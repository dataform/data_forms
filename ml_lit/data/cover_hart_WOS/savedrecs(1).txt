PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	PU	PI	PA	SN	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	PG	WC	SC	GA	UT
J	Pughineanu, C; Balan, I				Pughineanu, C.; Balan, I.			Parallel Algorithm Evaluation in the Image and Clustering Processing	ELEKTRONIKA IR ELEKTROTECHNIKA			English	Article							IMPLEMENTATION; SYSTEM	C. Pughineanu, I. Balan. Parallel Algorithm Evaluation in the Image and Clustering Processing // Electronics and Electrical Engineering. - Kaunas: Technologija, 2011. - No. 4(110). - P. 89-92. The increase of the information volume of the image type in the greatest part of the domains asks for the introduction of some storage and efficient recovery methods of the available data due to content. Unfortunately, the progress registered in the field of the multimedia databases with digital images is not remarkable as being outdated by info explosion. The article proposes compression algorithms aiming to reduce the quantity of data necessary to represent an image and the necessary clustering algorithms, namely the k-means algorithm and ISODATA, which were parallelized both from the point of view of the extracted areas and the execution time. The experimental results were obtained by the implementation of the algorithms using the MPI standard and their execution on a cluster. Ill. 12, bibl. 16 (in English; abstracts in English and Lithuanian).	[Pughineanu, C.; Balan, I.] Stefan Cel Mare Univ Suceava, Fac Elect Engn & Comp Sci, Suceava 720229, Romania	Pughineanu, C (reprint author), Stefan Cel Mare Univ Suceava, Fac Elect Engn & Comp Sci, Str Univ Nr 1, Suceava 720229, Romania.	secretariat@eed.usv.ro	Suceava, USV/E-8611-2011				BERRY WM, 2008, SURVEY TEXT MINING, V2; CIUFUDEAN C, 2009, 4 INT C IND APPL HOL, P225; Ciufudean C, 2009, ELEKTRON ELEKTROTECH, P51; CIUFUDEAN C, 2009, ELECT ELECT ENG, P65; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dambrauskas A, 2008, ELEKTRON ELEKTROTECH, P25; Feng Z, 2007, NEUROCOMPUTING, V70, P809, DOI 10.1016/j.neucom.2006.10.034; Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616; Memarsadeghi N, 2007, INT J COMPUT GEOM AP, V17, P71, DOI 10.1142/S0218195907002252; PENTIUC SG, 1997, APLICATII ALE RECUNO; Rata G, 2010, ELEKTRON ELEKTROTECH, P62; Pentiuc SG, 2010, ELEKTRON ELEKTROTECH, P87; TEUVO K, 1988, SELF ORG ASS MEMORY; Ungurean I, 2010, ELEKTRON ELEKTROTECH, P57; Vahdat-Nejad H, 2009, ADV ELECTR COMPUT EN, V9, P22, DOI 10.4316/AECE.2009.03005; Zamir O., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.290956	16	1	1	KAUNAS UNIV TECHNOLOGY	KAUNAS	KAUNAS UNIV TECHNOL, DEPT ELECTRONICS ENGINEERING, STUDENTU STR 50, KAUNAS, LT-51368, LITHUANIA	1392-1215		ELEKTRON ELEKTROTECH	Elektron. Elektrotech.		2011		4					89	92				4	Engineering, Electrical & Electronic	Engineering	761SU	WOS:000290422000020	
J	Xu, C; Mager, DE				Xu, Chao; Mager, Donald E.			Quantitative structure-pharmacokinetic relationships	EXPERT OPINION ON DRUG METABOLISM & TOXICOLOGY			English	Review						computational pharmacokinetics; machine learning algorithms; molecular descriptors; pharmacokinetics; physiologically-based pharmacokinetics	PLASMA-PROTEIN BINDING; STRUCTURE-PHARMACOKINETIC/PHARMACODYNAMIC RELATIONSHIPS; RELATIONSHIP 3D/4D-QSAR ANALYSES; ABSORPTION-DISPOSITION MODEL; MACHINE LEARNING TECHNIQUES; PHYSIOLOGICALLY-BASED MODEL; LIVER MICROSOMAL STABILITY; SUPPORT VECTOR MACHINE; ORAL-DRUG ABSORPTION; K-NEAREST-NEIGHBOR	Areas covered in this review: Empirical and mechanism-based QSPKR models are discussed, including specific examples for oral absorption, nonspecific protein binding, volume of distribution, total metabolic stability and specific interactions with drug metabolizing enzymes. Emphasis is placed on state-of-the-art techniques, including new approaches for the direct simulation of concentration-time profiles from molecular descriptors (temporal QSPKR). What the reader will gain: Reviewing the application of current QSPKR modeling techniques will place these methods in context and highlight their respective advantages and limitations, as well as opportunities for further refinement. Take home message: The expansion of readily available molecular descriptors and advanced algorithms has improved empirical models and enabled the development of robust models for non-congeneric series. Empirical models focus on point estimates of global PK processes and physiologically-based models may be more desirable than data-driven methods. Further integration of relevant biological and pharmacological mechanisms will improve the ability to predict the full time course of drug concentration and effect profiles for diverse compounds and experimental conditions.	[Xu, Chao; Mager, Donald E.] SUNY Buffalo, Dept Pharmaceut Sci, Buffalo, NY 14260 USA	Mager, DE (reprint author), SUNY Buffalo, Dept Pharmaceut Sci, 308 Hochstetter Hall, Buffalo, NY 14260 USA.	dmager@buffalo.edu	xu, chao/J-3781-2013	xu, chao/0000-0002-4574-0059	Eli Lilly Co.	C Xu has been supported with a Pre-Doctoral Fellowship from Eli Lilly & Co. DE Mager declares no conflict of interest and has received no payment in the preparation of this manuscript.	Afzelius L, 2004, J MED CHEM, V47, P907, DOI 10.1021/jm030972s; Afzelius L, 2004, DRUG METAB DISPOS, V32, P1218; Agoram B, 2001, ADV DRUG DELIVER REV, V50, pS41, DOI 10.1016/S0169-409X(01)00179-X; Almond LM, 2009, CURR DRUG METAB, V10, P420; Arrell DK, 2010, CLIN PHARMACOL THER, V88, P120, DOI 10.1038/clpt.2010.91; Austin RP, 2002, DRUG METAB DISPOS, V30, P1497, DOI 10.1124/dmd.30.12.1497; Balogh L, 2007, NANOMED-NANOTECHNOL, V3, P281, DOI 10.1016/j.nano.007.09.001; Bazeley PS, 2006, J CHEM INF MODEL, V46, P2698, DOI 10.1021/ci600267k; Berezhkovskiy LM, 2004, J PHARM SCI-US, V93, P1628, DOI 10.1002/jps.20073; Berger SI, 2009, BIOINFORMATICS, V25, P2466, DOI 10.1093/bioinformatics/btp465; Bermejo M, 1999, J PHARM SCI, V88, P398, DOI 10.1021/js980370+; Blakey GE, 1997, J PHARMACOKINET BIOP, V25, P277, DOI 10.1023/A:1025771608474; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Bursi R, 2001, J MOL GRAPH MODEL, V19, p[552, 607]; Bursi R, 2001, J MOL GRAPH MODEL, V19, P552, DOI 10.1016/S1093-3263(01)00089-4; Byvatov E, 2007, QSAR COMB SCI, V26, P618, DOI 10.1002/qsar.200630143; Chang C, 2009, J PHARM SCI-US, V98, P2857, DOI 10.1002/jps.21651; Chohan KK, 2005, J MED CHEM, V48, P5154, DOI 10.1021/jm048959a; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Czodrowski P, 2009, EXPERT OPIN DRUG MET, V5, P15, DOI [10.1517/17425250802568009 , 10.1517/17425250802568009]; Deconinck E, 2005, J PHARMACEUT BIOMED, V39, P91, DOI 10.1016/j.jpba.2005.03.008; DEDRICK RL, 1970, CANCER CHEMOTH REP 1, V54, P95; de Graaf C, 2005, J MED CHEM, V48, P2725, DOI 10.1021/jm040180d; DRESSMAN JB, 1985, J PHARM SCI, V74, P588, DOI 10.1002/jps.2600740523; Eitrich T, 2007, J CHEM INF MODEL, V47, P92, DOI 10.1021/ci60026l9; Ekins S, 2000, DRUG METAB DISPOS, V28, P994; Ekins S, 1999, PHARMACOGENETICS, V9, P477; Ekins S, 1999, J PHARMACOL EXP THER, V291, P424; Ekins S, 1999, J PHARMACOL EXP THER, V288, P21; Ekins S, 1999, J PHARMACOL EXP THER, V290, P429; Fenneteau F, 2010, J PHARM SCI-US, V99, P486, DOI 10.1002/jps.21802; Fliszar KA, 2007, J PHARM SCI-US, V96, P2161, DOI 10.1002/jps.20866; Gao H, 2008, DRUG METAB DISPOS, V36, P2130, DOI 10.1124/dmd.107.020131; Terfloth L, 2007, J CHEM INF MODEL, V47, P1688, DOI 10.1021/ci700010t; GELADI P, 1986, ANAL CHIM ACTA, V185, P1, DOI 10.1016/0003-2670(86)80028-9; Gertz M, 2008, DRUG METAB DISPOS, V36, P535, DOI 10.1124/dmd.107.018713; Ghuman J, 2005, J MOL BIOL, V353, P38, DOI 10.1016/j.jmb.2005.07.075; Gleeson MP, 2006, J MED CHEM, V49, P1953, DOI 10.1021/jm0510070; Gleeson MP, 2007, J COMPUT AID MOL DES, V21, P559, DOI 10.1007/s10822-007-9139-6; Gleeson MP, 2007, J MED CHEM, V50, P101, DOI 10.1021/jm060981b; Gobburu JVS, 1996, J PHARM SCI, V85, P505, DOI 10.1021/js950433d; Grass GM, 2001, DRUG DISCOV TODAY, V6, pS54; HINDERLING PH, 1984, J PHARMACOKINET BIOP, V12, P263, DOI 10.1007/BF01061721; Hou T, 2008, EXPERT OPIN DRUG MET, V4, P759, DOI [10.1517/17425255.4.6.759 , 10.1517/17425250802137235]; Hou TJ, 2007, J CHEM INF MODEL, V47, P2408, DOI 10.1021/ci7002076; Hou TJ, 2007, J CHEM INF MODEL, V47, P208, DOI 10.1021/ci600343x; Hudelson MG, 2008, J MED CHEM, V51, P648, DOI 10.1021/jm701130z; Jamei M, 2009, EXPERT OPIN DRUG MET, V5, P211, DOI [10.1517/17425250802691074 , 10.1517/17425250802691074]; Jensen BF, 2007, J MED CHEM, V50, P501, DOI 10.1021/jm060333; Jensen BF, 2003, J COMPUT AID MOL DES, V17, P849, DOI 10.1023/B:JCAM.0000021861.31978.da; Johnson TN, 2008, J PEDIATR GASTR NUTR, V47, P3, DOI 10.1097/MPG.0b013e31816a8cca; Johnson TN, 2010, CLIN PHARMACOKINET, V49, P189, DOI 10.2165/11318160-000000000-00000; Jones HM, 2004, DRUG METAB DISPOS, V32, P973, DOI 10.1124/dmd.104.000125; Jones HM, 2006, CLIN PHARMACOKINET, V45, P511, DOI 10.2165/00003088-200645050-00006; Jung E, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-245; Kamgang E, 2008, SAR QSAR ENVIRON RES, V19, P669, DOI 10.1080/10629360802547313; Karelson M., 2000, MOL DESCRIPTORS QSAR; Kier LB, 1976, MOL CONNECTIVITY CHE; Kilford PJ, 2008, DRUG METAB DISPOS, V36, P1194, DOI 10.1124/dmd.108.020834; Klopman G, 2002, EUR J PHARM SCI, V17, P253, DOI 10.1016/S0928-0987(02)00219-1; Kriegl JM, 2005, J COMPUT AID MOL DES, V19, P189, DOI 10.1007/s10822-005-3785-3; Lee PH, 2007, J COMPUT AID MOL DES, V21, P665, DOI 10.1007/s10822-007-9124-0; Linnankoski J, 2006, J MED CHEM, V49, P3674, DOI 10.1021/jm051231p; Lipinski CA, 1997, ADV DRUG DELIVER REV, V23, P3, DOI 10.1016/S0169-409X(96)00423-1; Lombardo F, 2006, J MED CHEM, V49, P2262, DOI 10.1021/jm050200r; Lombardo F, 2002, J MED CHEM, V45, P2867, DOI 10.1021/jm0200409; Lombardo F, 2004, J MED CHEM, V47, P1242, DOI 10.1021/jm030408h; Luttringer O, 2003, J PHARM SCI, V92, P1990, DOI 10.1002/jps.10461; Mager DE, 2003, J PHARM SCI, V92, P881, DOI 10.1002/jps.10343; Mager DE, 2001, J PHARMACOKINET PHAR, V28, P507, DOI 10.1023/A:1014414520282; Mager DE, 2006, ADV DRUG DELIVER REV, V58, P1326, DOI 10.1016/j.addr.2006.08.002; Mager DE, 2002, J PHARM SCI-US, V91, P2441, DOI 10.1002/jps.10231; Martinez MN, 2002, J CLIN PHARMACOL, V42, P620, DOI 10.1177/00970002042006005; MAYER JM, 1988, J PHARM SCI, V77, P359, DOI 10.1002/jps.2600770416; Nestorov I, 1998, J PHARMACOKINET BIOP, V26, P521, DOI 10.1023/A:1023221116200; Nigavekar SS, 2004, PHARM RES, V21, P476, DOI 10.1023/B:PHAM.0000019302.26097.cc; Obach RS, 2008, DRUG METAB DISPOS, V36, P1385, DOI 10.1124/dmd.108.020479; Obach RS, 1999, DRUG METAB DISPOS, V27, P1350; Obrezanova O, 2007, J CHEM INF MODEL, V47, P1847, DOI 10.1021/ci7000633; O'Brien SE, 2005, J MED CHEM, V48, P1287, DOI 10.1021/jm049254b; OIE S, 1979, J PHARM SCI, V68, P1203, DOI 10.1002/jps.2600680948; Oprea TI, 2004, CURR OPIN CHEM BIOL, V8, P349, DOI 10.1016/j.cbpa.2004.06.008; Palm K, 1997, PHARMACEUT RES, V14, P568, DOI 10.1023/A:1012188625088; Park S, 2010, J PHARMACOL EXP THER, V334, P124, DOI 10.1124/jpet.110.168526; Peters SA, 2008, CLIN PHARMACOKINET, V47, P261, DOI 10.2165/00003088-200847040-00004; Poulin P, 2002, J PHARM SCI, V91, P1358, DOI 10.1002/jps.10128; Poulin P, 2001, J PHARM SCI, V90, P436, DOI 10.1002/1520-6017(200104)90:4<436::AID-JPS1002>3.0.CO;2-P; Poulin P, 2000, J PHARM SCI, V89, P16, DOI 10.1002/(SICI)1520-6017(200001)89:1<16::AID-JPS3>3.0.CO;2-E; Poulin P, 2009, J PHARM SCI-US, V98, P4941, DOI 10.1002/jps.21759; Ripley B. D., 1996, PATTERN RECOGNITION; Rodgers T, 2006, J PHARM SCI-US, V95, P1238, DOI 10.1002/jps.20502; Rodgers T, 2005, J PHARM SCI-US, V94, P1259, DOI 10.1002/jps.20322; Sakiyama Y, 2009, EXPERT OPIN DRUG MET, V5, P149, DOI [10.1517/17425250902753261 , 10.1517/17425250902753261]; Sakiyama Y, 2008, J MOL GRAPH MODEL, V26, P907, DOI 10.1016/j.jmgm.2007.06.005; Schneider G, 2005, NAT REV DRUG DISCOV, V4, P649, DOI 10.1038/nrd1799; Schwaighofer A, 2008, J CHEM INF MODEL, V48, P785, DOI 10.1021/ci700142c; Shen M, 2003, J MED CHEM, V46, P3013, DOI 10.1021/jm020491t; Sui XF, 2009, EUR J MED CHEM, V44, P4455, DOI 10.1016/j.ejmech.2009.06.004; Sun H, 2010, CHEM BIOL DRUG DES, V75, P3, DOI 10.1111/j.1747-0285.2009.00899.x; TOON S, 1983, J PHARMACOL EXP THER, V225, P752; Turner JV, 2004, PHARM RES, V21, P68, DOI 10.1023/B:PHAM.0000012154.09631.26; Urva SR, 2010, J PHARM SCI-US, V99, P1582, DOI 10.1002/jps.21918; Usansky HH, 2005, J PHARMACOL EXP THER, V314, P391, DOI 10.1124/jpet.104.076182; van de Waterbeemd H, 2001, J COMPUT AID MOL DES, V15, P273, DOI 10.1023/A:1008192010023; Vapnik V.N., 1995, NATURE STAT LEARNING; VENGPEDERSEN P, 1993, J PHARM SCI, V82, P918, DOI 10.1002/jps.2600820910; Votano JR, 2006, J MED CHEM, V49, P7169, DOI 10.1021/jm051245v; Wajima T, 2004, J PHARM SCI-US, V93, P1890, DOI 10.1002/jps.20099; Walker JR, 2009, J CLIN PHARMACOL, V49, P1185, DOI 10.1177/0091270009340783; Wang JM, 2006, J CHEM INF MODEL, V46, P2674, DOI 10.1021/ci060087t; Wang W, 2008, CLIN PHARMACOL THER, V84, P548, DOI 10.1038/clpt.2008.170; Wang YH, 2005, BIOORG MED CHEM LETT, V15, P4076, DOI 10.1016/j.bmcl.2005.06.015; Watanabe T, 2009, J PHARMACOL EXP THER, V328, P652, DOI 10.1124/jpet.108.146647; WATARI N, 1988, J PHARMACOKINET BIOP, V16, P279, DOI 10.1007/BF01062138; Willmann S, 2004, J MED CHEM, V47, P4022, DOI 10.1021/jm030999b; Winkler DA, 2004, MOL BIOTECHNOL, V27, P139, DOI 10.1385/MB:27:2:139; Xu C, 2009, ACTA CRYSTALLOGR E, V65, pM517, DOI 10.1107/S1600536809012288; Yan L, 2008, DRUG METAB DISPOS, V36, P759, DOI 10.1124/dmd.107.019067; Yap CW, 2005, J PHARM SCI-US, V94, P153, DOI 10.1002/jps.20232; Yap CW, 2006, J MOL GRAPH MODEL, V24, P383, DOI 10.1016/j.jmgm.2005.10.004; Yu LX, 1999, INT J PHARM, V186, P119, DOI 10.1016/S0378-5173(99)00147-7	122	1	1	INFORMA HEALTHCARE	LONDON	TELEPHONE HOUSE, 69-77 PAUL STREET, LONDON EC2A 4LQ, ENGLAND	1742-5255		EXPERT OPIN DRUG MET	Expert Opin. Drug Metab. Toxicol.	JAN	2011	7	1					63	77		10.1517/17425255.2011.537257		15	Biochemistry & Molecular Biology; Pharmacology & Pharmacy	Biochemistry & Molecular Biology; Pharmacology & Pharmacy	696AW	WOS:000285415300005	
J	Tallon-Ballesteros, AJ; Hervas-Martinez, C				Tallon-Ballesteros, Antonio J.; Hervas-Martinez, Cesar			A two-stage algorithm in evolutionary product unit neural networks for classification	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Artificial neural networks; Product units; Evolutionary algorithms; Classification; Population diversity	LISTERIA-MONOCYTOGENES; GENETIC ALGORITHMS; GROWTH LIMITS; POPULATION; REGRESSION; DIVERSITY	This paper presents a procedure to add broader diversity at the beginning of the evolutionary process. It consists of creating two initial populations with different parameter settings, evolving them for a small number of generations, selecting the best individuals from each population in the same proportion and combining them to constitute a new initial population. At this point the main loop of an evolutionary algorithm is applied to the new population. The results show that our proposal considerably improves both the efficiency of previous methodologies and also, significantly, their efficacy in most of the data sets. We have carried out our experimentation on twelve data sets from the UCI repository and two complex real-world problems which differ in their number of instances, features and classes. (C) 2010 Elsevier Ltd. All rights reserved.	[Tallon-Ballesteros, Antonio J.] Univ Seville, Dept Languages & Comp Syst, E-41012 Seville, Spain; [Hervas-Martinez, Cesar] Univ Cordoba, Dept Comp Sci & Numer Anal, E-14071 Cordoba, Spain	Tallon-Ballesteros, AJ (reprint author), Univ Seville, Dept Languages & Comp Syst, Reina Mercedes Ave, E-41012 Seville, Spain.	atallon@us.es; chervas@uco.es			Spanish Inter-Ministerial Commission of Science and Technology (MICYT) [TIN2007-68084-C02-02, TIN2008-06681-C06-03]; FEDER; "Junta de Andalucia" (Spain) [P08-TIC-3745]	This work has been partially subsidized by TIN2007-68084-C02-02 and TIN2008-06681-C06-03 projects of the Spanish Inter-Ministerial Commission of Science and Technology (MICYT), FEDER funds and the P08-TIC-3745 project of the "Junta de Andalucia" (Spain).	Abraham A, 2004, NEUROCOMPUTING, V56, P1, DOI 10.1016/S0925-2312(03)00369-2; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; AMOR H. B., 2005, P GECCO 2005, P1531, DOI 10.1145/1068009.1068250; ANGELINE PJ, 1994, IEEE T NEURAL NETWOR, V5, P54, DOI 10.1109/72.265960; Asuncion A., 2007, UCI MACHINE LEARNING; Beuchat LR, 1996, FOOD CONTROL, V7, P223, DOI 10.1016/S0956-7135(96)00039-4; Bishop C. M., 1995, NEURAL NETWORKS PATT; CHOP NE, 2005, P ART NEUR NETW ENG; Commission E., 1999, OP SCI COMM VET MEAS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Curran D, 2006, ADAPT BEHAV, V14, P315, DOI 10.1177/1059712306072335; de Garis H., 1990, P 7 INT C MACH LEARN, P132; Dunn O.J., 1974, APPL STAT ANAL VARIA; Durbin R., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.1.133; Fenlon DR, 1996, J APPL BACTERIOL, V81, P641, DOI 10.1111/j.1365-2672.1996.tb01966.x; Frank E., 1998, P 15 INT C MACH LEAR, P144; Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372; Goh CK, 2008, IEEE T NEURAL NETWOR, V19, P1531, DOI 10.1109/TNN.2008.2000444; Goldberg D. E, 1989, GENETIC ALGORITHMS S; HEITKOETTER J, 2001, HITCH HIKERS GUIDE E; Hervas C, 2008, CHEMOMETR INTELL LAB, V92, P179, DOI 10.1016/j.chemolab.2008.03.005; HOCHBERG Y, 1987, MULTIPLE COMP MEANS; HOWLETT RJ, 2001, RECENT DEV THEORY AP, V1; IMAN RL, 1980, COMMUN STAT A-THEOR, V9, P571, DOI 10.1080/03610928008827904; Inoue H., 2005, P INT JOINT C NEUR N, V2, P1205, DOI 10.1109/IJCNN.2005.1556025; Ismaily A., 2000, INT JOINT C NEUR NET, V1, P132; JANSON DJ, 1993, IEEE EXPERT, V8, P26, DOI 10.1109/64.236478; Kohavi R., 1995, P 14 INT JOINT C ART, V2, P1137; Lozano M, 2008, INFORM SCIENCES, V178, P4421, DOI 10.1016/j.ins.2008.07.031; Maaranen H, 2004, COMPUT MATH APPL, V47, P1885, DOI 10.1016/j.camwa.2003.07.011; Maaranen H, 2007, J GLOBAL OPTIM, V37, P405, DOI 10.1007/s10898-006-9056-6; Mahfoud S. W., 1995, THESIS U ILLINOIS UR; Martinez-Estudillo A, 2006, NEURAL NETWORKS, V19, P477, DOI 10.1016/j.neunet.2005.11.001; Martinez-Estudillo FJ, 2006, LECT NOTES COMPUT SC, V4224, P1320; MILLER GF, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P379; Miller RG, 1981, SIMULTANEOUS STAT IN; Prechelt L., 1994, 2194 U KARLSR FAK IN; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Rechenberg I., 1973, EVOLUTIONSSTRATEGIE; Schmitt M, 2001, NEURAL COMPUT, V14, P241; Snedecor G. W., 1980, STAT METHODS; Tallon-Ballesteros A. J., 2007, P IADIS INT C APPL C, P266; Tienungoon S, 2000, APPL ENVIRON MICROB, V66, P4979, DOI 10.1128/AEM.66.11.4979-4987.2000; URSEM R., 2002, LECT NOTES COMPUTER, V2439, P462; Valero A, 2007, FOOD MICROBIOL, V24, P452, DOI 10.1016/j.fm.2006.10.002; Vapnik V.N., 1995, NATURE STAT LEARNING; Wang L., 2002, P 4 WORLD C INT CONT, V3, P1769; Witten I., 2005, DATA MINING PRACTICA; Yao X, 1997, IEEE T NEURAL NETWOR, V8, P694, DOI 10.1109/72.572107; Yao X, 1999, P IEEE, V87, P1423	50	5	5	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	JAN	2011	38	1					743	754		10.1016/j.eswa.2010.07.028		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	660AA	WOS:000282607800084	
S	Markowska-Kaczmar, U; Minda, P; Ociepa, K; Olszowy, D; Pawlikowski, R		Corchado, E; Kurzynski, M; Wozniak, M		Markowska-Kaczmar, Urszula; Minda, Pawel; Ociepa, Krzysztof; Olszowy, Dariusz; Pawlikowski, Roman			Towards Automatic Image Annotation Supporting Document Understanding	HYBRID ARTIFICIAL INTELLIGENT SYSTEMS, PART I	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	6th International Conference on Hybrid Artificial Intelligence Systems (HAIS 2011)	MAY 23-25, 2011	Wroclaw, POLAND	Wroclaw Univ Technol, IEEE Systems, Man & Cybernet Soc, Spanish Chapter, IEEE Systems, Man & Cybernet Soc, Czech Republ Chapter, Spanish Assoc Artificial Intelligence, MIR LABS, Int Federat Computat Logic	Wroclaw Univ Technol	Image annotation; image classification; text understanding; feature extraction; machine learning; SVM; k-NN; fuzzy logic	CLASSIFICATION	The paper describes our research concerning image classification of types of graphics like plots, flow charts, illustrations and photos. Illustrations and photos are also classified into one of the following semantic classes: buildings, people, nature landscape, and interior. On this basis each image is annotated by its type and class. The key elements of the system - feature extraction and classification methods - are described in detail. A new classifier based on fuzzy logic was proposed. Moreover, we developed the Multi-Classifier, a hierarchical architecture encouraging the creation of hybrid classifiers tailored to the problem being solved. Experimental results of classification efficiency show that our approach is definitely worth further development.	[Markowska-Kaczmar, Urszula; Minda, Pawel; Ociepa, Krzysztof; Olszowy, Dariusz; Pawlikowski, Roman] Wroclaw Univ Technol, PL-50370 Wroclaw, Poland	Markowska-Kaczmar, U (reprint author), Wroclaw Univ Technol, PL-50370 Wroclaw, Poland.	urszula.markowska-kaczmar@pwr.wroc.pl					Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679; Chen L., 2003, IEEE Trans. Syst. Man Cybernet, V3, P2049; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Lu X., 2009, IJDAR, V12; Malathi G., 2010, IJCA, V1, P0975; [Anonymous], ALIPR-Automatic Photo Tagging and Visual Image Search; [Anonymous], MIT Indoor Scene Recognition Database	10	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-21218-5	LECT NOTES ARTIF INT			2011	6678						420	427				8	Computer Science, Artificial Intelligence	Computer Science	BXZ78	WOS:000297712100053	
S	Triguero, I; Garcia, S; Herrera, F		Corchado, E; Kurzynski, M; Wozniak, M		Triguero, Isaac; Garcia, Salvador; Herrera, Francisco			Enhancing IPADE Algorithm with a Different Individual Codification	HYBRID ARTIFICIAL INTELLIGENT SYSTEMS, PART II	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	6th International Conference on Hybrid Artificial Intelligence Systems (HAIS 2011)	MAY 23-25, 2011	Wroclaw, POLAND	Wroclaw Univ Technol, IEEE Systems, Man & Cybernet Soc, Spanish Chapter, IEEE Systems, Man & Cybernet Soc, Czech Republ Chapter, Spanish Assoc Artificial Intelligence, MIR LABS, Int Federat Computat Logic	Wroclaw Univ Technol		CLASSIFICATION; ABSTRACTION; CLASSIFIERS; PROTOTYPES	Nearest neighbor is one of the most used techniques for performing classification tasks. However, its simplest version has several drawbacks, such as low efficiency, storage requirements and sensitivity to noise. Prototype generation is an appropriate process to alleviate these drawbacks that allows the fitting of a data set for nearest neighbor classification. In this work, we present an extension of our previous proposal called IPADE, a methodology to learn iteratively the positioning of prototypes using a differential evolution algorithm. In this extension, which we have called IPADECS, a complete solution is codified in each individual. The results are contrasted with non-parametrical statistical tests and show that our proposal outperforms previously proposed methods.	[Triguero, Isaac; Herrera, Francisco] Univ Granada, CITIC UGR, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain	Triguero, I (reprint author), Univ Granada, CITIC UGR, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain.	triguero@decsai.ugr.es; sglopez@ujaen.es; herrera@decsai.ugr.es	Herrera, Francisco/C-6856-2008	Herrera, Francisco/0000-0002-7283-312X			ALCALAFDEZ J, 2010, J MULTIPLE VALUED LO; Alpaydin E., 2010, INTRO MACHINE LEARNI; Cervantes A, 2009, IEEE T SYST MAN CY B, V39, P1082, DOI 10.1109/TSMCB.2008.2011816; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; Chen CH, 1996, PATTERN RECOGN LETT, V17, P819, DOI 10.1016/0167-8655(96)00041-4; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FERRANTE N, 2009, MEMETIC COMPUTING, V1, P153; Garcia EK, 2010, IEEE T KNOWL DATA EN, V22, P1274, DOI 10.1109/TKDE.2009.159; Garcia S, 2010, INFORM SCIENCES, V180, P2044, DOI 10.1016/j.ins.2009.12.010; Garcia S, 2008, PATTERN RECOGN, V41, P2693, DOI 10.1016/j.patcog.2008.02.006; Garcia S, 2008, J MACH LEARN RES, V9, P2677; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Lam W, 2002, IEEE T PATTERN ANAL, V24, P1075; LIU H, 2001, INT SERIES ENG COMPU; Sanchez JS, 2004, PATTERN RECOGN, V37, P1561, DOI 10.1016/j.patcog.2003.12.012; Triguero I, 2010, IEEE T NEURAL NETWOR, V21, P1984, DOI 10.1109/TNN.2010.2087415	16	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-21221-5	LECT NOTES ARTIF INT			2011	6679						262	270				9	Computer Science, Artificial Intelligence	Computer Science	BXZ79	WOS:000297712800032	
S	Chahine, K; Drissi, KE; Pasquier, C; Kerroum, K; Faure, C; Jouannet, T; Michou, M		Salame, C; ElCharif, H; Hassan, FE; ElTahchi, M		Chahine, Khaled; Drissi, Khalil El Khamlichi; Pasquier, Christophe; Kerroum, Kamal; Faure, Claire; Jouannet, Thierry; Michou, Michel			Electric Load Disaggregation in Smart Metering Using a Novel Feature Extraction Method and Supervised Classification	IMPACT OF INTEGRATED CLEAN ENERGY ON THE FUTURE OF THE MEDITERRANEAN ENVIRONMENT	Energy Procedia		English	Proceedings Paper	Conference on Impact of Integrated Clean Energy on the Future of the Mediterranean Environment	APR 14-16, 2011	Beirut, LEBANON			Matrix Pencil Method; Nonintrusive Appliance Load Monitoring; Supervised Learning; Power Saving; Smart Meters		Improving energy efficiency by monitoring household electrical consumption is of significant importance with the present-day climate change concerns. A solution for the electrical consumption management problem is the use of a nonintrusive appliance load monitoring system. This system captures the signals from the aggregate consumption, extracts the features from these signals and classifies the extracted features in order to identify the switched on appliances. This paper complements a novel feature extraction scheme presented in a previous work for load disaggregation with a comparative study of supervised classification methods. The objective of the current work is hence to make use of the feature extraction scheme to construct a database of signatures and then to compare different supervised learning methods for load classification. Preliminary results indicate high classification accuracy of all tested methods.	[Chahine, Khaled; Drissi, Khalil El Khamlichi; Pasquier, Christophe; Kerroum, Kamal; Faure, Claire] Univ Clermont Ferrand, CNRS, UMR 6602, LASMEA, F-63177 Aubiere, France	Chahine, K (reprint author), Univ Clermont Ferrand, CNRS, UMR 6602, LASMEA, 24 Ave Landais, F-63177 Aubiere, France.	khaled.chahine@univ-bpclermont.fr					Cestnik B, 1987, PROGR MACHINE LEARNI, P31; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HART GW, 1992, P IEEE, V80, P1870, DOI 10.1109/5.192069; HUA Y, 1990, IEEE T ACOUST SPEECH, V38, P814, DOI 10.1109/29.56027; Najmeddine H., 2008, French Patent, Patent No. [FR 0856717, 0856717]; Najmeddine H., 2010, P 9 INT C ENV EL ENG, P238; Vapnik V.N., 1995, NATURE STAT LEARNING	7	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1876-6102		ENRGY PROCED			2011	6						627	632		10.1016/j.egypro.2011.05.072		6	Energy & Fuels; Environmental Sciences	Energy & Fuels; Environmental Sciences & Ecology	BYE94	WOS:000298294900072	
J	Zurada, J; Karwowski, W				Zurada, Jozef; Karwowski, Waldemar			Knowledge Discovery Through Experiential Learning From Business and Other Contemporary Data Sources: A Review and Reappraisal	INFORMATION SYSTEMS MANAGEMENT			English	Article						knowledge discovery in databases; data mining; methods; tools; methodologies; experiential learning; applications; review	FUZZY INFERENCE SYSTEM; CLASSIFICATION; NETWORKS	Every day massive amount of data is generated, collected, and stored in information repositories such as databases and data warehouses. Current information technology is sufficiently mature and powerful to store any amount of raw data in an organized manner. However, finding useful patterns, trends, rules, correlations, and deviations in large amount of data, and/or making meaningful predictions from it still remains one of the main challenges of the information era. The more data one has, the more difficult it is to analyze and draw meaningful conclusions. Knowledge discovery in databases (KDD) and data mining (DM) is a field, which uses computer-based and analytic technologies to efficiently extract intelligence from data that humans need. In this article, we review the process of knowledge discovery in databases, and describe selected methodologies, methods and tools, tasks, basic learning paradigms, and applications for knowledge generation by computer learning from data instances. We also examine the current trends in the field with respect to the data types mined, data mining methods used, classes of data mining applications, as well as the data mining software used.	[Zurada, Jozef] Univ Louisville, Dept Comp Informat Syst, Coll Business, Louisville, KY 40292 USA; [Karwowski, Waldemar] Univ Cent Florida, Inst Adv Syst Engn, Dept Ind Engn & Management Syst, Orlando, FL 32816 USA	Zurada, J (reprint author), Univ Louisville, Dept Comp Informat Syst, Coll Business, Louisville, KY 40292 USA.	jmzura01@louisville.edu					Adriaans P., 1996, DATA MINING; Aggarwal C.C, 2005, NEXT GENERATION DATA, P447; Berry MJA, 2000, MASTERING DATA MININ; Breiman L, 1984, CLASSIFICATION REGRE; Burr Ridge I, 1997, MACHINE LEARNING; Chan C, 2002, INFORM SYST MANAGE, V19, P56, DOI 10.1201/1078/43202.19.4.20020901/38835.7; Cherkassky V., 1999, LEARNING DATA CONCEP; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dhar V, 1997, 7 METHODS TRANSFORMI; Fayyad U, 1996, COMMUN ACM, V39, P27, DOI 10.1145/240455.240464; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Frawley W., 1992, AI MAGAZINE      FAL, P213; Giudici P, 2003, APPL DATA MINING STA; Goldberg D. E, 1989, GENETIC ALGORITHMS S; Guan J, 2008, J REAL ESTATE RES, V30, P395; Han J., 2001, DATA MINING CONCEPTS; Hand DJ, 1997, J R STAT SOC A STAT, V160, P523, DOI 10.1111/j.1467-985X.1997.00078.x; Holland J. H., 1992, ADAPTATION NATURAL A; HOLLAND JH, 1992, SCI AM, V267, P66; Hormozi AM, 2004, INFORM SYST MANAGE, V21, P62, DOI 10.1201/1078/44118.21.2.20040301/80423.9; Huang YM, 2006, NONLINEAR ANAL-REAL, V7, P720, DOI 10.1016/j.nonrwa.2005.04.006; JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541; Jern M, 1998, INFORM SYSTEMS MANAG, V15, P1, DOI 10.1201/1078/43185.15.3.19980601/31137.10; Kantardzic M., 2005, NEW GENERATION DATA; Kantardzic M., 2003, DATA MINING CONCEPTS; Merril D.M., 1977, TEACHING CONCEPTS IN; Oxford English Dictionary for Schools, 2008, OXFORD ENGLISH DICT; Pai W. C., 2004, Information Systems Management, V21, DOI 10.1201/1078/43877.21.1.20041201/78988.8; Park J., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.246; Pedrycz W., 1998, INTRO FUZZY SETS ANA; Piatetsky-Shapiro G., 2006, SIGKDD EXPLORATIONS, V8, P70; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Power DJ, 2008, INFORM SYST MANAGE, V25, P149, DOI 10.1080/10580530801941124; PYLE D, 1999, DATA PREPARATION DAT, DOI DOI 10.1080/10580530801941124; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Roiger R., 2003, BUS AN BUS INT SOFTW; Roiger R. J., 2003, DATA MINING TUTORIAL; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Stehr Nico, 1994, KNOWLEDGE SOC; Stehr Nico, 2001, FRAGILITY MODERN SOC; Tan P. N., 2006, INTRO DATA MINING; Tan P-N., 2006, NEW GENERATION DATA; Vapnik V.N, 1998, CZECH J EC FINANCE; Vapnik V.N., 1998, STAT LEARNING THEORY; Witten I., 2005, DATA MINING PRACTICA; Yang YX, 2007, EUR J OPER RES, V183, P1521, DOI 10.1016/j.ejor.2006.10.066; Yoon Y, 1999, INFORM SYST MANAGE, V16, P64, DOI 10.1201/1078/43188.16.2.19990301/31178.10; Zadeh L, 1965, OPEN STANDARDS CLOUD, V8, P338; Zadeh L.A., 1965, FUZZY SETS INFORM CO, P338, DOI DOI 10.1016/S0019-9958(65)90241-X; Zeller M., 2007, REV BUSINESS INFORM	51	2	2	AUERBACH PUBLICATIONS	BOCA RATON	C/O CRC PRESS L L C, 2000 CORPORATE BLVD NW, BOCA RATON, FL 33431 USA	1058-0530		INFORM SYST MANAGE	Inf. Syst. Manage.		2011	28	3			SI		258	274		10.1080/10580530.2010.493846		17	Computer Science, Information Systems	Computer Science	887VR	WOS:000299960000007	
J	Jeng, SL; Liu, YT				Jeng, Shuen-Lin; Liu, Yu-Te			Adaptive tangent distance classifier on recognition of handwritten digits	JOURNAL OF APPLIED STATISTICS			English	Article						adaptive nearest neighbor; handwritten digit; invariant transformation; pattern recognition; tangent distance	PATTERN-RECOGNITION; ALGORITHM	Simard et al. [16,17] proposed a transformation distance called "tangent distance" (TD) which can make pattern recognition be efficient. The key idea is to construct a distance measure which is invariant with respect to some chosen transformations. In this research, we provide a method using adaptive TD based on an idea inspired by "discriminant adaptive nearest neighbor" [7]. This method is relatively easy compared with many other complicated ones. A real handwritten recognition data set is used to illustrate our new method. Our results demonstrate that the proposed method gives lower classification error rates than those by standard implementation of neural networks and support vector machines and is as good as several other complicated approaches.	[Jeng, Shuen-Lin] Natl Cheng Kung Univ, Dept Stat, Tainan 70101, Taiwan; [Liu, Yu-Te] Natl Cheng Kung Univ, Dept Ind & Informat Management, Tainan 70101, Taiwan	Jeng, SL (reprint author), Natl Cheng Kung Univ, Dept Stat, Tainan 70101, Taiwan.	sljeng@mail.ncku.edu.tw					Adankon MM, 2009, PATTERN RECOGN, V42, P3264, DOI 10.1016/j.patcog.2008.10.023; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Haasdonk B., 2002, V2, P864; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hastie T, 2009, ELEMENTS STAT LEARNI; Hastie T., 1995, V7, P999; John G.C., 1979, ACM Trans. Math. Softw, V5, P183; Keysers D., 2000, P 15 INT C PATT REC, V2, P38, DOI 10.1109/ICPR.2000.906014; Keysers D, 2004, IEEE T PATTERN ANAL, V26, P269, DOI 10.1109/TPAMI.2004.1262198; Li B, 2008, PATTERN RECOGN, V41, P3287, DOI 10.1016/j.patcog.2008.05.014; Paredes R., 2002, V2, P38; Rivest R.L., 1974, Information Processing '74, P678; Shen C, 2008, PATTERN RECOGN, V41, P3644, DOI 10.1016/j.patcog.2008.06.015; SIMARD P, 1993, ADV NEURAL INFORMATI, V5, P50; Simard PY, 2000, INT J IMAG SYST TECH, V11, P181, DOI 10.1002/1098-1098(2000)11:3<181::AID-IMA1003>3.0.CO;2-E; Sona D., 1998, P377; Sona D, 1997, ADV NEUR IN, V9, P786; Vasconcelos N., 1997, V10, P843; Xue H, 2009, PATTERN RECOGN, V42, P93, DOI 10.1016/j.patcog.2008.07.010; Yvonne C.B., 1982, Analysis, Manifolds and Physics	21	0	0	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0266-4763		J APPL STAT	J. Appl. Stat.		2011	38	11					2647	2659		10.1080/02664763.2011.567247		13	Statistics & Probability	Mathematics	873YY	WOS:000298923300018	
J	Xiao, XA; Wang, P; Chou, KC				Xiao, Xuan; Wang, Pu; Chou, Kuo-Chen			GPCR-2L: predicting G protein-coupled receptors and their types by hybridizing two different modes of pseudo amino acid compositions	MOLECULAR BIOSYSTEMS			English	Article							STRUCTURAL CLASS PREDICTION; SUBCELLULAR LOCATION PREDICTION; FUNCTIONAL DOMAIN COMPOSITION; SUPPORT VECTOR MACHINE; MODIFIED MAHALANOBIS DISCRIMINANT; COMPLEXITY MEASURE FACTOR; INFLUENZA-A VIRUS; APOPTOSIS PROTEINS; MEMBRANE-PROTEINS; EVOLUTION INFORMATION	G protein-coupled receptors (GPCRs) are among the most frequent targets of therapeutic drugs. With the avalanche of newly generated protein sequences in the post genomic age, to expedite the process of drug discovery, it is highly desirable to develop an automated method to rapidly identify GPCRs and their types. A new predictor was developed by hybridizing two different modes of pseudo-amino acid composition (PseAAC): the functional domain PseAAC and the low-frequency Fourier spectrum PseAAC. The new predictor is called GPCR-2L, where "2L" means that it is a two-layer predictor: the 1st layer prediction engine is to identify a query protein as GPCR or not; if it is, the prediction will be automatically continued to further identify it as belonging to one of the following six types: (1) rhodopsin-like (Class A), (2) secretin-like (Class B), (3) metabotropic glutamate/pheromone (Class C), (4) fungal pheromone (Class D), (5) cAMP receptor (Class E), or (6) frizzled/smoothened family (Class F). The overall success rate of GPCR-2L in identifying proteins as GPCRs or non-GPCRs is over 97.2%, while identifying GPCRs among their six types is over 97.8%. Such high success rates were derived by the rigorous jackknife cross-validation on a stringent benchmark dataset, in which none of the included proteins had >= 40% pairwise sequence identity to any other protein in a same subset. As a user-friendly web-server, GPCR-2L is freely accessible to the public at http://icpr.jci.edu.cn/bioinfo/GPCR-2L, by which one can obtain the 2-level results in about 20 s for a query protein sequence of 500 amino acids. The longer the sequence is, the more time it may usually need. The high success rates reported here indicate that it is a quite effective approach to identify GPCRs and their types with the functional domain information and the low-frequency Fourier spectrum analysis. It is anticipated that GPCR-2L may become a useful tool for both basic research and drug development in the areas related to GPCRs.	[Xiao, Xuan; Wang, Pu] Jing De Zhen Ceram Inst, Dept Comp, Jing De Zhen 333403, Peoples R China; [Xiao, Xuan; Chou, Kuo-Chen] Gordon Life Sci Inst, San Diego, CA 92130 USA	Xiao, XA (reprint author), Jing De Zhen Ceram Inst, Dept Comp, Jing De Zhen 333403, Peoples R China.	xxiao@gordonlifescience.org; kcchou@gordonlifescience.org	Chou, Kuo-Chen/A-8340-2009		National Natural Science Foundation of China [60961003]; Chinese Ministry of Education [210116]; Province National Natural Science Foundation of Jiangxi [2009GZS0064]; Department of Education of JiangXi Province [GJJ09271]; plan for training youth scientists (stars of Jing-Gang) of province Jiangxi	The authors wish to expresses their gratitude to the three anonymous reviewers, whose constructive comments were very helpful for improving the presentation of the paper. The work in this research was supported by the grants from the National Natural Science Foundation of China (no. 60961003), the Key Project of Chinese Ministry of Education (no. 210116), the Province National Natural Science Foundation of Jiangxi(no. 2009GZS0064), the Department of Education of JiangXi Province (No. GJJ09271), and the plan for training youth scientists (stars of Jing-Gang) of province Jiangxi.	Altschul SE, 1997, THEORETICAL AND COMPUTATIONAL METHODS IN GENOME RESEARCH, P1; BALDWIN JM, 1994, CURR OPIN CELL BIOL, V6, P180, DOI 10.1016/0955-0674(94)90134-1; Cai YD, 2003, BIOPHYS J, V84, P3257; Call ME, 2006, CELL, V127, P355, DOI 10.1016/j.cell.2006.08.044; Call ME, 2010, NAT IMMUNOL, V11, P1023, DOI 10.1038/ni.1943; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; Chen C, 2009, PROTEIN PEPTIDE LETT, V16, P27; Chen L, 2010, MOLECULES, V15, P8177, DOI 10.3390/molecules15118177; Chou K. C., 2009, NAT SCI, V2, P63, DOI DOI 10.4236/NS.2009.12011; Chou KC, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0009931; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2003, BIOCHEM BIOPH RES CO, V308, P148, DOI 10.1016/S0006-291X(03)01342-1; Chou KC, 2008, BIOCHEM BIOPH RES CO, V376, P321, DOI 10.1016/j.bbrc.2008.08.125; Chou KC, 2004, BIOCHEM BIOPH RES CO, V316, P636, DOI 10.1016/j.bbrc.2004.02.098; CHOU KC, 1989, TRENDS BIOCHEM SCI, V14, P212, DOI 10.1016/0968-0004(89)90026-1; Chou KC, 2007, ANAL BIOCHEM, V370, P1, DOI 10.1016/j.ab.2007.07.006; Chou KC, 2001, PROTEINS, V44, P60, DOI 10.1002/prot.1072.abs; Chou KC, 2008, NAT PROTOC, V3, P153, DOI 10.1038/nprot.2007.494; Chou KC, 1999, PROTEINS, V34, P137, DOI 10.1002/(SICI)1097-0134(19990101)34:1<137::AID-PROT11>3.0.CO;2-O; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; Chou KC, 2000, FEBS LETT, V470, P249, DOI 10.1016/S0014-5793(00)01333-8; Chou KC, 2004, BIOCHEM BIOPH RES CO, V319, P433, DOI 10.1016/j.bbrc.2004.05.016; CHOU KC, 1977, SCI SINICA, V20, P447; Chou KC, 2004, CURR MED CHEM, V11; Chou KC, 2000, BIOCHEM BIOPH RES CO, V278, P477, DOI 10.1006/bbrc.2000.3815; Chou KC, 2002, J PROTEOME RES, V1, P429, DOI 10.1021/pr025527k; CHOU KC, 1994, J BIOL CHEM, V269, P22014; Chou K.-C., 2010, NAT SCI, V2, P1090, DOI DOI 10.4236/NS.2010.210136; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2005, J PROTEOME RES, V4, P1413, DOI 10.1021/pr050087t; Chou KC, 2007, BIOCHEM BIOPH RES CO, V360, P339, DOI 10.1016/j.bbrc.2007.06.027; Chou KC, 2009, CURR PROTEOMICS, V6, P262; CHOU KC, 1995, FEBS LETT, V363, P123, DOI 10.1016/0014-5793(95)00240-A; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou KC, 2004, J PROTEOME RES, V3, P1284, DOI 10.1021/pr049849v; CHOU KC, 1988, BIOPHYS CHEM, V30, P3, DOI 10.1016/0301-4622(88)85002-6; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ding H, 2009, PROTEIN PEPTIDE LETT, V16, P351; Ding YS, 2008, PATTERN RECOGN LETT, V29, P1887, DOI 10.1016/j.patrec.2008.06.007; Ding YS, 2007, PROTEIN PEPTIDE LETT, V14, P811; Douglas SM, 2007, P NATL ACAD SCI USA, V104, P6644, DOI 10.1073/pnas.0700930104; Du QS, 2006, J BIOMOL STRUCT DYN, V23, P635; Elrod DW, 2002, PROTEIN ENG, V15, P713, DOI 10.1093/protein/15.9.713; Esmaeili M, 2010, J THEOR BIOL, V263, P203, DOI 10.1016/j.jtbi.2009.11.016; Fang Y, 2008, AMINO ACIDS, V34, P103, DOI 10.1007/s00726-007-0568-2; Feng KY, 2005, BIOCHEM BIOPH RES CO, V334, P213, DOI 10.1016/j.bbrc.2005.06.075; Finn RD, 2006, NUCLEIC ACIDS RES, V34, pD247, DOI 10.1093/nar/gkj149; Gao QB, 2006, PROTEIN ENG DES SEL, V19, P511, DOI 10.1093/protein/gzl038; Georgiou DN, 2009, J THEOR BIOL, V257, P17, DOI 10.1016/j.jtbi.2008.11.003; Gonzalez-Diaz H, 2008, PROTEOMICS, V8, P750, DOI 10.1002/pmic.200700638; Gu Q, 2010, PROTEIN PEPTIDE LETT, V17, P559; GUDERMANN T, 1995, J MOL MED-JMM, V73, P51, DOI 10.1007/BF00270578; He ZS, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0009603; HOPP TP, 1981, P NATL ACAD SCI-BIOL, V78, P3824, DOI 10.1073/pnas.78.6.3824; Horn F, 1998, NUCLEIC ACIDS RES, V26, P275, DOI 10.1093/nar/26.1.275; Jahandideh S, 2007, BIOPHYS CHEM, V128, P87, DOI 10.1016/j.bpc.2007.03.006; Jiang XY, 2008, PROTEIN PEPTIDE LETT, V15, P392, DOI 10.2174/092986608784246443; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KLEIN P, 1986, BIOCHIM BIOPHYS ACTA, V874, P205, DOI 10.1016/0167-4838(86)90119-6; KLEIN P, 1986, BIOPOLYMERS, V25, P1659, DOI 10.1002/bip.360250909; Lefkowitz RJ, 2000, NAT CELL BIOL, V2, pE133, DOI 10.1038/35017152; Letunic I, 2006, NUCLEIC ACIDS RES, V34, pD257, DOI 10.1093/nar/gkj079; Li FM, 2008, PROTEIN PEPTIDE LETT, V15, P612, DOI 10.2174/092986608784966930; Li WZ, 2006, BIOINFORMATICS, V22, P1658, DOI 10.1093/bioinformatics/btl158; Lin H, 2008, PROTEIN PEPTIDE LETT, V15, P739, DOI 10.2174/092986608785133681; Lin H, 2009, ACTA BIOTHEOR, V57, P321, DOI 10.1007/s10441-008-9067-4; Lin H, 2008, J THEOR BIOL, V252, P350, DOI 10.1016/j.jtbi.2008.02.004; Liu H, 2005, BIOCHEM BIOPH RES CO, V336, P737, DOI 10.1016/j.bbrc.2005.08.160; Liu WM, 1998, J PROTEIN CHEM, V17, P209, DOI 10.1023/A:1022576400291; Marchler-Bauer A, 2007, NUCLEIC ACIDS RES, V35, pD237, DOI 10.1093/nar/gkl951; METFESSEL BA, 1993, PROTEIN SCI, V2, P1171; Murvai J, 2001, NUCLEIC ACIDS RES, V29, P58, DOI 10.1093/nar/29.1.58; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Niu B, 2006, PROTEIN PEPTIDE LETT, V13, P489, DOI 10.2174/092986606776819619; Oppenheim A. V., 1985, SIGNALS SYSTEMS; Oxenoid K, 2005, P NATL ACAD SCI USA, V102, P10870, DOI 10.1073/pnas.0504920102; Pielak RM, 2009, P NATL ACAD SCI USA, V106, P7379, DOI 10.1073/pnas.0902548106; Pielak RM, 2010, BIOCHEM BIOPH RES CO, V401, P58, DOI 10.1016/j.bbrc.2010.09.008; PIELAK RM, 2010, BIOCHIM BIOPHYS ACTA, DOI DOI 10.1016/J.BBAMEM.2010.1004.1015; Qiu JD, 2009, ANAL BIOCHEM, V390, P68, DOI 10.1016/j.ab.2009.04.009; Roth BL, 1998, DRUG ALCOHOL DEPEN, V51, P73, DOI 10.1016/S0376-8716(98)00067-2; Schnell JR, 2008, NATURE, V451, P591, DOI 10.1038/nature06531; Shen HB, 2006, J THEOR BIOL, V240, P9, DOI 10.1016/j.jtbi.2005.08.016; TATUSOV RL, 2003, BMC BIOINFORMATICS, V4, pNIL1, DOI DOI 10.1186/1471-2105-4-41; Wang JF, 2009, NAT STRUCT MOL BIOL, V16, P1267, DOI 10.1038/nsmb.1707; Wang JF, 2010, CURR DRUG METAB, V11, P342; Wang SQ, 2007, BIOCHEM BIOPH RES CO, V354, P634, DOI 10.1016/j.bbrc.2006.12.235; Wang SQ, 2010, BIOCHEM BIOPH RES CO, V401, P188, DOI 10.1016/j.bbrc.2010.09.020; Wei DQ, 2006, BIOCHEM BIOPH RES CO, V344, P1048, DOI 10.1016/j.bbrc.2006.03.210; Wen Z, 2007, AMINO ACIDS, V32, P277, DOI 10.1007/s00726-006-0341-y; WOOTTON JC, 1993, COMPUT CHEM, V17, P149, DOI 10.1016/0097-8485(93)85006-X; Xiao X, 2006, J COMPUT CHEM, V27, P478, DOI 10.1002/jcc.20354; Xiao X, 2009, J COMPUT CHEM, V30, P1414, DOI 10.1002/jcc.21163; Xiao X, 2010, INTERDISCIP SCI, V2, P180, DOI 10.1007/s12539-010-0080-3; Xiao X, 2009, J APPL CRYSTALLOGR, V42, P169, DOI 10.1107/S0021889809002751; Xiao X, 2006, AMINO ACIDS, V30, P49, DOI 10.1007/s00726-005-0225-6; Xiao X, 2008, J THEOR BIOL, V254, P691, DOI 10.1016/j.jtbi.2008.06.016; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Zeng YH, 2009, J THEOR BIOL, V259, P366, DOI 10.1016/j.jtbi.2009.03.028; ZHANG CT, 1995, PROTEIN ENG, V8, P425, DOI 10.1093/protein/8.5.425; Zhang GY, 2008, J THEOR BIOL, V253, P310, DOI 10.1016/j.jtbi.2008.03.015; Zhang GY, 2008, PROTEIN PEPTIDE LETT, V15, P1132, DOI 10.2174/092986608786071184; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou XB, 2007, J THEOR BIOL, V248, P546, DOI 10.1016/j.jtbi.2007.06.001	107	73	73	ROYAL SOC CHEMISTRY	CAMBRIDGE	THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND	1742-206X		MOL BIOSYST	Mol. Biosyst.		2011	7	3					911	919		10.1039/c0mb00170h		9	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	721PM	WOS:000287367100036	
S	Viswanath, P; Chennakesalu, S; Rajkumar, R; Sekhar, NR		Sombattheera, C; Agarwal, A; Udgata, SK; Lavangnananda, K		Viswanath, Pulabaigari; Chennakesalu, S.; Rajkumar, R.; Sekhar, Ni. Raja			Pattern Synthesis Using Fuzzy Partitions of the Feature Set for Nearest Neighbor Classifier Design	MULTI-DISCIPLINARY TRENDS IN ARTIFICIAL INTELLIGENCE	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	5th Multi-Disciplinary International Workshop on Artificial Intelligence, MIWAI-2011	DEC 07-09, 2011	Hyderabad, INDIA	IBM India, Locuz Enterprise Solut Ltd, IDRBT, Winzest	Univ Hyderabad	Pattern synthesis; fuzzy partition; nearest neighbor classifier; partition around medoids		Nearest neighbor classifiers require a larger training set in order to achieve a better classification accuracy. For a higher dimensional data, if the training set size is small, it suffers from the curse of dimensionality effect and performance gets degraded. Partition based pattern synthesis is an existing technique of generating a larger set of artificial training patterns based on a chosen partition of the feature set. If the blocks of the partition are statistically independent then the quality of synthetic patterns generated is high. But, such a partition, often does not exist for real world problems. So, approximate ways of generating a partition based on correlation coefficient values between pairs of features were used earlier in some studies. That is, an approximate hard partition, where each feature belongs to exactly one cluster (block) of the partition was used for doing the synthesis. The current paper proposes an improvement over this. Instead of having a hard approximate partition, a soft approximate partition based on fuzzy set theory could be beneficial. The present paper proposes such a fuzzy partitioning method of the feature set called fuzzy partition around medoids (fuzzy-PAM). Experimentally, using some standard data-sets, it is demonstrated that the fuzzy partition based synthetic patters are better as for as the classification accuracy is concerned.	[Viswanath, Pulabaigari; Chennakesalu, S.; Rajkumar, R.; Sekhar, Ni. Raja] Rajeev Gandhi Mem Coll Engn & Technol, Dept Comp Sci & Engn, Nandyal 518501, AP, India	Viswanath, P (reprint author), Rajeev Gandhi Mem Coll Engn & Technol, Dept Comp Sci & Engn, Nandyal 518501, AP, India.	viswanath.pulabaigari@gmail.com; schennakesavcse@gmail.com; m.rajasekhar.cse@gmail.com; rajsri1229@yahoo.co.in					Ananthanarayana VS, 2001, PATTERN RECOGN, V34, P2249, DOI 10.1016/S0031-3203(01)00028-0; Babu T. R., 2001, PATTERN RECOGN, V34, P523, DOI 10.1016/S0031-3203(00)00094-7; Bellman R., 1961, ADAPTIVE CONTROL PRO; Bishop C. M., 1995, NEURAL NETWORKS PATT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Duda R.O., 2000, PATTERN CLASSIFICATI; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814; Han J., 2001, DATA MINING CONCEPTS; Murphy P.M, 2000, UCI REPOSITORY MACHI; Viswanath P., 2004, INFORM FUSION, V5, P239, DOI 10.1016/j.inffus.2004.02.003; Viswanath P, 2005, PATTERN RECOGN, V38, P1187, DOI 10.1016/j.patcog.2004.10.007; Viswanath P, 2005, LECT NOTES COMPUT SC, V3776, P799; Viswanath P, 2004, INT C PATT RECOG, P416; Viswanath P, 2006, PATTERN RECOGN LETT, V27, P1714, DOI 10.1016/j.patrec.2006.04.015	15	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-25724-7	LECT NOTES ARTIF INT			2011	7080						124	135				12	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BBT71	WOS:000308110800011	
B	Labiak, J; Livescu, K			Int  Speech Commun Assoc	Labiak, John; Livescu, Karen			Nearest Neighbors with Learned Distances for Phonetic Frame Classification	12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5			English	Proceedings Paper	12th Annual Conference of the International-Speech-Communication-Association 2011 (INTERSPEECH 2011)	AUG 27-31, 2011	Florence, ITALY	Int Speech Commun Assoc		Phonetic classification; nearest neighbors; distance learning; multilayer perceptrons		Nearest neighbor-based techniques provide an approach to acoustic modeling that avoids the often lengthy and heuristic process of training traditional Gaussian mixture-based models. Here we study the problem of choosing the distance metric for a k-nearest neighbor (k-NN) phonetic frame classifier. We compare the standard Euclidean distance to two learned Mahalanobis distances, based on large-margin nearest neighbors (LMNN) and locality preserving projections (LPP). We use locality sensitive hashing for approximate nearest neighbor search to reduce the test time of k-NN classification. We compare the error rates of these approaches, as well as of baseline Gaussian mixture-based and multilayer perceptron classifiers, on the task of phonetic frame classification of speech from the TIMIT database. The k-NN classifiers outperform Gaussian mixture models, but not multilayer perceptrons. We find that the best k-NN classification performance is obtained using LPP, while LMNN is close behind.	[Labiak, John] Univ Chicago, Dept Stat, Chicago, IL 60637 USA	Labiak, J (reprint author), Univ Chicago, Dept Stat, Chicago, IL 60637 USA.	labiak@galton.uchicago.edu; klivescu@ttic.edu					Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494; Arya S., 1994, S DISCR ALG; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deselaers T., 2007, ICSLP; Golipour L., 2010, INTERSPEECH; He X., 2003, NIPS; Johnson D., 2007, ICSI QUICKNET SOFTWA; Lamel L., 1989, SPEECH INPUT OUTPUT; Shakhnarovich G., 2005, THESIS MIT; Singh-Miller N., 2009, NIPS; Tang Y., 2008, ICASSP; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207	12	0	0	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE		978-1-61839-270-1				2011							2348	2351				4	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic	Computer Science; Engineering	BEG84	WOS:000316502201076	
B	Attabi, Y; Dumouchel, P			Int  Speech Commun Assoc	Attabi, Yazid; Dumouchel, Pierre			Weighted Ordered Classes - Nearest Neighbors: A New Framework for Automatic Emotion Recognition From Speech	12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5			English	Proceedings Paper	12th Annual Conference of the International-Speech-Communication-Association 2011 (INTERSPEECH 2011)	AUG 27-31, 2011	Florence, ITALY	Int Speech Commun Assoc		similarity-based classification; GMM; neighborhood pattern; feature selection; logistic regression		In this paper we present a new framework for emotion recognition from speech based on a similarity concept called Weighted Ordered Classes-Nearest Neighbors (WOC-NN). Unlike the k-nearest neighbor, an instance-similarity based method; WOC-NN computes similarities between a test instance and a class pattern of each emotion class. An emotion class pattern is a representation of its ranked neighboring classes. A Hamming distance is used as distance metric, enhanced with two improvements: i) weighting the importance of each class rank of each neighborhood pattern and ii) discarding irrelevant class ranks from the patterns. Thus, the decision process in WOC-NN exploits more information than Bayes rule which makes use only of the information about the model class that minimizes Bayes risk. This extra information allows WOC-NN to get more accurate prediction. Also, the results show that the proposed system outperforms the result of state-of-the art systems when applied to the FAU AIBO corpus.	[Attabi, Yazid; Dumouchel, Pierre] Ecole Technol Super, Montreal, PQ, Canada	Attabi, Y (reprint author), Ecole Technol Super, Montreal, PQ, Canada.	yazid.attabi@crim.ca; pierre.dumouchel@crim.ca					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Grimm M., 2008, P IEEE INT C MULT EX; Hall M., 2009, SIGKDD EXPLORATIONS, V11, P1; Kockmann M., 2009, INTERSPEECH; Lee C.-C., 2009, INTERSPEECH; Rubin D, 1997, J ROYAL STAT SOC B, V39, P1; Schuller B., 2009, INTERSPEECH; Schuller B., 2007, P INT, P2253; Young S., 1993, HTK HIDDEN MARKOV MO	9	0	0	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE		978-1-61839-270-1				2011							3132	3135				4	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic	Computer Science; Engineering	BEG84	WOS:000316502201272	
S	Ramachandran, L; Gehringer, EF			IEEE	Ramachandran, Lakshmi; Gehringer, Edward F.			Determining Degree of Relevance of Reviews Using a Graph-Based Text Representation	2011 23RD IEEE INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE (ICTAI 2011)	Proceedings-International Conference on Tools With Artificial Intelligence		English	Proceedings Paper	23rd IEEE International Conference on Tools with Artificial Intelligence (ICTAI)	NOV 07-09, 2011	Boca Raton, FL	IEEE, IEEE Comp Soc, IEEE Comp Soc Tech Comm Multimedia Comp (TCMC), Bio & Artificial Intelligence Soc (BAIS), Florida Atlant Univ (FAU), Univ Technol, Ctr Quantum Comp & Intelligent Syst (UTS-QCIS), Tsinghua Univ, Arnetminer		relevance; graph-based representation; plagiarism; paraphrasing; k-nearest neighbor		Reviews are text-based feedback provided by reviewers to authors. The quality of a review can be determined by identifying how relevant it is to the work that the review was written for as well as its similarity to existing well-written and coherent reviews. Relevance between two pieces of text can be determined by identifying semantic and syntactic similarities between them. In this paper, we make use of string-based metrics that incorporate concepts of paraphrasing and plagiarism to determine matching between texts. We use a graph-based text representation technique. We use the k-nearest neighbor classification algorithm to build a supervised model and classify text as LOW, MEDIUM or HIGH based on values of the metrics. We evaluate our approach on three data sets from student assignments and show that our model achieves an average accuracy of 63%.	[Ramachandran, Lakshmi; Gehringer, Edward F.] NC State Univ, Dept Comp Sci, Raleigh, NC 27607 USA	Ramachandran, L (reprint author), NC State Univ, Dept Comp Sci, Raleigh, NC 27607 USA.	lramach@ncsu.edu; efg@ncsu.edu					Bengoetxea E., 2002, THESIS U BASQUE COUN; Boonthum C., 2004, ACLSTUDENT 04; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Gehringer E. F., 2007, INNOVATE J ONLINE ED; Qiu L, 2006, EMNLP 06, P18	5	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1082-3409	978-0-7695-4596-7	PROC INT C TOOLS ART			2011							442	445		10.1109/ICTAI.2011.72		4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BYJ28	WOS:000299009900064	
S	Gottemukkula, V; Derakhshani, R			IEEE	Gottemukkula, Vikas; Derakhshani, Reza			Classification-guided Feature Selection for NIRS-based BCI	2011 5TH INTERNATIONAL IEEE/EMBS CONFERENCE ON NEURAL ENGINEERING (NER)	International IEEE EMBS Conference on Neural Engineering		English	Proceedings Paper	5th International IEEE Engineering-in-Medicine-and-Biology-Society (EMBS) Conference on Neural Engineering (NER)	APR 27-MAY 01, 2011	Cancun, MEXICO	Natl Sci Fdn (NSF), Engn Med & Biol Soc (EMBS), IEEE			BRAIN-COMPUTER INTERFACE; SYSTEMS; ADULT	Motor movements induce distinct patterns in the hemodynamics of the motor cortex, which may be captured by Near-Infrared Spectroscopy (NIRS) for Brain Computer Interfaces (BCI). We present a classification-guided (wrapper) method for time-domain NIRS feature extraction to classify left and right hand movements. Four different wrapper methods, based on univariate and multivariate ranking and sequential forward and backward selection, along with three different classifiers (k-Nearest neighbor, Bayes, and Support Vector Machines) were studied. Using NIRS data from two subjects we show that a rank-based wrapper in conjunction with polynomial SVMs can achieve 100% sensitivity and specificity separating left and right hand movements (5-fold cross validation). Results show the promise of wrapper methods in classifying NIRS signals for BCI applications.	[Gottemukkula, Vikas; Derakhshani, Reza] Univ Missouri, Kansas City, MO 64112 USA	Gottemukkula, V (reprint author), Univ Missouri, Kansas City, MO 64112 USA.	vgq57@mail.umkc.edu; reza@umkc.edu					Allison BZ, 2007, EXPERT REV MED DEVIC, V4, P463, DOI 10.1586/17434440.4.4.463; Barbour RL, 2009, LECT NOTES ARTIF INT, V5638, P709, DOI 10.1007/978-3-642-02812-0_80; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Coyle S, 2004, PHYSIOL MEAS, V25, P815, DOI 10.1088/0967-3334/25/4/003; Coyle SM, 2007, J NEURAL ENG, V4, P219, DOI 10.1088/1741-2560/4/3/007; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Fukui Y, 2003, APPL OPTICS, V42, P2881, DOI 10.1364/AO.42.002881; Huppert TJ, 2006, NEUROIMAGE, V29, P368, DOI 10.1016/j.neuroimage.2005.08.065; Niide W., 2009, IEEE P INT JOINT C N, P2264; Nozawa T, 2009, LECT NOTES COMPUT SC, V5618, P413, DOI 10.1007/978-3-642-02559-4_45; Rowan A. J., 2003, PRIMER EEG; Schmitz C. H., 2009 BERL BRAIN COMP; Sitaram R, 2007, NEUROIMAGE, V34, P1416, DOI 10.1016/j.neuroimage.2006.11.005; Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P1; Waske B., P IGARSS 2006 DENV C, P168	15	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1948-3546	978-1-4244-4141-9	I IEEE EMBS C NEUR E			2011							72	75				4	Engineering, Biomedical; Neurosciences	Engineering; Neurosciences & Neurology	BYH13	WOS:000298735800017	
B	Chalmers, N; Glasgow, J; Scott, S			IEEE	Chalmers, Nathan; Glasgow, Janice; Scott, Stephen			Dynamic Time Warping as a Spatial Assessment of Sensorimotor Impairment resulting from Stroke	2011 ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY (EMBC)			English	Proceedings Paper	33rd Annual International Conference of the IEEE Engineering-in-Medicine-and-Biology-Society (EMBS)	AUG 30-SEP 03, 2011	Boston, MA	IEEE, Engn Med & Biol Soc (EMBS)			CLASSIFICATION	Robotic assessment of sensorimotor impairment began in the mid 1990s as a means to address some of the issues regarding inter-rater reliability and the lack of precision associated with traditional measures of sensorimotor impairment. Robotic measures of postural control, reaction time, movement smoothness, and movement error associated with robotic assessment of the upper-limb fail to recognize the inherent spatial and geometric differences between stroke and control hand path trajectories. In this study we propose the application of a class of algorithms, Dynamic Time Warping, designed to quantify the spatial difference and skew between hand written characters and vocal waveforms as a means for identifying individuals exhibiting sensorimotor impairment. In order to achieve this 85 stroke subjects, and 54 age, gender, and handedness matched control subjects, underwent robotic assessment of the upper-limb. Subjects were identified as either stroke or control using a K Nearest Neighbour classifier with a Dynamic Time Warping distance metric. Classification accuracy, sensitivity, and specificity in excess of %80 percent was achieved.								ADAMS HP, 1993, STROKE, V24, P35; Coderre AM, 2010, NEUROREHAB NEURAL RE, V24, P528, DOI 10.1177/1545968309356091; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DONAHUE RP, 1986, JAMA-J AM MED ASSOC, V255, P2311, DOI 10.1001/jama.255.17.2311; Gladstone DJ, 2002, NEUROREHAB NEURAL RE, V16, P232, DOI 10.1177/154596802401105171; GOWLAND C, 1993, STROKE, V24, P58; Lum P. S., 2003, TOP STROKE REHABIL, V8, P40; Ottenbacher KJ, 1996, ARCH PHYS MED REHAB, V77, P1226, DOI 10.1016/S0003-9993(96)90184-7; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; Scott SH, 1999, J NEUROSCI METH, V89, P119, DOI 10.1016/S0165-0270(99)00053-9; Somervuo P, 1999, NEURAL PROCESS LETT, V10, P151, DOI 10.1023/A:1018741720065; Sung P., 2009, P 2009 IEEE INT C AC, P477	12	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-4122-8				2011							8235	8238				4	Engineering, Biomedical; Engineering, Electrical & Electronic	Engineering	BYH52	WOS:000298810006088	
S	Mikawa, K; Ishida, T; Goto, M			IEEE	Mikawa, Kenta; Ishida, Takashi; Goto, Masayuki			A Proposal of Extended Cosine Measure for Distance Metric Learning in Text Classification	2011 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS (SMC)	IEEE International Conference on Systems Man and Cybernetics Conference Proceedings		English	Proceedings Paper	IEEE International Conference on Systems, Man and Cybernetics (SMC)	OCT 09-12, 2011	Anchorage, AK	IEEE, IEEE Syst, Man & Cybernet Soc, IEEE Circuits & Syst Soc (CAS), IEEE Engn, Med & Biol Soc (EMB)		metric learning; extended cosine measure; vector space model; similality measure; text mining		This paper discusses a new similarity measure between documents on a vector space model from the view point of distance metric learning. The documents are represented by points in the vector space by using the information of frequencies of words appearing in each document. The similarity measure between two different documents is useful to recognize the relationship and can be applied to classification or clustering of the data. Usually, the cosine similarity and the Euclid distance have been used in order to measure the similarity between points in the Euclidean space. However, these measures do not take the correlation among words which appear in documents into consideration on an application of the vector space model to document analysis. Generally speaking, many words which appear in documents have correlation to one another depending on the sentence structures, topics and subjects. Therefore, it is effective to build a suitable metric measure taking the correlation of words into consideration on the vector space in order to improve the performance of document classification and clustering. This paper presents a new effective method to acquire a distance measure on the document vector space based on an extended cosine measure. In addition, the way of distance metric learning is proposed to acquire the proper metric from the view point of supervised learning. The effectiveness of our proposal is clarified by simulation experiments for the text classification problems of the customer review which is posted on the web site and the newspaper article.	[Mikawa, Kenta; Goto, Masayuki] Waseda Univ, Dep Creat Sci & Engn, Tokyo, Japan	Mikawa, K (reprint author), Waseda Univ, Dep Creat Sci & Engn, Tokyo, Japan.	mikawa@it.mgmt.waseda.jp; ishida@it.mgmt.waseda.jp					Bishop C. M., 2006, PATTERN RECOGNITION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davis J. V., 2007, P 24 INT C MACH LEAR, P209, DOI DOI 10.1145/1273496.127352; Goto M., 2008, INT S INF THEOR ITS; Goto M., 2007, IEEE INT C COMP INF, P674; Hearst M. A., 1999, ACL 99 P, P3; Hofmann T., 1999, Proceedings of SIGIR '99. 22nd International Conference on Research and Development in Information Retrieval, DOI 10.1145/312624.312649; Lim Junae, 2009, P AS C COMP VIS, P299; Manning C., 2008, INTRO INFORM RETRIEV; Mpchihashi Daichi, 2006, SYSTEMS COMPUTERS JA, V37, P12; Nagata Masaaki, 1994, P 15 INT C COMP LING, P201; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Shen CH, 2010, IEEE T NEURAL NETWOR, V21, P1524, DOI 10.1109/TNN.2010.2052630; Xing Eric P., 2007, P COMP VIS PATT REC; YANG L., 2007, P COMP VIS PATT REC; Yang L, 2006, DISTANCE METRIC LEAR; Yang L., 2007, P 23 C UNC ART INT	17	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X	978-1-4577-0653-0	IEEE SYS MAN CYBERN			2011							1741	1746				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Information Systems	Computer Science	BYG71	WOS:000298615102005	
B	Hernandez, O; Ramirez, C; Villeda, J			IEEE	Hernandez, Oscar; Ramirez, Carlos; Villeda, Julio			A TOLERANT ALGORITHM FOR CARDIAC PULSES CHARACTERIZATION IN BALLISTOCARDIOGRAPHY SIGNALS IN A NON-INVASIVE SYSTEM	2011 IEEE STATISTICAL SIGNAL PROCESSING WORKSHOP (SSP)			English	Proceedings Paper	IEEE Statistical Signal Processing Workshop (SSP)	JUN 28-30, 2011	Nice, FRANCE	IEEE		BCG signals; heartbeat; heart rate; cardiac pulse detection; signal processing; non-invasive systems; EMFi sensors		A variety of signal processing methods have been developed for detecting the heartbeat from signals obtained by non-invasive devices. In this paper, an algorithm developed for the accurate detection of heartbeats from a ballistocardiography signal is presented. The signal is obtained using a regular chair adapted with Electro-Mechanical Film (EMFi) sensors and an acquisition system, so a ballistocardiogram is generated. The presence of important disturbances in this type of signal is unavoidable due to several natural causes; therefore, its processing involves significant difficulties to be tackled in order to obtain reliable lectures of the heartbeat. The algorithm presented here performs consistently well, showing a very low error rate, even if the signal contains significant noise.	[Hernandez, Oscar; Ramirez, Carlos; Villeda, Julio] Tecnol Monterrey, Monterrey, Mexico	Hernandez, O (reprint author), Tecnol Monterrey, Monterrey, Mexico.	ohernand@itesm.mx; cramireg@itesm.mx; a01203113@itesm.mx					Akhbardeh Alireza, 2005, P 2005 IEEE INT S IN; Baron CAlberto, 2009, REV COLOMBIANA CARDI, V16; Bidargaddi Niranjan, 2008, VANC CAN 30 ANN INT; Brink Mark, 2006, BEHAV RES METHODS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Eduardo Pinheiro, BLOOD PRESSURE HEART; Junila Sakari, 2005, TAMP FINL IEEE SIPS; Lekkala Jukka, 2006, RIO DE JAN BRAZ 18 W; Mandeville Peter B, 2009, TIPS BIOESTADISTICOS, VXII, P220; Paajanen M, 2001, IEEE T DIELECTRICS E, V8; Paalasmaa Joonas, 2008, DETECTING HEARTBEATS; Ramirez, 2010, QUER ASEE IEEE FRONT; Richard M.Wiard, 2009, 31 ANN INT C IEEE EM; Schutz A., 2007, ED PSYCHOL SERIES; Shin J. H., 2008, VANC CAN 30 ANN INT; Wang Xu, 2009, 2 INT WORKSH KNOWL D; Yu Xinsheng, 1996, IEEE TENCON DIGITAL	17	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4577-0570-0				2011							465	468				4	Engineering, Electrical & Electronic	Engineering	BYF18	WOS:000298377500117	
B	Luque, RM; Elizondo, D; Lopez-Rubio, E; Palomo, EJ			IEEE	Luque, R. M.; Elizondo, D.; Lopez-Rubio, E.; Palomo, E. J.			GA-based Feature Selection Approach in Biometric Hand Systems	2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)			English	Proceedings Paper	International Joint Conference on Neural Networks (IJCNN)	JUL 31-AUG 05, 2011	San Jose, CA	Int Neural Network Soc (INNS), IEEE Computat Intelligence Soc (CIS), Natl Sci Fdn (NSF), Cognimem Technol, Inc, Univ Cincinnati Coll Engn & Appl Sci, Toyota Res Inst N Amer, Univ Cincinnati, Sch Elect & Compu Syst			MODEL-BASED APPROACH; PALMPRINT; MOMENTS; FACE	In this paper, a novel methodology for using feature selection in hand biometric systems, based on genetic algorithms and mutual information is presented. A hand segmentation algorithm based on adaptive threshold and active contours is also applied, in order to deal with complex backgrounds and non-homogeneous illumination. The aim of this methodology is two-fold. On the one hand, getting robust features in biometric systems with no restriction in the hand-pose and in its orientation with regard to the camera. On the other hand, providing a subset of features which reduce the complexity of the identification process and maximize the generalization rate of the classifiers. By using the IITD Palmprint Database, which is an example of such free hand-pose biometric systems, the experimental results show that it is not always necessary to apply sophisticated classification methods to obtain good accuracy results. Simple classifiers such as kNN and LDA together with this feature selection approach, get even better generalisation rates than other more elaborate and complex methods.	[Luque, R. M.; Lopez-Rubio, E.; Palomo, E. J.] Univ Malaga, Dept Comp Languages & Comp Sci, ETSI Informat, E-29071 Malaga, Spain	Luque, RM (reprint author), Univ Malaga, Dept Comp Languages & Comp Sci, ETSI Informat, E-29071 Malaga, Spain.	rmluque@lcc.uma.es; elizondo@dmu.ac.uk; ezeqlr@lcc.uma.es; ejpalomo@lcc.uma.es					Amayeh G, 2009, COMPUT VIS IMAGE UND, V113, P477, DOI 10.1016/j.cviu.2008.11.007; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 2001, PATTERN CLASSIFICATI; Duta N, 2009, PATTERN RECOGN, V42, P2797, DOI 10.1016/j.patcog.2009.02.007; Dutagaci H., 2008, J ELECTRON IMAGING, V17, P11; Faundez-Zanuy M, 2007, NEURAL PROCESS LETT, V26, P201, DOI 10.1007/s11063-007-9052-y; Fong L. L., 2009, INT C SOFT COMP PATT, P364; Guo BF, 2009, IEEE T SYST MAN CY A, V39, P36, DOI 10.1109/TSMCA.2008.2007977; Guyon A., 2003, J MACH LEARN RES, V3, P1157; Kumar A, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P583; Kumar A, 2003, LECT NOTES COMPUT SC, V2688, P668; Leung AP, 2005, LECT NOTES COMPUT SC, V3723, P184; Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554; Lopez-Rubio E, 2010, NEURAL NETWORKS, V23, P1208, DOI 10.1016/j.neunet.2010.07.002; McLachlan GJ, 2002, BIOINFORMATICS, V18, P413, DOI 10.1093/bioinformatics/18.3.413; Mohanty P, 2007, IEEE T PATTERN ANAL, V29, P2065, DOI 10.1109/TPAMI.2007.1129; Rani PE, 2010, COMM COM INF SC, V101, P449; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; Sanchez-Reillo R, 2000, IEEE T PATTERN ANAL, V22, P1168, DOI 10.1109/34.879796; Sun ZH, 2004, PATTERN RECOGN, V37, P2165, DOI 10.1016/j.patcog.2004.03.013; Whitaker RT, 1998, INT J COMPUT VISION, V29, P203, DOI 10.1023/A:1008036829907; Yang J, 2007, IEEE T PATTERN ANAL, V29, P650, DOI 10.1109/TPAMI.2007.1008; Yrk E., 2006, IMAGE VISION COMPUT, V24, P483	24	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-9636-5				2011							246	253				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BXX80	WOS:000297541200038	
B	Alippi, C; Boracchi, G; Roveri, M			IEEE	Alippi, Cesare; Boracchi, Giacomo; Roveri, Manuel			An Effective Just-in-Time Adaptive Classifier for Gradual Concept Drifts	2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)			English	Proceedings Paper	International Joint Conference on Neural Networks (IJCNN)	JUL 31-AUG 05, 2011	San Jose, CA	Int Neural Network Soc (INNS), IEEE Computat Intelligence Soc (CIS), Natl Sci Fdn (NSF), Cognimem Technol, Inc, Univ Cincinnati Coll Engn & Appl Sci, Toyota Res Inst N Amer, Univ Cincinnati, Sch Elect & Compu Syst				Classification systems designed to work in nonstationary conditions rely on the ability to track the monitored process by detecting possible changes and adapting their knowledge-base accordingly. Adaptive classifiers present in the literature are effective in handling abrupt concept drifts (i.e., sudden variations), but, unfortunately, they are not able to adapt to gradual concept drifts (i.e., smooth variations) as these are, in the best case, detected as a sequence of abrupt concept drifts. To address this issue we introduce a novel adaptive classifier that is able to track and adapt its knowledge base to gradual concept drifts (modeled as polynomial trends in the expectations of the conditional probability density functions of input samples), while maintaining its effectiveness in dealing with abrupt ones. Experimental results show that the proposed classifier provides high classification accuracy both on synthetically generated datasets and measurements from real sensors.	[Alippi, Cesare; Boracchi, Giacomo; Roveri, Manuel] Politecn Milan, Dipartimento Elettron & Informaz, I-20133 Milan, Italy	Alippi, C (reprint author), Politecn Milan, Dipartimento Elettron & Informaz, I-20133 Milan, Italy.	cesare.alippi@polimi.it; giacomo.boracchi@polimi.it; manuel.roveri@polimi.it					Alippi C, 2008, IEEE T NEURAL NETWOR, V19, P2053, DOI 10.1109/TNN.2008.2003998; Alippi C., 2010, P IJCNN, P1; Alippi C, 2010, LECT NOTES COMPUT SC, V6353, P458; Alippi C, 2009, Proceedings 2009 International Joint Conference on Neural Networks (IJCNN 2009 - Atlanta), DOI 10.1109/IJCNN.2009.5178799; Basseville M., 1993, DETECTION ABRUPT CHA; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Elwell Ryan, 2009, Proceedings 2009 International Joint Conference on Neural Networks (IJCNN 2009 - Atlanta), DOI 10.1109/IJCNN.2009.5178779; Gama J., 2006, LECT NOTES COMPUTER, P42; Goldenshulger A., 1997, MATH METH STAT, V6, P135; Horvath L, 2004, J STAT PLAN INFER, V126, P225, DOI 10.1016/j.jspi.2003.07.014; Katkovnik V, 1999, IEEE T SIGNAL PROCES, V47, P2567, DOI 10.1109/78.782208; Klinkenberg R., 2004, INCREMENTAL LEARNING, V8; KOLTER JZ, 2003, P 3 IEEE INT C DAT M, P123; Kolter JZ, 2007, J MACH LEARN RES, V8, P2755; Lai TL, 2001, STAT SINICA, V11, P303; Nishida Kyosuke, 2009, Proceedings 2009 International Joint Conference on Neural Networks (IJCNN 2009 - Atlanta), DOI 10.1109/IJCNN.2009.5178619; Street W.N., 2001, P 7 ACM SIGKDD INT C, P377, DOI DOI 10.1145/502512.502568; Tartakovsky A. G., 2006, STAT METHODOLOGY, V3, P252, DOI 10.1016/j.stamet.2005.05.003; Tsymbal A., 2004, TCDCS200415 TRIN COL; Wang H., 2003, P 9 ACM SIGKDD INT C, P226, DOI DOI 10.1145/956750.956778; Wang P, 2007, IEEE T KNOWL DATA EN, V19, P1202, DOI 10.1109/TKDE.2007.1057.; Widmer G, 1996, MACH LEARN, V23, P69, DOI 10.1023/A:1018046501280	22	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-9636-5				2011							1675	1682				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BXX80	WOS:000297541201113	
B	Rubio, T; Zhang, TT; Georgiopoulos, M; Kaylani, A			IEEE	Rubio, Talitha; Zhang, Tiantian; Georgiopoulos, Michael; Kaylani, Assem			Multi-Objective Evolutionary Optimization of Exemplar-Based Classifiers: A PNN Test Case	2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)			English	Proceedings Paper	International Joint Conference on Neural Networks (IJCNN)	JUL 31-AUG 05, 2011	San Jose, CA	Int Neural Network Soc (INNS), IEEE Computat Intelligence Soc (CIS), Natl Sci Fdn (NSF), Cognimem Technol, Inc, Univ Cincinnati Coll Engn & Appl Sci, Toyota Res Inst N Amer, Univ Cincinnati, Sch Elect & Compu Syst			NEURAL-NETWORK; PATTERN-CLASSIFICATION; MULTIDIMENSIONAL MAPS; ALGORITHMS; SYSTEMS; ARTMAP	In this paper the major principles to effectively design a parameter-less, multi-objective evolutionary algorithm that optimizes a population of probabilistic neural network (PNN) classifier models are articulated; PNN is an example of an exemplar-based classifier. These design principles are extracted from experiences, discussed in this paper, which guided the creation of the parameter-less multi-objective evolutionary algorithm, named MO-EPNN (multi-objective evolutionary probabilistic neural network). Furthermore, these design principles are also corroborated by similar principles used for an earlier design of a parameter-less, multi-objective genetic algorithm used to optimize a population of ART (adaptive resonance theory) models, named MO-GART (multi-objective genetically optimized ART); the ART classifier model is another example of an exemplar-based classifier model. MO-EPNN's performance is compared to other popular classifier models, such as SVM (Support Vector Machines) and CART (Classification and Regression Trees), as well as to an alternate competitive method to genetically optimize the PNN. These comparisons indicate that MO-EPNN's performance (generalization on unseen data and size) compares favorably to the aforementioned classifier models and to the alternate genetically optimized PNN approach. MO-EPPN's good performance, and MO-GART's earlier reported good performance, both of whose design relies on the same principles, gives credence to these design principles, delineated in this paper.	[Rubio, Talitha; Zhang, Tiantian; Georgiopoulos, Michael] Univ Cent Florida, Dept EECS, Orlando, FL 32816 USA	Rubio, T (reprint author), Univ Cent Florida, Dept EECS, Orlando, FL 32816 USA.	michaelg@ucf.edu					Anagnostopoulos G., 2001, THESIS U CENTRAL FLO; Breiman L, 1984, CLASSIFICATION REGRE; CARPENTER GA, 1992, IEEE T NEURAL NETWOR, V3, P698, DOI 10.1109/72.159059; Coello CAC, 2006, IEEE COMPUT INTELL M, V1, P28, DOI 10.1109/MCI.2006.1597059; Coello CAC, 2000, ACM COMPUT SURV, V32, P109, DOI 10.1145/358923.358929; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Gonzalez J, 2003, IEEE T NEURAL NETWOR, V14, P1478, DOI 10.1109/TNN.2003.820657; ISHIBUCHI H, 1994, FUZZY SET SYST, V65, P237, DOI 10.1016/0165-0114(94)90022-1; Ishibuchi H, 2007, INT J APPROX REASON, V44, P4, DOI 10.1016/j.ijar.2006.01.004; Kaylani A, 2010, IEEE T NEURAL NETWOR, V21, P529, DOI 10.1109/TNN.2009.2037813; Mao KZ, 2000, IEEE T NEURAL NETWOR, V11, P1009, DOI 10.1109/72.857781; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; Newman D. J., 1998, UCI REPOSITORY MACHI; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Vapnik V.N., 1995, NATURE STAT LEARNING; Williamson JR, 1996, NEURAL NETWORKS, V9, P881, DOI 10.1016/0893-6080(95)00115-8; Zitzler E., 2001, SPEA2 IMPROVING STRE; Zitzler E, 2000, EVOL COMPUT, V8, P173, DOI 10.1162/106365600568202	19	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-9636-5				2011							1722	1731				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BXX80	WOS:000297541201119	
B	Malik, UA; Ahmed, SU; Kunwar, F			IEEE	Malik, U. A.; Ahmed, S. U.; Kunwar, F.			A Self-Organizing Neural Scheme for Road Detection in Varied Environments	2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)			English	Proceedings Paper	International Joint Conference on Neural Networks (IJCNN)	JUL 31-AUG 05, 2011	San Jose, CA	Int Neural Network Soc (INNS), IEEE Computat Intelligence Soc (CIS), Natl Sci Fdn (NSF), Cognimem Technol, Inc, Univ Cincinnati Coll Engn & Appl Sci, Toyota Res Inst N Amer, Univ Cincinnati, Sch Elect & Compu Syst		Autonomous vehicle control; road detection; neural networks; unsupervised learning; self-organizing maps; feature based classification	SYSTEM	Detection of a drivable space is a key step in the autonomous control of a vehicle. In this paper we propose an adaptive vision based algorithm for road detection in diverse outdoor conditions. Our novel approach employs feature based classification and uses the Kohonen Self-Organizing Map (SOM) for the purpose of road detection. The robustness of the algorithm lies in the unique ability of SOM to organize information while learning diverse inputs. Features used for the training and testing of SOM are identified. The proposed method is capable of working with structured as well as unstructured roads and noisy environments that may be encountered by an intelligent vehicle. The proposed technique is extensively compared with the k-Nearest Neighbor (KNN) algorithm. Results show that SOM outperforms KNN in classification consistency and is independent to the lighting conditions while taking comparable classification time which shows that the network can also be used as an online learning architecture.	[Malik, U. A.; Ahmed, S. U.; Kunwar, F.] NUST, CEME, Dept Mechatron Engn, Islamabad, Pakistan	Malik, UA (reprint author), NUST, CEME, Dept Mechatron Engn, Islamabad, Pakistan.	usman.malik88@gmail.com; s.usman87@yahoo.com; k.faraz@ceme.nust.edu.pk					Alvarez JM, 2007, LECT NOTES COMPUT SC, V4478, P9; Arnay R, 2008, ELECTRON LETT, V44, P725, DOI 10.1049/el:20080608; Bertozzi M., 2002, ATTI 6 CONV ASS IT I, P627; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRISMAN JD, 1993, IEEE T ROBOTIC AUTOM, V9, P49, DOI 10.1109/70.210794; Foedisch Mike, 2004, 33 APPL IM PATT REC, P16, DOI 10.1109/AIPR.2004.9; Jeon Byoung-Ki, 2000, IEEE INT C IM PROC, V2, P688; Jochem T. M., 1993, IAS 3 INT C INT AUT, P15; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Pomerleau Dean A., 1991, NEURAL COMPUTATION J, V3; Rasheed U., 2010, INT C MECH AUT ICMA, P1609; Tao Xiping, 1997, IEEE INT C INT PROC, V2, P1302; Crisman J. D., 1991, Proceedings. 1991 IEEE International Conference on Robotics and Automation (Cat. No.91CH2969-4), DOI 10.1109/ROBOT.1991.132000; Wu X. W., 2008, INT VEH S, P602; Xu Guobao, 2007, IEEE INT C GREY SYST; Yang XY, 2011, INT GEOL REV, V53, P580, DOI 10.1080/00206810903211906; Zhang J., 1994, P IEEE C INT VEH, P260, DOI DOI 10.1109/IVS.1994.639516; Zheng Tie Liu Nanning, 2003, P INTELLIGENT TRANSP, V2, P1251; Zhou Shengyan, 2010, IEEE INT VEH S SAN D, P256	19	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-9636-5				2011							3049	3054				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BXX80	WOS:000297541203027	
J	Doderer, MS; Yoon, K; Robbins, KA				Doderer, Mark S.; Yoon, Kihoon; Robbins, Kay A.			SIDEKICK: Genomic data driven analysis and decision-making framework	BMC BIOINFORMATICS			English	Article							MOLECULAR INTERACTION DATABASE; PROTEIN INTERACTION DATABASE; INTERACTION NETWORK; INTERACTING PROTEINS; GENE-EXPRESSION; UPDATE; BIOINFORMATICS; DISCOVERY; ONTOLOGY; PATTERN	Background: Scientists striving to unlock mysteries within complex biological systems face myriad barriers in effectively integrating available information to enhance their understanding. While experimental techniques and available data sources are rapidly evolving, useful information is dispersed across a variety of sources, and sources of the same information often do not use the same format or nomenclature. To harness these expanding resources, scientists need tools that bridge nomenclature differences and allow them to integrate, organize, and evaluate the quality of information without extensive computation. Results: Sidekick, a genomic data driven analysis and decision making framework, is a web-based tool that provides a user-friendly intuitive solution to the problem of information inaccessibility. Sidekick enables scientists without training in computation and data management to pursue answers to research questions like "What are the mechanisms for disease X" or "Does the set of genes associated with disease X also influence other diseases." Sidekick enables the process of combining heterogeneous data, finding and maintaining the most up-to-date data, evaluating data sources, quantifying confidence in results based on evidence, and managing the multi-step research tasks needed to answer these questions. We demonstrate Sidekick's effectiveness by showing how to accomplish a complex published analysis in a fraction of the original time with no computational effort using Sidekick. Conclusions: Sidekick is an easy-to-use web-based tool that organizes and facilitates complex genomic research, allowing scientists to explore genomic relationships and formulate hypotheses without computational effort. Possible analysis steps include gene list discovery, gene-pair list discovery, various enrichments for both types of lists, and convenient list manipulation. Further, Sidekick's ability to characterize pairs of genes offers new ways to approach genomic analysis that traditional single gene lists do not, particularly in areas such as interaction discovery.	[Doderer, Mark S.; Robbins, Kay A.] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX 78249 USA; [Doderer, Mark S.] Univ Texas Hlth Sci Ctr San Antonio, Greehey Childrens Canc Res Inst, San Antonio, TX 78229 USA; [Yoon, Kihoon] Univ Texas Hlth Sci Ctr San Antonio, Dept Epidemiol & Biostat, San Antonio, TX 78229 USA	Doderer, MS (reprint author), Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX 78249 USA.	mdoderer@cs.utsa.edu			NIH Research Centers in Minority Institutions [2G12RR1364-06A1]	We acknowledge support from NIH Research Centers in Minority Institutions 2G12RR1364-06A1 (KAR) and computational support from the SA Computational Biology Initiative. Sidekick uses web services and data from a number of sources including NCBI, NCIBI, and EBI.	Alfarano C, 2005, NUCLEIC ACIDS RES, V33, pD418, DOI 10.1093/nar/gki051; Bare JC, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-456; Beuming T, 2005, BIOINFORMATICS, V21, P827, DOI 10.1093/bioinformatics/bti098; Bindea G, 2009, BIOINFORMATICS, V25, P1091, DOI 10.1093/bioinformatics/btp101; Castellano M, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-S6-S23; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEMPSTER AP, 1967, ANN MATH STAT, V38, P325, DOI 10.1214/aoms/1177698950; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DODERER M, 2010, BMC SYST BIOL, V4, P36; Du ZD, 2009, NUCLEIC ACIDS RES, V37, pW345, DOI 10.1093/nar/gkp463; Fraser HB, 2004, P NATL ACAD SCI USA, V101, P9033, DOI 10.1073/pnas.0402591101; GOODMAN J, 2006, CEAS 2006 3 C EM ANT; Goodman SN, 1999, ANN INTERN MED, V130, P995; Grossmann S, 2007, BIOINFORMATICS, V23, P3024, DOI 10.1093/bioinformatics/btm440; Han JDJ, 2004, NATURE, V430, P88, DOI 10.1038/nature02555; Hermjakob H, 2004, NUCLEIC ACIDS RES, V32, pD452, DOI 10.1093/nar/gkh052; Jayapandian M, 2007, NUCLEIC ACIDS RES, V35, pD566, DOI 10.1093/nar/gkl859; Joshi-Tope G, 2005, NUCLEIC ACIDS RES, V33, pD428, DOI 10.1093/nar/gki072; MATHIVANAN S, 2006, BMC BIOINFORM S5, V7, pNI436, DOI DOI 10.1186/1471-2105-7-S5-S19; Matos S, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-212; Pagel P, 2005, BIOINFORMATICS, V21, P832, DOI 10.1093/bioinformatics/bti115; Parkinson H, 2009, NUCLEIC ACIDS RES, V37, pD868, DOI 10.1093/nar/gkn889; Peri S, 2003, GENOME RES, V13, P2363, DOI 10.1101/gr.1680803; Pounds S, 2009, BIOINFORMATICS, V25, P2013, DOI 10.1093/bioinformatics/btp357; Ramos H, 2008, BIOINFORMATICS, V24, P2110, DOI 10.1093/bioinformatics/btn363; Reich M, 2006, NAT GENET, V38, P500, DOI 10.1038/ng0506-500; Rowe A, 2003, BIOINFORMATICS, V19, pi225, DOI 10.1093/bioinformatics/btg1031; Salwinski L, 2004, NUCLEIC ACIDS RES, V32, pD449, DOI 10.1093/nar/gkh086; Shannon PT, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-176; Stark C, 2006, NUCLEIC ACIDS RES, V34, pD535, DOI 10.1093/nar/gkj109; Stelzl U, 2005, CELL, V122, P957, DOI 10.1016/j.cell.2005.08.029; Zanzoni A, 2002, FEBS LETT, V513, P135, DOI 10.1016/S0014-5793(01)03293-8	32	1	1	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	DEC 30	2010	11								611	10.1186/1471-2105-11-611		12	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	706BJ	WOS:000286189400001	
J	Menzies, T; Milton, Z; Turhan, B; Cukic, B; Jiang, Y; Bener, A				Menzies, Tim; Milton, Zach; Turhan, Burak; Cukic, Bojan; Jiang, Yue; Bener, Ayse			Defect prediction from static code features: current results, limitations, new approaches	AUTOMATED SOFTWARE ENGINEERING			English	Article						Defect prediction; Static code features; WHICH	SOFTWARE; INSPECTIONS; CRITIQUE	Building quality software is expensive and software quality assurance (QA) budgets are limited. Data miners can learn defect predictors from static code features which can be used to control QA resources; e.g. to focus on the parts of the code predicted to be more defective. Recent results show that better data mining technology is not leading to better defect predictors. We hypothesize that we have reached the limits of the standard learning goal of maximizing area under the curve (AUC) of the probability of false alarms and probability of detection "AUC(pd, pf)"; i.e. the area under the curve of a probability of false alarm versus probability of detection. Accordingly, we explore changing the standard goal. Learners that maximize "AUC(effort, pd)" find the smallest set of modules that contain the most errors. WHICH is a meta-learner framework that can be quickly customized to different goals. When customized to AUC(effort, pd), WHICH out-performs all the data mining methods studied here. More importantly, measured in terms of this new goal, certain widely used learners perform much worse than simple manual methods. Hence, we advise against the indiscriminate use of learners. Learners must be chosen and customized to the goal at hand. With the right architecture (e.g. WHICH), tuning a learner to specific local business goals can be a simple task.	[Menzies, Tim; Milton, Zach; Cukic, Bojan; Jiang, Yue] W Virginia Univ, Morgantown, WV 26506 USA; [Turhan, Burak] Univ Oulu, Oulu, Finland; [Bener, Ayse] Bogazici Univ, Istandbul, Turkey	Menzies, T (reprint author), W Virginia Univ, Morgantown, WV 26506 USA.	tim@menzies.us; zmilton@mix.wvu.edu; burak.turhan@oulu.fi; bojan.cukic@mail.csee.wvu.edu; yjiang1@mix.wvu.edu; bener@boun.edu.tr	Turhan, Burak/G-7400-2011		NSF [CCF-0810879]; Turkish Scientific Research Council (Tubitak) [EEEAG 108E014]	This research was supported by NSF grant CCF-0810879 and the Turkish Scientific Research Council (Tubitak EEEAG 108E014). For an earlier draft, see http://menzies.us/pdf/08bias.pdf.	ARISHOLM E, 2006, 5 ACM IEEE INT S EMP; Blake CL, 1998, UCI REPOSITORY MACHI; Bradley P. S., 1998, KNOWLEDGE DISCOVERY, P9; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1984, CLASSIFICATION REGRE; Brieman L, 1996, MACH LEARN, V24, P123; CHAPMAN M, 2002, P NASA SOFTW ASS S C; Cohen P, 1995, EMPIRICAL METHODS AR; Cohen W. W., 1995, INT C MACH LEARN, P115; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dietterich TG, 1997, AI MAG, V18, P97; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Elkan C., 2001, P 17 INT JOINT C ART; FAGAN ME, 1986, IEEE T SOFTWARE ENG, V12, P744; FAGAN ME, 1976, IBM SYST J, V15, P182; FAWCETT T, 2001, 2001 IEEE INT C DAT; FENTON N, 1994, IEEE SOFTWARE, V86, P95; FENTON NE, 1995, SOFTWARE METRICS RIG; Fenton NE, 1997, SOFTWARE METRICS RIG; Fenton NE, 1999, IEEE T SOFTWARE ENG, V25, P675, DOI 10.1109/32.815326; FREUND Y, 1997, JCSS J COMPUT SYST S, V55; HALL G, 2000, J SYST SOFTWARE, P111; Halstead M., 1977, ELEMENTS SOFTWARE SC; Huang J, 2005, IEEE T KNOWL DATA EN, V17, P299; JIANG Y, 2008, EMPIR SOFTW ENG, P561; JIANG Y, 2008, DEFECTS; Khoshgoftaar T. M., 2001, Proceedings 12th International Symposium on Software Reliability Engineering, DOI 10.1109/ISSRE.2001.989459; KHOSHGOFTAAR TM, 2001, RECENT ADV RELIABILI, P247; Khoshgoftaar TM, 2003, EMPIR SOFTW ENG, V8, P255, DOI 10.1023/A:1024424811345; KORU A, 2007, P PROMISE 07 ICSE; KORU A, 2009, SOFTW ENG IEEE T, V35, P293; KORU A, 2008, EMPIR SOFTW ENG, P473; LESSMANN S, 2008, IEEE T SOFTW ENG; Leveson N., 1995, SAFEWARE SYSTEM SAFE; Littlewood B, 1997, IEEE T SOFTWARE ENG, V23, P673, DOI 10.1109/32.637384; Lowry M., 1998, Proceedings 13th IEEE International Conference on Automated Software Engineering (Cat. No.98EX239), DOI 10.1109/ASE.1998.732690; LUTZ R, 2003, J SYST SOFTW; McCabe T. J., 1976, IEEE Transactions on Software Engineering, VSE-2, DOI 10.1109/TSE.1976.233837; Menzies T, 2000, IEEE SOFTWARE, V17, P107, DOI 10.1109/52.877876; MENZIES T, 2002, P IEEE ASE 2002; MENZIES T, 2004, 2004 IEEE C HIGH ASS; MENZIES T, 2007, IEEE T SOFTW ENG; MILTON Z, 2008, THESIS; Mockus A, 2005, PROC INT CONF SOFTW, P225; Musa J.D., 1987, SOFTWARE RELIABILITY; Nagappan N, 2005, PROC INT CONF SOFTW, P580; Nagappan N., 2008, ICSE 08; NAGAPPAN N, 2005, ICSE 2005; NIKORA A, 2004, PERSONNEL COMMUNICAT; NIKORA A, 2003, 9 INT SOFTW METR S M; Ostrand T. J., 2004, INT S SOFTW TEST AN, P86; PORTER AA, 1990, IEEE SOFTWARE    MAR, P46; PUGH W, 1990, COMMUN ACM, V33, P668, DOI 10.1145/78973.78977; Quinlan J. R., 1992, C4 5 PROGRAMS MACHIN; Quinlan J. R, 1992, 5 AUSTR JOINT C ART, P343; RAFFO D, 2005, COMMUNICATION; Rakitin S.R., 2001, SOFTWARE VERIFICATIO; SHEPPERD M, 1994, J SYST SOFTWARE, V26, P197, DOI 10.1016/0164-1212(94)90011-6; Shull F., 2002, Proceedings Eighth IEEE Symposium on Software Metrics, DOI 10.1109/METRIC.2002.1011343; Shull F, 2000, COMPUTER, V33, P73, DOI 10.1109/2.869376; SRINIVASAN K, 1995, IEEE T SOFTWARE ENG, V21, P126, DOI 10.1109/32.345828; Tang W, 2004, PROC INT C TOOLS ART, P373; TIAN J, 1995, IEEE T SOFTWARE ENG, V21, P641, DOI 10.1109/32.403788; TOSUN A, 2009, PROMISE 09; TOSUN A, 2010, IAAI 10; TURHAN B, 2009, EMPIR SOFTW ENG, V68, P278; Turner J., 2006, PREDICTIVE APPROACH; VOAS J, 1995, IEEE SOFTWARE    MAY, P17; WEYUKER E, 2008, EMPIR SOFTW ENG; Witten I. H., 2005, DATA MINING; YANG Y, 2006, ECML, P533; Zimmermann T, 2009, ESEC FSE 09	73	18	20	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0928-8910		AUTOMAT SOFTW ENG	Automat. Softw. Eng.	DEC	2010	17	4					375	407		10.1007/s10515-010-0069-5		33	Computer Science, Software Engineering	Computer Science	630EZ	WOS:000280257100002	
J	Quirino, T; Kubat, M; Bryan, NJ				Quirino, Thiago; Kubat, Miroslav; Bryan, Nicholas J.			Instinct-Based Mating in Genetic Algorithms Applied to the Tuning of 1-NN Classifiers	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						Genetic algorithm; mating strategies; multiobjective optimization; nearest-neighbor classifiers	NEAREST-NEIGHBOR CLASSIFIER; EVOLUTIONARY ALGORITHMS; SELECTION; REDUCTION; SEARCH; DESIGN; RULE	The behavior of the genetic algorithm (GA), a popular approach to search and optimization problems, is known to depend, among other factors, on the fitness function formula, the recombination operator, and the mutation operator. What has received less attention is the impact of the mating strategy that selects the chromosomes to be paired for recombination. Existing GA implementations mostly choose them probabilistically, according to their fitness function values, but we show that more sophisticated mating strategies can not only accelerate the search, but perhaps even improve the quality of the GA-generated solution. In our implementation, we took inspiration from the "opposites-attract" principle that is so common in nature. As a testbed, we chose the problem of 1-NN classifier tuning where genetic solutions have been employed before, and are thus well-understood by the research community. We propose three "instinct-based" mating strategies and experimentally investigate their behaviors.	[Quirino, Thiago; Kubat, Miroslav] Univ Miami, Dept Elect & Comp Engn, Coral Gables, FL 33146 USA; [Bryan, Nicholas J.] Stanford Univ, Dept Mus, Ctr Comp Res Mus & Acoust CCRMA, Stanford, CA 94305 USA	Quirino, T (reprint author), Univ Miami, Dept Elect & Comp Engn, 1251 Mem Dr, Coral Gables, FL 33146 USA.	t.quirino@umiami.edu; mkubat@miami.edu; nbryan@stanford.edu			US National Science Foundation [IIS0513702]	The work was supported by the US National Science Foundation award #IIS0513702.	Angiulli F., 2005, P 22 INT C MACH LEAR, P25, DOI 10.1145/1102351.1102355; Bentley P., 1999, EVOLUTIONARY DESIGN; Cano JR, 2003, IEEE T EVOLUT COMPUT, V7, P561, DOI 10.1109/TEVC.2003.819265; CANTUPAZ CKE, 2004, P ACM SIGKDD INT C K, P788; Cantu-Paz E., 1998, CALCULATEURS PARALLE, V10, P141; CANTUPAZ E, 1997, 97004 ILL GEN ALG LA; CHEATHAM M, 2006, P ITNG, P364; Chen JH, 2005, INT J APPROX REASON, V40, P3, DOI 10.1016/j.ijar.2004.11.009; CHEN SSS, 1999, P C EV COMP CEC 99, P177; Coello Coello C. A., 2005, Genetic Programming and Evolvable Machines, V6, DOI 10.1007/s10710-005-6164-x; Coello C.A.C., 1999, KNOWL INF SYST, V1, P129; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017; ESHELMAN LJ, 1991, ADAPTIVE SEARCH ALGO; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; FIX E, 1989, INT STAT REV, V57, P238, DOI 10.2307/1403797; Freidman J., 1977, ACM T MATH SOFTWARE, V3, P209, DOI 10.1145/355744.355745; GILPITA R, 2007, P C INT DAT ENG AUT, P1141; Goh KS, 2003, ARTIF INTELL REV, V19, P123, DOI 10.1023/A:1022692631328; Goldberg D. E, 1989, GENETIC ALGORITHMS S; Gong MG, 2008, EVOL COMPUT, V16, P225, DOI 10.1162/evco.2008.16.2.225; Grosso P.B., 1985, THESIS U MICHIGAN; Hart Emma, 2008, Applied Soft Computing Journal, V8, DOI 10.1016/j.asoc.2006.12.004; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Ho SY, 2002, PATTERN RECOGN LETT, V23, P1495, DOI 10.1016/S0167-8655(02)00109-5; Horowitz E., 1997, COMPUTER ALGORITHMS; Ishibuchi H, 2000, P GEN EV COMP C, P1069; Knowles JD, 2000, EVOL COMPUT, V8, P149, DOI 10.1162/106365600568167; Konak A, 2006, RELIAB ENG SYST SAFE, V91, P992, DOI 10.1016/j.ress.2005.11.018; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; Kuncheva LI, 1999, PATTERN RECOGN LETT, V20, P1149, DOI 10.1016/S0167-8655(99)00082-3; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; LIEPINS GE, 1990, OPERATIONS RES ARTIF, P29; LIN EGS, 1994, P 6 IEEE S PAR DISTR; Llora X., 2003, Intelligent Data Analysis, V7; MUNETOMO M, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P649; Nene SA, 1997, IEEE T PATTERN ANAL, V19, P989, DOI 10.1109/34.615448; Newman CBDJ, 1998, UCI REPOSITORY MACHI; RAGUWANSHI MM, 2006, P IEEE INT C CYB INT; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; RITZEL BJ, 1994, WATER RESOUR RES, V30, P1589, DOI 10.1029/93WR03511; Rozsypal A., 2003, Intelligent Data Analysis, V7; RUKOVANSKY I, 2009, P WORLD C ENG COMP S, V2, P1038; SANCHEZVELAZCO J, 2003, P UK WORKSH COMP INT, P217; Schaffer J., 1985, P 1 INT C GEN ALG, P93; SORYANI M, 2006, P WORLD AC SCI ENG T, V18, P364; SPROULL RF, 1991, ALGORITHMICA, V6, P579, DOI 10.1007/BF01759061; Srinivas N., 1994, Evolutionary Computation, V2, P221, DOI 10.1162/evco.1994.2.3.221; VELAZCO JS, 2003, P UK WORKSH COMP INT, P217; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; YAO PGJ, 2005, P IEEE C EVOLUTIONAR, V1, P816; ZHU JPH, 2006, NATURAL COMPUTATION, P480; Zhu YN, 2006, LECT NOTES COMPUT SC, V4113, P634, DOI 10.1007/11816157_75; Zitzler E, 1999, IEEE T EVOLUT COMPUT, V3, P257, DOI 10.1109/4235.797969; 2009, EUROPEAN SOC HUM MAY	55	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	DEC	2010	22	12					1724	1737		10.1109/TKDE.2009.211		14	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	666QV	WOS:000283133800006	
J	Triguero, I; Garcia, S; Herrera, F				Triguero, Isaac; Garcia, Salvador; Herrera, Francisco			IPADE: Iterative Prototype Adjustment for Nearest Neighbor Classification	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						Classification; differential evolution; nearest neighbor; prototype generation	DIFFERENTIAL EVOLUTION; PATTERN-CLASSIFICATION; GLOBAL OPTIMIZATION; ALGORITHMS; REDUCTION; DESIGN; ABSTRACTION; CLASSIFIERS; SPACES	Nearest prototype methods are a successful trend of many pattern classification tasks. However, they present several shortcomings such as time response, noise sensitivity, and storage requirements. Data reduction techniques are suitable to alleviate these drawbacks. Prototype generation is an appropriate process for data reduction, which allows the fitting of a dataset for nearest neighbor (NN) classification. This brief presents a methodology to learn iteratively the positioning of prototypes using real parameter optimization procedures. Concretely, we propose an iterative prototype adjustment technique based on differential evolution. The results obtained are contrasted with nonparametric statistical tests and show that our proposal consistently outperforms previously proposed methods, thus becoming a suitable tool in the task of enhancing the performance of the NN classifier.	[Triguero, Isaac; Herrera, Francisco] Univ Granada, Dept Comp Sci & Artificial Intelligence, CITIC UGR, E-18071 Granada, Spain; [Garcia, Salvador] Univ Jaen, Dept Comp Sci, Jaen 23071, Spain	Triguero, I (reprint author), Univ Granada, Dept Comp Sci & Artificial Intelligence, CITIC UGR, E-18071 Granada, Spain.	triguero@decsai.ugr.es; sglopez@ujaen.es; herrera@decsai.ugr.es	Herrera, Francisco/C-6856-2008	Herrera, Francisco/0000-0002-7283-312X	 [TIN2008-06681-C06-01]	Manuscript received June 10, 2010; revised September 3, 2010; accepted October 9, 2010. Date of publication October 28, 2010; date of current version November 30, 2010. This work was supported by TIN2008-06681-C06-01.	ALCALAFDEZ J, 2010, J MULTIPLE IN PRESS; Alpaydin E., 2010, INTRO MACHINE LEARNI; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Burr Ridge I, 1997, MACHINE LEARNING; Cervantes A, 2009, IEEE T SYST MAN CY B, V39, P1082, DOI 10.1109/TSMCB.2008.2011816; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; Chen CH, 1996, PATTERN RECOGN LETT, V17, P819, DOI 10.1016/0167-8655(96)00041-4; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fayed HA, 2009, IEEE T NEURAL NETWOR, V20, P890, DOI 10.1109/TNN.2009.2018547; Fayed HA, 2007, PATTERN RECOGN, V40, P1498, DOI 10.1016/j.patcog.2006.10.018; Fernandez F, 2004, J HEURISTICS, V10, P431, DOI 10.1023/B:HEUR.0000034715.70386.5b; Fernandez F, 2008, IEEE T NEURAL NETWOR, V19, P40, DOI 10.1109/TNN.2007.902955; Garcia EK, 2010, IEEE T KNOWL DATA EN, V22, P1274, DOI 10.1109/TKDE.2009.159; Garcia S, 2009, SOFT COMPUT, V13, P959, DOI 10.1007/s00500-008-0392-y; Garcia S, 2010, INFORM SCIENCES, V180, P2044, DOI 10.1016/j.ins.2009.12.010; Garcia-Pedrajas N, 2009, IEEE T NEURAL NETWOR, V20, P258, DOI 10.1109/TNN.2008.2005496; Kim SW, 2003, PATTERN RECOGN, V36, P1083, DOI 10.1016/S0031-3203(02)00115-2; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Kononenko I., 2007, MACHINE LEARNING DAT; Lam W, 2002, IEEE T PATTERN ANAL, V24, P1075; Li J, 2005, INT J ARTIF INTELL T, V14, P261, DOI 10.1142/S0218213005002090; Liu H., 2001, INSTANCE SELECTION C; Liu H., 1998, FEATURE EXTRACTION C; Lozano M, 2006, PATTERN RECOGN, V39, P1827, DOI 10.1016/j.patcog.2006.04.005; Nanni L, 2009, NEUROCOMPUTING, V72, P1092, DOI 10.1016/j.neucom.2008.03.008; Neri F, 2009, MEMETIC COMPUTING J, V1, P153; Papadopoulos A. N., 2004, NEAREST NEIGHBOR SEA; PARADES R, 2006, PATTERN RECOGN, V39, P180; PRICE KV, 2005, NAT COMP SER, pR7; Price KV, 1999, INTRO DIFFERENTIAL E; Sanchez JS, 2004, PATTERN RECOGN, V37, P1561, DOI 10.1016/j.patcog.2003.12.012; Alcala-Fdez J, 2009, SOFT COMPUT, V13, P307, DOI 10.1007/s00500-008-0323-y; Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; Witten I., 2005, DATA MINING PRACTICA; WU X, 2009, 10 TEN ALGORITHMS DA	36	12	13	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	DEC	2010	21	12					1984	1990		10.1109/TNN.2010.2087415		7	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	691AX	WOS:000285053800012	
J	Du, QA; Wei, W; May, D; Younan, NH				Du, Qian; Wei, Wei; May, Daniel; Younan, Nicolas H.			Noise-Adjusted Principal Component Analysis for Buried Radioactive Target Detection and Classification	IEEE TRANSACTIONS ON NUCLEAR SCIENCE			English	Article						Buried target detection; classification; Gammaray spectral analysis; noise-adjusted principal component analysis; principal component analysis		We present a noise-adjusted principal component analysis (NAPCA)-based approach to the detection and classification of buried radioactive targets with short sensor dwell time. The data used in the experiments is the gamma spectroscopy collected by a Sodium Iodide (NAI) scintillation detector. Spectral transformation methods are first applied to the data, followed by NAPCA. Then kappa-nearest neighbor (kappa NN) clustering is applied to the NAPCA-transformed feature subspace to achieve detection or classification. This method is evaluated using a database of 240 spectral measurements consisting of background (construction sand), benign material measurements (uranium ore), and target measurements (depleted uranium) at various depths. Compared to other widely used algorithms for depleted uranium, the proposed technique can provide better performance.	[Du, Qian; Wei, Wei; May, Daniel; Younan, Nicolas H.] Mississippi State Univ, Dept Elect & Comp Engn, Mississippi State, MS 39762 USA	Du, QA (reprint author), Mississippi State Univ, Dept Elect & Comp Engn, Mississippi State, MS 39762 USA.	du@ece.msstate.edu			U.S. Army Engineer Research and Development Center at Vicksburg, Mississippi	This work was supported by the U.S. Army Engineer Research and Development Center at Vicksburg, Mississippi.	Anderson KK, 2008, J RADIOANAL NUCL CH, V276, P713, DOI 10.1007/s10967-008-0622-x; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ely J, 2006, NUCL INSTRUM METH A, V560, P373, DOI 10.1016/j.nima.2006.01.053; GREEN AA, 1988, IEEE T GEOSCI REMOTE, V26, P65, DOI 10.1109/36.3001; HASLIP DS, 2000, TM2000049 DREO; KOUZES RT, 2007, J RADIOANALYT NUCL C, V276, P719; LEE JB, 1990, IEEE T GEOSCI REMOTE, V28, P295, DOI 10.1109/36.54356; Pfund DM, 2007, IEEE T NUCL SCI, V54, P1232, DOI 10.1109/TNS.2007.901202; Roger RE, 1996, INT J REMOTE SENS, V17, P1951; Runkle RC, 2006, IEEE T NUCL SCI, V53, P1418, DOI 10.1109/TNS.2006.874883; STROMSWOLD DC, 2004, IEEE NUCL SCI S, V1, P196, DOI 10.1109/NSSMIC.2004.1462180; Tamhane A. C., 2000, STAT DATA ANAL ELEME	12	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9499		IEEE T NUCL SCI	IEEE Trans. Nucl. Sci.	DEC	2010	57	6					3760	3767		10.1109/TNS.2010.2084105		8	Engineering, Electrical & Electronic; Nuclear Science & Technology	Engineering; Nuclear Science & Technology	695FO	WOS:000285356200017	
J	Visweswaran, S; Cooper, GF				Visweswaran, Shyam; Cooper, Gregory F.			Learning Instance-Specific Predictive Models	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						instance-specific; Bayesian network; Markov blanket; Bayesian model averaging	BAYESIAN NETWORK CLASSIFIERS; MARKOV BLANKET INDUCTION; FEATURE-SELECTION; CAUSAL DISCOVERY; LOCAL CAUSAL; CLASSIFICATION; ALGORITHMS	This paper introduces a Bayesian algorithm for constructing predictive models from data that are optimized to predict a target variable well for a particular instance. This algorithm learns Markov blanket models, carries out Bayesian model averaging over a set of models to predict a target variable of the instance at hand, and employs an instance-specific heuristic to locate a set of suitable models to average over. We call this method the instance-specific Markov blanket (ISMB) algorithm. The ISMB algorithm was evaluated on 21 UCI data sets using five different performance measures and its performance was compared to that of several commonly used predictive algorithms, including nave Bayes, C4.5 decision tree, logistic regression, neural networks, k-Nearest Neighbor, Lazy Bayesian Rules, and AdaBoost. Over all the data sets, the ISMB algorithm performed better on average on all performance measures against all the comparison algorithms.	[Visweswaran, Shyam; Cooper, Gregory F.] Univ Pittsburgh, Dept Biomed Informat, Pittsburgh, PA 15260 USA	Visweswaran, S (reprint author), Univ Pittsburgh, Dept Biomed Informat, Pittsburgh, PA 15260 USA.	SHV3@PITT.EDU; GFC@PITT.EDU			National Library of Medicine [NLM R01-LM008374, T15-LM007059]	This work was supported by a grant from the National Library of Medicine (NLM R01-LM008374) and a training grant from the National Library of Medicine to the University of Pittsburgh's Biomedical Informatics Training Program (T15-LM007059).	Aha D.W., 1998, FEATURE EXTRACTION C, P13; Aliferis C. F., 2003, P 2003 AM MED INF AS, P21; Aliferis CF, 2010, J MACH LEARN RES, V11, P235; Aliferis CF, 2010, J MACH LEARN RES, V11, P171; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Caruana R., 2004, P 10 ACM SIGKDD INT, P69, DOI 10.1145/1014052.1014063; Cerquides J, 2005, LECT NOTES ARTIF INT, V3720, P72; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1023/A:1022649401552; Cover T., 2006, ELEMENTS INFORM THEO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NOR; Dash D, 2004, J MACH LEARN RES, V5, P1177; Dash D., 2002, P 19 INT C MACH LEAR, P91; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Frank A., 2010, UCI MACHINE LEARNING; Friedman JH, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P717; Friedman N, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P206; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; FU S, 2008, P ADV KNOWL DISC DAT, P562; Gottrup C, 2005, ARTIF INTELL MED, V33, P223, DOI 10.1016/j.artmed.2004.06.003; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; Heckerman D., 1999, LEARNING GRAPHICAL M; Hoeting JA, 1999, STAT SCI, V14, P382; Hwang KB, 2005, IEEE T SYST MAN CY B, V35, P1302, DOI 10.1109/TSMCB.2005.850162; Kohavi R, 1996, P 2 INT C KNOWL DISC, p202~207; Koller D., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Madden MG, 2002, LECT NOTES ARTIF INT, V2464, P203; MADDEN MG, 2002, CSLG0211003 CORR; Madigan D., 1994, J AM STAT ASSOC, V89, P1335; MARGARITIS D, 1999, P 1999 C ADV NEUR IN; MINKA TP, 2002, BAYESIAN MODEL AVERA; Moore A. W., 2003, P 20 INT C MACH LEAR, P552; Neapolitan R, 2003, LEARNING BAYESIAN NE; PAZZANI M, 1995, P 5 INT WORKSH ART I, P239; PAZZANI MJ, 1998, FEATURE EXTRACTION C; Pearl J., 1988, PROBABILISTIC REASON, p[505, 506, 507, 524]; Raftery AE, 1997, J AM STAT ASSOC, V92, P179, DOI 10.2307/2291462; TING KM, 1999, P 19 SGES INT C KNOW, P122; Tsamardinos I, 2006, MACH LEARN, V65, P31, DOI 10.1007/s10994-006-6889-7; Tsamardinos I., 2003, 9 INT WORKSH ART INT; VISWESWARAN S, 2004, P 18 ANN C NEUR INF; VISWESWARAN S, 2009, DBMI0912 U PITTSB; Visweswaran S, 2010, J BIOMED INFORM, V43, P669, DOI 10.1016/j.jbi.2010.04.009; Wasserman L, 2000, J MATH PSYCHOL, V44, P92, DOI 10.1006/jmps.1999.1278; Witten I., 2005, DATA MINING PRACTICA; Yeung KY, 2005, BIOINFORMATICS, V21, P2394, DOI 10.1093/bioinformatics/bti319; Zhang JP, 1997, ARTIF INTELL REV, V11, P175, DOI 10.1023/A:1006500703083; Zheng ZJ, 2000, MACH LEARN, V41, P53, DOI 10.1023/A:1007613203719	49	0	0	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	DEC	2010	11						3333	3369				37	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	712BO	WOS:000286637200003	
J	DiCicco, TM; Patel, R				DiCicco, Thomas M.; Patel, Rupal			Machine Classification of Prosodic Control in Dysarthria	JOURNAL OF MEDICAL SPEECH-LANGUAGE PATHOLOGY			English	Article						machine classification; prosody; dysarthria; voice-driven AAC aids	CEREBRAL-PALSY; COMMUNICATION; CHILDREN	Recent studies suggest that speakers with dysarthria may be able to manipulate prosodic features sufficiently to convey information. Leveraging prosodic cues as an alternative or augmentative communication (AAC) signal may allow some individuals with dysarthria to use their vocalizations to engage in richer and more efficient interactions. As an initial step towards building voice-driven communication aids, the performance of three machine classification algorithms was compared to determine which algorithm(s) was most accurate and efficient for classifying a dataset of prosodic manipulations. Our findings suggest that machine classification of dysarthric productions is feasible using preexisting machine learners and rather minimal training data. Highly accurate classification of categorical duration control was achieved for all speakers with dysarthria; however, classification of pitch categories and simultaneous duration-pitch control varied widely across speakers. These findings have implications for harnessing the residual vocal abilities of individuals with dysarthria for machine-mediated AAC interactions.	[Patel, Rupal] Northeastern Univ, Dept Speech Language Pathol & Audiol, Boston, MA 02115 USA	Patel, R (reprint author), Northeastern Univ, Dept Speech Language Pathol & Audiol, 360 Huntington Ave,102 Forsyth Bldg, Boston, MA 02115 USA.	r.patel@neu.edu	orozco, victoria/F-7313-2011		National Institutes of Health [T32 DC000038]	This research was supported in part by funding from the National Institutes of Health (grant #T32 DC000038).	Beukelman D, 1998, AUGMENTATIVE ALTERNA; Boersma P., 2007, PRAAT SYSTEM DOING P; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P2; Ciocca Valter, 2004, Journal of Physiological Anthropology and Applied Human Science, V23, P283, DOI 10.2114/jpa.23.283; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 2001, PATTERN CLASSIFICATI; Eick CF, 2005, LECT NOTES COMPUT SC, V3488, P248; LEDORZE G, 1994, J COMMUN DISORD, V27, P1; MATHYLAIKKO P, 1993, TECHNOL DISABIL, V2, P57; Patel R, 2004, J MED SPEECH-LANG PA, V12, P189; Patel R, 2006, J MED SPEECH-LANG PA, V14, P279; Patel R, 2003, J SPEECH LANG HEAR R, V46, P1401, DOI 10.1044/1092-4388(2003/109); PATEL R, 1998, AAAI WORKSH INT ART, P40; Patel R, 2007, CLIN LINGUIST PHONET, V21, P833, DOI 10.1080/02699200701559476; Patel R, 2009, J SPEECH LANG HEAR R, V52, P206, DOI 10.1044/1092-4388(2008/07-0078); PATEL R, 2002, ALTERNATIVE AUGMENTA, V18, P2, DOI 10.1080/714043392; SHEIN F, 1990, AUGMENTATIVE ALTERNA, P36; VANCE JE, 1994, EUR J DISORDER COMM, V29, P61; VANDERHEIDEN P, 1985, ELECT DEVICES REHABI, P262	19	0	0	DELMAR CENGAGE LEARNING	FLORENCE	PO BOX 6904, FLORENCE, KY 41022-6904 USA	1065-1438		J MED SPEECH-LANG PA	J. Med. Speech-Lang. Pathol.	DEC	2010	18	4					35	39				5	Audiology & Speech-Language Pathology; Clinical Neurology	Audiology & Speech-Language Pathology; Neurosciences & Neurology	688QO	WOS:000284866700005	
J	Sadatnezhad, K; Boostani, R; Ghanizadeh, A				Sadatnezhad, Khadijeh; Boostani, Reza; Ghanizadeh, Ahmad			Proposing an adaptive mutation to improve XCSF performance to classify ADHD and BMD patients	JOURNAL OF NEURAL ENGINEERING			English	Article							BRAIN-COMPUTER INTERFACES; EEG POWER SPECTRA; ALPHA ASYMMETRY; CLASSIFICATION; MANIA; ALGORITHMS; DISORDER; SIGNALS	There is extensive overlap of clinical symptoms observed among children with bipolar mood disorder (BMD) and those with attention deficit hyperactivity disorder (ADHD) Thus, diagnosis according to clinical symptoms cannot be very accurate It is therefore desirable to develop quantitative criteria for automatic discrimination between these disorders This study is aimed at designing an efficient decision maker to accurately classify ADHD and BMD patients by analyzing their electroencephalogram (EEG) signals In this study, 22 channels of EEGs have been recorded from 21 subjects with ADHD and 22 individuals with BMD Several informative features, such as fractal dimension, band power and autoregressive coefficients, were extracted from the recorded signals Considering the multimodal overlapping distribution of the obtained features, linear discriminant analysis (LDA) was used to reduce the input dimension in a more separable space to make it more appropriate for the proposed classifier A piecewise linear classifier based on the extended classifier system for function approximation (XCSF) was modified by developing an adaptive mutation rate, which was proportional to the genotypic content of best individuals and their fitness in each generation The proposed operator controlled the trade-off between exploration and exploitation while maintaining the diversity in the classifier's population to avoid premature convergence To assess the effectiveness of the proposed scheme the extracted features were applied to support vector machine, LDA, nearest neighbor and XCSF classifiers To evaluate the method, a noisy environment was simulated with different noise amplitudes It is shown that the results of the proposed technique are more robust as compared to conventional classifiers Statistical tests demonstrate that the proposed classifier is a promising method for discriminating between ADHD and BMD patients	[Sadatnezhad, Khadijeh; Boostani, Reza] Shiraz Univ, Dept Comp Sci & Engn, Sch Engn, Shiraz, Iran; [Ghanizadeh, Ahmad] Shiraz Univ Med & Sci, Res Ctr Psychiat & Behav Sci, Hafez Hosp, Shiraz, Iran	Sadatnezhad, K (reprint author), Shiraz Univ, Dept Comp Sci & Engn, Sch Engn, Shiraz, Iran.		Ghanizadeh, Ahmad/C-2177-2011				American Psychiatric Association, 1994, DIAGN STAT MAN MENT; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Bahrami B, 2005, NEUROREPORT, V16, P187, DOI 10.1097/00001756-200502080-00025; BASHASHATI A, J NEURAL ENG, V4, pR32; Bastien CH, 2003, SLEEP, V26, P313; Boostani Reza, 2004, J Neural Eng, V1, P212, DOI 10.1088/1741-2560/1/4/004; Boostani R, 2009, EXPERT SYST APPL, V36, P6492, DOI 10.1016/j.eswa.2008.07.037; BOOSTANI R, 2007, J MED BIOL ENG COMPU, V45, P404; BULL L, 2000, COM ADAP SY, P460; BURGES CJC, 1998, KNOWL DISCOV DATA MI, V2; BURGES JC, 1998, KNOWL DISCOV DATA MI, V2, P1; Butz M. V., 2002, J SOFT COMPUTING, V6, P144; Butz MV, 2008, P 10 ANN C GEN EV CO, P1365, DOI 10.1145/1389095.1389361; Butz MV, 2004, IEEE T EVOLUT COMPUT, V8, P28, DOI 10.1109/TEVC.2003.818194; BUTZ MV, 2006, P 8 ANN C GEN EV COM, P1457, DOI 10.1145/1143997.1144237; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEIVANAYAGI S, 2007, INT J SYST CYBERN IN, V5, P75; Duda R. O., 2001, PATTERN RECOGNITION; DUDA RO, 2001, PAATERN CLASSIFICATI; FRIEDMAN JHK, 1997, DATA MINING KNOWL DI, V1; Galka A., 2000, TOPICS NONLINEAR TIM; Hale TS, 2010, J PSYCHIATR RES, V44, P605, DOI 10.1016/j.jpsychires.2009.11.012; Hale TS, 2009, NEUROPSYCHOLOGIA, V47, P2082, DOI 10.1016/j.neuropsychologia.2009.03.021; Hartigan J., 1975, CLUSTERING ALGORITHM; He P, 2007, MED BIOL ENG COMPUT, V45, P495, DOI 10.1007/s11517-007-0179-9; HIGUCHI T, 1988, PHYSICA D, V31, P277, DOI 10.1016/0167-2789(88)90081-4; Huan Nai-Jen, 2004, J Neural Eng, V1, P142, DOI 10.1088/1741-2560/1/3/003; Koek RJ, 1999, J AFFECT DISORDERS, V53, P109, DOI 10.1016/S0165-0327(98)00171-2; LANZI PL, 2002, LECT NOTES ARTIF INT, V2321, P57; Lotte F, 2007, J NEURAL ENG, V4, pR1, DOI 10.1088/1741-2560/4/R01; Mandelbrot B. B., 1983, FRACTAL GEOMETRY NAT; Nandan M, 2010, J NEURAL ENG, V7, DOI 10.1088/1741-2560/7/3/036001; OLUBOKA O, 2009, CAN J PSYCHIAT, V47, P364; PETROSIAN A, 1995, P 9 IEEE S COMP BAS; Raghavendra BS, 2009, PHYSIOL MEAS, V30, P795, DOI 10.1088/0967-3334/30/8/005; Sabeti M, 2007, BIOMED SIGNAL PROCES, V2, P122, DOI 10.1016/j.bspc.2007.03.003; Sabeti M, 2009, ARTIF INTELL MED, V47, P263, DOI 10.1016/j.artmed.2009.03.003; SALETU B, 2002, INT C SERIES, V1232, P627, DOI 10.1016/S0531-5131(02)00168-1; Sander C, 2010, CLIN NEUROPHYSIOL, V121, P1511, DOI 10.1016/j.clinph.2010.03.021; SKINNER BT, 2007, P 29 ANN INT C IEEE; Small JG, 1999, J AFFECT DISORDERS, V53, P217, DOI 10.1016/S0165-0327(98)00124-4; Snyder SM, 2008, PSYCHIAT RES, V159, P346, DOI 10.1016/j.psychres.2007.05.006; STALPH PO, 2009, N001 COBOSLAB U WURZ; Stoica P., 1997, INTRO SPECTRAL ANAL; Swartwood JN, 2003, PEDIATR NEUROL, V28, P199, DOI 10.1016/S0887-8994(02)00514-3; Tang YQ, 2007, INT J PSYCHOPHYSIOL, V65, P2, DOI 10.1016/j.ijpsycho.2007.02.004; Thomasson N., 2002, NONLINEAR DYNAMICS P, V6, P259, DOI 10.1023/A:1015082611626; Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293; Vapnik V.N., 1995, NATURE STAT LEARNING; Wilson S. W., 2002, Natural Computing, V1, DOI 10.1023/A:1016535925043; Wilson S. W., 2001, P GEN EV COMP C GECC, P974; Wilson SW, 1995, EVOL COMPUT, V3, P149, DOI 10.1162/evco.1995.3.2.149	52	0	0	IOP PUBLISHING LTD	BRISTOL	DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND	1741-2560		J NEURAL ENG	J. Neural Eng.	DEC	2010	7	6							066006	10.1088/1741-2560/7/6/066006		12	Engineering, Biomedical; Neurosciences	Engineering; Neurosciences & Neurology	694BS	WOS:000285270600007	
J	Ferrandiz, S; Boulle, M				Ferrandiz, Sylvain; Boulle, Marc			Bayesian instance selection for the nearest neighbor rule	MACHINE LEARNING			English	Article						Nearest neighbor; Instance selection; Voronoi tesselation; Maximum a posteriori	LEARNING ALGORITHMS; GRAPHS	The nearest neighbors rules are commonly used in pattern recognition and statistics. The performance of these methods relies on three crucial choices: a distance metric, a set of prototypes and a classification scheme. In this paper, we focus on the second, challenging issue: instance selection. We apply a maximum a posteriori criterion to the evaluation of sets of instances and we propose a new optimization algorithm. This gives birth to Eva, a new instance selection method. We benchmark this method on real datasets and perform a multi-criteria analysis: we evaluate the compression rate, the predictive accuracy, the reliability and the computational time. We also carry out experiments on synthetic datasets in order to discriminate the respective contributions of the criterion and the algorithm, and to illustrate the advantages of Eva over the state-of-the-art algorithms. The study shows that Eva outputs smaller and more reliable sets of instances, in a competitive time, while preserving the predictive accuracy of the related classifier.	[Ferrandiz, Sylvain; Boulle, Marc] Orange Labs, F-22300 Lannion, France	Ferrandiz, S (reprint author), Orange Labs, 2 Ave Pierre Marzin, F-22300 Lannion, France.	sylvain.ferrandiz@orange-ftgroup.com; marc.boulle@orange-ftgroup.com					AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Asuncion A., 2007, UCI MACHINE LEARNING; Berndt D. J., 1996, FINDING PATTERNS TIM; Bhattacharya B, 2005, LECT NOTES COMPUT SC, V3776, P60; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; BUNKE H, 2000, ICPR, P2117; Cameron-Jones R.M., 1995, P 8 AUSTR JOINT C AR, P99; CHANG C, 1991, IEEE T COMPUT, V23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devroye L, 1996, PROBABILISTIC THEORY; Duda R. O., 2001, PATTERN CLASSIFICATI; Ferrandiz S, 2006, INTELL DATA ANAL, V10, P269; Fix E., 1951, 4 USAF SCH AV MED; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Grunwald P. D., 2005, ADV MINIMUM DESCRIPT; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hansen P, 2001, EUR J OPER RES, V130, P449, DOI 10.1016/S0377-2217(00)00100-4; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; JAROMCZYK JW, 1992, P IEEE, V80, P1502, DOI 10.1109/5.163414; Kohonen T., 2001, SELF ORGANIZING MAPS; Levenshtein V. I., 1966, CYBERNETICS CONTROL, V10, P707; Liu H., 2001, INSTANCE SELECTION C; MacQueen J., 1967, 5 BERK S MATH STAT P, P281; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Robert C.P., 2001, BAYESIAN CHOICE DECI; Salzberg S., 1991, MACH LEARN, V6, P277; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P507, DOI 10.1016/S0167-8655(97)00035-4; Scholkopf B., 2001, LEARNING KERNELS SUP; Sebban M., 2002, J MACHINE LEARNING R, V3, P863; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; TOUSSAINT GT, 1975, P INT COMP SOFTW APP, P55; Toussaint G. T., 1985, Computer Science and Statistics. Proceedings of the Sixteenth Symposium on the Interface; Vapnik V., 1996, NATURE STAT LEARNING; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; Wilson HR, 1997, VISUAL NEUROSCI, V14, P403	39	2	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	DEC	2010	81	3					229	256		10.1007/s10994-010-5170-2		28	Computer Science, Artificial Intelligence	Computer Science	657QP	WOS:000282427700002	
J	Trotter, MWB; Sadowski, PG; Dunkley, TPJ; Groen, AJ; Lilley, KS				Trotter, Matthew W. B.; Sadowski, Pawel G.; Dunkley, Tom P. J.; Groen, Arnoud J.; Lilley, Kathryn S.			Improved sub-cellular resolution via simultaneous analysis of organelle proteomics data across varied experimental conditions	PROTEOMICS			English	Article						Bioinformatics; Organelle proteomics; Protein localisation; Statistical models; Support vector machines	SUPPORT VECTOR MACHINES; PROTEINS; LOCALIZATION; TAGS	Spatial organisation of proteins according to their function plays an important role in the specificity of their molecular interactions Emerging proteomics methods seek to assign proteins to sub cellular locations by partial separation of organelles and computational analysis of protein abundance distributions among partially separated fractions Such methods permit simultaneous analysis of unpurified organelles and promise proteome wide localisation in scenarios wherein perturbation may prompt dynamic re distribution Resolving organelles that display similar behavior during a protocol designed to provide partial enrichment represents a possible shortcoming We employ the Localisation of Organelle Proteins by Isotope Tagging (LOPIT) organelle proteomics platform to demonstrate that combining information from distinct separations of the same material can improve organelle resolution and assignment of proteins to sub cellular locations Two previously published experiments whose distinct gradients are alone unable to fully resolve six known protei n-organelle groupings are subjected to a rigorous analysis to assess protein organelle association via a contemporary pattern recognition algorithm Upon straightforward combination of single gradient data we observe significant improvement in protein organelle association via both a non linear support vector machine algorithm and partial least squares discriminant analysis The outcome yields suggestions for further improvements to present organelle proteomics platforms and a robust analytical methodology via which to associate proteins with sub cellular organelles	[Trotter, Matthew W. B.] Univ Cambridge, Anne McLaren Lab Regenerat Med, Cambridge, England; [Trotter, Matthew W. B.] Univ Cambridge, Dept Surg, Cambridge, England; [Sadowski, Pawel G.; Dunkley, Tom P. J.; Groen, Arnoud J.; Lilley, Kathryn S.] Univ Cambridge, Dept Biochem, Cambridge Syst Biol Ctr, Cambridge Ctr Prote, Cambridge, England	Trotter, MWB (reprint author), Univ Cambridge, Anne McLaren Lab Regenerat Med, W Forvie Bldg,Robinson Way, Cambridge, England.				EU framework 6 WallNet Consortium; BBSRC [BB/E024777/1]; MRC Centre for Stern Cell Biology and Regenerative Medicine University of Cambridge	Support for this work was provided by grants from EU framework 6 WallNet Consortium awarded to P G S and ERA PG Consortium (BBSRC grant BB/E024777/1) awarded to A J G and support to M W B T by an M RC Centre Grant (MRC Centre for Stern Cell Biology and Regenerative Medicine University of Cambridge) The authors wish to thank Dr Sean B Holden, University of Cambridge Computer Laboratory for reading a revised version of the manuscript	Andersen JS, 2003, NATURE, V426, P570, DOI 10.1038/nature02166; Andreyev AY, 2010, MOL CELL PROTEOMICS, V9, P388, DOI 10.1074/mcp.M900432-MCP200; Barbe L, 2008, MOL CELL PROTEOMICS, V7, P499, DOI 10.1074/mcp.M700325-MCP200; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Caputo B., 2002, P NIPS WORKSH STAT M; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; de Duve C, 1971, J Cell Biol, V50, P20; Dreger M, 2003, MASS SPECTROM REV, V22, P27, DOI 10.1002/mas.10047; Dunkley TPJ, 2006, P NATL ACAD SCI USA, V103, P6518, DOI 10.1073/pnas.0506958103; Foster LJ, 2006, CELL, V125, P187, DOI 10.1016/j.cell.2006.03.022; Gilchrist A, 2006, CELL, V127, P1265, DOI 10.1016/j.cell.2006.10.036; Hall SL, 2009, MOL CELL PROTEOMICS, V8, P1295, DOI 10.1074/mcp.M800394-MCP200; Huh WK, 2003, NATURE, V425, P686, DOI 10.1038/nature02026; KARTZOGLOU A, 2010, AN S4 PACKAGE KERNEL; Kohavi R., 1995, P 14 INT JOINT C ART, V2, P1137; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565; Lam YW, 2007, CURR BIOL, V17, P749, DOI 10.1016/j.cub.2007.03.064; Lilley KS, 2007, CURR OPIN PLANT BIOL, V10, P594, DOI 10.1016/j.pbi.2007.08.006; MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491; Ow SY, 2008, J PROTEOME RES, V7, P1615, DOI 10.1021/pr700604v; Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491; Ratsch G, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-S1-S9; Sadowski PG, 2008, PROTEOMICS, V8, P3991, DOI 10.1002/pmic.200800217; Scholkopf B, 1997, IEEE T SIGNAL PROCES, V45, P2758, DOI 10.1109/78.650102; Tan DJL, 2009, J PROTEOME RES, V8, P2667, DOI 10.1021/pr800866n; Thompson A, 2003, ANAL CHEM, V75, P1895, DOI 10.1021/ac0262560; van Rijsbergen CJ, 1979, INFORM RETRIEVAL; Vapnik V.N., 1995, NATURE STAT LEARNING; WESTON J, 1999, P ESANN99 BRUSSELS; Wiese S, 2007, MOL CELL PROTEOMICS, V6, P2045, DOI 10.1074/mcp.M700169-MCP200	31	6	6	WILEY-V C H VERLAG GMBH	WEINHEIM	PO BOX 10 11 61, D-69451 WEINHEIM, GERMANY	1615-9853		PROTEOMICS	Proteomics	DEC	2010	10	23					4213	4219		10.1002/pmic.201000359		7	Biochemical Research Methods; Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	701VK	WOS:000285851900008	
J	Hahnke, V; Rupp, M; Krier, M; Rippmann, F; Schneider, G				Haehnke, Volker; Rupp, Matthias; Krier, Mireille; Rippmann, Friedrich; Schneider, Gisbert			Pharmacophore Alignment Search Tool: Influence of Canonical Atom Labeling on Similarity Searching	JOURNAL OF COMPUTATIONAL CHEMISTRY			English	Article						global alignment; line notation; molecular graph; similarity; virtual screening	DIMENSIONALITY REDUCTION; SEQUENCE ALIGNMENTS; CHEMICAL-STRUCTURES; ALGORITHM; MOLECULES; REPRESENTATION; GENERATION; FRAMEWORK; LIBRARY	Previously, (Hahnke et al., J Comput Chem 2009, 30, 761) we presented the Pharmacophore Alignment Search Tool (PhAST), a ligand-based virtual screening technique representing molecules as strings coding pharmacophoric features and comparing them by global pairwise sequence alignment. To guarantee unambiguity during the reduction of two-dimensional molecular graphs to one-dimensional strings, PhAST employs a graph canonization step. Here, we present the results of the comparison of 11 different algorithms for graph canonization with respect to their impact on virtual screening. Retrospective screenings of a drug-like data set were evaluated using the BED-ROC metric, which yielded averaged values between 0.4 and 0.14 for the best-performing and worst-performing canonization technique. We compared five scoring schemes for the alignments and found preferred combinations of canonization algorithms and scoring functions. Finally, we introduce a performance index that helps prioritize canonization approaches without the need for extensive retrospective evaluation. (C) 2010 Wiley Periodicals, Inc. J Comput Chem 31: 2810-2826, 2010	[Haehnke, Volker; Schneider, Gisbert] ETH, Inst Pharmaceut Sci, CH-8093 Zurich, Switzerland; [Haehnke, Volker] Goethe Univ Frankfurt, Chair Chem & Bioinformat, D-60323 Frankfurt, Germany; [Rupp, Matthias] German Res Ctr Environm Hlth, Helmholtz Zentrum Munchen, D-85764 Neuherberg, Germany; [Krier, Mireille; Rippmann, Friedrich] Merck KGaA, Merck Serono Res Bio & Chemoinformat, D-64293 Darmstadt, Germany	Schneider, G (reprint author), ETH, Inst Pharmaceut Sci, CH-8093 Zurich, Switzerland.	gisbert.schneider@pharma.ethz.ch			Merck KGaA	V.H. is grateful for a Ph.D. scholarship granted by Merck KGaA.	Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Booth HS, 2004, J COMPUT BIOL, V11, P616, DOI 10.1089/cmb.2004.11.616; Borchers B, 1999, OPTIM METHOD SOFTW, V11-2, P613, DOI 10.1080/10556789908805765; Brenner SE, 1998, P NATL ACAD SCI USA, V95, P6073, DOI 10.1073/pnas.95.11.6073; Chia N, 2006, J COMPUT BIOL, V13, P429, DOI 10.1089/cmb.2006.13.429; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAMERAU FJ, 1964, COMMUN ACM, V7, P171, DOI 10.1145/363958.363994; Dayhoff M.O., 1978, ATLAS PROTEIN SEQUEN; Doolin D. M., 1999, Scientific Programming, V7; Durbin R, 1998, BIOL SEQUENCE ANAL; Faulon JL, 2004, J CHEM INF COMP SCI, V44, P427, DOI 10.1021/ci0341823; FLOYD RW, 1962, COMMUN ACM, V5, P345, DOI 10.1145/367766.368168; Hähnke Volker, 2009, J Comput Chem, V30, P761, DOI 10.1002/jcc.21095; Hartmann AK, 2002, PHYS REV E, V65, DOI 10.1103/PhysRevE.65.056102; JOCHUM C, 1977, J CHEM INF COMP SCI, V17, P113, DOI 10.1021/ci60010a014; KARLIN S, 1990, P NATL ACAD SCI USA, V87, P2264, DOI 10.1073/pnas.87.6.2264; Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226; Kondor R. I., 2002, P 19 INT C MACH LEAR; Krier M, 2009, J CHEM INF MODEL, V49, P1280, DOI 10.1021/ci8003418; LIPMAN DJ, 1985, SCIENCE, V227, P1435, DOI 10.1126/science.2983426; MASSEY FJ, 1951, J AM STAT ASSOC, V46, P68, DOI 10.2307/2280095; MORGAN HL, 1965, J CHEM DOC, V5, P107, DOI 10.1021/c160017a018; MULLERHANNEMANN M, 2000, J EXP ALGOR, V5; NEEDLEMA.SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4; Newberg LA, 2008, J COMPUT BIOL, V15, P1187, DOI 10.1089/cmb.2008.0125; Pearson K., 1896, PHILOS T R SOC A, V187, P253, DOI DOI 10.1098/RSTA.1896.0007; Pearson K, 1901, PHILOS MAG, V2, P559; Prabhakar YS, 2006, J CHEM INF MODEL, V46, P52, DOI 10.1021/ci050096m; Proschak E, 2007, J CHEM INF MODEL, V47, P295, DOI 10.1021/ci600305h; RUPP M, 2009, KERNEL METHODS VIRTU; Schneider P, 2003, QSAR COMB SCI, V22, P713, DOI 10.1002/qsar.200330825; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Shaw B., 2007, P 11 INT C ART INT S; Shaw B., 2009, P 26 INT C MACH LEAR; SMOLA AJ, 2003, P 16 ANN C COMP LEAR; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Truchon JF, 2007, J CHEM INF MODEL, V47, P488, DOI 10.1021/ci600426e; Tsuda K, 2004, BIOINFORMATICS, V20, P326, DOI 10.1093/bioinformatics/bth906; VINGRON M, 1994, J MOL BIOL, V235, P1, DOI 10.1016/S0022-2836(05)80006-3; WARSHALL S, 1962, J ACM, V9, P11, DOI 10.1145/321105.321107; WEININGER D, 1989, J CHEM INF COMP SCI, V29, P97, DOI 10.1021/ci00062a008; Zhao W, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-225	42	5	5	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0192-8651		J COMPUT CHEM	J. Comput. Chem.	NOV 30	2010	31	15					2810	2826		10.1002/jcc.21574		17	Chemistry, Multidisciplinary	Chemistry	656EV	WOS:000282309900013	
J	Kim, DJ; Chung, KW; Hong, KS				Kim, Dong-Ju; Chung, Kwang-Woo; Hong, Kwang-Seok			Person Authentication using Face, Teeth and Voice Modalities for Mobile Device Security	IEEE TRANSACTIONS ON CONSUMER ELECTRONICS			English	Article						person authentication; multimodal biometrics	SPEAKER IDENTIFICATION; BIOMETRICS; RECOGNITION; INFORMATION; FUSION; MODELS; IMAGE	In this paper, we propose an enhanced multimodal personal authentication system for mobile device security. The proposed approach fuses information obtained from face, teeth and voice modalities to improve performance. To integrate three modalities, we employ various fusion techniques such as the weighted-summation rule, K-NN, Fisher and Gaussian classifiers, and we then evaluate the authentication performance of the proposed system. The performance is evaluated on a database consisting of 1000 biometric traits that correspond to the face, teeth and voice modalities of 50 persons, i.e., 20 biometric traits per individual, in which these biometric traits are simultaneously collected by a smart-phone device. The experiment results integrating the three modalities showed the error rates of 1.64%, 4.70%, 3.06% and 1.98% for the weighted-summation rule, K-NN, Fisher and Gaussian classifier, respectively, and that the weight-summation rule outperformed the other classification approaches. In contrast, the error rates regarding a single modality were 5.09%, 7.75% and 8.98% for face, teeth, and voice modalities, respectively. From these results, we confirmed that the proposed method achieved a significant performance improvement over the methods using a single modality, and the results showed that the proposed method was very effective through various fusion experiments.(1)	[Kim, Dong-Ju; Hong, Kwang-Seok] Sungkyunkwan Univ, Sch Informat & Commun Engn, Suwon 440746, South Korea; [Chung, Kwang-Woo] Korea Natl Railrd Coll, Dept Railrd Train Operat & Mechatron, Uiwang Si 437763, Kyungkki Do, South Korea	Kim, DJ (reprint author), Sungkyunkwan Univ, Sch Informat & Commun Engn, 300 Chunchun Dong, Suwon 440746, South Korea.	radioguy@skku.edu; ckw1201@hanmail.net; kshong@skku.ac.kr			MKE, Korea under ITRC [NIPA-2010-(C1090-1021-0008)]; MEST [2010-0020210]	This research was supported by MKE, Korea under ITRC NIPA-2010-(C1090-1021-0008), and PRCP through NRF of Korea, funded by MEST(2010-0020210).	Aleksic PS, 2006, P IEEE, V94, P2025, DOI 10.1109/JPROC.2006.886017; Anil K. J, 2004, IEEE T CIRCUITS SYST, V14, P4; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Erzin E, 2005, IEEE T MULTIMEDIA, V7, P840, DOI 10.1109/TMM.2005.854464; Fukunaga K., 1990, INTRO STAT PATTERN R; Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012; KADAMBE S, 1991, THESIS U RHODE ISLAN; Kim DJ, 2010, J NETW COMPUT APPL, V33, P283, DOI 10.1016/j.jnca.2009.12.016; Kim DJ, 2008, IEEE T CONSUM ELECTR, V54, P1790; Kim TW, 2006, IEICE T INF SYST, VE89D, P1309, DOI 10.1093/ietisy/e89-d.3.1309; KUO B, 2003, P GEOSC REM SENS S I, V1, P276; KUO SS, 1994, IEEE T PATTERN ANAL, V16, P842; NADEE C, 2005, 3 INT C INT SENS INF, P14; Nefian A., 1999, IEEE INT C AC SPEECH, V6; O'Shaughnessy D., 1987, SPEECH COMMUNICATION; PRAJUABKLANG K, 2004, P 4 INF COMP ENG POS, V4, P172; Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361; Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5; Viola P., 2001, TECHNICAL REPORT SER; Wark T, 2001, DIGIT SIGNAL PROCESS, V11, P169, DOI 10.1006/dspr.2001.0397	20	6	6	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0098-3063		IEEE T CONSUM ELECTR	IEEE Trans. Consum. Electron.	NOV	2010	56	4					2678	2685		10.1109/TCE.2010.5681156		8	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	705EM	WOS:000286111700092	
J	Biau, G; Devroye, L				Biau, Gerard; Devroye, Luc			On the layered nearest neighbour estimate, the bagged nearest neighbour estimate and the random forest method in regression and classification	JOURNAL OF MULTIVARIATE ANALYSIS			English	Article						Regression estimation; Layered nearest neighbours; One nearest neighbour estimate; Bagging; Random forests	NUMBER; MAXIMA; TREES	Let X(1) X be identically distributed random vectors in R(d), independently drawn according to some probability density. An observation Xi is said to be a layered nearest neighbour (LNN) of a point x if the hyperrectangle defined by x and Xi contains no other data points. We first establish consistency results on L(x), the number of LNN of x. Then, given a sample (X, Y), (X(1), Y(1)),, (X(n), Y(n)) of independent identically distributed random vectors from Rd x R, one may estimate the regression function r(x) = E[Y] X = x by the LNN estimate r(n)(x), defined as an average over the Y's corresponding to those X, which are LNN of x. Under mild conditions on r, we establish the consistency of El r (x) r(x) towards 0 as n -> infinity, for almost all x and all p >= 1, and discuss the links between r and the random forest estimates of Breiman (2001) [8]. We finally show the universal consistency of the bagged (bootstrap-aggregated) nearest neighbour method for regression and classification. (c) 0 2010 Elsevier Inc. All rights reserved.	[Biau, Gerard] Univ Paris 06, LSTA, F-75252 Paris 05, France; [Biau, Gerard] Univ Paris 06, LPMA, F-75252 Paris, France; [Biau, Gerard] Ecole Normale Super, DMA, F-75230 Paris 05, France; [Devroye, Luc] McGill Univ, Sch Comp Sci, Montreal, PQ H3A 2K6, Canada	Biau, G (reprint author), Univ Paris 06, LSTA, Boite 158,Tour 15-25,2Eme Etage,4 Pl Jussieu, F-75252 Paris 05, France.	gerard.biau@upmc.fr; lucdevroye@gmail.com			Agence Nationale pour la Recherche [ANR-09-BLAN-0051-02]; NSERC [A3456]; FQRNT [90-ER-0291]	Gerard Biau's research was supported by the French "Agence Nationale pour la Recherche" under grant ANR-09-BLAN-0051-02 "CLARA". The research at the ENS is carried out within the INRIA project "CLASSIC" hosted by Ecole Normale Superieure and CNRS. Luc Devroye's research was sponsored by NSERC Grant A3456 and FQRNT Grant 90-ER-0291.	Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Bai ZD, 1998, ANN APPL PROBAB, V8, P886; Bai ZD, 2005, RANDOM STRUCT ALGOR, V27, P290, DOI 10.1002/rsa.20053; BARNDORF.O, 1966, THEOR PROBAB APPL+, V11, P249, DOI 10.1137/1111020; Biau G, 2008, J MACH LEARN RES, V9, P2015; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BREIMAN L, 2004, 670 UC BERK STAT DEP; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BREIMAN L, 2000, 577 UC BERK STAT DEP; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cutler A., 2001, COMPUTING SCI STAT, V33, P490; Devroye L, 1996, PROBABILISTIC THEORY; DEVROYE LP, 1978, IEEE T INFORM THEORY, V24, P142, DOI 10.1109/TIT.1978.1055865; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Doeblin W., 1938, REV MATH UNION INTER, V2, P77; Fix E., 1951, 4 USAF SCH AV MED; Gyorfi L., 2002, DISTRIBUTION FREE TH; Lin Y, 2006, J AM STAT ASSOC, V101, P578, DOI 10.1198/016214505000001230; Marcinkiewicz J., 1937, FUND MATH, V29, P60; Petrov W, 1975, SUMS INDEPENDENT RAN; Rachev S. T., 1998, MASS TRANSPORTATION, VI; Steele BM, 2009, MACH LEARN, V74, P235, DOI 10.1007/s10994-008-5096-0; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; Wheeden R. L., 1977, MEASURE INTEGRAL INT	24	13	14	ELSEVIER INC	SAN DIEGO	525 B STREET, STE 1900, SAN DIEGO, CA 92101-4495 USA	0047-259X		J MULTIVARIATE ANAL	J. Multivar. Anal.	NOV	2010	101	10					2499	2518		10.1016/j.jmva.2010.06.019		20	Statistics & Probability	Mathematics	657DZ	WOS:000282394600018	
J	Costa, ES; Pedreira, CE; Barrena, S; Lecrevisse, Q; Flores, J; Quijano, S; Almeida, J; Garcia-Macias, MD; Bottcher, S; Van Dongen, JJM; Orfao, A				Costa, E. S.; Pedreira, C. E.; Barrena, S.; Lecrevisse, Q.; Flores, J.; Quijano, S.; Almeida, J.; del Carmen Garcia-Macias, M.; Bottcher, S.; Van Dongen, J. J. M.; Orfao, A.		EuroFlow Consortium	Automated pattern-guided principal component analysis vs expert-based immunophenotypic classification of B-cell chronic lymphoproliferative disorders: a step forward in the standardization of clinical immunophenotyping	LEUKEMIA			English	Article						haematological malignancies; flow cytometry; immunophenotyping; FCS data; principal component analysis; B-cell chronic lymphoproliferative disorders	CHRONIC LYMPHOCYTIC-LEUKEMIA; MINIMAL RESIDUAL DISEASE; MULTIPARAMETER FLOW-CYTOMETRY; INTERNATIONAL CONSENSUS RECOMMENDATIONS; ACUTE LYMPHOBLASTIC-LEUKEMIA; HEMATOLYMPHOID NEOPLASIA; DIAGNOSIS; LYMPHOMA; REAGENTS; MULTICENTER	Immunophenotypic characterization of B-cell chronic lymphoproliferative disorders (B-CLPD) is becoming increasingly complex due to usage of progressively larger panels of reagents and a high number of World Health Organization (WHO) entities. Typically, data analysis is performed separately for each stained aliquot of a sample; subsequently, an expert interprets the overall immunophenotypic profile (IP) of neoplastic B-cells and assigns it to specific diagnostic categories. We constructed a principal component analysis (PCA)-based tool to guide immunophenotypic classification of B-CLPD. Three reference groups of immunophenotypic data files-FB-cell chronic lymphocytic leukemias (B-CLL; n = 10), mantle cell (MCL; n = 10) and follicular lymphomas (FL; n = 10)-were built. Subsequently, each of the 175 cases studied was evaluated and assigned to either one of the three reference groups or to none of them (other B-CLPD). Most cases (89%) were correctly assigned to their corresponding WHO diagnostic group with overall positive and negative predictive values of 89 and 96%, respectively. The efficiency of the PCA-based approach was particularly high among typical B-CLL, MCL and FL vs other B-CLPD cases. In summary, PCA-guided immunophenotypic classification of B-CLPD is a promising tool for standardized interpretation of tumor IP, their classification into well-defined entities and comprehensive evaluation of antibody panels. Leukemia (2010) 24, 1927-1933; doi:10.1038/leu.2010.160; published online 16 September 2010	[Costa, E. S.] Univ Fed Rio de Janeiro, Pediat Inst Martagao Gesteira IPPMG, Rio De Janeiro, Brazil; [Pedreira, C. E.] Univ Fed Rio de Janeiro, Fac Med, Rio De Janeiro, Brazil; [Pedreira, C. E.] Univ Fed Rio de Janeiro, COPPE, Engn Grad Program, BR-21945 Rio De Janeiro, Brazil; [Barrena, S.; Lecrevisse, Q.; Flores, J.; Quijano, S.; Almeida, J.; Orfao, A.] Univ Salamanca, CSIC, IBMCC, Cytometry Serv,Dept Med & Canc Res Ctr, E-37008 Salamanca, Spain; [del Carmen Garcia-Macias, M.] Univ Salamanca, Univ Hosp, Dept Pathol, E-37008 Salamanca, Spain; [Bottcher, S.] Univ Schleswig Holstein, Kiel, Germany; [Van Dongen, J. J. M.] Univ Med Ctr Rotterdam, Erasmus MC, Dept Immunol, Rotterdam, Netherlands	Orfao, A (reprint author), CSIC USAL, Dept Med, Ctr Invest Canc, Inst Biol Mol & Celular Canc, Paseo Univ Coimbra S-N,Campus Miguel de Unamuno, Salamanca 37007, Spain.	orfao@usal.es	IBSAL, Secretaria/H-3719-2011		Spanish Network of Cancer Research Centers [ISCIII RTICC-RD06/0020/0035-FEDER]; Fondo de Investigacion Sanitaria [FIS 08/90881]; Ministerio de Ciencia e Innovacion (Madrid, Spain); Ministerio de Educacion y Ciencia, (Madrid, Spain) [PHB 2004-0800-PC]; Consejeria de Educacion [SA016-A-09]; Junta de Castilla y Leon, Valladolid, Spain; CAPES/Ministerio da Educacao (Brasilia, Brazil); EuroFlow Consortium [LSHB-CT-2006-018708]; European Commission; Cancer Research Foundation; University of Salamanca (Salamanca, Spain); CNPq- Brazilian National Research Council, Brasilia, Brazil [305306/2004-9, 558147/2008-9, 478234/2007-4]; FAPERJ-Fundacao de amparo a pesquisa do Rio de Janeiro, (Rio de Janeiro, Brazil) [26/110.301/2007, E-26/102-781/2008]; Jovens Pesquisadores [03/2006]; Fundacion Carolina, Spain; Fundacion Marcelino Botin (Madrid, Spain)	This work has been partially supported by the following Grants: Spanish Network of Cancer Research Centers (ISCIII RTICC-RD06/0020/0035-FEDER), FIS 08/90881 from the 'Fondo de Investigacion Sanitaria', Ministerio de Ciencia e Innovacion (Madrid, Spain), Programa Hispano-Brasileno de Cooperacion Universitaria Ref. PHB 2004-0800-PC (Ministerio de Educacion y Ciencia) (Madrid, Spain), SA016-A-09 from the Consejeria de Educacion, Junta de Castilla y Leon, Valladolid, Spain, and CAPES/Ministerio da Educacao (Brasilia, Brazil), the EuroFlow Consortium (Grant number LSHB-CT-2006-018708), from the European Commission and by the 'Accion Transversal del Cancer' project through an agreement between the Instituto de Salud Carlos III (ISCIII), Ministerio de Ciencia e Innovacion (Madrid, Spain) and the Cancer Research Foundation of the University of Salamanca (Salamanca, Spain). CEP and ESC were partially supported by a grant from CNPq- Brazilian National Research Council, Brasilia, Brazil (Ref: 305306/2004-9, 558147/2008-9 PDP and 478234/2007-4) and FAPERJ-Fundacao de amparo a pesquisa do Rio de Janeiro, (Rio de Janeiro, Brazil) ('Pensa-Rio' project E-26/110.301/2007, E-26/102-781/2008 CNE and 'Jovens Pesquisadores' no 03/2006). CEP and ESC were partially supported by a grant from Fundacion Carolina, Spain. QL was supported by a grant from Fundacion Marcelino Botin (Madrid, Spain).	Ashman M, 2007, CYTOM PART B-CLIN CY, V72B, P380, DOI 10.1002/cyto.b.20178; Baseggio L, 2010, HAEMATOL-HEMATOL J, V95, P604, DOI 10.3324/haematol.2009.011049; Bottcher S, 2009, LEUKEMIA, V23, P2007, DOI 10.1038/leu.2009.140; Braylan RC, 2001, CYTOMETRY, V46, P23, DOI 10.1002/1097-0320(20010215)46:1<23::AID-CYTO1033>3.0.CO;2-Z; Braylan RC, 2004, CYTOM PART A, V58A, P57, DOI 10.1002/cyto.a.10101; Bottcher S, 2008, HAEMATOL-HEMATOL J, V93, P551, DOI 10.3324/haematol.11267; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cro L, 2009, HEMATOL ONCOL, V27, P140, DOI 10.1002/hon.888; Cualing H, 1999, LAB INVEST, V79, P205; DUDA R. O., 2001, PATTERN CLASSIFICATI, P526; Dworzak MN, 2008, CYTOM PART B-CLIN CY, V74B, P331, DOI 10.1002/cyto.b.20430; Gachard N, 2008, HAEMATOL-HEMATOL J, V93, P215, DOI 10.3324/haematol.11622; Goldaniga M, 2008, AM J HEMATOL, V83, P349, DOI 10.1002/ajh.21065; Greig B, 2007, CYTOM PART B-CLIN CY, V72B, pS23, DOI 10.1002/cyto.b.20364; Harris NL, 1999, J CLIN ONCOL, V17, P3835; Jolliffe I. T., 2004, PRINCIPAL COMPONENT; Kaleem Z, 2006, ARCH PATHOL LAB MED, V130, P1850; Macey MG, 1999, CYTOMETRY, V38, P153, DOI 10.1002/(SICI)1097-0320(19990815)38:4<153::AID-CYTO2>3.0.CO;2-E; Mahnke YD, 2007, CLIN LAB MED, V27, P469, DOI 10.1016/j.cII.2007.05.002; Matutes E, 2007, BEST PRACT RES CL HA, V20, P367, DOI 10.1016/j.beha.2007.03.001; Matutes E, 2008, LEUKEMIA, V22, P487, DOI 10.1038/sj.leu.2405068; Matutes E, 2002, J CLIN PATHOL, V55, P180; Morice WG, 2008, MAYO CLIN PROC, V83, P776, DOI 10.4065/83.7.776; Mourad WA, 2003, DIAGN CYTOPATHOL, V28, P191, DOI 10.1002/dc.10268; Nieto WG, 2009, BLOOD, V114, P33, DOI 10.1182/blood-2009-01-197368; Pedreira CE, 2008, CYTOM PART A, V73A, P834, DOI 10.1002/cyto.a.20608; Pedreira CE, 2008, CYTOM PART A, V73A, P1141, DOI 10.1002/cyto.a.20638; Quijano S, 2008, BLOOD, V111, P5130, DOI 10.1182/blood-2007-10-119289; Ratei R, 2009, LEUKEMIA, V23, P528, DOI 10.1038/leu.2008.324; Ratei R, 2007, LEUKEMIA, V21, P1204, DOI 10.1038/sj.leu.2404675; Rawstron AC, 2007, LEUKEMIA, V21, P956, DOI 10.1038/sj.leu.2404584; Rossmann E D, 2001, Hematol J, V2, P300, DOI 10.1038/sj.thj.6200119; Ruiz-Arguelles A, 2006, CYTOM PART B-CLIN CY, V70B, P39, DOI 10.1002/cyto.20083; Sanchez ML, 2002, LEUKEMIA, V16, P1460, DOI 10.1038/sj.leu.2402584; Stetler-Stevenson M, 2007, CLIN FLOW CYTOMETRIC; Wood BL, 2007, CYTOM PART B-CLIN CY, V72B, pS14, DOI 10.1002/cyto.b.20363; WOOD BL, 2005, CURRENT PROTOCOLS CY, P21	37	20	20	NATURE PUBLISHING GROUP	LONDON	MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	0887-6924		LEUKEMIA	Leukemia	NOV	2010	24	11					1927	1933		10.1038/leu.2010.160		7	Oncology; Hematology	Oncology; Hematology	678EV	WOS:000284057400013	
J	Yuan, YL; Shi, XH; Li, XL; Lu, WC; Cai, YD; Gu, L; Liu, LA; Li, MJ; Kong, XY; Xing, M				Yuan, YouLang; Shi, XiaoHe; Li, XinLei; Lu, WenCong; Cai, YuDong; Gu, Lei; Liu, Liang; Li, MinJie; Kong, XiangYin; Xing, Meng			Prediction of interactiveness of proteins and nucleic acids based on feature selections	MOLECULAR DIVERSITY			English	Article						Nucleic acid and protein interaction; Feature selection; Prediction; mRMR; Forward feature wrapper	DNA-BINDING PROTEINS; SUPPORT VECTOR MACHINES; RIBOSOMAL-RNA-BINDING; ADABOOST; CLASSIFICATION; SEQUENCES	It is important to identify which proteins can interact with nucleic acids for the purpose of protein annotation, since interactions between nucleic acids and proteins involve in numerous cellular processes such as replication, transcription, splicing, and DNA repair. This research tries to identify proteins that can interact with DNA, RNA, and rRNA, respectively. mRMR (Minimum redundancy and maximum relevance), with its elegant mathematical formulation, has been applied widely in processing biological data and feature analysis since its introduction in 2005. mRMR plus incremental feature selection (IFS) is known to be very efficient in feature selection and analysis, and able to improve both effectiveness and efficiency of a prediction model. IFS is applied to decide how many features should be selected from feature list provided by mRMR. In the end, the selected features of mRMR and IFS are further refined by a conventional feature selection method-forward feature wrapper (FFW), by reordering the features. Each protein is coded by 132 features including amino acid compositions and physicochemical properties. After the feature selection, k-Nearest Neighbor algorithm, the adopted prediction model, is trained and tested. As a result, the optimized prediction accuracies for the DNA, RNA, and rRNA are 82.0, 83.4, and 92.3%, respectively. Furthermore, the most important features that contribute to the prediction are identified and analyzed biologically. The predictor, developed for this research, is available for public access at http://chemdata.shu.edu.cn/protein_na_mrmr/.	[Yuan, YouLang; Lu, WenCong; Liu, Liang; Li, MinJie] Shanghai Univ, Coll Sci, Dept Chem, Chem Data Min Lab, Shanghai 200444, Peoples R China; [Shi, XiaoHe; Li, XinLei; Kong, XiangYin] Shanghai Jiao Tong Univ, Sch Med, Inst Hlth Sci, Shanghai 200030, Peoples R China; [Shi, XiaoHe; Li, XinLei; Kong, XiangYin] Chinese Acad Sci, Shanghai Inst Biol Sci, Shanghai, Peoples R China; [Cai, YuDong; Xing, Meng] Shanghai Univ, Inst Syst Biol, Shanghai 200444, Peoples R China; [Gu, Lei] Univ Bonn, B IT, Dept Life Sci Informat, D-53113 Bonn, Germany; [Gu, Lei] Fraunhofer Inst Algorithms & Sci Comp SCAI, Dept Bioinformat, D-53754 St Augustin, Germany	Lu, WC (reprint author), Shanghai Univ, Coll Sci, Dept Chem, Chem Data Min Lab, 99 Shang Da Rd, Shanghai 200444, Peoples R China.	wclu@shu.edu.cn; cai_yud@yahoo.com.cn			National Basic Research Program of China [2004CB518603]; Shanghai Commission for Science and Technology [KSCX2-YW-R-112]; Shanghai Leading Academic Discipline Project [J50101]; Excellent Young Teachers Program of Shanghai [B.37-0101-07-716]	This research is supported by the grant of National Basic Research Program of China (2004CB518603), grant from Shanghai Commission for Science and Technology (KSCX2-YW-R-112), grant from Shanghai Leading Academic Discipline Project (J50101), Excellent Young Teachers Program of Shanghai (B.37-0101-07-716).	Ahmad S, 2004, J MOL BIOL, V341, P65, DOI 10.1016/j.jmb.2004.05.058; Bleichert F, 2006, P NATL ACAD SCI USA, V103, P9464, DOI 10.1073/pnas.0603673103; Cai YD, 2008, MOL DIVERS, V12, P131, DOI 10.1007/s11030-008-9085-9; Cai YD, 2009, J PROTEOME RES, V8, P999, DOI 10.1021/pr800717y; Cai YD, 2003, BBA-PROTEINS PROTEOM, V1648, P127, DOI 10.1016/S1570-9639(03)00112-2; Cai YD, 2008, BIOCHEM BIOPH RES CO, V372, P862, DOI 10.1016/j.bbrc.2008.05.143; CHOTHIA C, 1990, ANNU REV BIOCHEM, V59, P1007, DOI 10.1146/annurev.biochem.59.1.1007; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Frishman D, 1997, PROTEINS, V27, P329, DOI 10.1002/(SICI)1097-0134(199703)27:3<329::AID-PROT1>3.0.CO;2-8; Graveley BR, 2004, MOL CELL, V13, P302, DOI 10.1016/S1097-2765(04)00055-3; Hegarat N, 2008, BIOCHIMIE, V90, P1265, DOI 10.1016/j.biochi.2008.03.012; Henikoff S, 1997, SCIENCE, V278, P609, DOI 10.1126/science.278.5338.609; JenJacobson L, 1997, BIOPOLYMERS, V44, P153, DOI 10.1002/(SICI)1097-0282(1997)44:2<153::AID-BIP4>3.0.CO;2-U; Jin YH, 2008, PROTEIN PEPTIDE LETT, V15, P286; Jones S, 2003, NUCLEIC ACIDS RES, V31, P2811, DOI 10.1093/nar/gkg386; Li WJ, 2008, MOL DIVERS, V12, P171, DOI 10.1007/s11030-008-9093-9; Li WZ, 2001, BIOINFORMATICS, V17, P282, DOI 10.1093/bioinformatics/17.3.282; Liu L, 2009, BIOCHEM BIOPH RES CO, V380, P318, DOI 10.1016/j.bbrc.2009.01.077; Lu L, 2010, MOL DIVERS, V14, P81, DOI 10.1007/s11030-009-9149-5; Lu LY, 2010, MOL DIVERS, V14, P815, DOI 10.1007/s11030-009-9177-1; Marcotte EM, 1999, SCIENCE, V285, P751, DOI 10.1126/science.285.5428.751; Moine H, 1997, RNA, V3, P255; Mucchielli-Giorgi MH, 1999, BIOINFORMATICS, V15, P176, DOI 10.1093/bioinformatics/15.2.176; Niu B, 2009, MOL DIVERS, V13, P313, DOI 10.1007/s11030-009-9116-1; Niu B, 2008, MOL DIVERS, V12, P41, DOI 10.1007/s11030-008-9073-0; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226; POWERS T, 1995, RNA, V1, P194; Sanchez-Diaz Patricia, 2006, RNA Biol, V3, P101; Shanahan HP, 2004, NUCLEIC ACIDS RES, V32, P4732, DOI 10.1093/nar/gkh803; Shazman S, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000146; Stawiski EW, 2003, J MOL BIOL, V326, P1065, DOI 10.1016/S0022-2836(03)00031-7; STERN S, 1989, SCIENCE, V244, P783, DOI 10.1126/science.2658053; Szilagyi A, 2006, J MOL BIOL, V358, P922, DOI 10.1016/j.jmb.2006.02.053; Vigneault F, 2005, EXPERT REV PROTEOMIC, V2, P705, DOI 10.1586/14789450.2.5.705; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Woodson SA, 1998, CURR OPIN STRUC BIOL, V8, P294, DOI 10.1016/S0959-440X(98)80061-4; Xu XC, 2008, J PROTEOME RES, V7, P4521, DOI 10.1021/pr800292w; Yu XJ, 2006, J THEOR BIOL, V240, P175, DOI 10.1016/j.jtbi.2005.09.018	39	4	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1381-1991		MOL DIVERS	Mol. Divers.	NOV	2010	14	4					627	633		10.1007/s11030-009-9198-9		7	Biochemistry & Molecular Biology; Chemistry, Applied; Chemistry, Medicinal; Chemistry, Multidisciplinary	Biochemistry & Molecular Biology; Chemistry; Pharmacology & Pharmacy	685BI	WOS:000284598600003	
J	Antiqueira, L; Rodrigues, FA; van Wijk, BCM; Costa, LD; Daffertshofer, A				Antiqueira, Lucas; Rodrigues, Francisco A.; van Wijk, Bernadette C. M.; Costa, Luciano da F.; Daffertshofer, Andreas			Estimating complex cortical networks via surface recordings-A critical note	NEUROIMAGE			English	Article						Graph theory; Sampling; Canonical variable analysis; Encephalography	GRAPH-THEORETICAL ANALYSIS; SMALL-WORLD NETWORKS; HUMAN BRAIN; FUNCTIONAL CONNECTIVITY; SCALE-FREE; ORGANIZATION	We discuss potential caveats when estimating topologies of 3D brain networks from surface recordings. It is virtually impossible to record activity from all single neurons in the brain and one has to rely on techniques that measure average activity at sparsely located (non-invasive) recording sites Effects of this spatial sampling in relation to structural network measures like centrality and assortativity were analyzed using multivariate classifiers A simplified model of 3D brain connectivity incorporating both short- and long-range connections served for testing. To mimic M/EEG recordings we sampled this model via non-overlapping regions and weighted nodes and connections according to their proximity to the recording sites We used various complex network models for reference and tried to classify sampled versions of the "brain-like" network as one of these archetypes It was found that sampled networks may substantially deviate in topology from the respective original networks for small sample sizes For experimental studies this may imply that surface recordings can yield network structures that might not agree with its generating 3D network. (C) 2010 Elsevier Inc All rights reserved	[Antiqueira, Lucas; Costa, Luciano da F.] Univ Sao Paulo, Inst Fis Sao Carlos, Grp Computacao Interdisciplinar, BR-13560970 Sao Carlos, SP, Brazil; [Rodrigues, Francisco A.] Univ Sao Paulo, Inst Ciencias Matemat & Computacao, Dept Matemat Aplicada & Estat, BR-13560970 Sao Carlos, SP, Brazil; [van Wijk, Bernadette C. M.; Daffertshofer, Andreas] Vrije Univ Amsterdam, Res Inst MOVE, NL-1081 BT Amsterdam, Netherlands	Antiqueira, L (reprint author), Univ Sao Paulo, Inst Fis Sao Carlos, Grp Computacao Interdisciplinar, Campus Sao Carlos,Caixa Postal 369, BR-13560970 Sao Carlos, SP, Brazil.		Rodrigues, Francisco Aparecido/E-4418-2011; Antiqueira, Lucas/E-9668-2011; Costa, Luciano/H-5475-2011		FAPESP [05/00587-5, 06/61743-7, 07/50633-9]; CNPq [301303/06-1]; Netherlands Organisation for Scientific Research (NWO) [452-04-344, 021-002-047]	Luciano da F. Costa is grateful to FAPESP (#05/00587-5) and CNPq (#301303/06-1) for financial support Lucas Antiqueira and Francisco A. Rodrigues also thank FAPESP's funding (processes #06/61743-7 and #07/50633-9, respectively). We further thank the Netherlands Organisation for Scientific Research (NWO) for financial support (#452-04-344 awarded to Andreas Daffertshofer, #021-002-047 awarded to Bernadette van Wijk)	Achard S, 2006, J NEUROSCI, V26, P63, DOI 10.1523/JNEUROSCI.3874-05.2006; Antiqueira L, 2009, NEW J PHYS, V11, DOI 10.1088/1367-2630/11/1/013058; Barabasi AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509; Bassettt DS, 2006, P NATL ACAD SCI USA, V103, P19518, DOI 10.1073/pnas.0606005103; Boccaletti S, 2006, PHYS REP, V424, P175, DOI 10.1016/j.physrep.2005.10.009; Bollobas B., 1998, MODERN GRAPH THEORY; Bullmore E, 2009, NAT REV NEUROSCI, V10, P186, DOI 10.1038/nrn2575; Buzsaki G, 2004, TRENDS NEUROSCI, V27, P186, DOI 10.1016/j.tins.2004.02.007; CAMPBELL NA, 1981, SYST ZOOL, V30, P268, DOI 10.2307/2413249; Costa L. da F., 2006, J STAT PHYS, V125, P841; Costa LD, 2007, ADV PHYS, V56, P167, DOI 10.1080/00018730601170527; Costa LD, 2004, PHYS REV LETT, V93, DOI 10.1103/PhysRevLett.93.098702; Costa LD, 2006, EUR PHYS J B, V50, P237, DOI 10.1140/epjb/e2006-00107-0; Costa L. da F., 2001, SHAPE ANAL CLASSIFIC; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dall'Asta L, 2006, THEOR COMPUT SCI, V355, P6, DOI 10.1016/j.tcs.2005.12.009; Duda R. O., 2001, PATTERN CLASSIFICATI; FREEMAN LC, 1977, SOCIOMETRY, V40, P35, DOI 10.2307/3033543; Fukunaga K., 1990, INTRO STAT PATTERN R; Hall M., 2009, SIGKDD EXPLORATIONS, V11, P10, DOI DOI 10.1145/1656274.1656278; Han JDJ, 2005, NAT BIOTECHNOL, V23, P839, DOI 10.1038/nbt1116; He Y, 2007, CEREB CORTEX, V17, P2407, DOI 10.1093/cercor/bhl149; Johnson R.A., 1998, APPL MULTIVARIATE ST; Jolliffe I. T., 2002, PRINCIPAL COMPONENT; Kramer MA, 2009, PHYS REV E, V79, DOI 10.1103/PhysRevE.79.061916; Latora V, 2001, PHYS REV LETT, V87, DOI 10.1103/PhysRevLett.87.198701; Lee SH, 2006, PHYS REV E, V73, DOI 10.1103/PhysRevE.73.016102; Liu Y, 2008, BRAIN, V131, P945, DOI 10.1093/brain/awn018; Martin S, 2006, PHYSICA A, V371, P870, DOI 10.1016/j.physa.2006.04.046; Micheloyannis S, 2006, NEUROSCI LETT, V402, P273, DOI 10.1016/j.neulet.2006.04.006; Newman MEJ, 2002, PHYS REV LETT, V89, DOI 10.1103/PhysRevLett.89.208701; Newman MEJ, 1999, PHYS LETT A, V263, P341, DOI 10.1016/S0375-9601(99)00757-4; Pastor-Satorras R, 2001, PHYS REV LETT, V87, DOI 10.1103/PhysRevLett.87.258701; Ponten SC, 2007, CLIN NEUROPHYSIOL, V118, P918, DOI 10.1016/j.clinph.2006.12.002; Reijneveld JC, 2007, CLIN NEUROPHYSIOL, V118, P2317, DOI 10.1016/j.clinph.2007.08.010; Salvador R, 2005, CEREB CORTEX, V15, P1332, DOI 10.1093/cercor/bhi016; Sporns O, 2004, TRENDS COGN SCI, V8, P418, DOI 10.1016/j.tics.2004.07.008; Stam CJ, 2009, BRAIN, V132, P213, DOI 10.1093/brain/awn262; Stam CJ, 2004, NEUROSCI LETT, V355, P25, DOI 10.1016/j.neulet.2003.10.063; STROGATZ S. H., 1998, NATURE, V393, P6684; Stumpf MPH, 2005, P NATL ACAD SCI USA, V102, P4221, DOI 10.1073/pnas.0501179102; Supekar K, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000100; van den Heuvel MP, 2008, NEUROIMAGE, V43, P528, DOI 10.1016/j.neuroimage.2008.08.010; Zwarts MJ, 2003, MUSCLE NERVE, V28, P1, DOI 10.1002/mus.10358	44	7	7	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1053-8119		NEUROIMAGE	Neuroimage	NOV 1	2010	53	2					439	449		10.1016/j.neuroimage.2010.06.018		11	Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical Imaging	Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging	648JB	WOS:000281688000008	
J	Franco, A; Maltoni, D; Nanni, L				Franco, Annalisa; Maltoni, Davide; Nanni, Loris			Data pre-processing through reward-punishment editing	PATTERN ANALYSIS AND APPLICATIONS			English	Article						Editing; Nearest neighbor classifier	NEAREST NEIGHBOR RULES; NEURAL-NETWORKS; CLASSIFIERS; PREDICTION; SETS	The nearest neighbor (NN) classifier represents one of the most popular non-parametric classification approaches and has been successfully applied in several pattern recognition problems. The two main limitations of this technique are its computational complexity and its sensitivity to the presence of outliers in the training set. Though the first problem has been partially overcome thanks to the availability of inexpensive memory and high processing speeds, the second one still persists, and several editing and condensing techniques have been proposed, aimed at selecting a proper set of prototypes from the training set. In this work, an editing technique is proposed, based on the idea of rewarding the patterns that contribute to a correct classification and punishing those that provide a wrong one. The analysis is carried out both at local and at global level, by analyzing the training set at different scales. A score is calculated for each pattern, and the patterns whose score is lower than a predefined threshold are edited out. An extensive experimentation has been conducted on several classification problems both to evaluate the efficacy of the proposed technique with respect to other editing approaches and to investigate the advantage of using reward-punishment editing in combination with condensing techniques or as a pre-processing stage when classifiers different from the NN are adopted.	[Franco, Annalisa; Maltoni, Davide; Nanni, Loris] Univ Bologna, DEIS, IEIIT, I-40136 Bologna, Italy	Franco, A (reprint author), Univ Bologna, DEIS, IEIIT, Viale Risorgimento 2, I-40136 Bologna, Italy.	annalisa.franco@unibo.it; davide.maltoni@unibo.it; loris.nanni@unibo.it					BARANDELA R, 2000, P JOINT IAPR INT WOR, P621; Bezdek J., 1981, PATTERN RECOGNITION; Blake CL, 1998, UCI REPOSITORY MACHI; CHAVES E, 2001, FAST ALGORITHM ALL K; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 2000, PATTERN ANAL APPL, V3, P19, DOI 10.1007/s100440050003; Demsar J, 2006, J MACH LEARN RES, V7, P1; Duda R.O., 2000, PATTERN CLASSIFICATI; EICK C, 2004, P 4 INT C DAT MIN, P375; FRANCO A, 2004, P INT C PATT REC ICP, V4, P424, DOI 52228242,12,1; Gaede V, 1998, ACM COMPUT SURV, V30, P170, DOI 10.1145/280277.280279; GARCIA V, 2010, PATTERN ANA IN PRESS; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; KOHONEN T, 2001, SELF ORG; KOPLOWITZ J, 1981, PATTERN RECOGN, V13, P251, DOI 10.1016/0031-3203(81)90102-3; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; LI YG, 2005, P ICIT, P950; Mollineda RA, 2002, PATTERN RECOGN, V35, P2771, DOI 10.1016/S0031-3203(01)00208-4; Paredes R., 2000, P 15 INT C PATT REC, V2, P25, DOI 10.1109/ICPR.2000.906011; Paredes R, 2006, PATTERN RECOGN, V39, P180, DOI 10.1016/j.patcog.2005.06.001; PEDREIRA C, 2006, IEEE T PATTERN ANAL, V18, P157; Reinhardt A, 1998, NUCLEIC ACIDS RES, V26, P2230, DOI 10.1093/nar/26.9.2230; Riquelme JC, 2003, PATTERN RECOGN, V36, P1009, DOI 10.1016/S0031-3203(02)00119-X; Rognvaldsson T, 2004, BIOINFORMATICS, V20, P1702, DOI 10.1093/bioinformatics/bth144; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P1179, DOI 10.1016/S0167-8655(97)00112-8; Sanchez JS, 2003, PATTERN RECOGN LETT, V24, P1015, DOI 10.1016/S0167-8655(02)00225-8; Sanchez JS, 2007, PATTERN ANAL APPL, V10, P189, DOI 10.1007/s10044-007-0061-2; Shakhnarovich G., 2006, NEAREST NEIGHBOR MET; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P121; Vapnik V.N., 1998, STAT LEARNING THEORY; Vazquez F, 2005, LECT NOTES COMPUT SC, V3523, P35; Watson C.I., 1992, NIST SPECIAL DATABAS; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Yin XC, 2005, PATTERN RECOGN LETT, V26, P2195, DOI 10.1016/j.patrec.2005.03.029	35	1	1	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1433-7541		PATTERN ANAL APPL	Pattern Anal. Appl.	NOV	2010	13	4					367	381		10.1007/s10044-010-0182-x		15	Computer Science, Artificial Intelligence	Computer Science	668WL	WOS:000283304500001	
J	Qi, X; Pan, YS; Sivak, MV; Willis, JE; Isenberg, G; Rollins, AM				Qi, Xin; Pan, Yinsheng; Sivak, Michael V., Jr.; Willis, Joseph E.; Isenberg, Gerard; Rollins, Andrew M.			Image analysis for classification of dysplasia in Barrett's esophagus using endoscopic optical coherence tomography	BIOMEDICAL OPTICS EXPRESS			English	Article								Barrett's esophagus (BE) and associated adenocarcinoma have emerged as a major health care problem. Endoscopic optical coherence tomography is a microscopic sub-surface imaging technology that has been shown to differentiate tissue layers of the gastrointestinal wall and identify dysplasia in the mucosa, and is proposed as a surveillance tool to aid in management of BE. In this work a computer-aided diagnosis (CAD) system has been demonstrated for classification of dysplasia in Barrett's esophagus using EOCT. The system is composed of four modules: region of interest segmentation, dysplasia-related image feature extraction, feature selection, and site classification and validation. Multiple feature extraction and classification methods were evaluated and the process of developing the CAD system is described in detail. Use of multiple EOCT images to classify a single site was also investigated. A total of 96 EOCT image-biopsy pairs (63 non-dysplastic, 26 low-grade and 7 high-grade dysplastic biopsy sites) from a previously described clinical study were analyzed using the CAD system, yielding an accuracy of 84% for classification of non-dysplastic vs. dysplastic BE tissue. The results motivate continued development of CAD to potentially enable EOCT surveillance of large surface areas of Barrett's mucosa to identify dysplasia. (C) 2010 Optical Society of America	[Qi, Xin; Pan, Yinsheng; Rollins, Andrew M.] Case Western Reserve Univ, Dept Biomed Engn, Cleveland, OH 44106 USA; [Sivak, Michael V., Jr.; Isenberg, Gerard; Rollins, Andrew M.] Case Western Reserve Univ, Dept Med, Cleveland, OH 44106 USA; [Willis, Joseph E.] Case Western Reserve Univ, Dept Pathol, Cleveland, OH 44106 USA	Qi, X (reprint author), Case Western Reserve Univ, Dept Biomed Engn, Cleveland, OH 44106 USA.	Rollins@case.edu			National Institutes of Health [CA94304, CA114276]	The authors acknowledge the contributions of Brian Wolf, and Matthew Ford and the financial support of the National Institutes of Health (CA94304 and CA114276). The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.	Adler DC, 2009, ENDOSCOPY, V41, P773, DOI 10.1055/s-0029-1215045; Bouma BE, 2000, GASTROINTEST ENDOSC, V51, P467, DOI 10.1016/S0016-5107(00)70449-4; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Caudill M., 1992, UNDERSTANDING NEURAL; CHAUDHURI BB, 1993, PATTERN RECOGN LETT, V14, P147, DOI 10.1016/0167-8655(93)90088-U; Chen CM, 2003, RADIOLOGY, V226, P504, DOI 10.1148/radiol.2262011843; Chen WJ, 2004, MED PHYS, V31, P1076, DOI 10.1118/1.1695652; Chen Y, 2007, ENDOSCOPY, V39, P599, DOI 10.1055/s-2007-966648; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Das A, 2000, GASTROINTEST ENDOSC, V51, pAB93; Destounis SV, 2004, RADIOLOGY, V232, P578, DOI 10.1148/radiol.2322030034; DeVault KR, 2000, DIGEST DIS, V18, P195, DOI 10.1159/000051399; Efron B., 1993, INTRO BOOTSTRAP; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Ellis RL, 2007, RADIOLOGY, V245, P88, DOI 10.1148/radiol.2451060760; Evans JA, 2006, CLIN GASTROENTEROL H, V4, P38, DOI 10.1053/S1542-3565(05)00746-9; Falk GW, 1999, GASTROINTEST ENDOSC, V49, P170, DOI 10.1016/S0016-5107(99)70482-7; Fisher N. I., 1993, STAT ANAL CIRCULAR D; Fisher RA, 1936, ANN EUGENIC, V7, P179; Giger ML, 2001, IEEE T MED IMAGING, V20, P1205, DOI 10.1109/TMI.2001.974915; Gilhuijs KGA, 1998, MED PHYS, V25, P1647, DOI 10.1118/1.598345; Gokturk SB, 2001, IEEE T MED IMAGING, V20, P1251, DOI 10.1109/42.974920; Gur D, 2004, J NATL CANCER I, V96, P185, DOI 10.1093/jnci/djh067; Hall FM, 2004, AM J ROENTGENOL, V182, P1598; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; HARWOOD D, 1995, PATTERN RECOGN LETT, V16, P1, DOI 10.1016/0167-8655(94)00061-7; Hastie T, 2001, ELEMENTS STAT LEARNI; Horng MH, 2002, COMPUT MED IMAG GRAP, V26, P33, DOI 10.1016/S0895-6111(01)00029-5; Hornick Jason L, 2007, Gastroenterol Clin North Am, V36, P775, DOI 10.1016/j.gtc.2007.08.004; Horsch K, 2004, ACAD RADIOL, V11, P272, DOI 10.1016/S1076-6332(03)00719-0; Horsch K, 2002, MED PHYS, V29, P157, DOI 10.1118/1.1429239; Huo ZM, 2000, MED PHYS, V27, P4, DOI 10.1118/1.598851; Isenberg G, 2005, GASTROINTEST ENDOSC, V62, P825, DOI 10.1016/j.gie.2005.07.048; Isenberg G. A., 2003, TECH GASTROINTEST EN, V5, P94, DOI 10.1053/tgie.2003.50005; Jackle S, 2000, ENDOSCOPY, V32, P750, DOI 10.1055/s-2000-7705; Jain A. K., 1998, HDB PATTERN RECOGNIT, P207; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; Joo S, 2004, IEEE T MED IMAGING, V23, P1292, DOI 10.1109/TMI.2004.834617; Karlon WJ, 1998, ANAT REC, V252, P612, DOI 10.1002/(SICI)1097-0185(199812)252:4<612::AID-AR12>3.0.CO;2-1; Kohonen T., 1987, SELF ORG ASS MEMORY; Kupinski MA, 1998, IEEE T MED IMAGING, V17, P510, DOI 10.1109/42.730396; Laws K. I., 1980, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V238; Li XD, 2000, ENDOSCOPY, V32, P921, DOI 10.1055/s-2000-9626; Maley Carlo C, 2006, J Natl Compr Canc Netw, V4, P367; Park J, 2001, ARTIF INTELL MED, V23, P277, DOI 10.1016/S0933-3657(01)00086-0; Petrick N, 1996, MED PHYS, V23, P1685, DOI 10.1118/1.597756; Pfau PR, 2003, GASTROINTEST ENDOSC, V58, P196, DOI 10.1067/mge.2003.344; Pitas I., 2000, DIGITAL IMAGE PROCES; Pitris C, 2000, J GASTROENTEROL, V35, P87, DOI 10.1007/s005350050019; Poneros John M, 2004, Gastrointest Endosc Clin N Am, V14, P573, DOI 10.1016/j.giec.2004.03.002; Poneros JM, 2001, GASTROENTEROLOGY, V120, P7, DOI 10.1053/gast.2001.20911; Prasad AM, 2006, ECOSYSTEMS, V9, P181, DOI 10.1007/s10021-005-0054-1; Qi X, 2006, J BIOMED OPT, V11, DOI 10.1117/1.2337314; Qi X, 2004, GASTROENTEROLOGY, V126, pA351; Reunanen J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753715; Ripley B. D., 1996, PATTERN RECOGNITION; Rollins AM, 1998, OPT EXPRESS, V3, P219; Rollins AM, 1999, OPT LETT, V24, P1358, DOI 10.1364/OL.24.001358; Sahiner B, 2007, RADIOLOGY, V242, P716, DOI 10.1148/radiol.2423051464; Sahiner B, 2001, IEEE T MED IMAGING, V20, P1275, DOI 10.1109/42.974922; Sampliner RE, 2002, AM J GASTROENTEROL, V97, P1888; Sayana H, 2007, Minerva Gastroenterol Dietol, V53, P157; SCHMITT JM, 1993, APPL OPTICS, V32, P6032, DOI 10.1364/AO.32.006032; SCHMITT JM, 1994, PHYS MED BIOL, V39, P1705, DOI 10.1088/0031-9155/39/10/013; Sharma P, 2004, GASTROENTEROLOGY, V127, P310, DOI 10.1053/j.gastro.2004.04.010; Sivak MV, 2000, GASTROINTEST ENDOSC, V51, P474, DOI 10.1016/S0016-5107(00)70450-0; Sluimer I, 2006, IEEE T MED IMAGING, V25, P385, DOI 10.1109/TMI.2005.862753; Solaymani-Dodaran M, 2005, AM J GASTROENTEROL, V100, P2616, DOI 10.1111/j.1572-0241.2005.00340.x; Van Uitert Robert L, 2007, IEEE Trans Med Imaging, V26, P1069, DOI 10.1109/TMI.2007.896927; Summers RM, 2002, ABDOM IMAGING, V27, P268, DOI 10.1007/s00261-001-0168-7; Suzuki K, 2005, IEEE T MED IMAGING, V24, P1138, DOI 10.1109/TMI.2005.852048; Taplin SH, 2006, AM J ROENTGENOL, V187, P1475, DOI 10.2214/AJR.05.0940; Timp S, 2007, IEEE T MED IMAGING, V26, P945, DOI [10.1109/TMI.2007.897392, 10.1109/TM1.2007.897392]; Tutuian Radu, 2003, Gastrointest Endosc Clin N Am, V13, P227, DOI 10.1016/S1052-5157(03)00009-6; Vakoc BJ, 2007, GASTROINTEST ENDOSC, V65, P898, DOI 10.1016/j.gie.2006.08.009; van Ginneken B, 2002, IEEE T MED IMAGING, V21, P139, DOI 10.1109/42.993132; Vieth M, 2006, ENDOSCOPY, V38, P1201, DOI 10.1055/s-2006-944993; Vince DG, 2000, COMPUT MED IMAG GRAP, V24, P221, DOI 10.1016/S0895-6111(00)00011-2; Warren Burhenne Linda J., 2000, Radiology, V215, P554; Westphal V, 2005, GASTROINTEST ENDOSC, V61, P537, DOI 10.1016/S0016-5107(05)00084-2; White PM, 2001, RADIOLOGY, V219, P739; Yu L, 2004, J MACH LEARN RES, V5, P1205; Yun SH, 2006, NAT MED, V12, P1429, DOI 10.1038/nm1450; Zuccaro G, 2001, AM J GASTROENTEROL, V96, P2633	87	7	7	OPTICAL SOC AMER	WASHINGTON	2010 MASSACHUSETTS AVE NW, WASHINGTON, DC 20036 USA	2156-7085		BIOMED OPT EXPRESS	Biomed. Opt. Express	OCT 1	2010	1	3					825	847				23	Biochemical Research Methods; Optics; Radiology, Nuclear Medicine & Medical Imaging	Biochemistry & Molecular Biology; Optics; Radiology, Nuclear Medicine & Medical Imaging	V21LM	WOS:000208209100009	
J	Teixeira, LA; de Oliveira, ALI				Teixeira, Lamartine Almeida; Inacio de Oliveira, Adriano Lorena			A method for automatic stock trading combining technical analysis and nearest neighbor classification	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Stock trend prediction; Financial forecasting; Machine learning; Nearest neighbor prediction	NEURAL-NETWORKS; MARKETS; MACHINE	In this paper we propose and analyze a novel method for automatic stock trading which combines technical analysis and the nearest neighbor classification. Our first and foremost objective is to study the feasibility of the practical use of an intelligent prediction system exclusively based on the history of daily stock closing prices and volumes. To this end we propose a technique that consists of a combination of a nearest neighbor classifier and some well known tools of technical analysis, namely, stop loss, stop gain and RSI filter. For assessing the potential use of the proposed method in practice we compared the results obtained to the results that would be obtained by adopting a buy-and-hold strategy. The key performance measure in this comparison was profitability. The proposed method was shown to generate considerable higher profits than buy-and-hold for most of the companies, with few buy operations generated and, consequently, minimizing the risk of market exposure. (C) 2010 Elsevier Ltd. All rights reserved.	[Inacio de Oliveira, Adriano Lorena] Univ Fed Pernambuco, Informat Ctr, Recife, PE, Brazil; [Teixeira, Lamartine Almeida] Univ Fed Pernambuco, Dept Comp Syst, Recife, PE, Brazil	de Oliveira, ALI (reprint author), Univ Fed Pernambuco, Informat Ctr, Recife, PE, Brazil.	lat@dsc.upe.br; alio@cin.ufpe.br					AFOLABI MO, 2007, P 40 HAW INT C SYST, P48; Bao DP, 2008, EXPERT SYST APPL, V34, P620, DOI 10.1016/j.eswa.2006.09.043; Cao LJ, 2003, IEEE T NEURAL NETWOR, V14, P1506, DOI 10.1109/TNN.2003.820556; Chang J, 2007, P 2 INT C INN COMP I, P390; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FAMA EF, 1970, J FINANC, V25, P383, DOI 10.2307/2325486; GUO X, 2007, 3 INT C NAT COMP ICN, P518, DOI 10.1109/ICNC.2007.145; Hassoun M. H., 1995, FUNDAMENTALS ARTIFIC; HAUGEN RA, 1999, NEW FINANCE CASE EFF; Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.121.126; Kim HJ, 2007, APPL SOFT COMPUT, V7, P569, DOI 10.1016/j.asoc.2006.03.004; Kwon YK, 2007, IEEE T NEURAL NETWOR, V18, P851, DOI 10.1109/TNN.2007.891629; Leigh W, 2008, IEEE T SYST MAN CY A, V38, P93, DOI 10.1109/TSMCA.2007.909508; Los CA, 2000, ADV E, V14, P329; MANDZIUK J, 2007, P INT JOINT C NEUR N, P2515; Murphy JJ, 1999, TECHNICAL ANAL FINAN; NAGARAJAN V, 2005, INT C CONTR AUT ICCA, P259; Nanni L, 2006, PATTERN RECOGN LETT, V27, P109, DOI 10.1016/j.patrec.2005.07.008; Saad EW, 1998, IEEE T NEURAL NETWOR, V9, P1456, DOI 10.1109/72.728395; SAI Y, 2007, IEEE INT C GRAN COMP, P659; TAN P, 1994, P 2 SING INT C INT S; TEIXEIRA LA, 2008, P 2008 10 BRAZ S NEU, P33; Vanstone B., 2003, Proceedings of the Eighth Australian and New Zealand Intelligent Information Systems Conference (ANZIIS 2003); White H, 1988, IEEE INT C NEURAL NE, P451; BRAZILIAN MERCANTILE	26	2	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	OCT	2010	37	10					6885	6890		10.1016/j.eswa.2010.03.033		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	619DA	WOS:000279408200018	
J	Giacco, F; Thiel, C; Pugliese, L; Scarpetta, S; Marinaro, M				Giacco, Ferdinando; Thiel, Christian; Pugliese, Luca; Scarpetta, Silvia; Marinaro, Maria			Uncertainty Analysis for the Classification of Multispectral Satellite Images Using SVMs and SOMs	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article						Land-cover maps; remotely sensed images; self-organizing maps (SOMs); soft classification; support vector machines (SVMs); uncertainty	SUPPORT VECTOR MACHINES; LAND-COVER CLASSIFICATION; NEURAL-NETWORK; FEATURES; ASTER; MAPS	Classification of multispectral remotely sensed data with textural features is investigated with a special focus on uncertainty analysis in the produced land-cover maps. Much effort has already been directed into the research of satisfactory accuracy-assessment techniques in image classification, but a common approach is not yet universally adopted. We look at the relationship between hard accuracy and the uncertainty on the produced answers, introducing two measures based on maximum probability and a quadratic entropy. Their impact differs depending on the type of classifier. In this paper, we deal with two different classification strategies, based on support vector machines (SVMs) and Kohonen's self-organizingmaps (SOMs), both suitably modified to give soft answers. Once the multiclass probability answer vector is available for each pixel in the image, we studied the behavior of the overall classification accuracy as a function of the uncertainty associated with each vector, given a hard-labeled test set. The experimental results show that the SVM with one-versus-one architecture and linear kernel clearly outperforms the other supervised approaches in terms of overall accuracy. On the other hand, our analysis reveals that the proposed SOM-based classifier, despite its unsupervised learning procedure, is able to provide soft answers which are the best candidates for a fusion with supervised results.	[Giacco, Ferdinando; Scarpetta, Silvia; Marinaro, Maria] Univ Salerno, Dept Phys, I-84084 Salerno, Italy; [Giacco, Ferdinando; Scarpetta, Silvia] Natl Inst Nucl Phys, Grp Collegato Salerno, Sez Napoli, Salerno, Italy; [Thiel, Christian] Univ Ulm, Inst Neural Informat Proc, D-89069 Ulm, Germany; [Thiel, Christian] Crealyt GmbH, D-94032 Passau, Germany; [Pugliese, Luca; Marinaro, Maria] Int Inst Adv Sci Studies Eduardo R Caianiello, I-84019 Vietri Sul Mare, Italy	Giacco, F (reprint author), Univ Salerno, Dept Phys, I-84084 Salerno, Italy.	giacco@sa.infn.it					Angulo C, 2006, NEURAL PROCESS LETT, V23, P89, DOI 10.1007/s11063-005-3500-3; BALTSAVIAS E, 2001, ISPRS WORKSH HANN GE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dial G, 2003, REMOTE SENS ENVIRON, V88, P23, DOI 10.1016/j.rse.2003.08.014; FAUVEL M, 2007, P IGARSS JUL, P1497; Fauvel M, 2008, IEEE T GEOSCI REMOTE, V46, P3804, DOI 10.1109/TGRS.2008.922034; Fauvel M., 2006, P ICASSP MAY; Foody GM, 2002, REMOTE SENS ENVIRON, V80, P185, DOI 10.1016/S0034-4257(01)00295-4; Foody GM, 2004, IEEE T GEOSCI REMOTE, V42, P1335, DOI 10.1109/TGRS.2004.827257; Foody GM, 2002, INT J REMOTE SENS, V23, P3853, DOI 10.1080/01431160110109570; FRANKLIN SE, 1990, INT J REMOTE SENS, V11, P551; Fujisada H, 1998, IEEE T GEOSCI REMOTE, V36, P1101, DOI 10.1109/36.700994; GIACCO F, 2008, P SPPRA, P151; GIDUDU A, 2007, 28 AS C REM SENS; GONG P, 1992, REMOTE SENS ENVIRON, V40, P137, DOI 10.1016/0034-4257(92)90011-8; GOODCHILD MF, 1992, VISUALIZATION GEOGRA, P158; GUALTIERI J., 2000, P IGARSS HON HI, P813; HALLDORSSON GH, 2003, P IEEE GEOSC REM SEN, V3, P2054; Hastie T, 1998, ANN STAT, V26, P451; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Huang C, 2002, INT J REMOTE SENS, V23, P725, DOI 10.1080/01431160110040323; Ito Y, 1997, INT J REMOTE SENS, V18, P829, DOI 10.1080/014311697218782; Ji CY, 2000, PHOTOGRAMM ENG REM S, V66, P1451; KAHSAY L, 2005, COMP MULTICLASS SVM, P334; LI Z, 2010, INT J REMOT IN PRESS; LIN HT, NOTE PLATTS PROBABIL; MARCEAU DJ, 1990, IEEE T GEOSCI REMOTE, V28, P513, DOI 10.1109/TGRS.1990.572937; Mather P. M., 1999, COMPUTER PROCESSING; Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865; PAL NR, 1994, IEEE T FUZZY SYST, V2, P107, DOI 10.1109/91.277960; Platt J. C., 1999, ADV LARGE MARGIN CLA, P61; Pugliese L, 2005, LECT NOTES COMPUT SC, V3617, P1190; SCHOLKOPF B, 2002, SUPPORT VECTOR MACHI; Shaban MA, 2001, INT J REMOTE SENS, V22, P565, DOI 10.1080/01431160050505865; Shapiro LG, 1992, COMPUTER ROBOT VISIO; Thiel C, 2007, LECT NOTES ARTIF INT, V4694, P156; THIEL C, 2009, P 18 IT WORKSH NEUR, V193, P254; Tso B., 2001, CLASSIFICATION METHO; Vapnik V.N., 1995, NATURE STAT LEARNING; Villmann T, 2003, NEURAL NETWORKS, V16, P389, DOI 10.1016/S0893-6080(03)00021-2; VILLMANN T, 2001, RECENT ADV APPL, P121; Wan WJ, 1999, IEEE T GEOSCI REMOTE, V37, P1344; Webb A., 2002, STAT PATTERN RECOGNI; Wu TF, 2004, J MACH LEARN RES, V5, P975; Xu M, 2005, REMOTE SENS ENVIRON, V97, P322, DOI 10.1016/j.rse.2005.05.008; Yamaguchi Y, 1998, IEEE T GEOSCI REMOTE, V36, P1062, DOI 10.1109/36.700991	46	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0196-2892		IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	OCT	2010	48	10					3769	3779		10.1109/TGRS.2010.2047863		11	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing	Geochemistry & Geophysics; Engineering; Remote Sensing	669KY	WOS:000283349400016	
J	Zhang, S; Jank, W; Shmueli, G				Zhang, Shu; Jank, Wolfgang; Shmueli, Galit			Real-time forecasting of online auctions via functional K-nearest neighbors	INTERNATIONAL JOURNAL OF FORECASTING			English	Article						eBay; Functional forecasting; Functional data; Kullback-Leibler distance; Beta distribution; Dynamics	NONPARAMETRIC REGRESSION; PATTERN-CLASSIFICATION; DISTANCE MEASURES; CONVERGENCE; MODELS	Forecasting prices in online auctions is important for both buyers and sellers. With good forecasts, bidders can make informed bidding decisions and sellers can select the right time and place to list their products. While information from other auctions can help forecast an ongoing auction, it should be weighted by its relevance to the auction of interest. We propose a novel functional K-nearest neighbor (fKNN) forecaster for real-time forecasting of online auctions. The forecaster uses information from other auctions and weights their contributions by their relevance in terms of auction, seller and product features, and by the similarity of the price paths. We capture an auction's price path by borrowing ideas from functional data analysis. We propose a novel Beta growth model, and then measure the distances between two price paths via the Kullback-Leibler distance. Our resulting fKNN forecaster incorporates a mixture of functional and non-functional distances. We apply the forecaster to several large datasets of eBay auctions, showing an improved predictive performance over several competing models. We also investigate the performance across various levels of data heterogeneity, and find that fKNN is particularly effective for forecasting heterogeneous auction populations. (C) 2009 International Institute of Forecasters. Published by Elsevier B.V. All rights reserved.	[Jank, Wolfgang; Shmueli, Galit] Univ Maryland, Robert H Smith Sch Business, College Pk, MD 20742 USA; [Zhang, Shu] Univ Maryland, Appl Math & Sci Computat Program, College Pk, MD 20742 USA	Shmueli, G (reprint author), Univ Maryland, Robert H Smith Sch Business, College Pk, MD 20742 USA.	gshmueli@rhsmith.umd.edu					Abramowitz M. M., 1972, HDB MATH FUNCTIONS F; BASSEVILLE M, 1989, SIGNAL PROCESS, V18, P349, DOI 10.1016/0165-1684(89)90079-0; Becker R. A., 1988, NEW S LANGUAGE; Caccetta L, 2005, MODSIM 2005: INTERNATIONAL CONGRESS ON MODELLING AND SIMULATION: ADVANCES AND APPLICATIONS FOR MANAGEMENT AND DECISION MAKING, P1737; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1981, ANN STAT, V9, P1310, DOI 10.1214/aos/1176345647; GHANI R, 2004, INT WORKSH DAT MIN A; GOLDSTEI.M, 1972, IEEE T INFORM THEORY, V18, P627, DOI 10.1109/TIT.1972.1054888; HYDE V, 2008, STAT METHODS E COMME, P291, DOI 10.1002/9780470315262.ch13; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; JANK W, 2008, AUTOMATED DATA DRIVE; Jank W, 2007, J ROY STAT SOC C-APP, V56, P1, DOI 10.1111/j.1467-9876.2007.00562.x; JANK W, 2009, HDB INFORM SYSTEMS S, P237; Jap SD, 2008, MARKET SCI, V27, P949, DOI 10.1287/mksc.1080.0363; Kulkarni SR, 1998, IEEE T INFORM THEORY, V44, P2178, DOI 10.1109/18.720536; KULKARNI SR, 1995, IEEE T INFORM THEORY, V41, P1028, DOI 10.1109/18.391248; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; LEVINSON N, 1946, J MATH PHYS CAMB, V25, P261; Nalewajski RF, 2000, P NATL ACAD SCI USA, V97, P8879, DOI 10.1073/pnas.97.16.8879; Ramsay JO, 2005, FUNCTIONAL DATA ANAL; Rauber TW, 2008, PATTERN RECOGN, V41, P637, DOI 10.1016/j.patcog.2007.06.023; Shmueli G, 2006, DECIS SUPPORT SYST, V42, P1521, DOI 10.1016/j.dss.2006.01.001; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; Simonoff J. S., 1996, SMOOTHING METHODS ST; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; Wang S, 2008, J BUS ECON STAT, V26, P144, DOI 10.1198/073500106000000477	26	4	4	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-2070		INT J FORECASTING	Int. J. Forecast.	OCT-DEC	2010	26	4					666	683		10.1016/j.ijforecast.2009.08.006		18	Economics; Management	Business & Economics	663QM	WOS:000282902600007	
J	Shen, HB; Chou, KC				Shen, Hong-Bin; Chou, Kuo-Chen			Virus-mPLoc: A Fusion Classifier for Viral Protein Subcellular Location Prediction by Incorporating Multiple Sites	JOURNAL OF BIOMOLECULAR STRUCTURE & DYNAMICS			English	Article						Virus-infected cell; Multiplex protein; PseAAC; Gene ontology; Functional domain; Sequential evolution; OET-KNN; Fusion approach	AMINO-ACID-COMPOSITION; MOLECULAR-DYNAMICS SIMULATIONS; STRUCTURAL CLASS PREDICTION; ENZYME SUBFAMILY CLASSES; IMPROVED HYBRID APPROACH; SUPPORT VECTOR MACHINE; AIDS DRUG DESIGN; APOPTOSIS PROTEINS; GENE ONTOLOGY; V3 LOOP	Knowledge of the subcellular localization of viral proteins in a host cell or virus-infected cell is very important because it is closely related to their destructive tendencies and consequences. Facing the avalanche of new protein sequences discovered in the post genomic era, we are challenged to develop automated methods for quickly and accurately predicting the location sites of viral proteins in a host cell; the information thus acquired is particularly important for medical science and antiviral drug design. In view of this, a new fusion classifier called "Virus-mPLoc" was established by hybridizing the gene ontology information. Functional domain information, and sequential evolutionary information. The new predictor not only can more accurately predict the location sites of viral proteins in a host cell, but also have the capacity to identify the multiple-location virus proteins, which is beyond the reach of any existing predictors specialized for viral proteins. For reader's convenience, a user-friendly web-server for Virus-mPLoc was designed that is freely accessible at http://www.csbio.sjtu.edu.cn/bioinf/virus-multi/.	[Shen, Hong-Bin; Chou, Kuo-Chen] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China; [Shen, Hong-Bin; Chou, Kuo-Chen] Gordon Life Sci Inst, San Diego, CA 92130 USA	Shen, HB (reprint author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.	hbshen@sjtu.edu.cn; kcchou@gordonlifescience.org	Chou, Kuo-Chen/A-8340-2009		National Natural Science Foundation of China [60704047]; Shanghai Science and Technology Commission [08ZR1410600, 08JC1410600]; Shanghai Pujiang Program; Shanghai Municipal Education Commission [10ZZ17]; Shanghai Leading Academic Discipline Project [S30201]	The authors are very much indebted to Professor Dr. Ramaswamy H. Sarma for his valuable suggestion in improving the elucidation why the knowledge of protein subcellular localization is vitally important to drug design. The authors also wish to thank the two anonymous reviewers whose constructive comments are very helpful for strengthening the presentation of this paper. This work was supported by the National Natural Science Foundation of China (Grant No. 60704047), the Shanghai Science and Technology Commission (Grant No. 08ZR1410600, 08JC1410600), sponsored by the Shanghai Pujiang Program, the Innovation Program of Shanghai Municipal Education Commission (10ZZ17) and Shanghai Leading Academic Discipline Project (Grant No. S30201).	Akten ED, 2009, J BIOMOL STRUCT DYN, V27, P13; Andrianov AM, 2009, J BIOMOL STRUCT DYN, V26, P445; Andrianov AM, 2009, J BIOMOL STRUCT DYN, V27, P179; Ashburner M, 2000, NAT GENET, V25, P25; Braun GH, 2008, J BIOMOL STRUCT DYN, V25, P347; Camon E, 2003, GENOME RES, V13, P662, DOI 10.1101/gr.461403; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; Chen C, 2009, PROTEIN PEPTIDE LETT, V16, P27; Chen CY, 2009, J BIOMOL STRUCT DYN, V27, P171; Chen CYC, 2009, J BIOMOL STRUCT DYN, V27, P271; Chen CYC, 2008, J BIOMOL STRUCT DYN, V26, P57; Chen YL, 2007, J THEOR BIOL, V248, P377, DOI 10.1016/j.jtbi.2007.05.019; CHEN YM, 1995, SCIENCE, V270, P789, DOI 10.1126/science.270.5237.789; Chou K. C., 2009, OPEN BIOINFORMATICS, V3, P31; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2008, BIOCHEM BIOPH RES CO, V376, P321, DOI 10.1016/j.bbrc.2008.08.125; Chou KC, 2008, NAT PROTOC, V3, P153, DOI 10.1038/nprot.2007.494; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 2004, CURR MED CHEM, V11, P2105; CHOU KC, 1994, J BIOL CHEM, V269, P22014; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2009, CURR PROTEOMICS, V6, P262; Chou KC, 2007, J PROTEOME RES, V6, P1728, DOI 10.1021/pr060635i; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Ding H, 2009, PROTEIN PEPTIDE LETT, V16, P351; Ding YS, 2008, PATTERN RECOGN LETT, V29, P1887, DOI 10.1016/j.patrec.2008.06.007; Esmaeili M, 2010, J THEOR BIOL, V263, P203, DOI 10.1016/j.jtbi.2009.11.016; Finn RD, 2006, NUCLEIC ACIDS RES, V34, pD247, DOI 10.1093/nar/gkj149; Georgiou DN, 2009, J THEOR BIOL, V257, P17, DOI 10.1016/j.jtbi.2008.11.003; Gerstein M, 2003, CURR OPIN STRUC BIOL, V13, P341, DOI 10.1016/S0959-440X(03)00080-0; Glory E, 2007, DEV CELL, V12, P7, DOI 10.1016/j.devcel.2006.12.007; Hage-Melim LID, 2009, J BIOMOL STRUCT DYN, V27, P27; Jiang XY, 2008, PROTEIN PEPTIDE LETT, V15, P392, DOI 10.2174/092986608784246443; Josa D, 2008, J BIOMOL STRUCT DYN, V25, P373; Kaytor MD, 1999, J BIOL CHEM, V274, P37507, DOI 10.1074/jbc.274.53.37507; Kedarisetti KD, 2006, BIOCHEM BIOPH RES CO, V348, P981, DOI 10.1016/j.bbrc.2006.07.141; Letunic I, 2006, NUCLEIC ACIDS RES, V34, P257; Li FM, 2008, PROTEIN PEPTIDE LETT, V15, P612, DOI 10.2174/092986608784966930; Lin H, 2008, PROTEIN PEPTIDE LETT, V15, P739, DOI 10.2174/092986608785133681; Lin H, 2009, ACTA BIOTHEOR, V57, P321, DOI 10.1007/s10441-008-9067-4; Lin H, 2008, J THEOR BIOL, V252, P350, DOI 10.1016/j.jtbi.2008.02.004; Loewenstein Y, 2009, GENOME BIOL, V10, DOI 10.1186/gb-2009-10-2-207; Marchler-Bauer A., 2007, NUCLEIC ACIDS RES, V35, P237, DOI DOI 10.1093/NAR/GKL951; Matsuda S, 2005, PROTEIN SCI, V14, P2804, DOI 10.1110/ps.051597405; Modrak DE, 2006, MOL CANCER THER, V5, P200, DOI 10.1158/1535-7163.MCT-05-0420; Mohan S, 2009, J BIOMOL STRUCT DYN, V26, P455; NAKAI K, 1991, PROTEINS, V11, P95, DOI 10.1002/prot.340110203; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Tatusov RL, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-41; Qiu JD, 2009, ANAL BIOCHEM, V390, P68, DOI 10.1016/j.ab.2009.04.009; Ramalho TC, 2009, J BIOMOL STRUCT DYN, V27, P195; Schaffer AA, 2001, NUCLEIC ACIDS RES, V29, P2994, DOI 10.1093/nar/29.14.2994; Shafer G., 1976, MATH THEORY EVIDENCE; Shen H. B., 2009, J BIOMED SCI ENG, V2, P136, DOI DOI 10.4236/JBISE.2009.23024; SHEN HB, 2009, R PROTEOME RES QA, V8, P1577; Shen HB, 2005, BIOCHEM BIOPH RES CO, V334, P288, DOI 10.1016/j.bbrc.2005.06.087; Shen HB, 2007, BIOPOLYMERS, V85, P233, DOI 10.1002/bip.20640; Wong JH, 2009, PROTEIN PEPTIDE LETT, V16, P1399; Zeng YH, 2009, J THEOR BIOL, V259, P366, DOI 10.1016/j.jtbi.2009.03.028; Zhang GY, 2008, J THEOR BIOL, V253, P310, DOI 10.1016/j.jtbi.2008.03.015; Zhang JP, 2009, J BIOMOL STRUCT DYN, V27, P159; Zhao JH, 2009, J BIOMOL STRUCT DYN, V26, P481; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou XB, 2007, J THEOR BIOL, V248, P546, DOI 10.1016/j.jtbi.2007.06.001; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565	69	19	20	ADENINE PRESS	SCHENECTADY	2066 CENTRAL AVE, SCHENECTADY, NY 12304 USA	0739-1102		J BIOMOL STRUCT DYN	J. Biomol. Struct. Dyn.	OCT	2010	28	2					175	186				12	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	634GH	WOS:000280567800004	
J	Gao, YL; Gao, F				Gao, Yunlong; Gao, Feng			Edited AdaBoost by weighted kNN	NEUROCOMPUTING			English	Article						AdaBoost; Overfitting; kNN rules; Adaptability; Feature space	NEAREST-NEIGHBOR CLASSIFICATION; MARGIN; ENSEMBLES; VARIANCE; BIAS	Any realistic model of learning from samples must address the issue of noisy data. AdaBoost is known as an effective method for improving the performance of base classifiers both theoretically and empirically. However, previous studies have shown that AdaBoost is prone to overfitting, especially in noisy domains. On the other hand, the kNN rule is one of the oldest and simplest methods for pattern classification. Nevertheless, it often yields competitive results, and in certain domains, when cleverly combined with prior knowledge, it has significantly advanced the state-of-the-art. In this paper, an edited AdaBoost by weighted kNN (EAdaBoost) is designed where AdaBoost and kNN naturally complement each other. First, AdaBoost is run on the training data to capitalize on some statistical regularity in the data. Then, a weighted kNN algorithm is run on the feature space composed of classifiers produced by AdaBoost to achieve competitive results. AdaBoost is then used to enhance the classification accuracy and avoid overfitting by editing the data sets using the weighted kNN algorithm for improving the quality of training data. Experiments performed on ten different UCI data sets show that the new Boosting algorithm almost always achieves considerably better classification accuracy than AdaBoost. Furthermore, experiments on data with artificially controlled noise indicate that the new Boosting algorithm is robust to noise. (C) 2010 Elsevier B.V. All rights reserved.	[Gao, Yunlong; Gao, Feng] Xi An Jiao Tong Univ, Syst Engn Inst, Xian 710049, Peoples R China	Gao, YL (reprint author), Xi An Jiao Tong Univ, Syst Engn Inst, Xian 710049, Peoples R China.	ylgao@sei.xjtu.edu.cn			National Natural Science Foundation of China [60974101]; Foundation of Ministry of Education of China [20060698029]; Program for New Century Excellent Talents in University [NCET-06-0828]	The authors would like to thank the anonymous reviewers for their valuable suggestions that improved this work. This work was partially supported by the National Natural Science Foundation of China (No. 60974101), Ph.D. Programs Foundation of Ministry of Education of China (No. 20060698029) and Program for New Century Excellent Talents in University (No. NCET-06-0828).	Abney S., 1999, P 1999 JOINT SIGDAT, P38; Angelova A, 2005, PROC CVPR IEEE, P494; Bauschke H. H., 1997, J CONVEX ANAL, V4, P27; Bishop C. M., 1995, NEURAL NETWORKS PATT; Blake CL, 1998, UCI REPOSITORY MACHI; Chopra S, 2005, PROC CVPR IEEE, P539; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Domeniconi C, 2005, IEEE T NEURAL NETWOR, V16, P899, DOI 10.1109/TNN.2005.849821; Domingo C., 2000, P 13 ANN C COMP LEAR, P180; Domingos P., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); DRUCKER H, 1994, NEURAL COMPUT, V6, P1289, DOI 10.1162/neco.1994.6.6.1289; Duda R., 1973, PATTERN CLASSIFICATI; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y, 2001, MACH LEARN, V43, P293, DOI 10.1023/A:1010852229904; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Garcia-Laencina PJ, 2009, NEUROCOMPUTING, V72, P1483, DOI 10.1016/j.neucom.2008.11.026; Gil-Pita R, 2007, LECT NOTES COMPUT SC, V4881, P1141; Gomez-Verdejo V, 2006, NEUROCOMPUTING, V69, P679, DOI 10.1016/j.neucom.2005.12.011; Grove A. J., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; JIANG W, 2000, 0003 NW U DEP STAT; JIN R, 2003, P 20 INT C MACH LEAR, P148; Kanamori T, 2007, NEURAL COMPUT, V19, P2183, DOI 10.1162/neco.2007.19.8.2183; Kumar M., 2007, PROMOTING FISCAL DIS, P1; Martinez-Munoz G, 2008, NEUROCOMPUTING, V71, P2521, DOI 10.1016/j.neucom.2007.11.041; Masip D, 2006, PATTERN RECOGN, V39, P164, DOI 10.1016/j.patcog.2005.06.004; Mason L, 2000, MACH LEARN, V38, P243, DOI 10.1023/A:1007697429651; MEIR R, 2003, ADV LECT MACHINE LEA, V2600, P118, DOI 10.1007/3-540-36434-X_4; Merler S, 2004, INT J PATTERN RECOGN, V18, P891, DOI 10.1142/S0218001404003460; Muhlenbach F, 2004, J INTELL INF SYST, V22, P89, DOI 10.1023/A:1025832930864; RATSCH G, 1999, P 1998 C ADV NEUR IN, P564; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; Romero E, 2004, NEUROCOMPUTING, V57, P313, DOI 10.1016/j.neucom.2003.10.011; Schapire RE, 1998, ANN STAT, V26, P1651; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Servedio Rocco A., 2003, J MACHINE LEARNING R, V4, P633; Vezhnevets A., 2007, P 18 EUR C MACH LEAR, P430; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207	39	6	7	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	OCT	2010	73	16-18			SI		3079	3088		10.1016/j.neucom.2010.06.024		10	Computer Science, Artificial Intelligence	Computer Science	809YI	WOS:000294092200029	
J	Samsudin, NA; Bradley, AP				Samsudin, Noor A.; Bradley, Andrew P.			Nearest neighbour group-based classification	PATTERN RECOGNITION			English	Article						Group-based classification; Nearest neighbour; Compound classification	PATTERN-RECOGNITION; RULES	The purpose of group-based classification (GBC) is to determine the class label for a set of test samples, utilising the prior knowledge that the samples belong to same, but unknown class. This can be seen as a simplification of the well studied, but computationally complex, non-sequential compound classification problem. In this paper, we extend three variants of the nearest neighbour algorithm to develop a number of non-parametric group-based classification techniques. The performances of the proposed techniques are then evaluated on both synthetic and real-world data sets and their performance compared with techniques that label test samples individually. The results show that, while no one algorithm clearly outperforms all others on all data sets, the proposed group-based classification techniques have the potential to outperform the individual-based techniques, especially as the (group) size of the test set increases. In addition, it is shown that algorithms that pool information from the whole test set perform better than two-stage approaches that undertake a vote based on the class labels of individual test samples. (C) 2010 Elsevier Ltd. All rights reserved.	[Samsudin, Noor A.; Bradley, Andrew P.] Univ Queensland, Sch Informat Technol & Elect Engn, St Lucia, Qld 4072, Australia	Samsudin, NA (reprint author), Univ Queensland, Sch Informat Technol & Elect Engn, St Lucia, Qld 4072, Australia.	azah@itee.uq.edu.au; bradley@itee.uq.edu.au	Bradley, Andrew/C-5685-2009	Bradley, Andrew/0000-0003-0109-6844			ALPAYDIN E, 2004, ASSESSING COMP CLASS; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Bradley AP, 1996, PATTERN RECOGN LETT, V17, P287, DOI 10.1016/0167-8655(95)00121-2; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NOR; Duda R. O., 2001, PATTERN CLASSIFICATI; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; DYBOWSKI R, 1995, PATTERN RECOGN LETT, V16, P703, DOI 10.1016/0167-8655(95)00016-A; Fisher RA, 1936, ANN EUGENIC, V7, P179; FRANK E, 2003, C UNC ART INT, P249; Fukunaga K., 1990, INTRO STAT PATTERN R; Han J., 2006, DATA MINING CONCEPTS; HAN KK, 1999, TEXT CATEGORIZATION; Indyk P, 1998, 30 ANN ACM S THEOR C, P604, DOI 10.1145/276698.276876; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; JIANG L, 2005, 18 CAN C ART INT, P280; Jiang LX, 2005, Progress in Intelligence Computation & Applications, P344; JIANG L, 2006, 3 INT C FUZZ SYST KN, P365; KLEINBERG JM, 1997, 29 ACM STOC, P599; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; LANDGREBE TCW, 2005, INT WORKSH MULT CLAS; LANGLEY P, 1994, P UNC ART INT M KAUF, P400; Lewis D., 1998, P 10 EUR C MACH LEAR, P4; MACLEOD JES, 1987, IEEE T SYST MAN CYB, V17, P689, DOI 10.1109/TSMC.1987.289362; Marinakis Y, 2008, EXPERT SYST APPL, V35, P1645, DOI 10.1016/j.eswa.2007.08.089; Martinez W. L., 2002, COMPUTATIONAL STAT H; Mitani Y, 2006, PATTERN RECOGN LETT, V27, P1151, DOI 10.1016/j.patrec.2005.12.016; MORIN RL, 1981, IEEE T SYST MAN CYB, V11, P241; NORDIN B, 1994, AUTOMATED CERVICAL C, P44; SAMSUDIN NA, 2008, 19 INT C PATT REC IE; SAMUEL E, 1965, J ROY STAT SOC B, V27, P238; TOUSSAINT GT, 1978, PATTERN RECOGN, V10, P189, DOI 10.1016/0031-3203(78)90027-4; Tsakonas A, 2004, ARTIF INTELL MED, V32, P195, DOI 10.1016/j.artmed.2004.02.007; XIE Z, 2002, 6 PAC AS C KDD, P104	37	4	4	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	OCT	2010	43	10					3458	3467		10.1016/j.patcog.2010.05.010		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	626ZH	WOS:000280006700024	
J	Karacali, B				Karacali, Bilge			Quasi-supervised learning for biomedical data analysis	PATTERN RECOGNITION			English	Article						Biomedical data analysis; Abnormality detection; Nearest neighbor rule; Support vector machines; Flow cytometry; Electroencephalography	NEAREST-NEIGHBOR RULE; STRUCTURAL RISK; ELECTROENCEPHALOGRAPHY; MINIMIZATION; NETWORKS	We present a novel formulation for pattern recognition in biomedical data. We adopt a binary recognition scenario where a control dataset contains samples of one class only, while a mixed dataset contains an unlabeled collection of samples from both classes. The mixed dataset samples that belong to the second class are identified by estimating posterior probabilities of samples for being in the control or the mixed datasets. Experiments on synthetic data established a better detection performance against possible alternatives. The fitness of the method in biomedical data analysis was further demonstrated on real multi-color flow cytometry and multi-channel electroencephalography data. (C) 2010 Elsevier Ltd. All rights reserved.	Izmir Inst Technol Urla, Elect & Elect Engn Dept, TR-35430 Izmir, Turkey	Karacali, B (reprint author), Izmir Inst Technol Urla, Elect & Elect Engn Dept, TR-35430 Izmir, Turkey.	bilgekaracali@iyte.edu.tr					BINNIE CD, 1994, J NEUROL NEUROSUR PS, V57, P1308, DOI 10.1136/jnnp.57.11.1308; CHAPELLE O, 2006, INTRO SEMISUPERVISED; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI; FLANAGAN J, 2005, P INT INT C AD KNOWL, P167; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; GATTEI V, 2004, J CLIN ONCOL, V22, P6567; GOWDA KC, 1979, PATTERN RECOGN, V11, P383; Haykin S, 2008, NEURAL NETWORKS LEAR; Henze N, 1999, ANN STAT, V27, P290; Hero AO, 2002, IEEE SIGNAL PROC MAG, V19, P85, DOI 10.1109/MSP.2002.1028355; Ingber L, 1997, PHYS REV E, V55, P4578, DOI 10.1103/PhysRevE.55.4578; Karacali B, 2003, IEEE T NEURAL NETWOR, V14, P127, DOI 10.1109/TNN.2002.804315; Karacali B., 2007, BMC MED IMAGING, V7; Karacali B, 2004, PATTERN RECOGN LETT, V25, P63, DOI 10.1016/j.patrec.2003.09.002; McLachlan G, 2004, WILEY SERIES PROBABI; Neemuchwala H.F., 2005, MULTISENSOR IMAGE FU, P185; Perfetto SP, 2004, NAT REV IMMUNOL, V4, P648, DOI 10.1038/nri1416; Porjesz B, 2003, ALCOHOL RES HEALTH, V27, P153; Roederer M, 2001, CYTOMETRY, V45, P37, DOI 10.1002/1097-0320(20010901)45:1<37::AID-CYTO1142>3.0.CO;2-E; Sachs K, 2005, SCIENCE, V308, P523, DOI 10.1126/science.1105809; Vapnik V.N., 1998, STAT LEARNING THEORY	23	3	3	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	OCT	2010	43	10					3674	3682		10.1016/j.patcog.2010.04.024		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	626ZH	WOS:000280006700041	
J	Guo, Y; Graber, A; McBurney, RN; Balasubramanian, R				Guo, Yu; Graber, Armin; McBurney, Robert N.; Balasubramanian, Raji			Sample size and statistical power considerations in high-dimensionality data settings: a comparative study of classification algorithms	BMC BIOINFORMATICS			English	Article							DIFFERENTIALLY EXPRESSED GENES; FALSE DISCOVERY RATE; MICROARRAY EXPERIMENTS; DNA MICROARRAY; CANCER; CLASSIFIERS	Background: Data generated using 'omics' technologies are characterized by high dimensionality, where the number of features measured per subject vastly exceeds the number of subjects in the study. In this paper, we consider issues relevant in the design of biomedical studies in which the goal is the discovery of a subset of features and an associated algorithm that can predict a binary outcome, such as disease status. We compare the performance of four commonly used classifiers (K-Nearest Neighbors, Prediction Analysis for Microarrays, Random Forests and Support Vector Machines) in high-dimensionality data settings. We evaluate the effects of varying levels of signal-to-noise ratio in the dataset, imbalance in class distribution and choice of metric for quantifying performance of the classifier. To guide study design, we present a summary of the key characteristics of 'omics' data profiled in several human or animal model experiments utilizing high-content mass spectrometry and multiplexed immunoassay based techniques. Results: The analysis of data from seven 'omics' studies revealed that the average magnitude of effect size observed in human studies was markedly lower when compared to that in animal studies. The data measured in human studies were characterized by higher biological variation and the presence of outliers. The results from simulation studies indicated that the classifier Prediction Analysis for Microarrays (PAM) had the highest power when the class conditional feature distributions were Gaussian and outcome distributions were balanced. Random Forests was optimal when feature distributions were skewed and when class distributions were unbalanced. We provide a free open-source R statistical software library (MVpower) that implements the simulation strategy proposed in this paper. Conclusion: No single classifier had optimal performance under all settings. Simulation studies provide useful guidance for the design of biomedical studies involving high-dimensionality data.	[Balasubramanian, Raji] Univ Massachusetts, Dept Biostat & Epidemiol, Amherst, MA 01003 USA; [Guo, Yu] BG Med Inc, Waltham, MA 02451 USA; [Graber, Armin] Eduard Wallnoefer Zentrum 1, UMIT, Inst Bioinformat & Translat Res, A-6060 Hall In Tirol, Austria; [McBurney, Robert N.] Optimal Med Ltd, Warwick CV35 9EF, England	Balasubramanian, R (reprint author), Univ Massachusetts, Dept Biostat & Epidemiol, 715 N Pleasant St, Amherst, MA 01003 USA.	rbalasub@schoolph.umass.edu					Aliferis CF, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004922; ANDERSON TW, 1952, ANN MATH STAT, V23, P193, DOI 10.1214/aoms/1177729437; Andersson U, 2009, BIOMARKERS, V14, P572, DOI 10.3109/13547500903261354; Bijlsma S, 2006, ANAL CHEM, V78, P567, DOI 10.1021/ac051495j; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davis J, 2006, ICML 06, P233, DOI DOI 10.1145/1143844.1143874; Dobbin K, 2005, BIOSTATISTICS, V6, P27, DOI 10.1093/biostatistics/kxh015; Dobbin KK, 2007, BIOSTATISTICS, V8, P101, DOI 10.1093/biostatistics/kxj036; Ein-Dor L, 2006, P NATL ACAD SCI USA, V103, P5923, DOI 10.1073/pnas.0601231103; Gourin CG, 2009, LARYNGOSCOPE, V119, P1291, DOI 10.1002/lary.20279; Hua J, 2009, PATTERN RECOGN, V42, P15; Hwang DH, 2002, BIOINFORMATICS, V18, P1184, DOI 10.1093/bioinformatics/18.9.1184; Jung SH, 2005, BIOSTATISTICS, V6, P157, DOI 10.1093/bostatistics/kxh026; LANDGREBE TCW, 2006, P 18 INT C PATT REC, P123; Lee MLT, 2002, STAT MED, V21, P3543, DOI 10.1002/sim.1335; Li SYS, 2005, STAT MED, V24, P2267, DOI 10.1002/sim.2119; LIU Y, 2007, IEEE INT C AC SPEECH, P185; McBurney RN, 2009, TOXICOL PATHOL, V37, P52, DOI 10.1177/0192623308329287; Mills KI, 2009, BLOOD, V114, P1063, DOI 10.1182/blood-2008-10-187203; Muller P, 2004, J AM STAT ASSOC, V99, P990, DOI 10.1198/016214504000001646; ORICHARD DPF, 2001, PATTERN CLASSIFICATI; Pawitan Y, 2005, BIOINFORMATICS, V21, P3017, DOI 10.1093/bioinformatics/bti448; Pounds S, 2005, BIOINFORMATICS, V21, P4263, DOI 10.1093/bioinformatics/bti699; Storey JD, 2002, J ROY STAT SOC B, V64, P479, DOI 10.1111/1467-9868.00346; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Tsai CA, 2005, BIOINFORMATICS, V21, P1502, DOI 10.1093/bioinformatics/bti162; Wang SJ, 2004, J COMPUT BIOL, V11, P714, DOI 10.1089/1066527041887267; Wei CM, 2004, BMC GENOMICS, V5, DOI 10.1186/1471-2164-5-87; [Anonymous], R PROJ STAT COMP; *TNO, TNO QUAL LIF	32	3	4	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	SEP 3	2010	11								447	10.1186/1471-2105-11-447		19	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	660PM	WOS:000282655600002	
J	Shen, CH; Kim, J; Wang, L				Shen, Chunhua; Kim, Junae; Wang, Lei			Scalable Large-Margin Mahalanobis Distance Metric Learning	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						Distance metric learning; large-margin nearest neighbor; Mahalanobis distance; semidefinite optimization	MATRIX	For many machine learning algorithms such as k-nearest neighbor (k-NN) classifiers and k-means clustering, often their success heavily depends on the metric used to calculate distances between different data points. An effective solution for defining such a metric is to learn it from a set of labeled training samples. In this work, we propose a fast and scalable algorithm to learn a Mahalanobis distance metric. The Mahalanobis metric can be viewed as the Euclidean distance metric on the input data that have been linearly transformed. By employing the principle of margin maximization to achieve better generalization performances, this algorithm formulates the metric learning as a convex optimization problem and a positive semidefinite (p.s.d.) matrix is the unknown variable. Based on an important theorem that a p.s.d. trace-one matrix can always be represented as a convex combination of multiple rank-one matrices, our algorithm accommodates any differentiable loss function and solves the resulting optimization problem using a specialized gradient descent procedure. During the course of optimization, the proposed algorithm maintains the positive semidefiniteness of the matrix variable that is essential for a Mahalanobis metric. Compared with conventional methods like standard interior-point algorithms [2] or the special solver used in large margin nearest neighbor [24], our algorithm is much more efficient and has a better performance in scalability. Experiments on benchmark data sets suggest that, compared with state-of-the-art metric learning algorithms, our algorithm can achieve a comparable classification accuracy with reduced computational complexity.	[Shen, Chunhua] NICTA, Canberra Res Lab, Canberra, ACT 2601, Australia; [Shen, Chunhua; Kim, Junae; Wang, Lei] Australian Natl Univ, Canberra, ACT 0200, Australia	Shen, CH (reprint author), NICTA, Canberra Res Lab, Canberra, ACT 2601, Australia.	chunhua.shen@nicta.com.au; junae.kim@anu.edu.au; lei.wang@anu.edu.au			Australian Government	This work was supported in part by the National ICT Australia, funded by the Australian Government as represented by the Department of Broadband, Communications and the Digital Economy, and the Australian Research Council through the Information and Communications Technology Center of Excellence program.	Borchers B, 1999, OPTIM METHOD SOFTW, V11-2, P613, DOI 10.1080/10556789908805765; Boyd S., 2004, CONVEX OPTIMIZATION; Chang C.C., 2001, LIBSVM LIB SUPPORT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davis J. V., 2007, P 24 INT C MACH LEAR, P209, DOI DOI 10.1145/1273496.127352; Fei-Fei L., 2004, P IEEE CVPR WORKSH G, P178; Goldberger J., 2005, ADV NEURAL INFORM PR, V17, P513; Granas A, 2007, J FIX POINT THEORY A, V1, P1, DOI 10.1007/s11784-006-0010-5; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; KIM J, 2009, LNCS, V5996, P299; Kulis B, 2009, J MACH LEARN RES, V10, P341; Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27; Lehoucq R. B., 1998, ARPACK USERS GUIDE S; Lowe D, 1999, P INT C COMP VIS, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Newman D. J., 1998, UCI REPOSITORY MACHI; Nocedal J, 1999, NUMERICAL OPTIMIZATI; Rosales R., 2006, P ACM SIGKDD INT C K, P367, DOI 10.1145/1150402.1150444; Shen C., 2008, P ADV NEUR INF PROC, P1473; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766; Tutuncu RH, 2003, MATH PROGRAM, V95, P189, DOI 10.1007/s10107-002-0347-5; Vapnik V.N., 1998, STAT LEARNING THEORY; Weinberger K., 2006, P NIPS, P1475; Winn J., 2005, ICCV, V2, P1800; Xing EP, 2003, P NIPS, P505; Yang L, 2010, IEEE T PATTERN ANAL, V32, P30, DOI 10.1109/TPAMI.2008.273	27	8	8	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	SEP	2010	21	9					1524	1530		10.1109/TNN.2010.2052630		7	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	667XT	WOS:000283231200014	
J	Sarac, OS; Atalay, V; Cetin-Atalay, R				Sarac, Oemer Sinan; Atalay, Volkan; Cetin-Atalay, Rengul			GOPred: GO Molecular Function Prediction by Combined Classifiers	PLOS ONE			English	Article							PROTEIN FUNCTION; NEURAL-NETWORKS; CLASSIFICATION; SEQUENCE; ANNOTATION; SUPPORT; DISCOVERY; SOFTWARE; FEATURES; GENOMES	Functional protein annotation is an important matter for in vivo and in silico biology. Several computational methods have been proposed that make use of a wide range of features such as motifs, domains, homology, structure and physicochemical properties. There is no single method that performs best in all functional classification problems because information obtained using any of these features depends on the function to be assigned to the protein. In this study, we portray a novel approach that combines different methods to better represent protein function. First, we formulated the function annotation problem as a classification problem defined on 300 different Gene Ontology (GO) terms from molecular function aspect. We presented a method to form positive and negative training examples while taking into account the directed acyclic graph (DAG) structure and evidence codes of GO. We applied three different methods and their combinations. Results show that combining different methods improves prediction accuracy in most cases. The proposed method, GOPred, is available as an online computational annotation tool (http://kinaz.fen.bilkent.edu.tr/gopred).	[Sarac, Oemer Sinan; Atalay, Volkan] Middle E Tech Univ, Dept Comp Engn, TR-06531 Ankara, Turkey; [Cetin-Atalay, Rengul] Bilkent Univ, Dept Mol Biol & Genet, Fac Sci, Ankara, Turkey	Sarac, OS (reprint author), Tech Univ Dresden, Ctr Biotechnol, Dresden, Germany.	rengul@bilkent.edu.tr	Atalay, Rengul/F-5780-2013		Scientific and Technological Research Council of Turkey (TUBITAK-EEAG) [105E035]	This study was supported by The Scientific and Technological Research Council of Turkey (TUBITAK-EEAG) (105E035). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.	ALTAY C, 1970, BLOOD-J HEMATOL, V36, P219; ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; ARAMPATZIS A, 2001, P 10 TEXT RETR C TRE, P596; Bairoch A, 2005, NUCLEIC ACIDS RES, V33, P154; BENHUR A, 2003, ISMB S, V26, P33; Blekas K, 2005, J COMPUT BIOL, V12, P64, DOI 10.1089/cmb.2005.12.64; Bodemann BO, 2008, NAT REV CANCER, V8, P133, DOI 10.1038/nrc2296; Cai CZ, 2003, NUCLEIC ACIDS RES, V31, P3692, DOI 10.1093/nar/gkg600; Cheng BYM, 2005, PROTEINS, V58, P955, DOI 10.1002/prot.20373; Cho YJ, 2008, P NATL ACAD SCI USA, V105, P5396, DOI 10.1073/pnas.0705410105; COLBY WW, 1986, MOL CELL BIOL, V6, P730; Costa V, 2009, BMC GENOMICS, V10, DOI 10.1186/1471-2164-10-250; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEMOS D, 2000, PROTEINS, V41, P98; Duda R.O., 2000, PATTERN CLASSIFICATI; EISNER R, 2005, P IEEE S COMP INT BI; ENGELHARDT BE, 2005, PLOS COMPUT BIOL, V1, P45; Fernandes AP, 2004, ANTIOXID REDOX SIGN, V6, P63, DOI 10.1089/152308604771978354; Friedberg I, 2006, BRIEF BIOINFORM, V7, P225, DOI 10.1093/bib/bbl004; Gilks WR, 2005, MATH BIOSCI, V193, P223, DOI 10.1016/j.mbs.2004.08.001; Guermeur Y, 2004, NEUROCOMPUTING, V56, P305, DOI 10.1016/j.neucom.2003.10.004; Hannenhalli SS, 2000, J MOL BIOL, V303, P61, DOI 10.1006/jmbi.2000.4036; Hasumi H, 2008, GENE, V415, P60, DOI 10.1016/j.gene.2008.02.022; Hawkins T, 2006, PROTEIN SCI, V15, P1550, DOI 10.1110/ps.062153506; Holloway DT, 2006, IBM J RES DEV, V50, P631; Jensen LJ, 2002, J MOL BIOL, V319, P1257, DOI 10.1016/S0022-2836(02)00379-0; Karchin R, 2002, BIOINFORMATICS, V18, P147, DOI 10.1093/bioinformatics/18.1.147; King RD, 2000, YEAST, V17, P283, DOI 10.1002/1097-0061(200012)17:4<283::AID-YEA52>3.0.CO;2-F; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; KUNIK V, 2005, COMPUTATIONAL SYSTEM, P80; Leslie CS, 2004, BIOINFORMATICS, V20, P467, DOI 10.1093/bioinformatics/btg431; Liu AH, 2001, IBM SYST J, V40, P379; Martin DMA, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-178; McChesney PA, 2006, CANCER RES, V66, P1346, DOI 10.1158/0008-5472.CANT-05-3593; Melvin I, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-389; Pasquier C, 2001, PROTEINS, V44, P361, DOI 10.1002/prot.1101; Rice P, 2000, TRENDS GENET, V16, P276, DOI 10.1016/S0168-9525(00)02024-2; Sarac OS, 2008, COMPUT BIOL CHEM, V32, P122, DOI 10.1016/j.compbiolchem.2007.11.004; Sasson O, 2006, PROTEIN SCI, V15, P1557, DOI 10.1110/ps.062185706; Schwanbeck R, 2008, CELLS TISSUES ORGANS, V188, P91, DOI 10.1159/000113531; Shanahan James G., 2003, CIKM ACM, P247; Sohn SY, 2007, PATTERN RECOGN, V40, P33, DOI 10.1016/j.patcog.2006.06.027; SOKOLOV A, 2008, P 2 INT WORKSH MACH, P49; Tanaka S, 2004, J BIOL CHEM, V279, P14256, DOI 10.1074/jbc.M313755200; VOGELSTEIN B, 1992, CELL, V70, P523, DOI 10.1016/0092-8674(92)90421-8; Wang JTL, 2001, IBM SYST J, V40, P426; Wang XY, 2003, INFORM SCIENCES, V155, P1, DOI 10.1016/S0020-0255(03)00067-7; Wass MN, 2008, BIOINFORMATICS, V24, P798, DOI 10.1093/bioinformatics/btn037; WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968; Yildiz A, 2005, TRENDS CELL BIOL, V15, P112, DOI 10.1016/j.tcb.2004.12.007; ZHAI C, 1998, P TREC 7, P96	52	4	4	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	185 BERRY ST, STE 1300, SAN FRANCISCO, CA 94107 USA	1932-6203		PLOS ONE	PLoS One	AUG 31	2010	5	8							e12382	10.1371/journal.pone.0012382		11	Multidisciplinary Sciences	Science & Technology - Other Topics	644TX	WOS:000281405300006	
J	Olvera-Lopez, JA; Carrasco-Ochoa, JA; Martinez-Trinidad, JF; Kittler, J				Arturo Olvera-Lopez, J.; Ariel Carrasco-Ochoa, J.; Francisco Martinez-Trinidad, J.; Kittler, Josef			A review of instance selection methods	ARTIFICIAL INTELLIGENCE REVIEW			English	Article						Instance selection; Supervised learning; Data reduction; Pre-processing	NEAREST-NEIGHBOR RULE; EVOLUTIONARY PROTOTYPE SELECTION; LEARNING ALGORITHMS; GENETIC ALGORITHMS; SEQUENTIAL SEARCH; OBJECT SELECTION; TABU SEARCH; CLASSIFICATION; REDUCTION; SUBSET	In supervised learning, a training set providing previously known information is used to classify new instances. Commonly, several instances are stored in the training set but some of them are not useful for classifying therefore it is possible to get acceptable classification rates ignoring non useful cases; this process is known as instance selection. Through instance selection the training set is reduced which allows reducing runtimes in the classification and/or training stages of classifiers. This work is focused on presenting a survey of the main instance selection methods reported in the literature.	[Arturo Olvera-Lopez, J.] Benemerita Univ Autonoma Puebla, Fac Ciencias Comp, Puebla 72570, Mexico; [Ariel Carrasco-Ochoa, J.; Francisco Martinez-Trinidad, J.] Natl Inst Astrophys Opt & Elect, Dept Comp Sci, Puebla 72000, Mexico; [Kittler, Josef] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England	Olvera-Lopez, JA (reprint author), Benemerita Univ Autonoma Puebla, Fac Ciencias Comp, Av San Claudio & 14 Sur,Ciudad Univ, Puebla 72570, Mexico.	aolvera@cs.buap.mx; ariel@ccc.inaoep.mx; fmartine@ccc.inaoep.mx; j.kittler@surrey.ac.uk					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Bezdek JC, 2001, INT J INTELL SYST, V16, P1445, DOI 10.1002/int.1068; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Caises Y, 2009, LECT NOTES COMPUT SC, V5788, P17; Cano JR, 2005, PATTERN RECOGN LETT, V26, P953, DOI 10.1016/j.patrec.2004.09.043; Cano JR, 2003, IEEE T EVOLUT COMPUT, V7, P561, DOI 10.1109/TEVC.2003.819265; Cerveron V, 2001, IEEE T SYST MAN CY B, V31, P408, DOI 10.1109/3477.931531; Chien C., 2006, P 18 INT C PATT REC, P556; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; de Haro-Garcia A, 2009, DATA MIN KNOWL DISC, V18, P392, DOI 10.1007/s10618-008-0121-2; Devijver P. A., 1980, Proceedings of the 5th International Conference on Pattern Recognition; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; Garain U, 2008, PATTERN ANAL APPL, V11, P353, DOI 10.1007/s10044-008-0106-1; Garcia S, 2008, PATTERN RECOGN, V41, P2693, DOI 10.1016/j.patcog.2008.02.006; GLOVER F, 1986, COMPUT OPER RES, V13, P563, DOI 10.1016/0305-0548(86)90050-X; GROCHOWSKI M, 2004, LNAI, P580; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KEPING Z, 2003, P 2 IEEE INT C MACH, V1, P94; KITTLER J, 1986, HDB PATTERN RECOGNIT, P203; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; Kuncheva LI, 1997, PATTERN RECOGN, V30, P1041, DOI 10.1016/S0031-3203(96)00134-3; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; Liu H, 2002, DATA MIN KNOWL DISC, V6, P115, DOI 10.1023/A:1014056429969; Lumini A, 2006, PATTERN RECOGN, V39, P495, DOI 10.1016/j.patcog.2005.11.004; Mollineda RA, 2002, PATTERN RECOGN, V35, P2771, DOI 10.1016/S0031-3203(01)00208-4; Narayan BL, 2006, PATTERN RECOGN LETT, V27, P187, DOI 10.1016/j.patrec.2005.08.015; Olvera-Lopez JA, 2009, INTELL DATA ANAL, V13, P599, DOI 10.3233/IDA-2009-0383; Olvera-Lopez JA, 2005, LECT NOTES COMPUT SC, V3578, P280; Olvera-Lopez JA, 2007, LECT NOTES ARTIF INT, V4571, P694; Olvera-Lopez JA, 2007, ADV INTEL SOFT COMPU, V45, P27; Olvera-Lopez JA, 2008, LECT NOTES COMPUT SC, V5197, P153, DOI 10.1007/978-3-540-85920-8_19; Paredes R., 2000, P 15 INT C PATT REC, V2, P25, DOI 10.1109/ICPR.2000.906011; PUDIL P, 1994, INT C PATT RECOG, P279, DOI 10.1109/ICPR.1994.576920; Raicharoen T, 2005, PATTERN RECOGN LETT, V26, P1554, DOI 10.1016/j.patrec.2005.01.003; Riquelme JC, 2003, PATTERN RECOGN, V36, P1009, DOI 10.1016/S0031-3203(02)00119-X; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Spillmann B, 2006, LECT NOTES COMPUT SC, V4109, P287; Srisawat A, 2006, LECT NOTES ARTIF INT, V4099, P975; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; Vapnik V.N., 1995, NATURE STAT LEARNING; Vazquez F, 2005, LECT NOTES COMPUT SC, V3523, P35; VENMANN CJ, 2005, IEEE T PATTERN ANAL, V27, P1417; VENMANN CJ, 2002, IEEE T PATTERN ANAL, V24, P1273; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; YUANGUI L, 2005, LNCS, V3610, P528; Zhang HB, 2002, PATTERN RECOGN, V35, P1481, DOI 10.1016/S0031-3203(01)00137-6	48	8	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0269-2821		ARTIF INTELL REV	Artif. Intell. Rev.	AUG	2010	34	2					133	143		10.1007/s10462-010-9165-y		11	Computer Science, Artificial Intelligence	Computer Science	619TP	WOS:000279453500003	
J	Li, H; Sun, J; Wu, J				Li, Hui; Sun, Jie; Wu, Jian			Predicting business failure using classification and regression tree: An empirical comparison with popular classical statistical methods and top classification mining methods	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Business failure prediction (BFP); Data mining; Classification and regression tree (CART)	SUPPORT VECTOR MACHINES; FINANCIAL DISTRESS PREDICTION; BANKRUPTCY PREDICTION; NEURAL-NETWORK; CANCER CLASSIFICATION; DISCRIMINANT-ANALYSIS; MODEL; ENSEMBLE; RATIOS; CLASSIFIERS	Predicting business failure is a very critical task for government officials, stock holders, managers, employees, investors and researchers, especially in nowadays competitive economic environment. Several top 10 data mining methods have become very popular alternatives in business failure prediction (BFP), e.g., support vector machine and k nearest neighbor. In comparison with the other classification mining methods, advantages of classification and regression tree (CART) methods include: simplicity of results, easy implementation, nonlinear estimation, being non-parametric, accuracy and stable. However, there are seldom researches in the area of BFP that witness the applicability of CART, another method among the top 10 algorithms in data mining. The aim of this research is to explore the performance of BFP using the commonly discussed data mining technique of CART. To demonstrate the effectiveness of BFP using CART, business failure predicting tasks were performed on the data set collected from companies listed in the Shanghai Stock Exchange and Shenzhen Stock Exchange. Thirty times' hold-out method was employed as the assessment, and the two commonly used methods in the top 10 data mining algorithms, i.e., support vector machine and k nearest neighbor, and the two baseline benchmark methods from statistic area, i.e., multiple discriminant analysis (MDA) and logistics regression, were employed as comparative methods. For comparative methods, stepwise method of MDA was employed to select optimal feature subset. Empirical results indicated that the optimal algorithm of CART outperforms all the comparative methods in terms of predictive performance and significance test in short-term BFP of Chinese listed companies. (C) 2010 Elsevier Ltd. All rights reserved.	[Li, Hui; Sun, Jie; Wu, Jian] Zhejiang Normal Univ, Sch Business Adm, Jinhua City 321004, Zhejiang, Peoples R China	Li, H (reprint author), Zhejiang Normal Univ, Sch Business Adm, 91 Subbox POB 62,YingBinDaDao 688, Jinhua City 321004, Zhejiang, Peoples R China.	lihuihit@gmail.com; sunjiehit@gmail.com	Li, Hui/G-6408-2011		National Natural Science Foundation of China [70801055]; Zhejiang Provincial Natural Science Foundation of China [Y6090392]	This research is partially supported by the National Natural Science Foundation of China (No. 70801055) and the Zhejiang Provincial Natural Science Foundation of China (No. Y6090392). The authors gratefully thank editors and anonymous referees for their comments and recommendations.	Altman E., 1998, J BANK FINANC, V21, P1721; ALTMAN EI, 1968, J FINANC, V23, P589, DOI 10.2307/2978933; Altman E.I., 1997, FINANCIAL MARKETS I, V6, P1, DOI 10.1111/1468-0416.00010; Balcaen S., 2006, BRIT ACCOUNTING REV, V38, P63, DOI 10.1016/j.bar.2005.09.001; BEAVER WH, 1966, J ACCOUNTING RES, V4, P71, DOI 10.2307/2490171; Breiman L, 1984, CLASSIFICATION REGRE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAVID AB, 2008, EXPERT SYSTEMS APPL, V34, P2783; Dimitras AI, 1996, EUR J OPER RES, V90, P487, DOI 10.1016/0377-2217(95)00070-4; Ding YS, 2008, EXPERT SYST APPL, V34, P3081, DOI 10.1016/j.eswa.2007.06.037; DOUMPOS M, 1999, MULTINATIONAL FINANC, V3, P71; Elhadi MT, 2000, EXPERT SYST APPL, V18, P215, DOI 10.1016/S0957-4174(99)00063-9; Etemadi H, 2009, EXPERT SYST APPL, V36, P3199, DOI 10.1016/j.eswa.2008.01.012; Hong JH, 2008, NEUROCOMPUTING, V71, P3275, DOI 10.1016/j.neucom.2008.04.033; Hua ZS, 2007, EXPERT SYST APPL, V33, P434, DOI 10.1016/j.eswa.2006.05.006; Huang SM, 2008, EXPERT SYST APPL, V35, P1034, DOI 10.1016/j.eswa.2007.08.040; Huang WL, 2007, BIOSYSTEMS, V90, P405, DOI 10.1016/j.biosystems.2006.10.004; Hui XF, 2006, LECT NOTES ARTIF INT, V3885, P274; Hung C, 2009, EXPERT SYST APPL, V36, P5297, DOI 10.1016/j.eswa.2008.06.068; Jo HK, 1997, EXPERT SYST APPL, V13, P97, DOI 10.1016/S0957-4174(97)00011-0; Jones S., 2007, BRIT ACCOUNTING REV, V39, P89, DOI 10.1016/j.bar.2006.12.003; Koh H., 1992, J BUSINESS FINANCE A, V19, P187, DOI 10.1111/j.1468-5957.1992.tb00618.x; Kuncheva L., 2004, COMBINING PATTERN CL; Lee G., 1999, J MANAGE INFORM SYST, V16, P63; Lee TS, 2006, COMPUT STAT DATA AN, V50, P1113, DOI 10.1016/j.csda.2004.11.006; Li B, 2008, COMPUT STAT DATA AN, V52, P4790, DOI 10.1016/j.csda.2008.03.024; LI H, 2008, KNOWLEDGE BASED SYST, V21; Lin FY, 2001, KNOWL-BASED SYST, V14, P189, DOI 10.1016/S0950-7051(01)00096-X; Lin RH, 2009, EXPERT SYST APPL, V36, P1593, DOI 10.1016/j.eswa.2007.11.068; Martens D, 2007, EUR J OPER RES, V183, P1466, DOI 10.1016/j.ejor.2006.04.051; Martin D., 1977, J BANK FINANC, V1, P249, DOI DOI 10.1016/0378-4266(77)90022-X; McLeay S., 2000, BRIT ACCOUNTING REV, V32, P213, DOI 10.1006/bare.1999.0120; Min JH, 2009, EXPERT SYST APPL, V36, P5256, DOI 10.1016/j.eswa.2008.06.073; Min JH, 2008, EXPERT SYST APPL, V35, P1762, DOI 10.1016/j.eswa.2007.08.070; Min JH, 2005, EXPERT SYST APPL, V28, P603, DOI 10.1016/j.eswa.2004.12.008; Min SH, 2006, EXPERT SYST APPL, V31, P652, DOI 10.1016/j.eswa.2005.09.070; Nanni L, 2009, EXPERT SYST APPL, V36, P3028, DOI 10.1016/j.eswa.2008.01.018; OHLSON JA, 1980, J ACCOUNTING RES, V18, P109, DOI 10.2307/2490395; Okun O, 2009, ARTIF INTELL MED, V45, P151, DOI 10.1016/j.artmed.2008.08.004; Park CS, 2002, EXPERT SYST APPL, V23, P255, DOI 10.1016/S0957-4174(02)00045-3; Polat K, 2007, EXPERT SYST APPL, V32, P625, DOI 10.1016/j.eswa.2006.01.027; Ravi V, 2008, APPL SOFT COMPUT, V8, P1539, DOI 10.1016/j.asoc.2007.12.003; Sarkar S, 2001, MANAGE SCI, V47, P1457, DOI 10.1287/mnsc.47.11.1457.10253; Shin KS, 2005, EXPERT SYST APPL, V28, P127, DOI 10.1016/j.eswa.2004.08.009; Sun J, 2008, EXPERT SYST APPL, V35, P818, DOI 10.1016/j.eswa.2007.07.045; Sun J, 2006, LECT NOTES ARTIF INT, V4093, P947; Sun J, 2008, KNOWL-BASED SYST, V21, P1, DOI 10.1016/j.knosys.2006.11.003; Sun LL, 2007, EUR J OPER RES, V180, P738, DOI 10.1016/j.ejor.2006.04.019; Tsai CF, 2008, EXPERT SYST APPL, V34, P2639, DOI 10.1016/j.eswa.2007.05.019; Vapnik V.N., 1995, NATURE STAT LEARNING; Wu CH, 2007, EXPERT SYST APPL, V32, P397, DOI 10.1016/j.eswa.2005.12.008; Wu WW, 2010, EXPERT SYST APPL, V37, P2371, DOI 10.1016/j.eswa.2009.07.056; Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2; Yang ZR, 1999, J BUS RES, V44, P67, DOI 10.1016/S0148-2963(97)00242-7; Yip AYN, 2004, LECT NOTES ARTIF INT, V3215, P665; Yu L, 2008, EXPERT SYST APPL, V34, P1434, DOI 10.1016/j.eswa.2007.01.009; Zhu Z, 2007, INFORM SCIENCES, V177, P1180, DOI 10.1016/j.ins.2006.08.002	57	9	9	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	AUG	2010	37	8					5895	5904		10.1016/j.eswa.2010.02.016		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	605VR	WOS:000278376100043	
J	Rodriguez, RM; Martinez, L; Ruan, D; Liu, J				Rodriguez, Rosa M.; Martinez, Luis; Ruan, Da; Liu, Jun			USING COLLABORATIVE FILTERING FOR DEALING WITH MISSING VALUES IN NUCLEAR SAFEGUARDS EVALUATION	INTERNATIONAL JOURNAL OF UNCERTAINTY FUZZINESS AND KNOWLEDGE-BASED SYSTEMS			English	Article						Nuclear safeguards; fuzzy linguistic approach; 2-tuple; missing values; trust-worthy; collaborative filtering; imputation	GROUP DECISION-MAKING; REPRESENTATION MODEL; PREFERENCE RELATIONS; CLASSIFICATION; INFORMATION; PERFORMANCE; ALGORITHMS; OPERATORS; SYSTEM; WORDS	Nuclear safeguards evaluation aims to verify that countries are not misusing nuclear programs for nuclear weapons purposes. Experts of the International Atomic Energy Agency (IAEA) carry out an evaluation process in which several hundred so findicat ors are assessed according to the information obtained from different sources, such as State declarations, on-site inspections, IAEA non-safeguards databases and other open sources. These assessments are synthesized in a hierarchical way to obtain a global assessm ent. Much information and many sources of information related to nuclear safeguards the imputed values.	[Rodriguez, Rosa M.; Martinez, Luis] Univ Jaen, Dept Comp Sci, Jaen 23071, Spain; [Ruan, Da] Belgian Nucl Res Ctr SCK CEN, B-2400 Mol, Belgium; [Ruan, Da] Univ Ghent, B-9000 Ghent, Belgium; [Liu, Jun] Univ Ulster, Sch Comp & Math, Coleraine BT37 0QB, Londonderry, North Ireland	Rodriguez, RM (reprint author), Univ Jaen, Dept Comp Sci, Campus Lagunillas S-N, Jaen 23071, Spain.	rmrodrig@ujaen.es; martin@ujaen.es; druan@sckcen.be; j.liu@ulster.ac.uk	Rodriguez, Rosa M./B-9618-2011; Liu, Jun/C-1338-2011; Martinez, Luis/A-1746-2009; Research Group, Sinbad2/D-2448-2011	Rodriguez, Rosa M./0000-0002-1736-8915; Martinez, Luis/0000-0003-4245-8813; 			ADOMAVICIUS RG, 2005, IEEE T KNOWL DATA EN, V17, P734; ANCHEZ PJ, 2009, INFORM SCI, V179, P2333; Arfi B, 2005, POLIT ANAL, V13, P23, DOI 10.1093/pan/mpi002; BONISSONE PP, 1986, SELECTING UNCERTAINT; Castellano EJ, 2009, J UNIVERS COMPUT SCI, V15, P2786; Chang SL, 2007, EUR J OPER RES, V177, P1013, DOI 10.1016/j.ejor.2006.01.032; Chen CT, 2001, INT J UNCERTAIN FUZZ, V9, P103, DOI 10.1142/S0218488501001022; Cheng CH, 2002, EUR J OPER RES, V142, P174, DOI 10.1016/S0377-2217(01)00280-6; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Degani R., 1988, International Journal of Approximate Reasoning, V2, DOI 10.1016/0888-613X(88)90105-3; Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776; DUBOIS D, 1988, COMPUT MATH APPL, V15, P797, DOI 10.1016/0898-1221(88)90117-4; Grzymala-Busse J.W, 2009, P 4 INT ISKE C INT D, P153; Herlocker J, 2002, INFORM RETRIEVAL, V5, P287, DOI 10.1023/A:1020443909834; Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772; Herrera F, 2000, IEEE T FUZZY SYST, V8, P746, DOI 10.1109/91.890332; Herrera-Viedma E, 2007, IEEE T SYST MAN CY B, V37, P176, DOI 10.1109/TSMCB.2006.875872; JIANG N, 2008, ADV DATABASES COCEPT, V4443, P981; JIMENEZ A, 2009, P 4 ISKE C INT DEC M, P203; KABAK O, 2009, P 2009 IEEE INT C SY, P2285; KABAK O, 2009, P 4 INT ISKE C INT D, P145; KABAK O, IEEE T KNOWLEDGE DAT; Landgrebe TCW, 2008, IEEE T PATTERN ANAL, V30, P810, DOI 10.1109/TPAMI.2007.70740; Little R. J. A., 1987, STAT ANAL MISSING DA; Liu J., 2002, INT J APPL MATH COMP, V12, P449; Liu J., 2009, INT J NUCL KNOWLEDGE, V3, P312; Martinez L, 2007, INT J APPROX REASON, V44, P148, DOI 10.1016/j.ijar.2006.07.006; Martinez L, 2008, INT J COMPUT INT SYS, V1, P225, DOI 10.2991/ijcis.2008.1.3.4; MASCHIO L, 2007, INT J NUCL KNOLEDGE, V2, P410; OLTMAN LB, 2008, CONCEPT LATTICES THE, V4923, P155; O'Mahony MP, 2004, ARTIF INTELL REV, V21, P215, DOI 10.1023/B:AIRE.0000036256.39422.25; PAWLAK M, 1993, IEEE T INFORM THEORY, V39, P979, DOI 10.1109/18.256504; RUAN D, 2003, INT J LOGISTICS INFO, V16, P401; Sarwar B, 2001, WORLD WIDE WEB, P285; Siddique J, 2008, COMPUT STAT DATA AN, V53, P405, DOI 10.1016/j.csda.2008.07.042; Ungar L. H., 1998, P WORKSH REC SYST; Wang JH, 2006, IEEE T FUZZY SYST, V14, P435, DOI 10.1109/TFUZZ.2006.876337; Xu ZS, 2004, INFORM SCIENCES, V166, P19, DOI 10.1016/j.ins.2003.10.006; YAGER RR, 1998, J APPROXIMATE REASON, V18, P32; Yager R.R., 1999, COMPUTING WORDS INFO, P50; YAGER RR, 1995, INT J APPROX REASON, V12, P237, DOI 10.1016/0888-613X(94)00035-2; YAGER RR, 1993, FUZZY SET SYST, V59, P125, DOI 10.1016/0165-0114(93)90194-M; Yeh CH, 2003, TRANSPORT RES E-LOG, V39, P35, DOI 10.1016/S1366-5545(02)00017-0; ZADEH LA, 1975, INFORM SCIENCES, V8, P301, DOI 10.1016/0020-0255(75)90046-8; ZADEH LA, 1975, INFORM SCIENCES, V9, P43, DOI 10.1016/0020-0255(75)90017-1; ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90036-5; Zhang SC, 2006, LECT NOTES ARTIF INT, V4099, P1010; *IAEA, 1999, STR314 IAEA; *IAEA, 2001, IAEA B, V43	49	2	2	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-4885		INT J UNCERTAIN FUZZ	Int. J. Uncertainty Fuzziness Knowl.-Based Syst.	AUG	2010	18	4					431	449		10.1142/S0218488510006635		19	Computer Science, Artificial Intelligence	Computer Science	622DP	WOS:000279640100006	
J	Bounhas, I; Elayeb, B; Evrard, F; Slimani, Y				Bounhas, Ibrahim; Elayeb, Bilel; Evrard, Fabrice; Slimani, Yahya			Toward a Computer Study of the Reliability of Arabic Stories	JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY			English	Article							INFORMATION QUALITY; WEB; JUDGMENT; TRUST	The Arabic storytelling methodology provides solutions to the problem of information reliability. The reliability of a story depends on the credibility of its narrators. To insure reliability verification, the narrators' names are explicitly cited at the head of the story, which constitute its chain of narrators. Stories were reported from a generation to another to insure the reliable transmission of historical knowledge. We present a set of tools based on the Arabic storytelling methodology. We start by presenting this methodology as a set of principles for information-reliability assessment. Then, we detail an architecture designed to support the study of the reliability of Arabic stories. Indeed, we developed grammars for parsing Arabic full names and chains of narrators of Arabic stories. After that, an intelligent identity recognizer links names found in chains of narrators to the biographies of the corresponding persons. We model this step as a possibilistic information retrieval task. Finally, chains are analyzed through metadata available in biographies to help the user identify sources of unreliability. We propose to identify the class of reliability of a story with a possibilistic classifier. The achieved results in named entity and identity recognition were satisfactory and confirm to the targets set for the precision, recall, and F-measure metrics. The developed tools also are reusable components that can be used to study the reliability of other types of Arabic texts.	[Bounhas, Ibrahim; Slimani, Yahya] Univ Tunis, Dept Comp Sci, Fac Sci Tunis, Tunis 1060, Tunisia; [Elayeb, Bilel; Evrard, Fabrice] Comp Sci Res Inst Toulouse IRIT, F-31071 Toulouse, France; [Elayeb, Bilel] Natl Sch Comp Sci ENSI, RIADI GDL Res Lab, Manouba 2010, Tunisia	Bounhas, I (reprint author), Univ Tunis, Dept Comp Sci, Fac Sci Tunis, Tunis 1060, Tunisia.	Bounhas.ibrahim@yahoo.fr; Bilel.Elayeb@riadi.mu.tn; Fabrice.Evrard@enseeiht.fr; yahya.slimani@fst.mu.tn					BENFERHAT S, 1999, P 15 C UNC ART INT U, P57; Bishop CM, 1996, NEURAL NETWORKS PATT; BORDOGNA G, 2009, METHODOLOGIES APPL, V14, P799; BORGELT C, 2000, CISM COURSES LECT, V408, P51; CHEN J, 2007, 6 WUH INT C E BUS WU; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DACOSTA P, 2007, LECT NOTES COMPUTER, V4578, P110; DEBRUIN JS, 2006, P 6 IEEE INT C DAT M, P171; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dubois D, 1994, POSSIBILITY THEORY A; Dubois D., 1987, THEORIE POSSIBILITIE; Dubois D., 1988, POSSIBILITY THEORY; Dubois D., 1998, HDB DEFEASIBLE REASO, V1, P169; Elayeb Bilel, 2009, Interactive Technology and Smart Education, V6, DOI 10.1108/17415650910965191; Gilens M, 2000, J POLIT, V62, P369; GRUBER T, 2006, 5 INT SEM WEB C ATH; Haouari B, 2009, FUZZY SET SYST, V160, P3224, DOI 10.1016/j.fss.2009.01.009; Knight S., 2005, INFORM SCI J, V8, P159; LUCAS S, 2002, THESIS U CHICAGO; Lynch CA, 2001, J AM SOC INF SCI TEC, V52, P12, DOI 10.1002/1532-2890(2000)52:1<12::AID-ASI1062>3.0.CO;2-V; NAUMANN F, 2000, P INT C INF QUAL CAM, P396; PARKER M, 2006, M COMM INF DEV COUNT; Pearl J., 1988, PROBABILISTIC REASON, p[505, 506, 507, 524]; QUINLAN JR, 1986, MACH LEARN, V1, P106; Richardson M, 2003, LECT NOTES COMPUT SC, V2870, P351; Rieh SY, 2002, J AM SOC INF SCI TEC, V53, P145, DOI 10.1002/asi.10017.abs; ROMNEY M, 2005, P 6 INT C INF TECHN; Sahami M., 1996, P 2 INT C KNOWL DISC, P335; Shaalan K, 2009, J AM SOC INF SCI TEC, V60, P1652, DOI 10.1002/asi.21090; Shaalan K., 2007, P 2007 WORKSH COMP A, P17, DOI 10.3115/1654576.1654581; Shafer G., 1976, MATH THEORY EVIDENCE; Stvilia B, 2007, J AM SOC INF SCI TEC, V58, P1720, DOI 10.1002/asi.20652; STVILIA BA, 2008, P 8 ACM IEEE CS JOIN, P469, DOI 10.1145/1378889.1379014; VIGNAUX G, 2005, RECHERCHE INFORM PAN; Viola P. A., 2005, P 28 ANN INT ACM SIG, P330, DOI 10.1145/1076034.1076091; Xu YJ, 2006, J AM SOC INF SCI TEC, V57, P961, DOI 10.1002/asi.20361; ZACKLAD M, 2007, NUMERIQUE IMPACT CYC, P1; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; ZADEH LA, 1978, FUZZY SETS SYSTEMS, V1, P28; ZHU QG, 2000, J NANJING I METEOROL, V23, P1; ZITOUNI I, 2005, P ACL WORKSH COMP AP, P63, DOI 10.3115/1621787.1621800	41	2	2	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	1532-2882		J AM SOC INF SCI TEC	J. Am. Soc. Inf. Sci. Technol.	AUG	2010	61	8					1686	1705		10.1002/asi.21356		20	Computer Science, Information Systems; Information Science & Library Science	Computer Science; Information Science & Library Science	627DJ	WOS:000280019100013	
J	Wang, Y; Xu, XY; Zhao, HF; Hua, ZS				Wang, Yu; Xu, Xiaoyan; Zhao, Haifeng; Hua, Zhongsheng			Semi-supervised learning based on nearest neighbor rule and cut edges	KNOWLEDGE-BASED SYSTEMS			English	Article						Semi-supervised learning; Nearest neighbor rule; Cut edges	UNLABELED DATA; PATTERN-CLASSIFICATION	In this paper, we propose a novel semi-supervised learning approach based on nearest neighbor rule and cut edges In the first step of our approach, a relative neighborhood graph based on all training samples is constructed for each unlabeled sample, and the unlabeled samples whose edges are all connected to training samples from the same class are labeled. These newly labeled samples are then added into the training samples In the second step, standard self-training algorithm using nearest neighbor rule is applied for classification until a predetermined stopping criterion is met. In the third step, a statistical test is applied for label modification, and in the last step, the remaining unlabeled samples are classified using standard nearest neighbor rule The main advantages of the proposed method are: (1) it reduces the error reinforcement by using relative neighborhood graph for classification in the initial stages of semi-supervised learning: (2) it introduces a label modification mechanism for better classification performance. Experimental results show the effectiveness of the proposed approach (C) 2010 Elsevier B.V. All rights reserved.	[Wang, Yu; Xu, Xiaoyan; Hua, Zhongsheng] Univ Sci & Technol China, Sch Management, Hefei 230026, Anhui, Peoples R China; [Wang, Yu] Chongqing Univ, Sch Business Adm & Econ, Dept Informat Management & Informat Syst, Chongqing 400030, Peoples R China; [Zhao, Haifeng] Tongji Univ, Sch Econ & Management, Shanghai 200092, Peoples R China	Hua, ZS (reprint author), Univ Sci & Technol China, Sch Management, Hefei 230026, Anhui, Peoples R China.				National Natural Science Foundation of China [70725001, 70821001]	The authors would like to thank the anonymous referees and the editor for their helpful comments and suggestions, which significantly improved the paper. This research was supported by the National Natural Science Foundation of China under Grants Nos. 70725001 and 70821001.	Bennett K. P., 1998, P NEUR INF PROC SYST; Blum A., 2001, P 18 INT C MACH LEAR; Blum A., 1998, P 11 ANN C COMP LEAR; Brodley CE, 1999, J ARTIF INTELL RES, V11, P131; Chapelle O., 2006, SEMISUPERVISED LEARN; Chawla N, 2005, J ARTIF INTELL RES, V23, P331; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COZMAN F, 2003, P 20 INT C MACH LEAR; De Bie T., 2006, SEMISUPERVISED LEARN; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; FUJINO A, 2005, P 20 NAT C ART INT; Gabrys B, 2004, INT J APPROX REASON, V35, P251, DOI 10.1016/j.ijar.2003.08.005; Jones R., 2005, THESIS CARNEGIE MELL; Kang P, 2008, PATTERN RECOGN, V41, P3507, DOI 10.1016/j.patcog.2008.04.009; Lee CH, 2007, KNOWL-BASED SYST, V20, P220, DOI 10.1016/j.knosys.2006.05.014; Li YQ, 2008, PATTERN RECOGN LETT, V29, P1285, DOI 10.1016/j.patrec.2008.01.030; Muhlenbach F, 2004, J INTELL INF SYST, V22, P89, DOI 10.1023/A:1025832930864; NIGAM K, 2000, P 9 INT C INF KNOWL; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Vapnik V.N., 1998, STAT LEARNING THEORY; Wang F, 2007, NEUROCOMPUTING, V70, P2931, DOI 10.1016/j.neucom.2006.11.004; ZHOU D, 2004, P NEUR INF PROC SYST; ZHOU Z, 2007, P 22 NAT C ART INT; Zhou Z.H., 2005, P ADV KNOWL DISC DAT; Zhu X., 2008, 1530 U WISC DEP COMP	25	4	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051		KNOWL-BASED SYST	Knowledge-Based Syst.	AUG	2010	23	6					547	554		10.1016/j.knosys.2010.03.012		8	Computer Science, Artificial Intelligence	Computer Science	633UO	WOS:000280532400007	
J	Lo, P; Sporring, J; Ashraf, H; Pedersen, JJH; de Bruijne, M				Lo, Pechin; Sporring, Jon; Ashraf, Haseem; Pedersen, Jesper J. H.; de Bruijne, Marleen			Vessel-guided airway tree segmentation: A voxel classification approach	MEDICAL IMAGE ANALYSIS			English	Article						Airway segmentation; Lung computed tomography; Appearance model; Blood vessel; Classification	OBSTRUCTIVE PULMONARY-DISEASE; RAY CT IMAGES; VIRTUAL BRONCHOSCOPY; COMPUTED-TOMOGRAPHY; MULTISLICE CT; RECONSTRUCTION; REGISTRATION; DIMENSIONS; ALGORITHM; EMPHYSEMA	This paper presents a method for airway tree segmentation that uses a combination of a trained airway appearance model, vessel and airway orientation information, and region growing. We propose a voxel classification approach for the appearance model, which uses a classifier that is trained to differentiate between airway and non-airway voxels. This is in contrast to previous works that use either intensity alone or hand crafted models of airway appearance. We show that the appearance model can be trained with a set of easily acquired, incomplete, airway tree segmentations. A vessel orientation similarity measure is introduced, which indicates how similar the orientation of an airway candidate is to the orientation of the neighboring vessel. We use this vessel orientation similarity measure to overcome regions in the airway tree that have a low response from the appearance model. The proposed method is evaluated on 250 low dose computed tomography images from a lung cancer screening trial. Our experiments showed that applying the region growing algorithm on the airway appearance model produces more complete airway segmentations, leading to on average 20% longer trees, and 50% less leakage. When combining the airway appearance model with vessel orientation similarity, the improvement is even more significant (p < 0.01) than only using the airway appearance model, with on average 7% increase in the total length of branches extracted correctly. (C) 2010 Elsevier B.V. All rights reserved.	[Lo, Pechin; Sporring, Jon; de Bruijne, Marleen] Univ Copenhagen, Dept Comp Sci, Image Grp, DK-1168 Copenhagen, Denmark; [Ashraf, Haseem] Gentofte Univ Hosp, Dept Radiol, Copenhagen, Denmark; [Pedersen, Jesper J. H.] Copenhagen Univ Hosp, Rigshosp, Dept Cardio Thorac Surg, Copenhagen, Denmark; [de Bruijne, Marleen] Erasmus MC Univ, Med Ctr, Dept Radiol, Biomed Imaging Grp Rotterdam, Rotterdam, Netherlands; [de Bruijne, Marleen] Erasmus MC Univ, Med Ctr, Dept Med Informat, Biomed Imaging Grp Rotterdam, Rotterdam, Netherlands	Lo, P (reprint author), Univ Copenhagen, Dept Comp Sci, Image Grp, DK-1168 Copenhagen, Denmark.	pechin@diku.dk; sporring@diku.dk; haseem@dadlnet.dk; jesper.holst.pedersen@rh.regionh.dk; marleen@diku.dk			Danish Council for Strategic Research; Netherlands Organization for Scientific Research (NWO); AstraZeneca, Lund, Sweden	This work is partly funded by the Danish Council for Strategic Research under the Programme Commission for Nanoscience and Technology, Biotechnology and IT (NABIIT), the Netherlands Organization for Scientific Research (NWO), and AstraZeneca, Lund, Sweden.	Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Aykac D, 2003, IEEE T MED IMAGING, V22, P940, DOI 10.1109/TMI.2003.815905; Berger P, 2005, RADIOLOGY, V235, P1055, DOI 10.1148/radiol.2353040121; Bulow T, 2005, P SOC PHOTO-OPT INS, V5746, P730, DOI 10.1117/12.595286; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Coxson HO, 2005, ACAD RADIOL, V12, P1457, DOI 10.1016/j.acra.2005.08.013; DUDA RO, 2001, PATTERN CLASSIFICATI, P174; Fetita CI, 2004, IEEE T MED IMAGING, V23, P1353, DOI 10.1109/TMI.2004.826945; Gorbunova V, 2008, LECT NOTES COMPUT SC, V5242, P863, DOI 10.1007/978-3-540-85990-1_104; GRAHAM MW, 2008, MED IMAGING 2008 IMA, V6914; Hu SY, 2001, IEEE T MED IMAGING, V20, P490, DOI 10.1109/42.929615; Kiraly AP, 2002, ACAD RADIOL, V9, P1153, DOI 10.1016/S1076-6332(03)80517-2; Kitasaka T, 2003, LECT NOTES COMPUT SC, V2879, P603; Kuhnigk JM, 2003, P SOC PHOTO-OPT INS, V5032, P1482, DOI 10.1117/12.480321; Lee YK, 2008, LUNG, V186, P157, DOI 10.1007/s00408-008-9071-0; Li BJ, 2008, MED PHYS, V35, P5575, DOI 10.1118/1.3005633; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; LO P, 2008, MED IMAGING 2008 IMA, V6914; Lo P., 2009, P 2 INT WORKSH PULM, P323; Lo P., 2009, 2 INT WORKSH PULM IM, P175; LO P, 2008, P 1 INT WORKSH PULM, P113; Malladi R., 1996, P IEEE INT C COMP VI, P489, DOI 10.1109/ICIP.1996.559540; Mayer D, 2004, ACAD RADIOL, V11, P551, DOI 10.1016/j.acra.2004.01.012; MORI K, 2008, MED IMAGING 2008 IMA, V6914; Mori K., 1995, P 13 ICPR, V3, P528, DOI 10.1109/ICPR.1996.547003; Murray CJL, 1996, SCIENCE, V274, P740, DOI 10.1126/science.274.5288.740; Nakano Y, 2000, AM J RESP CRIT CARE, V162, P1102; Ochs RA, 2007, MED IMAGE ANAL, V11, P315, DOI 10.1016/j.media.2007.03.004; PEDERSEN J, 2009, J THORAC ONCOL, V4, P563; PISUPATI C, 1996, P C MATH MORPH ITS A, P409; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Rabe KF, 2007, AM J RESP CRIT CARE, V176, P532, DOI 10.1164/rccm.200703-456SO; Schlatholter T, 2002, P SOC PHOTO-OPT INS, V4684, P103, DOI 10.1117/12.467061; Singh H, 2004, LECT NOTES COMPUT SC, V3217, P975; Sonka M, 1996, IEEE T MED IMAGING, V15, P314, DOI 10.1109/42.500140; Tschirren J., 2009, P 2 INT WORKSH PULM, P227; Tschirren J, 2005, IEEE T MED IMAGING, V24, P1529, DOI 10.1109/TMI.2005.857654; TSITSIKLIS JN, 1995, IEEE T AUTOMAT CONTR, V40, P1528, DOI 10.1109/9.412624; UKIL S, 2006, MED IMAGING 2006 IMA, V6144; Van Lersel CA, 2006, INT J CANCER, V120, P868; van Ginneken B, 2008, LECT NOTES COMPUT SC, V5241, P219, DOI 10.1007/978-3-540-85988-8_27; Wang T, 2007, PATTERN RECOGN LETT, V28, P501, DOI 10.1016/j.patrec.2006.09.004; Weickert J, 1997, COMP IMAG VIS, V8, P45; Weickert J, 1999, INT J COMPUT VISION, V31, P111, DOI 10.1023/A:1008009714131; Zhou X, 2006, COMPUT MED IMAG GRAP, V30, P299, DOI 10.1016/j.compmedimag.2006.06.002	45	19	20	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1361-8415		MED IMAGE ANAL	Med. Image Anal.	AUG	2010	14	4					527	538		10.1016/j.media.2010.03.004		12	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging	Computer Science; Engineering; Radiology, Nuclear Medicine & Medical Imaging	623RM	WOS:000279759800004	
J	Tahir, MA; Smith, J				Tahir, Muhammad Atif; Smith, Jim			Creating diverse nearest-neighbour ensembles using simultaneous metaheuristic feature selection	PATTERN RECOGNITION LETTERS			English	Article						Tabu Search; 1NN classifier; Feature selection; Ensemble classifiers	STATISTICAL PATTERN-RECOGNITION; GENETIC ALGORITHMS; SEARCH ALGORITHM; CLASSIFICATION; CLASSIFIERS; IMAGERY	The nearest-neighbour (1NN) classifier has long been used in pattern recognition, exploratory data analysis, and data mining problems. A vital consideration in obtaining good results with this technique is the choice of distance function, and correspondingly which features to consider when computing distances between samples. In recent years there has been an increasing interest in creating ensembles of classifiers in order to improve classification accuracy. This paper proposes a new ensemble technique which combines multiple 1NN classifiers, each using a different distance function, and potentially a different set of features (feature vector). These feature vectors are determined for each distance metric simultaneously using Tabu Search to minimise the ensemble error rate. We show that this approach implicitly selects for a diverse set of classifiers, and by doing so achieves greater performance improvements than can be achieved by treating the classifiers independently, or using a single feature set. Naturally, optimising the level of ensembles necessitates a much larger solution space, to make this approach tractable, we show how Tabu Search at the ensemble level can be hybridised with local search at the level of individual classifiers. The proposed ensemble classifier with different distance metrics and different feature vectors is evaluated using various benchmark datasets from UCI Machine Learning Repository and a real-world machine-vision application. Results have indicated a significant increase in the performance when compared with various well-known classifiers. Furthermore, the proposed ensemble method is also compared with ensemble classifier using different distance metrics but with same feature vector (with or without feature selection (FS)). (C) 2010 Elsevier B.V. All rights reserved.	[Tahir, Muhammad Atif] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England; [Smith, Jim] Univ W England, Dept Comp Sci, Bristol BS16 1QT, Avon, England	Tahir, MA (reprint author), Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.	m.tahir@surrey.ac.uk			European Commission [STRP016429]	This work is supported by the European Commission (Project No. STRP016429, acronym DynaVis). This publication reflects only the authors' views.	Alpaydin E, 1997, ARTIF INTELL REV, V11, P115, DOI 10.1023/A:1006563312922; Amaldi E, 1998, THEOR COMPUT SCI, V209, P237, DOI 10.1016/S0304-3975(97)00115-1; BAO Y, 2004, LNCS, V3177; Bay S.D., 1998, P 15 INT C MACH LEAR, P37; Blake C.L., UCI REPOSITORY MACHI; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cunningham P, 2000, LECT NOTES ARTIF INT, V1810, P109; Davies S, 1994, P 1994 AAAI FALL S R, P37; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Duda R., 1973, PATTERN CLASSIFICATI; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Glover F., 1990, ORSA Journal on Computing, V2; Glover F., 1989, ORSA Journal on Computing, V1; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Kohavi R., 1995, P 14 INT JOINT C ART, V2, P1137; KOHONEN K, 1997, SELF ORGANIZING MAPS; KORYCINSKI D, 2003, P IEEE INT GEOSC REM; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Kuncheva L.I., 2005, INFORM FUSION, V6, P3, DOI 10.1016/j.inffus.2004.04.009; Michie D, 1994, MACHINE LEARNING NEU; Okun O., 2005, P ICML WORKSH LEARN, P51; Paredes R, 2006, IEEE T PATTERN ANAL, V28, P1100, DOI 10.1109/TPAMI.2006.145; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; SAIT SM, 1999, GEN ITERATIVE ALGORI; Sannen D, 2008, LECT NOTES COMPUT SC, V5008, P171; Serpico SB, 2001, IEEE T GEOSCI REMOTE, V39, P1360, DOI 10.1109/36.934069; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; SMITH JE, 1994, P IEE C GEN ALG IM P; Tahir MA, 2006, IEEE T INF TECHNOL B, V10, P782, DOI 10.1109/TITB.2006.879596; TAHIR MA, 2007, PATTERN RECOGNITION, V28; TAHIR MA, 2006, P IEEE INT C DAT MIN; Tsymbal A., 2003, Information Fusion, V4, DOI 10.1016/S1566-2535(03)00004-6; TSYMBAL A, 2004, LNCS, V3181; Wang JG, 2007, PATTERN RECOGN LETT, V28, P207, DOI 10.1016/j.patrec.2006.07.002; WHITNEY AW, 1971, IEEE T COMPUT, VC 20, P1100, DOI 10.1109/T-C.1971.223410; Witten I., 2005, DATA MINING PRACTICA; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Yu SX, 2002, PATTERN RECOGN LETT, V23, P183, DOI 10.1016/S0167-8655(01)00118-0; Zhang HB, 2002, PATTERN RECOGN, V35, P701, DOI 10.1016/S0031-3203(01)00046-2	46	2	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	AUG 1	2010	31	11					1470	1480		10.1016/j.patrec.2010.01.030		11	Computer Science, Artificial Intelligence	Computer Science	624QO	WOS:000279834800029	
J	Lucchese, C; Vlachos, M; Rajan, D; Yu, PS				Lucchese, Claudio; Vlachos, Michail; Rajan, Deepak; Yu, Philip S.			Rights protection of trajectory datasets with nearest-neighbor preservation	VLDB JOURNAL			English	Article						Trajectories; Time-series; Watermarking; Rights protection; Nearest neighbors	SPREAD-SPECTRUM WATERMARKING; MODULATION	Companies frequently outsource datasets to mining firms, and academic institutions create repositories or share datasets in the interest of promoting research collaboration. Still, many practitioners have reservations about sharing or outsourcing datasets, primarily because of fear of losing the principal rights over the dataset. This work presents a way of convincingly claiming ownership rights over a trajectory dataset, without, at the same time, destroying the salient dataset characteristics, which are important for accurate search operations and data-mining tasks. The digital watermarking methodology that we present distorts imperceptibly a collection of sequences, effectively embedding a secret key, while retaining as well as possible the neighborhood of each object, which is vital for operations such as similarity search, classification, or clustering. A key contribution in this methodology is a technique for discovering the maximum distortion that still maintains such desirable properties. We demonstrate both analytically and empirically that the proposed dataset marking techniques can withstand a number of attacks (such a translation, rotation, noise addition, etc) and therefore can provide a robust framework for facilitating the secure dissemination of trajectory datasets.	[Lucchese, Claudio] ISTI CNR, Pisa, Italy; [Vlachos, Michail] IBM Zurich Res Lab, Ruschlikon, Switzerland; [Rajan, Deepak] IBM TJ Watson Res Ctr, Hawthorne, NY USA; [Yu, Philip S.] Univ Illinois, Chicago, IL USA	Lucchese, C (reprint author), ISTI CNR, Pisa, Italy.	claudio.lucchese@isti.cnr.it	Lucchese, Claudio/G-3947-2012		National Science Foundation [IIS-0914934]	This work is partially supported by the National Science Foundation under Grants No. IIS-0914934.	AGARWAL P, 2008, P ACM WORKSH MULT SE, P91, DOI 10.1145/1411328.1411346; AGARWAL P, 2006, P 8 WORKSH MULT SEC, P230, DOI 10.1145/1161366.1161407; Agrawal R, 2000, P ACM SIGMOD C MAN D, P439, DOI DOI 10.1145/342009.335438; Agrawal R., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; BASSIA P, 1998, EUR SIGN PROC C EUSI; Becker M, 2004, Proceedings of the Fourth IEEE International Symposium on Signal Processing and Information Technology, P353, DOI 10.1109/ISSPIT.2004.1433792; Bertino E, 2006, IEEE T SYST MAN CY A, V36, P429, DOI 10.1109/TSMCA.2006.871796; BRICKELL J, 2008, P SIGKDD, P78; Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725; Chen B, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P13; Chen K, 2005, P 5 IEEE INT C DAT M, P589; Cheng Q, 2003, IEEE T SIGNAL PROCES, V51, P906, DOI 10.1109/TSP.2003.809374; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COX IJ, 2007, DIGITALWATERMARKING; COX IJ, 2004, INT C CONTR AUT ROB; Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120; Deshpande P.M., 2008, P 11 INT C EXT DAT T, P356; Fridrich J., 2006, P ACM MULT SEC WORKS, P2, DOI 10.1145/1161366.1161369; Fridrich J., 2007, P 9 ACM MULT SEC WOR, P3, DOI 10.1145/1288869.1288872; Green DM, 1966, SIGNAL DETECTION THE; Jagannathan Geetha, 2006, P SIAM INT C DAT MIN; JIN X, 2005, P DASFAA; KARGUPTA H., 2003, P 3 IEEE INT C DAT M, P99; Keogh E., 2002, P 8 ACM SIGKDD INT C, P102; KESAL M, 2005, ACM MULTIMEDIA SYSTE, P133; Kifer D., 2006, P ACM SIGMOD INT C M, P217, DOI 10.1145/1142473.1142499; LI F, 2007, P ICDE, P686; LI S, 2007, INT J GRAPH VIS IMAG, V7, P27; Li T., 2009, P 15 ACM SIGKDD INT, P517, DOI 10.1145/1557019.1557079; LIU L, 2006, ICDM INT WORKSH PRIV; LIU Y, 2008, P ACM MULT SEC WORKS, P43, DOI 10.1145/1411328.1411338; Lucchese C, 2008, PROC INT CONF DATA, P1349, DOI 10.1109/ICDE.2008.4497552; MAITY SP, 2002, IND C COMP VIS GRAPH; Malvar HS, 2003, IEEE T SIGNAL PROCES, V51, P898, DOI 10.1109/TSP.2003.809385; MOULIN P, 2000, IEEE INT C IM PROC; MOULIN P, 2000, P IEEE INT C IM PROC, V3, P667; Niu XM, 2006, INT J INNOV COMPUT I, V2, P1301; Oliveira S.R.M., 2003, P 18 BRAZ S DAT MAN, P304; Perez-Freire L, 2009, IEEE T INF FOREN SEC, V4, P2, DOI 10.1109/TIFS.2008.2009603; Pinkas B., 2002, SIGKDD EXPLORATIONS, V4, P12; Rastogi Vibhor, 2007, P INT C VER LARG DAT, P531; SAGETONG P, 2002, IEEE INT C IM PROC, P653; SIMITOPOULOS D, 2002, IEEE INT C MULT EXP; Sion R, 2006, IEEE T KNOWL DATA EN, V18, P699, DOI 10.1109/TKDE.2006.82; Sion R, 2004, IEEE T KNOWL DATA EN, V16, P1509, DOI 10.1109/TKDE.2004.94; Solachidis V, 2004, IEEE COMPUT GRAPH, V24, P44, DOI 10.1109/MCG.2004.1297010; Swanson MD, 1998, SIGNAL PROCESS, V66, P337, DOI 10.1016/S0165-1684(98)00014-0; THURAISINGHAM BM, 2008, ENCY GIS, P898, DOI 10.1007/978-0-387-35973-1_1018; TOPKARA U, 2006, MM SEC 06, P164; VAIDYA J, 2003, SIGKDD; VAIDYA J, 2004, P SDM; VLACHOS M, 2008, P EDBT, P276; Voigt M, 2004, P 2004 MULT SEC WORK, P160, DOI 10.1145/1022431.1022459; Voyatzis G., 1996, EUR C MULT APPL SERV, V2, P687; XU Y, 2008, ADV DATABASE SYSTEMS, P487; Yamazaki S., 2004, P PAC RIM WORKSH DIG, P177; Yu H., 2006, SAC 06, P603; YU H, 2006, PAC AS C KNOWL DISC, P647; YU P., 2004, P 9 INT C EXT DAT TE, P183; Zhu WW, 1999, IEEE T CIRC SYST VID, V9, P545; ZMUDZINSKI S, 2008, P ACM WORKSH MULT SE, P75, DOI 10.1145/1411328.1411343; [Anonymous], UCI REP MACH LEARN D; 2000, INFORM HIDING TECHNI	65	0	0	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1066-8888		VLDB J	VLDB J.	AUG	2010	19	4					531	556		10.1007/s00778-010-0178-6		26	Computer Science, Hardware & Architecture; Computer Science, Information Systems	Computer Science	634QZ	WOS:000280599600004	
J	Zhu, XY; Song, QB; Jia, ZH				Zhu, Xiaoyan; Song, Qinbao; Jia, Zihan			A Weighted Voting-Based Associative Classification Algorithm	COMPUTER JOURNAL			English	Article						classification; association rule; associative classification; weighted voting	MULTIPLE DATA SETS; STATISTICAL COMPARISONS; CLASSIFIERS	A new associative classification algorithm based on weighted voting (ACWV) is presented. ACWV takes advantage of two methods: the optimal rule method preferring high-quality rules and the voting method considering the majority of the rules. Moreover, the method takes into account both the length and convictions of rules to calculate their weights. First, ACWV builds a class-count FP-tree (called CCFP-tree) from the given historical data. After that, the weighted voting result for a new instance can be obtained from the CCFP-tree directly without storing, retrieving and sorting rules explicitly. The label of the class with maximal sum of weighted votes is then that of the new instance. Results of the experiments with 36 data sets selected from the UCI machine learning repository show that the proposed method has its advantages in comparison with previous methods in terms of classification accuracy.	[Zhu, Xiaoyan; Song, Qinbao; Jia, Zihan] Xi An Jiao Tong Univ, Dept Comp Sci & Technol, Xian 710049, Peoples R China	Song, QB (reprint author), Xi An Jiao Tong Univ, Dept Comp Sci & Technol, Xian 710049, Peoples R China.	qbsong@mail.xjtu.edu.cn			National Natural Science Foundation of China [60673124, 90718024]; Program for New Century Excellent Talents in University [NCET-07-0674]; Hi-Tech Research & Development Program of China [2006AA01Z183]; Scientific Research Foundation for the Returned Overseas Chinese Scholars, State Education Ministry	This work was supported by the National Natural Science Foundation of China [60673124, 90718024]; the Program for New Century Excellent Talents in University [NCET-07-0674]; the Hi-Tech Research & Development Program of China [2006AA01Z183]; and the Scientific Research Foundation for the Returned Overseas Chinese Scholars, State Education Ministry.	Agrawal R, 1994, P 20 INT C VER LARG, P487; Asuncion A., 2007, UCI MACHINE LEARNING; Baralis E, 2008, IEEE T KNOWL DATA EN, V20, P156, DOI 10.1109/TKDE.2007.190677; Coenen F, 2004, IEEE T KNOWL DATA EN, V16, P774, DOI 10.1109/TKDE.2004.8; COENEN F, 2004, P 4 IEEE INT C DAT M, P59; Cohen W. W., 1995, P 12 INT C MACH LEAR, P115; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Demsar J, 2006, J MACH LEARN RES, V7, P1; Duda R., 1973, PATTERN CLASSIFICATI; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Friedman M, 1940, ANN MATH STAT, V11, P86, DOI 10.1214/aoms/1177731944; Garcia S, 2008, J MACH LEARN RES, V9, P2677; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Joachims T, 1998, P 10 EUR C MACH LEAR, P137; Lavrac N., 1999, P 9 INT WORKSH IND L, P174; Li W., 2001, P IEEE INT C DAT MIN, P369; Liu B, 1998, P 4 INT C KNOWL DISC, P80; Meretakis D., 1999, P 5 ACM SIGKDD INT C, P165, DOI 10.1145/312129.312222; Nemenyi B., 1963, THESIS PRINCETON U; Pazzani M. J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Quinlan J. R., 1983, MACHINE LEARNING ART, P463; Quinlan J. R., 1993, P EUR C MACH LEARN, P3; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Thabtah F., 2005, P 3 ACS IEEE INT C C, P33; Wang PL, 2000, J EUR CERAM SOC, V20, P23, DOI 10.1016/S0955-2219(99)00090-4; WANG YJ, 2007, P 7 IEEE INT C DAT M, P271; WEKA, DAT MIN SOFTW JAV; WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968; YIN JQ, 2003, J EXP THER ONCOL, V3, P1; ZHANG X, 2000, P INT DAT ENG AUT LE, P48	30	1	2	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0010-4620		COMPUT J	Comput. J.	JUL	2010	53	6					786	801		10.1093/comjnl/bxp074		16	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	616CJ	WOS:000279185400012	
J	Watanabe, T; Kobunai, T; Yamamoto, Y; Kanazawa, T; Konishi, T; Tanaka, T; Matsuda, K; Ishihara, S; Nozawa, K; Eshima, K; Muto, T; Nagawa, H				Watanabe, Toshiaki; Kobunai, Takashi; Yamamoto, Yoko; Kanazawa, Takamitsu; Konishi, Tsuyoshi; Tanaka, Toshiaki; Matsuda, Keiji; Ishihara, Soichiro; Nozawa, Keijiro; Eshima, Kiyoshi; Muto, Tetsuichiro; Nagawa, Hirokazu			Prediction of liver metastasis after colorectal cancer using reverse transcription-polymerase chain reaction analysis of 10 genes	EUROPEAN JOURNAL OF CANCER			English	Article						Liver metastasis; Colorectal cancer; RT-PCR; Microarray; Prediction	COLON-CANCER; BREAST-CANCER; CYCLOOXYGENASE-2 EXPRESSION; ADJUVANT CHEMOTHERAPY; PATIENT SURVIVAL; DNA MICROARRAY; RECTAL-CANCER; STAGE-II; CARCINOMA; AMPHIREGULIN	Purpose: Liver metastasis is one of the major types of recurrence after surgery for colorectal cancer. Traditional methods of predicting liver metastasis are limited in their accuracy, suggesting the need to develop new predictors. We developed a 10-gene signature that is closely associated with the development of liver metastasis after colorectal cancer. Patients and methods: We examined a total of 189 frozen specimens of primary colorectal cancers using both microarray and quantitative real-time reverse transcriptase-polymerase chain reaction (RT-PCR) analysis. Initially, we studied gene expression in colorectal cancer tissue from 160 randomly selected patients who had undergone surgical resection of colorectal cancer and evaluated the association between the level of gene expression and the occurrence of liver metastasis. We developed a gene-expression model for the prediction of liver metastasis based on the RT-PCR findings. We then used specimens from 29 other patients for validation. Results: The expression of 14 genes was correlated with liver metastasis according to both microarray and RT-PCR analysis. We constructed an accurate predictive model based on the results for 10 of these genes, which included epiregulin (EREG), amphiregulin (AREG), cyclooxygenase 2 (COX-2) and lymphocyte-specific protein tyrosine kinase (LCK). The 10-gene signature was an independent predictor of liver metastasis. The model was validated in the independent set of 29 patients. The predictive accuracy of the model in a test set of patients was 86.2%. Conclusion: The 10-gene signature identified in this study is closely associated with the occurrence of liver metastasis in colorectal cancer patients. (C) 2010 Elsevier Ltd. All rights reserved.	[Watanabe, Toshiaki; Kobunai, Takashi; Yamamoto, Yoko; Matsuda, Keiji; Ishihara, Soichiro; Nozawa, Keijiro] Teikyo Univ, Sch Med, Dept Surg, Itabashi Ku, Tokyo 1738605, Japan; [Kanazawa, Takamitsu; Konishi, Tsuyoshi; Tanaka, Toshiaki; Nagawa, Hirokazu] Univ Tokyo, Dept Surg Oncol, Bunkyo Ku, Tokyo 1138655, Japan; [Kobunai, Takashi; Eshima, Kiyoshi] Taiho Pharmaceut Co Ltd, Tokushima Res Ctr, Kawaguchi, Tokushima 7710194, Japan; [Muto, Tetsuichiro] JFCR, Canc Inst Hosp, Kotoh Ku, Tokyo 1358550, Japan	Watanabe, T (reprint author), Teikyo Univ, Sch Med, Dept Surg, Itabashi Ku, 2-11-1 Kaga, Tokyo 1738605, Japan.	toshwatanabe@yahoo.co.jp			Ministry of Education, Culture, Sports, Science and Technology of Japan; Ministry of Health, Labor and Welfare of Japan	This study was supported by a Grant-in-Aid for Scientific Research from the Ministry of Education, Culture, Sports, Science and Technology of Japan and by a grant from the Ministry of Health, Labor and Welfare of Japan.	Andre T, 2004, NEW ENGL J MED, V350, P2343, DOI 10.1056/NEJMoa032709; Berasain C, 2005, GASTROENTEROLOGY, V128, P424, DOI 10.1053/j.gastro.2004.11.006; Bertucci F, 2004, ONCOGENE, V23, P1377, DOI 10.1038/sj.onc.1207262; Botti C, 2004, CLIN CANCER RES, V10, P1360, DOI 10.1158/1078-0432.CCR-1092-03; Brown CL, 1998, J BIOL CHEM, V273, P17258, DOI 10.1074/jbc.273.27.17258; Chang GJ, 2007, J NATL CANCER I, V99, P433, DOI 10.1093/jnci/djk092; Chen CN, 2005, J CLIN ONCOL, V23, P7286, DOI 10.1200/JCO.2004.00.2253; Chen HY, 2007, NEW ENGL J MED, V356, P11, DOI 10.1056/NEJMoa060096; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; D'Arrigo A, 2005, INT J CANCER, V115, P256, DOI 10.1002/ijc.20883; Ding Yongzeng, 2007, J Biomol Tech, V18, P321; Eltarhouny S. A., 2008, Experimental Oncology, V30, P91; Endoh H, 2004, J CLIN ONCOL, V22, P811, DOI 10.1200/JCO.2004.04.109; Fux R, 2005, CLIN CANCER RES, V11, P4754, DOI 10.1158/1078-0432.CCR-04-2586; Gupta GP, 2007, NATURE, V446, P765, DOI 10.1038/nature05760; Helms MW, 2008, BRIT J CANCER, V99, P774, DOI 10.1038/sj.bjc.6604556; Johnson PM, 2002, J GASTROINTEST SURG, V6, P883, DOI 10.1016/S1091-255X(02)00131-2; Ki DH, 2007, INT J CANCER, V121, P2005, DOI 10.1002/ijc.22975; KRASNA MJ, 1988, CANCER, V61, P1018, DOI 10.1002/1097-0142(19880301)61:5<1018::AID-CNCR2820610527>3.0.CO;2-H; Kuebler JP, 2007, J CLIN ONCOL, V25, P2198, DOI 10.1200/JCO.2006.08.2974; Le Voyer TE, 2003, J CLIN ONCOL, V21, P2912, DOI 10.1200/JCO.2003.05.062; Li MH, 2004, INT J ONCOL, V24, P305; Liu R, 2007, NEW ENGL J MED, V356, P217, DOI 10.1056/NEJMoa063994; Lossos IS, 2004, NEW ENGL J MED, V350, P1828, DOI 10.1056/NEJMoa032520; Masunaga R, 2000, CLIN CANCER RES, V6, P4064; Michiels S, 2005, LANCET, V365, P488, DOI 10.1016/S0140-6736(05)17866-0; Mottolese M, 2000, INT J CANCER, V89, P127, DOI 10.1002/(SICI)1097-0215(20000320)89:2<127::AID-IJC5>3.0.CO;2-4; Ogawa S, 2004, ANTICANCER RES, V24, P1569; Ohji Y, 2007, ONCOL REP, V17, P525; Sheehan KM, 1999, JAMA-J AM MED ASSOC, V282, P1254, DOI 10.1001/jama.282.13.1254; Shigeishi H, 2008, ONCOL REP, V19, P1557; Takata R, 2005, CLIN CANCER RES, V11, P2625, DOI 10.1158/1078-0432.CCR-04-1988; TALBOT IC, 1980, BRIT J SURG, V67, P439, DOI 10.1002/bjs.1800670619; Watanabe T, 2007, CLIN CANCER RES, V13, P415, DOI 10.1158/1078-0432.CCR-06-0753; Watanabe T, 2001, NEW ENGL J MED, V344, P1196, DOI 10.1056/NEJM200104193441603; Watanabe T, 2006, CANCER RES, V66, P3370, DOI 10.1158/0008-5472.CAN-05-3834; Watanabe T, 2006, CANCER RES, V66, P9804, DOI 10.1158/0008-5472.CAN-06-1163; Weitz J, 2005, LANCET, V365, P153, DOI 10.1016/S0140-6736(05)17706-X; Yamada M, 2008, CLIN CANCER RES, V14, P2351, DOI 10.1158/1078-0432.CCR-07-4499; Yamasaki M, 2007, INT J ONCOL, V30, P129; Zhang H, 2002, AM J GASTROENTEROL, V97, P1037	41	13	14	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0959-8049		EUR J CANCER	Eur. J. Cancer	JUL	2010	46	11					2119	2126		10.1016/j.ejca.2010.04.019		8	Oncology	Oncology	632AZ	WOS:000280393700025	
J	Roh, SB; Ahn, TC; Pedrycz, W				Roh, Seok-Beom; Ahn, Tae-Chon; Pedrycz, Witold			The design methodology of radial basis function neural networks based on fuzzy K-nearest neighbors approach	FUZZY SETS AND SYSTEMS			English	Article						Classification; Fuzzy K-NN; Auxiliary information granules; Supervised clustering; Cluster homogeneity	LEARNING ALGORITHM; LOGIC SYSTEMS; RBF NETWORKS; RULE-BASE; C-MEANS; INFERENCE; CLASSIFICATION; IDENTIFICATION; APPROXIMATION	Various approaches to partitioning of high-dimensional input space have been studied with the intent of developing homogeneous clusters formed over input and output spaces of variables encountered in system modeling. In this study, we propose a new design methodology of a fuzzy model where the input space is partitioned by making use of sonic classification algorithm, especially, fuzzy K-nearest neighbors (K-NN) classifier being guided by some auxiliary information granules formed in the output space. This classifier being regarded in the context of this design as a supervision mechanism is used to capture the distribution of data over the output space. This type of supervision is beneficial when developing the structure in the input space. It is demonstrated that data involved in a partition constructed by the fuzzy K-NN method realized in the input space show a high level of homogeneity with regard to the data present in the output space. This enhances the performance of the fuzzy rule-based model whose premises in the rules involve partitions formed by the fuzzy K-NN. The design is illustrated with the aid of numeric examples that also provide a detailed insight into the performance of the fuzzy models and quantify several crucial design issues. (C) 2009 Elsevier B.V. All rights reserved.	[Pedrycz, Witold] Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2G7, Canada; [Roh, Seok-Beom; Ahn, Tae-Chon] Wonkwang Univ, Dept Elect & Control Engn, Iksan 570749, Chon Buk, South Korea; [Pedrycz, Witold] Polish Acad Sci, Syst Res Inst, PL-01447 Warsaw, Poland	Pedrycz, W (reprint author), Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2G7, Canada.	nado@wonkwang.ac.kr; tcahn@wonkwang.ac.kr; pedrycz@ee.ualberta.ca			Joosan Scholarship Foundation of Wonkwang University	This paper was supported by Joosan Scholarship Foundation of Wonkwang University in 2007.	Bishop C. M., 1995, NEURAL NETWORKS PATT; Castro JL, 2007, FUZZY SET SYST, V158, P2057, DOI 10.1016/j.fss.2007.04.014; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Destercke S, 2007, FUZZY SET SYST, V158, P2078, DOI 10.1016/j.fss.2007.04.026; Dickerson JA, 1996, IEEE T SYST MAN CY B, V26, P542, DOI 10.1109/3477.517030; ELANAYAR S, 1994, IEEE T NEURAL NETWOR, V5, P594, DOI 10.1109/72.298229; Hastie T, 2001, ELEMENTS STAT LEARNI; Huang GB, 2004, IEEE T SYST MAN CY B, V34, P2284, DOI 10.1109/TSMCB.2004.834428; JANG JSR, 1993, IEEE T NEURAL NETWOR, V4, P156, DOI 10.1109/72.182710; Juang CF, 1998, IEEE T FUZZY SYST, V6, P12; KELLER JM, 1992, IEEE T NEURAL NETWOR, V3, P761, DOI 10.1109/72.159064; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Kim E, 1997, IEEE T FUZZY SYST, V5, P328; Lee C. C., 1990, IEEE T SYST MAN CYB, V20, P418; LEONARD JA, 1992, IEEE T NEURAL NETWOR, V3, P624, DOI 10.1109/72.143377; Lin CH, 2006, FUZZY SET SYST, V157, P1036, DOI 10.1016/j.fss.2005.09.001; Lin CJ, 2008, FUZZY SET SYST, V159, P2890, DOI 10.1016/j.fss.2008.01.020; LIN CT, 1991, IEEE T COMPUT, V40, P1320, DOI 10.1109/12.106218; Liu JW, 2008, FUZZY SET SYST, V159, P2428, DOI 10.1016/j.fss.2008.03.018; Liu ZQ, 1997, IEEE T FUZZY SYST, V5, P209; MENDEL JM, 1995, P IEEE, V83, P345, DOI 10.1109/5.364485; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; Mouzouris GC, 1997, J INTELL FUZZY SYST, V5, P367; Pedrycz W, 2003, IEEE T FUZZY SYST, V11, P652, DOI 10.1109/TFUZZ.2003.817853; Pedrycz W, 1996, PATTERN RECOGN LETT, V17, P625, DOI 10.1016/0167-8655(96)00027-X; Pedrycz W, 1998, IEEE T NEURAL NETWOR, V9, P601, DOI 10.1109/72.701174; Pedrycz W, 1997, IEEE T FUZZY SYST, V5, P256, DOI 10.1109/91.580800; Quinlan JR, 1993, P 10 INT C MACH LEAR, P236; Sarkar M, 2007, FUZZY SET SYST, V158, P2134, DOI 10.1016/j.fss.2007.04.023; Staiano A, 2006, NEUROCOMPUTING, V69, P1570, DOI 10.1016/j.neucom.2005.06.014; SUN CT, 1994, IEEE T FUZZY SYST, V2, P64; TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116; Tsekouras G, 2005, FUZZY SET SYST, V150, P245, DOI 10.1016/j.fss.2004.04.013; Tsipouras MG, 2008, FUZZY SET SYST, V159, P3201, DOI 10.1016/j.fss.2008.04.004; WHITEHEAD BA, 1994, IEEE T NEURAL NETWOR, V5, P15, DOI 10.1109/72.265957	36	5	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114		FUZZY SET SYST	Fuzzy Sets Syst.	JUL 1	2010	161	13					1803	1822		10.1016/j.fss.2009.10.014		20	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	598VP	WOS:000277867500004	
J	Shibata, T; Wada, T				Shibata, Tomoyuki; Wada, Toshikazu			K-D Decision Tree: An Accelerated and Memory Efficient Nearest Neighbor Classifier	IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS			English	Article						nearest neighbor classifier; k-d tree; Voronoi condensing; local nearest neighbor search; safe node; editing	RULE; ALGORITHM	This paper presents a novel algorithm for Nearest Neighbor (NN) classifier. NN classification is a well-known method of pattern classification having the following properties: * it performs maximum-margin classification and achieves less than twice the ideal Bayesian error, * it does not require knowledge of pattern distributions, kernel functions or base classifiers, and * it can naturally be applied to multiclass classification problems. Among the drawbacks are A) inefficient memory use and B) ineffective pattern classification speed. This paper deals with the problems A and B. In most cases. NN search algorithms, such as k-d tree, are employed as a pattern search engine of the NN classifier. However, NN classification does not always require the NN search. Based on this idea, we propose a novel algorithm named k-d decision tree (KDDT). Since KDDT uses Voronoi-condensed prototypes, it consumes less memory than naive NN classifiers. We have confirmed that KDDT is much faster than NN search-based classifier through a comparative experiment (from 9 to 369 times faster than NN search based classifier). Furthermore, in order to extend applicability of the KDDT algorithm to high-dimensional NN classification, we modified it by incorporating Gabriel editing or RNG editing instead of Voronoi condensing. Through experiments using simulated and real data, we have confirmed the modified KDDT algorithms are superior to the original one.	[Shibata, Tomoyuki] Toshiba Co Ltd, Corp Res & Dev Ctr, Kawasaki, Kanagawa 2128582, Japan; [Wada, Toshikazu] Wakayama Univ, Dept Comp & Commun Sci, Wakayama 6408510, Japan	Shibata, T (reprint author), Toshiba Co Ltd, Corp Res & Dev Ctr, Kawasaki, Kanagawa 2128582, Japan.	tomoyuki1.shibata@toshiba.co.jp; twada@ieee.org					Aha D. W., 1991, P DARPA CAS BAS REAS, P147; Aha D.W., 1989, P 11 INT JOINT C ART, P794; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Bhattacharya B., 1981, INT S INF THEOR SANT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Dasarathy BV, 2000, PATTERN ANAL APPL, V3, P19, DOI 10.1007/s100440050003; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; KATO T, 2004, INFORM PROCESSING SO, V45, P110; KATO T, 2004, 17 IAPR INT C PATT R, P135; Merz C. J., 1996, UCI REPOSITORY MACHI; MESSER K, 1999, 2 INT C AVBPA WASH D; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P121; Vapnik V.N., 1995, NATURE STAT LEARNING	20	0	0	IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG	TOKYO	KIKAI-SHINKO-KAIKAN BLDG MINATO-KU SHIBAKOEN 3 CHOME, TOKYO, 105, JAPAN	0916-8532		IEICE T INF SYST	IEICE Trans. Inf. Syst.	JUL	2010	E93D	7					1670	1681		10.1587/transinf.E93.D.1670		12	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	644AF	WOS:000281342100002	
J	Ball, NM; Brunner, RJ				Ball, Nicholas M.; Brunner, Robert J.			DATA MINING AND MACHINE LEARNING IN ASTRONOMY	INTERNATIONAL JOURNAL OF MODERN PHYSICS D			English	Review						Data mining; machine learning; knowledge discovery in databases; astroinformatics; astrostatistics; Virtual Observatory	DIGITAL-SKY-SURVEY; ARTIFICIAL NEURAL-NETWORKS; ESTIMATING PHOTOMETRIC REDSHIFTS; STAR-GALAXY CLASSIFICATION; SUPPORT VECTOR MACHINES; HUBBLE DEEP FIELD; AUTOMATED MORPHOLOGICAL CLASSIFICATION; INDEPENDENT COMPONENT ANALYSIS; BROAD-BAND PHOTOMETRY; LUMINOUS RED GALAXIES	We review the current state of data mining and machine learning in astronomy. Data Mining can have a somewhat mixed connotation from the point of view of a researcher in this field. If used correctly, it can be a powerful approach, holding the potential to fully exploit the exponentially increasing amount of available data, promising great scientific advance. However, if misused, it can be little more than the black box application of complex computing algorithms that may give little physical insight, and provide questionable results. Here, we give an overview of the entire data mining process, from data collection through to the interpretation of results. We cover common machine learning algorithms, such as artificial neural networks and support vector machines, applications from a broad range of astronomy, emphasizing those in which data mining techniques directly contributed to improving science, and important current and future directions, including probability density functions, parallel algorithms, Peta-Scale computing, and the time domain. We conclude that, so long as one carefully selects an appropriate algorithm and is guided by the astronomical problem at hand, data mining can be very much the powerful tool, and not the questionable black box.	[Ball, Nicholas M.] Natl Res Council Canada, Herzberg Inst Astrophys, Victoria, BC V9E 2E7, Canada; [Brunner, Robert J.] Univ Illinois, Dept Astron, Urbana, IL 61801 USA	Ball, NM (reprint author), Natl Res Council Canada, Herzberg Inst Astrophys, 5017 W Saanich Rd, Victoria, BC V9E 2E7, Canada.	nick.ball@nrc-cnrc.gc.ca; bigdog@illinois.edu			NASA [NN6066H156, NNG06GF89G]; Microsoft Research; University of Illinois	The authors acknowledge support from NASA through grants NN6066H156 and NNG06GF89G, from Microsoft Research, and from the University of Illinois.	Aarts E., 1989, SIMULATED ANNEALING; Abdalla FB, 2008, MON NOT R ASTRON SOC, V387, P945, DOI 10.1111/j.1365-2966.2008.12881.x; Abe S., 2005, SUPPORT VECTOR MACHI; ADAMO JM, 2000, DATA MINING ASS RULE; Adams A., 1994, VISTAS ASTRON, V38, P273, DOI 10.1016/0083-6656(94)90037-X; Aggarwal CC, 2008, ADV DATABASE SYST, V34, P1, DOI 10.1007/978-0-387-70992-5; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; AIZERMAN MA, 1964, AUTOMAT REM CONTR, V25, P1175; AMDAHL G, 1967, SPRING JOINT COMPUTE; Andreon S, 2000, MON NOT R ASTRON SOC, V319, P700, DOI 10.1046/j.1365-8711.2000.03700.x; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Babbedge TSR, 2004, MON NOT R ASTRON SOC, V353, P654, DOI 10.1111/j.1365-2966.2004.08105.x; Madduri K, 2008, CH CRC COMP SCI SER, P237; BAILERJONES CAL, 2008, ASTRONOMICAL SOC PAC, V394; Bailer-Jones CAL, 2008, MON NOT R ASTRON SOC, V391, P1838, DOI 10.1111/j.1365-2966.2008.13983.x; BAILERJONES CAL, 2002, AUTOMATED DATA ANAL; Bailer-Jones CAL, 1998, MON NOT R ASTRON SOC, V298, P361, DOI 10.1046/j.1365-8711.1998.01596.x; Bailey S, 2007, ASTROPHYS J, V665, P1246, DOI 10.1086/519832; BALDWIN JA, 1981, PUBL ASTRON SOC PAC, V93, P5, DOI 10.1086/130766; Ball NM, 2008, MON NOT R ASTRON SOC, V383, P907, DOI 10.1111/j.1365-2966.2007.12627.x; Ball NM, 2007, ASTROPHYS J, V663, P774, DOI 10.1086/518362; Ball NM, 2006, ASTROPHYS J, V650, P497, DOI 10.1086/507440; Ball NM, 2004, MON NOT R ASTRON SOC, V348, P1038, DOI 10.1111/j.1365-2966.2004.07429.x; Ball NM, 2008, ASTROPHYS J, V683, P12, DOI 10.1086/589646; Ball NM, 2006, MON NOT R ASTRON SOC, V373, P845, DOI 10.1111/j.1365-2966.2006.11082.x; Bamford SP, 2008, MON NOT R ASTRON SOC, V391, P607, DOI 10.1111/j.1365-2966.2008.13963.x; Banerji M, 2008, MON NOT R ASTRON SOC, V386, P1219, DOI 10.1111/J.1365-2966.2008.13095.X; Barden M, 2008, ASTROPHYS J SUPPL S, V175, P105, DOI 10.1086/524039; Barnes DG, 2006, PUBL ASTRON SOC AUST, V23, P82, DOI 10.1071/AS06009; BAUM W, 1962, IAU S, V15; Bazarghan M, 2008, ASTROPHYS SPACE SCI, V315, P201, DOI 10.1007/s10509-008-9816-5; Bazell D, 2000, MON NOT R ASTRON SOC, V316, P519, DOI 10.1046/j.1365-8711.2000.03525.x; Bazell D, 1998, ASTROPHYS J SUPPL S, V116, P47, DOI 10.1086/313098; Bazell D, 2001, ASTROPHYS J, V548, P219, DOI 10.1086/318696; Bazell D, 2005, ASTROPHYS J, V618, P723, DOI 10.1086/426068; Bazell D, 2006, ASTROPHYS J, V649, P678, DOI 10.1086/506504; Becker AC, 2008, ASTRON NACHR, V329, P280, DOI 10.1002/asna.200710937; BECKER RH, 1995, ASTROPHYS J, V450, P559, DOI 10.1086/176166; BELL G, 2006, IEEE COMPUT, V39, P110; Bell G, 2009, SCIENCE, V323, P1297, DOI 10.1126/science.1170411; Belleman RG, 2008, NEW ASTRON, V13, P103, DOI 10.1016/j.newast.2007.07.004; Benitez N, 2000, ASTROPHYS J, V536, P571, DOI 10.1086/308947; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Bertin E, 1996, ASTRON ASTROPHYS SUP, V117, P393, DOI 10.1051/aas:1996164; BHADURI K, 2006, DISTRIBUTED DATA MIN; Bishop C. M., 2007, PATTERN RECOGNITION; Bishop C. M., 1995, NEURAL NETWORKS PATT; Bogdanos C, 2009, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2009/05/006; BORKIN M, 2007, ASTRONOMICAL SOC PAC, V376; BORNE K, 2008, AM I PHYS C SERIES, V1082; BORNE K, 2009, DATA MIN KNOWL DISC, P91; Bottino M, 2008, MON NOT R ASTRON SOC, V389, P1190, DOI 10.1111/j.1365-2966.2008.13704.x; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BRESCIA M, 2009, MEMORIE SOC ASTRONOM, V80, P565; Brodwin M, 2006, ASTROPHYS J, V651, P791, DOI 10.1086/507838; BROWN SD, 1992, SPRINGER INT SERIES; Brun R, 1997, NUCL INSTRUM METH A, V389, P81, DOI 10.1016/S0168-9002(97)00048-X; Brunner RJ, 1997, ASTROPHYS J, V482, pL21, DOI 10.1086/310674; BRUNNER RJ, 2007, DEV DEPLOYING ADV AL; Budavari T, 2009, ASTROPHYS J, V695, P747, DOI 10.1088/0004-637X/695/1/747; Budavari T, 2008, ASTROPHYS J, V679, P301, DOI 10.1086/587156; Budavari T, 2000, ASTRON J, V120, P1588, DOI 10.1086/301514; Budavari T, 2001, ASTRON J, V122, P1163, DOI 10.1086/322131; Buell D, 2007, COMPUTER, V40, P23, DOI 10.1109/MC.2007.91; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P2; Burl MC, 1998, MACH LEARN, V30, P165, DOI 10.1023/A:1007400206189; BURL MC, 1999, SOC PHOTOOPTICAL INS, V3695; CANTUPAZ E, 2002, GECCO 02; Carballo R, 2004, MON NOT R ASTRON SOC, V353, P211, DOI 10.1111/j.1365-2966.2004.08056.x; Carballo R, 2008, MON NOT R ASTRON SOC, V391, P369, DOI 10.1111/j.1365-2966.2008.13896.x; CARLILES S, 2008, ASTRONOMICAL SOC PAC, V394; CERNY V, 1985, J OPTIMIZ THEORY APP, V45, P41, DOI 10.1007/BF00940812; Chapelle O., 2006, SEMISUPERVISED LEARN; CHARBONNEAU P, 1995, ASTROPHYS J SUPPL S, V101, P309, DOI 10.1086/192242; Chattopadhyay T, 2007, ASTROPHYS J, V667, P1017, DOI 10.1086/520317; CHILINGARIAN IV, 2009, MULTIWAVELENGTH ASTR; Claeskens JF, 2006, MON NOT R ASTRON SOC, V367, P879, DOI 10.1111/j.1365-2966.2006.10024.x; Cohen SH, 2003, ASTRON J, V125, P1762, DOI 10.1086/368367; Coley David A., 1997, INTRO GENETIC ALGORI; Colless M., 2003, ARXIVASTROPH0306581; Collister A, 2007, MON NOT R ASTRON SOC, V375, P68, DOI 10.1111/j.1365-2966.2006.11305.x; Collister AA, 2004, PUBL ASTRON SOC PAC, V116, P345, DOI 10.1086/383254; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; Comparato M, 2007, PUBL ASTRON SOC PAC, V119, P898, DOI 10.1086/521375; Connolly A. J., 2000, ARXIVASTROPH0008187; CONNOLLY AJ, 1995, ASTRON J, V110, P1071, DOI 10.1086/117587; Connolly AJ, 1998, ASTROPHYS J, V499, pL125, DOI 10.1086/311362; Connolly AJ, 1995, ASTRON J, V110, P2655, DOI 10.1086/117720; Connolly AJ, 1999, ASTRON J, V117, P2052, DOI 10.1086/300839; Conselice CJ, 2003, ASTROPHYS J SUPPL S, V147, P1, DOI 10.1086/375001; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; Csabai I, 2000, ASTRON J, V119, P69, DOI 10.1086/301159; Csabai I, 2003, ASTRON J, V125, P580, DOI 10.1086/345883; Cunha CE, 2009, MON NOT R ASTRON SOC, V396, P2379, DOI 10.1111/j.1365-2966.2009.14908.x; D'Abrusco R, 2007, ASTROPHYS J, V663, P752, DOI 10.1086/518020; D'Abrusco R, 2009, MON NOT R ASTRON SOC, V396, P223, DOI 10.1111/j.1365-2966.2009.14754.x; Dasarathy B., 1991, NEAREST NEIGHBOR PAT; De Vaucouleurs G., 1948, Annales d'Astrophysique, V11; de Vaucouleurs G., 1959, HDB PHYSIK, V53, P275; de la Calleja J, 2004, MON NOT R ASTRON SOC, V349, P87, DOI 10.1111/j.1365-2966.2004.07442.x; Dempster A. P., 1977, J ROYAL STAT SOC B, V39, DOI DOI 10.2307/2984875; DERRIERE S, 2004, ASTRONOMICAL SOC PAC, V314; de Theije PAM, 1999, ASTRON ASTROPHYS, V341, P371; DEVAUCOULEURS G, 1956, MEMOIRS COMMONWEALTH, V3; DEVAUCOULEURS G, 1977, EVOLUTION GALAXIES S; DJORGOVSKI SG, 1998, WIDE FIELD SURVEYS C; DJORGOVSKI SG, 2001, ASTRONOMICAL SOC PAC, V225; Djorgovski SG, 2008, ASTRON NACHR, V329, P263, DOI 10.1002/asna.200710948; Dolence J., 2008, 9 LCI INT C HIGH PER; DONALEK C, 2008, AM I PHYS C SERIES V, V1082; DOWLER P, 2008, ASTRONOMICAL SOC PAC, V394; Drake AJ, 2009, ASTROPHYS J, V696, P870, DOI 10.1088/0004-637X/696/1/870; DRAKE AJ, 2007, B AM ASTRON SOC, V38; Duda R., 1973, PATTERN CLASSIFICATI; Duda R.O., 2000, PATTERN CLASSIFICATI; EBCIOGLU K, 2004, COMP DRIV PERF WORKS; EBISUZAKI T, 1993, PUBL ASTRON SOC JPN, V45, P269; EYER L, 2008, AM I PHYS C SERIES, V1082; FaundezAbans M, 1996, ASTRON ASTROPHYS SUP, V116, P395, DOI 10.1051/aas:1996122; FIRMANI C, 2003, REV MEXICANA ASTRONO, V17; Firth AE, 2003, MON NOT R ASTRON SOC, V339, P1195, DOI 10.1046/j.1365-8711.2003.06271.x; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fix E., 1951, 4 USAF SCH AV MED; Fluke CJ, 2009, PUBL ASTRON SOC AUST, V26, P64, DOI 10.1071/AS08025; Folkes SR, 1996, MON NOT R ASTRON SOC, V283, P651; FREEMAN KC, 1970, ASTROPHYS J, V160, P811, DOI 10.1086/150474; FREEMAN M, 2005, IADIS AC; Freitas A. A, 1998, MINING VERY LARGE DA; Gaburov E, 2009, NEW ASTRON, V14, P630, DOI 10.1016/j.newast.2009.03.002; Gao D, 2008, MON NOT R ASTRON SOC, V386, P1417, DOI 10.1111/j.1365-2966.2008.13070.x; GAO D, 2008, ASTRONOMICAL SOC PAC, V394; GARCIA V, 2008, ARXIV08041448; GARDNER JP, 2007, CLADE 07; GOEBEL J, 1989, ASTRON ASTROPHYS, V222, pL5; Goldberg D. E, 1989, GENETIC ALGORITHMS S; Goldberg D.E., 2002, DESIGN INNOVATION LE; GOMEZ EL, 2009, ARXIV09030266; Gonzalez-Solares EA, 2008, MON NOT R ASTRON SOC, V388, P89, DOI 10.1111/j.1365-2966.2008.13399.x; Graham AW, 2005, PUBL ASTRON SOC AUST, V22, P118, DOI 10.1071/AS05001; GRAY AG, 2004, ASTRONOMICAL SOC PAC, V314; Gray J., 2005, MSRTR200510; Gray J., 2002, ARXIVCS0202014; GRAY N, 2008, ASTRONOMICAL SOC PAC, V394; Guglielmetti F, 2009, MON NOT R ASTRON SOC, V396, P165, DOI 10.1111/j.1365-2966.2009.14739.x; Gulati RK, 2000, ASTROPHYS SPACE SCI, V273, P73, DOI 10.1023/A:1002699908879; Gupta R, 2004, ASTROPHYS J SUPPL S, V152, P201, DOI 10.1086/420967; Gwyn SDJ, 1996, ASTROPHYS J, V468, pL77, DOI 10.1086/310237; Hand DJ, 2006, STAT SCI, V21, P1, DOI 10.1214/088342306000000060; Hastie T, 2009, SPRINGER SERIES STAT; Haupt R.L., 2004, PRACTICAL GENETIC AL; Hey S., 2009, 4 PARADIGM DATA INTE; Hodapp KW, 2004, ASTRON NACHR, V325, P636, DOI 10.1002/asna.200410300; Hogg D. W., 2008, ARXIV08074820; Holland J., 1975, ADAPTATION NATURAL A; HOPFIELD JJ, 1986, SCIENCE, V233, P625, DOI 10.1126/science.3755256; Hsieh BC, 2005, ASTROPHYS J SUPPL S, V158, P161, DOI 10.1086/429293; Hubble E., 1936, REALM NEBULAE; Hubble E, 1926, ASTROPHYS J, V64, P321, DOI 10.1086/143018; Huertas-Company M, 2009, ASTRON ASTROPHYS, V497, P743, DOI 10.1051/0004-6361/200811255; Huertas-Company M, 2008, ASTRON ASTROPHYS, V478, P971, DOI 10.1051/0004-6361:20078625; Humason M.L., 1936, Astrophysical Journal, V83, DOI 10.1086/143696; HUT P, 2008, IAU S, V246; Hyvarinen A., 2001, INDEPENDENT COMPONEN; IVEZIC Z, 2008, ARXIV08052366 LSTT C; IVEZIC Z, 2008, AM I PHYS C SERIES, V1082; JARVIS JF, 1981, ASTRON J, V86, P476, DOI 10.1086/112907; JEFFREY W, 1986, ASTROPHYS J, V310, P473, DOI 10.1086/164700; Jin RM, 2005, IEEE T KNOWL DATA EN, V17, P71; Johnston S, 2007, PUBL ASTRON SOC AUST, V24, P174, DOI 10.1071/AS07033; Jolliffe I.T., 2002, SPRINGER SERIES STAT; Kaczmarczik MC, 2009, ASTRON J, V138, P19, DOI 10.1088/0004-6256/138/1/19; Kamath C., 2009, SCI DATA MINING PRAC; Kamath C, 2002, COMPUT SCI ENG, V4, P52, DOI 10.1109/MCISE.2002.1014980; Kamath C, 2008, J PHYS CONF SER, V125, P12094, DOI 10.1088/1742-6596/125/1/012094; Kargupta H., 2000, ADV DISTRIBUTED PARA; Karhunen K., 1947, ANN ACAD SCI FENN A1, V37, P3; Kecman V., 2001, LEARNING SOFT COMPUT; Kelly BC, 2005, ASTRON J, V129, P1287, DOI 10.1086/427999; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kitching T., 2009, ARXIV09013143; Kitsionas S, 2005, ASTRON ASTROPHYS, V434, P475, DOI 10.1051/0004-6361:20041916; Klemela J, 2009, WILEY SERIES PROBABI; Knigge C, 2008, MON NOT R ASTRON SOC, V386, P1426, DOI 10.1111/j.1365-2966.2008.13081.x; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Kohonen T., 2001, SPRINGER SERIES INFO, V30; Kohonen T., 1989, SELF ORG ASS MEMORY; KOO DC, 1999, ASTRONOMICAL SOC PAC, V191; KOO DC, 1985, ASTRON J, V90, P418, DOI 10.1086/113748; KUMAR ND, 2008, THESIS OXFORD U; Lahav O, 1996, MON NOT R ASTRON SOC, V283, P207; LAHAV O, 1995, SCIENCE, V267, P859, DOI 10.1126/science.267.5199.859; LANDSMAN WB, 1993, ASTRONOMICAL SOC PAC, V52; Lanzetta KM, 1996, NATURE, V381, P759, DOI 10.1038/381759a0; Lauberts A., 1989, SURFACE PHOTOMETRY C; Lee T.W., 1998, INDEPENDENT COMPONEN; LEMSON G, 2009, MEMORIE SOC ASTRONOM, V80, P342; Levenberg K., 1944, Quarterly of Applied Mathematics, V2; LEVY S, 2003, IAU S, V208; [李丽丽 Li Lili], 2006, [天文学进展, Progress in Astronomy], V24, P285; Li LL, 2007, CHINESE J ASTRON AST, V7, P448, DOI 10.1088/1009-9271/7/3/16; Li R, 2008, ADV SPACE RES, V42, P1469, DOI 10.1016/j.asr.2007.12.015; Lilly SJ, 2007, ASTROPHYS J SUPPL S, V172, P70, DOI 10.1086/516589; Lintott CJ, 2008, MON NOT R ASTRON SOC, V389, P1179, DOI 10.1111/j.1365-2966.2008.13689.x; LOH ED, 1986, ASTROPHYS J, V303, P154, DOI 10.1086/164062; Lopes PAA, 2007, MON NOT R ASTRON SOC, V380, P1608, DOI 10.1111/j.1365-2966.2007.12203.x; Love M., 1948, PROCESSUS STOCHASTIQ; Lu HL, 2006, ASTRON J, V131, P790, DOI 10.1086/498711; MacQueen J., 1967, P 5 BERK S MATH STAT; MADDOX SJ, 1990, MON NOT R ASTRON SOC, V243, P692; MADGWICK D, 2001, MINING SKY; Madgwick DS, 2003, MON NOT R ASTRON SOC, V338, P197, DOI 10.1046/j.1365-8711.2003.06033.x; Mahabal A, 2008, ASTRON NACHR, V329, P288, DOI 10.1002/asna.200710943; MAHABAL A, 2008, AM I PHYS C SERIES, V1082; Maino D, 2002, MON NOT R ASTRON SOC, V334, P53, DOI 10.1046/j.1365-8711.2002.05425.x; Manteiga M, 2009, ASTRON J, V137, P3245, DOI 10.1088/0004-6256/137/2/3245; Margoniner VE, 2008, ASTROPHYS J, V679, P31, DOI 10.1086/528365; Marquardt D. W., 1963, J SOC IND APPL MATH, VII, P2; Massarotti M, 2001, ASTRON ASTROPHYS, V368, P74, DOI 10.1051/0004-6361:20000553; MCCONNELL SM, 2005, ASTRONOMICAL SOC PAC, V347; McGlynn TA, 2004, ASTROPHYS J, V616, P1284, DOI 10.1086/424955; McLachlan G., 2008, WILEY SERIES PROBABI; MILLER AS, 1993, VISTAS ASTRON, V36, P141, DOI 10.1016/0083-6656(93)90118-4; Miller AS, 1996, MON NOT R ASTRON SOC, V279, P293; MISRA A, 2008, AAS DIVISION PLANETA; Mitchell M., 1998, INTRO GENETIC ALGORI; Mobasher B, 1996, MON NOT R ASTRON SOC, V282, pL7; Molinari E, 1998, ASTRON ASTROPHYS, V330, P447; MOORE A, 2001, MINING SKY; Moore G.E., 1965, ELECTRONICS, V38, P114; MORGAN JN, 1963, J AM STAT ASSOC, V58, P415, DOI 10.2307/2283276; Morgan W. W., 1943, ATLAS STELLAR SPECTR; MORGAN WW, 1958, PUBL ASTRON SOC PAC, V70, P364, DOI 10.1086/127243; MORGAN WW, 1959, PUBL ASTRON SOC PAC, V71, P394, DOI 10.1086/127415; MORGAN WW, 1957, PUBL ASTRON SOC PAC, V69, P291, DOI 10.1086/127075; Mustard JF, 1998, J GEOPHYS RES-PLANET, V103, P19419, DOI 10.1029/98JE01901; Myers AD, 2009, MON NOT R ASTRON SOC, V399, P2279, DOI [10.1111/J.1365-2966.2009.15432.X, 10.1111/j.1365-2966.2009.15432.x]; Naim A, 1997, ASTROPHYS J SUPPL S, V111, P357, DOI 10.1086/313022; Naim A, 1997, ASTROPHYS J, V476, P510, DOI 10.1086/303661; NAIM A, 1995, MON NOT R ASTRON SOC, V275, P567; NAIM A, 1995, MON NOT R ASTRON SOC, V274, P1107; Niemack MD, 2009, ASTROPHYS J, V690, P89, DOI [10.1088/0004-637X/690/1/89, 10.1088/0004-637/690/1/89]; Norman M. L., 2007, ARXIV07051556; OCHSENBEIN F, 2004, INT VIRTUAL OBSERVAT; Odewahn SC, 2002, ASTROPHYS J, V568, P539, DOI 10.1086/339036; ODEWAHN SC, 1992, ASTRON J, V103, P318, DOI 10.1086/116063; ODEWAHN SC, 1994, VISTAS ASTRON, V38, P281, DOI 10.1016/0083-6656(94)90038-8; Odewahn SC, 1996, ASTROPHYS J, V472, pL13, DOI 10.1086/310345; Odewahn SC, 2004, ASTRON J, V128, P3092, DOI 10.1086/425525; ORD S, 2009, ARXIV09020915; Owens EA, 1996, MON NOT R ASTRON SOC, V281, P153; Oyaizu H, 2008, ASTROPHYS J, V674, P768, DOI 10.1086/523666; Padmanabhan N, 2005, MON NOT R ASTRON SOC, V359, P237, DOI 10.1111/j.1365-2966.2005.08915.x; Parker D. B., 1985, TR47 MIT CTR COMP RE; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Patterson F. S., 1940, HARVARD B, V914, P9; PEEL D., 2000, WILEY SERIES PROBABI; Perryman MAC, 2001, ASTRON ASTROPHYS, V369, P339, DOI 10.1051/0004-6361:20010085; Philip NS, 2002, ASTRON ASTROPHYS, V385, P1119, DOI 10.1051/0004-6361:20020219; PHILLIPS NG, 2001, ARXIVASTROPH0108234; Pires S, 2006, ASTRON ASTROPHYS, V455, P741, DOI 10.1051/0004-6361:20053820; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; Pyle D., 1999, MORGAN KAUFMANN SERI; Qin DM, 2003, CHINESE J ASTRON AST, V3, P277; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Ramirez JF, 2001, EXP ASTRON, V12, P163, DOI 10.1023/A:1021899116161; Richards GT, 2001, ASTRON J, V122, P1151, DOI 10.1086/322132; Richards GT, 2009, ASTROPHYS J SUPPL S, V180, P67, DOI 10.1088/0067-0049/180/1/67; Ripley B. D., 2008, PATTERN RECOGNITION; ROBERTS MS, 1994, ANNU REV ASTRON ASTR, V32, P115, DOI 10.1146/annurev.astro.32.1.115; Roberts S., 2001, INDEPENDENT COMPONEN; Rohde DJ, 2006, MON NOT R ASTRON SOC, V369, P2, DOI 10.1111/j.1365-2966.2006.10304.x; Rokach L., 2008, DATA MINING DECISION; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salvato M, 2009, ASTROPHYS J, V690, P1250, DOI 10.1088/0004-637X/690/2/1250; SALZBERG S, 1995, PUBL ASTRON SOC PAC, V107, P279, DOI 10.1086/133551; SALZBERG SL, 1995, DATA MIN KNOWL DISC, V1, P1; Sandage A., 1961, HUBBLE ATLAS GALAXIE; Sandage A., 1994, CARNEGIE ATLAS GALAX; Sandage A, 2005, ANNU REV ASTRON ASTR, V43, P581, DOI 10.1146/annurev.astro.43.112904.104839; Sawicki MJ, 1997, ASTRON J, V113, P1, DOI 10.1086/118231; Scaringi S, 2008, MON NOT R ASTRON SOC, V390, P1339, DOI 10.1111/j.1365-2966.2008.13765.x; Scarpino M., 2008, PROGRAMMING CELL PRO; Schlkopf B., 2001, LEARNING KERNELS SUP; SCOTT DW, 1992, WILEY SERIES PROBABI; Scranton R, 2007, ARXIV07090752; Scranton R., 2005, ARXIVASTROPH0508564; SERRARICART M, 1993, ASTRON J, V106, P1685, DOI 10.1086/116758; SerraRicart M, 1996, ASTRON ASTROPHYS SUP, V115, P195; Sersic J. L., 1968, ATLAS GALAXIAS AUSTR; Shakhnarovich G., 2006, NEAREST NEIGHBOR MET; SHIRASAKI Y, 2005, ASTRONOMICAL SOC PAC, V347; Silverman B.W., 1986, MONOGRAPHS STAT APPL; Singh HP, 1998, MON NOT R ASTRON SOC, V295, P312, DOI 10.1046/j.1365-8711.1998.01255.x; Sivanandam SN, 2007, INTRO GENETIC ALGORI; Slonim N, 2001, MON NOT R ASTRON SOC, V323, P270, DOI 10.1046/j.1365-8711.2001.04125.x; Solorio T, 2005, MON NOT R ASTRON SOC, V363, P543, DOI 10.1111/j.1365-2966.2005.09456.x; Sowards-Emmerd D, 2000, ASTRON J, V119, P2598, DOI 10.1086/301394; SPIEKERMANN G, 1992, ASTRON J, V103, P2102, DOI 10.1086/116215; Springel V, 2005, NATURE, V435, P629, DOI 10.1038/nature03597; STEBBINS J, 1948, ASTROPHYS J, V108, P413, DOI 10.1086/145077; Steinhaus H., 1956, B ACAD POL SCI, V1, P801; Steinwart I, 2008, INFORM SCI STAT, P1; STETSON PB, 1987, PUBL ASTRON SOC PAC, V99, P191, DOI 10.1086/131977; Stone J. V., 2004, INDEPENDENT COMPONEN; STORRIELOMBARDI MC, 1992, MNRAS, V259, P8; STORRIELOMBARDI MC, 1994, VISTAS ASTRON, V38, P331, DOI 10.1016/0083-6656(94)90044-2; STUDENMUND AH, 2005, USING ECONOMETRICS; Suchkov AA, 2005, ASTRON J, V130, P2439, DOI 10.1086/497363; SZALAY AS, 2009, HAW INT C SYST SCI; SZALAY AS, 2002, SPIE ASTRONOMY TELES; SZALAY T, 2008, ARXIV08112055; Tagliaferri R, 2003, NEURAL NETWORKS, V16, P297, DOI 10.1016/S0893-6080(03)00028-5; Taylor CC, 1997, PEDIATR RES, V41, P411, DOI 10.1203/00006450-199703000-00018; TAYLOR JD, 2007, ASTRONOMICAL SOC PAC, V376; TAYLOR M, 2007, ASTRONOMICAL SOC PAC, V374; TAYLOR MB, 2006, ASTRONOMICAL SOC PAC, V351; TAYLOR MB, 2005, ASTRONOMICAL SOC PAC, V347; TISHBY N, 1999, 37 ANN ALL C COMM CO; Titterington D. M., 1985, STAT ANAL FINITE MIX; Tsalmantza P, 2007, ASTRON ASTROPHYS, V470, P761, DOI 10.1051/0004-6361:20077300; URUNKAR N, 2007, HIGHLIGHTS ASTRONOMY, V14, P620; VAIDYA J, 2005, PRIVACY PRESERVING D; VANDENBERGH S, 1976, ASTROPHYS J, V206, P883, DOI 10.1086/154452; VANDENBERGH S, 1960, ASTROPHYS J, V131, P215, DOI 10.1086/146821; VANDENBERGH S, 1960, ASTROPHYS J, V131, P558, DOI 10.1086/146869; van Breukelen C, 2009, MON NOT R ASTRON SOC, V395, P1845, DOI 10.1111/j.1365-2966.2009.14692.x; VANDENBERGH S, 1998, GALAXY MORPHOLOGY CL; VANLAARHIVEN PJM, 1987, SIMULATED ANNEALING; Vanzella E, 2004, ASTRON ASTROPHYS, V423, P761, DOI 10.1051/0004-6361:20040176; Vapnik V, 1999, NATURE STAT LEARNING; VIGNALI C, 2009, MULTIWAVELENGTH ASTR; VONHIPPEL T, 1994, MON NOT R ASTRON SOC, V269, P97; Wadadekar Y, 2005, PUBL ASTRON SOC PAC, V117, P79, DOI 10.1086/427710; Wang D, 2008, CHINESE J ASTRON AST, V8, P119, DOI 10.1088/1009-9271/8/1/13; Wang L, 2005, SUPPORT VECTOR MACHI; Wang Y, 1998, ASTRON J, V116, P2081, DOI 10.1086/300592; Waniak W, 2006, EXP ASTRON, V21, P151, DOI 10.1007/s10686-007-9079-0; Wasserman L, 2005, ALL STAT CONCISE COU; WATANABE M, 2003, STAT SERIES TEXTBOOK; Weaver WB, 1997, ASTROPHYS J, V487, P847, DOI 10.1086/304651; Weinstein MA, 2004, ASTROPHYS J SUPPL S, V155, P243, DOI 10.1086/425355; WEIR N, 1995, ASTRON J, V109, P2401, DOI 10.1086/117459; Weir N, 1995, PUBL ASTRON SOC PAC, V107, P1243, DOI 10.1086/133683; WELGE M, 1999, 12 NAT C HIGH PERF N; Wells D. C., 1981, Astronomy & Astrophysics Supplement Series, V44; WERBOS P, 1974, THESIS HARVARD CAMBR; White RL, 2000, ASTROPHYS J SUPPL S, V126, P133, DOI 10.1086/313300; WHITE RL, 2008, AM I PHYS C SERIES, V1082; Windhorst R, 1999, ASTROPHYS SPACE SCI, V269, P243, DOI 10.1023/A:1017059922502; Witten I., 2005, MORGAN KAUFMANN SERI; Wittman D, 2009, ASTROPHYS J LETT, V700, pL174, DOI 10.1088/0004-637X/700/2/L174; Wolf C, 2003, ASTRON ASTROPHYS, V408, P499, DOI 10.1051/0004-6361:20030990; Wolf C, 2009, MON NOT R ASTRON SOC, V397, P520, DOI 10.1111/j.1365-2966.2009.14953.x; Won E, 2007, NUCL INSTRUM METH A, V581, P816, DOI 10.1016/j.nima.2007.08.163; Wozniak PR, 2004, ASTRON J, V128, P2965, DOI 10.1086/425526; Wu XB, 2004, CHINESE J ASTRON AST, V4, P17; Yip CW, 2004, ASTRON J, V128, P585, DOI 10.1086/422429; Yip CW, 2004, ASTRON J, V128, P2603, DOI 10.1086/425626; York DG, 2000, ASTRON J, V120, P1579, DOI 10.1086/301513; ZAKI MJ, 2002, LECT NOTES ARTIFICIA, V1759; ZHANG C, 2002, LECT NOTES COMPUTER; Zhang YX, 2007, CHINESE J ASTRON AST, V7, P289, DOI 10.1088/1009-9271/7/2/13; Zhang YX, 2003, PUBL ASTRON SOC PAC, V115, P1006, DOI 10.1086/376847; Zhang YX, 2009, MON NOT R ASTRON SOC, V392, P233, DOI 10.1111/j.1365-2966.2008.14022.x; Zhang YX, 2008, ADV SPACE RES, V41, P1949, DOI 10.1016/j.asr.2007.07.019; ZHAO MF, 2007, ASTRON ASTROPHYS, V31, P352; Zhao YH, 2008, ADV SPACE RES, V41, P1955, DOI 10.1016/j.asr.2007.07.020; Zhu X., 2009, SYNTHESIS LECT ARTIF	374	16	17	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-2718		INT J MOD PHYS D	Int. J. Mod. Phys. D	JUL	2010	19	7					1049	1106		10.1142/S0218271810017160		58	Astronomy & Astrophysics	Astronomy & Astrophysics	633KI	WOS:000280500600001	
J	Lee, H; Hong, S; Nizami, IF; Kim, E				Lee, Heesung; Hong, Sungjun; Nizami, Imran Fareed; Kim, Euntai			An efficient design of a nearest neighbor classifier for various-scale problems	PATTERN RECOGNITION LETTERS			English	Article						Genetic algorithm; Nearest neighbor; Editing for the NN; Feature selection	FEATURE-SELECTION; GENETIC ALGORITHM	By appropriate editing of the reference set and judicious selection of features, we can obtain an optimal nearest neighbor (NN) classifier that maximizes the accuracy of classification and saves computational time and memory resources. In this paper, we propose a new method for simultaneous reference set editing and feature selection for a nearest neighbor classifier. The proposed method is based on the genetic algorithm and employs different genetic encoding strategies according to the size of the problem, such that it can be applied to classification problems of various scales. Compared with the conventional methods, the classifier uses some of the considered references and features, not all of them, but demonstrates better classification performance. To demonstrate the performance of the proposed method, we perform experiments on various databases. (C) 2010 Elsevier B.V. All rights reserved.	[Lee, Heesung; Hong, Sungjun; Nizami, Imran Fareed; Kim, Euntai] Yonsei Univ, Sch Elect & Elect Engn, Seoul 120749, South Korea	Kim, E (reprint author), Yonsei Univ, Sch Elect & Elect Engn, C613 Sinchon Dong, Seoul 120749, South Korea.	etkim@yonsei.ac.kr			Korea Science & Engineering Foundation [R01-2006-000-11016-0]	This work was supported by Grant No. R01-2006-000-11016-0 from Basic Research Program of the Korea Science & Engineering Foundation.	Chen JH, 2005, INT J APPROX REASON, V40, P3, DOI 10.1016/j.ijar.2004.11.009; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davis L, 1991, HDB GENETIC ALGORITH; Duda R. O., 2001, PATTERN CLASSIFICATI; Gil-Pita R, 2007, LECT NOTES COMPUT SC, V4881, P1141; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; GOSE E, 1996, PATTEN RECOGNITION I; Hagan M. T., 1995, NEURAL NETWORK DESIG; Hastie T, 2001, ELEMENTS STAT LEARNI; Ho SY, 2002, PATTERN RECOGN LETT, V23, P1495, DOI 10.1016/S0167-8655(02)00109-5; Hong JH, 2006, PATTERN RECOGN LETT, V27, P143, DOI 10.1016/j.patrec.2005.07.009; Hwang JP, 2006, P ICEIC, P98; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; JUO H, 2004, ARTIF INTELL, V17, P919; Kim EY, 2006, PATTERN RECOGN LETT, V27, P1252, DOI 10.1016/j.patrec.2005.07.023; Kuncheva LI, 1999, PATTERN RECOGN LETT, V20, P1149, DOI 10.1016/S0167-8655(99)00082-3; Lee H, 2007, INTEGR COMPUT-AID E, V14, P161; Lee H, 2009, INT J COMPUT MATH, V86, P1105, DOI 10.1080/00207160701724760; Lee H, 2008, ETRI J, V30, P799; Lossos IS, 2000, P NATL ACAD SCI USA, V97, P10209, DOI 10.1073/pnas.180316097; MERELO JJ, 1995, ARTIFICIAL NEURAL NE; Murphy P., 1994, UCI REPOSITORY MACHI	22	1	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	JUL 1	2010	31	9					1020	1027		10.1016/j.patrec.2010.01.001		8	Computer Science, Artificial Intelligence	Computer Science	603CO	WOS:000278186200029	
J	Farcomeni, A				Farcomeni, Alessio			BAYESIAN CONSTRAINED VARIABLE SELECTION	STATISTICA SINICA			English	Article						Constraints; Gibbs sampler; hierarchical models; variable selection	MODEL SELECTION; REGRESSION; LASSO	By building on the stochastic search approach (George and McCulloch (1993)) we propose a strategy for performing constrained variable selection. We discuss hierarchical and grouping constraints, and introduce anti-hierarchical constraints in which the inclusion of a variable forces another to be excluded from the model. We prove consistency results about models receiving maximal posterior probability, and about the median model (Barbieri and Berger (2004)), and discuss extensions to generalized linear models.	Univ Roma La Sapienza, I-00185 Rome, Italy	Farcomeni, A (reprint author), Univ Roma La Sapienza, Piazzale Aldo Moro 5, I-00185 Rome, Italy.	alessio.farcomeni@uniroma1.it					ATKINSON AC, 1978, BIOMETRIKA, V65, P39, DOI 10.1093/biomet/65.1.39; AUTIN F, 2004, MAXISET COMP PROCEDU; Barbieri MM, 2004, ANN STAT, V32, P870, DOI 10.1214/009053604000000238; BERK RH, 1966, ANN MATH STAT, V37, P51, DOI 10.1214/aoms/1177699597; Chipman H., 2001, IMS LECT NOTES MONOG, V38, P67; Cholongitas E, 2006, LIVER TRANSPLANT, V12, P1049, DOI 10.1002/lt.20824; Clyde M. A., 1999, BAYESIAN STAT, V6, P157; Cordell HJ, 2002, HUM MOL GENET, V11, P2463, DOI 10.1093/hmg/11.20.2463; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DELLAPORTAS P, 1993, APPL STAT-J ROY ST C, V42, P443, DOI 10.2307/2986324; Dmochowski J., 1999, BAYESIAN STAT, P543; George EI, 1997, STAT SINICA, V7, P339; GEORGE EI, 1993, J AM STAT ASSOC, V88, P881, DOI 10.2307/2290777; Geweke J., 1996, BAYESIAN STAT, V5, P609; GILKS WR, 1992, APPL STAT-J ROY ST C, V41, P337, DOI 10.2307/2347565; GILKS WR, 1995, APPL STAT-J ROY ST C, V44, P455, DOI 10.2307/2986138; Gustafson P, 2008, ANN APPL STAT, V2, P1478, DOI 10.1214/08-AOAS188; Hans C, 2007, J AM STAT ASSOC, V102, P507, DOI 10.1198/016214507000000121; Hoeting JA, 1999, STAT SCI, V14, P382; Hosmer DW, 1989, APPL LOGISTIC REGRES; Kim Y, 2006, STAT SINICA, V16, P375; King R, 2001, BIOMETRIKA, V88, P317, DOI 10.1093/biomet/88.2.317; Lahiri P, 2001, IMS LECT NOTES MONOG, V38; Lunn DJ, 2000, STAT COMPUT, V10, P325, DOI 10.1023/A:1008929526011; MADIGAN D, 1995, INT STAT REV, V63, P215, DOI 10.2307/1403615; McCullagh P., 1989, GEN LINEAR MODELS; Meier L, 2008, J R STAT SOC B, V70, P53; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Meyer MC, 2002, J AM STAT ASSOC, V97, P859, DOI 10.1198/0162145023886818654; Robert C.P., 1999, MONTE CARLO STAT MET; SCHEFFE H, 1963, ANAL VARIANCE; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Zhao P, 2009, ANN STAT, V37, P3468, DOI 10.1214/07-AOS584; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735	35	4	4	STATISTICA SINICA	TAIPEI	C/O DR H C HO, INST STATISTICAL SCIENCE, ACADEMIA SINICA, TAIPEI 115, TAIWAN	1017-0405		STAT SINICA	Stat. Sin.	JUL	2010	20	3					1043	1062				20	Statistics & Probability	Mathematics	633VA	WOS:000280533600014	
J	Chou, KC; Shen, HB				Chou, Kuo-Chen; Shen, Hong-Bin			Plant-mPLoc: A Top-Down Strategy to Augment the Power for Predicting Plant Protein Subcellular Localization	PLOS ONE			English	Article							AMINO-ACID-COMPOSITION; SUPPORT VECTOR MACHINES; FUNCTIONAL DOMAIN COMPOSITION; COUPLED RECEPTOR CLASSES; LOCATION PREDICTION; APOPTOSIS PROTEINS; GENE ONTOLOGY; EVOLUTION INFORMATION; APPROXIMATE ENTROPY; STRUCTURAL CLASSES	One of the fundamental goals in proteomics and cell biology is to identify the functions of proteins in various cellular organelles and pathways. Information of subcellular locations of proteins can provide useful insights for revealing their functions and understanding how they interact with each other in cellular network systems. Most of the existing methods in predicting plant protein subcellular localization can only cover three or four location sites, and none of them can be used to deal with multiplex plant proteins that can simultaneously exist at two, or move between, two or more different location sits. Actually, such multiplex proteins might have special biological functions worthy of particular notice. The present study was devoted to improve the existing plant protein subcellular location predictors from the aforementioned two aspects. A new predictor called "Plant-mPLoc'' is developed by integrating the gene ontology information, functional domain information, and sequential evolutionary information through three different modes of pseudo amino acid composition. It can be used to identify plant proteins among the following 12 location sites: (1) cell membrane, (2) cell wall, (3) chloroplast, (4) cytoplasm, (5) endoplasmic reticulum, (6) extracellular, (7) Golgi apparatus, (8) mitochondrion, (9) nucleus, (10) peroxisome, (11) plastid, and (12) vacuole. Compared with the existing methods for predicting plant protein subcellular localization, the new predictor is much more powerful and flexible. Particularly, it also has the capacity to deal with multiple-location proteins, which is beyond the reach of any existing predictors specialized for identifying plant protein subcellular localization. As a user-friendly web-server, Plant-mPLoc is freely accessible at http://www.csbio.sjtu.edu.cn/bioinf/plant-multi/. Moreover, for the convenience of the vast majority of experimental scientists, a step-by-step guide is provided on how to use the web-server to get the desired results. It is anticipated that the Plant-mPLoc predictor as presented in this paper will become a very useful tool in plant science as well as all the relevant areas.	[Chou, Kuo-Chen; Shen, Hong-Bin] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China; [Chou, Kuo-Chen; Shen, Hong-Bin] Gordon Life Sci Inst, San Diego, CA USA	Chou, KC (reprint author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China.	kcchou@gordonlifescience.org	Chou, Kuo-Chen/A-8340-2009		National Natural Science Foundation of China [60704047]; Science and Technology Commission of Shanghai Municipality [08ZR1410600, 08JC1410600]; Shanghai Pujiang Program	This work was supported by the National Natural Science Foundation of China (Grant No. 60704047), Science and Technology Commission of Shanghai Municipality (Grant No. 08ZR1410600, 08JC1410600) and sponsored by the Shanghai Pujiang Program. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.	Ashburner M, 2000, NAT GENET, V25, P25; Barrell D, 2009, NUCLEIC ACIDS RES, V37, pD396, DOI 10.1093/nar/gkn803; Cai YD, 2003, BIOPHYS J, V84, P3257; Camon E, 2003, GENOME RES, V13, P662, DOI 10.1101/gr.461403; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; Chen C, 2009, PROTEIN PEPTIDE LETT, V16, P27; Chen K, 2008, J COMPUT CHEM, V29, P1596, DOI 10.1002/jcc.20918; Chou K. C., 2009, OPEN BIOINFORMATICS, V3, P31; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2008, BIOCHEM BIOPH RES CO, V376, P321, DOI 10.1016/j.bbrc.2008.08.125; Chou KC, 2004, BIOCHEM BIOPH RES CO, V316, P636, DOI 10.1016/j.bbrc.2004.02.098; Chou KC, 2007, ANAL BIOCHEM, V370, P1, DOI 10.1016/j.ab.2007.07.006; Chou KC, 2008, NAT PROTOC, V3, P153, DOI 10.1038/nprot.2007.494; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; Chou KC, 2007, J CELL BIOCHEM, V100, P665, DOI 10.1002/jcb.21096; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2004, CURR MED CHEM, V11, P2105; CHOU KC, 1994, J BIOL CHEM, V269, P22014; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2007, BIOCHEM BIOPH RES CO, V360, P339, DOI 10.1016/j.bbrc.2007.06.027; Chou KC, 2009, CURR PROTEOMICS, V6, P262; Chou KC, 2007, J PROTEOME RES, V6, P1728, DOI 10.1021/pr060635i; CHOU KC, 1995, FEBS LETT, V363, P123, DOI 10.1016/0014-5793(95)00240-A; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Ding H, 2009, PROTEIN PEPTIDE LETT, V16, P351; Ding YS, 2008, PATTERN RECOGN LETT, V29, P1887, DOI 10.1016/j.patrec.2008.06.007; Ehrlich JS, 2002, DEV CELL, V3, P259, DOI 10.1016/S1534-5807(02)00216-2; Emanuelsson O, 2000, J MOL BIOL, V300, P1005, DOI 10.1006/jmbi.2000.3903; Esmaeili M, 2010, J THEOR BIOL, V263, P203, DOI 10.1016/j.jtbi.2009.11.016; Finn R., 2006, NUCLEIC ACIDS RES, V34, P247; Georgiou DN, 2009, J THEOR BIOL, V257, P17, DOI 10.1016/j.jtbi.2008.11.003; Gerstein M, 2003, CURR OPIN STRUC BIOL, V13, P341, DOI 10.1016/S0959-440X(03)00080-0; Glory E, 2007, DEV CELL, V12, P7, DOI 10.1016/j.devcel.2006.12.007; Gonzalez-Diaz H, 2008, PROTEOMICS, V8, P750, DOI 10.1002/pmic.200700638; Gu Q, 2010, PROTEIN PEPTIDE LETT, V17, P559; He ZS, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0009603; Jiang XY, 2008, PROTEIN PEPTIDE LETT, V15, P392, DOI 10.2174/092986608784246443; JIANG Y, 2008, J COMPUT CHEM; Letunic I, 2006, NUCLEIC ACIDS RES, V34, P257; Li FM, 2008, PROTEIN PEPTIDE LETT, V15, P612, DOI 10.2174/092986608784966930; Lin H, 2008, PROTEIN PEPTIDE LETT, V15, P739, DOI 10.2174/092986608785133681; Lin H, 2009, ACTA BIOTHEOR, V57, P321, DOI 10.1007/s10441-008-9067-4; Lin H, 2008, J THEOR BIOL, V252, P350, DOI 10.1016/j.jtbi.2008.02.004; Loewenstein Y, 2009, GENOME BIOL, V10, DOI 10.1186/gb-2009-10-2-207; Marchler-Bauer A., 2007, NUCLEIC ACIDS RES, V35, P237, DOI DOI 10.1093/NAR/GKL951; Matsuda S, 2005, PROTEIN SCI, V14, P2804, DOI 10.1110/ps.051597405; Millar AH, 2009, PLANT CELL, V21, P1625, DOI 10.1105/tpc.109.066019; Murvai J, 2001, NUCLEIC ACIDS RES, V29, P58, DOI 10.1093/nar/29.1.58; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Tatusov RL, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-41; PIERLEONI A, 2006, BIOINFORMATICS, V22, P408; Qiu JD, 2009, ANAL BIOCHEM, V390, P68, DOI 10.1016/j.ab.2009.04.009; Schaffer AA, 2001, NUCLEIC ACIDS RES, V29, P2994, DOI 10.1093/nar/29.14.2994; Schnell JR, 2008, NATURE, V451, P591, DOI 10.1038/nature06531; Shafer G., 1976, MATH THEORY EVIDENCE; Shen H. B., 2009, J BIOMED SCI ENG, V2, P136, DOI DOI 10.4236/JBISE.2009.23024; Shen HB, 2005, BIOCHEM BIOPH RES CO, V334, P288, DOI 10.1016/j.bbrc.2005.06.087; Small I, 2004, PROTEOMICS, V4, P1581, DOI 10.1002/pmic.200300776; Smith C, 2008, SUBCELLULAR TARGETIN; Wang JF, 2009, NAT STRUCT MOL BIOL, V16, P1267, DOI 10.1038/nsmb.1707; Yang JY, 2009, J THEOR BIOL, V257, P618, DOI 10.1016/j.jtbi.2008.12.027; Zeng YH, 2009, J THEOR BIOL, V259, P366, DOI 10.1016/j.jtbi.2009.03.028; Zhang GY, 2008, J THEOR BIOL, V253, P310, DOI 10.1016/j.jtbi.2008.03.015; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou XB, 2007, J THEOR BIOL, V248, P546, DOI 10.1016/j.jtbi.2007.06.001; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565	69	135	136	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	185 BERRY ST, STE 1300, SAN FRANCISCO, CA 94107 USA	1932-6203		PLOS ONE	PLoS One	JUN 28	2010	5	6							e11335	10.1371/journal.pone.0011335		11	Multidisciplinary Sciences	Science & Technology - Other Topics	617DB	WOS:000279259900008	
J	Vauclin, S; Gardin, I; Doyeux, K; Hapdey, S; Edet-Sanson, A; Vera, P				Vauclin, S.; Gardin, I.; Doyeux, K.; Hapdey, S.; Edet-Sanson, A.; Vera, P.			F-18-FDG PET image segmentation. Principles and literature reviewing	MEDECINE NUCLEAIRE-IMAGERIE FONCTIONNELLE ET METABOLIQUE			French	Review						Segmentation; F-18-FDG PET Imaging	POSITRON-EMISSION-TOMOGRAPHY; TARGET VOLUME DELINEATION; CELL LUNG-CANCER; FDG-PET; THRESHOLD SEGMENTATION; AUTOMATIC SEGMENTATION; ONCOLOGICAL PET; EDGE-DETECTION; TUMOR VOLUME; MODEL	Several segmentation methods of lesion uptake in F-18-FDG PET imaging have been proposed in the literature. Their principles are presented along with their clinical results. The main approach proposed in the literature is the thresholding method. The most commonly used is a constant threshold around 40% of the maximum uptake within the lesion. This simple approach is not valid for small (<4 or 5 mL), poorly contrasted positive tissue (SUV < 2) or lesion in movement. To limit these problems, more complex thresholding algorithms have been proposed to define the optimal threshold value to be applied to segment the lesion. The principle is to adapt the threshold following a fitting model according to one or two characteristic image parameters. Those algorithms based on iterative approaches to find the optimal threshold value are preferred as they take into account patient data. The main drawback is the need of a calibration step depending on the PET device, the acquisition conditions and the algorithm used for image reconstruction. To avoid this problem, some more sophisticated segmentation methods have been proposed in the literature: derivative methods, watershed and pattern recognition algorithms. The delineation of positive tissue on FDG-PET images is a complex problem, always under investigation. (C) 2010 Elsevier Masson SAS. All rights reserved.	[Vauclin, S.; Gardin, I.; Doyeux, K.; Hapdey, S.; Edet-Sanson, A.; Vera, P.] Univ Rouen, Lab LITIS, EA 4108, F-76801 St Etienne, France; [Vauclin, S.; Doyeux, K.] Siemens Med Solut, F-93527 St Denis, France; [Gardin, I.; Hapdey, S.; Edet-Sanson, A.; Vera, P.] Ctr Hosp Univ Rouen, Ctr Henri Becquerel, Dept Nucl Med, F-76038 Rouen, France	Gardin, I (reprint author), Univ Rouen, Lab LITIS, EA 4108, Ave Univ,BP 8, F-76801 St Etienne, France.	Isabelle.gardin@rouen.fnclcc.fr					ALPARSLAN E, 1980, SIGNAL PROCESS, V2, P179, DOI 10.1016/0165-1684(80)90009-2; Aristophanous M, 2007, MED PHYS, V34, P4223, DOI 10.1118/1.2791035; Aykac D, 2003, IEEE T MED IMAGING, V22, P940, DOI 10.1109/TMI.2003.815905; Barra V, 2001, IEEE T MED IMAGING, V20, P549, DOI 10.1109/42.932740; BESAG J, 1986, J ROY STAT SOC B MET, V48, P259; Beucher S., 1993, MATH MORPHOLOGY IMAG, P433; Beucher S., 1979, P INT WORKSH IM PROC, P17; Bezdek J., 1981, PATTERN RECOGNITION; Black QC, 2004, INT J RADIAT ONCOL, V60, P1272, DOI 10.1016/j.ijrobp.2004.06.254; BOUCHONMEUNIER B, 2007, LOGIQUC FLOUC QUE SA; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679; Chellappa R., 1993, MARKOV RANDOM FIELDS; Chen CH, 1999, J NUCL MED, V40, P118; CHEN JL, 2001, COMPUTER SCI, P468; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daisne JF, 2003, RADIOTHER ONCOL, V69, P237, DOI 10.1016/j.radonc.2003.10.009; Daisne JF, 2004, RADIOLOGY, V233, P93, DOI 10.1148/radiol.2331030660; Daisne JF, 2003, RADIOTHER ONCOL, V69, P247, DOI 10.1016/S0167-8140(03)00270-6; DEMPSTER AP, 1967, ANN MATH STAT, V38, P325, DOI 10.1214/aoms/1177698950; DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164; DIGABEL H, 1997, 2 EUR S QUAL AN MICR, P85; Drever L, 2006, MED PHYS, V33, P1583, DOI 10.1118/1.2198308; Drever L, 2007, MED PHYS, V34, P1253, DOI 10.1118/1.2712043; Drever L, 2007, J APPL CLIN MED PHYS, V8, P93; DUDA RO, 1973, CLASSICATION SCENE A; Erdi YE, 1997, CANCER, V80, P2505, DOI 10.1002/(SICI)1097-0142(19971215)80:12+<2505::AID-CNCR24>3.3.CO;2-B; Esnault J M, 2007, Medecine Nucleaire, V31, DOI 10.1016/j.mednuc.2006.12.009; Fernandez LL, 2005, ARQ NEURO-PSIQUIAT, V63, P1, DOI 10.1590/S0004-282X2005000100001; Fix E, 1951, DISCRIMINATORY ANAL; FU KS, 1981, PATTERN RECOGN, V13, P3, DOI 10.1016/0031-3203(81)90028-5; Geets X, 2007, EUR J NUCL MED MOL I, V34, P1427, DOI 10.1007/s00259-006-0363-4; German S., 1984, IEEE T PATTERN ANAL, V6, P721; Green AJ, 2008, EUR J NUCL MED MOL I, V35, P393, DOI 10.1007/s00259-007-0602-3; Guan HY, 2006, IEEE IMAGE PROC, P85, DOI 10.1109/ICIP.2006.312368; Hatt M, 2007, PHYS MED BIOL, V52, P3467, DOI 10.1088/0031-9155/52/12/010; Jentzen W, 2007, J NUCL MED, V48, P108; Kass M., 1988, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KHATCHADOURIAN S, 2006, 6 IFAC S MOD CONTR B; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Krohn T, 2007, NUKLEARMED-NUCL MED, V46, P141, DOI 10.1160/nukmed-0052; MacQueen JB, 1967, P 5 BERK S MATH STAT, P281; Montgomery DWG, 2007, MED PHYS, V34, P722, DOI 10.1118/1.2432404; Nestle U, 2005, J NUCL MED, V46, P1342; Nestle U, 2007, EUR J NUCL MED MOL I, V34, P453, DOI 10.1007/s00259-006-0252-x; Nestle U, 2009, PHYS MED BIOL, V54, pR1, DOI 10.1088/0031-9155/54/1/R01; Pham DL, 2000, ANNU REV BIOMED ENG, V2, P315, DOI 10.1146/annurev.bioeng.2.1.315; POTESIL V, 2007, PROG BIOMED OPT IMAG, V8, P1; RIDDELL C, 1998, IEEE NUCL SCI S C RE, P1912; Rietzel E, 2005, INT J RADIAT ONCOL, V61, P1535, DOI 10.1016/j.ijrobp.2004.11.037; ROBERTS LG, 1965, MACHINE PERCEPTION 3, P159; Rosenfeld A., 1970, PICTURE PROCESSING P; SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9; SCHURMANN J, 1996, PATTERN CLASSICATION; SHAFER G, 1976, MATHEMATICAL THEORY; Shattuck DW, 2001, NEUROIMAGE, V13, P856, DOI 10.1016/j.neuroimage.2008.10.066; Shen G, 2007, MED PHYS, V34, P2395, DOI 10.1118/1.2760624; SMETS P, 1992, INT J INTELL SYST, V7, P37, DOI 10.1002/int.4550070106; SOBEL I, 1978, COMPUT VISION GRAPH, V8, P127, DOI 10.1016/S0146-664X(78)80020-3; Sonka M, 1996, IEEE T MED IMAGING, V15, P314, DOI 10.1109/42.500140; Soret M, 2007, J NUCL MED, V48, P932, DOI 10.2967/jnumed.106.035774; Tylski P, 2010, J NUCL MED, V51, P268, DOI 10.2967/jnumed.109.066241; Tylski P, 2006, IEEE NUCL SCI CONF R, P2063, DOI 10.1109/NSSMIC.2006.354319; Vauclin S, 2009, PHYS MED BIOL, V54, P6901, DOI 10.1088/0031-9155/54/22/010; Yaremko B, 2005, PHYS MED BIOL, V50, P5969, DOI 10.1088/0031-9155/50/24/014; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; ZHANG P, 2006, THESIS U ROUEN	66	2	2	ELSEVIER FRANCE-EDITIONS SCIENTIFIQUES MEDICALES ELSEVIER	PARIS	23 RUE LINOIS, 75724 PARIS, FRANCE	0928-1258		MED NUCL	Med. Nucl.-Imag. Fonct. Metab.	JUN	2010	34	6					358	369		10.1016/j.mednuc.2010.03.005		12	Pathology	Pathology	615JX	WOS:000279132300005	
J	Gu, SC; Tan, Y; He, XG				Gu, Suicheng; Tan, Ying; He, Xingui			Discriminant analysis via support vectors	NEUROCOMPUTING			English	Article						Discriminant analysis via support vectors; Fisher's criteria; Linear discriminant analysis; Regularized discriminant analysis	DIMENSIONALITY REDUCTION; FACE RECOGNITION; EIGENFACES; FRAMEWORK; SELECTION	In this paper, we show how support vector machine (SVM) can be employed as a powerful tool for k-nearest neighbor (kNN) classifier. A novel multi-class dimensionality reduction approach, discriminant analysis via support vectors (SVDA), is proposed. First, the SVM is employed to compute an optimal direction to discriminant each two classes. Then, the criteria of class separability is constructed. At last, the projection matrix is computed. The kernel mapping idea is used to derive the non-linear version, kernel discriminant via support vectors (SVKD). In SVDA, only support vectors are involved to compute the transformation matrix. Thus, the computational complexity can be greatly reduced for kernel based feature extraction. Experiments carried out on several standard databases show a clear improvement on LDA-based recognition. (C) 2010 Elsevier B.V. All rights reserved.	[Gu, Suicheng; Tan, Ying; He, Xingui] Peking Univ, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China; [Gu, Suicheng; Tan, Ying; He, Xingui] Peking Univ, Dept Machine Intelligence, Sch Elect Engn & Comp Sci, Beijing 100871, Peoples R China	Tan, Y (reprint author), Peking Univ, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China.	ytan@pku.edu.cn			National Natural Science Foundation of China (NSFC) [60875080, 60673020]; National High Technology Research and Development Program of China (863 Program) [2007AA01Z453]	This work was supported by National Natural Science Foundation of China (NSFC), under Grant no. 60875080 and 60673020, and also partially supported by the National High Technology Research and Development Program of China (863 Program), with Grant no. 2007AA01Z453.	Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bi J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753643; BIAN W, 2008, IEEE INT C PATT REC, P1; CAI D, 2007, IJCAL; CHEN LF, 2001, PATTERN RECOGN, P1713; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CU S, 2010, SCI CHINA F; Duda R., 1973, PATTERN CLASSIFICATI; Fan RE, 2005, J MACH LEARN RES, V6, P1889; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; He XF, 2005, IEEE T PATTERN ANAL, V27, P328; KOCSOR A, 2004, ECML; Li XL, 2008, IEEE T SYST MAN CY B, V38, P342, DOI 10.1109/TSMCB.2007.911536; Liu W, 2008, IEEE DATA MINING, P433, DOI 10.1109/ICDM.2008.101; PANG Y, INT J COMPUTER MATH; Pang YW, 2008, IEEE T CIRC SYST VID, V18, P989, DOI 10.1109/TCSVT.2008.924108; Pang YW, 2008, IEEE T SYST MAN CY B, V38, P1176, DOI 10.1109/TSMCB.2008.923151; Pang YW, 2009, IEEE T IMAGE PROCESS, V18, P903, DOI 10.1109/TIP.2008.2011167; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Tao DC, 2009, IEEE T PATTERN ANAL, V31, P260, DOI 10.1109/TPAMI.2008.70; TORRESANI L, 2006, NIPS; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Vapnik V.N., 1995, NATURE STAT LEARNING; Weinberger KQ, 2006, NIPS; Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598; YUAN Y, 2008, IEEE INT C SYST MAN, P2231; Zhang T., 2008, ECCV 08, P725; Zhang TH, 2008, IEEE IJCNN, P1670; Zhang TH, 2009, IEEE T KNOWL DATA EN, V21, P1299, DOI 10.1109/TKDE.2008.212	29	4	4	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	JUN	2010	73	10-12			SI		1669	1675		10.1016/j.neucom.2009.09.021		7	Computer Science, Artificial Intelligence	Computer Science	615KL	WOS:000279134100017	
J	Sotoca, JM; Pla, F				Martinez Sotoca, Jose; Pla, Filiberto			Supervised feature selection by clustering using conditional mutual information-based distances	PATTERN RECOGNITION			English	Article						Supervised feature selection; Clustering; Conditional mutual information	INPUT FEATURE-SELECTION; CLASSIFICATION	In this paper, a supervised feature selection approach is presented, which is based on metric applied on continuous and discrete data representations. This method builds a dissimilarity space using information theoretic measures, in particular conditional mutual information between features with respect to a relevant variable that represents the class labels. Applying a hierarchical clustering, the algorithm searches for a compression of the information contained in the original set of features. The proposed technique is compared with other state of art methods also based on information measures. Eventually, several experiments are presented to show the effectiveness of the features selected from the point of view of classification accuracy. (C) 2010 Elsevier Ltd. All rights reserved.	[Martinez Sotoca, Jose; Pla, Filiberto] Univ Jaume 1, Inst New Imaging Technol, Dept Llenguatges & Sistemes Informat, Castellon de La Plana 12071, Spain	Sotoca, JM (reprint author), Univ Jaume 1, Inst New Imaging Technol, Dept Llenguatges & Sistemes Informat, Campus Riu Sec, Castellon de La Plana 12071, Spain.	sotoca@lsi.uji.es; pla@lsi.uji.es			Spanish Ministry of Science and Education [CSD2007-00018]; Spanish CICYT [AYA2008-059665-004-04]; Fundacio Caixa-Castello [P1-1B2007-48, P1-1B2009-45]	This work has been partially supported by the Spanish Ministry of Science and Education under Project CSD2007-00018, AYA2008-059665-004-04 from the Spanish CICYT, P1-1B2007-48 and P1-1B2009-45 (Fundacio Caixa-Castello).	BAKER LD, 1998, 21 ACM INT C RES DEV, P96; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Breiman L, 1984, CLASSIFICATION REGRE; Cover T. M., 1991, ELEMENTS INFORM THEO; COVER TM, 1974, IEEE T SYST MAN CYB, VSMC4, P116; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; Dash M., 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; Dhillon I. S., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753661; Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Guyon I., 2006, SERIES STUDIES FUZZI; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; JOHNSONGENTILE K, 1994, J EDUC COMPUT RES, V11, P121; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Kwak N, 2002, IEEE T PATTERN ANAL, V24, P1667, DOI 10.1109/TPAMI.2002.1114861; Kwak N, 2002, IEEE T NEURAL NETWOR, V13, P143, DOI 10.1109/72.977291; LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115; Murphy P. M., 1995, UCI REPOSITORY MACHI; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226; PEREIRA F, 1993, 31ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P183; PUDIL P, 1994, PATTERN RECOGN, V2, P279, DOI 10.1109/ICPR.1994.576920; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; Slonim N., 1999, P ADV NEUR INF PROC, P617; TISHBY N, 1999, 37 ANN ALL C URB U I; Ward JJ, 1963, AM STAT ASS J, V58, P236; Yeung R. W., 2002, 1 COURSE INFORM THEO	30	20	24	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	JUN	2010	43	6					2068	2081		10.1016/j.patcog.2009.12.013		14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	574KJ	WOS:000275987700007	
J	Derrac, J; Garcia, S; Herrera, F				Derrac, Joaquin; Garcia, Salvador; Herrera, Francisco			IFS-CoCo: Instance and feature selection based on cooperative coevolution with nearest neighbor rule	PATTERN RECOGNITION			English	Article						Evolutionary algorithms; Feature selection; Instance selection; Cooperative coevolution; Nearest neighbor	FEATURE SUBSET-SELECTION; EVOLUTIONARY PROTOTYPE SELECTION; MULTIPLE DATA SETS; GENETIC ALGORITHM; CLASSIFICATION PROBLEMS; STATISTICAL COMPARISONS; LEARNING ALGORITHMS; REDUCTION SCHEMES; NEURAL-NETWORKS; COMPLEXITY	Feature and instance selection are two effective data reduction processes which can be applied to classification tasks obtaining promising results. Although both processes are defined separately, it is possible to apply them simultaneously. This paper proposes an evolutionary model to perform feature and instance selection in nearest neighbor classification. It is based on cooperative coevolution, which has been applied to many computational problems with great success. The proposed approach is compared with a wide range of evolutionary feature and instance selection methods for classification. The results contrasted through non-parametric statistical tests show that our model outperforms previously proposed evolutionary approaches for performing data reduction processes in combination with the nearest neighbor rule. (C) 2009 Elsevier Ltd. All rights reserved.	[Derrac, Joaquin; Herrera, Francisco] Univ Granada, CITIC UGR Res Ctr Informat & Commun Technol, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain; [Garcia, Salvador] Univ Jaen, Dept Comp Sci, Jaen 23071, Spain	Derrac, J (reprint author), Univ Granada, CITIC UGR Res Ctr Informat & Commun Technol, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain.	jderrac@decsai.ugr.es; sglopez@ujaen.es; herrera@decsai.ugr.es	Herrera, Francisco/C-6856-2008	Herrera, Francisco/0000-0002-7283-312X	 [TIN2008-06681-006-01]	This work was supported by Project TIN2008-06681-006-01.	Ahn H, 2009, APPL SOFT COMPUT, V9, P599, DOI 10.1016/j.asoc.2008.08.002; Alpaydin E, 2004, INTRO MACHINE LEARNI; Asuncion A., 2007, UCI REPOSITORY MACHI; Bala J, 1996, EVOL COMPUT, V4, P297, DOI 10.1162/evco.1996.4.3.297; Bandyopadhyay S, 2008, PATTERN RECOGN, V41, P1338, DOI 10.1016/j.patcog.2007.10.003; Ben-David A, 2007, ENG APPL ARTIF INTEL, V20, P875, DOI 10.1016/j.engappai.2007.01.001; Bezdek JC, 2001, INT J INTELL SYST, V16, P1445, DOI 10.1002/int.1068; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Cano JR, 2005, PATTERN RECOGN LETT, V26, P953, DOI 10.1016/j.patrec.2004.09.043; Cano JR, 2008, PATTERN RECOGN LETT, V29, P2156, DOI 10.1016/j.patrec.2008.08.001; Cano JR, 2003, IEEE T EVOLUT COMPUT, V7, P561, DOI 10.1109/TEVC.2003.819265; Cano JR, 2007, DATA KNOWL ENG, V60, P90, DOI 10.1016/j.datak.2006.01.008; Casillas J, 2001, INFORM SCIENCES, V136, P135, DOI 10.1016/S0020-0255(01)00147-5; Cohen J, 1960, EDUC PSYCHOL MEAS, V20, P46; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Demsar J, 2006, J MACH LEARN RES, V7, P1; Eiben A. E., 2003, INTRO EVOLUTIONARY C; Eshelman L., 1991, FDN GENETIC ALGORITH, P265; Freitas A.A., 2002, DATA MINING KNOWLEDG; Garcia S, 2008, PATTERN RECOGN, V41, P2693, DOI 10.1016/j.patcog.2008.02.006; Garcia S, 2008, J MACH LEARN RES, V9, P2677; Garcia-Pedrajas N, 2007, PATTERN RECOGN, V40, P80, DOI 10.1016/j.patcog.2006.06.024; Ghosh A, 2005, EVOLUTIONARY COMPUTA; Gil-Pita R, 2008, INT J NEURAL SYST, V18, P1; Gonzalez A, 2001, IEEE T SYST MAN CY B, V31, P417, DOI 10.1109/3477.931534; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Haro-Garcia Aida, 2009, Data Mining and Knowledge Discovery, V18, DOI 10.1007/s10618-008-0121-2; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Ho SY, 2002, PATTERN RECOGN LETT, V23, P1495, DOI 10.1016/S0167-8655(02)00109-5; Ho TK, 2002, IEEE T PATTERN ANAL, V24, P289; Hofbauer J., 1998, EVOLUTIONARY GAMES P; Inza I, 2001, INT J APPROX REASON, V27, P143, DOI 10.1016/S0888-613X(01)00038-X; Ishibuchi H., 2001, INSTANCE SELECTION C, P95; Ishibuchi H, 1999, LECT NOTES ARTIF INT, V1585, P82; Jankowski N, 2004, LECT NOTES ARTIF INT, V3070, P598; Kim KJ, 2006, EXPERT SYST APPL, V30, P519, DOI 10.1016/j.eswa.2005.10.007; Kim SW, 2003, PATTERN ANAL APPL, V6, P232, DOI 10.1007/s10044-003-0191-0; Kim SW, 2007, PATTERN RECOGN, V40, P2946, DOI 10.1016/j.patcog.2007.03.006; Kim SW, 2009, PATTERN RECOGN, V42, P2695, DOI 10.1016/j.patcog.2009.04.019; Kira K., 1992, P 9 INT C MACH LEARN, P249; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kolesnikov A, 2005, PATTERN RECOGN, V38, P381, DOI 10.1016/j.patcog.2004.07.005; Kuncheva LI, 1999, PATTERN RECOGN LETT, V20, P1149, DOI 10.1016/S0167-8655(99)00082-3; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; Li Y, 2009, PATTERN RECOGN, V42, P1914, DOI 10.1016/j.patcog.2008.10.011; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; Liu H., 2001, INSTANCE SELECTION C; Liu H., 1998, FEATURE SELECTION KN; LIU H, 1996, 9 INT C IND ENG APPL, P419; Liu H., 2005, IEEE T KNOWL DATA EN, V17, P1, DOI 10.1109/TKDE.2005.56; Liu H, 2008, CH CRC DATA MIN KNOW, P3; Liu H, 2002, DATA MIN KNOWL DISC, V6, P115, DOI 10.1023/A:1014056429969; Marchiori E, 2008, J MACH LEARN RES, V9, P997; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; Olvera-Lopez JA, 2010, PATTERN ANAL APPL, V13, P131, DOI 10.1007/s10044-008-0142-x; PANAIT L, 2003, INT JOINT C ART INT, P653; Panait L, 2006, GECCO 2006: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2, P345; Paredes R, 2006, IEEE T PATTERN ANAL, V28, P1100, DOI 10.1109/TPAMI.2006.145; Perner P, 2008, APPL INTELL, V28, P238, DOI 10.1007/s10489-007-0064-0; POPOVICI E, 2006, IEEE C EV COMP CEC 2, P1610, DOI DOI 10.1109/CEC.2006.1688501; Potter MA, 2000, EVOL COMPUT, V8, P1, DOI 10.1162/106365600568086; PRICE PW, 1998, BIOL EVOLUTION; Pyle D, 1999, DATA PREPARATION DAT; Rokach L, 2008, PATTERN RECOGN, V41, P1676, DOI 10.1016/j.patcog.2007.10.013; Ros F, 2008, PATTERN ANAL APPL, V11, P179, DOI 10.1007/s10044-007-0089-3; ROSIN CD, 1997, EVOLUTIONARY COMPUTA, V15, P1; Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344; Sheskin D. J., 1997, HDB PARAMETRIC NONPA; Shie JD, 2008, APPL INTELL, V28, P69, DOI 10.1007/s10489-007-0042-6; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; Sierra B, 2001, LECT NOTES ARTIF INT, V2101, P20; Singh S, 2003, IEEE T PATTERN ANAL, V25, P1534, DOI 10.1109/TPAMI.2003.1251146; Stracuzzi DJ, 2004, J MACH LEARN RES, V5, P1331; TEIXEIRA J, 2008, INT C MACH LEARN CYB, P374; TRAVIS CS, 2008, GEN EV COMP C GECCO, P371; Wang CM, 2009, EXPERT SYST APPL, V36, P5900, DOI 10.1016/j.eswa.2008.07.026; Wang SR, 2006, APPL INTELL, V25, P359, DOI 10.1007/s10489-006-0112-1; WHITLEY D, 1998, P 3 ANN C GEN PROGRA, P504; Wiegand R.P., 2001, GENETIC EVOLUTIONARY, P1235; WIEGAND RP, 2004, PARALLEL PROBLEM SOL, V8, P912; WIEGAND RP, 2004, EVOLUTIONARY COMPUTA, V12, P405; Wiegand RP, 2003, THESIS G MASON U FAI; WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Witten I., 2005, DATA MINING PRACTICA; Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585893; Wolpert DH, 2005, IEEE T EVOLUT COMPUT, V9, P721, DOI 10.1109/TEVC.2005.856205; Wu X, 2009, CH CRC DATA MIN KNOW, P1, DOI 10.1201/9781420089653; Zhang P, 2005, PATTERN RECOGN LETT, V26, P909, DOI 10.1016/j.patrec.2004.09.053	91	17	18	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	JUN	2010	43	6					2082	2105		10.1016/j.patcog.2009.12.012		24	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	574KJ	WOS:000275987700008	
J	Liaw, YC; Leou, ML; Wu, CM				Liaw, Yi-Ching; Leou, Maw-Lin; Wu, Chien-Min			Fast exact k nearest neighbors search using an orthogonal search tree	PATTERN RECOGNITION			English	Article						k nearest neighbors; Fast algorithm; Principal axis search tree; Orthonormal basis	IMAGE VECTOR QUANTIZATION; ALGORITHM; CLASSIFICATION; IMPROVEMENT; BRANCH	The problem of k nearest neighbors (kNN) is to find the nearest k neighbors for a query point from a given data set. In this paper, a novel fast kNN search method using an orthogonal search tree is proposed. The proposed method creates an orthogonal search tree for a data set using an orthonormal basis evaluated from the data set. To find the kNN for a query point from the data set, projection values of the query point onto orthogonal vectors in the orthonormal basis and a node elimination inequality are applied for pruning unlikely nodes. For a node, which cannot be deleted, a point elimination inequality is further used to reject impossible data points. Experimental results show that the proposed method has good performance on finding kNN for query points and always requires less computation time than available kNN search algorithms, especially for a data set with a big number of data points or a large standard deviation. (C) 2010 Elsevier Ltd. All rights reserved.	[Liaw, Yi-Ching; Leou, Maw-Lin; Wu, Chien-Min] Nanhua Univ, Dept Comp Sci & Informat Engn, Chiayi 622, Taiwan	Liaw, YC (reprint author), Nanhua Univ, Dept Comp Sci & Informat Engn, Chiayi 622, Taiwan.	ycliaw@mail.nhu.edu.tw			National Science Council of Taiwan, ROC [NSC-98-2221-E-343-008]	This work was supported by a Grant from National Science Council of Taiwan, ROC under Grant no. NSC-98-2221-E-343-008.	BEI CD, 1985, IEEE T COMMUN, V33, P1132; CHEN CY, 1995, PATTERN RECOGN LETT, V16, P339, DOI 10.1016/0167-8655(94)00109-G; Chen YS, 2007, PATTERN RECOGN, V40, P360, DOI 10.1016/j.patcog.2005.08.016; CHENG DY, 1984, IEEE INT C AC SPEECH, V1; Cooley W.W., 1971, MULTIVARIATE DATA AN; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; Garcia-Pedrajas N, 2009, EXPERT SYST APPL, V36, P10570, DOI 10.1016/j.eswa.2009.02.065; Gersho A, 1991, VECTOR QUANTIZATION; Jolliffe I. T., 2002, PRINCIPAL COMPONENT; Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616; KIM BS, 1986, IEEE T PATTERN ANAL, V8, P761; Lai JZC, 2007, PATTERN RECOGN, V40, P351, DOI 10.1016/j.patcog.2006.04.024; Liaw YC, 2002, PATTERN RECOGN, V35, P329, DOI 10.1016/S0031-3203(01)00048-6; Liaw YC, 2009, PATTERN RECOGN, V42, P867, DOI 10.1016/j.patcog.2008.10.001; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; Liu T, 2006, J MACH LEARN RES, V7, P1135; Lu ZM, 2005, INT J INNOV COMPUT I, V1, P35; McNames J, 2001, IEEE T PATTERN ANAL, V23, P964, DOI 10.1109/34.955110; Mico L, 1996, PATTERN RECOGN LETT, V17, P731, DOI 10.1016/0167-8655(96)00032-3; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Nene SA, 1997, IEEE T PATTERN ANAL, V19, P989, DOI 10.1109/34.615448; Omohundro S. M., 1989, 5 BALLTREE CONSTRUCT; RA SW, 1993, IEEE T CIRCUITS-II, V40, P576, DOI 10.1109/82.257335; Roth V, 2003, IEEE T PATTERN ANAL, V25, P1540, DOI 10.1109/TPAMI.2003.1251147; SPROULL RF, 1991, ALGORITHMICA, V6, P579, DOI 10.1007/BF01759061; Tai SC, 1996, IEEE T COMMUN, V44, P1623, DOI 10.1109/26.545888; Theodoridis S, 2003, PATTERN RECOGNITION; Wang B, 2004, LECT NOTES COMPUT SC, V3177, P191; STATLOG LANDSAT SATE	31	7	8	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	JUN	2010	43	6					2351	2358		10.1016/j.patcog.2010.01.003		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	574KJ	WOS:000275987700028	
J	Chen, L; Feng, KY; Cai, YD; Chou, KC; Li, HP				Chen, Lei; Feng, Kai-Yan; Cai, Yu-Dong; Chou, Kuo-Chen; Li, Hai-Peng			Predicting the network of substrate-enzyme-product triads by combining compound similarity and functional domain composition	BMC BIOINFORMATICS			English	Article							AMINO-ACID-COMPOSITION; PROTEIN SUBCELLULAR LOCATION; HIV-1 REVERSE-TRANSCRIPTASE; SUPPORT VECTOR MACHINES; SEQUENTIAL EVOLUTION INFORMATION; NEAREST-NEIGHBOR ALGORITHM; GRAPHICAL RULES; QUATERNARY STRUCTURE; SECONDARY STRUCTURE; WEB SERVER	Background: Metabolic pathway is a highly regulated network consisting of many metabolic reactions involving substrates, enzymes, and products, where substrates can be transformed into products with particular catalytic enzymes. Since experimental determination of the network of substrate-enzyme-product triad (whether the substrate can be transformed into the product with a given enzyme) is both time-consuming and expensive, it would be very useful to develop a computational approach for predicting the network of substrate-enzyme-product triads. Results: A mathematical model for predicting the network of substrate-enzyme-product triads was developed. Meanwhile, a benchmark dataset was constructed that contains 744,192 substrate-enzyme-product triads, of which 14,592 are networking triads, and 729,600 are non-networking triads; i.e., the number of the negative triads was about 50 times the number of the positive triads. The molecular graph was introduced to calculate the similarity between the substrate compounds and between the product compounds, while the functional domain composition was introduced to calculate the similarity between enzyme molecules. The nearest neighbour algorithm was utilized as a prediction engine, in which a novel metric was introduced to measure the "nearness" between triads. To train and test the prediction engine, one tenth of the positive triads and one tenth of the negative triads were randomly picked from the benchmark dataset as the testing samples, while the remaining were used to train the prediction model. It was observed that the overall success rate in predicting the network for the testing samples was 98.71%, with 95.41% success rate for the 1,460 testing networking triads and 98.77% for the 72,960 testing non-networking triads. Conclusions: It is quite promising and encouraged to use the molecular graph to calculate the similarity between compounds and use the functional domain composition to calculate the similarity between enzymes for studying the substrate-enzyme-product network system. The software is available upon request.	[Cai, Yu-Dong] Shanghai Univ, Inst Syst Biol, Shanghai 200444, Peoples R China; [Chen, Lei] Shanghai Maritime Univ, Coll Informat Engn, Shanghai 201306, Peoples R China; [Chen, Lei] Fudan Univ, Ctr Computat Syst Biol, Shanghai 200433, Peoples R China; [Feng, Kai-Yan] Univ Manchester, Sch Med, Div Imaging Sci, Manchester M13 9PT, Lancs, England; [Cai, Yu-Dong; Chou, Kuo-Chen] Gordon Life Sci Inst, San Diego, CA 92130 USA; [Li, Hai-Peng] Chinese Acad Sci, Shanghai Inst Biol Sci, CAS MPG Partner Inst Computat Biol, Shanghai 200031, Peoples R China	Cai, YD (reprint author), Shanghai Univ, Inst Syst Biol, Shanghai 200444, Peoples R China.	cai_yud@yahoo.com.cn; lihaipeng@picb.ac.cn	Chen, Lei/A-2275-2011; Chou, Kuo-Chen/A-8340-2009		Shanghai Commission for Science and Technology [KSCX2-YW-R-112]	We would like to take this opportunity to thank the four anonymous Reviewers for their constructive comments, which are very helpful for strengthening the presentation of this paper. This study was supported by the Grant from Shanghai Commission for Science and Technology (KSCX2-YW-R-112).	Almonacid DE, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000700; ALTHAUS IW, 1993, J BIOL CHEM, V268, P6119; ALTHAUS IW, 1993, J BIOL CHEM, V268, P14875; ALTHAUS IW, 1993, BIOCHEMISTRY-US, V32, P6548, DOI 10.1021/bi00077a008; Andraos J, 2008, CAN J CHEM, V86, P342, DOI 10.1139/V08-020; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Cai YD, 2005, J PROTEOME RES, V4, P967, DOI 10.1021/pr0500399; Cai YD, 2005, J PROTEOME RES, V4, P109, DOI 10.1021/pr049835p; Cai YD, 2003, BIOCHEM BIOPH RES CO, V305, P407, DOI 10.1016/S0006-291X(03)00775-7; Cai YD, 2003, BIOPHYS J, V84, P3257; Chen C, 2009, PROTEIN PEPTIDE LETT, V16, P27; Chou K. C., 2009, NAT SCI, V2, P63, DOI DOI 10.4236/NS.2009.12011; Chou KC, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0009931; Chou K. C., 2009, OPEN BIOINFORMATICS, V3, P31; CHOU KC, 1990, BIOPHYS CHEM, V35, P1, DOI 10.1016/0301-4622(90)80056-D; Chou KC, 2008, BIOCHEM BIOPH RES CO, V376, P321, DOI 10.1016/j.bbrc.2008.08.125; Chou KC, 2007, ANAL BIOCHEM, V370, P1, DOI 10.1016/j.ab.2007.07.006; CHOU KC, 1989, J BIOL CHEM, V264, P12074; CHOU KC, 1994, ANAL BIOCHEM, V221, P217, DOI 10.1006/abio.1994.1405; CHOU KC, 1981, J THEOR BIOL, V91, P637; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; CHOU KC, 1981, CAN J CHEM, V59, P737; Chou K. C., 2006, EXCLI J, V5, P55; CHOU KC, 1980, BIOCHEM J, V187, P829; Chou KC, 2004, CURR MED CHEM, V11, P2105; Chou KC, 2004, BIOCHEM BIOPH RES CO, V320, P1236, DOI 10.1016/j.bbrc.2004.06.073; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; Chou KC, 2010, CURR DRUG METAB, V11, P369; Chou KC, 2009, CURR PROTEOMICS, V6, P262; CHOU KC, 1980, EUR J BIOCHEM, V113, P195; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Ding CHQ, 2001, BIOINFORMATICS, V17, P349, DOI 10.1093/bioinformatics/17.4.349; Du QS, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0009388; Fukunaga K., 1990, INTRO STAT PATTERN R; Goto S, 1998, BIOINFORMATICS, V14, P591, DOI 10.1093/bioinformatics/14.7.591; Hattori M, 2003, J AM CHEM SOC, V125, P11853, DOI 10.1021/ja036030u; HUNTER S, 2009, NUCLEIC ACIDS RES, pD211; Jia PL, 2007, BIOCHEM BIOPH RES CO, V357, P366, DOI 10.1016/j.bbrc.2007.03.139; Kanehisa M, 2006, NUCLEIC ACIDS RES, V34, pD354, DOI 10.1093/nar/gkj102; Kanehisa M, 2008, NUCLEIC ACIDS RES, V36, pD480, DOI 10.1093/nar/gkm882; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Kuhn M, 2008, NUCLEIC ACIDS RES, V36, pD684, DOI 10.1093/nar/gkm795; Martin YC, 2002, J MED CHEM, V45, P4350, DOI 10.1021/jm020155c; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; McGregor MJ, 1997, J CHEM INF COMP SCI, V37, P443, DOI 10.1021/ci960151e; Murvai J, 2001, NUCLEIC ACIDS RES, V29, P58, DOI 10.1093/nar/29.1.58; MYERS D, 1985, COMPUT APPL BIOSCI, V1, P105; QU DL, 1992, J CHEM INF COMP SCI, V32, P443, DOI 10.1021/ci00009a008; Shen HB, 2009, J THEOR BIOL, V256, P441, DOI 10.1016/j.jtbi.2008.10.007; Shen HB, 2007, BIOCHEM BIOPH RES CO, V364, P53, DOI 10.1016/j.bbrc.2007.09.098; Shen HB, 2009, J PROTEOME RES, V8, P1577, DOI 10.1021/pr800957q; Steinbeck C, 2006, CURR PHARM DESIGN, V12, P2111, DOI 10.2174/138161206777585274; Wang JF, 2009, MED CHEM, V5, P263; WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005; Willett P, 1998, J CHEM INF COMP SCI, V38, P983, DOI 10.1021/ci9800211; Xiao X, 2009, J APPL CRYSTALLOGR, V42, P169, DOI 10.1107/S0021889809002751; Xu XC, 2008, J PROTEOME RES, V7, P4521, DOI 10.1021/pr800292w; Yu XJ, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-187; ZHOU GP, 1984, BIOCHEM J, V222, P169	60	38	38	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	MAY 31	2010	11								293	10.1186/1471-2105-11-293		11	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	623IW	WOS:000279734000001	
J	Shen, HB; Chou, KC				Shen, Hong-Bin; Chou, Kuo-Chen			Gneg-mPLoc: A top-down strategy to enhance the quality of predicting subcellular localization of Gram-negative bacterial proteins	JOURNAL OF THEORETICAL BIOLOGY			English	Article						Multiplex protein; Homology search; Representative proteins; Gene ontology; Functional domain; Sequential evolution; Ensemble classifier; Fusion approach	AMINO-ACID-COMPOSITION; STRUCTURAL CLASS PREDICTION; LOCATION PREDICTION; SORTING SIGNALS; MULTIPLE SITES; GENE ONTOLOGY; CLASSIFIER; BIOINFORMATICS; ANNOTATION; PROTEOMICS	By incorporating the information of gene ontology, functional domain, and sequential evolution, a new predictor called Gneg-mPLoc was developed. It can be used to identify Gram-negative bacterial proteins among the following eight locations: (1) cytoplasm, (2) extracellular, (3) fimbrium, (4) flagellum, (5) inner membrane, (6) nucleoid, (7) outer membrane, and (8) periplasm. It can also be used to deal with the case when a query protein may simultaneously exist in more than one location. Compared with the original predictor called Gneg-PLoc, the new predictor is much more powerful and flexible. For a newly constructed stringent benchmark dataset in which none of proteins included has >= 25% pairwise sequence identity to any other in a same subset (location), the overall jackknife success rate achieved by Gneg-mPLoc was 85.5%, which was more than 14% higher than the corresponding rate by the Gneg-PLoc. As a user friendly web-server, Gneg-mPLoc is freely accessible at http://www.csbio.sjtu.edu.cn/bioinf/Gneg-multi/. (C) 2010 Elsevier Ltd. All rights reserved.	[Shen, Hong-Bin; Chou, Kuo-Chen] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China; [Shen, Hong-Bin; Chou, Kuo-Chen] Gordon Life Sci Inst, San Diego, CA 92130 USA	Shen, HB (reprint author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.	hbshen@sjtu.edu.cn	Chou, Kuo-Chen/A-8340-2009		National Natural Science Foundation of China [60704047]; Science and Technology Commission of Shanghai Municipality [08ZR1410600, 08JC1410600]; Shanghai Municipal Education Commission [10ZZ17]	The authors would thank the two anonymous reviewers for their constructive comments. This work was supported by the National Natural Science Foundation of China (Grant no. 60704047), the Science and Technology Commission of Shanghai Municipality (Grant no. 08ZR1410600, 08JC1410600), and sponsored by the Shanghai Pujiang Program and Innovation Program of Shanghai Municipal Education Commission (10ZZ17).	Ashburner M, 2000, NAT GENET, V25, P25; Camon E, 2003, GENOME RES, V13, P662, DOI 10.1101/gr.461403; Chen C, 2009, PROTEIN PEPTIDE LETT, V16, P27; Chou KC, 2006, J PROTEOME RES, V5, P3420, DOI 10.1021/pr060404b; Chou KC, 2007, ANAL BIOCHEM, V370, P1, DOI 10.1016/j.ab.2007.07.006; Chou KC, 2008, NAT PROTOC, V3, P153, DOI 10.1038/nprot.2007.494; Chou KC, 2007, J CELL BIOCHEM, V100, P665, DOI 10.1002/jcb.21096; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2004, CURR MED CHEM, V11, P2105; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2009, CURR PROTEOMICS, V6, P262; Chou KC, 2007, J PROTEOME RES, V6, P1728, DOI 10.1021/pr060635i; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Ding H, 2009, PROTEIN PEPTIDE LETT, V16, P351; FAVRE D, 1993, J BACTERIOL, V175, P3710; Finn RD, 2006, NUCLEIC ACIDS RES, V34, pD247, DOI 10.1093/nar/gkj149; Gardy JL, 2003, NUCLEIC ACIDS RES, V31, P3613, DOI 10.1093/nar/gkg602; Gardy JL, 2005, BIOINFORMATICS, V21, P617, DOI 10.1093/bioinformatics/bti057; Gerstein M, 2003, CURR OPIN STRUC BIOL, V13, P341, DOI 10.1016/S0959-440X(03)00080-0; Glory E, 2007, DEV CELL, V12, P7, DOI 10.1016/j.devcel.2006.12.007; Gonzalez-Diaz H, 2008, PROTEOMICS, V8, P750, DOI 10.1002/pmic.200700638; Kedarisetti KD, 2006, BIOCHEM BIOPH RES CO, V348, P981, DOI 10.1016/j.bbrc.2006.07.141; Letunic I, 2006, NUCLEIC ACIDS RES, V34, P257; Lin H, 2008, J THEOR BIOL, V252, P350, DOI 10.1016/j.jtbi.2008.02.004; Loewenstein Y, 2009, GENOME BIOL, V10, DOI 10.1186/gb-2009-10-2-207; Marchler-Bauer A., 2007, NUCLEIC ACIDS RES, V35, P237, DOI DOI 10.1093/NAR/GKL951; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; NAKAI K, 1991, PROTEINS, V11, P95, DOI 10.1002/prot.340110203; Tatusov RL, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-41; Schaffer AA, 2001, NUCLEIC ACIDS RES, V29, P2994, DOI 10.1093/nar/29.14.2994; Shafer G., 1976, MATH THEORY EVIDENCE; Shen HB, 2007, BIOCHEM BIOPH RES CO, V355, P1006, DOI 10.1016/j.bbrc.2007.02.071; Smith C, 2008, SUBCELLULAR TARGETIN; Zeng YH, 2009, J THEOR BIOL, V259, P366, DOI 10.1016/j.jtbi.2009.03.028; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565	38	30	30	ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0022-5193		J THEOR BIOL	J. Theor. Biol.	MAY 21	2010	264	2					326	333		10.1016/j.jtbi.2010.01.018		8	Biology; Mathematical & Computational Biology	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology	588GG	WOS:000277055500016	
J	Gobena, AK; Gan, TY				Gobena, A. K.; Gan, T. Y.			Incorporation of seasonal climate forecasts in the ensemble streamflow prediction system	JOURNAL OF HYDROLOGY			English	Article						Streamflow forecasting; Ensemble streamflow prediction; Model output statistics; K-nearest neighbors re-sampling; Canada; South Saskatchewan River basin	RAINFALL-RUNOFF MODELS; COLUMBIA RIVER STREAMFLOW; GLOBAL OPTIMIZATION; BRITISH-COLUMBIA; CALIBRATION; BASIN	A technique for incorporating 0-3 months lead temperature and precipitation forecasts from two Canadian numerical weather prediction (NWP) models into the ensemble streamflow prediction (ESP) system is presented. The technique involves downscaling monthly NWP forecast outputs to station locations using the model output statistics (MOS) approach and then temporally disaggregating the monthly forecasts into daily input weather data suitable for driving a hydrologic model. The daily weather sequence for a desired month is generated by a nearest neighbor re-sampling of one of the years in the historical record, and then modifying the daily weather data for the same month of the re-sampled year so as to reproduce the MOS-based monthly forecast value. Streamflow forecasts from the MOS-based scheme are compared to pre-ESP and post-ESP re-sampling schemes without seasonal climate forecast guidance. In the pre-ESP scheme, daily weather inputs for the hydrologic model were conditionally re-sampled from historical records. In the post-ESP scheme, streamflow traces produced by the climatic ESP system were conditionally re-sampled. The three schemes were applied to the Bow and Castle rivers, both located in the headwaters of the South Saskatchewan River basin in the province of Alberta, Canada. Correlations between the MOS-based median forecast and observed flow for the Castle River were consistently higher than those based on the pre-ESP and post-ESP schemes. Other skill measures showed mixed results, with the MOS-based forecasts being more skillful in some cases and less skillful in others. All three schemes exhibited better skill for above-normal flow categories than for below-normal categories. It is also shown that considerable improvement in the ESP forecast skill could be achieved through more accurate simulation of streamflow, particularly for forecast issue dates late in the water year. (C) 2010 Elsevier B.V. All rights reserved.	[Gobena, A. K.; Gan, T. Y.] Univ Alberta, Dept Civil & Environm Engn, Edmonton, AB T6G 2W2, Canada	Gan, TY (reprint author), Univ Alberta, Dept Civil & Environm Engn, Edmonton, AB T6G 2W2, Canada.	tgan@ualberta.ca			Canadian Water Networks (CWN); NSERC of Canada; University of Alberta	Partial support for this study was provided by the Canadian Water Networks (CWN), and NSERC of Canada. The first author was also partially supported by a graduate assistantship of the University of Alberta. Natural streamflow data for the Bow and Castle rivers were extracted from the Canadian hydrometric data (HY-DAT) archive. Daily meteorological data were obtained from the Canadian Daily Climate Data archive while snow course data were supplied by Mr. Chacko Abraham of Alberta Environment. The digital elevation model (DEM) used for generating physiographic data for the study basins was obtained from the National Water Research Institute (NWRI).	ABRAHAM C, 1999, EVAPORATION EVAPOTRA; ANDERSON E, 1973, HYDRO17 NWS US DEP C; Burnash R. J., 1973, GEN STREAMFLOW SIMUL; Clark MP, 2004, J HYDROMETEOROL, V5, P15, DOI 10.1175/1525-7541(2004)005<0015:UOMNWP>2.0.CO;2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAY GN, 1985, J WATER RES PL-ASCE, V111, P157; Druce DJ, 2001, J HYDROL, V249, P102, DOI 10.1016/S0022-1694(01)00415-2; DUAN QY, 1992, WATER RESOUR RES, V28, P1015, DOI 10.1029/91WR02985; Franz KJ, 2003, J HYDROMETEOROL, V4, P1105, DOI 10.1175/1525-7541(2003)004<1105:VONWSE>2.0.CO;2; GALEATI G, 1990, HYDROLOG SCI J, V35, P79, DOI 10.1080/02626669009492406; GAN TY, 1990, WATER RESOUR RES, V26, P1595, DOI 10.1029/WR026i007p01595; Gangopadhyay S, 2005, WATER RESOUR RES, V41, DOI 10.1029/2004WR003444; Gobena AK, 2009, J HYDROL ENG, V14, P628, DOI 10.1061/(ASCE)HE.1943-5584.0000021; Grantz K, 2005, WATER RESOUR RES, V41, DOI 10.1029/2004WR003467; Hamlet AF, 1999, J WATER RES PL-ASCE, V125, P333, DOI 10.1061/(ASCE)0733-9496(1999)125:6(333); Hamon W. R., 1961, J HYDRAULICS DIVISIO, V87, P107; Hopkinson C, 1998, HYDROL PROCESS, V12, P1745, DOI 10.1002/(SICI)1099-1085(199808/09)12:10/11<1745::AID-HYP692>3.0.CO;2-S; Hsieh WW, 2001, WATER RESOUR RES, V37, P1753, DOI 10.1029/2000WR900410; Hsieh WW, 2003, J WATER RES PL-ASCE, V129, P146, DOI 10.1061/(ASCE)0733-9496(2003)129:2(146); KARLSSON M, 1987, WATER RESOUR RES, V23, P1300, DOI 10.1029/WR023i007p01300; Lall U, 1996, WATER RESOUR RES, V32, P679, DOI 10.1029/95WR02966; Loader C., 1997, STAT COMPUT GRAPH NE, V8, P11; Mason SJ, 1999, WEATHER FORECAST, V14, P713, DOI 10.1175/1520-0434(1999)014<0713:CPROCA>2.0.CO;2; McFarlane N, 2005, CCCMA 3 GENERATION A; Oudin L, 2005, J HYDROL, V303, P290, DOI 10.1016/j.jhydrol.2004.08.026; Prairie JR, 2006, J HYDROL ENG, V11, P371, DOI 10.1061/(ASCE)1084-0699(2006)11:4(371); Rajagopalan B, 1999, WATER RESOUR RES, V35, P3089, DOI 10.1029/1999WR900028; Regonda SK, 2006, WATER RESOUR RES, V42, DOI 10.1029/2005WR004653; Serneels S, 2005, CHEMOMETR INTELL LAB, V79, P55, DOI 10.1016/j.chemolab.2005.04.007; Sharif M, 2006, J HYDROL, V325, P179, DOI 10.1016/j.jhydrol.2005.10.015; Singhrattna N, 2005, INT J CLIMATOL, V25, P649, DOI 10.1002/joc.1144; SOROOSHIAN S, 1993, WATER RESOUR RES, V29, P1185, DOI 10.1029/92WR02617; SOROOSHIAN S, 1983, WATER RESOUR RES, V19, P260, DOI 10.1029/WR019i001p00260; Werner K, 2004, J HYDROMETEOROL, V5, P1076, DOI 10.1175/JHM-381.1; Wilks D. S., 2006, STAT METHODS ATMOSPH; Wood AW, 2002, J GEOPHYS RES-ATMOS, V107, DOI 10.1029/2001JD000659; Yates D, 2003, WATER RESOUR RES, V39, DOI 10.1029/2002WR001769; *ALB ENV, 2006, WAT SUPPL OUTL ALB; *ALB ENV, 2006, WAT ALB ALB ENV; *ALB ENV, 2005, ALB ENV PUBL, V1011; *ALB ENV, 2002, ALB ENV PUBL T, V656	41	4	4	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0022-1694		J HYDROL	J. Hydrol.	MAY 7	2010	385	1-4					336	352		10.1016/j.jhydrol.2010.03.002		17	Engineering, Civil; Geosciences, Multidisciplinary; Water Resources	Engineering; Geology; Water Resources	597ZV	WOS:000277802100031	
J	Kassner, A; Thornhill, RE				Kassner, A.; Thornhill, R. E.			Texture Analysis: A Review of Neurologic MR Imaging Applications	AMERICAN JOURNAL OF NEURORADIOLOGY			English	Review							ACUTE ISCHEMIC-STROKE; MAGNETIC-RESONANCE SPECTROSCOPY; PROGRESSIVE MULTIPLE-SCLEROSIS; BRAIN-TUMOR CHARACTERIZATION; EUROPEAN-ECONOMIC-COMMUNITY; CONCERTED RESEARCH-PROJECT; FOCAL CORTICAL DYSPLASIA; PATTERN-RECOGNITION; TISSUE CHARACTERIZATION; INTRACRANIAL TUMORS	Texture analysis describes a variety of image-analysis techniques that quantify the variation in surface intensity or patterns, including some that are imperceptible to the human visual system Texture analysis may be particularly well-suited for lesion segmentation and characterization and for the longitudinal monitoring of disease or recovery We begin this review by outlining the general procedure for performing texture analysis, identifying some potential pitfalls and strategies for avoiding them We then provide an overview of some intriguing neuro-MR imaging applications of texture analysis, particularly in the characterization of brain tumors, prediction of seizures in epilepsy, and a host of applications to MS	[Kassner, A.; Thornhill, R. E.] Univ Toronto, Dept Med Imaging, Toronto, ON M5S 3E2, Canada; [Kassner, A.; Thornhill, R. E.] Hosp Sick Children, Div Physiol & Expt Med, Toronto, ON M5G 1X8, Canada	Kassner, A (reprint author), Univ Toronto, Dept Med Imaging, Fitzgerald Bldg,Room 125,150 Coll St, Toronto, ON M5S 3E2, Canada.		Kassner, Andrea/F-3847-2010		Canadian Stroke Network; Canadian Institutes of Health Research; Canada Research Chair Program	this work was supported by the Canadian Stroke Network, the Canadian Institutes of Health Research, and the Canada Research Chair Program	ANDERSON RE, 1989, JAMA-J AM MED ASSOC, V261, P1610, DOI 10.1001/jama.261.11.1610; Antel SB, 2003, NEUROIMAGE, V19, P1748, DOI 10.1016/S1053-8119(03)00226-X; Avoli M, 1999, ANN NEUROL, V46, P816, DOI 10.1002/1531-8249(199912)46:6<816::AID-ANA3>3.0.CO;2-O; Barkovich AJ, 1996, J CLIN NEUROPHYSIOL, V13, P481, DOI 10.1097/00004691-199611000-00003; Bernasconi A, 2001, ANN NEUROL, V49, P770, DOI 10.1002/ana.1013; Bonilha L, 2003, EPILEPSIA, V44, P1546, DOI 10.1111/j.0013-9580.2003.27103.x; Breij ECW, 2008, ANN NEUROL, V63, P16, DOI 10.1002/ana.21311; Brown R, 2008, CLIN CANCER RES, V14, P2357, DOI 10.1158/1078-0432.CCR-07-1964; CHIEN YP, 1974, IEEE T SYST MAN CYB, VMC 4, P145, DOI 10.1109/TSMC.1974.5409108; CONNERS RW, 1980, IEEE T PATTERN ANAL, V2, P204; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DARLING EM, 1968, IEEE T SYST SCI CYB, VSSC4, P38, DOI 10.1109/TSSC.1968.300186; Daubechies I., 1992, 10 LECT WAVELETS; Davies GR, 2005, J NEUROL, V252, P1037, DOI 10.1007/s00415-005-0808-x; DRABYCZ S, 2009, NEUROIMAGE, V49, P1398; EARNEST F, 1988, RADIOLOGY, V166, P823; Freeborough PA, 1998, IEEE T MED IMAGING, V17, P475, DOI 10.1109/42.712137; Gabor D., 1946, J IND ELECT ENG LOND, V93, P445; Galloway MM, 1975, COMPUTER GRAPHICS IM, V4, P172, DOI 10.1016/S0146-664X(75)80008-6; Georgiadis P, 2009, MAGN RESON IMAGING, V27, P120, DOI 10.1016/j.mri.2008.05.017; Georgiadis P, 2008, COMPUT METH PROG BIO, V89, P24, DOI 10.1016/j.cmpb.2007.10.007; Gibbs P, 2003, MAGNET RESON MED, V50, P92, DOI 10.1002/mrm.10496; GOROVITZ S, 1976, FDN ETHICS ITS RELAT, P248; Hacke W, 2008, NEW ENGL J MED, V359, P1317, DOI 10.1056/NEJMoa0804656; HALL EL, 1971, IEEE T COMPUT, VC 20, P1032, DOI 10.1109/T-C.1971.223399; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Herlidou-Meme S, 2003, MAGN RESON IMAGING, V21, P989, DOI 10.1016/S0730-725X(03)00212-1; HSU SY, 1979, COMPUT VISION GRAPH, V9, P117, DOI 10.1016/0146-664X(79)90052-2; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; JULESZ B, 1973, PERCEPTION, V2, P391, DOI 10.1068/p020391; KAIZER H, 1955, 121 BOST U RES LAB; Kassner A, 2009, J MAGN RESON IMAGING, V30, P933, DOI 10.1002/jmri.21940; Kassner A, 2009, AM J NEURORADIOL, V30, P1864, DOI 10.3174/ajnr.A1774; Kassner A, 2005, AM J NEURORADIOL, V26, P2213; LARSSON HBW, 1990, MAGNET RESON MED, V16, P117, DOI 10.1002/mrm.1910160111; LERSKI R A, 1979, Ultrasound in Medicine and Biology, V5, P341, DOI 10.1016/0301-5629(79)90004-8; LERSKI RA, 1993, MAGN RESON IMAGING, V11, P873, DOI 10.1016/0730-725X(93)90205-R; Li DKB, 1999, ANN NEUROL, V46, P197, DOI 10.1002/1531-8249(199908)46:2<197::AID-ANA9>3.0.CO;2-P; Mahmoud-Ghoneim Doaa, 2008, BMC Med Imaging, V8, P18, DOI 10.1186/1471-2342-8-18; Mahmoud-Ghoneim D, 2003, MAGN RESON IMAGING, V21, P983, DOI 10.1016/S0730-725X(03)00201-7; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; Mayerhoefer ME, 2005, J MAGN RESON IMAGING, V22, P674, DOI 10.1002/jmri.20429; Mikulis DJ, 2007, J MAGN RESON IMAGING, V26, P838, DOI 10.1002/jmri.21041; Provenzale JM, 2006, RADIOLOGY, V239, P632, DOI 10.1148/radiol.2393042031; Roberts HC, 2000, AM J NEURORADIOL, V21, P891; Rovaris M, 2006, LANCET NEUROL, V5, P343, DOI 10.1016/S1474-4422(06)70410-0; Sankar T, 2008, HUM BRAIN MAPP, V29, P931, DOI 10.1002/hbm.20437; SCHAD LR, 1993, MAGN RESON IMAGING, V11, P889, DOI 10.1016/0730-725X(93)90206-S; Schmierer K, 2004, ANN NEUROL, V56, P407, DOI 10.1002/ana.20202; Seppa M, 2005, NEUROIMAGE, V26, P1, DOI 10.1016/j.neuroimage.2005.01.030; Stockwell RG, 2007, DIGIT SIGNAL PROCESS, V17, P371, DOI 10.1016/j.dsp.2006.04.006; Tang XO, 1998, IEEE T IMAGE PROCESS, V7, P1602, DOI 10.1109/83.725367; Theocharakis P, 2009, MAGN RESON IMAGING, V27, P417, DOI 10.1016/j.mri.2008.07.014; TOFTS PS, 1991, MAGNET RESON MED, V17, P357, DOI 10.1002/mrm.1910170208; Tourassi GD, 1999, RADIOLOGY, V213, P317; Tozer DJ, 2009, J MAGN RESON IMAGING, V30, P506, DOI 10.1002/jmri.21885; Tzacheva AA, 2003, J MAGN RESON IMAGING, V17, P337, DOI 10.1002/jmri.10259; vanBuchem MA, 1996, MAGNET RESON MED, V36, P632, DOI 10.1002/mrm.1910360420; Waubant E, 2006, DIS MARKERS, V22, P235; WEINSHENKER BG, 1989, BRAIN, V112, P133, DOI 10.1093/brain/112.1.133; WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269; Wolinsky JS, 2002, MULT SCLER, V8, P85, DOI 10.1177/135245850200800118; Woods BJ, 2007, J MAGN RESON IMAGING, V25, P495, DOI 10.1002/jmri.20837; Yu O, 2001, MAGN RESON IMAGING, V19, P1305, DOI 10.1016/S0730-725X(01)00464-7; Yu O, 1999, MAGN RESON IMAGING, V17, P1261, DOI 10.1016/S0730-725X(99)00062-4; Zacharaki EI, 2009, MAGN RESON MED, V62, P1609, DOI 10.1002/mrm.22147; Zhang J, 2008, MAGN RESON IMAGING, V26, P1160, DOI 10.1016/j.mri.2008.01.016; Zhang YY, 2009, NEUROIMAGE, V47, P107, DOI 10.1016/j.neuroimage.2009.03.075; Zhu H, 2003, MED PHYS, V30, P1134, DOI 10.1118/1.1576931	69	13	14	AMER SOC NEURORADIOLOGY	OAK BROOK	2210 MIDWEST RD, OAK BROOK, IL 60521 USA	0195-6108		AM J NEURORADIOL	Am. J. Neuroradiol.	MAY	2010	31	5					809	816		10.3174/ajnr.A2061		8	Clinical Neurology; Neuroimaging; Radiology, Nuclear Medicine & Medical Imaging	Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging	599MH	WOS:000277916600005	
J	Whiting, JS; Dinerstein, J; Egbert, PK; Ventura, D				Whiting, Jeffrey S.; Dinerstein, Jonathan; Egbert, Parris K.; Ventura, Dan			COGNITIVE AND BEHAVIORAL MODEL ENSEMBLES FOR AUTONOMOUS VIRTUAL CHARACTERS	COMPUTATIONAL INTELLIGENCE			English	Article						behavioral animation; cognitive modeling; ensembles; autonomous agents; AI-based animation	ANIMATION; AGENTS	Cognitive and behavioral models have become popular methods for creating autonomous self-animating characters. Creating these models present the following challenges: (1) creating a cognitive or behavioral model is a time-intensive and complex process that must be done by an expert programmer and (2) the models are created to solve a specific problem in a given environment and because of their specific nature cannot be easily reused. Combining existing models together would allow an animator, without the need for a programmer, to create new characters in less time and to leverage each model's strengths, resulting in an increase in the character's performance and in the creation of new behaviors and animations. This article provides a framework that can aggregate existing behavioral and cognitive models into an ensemble. An animator has only to rate how appropriately a character performs in a set of scenarios and the system then uses machine learning to determine how the character should act given the current situation. Empirical results from multiple case studies validate the approach.	[Whiting, Jeffrey S.; Dinerstein, Jonathan; Egbert, Parris K.; Ventura, Dan] Brigham Young Univ, Dept Comp Sci, Provo, UT 84602 USA	Ventura, D (reprint author), Brigham Young Univ, Dept Comp Sci, Provo, UT 84602 USA.	ventura@cs.byu.edu					Andrews J. R., 1983, CONTROL MANUFACTURIN, P243; BLUMBERG B, 2002, P 29 ANN C COMP GRAP, P417, DOI 10.1145/566570.566597; BLUMBERG BM, 1995, P SIGGRAPH, V95, P47; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BURKE R, 2001, P GAM DEV C SAN JOS, P147; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Dinerstein J, 2005, COMPUT INTELL, V21, P90, DOI 10.1111/j.0824-7935.2005.00266.x; Dinerstein J, 2004, COMPUT ANIMAT VIRT W, V15, P95, DOI 10.1002/cav.8; Dinerstein J, 2005, ACM T GRAPHIC, V24, P262, DOI 10.1145/1061347.1061352; Dinerstein J, 2008, COMPUT INTELL, V24, P235; Faloutsos P, 2001, COMP GRAPH, P251; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Funge J., 1999, P SIGGRAPH 99, P29, DOI 10.1145/311535.311538; Gervasi V, 2004, DISCRETE APPL MATH, V144, P324, DOI 10.1016/j.dam.2003.11.010; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Hart P., 1968, IEEE T SYST SCI CYB, P100; JORDAN MI, 1993, P INT JOINT C NEUR N, V2; Reynolds C., 1987, ACM SIGGRAPH 87 C P, V21, P25, DOI 10.1145/37402.37406; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; TOMLINSON B, 2003, LECT NOTES COMPUTER, V2564, P35; Tu Xiaoyuan, 1994, P SIGGRAPH 94, P43, DOI 10.1145/192161.192170; Weiss G., 1999, MULTIAGENT SYSTEMS M; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; YOON SY, 2000, P 17 NAT C ART INT 1, P249	25	1	1	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0824-7935		COMPUT INTELL-US	Comput. Intell.	MAY	2010	26	2					142	159				18	Computer Science, Artificial Intelligence	Computer Science	588PA	WOS:000277083200002	
J	Korfiatis, PD; Karahaliou, AN; Kazantzi, AD; Kalogeropoulou, C; Costaridou, LI				Korfiatis, Panayiotis D.; Karahaliou, Anna N.; Kazantzi, Alexandra D.; Kalogeropoulou, Cristina; Costaridou, Lena I.			Texture-Based Identification and Characterization of Interstitial Pneumonia Patterns in Lung Multidetector CT	IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE			English	Article						Image segmentation; image texture analysis; respiratory system	HIGH-RESOLUTION CT; COMPUTER-AIDED DIAGNOSIS; GROUND-GLASS; CLASSIFICATION; SEGMENTATION; QUANTIFICATION; DISEASE; TOMOGRAPHY; FIBROSIS; MDCT	Identification and characterization of diffuse parenchyma lung disease (DPLD) patterns challenges computer-aided schemes in computed tomography (CT) lung analysis. In this study, an automated scheme for volumetric quantification of interstitial pneumonia (IP) patterns, a subset of DPLD, is presented, utilizing a multidetector CT (MDCT) dataset. Initially, lung-field segmentation is achieved by 3-D automated gray-level thresholding combined with an edge-highlighting wavelet preprocessing step, followed by a texture-based border refinement step. The vessel tree volume is identified and removed from lung field, resulting in lung parenchyma (LP) volume. Following, identification and characterization of IP patterns is formulated as a three-class pattern classification of LP into normal, ground glass, and reticular patterns, by means of k-nearest neighbor voxel classification, exploiting 3-D cooccurrence features. Performance of the proposed scheme in indentifying and characterizing ground glass and reticular patterns was evaluated by means of volume overlap (ground glass: 0.734 +/- 0.057, reticular: 0.815 +/- 0.037), true-positive fraction (ground glass: 0.638 +/- 0.055, reticular: 0.942 +/- 0.023) and false-positive fraction (ground glass: 0.361 +/- 0.027, reticular: 0.147 +/- 0.032) on five MDCT scans.	[Korfiatis, Panayiotis D.; Karahaliou, Anna N.; Costaridou, Lena I.] Univ Patras, Sch Med, Dept Med Phys, Patras 26500, Greece; [Kazantzi, Alexandra D.; Kalogeropoulou, Cristina] Univ Hosp Patras, Dept Radiol, Patras 26500, Greece	Korfiatis, PD (reprint author), Univ Patras, Sch Med, Dept Med Phys, Patras 26500, Greece.	korfp@upatras.gr; karahaliou.a@med.upatras.gr; akazantzi@yahoo.gr; rat@upatras.gr; costarid@upatras.gr			University of Patras [C. 180]	This work was supported in part by the Caratheodory Programe (C. 180) of the University of Patras.	Aziz ZA, 2004, THORAX, V59, P506, DOI 10.1136/thx.2003.020396; Chabat F, 2003, RADIOLOGY, V228, P871, DOI 10.1148/radiol.2283020505; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EINSLEIN K, 1977, STAT METHODS DIGITAL, P76; Haralick RM, 1973, IEEE T SYST MAN CYB, VSMC-3; Kauczor HU, 2000, AM J ROENTGENOL, V175, P1329; Korfiatis P, 2008, MED PHYS, V35, P5290, DOI 10.1118/1.3003066; KORFIATIS P, P 8 IEEE INT C BIOIN, P1; Korfiatis P, 2007, BRIT J RADIOL, V80, P996, DOI 10.1259/bjr/20861881; Marten K, 2009, EUR RADIOL, V19, P324, DOI 10.1007/s00330-008-1152-1; Sensakovic WF, 2006, MED PHYS, V33, P3085, DOI 10.1118/1.2214165; Sluimer I, 2005, IEEE T MED IMAGING, V24, P1025, DOI 10.1109/TMI.2005.851757; Sluimer I, 2006, IEEE T MED IMAGING, V25, P385, DOI 10.1109/TMI.2005.862753; Sluimer IC, 2003, MED PHYS, V30, P3081, DOI 10.1118/1.1624771; Sluimer IC, 2006, MED PHYS, V33, P2610, DOI 10.1118/1.2207131; Uchiyama Y, 2003, MED PHYS, V30, P2440, DOI 10.1118/1.1597431; Xu Y, 2006, IEEE T MED IMAGING, V25, P464; Xu Y, 2006, ACAD RADIOL, V13, P969, DOI 10.1016/j.acra.2006.04.017; Zavaletta VA, 2007, ACAD RADIOL, V14, P772, DOI 10.1016/j.acra.2007.03.009; Zhou C, 2007, MED PHYS, V34, P4567, DOI 10.1118/1.2804558	20	7	7	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1089-7771		IEEE T INF TECHNOL B	IEEE T. Inf. Technol. Biomed.	MAY	2010	14	3					675	680		10.1109/TITB.2009.2036166		6	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Medical Informatics	Computer Science; Mathematical & Computational Biology; Medical Informatics	607WP	WOS:000278538300016	
J	El-Yaniv, R; Wiener, Y				El-Yaniv, Ran; Wiener, Yair			On the Foundations of Noise-free Selective Classification	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						classification with a reject option; selective classification; perfect learning; high performance classification; risk-coverage trade-off	REJECT-OPTION; CLASSIFIERS; BOUNDS; RULE	We consider selective classification, a term we adopt here to refer to 'classification with a reject option.' The essence in selective classification is to trade-off classifier coverage for higher accuracy. We term this trade-off the risk-coverage (RC) trade-off. Our main objective is to characterize this trade-off and to construct algorithms that can optimally or near optimally achieve the best possible trade-offs in a controlled manner. For noise-free models we present in this paper a thorough analysis of selective classification including characterizations of RC trade-offs in various interesting settings.	[El-Yaniv, Ran; Wiener, Yair] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	El-Yaniv, R (reprint author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	RANI@CS.TECHNION.AC.IL; WYAIR@TX.TECHNION.AC.IL					Anthony M., 1999, NEURAL NETWORK LEARN; Antos A, 1998, MACH LEARN, V30, P31, DOI 10.1023/A:1007454427662; Atlas L., 1990, NEURAL INFORM PROCES, P566; BARTLETT PL, 2007, M980 FLOR STAT U DEP; BENTLEY J, 1978, J ACM, V25; Blumer A., 1989, J ACM, V36; BOUNSIAR A, 2006, INT J COMPUTATIONAL, V3, P312; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; Chow C.K., 1957, Institute of Radio Engineers Transactions on Electronic Computers, VEC-6; COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Freund Y, 2004, ANN STAT, V32, P1698, DOI 10.1214/009053604000000058; Friedman E., 2009, P 22 ANN C LEARN THE; FUMERA G, 2000, P SSPR SPR, P863; FUMERA G, 2002, P 1 INT WORKSH PATT, P811; Hanczar B, 2008, BIOINFORMATICS, V24, P1889, DOI 10.1093/bioinformatics/btn349; Hanneke S., 2009, THESIS CARNEGIE MELL; Hanneke S., 2007, ICML 07, P353; HAUSSLER D, 1988, ARTIF INTELL, V36, P177, DOI 10.1016/0004-3702(88)90002-1; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; Herbei R, 2006, CAN J STAT, V34, P709; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; Landgrebe TCW, 2006, PATTERN RECOGN LETT, V27, P908, DOI 10.1016/j.patrec.2005.10.015; Langford J, 2005, J MACH LEARN RES, V6, P273; MELTZER PS, 2001, NATURE MED, V7; Mitchell T., 1977, IJCAI 77, P305; Pietraszek T., 2005, P 22 INT C MACH LEAR, P665, DOI 10.1145/1102351.1102435; PREPARATA FP, 1990, COMPUTATIONAL GOMETR; Santos-Pereira CM, 2005, PATTERN RECOGN LETT, V26, P943, DOI 10.1016/j.patrec.2004.09.042; Tortorella F, 2000, LECT NOTES COMPUT SC, V1876, P611; Tsybakov AB, 2004, ANN STAT, V32, P135; Vapnik V.N., 1998, STAT LEARNING THEORY; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; Wegkamp M, 2007, ELECTRON J STAT, V1, P155, DOI 10.1214/07-EJS058; YOGANANDA AP, 2007, ICML 07, P713	35	3	3	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	MAY	2010	11						1605	1641				37	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	658WB	WOS:000282522000002	
J	Olvera-Lopez, JA; Carrasco-Ochoa, JA; Martinez-Trinidad, JF				Arturo Olvera-Lopez, J.; Ariel Carrasco-Ochoa, J.; Francisco Martinez-Trinidad, J.			A new fast prototype selection method based on clustering	PATTERN ANALYSIS AND APPLICATIONS			English	Article						Prototype selection; Supervised classification; Instance-based classifiers; Border prototypes; Data reduction; Clustering	NEAREST-NEIGHBOR RULE; LEARNING ALGORITHMS; INSTANCE SELECTION; CLASSIFICATION	In supervised classification, a training set T is given to a classifier for classifying new prototypes. In practice, not all information in T is useful for classifiers, therefore, it is convenient to discard irrelevant prototypes from T. This process is known as prototype selection, which is an important task for classifiers since through this process the time for classification or training could be reduced. In this work, we propose a new fast prototype selection method for large datasets, based on clustering, which selects border prototypes and some interior prototypes. Experimental results showing the performance of our method and comparing accuracy and runtimes against other prototype selection methods are reported.	[Arturo Olvera-Lopez, J.; Ariel Carrasco-Ochoa, J.; Francisco Martinez-Trinidad, J.] Natl Inst Astrophys Opt & Elect, Dept Comp Sci, Puebla 72000, Mexico	Olvera-Lopez, JA (reprint author), Natl Inst Astrophys Opt & Elect, Dept Comp Sci, Luis Enrrique Erro 1,Sta Maria Tonantzintla, Puebla 72000, Mexico.	aolvera@ccc.inaoep.mx; ariel@ccc.inaoep.mx; fmartine@ccc.inaoep.mx					Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Bezdek JC, 2001, INT J INTELL SYST, V16, P1445, DOI 10.1002/int.1068; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; CHIDANANDAGOWDA K, 1979, IEEE T INFORM THEORY, V25, P488; Chien C., 2006, P 18 INT C PATT REC, P556; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRISTANNI N, 2000, INTRO SUPPORT VECTOR; Devijver P. A., 1980, Proceedings of the 5th International Conference on Pattern Recognition; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Duda R.O., 2000, PATTERN CLASSIFICATI; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Karacali B, 2003, IEEE T NEURAL NETWOR, V14, P127, DOI 10.1109/TNN.2002.804315; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; Liu H, 2002, DATA MIN KNOWL DISC, V6, P115, DOI 10.1023/A:1014056429969; Lumini A, 2006, PATTERN RECOGN, V39, P495, DOI 10.1016/j.patcog.2005.11.004; Mollineda RA, 2002, PATTERN RECOGN, V35, P2771, DOI 10.1016/S0031-3203(01)00208-4; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Raicharoen T, 2005, PATTERN RECOGN LETT, V26, P1554, DOI 10.1016/j.patrec.2005.01.003; Spillmann B, 2006, LECT NOTES COMPUT SC, V4109, P287; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; Vapnik V.N., 1998, STAT LEARNING THEORY; Vapnik V.N., 1995, NATURE STAT LEARNING; VENMANN CJ, 2005, IEEE T PATTERN ANAL, V27, P1417; VENMANN CJ, 2002, IEEE T PATTERN ANAL, V24, P1273; Vojtech F, 2004, STAT PATTERN RECOGNI; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Witten I., 2005, DATA MINING PRACTICA; *MATHWORKS INC, 1994, NAT	29	10	10	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1433-7541		PATTERN ANAL APPL	Pattern Anal. Appl.	MAY	2010	13	2					131	141		10.1007/s10044-008-0142-x		11	Computer Science, Artificial Intelligence	Computer Science	587VR	WOS:000277023400001	
J	Wei, XL; Li, KC				Wei, Xuelian; Li, Ker-Chau			Exploring the within- and between-class correlation distributions for tumor classification	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article						cancer research; gene expression	GENE-EXPRESSION; PROSTATE-CANCER; PREDICTION; PATTERNS; LUNG; ADENOCARCINOMA; DISCOVERY; LEUKEMIA; LOCI	To many biomedical researchers, effective tumor classification methods such as the support vector machine often appear like a black box not only because the procedures are complex but also because the required specifications, such as the choice of a kernel function, suffer from a clear guidance either mathematically or biologically. As commonly observed, samples within the same tumor class tend to be more similar in gene expression than samples from different tumor classes. But can this well-received observation lead to a useful procedure of classification and prediction? To address this issue, we first conceived a statistical framework and derived general conditions to serve as the theoretical foundation that supported the aforementioned empirical observation. Then we constructed a classification procedure that fully utilized the information obtained by comparing the distributions of within-class correlations with between-class correlations via Kullback-Leibler divergence. We compared our approach with many machine-learning techniques by applying to 22 binary- and multiclass gene-expression datasets involving human cancers. The results showed that our method performed as efficiently as support vector machine and Naive Bayesian and outperformed other learning methods (decision trees, linear discriminate analysis, and k-nearest neighbor). In addition, we conducted a simulation study and showed that our method would be more effective if the arriving new samples are subject to the often-encountered baseline shift or increased noise level problems. Our method can be extended for general classification problems when only the similarity scores between samples are available.	[Wei, Xuelian; Li, Ker-Chau] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA; [Li, Ker-Chau] Acad Sinica, Inst Stat Sci, Taipei 115, Taiwan	Li, KC (reprint author), Univ Calif Los Angeles, Dept Stat, 8125 Math Sci Bldg,Box 951554, Los Angeles, CA 90095 USA.	kcli@stat.ucla.edu			National Science Foundation [DMS0406091, DMS-0707160]; National Science Council, Taiwan [NSC95-3114-P-002-005-Y, NSC97-2627-P-001-003, NSC98-2314-B-001-001-MY3]	This work was supported in part by National Science Foundation Grants DMS0406091 and DMS-0707160 and by National Science Council Grants from Taiwan NSC95-3114-P-002-005-Y, NSC97-2627-P-001-003, and NSC98-2314-B-001-001-MY3.	Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Alter O, 2000, P NATL ACAD SCI USA, V97, P10101, DOI 10.1073/pnas.97.18.10101; Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765; Berry R, 2000, AM J HUM GENET, V67, P82, DOI 10.1086/302994; Berthon P, 1998, AM J HUM GENET, V62, P1416, DOI 10.1086/301879; Bhattacharjee A, 2001, P NATL ACAD SCI USA, V98, P13790, DOI 10.1073/pnas.191502998; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DONG JT, 1995, SCIENCE, V268, P884, DOI 10.1126/science.7754374; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; FUKUNAGA K, 1990, INTRO STAT PATTERN R, P592; Garber ME, 2001, P NATL ACAD SCI USA, V98, P13784, DOI 10.1073/pnas.241500798; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Lapointe J, 2004, P NATL ACAD SCI USA, V101, P811, DOI 10.1073/pnas.0304146101; Patrick E. A., 1972, FUNDAMENTALS PATTERN; Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Qiu P, 2005, BIOINFORMATICS, V21, P3114, DOI 10.1093/bioinformatics/bti483; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Stuart RO, 2004, P NATL ACAD SCI USA, V101, P615, DOI 10.1073/pnas.2536479100; VINCENT T, 2005, CANC PRINCIPLES PRAC; Welsh JB, 2001, CANCER RES, V61, P5974; Wigle DA, 2002, CANCER RES, V62, P3005; Witte JS, 2000, AM J HUM GENET, V67, P92, DOI 10.1086/302960; Wong DJ, 2008, CANCER RES, V68, P369, DOI 10.1158/0008-5472.CAN-07-0382; Xu JF, 2001, HUM GENET, V108, P335, DOI 10.1007/s004390100488; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	27	5	5	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424		P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	APR 13	2010	107	15					6737	6742		10.1073/pnas.0910140107		6	Multidisciplinary Sciences	Science & Technology - Other Topics	583AC	WOS:000276642100034	
J	Ghiassi, M; Burnley, C				Ghiassi, M.; Burnley, C.			Measuring effectiveness of a dynamic artificial neural network algorithm for classification problems	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Classification; Dynamic artificial neural networks; Discriminant analysis; Nearest neighbor; Support vector machines; Pattern recognition	NEAREST-NEIGHBOR CLASSIFICATION; SUPPORT VECTOR MACHINES; DISCRIMINANT-ANALYSIS; COVARIANCE MATRICES; CLASSIFIERS	Classification is the process of assigning an object to one of a set of classes based on its attributes. Classification problems have been examined in fields as diverse as biology, medicine, business, image recognition, and forensics. Developing more accurate and widely applicable classification methods has significant implications in these and many other fields. This paper presents a dynamic artificial neural network (DAN2) as an alternate approach for solving classification problems. We show DAN2 to be an effective approach and compare its performance with linear discriminant analysis, quadratic discriminant analysis, k-nearest neighbor algorithms, support vector machines, and traditional artificial neural networks using benchmark and real-world application data sets. These data sets vary in the number of classes (two vs. multiple) and the source of the data (synthetic vs. real-world). We found DAN2 to be a very effective classification method for two-class data sets with accuracy improvements as high as 37.2% when compared to the other methods. We also introduce a hierarchical DAN2 model for multiple class data sets that shows marked improvements (up to 89%) over all other methods, and offers better accuracy in all cases. (C) 2009 Elsevier Ltd. All rights reserved.	[Ghiassi, M.; Burnley, C.] Santa Clara Univ, Santa Clara, CA 95053 USA	Ghiassi, M (reprint author), Santa Clara Univ, 316 P Lucas Hall,500 El Camino Real, Santa Clara, CA 95053 USA.	mghiassi@scu.edu; corrinaburnley@gmail.com					Amasyali MF, 2008, IEEE T NEURAL NETWOR, V19, P356, DOI 10.1109/TNN.2007.910729; ANDERSON TW, 1962, ANN MATH STAT, V33, P420, DOI 10.1214/aoms/1177704568; Asuncion A., 2007, UCI MACHINE LEARNING; Berardi VL, 1999, DECISION SCI, V30, P659, DOI 10.1111/j.1540-5915.1999.tb00902.x; BILLINGS SA, 2002, NEURAL NETWORKS, V15, P262; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; CHAOVALITWONGSE W, 2007, IEEE T SYSTEMS MAN A, V37; Christianini N., 2000, INTRO SUPPORT VECTOR; Chu S, 1998, SCIENCE, V282, P699, DOI 10.1126/science.282.5389.699; CLUNIESROSS CW, 1960, BIOMETRIKA, V47, P185, DOI 10.2307/2332972; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CURRAM SP, 1994, J OPER RES SOC, V45, P440, DOI 10.1057/jors.1994.62; Duda R. O., 2001, PATTERN CLASSIFICATI; ENAS GG, 1986, COMPUT MATH APPL-A, V12, P235, DOI 10.1016/0898-1221(86)90076-3; Fisher RA, 1936, ANN EUGENIC, V7, P465; FIX E, 1952, 11 USAF SCH AV; FIX E, 1951, 4 USAF SCH AV; Ghiassi M, 2005, NEUROCOMPUTING, V63, P397, DOI 10.1016/j.neucom.2004.03.014; Ghiassi M., 2005, INT J FORECASTING, V21, P241; HART A, 1992, J OPER RES SOC, V43, P215, DOI 10.1057/jors.1992.31; Kim N, 2003, IEEE T NEURAL NETWOR, V14, P1065, DOI 10.1109/TNN.2003.816037; Lachenbruch P.A., 1973, COMMUN STAT, V1, P39, DOI 10.1080/03610917308542640; Lee J, 2007, IEEE T GEOSCI REMOTE, V45, P2953, DOI 10.1109/TGRS.2007.900675; Liang Yulan, 2005, Int J Bioinform Res Appl, V1, P399, DOI 10.1504/IJBRA.2005.008443; MARKS S, 1974, J AM STAT ASSOC, V69, P555, DOI 10.2307/2285696; Muezzinoglu MK, 2006, PATTERN RECOGN, V39, P747, DOI 10.1016/j.patcog.2005.10.026; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Panel on Discrimination Analysis Classification and Clustering, 1989, STAT SCI, V4, P34; Porter WA, 1996, INFORM SCIENCES, V94, P151, DOI 10.1016/0020-0255(96)00130-2; RIPLEY BD, 1994, J ROY STAT SOC B MET, V56, P409; RUBIN PA, 1990, DECISION SCI, V21, P373, DOI 10.1111/j.1540-5915.1990.tb01691.x; SMITH CAB, 1947, ANN EUGENIC, V13, P272; Tsai CF, 2008, EXPERT SYST, V25, P380, DOI 10.1111/j.1468-0394.2008.00449.x; Viaene S, 2002, J RISK INSUR, V69, P373, DOI 10.1111/1539-6975.00023; YOON YO, 1993, J OPER RES SOC, V44, P51, DOI 10.2307/2584434; Zhang GP, 2001, COMPUT OPER RES, V28, P1183, DOI 10.1016/S0305-0548(00)00033-2; *RAPIDMINERCOMMUNI, 2008, RAP 1 GMBH VERS 4 2; *SPSS INC, 2000, CLEM DAT MIN SYST	38	6	7	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	APR	2010	37	4					3118	3128		10.1016/j.eswa.2009.09.017		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	551JB	WOS:000274202900047	
J	Biau, G; Cerou, F; Guyader, A				Biau, Gerard; Cerou, Frederic; Guyader, Arnaud			Rates of Convergence of the Functional k-Nearest Neighbor Estimate	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article						Compact embedding; nearest neighbor estimate; rates of convergence; regression estimation; reproducing kernel Hilbert space; Sobolev space		Let F be a separable Banach space, and let (X,Y) be a random pair taking values in F x R. Motivated by a broad range of potential applications, we investigate rates of convergence of the k-nearest neighbor estimate r(n)(x) of the regression function r(x) = E[Y vertical bar X = x], based on n independent copies of the pair (X, Y). Using compact embedding theory, we present explicit and general finite sample bounds on the expected squared difference E[r(n)(X) - r(X)](2) and particularize our results to classical function spaces such as Sobolev spaces, Besov spaces, and reproducing kernel Hilbert spaces.	[Biau, Gerard] Univ Paris 06, LSTA, F-75013 Paris, France; [Biau, Gerard] Univ Paris 06, LPMA, F-75013 Paris, France; [Cerou, Frederic; Guyader, Arnaud] INRIA Rennes Bretagne Atlantique Aspi Project Tea, F-35042 Rennes, France; [Guyader, Arnaud] Univ Rennes 2, F-35043 Rennes, France	Biau, G (reprint author), Univ Paris 06, LSTA, F-75013 Paris, France.	gerard.biau@upmc.fr; Fred-eric.Cerou@inria.fr; arnaud.guyader@uhb.fr					ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI 10.2307/1990404; Cerou F., 2006, ESAIM-PROBAB STAT, V10, P340, DOI 10.1051/ps:2006014; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cucker F, 2002, B AM MATH SOC, V39, P1; Devroye L, 1996, PROBABILISTIC THEORY; EDMUNDS LE, 1996, FUNCTION SPACES ENTR; Fix E., 1951, 4 USAF SCH AV MED; Fix E., 1952, 11 USAF SCH AV MED; Gyorfi L., 2002, DISTRIBUTION FREE TH; IBRAGIMOV I, 1981, STAT ESTIMATION SYMP; Kolmogorov A.N., 1961, AM MATH SOC TRANSL, V17, P277; KULKARNI SR, 1995, IEEE T INFORM THEORY, V41, P1028, DOI 10.1109/18.391248; PREISS D, 1981, COMMENT MATH U CAROL, V1, P181; RAMSAY J. O., 1997, FUNCTIONAL DATA ANAL; Scholkopf B., 2002, LEARNING KERNELS; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; Zhou DX, 2002, J COMPLEXITY, V18, P739, DOI 10.1006/jcom.2002.0635	18	4	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9448		IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	APR	2010	56	4					2034	2040		10.1109/TIT.2010.2040857		7	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	574OG	WOS:000275999500042	
J	Cheng, HB; Tan, PN; Jin, R				Cheng, Haibin; Tan, Pang-Ning; Jin, Rong			Efficient Algorithm for Localized Support Vector Machine	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						Classification; support vector machine; kernel-based learning; local learning	NEAREST-NEIGHBOR CLASSIFIERS; CLASSIFICATION	This paper presents a framework called Localized Support Vector Machine (LSVM) for classifying data with nonlinear decision surfaces. Instead of building a sophisticated global model from the training data, LSVM constructs multiple linear SVMs, each of which is designed to accurately classify a given test example. A major limitation of this framework is its high computational cost since a unique model must be constructed for each test example. To overcome this limitation, we propose an efficient implementation of LSVM, termed Profile SVM (PSVM). PSVM partitions the training examples into clusters and builds a separate linear SVM model for each cluster. Our empirical results show that 1) LSVM and PSVM outperform nonlinear SVM for all 20 of the evaluated data sets and 2) PSVM achieves comparable performance as LSVM in terms of model accuracy but with significant computational savings. We also demonstrate the efficacy of the proposed approaches in terms of classifying data with spatial and temporal dependencies.	[Cheng, Haibin] Yahoo Labs, Santa Clara, CA 95051 USA; [Tan, Pang-Ning; Jin, Rong] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48823 USA	Cheng, HB (reprint author), Yahoo Labs, 2627 Pilot Knob Dr, Santa Clara, CA 95051 USA.	hcheng@yahoo-inc.com; ptan@msu.edu; rongjin@msu.edu			US National Science Foundation (NSF) [0712987]	The authors would like to thank Dr Ron Bekkerman, Dr Chih-Chung Chang, and Dr Chih-Jen Lin for sharing the Enron e-mail data and LIBSVM [9] tools. This work is partially supported by the US National Science Foundation (NSF)-III Grant No. 0712987.	Aizerman M., 1964, AUTOMAT REM CONTR, V25, P821; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; BACH F, 2004, UCBCSD041307 EL ENG; Bekkerman R., 2004, AUTOMATIC CATEGORIZA; Bellman R., 1961, ADAPTIVE CONTROL PRO; BOTTOU L, 1992, NEURAL COMPUT, V4, P888, DOI 10.1162/neco.1992.4.6.888; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P2; Chang C-C., 2001, LIBSVM LIB SUPPORT V; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domeniconi C, 2005, IEEE T NEURAL NETWOR, V16, P899, DOI 10.1109/TNN.2005.849821; Frohlich H, 2005, P IEEE INT JOINT C N, V3, P1431, DOI 10.1109/IJCNN.2005.1556085; Gilardi N., 2000, J GEOGRAPHIC INFORMA, V4, P11; Gunn S, 1998, SUPPORT VECTOR MACHI; Hand DJ, 2003, PATTERN RECOGN LETT, V24, P1555, DOI 10.1016/S0167-8655(02)00394-X; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; HECHENBICHLER K, 2006, 386 SFB; Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616; KIRITCHENKO S, 2004, P INT INT INF SYST I, P523; KOPERSKI K, 1998, P INT S SPAT DAT HAN; Lau K W, 2008, Pattern Recognition, V41, DOI 10.1016/j.patcog.2007.08.013; Lin Chih-Jen, 2001, COMP METHODS MULTICL; Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865; Newman D. J., 1998, UCI REPOSITORY MACHI; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; PAWLAK M, 1994, P INT C PATT REC; Platt JC, 2000, ADV NEUR IN, V12, P547; Rifkin R, 2004, J MACH LEARN RES, V5, P101; RODDICK JF, 2001, TEMPORAL SPATIAL SPA; Schrijver A., 1998, THEORY LINEAR INTEGE; Vapnik V.N., 1998, STAT LEARNING THEORY; VINCENT P, 2001, ADV NEURAL INFORM PR, P985; Weinberger KQ, 2006, ADV NEURAL INFORM PR, V18, P1473; Zhang H., 2006, P IEEE C COMP VIS PA; Zhu X., 2002, P INT C MACH LEARN	35	4	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	APR	2010	22	4					537	549		10.1109/TKDE.2009.116		13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	557FK	WOS:000274654800006	
J	Maas, MC; van der Laan, DJ; van Eijk, CWE; Schaart, DR; Beekman, FJ; Bruyndonckx, P; Lemaitre, C				Maas, Marnix C.; van der Laan, D. J. (Jan); van Eijk, Carel W. E.; Schaart, Dennis R.; Beekman, Freek J.; Bruyndonckx, Peter; Lemaitre, Cedric			Model of the point spread function of monolithic scintillator PET detectors for perpendicular incidence	MEDICAL PHYSICS			English	Article						avalanche photodiodes; positron emission tomography; solid scintillation detectors	SMALL-ANIMAL PET; HIGH-RESOLUTION; SIMULATION TOOLKIT; APD ARRAYS; BLOCKS; LSO; RECONSTRUCTION; DIMENSIONS; SCANNER; MODULES	Methods: A PSF model was developed that essentially consists of two convolved components, one accounting for the spatial distribution of the energy deposited by annihilation photons within the crystal, and the other for the influences of statistical signal fluctuations and electronic noise. The model was validated through comparison with spatial resolution measurements on a detector consisting of an LYSO:Ce(3+) crystal read out by two APD arrays. Results: The model is shown to describe the measured detector spatial response well at the noise levels found in the experiments. In addition, it is demonstrated how the model can be used to correct the measured spatial response for the influence of the finite diameter of the annihilation photon beam used in the experiments, thus obtaining an estimate of the intrinsic detector PSF. Conclusions: Despite its simplicity, the proposed model is an accurate tool for analyzing the detector PSF of monolithic scintillator detectors and can be used to estimate the intrinsic detector PSF from the measured one.	[Maas, Marnix C.; van der Laan, D. J. (Jan); van Eijk, Carel W. E.; Schaart, Dennis R.; Beekman, Freek J.] Delft Univ Technol, NL-2629 JB Delft, Netherlands; [Beekman, Freek J.] Univ Med Ctr Utrecht, Rudolf Magnus Inst, Utrecht, Netherlands; [Beekman, Freek J.] Image Sci Inst, Utrecht, Netherlands; [Bruyndonckx, Peter; Lemaitre, Cedric] Vrije Univ Brussels, B-1050 Brussels, Belgium	Schaart, DR (reprint author), Delft Univ Technol, Mekelweg 15, NL-2629 JB Delft, Netherlands.	d.r.schaart@tudelft.nl					Abreu MC, 2006, IEEE T NUCL SCI, V53, P71, DOI 10.1109/TNS.2006.870173; Agostinelli S, 2003, NUCL INSTRUM METH A, V506, P250, DOI 10.1016/S0168-9002(03)01368-8; Aliaga RJ, 2006, IEEE T NUCL SCI, V53, P776, DOI 10.1109/TNS.2006.875438; Bruyndonckx P, 2008, IEEE T NUCL SCI, V55, P918, DOI 10.1109/TNS.2008.922811; Bruyndonckx P, 2006, IEEE NUCL SCI CONF R, P2518, DOI 10.1109/NSSMIC.2006.354422; Bruyndonckx P, 2006, IEEE T NUCL SCI, V53, P2536, DOI 10.1109/TNS.2006.882799; Bruyndonckx P, 2004, IEEE T NUCL SCI, V51, P2520, DOI 10.1109/TNS.2004.835782; CHERRY S, 2004, PHYS MED BIOL, V13, pR48; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Jan S, 2004, PHYS MED BIOL, V49, P4543, DOI 10.1088/0031-9155/49/19/007; JEAN YC, 1990, PHYS REV B, V42, P9705, DOI 10.1103/PhysRevB.42.9705; Joung J, 2002, NUCL INSTRUM METH A, V489, P584, DOI 10.1016/S0168-9002(02)00861-6; KARP JS, 1990, J NUCL MED, V31, P617; Krishnamoorthy S, 2005, IEEE NUCL SCI CONF R, P2845; Lagarias JC, 1998, SIAM J OPTIMIZ, V9, P112, DOI 10.1137/S1052623496303470; Leahy RM, 2000, STAT COMPUT, V10, P147, DOI 10.1023/A:1008946426658; LeBlanc JW, 2004, IEEE T NUCL SCI, V51, P746, DOI 10.1109/TNS.2004.829754; Lerche CW, 2009, NUCL INSTRUM METH A, V604, P359, DOI 10.1016/j.nima.2009.01.060; Maas MC, 2008, IEEE T NUCL SCI, V55, P842, DOI 10.1109/TNS.2008.921493; Maas MC, 2009, PHYS MED BIOL, V54, P1893, DOI 10.1088/0031-9155/54/7/003; Maas MC, 2004, IEEE NUCL SCI CONF R, P2942; McCallum S, 2005, PHYS MED BIOL, V50, P4187, DOI 10.1088/0031-9155/50/17/019; MIYAOKA RS, 2008, IEEE NUCL SCI S, P4688; Moehrs S, 2006, PHYS MED BIOL, V51, P1113, DOI 10.1088/0031-9155/51/5/004; Panin VY, 2006, IEEE T MED IMAGING, V25, P907, DOI 10.1109/TMI.2006.876171; Qi JY, 1998, PHYS MED BIOL, V43, P1001, DOI 10.1088/0031-9155/43/4/027; Schaart DR, 2009, PHYS MED BIOL, V54, P3501, DOI 10.1088/0031-9155/54/11/015; van der Laan DJ, 2007, NUCL INSTRUM METH A, V571, P227, DOI 10.1016/j.nima.2006.10.069; VANEIJK CWE, 2008, IEEE NUCL SCI S, P3861; Vaska P, 2004, IEEE NUCL SCI CONF R, P3463; Webb A., 2002, STAT PATTERN RECOGNI	31	5	5	AMER ASSOC PHYSICISTS MEDICINE AMER INST PHYSICS	MELVILLE	STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA	0094-2405		MED PHYS	Med. Phys.	APR	2010	37	4					1904	1913		10.1118/1.3355889		10	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	577GT	WOS:000276211200055	
J	Toyama, J; Kudo, M; Imai, H				Toyama, Jun; Kudo, Mineichi; Imai, Hideyuki			Probably correct k-nearest neighbor search in high dimensions	PATTERN RECOGNITION			English	Article						Pattern recognition; The k-nearest neighbor method; Probably correct algorithm; PAC framework	ALGORITHM; RULE	A novel approach for k-nearest neighbor (k-NN) searching with Euclidean metric is described. It is well known that many sophisticated algorithms cannot beat the brute-force algorithm when the dimensionality is high. In this study, a probably correct approach, in which the correct set of k-nearest neighbors is obtained in high probability, is proposed for greatly reducing the searching time. We exploit the marginal distribution of the k th nearest neighbors in low dimensions, which is estimated from the stored data (an empirical percentile approach). We analyze the basic nature of the marginal distribution and show the advantage of the implemented algorithm, which is a probabilistic variant of the partial distance searching. Its query time is sublinear in data size n, that is, O(mn delta) with S=o(1) in n and delta <= 1, for any fixed dimension m. (C) 2009 Elsevier Ltd. All rights reserved.	[Toyama, Jun; Kudo, Mineichi; Imai, Hideyuki] Hokkaido Univ, Grad Sch Informat Sci & Technol, Div Comp Sci, Sapporo, Hokkaido 0600814, Japan	Kudo, M (reprint author), Hokkaido Univ, Grad Sch Informat Sci & Technol, Div Comp Sci, Sapporo, Hokkaido 0600814, Japan.	mine@main.ist.hokudai.ac.jp	Kudo, Mineichi/B-9973-2011				Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494; Andoni A., 2006, NEAREST NEIGHBOR MET; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Baccini A., 1996, P ORD SYMB DAT AN, P359; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; BENTLEY JL, 1980, ACM T MATH SOFTWARE, V6, P563, DOI 10.1145/355921.355927; BERCHTOLD S, 1998, P 14 IEEE C DAT ENG, P23; Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28; Califano A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), DOI 10.1109/CVPR.1991.139656; CHANG CC, 1993, PATTERN RECOGN LETT, V14, P625, DOI 10.1016/0167-8655(93)90047-H; CHENG DY, 1984, P IEEE INT C AC SPEE, P372; Ciaccia P., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), DOI 10.1109/ICDE.2000.839417; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CUNN YL, MNIST DATASET HANDWR; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Djouadi A, 1997, IEEE T PATTERN ANAL, V19, P277, DOI 10.1109/34.584107; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; Fukunaga K., 1990, INTRO STAT PATTERN R; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Guttman A., 1984, ACM SIGMOD, P47; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; Kleinberg J. M., 1997, P 29 ANN ACM S THEOR, P599, DOI 10.1145/258533.258653; Kwak N, 2008, IEEE T PATTERN ANAL, V30, P1672, DOI 10.1109/TPAMI.2008.114; MANEEWONGVATANA S, 2001, LECT NOTES COMPUTER, V2513, P172; McNames J, 2001, IEEE T PATTERN ANAL, V23, P964, DOI 10.1109/34.955110; Nene SA, 1997, IEEE T PATTERN ANAL, V19, P989, DOI 10.1109/34.615448; Sellis T., 1987, Proceedings of the Thirteenth International Conference on Very Large Data Bases: 1987 13th VLDB; Wolfson H.J., 1990, P 1 EUR C COMP VIS, P526	31	5	6	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	APR	2010	43	4					1361	1372		10.1016/j.patcog.2009.09.026		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	561CW	WOS:000274954100014	
J	Caulier, Y				Caulier, Yannick			Inspection of complex surfaces by means of structured light patterns	OPTICS EXPRESS			English	Article								This paper addresses the generalization of a surface inspection methodology developed within an industrial context for the characterization of specular cylindrical surfaces. The principle relies on the interpretation of a stripe pattern, obtained after projecting a structured light onto the surface to be inspected. The main objective of this paper is to apply this technique to a broader range of surface geometries and types, i.e. to free-form rough and free-form specular shapes. One major purpose of this paper is to propose a general free-form stripe image interpretation approach on the basis of a four step procedure: (i) comparison of different feature-based image content description techniques, (ii) determination of optimal feature sub-groups, (iii) fusion of the most appropriate ones, and (iv) selection of the optimal features. The first part of this paper is dedicated to the general problem statement with the definition of different image data sets that correspond to various types of free-form rough and specular shapes recorded with a structured illumination. The second part deals with the definition and optimization of the most appropriate pattern recognition process. It is shown that this approach leads to an increase in the classification rates of more than 2 % between the initial fused set and the selected one. Then, it is demonstrated that with approximately a fourth of the initial features, similar high classification rates of free-form surfaces can be obtained. (C) 2010 Optical Society of America	Fraunhofer Inst Integrated Circuits IIS, Dept Proc Integrated Inspect Syst, D-91058 Erlangen, Germany	Caulier, Y (reprint author), Fraunhofer Inst Integrated Circuits IIS, Dept Proc Integrated Inspect Syst, D-91058 Erlangen, Germany.	yannick.caulier@iis.fraunhofer.de			Bavarian Research Foundation BFS (Bayerische Forschungsstiftung)	The author would like to thank the Bavarian Research Foundation BFS (Bayerische Forschungsstiftung) for its financial support.	BESL JP, 1985, ACM COMPUT SURV, V17, P75; CAULIER Y, 2007, EURASIP J IMAGE VIDE, V2007; CAULIER Y, 2008, J OPT ENG, V47; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DELCROIX G, 2001, INT SOC ELECT IMAGIN, V10, P196; Gutierrez-Osuna R, 2002, IEEE SENS J, V2, P189, DOI 10.1109/JSEN.2002.800688; HUANG Z, 1992, 11 INT C IM SPEECH S, V3, P105; Kammel S., 2004, THESIS U KARLSRUHE; Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence; Kunttu I, 2006, MACH VISION APPL, V17, P211, DOI 10.1007/s00138-006-0030-6; Leon FP, 1997, P SOC PHOTO-OPT INS, V3208, P394; LI WB, 2005, IEEE T ANTENN PROPAG, V53, P1154; MARINO P, 1999, 25 ANN C IEEE IND EL, V3, P1330; NAYAR SK, 1990, IEEE T ROBOTIC AUTOM, V6, P208, DOI 10.1109/70.54736; PERNKOPF F, 2004, P 17 INT C PATT REC; PETZ M, 2002, OPTICAL 3D MEASUREME; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; REINDL I, 2007, IEEE C INSTR MEAS IM; SEULIN R, 2001, 5 INT C QUAL CONTR A; SOON HS, 2005, FRINGE 2005 FAULT DE; Tsai DM, 2003, IMAGE VISION COMPUT, V21, P307, DOI 10.1016/S0262-8856(03)00007-6; UNSALAN C, 1998, THESIS U HACETTEPE T; Weska J. S., 1978, COMPUT GRAPHICS IMAG, V7, P259; WILLIAMS A, 2008, INSPECT MAGAZINE; Witten I. H., 2008, M KAUFMANN SERIES DA; WOODHAM RJ, 1991, PHOTOMETRIC STEREO L; *AC 3D, 2005, FE SUBSTR BUMP INSP; *COM AG, 2005, FEINF FOX HIGH RES 2; *SOLV, 2007, PREC 3D WAF BUMP INS	29	3	4	OPTICAL SOC AMER	WASHINGTON	2010 MASSACHUSETTS AVE NW, WASHINGTON, DC 20036 USA	1094-4087		OPT EXPRESS	Opt. Express	MAR 29	2010	18	7					6642	6660				19	Optics	Optics	582MP	WOS:000276602000024	
J	Huang, Y; Xu, D; Cham, TJ				Huang, Yi; Xu, Dong; Cham, Tat-Jen			Face and Human Gait Recognition Using Image-to-Class Distance	IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY			English	Article						Face recognition; human gait recognition; image-to-class distance	ALGORITHMS; CHALLENGE	We propose a new distance measure for face recognition and human gait recognition. Each probe image (a face image or an average human silhouette image) is represented as a set of local features uniformly sampled over a grid with fixed spacing, and each gallery image is represented as a set of local features sampled at each pixel. We formulate an integer programming problem to compute the distance (referred to as the image-to-class distance) from one probe image to all the gallery images belonging to a certain class, in which any feature of the probe image can be matched to only one feature from one of the gallery images. Considering computational efficiency as well as the fact that face images or average human silhouette images are roughly aligned in the preprocessing step, we also enforce a spatial neighborhood constraint by only allowing neighboring features that are within a given spatial distance to be considered for feature matching. The integer programming problem is further treated as a classical minimum-weight bipartite graph matching problem, which can be efficiently solved with the Kuhn-Munkres algorithm. We perform comprehensive experiments on three benchmark face databases: 1) the CMU PIE database; 2) the FERET database; and 3) the FRGC database, as well as the USF Human ID gait database. The experiments clearly demonstrate the effectiveness of our image-to-class distance.	[Huang, Yi; Cham, Tat-Jen] Nanyang Technol Univ, Sch Comp Engn, Ctr Multimedia & Network Technol, Singapore 639798, Singapore	Huang, Y (reprint author), Nanyang Technol Univ, Sch Comp Engn, Ctr Multimedia & Network Technol, Singapore 639798, Singapore.	hu0005yi@ntu.edu.sg; dongxu@ntu.edu.sg; ASTJCham@ntu.edu.sg	Xu, Dong/A-3694-2011		Singapore National Research Foundation Interactive Digital Media Research and Development Program [NRF2008IDM-IDM004-018]; MOE AcRF Tier-1 [RG63/07]	Manuscript received September 19, 2008; revised March 19, 2009 and June 10, 2009. First version published November 3, 2009; current version published March 5, 2010. This work was supported by the Singapore National Research Foundation Interactive Digital Media Research and Development Program, under research Grant NRF2008IDM-IDM004-018 and MOE AcRF Tier-1 Grant RG63/07. This paper was recommended by Associate Editor S. Pankanti.	BELHUMEUR P, 1997, IEEE T PATTERN ANAL, V7, P711; BOIMAN O, 2006, P NEUR INF PROC SYST; Boiman O., 2008, P IEEE C COMP VIS PA, P1; CHEN LB, 2004, P AS C COMP VIS; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; Cootes T., 1999, P BRIT MACH VIS C, V1, P173; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38; Kale A, 2004, IEEE T IMAGE PROCESS, V13, P1163, DOI 10.1109/TIP.2004.832865; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Liu Z., 2004, P IEEE COMP SOC C CO, P211; Liu ZY, 2006, IEEE T PATTERN ANAL, V28, P863; LUCEY S, 2004, P IEEE C COMP VIS PA, V2, P855, DOI 10.1109/CVPR.2004.1315254; LUCEY S, 2005, P BRIT MACH VIS C; MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32; Phillips PJ, 2005, PROC CVPR IEEE, P947; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39; Shan S. G., 2004, P IEEE INT C AUT FAC, P314; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Sivic J., 2003, Proceedings Ninth IEEE International Conference on Computer Vision; Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), DOI 10.1109/CVPR.1991.139758; Wang LW, 2005, IEEE T PATTERN ANAL, V27, P1334; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; Xu D, 2008, IEEE T IMAGE PROCESS, V17, P2256, DOI 10.1109/TIP.2008.2004430; Xu D, 2006, IEEE T CIRC SYST VID, V16, P896, DOI 10.1109/TCSVT.2006.877418; Xu D, 2007, IEEE T IMAGE PROCESS, V16, P2811, DOI 10.1109/TIP.2007.906769	28	9	9	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1051-8215		IEEE T CIRC SYST VID	IEEE Trans. Circuits Syst. Video Technol.	MAR	2010	20	3					431	438		10.1109/TCSVT.2009.2035852		8	Engineering, Electrical & Electronic	Engineering	565ND	WOS:000275299600009	
J	Ghasemzadeh, H; Loseu, V; Jafari, R				Ghasemzadeh, Hassan; Loseu, Vitali; Jafari, Roozbeh			Structural Action Recognition in Body Sensor Networks: Distributed Classification Based on String Matching	IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE			English	Article						Body sensor networks (BSNs); collaborative signal processing; distributed computing; motion primitives; physical movement monitoring	CLUSTER-ANALYSIS	Mobile sensor-based systems are emerging as promising platforms for healthcare monitoring. An important goal of these systems is to extract physiological information about the subject wearing the network. Such information can be used for life logging, quality of life measures, fall detection, extraction of contextual information, and many other applications. Data collected by these sensor nodes are overwhelming, and hence, an efficient data processing technique is essential. In this paper, we present a system using inexpensive, off-the-shelf inertial sensor nodes that constructs motion transcripts from biomedical signals and identifies movements by taking collaboration between the nodes into consideration. Transcripts are built of motion primitives and aim to reduce the complexity of the original data. We then label each primitive with a unique symbol and generate a sequence of symbols, known as motion template, representing a particular action. This model leads to a distributed algorithm for action recognition using edit distance with respect to motion templates. The algorithm reduces the number of active nodes during every classification decision. We present our results using data collected from five normal subjects performing transitional movements. The results clearly illustrate the effectiveness of our framework. In particular, we obtain a classification accuracy of 84.13% with only one sensor node involved in the classification process.	[Ghasemzadeh, Hassan; Loseu, Vitali; Jafari, Roozbeh] Univ Texas Dallas, Dept Elect Engn, Richardson, TX 75080 USA	Ghasemzadeh, H (reprint author), Univ Texas Dallas, Dept Elect Engn, Richardson, TX 75080 USA.	h.ghasemzadeh@utdallas.edu; vitali.loseu@utdallas.edu; rjafari@utdallas.edu					AFALG J, 2007, ADV KNOWL DISCOVERY, P23; Akyildiz IF, 2002, COMPUT NETW, V38, P393, DOI 10.1016/S1389-1286(01)00302-4; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Fihl P, 2006, LECT NOTES COMPUT SC, V4069, P375; FINDLEY LJ, 1981, J NEUROL NEUROSUR PS, V44, P534, DOI 10.1136/jnnp.44.6.534; Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578; Ghasemzadeh H, 2009, IEEE J SEL AREA COMM, V27, P58, DOI 10.1109/JSAC.2009.090107; GHASEMZADEH H, 2009, P IEEE ACM DES AUT T, P1; GHASEMZADEH H, 2009, 31 ANN INT C IEEE EN; Guenterberg E., 2009, P 5 IEEE INT C DISTR, P145; GUERRAFILHO G, FS 05, P70; GUIMARAES G, 2005, P 18 INT C INN APPL, P332; HARMS H, P 4 INT C BOD AR NET; HUSZ Z, P IEEE C ADV VID SIG, P330; HYMAN L.M., 1975, PHONOLOGY THEORY ANA; JENKINS OC, P 2 INT JOINT C AUT, P225; JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588; KANG S, 2008, P INT C MOB SYST APP, P267, DOI DOI 10.1145/1378600.1378630; Levenshtein V. I., 1966, SOV PHYS DOKL, V10, P707; MacQueen J. B., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; McLachlan G., 2008, EM ALGORITHM EXTENSI; MUSALOIU-E R., 2007, INT J SENS NETW, V3, P43; Niwase N, 2005, IEICE T INF SYST, VE88D, P2492, DOI 10.1093/ietisy/e88-d.11.2492; POLASTRE J, P 4 INT S INF PROC S, P364; ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7; Stergiou N, 2003, INNOVATIVE ANAL HUMA; STIEFMEIER T, P ICST 2 INT C BOD A, P1; Veltink P H, 1996, IEEE Trans Rehabil Eng, V4, P375, DOI 10.1109/86.547939; Zappi P, 2008, LECT NOTES COMPUT SC, V4913, P17	31	10	12	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1089-7771		IEEE T INF TECHNOL B	IEEE T. Inf. Technol. Biomed.	MAR	2010	14	2					425	435		10.1109/TITB.2009.2036722		11	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Medical Informatics	Computer Science; Mathematical & Computational Biology; Medical Informatics	570IG	WOS:000275666100030	
J	Roh, SB; Ahn, TC; Pedrycz, W				Roh, Seok-Beom; Ahn, Tae-Chon; Pedrycz, Witold			The Refinement of Models With the Aid of the Fuzzy k-Nearest Neighbors Approach	IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT			English	Article						Fuzzy k-nearest neighbors (kNN); global model; incremental model; local model; model refinement	CLASSIFICATION; REGRESSION	In this paper, we propose a new design methodology that supports the development of hybrid incremental models. These models result through an iterative process in which a parametric model and a nonparametric model are combined so that their underlying and complementary functionalities become fully exploited. The parametric component of the hybrid model captures some global relationships between the input variables and the output variable. The nonparametric model focuses on capturing local input-output relationships and thus augments the behavior of the model being formed at the global level. In the underlying design, we consider linear and quadratic regression to be a parametric model, whereas a fuzzy k-nearest neighbors model serves as the nonparametric counterpart of the overall model. Numeric results come from experiments that were carried out on some low-dimensional synthetic data sets and several machine learning data sets from the University of California-Irvine Machine Learning Repository.	[Roh, Seok-Beom; Ahn, Tae-Chon] Wonkwang Univ, Dept Elect Elect & Informat Engn, Iksan 570749, South Korea; [Pedrycz, Witold] Polish Acad Sci, Syst Res Inst, PL-01447 Warsaw, Poland; [Pedrycz, Witold] Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2G7, Canada	Roh, SB (reprint author), Wonkwang Univ, Dept Elect Elect & Informat Engn, Iksan 570749, South Korea.	nado@wonkwang.ac.kr; tcahn@wonkwang.ac.kr; pedrycz@ee.ualberta.ca			Wonkwang University	Manuscript received October 8, 2008; revised April 14, 2009. First published September 22, 2009; current version published February 10, 2010. This work was supported in part by the Wonkwang University (2007). The Associate Editor coordinating the review process for this paper was Dr. Gilles Mauris.	Blanzieri E, 2008, IEEE T GEOSCI REMOTE, V46, P1804, DOI 10.1109/TGRS.2008.916090; CHEN S, 1999, J CHIN CHEM SOC-TAIP, V4, P239; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ferrari S, 2005, IEEE T INSTRUM MEAS, V54, P1463, DOI 10.1109/TIM.2005.851471; Guvenir HA, 2000, KNOWL-BASED SYST, V13, P207; Hardle W, 1990, APPL NONPARAMETRIC R; Hastie T, 2001, ELEMENTS STAT LEARNI; Li W, 2008, IEEE T INSTRUM MEAS, V57, P2273, DOI 10.1109/TIM.2008.922092; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; Pedrycz W, 2008, IEEE T INSTRUM MEAS, V57, P829, DOI 10.1109/TIM.2007.913809; Pedrycz W, 2007, IEEE T FUZZY SYST, V15, P507, DOI 10.1109/TFUZZ.2006.889967; Samaniego L, 2008, IEEE T GEOSCI REMOTE, V46, P2112, DOI 10.1109/TGRS.2008.916629; VARALLYAY G, 2006, AGROKEM TALAJTAN, V55, P1; Wang N, 2007, INFORM SCIENCES, V177, P3882, DOI 10.1016/j.ins.2007.03.002; Weatherspoon MH, 2007, IEEE T INSTRUM MEAS, V56, P2067, DOI 10.1109/TIM.2007.895585	15	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9456		IEEE T INSTRUM MEAS	IEEE Trans. Instrum. Meas.	MAR	2010	59	3					604	615		10.1109/TIM.2009.2025070		12	Engineering, Electrical & Electronic; Instruments & Instrumentation	Engineering; Instruments & Instrumentation	553RC	WOS:000274383500014	
J	Wei, JM; Wang, SQ; Yuan, XJ				Wei, Jin-Mao; Wang, Shu-Qin; Yuan, Xiao-Jie			Ensemble Rough Hypercuboid Approach for Classifying Cancers	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						Rough sets; rough hypercuboid; explicit region; implicit region; gene expression data	GENE-EXPRESSION SIGNATURES; ARTIFICIAL NEURAL-NETWORKS; FEATURE-SELECTION; NEAREST-NEIGHBOR; MOLECULAR CLASSIFICATION; SUBCELLULAR-LOCALIZATION; CLASS PREDICTION; SETS; PROTEINS; INFORMATION	Cancer classification is the critical basis for patient-tailored therapy. Conventional histological analysis tends to be unreliable because different tumors may have similar appearance. The advances in microarray technology make individualized therapy possible. Various machine learning methods can be employed to classify cancer tissue samples based on microarray data. However, few methods can be elegantly adopted for generating accurate and reliable as well as biologically interpretable rules. In this paper, we introduce an approach for classifying cancers based on the principle of minimal rough fringe. For training rough hypercuboid classifiers from gene expression data sets, the method dynamically evaluates all available genes and sifts the genes with the smallest implicit regions as the dimensions of implicit hypercuboids. An unseen object is predicted to be a certain class if it falls within the corresponding class hypercuboid. Based upon the method, ensemble rough hypercuboid classifiers are subsequently constructed. Experimental results on some open cancer gene expression data sets show that the proposed method is capable of generating accurate and interpretable rules compared with some other machine learning methods. Hence, it is a feasible way of classifying cancer tissues in biomedical applications.	[Wei, Jin-Mao; Yuan, Xiao-Jie] Nankai Univ, Coll Informat Tech Sci, Tianjin 300071, Peoples R China; [Wang, Shu-Qin] NE Normal Univ, Coll Math & Stat, Changchun 130024, Jilin, Peoples R China; [Wang, Shu-Qin] NE Normal Univ, MOE, Key Lab Appl Stat, Changchun 130024, Jilin, Peoples R China	Wei, JM (reprint author), Nankai Univ, Coll Informat Tech Sci, Weijin Rd 94, Tianjin 300071, Peoples R China.	weijm@nankai.edu.cn; wangsq562@nenu.edu.cn; yuanxj@nankai.edu.cn			Science Foundation of Jilin Province [20040529]; Industrialization Foundation of Changchun High-Tech [06GJ20]; National 863 High Technology Research and Development Program of China [2009AA01Z152]	This work was supported by the Science Foundation of Jilin Province under grant 20040529, the Industrialization Foundation of Changchun High-Tech under grant 06GJ20, and the National 863 High Technology Research and Development Program of China under grant 2009AA01Z152. Guo-Ying Wang and Yang Xu collected and preprocessed the data.	Ali K., 1995, LINK ERROR CORRELATI; Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Ananthanarayana VS, 2003, PATTERN RECOGN LETT, V24, P851, DOI 10.1016/S0167-8655(02)00197-6; Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765; Bazan J. G., 1994, P S METH INT SYST, P346; Bazan JG, 2006, FUND INFORM, V72, P37; BAZAN JG, 1996, P 6 INT C INF PROC M, V3, P1147; Beer DG, 2002, NAT MED, V8, P816, DOI 10.1038/nm733; Bhattacharjee A, 2001, P NATL ACAD SCI USA, V98, P13790, DOI 10.1073/pnas.191502998; Bi YX, 2006, ARTIF INTELL REV, V26, P191, DOI 10.1007/s10462-007-9049-y; BUNDY A, 1985, ARTIF INTELL, V27, P137, DOI 10.1016/0004-3702(85)90052-9; Chou KC, 2007, BIOCHEM BIOPH RES CO, V357, P633, DOI 10.1016/j.bbrc.2007.03.162; Chou KC, 2006, CURR MED CHEM, V13, P3263, DOI 10.2174/092986706778773077; Chou KC, 1996, ANAL BIOCHEM, V233, P1, DOI 10.1006/abio.1996.0001; Chou KC, 2004, CURR MED CHEM, V11, P2105; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2007, BIOCHEM BIOPH RES CO, V360, P339, DOI 10.1016/j.bbrc.2007.06.027; Chou KC, 2006, BIOCHEM BIOPH RES CO, V347, P150, DOI 10.1016/j.bbrc.2006.06.059; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich TG, 2000, LECT NOTES COMPUTER, P1; Duda R., 1973, PATTERN CLASSIFICATI; GEMAN D, 2004, STAT APPL GENET MOL, V3; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Greco S, 2001, EUR J OPER RES, V129, P1, DOI 10.1016/S0377-2217(00)00167-3; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HU Q, 2006, P 2006 IEEE C MACH L, P13; Hu QH, 2007, PATTERN RECOGN, V40, P3728, DOI 10.1016/j.patcog.2007.04.022; Hu X., 2001, P IEEE INT C DAT MIN, P233; Kedarisetti KD, 2006, BIOCHEM BIOPH RES CO, V348, P981, DOI 10.1016/j.bbrc.2006.07.141; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Kim D, 2001, PATTERN RECOGN, V34, P1613, DOI 10.1016/S0031-3203(00)00057-1; Kim HC, 2003, PATTERN RECOGN, V36, P2757, DOI 10.1016/S0031-3203(03)00175-4; Kittler J, 1998, PATTERN ANAL APPL, V1, P18, DOI 10.1007/BF01238023; Lin T. Y., 1997, ROUGH SETS DATA MINI; Lubec G, 2005, PROG NEUROBIOL, V77, P90, DOI 10.1016/j.pneurobio.2005.10.001; Nguyen HS, 2006, LECT NOTES COMPUT SC, V4100, P334; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; PAWLAK Z, 1988, INT J MAN MACH STUD, V29, P81, DOI 10.1016/S0020-7373(88)80032-4; Pawlak Z., 1991, ROUGH SETS THEORETIC; Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; ROYA A, 2003, PATTERN RECOGN, V24, P895; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1023/A:1022661727670; Shen HB, 2006, BIOINFORMATICS, V22, P1717, DOI 10.1093/bioinformatics/btl170; Shen HB, 2007, BIOCHEM BIOPH RES CO, V355, P1006, DOI 10.1016/j.bbrc.2007.02.071; Shen HB, 2007, PROTEIN ENG DES SEL, V20, P39, DOI 10.1093/protein-gzl053; Shen Q, 2002, PATTERN RECOGN, V35, P2425, DOI 10.1016/S0031-3203(01)00229-1; SINDHWANI V, 2001, P 1 SIAM INT C DAT M, P5; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; Su AI, 2001, CANCER RES, V61, P7388; Swiniarski RW, 2003, PATTERN RECOGN LETT, V24, P833, DOI 10.1016/S0167-8655(02)00196-4; Tan AC, 2005, BIOINFORMATICS, V21, P3896, DOI 10.1093/bioinformatics/bti631; Theodoridis S, 2003, PATTERN RECOGNITION; THORNTON C, 1987, P INT JOINT C ART IN, P301; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Tumer K., 1996, Connection Science, V8, DOI 10.1080/095400996116839; Vapnik V.N., 1995, NATURE STAT LEARNING; Wang XY, 2007, PATTERN RECOGN LETT, V28, P459, DOI 10.1016/j.patrec.2006.09.003; Wei JM, 2007, KNOWL-BASED SYST, V20, P695, DOI 10.1016/j.knosys.2006.10.001; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; Yao X, 1998, IEEE T SYST MAN CY B, V28, P417, DOI 10.1109/3477.678637; Yao YY, 2001, INT J INTELL SYST, V16, P87, DOI 10.1002/1098-111X(200101)16:1<87::AID-INT7>3.0.CO;2-S; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6; Zhong N, 2001, J INTELL INF SYST, V16, P199, DOI 10.1023/A:1011219601502; Zhou ZH, 2005, IEEE T SYST MAN CY B, V35, P725, DOI 10.1109/TSMCB.2005.845396; Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X	69	3	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAR	2010	22	3					381	391		10.1109/TKDE.2009.114		11	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	545BL	WOS:000273707000006	
J	Zheng, WM; Lin, ZC; Tang, XO				Zheng, Wenming; Lin, Zhouchen; Tang, Xiaoou			A Rank-One Update Algorithm for Fast Solving Kernel Foley-Sammon Optimal Discriminant Vectors	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						Dimensionality reduction; discriminant analysis; kernel Foley-Sammon optimal discriminant vectors (KFSODVs); principal eigenvector	FACE-RECOGNITION; COMPONENT ANALYSIS; FEATURE-EXTRACTION; OPTIMAL SET; CLASSIFICATION; TRANSFORMATION; CRITERION; LDA	Discriminant analysis plays an important role in statistical pattern recognition. A popular method is the Foley-Sammon optimal discriminant vectors (FSODVs) method, which aims to find an optimal set of discriminant vectors that maximize the Fisher discriminant criterion under the orthogonal constraint. The FSODVs method outperforms the classic Fisher linear discriminant analysis (FLDA) method in the sense that it can solve more discriminant vectors for recognition. Kernel Foley-Sammon optimal discriminant vectors (KFSODVs) is a nonlinear extension of FSODVs via the kernel trick. However, the current KFSODVs algorithm may suffer from the heavy computation problem since it involves computing the inverse of matrices when solving each discriminant vector, resulting in a cubic complexity for each discriminant vector. This is costly when the number of discriminant vectors to be computed is large. In this paper, we propose a fast algorithm for solving the KFSODVs, which is based on rank-one update (ROU) of the eigensytems. It only requires a square complexity for each discriminant vector. Moreover, we also generalize our method to efficiently solve a family of optimally constrained generalized Rayleigh quotient (OCGRQ) problems which include many existing dimensionality reduction techniques. We conduct extensive experiments on several real data sets to demonstrate the effectiveness of the proposed algorithms.	[Zheng, Wenming] Southeast Univ, Res Ctr Learning Sci, Minist Educ, Key Lab Child Dev & Learning Sci, Nanjing 210096, Jiangsu, Peoples R China; [Lin, Zhouchen; Tang, Xiaoou] Microsoft Res Asia, Beijing 100080, Peoples R China	Zheng, WM (reprint author), Southeast Univ, Res Ctr Learning Sci, Minist Educ, Key Lab Child Dev & Learning Sci, Nanjing 210096, Jiangsu, Peoples R China.	wenming_zheng@seu.edu.cn; zhoulin@microsoft.com; xtang@ie.cuhk.edu.hk	Tang, Xiaoou/G-6509-2012		Natural Science Foundation of China (NSFC) [60503023, 60872160]; Southeast University of China [XJ2008320]	This work was supported in part by the Natural Science Foundation of China (NSFC) under Grants 60503023 and 60872160, and in part by the Science Technology Foundation of Southeast University of China under Grant XJ2008320.	Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; BELHUMEUR P, 1997, IEEE T PATTERN ANAL, V7, P711; Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945; Cai D, 2005, P 28 ANN INT ACM SIG, P3, DOI 10.1145/1076034.1076039; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUCHENE J, 1988, IEEE T PATTERN ANAL, V10, P978, DOI 10.1109/34.9121; Fisher RA, 1936, ANN EUGENIC, V7, P179; FOLEY DH, 1975, IEEE T COMPUT, VC 24, P281, DOI 10.1109/T-C.1975.224208; Fukunaga K., 1990, INTRO STAT PATTERN R; Golub G., 1996, MATRIX COMPUTATIONS; Graham D. B., 1998, NATO ASI SERIES F, V163, P446; Howland P, 2004, IEEE T PATTERN ANAL, V26, P995, DOI 10.1109/TPAMI.2004.46; Jin Z, 2001, PATTERN RECOGN, V34, P1405, DOI 10.1016/S0031-3203(00)00084-4; Liang YX, 2007, PATTERN RECOGN, V40, P3606, DOI 10.1016/j.patcog.2007.03.030; Liang ZZ, 2005, PATTERN RECOGN, V38, P307, DOI 10.1016/j.patcog.2004.06.006; LIU K, 1992, PATTERN RECOGN, V25, P731, DOI 10.1016/0031-3203(92)90136-7; Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P117, DOI 10.1109/TNN.2002.806629; Martinez A, 1998, 24 CVC TECH; OKADA T, 1985, PATTERN RECOGN, V18, P139, DOI 10.1016/0031-3203(85)90037-8; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Qin AK, 2005, PATTERN RECOGN, V38, P613, DOI 10.1016/j.patcog.2004.09.007; RAO CR, 1948, J ROY STAT SOC B, V10, P159; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SWETS D, 1996, IEEE T PATTERN ANAL, V8, P831; WANG X, 2003, P 9 IEEE INT C COMP, V1, P13; Wang XG, 2004, PROC CVPR IEEE, P564; Yang J, 2005, IEEE T PATTERN ANAL, V27, P230; Ye JP, 2005, J MACH LEARN RES, V6, P483; Zheng WM, 2009, IEEE SIGNAL PROC LET, V16, P766, DOI 10.1109/LSP.2009.2023939; Zheng WM, 2005, IEEE T NEURAL NETWOR, V16, P1, DOI 10.1109/TNN.2004.836239; Zheng WM, 2006, NEURAL COMPUT, V18, P979	31	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	MAR	2010	21	3					393	403		10.1109/TNN.2009.2037149		11	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	562HH	WOS:000275040300003	
J	Marchiori, E				Marchiori, Elena			Class Conditional Nearest Neighbor for Large Margin Instance Selection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computing methodologies; artificial intelligence; learning; heuristics design; machine learning	LARGE DATA SETS; LEARNING ALGORITHMS; CLASSIFICATION; NETWORKS; RULE; CLASSIFIERS; CONDENSATION	This paper presents a relational framework for studying properties of labeled data points related to proximity and labeling information in order to improve the performance of the 1NN rule. Specifically, the class conditional nearest neighbor (ccnn) relation over pairs of points in a labeled training set is introduced. For a given class label c, this relation associates to each point a its nearest neighbor computed among only those points with class label c (excluded a). A characterization of ccnn in terms of two graphs is given. These graphs are used for defining a novel scoring function over instances by means of an information-theoretic divergence measure applied to the degree distributions of these graphs. The scoring function is employed to develop an effective large margin instance selection method, which is empirically demonstrated to improve storage and accuracy performance of the 1NN rule on artificial and real-life data sets.	Radboud Univ Nijmegen, Inst Comp & Informat Sci, Fac Sci, NL-6525 ED Nijmegen, Netherlands	Marchiori, E (reprint author), Radboud Univ Nijmegen, Inst Comp & Informat Sci, Fac Sci, Toernooiveld 1, NL-6525 ED Nijmegen, Netherlands.	elenam@cs.ru.nl			NWO [639.023.604]	The author thanks the editor and the reviewers for their constructive comments and the ML and SNN groups at the Radboud University for useful discussions. This work was partially supported by the NWO project 639.023.604.	AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Angiulli F, 2007, IEEE T KNOWL DATA EN, V19, P1450, DOI 10.1109/TKDE.2007.190645; Angiulli F, 2007, IEEE T KNOWL DATA EN, V19, P1593, DOI 10.1109/TKDE.2007.190665; BARNETT V, 1976, J ROY STAT SOC A STA, V139, P318, DOI 10.2307/2344839; Bartlett PL, 1997, ADV NEUR IN, V9, P134; Brighton H, 1999, LECT NOTES ARTIF INT, V1704, P283; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Cameron-Jones R.M., 1995, P 8 AUSTR JOINT C AR, P99; Chapelle O., 2005, P 10 INT WORKSH ART, P57; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crammer K., 2002, P 17 C NEUR INF PROC, P462; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; DASARATHY BV, 1995, P SOC PHOTO-OPT INS, P34; DASARATHY BV, 1995, OPT ENG, V34, P2785, DOI 10.1117/12.210755; Demsar J, 2006, J MACH LEARN RES, V7, P1; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Garcia S, 2008, PATTERN RECOGN, V41, P2693, DOI 10.1016/j.patcog.2008.02.006; GILADBACHRACH R, 2004, P INT C MACH LEARN; Grother PJ, 1997, PATTERN RECOGN, V30, P459, DOI 10.1016/S0031-3203(96)00098-2; Hammer B, 2005, NEURAL PROCESS LETT, V21, P109, DOI 10.1007/s11063-004-1547-1; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; JANKOWSKI N, 2004, ARTIF INTELL, P580; Kleinberg J. M., 1997, P 29 ANN ACM S THEOR, P599, DOI 10.1145/258533.258653; Krishna K, 2000, IEEE T NEURAL NETWOR, V11, P1361, DOI 10.1109/72.883447; Kuncheva LI, 1999, PATTERN RECOGN LETT, V20, P1149, DOI 10.1016/S0167-8655(99)00082-3; LIN J, 1991, IEEE T INFORM THEORY, V37, P1; Marchiori E, 2008, J MACH LEARN RES, V9, P997; MCCAMMON RB, 1972, J SEDIMENT PETROL, V42, P422; Paredes R, 2006, IEEE T PATTERN ANAL, V28, P1100, DOI 10.1109/TPAMI.2006.145; Peng J, 2004, IEEE T PATTERN ANAL, V26, P656; Pkalska E., 2006, Pattern Recognition, V39, DOI 10.1016/j.patcog.2005.06.012; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Sanchez JS, 2007, PATTERN ANAL APPL, V10, P189, DOI 10.1007/s10044-007-0061-2; Schapire R. E., 1997, P 14 INT C MACH LEAR, P322; Tahir MA, 2007, PATTERN RECOGN LETT, V28, P438, DOI 10.1016/j.patrec.2006.08.016; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; TOUSSAINT G, 2002, P INTERFACE 2002 34, P83; Vapnik V.N., 1995, NATURE STAT LEARNING; Wang JG, 2007, PATTERN RECOGN LETT, V28, P207, DOI 10.1016/j.patrec.2006.07.002; WEINBERGER KQ, 2006, P C NEUR INF PROC SY; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson HR, 1997, VISUAL NEUROSCI, V14, P403	46	14	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2010	32	2					364	370		10.1109/TPAMI.2009.56		7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	532IT	WOS:000272741500013	
J	Depeursinge, A; Iavindrasana, J; Hidki, A; Cohen, G; Geissbuhler, A; Platon, A; Poletti, PA; Muller, H				Depeursinge, Adrien; Iavindrasana, Jimison; Hidki, Asmaa; Cohen, Gilles; Geissbuhler, Antoine; Platon, Alexandra; Poletti, Pierre-Alexandre; Mueller, Henning			Comparative Performance Analysis of State-of-the-Art Classification Algorithms Applied to Lung Tissue Categorization	JOURNAL OF DIGITAL IMAGING			English	Article						Quantitative image analysis; feature extraction; texture analysis; chest high-resolution CT; supervised learning; support vector machines	COMPUTER-AIDED DIAGNOSIS; DISEASE PATTERNS; RECOGNITION; SEGMENTATION; RETRIEVAL; IMAGES; SYSTEM	In this paper, we compare five common classifier families in their ability to categorize six lung tissue patterns in high-resolution computed tomography (HRCT) images of patients affected with interstitial lung diseases (ILD) and with healthy tissue. The evaluated classifiers are naive Bayes, k-nearest neighbor, J48 decision trees, multilayer perceptron, and support vector machines (SVM). The dataset used contains 843 regions of interest (ROI) of healthy and five pathologic lung tissue patterns identified by two radiologists at the University Hospitals of Geneva. Correlation of the feature space composed of 39 texture attributes is studied. A grid search for optimal parameters is carried out for each classifier family. Two complementary metrics are used to characterize the performances of classification. These are based on McNemar's statistical tests and global accuracy. SVM reached best values for each metric and allowed a mean correct prediction rate of 88.3% with high class-specific precision on testing sets of 423 ROIs.	[Depeursinge, Adrien; Iavindrasana, Jimison; Hidki, Asmaa; Cohen, Gilles; Geissbuhler, Antoine; Mueller, Henning] Univ Hosp Geneva, Serv Med Informat, CH-1211 Geneva 14, Switzerland; [Depeursinge, Adrien; Iavindrasana, Jimison; Hidki, Asmaa; Cohen, Gilles; Geissbuhler, Antoine; Platon, Alexandra; Poletti, Pierre-Alexandre; Mueller, Henning] Univ Geneva, CH-1211 Geneva, Switzerland; [Platon, Alexandra; Poletti, Pierre-Alexandre] Univ Hosp Geneva, Serv Emergency Radiol, CH-1211 Geneva 14, Switzerland; [Mueller, Henning] Univ Appl Sci, Sierre, Switzerland	Depeursinge, A (reprint author), Univ Hosp Geneva, Serv Med Informat, 24 Rue Micheli du Crest, CH-1211 Geneva 14, Switzerland.	adrien.depeursinge@sim.hcuge.ch			Swiss National Science Foundation [200020-118638/1]; University and Hospitals of Geneva [05-9-II]; EU [IST 032691]	We thank Dr. Melanie Hilario for her valuable comments on the methodology for benchmarking the classifiers. This work was supported by the Swiss National Science Foundation (FNS) with grant 200020-118638/1, the equalization fund of University and Hospitals of Geneva (grant 05-9-II), and the EU 6th Framework Program in the context of the KnowARC project (IST 032691).	Aisen AM, 2003, RADIOLOGY, V228, P265, DOI 10.1148/radiol.2281020126; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037//0033-295X.94.2.115; Bishop C. M., 2006, PATTERN RECOGNITION; Bishop C. M., 1995, NEURAL NETWORKS PATT; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P2; CABAN J, 2007, MEDICAL IMAGING 2007, V6514; Chang C-C., 2001, LIBSVM LIB SUPPORT V; Cohen G, 2006, ARTIF INTELL MED, V37, P7, DOI 10.1016/j.artmed.2005.03.002; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEPEURSINGE A, 2006, SWISS C MED INF SSIM; Depeursinge A., 2007, MED IMAGING 2007 COM, V6514, p65143P; Depeursinge A., 2007, 29 ANN INT C IEEE EM, P6259, DOI 10.1109/IEMBS.2007.4353786; DIETTERICH TG, 1998, NEURAL COMPUT, V10, P7; Flaherty KR, 2004, AM J RESP CRIT CARE, V170, P904, DOI 10.1164/rccm.200402-147OC; Frank E, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P1305, DOI 10.1007/0-387-25465-X_62; Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Kubat M., 1997, P 14 INT C MACH LEAR, P179; Mller Henning, 2004, INT J MED INFORM, V73, P1; Nishikawa RA, 2007, COMPUT MED IMAG GRAP, V31, P224, DOI 10.1016/j.compmedimag.2007.02.009; QUINLAN JR, 1986, MACH LEARN, V1, P106; Shamsheyeva A, 2004, P SOC PHOTO-OPT INS, V5370, P1548, DOI 10.1117/12.534877; Shamsheyeva A, 2004, Proceedings of the 2004 Intelligent Sensors, Sensor Networks & Information Processing Conference, P439; Shyu CR, 1999, COMPUT VIS IMAGE UND, V75, P111, DOI 10.1006/cviu.1999.0768; STARK P, 2007, HIGH RESOLUTION COMP; Tourassi GD, 1999, RADIOLOGY, V213, P317; UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936; Uppaluri R, 1999, AM J RESP CRIT CARE, V160, P648; van der Walt C., 2006, P 16 ANN S PATT REC, P166; Van De Ville D, 2005, IEEE T IMAGE PROCESS, V14, P1798, DOI 10.1109/TIP.2005.857249; Vapnik V, 1999, NATURE STAT LEARNING; Witten I., 2005, MORGAN KAUFMANN SERI; Wong JSJ, 2006, LECT NOTES COMPUT SC, V4304, P233; Zavaletta V. A., 2007, MED IMAGING 2007 PHY, V6511, p65111Q; Zrimec T, 2007, ST HEAL T, V129, P1324	35	4	4	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0897-1889		J DIGIT IMAGING	J. Digit. Imaging	FEB	2010	23	1					18	30		10.1007/s10278-008-9158-4		13	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	546ZD	WOS:000273853400004	
J	Biau, G; Cerou, F; Guyader, A				Biau, Gerard; Cerou, Frederic; Guyader, Arnaud			On the Rate of Convergence of the Bagged Nearest Neighbor Estimate	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						bagging; resampling; nearest neighbor estimate; rates of convergence	NONPARAMETRIC REGRESSION	Bagging is a simple way to combine estimates in order to improve their performance. This method, suggested by Breiman in 1996, proceeds by resampling from the original data set, constructing a predictor from each subsample, and decide by combining. By bagging an n-sample, the crude nearest neighbor regression estimate is turned into a consistent weighted nearest neighbor regression estimate, which is amenable to statistical analysis. Letting the resampling size k(n) grows appropriately with n, it is shown that this estimate may achieve optimal rate of convergence, independently from the fact that resampling is done with or without replacement. Since the estimate with the optimal rate of convergence depends on the unknown distribution of the observations, adaptation results by data-splitting are presented.	[Biau, Gerard] Univ Paris 06, LSTA, F-75013 Paris, France; [Biau, Gerard] Univ Paris 06, LPMA, F-75013 Paris, France; [Cerou, Frederic] INRIA Rennes Bretagne Atlantique, Aspi Project Team, F-35042 Rennes, France; [Guyader, Arnaud] Univ Rennes 2, F-35043 Rennes, France	Biau, G (reprint author), Univ Paris 06, LSTA, Boite 158,175 Rue Chevaleret, F-75013 Paris, France.	GERARD.BIAU@UPMC.FR; FREDERIC.CEROU@INRIA.FR; ARNAUD.GUYADER@UHB.FR					BIAU G, 2008, LAYERED NEAREST NEIG; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Buhlmann P, 2002, ANN STAT, V30, P927; Buja A, 2006, STAT SINICA, V16, P323; Cover T.M., 1968, P HAW INT C SYST SCI, P413; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devroye L, 1996, PROBABILISTIC THEORY; DEVROYE L, 1981, ANN STAT, V9, P1310, DOI 10.1214/aos/1176345647; Dietterich TG, 2000, LECT NOTES COMPUTER, P1; Fix E., 1951, 4 USAF SCH AV MED; Fix E., 1952, 11 USAF SCH AV MED; Friedman JH, 2007, J STAT PLAN INFER, V137, P669, DOI 10.1016/j.jspi.2006.06.002; Gradshteyn I. S., 2007, TABLE INTEGRALS SERI; GYORFI L, 1978, IEEE T INFORM THEORY, V29, P509; Gyorfi L., 2002, DISTRIBUTION FREE TH; Hall P, 2005, J ROY STAT SOC B, V67, P363, DOI 10.1111/j.1467-9868.2005.00506.x; Ibragimov I., 1981, STAT ESTIMATION ASYM; Ibragimov I. A., 1982, THEOR PROBAB APPL, V27, P81; IBRAGIMOV IA, 1980, DOKL AKAD NAUK SSSR+, V252, P780; Kolmogorov A.N., 1961, AM MATH SOC TRANSL, V17, P277; KULKARNI SR, 1995, IEEE T INFORM THEORY, V41, P1028, DOI 10.1109/18.391248; Lin Y, 2006, J AM STAT ASSOC, V101, P578, DOI 10.1198/016214505000001230; PSALTIS D, 1994, IEEE T INFORM THEORY, V40, P820, DOI 10.1109/18.335893; Steele BM, 2009, MACH LEARN, V74, P235, DOI 10.1007/s10994-008-5096-0; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; Venkatesh S. S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130396	28	9	10	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	FEB	2010	11						687	712				26	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	589XC	WOS:000277186500010	
S	Yang, T; Cao, LB; Zhang, CQ		Zaki, MJ; Yu, JX; Ravindran, B; Pudi, V		Yang, Tao; Cao, Longbing; Zhang, Chengqi			A Novel Prototype Reduction Method for the K-Nearest Neighbor Algorithm with K >= 1	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PT II, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	14th Pacific-Asia Conference on Knowledge Discovery and Data Mining	JUN 21-24, 2010	Hyderabad, INDIA	IIIT Hyderbad, AFOSR, AOARD, ONRG			CLASSIFICATION; ERROR	In this paper, a novel prototype reduction algorithm is proposed, which aims at reducing the storage requirement and enhancing the online speed while retaining the same level of accuracy for a K-nearest neighbor (KNN) classifier. To achieve this goal, our proposed algorithm learns the weighted similarity function for a KNN classifier by maximizing the leave-one-out cross-validation accuracy. Unlike the classical methods PW, LPD and WDNN which can only work with K = 1 our developed algorithm can work with K >= 1. This flexibility allows our lean it algorithm to have superior classification accuracy and noise robustness. The proposed approach is assessed through experiments with twenty real world benchmark data sets. In all these experiments, the proposed approach shows it can dramatically reduce the storage requirement and online time for KNN while having equal or better accuracy than KNN, and it also shows comparable results to several prototype reduction methods proposed in literature.	[Yang, Tao; Cao, Longbing; Zhang, Chengqi] Univ Technol Sydney, Fac Engn & Informat Technol, Sydney, NSW 2007, Australia	Yang, T (reprint author), Univ Technol Sydney, Fac Engn & Informat Technol, Sydney, NSW 2007, Australia.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Hastie T, 2009, ELEMENTS STAT LEARNI; Jahromi MZ, 2009, INFORM SCIENCES, V179, P2964, DOI 10.1016/j.ins.2009.04.012; Kohonen T., 1989, SELF ORG ASS MEMORY; Loog M, 2004, IEEE T PATTERN ANAL, V26, P732, DOI 10.1109/TPAMI.2004.13; Paredes R, 2006, PATTERN RECOGN, V39, P180, DOI 10.1016/j.patcog.2005.06.001; Paredes R, 2006, IEEE T PATTERN ANAL, V28, P1100, DOI 10.1109/TPAMI.2006.145; Peng J, 2004, IEEE T PATTERN ANAL, V26, P656; RIDDER D, 2004, P 17 INT C PATT REC, V2, P295; Wang JG, 2007, PATTERN RECOGN LETT, V28, P207, DOI 10.1016/j.patrec.2006.07.002; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Yang T, 2008, NEUROCOMPUTING, V71, P3001, DOI 10.1016/j.neucom.2008.01.014	12	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-13671-9	LECT NOTES ARTIF INT			2010	6119		II				89	100				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BQR44	WOS:000281629400010	
S	Caballero, Y; Bello, R; Arco, L; Garcia, M; Ramentol, E		Koronacki, J; Ras, ZW; Wierzchon, ST; Kacprzyk, J		Caballero, Yaile; Bello, Rafael; Arco, Leticia; Garcia, Maria; Ramentol, Enislay			Knowledge Discovery Using Rough Set Theory	ADVANCES IN MACHINE LEARNING I: DEDICATED TO THE MEMORY OF PROFESSOR RYSZARD S. MICHALSKI	Studies in Computational Intelligence		English	Article; Book Chapter						knowledge discovery; Rough Set Theory	FEATURE-SELECTION; APPROXIMATION SPACES; SYSTEM; EXTRACTION	Rough Set Theory (RST) opened a new direction in the development of incomplete information theories and is a powerful data analysis tool. In this investigation, the possibility of using this theory to generate a priori knowledge about a dataset is demonstrated. A proposal is developed for previous characterization of training sets, using RST estimation measurements. This characterization offers an assessment of the quality of data in order to use them as a training set in machine learning techniques. The proposal has been experimentally studied using international databases and some known classifiers such as MLP, C4.5 and K-NN, and satisfactory results have been obtained.	[Caballero, Yaile; Ramentol, Enislay] Univ Camaguey, Dept Comp Sci, Camaguey, Cuba; [Bello, Rafael; Garcia, Maria] Univ Cent Las Villas, Dept Comp Sci, Santa Clara, CA USA	Caballero, Y (reprint author), Univ Camaguey, Dept Comp Sci, Camaguey, Cuba.	yailec@yahoo.com; rbellop@uclv.edu.cu; leticiaa@uclv.edu.cu; mmgarcia@uclv.edu.cu; enislay.ramentol@reduc.edu.cu					AHN BS, 2000, INTEGRATED METHODOLO; ARCO L, 2006, 5 MEX INT C ART INT; BAZAN J, 2003, LNCS LNAI, V2639; Bazan JG, 2005, LECT NOTES COMPUT SC, V3400, P37; Bello R, 2006, LECT NOTES COMPUT SC, V4225, P588; Bosc P., 1993, P 2 WORKSH UNC MAN I; CABALLERO Y, 2007, 3 INT ICSC S INF TEC, P161; CABALLERO Y, 2007, P 7 INT C INT SYST D; CABALLERO Y, 2007, 2 C INT BIOINF NEUR; CARLIN US, 1998, ECAI 1998 WORKSH INT; CHIN KS, 2003, LNCS LNAI, V2639; CHOUBEY SK, 1996, P 5 IEEE INT C FUZZ, V2, P1122, DOI 10.1109/FUZZY.1996.561296; CHOUCHOULAS AAS, 1999, LECT NOTES ARTIF INT, V11, P118; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEOGUN JS, 1995, 1 INT C KNOWL DISC D, P69; DUNSTSH I, 2000, ROUGH SET DATA ANAL; GARCIA JM, 2003, KNN WORKSH SUIT DES; GRABOWSKI A, 2003, J FORMALIZED MATH, V15; GRECO S, 2003, LNCS LNAI, V2639; Greco S, 2001, EUR J OPER RES, V129, P1, DOI 10.1016/S0377-2217(00)00167-3; Grzymala-Busse J.W., 2004, P IPMU 2004 10 INT C, P923; Grzymala-Busse J.W., 1994, P WORKSH INT INF SYS, VIII; Hor CL, 2005, LECT NOTES COMPUT SC, V3400, P82; HU XT, 2003, LNCS LNAI, V2639; KIERCZAK M, 2006, INT S FUZZ ROUGH SET; KOCZKODAJ WW, 1998, ACM, V41; KOHAVI R, 1994, 3 INT WORKSH ROUGH S; Komorowski J., 1999, ROUGH FUZZY HYBRIDIZ, P3; Kostek B, 2005, LECT NOTES COMPUT SC, V3400, P112; LAZO M, 2001, OVERVIEW EVOLUTION C, P753; Lee S, 2002, LECT NOTES ARTIF INT, V2475, P568; MIAO D, 2003, LNCS LNAI, V2639; Midelfart H, 2002, FUND INFORM, V53, P155; Mitra S, 2005, LECT NOTES COMPUT SC, V3400, P134; OHRN A, 1998, STUDIES FUZZINESS SO, V18, P376; Orlowska E., 1998, INCOMPLETE INFORM RO; Pal S. K., 1999, ROUGH FUZZY HYBRIDIZ; PAL SK, 2002, IEEE T NEURAL NETWOR; PAL SK, 2003, LNCS LNAI, V2639; Parsons S., 1996, IEEE T KNOWLEDGE DAT, V8; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; PAWLAK Z, 1995, COMM ACM, V38; Peters JF, 2005, LECT NOTES COMPUT SC, V3400, P153; Pinero P, 2003, LECT NOTES COMPUT SC, V2905, P488; Quinlan J.R., 1993, C 4 5 PROGRAMS MACHI; REVETT K, 2006, INT S FUZZ ROUGH SET; ROSEMBLATT F, 1962, PRINCIPLES NEURODYNA; RUIZ R, 2006, HEURISTICAS SELECCIO; SANTIESTEBAN Y, 2003, REV CIENCIAS MATEMAT, V21; SEGOVIA MJ, 2003, PREDICCION INSOLVENC; SKOWRON A, 1992, INT WORKSH ROUGH SET, P62; SKOWRON A, 2003, LNCS LNAI, V2639; Skowron A, 2005, LECT NOTES COMPUT SC, V3400, P175; SKOWRON A, 1999, LNCS LNAI, V1711; Slezak D, 2005, LECT NOTES COMPUT SC, V3400, P202; Slowinski R., 1997, ADV MACHINE INTELLIG, VIV, P17; SUGIHARA K, 2006, INT S FUZZ ROUGH SET; Suraj Z, 2005, LECT NOTES COMPUT SC, V3400, P190; Tay FEH, 2003, ENG APPL ARTIF INTEL, V16, P39, DOI 10.1016/S0952-1976(03)00022-8; Tsumoto S, 2003, EXPERT SYST APPL, V24, P189, DOI 10.1016/S0957-4174(02)00142-2; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; WITTEN I, 2005, DATA MINING PRACTICA, P296; Wolski M, 2005, LECT NOTES COMPUT SC, V3400, P230; YAO YS, 1999, INFORM THEORETIC MEA, P231; YAO YY, 2003, LNCS LNAI, V2639; ZHAO Y, 2003, LNCS LNAI, V2639; ZHENG Z, 2003, LNCS LNAI, V2639; Zhong N, 2001, J INTELL INF SYST, V16, P199, DOI 10.1023/A:1011219601502	68	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1860-949X	978-3-642-05176-0	STUD COMPUT INTELL			2010	262						367	383			10.1007/978-3-642-05177-7	17	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Automation & Control Systems; Computer Science	BND24	WOS:000274200800018	
S	Tarakanov, AO		Koronacki, J; Ras, ZW; Wierzchon, ST; Kacprzyk, J		Tarakanov, Alexander O.			Immunocomputing for Speaker Recognition	ADVANCES IN MACHINE LEARNING II: DEDICATED TO THE MEMORY OF PROFESSOR RYSZARD S. MICHALSKI	Studies in Computational Intelligence		English	Article; Book Chapter							FORMAL IMMUNE NETWORK; INTRUSION DETECTION; RECEPTOR MOSAICS; PATTERN-RECOGNITION; CLASSIFICATION; CYTOKINE; MODEL	Based on mathematical models of immunocomputing, this chapter proposes an approach to speaker recognition by intelligent signal processing. The approach includes both low-level feature extraction and high-level ("intelligent") pattern recognition. The key model is the formal immune network (FIN) including apoptosis (programmed cell death) and immunization both controlled by cytokines (messenger proteins). Such FIN can be formed from audio signals using discrete tree transform (DTT), singular value decomposition (SVD), and the proposed index of inseparability in comparison with the Renyi entropy. Application is demonstrated on the task of recognizing nine male speakers by their utterances of two Japanese vowels. The obtained results suggest that the proposed approach outperforms state of the art approaches of computational intelligence.	Russian Acad Sci, St Petersburg Inst Informat & Automat, St Petersburg 199178, Russia	Tarakanov, AO (reprint author), Russian Acad Sci, St Petersburg Inst Informat & Automat, 14 Line 39, St Petersburg 199178, Russia.	tar@iias.spb.su					Adamatzky A., 1994, IDENTIFICATION CELLU; Agnati LF, 2005, J MOL NEUROSCI, V26, P193, DOI 10.1385/JMN/26:02:193; Agnati LF, 2005, BIOSYSTEMS, V80, P165, DOI 10.1016/j.biosystems.2004.11.004; Agnati LF, 2008, BRAIN RES REV, V58, P400, DOI 10.1016/j.brainresrev.2007.10.002; ANTONIOL G, 2005, ACM SIGSOFT, V30, P1, DOI 10.1145/1082983.1083156; Atreas ND, 2004, COMP FUNCT GENOM, V5, P69, DOI 10.1002/cfg.367; Atreas ND, 2003, LECT NOTES COMPUT SC, V2787, P111; Chao DL, 2004, J THEOR BIOL, V228, P227, DOI 10.1016/j.jtbi.2003.12.011; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasgupta D., 2008, IMMUNOLOGICAL COMPUT; DASGUPTA D, 2005, ENHANCING COMPUTER S, P165; Dasgupta D, 2006, IEEE COMPUT INTELL M, V1, P40, DOI 10.1109/MCI.2006.329705; Dasgupta D, 2004, LECT NOTES COMPUT SC, V3239, P1; Fuxe KG, 2008, BRAIN RES REV, V58, P453, DOI 10.1016/j.brainresrev.2008.04.003; Goncharova LB, 2008, CURR MED CHEM, V15, P1297, DOI 10.2174/092986708784535009; Goncharova LB, 2005, LECT NOTES COMPUT SC, V3627, P72; Goncharova LB, 2008, CURR MED CHEM, V15, P210; Goncharova LB, 2007, BRAIN RES REV, V55, P155, DOI 10.1016/j.brainresrev.2007.02.003; Horn R.A., 1986, MATRIX ANAL; Johnson JE, 2005, LECT NOTES COMPUT SC, V3685, P129; Kozyrev S.V., 2002, IZV MATH+, V66, p[149, 367], DOI 10.1070/IM2002v066n02ABEH000381; Kudo M, 1999, PATTERN RECOGN LETT, V20, P1103, DOI 10.1016/S0167-8655(99)00077-X; Rabiner L., 1993, FUNDAMENTAL SPEECH R; Renyi A., 1961, 4TH P BERK S MATH ST, V1, P547; Sokolova L, 2003, LECT NOTES COMPUT SC, V2787, P120; Tarakanov A, 2007, INT J UNCONV COMPUT, V3, P123; Tarakanov A, 2007, J CELL AUTOM, V2, P39; TARAKANOV A, 2007, 1 IEEE S FDN COMP IN, P503; TARAKANOV A, 2002, P 1 INT C ART IMM SY, P32; TARAKANOV A, 2002, KYBERNETES, V31, P394; TARAKANOV A, 2007, RADIOSYSTEMS, V106, P90; Tarakanov A. O., 2003, IMMUNOCOMPUTING PRIN; Tarakanov AO, 2008, IEEE COMPUT INTELL M, V3, P22, DOI 10.1109/MCI.2008.919069; TARAKANOV AO, 2009, HDB RES ARTIFICIAL I, P241; Tarakanov AO, 2005, LECT NOTES COMPUT SC, V3685, P394; TARAKANOV AO, 2007, LNGC, V14, P252; TARAKANOV AO, 2007, ADV APPL SELF ORGANI, P269; TARAKANOV AO, 2005, INT J UNCONV COMPUT, V1, P357; Tarakanov AO, 2007, COMM COM INF SC, V1, P308, DOI 10.1007/978-3-540-73986-9_26; TARAKANOV AO, 2009, NEURAL COMP IN PRESS; Tarakanov AO, 2004, LECT NOTES COMPUT SC, V3239, P236; Tarakanov AO, 2005, LECT NOTES ARTIF INT, V3630, P510; Timmis J., 2002, ARTIFICIAL IMMUNE SY; ZHAO W, 2005, ACM SIGACT NEWS, V36, P14, DOI 10.1145/1107523.1107532	44	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1860-949X	978-3-642-05178-4	STUD COMPUT INTELL			2010	263						515	529			10.1007/978-3-642-05179-1	15	Computer Science, Artificial Intelligence	Computer Science	BND29	WOS:000274201700024	
S	Solorio-Fernandez, S; Carrasco-Ochoa, JA; Martinez-Trinidad, JF		CarrascoOchoa, JA; MartinezTrinidad, JF; Kittler, J		Solorio-Fernandez, Saul; Ariel Carrasco-Ochoa, J.; Fco. Martinez-Trinidad, Jose			Hybrid Feature Selection Method for Supervised Classification Based on Laplacian Score Ranking	ADVANCES IN PATTERN RECOGNITION	Lecture Notes in Computer Science		English	Proceedings Paper	2nd Mexican Conference on Pattern Recognition	SEP 27-29, 2010	Puebla, MEXICO	Natl Inst Astrophys, Comp Sci Dept, Opt & Elect, Natl Polytechn Inst, Comp Res	Natl Inst Astrophys	Supervised Feature Selection; Laplacian Score; Feature Ranking		In this paper, we introduce a new hybrid filter-wrapper method for supervised feature selection, based on the Laplacian Score ranking combined with a wrapper strategy. We propose to rank features with the Laplacian Score to reduce the search space, and then we use this order to find the best feature subset. We compare our method against other based on ranking feature selection methods, namely, Information Gain Attribute Ranking, Relief, Correlation-based Feature Selection, and additionally we include in our comparison a Wrapper Subset Evaluation method. Empirical results over ten real-world datasets from the UCI repository show that our hybrid method is competitive and outperforms in most of the cases to the other feature selection methods used in our experiments.	[Solorio-Fernandez, Saul; Ariel Carrasco-Ochoa, J.; Fco. Martinez-Trinidad, Jose] Natl Inst Astrophys Opt & Elect, Puebla 72840, Mexico	Solorio-Fernandez, S (reprint author), Natl Inst Astrophys Opt & Elect, Luis Enrique Erro 1, Puebla 72840, Mexico.	sausolofer@ccc.inaoep.mx; ariel@ccc.inaoep.mx; fmartine@ccc.inaoep.mx					Asuncion A., 2007, UCI MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Das S, 2001, ICML 01, P74; Dash M., 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; Dash M, 1998, LECT NOTES ARTIF INT, V1531, P238; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288651; GARCIA DG, 2009, 4 INT C MACH LEARN A, P425; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hall M., 2009, SIGKDD EXPLORATIONS, V11; Hall MA, 2003, IEEE T KNOWL DATA EN, V15, P1437, DOI 10.1109/TKDE.2003.1245283; Hall MA, 1998, THESIS U WAIKATO HAM; He X., 2006, ADV NEURAL INFORM PR, V18, P507; JENSEN R, 2008, COMPUT INTELL, P61; John G, 1995, ESTIMATING CONTINUOU, P338; KIM Y, 2003, FEATURE SELECTION DA, P80; KIRA K, 1992, MACHINE LEARNING /, P249; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kononenko I., 1994, EUR C MACH LEARN, P171; Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491; LIU R, 2009, WORKSH INT INF TECHN, V3, P65; LOUGHREY J, 2005, TCDCS200537 DEP COMP; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; Niijima S, 2009, IEEE ACM T COMPUT BI, V6, P605, DOI 10.1109/TCBB.2007.70257; PAL SK, 2004, PATTERN RECOGN, P59; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Witten I., 2005, DATA MINING PRACTICA; Xing E. P., 2001, P 18 INT C MACH LEAR, P601; Yu L, 2004, J MACH LEARN RES, V5, P1205; ZHANG L, 2004, INT C COMP INF TECHN, P233; Zhao Z., 2007, ICML, P1151	31	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-15991-6	LECT NOTES COMPUT SC			2010	6256						260	269				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BTC02	WOS:000286415900028	
B	Walters-Williams, J; Li, Y		Elleithy, K		Walters-Williams, Janett; Li, Yan			Comparative Study of Distance Functions for Nearest Neighbors	ADVANCES TECHNIQUES IN COMPUTING SCIENCES AND SOFTWARE ENGINEERING			English	Proceedings Paper	International Conference on Systems, Computing Sciences and Software Engineering	2008	Bridgeport, CT			Kullback-Leibler distance; Euclidean distance; Mahalanobis distance; Manhattan distance; Hamming distance; Minkowski distance; Nearest Neighbor		Many learning algorithms rely on distance metrics to receive their input data. Research has shown that these metrics can improve the performance of these algorithms. Over the years an often popular function is the Euclidean function. In this paper, we investigate a number of different metrics proposed by different communities, including Mahalanobis, Euclidean, Kullback-Leibler and Hamming distance. Overall, the best-performing method is the Mahalanobis distance metric.	[Walters-Williams, Janett] Univ Technol, Sch Comp & Informat Technol, Kingston 6, Jamaica	Walters-Williams, J (reprint author), Univ Technol, Sch Comp & Informat Technol, Kingston 6, Jamaica.	jwalters@utech.edu.jm; liyan@usq.edu.au					Abdi H., 2007, ENCY MEASUREMENT STA; Bar-Hillel A., 2006, THESIS HEBREW U JERU; BEITAO L, 2002, P IEEE C IM PROC SEP; BORIAH S, 2008, P 2008 SOC IND APPL, P23; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davis J.V., 2007, P 24 INT C MACH LEAR; GRIFFITHS R, 1992, P SURV RES METH SECT; JENSEN DD, 2002, MULTIPLE COMPARISONS, P1; JONES WP, 1987, J AM SOC INFORM SCI, V38, P420, DOI 10.1002/(SICI)1097-4571(198711)38:6<420::AID-ASI3>3.0.CO;2-S; KAMICHETY HM, 2002, EMPIRICAL FRAMEWORK; NOREAULT T, 1981, SIGIR 80 P 3 ANN ACM, P76; QIAN G, 2004, P ACM S APPL COMP; Tumminello M, 2007, PHYS REV E, V76, DOI 10.1103/PhysRevE.76.031123; WEINBERGER K, 2006, ADV NEURAL INFORM PR; WEINBERGER KQ, 2007, INT C MACH IN PRESS; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; WILSON DR, 1997, THESIS B YOUNG U; WOLFEL M, 2005, P 13 EUR SIGN PROC C; Zwick R., 1987, International Journal of Approximate Reasoning, V1, DOI 10.1016/0888-613X(87)90015-6	19	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY		978-90-481-3659-9				2010							79	84		10.1007/978-90-481-3660-5_14		6	Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BQR66	WOS:000281650200014	
S	McSherry, D; Stretch, C		Coyle, L; Freyne, J		McSherry, David; Stretch, Christopher			An Analysis of Order Dependence in k-NN	ARTIFICIAL INTELLIGENCE AND COGNITIVE SCIENCE	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	20th Irish Conference on Artificial Intelligence and Cognitive Science	AUG 19-21, 2009	Dublin, IRELAND	Sch Comp Sci & Informat, CLARITY, Sci Fdn Ireland Ctr Sci, Engn & Technol, Tyndall Natl Inst, CLIQUE, Strateg Res Cluster, Sci Fdn Ireland (SFI), IBM, Idiro Technol, Norkom Technol	Univ Coll Dublin	classification; k-NN; instance-based learning; case-based reasoning		In classification based on k-NN with majority voting, the class assigned to a given problem is the one that occurs most frequently in the k most similar cases (or instances) in the dataset. However, different versions of k-NN may use different strategies to select the cases on which the solution is based when there are ties for the kth most similar case. One strategy is to break ties for the kth most similar case based on the ordering of cases in the dataset. We present an analysis of the order dependence introduced by this strategy and its effects on the algorithm's performance.	[McSherry, David; Stretch, Christopher] Univ Ulster, Sch Comp & Informat Engn, Coleraine BT52 1SA, Londonderry, North Ireland	McSherry, D (reprint author), Univ Ulster, Sch Comp & Informat Engn, Coleraine BT52 1SA, Londonderry, North Ireland.	dmg.mcsherry@ulster.ac.uk; ct.stretch@ulster.ac.uk					Aha DW, 1998, KNOWL-BASED SYST, V11, P261, DOI 10.1016/S0950-7051(98)00066-5; Asuncion A., 2007, UCI MACHINE LEARNING; BROOKS AD, 2001, KNNFLEX MORE FLEXIBL; Burr Ridge I, 1997, MACHINE LEARNING; CENDROWSKA J, 1987, INT J MAN MACH STUD, V27, P349, DOI 10.1016/S0020-7373(87)80003-2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence; Langley P., 1995, LEARNING HUMANS MACH; Leake D, 2007, LECT NOTES COMPUT SC, V4626, P194; McSherry D, 2002, LECT NOTES ARTIF INT, V2416, P219; Ripley B. D., 1996, PATTERN CLASSIFICATI; Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2; ZHUA M, 2007, J CLIN EPIDEMIOL, V60, P1015; *R FDN STAT COMP, 2009, R DEV COR TEAM LANG	14	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-17079-9	LECT NOTES ARTIF INT			2010	6206						207	218				12	Computer Science, Artificial Intelligence	Computer Science	BTF44	WOS:000286799900023	
S	Jagannathan, R; Petrovic, S; McKenna, A; Newton, L		Papadopoulos, H; Andreou, AS; Bramer, M		Jagannathan, Rupa; Petrovic, Sanja; McKenna, Angela; Newton, Louise			A Fuzzy Non-linear Similarity Measure for Case-Based Reasoning Systems for Radiotherapy Treatment Planning	ARTIFICIAL INTELLIGENCE APPLICATIONS AND INNOVATIONS	IFIP Advances in Information and Communication Technology		English	Proceedings Paper	6th IFIP Conference on Artificial Intelligence Applications and Innovations	OCT 06-07, 2010	Larnaca, CYPRUS	Univ Cyprus, Cyprus Univ Technol, Frederick Univ, Cyprus Tourism Org		Case-based Reasoning; Fuzzy Logic; Radiotherapy Treatment Planning; Decision-Support Systems		This paper presents a decision support system for treatment planning in brain cancer radiotherapy. The aim of a radiotherapy treatment plan is to apply radiation in a way that destroys tumour cells but minimizes the damage to healthy tissue and organs at risk. Treatment planning for brain cancer patients is a complex decision-making process that relies heavily on the subjective experience and expert domain knowledge of clinicians. We propose to capture this experience by using case-based reasoning. Central to the working of our case-based reasoning system is a novel similarity measure that takes into account the non-linear effect of the individual case attributes on the similarity measure. The similarity measure employs fuzzy sets. Experiments, which were carried out to evaluate the similarity measure using real brain cancer patient cases show promising results.	[Jagannathan, Rupa; Petrovic, Sanja] Univ Nottingham, Automated Scheduling Optimisat & Planning Res Grp, Sch Comp Sci, Nottingham NG7 2RD, England	Jagannathan, R (reprint author), Univ Nottingham, Automated Scheduling Optimisat & Planning Res Grp, Sch Comp Sci, Nottingham NG7 2RD, England.	rxj@cs.nott.ac.uk; sxp@cs.nott.ac.uk; angela.mckenna@nuh.nhs.uk; louise.newton@nuh.nhs.uk					Berger J., 1994, Proceedings of the Tenth Conference on Artificial Intelligence for Applications (Cat. No. 94CH3421-5), DOI 10.1109/CAIA.1994.323677; Cheng CB, 2003, MATH COMPUT MODEL, V38, P385, DOI 10.1016/S0895-7177(03)00228-0; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Haas O. C. L., 1998, P 1998 IEEE INT C CO; Holt A, 2005, KNOWL ENG REV, V20, P289, DOI 10.1017/S0269888906000622; Kolodner J., 1993, CASE BASED REASONING; Mishra N, 2009, PROC INT C TOOLS ART, P776; NEMA, DICOM DIG IM COMM ME; Oldham M, 1998, PHYS MED BIOL, V43, P2123, DOI 10.1088/0031-9155/43/8/010; Schmidt R, 2001, INT J MED INFORM, V64, P355, DOI 10.1016/S1386-5056(01)00221-0; SONG X, 2007, ICCBR 2007 LNCS LNAI, V4626, P348; WANG R, 2005, INFORM TECHNOLOGY AP, V1, P341	12	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1868-4238	978-3-642-16238-1	IFIP ADV INF COMM TE			2010	339						112	119				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BWD73	WOS:000293683700017	
S	Moka, E; Refanidis, I		Konstantopoulos, S; Perantonis, S; Karkaletsis, V; Spyropoulos, CD; Vouros, G		Moka, Evangelia; Refanidis, Ioannis			Towards Intelligent Management of a Student's Time	ARTIFICIAL INTELLIGENCE: THEORIES, MODELS AND APPLICATIONS, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	6th Hellenic Conference on Artificial Intelligence	MAY 04-07, 2010	Athens, GREECE	Hellen Soc Artificial Intelligence, Inst Informat & Telecommun, NCSR		Intelligent systems; scheduling; calendar applications		In parallel with studies, a lot of extra activities need to be fitted in a student's schedule. Frequently, excessive workload results in poor performance or in failing to finish the studies. The problem is more severe in lifelong learning, where students are professionals with family duties. So, the need of making informative decisions as of whether taking a specific course fits into a student's schedule is of great importance. This paper illustrates a system, called EDUPLAN and being currently under development, which aims at helping the student to make intelligent management of her time. EDUPLAN aims at informing the student as for which learning objects can fit her schedule or not, as well as at organizing her time. This can be achieved using scheduling algorithms and a description of the user's tasks and events. In the paper we also extend the LOM 1484.12.3 (TM)-2005 ontology with classes that can be used to describe the temporal distribution of the workload of any learning object. Finally, we provide EDUPLAN'S architecture, being built around the existing SELFPLANNER intelligent calendar application.	[Moka, Evangelia; Refanidis, Ioannis] Univ Macedonia, Dept Appl Informat, Thessaloniki 54006, Greece	Moka, E (reprint author), Univ Macedonia, Dept Appl Informat, Egnatia Str 156, Thessaloniki 54006, Greece.	emoka@uom.gr; yrefanid@uom.gr					ALEXIADIS A, 2009, 5 IFIP C ART INT APP, P399; Cormen T.H., 2009, INTRO ALGORITHMS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237; REFANIDIS I, 2010, COMPUTATION IN PRESS; Refanidis I., 2007, P 17 INT C AUT PLANN, P272	6	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-12841-7	LECT NOTES ARTIF INT			2010	6040						383	388				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BQO34	WOS:000281445400047	
J	Raniszewski, M				Raniszewski, Marcin			The Edited Nearest Neighbor Rule Based on the Reduced Reference Set and the Consistency Criterion	BIOCYBERNETICS AND BIOMEDICAL ENGINEERING			English	Article						editing techniques; nearest neighbor rule; consistency criterion; reference set reduction; representativeness measure		In this paper a new editing procedure for the Nearest Neighbor Rule (NN) is presented. The representativeness measure is introduced and used to choose the most representative samples of the classes. These samples constitute a reduced reference set. An edited reference set is created from all the training set samples (including samples from the reduced set), which are correctly classified by the NN rule operating with the reduced set. The performance of the presented method is evaluated and compared with five other well-known editing techniques, on five medical datasets.	Tech Univ Lodz, Dept Comp Engn, PL-90924 Lodz, Poland	Raniszewski, M (reprint author), Tech Univ Lodz, Dept Comp Engn, Stefanowskiego 18-22, PL-90924 Lodz, Poland.	mranisz@kis.p.lodz.pl					Asuncion A., 2007, UCI MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1980, Proceedings of the 5th International Conference on Pattern Recognition; Duda R. O., 2001, PATTERN CLASSIFICATI; FIX E, 1952, 11 USAF SCH AV MED, P280; Fix E., 1951, 4 USAF SCH AV MED, P261; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KOHAVI R, 1995, P 14 INT JOINT C ART, P338; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; NAKAI K, 1991, PROTEINS, V11, P95, DOI 10.1002/prot.340110203; RANISZEWSKI M, 2007, COMPUTER RECOGNITION, V2, P258; Theodoridis S, 2006, PATTERN RECOGNITION, 3RD EDITION, P1; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	14	0	0	PWN-POLISH SCIENTIFIC PUBL	WARSAW	UL KS TROJDENA 4, WARSAW, 02-109, POLAND	0208-5216		BIOCYBERN BIOMED ENG	Biocybern. Biomed. Eng.		2010	30	1					31	40				10	Engineering, Biomedical	Engineering	565PY	WOS:000275307700003	
S	Hu, ZB; Cai, ZH		Cai, Z; Tong, HJ; Kang, Z; Liu, Y		Hu, Zhenbang; Cai, Zhihua			Feature Synthesis Algorithm Combined with k-NN Classifier for Spectral Data Classification	COMPUTATIONAL INTELLIGENCE AND INTELLIGENT SYSTEMS	Communications in Computer and Information Science		English	Proceedings Paper	5th International Symposium on Intelligence Computation and Applications	OCT 22-24, 2010	Wuhan, PEOPLES R CHINA	China Univ Geosciences, China Univ Geosciences, Sch Comp Sci		feature extraction; feature selection; spectral data; k-NN	HYPERSPECTRAL DATA; IMAGES	A feature synthesis algorithm combined with modified k-NN classifier is described in this paper. The feature information of the training data is extracted firstly. In the classification phase, the feature information of the training data and the testing data are compared to make the initial prediction. If the predicting result is {C} which has only one element, testing data will be labeled class C. If the predicting result is {C(1), C(2), ... C(i)}, the corresponding subset of the training data set will be used in the k-NN algorithm to attain the predicted result. It is shown that this algorithm combined k-NN rule reduces computing time. If the feature information set could well generalize the training data, the error rate of the algorithm is decreased. The effectiveness of this proposed approach is verified on a public remote sensing data set.	[Hu, Zhenbang; Cai, Zhihua] China Univ Geosci, Sch Comp Sci, Wuhan 430074, Peoples R China	Hu, ZB (reprint author), China Univ Geosci, Sch Comp Sci, 388 Lumo Rd, Wuhan 430074, Peoples R China.	gelduoe@126.com; zhcai@cug.edu.cn					Blake CL, 1998, UCI REPOSITORY MACHI; Budevska BO, 2003, APPL SPECTROSC, V57, P124, DOI 10.1366/000370203321535015; CLARKE LP, 1993, MAGN RESON IMAGING, V11, P95, DOI 10.1016/0730-725X(93)90417-C; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deer PJ, 2003, FUZZY SET SYST, V137, P191, DOI 10.1016/S0165-0114(02)00220-8; DOSSANTOS JA, 2010, INFORM SCI; Erives H, 2005, COMPUT ELECTRON AGR, V47, P103, DOI 10.1016/j.compag.2004.11.016; FIX E, 11 USAF SCH AV MED, P280; Freeman JE, 2004, BREAST CANCER RES TR, V88, pS41; GREEN AA, 1988, IEEE T GEOSCI REMOTE, V26, P65, DOI 10.1109/36.3001; GUPTA MR, 2006, IEEE IMAGE PROC, P1585; Krishnaswamy J, 2009, REMOTE SENS ENVIRON, V113, P857, DOI 10.1016/j.rse.2008.12.011; Moussaoui S, 2008, NEUROCOMPUTING, V71, P2194, DOI 10.1016/j.neucom.2007.07.034; Muhammed HH, 2005, BIOSYST ENG, V91, P9, DOI 10.1016/j.biosystemseng.2005.02.007; Nakariyakul S, 2009, J FOOD ENG, V94, P358, DOI 10.1016/j.jfoodeng.2009.04.001; Overton G, 2004, LASER FOCUS WORLD, V40, P33; Peddle DR, 2001, COMPUT GEOSCI-UK, V27, P203, DOI 10.1016/S0098-3004(00)00096-0; Richards J. A., 1999, REMOTE SENSING DIGIT; Torres RD, 2009, PATTERN RECOGN, V42, P283, DOI 10.1016/j.patcog.2008.04.010; Wang J, 2006, IEEE T GEOSCI REMOTE, V44, P1586, DOI 10.1109/TGRS.2005.80297; Yang CC, 2002, BIOSYST ENG, V83, P291, DOI 10.1016/S1537-5110(02)00195-2; Zuzak KJ, 2003, AM J PHYSIOL-HEART C, V285, pH1183, DOI 10.1152/ajpheart.00243.2003	22	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1865-0929	978-3-642-16387-6	COMM COM INF SC			2010	107						254	263		10.1007/978-3-642-16388-3_28		10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BTZ20	WOS:000288485100028	
B	Cheng, JM; Yan, L; Zhang, C; Pei, Z		Ruan, D; Li, TR; Xu, Y; Chen, GQ; Kerre, EE		Cheng, Jianmei; Yan, Li; Zhang, Chao; Pei, Zheng			A COMBINED METHOD TO DEAL WITH UNCERTAIN DATA IN FUZZY K-NEAREST NEIGHBOR CLASSIFIER	COMPUTATIONAL INTELLIGENCE: FOUNDATIONS AND APPLICATIONS: PROCEEDINGS OF THE 9TH INTERNATIONAL FLINS CONFERENCE	World Scientific Proceedings Series on Computer Engineering and Information Science		English	Proceedings Paper	9th International FLINS Conference on Computational Intelligence: Foundations and Applications	AUG 02-04, 2010	Emei, PEOPLES R CHINA			FKNN; Editing Technique; Membership Functions; Fuzzy Set; Pattern Recognition		To improve the accuracy of recognition, we propose an approach to modify initial membership function in fuzzy k-nearest neighbors classifier (FKNN). The aim of the approach is that it will specify degree of the object which belongs to each class. The modified function is based on the relationship between patterns in labeled sample set that can deal with some uncertain data. In addition, the combination of edited technique and the modified initial membership technique based on FKNN was used to deal with uncertain data.	[Cheng, Jianmei; Yan, Li; Zhang, Chao; Pei, Zheng] Xihua Univ, Sch Math & Comp Engn, Chengdu 610039, Sichuan, Peoples R China	Cheng, JM (reprint author), Xihua Univ, Sch Math & Comp Engn, Chengdu 610039, Sichuan, Peoples R China.	freecjm2003@163.com					Choi BI, 2009, INFORM SCIENCES, V179, P2102, DOI 10.1016/j.ins.2008.04.009; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI; Guan D, 2009, INFORM SCIENCES, V179, P2273, DOI 10.1016/j.ins.2009.02.011; Hung WL, 2008, PATTERN RECOGN LETT, V29, P1317, DOI 10.1016/j.patrec.2008.02.003; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P1; Wang X, 2009, STUD FUZZ SOFT COMP, V245, P1, DOI 10.1007/978-3-540-78311-4; Wang XZ, 2004, PATTERN RECOGN LETT, V25, P1123, DOI 10.1016/j.patrec.2004.03.008; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Yang MS, 1998, IEEE T SYST MAN CY B, V28, P461, DOI 10.1109/3477.678652	11	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	PO BOX 128 FARRER RD, SINGAPORE 9128, SINGAPORE		978-981-4324-69-4	WD SCI P COMP ENG			2010	4						282	287				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BVA99	WOS:000290926800041	
S	Kim, J; Shen, CH; Wang, L		Zha, H; Taniguchi, RI; Maybank, S		Kim, Junae; Shen, Chunhua; Wang, Lei			A Scalable Algorithm for Learning a Mahalanobis Distance Metric	COMPUTER VISION - ACCV 2009, PT III	Lecture Notes in Computer Science		English	Proceedings Paper	9th Asian Conference on Computer Vision	SEP 23-27, 2009	Xian, PEOPLES R CHINA	Peking Univ, Key Lab Machine Percept, Chinese Acad Sci, Natl lab Pattern Recognit, Inst Automat, Natl Nat Sci Fdn China, Microsoft Res, Fujitsu, Microview, Luster				A distance metric that can accurately reflect the intrinsic characteristics of data is critical for visual recognition tasks. An effective solution to defining such a metric is to learn it from a set of training samples. In this work, we propose a fast and scalable algorithm to learn a Mahalanobis distance. By employing the principle of margin maximization to secure better generalization performances, this algorithm formulates the metric learning as a convex optimization problem with a positive semidefinite (psd) matrix variable. Based on an important theorem that a psd matrix with trace of one can always be represented as a convex combination of multiple rank-one matrices, our algorithm employs a differentiable loss function and solves the above convex optimization with gradient descent methods. This algorithm not only naturally maintains the psd requirement; of the matrix variable that is essential for metric learning; but also significantly cuts down computational overhead, making it much more efficient with the increasing dimensions of feature vectors. Experimental study on benchmark data sets indicates that, compared with the existing metric learning algorithms, our algorithm can achieve higher classification accuracy with much less computational load.	[Kim, Junae; Shen, Chunhua; Wang, Lei] Australian Natl Univ, Canberra, ACT, Australia	Kim, J (reprint author), Australian Natl Univ, Canberra, ACT, Australia.	junae.kim@anu.edu.au; chunhua.shen@nicta.com.au; lei.wang@anu.edu.au					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FEIPEI L, 2004, WORKSH GEN MOD BAS V; Goldberger J., 2005, P ADV NEUR INF PROC; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, DOI 10.1109/ICCV.1999.790410; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Nocedal J, 1999, NUMERICAL OPTIMIZATI; SCHOLKPF B, 2002, LEARNING KERNELS SUP; Shen C., 2008, P ADV NEUR INF PROC, P1473; SMEULDERS AWM, 2000, IEEE T PATTERN ANAL, V22, P1; Vapnik V.N., 1998, STAT LEARNING THEORY; Weinberger K., 2006, P NIPS, P1475; Winn J., 2005, Proceedings. Tenth IEEE International Conference on Computer Vision; Xing EP, 2003, P NIPS, P505; YANG L, 2008, IEEE T PATTERN ANAL, V10	15	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-12296-5	LECT NOTES COMPUT SC			2010	5996						299	310				12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BPQ60	WOS:000279642800029	
J	Kral, P; Cerisara, C				Kral, Pavel; Cerisara, Christophe			DIALOGUE ACT RECOGNITION APPROACHES	COMPUTING AND INFORMATICS			English	Article						Bayesian approaches; dialogue act; lexical information; prosody; syntactic information	MULTIPARTY MEETINGS; CLASSIFICATION; SPEECH	This paper deals with automatic dialogue act (DA) recognition. Dialogue acts are sentence-level units that represent states of a dialogue, such as questions, statements, hesitations, etc. The knowledge of dialogue act realizations in a discourse or dialogue is part of the speech understanding and dialogue analysis process. It is of great importance for many applications: dialogue systems, speech recognition, automatic machine translation, etc. The main goal of this paper is to study the existing works about DA recognition and to discuss their respective advantages and drawbacks. A major concern in the DA recognition domain is that, although a few DA annotation schemes seem now to emerge as standards, most of the time, these DA tag-sets have to be adapted to the specificities of a given application, which prevents the deployment of standardized DA databases and evaluation procedures. The focus of this review is put on the various kinds of information that can be used to recognize DAs, such as prosody, lexical, etc., and on the types of models proposed so far to capture this information. Combining these information sources tends to appear nowadays as a prerequisite to recognize DAs.	[Kral, Pavel] Univ W Bohemia, Dept Comp Sci & Engn, Plzen 30614, Czech Republic; [Cerisara, Christophe] LORIA UMR 7503, F-54506 Vandoeuvre Les Nancy, France	Kral, P (reprint author), Univ W Bohemia, Dept Comp Sci & Engn, Plzen 30614, Czech Republic.	pkral@kiv.zcu.cz; cerisara@loria.fr	Kral, Pavel/C-5631-2013				AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ALEXANDERSSON J, 1997, 191 VERBMOBIL; Allen J., 1997, DRAFT DAMSL DIALOG A; Andernach T., 1997, ECML MLNET WORKSH EM, P85; ANDERNACH T, 1996, NEMLAP 2; ANG J, 2005, P ICASSP MARCH; Austin's J. L., 1962, DO THINGS WORDS; BANGALORE S, 2006, ICASSP 06; BARD EG, 1996, ICSLP 96, V3, P1958; Berger J. O., 1985, STAT DECISION THEORY; BILMES J, 2003, HUM LANG TECHN C EDM; Breiman L, 1984, CLASSIFICATION REGRE; Brill E., 1993, THESIS U PENNSYLVANI; CARLETTA J, 2005, MULT INT REL MACH LE, P11; Carletta J, 1997, COMPUT LINGUIST, V23, P13; COHEN W, 1996, 13 NAT C ART INT AAA, V1, P709; Cottrell M, 1998, NEUROCOMPUTING, V21, P119, DOI 10.1016/S0925-2312(98)00034-4; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAELEMANS W, 2003, TIMBL TILBURG MEMORY; DHILLON R, 2004, TR04002 INT COMP SCI; Dielmann A, 2007, INT CONF ACOUST SPEE, P133; DOUGLAS PT, 2004, 37 ANN HAW INT C SYS; GARNER PN, 1996, ICSLP 96, V3, P1880; GRAU S, 2004, 9 INT C SPEECH COMP, P495; HAYKIN S, 1999, NEURAL NETWORKS COMP; IVANOVA EI, 2005, AKTUALNYE PROBLEMY B, P79; JANIN A, 2003, ICASSP 2003, P364; JEKAT S, 1995, 65 VERBM; JEONG M, 2006, JOINTLY PREDICTING D; JI G, 2005, P ICASSP PHIL US, V1, P33; Jurafsky D., 1997, 9701 U COL I COGN SC; KEIZER S, 2002, DIALOGUE ACT CLASSIF; Keizer S., 2002, 3 ACL SIGDIAL WORKSH, P88; Kohonen T., 1995, SPRINGER SERIES INFO, V30; KOLAR J, 2007, INTERSPEECH 2007, P1621; Kral Pavel, 2007, Journal of Multimedia, V2, DOI 10.4304/jmm.2.3.1-8; LANGLAIS P, 1995, THESIS U AVIGNON PAY; LENDVAI P, 2003, EACL 03 WORKSH DIAL, P69; Levin L., 2003, 4 SIGDIAL WORKSH DIS; Liu Y., 2004, THESIS PURDUE U; MANA N, 2003, EUROSPEECH 2003; MARTIN P, 1987, LINGUISTICS, V2, P925; Mast M., 1996, Connectionist, Statistical and Symbolic Approaches to Learning for Natural Language Processing; McDaniel Jane, 1992, ICASSP 92 IEEE INT C, V1, P517; Meteer M., 1995, DYSFLUENCY ANNOTATIO; QUANG VM, 2007, INTERSPEECH 2007, P2257; REITHINGER N, 1997, EUROSPEECH 97, P2235; REITHINGER N, 1995, 33 ANN M ASS COMP LI, P116; RIES K, 1999, ICASSP 99, V3, P497; ROSSET S, 2008, COMMUNICATION; ROTARU M, 2002, DIALOG ACT TAGGING U; SAMUEL K, 1998, 17 INT C COMP LING M, V2, P1150; SANCHIS E, 2002, 2 INT C HYBR INT SYS, P644; Shriberg E., 1998, LANG SPEECH, V41, P439; Shriberg E, 2000, SPEECH COMMUN, V32, P127, DOI 10.1016/S0167-6393(00)00028-5; Stolcke A., 1996, P INT C SPOK LANG PR, P1005, DOI 10.1109/ICSLP.1996.607773; Stolcke A, 2000, COMPUT LINGUIST, V26, P339, DOI 10.1162/089120100561737; Stolcke A., 1998, Applying Machine Learning to Discourse Processing. Papers from the 1998 AAAI Symposium; TUR G, 2006, MODEL ADAPTATION DIA; van den Bosch A, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P499; WEBB N, 2005, CS0501 U SHEFF DEP C; Woller J., 1996, BASICS MONTE CARLO S; WRIGHT H, 1998, ICSLP 98, V4, P1403; Zimmermann M, 2006, LECT NOTES COMPUT SC, V4299, P190	64	0	0	SLOVAK ACAD SCIENCES INST INFORMATICS	BRATISLAVA	DUBRAVSKA CESTA 9, 84237 BRATISLAVA, SLOVAKIA	1335-9150		COMPUT INFORM	Comput. Inform.		2010	29	2					227	250				24	Computer Science, Artificial Intelligence	Computer Science	623OR	WOS:000279752200004	
J	Marini, F				Marini, Federico			Classification Methods in Chemometrics	CURRENT ANALYTICAL CHEMISTRY			English	Article						Pattern recognition; Classification; Chemometrics; Discriminant analysis; Class modeling	SUPERVISED PATTERN-RECOGNITION; CLASS-MODELING TECHNIQUES; MULTILAYER FEEDFORWARD NETWORKS; ARTIFICIAL NEURAL-NETWORKS; SOLVING CHEMICAL PROBLEMS; OLIVE OIL VARIETIES; FLUORESCENCE SPECTROSCOPY; GEOGRAPHICAL ORIGIN; AUTHENTICATION; DISCRIMINATION	Pattern recognition methods, i.e. the methods concentrating on the possibility of assigning an object to a class based on the result of a set of measurements are ubiquitous in chemometrics. In this paper, the main chemometric classification methods are discussed in terms of their nature, behavior, advantages and drawbacks. Both parametric and non parametric or discriminant and modeling techniques are illustrated together with a discussion of some applications to real world problems.	Univ Roma La Sapienza, Dept Chem, I-00185 Rome, Italy	Marini, F (reprint author), Univ Roma La Sapienza, Dept Chem, Piazzale Aldo Moro 5, I-00185 Rome, Italy.	fmmonet@hotmail.com					Barker M, 2003, J CHEMOMETR, V17, P166, DOI 10.1002/cem.785; Bellanti F, 2008, MICROCHEM J, V88, P113, DOI 10.1016/j.microc.2007.11.019; Bishop C. M., 1995, NEURAL NETWORKS PATT; Brodnjak-Voncina D, 2002, ANAL CHIM ACTA, V462, P87, DOI 10.1016/S0003-2670(02)00298-2; Bucci R, 2002, J AGR FOOD CHEM, V50, P413, DOI 10.1021/jf010696v; Checa-Moreno R, 2008, TALANTA, V75, P697, DOI 10.1016/j.talanta.2007.12.020; Christensen JH, 2007, J CHROMATOGR A, V1169, P1, DOI 10.1016/j.chroma.2007.08.077; COOMANS D, 1982, ANAL CHIM ACTA, V136, P15, DOI 10.1016/S0003-2670(01)95359-0; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; De Benedetto GE, 2005, J CULT HERIT, V6, P205, DOI 10.1016/j.culher.2005.06004; DERDE MP, 1986, ANAL CHIM ACTA, V184, P33, DOI 10.1016/S0003-2670(00)86468-5; DERDE MP, 1989, ANAL CHIM ACTA, V223, P19, DOI 10.1016/S0003-2670(00)84072-6; Dixon SJ, 2007, CHEMOMETR INTELL LAB, V87, P161, DOI 10.1016/j.chemolab.2006.12.004; Duda R. O., 2001, PATTERN CLASSIFICATI; Fisher RA, 1936, ANN EUGENIC, V7, P179; Forina M, 2008, CHEMOMETR INTELL LAB, V93, P132, DOI 10.1016/j.chemolab.2008.05.003; HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Kohonen T., 2001, SELF ORGANIZING MAPS; Kowalkowski T, 2007, J ENVIRON SCI HEAL A, V42, P421, DOI 10.1080/10934520601187336; KOWALSKI BR, 1975, NATURWISSENSCHAFTEN, V62, P10; KOWALSKI BR, 1972, J AM CHEM SOC, V94, P5632, DOI 10.1021/ja00771a016; KVASNICKA V, 1993, J AM CHEM SOC, V115, P1495, DOI 10.1021/ja00057a039; Lukasiak BM, 2007, CHEMOMETR INTELL LAB, V87, P18, DOI 10.1016/j.chemolab.2006.01.003; Marini F, 2006, CHEMOMETR INTELL LAB, V80, P140, DOI 10.1016/j.chemolab.2005.05.002; Marini F, 2003, MICROCHEM J, V74, P239, DOI 10.1016/S0026-265X(03)00028-6; Marini F, 2003, EUR J LIPID SCI TECH, V105, P697, DOI 10.1002/ejlt.200300797; Marini F, 2004, CHEMOMETR INTELL LAB, V73, P85, DOI 10.1016/j.chemolab.2003.12.007; Marini F, 2004, ANAL CHIM ACTA, V510, P231, DOI 10.1016/j.aca.2004.01.009; Marini F, 2004, ANAL CHIM ACTA, V515, P117, DOI 10.1016/j.aca.2004.01.013; Marini F, 2006, CHEMOMETR INTELL LAB, V84, P164, DOI 10.1016/j.chemolab.2006.04.017; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Melssen W, 2006, CHEMOMETR INTELL LAB, V83, P99, DOI 10.1016/j.chemolab.2006.02.003; NOMIKOS P, 1995, TECHNOMETRICS, V37, P41, DOI 10.2307/1269152; Norgaard L, 2007, J CHEMOMETR, V21, P451, DOI 10.1002/cem.1042; Pomerantsev AL, 2008, J CHEMOMETR, V22, P601, DOI 10.1002/cem.1147; Ramos PM, 2008, TALANTA, V75, P926, DOI 10.1016/j.talanta.2007.12.030; Garcia JCR, 2006, J AGR FOOD CHEM, V54, P7206, DOI 10.1021/jf060823t; Stenlund H, 2008, ANAL CHEM, V80, P6898, DOI 10.1021/ac8005318; Todeschini R, 2007, CHEMOMETR INTELL LAB, V87, P3, DOI 10.1016/j.chemolab.2005.11.001; Vandeginste B.G.M., 1998, HDB CHEMOMETRICS Q B, P207; Vandeginste B.G.M., 1998, HDB CHEMOMETRICS Q B, P649; Whelehan OP, 2006, CHEMOMETR INTELL LAB, V84, P82, DOI 10.1016/j.chemolab.2006.03.008; Wold S., 1977, ACS SYM SER, V52, P243, DOI DOI 10.1021/BK-1977-0052.CH012; Wold S., 1983, LECT NOTES MATH, P286; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5; WoldIII S., 1983, FOOD RES DATA ANAL, P147; Zupan J, 1997, CHEMOMETR INTELL LAB, V38, P1, DOI 10.1016/S0169-7439(97)00030-0; Zupan J., 1999, NEURAL NETWORKS CHEM; ZUPAN J, 1991, ANAL CHIM ACTA, V248, P1, DOI 10.1016/S0003-2670(00)80865-X	50	3	3	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y26, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	1573-4110		CURR ANAL CHEM	Curr. Anal. Chem.	JAN	2010	6	1					72	79				8	Chemistry, Analytical	Chemistry	543TP	WOS:000273601800011	
J	da Costa, ES; Peres, RT; Almeida, J; Lecrevisse, Q; Arroyo, ME; Teodosio, C; Pedreira, CE; van Dongen, JJM; Orfao, A				da Costa, Elaine Sobral; Peres, Rodrigo Tosta; Almeida, Julia; Lecrevisse, Quentin; Elena Arroyo, Maria; Teodosio, Cristina; Pedreira, Carlos Eduardo; van Dongen, Jacques J. M.; Orfao, Alberto		EuroFlow Consortium	Harmonization of Light Scatter and Fluorescence Flow Cytometry Profiles Obtained After Staining Peripheral Blood Leucocytes for Cell Surface-Only Versus Intracellular Antigens with the Fix & Perm (TM) Reagent	CYTOMETRY PART B-CLINICAL CYTOMETRY			English	Article						light scatter; intracellular proteins; immunofluorescence; flow cytometry; cell fixation; automation; eigenvectors	ACUTE MYELOID-LEUKEMIA; CYTOPLASMIC ANTIGENS; MALIGNANT LEUKOCYTES; MYELOPEROXIDASE; CLASSIFICATION; EXPRESSION; DISORDERS; DIAGNOSIS; MEMBRANE; FIXATION	Staining for intracellular markers with the Fix & PerM (TM) reagent is associated with variations in the scatter properties of leucocytes, limiting automated analysis of flow cytometry (FCM) data. Here, we investigated those variables significantly contributing to changes in the light scatter, autofluorescence, and bcl2 staining characteristics of peripheral blood (PB) leucocytes, after fixation with Fix & Perm (TM). Our major aim was to evaluate a new mathematical approach for automated harmonization of FCM data from datafiles corresponding to aliquots of a sample treated with cell-surface-only versus Fix & Perm intracellular staining techniques. Overall, neither the anticoagulant used nor sample storage for <24 h showed significant impact on the light scatter and fluorescence properties of PB leucocytes; similarly, the duration of the fixation period (once >15 min were used) had a minimum impact on the FCM properties of PB leucocytes. Conversely, changes in cell/protein concentrations and the fixative/sample (vol/vol) ratio had a clear impact on the light scatter features of some populations of leucocytes. Accordingly, lower cell/protein concentrations were associated with lower scatter values, particularly for the neutrophils. Such changes could be partially corrected through the use of higher fixative to sample volume ratios. Despite the variable changes detected between aliquots of the same sample treated with cell surface-only versus intracellular staining procedures, the new mathematical approach here proposed and evaluated for automated harmonization of common parameters in both datafiles, could correct the FCM profiles of leucocytes derived from cells undergoing conventional fixation/permeabilization procedures, and made them indistinguishable from those corresponding to aliquots of the same sample treated with cell-surface-only staining techniques.	[Almeida, Julia; Lecrevisse, Quentin; Elena Arroyo, Maria; Teodosio, Cristina; Orfao, Alberto] USAL, CSIC, IBMCC, Ctr Invest Canc,Serv Gen Citometria, Salamanca 37007, Spain; [Almeida, Julia; Lecrevisse, Quentin; Elena Arroyo, Maria; Teodosio, Cristina; Orfao, Alberto] Univ Salamanca, Dept Med, E-37008 Salamanca, Spain; [da Costa, Elaine Sobral] Univ Fed Rio de Janeiro, Inst Pediat & Puericultura Martagao Gesteira, Rio De Janeiro, Brazil; [da Costa, Elaine Sobral] Univ Fed Rio de Janeiro, Programa Posgrad, Med Clin, Rio De Janeiro, Brazil; [Peres, Rodrigo Tosta; Pedreira, Carlos Eduardo] Univ Fed Rio de Janeiro, Sch Med, Rio De Janeiro, Brazil; [Peres, Rodrigo Tosta; Pedreira, Carlos Eduardo] Univ Fed Rio de Janeiro, COPPE, PEE, Engn Grad Program, BR-21945 Rio De Janeiro, Brazil; [van Dongen, Jacques J. M.] Erasmus MC, Dept Immunol, Rotterdam, Netherlands	Orfao, A (reprint author), USAL, CSIC, IBMCC, Ctr Invest Canc,Serv Gen Citometria, Paseo Univ Coimbra S-N,Campus Miguel Unamuno, Salamanca 37007, Spain.	orfao@usal.es	IBSAL, Secretaria/H-3719-2011		Prof. Nelson Spector (Department of Clinica Medica, Federal University of Rio de Janeiro, Brazil)	The authors thank Prof. Nelson Spector (Department of Clinica Medica, Federal University of Rio de Janeiro, Brazil) for his helpful support.	Basso G, 2001, HAEMATOLOGICA, V86, P675; BAUER KD, 1994, METHOD CELL BIOL, V41, P351; BENE MC, 1995, LEUKEMIA, V9, P1783; Braylan RC, 2001, CYTOMETRY, V46, P23, DOI 10.1002/1097-0320(20010215)46:1<23::AID-CYTO1033>3.0.CO;2-Z; BRUNO S, 1992, CYTOMETRY, V13, P496, DOI 10.1002/cyto.990130508; CATOVSKY D, 1992, LEUKEMIA, V6, P1; CLEVENGER CV, 1993, CLIN FLOW CYTOMETRY, P157; Costa ES, 2006, LEUKEMIA, V20, P1221, DOI 10.1038/sj.leu.2404241; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DRACH D, 1993, LEUKEMIA RES, V17, P455, DOI 10.1016/0145-2126(93)90102-Q; DUDA RO, 2001, PATTERN CLASSIFICATI, P174; Francis C, 1996, CYTOMETRY, V25, P58, DOI 10.1002/(SICI)1097-0320(19960901)25:1<58::AID-CYTO7>3.0.CO;2-A; Gibbs G, 2005, CLIN LAB HAEMATOL, V27, P258, DOI 10.1111/j.1365-2257.2005.00703.x; Groeneveld K, 1996, LEUKEMIA, V10, P1383; ISLAM D, 1995, CYTOMETRY, V22, P128, DOI 10.1002/cyto.990220208; JACOBBERGER JW, 2000, IMMUNOPHENOTYPING, P361; Kappelmayer J, 2000, J IMMUNOL METHODS, V242, P53, DOI 10.1016/S0022-1759(00)00220-9; KNAPP W, 1994, CYTOMETRY, V18, P187, DOI 10.1002/cyto.990180402; Konikova E, 1998, NEOPLASMA, V45, P282; Lacombe F, 1997, LEUKEMIA, V11, P1878, DOI 10.1038/sj.leu.2400847; Lanza F, 1997, CYTOMETRY, V30, P134; Macey MG, 1999, CYTOMETRY, V38, P153, DOI 10.1002/(SICI)1097-0320(19990815)38:4<153::AID-CYTO2>3.0.CO;2-E; Millard I, 1998, CLIN CHEM, V44, P2320; Nakase K, 1998, CYTOMETRY, V34, P198, DOI 10.1002/(SICI)1097-0320(19980815)34:4<198::AID-CYTO4>3.0.CO;2-C; Pedreira CE, 2008, CYTOM PART A, V73A, P1141, DOI 10.1002/cyto.a.20638; PIZOLLO G, 1994, LEUKEMIA, V8, P672; Ruiz-Arguelles A, 2006, CYTOM PART B-CLIN CY, V70B, P39, DOI 10.1002/cyto.20083; SARTOR M, 1994, CYTOMETRY, V18, P119, DOI 10.1002/cyto.990180302; SCHIMENTI KJ, 1992, CYTOMETRY, V13, P48, DOI 10.1002/cyto.990130109; SLAPERCORTENBACH ICM, 1988, BLOOD, V72, P1639; STELZER GT, 1993, ANN NY ACAD SCI, V677, P265, DOI 10.1111/j.1749-6632.1993.tb38783.x; STEWART CC, 1992, CANCER, V69, P1543, DOI 10.1002/1097-0142(19920315)69:6+<1543::AID-CNCR2820691307>3.0.CO;2-O; STRANG G, 2006, LINEAR ALGEBRA ITS A, P80; STRANG G, 2006, LINEAR ALGEBRA ITS A, P243; Van Lochem EG, 1997, LEUKEMIA, V11, P2208, DOI 10.1038/sj.leu.2400862; VANZAANEN HCT, 1995, BRIT J HAEMATOL, V91, P55	36	3	3	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	1552-4949		CYTOM PART B-CLIN CY	Cytom. Part B-Clin. Cytom.	JAN	2010	78B	1					11	20		10.1002/cyto.b.20486		10	Medical Laboratory Technology; Pathology	Medical Laboratory Technology; Pathology	538EW	WOS:000273168100003	
B	Lavrac, N; Zupan, B		Maimon, O; Rokach, L		Lavrac, Nada; Zupan, Blaz			Data Mining in Medicine	DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, SECOND EDITION			English	Article; Book Chapter						Data Mining in Medicine; Inductive Logic Programming; Decision Trees; Rule Induction; Case-based Reasoning; Instance-based Learning; Supervised Learning; Neural Networks	ARTIFICIAL NEURAL NETWORKS; BREAST-CANCER DIAGNOSIS; FUZZY-LOGIC; EXTRACTING RULES; EXPERT-SYSTEM; PATTERN-CLASSIFICATION; FUNCTION DECOMPOSITION; BACKGROUND KNOWLEDGE; ALGORITHM; MODEL	Extensive amounts of data stored in medical databases require the development of specialized tools for accessing the data, data analysis, knowledge discovery, and effective use of stored knowledge and data. This chapter focuses on Data Mining methods and tools for knowledge discovery. The chapter sketches the selected Data Mining techniques, and illustrates their applicability to medical diagnostic and prognostic problems.	[Lavrac, Nada] Jozef Stefan Inst, Ljubljana 1000, Slovenia; [Lavrac, Nada] Nova Gorica Polytech, Nova Gorica 5000, Slovenia; [Zupan, Blaz] Univ Ljubljana, Fac Comp & Informat Sci, Ljubljana 1000, Slovenia; [Zupan, Blaz] Baylor Coll Med, Dept Mol & Human Genet, Houston, TX 77030 USA	Lavrac, N (reprint author), Jozef Stefan Inst, Jamova 39, Ljubljana 1000, Slovenia.						AAMODT A, 1994, AI COMMUN, V7, P39; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Andrews PJD, 2002, J NEUROSURG, V97, P326, DOI 10.3171/jns.2002.97.2.0326; Andrews R, 1995, KNOWL-BASED SYST, V8, P373, DOI 10.1016/0950-7051(96)81920-4; ASTION ML, 1992, ARCH PATHOL LAB MED, V116, P995; Averbuch M, 2004, ST HEAL T, V107, P282; BARLOW TW, 1995, J MOL GRAPHICS, V13, P53; BAXT WG, 1964, LANCET, V364, P1135; Becker K, 1997, ARTIF INTELL MED, V11, P33, DOI 10.1016/S0933-3657(97)00020-1; Bradburn C, 1993, Comput Nurs, V11, P20; Bratko I, 1989, KARDIO STUDY DEEP QU; BRATKO I, 1987, AL METHODS STAT; Breault JL, 2002, ARTIF INTELL MED, V26, P37, DOI 10.1016/S0933-3657(02)00051-9; Breiman L, 1984, CLASSIFICATION REGRE; Brossette SE, 1998, J AM MED INFORM ASSN, V5, P373; CARPENTER GA, 1993, P WORLD C NEUR NETW, P501; Carrault G, 2003, ARTIF INTELL MED, V28, P231, DOI 10.1016/S0933-3657(03)00066-6; Caruana R, 1996, ADV NEUR IN, V8, P959; CENDROWSKA J, 1987, INT J MAN MACH STUD, V27, P349, DOI 10.1016/S0020-7373(87)80003-2; CESTNIK B, 1987, PROGR MACHINE LEARNI; Cestnik B., 1990, P EUR C ART INT, P147; Chung F. L., 1992, International Journal of Neural Systems, V3, DOI 10.1142/S0129065792000231; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Clark P., 1991, P 5 EUR WORK SESS LE, P151; Compton P, 1989, APPL EXPERT SYSTEMS, P366; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Craven MW, 1997, FUTURE GENER COMP SY, V13, P211, DOI 10.1016/S0167-739X(97)00022-8; Cristianini N, 2000, INTRO SUPPORT VECTOR; Dasarathy B.V., 1990, NEAREST NEIGHBOR NN; Dehaspe L., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; DeRaedt L, 1997, MACH LEARN, V26, P99, DOI 10.1023/A:1007361123060; DIBONA S, 2003, AL MED, V28; Downs J, 1996, ARTIF INTELL MED, V8, P403, DOI 10.1016/0933-3657(95)00044-5; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Dybowski R, 1996, LANCET, V347, P1146, DOI 10.1016/S0140-6736(96)90609-1; Dzeroski S, 1996, Technol Health Care, V4, P203; EDWARDS G, 1993, PATHOLOGY, V25, P27; Fausett L., 1994, FUNDAMENTALS NEURAL; Fayyad U, 1996, COMMUN ACM, V39, P27, DOI 10.1145/240455.240464; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1023/A:1022852608280; FIX E, 1957, 4 US AIR FORC SCH AV; Frawley WJ, 1991, KNOWLEDGE DISCOVERY; Gamberger D, 2003, ARTIF INTELL MED, V28, P27, DOI 10.1016/S0933-3657(03)00034-4; Gamberger D., 2002, J ARTIF INTELL RES, V17, P501; Gaspari M, 2002, ARTIF INTELL MED, V25, P187, DOI 10.1016/S0933-3657(02)00015-5; GOLDBERG DE, 1989, GENETIC ALGORITHMS S, P68; GONZALEZ JS, 1999, ARTIF INTELL, V190, P75; Gyongyosi M, 2002, ARTIF INTELL MED, V26, P237, DOI 10.1016/S0933-3657(02)00084-2; Ham FM, 1996, IEEE T BIO-MED ENG, V43, P425, DOI 10.1109/10.486263; Henson DB, 1997, ARTIF INTELL MED, V10, P99, DOI 10.1016/S0933-3657(97)00388-6; Holte RC, 1989, P 11 INT JOINT C ART, P813; HORN KA, 1985, AUST COMPUT J, V17, P7; KAHN CE, 1994, INVEST RADIOL, V29, P643, DOI 10.1097/00004424-199406000-00009; KATTAN MW, 1995, ARCH PATHOL LAB MED, V119, P672; Kattan MW, 1997, KLUWER INT SER ENG C, V414, P295; Kira K., 1992, P 9 INT C MACH LEARN, P249; Kira K., 1992, P 10 NAT C ART INT, P129; KOEHLE M, 1997, P IEEE S COMP MED SY, P138; Kohavi R., 1997, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V6, DOI 10.1142/S021821309700027X; Kohonen T., 1988, SELF ORG ASS MEMORY; Komorowski J, 1999, ARTIF INTELL MED, V15, P167, DOI 10.1016/S0933-3657(98)00051-7; KONONENKO I, 1995, P ISSEK WORKSH MATH, P199; Kononenko I, 1994, P EUR C MACH LEARN, P171; KONONENKO I, 1993, APPL ARTIF INTELL, V7, P317, DOI 10.1080/08839519308949993; Kononenko I, 1991, P 6 EUR WORK SESS LE, p206~219; Kovalerchuk B, 1997, ARTIF INTELL MED, V11, P75, DOI 10.1016/S0933-3657(97)00021-3; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; Labatut V, 2004, ARTIF INTELL MED, V30, P119, DOI 10.1016/S0933-3657(03)00042-3; Lam W, 1998, IEEE T PATTERN ANAL, V20, P240; Larranaga P, 1997, P ART INT MED EUR, P261; Lavrac N, 2004, J MACH LEARN RES, V5, P153; LAVRAC N, 1993, APPL ARTIF INTELL, V7, P273, DOI 10.1080/08839519308949989; LAVRAE N, 1994, INDUCTIVE LOGIC PROG; LIESTOL K, 1994, STAT MED, V13, P1189, DOI 10.1002/sim.4780131202; Lin T. Y., 1997, ROUGH SETS DATA MINI; LUBSEN J, 1978, METHOD INFORM MED, V17, P127; Macura RT, 1997, ARTIF INTELL MED, V9, P1, DOI 10.1016/S0933-3657(96)00358-2; Malmberg LP, 1996, CLIN PHYSIOL, V16, P115, DOI 10.1111/j.1475-097X.1996.tb00562.x; Mariuzzi GM, 1997, PATHOL RES PRACT, V193, P535; Markey MK, 2003, ARTIF INTELL MED, V27, P113, DOI 10.1016/S0933-3657(03)00003-4; MCSHERRY D, 1997, P 6 C ART INT MED EU, P223; MICHALSKI R, 1986, P 5 NAT C ART INT AA, P1045; MICHALSKI RS, 1983, MACHINE LEARNING AI, V1, P331; MICHALSKI RS, 1986, P 5 NAT C ART INT MO, P3; MICHALSKI RS, 1986, MACHINE LEARNING ART, P3; Mizoguchi F, 1997, KLUWER INT SER ENG C, V414, P227; Modai I, 1996, J Med Syst, V20, P403, DOI 10.1007/BF02257284; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; NIBLETT T, 1986, RES DEV EXPERT SYSTE, V3, P24; PAWLAK Z, 1991, THEORETICAL ASPECTS, V9; PAWLAK Z, 1981, INFORM SYST, V6, P205, DOI 10.1016/0306-4379(81)90023-5; Pearl J., 1988, PROBABILISTIC REASON, p[505, 506, 507, 524]; Pilih IA, 1997, KLUWER INT SER ENG C, V414, P131; POLKOWSKI L, 1998, ROUGH SETS KNOWLEDGE, V18; Prochazka A, 1996, CAN J PHYSIOL PHARM, V74, P456, DOI 10.1139/cjpp-74-4-456; QUAGLINI S, 1994, MED DECIS MAKING, V14, P223, DOI 10.1177/0272989X9401400304; Quinlan J. R., 1993, PROGRAMS MACHINE LEA; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; Quinlan J. R., 1986, INDUCTION DECISION T, V1, P81, DOI DOI 10.1007/BF00116251; RAU G, 1995, ARTIF ORGANS, V19, P105, DOI 10.1111/j.1525-1594.1995.tb02255.x; Richeldi M, 1995, LECT NOTES ARTIF INT, V912, P335; Riva A, 1996, ARTIF INTELL MED, V8, P217, DOI 10.1016/0933-3657(95)00034-8; ROKACH L, 2004, LECT NOTES ARTIF INT, V3055, P17228; ROSETTA A, ROUGH SET TOOLKIT AN; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; Sacha JP, 2002, ARTIF INTELL MED, V26, P109, DOI 10.1016/S0933-3657(02)00055-6; SAMMUT C, 1998, INTRO RIPPLE DOWN RU; Setiono R, 1997, NEURAL COMPUT, V9, P205, DOI 10.1162/neco.1997.9.1.205; Setiono R, 2000, ARTIF INTELL MED, V18, P205, DOI 10.1016/S0933-3657(99)00041-X; Setiono R, 1996, ARTIF INTELL MED, V8, P37, DOI 10.1016/0933-3657(95)00019-4; SHANNON CE, 1948, AT&T TECH J, V27, P379; SHAWLIK JW, 1991, MACH LEARN, V6, P111; SKOWRON A, 1995, P 5 SCAND C ART INT, P220; Srinivasan A, 1997, KLUWER INT SER ENG C, V414, P243; Steimann F, 1997, ARTIF INTELL MED, V11, P1; Stel VS, 2003, J AM GERIATR SOC, V51, P1356, DOI 10.1046/j.1532-5415.2003.51452.x; SZOLOVITS P, 1995, METHOD INFORM MED, V34, P111; Tsumoto S, 1998, LECT NOTES ARTIF INT, V1424, P475; Vapnik V.N., 1998, STAT LEARNING THEORY; VINTERBO S, 1999, AL MED, V18, P117; WETTSCHERECK D, 1994, THESIS OREGON STATE; Witten I.H., 1999, DATA MINING PRACTICA; WOLPERT D, 1989, NEURAL NETWORKS, V3, P445; Wrobel S, 1997, LECT NOTES ARTIF INT, V1263, P78; Wu CH, 1997, COMPUT CHEM, V21, P237, DOI 10.1016/S0097-8485(96)00038-1; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; Zelic I, 1997, J Med Syst, V21, P429, DOI 10.1023/A:1022880431298; Zhu Y, 1997, IEEE T MED IMAGING, V16, P55; Zupan B, 1998, ARTIF INTELL MED, V14, P101, DOI 10.1016/S0933-3657(98)00018-9; Zupan B, 1998, IEEE INTELL SYST APP, V13, P38, DOI 10.1109/5254.671090; Zupan B, 1997, KLUWER INT SER ENG C, V414, P261; Zupan B, 2001, METHOD INFORM MED, V40, P25	133	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES		978-0-387-09822-7				2010							1111	1136		10.1007/978-0-387-09823-4_58	10.1007/978-0-387-09823-4	26	Computer Science, Artificial Intelligence	Computer Science	BVX97	WOS:000293102200058	
S	Aug, HH; Gopalkrishnan, V; Hoi, SCH; Ng, WK		Kitagawa, H; Ishikawa, Y; Li, Q; Watanabe, C		Aug, Hock Hee; Gopalkrishnan, Vivekanand; Hoi, Steven C. H.; Ng, Wee Keong			Adaptive Ensemble Classification in P2P Networks	DATABASE SYSTEMS FOR ADVANCED APPLICATIONS, PT I, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	15th International Conference on Database Systems for Advanced Applications	APR 01-04, 2010	Tsukuba, JAPAN				TO-PEER NETWORKS	Classification in P2P networks has become an important research problem in data mining due to the popularity of P2P computing environments. This is still an open difficult research problem due to a variety of challenges, such as non-i.i.d. data distribution, skewed or disjoint class distribution, satiability; peer dynamism and a synchronism. In this paper, we present a novel P2P Adaptive Classification Ensemble (PACE.) framework to perform classification in P2P networks. Unlike regular ensemble classification approaches, our new framework adapts to the test data. distribution and dynamically adjusts the voting scheme by combining a subset of classifiers/peers according to the test data example. In our approach, we implement the proposed PACE solution together with the state-of-the-art linear SVM as the base classifier for scalable P2P classification. Extensive empirical studies show that the proposed PACE method is both efficient and effective in improving classification performance over regular methods under various adverse conditions.	[Aug, Hock Hee; Gopalkrishnan, Vivekanand; Hoi, Steven C. H.; Ng, Wee Keong] Nanyang Technol Univ, Singapore, Singapore	Aug, HH (reprint author), Nanyang Technol Univ, Singapore, Singapore.		Hoi, Steven Chu Hong/A-3736-2011				ANDONI A, 2006, FOCS, P459; ANG HH, 2008, VLDB WORKSH DBISP2P, P13; Ang HH, 2008, LECT NOTES ARTIF INT, V5211, P55; Arthur D., 2007, SODA 07, P1027; Asuncion A., 2007, UCI MACHINE LEARNING; BERCHTOLD S, 1998, IEEE INT C DAT ENG 1, P209; Bhaduri K., 2008, STAT ANAL DATA MININ, V1, P85, DOI 10.1002/sam.10006; Breiman L, 1999, MACH LEARN, V36, P85, DOI 10.1023/A:1007563306331; Chan PK, 1998, KNOWLEDGE DISCOVERY, V1998, P164; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Datta S, 2006, IEEE INTERNET COMPUT, V10, P18, DOI 10.1109/MIC.2006.74; GORODETSKIY V, 2006, HYBRID INFORM TECHNO, P224; Hsich C.-J., 2008, ICML, P408; Jordan MI, 1995, NEURAL NETWORKS, V8, P1409, DOI 10.1016/0893-6080(95)00014-3; Luo P, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P968; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; SIERSDORFER S, 2006, ECIR, P265	17	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-12025-1	LECT NOTES COMPUT SC			2010	5981		I				34	48				15	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BPO85	WOS:000279562400003	
S	Narvaez, F; Diaz, G; Romero, E		Marti, J; Oliver, A; Freixenet, J; Marti, R		Narvaez, Fabian; Diaz, Gloria; Romero, Eduardo			Automatic BI-RADS Description of Mammographic Masses	DIGITAL MAMMOGRAPHY	Lecture Notes in Computer Science		English	Proceedings Paper	10th International Workshop on Digital Mammography	JUN 16-18, 2010	Girona, SPAIN	Univ Girona, Comp Vision & Robot Grp		Automatic Annotation; BI-RADS; Computer Aided Diagnosis; Content-based Image Retrieval	COMPUTER-AIDED DIAGNOSIS; ZERNIKE MOMENTS; CLASSIFICATION	This paper presents a Call (Content Based Information Retrieval) framework for automatic description of mammographic masses according to the well known BI-RADS lexicon. Unlike other approaches, we do not attempt to segment masses but instead, we describe the regions an expert selects, after the series of rules defined in the BI-RADS lexicon. The content based retrieval strategy searches similar regions by automatically computing the Mahalanobis distance of feature vectors that describe main shape and texture characteristics of the selected regions. A description of a. test region is based on the BI-RADS description associated to the retrieved regions. The strategy was assessed in a set of 444 masses with different shapes and margins. Suggested descriptions were compared with a ground truth already provided by the data base, showing a precision rate of 82.6% for the retrieval task and a sensitivity rate of 80% for the annotation task.	[Narvaez, Fabian; Diaz, Gloria; Romero, Eduardo] Natl Univ Colombia, Bioingenium Res Grp, Dept Med, Bogota, Colombia	Narvaez, F (reprint author), Natl Univ Colombia, Bioingenium Res Grp, Dept Med, Bogota, Colombia.	frnarvaeze@unal.edu.co; gmdiazc@unal.edu.co; edromero@unal.edu.co					AMADASUN M, 1989, IEEE T SYST MAN CYB, V19, P1264, DOI 10.1109/21.44046; American College of Radiology (ACR), 1998, ILL BREAST IM REP DA; Belkasim S., 2004, 4 INT C COMP INF TEC, V1, P790; Bird R., 1992, RADIOLOGY, V178, P234; BOVIS K, 2002, MED IMAGE UNDERSTAND; Buseman S, 2003, CANCER, V97, P352, DOI 10.1002/cncr.11050; Cheng HD, 2006, PATTERN RECOGN, V39, P646, DOI 10.1016/j.patcog.2005.07.006; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Gur D, 2004, RADIOLOGY, V233, P418, DOI 10.1148/radiol.2332040277; Heath M, 2001, P 5 INT WORKSH DIG M, P212; Hosny KM, 2008, J REAL-TIME IMAGE PR, V3, P97, DOI 10.1007/s11554-007-0058-5; Kim HK, 2000, SIGNAL PROCESS-IMAGE, V16, P87, DOI 10.1016/S0923-5965(00)00018-7; Maggio C. D., 2004, EUR J NUCL MED MO S1, V31, pS59; MARIAS K, 2005, P IEEE ENG MED BIOL; Nishikawa RA, 2007, COMPUT MED IMAG GRAP, V31, P224, DOI 10.1016/j.compmedimag.2007.02.009; Petrick N, 1996, IEEE T MED IMAGING, V15, P59, DOI 10.1109/42.481441; PETROUDI S, 2003, IEEE INT C ENG MED B; Rangayyan RM, 2007, J FRANKLIN I, V344, P312, DOI 10.1016/j.jfranklin.2006.09.003; Rosa NA, 2008, IEEE ENG MED BIO, P406, DOI 10.1109/IEMBS.2008.4649176; TAO Y, 2008, P SPIE; Tao YM, 2007, P SOC PHOTO-OPT INS, V6514, pZ5141, DOI 10.1117/12.711528; TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920; VERMA K, 2002, IEEE T INF TECHNOL B, V16, P219; Wee CY, 2007, IMAGE VISION COMPUT, V25, P967, DOI 10.1016/j.imavis.2006.07.010; Zheng B, 2007, ACAD RADIOL, V14, P917, DOI 10.1016/j.acra.2007.04.012; [Anonymous], 2007, AM CANC STAT	26	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-13665-8	LECT NOTES COMPUT SC			2010	6136						673	681				9	Computer Science, Theory & Methods; Radiology, Nuclear Medicine & Medical Imaging	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	BSN74	WOS:000285030000091	
J	Pughineanu, C				Pughineanu, C.			Evaluation of the Performances of a Parallel Algorithm to Recognize the Patterns in Relation with the Sequential Variant	ELEKTRONIKA IR ELEKTROTECHNIKA			English	Article								C. Pughineanu. Evaluation of the Performances of a Parallel Algorithm to Recognize the Patterns in Relation with the Sequential Variant // Electronics and Electrical Engineering. - Kaunas: Technologija, 2010. - No. 9(105). - P. 65-68. To achieve an algorithm to efficiently recognize the patterns to return the best solution, we need an intensive processing of the entrance set data. In most cases there is a compromise between the taking over of the entrance set data and the algorithm execution time. The intensive processing of the entrance set data needs rather high calculation resources which cannot always be obtained from the ordinary calculation systems. In this paper we suggest the parallelization of an algorithm to recognize the patterns in scientific literature, its parallelization and the evaluation of this variant in relation to the sequential algorithm. This algorithm will be tested using a cluster formed of 28 nods, each nod having 2 quad core 2.33GHz processors. Bibl. 13 (in English; abstracts in English and Lithuanian).	Stefan Cel Mare Univ Suceava, Fac Elect Engn & Comp Sci, Suceava 720229, Romania	Pughineanu, C (reprint author), Stefan Cel Mare Univ Suceava, Fac Elect Engn & Comp Sci, Str Univ 13, Suceava 720229, Romania.						Alexa D, 2008, IET POWER ELECTRON, V1, P224, DOI 10.1049/iet-pel:20070149; Asuncion A., 2007, UCI MACHINE LEARNING; CIUFUDEAN C, 2009, ELEKTRON ELEKTROTECH, P65; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dambrauskas A, 2008, ELEKTRON ELEKTROTECH, P25; JETINSKIS J, 2009, ELEKTRON ELEKTROTECH, P3; Kohonen T., 1988, SELF ORG ASS MEMORY; PENTIUC SG, 1997, APLICATII ALE RECUNO; Rata G, 2010, ELEKTRON ELEKTROTECH, P62; Pentiuc SG, 2010, ELEKTRON ELEKTROTECH, P87; Ungurean I, 2010, ELEKTRON ELEKTROTECH, P57; VANDATNEJAD H, 2009, ADV ELECTR COMPUT EN, V9, P22; ZAMIR O, 1998, RES DEV INFORM RETRI, P46	13	0	0	KAUNAS UNIV TECHNOLOGY	KAUNAS	KAUNAS UNIV TECHNOL, DEPT ELECTRONICS ENGINEERING, STUDENTU STR 50, KAUNAS, LT-51368, LITHUANIA	1392-1215		ELEKTRON ELEKTROTECH	Elektron. Elektrotech.		2010		9					65	68				4	Engineering, Electrical & Electronic	Engineering	708NH	WOS:000286368000014	
J	Yang, W; Triggs, B; Dai, DX; Xia, GS				Yang, Wen; Triggs, Bill; Dai, Dengxin; Xia, Gui-Song			Scene Segmentation with Low-Dimensional Semantic Representations and Conditional Random Fields	EURASIP JOURNAL ON ADVANCES IN SIGNAL PROCESSING			English	Article							MARKOV RANDOM-FIELDS; ENERGY MINIMIZATION; OBJECT RECOGNITION; FEATURE SPACE; GRAPH CUTS; CLASSIFICATION	This paper presents a fast, precise, and highly scalable semantic segmentation algorithm that incorporates several kinds of local appearance features, example-based spatial layout priors, and neighborhood-level and global contextual information. The method works at the level of image patches. In the first stage, codebook-based local appearance features are regularized and reduced in dimension using latent topic models, combined with spatial pyramid matching based spatial layout features, and fed into logistic regression classifiers to produce an initial patch level labeling. In the second stage, these labels are combined with patch-neighborhood and global aggregate features using either a second layer of Logistic Regression or a Conditional Random Field. Finally, the patch-level results are refined to pixel level using MRF or over-segmentation based methods. The CRF is trained using a fast Maximum Margin approach. Comparative experiments on four multi-class segmentation datasets show that each of the above elements improves the results, leading to a scalable algorithm that is both faster and more accurate than existing patch-level approaches.	[Yang, Wen; Dai, Dengxin] Wuhan Univ, Sch Elect Informat, Wuhan 430079, Peoples R China; [Triggs, Bill] Lab Jean Kuntzmann, AI Team, F-38402 Grenoble, France; [Xia, Gui-Song] TELECOM ParisTech, CNRS LTCI, F-75013 Paris, France	Yang, W (reprint author), Wuhan Univ, Sch Elect Informat, Wuhan 430079, Peoples R China.	yangwen@whu.edu.cn			Chinese National Natural Sciences Foundation [40801183, 60890074]; European Union [027978]	The authors would like to thank Professor T. Joachims of Cornell University for his help with SVMStruct. The research was supported in part by the Chinese National Natural Sciences Foundation Grants 40801183 and 60890074 and by European Union IST project 027978 CLASS.	Anguelov D, 2005, PROC CVPR IEEE, P169; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bosch A, 2006, LECT NOTES COMPUT SC, V3954, P517; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Cao L., 2007, P IEEE 11 INT C COMP; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Criminisi A., 2004, MICROSOFT RES CAMBRI; Csurka G., 2008, P BRIT MACH VIS C; Fan RE, 2008, J MACH LEARN RES, V9, P1871; Galleguillos C., 2008, P 26 IEEE C COMP VIS; Gould S, 2008, INT J COMPUT VISION, V80, P300, DOI 10.1007/s11263-008-0140-x; Grauman K., 2005, Proceedings. Tenth IEEE International Conference on Computer Vision; He X., 2006, P 9 EUR C COMP VIS, V1, P338; He X., 2008, P 26 IEEE C COMP VIS; He X., 2008, ADV NEURAL INFORM PR; He XM, 2004, PROC CVPR IEEE, P695; Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950; Joachims T., 2009, MACH LEARN, V76, P27; Komodakis N, 2007, IEEE T PATTERN ANAL, V29, P1436, DOI 10.1109/TPAMI.2007.1061; Komodakis N, 2008, COMPUT VIS IMAGE UND, V112, P14, DOI 10.1016/j.cviu.2008.06.007; Kumar S., 2005, Proceedings. Tenth IEEE International Conference on Computer Vision; Kyrki V, 2004, PATTERN RECOGN LETT, V25, P311, DOI 10.1016/j.patrec.2003.10.008; LAFFERTY J. D., 2001, P 18 INT C MACH LEAR, P282; Lazebnik S., 2006, P IEEE C COMP VIS PA, P2169; Lin C.-J., 2007, P 24 INT C MACH LEAR, P561, DOI 10.1145/1273496.1273567; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; McCallum A, 2006, P 23 INT C MACH LEAR, P577, DOI DOI 10.1145/1143844.1143917; Perona P., 2005, P IEEE C COMP VIS PA, P524; Quelhas P., 2005, Proceedings. Tenth IEEE International Conference on Computer Vision; Rabinovich A., 2007, P IEEE 11 INT C COMP; Rasiwasia N., 2008, P 26 IEEE C COMP VIS; SCHROFF F, 2006, P IND C COMP VIS GRA; Schroff F., 2008, P BRIT MACH VIS C, P541; Shotton J., 2008, P 26 IEEE C COMP VIS; Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1; Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844; Szummer M., 2008, P 10 EUR C COMP VIS; Taskar B., 2005, P 22 INT C MACH LEAR, P896, DOI 10.1145/1102351.1102464; Taskar B, 2006, J MACH LEARN RES, V7, P1627; Torralba A., 2005, ADV NEURAL INFORM PR, P1401; Toyoda T, 2008, IEEE T PATTERN ANAL, V30, P1483, DOI 10.1109/TPAMI.2008.105; Tsochantaridis I., 2005, J MACHINE LEARNING R, V6; Tu Z., 2008, P 26 IEEE C COMP VIS; van de Weijer J, 2006, LECT NOTES COMPUT SC, V3952, P334; Verbeek J., 2007, P IEEE COMP SOC C CO; VERBEEK J, 2008, ADV NEURAL INFORM PR, P1553; Vishwanathan S., 2006, P 23 INT C MACH LEAR, P969, DOI 10.1145/1143844.1143966; Xing E., 2005, P 21 ANN C UNC ART I; Yang L., 2007, P IEEE COMP SOC C CO	50	0	0	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	1687-6180		EURASIP J ADV SIG PR	EURASIP J. Adv. Signal Process.		2010									196036	10.1155/2010/196036		14	Engineering, Electrical & Electronic	Engineering	760MF	WOS:000290327700001	
J	Govindarajan, M; Chandrasekaran, RM				Govindarajan, M.; Chandrasekaran, R. M.			Evaluation of k-Nearest Neighbor classifier performance for direct marketing	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Data mining; Cross-validation; k-Nearest Neighbor; Runtime; Accuracy		Text data mining is a process of exploratory data analysis. Classification maps data into predefined groups or classes. It is often referred to as supervised learning because the classes are determined before examining the data. This paper describes the proposed k-Nearest Neighbor classifier that performs comparative cross-validation for the existing k-Nearest Neighbor classifier. The feasibility and the benefits of the proposed approach are demonstrated by means of data mining problem: direct marketing. Direct marketing has become an important application field of data mining. Comparative cross-validation involves estimation of accuracy by either stratified k-fold cross-validation or equivalent repeated random subsampling. While the proposed method may have a high bias; its performance (accuracy estimation in our case) may be poor due to a high variance. Thus the accuracy with the proposed k-Nearest Neighbor classifier was less than that with the existing k-Nearest Neighbor classifier, and the smaller the improvement in runtime the larger the improvement in precision and recall. In our proposed method we have determined the classification accuracy and prediction accuracy where the prediction accuracy is comparatively high. (C) 2009 Elsevier Ltd. All rights reserved.	[Govindarajan, M.; Chandrasekaran, R. M.] Annamalai Univ, Dept Comp Sci & Engn, Annamalainagar 608002, Tamil Nadu, India	Govindarajan, M (reprint author), Annamalai Univ, Dept Comp Sci & Engn, Annamalainagar 608002, Tamil Nadu, India.	govind_aucse@yahoo.com; aurmc@sify.com			All India Council for Technical Education, New Delhi	The authors gratefully acknowledge the authorities of Annamalai University for the facilities offered and encouragement to carry out this work. This part of work is Supported in part by the first author who got Career Award for Young Teachers (CAYT) grant from All India Council for Technical Education, New Delhi. They would also like to thank the reviewers for their Valuable remarks	Bauer C. L., 1988, J DIRECT MARKETING, V2, P16, DOI 10.1002/dir.4000020305; Blake CL, 1998, UCI REPOSITORY MACHI; Burr Ridge I, 1997, MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B., 1991, NEAREST NEIGHBOR PAT; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; DUNHAM MH, 2003, DATA MINING INTRO AD, P90; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; HAN J, 2003, DATA MINING CONCEPTS, P359; HOTTA S, 2004, P 17 INT C PATT REC; ISHIIL N, 2005, P 2005 3 ACIS INT C; Jacobs C.E., 1995, P SIGGRAPH 95, P277, DOI 10.1145/218380.218454; JOVANOVIC N, 2002, MEMBER IEEE FDN PRED; Knuth D. E., 1973, ART COMPUTER PROGRAM, V3; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Lee HJ, 2007, EXPERT SYST APPL, V33, P522, DOI 10.1016/j.eswa.2006.05.016; MADEIRA S, 2002, 1049001 IDMEC TU LIS; Phillips P. J., 1998, ADV NEURAL INFORM PR, V11, P803; Ross S., 1988, 1 COURSE PROBABILITY; SALTON G, 1971, SMART INFORM RETRIEV; SAMET H, 2003, P 12 INT C IM AN PRO; SOUSA JM, 2002, P 11 IEEE INT C FUZZ; TANA S, 2006, EXPERT SYSTEMS APPL, V30, P290; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Vapnik V.N., 1998, STAT LEARNING THEORY; WISKOTT L, 1997, TPAMI, V19, P775; ZHU H, 2003, P 3 IEEE INT C DAT M	28	1	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	JAN	2010	37	1					253	258		10.1016/j.eswa.2009.04.055		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	516VI	WOS:000271571000029	
S	Perkovic, T; Cagalj, M; Saxena, N		Sion, R		Perkovic, Toni; Cagalj, Mario; Saxena, Nitesh			Shoulder-Surfing Safe Login in a Partially Observable Attacker Model	FINANCIAL CRYPTOGRAPHY AND DATA SECURITY	Lecture Notes in Computer Science		English	Proceedings Paper	14th Financial Cryptography and Data Security International Conference	JAN 25-28, 2010	Tenerife, SPAIN					Secure login methods based on human cognitive skills can be classified into two categories based on information available to a passive attacker: (i) the attacker fully observes the entire input and output of a login procedure, (ii) the attacker only partially observes the input and output. Login methods secure in the fully observable model imply very long secrets and/or complex calculations. In this paper, we study three simple PIN-entry methods designed for the partially observable attacker model. A notable feature of the first method is that the user needs to perform a very simple mathematical operation, whereas, in the other two methods, the user performs a simple table lookup. Our usability study shows that all the methods have reasonably low login times and minimal error rates. These results, coupled with low-cost hardware requirements (only earphones), are a significant improvement over existing approaches for this model [9,10]. We also show that side-channel timing attacks present a real threat to the security of login schemes based on human cognitive skills.	[Perkovic, Toni; Cagalj, Mario] Univ Split, FESB, Split, Croatia	Perkovic, T (reprint author), Univ Split, FESB, Split, Croatia.						BACKES M, 2008, IEEE S SEC PRIV MAY; Brooke J., 1996, USABILITY EVALUATION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GOLLE P., 2007, P IEEE S SEC PRIV; Hopper N.J., 2001, LNCS, V2248, P52; KOCHER P., 1996, LECT NOTES COMPUTER, V1109, P104; KUBER R, 2006, INTERACTIVE EXPERIEN; O'Rourke N., 2005, STEP BY STEP APPROAC; SASAMOTO H, 2008, ACM C HIM FACT COMP; TARI F, 2006, SOUPS; WEINSHALL D., 2006, P IEEE S SEC PRIV; WILFONG GT, 1999, METHOD APPARTUS SECU; SCI BEHIND PASSFACES	13	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-14576-6	LECT NOTES COMPUT SC			2010	6052						351	358				8	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BTC09	WOS:000286416700029	
J	Gayer, G				Gayer, Gabrielle			Perception of probabilities in situations of risk: A case based approach	GAMES AND ECONOMIC BEHAVIOR			English	Article						Distortion of probabilities; Case based decision theory; Similarity	PROSPECT-THEORY; SIMILARITY; DECISION; UNCERTAINTY; UTILITY; CHOICE	This paper provides a description of a possible mental process individuals go through in their attempt to comprehend stated probabilities in simple lotteries. The evaluation of probabilities is based on the following main components: lotteries encountered in the past, the realizations of these lotteries, and the similarity between stated probabilities. A probability is evaluated based on the experienced relative frequencies of outcomes that had that stated probability, as well as outcomes of other lotteries that had similar stated probabilities. This process may result in distortion of probabilities as observed in the literature, and in particular, in overvaluing low probabilities and undervaluing high probabilities. If the decision maker uses a less permissive similarity function as the size of memory grows, she will learn the real value of the stated probabilities. If, however, the similarity function is independent of memory, biases persist even when data are accumulated. (C) 2009 Elsevier Inc. All rights reserved.	Univ Haifa, Dept Econ, IL-31905 Haifa, Israel	Gayer, G (reprint author), Univ Haifa, Dept Econ, IL-31905 Haifa, Israel.	gabi.gayer@gmail.com					Akaike H., 1954, ANN I STAT MATH, V6, P127, DOI 10.1007/BF02900741; Allais M, 1953, ECONOMETRICA, V21, P503, DOI 10.2307/1907921; Berger J. O., 1985, STAT DECISION THEORY; Billot A, 2008, MATH SOC SCI, V55, P107, DOI 10.1016/j.mathsocsci.2007.08.002; Billot A, 2005, ECONOMETRICA, V73, P1125, DOI 10.1111/j.1468-0262.2005.00611.x; Chew S., 1983, ECONOMETRICA, V51, P1065; COMBS B, 1979, JOURNALISM QUART, V56, P837; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1983, ANN STAT, V11, P896, DOI 10.1214/aos/1176346255; Devroye L.P., 1985, NONPARAMETRIC DENSIT; Duda R., 1973, PATTERN CLASSIFICATI; Gilboa I., 2001, THEORY CASE BASED DE; GILBOA I, 1995, Q J ECON, V110, P605, DOI 10.2307/2946694; Gilboa I, 2006, REV ECON STAT, V88, P433, DOI 10.1162/rest.88.3.433; Gilboa I, 2003, ECONOMETRICA, V71, P1, DOI 10.1111/1468-0262.00388; Guerdjikova A, 2008, GAME ECON BEHAV, V63, P107, DOI 10.1016/j.geb.2007.10.004; Hertwig R, 2004, PSYCHOL SCI, V15, P534, DOI 10.1111/j.0956-7976.2004.00715.x; KAHNEMAN D, 1979, ECONOMETRICA, V47, P263, DOI 10.2307/1914185; Morgenstern O., 1944, THEORY GAMES EC BEHA; Mosteller F, 1951, J POLIT ECON, V59, P371, DOI 10.1086/257106; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Prakasa-Rao B.L.S., 1983, NONPARAMETRIC FUNCTI; PRESTON MG, 1948, AM J PSYCHOL, V61, P183, DOI 10.2307/1416964; Quiggin J., 1982, J ECON BEHAV ORGAN, V3, P225; Rosenblatt M., 1956, ANN MATH STAT, V27, P642; RUBINSTEIN A, 1988, J ECON THEORY, V46, P145, DOI 10.1016/0022-0531(88)90154-8; SHEPARD RN, 1987, SCIENCE, V237, P1317, DOI 10.1126/science.3629243; TVERSKY A, 1992, J RISK UNCERTAINTY, V5, P297, DOI 10.1007/BF00122574; TVERSKY A, 1973, COGNITIVE PSYCHOL, V5, P207, DOI 10.1016/0010-0285(73)90033-9; TVERSKY A, 1974, SCIENCE, V185, P1124, DOI 10.1126/science.185.4157.1124; Ullah A, 1999, NONPARAMETRIC ECONOM; Wakker PP, 2004, PSYCHOL REV, V111, P236, DOI 10.1037/0033-295X.111.1.236; YAARI ME, 1987, ECONOMETRICA, V55, P95, DOI 10.2307/1911158	34	3	3	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0899-8256		GAME ECON BEHAV	Games Econ. Behav.	JAN	2010	68	1					130	143		10.1016/j.geb.2009.05.002		14	Economics	Business & Economics	547ZP	WOS:000273928700010	
S	Berthold, MR; Borgelt, C; Hoppner, F; Klawonn, F	Berthold, MR; Borgelt, C; Hoppner, F; Klawonn, F			Berthold, Michael R.; Borgelt, Christian; Hoeppner, Frank; Klawonn, Frank	Berthold, MR; Borgelt, C; Hoppner, F; Klawonn, F		Finding Predictors	GUIDE TO INTELLIGENT DATA ANALYSIS: HOW TO INTELLIGENTLY MAKE SENSE OF REAL DATA	Texts in Computer Science		English	Article; Book Chapter							LOCALLY WEIGHTED REGRESSION; ALGORITHMS		[Berthold, Michael R.] Univ Konstanz, FB Informat & Informat Wissensch, D-78457 Constance, Germany; [Borgelt, Christian] European Ctr Soft Comp, Intelligent Data Anal & Graph Models Res Unit, Mieres 33600, Asturias, Spain; [Hoeppner, Frank] Ostfalia Univ Appl Sci, FB Wirtschaft, D-38440 Wolfsburg, Germany; [Klawonn, Frank] Ostfalia Univ Appl Sci, FB Informat, D-38302 Wolfenbuttel, Germany	Berthold, MR (reprint author), Univ Konstanz, FB Informat & Informat Wissensch, D-78457 Constance, Germany.	Michael.Berthold@uni-konstanz.de; christian.borgelt@softcomputing.es; f.hoeppner@ostfalia.de; f.klawonn@ostfalia.de; Michael.Berthold@uni-konstanz.de; christian.borgelt@softcomputing.es; f.hoeppner@ostfalia.de; f.klawonn@ostfalia.de					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; AURENHAMMER F, 1991, ACM COMPUT SURV, V23, P345, DOI DOI 10.1145/116873.116880; BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93597.98741; BENTLEY JL, 1980, COMMUN ACM, V23, P214, DOI 10.1145/358841.358850; Blum M., 1973, Journal of Computer and System Sciences, V7, DOI 10.1016/S0022-0000(73)80033-9; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P49; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Burr Ridge I, 1997, MACHINE LEARNING; Chang C-C., 2001, LIBSVM LIB SUPPORT V; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; CLEVELAND WS, 1979, J AM STAT ASSOC, V74, P829, DOI 10.2307/2286407; CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P596, DOI 10.2307/2289282; Cormen T. H., 2001, INTRO ALGORITHMS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini Nello, 2004, KERNEL METHODS PATTE; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y., 1990, Proceedings of the Third Annual Workshop on Computational Learning Theory; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; Haykin S, 2008, NEURAL NETWORKS LEAR; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Manolopoulos Y., 2005, R TREES THEORY APPL; Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, DOI 10.1109/MCAS.2006.1688199; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Scholkopf B., 2001, LEARNING KERNELS SUP; SHAKHNAROVICH C, 2003, NEAREST NEIGHBOR MET; Smola A. J., 2003, TUTORIAL SUPPORT VEC; TROPF H, 1981, ANGEW INFORM, P71; Voronoi G, 1907, J REINE ANGEW MATH, V133, P97; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; XU L, 2008, ENCY ARTIFICIAL INTE, P318	36	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1868-0941	978-1-84882-259-7	TEXTS COMPUT SCI			2010							259	296		10.1007/978-1-84882-260-3_9	10.1007/978-1-84882-260-3	38	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BPV06	WOS:000280060600009	
S	Ghorbani, AA; Onut, IV		Romay, MG; Corchado, E; GarciaSebastian, MT		Ghorbani, Ali A.; Onut, Iosif-Viorel			Y-Means: An Autonomous Clustering Algorithm	HYBRID ARTIFICIAL INTELLIGENCE SYSTEMS, PT 1	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	5th International Conference on Hybrid Artificial Intelligence Systems	JUN 23-25, 2010	San Sebastian, SPAIN		Univ Pais Vasco	Clustering; Data mining; K-means; Machine learning; Unsupervised learning		This paper proposes an unsupervised clustering technique for data classification based on the K-means algorithm. The K-means algorithm is well known for its simplicity and low time complexity. However, the algorithm has three main drawbacks: dependency on the initial centroids, dependency on the number of clusters, and degeneracy. Our solution accommodates these three issues, by proposing an approach to automatically detect a semi-optimal number of clusters according to the statistical nature of the data. As a side effect; the method also makes choices of the initial centroid-seeds not critical to the clustering results. The experimental results show the robustness of the Y-means algorithm as well as its good performance against a set of other well known unsupervised clustering techniques. Furthermore, we study the performance of our proposed solution against different distance and outlier-detection functions and recommend the best combinations.	[Ghorbani, Ali A.; Onut, Iosif-Viorel] Univ New Brunswick, Fac Comp Sci, Fredericton, NB E3B 5A3, Canada	Ghorbani, AA (reprint author), Univ New Brunswick, Fac Comp Sci, Fredericton, NB E3B 5A3, Canada.						CHAN PK, 2005, LEARNING RULES CLUST, P81; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Dunn J. C., 1973, Journal of Cybernetics, V3; FRIGGE M, 1989, AM STAT, V43, P50, DOI 10.2307/2685173; GIBSON HR, 1994, ELEMENTARY STAT; Guan Y., 2003, P CAN C EL COMP ENG, P1083; Han J., 2001, DATA MINING CONCEPTS; Hansen P, 2001, PATTERN RECOGN, V34, P405, DOI 10.1016/S0031-3203(99)00216-2; Jain A, 1988, ALGORITHMS CLUSTER D; Kohonen T., 1997, SELF ORG MAP; Lei JZ, 2004, SECOND ANNUAL CONFERENCE ON COMMUNICATION NETWORKS AND SERVICES RESEARCH, PROCEEDINGS, P190; Lin Y. T., 2001, PATTERN RECOGN, V34, P415; LIPPMAN RP, 1987, P ASSP MAGAZINE, V4, P4; MacQueen J. B., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; MAHALANOBIS P, 2002, P NATL I SCI, V2, P49; Pelleg D., 2000, P 17 INT C MACH LEAR, P727; Portnoy L, 2001, P ACM CSS WORKSH DAT; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; Spath H., 1980, CLUSTERING ANAL ALGO, P1980; WALPOLE RE, 1983, ELEMENTARY STAT CONC; *MIT LINC LAB, 1998, INTR DET EV DAT SET; *U CA IRV, 1999, KNOWL DISC DAT MIN D	24	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-13768-6	LECT NOTES ARTIF INT			2010	6076						1	13				13	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BTF66	WOS:000286842000001	
S	Tellaeche, A; Arana, R; Ibarguren, A; Martinez-Otzeta, JM		Romay, MG; Corchado, E; GarciaSebastian, MT		Tellaeche, A.; Arana, R.; Ibarguren, A.; Martinez-Otzeta, J. M.			Automatic Quality Inspection of Percussion Cap Mass Production by Means of 3D Machine Vision and Machine Learning Techniques	HYBRID ARTIFICIAL INTELLIGENCE SYSTEMS, PT 1	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	5th International Conference on Hybrid Artificial Intelligence Systems	JUN 23-25, 2010	San Sebastian, SPAIN		Univ Pais Vasco	3D imaging; high speed inspection; machine learning classifiers		The exhaustive quality control is becoming very important in the world's globalized market. One of these examples where quality control becomes critical is the percussion cap mass production. These elements must achieve a minimum tolerance deviation in their fabrication. This paper outlines a machine vision development using a 3D camera for the inspection of the whole production of percussion caps. This system presents multiple problems, such as metallic reflections in the percussion caps, high speed movement of the system and mechanical errors and irregularities in percussion cap placement. Due to these problems, it is impossible to solve the problem by traditional image processing methods, and hence, machine learning algorithms have been tested to provide a feasible classification of the possible errors present in the percussion caps.	[Tellaeche, A.; Arana, R.; Ibarguren, A.; Martinez-Otzeta, J. M.] Fdn Tekniker, Eibar 20600, Gipuzkoa, Spain	Tellaeche, A (reprint author), Fdn Tekniker, Av Otaola 20, Eibar 20600, Gipuzkoa, Spain.	atellaeche@tekniker.es; rarana@tekniker.es; aibarguren@tekniker.es; jmmartinez@tekniker.es					Boehnke K.E., 2008, THESIS POLITEHNICA U; Bosche F, 2010, ADV ENG INFORM, V24, P107, DOI 10.1016/j.aei.2009.08.006; Castillo E, 1997, MONOGRAPHS COMPUTER, P481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Draper NR, 1998, APPL REGRESSION ANAL; Friedman N, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1277; Gonzalez R.C., 2008, DIGITAL IMAGE PROCES; Jensen F.V., 2007, INFORM SCI STAT; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kuncheva L., 2004, COMBINING PATTERN CL; Leopold J, 2003, MEASUREMENT, V33, P179, DOI 10.1016/S0263-2241(02)00056-8; Li QG, 2010, MEAS SCI TECHNOL, V21, DOI 10.1088/0957-0233/21/1/015702; PICONRUIZ A, 2010, DYNA, V84, P733; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, INDUCTION DECISION T, V1, P81, DOI DOI 10.1007/BF00116251; Shakhnarovich G., 2005, NEAREST NEIGHBOR MET; Tellaeche A, 2008, PATTERN RECOGN, V41, P521, DOI 10.1016/j.pateog.2007.07.007	19	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-13768-6	LECT NOTES ARTIF INT			2010	6076						270	277				8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BTF66	WOS:000286842000033	
S	Hua, Q; Ji, AB; He, Q			IEEE	Hua, Qiang; Ji, Aibing; He, Qiang			Multiple Real-valued K Nearest Neighbor Classifiers System by Feature Grouping	IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS (SMC 2010)	IEEE International Conference on Systems Man and Cybernetics Conference Proceedings		English	Proceedings Paper	IEEE International Conference on Systems, Man and Cybernetics	OCT 10-13, 2010	Istanbul, TURKEY	IEEE			FEATURE SUBSETS	This paper proposes a method to fuse Real-valued K nearest neighbor classifier by feature grouping. Real-valued K nearest neighbor classifier can approximate continuous-valued target functious, which can provide more information than crisp K nearest neighbor classifier in fusion. In addition real-valued K nearest neighbor classifier is sensitive to feature perturbation. Therefore, when multiple real-valued K nearest neighbor classifiers are fused by feature grouping, the performance of the fusion is better than single classifier. In order to validate the performance of fusion, four datasets are selected from vel Repository. Experimental results show that the performance of fusion is better than single classifier and multiple classifier system by other perturbations.	[Hua, Qiang; Ji, Aibing] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Engn, Nanjing 210016, Peoples R China	Hua, Q (reprint author), Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Engn, Nanjing 210016, Peoples R China.	huaq@nuaa.edu.cn					Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Bryll R, 2003, PATTERN RECOGN, V36, P1291, DOI 10.1016/S0031-3203(02)00121-8; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Lam L, 1997, IEEE T SYST MAN CY A, V27, P553, DOI 10.1109/3468.618255; Mitchell Tom M., 2003, MACHINE LEARNING; Vishwath P., 2004, Information fusion, P239; Wang LJ, 2008, INT J INNOV COMPUT I, V4, P369; [Anonymous], UCI REP MACH LEARN D; [Anonymous], Croel repository	11	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X	978-1-4244-6588-0	IEEE SYS MAN CYBERN			2010												4	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Information Systems	Computer Science	BWU85	WOS:000295015304022	
S	Wu, QO; Tan, SB; Duan, MY; Cheng, XQ		Cheng, PJ; Kan, MY; Lam, W; Nakov, P		Wu, Qiong; Tan, Songbo; Duan, Miyi; Cheng, Xueqi			A Two-Stage Algorithm for Domain Adaptation with Application to Sentiment Transfer Problems	INFORMATION RETRIEVAL TECHNOLOGY	Lecture Notes in Computer Science		English	Proceedings Paper	6th Asia Information Retrieval Societies Conference	DEC 01-03, 2010	Taipei, TAIWAN	Natl Taiwan Univ, Natl Sci Council, Republ China, Minist Educ, Republ China		Domain Adaptation; Sentiment Classification; Information Retrieval	CLASSIFICATION; REFINEMENT; EM	Classification systems are typically domain-specific, and the performance decreases sharply when transferred from one domain to another domain. Building these systems involves annotating a large amount of data for every domain, which needs much human labor. So, a reasonable way is to utilize labeled data in one existing (or called source) domain for classification in target domain. To address this problem, we propose a two-stage algorithm for domain adaptation. At the first transition stage, we share the information between the source domain and the target domain to get some most confidently labeled documents in the target domain, and at the second transmission stage, we exploit them to label the target-domain data via following the intrinsic structure revealed by the target domain. The experimental results on sentiment data indicate that the proposed approach could improve the performance of domain adaptation dramatically.	[Wu, Qiong; Tan, Songbo; Duan, Miyi; Cheng, Xueqi] Chinese Acad Sci, Inst Comp Technol, Beijing 100864, Peoples R China	Wu, QO (reprint author), Chinese Acad Sci, Inst Comp Technol, Beijing 100864, Peoples R China.	wuqiong@software.ict.ac.cn; tansongbo@software.ict.ac.cn; duanmiyi@software.ict.ac.cn; cxq@ict.ac.cn	Cheng, Xueqi/F-1706-2010; Tan, Songbo/A-7450-2012				Andreevskaia A., 2008, ACL 2008, P290; AUE A, 2005, RANLP 2005; Carroll S.M., 1989, P IJCNN P, V1, P607; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CUI H, 2006, AM ASS ART INT P 200, P1265; Dai W., 2007, AAAI, P540; Daume H, 2006, J ARTIF INTELL RES, V26, P101; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; JIANG J, 2007, CIKM 2007, P401; JOACHIMS T, 1998, TEXT CATEGORIZATION, P137; Joachims T., 1999, TRANSDUCTIVE INFEREN, P200; LANQUILLON C, 2000, LNCS LNAI, V1910, P167; LEWIS D, 1992, THESIS AMHERST MA US; LUO P, 2008, CIKM 2008, P103; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Pang B., 2002, EMNLP 02, P79; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; TAN S, 2009, ECIR 2009, P337; TAN S, 2005, CIKM 2005, P469; Tan SB, 2006, EXPERT SYST APPL, V30, P290, DOI 10.1016/j.eswa.2005.07.019; Tan SH, 2007, RAFFLES B ZOOL, pIII; WU Q, 2009, ACL 2009, P317; Xing DK, 2007, LECT NOTES ARTIF INT, V4702, P324; Zhou D., 2003, NIPS, P169	24	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-17186-4	LECT NOTES COMPUT SC			2010	6458						443	453				11	Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BUF65	WOS:000289174800043	
B	Kruatrachue, B; Choowong, T			IEEE	Kruatrachue, Boontee; Choowong, Teeratorn			Prototype Selection using Reinforcement Learning and Minimal Consistent Subset Identification guide	INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS 2010)			English	Proceedings Paper	International Conference on Control, Automation and Systems (ICCAS 2010)	OCT 27-30, 2010	Gyeonggi do, SOUTH KOREA	Natl IT Ind Promot Agcy, Korean Federat Sci & Technol Soc, Korea Natl Tourism Org, Hyundai Heavy Ind Co, POSCO, LS Ind Syst Co, Samsung Heavy Ind Co, Autopower Co, Gangneung Wonju Natl Univ		reinforcement learning; prototype selection; minimal consistent subset; nearest neighbor classification	CLASSIFICATION	This paper try to apply Reinforcement Learning (RL) to a task with large number of states. This usually is a difficult task since RL has less chance to visit all state or has enough number of visit to learn average reward accurately. Moreover, RL may not be able to learn or obtain any optimal solution as RL learn by averaging rewards from each action performing in each state. In order to alleviate this RL learning problem, any solution to a task such as, non-optimal algorithm or heuristics can collaborate with RL by using their knowledge to prune the non-optimal action in each state. This reduces search space of RL and helps it learn faster. A Minimal consistent subset problem is used as an example to demonstrate how RL can learn faster with the help of other heuristics.	[Kruatrachue, Boontee; Choowong, Teeratorn] King Mongkuts Inst Technol Ladkrabang, Fac Engn, Bangkok, Thailand	Kruatrachue, B (reprint author), King Mongkuts Inst Technol Ladkrabang, Fac Engn, Bangkok, Thailand.	booontee@yahoo.com; teeraongawa@hotmail.com					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; Sutton R. S., 1998, REINFORCEMENT LEARNI; *U CA DEP INF COMP, 1998, UCI MACH LEARN REP	5	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-89-93215-02-1				2010							2320	2323				4	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	BWU79	WOS:000294964400496	
S	Saeedmanesh, M; Izadi, T; Ahvar, E		Ao, SI; Castillo, O; Douglas, C; Feng, DD; Lee, JA		Saeedmanesh, M.; Izadi, T.; Ahvar, E.			HDM: A Hybrid Data Mining Technique for Stock Exchange Prediction	INTERNATIONAL MULTICONFERENCE OF ENGINEERS AND COMPUTER SCIENTISTS (IMECS 2010), VOLS I-III	Lecture Notes in Engineering and Computer Science		English	Proceedings Paper	International Multi-Conference of Engineers and Computer Scientists 2010	MAR 17-19, 2010	Hong Kong, PEOPLES R CHINA	IAENG Soc Artificial Intelligence, IAENG Soc Bioinformat, IAENG Soc Comp Sci, IAENG Soc Data Mining, IAENG Soc Elect Engn, IAENG Soc Imaging Engn, IAENG Soc Ind Engn, IAENG Soc Internet Comp & Web Serv, IAENG Soc Sci Comp, IAENG Soc Software Engn, IAENG Soc Wireless Networks		stock exchange; data mining; prediction	ARTIFICIAL NEURAL-NETWORKS; CLASSIFICATION; INDEX	This paper(3) addresses the accuracy of predictions in stock exchange using data mining methods. To do this we modeled the problem by means of a time series. After this, a novel data mining technique is used to classify data. The proposed technique combines the advantages of time series analysis and data mining approaches in order to enhance the prediction accuracy. In order to evaluate the proposed technique, it is compared with the well known data mining techniques. In comparisons we used the Dow Jones Industrial data for all methods to have fair comparison. Results show that the proposed technique has at least 34% improvement in prediction accuracy.	[Saeedmanesh, M.; Izadi, T.] Azad Univ, Dept Comp Engn, Mashhad, Iran	Saeedmanesh, M (reprint author), Azad Univ, Dept Comp Engn, Mashhad, Iran.	m.saeedmanesh@iau-aligudarz.ac.ir; t-izadi@iau-arak.ac.ir; ehssana2000@yahoo.com					Athitsos V., 2005, P CVPR 05 IEEE COMP; Athitsos V, 2005, PROC CVPR IEEE, P486; Baestaens D.J.E., 1996, FORECASTING FINANCIA, P254; Bauer R. J., 1994, GENETIC ALGORITHMS I; Caldwell R., 1997, P 1 INFFC FIN TECHN; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Creedy J., 1997, NONLINEAR EC MODELS; Hann TH, 1996, NEUROCOMPUTING, V10, P323, DOI 10.1016/0925-2312(95)00137-9; Kamijo K., 1990, P INT JOINT C NEUR N, P215; Kantardzic M., 2003, DATA MINING CONCEPTS; Katz J.O., 1994, NEUROVEST J, V2, P5; Kim KJ, 2000, EXPERT SYST APPL, V19, P125, DOI 10.1016/S0957-4174(00)00027-0; Kohara K., 1997, International Journal of Intelligent Systems in Accounting, Finance and Management, V6, DOI 10.1002/(SICI)1099-1174(199703)6:1<11::AID-ISAF115>3.3.CO;2-V; Latourrette M, 2000, P 11 EUR C MACH LEAR, P238; Peng J, 2001, CVPR 01, P58; Quah TS, 1999, EXPERT SYST APPL, V17, P295, DOI 10.1016/S0957-4174(99)00041-X; Tang Z.H., 2005, DATA MINING SQL SERV; Trippi R.R., 1992, J PORTFOLIO MANAGE, V19, P309; Tsaih R, 1998, DECIS SUPPORT SYST, V23, P161, DOI 10.1016/S0167-9236(98)00028-1; Weigend A. S., 1993, TIME SERIES PREDICTI; Witten I. H., 2000, DATA MINING PRACTICA; Yoon Y., 1991, P 24 ANN HAW INT C S, P156; YU XH, 1992, IEEE T NEURAL NETWOR, V3, P1019, DOI 10.1109/72.165604; Zhang GQ, 1998, INT J FORECASTING, V14, P35, DOI 10.1016/S0169-2070(97)00044-7; Zhang H, 2006, CVPR, P2126	25	0	0	INT ASSOC ENGINEERS-IAENG	HONG KONG	UNIT1, 1-F, 37-39 HUNG TO ROAD, KWUN TONG, HONG KONG, 00000, PEOPLES R CHINA	2078-0958	978-988-17012-8-2	LECT NOTES ENG COMP			2010							587	592				6	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BAB67	WOS:000303703800108	
B	Mittard-Runte, V; Bekel, T; Blom, J; Dondrup, M; Henckel, K; Jaenicke, S; Krause, L; Linke, B; Neuweger, H; Schneiker-Bekel, S; Goesmann, A	Cock, JM; TessmarRaible, K; Boyen, C; Viard, F			Mittard-Runte, Virginie; Bekel, Thomas; Blom, Jochen; Dondrup, Michael; Henckel, Kolja; Jaenicke, Sebastian; Krause, Lutz; Linke, Burkhard; Neuweger, Heiko; Schneiker-Bekel, Susanne; Goesmann, Alexander	Cock, JM; TessmarRaible, K; Boyen, C; Viard, F		Practical Guide: Genomic Techniques and How to Apply Them to Marine Questions	INTRODUCTION TO MARINE GENOMICS			English	Article; Book Chapter							PROTEIN-CODING GENES; HIDDEN MARKOV MODEL; NUCLEOTIDE-SEQUENCE DATABASE; SELF-TRAINING METHOD; MICROARRAY DATA; MICROBIAL GENOMES; CODON USAGE; DROSOPHILA-MELANOGASTER; OLIGONUCLEOTIDE ARRAYS; EXPRESSION PATTERNS	In recent years, modern high-throughput techniques in genome and post-genome research have made a marked impact on the marine sciences. Today, massively parallel DNA sequencing and hybridization approaches allow the identification of not only the gene repertoire but also the gene regulatory networks that function within an organism. The huge amounts of data acquired from such experiments can only be handled with intensive bioinformatics support that has to provide an adequate infrastructure for storing and analysing these data. Bioinformatics has to deliver efficient data analysis algorithms, user-friendly tools and software applications, as well as extensive hardware infrastructure to deal with these genome-scale analyses. The following chapter briefly introduces not only the most relevant topics of bioinformatics for functional and structural genomics but also addresses the practical aspects of other steps of a genome project such as sequencing or data management issues. The chapter will take the reader through the different technical approaches that can be applied in marine genomics projects. In the first part, we will mainly focus on data generation, introducing classical genome sequencing approaches such as the Sanger method and the shotgun technique. Moreover, a short overview of the current status of the next generation of sequencing techniques will be given. In the second part, we briefly introduce the concept of data management for bioinformatics applications. In the third part, we describe the basic principles of genome sequence analysis and address topics like EST clustering and genome assembly, gene prediction, gene function assignment and classification as well as whole genome annotation. In the fourth part of this chapter, we present an overview of transcriptome data analysis using microarray hybridization technology. After a brief introduction to microarray technology we describe state-of-the-art methods for image processing, data normalization, significance testing and cluster analysis.	[Mittard-Runte, Virginie; Bekel, Thomas; Blom, Jochen; Henckel, Kolja; Jaenicke, Sebastian; Linke, Burkhard; Neuweger, Heiko; Goesmann, Alexander] Univ Bielefeld, CeBiTec, BRF Computat Genom Grp, D-33594 Bielefeld, Germany; [Dondrup, Michael] Unit BCCS, Computat Biol Unit, N-5008 Bergen, Norway; [Krause, Lutz] Nestle Res Ctr, BioAnalyt Sci Dept, CH-1000 Lausanne 26, Switzerland; [Schneiker-Bekel, Susanne] Univ Bielefeld, CeBiTec, Int NRW Grad Sch Bioinformat & Genome Res, D-33594 Bielefeld, Germany	Mittard-Runte, V (reprint author), Univ Bielefeld, CeBiTec, BRF Computat Genom Grp, D-33594 Bielefeld, Germany.	vrunte@cebitec.uni-bielefeld.de; thomas.bekel@cebitec.uni-bielefeld.de; jblom@cebitec.uni-bielefeld.de; michael.dondrup@bccs.uib.no; khenckel@cebitec.uni-bielefeld.de; sjaenick@cebitec.uni-bielefeld.de; lutz.krause@rdls.nestle.com; burkhard.linke@cebitec.uni-bielefeld.de; hneuwege@cebitec.uni-bielefeld.de; Susanne.Schneiker@cebitec.uni-bielefeld.de; agoesman@cebitec.uni-bielefeld.de	Krause, Lutz/G-6283-2013	Krause, Lutz/0000-0003-3806-0845			ADAMS CP, 1997, Patent No. 5641658; Alexandersson M, 2003, GENOME RES, V13, P496, DOI 10.1101/gr.424203; Allen JE, 2005, BIOINFORMATICS, V21, P3596, DOI 10.1093/bioinformatics/bti609; Allison DB, 2006, NAT REV GENET, V7, P55, DOI 10.1038/nrg1749; ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Ashburner M, 2000, NAT GENET, V25, P25; Aziz RK, 2008, BMC GENOMICS, V9, DOI 10.1186/1471-2164-9-75; Badger JH, 1999, MOL BIOL EVOL, V16, P512; Bairoch A, 2008, NUCLEIC ACIDS RES, V36, pD190, DOI 10.1093/nar/gkm895; Baldi P, 2001, BIOINFORMATICS, V17, P509, DOI 10.1093/bioinformatics/17.6.509; Ball CA, 2004, PLOS BIOL, V2, P1276, DOI 10.1371/journal.pbio.0020317; Bammler T, 2005, NAT METHODS, V2, P351; Barrett T., 2007, NUCLEIC ACIDS RES, V35, P760; Bartels D, 2005, BIOINFORMATICS, V21, P853, DOI 10.1093/bioinformatics/bti091; BAUERLE RH, 1966, P NATL ACAD SCI USA, V56, P111, DOI 10.1073/pnas.56.1.111; Bekel T, 2009, J BIOTECHNOL, V140, P3, DOI 10.1016/j.jbiotec.2009.01.006; Bendtsen JD, 2004, J MOL BIOL, V340, P783, DOI 10.1016/j.jmb.2004.05.028; Benson DA, 2008, NUCLEIC ACIDS RES, V36, pD25, DOI 10.1093/nar/gkm929; Berman H, 2003, NAT STRUCT BIOL, V10, P980, DOI 10.1038/nsb1203-980; Besemer J, 2001, NUCLEIC ACIDS RES, V29, P2607, DOI 10.1093/nar/29.12.2607; Besemer J, 2005, NUCLEIC ACIDS RES, V33, pW451, DOI 10.1093/nar/gki487; Birney E, 2004, GENOME RES, V14, P988, DOI 10.1101/gr.1865504; Black MA, 2002, BIOINFORMATICS, V18, P1609, DOI 10.1093/bioinformatics/18.12.1609; Brazma A, 2001, NAT GENET, V29, P365, DOI 10.1038/ng1201-365; BREJOVA B, 2005, BIOINFORMATICS, V21, P57; Brent MR, 2007, NAT BIOTECHNOL, V25, P883, DOI 10.1038/nbt0807-883; Brunak S, 2002, SCIENCE, V298, P1333; Burge C, 1997, J MOL BIOL, V268, P78, DOI 10.1006/jmbi.1997.0951; Chen YA, 2007, BMC GENOMICS, V8, DOI 10.1186/1471-2164-8-416; Chothia C, 2003, SCIENCE, V300, P1701, DOI 10.1126/science.1085371; Cochrane G, 2008, NUCLEIC ACIDS RES, V36, pD5, DOI 10.1093/nar/gkm1018; Cochrane G, 2006, OMICS, V10, P105, DOI 10.1089/omi.2006.10.105; Codd E.F., 1990, RELATIONAL MODEL DAT; Conesa A, 2005, BIOINFORMATICS, V21, P3674, DOI 10.1093/bioinformatics/bti610; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dandekar T, 1998, TRENDS BIOCHEM SCI, V23, P324, DOI 10.1016/S0968-0004(98)01274-2; Datson NA, 1999, NUCLEIC ACIDS RES, V27, P1300, DOI 10.1093/nar/27.5.1300; Delcher AL, 1999, NUCLEIC ACIDS RES, V27, P4636, DOI 10.1093/nar/27.23.4636; Delcher AL, 2007, BIOINFORMATICS, V23, P673, DOI 10.1093/bioinformatics/btm009; Demeter J, 2007, NUCLEIC ACIDS RES, V35, pD766, DOI 10.1093/nar/gkl1019; Djebali S, 2006, GENOME BIOL, V7, DOI 10.1186/gb-2006-7-s1-s7; Dondrup M, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-50; Dondrup M, 2003, J BIOTECHNOL, V106, P135, DOI 10.1016/j.jbiotec.2003.08.010; Dressman D, 2003, P NATL ACAD SCI USA, V100, P8817, DOI 10.1073/pnas.1133470100; Durbin R, 1998, BIOL SEQUENCE ANAL; Edwards RA, 2006, BMC GENOMICS, V7, DOI 10.1186/1471-2164-7-57; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Elsik CG, 2007, GENOME BIOL, V8, DOI 10.1186/gb-2007-801-r13; Emanuelsson O, 1999, PROTEIN SCI, V8, P978; Emanuelsson O, 2007, NAT PROTOC, V2, P953, DOI 10.1038/nprot.2007.131; Ewing B, 1998, GENOME RES, V8, P175; Fedurco M, 2006, NUCLEIC ACIDS RES, V34, DOI 10.1093/nar/gnj023; FLEISCHMANN RD, 1995, SCIENCE, V269, P496, DOI 10.1126/science.7542800; Flicek P, 2008, NUCLEIC ACIDS RES, V36, pD707, DOI 10.1093/nar/gkm988; Florea L, 1998, GENOME RES, V8, P967; Gaasterland T, 2000, GENOME RES, V10, P502, DOI 10.1101/gr.10.4.502; Gartemann KH, 2008, J BACTERIOL, V190, P2138, DOI 10.1128/JB.01595-07; Gentleman R., 2005, BIOINFORMATICS COMPU; GENTLEMAN RC, 2004, GENOME BIOL, V5, P80; Goesmann A, 2005, NUCLEIC ACIDS RES, V33, pW710, DOI 10.1093/nar/gki400; Goldberg SMD, 2006, P NATL ACAD SCI USA, V103, P11240, DOI 10.1073/pnas.0604351103; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gordon D, 2001, GENOME RES, V11, P614, DOI 10.1101/gr.171401; Gordon D, 1998, GENOME RES, V8, P195; GOUY M, 1982, NUCLEIC ACIDS RES, V10, P7055, DOI 10.1093/nar/10.22.7055; Green P, 2002, P NATL ACAD SCI USA, V99, P4143, DOI 10.1073/pnas.082095999; Gresham D, 2006, SCIENCE, V311, P1932, DOI 10.1126/science.1123726; Gross SS, 2006, J COMPUT BIOL, V13, P379, DOI 10.1089/cmb.2006.13.379; Guigo R, 2005, NAT METHODS, V2, P575, DOI 10.1038/nmeth0805-575; Guigo R, 2006, GENOME BIOL, V7, DOI 10.1186/gb-2006-7-s1-s2; Guo FB, 2003, NUCLEIC ACIDS RES, V31, P1780, DOI 10.1093/nar/gkg254; Haas BJ, 2008, GENOME BIOL, V9, DOI 10.1186/gb-2008-9-1-r7; Henrick K, 2008, NUCLEIC ACIDS RES, V36, pD426, DOI 10.1093/nar/gkm937; Herring CD, 2006, NAT GENET, V38, P1406, DOI 10.1038/ng1906; Huang XQ, 1999, GENOME RES, V9, P868, DOI 10.1101/gr.9.9.868; Huang XQ, 1997, GENOMICS, V46, P37, DOI 10.1006/geno.1997.4984; IIZUKA M, 1994, BIOCHEM BIOPH RES CO, V205, P1474, DOI 10.1006/bbrc.1994.2831; Iseli C, 1999, P INT C INTELL SYST, V7, P138; Ju JY, 2006, P NATL ACAD SCI USA, V103, P19635, DOI 10.1073/pnas.0609513103; Kaiser O, 2003, J BIOTECHNOL, V106, P121, DOI 10.1016/j.jbiotec.2003.08.008; Kall L, 2007, NUCLEIC ACIDS RES, V35, pW429, DOI 10.1093/nar/gkm256; Kanehisa M, 2000, NUCLEIC ACIDS RES, V28, P27, DOI 10.1093/nar/28.1.27; Kent WJ, 2002, GENOME RES, V12, P656, DOI [10.1101/gr.229202, 10.1101/gr.229202. Article published online before March 2002]; Korf I, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-59; Korf I, 2001, Bioinformatics, V17 Suppl 1, pS140; Krause A, 2006, NAT BIOTECHNOL, V24, P1385, DOI 10.1038/nbt1243; Krause L, 2007, NUCLEIC ACIDS RES, V35, P540, DOI 10.1093/nar/gkl1083; Krogh A, 2001, J MOL BIOL, V305, P567, DOI 10.1006/jmbi.2000.4315; Kuster H, 2007, PHYTOCHEMISTRY, V68, P19, DOI 10.1016/j.phytochem.2006.09.026; Lafay B, 1999, NUCLEIC ACIDS RES, V27, P1642, DOI 10.1093/nar/27.7.1642; Lagesen K, 2007, NUCLEIC ACIDS RES, V35, P3100, DOI 10.1093/nar/gkm160; LANDER E S, 1988, Genomics, V2, P231, DOI 10.1016/0888-7543(88)90007-9; Larsen TS, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-21; Lawrence JG, 1996, GENETICS, V143, P1843; Lee MLT, 2000, P NATL ACAD SCI USA, V97, P9834, DOI 10.1073/pnas.97.18.9834; Li C, 2001, P NATL ACAD SCI USA, V98, P31, DOI 10.1073/pnas.011404098; Li SYS, 2005, STAT MED, V24, P2267, DOI 10.1002/sim.2119; Lin M, 2004, BIOINFORMATICS, V20, P1233, DOI 10.1093/bioinformatics/bth069; Linke Burkhard, 2006, Appl Bioinformatics, V5, P193, DOI 10.2165/00822942-200605030-00008; Liolios K, 2008, NUCLEIC ACIDS RES, V36, pD475, DOI 10.1093/nar/gkm884; LIPSHUTZ RJ, 1995, BIOTECHNIQUES, V19, P442; Lipshutz RJ, 1999, NAT GENET, V21, P20, DOI 10.1038/4447; Liu JJ, 2005, BIOINFORMATICS, V21, P2691, DOI 10.1093/bioinformatics/bti419; Lomsadze A, 2005, NUCLEIC ACIDS RES, V33, P6494, DOI 10.1093/nar/gki937; Lowe TM, 1997, NUCLEIC ACIDS RES, V25, P955, DOI 10.1093/nar/25.5.955; Lukashin AV, 1998, NUCLEIC ACIDS RES, V26, P1107, DOI 10.1093/nar/26.4.1107; Majoros WH, 2005, BIOINFORMATICS, V21, P1782, DOI 10.1093/bioinformatics/bti297; Majoros WH, 2004, BIOINFORMATICS, V20, P2878, DOI 10.1093/bioinformatics/bth315; Mangalam Harry, 2002, Brief Bioinform, V3, P296, DOI 10.1093/bib/3.3.296; Mao XZ, 2005, BIOINFORMATICS, V21, P3787, DOI 10.1093/bioinformatics/bti430; Mardis ER, 2008, ANNU REV GENOM HUM G, V9, P387, DOI 10.1146/annurev.genom.9.081307.164359; Margulies M, 2005, NATURE, V437, P376, DOI 10.1038/nature03959; Mathe C, 2002, NUCLEIC ACIDS RES, V30, P4103, DOI 10.1093/nar/gkf543; Matsumura H, 2003, P NATL ACAD SCI USA, V100, P15718, DOI 10.1073/pnas.2536670100; Maurer M, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-101; McHardy AC, 2004, PROTEOMICS, V4, P46, DOI 10.1002/pmic.200300501; McHardy AC, 2004, BIOINFORMATICS, V20, P1622, DOI 10.1093/bioinformatics/bth137; Meyer F, 2003, NUCLEIC ACIDS RES, V31, P2187, DOI 10.1093/nar/gkg312; Millar CD, 2008, TRENDS ECOL EVOL, V23, P386, DOI 10.1016/j.tree.2008.04.002; Miron M, 2006, TRENDS GENET, V22, P84, DOI 10.1016/j.tig.2005.12.001; Moore JE, 2003, NUCLEIC ACIDS RES, V31, P7271, DOI 10.1093/nar/gkg905; Mott R, 1997, COMPUT APPL BIOSCI, V13, P477; Mulder N., 2007, NUCLEIC ACIDS RES, V35, P224; Nagaraj SH, 2007, NUCLEIC ACIDS RES, V35, pW143, DOI 10.1093/nar/gkm378; Nakano M, 2003, J BIOTECHNOL, V102, P117, DOI 10.1016/S0168-1656(03)00023-3; NEEDLEMA.SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4; Nekrutenko A, 2003, NUCLEIC ACIDS RES, V31, P3564, DOI 10.1093/nar/gkg597; Ng P, 2005, NAT METHODS, V2, P105, DOI 10.1038/NMETH733; Ng P, 2006, NUCLEIC ACIDS RES, V34, DOI 10.1093/nar/gkl444; Tatusov RL, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-41; Noguchi H, 2006, NUCLEIC ACIDS RES, V34, P5623, DOI 10.1093/nar/gkl723; Ou HY, 2004, INT J BIOCHEM CELL B, V36, P535, DOI 10.1016/j.biocel.2003.08.013; Overbeek R, 1999, P NATL ACAD SCI USA, V96, P2896, DOI 10.1073/pnas.96.6.2896; Overbeek R, 2003, NUCLEIC ACIDS RES, V31, P164, DOI 10.1093/nar/gkg148; OVERBEEK R, 2004, COMMUN ACM, V47, P47; Overbeek R, 2005, NUCLEIC ACIDS RES, V33, P5691, DOI 10.1093/nar/gki866; Overbeek R, 2000, NUCLEIC ACIDS RES, V28, P123, DOI 10.1093/nar/28.1.123; Page GP, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-84; PAN W, 2002, GENOME BIOL; Parkinson H, 2007, NUCLEIC ACIDS RES, V35, pD747, DOI 10.1093/nar/gkl995; Parra G, 2003, GENOME RES, V13, P108, DOI 10.1101/gr.871403; Pavlidis P, 2002, J COMPUT BIOL, V9, P401, DOI 10.1089/10665270252935539; PEARSON WR, 1988, P NATL ACAD SCI USA, V85, P2444, DOI 10.1073/pnas.85.8.2444; Pertea G, 2003, BIOINFORMATICS, V19, P651, DOI 10.1093/bioinformatics/btg034; Pieler R, 2004, BIOINFORMATICS, V20, P1971, DOI 10.1093/bioinformatics/bth174; PROBER JM, 1987, SCIENCE, V238, P336, DOI 10.1126/science.2443975; Pruitt K.D., 2007, NUCLEIC ACIDS RES, V35, P61; Quackenbush J, 2003, SCIENCE, V302, P240, DOI 10.1126/science.1090887; Quackenbush J, 2002, NAT GENET, V32, P496, DOI 10.1038/ng1032; Quackenbush J, 2001, NAT REV GENET, V2, P418, DOI 10.1038/35076576; Quevillon E., 2005, NUCLEIC ACIDS RES, V33, P116; Rayner TF, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-489; REECK GR, 1987, CELL, V50, P667, DOI 10.1016/0092-8674(87)90322-9; Reese MG, 2000, GENOME RES, V10, P529, DOI 10.1101/gr.10.4.529; Repsilber D, 2005, METHOD INFORM MED, V44, P400; Ronaghi M, 1998, SCIENCE, V281, P363, DOI 10.1126/science.281.5375.363; RUTHERFORD K, 2000, BIOINFORMATICS, V16, P945; Saal L. H., 2002, GENOME BIOL, V3; Saeed AI, 2003, BIOTECHNIQUES, V34, P374; Saha S, 2002, NAT BIOTECHNOL, V20, P508, DOI 10.1038/nbt0502-508; Salamov AA, 2000, GENOME RES, V10, P516, DOI 10.1101/gr.10.4.516; SANGER F, 1977, P NATL ACAD SCI USA, V74, P5467; SCHENA M, 1995, SCIENCE, V270, P467, DOI 10.1126/science.270.5235.467; SCHIEX T, 2001, LNCS, V2066, P111; Schneiker S, 2007, NAT BIOTECHNOL, V25, P1281, DOI 10.1038/nbt1354; Schneiker S, 2006, NAT BIOTECHNOL, V24, P997, DOI 10.1038/nbt1232; Shendure J, 2004, NAT REV GENET, V5, P335, DOI 10.1038/nrg1325; Shendure J, 2005, SCIENCE, V309, P1728, DOI 10.1126/science.1117389; SHENDURE JA, 2008, CURR PROTOC MOL BIOL, P1; Skovgaard M, 2001, TRENDS GENET, V17, P425, DOI 10.1016/S0168-9525(01)02372-1; Slater GS, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-31; SMITH MW, 1992, TRENDS BIOCHEM SCI, V17, P489, DOI 10.1016/0968-0004(92)90335-7; SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5; Sonnhammer E L, 1998, Proc Int Conf Intell Syst Mol Biol, V6, P175; Spellman P. T., 2002, GENOME BIOL, V3; Stanke M., 2003, BIOINFORMATICS S2, V19, pii215; Stanke M, 2006, GENOME BIOL, V7, DOI 10.1186/gb-2006-7-s1-s11; Sturn A, 2002, BIOINFORMATICS, V18, P207, DOI 10.1093/bioinformatics/18.1.207; Sugawara H, 2008, NUCLEIC ACIDS RES, V36, pD22, DOI 10.1093/nar/gkm889; Suzek BE, 2001, BIOINFORMATICS, V17, P1123, DOI 10.1093/bioinformatics/17.12.1123; Tamames J, 1997, J MOL EVOL, V44, P66, DOI 10.1007/PL00006122; TATSUOV RL, 1996, CURR BIOL, V6, P279; Team R.D.C, 2008, R LANG ENV STAT COMP; Tech M, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-121; Thieme F, 2005, J BACTERIOL, V187, P7254, DOI 10.1128/JB.187.21.7254-7266.2005; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Usuka J, 2000, BIOINFORMATICS, V16, P203, DOI 10.1093/bioinformatics/16.3.203; van Baren MJ, 2006, GENOME RES, V16, P678, DOI 10.1101/gr.4766206; Vapnik V., 1999, STAT LEARNING THEORY; VELCULESCU VE, 1995, SCIENCE, V270, P484, DOI 10.1126/science.270.5235.484; von Mering C., 2005, NUCLEIC ACIDS RES, V33, P433; Vorhoelter FJ, 2008, J BIOTECHNOL, V134, P33, DOI 10.1016/j.jbiotec.2007.12.013; Wei CC, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-327; Wilkinson Mark D, 2002, Brief Bioinform, V3, P331, DOI 10.1093/bib/3.4.331; Wu J., 2006, NUCLEIC ACIDS RES, V34, P720; Wu TD, 2005, BIOINFORMATICS, V21, P1859, DOI 10.1093/bioinformatics/bti310; Wu W, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-191; Yang YH, 2002, NAT REV GENET, V3, P579; Yauk C, 2005, J BIOCHEM BIOPH METH, V64, P69, DOI 10.1016/j.jbbm.2005.06.002; Yauk CL, 2004, NUCLEIC ACIDS RES, V32, DOI 10.1093/nar/gnh123; Zhang MQ, 2002, NAT REV GENET, V3, P698, DOI 10.1038/nrg890; Zhang Z, 2000, J COMPUT BIOL, V7, P203, DOI 10.1089/10665270050081478	202	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES		978-90-481-8616-7				2010							315	378		10.1007/978-90-481-8639-6_9	10.1007/978-90-481-8639-6	64	Genetics & Heredity	Genetics & Heredity	BOY65	WOS:000278068900009	
J	Yang, CH; Chuang, LY; Yang, CH				Yang, Cheng-Huei; Chuang, Li-Yeh; Yang, Cheng-Hong			IG-GA: A Hybrid Filter/Wrapper Method for Feature Selection of Microarray Data	JOURNAL OF MEDICAL AND BIOLOGICAL ENGINEERING			English	Article						Feature selection; Information gain (IG); Genetic algorithms (GA); K-nearest neighbor (K-NN); Leave-one-out cross-validation (LOOCV)	GENETIC ALGORITHMS; CLASSIFICATION; INFORMATION	Gene expression profiles have great potential as a medical diagnostic tool since they represent the state of a cell at the molecular level. Available training data sets for classification of cancer types generally have a fairly small sample size compared to the number of genes involved. This fact poses an insurmountable problem to some classification methodologies due to training data limitations. Feature selection is considered a problem of global combinatorial optimization in machine learning, which reduces the number of features, removes irrelevant, noisy and redundant data, and results in acceptable classification accuracy. Hence, selecting relevant genes from the microarray data poses a formidable challenge to researchers due to the high-dimensionality of features, multi-class categories being involved, and the usually small sample size. To overcome this difficulty, a good selection method for genes relevant for sample classification is needed in order to improve prediction accuracy, and to avoid incomprehensibility due to the large number of genes investigated. In this paper, we proposed a filter method (information gain, IG) and a wrapper method (genetic algorithm, GA) for feature selection in microarray data sets. IG was used to select important feature subsets (genes) from all features in the gene expression data, and a GA was employed for actual feature selection. The K-nearest neighbor (K-NN) method with leave-one-out cross-validation (LOOCV) served as an evaluator of the IG-GA. The proposed method was applied and compared to eleven classification problems taken from the literature. Experimental results show that our method simplifies the number of gene expression levels effectively and either obtains higher classification accuracy or uses fewer features compared to other feature selection methods.	[Chuang, Li-Yeh] I Shou Univ, Inst Biotechnol & Chem Engn, Kaohsiung 800, Taiwan; [Yang, Cheng-Huei] Natl Kaohsiung Marine Univ, Dept Elect Commun Engn, Kaohsiung 811, Taiwan; [Yang, Cheng-Hong] Toko Univ, Dept Network Syst, Chiayi 613, Taiwan; [Yang, Cheng-Hong] Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, Kaohsiung 807, Taiwan	Chuang, LY (reprint author), I Shou Univ, Inst Biotechnol & Chem Engn, Kaohsiung 800, Taiwan.	chuang@isu.edu.tw; chyang@cc.kuas.edu.tw	Chuang, Li-Yeh/E-5005-2011		National Science Council in Taiwan [NSC 94-2622-E-151-025-CC3, NSC 94-2311-B037-001, NSC 93-2213-E-214-037, NSC 92-2213-E-214-036]	This work was partly supported by the National Science Council in Taiwan under grants NSC 94-2622-E-151-025-CC3, NSC 94-2311-B037-001, NSC 93-2213-E-214-037, and NSC 92-2213-E-214-036.	BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Burr Ridge I, 1997, MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crammer K, 2000, P 13 ANN C COMP LEAR, P35; Dasarathy B., 1991, NEAREST NEIGHBOR NN, P1; DAVIS L, 1990, MACH LEARN, V117; Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017; Dias AHF, 2002, IEEE T MAGN, V38, P1133, DOI 10.1109/20.996290; Fix E., 1951, 4 USAF SCH AV MED, P261; Frank E, 2004, BIOINFORMATICS, V20, P2479, DOI 10.1093/bioinformatics/bth261; Goldberg D. E., GENETIC ALGORITHMS S; Holland JH, 1992, ADAPTATION NATURE AR; HOU ESH, 1994, IEEE T PARALL DISTR, V5, P113, DOI 10.1109/71.265940; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Huang HL, 2007, BIOSYSTEMS, V90, P78, DOI 10.1016/j.biosystems.2006.07.002; KIM S, 2001, P 2001 C EV COMP, V2, P1253; Kressel UHG, 1999, ADVANCES IN KERNEL METHODS, P255; Li LP, 2001, BIOINFORMATICS, V17, P1131, DOI 10.1093/bioinformatics/17.12.1131; Martin-Valdivia MT, 2008, INFORM PROCESS MANAG, V44, P1146, DOI 10.1016/j.ipm.2007.09.014; MUKRAS R, 2007, P IJCAI TEXTL WORKSH; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; Platt JC, 2000, ADV NEUR IN, V12, P547; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; TSAI CF, 2002, P JOINT C INF SCI, V3, P362; Turing A.M., 1950, MIND, V59, P433, DOI DOI 10.1093/MIND/LIX.236.433; Vafaie H., 1992, Proceedings. Fourth International Conference on Tools with Artificial Intelligence, TAI '92 (Cat. No. 92CH3203-7), DOI 10.1109/TAI.1992.246402; YU B, 1993, PATTERN RECOGN, V26, P883, DOI 10.1016/0031-3203(93)90054-Z; Zhang HB, 2002, PATTERN RECOGN, V35, P701, DOI 10.1016/S0031-3203(01)00046-2; Zhu ZX, 2007, IEEE T SYST MAN CY B, V37, P70, DOI 10.1109/TSMCB.2006.883267	31	1	1	DEPT BIOMEDICAL ENGINEERING	TAINAN CITY	NAT CHENG KUNG UNIV, NO 1 UNIVERSITY RD, TAINAN CITY, TAIWAN 701, PEOPLES R CHINA	1609-0985		J MED BIOL ENG	J. Med. Biol. Eng.		2010	30	1					23	28				6	Engineering, Biomedical	Engineering	571HU	WOS:000275743700003	
J	Mariolis, IG; Dermatas, ES				Mariolis, I. G.; Dermatas, E. S.			Automated assessment of textile seam quality based on surface roughness estimation	JOURNAL OF THE TEXTILE INSTITUTE			English	Article						machine vision; seam pucker; quality control; kNNc		In this paper the issue of automated seam quality control is addressed, focusing especially on seam pucker evaluation. Currently this task is accomplished by human experts considering five grades of quality. The proposed method estimates surface roughness of seam specimens producing robust and efficient novel features highly correlated to quality grades (QGs). At the initial stage, oblique illumination is applied and two-dimensional images of the specimens are acquired. The images are automatically rotated and centered in respect to the seam line and segmented into four regions. Each region produces an intensity curve through averaging, and roughness estimation is performed based on intensity mean deviation. Finally, a QG is assigned to each specimen using a k-nearest neighbor classifier (kNNc). A data set containing 211 seam specimens, created by two different kinds of fabric, has been used for testing and a correct classification rate of 81.04% has been produced matching up to the performance of human experts.	[Mariolis, I. G.; Dermatas, E. S.] Univ Patras, Dept Elect Engn & Comp Sci, Patras 26500, Greece	Mariolis, IG (reprint author), Univ Patras, Dept Elect Engn & Comp Sci, Patras 26500, Greece.	mariolis@george.wcl2.ee.upatras.gr					Aibara T, 1999, P SOC PHOTO-OPT INS, V3652, P110, DOI 10.1117/12.341130; Bahlmann C, 1999, PATTERN RECOGN, V32, P1049, DOI 10.1016/S0031-3203(98)00128-9; Cohen J, 1960, EDUC PSYCHOL MEAS, V20, P46; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Kang TJ, 2005, TEXT RES J, V75, P751, DOI 10.1177/0040517505058855; Koehl L, 2007, STUD COMP INTELL, P39; Kohavi R., 1995, P 14 INT JOINT C ART, V2, P1137; Krause EF, 1987, TAXICAB GEOMETRY; Mariolis IG, 2006, 37 INT S NOV TEXT LJ; Seber G. A. F., 1984, MULTIVARIATE OBSERVA; Spath H., 1985, CLUSTER DISSECTION A; Witten H., 2005, DATA MINING PRACTICA; Zaouali R, 2007, J TEXT I, V98, P443, DOI 10.1080/00405000701489156; *ISO DIS, 1981, 7770 ISODIS	14	2	2	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0040-5000		J TEXT I	J. Text. Inst.		2010	101	7					653	659		10.1080/00405000902732883		7	Materials Science, Textiles	Materials Science	612TA	WOS:000278924800008	
S	Yusof, Y; Rana, OF		Setchi, R; Jordanov, I; Howlett, RJ; Jain, LC		Yusof, Yuhanis; Rana, Omer F.			Classification of Software Artifacts Based on Structural Information	KNOWLEDGE-BASED AND INTELLIGENT INFORMATION AND ENGINEERING SYSTEMS, PT IV	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	14th International Conference on Knowledge-Based and Intelligent Information and Engineering Systems	SEP 08-10, 2010	Cardiff, WALES	Cardiff Univ, Sch Engn, KES Int		classification; software metrics; decision tree; k-nearest neighborhood; discriminant analysis		Classification of software artifacts, in particularly the source code files, are currently performed by administrator of a repository. Even though there exist automated classification on these repositories, nevertheless existing approach focuses on semantic analysis of keywords found in the artifact. This paper presents the use of structural information, that is the software metrics, in determining the appropriate application domain for a particular artifact. Results obtained from the study show that there is a difference in the metrics' trend between files of different application domain. It is also learned that results obtained using k-nearest neighborhood outperformed C4.5 decision tree and the one generated based on Discriminant; Analysis in classifying files of database and graphics domain.	[Yusof, Yuhanis] Univ Utara Malaysia, Coll Arts & Sci, Sintok 06010, Kedah, Malaysia	Yusof, Y (reprint author), Univ Utara Malaysia, Coll Arts & Sci, Informat Technol Bldg, Sintok 06010, Kedah, Malaysia.	yuhanis@uum.edu.my; o.f.rana@cs.cardiff.ac.uk					Chung KP, 2005, INT CONF E BUS ENG, P346; Cohen S., 2003, P 29 VLDB C BERL GER; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; FUCHS NE, 1992, SOFTWARE ENG J, V7, P323; Ganti V, 1999, COMPUTER, V32, P38, DOI 10.1109/2.781633; Kawaguchi S., 2004, Proceedings. 11th Asia-Pacific Software Engineering Conference; KAWAGUCHI S, 2002, P 6 INT WORKSH PRINC, P195; Klecka W. R., 1980, DISCRIMINANT ANAL; Kwon OW, 2003, INFORM PROCESS MANAG, V39, P25, DOI 10.1016/S0306-4573(02)00022-5; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; MARCUS A, 2004, WCRE, P214; NAGAPPAN N, 2004, MACH LEARN, P60; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Ruggieri S, 2002, IEEE T KNOWL DATA EN, V14, P438, DOI 10.1109/69.991727; SHAFIA, 2010, EUROPEAN J SCI RES, V41, P109; Ugurel S., 2002, P 8 ACM SIGKDD INT C, P632; WALTERS S, 2005, CATALOGING CLASSIFIC, V41, P163, DOI 10.1300/J104v41n01_08; *DSFP, DSFP MOD FOR SVM SUP; *U WAIK, WEK; C C CODE COUNTER	21	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-15383-9	LECT NOTES ARTIF INT			2010	6279						546	555				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BUI34	WOS:000289445700058	
B	El-Alfy, EM		Peters, H; Vogel, M		El-Alfy, El-Sayed M.			LEARNING METHODS FOR SPAM FILTERING	MACHINE LEARNING RESEARCH PROGRESS			English	Article; Book Chapter						Machine Learning; Text Categorization; Classification; Spam Filtering; Unsolicited Commercial E-mail; Bayesian Filter; Memory-Based Learning; Boosting; Neural Networks; Support Vector Machines	ROUGH SET APPROACH; NEURAL-NETWORK; E-MAIL; ALGORITHMS; MODEL; PERFORMANCE	With the increasing popularity of electronic mail, several persons and companies have found it an easy way to quickly disseminate unsolicited messages to a large number of users at very low costs for the senders. Consequently, unsolicited or spam e-mails have dramatically become a major threat that can negatively impact the usability of the electronic mail as a reliable communication means. Besides wasting considerable time and money for business users and network administrators, spam consumes network bandwidth and server storage space, slows down e-mail servers, and provides a medium to distribute harmful and/or offensive content. Hence, it has become an important and indispensable aspect of any recent e-mail system to incorporate a spam filtering subsystem. In this chapter, we present an overview of the spam filtering problem and survey the state-of-the-art of the proposed and deployed machine learning based methods. We begin with a brief review of potential spam threats for network users and resources, and some market analysis indicators of the spam growth rate. After that, we formally describe the machine learning spam filtering problem and discuss various approaches for representing e-mail messages and selecting relevant features. Then, we describe some common metrics and benchmark corpora for evaluating and comparing the performance of different learning methods for spam filtering. Next, we discuss various learning algorithms that have been applied to this problem and survey the related work. Finally, we present a case study to compare the performance of a number of these learning methods on one of the publicly available datasets.	King Fahd Univ Petr & Minerals, Coll Comp Sci & Engn, Dhahran, Saudi Arabia	El-Alfy, EM (reprint author), King Fahd Univ Petr & Minerals, Coll Comp Sci & Engn, Dhahran, Saudi Arabia.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; AHMED S, 2004, P 1 C EM ANT CEAS; ANDROUTSOPOULOS I, 2000, 20005 DEMO NCSR I IN; ANDROUTSOPOULOS I, 2000, WORKSH MACH LEARN TE, P1; Androutsopoulos I., 2000, P 23 ANN INT ACM SIG; ANDROUTSOPOULOS I, 2005, P 2 C EM ANT CEAS 05; Androutsopoulos I, 2000, P WORKSH MACH LEARN, P9; Androutsopoulos I., 2004, LEARNING FILTER UNSO; BEKKERMAN R, 2004, IR418 CIIR; Bishop C. M., 2007, PATTERN RECOGNITION; BLANZIERI E, 2007, INSTANCE BASED SPAM; BLANZIERI E, 2006, DIT06056; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P2; Burr Ridge I, 1997, MACHINE LEARNING; BURTON B, 2003, P MIT SPAM C; Carpinteiro OAS, 2006, LECT NOTES COMPUT SC, V4132, P847; Carpinter J, 2006, COMPUT SECUR, V25, P566, DOI 10.1016/j.cose.2006.06.001; CARPINTER JM, 2005, 0405 HONS U CANT COM; Carreras X., 2001, P 4 INT C REC ADV NA; CHEN T, 2003, SPAM E MAIL FILTER U; CHHABRA S, 2004, P 4 IEEE INT C DAT M; CHOUCHOULAS A, 1999, THESIS U EDINBURGH; CHUAN Z, 2004, P 5 INT C PAR DISTR; CHUAN Z, 2005, ACM SIGOPS OPERATING, V39, P34, DOI DOI 10.1145/1044552.1044555; CLARK J, 2003, P IEEE WIC INT C WEB; Cohen W. W., 1995, P 12 INT C MACH LEAR; COHEN WW, 1996, P AAAI 96 SPRING S M; CORMACK G, 2005, 2 C EM ANT SPAM; CORMACK G, 2006, 15 TEXT RETR C P; CORMACK GV, 2006, 3 C EM ANT CEAS 06 M; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cranor LF, 1998, COMMUN ACM, V41, P74, DOI 10.1145/280324.280336; Cristianini N, 2000, INTRO SUPPORT VECTOR; DAELEMANS W, 0703 ILK TILB U DEP; DEEPAK P, 2005, S APPL INT SAINT 05; Dietterich T.G., 2002, HDB BRAIN THEORY NEU; Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; DRUCKER H, 1995, NIPS 1995, P479; ELALFY ESM, 2008, P IEEE INT JOINT C N; ELALFY ESM, 2008, P IEEE INT C COMP SY; ERYIGIT G, 2005, P INT C ART INT APPL, P457; Fallows D., 2003, SPAM IT IS HURTING E; FARRUGIA A, 2004, THESIS MONASH U; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Fdez-Riverola F, 2007, EXPERT SYST APPL, V33, P36, DOI 10.1016/j.eswa.2006.04.011; Fdez-Riverola F, 2007, DECIS SUPPORT SYST, V43, P722, DOI 10.1016/j.dss.2006.11.012; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Fuad M.M., 2004, P 7 INT C COMP INF T; Furnkranz J., 1994, P 11 INT C MACH LEAR; Gansterer W.N., 2005, ANTISPAM METHODS STA; GARCIA F, 2004, P 19 IFIP INT INF SE; GAVRILIS D, 2006, LECT NOTES COMPUTER, V3955; GEORGIOUA E, 2007, J NETWORK C IN PRESS; Glymin M, 2007, LECT NOTES ARTIF INT, V4585, P350, DOI 10.1007/978-3-540-73451-2_37; Gomes LH, 2007, PERFORM EVALUATION, V64, P690, DOI 10.1016/j.peva.2006.11.001; Gordillo J, 2007, EXPERT SYST APPL, V33, P667, DOI 10.1016/j.eswa.2006.06.016; GRAHAM P, 2003, P 1 ANN SPAM C; HANLEY JA, 1983, RADIOLOGY, V148, P839; Hershkop S, 2005, P 11 ACM SIGKDD INT; HIDALGO JMG, 2000, P 2 WORKSH LEARN LAN, V7, P99; Hoanca B, 2006, IEEE TECHNOL SOC MAG, V25, P22, DOI 10.1109/MTAS.2006.1607720; Hsiao WF, 2008, EXPERT SYST APPL, V34, P1599, DOI 10.1016/j.eswa.2007.01.018; HUAIBIN W, 2005, LECT NOTES COMPUTER, P1147; Huang J, 2005, IEEE T KNOWL DATA EN, V17, P299; Huang T-M, 2006, KERNEL BASED ALGORIT; ISLAM MR, 2007, 6 IEEE ACIS INT C CO; Jensen F.V., 2001, BAYESIAN NETWORKS DE; Jimenez D.A., 1998, P 1998 INT JOINT C N, P753; Joachims T, SVM LIGHT; Joachims T, 1998, P 10 EUR C MACH LEAR, P137; John G., 1995, P 11 C UNC ART INT, P338; Johnson PRE, 1997, BRIT J HAEMATOL, V97, P1, DOI 10.1046/j.1365-2141.1997.00984.x; JUNEJO KN, 2006, P 17 EUR C MACH LEAR; JUNG J, 2004, P 4 ACM SIGCOMM C IN; Khorsi Ahmed, 2007, Informatica, V31; KLIMT B, 2004, P 1 C EM ANT CEAS; Kohonen T, 2001, SELF ORG MAPS; Kolcz A., 2001, P TEXTDM 01 WORKSH T; Komorowski J., 1999, ROUGH FUZZY HYBRIDIZ; Koprinska I, 2007, INFORM SCIENCES, V177, P2167, DOI 10.1016/j.ins.2006.12.005; Lai CC, 2007, KNOWL-BASED SYST, V20, P249, DOI 10.1016/j.knosys.2006.05.016; LAI CC, 2004, P 4 INT C HYBR INT S; LEIBA B, 2004, P 1 C EM ANT MOUNT V; Lohninger H., 1999, TEACH ME DATA ANAL; LUO X, 2005, P IEEE INT JOINT C N, V4, P2571; LYON J, 2006, 4406 RFC; Manning C.D., 2007, INTRO INFORM RETRIEV; METSIS V, 2006, P 2 C EM ANT CEAS MO; MEYER TA, 2004, P 1 C EM ANT CEAS; Neapolitan R., 2004, LEARNING BAYESIAN NE; NELSON M, 2003, ANTISPAM BUSINESS IS; Nicholas T., 2003, USING ADABOOST DECIS; O'Brien C., 2003, P 1 INT S INF COMM T, P291; OSUMA E, 1997, 1602 MIT AI LAB; Ozgur L, 2004, PATTERN RECOGN LETT, V25, P1819, DOI 10.1016/j.patrec.2004.07.004; Ozgur L, 2004, LECT NOTES COMPUT SC, V3177, P505; PANG XL, 2007, P 3 INT C NAT COMP, V2, P484; PANTEL P, 1998, P AAAI WORKSH LEARN; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Platt J, 1998, ADV KERNEL METHODS S; Provost J., 1999, AITR99284 U TEX AUST; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RAINIE L, 2004, CAN SPAM ACT HAS NOT; RENNIE J, 2000, KDD 2000 TEXT MIN WO; RIOS G, 2004, P 1 C EM ANT MOUNT V; Rocchio J. J., 1971, SMART RETRIEVAL SYST, P313; Russell S., 2003, ARTIFICIAL INTELLIGE; Sahami M., 1998, P AAAI WORKSH LEARN, P55; Sakkis G, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P44; Sakkis G, 2003, INFORM RETRIEVAL, V6, P49, DOI 10.1023/A:1022948414856; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; SCHNEIDER K, 2003, P 10 C EUR CHAPT ASS; Sculley D., 2007, P 30 ANN INT ACM SIG, P415, DOI 10.1145/1277741.1277813; Sebastiani F., 2002, ACM COMPUT SURV, V34, P47; SEBASTIANI FA, 2001, ERCIM NEWS; SEBASTIANI FA, 1999, P 1 ARG S ART INT AS; Sebban M, 2002, PATTERN RECOGN, V35, P835, DOI 10.1016/S0031-3203(01)00084-X; SEEWALD AK, 2004, TR200411 OST FORSCH; SIEFKES C, 2004, P EUR C PRINC PRACT; Sinclair S, 2004, J COMPUTING SCI COLL, V19, P344; STUART I, 2004, LECT NOTES COMPUTER, P442; Su M, 2001, IEEE IJCNN, P2159; Swann A, 1998, ELECTRON LETT, V34, P1408, DOI 10.1049/el:19981000; Tresp V., 2001, HDB NEURAL NETWORK S; TRETYAKOV K, 2004, I COMP SCI U TART DA, P60; TRUDGIAN DC, 2004, P 5 INT C INT DAT EN, P578; TUTTLE A, 2004, CS200403 DALH U; Wang CC, 2004, J RES PRACT INF TECH, V36, P3; Wang CC, 2007, COMPUT SECUR, V26, P381, DOI 10.1016/j.cose.2006.12.012; WEBB S, 2005, INT C COLL COMP NETW; WILSON DR, 1997, THESIS B YOUNG U; WOITASZEK M, 2003, P 2003 S APPL INT OR; Wong M., 2006, 4408 RFC; Yang Y., 2007, P 2007 IEEE INT S CO; Yang Y., 1997, P 14 INT C MACH LEAR; Yang Y. M., 1999, INFORM RETRIEVAL, V1, P69, DOI 10.1023/A:1009982220290; YANG Z, 2006, 6 INT C INT SYST DES; YAO YY, 1992, INT J MAN MACH STUD, V37, P793, DOI 10.1016/0020-7373(92)90069-W; YERAZUNIS B, 2003, P SPAM C; YERAZUNIS W, 2005, MIT SPAM C; Yu B., 2003, NONLINEAR ESTIMATION; Zhang HW, 2003, CHINESE J ASTRON AST, V3, P453; Zhang L., 2004, ACM T ASIAN LANGUAGE, V3, P243, DOI 10.1145/1039621.1039625; ZHAO W, 2005, IEEE TENCON 05 HONG, P2246; Zhao WQ, 2005, Proceedings of the 2005 International Conference on Active Media Technology (AMT 2005), P403; Zhao WQ, 2006, LECT NOTES ARTIF INT, V4062, P766; Zhou Y., 2005, P 17 IEEE INT C TOOL, P302; ZIARKO W, 1993, J COMPUT SYST SCI, V46, P39, DOI 10.1016/0022-0000(93)90048-2; ZORKADIS V, 2005, POC IEEE INT JOINT C, V1, P179; Zorkadis V, 2005, NEURAL NETWORKS, V18, P799, DOI 10.1016/j.neunet.2005.06.045; [Anonymous], UCI MACH LEARN REP; *ECML PKDD, 2006, DISC CHALL; *GFI SOFT, 2007, WHY BAY FILT MOST EF; *GFI SOFT, 2007, KEEP SPAM YOUR NETW; *MESSAGELABS, 2006, MESSAGELABS INT 2006	156	0	0	NOVA SCIENCE PUBLISHERS, INC	HAUPPAUGE	400 OSER AVE, STE 1600, HAUPPAUGE, NY 11788-3635 USA		978-1-60456-646-8				2010							383	425				43	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BPE16	WOS:000278665800015	
S	Rathi, Y; Malcolm, J; Michailovich, O; Goldstein, J; Seidman, L; McCarley, RW; Westin, CF; Shenton, ME		Jiang, T; Navab, N; Pluim, JPW; Viegever, MA		Rathi, Yogesh; Malcolm, James; Michailovich, Oleg; Goldstein, Jill; Seidman, Larry; McCarley, Robert W.; Westin, Carl-Fredrik; Shenton, Martha E.			Biomarkers for Identifying First-Episode Schizophrenia Patients Using Diffusion Weighted Imaging	MEDICAL IMAGE COMPUTING AND COMPUTER-ASSISTED INTERVENTION - MICCAI 2010, PT I	Lecture Notes in Computer Science		English	Proceedings Paper	13th International Conference on Medical Image Computing and Computer-Assisted Intervention	SEP 20-24, 2010	Beijing, PEOPLES R CHINA	MICCAI Soc	China Natl Convent Ctr		DENSITY-FUNCTION; TENSOR IMAGES; WHITE-MATTER; MRI; CLASSIFICATION; DECONVOLUTION; TRACTOGRAPHY; FRAMEWORK	Recent advances in diffusion weighted MR imaging (dMRI) has made it a tool of choice for investigating white matter abnormalities of the brain and central nervous system. In this work, we design a system that detects abnormal features (biomarkers) of first-episode schizophrenia patients and then classifies them using these features. We use two different models of the dMRI data, namely, spherical harmonics and the two-tensor model. The algorithm works by first computing several diffusion measures from each model. An affine-invariant representation of each subject is then computed, thus avoiding the need for registration. This representation is used within a kernel based feature selection algorithm to determine the biomarkers that are statistically different between the two populations. Confirmation of how well these biomarkers identify each population is obtained by using several classifiers such as, k-nearest neighbors, Parzen window classifier, and support vector machines to separate 21 first-episode patients from 20 age-matched normal controls. Classification results using leave-manyout cross-validation scheme are given for each representation. This algorithm is a first step towards early detection of schizophrenia.	[Rathi, Yogesh; Goldstein, Jill; Seidman, Larry; Westin, Carl-Fredrik; Shenton, Martha E.] Harvard Univ, Sch Med, Boston, MA 02115 USA	Rathi, Y (reprint author), Harvard Univ, Sch Med, Boston, MA 02115 USA.						Anderson AW, 2005, MAGNET RESON MED, V54, P1194, DOI 10.1002/mrm.20667; Barmpoutis A., 2009, NEUROIMAGE; BASSER PJ, 1994, BIOPHYS J, V66, P259; Behrens TEJ, 2007, NEUROIMAGE, V34, P144, DOI 10.1016/j.neuroimage.2006.09.018; Budde MD, 2007, MAGN RESON MED, V57, P688, DOI 10.1002/mrm.21200; Caan MWA, 2006, MED IMAGE ANAL, V10, P841, DOI 10.1016/j.media.2006.07.006; Caprihan A, 2008, NEUROIMAGE, V42, P675, DOI 10.1016/j.neuroimage.2008.04.255; CHENEVERT TL, 1990, RADIOLOGY, V177, P401; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davatzikos C, 2005, ARCH GEN PSYCHIAT, V62, P1218, DOI 10.1001/archpsyc.62.11.1218; Descoteaux M, 2007, MAGN RESON MED, V58, P497, DOI 10.1002/mrm.21277; Friedman JI, 2008, AM J PSYCHIAT, V165, P1024, DOI 10.1176/appi.ajp.2008.07101640; GRETTON A., 2008, J MACHINE LEARNING R, V1, P1; Jain A. K., 1988, Pattern Recognition and Artificial Intelligence. Towards an Integration. Proceedings of an International Workshop; Jansons KM, 2003, INVERSE PROBL, V19, P1031, DOI 10.1088/0266-5611/19/5/303; Jian B, 2007, IEEE T MED IMAGING, V26, P1464, DOI 10.1109/TMI.2007.907552; Khurd P, 2007, LECT NOTES COMPUT SC, V4584, P581; Kindlmann G, 2007, IEEE T MED IMAGING, V26, P1483, DOI 10.1109/TMI.2007.907277; Kubicki M, 2007, J PSYCHIAT RES, V41, P15, DOI 10.1016/j.jspychires.2005.05.005; Malcolm JG, 2009, LECT NOTES COMPUT SC, V5636, P126, DOI 10.1007/978-3-642-02498-6_11; McGlashan TH, 1996, SCHIZOPHRENIA BULL, V22, P197; Ozarslan E, 2005, MAGNET RESON MED, V53, P866, DOI 10.1002/mrm.20411; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PICARD RR, 1984, J AM STAT ASSOC, V79, P575, DOI 10.2307/2288403; Pohl KM, 2009, LECT NOTES COMPUT SC, V5636, P300, DOI 10.1007/978-3-642-02498-6_25; Schobel SA, 2009, ARCH GEN PSYCHIAT, V66, P938, DOI 10.1001/archgenpsychiatry.2009.115; Scholkopf B., 1999, ADV KERNEL METHODS S; Tournier JD, 2004, NEUROIMAGE, V23, P1176, DOI 10.1016/j.neuroimage.2004.07.037; Tuch DS, 2004, MAGNET RESON MED, V52, P1358, DOI 10.1002/mrm.20279	29	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-15704-2	LECT NOTES COMPUT SC			2010	6361						657	665				9	Computer Science, Software Engineering; Computer Science, Theory & Methods; Neuroimaging; Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging	Computer Science; Neurosciences & Neurology; Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging	BTS19	WOS:000287946100080	
S	Freiman, M; Sela, Y; Edrei, Y; Pappo, O; Joskowicz, L; Abramovitch, R		Karssemeijer, N; Summers, RM		Freiman, M.; Sela, Y.; Edrei, Y.; Pappo, O.; Joskowicz, L.; Abramovitch, R.			Multi-class SVM model for fMRI-based classification and grading of liver fibrosis	MEDICAL IMAGING 2010: COMPUTER - AIDED DIAGNOSIS	Proceedings of SPIE		English	Proceedings Paper	Conference on Medical Imaging 2010 - Computer-Aided Diagnosis	FEB 16-18, 2010	San Diego, CA	SPIE, Medtronic, Inc, Aeroflex, Inc, Tungsten Heavy Powder, Inc		Abdominal; Characterization; Machine Learning	MR ELASTOGRAPHY; VECTOR MACHINES; BIOPSY; DIAGNOSIS; PERFUSION; HYPERCAPNIA; HYPEROXIA; CIRRHOSIS	We present a novel non-invasive automatic method for the classification and grading of liver fibrosis from fMRI maps based on hepatic hemodynamic changes. This method automatically creates a model for liver fibrosis grading based on training datasets. Our supervised learning method evaluates hepatic hemodynamics from an anatomical MRI image and three T2*-W fMRI signal intensity time-course scans acquired during the breathing of air, air-carbon dioxide, and carbogen. It constructs a statistical model of liver fibrosis from these fMRI scans using a binary-based one-against-all multi class Support Vector Machine (SVM) classifier. We evaluated the resulting classification model with the leave-one out technique and compared it to both full multi-class SVM and K-Nearest Neighbor (KNN) classifications. Our experimental study analyzed 57 slice sets from 13 mice, and yielded a 98.2% separation accuracy between healthy and low grade fibrotic subjects, and an overall accuracy of 84.2% for fibrosis grading. These results are better than the existing image-based methods which can only discriminate between healthy and high grade fibrosis subjects. With appropriate extensions, our method may be used for non-invasive classification and progression monitoring of liver fibrosis in human patients instead of more invasive approaches, such as biopsy or contrast-enhanced imaging.	[Freiman, M.; Sela, Y.; Joskowicz, L.] Hebrew Univ Jerusalem, Sch Engn & Comp Sci, IL-91905 Jerusalem, Israel	Freiman, M (reprint author), Hebrew Univ Jerusalem, Sch Engn & Comp Sci, IL-91905 Jerusalem, Israel.	freiman@cs.huji.ac.il					Annet L, 2007, J MAGN RESON IMAGING, V25, P122, DOI 10.1002/jmri.20771; Annet L, 2003, RADIOLOGY, V229, P409, DOI 10.1148/radiol.2292021128; Barash H, 2007, RADIOLOGY, V243, P727, DOI 10.1148/radiol.2433060433; Barasli H, 2008, HEPATOLOGY, V48, P1232, DOI 10.1002/hep.22394; BATTS KP, 1995, AM J SURG PATHOL, V19, P1409, DOI 10.1097/00000478-199512000-00007; Bonekamp S, 2009, J HEPATOL, V50, P17, DOI 10.1016/j.jhep.2008.10.016; Bravo AA, 2001, NEW ENGL J MED, V344, P495, DOI 10.1056/NEJM200102153440706; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628; Freiman M, 2008, LECT NOTES COMPUT SC, V5241, P85, DOI 10.1007/978-3-540-85988-8_11; Friedman SL, 2003, J HEPATOL, V38, pS38, DOI 10.1016/S0168-8278(02)00429-4; GARCIATSAO G, 1993, ANN INTERN MED, V118, P150; Hagiwara M, 2008, RADIOLOGY, V246, P926, DOI 10.1148/radiol.2463070077; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Huwart L, 2006, NMR BIOMED, V19, P173, DOI 10.1002/nbm.1030; Kato H, 2007, AM J ROENTGENOL, V189, P117, DOI 10.2214/AJR.07.2070; Mazza E, 2008, LECT NOTES COMPUT SC, V5242, P726, DOI 10.1007/978-3-540-85990-1_87; NORD HJ, 1982, GASTROINTEST ENDOSC, V28, P102; Pandharipande PV, 2005, RADIOLOGY, V234, P661, DOI 10.1148/radiol.2343031362; PICCININO F, 1986, J HEPATOL, V2, P165, DOI 10.1016/S0168-8278(86)80075-7; Popov Y, 2005, J HEPATOL, V43, P1045, DOI 10.1016/j.jhep.2005.06.025; Rifkin R, 2004, J MACH LEARN RES, V5, P101; Rohlfing T, 2004, MED PHYS, V31, P427, DOI 10.1118/1.1644513; Rouviere O, 2006, RADIOLOGY, V240, P440, DOI 10.1148/radiol.2402050606; Thorsten J, 1999, ADV KERNEL METHODS S, P169; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Vapnik V.N., 1995, NATURE STAT LEARNING	27	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	978-0-8194-8025-5	PROC SPIE			2010	7624								76240S	10.1117/12.841242		8	Engineering, Biomedical; Optics; Radiology, Nuclear Medicine & Medical Imaging	Engineering; Optics; Radiology, Nuclear Medicine & Medical Imaging	BSK55	WOS:000284752400026	
S	Chen, C; Chernoff, K; Karemore, G; Lo, P; Nielsen, M; Lauze, F		Dawant, BM; Haynor, DR		Chen, C.; Chernoff, K.; Karemore, G.; Lo, P.; Nielsen, M.; Lauze, F.			Classification in medical images using adaptive metric k-NN	MEDICAL IMAGING 2010: IMAGE PROCESSING	Proceedings of SPIE		English	Proceedings Paper	Conference on Medical Imaging 2010 - Image Processing	FEB 14-16, 2010	San Diego, CA	SPIE, Medtronic, Inc., Aeroflex, Inc., OpenXi, Tungsten Heavy Powder, Inc.		k-NN; metric; Mahalanobis distance; covariance matrix; cardiovascular disease; mammograms; breast cancer		The performance of the k-nearest neighborhoods (k-NN) classifier is highly dependent on the distance metric used to identify the k nearest neighbors of the query points. The standard Euclidean distance is commonly used in practice. This paper investigates the performance of k-NN classifier with respect to different adaptive metrics in the context of medical imaging. We propose using adaptive metrics such that the structure of the data is better described, introducing some unsupervised learning knowledge in k-NN. We investigated four different metrics are estimated: a theoretical metric based on the assumption that images are drawn from Brownian Image Model (BIM), the normalized metric based on variance of the data, the empirical metric is based on the empirical covariance matrix of the unlabeled data, and an optimized metric obtained by minimizing the classification error. The spectral structure of the empirical covariance also leads to Principal Component Analysis (PCA) performed on it which results the subspace metrics. The metrics are evaluated on two data sets: lateral X-rays of the lumbar aortic/spine region, where we use k-NN for performing abdominal aorta calcification detection; and mammograms, where we use k-NN for breast cancer risk assessment. The results show that appropriate choice of metric can improve classification.	[Chen, C.; Chernoff, K.; Karemore, G.; Lo, P.; Nielsen, M.; Lauze, F.] Univ Copenhagen, DIKU, Copenhagen, Denmark	Chen, C (reprint author), Univ Copenhagen, DIKU, Univ Pk 1, Copenhagen, Denmark.	chen@diku.dk					CHERNOFF K, 2009, THESIS U COPENHAGEN; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; Globerson A, 2006, ADV NEURAL INFORM PR, V19, P451; Goldberger J., 2005, ADV NEURAL INFORM PR, V17, P513; Hastie T, 2009, ELEMENTS STAT LEARNI; Mandelbrot B., 1982, FRACTAL GEOMETRY NAT; Pedersen KS, 2003, LECT NOTES COMPUT SC, V2695, P281; SUZUKI K, 2010, ALGORITHMS, V3; Weinberger K., 2006, P ADV NEUR INF PROC, P1473; Xiang SM, 2008, PATTERN RECOGN, V41, P3600, DOI 10.1016/j.patcog.2008.05.018; Xing E. P., 2002, ADV NEURAL INFORMATI, V15, P505; Yang L, 2007, P SOC PHOTO-OPT INS, V6514, pH5141, DOI 10.1117/12.710076	13	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	978-0-8194-8024-8	PROC SPIE			2010	7623								76230S	10.1117/12.844338		9	Optics; Radiology, Nuclear Medicine & Medical Imaging	Optics; Radiology, Nuclear Medicine & Medical Imaging	BSO04	WOS:000285048800026	
J	Chuang, LY; Yang, CS; Wu, KC; Yang, CH				Chuang, L. -Y.; Yang, C. -S.; Wu, K. -C.; Yang, C. -H.			Correlation-based Gene Selection and Classification Using Taguchi-BPSO	METHODS OF INFORMATION IN MEDICINE			English	Article						Microarray data; correlation-based feature selection; Taguchi-binary particle swarm optimization; K-nearest neighbor	MICROARRAY DATA; CANCER CLASSIFICATION; EXPRESSION; PREDICTION; ALGORITHM; BIOINFORMATICS; IDENTIFICATION; OPTIMIZATION; CLASSIFIERS; INFORMATION	Background: Microarray data with reference to gene expression profiles have provided some valuable results related to a variety of problems, and contributed to advances in clinical medicine. Microarray data characteristically have a high dimension and small sample size, which makes it difficult for a general classification method to obtain correct data for classification. However, not every gene is potentially relevant for distinguishing the sample class. Thus, in order to analyze gene expression profiles correctly, feature (gene) selection is crucial for the classification process, and an effective gene extraction method is necessary for eliminating irrelevant genes and decreasing the classification error rate. Objective: The purpose of gene expression analysis is to discriminate between classes of samples, and to predict the relative importance of each gene for sample classification. Method: In this paper, correlation-based feature selection (CFS) and Taguchi-binary particle swarm optimization (TBPSO) were combined into a hybrid method, and the K-nearest neighbor (K-NN) with leave-one-out cross-validation (LOOCV) method served as a classifier for ten gene expression profiles. Results: Experimental results show that this hybrid method effectively simplifies feature selection by reducing the number of features needed. The classification error rate obtained by the proposed method had the lowest classification error rate for all of the ten gene expression data set problems tested. For six of the gene expression profile data sets a classification error rate of zero could be reached. Conclusion: The introduced method outperformed five other methods from the literature in terms of classification error rate. It could thus constitute a valuable tool for gene expression analysis in future studies.	[Yang, C. -H.] Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, Kaohsiung 807, Taiwan; [Chuang, L. -Y.] I Shou Univ, Inst Biotechnol & Chem Engn, Kaohsiung, Taiwan; [Yang, C. -S.] Natl Cheng Kung Univ, Inst Biomed Engn, Tainan 70101, Taiwan; [Yang, C. -S.] Chiayi Christian Hosp, Dept Plast Surg, Chiayi, Taiwan; [Wu, K. -C.] Natl Kaohsiung Univ Appl Sci, Dept Comp Sci & Informat Engn, Kaohsiung 807, Taiwan; [Yang, C. -H.] Toko Univ, Dept Network Syst, Chiayi, Taiwan	Yang, CH (reprint author), Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, Kaohsiung 807, Taiwan.	chyang@cc.kuas.edu.tw					Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Cawley GC, 2003, PATTERN RECOGN, V36, P2585, DOI 10.1016/S0031-3203(03)00136-5; Chang TC, 2006, INT J ADV MANUF TECH, V31, P164, DOI 10.1007/s00170-005-0180-0; Chen WC, 2008, EXPERT SYST APPL, V35, P843, DOI 10.1016/j.cswa.2007.07.037; Chuang LY, 2008, COMPUT BIOL CHEM, V32, P29, DOI 10.1016/j.compbiolchem.2007.09.005; Conover W, 1980, PRACTICAL NONPARAMET; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deb K, 2003, BIOSYSTEMS, V72, P111, DOI 10.1016/S0303-2647(03)00138-2; Diaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3; Fix E., 1951, TECHNICAL REPORT; Frank E, 2004, BIOINFORMATICS, V20, P2479, DOI 10.1093/bioinformatics/bth261; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hall M.A., 1999, THESIS U WAIKATO; Huang HL, 2007, BIOSYSTEMS, V90, P78, DOI 10.1016/j.biosystems.2006.07.002; Huerta EB, 2006, LECT NOTES COMPUT SC, V3907, P34; Inza I, 2004, ARTIF INTELL MED, V31, P91, DOI 10.1016/j.artmed.2004.01.007; KENNEDY J, 1997, 1997 IEEE INT C SYST, V4105, P4104; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Kodaz H, 2009, EXPERT SYST APPL, V36, P3086, DOI 10.1016/j.eswa.2008.01.026; Kohavi R, 1997, ARTIF INTELL, V1, P273; Kwak N, 2002, IEEE T NEURAL NETWOR, V13, P143, DOI 10.1109/72.977291; Liu H., 1998, FEATURE SELECTION KN; Liu X., 2005, BMC BIOINFORMATICS, V6, P76; Loughrey J., 2005, RES DEV INTELLIGENT, VXXI, P33; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; Okun O, 2009, ARTIF INTELL MED, V45, P151, DOI 10.1016/j.artmed.2008.08.004; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Ramaswamy S, 2003, NAT GENET, V33, P49, DOI 10.1038/ng1060; REUNANEN J, 2003, J MACHINE LEARNING R, V3; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344; SCHAFFER C, 1993, MACH LEARN, V10, P153, DOI 10.1007/BF00993504; Secrest BR, 2003, PROCEEDINGS OF THE 2003 IEEE SWARM INTELLIGENCE SYMPOSIUM (SIS 03), P198, DOI 10.1109/SIS.2003.1202268; Shi XH, 2005, INFORM PROCESS LETT, V93, P255, DOI 10.1016/j.ipl.2004.11.003; Shi YH, 1998, IEEE C EVOL COMPUTAT, P69, DOI 10.1109/ICEC.1998.699146; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Sohn SY, 2007, PATTERN RECOGN, V40, P33, DOI 10.1016/j.patcog.2006.06.027; STONE M, 1974, J R STAT SOC B, V36, P111; Taguchi G, 2000, ROBUST ENG; Tahir MA, 2007, PATTERN RECOGN LETT, V28, P438, DOI 10.1016/j.patrec.2006.08.016; Tan SB, 2006, EXPERT SYST APPL, V30, P290, DOI 10.1016/j.eswa.2005.07.019; Tsai JT, 2004, IEEE T EVOLUT COMPUT, V8, P365, DOI 10.1109/TEVC.2004.826895; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Verron S, 2008, J PROCESS CONTR, V18, P479, DOI 10.1016/j.jprocont.2007.08.003; Wang XY, 2007, PATTERN RECOGN LETT, V28, P459, DOI 10.1016/j.patrec.2006.09.003; Wang Y, 2005, COMPUT BIOL CHEM, V29, P37, DOI 10.1016/j.compbiolchem.2004.11.001; WOLPERT DH, 1993, SFITR92035001; Wu Y., 2000, TAGUCHI METHODS ROBU; Xiong MM, 2001, GENOME RES, V11, P1878; Yang CH, 2008, LECT NOTES COMPUT SC, V5326, P112; YANG CS, IJCNN 2008, P2147; Zhu ZX, 2007, IEEE T SYST MAN CY B, V37, P70, DOI 10.1109/TSMCB.2006.883267	54	4	4	SCHATTAUER GMBH-VERLAG MEDIZIN NATURWISSENSCHAFTEN	STUTTGART	HOLDERLINSTRASSE 3, D-70174 STUTTGART, GERMANY	0026-1270		METHOD INFORM MED	Methods Inf. Med.		2010	49	3					254	268		10.3414/ME09-01-0010		15	Computer Science, Information Systems; Health Care Sciences & Services; Medical Informatics	Computer Science; Health Care Sciences & Services; Medical Informatics	611MC	WOS:000278818400006	
S	Hoelzl, G		Phan, T; Montanari, R; Zerfos, P		Hoelzl, Gerold			A Personalised Body Motion Sensitive Training System Based on Auditive Feedback	MOBILE COMPUTING, APPLICATIONS AND SERVICES	Lecture Notes of the Institute for Computer Sciences Social Informatics and Telecommunications Engineering		English	Proceedings Paper	1st International Conference on Mobile Computing, Applications, and Services (MobiCASE 2009)	OCT 26-29, 2009	San Diego, CA	ICST				In this paper the architecture and functionality of a personalized body motion sensitive training system based on auditive feedback is discussed. The system supports recognition of body motion using body worn sensors and gives the user feedback about his or her current status in adaptively selecting audio files accompanying the speed and path of exercise.	Johannes Kepler Univ Linz, A-4040 Linz, Austria	Hoelzl, G (reprint author), Johannes Kepler Univ Linz, A-4040 Linz, Austria.	gerold.hoelzl@gmail.com					Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1; Beigl M., 2004, P 1 INT WORKSH NETW, P153; Bringmann B, 2005, LECT NOTES ARTIF INT, V3721, P46; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dideles M., 2003, CROSSROADS, V9; Estrin D., 2002, IEEE Pervasive Computing, V1, DOI 10.1109/MPRV.2002.993145; Gemperle F., 1998, INT S WEAR COMP, P116; Hainsworth S.W., 2003, TECHNIQUES AUTOMATED; Hay JG, 1978, BIOMECHANICS SPORTS; Heinz E. A., 2006, P 2 IEEE S COMP INT, P98; Jensen K., 2003, APPL SIGNAL PROCESSI, P87; Krassi B.A., 2001, P 12 C EXTR ROB; Lee S.-W., 2001, CONTROL APPL 2001 CC, P1152; Lukowicz P., 2002, WEAR COMP IEEE INT S, P133; Lukowicz P, 2004, LECT NOTES COMPUT SC, V3001, P18; Lukowicz P, 2006, LECT NOTES COMPUT SC, V3968, P101	16	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1867-8211	978-3-642-12606-2	L N INST COMP SCI SO			2010	35						12	25				14	Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods; Telecommunications	Computer Science; Telecommunications	BBJ27	WOS:000307044100002	
S	Rafique, U; Huang, SY		Dix, J; Witteveen, C		Rafique, Umair; Huang, Shell Ying			Preference Generation for Autonomous Agents	MULTIAGENT SYSTEM TECHNOLOGIES	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	8th International Workshop on Multi-Agent Systems Technologies	SEP 27-29, 2010	Leipzig, GERMANY			Autonomous Agents; BDI; Goal Generation; Preference Generation	LEARNING ALGORITHMS	An intelligent agent situated in an environment needs to know the preferred states it is expected to achieve or maintain so that it can work towards achieving or maintaining them. We refer to all these preferred states as "preferences". The preferences an agent has selected to bring about at a given time are called "goals". This selection of preferences as goals is generally referred to as "goal generation". Basic aim behind goal generation is to provide the agent with a way of getting new goals. Although goal generation results in an increase in the agent's knowledge about its goals, the overall autonomy of the agent does not increase as its goals are derived from its preferences (which are programmed). We argue that to achieve greater autonomy, an agent must be able to generate new preferences. In this paper we discuss how an agent can generate new preferences based on analogy between new objects and the objects it has known preferences for.	[Rafique, Umair; Huang, Shell Ying] Nanyang Technol Univ, Sch Comp Engn, Singapore, Singapore	Rafique, U (reprint author), Nanyang Technol Univ, Sch Comp Engn, Singapore, Singapore.	umai0001@ntu.edu.sg; assyhuang@ntu.edu.sg					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Bratman M., 1987, INTENTION PLANS PRAC; Broersen J., 2002, COGNITIVE SCI Q, V2, P428; Clement B. J., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DIGNUM F, 2002, COGNITIVE SCI Q, V2; Maslow AH, 1954, MOTIVATION PERSONALI; PEREIRA CD, 2008, P AAMAS 08 IFAAMAS, P397; RAFIQUE U, 2009, P ICAI 09, V2, P582; Reiss S, 2004, REV GEN PSYCHOL, V8, P179, DOI 10.1037/1089-2680.8.3.179; SIMON HA, 1967, PSYCHOL REV, V74, P29, DOI 10.1037/h0024127; Simpson R, 2006, LECT NOTES COMPUT SC, V4008, P71; THANGARAJAH J, 2007, CP 07 WORKSH CONSTR; Thangarajah J., 2003, P 18 INT JOINT C ART, P721; THANGARAJAH J, 2002, AUSTR COMPUTER SCI C, V24, P259; Thomason R. H., 2000, P 7 INT C PRINC KNOW, P702; van Riemsdijk M.B., 2008, P 7 INT C AUT AG MUL, P713; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; Winikoff M, 2003, P 2 INT JOINT C AUT, P401	20	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-16177-3	LECT NOTES ARTIF INT			2010	6251						173	184				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BUF32	WOS:000289106100017	
J	Temel, T				Temel, Turgay			A NEW DIGITAL COCHLEA MODEL NEURO-SPIKE REPRESENTATION OF AUDITORY SIGNALS AND ITS APPLICATION TO CLASSIFICATION OF BAT-LIKE BIOSONAR ECHOES	NEURAL NETWORK WORLD			English	Article						Audio processing systems; pattern recognition and classification; cochlea model; spike coding	STATISTICS; TRAINS	For an improved neuro-spike representation of auditory signals within cochlea models, a new digital ARMA-type low-pass filter structure is proposed. It is compared to more conventional AR-type counterpart on a classification of biosonar echoes, in which echoes from various tree species insonified with a bat-like chirp call are converted to biologically plausible feature vectors. Next, parametric and non-parametric models of the class-conditional densities are built from the echo feature vectors. The models are deployed in single-shot and sequential-decision classification algorithms. The results indicate that the proposed ARMA filter structure offers an improved single-echo classification performance, which leads to faster sequential-decision making than its AR-type counterpart.	Bahcesehir Univ, Fac Engn, TR-34349 Istanbul, Turkey	Temel, T (reprint author), Bahcesehir Univ, Fac Engn, TR-34349 Istanbul, Turkey.	turgaytemel@hotmail.com					AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Bishop C. M., 2006, PATTERN RECOGNITION; Carmena JM, 2004, INFORM SCIENCES, V161, P71, DOI 10.1016/j.ins.2003.03.009; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dau T, 1996, J ACOUST SOC AM, V99, P3615, DOI 10.1121/1.414959; DAVIS S, 1980, IEEE T ACOUST SPEECH, V4, P357; Dempster A. P., 1977, J ROYAL STAT SOC B, V39, DOI DOI 10.2307/2984875; Destexhe A, 2004, NATURE, V431, P789, DOI 10.1038/nature03011; Dragalin VP, 1999, IEEE T INFORM THEORY, V45, P2448, DOI 10.1109/18.796383; ELLIOT P, 2004, BIOL CONSERV, V120, P600, DOI 10.1016/j.biocon.2004.04.001; GONG G, 1986, J AM STAT ASSOC, V81, P108, DOI 10.2307/2287975; Grunwald JE, 2004, P NATL ACAD SCI USA, V101, P5670, DOI 10.1073/pnas.0308029101; Hafner V, 2005, ADAPT BEHAV, V13, P87, DOI 10.1177/105971230501300202; Kim SM, 2003, J ACOUST SOC AM, V114, P3179, DOI 10.1121/1.1624070; Kuc R, 2001, J ACOUST SOC AM, V110, P2198, DOI 10.1121/1.1401741; LLYOD SP, 1982, IEEE T INFORM THEORY, V28, P129; Lyon R. F., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing; LYON RF, 1988, IEEE T ACOUST SPEECH, V36, P1119, DOI 10.1109/29.1639; MEDDIS R, 1986, J ACOUST SOC AM, V79, P702, DOI 10.1121/1.393460; Mino H, 2007, IEEE T BIO-MED ENG, V54, P360, DOI 10.1109/TBME.2006.890486; MOORE GP, 1970, BIOPHYS J, V10, P876; MULLER R, 2003, NETWORK-COMP NEURAL, V14, P596; MULLER R, 2000, P ICSC S INT SYST AP, P915; PATTERSON RD, 1996, ADV SPEECH HEARING L, V3; PERKEL DH, 1967, BIOPHYS J, V7, P419; RISSANEN J, 1986, ANN STAT, V14, P1080, DOI 10.1214/aos/1176350051; Roxin A, 2008, J NEUROSCI, V28, P10734, DOI 10.1523/JNEUROSCI.1016-08.2008; SANDERSO.AC, 1973, BIOPHYS J, V13, P218; Sanderson MI, 2003, J ACOUST SOC AM, V114, P1648, DOI 10.1121/1.1598195; Scott A, 2002, NEUROSCIENCE MATH PR; Slaney M., 1993, VISUAL REPRESENTATIO, P95; Tetzlaff T, 2008, NEURAL COMPUT, V20, P2133, DOI 10.1162/neco.2008.05-07-525; WANG M, 2006, THESIS U TUEBINGEN G; Zeddies DG, 2004, J ACOUST SOC AM, V116, P426, DOI 10.1121/1.1755237	34	0	0	ACAD SCIENCES CZECH REPUBLIC, INST COMPUTER SCIENCE	182 07 PRAGUE 8	POD VODARENSKOU VEZI 2, 182 07 PRAGUE 8, 00000, CZECH REPUBLIC	1210-0552		NEURAL NETW WORLD	Neural Netw. World		2010	20	2					223	239				17	Computer Science, Artificial Intelligence	Computer Science	593EA	WOS:000277434000004	
J	Boostani, R; Dehzangi, O; Jarchi, D; Zolghadri, MJ				Boostani, Reza; Dehzangi, Omid; Jarchi, Delaram; Zolghadri, Mansoor J.			AN EFFICIENT PATTERN CLASSIFICATION APPROACH: COMBINATION OF WEIGHTED LDA WITH WEIGHTED NEAREST NEIGHBOR	NEURAL NETWORK WORLD			English	Article						LDA; PCA; weighted nearest neighbor (WNN); weighted LDA (WLDA)	FACE RECOGNITION; RULE	Linear discriminant analysis (LDA) is a versatile method in all pattern recognition fields but it suffers from some limitations. In a multi-class problem, when samples of a class are far from other classes samples, it leads to bias of the whole decision boundaries of LDA in favor of the farthest class. To overcome this drawback, this study is aimed at minimizing this bias by redefining the between- and within-class scatter matrices via incorporating weight vectors derived from Fisher value of classes pairs. After projecting the input patterns into a lower-dimensional space in which the class samples are more separable, a new version of nearest neighbor (NN) method with an adaptive distance measure is employed to classify the transformed samples. To speed up the adaptive distance routine, an iterative learning algorithm that minimizes the error rate is presented. This efficient method is applied to six standard datasets driven from the UCI repository dataset and test results are evaluated from three aspects in terms of accuracy, robustness, and complexity. Results show the supremacy of the proposed two-layer classifier in comparison with the combination of different versions of LDA and NN methods from the three points of view. Moreover, the proposed classifier is assessed in the noisy environment of those datasets and the achieved results confirm the high robustness of the introduced scheme when compared to others.	[Boostani, Reza; Dehzangi, Omid; Jarchi, Delaram; Zolghadri, Mansoor J.] Shiraz Univ, Fac Elect & Comp Engn, Shiraz, Iran	Boostani, R (reprint author), Shiraz Univ, Fac Elect & Comp Engn, Shiraz, Iran.	boostani@shirazu.ac.ir; dehzangi@cse.shirazu.ac.ir; jarchi@cse.shirazu.ac.ir; zjahromi@shirazu.ac.ir					Asuncion A., 2007, UCI MACHINE LEARNING; BAILEY, 1978, IEEE T SYST MAN CYB, V8, P311; Chakrabarti S, 2003, VLDB J, V12, P170, DOI 10.1007/s00778-003-0098-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, NEAREST NEIGHBOR NN; Duda R. O., 2001, PATTERN CLASSIFICATI; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fukunaga K., 1990, INTRO STAT PATTERN C; Goldberger J., 2004, NEURAL INFORM PROCES, V17, P513; JARCHI D, 2006, T ENG COMPUTATIONAL, V18, P18; Jin Z, 2001, PATTERN RECOGN, V34, P1405, DOI 10.1016/S0031-3203(00)00084-4; Jing XY, 2004, IEEE T SYST MAN CY B, V34, P1942, DOI 10.1109/TSMCB.2004.831770; LETTE F, 2007, J NEURAL ENG, V4, pR1; Loog M, 2001, IEEE T PATTERN ANAL, V23, P762, DOI 10.1109/34.935849; MACLEOD JES, 1987, IEEE T SYST MAN CYB, V17, P689, DOI 10.1109/TSMC.1987.289362; Pang YW, 2006, NEUROCOMPUTING, V69, P949, DOI 10.1016/j.neucom.2005.07.005; RASSON JP, 2000, J NEURAL NETWORK WOR, V10, P279; Sanz SS, 2009, NEURAL NETW WORLD, V19, P37; Wang Jing, 2006, Cancer Inform, V2, P87; Wang JG, 2007, PATTERN RECOGN LETT, V28, P207, DOI 10.1016/j.patrec.2006.07.002; Wang JG, 2006, PATTERN RECOGN, V39, P417, DOI 10.1016/j.patcog.2005.08.009; WEINBERGER K, 2006, ADV NEURAL INFORM PR, P18; Ye JP, 2004, IEEE T PATTERN ANAL, V26, P982; Zuo WM, 2006, IEEE T SYST MAN CY B, V36, P946, DOI 10.1109/TSMCB.2005.863377	25	1	1	ACAD SCIENCES CZECH REPUBLIC, INST COMPUTER SCIENCE	182 07 PRAGUE 8	POD VODARENSKOU VEZI 2, 182 07 PRAGUE 8, 00000, CZECH REPUBLIC	1210-0552		NEURAL NETW WORLD	Neural Netw. World		2010	20	5					621	635				15	Computer Science, Artificial Intelligence	Computer Science	689GM	WOS:000284915500004	
B	Ballabio, D; Todeschini, R		Preedy, VR; Watson, RR		Ballabio, Davide; Todeschini, Roberto			Geographical Characterization of Olive Oil by Means of Multivariate Classification: Application of CAIMAN	OLIVES AND OLIVE OIL IN HEALTH AND DISEASE PREVENTION			English	Article; Book Chapter							INFLUENCE MATRIX ANALYSIS; PATTERN-RECOGNITION; ELECTRONIC NOSE; DISCRIMINATION; ORIGIN		[Ballabio, Davide; Todeschini, Roberto] Univ Milano Bicocca, Dept Environm Sci, Milano Chemometr & QSAR Res Grp, I-20126 Milan, Italy	Ballabio, D (reprint author), Univ Milano Bicocca, Dept Environm Sci, Milano Chemometr & QSAR Res Grp, Pda Sci 1, I-20126 Milan, Italy.						Alves MR, 2005, ANAL CHIM ACTA, V549, P166, DOI 10.1016/j.aca.2005.06.033; ARMANINO C, 1989, CHEMOMETR INTELL LAB, V5, P343, DOI 10.1016/0169-7439(89)80034-6; Ballabio D, 2006, ANAL CHIM ACTA, V570, P249, DOI 10.1016/j.aca.2006.04.029; Barker M, 2003, J CHEMOMETR, V17, P166, DOI 10.1002/cem.785; Cook R. D., 1982, RESIDUAL INFLUENCE R; Cosio MS, 2006, ANAL CHIM ACTA, V567, P202, DOI 10.1016/j.aca.2006.03.035; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EDDIB O, 1987, ANALYST, V112, P391, DOI 10.1039/an9871200391; FORINA M., 1983, FOOD RES DATA ANAL, P189; Guadarrama A, 2001, ANAL CHIM ACTA, V432, P283, DOI 10.1016/S0003-2670(00)01383-0; Kohonen T., 1988, SELF ORG ASS MEMORY; KOWALSKI BR, 1972, ANAL CHEM, V44, P1405, DOI 10.1021/ac60316a008; Lanteri S, 2002, FOOD CHEM, V76, P501, DOI 10.1016/S0308-8146(01)00370-3; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Oliveros CC, 2005, J CHROMATOGR A, V1076, P7, DOI 10.1016/j.chroma.2005.04.020; Todeschini R, 2007, CHEMOMETR INTELL LAB, V87, P3, DOI 10.1016/j.chemolab.2005.11.001; Wold H., 1966, MULTIVARIATE ANAL, P391; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5; Zupan J., 1994, ACTA CHIM SLOV, V41, P327	19	0	0	ELSEVIER ACADEMIC PRESS INC	SAN DIEGO	525 B STREET, SUITE 1900, SAN DIEGO, CA 92101-4495 USA		978-0-08-092220-1				2010							129	137		10.1016/B978-0-12-374420-3.00016-4		9	Food Science & Technology; Nutrition & Dietetics	Food Science & Technology; Nutrition & Dietetics	BCR84	WOS:000311115400017	
S	Sreenivasulu, N; Sunkar, R; Wobus, U; Strickert, M		Sunkar, R		Sreenivasulu, Nese; Sunkar, Ramanjulu; Wobus, Ulrich; Strickert, Marc			Array Platforms and Bioinformatics Tools for the Analysis of Plant Transcriptome in Response to Abiotic Stress	PLANT STRESS TOLERANCE: METHODS AND PROTOCOLS	Methods in Molecular Biology		English	Article; Book Chapter						Array technology; microarrays; macroarrays; transcriptome analysis; bioinformatics tools; abiotic stress	GENE-EXPRESSION ANALYSIS; LENGTH CDNA MICROARRAY; ARABIDOPSIS-THALIANA; COLD-STRESS; OLIGONUCLEOTIDE MICROARRAYS; MESSENGER-RNA; DROUGHT; TOLERANCE; DATABASE; DISPLAY	Current microarray technologies allow high-density in situ synthesis of oligonucleotides or ex situ spotting of target molecules (cDNA) for conducting genome-wide comparative gene expression profiling studies. The avalanche of available microarray gene expression data from model plant species covering cell-related, tissue-specific, and developmental events, as well as perturbations to a variety of environmental stimuli has triggered many activities regarding the development of adequate bioinformatics tools for the analysis of these complex data sets. In this chapter we summarize the technical issues of different microarray technologies, discuss the availability of bioinformatics tools, and present approaches to extract biologically meaningful knowledge. For case studies of abiotic stress transcriptome analysis we highlight the unprecedented opportunities provided by these high-throughput technologies to understand networks of regulatory and metabolic pathway responses of plant cells to the application of abiotic stress stimuli.	[Sreenivasulu, Nese; Wobus, Ulrich; Strickert, Marc] Leibniz Inst Plant Genet & Crop Plant Res IPK, Gatersleben, Germany; [Sunkar, Ramanjulu] Oklahoma State Univ, Dept Biochem & Mol Biol, Stillwater, OK 74078 USA	Sreenivasulu, N (reprint author), Leibniz Inst Plant Genet & Crop Plant Res IPK, Gatersleben, Germany.	ramanjulu.sunkar@okstate.edu; ramanjulu.sunkar@okstate.edu					Abdi H, 2007, ENCY MEASUREMENT STA, P1; Aceituno FF, 2008, BMC GENOMICS, V9, DOI 10.1186/1471-2164-9-438; Balasubramaniyan R, 2005, BIOINFORMATICS, V21, P1069, DOI 10.1093/bioinformatics/bti095; Bar-Joseph Z, 2001, Bioinformatics, V17 Suppl 1, pS22; Barrett T, 2006, METHOD ENZYMOL, V411, P352, DOI 10.1016/S0076-6879(06)11019-8; Bell GW, 2006, METHOD ENZYMOL, V411, P408, DOI 10.1016/S0076-6879(06)11022-8; Berger Dave K., 2007, V382, P177, DOI 10.1007/978-1-59745-304-2_12; Bohnert HJ, 2006, CURR OPIN PLANT BIOL, V9, P180, DOI 10.1016/j.pbi.2006.01.003; Bolstad BM, 2003, BIOINFORMATICS, V19, P185, DOI 10.1093/bioinformatics/19.2.185; Breitkreutz BJ, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-3-r22; Cheng Y., 2000, P 8 INT C INT SYST M, P93; Chou Cheng-Chung, 2007, V381, P213; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAIGON DJ, 2004, NUCLEIC ACIDS RES, V32, P575; de Hoon MJL, 2004, BIOINFORMATICS, V20, P1453, DOI 10.1093/bioinformatics/bth078; Denby K, 2005, TRENDS BIOTECHNOL, V23, P547, DOI 10.1016/j.tibtech.2005.09.001; Dinneny JR, 2008, SCIENCE, V320, P942, DOI 10.1126/science.1153795; Azuaje F, 2005, DATA ANALYSIS AND VISUALIZATION IN GENOMICS AND PROTEOMICS, P1, DOI 10.1002/0470094419; Durbin B P, 2002, Bioinformatics, V18 Suppl 1, pS105; Durinck Steffen, 2008, V452, P89, DOI 10.1007/978-1-60327-159-2_4; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; FODOR SPA, 1991, SCIENCE, V251, P767, DOI 10.1126/science.1990438; Fontana P, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004619; Hazen Samuel P., 2003, Functional & Integrative Genomics, V3, P105, DOI 10.1007/s10142-003-0088-4; Horan K, 2008, PLANT PHYSIOL, V147, P41, DOI 10.1104/pp.108.117366; Irizarry RA, 2003, NUCLEIC ACIDS RES, V31, DOI 10.1093/nar/gng015; KATO K, 1995, NUCLEIC ACIDS RES, V23, P3685, DOI 10.1093/nar/23.18.3685; Kilian J, 2007, PLANT J, V50, P347, DOI 10.1111/j.1365-313X.2007.03052.x; Knudsen S, 2004, GUIDE ANAL DNA MICRO; Kreps JA, 2002, PLANT PHYSIOL, V130, P2129, DOI 10.1104/pp.008532; Lee JA, 2007, INFORM SCI STAT, P1; Leek JT, 2006, BIOINFORMATICS, V22, P507, DOI 10.1093/bioinformatics/btk005; Lescallett Jennifer, 2004, V258, P71; LIANG P, 1992, SCIENCE, V257, P967, DOI 10.1126/science.1354393; Lister R, 2009, CURR OPIN PLANT BIOL, V12, P107, DOI 10.1016/j.pbi.2008.11.004; Ma SS, 2007, GENOME BIOL, V8, DOI 10.1186/gb-2007-8-4-r49; Ma SS, 2007, GENOME RES, V17, P1614, DOI 10.1101/gr.6911207; MACK GA, 1981, J AM STAT ASSOC, V76, P175, DOI 10.2307/2287064; Manfield IW, 2006, NUCLEIC ACIDS RES, V34, pW504, DOI 10.1093/nar/gkl204; MCQUITTY LL, 1966, EDUC PSYCHOL MEAS, V26, P825, DOI 10.1177/001316446602600402; Mentzen WI, 2008, BMC PLANT BIOL, V8, DOI 10.1186/1471-2229-8-99; Parkinson H, 2009, NUCLEIC ACIDS RES, V37, pD868, DOI 10.1093/nar/gkn889; Seki M, 2002, PLANT J, V31, P279, DOI 10.1046/j.1365-313X.2002.01359.x; Seki M, 2001, PLANT CELL, V13, P61, DOI 10.1105/tpc.13.1.61; Shi LM, 2006, NAT BIOTECHNOL, V24, P1151, DOI 10.1038/nbt1239; Spannagl M, 2007, NUCLEIC ACIDS RES, V35, pD834, DOI 10.1093/nar/gkl945; Sreenivasulu N, 2002, MOL GENET GENOMICS, V266, P758, DOI 10.1007/s00438-001-0614-9; Sreenivasulu N, 2007, GENE, V388, P1, DOI 10.1016/j.gene.2006.10.009; Sreenivasulu N, 2008, PLANT PHYSIOL, V146, P1738, DOI 10.1104/pp.107.111781; SREENIVASULU N, CURRENT SCI, V83, P965; STRICKERT M, 2007, BMC BIOINFORMATICS, V8; Sunkar R, 2007, TRENDS PLANT SCI, V12, P301, DOI 10.1016/j.tplants.2007.05.001; Thimm O, 2004, PLANT J, V37, P914, DOI 10.1111/j.1365-313X.2004.02016.x; ULTSCH A, 2004, P EUR S ART NEUR NET, P501; USADEL B, 2006, BMC BIOINFORMATICS, V7, P1436; VELCULESCU VE, 1995, SCIENCE, V270, P484, DOI 10.1126/science.270.5235.484; Weston DJ, 2008, BMC SYST BIOL, V2, DOI 10.1186/1752-0509-2-16; Wise Roger P., 2007, V406, P347; XIE Y, 2002, P 35 S INT COMP SCI; Yamaguchi-Shinozaki K, 2005, TRENDS PLANT SCI, V10, P88, DOI 10.1016/j.tplanys.2004.12.012; Yeung KY, 2001, BIOINFORMATICS, V17, P763, DOI 10.1093/bioinformatics/17.9.763; Zeller G, 2009, PLANT J, V58, P1068, DOI 10.1111/j.1365-313X.2009.03835.x; Zhang JD, 2009, BIOINFORMATICS, V25, P1470, DOI 10.1093/bioinformatics/btp167; Zimmermann P, 2004, PLANT PHYSIOL, V136, P2621, DOI 10.1104/pp.104.046367	64	4	5	HUMANA PRESS INC	TOTOWA	999 RIVERVIEW DR, STE 208, TOTOWA, NJ 07512-1165 USA	1064-3745	978-1-60761-701-3	METHODS MOL BIOL	Methods Mol. Biol.		2010	639						71	93		10.1007/978-1-60761-702-0_5	10.1007/978-1-60761-702-0	23	Biochemical Research Methods; Biochemistry & Molecular Biology; Plant Sciences	Biochemistry & Molecular Biology; Plant Sciences	BOZ44	WOS:000278106400005	
B	Zhao, X; Saeedi, S; El-Sheimy, N; Syed, Z; Goodall, C			ION	Zhao, X.; Saeedi, S.; El-Sheimy, N.; Syed, Z.; Goodall, C.			Towards Arbitrary Placement of Multi-sensors Assisted Mobile Navigation System	PROCEEDINGS OF THE 23RD INTERNATIONAL TECHNICAL MEETING OF THE SATELLITE DIVISION OF THE INSTITUTE OF NAVIGATION (ION GNSS 2010)			English	Proceedings Paper	23rd International Technical Meeting of the Satellite Division of the Institute-of-Navigation (ION GNSS-2010)	SEP 21-24, 2010	Portland, OR					Multi-sensors assisted navigation system is one of the most promising solutions for GPS-denied areas. However, as the portable positioning device can be arbitrarily placed on the user's body, it violates the assumed condition of sensor enabled positioning: the alignment. This poses great challenge since sensors 'placement greatly impacts on the positioning solution. The paper attempts to solve this problem by classifying the placement mode from the accelerometer and gyro signals. Then the system adapts proper pedestrian dead reckoning algorithms according to the identified device placement. Six commonly used placement modes including belt, pocket, backpack, in-hand dangling, messaging and near the ear talking are considered as the study cases in this paper. Simple time and frequency domain features are extracted from the inertial sensors then some machine learning algorithms, such as k-nearest neighbour, artificial neural networks, and support vector machines are applied for classification. Subsequently, step detections can be conducted by selecting the most appropriate sensor. Stride length and heading can be further estimated. From some preliminary field test results, the placement-aware solution shows significant improvement over conventional pedestrian solutions. The system fits for a variety of applications in the mass market, such as E-911, personnel/patient monitoring, indoor positioning, and many other location-based services.	[Zhao, X.; Saeedi, S.; Syed, Z.] Univ Calgary, MMSS Res Grp, Dept Geomat Engn, Calgary, AB T2N 1N4, Canada	Zhao, X (reprint author), Univ Calgary, MMSS Res Grp, Dept Geomat Engn, Calgary, AB T2N 1N4, Canada.						BEGG R, 2006, COMPUTATIONAL INTELL, P243; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FOODY GM, 2004, TRANSACTIONS, V42, P1335; KWAKKEL S, 2008, 20279 UCGE; MOGHAVVEMI M, 2000, POWER, V28, P167; Shin E. H., 2005, 20219 UCGE; SYED ZF, 2009, 20288 UCGE; Zhao X., 2009, ION GNSS 2009 SAV GA	8	0	0	INST NAVIGATION	WASHINGTON	815 15TH ST NW, STE 832, WASHINGTON, DC 20005 USA						2010							556	564				9	Remote Sensing	Remote Sensing	BUY82	WOS:000290734900046	
B	Jin, X; Mukherjee, K; Gupta, S; Ray, A			ASME	Jin, Xin; Mukherjee, Kushal; Gupta, Shalabh; Ray, Asok			WAVELET-BASED FEATURE EXTRACTION FOR BEHAVIOR RECOGNITION IN MOBILE ROBOTS	PROCEEDINGS OF THE ASME DYNAMIC SYSTEMS AND CONTROL CONFERENCE 2010, VOL 1			English	Proceedings Paper	ASME Dynamic Systems and Control Conference	SEP 12-15, 2010	Cambridge, MA				TIME-SERIES ANALYSIS	This paper introduces a dynamic data-driven method for behavior recognition in mobile robots. The core concept of the paper is built upon the principle of symbolic dynamic filtering (SDF) that is used to extract relevant information in complex dynamical systems. The objective here is to identify the robot behavior from time-series data of piezoelectric sensor signals from the pressure sensitive floor in a laboratory environment. A symbolic feature extraction method is presented by partitioning of two-dimensional wavelet images of sensor time-series data. The K-nearest neighbors (k-NN) algorithm is used to identify the patterns extracted by SDF. The proposed method is validated by experimentation, on a networked robotics test bed to detect and identify the type and motion profile of mobile robots.	[Jin, Xin; Mukherjee, Kushal; Gupta, Shalabh; Ray, Asok] Penn State Univ, Dept Mech Engn, University Pk, PA 16802 USA	Ray, A (reprint author), Penn State Univ, Dept Mech Engn, University Pk, PA 16802 USA.	xuj103@psu.edu; kum162@psu.edu; szg107@psu.edu; axr2@psu.edu					Abry P., 1997, ONDELETTES TURBULENC; Buhl M, 2005, PHYS REV E, V71, DOI 10.1103/PhysRevE.71.046213; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fukunaga K., 1990, STAT PATTERN RECOGNI; Gerkey BP, 2003, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS 2003, VOL 1-3, P317; Gupta S, 2009, J STAT PHYS, V134, P337, DOI 10.1007/s10955-009-9679-3; Gupta S., 2007, PATTERN RECOGN, P17; Gupta S, 2007, MECH SYST SIGNAL PR, V21, P866, DOI 10.1016/j.ymssp.2005.08.022; Lee T.W., 1998, INDEPENDENT COMPONEN; Lind D.A., 1995, INTRO SYMBOLIC DYNAM; Mallat S, 2009, WAVELET TOUR OF SIGNAL PROCESSING: THE SPARSE WAY, P1; Pittner S, 1999, IEEE T PATTERN ANAL, V21, P83, DOI 10.1109/34.745739; Rajagopalan V, 2006, SIGNAL PROCESS, V86, P3309, DOI 10.1016/j.sigpro.2006.01.014; Ray A., 2008, APPL PHYS LETT, V92; Ray A, 2004, SIGNAL PROCESS, V84, P1115, DOI 10.1016/j.sigpro.2004.03.011; Ray S, 2001, NEURAL NETWORKS FOR SIGNAL PROCESSING XI, P233, DOI 10.1109/NNSP.2001.943128; Rosipal R, 2000, PERSP NEURAL COMP, P321	17	0	0	AMER SOC MECHANICAL ENGINEERS	NEW YORK	THREE PARK AVENUE, NEW YORK, NY 10016-5990 USA		978-0-7918-4417-5				2010							875	882				8	Automation & Control Systems; Engineering, Multidisciplinary	Automation & Control Systems; Engineering	BFG61	WOS:000319789100113	
S	Coelho, F; Braga, AP; Verleysen, M		Bloch, I; Cesar, RM		Coelho, Frederico; Braga, Antonio Padua; Verleysen, Michel			Multi-Objective Semi-Supervised Feature Selection and Model Selection Based on Pearson's Correlation Coefficient	PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS, COMPUTER VISION, AND APPLICATIONS	Lecture Notes in Computer Science		English	Proceedings Paper	15th Iberoamerican Congress on Pattern Recognition	NOV 08-11, 2010	Sao Paulo, BRAZIL	Brazilian Bioethanol Sci & Technol Lab, Brazilian Neural Networks Soc, Coordenacao Aperfeicoamento Pessoal Nivel Superior, Chilean Assoc Pattern Recognit, Natl Council Technol & Sci Dev, Cuban Assoc Pattern Recognit, Fundacao Amparo Pesquisa Estado Sao Paulo, Fed Univ ABC, Int Assoc Pattern Recognit, Inst Telecom, Telecom ParisTech, Mexican Assoc Comp Vision, Neural Comp & Robot, Portuguese Assoc Pattern Recognition, Spanish Assoc Pattern Recognit & Image Anal, Brazilian Comp Soc, Special Interest Grp Pattern Recognit, Univ Sao Paulo		Semi-supervised; feature selection; Pearson; Relief	CLASSIFICATION	This paper presents a Semi-Supervised Feature Selection Method based on a univariate relevance measure applied to a multiobjective approach of the problem. Along the process of decision of the optimal solution within Pareto-optimal set, atempting to maximize the relevance indexes of each feature, it is possible to determine a minimum set of relevant features and, at the same time, to determine the optimal model of the neural network.	[Coelho, Frederico; Braga, Antonio Padua] Univ Fed Minas Gerais, Belo Horizonte, MG, Brazil	Coelho, F (reprint author), Univ Fed Minas Gerais, Belo Horizonte, MG, Brazil.	fredgfc@ufmg.br; apbraga@ufmg.br; michel.verleysen@uclouvain.be	Braga, Antonio/A-2912-2008	Braga, Antonio/0000-0002-9007-0920			Belkin M, 2004, MACH LEARN, V56, P209, DOI 10.1023/B:MACH.0000033120.25363.1e; BLAND RG, 1981, OPER RES, V29, P1039, DOI 10.1287/opre.29.6.1039; Chankong V., 1983, MULTIOBJECTIVE DECIS; Chapelle O., 2006, SEMISUPERVISED LEARN; COELHO F, 2010, SOFT COMPUTING FUSIO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dy JG, 2004, J MACH LEARN RES, V5, P845; Fisher RA, 1936, ANN EUGENIC, V7, P179; KASABOV N, 2004, P INT C NEUR NETW SI; KIRA K, 1992, MACHINE LEARNING /, P249; KIRA K, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P129; LAWLER EL, 1966, OPER RES, V14, P699, DOI 10.1287/opre.14.4.699; Le Cun Y, 1990, ADV NEURAL INFORMATI, V2, P598; Liang F, 2007, STAT SCI, V22, P189, DOI 10.1214/088342307000000032; Malerba D, 2009, ENG APPL ARTIF INTEL, V22, P109, DOI 10.1016/j.engappai.2008.04.005; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133; Parma GG, 2003, INT J ADAPT CONTROL, V17, P501, DOI 10.1002/acs.758; Press W. H., 1992, NUMERICAL RECIPES C; Teixeira RD, 2000, NEUROCOMPUTING, V35, P189, DOI 10.1016/S0925-2312(00)00327-1; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Vapnik V.N., 1995, NATURE STAT LEARNING; Wang JH, 2009, J MACH LEARN RES, V10, P719; Wish M., 1978, MULTIDIMENSIONAL SCA; WU J, 2009, LNCS LNAI, V5446, P345; Zhang D., 2007, SIAM DATA MINING, P629	25	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-16686-0	LECT NOTES COMPUT SC			2010	6419						509	516				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BUV07	WOS:000290420500067	
J	Yang, L; Xia, JF; Gui, J				Yang, Lei; Xia, Jun-Feng; Gui, Jie			Prediction of Protein-Protein Interactions from Protein Sequence Using Local Descriptors	PROTEIN AND PEPTIDE LETTERS			English	Article; Proceedings Paper	5th International Conference on Intelligent Computing	SEP 16-19, 2009	Ulsan, SOUTH KOREA	IEEE Computat Intelligence Soc, Int Neural Network Soc, Natl Nat Sci Fdn China		Feature representation; KNNs; local descriptors; PPIs prediction; protein sequence; sequence-based method	RESIDUE CONSERVATION; INTERACTION SITES; CLASSIFICATION; INFORMATION	With a huge amount of protein sequence data, the computational method for protein-protein interaction (PPI) prediction using only the protein sequences information have drawn increasing interest. In this article, we propose a sequence-based method based on a novel representation of local protein sequence descriptors. Local descriptors account for the interactions between residues in both continuous and discontinuous regions of a protein sequence, so this method enables us to extract more PPI information from the sequence. A series of elaborate experiments are performed to optimize the prediction model by varying the parameter k and the distance measuring function of the k-nearest neighbors learning system and the ways of coding a protein pair. When performed on the PPI data of Saccharomyces cerevisiae, the method achieved 86.15% prediction accuracy with 81.03% sensitivity at the precision of 90.24%. An independent data set of 986 Escherichia coli PPIs was used to evaluate this prediction model and the prediction accuracy is 73.02%. Given the complex nature of PPIs, the performance of our method is promising, and it can be a helpful supplement for PPIs prediction.	[Yang, Lei; Xia, Jun-Feng] Chinese Acad Sci, Hefei Inst Intelligent Machines, Intelligent Comp Lab, Hefei 230031, Anhui, Peoples R China; [Yang, Lei; Xia, Jun-Feng; Gui, Jie] Univ Sci & Technol China, Sch Life Sci, Hefei 230027, Anhui, Peoples R China; [Gui, Jie] Univ Sci & Technol China, Dept Automat, Hefei 230026, Anhui, Peoples R China	Xia, JF (reprint author), Chinese Acad Sci, Hefei Inst Intelligent Machines, Intelligent Comp Lab, POB 1130, Hefei 230031, Anhui, Peoples R China.	jfxia@mail.ustc.edu.cn					Bock JR, 2003, BIOINFORMATICS, V19, P125, DOI 10.1093/bioinformatics/19.1.125; Bock JR, 2001, BIOINFORMATICS, V17, P455, DOI 10.1093/bioinformatics/17.5.455; Chang C-C., 2001, LIBSVM LIB SUPPORT V; Chen XW, 2009, BIOINFORMATICS, V25, P585, DOI 10.1093/bioinformatics/btp039; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cui J, 2007, MOL IMMUNOL, V44, P514, DOI 10.1016/j.molimm.2006.02.010; Davies MN, 2008, BIOINFORMATICS, V24, P1980, DOI 10.1093/bioinformatics/btn382; Guo YZ, 2008, NUCLEIC ACIDS RES, V36, P3025, DOI 10.1093/nar/gkn159; Huang DS, 2006, PATTERN RECOGN, V39, P2293, DOI 10.1016/j.patcog.2005.11.012; Ito T, 2001, P NATL ACAD SCI USA, V98, P4569, DOI 10.1073/pnas.061034498; Li JJ, 2006, INT J BIOL MACROMOL, V38, P241, DOI 10.1016/j.ijbiomac.2006.02.024; Liu L, 2009, BIOCHEM BIOPH RES CO, V380, P318, DOI 10.1016/j.bbrc.2009.01.077; Marcotte EM, 1999, NATURE, V402, P83; Marcotte EM, 1999, SCIENCE, V285, P751, DOI 10.1126/science.285.5428.751; Marcotte EM, 2001, BIOINFORMATICS, V17, P359, DOI 10.1093/bioinformatics/17.4.359; Najafabadi HS, 2008, GENOME BIOL, V9, DOI 10.1186/gb-2008-9-5-r87; Pazos F, 1997, J MOL BIOL, V271, P511, DOI 10.1006/jmbi.1997.1198; Pazos F, 2001, PROTEIN ENG, V14, P609, DOI 10.1093/protein/14.9.609; Shen JW, 2007, P NATL ACAD SCI USA, V104, P4337, DOI 10.1073/pnas.0607879104; Tong JC, 2008, FRONT BIOSCI, V13, P6072, DOI 10.2741/3138; Uetz P, 2000, NATURE, V403, P623; Wang B, 2006, PROTEIN PEPTIDE LETT, V13, P999, DOI 10.2174/092986606778777498; Wang B, 2006, FEBS LETT, V580, P380, DOI 10.1016/j.febslet.2005.11.081; Williams NE, 2000, METHOD CELL BIOL, V62, P449; Xenarios I, 2002, NUCLEIC ACIDS RES, V30, P303, DOI 10.1093/nar/30.1.303; Xia JF, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-174; Xia JF, 2010, PROTEIN PEPTIDE LETT, V17, P137; Zhao XM, 2005, NEURAL NETWORKS, V18, P1019, DOI 10.1016/j.neunet.2005.07.002; Zhu H, 2001, SCIENCE, V293, P2101, DOI 10.1126/science.1062191	29	3	3	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y26, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	0929-8665		PROTEIN PEPTIDE LETT	Protein Pept. Lett.		2010	17	9					1085	1090				6	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	644ZU	WOS:000281421500004	
S	Derrac, J; Garcia, S; Herrera, F		Unay, D; Cataltepe, Z; Aksoy, S		Derrac, Joaquin; Garcia, Salvador; Herrera, Francisco			IFS-CoCo in the Landscape Contest: Description and Results	RECOGNIZING PATTERNS IN SIGNALS, SPEECH, IMAGES, AND VIDEOS	Lecture Notes in Computer Science		English	Proceedings Paper	20th International Conference on Pattern Recognition Conference	APR 23-26, 2010	Istanbul, TURKEY			Evolutionary Algorithms; Feature selection; Instance selection; Cooperative coevolution; Nearest neighbor	CLASSIFICATION; ALGORITHMS	In this work, we describe the main features of IFS-CoCo, a coevolutionary method performing instance and feature selection for nearest neighbor classifiers. The coevolutionary model and several related background topics are revised, in order to present the method to the ICPR'10 contest "Classifier domains of competence: The Landscape contest". The results obtained show that our proposal is a very competitive approach in the domains considered, outperforming both the benchmark results of the contest and the nearest neighbor rule.	[Derrac, Joaquin; Herrera, Francisco] Univ Granada, Dept Comp Sci & Artificial Intelligence, CITIC UGR, E-18071 Granada, Spain	Derrac, J (reprint author), Univ Granada, Dept Comp Sci & Artificial Intelligence, CITIC UGR, E-18071 Granada, Spain.	jderrac@decsai.ugr.es; sglopez@ujaen.es; herrera@decsai.ugr.es	Herrera, Francisco/C-6856-2008	Herrera, Francisco/0000-0002-7283-312X			Aha D.W., 1997, LAZY LEARNING; Cano JR, 2003, IEEE T EVOLUT COMPUT, V7, P561, DOI 10.1109/TEVC.2003.819265; Chen YH, 2009, J MACH LEARN RES, V10, P747; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Derrac J, 2010, PATTERN RECOGN, V43, P2082, DOI 10.1016/j.patcog.2009.12.012; Eiben A. E., 2003, INTRO EVOLUTIONARY C; Eshelman LJ, 1991, CHC ADAPTIVE SEARCH, P265; Freitas A.A., 2002, DATA MINING KNOWLEDG; Ghosh A, 2005, EVOLUTIONARY COMPUTA; Ho SY, 2002, PATTERN RECOGN LETT, V23, P1495, DOI 10.1016/S0167-8655(02)00109-5; Jansen T, 2004, EVOL COMPUT, V12, P405, DOI 10.1162/1063656043138905; LIU H, 2007, CHPMN HLL CRC DTA; LIU H, 2001, INT SERIES ENG COMPU; Potter MA, 2000, EVOL COMPUT, V8, P1, DOI 10.1162/106365600568086; PRICE PW, 1998, BIOL EVOLUTION; Pyle D, 1999, M KAUFMANN SERIES DA; ROSIN CD, 1997, EVOLUTIONARY COMPUTA, V15, P1; WHITLEY D, 1998, P 3 ANN C GEN PROGRA, P504; Wiegand RP, 2003, THESIS G MASON U FAI; Wolpert DH, 2005, IEEE T EVOLUT COMPUT, V9, P721, DOI 10.1109/TEVC.2005.856205; Wu X, 2009, CH CRC DATA MIN KNOW, P1, DOI 10.1201/9781420089653	21	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-17710-1	LECT NOTES COMPUT SC			2010	6388						56	65				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BUN10	WOS:000289811600006	
S	He, Q; Zhuang, FZ; Li, JC; Shi, ZZ		Yu, J; Greco, S; Lingras, P; Wang, G; Skowron, A		He, Qing; Zhuang, Fuzhen; Li, Jincheng; Shi, Zhongzhi			Parallel Implementation of Classification Algorithms Based on MapReduce	ROUGH SET AND KNOWLEDGE TECHNOLOGY (RSKT)	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	5th International Conference on Rough Set and Knowledge Technology (RSKT)	OCT 15-17, 2010	Beijing, PEOPLES R CHINA	Beijing Jiaotong Univ, Natl Nat Sci Fdn China (NSFC), Int Rough Set Soc (IRSS), Chinese Assoc Artificial Intelligence, Rough Sets & Soft Computat Soc (CRSSC)		Data Mining; Classification; Parallel Implementation; Large Dataset; MapReduce		Data mining has attracted extensive research for several decades. As an important task of data mining, classification plays an important role in information retrieval, web searching, CRM, etc. Most of the present classification techniques are serial, which become impractical for large dataset. The computing resource is under-utilized and the executing time is not waitable. Provided the program mode of MapReduce, we propose the parallel implementation methods of several classification algorithms, such as k-nearest neighbors, naive bayesian model and decision tree, etc. Preparatory experiments show that the proposed parallel methods can not only process large dataset, but also can be extended to execute on a cluster, which can significantly improve the efficiency.	[He, Qing; Zhuang, Fuzhen; Li, Jincheng; Shi, Zhongzhi] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China	He, Q (reprint author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.	heq@ics.ict.ac.cn; zhuangfz@ics.ict.ac.cn; lijincheng@ics.ict.ac.cn; shizz@ics.ict.ac.cn					Burr Ridge I, 1997, MACHINE LEARNING; Buyya R., 2008, P 10 IEEE INT C HIGH; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Dean J., 2004, P 6 S OP SYST DES IM; Duda R. O., 2001, PATTERN CLASSIFICATI; Elsayed T., 2008, P 46 ANN M ASS COMP, P262; Michie D, 1994, MACHINE LEARNING NEU; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1997, C4 5 PROGRAMS MACHIN; Weiss Aaron, 2007, Networker, V11, DOI 10.1145/1327512.1327513; Weiss S.M., 1991, NEURAL NETS MACHINE	12	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-16247-3	LECT NOTES ARTIF INT			2010	6401						655	662				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BDT68	WOS:000314802800089	
S	Zhu, PF; Hu, QH; Yang, YB		Szczuka, M; Kryszkiewicz, M; Ramanna, S; Jensen, R; Hu, QH		Zhu, Pengfei; Hu, Qinghua; Yang, Yongbin			Weighted Nearest Neighbor Classification via Maximizing Classification Consistency	ROUGH SETS AND CURRENT TRENDS IN COMPUTING, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	7th International Conference on Rough Sets and Current Trends in Computing	JUN 28-30, 2010	Warsaw, POLAND		Univ Warsaw			The nearest neighbor classification is a. simple and effective technique for pattern recognition. The performance of this technique is known to be sensitive to the distance function used in classifying a test instance. In this paper, we propose a technique to learn sample weights via, maximizing classification consistency. Experimental analysis shows that the distance trained in this way enlarges the classification consistency on several datasets and has a strong ability to tolerate noise. Moreover, the proposed approach has better performance than nearest neighbor classification and several state-of-the-art methods.	[Zhu, Pengfei; Hu, Qinghua; Yang, Yongbin] Harbin Inst Technol, Harbin 150001, Peoples R China	Zhu, PF (reprint author), Harbin Inst Technol, Harbin 150001, Peoples R China.	huqinghua@hit.edu.cn; huqinghua@hit.edu.cn					Asuncion A., 2007, UCI MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GILADBACHRACH R, 2004, ICML 2004; Hastie T, 1996, ADV NEUR IN, V8, P409; Howe N, 1997, LECT NOTES ARTIF INT, V1266, P455; Hu QH, 2007, PATTERN RECOGN, V40, P3509, DOI 10.1016/j.patcog.2007.03.017; Hu X., 1999, KNOWL INF SYST, V1, P33; KOHAVI R, 1997, LNCS, V1224, P455; Morsi NN, 1998, FUZZY SET SYST, V100, P327, DOI 10.1016/S0165-0114(97)00104-8; Paredes R, 2006, IEEE T PATTERN ANAL, V28, P1100, DOI 10.1109/TPAMI.2006.145; Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; SLEZAK D, 2009, INFORM SCI, V1789, P197; Wang JG, 2007, PATTERN RECOGN LETT, V28, P207, DOI 10.1016/j.patrec.2006.07.002; WEINBERGER K, ADV NEURAL INFORM PR, V18; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; YAO Y, 2008, INFORM SCI, V78, P3356	16	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-13528-6	LECT NOTES ARTIF INT			2010	6086						347	355				9	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BQR34	WOS:000281605400037	
S	Bounhas, M; Mellouli, K; Prade, H; Serrurier, M		Deshpande, A; Hunter, A		Bounhas, Myriam; Mellouli, Khaled; Prade, Henri; Serrurier, Mathieu			From Bayesian Classifiers to Possibilistic Classifiers for Numerical Data	SCALABLE UNCERTAINTY MANAGEMENT, SUM 2010	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	4th Annual International Conference on Scalable Uncertainty Management (SUM)	SEP 27-29, 2010	Toulouse, FRANCE			Naive Possibilistic Classifier; Possibility Theory; Naive Bayesian Classifier; Gaussian Distribution; Kernel Density; Numerical Data	NETWORK CLASSIFIERS; CLASSIFICATION	Naive Bayesian classifiers are well-known for their simplicity and efficiency. They rely on independence hypotheses, together with a normality assumption, which may be too demanding, when dealing with numerical data. Possibility distributions are more compatible with the representation of poor data. This paper investigates two kinds of possibilistic elicitation methods that will be embedded into possibilistic naive classifiers. The first one is derived from a probability-possibility transformation of Gaussian distributions (or mixtures of them), which introduces some further tolerance. The second kind is based on a direct interpretation of data in fuzzy histogram or possibilistic formats that exploit an idea of proximity between attribute values in different ways. Besides, possibilistic classifiers may be allowed to leave the classification open between several classes in case of insufficient information for choosing one (which may be of interest when the number of classes is large). The experiments reported show the interest of possibilistic classifiers.	[Bounhas, Myriam; Mellouli, Khaled] ISG Tunis, Lab LARODEC, Le Bardo 2000, Tunisia	Bounhas, M (reprint author), ISG Tunis, Lab LARODEC, 41 Rue Liberte, Le Bardo 2000, Tunisia.	Myriam_Bounhas@yahoo.fr; Khaled.Mellouli@topnet.tn; Prade@irit.fr; Serrurier@irit.fr					Ben Amor N, 2004, IEEE INT CONF FUZZY, P653; Ben Amor N, 2002, INT J UNCERTAIN FUZZ, V10, P117; Benferhat S, 2008, LECT NOTES ARTIF INT, V5291, P63, DOI 10.1007/978-3-540-87993-0_7; Bishop CM, 1996, NEURAL NETWORKS PATT; Borgelt C., 1998, P 7 IEEE INT C FUZZ, P663; Borgelt C, 1999, P 7 EUR C INT TECHN, P556; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Denton A, 2004, P 4 SIAM INT C DAT M; Dubois D., 1993, FUZZY LOGIC STATE AR, P103; Dubois D, 1993, P 5 INT FUZZ SYST AS; DUBOIS D, 1992, FUZZY SET SYST, V49, P65, DOI 10.1016/0165-0114(92)90110-P; Dubois D., 2004, Reliable Computing, V10, DOI 10.1023/B:REOM.0000032115.22510.b5; Dubois D., 1998, HDB DEFEASIBLE REASO, V1, P169; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Grossman D., 2004, P MACH LEARN, P46; Haouari B, 2009, FUZZY SET SYST, V160, P3224, DOI 10.1016/j.fss.2009.01.009; Jenhani Ilyes, 2008, International Journal of Approximate Reasoning, V48, DOI 10.1016/j.ijar.2007.12.002; John G. H., 1995, P 11 C UNC ART INT; Kotsiantis S B, 2007, Informatica, V31; Langley P., 1994, P 10 C UNC ART INT, P399; Langley P, 1992, P AAAI 1992, V7, P223; Mertz J., UCI REPOSITORY MACHI; Pearl J., 1988, PROBABILISTIC REASON, p[505, 506, 507, 524]; Perez A, 2009, INT J APPROX REASON, V50, P341, DOI 10.1016/j.ijar.2008.08.008; Qin B., 2009, IEEE INT C DAT ENG; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; SOLOMONOFF RJ, 1964, INFORM CONTROL, V7, P224, DOI 10.1016/S0019-9958(64)90131-7; Strauss O., 2000, P 15 ICPR BARC SPAIN, P2684; Sudkamp T, 2000, P 90 IEEE INT C FUZZ, P735; Yamada K., 2001, IFSA WORLD C 20 NAFI, V1, P70; Zaffalon M, 2002, J STAT PLAN INFER, V105, P5, DOI 10.1016/S0378-3758(01)00201-4	31	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-15950-3	LECT NOTES ARTIF INT			2010	6379						112	125				14	Computer Science, Artificial Intelligence	Computer Science	BDB30	WOS:000312447800015	
B	Lu, WC		Gaber, MM		Lu Wencong			Data Mining and Discovery of Chemical Knowledge	SCIENTIFIC DATA MINING AND KNOWLEDGE DISCOVERY: PRINCIPLES AND FOUNDATIONS			English	Article; Book Chapter							SUPPORT VECTOR MACHINES; TERNARY INTERMETALLIC COMPOUNDS; FISHER DISCRIMINANT-ANALYSIS; PARTIAL LEAST-SQUARES; REDUCTASE INHIBITORY-ACTIVITY; PRINCIPAL COMPONENT ANALYSIS; MONITORING BATCH PROCESSES; FAULT-DIAGNOSIS; NONTRANSITION ELEMENTS; TRANSITION-ELEMENTS		Shanghai Univ, Shanghai, Peoples R China	Lu, WC (reprint author), Shanghai Univ, 99 Shangda Rd, Shanghai, Peoples R China.	wclu@shu.edu.cn					Alves CN, 2000, J MOL STRUC-THEOCHEM, V530, P39, DOI 10.1016/S0166-1280(00)00325-0; ANDROULAKIS IP, 1991, COMPUT CHEM ENG, V15, P217, DOI 10.1016/0098-1354(91)85009-J; Bao XH, 2003, ACTA PHARMACOL SIN, V24, P472; Belousov AI, 2002, CHEMOMETR INTELL LAB, V64, P15, DOI 10.1016/S0169-7439(02)00046-1; BHAT N, 1990, COMPUT CHEM ENG, V14, P573, DOI 10.1016/0098-1354(90)87028-N; BILYALOV YR, 1992, J ALLOY COMPD, V189, pL5, DOI 10.1016/0925-8388(92)90029-9; Burbidge R, 2001, COMPUT CHEM, V26, P5, DOI 10.1016/S0097-8485(01)00094-8; Cai YD, 2003, PEPTIDES, V24, P665, DOI 10.1016/S0196-9781(03)00133-5; Cai YD, 2003, PEPTIDES, V24, P629, DOI 10.1016/S0196-9781(03)00100-1; CHEN N, 1998, P INT C MULTISOURCE; Chen N., 2004, SUPPORT VECTOR MACHI; 陈念贻, 2002, [计算机与应用化学, Computers and Applied Chemistry], V19, P691; Chen NY, 1999, CHEMOMETR INTELL LAB, V45, P329; Chen NY, 1999, J ALLOY COMPD, V289, P126, DOI 10.1016/S0925-8388(99)00133-4; Chen NY, 1999, J ALLOY COMPD, V292, P129; Chen NY, 1999, J ALLOY COMPD, V289, P120, DOI 10.1016/S0925-8388(99)00134-6; CHEN NY, 1999, PATTERN RECOGNITION; Chiang LH, 2000, CHEMOMETR INTELL LAB, V50, P243, DOI 10.1016/S0169-7439(99)00061-1; Chiang LH, 2004, COMPUT CHEM ENG, V28, P1389, DOI 10.1016/j.compchemeng.2003.10.002; Chouai A, 2000, CHEM ENG PROCESS, V39, P171, DOI 10.1016/S0255-2701(99)00086-0; Chung SSM, 2003, J AM SOC NEPHROL, V14, pS233, DOI 10.1097/01.ASN.0000077408.15865.06; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 2001, PATTERN CLASSIFICATI; Dufour P, 2004, COMPUT CHEM ENG, V28, P545, DOI 10.1016/j.compchemeng.2003.08.007; ESPASO JI, 1994, SOLID STATE COMMUN, V92, P389; Flores-Cerrillo J, 2004, AICHE J, V50, P1219, DOI 10.1002/aic.10147; GALVAODASILVA E, 1994, J MAGN MAGN MATER, V138, P63; Gayen S, 2004, BIOORGAN MED CHEM, V12, P1493, DOI 10.1016/j.bmc.2003.12.031; GELADI P, 1986, ANAL CHIM ACTA, V185, P1, DOI 10.1016/0003-2670(86)80028-9; Goldberg D. E, 1989, GENETIC ALGORITHMS S; GORDIER G, 1993, J ALLOY COMPD, V201, P197; GORDIER G, 1991, J LESS-COMMON MET, V169, P291; Gunn S, 1998, SUPPORT VECTOR MACHI; Hadamard J., 1923, LECT CAUCHY PROBLEM; He QP, 2005, AICHE J, V51, P555, DOI 10.1002/aic.10325; Jade AM, 2006, CHEM ENG SCI, V61, P688, DOI 10.1016/j.ces.2005.08.002; [Ji Xiaobo 纪晓波], 2005, [计算机与应用化学, Computers and Applied Chemistry], V22, P449; JOACHIMS T, 2001, THESIS U DORTMUND; Kulkarni A, 2004, COMPUT CHEM ENG, V28, P311, DOI 10.1016/S0098-1354(03)00188-1; Low KH, 2004, CHEM ENG PROCESS, V43, P273, DOI 10.1016/S0255-2701(03)00123-5; 陆文聪, 2002, [计算机与应用化学, Computers and Applied Chemistry], V19, P697; [陆文聪 Lu Wencong], 2002, [计算机与应用化学, Computers and Applied Chemistry], V19, P473; Lu WC, 1999, J ALLOY COMPD, V289, P131, DOI 10.1016/S0925-8388(99)00132-2; Lyon R. N., 1952, LIQUID METALS HDB; Nomikos P, 1995, CHEMOMETR INTELL LAB, V30, P97, DOI 10.1016/0169-7439(95)00043-7; MAKLOUF SA, 1994, J MAGN MAGN MATER, V135, P257; Maria G, 2007, COMPUT CHEM ENG, V31, P1231, DOI 10.1016/j.compchemeng.2006.10.009; Matsuda H, 2002, CHEM PHARM BULL, V50, P788, DOI 10.1248/cpb.50.788; McKay B, 1997, COMPUT CHEM ENG, V21, P981, DOI 10.1016/S0098-1354(96)00329-8; Murray AI, 1995, APPL NEURAL NETWORKS; Nascimento CAO, 2000, COMPUT CHEM ENG, V24, P2303, DOI 10.1016/S0098-1354(00)00587-1; NOMIKOS P, 1994, AICHE J, V40, P1361, DOI 10.1002/aic.690400809; Pearson K, 1901, PHILOS MAG, V2, P559; Platt JC, FAST TRAINING SUPPOR; Prabhakar YS, 2006, J CHEM INF MODEL, V46, P86, DOI 10.1021/ci050060u; Smil V, 1999, NATURE, V400, P415, DOI 10.1038/22672; STEWART JJP, 1989, J COMPUT CHEM, V10, P209, DOI 10.1002/jcc.540100208; TERASHIMA H, 1984, J PHARMACOL EXP THER, V229, P226; Toumi A, 2007, CHEM ENG PROCESS, V46, P1067, DOI 10.1016/j.cep.2006.06.026; Trotter MWB, 2001, MEAS CONTROL-UK, V34, P235; Van Gestel T, 2001, IEEE T NEURAL NETWOR, V12, P809, DOI 10.1109/72.935093; VAPNIK V, 1995, NATURE STAT LEANIING; Vapnik V.N., 1998, STAT LEARNING THEORY; VILLARS P, 1983, J LESS-COMMON MET, V92, P215, DOI 10.1016/0022-5088(83)90489-7; WAN V, 2000, P IEEE SIGN PROC SOC, V2, P775; Wang XZ, 1998, IND ENG CHEM RES, V37, P2215, DOI 10.1021/ie970620h; Wise BM, 1996, J PROCESS CONTR, V6, P329, DOI 10.1016/0959-1524(96)00009-1; Zimmet P, 2001, NATURE, V414, P782, DOI 10.1038/414782a; [Anonymous], 2002, HYPERCHEM REL 7 0 WI	69	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES		978-3-642-02787-1				2010							269	317		10.1007/978-3-642-02788-8_11	10.1007/978-3-642-02788-8	49	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BLT52	WOS:000270986400011	
J	Chakrabarti, A; Regev, O				Chakrabarti, Amit; Regev, Oded			AN OPTIMAL RANDOMIZED CELL PROBE LOWER BOUND FOR APPROXIMATE NEAREST NEIGHBOR SEARCHING	SIAM JOURNAL ON COMPUTING			English	Article						cell probe model; nearest neighbor search; round elimination	PROTEIN SECONDARY STRUCTURE; COMMUNICATION COMPLEXITY; PREDICTION	We consider the approximate nearest neighbor search problem on the Hamming cube {0, 1}(d). We show that a randomized cell probe algorithm that uses polynomial storage and word size d(O(1)) requires a worst case query time of O(log log d/log log log d). The approximation factor may be as loose as 2log(1-eta d) for any fixed eta > 0. Our result fills a major gap in the study of this problem since all earlier lower bounds either did not allow randomization [A. Chakrabarti et al., A lower bound on the complexity of approximate nearest-neighbor searching on the Hamming cube, in Discrete and Computational Geometry, Springer, Berlin, 2003, pp. 313-328; D. Liu, Inform. Process. Lett., 92 (2004), pp. 23-29] or did not allow approximation [A. Borodin, R. Ostrovsky, and Y. Rabani, Proceedings of the 31st Annual ACM Symposium on Theory of Computing, 1999, pp. 312-321; O. Barkol and Y. Rabani, Proceedings of the 32nd Annual ACM Symposium on Theory of Computing, 2000, pp. 388-396; T. S. Jayram et al., J. Comput. System Sci., 69 (2004), pp. 435-447]. We also give a cell probe algorithm that proves that our lower bound is optimal. Our proof uses a lower bound on the round complexity of the related communication problem. We show, additionally, that considerations of bit complexity alone cannot prove any nontrivial cell probe lower bound for the problem. This shows that the "richness technique" [P. B. Miltersen et al., J. Comput. System Sci., 57 (1998), pp. 37-49] used in a lot of recent research around this problem would not have helped here. Our proof is based on information theoretic techniques for communication complexity, a theme that has been prominent in recent research [A. Chakrabarti et al., Proceedings of the 42nd Annual IEEE Symposium on Foundations of Computer Science, 2001, pp. 270-278; Z. Bar-Yossef et al., Proceedings of the 43rd Annual IEEE Symposium on Foundations of Computer Science, 2002, pp. 209-218; P. Sen, Proceedings of the 18th Annual IEEE Conference on Computational Complexity, 2003, pp. 73-83; R. Jain, J. Radhakrishnan, and P. Sen, Proceedings of the 30th International Colloquium on Automata, Languages and Programming, 2003, pp. 300-315].	[Chakrabarti, Amit] Dartmouth Coll, Dept Comp Sci, Hanover, NH 03755 USA; [Chakrabarti, Amit] Inst Adv Study, Princeton, NJ 08540 USA; [Regev, Oded] Tel Aviv Univ, Blavatnik Sch Comp Sci, IL-69978 Tel Aviv, Israel; [Regev, Oded] Univ Calif Berkeley, Berkeley, CA 94720 USA	Chakrabarti, A (reprint author), Dartmouth Coll, Dept Comp Sci, Hanover, NH 03755 USA.	ac@cs.dartmouth.edu; odedr@post.tau.ac.il			NSF [CCR-9987845, CCF-0448277]; Binational Science Foundation; Israel Science Foundation; European Commission; IST [015848]; Army Research Office [DAAD19-03-1-0082]; European Research Council (ERC)	Computer Science Department, Dartmouth College, Hanover, NH 03755 (ac@cs.dartmouth.edu). This work was partly done while this author was at the Institute for Advanced Study, Princeton, NJ. This author's work was supported in part by NSF grants CCR-9987845 and CCF-0448277.Blavatnik School of Computer Science, Tel Aviv University, Tel Aviv 69978, Israel (odedr@post.tau.ac.il). This work was partly done while this author was at the University of California, Berkeley. This author's research was supported by the Binational Science Foundation, the Israel Science Foundation, the European Commission under the Integrated Project QAP funded by the IST directorate as contract 015848, Army Research Office grant DAAD19-03-1-0082, and a European Research Council (ERC) Starting Grant.	ANDONI A, 2006, P 47 ANN IEEE S FDN, P449; Barkol O., 2000, Proceedings of the Thirty Second Annual ACM Symposium on Theory of Computing, DOI 10.1145/335305.335350; Bar-Yossef Z., 2002, Proceedings 43rd Annual IEEE Symposium on Foundations of Computer Science, DOI 10.1109/SFCS.2002.1181944; Beame P., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, DOI 10.1145/301250.301323; BEAME P, 2003, COMMUNICATION; Borodin A., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, DOI 10.1145/301250.301330; Chakrabarti A., 2001, Proceedings 42nd IEEE Symposium on Foundations of Computer Science, DOI 10.1109/SFCS.2001.959901; CHAKRABARTI A, 2003, DISCRETE COMPUT GEOM, P313; Chakrabarti A., 2004, Proceedings. 45th Annual IEEE Symposium on Foundations of Computer Science; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; de Berg M, 2000, COMPUTATIONAL GEOMET; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Duda R., 1973, PATTERN CLASSIFICATI; FREDMAN ML, 1984, J ACM, V31, P538, DOI 10.1145/828.1884; Har-Peled S., 2001, Proceedings 42nd IEEE Symposium on Foundations of Computer Science, DOI 10.1109/SFCS.2001.959884; HARSHA P, 2007, P 22 CCC, P10, DOI DOI 10.1109/CCC.2007.32; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; Jain R., 2003, P 30 INT C AUT LANG, P300; Jayram TS, 2004, J COMPUT SYST SCI, V69, P435, DOI 10.1016/j.jcss.2004.04.006; Kushilevitz E, 2000, SIAM J COMPUT, V30, P457, DOI 10.1137/S0097539798347177; Liu D, 2004, INFORM PROCESS LETT, V92, P23, DOI 10.1016/j.ipl.2004.06.001; Miltersen P. B., 1994, Proceedings of the Twenty-Sixth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/195058.195415; Miltersen PB, 1998, J COMPUT SYST SCI, V57, P37, DOI 10.1006/jcss.1998.1577; NEWMAN I, 1991, INFORM PROCESS LETT, V39, P67, DOI 10.1016/0020-0190(91)90157-D; Patrascu M, 2009, SIAM J COMPUT, V39, P730, DOI 10.1137/070684859; SALAMOV AA, 1995, J MOL BIOL, V247, P11, DOI 10.1006/jmbi.1994.0116; Salton G, 1983, INTRO MODERN INFORM; Sen P., 2003, Proceedings 18th IEEE Annual Conference on Computational Complexity; YAO ACC, 1981, J ACM, V28, P615, DOI 10.1145/322261.322274; Yao AC-C, 1977, P 18 ANN IEEE S FDN, P222, DOI DOI 10.1109/SFCS.1977.24; YI TM, 1993, J MOL BIOL, V232, P1117, DOI 10.1006/jmbi.1993.1464	31	0	2	SIAM PUBLICATIONS	PHILADELPHIA	3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA	0097-5397		SIAM J COMPUT	SIAM J. Comput.		2010	39	5					1919	1940		10.1137/080729955		22	Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	595BC	WOS:000277584700009	
S	Ozer, S; Chen, CH; Yetik, IS		Hancock, ER; Wilson, RC; Windeatt, T; Ulusoy, I; Escolano, F		Ozer, Sedat; Chen, Chi Hau; Yetik, Imam Samil			Using K-NN SVMs for Performance Improvement and Comparison to K-Highest Lagrange Multipliers Selection	STRUCTURAL, SYNTACTIC, AND STATISTICAL PATTERN RECOGNITION	Lecture Notes in Computer Science		English	Proceedings Paper	Joint IAPR International Workshop on SSPR & SPR	AUG 18-20, 2010	Izmir, TURKEY	IAPR, Pattern Anal Stat Modelling & Comp Learning		Support Vector Machine; KNN SVM; Post-processing; Support Vector Reduction	SUPPORT VECTOR MACHINE	Support Vector Machines (SVM) can perform very well on noise free data sets and can usually achieve good classification accuracies when the data is noisy. However, because of the overfitting problem, the accuracy decreases if the SVM is modeled improperly or if the data is excessively noisy or nonlinear. For SVM, most of the misclassification occurs when the test data lies closer to the decision boundary. Therefore in this paper, we investigate the effect of Support Vectors found by SVM, and their effect on the decision when used with the Gaussian kernel. Based on the discussion results we also propose a new technique to improve the performance of SVM by creating smaller clusters along the decision boundary in the higher dimensional space. In this way we reduce the overfitting problem that occurs because of the model selection or the noise effect. As an alternative SVM tuning method, we also propose using only K highest Lagrange multipliers to summarize the decision boundary instead of the whole support vectors and compare the performances. Thus with test results, we show that the number of Support Vectors can be decreased further by using only a fraction of the support vectors found at the training step as a post-processing method.	[Ozer, Sedat] Rutgers State Univ, Dept Elect & Comp Engn, New Brunswick, NJ 08903 USA	Ozer, S (reprint author), Rutgers State Univ, Dept Elect & Comp Engn, New Brunswick, NJ 08903 USA.	sozer@umassd.edu; cchen@umassd.edu; yetik@iit.edu					Artan Y, 2008, I S BIOMED IMAGING, P488, DOI 10.1109/ISBI.2008.4541039; Asuncion A., UCI MACHINE LEARNING; Bishop C. M., 2006, PATTERN RECOGNITION; Canu S., 2005, SVM KERNEL METHODS M; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DECOSTE D, 2003, 20 INT C MACH LEARN; El-Naqa I, 2002, IEEE T MED IMAGING, V21, P1552, DOI 10.1109/TMI.2002.806569; LUCEY S, 2008, IEEE C COMP VIS PATT, P1; MING T, 2003, IEEE INTELLIGENT TRA, V1, P373; OZER S, 2008, 19 INT C PATT REC IC; Ozer S, 2009, 2009 IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: FROM NANO TO MACRO, VOLS 1 AND 2, P73, DOI 10.1109/ISBI.2009.5192986; Vapnik V.N., 1998, STAT LEARNING THEORY; ZHANG H, 2006, IEEE C COMP VIS PATT; Zhang L, 2004, IEEE T SYST MAN CY B, V34, P34, DOI 10.1109/TSMCB.2003.811113	14	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-14979-5	LECT NOTES COMPUT SC			2010	6218						532	539				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BTB95	WOS:000286412900052	
S	Gomolinska, A		Peters, JF; Skowron, A		Gomolinska, Anna			Satisfiability Judgement under Incomplete Information	TRANSACTIONS ON ROUGH SETS XI	Lecture Notes in Computer Science		English	Article; Book Chapter						satisfiability of formulas; judgement making; concept modelling; knowledge discovery; Pawlak information system; descriptor language; approximation space	ROUGH SET APPROACH; APPROXIMATION SPACES; FUZZY-LOGIC; PROPOSITIONAL CALCULI; MODEL CHECKING; TIMED AUTOMATA; CLASSIFICATION; FORMULAS; SYSTEMS; RULES	In this paper we keep on discussing satisfiability of conditions by objects when information about the situation considered, including objects of some sort and concepts comprised of them, is incomplete. Our approach to satisfiability is that of concept modelling and we have a rough granular view or the problem. Objects considered are known partially, in terms of values of attributes of Pawlak information systems. An additional knowledge (domain knowledge) is assumed to be available. We choose descriptor languages for Pawlak information systems as specification languages in which we will express conditions about objects and concepts.	Bialystok Univ, Dept Math, PL-15267 Bialystok, Poland	Gomolinska, A (reprint author), Bialystok Univ, Dept Math, Akad 2, PL-15267 Bialystok, Poland.	anna.gom@math.uwb.edu.pl					AARNODT A, 1994, AI COMMUN, V7, P39; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BANERJEE M, 1994, P RSKD 1993, P196; Barwise J., 1997, INFORM FLOW LOGIC DI; Bazan J, 2006, LECT NOTES COMPUT SC, V4100, P39; BAZAN JG, 1998, LNCS, V1424, P521; Bazan JG, 2004, LECT NOTES ARTIF INT, V3066, P346; Bazan JG, 2008, LECT NOTES COMPUT SC, V5390, P474, DOI 10.1007/978-3-540-89876-4_26; BELNAP N., 1977, MODERN USES MULTIPLE, P8; Bolc L., 1992, MANY VALUED LOGICS; Borkowski L., 1970, J LUKASIEWICZ SELECT; Chellas B. F., 1980, MODAL LOGIC INTRO; Cios K., 2007, DATA MINING KNOWLEDG; Cook S. A., 1971, Proceedings of the 3rd annual ACM symposium on theory of computing, DOI 10.1145/800157.805047; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEMRI S. P, 2002, INCOMPLETE INFORM ST; Drwal G., 1998, P 7 INT S INT INF SY, P392; Duda R., 2000, PATTERN CLASSIFICATI; Dzeroski S., 2001, RELATIONAL DATA MINI; Emerson E. A., 1990, HDB THEORETICAL COMP, VB, P995; Fagin R., 1995, REASONING KNOWLEDGE; Fensel D., 2003, ONTOLOGIES SILVER BU; Gomolinska A, 2006, FUND INFORM, V72, P139; Gomolinska A, 2007, FUND INFORM, V79, P319; Gomolinska A, 2008, LECT NOTES COMPUT SC, V5390, P35, DOI 10.1007/978-3-540-89876-4_3; Gomolinska A, 2004, FUND INFORM, V60, P159; Gomolinska A, 2008, FUND INFORM, V85, P139; Gomolinska A, 2005, FUND INFORM, V67, P77; Gomolinska A., 2005, Proceedings. The 2005 IEEE/WIC/ACM International Conference on Intelligent Agent Technology; GOMOLINSKA A, 2003, ELECT NOTICES THEORE, V82, P1; GOMOLINSKA A, 2009, P 18 WORKSH CONC SPE, V1, P164; Gomolinska A, 2009, LECT NOTES COMPUT SC, V5656, P117; GOMOLINSKA A, 2008, HDB GRANULAR COMPUTI, P449, DOI 10.1002/9780470724163.ch20; Greco S, 2006, LECT NOTES ARTIF INT, V3885, P7; Greco S, 1999, LECT NOTES ARTIF INT, V1711, P146; Grzymala-Busse J. W., 1992, INTELLIGENT DECISION, P3; Grzymala-Busse JW, 2005, LECT NOTES COMPUT SC, V3700, P58; Grzymala-Busse JW, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P1347, DOI 10.1007/0-387-25465-X_65; Hastie T, 2009, ELEMENTS STAT LEARNI; Hirano S., 2003, ROUGH SET THEORY GRA; HORNBY AS, 2007, OXFORD ADV LEARNERS; Jankowski A., 2007, LNCS, V4374, P94; Kahneman D., 1982, JUDGMENT UNCERTAINTY; KANT I, 1988, CRITIQUE JUDGMENT; Keefe R., 2000, THEORIES VAGUENESS; Kephart JO, 2005, PROC INT CONF SOFTW, P15, DOI 10.1145/1062455.1062464; Kleene S. C., 1952, INTRO METAMATHEMATIC; Klir G.J., 1998, UNCERTAINTY BASED IN; KLOESGEN W, 2002, HDB KNOWLEDGE DISCOV; KONDRATOFF Y, 1990, MACHINE LEARNING ART, V3; Kripke S. A., 1963, Z MATH LOGIK GRUNDLA, V9, P67, DOI 10.1002/malq.19630090502; KRIPKE S. A., 1965, THEORY MODELS, P206; Kryszkiewicz M, 1998, INFORM SCIENCES, V112, P39, DOI 10.1016/S0020-0255(98)10019-1; LESNIEWSKI S, 1916, FDN GEN SET THEORY 1, V2; LIPSKI W, 1976, P 3 INT S AUT LANG P, P120; LIU J, 2008, P 4 INT C NAT COMP I, P3; Liu J., 2005, AUTONOMY ORIENTED CO; Lukasiewicz J., 1920, RUCH FILOZOFICZNY, V5, P170; Lukasiewicz J., 1970, J LUKASIEWICZ SELECT, P16; Lukasiewicz J., 1930, CR HEBD ACAD SCI, VIII, P51; Maimon O., 2005, DATA MINING KNOWLEDG; MICHALSKI RS, 1993, MACH LEARN, V11, P111, DOI 10.1007/BF00993074; Michalski R. S., 1994, MACHINE LEARNING MUL, V4; Michalski R. S., 1983, MACHINE LEARNING ART; Mitchell Melanie, 2001, P335; Mitchell M., 1993, ANALOGY MAKING PERCE; Mitchell TM, 1998, MACHINE LEARNING; Nguyen H. S., 2001, COMPUT INTELL, V17, P514; NGUYEN SH, 2005, LNCS, V3518, P312; Nguyen SH, 2004, LECT NOTES COMPUT SC, V3100, P187; Nguyen SH, 2006, LECT NOTES ARTIF INT, V4259, P547; PAVELKA J, 1979, Z MATH LOGIK, V25, P447, DOI 10.1002/malq.19790252510; PAVELKA J, 1979, Z MATH LOGIK, V25, P119, DOI 10.1002/malq.19790250706; PAVELKA J, 1979, Z MATH LOGIK, V25, P45, DOI 10.1002/malq.19790250304; Pawlak Z., 1983, INFORM SYSTEMS THEOR; Pawlak Z., 1998, ROUGH SETS KNOWLEDGE, P10; Pawlak Z., 1991, ROUGH SETS THEORETIC; Pawlak Z., 1987, B POLISH ACAD SCI TE, P253; Pawlak Z, 2005, LECT NOTES COMPUT SC, V3700, P1; PAWLAK Z, 2001, ROUGH SET METHODS AP, P583; PAWLAK Z, 1981, INFORM SYST, V6, P205, DOI 10.1016/0306-4379(81)90023-5; Pedrycz W., 2008, HDB GRANULAR COMPUTI; Pedrycz W., 2001, GRANULAR COMPUTING E; Penczek W, 2008, FUND INFORM, V85, P425; Penczek W, 2002, FUND INFORM, V51, P135; Peters JF, 2005, ADV SOFT COMP, P13, DOI 10.1007/3-540-32370-8_2; Plous S, 1993, PSYCHOL JUDGEMENT DE; POGORZELSKI WA, 1994, NOTIONS THEOREMS ELE; Polkowski L., 2002, ROUGH SETS MATH FDN; Polkowski L., 1998, ROUGH SETS KNOWLEDGE, V1; POLKOWSKI L, 2001, ROUGH SET METHODS AP, P89; POLKOWSKI L, 1999, COMPUTING WORDS INFO, V1, P201; Polkowski L, 2008, LECT NOTES ARTIF INT, V5009, P197, DOI 10.1007/978-3-540-79721-0_30; POLKOWSKI L, 2001, ROUGH SET METHODS AP; Polkowski L, 1996, INT J APPROX REASON, V15, P333, DOI 10.1016/S0888-613X(96)00072-2; POLKOWSKI L, 1994, LECT NOTES ARTIF INT, V869, P85; Polkowski L, 2004, FUND INFORM, V61, P37; Rescher N., 1969, MANY VALUED LOGIC; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Rosser J.B., 1958, MANY VALUED LOGICS; Segerberg K., 1971, ESSAY CLASSICAL MODA, VI; Skowron A., 1996, Fundamenta Informaticae, V27; SKOWRON A, 2005, LNCS, V3641, P718; Skowron A, 1999, LECT NOTES ARTIF INT, V1704, P542; Skowron A, 2005, LECT NOTES COMPUT SC, V3400, P175; Slowinski R, 2007, LECT NOTES ARTIF INT, V4585, P5, DOI 10.1007/978-3-540-73451-2_2; Slowinski R., 1997, ADV MACHINE INTELLIG, VIV, P17; Staab S., 2004, HDB ONTOLOGIES; Stefanowski J, 2001, COMPUT INTELL, V17, P545, DOI 10.1111/0824-7935.00162; Stefanowski J., 1998, ROUGH SETS KNOWLEDGE, V1, P500; Stepaniuk J, 2004, FUND INFORM, V61, P139; STEPANIUK J, 2007, LNCS, V4374, P351; STEPANIUK J, 2001, ROUGH SET METHODS AP, P137; Stone P., 2000, LAYERED LEARNING MUL; Surma S. J., 1992, STANISLAW LESNIEWSKI; Synak P, 2005, FUND INFORM, V67, P249; Tarski A., 1944, PHILOS PHENOMENOLOGI, V4, P341, DOI 10.2307/2102968; Thiele LP, 2006, HEART OF JUDGMENT: PRACTICAL WISDOM, NEUROSCIENCE, AND NARRATIVE, P1, DOI 10.1017/CBO9780511498718; Torra V., 2007, MODELING DECISIONS I; Vapnik V.N., 1998, STAT LEARNING THEORY; Wojna A, 2005, LECT NOTES COMPUT SC, V3700, P277; Wozna B, 2003, FUND INFORM, V55, P223; Xu ZB, 2002, INFORM SCIENCES, V141, P227, DOI 10.1016/S0020-0255(02)00174-3; Yao Y., 1997, ROUGH SETS DATA MINI, P47; YAO YY, 1992, INT J MAN MACH STUD, V37, P793, DOI 10.1016/0020-7373(92)90069-W; Zadeh L., 1975, SYNTHESE, V30, P407, DOI DOI 10.1007/BF00485052; Zadeh L., 1999, COMPUTING WORDS INFO; ZADEH LA, 1973, IEEE T SYST MAN CYB, VSMC3, P28, DOI 10.1109/TSMC.1973.5408575; Zadeh L. A., 1979, ADV FUZZY SET THEORY, P3; Zadeh LA, 1996, IEEE T FUZZY SYST, V4, P103, DOI 10.1109/91.493904; Zhao Y, 2007, INFORM SCIENCES, V177, P4959, DOI 10.1016/j.ins.2007.06.031; Ziarko W, 2005, LECT NOTES ARTIF INT, V3641, P283; ZIARKO W, 1993, J COMPUT SYST SCI, V46, P39, DOI 10.1016/0022-0000(93)90048-2	133	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-11478-6	LECT NOTES COMPUT SC			2010	5946						66	91			10.1007/978-3-642-11479-3	26	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BNG61	WOS:000274515500005	
S	Terlecki, P		Peters, JF; Skowron, A; Slowinski, R; Lingras, P; Miao, DQ; Tsumoto, S		Terlecki, Pawei			On the Relation between Jumping Emerging Patterns and Rough Set Theory with Application to Data Classification	TRANSACTIONS ON ROUGH SETS XII	Lecture Notes in Computer Science		English	Article; Book Chapter							NEGATIVE ASSOCIATION RULES; FREQUENT CLOSED ITEMSETS; TRANSACTION DATABASES; FEATURE-SELECTION; FAST DISCOVERY; EM ALGORITHM; REDUCTS; COMPLEXITY; ATTRIBUTE; REPRESENTATION	Contrast patterns are an essential element of classification methods based on data mining. Among many propositions, jumping emerging patterns (JEPs) have gained significant recognition due to their simplicity and strong discrimination capabilities. This thesis considers JEPs in terms of discovery and classification. The focus is put on their correspondence to the rough set theory. Transformations between transactional data and decision tables allow us to demonstrate relations of JEPs and global/local reducts. As a part of this discussion, we introduce the concept of a jumping emerging pattern with negation (JEPN). Our observations lead to two novel JEP mining methods based on local reducts: global condensation and local projection. Both attempt to decrease dimensionality of subproblems prior to reduct computation. We show that JEP mining can be reduced to the reduct set problem. The latter is addressed with a new approach, called RedApriori, that follows an Apriori candidate generation scheme and employs pruning based on the notion of attribute set dependence. In addition, we discuss different ways of storing pattern collections and propose a CC-Trie, a tree structure that ensures compactness of information and fast pattern lookups.	Warsaw Univ Technol, Inst Comp Sci, PL-00665 Warsaw, Poland	Terlecki, P (reprint author), Warsaw Univ Technol, Inst Comp Sci, Nowowiejska 15-19, PL-00665 Warsaw, Poland.	pterleck@ii.pw.edu.pl					Agrawal R., 1994, VLDB, P487; Aloul F., 2002, INT WORKSH LOG SYNTH, P131; ANDERSON M, 1994, SYNTHESIS INFORM SYS; Antonie ML, 2004, LECT NOTES ARTIF INT, V3202, P27; Asuncion A., 2007, UCI MACHINE LEARNING; BAILEY J, 2002, LNCS LNAI, V2431, P39; Bailey J., 2003, ICDM, P485; BAILEY J, 2007, UCI MACHINE LEARNING, P226; Baralis E, 2004, ACM T DATABASE SYST, V29, P635, DOI 10.1145/1042046.1042048; Bastide Yves, 2000, SIGKDD EXPLORATIONS, V2, P66, DOI DOI 10.1145/380995.381017; Bayardo R.J., 1998, SIGMOD, P85; Bazan J. G., 1994, LECT NOTES ARTIF INT, V869, P346; Bazan J.G., 2000, ROUGH SET METHODS AP, P49; Bazan J.G., 2001, LECT NOTES ARTIF INT, V2005, P106; BAZAN JG, 1998, THESIS U WARSAW; BERGE C, 1989, HYPERGRAPHS, V45; Bhatt RB, 2005, PATTERN RECOGN LETT, V26, P965, DOI 10.1016/j.patrec.2004.09.044; Birkhoff G, 1967, LATTICE THEORY; BJORVAND AT, IMACS; Blum A., 1998, COLT, P92; Bodon F., 2003, CEUR WORKSHOP P, V90; Boulicaut J.-F., 2000, FQAS, P425; Brin S, 1997, SIGMOD, P265; Brown F. M., 1990, BOOLEAN REASONING; BRYANT RE, 1986, IEEE T COMPUT, V35, P677; CERNY E, 1977, IEEE T COMPUT, V26, P745; CHAN CC, 2008, LNCS LNAI, V5306; Chmielewski MR, 1996, INT J APPROX REASON, V15, P319, DOI 10.1016/S0888-613X(96)00074-6; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; Cichosz P, 2000, LEARNING SYSTEMS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CYKIER A, 1997, PRIME IMPLICANTS BOO; Dehuri S, 2008, APPL SOFT COMPUT, V8, P477, DOI 10.1016/j.asoc.2007.02.009; Delany SJ, 2005, LECT NOTES ARTIF INT, V3620, P177; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DEMRI S. P, 2002, INCOMPLETE INFORM ST; Dominik A, 2007, LECT NOTES ARTIF INT, V4702, P67; DONG G, 2003, LNCS, V2762; Dong G., 1999, KNOWLEDGE DISCOVERY, P43; Dong GZ, 1999, LECT NOTES ARTIF INT, V1721, P30; Dong GZ, 2005, KNOWL INF SYST, V8, P178, DOI 10.1007/s10115-004-0178-1; Elbassioni KM, 2008, DISCRETE APPL MATH, V156, P2109, DOI 10.1016/j.dam.2007.05.030; FAN H, 2004, THESIS U MELBOURNE; Fan H., 2002, LNCS LNAI, V2336, P456; FAN H, 2007, UCI MACHINE LEARNING, P189; Fan H, 2006, IEEE T KNOWL DATA EN, V18, P721, DOI 10.1109/TKDE.2006.95; FAYYAD UM, 1993, IJCAI-93, VOLS 1 AND 2, P1022; Frelicot C, 2002, PATTERN ANAL APPL, V5, P234; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FUMERA G, 2003, ICIAP, P582; GARFINKEL R, 1978, INTEGER PROGRAMMING; Garriga GC, 2008, J MACH LEARN RES, V9, P559; GRECO S, 2006, LNCS LNAI, V4259; Grzymala-Busse JW, 2003, DATA MINING: OPPORTUNITIES AND CHALLENGES, P142; Han J., 2002, INT C DAT MIN, P211; Han J, 2000, SIGMOD 00, P1, DOI DOI 10.1145/342009.335372; Han J., 2006, DATA MINING CONCEPTS; HIRANO S, 1994, ICTAI, P332; Hussain F, 2000, LECT NOTES ARTIF INT, V1805, P86; INOKUCHI A, 1998, LNCS, V1424, P13; Jackson Q, 2001, IEEE T GEOSCI REMOTE, V39, P2664, DOI 10.1109/36.975001; KARYPSIS G, 2002, CLUTO CLUSTERING TOO; Kavvadias DJ, 1999, LECT NOTES COMPUT SC, V1668, P72; Ke LJ, 2008, PATTERN RECOGN LETT, V29, P1351, DOI 10.1016/j.patrec.2008.02.006; KOHAVI R, 1994, ICTAI, P740; KOMOROWSKI J, 2002, CASE STUDIES PUBLIC, P554; Kryszkiewicz M, 2004, LECT NOTES COMPUT SC, V3100, P120; KRYSZKIEWICZ M, 1994, THESIS WARSAW U TECH; Kryszkiewicz M, 2007, LECT NOTES ARTIF INT, V4585, P320, DOI 10.1007/978-3-540-73451-2_34; Kryszkiewicz M, 2005, LECT NOTES ARTIF INT, V3518, P672; KRYSZKIEWICZ M, 1993, 4293 ICS; Lasek P., 2008, T ROUGH SETS, V9, P76; LI J, 2001, THESIS U MELBOURNE; LI J, 1998, LNCS, V1424, P191; Li J, 2001, Genome Inform, V12, P3; Li JY, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P430; Li J., 2001, KNOWL INF SYST, V3, P131, DOI 10.1007/PL00011662; Li J., 2000, ICML 2000, P551; Li JY, 2004, MACH LEARN, V54, P99, DOI 10.1023/B:MACH.0000011804.08528.7d; Li JY, 2002, BIOINFORMATICS, V18, P725, DOI 10.1093/bioinformatics/18.5.725; Li JY, 2004, DATA MIN KNOWL DISC, V9, P89, DOI 10.1023/B:DAMI.0000026901.85057.58; LI W, 2001, CLASSIFICATION BASED; Li Wenmin, 2001, ICDM, P369; Li YQ, 2006, NEURAL COMPUT, V18, P2730, DOI 10.1162/neco.2006.18.11.2730; Lin T. Y., 2002, DATA MINING ROUGH SE; Lingras P, 1998, INFORM SCIENCES, V110, P207, DOI 10.1016/S0020-0255(97)10045-7; LINGRAS P, 2002, CLUTO CLUSTERING TOO, P369; LIU B, 1998, LNCS, V1424, P504; Liu B., 1998, KNOWLEDGE DISCOVERY, P80; LOEKITO E, 2006, KDD, P307; MERETAKIS D, 1999, KNOWLEDGE DISCOVERY, P165; MERRIS R, 2000, GRAPH THEORY; Minato S., 1996, BINARY DECISION DIAG; Minato S., 1993, DES AUT C, P272; MISHCHENKO A, 2001, INTRO ZERO SUPPRESSE; Nguyen HS, 1999, LECT NOTES ARTIF INT, V1711, P137; NGUYEN HS, 2003, LNCS, V2762, P545; PADMANABBAN B, 2000, KDD 2000, P54; Pasquier N, 1999, LECT NOTES COMPUT SC, V1540, P398; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Pawlak Z, 2007, INFORM SCIENCES, V177, P28, DOI 10.1016/j.ins.2006.06.006; PAWLAK Z, 1995, COMPUTATIONAL INTELL, V11, P232; Pawlak Z., 1992, ROUGH SETS THEORETIC; Pawlak Z, 1999, INT J HUM-COMPUT ST, V51, P369, DOI 10.1006/ijhc.1983.0315; Pawlak Z, 2007, INFORM SCIENCES, V177, P3, DOI 10.1016/j.ins.2006.06.003; Polkowski L., 2002, ROUGH SETS MATH FDN; Polkowski L., 1998, LNCS, V1424; Qian XY, 2006, LECT NOTES COMPUT SC, V4304, P295; RAMAMOHANARAO K, 2005, ICISIP, P39; ROMANSKI S, 1988, JCDKB, P310; ROMANSKI S, 1989, THESIS WARSAW U TECH; RUIZ IF, 2001, LNCS LNAI, V2226, P50; SAPIECHA P, 1992, 2192 ICS; Savasere A., 1998, ICDE, P494; SHAN N, 1994, INT WORKSH ROUGH SET, P326; Skowron A., 1995, KDD-95 Proceedings. First International Conference on Knowledge Discovery and Data Mining; Skowron A, 1994, ROUGH SET THEORY EVI, P193; Skowron A, 2004, FUND INFORM, V59, P241; SKOWRON A, 1993, IJCAI, P622; Skowron A, 2005, FUND INFORM, V64, P417; Skowron A., 1992, INTELLIGENT DECISION, P331; SLEZAK D, 2005, LNCS LNAI, V3641; SLEZAK D, 1996, INT C INF PROC MAN U, V3, P1159; SLEZAK D, 2000, LNCS, V1910, P157; Slezak D, 2002, FUND INFORM, V53, P365; Slezak D, 2005, LECT NOTES COMPUT SC, V3488, P354; Soulet A, 2007, LECT NOTES COMPUT SC, V4747, P223; Soulet A, 2005, LECT NOTES COMPUT SC, V3377, P173; Stefanowski J, 2007, T ROUGH SETS, V6, P329; SUSMAGA R, 2003, LNCS, V2762, P450; SUZUKI E, 1997, KDD, P259; Swiniarski RW, 2003, PATTERN RECOGN LETT, V24, P833, DOI 10.1016/S0167-8655(02)00196-4; TERLECKI P, 1994, ICTAI, P39; TERLECKI P, 2002, CLUTO CLUSTERING TOO, P438; Terlecki P, 2007, LECT NOTES ARTIF INT, V4482, P363; TERLECKI P, 2000, LNCS, V1910, P358; Terlecki P, 2007, INFORM SCIENCES, V177, P5675, DOI 10.1016/j.ins.2007.07.018; TERLECKI P, 2008, T COMPUTATIONAL SCI, V2, P118; Terlecki P, 2008, LECT NOTES ARTIF INT, V5012, P723, DOI 10.1007/978-3-540-68125-0_69; Terlecki P, 2007, INFORM SCIENCES, V177, P74, DOI 10.1016/j.ins.2006.04.002; Terlecki P, 2006, LECT NOTES ARTIF INT, V4062, P268; TERLECKI P, 2007, ICCS WORKSH; TING RMH, 2006, SDM; VAILAYA A, 2000, REJECT OPTION VQ BAS, P2048; WALCZAK Z, 2004, NAT C EV COMP GLOB O; WANG G, 2008, LNCS LNAI, V5009; Wang JY, 2005, IEEE T KNOWL DATA EN, V17, P652; Wang LS, 2005, THEOR COMPUT SCI, V335, P15, DOI 10.1016/j.tcs.2004.12.014; WANG X, 1993, IJCAI, P451; Wang Z, 2004, LECT NOTES ARTIF INT, V3339, P1062; Wegener I., 1987, COMPLEXITY BOOLEAN F; WOJNA A, 2004, THESIS U WARSAW; WROBLEWSKI J, 2001, THESIS U WARSAW; WROBLEWSKI J, 1995, JCIS 95, P186; Wu XD, 2004, ACM T INFORM SYST, V22, P381, DOI 10.1145/1010614.1010616; Yao YY, 2004, LECT NOTES COMPUT SC, V3135, P297; Yao YY, 2008, INT J APPROX REASON, V49, P255, DOI 10.1016/j.ijar.2007.05.019; Yoon HS, 2005, LECT NOTES COMPUT SC, V3610, P965; YU LTH, 2004, C AS PAC BIOINF DUN, P75; Yuan XH, 2002, IEEE SYMP COMP COMMU, P623; ZHOU PL, 2007, PDPTA, P924; ZIARKO W, 1993, IJCAI, P283; ZIGHED DA, 2000, LNCS, V1910	163	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-14466-0	LECT NOTES COMPUT SC			2010	6190						236	338			10.1007/978-3-642-14467-7	103	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BSO37	WOS:000285116400013	
S	Metzler, J; Willersinn, D		Rahman, Z; Reichenbach, SE; Neifeld, MA		Metzler, Juergen; Willersinn, Dieter			Human Detection in MOUT Scenarios using Covariance Descriptors and Supervised Manifold Learning	VISUAL INFORMATION PROCESSING XIX	Proceedings of SPIE		English	Proceedings Paper	Conference on Visual Information Processing XIX	APR 06-07, 2010	Orlando, FL	SPIE		covariance descriptor; human detection; Laplacian Eigenmaps; military operations in urban terrain; region covariance; supervised manifold learning	NONLINEAR DIMENSIONALITY REDUCTION; COMPONENT ANALYSIS; IMAGE; FRAMEWORK; NETWORKS	Military Operations in Urban Terrain (MOUT) require the capability to perceive and to analyse the situation around a patrol in order to recognize potential threats. As in MOUT scenarios threats usually arise from humans one important task is the robust detection of humans. Detection of humans in MOUT by image processing systems can be very challenging, e.g., due to complex outdoor scenes where humans have a weak contrast against the background or are partially occluded. Porikli et al. introduced covariance descriptors and showed their usefulness for human detection in complex scenes. However, these descriptors do not lie on a vector space and so well-known machine learning techniques need to be adapted to train covariance descriptor classifiers. We present a novel approach based on manifold learning that simplifies the classification of covariance descriptors. In this paper, we apply this approach for detecting humans. We describe our human detection method and evaluate the detector on benchmark data sets generated from real-world image sequences captured during MOUT exercises.	[Metzler, Juergen; Willersinn, Dieter] Fraunhofer Inst Optron Syst Technol & Image Explo, D-76131 Karlsruhe, Germany	Metzler, J (reprint author), Fraunhofer Inst Optron Syst Technol & Image Explo, Fraunhoferstr 1, D-76131 Karlsruhe, Germany.						Belkin M., 2002, NEURAL COMPUT, V4, P1373; Belkin M, 2002, ADV NEUR IN, V14, P585; Camastra F., 2007, ADV INFORM KNOWLEDGE; Cayton L., 2005, ALGORITHMS MANIFOLD; Chung F., 1996, CBMS LECT FRESN; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dalal N., 2005, COMPUTER VISION PATT; Forstner W., 1987, P ISPRS INT C FAST P, P281; Forstner W., 1999, METRIC COVARIANCE MA; Gavrila DM, 2007, INT J COMPUT VISION, V73, P41, DOI 10.1007/s11263-006-9038-7; GNANADESIKAN R, 1969, MULTIVARIATE ANAL, V2; GREG A, 2003, CVPR, V2, P681; Harris C., 1988, P 4 ALV VIS C, P147; HEINZE N, 2007, SPIE DEF SEC S ORL; Horn R., 1985, MATRIX ANAL; HUBNER Y, 2008, P SPIE DEF SEC EUR C; KARCHER H, 1977, COMMUN PUR APPL MATH, V30, P509, DOI 10.1002/cpa.3160300502; KENDALL WS, 1990, P LOND MATH SOC, V61, P371; KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209; KRUGER W, 2001, MACH VISION APPL, V13, P30; Lawrence ND, 2004, ADV NEUR IN, V16, P329; Lee DJ, 2004, P SOC PHOTO-OPT INS, V5438, P81, DOI 10.1117/12.542981; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; LEIBE B, 2004, ECCV 04 WORKSH STAT; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; PAISITKRIANGKRA S, 2008, P IEEE C DIG IM COMP, P53; Pearson K, 1901, PHILOS MAG, V2, P559; Pennec X, 2006, J MATH IMAGING VIS, V25, P127, DOI 10.1007/s10851-006-6228-4; Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Porikli F., 2005, P IEEE C COMP VIS PA; Porikli F, 2006, IEEE IMAGE PROC, P1581, DOI 10.1109/ICIP.2006.312610; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Saul L. K., 2003, J MACHINE LEARNING R, V4, P119; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SKOVGAARD LT, 1984, SCAND J STAT, V11, P211; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; TUZEL O, 2006, EUR C COMP VIS GRAZ, V2, P589; Tuzel O., 2007, CVPR; Utsumi A, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P39; Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8; von Luxburg U, 2007, TR149 M PLANCK I BIO	42	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	978-0-8194-8165-8	PROC SPIE			2010	7701								770106	10.1117/12.850213		11	Engineering, Electrical & Electronic; Optics	Engineering; Optics	BSO07	WOS:000285051200005	
S	Yu, XA; Wei, X; Lin, X		Wang, FL; Gong, ZG; Luo, XF; Lei, JS		Yu, Xiao; Wei, Xu; Lin, Xia			Algorithms of BBS Opinion Leader Mining Based on Sentiment Analysis	WEB INFORMATION SYSTEMS AND MINING	Lecture Notes in Computer Science		English	Proceedings Paper	International Conference on Web Information Systems and Mining	OCT 23-24, 2010	Sanya, PEOPLES R CHINA	Hainan Province Inst Comp, Qiongzhou Univ		social network; Opinion Leader; community discovery; sentiment analysis		Opinion leaders play a crucial role in online communities, which can guide the direction of public opinion. Most proposed algorithms on opinion leaders mining in internet social network are based on network structure and usually omit the fact that opinion leaders are field-limited and the opinion sentiment orientation analysis is the vital factor of one's authority. We propose a method to find the interest group based on topic content analysis, which combine the advantages of clustering and classification algorithms. Then we use the method of sentiment analysis to define the authority value as the weight of the link between users. On this basis, an algorithm named LeaderRank is proposed to identify the opinion leaders in BBS, and experiments indicate that LeaderRank algorithm can effectively improve the accuracy of leaders mining.	[Yu, Xiao; Wei, Xu; Lin, Xia] Huazhong Univ Sci & Technol, Elect & Informat Engn Dept, Wuhan 430074, Peoples R China	Yu, XA (reprint author), Huazhong Univ Sci & Technol, Elect & Informat Engn Dept, Wuhan 430074, Peoples R China.	xiaoyu@mail.hust.edu.cn; xuwei@mail.hust.edu.cn; xialin@mail.hust.edu.cn					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; MATSUMURA N, 2002, WWW 2002; NEWMAN ME, 2004, J PHYS REV E; Scott J, 2000, SOCIAL NETWORK ANALY; WU F, 2003, J EURO PHYS J B, V38, P331; YANG S, 2009, EMOTION MINING RES M, P71; ZHAI ZW, 2008, J IEEE P WEB INTELLI; ZHANG J, 2007, J WWW 2007; Zhou HM, 2009, ISI: 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS, P266	9	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-16514-6	LECT NOTES COMPUT SC			2010	6318						360	369				10	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BTB82	WOS:000286404600045	
S	Rajan, P; Canto, M; Gorospe, E; Almario, A; Kage, A; Winter, C; Hager, G; Wittenberg, T; Munzenmayer, C		Dossel, O; Schlegel, WC		Rajan, P.; Canto, M.; Gorospe, E.; Almario, A.; Kage, A.; Winter, C.; Hager, G.; Wittenberg, T.; Muenzenmayer, C.			AUTOMATED DIAGNOSIS OF BARRETT'S ESOPHAGUS WITH ENDOSCOPIC IMAGES	WORLD CONGRESS ON MEDICAL PHYSICS AND BIOMEDICAL ENGINEERING, VOL 25, PT 4: IMAGE PROCESSING, BIOSIGNAL PROCESSING, MODELLING AND SIMULATION, BIOMECHANICS	IFMBE Proceedings		English	Proceedings Paper	World Congress on Medical Physics and Biomedical Engineering	SEP 07-12, 2009	Munich, GERMANY	IUPESM, IOMP			TEXTURE CLASSIFICATION; FEATURES	In this paper, we describe current progress on the development of a Computer Assisted Diagnosis System (CAD) for the classification of Barrett's esophagus and associated neoplasia. Barrett's esophagus is a condition in which normal squamous mucosa is replaced by columnar epithelium, which is similar to the lining of the intestine. Barrett's esophagus as a known precancerous condition leading to esophageal cancer. Diagnosis is performed via histological analysis of tissue located during endoscopic examination. We compare four different automated classification tools (SVM, KNN, and Boosting) operating on three different imaging modalities (white light, narrow-band, and acetic acid chromoendoscopy) for lesion classification. Preliminary results suggest that narrow band imaging is more effective than either of the other two modalities for disease assessment.	[Rajan, P.; Hager, G.] Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA	Munzenmayer, C (reprint author), Fraunhofer Inst Integrated Circuits IIS, Wolfsmantel 33, Erlangen, Germany.	christian.muenzenmayer@iis.fraunhofer.de					Bishop C. M., 2006, PATTERN RECOGNITION; Camilleri M, 2005, CLIN GASTROENTEROL H, V3, P543, DOI 10.1053/S1542-3565(05)00153-9; CHEN YQ, 1995, PATTERN RECOGN, V28, P537, DOI 10.1016/0031-3203(94)00116-4; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fortun PJ, 2006, ALIMENT PHARM THERAP, V23, P735, DOI 10.1111/j.1365-2036.2006.02823.x; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Guelrud M, 1998, GASTROINTEST ENDOSC, P57; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Kage A, 2008, BILDVERARBEITUNG MED, P272, DOI 10.1007/978-3-540-78640-5_55; Mitchell TM, 1999, COMMUN ACM, V42, P30, DOI 10.1145/319382.319388; Munzenmayer C, 2006, THESIS U KOBLENZ LAN; OHANIAN PP, 1992, PATTERN RECOGN, V25, P819, DOI 10.1016/0031-3203(92)90036-I; Palm C, 2004, PATTERN RECOGN, V37, P965, DOI 10.1016/j.patcog.2003.09.010; Wanderley JFC, 2001, IEEE T IMAGE PROCESS, V10, P1630, DOI 10.1109/83.967391; Wittenberg T, 2003, ADV QUANTITATIVE LAR	15	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1680-0737	978-3-642-03881-5	IFMBE PROC			2010	25		4				2189	2192				4	Engineering, Biomedical	Engineering	BZB27	WOS:000300975300581	
S	Laranjeiro, N; Oliveira, R; Vieira, M			IEEE	Laranjeiro, Nuno; Oliveira, Rui; Vieira, Marco			Applying Text Classification Algorithms in Web Services Robustness Testing	2010 29TH IEEE INTERNATIONAL SYMPOSIUM ON RELIABLE DISTRIBUTED SYSTEMS SRDS 2010	Symposium on Reliable Distributed Systems Proceedings		English	Proceedings Paper	29th IEEE International Symposium on Reliable Distributed Systems	OCT 31-NOV 03, 2010	New Delhi, INDIA	IEEE Comp Soc Tech Comm, Micrisoft Res, IBM, NSF		web services; robustnes testing; classification	LINEAR CLASSIFICATION; OPERATING-SYSTEMS; CATEGORIZATION	Testing web services for robustness is an effective way of disclosing software bugs. However, when executing robustness tests, a very large amount of service responses has to be manually classified to distinguish regular responses from responses that indicate robustness problems. Besides requiring a large amount of time and effort, this complex classification process can easily lead to errors resulting from the human intervention in such a laborious task. Text classification algorithms have been applied successfully in many contexts (e.g., spam identification, text categorization, etc) and are considered a powerful tool for the successful automation of several classification-based tasks. In this paper we present a study on the applicability of five widely used text classification algorithms in the context of web services robustness testing. In practice, we assess the effectiveness of Support Vector Machines, Naive Bayes, Large Linear Classification, K-nearest neighbor (Ibk), and Hyperpipes in classifying web services responses. Results indicate that these algorithms can be effectively used to automate the identification of robustness issues while reducing human intervention. However, in all mechanisms there are cases of misclassified responses, which means that there is space for improvement.	[Laranjeiro, Nuno; Oliveira, Rui; Vieira, Marco] Univ Coimbra, CISUC, Dept Informat Engn, P-3000 Coimbra, Portugal	Laranjeiro, N (reprint author), Univ Coimbra, CISUC, Dept Informat Engn, P-3000 Coimbra, Portugal.	cnl@dei.uc.pt; racoliv@student.dei.uc.pt; mvieira@dei.uc.pt					Cohen W. W., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Curbera F, 2002, IEEE INTERNET COMPUT, V6, P86, DOI 10.1109/4236.991449; Eisenstein J., 2004, P 6 INT C MULT INT I, P113, DOI 10.1145/1027933.1027954; Erl T., 2005, SERVICE ORIENTED ARC; Fan RE, 2008, J MACH LEARN RES, V9, P1871; Hall M., 2009, SIGKDD EXPLORATIONS, V11, P10, DOI DOI 10.1145/1656274.1656278; Joachims T., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings; KALAPANIDAS SE, 2003, 1 BALC C INF THESS, P356; Kobayashi T, 2009, LECT NOTES ARTIF INT, V5632, P137, DOI 10.1007/978-3-642-03070-3_11; Koopman P, 1999, DIG PAP INT SYMP FAU, P30, DOI 10.1109/FTCS.1999.781031; Koopman P, 1997, SYM REL DIST SYST, P72; Laranjeiro N, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON SERVICES COMPUTING, PROCEEDINGS, VOL 2, P187, DOI 10.1109/SCC.2008.123; LIU FY, HUMAN INTERACTION MA, P13; OLIVEIRA R, DATASET CLASSIFICATI; Popa IS, 2007, COMP MED SY, P421, DOI 10.1109/CBMS.2007.108; RODRIGUEZ M, 1999, 3 EUR DEP COMP C EDD, P143; Rogati M., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; SIBLINI R, 2005, 3 ACS IEEE INT C COM, P135; Vieira M, 2007, I C DEPEND SYS NETWO, P131, DOI 10.1109/DSN.2007.16; Wang BY, 2005, PDCAT 2005: SIXTH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS AND TECHNOLOGIES, PROCEEDINGS, P913; XU W, 2005, 16 IEEE INT S SOFTW, P10; Yang Y., 1994, 17 ANN INT ACM SIGIR, P13; Zhang T, 2001, INFORM RETRIEVAL, V4, P5, DOI 10.1023/A:1011441423217	26	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1060-9857	978-0-7695-4250-8	SYM REL DIST SYST			2010							255	264		10.1109/SRDS.2010.36		10	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BTO39	WOS:000287486100028	
B	Lai, JC; Leung, FH; Ling, SH			IEEE	Lai, Johnny C.; Leung, Frank H.; Ling, Sai-Ho			A New Differential Evolution with Self-terminating Ability using Fuzzy Control and K-Nearest Neighbors	2010 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC)	IEEE Congress on Evolutionary Computation		English	Proceedings Paper	2010 IEEE World Congress on Computational Intelligence	JUL 18-23, 2010	Barcelona, SPAIN	IEEE, IEEE Computat Intelligence Soc, Int Neural Network Soc, Evolut Program Soc, IET			OPTIMIZATION	A new Differential Evolution (DE) that incorporates fuzzy control and k-nearest neighbors algorithm to determine the terminating condition is proposed. A technique called Iteration Windows is introduced to govern the number of iteration in each searching stage. The size of the iteration windows is controlled by a fuzzy controller, which uses the information provided by the k-nearest neighbors system to analyze the population during the searching process. The controller keeps controlling the iteration windows until the end of the searching process. The wavelet based mutation process is embedded in the DE searching process to enhance the searching performance of DE. The F weight of DE is also controlled by the fuzzy controller to further speed up the searching process. A suite of benchmark test functions is employed to evaluate the performance of the proposed method. It is shown empirically that the proposed method can terminate the searching process with a reasonable number of iteration.	[Lai, Johnny C.; Leung, Frank H.] Hong Kong Polytech Univ, Dept Elect & Informat Engg, Ctr Signal Proc, Hung Ham, Hong Kong, Peoples R China	Lai, JC (reprint author), Hong Kong Polytech Univ, Dept Elect & Informat Engg, Ctr Signal Proc, Hung Ham, Hong Kong, Peoples R China.	08900438r@polyu.edu.hk; enfrank@inet.polyu.edu.hk; steve.ling@uts.edu.au					Babu B.V., 2001, P 12 ISME INT C MECH, P153; BOSC P, 1997, FUZZY INFORM ENG GUI, P233; Bremner D, 2005, DISCRETE COMPUT GEOM, V33, P593, DOI 10.1007/s00454-004-1152-0; Chakraborty U.K., 2008, ADV DIFFERENTIAL EVO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EFTEKHARI MM, 2003, ENERGY BUILDINGS, V35; Fogel LJ, 1994, COMPUTATIONAL INTELL; Goldberg D. E, 1989, GENETIC ALGORITHMS S; GRABOT B, 1997, FUZZY INFORM ENG GUI, P695; Klir G.J., 1988, FUZZY SETS UNCERTAIN; Ling SH, 2008, IEEE T SYST MAN CY B, V38, P743, DOI 10.1109/TSMCB.2008.921005; MAMDANI EH, 1975, INT J MAN MACH STUD, V7, P1, DOI 10.1016/S0020-7373(75)80002-2; PATERLINI S, 2004, P IEEE C EV COMP, V2, P2004; Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328; Toussaint G, 2005, INT J COMPUT GEOM AP, V15, P101, DOI 10.1142/S0218195905001622; Van Sickel J. H., 2007, P INT SYST APPL POW, P1; Yao X, 1999, IEEE T EVOLUT COMPUT, V3, P82; Zahan S., 1999, FUZZY NEURO FUZZY SY	18	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-8126-2	IEEE C EVOL COMPUTAT			2010												8	Engineering, Electrical & Electronic; Mathematical & Computational Biology	Engineering; Mathematical & Computational Biology	BTM91	WOS:000287375801030	
B	Triguero, I; Garcia, S; Herrera, F			IEEE	Triguero, Isaac; Garcia, Salvador; Herrera, Francisco			A preliminary study on the use of differential evolution for adjusting the position of examples in nearest neighbor classification	2010 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC)	IEEE Congress on Evolutionary Computation		English	Proceedings Paper	2010 IEEE World Congress on Computational Intelligence	JUL 18-23, 2010	Barcelona, SPAIN	IEEE, IEEE Computat Intelligence Soc, Int Neural Network Soc, Evolut Program Soc, IET			MULTIPLE DATA SETS; STATISTICAL COMPARISONS; GLOBAL OPTIMIZATION; LEARNING ALGORITHMS; CLASSIFIERS; REDUCTION; SELECTION; SPACES	Nearest neighbor is one of the most successfully used techniques for performing classification and pattern recognition tasks. Its simplicity and effectiveness justify the use of this technique in certain domains but it however presents several drawbacks referring to time response, noise sensitivity and storage requirements. Several solutions have been proposed in order to alleviate these problems, such as improving the technique for speeding up or carrying out a data reduction process. Prototype generation is a suitable process for data reduction that allows to fit a data set for nearest neighbor classification. Position adjustment of prototypes is a successful technique within the prototype generation methodology. Evolutionary algorithms are adaptive methods based on natural evolution that may be used for search and optimization. Position adjustment of prototypes can be viewed as a search problem, thus it could be solved using evolutionary algorithms. In this paper, we perform a preliminary study on the use of differential evolution algorithms to the prototype generation problem. Differential evolution models are compared with other algorithms for adjusting the position of prototypes and the results are contrasted through non-parametrical statistical tests. The results show that some differential evolution models consistently outperform previously proposed methods.	[Triguero, Isaac; Herrera, Francisco] Univ Granada, Dept Comp Sci & Artificial Intelligence, CITIC UGR Res Ctr Informat & Commun Technol, E-18071 Granada, Spain	Triguero, I (reprint author), Univ Granada, Dept Comp Sci & Artificial Intelligence, CITIC UGR Res Ctr Informat & Commun Technol, E-18071 Granada, Spain.	triguero@decsai.ugr.es; sglopez@ujaen.es; herrera@decsai.ugr.es	Herrera, Francisco/C-6856-2008	Herrera, Francisco/0000-0002-7283-312X			AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Alpaydin E., 2010, INTRO MACHINE LEARNI; Asuncion A., 2007, UCI MACHINE LEARNING; Cano JR, 2003, IEEE T EVOLUT COMPUT, V7, P561, DOI 10.1109/TEVC.2003.819265; Cervantes A, 2009, IEEE T SYST MAN CY B, V39, P1082, DOI 10.1109/TSMCB.2008.2011816; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; Chen CH, 1996, PATTERN RECOGN LETT, V17, P819, DOI 10.1016/0167-8655(96)00041-4; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Das S, 2009, IEEE T EVOLUT COMPUT, V13, P526, DOI 10.1109/TEVC.2008.2009457; Demsar J, 2006, J MACH LEARN RES, V7, P1; Fernandez A, 2010, IEEE T EVOLUT COMPUT, V14, P913, DOI 10.1109/TEVC.2009.2039140; Fernandez F, 2004, J HEURISTICS, V10, P431, DOI 10.1023/B:HEUR.0000034715.70386.5b; Garain U, 2008, PATTERN ANAL APPL, V11, P353, DOI 10.1007/s10044-008-0106-1; Garcia S, 2008, PATTERN RECOGN, V41, P2693, DOI 10.1016/j.patcog.2008.02.006; Garcia S, 2008, J MACH LEARN RES, V9, P2677; KENNEDY J, 1995, IEEE INT C NEUR NETW, P1942; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Llora X, 2001, P 18 INT C MACH LEAR, P337; Lozano M, 2006, PATTERN RECOGN, V39, P1827, DOI 10.1016/j.patcog.2006.04.005; Nanni L., 2008, NEUROCOMPUTING, V72, P1092; NERI F, 2001, MEMETIC COMPUTING, V2, P153; Neri F, 2010, ARTIF INTELL REV, V33, P61, DOI 10.1007/s10462-009-9137-2; PRICE KV, 2005, NAT COMP SER, pR7; Qin AK, 2009, IEEE T EVOLUT COMPUT, V13, P398, DOI 10.1109/TEVC.2008.927706; Rahnamayan S, 2008, IEEE T EVOLUT COMPUT, V12, P64, DOI 10.1109/TEVC.2007.894200; Sheskin D., 2006, HDB PARAMETRIC NONPA; Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Zhang JQ, 2009, IEEE T EVOLUT COMPUT, V13, P945, DOI 10.1109/TEVC.2009.2014613	29	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-8126-2	IEEE C EVOL COMPUTAT			2010												8	Engineering, Electrical & Electronic; Mathematical & Computational Biology	Engineering; Mathematical & Computational Biology	BTM91	WOS:000287375804024	
S	Ashkezari, S; Akbarzadeh, MR			IEEE	Ashkezari-T, Soheila; Akbarzadeh-T, Mohammad-R			Fuzzy-Bayesian Network Approach to Genre-based Recommender Systems	2010 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS (FUZZ-IEEE 2010)	IEEE International Conference on Fuzzy Systems		English	Proceedings Paper	2010 IEEE World Congress on Computational Intelligence	JUL 18-23, 2010	Barcelona, SPAIN	IEEE, IEEE Computat Intelligence Soc, Int Neural Network Soc, Evolut Program Soc, IET				The World Wide Web has created a new media for mass marketing that can also be highly customized to online customers' needs and expectations. Recommender Systems (RS) play an important role in this area. Here, we aim to establish a genre-based collaborative RS to automatically suggest and rank a list of appropriate items (movies) to a user based on the user profile and the past voting patterns of other users with similar tastes. The contribution of this paper is using genre based information in a hybrid fuzzy-Bayesian network collaborative RS. The interest to the different genres is computed based on a hybrid user model. The similarity of like-minded users according to the fuzzy distance and also Pearson correlation coefficient is involved in a Bayesian network.	[Ashkezari-T, Soheila; Akbarzadeh-T, Mohammad-R] Ferdowsi Univ Mashhad, Ctr Appl Res Soft Comp & Intelligent Syst, Dept Comp Engn, Cognit Comp Lab, Mashhad 917751111, Iran	Ashkezari, S (reprint author), Ferdowsi Univ Mashhad, Ctr Appl Res Soft Comp & Intelligent Syst, Dept Comp Engn, Cognit Comp Lab, Mashhad 917751111, Iran.	Soheila.Ashkezari@stu-mil.um.ac.ir					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; de Campos LM, 2008, FUZZY SET SYST, V159, P1554, DOI 10.1016/j.fss.2008.01.016; HERLOCKER JL, 2003, EVALUATING COLLABORA; Krulwich B, 1997, AI MAG, V18, P37; Kyoung-jae Kim, 2008, Expert Systems with Applications, V34, DOI 10.1016/j.eswa.2006.12.025; LANG K, P 1995 12 INT C MACH; Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344; MARTINEZ ABB, 2009, IEEE T CONSUMER ELEC, V55; MILLER B, 2002 P INT C INT US, P263; MOONEY RJ, DL 00, P195; O'Sullivan D, 2004, USER MODEL USER-ADAP, V14, P5, DOI 10.1023/B:USER.0000010131.72217.12; Pazzani M., 1999, ARTIF INTELL, p393~408; Resnick P, P 1994 ACM C COMP SU, P175; SHARDANAND U, P 1995 C HUM FACT CO, P210; SYMEONIDIS P, 2008, EXPERT SYSTEMS APPL, V34; Symeonidis P., 2008, IEEE T SYSTEMS MAN C, V38; YAHYA M, 2008, EXPERT SYSTEMS APPL, V35, P1386; YOSHII K, 2008, IEEE T AUDIO SPEECH, V16	18	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7584	978-1-4244-6920-8	IEEE INT CONF FUZZY			2010												7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BTO07	WOS:000287453601108	
S	Hartert, L; Mouchaweh, MS; Billaudel, P			IEEE	Hartert, L.; Mouchaweh, M. Sayed; Billaudel, P.			Dynamic K-Nearest Neighbors For The Monitoring Of Evolving Systems	2010 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS (FUZZ-IEEE 2010)	IEEE International Conference on Fuzzy Systems		English	Proceedings Paper	2010 IEEE World Congress on Computational Intelligence	JUL 18-23, 2010	Barcelona, SPAIN	IEEE, IEEE Computat Intelligence Soc, Int Neural Network Soc, Evolut Program Soc, IET			CLASSIFICATION	In this article, a new Pattern Recognition (PR) approach is proposed to monitor the functioning modes evolutions in dynamic systems. When a functioning mode evolves, the system characteristics change and the observations, i.e. the patterns, obtained on the system change too. In this case, classes representing the system functioning modes have to be updated by keeping representative patterns only. The developed PR approach is based on the K-Nearest Neighbors (KNN) method. It is named Dynamic KNN (DKNN) and comprises two phases: a detection phase to detect and confirm classes evolutions and an adaptation phase realized incrementally to update the evolved classes parameters and reduce the dataset. To illustrate this approach, the monitoring of weldings quality (good or bad) is realized on an industrial system, based on acoustic noises issued of weldings operations.	[Hartert, L.; Mouchaweh, M. Sayed; Billaudel, P.] Univ Reims, Ctr Rech STIC URCA CReSTIC, F-51687 Reims, France	Hartert, L (reprint author), Univ Reims, Ctr Rech STIC URCA CReSTIC, Moulin Housse,BP 1039, F-51687 Reims, France.	laurent.hartert@univ-reims.fr; moamar.sayed-mouchaweh@univ-reims.fr; patrice.billaudel@univ-reims.fr					AMADOUBOUBACAR H, 2005, IEEE IJCNN05 P MONTR; Angelov P, 2004, INFORM SCIENCES, V161, P21, DOI 10.1016/j.ins.2003.03.006; Angstenberger L., 2000, THESIS RHEINISCH WES; Chiementin X, 2008, J VIB CONTROL, V14, P1675, DOI 10.1177/1077546307082985; Cohen L., 2004, TDM WORKSH BRIGHT UK; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUBUISSON B, 1990, TRAITE NOUVELLES DM; Duda R. O., 2001, PATTERN CLASSIFICATI; Fix E., 1951, DISCRIMINATORY ANAL, P261; GIBB WJ, 1994, IEEE T BIO-MED ENG, V41, P804, DOI 10.1109/10.310096; Guedalia ID, 1999, NEURAL COMPUT, V11, P521, DOI 10.1162/089976699300016755; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; LAW YN, 2005, 9 EUR C PRINC PRACT; Manders EJ, 2000, IEEE T INSTRUM MEAS, V49, P503, DOI 10.1109/19.850384; MIN R, 2005, THESIS U TORONTO; Nakhaeizadeh G., 1997, CLASSIFICATION KNOWL, P123; RONCAGLIA A, 2004, IEEE SENSOR J, V4; VACHKOV G, 2009, IFSA EUSFLAT 09 LISB	18	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7584	978-1-4244-6920-8	IEEE INT CONF FUZZY			2010												7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BTO07	WOS:000287453602047	
S	Heo, G; Klette, R; Woo, YW; Kim, KB; Kim, NH			IEEE	Heo, Gyeongyong; Klette, Reinhard; Woo, Young Woon; Kim, Kwang-Baek; Kim, Nam Ho			Fuzzy Support Vector Machine with a Fuzzy Nearest Neighbor Classifier for Insect Footprint Classification	2010 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS (FUZZ-IEEE 2010)	IEEE International Conference on Fuzzy Systems		English	Proceedings Paper	2010 IEEE World Congress on Computational Intelligence	JUL 18-23, 2010	Barcelona, SPAIN	IEEE, IEEE Computat Intelligence Soc, Int Neural Network Soc, Evolut Program Soc, IET			SVM	The support vector machine (SVM) of statistical learning theory was successfully applied in various fields, but still suffers from noise sensitivity originating from the fact that all the data points are treated equally. To relax this problem, the SVM was extended into a fuzzy SVM (FSVM) by the introduction of fuzzy memberships. The FSVM also has been further extended in two ways, by adopting a different objective function with the help of domain-specific knowledge, or by employing a different membership calculation method. In this paper we follow the second approach by proposing a new membership calculation method using a fuzzy k nearest neighbor classifier (F-KNN). Although there are already several membership calculation methods to enhance the performance of the FSVM, one problem in those methods is that they assume a specific data distribution. The F-KNN does not assume any data distribution, which helps the proposed method to accommodate various data distributions in real world problems. The proposed algorithm was applied to an insect footprint classification problem, and results verify the effectiveness of the method.	[Heo, Gyeongyong; Woo, Young Woon] Dong Eui Univ, Dept Multimedia Engn, Pusan, South Korea	Heo, G (reprint author), Dong Eui Univ, Dept Multimedia Engn, Pusan, South Korea.	gyeongy-ong.heo@gmail.com; r.klette@auckland.ac.nz; ywwoo@deu.ac.kr; gbkim@silla.ac.kr; nhk@pknu.ac.kr					ABUTALEB AS, 1989, COMPUT VISION GRAPH, V47, P22, DOI 10.1016/0734-189X(89)90051-0; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRISTIANINI N, 2004, J MACHINE LEARNING R, V5, P27; FULIN C, 2004, PATTERN RECOGN, V25, P1647; HEO G, 2009, P 2009 INT C FUZZ SY; Hsu C., 2003, PRACTICAL GUIDE SUPP; Jiang XF, 2006, NEURAL COMPUT APPL, V15, P268, DOI 10.1007/s00521-006-0028-z; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Lin CF, 2002, IEEE T NEURAL NETWOR, V13, P464, DOI 10.1109/72.991432; Liu Y, 2007, IEEE T SIGNAL PROCES, V55, P3272, DOI 10.1109/TSP.2007.894403; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SHILTON A, 2007, P IEEE INT C FUZZ SY, P1; Shin BS, 2008, 2008 THIRD INTERNATIONAL CONFERENCE ON BIO-INSPIRED COMPUTING: THEORIES AND APPLICATIONS, P97, DOI 10.1109/BICTA.2008.4656710; SHIN BS, 2007, P 2 PAC RIM S SANT C, P311; Tao Q, 2005, IEEE T NEURAL NETWOR, V16, P1561, DOI 10.1109/tnn.2005.857955; Vapnik V.N., 1998, STAT LEARNING THEORY; Wang L, 2004, INT C PATT RECOG, P981; Wang YQ, 2005, IEEE T FUZZY SYST, V13, P820, DOI 10.1109/TFUZZ.2005.859320	18	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7584	978-1-4244-6920-8	IEEE INT CONF FUZZY			2010												6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BTO07	WOS:000287453600058	
S	Iglesias, JA; Angelov, P; Ledezma, A; Sanchis, A			IEEE	Iglesias, Jose A.; Angelov, Plamen; Ledezma, Agapito; Sanchis, Araceli			User Modeling: Through Statistical Analysis and an Evolving Classifier	2010 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS (FUZZ-IEEE 2010)	IEEE International Conference on Fuzzy Systems		English	Proceedings Paper	2010 IEEE World Congress on Computational Intelligence	JUL 18-23, 2010	Barcelona, SPAIN	IEEE, IEEE Computat Intelligence Soc, Int Neural Network Soc, Evolut Program Soc, IET			SEQUENCE CLASSIFICATION; FUZZY MODELS	Knowledge about computer users is very beneficial for assisting them, predicting their future actions or detecting masqueraders. In this paper, an approach for creating and recognizing automatically the behavior profile of a computer user is combined with an evolving method to keep up to date the created profiles. The behavior of a computer is represented in this research as the sequence of commands s/he types during a period of time. This sequence is treated using statistical methods in order to create the corresponding user profile. However, as a user profile is usually not fixed but rather it changes and evolves, we propose a user profile classifier based on Evolving Systems. This paper describes briefly the model creation method and the evolving classifier, which are compared with well established off-line and on-line classifiers.	[Iglesias, Jose A.; Ledezma, Agapito; Sanchis, Araceli] Univ Carlos III Madrid, CAOS Grp, E-28903 Getafe, Spain	Iglesias, JA (reprint author), Univ Carlos III Madrid, CAOS Grp, E-28903 Getafe, Spain.	jiglesia@inf.uc3m.es; p.angelov@lancaster.ac.uk; ledezma@inf.uc3m.es; masm@inf.uc3m.es					Agrawal R, 1995, INT C DAT ENG, P3; Anderson JR., 1995, LEARNING MEMORY INTE; ANGELOV P, 2002, RULE BASED MODELS TO; Angelov P, 2005, IEEE INT CONF FUZZY, P1068; ANGELOV P, 2007, COMP INT IM SIGN PRO, P220; Angelov PP, 2004, IEEE T SYST MAN CY B, V34, P484, DOI 10.1109/TSMCB.2003.817053; Angelov PP, 2008, IEEE T FUZZY SYST, V16, P1462, DOI 10.1109/TFUZZ.2008.925904; Barrow L., 2008, 14240 NAT BUR EC RES; COULL S, 2003, ACSAC 03 P 19 ANN CO, P24; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FREDKIN E, 1960, COMMUN ACM, V3, P490, DOI 10.1145/367390.367400; Greenberg S., 1988, THESIS U CALGARY ALB; Hackos J., 1998, USER TASK ANAL INTER; Iglesias JA, 2006, LECT NOTES ARTIF INT, V3885, P117; Iglesias JA, 2009, 2009 IEEE WORKSHOP ON EVOLVING AND SELF-DEVELOPING INTELLIGENT SYSTEMS, P16, DOI 10.1109/ESDIS.2009.4938994; Iglesias JA, 2009, LECT NOTES COMPUT SC, V5535, P90, DOI 10.1007/978-3-642-02247-0_11; Iglesias JA, 2007, LECT NOTES COMPUT SC, V4723, P207; Kaminka GA, 2003, LECT NOTES ARTIF INT, V2752, P111; Ma QC, 2001, IEEE T SYST MAN CY C, V31, P468; MACEDO AA, 2003, HYPERTEXT 2003, P48; Nasoz F, 2007, LECT NOTES COMPUT SC, V4552, P421; Pepyne DL, 2004, P AMER CONTR CONF, P982; Quinlan J., 2003, DATA MINING TOOLS SE; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Rish I, 2001, P IJCAI 01 WORKSH EM; SCHONLAU M, 2001, STAT SCI; Spiliopoulou M., 1998, P EDBT WORKSH WEBDB9, P109; Webb G. I, 1993, P AI ED93 WORLD C AR, P497; Webb GI, 2001, USER MODEL USER-ADAP, V11, P19, DOI 10.1023/A:1011117102175; ZHOU X, 2007, COMP INT SEC DEF APP, P131	30	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7584	978-1-4244-6920-8	IEEE INT CONF FUZZY			2010												8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BTO07	WOS:000287453602125	
B	Jia, S; Qian, YT; Li, JM; Liu, WX; Ji, Z			IEEE	Jia, Sen; Qian, Yuntao; Li, Jiming; Liu, Weixiang; Ji, Zhen			FEATURE EXTRACTION AND SELECTION HYBRID ALGORITHM FOR HYPERSPECTRAL IMAGERY CLASSIFICATION	2010 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM	IEEE International Symposium on Geoscience and Remote Sensing IGARSS		English	Proceedings Paper	IEEE International Geoscience and Remote Sensing Symposium	JUN 25-30, 2010	Honolulu, HI	IEEE		Hyperspectral imagery classification; dimensionality reduction; discrete wavelet transform; affinity propagation		Due to the enormous amounts of data contained in hyper-spectral imagery, the main challenge for hyperspectral image classification is to improve the accuracy with less computation complexity. Hence, dimensionality reduction (DR) is often adopted, which includes two different kinds of methods, feature extraction and feature selection. In this paper, discrete wavelet transform (DWT) and affinity propagation (AP), which belong to feature extraction and feature selection respectively, are combined together to accomplish the DR task. Firstly, DWT-based features are extracted from the original hyperspectral data; secondly, AP is applied to select representative features from the obtained ones. Experimental results demonstrate that, compared with some other DR methods which only make use of feature extraction or feature selection, the features acquired by the hybrid technique make the classification results more accurate.	[Jia, Sen; Liu, Weixiang; Ji, Zhen] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen City Key Lab Embedded Syst Design, Shenzhen, Peoples R China	Jia, S (reprint author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen City Key Lab Embedded Syst Design, Shenzhen, Peoples R China.						Berkhin P, 2002, SURVEY CLUSTERING DA; Chang CI, 2006, IEEE T GEOSCI REMOTE, V44, P1575, DOI 10.1109/TGRS.2006.864389; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Frey J., 2007, SCIENCE, V315, P972; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Jia S., 2008, P 2008 DIG IM COMP T, P137, DOI DOI 10.1109/DICTA.2008.42; Lillesand T. M., 2004, REMOTE SENSING IMAGE; Mallat S, 1999, WAVELET TOUR SIGNAL; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; Neher R, 2005, IEEE T GEOSCI REMOTE, V43, P1363, DOI 10.1109/TGRS.2005.846865; [Anonymous], AVIRIS NW INDIANAS I	11	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-9566-5	INT GEOSCI REMOTE SE			2010							72	75		10.1109/IGARSS.2010.5652463		4	Geosciences, Multidisciplinary; Remote Sensing	Geology; Remote Sensing	BTS07	WOS:000287933800019	
B	Kaya, GT; Ersoy, OK; Kamasak, ME			IEEE	Kaya, G. Taskin; Ersoy, O. K.; Kamasak, M. E.			HYBRID SVM AND SVSA METHOD FOR CLASSIFICATION OF REMOTE SENSING IMAGES	2010 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM	IEEE International Symposium on Geoscience and Remote Sensing IGARSS		English	Proceedings Paper	30th IEEE International Geoscience and Remote Sensing Symposium (IGARSS) on Remote Sensing - Global Vision for Local Action	JUN 25-30, 2010	Honolulu, HI	IEEE		Support Vector Machines; Support Vector Selection and Adaptation; Hybrid SVM and SVSA		A linear support vector machine (LSVM) is based on determining an optimum hyperplane that separates the data into two classes with the maximum margin. The LSVM typically has high classification accuracy for linearly separable data. However, for nonlinearly separable data, it usually has poor performance. For this type of data, the Support Vector Selection and Adaptation (SVSA) method was developed, but its classification accuracy is not very high for linearly separable data in comparison to LSVM. In this paper, we present a new classifier that combines the LSVM with the SVSA, to be called the Hybrid SVM and SVSA method (HSVSA), for classification of both linearly and nonlinearly separable data and remote sensing images as well. The experimental results show that the HSVSA has higher classification accuracy than the traditional LSVM, the nonlinear SVM (NSVM) with the radial basis kernel, and the previous SVSA.	[Kaya, G. Taskin] Istanbul Tech Univ, Inst Informat, TR-80626 Istanbul, Turkey	Kaya, GT (reprint author), Istanbul Tech Univ, Inst Informat, TR-80626 Istanbul, Turkey.	gulsen@be.itu.edu.tr; ersoy@purdue.edu; kamasak@itu.edu.tr					Cherkassky V, 1998, LEARNING DATA CONCEP; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Kasapoglu NG, 2007, IEEE T GEOSCI REMOTE, V45, P3880, DOI 10.1109/TGRS.2007.900699; KAYA G, 2009, 4 INT REC ADV SPAC T, P408; KAYA GT, 2009, INT S INN INT SYST A; KAYA GT, 2009, IEEE INT GEOSC REM S; Kohonen T, 1986, TKKFA601 HELS U TECH; Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865; [Yue Shihong 岳士弘], 2003, Applied Mathematics. Series B : A Journal of Chinese Universities, V18, P332, DOI 10.1007/s11766-003-0059-5	9	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-9566-5	INT GEOSCI REMOTE SE			2010							2828	2831				4	Geosciences, Multidisciplinary; Remote Sensing	Geology; Remote Sensing	BTS07	WOS:000287933802250	
S	van Dam, HT; Seifert, S; Vinke, R; Dendooven, P; Lohner, H; Beekman, FJ; Schaart, DR			IEEE	van Dam, Herman T.; Seifert, Stefan; Vinke, Ruud; Dendooven, Peter; Lohner, Herbert; Beekman, Freek J.; Schaart, Dennis R.			An Improved Nearest Neighbor Method for the Estimation of the Gamma Photon Entry Point in Monolithic Scintillator Detectors for PET	2010 IEEE NUCLEAR SCIENCE SYMPOSIUM CONFERENCE RECORD (NSS/MIC)	IEEE Nuclear Science Symposium Conference Record		English	Proceedings Paper	IEEE Nuclear Science Symposium (NSS)/Medical Imaging Conference (MIC)/17th International Workshop on Room-Temperature Semiconductor X-ray and Gamma-ray Detectors	OCT 30-NOV 06, 2010	Knoxville, TN	Inst Elect & Elect Engineers, Nucl & Plasma Sci Soc, IEEE			CLASSIFICATION; DEPTH	Several improvements of the k-nearest neighbor (k-NN) method for the determination of the entry point (x,y) of a gamma photon in a monolithic scintillator PET detector have been investigated with the aim to obtain better spatial resolution and/or to enable faster detector calibration by reducing the amount of required reference data and by allowing for calibrating with a line source. These methods were tested on a dataset measured with a SiPM-array-based monolithic LYSO detector. It appears that similar to 10% to similar to 25% better spatial resolution can be obtained compared to the standard approach. Moreover, some of the improved methods using two orders of magnitude less reference data, yield essentially the same spatial resolution as the standard method, which reduces the time needed for calibration as well as entry point computation. Finally, line source calibration is shown to be possible with some of the methods, yielding better results than the standard method and allowing much faster and easier collection of the reference data.	[van Dam, Herman T.; Seifert, Stefan; Beekman, Freek J.; Schaart, Dennis R.] Delft Univ Technol, NL-2629 JB Delft, Netherlands	Schaart, DR (reprint author), Delft Univ Technol, NL-2629 JB Delft, Netherlands.	d.r.schaart@tudelft.nl					BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Fix E., 1951, 4 USAF SCH AV MED; Hotta S, 2004, INT C PATT RECOG, P412, DOI 10.1109/ICPR.2004.1333790; Ling T, 2007, PHYS MED BIOL, V52, P2213, DOI 10.1088/0031-9155/52/8/012; Maas MC, 2006, IEEE T NUCL SCI, V53, P1071, DOI 10.1109/TNS.2006.873711; Maas MC, 2009, PHYS MED BIOL, V54, P1893, DOI 10.1088/0031-9155/54/7/003; Maas MC, 2010, MED PHYS, V37, P1904, DOI 10.1118/1.3355889; Schaart DR, 2009, PHYS MED BIOL, V54, P3501, DOI 10.1088/0031-9155/54/11/015	10	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1082-3654	978-1-4244-9106-3	IEEE NUCL SCI CONF R			2010							3088	3092				5	Engineering, Electrical & Electronic; Nuclear Science & Technology; Physics, Applied	Engineering; Nuclear Science & Technology; Physics	BBB94	WOS:000306402903056	
S	Liyanage, SR; Xu, JX; Guan, CT; Ang, KK; Lee, TH			IEEE	Liyanage, S. R.; Xu, J. -X.; Guan, C. T.; Ang, K. K.; Lee, T. H.			EEG Signal Separation for Multi-Class Motor Imagery using Common Spatial Patterns Based on Joint Approximate Diagonalization	2010 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS IJCNN 2010	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	World Congress on Computational Intelligence (WCCI 2010)	2010	Barcelona, SPAIN	IEEE			EXTRACTION	The design of multiclass BCI is a very challenging task because of the need to extract complex spatial and temporal patterns from noisy multidimensional time series generated from EEG measurements. This paper proposes a Multiclass Common Spatial Pattern (MCSP) based on Joint Approximate Diagonalization (JAD) for multiclass BCIs. The proposed method based on fast Frobenius diagonalization (FFDIAG) is compared with another method based on Jacobi angles on the BCI competition IV dataset 2a. The classification accuracies obtained from 10x10-fold cross-validations on the training dataset are compared using K-Nearest Neighbor, Classification Trees and Support Vector Machine classifiers. The proposed MCSP based on FFDIAG yields an averaged accuracy of 53.6% compared to 32.8% given by the method based on Jacobi angles and 27.8% of the one versus rest CSP methods.	[Liyanage, S. R.; Lee, T. H.] Natl Univ Singapore, Grad Sch Integrat Sci & Engn, Singapore, Singapore	Liyanage, SR (reprint author), Natl Univ Singapore, Grad Sch Integrat Sci & Engn, Singapore, Singapore.	sidath@nus.edu.sg; elexujx@nus.edu.sg; ctguan@i2r.a-star.edu.sg; kkang@i2r.a-star.edu.sg; eleleeth@nus.edu.sg					Ang K. K., 2008, P IJCNN 08, P2391; Blankertz B., BCI COMPETITION 4; Breiman L, 1984, CLASSIFICATION REGRE; BUNSEGERSTNER A, 1993, SIAM J MATRIX ANAL A, V14, P927, DOI 10.1137/0614062; CARDOSO JF, 1993, IEE PROC-F, V140, P362; Cardoso JF, 1996, SIAM J MATRIX ANAL A, V17, P161, DOI 10.1137/S0895479893259546; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dornhege G, 2004, IEEE T BIO-MED ENG, V51, P993, DOI 10.1109/TBME.2004.827088; Duda R. O., 2001, PATTERN CLASSIFICATI; Flannery B., 1992, NUMERICAL RECIPES C; Fukunaga K., 1990, INTRO STAT PATTERN R; Grosse-Wentrup M, 2008, IEEE T BIO-MED ENG, V55, P1991, DOI 10.1109/TBME.2008.921154; Hori G., 1999, P NOLTA 99, P675; Joho M., 2002, P IEEE SENS ARR MULT, P403; KOLES ZJ, 1991, ELECTROEN CLIN NEURO, V79, P440, DOI 10.1016/0013-4694(91)90163-X; Mueller-Gerking Johannes, 1999, Clinical Neurophysiology, V110, P787; Ramoser H, 2000, IEEE T REHABIL ENG, V8, P441, DOI 10.1109/86.895946; Vapnik V.N., 1998, STAT LEARNING THEORY; Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3; Ziehe A, 2004, J MACH LEARN RES, V5, P777	20	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576	978-1-4244-6917-8	IEEE IJCNN			2010												6	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BTN74	WOS:000287421402034	
S	Monteith, K; Martinez, T			IEEE	Monteith, Kristine; Martinez, Tony			Using Multiple Measures to Predict Confidence in Instance Classification	2010 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS IJCNN 2010	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	World Congress on Computational Intelligence (WCCI 2010)	2010	Barcelona, SPAIN	IEEE				Selecting an effective method for combining the votes of classifiers in an ensemble can have a significant impact on the ensemble's overall classification accuracy. Some methods cannot even achieve as high a classification accuracy as the most accurate individual classifying component. To address this issue, we present the strategy of Aggregate Confidence Ensembles, which uses multiple measures to estimate a classifier's confidence in its predictions on an instance-by-instance basis. Using these confidence estimators to weight the votes in an ensemble results in an overall average increase in classification accuracy compared to the most accurate classifier in the ensemble. These aggregate measures result in higher classification accuracy than using a collection of single confidence estimates. Aggregate Confidence Ensembles outperform three baseline ensemble creation strategies, as well as the methods of Modified Stacking and Arbitration, both in terms of average classification accuracy and algorithm-by-algorithm comparisons in accuracy over 36 data sets.	[Monteith, Kristine; Martinez, Tony] Brigham Young Univ, Dept Comp Sci, Provo, UT 84602 USA	Monteith, K (reprint author), Brigham Young Univ, Dept Comp Sci, Provo, UT 84602 USA.	kristinemonteith@gmail.com; martinez@cs.byu.edu					Ortega J., 2001, Knowledge and Information Systems, V3, DOI 10.1007/PL00011679; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Burr Ridge I, 1997, MACHINE LEARNING; CARUANA R., 2006, P 23 INT C MACH LEAR, P161, DOI 10.1145/1143844.1143865; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domingos P., 2000, P 17 INT C MACH LEAR, P223; Dzeroski S, 2004, MACH LEARN, V54, P255, DOI 10.1023/B.MAC.0000015881.36452.6e; Ferri C., 2004, P 21 INT C MACH LEAR, P289; Freund Y, 1996, P 13 INT C MACH LEAR; Giacinto G., 2000, P 15 INT C PATT REC; Hettich S., 1998, UCI REPOSITORY MACHI; Hoeting JA, 1999, STAT SCI, V14, P382; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; KOHAVI R, 1995, P 8 EUR C MACH LEARN; Kohavi R, 1996, P 13 INT C MACH LEAR, P275; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; Lang K., 1995, P 12 INT C MACH LEAR, P331; MERZ CJ, 1995, P 5 INT WORKSH ART I, P386; Peterson A. H., 2005, P ICML WORKSH MET, P68; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Ruta D., 2005, Information Fusion, V6, DOI 10.1016/j.inffus.2004.04.008; Ruta D., 2001, P 4 INT S SOFT COMP; Witten I., 2005, DATA MINING PRACTICA; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	26	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576	978-1-4244-6917-8	IEEE IJCNN			2010												8	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BTN74	WOS:000287421400121	
B	Xiao, YL		Xu, H		Xiao, Yongliang			An Effective Video Shot Boundary Detection Method Based on Supervised Learning	2ND IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL (ICACC 2010), VOL. 4			English	Proceedings Paper	2nd IEEE International Conference on Advanced Computer Control	MAR 27-29, 2010	Shenyang, PEOPLES R CHINA	IEEE		shot boundary detection; supervised learning; Non-locality preserving projections; SVM	RECOGNITION	Video shot boundary detection plays an every important role in video processing. It is the first step toward video content analysis and content-based video retrieval. We develop a novel approach for video shot boundary detection based on supervised learning. Our method consists in first extracting video frame feature using a supervised kernel non-locality preserving projections, then video frames are split into abrupt transitions, gradual transitions or normal frames using two cascaded Localized-SVM classifiers. Experimental results show the effectiveness of our method.	Hunan Coll Finance & Econ, Dept Informat Management, Changsha, Hunan, Peoples R China	Xiao, YL (reprint author), Hunan Coll Finance & Econ, Dept Informat Management, Changsha, Hunan, Peoples R China.	xylroc@gmail.com					Albanese M, 2004, MULTIMED TOOLS APPL, V24, P253, DOI 10.1023/B:MTAP.0000039421.91449.10; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Boreczky JS, 1996, P SOC PHOTO-OPT INS, V2670, P170, DOI 10.1117/12.234794; CHAVEZ GC, 2007, P 14 INT C SYST SIGN, P209; CHENG HB, SDM 2007; COOPER M, 2007, IEEE T MULTIMEDIA, P610; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Hanjalic A, 2002, IEEE T CIRC SYST VID, V12, P90, DOI 10.1109/76.988656; He X.F., 2003, P ADV NEUR INF PROC, P153; HECHENBICHLER K, 2006, 399 SFB, P386; JIAN Y, 2006, P CONTR AUT ROB VIS, P1; JINHUI Y, 2007, IEEE T CIRCUITS SYST, P168; SCHOLKOPF B, 2002, LEARNING KERNELS SUP, P34; Vasconcelos N, 2000, IEEE T IMAGE PROCESS, V9, P3, DOI 10.1109/83.817595; Vasconcelos N, 2003, PROC CVPR IEEE, P762; Zhang H, 2006, P IEEE C COMP VIS PA, P2126, DOI DOI 10.1109/CVPR.2006.301; Zhang H., 1993, MULTIMEDIA SYSTEMS, V1, P10, DOI 10.1007/BF01210504	17	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-5847-9				2010							371	374				4	Automation & Control Systems; Engineering, Electrical & Electronic	Automation & Control Systems; Engineering	BUG30	WOS:000289202000085	
S	Shaneck, M; Kim, Y			IEEE	Shaneck, Mark; Kim, Yongdae			Efficient Cryptographic Primitives for Private Data Mining	43RD HAWAII INTERNATIONAL CONFERENCE ON SYSTEMS SCIENCES VOLS 1-5 (HICSS 2010)	Proceedings of the Annual Hawaii International Conference on System Sciences		English	Proceedings Paper	43rd Hawaii International Conference on Systems Sciences (HICSS 2010)	JAN 05-08, 2010	Honolulu, HI	Univ Hawaii, Shidler Coll Business			PROTOCOL	Data mining is frequently obstructed by privacy concerns In many cases data is distributed, and bringing the data together in one place for analysis is not possible due to privacy laws (e g HIPAA) or policies Privacy preserving data mining techniques have been developed to address this issue by providing mechanisms to mine the data while giving certain privacy guarantees However when these techniques are built on cryptographic primitives, while providing strong privacy they are often too inefficient to be used in practical settings To this end, we address the problem of efficiency by investigating trade-offs that can be made in the trust model By making reasonable concessions in the trust model, that is, by adding a non-collaborative third party, we can achieve great gains in efficiency We show this by creating a novel protocol for privately computing dot product, a foundational primitive for many private data mining activities We also investigate how to extend our protocol in the case when a third party cannot be completely trusted by both participating parties, thus reducing the amount of trust needed in the third party We then show experimentally the gains in efficiency that can be realized in the computation of the private dot product using this model	[Shaneck, Mark] Liberty Univ, Dept Comp Sci, Lynchburg, VA USA	Shaneck, M (reprint author), Liberty Univ, Dept Comp Sci, Lynchburg, VA USA.	mshaneck@liberty.edu; kyd@cs.umn.edu					AIELLO B, 2001, P ADV CRYPT EUR; ALGESHEIMER J, 2002, P 22 ANN INT CRYPT C; ARYA S, 2002, P ACM SIAM S DISCR A; ARYA S, 2002, P S THEOR COMP; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; ARYA S, 1993, P ACM SIAM S DISCR A; ARYA S, 1994, P ACM SIAM S DISCR A; Atallah MJ, 2001, P 17 ANN COMP SEC AP; BENOR M, 1988, P 20 ANN S THEOR COM; BLAKE I, 2006, P FIN CRYPT; Breunig M., 2000, P ACM INT C MAN DAT; BREUNIG MM, 1999, P 3 EUR C PRINC DAT; CLARKSON K, 1994, P ACM S COMP GEOM; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CREPEAU C, 1987, P ADV CRYPT; Du W., 2002, P WORKSH PRIV SEC DA; DU WL, 2002, P 2002 WORKSH NEW SE; ERTOZ L., 2001, WORKSH CLUST HIGH DI; ERTOZ L, 2003, P SIAM INT C DAT MIN; EVEN S, 1985, COMMUN ACM, V28, P637, DOI 10.1145/3812.3818; GENNARO R, 1998, P 17 ANN ACM S PRINC; GOETHALS B, 2004, P 7 ANN INT C INF SE; Goldreich O., 2004, FDN CRYPTOGRAPHY, V2; Indyk P., 1998, P S THEOR COMP; IOANNIDIS I, 2002, P 31 INT C PAR PROC; IOANNIDIS I, 2003, P HAW INT C SYST SCI; JARVIS RA, 1973, IEEE T COMPUT, VC-22, P1025, DOI 10.1109/T-C.1973.223640; KILTZ E, 2006, P 3 THEOR CRYPT C; KLEINGBERG J, 1997, P ACM S THEOR COMP; KUSHLEVITZ E, 1998, P ACM S THEOR COMP; LAUR S, 2004, P 9 NORD WORKSH SEC; LIN HY, 2005, P 3 INT C APPL CRYPT; LIPMAA H, 2005, P 8 INF SEC C; NAOR M, 2001, P 12 ANN S DISCR ALG; NAOR M, 1999, P 31 ANN ACM S THEOR; PAILLIER P, 1999, P EUR; Rabin M., 1981, TR81 HARV U; RAVIKUMAR P, 2004, P ICDM WORKSH PRIV S; SHAMIR A, 1979, COMMUN ACM, V22, P512; SHANECK M, 2006, 06014 U MINN; Tzeng WG, 2004, IEEE T COMPUT, V53, P232; Vaidya J, 2002, P ACM INT C KNOWL DI; VAIDYA J, 2003, P 2003 ACM WORKSH PR; VAIDYA J, 2004, P 4 IEEE INT C DAT M; Yang ZQ, 2006, COMPUT SYST SCI ENG, V21, P47; Yao A. C., 1986, P 27 IEEE S FDN COMP; 2007, GNU MULTIPLE PRECISI	47	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1060-3425	978-1-4244-5509-6	P ANN HICSS			2010							917	925				9	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BRD18	WOS:000282391801002	
J	Chan, YB; Hall, P				Chan, Yao-Ban; Hall, Peter			ROBUST NEAREST-NEIGHBOR METHODS FOR CLASSIFYING HIGH-DIMENSIONAL DATA	ANNALS OF STATISTICS			English	Article						Classification boundary; detection boundary; false discovery rate; heterogeneous components; higher criticism; optimal classification; threshold; zero-one data	PATTERN-CLASSIFICATION; CONVERGENCE; PERFORMANCE	We suggest a robust nearest-neighbor approach to classifying high-dimensional data. The method enhances sensitivity by employing a threshold and truncates to a sequence of zeros and ones in order to reduce the deleterious impact of heavy-tailed data. Empirical rules are suggested for choosing the threshold. They require the bare minimum of data only one data vector is needed from each population. Theoretical and numerical aspects of performance are explored, paying particular attention to the impacts of correlation and heterogeneity among data components. On the theoretical side, it is shown that our truncated, thresholded, nearest-neighbor classifier enjoys the same classification boundary as more conventional, nonrobust approaches, which require finite moments in order to achieve good performance. In particular, the greater robustness of our approach does not come at the price of reduced effectiveness. Moreover, when both training sample sizes equal 1, our new method can have performance equal to that of optimal classifiers that require independent and identically distributed data with known marginal distributions; yet, our classifier does not itself need conditions of this type.	[Chan, Yao-Ban; Hall, Peter] Univ Melbourne, Dept Math & Stat, Parkville, Vic 3010, Australia	Chan, YB (reprint author), Univ Melbourne, Dept Math & Stat, Parkville, Vic 3010, Australia.	y.chan@ms.unimelb.edu.au; P.Hall@ms.unimelb.edu.au					Cover T.M., 1968, P HAW INT C SYST SCI, P413; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Devroye L, 1996, PROBABILISTIC THEORY; Donoho D, 2004, ANN STAT, V32, P962, DOI 10.1214/009053604000000265; Efron B, 2004, J AM STAT ASSOC, V99, P96, DOI 10.1198/016214504000000089; FRITZ J, 1975, IEEE T INFORM THEORY, V21, P552, DOI 10.1109/TIT.1975.1055443; Hall P, 2008, J ROY STAT SOC B, V70, P159; Hedenfalk I, 2001, NEW ENGL J MED, V344, P539, DOI 10.1056/NEJM200102223440801; Holst M, 2001, ANN STAT, V29, P1424; Ingster Y, 1999, MATH METHODS STAT, V7, P401; INGSTER YI, 2001, MATH METHODS STAT, V10, P395; INGSTER YI, 2002, MATH METHODS STAT, V11, P37; JIN J, 2002, DETECTION BOUN UNPUB; KULKARNI SR, 1995, IEEE T INFORM THEORY, V41, P1028, DOI 10.1109/18.391248; PSALTIS D, 1994, IEEE T INFORM THEORY, V40, P820, DOI 10.1109/18.335893; Shakhnarovich G., 2006, NEAREST NEIGHBOR MET; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698	18	1	1	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	0090-5364		ANN STAT	Ann. Stat.	DEC	2009	37	6A					3186	3203		10.1214/08-AOS591		18	Statistics & Probability	Mathematics	518EO	WOS:000271673500004	
J	Chong, RM; Tanaka, T				Chong, Rachel Mabanag; Tanaka, Toshihisa			Detection and Classification of Invariant Blurs	IEICE TRANSACTIONS ON FUNDAMENTALS OF ELECTRONICS COMMUNICATIONS AND COMPUTER SCIENCES			English	Article						image extrema; invariant blurs; blur detection; blur classification	BLIND IMAGE DECONVOLUTION; NEURAL-NETWORK; PARAMETERS IDENTIFICATION; MULTIVALUED NEURONS; RESTORATION	A new algorithm for simultaneously detecting and identifying invariant blurs is proposed. This is mainly based on the behavior of extrema values in an image. It is computationally simple and fast thereby making it suitable for preprocessing especially fit practical imaging applications. Benefits of employing this method includes the elimination of unnecessary processes since unblurred images will be separated from the blurred ones which require deconvotution. Additionally, it can improve reconstruction performance by proper identification of blur type so that a more effective blur specific deconvolution algorithm can be applied. Experimental results on natural images and its synthetically blurred versions show the characteristics and validity of the proposed method. Furthermore, it can be observed that feature selection makes the method more efficient and effective.	[Chong, Rachel Mabanag; Tanaka, Toshihisa] Tokyo Univ Agr & Technol, Dept Elect & Elect Engn, Koganei, Tokyo 1848588, Japan	Chong, RM (reprint author), Tokyo Univ Agr & Technol, Dept Elect & Elect Engn, Koganei, Tokyo 1848588, Japan.	chong@sip.tuat.ac.jp; tanakat@cc.tuat.ac.jp			KAKENHI [1830057]; Support Center for Advanced Telecommunications Technology Research (SCAT)	This work is supported in part by KAKENHI, Grant-in-Aid for Scientific Research (1830057) and the Support Center for Advanced Telecommunications Technology Research (SCAT), 2009.	Aizenberg I, 2007, SOFT COMPUT, V11, P169, DOI 10.1007/s00500-006-0075-5; Aizenberg I, 2008, IEEE T NEURAL NETWOR, V19, P883, DOI 10.1109/TNN.2007.914158; AIZENBERG I, 2006, COMPUTATIONAL INTELL, V17, P441; Aizenberg I, 2002, P SOC PHOTO-OPT INS, V4667, P460, DOI 10.1117/12.468009; Aizenberg I, 2002, LECT NOTES COMPUT SC, V2415, P1231; Bhutta AA, 2006, LECT NOTES COMPUT SC, V4141, P94; CHANG MM, 1991, IEEE T SIGNAL PROCES, V39, P2323, DOI 10.1109/78.91207; CHONG RM, 2008, IEEE INT C SIGN IM T, V1, P320; Chung Y, 2004, IEEE C CYB INT SYST, V1, P356; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Kundur D, 1996, IEEE SIGNAL PROC MAG, V13, P43, DOI 10.1109/79.489268; Kundur D, 1996, IEEE SIGNAL PROC MAG, V13, P61, DOI 10.1109/79.543976; LAGENDIJK RL, 2005, HDB IMAGE VIDEO PROC, P125; Marziliano P., 2002, P INT C IM PROC ROCH, V3, P57; ROOMS F, 2002, IEEE INT C AC SPEECH, V4, P4190; SAVAKIS AE, 1999, IEEE INT C IM PROC, V2, P885; Savakis AE, 1993, IEEE T IMAGE PROCESS, V2, P141, DOI 10.1109/83.217219; Theodoridis S, 2006, PATTERN RECOGNITION, 3RD EDITION, P1; TONG H, 2004, IEEE INT C MULT EXPO, V1, P17; Wu SQ, 2007, IEEE IC COMP COM NET, P1166; Banham MR, 1997, IEEE SIGNAL PROC MAG, V14, P24, DOI 10.1109/79.581363	21	2	2	IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG	TOKYO	KIKAI-SHINKO-KAIKAN BLDG MINATO-KU SHIBAKOEN 3 CHOME, TOKYO, 105, JAPAN	0916-8508		IEICE T FUND ELECTR	IEICE Trans. Fundam. Electron. Commun. Comput. Sci.	DEC	2009	E92A	12					3313	3320		10.1587/transfun.E92.A.3313		8	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	538NH	WOS:000273190700045	
J	Qian, Y; Yao, F; Jia, S				Qian, Y.; Yao, F.; Jia, S.			Band selection for hyperspectral imagery using affinity propagation	IET COMPUTER VISION			English	Article							REMOTE-SENSING IMAGES; CLASSIFICATION; ALGORITHMS	Hyperspectral imagery generally contains enormous amounts of data because of hundreds of spectral bands. Band selection is often adopted to reduce computational cost and accelerate knowledge discovery and other tasks such as subsequent classification. An exemplar-based clustering algorithm termed affinity propagation for band selection is proposed. Affinity propagation is derived from factor graph, and operates by initially considering all data points as potential cluster centres (exemplars) and then exchanging messages between data points until a good set of exemplars and clusters emerges. Affinity propagation has been applied to computer vision and bioinformatics, and shown to be much faster than other clustering methods for large data. By combining the information about the discriminative capability of each individual band and the correlation/similarity between bands, the exemplars generated by affine propagation have higher importance and less correlation/similarity. The performance of band selection is evaluated through a pixel image classification task. Experimental results demonstrate that, compared with some popular band selection methods, the bands selected by affinity propagation best characterise the hyperspectral imagery from the pixel classification standpoint.	[Qian, Y.; Yao, F.] Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Zhejiang, Peoples R China; [Jia, S.] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China	Qian, Y (reprint author), Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Zhejiang, Peoples R China.	ytqian@zju.edu.cn			National Natural Science Foundation of China [60872071]	This work was supported by National Natural Science Foundation of China under project No. 60872071. We would like to thank anonymous reviewers who helped us considerably to improve the quality of this paper, and gave us many valuable suggestions.	Agarwal PK, 2002, ALGORITHMICA, V33, P201, DOI 10.1007/s00453-001-0110-y; Cardoso J.F., 2003, J MACHINE LEARNING R, V4, P1177, DOI 10.1162/jmlr.2003.4.7-8.1177; Chang CI, 1999, IEEE T GEOSCI REMOTE, V37, P2631; Chang C.-I., 2003, HYPERSPECTRAL IMAGIN; Chang CI, 2006, IEEE T GEOSCI REMOTE, V44, P1575, DOI 10.1109/TGRS.2006.864389; Cover T. M., 1991, ELEMENTS INFORM THEO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dash M, 1997, PROC INT C TOOLS ART, P532, DOI 10.1109/TAI.1997.632300; Dueck D., 2009, THESIS U TORONTO; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; Goutte C, 1999, NEUROIMAGE, V9, P298, DOI 10.1006/nimg.1998.0391; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Jain A. K., 1999, ACM COMPUT SURV, V31; Jimenez-Rodriguez LO, 2007, IEEE T GEOSCI REMOTE, V45, P469, DOI 10.1109/TGRS.2006.885412; Kohavi R., 1995, INT JOINT C ART INT, V2, P1137; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; Kumar S, 2001, IEEE T GEOSCI REMOTE, V39, P1368, DOI 10.1109/36.934070; Martinez-Uso A, 2007, IEEE T GEOSCI REMOTE, V45, P4158, DOI 10.1109/TGRS.2007.904951; Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133; Neher R, 2005, IEEE T GEOSCI REMOTE, V43, P1363, DOI 10.1109/TGRS.2005.846865; Rifkin R, 2004, J MACH LEARN RES, V5, P101; Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899; Serpico SB, 2001, IEEE T GEOSCI REMOTE, V39, P1360, DOI 10.1109/36.934069; SOTOCA JM, 2006, P SSPR SPR 2006 AUG, P853	25	9	13	INST ENGINEERING TECHNOLOGY-IET	HERTFORD	MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND	1751-9632		IET COMPUT VIS	IET Comput. Vis.	DEC	2009	3	4					213	222		10.1049/iet-cvi.2009.0034		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	536KP	WOS:000273043600005	
J	Fayed, HA; Atiya, AF; Hashem, SMR				Fayed, Hatem A.; Atiya, Amir F.; Hashem, Sherif M. R.			HYPERSPHERICAL PROTOTYPES FOR PATTERN CLASSIFICATION	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article						Pattern classification; nearest neighbor; hyperspherical prototypes	NEAREST-NEIGHBOR CLASSIFICATION; ALGORITHM; SEARCH; RULE; CLASSIFIERS; SELECTION; MODEL	The nearest neighbor method is one of the most widely used pattern classification methods. However its major drawback in practice is the curse of dimensionality. In this paper, we propose a new method to alleviate this problem significantly. In this method, we attempt to cover the training patterns of each class with a number of hyperspheres. The method attempts to design hyperspheres as compact as possible, and we pose this as a quadratic optimization problem. We performed several simulation experiments, and found that the proposed approach results in considerable speed-up over the k-nearest-neighbor method while maintaining the same level of accuray. It also significantly beats other prototype classification methods (Like LVQ, RCE and CCCD) in most performance aspects.	[Fayed, Hatem A.; Hashem, Sherif M. R.] Cairo Univ, Dept Engn Math & Phys, Giza, Egypt; [Atiya, Amir F.] Cairo Univ, Dept Comp Engn, Giza, Egypt	Fayed, HA (reprint author), Cairo Univ, Dept Engn Math & Phys, Giza, Egypt.	h_fayed@eng.cu.edu.eg; amir@alumni.caltech.edu; shashem@ieee.org					ATIYA A, 2006, LECT NOTES COMPUTER, V4223, P116; ATIYA A, 2004, P 1 INT COMP ENG C I, P258; Barandela R, 2005, INT J PATTERN RECOGN, V19, P787, DOI 10.1142/S0218001405004332; Bazaraa M. S., 1979, NONLINEAR PROGRAMMIN; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Blake C.L., UCI REPOSITORY MACHI; Blumenthal L.M., 1941, B AM MATH SOC, V47, P771, DOI 10.1090/S0002-9904-1941-07565-8; BURMAN P, 1989, BIOMETRIKA, V76, P503, DOI 10.1093/biomet/76.3.503; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Djouadi A, 1997, IEEE T PATTERN ANAL, V19, P277, DOI 10.1109/34.584107; Duda R. O., 2001, PATTERN CLASSIFICATI; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Fayed HA, 2007, PATTERN RECOGN, V40, P1498, DOI 10.1016/j.patcog.2006.10.018; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; Fukunaga K., 1990, INTRO STAT PATTERN R; Gagne C, 2007, INT J PATTERN RECOGN, V21, P921, DOI 10.1142/S0218001407005752; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hattori K, 1999, PATTERN RECOGN, V32, P425, DOI 10.1016/S0031-3203(98)00097-1; HUDAK MJ, 1992, CYBERNET SYST, V23, P483, DOI 10.1080/01969729208927478; John F., 1948, COURANT ANNIVERSARY, P187; Kaufman L., 1990, FINDING GROUPS DATA; Khachiyan LG, 1996, MATH OPER RES, V21, P307, DOI 10.1287/moor.21.2.307; Kohonen T., 1989, SELF ORG ASS MEMORY; Kositsky M., 1996, Proceedings of the 13th International Conference on Pattern Recognition, DOI 10.1109/ICPR.1996.547664; Kumar P, 2003, SIAM PROC S, P45; LEE EW, 1998, IEEE T PATTERN ANAL, V20, P567; Mehrotra S, 1992, SIAM J OPTIMIZ, V2, P575, DOI 10.1137/0802028; Michie D, 1994, MACHINE LEARNING NEU; Nene SA, 1997, IEEE T PATTERN ANAL, V19, P989, DOI 10.1109/34.615448; Nock R, 2003, INT J PATTERN RECOGN, V17, P1369, DOI 10.1142/S0218001403002952; POST MJ, 1984, P 16 ANN ACM S THEOR, P108, DOI 10.1145/800057.808672; Prechelt L., 1994, PROBEN1 SET NEURAL N; Priebe CE, 2003, J CLASSIF, V20, P3, DOI 10.1007/s00357-003-0003-7; Qiu XP, 2006, INT J PATTERN RECOGN, V20, P1245, DOI 10.1142/S0218001406005186; REILLY DL, 1982, BIOL CYBERN, V45, P35, DOI 10.1007/BF00387211; Salzberg S., 1991, MACH LEARN, V6, P277; SILVERMAN BW, 1980, SIAM J SCI STAT COMP, V1, P401, DOI 10.1137/0901028; TOUSSAINT G, 2002, P INTERFACE 2002 34, P83; TSUMURA N, 1995, PATTERN RECOGN, V28, P1621, DOI 10.1016/0031-3203(95)00027-W; VOLMER S, 2002, P 5 INT C VIS INF SY, P36; WELZL E, 1991, LECT NOTES COMPUT SC, V555, P359; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wolfe P., 1961, Q APPL MATH, V19, P239; Wright S. J., 1997, PRIMAL DUAL INTERIOR; Zhang HB, 2002, PATTERN RECOGN, V35, P1481, DOI 10.1016/S0031-3203(01)00137-6	46	1	1	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014		INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	DEC	2009	23	8					1549	1575		10.1142/S0218001409007740		27	Computer Science, Artificial Intelligence	Computer Science	541OK	WOS:000273425500002	
J	Hu, JN; Deng, WH; Guo, J; Xu, WR				Hu, Jiani; Deng, Weihong; Guo, Jun; Xu, Weiran			Learning a locality discriminating projection for classification	KNOWLEDGE-BASED SYSTEMS			English	Article						Feature exaction; Manifold learning; Discriminant analysis	NONLINEAR DIMENSIONALITY REDUCTION; FACE RECOGNITION; PALM BIOMETRICS; LAPLACIANFACES; EIGENFACES; FRAMEWORK	This paper introduces a new algorithm called locality discriminating projection (LDP) for subspace learning, which provides a new scheme for discriminant analysis by considering both the manifold structure and the prior class information. In the LDP algorithm, the overlap among the class-specific manifolds is approximated by an invader graph, and a locality discriminant criterion is proposed to find the projections that best preserve the within-class local structures while decrease the between-class overlap. The feasibility of the LDP algorithm has been successfully tested in text data and visual recognition experiments. Experiment results show it is an effective technique for data modeling and classification comparing to linear discriminant analysis, locality preserving projection, and marginal Fisher analysis. (C) 2009 Elsevier B.V. All rights reserved.	[Hu, Jiani; Deng, Weihong; Guo, Jun; Xu, Weiran] Beijing Univ Posts & Telecommun, Beijing 100876, Peoples R China	Hu, JN (reprint author), Beijing Univ Posts & Telecommun, Xi Tu Chen Rd 10, Beijing 100876, Peoples R China.	cughu@126.com			National High-Tech Development Plan of China [2007AA01Z417]; Foundation of China Education Ministry	This work was partially sponsored by National High-Tech Development Plan of China (2007AA01Z417), and the Foundation of China Education Ministry for III project.	Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Belkin M, 2002, ADV NEUR IN, V14, P585; Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945; CHUNG FRK, 1997, AMS REGIONAL C SER M; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deng WH, 2008, IEEE T PATTERN ANAL, V30, P1503, DOI 10.1109/TPAMI.2007.70783; Geng X, 2005, IEEE T SYST MAN CY B, V35, P1098, DOI 10.1109/TSMCB.2005.850151; He X., 2003, P C ADV NEUR INF PRO; He XF, 2005, IEEE T PATTERN ANAL, V27, P328; Howland P, 2004, IEEE T PATTERN ANAL, V26, P995, DOI 10.1109/TPAMI.2004.46; HU J, 2007, P IEEE RAD FREQ INT, P689, DOI 10.1145/1277741.1277860; Loog M, 2004, IEEE T PATTERN ANAL, V26, P732, DOI 10.1109/TPAMI.2004.13; Martinez AM, 2005, IEEE T PATTERN ANAL, V27, P1934, DOI 10.1109/TPAMI.2005.250; Roth D, 2002, NEURAL COMPUT, V14, P1071, DOI 10.1162/089976602753633394; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Sebastiani F., 2002, ACM COMPUT SURV, V34, P47; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; VASCONCELOS N, 2004, P 8 EUR C COMP VIS, V3, P430; Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598; Yang J, 2007, IEEE T PATTERN ANAL, V29, P650, DOI 10.1109/TPAMI.2007.1008	22	11	12	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051		KNOWL-BASED SYST	Knowledge-Based Syst.	DEC	2009	22	8					562	568		10.1016/j.knosys.2009.02.010		7	Computer Science, Artificial Intelligence	Computer Science	524AY	WOS:000272117400002	
J	Li, J; Allinson, NM				Li, Jing; Allinson, Nigel M.			Subspace learning-based dimensionality reduction in building recognition	NEUROCOMPUTING			English	Article						Subspace learning; Building recognition; Biologically-inspired feature extraction; Gist features; Dimensionality reduction	DISCRIMINANT-ANALYSIS; RELEVANCE-FEEDBACK; VISUAL-ATTENTION; FACE RECOGNITION; IMAGE RETRIEVAL; FEATURES; CLASSIFICATION; SCENE	Building recognition is a relatively specific recognition task in object recognition, which is challenging since it encounters rotation, scaling, illumination changes, occlusion. etc. Subspace learning, which dominates dimensionality reduction, has been widely exploited in computer vision research in recent years. it consists of classical linear dimensionality reduction methods, manifold learning, etc. To explore how different subspace learning algorithms affect building recognition, some representative algorithms, i.e., principal component analysis, linear discriminant analysis, locality preserving projections (unsupervised/supervised), and semi-supervised discriminant analysis, are applied for dimensionality reduction. Moreover, a building recognition scheme based on biologically-inspired feature extraction is proposed in this paper. Experiments undertaken on our own building database demonstrate that the proposed scheme embedded with subspace learning can achieve satisfactory results. (C) 2009 Elsevier B.V. All rights reserved.	[Li, Jing; Allinson, Nigel M.] Univ Sheffield, Vis & Informat Engn Res Grp, Dept Elect & Elect Engn, Sheffield S1 3JD, S Yorkshire, England	Li, J (reprint author), Univ Sheffield, Vis & Informat Engn Res Grp, Dept Elect & Elect Engn, Mappin St, Sheffield S1 3JD, S Yorkshire, England.	elq06jl@sheffield.ac.uk; n.allinson@sheffield.ac.uk					Ali H., 2007, P INT S MOB MAPP TEC, P28; Belkin M, 2002, ADV NEUR IN, V14, P585; Bellman R., 1961, ADAPTIVE CONTROL PRO; CAI D, 2005, 2636 U ILL URB DEP C; Cai D., 2007, P IEEE INT C COMP VI, P1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6; Dorko G., 2003, P INT C COMP VIS, V1, P634; Fergus R., 2003, P IEEE C COMP VIS PA, V2, P264; Ferrari V, 2006, LECT NOTES COMPUT SC, V4170, P145; FRITZ G, 2005, P IEEE INT C ICRA, P131, DOI 10.1109/ROBOT.2005.1570108; Harris C., 1988, ALV VIS C, P147; He X., 2007, ACM T MULTIMEDIA COM, V3; He X, 2008, IEEE T KNOWL DATA EN, V20, P189, DOI 10.1109/TKDE.2007.190692; He X., 2003, P C ADV NEUR INF PRO; Hutchings R., 2005, CSTR06017 U BRIST; Iqbal Q., 1999, P IEEE INT C COMP VI, V1, P42; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jolliffe I. T., 2002, PRINCIPAL COMPONENT; Lazebnik S., 2006, P CVPR, V2, P2169; LEE DC, 2003, CYTOKINE HDB, V2, P959; Leibe B., 2003, P BRIT MACH VIS C, P759; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Li F, 2003, P IEEE INT C COMP VI, V2, P1134; Li J, 2008, NEUROCOMPUTING, V71, P1771, DOI 10.1016/j.neucom.2007.11.032; LI Y, 2002, P INT C PATT REC, V3, P952; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MARCELJA S, 1980, J OPT SOC AM, V70, P1297, DOI 10.1364/JOSA.70.001297; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Mikolajczyk K., 2005, P ICCV, V2, P1792; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40; SONG D, IEEE T IMAG IN PRESS; Song D., 2008, P IEEE INT C PATT RE, P1; TAO D, 2008, IEEE T CIRCUITS SYST, V18, P1; Tao DC, 2004, INT C PATT RECOG, P1013; Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096; Tao DC, 2009, IEEE T PATTERN ANAL, V31, P260, DOI 10.1109/TPAMI.2008.70; Tao DC, 2006, IEEE T MULTIMEDIA, V8, P716, DOI 10.1109/TMM.2005.861375; Tao DC, 2007, IEEE T KNOWL DATA EN, V19, P568, DOI 10.1109/TKDE.2007.1003; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Torralba A., 2003, P 9 IEEE INT C COMP, P273; TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5; TURNER RS, 1994, EYES MIND VISION H H; Ullah MM, 2008, IEEE INT CONF ROBOT, P530, DOI 10.1109/ROBOT.2008.4543261; Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4; Wu Jiang, 2008, V446, P1, DOI 10.1007/978-1-60327-084-7_1; Xu D, 2007, IEEE T SYST MAN CY B, V37, P1226, DOI 10.1109/TSMCB.2006.888925; Yan SC, 2007, IEEE T IMAGE PROCESS, V16, P212, DOI 10.1109/TIP.2006.884929; ZHANG T, 2008, P IEEE INT JOINT C N, P1671; ZHANG T, 2008, IEEE T KNOWLEDGE DAT; Zhang T., 2008, P 10 EUR C COMP VIS, P725; ZHANG W, 2005, IEEE COMP SOC C COMP, P21	55	3	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	DEC	2009	73	1-3			SI		324	330		10.1016/j.neucom.2009.08.016		7	Computer Science, Artificial Intelligence	Computer Science	530QI	WOS:000272607000038	
J	Yang, XB; Chen, SC; Chen, B; Pan, ZS				Yang, Xubing; Chen, Songcan; Chen, Bin; Pan, Zhisong			Proximal support vector machine using local information	NEUROCOMPUTING			English	Article						Proximal classification; Eigenvalue; Manifold learning; Outlier	NONLINEAR DIMENSIONALITY REDUCTION; DISCRIMINANT-ANALYSIS; GENERALIZED EIGENVALUES; FACE RECOGNITION; CLASSIFICATION	Instead of standard support vector machines (SVMs) that classify points to one of two disjoint half-spaces by solving a quadratic program, the plane classifier GEPSVM (proximal SVM classification via generalized eigenvalues) classifies points by assigning them to the closest of two nonparallel planes which are generated by their corresponding generalized eigenvalue problems. A simple geometric interpretation of GEPSVM is that each plane is closest to the points of its own class and furthest to the points of the other class. Analysis and experiments have demonstrated its capability in both computation time and test correctness. In this paper, following the geometric intuition of GEPSVM, a new supervised learning method called proximal support vector machine using local information (LIPSVM) is proposed. With the introduction of proximity information (consideration of underlying information such as correlation or similarity between points) between the training points, LIPSVM not only keeps aforementioned characteristics of CEPSVM, but also has its additional advantages: (1) robustness to outliers; (2) each plane is generated from its corresponding standard rather than generalized eigenvalue problem to avoid matrix singularity; (3) comparable classification ability to the eigenvalue-based classifiers GEPSVM and LDA. Furthermore, the idea of LIPSVM can be easily extended to other classifiers, such as LDA. Finally, some experiments on the artificial and benchmark datasets show the effectiveness of LIPSVM. Crown Copyright (C) 2009 Published by Elsevier B.V. All rights reserved.	[Yang, Xubing; Chen, Songcan; Chen, Bin] Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, Nanjing 210016, Peoples R China; [Yang, Xubing] Nanjing Forestry Univ, Coll Informat Sci & Technol, Nanjing 210037, Peoples R China; [Pan, Zhisong] PLA Univ Sci Technol, Inst Command Automat, Nanjing 210007, Peoples R China	Chen, SC (reprint author), Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, Nanjing 210016, Peoples R China.	xbyang@nuaa.edu.cn; s.chen@nuaa.edu.cn; b.chen@nuaa.edu.cn; pzsong@nuaa.edu.cn			National Natural Science Foundations of China [60773061, 60603029]; Jiangsu Science Foundation [BK2008381, BK2009393]	We thank the anonymous reviewers for their valuable comments and suggestions. This research was supported by the National Natural Science Foundations of China (60773061, 60603029), and the Jiangsu Science Foundation (BK2008381, BK2009393).	BERKES P, LECT NOTES COMPUTER, V3696, P285; Blanz V., 1996, LNCS, V1112, P251; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P1, DOI [DOI 10.1023/A:1009715923555, 10.1023/A:1009715923555]; Burr Ridge I, 1997, MACHINE LEARNING; Centeno TP, 2006, J MACH LEARN RES, V7, P455; CHEN HT, 2005, P INT C COMP VIS PAT; Chen SC, 2004, PATTERN RECOGN, V37, P1545, DOI 10.1016/j.pateog.2003.11.008; Cifarelli C, 2007, J CLASSIF, V24, P205, DOI 10.1007/s00357-007-0012-z; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fung G., 2001, P KDD 2001 KNOWL DIS, P77, DOI 10.1145/502512.502527; Guarracino M., 2006, 20 INT C ADV INF NET, V2, P588, DOI 10.1109/AINA.2006.47; Guarracino MR, 2007, OPTIM METHOD SOFTW, V22, P73, DOI 10.1080/10556780600883874; Joachims T., 1999, P 10 EUR C MACH LEAR, P137; Kuss M., 2003, 108 M PLANCK I BIOL; Lafon S, 2006, IEEE T PATTERN ANAL, V28, P1784, DOI 10.1109/TPAMI.2006.223; Li H., 2004, P C ADV NEUR INF PRO, P97; LI T, 2003, P 12 INT C INF KNOWL, P317; LIN RS, 2004, 17 INT C PATT REC IC, P757; Liu CJ, 2001, IEEE T IMAGE PROCESS, V10, P598, DOI 10.1109/83.913594; Liu J, 2008, PATTERN RECOGN, V41, P102, DOI 10.1016/j.patcog.2007.06.001; Mangasarian OL, 2006, IEEE T PATTERN ANAL, V28, P69, DOI 10.1109/TPAMI.2006.17; MARNO V, 1993, J ECONOMETRICS, V59, P125; MIKA S, 2002, THESIS TU BERLIN; Mika S., 1999, NEURAL NETWORKS SIGN, VIX, P41; MIKE S, 2001, ADV NEURAL INFORM PR, V13, P591; Mordohai P, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P798; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Murphy P. M., 1992, UCI MACHINE LEARNING; Nelkin M., 2002, ADV NEURAL INFORM PR, P585; OSUNA E, 1997, IEEE C COMP VIS PATT, P130; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; SCHLKOPF B, 1998, NEURAL COMPUTATION, V10; Schmidt M., 1996, INT 96 P SYDN; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B., 2002, LEARNING KERNELS; Scholkopf B, 1998, ADV NEUR IN, V10, P640; Scholkopf B., 1999, ADV KERNEL METHODS; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; WANG M, IEEE T NEURAL NETWOR, V16, P557; Weinberger K.Q., 2004, P IEEE C COMP VIS PA, P988, DOI 10.1109/CVPR.2004.1315272; Wu YQ, 2002, PATTERN RECOGN, V35, P2311, DOI 10.1016/S0031-3203(01)00132-7; Yan S., P 2005 IEEE COMP SOC; Yan SC, 2007, IEEE T IMAGE PROCESS, V16, P212, DOI 10.1109/TIP.2006.884929; ZHANG H, 2005, IEEE T SYSTEMS MAN B, V35	44	6	7	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	DEC	2009	73	1-3			SI		357	365		10.1016/j.neucom.2009.08.002		9	Computer Science, Artificial Intelligence	Computer Science	530QI	WOS:000272607000042	
J	Eskofier, B; Oleson, M; DiBenedetto, C; Hornegger, J				Eskofier, B.; Oleson, M.; DiBenedetto, C.; Hornegger, J.			Embedded surface classification in digital sports	PATTERN RECOGNITION LETTERS			English	Article						Microprocessor; Embedded classification; Digital sports; adidas_1; Surface classification	TEXTURAL FEATURES; RUNNERS	In this presentation, we give a detailed analysis of the considerations needed for mapping the complete pattern classification chain to the restricted embedded system hardware environment. We describe the methodology of the design, realization and testing process that takes these hardware limitations into account. For this purpose, we consider a particular embedded application from the field of digital sports: a novel running shoe that is capable of sensing run-specific parameters and adapting the cushioning setting accordingly. Of utmost importance in this context is the classification of the current surface condition in order to enable optimal adaptation to the prevailing situation. Following our design approach, we provide a classification system with a runner-independent surface classification rate of more than 80%. This system is implemented in the current version of the aforementioned running shoe. The presented methodology is quite general as it makes no system-dependent assumptions and can thus be transferred to many other embedded classification applications. (C) 2009 Elsevier B.V. All rights reserved.	[Eskofier, B.; Hornegger, J.] Univ Erlangen Nurnberg, Dept Comp Sci, Inst Pattern Recognit, D-91058 Erlangen, Germany; [Oleson, M.; DiBenedetto, C.] Adidas AG, Adidas Innovat Team, Portland, OR 97217 USA	Eskofier, B (reprint author), Univ Erlangen Nurnberg, Dept Comp Sci, Inst Pattern Recognit, Martensstr 3, D-91058 Erlangen, Germany.	bjoern.eskofier@informatik.uni-erlangen.de; mark.oleson@adidas.com; christian.dibenedetto@adidas.com; joachim.hornegger@informatik.uni-erlangen.de					Assfalg J, 2002, IEEE MULTIMEDIA, V9, P52, DOI 10.1109/93.998060; BISIANI R, 1987, ENCY ARTIFICIAL INTE, P55; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DIBENEDETTO C, 2005, Patent No. 1582108; DIBENEDETTO C, 2004, Patent No. 20040177531; Duda R., 1973, PATTERN CLASSIFICATI; Duda R.O., 2000, PATTERN CLASSIFICATI; EIBE F, 1998, MACH LEARN, P144; Englehart K, 2003, IEEE T BIO-MED ENG, V50, P848, DOI [10.1109/TBME.2003.813539, 10.1109/TMBE.2003.813539]; Eskofier B. M., 2008, 19 INT C PATT REC 20, P1; Fisher RA, 1936, ANN EUGENIC, V7, P179; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Fukunaga K., 1990, INTRO STAT PATTERN R; Furui S., 2004, ACOUST SOC AM J, V116, P2497; Hacker C, 2006, LECT NOTES ARTIF INT, V4188, P581; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; LANGLEY P, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P223; Lee Y., 1991, NEURAL COMPUT, V3, P440, DOI 10.1162/neco.1991.3.3.440; Lun V, 2004, BRIT J SPORT MED, V38, P576, DOI 10.1136/bjsm.2003.005488; MILGROM C, 1992, CLIN ORTHOP RELAT R, P189; OHANIAN PP, 1992, PATTERN RECOGN, V25, P819, DOI 10.1016/0031-3203(92)90036-I; Olds EG, 1938, ANN MATH STAT, V9, P133, DOI 10.1214/aoms/1177732332; Schapire RE, 1998, ANN STAT, V26, P1651; SCHMIDT RO, 1986, IEEE T ANTENN PROPAG, V34, P276, DOI 10.1109/TAP.1986.1143830; Spearman C, 1904, AM J PSYCHOL, V15, P72, DOI 10.2307/1412159; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Vapnik V.N., 1998, STAT LEARNING THEORY; von Tscharner V, 2003, J ELECTROMYOGR KINES, V13, P253, DOI 10.1016/S1050-6411(02)00111-6; Witten I., 2005, DATA MINING PRACTICA; Wolf L, 2002, INT J COMPUT VISION, V48, P53, DOI 10.1023/A:1014855311993	30	3	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	DEC 1	2009	30	16					1448	1456		10.1016/j.patrec.2009.08.004		9	Computer Science, Artificial Intelligence	Computer Science	520MR	WOS:000271849300002	
J	Samaniego, L; Schulz, K				Samaniego, Luis; Schulz, Karsten			Supervised Classification of Agricultural Land Cover Using a Modified k-NN Technique (MNN) and Landsat Remote Sensing Imagery	REMOTE SENSING			English	Article						land use classification; supervised classification; nearest neighbors; agricultural land cover; crops		Nearest neighbor techniques are commonly used in remote sensing, pattern recognition and statistics to classify objects into a predefined number of categories based on a given set of predictors. These techniques are especially useful for highly nonlinear relationship between the variables. In most studies the distance measure is adopted a priori. In contrast we propose a general procedure to find an adaptive metric that combines a local variance reducing technique and a linear embedding of the observation space into an appropriate Euclidean space. To illustrate the application of this technique, two agricultural land cover classifications using mono-temporal and multi-temporal Landsat scenes are presented. The results of the study, compared with standard approaches used in remote sensing such as maximum likelihood (ML) or k-Nearest Neighbor (k-NN) indicate substantial improvement with regard to the overall accuracy and the cardinality of the calibration data set. Also, using MNN in a soft/fuzzy classification framework demonstrated to be a very useful tool in order to derive critical areas that need some further attention and investment concerning additional calibration data.	[Schulz, Karsten] Univ Munich, Dept Geog, D-80333 Munich, Germany; [Samaniego, Luis] UFZ Helmholtz Ctr Environm Res, Dept Computat Hydrosyst, D-04318 Leipzig, Germany	Schulz, K (reprint author), Univ Munich, Dept Geog, Luisenstr 37, D-80333 Munich, Germany.	luis.samaniego@ufz.de; k.schulz@lmu.de					Aarts E., 1989, SIMULATED ANNEALING; Atkinson PM, 1997, INT J REMOTE SENS, V18, P699, DOI 10.1080/014311697218700; Bachmann CM, 2005, IEEE T GEOSCI REMOTE, V43, P441, DOI 10.1109/TGRS.2004.842292; Bardossy A, 2005, WATER RESOUR RES, V41, DOI 10.1029/2004WR003851; Bardossy A, 2002, IEEE T GEOSCI REMOTE, V40, P362, DOI 10.1109/36.992798; CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P596, DOI 10.2307/2289282; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deer PJ, 2003, FUZZY SET SYST, V137, P191, DOI 10.1016/S0165-0114(02)00220-8; Dennison PE, 2009, REMOTE SENS ENVIRON, V113, P1646, DOI 10.1016/j.rse.2009.03.010; Falkenauer E., 1997, GENETIC ALGORITHMS G; Foody GM, 1996, INT J REMOTE SENS, V17, P1317; Foody GM, 2004, IEEE T GEOSCI REMOTE, V42, P1335, DOI 10.1109/TGRS.2004.827257; Franco-Lopez H, 2001, REMOTE SENS ENVIRON, V77, P251, DOI 10.1016/S0034-4257(01)00209-7; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Fukunaga K., 1990, INTRO STAT PATTERN R; Goodin DG, 2004, IEEE T GEOSCI REMOTE, V42, P154, DOI 10.1109/TGRS.2003.815674; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Isaaks E, 1989, INTRO APPL GEOSTATIS; Joshi PKK, 2006, REMOTE SENS ENVIRON, V103, P190, DOI 10.1016/j.rse.2006.04.010; Liu JY, 2005, REMOTE SENS ENVIRON, V98, P442, DOI 10.1016/j.rse.2005.08.012; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; Mahalanobis P.C, 1936, P NATL I SCI INDIA, V2, P4955; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; Massa A, 2005, IEEE T GEOSCI REMOTE, V43, P2084, DOI 10.1109/TGRS.2005.853186; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Peng J, 2004, IEEE T PATTERN ANAL, V26, P656; Poggi G, 2005, IEEE T GEOSCI REMOTE, V43, P1901, DOI 10.1109/TGRS.2005.852163; Potapov P, 2008, REMOTE SENS ENVIRON, V112, P3708, DOI 10.1016/j.rse.2008.05.006; Powell SL, 2008, REMOTE SENS ENVIRON, V112, P1895, DOI 10.1016/j.rse.2007.09.010; Richards J. A., 2006, REMOTE SENSING DIGIT; Samaniego L, 2008, IEEE T GEOSCI REMOTE, V46, P2112, DOI 10.1109/TGRS.2008.916629; Serpico SB, 2007, IEEE T GEOSCI REMOTE, V45, P484, DOI 10.1109/TGRS.2006.886177; Tolson BA, 2007, WATER RESOUR RES, V43, DOI 10.1029/2005WR004723; Zhu HW, 2005, IEEE T GEOSCI REMOTE, V43, P1874	35	2	2	MDPI AG	BASEL	POSTFACH, CH-4005 BASEL, SWITZERLAND	2072-4292		REMOTE SENS-BASEL	Remote Sens.	DEC	2009	1	4					875	895		10.3390/rs1040875		21	Remote Sensing	Remote Sensing	V24HH	WOS:000208401000013	
J	Larrua, A; Olivera, I; Caballero, Y; Filiberto, Y; Guerra, M; Bello, R; Bonilla, J				Larrua, A.; Olivera, I; Caballero, Y.; Filiberto, Y.; Guerra, M.; Bello, R.; Bonilla, J.			Application of the Artificial Intelligence to the Prediction of the Ultimate Resistant Capacity of Connections in Steel-Concrete Composite Structures	REVISTA DE LA CONSTRUCCION			Spanish	Article						Composite structures; connectors; artificial intelligence	STUD SHEAR CONNECTORS	In the work the connections in steel-concrete composite structures are treated and different variants of the 'push out" test are described when stud connectors are used in composite beams made up with steel deck oriented perpendicularly to the axis of the steel beams. A database is presented with experimental results that serve as base for the realization of the predictions using artificial intelligence. The algorithm k-NN is described and the technique of optimization Particle Swan Optimization (PSO) is introduced in the assignment of weight to the attributes. It is developed an experiment with the objective of determining the precision of the algorism k-NN, considering two variables: k (near neighbours' number) and "variants of weight", being 20 study combinations. The automated system PROCON was developed that speeded up the obtaining of results. The results reached with the variant of more effectiveness are compared with those that are obtained when evaluating the entrance data using the formulations of the current codes: AISC and Eurocode-4. Promissory results are obtained, being demonstrated that the algorism k - NN is an effective technique that favours the creation of new data for the generation of a representative group of the possible design situations, from face to the improvement of the calculation methods, in a quick and simple way, supplementing, to those ends, to classic experimentation and the numeric simulation.	[Larrua, A.; Olivera, I] Univ Camaguey, Grp Invest Estructuras, Camaguey, Cuba; [Caballero, Y.; Filiberto, Y.; Guerra, M.] Univ Camaguey, Grp Invest Inteligencia Artificial, Camaguey, Cuba; [Bello, R.] Univ Cent Martha Abreu Las Villas, Ctr Estudio Informat, Santa Clara, Cuba; [Bonilla, J.] Univ Ciego Avila, Fac Informat, Ciego De Avila, Cuba	Larrua, A (reprint author), Univ Camaguey, Grp Invest Estructuras, Camaguey, Cuba.	rafael.larrua@reduc.edu.cu					American Institute of Steel Construction, 2010, 199411 EN EUR COMM S; BONILLA J, 2008, THESIS UCLV SANTA CL; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DIAZ B, 1998, BEHAV WELDED SHEAR S; FIX E, 1951, 44 USAF SCH AV MED; GARCIA JM, 2003, K NN WORKSHOP SUITE; JAYAS BS, 1998, CANADIAN J CIVIL ENG, V15, P240; Johnson RP, 1998, P I CIVIL ENG-STR B, V128, P244; Kennedy J., 1995, P 1995 IEEE INT C NE; Lam D, 2005, J STRUCT ENG-ASCE, V131, P96, DOI 10.1016/(ASCE)0733-9445(2005)131:1(96); LYONS JC, 1994, 9407 CENPIST VIRG PO; Quinlan J.R., 1993, C 4 5 PROGRAMS MACHI; RAMBORODDENBERR.MD, 2002, THESIS U BLACKSBURG; Reyes-Sierra M., 2006, INT J COMPUTATIONAL, V2, P287; ROBINSON H, 1988, CAN J CIVIL ENG, V15, P553; ROSEMBLATT F, 1962, PRINCIPLES NEURODYNA; SUBLETT CN, 1992, 9203 CENPIST VIRG PO; WILSON DR, 1997, ADV INSTANCE BASED L; *AISC, 2005, 3605 ANSIAISC, P77	19	0	0	PONTIFICIA UNIV CATOLICA CHILE, ESCUELA CONSTRUCCION CIVIL	SANTIAGO	AV VICUNA MACKENNA 4860, SANTIAGO, 0000, CHILE	0718-915X		REV CONSTR	Rev. Constr.	DEC	2009	8	2					109	119				11	Construction & Building Technology; Engineering, Civil	Construction & Building Technology; Engineering	539BG	WOS:000273227800010	
J	Haouari, B; Ben Amor, N; Elouedi, Z; Mellouli, K				Haouari, Bakhta; Ben Amor, Nahla; Elouedi, Zied; Mellouli, Khaled			Naive possibilistic network classifiers	FUZZY SETS AND SYSTEMS			English	Article; Proceedings Paper	8th Conference of the International-Association-for-Fuzzy-Set-Management-and-Economy (SIGEF)	NOV 30-DEC 02, 2006	Hammamet, TUNISIA	Int Assoc Fuzzy Set Management & Econ		Possibility theory; Classification; Naive Bayes classifier; Possibilistic classifier; Aggregation operators	FEATURE SUBSET-SELECTION; INDEPENDENCE	Naive Bayesian network classifiers have proved their effectiveness to accomplish the classification task, even if they work under the strong assumption of independence of attributes in the context of the class node. However, as all of them are based on probability theory, they run into problems when they are faced with imperfection. This paper proposes a new approach of classification under the possibilistic framework with naive classifiers. To output the naive possibilistic network classifier, two procedures are studied namely the building phase, which deals with imperfect (imprecise/uncertain) dataset attributes and classes, and the classification phase, which is used to classify new instances that may be characterized by imperfect attributes. To improve the performance of our classifier, we propose two extensions namely selective naive possibilistic classifier and semi-naive possibilistic classifier. Experimental study has shown naive Bayes style possibilistic classifier, and is efficient in the imperfect case. (C) 2009 Elsevier B.V. All rights reserved.	[Haouari, Bakhta; Ben Amor, Nahla; Elouedi, Zied] Inst Super Gest Tunis, LARODEC, Le Bardo 2000, Tunisia; [Mellouli, Khaled] Inst Hautes Etud Commerciales Tunis, Tunis, Tunisia	Haouari, B (reprint author), Inst Super Gest Tunis, LARODEC, 41 Ave Liberte, Le Bardo 2000, Tunisia.	bakhtahaouari@yahoo.fr					Aha W., 1996, UCI REPOSITORY MACHI; Ben Amor N., 2003, Soft Computing, V8, DOI 10.1007/S00500-002-0255-X; BENAMOR N, 2004, P IEEE INT C FUZZ SY, V2, P653; Ben Amor N, 2002, INT J UNCERTAIN FUZZ, V10, P117; Bishop CM, 1996, NEURAL NETWORKS PATT; Borgelt C., 1998, P 7 IEEE INT C FUZZ, P663; Borgelt C, 1999, P 7 EUR C INT TECHN, P556; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; DUBOIS D, 2000, P 3 INT C INF FUS PA, P21; DUBOIS D, 1994, POSSIBILITY THEORY A; Dubois D., 1988, POSSIBILITY THEORY; Dubois D., 1998, HDB DEFEASIBLE REASO, V1, P169; Duda R., 1973, PATTERN CLASSIFICATI; ELOUEDI Z, 2006, LFA TOULOUSE, P61; Fonck P, 1997, INT J APPROX REASON, V16, P149, DOI 10.1016/S0888-613X(96)00095-3; FRIEH JM, 1997, ANN ORTHOP OUEST, V29, P161; Geiger D, 1996, ARTIF INTELL, V82, P45, DOI 10.1016/0004-3702(95)00014-3; Grossman D., 2004, P MACH LEARN, P46; Iba W., 1992, P 10 NAT C ART INT, P223; Inza I, 2000, ARTIF INTELL, V123, P157, DOI 10.1016/S0004-3702(00)00052-7; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kononenko I, 1991, P 6 EUR WORK SESS LE, p206~219; Langley P., 1994, P 10 C UNC ART INT, P399; LI X, 2003, IEEE WORKSH AUT SPEE; Liu H., 1998, FEATURE SELECTION KN; PAZZANI M, 1997, LEARNING DATA ARTIFI, P239; PEARL J, 1988, PROBABILISTIC REASON, P221; QUINLAN JR, 1986, MACH LEARN, V1, P106; Sahami M., 1996, P 2 INT C KNOWL DISC, P335; Shafer G., 1976, MATH THEORY EVIDENCE; Yager RR, 1997, INT J INTELL SYST, V12, P1; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; Zadeh L. A., 1978, Fuzzy Sets and Systems, V1, DOI 10.1016/0165-0114(78)90029-5	34	7	7	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114		FUZZY SET SYST	Fuzzy Sets Syst.	NOV 16	2009	160	22					3224	3238		10.1016/j.fss.2009.01.009		15	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	504TU	WOS:000270641400004	
J	Gertheiss, J; Tutz, G				Gertheiss, Jan; Tutz, Gerhard			Feature selection and weighting by nearest neighbor ensembles	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS			English	Article						Nearest neighbor methods; Variable selection; Ensemble methods; Classification	PATTERN-RECOGNITION; CLASSIFICATION; DISCRIMINATION; REGRESSION	In the field of statistical discrimination nearest neighbor methods are a well known, quite simple but successful nonparametric classification tool If the number of predictors increases, however, predictive power normally deteriorates. In general. if some covariates are assumed to be noise variables. variable selection is a promising approach. The paper's main focus is on the development and evaluation of a nearest neighbor ensemble with implicit variable selection. In contrast to other nearest neighbor approaches we are not primarily interested in classification, but in estimating the (posterior) class probabilities. In simulation studies and for real world data the proposed nearest neighbor ensemble is compared to an extended forward/backward variable selection procedure for nearest neighbor classifiers, and some alternative well established classification tools (that offer probability estimates as well). Despite its simple structure, the proposed method's performance is quite good - especially if relevant covariates can be separated from noise variables. Another advantage of the presented ensemble is the easy identification of interactions that are usually hard to detect. So not simply variable selection but rather some kind of feature selection is performed. (C) 2009 Elsevier B.V. All rights reserved	[Gertheiss, Jan; Tutz, Gerhard] Univ Munich, D-80799 Munich, Germany	Gertheiss, J (reprint author), Univ Munich, Akad Str 1, D-80799 Munich, Germany.						Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1984, CLASSIFICATION REGRE; Brier G.W., 1950, MONTHLY WEATHER REVI, V78, P1, DOI DOI 10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOMENICONI C, 2004, P 17 INT C PATT REC; Efron B, 2004, ANN STAT, V32, P407; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Ferraty F., 2006, NONPARAMETRIC FUNCTI; Fix E, 1951, DISCRIMINATORY ANAL; FORINA M, 1982, FOOD RES DATA ANAL, P189; FRIEDMAN JH, 1994, FLEIBLE METRIC NEARE; Gertheiss J, 2009, J CHEMOMETR, V23, P149, DOI 10.1002/cem.1211; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hastie T, 2001, ELEMENTS STAT LEARNI; HECHENBICHLER K, 2004, 399 SFB386 L M U MUN; Japon-Lujan R, 2006, J AGR FOOD CHEM, V54, P9706, DOI 10.1021/jf062546w; Karama M, 2004, SCI ENG COMPOS MATER, V11, P1; KOWALSKI BR, 1972, ANAL CHEM, V44, P1405, DOI 10.1021/ac60316a008; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; LECESSIE S, 1992, APPL STAT-J ROY ST C, V41, P191; LEISCH F, MLBENCH MACHINE LEAR; Liaw A, 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; Lukasiak BM, 2007, CHEMOMETR INTELL LAB, V87, P18, DOI 10.1016/j.chemolab.2006.01.003; Newman D. J., 1998, UCI REPOSITORY MACHI; Ripley B. D., 1996, PATTERN RECOGNITION; Selten Reinhard, 1998, EXPT EC, V1, P43, DOI 10.1023/A:1009957816843; SILVERMAN BW, 1989, INT STAT REV, V57, P233, DOI 10.2307/1403796; Therneau TM, RPART RECURSIVE PART; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; TURLACH BA, QUADPROG FUNCTIONS S; Venables WN, 2002, MODERN APPL STAT S; Yankow D., 2006, LECT NOTES COMPUTER, P545; [Anonymous], 2009, R LANG ENV STAT COMP	33	5	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-7439		CHEMOMETR INTELL LAB	Chemometrics Intell. Lab. Syst.	NOV 15	2009	99	1					30	38		10.1016/j.chemolab.2009.07.004		9	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	512MU	WOS:000271254400004	
J	Dekel, O; Shalev-Shwartz, S; Singer, Y				Dekel, Ofer; Shalev-Shwartz, Shai; Singer, Yoram			Individual Sequence Prediction Using Memory-Efficient Context Trees	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article						Context trees; online learning; perceptron; shifting bounds	PROBABILISTIC-AUTOMATA; LENGTH	Context trees are a popular and effective tool for tasks such as compression, sequential prediction, and language modeling. We present an algebraic perspective of context trees for the task of individual sequence prediction. Our approach stems from a generalization of the notion of margin used for linear predictors. By exporting the concept of margin to context trees, we are able to cast the individual sequence prediction problem as the task of finding a linear separator in a Hilbert space, and to apply techniques from machine learning and online optimization to this problem. Our main contribution is a memory efficient adaptation of the perceptron algorithm for individual sequence prediction. We name our algorithm the shallow perceptron and prove a shifting mistake bound, which relates its performance with the performance of any sequence of context trees. We also prove that the shallow perceptron grows a context tree at a rate that is upper bounded by its mistake rate, which imposes an upper bound on the size of the trees grown by our algorithm.	[Dekel, Ofer] Microsoft Res, Redmond, WA 98052 USA; [Shalev-Shwartz, Shai] Hebrew Univ Jerusalem, Dept Comp Sci & Engn, IL-91904 Jerusalem, Israel; [Singer, Yoram] Google Res, Mountain View, CA 94043 USA	Dekel, O (reprint author), Microsoft Res, Redmond, WA 98052 USA.	oferd@microsoft.com; shais@cs.huji.ac.il; singer@google.com			Israeli Science Foundation [522-04]	This work was supported in part by the Israeli Science Foundation under Grant 522-04.	AGMON S, 1954, CAN J MATH, V6, P382, DOI 10.4153/CJM-1954-037-2; Apostolico A, 2000, J COMPUT BIOL, V7, P381, DOI 10.1089/106652700750050844; Blackwell D., 1956, PAC J MATH, V6, P1; Buhlmann P, 1999, ANN STAT, V27, P480; Cesa-Bianchi N., 2006, PREDICTION LEARNING; CESABIANCHI N, 2006, P 19 ANN C LEARN THE, P483; Cover T., 1965, P 4 PRAG C INF THEOR, P263; COVER TM, 1977, IEEE T SYST MAN CYB, V7, P421, DOI 10.1109/TSMC.1977.4309738; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crammer K, 2006, J MACH LEARN RES, V7, P551; Duda R., 1973, PATTERN CLASSIFICATI; FEDER M, 1992, IEEE T INFORM THEORY, V38, P1258, DOI 10.1109/18.144706; GENTILE C, 2002, MACH LEARN, V53; Hannan J., 1957, CONTRIBUTIONS THEORY, V3, P97; Helmbold DP, 1997, MACH LEARN, V27, P51, DOI 10.1023/A:1007396710653; Novikoff A.B., 1962, P S MATH THEOR AUT, V12, P615; Pereira FC, 1999, MACH LEARN, V36, P183, DOI 10.1023/A:1007670818503; Robbins H., 1951, P 2 BERK S MATH STAT, P131; Ron D, 1996, MACH LEARN, V25, P117, DOI 10.1023/A:1026490906255; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Shalev-Shwartz S., 2007, THESIS HEBREW U JERU; SHALEVSHWARTZ S, 2006, ADV NEURAL INFORM PR, V20; Willems F. M. J., 1994, Proceedings. 1994 IEEE International Symposium on Information Theory (Cat. No.94CH3467-8), DOI 10.1109/ISIT.1994.394632; WILLEMS FMJ, 1995, IEEE T INFORM THEORY, V41, P653, DOI 10.1109/18.382012; WILLEMS FMJ, 1993, P 1993 IEEE INT S IN, P59, DOI 10.1109/ISIT.1993.748374; ZIV J, 1978, IEEE T INFORM THEORY, V24, P530, DOI 10.1109/TIT.1978.1055934	26	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9448		IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	NOV	2009	55	11					5251	5262		10.1109/TIT.2009.2030460		12	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	509LQ	WOS:000271019700033	
J	Lin, WZ; Xiao, X; Chou, KC				Lin, Wei-Zhong; Xiao, Xuan; Chou, Kuo-Chen			GPCR-GIA: a web-server for identifying G-protein coupled receptors and their families with grey incidence analysis	PROTEIN ENGINEERING DESIGN & SELECTION			English	Article						ensemble classifier; fusion; K nearest neighbor algorithm; pseudo amino acid composition; web server	AMINO-ACID-COMPOSITION; SUBCELLULAR LOCATION PREDICTION; SUPPORT VECTOR MACHINE; MODIFIED MAHALANOBIS DISCRIMINANT; STRUCTURAL CLASS PREDICTION; COMPLEXITY MEASURE FACTOR; ENZYME SUBFAMILY CLASSES; IMPROVED HYBRID APPROACH; APOPTOSIS PROTEINS; MEMBRANE-PROTEINS	G-protein-coupled receptors (GPCRs) play fundamental roles in regulating various physiological processes as well as the activity of virtually all cells. Different GPCR families are responsible for different functions. With the avalanche of protein sequences generated in the post-genomic age, it is highly desired to develop an automated method to address the two problems: given the sequence of a query protein, can we identify whether it is a GPCR? If it is, what family class does it belong to? Here, a two-layer ensemble classifier called GPCR-GIA was proposed by introducing a novel scale called 'grey incident degree'. The overall success rate by GPCR-GIA in identifying GPCR and non-GPCR was about 95%, and that in identifying the GPCRs among their nine family classes was about 80%. These rates were obtained by the jackknife cross-validation tests on the stringent benchmark data sets where none of the proteins has >= 50% pairwise sequence identity to any other in a same class. Moreover, a user-friendly web-server was established at http://218.65.61.89:8080/bioinfo/GPCR-GIA. For user's convenience, a step-by-step guide on how to use the GPCR-GIA web server is provided. Generally speaking, one can get the desired two-level results in around 10 s for a query protein sequence of 300-400 amino acids; the longer the sequence is, the more time that is needed.	[Lin, Wei-Zhong; Xiao, Xuan] Jing De Zhen Ceram Inst, Dept Comp, Jing De Zhen 333001, Peoples R China; [Chou, Kuo-Chen] Gordon Life Sci Inst, San Diego, CA 92130 USA	Xiao, X (reprint author), Jing De Zhen Ceram Inst, Dept Comp, Jing De Zhen 333001, Peoples R China.	xiaoxuan0326@yahoo.com.cn	Chou, Kuo-Chen/A-8340-2009		National Natural Science Foundation of China [60661003]; department of education of JiangXi Province [GJJ09271]	The work in this research was supported by the grants from the National Natural Science Foundation of China (No. 60661003), the department of education of JiangXi Province (No. GJJ09271), and the plan for training youth scientists (stars of Jing-Cang) of Jiangxi Province.	Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Bhasin M, 2005, NUCLEIC ACIDS RES, V33, pW143, DOI 10.1093/nar/gki351; Cai YD, 2005, J THEOR BIOL, V234, P145, DOI 10.1016/j.jtbi.200.11.017; Call ME, 2006, CELL, V127, P355, DOI 10.1016/j.cell.2006.08.044; Chen C, 2006, ANAL BIOCHEM, V357, P116, DOI 10.1016/j.ab.2006.07.022; Chen C, 2006, J THEOR BIOL, V243, P444, DOI 10.1016/j.jtbi.2006.06.025; Chen C, 2009, PROTEIN PEPTIDE LETT, V16, P27; Chen YL, 2007, J THEOR BIOL, V245, P775, DOI 10.1016/j.jtbi.2006.11.010; Chen YL, 2007, J THEOR BIOL, V248, P377, DOI 10.1016/j.jtbi.2007.05.019; Chou K. C., 2009, OPEN BIOINFORMATICS, V3, P31; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2003, PROTEINS, V53, P282, DOI 10.1002/prot.10500; Chou KC, 2007, ANAL BIOCHEM, V370, P1, DOI 10.1016/j.ab.2007.07.006; Chou KC, 2001, PROTEINS, V44, P60, DOI 10.1002/prot.1072.abs; Chou KC, 2008, NAT PROTOC, V3, P153, DOI 10.1038/nprot.2007.494; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 2006, J PROTEOME RES, V5, P1888, DOI 10.1021/pr060167c; Chou KC, 2007, BIOCHEM BIOPH RES CO, V357, P633, DOI 10.1016/j.bbrc.2007.03.162; Chou KC, 2006, J PROTEOME RES, V5, P316, DOI 10.1021/pr050331g; Chou KC, 2002, J PROTEOME RES, V1, P429, DOI 10.1021/pr025527k; Chou KC, 2004, CURR MED CHEM, V11, P2105; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2005, J PROTEOME RES, V4, P1681, DOI 10.1021/pr050145a; Chou KC, 2005, J PROTEOME RES, V4, P1413, DOI 10.1021/pr050087t; Chou KC, 2007, BIOCHEM BIOPH RES CO, V360, P339, DOI 10.1016/j.bbrc.2007.06.027; Chou KC, 2007, J PROTEOME RES, V6, P1728, DOI 10.1021/pr060635i; Chou KC, 2004, PROTEIN SCI, V13, P2857, DOI 10.1110/ps.04981104; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENG JL, 1985, SYST CONTROL LETT, V1, P288; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Ding H, 2009, PROTEIN PEPTIDE LETT, V16, P351; Ding YS, 2008, PATTERN RECOGN LETT, V29, P1887, DOI 10.1016/j.patrec.2008.06.007; Douglas SM, 2007, P NATL ACAD SCI USA, V104, P6644, DOI 10.1073/pnas.0700930104; Du PF, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-518; Gao QB, 2006, PROTEIN ENG DES SEL, V19, P511, DOI 10.1093/protein/gzl038; Georgiou DN, 2009, J THEOR BIOL, V257, P17, DOI 10.1016/j.jtbi.2008.11.003; GONZALEZDIAZ H, 2007, CURR TOP MED CHEM, V10, P1015; Gonzalez-Diaz H, 2008, CURR TOP MED CHEM, V8, P1676, DOI 10.2174/156802608786786543; Gonzalez-Diaz H, 2008, PROTEOMICS, V8, P750, DOI 10.1002/pmic.200700638; Hall RA, 2002, CIRC RES, V91, P672, DOI 10.1161/01.RES.0000037000.74258.03; Heuss C, 2000, TRENDS NEUROSCI, V23, P469, DOI 10.1016/S0166-2236(00)01643-X; Hill CA, 2002, SCIENCE, V298, P176, DOI 10.1126/science.1076196; HOPP TP, 1981, P NATL ACAD SCI-BIOL, V78, P3824, DOI 10.1073/pnas.78.6.3824; Jiang XY, 2008, PROTEIN PEPTIDE LETT, V15, P392, DOI 10.2174/092986608784246443; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Li FM, 2008, PROTEIN PEPTIDE LETT, V15, P612, DOI 10.2174/092986608784966930; Lin H, 2007, BIOCHEM BIOPH RES CO, V354, P548, DOI 10.1016/j.bbrc.2007.01.011; Lin H, 2008, PROTEIN PEPTIDE LETT, V15, P739, DOI 10.2174/092986608785133681; Lin H, 2007, J COMPUT CHEM, V28, P1463, DOI 10.1002/jcc.20554; Lin H, 2009, ACTA BIOTHEOR, V57, P321, DOI 10.1007/s10441-008-9067-4; Lin H, 2008, J THEOR BIOL, V252, P350, DOI 10.1016/j.jtbi.2008.02.004; Liu H, 2005, BIOCHEM BIOPH RES CO, V336, P737, DOI 10.1016/j.bbrc.2005.08.160; LIU SF, 2006, SCI INQ, V7, P111; Mahalanobis P., 1936, P NAT I SCI INDIA, V2, P49; Mardia K. V., 1979, MULTIVARIATE ANAL, P322; Matsunami H, 2000, NATURE, V404, P601; Milligan G, 2001, TRENDS PHARMACOL SCI, V22, P513, DOI 10.1016/S0165-6147(00)01801-0; Mondal S, 2006, J THEOR BIOL, V243, P252, DOI 10.1016/j.jtbi.2006.06.014; Mundra P, 2007, PATTERN RECOGN LETT, V28, P1610, DOI 10.1016/j.patrec.2007.04.001; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; Otaki JM, 2003, J THEOR BIOL, V223, P27, DOI 10.1016/S0022-5193(03)00068-7; Oxenoid K, 2005, P NATL ACAD SCI USA, V102, P10870, DOI 10.1073/pnas.0504920102; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; Pillai K. C. S., 1985, ENCY STATISTICAL SCI, V5, P176; Qiu JD, 2009, ANAL BIOCHEM, V390, P68, DOI 10.1016/j.ab.2009.04.009; Schnell JR, 2008, NATURE, V451, P591, DOI 10.1038/nature06531; Shen H. B., 2009, J BIOMED SCI ENG, V2, P136, DOI DOI 10.4236/JBISE.2009.23024; Shen HB, 2006, BIOINFORMATICS, V22, P1717, DOI 10.1093/bioinformatics/btl170; Shen HB, 2005, BIOCHEM BIOPH RES CO, V334, P288, DOI 10.1016/j.bbrc.2005.06.087; Shen HB, 2009, J THEOR BIOL, V256, P441, DOI 10.1016/j.jtbi.2008.10.007; Shen HB, 2007, BIOCHEM BIOPH RES CO, V363, P297, DOI 10.1016/j.bbrc.2007.08.140; Shen HB, 2007, BIOCHEM BIOPH RES CO, V364, P53, DOI 10.1016/j.bbrc.2007.09.098; Shen HB, 2006, J THEOR BIOL, V240, P9, DOI 10.1016/j.jtbi.2005.08.016; Shen HB, 2005, BIOCHEM BIOPH RES CO, V337, P752, DOI 10.1016/j.bbrc.2005.09.117; Shen HB, 2008, ANAL BIOCHEM, V373, P386, DOI 10.1016/j.ab.2007.10.012; TANFORD C, 1962, J AM CHEM SOC, V84, P4240, DOI 10.1021/ja00881a009; Wang SQ, 2006, J THEOR BIOL, V242, P941, DOI 10.1016/j.jtbi.2006.05.006; Wen Z, 2007, AMINO ACIDS, V32, P277, DOI 10.1007/s00726-006-0341-y; Xiao X, 2006, J COMPUT CHEM, V27, P478, DOI 10.1002/jcc.20354; Xiao X, 2009, J COMPUT CHEM, V30, P1414, DOI 10.1002/jcc.21163; Xiao X, 2009, J APPL CRYSTALLOGR, V42, P169, DOI 10.1107/S0021889809002751; Xiao X, 2008, J COMPUT CHEM, V29, P2018, DOI 10.1002/jcc.20955; Xiao X, 2008, J THEOR BIOL, V254, P691, DOI 10.1016/j.jtbi.2008.06.016; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Zeng YH, 2009, J THEOR BIOL, V259, P366, DOI 10.1016/j.jtbi.2009.03.028; Zhang GY, 2008, J THEOR BIOL, V253, P310, DOI 10.1016/j.jtbi.2008.03.015; Zhang GY, 2008, PROTEIN PEPTIDE LETT, V15, P1132, DOI 10.2174/092986608786071184; Zhang TL, 2008, J THEOR BIOL, V250, P186, DOI 10.1016/j.jtbi.2007.09.014; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2006, PROTEINS, V63, P681, DOI 10.1002/prot.20898; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou XB, 2007, J THEOR BIOL, V248, P546, DOI 10.1016/j.jtbi.2007.06.001	94	51	51	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1741-0126		PROTEIN ENG DES SEL	Protein Eng. Des. Sel.	NOV	2009	22	11					699	705		10.1093/protein/gzp057		7	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology	510RU	WOS:000271109800007	
J	Batsakis, S; Petrakis, EGM; Milios, E				Batsakis, Sotiris; Petrakis, Euripides G. M.; Milios, Evangelos			Improving the performance of focused web crawlers	DATA & KNOWLEDGE ENGINEERING			English	Article						Focused crawler; Learning crawler; Hidden Markov Model (HMM) crawler; World Wide Web	CLASSIFICATION; ALGORITHM	This work addresses issues related to the design and implementation of focused crawlers. Several variants of state-of-the-art crawlers relying on web page content and link information for estimating the relevance of web pages to a given topic are proposed. Particular emphasis is given to crawlers capable of learning not only the content of relevant pages (as classic crawlers do) but also paths leading to relevant pages. A novel learning crawler inspired by a previously proposed Hidden Markov Model (HMM) crawler is described as well. The crawlers have been implemented using the same baseline implementation (only the priority assignment function differs in each crawler) providing an unbiased evaluation framework for a comparative analysis of their performance. All crawlers achieve their maximum performance when a combination of web page content and (link) anchor text is used for assigning download priorities to web pages. Furthermore, the new HMM crawler improved the performance of the original HMM crawler and also outperforms classic focused crawlers in searching for specialized topics. (C) 2009 Elsevier B.V. All rights reserved.	[Batsakis, Sotiris; Petrakis, Euripides G. M.] TUC, Dept Elect & Comp Engn, GR-73100 Khania, Crete, Greece; [Milios, Evangelos] Dalhousie Univ, Fac Comp Sci, Halifax, NS B3H 1W5, Canada	Batsakis, S (reprint author), TUC, Dept Elect & Comp Engn, GR-73100 Khania, Crete, Greece.	batsakis@softnet.tuc.gr; petrakis@intelligence.tuc.gr; eem@cs.dal.ca					Aggarwal CC, 2001, P 10 INT WORLD WID W, P96, DOI DOI 10.1145/371920.371955; BADIA A, 2006, P 15 INT C WORLD WID, P1043, DOI 10.1145/1135777.1136006; Bao SH, 2008, IEEE T KNOWL DATA EN, V20, P1297, DOI 10.1109/TKDE.2008.98; BERGMARK D, 2002, P 2 ACM IEEE CS JOIN; BERGMARK D, 2002, 6 EUR C DIG LIB ROM; CHAKRABARTI S, 1999, P 8 INT WORLD WID WE; Chakrabarti S., 2002, P 11 INT WORLD WID W, P148; CHANG CH, 2006, IEEE T KNOWLEDGE DAT; CHEN Y, 2007, THESIS VIRGINIA POLY; Cho J, 2001, THESIS STANFORD U; CORLEY C, 2005, P ACL WORKSH EMP MOD, P13, DOI 10.3115/1631862.1631865; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; De Bra P., 1994, P 4 RIAO C NEW YORK, P481; Diligenti M., 2000, P 26 INT C VER LARG, P527; Ehrig M, 2003, P S APPL COMP SAC 20; Hersovici M, 1998, COMPUT NETWORKS ISDN, V30, P317, DOI 10.1016/S0169-7552(98)00038-5; HLIAOUTAKIS A, 2006, INT J SEMANT WEB INF, V3, P55; Kraft R, 2003, FIRST LATIN AMERICAN WEB CONGRESS, PROCEEDINGS, P84; LI J, 2005, P 14 INT WORLD WID W, P1190; Liu H, 2004, P 6 ANN ACM INT WORK, P16, DOI 10.1145/1031453.1031458; Liu HY, 2006, DATA KNOWL ENG, V59, P270, DOI 10.1016/j.datak.2006.01.012; MCCOWN F, 2007, ACM IEEE JOINT C DIG, P309; Menczer F., 2004, ACM T INTERNET TECHN, V4, P378, DOI 10.1145/1031114.1031117; Page L., 1998, P 7 INT WORLD WID WE, P107; Pant G, 2006, IEEE T KNOWL DATA EN, V18, P107; Pant G., 2004, P 4 ACM IEEE CS JOIN, P142, DOI 10.1145/996350.996384; Pant G, 2005, ACM T INFORM SYST, V23, P430, DOI 10.1145/1095872.1095875; Pivk A, 2007, DATA KNOWL ENG, V60, P567, DOI 10.1016/j.datak.2006.04.002; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; Rabiner L. R., 1986, IEEE ASSP Magazine, V3, DOI 10.1109/MASSP.1986.1165342; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; Steinbach M., 2000, 6 ACM SIGKDD WORLD T; VARELAS G, 2005, 7 ACM INT WORKSH WEB; XU Q, 2007, P 16 INT C WORLD WID, P1159, DOI 10.1145/1242572.1242744	34	9	9	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-023X		DATA KNOWL ENG	Data Knowl. Eng.	OCT	2009	68	10					1001	1013		10.1016/j.datak.2009.04.002		13	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	504GK	WOS:000270603900007	
J	Annoni, M; Cristaldi, L; Lazzaroni, M; Ferrari, S				Annoni, Massimiliano; Cristaldi, Loredana; Lazzaroni, Massimo; Ferrari, Stefano			Nozzles Classification in a High-Pressure Water Jet System	IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT			English	Article						Classification; diagnosis; water jet (WJ) systems		In this paper, a technique for classifying the working condition of a water jet system is presented. The classifier is based on the discrete Fourier transform (DFT) of the electrical power signal. It is shown that this information can characterize the working condition of the system and predict the presence of (an incoming) faulty behavior. Experiments and comparisons with the 1-nearest-neighbor (1-NN) classifier have been carried out, showing promising results.	[Annoni, Massimiliano] Politecn Milan, Dipartimento Meccan, I-20156 Milan, Italy; [Cristaldi, Loredana] Politecn Milan, Dipartimento Elettrotecn, I-20133 Milan, Italy; [Lazzaroni, Massimo; Ferrari, Stefano] Univ Milan, Dipartimento Tecnol Informaz, I-26013 Crema, Italy	Annoni, M (reprint author), Politecn Milan, Dipartimento Meccan, I-20156 Milan, Italy.	massimiliano.annoni@polimi.it; loredana.cristaldi@polimi.it; lazzaroni@dti.unimi.it; ferrari@dti.unimi.it	Ferrari, Stefano/F-3407-2010				ANNONI A, 2005, IMTC, P1311; ANNONI M, 2004, 17 INT C WAT JETT, P415; CHALMERS E, 1993, 7 AM WAT JET C SEATT, P327; Cherkassky V, 1998, LEARNING DATA; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristaldi L, 2004, IEEE T INSTRUM MEAS, V53, P1020, DOI 10.1109/TIM.2004.830589; Fabien BC, 2003, MATH COMP MODEL DYN, V9, P45, DOI 10.1076/mcmd.9.1.45.16513; Friedman M, 1999, INTRO PATTERN RECOGN; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; Jain A. K., 2000, IEEE T PATTERN ANAL, V22, P1; SINGH PJ, 1997, 9 AM WAT C DEAB MICH, P397; TREMBLAY M, 1999, 10 AM WAT C, P167; TUNKEL PJ, 1997, 9 AM WAT C, P397	13	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9456		IEEE T INSTRUM MEAS	IEEE Trans. Instrum. Meas.	OCT	2009	58	10					3739	3745		10.1109/TIM.2009.2019702		7	Engineering, Electrical & Electronic; Instruments & Instrumentation	Engineering; Instruments & Instrumentation	493XP	WOS:000269772900045	
J	Manns, JR; Eichenbaum, H				Manns, Joseph R.; Eichenbaum, Howard			A cognitive map for object memory in the hippocampus	LEARNING & MEMORY			English	Article							IMPAIRED RECOGNITION MEMORY; ENTORHINAL CORTEX; SPATIAL REPRESENTATION; EPISODIC MEMORY; PLACE CELLS; DECLARATIVE MEMORY; PERIRHINAL CORTEX; RATS; DAMAGE; NEURONS	The hippocampus has been proposed to support a cognitive map, a mental representation of the spatial layout of an environment as well as the nonspatial items encountered in that environment. In the present study, we recorded simultaneously from 43 to 61 hippocampal pyramidal cells as rats performed an object recognition memory task in which novel and repeated objects were encountered in different locations on a circular track. Multivariate analyses of the neural data indicated that information about object identity was represented secondarily to the primary information dimension of object location. In addition, the neural data related to performance on the recognition memory task. The results suggested that objects were represented as points of interest on the hippocampal cognitive map and that this map was useful in remembering encounters with particular objects in specific locations.	[Manns, Joseph R.] Emory Univ, Dept Psychol, Atlanta, GA 30322 USA; [Eichenbaum, Howard] Boston Univ, Ctr Memory & Brain, Boston, MA 02215 USA	Manns, JR (reprint author), Emory Univ, Dept Psychol, Atlanta, GA 30322 USA.	jmanns@emory.edu			NIH [MH079564, MH51570]; NSF [SBE0354378]	We thank Kimberly Ong, Lisa Pytka, Carolyn Pearson, and Hannah Dalke for their assistance. This research was supported by grants NIH MH079564 (J. R. M), NIH MH51570 (H. E.), and NSF SBE0354378 (H. E.).	Alvarez P, 2001, LEARN MEMORY, V8, P79, DOI 10.1101/lm.38201; Bachevalier J, 2008, HIPPOCAMPUS, V18, P64, DOI 10.1002/hipo.20369; Bunsey M, 1996, NATURE, V379, P255, DOI 10.1038/379255a0; Burgess N, 2002, NEURON, V35, P625, DOI 10.1016/S0896-6273(02)00830-9; Burwell RD, 1998, NEUROREPORT, V9, P3013, DOI 10.1097/00001756-199809140-00017; Clark RE, 2002, J NEUROSCI, V22, P4663; Clark RE, 2000, J NEUROSCI, V20, P8853; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Eichenbaum H, 1999, NEURON, V23, P209, DOI 10.1016/S0896-6273(00)80773-4; ENNACEUR A, 1988, BEHAV BRAIN RES, V31, P47, DOI 10.1016/0166-4328(88)90157-X; Fortin NJ, 2002, NAT NEUROSCI, V5, P458, DOI 10.1038/nn834; Fortin NJ, 2004, NATURE, V431, P188, DOI 10.1038/nature02853; Fyhn M, 2004, SCIENCE, V305, P1258, DOI 10.1126/science.1099901; Hafting T, 2005, NATURE, V436, P801, DOI 10.1038/nature03721; Hargreaves EL, 2005, SCIENCE, V308, P1792, DOI 10.1126/science.1110449; JUNG MW, 1994, J NEUROSCI, V14, P7347; Kesner RP, 2002, BEHAV NEUROSCI, V116, P286, DOI 10.1037//0735-7044.116.2.286; Kjelstrup KB, 2008, SCIENCE, V321, P140, DOI 10.1126/science.1157086; Knierim JJ, 2006, HIPPOCAMPUS, V16, P755, DOI 10.1002/hipo.20203; Leutgeb S, 2005, SCIENCE, V309, P619, DOI 10.1126/science.1114037; Manns JR, 2006, HIPPOCAMPUS, V16, P795, DOI 10.1002/hipo.20205; Manns JR, 2007, NEURON, V56, P530, DOI 10.1016/j.neuron.2007.08.017; Manns JR, 2000, P NATL ACAD SCI USA, V97, P12375, DOI 10.1073/pnas.220398097; McNaughton BL, 2006, NAT REV NEUROSCI, V7, P663, DOI 10.1038/nrn1932; MILLER EK, 1993, J NEUROSCI, V13, P1460; Moser EI, 2008, ANNU REV NEUROSCI, V31, P69, DOI 10.1146/annurev.neuro.31.061307.090723; Mumby DG, 2002, LEARN MEMORY, V9, P49, DOI 10.1101/lm.41302; O'Keefe J., 1978, HIPPOCAMPUS COGNITIV; O'Keefe J, 1999, HIPPOCAMPUS, V9, P352, DOI 10.1002/(SICI)1098-1063(1999)9:4<352::AID-HIPO3>3.0.CO;2-1; Pascalis O, 2004, NEUROPSYCHOLOGIA, V42, P1293, DOI 10.1016/j.neuropsychologia.2004.03.005; Pihlajamaki M, 2004, EUR J NEUROSCI, V19, P1939, DOI 10.1111/j.1460.9568.2004.03282.x; SAVE E, 1992, BEHAV NEUROSCI, V106, P447, DOI 10.1037/0735-7044.106.3.447; Suzuki WA, 1997, J NEUROPHYSIOL, V78, P1062; SUZUKI WA, 1994, J COMP NEUROL, V350, P497, DOI 10.1002/cne.903500402; TOLMAN EC, 1948, PSYCHOL REV, V55, P189, DOI 10.1037/h0061626; WITTER MP, 1991, J COMP NEUROL, V307, P437, DOI 10.1002/cne.903070308; Witter MP, 2000, HIPPOCAMPUS, V10, P398, DOI 10.1002/1098-1063(2000)10:4<398::AID-HIPO6>3.0.CO;2-K; Wood ER, 1999, NATURE, V397, P613; Wood ER, 2000, NEURON, V27, P623, DOI 10.1016/S0896-6273(00)00071-4; Young BJ, 1997, J NEUROSCI, V17, P5183; Zola SM, 2000, J NEUROSCI, V20, P451	41	38	41	COLD SPRING HARBOR LAB PRESS, PUBLICATIONS DEPT	WOODBURY	500 SUNNYSIDE BLVD, WOODBURY, NY 11797-2924 USA	1072-0502		LEARN MEMORY	Learn. Mem.	OCT	2009	16	10					616	624		10.1101/lm.1484509		9	Neurosciences; Psychology, Experimental	Neurosciences & Neurology; Psychology	501GH	WOS:000270368500007	
J	Murphy, K; van Ginneken, B; Schilham, AMR; de Hoop, BJ; Gietema, HA; Prokop, M				Murphy, K.; van Ginneken, B.; Schilham, A. M. R.; de Hoop, B. J.; Gietema, H. A.; Prokop, M.			A large-scale evaluation of automatic pulmonary nodule detection in chest CT using local image features and k-nearest-neighbour classification	MEDICAL IMAGE ANALYSIS			English	Article						Nodule detection; Lung nodule; CT; Automatic detection; kNN; Shape index	COMPUTER-AIDED DETECTION; THIN-SECTION CT; LUNG-CANCER; HELICAL CT; SPIRAL CT; TOMOGRAPHY; SEGMENTATION; ALGORITHM; FEASIBILITY; EXPERIENCE	A scheme for the automatic detection of nodules in thoracic computed tomography scans is presented and extensively evaluated. The algorithm uses the local image features of shape index and curvedness in order to detect candidate structures in the lung volume and applies two successive k-nearest-neighbour classifiers in the reduction of false-positives. The nodule detection system is trained and tested on three databases extracted from a large-scale experimental screening study. The databases are constructed in order to evaluate the algorithm on both randomly chosen screening data as well as data containing higher proportions of nodules requiring follow-up. The system results are extensively evaluated including performance measurements on specific nodule types and sizes within the databases and on lesions which later proved to be malignant. In a random selection of 813 scans from the screening study a sensitivity of 80% with an average 4.2 false-positives per scan is achieved. The detection results presented are a realistic measure of a CAD system performance in a low-dose screening study which includes a diverse array of nodules of many varying sizes, types and textures. (C) 2009 Elsevier B.V. All rights reserved.	[Murphy, K.; van Ginneken, B.; Schilham, A. M. R.] Univ Med Ctr, Image Sci Inst, NL-3584 CX Utrecht, Netherlands; [de Hoop, B. J.; Gietema, H. A.; Prokop, M.] Univ Med Ctr, Dept Radiol, NL-3584 CX Utrecht, Netherlands	Murphy, K (reprint author), Univ Med Ctr, Image Sci Inst, Heidelberglaan 100,Room Q0S-459, NL-3584 CX Utrecht, Netherlands.	keelin@isi.uu.nl	van Ginneken, Bram/A-3728-2012	van Ginneken, Bram/0000-0003-2028-8972			American Cancer Society, 2008, CANC FACTS FIG; Aoki T, 2000, AM J ROENTGENOL, V174, P763; Arimura H, 2004, ACAD RADIOL, V11, P617, DOI 10.1016/j.acra.2004.02.009; Bae KT, 2005, RADIOLOGY, V236, P286, DOI 10.1148/radiol.2361041286; Bellotti R, 2007, MED PHYS, V34, P4901, DOI 10.1118/1.2804720; Betke M, 2003, MED IMAGE ANAL, V7, P265, DOI 10.1016/S1361-8415(03)00007-0; Brown MS, 2003, RADIOLOGY, V226, P256, DOI 10.1148/radiol.2261011708; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679; Chang S, 2004, LECT NOTES COMPUT SC, V3217, P821; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dehmeshki J, 2007, COMPUT MED IMAG GRAP, V31, P408, DOI 10.1016/j.compmedimag.2007.03.002; Duda R. O., 2001, PATTERN CLASSIFICATI; Enquobahrie AA, 2007, ACAD RADIOL, V14, P579, DOI 10.1016/j.acra.2007.01.029; Ge ZY, 2005, MED PHYS, V32, P2443, DOI 10.1118/1.1944667; Gohagan JK, 2005, LUNG CANCER-J IASLC, V47, P9, DOI 10.1016/j.lungcan.2004.06.007; GURNEY JW, 1996, RADIOLOGY, V199, P122; Henschke CI, 2001, ONCOLOGIST, V6, P147, DOI 10.1634/theoncologist.6-2-147; Hu SY, 2001, IEEE T MED IMAGING, V20, P490, DOI 10.1109/42.929615; Jeong YJ, 2007, AM J ROENTGENOL, V188, P57, DOI 10.2214/AJR.05.2131; Kakinuma R, 1999, RADIOLOGY, V212, P61; Kawata Y, 2004, LECT NOTES COMPUT SC, V3217, P838; Koenderink JJ, 1990, SOLID SHAPE; Kostis WJ, 2003, IEEE T MED IMAGING, V22, P1259, DOI 10.1109/TMI.2003.817785; Li Q, 2008, ACAD RADIOL, V15, P165, DOI 10.1016/j.acra.2007.09.018; Matsumoto S, 2006, MED IMAGE ANAL, V10, P343, DOI 10.1016/j.media.2005.07.001; McCulloch CC, 2004, ACAD RADIOL, V11, P258, DOI 10.1016/S1076-6332(03)00729-3; Mendonca PRS, 2007, LECT NOTES COMPUT SC, V4584, P134; METZ CE, 1986, INVEST RADIOL, V21, P720; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P734, DOI 10.1109/TPAMI.2002.1008381; MURPHY K, 2007, P SPIE, V6514; New York Early Lung Cancer Action Project Investigators, 2007, RADIOLOGY, V243, P239; Novello S, 2005, ANN ONCOL, V16, P1662, DOI 10.1093/annonc/mdi314; Paik DS, 2004, IEEE T MED IMAGING, V23, P661, DOI 10.1109/TMI.2004.826362; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Reeves AP, 2006, IEEE T MED IMAGING, V25, P435, DOI 10.1109/TMI.2006.871548; Retico A, 2008, COMPUT BIOL MED, V38, P525, DOI 10.1016/j.compbiomed.2008.02.001; Rubin GD, 2005, RADIOLOGY, V234, P274, DOI 10.1148/radiol.2341040589; Sluimer I, 2005, IEEE T MED IMAGING, V24, P1025, DOI 10.1109/TMI.2005.851757; Swensen SJ, 2002, AM J RESP CRIT CARE, V165, P508, DOI 10.1164/rccm.2107006; Swensen SJ, 2005, RADIOLOGY, V235, P259, DOI 10.1148/radiol.2351041662; White CS, 1996, RADIOLOGY, V199, P109; Wiemker R, 2005, BRIT J RADIOL, V78, pS46, DOI 10.1259/bjr/30281702; Xu DM, 2006, LUNG CANCER, V54, P177, DOI 10.1016/j.lungcan.2006.08.006; YE X, 2007, C P IEEE ENG MED BIO, V1, P4449; Zhang XW, 2005, LECT NOTES COMPUT SC, V3565, P664; Zhao Binsheng, 2003, J Appl Clin Med Phys, V4, P248, DOI 10.1120/1.1582411; Zhou Jinghao, 2006, Med Image Comput Comput Assist Interv, V9, P784	47	20	21	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1361-8415		MED IMAGE ANAL	Med. Image Anal.	OCT	2009	13	5					757	770		10.1016/j.media.2009.07.001		14	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging	Computer Science; Engineering; Radiology, Nuclear Medicine & Medical Imaging	499YY	WOS:000270264200006	
J	Chuang, LY; Yang, CS; Li, JC; Yang, CH				Chuang, Li-Yeh; Yang, Cheng-San; Li, Jung-Chike; Yang, Cheng-Hong			Chaotic Genetic Algorithm for Gene Selection and Classification Problems	OMICS-A JOURNAL OF INTEGRATIVE BIOLOGY			English	Article							MICROARRAY DATA; CANCER CLASSIFICATION; DESIGN OPTIMIZATION; SYSTEM	Pattern recognition techniques suffer from a well-known curse, the dimensionality problem. The microarray data classification problem is a classical complex pattern recognition problem. Selecting relevant genes from microarray data poses a formidable challenge to researchers due to the high-dimensionality of features, multiclass categories being involved, and the usually small sample size. The goal of feature (gene) selection is to select those subsets of differentially expressed genes that are potentially relevant for distinguishing the sample classes. In this paper, information gain and chaotic genetic algorithm are proposed for the selection of relevant genes, and a K-nearest neighbor with the leave-one-out crossvalidation method serves as a classifier. The chaotic genetic algorithm is modified by using the chaotic mutation operator to increase the population diversity. The enhanced population diversity expands the GA's search ability. The proposed approach is tested on 10 microarray data sets from the literature. The experimental results show that the proposed method not only effectively reduced the number of gene expression levels, but also achieved lower classification error rates than other methods.	[Li, Jung-Chike; Yang, Cheng-Hong] Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, Kaohsiung 807, Taiwan; [Chuang, Li-Yeh] I Shou Univ, Inst Biotechnol & Chem Engn, Kaohsiung, Taiwan; [Yang, Cheng-San] Chiayi Christian Hosp, Dept Plast Surg, Chiayi, Taiwan; [Yang, Cheng-San] Natl Cheng Kung Univ, Inst Biomed Engn, Tainan 70101, Taiwan	Yang, CH (reprint author), Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, 415 Chien Kung Rd, Kaohsiung 807, Taiwan.	chyang@cc.kuas.edu.tw	Chuang, Li-Yeh/E-5005-2011		National Science Council in Taiwan [NSC96-2622-E-151-019-CC3, NSC96-2622-E214-004-CC3, NSC95-2221-E-151-004-MY3, NSC95-2221-E-214-087, NSC95-2622-E-214-004, NSC94-2622E-151-025-CC3, NSC94-2622-E-151-025-CC3]	This work is partly supported by the National Science Council in Taiwan under grants NSC96-2622-E-151-019-CC3, NSC96-2622-E214-004-CC3, NSC95-2221-E-151-004-MY3, NSC95-2221-E-214-087, NSC95-2622-E-214-004, NSC94-2622E-151-025-CC3, and NSC94-2622-E-151-025-CC3.	ALATAS B, 2007, CHAOS SOLIT IN PRESS; Statnikov A, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-319; Coelho LDS, 2008, EXPERT SYST APPL, V34, P1905, DOI 10.1016/j.eswa.2007.02.002; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davis L, 1991, HDB GENETIC ALGORITH; Deep K, 2007, APPL MATH COMPUT, V193, P211, DOI 10.1016/j.amc.2007.03.046; Diaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3; Fallahi K, 2008, COMMUN NONLINEAR SCI, V13, P763, DOI 10.1016/j.cnsns.2006.07.006; Gupta S, 2007, MECH MACH THEORY, V42, P1418, DOI 10.1016/j.mechmachtheory.2006.10.002; Hastie T, 2001, ELEMENTS STAT LEARNI; Herrera F, 2000, APPL INTELL, V13, P187, DOI 10.1023/A:1026531008287; Holland J. H., 1992, ADAPTATION NATURAL A; Huang HL, 2007, BIOSYSTEMS, V90, P78, DOI 10.1016/j.biosystems.2006.07.002; KODAZ H, 2009, MED APPL INFORM GAIN; Liu SY, 2008, J SOUND VIB, V310, P855, DOI 10.1016/j.jsv.2007.08.006; Liu X., 2005, BMC BIOINFORMATICS, V6, P76; Martin-Valdivia MT, 2008, INFORM PROCESS MANAG, V44, P1146, DOI 10.1016/j.ipm.2007.09.014; MUKRAS R, 2007, P IJCAI; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; PEASE A, P NATL ACAD SCI US, V96, P5022; Shadrokh S, 2007, EUR J OPER RES, V181, P86, DOI 10.1016/j.ejor.2006.03.056; Snyder LV, 2006, EUR J OPER RES, V174, P38, DOI 10.1016/j.ejor.2004.09.057; Srinivasa KG, 2007, INFORM SCIENCES, V177, P4295, DOI 10.1016/j.ins.2007.05.008; Tahir MA, 2007, PATTERN RECOGN LETT, V28, P438, DOI 10.1016/j.patrec.2006.08.016; TAHIR MA, 2005, EURASIP J APPL SIG P, V14, P2241; Tan SB, 2006, EXPERT SYST APPL, V30, P290, DOI 10.1016/j.eswa.2005.07.019; VERRON S, 2009, J PROCESS CONTROL; Wang XY, 2007, PATTERN RECOGN LETT, V28, P459, DOI 10.1016/j.patrec.2006.09.003; Yang DX, 2007, CHAOS SOLITON FRACT, V34, P1366, DOI 10.1016/j.chaos.2006.04.057	29	5	5	MARY ANN LIEBERT INC	NEW ROCHELLE	140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA	1536-2310		OMICS	OMICS	OCT	2009	13	5					407	420		10.1089/omi.2009.0007		14	Biotechnology & Applied Microbiology; Genetics & Heredity	Biotechnology & Applied Microbiology; Genetics & Heredity	500TO	WOS:000270328100005	
J	Dalton, L; Ballarin, V; Brun, M				Dalton, Lori; Ballarin, Virginia; Brun, Marcel			Clustering Algorithms: On Learning, Validation, Performance, and Applications to Genomics	CURRENT GENOMICS			English	Article						Clustering; genomics; profiling; microarray; validation index	GENE-EXPRESSION DATA; SELF-ORGANIZING MAPS; MOLECULAR CLASSIFICATION; PATTERNS; DISCOVERY; LYMPHOMA; MATRIX	The development of microarray technology has enabled scientists to measure the expression of thousands of genes simultaneously, resulting in a surge of interest in several disciplines throughout biology and medicine. While data clustering has been used for decades in image processing and pattern recognition, in recent years it has joined this wave of activity as a popular technique to analyze microarrays. To illustrate its application to genomics, clustering applied to genes from a set of microarray data groups together those genes whose expression levels exhibit similar behavior throughout the samples, and when applied to samples it offers the potential to discriminate pathologies based on their differential patterns of gene expression. Although clustering has now been used for many years in the context of gene expression microarrays, it has remained highly problematic. The choice of a clustering algorithm and validation index is not a trivial one, more so when applying them to high throughput biological or medical data. Factors to consider when choosing an algorithm include the nature of the application, the characteristics of the objects to be analyzed, the expected number and shape of the clusters, and the complexity of the problem versus computational power available. In some cases a very simple algorithm may be appropriate to tackle a problem, but many situations may require a more complex and powerful algorithm better suited for the job at hand. In this paper, we will cover the theoretical aspects of clustering, including error and learning, followed by an overview of popular clustering algorithms and classical validation indices. We also discuss the relative performance of these algorithms and indices and conclude with examples of the application of clustering to computational biology.	[Dalton, Lori] Texas A&M Univ, Dept Elect & Comp Engn, College Stn, TX 77843 USA; [Ballarin, Virginia; Brun, Marcel] Univ Nacl Mar del Plata, Fac Ingn, Mar Del Plata, Argentina	Dalton, L (reprint author), Texas A&M Univ, Dept Elect & Comp Engn, College Stn, TX 77843 USA.	ldalton@tamu.edu	Dalton, Lori/G-7254-2012		Agencia Nacional de Promocion Cientifica y Tecnologica [PICT2006-02313]	We would like to acknowledge the Agencia Nacional de Promocion Cientifica y Tecnologica (PICT2006-02313) for supporting part of the work behind this paper. We would also thank the reviewers for their helpful comments.	Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; ANDENBERG MR, 1973, CLUSTER ANAL APPL; Azuaje F, 2002, BIOINFORMATICS, V18, P319, DOI 10.1093/bioinformatics/18.2.319; AZUAJE F, 2002, PRACTICAL APPROACH M, P230; Bach FR, 2004, ADV NEUR IN, V16, P305; Ben-Dor A, 1999, J COMPUT BIOL, V6, P281, DOI 10.1089/106652799318274; Bittner M, 2000, NATURE, V406, P536, DOI 10.1038/35020115; Bolshakova N, 2003, SIGNAL PROCESS, V83, P825, DOI 10.1016/S0165-1684(02)00475-9; Bottou Lon, 1995, ADV NEURAL INFORMATI, V7, P585; Brazma A, 2000, FEBS LETT, V480, P17, DOI 10.1016/S0014-5793(00)01772-5; Brun M, 2007, PATTERN RECOGN, V40, P807, DOI 10.1016/j.patcog.2006.06.026; BRUN M, 2005, P SOC PHOTO-OPT INS, V5916, P283; BRUN MCD, 2005, GENOMIC SIGNAL PROCE, P129; Brunet JP, 2004, P NATL ACAD SCI USA, V101, P4164, DOI 10.1073/pnas.0308531101; Bullinger L, 2004, NEW ENGL J MED, V350, P1605, DOI 10.1056/NEJMoa031046; Chipman H, 2003, STAT ANAL GENE EXPRE, P159; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dembele D, 2003, BIOINFORMATICS, V19, P973, DOI 10.1093/bioinformatics/btg119; Devroye L, 1996, PROBABILISTIC THEORY; Dougherty ER, 2004, PATTERN RECOGN, V37, P917, DOI 10.1016/j.patcog.2003.10.003; Dougherty ER, 2002, J COMPUT BIOL, V9, P105, DOI 10.1089/10665270252833217; Duda R., 2000, PATTERN CLASSIFICATI; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; FISHER L, 1971, BIOMETRIKA, V58, P91, DOI 10.2307/2334320; Fraley C, 2002, J AM STAT ASSOC, V97, P611, DOI 10.1198/016214502760047131; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gose E, 1996, PATTERN RECOGNITION; Guenter S., 2001, P 3 IAPR TC15 WORKSH, P229; Halkidi M, 2001, J INTELL INF SYST, V17, P107, DOI 10.1023/A:1012801612483; Hua JP, 2007, BIOINFORMATICS, V23, P57, DOI 10.1093/bioinformatics/btl536; Jain A., 2004, P 17 INT C PATT REC, V1, P260; Jain A., 1988, ALGORITHMS CLUSTERIN; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Johnson CD, 2003, PHYSIOL GENOMICS, V13, P263, DOI 10.1152/physiolgenomics.00006.2003; Kalton A., 2001, P 7 ACM SIGKDD INT C, P299, DOI 10.1145/502512.502555; Kamishima T, 2003, MACH LEARN, V53, P199, DOI 10.1023/A:1026351106797; Kerr MK, 2001, P NATL ACAD SCI USA, V98, P8961, DOI 10.1073/pnas.161273698; Lubovac Z., 2001, P MATH COMP BIOL CHE, P149; Morrison C, 2004, AM J PATHOL, V165, P565, DOI 10.1016/S0002-9440(10)63321-4; Ramoni MF, 2002, P NATL ACAD SCI USA, V99, P9121, DOI 10.1073/pnas.132656399; ROSALES R, 2004, P 21 INT C MACH LEAR; Roth V, 2002, P INT C COMP STAT, P123; Roth V, 2002, LECT NOTES COMPUT SC, V2415, P607; ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7; Schliep A, 2003, BIOINFORMATICS, V19, P255; Sharan R, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P307; Somogyi R, 1997, NONLINEAR ANAL-THEOR, V30, P1815, DOI 10.1016/S0362-546X(97)00217-4; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Tavazoie S, 1999, NAT GENET, V22, P281; Theodoridis S., 1999, PATTERN RECOGNITION; Toronen P, 1999, FEBS LETT, V451, P142, DOI 10.1016/S0014-5793(99)00524-4; VANNESS JW, 1973, BIOMETRIKA, V60, P422, DOI 10.1093/biomet/60.2.422; Wang JB, 2002, BMC BIOINFORMATICS, V3, DOI 10.1186/1471-2105-3-36; Xing E. P., 2002, ADV NEURAL INFORMATI, V15, P505; Yeung KY, 2001, BIOINFORMATICS, V17, P977, DOI 10.1093/bioinformatics/17.10.977; Yeung KY, 2001, BIOINFORMATICS, V17, P309, DOI 10.1093/bioinformatics/17.4.309; ZHAO H, 2006, PLOS MED, V3, P13	57	3	3	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y26, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	1389-2029		CURR GENOMICS	Curr. Genomics	SEP	2009	10	6					430	445				16	Biochemistry & Molecular Biology; Genetics & Heredity	Biochemistry & Molecular Biology; Genetics & Heredity	487AB	WOS:000269241500007	
J	Chen, ZS; Ji, CY				Chen, Zesheng; Ji, Chuanyi			An Information-Theoretic View of Network-Aware Malware Attacks	IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY			English	Article						Attack models; network security; performance metrics	WORMS	This work provides an information-theoretic view to better understand the relationships between aggregated vulnerability information viewed by attackers and a class of randomized epidemic scanning algorithms. In particular, this work investigates three aspects: 1) a network vulnerability as the nonuniform vulnerable-host distribution, 2) threats, i.e., intelligent malwares that exploit such a vulnerability, and 3) defense, i.e., challenges for fighting the threats. We first study five large data sets and observe consistent clustered vulnerable-host distributions. We then present a new metric, referred to as the nonuniformity factor, that quantifies the unevenness of a vulnerable-host distribution. This metric is essentially the Renyi information entropy that unifies the nonuniformity of a vulnerable-host distribution with different malware-scanning methods. Next, we draw a relationship between Renyi entropies and randomized epidemic scanning algorithms. We find that the infection rates of malware-scanning methods are characterized by the Renyi entropies that relate to the information bits in a nonunform vulnerable-host distribution extracted by a randomized scanning algorithm. Meanwhile, we show that a representative network-aware malware can increase the spreading speed by exactly or nearly a nonuniformity factor when compared to a random-scanning malware at an early stage of malware propagation. This quantifies that how much more rapidly the Internet can be infected at the early stage when a malware exploits an uneven vulnerable-host distribution as a network-wide vulnerability. Furthermore, we analyze the effectiveness of defense strategies on the spread of network-aware malwares. Our results demonstrate that counteracting network-aware malwares is a significant challenge for the strategies that include host-based defenses and IPv6.	[Chen, Zesheng] Florida Int Univ, Dept Elect & Comp Engn, Miami, FL 33174 USA; [Ji, Chuanyi] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA	Chen, ZS (reprint author), Florida Int Univ, Dept Elect & Comp Engn, Miami, FL 33174 USA.	zchen@fiu.edu; jic@ece.gatech.edu			NSF [ECS 0300605]	This work was supported in part by NSF ECS 0300605.	Barford P., 2006, P PASS ACT MEAS C PA; BELLOVIN SM, 2006, LOGIN USENIX MAGAZIN, V31, P70; BRUMLEY D, 2006, ACM S INFORMATION CO; Cachin C., 1997, THESIS SWISS FEDERAL; Chen L, 2007, LECT NOTES OPER RES, V7, P5; CHEN Z, 2008, ARXIV08050802V2; Chen Z., 2003, P IEEE INFOCOM, P1890; Chen Z., 2007, INT J SECURITY NETWO, V2, P71, DOI 10.1504/IJSN.2007.012826; CHEN Z, 2007, P INFOCOM 07 ANCH AK; CHEN Z, 2008, P INFOCOM 08 MIN C P; Cheng MF, 2005, BMC INFECT DIS, V5, DOI 10.1186/1471-2334-5-22; Cover T. M., 1991, ELEMENTS INFORM THEO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FENG H, 2005, P INFOCOM05 MIAM FL, V4, P2405; Gu G., 2007, P 3 INT C SEC PRIV C; GU GF, 2004, P 20 ANN COMP SEC AP; KOHLER E, 2002, ACM SIGCOMM INT MEAS; Moore D, 2003, IEEE SECUR PRIV, V4; MOORE D, 2002, ACM SIGCOMM INT MEAS; PRYADKIN Y, 2004, ISIT2004598 USC INF; Rajab M. A., 2005, Proceedings of the 14th USENIX Security Symposium; Renyi A., 1976, SELECTED PAPERS, V2, P526; Renyi A., 1970, PROBABILITY THEORY; Ross S., 2002, SIMULATION; Shakkottai S, 2007, IEEE J SEL AREA COMM, V25, P1745, DOI 10.1109/JSAC.2007.071212; Shannon C, 2004, IEEE SECUR PRIV, V2, P46, DOI 10.1109/MSP.2004.59; Staniford S., 2002, P 11 USENIX SEC S SE; TWYCROSS J, 2003, P 12 USENIX SEC S AU, P285; VENKATARAMAN S, 2007, P 16 USENIX SEC S SE; Vojnovic M, 2008, IEEE ACM T NETWORK, V16, P1066, DOI 10.1109/TNET.2007.909678; VOJNOVIC M, 2008, P INFOCOM 08 PHOEN A; YEGNESWARAN V, 2004, P S REC ADV INTR DET; ZOU CC, 2003, 10 ACM C COMP COMM S; Zou CC, 2006, SIMUL-T SOC MOD SIM, V82, P75, DOI 10.1177/0037549706065344; ZOU CC, 2006, ELSEVIER J PERFORMAN, V63, P700; *CERT COORD CTR, 2008, IN200109 CERT COORD; *WIK, 2008, SELF INF; *WIK, 2008, AG COMP WORM; *WIK, 2008, SAM XSS; 2008, ANALYSIS BLASTER WOR; 2008, INTERNET PROTOCOL V4	41	3	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1556-6013		IEEE T INF FOREN SEC	IEEE Trans. Inf. Forensic Secur.	SEP	2009	4	3					530	541		10.1109/TIFS.2009.2025847		12	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	485WQ	WOS:000269155900022	
J	Babu, VS; Viswanath, P				Babu, V. Suresh; Viswanath, P.			Rough-fuzzy weighted k-nearest leader classifier for large data sets	PATTERN RECOGNITION			English	Article						k-NNC; Rough-fuzzy sets; Leaders-subleaders; Bayes classifier and RF-wk-NLC	LEARNING ALGORITHMS; NEIGHBOR RULE; REDUCTION; CATEGORIZATION; SELECTION	A leaders set which is derived using the leaders clustering method can be used in place of a large training set to reduce the computational burden of a classifier. Recently, a fast and efficient leader-based classifier called weighted k-nearest leader-based classifier is shown by us to be an efficient and faster classifier. But, there exist some uncertainty while calculating the relative importance (weight) of the prototypes. This paper proposes a generalization over the earlier proposed k-nearest leader-based classifier where a novel soft computing approach is used to resolve the uncertainty. Combined principles of rough set theory and fuzzy set theory are used to analyze the proposed method. The proposed method called rough-fuzzy weighted k-nearest leader classifier (RF-wk-NLC) uses a two level hierarchy of prototypes along with their relative importance. RF-wk-NLC is shown by using some standard data sets to have improved performance and is compared with the earlier related methods. (C)2008 Elsevier Ltd. All rights reserved.	[Babu, V. Suresh] Indian Inst Technol, Dept Comp Sci & Engn, Gauhati 781039, India; [Viswanath, P.] Rajeev Gandhi Mem Coll Engn & Technol, Dept Comp Sci & Engn, Nandyal 518501, Andhra Pradesh, India	Babu, VS (reprint author), Indian Inst Technol, Dept Comp Sci & Engn, Gauhati 781039, India.	vsbabu@iitg.ernet.in; viswanath.pulabaigari@gmail.com					Aha DW, 1997, ARTIF INTELL REV, V11, P7, DOI 10.1023/A:1006538427943; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Alpaydin E, 1997, ARTIF INTELL REV, V11, P115, DOI 10.1023/A:1006563312922; Angiulli F, 2007, IEEE T KNOWL DATA EN, V19, P1450, DOI 10.1109/TKDE.2007.190645; Asharaf S, 2004, FUZZY SET SYST, V148, P119, DOI 10.1016/j.fss.2004.03.009; Asharaf S, 2003, PATTERN RECOGN, V36, P3015, DOI 10.1016/S0031-3203(03)00081-5; BABU VS, 2007, LECT NOTES COMPUTER, P17; Barandela R, 2005, INT J PATTERN RECOGN, V19, P787, DOI 10.1142/S0218001405004332; Bezdek JC, 1998, IEEE T SYST MAN CY C, V28, P67, DOI 10.1109/5326.661091; Bian H., 2003, 22 INT C N AM FUZZ I, P500, DOI 10.1109/NAFIPS.2003.1226836; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; CHANAS S, 1992, FUZZY SET SYST, V47, P391, DOI 10.1016/0165-0114(92)90305-N; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DEVI VS, 2000, THESIS DEP ELECT ENG; DUBOIS D, 1990, INT J GEN SYST, V17, P191, DOI 10.1080/03081079008935107; Duda R.O., 2000, PATTERN CLASSIFICATI; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; JAIN AK, 1987, IEEE T PATTERN ANAL, V9, P628; Jensen R, 2004, FUZZY SET SYST, V141, P469, DOI 10.1016/S0165-0114(03)00021-6; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Kohonen T, 1995, SELF ORGANIZING MAPS; Mollineda RA, 2002, PATTERN RECOGN, V35, P2771, DOI 10.1016/S0031-3203(01)00208-4; NANDA S, 1992, FUZZY SET SYST, V45, P157, DOI 10.1016/0165-0114(92)90114-J; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Sanchez JS, 2006, NEUROCOMPUTING, V69, P922, DOI 10.1016/j.neucom.2005.10.001; Sanchez JS, 2004, PATTERN RECOGN, V37, P1561, DOI 10.1016/j.patcog.2003.12.012; Sarkar M, 2007, FUZZY SET SYST, V158, P2134, DOI 10.1016/j.fss.2007.04.023; Shen Q, 2002, PATTERN RECOGN, V35, P2425, DOI 10.1016/S0031-3203(01)00229-1; Spath H, 1980, CLUSTER ANAL ALGORIT; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; Vijaya PA, 2004, PATTERN RECOGN LETT, V25, P505, DOI 10.1016/j.patrec.2003.12.013; WATSON I, KNOWLEDGE ENG REV, V9; Wilfong G., 1992, International Journal of Computational Geometry & Applications, V2, DOI 10.1142/S0218195992000226; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Yao YY, 1998, INFORM SCIENCES, V109, P227, DOI 10.1016/S0020-0255(98)10023-3; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	42	5	5	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	SEP	2009	42	9					1719	1731		10.1016/j.patcog.2008.11.021		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	459GI	WOS:000267089000001	
J	Li, Y; Lu, BL				Li, Yun; Lu, Bao-Liang			Feature selection based on loss-margin of nearest neighbor classification	PATTERN RECOGNITION			English	Article						Feature selection; Loss function; Margin; Energy-based model	SIMILARITY	The problem of selecting a subset of relevant features is classic and found in many branches of science including-examples in pattern recognition. In this paper, we propose a new feature selection criterion based on low-loss nearest neighbor classification and a novel feature selection algorithm that optimizes the margin of nearest neighbor classification through minimizing its loss function. At the same time, theoretical analysis based on energy-based model is presented, and some experiments are also conducted on several benchmark real-world data sets and facial data sets for gender classification to show that the proposed feature selection method outperforms other classic ones. (C) 2008 Elsevier Ltd. All rights reserved.	[Li, Yun] Nanjing Univ Posts & Telecommun, Inst Comp Technol, Nanjing 210003, Peoples R China; [Lu, Bao-Liang] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China	Li, Y (reprint author), Nanjing Univ Posts & Telecommun, Inst Comp Technol, 66 Xinmofan Rd, Nanjing 210003, Peoples R China.	yuncloudlee@gmail.com			National Natural Science Foundation of China [NSFC 60773090]; Shanghai Jiao Tong University; Microsoft Research Asian Joint Laboratory for Intelligent Computing and Intelligent Systems; Natural science fund for colleges and universities in Jiangsu Province [08KJB520007]; Scientific Research Foundation of Nanjing University of Posts and Telecommunications [NY207137]	We gratefully thank OMRON Cooperation for supplying facial images and R.G. Bachral for the code of Simba. This work was done in part while the first author was a Postdoctoral fellow at Department of Computer Science and Engineering, Shanghai Jiao Tong University, P.R. China. This research was partially supported by the National Natural Science Foundation of China via the Grants NSFC 60773090, and Shanghai Jiao Tong University and Microsoft Research Asian Joint Laboratory for Intelligent Computing and Intelligent Systems, Natural science fund for colleges and universities in Jiangsu Province via the Grants 08KJB520007, and Scientific Research Foundation of Nanjing University of Posts and Telecommunications via the Grants NY207137.	Bachrach R.G., 2004, P INT C MACH LEARN B; Chang C.-C., 2002, LIBSVM LIB SUPPORT V; Chopra S, 2005, PROC CVPR IEEE, P539; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAMMER K, 2002, P ADV NEUR INF PROC; Devijver P. A., 1982, PATTERN RECOGNITION; Guyon I., 2006, FEATURE EXTRACTION F; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Kira K., 1992, P 9 INT C MACH LEARN, P249; KOHAVI R, 1997, ARTIF INTELL, V97, P234; Kononenko I, 1994, P EUR C MACH LEARN, P171; LECUN Y, 2005, P INT WORKSH ART INT; LeCun Y., 2006, PREDICTING STRUCTURE; LI Y, 2007, LECT NOTES COMPUTER, V4781, P196; LIAN HC, 2005, LNCS, V3611, P433; Liu H., 1998, FEATURE SELECTION KN; Liu H., 2005, IEEE T KNOWL DATA EN, V17, P494; Merz C. J., 1996, UCI REPOSITORY MACHI; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133; Schapire RE, 1998, ANN STAT, V26, P1651; Sikonja M.R., 1997, P 14 INT C ICML 97, P296; WEINBERGER KQ, 2006, P ADV NEUR INF PROC, V18; Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2; XU LL, 2006, NAT C ART INT AAAI, P536	25	12	14	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	SEP	2009	42	9					1914	1921		10.1016/j.patcog.2008.10.011		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	459GI	WOS:000267089000020	
J	Farcomeni, A				Farcomeni, Alessio			Generalized Augmentation to Control the False Discovery Exceedance in Multiple Testing	SCANDINAVIAN JOURNAL OF STATISTICS			English	Article						dependence; DNA microarrays; false discovery exceedance; false discovery rate; family-wise error rate; multiple testing	PROPORTION; NUMBER; CLASSIFICATION; HYPOTHESES; VARIANCE; HEALTH; RATES	A new multiple testing procedure, the generalized augmentation procedure (GAUGE), is introduced. The procedure is shown to control the false discovery exceedance and to be competitive in terms of power. It is also shown how to apply the idea of GAUGE to achieve control of other error measures. Extensions to dependence are discussed, together with a modification valid under arbitrary dependence. We present an application to an original study on prostate cancer and on a benchmark data set on colon cancer.	Univ Roma La Sapienza, I-00185 Rome, Italy	Farcomeni, A (reprint author), Univ Roma La Sapienza, Piazzale Aldo Moro 5, I-00185 Rome, Italy.	alessio.farcomeni@uniroma1.it					Abramovich F, 2006, ANN STAT, V34, P584, DOI 10.1214/009053606000000074; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Benjamini Y, 2000, J EDUC BEHAV STAT, V25, P60, DOI 10.2307/1165312; Benjamini Y, 2006, BIOMETRIKA, V93, P491, DOI 10.1093/biomet/93.3.491; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; BICKEL DR, 2004, ARXIVQBIO0404032V1 M; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOUKAN P, 1994, LECT NOTES STAT, V85; DUDOIT S, 2004, 166 U CAL DIV BIOST; ESARY JD, 1967, ANN MATH STAT, V38, P1466, DOI 10.1214/aoms/1177698701; Farcomeni A, 2008, STAT METHODS MED RES, V17, P347, DOI 10.1177/0962280206079046; Farcomeni A, 2007, SCAND J STAT, V34, P275, DOI 10.1111/j.1467-9469.2006.00530.x; Finner H, 2002, ANN STAT, V30, P220; Genovese C, 2002, J ROY STAT SOC B, V64, P499, DOI 10.1111/1467-9868.00347; Genovese CR, 2006, J AM STAT ASSOC, V101, P1408, DOI 10.1198/016214506000000339; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guo WG, 2007, STAT APPL GENET MOL, V6; Hochberg Y., 1987, MULTIPLE COMP PROCED; Kerr MK, 2000, J COMPUT BIOL, V7, P819, DOI 10.1089/10665270050514954; KUMAR JD, 1983, ANN STAT, V11, P286; Lehmann EL, 2005, ANN STAT, V33, P1138, DOI 10.1214/009053605000000084; MARSHALL AW, 1967, J AM STAT ASSOC, V62, P30, DOI 10.2307/2282907; Meinshausen N, 2006, ANN STAT, V34, P373, DOI 10.1214/009053605000000741; Ottenbacher KJ, 1998, AM J EPIDEMIOL, V147, P615; Owen AB, 2005, J ROY STAT SOC B, V67, P411, DOI 10.1111/j.1467-9868.2005.00509.x; Pacifico MP, 2004, J AM STAT ASSOC, V99, P1002, DOI 10.1198/0162145000001655; R Development Core Team, 2007, R LANG ENV STAT COMP; Sarkar SK, 2007, ANN STAT, V35, P2405, DOI 10.1214/009053607000000398; Schaffer CM, 1998, J MARKET RES SOC, V40, P155; Schlaeppi M, 1996, BRIT J CLIN PRACT, V50, P14; SMITH RL, 2001, LECT NOTES U N CAROL; Soon SYT, 1996, STAT SINICA, V6, P703; Storey JD, 2002, J ROY STAT SOC B, V64, P479, DOI 10.1111/1467-9868.00346; Valentini A, 2007, DRUG METAB DISPOS, V35, P968, DOI 10.1124/dmd.107.014662; van der Laan M., 2004, STAT APPL GENET MOL, V3; van der Laan M., 2004, STAT APPL GENET MOL, V3; van der Laan MJ, 2005, STAT APPL GENET MO B, V4; Vedantham K, 2001, CAN J PSYCHIAT, V46, P149; Westfall PH, 1993, RESAMPLING BASED MUL	39	1	1	WILEY-BLACKWELL PUBLISHING, INC	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0303-6898		SCAND J STAT	Scand. J. Stat.	SEP	2009	36	3					501	517		10.1111/j.1467-9469.2008.00633.x		17	Statistics & Probability	Mathematics	483SP	WOS:000268988600008	
J	Heimann, T; van Ginneken, B; Styner, MA; Arzhaeva, Y; Aurich, V; Bauer, C; Beck, A; Becker, C; Beichel, R; Bekes, G; Bello, F; Binnig, G; Bischof, H; Bornik, A; Cashman, PMM; Chi, Y; Cordova, A; Dawant, BM; Fidrich, M; Furst, JD; Furukawa, D; Grenacher, L; Hornegger, J; Kainmuller, D; Kitney, RI; Kobatake, H; Lamecker, H; Lange, T; Lee, J; Lennon, B; Li, R; Li, S; Meinzer, HP; Nemeth, G; Raicu, DS; Rau, AM; van Rikxoort, EM; Rousson, M; Rusko, L; Saddi, KA; Schmidt, G; Seghers, D; Shimizu, A; Slagmolen, P; Sorantin, E; Soza, G; Susomboon, R; Waite, JM; Wimmer, A; Wolf, I				Heimann, Tobias; van Ginneken, Bram; Styner, Martin A.; Arzhaeva, Yulia; Aurich, Volker; Bauer, Christian; Beck, Andreas; Becker, Christoph; Beichel, Reinhard; Bekes, Gyoergy; Bello, Fernando; Binnig, Gerd; Bischof, Horst; Bornik, Alexander; Cashman, Peter M. M.; Chi, Ying; Cordova, Andres; Dawant, Benoit M.; Fidrich, Marta; Furst, Jacob D.; Furukawa, Daisuke; Grenacher, Lars; Hornegger, Joachim; Kainmueller, Dagmar; Kitney, Richard I.; Kobatake, Hidefumi; Lamecker, Hans; Lange, Thomas; Lee, Jeongjin; Lennon, Brian; Li, Rui; Li, Senhu; Meinzer, Hans-Peter; Nemeth, Gabor; Raicu, Daniela S.; Rau, Anne-Mareike; van Rikxoort, Eva M.; Rousson, Mikael; Rusko, Laszlo; Saddi, Kinda A.; Schmidt, Guenter; Seghers, Dieter; Shimizu, Akinobu; Slagmolen, Pieter; Sorantin, Erich; Soza, Grzegorz; Susomboon, Ruchaneewan; Waite, Jonathan M.; Wimmer, Andreas; Wolf, Ivo			Comparison and Evaluation of Methods for Liver Segmentation From CT Datasets	IEEE TRANSACTIONS ON MEDICAL IMAGING			English	Article						Evaluation; liver; segmentation	FREE-FORM DEFORMATIONS; IMAGE SEGMENTATION; DIAGNOSTIC SYSTEM; SHAPE MODELS; REGISTRATION; ALGORITHM; EFFICIENT; CLASSIFICATION; CLASSIFIERS; VALIDATION	This paper presents a comparison study between 10 automatic and six interactive methods for liver segmentation from contrast-enhanced CT images. It is based on results from the "MICCAI 2007 Grand Challenge" workshop, where 16 teams evaluated their algorithms on a common database. A collection of 20 clinical images with reference segmentations was provided to train and tune algorithms in advance. Participants were also allowed to use additional proprietary training data for that purpose. All teams then had to apply their methods to 10 test datasets and submit the obtained results. Employed algorithms include statistical shape models, atlas registration, level-sets, graph-cuts and rule-based systems. All results were compared to reference segmentations five error measures that highlight different aspects of segmentation accuracy. All measures were combined according to a specific scoring system relating the obtained values to human expert variability. In general, interactive methods reached higher average scores than automatic approaches and featured a better consistency of segmentation quality. However, the best automatic methods (mainly based on statistical shape models with some additional free deformation) could compete well on the majority of test images. The study provides an insight in performance of different segmentation approaches under real-world conditions and highlights achievements and limitations of current image analysis techniques.	[Heimann, Tobias; Meinzer, Hans-Peter; Rau, Anne-Mareike; Wolf, Ivo] German Canc Res Ctr, Div Med & Biol Informat, D-69121 Heidelberg, Germany; [van Ginneken, Bram; Arzhaeva, Yulia; van Rikxoort, Eva M.] Univ Med Ctr Utrecht, Image Sci Inst, NL-3584 CX Utrecht, Netherlands; [Styner, Martin A.] Univ N Carolina, Dept Psychiat & Comp Sci, Chapel Hill, NC 27514 USA; [Aurich, Volker; Beck, Andreas] Univ Dusseldorf, Inst Comp Sci, D-40225 Dusseldorf, Germany; [Bauer, Christian; Bischof, Horst; Bornik, Alexander] Graz Univ Technol, Inst Comp Graph & Vis, A-8010 Graz, Austria; [Beichel, Reinhard] Univ Iowa, Dept Elect & Comp Engn, Iowa City, IA 52242 USA; [Beichel, Reinhard] Univ Iowa, Dept Internal Med, Iowa City, IA 52242 USA; [Sorantin, Erich] Med Univ Graz, Dept Radiol, A-8036 Graz, Austria; [Becker, Christoph] Univ Hosp Munich, Dept Clin Radiol, D-81377 Munich, Germany; [Cordova, Andres] Clin Alemana Santiago, Dept Oncol, Santiago, Chile; [Grenacher, Lars] Univ Heidelberg Hosp, Dept Diagnost Radiol, D-69118 Heidelberg, Germany; [Bekes, Gyoergy; Fidrich, Marta; Nemeth, Gabor; Rusko, Laszlo] GE Hungary ZRT, Healthcare Div, H-6720 Szeged, Hungary; [Bello, Fernando] Univ London Imperial Coll Sci Technol & Med, Dept Biosurg & Surg Technol, London SW7 2AZ, England; [Cashman, Peter M. M.; Chi, Ying; Kitney, Richard I.] Univ London Imperial Coll Sci Technol & Med, Dept Bioengn, London SW7 2AZ, England; [Binnig, Gerd; Schmidt, Guenter] Definiens AG Res, D-80339 Munich, Germany; [Dawant, Benoit M.; Li, Rui] Vanderbilt Univ, Dept Elect Engn & Comp Sci, Nashville, TN 37235 USA; [Lennon, Brian; Li, Senhu; Waite, Jonathan M.] Pathfinder Therapeut Inc, Nashville, TN 37203 USA; [Furst, Jacob D.; Raicu, Daniela S.; Susomboon, Ruchaneewan] Depaul Univ, Coll Comp & Digital Media, Sch Comp, Intelligent Multimedia Proc Lab, Chicago, IL 60604 USA; [Furukawa, Daisuke; Kobatake, Hidefumi; Shimizu, Akinobu] Tokyo Univ Agr & Technol, Fuchu, Tokyo 183, Japan; [Hornegger, Joachim; Wimmer, Andreas] Univ Erlangen Nurnberg, Dept Comp Sci, Chair Pattern Recognit, D-91058 Erlangen, Germany; [Soza, Grzegorz] Siemens AG, Healthcare Sector, Computed Tomog, Forchheim, Germany; [Kainmueller, Dagmar; Lamecker, Hans] Zuse Inst Berlin, D-14195 Berlin, Germany; [Lange, Thomas] Charite Univ Med Berlin, Dept Surg & Surg Oncol, D-10117 Berlin, Germany; [Lee, Jeongjin] Catholic Univ Korea, Dept Digital Media, Seoul, South Korea; [Rousson, Mikael; Saddi, Kinda A.] Siemens Corp Res, Dept Imaging & Visualizat, Princeton, NJ 08540 USA; [Seghers, Dieter; Slagmolen, Pieter] Univ Hosp Gasthuisberg, Fac Med, Med Image Comp ESAT PSI, B-3000 Louvain, Belgium; [Seghers, Dieter; Slagmolen, Pieter] Univ Hosp Gasthuisberg, Fac Engn, B-3000 Louvain, Belgium	Heimann, T (reprint author), German Canc Res Ctr, Div Med & Biol Informat, D-69121 Heidelberg, Germany.	t.heimann@dkfz.de; bram@isi.uu.nl; martin_styner@ieee.org	van Ginneken, Bram/A-3728-2012; SHIMIZU, Akinobu/G-1085-2013	van Ginneken, Bram/0000-0003-2028-8972; 	Siemens AG, Healthcare Sector (Forchheim, Germany)	This work was supported by Siemens AG, Healthcare Sector (Forchheim, Germany).	Alkoot FM, 2002, PATTERN ANAL APPL, V5, P326; Armato SG, 2004, RADIOLOGY, V232, P739, DOI 10.1148/radiol.2323032035; Armato SG, 1998, P SOC PHOTO-OPT INS, V3338, P916, DOI 10.1117/12.310968; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Beck A., 2007, P MICCAI WORKSH 3 D, P225; Beichel R., 2007, P MICCAI WORKSH 3 D, P235; BELLMAN R, 1966, SCIENCE, V153, P34, DOI 10.1126/science.153.3731.34; BORNIK A, 2006, P IEEE S 3D US INT, P29; Bornik A, 2006, P ACM S VIRT REAL SO, P197, DOI 10.1145/1180495.1180536; Bouix S, 2007, NEUROIMAGE, V36, P1207, DOI 10.1016/j.neuroimage.2007.04.031; Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5; Carr J.C., 2001, P ACM SIGGRAPH 2001, P67, DOI DOI 10.1145/383259.383266; Chaney E, 2005, MED PHYS, V32, P3507, DOI 10.1118/1.2131093; Chefd'hotel C., 2007, P MICCAI WORKSH 3 D, P207; Chen EL, 1998, IEEE T BIO-MED ENG, V45, P783; Chi Y., 2007, P MICCAI WORKSH 3 D, P167; Christensen GE, 1996, IEEE T IMAGE PROCESS, V5, P1435, DOI 10.1109/83.536892; CLARKE LP, 1995, MAGN RESON IMAGING, V13, P343, DOI 10.1016/0730-725X(94)00124-L; COOTES T, 1994, IMAGE VISION COMPUT, V6, P355; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dawant B. M., 2007, P MICCAI WORKSH 3 D, P215; Duda R.O., 2000, PATTERN CLASSIFICATI; Floater MS, 2005, MATH VISUAL, P157, DOI 10.1007/3-540-26808-1_9; Fogel L. J., 1966, ARTIFICIAL INTELLIGE; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Furukawa D., 2007, P MICCAI WORKSH 3 D, P117; Gerig G., 2001, LNCS, V2208, P516; Gletsos M, 2003, IEEE T INF TECHNOL B, V7, P153, DOI 10.1109/TITB.2003.813793; Haralick RM, 1973, IEEE T SYST MAN CYB, VSMC-3; HEIMANN T, 2007, P MICCAI WORKSH 3 D; Heimann T, 2006, LECT NOTES COMPUT SC, V4191, P41; Heimann T, 2007, LECT NOTES COMPUT SC, V4584, P1; Heimann T., 2007, P MICCAI WORKSH 3 D, P161; Heimann T., 2004, INT ARCH PHOTOGRAMME, VXXXV, P317; Heimann T, 2007, METHOD INFORM MED, V46, P275, DOI 10.1160/ME9043; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Jaccard P, 1901, B SOC VAUD SCI NAT, V37, P547; Kainmuller D., 2007, P MICCAI WORKSH 3D S, P109; Lamecker H., 2004, SEGMENTATION LIVER U; Lee J., 2007, P MICCAI WORKSH 3 D, P189; Li K, 2005, LECT NOTES COMPUT SC, V3565, P406; MacQueen JB, 1967, P 5 BERK S MATH STAT, P281; Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; Mattes D, 2003, IEEE T MED IMAGING, V22, P120, DOI 10.1109/TMI.2003.809072; McLachlan G., 2008, EM ALGORITHM EXTENSI; Meinzer HP, 2002, COMPUT GRAPH-UK, V26, P569, DOI 10.1016/S0097-8493(02)00102-4; NIESSEN WJ, 2000, PERFORMANCE CHARACTE, P275; Osher S, 2003, GEOMETRIC LEVEL SET; Pan S., 2001, P SOC PHOTO-OPT INS, V4332, P128, DOI 10.1117/12.431019; Park H, 2003, IEEE T MED IMAGING, V22, P483, DOI 10.1109/TMI.2003.809139; POHLE R, 2001, P SPIE MED IMAGING, V4322, P1337, DOI 10.1117/12.431013; PRICE K, 1986, COMPUT VISION GRAPH, V36, P387, DOI 10.1016/0734-189X(86)90083-6; Radtke A, 2007, WORLD J SURG, V31, P175, DOI 10.1007/s00268-005-0718-1; Rohlfing T., 2005, HDB MED IMAGE ANAL, V3, P435; Rousson M, 2005, LECT NOTES COMPUT SC, V3750, P757; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; Rusko L., 2007, P MICCAI WORKSH 3 D, P143; Schmidt G., 2007, P MICCAI WORKSH 3 D, P125; Schwefel H.-P., 1995, EVOLUTION OPTIMUM SE; Seghers D., 2007, P MICCAI WORKSH 3 D, P135; Sethian JA, 1999, LEVEL SET METHODS FA; Shimizu Akinobu, 2007, International Journal of Computer Assisted Radiology and Surgery, V2, DOI 10.1007/s11548-007-0135-z; Shimizu A, 2004, P COMP ASS RAD SURG, P1361; Shimizu A, 2006, INT J CARS, V1, P525; Slagmolen P, 2007, P MICCAI WORKSH 3 D, P197; Soler L, 2001, Comput Aided Surg, V6, P131, DOI 10.3109/10929080109145999; Sonka M., 2007, IMAGE PROCESSING ANA; Styner MA, 2002, PROC SPIE, V4684, P278, DOI 10.1117/12.467167; Susomboon R., 2007, P MICCAI WORKSH 3 D, P151; Tanimoto T, 1958, ELEMENTARY MATH THEO; Tsai A, 2003, IEEE T MED IMAGING, V22, P137, DOI 10.1109/TMI.2002.808355; van Rikxoort E., 2007, P MICCAI WORKSH 3 D, P101; Warfield SK, 2004, IEEE T MED IMAGING, V23, P903, DOI 10.1109/TMI.2004.828354; Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190; Whitaker R.T., 2001, P INT C IM PROC, V3, P142; Wimmer A., 2007, P MICCAI WORKSH 3 D, P179; Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015; Zhang YJ, 1996, PATTERN RECOGN, V29, P1335, DOI 10.1016/0031-3203(95)00169-7	79	94	99	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0278-0062		IEEE T MED IMAGING	IEEE Trans. Med. Imaging	AUG	2009	28	8					1251	1265		10.1109/TMI.2009.2013851		15	Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging	Computer Science; Engineering; Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging	477NJ	WOS:000268525500012	
J	Lee, H; Hong, S; Nizami, IF; Kim, E				Lee, Heesung; Hong, Sungjun; Nizami, Imran Fareed; Kim, Euntai			A Noise Robust Gait Representation: Motion Energy Image	INTERNATIONAL JOURNAL OF CONTROL AUTOMATION AND SYSTEMS			English	Article						Biometrics; gait recognition; MEI; NLPR database; noise	RECOGNITION; IDENTIFICATION	Gait-based human identification aims to discriminate individuals by the way they walk. A unique advantage of gait as a biometric is that it requires no subject contact and is easily acquired at a distance, which stands in contrast to other biometric techniques involving face, fingerprints, iris, etc. This paper proposes a new gait representation called motion energy image (MEI). Compared with other gait features, MEI is more robust against noise that can be included in binary gait silhouette images due to various factors. The effectiveness of the proposed method for gait recognition is demonstrated using experiments performed on the NLPR database.	[Lee, Heesung; Hong, Sungjun; Kim, Euntai] Yonsei Univ, Sch Elect & Elect Engn, Seoul 120749, South Korea; [Nizami, Imran Fareed] Bahria Univ, Islamabad, Pakistan	Kim, E (reprint author), Yonsei Univ, Sch Elect & Elect Engn, 134 Sinchon Dong, Seoul 120749, South Korea.	4u2u@yonsei.ac.kr; imjune@yonsei.ac.kr; imran2k2@gmail.com; etkim@yonsei.ac.kr			Korea Science and Engineering Foundation (KOSEF) through the Biometrics Engineering Research Center (BERC) at Yonsei University [R11-2002-105-09002-0]	This work was supported by the Korea Science and Engineering Foundation (KOSEF) through the Biometrics Engineering Research Center (BERC) at Yonsei University. Grant Number: R11-2002-105-09002-0 (2009).	Bazin A.I., 2005, P IEE WORKSH APPL CO, P60; BenAbdelkader C., 2001, P INT C AUD VID BAS, P284; Bobick AF, 2001, PROC CVPR IEEE, P423; Collins R. T., 2002, Proceedings of Fifth IEEE International Conference on Automatic Face Gesture Recognition, DOI 10.1109/AFGR.2002.1004181; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ekinci M, 2006, Proceedings of the Seventh International Conference on Automatic Face and Gesture Recognition - Proceedings of the Seventh International Conference, P517; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38; HONG S, 2006, P SICE ICCAS2006, P3937; HORPRASER T, 1999, P IEEE INT C COMP VI; Kale A, 2004, IEEE T IMAGE PROCESS, V13, P1163, DOI 10.1109/TIP.2004.832865; KALE A, 2003, P INT C AUD VID BAS, P706; LAM T, 2006, P INT C BIOM, P612; Lee L., 2002, Proceedings of Fifth IEEE International Conference on Automatic Face Gesture Recognition, DOI 10.1109/AFGR.2002.1004148; Phillips P. J., 2002, Proceedings of Fifth IEEE International Conference on Automatic Face Gesture Recognition, DOI 10.1109/AFGR.2002.1004145; Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505	16	8	8	INST CONTROL ROBOTICS & SYSTEMS, KOREAN INST ELECTRICAL ENGINEERS	BUCHEON	BUCHEON TECHNO PARK 401-1506, 193 YAKDAE-DONG WONMI-GU, BUCHEON, GYEONGGI-DO 420-734, SOUTH KOREA	1598-6446		INT J CONTROL AUTOM	Int. J. Control Autom. Syst.	AUG	2009	7	4					638	643		10.1007/s12555-009-0414-2		6	Automation & Control Systems	Automation & Control Systems	477HF	WOS:000268509200014	
J	Niu, B; Jin, YH; Lu, L; Fen, KY; Gu, L; He, ZS; Lu, WC; Li, YX; Cai, Y				Niu, Bing; Jin, Yuhuan; Lu, Lin; Fen, Kaiyan; Gu, Lei; He, Zhisong; Lu, Wencong; Li, Yixue; Cai, Yudong			Prediction of interaction between small molecule and enzyme using AdaBoost	MOLECULAR DIVERSITY			English	Article						Small molecule-enzyme couple; Chemical functional group; Biochemical and physicochemical properties; AdaBoost; Metabolic pathway	SUPPORT VECTOR MACHINES; MEMBRANE-PROTEIN TYPES; AMINO-ACID-COMPOSITION; FUNCTIONAL DOMAIN COMPOSITION; NEURAL-NETWORK MODEL; BETA-TURN TYPES; SUBCELLULAR LOCATION; STRUCTURAL CLASS; CLASSIFICATION; ALGORITHM	The knowledge of whether one enzyme can interact with a small molecule is essential for understanding the molecular and cellular functions of organisms. In this paper, we introduce a classifier to predict the small molecule- enzyme interaction, i.e., whether they can interact with each other. Small molecules are represented by their chemical functional groups, and enzymes are represented by their biochemical and physicochemical properties, resulting in a total of 160 features. These features are input into the AdaBoost classifier, which is known to have good generalization ability to predict interaction. As a result, the overall prediction accuracy, tested by tenfold cross-validation and independent sets, is 81.76% and 83.35%, respectively, suggesting that this strategy is effective. In this research, we typically choose interactions between small molecules and enzymes involved in metabolism to ultimately improve further understanding of metabolic pathways. An online predictor developed by this research is available at http://chemdata.shu.edu.cn.	[Jin, Yuhuan; Lu, Wencong] Shanghai Univ, Coll Sci, Dept Chem, Shanghai 200444, Peoples R China; [Niu, Bing] Shanghai Univ, Shanghai 200072, Peoples R China; [Lu, Lin] Shanghai Jiao Tong Univ, Dept Biomed Engn, Shanghai 200040, Peoples R China; [Fen, Kaiyan] Univ Manchester, Div Imaging Sci & Biomed Engn, Manchester M13 9PT, Lancs, England; [Gu, Lei; Li, Yixue] Chinese Acad Sci, Shanghai Inst Biol Sci, Key Lab Mol Syst Biol, Bioinformat Ctr, Shanghai 200031, Peoples R China; [He, Zhisong] Zhejiang Univ, Coll Life Sci, Dept Bioinformat, Hangzhou 310058, Zhejiang, Peoples R China; [Li, Yixue] Shanghai Ctr Bioinformat Technol, Shanghai 200235, Peoples R China; [Li, Yixue] Shanghai Jiao Tong Univ, Coll Life Sci & Biotechnol, Shanghai 200030, Peoples R China; [Cai, Yudong] Shanghai Univ, Inst Syst Biol, Shanghai 200244, Peoples R China; [Cai, Yudong] Chinese Acad Sci, Shanghai Inst Biol Sci, CAS MPG Partner Inst Computat Biol, Dept Combinator & Geometry, Shanghai 200031, Peoples R China	Lu, WC (reprint author), Shanghai Univ, Coll Sci, Dept Chem, 99 Shang Da Rd, Shanghai 200444, Peoples R China.	wclu@shu.edu.cn; cyd@picb.ac.cn	Jin, Yuhuan/G-9005-2013		National Natural Science Foundation of China [20503015]; Chinese Academy of Science [KSCX2-YWR-112]; Shanghai Leading Academic Discipline Project [J50101]	This work was supported by National Natural Science Foundation of China (No. 20503015), basic research grant of the Chinese Academy of Science (KSCX2-YWR-112), and the Shanghai Leading Academic Discipline Project (No. J50101).	BENDER ML, 1973, CATALYSIS ENZYME ACT; Bishop C. M., 1995, NEURAL NETWORKS PATT; BROOKSBANK C, 2005, NUCLEIC ACIDS RES, V33, P46; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Bugg T, 1997, INTRO ENZYME COENZYM; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Cai YD, 2003, J THEOR BIOL, V221, P115, DOI 10.1006/jtbi.2003.3179; Cai YD, 2002, PEPTIDES, V23, P205, DOI 10.1016/S0196-9781(01)00597-6; Cai YD, 2001, J BIOMOL STRUCT DYN, V18, P607; Cai YD, 2002, J COMPUT CHEM, V23, P267, DOI 10.1002/jcc.10017; Cai YD, 2006, J THEOR BIOL, V238, P172, DOI 10.1016/j.jtbi.2005.05.034; Cai YD, 2002, COMPUT CHEM, V26, P347, DOI 10.1016/S0097-8485(01)00125-5; Cai YD, 2002, J PEPT SCI, V8, P297, DOI 10.1002/psc.401; Cai YD, 2002, COMPUT CHEM, V26, P179, DOI 10.1016/S0097-8485(01)00106-1; CAI YD, 2007, METABOLIC PATHWAYMOD, P1; Cai YD, 2003, BIOPHYS J, V84, P3257; Cai YD, 2002, J CELL BIOCHEM, V84, P343, DOI 10.1002/jcb.10030; Caspi R, 2006, NUCLEIC ACIDS RES, V34, pD511, DOI 10.1093/nar/gkj128; CHOTHIA C, 1990, ANNU REV BIOCHEM, V59, P1007, DOI 10.1146/annurev.biochem.59.1.1007; Chou KC, 1997, J PROTEIN CHEM, V16, P575, DOI 10.1023/A:1026366706677; Chou KC, 1999, PROTEINS, V34, P137, DOI 10.1002/(SICI)1097-0134(19990101)34:1<137::AID-PROT11>3.0.CO;2-O; Chou K. C., 2006, EXCLI J, V5, P55; Chou KC, 2005, J CHEM INF MODEL, V45, P407, DOI 10.1021/ci049686v; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Creighton T. E., 1993, PROTEINS STRUCTURES; Cristianini N, 2000, INTRO SUPPORT VECTOR; Dubchak I, 1999, PROTEINS, V35, P401, DOI 10.1002/(SICI)1097-0134(19990601)35:4<401::AID-PROT3>3.0.CO;2-K; Fix E., 1951, DISCRIMINATORY ANAL, P261; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y, 2000, ANN STAT, V28, P391; Freund Y, 2004, J MACH LEARN RES, V4, P933, DOI 10.1162/1532443041827916; Freund Y, 2004, ANN STAT, V32, P1698, DOI 10.1214/009053604000000058; Freund Y, 1999, MACH LEARN, V37, P277, DOI 10.1023/A:1007662407062; Frishman D, 1997, PROTEINS, V27, P329, DOI 10.1002/(SICI)1097-0134(199703)27:3<329::AID-PROT1>3.0.CO;2-8; Goto S, 1998, BIOINFORMATICS, V14, P591, DOI 10.1093/bioinformatics/14.7.591; HERMANN D, 2005, BIOORGANIC CHEM CHEM, pCH2; HUBERTY C, 1994, APPL DISCRIMINANT AN; HYONEMYONG E, 1996, ENZYMOLOGY PRIMER RE; Jiang XY, 2008, AMINO ACIDS, V34, P669, DOI 10.1007/s00726-008-0034-9; Jin YH, 2008, PROTEIN PEPTIDE LETT, V15, P286; Johnson R.A., 1982, APPL MULTIVARIATE ST; Kanehisa M, 2006, NUCLEIC ACIDS RES, V34, pD354, DOI 10.1093/nar/gkj102; KOHONEN T, 1988, NEURAL NETWORKS, V1, P3, DOI 10.1016/0893-6080(88)90020-2; Kohonen T, 1997, NEURAL COMPUT, V9, P1321, DOI 10.1162/neco.1997.9.6.1321; Kohonen T, 1998, NEUROCOMPUTING, V21, P19, DOI 10.1016/S0925-2312(98)00031-9; Kuhn M., 2008, NUCLEIC ACIDS RES, V36, P684; Marchand-Geneste N, 2002, J MED CHEM, V45, P399, DOI 10.1021/jm0155244; Mardia K. V., 1979, MULTIVARIATE ANAL, P521; Metzler D.E., 1977, BIOCH CHEM REACTIONS; MICHAEL P, 1997, ORGANIC BIOORGANIC M; Mucchielli-Giorgi MH, 1999, BIOINFORMATICS, V15, P176, DOI 10.1093/bioinformatics/15.2.176; Niu B, 2006, PROTEIN PEPTIDE LETT, V13, P489, DOI 10.2174/092986606776819619; Niu B, 2008, MOL DIVERS, V12, P41, DOI 10.1007/s11030-008-9073-0; Ochs RA, 2007, MED IMAGE ANAL, V11, P315, DOI 10.1016/j.media.2007.03.004; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; SARAH AT, 2001, TRENDS BIOTECHNOL, V19, P482; Schapire RE, 1998, ANN STAT, V26, P1651; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Scholkopf B., 2002, LEARNING KERNELS; Tan C, 2007, ANAL BIOANAL CHEM, V389, P667, DOI 10.1007/s00216-007-1461-2; Tusnady GE, 1998, J MOL BIOL, V283, P489, DOI 10.1006/jmbi.1998.2107; Vapnik V.N., 1998, STAT LEARNING THEORY; Vapnik V.N., 1995, NATURE STAT LEARNING; Wheeler DL, 2007, NUCLEIC ACIDS RES, V35, pD5, DOI DOI 10.1093/NAR/GKL1031; Wishart DS, 2007, NUCLEIC ACIDS RES, V35, pD521, DOI 10.1093/nar/gkl923; Xie XD, 2006, BIOINFORMATICS, V22, P2722, DOI 10.1093/bioinformatics/btl482	68	19	19	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1381-1991		MOL DIVERS	Mol. Divers.	AUG	2009	13	3					313	320		10.1007/s11030-009-9116-1		8	Biochemistry & Molecular Biology; Chemistry, Applied; Chemistry, Medicinal; Chemistry, Multidisciplinary	Biochemistry & Molecular Biology; Chemistry; Pharmacology & Pharmacy	474SO	WOS:000268304500006	
J	Lu, J; Niu, B; Liu, L; Lu, WC; Cai, YD				Lu, Jin; Niu, Bing; Liu, Liang; Lu, Wen-Cong; Cai, Yu-Dong			Prediction of Small Molecules' Metabolic Pathways Based on Functional Group Composition	PROTEIN AND PEPTIDE LETTERS			English	Review						Adaboost; Jackknife cross-validation test; Independent set test; Metabolism	AMINO-ACID-COMPOSITION; PROTEIN SUBCELLULAR LOCATION; SUPPORT VECTOR MACHINES; STRUCTURAL CLASS PREDICTION; MODIFIED MAHALANOBIS DISCRIMINANT; NEAREST-NEIGHBOR ALGORITHM; ENZYME SUBFAMILY CLASSES; IMPROVED HYBRID APPROACH; NEURAL-NETWORK MODEL; DOMAIN COMPOSITION	How to correctly and efficiently determine small molecules' biological function is a challenge and has a positive effect on further metabonomics analysis. Here, we introduce a computational approach to address this problem. The new approach is based on AdaBoost method and featured by function group composition to the metabolic pathway analysis, which can fast and automatically map the small chemical molecules back to the possible metabolic pathway that they belong to. As a result, jackknife cross validation test and independent set test on the model reached 73.7% and 73.8%, respectively. It can be concluded that the current approach is very promising for mapping some unknown molecules' possible metabolic pathway. An online predictor developed by this research is available at http://chemdata.shu.edu.cn/pathway.	[Lu, Jin; Niu, Bing; Liu, Liang; Lu, Wen-Cong] Shanghai Univ, Sch Mat Sci & Engn, Shanghai 200072, Peoples R China; [Liu, Liang; Lu, Wen-Cong] Shanghai Univ, Coll Sci, Dept Chem, Shanghai 200444, Peoples R China; [Cai, Yu-Dong] Shanghai Univ, Inst Syst Biol, Shanghai 200444, Peoples R China; [Cai, Yu-Dong] Chinese Acad Sci, Shanghai Inst Biol Sci, CAS MPG Partner Inst Computat Biol, Beijing 100864, Peoples R China	Lu, WC (reprint author), Shanghai Univ, Sch Mat Sci & Engn, 149 Yan Chang Rd, Shanghai 200072, Peoples R China.	wclu@shu.edu.cn; cyd@picb.ac.cn			Shanghai Leading Academic Discipline Project [J50101]	Financial support to this work is from Shanghai Leading Academic Discipline Project (Project Number: J50101).	Andraos J, 2008, CAN J CHEM, V86, P342, DOI 10.1139/V08-020; Anishetty S, 2005, COMPUT BIOL CHEM, V29, P368, DOI 10.1016/j.compbiolchem.2005.07.001; Bishop C. M., 1995, NEURAL NETWORKS PATT; Boros L G, 2007, Ernst Schering Found Symp Proc, P189; Burkart MD, 2003, ORG BIOMOL CHEM, V1, P1, DOI 10.1039/b210173d; Cai YD, 2001, J BIOMOL STRUCT DYN, V18, P607; Cai YD, 2004, BIOINFORMATICS, V20, P1292, DOI 10.1093/bioinformatics/bth085; Cai YD, 2006, J THEOR BIOL, V238, P172, DOI 10.1016/j.jtbi.2005.05.034; Cai YD, 2005, J PROTEOME RES, V4, P967, DOI 10.1021/pr0500399; Cai YD, 2003, BIOCHEM BIOPH RES CO, V305, P407, DOI 10.1016/S0006-291X(03)00775-7; Cai YD, 2004, J THEOR BIOL, V226, P373, DOI 10.1016/j.jtbi.2003.08.015; Cai YD, 2002, COMPUT CHEM, V26, P179, DOI 10.1016/S0097-8485(01)00106-1; Cai YD, 2006, J THEOR BIOL, V238, P395, DOI 10.1016/j.jtbi.2005.05.035; Cai YD, 2003, BIOPHYS J, V84, P3257; Cai YD, 2002, J CELL BIOCHEM, V84, P343, DOI 10.1002/jcb.10030; CAI YD, 2007, MIMS EPRINT, V110, P1; Cai YD, 2004, BIOINFORMATICS, V20, P1151, DOI 10.1093/bioinformatics/bth054; Chen C, 2006, ANAL BIOCHEM, V357, P116, DOI 10.1016/j.ab.2006.07.022; Chen C, 2006, J THEOR BIOL, V243, P444, DOI 10.1016/j.jtbi.2006.06.025; Chen C, 2008, J THEOR BIOL, V253, P388, DOI 10.1016/j.jtbi.2008.03.009; Chen J, 2007, AMINO ACIDS, V33, P423, DOI 10.1007/s00726-006-0485-9; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; CHOU KC, 1990, BIOPHYS CHEM, V35, P1, DOI 10.1016/0301-4622(90)80056-D; Chou KC, 2003, BIOCHEM BIOPH RES CO, V310, P675, DOI 10.1016/j.bbrc.2003.09.053; Chou KC, 2003, BIOCHEM BIOPH RES CO, V308, P148, DOI 10.1016/S0006-291X(03)01342-1; Chou KC, 2008, BIOCHEM BIOPH RES CO, V376, P321, DOI 10.1016/j.bbrc.2008.08.125; Chou KC, 2007, ANAL BIOCHEM, V370, P1, DOI 10.1016/j.ab.2007.07.006; CHOU KC, 1989, J BIOL CHEM, V264, P12074; CHOU KC, 1994, ANAL BIOCHEM, V221, P217, DOI 10.1006/abio.1994.1405; Chou KC, 2008, NAT PROTOC, V3, P153, DOI 10.1038/nprot.2007.494; Chou KC, 1998, BIOCHEM BIOPH RES CO, V252, P63, DOI 10.1006/bbrc.1998.9498; Chou KC, 1999, PROTEINS, V34, P137, DOI 10.1002/(SICI)1097-0134(19990101)34:1<137::AID-PROT11>3.0.CO;2-O; CHOU KC, 1998, ABSTR PAP AM CHEM S, V208, pU208; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; Chou KC, 2006, BIOCHEM BIOPH RES CO, V348, P1479, DOI 10.1016/j.bbrc.2006.08.030; Chou KC, 2007, J CELL BIOCHEM, V100, P665, DOI 10.1002/jcb.21096; CHOU KC, 1992, J MOL BIOL, V223, P509, DOI 10.1016/0022-2836(92)90666-8; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 2000, BIOCHEM BIOPH RES CO, V278, P477, DOI 10.1006/bbrc.2000.3815; Chou K. C., 2006, EXCLI J, V5, P55; Chou KC, 2006, J PROTEOME RES, V5, P1888, DOI 10.1021/pr060167c; Chou KC, 2007, BIOCHEM BIOPH RES CO, V357, P633, DOI 10.1016/j.bbrc.2007.03.162; Chou KC, 1996, ANAL BIOCHEM, V233, P1, DOI 10.1006/abio.1996.0001; Chou KC, 2004, CURR MED CHEM, V11, P2105; Chou KC, 2005, J CHEM INF MODEL, V45, P407, DOI 10.1021/ci049686v; CHOU KC, 1981, J THEOR BIOL, V89, P581, DOI 10.1016/0022-5193(81)90030-8; Chou KC, 2004, BIOCHEM BIOPH RES CO, V320, P1236, DOI 10.1016/j.bbrc.2004.06.073; Chou KC, 2004, J CELL BIOCHEM, V91, P1197, DOI 10.1002/jcb.10790; Chou KC, 2003, J CELL BIOCHEM, V90, P1250, DOI 10.1002/jcb.10719; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2007, BIOCHEM BIOPH RES CO, V360, P339, DOI 10.1016/j.bbrc.2007.06.027; Chou KC, 2007, J PROTEOME RES, V6, P1728, DOI 10.1021/pr060635i; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou KC, 2006, BIOCHEM BIOPH RES CO, V347, P150, DOI 10.1016/j.bbrc.2006.06.059; CHOU KC, 1993, J BIOL CHEM, V268, P16938; CHOU KC, 1988, BIOPHYS CHEM, V30, P3, DOI 10.1016/0301-4622(88)85002-6; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; Dea-Ayuela MA, 2008, BIOORGAN MED CHEM, V16, P7770, DOI 10.1016/j.bmc.2008.07.023; de Atauri P, 2000, BIOTECHNOL BIOENG, V68, P18, DOI 10.1002/(SICI)1097-0290(20000405)68:1<18::AID-BIT3>3.0.CO;2-5; Ding YS, 2008, PATTERN RECOGN LETT, V29, P1887, DOI 10.1016/j.patrec.2008.06.007; Ding YS, 2007, PROTEIN PEPTIDE LETT, V14, P811; Du PF, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-518; Du PF, 2008, J THEOR BIOL, V253, P579, DOI 10.1016/j.jtbi.2008.04.006; Du QS, 2008, CURR PROTEIN PEPT SC, V9, P248, DOI 10.2174/138920308784534005; Fang Y, 2008, AMINO ACIDS, V34, P103, DOI 10.1007/s00726-007-0568-2; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y, 2000, ANN STAT, V28, P391; Freund Y, 2004, J MACH LEARN RES, V4, P933, DOI 10.1162/1532443041827916; Freund Y, 2004, ANN STAT, V32, P1698, DOI 10.1214/009053604000000058; Freund Y, 1999, MACH LEARN, V37, P277, DOI 10.1023/A:1007662407062; Gao Y, 2005, AMINO ACIDS, V28, P373, DOI 10.1007/s00726-005-0206-9; Girgis RR, 2008, MOL PSYCHIATR, V13, P918, DOI 10.1038/mp.2008.40; Gordon Glen A, 2008, Journal of Biomedical Science & Engineering, V1, DOI 10.4236/jbise.2008.13025; JACKSON RC, 1995, TOXICOLOGY, V102, P197, DOI 10.1016/0300-483X(95)03048-K; Jahandideh S, 2007, J THEOR BIOL, V249, P785, DOI 10.1016/j.jtbi.2007.09.002; Jia PL, 2007, BIOCHEM BIOPH RES CO, V357, P366, DOI 10.1016/j.bbrc.2007.03.139; Jiang XY, 2008, PROTEIN PEPTIDE LETT, V15, P392, DOI 10.2174/092986608784246443; Jin YH, 2008, PROTEIN PEPTIDE LETT, V15, P286; Kanehisa M, 2006, NUCLEIC ACIDS RES, V34, pD354, DOI 10.1093/nar/gkj102; Kannan S, 2008, PROTEIN PEPTIDE LETT, V15, P1107, DOI 10.2174/092986608786071085; Kedarisetti KD, 2006, BIOCHEM BIOPH RES CO, V348, P981, DOI 10.1016/j.bbrc.2006.07.141; Li FM, 2008, PROTEIN PEPTIDE LETT, V15, P612, DOI 10.2174/092986608784966930; Li FM, 2008, AMINO ACIDS, V34, P119, DOI 10.1007/s00726-007-0545-9; Lin H, 2007, BIOCHEM BIOPH RES CO, V354, P548, DOI 10.1016/j.bbrc.2007.01.011; Lin H, 2008, PROTEIN PEPTIDE LETT, V15, P739, DOI 10.2174/092986608785133681; Lin H, 2007, J COMPUT CHEM, V28, P1463, DOI 10.1002/jcc.20554; Lin H, 2008, J THEOR BIOL, V252, P350, DOI 10.1016/j.jtbi.2008.02.004; Liu DQ, 2007, AMINO ACIDS, V32, P493, DOI 10.1007/s00726-006-0466-z; Liu H, 2005, BIOCHEM BIOPH RES CO, V336, P737, DOI 10.1016/j.bbrc.2005.08.160; Mahalanobis P., 1936, P NAT I SCI INDIA, V2, P49; MARCHANDGENESTE N, 2002, NEW APPROACH PHARMAC, P399; Mardia K. V., 1979, MULTIVARIATE ANAL, P521; Mondal S, 2006, J THEOR BIOL, V243, P252, DOI 10.1016/j.jtbi.2006.06.014; Moreno-Sanchez R, 2008, FEBS J, V275, P3454, DOI 10.1111/j.1742-4658.2008.06492.x; Mundra P, 2007, PATTERN RECOGN LETT, V28, P1610, DOI 10.1016/j.patrec.2007.04.001; MYERS D, 1985, COMPUT APPL BIOSCI, V1, P105; Nicholson JK, 2004, NAT BIOTECHNOL, V22, P1268, DOI 10.1038/nbt1015; Niu B, 2006, PROTEIN PEPTIDE LETT, V13, P489, DOI 10.2174/092986606776819619; Niu B, 2008, MOL DIVERS, V12, P41, DOI 10.1007/s11030-008-9073-0; Pireddu L, 2006, NUCLEIC ACIDS RES, V34, pW714, DOI 10.1093/nar/gkl228; SALZBERG S, 1992, J MOL BIOL, V227, P371, DOI 10.1016/0022-2836(92)90892-N; Schapire RE, 1998, ANN STAT, V26, P1651; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Shen HB, 2009, ANAL BIOCHEM, V385, P153, DOI 10.1016/j.ab.2008.10.020; Shen HB, 2007, EXPERT REV PROTEOMIC, V4, P453, DOI 10.1586/14789450.4.4.453; Shen HB, 2005, BIOCHEM BIOPH RES CO, V334, P288, DOI 10.1016/j.bbrc.2005.06.087; Shen HB, 2007, BIOPOLYMERS, V85, P233, DOI 10.1002/bip.20640; Shen HB, 2007, BIOCHEM BIOPH RES CO, V363, P297, DOI 10.1016/j.bbrc.2007.08.140; Shen HB, 2007, BIOCHEM BIOPH RES CO, V355, P1006, DOI 10.1016/j.bbrc.2007.02.071; Shen HB, 2007, PROTEIN ENG DES SEL, V20, P39, DOI 10.1093/protein-gzl053; Sirois S, 2004, J CHEM INF COMP SCI, V44, P1111, DOI 10.1021/ci034270n; Tian FF, 2008, PROTEIN PEPTIDE LETT, V15, P1033, DOI 10.2174/092986608786071120; Vapnik V.N., 1998, STAT LEARNING THEORY; Wang M, 2005, AMINO ACIDS, V28, P395, DOI 10.1007/s00726-005-0189-6; Wang M, 2004, PROTEIN ENG DES SEL, V17, P509, DOI 10.1093/protein/gzh061; Wang T, 2008, PROTEIN PEPTIDE LETT, V15, P915, DOI 10.2174/092986608785849308; Wardani AK, 2006, BIOCHEM ENG J, V28, P220, DOI 10.1016/j.bej.2005.10.003; Xiao X, 2007, PROTEIN PEPTIDE LETT, V14, P871, DOI 10.2174/092986607782110293; Xiao X, 2005, AMINO ACIDS, V28, P29, DOI 10.1007/s00726-004-0154-9; Xiao X, 2006, AMINO ACIDS, V30, P49, DOI 10.1007/s00726-005-0225-6; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Yamanishi Y, 2007, FEBS J, V274, P2262, DOI 10.1111/j.1742-4658.2007.05763.x; Yang ZR, 2008, OPEN BIOINFORM J, V2, P90; Zhang GY, 2008, J THEOR BIOL, V253, P310, DOI 10.1016/j.jtbi.2008.03.015; Zhang GY, 2008, PROTEIN PEPTIDE LETT, V15, P1132, DOI 10.2174/092986608786071184; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; ZHOU GP, 1984, BIOCHEM J, V222, P169; Zhou XB, 2007, J THEOR BIOL, V248, P546, DOI 10.1016/j.jtbi.2007.06.001	132	17	17	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y26, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	0929-8665		PROTEIN PEPTIDE LETT	Protein Pept. Lett.	AUG	2009	16	8					969	976				8	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	482LO	WOS:000268890600015	
J	Medina, JLV; Boque, R; Ferre, J				Villa Medina, Joe L.; Boque, Ricard; Ferre, Joan			Bagged k-nearest neighbours classification with uncertainty in the variables	ANALYTICA CHIMICA ACTA			English	Article						Uncertainty; Classification; Reliability; Nearest neighbours; Bootstrap	BOOTSTRAP METHODS	An analytical result should be expressed as x +/- U, where x is the experimental result obtained for a given variable and U is its uncertainty. This uncertainty is rarely taken into account in supervised classification. In this paper, we propose to include the information about the uncertainty of the experimental results to compute the reliability of classification. The method combines k-nearest neighbours (M) with a nested bootstrap scheme, in which a new bootstrap training set is generated using the classical bootstrap in the first level (B times) and a new bootstrap method, called U-bootstrap, in the second level (D times). Two bootstraps are used to reduce the effect of sampling in the first level and the effect of the uncertainty in the second one. These B x D new training bootstrap sets are used to compute the reliability of classification for an unknown object using kNN. The object is classified into the class with the highest reliability. In this method, unlike the classical kNN and Probabilistic Bagged k-nearest neighbours (PBkNN), the reliability of classification changes (increases or decreases) when the uncertainty is increased. These changes depend on the position of the unknown object with respect to the training objects. For the benchmark Wine dataset, we found similar values of classification error rate (CER) than for kNN (5.57%), but lower than Probabilistic Bagged k-nearest neighbours using Hamamoto's bootstrap (7.96%) or Efron's bootstrap (8.97%). (C) 2009 Elsevier B.V. All rights reserved.	[Villa Medina, Joe L.; Boque, Ricard; Ferre, Joan] Univ Rovira & Virgili, Dept Analyt Chem & Organ Chem, Tarragona 43007, Catalonia, Spain	Boque, R (reprint author), Univ Rovira & Virgili, Dept Analyt Chem & Organ Chem, C Marcel Li Domingo S-N, Tarragona 43007, Catalonia, Spain.	ricard.boque@urv.cat			Spanish Ministry of Education and Science [CTQ2007-66918]	The authors thank support of Department of Universities, Research and Information Society of Catalonia - Spain, for providing Joe Luis Villa's doctoral fellowship and project CTQ2007-66918 of the Spanish Ministry of Education and Science.	Asuncion A., UCI MACHINE LEARNING; Brieman L, 1996, MACH LEARN, V24, P123; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; De la Rosa JI, 2006, IEEE T INSTRUM MEAS, V55, P820, DOI 10.1109/TIM.2006.873779; Duda R. O., 2001, PATTERN CLASSIFICATI; Efron B., 1993, INTRO BOOTSTRAP; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Ellison S.L.R., 2000, EURACHEM CITAC GUIDE; FORINA M, 1986, VITIS, V25, P189; Gurov S. I., 2004, Computational Mathematics and Modeling, V15, DOI 10.1023/B:COMI.0000047346.87442.ef; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814; Henderson AR, 2005, CLIN CHIM ACTA, V359, P1, DOI 10.1016/j.cccn.2005.04.002; HINKLEY D, 1997, BOOTSTRAP METHODS TH, P575; HINKLEY DV, 1988, J ROY STAT SOC B MET, V50, P321; Holmes CC, 2002, J ROY STAT SOC B, V64, P295, DOI 10.1111/1467-9868.00338; Horwitz W, 2006, J AOAC INT, V89, P1095; MASSART DL, 1997, HDB CHEMOMETRICS Q A; Mooney C. Z, 1993, BOOTSTRAPPING NONPAR; Ramsey MH, 1998, J ANAL ATOM SPECTROM, V13, P97, DOI 10.1039/a706815h; Villa JL, 2008, CHEMOMETR INTELL LAB, V94, P51, DOI 10.1016/j.chemolab.2008.06.007; WEBB AR, 2002, STAT PATTERN RECOGNI, P252; Wehrens R, 2000, CHEMOMETR INTELL LAB, V54, P35, DOI 10.1016/S0169-7439(00)00102-7; [Anonymous], 2005, 17025 ISOIEC	23	2	4	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0003-2670		ANAL CHIM ACTA	Anal. Chim. Acta	JUL 30	2009	646	1-2					62	68		10.1016/j.aca.2009.05.016		7	Chemistry, Analytical	Chemistry	464RX	WOS:000267525000008	
J	Kodell, RL; Pearce, BA; Baek, S; Moon, H; Ahn, H; Young, JF; Chen, JJ				Kodell, Ralph L.; Pearce, Bruce A.; Baek, Songjoon; Moon, Hojin; Ahn, Hongshik; Young, John F.; Chen, James J.			A model-free ensemble method for class prediction with application to biomedical decision making	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						Cancer; Disease classification; Convex hull; Gene imprinting; Genomics; k-Nearest-neighbor; Medical screening	HIGH-DIMENSIONAL DATA; GENE-EXPRESSION; CLASSIFICATION; CANCER	Objective: A classification algorithm that utilizes two-dimensional convex hulls of training-set samples is presented. Methods and material: For each pair of predictor variables, separate convex hulls of positive and negative samples in the training set are formed, and these convex hulls are used to classify test points according to a nearest-neighbor criterion. An ensemble of these two-dimensional convex-hull classifiers is formed by trimming the (m)C(2) possible classifiers derived from the m predictors to a set of classifiers comprised of only unique predictor variables. Because only two-dimensional spaces are required to be populated by training-set samples, the "curse of dimensionality" is not an issue. At the same time, the power of ensemble voting is exploited by combining the classifications of the unique two-dimensional classifiers to reach a final classification. Results: The algorithm is illustrated by application to three publicly available biomedical data sets with genomic predictors and is shown to have prediction accuracy that is competitive with a number of published classification procedures. Conclusion: Because of its superior performance in terms of sensitivity and negative predictive value compared to its competitors, the convex-hull ensemble classifier demonstrates good potential for medical screening, where often the major emphasis is placed on having reliable negative predictions. (C) 2008 Elsevier B.V. All rights reserved.	[Kodell, Ralph L.] Univ Arkansas Med Sci, Dept Biostat, Little Rock, AR 72205 USA; [Pearce, Bruce A.] Natl Ctr Toxicol Res, Informat Technol Staff, Jefferson, AR 72079 USA; [Baek, Songjoon; Young, John F.; Chen, James J.] Natl Ctr Toxicol Res, Div Personalized Nutr & Med, Jefferson, AR 72079 USA; [Moon, Hojin] Calif State Univ Long Beach, Dept Math & Stat, Long Beach, CA 90840 USA; [Ahn, Hongshik] SUNY Stony Brook, Dept Appl Math & Stat, Stony Brook, NY 11794 USA	Kodell, RL (reprint author), Univ Arkansas Med Sci, Dept Biostat, 781,4301 W Markham St,COPH 3218, Little Rock, AR 72205 USA.	rlkodell@uams.edu					Ahn H, 2007, COMPUT STAT DATA AN, V51, P6166, DOI 10.1016/j.csda.2006.12.043; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; Bellman R., 1957, DYNAMIC PROGRAMMING; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Chen JJ, 2005, SAR QSAR ENVIRON RES, V16, P517, DOI 10.1080/10659360500468468; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; EFRON B, 1981, BIOMETRIKA, V68, P589, DOI 10.1093/biomet/68.3.589; Foster DP, 2004, J AM STAT ASSOC, V99, P303, DOI 10.1198/016214504000000287; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Greally JM, 2002, P NATL ACAD SCI USA, V99, P327, DOI 10.1073/pnas.012539199; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Hastie T, 2001, ELEMENTS STAT LEARNI; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; KIM H, 2002, COMPUTING SCI STAT, V33, P608; Krogh A, 1995, ADV NEURAL INFORMATI, V7, P231; Lam L, 1997, IEEE T SYST MAN CY A, V27, P553, DOI 10.1109/3468.618255; Lee JW, 2005, COMPUT STAT DATA AN, V48, P869, DOI 10.1016/j.csda.2004.03.017; Liu Y, 2000, IEEE T EVOLUT COMPUT, V4, P380; Mardia K. V., 1979, MULTIVARIATE ANAL, P521; Moon H, 2007, ARTIF INTELL MED, V41, P197, DOI 10.1016/j.artmed.2007.07.003; MOON H, 2006, GENOME BIOL, V7; Opitz DW, 1996, ADV NEUR IN, V8, P535; Perrone M.P., 1993, NEURAL NETWORKS SPEE, P126; Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, DOI 10.1109/MCAS.2006.1688199; SIMON R, 2005, J CLIN ONCOL, V96, P1; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Tong WD, 2003, J CHEM INF COMP SCI, V43, P525, DOI 10.1021/ci020058s; Tsymbal A., 2005, Information Fusion, V6, DOI 10.1016/j.inffus.2004.04.003; Tumer K., 1996, CONNECT SCI, V8, P385; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vapnik V.N., 1995, NATURE STAT LEARNING; Young JF, 2006, J TOXICOL ENV HEAL A, V69, P1527, DOI 10.1080/15287390500468746	39	4	4	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657		ARTIF INTELL MED	Artif. Intell. Med.	JUL	2009	46	3					267	276		10.1016/j.artmed.2008.11.001		10	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	471GC	WOS:000268043000006	
J	Miao, DQ; Duan, QG; Zhang, HY; Jiao, N				Miao, Duoqian; Duan, Qiguo; Zhang, Hongyu; Jiao, Na			Rough set based hybrid algorithm for text classification	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Text classification; Variable precision rough set (VPRS); k-nearest neighbor (kNN); Rocchio algorithm		Automatic classification of text documents, one of essential techniques for Web mining, has always been a hot topic flue to the explosive growth of digital documents available on-line. In text classification community, k-nearest neighbor (kNN) is a simple and yet effective classifier. However, as being a lazy learning method Without premodelling, kNN has a high cost to classify new documents when training set is large. Rocchio algorithm is another well-known and widely used technique for text classification. One drawback of [tie Rocchio classifier is that it restricts the hypothesis space to the set of linear separable hyperplane regions. When the data does not fit its underlying assumption well, Rocchio classifier suffers. In this paper, a hybrid algorithm based on variable precision rough set is proposed to combine the strength of both kNN and Rocchio techniques and overcome their weaknesses. Art experimental evaluation of different methods is carried out oil two common text corpora, i.e., the Reuters-21578 collection and the 20-newsgroup collection. The experimental results indicate that the novel algorithm achieves significant performance improvement. (C) 2008 Elsevier Ltd. All rights reserved.	[Miao, Duoqian; Duan, Qiguo; Zhang, Hongyu; Jiao, Na] Tongji Univ, Dept Comp Sci & Technol, Shanghai 201804, Peoples R China	Miao, DQ (reprint author), Tongji Univ, Dept Comp Sci & Technol, Caoan St 4800, Shanghai 201804, Peoples R China.	miaoduoqian@163.com; dqgcn@126.com			National Natural Science Foundation of China [60775036, 60475019]; Foundation of Ministry of Education of China [20060247039]	This study is supported by the National Natural Science Foundation of China (Granted Nos. 60775036 and 60475019) and the Ph.D. programs Foundation of Ministry of Education of China (No. 20060247039).	BUCKLEY C, 1994, P 17 ANN ACM SIGIR C; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich TG, 2000, LECT NOTES COMPUTER, P1; Han E.-H., 2000, CENTROID BASED DOCUM; Joachims T., 1998, 10 EUR C MACH LEARN, P137; Joachims T., 1997, P 14 INT C MACH LEAR; Lam W, 1998, SIGIR 98, P81; Lewis D.D., 1998, 10 EUR C MACH LEARN, P4; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Sarkar M, 2007, FUZZY SET SYST, V158, P2134, DOI 10.1016/j.fss.2007.04.023; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; TANG SB, 2007, EXPERT SYSTEMS APPL, V33, P215; Tang YH, 2007, IEICE T INF SYST, VE90D, P1787, DOI 10.1093/ietisy/e90-d.11.1787; YANG Y, 1999, 22 ANN INT ACM SIGIR; Yang Y., 1997, ICML 97, P412; ZIARKO W, 1993, J COMPUT SYST SCI, V46, P39, DOI 10.1016/0022-0000(93)90048-2	17	7	9	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	JUL	2009	36	5					9168	9174		10.1016/j.eswa.2008.12.026		7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	427MG	WOS:000264782800050	
J	Chevrefils, C; Cheriet, F; Aubin, CE; Grimard, G				Chevrefils, Claudia; Cheriet, Farida; Aubin, Carl-Eric; Grimard, Guy			Texture Analysis for Automatic Segmentation of Intervertebral Disks of Scoliotic Spines From MR Images	IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE			English	Article; Proceedings Paper	5th IEEE International Special Topic Conference on Information Technology in Biomedicine	OCT, 2006	Ioannina, GREECE	IEEE Engn Med & Biol Soc, Univ Ioanniana, Natl Tech Univ Athens		Classification; MRI; segmentation; texture features	MAGNETIC-RESONANCE IMAGES; WATERSHED SEGMENTATION; CLASSIFICATION; SHAPE; SPECTROSCOPY; CARTILAGE; FEATURES; TUMORS; MODEL	This paper presents a unified framework for automatic segmentation of intervertebral disks of scoliotic spines from different types of magnetic resonance (MR) image sequences. The method exploits a combination of statistical and spectral texture features to discriminate closed regions representing intervertebral disks from background in MR images of the spine. Specific texture features are evaluated for three types of MR sequences acquired in the sagittal plane: 2-D spin echo, 3-D multiecho data image combination, and 3-D fast imaging with steady state precession. A total of 22 texture features (18 statistical and 4 spectral) are extracted from every closed region obtained from an automatic segmentation procedure based on the watershed approach. The feature selection step based on principal component analysis and clustering process permit to decide among all the extracted features which ones resulted in the highest rate of good classification. The proposed method is validated using a supervised k-nearest-neighbor classifier on 505 MR images coming from three different scoliotic patients and three different MR acquisition protocols. Results suggest that the selected texture features and classification can contribute to solve the problem of oversegmentation inherent to existing automatic segmentation methods by successfully discriminating intervertebral disks from the background on MRI of scoliotic spines.	[Chevrefils, Claudia; Cheriet, Farida; Aubin, Carl-Eric] Ecole Polytech, Inst Biomed Engn, Montreal, PQ H3C 3A7, Canada; [Cheriet, Farida] Ecole Polytech, Dept Comp Engn & Software, Montreal, PQ H3C 3A7, Canada; [Chevrefils, Claudia; Cheriet, Farida; Aubin, Carl-Eric] St Justine Univ Hosp Ctr, Montreal, PQ H3T 1C5, Canada; [Grimard, Guy] Hop St Justine, Dept Orthopaed, Montreal, PQ H3T 1C5, Canada; [Aubin, Carl-Eric] Ecole Polytech, Dept Mech Engn, Montreal, PQ H3C 3A7, Canada	Chevrefils, C (reprint author), Ecole Polytech, Inst Biomed Engn, Montreal, PQ H3C 3A7, Canada.	claudia.chevrefils@polymtl.ca; farida.cheriet@polymtl.ca; carl-eric.aubin@polymtl.ca; guy_grimard@ssss.gouv.qc.ca					BEZDEK JC, 1993, MED PHYS, V20, P1033, DOI 10.1118/1.597000; BOOTH S, 2001, P CAN C EL COMP ENG, P1303; CAI H, P 07 4 IEEE INT S BI, P600; Carballido-Gamio J, 2004, IEEE T MED IMAGING, V23, P36, DOI 10.1109/TMI.2003.819929; Cates JE, 2005, MED IMAGE ANAL, V9, P566, DOI 10.1016/j.media.2005.04.007; Chen P, 2006, STUD NONLINEAR DYN E, V10; CHEVREFILS C, P IM AN REC 4 INT C, P1017; CLARKE LP, 1995, MAGN RESON IMAGING, V13, P343, DOI 10.1016/0730-725X(94)00124-L; CLARKE LP, 1993, MAGN RESON IMAGING, V11, P95, DOI 10.1016/0730-725X(93)90417-C; Coulon O, 2002, MAGN RESON MED, V47, P1176, DOI 10.1002/mrm.10162; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dokladal P, 2003, PATTERN RECOGN, V36, P2463, DOI 10.1016/S0031-3203(03)00118-3; Duda R. O., 2001, PATTERN CLASSIFICATI; FRALICK SC, 1971, IEEE T INFORM THEORY, V17, P440, DOI 10.1109/TIT.1971.1054663; Galanaud D, 2006, MAGN RESON MED, V55, P1236, DOI 10.1002/mrm.20886; Galloway MM, 1975, COMPUTER GRAPHICS IM, V4, P172, DOI 10.1016/S0146-664X(75)80008-6; GEORGIADIS P, 2008, COMPUT METH PROG BIO, V89, P264; GEORGY BA, 1994, AM J ROENTGENOL, V162, P923; Ginneken B., 2002, IEEE T MED IMAGING, V21, P924; Gonzalez R. C., 2004, DIGITAL IMAGE PROCES; Grau V, 2004, PATTERN RECOGN, V37, P47, DOI 10.1016/j.patcog.2003.07.009; Han J., 2001, DATA MINING CONCEPTS; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; HERLIDOU S, 2001, P 23 ANN INT C IEEE, P2340; HOAD CL, 2001, PHYS MED BIOL, V46, P213; HURTUT T, P IM AN REC 4 INT C, P187; Isgum I, 2007, MED PHYS, V34, P1450, DOI 10.1118/1.2710548; Jain A. K., 2000, IEEE T PATTERN ANAL, V22, P1; Martel A L, 1998, Comput Aided Surg, V3, P40, DOI 10.3109/10929089809148127; MODIC MT, 1983, AM J ROENTGENOL, V141, P1129; Mu TT, 2008, J DIGIT IMAGING, V21, P153, DOI 10.1007/s10278-007-9102-z; Muensterer OJ, 1996, CLIN BIOMECH, V11, P260, DOI 10.1016/0268-0033(95)00069-0; Oliver A, 2008, IEEE T INF TECHNOL B, V12, P55, DOI 10.1109/TITB.2007.903514; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62; Patino L, 2005, PATTERN RECOGN LETT, V26, P819, DOI 10.1016/j.patrec.2004.09.036; Peng Zhigang, 2005, Conf Proc IEEE Eng Med Biol Soc, V3, P2527; SCHAD LR, 1993, MAGN RESON IMAGING, V11, P889, DOI 10.1016/0730-725X(93)90206-S; Schmid MR, 2005, AM J ROENTGENOL, V184, P1744; SEBBAHI A, P CAR 96 COMP ASS RA, P302; Seghers D, 2007, IEEE T MED IMAGING, V26, P1115, DOI 10.1109/TMI.2007.896924; Smyth PP, 1997, IMAGE VISION COMPUT, V15, P575, DOI 10.1016/S0262-8856(97)00006-1; SOLANAS E, P 01 INT C IM PROC 7, P885; Sonka M, 2004, HDB MED IMAGING MED; TAXT T, 1994, IEEE T MED IMAGING, V13, P470, DOI 10.1109/42.310878; Tek FB, 2004, ELECTRON LETT, V40, P1332, DOI 10.1049/el:20045834; van Ginneken B, 2006, MED IMAGE ANAL, V10, P19, DOI 10.1016/j.media.2005.02.002; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344; Wells WM, 1996, IEEE T MED IMAGING, V15, P429, DOI 10.1109/42.511747; ZHU H, 2001, P IEEE INT C FUZZ SY, P27	49	7	7	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1089-7771		IEEE T INF TECHNOL B	IEEE T. Inf. Technol. Biomed.	JUL	2009	13	4					608	620		10.1109/TITB.2009.2018286		13	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Medical Informatics	Computer Science; Mathematical & Computational Biology; Medical Informatics	468QU	WOS:000267835800025	
J	Chaudhuri, P; Ghosh, AK; Oja, H				Chaudhuri, Probal; Ghosh, Anil K.; Oja, Hannu			Classification Based on Hybridization of Parametric and Nonparametric Classifiers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayes risk; bandwidth; kernel density estimation; LDA; misclassification rate; multiscale smoothing; nearest neighbor; QDA	NEAREST-NEIGHBOR CLASSIFICATION; KERNEL DENSITY-ESTIMATION; PATTERN-CLASSIFICATION; DISCRIMINANT-ANALYSIS; SCALE-SPACE; REGRESSION; VISUALIZATION; VIEW	Parametric methods of classification assume specific parametric models for competing population densities (e. g., Gaussian population densities can lead to linear and quadratic discriminant analysis) and they work well when these model assumptions are valid. Violation in one or more of these parametric model assumptions often leads to a poor classifier. On the other hand, nonparametric classifiers (e. g., nearest-neighbor and kernel-based classifiers) are more flexible and free from parametric model assumptions. But, the statistical instability of these classifiers may lead to poor performance when we have small numbers of training sample observations. Nonparametric methods, however, do not use any parametric structure of population densities. Therefore, even when one has some additional information about population densities, that important information is not used to modify the nonparametric classification rule. This paper makes an attempt to overcome these limitations of parametric and nonparametric approaches and combines their strengths to develop some hybrid classification methods. We use some simulated examples and benchmark data sets to examine the performance of these hybrid discriminant analysis tools. Asymptotic results on their misclassification rates have been derived under appropriate regularity conditions.	[Chaudhuri, Probal; Ghosh, Anil K.] Indian Stat Inst, Theoret Stat & Math Unit, Calcutta 700108, India; [Oja, Hannu] Univ Tampere, Tampere Sch Publ Hlth, Tampere 33014, Finland	Chaudhuri, P (reprint author), Indian Stat Inst, Theoret Stat & Math Unit, 203 BT Rd, Calcutta 700108, India.	probal@isical.ac.in; anilkghosh@rediffmail.com; Hannu.Oja@uta.fi			Council of Scientific and Industrial Research; Department of Biotechnology, Government of India; Academy of Finland	The authors would like to thank the reviewers for their careful reading of the earlier version of the paper and for providing them with several helpful comments. The research of Probal Chaudhuri was partially supported by the grants of the Council of Scientific and Industrial Research and the Department of Biotechnology, Government of India. The research of Hannu Oja was partially supported by the grants of the Academy of Finland.	Bolance C, 2003, INSUR MATH ECON, V32, P19, DOI 10.1016/S0167-6687(02)00191-9; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Buch-Larsen T, 2005, STATISTICS, V39, P503, DOI 10.1080/02331880500439782; Chaudhuri P, 1999, J AM STAT ASSOC, V94, P807, DOI 10.2307/2669996; Chaudhuri P, 2000, ANN STAT, V28, P408; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Duda R.O., 2000, PATTERN CLASSIFICATI; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fix E, 1951, DISCRIMINATORY ANAL; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; FRIEDMAN J. H., 1994, FLEXIBLE METRIC NEAR; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; Ghosh AK, 2007, INT J PATTERN RECOGN, V21, P1103, DOI 10.1142/S0218001407005855; Ghosh AK, 2005, IEEE T PATTERN ANAL, V27, P1592, DOI 10.1109/TPAMI.2005.204; Ghosh AK, 2006, TECHNOMETRICS, V48, P120, DOI 10.1198/004017005000000391; Glad IK, 1998, SCAND J STAT, V25, P649, DOI 10.1111/1467-9469.00127; Godtliebsen F, 2002, J COMPUT GRAPH STAT, V11, P1, DOI 10.1198/106186002317375596; Hand D. J., 1982, KERNEL DISCRIMINANT; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hastie T, 2001, ELEMENTS STAT LEARNI; HASTIE T, 1994, J AM STAT ASSOC, V89, P1255, DOI 10.2307/2290989; HJORT NL, 1995, ANN STAT, V23, P882, DOI 10.1214/aos/1176324627; Hjort NL, 1996, ANN STAT, V24, P1619; Holmes CC, 2002, J ROY STAT SOC B, V64, P295, DOI 10.1111/1467-9868.00338; Holmes CC, 2003, BIOMETRIKA, V90, P99, DOI 10.1093/biomet/90.1.99; Hoti F, 2004, PATTERN RECOGN, V37, P409, DOI 10.1016/j.patcog.2003.08.004; JONES MC, 1995, BIOMETRIKA, V82, P327, DOI 10.1093/biomet/82.2.327; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; LAI SL, 1977, THESIS U CALIFORNIA; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MACK YP, 1981, SIAM J ALGEBRA DISCR, V2, P311, DOI 10.1137/0602035; Mahalanobis P., 1936, P NAT I SCI INDIA, V2, P49; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; OLKIN I, 1987, J AM STAT ASSOC, V82, P858, DOI 10.2307/2288797; Ripley B. D., 1996, PATTERN RECOGNITION; Schapire RE, 1998, ANN STAT, V26, P1651; Scott D. W., 1992, MULTIVARIATE DENSITY; SHALAK DB, 1996, THESIS U MASSACHUSET; SILVERMAN BW, 1978, ANN STAT, V6, P177, DOI 10.1214/aos/1176344076; Silverman B.W., 1986, DENSITY ESTIMATION S; Vapnik V.N., 1998, STAT LEARNING THEORY; Wand M. P., 1995, KERNEL SMOOTHING; Wichern D. W., 1992, APPL MULTIVARIATE ST	45	4	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2009	31	7					1153	1164		10.1109/TPAMI.2008.149		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	447KB	WOS:000266188900001	
J	Guan, D; Yuan, W; Lee, YK; Lee, S				Guan, Donghai; Yuan, Weiwei; Lee, Young-Koo; Lee, Sungyoung			Nearest neighbor editing aided by unlabeled data	INFORMATION SCIENCES			English	Article						Nearest neighbor editing; Unlabeled data; Edited nearest neighbor; Repeated edited nearest neighbor; All k-NN	IMAGE RETRIEVAL; RULE; CLASSIFICATION; FRAMEWORK; REDUCTION; SELECTION	This paper proposes a novel method for nearest neighbor editing. Nearest neighbor editing aims to increase the classifier's generalization ability by removing noisy instances from the training set. Traditionally nearest neighbor editing edits (removes/retains) each instance by the voting of the instances in the training set (labeled instances). However, motivated by semi-supervised learning, we propose a novel editing methodology which edits each training instance by the voting of all the available instances (both labeled and unlabeled instances). We expect that the editing performance could be boosted by appropriately using unlabeled data. Our idea relies on the fact that in many applications, in addition to the training instances, many unlabeled instances are also available since they do not need human annotation effort. Three popular data editing methods, including edited nearest neighbor, repeated edited nearest neighbor and All k-NN are adopted to verify our idea. They are tested on a set of LICI data sets. Experimental results indicate that all the three editing methods can achieve improved performance with the aid of unlabeled data. Moreover, the improvement is more remarkable when the ratio of training data to unlabeled data is small. (C) 2009 Elsevier Inc. All rights reserved.	[Guan, Donghai; Yuan, Weiwei; Lee, Young-Koo; Lee, Sungyoung] Kyung Hee Univ, Dept Comp Engn, Yongin 446701, South Korea	Lee, YK (reprint author), Kyung Hee Univ, Dept Comp Engn, Yongin 446701, South Korea.	yklee@khu.ac.kr			IITA (Institute of Information Technology Advancement) [IITA-2009-(CIO90-0902-0002)]; Korea government (MOST) [2008-1342]	Many thanks to Prof. Brian J. d'Auriol for proofreading of our paper. We also thank the reviewers for their constructive comments. This research was supported by the MKE (Ministry of Knowledge Economy), Korea, under the ITRC (Information Technology Research Center) support program supervised by the IITA (Institute of Information Technology Advancement) (IITA-2009-(CIO90-0902-0002)). This work was also supported by the Korea Science and Engineering Foundation (KOSEF) grant funded by the Korea government (MOST) (No. 2008-1342).	Angluin D., 1988, Machine Learning, V2, DOI 10.1007/BF00116829; Bennett K. P., 2002, P 8 ACM SIGKDD INT C, P289; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; Cheng J, 2007, PATTERN RECOGN, V40, P330, DOI 10.1016/j.patcog.2006.06.005; Constantinopoulos C, 2008, NEUROCOMPUTING, V71, P2489, DOI 10.1016/j.neucom.2007.11.039; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; De RK, 2001, INFORM SCIENCES, V132, P179, DOI 10.1016/S0020-0255(01)00070-6; Devijver P. A., 1982, PATTERN RECOGNITION; Ferri F. J., 1992, Proceedings. 11th IAPR International Conference on Pattern Recognition. Vol.II. Conference B: Pattern Recognition Methodology and Systems, DOI 10.1109/ICPR.1992.201851; HAND DJ, 1978, INFORM SCIENCES, V14, P171, DOI 10.1016/0020-0255(78)90040-3; HANDL J, 2006, P INT JOINT C NEUR N, P3319; Liu CH, 2008, INFORM SCIENCES, V178, P3347, DOI 10.1016/j.ins.2008.05.006; Liu H., 2001, INSTANCE SELECTION C; PENROD CS, 1977, IEEE T SYST MAN CYB, V7, P92; Qin T, 2008, PATTERN RECOGN LETT, V29, P637, DOI 10.1016/j.patrec.2007.11.015; Riloff E., 2003, P 7 C NAT LANG LEARN, P25; RIPLEY BD, 1996, PATTERN RECOGN, P198; Song YQ, 2008, PATTERN RECOGN, V41, P2789, DOI 10.1016/j.patcog.2008.01.001; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; WILSON DL, 1972, IEEE T SYST MAN CYB, V2, P431; Zhang DQ, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P629; Zhao JD, 2008, NEUROCOMPUTING, V71, P1842, DOI 10.1016/j.neucom.2007.06.014; Zhu XQ, 2008, PATTERN RECOGN, V41, P2980, DOI 10.1016/j.patcog.2008.03.008	23	7	10	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255		INFORM SCIENCES	Inf. Sci.	JUN 13	2009	179	13					2273	2282		10.1016/j.ins.2009.02.011		10	Computer Science, Information Systems	Computer Science	447UA	WOS:000266216100016	
J	Harmon, RS; Remus, J; McMillan, NJ; McManus, C; Collins, L; Gottfried, JL; DeLucia, FC; Miziolek, AW				Harmon, Russell S.; Remus, Jeremiah; McMillan, Nancy J.; McManus, Catherine; Collins, Leslie; Gottfried, Jennifer L., Jr.; DeLucia, Frank C.; Miziolek, Andrzej W.			LIBS analysis of geomaterials: Geochemical fingerprinting for the rapid analysis and discrimination of minerals	APPLIED GEOCHEMISTRY			English	Article; Proceedings Paper	Goldschmidt Conference 2006	2006	Cologne, GERMANY				INDUCED BREAKDOWN SPECTROSCOPY; REAL-TIME; SENSOR TECHNOLOGY; BERYL; SOILS; AIR	Laser-induced breakdown spectroscopy (LIBS) is a simple atomic emission spectroscopy technique capable of real-time, essentially non-destructive determination of the elemental composition of any substance (solid, liquid, or gas). LIBS, which is presently undergoing rapid research and development as a technology for geochemical analysis, has attractive potential as a field tool for rapid man-portable and/or stand-off chemical analysis. In LIBS, a pulsed laser beam is focused such that energy absorption produces a high-temperature microplasma at the sample surface resulting in the dissociation and ionization of small amounts of material, with both continuum and atomic/ionic emission generated by the plasma during cooling. A broadband spectrometer-detector is used to spectrally and temporally resolve the light from the plasma and record the intensity of elemental emission lines. Because the technique is simultaneously sensitive to all elements, a single laser shot can be used to track the spectral intensity of specific elements or record the broadband LIBS emission spectra, which are unique chemical 'fingerprints' of a material. In this study, a broad spectrum of geological materials was analyzed using a commercial bench-top LIBS system with broadband detection from similar to 200-965 nm, with multiple single-shot spectra acquired. The subsequent use of statistical signal processing approaches to rapidly identify and classify samples highlights the potential of LIBS for 'geochemical fingerprinting' in a variety of geochemical, mineralogical, and environmental applications that would benefit from either real-time or in-field chemical analysis. Published by Elsevier Ltd.	[Harmon, Russell S.] ARL Army Res Off, Res Triangle Pk, NC USA; [Remus, Jeremiah; Collins, Leslie] Duke Univ, Dept Elect Engn, Durham, NC 27703 USA; [McMillan, Nancy J.] New Mexico State Univ, Dept Geol Sci, Las Cruces, NM 88003 USA; [McManus, Catherine] Baylor Univ, Dept Chem, Waco, TX 76798 USA; [Gottfried, Jennifer L., Jr.; DeLucia, Frank C.; Miziolek, Andrzej W.] USA, Res Lab, Aberdeen Proving Ground, MD 21005 USA	Harmon, RS (reprint author), ARL Army Res Off, POB 12211, Res Triangle Pk, NC USA.	russell.harmon@us.army.mil	Gottfried, Jennifer/G-6333-2010; De Lucia, Frank/D-5630-2012				ABDURIYIM A, 2003, ANAL CS PINK BERYL U; Arca G, 1997, APPL SPECTROSC, V51, P1102, DOI 10.1366/0003702971941863; Carranza JE, 2001, SPECTROCHIM ACTA B, V56, P851, DOI 10.1016/S0584-8547(01)00183-5; Corsi M., 2000, RES ADV APPL SPECTRO, V1, P41; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CREMERS DA, 1984, APPL SPECTROSC, V38, P721, DOI 10.1366/0003702844555034; Cremers DA, 2006, LASER-INDUCED BREAKDOWN SPECTROSCOPY (LIBS): FUNDAMENTALS AND APPLICATIONS, P1; Detalle V, 2003, APPL OPTICS, V42, P5971, DOI 10.1364/AO.42.005971; Duda R.O., 2000, PATTERN CLASSIFICATI; Eppler AS, 1996, APPL SPECTROSC, V50, P1175, DOI 10.1366/0003702963905123; Fabre C, 2002, GEOCHIM COSMOCHIM AC, V66, P1401, DOI 10.1016/S0016-7037(01)00858-4; Fix E., 1951, 4 USAF SCH AV MED, P261; FRITSCH E, 1987, GEMS GEMOL, V23, P26; FRITSCH E, 1988, GEMS GEMOL, V24, P81; FRITSCH E, 1988, GEMS GEMOL, V24, P3; Harmon RS, 2005, GEOCHEM-EXPLOR ENV A, V5, P21, DOI 10.1144/1467-7873/03-059; Harmon RS, 2006, APPL GEOCHEM, V21, P730, DOI 10.1016/j.apgeochem.2006.02.003; Klein C., 2008, MINERAL SCI; McManus CE, 2008, APPL OPTICS, V47, pG72, DOI 10.1364/AO.47.000G72; McMillan NJ, 2006, ANAL BIOANAL CHEM, V385, P263, DOI 10.1007/s00216-006-0374-9; McMillan NJ, 2007, SPECTROCHIM ACTA B, V62, P1528, DOI 10.1016/j.sab.2007.10.037; Russo RE, 2006, LASER-INDUCED BREAKDOWN SPECTROSCOPY (LIBS): FUNDAMENTALS AND APPLICATIONS, pXV; MONKEBLANKENBUR.L, 1989, LASER MICROANALYSIS; Parriger C.G., 2006, LASER INDUCED BREAKD, P171; Pasquini C, 2007, J BRAZIL CHEM SOC, V18, P463, DOI 10.1590/S0103-50532007000300002; Payling R, 2000, OPTICAL EMISSION LIN; PRICE DC, 1976, J PHYSIQUE         C, V6, P811; Ralchenko Y., 2008, NIST ATOMIC SPECTRA; Rusak DA, 1997, CRIT REV ANAL CHEM, V27, P257, DOI 10.1080/10408349708050587; SABSABI M, 2007, 1 N AM LIBS S NASLIB; Salle B, 2004, SPECTROCHIM ACTA B, V59, P1413, DOI 10.1016/j.sab.2004.06.006; SCHALLER WT, 1962, AM MINERAL, V47, P672; Song K, 1997, APPL SPECTROSC REV, V32, P183, DOI 10.1080/05704929708003314; Theriault GA, 1998, FIELD ANAL CHEM TECH, V2, P117, DOI 10.1002/(SICI)1520-6521(1998)2:2<117::AID-FACT8>3.0.CO;2-T; Viana RR, 2002, PHYS CHEM MINER, V29, P668, DOI 10.1007/s00269-002-0278-y	35	35	36	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0883-2927		APPL GEOCHEM	Appl. Geochem.	JUN	2009	24	6					1125	1141		10.1016/j.apgeochem.2009.02.009		17	Geochemistry & Geophysics	Geochemistry & Geophysics	459VV	WOS:000267141200018	
J	Sun, YM; Wong, AKC; Kamel, MS				Sun, Yanmin; Wong, Andrew K. C.; Kamel, Mohamed S.			CLASSIFICATION OF IMBALANCED DATA: A REVIEW	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article						Classification; class imbalance problem	CLASSIFIERS; DISCOVERY; INDUCTION	Classification of data with imbalanced class distribution has encountered a significant drawback of the performance attainable by most standard classifier learning algorithms which assume a relatively balanced class distribution and equal misclassification costs. This paper provides a review of the classification of imbalanced data regarding: the application domains; the nature of the problem; the learning difficulties with standard classifier learning algorithms; the learning objectives and evaluation measures; the reported research solutions; and the class imbalance problem in the presence of multiple classes.	[Sun, Yanmin] Pattern Discovery Technol Inc, Waterloo, ON N2L 5Z4, Canada; [Wong, Andrew K. C.] Univ Waterloo, Syst Design Dept, Waterloo, ON N2L 3G1, Canada; [Kamel, Mohamed S.] Univ Waterloo, Dept Elect & Comp Engn, Waterloo, ON N2L 3G1, Canada	Sun, YM (reprint author), Pattern Discovery Technol Inc, 554 Parkside Dr, Waterloo, ON N2L 5Z4, Canada.		Kamel, Mohamed/D-9323-2011				Abe N., 2004, P 10 ACM SIGKDD INT, P3, DOI 10.1145/1014052.1014056; Akbani R, 2004, P 15 EUR C MACH LEAR, P39; ANAND R, 1993, IEEE T NEURAL NETWOR, V4, P962, DOI 10.1109/72.286891; Batista G. E., 2004, SIGKDD EXPLORATIONS, V6, P20, DOI DOI 10.1145/1007730.1007735; Bradford J. P., 1998, P 10 EUR C MACH LEAR, P131; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Cardie C., 1997, P 14 INT C MACH LEAR, P57; Carvajal K, 2004, INSIGHT, V46, P399, DOI 10.1784/insi.46.7.399.55578; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; Chawla NV, 2003, P 7 EUR C PRINC PRAC, P107; CHAWLA NV, DATA MINING KNOWLEDG; CHAWLA NV, 2004, SIGKDD EXPLORATIONS, V6; CHAWLA NV, 2005, WORKSH UT BAS DAT MI; Chawla NV, 2004, SIGKDD EXPLORATIONS, V6, P1; Chawla NV, 2003, P ICML 2003 WORKSH L; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOMINGOS P, 1999, ACM SIGKDD 1999, P155; Duda R., 1973, PATTERN CLASSIFICATI; Duda R. O., 2001, PATTERN CLASSIFICATI; Elkan Charles, RESULTS KDD 99 CLASS; ESTABROOKS A, 2000, THESIS DALHOUSIE U H; Ezawa K J, 1996, P 13 INT C MACH LEAR, P139; Fan W., 1999, P 16 INT C MACH LEAR, P97; Fawcett T, 1997, DATA MIN KNOWL DISC, V1, P291, DOI 10.1023/A:1009700419189; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Guo H, 2004, SIGKDD EXPLORATIONS, V6, P30; HANLEY JA, 1982, RADIOLOGY, V143, P29; HECHERMAN D, 1996, ADV KNOWLEDGE DISCOV, P273; Hertz J., 1991, INTRO THEORY NEURAL; Holte RC, 1989, P 11 INT JOINT C ART, P813; Japkowicz N., 2002, Intelligent Data Analysis, V6; JAPKOWICZ N, 2001, P 14 C CAN SOC COMP, P67; JAPKOWICZ N, 2001, MACH LEARN, V41; Japkowicz N., 2000, P AAAI 2000 WORKSH L; JOSHI M, 2001, P 1 IEEE INT C DAT M; JOSHI MV, 2002, THESIS U MINNESOTA T; KAMEL MS, 2003, P 4 INT WORKSH MULT; KITTLER J, 1998, IEEE T PATT ANAL MAC, V20; Kubat M, 1998, MACH LEARN, V30, P195, DOI 10.1023/A:1007452223027; Kuck H., 2004, THESIS U BRIT COLUMB; Lewis D., 1998, P 17 ANN INT ACM SIG, P73; Li J., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; Li JY, 2004, MACH LEARN, V54, P99, DOI 10.1023/B:MACH.0000011804.08528.7d; Li W., 2001, P IEEE INT C DAT MIN, P369; Lin Y, 2002, MACH LEARN, V46, P191, DOI 10.1023/A:1012406528296; Ling C. X., 2004, P 21 INT C MACH LEAR; Ling C. X., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Liu B, 1998, P 4 INT C KNOWL DISC, P80; Liu B., 2000, P 4 EUR C PRINC DAT, P504; Ma Y., 1999, P 5 ACM SIGKDD INT C, P337, DOI 10.1145/312129.312274; Manevitz LM, 2001, J MACHINE LEARNING R, V2, P139; Margineantu D., 2002, P 13 EUR C MACH LEAR, P270; MURPH PM, 1991, UCI REPOSITORY MACHI; Pearl J., 1988, PROBABILISTIC REASON, p[505, 506, 507, 524]; Prati R. C., 2004, P 3 MEX INT C ART IN, P312; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; QUINLAN JR, 1991, MACH LEARN, V6, P93, DOI 10.1007/BF00153762; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1986, MACH LEARN, V1, P106; RASKUTTI B, 2004, P EUR C MACH LEARN P, P60; RIDDLE P, 1994, APPL ARTIF INTELL, V8, P125, DOI 10.1080/08839519408945435; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Schapire R, 2002, MSRI WORKSH NONL EST, P149; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; STEWARD S, 1997, CELLULAR BUSINESS, P23; SUN Y, 2005, 4 INT C MACH LEARN D, P21; SUN Y, 2006, P 6 INT C DAT MIN, P592; Sun YM, 2007, PATTERN RECOGN, V40, P3358, DOI 10.1016/j.patcog.2007.04.009; Tan P. N., 2006, INTRO DATA MINING; TAX DMJ, 2002, INT C PATT REC QUEB; Ting K., 1994, P 10 CAN C ART INT, P91; Ting K., 2000, P 17 INT C MACH LEAR, P983; Turney P., 2000, P WORKSH COST SENS L, P15; Vapnik V.N., 1963, Avtomatika i Telemekhanika, V24; WALTERS D, 1994, MOBILE PHONE NEWS, P4; Wang Y., 1997, THESIS U WATERLOO WA; Wang Y, 2003, IEEE T KNOWL DATA EN, V15, P764, DOI 10.1109/TKDE.2003.1198405; Weiss G. M., 2004, SIGKDD EXPLORATIONS, V6, P7; Weiss GM, 2003, J ARTIF INTELL RES, V19, P315; Wong AKC, 1997, IEEE T KNOWL DATA EN, V9, P877, DOI 10.1109/69.649314; WU G, 2003, P ICML 03 WORKSH LEA; Yin XX, 2003, SIAM PROC S, P331; Zadrozny B., 2003, P 3 IEEE INT C DAT M, P435; Zadrozny B., 2001, P 7 ACM SIGKDD INT C, P204, DOI 10.1145/502512.502540; ZHANG J, 2003, P ICML 03 WORKSH LEA; Zhou S., 2000, P 6 ACM SIGKDD INT C, P265, DOI 10.1145/347090.347147; Zhou ZH, 2006, IEEE T KNOWL DATA EN, V18, P63	92	32	33	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014		INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	JUN	2009	23	4					687	719				33	Computer Science, Artificial Intelligence	Computer Science	459QC	WOS:000267117500002	
J	Wechsler, H				Wechsler, Harry			Linguistics and face recognition	JOURNAL OF VISUAL LANGUAGES AND COMPUTING			English	Article						Authentication; Biometrics; Boosting; Clustering; Cross-validation; Data fusion; Face recognition; Feature selection; FERET; Forensics; FRGC; ICA; k Nearest neighbor; Likelihood ratio; Linguistics; Margin; MDL; Multimodal integration; Neyman-Pearson; Occlusion; Recognition; p-Values; Parsing; Random deficiency; Ranking; Recognition-by-parts; Segmentation; SIFT; Strangeness; Surveillance; Transcluction; Typicality	FORENSIC SPEAKER RECOGNITION; NATURAL IMAGE SEQUENCES; CORTEX; CATEGORIZATION; TRANSDUCTION; CLASSIFIER; FILTERS; SEARCH; MODEL	We describe in this paper a novel biometric methodology for face recognition suitable to address pose, illumination, and expression (PIE) image variability, temporal change, flexible matching, and last but not least occlusion and disguise that are usually referred to as denial and deception. The adverse conditions listed above affect the scope and performance of biometric analysis vis-A-vis both training and testing. The conceptual framework proposed here draws support from discriminative methods using likelihood ratios. At the conceptual level it links forensics and biometrics, while at the implementation level it links the Bayesian framework and statistical learning theory. As many of the concerns listed usually affect only parts of the face, a non-parametric recognition-by-part approach is advanced here for the purpose of reliable face recognition. Recognition-by-parts facilitates authentication because it does not seek for explicit invariance. Instead, it handles variability using component-based configurations that are flexible enough to compensate among others for limited pose changes, if any, and limited occlusion and disguise. The recognition-by-parts approach proposed here supports incremental and progressive processing. It is similar in nature to modern linguistics and practical intelligence with the emphasis on semantics and pragmatics. Layered categorization starts with face detection using implicit rather than explicit segmentation. It proceeds with face authentication that involves feature selection of local patch instances including dimensionality reduction, exemplar-based clustering of patches into parts, and data fusion for matching using boosting driven by parts that play the role of weak learners. The implementation. driven by transcluction, employs proximity and typicality (ranking) realized using strangeness and random deficiency p-values, respectively. The feasibility and reliability of the proposed architecture has been validated using FERET and FRGC data. The paper concludes with suggestions for augmenting and enhancing the scope and utility of the recognition-by-parts architecture. (c) 2009 Elsevier Ltd. All rights reserved.	George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA	Wechsler, H (reprint author), George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA.	wechsler@gmu.edu					Barlow H. B., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.3.295; Becker B., 2008, 8 INT C AUT FAC GEST; BLACK B, 1994, TEX LAW REV, V72, P715; Champod C, 2000, SPEECH COMMUN, V31, P193, DOI 10.1016/S0167-6393(99)00078-3; Chapelle O., 2006, SEMISUPERVISED LEARN; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COX IJ, 1996, P C COMP VIS PATT RE; Delorme A, 2001, NEURAL NETWORKS, V14, P795, DOI 10.1016/S0893-6080(01)00049-1; DESSIMOZ D, 2008, HDB BIOMETRICS; El-Yaniv R, 2005, PATTERN RECOGN LETT, V26, P2104, DOI 10.1016/j.patrec.2005.03.025; Freund Y., 1996, 13 INT C MACH LEARN, P148; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Gonzalez-Rodriguez J, 2007, IEEE T AUDIO SPEECH, V15, P2104, DOI 10.1109/TASL.2007.902747; GUTTA S, 2004, 1 INT C BIOM AUTH HO; Hand DJ, 2006, STAT SCI, V21, P1, DOI 10.1214/088342306000000060; Ho SS, 2008, IEEE T PATTERN ANAL, V30, P1557, DOI 10.1109/TPAMI.2007.70811; Hyvarinen A, 2003, J OPT SOC AM A, V20, P1237, DOI 10.1364/JOSAA.20.001237; Kahneman D., 2000, CHOICES VALUES FRAME; KOLLER D, 1996, 13 INT C MACH LEARN; Lai H, 2008, COMPUT VIS IMAGE UND, V111, P329, DOI 10.1016/j.cviu.2008.01.003; Li F, 2005, IEEE T PATTERN ANAL, V27, P1686; LI F, 2009, INT J PATTE IN PRESS; Li Ming, 1997, INTRO KOLMOGOROV COM; Liu CJ, 2001, IEEE T IMAGE PROCESS, V10, P598, DOI 10.1109/83.913594; Liu CJ, 2000, IEEE T PATTERN ANAL, V22, P570, DOI 10.1109/34.862196; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; PHILLIPS PJ, 2005, OVERVIEW FACE RECOGN; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Pinto N., 2008, WORKSH FAC REAL LIF; Pinto Nicolas, 2008, PLOS COMPUTATIONAL B, V4, P0151; PONCE J, 2006, LECT NOTES COMPUTER; PUJOL A, 2001, INT C IM AN PROC, P273; RAMANATHAN V, 2009, ROBUST FACE I PRESS; Rubinstein Y., 1997, KDD, P49; RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006; RULLEN RV, 1998, BIOSYSTEMS, V48, P229; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Serre T, 2007, P NATL ACAD SCI USA, V104, P6424, DOI 10.1073/pnas.0700622104; Shi J, 2006, COMPUT VIS IMAGE UND, V102, P117, DOI 10.1016/j.cviu.2005.10.002; Sinha P, 2006, P IEEE, V94, P1948, DOI 10.1109/JPROC.2006.884093; Smith JD, 2005, J EXP PSYCHOL LEARN, V31, P1171, DOI 10.1037/0278-7393.31.6.1171; Smith JD, 2005, J EXP PSYCHOL GEN, V134, P443, DOI 10.1037/0096-3445.134.4.443; Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0; Tsunoda K, 2001, NAT NEUROSCI, V4, P832, DOI 10.1038/90547; van Hateren JH, 1998, P ROY SOC B-BIOL SCI, V265, P2315; Vapnik V.N., 1998, STAT LEARNING THEORY; VOVK V, 1999, 16 INT C MACH LEARN; VYGOTSKY L, 1976, MIND SOC	48	0	0	ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	1045-926X		J VISUAL LANG COMPUT	J. Vis. Lang. Comput.	JUN	2009	20	3					145	155		10.1016/j.jvlc.2009.01.001		11	Computer Science, Software Engineering	Computer Science	449RI	WOS:000266347300003	
J	Yang, HQ; Huang, KZ; King, I; Lyu, MR				Yang, Haiqin; Huang, Kaizhu; King, Irwin; Lyu, Michael R.			Localized support vector regression for time series prediction	NEUROCOMPUTING			English	Article						Support vector regression; Second order conic programming; Time series prediction	MINIMAX PROBABILITY MACHINE	Time series prediction, especially financial time series prediction, is a challenging task in machine learning. In this issue, the data are usually non-stationary and volatile in nature. Because of its good generalization power, the support vector regression (SVR) has been widely applied in this application. The standard SVR employs a fixed epsilon-tube to tolerate noise and adopts the l(p)-norm (p = 1 or 2) to model the functional complexity of the whole data set. One problem of the standard SVR is that it considers data in a global fashion only. Therefore it may lack the flexibility to capture the local trend of data; this is a critical aspect of volatile data, especially financial time series data. Aiming to attack this issue, we propose the localized support vector regression (LSVR) model. This novel model is demonstrated to provide a systematic and automatic scheme to adapt the margin locally and flexibly; while the margin in the standard SVR is fixed globally. Therefore, the LSVR can tolerate noise adaptively. The proposed LSVR is promising in the sense that it not only captures the local information in data, but more importantly, it establishes connection with several models. More specifically: (1) it can be regarded as the regression extension of a recently proposed promising classification model, the Maxi-Min Margin Machine: (2) it incorporates the standard SVR as a special case under certain mild assumptions. We provide both theoretical justifications and empirical evaluations for this novel model. The experimental results on synthetic data and real financial data demonstrate its advantages over the standard SVR. Crown Copyright (C) 2008 Published by Elsevier B.V. All rights reserved.	[Yang, Haiqin; Huang, Kaizhu; King, Irwin; Lyu, Michael R.] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China	Yang, HQ (reprint author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.	hqyang@cse.cuhk.edu.hk			Council of the Hong Kong SAR, China [CUHK 4125/07E, CUHK 4150/07E]	The work described in this paper was fully supported by two grants from the Research Grants Council of the Hong Kong SAR, China (Project nos. CUHK 4125/07E and CUHK 4150/07E).	Bertsekas D.P., 1999, NONLINEAR PROGRAMMIN; BERTSIMAS D, 1997, INDUCTION LINEAR OPT; Boyd S., 2004, CONVEX OPTIMIZATION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; FERNANDEZ R, 1999, P ECCAI ADV COURS AR; Fukunaga K., 1990, INTRO STAT PATTERN R; HUANG K, 2004, 21 INT C MACH LEARN, P401; HUANG K, 2004, P 2004 IEEE COMP SOC, V2, P558; HUANG K, 2006, P INT JOINT C NEUR N; Huang KZ, 2006, IEEE T SYST MAN CY B, V36, P913, DOI 10.1109/TSMCB.2006.870610; Huang KZ, 2004, J MACH LEARN RES, V5, P1253; Huang KZ, 2006, IEEE T BIO-MED ENG, V53, P821, DOI 10.1109/TBME.2006.872819; Huang KZ, 2008, IEEE T NEURAL NETWOR, V19, P260, DOI 10.1109/TNN.2007.905855; KHEMCHANDANI R, 2007, EXPERT SYSTEMS APPL, V36, P132; Lanckriet G. R. G., 2003, J MACHINE LEARNING R, V3, P555; Lobo MS, 1998, LINEAR ALGEBRA APPL, V284, P193, DOI 10.1016/S0024-3795(98)10032-0; Montgomery D. C., 1999, APPL STAT PROBABILIT; Nesterov Y., 1994, STUDIES APPL MATH; Platt J., 1998, MSRTR9814; Povinelli RJ, 2003, IEEE T KNOWL DATA EN, V15, P339, DOI 10.1109/TKDE.2003.1185838; PRUESSNER A, 2003, OPTIMIZATION SOFTWAR; Scholkopf B., 2002, LEARNING KERNELS; Scholkopf B, 1999, ADV NEUR IN, V11, P330; Smola A.J., 1998, NCTR98030 NEUROCOLT; STROHMANN TR, 2003, ADV NEURAL INFORM PR, V15; Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766; Sturm JF, 2000, HIGH PERFORMANCE OPT, P157; Tay FEH, 2002, NEURAL PROCESS LETT, V15, P179, DOI 10.1023/A:1015249103876; Van Gestel T, 2001, IEEE T NEURAL NETWOR, V12, P809, DOI 10.1109/72.935093; Vapnik V, 1999, NATURE STAT LEARNING; Vapnik V.N., 1998, STAT LEARNING THEORY; Yang HQ, 2002, LECT NOTES COMPUT SC, V2412, P391; Yang HQ, 2004, STUD FUZZ SOFT COMP, V152, P334	34	6	10	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	JUN	2009	72	10-12					2659	2669		10.1016/j.neucom.2008.09.014		11	Computer Science, Artificial Intelligence	Computer Science	454SG	WOS:000266702300064	
J	Hong, SH; Hendrickx, JMH; Borchers, B				Hong, Sung-ho; Hendrickx, Jan M. H.; Borchers, Brian			Up-scaling of SEBAL derived evapotranspiration maps from Landsat (30 m) to MODIS (250 m) scale	JOURNAL OF HYDROLOGY			English	Article						Up-scaling; Evapotranspiration; SEBAL; Landsat; MODIS	SOIL HEAT-FLUX; DIGITAL ELEVATION MODEL; REMOTELY-SENSED DATA; ENERGY-BALANCE; NET-RADIATION; HETEROGENEOUS TERRAIN; EVAPORATIVE FRACTION; SURFACE-TEMPERATURE; SPATIAL VARIABILITY; AVHRR DATA		[Hong, Sung-ho; Hendrickx, Jan M. H.; Borchers, Brian] New Mexico Inst Min & Technol, Earth & Environm Sci, Socorro, NM 87801 USA	Hendrickx, JMH (reprint author), New Mexico Inst Min & Technol, Earth & Environm Sci, Socorro, NM 87801 USA.	hendrick@nmt.edu	Borchers, Brian/C-1984-2008	Borchers, Brian/0000-0001-5370-5811			Allen R. G., 1998, 56 FAO; Allen RG, 2007, J IRRIG DRAIN E-ASCE, V133, P380, DOI 10.1061/(ASCE)0733-9437(2007)133:4(380); ANSELIN L, 1993, SPATIAL STAT ANAL GE; ATKINSON P, 1985, ACSM ASPRS FALL C, P929; Bastiaanssen WGM, 1998, J HYDROL, V212, P198, DOI 10.1016/S0022-1694(98)00253-4; Bastiaanssen WGM, 2005, J IRRIG DRAIN E-ASCE, V131, P85, DOI 10.1061/(ASCE)0733-9437(2005)131:1(85); Bastiaanssen WGM, 2000, J HYDROL, V229, P87, DOI 10.1016/S0022-1694(99)00202-4; Bian L, 1999, PHOTOGRAMM ENG REM S, V65, P73; BIAN L, 1997, MULTISCALE NATURE SP; BROWN DG, 1993, COMPUT GEOSCI, V19, P499, DOI 10.1016/0098-3004(93)90078-J; Brutsaert W., 1982, EVAPORATION ATMOSPHE; BRUTSAERT W, 1992, J GEOPHYS RES-ATMOS, V97, P18377; Carmel Y, 2001, PHOTOGRAMM ENG REM S, V67, P865; Carmel Y, 2004, IEEE GEOSCI REMOTE S, V1, P39, DOI 10.1109/LGRS.2004.823453; CHEHBOUNI A, 1995, J CLIMATE, V8, P1386, DOI 10.1175/1520-0442(1995)008<1386:AFASPA>2.0.CO;2; CHOUDHURY BJ, 1987, AGR FOREST METEOROL, V39, P283, DOI 10.1016/0168-1923(87)90021-9; Cihlar J, 1997, REMOTE SENS ENVIRON, V60, P35, DOI 10.1016/S0034-4257(96)00137-X; CLOTHIER BE, 1986, AGR FOREST METEOROL, V37, P319, DOI 10.1016/0168-1923(86)90069-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crago RD, 1996, J HYDROL, V180, P173, DOI 10.1016/0022-1694(95)02903-6; Croley TE, 2005, J HYDROL ENG, V10, P182, DOI 10.1061/(ASCE)1084-0699(2005)10:3(182); Dai XL, 1998, IEEE T GEOSCI REMOTE, V36, P1566; DAUGHTRY CST, 1990, REMOTE SENS ENVIRON, V32, P111, DOI 10.1016/0034-4257(90)90012-B; DECOLA L, 1994, INT J GEOGR INF SYST, V8, P411, DOI 10.1080/02693799408902011; Dodgson NA, 1997, IEEE T IMAGE PROCESS, V6, P1322, DOI 10.1109/83.623195; EBLERINGER JR, 1993, SCALING PHYSL PROCES; Eugenio F, 2003, IEEE T GEOSCI REMOTE, V41, P2869, DOI 10.1109/TGRS.2003.817226; Farah H., 2004, INT J APPL EARTH OBS, V5, P129, DOI 10.1016/j.jag.2004.01.003; FRENCH AN, 2001, THESIS U MARYLAND CO; French AN, 2002, AGRONOMIE, V22, P105, DOI 10.1051/agro:2001010; Gentine P, 2007, AGR FOREST METEOROL, V143, P13, DOI 10.1016/j.agrformet.2006.11.002; Gupta V. K., 1986, SCALE PROBLEMS HYDRO; Hendrickx JMH, 2005, P SOC PHOTO-OPT INS, V5811, P138, DOI 10.1117/12.603361; Hong SH, 2005, P SOC PHOTO-OPT INS, V5811, P147, DOI 10.1117/12.603385; Hong S.H., 2008, THESIS NEW MEXICO I; KUSTAS WP, 1993, REMOTE SENS ENVIRON, V46, P319, DOI 10.1016/0034-4257(93)90052-Y; LAM NSN, 1992, PROF GEOGR, V44, P88, DOI 10.1111/j.0033-0124.1992.00088.x; LHOMME JP, 1992, AGR FOREST METEOROL, V61, P11, DOI 10.1016/0168-1923(92)90022-V; LI B, 1994, J CLIMATE, V7, P527, DOI 10.1175/1520-0442(1994)007<0527:TIOSVO>2.0.CO;2; Liang S, 2004, QUANTITATIVE REMOTE; Liang SL, 2002, REMOTE SENS ENVIRON, V83, P149, DOI 10.1016/S0034-4257(02)00092-5; Liang SP, 2000, J PROTEIN CHEM, V19, P225, DOI 10.1023/A:1007011904904; Maayar M. E., 2006, Remote Sensing of Environment, V102, DOI 10.1016/j.rse.2006.01.017; MARK DM, 1984, J INT ASS MATH GEOL, V16, P671, DOI 10.1007/BF01033029; Mecikalski JR, 1999, J APPL METEOROL, V38, P1352, DOI 10.1175/1520-0450(1999)038<1352:EFOCSU>2.0.CO;2; Mengelkamp HT, 2006, B AM METEOROL SOC, V87, P775, DOI 10.1175/BAMS-87-6-775; Morse A., 2000, APPL SEBAL METHODOLO; NELLIS M D, 1989, Landscape Ecology, V2, P93, DOI 10.1007/BF00137153; NISHIDA K, 2003, J GEOGRAPH RES, V108, DOI DOI 10.1029/2002JD002062; PRICE JC, 1984, J GEOPHYS RES-ATMOS, V89, P7231, DOI 10.1029/JD089iD05p07231; QUATTROCHI DA, 1997, SCALE MULTISCALING R; SEGUIN B, 1991, REMOTE SENS ENVIRON, V35, P141, DOI 10.1016/0034-4257(91)90007-S; SEYFRIED MS, 1995, WATER RESOUR RES, V31, P173, DOI 10.1029/94WR02025; Shuttleworth W. J., 1989, IAHS PUBL, V186, P67; SHUTTLEWORTH WJ, 1991, REV GEOPHYS, V29, P585, DOI 10.1029/91RG01815; STOMS DM, 1992, PHOTOGRAMM ENG REM S, V58, P1587; Tasumi M., 2003, THESIS U IDAHO MOSCO; TOWNSHEND JRG, 1992, IEEE T GEOSCI REMOTE, V30, P1054, DOI 10.1109/36.175340; Turner MG, 1989, LANDSCAPE ECOL, V3, P153, DOI 10.1007/BF00131534; Van Rompaey AJJ, 1999, INT J GEOGR INF SCI, V13, P577, DOI 10.1080/136588199241120; Vazquez DP, 1997, REMOTE SENS ENVIRON, V62, P215, DOI 10.1016/S0034-4257(97)00091-6; Vieux B. E., 1993, J COMPUT CIVIL ENG, V7, P310, DOI 10.1061/(ASCE)0887-3801(1993)7:3(310); WOLOCK DM, 1994, WATER RESOUR RES, V30, P3041, DOI 10.1029/94WR01971; ZHANG WH, 1994, WATER RESOUR RES, V30, P1019, DOI 10.1029/93WR03553; *ERDAS, 2002, FIELD GUID	65	14	15	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0022-1694		J HYDROL	J. Hydrol.	MAY 30	2009	370	1-4					122	138		10.1016/j.jhydrol.2009.03.002		17	Engineering, Civil; Geosciences, Multidisciplinary; Water Resources	Engineering; Geology; Water Resources	453WY	WOS:000266644800012	
J	Baroni, MV; Arrua, C; Nores, ML; Faye, P; Diaz, MDP; Chiabrando, GA; Wunderlin, DA				Veronica Baroni, Maria; Arrua, Carina; Laura Nores, Maria; Faye, Pablo; del Pilar Diaz, Maria; Alberto Chiabrando, Gustavo; Alberto Wunderlin, Daniel			Composition of honey from Cordoba (Argentina): Assessment of North/South provenance by chemometrics	FOOD CHEMISTRY			English	Article						Honey; Geographical origin; Metals; Chemical traceability; Multivariate statistics	AMINO-ACID-COMPOSITION; MINERAL-CONTENT; PHYSICOCHEMICAL CHARACTERISTICS; FLUORESCENCE SPECTROSCOPY; GEOGRAPHICAL ORIGIN; BOTANICAL ORIGIN; SPANISH HONEYS; FLORAL ORIGIN; CLASSIFICATION; POLLEN	We report the characterisation of honey samples produced in Cordoba (Argentina) and their classification by geographical provenance (North/South) using chemometrics. Twenty-two variables were analysed considering both chemical properties and mineral profile. Honey samples were found to meet the international specifications for the evaluated parameters. Classification of honey in according to its geographical provenance (North/South) was achieved by pattern recognition techniques applied to 15 out of 22 variables. Glucose. pH, free acidity, free amino acids, calcium and zinc were selected by stepwise discriminant analysis, explaining the classification of honey according to their geographical origin. Application of k-nearest-neighbour classification procedure to these six selected variables produced a successful assignation (99% correct) of honey to its provenance. On the other hand only 83% right assignation was observed, when the 15 variables were used, confirming that the use of all available features is unnecessary to get good geographical discrimination. (C) 2008 Elsevier Ltd. All rights reserved.	[Veronica Baroni, Maria; Arrua, Carina; Alberto Chiabrando, Gustavo; Alberto Wunderlin, Daniel] Univ Nacl Cordoba, CONICET, Fac Ciencias Quim, Dto Bioquim Clin, RA-5000 Cordoba, Argentina; [Laura Nores, Maria] Univ Nacl Cordoba, CONICET, Fac Ciencias Med, RA-5000 Cordoba, Argentina; [Faye, Pablo] Univ Nacl Cordoba, Fac Ciencias Agropecuarias, RA-5000 Cordoba, Argentina; [del Pilar Diaz, Maria] Univ Nacl Cordoba, Fac Ciencias Med, Escuela Nutr, RA-5000 Cordoba, Argentina	Wunderlin, DA (reprint author), Univ Nacl Cordoba, CONICET, Fac Ciencias Quim, Dto Bioquim Clin, Ciudad Univ, RA-5000 Cordoba, Argentina.	dwunder@fcq.unc.edu.ar			CONICET (National Research Council-Argentina); Secretaria de Ciencia y Tecnica-Universidad Nacional de Cordoba (Science Secretary of the University of Cordoba)	We thank CONICET (National Research Council-Argentina) and Secretaria de Ciencia y Tecnica-Universidad Nacional de Cordoba (Science Secretary of the University of Cordoba) for a fellowship and financial support.	Anklam E, 1998, FOOD CHEM, V63, P549, DOI 10.1016/S0308-8146(98)00057-0; Baroni MV, 2006, J AGR FOOD CHEM, V54, P7235, DOI 10.1021/jf061080e; Baroni MV, 2002, J AGR FOOD CHEM, V50, P1362, DOI 10.1021/jf011214i; Baroni MV, 2004, J AGR FOOD CHEM, V52, P7222, DOI 10.1021/jf049068e; Buldini PL, 2001, FOOD CHEM, V73, P487, DOI 10.1016/S0308-8146(01)00132-7; Cometto PM, 2006, J AGR FOOD CHEM, V54, P9458, DOI 10.1021/jf061325n; Corbella E, 2006, LWT-FOOD SCI TECHNOL, V39, P534, DOI 10.1016/j.lwt.2005.03.011; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devillers J, 2004, FOOD CHEM, V86, P305, DOI 10.1016/j.foodchem.2003.09.029; Downey G, 2005, FOOD CHEM, V91, P347, DOI 10.1016/j.foodchem.2004.06.020; Fernandez-Torres R, 2005, TALANTA, V65, P686, DOI 10.1016/j.talanta.2004.07.030; González Paramás A. M., 2000, Journal of the Science of Food and Agriculture, V80, P157, DOI 10.1002/(SICI)1097-0010(20000101)80:1<157::AID-JSFA506>3.3.CO;2-2; Guler A, 2007, FOOD CHEM, V105, P1119, DOI 10.1016/j.foodchem.2007.02.024; Hernandez OM, 2005, FOOD CHEM, V93, P449, DOI 10.1016/j.foodchem.2004.10.036; Iglesias MT, 2004, J AGR FOOD CHEM, V52, P84, DOI 10.1021/jf030454q; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; Latorre MJ, 2000, ANALYST, V125, P307, DOI 10.1039/a905978d; Munoz E, 2006, FOOD CHEM, V94, P478, DOI 10.1016/j.foodchem.2005.01.022; Nanda V, 2003, J FOOD COMPOS ANAL, V16, P613, DOI 10.1016/S0889-1575(03)00062-0; NELLY S, 2005, TRENDS FOOD SCI TECH, V16, P555; Nozal MJ, 2005, J AGR FOOD CHEM, V53, P3095, DOI 10.1021/jf0489724; Ouchemoukh S, 2007, FOOD CONTROL, V18, P52, DOI 10.1016/j.foodcont.2005.08.007; Perez RA, 2007, J AGR FOOD CHEM, V55, P360, DOI 10.1021/jf062055b; Popek S, 2002, FOOD CHEM, V79, P401, DOI 10.1016/S0308-8146(02)00391-6; Przybylowski P, 2001, FOOD CHEM, V74, P289, DOI 10.1016/S0308-8146(01)00153-4; Rebolo S, 2000, ANAL CHIM ACTA, V417, P211, DOI 10.1016/S0003-2670(00)00929-6; Ruoff K, 2006, J AGR FOOD CHEM, V54, P6858, DOI 10.1021/jf060697t; Sikorska E, 2005, FOOD CHEM, V89, P217, DOI 10.1016/j.foodchem.2004.02.028; Terrab A, 2004, FOOD CHEM, V88, P537, DOI 10.1016/j.foodchem.2004.01.068; Woodcock T, 2007, J AGR FOOD CHEM, V55, P9128, DOI 10.1021/jf072010q; Wunderlin DA, 1998, J AGR FOOD CHEM, V46, P1855, DOI 10.1021/jf9710140; *AOAC, 1995, OFF METH AN ASS OFF, P44; *CAA, 1997, CAP 10 PROD AZ; *COD AL COMM, 1993, 199314 FAOWHO COD AL	34	23	24	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0308-8146		FOOD CHEM	Food Chem.	MAY 15	2009	114	2					727	733		10.1016/j.foodchem.2008.10.018		7	Chemistry, Applied; Food Science & Technology; Nutrition & Dietetics	Chemistry; Food Science & Technology; Nutrition & Dietetics	411PT	WOS:000263662400056	
J	Castro, JL; Navarro, M; Sanchez, JM; Zurita, JM				Castro, J. L.; Navarro, M.; Sanchez, J. M.; Zurita, J. M.			Loss and gain functions for CBR retrieval	INFORMATION SCIENCES			English	Article						CBR; Similarity; Probability; Fuzzy system; Retrieval stage	REASONING SYSTEM; INCREMENTAL DEVELOPMENT; REDUCTION TECHNIQUE; SIMILARITY MEASURES; MEDICAL DIAGNOSIS; DECISION-THEORY; CLASSIFICATION; PREDICTION; WEIGHTS; MODEL	The method described in this article evaluates case similarity in the retrieval stage of case-based reasoning (CBR). It thus plays a key role in deciding which case to select, and therefore, in deciding which solution will be eventually applied. In CBR, there are many retrieval techniques. One feature shared by most is that case retrieval is based on attribute similarity and importance. However, there are other crucial factors that should be considered, such as the possible consequences of a given solution, in other words its potential loss and gain. As their name clearly implies, these concepts are defined as functions measuring loss and gain when a given retrieval case solution is applied. Moreover, these functions help the user to choose the best solution so that when a mistake is made the resulting loss is minimal. In this way, the highest benefit is always obtained. (C) 2009 Elsevier Inc. All rights reserved.	[Castro, J. L.; Navarro, M.; Sanchez, J. M.; Zurita, J. M.] Univ Granada, ETSI Informat, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain	Zurita, JM (reprint author), Univ Granada, ETSI Informat, Dept Comp Sci & Artificial Intelligence, C Daniel Saucedo Aranda S-N, E-18071 Granada, Spain.	castro@decsai.ugr.es; marianj@decsai.ugr.es; jmsa@decsai.ugr.es; zurita@decsai.ugr.es	Castro, Juan Luis/C-2403-2012; Zurita , Jose Manuel/E-1037-2012		Ministerio de Educacion y Ciencia [TIN2006-03122, TIN2004-07236]	The authors would like to thank and Ministerio de Educacion y Ciencia that support this paper with its Projects: TIN2006-03122 and TIN2004-07236. And also to Dr. Lucia Martin Romera for checking the examples.	AAMODT A, 1994, AI COMMUN, V7, P39; Ahn H, 2007, EXPERT SYST APPL, V32, P1011, DOI 10.1016/j.eswa.2006.02.021; Allais M., 1979, EXPECTED UTILITY HYP; Dogan SZ, 2008, J CONSTR ENG M ASCE, V134, P146, DOI 10.1061/(ASCE)0733-9364(2008)134:2(146); Bayes T., 1763, PHILOS T ROY SOC LON, V53, P370, DOI DOI 10.1098/RSBL.1763.0053; BECKER GM, 1964, BEHAV SCI, V9, P226, DOI 10.1002/bs.3830090304; Bichindaritz I, 2006, ARTIF INTELL MED, V36, P127, DOI 10.1016/j.artmed.2005.10.008; CASTRO JL, 2008, P IADIS MULT C COMP, P151; Castro J.L., 2007, P 7 INT C CAS BAS RE, P21; CASTRO JL, 2006, P EUR MED C INF SYST; Chang PC, 2008, EXPERT SYST APPL, V34, P2049, DOI 10.1016/j.eswa.2007.02.011; Cheng MY, 2009, EXPERT SYST APPL, V36, P4106, DOI 10.1016/j.eswa.2008.03.025; Chiu C.C., 2007, LECT NOTES COMPUTER, P541; CHIU CY, 2007, P 4 INT C FUZZ SYST, P344; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daengdej J, 1997, KNOWL-BASED SYST, V10, P153, DOI 10.1016/S0950-7051(97)00027-0; DeGroot M.H., 1970, OPTIMAL STAT DECISIO; EDWARDS AWF, 1974, INT STAT REV, V42, P9, DOI 10.2307/1402681; ELTER M, 2007, COMPUTER ASSISTED RA, V2, P340; FISHBURN PC, 1981, THEOR DECIS, V13, P39; Gancarski P, 2008, PATTERN RECOGN, V41, P983, DOI 10.1016/j.patcog.2007.07.008; Gu M., 2005, IEEE INT C INF REUS, P427; Ha SH, 2008, APPL INTELL, V29, P279, DOI 10.1007/s10489-007-0094-7; Hammond K.J., 1989, CASE BASED PLANNING; Hoffmann A, 2006, APPL ARTIF INTELL, V20, P507, DOI 10.1080/08839510600753782; Hsu CC, 2004, INFORM SCIENCES, V166, P231, DOI 10.1016/j.ins.2003.11.009; Im KH, 2007, EXPERT SYST APPL, V32, P77, DOI 10.1016/j.eswa.2005.11.020; Juarez JM, 2009, FUZZY SET SYST, V160, P214, DOI 10.1016/j.fss.2008.05.017; Keeney RL, 1976, DECISIONS MULTIPLE O; Kolodner J., 1993, CASE BASED REASONING; KOLODNER JL, 1983, COGNITIVE SCI, V7, P281, DOI 10.1207/s15516709cog0704_2; Lavrac N, 1999, ARTIF INTELL MED, V16, P3, DOI 10.1016/S0933-3657(98)00062-1; Leake D.B., 1996, CASE BASED REASONING; Li H, 2006, INFORM SCIENCES, V176, P2960, DOI 10.1016/j.ins.2005.09.003; Li H, 2008, KNOWL-BASED SYST, V21, P868, DOI 10.1016/j.knosys.2008.03.047; Li Qing, 2007, Journal of Beijing University of Aeronautics and Astronautics, V33; Liao TW, 1998, APPL ARTIF INTELL, V12, P267, DOI 10.1080/088395198117730; Liao TW, 2000, ENG APPL ARTIF INTEL, V13, P199, DOI 10.1016/S0952-1976(99)00052-4; Liu CH, 2008, INFORM SCIENCES, V178, P3347, DOI 10.1016/j.ins.2008.05.006; Nash JF, 1950, ECONOMETRICA, V18, P155, DOI 10.2307/1907266; Negny S, 2008, COMPUT-AIDED CHEM EN, V25, P1009; Nunez H, 2004, ENVIRON MODELL SOFTW, V19, P809, DOI 10.1016/j.envsoft.2003.03.003; Park CS, 2002, EXPERT SYST APPL, V23, P255, DOI 10.1016/S0957-4174(02)00045-3; Park YJ, 2006, EXPERT SYST, V23, P2, DOI 10.1111/j.1468-0394.2006.00321.x; Peng J.C., 1975, 78 STANF U DEP STAT; Raphael B, 2007, ADV ENG INFORM, V21, P311, DOI [10.1016/j.aei.2007.02.001, 10.1109/TCAD.2007.02.001]; Renaud J, 2008, MATH COMPUT SIMULAT, V77, P499, DOI 10.1016/j.matcom.2007.11.024; RUBIN H, 1987, STATISTICS DECISIONS, V5, P47; Sadek AW, 2001, TRANSPORT RES C-EMER, V9, P353, DOI 10.1016/S0968-090X(00)00046-2; Schaaf JW, 1996, LECT NOTES ARTIF INT, V1168, P362; Schank R. C., 1977, SCRIPTS PLANS GOALS; Schank R. C., 1982, DYNAMIC MEMORY THEOR; Shin KS, 1999, EXPERT SYST APPL, V16, P85, DOI 10.1016/S0957-4174(98)00063-3; Singh M, 2005, PATTERN RECOGN LETT, V26, P1995, DOI 10.1016/j.patrec.2005.03.015; Smyth B, 1998, ARTIF INTELL, V102, P249, DOI 10.1016/S0004-3702(98)00059-9; Sun ZH, 2004, INFORM SCIENCES, V165, P21, DOI 10.1016/j.ins.2003.09.020; TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116; Tsatsoulis C, 1997, IEEE EXPERT, V12, P46, DOI 10.1109/64.608193; Tsui K.W., 1979, CANAD J STAT, V7, P193, DOI 10.2307/3315119; Wald A., 1950, STAT DECISION FUNCTI; Watson I, 1999, KNOWL-BASED SYST, V12, P303, DOI 10.1016/S0950-7051(99)00020-9; WEERAHANDI S, 1983, ANN STAT, V11, P1032; Witten I., 2005, DATA MINING PRACTICA; Zhuang ZY, 2009, EUR J OPER RES, V195, P662, DOI 10.1016/j.ejor.2007.11.003; ZIDEK JV, 1986, STAT DECISIONS, V4, P1	65	19	23	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255		INFORM SCIENCES	Inf. Sci.	MAY 13	2009	179	11					1738	1750		10.1016/j.ins.2009.01.017		13	Computer Science, Information Systems	Computer Science	435BL	WOS:000265318100017	
J	Zeng, Y; Yang, YP; Zhao, L				Zeng, Yong; Yang, Yupu; Zhao, Liang			Nonparametric classification based on local mean and class statistics	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						k-nearest neighbor classification rule (k-NNR); Local mean; Statistic; Distance measure; Cross-validation		The k-nearest neighbor classification rule (k-NNR) is a very simple, yet powerful nonparametric classification method. As a variant of the k-NNR, a nonparametric classification method based on the local mean vector has achieved good classification performance. In pattern classification, the sample mean and sample covariance are the most important statistics related to class discriminatory information. In this paper, a new variant of the k-NNR, a nonparametric classification method based on the local mean vector and class statistics has been proposed. Not only the local information of the k nearest neighbors of the unclassified pattern in each individual class but also the global knowledge of samples in each individual class are taken into account in this new classification method. The proposed classification method is compared with the k-NNR, and the local mean-based nonparametric classification in terms of the classification error rate on the unknown patterns. Experimental results confirm the validity of this new classification approach. (C) 2008 Elsevier Ltd. All rights reserved.	[Zeng, Yong; Yang, Yupu; Zhao, Liang] Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200240, Peoples R China	Zeng, Y (reprint author), Shanghai Jiao Tong Univ, Dept Automat, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.	zeng_yong@sjtu.edu.cn					Asuncion A., 2007, UCI MACHINE LEARNING; Bhattacharyya A., 1943, Bulletin of the Calcutta Mathematical Society, V35; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 2001, PATTERN CLASSIFICATI; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fukunaga K., 1990, INTRO STAT PATTERN R; Jain A. K., 1988, PATTERN RECOGNITION; Mitani Y, 2006, PATTERN RECOGN LETT, V27, P1151, DOI 10.1016/j.patrec.2005.12.016; PSALTIS D, 1994, IEEE T INFORM THEORY, V40, P667; Rumelhart D E, 1986, PARALLEL DISTRIBUTED; VANNESS J, 1980, PATTERN RECOGN, V12, P355, DOI 10.1016/0031-3203(80)90012-6	11	5	5	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	MAY	2009	36	4					8443	8448		10.1016/j.eswa.2008.10.041		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	423WX	WOS:000264528600126	
J	Wang, Q; Kulkarni, SR; Verdu, S				Wang, Qing; Kulkarni, Sanjeev R.; Verdu, Sergio			Divergence Estimation for Multidimensional Densities Via k-Nearest-Neighbor Distances	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article; Proceedings Paper	IEEE International Symposium on Information Theory	JUL 09-14, 2006	Seattle, WA	IEEE Informat Theory Soc, USN, Dept Navy Sci & Technol, Microsoft, Natl Sci Fdn		Divergence; information measure; Kullback-Leibler; nearest-neighbor; partition; random vector; universal estimation	MUTUAL INFORMATION; CONSISTENCY; ENTROPY	A new universal estimator of divergence is presented for multidimensional continuous densities based on k-nearest-neighbor (k-NN) distances. Assuming independent and identically distributed (i.i.d.) samples, the new estimator is proved to be asymptotically unbiased and mean-square consistent. In experiments with high-dimensional data, the k-NN approach generally exhibits faster convergence than previous algorithms. It is also shown that the speed of convergence of the k-NN method can be further improved by an adaptive choice of k.	[Wang, Qing] Credit Suisse Grp, New York, NY 10010 USA; [Kulkarni, Sanjeev R.; Verdu, Sergio] Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA	Wang, Q (reprint author), Credit Suisse Grp, New York, NY 10010 USA.	qingwang@princeton.edu; kulkarni@princeton.edu; verdu@princeton.edu					Bentley JL, 1975, COMMUN ACM, V18; BHATTACH.PK, 1967, ANN MATH STAT, V38, P1770, DOI 10.1214/aoms/1177698611; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASU T, 2006, P 38 S INT STAT COMP; Dawy Z, 2006, IEEE ACM T COMPUT BI, V3, P47, DOI 10.1109/TCBB.2006.9; DAWY Z, 2005, P 2005 IEEE INT C CO, V2, P815; DEVROYE L, 1996, PROBABLISTIC THEORY; DEVROYE LP, 1977, ANN STAT, V5, P536, DOI 10.1214/aos/1176343851; Devroye L., 1987, PROGR PROBABILITY ST, V14; DEVROYE L, 1994, ANN STAT, V22, P1371, DOI 10.1214/aos/1176325633; Dhillon I. S., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753661; Feller W., 1970, INTRO PROBABILITY TH; Fix E., 1951, 4 USAF SCH AV MED; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; Goldberger J., 2003, P 9 IEEE INT C COMP, V1, P487, DOI 10.1109/ICCV.2003.1238387; Goria MN, 2005, J NONPARAMETR STAT, V17, P277, DOI 10.1080/104852504200026815; Hinneburg A., 2000, P 26 INT C VER LARG, P506; Johnson DH, 2001, J COMPUT NEUROSCI, V10, P47, DOI 10.1023/A:1008968010214; Kozachenko L. F., 1987, Problems of Information Transmission, V23; Kraskov A., 2004, PHYS REV E, V69; KRISHNAMURTHY B, 2005, P 21 INT C DAT ENG W, P1185; Kulkarni SR, 2002, IEEE T INFORM THEORY, V48, P2785, DOI 10.1109/TIT.2002.802611; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Lebesgue H, 1910, ANN ECOLE NORM, V27, P361; Leonenko N, 2008, TATRA MT MATH PUBL, V39, P265; Liu C., 2003, P IEEE C COMP VIS PA, V1, P587; Loeve M., 1977, PROBABILITY THEORY; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MATHIASSEN JR, 2002, P 7 EUR C COMP VIS 3, P133; Ramirez J, 2004, IEEE SIGNAL PROC LET, V11, P266, DOI 10.1109/LSP.2003.821762; Sarkis M, 2007, IEEE SIGNAL PROC MAG, V24, P83, DOI 10.1109/MSP.2007.273061; SCHNEIDMAN E, 2003, ADV NEURAL INFORM PR, V15, P197; Silverman B.W., 1986, DENSITY ESTIMATION S; Steuer R, 2002, BIOINFORMATICS, V18, pS231; Tsybakov AB, 1996, SCAND J STAT, V23, P75; Verdu S, 2005, Proceedings of the IEEE ITSOC Information Theory Workshop 2005 on Coding and Complexity, P232; VICTOR JD, 2002, PHYS REV E, V66; Wang Q, 2005, IEEE T INFORM THEORY, V51, P3064, DOI 10.1109/TIT.2005.853314; WANG Q, 2006, P INT S INF THEOR, P242; Wilson R, 2007, IEEE T INF FOREN SEC, V2, P364, DOI 10.1109/TIFS.2007.902666; Ye C., 2006, P IEEE INT S INF THE, P2593	41	17	17	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9448		IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	MAY	2009	55	5					2392	2405		10.1109/TIT.2009.2016060		14	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	440PU	WOS:000265713000034	
J	Lazzaroni, M; Ferrari, S; Cristaldi, L; Annoni, M				Lazzaroni, Massimo; Ferrari, Stefano; Cristaldi, Loredana; Annoni, Massimiliano			Nozzle and Working-Condition Classifications for Water Jet Systems	IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT			English	Article						Fault diagnosis; feature extraction; pattern classification; pattern recognition (PR); power measurement; statistical process control; water jet systems		In this paper, a technique for assessing both the working and healthy conditions of water jet-system nozzles is presented. The proposed classifier is based on the discrete Fourier transform (DFT) of the instantaneous electrical power signal. With this in mind, it will be shown that the electrical power signal supports all necessary information to characterize both the working condition of the system and the nozzle type. Furthermore, the same signal can be analyzed with the aim of predicting the presence of an incoming faulty behavior. The presented technique is also used to build a second type of classifier. While the first one is of general application, the second one can be used when the properties of the orifice are known, and only the working conditions have to be classified. Results show the effectiveness of the proposed approach, which, due to its simplicity, can be embedded in a low-cost real-time diagnostic system. For the sake of clarity, a brief description of a water jet system is also presented.	[Lazzaroni, Massimo; Ferrari, Stefano] Univ Milan, Dept Informat Technol, I-26013 Crema, Italy; [Cristaldi, Loredana] Politecn Milan, Dipartimento Elettrotecn, I-20133 Milan, Italy; [Annoni, Massimiliano] Politecn Milan, Dipartimento Meccan, I-20133 Milan, Italy	Lazzaroni, M (reprint author), Univ Milan, Dept Informat Technol, I-26013 Crema, Italy.	lazzaroni@dti.unimi.it; ferrari@dti.unimi.it; loredana.cristaldi@polimi.it; massimiliano.annoni@polimi.it	Ferrari, Stefano/F-3407-2010				ANNONI A, 2005, P IMTC OTT ON CAN MA, P1311; ANNONI M, 2004, P 17 INT C WAT JETT, P415; ANNONI M, 2007, P IEEE INSTR MEAS TE, P1; BRIAN C, 2003, MATH COMP MODEL DYN, V9, P45; CHALMERS EJ, 1993, P 7 AM WAT JET C AUG, P327; Cherkassky V, 1998, LEARNING DATA; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristaldi L, 2004, IEEE T INSTRUM MEAS, V53, P1020, DOI 10.1109/TIM.2004.830589; Friedman M, 1999, INTRO PATTERN RECOGN; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; Jain A. K., 2000, IEEE T PATTERN ANAL, V22, P1; LAZZARONI M, 2008, P IEEE INT INSTR MEA, P1435; RAMULU M, 1999, P 10 AM WAT C; SINGH PJ, 1997, P 9 AM WAT C, P397; TUNKEL RN, 1997, P 9 AM WAT C	15	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9456		IEEE T INSTRUM MEAS	IEEE Trans. Instrum. Meas.	MAY	2009	58	5					1546	1554		10.1109/TIM.2009.2012961		9	Engineering, Electrical & Electronic; Instruments & Instrumentation	Engineering; Instruments & Instrumentation	435WH	WOS:000265373500033	
J	Diamantini, C; Potena, D				Diamantini, Claudia; Potena, Domenico			Bayes Vector Quantizer for Class-Imbalance Problem	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						Class imbalance; labeled vector quantizer; average misclassification risk minimization; cost-sensitive learning		The class-imbalance problem is the problem of learning a classification rule from data that are skewed in favor of one class. On these data sets, traditional learning techniques tend to overlook the less numerous classes, at the advantage of the majority class. However, the minority class is often the most interesting one for the task at hand. For this reason, the class-imbalance problem has received increasing attention in the last few years. In the present paper, we point the attention of the reader to a learning algorithm for the minimization of the average misclassification risk. In contrast to some popular class-imbalance learning methods, this method has its roots in statistical decision theory. A particular interesting characteristic is that when class distributions are unknown, the method can work by resorting to stochastic gradient algorithm. We study the behavior of this algorithm on imbalanced data sets, demonstrating that this principled approach allows to obtain better classification performances compared to the principal methods proposed in the literature.	[Diamantini, Claudia; Potena, Domenico] Univ Politecn Marche, Dipartimento Ingn Informat Gest & Automaz, I-60131 Ancona, Italy	Diamantini, C (reprint author), Univ Politecn Marche, Dipartimento Ingn Informat Gest & Automaz, Via Brecce Bianche 12, I-60131 Ancona, Italy.	diamantin@diiga.univpm.it; potena@diiga.univpm.it					Akbani R, 2004, P 15 EUR C MACH LEAR, P39; Asuncion A., 2007, UCI MACHINE LEARNING; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DIAMANTINI C, 2000, ACM SIGKDD EXPLORATI, V2, P54; Diamantini C, 1998, IEEE T NEURAL NETWOR, V9, P174, DOI 10.1109/72.655039; Dietterich T.G., 2002, HDB BRAIN THEORY NEU; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Drummond C., 2003, ICML WORKSH LEARN IM; Elkan C, 2001, P 17 INT JOINT C ART, P973; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Fukunaga K., 1990, INTRO STAT PATTERN R; Gersho A., 1992, VECTOR QUANTIZATION; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hartigan J., 1975, CLUSTERING ALGORITHM; HAYKIN S, 1999, NEURAL NETWORKS COMP; KARAKOULAS G, 1999, P NEUR INF PROC WORK, P253; Kohonen T., 1988, P IEEE INT C NEUR NE, V1, P61; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Kubat M, 1997, P 9 EUR C MACH LEARN, P146; KUKAR M, 1998, P 10 EUR C MACH LEAR, P268; Liu XY, 2006, IEEE DATA MINING, P970; Liu XY, 2006, IEEE DATA MINING, P965; Maloof M.A., 2003, ICML WORKSH LEARN IM; Margineantu D., 2002, P 13 EUR C MACH LEAR, P270; MELVILLE P, 2005, P 16 EUR C MACH LEAR, P268; Provost F, 2000, AAAI WORKSH LEARN IM, P1; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Richard M. D., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.4.461; Saitta L., 2000, MACHINE LEARNING TEC; Sheng V.S., 2006, P 21 NAT C ART INT, P476; Ting K., 2000, P 17 INT C MACH LEAR, P983; Ting KM, 2002, IEEE T KNOWL DATA EN, V14, P659; Vapnik V.N., 1998, STAT LEARNING THEORY; Veropoulos K, 1999, P INT JOINT C ART IN, P55; Vlachos M., 2002, P 8 ACM SIGKDD INT C, P645; Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849; Weiss G. M., 2004, ACM SIGKDD EXPLORATI, V6, P7, DOI 10.1145/1007730.1007734; Witten I., 2005, DATA MINING PRACTICA; Wu G, 2005, IEEE T KNOWL DATA EN, V17, P786, DOI 10.1109/TKDE.2005.95; Zhou ZH, 2006, IEEE T KNOWL DATA EN, V18, P63	41	5	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAY	2009	21	5					638	651		10.1109/TKDE.2008.187		14	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	420PB	WOS:000264300600003	
J	Li, FY; Wechsler, H				Li, Fayin; Wechsler, Harry			FACE AUTHENTICATION USING RECOGNITION-BY-PARTS, BOOSTING AND TRANSDUCTION	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article						Authentication; biometrics; boosting; clustering; cross-validation; data fusion; dimensionality reduction; face recognition; feature selection; forensics; k-nearest neighbor; likelihood ratio; margin; Neyman-Pearson; occlusion; open set recognition; p-values; ranking; recognition-by-parts; segmentation; SIFT; strangeness; surveillance; transduction; typicality	FORENSIC SPEAKER RECOGNITION; OBJECT RECOGNITION; CORTEX	The paper describes an integrated recognition-by-parts architecture for reliable and robust face recognition. Reliability and robustness are characteristic of the ability to deploy full-fledged and operational biometric engines, and handling adverse image conditions that include among others uncooperative subjects, occlusion, and temporal variability, respectively. The architecture proposed is model-free and non-parametric. The conceptual framework draws support from discriminative methods using likelihood ratios. At the conceptual level it links forensics and biometrics, while at the implementation level it links the Bayesian framework and statistical learning theory (SLT). Layered categorization starts with face detection using implicit rather than explicit segmentation. It proceeds with face authentication that involves feature selection of local patch instances including dimensionality reduction, exemplar-based clustering of patches into parts, and data fusion for matching using boosting driven by parts that play the role of weak-learners. Face authentication shares the same implementation with face detection. The implementation, driven by transduction, employs proximity and typicality (ranking) realized using strangeness and p-values, respectively. The feasibility and reliability of the proposed architecture are illustrated using FRGC data. The paper concludes with suggestions for augmenting and enhancing the scope and utility of the proposed architecture.	[Li, Fayin; Wechsler, Harry] George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA	Li, FY (reprint author), George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA.	fayin.li@gmail.com; wechsler@gmu.edu					Anderson K, 2004, COMPUT VIS IMAGE UND, V95, P184, DOI 10.1016/j.cviu.2004.01.001; ASHRAF AB, 2008, LEARNING PATCH CORRE; Balas B.J., 2006, ACM T APPL PERCEPT, V3, P354, DOI 10.1145/1190036.1190038; Barlow H. B., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.3.295; BLACK B, 1994, TEX LAW REV, V72, P715; Champod C, 2000, SPEECH COMMUN, V31, P193, DOI 10.1016/S0167-6393(99)00078-3; Chapelle O., 2006, SEMISUPERVISED LEARN; Cherkassky V, 2007, LEARNING DATA; COTT HB, 1966, ADAPTIVE COLORATION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DESSIMOZ D, 2008, HDB BIOMETRICS; DHILLON IS, 2004, KERNEL K MEANS SPECT; Duda R.O., 2000, PATTERN CLASSIFICATI; Edelman G.M., 1987, NEURAL DARWINISM; El-Yaniv R, 2005, PATTERN RECOGN LETT, V26, P2104, DOI 10.1016/j.patrec.2005.03.025; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Freund Y., 1996, 13 INT C MACH LEARN, P148; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Gonzalez-Rodriguez J, 2007, IEEE T AUDIO SPEECH, V15, P2104, DOI 10.1109/TASL.2007.902747; GURARI EM, 1982, IEEE T PATTERN ANAL, V4, P304; GUTTA S, 2004, 1 INT C BIOM AUTH HO; Heisele B, 2007, INT J COMPUT VISION, V74, P167, DOI 10.1007/s11263-006-0006-z; Heisele B, 2003, COMPUT VIS IMAGE UND, V91, P6, DOI 10.1016/S1077-3142(03)00073-0; Ho SS, 2008, IEEE T PATTERN ANAL, V30, P1557, DOI 10.1109/TPAMI.2007.70811; KOLLER D, 1996, 13 INT C MACH LEARN; LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173; Lai H, 2008, COMPUT VIS IMAGE UND, V111, P329, DOI 10.1016/j.cviu.2008.01.003; Li F, 2005, IEEE T PATTERN ANAL, V27, P1686; Li Ming, 1997, INTRO KOLMOGOROV COM; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; LUCEY S, 2006, LEARNING PATCH DEPEN; McNeill Daniel, 1998, FACE NATURAL HIST; Melluish T., 2001, TYPICALNESS FRAMEWOR; PHILLIPS PJ, 2005, COMPUTER VISION PATT; Pinto N., 2008, PLOS COMPUTATIONAL B, V4, P151; PRODROU K, 2002, P 13 EUR C MACH LEAR, P381; Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714; Rubinstein Y., 1997, KDD, P49; RULLEN RV, 1998, BIOSYSTEMS, V48, P229; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Singh R, 2009, IMAGE VISION COMPUT, V27, P245, DOI 10.1016/j.imavis.2007.06.010; Sinha P, 2006, P IEEE, V94, P1948, DOI 10.1109/JPROC.2006.884093; Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0; Tsunoda K, 2001, NAT NEUROSCI, V4, P832, DOI 10.1038/90547; Vapnik VN, 2000, NATURE STAT LEARNING; Vapnik V.N., 1998, STAT LEARNING THEORY; Viola P., 2001, RAPID OBJECT DETECTI; VOVK V, 1999, 16 INT C MACH LEARN; WISCOTT L, 1997, IEEE PATTERN RECOGNI, V19, P775	49	4	4	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014		INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	MAY	2009	23	3					545	573				29	Computer Science, Artificial Intelligence	Computer Science	459PC	WOS:000267114600009	
J	Wang, LW; Sugiyama, M; Yang, C; Hatano, K; Feng, JF				Wang, Liwei; Sugiyama, Masashi; Yang, Cheng; Hatano, Kohei; Feng, Jufu			Theory and Algorithm for Learning with Dissimilarity Functions	NEURAL COMPUTATION			English	Article							COVARIATE SHIFT; REPRESENTATION; CLASSIFICATION; RECOGNITION; DISTANCE; KERNELS; IMAGES	We study the problem of classification when only a dissimilarity function between objects is accessible. That is, data samples are represented not by feature vectors but in terms of their pairwise dissimilarities. We establish sufficient conditions for dissimilarity functions to allow building accurate classifiers. The theory immediately suggests a learning paradigm: construct an ensemble of simple classifiers, each depending on a pair of examples; then find a convex combination of them to achieve a large margin. We next develop a practical algorithm referred to as dissimilarity-based boosting (DBoost) for learning with dissimilarity functions under theoretical guidance. Experiments on a variety of databases demonstrate that the DBoost algorithm is promising for several dissimilarity measures widely used in practice.	[Wang, Liwei; Yang, Cheng; Feng, Jufu] Peking Univ, MOE Sch Elect Engn & Comp Sci, Key Lab Machine Percept, Beijing 100871, Peoples R China; [Sugiyama, Masashi] Tokyo Inst Technol, Dept Comp Sci, Meguro Ku, Tokyo 1528552, Japan; [Hatano, Kohei] Kyushu Univ, Dept Informat, Nishi Ku, Fukuoka 8190395, Japan	Wang, LW (reprint author), Peking Univ, MOE Sch Elect Engn & Comp Sci, Key Lab Machine Percept, Beijing 100871, Peoples R China.	wanglw@cis.pku.edu.cn; sugi@cs.titech.ac.jp; yangch@cis.pku.edu.cn; hatano@i.kyushu-u.ac.jp; fjf@cis.pku.edu.cn			NSFC [60775005, 60635030]; Tokyo Institute of Technology	We thank Masayuki Takeda for kindly providing us Japanese song data, and we also thank Kazuhito Hagio for preprocessing them. This work was supported by NSFC(60775005, 60635030) and Global COE Program of the Tokyo Institute of Technology.	Asuncion A., 2007, UCI MACHINE LEARNING; Balcan MF, 2008, MACH LEARN, V72, P89, DOI 10.1007/s10994-008-5059-5; BALCAN MF, 2006, P INT C MACH LEARN; Balcan MF, 2006, MACH LEARN, V65, P79, DOI 10.1007/s10994-006-7550-1; BALCAN MF, 2004, P INT WORKSH ALG LEA; BALCAN MF, 2008, P 21 ANN C LEARN THE; BREIMAN L, 1984, CLASSIFICATION TREES; Chang C, 2001, LIB SUPPORT VECTOR M; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FREUND Y, 1996, P INT C MACH LEARN S; Fukunaga K., 1990, INTRO STAT PATTERN R; Gartner T., 2003, SIGKDD EXPLORATIONS, V5, pS268; Goldfarb L., 1985, PROGR PATTERN RECOGN, V2, P241; GRAEPEL T, 1999, ADV NEURAL INFORM PR, V12; HAGIO K, 2006, THESIS KYUSHU U; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; Jain AK, 1997, IEEE T PATTERN ANAL, V19, P1386, DOI 10.1109/34.643899; Li JL, 2002, IEEE T IMAGE PROCESS, V11, P636, DOI 10.1109/TIP.2002.1014995; Maltoni D., 2003, HDB FINGERPRINT RECO; Pekalska E, 2002, PATTERN RECOGN LETT, V23, P943, DOI 10.1016/S0167-8655(02)00024-7; Saigo H, 2004, BIOINFORMATICS, V20, P1682, DOI 10.1093/bioinformatics/bth141; Schapire RE, 1998, ANN STAT, V26, P1651; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Shimodaira H, 2000, J STAT PLAN INFER, V90, P227, DOI 10.1016/S0378-3758(00)00115-4; Simard P., 1993, ADV NEURAL INFORM PR, V5; SREBRO N, 2007, P 20 ANN C LEARN THE; Sugiyama M, 2007, J MACH LEARN RES, V8, P985; Vapnik V.N., 1998, STAT LEARNING THEORY; WANG L, 2008, P 21 ANN C LEARN THE; Wang LW, 2005, IEEE T PATTERN ANAL, V27, P1334; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342	32	2	2	M I T PRESS	CAMBRIDGE	238 MAIN STREET, STE 500, CAMBRIDGE, MA 02142-1046 USA	0899-7667		NEURAL COMPUT	Neural Comput.	MAY	2009	21	5					1459	1484		10.1162/neco.2008.08-06-805		26	Computer Science, Artificial Intelligence	Computer Science	446FT	WOS:000266106800010	
J	Wang, Y; Li, L; Ni, J; Huang, SH				Wang, Yong; Li, Lin; Ni, Jun; Huang, Shuhong			Feature selection using tabu search with long-term memories and probabilistic neural networks	PATTERN RECOGNITION LETTERS			English	Article						Feature selection; Tabu Search; Probabilistic neural network; Curse of dimensionality; Smoothing parameter	PATTERN-CLASSIFICATION; BOUND ALGORITHM; BRANCH	Feature selection is a dimensionality reduction problem in order to reduce measurement costs, shorten computational time, relieve the curse of dimensionality. and improve classification accuracy. In this paper, a hybrid approach using tabu search and probabilistic neural networks is proposed and applied to feature selection problems. The proposed tabu search algorithm differs from previous research by using a long-term memory instead of a short-term memory to avoid the necessity of the delicate tuning of the memory length and to decrease the risk of generating a cycle that traps the search in local optimal Solutions. The probabilistic neural networks integrated in the proposed hybrid approach are an outgrowth of Bayesian classifiers that outperform backpropagation-based neural networks in their global convergence and rapid training. Extensive experiments on real-world data sets are performed and the comparison with previous research indicates that the proposed hybrid approach can select an equal or smaller number of features while improving classification accuracy. (C) 2009 Elsevier B.V. All rights reserved.	[Wang, Yong; Li, Lin; Ni, Jun] Univ Michigan, Dept Mech Engn, Ann Arbor, MI 48105 USA; [Wang, Yong; Huang, Shuhong] Huazhong Univ Sci & Technol, Sch Energy & Power Engn, Wuhan 430074, Peoples R China	Li, L (reprint author), Univ Michigan, Dept Mech Engn, Ann Arbor, MI 48105 USA.	lilz@umich.edu			China Scholarship Council; S.M. Wu Manufacturing Research Center at the University of Michigan-Ann Arbor	This work is sponsored by China Scholarship Council and S.M. Wu Manufacturing Research Center at the University of Michigan-Ann Arbor. The authors Would like to thank the UCI Machine Learning Repository for providing the data sets used in this paper. The authors Would also like to thank Dr. Muhammad Atif Tahir for his helpful explanations to our questions regarding to his work (Tahir et al., 2007).	Asuncion A., 2007, UCI MACHINE LEARNING; Billings SA, 2007, NEURAL NETWORKS, V20, P1081, DOI 10.1016/j.neunet.2007.09.017; Bishop C. M., 1995, NEURAL NETWORKS PATT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1977, IEEE T SYST MAN CYB, V7, P657, DOI 10.1109/TSMC.1977.4309803; Dreo J., 2006, METAHEURISTICS HARD; FOROUTAN I, 1987, IEEE T SYST MAN CYB, V17, P187, DOI 10.1109/TSMC.1987.4309029; GLOVER F, 1986, COMPUT OPER RES, V13, P533, DOI 10.1016/0305-0548(86)90048-1; Glover F., 1997, TABU SEARCH; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; HUANG CJ, 2003, P 15 IEEE INT C TOOL; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Kohavi R, 1997, ARTIF INTELL, V1, P273; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Mao KZ, 2000, IEEE T NEURAL NETWOR, V11, P1009, DOI 10.1109/72.857781; NARENDRA P, 1977, IEEE T COMPUT, V26, P917; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; PUDIL P, 1994, PATTERN RECOGN, V2, P279, DOI 10.1109/ICPR.1994.576920; Ripley B. D., 1996, PATTERN RECOGNITION; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; Somol P, 1999, PATTERN RECOGN LETT, V20, P1157, DOI 10.1016/S0167-8655(99)00083-5; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; SPECHT DF, 1992, INT JOINT C NEUR NET; Tahir MA, 2007, PATTERN RECOGN LETT, V28, P438, DOI 10.1016/j.patrec.2006.08.016; TAHIR MA, 2005, EURASIP J APPL SIG P, V14, P2241; Wasserman P.D., 1993, ADV METHODS NEURAL C; YU B, 1993, PATTERN RECOGN, V26, P883, DOI 10.1016/0031-3203(93)90054-Z; Zhang HB, 2002, PATTERN RECOGN, V35, P701, DOI 10.1016/S0031-3203(01)00046-2	28	7	7	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	MAY 1	2009	30	7					661	670		10.1016/j.patrec.2009.02.001		10	Computer Science, Artificial Intelligence	Computer Science	440VI	WOS:000265727400002	
J	Maas, MC; Schaart, DR; van der Laan, DJ; Bruyndonckx, P; Lemaitre, C; Beekman, FJ; van Eijk, CWE				Maas, Marnix C.; Schaart, Dennis R.; van der Laan, D. J. (Jan); Bruyndonckx, Peter; Lemaitre, Cedric; Beekman, Freek J.; van Eijk, Carel W. E.			Monolithic scintillator PET detectors with intrinsic depth-of-interaction correction	PHYSICS IN MEDICINE AND BIOLOGY			English	Article							SMALL ANIMAL PET; SPATIAL-RESOLUTION; MICROPET SCANNER; READ-OUT; PERFORMANCE; DESIGN; TOMOGRAPH; MODULES; SENSITIVITY	We developed positron emission tomography ( PET) detectors based on monolithic scintillation crystals and position-sensitive light sensors. Intrinsic depth-of-interaction (DOI) correction is achieved by deriving the entry points of annihilation photons on the front surface of the crystal from the light sensor signals. Here we characterize the next generation of these detectors, consisting of a 20 mm thick rectangular or trapezoidal LYSO:Ce crystal read out on the front and the back (double-sided readout, DSR) by Hamamatsu S8550SPL avalanche photodiode (APD) arrays optimized for DSR. The full width at half maximum (FWHM) of the detector point-spread function (PSF) obtained with a rectangular crystal at normal incidence equals similar to 1.05 mm at the detector centre, after correction for the similar to 0.9 mm diameter test beam of annihilation photons. Resolution losses of several tenths of a mm occur near the crystal edges. Furthermore, trapezoidal crystals perform almost equally well as rectangular ones, while improving system sensitivity. Due to the highly accurate DOI correction of all detectors, the spatial resolution remains essentially constant for angles of incidence of up to at least 30 degrees. Energy resolutions of similar to 11% FWHM are measured, with a fraction of events of up to 75% in the full-energy peak. The coincidence timing resolution is estimated to be 2.8 ns FWHM. The good spatial, energy and timing resolutions, together with the excellent DOI correction and high detection efficiency of our detectors, are expected to facilitate high and uniform PET system resolution.	[Maas, Marnix C.; Schaart, Dennis R.; van der Laan, D. J. (Jan); Beekman, Freek J.; van Eijk, Carel W. E.] Delft Univ Technol, NL-2629 JB Delft, Netherlands; [Bruyndonckx, Peter; Lemaitre, Cedric] Vrije Univ Brussels, B-1050 Brussels, Belgium; [Beekman, Freek J.] Univ Med Ctr Utrecht, Utrecht, Netherlands	Maas, MC (reprint author), Delft Univ Technol, Mekelweg 15, NL-2629 JB Delft, Netherlands.	d.r.schaart@tudelft.nl					Abreu MC, 2006, IEEE T NUCL SCI, V53, P71, DOI 10.1109/TNS.2006.870173; Bloomfield PM, 1997, PHYS MED BIOL, V42, P389, DOI 10.1088/0031-9155/42/2/010; Bruyndonckx P, 2003, IEEE T NUCL SCI, V50, P1415, DOI 10.1109/TNS.2003.817348; Bruyndonckx P, 2004, IEEE T NUCL SCI, V51, P2520, DOI 10.1109/TNS.2004.835782; Catana C, 2006, J NUCL MED, V47, P1968; Clement D., 1998, 1998 IEEE Nuclear Science Symposium Conference Record. 1998 IEEE Nuclear Science Symposium and Medical Imaging Conference (Cat. No.98CH36255), DOI 10.1109/NSSMIC.1998.773818; Correia JA, 1999, IEEE T NUCL SCI, V46, P631, DOI 10.1109/23.775590; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; de Haas JTM, 2005, NUCL INSTRUM METH A, V537, P97, DOI 10.1016/j.nima.2004.07.243; Del Guerra A, 1998, NUCL INSTRUM METH A, V409, P537, DOI 10.1016/S0168-9002(97)01311-9; Du HN, 2008, PHYS MED BIOL, V53, P1829, DOI 10.1088/0031-9155/53/7/002; Judenhofer MS, 2008, NAT MED, V14, P459, DOI 10.1038/nm1700; Lecomte R, 1996, IEEE T NUCL SCI, V43, P1952, DOI 10.1109/23.507252; Maas MC, 2008, IEEE T NUCL SCI, V55, P842, DOI 10.1109/TNS.2008.921493; MAAS MC, 2008, THESIS DELFT U TECHN; Maas MC, 2006, IEEE T NUCL SCI, V53, P1071, DOI 10.1109/TNS.2006.873711; McElroy DP, 2005, IEEE T NUCL SCI, V52, P199, DOI 10.1109/TNS.2004.843114; Orita N, 2005, IEEE T NUCL SCI, V52, P8, DOI 10.1109/TNS.2004.843158; Seidel J, 2003, IEEE T NUCL SCI, V50, P1347, DOI 10.1109/TNS.2003.817282; Surti S, 2003, IEEE T NUCL SCI, V50, P1357, DOI 10.1109/TNS.2003.817950; Tai YC, 2005, J NUCL MED, V46, P455; Tai YC, 2003, PHYS MED BIOL, V48, P1519, DOI 10.1088/0031-9155/48/11/303; van der Laan DJ, 2007, NUCL INSTRUM METH A, V571, P227, DOI 10.1016/j.nima.2006.10.069; van der Laan DJJ, 2006, IEEE T NUCL SCI, V53, P1063, DOI 10.1109/TNS.2006.873710; Wang GC, 2004, IEEE T NUCL SCI, V51, P775, DOI 10.1109/TNS.2004.829785; Weber S, 1999, IEEE NUCL SCI CONF R, P1603, DOI 10.1109/NSSMIC.1999.842872; Woody C, 2007, NUCL INSTRUM METH A, V571, P102, DOI 10.1016/j.nima.2006.10.039; Ziemons K, 2005, NUCL INSTRUM METH A, V537, P307, DOI 10.1016/j.nima.2004.08.032	28	36	36	IOP PUBLISHING LTD	BRISTOL	DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND	0031-9155		PHYS MED BIOL	Phys. Med. Biol.	APR 7	2009	54	7					1893	1908		10.1088/0031-9155/54/7/003		16	Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging	Engineering; Radiology, Nuclear Medicine & Medical Imaging	420LY	WOS:000264292500003	
J	Giguere, P; Dudek, G				Giguere, Philippe; Dudek, Gregory			Clustering sensor data for autonomous terrain identification using time-dependency	AUTONOMOUS ROBOTS			English	Article; Proceedings Paper	4th Robotics Science and Systems Conference	JUN, 2008	Zurich, SWITZERLAND			Terrain identification; Unsupervised learning; Clustering; Mobile robots; Legged robots; Machine learning; Hidden Markov model	CLASSIFICATION	In this paper we are interested in autonomous vehicles that can automatically develop terrain classifiers without human interaction or feedback. A key issue is the clustering of time-series data collected by the sensors of a ground-based vehicle moving over several terrain surfaces (e.g. concrete or soil). In this context, we present a novel off-line windowless clustering algorithm that exploits time-dependency between samples. In terrain coverage, sets of sensory measurements are returned that are spatially, and hence temporally, correlated. Our algorithm works by finding a set of parameter values for a user-specified classifier that minimize a cost function. This cost function is related to the change in classifier probability estimates over time. The main advantage over other existing methods is its ability to cluster data for fast-switching systems that either have high process or observation noise, or complex distributions that cannot be properly characterized within the time interval that the system stays in a single state. The algorithm was evaluated using three different classifiers (linear separator, mixture of Gaussians and k-Nearest Neighbor), over both synthetic data sets and two different mobile robotic platforms, with success. Comparisons are provided against a window-based algorithm and against a hidden Markov model trained with Expectation-Maximization, with positive results.	[Giguere, Philippe; Dudek, Gregory] McGill Univ, Ctr Intelligent Machines, Montreal, PQ H3A 2A7, Canada	Giguere, P (reprint author), McGill Univ, Ctr Intelligent Machines, Montreal, PQ H3A 2A7, Canada.	philg@cim.mcgill.ca; dudek@cim.mcgill.ca	Dudek, Gregory/H-3567-2012				Brooks CA, 2005, IEEE T ROBOT, V21, P1185, DOI 10.1109/TRO.2005.855994; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUDEK G, 2005, P IEEE RSJ INT C INT; DuPont EM, 2008, AUTON ROBOT, V24, P337, DOI 10.1007/s10514-007-9077-0; GIGUERE P, 2009, P IEEE INT C ROB AUT; GIGUERE P, 2006, P ROB SCI SYST PHIL; GIGUERE P, 2009, CAN C COMP ROB VIS K; KOHLMORGEN J, 2001, NNSP 2001 NEURAL NET, V11, P113; KOHLMORGEN J, 2000, P IEEE NEUR NETW SIG, P85; LENSER S, 2003, P 2003 IEEE INT C RO; LENSER S, 2004, P IEEE RSJ INT C INT, V3, P2719; Murphy K., 2005, HIDDEN MARKOV MODEL; Pawelzik K, 1996, NEURAL COMPUT, V8, P340, DOI 10.1162/neco.1996.8.2.340; Rabiner L.R., 1989, IEEE P, V77, P257; SADHUKAN D, 2003, P FLOR C REC ADV ROB; SREBRO N, 2005, PASCAL WORKSH STAT O; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; WEISS C, 2007, P 3 EUR C MOB ROB EC, P7; Weiss C, 2006, 2006 IEEE/RSJ International Conference on Intelligent Robots and Systems, Vols 1-12, P4429, DOI 10.1109/IROS.2006.282076	19	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0929-5593		AUTON ROBOT	Auton. Robot.	APR	2009	26	2-3					171	186		10.1007/s10514-009-9114-2		16	Computer Science, Artificial Intelligence; Robotics	Computer Science; Robotics	440EV	WOS:000265684000006	
J	Jarchi, D; Boostani, R; Taheri, M; Sanei, S				Jarchi, Delaram; Boostani, Reza; Taheri, Mohammad; Sanei, Saeid			Seizure source localization using a hybrid second order blind identification and extended rival penalized competitive learning algorithm	BIOMEDICAL SIGNAL PROCESSING AND CONTROL			English	Article						Seizure; SOBI; RPCL; Clustering; Localization; BSS	SOURCE SEPARATION; EPILEPTIC FOCI; TOMOGRAPHY	Localization of seizure sources prior to neurosurgery is crucial. In this paper, a new method is proposed to localize the seizure sources from multi-channel electroencephalogram (EEG) signals. Blind source separation based on second order blind identification (SOBI) is primarily applied to estimate the brain source signals in each window of the EEG signals. A new clustering method based on rival penalized competitive learning (RPCL) is then developed to cluster the rows of the estimated unmixing matrices in all the windows. The algorithm also includes pre and post-processing stages. By multiplying each cluster center to the EEG signals, the brain signal sources are approximated. According to a complexity value measure, the main seizure source signal is separated from the others. This signal is projected back to the electrodes' space and is subjected to the dipole source localization using a single dipole model. The simulation results verify the accuracy of the system. in addition, correct localization of the seizure source is consistent with the clinical tests derived using the simultaneous intracranial recordings. (C) 2009 Elsevier Ltd. All rights reserved.	[Jarchi, Delaram; Boostani, Reza; Taheri, Mohammad] Shiraz Univ, Dept Comp Sci & Engn, Shiraz, Iran; [Sanei, Saeid] Cardiff Univ, Sch Engn, Ctr DSP, Cardiff, S Glam, Wales	Jarchi, D (reprint author), Shiraz Univ, Dept Comp Sci & Engn, Shiraz, Iran.	delaram.jarchi@gmail.com					BAI X, 2006, IEEE T BIOMEDICAL EN, V53; Ball G. H., 1965, ISODATA NOVEL METHOD; Bell A.J., 1995, NEURAL COMPUT, V7, P1004; Belouchrani A, 1997, IEEE T SIGNAL PROCES, V45, P434, DOI 10.1109/78.554307; CARDOSO JF, 1993, IEE PROC-F, V140, P362; Cardoso JF, 1996, SIAM J MATRIX ANAL A, V17, P161, DOI 10.1137/S0895479893259546; Corsini J, 2006, IEEE T BIO-MED ENG, V53, P790, DOI 10.1109/TBME.2005.862551; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; daSilva EA, 1997, EPILEPSIA, V38, P1198; IASEMIDIS LD, 2000, NONLINEAR BIOMEDICAL; Iasemidis Leon D, 2003, IEEE Trans Biomed Eng, V50, P549, DOI 10.1109/TBME.2003.810705; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Jarchi D, 2007, Proceedings of the 2007 15th International Conference on Digital Signal Processing, P183; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; KAVANAGH RN, 1978, IEEE T BIO-MED ENG, V25, P421, DOI 10.1109/TBME.1978.326339; Ma JW, 2006, IEEE T SYST MAN CY B, V36, P722, DOI 10.1109/TSMCB.2006.870633; MacQueen J. B., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; MARKS DA, 1992, ANN NEUROL, V31, P250, DOI 10.1002/ana.410310304; MICO ML, 1994, PATTERN RECOGN LETT, V15, P9, DOI 10.1016/0167-8655(94)90095-7; MISHRA SK, 1994, MACH INTELL PATT REC, V16, P425; MOSHER JC, 1992, IEEE T BIO-MED ENG, V39, P541, DOI 10.1109/10.141192; Pataraia E, 2002, NEUROSURG REV, V25, P141, DOI 10.1007/s10143-001-0197-2; Sanei S., 2007, EEG SIGNAL PROCESSIN; SARVAS J, 1987, PHYS MED BIOL, V32, P11, DOI 10.1088/0031-9155/32/1/004; Scherg M., 1990, ADV AUDIOL, P40; Scherg Michael, 1992, Brain Topography, V5, P103, DOI 10.1007/BF01129037; XU L, 1993, IEEE T NEURAL NETWOR, V4, P636, DOI 10.1109/72.238318; *W JOHN LTD, 2002, SONS STAT PATT REC	28	1	1	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1746-8094		BIOMED SIGNAL PROCES	Biomed. Signal Process. Control	APR	2009	4	2					108	117		10.1016/j.bspc.2009.01.004		10	Engineering, Biomedical; Medical Laboratory Technology	Engineering; Medical Laboratory Technology	440MR	WOS:000265704900005	
J	Chen, SM; Shie, JD				Chen, Shyi-Ming; Shie, Jen-Da			Fuzzy classification systems based on fuzzy information gain measures	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Fuzzy information gain; Fuzzy entropy; Classification problems; Feature weights; Membership grades	MEMBERSHIP FUNCTIONS; RULES	In this paper, we present a new method for handling classification problems using a new fuzzy information gain measure. Based on the proposed fuzzy information gain measure, we propose an algorithm for constructing membership functions, calculating the class degree of each subset of training instances with respect to each class and Calculating the fuzzy entropy of each subset of training instances. Based on the constructed membership function of each fuzzy set of each feature, the obtained class degree of each subset of training instances with respect to each class and the obtained fuzzy entropy of each subset of training instances, we propose an evaluating function for classifying testing instances. The proposed method gets higher average classification accuracy rates than the methods presented in [John, G. H., & Langley. P. (1995). Estimating continuous distributions in Bayesian classifiers. In Proceedings of the 11th conference oil uncertainty in artificial intelligence, Montreal, Canada (pp. 338-345): Platt, J. C. (1999). Using analytic QP and sparseness to speed training of support vector machines. In Proceedings of the 13th annual conference on neural information processing systems, Denver, Colorado (pp. 557-563); Quinlan, J. R. (1993). C4.5: Programs for machine learning. San Francisco: Morgan Kaufmann]. (c) 2008 Elsevier Ltd. All rights reserved.	[Chen, Shyi-Ming; Shie, Jen-Da] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei, Taiwan	Chen, SM (reprint author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei, Taiwan.	smchen@mail.ntust.edu.tw			National Science Council, Republic of China [NSC 95-2221-E-011-116-MY2]	This work was supported in part by the National Science Council, Republic of China, under Grant NSC 95-2221-E-011-116-MY2.	BAIM PW, 1988, IEEE T PATTERN ANAL, V10, P888, DOI 10.1109/34.9110; BANERJI RB, 1964, GEN SYST, V9, P135; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Caruana R., 1994, P 11 INT C MACH LEAR, P28; Catlett J., 1991, P EUR WORK SESS LEAR, P164; Chaikla N., 1999, P 1999 IEEE INT C SY, V5, P538; Chen SM, 2002, CYBERNET SYST, V33, P723, DOI 10.1080/01969720290040812; Chen SM, 2005, CYBERNET SYST, V36, P397, DOI 10.1080/01969720490929562; Chen S.M., 2005, P 2005 IEEE INT C FU, P183, DOI 10.1109/FUZZY.2005.1452390; Chen SM, 2002, CYBERNET SYST, V33, P841, DOI 10.1080/01969720290040867; CHMIELEWSKI MR, 1994, P 3 INT WORKSH ROUGH, P294; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; De RK, 1997, PATTERN RECOGN, V30, P1579, DOI 10.1016/S0031-3203(96)00190-2; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Fisher RA, 1936, ANN EUGENIC, V7, P179; GOMEZ J, 2005, P 2005 IEEE C EV COM, P1637; Hartigan J.A., 1979, J ROYAL STAT SOC C, V28, P100; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; John G., 1995, P 11 C UNC ART INT, P338; Maass W., 1994, Proceedings of the Seventh Annual ACM Conference on Computational Learning Theory, COLT 94, DOI 10.1145/180139.181016; ONGKOWIJAYA BT, 2004, P 7 INT C SIGN PROC, P663; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; Platt J, 1999, P 13 ANN C NEUR INF, P557; Quinlan JR, 1993, C 45 PROGRAMS MACHIN; QUINLAN JR, 1986, MACH LEARN, V1, P106; Ramesh VE, 1999, PATTERN RECOGN, V32, P217, DOI 10.1016/S0031-3203(98)00141-1; SHIE JD, 2006, P 2006 IEEE INT C FU, P5427; SHIE JD, 2007, APPL INTELL, V28, P69; WINKLER SM, 2006, P 20 INT S PAR DISTR, P2295; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90036-5	31	5	7	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	APR	2009	36	3					4517	4522		10.1016/j.eswa.2008.05.020		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	410NJ	WOS:000263584100043	
J	Chen, JN; Huang, HK; Tian, SF; Qu, YL				Chen, Jingnian; Huang, Houkuan; Tian, Shengfeng; Qu, Youli			Feature selection for text classification with Naive Bayes	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Text classification; Feature selection; Text preprocessing; Naive Bayes	NEAREST-NEIGHBOR; CATEGORIZATION	As an important preprocessing technology in text classification, feature selection can improve the scalability, efficiency and accuracy of a text classifier. In general, a good feature selection method should consider domain and algorithm characteristics. As the Naive Bayesian classifier is very simple and efficient and highly sensitive to feature selection, so the research of feature selection specially for it is significant. This paper presents two feature evaluation metrics for the Naive Bayesian classifier applied on multi-class text datasets: Multi-class Odds Ratio (MOR), and Class Discriminating Measure (CDM). Experiments of text classification with Naive Bayesian classifiers were carried out on two multi-class texts collections. As the results indicate, CDM and MOR gain obviously better selecting effect than other feature selection approaches. (C) 2008 Elsevier Ltd. All rights reserved.	[Chen, Jingnian; Huang, Houkuan; Tian, Shengfeng; Qu, Youli] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China; [Chen, Jingnian] Shandong Univ Finance, Dept Informat & Comp Sci, Jinan 250014, Shandong, Peoples R China	Chen, JN (reprint author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.	jnchen06@163.com			National Natural Science Foundation of China [60503017, 60673089]	This research is supported by National Natural Science Foundation of China under Grant Nos. 60503017 and 60673089.	COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Forman G., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753670; Frank E., 2006, P 10 EUR C PRINC PRA, P503; Joachims T, 1998, P 10 EUR C MACH LEAR, P137; John G. H., 1994, P 11 INT C MACH LEAR, P121; Kim SB, 2006, IEEE T KNOWL DATA EN, V18, P1457; Lewis D., 1998, P 10 EUR C MACH LEAR, P4; Lewis D.D., 1994, P 3 ANN S DOC AN INF, P81; McCallum A., 1998, AAAI 98 WORKSH LEARN; Mladenic D, 2003, DECIS SUPPORT SYST, V35, P45, DOI 10.1016/S0167-9236(02)00097-0; Mladenic D., 1999, P 16 INT C MACH LEAR, P258; Shang WQ, 2007, EXPERT SYST APPL, V33, P1, DOI 10.1016/j.eswa.2006.04.001; Tan SB, 2005, EXPERT SYST APPL, V28, P667, DOI 10.1016/j.eswa.2004.12.023; Wiener E.D., 1995, P 4 ANN S DOC AN INF, P317; YANG YM, 1994, ACM T INFORM SYST, V12, P252, DOI 10.1145/183422.183424; Yang Y., 1999, INFORMATION RETRIEVA, V1, P76; Yang Y, 1997, P 14 INT C MACH LEAR, P412; [周茜 Zhou Qian], 2004, [中文信息学报, Journal of Chinese Information Processing], V18, P17	18	28	33	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	APR	2009	36	3					5432	5435		10.1016/j.eswa.2008.06.054		4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	410NJ	WOS:000263584100156	
J	Jung, S; Lim, T; Kim, D				Jung, Sabum; Lim, Taesoo; Kim, Dongsoo			Integrating radial basis function networks with case-based reasoning for product design	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Case-based reasoning (CBR); Radial basis function network (RBFN); Design expert system; Product design	ADAPTATION; ALGORITHM; KNOWLEDGE	This paper presents a case-based design expert system that automatically determines the design values of a product. We focus on the design problem of a shadow mask which is a core component of monitors in the electronics industry. In case-based reasoning (CBR), it is important to retrieve similar cases and adapt them to meet design specifications exactly. Notably, difficulties in automating the adaptation process have prevented designers from being able to use design expert systems easily and efficiently. In this paper, we present a hybrid approach combining CBR and artificial neural networks in order to solve the problems Occurring during the adaptation process. We first constructed a radial basis function network (RBFN) composed of representative cases created by K-means clustering. Then, the representative case most similar to the current problem was adjusted using the network. The rationale behind the proposed approach is discussed, and experimental results acquired from real shadow mask design are presented. Using the design expert system, designers can reduce design time and errors and enhance the total quality of design. Furthermore, the expert system facilitates effective sharing of design knowledge among designers. (C) 2008 Elsevier Ltd. All rights reserved.	[Kim, Dongsoo] Soongsil Univ, Dept Ind & Informat Syst Engn, Seoul 156743, South Korea; [Jung, Sabum] LG Prod Engn Res Inst, Dev Res Grp, Pyongtaek 451713, Gyeonggi, South Korea; [Lim, Taesoo] Sungkyul Univ, Dept Comp Engn, Anyang 430742, Gyeonggi, South Korea	Kim, D (reprint author), Soongsil Univ, Dept Ind & Informat Syst Engn, Seoul 156743, South Korea.	skk1991@hotmail.com; tshou@sungkyul.edu; dskim@ssu.ac.kr			Soongsil University Research Fund	This work was supported by the Soongsil University Research Fund.	Chan FTS, 2005, EXPERT SYST APPL, V29, P121, DOI 10.1016/j.eswa.2005.01.010; CIOS KJ, 1998, KLUWER INT SERIES EN, P319; CORCHARDO JM, 1998, IEEE WORLD C COMPUTA, V1, P713; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Craw S, 2006, ARTIF INTELL, V170, P1175, DOI 10.1016/j.artint.2006.09.001; GARZA AGD, 1999, INT C CAS BAS REAS I; GOLDING AR, 1995, TR9419A MERL; Hanney K., 1997, P 2 INT C CAS BAS RE, P359; Haque BU, 2000, KNOWL-BASED SYST, V13, P101, DOI 10.1016/S0950-7051(00)00051-4; Kim SM, 2003, GENE DEV, V17, P330, DOI 10.1101/gad.1046203; Kolodner J., 1993, CASE BASED REASONING; MAHER M, 1997, IEEE EXPERT INTE MAR, P34; Mille A, 2006, ANNU REV CONTROL, V30, P223, DOI 10.1016/j.arcontrol.2006.09.003; Pal S.K., 2004, FDN SOFT CASE BASED; Passone S, 2006, KNOWL-BASED SYST, V19, P192, DOI 10.1016/j.knosys.2005.07.007; QUINLAN JR, 1986, MACH LEARN, V1, P106; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; Zheng GL, 1996, NEURAL NETWORKS, V9, P1619, DOI 10.1016/0893-6080(95)00139-5	18	3	4	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	APR	2009	36	3					5695	5701		10.1016/j.eswa.2008.06.099		7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	410NJ	WOS:000263584100186	
J	Kianmehr, K; Alhajj, R				Kianmehr, Keivan; Alhajj, Reda			Calling communities analysis and identification using machine learning techniques	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Social communities; Classification; Clustering; Customer behavior; Machine learning	NETWORKS	The analysis of social communities related logs has recently received considerable attention for its importance in shedding light on social concerns by identifying different groups, and hence helps in resolving issues like predicting terrorist groups. In the customer analysis domain, identifying calling communities can be used for determining a particular customer's value according to the general pattern behavior of the community that the customer belongs to; this helps the effective targeted marketing design, which is Significantly important for increasing profitability. In telecommunication industry, machine learning techniques have been applied to the Call Detail Record (CDR) for predicting customer behavior such as churn prediction. In this paper, we pursue identifying the calling communities and demonstrate how cluster analysis can be used to effectively identify communities using information derived from the CDR data. We use the information extracted from the cluster analysis to identify customer calling patterns. Customers calling patterns are then given to a classification algorithm to generate a classifier model for predicting the calling communities of a customer. We apply different machine learning techniques to build classifier models and compare them in terms of classification accuracy and computational performance. The reported test results demonstrate the applicability and effectiveness of the proposed approach. (C) 2008 Elsevier Ltd. All rights reserved.	[Kianmehr, Keivan; Alhajj, Reda] Univ Calgary, Dept Comp Sci, Calgary, AB T2N 1N4, Canada; [Alhajj, Reda] Global Univ, Dept Comp Sci, Beirut, Lebanon	Alhajj, R (reprint author), Univ Calgary, Dept Comp Sci, Calgary, AB T2N 1N4, Canada.	alhajj@cpsc.ucalgary.ca					ALLWEIN E, 2000, REDUCING MULTICLASS, P83006; BISHOP CM, 1995, NEURAL NETWORKS PATT, P83006; BREIMAN L, 1984, CLASSIFICATION REGRE, P83006; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1023/A:1022649401552; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRISTIANINI N, 2000, INTRO SUPPORT VECTOR, P83006; D'andrade R., 1978, PSYCHOMETRIKA, V4, P58; DUNHAM MH, 2000, DATA MINING TECHNIQU, P83006; EDELSTEIN HA, 1999, INTRO DATA MINING KN, P83006; Flake G. W., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347121; Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799; HAN J, 2000, DATA MINING CONCEPTS, P83006; HASAN M, 2006, P WORKSH LINK AN COU, P83006; HAYKIN S, 1998, NEURAL NETWORKS COMP, P83006; John G., 1995, P 11 C UNC ART INT, P338; JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588; Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140; NASRULLAH M, 2006, LECT NOTES ARTIF INT, V4093, P1037; Pearl J., 1985, P 7 C COGN SCI SOC, P329; QUINLAN J, 1993, C4 5 PROGRAMS MACHIN, P83006; RATSCH G, 2002, ADAPTING CODES EMBED, P83006; ROMESBURG HC, 2004, CLUSTER ANAL RES, P83006; VAPNIK VN, 1998, STAT LEARNING THEORY, P83006; YAN L, 2005, P IEEE INT JOINT C A, V4, P2555	25	4	4	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	APR	2009	36	3					6218	6226		10.1016/j.eswa.2008.07.072		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	413UD	WOS:000263817100058	
J	Mora-Florez, J; Morales-Espana, G; Perez-Londono, S				Mora-Florez, J.; Morales-Espana, G.; Perez-Londono, S.			Learning-based strategy for reducing the multiple estimation problem of fault zone location in radial power systems	IET GENERATION TRANSMISSION & DISTRIBUTION			English	Article							ALGORITHM	A learning-based strategy that uses support vector machines and k nearest neighbours is proposed for locating the faulted zone in radial power systems, specifically in distribution networks. The main goal is to reduce the multiple estimation of the fault location, inherent in those methods that use single end measurements. A selection of features obtained from the fundamentals of voltages and currents, measured at the power substation, are analysed and used as inputs of the proposed zone locator. Performance of several combinations of these features considering all fault types, different short-circuit levels and variation of the fault resistance, and the system load is evaluated. An application example illustrates the high precision to locate the faulted zone, obtained with the proposed methodology. The proposal provides appropriate information for the prevention and opportune attention of faults, requires minimum investment and overcomes the multiple estimation problem of the classic impedance based methods.	[Mora-Florez, J.; Perez-Londono, S.] Technol Univ Pereira, Dept Elect Engn, Pereira, Colombia; [Morales-Espana, G.] Delft Univ Technol, Delft, Netherlands	Mora-Florez, J (reprint author), Technol Univ Pereira, Dept Elect Engn, Pereira, Colombia.	jjmora@utp.edu.co	Morales-Espana, German Andres/B-3713-2012	Morales-Espana, German Andres/0000-0002-6372-6197			AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CHIHWEI H, 2003, PRACTICAL GUIDE SUPP; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; Dagenhart J, 2000, IEEE T IND APPL, V36, P30, DOI 10.1109/28.821792; Das R., 1998, THESIS U SASKATCHEWA; IEEE Distribution System Analysis Subcommittee, 1993, RAD TEST FEED; MESCAL A, 2003, ELECTR POW SYST RES, V64, P87; MORA J, 2006, TRANSM DISTR C EXP L; Mora-Florez J., 2006, THESIS U GIRONA SPAI; Mora-Florez J, 2007, IEEE T POWER DELIVER, V22, P1715, DOI 10.1109/TPWRD.2006.883021; Mora-Florez J, 2008, ELECTR POW SYST RES, V78, P657, DOI 10.1016/j.epsr.2007.05.010; NOVOSEL D, 1998, Patent No. 5839093; Purushothama GK, 2001, INT J ELEC POWER, V23, P491, DOI 10.1016/S0142-0615(00)00068-5; Short T. A., 2003, ELECT POWER DISTRIBU; TAKAGI T, 1981, IEEE T POWER AP SYST, V100, P1316, DOI 10.1109/TPAS.1981.316604; THUKARAM D, 2006, POW IND C IEEE, DOI DOI 10.1109/POWERI.2006.1632510; Thukaram D, 2005, IEEE T POWER DELIVER, V20, P710, DOI 10.1109/TPWRD.2005.844307; Vapnik VN, 2000, NATURE STAT LEARNING; WARRINGTON A, 1978, PROTECTIVE RELAYS TH; [Anonymous], 2004, C37114 IEEE	22	7	8	INST ENGINEERING TECHNOLOGY-IET	HERTFORD	MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND	1751-8687		IET GENER TRANSM DIS	IET Gener. Transm. Distrib.	APR	2009	3	4					346	356		10.1049/iet-gtd.2008.0164		11	Engineering, Electrical & Electronic	Engineering	434ET	WOS:000265258700004	
J	Xiao, X; Wang, P; Chou, KC				Xiao, Xuan; Wang, Pu; Chou, Kuo-Chen			Predicting the quaternary structure attribute of a protein by hybridizing functional domain composition and pseudo amino acid composition	JOURNAL OF APPLIED CRYSTALLOGRAPHY			English	Article							SUBCELLULAR LOCATION PREDICTION; COMPLEXITY MEASURE FACTOR; ENZYME SUBFAMILY CLASSES; SUPPORT VECTOR MACHINE; INFLUENZA-A VIRUS; ENSEMBLE CLASSIFIER; APOPTOSIS PROTEINS; MEMBRANE-PROTEIN; PHOSPHOLAMBAN PENTAMER; FUSION CLASSIFIER	In vivo, some proteins exist as monomers (single polypeptide chains) and others as oligomers. The latter are composed of two or more chains (subunits) that are associated with each other through noncovalent interactions and, occasionally, disulfide bonds. Oligomers can be further classified into homo-oligomers (formed by identical subunits) and hetero-oligomers (formed by different subunits), and they form the structural basis of various biological functions such as cooperative effects, the allosteric mechanism and ion-channel gating. Therefore, it would be of less interest or of low priority for crystallographic scientists to crystallize a single protein chain and determine its three-dimensional structure if it is already known as part of an oligomer. However, it is both time-consuming and laborious to acquire such information on the quaternary structure attribute purely by experiment. In particular, with the avalanche of protein sequences generated in the post-genomic age, it is highly desirable to develop an automated method by which crystallographic scientists can rapidly and effectively identify which quaternary attribute a particular protein chain has according to its sequence information. In view of this, a computational method has been developed by hybridizing the approaches of functional domain composition and pseudo amino acid composition. For the convenience of crystallographic scientists, a user-friendly web server, PQSA-Pred, has been established at http://218.65.61.89:8080/bioinfo/pqsa-pred, by which the desired information can be easily obtained.	[Xiao, Xuan; Wang, Pu] Jing De Zhen Ceram Inst, Dept Comp, Jing De Zhen 33300, Peoples R China; [Chou, Kuo-Chen] Gordon Life Sci Inst, San Diego, CA 92130 USA	Xiao, X (reprint author), Jing De Zhen Ceram Inst, Dept Comp, Jing De Zhen 33300, Peoples R China.	xiaoxuan0326@yahoo.com.cn	Chou, Kuo-Chen/A-8340-2009				ALTSCHUL SF, 1997, NUCLEIC ACIDS RES, V25, P3402; Carugo O, 2007, J APPL CRYSTALLOGR, V40, P986, DOI 10.1107/S0021889807041076; Chen C, 2008, J THEOR BIOL, V253, P388, DOI 10.1016/j.jtbi.2008.03.009; Chen K, 2008, J COMPUT CHEM, V29, P1596, DOI 10.1002/jcc.20918; Chen YL, 2007, J THEOR BIOL, V245, P775, DOI 10.1016/j.jtbi.2006.11.010; Chen YL, 2007, J THEOR BIOL, V248, P377, DOI 10.1016/j.jtbi.2007.05.019; Chen ZH, 2002, J BIOL CHEM, V277, P24653, DOI 10.1074/jbc.M111862200; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2006, J PROTEOME RES, V5, P3420, DOI 10.1021/pr060404b; Chou KC, 2008, BIOCHEM BIOPH RES CO, V376, P321, DOI 10.1016/j.bbrc.2008.08.125; Chou KC, 2004, BIOCHEM BIOPH RES CO, V316, P636, DOI 10.1016/j.bbrc.2004.02.098; Chou KC, 2003, PROTEINS, V53, P282, DOI 10.1002/prot.10500; Chou KC, 2007, ANAL BIOCHEM, V370, P1, DOI 10.1016/j.ab.2007.07.006; Chou KC, 2001, PROTEINS, V44, P60, DOI 10.1002/prot.1072.abs; Chou KC, 2008, NAT PROTOC, V3, P153, DOI 10.1038/nprot.2007.494; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; Chou KC, 2007, J CELL BIOCHEM, V100, P665, DOI 10.1002/jcb.21096; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2004, J PROTEOME RES, V3, P856, DOI 10.1021/pr049931q; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 2004, BIOCHEM BIOPH RES CO, V319, P433, DOI 10.1016/j.bbrc.2004.05.016; Chou KC, 2000, BIOCHEM BIOPH RES CO, V278, P477, DOI 10.1006/bbrc.2000.3815; Chou KC, 2006, J PROTEOME RES, V5, P1888, DOI 10.1021/pr060167c; Chou KC, 2007, BIOCHEM BIOPH RES CO, V357, P633, DOI 10.1016/j.bbrc.2007.03.162; Chou KC, 2004, CURR MED CHEM, V11, P2105; CHOU KC, 1994, J BIOL CHEM, V269, P22014; Chou KC, 2006, J CELL BIOCHEM, V99, P517, DOI 10.1002/jcb.20879; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; CHOU KC, 1988, P NATL ACAD SCI USA, V85, P4295, DOI 10.1073/pnas.85.12.4295; Chou KC, 2007, J PROTEOME RES, V6, P1728, DOI 10.1021/pr060635i; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou KC, 2006, BIOCHEM BIOPH RES CO, V347, P150, DOI 10.1016/j.bbrc.2006.06.059; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Ding YS, 2008, PATTERN RECOGN LETT, V29, P1887, DOI 10.1016/j.patrec.2008.06.007; Doyle DA, 1998, SCIENCE, V280, P69, DOI 10.1126/science.280.5360.69; Du PF, 2008, J THEOR BIOL, V253, P579, DOI 10.1016/j.jtbi.2008.04.006; Finn RD, 2006, NUCLEIC ACIDS RES, V34, pD247, DOI 10.1093/nar/gkj149; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Garian R, 2001, BIOINFORMATICS, V17, P551, DOI 10.1093/bioinformatics/17.6.551; Jiang XY, 2008, PROTEIN PEPTIDE LETT, V15, P392, DOI 10.2174/092986608784246443; Jin YH, 2008, PROTEIN PEPTIDE LETT, V15, P286; Kannan S, 2008, PROTEIN PEPTIDE LETT, V15, P1107, DOI 10.2174/092986608786071085; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Letunic I, 2006, NUCLEIC ACIDS RES, V34, pD257, DOI 10.1093/nar/gkj079; Li FM, 2008, PROTEIN PEPTIDE LETT, V15, P612, DOI 10.2174/092986608784966930; Li WZ, 2006, BIOINFORMATICS, V22, P1658, DOI 10.1093/bioinformatics/btl158; Lin H, 2008, PROTEIN PEPTIDE LETT, V15, P739, DOI 10.2174/092986608785133681; Lin H, 2008, J THEOR BIOL, V252, P350, DOI 10.1016/j.jtbi.2008.02.004; Mahalanobis P., 1936, P NAT I SCI INDIA, V2, P49; Marchler-Bauer A, 2007, NUCLEIC ACIDS RES, V35, pD237, DOI 10.1093/nar/gkl951; Mardia K. V., 1979, MULTIVARIATE ANAL, P322; Tatusov RL, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-41; Niu B, 2008, PROTEIN PEPTIDE LETT, V15, P590, DOI 10.2174/092986608784966921; Oxenoid K, 2007, PROTEIN SCI, V16, P1977, DOI 10.1110/ps.072975107; Oxenoid K, 2005, P NATL ACAD SCI USA, V102, P10870, DOI 10.1073/pnas.0504920102; Perutz M. F., 1964, SCI AM, V211, P65; Pillai K. C. S., 1985, ENCY STATISTICAL SCI, V5, P176; Schnell JR, 2008, NATURE, V451, P591, DOI 10.1038/nature06531; Shen HB, 2007, BIOPOLYMERS, V85, P233, DOI 10.1002/bip.20640; Shen HB, 2007, BIOCHEM BIOPH RES CO, V355, P1006, DOI 10.1016/j.bbrc.2007.02.071; Shen HB, 2007, PROTEIN ENG DES SEL, V20, P39, DOI 10.1093/protein-gzl053; Shen HB, 2007, BIOCHEM BIOPH RES CO, V364, P53, DOI 10.1016/j.bbrc.2007.09.098; Shen HB, 2008, ANAL BIOCHEM, V373, P386, DOI 10.1016/j.ab.2007.10.012; Shi MG, 2008, PROTEIN PEPTIDE LETT, V15, P692, DOI 10.2174/092986608785133627; Tian FF, 2008, PROTEIN PEPTIDE LETT, V15, P1033, DOI 10.2174/092986608786071120; Tretter V, 1997, J NEUROSCI, V17, P2728; Wang T, 2008, PROTEIN PEPTIDE LETT, V15, P915, DOI 10.2174/092986608785849308; Wu G, 2008, PROTEIN PEPTIDE LETT, V15, P144; Xiao X, 2006, J COMPUT CHEM, V27, P478, DOI 10.1002/jcc.20354; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Zhang GY, 2008, J THEOR BIOL, V253, P310, DOI 10.1016/j.jtbi.2008.03.015; Zhang GY, 2008, PROTEIN PEPTIDE LETT, V15, P1132, DOI 10.2174/092986608786071184; Zhang SW, 2003, BIOINFORMATICS, V19, P2390, DOI 10.1093/bioinformatics/btg331; Zhang SW, 2006, AMINO ACIDS, V30, P461, DOI 10.1007/s00726-006-0263-8; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou XB, 2007, J THEOR BIOL, V248, P546, DOI 10.1016/j.jtbi.2007.06.001	79	60	60	WILEY-BLACKWELL PUBLISHING, INC	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0021-8898		J APPL CRYSTALLOGR	J. Appl. Crystallogr.	APR	2009	42						169	173		10.1107/S0021889809002751		5	Crystallography	Crystallography	420MB	WOS:000264292800003	
J	Liu, L; Cai, YD; Lu, WC; Feng, KY; Peng, CR; Niu, B				Liu, Liang; Cai, Yudong; Lu, Wencong; Feng, Kaiyan; Peng, Chunrong; Niu, Bing			Prediction of protein-protein interactions based on PseAA composition and hybrid feature selection	BIOCHEMICAL AND BIOPHYSICAL RESEARCH COMMUNICATIONS			English	Article						Bioinformatics; Proteomics; Protein-protein interactions; KNNs; Feature selection	AMINO-ACID-COMPOSITION; HYBRIDIZATION SPACE; FOLDING TYPES; INTERFACES; DROSOPHILA; GENE; TRANSACTIVATION; SEQUENCES; INTACT; E2F	Based on pseudo amino acid (PseAA) composition and a novel hybrid feature selection frame, this paper presents a computational system to predict the PPIs (protein-protein interactions) using 8796 protein pairs. These pairs are coded by PseAA composition, resulting in 114 features. A hybrid feature selection system, mRMR-KNNs-wrapper, is applied to obtain an optimized feature set by excluding poor-performed and/or redundant features, resulting in 103 remaining features. Using the optimized 103-feature subset, a prediction model is trained and tested in the k-nearest neighbors (KNNs) learning system. This prediction model achieves an overall accurate prediction rate of 76.18%, evaluated by 10-fold cross-validation test, which is 1.46% higher than using the initial 114 features and is 6.51% higher than the 20 features, coded by amino acid compositions. The PPIs predictor, developed for this research, is available for public use at http://chemdata.shu.edu.cn/ppi. (c) 2009 Elsevier Inc. All rights reserved.	[Cai, Yudong] Shanghai Univ, Inst Syst Biol, Shanghai 200444, Peoples R China; [Liu, Liang; Lu, Wencong; Peng, Chunrong] Shanghai Univ, Coll Sci, Dept Chem, Shanghai 200444, Peoples R China; [Liu, Liang; Niu, Bing] Shanghai Univ, Sch Mat Sci & Engn, Shanghai 200072, Peoples R China; [Cai, Yudong] Chinese Acad Sci, Shanghai Inst Biol Sci, Dept Combinator & Geometry, MPG Partner Inst Computat Biol, Shanghai 200031, Peoples R China; [Feng, Kaiyan] Univ Manchester, Div Imaging Sci & Biomed Engn, Manchester M13 9PT, Lancs, England	Cai, YD (reprint author), Shanghai Univ, Inst Syst Biol, 99 Shang Da Rd, Shanghai 200444, Peoples R China.	cyd@picb.ac.cn; wclu@shu.edu.cn			National Natural Science Foundation of China [20503015, 30672671]; Shanghai Leading Academic Discipline Project [J50101]	This work was funded by National Natural Science Foundation of China (20503015 and 30672671), Shanghai Leading Academic Discipline Project (J50101) and Systems Biology Research Foundation of Shanghai University.	Alberts Bruce, 2004, MOL BIOL CELL; Ben-Hur A., 2005, BIOINFORMATICS S1, V21, P38; Bock JR, 2003, BIOINFORMATICS, V19, P125, DOI 10.1093/bioinformatics/19.1.125; Bock JR, 2001, BIOINFORMATICS, V17, P455, DOI 10.1093/bioinformatics/17.5.455; Cai YD, 2006, J THEOR BIOL, V238, P395, DOI 10.1016/j.jtbi.2005.05.035; Chen XW, 2005, BIOINFORMATICS, V21, P4394, DOI 10.1093/bioinformatics/bti721; CHOU JJW, 1993, J THEOR BIOL, V161, P251, DOI 10.1006/jtbi.1993.1053; Chou KC, 2001, PROTEINS, V44, P60, DOI 10.1002/prot.1072.abs; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou K. C., 2006, EXCLI J, V5, P55; Chou KC, 2006, J PROTEOME RES, V5, P316, DOI 10.1021/pr050331g; CHOU KC, 1994, J BIOL CHEM, V269, P22014; Chou KC, 2006, BIOCHEM BIOPH RES CO, V339, P1015, DOI 10.1016/j.bbrc.2005.10.196; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DING C, 2003, P 2 IEEE COMP SYST B, V11, P523; Du W, 1996, GENE DEV, V10, P1206, DOI 10.1101/gad.10.10.1206; DYNLACHT BD, 1994, P NATL ACAD SCI USA, V91, P6359, DOI 10.1073/pnas.91.14.6359; Enright AJ, 1999, NATURE, V402, P86; Giot L, 2003, SCIENCE, V302, P1727, DOI 10.1126/science.1090289; HELIN K, 1993, GENE DEV, V7, P1850, DOI 10.1101/gad.7.10.1850; Hermjakob H, 2004, NUCLEIC ACIDS RES, V32, pD452, DOI 10.1093/nar/gkh052; HUBBARD SJ, 1994, PROTEIN SCI, V3, P2194; Jansen R, 2003, SCIENCE, V302, P449, DOI 10.1126/science.1087361; Kerrien S, 2007, NUCLEIC ACIDS RES, V35, pD561, DOI 10.1093/nar/gkl958; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Lander ES, 2001, NATURE, V409, P860, DOI 10.1038/35057062; LANGLEY P, 1994, AAAI FALL S REV; LAWRENCE MC, 1993, J MOL BIOL, V234, P946, DOI 10.1006/jmbi.1993.1648; Martin S, 2005, BIOINFORMATICS, V21, P218, DOI 10.1093/bioinformatics/bth483; Mering C.V., 2005, NUCLEIC ACIDS RES, V33, pD433; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; Ofran Y, 2003, J MOL BIOL, V325, P377, DOI 10.1016/S0022-2836(02)01223-8; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226; Pitre S, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-365; Sprinzak E, 2001, J MOL BIOL, V311, P681, DOI 10.1006/jmbi.2001.4920; Tayers M., 1999, NATURE, V422, P193; Tsai CJ, 1997, PROTEIN SCI, V6, P53; YOUNG L, 1994, PROTEIN SCI, V3, P717; Zhou GP, 2006, PROTEINS, V63, P681, DOI 10.1002/prot.20898; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365	41	18	22	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0006-291X		BIOCHEM BIOPH RES CO	Biochem. Biophys. Res. Commun.	MAR 6	2009	380	2					318	322		10.1016/j.bbrc.2009.01.077		5	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	412RP	WOS:000263742200021	
J	Satapathy, SC; Murthy, JVR; Reddy, PVGDP; Misra, BB; Dash, PK; Panda, G				Satapathy, Suresh Chandra; Murthy, J. V. R.; Reddy, P. V. G. D. Prasad; Misra, B. B.; Dash, P. K.; Panda, G.			Particle swarm optimized multiple regression linear model for data classification	APPLIED SOFT COMPUTING			English	Article						Particle swarm optimization (PSO); Least square estimation; Multiple linear regression	PATTERN-CLASSIFICATION; CLASSIFIERS	This paper presents a new data classification method based on particle swarm optimization (PSO) techniques. The paper discusses the building of a classifier model based on multiple regression linear approach. The coefficients of multiple regression linear models (MRLMs) are estimated using least square estimation technique and PSO techniques for percentage of correct classification performance comparisons. The mathematical models are developed for many real world datasets collected from UCI machine repository. The mathematical models give the user an insight into how the attributes are interrelated to predict the class membership. The proposed approach is illustrated on many real data sets for classification purposes. The comparison results on the illustrative examples show that the PSO based approach is superior to traditional least square approach in classifying multi-class data sets. (c) 2008 Elsevier B.V. All rights reserved.	[Satapathy, Suresh Chandra] Anil Neerukonda Inst Technol & Sci, Vishakapatnam, Andhra Pradesh, India; [Murthy, J. V. R.] JNTU Coll Engn, Kakinada, India; [Misra, B. B.; Dash, P. K.] Coll Engn, Bhubaneswar, Orissa, India; [Panda, G.] Natl Inst Technol, Rourkela, India	Satapathy, SC (reprint author), Anil Neerukonda Inst Technol & Sci, Vishakapatnam, Andhra Pradesh, India.	sureshsatapathy@ieee.org					Adem J, 2006, EUR J OPER RES, V168, P181, DOI 10.1016/j.ejor.2004.04.031; Blake CL, 1998, UCI REPOSITORY MACHI; Bojarczuk CC, 2000, IEEE ENG MED BIOL, V19, P38, DOI 10.1109/51.853480; Buntine W., 1992, Statistics and Computing, V2, DOI 10.1007/BF01889584; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; Eberhart RC, 2000, IEEE C EVOL COMPUTAT, P84, DOI 10.1109/CEC.2000.870279; ERENGUC SS, 1990, MANAGE DECIS ECON, V11, P215, DOI 10.1002/mde.4090110403; Friedman J.H., 1984, CLASSIFICATION REGRE; HANSON R, 1992, P 12 INT JOINT C ART, P692; Kennedy J, 2002, IEEE C EVOL COMPUTAT, P1671; Kennedy J., 1995, P IEEE INT C NEUR NE, V4, P1942, DOI DOI 10.1109/ICNN.1995.488968; Kishore JK, 2000, IEEE T EVOLUT COMPUT, V4, P242, DOI 10.1109/4235.873235; KOZA JR, 1992, PROGRAMMING PROGRAMS; Lawson Charles L., 1974, SOLVING LEAST SQUARE; Michie D, 1994, MACHINE LEARNING NEU; MORF M, 1975, IEEE T AUTOMAT CONTR, V20, P487, DOI 10.1109/TAC.1975.1100994; Muni DP, 2004, IEEE T EVOLUT COMPUT, V8, P183, DOI 10.1109/TEVC.2004.825567; RAUSS PJ, 2000, P GEN EV COMP C GECC, P726; Richard M. D., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.4.461; Tsoi A. C., 1991, ADV NEURAL INFORMATI, V3, P963	21	4	4	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1568-4946		APPL SOFT COMPUT	Appl. Soft. Comput.	MAR	2009	9	2					470	476		10.1016/j.asoc.2008.05.007		7	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	400SE	WOS:000262888100003	
J	Zeng, Y; Yang, YP; Zhao, L				Zeng, Yong; Yang, Yupu; Zhao, Liang			Pseudo nearest neighbor rule for pattern classification	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						The k-nearest neighbor classification rule (k-NNR); Pseudo nearest neighbor classification rule (PNNR); Distance weighted k-nearest neighbor rule; The local mean-based learning; Pseudo nearest neighbor (PNN)		In this paper, we propose a new pseudo nearest neighbor classification rule (PNNR). It is different from the previous nearest neighbor rule (NNR), this new rule utilizes the distance weighted local learning in each class to get a new nearest neighbor of the unlabeled pattern-pseudo nearest neighbor (PNN), and then assigns the label associated with the PNN for the unlabeled pattern using the NNR. The proposed PNNR is compared with the k-NNR, distance weighted k-NNR, and the local mean-based nonparametric classification [Mitani, Y., & Hamamoto, Y. (2006). A local mean-based nonparametric classifier. Pattern Recognition Letters, 27, 1151-1159] in terms of the classification accuracy oil the unknown patterns. Experimental results confirm the validity of this new classification rule even in practical situations. (C) 2008 Elsevier Ltd. All rights reserved.	[Zeng, Yong; Yang, Yupu; Zhao, Liang] Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200240, Peoples R China	Zeng, Y (reprint author), Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200240, Peoples R China.	zeng_yong@sjtu.cdu.cn					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NOR; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Ferri FJ, 1999, IEEE T SYST MAN CY B, V29, P667, DOI 10.1109/3477.790454; FIX E, 1951, TR4 USAF SCH AV MED; Fukunaga K., 1990, INTRO STAT PATTERN R; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Kohavi R., 1997, P 9 EUR C MACH LEARN; Merz C. J., 1996, UCI REPOSITORY MACHI; Mitani Y, 2006, PATTERN RECOGN LETT, V27, P1151, DOI 10.1016/j.patrec.2005.12.016; MORIN RL, 1981, IEEE T SYST MAN CYB, V11, P241; Paredes R, 2006, PATTERN RECOGN, V39, P180, DOI 10.1016/j.patcog.2005.06.001; Paredes R, 2000, PATTERN RECOGN LETT, V21, P1027, DOI 10.1016/S0167-8655(00)00064-7; PENROD CS, 1977, IEEE T SYST MAN CYB, V7, P92; Ricci F, 1999, IEEE T PATTERN ANAL, V21, P380, DOI 10.1109/34.761268; VANNESS J, 1980, PATTERN RECOGN, V12, P355, DOI 10.1016/0031-3203(80)90012-6; Wilson D. R., 1996, Proceedings of the IASTED International Conference. Artificial Intelligence, Expert Systems and Neural Networks	18	2	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	MAR	2009	36	2					3587	3595		10.1016/j.eswa.2008.02.003		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	390QF	WOS:000262178100105	
J	van den Bosch, A; van Erp, M; Sporleder, C				van den Bosch, Antal; van Erp, Marieke; Sporleder, Caroline			Making a Clean Sweep of Cultural Heritage	IEEE INTELLIGENT SYSTEMS			English	Article									[van den Bosch, Antal; van Erp, Marieke] Tilburg Univ, Tilburg, Netherlands	van den Bosch, A (reprint author), Tilburg Univ, Tilburg, Netherlands.	antal.vdnbosch@uvt.nl; m.g.j.vanerp@uvt.nl; csporled@coli.uni-sb.de					Chapman AD, 2005, PRINCIPLES METHODS D; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAELEMANS PPW, 2005, MEMORY BASED LANGUAG; Kubica J, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P131, DOI 10.1109/ICDM.2003.1250912; MALETIC SJ, 2000, P INT C INF QU ICIQ, P200; REYNAERT M, 2005, THESIS TILBURG U; SPORLEDER C, 2006, P EACL 2006 WORKSH A, P40; Van Hulse JD, 2007, KNOWL INF SYST, V11, P171, DOI 10.1007/s10115-006-0022-x; Zhu XQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P378	9	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1541-1672		IEEE INTELL SYST	IEEE Intell. Syst.	MAR-APR	2009	24	2					54	63				10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	421ZT	WOS:000264397500011	
J	Steele, BM				Steele, Brian M.			Exact bootstrap k-nearest neighbor learners	MACHINE LEARNING			English	Article						Bagging; k-nearest neighbor; Classification; Regression; Ensemble methods	DISCRIMINANT-ANALYSIS; REGRESSION; CLASSIFICATION; CLASSIFIERS; SAMPLE	Bootstrap aggregation, or bagging, is a method of reducing the prediction error of a statistical learner. The goal of bagging is to construct a new learner which is the expectation of the original learner with respect to the empirical distribution function. In nearly all cases, the expectation cannot be computed analytically, and bootstrap sampling is used to produce an approximation. The k-nearest neighbor learners are exceptions to this generalization, and exact bagging of many k-nearest neighbor learners is straightforward. This article presents computationally simple and fast formulae for exact bagging of k-nearest neighbor learners and extends exact bagging methods from the conventional bootstrap sampling (sampling n observations with replacement from a set of n observations) to bootstrap sub-sampling schemes (with and without replacement). In addition, a partially exact k-nearest neighbor regression learner is developed. The article also compares the prediction error associated with elementary and exact bagging k-nearest neighbor learners, and several other ensemble methods using a suite of publicly available data sets.	Univ Montana, Dept Math Sci, Missoula, MT 59812 USA	Steele, BM (reprint author), Univ Montana, Dept Math Sci, Missoula, MT 59812 USA.	steeleb@mso.umt.edu					ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; BHATTACH.PK, 1974, ANN STAT, V2, P1034, DOI 10.1214/aos/1176342823; BIAU G, 2008, CONSISTENCY RANDOM F; Bickel PJ, 1997, STAT SINICA, V7, P1; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Buhlmann P, 2002, ANN STAT, V30, P927; Buja A, 2006, STAT SINICA, V16, P323; Caprile B, 2004, LECT NOTES COMPUT SC, V3077, P72; CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P596, DOI 10.2307/2289282; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Friedman JH, 2007, J STAT PLAN INFER, V137, P669, DOI 10.1016/j.jspi.2006.06.002; GERTHEISS J, 2008, 033 U MUNICH DEP STA; Grandvalet Y, 2004, MACH LEARN, V55, P251, DOI 10.1023/B:MACH.0000027783.34431.42; Hall P, 2005, J ROY STAT SOC B, V67, P363, DOI 10.1111/j.1467-9868.2005.00506.x; Hastie T, 2001, ELEMENTS STAT LEARNI; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.2307/1267351; Hutson AD, 2000, J ROY STAT SOC B, V62, P89, DOI 10.1111/1467-9868.00221; Loader C., 1999, LOCAL REGRESSION LIK; LOH WL, 1995, J MULTIVARIATE ANAL, V53, P264, DOI 10.1006/jmva.1995.1036; Maclin R., 1997, P 14 NAT C ART INT, P546; Mood A.M, 1974, INTRO THEORY STAT; PANCOV P, 2007, ADV INTELLIGENT DATA, V7, P118; Ripley B. D., 1996, PATTERN RECOGNITION; Skurichina M, 1998, PATTERN RECOGN, V31, P909, DOI 10.1016/S0031-3203(97)00110-6; Steele BM, 2003, ENVIRON ECOL STAT, V10, P333, DOI 10.1023/A:1025111108050; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	32	4	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	MAR	2009	74	3					235	255		10.1007/s10994-008-5096-0		21	Computer Science, Artificial Intelligence	Computer Science	407RV	WOS:000263382900001	
J	Garcia-Laencina, PJ; Sancho-Gomez, JL; Figueiras-Vidal, AR; Verleysen, M				Garcia-Laencina, Pedro J.; Sancho-Gomez, Jose-Luis; Figueiras-Vidal, Anibal R.; Verleysen, Michel			K nearest neighbours with mutual information for simultaneous classification and missing data imputation	NEUROCOMPUTING			English	Article	18th European Symposium on Artificial Neural Networks	APR, 2008	Brugge, BELGIUM			Missing data; Pattern classification; Imputation; K nearest neighbours; Mutual information	LEARNING VECTOR QUANTIZATION; FEATURE-SELECTION; ALGORITHMS; VALUES	Missing data is a common drawback in many real-life pattern classification scenarios. One of the most popular solutions is missing data imputation by the K nearest neighbours (KNN) algorithm. In this article, we propose a novel KNN imputation procedure using a feature-weighted distance metric based on mutual information (MI). This method provides a missing data estimation aimed at solving the classification task, i.e., it provides an imputed dataset which is directed toward improving the classification performance. The MI-based distance metric is also used to implement an effective KNN classifier. Experimental results on both artificial and real classification datasets are provided to illustrate the efficiency and the robustness of the proposed algorithm. (C) 2009 Elsevier B.V. All rights reserved.	[Garcia-Laencina, Pedro J.; Sancho-Gomez, Jose-Luis] Univ Politecn Cartagena, Dept Informat & Commun Technol, Murcia 30202, Spain; [Figueiras-Vidal, Anibal R.] Univ Carlos III Madrid, Dept Signal Theory & Commun, Madrid 28911, Spain; [Verleysen, Michel] Univ Catholique Louvain, DICE, Machine Learning Grp, B-1348 Louvain, Belgium	Garcia-Laencina, PJ (reprint author), Univ Politecn Cartagena, Dept Informat & Commun Technol, Plaza Hosp 1, Murcia 30202, Spain.	pedroj.garcia@upct.es	Garcia-Laencina, Pedro J./I-2173-2012				Acuna E, 2004, ST CLASS DAT ANAL, P639; Aha D.W., 1997, LAZY LEARNING; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Allison PD, 2001, SAGE U PAPERS SERIES; Batista G.E., 2002, 2 INT C HYBR INT SYS, V87, P251; Batista GEAPA, 2003, APPL ARTIF INTELL, V17, P519, DOI 10.1080/08839510390219309; Bishop C. M., 1995, NEURAL NETWORKS PATT; Brown JG, 2002, APPL ECON LETT, V9, P311, DOI 10.1080/13504850110069980; Burr Ridge I, 1997, MACHINE LEARNING; Cover T. M., 1991, ELEMENTS INFORM THEO; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N., 2000, SUPPORT VECTOR MACHI; Duda R.O., 2000, PATTERN CLASSIFICATI; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Francois D, 2007, NEUROCOMPUTING, V70, P1276, DOI 10.1016/j.neucom.2006.11.019; Gabrys B, 2002, INT J APPROX REASON, V30, P149, DOI 10.1016/S0888-613X(02)00070-1; Ghahramani Z., 1994, ADV NEURAL INFORMATI, V6, P120; HALATCHEV M, 2005, COMAD, P83; Hammer B, 2002, NEURAL NETWORKS, V15, P1059, DOI 10.1016/S0893-6080(02)00079-5; HECHENBICHLER K, 2007, WEIGHTED K NEAREST N; ISHIBUCHI H, 1993, P IEEE INT JOINT C N, P1871; JEREZ JM, 2006, BIOMED 06, P323; Kim H, 2005, BIOINFORMATICS, V21, P187, DOI 10.1093/bioinformatics/bth499; KIM H, 2004, IEEE COMP SYST BIOIN; Kullback S., 1959, INFORM THEORY STAT; Kwak N, 2002, IEEE T PATTERN ANAL, V24, P1667, DOI 10.1109/TPAMI.2002.1114861; Little RJA, 1999, J RHEUMATOL, V26, P1654; Little RJA, 2002, STAT ANAL MISSING DA; MARKEY MK, 2004, INT C MACH LEARN APP, P351; McLachlan G, 1997, EM ALGORITHM EXTENSI; Narayanan S, 2002, IEEE IJCNN, P2872, DOI 10.1109/IJCNN.2002.1007604; Newman D. J., 1998, UCI REPOSITORY MACHI; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Rossi F, 2006, CHEMOMETR INTELL LAB, V80, P215, DOI 10.1016/j.chemolab.2005.06.010; Rubin DB, 1987, MULTIPLE IMPUTATION; Schafer JL, 1997, ANAL INCOMPLETE MULT; Sehgal MSB, 2005, BIOINFORMATICS, V21, P2417, DOI 10.1093/bioinformatics/bti345; SONG Y, 2007, 11 EUR C PRINC PRACT, P248; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; Tsumoto S, 2000, P INT COMP SOFTW APP, V24, P467; Villmann T, 2006, NEURAL NETWORKS, V19, P610, DOI 10.1016/j.neunet.2005.07.013; Weinberger KQ, 2006, ADV NEURAL INFORM PR, V18, P1473; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256	44	12	16	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	MAR	2009	72	7-9					1483	1493		10.1016/j.neucom.2008.11.026		11	Computer Science, Artificial Intelligence	Computer Science	430MM	WOS:000264993200012	
J	Diaz, NN; Krause, L; Goesmann, A; Niehaus, K; Nattkemper, TW				Diaz, Naryttza N.; Krause, Lutz; Goesmann, Alexander; Niehaus, Karsten; Nattkemper, Tim W.			TACOA - Taxonomic classification of environmental genomic fragments using a kernelized nearest neighbor approach	BMC BIOINFORMATICS			English	Article							HORIZONTAL GENE-TRANSFER; PHYLOGENETIC CLASSIFICATION; DNA FRAGMENTS; PREDICTION; SEQUENCES; BACTERIAL; DATABASE; PROKARYOTES; FREQUENCIES; ALGORITHMS	Background: Metagenomics, or the sequencing and analysis of collective genomes (metagenomes) of microorganisms isolated from an environment, promises direct access to the "unculturable majority". This emerging field offers the potential to lay solid basis on our understanding of the entire living world. However, the taxonomic classification is an essential task in the analysis of metagenomics data sets that it is still far from being solved. We present a novel strategy to predict the taxonomic origin of environmental genomic fragments. The proposed classifier combines the idea of the k-nearest neighbor with strategies from kernel-based learning. Results: Our novel strategy was extensively evaluated using the leave-one-out cross validation strategy on fragments of variable length (800 bp - 50 Kbp) from 373 completely sequenced genomes. TACOA is able to classify genomic fragments of length 800 bp and 1 Kbp with high accuracy until rank class. For longer fragments >= 3 Kbp accurate predictions are made at even deeper taxonomic ranks (order and genus). Remarkably, TACOA also produces reliable results when the taxonomic origin of a fragment is not represented in the reference set, thus classifying such fragments to its known broader taxonomic class or simply as "unknown". We compared the classification accuracy of TACOA with the latest intrinsic classifier PhyloPythia using 63 recently published complete genomes. For fragments of length 800 bp and 1 Kbp the overall accuracy of TACOA is higher than that obtained by PhyloPythia at all taxonomic ranks. For all fragment lengths, both methods achieved comparable high specificity results up to rank class and low false negative rates are also obtained. Conclusion: An accurate multi-class taxonomic classifier was developed for environmental genomic fragments. TACOA can predict with high reliability the taxonomic origin of genomic fragments as short as 800 bp. The proposed method is transparent, fast, accurate and the reference set can be easily updated as newly sequenced genomes become available. Moreover, the method demonstrated to be competitive when compared to the most current classifier PhyloPythia and has the advantage that it can be locally installed and the reference set can be kept up-to-date.	[Diaz, Naryttza N.; Goesmann, Alexander] Univ Bielefeld, Ctr Biotechnol CeBiTec, Bielefeld, Germany; [Diaz, Naryttza N.; Nattkemper, Tim W.] Univ Bielefeld, Biodata Min & Appl Neuroinformat Grp, Fac Technol, Bielefeld, Germany; Univ Bielefeld, Fac Biol, Proteome & Metabolome Res, Bielefeld, Germany; [Krause, Lutz] Nestle Res Ctr, BioAnalyt Sci Dept, CH-1000 Lausanne, Switzerland	Diaz, NN (reprint author), Univ Bielefeld, Ctr Biotechnol CeBiTec, Bielefeld, Germany.	ndiaz@CeBiTec.Uni-Bielefeld.DE; Lutz.Krause@rdls.nestle.com; agoesman@CeBiTec.Uni-Bielefeld.DE; karsten.niehaus@CeBiTec.Uni-Bielefeld.DE; tim.nattkemper@Uni-Bielefeld.DE	Niehaus, Karsten/A-3966-2010; Krause, Lutz/G-6283-2013	Krause, Lutz/0000-0003-3806-0845	Deutscher Akademischer Austauschdienst	NND was supported by the Deutscher Akademischer Austauschdienst. The authors wish to thank Torsten Kasch, Achim Neumann, Ralf Nolte, Bjrn Fischer and Volker Tlle as members of the Bioinformatics Resource Facility for providing the computational and technical support to accomplish this work. We thank I. Rigoutsos from the Bioinformatics and Pattern Discovery Group, IBM Thomas J Watson Research Center for all the help in using the PhyloPythia web server.	ABE T, 2006, POLAR BIOSCI, V20, P103; Abe T, 2005, DNA RES, V12, P281, DOI 10.1093/dnares/dsi015; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Berrar D, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-73; Bohlin J, 2008, BMC GENOMICS, V9, DOI 10.1186/1471-2164-9-104; Bohlin J, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000057; Brown JR, 2003, NAT REV GENET, V4, P121, DOI 10.1038/nrg1000; Campbell A, 1999, P NATL ACAD SCI USA, V96, P9184, DOI 10.1073/pnas.96.16.9184; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Finn RD, 2008, NUCLEIC ACIDS RES, V36, pD281, DOI 10.1093/nar/gkm960; FLEISCHMANN RD, 1995, SCIENCE, V269, P496, DOI 10.1126/science.7542800; Foerstner KU, 2005, EMBO REP, V6, P1208, DOI 10.1038/sj.embor.7400538; Garcia-Vallve S, 2000, GENOME RES, V10, P1719, DOI 10.1101/gr.130000; Hastie T., 2002, ELEMENTS STAT LEARNI; Huson DH, 2007, GENOME RES, V17, P377, DOI 10.1101/gr.5969107; Karlin S, 1997, J BACTERIOL, V179, P3899; Keeling PJ, 2008, NAT REV GENET, V9, P605, DOI 10.1038/nrg2386; Koonin EV, 2001, ANNU REV MICROBIOL, V55, P709, DOI 10.1146/annurev.micro.55.1.709; Krause L, 2008, NUCLEIC ACIDS RES, V36, P2230, DOI 10.1093/nar/gkn038; Krause L, 2008, J BIOTECHNOL, V136, P91, DOI 10.1016/j.jbiotec.2008.06.003; Margulies M, 2005, NATURE, V437, P376, DOI 10.1038/nature03959; McHardy AC, 2007, NAT METHODS, V4, P63, DOI 10.1038/NMETH976; Overbeek R, 2005, NUCLEIC ACIDS RES, V33, P5691, DOI 10.1093/nar/gki866; Podell S, 2007, GENOME BIOL, V8, DOI 10.1186/gb-2007-8-2-r16; Raes J, 2007, CURR OPIN MICROBIOL, V10, P490, DOI 10.1016/j.mib.2007.09.001; Ruepp A, 2000, NATURE, V407, P508; Saha S, 2006, GENET MOL RES, V5, P224; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; Sandberg R, 2001, GENOME RES, V11, P1404, DOI 10.1101/gr.186401; SANGER F, 1977, P NATL ACAD SCI USA, V74, P5463, DOI 10.1073/pnas.74.12.5463; Stein JL, 1996, J BACTERIOL, V178, P591; Chan CKK, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-215; Teeling H, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-163; Teeling H, 2004, ENVIRON MICROBIOL, V6, P938, DOI 10.1111/j.1462-2920.2004.00624.x; Tran TN, 2006, COMPUT STAT DATA AN, V51, P513, DOI 10.1016/j.csda.2005.10.001; Tyson GW, 2004, NATURE, V428, P37, DOI 10.1038/nature02340; Venter JC, 1998, SCIENCE, V280, P1540, DOI 10.1126/science.280.5369.1540; Wheeler DL, 2002, NUCLEIC ACIDS RES, V30, P13, DOI 10.1093/nar/30.1.13; Yao ZZ, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-S1-S11; ZHANG SH, 2008, NATURE PRECEDINGS, P1; Zhu M, 2007, BMC MED INFORM DECIS, V7, DOI 10.1186/1472-6947-7-41	42	47	48	BIOMED CENTRAL LTD	LONDON	CURRENT SCIENCE GROUP, MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	FEB 11	2009	10								56	10.1186/1471-2105-10-56		16	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	416LP	WOS:000264007900001	
J	Sakiyama, Y				Sakiyama, Yojiro			The use of machine learning and nonlinear statistical tools for ADME prediction	EXPERT OPINION ON DRUG METABOLISM & TOXICOLOGY			English	Review						ADME; ensemble; in silico; kernel; machine learning; nonlinear	SUPPORT VECTOR MACHINES; STRUCTURE-PROPERTY RELATIONSHIPS; RECURSIVE-PARTITIONING MODEL; HUMAN INTESTINAL-ABSORPTION; LIVER MICROSOMAL STABILITY; BRAIN-BARRIER PERMEATION; SELF-ORGANIZING MAPS; GENE-EXPRESSION DATA; IN-SILICO; AQUEOUS SOLUBILITY	Absorption, distribution, metabolism and excretion (ADME)-related failure of drug candidates is a major issue for the pharmaceutical industry today. Prediction of ADME by in silico tools has now become an inevitable paradigm to reduce cost and enhance efficiency in pharmaceutical research. Recently, machine learning as well as nonlinear statistical tools has been widely applied to predict routine ADME end points. To achieve accurate and reliable predictions, it would be a prerequisite to understand the concepts, mechanisms and limitations of these tools. Here, we have devised a small synthetic nonlinear data set to help understand the mechanism of machine learning by 2D-visualisation. We applied six new machine learning methods to four different data sets. The methods include Naive Bayes classifier, classification and regression tree, random forest, Gaussian process, support vector machine and k nearest neighbour. The results demonstrated that ensemble learning and kernel machine displayed greater accuracy of prediction than classical methods irrespective of the data set size. The importance of interaction with the engineering field is also addressed. The results described here provide insights into the mechanism of machine learning, which will enable appropriate usage in the future.	Sandwich Labs, Pfizer Global Res & Dev, Pharmacokinet Dynam Metab, Sandwich CT13 9NJ, Kent, England	Sakiyama, Y (reprint author), Sandwich Labs, Pfizer Global Res & Dev, Pharmacokinet Dynam Metab, Sandwich CT13 9NJ, Kent, England.	Yojiro.Sakiyama@pfizer.com					AKAIKE H, 1978, BIOMETRIKA, V65, P53, DOI 10.1093/biomet/65.1.53; Arimoto R, 2005, J BIOMOL SCREEN, V10, P197, DOI 10.1177/1087057104274091; ATKSON CG, 1997, ARTIF INTELL REV, V11, P11; Balakin Konstantin V, 2005, Curr Drug Discov Technol, V2, P99, DOI 10.2174/1570163054064666; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; BARRETT SJ, 2005, ADV APPL MACHINE LEA; Bayes T., 1763, PHILOS T ROY SOC LON, V53, P370, DOI DOI 10.1098/RSBL.1763.0053; Bellman R., 1961, ADAPTIVE CONTROL PRO; Bishop C. M., 2006, PATTERN RECOGNITION; Bishop C. M., 1995, NEURAL NETWORKS PATT; Boubacar HA, 2008, NEURAL NETWORKS, V21, P1287, DOI 10.1016/j.neunet.2008.03.016; BOX GBP, 2005, FRACTIONAL FACTORIAL; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Broomhead D. S., 1988, Complex Systems, V2; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Bruneau P, 2001, J CHEM INF COMP SCI, V41, P1605, DOI 10.1021/ci010363y; Burbidge R, 2001, COMPUT CHEM, V26, P5, DOI 10.1016/S0097-8485(01)00094-8; Burden FR, 2000, J CHEM INF COMP SCI, V40, P1423, DOI 10.1021/ci000450a; Burden FR, 2001, J CHEM INF COMP SCI, V41, P830, DOI 10.1021/ci000459c; Burr Ridge I, 1997, MACHINE LEARNING; Burton J, 2006, J MED CHEM, V49, P6231, DOI 10.1021/jm060267u; Cartmell J, 2005, J COMPUT AID MOL DES, V19, P821, DOI 10.1007/s10822-005-9029-8; CATUANA R, 2008, P 25 INT C MACH LEAR; Chohan KK, 2005, J MED CHEM, V48, P5154, DOI 10.1021/jm048959a; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; de Cerqueira Lima P., 2006, J CHEM INF MODEL, V46, P1245; Deconinck E, 2005, J PHARMACEUT BIOMED, V39, P91, DOI 10.1016/j.jpba.2005.03.008; Deconinck E, 2005, J PHARMACEUT BIOMED, V39, P1021, DOI 10.1016/j.jpba.2005.05.034; de Graaf C, 2005, J MED CHEM, V48, P2725, DOI 10.1021/jm040180d; de Groot MJ, 2002, ADV DRUG DELIVER REV, V54, P367, DOI 10.1016/S0169-409X(02)00009-1; Delaney JS, 2004, J CHEM INF COMP SCI, V44, P1000, DOI 10.1021/ci034243x; Devillers J, 1998, J PHARM SCI-US, V87, P1086, DOI 10.1021/js980101j; DOGRA SK, 2008, CHOICE MODELS QSARWO; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Ekins S, 2006, J MED CHEM, V49, P5059, DOI 10.1021/jm060076r; Ekins Sean, 2005, Expert Opin Drug Metab Toxicol, V1, P303, DOI 10.1517/17425255.1.2.303; Embrechts MJ, 2007, DRUG METAB DISPOS, V35, P325, DOI 10.1124/dmd.106.013185; Fox T, 2006, CURR TOP MED CHEM, V6, P1579, DOI 10.2174/156802606778108915; FRIEDMAN J, 1988, MULTIVARIATE ADAPTIV; Frohlich H, 2006, QSAR COMB SCI, V25, P317, DOI 10.1002/qsar.200510135; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Gamerman D., 1997, MARKOV CHAIN MONTE C; Ghose AK, 2008, J MED CHEM, V51, P5149, DOI 10.1021/jm800475y; Gleeson MP, 2006, J MED CHEM, V49, P1953, DOI 10.1021/jm0510070; Golbraikh A, 2002, J MOL GRAPH MODEL, V20, P269, DOI 10.1016/S1093-3263(01)00123-1; GOOD IJ, 1964, ESTIMATION PROBABILI; GREEN DM, 1966, SIGNAL DETECTION THE, P45; GUPTA N, QSARWORLD STRAND LIF; Hansch C, 2004, DRUG METAB REV, V36, P105, DOI 10.1081/DMR-120028428; Hawkins DM, 2003, J CHEM INF COMP SCI, V43, P579, DOI 10.1021/ci025626i; Hebb D O, 1949, ORG BEHAV; HESTENES MR, 1952, J RES NAT BUR STAND, V49, P409, DOI 10.6028/jres.049.044; Holland J., 1975, ADAPTATION NATURAL A; Hopfield JJ, 1982, NATL ACAD SCI, V79, P2554, DOI DOI 10.1073/PNAS.79.8.2554; Hou TJ, 2007, J CHEM INF MODEL, V47, P2408, DOI 10.1021/ci7002076; Hou TJ, 2007, J CHEM INF MODEL, V47, P208, DOI 10.1021/ci600343x; Hsu C.-W., PRACTICAL GUIDE SUPP; Hunt EB, 1966, EXPT INDUCTION; Huuskonen J, 1997, J PHARM SCI, V86, P450, DOI 10.1021/js960358m; Jensen TS, 2002, EUR J PAIN-LONDON, V6, P3, DOI 10.1016/S1090-3801(02)90002-9; Jin B, 2007, INT J DATA MIN BIOIN, V1, P270, DOI 10.1504/IJDMB.2007.011613; Jordan M., 1999, LEARNING GRAPHICAL M; Jung E, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-245; Kaiser D, 2007, J MED CHEM, V50, P1698, DOI 10.1021/jm060604z; Karthikeyan M, 2005, J CHEM INF MODEL, V45, P581, DOI 10.1021/ci0500132; Keefer CE, 2006, CHEMOMETR INTELL LAB, V84, P40, DOI 10.1016/j.chemolab.2006.04.013; Klon AE, 2006, J CHEM INF MODEL, V46, P1945, DOI 10.1021/ci0601315; Kohavi R., 1995, P 14 INT JOINT C ART, V2, P1137; Kohonen T., 1984, SELF ORG ASS MEMORY; Kola I, 2004, NAT REV DRUG DISCOV, V3, P711, DOI 10.1038/nrd1470; Kononenko I., 2007, MACHINE LEARNING DAT; Kriegl JM, 2005, J COMPUT AID MOL DES, V19, P189, DOI 10.1007/s10822-005-3785-3; Kuentz M, 2003, PHARM DEV TECHNOL, V8, P453, DOI 10.1081/PDT-120024698; Kurogi Y, 2001, CURR MED CHEM, V8, P1035; Lamanna C, 2008, J MED CHEM, V51, P2891, DOI 10.1021/jm701407x; Lee PH, 2007, J COMPUT AID MOL DES, V21, P665, DOI 10.1007/s10822-007-9124-0; Li GZ, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-S6-S7; Li H, 2005, J CHEM INF MODEL, V45, P1376, DOI 10.1021/ci050135u; Li H, 2007, J PHARM SCI-US, V96, P2838, DOI 10.1002/jps.20985; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; Liu HX, 2005, J COMPUT AID MOL DES, V19, P499, DOI 10.1007/s10822-005-9003-5; Liu KH, 2008, COMPUT BIOL MED, V38, P601, DOI 10.1016/j.compbiomed.2008.02.007; Liu Q, 2008, J BIOMOL STRUCT DYN, V25, P685; Lombardo F, 2006, J MED CHEM, V49, P2262, DOI 10.1021/jm050200r; Ma WP, 2006, J CHROMATOGR A, V1113, P140, DOI 10.1016/j.chroma.2006.01.136; Ma Xiao Hua, 2008, Curr Drug Saf, V3, P100, DOI 10.2174/157488608784529224; MACKAY DJC, 1992, NEURAL COMPUT, V4, P720, DOI 10.1162/neco.1992.4.5.720; MACKAY DJC, 1995, MAXIMUM ENTROPY BAYE, P211; Mente SR, 2005, J COMPUT AID MOL DES, V19, P465, DOI 10.1007/s10822-005-9001-7; Minka T. P., 2001, P 17 C UNC ART INT, P362; Banka H, 2008, CH CRC COMP SCI DATA, P277; MOSTELLER F, 1948, ANN MATH STAT, V19, P58, DOI 10.1214/aoms/1177730290; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Narasimhan B, 2006, CHEM PHARM BULL, V54, P1067, DOI 10.1248/cpb.54.1067; Narayanan R, 2005, BIOORGAN MED CHEM, V13, P3017, DOI 10.1016/j.bmc.2005.01.061; NEAL RM, 1997, 9702 U TOR DEP STAT, V45, P5; Neal R.M., 1996, BAYESIAN LEARNING NE; Netzeva TI, 2005, ATLA-ALTERN LAB ANIM, V33, P155; Neumann MH, 2000, STAT SINICA, V10, P399; Nilsson Nils J., 1965, LEARNING MACHINES; Nocedal J, 1999, NUMERICAL OPTIMIZATI; Obrezanova O, 2007, J CHEM INF MODEL, V47, P1847, DOI 10.1021/ci7000633; Obrezanova O, 2008, J COMPUT AID MOL DES, V22, P431, DOI 10.1007/s10822-008-9193-8; O'Brien SE, 2005, J MED CHEM, V48, P1287, DOI 10.1021/jm049254b; Osuna E., 1997, NEURAL NETWORKS SIGN, P276; Palmer DS, 2007, J CHEM INF MODEL, V47, P150, DOI 10.1021/ci060164k; Pedersen A G, 1997, Proc Int Conf Intell Syst Mol Biol, V5, P226; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, DOI 10.1109/MCAS.2006.1688199; Polley MJ, 2005, AUST J CHEM, V58, P859, DOI 10.1071/CH05202; QUINLAIN JR, 1979, EXPERT SYSTEMS MICRO; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Rodriguez JJ, 2006, IEEE T PATTERN ANAL, V28, P1619, DOI 10.1109/TPAMI.2006.211; ROGERS D, 1994, J CHEM INF COMP SCI, V34, P854, DOI 10.1021/ci00020a020; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; Rumelhart DE H.G., 1986, PARALLEL DISTRIBUTED, P1; SAKIYAMA Y, 2008, P 2008 INT C MACH LE, V2, P784; Sakiyama Y, 2008, J MOL GRAPH MODEL, V26, P907, DOI 10.1016/j.jmgm.2007.06.005; Sato T, 2008, J MED CHEM, V51, P7705, DOI 10.1021/jm800504q; Schroeter T, 2007, MOL PHARMACEUT, V4, P524, DOI 10.1021/mp0700413; Schroeter TS, 2007, J COMPUT AID MOL DES, V21, P651, DOI 10.1007/s10822-007-9160-9; Schwaighofer A, 2008, J CHEM INF MODEL, V48, P785, DOI 10.1021/ci700142c; Schwaighofer A, 2007, J CHEM INF MODEL, V47, P407, DOI 10.1021/ci600205g; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SKINNER BT, 2007, C P IEEE ENG MED BIO, P3120; SONNENBURG S, J MACH LEARN, P2443; Sorich MJ, 2008, CURR DRUG METAB, V9, P60, DOI 10.2174/138920008783331167; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; STOKES ME, 1995, CATEGORICAL DATA ANA, P98; STONE M, 1974, J R STAT SOC B, V36, P111; Susnow RG, 2003, J CHEM INF COMP SCI, V43, P1308, DOI 10.1021/ci030283p; Svetnik V, 2005, J CHEM INF MODEL, V45, P786, DOI 10.1021/ci0500379; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Team RDC, R LANG ENV STAT COMP; Tong WD, 2005, CURR COMPUT-AID DRUG, V1, P195, DOI 10.2174/1573409053585663; TOPLISS JG, 1979, J MED CHEM, V22, P1238, DOI 10.1021/jm00196a017; Toronen P, 1999, FEBS LETT, V451, P142, DOI 10.1016/S0014-5793(99)00524-4; Tropsha A, 2003, QSAR COMB SCI, V22, P69, DOI 10.1002/qsar.200390007; Trotter MWB, 2003, QSAR COMB SCI, V22, P533, DOI 10.1002/qsar.200310006; Vapnik V.N., 1995, NATURE STAT LEARNING; Varma S, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-91; Votano JR, 2006, J MED CHEM, V49, P7169, DOI 10.1021/jm051245v; Wang YH, 2005, J COMPUT AID MOL DES, V19, P137, DOI 10.1007/s10822-005-3321-5; Wang YH, 2005, BIOORG MED CHEM LETT, V15, P4076, DOI 10.1016/j.bmcl.2005.06.015; Wang YH, 2005, J CHEM INF MODEL, V45, P750, DOI 10.1021/ci050041k; Whittaker J., 1990, GRAPHICAL MODELS APP, P507; Williams CKI, 1998, IEEE T PATTERN ANAL, V20, P1342, DOI 10.1109/34.735807; Winkler DA, 2004, DRUG FUTURE, V29, P1043, DOI 10.1358/dof.2004.029.10.863395; Wu CFJ, 2000, EXPT PLANNING ANAL P; Yamashita F, 2006, J CHEM INF MODEL, V46, P1054, DOI 10.1021/ci0504770; Yamashita F, 2008, J CHEM INF MODEL, V48, P364, DOI 10.1021/ci700262y; Yap CW, 2007, MINI-REV MED CHEM, V7, P1097, DOI 10.2174/138955707782331696; Yap CW, 2005, J CHEM INF MODEL, V45, P982, DOI 10.1021/ci0500536; Yap CW, 2006, CURR TOP MED CHEM, V6, P1593, DOI 10.2174/156802606778108942; Yin YH, 1996, NUCLEIC ACIDS RES, V24, P1279, DOI 10.1093/nar/24.7.1279; Yoo PD, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-272; Zhang LY, 2008, PHARM RES-DORDR, V25, P1902, DOI 10.1007/s11095-008-9609-0; Zhang SX, 2006, J CHEM INF MODEL, V46, P1984, DOI 10.1021/ci060132x; Zhao CY, 2006, PHARM RES, V23, P41, DOI 10.1007/s11095-005-8716-4; Zien A, 2000, BIOINFORMATICS, V16, P799, DOI 10.1093/bioinformatics/16.9.799; [Anonymous], WEKA 3 DATA MINING S; 2008, INT C MACH LEARN MOD	165	6	6	INFORMA HEALTHCARE	LONDON	TELEPHONE HOUSE, 69-77 PAUL STREET, LONDON EC2A 4LQ, ENGLAND	1742-5255		EXPERT OPIN DRUG MET	Expert Opin. Drug Metab. Toxicol.	FEB	2009	5	2					149	169		10.1517/17425250902753261		21	Biochemistry & Molecular Biology; Pharmacology & Pharmacy	Biochemistry & Molecular Biology; Pharmacology & Pharmacy	419QH	WOS:000264233800005	
J	Frigui, H; Gader, P				Frigui, Hichem; Gader, Paul			Detection and Discrimination of Land Mines in Ground-Penetrating Radar Based on Edge Histogram Descriptors and a Possibilistic K-Nearest Neighbor Classifier	IEEE TRANSACTIONS ON FUZZY SYSTEMS			English	Article						Edge histogram descriptor; feature-based discrimination; land mine detection; possibilistic K-nearest neighbor (K-NN)	PATTERN-CLASSIFICATION; LANDMINES; GPR; RULE	This paper describes an algorithm for land mine detection using sensor data generated by a ground-penetrating radar (GPR) system that uses edge histogram descriptors for feature extraction and a possibilistic K-nearest neighbors (K-NNs) rule for confidence assignment. The algorithm demonstrated the best performance among several high-performance algorithms in extensive testing on a large real-world datasets associated with the difficult problem of land mine detection. The superior performance of the algorithm is attributed to the use of the possibilistic K-NN algorithm, thereby providing important evidence supporting the use of possibilistic methods in real-world applications. The GPR produces a 3-D array of intensity values, representing a volume below the surface of the ground. First, a computationally inexpensive pre-screening algorithm for anomaly detection is used to focus attention and identify candidate signatures that resemble mines. The identified regions of interest are processed further by a feature extraction algorithm to capture their salient features. We use translation-invariant features that are based on the local edge distribution of the 3-D GPR signatures. Specifically, each 3-D signature is divided into subsignatures, and the local edge distribution for each subsignature is represented by a histogram. Next, the training signatures are clustered to identify prototypes. The main idea is to identify few prototypes that can capture the variations of the signatures within each class. These variations could be due to different mine types, different soil conditions, different weather conditions, etc. Fuzzy memberships are assigned to these representatives to capture their degree of sharing among the mines and false alarm classes. Finally, a possibilistic K-NN-based rule is used to assign a confidence value to distinguish true detections from false alarms. The proposed algorithm is implemented and integrated within a complete land mine prototype system. It is trained, field-tested, evaluated, and compared using a large-scale cross-validation experiment that uses a diverse dataset acquired from four outdoor test sites at different geographic locations. This collection covers over 41807 m(2) of ground and includes 1593 mine encounters.	[Frigui, Hichem] Univ Louisville, Dept Comp Sci & Comp Engn, Louisville, KY 40292 USA; [Gader, Paul] Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA	Frigui, H (reprint author), Univ Louisville, Dept Comp Sci & Comp Engn, Louisville, KY 40292 USA.	h.frigui@louisville.edu; pgader@cise.ufl.edu			National Science Foundation (NSF) [CBET-0730802, CBET-0730484]; Kentucky Science and Engineering Foundation [KSEF-148-502-05-153]; U.S. Army [DAAB 15-02-D-0003]; Office of Naval Research [N00014-05-10789]; Army Research Office and U.S. Army Research Laboratory [DAAD19-02-2-0012]	Manuscript received February 27, 2(K)S; revised June 23, 2008; accepted August 16, 2008. First published September 3, 2008; current version published February 4, 2009. This work was supported in part by (he National Science Foundation (NSF) under Award CBET-0730802 and Award CBET-0730484, by the Kentucky Science and Engineering Foundation under Grant KSEF-148-502-05-153, by the U.S. Army under Grant DAAB 15-02-D-0003, by the Office of Naval Research under Award N00014-05-10789, and by an Army Research Office and U.S. Army Research Laboratory under Cooperative Agreement DAAD19-02-2-0012.	Ayers L., 2004, MIDAS MINE DETECTION; Brunzell H, 1999, IEEE T GEOSCI REMOTE, V37, P875, DOI 10.1109/36.752207; Carevic D, 1999, P SOC PHOTO-OPT INS, V3710, P973, DOI 10.1117/12.357117; Carevic D., 1999, SPIE C DET REM TECHN, P1284; CHEN AT, 1999, IEEE T PATTERN ANAL, V21, P77; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dubois D., 1988, POSSIBILITY THEORY; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Frigui H., 2005, EURASIP J APPL SIG P, V12, P1867; FRIGUI H, 2007, P SPIE C DET REM TEC, V6553; FRIGUI H, 2003, P IEEE INT C FUZZ SY, V2, P834; FRIGUI H, 2006, P SPIE C DET REM TEC, P6217; Gader P, 2004, IEEE T GEOSCI REMOTE, V42, P2522, DOI 10.1109/TGRS.2004.837333; Gader PD, 1999, P SOC PHOTO-OPT INS, V3710, P1075, DOI 10.1117/12.356988; Gader PD, 2004, P SOC PHOTO-OPT INS, V5415, P953, DOI 10.1117/12.544320; Gader PD, 2000, SIGNAL PROCESS, V80, P1069, DOI 10.1016/S0165-1684(00)00020-7; Gader PD, 2001, IEEE T GEOSCI REMOTE, V39, P1231, DOI 10.1109/36.927446; GUNATILAKA A, 2000, P SPIE C DET REM TEC, V5, P1008; Hastie T, 1996, ADV NEUR IN, V8, P409; Hattori K, 1999, PATTERN RECOGN, V32, P425, DOI 10.1016/S0031-3203(98)00097-1; HINTZ KJ, 2004, P SPIE C DET REM TEC, V9, P399; Ho KC, 2008, IEEE T GEOSCI REMOTE, V46, P1177, DOI 10.1109/TGRS.2008.915747; JUIFENG H, 2004, P INT C SIGN PROC IC, V3, P2159; KASKETT HT, 1999, P SPIE C DET REM TEC, P942; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Kohonen T., 1989, SELF ORG ASS MEMORY; KRISHNAPURAM R, 1993, INT J FUZZY SYST, V2, P98; Lee WH, 2007, IEEE T GEOSCI REMOTE, V45, P389, DOI 10.1109/TGRS.2006.887018; Lopera O, 2007, IEEE T GEOSCI REMOTE, V45, P707, DOI 10.1109/TGRS.2006.888136; MacDonald J., 2003, ALTERNATIVES LANDMIN; Manjunath B. S., 2002, INTRO MPEG 7 MULTIME; Milisavljevic N, 2008, IEEE T GEOSCI REMOTE, V46, P1488, DOI 10.1109/TGRS.2008.916210; Nguyen TT, 2005, P SOC PHOTO-OPT INS, V5794, P198, DOI 10.1117/12.626263; OHKI M, 1991, IEEE T CONSUM ELECTR, V37, P66, DOI 10.1109/30.73648; Proakis J.G., 1996, DIGITAL SIGNAL PROCE; Somasundaram SD, 2006, CLIMBING AND WALKING ROBOTS, P833, DOI 10.1007/3-540-26415-9_100; Stiles JM, 1999, P SOC PHOTO-OPT INS, V3710, P992, DOI 10.1117/12.357118; Tantum S.L., 2002, P SPIE C DET REM TEC, P728; Tax D. M. J., 2001, THESIS TU DELFT DELF; TORRIONE P, 2008, P SPIE C DET REM TEC, V6953; Torrione PA, 2006, IEEE T AERO ELEC SYS, V42, P644, DOI 10.1109/TAES.2006.1642579; Wilson JN, 2007, IEEE T GEOSCI REMOTE, V45, P2560, DOI 10.1109/TGRS.2007.900993; Witten TR, 1998, PROC SPIE, V3392, P576, DOI 10.1117/12.324230; Won IJ, 2001, IEEE T GEOSCI REMOTE, V39, P703, DOI 10.1109/36.917876; Yager R. R., 1997, ORDERED WEIGHTED AVE; Yang CC, 2005, IEEE T NEURAL NETWOR, V16, P743, DOI 10.1109/TNN.2005.844906; Yu SH, 1999, P SOC PHOTO-OPT INS, V3710, P961, DOI 10.1117/12.357116; Zahid N, 2001, FUZZY SET SYST, V120, P239, DOI 10.1016/S0165-0114(99)00074-3; ZHANG J, 2004, P INT S NEUR NETW 1, P636; *US DEP STAT, 1998, US DEP STAT PUBL; 1998, UN MAGAZINE	51	28	28	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1063-6706		IEEE T FUZZY SYST	IEEE Trans. Fuzzy Syst.	FEB	2009	17	1					185	199		10.1109/TFUZZ.2008.2005249		15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	405LB	WOS:000263225100016	
J	Vaidya, J; Clifton, CW				Vaidya, Jaideep; Clifton, Christopher W.			Privacy-Preserving Kth Element Score over Vertically Partitioned Data	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						Privacy; security; kth element score; top-k queries		Given a large integer data set shared vertically by two parties, we consider the problem of securely computing a score separating the kth and the (k+1)th element. An efficient secure protocol is developed to compute such a score while revealing little additional information. The proposed protocol is implemented using the Fairplay system and experimental results are reported. We show a real application of this protocol as a component used in the secure processing of top-k queries over vertically partitioned data.	[Vaidya, Jaideep] Rutgers State Univ, Management Sci & Informat Syst Dept, Newark, NJ 07102 USA; [Clifton, Christopher W.] Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA	Vaidya, J (reprint author), Rutgers State Univ, Management Sci & Informat Syst Dept, 180 Univ Ave, Newark, NJ 07102 USA.	jsvaidya@business.rutgers.edu; clifton@cs.purdue.edu			US National Science Foundation [CNS-0746943, IIS-0428168]; Rutgers Business School	This material is based upon work supported by the US National Science Foundation under Grants CNS-0746943 and IIS-0428168 and by a Research Resources Grant from Rutgers Business School.	AGGARWAL G, 2004, P IACR INT C THEOR A; AGRAWAL R, 2003, P ACM SIGMOD 03 JUN; BAWA M., 2003, P 29 INT C VER LARG, P922, DOI 10.1016/B978-012722442-8/50086-0; Breunig M, 2000, P ACM SIGMOD INT C M, P93, DOI DOI 10.1145/342009.335388; Bruno N, 2002, PROC INT CONF DATA, P369, DOI 10.1109/ICDE.2002.994751; Chaudhuri S., 1999, P 25 INT C VER LARG, P397; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Donjerkovic D, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P411; ERTOZ L, 2001, P TEXT MIN 1 SIAM IN; Fagin R., 2001, P 20 ACM S PRINC DAT, P102, DOI 10.1145/375551.375567; Fagin R., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, DOI 10.1145/275487.275488; Fagin R., 1996, Proceedings of the Fifteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1996, DOI 10.1145/237661.237715; Fagin R, 1999, J COMPUT SYST SCI, V58, P83, DOI 10.1006/jcss.1998.1600; Fischlin M, 2001, LECT NOTES COMPUT SC, V2020, P457; FREEDMAN MJ, 2004, P INT C THEOR APPL C; Goethals B, 2004, LECT NOTES COMPUT SC, V3506, P104; Goldreich O., 2004, FDN CRYPTOGRAPHY, V2; Ilyas I. F., 2003, P 29 INT C VER LARG, P754, DOI 10.1016/B978-012722442-8/50072-0; Ioannidis I, 2003, P 36 HAW INT C SYST, P205; JARVIS RA, 1973, IEEE T COMPUT, VC-22, P1025, DOI 10.1109/T-C.1973.223640; JIANG W, 2007, P 7 SIAM INT C DAT M; Kantarcioglu M, 2004, IEEE T KNOWL DATA EN, V16, P1026, DOI 10.1109/TKDE.2004.45; Malkhi D., 2004, Proceedings of the 13th USENIX Security Symposium; POHLIG SC, 1978, IEEE T INFORM THEORY, V24, P106, DOI 10.1109/TIT.1978.1055817; Shaneck M., 2006, P ICDM WORKSH, P541; VAIDYA J, 2005, ADV INFORM SECURITY, V19; Vaidya J., 2005, Journal of Computer Security, V13; Yao A.C.C., 1986, P 27 IEEE S FDN COMP, P162; Zhang N., 2005, P 31 INT C VER LARG, P889; 2003, SIGKDD EXPLORATIONS, V4, P48	30	4	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	FEB	2009	21	2					253	258		10.1109/TKDE.2008.167		6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	385KT	WOS:000261813800007	
J	Perez, A; Larranaga, P; Inza, I				Perez, Aritz; Larranaga, Pedro; Inza, Inaki			Bayesian classifiers based on kernel density estimation: Flexible classifiers	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING			English	Article						Bayesian network; Kernel density estimation; Supervised classification; Flexible naive Bayes	NETWORK CLASSIFIERS; CLASSIFICATION; EQUIVALENCE; VARIANCE; MIXTURES; BIAS	When learning Bayesian network based classifiers continuous variables are usually handled by discretization, or assumed that they follow a Gaussian distribution. This work introduces the kernel based Bayesian network paradigm for supervised classification. This paradigm is a Bayesian network which estimates the true density of the continuous variables using kernels. Besides, tree-augmented naive Bayes, k-dependence Bayesian classifier and complete graph classifier are adapted to the novel kernel based Bayesian network paradigm. Moreover, the strong consistency properties of the presented classifiers are proved and an estimator of the mutual information based on kernels is presented. The classifiers presented in this work can be seen as the natural extension of the flexible naive Bayes classifier proposed by John and Langley [G.H. John, P. Langley, Estimating continuous distributions in Bayesian classifiers, in: Proceedings of the 11th Conference on Uncertainty in Artificial Intelligence, 1995, pp. 338-345], breaking with its strong independence assumption. Flexible tree-augmented naive Bayes seems to have superior behavior for supervised classification among the flexible classifiers. Besides, flexible classifiers presented have obtained competitive errors compared with the state-of-the-art classifiers. (C) 2008 Elsevier Inc. All rights reserved.	[Perez, Aritz; Larranaga, Pedro; Inza, Inaki] Univ Basque Country, Intelligent Syst Grp, Dept Comp Sci & Artificial Intelligence, Madrid, Spain	Perez, A (reprint author), Univ Basque Country, Intelligent Syst Grp, Dept Comp Sci & Artificial Intelligence, Madrid, Spain.	aritz.perez@ehu.es; pedro.larranaga@ehu.es; inza@si.ehu.es	Larranaga, Pedro/F-9293-2013		Etortek, Saiotek and Research Groups [2007-2012 (IT-242-07)]; Basque Goverment [TIN2005-03824]; Consolider Ingenio [2010-CSD2007-00018]; Spanish Ministry of Education and Science; COMBIOMED	First, thanks to the helpful comments of the anonymous reviewers which have improved the quality of the paper. This work has been possible thanks to the Ph.D. grant Beca para la Formacion de Investigadores 2003-07 of the Basque Government. This work has been also supported by the Etortek, Saiotek and Research Groups 2007-2012 (IT-242-07) programs (Basque Goverment), TIN2005-03824 and Consolider Ingenio 2010-CSD2007-00018 projects (Spanish Ministry of Education and Science) and COMBIOMED network in computational biomedicine (Carlos III Health Institute).	ALADJEM M, 2002, LECT NOTES COMPUTER, V2396, P396; Aladjem M, 2005, IEEE T SIGNAL PROCES, V53, P4376, DOI 10.1109/TSP.2005.857007; Bilmes J., 1997, ICSITR97021 U BERK; Bishop C. M., 2006, PATTERN RECOGNITION; Bishop C. M., 1995, NEURAL NETWORKS PATT; Bishop CM, 1999, LEARNING GRAPHICAL M, P371; BOTTCHER SG, 2004, THESIS AALBORG U; BOUCKAERT R, 2004, P 17 AUSTR C ART INT, P1089; Casella G., 1990, STAT INFERENCE; Castillo E., 1997, EXPERT SYSTEMS PROBA; Cheng J, 1999, P 15 C UNC ART INT U, P101; Chickering DM, 2002, J MACH LEARN RES, V2, P445, DOI 10.1162/153244302760200696; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; Cormen T., 2003, INTRO ALGORITHMS; Cover T. M., 1991, ELEMENTS INFORM THEO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DeGroot M.H., 1970, OPTIMAL STAT DECISIO; DELAIGLE A, 2002, COMPUTATIONAL STAT D, V39, P1; Demsar J, 2006, J MACH LEARN RES, V7, P1; DEVROYE L, 1983, ANN STAT, V11, P896, DOI 10.1214/aos/1176346255; Diamantidis NA, 2000, ARTIF INTELL, V116, P1, DOI 10.1016/S0004-3702(99)00094-6; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Domingos Pedro, 2000, P 17 INT C MACH LEAR, P231; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; Duda R., 1973, PATTERN CLASSIFICATI; Duda R.O., 2000, PATTERN CLASSIFICATI; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; FIGUEIREDO MAT, 1999, LECT NOTES COMPUTER, V1654, P732; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; FUKUNAGA K, 1972, STAT PATTERN RECOGNI; Geiger D., 1994, LEARNING GAUSSIAN NE; German S., 1992, NEURAL COMPUT, V4, P1; Goldberg D. E, 1989, GENETIC ALGORITHMS S; GREINER R, 2005, MACH LEARN, V59, P97; GURWICZ Y, 2004, P 17 INT C PATT REC, V3, P700, DOI 52224783,12,1; Gurwicz Y, 2005, PATTERN RECOGN LETT, V26, P1761, DOI 10.1016/j.patrec.2004.12.008; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; Iba W., 1992, P 10 NAT C ART INT, P223; James GM, 2003, MACH LEARN, V51, P115, DOI 10.1023/A:1022899518027; Jebara T., 2004, MACHINE LEARNING DIS; John G., 1995, P 11 C UNC ART INT, P338; Kohavi R., 1995, INT JOINT C ART INT, V14, P1137; Kohavi R., 1996, ICML, P275; KOHAVI R, 1997, IMPROVING SIMPLE BAY; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohavi R., 1995, THESIS STANFORD U; Kononenko I, 1991, P 6 EUR WORK SESS LE, p206~219; Larranaga P., 2002, ESTIMATION DISTRIBUT; Lauritzen S. L., 1996, GRAPHICAL MODELS, p[505, 506]; LAURITZEN SL, 1989, ANN STAT, V17; LAURITZEN SL, 1984, 848 AALB U I EL SYST; Lerner B, 2004, ARTIF INTELL MED, V30, P301, DOI 10.1016/j.artmed.2003.11.005; Lerner B, 2001, NEURAL COMPUT APPL, V10, P39, DOI 10.1007/s005210170016; McLachlan GJ, 2000, FINITE MIXTURE MODEL; Minsky M., 1961, T I RADIO ENG, V49, P8; MOON YI, 1995, PHYS REV E, V52, P2318, DOI 10.1103/PhysRevE.52.2318; MORAL S, 2002, 1 EUR WHORKSH PROB G, P156; Murphy P. M., 1995, UCI REPOSITORY MACHI; Neapolitan R, 2003, LEARNING BAYESIAN NE; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PAZZANI M, 1997, LEARNING DATA ARTIFI, V5, P239; Pearl J., 1988, PROBABILISTIC REASON, p[505, 506, 507, 524]; Perez A, 2006, LECT NOTES ARTIF INT, V4265, P347; Perez A, 2006, INT J APPROX REASON, V43, P1, DOI 10.1016/j.ijar.2006.01.002; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1986, MACH LEARN, V1, P106; Raudys S., 1991, Informatica, V2; Romero V, 2006, INT J APPROX REASON, V42, P54, DOI 10.1016/j.ijar.2005.10.004; Roos T, 2005, MACH LEARN, V59, P267; Rosenblatt Frank, 1959, PRINCIPLES NEURODYNA; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; Sahami M., 1996, P 2 INT C KNOWL DISC, P335; SANTAFE G, 2005, P 8 EUR C SYMB QUANT, P148; Scott D. W., 1992, MULTIVARIATE DENSITY; Scott DW, 2001, TECHNOMETRICS, V43, P323, DOI 10.1198/004017001316975916; Silverman B.W., 1986, DENSITY ESTIMATION S; Simonoff J. S., 1996, SMOOTHING METHODS ST; Van der Putten P, 2004, MACH LEARN, V57, P177, DOI 10.1023/B:MACH.0000035476.95130.99; Wand M. P, 1995, MONOGRAPHS STAT APPL; Witten I., 2005, DATA MINING PRACTICA; YANG Y, 2003, 2003131 MON U SCH CO; Zhou A., 2003, P 8 INT C DAT SYST A, P285	82	13	17	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0888-613X		INT J APPROX REASON	Int. J. Approx. Reasoning	FEB	2009	50	2					341	362		10.1016/j.ijar.2008.08.008		22	Computer Science, Artificial Intelligence	Computer Science	421LD	WOS:000264359500014	
J	Weinberger, KQ; Saul, LK				Weinberger, Kilian Q.; Saul, Lawrence K.			Distance Metric Learning for Large Margin Nearest Neighbor Classification	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						convex optimization; semi-definite programming; Mahalanobis distance; metric learning; multi-class classification; support vector machines	RECOGNITION	The accuracy of k-nearest neighbor (kNN) classification depends significantly on the metric used to compute distances between different examples. In this paper, we show how to learn a Mahalanobis distance metric for kNN classification from labeled examples. The Mahalanobis metric can equivalently be viewed as a global linear transformation of the input space that precedes kNN classification using Euclidean distances. In our approach, the metric is trained with the goal that the k-nearest neighbors always belong to the same class while examples from different classes are separated by a large margin. As in support vector machines (SVMs), the margin criterion leads to a convex optimization based on the hinge loss. Unlike learning in SVMs, however, our approach requires no modification or extension for problems in multiway (as opposed to binary) classification. In our framework, the Mahalanobis distance metric is obtained as the solution to a semidefinite program. On several data sets of varying size and difficulty, we find that metrics trained in this way lead to significant improvements in kNN classification. Sometimes these results can be further improved by clustering the training examples and learning an individual metric within each cluster. We show how to learn and combine these local metrics in a globally integrated manner.	[Weinberger, Kilian Q.] Yahoo Res, Santa Clara, CA USA; [Saul, Lawrence K.] Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA	Weinberger, KQ (reprint author), Yahoo Res, 2821 Mission Coll Blvd, Santa Clara, CA USA.	KILIAN@YAHOO-INC.COM; SAUL@CS.UCSD.EDU			NSF [0238323]	We especially thank John C. Blitzer for his many suggestions to improve the algorithm and his generous help with various data sets. We also thank Koby Crammer for many useful comments and suggestions. This work was supported by NSF Award 0238323.	Bar-Hillel AB, 2005, J MACH LEARN RES, V6, P937; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Beygelzimer A., 2006, P 23 INT C MACH LEAR, P97, DOI 10.1145/1143844.1143857; BILENKO M, 2004, P 21 INT C MACH LEAR, P839; Boyd S., 2004, CONVEX OPTIMIZATION; Chopra S, 2005, P IEEE C COMP VIS PA, P349; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crammer K, 2001, J MACHINE LEARNING R, V2, P265; DASGUPTA S, 1999, 99006 UC BERK INT CO; De Bie T, 2003, LECT NOTES ARTIF INT, V2842, P175; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Fisher RA, 1936, ANN EUGENIC, V7, P179; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; Globerson A., 2006, ADV NEURAL INFORM PR, V18; Goldberger J., 2005, ADV NEURAL INFORM PR, V17, P513; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; KUMARA MT, 2007, J NANOSCI NANOTECHNO, V7, P1; Kwok J. T., 2003, P 20 INT C MACH LEAR, P400; Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27; LeCun Y. A., 1995, P INT C ART NEUR NET, P53; Liu T., 2005, ADV NEURAL INFORM PR, V17, P825; McCallum A, 1996, BOW TOOLKIT STAT LAN; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Omohundro S. M., 1987, Complex Systems, V1; Scholkopf B, 2002, LEARNING KERNELS SUP; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Shalev-Shwartz S., 2004, P 21 INT C MACH LEAR, P94; SHENTAL N, 2002, P 7 EUR C COMP VIS C, V4, P776; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; SIMARD PY, 1993, ADV NEURAL INFORM PR, V6, P50; Torresani Lorenzo, 2007, ADV NEURAL INFORM PR, V19, P1385; TSANG IW, 2005, P 2005 IEEE INT JOIN, V2, P954, DOI 10.1109/IJCNN.2005.1555981; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Vandenberghe L, 1996, SIAM REV, V38, P49, DOI 10.1137/1038003; Varma M., 2007, P IEEE INT C COMP VI, P1; Weinberger K. Q., 2008, P 25 INT C MACH LEAR, P1160, DOI 10.1145/1390156.1390302; Weinberger KQ, 2006, ADV NEURAL INFORM PR, V18, P1473; Xing E.P., 2002, ADV NEURAL INFORM PR, V14, P521	40	141	151	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	FEB	2009	10						207	244				38	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	507BG	WOS:000270824200005	
J	Lozano, A; Manfredi, G; Nieddu, L				Lozano, Angelica; Manfredi, Giuseppe; Nieddu, Luciano			An algorithm for the recognition of levels of congestion in road traffic problems	MATHEMATICS AND COMPUTERS IN SIMULATION			English	Article	6th Pan-American Workshop on Applied and Computational Mathematics	JUL 23-28, 2006	Oaxaca, MEXICO	Third PanAmer Adv Studies Inst, Computat Sci & Engn, USA Natl Sci Fdn, DOE		Vehicle detection; Image recognition; Traffic information	PROCESSING TECHNIQUES; PATTERN-RECOGNITION; CLASSIFICATION	Detection and recognition of the level of congestion at an intersection is a very important problem and a valuable source of information in traffic management. Although it is just one of all the aspects that make up a traffic management system, it seems to be a crucial point for gathering information. In this paper, we present a technique based on a k-means clustering algorithm for classification, which has been already successfully used in a number of pattern recognition problems, namely: as an algorithm for face recognition problems and in a number of medical diagnosis problems and it compares very well with the state of the art techniques. (C) 2007 IMACS. Published by Elsevier B.V. All rights reserved.	[Nieddu, Luciano] Libera Univ S Pio V, Dept Econ, Rome, Italy; [Lozano, Angelica] Univ Nacl Autonoma Mexico, Inst Ingn, Lab Transporte & Sistemas Territoriales, Mexico City, DF, Mexico; [Manfredi, Giuseppe] Libera Univ S Pio V, Dept Polit Sci, Rome, Italy	Nieddu, L (reprint author), Libera Univ S Pio V, Dept Econ, Rome, Italy.	alozanoc@iingen.unam.mx; g.manfredi@luspio.it; l.nieddu@luspio.it					Bellman R., 1961, ADAPTIVE CONTROL PRO; Cifarelli C, 2007, COMPUT OPER RES, V34, P3154, DOI 10.1016/j.cor.2005.11.023; Cochran W. G, 1977, SAMPLING TECHNIQUES; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; Efron B., 1993, INTRO BOOTSTRAP; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Firschein O., 1963, IEEE Transactions on Electronic Computers, VEC-12; FIX E, 1951, 2149004 US AIR FORC; Gordon AD, 1981, CLASSIFICATION; Grimaldi G., 2002, CENTRAL EUROPEAN J O, V10, P29; Hand D. J., 1981, DISCRIMINATION CLASS; Harlow C, 2001, TRANSPORT RES C-EMER, V9, P231, DOI 10.1016/S0968-090X(00)00034-6; Hastie T, 2001, ELEMENTS STAT LEARNI; Kastrinaki V, 2003, IMAGE VISION COMPUT, V21, P359, DOI 10.1016/S0262-8856(03)00004-0; KATRE UA, 1989, PATTERN RECOGN, V22, P423, DOI 10.1016/0031-3203(89)90051-4; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; NIEDDU L, 2001, APPROXIMATION OPTIMI; Nieddu L, 2000, EUR J OPER RES, V120, P459, DOI 10.1016/S0377-2217(98)00368-3; NIEDDU L, 1999, THESIS U ROME; PATRIZI G, RICERCA OPERATIVA, V10; Sheskin DJ, 2000, HDB PARAMETRIC NONPA; Siyal MY, 1999, REAL-TIME IMAGING, V5, P271, DOI 10.1006/rtim.1998.0140; Vapnik V.N., 1998, STAT LEARNING THEORY; Vapnik V.N., 1995, NATURE STAT LEARNING; Watanabe S., 1985, PATTERN RECOGNITION; Zhang X, 1997, TRANSPORT RES C-EMER, V5, P141, DOI 10.1016/S0968-090X(97)00007-7	27	2	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0378-4754		MATH COMPUT SIMULAT	Math. Comput. Simul.	FEB	2009	79	6					1926	1934		10.1016/j.matcom.2007.06.008		9	Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	417RG	WOS:000264093700011	
J	Yang, CY; Hsu, CC; Yang, JS				Yang, Chan-Yun; Hsu, Che-Chang; Yang, Jr-Syu			Stray Example Sheltering by Loss Regularized SVM and kNN Preprocessor	NEURAL PROCESSING LETTERS			English	Article						k-nearest-neighbor preprocessor; Stray training examples; Support vector machines; Classification; Pattern recognition	RISK MINIMIZATION; CLASSIFICATION	This paper presents a new model developed by merging a non-parametric k-nearest-neighbor (kNN) preprocessor into an underlying support vector machine (SVM) to provide shelters for meaningful training examples, especially for stray examples scattered around their counterpart examples with different class labels. Motivated by the method of adding heavier penalty to the stray example to attain a stricter loss function for optimization, the model acts to shelter stray examples. The model consists of a filtering kNN emphasizer stage and a classical classification stage. First, the filtering kNN emphasizer stage was employed to collect information from the training examples and to produce arbitrary weights for stray examples. Then, an underlying SVM with parameterized real-valued class labels was employed to carry those weights, representing various emphasized levels of the examples, in the classification. The emphasized weights given as heavier penalties changed the regularization in the quadratic programming of the SVM, and brought the resultant decision function into a higher training accuracy. The novel idea of real-valued class labels for conveying the emphasized weights provides an effective way to pursue the solution of the classification inspired by the additional information. The adoption of the kNN preprocessor as a filtering stage is effective since it is independent of SVM in the classification stage. Due to its property of estimating density locally, the kNN method has the advantage of distinguishing stray examples from regular examples by merely considering their circumstances in the input space. In this paper, detailed experimental results and a simulated application are given to address the corresponding properties. The results show that the model is promising in terms of its original expectations.	[Yang, Chan-Yun] Technol & Sci Inst No Taiwan, Dept Mech Engn, Taipei 112, Taiwan; [Hsu, Che-Chang; Yang, Jr-Syu] Tamkang Univ, Dept Mech & Electromech Engn, Tamsui 25137, Taipei County, Taiwan	Yang, CY (reprint author), Technol & Sci Inst No Taiwan, Dept Mech Engn, 2 Xue Yuan Rd, Taipei 112, Taiwan.	cyyang.research@gmail.com; 692342792@s92.tku.edu.tw; 096034@mail.tku.edu.tw					BARTLETT PL, 2003, 638 DEP STAT; BREIMAN L, 1996, 460 DEP STAT; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; Duda R.O., 2000, PATTERN CLASSIFICATI; FUKUNAGA K, 1990, STAT PATTERN RECOGNI, V2; Hastie T, 2001, ELEMENTS STAT LEARNI; HSU CC, 2005, INT C COMP INT SEC X, P550; MURPHY PM, 1995, UCI BENCHMARK REPOSI; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B., 2002, LEARNING KERNELS; Shawe-Taylor J, 1998, IEEE T INFORM THEORY, V44, P1926, DOI 10.1109/18.705570; Vapnik V.N., 1998, STAT LEARNING THEORY; Vapnik V.N., 1995, NATURE STAT LEARNING; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Vlachos P., 1989, STATLIB; WEBB A, 2002, STAT PATTERN RECOGNI, V2; YANG CY, 2006, INT C COMP INT SEC G, P172; YANG CY, 2003, IEEE INT C COMP CYB; Zhang T, 2004, ANN STAT, V32, P56	21	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1370-4621		NEURAL PROCESS LETT	Neural Process. Lett.	FEB	2009	29	1					7	27		10.1007/s11063-008-9092-y		21	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	407SI	WOS:000263384200002	
J	Orozco-Alzate, M; Duin, RPW; Castellanos-Dominguez, G				Orozco-Alzate, Mauricio; Duin, Robert P. W.; Castellanos-Dominguez, German			A generalization of dissimilarity representations using feature lines and feature planes	PATTERN RECOGNITION LETTERS			English	Article						Dissimilarity; Representation; Feature lines; Feature planes; Generalization	NEAREST FEATURE LINE; FACE RECOGNITION; PATTERN-CLASSIFICATION; FEATURE CLASSIFIERS; RETRIEVAL	Even though, under representational restrictions, the nearest feature rules and the dissimilarity-based classifiers are feasible alternatives to the nearest neighbor method; individually, they may not be sufficiently powerful if a very small set of prototypes is required, e.g. when it is computationally expensive to deal with larger sets of prototypes. In this paper, we show that combining both strategies, taking advantage of their individual properties, provides an improvement, particularly for correlated data sets. The combined strategy consists in deriving an enriched (generalized) dissimilarity representation by using the nearest feature rules, namely feature lines and feature planes. On top of that enriched representation, Bayesian classifiers can be constructed in order to obtain a good generalization. (C) 2008 Elsevier B.V. All rights reserved.	[Orozco-Alzate, Mauricio] Univ Nacl Colombia Sede Manizales, Dept Informat & Computac, Manizales, Caldas, Colombia; [Duin, Robert P. W.] Delft Univ Technol, Fac Elect Engn Math & Comp Sci, Informat & Commun Theory Grp, NL-2600 GA Delft, Netherlands; [Orozco-Alzate, Mauricio; Castellanos-Dominguez, German] Univ Nacl Colombia Sede Manizales, Grp Control & Procesamiento Digital Senales, Manizales, Caldas, Colombia	Orozco-Alzate, M (reprint author), Univ Nacl Colombia Sede Manizales, Dept Informat & Computac, Kilometro 7 Via Aeropuerto,Campus Nubia Bloque Q, Manizales, Caldas, Colombia.	morozcoa@bt.unal.edu.co; r.p.w.duin@tudelft.nl; cgcastellanosd@unal.edu.co			TU Delft Research; Universidad Nacional de Colombia [UN-VRI-20201004224]; Delft University of Technology; The Netherlands	This work is supported by a TU Delft Research Grant, the Scholarship Program for Outstanding Postgraduate Students from Universidad Nacional de Colombia and the research project UN-VRI-20201004224 (Universidad Nacional de Colombia). The work was undertaken while the first author was a Research Fellow at Delft University of Technology, The Netherlands.	Chen K, 2002, PATTERN RECOGN LETT, V23, P1735, DOI 10.1016/S0167-8655(02)00147-2; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; de Veld DCG, 2003, LASER SURG MED, V32, P367, DOI 10.1002/lsm.10185; Du H, 2007, PATTERN RECOGN, V40, P1486, DOI 10.1016/j.patcog.2006.10.021; DUIN RPW, 2002, P PRIS 2002 2002 INT, P20; Ekenel HK, 2005, IMAGE VISION COMPUT, V23, P469, DOI 10.1016/j.imavis.2004.09.002; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; HIGHLEYMAN WH, 1962, P IRE, V50, P1501, DOI 10.1109/JRPROC.1962.288194; KUNCHEVA LI, 2005, REAL MED DATA SETS; Li SZ, 2000, IEEE T SPEECH AUDI P, V8, P619, DOI 10.1109/89.861383; Li SZ, 2000, IEEE T PATTERN ANAL, V22, P1335, DOI 10.1109/34.888719; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Lozano M, 2006, PATTERN RECOGN, V39, P1827, DOI 10.1016/j.patcog.2006.04.005; Orozco-Alzate M, 2006, MACH VISION APPL, V17, P279, DOI 10.1007/s00138-006-0037-z; Pekalksa E., 2001, J MACHINE LEARNING R, V2, P175; Pekalska E, 2006, PATTERN RECOGN, V39, P189, DOI 10.1016/j.patcog.2005.06.012; PEKALSKA E, 2006, ICPR 06, V3, P137; Pekalska E, 2002, PATTERN RECOGN LETT, V23, P943, DOI 10.1016/S0167-8655(02)00024-7; Pekalska E, 2005, SER MACH PERCEPT ART, V64, P1, DOI 10.1142/9789812703170; RPW Duin, 2004, MATLAB TOOLBOX PATTE; TOUSSAINT GT, 1982, PATTERN RECOGN, P569; Uspensky J.V., 1948, THEORY EQUATIONS; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004	24	5	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	FEB 1	2009	30	3					242	254		10.1016/j.patrec.2008.09.010		13	Computer Science, Artificial Intelligence	Computer Science	402XA	WOS:000263045200008	
J	Nassiri-Mofakham, F; Nematbakhsh, MA; Baraani-Dastjerdi, A; Ghasem-Aghaee, N				Nassiri-Mofakham, Faria; Nematbakhsh, Mohammad Ali; Baraani-Dastjerdi, Ahmad; Ghasem-Aghaee, Nasser			Electronic promotion to new customers using mkNN learning	INFORMATION SCIENCES			English	Article						e-Commerce; e-Marketing; e-Advertisement; mkNN learning; Heuristic promotion strategy; New customer; Customer annoyance; Seller reputation; Customer anonymity; Association link	SIMILARITY MEASURE; PRODUCT TAXONOMY; E-COMMERCE; CLASSIFICATION; MARKET; RECOMMENDATIONS; SENSITIVITY; RETENTION; IMPACT; ONLINE	In recent years, several techniques have been proposed to model electronic promotions for existing customers. However, these techniques are not applicable for new customers with no previous profile or behavior data. This study models promotions to new customers in an electronic marketplace. We introduce a multi-valued k-Nearest Neighbor (mkNN) learning capability for modeling promotions to new customers. In this modified learning algorithm, instead of a single product category, the seller sends the new customer a promotion on a variable set of In categories (where m is a variable) with the highest rank of desirability among the most similar previous customers. Previous studies consider sellers' profits in promotion and marketing models. In addition to the sellers' profits, three important factors annoyance of customers, sellers' reputations, and customers' anonymity - are considered in this study. Without considering the customer's profile, we minimize unrelated and disliked offers to reduce the customer's annoyance and elevate the seller's reputation. The promotion models are evaluated in two separate experiments on populations with different degrees of optimism: (1) with fixed number of customers; and (2) in a fixed period of time. The evaluation is based on the parameters of customer population size and behavior as well as time interval. seller payoff, seller reputation, and the number of promotions canceled by the customers. The simulation results demonstrate that the proposed mkNN-based promotion strategies are moderately efficient with respect to all parameters for providing services in a large population. In addition, purchasing preferences of past customers, which are based on periodic promotions that a seller sends to customers, can generate future rapidly expanding demands in the market. By using these approaches, an advertising company can send acceptable promotions to customers without having specific profile information. (c) 2008 Elsevier Inc. All rights reserved.	[Nassiri-Mofakham, Faria; Nematbakhsh, Mohammad Ali; Baraani-Dastjerdi, Ahmad; Ghasem-Aghaee, Nasser] Univ Isfahan UI, Dept Comp Engn, Esfahan, Iran; [Nassiri-Mofakham, Faria] Univ Isfahan UI, Dept Informat Technol Engn, Esfahan, Iran	Nassiri-Mofakham, F (reprint author), Univ Isfahan UI, Dept Comp Engn, PO Code 81746-73441,Hezar Jerib Ave, Esfahan, Iran.	fnasirimofakham@yahoo.com; nematbakhsh@eng.ui.ac.ir; ahmad-b@eng.ui.ac.ir; aghaee@eng.ui.ac.ir					Ahn HJ, 2008, INFORM SCIENCES, V178, P37, DOI 10.1016/j.ins.2007.07.024; ATKESON CC, 1997, ARTIF INTELL, P75; Berry M. J. A., 1997, DATA MINING TECHNIQU; Berry MJA, 2000, MASTERING DATA MININ; Bhattacharya CB, 1998, J ACAD MARKET SCI, V26, P31, DOI 10.1177/0092070398261004; Buckinx W, 2004, EXPERT SYST APPL, V26, P509, DOI 10.1016/j.eswa.2003.10.009; Burr Ridge I, 1997, MACHINE LEARNING; Chen LS, 2008, INFORM SCIENCES, V178, P1032, DOI 10.1016/j.ins.2007.09.027; Chen MC, 2007, EXPERT SYST APPL, V33, P1110, DOI 10.1016/j.eswa.2006.08.007; Chiu CC, 2002, EXPERT SYST APPL, V22, P163, DOI 10.1016/S0957-4174(01)00052-5; Cho YH, 2004, EXPERT SYST APPL, V26, P233, DOI 10.1016/S0957-4174(03)00138-6; Colgate MR, 2000, J ACAD MARKET SCI, V28, P375, DOI 10.1177/0092070300283006; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crone SF, 2006, EUR J OPER RES, V173, P781, DOI 10.1016/j.ejor.2005.07.023; DEITEL HM, 2001, E COMMERCE E BUSINES; FAYYAD U, 1996, A1 MAGAZINE      FAL, P38; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Ganesh J, 2000, J MARKETING, V64, P65, DOI 10.1509/jmkg.64.3.65.18028; Han J., 2006, DATA MINING CONCEPTS; Hay B, 2003, LECT NOTES ARTIF INT, V2703, P50; Hung LP, 2005, EXPERT SYST APPL, V29, P383, DOI 10.1016/j.eswa.2005.04.016; JAIN AK, 1998, PRENTICE HALL ADV RE; JARVIS RA, 1973, IEEE T COMPUT, VC-22, P1025, DOI 10.1109/T-C.1973.223640; Kaefer F, 2005, COMPUT OPER RES, V32, P2595, DOI 10.1016/j.cor.2004.06.021; Kantardzic M., 2003, DATA MINING CONCEPTS; Kaufman L., 1990, FINDING GROUPS DATA; Kazienko P, 2007, INFORM SCIENCES, V177, P2269, DOI 10.1016/j.ins.2007.01.002; Kiang MY, 2000, DECIS SUPPORT SYST, V27, P383, DOI 10.1016/S0167-9236(99)00062-7; Kim E, 2003, DECIS SUPPORT SYST, V34, P167, DOI 10.1016/S0167-9236(02)00079-9; Kogan K, 2008, EUR J OPER RES, V188, P273, DOI 10.1016/j.ejor.2007.04.012; Lariviere B, 2004, EXPERT SYST APPL, V27, P277, DOI 10.1016/j.eswa.2004.02.002; LARIVIERE B, 2004, WP04282 U GENT FAC E; Larose Daniel T., 2005, DISCOVERING KNOWLEDG; Lee JS, 2005, EXPERT SYST APPL, V29, P700, DOI 10.1016/j.eswa.2005.04.037; Lewis D. D., 1992, REPRESENTATION LEARN; Mitchell TM, 1999, COMMUN ACM, V42, P30, DOI 10.1145/319382.319388; NASSIRIMOFAKHAM F, 2006, IRANIAN J INFORM SCI, V4, P15; Nassiri-Mofakham F, 2009, INT J HUM-COMPUT ST, V67, P1, DOI 10.1016/j.ijhcs.2008.08.001; Nassiri-Mofakham Faria, 2008, Simulation & Gaming, V39, DOI 10.1177/1046878107308094; Parr Rud O, 2001, DATA MINING COOKBOOK; PERNER P, 2002, ADV DATA MINING APPL, V2394, P39; Ponniah P., 2001, DATA WAREHOUSING FUN; Raghavan NRS, 2005, SADHANA-ACAD P ENG S, V30, P275; Ramakrishnan R., 2000, DATABASE MANAGEMENT; Silberschatz A., 2002, DATABASE SYSTEM CONC; Smith KA, 2000, J OPER RES SOC, V51, P532, DOI 10.1057/palgrave.jors.2600941; Tsao YC, 2008, COMPUT OPER RES, V35, P3562, DOI 10.1016/j.cor.2007.01.024; TVERSKY A, 1986, PSYCHOL REV, V93, P3, DOI 10.1037/0033-295X.93.1.3; TZONGRU L, 2006, ELECTRON COMMER R A, V5, P105; Urban Glen L, 1984, MARKET SCI, V3, P83, DOI 10.1287/mksc.3.2.83; Van den Poel D, 2004, EXPERT SYST APPL, V27, P53, DOI [10.1016/j.eswa.2003.12.003, 10.1016/j.eswa.2003.12.2003]; VANRIJSBERGEN CJ, 1977, J DOC, V33, P106; VANTOMME D, 2004, WP04224 U GENT FAC E; Vindevogel B, 2005, EXPERT SYST APPL, V28, P583, DOI 10.1016/j.eswa.2004.12.019; VINDEVOGEL B, 2004, WP04276 U GENT FAC E; Wang FH, 2008, INFORM SCIENCES, V178, P1848, DOI 10.1016/j.ins.2007.11.018; Weng SS, 2004, EXPERT SYST APPL, V26, P493, DOI 10.1016/j.eswa.2003.10.008; Zadrozny B., 2001, P 7 ACM SIGKDD INT C, P204, DOI 10.1145/502512.502540	58	2	2	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255		INFORM SCIENCES	Inf. Sci.	JAN 16	2009	179	3					248	266		10.1016/j.ins.2008.09.019		19	Computer Science, Information Systems	Computer Science	412FE	WOS:000263708600004	
J	Watanabe, T; Kobunai, T; Sakamoto, E; Yamamoto, Y; Konishi, T; Horiuchi, A; Shimada, R; Oka, T; Nagawa, H				Watanabe, Toshiaki; Kobunai, Takashi; Sakamoto, Etsuko; Yamamoto, Yoko; Konishi, Tsuyoshi; Horiuchi, Atsushi; Shimada, Ryu; Oka, Toshinori; Nagawa, Hirokazu			Gene Expression Signature for Recurrence in Stage III Colorectal Cancers	CANCER			English	Article						colorectal cancer; recurrence; lymph node metastasis; stage III; microarray; prediction; copy number; CABIN1; Duke stage C; tailored therapy	MICROARRAY ANALYSIS; DNA MICROARRAY; HYBRIDIZATION; POLYMORPHISM; PREDICTION; MUTATIONS; PROFILES; SURVIVAL	BACKGROUND: Colorectal cancer patients with lymph node metastases (stage III) show poorer prognosis than those without. Predicting development of recurrence may guide the need for intensive follow-up and/or adjuvant chemotherapy in such patients. The authors' objective was to identify a set of discriminating genes that could predict recurrence in stage III colorectal cancer. METHODS: Thirty-six stage III colorectal cancer patients were studied. Tumor samples were obtained from surgically resected specimens. Thirteen patients developed recurrence, whereas 23 patients did not. Gene expression profiles were determined using human HG-U133 Plus 2.0 Gene Chip (Affymetrix, Santa Clara, Calif). RESULTS: The authors identified 45 discriminating genes between patients with and without recurrence. By using this gene set, they established a new model to predict recurrence with an accuracy of 90.9%. The discriminating genes included calcineurin-binding protein 1 (CABIN1), whose expression differed remarkably between patients with and without recurrence (P = .0073). The authors further examined the DNA copy number of CABIN1 and were able to show a significant relation with recurrence (P < .012). Patients having CABIN1 gene loss demonstrated a higher risk of recurrence (odds ratio, 18.8). DNA copy number of CABIN1 alone could predict recurrence with an accuracy of 80.0%. CONCLUSIONS: The results of the current study demonstrated that gene expression profiling is useful in predicting recurrence in stage III colorectal cancer. The authors identified CABIN1 among discriminating genes that may play a key role in the development of recurrence. These results may help to establish an individualized therapy for stage III colorectal cancer. Cancer 2009;115:28392. (C) 2009 American Cancer Society.	[Watanabe, Toshiaki] Teikyo Univ, Sch Med, Dept Surg, Itabashi Ku, Tokyo 1738605, Japan; [Sakamoto, Etsuko; Oka, Toshinori] Taiho Pharmaceut Co Ltd, Tokushima Res Ctr, Personalized Med Res Lab, Tokushima, Japan; [Konishi, Tsuyoshi; Nagawa, Hirokazu] Univ Tokyo, Dept Surg Oncol, Tokyo, Japan	Watanabe, T (reprint author), Teikyo Univ, Sch Med, Dept Surg, Itabashi Ku, 2-11-1 Kaga, Tokyo 1738605, Japan.	toshwatanabe@yahoo.co.jp			Ministry of Education, Culture, sports, Science, and Technology of Japan; Ministry of Health, Labor and Welfare of Japan	This study was supported by a Grant-in-Aid for Scientific Research from the Ministry of Education, Culture, sports, Science, and Technology of Japan and a grant from the Ministry of Health, Labor and Welfare of Japan.	Arango D, 2005, GASTROENTEROLOGY, V129, P874, DOI 10.1053/j.gastro.2005.06.066; BELL SM, 1993, GASTROENTEROLOGY, V104, P57; BENHATTAR J, 1993, GASTROENTEROLOGY, V104, P1044; Buckley PG, 2005, HUM MUTAT, V26, P540, DOI 10.1002/humu.20255; Chin KV, 2002, PHARM RES-DORDR, V19, P1773, DOI 10.1023/A:1021425004264; Clarke PA, 2001, BIOCHEM PHARMACOL, V62, P1311, DOI 10.1016/S0006-2952(01)00785-7; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GOH HS, 1995, CANCER RES, V55, P5217; Landi S, 2000, MUTAT RES-REV MUTAT, V463, P247, DOI 10.1016/S1383-5742(00)00050-8; Pauletti G, 1996, ONCOGENE, V13, P63; PEMBLE S, 1994, BIOCHEM J, V300, P271; Pinkel D, 2005, NAT GENET, V37, pS11, DOI 10.1038/ng1569; Wang TL, 2002, P NATL ACAD SCI USA, V99, P16156, DOI 10.1073/pnas.202610899; Watanabe T, 2007, CLIN CANCER RES, V13, P415, DOI 10.1158/1078-0432.CCR-06-0753; Watanabe T, 2001, NEW ENGL J MED, V344, P1196, DOI 10.1056/NEJM200104193441603; Watanabe T, 2006, CANCER RES, V66, P3370, DOI 10.1158/0008-5472.CAN-05-3834; Watanabe T, 2006, CANCER RES, V66, P9804, DOI 10.1158/0008-5472.CAN-06-1163; Youn HD, 2000, IMMUNITY, V13, P85, DOI 10.1016/S1074-7613(00)00010-8; Zhang H, 1999, INT J CANCER, V84, P135, DOI 10.1002/(SICI)1097-0215(19990420)84:2<135::AID-IJC7>3.0.CO;2-C; Zhao XJ, 2004, CANCER RES, V64, P3060, DOI 10.1158/0008-5472.CAN-03-3308	20	12	13	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	0008-543X		CANCER	Cancer	JAN 15	2009	115	2					283	292		10.1002/cncr.24023		10	Oncology	Oncology	401LJ	WOS:000262941900008	
J	Dixon, SJ; Brereton, RG				Dixon, Sarah J.; Brereton, Richard G.			Comparison of performance of five common classifiers represented as boundary methods: Euclidean Distance to Centroids, Linear Discriminant Analysis, Quadratic Discriminant Analysis, Learning Vector Quantization and Support Vector Machines, as dependent on data structure	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS			English	Article						Classification; Boundary methods; Euclidean distance; Mahalanobis distance; Linear Discriminant Analysis; Quadratic Discriminant Analysis; Learning Vector Quantization; Support Vector Machines	CHROMATOGRAPHY-MASS-SPECTROMETRY; PATTERN-RECOGNITION; ELECTRONIC NOSE; CLASSIFICATION; PARAMETERS; ALGORITHMS; SELECTION	Five methods for discrimination are described, namely Euclidean Distance to centroids (EDC), Linear Discriminant Analysis (LDA) (based on the Mahalanobis distance and pooled variance covariance matrix), Quadratic Discriminant Analysis (QDA) (based on the Mahalanobis distance and individual class variance covariance matrix - non-Bayesian form), Learning Vector Quantization (LVQ) and Support Vector Machines (SVMs) (using soft boundaries and Radial Basis Functions), and illustrated graphically as boundary methods. The performance of each method was determined using four synthetic datasets each consisting of 200 samples half belonging to one of two classes, and a further two synthetic datasets containing 400 samples, again equally split between the two classes. In datasets 1 to 3. five variables were distributed multinormally, in dataset 1 the classes are distributed roughly circularly but with a significant degree of overlap, in dataset 2. the distribution is in elongated hyperellipsoids with small overlap, and in dataset 3 there is a region of complete overlap between classes. In dataset 4 two variables are distributed in a crescent shape. In datasets 5 and 6, 100 variables were generated from multinormal populations, some of which were potential discriminators, however a large proportion of the variables were designed to be uninformative. The methods were optimised using a training set and their performance evaluated using a test set: this was repeated 100 times for different test and training set splits. The average % correctly classified was computed for each class and model, as well as the model stability for each sample (the proportion of times the sample is classified into the same group over all 100 iterations). The conclusions are that the performance of the classifiers depends very much on the distribution of data. Approaches such as LVQ and SVMs that try to determine complex boundaries perform best when the data is not normally distributed such as in dataset 4, but can be prone to overfitting otherwise. QDA tends to perform best on multinormal data although it can be influenced by non-discriminative variables which show a difference in variance. It is recommended to look at the data structure prior to model building to determine the optimal type of model. (c) 2008 Elsevier B.V. All rights reserved.	[Dixon, Sarah J.; Brereton, Richard G.] Univ Bristol, Sch Chem, Ctr Chemometr, Bristol BS8 1TS, Avon, England	Brereton, RG (reprint author), Univ Bristol, Sch Chem, Ctr Chemometr, Bristol BS8 1TS, Avon, England.	r.g.brereton@bristol.ac.uk					Abe S., 2005, SUPPORT VECTOR MACHI; Amari S, 1999, NEURAL NETWORKS, V12, P783, DOI 10.1016/S0893-6080(99)00032-5; Brereton RG, 2006, TRAC-TREND ANAL CHEM, V25, P1103, DOI 10.1016/j.trac.2006.10.005; BRERETON RG, 2003, CHEMOMETRICS DATA AN; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CAGNONI S, 1994, IEEE INT C NEUR NETW, P762; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; De Maesschalck R, 2000, CHEMOMETR INTELL LAB, V50, P1, DOI 10.1016/S0169-7439(99)00047-7; Dixon SJ, 2007, CHEMOMETR INTELL LAB, V87, P161, DOI 10.1016/j.chemolab.2006.12.004; DUAN KB, 2005, MULTIPLE CLASSIFIER; Duda R. O., 2001, PATTERN CLASSIFICATI; FRANK IE, 1989, J CHEMOMETR, V3, P453; Fraser LA, 1997, PHYTOCHEM ANALYSIS, V8, P301, DOI 10.1002/(SICI)1099-1565(199711/12)8:6<301::AID-PCA373>3.0.CO;2-2; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Friedrichs F, 2005, NEUROCOMPUTING, V64, P107, DOI 10.1016/j.neucom.2004.11.022; FROHLICH H, 2005, IEEE INT JOINT C NEU, V3, P1431; Gardner JW, 2000, SENSOR ACTUAT B-CHEM, V69, P336, DOI 10.1016/S0925-4005(00)00482-2; GUNN SR, 1998, ONLINE REFERENCE MAN; Guo G, 2000, P INT C AUT FAC GEST, P196; HSU CW, 2003, ONLINE REFERENCE MAN; Keerthi SS, 2002, IEEE T NEURAL NETWOR, V13, P1225, DOI 10.1109/TNN.2002.1031955; Khuwaja GA, 2003, CYBERNET SYST, V34, P725, DOI 10.1080/01969720390241511; Kohonen T., 1992, P INT JOINT C NEUR N, V1, P725, DOI 10.1109/IJCNN.1992.287101; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Kohonen T., 1997, SELF ORG MAPS; Lloyd GR, 2007, J CHEM INF MODEL, V47, P1553, DOI 10.1021/ci700019q; Mahalanobis P., 1936, P NAT I SCI INDIA, V2, P49; Roggo Y, 2003, ANAL CHIM ACTA, V477, P187, DOI 10.1016/S0003-2670(02)01422-8; SCHMIDBAUER O, 1992, IEEE INT C AC SPEECH, V1, P441; Shawe-Taylor J, 2002, IEEE T INFORM THEORY, V48, P2721, DOI 10.1109/TIT.2002.802647; SMITS G F, 2002, P 2002 INT JOINT C N, V3, P2785; STEFANO CD, 2004, P 17 INT C PATT REC, V604, P601; Tong S, 2002, J MACH LEARN RES, V2, P45; Vapnik V.N., 1995, NATURE STAT LEARNING; WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9; Xu Y, 2006, CRIT REV ANAL CHEM, V36, P177, DOI 10.1080/10408340600969486; Zomer S, 2004, J CHEMOMETR, V18, P294, DOI 10.1002/cem.872; Zomer S, 2004, ANALYST, V129, P175, DOI 10.1039/b312982a; Zuppa M, 2004, SENSOR ACTUAT B-CHEM, V98, P305, DOI 10.1016/j.snb.2003.10.029	41	28	28	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-7439		CHEMOMETR INTELL LAB	Chemometrics Intell. Lab. Syst.	JAN 15	2009	95	1					1	17		10.1016/j.chemolab.2008.07.010		17	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	396OA	WOS:000262599800001	
J	Niu, B; Lu, L; Liu, L; Gu, TH; Feng, KY; Lu, WC; Cai, YD				Niu, Bing; Lu, Lin; Liu, Liang; Gu, Tian Hong; Feng, Kai-Yan; Lu, Wen-Cong; Cai, Yu-Dong			HIV-1 Protease Cleavage Site Prediction Based on Amino Acid Property	JOURNAL OF COMPUTATIONAL CHEMISTRY			English	Article						mRMR (maximum relevance, minimum redundancy); HIV protease; cleavage sites; KNN (K-nearest neighbors); AAindex	HUMAN-IMMUNODEFICIENCY-VIRUS; HYBRIDIZATION SPACE; INDEX DATABASE; PROTEINS; NETWORK; TYPE-1; SPECIFICITY; ALGORITHM; SELECTION; AAINDEX	Knowledge of the polyprotein cleavage sites by HIV protease will refine our understanding of its specificity, and the information thus acquired is useful for designing specific and efficient HIV protease inhibitors. Recently, several works have approached the HIV-1 protease specificity problem by applying a number of classifier creation and combination methods. The pace in searching for the proper inhibitors of HIV protease will be greatly expedited if one can find an accurate, robust, and rapid method for predicting the cleavage sites in proteins by HIV protease. In this article, we selected HIV-1 protease as the Subject of the study. 299 oligopeptides were chosen for the training set, while the other 63 oligopeptides were taken as a test set. The peptides are represented by features constructed by AAIndex (Kawashima et al., Nucleic Acids Res 1999, 27, 368; Kawashima and Kanehisa, Nucleic Acids Res 2000, 28, 374). The mRMR method (Maximum Relevance, Minimum Redundancy; Ding and Peng, Proc Second IEEE Comput Syst Bioinformatics Conf 2003, 523; Peng et al., IEEE Trans Pattern Anal Mach Intell 2005, 27, 1226) combining with incremental feature selection (IFS) and feature forward search (FFS) are applied to find the two important cleavage sites and to select 364 important biochemistry features by jackknife test. Using KNN (K-nearest neighbors) to combine the selected features, the prediction model obtains high accuracy rate of 91.3% for Jackknife cross-validation test and 87.3% for independent-set test. It is expected that our feature selection scheme can be referred to as a useful assistant technique for finding effective inhibitors of HIV protease, especially for the scientists in this field. (C) 2008 Wiley Periodicals, Inc. J Comput Chem 30: 33-39, 2009	[Lu, Wen-Cong; Cai, Yu-Dong] Shanghai Univ, Coll Sci, Dept Chem, Shanghai 200444, Peoples R China; [Niu, Bing; Liu, Liang; Gu, Tian Hong] Shanghai Univ, Sch Mat Sci & Engn, Shanghai 200072, Peoples R China; [Lu, Lin] Shanghai Jiao Tong Univ, Dept Biomed Engn, Shanghai 200040, Peoples R China; [Feng, Kai-Yan] Univ Manchester, Div Imaging Sci & Biomed Engn, Manchester M13 9PT, Lancs, England; [Cai, Yu-Dong] Chinese Acad Sci, MPG Partner Computat Biol, Dept Combinator & Geometry, Shanghai Inst Biol Sci, Shanghai 200031, Peoples R China	Lu, WC (reprint author), Shanghai Univ, Coll Sci, Dept Chem, 99 Shand Da Rd, Shanghai 200444, Peoples R China.	wclu@shu.edu.cn; cyd@picb.ac.cn			National Natural Science Foundation of China [20503015]; Systems Biology Research Foundation of Shanghai university	Contract/grant sponsor: Systems Biology Research Foundation of Shanghai university	BECK ZQ, 2000, VIROLOGY, V75, P9502; Cai YD, 2004, BIOINFORMATICS, V20, P1292, DOI 10.1093/bioinformatics/bth085; Cai YD, 2002, J COMPUT CHEM, V23, P267, DOI 10.1002/jcc.10017; Cai YD, 1998, ADV ENG SOFTW, V29, P119, DOI 10.1016/S0965-9978(98)00046-5; Cai YD, 2004, BIOINFORMATICS, V20, P1151, DOI 10.1093/bioinformatics/bth054; Chou KC, 2006, J PROTEOME RES, V5, P316, DOI 10.1021/pr050331g; Chou KC, 1996, ANAL BIOCHEM, V233, P1, DOI 10.1006/abio.1996.0001; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ding C, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P523; Ding YS, 2007, PROTEIN PEPTIDE LETT, V14, P811; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; JASKOLSKI M, 1991, BIOCHEMISTRY-US, V30, P1600, DOI 10.1021/bi00220a023; Kawashima S, 2000, NUCLEIC ACIDS RES, V28, P374, DOI 10.1093/nar/28.1.374; Kawashima S, 1999, NUCLEIC ACIDS RES, V27, P368, DOI 10.1093/nar/27.1.368; Kim JH, 2004, BIOINFORMATICS, V20, P3179, DOI 10.1093/bioinformatics/bth382; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; NAKAI K, 1988, PROTEIN ENG, V2, P93, DOI 10.1093/protein/2.2.93; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226; POORMAN RA, 1991, J BIOL CHEM, V266, P14554; Qian ZL, 2006, BIOCHEM BIOPH RES CO, V348, P1034, DOI 10.1016/j.bbrc.2006.07.149; Ridky TW, 1996, J BIOL CHEM, V271, P4709; Rognvaldsson T, 2004, BIOINFORMATICS, V20, P1702, DOI 10.1093/bioinformatics/bth144; Song H, 2007, COMPUT BIOL MED, V37, P1759, DOI 10.1016/j.compbiomed.2007.05.002; Thompson TB, 1995, J THEOR BIOL, V177, P369, DOI 10.1006/jtbi.1995.0254; WLODAWER A, 2000, BIOCHIM BIOPHYS ACTA, V7, P16	25	10	10	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	0192-8651		J COMPUT CHEM	J. Comput. Chem.	JAN 15	2009	30	1					33	39		10.1002/jcc.21024		7	Chemistry, Multidisciplinary	Chemistry	386UB	WOS:000261907000003	
S	Matsushita, Y; Wada, T		Wada, T; Huang, F; Lin, S		Matsushita, Yusuke; Wada, Toshikazu			Principal Component Hashing: An Accelerated Approximate Nearest Neighbor Search	ADVANCES IN IMAGE AND VIDEO TECHNOLOGY, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	3rd Pacific-Rim Symposium on Image and Video Technology (PSIVT 2009)	JAN 13-16, 2009	Tokyo, JAPAN	Natl Inst Informat, Microsoft Res, Forum Image Informat Japan, ACM SIG Multimedia, IEEE Japan Council, IEEE Comp Soc Japan Chapter, IPSJ SIG Comp Vis & Image Media, IEICE TG Pattern Recognit & Media Understanding, Int Informat Sci Fdn, Tateisi Sci & Technol Fdn, Telecommun Advancement Fdn		Approximate Nearest Neighbor Search; High dimensional space; p-stable Locality Sensitive Hashing	ALGORITHM	Nearest Neighbor (NN) search is a basic algorithm for data mining and machine learning applications. However, its acceleration in high dimensional space is a difficult problem. For solving this problem, approximate NN search algorithms have been investigated. Especially, LSH is getting highlighted recently, because it has a clear relationship between relative error ratio and the computational complexity. However, the p-stable LSH computes hash values independent of the data distributions, and hence, sometimes the search fails or consumes considerably long time. For solving this problem, we propose Principal Component Hashing (PCH), which exploits the distribution of the stored data. Through experiments, we confirmed that PCH is faster than ANN and LSH at the same accuracy.	[Matsushita, Yusuke; Wada, Toshikazu] Wakayama Univ, Grad Sch Syst Engn, Wakayama 6408510, Japan	Matsushita, Y (reprint author), Wakayama Univ, Grad Sch Syst Engn, 930 Sakaedani, Wakayama 6408510, Japan.	ymatsushita@vrl.sys.wakayama-u.ac.jp; twada@vrl.sys.wakayama-u.ac.jp; twada@vrl.sys.wakayama-u.ac.jp					Andoni A., 2006, P 47 ANN IEEE S FDN, P459; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; BRIN S., 1995, P 21 INT C VER LARG, P574; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Datar M, 2004, P 20 ANN S COMP GEOM; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; MICO ML, 1994, PATTERN RECOGN LETT, V15, P9, DOI 10.1016/0167-8655(94)90095-7; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, DOI 10.1016/0167-8655(86)90013-9; YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311; Zhang Z., 1992, 1658 INRIA; ANN LIB APPROXIMATE	12	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-92956-7	LECT NOTES COMPUT SC			2009	5414						374	385				12	Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BIV75	WOS:000263213300033	
S	Funes, A; Ferri, C; Hernandez-Orallo, J; Ramirez-Quintana, MJ		Theeramunkong, T; Kijsirikul, B; Cercone, N; Ho, TB		Funes, A.; Ferri, C.; Hernandez-Orallo, J.; Ramirez-Quintana, M. J.			An Instantiation of Hierarchical Distance-Based Conceptual Clustering for Propositional Learning	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	13th Pacific-Asia Conference on Knowledge Discovery and Data Mining	APR 27-30, 2009	Bangkok, THAILAND	Sirindhorn Int Inst Technol, Thammasat Univ, Chulalongkorn Univ, Asian Inst Technol, Natl Elect & Comp Technol Ctr, Thailand Convent & Exhibit Bureau, AF Off Sci Res, Asian Off Aerosp Res & Dev		conceptual clustering; hierarchical clustering; generalisation; distances; propositional learning		In this work we analyse the relationship between distance and generalisation operators for real numbers, nominal data and tuples in the context of hierarchical distance-based conceptual clustering (HDCC). HDCC is a general approach to conceptual clustering that extends the traditional algorithm for hierarchical clustering by producing conceptual generalisations of the discovered clusters. This snakes it possible to combine the flexibility of changing distances for several clustering problems and the advantage of having concepts which are crucial l or tasks as summarisation and descriptive data mining in general. In this work we propose it set of generalisation operators and distances for the data types mentioned before and we analyse the properties by them satisfied on the basis of three different levels of agreement between the clustering hierarchy obtained from the linkage distance and the hierarchy obtained by using generalisation operators.	[Funes, A.; Ferri, C.; Hernandez-Orallo, J.; Ramirez-Quintana, M. J.] Univ Politecn Valencia, DSIC, Valencia 46022, Spain	Funes, A (reprint author), Univ Politecn Valencia, DSIC, Camino Vera S-N, Valencia 46022, Spain.	afunes@dsic.upv.es; cferri@dsic.upv.es; jorallo@dsic.upv.es; mramirez@dsic.upv.es					Berkhin P, 2006, GROUPING MULTIDIMENSIONAL DATA: RECENT ADVANCES IN CLUSTERING, P25, DOI 10.1007/3-540-28349-8_2; Black C.L, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; ESTRUCH V, 2008, THESIS DSIC UPV; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1023/A:1022852608280; Fisher RA, 1936, ANN EUGENIC, V7, P179; FUNES A, 2008, LNCS, V5212, P349; FUNES A, 2008, THESIS DSIC UPV; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; MacQueen JB, 1967, P 5 BERK S MATH STAT, P281; Michalski R. S., 1983, MACHINE LEARNING ART, P331; Michalski R. S., 1980, International Journal of Policy Analysis and Information Systems, V4; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Talavera L, 2001, IEEE T PATTERN ANAL, V23, P196, DOI 10.1109/34.908969	14	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-01306-5	LECT NOTES ARTIF INT			2009	5476						637	646				10	Computer Science, Artificial Intelligence	Computer Science	BKN07	WOS:000268632000060	
S	Vo, N; Moran, B; Challa, S		Yu, W; He, HB; Zhang, N		Vo, Nhat; Moran, Bill; Challa, Subhash			Nonnegative-Least-Square Classifier for Face Recognition	ADVANCES IN NEURAL NETWORKS - ISNN 2009, PT 3, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	6th International Symposium on Neural Networks	MAY 26-29, 2009	Wuhan, PEOPLES R CHINA	Huazhong Univ Sci & Technol, Chinese Univ Hong Kong, Natl Nat Sci Fdn, IEEE Wuhan Sect, IEEE Computat Intel Soc, Int Neural Network Soc		Face Recognition; Eigenfaces; Fisherfaces; Nonnegative-Least-Square		In this paper, we propose a novel classification method, based on Nonnegative-Least-Square, (NNLS) algorithm, for face, recognition. Different from traditional classifiers, in our classifier, we consider each new sample (face) as a nonnegative linear combination of training samples (faces). By forcing the nonnegative constraint on linear coefficients, we obtain the nonnegative sparse representation that automatically discriminates between those classes present in the training set, Experimental results show the promising aspects of new classifier when comparing with the most popular classifiers such as Nearest Neighborhood (NN), Nearest Centroid (NC), and Nearest, Subspace (NS) in terms of recognition accuracy, efficiency, and numerical stability. Eigenfaces Fisherfaces, and Laplacianfaces are performed on Yale and ORL databases as feature extraction in these experiments	[Vo, Nhat; Moran, Bill; Challa, Subhash] Univ Melbourne, Melbourne, Vic 3010, Australia	Vo, N (reprint author), Univ Melbourne, Melbourne, Vic 3010, Australia.	n.vo@pgrad.unimelb.edu.au; b.moran@ee.unimelb.edu.au; subhash.challa@nicta.com.au					Bellhumeur P.N., 1997, IEEE T PATTERN ANAL, V19, P711; Cevikalp H, 2005, IEEE T PATTERN ANAL, V27, P4, DOI 10.1109/TPAMI.2005.9; Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fukunaga K., 1990, INTRO STAT PATTERN R; He XF, 2005, IEEE T PATTERN ANAL, V27, P328; Huang R., 2002, P INT C PATT REC QUE, V3, P29; LAWSON CL, 1974, PRENTICE HALL SERIES; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X; ZHAO W, 1998, FG, P336	11	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-01512-0	LECT NOTES COMPUT SC			2009	5553						449	456				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BKG61	WOS:000268029200049	
S	Gu, SC; Tan, Y; He, XG		Yu, W; He, HB; Zhang, N		Gu, Suicheng; Tan, Ying; He, Xhigui			Orthogonal Quadratic Discriminant Functions for Face Recognition	ADVANCES IN NEURAL NETWORKS - ISNN 2009, PT 3, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	6th International Symposium on Neural Networks	MAY 26-29, 2009	Wuhan, PEOPLES R CHINA	Huazhong Univ Sci & Technol, Chinese Univ Hong Kong, Natl Nat Sci Fdn, IEEE Wuhan Sect, IEEE Computat Intel Soc, Int Neural Network Soc		Orthogonal quadratic discriminant functions (OQDF); modified quadratic discriminant function (MQDF); small sample size (SSS); face recognition (FR); Laplacian Smoothing Transform(LST); Fisher's linear discriminant(FLD)	CLASSIFICATION	Small sample size (SSS) problem is usually a limit, to the robustness of learning methods hi face recognition. Especially in the quadratic discriminant functions (QDF), too many parameters need to be estimated and covariance matrix Of a Class is usually singular. In order to overcome the SSS problems, we proposed a, novel approach called orthogonal quadratic discriminate functions (C)QDF). The OQDF assumes probability distribution Functions of each two classes of face images have a uniform shape. Then, three OQDF models are developed. The Laplacian smoothing transform (LST) and Fisher's linear discriminant (FLD) are employed to preprocess the face images for the OQDF classifier. Finally, we evaluate, our proposed algorithms on two face databases, ORL and Yale.	[Gu, Suicheng; Tan, Ying; He, Xhigui] Peking Univ, Dept Machine Intelligence, Sch Elect Engn & Comp Sci, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China	Gu, SC (reprint author), Peking Univ, Dept Machine Intelligence, Sch Elect Engn & Comp Sci, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China.	ytan@pku.edu.cn					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 2001, PATTERN CLASSIFICATI; ER MJ, 2005, IEEE T NEURAL NETWOR, V16; Fan RE, 2005, J MACH LEARN RES, V6, P1889; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; GU S, 2008, LAPLACIAN SMOO UNPUB; Heisele B., 2001, ICCV; JUANG BH, 1992, IEEE T SIGNAL PROCES, V40, P3043, DOI 10.1109/78.175747; KIMURA F, 1987, IEEE T PATTERN ANAL, V9, P149; LIU CL, 2004, IEEE T NEURAL NETWOR; Long LA, 2008, FRONTIERS, V29, P1; LU J, 2003, PATTEN RECOGNITION L, P3079; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; WANG J, 2008, PATTERN RECOGN, P1528; Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X	16	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-01512-0	LECT NOTES COMPUT SC			2009	5553						466	475				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BKG61	WOS:000268029200051	
S	Khoo, S; Gedeon, T		Koppen, M; Kasbov, N; Coghill, G		Khoo, Suisin; Gedeon, Tom			Generalisation Performance vs. Architecture Variations in Constructive Cascade Networks	ADVANCES IN NEURO-INFORMATION PROCESSING, PT II	Lecture Notes in Computer Science		English	Proceedings Paper	15th International Conference on Neuro-Information Processing	NOV 25-28, 2008	Auckland, NEW ZEALAND	Asia Pacific Neural Network Assembly, Int Neural Network Soc, IEEE Computat Intell Soc, Japanese Neural Network Soc, European Neural Network Soc, Knowledge Engn & Discovery Res Inst, Auckland Univ Technol, Toyota USA, Auckland Sky City, Auckand Univ Technol, Sch Comp & Math Sci			FACE RECOGNITION	Constructive cascade algorithms are powerful methods for training feedforward neural networks with automation of the task of specifying the size and topology of network to use. A series of empirical studies were performed to examine the effect of imposing constraints on constructive cascade neural network architectures. Building a priori knowledge of the task into the network gives better generalisation performance. We introduce our Local Feature Constructive Cascade (LoCC) and Symmetry Local Feature Constructive Cascade (SymLoCC) algorithms, and show them to have good generalisation and network construction properties on face recognition tasks.	[Khoo, Suisin; Gedeon, Tom] Australian Natl Univ, Coll Engn & Comp Sci, Sch Comp Sci, Canberra, ACT 0200, Australia	Khoo, S (reprint author), Australian Natl Univ, Coll Engn & Comp Sci, Sch Comp Sci, GPO Box 4, Canberra, ACT 0200, Australia.	suisin.khoo@cs.anu.edu.au; tom@cs.anu.edu.au					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fahlman SE, 1990, CASCADE CORRELATION; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Grudin MA, 2000, PATTERN RECOGN, V33, P1161, DOI 10.1016/S0031-3203(99)00104-1; KHOO S, 2008, THESIS AUSTR NATL U; Kwok TY, 1997, IEEE T NEURAL NETWOR, V8, P630; LECUN Y, 1989, GEN NETWORK DESIGN S; Nguyen D., 1990, IJCNN International Joint Conference on Neural Networks (Cat. No.90CH2879-5), DOI 10.1109/IJCNN.1990.137819; Riedmiller M, 1993, IEEE INT C NEUR NETW, P586, DOI 10.1109/ICNN.1993.298623; TREADGOLD NK, 1998, P 1998 IEEE INT C SY, P4465; Treadgold NK, 1998, IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, P343	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-03039-0	LECT NOTES COMPUT SC			2009	5507						236	243				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BLN31	WOS:000270578200029	
B	Wu, CH; Yeh, JF; Chuang, ZJ		Tao, J; Tan, T		Wu, Chung-Hsien; Yeh, Jui-Feng; Chuang, Ze-Jing			Emotion Perception and Recognition from Speech	AFFECTIVE INFORMATION PROCESSING			English	Proceedings Paper	1st International Conference on Affective Computing and Intelligent Interaction	OCT 22-24, 2005	Beijing, PEOPLES R CHINA	Nokia Ltd, Siemens Ltd, Int Speech Commun Assoc, Natl Nat Sci Fdn China, Chinese Assoc Automat, China Soc Image & Graph, China Comp Federat, Natl High-Tech Res & Dev Program			HUMAN-COMPUTER INTERACTION; DIRECTED SPEECH; CLASSIFICATION; FEATURES	With the increasing role of speech interfaces in human-computer interaction applications, automatically recognizing emotions from human speech becomes more and more important. This chapter begins by introducing the correlations between basic speech features such as pitch, intensity, formants, MFCC, and so on, and the emotions. Several recognition methods are then described to illustrate the performance of the previously proposed models, including support vector machine (SVM), K-nearest neighbors (KNN), neural networks, and the like. To give a more practical description of all emotion recognition procedure, a new approach to emotion recognition is provided as a case study. In this case study, the Intonation Groups (IGs) of the input speech signals are first defined and extracted for C feature extraction. With the assumption of linear mapping between feature spaces in different emotional states, a feature compensation approach is proposed to characterize the feature space with better discriminability among emotional states. The compensation vector with respect to each emotional state is estimated using the Minimum Classification Err or (MCE) algorithm. The IG-based feature vectors compensated by the compensation vectors are used to train the Gaussian Mixture Models (GMMs) for each emotional state. The emotional state with the GMM having the maximal likelihood ratio is determined as the emotion state output.	[Wu, Chung-Hsien; Chuang, Ze-Jing] Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 70101, Taiwan	Wu, CH (reprint author), Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 70101, Taiwan.	chwu@csie.ncku.edu.tw					BHATTI MW, 2004, IEEE INT S CIRC SYST, P181; BOROD JC, 2000, NEUROPSYCHOLOGY EMOT, P3; Breazeal C, 2002, AUTON ROBOT, V12, P83, DOI 10.1023/A:1013215010749; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chuang Z.J., 2004, INT J COMPUTATIONAL, V9, P1; CICHOSZ J, 2005, INTERSPEECH 2005 LIS, P477; CICHOSZ J, 2007, EMOTION RECOGNITION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Damasio A. R., 1994, DESCARTES ERROR EMOT; Deng L, 2003, IEEE T SPEECH AUDI P, V11, P568, DOI 10.1109/TSA.2003.818076; Devillers L, 2005, NEURAL NETWORKS, V18, P407, DOI 10.1016/j.neunet.2005.03.007; DMELLO S, 2007, IEEE INTELL SYST APP, P53; Dudeyer P. Y., 2003, INT J HUMAN COMPUTER, V59, P157, DOI DOI 10.1016/S1071-581(02)00141-6; Engberg I., 1996, DOCUMENTATION DANISH; FERNANDEZ R, 2005, INTERSPEECH, P473; Fragopanagos N, 2005, NEURAL NETWORKS, V18, P389, DOI 10.1016/j.neunet.2005.03.006; HUBER R, 1998, P WORKSH TEXT SPEECH, P223; Inanoglu Z., 2005, IEEE INTELLIGENT USE, P251; Katz GS, 1996, CHILD DEV, V67, P205, DOI 10.1111/j.1467-8624.1996.tb01729.x; Kwon OW, 2003, P EUROSPEECH, P125; Lee C.-H., 2007, P INT, P1825; Lee CM, 2005, IEEE T SPEECH AUDI P, V13, P293, DOI 10.1109/TSA.2004.838534; LEVITY M, 2001, PROSODY SPEECH RECOG; Liscombe Jackson, 2005, P INT LISB PORT, P1845; Litman D.J., 2004, P HUM LANG TECHN C 4, P233; Morrison D, 2007, SPEECH COMMUN, V49, P98, DOI 10.1016/j.specom.2006.11.004; MURRAY IR, 1993, J ACOUST SOC AM, V93, P1097, DOI 10.1121/1.405558; Nakayama T, 1999, ELEC SOC S, V99, P2; Nwe TL, 2003, SPEECH COMMUN, V41, P603, DOI 10.1016/S01167-6393(03)00099-2; ORTONY A, 1990, PSYCHOL REV, V97, P315, DOI 10.1037//0033-295X.97.3.315; Paeschke A., 2000, P ISCA WORKSH SPEECH, P75; Pantic M, 2003, P IEEE, V91, P1370, DOI 10.1109/JPROC.2003.817122; Parrott W., 2001, EMOTIONS SOCIAL PSYC; Petrushin V., 2000, P 6 INT C SPOK LANG, P222; Petrushin V., 1999, P ART NEUR NETW ENG, P7; Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607; Pierre-Yves O, 2003, INT J HUM-COMPUT ST, V59, P157, DOI 10.1016/S1071-5819(03)00141-6; RAHURKAR MA, 2003, 8 EUR C SPEECH COMM, P721; Reeves B., 1996, MEDIA EQUATION PEOPL; Scherer K.R., 1999, HDB COGNITION EMOTIO, P637; SHAMI M, 2005, IEEE C MULT EXP ICME; Shami M, 2007, SPEECH COMMUN, V49, P201, DOI 10.1016/j.specom.2007.01.006; SHRIBERG E, 2005, EUR 2005 LISB PORT; Slaney M, 2003, SPEECH COMMUN, V39, P367, DOI 10.1016/S0167-6393(02)00049-3; ten Bosch L, 2003, SPEECH COMMUN, V40, P213, DOI 10.1016/S0167-6393(02)00083-3; VAPNIK VN, 2005, NATURE STAT LEARNING; VERVERIDIS D, 2005, IEEE INT C AC SPEECH, P593; WU J, 2002, 7 INT C SPOK LANG DE, P453; Yacoub S, 2003, P EUROSPEECH, P729	49	5	5	SPRINGER-VERLAG LONDON LTD	GODALMING	SWEETAPPLE HOUSE CATTESHALL RD FARNCOMBE, GODALMING GU7 1NH, SURREY, ENGLAND		978-1-84800-305-7				2009							93	110		10.1007/978-1-84800-306-4_6		18	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	BIZ98	WOS:000264082400006	
S	Gagliardi, F		Serra, R; Cucchiara, R		Gagliardi, Francesco			The Necessity of Machine Learning and Epistemology in the Development of Categorization Theories: A Case Study in Prototype-Exemplar Debate	AI (ASTERISK) IA 2009: EMERGENT PERSPECTIVES IN ARTIFICIAL INTELLIGENCE	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	11th Congress of the Italian-Association-for-Artificial-Intelligence	DEC 09-12, 2009	Reggio Emilia, ITALY	Italian Assoc Artificial Intelligence, Univ Modena Reggio Emilia		Machine Learning; Epistemology; Cognitive Psychology; Categorization Theories; Bias-Variance Dilemma; Instance-Based Learning	ATTENTIONAL ALLOCATION; CLASSIFICATION; ALGORITHMS; ACCOUNTS	In the present paper we discuss some aspects of the development of categorization theories concerning cognitive psychology and machine learning. We consider the thirty-year debate between prototype-theory and exemplartheory in the studies of cognitive psychology regarding the categorization processes. We propose this debate is ill-posed, because it neglects some theoretical and empirical results of machine learning about the bias-variance theorem and the existence of some instance-based classifiers which can embed models subsuming both prototype and exemplar theories. Moreover this debate lies on a epistemological error of pursuing a, so called, experimentum crucis. Then we present how an interdisciplinary approach, based on synthetic method for cognitive modelling, can be useful to progress both the fields of cognitive psychology and machine learning.	[Gagliardi, Francesco] Univ Roma La Sapienza, Dept Philosoph & Epistemol Studies, I-00161 Rome, Italy	Gagliardi, F (reprint author), Univ Roma La Sapienza, Dept Philosoph & Epistemol Studies, Via Carlo Fea, I-00161 Rome, Italy.	francesco.gagliardi@libero.it					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ANDERSON JR, 1991, PSYCHOL REV, V98, P409, DOI 10.1037/0033-295X.98.3.409; Bezdek JC, 1998, IEEE T SYST MAN CY C, V28, P67, DOI 10.1109/5326.661091; CORDESCHI R, 2003, RIV FILOSOFIA INTELL, V1, P1; CORDESCHI R, 1994, FILOSOFIA AUTOMI ORI, P19; CORDESCHI R, 2008, MECH MIND HIST, P219; CORDESCHI R, 2001, DISCOVERY ARTIFICIAL; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Gagliardi F., 2008, P 30 ANN C COGN SCI, P1176; Gardenfors P., 2000, CONCEPTUAL SPACES GE; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; HENERY RJ, 1994, MACHINE LEARNING NEU, P107; HOUDE O., 1998, VOCABULAIRE SCI COGN; KRUSCHKEA JK, 2001, INT ENCY SOCIAL BEHA, P1532; LANGLEY P, 2006, ARTIFICIAL INTELLIGE; MEDIN DL, 1999, MIT ENCY COGNITIVE S, P104; MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037//0033-295X.85.3.207; MEDIN DL, 1989, AM PSYCHOL, V44, P1469, DOI 10.1037//0003-066X.44.12.1469; Merton R. K., 1973, SOCIOLOGY SCI THEORE; Merton R. K., 1968, SOCIAL THEORY SOCIAL; Merton R. K., 1949, SOCIAL THEORY SOCIAL; Minda JP, 2002, J EXP PSYCHOL LEARN, V28, P275, DOI 10.1037//0278-7393.28.2.275; Murphy G., 2002, BIG BOOK CONCEPTS; Nieddu L, 2000, EUR J OPER RES, V120, P459, DOI 10.1016/S0377-2217(98)00368-3; Rogoff B., 1991, APPRENTICESHIP THINK; ROSCH E, 1975, J EXP PSYCHOL GEN, V104, P192, DOI 10.1037/0096-3445.104.3.192; ROSCH E, 1975, COGNITIVE PSYCHOL, V7, P573, DOI 10.1016/0010-0285(75)90024-9; Rosseel Y, 2002, J MATH PSYCHOL, V46, P178, DOI 10.1006/jmps.2001.1379; Thagard P., 2005, MIND INTRO COGNITIVE; Vanpaemel W., 2005, P 27 ANN C COGN SCI, P2277; Veenman CJ, 2005, IEEE T PATTERN ANAL, V27, P1417, DOI 10.1109/TPAMI.2005.187; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Witten I., 2005, DATA MINING PRACTICA; Zaki SR, 2003, J EXP PSYCHOL LEARN, V29, P1160, DOI 10.1037/0278-7393.29.6.1160	36	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-10290-5	LECT NOTES ARTIF INT			2009	5883						182	191				10	Computer Science, Artificial Intelligence	Computer Science	BPK22	WOS:000279047900019	
J	Kagie, M; van der Loos, M; van Wezel, M				Kagie, Martijn; van der Loos, Matthijs; van Wezel, Michiel			Including item characteristics in the probabilistic latent semantic analysis model for collaborative filtering	AI COMMUNICATIONS			English	Article						Recommender systems; probabilistic latent semantic analysis; hybrid recommender systems	RECOMMENDER SYSTEMS; MAXIMUM-LIKELIHOOD; REGRESSION; ALGORITHM; FRAMEWORK	We propose a new hybrid recommender system that combines some advantages of collaborative and content-based recommender systems. While it uses ratings data of all users, as do collaborative recommender systems, it is also able to recommend new items and provide an explanation of its recommendations, as do content-based systems. Our approach is based on the idea that there are communities of users that find the same characteristics important to like or dislike a product. This model is an extension of the probabilistic latent semantic model for collaborative filtering with ideas based on clusterwise linear regression. On a movie data set, we show that the model, at the cost of a very small loss in overall performance, is able to recommend new items and give an explanation of its recommendations to its users.	[Kagie, Martijn; van der Loos, Matthijs; van Wezel, Michiel] Erasmus Univ, Erasmus Sch Econ, NL-3000 DR Rotterdam, Netherlands	Kagie, M (reprint author), Erasmus Univ, Erasmus Sch Econ, POB 1738, NL-3000 DR Rotterdam, Netherlands.	kagie@ese.eur.nl; mvanderloos@ese.eur.nl; mvanwezel@ese.eur.nl					Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99; Aikake H., 1974, IEEE T AUTOMAT CONTR, V19, P716; Ansari A, 2000, J MARKETING RES, V37, P363, DOI 10.1509/jmkr.37.3.363.18779; Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124; Basu C., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Billsus D, 2000, USER MODEL USER-ADAP, V10, P147, DOI 10.1023/A:1026501525781; Bishop C. M., 2006, PATTERN RECOGNITION; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Breese J. S, 1998, P 14 C UNC ART INT, P43; Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564; Camargo SJ, 2007, J CLIMATE, V20, P3635, DOI 10.1175/JCLI4188.1; Claypool M., 1999, P ACM SIGIR WORKSH R; CONDLIFF MK, 1999, P ACM SIGIR WORKSH R; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DeSarbo W. S., 1992, MARKET LETT, V3, P273, DOI 10.1007/BF00994135; Desarbo WS, 2005, STRATEGIC MANAGE J, V26, P47, DOI 10.1002/smj.431; DESARBO WS, 1988, J CLASSIF, V5, P249, DOI 10.1007/BF01897167; GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867; Goldberg K, 2001, INFORM RETRIEVAL, V4, P133, DOI 10.1023/A:1011419012209; Good N., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); Herlocker J. L., 1999, Proceedings of SIGIR '99. 22nd International Conference on Research and Development in Information Retrieval, DOI 10.1145/312624.312682; Herlocker J. L., 2000, P 2000 ACM C COMP SU, P241, DOI DOI 10.1145/358916.358995; Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772; Hofmann T, 2004, ACM T INFORM SYST, V22, P89, DOI 10.1145/963770.963774; Hofmann T., 1999, P 15 C UNC ART INT U, P289; Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950; KOREN Y, 2009, IEEE COMPUT, V42, P30; KRIEGLER M, 2006, EUR J AGEING, V2, P13; Larcker DF, 2004, J ACCOUNTING RES, V42, P625, DOI 10.1111/j.1475-679X.2004.t01-1-00143.x; Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344; McCullagh P., 1989, MONOGRAPHS STAT APPL, V37; Mcsherry D, 2005, ARTIF INTELL REV, V24, P179, DOI 10.1007/s10462-005-4612-x; Melville P, 2002, P 18 NAT C ART INT, P187; Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943; Pazzani MJ, 1999, ARTIF INTELL REV, V13, P393, DOI 10.1023/A:1006544522159; Pazzani MJ, 2007, LNCS, V4321, P325, DOI DOI 10.1007/978-3-540-72079-9_10; Pennings JME, 2004, J BANK FINANC, V28, P951, DOI 10.1016/S0378-4266(03)00046-3; Popescul A., 2001, P 17 C UNC ART INT U, P437; PRASAD B, 2003, J ELECT COMMERCE RES, V4, P65; RAMASWAMY V, 1993, MARKET SCI, V12, P103, DOI 10.1287/mksc.12.1.103; Resnick P, 1997, COMMUN ACM, V40, P56, DOI 10.1145/245108.245121; Riedl J., 1994, P ACM C COMP SUPP CO, P175, DOI 10.1145/192844.192905; Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI DOI 10.1145/371920.372071; Schein A. I., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/564376.564421; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SHARDANAND U., 1995, P C HUM FACT COMP SY, P210, DOI DOI 10.1145/223904.223931; Sinha R., 2002, C HUM FACT COMP SYST, P830; SOBOROFF I, 1999, P IJCAI WORKSH MACH; Takacs G., 2008, P 2008 ACM C REC SYS, P267, DOI 10.1145/1454008.1454049; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; TINTAREV N, 2007, P 23 INT C DAT ENG W, P801; TRAN T, 2000, P KNOWL BAS EL MARK; Vriens M, 1996, J MARKETING RES, V33, P73, DOI 10.2307/3152014; WEDEL M, 1995, J CLASSIF, V12, P21, DOI 10.1007/BF01202266; Zhou YH, 2008, LECT NOTES COMPUT SC, V5034, P337	57	0	0	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0921-7126		AI COMMUN	AI Commun.		2009	22	4					249	265		10.3233/AIC-2009-0467		17	Computer Science, Artificial Intelligence	Computer Science	535HR	WOS:000272958500004	
S	Salmeri, A; Licciardi, CA; Lamorte, L; Valla, M; Giannantonio, R; Sgroi, M		Mokhtari, M; Khalil, I; Bauchet, J; Zhang, D; Nugent, C		Salmeri, Alessia; Licciardi, Carlo Alberto; Lamorte, Luca; Valla, Massimo; Giannantonio, Roberta; Sgroi, Marco			An Architecture to Combine Context Awareness and Body Sensor Networks for Health Care Applications	AMBIENT ASSISTIVE HEALTH AND WELLNESS MANAGEMENT IN THE HEART OF THE CITY, PROCEEDING	Lecture Notes in Computer Science		English	Proceedings Paper	7th International Conference on Smart Homes and Health Telematics	JUL 01-03, 2009	Tour, FRANCE			Body Sensor Network; Wireless Sensor Network; SPINE; Context Awareness Platform; Context Broker; ContextML; Context Query Language; health care monitoring		Information derived from wearable sensors, such as illness/fall alarms, can be enhanced with context information to provide advanced health care and assisted living applications. In this paper we describe an architecture that combines sensor and context data into a telecommunication service to detect emergency situations and generate alarm calls according to user's preferences and contacts geographic proximity.	[Salmeri, Alessia; Licciardi, Carlo Alberto; Lamorte, Luca; Valla, Massimo; Giannantonio, Roberta] Telecom Italia Lab, I-10148 Turin, Italy	Salmeri, A (reprint author), Telecom Italia Lab, Via Reiss Romoli 274, I-10148 Turin, Italy.	alessia.salmeri@telecomitalia.it; carlo.licciardi@telecomitalia.it; luca.lamorte@telecomitalia.it; massimo.valla@telecomitalia.it; roberta.giannantonio@telecomitalia.it; marco.sgroi@wsnlabberkeley.com					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEY AK, 2001, SPECIAL ISSUE CONTEX, V16, P97; GRAVINA R, 2008, 2008 IEEE INT C SYST; Henricksen K, 2005, LECT NOTES COMPUT SC, V3760, P846; LAMORTE L, 2007, 11 WORKSH CONT AW PR; LOMBRISER C, 2007, P 2 INT C BOD AR NET; LOMBRISER C., 2007, 15 FACHT KOMM VERT S, P127; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; REICHLE R, 2008, P 5 IEEE WORKSH CONT, P434; Roman M., 2002, IEEE Pervasive Computing, V1, DOI 10.1109/MPRV.2002.1158281; SEPPA VP, 2008, P 4 EUR C MED BIOM E; SHNAYDER V, 2005, TR0805 HARV U DIV EN	12	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-02867-0	LECT NOTES COMPUT SC			2009	5597						90	97				8	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Telecommunications	Computer Science; Telecommunications	BLG61	WOS:000270130800012	
J	Umezawa, K; Ikebe, J; Nomizu, M; Nakamura, H; Higo, J				Umezawa, Koji; Ikebe, Jinzen; Nomizu, Motoyoshi; Nakamura, Haruki; Higo, Junichi			Conformational Requirement on Peptides to Exert Laminin's Activities and Search for Protein Segments With Laminin's Activities	BIOPOLYMERS			English	Article						laminin; molecular dynamics; peptide conformation; database search; structure-function relationship	BETA-HAIRPIN PEPTIDE; ENERGY LANDSCAPE; CELL-ADHESION; DISORDERED CONFORMATIONS; MOLECULAR-DYNAMICS; CRYSTAL-STRUCTURE; EXPLICIT WATER; SWISS-MODEL; G-DOMAIN; CHAIN	The human laminin alpha 3 chain LG4 module has biological activities of cell adhesion, heparin binding, migration, and neurite outgrowth. The authors had previously identified that the active site of this protein is in residues 1411-1429 (amino-acid sequence = KNSFMALYLSKGRLVFALG called A3G756) and that a three-amino-acid sequence KGR in A3G756 is crucial for exerting the activities. An experiment has shown that a cyclo-hEF3A peptide (a cyclic analog of A3G756) exhibits stronger activities than a linear-hEF3A peptide (a linearized peptide of the cyclo-hEF3A peptide). This experiment implies that adopting a loop conformation may be important for exerting the activities. In this study, the authors first computed the solution structures of the cyclo-hEF3A and linear-hEF3A peptides by molecular dynamics simulations. The obtained conformational ensembles consisted of a variety of conformations, which is a usual property of short peptides in solution. The ensembles involved a fraction where the peptide adopted beta-hairpins and KGR was located at the hairpin head. If there are protein segments that adopt beta-hairpins similar to those sampled from the simulation and have the KGR sequence at the hairpin head, these segments may have some activities. Then, the authors searched a database for segments satisfying these requirements and detected six functional segments. Three of them had laminin's activity, and the remaining three had activities similar to laminin's activities. Analyses on the conformational ensembles of cyclo- and linear-hEF3A peptides suggest that not only the KGR position in the hairpin but also the inter-strand packing is important for exerting laminin's activities. (c) 2009 Wiley Periodicals, Inc. Biopolymers (Pept Sci) 92: 124-131, 2009.	[Higo, Junichi] Osaka Univ, Open Labs Adv Biosci & Biotechnol, Ctr Adv Med Engn & Informat, Osaka 5640874, Japan; [Umezawa, Koji; Ikebe, Jinzen] Osaka Univ, Open Labs Adv Biosci & Biotechnol, Grad Sch Frontier Biosci, Osaka 5650874, Japan; [Nomizu, Motoyoshi] Tokyo Univ Pharm & Life Sci, Sch Pharm, Lab Clin Biochem, Tokyo 1920392, Japan; [Nakamura, Haruki] Osaka Univ, Inst Prot Res, Suita, Osaka 5650871, Japan	Higo, J (reprint author), Osaka Univ, Open Labs Adv Biosci & Biotechnol, Ctr Adv Med Engn & Informat, 6-2-3 Furuedai, Osaka 5640874, Japan.	higo@protein.osaka-u.ac.jp					Arnold K, 2006, BIOINFORMATICS, V22, P195, DOI 10.1093/bioinformatics/bti770; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Burke DF, 2000, BIOINFORMATICS, V16, P513, DOI 10.1093/bioinformatics/16.6.513; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dai JY, 2004, CELL, V116, P649, DOI 10.1016/S0092-8674(04)00172-2; Espadaler J, 2004, NUCLEIC ACIDS RES, V32, pD185, DOI 10.1093/nar/gkh002; Frank BS, 2004, J BIOL CHEM, V279, P7909, DOI 10.1074/jbc.M310524200; Fukunishi Y, 2003, J PHYS CHEM B, V107, P13201, DOI 10.1021/jp035478e; Guex N, 1997, ELECTROPHORESIS, V18, P2714, DOI 10.1002/elps.1150181505; Gutteridge A, 2005, J MOL BIOL, V346, P21, DOI 10.1016/j.jmb.2004.11.013; Higo J, 2001, CHEM PHYS LETT, V337, P169, DOI 10.1016/S0009-2614(01)00118-X; Higo J, 2001, PROTEIN SCI, V10, P1160, DOI 10.1110/ps.44901; Iivanainen A, 1999, J BIOL CHEM, V274, P14107, DOI 10.1074/jbc.274.20.14107; Ikeda K, 2003, J COMPUT CHEM, V24, P310, DOI 10.1002/jcc.10160; Kamiya N, 2002, PROTEIN SCI, V11, P2297, DOI 10.1110/ps.0213102; Kasper C, 2000, NAT STRUCT BIOL, V7, P389; Katayama M, 2004, J MOL HISTOL, V35, P277; Kato K, 2002, BIOCHEMISTRY-US, V41, P10747, DOI 10.1021/bi020180k; Kato-Takagaki K, 2007, BIOCHEMISTRY-US, V46, P1952, DOI 10.1021/bi0620981; Kim JG, 2003, PHYS REV E, V68, DOI 10.1103/PhysRevE.68.021110; Kim JG, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.057103; Kollman P. A., 1997, COMPUTER SIMULATION; Laskowski RA, 2005, NUCLEIC ACIDS RES, V33, pW89, DOI 10.1093/nar/gki414; Laskowski RA, 2005, J MOL BIOL, V351, P614, DOI 10.1016/j.jmb.2005.05.067; Libby RT, 2000, J NEUROSCI, V20, P6517; Miner JH, 1997, J CELL BIOL, V137, P685, DOI 10.1083/jcb.137.3.685; Momota Y, 2005, J RECEPT SIG TRANSD, V25, P1, DOI 10.1081/RRS-200047870; Narasimhan J, 2005, J BIOL CHEM, V280, P27356, DOI 10.1074/jbc.M502814200; Onufriev A, 2000, J PHYS CHEM B, V104, P3712, DOI 10.1021/jp994072s; Rajarathnam K, 2001, J BIOL CHEM, V276, P4909, DOI 10.1074/jbc.M005085200; REYES AA, 1990, CELL REGUL, V1, P567; Ritchie KJ, 2004, SEMIN CELL DEV BIOL, V15, P237, DOI 10.1016/j.semcdb.2003.12.005; ROUSSELLE P, 1994, J CELL BIOL, V125, P205, DOI 10.1083/jcb.125.1.205; Rychaert J., 1977, J COMPUT PHYS, V23, P327; Sauder JM, 2000, PROTEINS, V40, P6, DOI 10.1002/(SICI)1097-0134(20000701)40:1<6::AID-PROT30>3.0.CO;2-7; Shirai H, 1999, FEBS LETT, V455, P188, DOI 10.1016/S0014-5793(99)00821-2; Terada T, 2002, J CHEM PHYS, V116, P33, DOI 10.1063/1.1423938; Tisi D, 2000, EMBO J, V19, P1432, DOI 10.1093/emboj/19.7.1432; Utani A, 2001, J BIOL CHEM, V276, P28779, DOI 10.1074/jbc.M101420200; Yang J, 2003, J BIOL CHEM, V278, P6516, DOI 10.1074/jbc.M210430200; Yang MY, 2006, J BIOL CHEM, V281, P28307, DOI 10.1074/jbc.M604413200	41	0	0	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	0006-3525		BIOPOLYMERS	Biopolymers		2009	92	2					124	131		10.1002/bip.21148		8	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	426ES	WOS:000264691400006	
B	Lavine, BK; Rayens, WS		Brown, SD; Tauler, R; Walczak, B		Lavine, B. K.; Rayens, W. S.			Classification: Basic Concepts	COMPREHENSIVE CHEMOMETRICS: CHEMICAL AND BIOCHEMICAL DATA ANALYSIS, VOLS 1-4			English	Article; Book Chapter							SUPPORT VECTOR MACHINES; MASS-SPECTROMETRY; DATA FUSION; NEURAL-NETWORKS; DISCRIMINATION; DOMAIN		[Lavine, B. K.] Oklahoma State Univ, Stillwater, OK 74078 USA; [Rayens, W. S.] Univ Kentucky, Dept Stat, Lexington, KY USA	Lavine, BK (reprint author), Oklahoma State Univ, Stillwater, OK 74078 USA.						Albano C., 1978, ANAL CHIM ACTA-COMP, V103, P429, DOI 10.1016/S0003-2670(01)83107-X; Brereton R. G., 1992, MULTIVARIATE PATTERN; Cheng C. Yan, 2008, Immunology Endocrine & Metabolic Agents in Medicinal Chemistry, V8, P1, DOI 10.2174/187152208783790778; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Forshed J, 2007, CHEMOMETR INTELL LAB, V85, P102, DOI 10.1016/j.chemolab.2006.05.002; ISENHOUR TL, 1971, ANAL CHEM, V43, pA20, DOI 10.1021/ac60304a037; James M., 1985, CLASSIFICATION; JURS PC, 1969, ANAL CHEM, V41, P21, DOI 10.1021/ac60270a002; Karakitsos P, 1996, ANAL QUANT CYTOL, V18, P245; KESMIR C, 1995, ELECTROPHORESIS, V16, P927, DOI 10.1002/elps.11501601156; Kowalski B. R., 1988, TRACS, V1, P71; Kowalski B.R., 1982, CLASSIFICATION PATTE; Lavine B, 2006, ANAL CHEM, V78, P4137, DOI 10.1021/ac060717q; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Myles AJ, 2004, J CHEMOMETR, V18, P286, DOI 10.1002/cem.870; Nilsson T, 1996, J MASS SPECTROM, V31, P1422, DOI 10.1002/(SICI)1096-9888(199612)31:12<1422::AID-JMS442>3.0.CO;2-5; Ramos PM, 2006, ANAL CHIM ACTA, V558, P274, DOI 10.1016/j.aca.2005.10.066; Ramos PM, 2007, ANAL CHIM ACTA, V584, P360, DOI 10.1016/j.aca.2006.11.051; Sharaf M.A., 1986, CHEMOMETRICS, P184; Tou J.T., 1974, PATTERN RECOGNITION; Vapnik V.N., 1998, STAT LEARNING THEORY; Varmuza K, 1980, PATTERN RECOGNITION; Woody NA, 2007, J CHEMOMETR, V21, P357, DOI 10.1002/cem.1060; Zomer S, 2004, J CHEMOMETR, V18, P294, DOI 10.1002/cem.872; Zomer S, 2004, ANALYST, V129, P175, DOI 10.1039/b312982a	25	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS		978-0-44-452701-1				2009							B507	B515				9	Chemistry, Medicinal; Pharmacology & Pharmacy	Pharmacology & Pharmacy	BCS71	WOS:000311292900069	
S	Brahnam, S; Nanni, L		Mumford, CL; Jain, LC		Brahnam, Sheryl; Nanni, Loris			Predicting Trait Impressions of Faces Using Classifier Ensembles	COMPUTATIONAL INTELLIGENCE: COLLABORATION, FUSION AND EMERGENCE	Intelligent Systems Reference Library		English	Article; Book Chapter							PHYSICAL ATTRACTIVENESS; RECOGNITION; IMAGES; PERCEPTION; MODELS	In the experiments presented in this chapter, single classifier systems and ensembles are trained to detect the social meanings people perceive in facial morphology. Exploring machine models of people's impressions of faces has value in the fields of social psychology and human-computer interaction. Our first concern in designing this study was developing a sound ground truth for this problem domain. We accomplished this by collecting a large number of faces that exhibited strong human consensus in a comprehensive set of trait categories. Several single classifier systems and ensemble systems composed of Levenberg-Marquardt neural networks using different methods of collaboration were then trained to match the human perception of the faces in the six trait dimensions of intelligence, maturity, warmth, sociality, dominance, and trustworthiness. Our results show that machine learning methods employing ensembles are as capable as most individual human beings are in their ability to predict the social impressions certain faces make on the average human observer. Single classifier systems did not match human performance as well as the ensembles did. Included in this chapter is a tutorial, suitable for the novice, on the single classifier systems and collaborative methods used in the experiments reported in the study.	[Brahnam, Sheryl] Missouri State Univ, Springfield, MO 65804 USA; [Nanni, Loris] Univ Bologna, DEIS, CNR, IEIIT, I-40136 Bologna, Italy	Brahnam, S (reprint author), Missouri State Univ, 901 S Natl, Springfield, MO 65804 USA.	sbrahnam@missouristate.edu; lnanni@deis.unibo.it					Abate AF, 2007, PATTERN RECOGN LETT, V28, P1885, DOI 10.1016/j.patrec.2006.12.018; Albright L, 1997, J PERS SOC PSYCHOL, V72, P558, DOI 10.1037/0022-3514.72.3.558; ALCOCK D, 1998, PSYCHOL REP, V3, P1435; Alpaydin E, 2004, INTRO MACHINE LEARNI; ALUNCAY H, 2000, SPEECH COMMUN, V4, P255; Bellman R., 1961, ADAPTIVE CONTROL PRO; BERRY DS, 1989, PERS SOC PSYCHOL B, V15, P266, DOI 10.1177/0146167289152013; BERRY DS, 1986, PSYCHOL BULL, V1, P3; BRAHNAM S, 2002, MODELING PHYS PERSON; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V1, P5; Bruce V., 1988, RECOGNISING FACES; Brunelli R., 1992, DARPA IM UND WORKSH, P311; BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061; Brunswik E., 1947, PERCEPTION REPRESENT; Bull R, 1988, SOCIAL PSYCHOL FACIA; BURTON AM, 1993, PERCEPTION, V22, P153, DOI 10.1068/p220153; CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842; COTTRELL GW, 1990, INTERNATIONAL NEURAL NETWORK CONFERENCE, VOLS 1 AND 2, P322; Cottrell G., 1991, ADV NEURAL INFORMATI, V3, P564; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; Czyz J, 2004, PATTERN RECOGN, V37, P1459, DOI 10.1016/j.patcog.2004.01.008; Duda R.O., 2000, PATTERN CLASSIFICATI; EAGLY AH, 1991, PSYCHOL BULL, V110, P109, DOI 10.1037/0033-2909.110.1.109; EDELMAN BE, 1998, J BIOL SYST, V3, P241; Efron B, 1982, JACKKNIFE BOOTSTRAP; Enlow DH, 1996, ESSENTIALS FACIAL GR; FEINGOLD A, 1992, PSYCHOL BULL, V111, P304, DOI 10.1037//0033-2909.111.2.304; FREIERMAN S, 2000, NY TIMES, pD6; GOLUMB BA, 1991, ADV NEURAL INF PROCE, P572; GUO G, 2001, IMAGE VISION COMPUT, P631; Heisele B, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P688; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Jain A, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P159, DOI 10.1109/AFGR.2004.1301524; JAIN AK, 2000, IEEE T PATTERN ANAL, V1, P4; KANGHAE S, 2007, 2 INT C ADV INF TECH; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kohonen T, 1977, ASS MEMORY SYSTEM TH; KOSUGI M, 1995, SYST COMPUT JPN, V6, P27; Kuncheva LI, 2000, KES'2000: FOURTH INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED INTELLIGENT ENGINEERING SYSTEMS & ALLIED TECHNOLOGIES, VOLS 1 AND 2, PROCEEDINGS, P185, DOI 10.1109/KES.2000.885788; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; KUNCHEVA LI, 2005, INFORM FUSION, V1, P3; KUNCHEVA LI, 2004, COMBINING PATTERN CL; Langlois JH, 2000, PSYCHOL BULL, V126, P390, DOI 10.1037/0033-2909.126.3.390; Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553; Lanitis A, 1997, IEEE T PATTERN ANAL, V19, P743, DOI 10.1109/34.598231; Levenberg K., 1944, Quarterly of Applied Mathematics, V2; LING CX, 2003, CANADIAN C AI, P329; LU X, 2004, SPIE BIOM TECHN HUM, P114; Marquardt D.W., 1963, SIAM J APPL MATH, V11, P431, DOI DOI 10.1137/0111030; Martinez A. M., 1998, 24 CVC; Martinez-Munoz G, 2005, PATTERN RECOGN, V38, P1483, DOI 10.1016/j.patcog.2005.02.020; MCARTHUR LZ, 1983, PSYCHOL REV, V90, P215, DOI 10.1037//0033-295X.90.3.215; MELVILLE P, 2003, IJCAI, P505; METZ CE, 1978, SEMIN NUCL MED, V8, P283, DOI 10.1016/S0001-2998(78)80014-2; MITSUMOTO ST, 1996, PATTERN RECOGN, V2, P331; MOGHADDAM B, 2000, 6 IEEE INT C AUT FAC, P306; MOGHADDAM B, 2002, IEEE T PATTERN ANAL, V5, P306; Mulford M, 1998, AM J SOCIOL, V103, P1565, DOI 10.1086/231401; Nocedal J, 1999, NUMERICAL OPTIMIZATI; OJA E, 1983, PRINCIPAL COMPONENTS; Opitz D., 1999, J ARTIFICIAL INTELLI, V11, P169; OTOOLE AJ, 1997, MEM COGNITION, P146; OTOOLE AJ, 1991, 13TH P ANN C COGN SC, P847; Padgett C, 1998, PROCEEDINGS OF THE TWENTIETH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P806; PHILLIPS PJ, 1998, ADV NEURAL INFORMATI, P803; ROSENBERG S, 1977, NEBRASKA S MOTIVATIO, P179; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Russell S.J., 2002, ARTIFICIAL INTELLIGE; SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519; SWETS D, 1996, IEEE T PATTERN ANAL, V8, P831; TODD JT, 1980, SCI AM, V242, P132; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Turk MA, 1991, IEEE C COMP VIS PATT, P586, DOI DOI 10.1109/CVPR.1991.139758; Valentin D, 1997, J MATH PSYCHOL, V41, P398, DOI 10.1006/jmps.1997.1186; VALENTIN D, 1994, PATTERN RECOGN, V27, P1209, DOI 10.1016/0031-3203(94)90006-X; Valentin D., 1994, J BIOL SYST, V2, P413, DOI 10.1142/S0218339094000258; van der Heijden F., 2004, CLASSIFICATION PARAM; Vapnik V.N., 1995, NATURE STAT LEARNING; WECHSLER H, 1998, 3 INT C AUT FAC GEST, P194; Whitaker C., 2003, EXAMINING RELATIONSH; Zebrowitz L, 1998, READING FACES WINDOW; Zebrowitz L. A., 2008, SOC PERS PSYCHOL COM, V2, P1497, DOI [10.1111/j.1751-9004.2008.00109.x, DOI 10.1111/J.1751-9004.2008.00109.X]; ZEBROWITZ LA, 1992, DEV PSYCHOL, V28, P1143, DOI 10.1037/0012-1649.28.6.1143; ZEBROWITZ LA, 1993, J PERS SOC PSYCHOL, V65, P85, DOI 10.1037//0022-3514.65.1.85; ZENOBI G, 2001, 12 C MACH LEARN, P576; ZHAO W, 2000, ACM COMP SURV, V4, P399; *MATHWORKS INC, 2000, US MATLAB LANG TECHN	89	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1868-4394	978-3-642-01798-8	INTEL SYST REF LIBR			2009	1						403	439			10.1007/978-3-642-01799-5	37	Computer Science, Artificial Intelligence	Computer Science	BKN57	WOS:000268703100012	
S	van den Bosch, A	Ludeling, A; Kyto, M			van den Bosch, Antal	Ludeling, A; Kyto, M		Machine learning	CORPUS LINGUISTICS, PART 2	Handbucher zur Sprach und Kommunikationswissenschaft		English	Article; Book Chapter							CLASSIFIERS									Abney Steven, 2002, P 40 ANN M ASS COMP, P360; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BANKO M, 2001, P 39 ANN M ASS COMP, P26, DOI 10.3115/1073012.1073017; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; Brants T, 2000, P 6 C APPL NAT LANG, P224, DOI 10.3115/974147.974178; Breiman L, 1984, CLASSIFICATION REGRE; Brill E, 1995, COMPUT LINGUIST, V21, P543; Burr Ridge I, 1997, MACHINE LEARNING; CANISIUS S, 2006, P CONLL 10 NEW YORK, P176, DOI 10.3115/1596276.1596309; CARRERAS X, 2002, P 13 EUR C MACH LEAR, P35; Carreras X., 2005, P 9 C COMP NAT LANG, P152, DOI 10.3115/1706543.1706571; Caruana R., 2004, P 10 ACM SIGKDD INT, P69, DOI 10.1145/1014052.1014063; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; Cohen W. W., 1995, P 12 INT C MACH LEAR, P115; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daelemans W, 1999, J EXP THEOR ARTIF IN, V11, P287, DOI 10.1080/095281399146436; Daelemans W, 1996, P 4 WORKSH VER LARG, P14; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Daume H, 2006, J ARTIF INTELL RES, V26, P101; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DIETTERICH TG, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P572; Furnkranz J., 1994, P 11 INT C MACH LEAR, P70; Johnson M, 1998, COMPUT LINGUIST, V24, P613; Kingsbury P., 2002, P HUM LANG TECHN C S; Klein D., 2003, P 41 M ASS COMP LING, P423; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; LAFFERTY J. D., 2001, P 18 INT C MACH LEAR, P282; Littlestone N., 1988, Machine Learning, V2, DOI 10.1007/BF00116827; Madsen R. E, 2005, P 22 INT C MACH LEAR, P545, DOI 10.1145/1102351.1102420; Marcus M, 1994, COMPUTATIONAL LINGUI, V19, P313; MARCUS M, 1994, P 1994 HUM LANG TECH, P110; Marsi E., 2003, P 41 ANN M ASS COMP, P489; Oostdijk N.H.J., 2002, P 3 INT C LANG RES E, P340; Punyakanok V, 2001, ADV NEUR IN, V13, P995; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Ratnaparkhi A., 1996, P C EMP METH NAT LAN, P133; RATNAPARKHI A, 1994, WORKSH HUM LANG TECH, P250; RISSANEN J, 1983, ANN STAT, V11, P416, DOI 10.1214/aos/1176346150; Rosenblatt F., 1958, PSYCHOL REV, V65, P368; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Shavlik J. W., 1990, READINGS MACHINE LEA; Thompson C.A., 1999, P 16 INT C MACH LEAR, P406; ULE T, 2003, P 14 M COMP LING NET; van Halteren H, 2001, COMPUT LINGUIST, V27, P199; VANDENBOSCH A, 2006, P 5 INT C LANG RES E; VANDENBOSCH A, 2002, P 40 ANN M ASS COMP, P433; VANEYNDE F, 2004, PART SPEECH TAGGING; Yarowsky D., 1995, P ACL, P189; ZAVREL J, 2000, P 2 INT C LANG RES E, P17; Zipf GK, 1935, PSYCHOBIOLOGY LANGUA	53	0	0	WALTER DE GRUYTER & CO	BERLIN 30	GENTHINER STRASSE 13, D-10785 BERLIN 30, GERMANY	1861-5090	978-3-11-021388-1	HANDB SPRACH KOMMUN			2009	29		2				855	874			10.1515/9783110213881.2	20	Linguistics	Linguistics	BOC63	WOS:000276188000004	
B	Babu, TR; Murty, MN; Subrahmanya, SV		Cao, L		Babu, T. Ravindra; Murty, M. Narasimha; Subrahmanya, S. V.			Multiagent Systems for Large Data Clustering	DATA MINING AND MULTI-AGENT INTEGRATION			English	Article; Book Chapter							AGENTS	Multiagent system is an applied research area encompassing many disciplines. With increasing computing power and easy availability of storage devices vast volumes of data is available containing enormous amount of hidden information. Generating abstractions froth such large data is a challenging data mining task. Efficient large data clustering schemes are important in dealing with such large data. In the current work we provide two different efficient approaches of multiagent based large pattern clustering that would generate abstraction with single database scan, integrating domain knowledge, multiagent systems, data mining and intelligence through agent-mining interaction. We illustrate the approaches based on implementation on practical data.	[Babu, T. Ravindra; Subrahmanya, S. V.] Infosys Technol Ltd, E Comm Res Lab, Bangalore 560100, Karnataka, India; [Murty, M. Narasimha] Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India	Babu, TR (reprint author), Infosys Technol Ltd, E Comm Res Lab, Bangalore 560100, Karnataka, India.	mnm@csa.iisc.ernet.in; subrahmanyasv@infosys.com					Abonyi J., 2005, Informatica, V29; AGOGINO A, 2006, EFFICIENT AGENT BASE, P1079; AGRAWAL R, 1993, P 1993 ACM SIGMOD IN, P266; Allwein E. L., 2000, MACHINE LEARNING RES, V1, P113; Babu T. R., 2001, PATTERN RECOGN, V34, P523, DOI 10.1016/S0031-3203(00)00094-7; BABU TR, 2004, P 4 INT C HYBR INT S, P266; BAGHSHAH MS, 2008, AGENT BASED CLUSTERI, P551; BAJAJ C, 1999, DATA VISUALIZATION T; BEKKERMAN R, 2007, WEB PAGE CLUSTERING, P2280; Bradley P. S., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Breban S., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems; Buccafurri F, 2002, LECT NOTES COMPUT SC, V2455, P109; CAO L, 2007, F TRADE AGENT MINING; CAO L, 2007, SIGKDD EXPLORATIONS, V9, P84; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVIJVER PA, 1986, PATTERN RECOGNITION; Duda R.O., 2000, PATTERN CLASSIFICATI; DUMOUCHEL W, 1999, P 5 ACM SIGKDD INT C, P6, DOI 10.1145/312129.312184; DURFEE EH, 1994, DISTRUBUTED PROBLEM; EDWARDS P, 1993, P SPEC INT GROUP COO, P163; Ferber J., 1999, MULTIAGENT SYSTEMS; FREIAS AA, 2002, DATA MINING KNOWLEDG; Garruzzo S, 2008, ACM T AUTON ADAP SYS, V3, DOI 10.1145/1352789.1352792; GHOSH J, 2002, NSF WORKSH NEXT GEN, P99; GOLFARELLI M, SPATIO TEMPORAL CLUS; Gomez J, 2003, SIAM PROC S, P83; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Han J., 2001, DATA MINING CONCEPTS; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Kaufman L., 1990, FINDING GROUPS DATA; KAZIENKO P, MULTIAGENT SYSTEM WE; KEARNS M, 1994, J ACM, V41, P67, DOI 10.1145/174644.174647; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P734, DOI 10.1109/TPAMI.2002.1008381; Mitra S., 2003, DATA MINING MULTIMED; Ogston E, 2004, LECT NOTES COMPUT SC, V2872, P59; OGSTON E, 2003, METHOD DECENTRALIZIN; Pal S.K., 2004, PATTERN RECOGNITION; Pal SK, 2004, INFORM SCIENCES, V163, P1, DOI 10.1016/j.ins.2003.03.012; Park JE, 2006, PROC WRLD ACAD SCI E, V11, P97; Piraveenan M, 2008, STUD COMPUT INTELL, V115, P485; Rosaci D, 2005, LECT NOTES COMPUT SC, V3590, P31; SCHAPIRE RE, 1999, P ALG LEARN THEOR; Sen S, 2007, LECT NOTES COMPUT SC, V4476, P28; SIAN SS, 1991, LECT NOTES ARTIF INT, V482, P440; Spath H, 1980, CLUSTER ANAL ALGORIT; TIAN Z, 1996, P 1996 ACM SIGMOD IN, P103; TOZICKA J, 2007, AUTON AGENT MULTI-AG; TOZICKA J, 2007, FRAMEWORK AGENT BASE, P678; Valiant L.G, 1988, TR1488 HARV U AIK CO; Viaene S, 2004, IEEE T KNOWL DATA EN, V16, P612, DOI 10.1109/TKDE.2004.1277822; Viswanath P, 2005, PATTERN RECOGN, V38, P1187, DOI 10.1016/j.patcog.2004.10.007; Weiss G, 2000, MULTIAGENT SYSTEMS M; WOOLDRIDGE M, 1994, P WORKSH DISTR SOFTW, P40; YOSHIDA K, 2001, INT J HYBRID INTELLI, V34, P523; YOSHIDA K, 2005, INT J HYBRID INTELLI, V2, P235; Zhao Y., 2007, P KDD 2007 WORKSH DO, P18, DOI 10.1145/1288552.1288555; INTEGRATION AGENTS D; DISTRIBUTED DATA MIN	59	1	1	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES		978-1-4419-0521-5				2009							219	238		10.1007/978-1-4419-0522-2_15	10.1007/978-1-4419-0522-2	20	Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BKW40	WOS:000269462600015	
S	Jo, T		Slezak, D; Kim, TH; Zhang, Y; Ma, J; Chung, KI		Jo, Taeho			Categorizing News Articles Using NTC without Decomposition	DATABASE THEORY AND APPLICATION	Communications in Computer and Information Science		English	Proceedings Paper	International Conference on Database Theory and Application held at the FGIT 2009 Conference	DEC 10-12, 2009	Cheju Isl, SOUTH KOREA				SUPPORT VECTOR MACHINES; CLASSIFICATION	In this research, we attempt to apply the NTC (Neural Text Categorizer) to the text categorization without decomposing it into binary classifications. Because a single classifier has its very weak robustness to the entire text categorization, it is usually decomposed into binary classifications as many as categories. However, it requires to rearrange and relabel the given training examples with positive or negative labels for decomposing the text categorization. The task of this research is to apply the NTC to the text categorization without the decomposition and validate its feasibility. Therefore, we will compare the NTC with other approaches in the text categorization in the environment where the text categorization is not decomposed and validate that the NTC is practical tool for implement a light version of text categorization system.	Inha Univ, Sch Comp & Informat Engn, Inchon, South Korea	Jo, T (reprint author), Inha Univ, Sch Comp & Informat Engn, Inchon, South Korea.	tjo018@inha.ac.kr					Burr Ridge I, 1997, MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N., 2000, SUPPORT VECTOR MACHI; Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; Estabrooks A, 2004, COMPUT INTELL, V20, P18, DOI 10.1111/j.0824-7935.2004.t01-1-00228.x; Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428; Joachims T., 1998, P 10 EUR C MACH LEAR, P143; Kononenko I., 1989, P 4 EUR WORK SESS LE, P91; Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687; Massand B., 1992, P 15 ACM INT C RES D, P59; McClelland J. L, 1986, PARALLEL DISTRIBUTED, V1; McClelland JL, 1986, PARALLEL DISTRIBUTED, V2; Mladenic D., 1999, P INT C MACH LEARN, P256; Ruiz ME, 2002, INFORM RETRIEVAL, V5, P87, DOI 10.1023/A:1012782908347; Sebastiani F., 2002, ACM COMPUT SURV, V34, P47; Wiener E.D., 1995, THESIS U COLORADO; Yang Y., 1999, INFORMATION RETRIEVA, V1, P67	17	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1865-0929	978-3-642-10582-1	COMM COM INF SC			2009	64						34	40				7	Computer Science, Hardware & Architecture; Computer Science, Theory & Methods	Computer Science	BPZ42	WOS:000280424500005	
S	Lee, YH; Tsao, WJ; Chu, TH		Weinhardt, C; Luckner, S; Stober, J		Lee, Yen-Hsien; Tsao, Wan-Jung; Chu, Tsai-Hsin			Use of Ontology to Support Concept-Based Text Categorization	DESIGNING E-BUSINESS SYSTEMS	Lecture Notes in Business Information Processing		English	Proceedings Paper	7th Workshop on e-Business (WeB 2008)	DEC 13, 2008	Paris, FRANCE	AIS SIGeBIZ, Karlsruhe Inst Technol, Natl Sun Yat Sen Univ, Univ Illinois, Ctr IT & eBusiness Manage, IESEG Sch Manage	Univ Karlsruhe, Inst Informat Syst & Manage	Document-category management; Concept-based text categorization; Ontology; k-nearest neighbors		Huge volumes of worldwide accessible information have led to the tool necessity for better handling of massive information to overcome the conventional manual method. Thus, automated text categorization technique serves to Support a more effective document organization management. Fundamentally. conventional text categorization techniques concentrate on the analysis of document contents and and measure the similarity based on the overlap among the features Of unlabeled documents and that of pre-classified documents. However, Such feature-based approach will be confront with the problems of word mismatch and word ambiguity. To lessen these problems, this study proposes an ontology-based text categorization technique. It employs the specific domain ontology to enable documents to be classified in accordance to their range of relevant concepts. The effectiveness of the proposed technique is measured and compared with its benchmark technique. The evaluation results Suggest Our proposed technique is more effective than the benchmarks.	[Chu, Tsai-Hsin] Natl Chiayi Univ, Dept E Learning Design & Management, Chiayi, Taiwan		yhlee@mail.ncyu.edu.tw; s0951317@mail.ncyu.edu.tw; thchu@mail.ncyu.edu.tw					Berry MW, 1995, SIAM REV, V37, P573, DOI 10.1137/1037127; Breiman L, 1984, CLASSIFICATION REGRE; BRILL E, 1992, THIRD CONFERENCE ON APPLIED NATURAL LANGUAGE PROCESSING, P152; BRILL E, 1994, 12 INT C ART INT, P722; Cardoso-Cachopo A, 2003, LECT NOTES COMPUT SC, V2857, P183; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; CLARK P, 1991, 5TH P EUR WORK SESS, P151; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Dumais S, 1998, 7 INT C INF KNOWL MA, P148; Fensel D., 2000, ONTOLOGIES SILVER BU; GRUBER TR, 1993, KNOWL ACQUIS, V5, P199, DOI 10.1006/knac.1993.1008; Heckerman D, 1997, DATA MIN KNOWL DISC, V1, P79, DOI 10.1023/A:1009730122752; Hotho A., 2001, IJCAI 2001 WORKSH TE; Ikonomakis M., 2005, WSEAS Transactions on Computers, V4; Kass G., 1980, APPL STATIST, V29, P119, DOI DOI 10.2307/2986296; Keet C. M. M., 2004, ASPECTS ONTOLOGY INT; Kohler J, 2003, BIOINFORMATICS, V19, P2420, DOI 10.1093/bioinformatics/btg340; Kohler J, 2006, KNOWL-BASED SYST, V19, P744, DOI 10.1016/j.knosys.2006.04.015; LEE YH, 2007, 7 PAC AS C INF SYST; Lewis D., 1994, 3 ANN S DOC AN INF R, P81; MAEDCHE A, 2000, 12 INT C SOFTW KNOWL; Maedche A. D., 2002, ONTOLOGY LEARNING SE; Mccallum A., 1998, AAAI 1998 WORKSH LEA; MORIN E, 1999, 5 INT C TERM KNOWL E; Moulinier I, 1997, LAFORIALIP6 U PAR 6; PEREZ AG, 1999, IJCAI 1999 WORKSH ON; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1986, MACH LEARN, V1, P106; Roussinov DG, 1999, DECIS SUPPORT SYST, V27, P67, DOI 10.1016/S0167-9236(99)00037-8; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Sebastiani F., 2002, ACM COMPUT SURV, V34, P47; SURYANTO H, 2000, WORKSH ONT LEARN BER; SZPAKOWICZ S, 1990, INT J MAN MACHINE ST; VOUTILAINEN A, 1993, WVLC, P48; WACHE H, 2001, 17 INT JOINT C ART I, P108; WEI C, 2002, HDB KNOWLEDGE MANAGE; YAMAGUCHI T, 2001, 2 WORKSH ONT LEARN S; Yang Y., 1997, ICML 97, P412; Yang Y. M., 1999, INFORM RETRIEVAL, V1, P69, DOI 10.1023/A:1009982220290; ZELIKOVITZ S, 2001, 10 ACM INT C INF KNO; *DELPH GROUP, 2002, TAX CONT CLASS MARK	43	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1865-1348	978-3-642-01255-6	LECT NOTES BUS INF			2009	22						201	213				13	Business; Computer Science, Hardware & Architecture; Computer Science, Information Systems	Business & Economics; Computer Science	BKK39	WOS:000268378000017	
B	Zhang, CZ; Xu, HJ				Zhang, Chengzhi; Xu, Hongjiao			Using Citation-KNN for Automatic Keyword Assignment	ECBI: 2009 INTERNATIONAL CONFERENCE ON ELECTRONIC COMMERCE AND BUSINESS INTELLIGENCE, PROCEEDINGS			English	Proceedings Paper	International Conference on Electronic Commerce and Business Intelligence	JUN 06-07, 2009	Beijing, PEOPLES R CHINA	Soc Management Sci China, Acad Comm		Keyword Extraction; Keyword Assignment; mplicit Keyword Extraction; Citation-KNN		Currently, the automatic keywords extraction method can only extract keywords appeared in the articles and it cannot extract the implicit keyword which does not appear in the articles. It is a difficult work to extract implicit keywords in an article in the task of automatic keywords extraction. This work can also be called automatic keyword assignment. In this paper, an automatic keyword assignment method based on Citation-KNN (Citation-K Nearest Neighborhood) is proposed. Experimental results show that the proposed method can not only improve the precision and recall of keyword extraction, but also extract implicit keyword which does not appear in the articles efficiently.	[Zhang, Chengzhi] Nanjing Univ Sci & Technol, Dept Informat Management, Nanjing, Peoples R China		zhangchz@istic.ac.cn; xuhongjiao_1111@163.com					ANJEWIERDEN A, 2001, P 13 BELG NETH C ART, P23; BAETZYATES R, 1999, MODEM INFORM RETRIEV, P27; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EDMUNDSO.HP, 1969, J ACM, V16, P264, DOI 10.1145/321510.321519; Edmundson H.P., 1959, R126 PRC, P1; Ercan G, 2007, INFORM PROCESS MANAG, V43, P1705, DOI 10.1016/j.ipm.2007.01.015; Hulth A, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P216; Li Su-Jian, 2004, Chinese Journal of Computers, V27; LOIS LE, 1970, INFORM STORAGE RETRI, V6, P313; LUHN HP, 1958, IBM J RES DEV, V2, P159; LUHN HP, 1957, IBM J RES DEV, V1, P309; Nevill-Manning C., 1999, P 16 INT JOINT C ART, P668; RAUBER A, 1999, P 4 ACM C DIG LIB DL, P240, DOI 10.1145/313238.313412; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; TAN P, 2006, INTRO DATA MINING, P225; Tomokiyo T., 2003, P ACL WORKSH MULT EX, P33, DOI 10.3115/1119282.1119287; Turney P. D., 2000, Information Retrieval, V2, DOI 10.1023/A:1009976227802; Turney P.D, 1997, ERB1051 I INF TECHN; Turney P.D., 1999, ERB1057 NRC, P1; Wang J., 2000, P 17 INT C MACH LEAR, P1119; Yang Y.M, 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; ZHANG CZ, 2008, RECENT ADV CHINESE C, V3, P260	22	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		978-0-7695-3661-3				2009							131	134		10.1109/ECBI.2009.25		4	Business; Computer Science, Information Systems; Economics; Management	Business & Economics; Computer Science	BMJ48	WOS:000272586700031	
J	Nanni, L; Lumini, A				Nanni, Loris; Lumini, Alessandra			Genetic nearest feature plane	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Nearest feature plane classifier; Clustering; Genetic algorithm	CLEAVAGE SITE PREDICTION; FACE RECOGNITION; PATTERN-CLASSIFICATION; NEIGHBOR CLASSIFIER; SELECTION; SYSTEM	The problem addressed in this paper concerns the complexity reduction of the nearest feature plane classifier, so that it may be applied also in dataset where the training set contains many patterns. This classifier considers, to classify a test pattern, the subspaces created by each combination of three training patterns. The main problem is that in dataset of high cardinality this method is unfeasible. A genetic algorithm is here used for dividing the training patterns in several clusters which centroids are used to build the feature planes used to classify the test set. The performance improvement with respect to other nearest neighbor based classifiers is validated through experiments with several benchmark datasets. (C) 2007 Elsevier Ltd. All rights reserved.	[Nanni, Loris; Lumini, Alessandra] Univ Bologna, DEIS, I-40126 Bologna, Italy	Nanni, L (reprint author), Univ Bologna, DEIS, Viale Risorgimento 2, I-40126 Bologna, Italy.	lnanni@deis.unibo.it	Lumini, Alessandra/B-6100-2013	Lumini, Alessandra/0000-0003-0290-7354	European Commission [IST-2002-507634]	This work has been supported by European Commission IST-2002-507634 Biosecure NoE projects. The authors would like to thank T. Rognvaldsson for sharing the HIV dataset; M. Moradi for providing the chromosome images and the features used in this study.	Bezdek J., 1981, PATTERN RECOGNITION; Cano JR, 2003, IEEE T EVOLUT COMPUT, V7, P561, DOI 10.1109/TEVC.2003.819265; CAPPELLI R, 2002, P WORKSH BIOM AUTH E, P133; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; Connie T, 2005, IMAGE VISION COMPUT, V23, P501, DOI 10.1016/j.imavis.2005.01.002; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Demsar J, 2006, J MACH LEARN RES, V7, P1; Gao QB, 2007, PATTERN RECOGN, V40, P346, DOI 10.1016/j.patcog.2006.06.033; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Kohonen T, 2001, SELF ORG MAPS; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Lumini A, 2006, PATTERN RECOGN LETT, V27, P1390, DOI 10.1016/j.patrec.2006.01.013; Lumini A, 2006, PATTERN RECOGN, V39, P495, DOI 10.1016/j.patcog.2005.11.004; Moradi M, 2006, PATTERN RECOGN LETT, V27, P19, DOI 10.1016/j.patrec.2005.06.011; Nanni L, 2006, NEUROCOMPUTING, V69, P1739, DOI 10.1016/j.neucom.2006.01.005; Nanni L, 2006, PATTERN RECOGN, V39, P711, DOI 10.1016/j.patcog.2005.11.002; Nanni L, 2007, PATTERN RECOGN LETT, V28, P487, DOI 10.1016/j.patrec.2006.09.002; OROZCOALZATE M, 2006, SOURCE MACHINE VISIO, V17, P279; PARADES R, 2006, PATTERN RECOGN, V39, P180; Pekalska E, 2006, PATTERN RECOGN, V39, P189, DOI 10.1016/j.patcog.2005.06.012; Rognvaldsson T, 2004, BIOINFORMATICS, V20, P1702, DOI 10.1093/bioinformatics/bth144; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004; Zhou YL, 2004, LECT NOTES COMPUT SC, V3175, P204	24	1	1	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	JAN	2009	36	1					838	843		10.1016/j.eswa.2007.10.009		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	418XI	WOS:000264182800082	
B	Fu, XX; Wei, H		Luo, Q; Gong, MM		Fu, Xixu; Wei, Hui			On Hierarchical Knowledge Acquisition and Application	FIRST IITA INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, PROCEEDINGS			English	Proceedings Paper	1st IITA International Joint Conference on Artificial Intelligence	APR 25-MAY 26, 2009	Hainan Isl, PEOPLES R CHINA	IITA, Engn Technol Press, IEEE SMC TC Educ Technol & Training, Intelligent Informat Technol Applicat Res Assoc, Wuhan Inst Technol, Huazhong Normal Univ		knowledge acquisition; knowledge representation; class hierarchy; ontology		Classification is a famous branch of machine learning. We have tried many ways to invent and improve algorithms to get better results from given data. However, few have been done on how to revise data to adapt machine learning. In this paper, the same classifiers are implemented on same object sets which are different in the granularity of classification to show different classification can make great difference in the quality of classification first. Then the development of knowledge-base is studied. At last, a progressive knowledge acquisition method is advanced inspired by human's cognition behavior.	[Fu, Xixu; Wei, Hui] Fudan Univ, Dept Comp Sci, Shanghai 200433, Peoples R China	Fu, XX (reprint author), Fudan Univ, Dept Comp Sci, Shanghai 200433, Peoples R China.	xxfu@shou.edu.cn; weihui@fudan.edu.cn					CALVANESEL D, 2008, P KR2008; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Flavell J.H., 2001, COGNITIVE DEV; FU XX, 2007, APPL TEXT MINING RSS; HUI W, 2007, INT C MACH LEARN CYB, V1, P131; KISELYOVA NN, 2002, ENG APPL ARTIF INTEL, V13, P533; NECHES R, 1993, ARTIF INTELL, V61, P65, DOI 10.1016/0004-3702(93)90094-R; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Sowa J., 2003, KNOWLEDGE REPRESENTA	10	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		978-0-7695-3615-6				2009							185	189		10.1109/JCAI.2009.147		5	Computer Science, Artificial Intelligence	Computer Science	BLX40	WOS:000271280800048	
S	Jirina, M; Jirina, M		Abraham, A; Hassanien, AE; Snasel, V		Jirina, Marcel; Jirina, Marcel, Jr.			Classification by the Use of Decomposition of Correlation Integral	FOUNDATIONS OF COMPUTATIONAL INTELLIGENCE, VOL 5: FUNCTION APPROXIMATION AND CLASSIFICATION	Studies in Computational Intelligence		English	Article; Book Chapter							CORRELATION DIMENSION; ALGORITHM; SYSTEMS	The correlation dimension is usually used to study features of fractals and data generating processes. For estimating the value of the correlation dimension in a particular case, a polynomial approximation of correlation integral is often used and then linear regression for logarithms of variables is applied. In this Chapter, we show that the correlation integral can be decomposed into functions each related to a particular point of data space. For these functions, one can use similar polynomial approximations such as the correlation integral. The essential difference is that the value of the exponent, which Would correspond to the correlation dimension, differs in accordance to the position of the point in question. Moreover, we show that the multiplicative constant represents the probability density estimation at that point. This finding is used to construct a classifier. Tests with some data sets from the Machine Learning Repository show that this classifier can be very effective.	[Jirina, Marcel] Inst Comp Sci, Prague 18207 8, Liben, Czech Republic; [Jirina, Marcel, Jr.] Czech Tech Univ, Fac Biomed Engn, Kladno 27201, Czech Republic	Jirina, M (reprint author), Inst Comp Sci, Pod Vodarenskou Vezi 2, Prague 18207 8, Liben, Czech Republic.	jirina@fbmi.cvut.cz; jirina@fbmi.cvut.cz					Bellman R., 1961, ADAPTIVE CONTROL PRO; Camastra F, 2001, NEURAL PROCESS LETT, V14, P27, DOI 10.1023/A:1011326007550; Camastra F, 2003, PATTERN RECOGN, V36, P2945, DOI 10.1016/S0031-3203(03)00176-6; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI; DVORAK I, 1990, PHYS LETT A, V145, P225, DOI 10.1016/0375-9601(90)90355-R; FRIEDMANN JH, 1994, FLEXIBLE METRIC NEAR; Gama J, 2003, THEOR COMPUT SCI, V292, P417, DOI 10.1016/S0304-3975(02)00179-2; GRASSBERGER P, 1983, PHYSICA D, V9, P189, DOI 10.1016/0167-2789(83)90298-1; Guerrero A, 2003, PHYS LETT A, V318, P373, DOI 10.1016/j.physleta.2003.09.023; Leamer E, 1978, SPECIFICATION SEARCH; LEV N, 2006, HAUSDORFF DIMENSION; Merz C., 1997, UCI REPOSITORY MACHI; OSBORNE AR, 1989, PHYSICA D, V35, P357, DOI 10.1016/0167-2789(89)90075-4; Paredes R, 2006, IEEE T PATTERN ANAL, V28, P1100, DOI 10.1109/TPAMI.2006.145; Pestov V, 2000, INFORM PROCESS LETT, V73, P47, DOI 10.1016/S0020-0190(99)00156-8; Takens F., 1985, DYNAMICAL SYSTEMS BI, V1125, P99, DOI 10.1007/BFb0075637; WEISSTEIN EW, 2007, INFORM DIMENSION; *WIK, G MARK THEOR; *WIK, LIN REGR	20	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1860-949X	978-3-642-01535-9	STUD COMPUT INTELL			2009	205						39	55			10.1007/978-3-642-01536-6	17	Computer Science, Artificial Intelligence	Computer Science	BKG34	WOS:000268010900002	
S	Zhou, HY; Schaefer, G		Hassanien, AE; Abraham, A; Herrera, F		Zhou, Huiyu; Schaefer, Gerald			An Overview of Dizzy C-Means Based Image Clustering Algorithms	FOUNDATIONS OF COMPUTATIONAL INTELLIGENCE VOLUME 2: APPROXIMATE REASONING	Studies in Computational Intelligence		English	Article; Book Chapter							FUZZY DATA; SEGMENTATION; INFORMATION; PARTITION; DISTANCE; MODELS; SHIFT	Clustering is an important step in many imaging applications with a variety of image clustering techniques having been introduced in the literature. In this chapter we provide an overview of several fuzzy c-means based image clustering concepts and their applications. In particular, we summarise the conventional fuzzy c-means (FCM) approaches as well as a number of its derivatives that aim at either speeding up the clustering process or at providing improved or more robust clustering performance.	[Zhou, Huiyu] Brunel Univ, Sch Engn & Design, Uxbridge UB8 3PH, Middx, England; [Schaefer, Gerald] Univ Loughborough, Dept Comp Sci, Loughborough, Leics, England	Zhou, HY (reprint author), Brunel Univ, Sch Engn & Design, Uxbridge UB8 3PH, Middx, England.	Huiyu.Zhou@brunel.ac.uk; Gerald.Schaefer@ieee.org					Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338; Auephanwiriyakul S, 2002, IEEE T FUZZY SYST, V10, P563, DOI 10.1109/TFUZZ.2002.803492; BEZDEK JC, 1980, IEEE T PATTERN ANAL, V2, P1; Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011; Chen SC, 2004, IEEE T SYST MAN CY B, V34, P1907, DOI 10.1109/TSMCB.2004.831165; Cheng HD, 1998, PATTERN RECOGN, V31, P857, DOI 10.1016/S0031-3203(97)00113-1; Cheng TW, 1998, FUZZY SET SYST, V93, P49, DOI 10.1016/S0165-0114(96)00232-1; Chuang KS, 2006, COMPUT MED IMAG GRAP, V30, P9, DOI 10.1016/j.compmedimag.2005.10.001; COMANICIU D, 1999, 7 INT C COMP VIS KER, P1197; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Coppi R, 2003, COMPUT STAT DATA AN, V43, P149; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dave RN, 1997, IEEE T FUZZY SYST, V5, P270, DOI 10.1109/91.580801; Eschrich S, 2003, IEEE T FUZZY SYST, V11, P262, DOI 10.1109/TFUZZ.2003.809902; Fan JL, 2003, PATTERN RECOGN LETT, V24, P1607, DOI 10.1016/S0167-8655(02)00401-4; Frieden B. R., 1999, PHYS FISHER INFORM U; GOWDA KC, 1991, PATTERN RECOGN, V24, P567; Hathaway RJ, 2000, IEEE T FUZZY SYST, V8, P576, DOI 10.1109/91.873580; HATHAWAY RJ, 1994, PATTERN RECOGN, V27, P429, DOI 10.1016/0031-3203(94)90119-8; HU R, 2002, NEURAL PARALLEL SCI, V10, P141; Hung WL, 2004, PATTERN RECOGN LETT, V25, P1603, DOI 10.1016/j.patrec.2004.06.006; KERSTEN PR, 1997, IEEE C FUZZ SYST, P957; Kolen JF, 2002, IEEE T FUZZY SYST, V10, P263, DOI 10.1109/91.995126; Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, DOI 10.1109/91.227387; Leski J, 2003, FUZZY SET SYST, V137, P215, DOI 10.1016/S0165-0114(02)00372-X; Menard M, 2003, PATTERN RECOGN, V36, P1325, DOI 10.1016/S0031-3203(02)00049-3; MIYAMOTA S, 1995, CONTROL CYBERN, V25, P421; Pedrycz W, 1998, IEEE T FUZZY SYST, V6, P411, DOI 10.1109/91.705509; SATO M, 1995, IEEE INT C FUZZ SYST, P2123; SZILAGYI L, 2003, 25 IEEE INT C ENG ME, V1, P724; TAKATA O, 1998, 2 IEEE INT C INT PRO, P67; Takata O, 2001, JOINT 9TH IFSA WORLD CONGRESS AND 20TH NAFIPS INTERNATIONAL CONFERENCE, PROCEEDINGS, VOLS. 1-5, P2511; WANG J, 2004, 8 EUR C COMP VIS, P238; Wei Li-Mei, 2000, Acta Electronica Sinica, V28; Yang MS, 2004, FUZZY SET SYST, V141, P301, DOI 10.1016/S0165-0114(03)00072-1; Yang MS, 1996, FUZZY SET SYST, V84, P49, DOI 10.1016/0165-0114(95)00308-8; Yang MS, 1999, FUZZY SET SYST, V106, P189, DOI 10.1016/S0165-0114(97)00277-7; Yong Y., 2004, MEASUREMENT SCI REV, V4, P11; Zhao MS, 2001, IEEE T FUZZY SYST, V9, P469, DOI 10.1109/91.928743; ZHOU H, 2008, 30 IEEE INT C ENG ME, P3091; Zhou HY, 2009, IEEE J-STSP, V3, P26, DOI 10.1109/JSTSP.2008.2010631	41	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1860-949X	978-3-642-01532-8	STUD COMPUT INTELL			2009	202						295	310			10.1007/978-3-642-01533-5	16	Computer Science, Artificial Intelligence; Engineering, Multidisciplinary	Computer Science; Engineering	BJV69	WOS:000267274900012	
S	Schumacher, T; Plessl, C; Platzner, M		Danek, M; Kadlec, J		Schumacher, Tobias; Plessl, Christian; Platzner, Marco			AN ACCELERATOR FOR K-TH NEAREST NEIGHBOR THINNING BASED ON THE IMORC INFRASTRUCTURE	FPL: 2009 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE LOGIC AND APPLICATIONS	International Conference on Field Programmable Logic and Applications		English	Proceedings Paper	International Conference on Field Programmable Logic and Applications	AUG 31-SEP 02, 2009	Prague, CZECH REPUBLIC	UTIA, AV, CR	ASCR, Informat Theory & Automat		FRAMEWORK	The creation and optimization of FPGA accelerators comprising several compute cores and memories are challenging tasks in high performance reconfigurable computing. In this paper, we present the design of such an accelerator for the k-th nearest neighbor thinning problem on an XD1000 reconfigurable computing system. The design leverages IMORC, an architectural template and highly versatile on-chip interconnect, to achieve speedups of 74 x over a 2.2GHz Opteron. Using IMORC with its asynchronous FIFOs and bitwidth conversion in the links between the cores, we are able to quickly create acclerator versions with varying degrees of core-level parallelism and memory mappings. Through the performance monitoring infrastructure of IMORC we gain insight into the data-dependent behavior of the accelerator which facilitates further performance optimizations.	[Schumacher, Tobias; Plessl, Christian; Platzner, Marco] Univ Gesamthsch Paderborn, D-4790 Paderborn, Germany	Schumacher, T (reprint author), Univ Gesamthsch Paderborn, Warburger Str 100, D-4790 Paderborn, Germany.	tobe@uni-paderborn.de; christian.plessl@uni-paderborn.de; platzner@uni-paderborn.de					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HOLLAND B, 2007, P HIGH PERF REC COMP; Koehler S, 2008, PARALLEL COMPUT, V34, P217, DOI 10.1016/j.parco.2008.01.008; Schumacher Tobias, 2008, Proceedings of the 2008 International Conference on Engineering of Reconfigurable Systems & Algorithms (ERSA 2008); SCHUMACHER T, 2009, P IEEE S FIELD PROGR; Shannon L., 2005, Proceedings. 13th Annual IEEE Symposium on Field-Programmable Custom Computing Machines; Shannon L, 2007, IEEE T VLSI SYST, V15, P377, DOI 10.1109/TVLSI.2007.893645; Slogsnat D, 2007, FPGA 2007: FIFTEENTH ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45; SMITH M, 2002, P INT S PERF EV COMP; STEFFEN C. P., 2007, P REC SYST SUMM I RS, P17; XtremeData Inc., 2008, XD1000 DEV SYST	11	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1946-1488	978-1-4244-3891-4	INT CON FIELD PROG			2009							338	344				7	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	BOT08	WOS:000277506300052	
J	Halder, A; Ghosh, A; Ghosh, S				Halder, Anindya; Ghosh, Ashish; Ghosh, Susmita			Aggregation Pheromone Density Based Pattern Classification	FUNDAMENTA INFORMATICAE			English	Article						Swarm intelligence; Ant colony optimization; Aggregation pheromone; Pattern classification	ANT COLONY OPTIMIZATION; RECOGNITION	The study of ant colonies behavior and their self-organizing capabilities is of interest to machine learning community, because it provides models of distributed adaptive organization which are useful to solve difficult optimization and classification problems among others. Social insects like ants, bees deposit pheromone (a type of chemical) in order to communicate between the members of their community. Pheromone, that causes clumping behavior in a species and brings individuals into a closer proximity, is called aggregation pheromone. This article presents a new algorithm (called, APC) for pattern classification based on this property of aggregation pheromone found in natural behavior of real ants. Here each data pattern is considered as an ant, and the training patterns (ants) form several groups or colonies depending on the number of classes present in the data set. A new test pattern (ant) will move along the direction where average aggregation pheromone density (at the location of the new ant) formed due to each colony of ants is higher and hence eventually it will join that colony. Thus each individual test pattern (ant) will finally join a particular colony. The proposed algorithm is evaluated with a number of benchmark data sets as well as various kinds of artificially generated data sets using three evaluation measures. Results are compared with four other well known conventional classification techniques. Experimental results show the potentiality of the proposed algorithm in terms of all the evaluation measures compared to other algorithms.	[Halder, Anindya; Ghosh, Ashish] Indian Stat Inst, Ctr Soft Comp Res, Calcutta 700108, India; [Ghosh, Ashish] Indian Stat Inst, Machine Intelligence Unit, Calcutta 700108, India; [Ghosh, Susmita] Dept Comp Sci Engn, Calcutta 700032, India; [Ghosh, Susmita] Jadavpur Univ, Calcutta 700032, India	Halder, A (reprint author), Indian Stat Inst, Ctr Soft Comp Res, Calcutta 700108, India.	anindya_t@isical.ac.in; ash@isical.ac.in			Department of Science and Technology, Govt. of India	Support of the Department of Science and Technology, Govt. of India to the Center for Soft Computing Research is thankfully acknowledged by Mr. Anindya Halder, Research Scholar of the Center, Indian Statistical Institute, Kolkata.	Bell W.J., 1984, P93; Chen L, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P1387; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dorigo M, 1996, IEEE T SYST MAN CY B, V26, P29, DOI 10.1109/3477.484436; Dorigo M., 2004, ANT COL OPT; Dorigo M., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585892; Duda R.O., 2000, PATTERN CLASSIFICATI; Englebrecht A.P., 2002, COMPUTATIONAL INTELL; Ghosh A, 2008, INFORM SCIENCES, V178, P2816, DOI 10.1016/j.ins.2008.02.015; GHOSH A, 2009, PATTERN REC IN PRESS; Ghosh S, 2006, LECT NOTES COMPUT SC, V4338, P118; Hand D. J., 1981, DISCRIMINATION CLASS; Handl J., 2007, SWARM INTELLIGENCE, V1, P95, DOI 10.1007/s11721-007-0008-7; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Kennedy J., 2001, SWARM INTELLIGENCE; Kothari M, 2007, Proceedings of the Sixth International Conference on Advances in Pattern Recognition, P193; KOTHARI M, 2006, P 9 INT C INF TECHN, P259; Kulkarni SR, 1998, IEEE T INFORM THEORY, V44, P2178, DOI 10.1109/18.720536; Kuncheva L., 2000, FUZZY CLASSIFIER DES; Liu B, 2003, P IEEE WIC INT C INT, P83; LIU B, 1920, P 6 AUSTR JAP JOINT, P180; Martens D, 2007, IEEE T EVOLUT COMPUT, V11, P651, DOI 10.1109/TEVC.2006.890229; Newman D. J., 1998, UCI REPOSITORY MACHI; ONO M, 1995, NATURE, V377, P334, DOI 10.1038/377334a0; PAL SK, 1977, IEEE T SYST MAN CYB, V7, P625; PAL SK, 1994, INFORM SCIENCES, V76, P297, DOI 10.1016/0020-0255(94)90014-0; Parpinelli RS, 2002, IEEE T EVOLUT COMPUT, V6, P321, DOI 10.1109/TEVC.2002.802452; PLATT JC, 1999, ADV NEURAL INFORM PR; Ripley B, 1995, PATTERN RECOGNITION; SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458; Salton G, 1983, INTRO MODERN INFORM; Scholkopf B, 2002, LEARNING KERNELS SUP; SOCHA K, EUROPEAN J OPERATION; SUKAMA M, 1993, J CHEM ECOL, V19, P2521; Tsutsui S., 2004, P 5 AS PAC C SIM EV; Tsutsui S., 2004, P 5 INT C REC ADV SO, P207; Wang XN, 2005, Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9, P5355; *WEK MACH LEARN PR, WEK	38	5	5	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0169-2968		FUND INFORM	Fundam. Inform.		2009	92	4					345	362		10.3233/FI-2009-78		18	Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	469LU	WOS:000267901400002	
J	Saha, S; Bandyopadhyay, S				Saha, Sriparna; Bandyopadhyay, Sanghamitra			Some Symmetry Based Classifiers	FUNDAMENTA INFORMATICAE			English	Article						Pattern Classification; Point Symmetry; Kd-tree; Symmetry based distance; Nearest Neighbor Rule; Line Symmetry	CLASSIFICATION; ALGORITHMS	In this paper, a novel point symmetry based pattern classifier (PSC) is proposed. A recently developed point symmetry based distance is utilized to determine the amount of point symmetry of a particular test pattern with respect to a class prototype. Kd-tree based nearest neighbor search is used for reducing the complexity of point symmetry distance computation. The proposed point symmetry based classifier is well-suited for classifying data sets having point symmetric classes, irrespective of any convexity, overlap or size. In order to classify data sets having line symmetry property, a line symmetry based classifier (LSC) along the lines of PSC is thereafter proposed in this paper. To measure the total amount of line symmetry of a particular point in a class, a new definition of line symmetry based distance is also provided. Proposed LSC preserves the advantages of PSC. The performance of PSC and LSC are demonstrated in classifying fourteen artificial and real-life data sets of varying complexities. For the purpose of comparison, k-NN classifier and the well-known support vector machine (SVM) based classifiers are executed on the data sets used here for the experiments. Statistical analysis, ANOVA, is also performed to compare the performance of these classification techniques.	[Saha, Sriparna; Bandyopadhyay, Sanghamitra] Indian Stat Inst, Machine Intelligence Unit, Calcutta 700108, India	Saha, S (reprint author), Indian Stat Inst, Machine Intelligence Unit, Calcutta 700108, India.	sriparna_r@isical.ac.in; sanghami@isical.ac.in	Bandyopadhyay, Sanghamitra/A-6597-2010				ANDERBERG MR, 2000, COMPUTATIONAL GEOMET; Anderson T.W., 1978, INTRO STAT ANAL DATA; Asuncion A., 2007, UCI MACHINE LEARNING; ATTNEAVE F, 1955, Am J Psychol, V68, P209, DOI 10.2307/1418892; Bandyopadhyay S, 2002, PATTERN RECOGN, V35, P2791, DOI 10.1016/S0031-3203(01)00234-5; Bandyopadhyay S, 2007, PATTERN RECOGN, V40, P3430, DOI 10.1016/j.patcog.2007.03.026; BENTLEY JL, 1980, ACM T MATH SOFTWARE, V6, P563, DOI 10.1145/355921.355927; Chou C.H., 2002, 2 WSEAS INT C SCI CO, P209; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crammer K., 2001, ALGORITHMIC IMPLEMEN; Cristianini N, 2000, INTRO SUPPORT VECTOR; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fix E., 1951, 4 USAF SCH AV MED; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; Gonzalez R., 1992, DIGITAL IMAGE PROCES; JOACHIMS T, 2007, SV MMULTICLASS MULTI; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; LIU CL, 1999, ICDAR 99 P 5 INT C D; Mount D., 2005, ANN LIB APPROXIMATE; Pal SK, 1998, IEEE T SYST MAN CY B, V28, P816, DOI 10.1109/3477.735391; PAL SK, 1977, IEEE T SYST MAN CYB, V7, P625; Su MS, 2001, IEEE T PATTERN ANAL, V23, P674	22	0	0	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0169-2968		FUND INFORM	Fundam. Inform.		2009	90	1-2					107	123		10.3233/FI-2009-0009		17	Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	417SB	WOS:000264096600009	
S	Derrac, J; Garcia, S; Herrera, F		Corchado, E; Wu, X; Oja, E; Herrero, A; Baruque, B		Derrac, Joaquin; Garcia, Salvador; Herrera, Francisco			A First Study on the Use of Coevolutionary Algorithms for Instance and Feature Selection	HYBRID ARTIFICIAL INTELLIGENCE SYSTEMS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	4th International Workshop on Hybrid Artificial Intelligence Systems	JUN 10-12, 2009	Salamanca, SPAIN					Cooperative Coevolution is a technique in the area of Evolutionary Computation. it has been applied to many combinatorial problems with great success. This contribution proposes a Cooperative Coevolution model for simultaneous performing some data, reduction processes in classification with nearest, neighbours methods through feature, and instance selection. In order to check its performance, we have compared the proposal with other evolutionary approaches for performing data reduction. Results have been analyzed and contrasted by using non-parametric statistical tests, finally showing that the proposed model outperforms the noncooperative evolutionary techniques.	[Derrac, Joaquin; Herrera, Francisco] Univ Granada, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain	Derrac, J (reprint author), Univ Granada, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain.	jderrac@correo.ugr.es; herrera@decsai.ugr.es; sglopez@ujaen.es	Herrera, Francisco/C-6856-2008	Herrera, Francisco/0000-0002-7283-312X			AU C, 2007, IEEE INT C TOOLS ART, P407; Baluja S., 1994, POPULATION BASED INC; Cano JR, 2003, IEEE T EVOLUT COMPUT, V7, P561, DOI 10.1109/TEVC.2003.819265; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Demsar J, 2006, J MACH LEARN RES, V7, P1; Eiben A. E., 2003, INTRO EVOLUTIONARY C; Eshelman L.J., 1990, FDN GENETIC ALGORITH, P265; FRAGOUDIS D, 2002, 8 ACM SIGKDD INT C K, P501; Freitas A.A., 2002, DATA MINING KNOWLEDG; Ghosh A, 2005, EVOLUTIONARY COMPUTA; Goldberg D. E, 1989, GENETIC ALGORITHMS S; Jansen T, 2004, EVOL COMPUT, V12, P405, DOI 10.1162/1063656043138905; Liu H, 2001, SPRINGER INT SERIES; Liu H, 2008, CH CRC DATA MIN KNOW, P3; NEWMAN DJ, 1998, UCI REPOSITORY ML DA; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; PANAIT L, 2003, INT JOINT C ART INT, P653; Panait L, 2006, GECCO 2006: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2, P345; Potter MA, 2000, EVOL COMPUT, V8, P1, DOI 10.1162/106365600568086; Pyle D, 1999, DATA PREPARATION DAT; White S. D., 1989, Veterinary Dermatology, V1, P1; Wolpert DH, 2005, IEEE T EVOLUT COMPUT, V9, P721, DOI 10.1109/TEVC.2005.856205	22	25	25	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-02318-7	LECT NOTES ARTIF INT			2009	5572						557	564				8	Computer Science, Artificial Intelligence	Computer Science	BKC98	WOS:000267794600067	
S	Parvin, H; Alizadeh, H; Minaei-Bidgoli, B		Ao, SL		Parvin, Hamid; Alizadeh, Hosein; Minaei-Bidgoli, Behrouz			Validation Based Modified K-Nearest Neighbor	IAENG TRANSACTIONS ON ENGINEERING TECHNOLOGIES, VOL II	AIP Conference Proceedings		English	Proceedings Paper	International Conference on Advances in Engineering Technologies held at the World Congress on Engineering and Computer Sciences	OCT 22-24, 2008	San Francisco, CA	Int Assoc Engn		MKNN; KNN Classification; Modified K-Nearest Neighbor; Weighted K-Nearest Neighbor; Neighbor Validation	CLASSIFICATION	In this paper, a new classification method for enhancing the performance of K-Nearest Neighbor is proposed which uses robust neighbors in training data. The robust neighbors are detected using a validation process. This method is more robust than traditional equivalent methods. This new classification method is called Modified K-Nearest Neighbor. Inspired the traditional KNN algorithm, the main idea is classifying the test samples according to their neighbor tags. This method is a kind of weighted KNN so that these weights are determined using a different procedure. The procedure computes the fraction of the same labeled neighbors to the total number of neighbors. The proposed method is evaluated on a variety of several standard UCI data sets. Experiments show the excellent improvement in accuracy in comparison with KNN method.	[Parvin, Hamid; Alizadeh, Hosein; Minaei-Bidgoli, Behrouz] Iran Univ Sci & Technol, Dept Comp Engn, Tehran, Iran	Parvin, H (reprint author), Iran Univ Sci & Technol, Dept Comp Engn, POB 16765-163, Tehran, Iran.						AEBERHARD S, 9202 J COOK U N QUEE; ALIZADEH H, 2009, 11 C INT FED CLASS S; ALIZAEDH H, 2008, P INT C CONV HYBR IN; BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; Bermejo S, 2000, PATTERN RECOGN, V33, P1999, DOI 10.1016/S0031-3203(99)00186-7; Blake C. L., 1998, UCI RESPOSITORY MACH; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DARASAY BV, NEAREST NEIGHBOR PAT; Duda R.O., 2000, PATTERN CLASSIFICATI; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Fix E., 1951, 4 USAF SCH AV MED; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; Gose E, 1996, PATTERN RECOGNITION; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; ITQON K, 2001, SPRINGER T I ELECT I; Jozwik A., 1983, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(83)90064-8; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KUNCHEVA L, 2005, COMBINING PATTERN CL; PARVIN H, 2009, INT J DIGIT IN PRESS; PARVIN H, 2008, P INT C CONV HYBR IN; PARVIN H, 2008, P INT C NETW COMP AD; ROUSSEAUW, 1983, S AFRICAN MED J	22	0	0	AMER INST PHYSICS	MELVILLE	2 HUNTINGTON QUADRANGLE, STE 1NO1, MELVILLE, NY 11747-4501 USA	0094-243X	978-0-7354-0663-6	AIP CONF PROC			2009	1127						153	161				9	Engineering, Multidisciplinary	Engineering	BKK66	WOS:000268391900015	
B	Xiong, W; Ong, SH; Le, TT; Lim, JH; Liu, J; Foong, K			IEEE	Xiong, Wei; Ong, S. H.; Le, T. T.; Lim, Joo Hwee; Liu, Jiang; Foong, Kelvin			Combining a Global SVM and Local Nearest-Neighbor Classifiers Driven by Local Discriminative Boundaries	ICIEA: 2009 4TH IEEE CONFERENCE ON INDUSTRIAL ELECTRONICS AND APPLICATIONS, VOLS 1-6			English	Proceedings Paper	4th IEEE Conference on Industrial Electronics and Applications	MAY 25-27, 2009	Xian, PEOPLES R CHINA	IEEE, Ind Elect Chapter Singapore, NW Polytechn Univ, IEEE Xian Sect, IEEE Control Syst Soc, IEEE Ind Elect Soc, Natl Nat Sci Fdn China, Inst Engn & Technol, Shaanxi Key Lab Informat Acquist & Proc		Support vector machines; nearest neighbors; local; combination; adaptive metric; boundary driven	CLASSIFICATION	Nonlinear support vector machines (SVMs) rely on the kernel trick and tradeoff parameters to build nonlinear models to classify complex problems and balance misclassification and generalization. The inconvenience in determining the kernel and the parameters has motivated the use of local nearest neighbor (NN) classifiers in lieu of global classifiers. This substitution ignores the advantage of SV-M in global error minimization. On the other hand, the NN rule assumes that class conditional probabilities are locally constant. Such an assumption does not hold near class boundaries and in any high dimensional space due to the curse of dimensionality. We propose a hybrid classification method combining the global SVM and local NN classifiers. Local classifiers occur only when the global SVM is likely to fail. Furthermore, local NN classifiers adopt an adaptive metric driven by local SVM discriminative boundaries. Improved performance has been demonstrated compared to partially similar.	[Xiong, Wei; Lim, Joo Hwee; Liu, Jiang] ASTAR, Inst Infocomm Res, Singapore 138632, Singapore	Xiong, W (reprint author), ASTAR, Inst Infocomm Res, Singapore 138632, Singapore.	wxiong@i2r.a-star.edu.sg					AINARI S, 1999, NEURAL NETWORKS, V12, P783; Chang C-C., 2001, LIBSVM LIB SUPPORT V; Cheng HB, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P461; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domeniconi C, 2005, IEEE T NEURAL NETWOR, V16, P899, DOI 10.1109/TNN.2005.849821; Duda R., 1973, PATTERN CLASSIFICATI; LI R, 2001, INT C INF INF ICII; Peng J, 2003, IEEE T NEURAL NETWOR, V14, P940, DOI 10.1109/TNN.2003.813835; TIAN M, 2003, P IEEE INT TRANSP SY, V1, P373; Vapnik V.N., 1995, NATURE STAT LEARNING; ZHANG H, 2006, IEEE C COMP VIS PATT	11	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-2799-4				2009							3588	3591				4	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	BMO85	WOS:000273183201320	
B	Dehzangi, O; Younessian, E; Fard, FH		Filipe, J		Dehzangi, Omid; Younessian, Ehsan; Fard, Fariborz Hosseini			AN ADAPTIVE CLASSIFIER DESIGN FOR ACCURATE SPEECH DATA CLASSIFICATION	ICINCO 2009: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, AUTOMATION AND ROBOTICS, VOL 2: ROBOTICS AND AUTOMATION			English	Proceedings Paper	6th International Conference on Informatics in Control, Automation and Robotics	JUL 02-05, 2009	Milan, ITALY	Inst Syst & Technologies Informat, Control & Commun, IFAC, Assoc Advancement Artificial Intelligence		Nearest neighbor; Linear discriminant analysis; Adaptive distance measure; Weight learning algorithm	NEAREST-NEIGHBOR CLASSIFICATION	In this paper, an adaptive approach to designing accurate classifiers using Nearest Neighbor (NN) and Linear Discriminant Analysis (LDA) is proposed. A novel NN rule with an adaptive distance measure is proposed to classify input patterns. An iterative learning algorithm is employed to incorporate a local weight to the Euclidean distance measure that attempts to minimize the number of misclassified patterns in the training set. In case of data sets with highly overlapped classes, this may cause the classifier to increase its complexity and overfit. As a solution, LDA is considered as a popular feature extraction technique that aims at creating a feature space that best discriminates the data distributions and reduces overlaps between different classes of data. In this paper, an improved variation of LDA (im-LDA) is investigated which aims to moderate the effect of outlier classes. The proposed classifier design is evaluated by 6 standard data sets from UCI ML repository and eventually by TIMIT data set for framewise classification of speech data. The results show the effectiveness of the designed classifier using im-LDA with the proposed ad-NN method.	[Dehzangi, Omid; Younessian, Ehsan] Nanyang Technol Univ, Singapore, Singapore	Dehzangi, O (reprint author), Nanyang Technol Univ, Singapore, Singapore.	dehzangi@pmail.ntu.edu.sg; ehsa0001@ntu.edu.sg; cbfn87@motorola.com					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Duda R. O., 2001, PATTERN CLASSIFICATI; Fisher RA, 1936, ANN EUGENIC, V7, P179; Friedman J ., 1994, 113 STANF U STAT DEP; Garofolo J.S., 1988, GETTING STARTED DARP; GRAVES A, 2005, INT JOINT C NEUR NET; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; JARCHI D, 2006, T ENG COMPUTATIONAL, V18, P18; Loog M, 2001, IEEE T PATTERN ANAL, V23, P762, DOI 10.1109/34.935849; MERZ CJ, 1996, UCIREPOSITORY MACHIN; Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093; Wang JG, 2007, PATTERN RECOGN LETT, V28, P207, DOI 10.1016/j.patrec.2006.07.002	13	0	0	INSTICC-INST SYST TECHNOLOGIES INFORMATION CONTROL & COMMUNICATION	SETUBAL	AVENIDA D MANUEL L, 27A 2 ESQUERDO, SETUBAL, 2910-595, PORTUGAL		978-989-674-000-9				2009							67	71				5	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Information Systems; Robotics	Automation & Control Systems; Computer Science; Robotics	BQW84	WOS:000282034200014	
S	Goger, D; Gorges, N; Worn, H			IEEE	Goeger, Dirk; Gorges, Nicolas; Woern, Heinz			Tactile Sensing for an Anthropomorphic Robotic Hand: Hardware and Signal Processing	ICRA: 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-7	IEEE International Conference on Robotics and Automation ICRA		English	Proceedings Paper	IEEE International Conference on Robotics and Automation	MAY 12-17, 2009	Kobe, JAPAN	IEEE			EXPLORATION	In this paper, a tactile sensing system for an anthropomorphic robot hand is presented. The tactile sensing system is designed as a construction kit making it very versatile. The sensor data preprocessing is embedded into the hand's hardware structure and is fully integrated. The sensor system is able to gather tactile pressure profiles and to measure vibrations in the sensor's cover. Additionally to the introduction of the hardware, the signal processing and the classification of the acquired sensor data will be explained in detail. These algorithms make the tactile sensing system capable to detect contact points, to classify contact patterns and to detect slip conditions during object manipulation and grasping.	[Goeger, Dirk; Gorges, Nicolas; Woern, Heinz] Univ Karlsruhe TH, Inst Proc Control & Robot, Karlsruhe, Germany	Goger, D (reprint author), Univ Karlsruhe TH, Inst Proc Control & Robot, Karlsruhe, Germany.	goeger@ira.uka.de; gorges@ira.uka.de; woern@ira.uka.de					Beucher S., 1991, SCANNING MICROSCOPY, P299; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAI J, 1994, P 2 BIENN EUR JOINT; GOGER D, 2007, IEEE C SENS ATL GA U; GORGES N, 2008, INT C INF CONTR AUT; Heidemann G., 2004, P IEEE INT C ROB AUT, P813; HOLWEG E, 1996, IEEE INT C ROB AUT M; HU M, 1962, IRE T INFORM THEOR, V8, P179; JOCKUSCH J, 1997, IEEE INT C ROB AUT A; Okamura AM, 2001, INT J ROBOT RES, V20, P925, DOI 10.1177/02783640122068191; SCHMID A, 2008, IEEE INT C ROB AUT P; Schmidt PA, 2006, ROBOT AUTON SYST, V54, P1005, DOI 10.1016/j.robot.2006.05.013; Schulz A., 2004, MECHATRONICS ROBOTIC, P936; SON J, 1994, IEEE INT C ROB AUT S; TURK M, 1991, COMPUTER VISION PATT; WEISS K, 2006, 4 DTSCH ROB K MUNCH; Weiss K., 2004, IEEE RAS INT C HUM R; Worn H., 2005, P IEEE INT C MECH AU	18	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1050-4729	978-1-4244-2788-8	IEEE INT CONF ROBOT			2009							2972	2978				7	Automation & Control Systems; Robotics	Automation & Control Systems; Robotics	BOB06	WOS:000276080401166	
B	Martin, JA; de Lope, J			IEEE	Antonio Martin H, Jose; de Lope, Javier			Ex < a >: An Effective Algorithm for Continuous Actions Reinforcement Learning Problems	IECON: 2009 35TH ANNUAL CONFERENCE OF IEEE INDUSTRIAL ELECTRONICS, VOLS 1-6			English	Proceedings Paper	35th Annual Conference of the IEEE-Industrial-Electronics-Society (IECON 2009)	NOV 03-05, 2009	Porto, PORTUGAL	IEEE Ind Elect Soc				In this paper the Ex < a > Reinforcement Learning algorithm is presented. This algorithm is designed to deal with problems where the use of continuous actions have clear advantages over the use of fine grained discrete actions. This new algorithm is derived from a baseline discrete actions algorithm implemented within a kind of k-nearest neighbors approach in order to produce a probabilistic representation of the input signal to construct robust state descriptions based on a collection (knn) of receptive field units and a probability distribution vector p(knn) over the knit collection. The baseline continuous-space-discreteactions kNN-TD(lambda) algorithm introduces probability traces as the natural adaptation of eligibility traces in the probabilistic context. Later the Ex < a >(lambda) algorithm is described as an extension of the baseline algorithms. Finally experimental results are presented for two (not easy) problems such as the Cart-Pole and Helicopter Hovering.	[Antonio Martin H, Jose] Univ Complutense Madrid, E-28040 Madrid, Spain	Martin, JA (reprint author), Univ Complutense Madrid, E-28040 Madrid, Spain.		Martin H., Jose Antonio/A-2388-2009				Abbeel P., 2005, NIPS; Anderson C. W., 1987, Proceedings of the Fourth International Workshop on Machine Learning; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Gordon Geoff, 1995, ICML, P261; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237; MARTIN JA, 2009, LECT NOTES COMPUTER, V5901, P305; Martin JAH, 2007, LECT NOTES COMPUT SC, V4739, P138; Ng A. Y., 2003, NIPS; Singh SP, 1996, MACH LEARN, V22, P123, DOI 10.1023/A:1018012322525; Sutton R. S., 1998, REINFORCEMENT LEARNI; Sutton R. S., 1988, Machine Learning, V3, DOI 10.1007/BF00115009; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698	15	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-4648-3				2009							1944	1949				6	Engineering, Electrical & Electronic	Engineering	BQE04	WOS:000280762000328	
B	AlSukker, A; Al-Ani, A; Atiya, A		Dourado, A; Rosa, A; Madani, K		AlSukker, Akram; Al-Ani, Ahmed; Atiya, Amir			A MODIFIED K-NEAREST NEIGHBOR CLASSIFIER TO DEAL WITH UNBALANCED CLASSES	IJCCI 2009: PROCEEDINGS OF THE INTERNATIONAL JOINT CONFERENCE ON COMPUTATIONAL INTELLIGENCE			English	Proceedings Paper	1st International Joint Conference on Computational Intelligence	OCT 05-07, 2009	Funchal, PORTUGAL	Inst Syst & Technol Informat, Control & Commun, Int Fuzzy Syst Assoc		kNN classifier; Unbalanced classes; Class-wise classification accuracy		We present in this paper a simple, yet valuable improvement to the traditional k-Nearest Neighbor (kNN) classifier. It aims at addressing the issue of unbalanced classes by maximizing the class-wise classification accuracy. The proposed classifier also gives the option of favoring a particular class through evaluating a small set of fuzzy rules. When tested on a number of UCI datasets, the proposed algorithm managed to achieve a uniformly good performance.	[AlSukker, Akram; Al-Ani, Ahmed] Univ Technol Sydney, Fac Engn & Informat Technol, Sydney, NSW 2007, Australia	AlSukker, A (reprint author), Univ Technol Sydney, Fac Engn & Informat Technol, Sydney, NSW 2007, Australia.	alsukker@eng.uts.edu.au; ahmed@eng.uts.edu.au; amir@alumni.caltech.edu					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Duda R., 1973, PATTERN CLASSIFICATI; DUDANI SA, 1976, SMC, V6, P325; GOLDBERGER J, NIPS; KELLER JM, FUZZY K NEAREST NEIG; NEWMAN AAA, 2007, UCI MACHINE LEARNING; Paredes R, 2006, IEEE T PATTERN ANAL, V28, P1100, DOI 10.1109/TPAMI.2006.145; Tan SB, 2005, EXPERT SYST APPL, V28, P667, DOI 10.1016/j.eswa.2004.12.023; Westin LK, 2001, RECEIVER OPERATING C; YONG Z, 2009, EXPERT SYST APPL, V36, P3587; ZENG Y, EXPERT SYST IN PRESS	12	0	0	INSTICC-INST SYST TECHNOLOGIES INFORMATION CONTROL & COMMUNICATION	SETUBAL	AVENIDA D MANUEL L, 27A 2 ESQUERDO, SETUBAL, 2910-595, PORTUGAL		978-989-674-014-6				2009							408	413				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BVA72	WOS:000290915300059	
S	Martinez-Rego, D; Fontenla-Romero, O; Porto-Diaz, I; Alonso-Betanzos, A			IEEE	Martinez-Rego, David; Fontenla-Romero, Oscar; Porto-Diaz, Iago; Alonso-Betanzos, Amparo			A New Supervised Local Modelling Classifier Based On Information Theory	IJCNN: 2009 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1- 6	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	JUN 14-19, 2009	Atlanta, GA	Int Neural Network Soc, IEEE Computat Intelligence Soc				In this paper, a novel supervised architecture for binary classification based on local modelling and information theory is described. The architecture is composed of two steps: in the first one, a separating borderline between the two classes is piecewise constructed by a set of centroids calculated by a modified clustering algorithm, based on information theory; each of these centroids define a region where, in the second step of the proposed architecture, a hyperplane is constructed and adjusted by means of one-layer neural networks. This new method allows for binary classification while maintaining adequate use of computational resources, a common problem for machine learning methods. The proposed architecture is applied over classical benchmark classification problems and data sets, and its results are compared with those obtained by other well-known statistical and machine learning classifiers.	[Martinez-Rego, David; Fontenla-Romero, Oscar; Porto-Diaz, Iago; Alonso-Betanzos, Amparo] Univ A Coruna, Dept Comp Sci, La Coruna, Spain	Martinez-Rego, D (reprint author), Univ A Coruna, Dept Comp Sci, La Coruna, Spain.	dmartinez@udc.es; ofontenla@udc.es; iporto@udc.es; ciamparo@udc.es					BAUM EB, 1990, NISP 3 P 1990 C ADV, V3, P904; Bishop C. M., 1995, NEURAL NETWORKS PATT; BREIMAN L, 1996, MACHINE LEARNING J, V26; Castillo E, 2002, NEURAL COMPUT, V14, P1429, DOI 10.1162/089976602753713007; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cox DR, 1970, ANAL BINARY DATA; DIMITRAKAKIS C, 2004, 12 EUR S ART NEUR NE; DRUCKER H, 1997, P 14 INT C MACH LEAR; FAHLMAN S. E., 1990, ADV NEURAL INFORMATI, V2, P524; Fisher R., 1936, ANN EUGEN, V7, P178; FONTENLAROMERO O, 2002, LECT NOTES COMPUTER, V2415, P1429; FREUND Y, 1997, J COMPUTER SYSTEM SC, V55, P19139; Fung G., 2001, P KDD 2001 KNOWL DIS, P77, DOI 10.1145/502512.502527; Kiang MY, 2003, DECIS SUPPORT SYST, V35, P441, DOI 10.1016/S0167-9236(02)00110-0; Kuncheva L., 2004, COMBINING PATTERN CL; Lee Y.-J., 2001, P 1 SIAM INT C DAT M; Martinez-Rego D., 2008, EUR S ART NEUR NETW, P295; MERCER J, 1909, PHILOS T R SOC A, V209; MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5; PRINCIPE J, 2005, NATURAL COMPUTING, V4, P39; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1986, MACH LEARN, V1, P106; RAMAKRISHNAN R, 2000, KDD 2000 P 6 ACM SIG, P64; Shawe-Taylor J., 2000, SUPPORT VECTOR MACHI; Suykens J.A.K., 2002, LEAST SQUARES SUPPOR; Weston J, 2006, SPIDER SVM TOOLBOX; WILLIAMFLAKE G, 1998, NEURAL NETWORKS TRIC, P145; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; [Anonymous], UCI MACH LEARN REP	29	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576	978-1-4244-3549-4	IEEE IJCNN			2009							166	172				7	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	BQB78	WOS:000280591600025	
S	Malof, JM; Mazurowski, MA; Tourassi, GD			IEEE	Malof, Jordan M.; Mazurowski, Maciej A.; Tourassi, Georgia D.			The Effect of Class Imbalance on Case Selection for Case-Based Classifiers, with Emphasis on Computer-Aided Diagnosis Systems	IJCNN: 2009 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1- 6	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	JUN 14-19, 2009	Atlanta, GA	Int Neural Network Soc, IEEE Computat Intelligence Soc		Cased-Based Learning; Computer-Aided Decision; Imbalance	LEARNING ALGORITHMS	in this paper the effect of class imbalance in the case base of a case-based classifier is investigated as it pertains to case base reduction and the resulting classifier performance. A k-nearest neighbor algorithm is used as a classifier and the Random Mutation Hill Climbing (RMHC) algorithm is used for case base reduction. The effects at various levels of positive class prevalence are tested in a binary classification problem. The results indicate that class imbalance is detrimental to both case base reduction and classifier performance. Selection with RMHC generally improves the classification performance regardless of the case base prevalence.	[Malof, Jordan M.] Univ Louisville, Dept Elect & Comp Engn, Louisville, KY 40292 USA	Malof, JM (reprint author), Univ Louisville, Dept Elect & Comp Engn, Louisville, KY 40292 USA.	jmmalo03@gmail.com; maciej.mazurowski@duke.edu; georgia.tourassi@duke.edu	Mazurowski, Maciej/D-4719-2011				AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda, 2001, PATTERN CLASSIFICATI; Mazurowski MA, 2008, PHYS MED BIOL, V53, P6079, DOI 10.1088/0031-9155/53/21/013; MAZUROWSKI MA, 2007, P INT JOINT C NEUR N, P2005; Mitchell T., MACHINE LEARNING; Obuchowski NA, 2003, RADIOLOGY, V229, P3, DOI 10.1148/radiol.2291010898; Skalak D., 2004, P 11 INT C MACH LEAR, P293; Tourassi GD, 2003, MED PHYS, V30, P2123, DOI 10.1118/1.1589494; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Zurada J., 1992, INTRO ARTIFICIAL NEU	12	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576	978-1-4244-3549-4	IEEE IJCNN			2009							1246	1251				6	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	BQB78	WOS:000280591600182	
B	Phyu, TN	Ao, SI	Castillo, O; Douglas, C; Feng, DD; Lee, JA		Phyu, Thair Nu	Ao, SI		Survey of Classification Techniques in Data Mining	IMECS 2009: INTERNATIONAL MULTI-CONFERENCE OF ENGINEERS AND COMPUTER SCIENTISTS, VOLS I AND II	Lecture Notes in Engineering and Computer Science		English	Proceedings Paper	International Multi-Conference of Engineers and Computer Scientists	MAR 18-20, 2009	Kowloon, PEOPLES R CHINA	Int Assoc Engineers, IAENG, Soc Artificial Intelligence, IAENG, Soc Bioinformat, IAENG, Soc Comp Sci, IAENG, Soc Data Min, IAENG, Soc Elect Engn, IAENG, Soc Imaging Engn, IAENG, Soc Ind Engn, IAENG, Soc Informat Syst Engn, IAENG, Soc Internet Comp & Web Serv, IAENG, Soc Mech Engn, IAENG, Soc Operat Res, IAENG, Soc Sci Comp, IAENG, Soc Software Engn, IAENG, Soc Wireless Networks		Bayesian; classification technique; fuzzy logic	NAIVE-BAYES CLASSIFIERS; LEARNING ALGORITHMS; DECISION TREES; NETWORKS	Classification is a data mining (machine learning) technique used to predict group membership for data instances. In this paper, we present the basic classification techniques. Several major kinds of classification method including decision tree induction, Bayesian networks, k-nearest neighbor classifier, case-based reasoning, genetic algorithm and fuzzy logic techniques. The goal of this survey is to provide a comprehensive review of different classification techniques in data mining.	Univ Comp Studies, Pakokku, Myanmar	Phyu, TN (reprint author), Univ Comp Studies, Pakokku, Myanmar.	Thair54@gmail.com					Baik S, 2004, LECT NOTES COMPUT SC, V3046, P206; Bouckaert RR, 2004, LECT NOTES ARTIF INT, V3339, P1089; Breslow LA, 1997, KNOWL ENG REV, V12, P1, DOI 10.1017/S0269888997000015; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Cheng J, 2002, ARTIF INTELL, V137, P43, DOI 10.1016/S0004-3702(02)00191-1; Cheng J., 2001, LECT NOTES COMPUTER, V2056, P141; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COWELL RG, 2001, P 17 INT C UNC ART I; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Elomaa T, 1999, LECT NOTES COMPUT SC, V1642, P63; Friedman N, 2003, MACH LEARN, V50, P95, DOI 10.1023/A:1020249912095; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Jensen FV, 1996, INTRO BAYESIAN NETWO; Kubat M., 2001, Intelligent Data Analysis, V5; MADDEN M, 2003, P EUR C MACH LEARN W, P59; McSherry D, 1999, KNOWL-BASED SYST, V12, P269, DOI 10.1016/S0950-7051(99)00024-6; Vivarelli F, 2001, NEURAL NETWORKS, V14, P427, DOI 10.1016/S0893-6080(01)00024-7; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Witten I., 2005, DATA MINING PRACTICA; Yang Y, 2003, LECT NOTES ARTIF INT, V2903, P440; Zhang GQP, 2000, IEEE T SYST MAN CY C, V30, P451, DOI 10.1109/5326.897072; Zheng ZJ, 2000, MACH LEARN, V40, P35, DOI 10.1023/A:1007626017208	23	0	0	INT ASSOC ENGINEERS-IAENG	HONG KONG	UNIT1, 1-F, 37-39 HUNG TO ROAD, KWUN TONG, HONG KONG, 00000, PEOPLES R CHINA		978-988-17012-2-0	LECT NOTES ENG COMP			2009							727	731				5	Computer Science, Artificial Intelligence; Engineering, Multidisciplinary	Computer Science; Engineering	BJI30	WOS:000266097200136	
S	Tarakanov, A		Popovich, VV; Schrenk, M; Claramunt, C; Korolenko, KV		Tarakanov, Alexander			Immunocomputing for Geoinformation Fusion and Forecast	INFORMATION FUSION AND GEOGRAPHIC INFORMATION SYSTEMS, PROCEEDINGS	Lecture Notes in Geoinformation and Cartography		English	Proceedings Paper	4th International Workshop on Information Fusion and Geographical Information Systems	MAY 17-20, 2009	St Petersburg, RUSSIA	RAS, St Petersburg Inst Informat & Automat		Immunocomputing; Geoinformation fusion; Spatio-temporal modeling; Forecast	INTRUSION DETECTION	Based on immunocomputing (IC), this paper proposes a new way for geoinformation fusion, spatio-temporal modeling, and forecast. The approach includes mathematically, rigorous mapping of high-dimensional spatio-temporal data into a scalar index, discrete tree transform (DTT) of the index values into states Of Cellular automata (CA), and identification of CA by IC. Numerical examples use official data of International Association for the Development of Freediving (AIDA), World Health Organization (WHO), as well as time series of Solar Influences Data Analysis Center (SIDC) and National Aeronautics and Space Administration (NASA). Anomaly index is also proposed using special the case of DTT. Recent results suggest that the IC approach Outperforms (by training time and accuracy) state-of-the-art approaches Of Computational intelligence.	RAS, St Petersburg Inst Informat & Automat, St Petersburg 199178, Russia	Tarakanov, A (reprint author), RAS, St Petersburg Inst Informat & Automat, 39,14 Liniya, St Petersburg 199178, Russia.	tar@iias.spb.su					Agnati LF, 2008, BRAIN RES REV, V58, P400, DOI 10.1016/j.brainresrev.2007.10.002; Atreas ND, 2003, LECT NOTES COMPUT SC, V2787, P111; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fuxe KG, 2008, BRAIN RES REV, V58, P453, DOI 10.1016/j.brainresrev.2008.04.003; Goncharova LB, 2008, CURR MED CHEM, V15, P1297, DOI 10.2174/092986708784535009; Goncharova LB, 2008, CURR MED CHEM, V15, P210; Goncharova LB, 2007, BRAIN RES REV, V55, P155, DOI 10.1016/j.brainresrev.2007.02.003; IVANCIUC Q, 2007, REV COMP CH, V23, P291; KUZNETSOV VI, 1999, ECOLOGICAL ATLAS; Tarakanov A, 2007, INT J UNCONV COMPUT, V3, P123; Tarakanov A, 2007, J CELL AUTOM, V2, P39; Tarakanov A. O., 2003, IMMUNOCOMPUTING PRIN; Tarakanov AO, 2008, IEEE COMPUT INTELL M, V3, P22, DOI 10.1109/MCI.2008.919069; TARAKANOV AO, 2007, LNGC, V14, P252; TARAKANOV AO, HDB RES ART IN PRESS; Yao JT, 2006, LECT NOTES ARTIF INT, V4062, P538; *NASA, OC COL TIM SER PROJ	17	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1863-2246	978-3-642-00303-5	LEC NOT GEO CARTO			2009							125	134		10.1007/978-3-642-00304-2_8		10	Computer Science, Interdisciplinary Applications; Geosciences, Multidisciplinary; Remote Sensing	Computer Science; Geology; Remote Sensing	BMU62	WOS:000273609500008	
B	Ballabio, D; Todeschini, R		Sun, DW		Ballabio, Davide; Todeschini, Roberto			Multivariate Classification for Qualitative Analysis	INFRARED SPECTROSCOPY FOR FOOD QUALITY ANALYSIS AND CONTROL			English	Article; Book Chapter							PATTERN-RECOGNITION; NETWORKS		[Ballabio, Davide; Todeschini, Roberto] Univ Milano Bicocca, Milano Chemometr & QSAR Res Grp, Dept Environm Sci, I-20126 Milan, Italy	Ballabio, D (reprint author), Univ Milano Bicocca, Milano Chemometr & QSAR Res Grp, Dept Environm Sci, Pzza Sci 1, I-20126 Milan, Italy.						Barker M, 2003, J CHEMOMETR, V17, P166, DOI 10.1002/cem.785; Breiman L, 1984, CLASSIFICATION REGRE; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DERDE MP, 1986, ANAL CHIM ACTA, V184, P33, DOI 10.1016/S0003-2670(00)86468-5; Fisher RA, 1936, ANN EUGENIC, V7, P179; Frank I.E., 1994, DATA ANAL HDB; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Hand DJ, 1997, CONSTRUCTION ASSESSM; HECHTNIELSEN R, 1987, APPL OPTICS, V26, P4979, DOI 10.1364/AO.26.004979; Jennrich RJ, 1977, STAT METHODS DIGITAL; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; Kohonen T., 1988, SELF ORG ASS MEMORY; KOWALSKI BR, 1972, ANAL CHEM, V44, P1405, DOI 10.1021/ac60316a008; Mardia K. V., 1979, MULTIVARIATE ANAL, P521; Massart DL, 1983, INTERPRETATION ANAL; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Norgaard L, 2006, J CHEMOMETR, V20, P425, DOI 10.1002/cem.1017; Todeschini R, 2007, CHEMOMETR INTELL LAB, V87, P3, DOI 10.1016/j.chemolab.2005.11.001; TODESCHINI R, 1989, CHEMOMETR INTELL LAB, V6, P213, DOI 10.1016/0169-7439(89)80086-3; Vapnik V, 1999, NATURE STAT LEARNING; Wold H., 1966, MULTIVARIATE ANAL; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5; Zupan J., 1993, NEURAL NETWORKS CHEM; Zupan J., 1994, ACTA CHIM SLOV, V41, P327; Zupan J, 1997, CHEMOMETR INTELL LAB, V38, P1, DOI 10.1016/S0169-7439(97)00030-0	26	5	5	ELSEVIER SCIENCE BV	AMSTERDAM	SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS		9780-0-80-92087-0				2009							83	104		10.1016/B978-0-12-374136-3.00004-3		22	Food Science & Technology; Spectroscopy	Food Science & Technology; Spectroscopy	BEI23	WOS:000316686500005	
J	Vanderlooy, S; Sprinkhuizen-Kuyper, IG; Smirnov, EN; van den Herik, HJ				Vanderlooy, Stijn; Sprinkhuizen-Kuyper, Ida G.; Smirnov, Evgueni N.; van den Herik, H. Jaap			The ROC isometrics approach to construct reliable classifiers	INTELLIGENT DATA ANALYSIS			English	Article						ROC analysis; isometrics; abstaining classifiers; reliable classifiers; cost-sensitive classification	ABSTAINING CLASSIFIERS; REJECT RULE; CLASSIFICATION	We address the problem of applying machine-learning classifiers in domains where incorrect classifications have severe consequences. In these domains we propose to apply classifiers only when their performance can be defined by the domain expert prior to classification. The classifiers so obtained are called reliable classifiers. In the article we present three main contributions. First, we establish the effect on an ROC curve when ambiguous instances are left unclassified. Second, we propose the ROC isometrics approach to tune and transform a classifier in such a way that it becomes reliable. Third, we provide an empirical evaluation of the approach. From our analysis and experimental evaluation we may conclude that the ROC isometrics approach is an effective and efficient approach to construct reliable classifiers. In addition, a discussion about related work clearly shows the benefits of the approach when compared with existing approaches that also have the option to leave ambiguous instances unclassified.	[Vanderlooy, Stijn; Smirnov, Evgueni N.; van den Herik, H. Jaap] Univ Limburg, MICC, NL-6200 MD Maastricht, Netherlands; [Sprinkhuizen-Kuyper, Ida G.] Radboud Univ Nijmegen, NICI, NL-6500 HE Nijmegen, Netherlands	Vanderlooy, S (reprint author), Univ Limburg, MICC, POB 616, NL-6200 MD Maastricht, Netherlands.	s.vanderlooy@micc.unimaas.nl	Sprinkhuizen-Kuyper, Ida/E-2829-2010	Sprinkhuizen-Kuyper, Ida/0000-0003-0273-9354	Dutch Organization for Scientific Research (NWO); POL [634.000.435]	We thank the reviewers for useful comments and suggestions. The first author is supported by the Dutch Organization for Scientific Research (NWO), ToKeN programme, viz. the IPOL project, grant nr: 634.000.435.	Agarwal S, 2005, J MACH LEARN RES, V6, P393; Atiya AF, 2005, NEURAL COMPUT, V17, P731, DOI 10.1162/0899766053019971; Cestnik B., 1990, P EUR C ART INT, P147; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; Chow C.K., 1957, Institute of Radio Engineers Transactions on Electronic Computers, VEC-6; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; DZEROSKI S, 1992, P 2 INT WORKSH IND L, P109; Elkan C, 2001, P 17 INT JOINT C ART, P973; Fawcett T., 2003, HPL20034; Fawcett T, 2005, MACH LEARN, V58, P33, DOI 10.1007/s10994-005-5256-4; Ferri C., 2004, P 1 INT WORKSH ROC A, P27; Ferri C, 2004, P 21 INT C MACH LEAR, P37; Flach P. A., 2003, P 20 INT C MACH LEAR, P194; FLACH PA, 2005, P 19 INT JOINT C ART, P702; Frelicot C, 2002, PATTERN ANAL APPL, V5, P234; FRIEDEL C, 2006, P ICML 2006 WORKSH R, P33; Furnkranz J, 2005, MACH LEARN, V58, P39, DOI 10.1007/s10994-005-5011-x; GUYON I, 2007, 20 INT JOINT C NEUR; Lachiche N., 2003, P 20 INT C MACH LEAR, P416; Lavrac N., 1994, INDUCTIVE LOGIC PROG; Ling CX, 2003, P 18 INT JOINT C ART; LU J, 2006, P 2 INT C ADV DAT MI, P223; Macskassy S.A., 2004, P 1 WORKSH ROC AN AI, P61; MARROCCO C, 2007, P 5 INT C MACH LEARN, P47; Muzzolini R, 1998, PATTERN RECOGN, V31, P345, DOI 10.1016/S0031-3203(97)00056-3; Newman D. J., 1998, UCI REPOSITORY MACHI; Niculescu-Mizil A., 2005, P 22 INT C MACH LEAR, P625, DOI 10.1145/1102351.1102430; PAZZANI M, 1994, AAAI S AI MED STANF, P106; Pietraszek T, 2007, INTELL DATA ANAL, V11, P293; Pietraszek T, 2007, MACH LEARN, V68, P137, DOI 10.1007/s10994-007-5013-y; PROEDROU K, 2001, 0102 ROYAL HOLL U LO; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; PROVOST F, 1998, P 15 INT C MACH LEAR, P43; Rijsbergen C. J. V., 1979, INFORM RETRIEVAL; Santos-Pereira CM, 2005, PATTERN RECOGN LETT, V26, P943, DOI 10.1016/j.patrec.2004.09.042; Swets JA, 2000, SCI AM, V283, P82; TING KM, 2002, P 5 INT C DISV SCI, P98; Tortorella F, 2004, PATTERN ANAL APPL, V7, P128, DOI 10.1007/s10044-004-0209-2; Tortorella F, 2005, PATTERN RECOGN LETT, V26, P167, DOI 10.1016/j.patrec.2004.09.004; Van Den Bossche R, 2006, J SLEEP RES, V15, P113; VANDERLOOY S, 2006, P ICML 2006 WORKSH R, P55; Weiss Gary M, 2007, Proceedings of the International Conference on Data Mining. DMIN 2007; Weiss GM, 2003, J ARTIF INTELL RES, V19, P315; Ye J., 2004, ADV NEURAL INFORM PR, P1569	46	2	3	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	1088-467X		INTELL DATA ANAL	Intell. Data Anal.		2009	13	1					3	37		10.3233/IDA-2009-0354		35	Computer Science, Artificial Intelligence	Computer Science	439KW	WOS:000265627000001	
J	Olvera-Lopez, JA; Martinez-Trinidad, JF; Carrasco-Ochoa, JA; Kittler, J				Olvera-Lopez, J. A.; Martinez-Trinidad, J. Fco.; Carrasco-Ochoa, J. A.; Kittler, J.			Prototype selection based on sequential search	INTELLIGENT DATA ANALYSIS			English	Article						Prototype selection; quality training set; supervised classification; sequential search	NEAREST-NEIGHBOR RULE; ORDERED PROJECTIONS; LEARNING ALGORITHMS; INSTANCE SELECTION; GENETIC ALGORITHMS; CLASSIFICATION; SET	In this paper, we propose and explore the use of the sequential search for solving the prototype selection problem since this kind of search has shown good performance for solving selection problems. We propose three prototype selection methods based on sequential search. The main goal of our methods is to reduce the training data without losing too much classification accuracy. Experiments and results are reported showing the effectiveness of the proposed methods and comparing their performance against other prototype selection methods.	[Olvera-Lopez, J. A.; Martinez-Trinidad, J. Fco.; Carrasco-Ochoa, J. A.] Natl Inst Astrophys Opt & Elect, Dept Comp Sci, Puebla 72840, Mexico; [Kittler, J.] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England	Olvera-Lopez, JA (reprint author), Natl Inst Astrophys Opt & Elect, Dept Comp Sci, Luis Enrique Erro 1, Puebla 72840, Mexico.	aolvera@ccc.inaoep.mx					Aguilar-Ruiz JS, 2006, LECT NOTES COMPUT SC, V4031, P1339; Asuncion A., 2007, UCI MACHINE LEARNING; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Bezdek JC, 2001, INT J INTELL SYST, V16, P1445, DOI 10.1002/int.1068; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Cerveron V, 2001, IEEE T SYST MAN CY B, V31, P408, DOI 10.1109/3477.931531; Chien HC, 2006, IEEE PHOTONIC TECH L, V18, P559, DOI 10.1109/LPT.2005.863994; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1980, Proceedings of the 5th International Conference on Pattern Recognition; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GLOVER F, 1986, COMPUT OPER RES, V13, P533, DOI 10.1016/0305-0548(86)90048-1; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KITTLER J, 1986, HDB PATTERN RECOGNIT, P203; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; Kuncheva LI, 1997, PATTERN RECOGN, V30, P1041, DOI 10.1016/S0031-3203(96)00134-3; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; Liu H, 2002, DATA MIN KNOWL DISC, V6, P115, DOI 10.1023/A:1014056429969; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; Lumini A, 2006, PATTERN RECOGN, V39, P495, DOI 10.1016/j.patcog.2005.11.004; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Raicharoen T, 2005, PATTERN RECOGN LETT, V26, P1554, DOI 10.1016/j.patrec.2005.01.003; Riquelme JC, 2003, PATTERN RECOGN, V36, P1009, DOI 10.1016/S0031-3203(02)00119-X; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Rumelhart D.E., 1986, LEARNING INTERNAL RE, V1, P318; Spillmann B, 2006, LECT NOTES COMPUT SC, V4109, P287; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; Vapnik V.N., 1995, NATURE STAT LEARNING; VENMANN CJ, 2005, IEEE T PATTERN ANAL, V27, P1417; VENMANN CJ, 2002, IEEE T PATTERN ANAL, V24, P1273; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	32	1	1	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	1088-467X		INTELL DATA ANAL	Intell. Data Anal.		2009	13	4					599	631		10.3233/IDA-2009-0383		33	Computer Science, Artificial Intelligence	Computer Science	494HP	WOS:000269802800005	
S	Caises, Y; Gonzalez, A; Leyva, E; Perez, R		Corchado, E; Yin, H		Caises, Yoel; Gonzalez, Antonio; Leyva, Enrique; Perez, Raul			SCIS: Combining Instance Selection Methods to Increase Their Effectiveness over a Wide Range of Domains	INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	10th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL 2009)	SEP 23-26, 2009	Burgos, SPAIN	Junta Castilla Leon, Univ Burgos, Diputac Burgos, Ayuntamiento Burgos, GCI, CSA, FAE, FEC		Instance selection; data reduction; machine learning	PROTOTYPE REDUCTION SCHEMES; LEARNING ALGORITHMS	Instance selection is a feasible strategy to solve the problem of dealing with large databases in inductive learning. There are several proposals in this area, but none of them consistently outperforms the others over it wide range of domains. In this paper(1) we present a set of measures to characterize the databases, as well as a new algorithm that uses these measures and, depending on the data characteristics, it applies the method or combination of methods expected to produce the best results. This approach was evaluated over 20 databases and with six different learning paradigms. The results have been compared with those achieved by five well-known state-of-the-art methods.			ycaises@facinf.uho.edu.cu; A.Gonzalez@decsai.ugr.es; eleyvam@facinf.uho.edu.cu; Raul_Perez@decsai.ugr.es	Leyva, Enrique/H-5244-2011; Gonzalez Munoz, Antonio/C-2427-2012	Gonzalez Munoz, Antonio/0000-0001-8889-7593			Aggarwal CC, 2001, LECT NOTES COMPUT SC, V1973, P420; Aha D.W., 1997, LAZY LEARNING; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Bernado E, 2002, LECT NOTES ARTIF INT, V2321, P115; Beyer K, 1999, LECT NOTES COMPUT SC, V1540, P217; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Demsar J, 2006, J MACH LEARN RES, V7, P1; Frank E, 1998, 15 INT C MACH LEARN, P144; Gonzalez A, 1999, IEEE T FUZZY SYST, V7, P176, DOI 10.1109/91.755399; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; John G. H., 1995, 11 C UNC ART INT, P338; Kim SW, 2003, PATTERN RECOGN, V36, P1083, DOI 10.1016/S0031-3203(02)00115-2; Kim SW, 2003, PATTERN ANAL APPL, V6, P232, DOI 10.1007/s10044-003-0191-0; KRUSKAL J.B., 1956, P AM MATH SOC, V7, P48, DOI DOI 10.1090/S0002-9939-1956-0078686-7; Mollineda RA, 2005, LECT NOTES COMPUT SC, V3523, P27; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Quinlan J. R., 1993, C4 5 PROGRAM MACHINE; Reinartz T, 2002, DATA MIN KNOWL DISC, V6, P191, DOI 10.1023/A:1014047731786; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; ZHAO K, 2003, INT C MACH LEARN CYB, V1, P94; [Anonymous], UCI MACH LEARN REP	23	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-04393-2	LECT NOTES COMPUT SC			2009	5788						17	24				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BND11	WOS:000274188700003	
S	Ishii, N; Hoki, Y; Okada, Y; Bao, YG		Corchado, E; Yin, H		Ishii, Naohiro; Hoki, Yuta; Okada, Yuki; Bao, Yongguang			Nearest Neighbor Classification by Relearning	INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	10th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL 2009)	SEP 23-26, 2009	Burgos, SPAIN	Junta Castilla Leon, Univ Burgos, Diputac Burgos, Ayuntamiento Burgos, GCI, CSA, FAE, FEC				Since the k-nearest neighbor (kNN) classification is a simple and effective classification approach, it is well known in the data classification. However, improving performance of the classifier is still attractive to cope with the high accuracy processing. A tolerant rough set is considered as a basis of the classification of data. The data classification is realized by applying the kNN with distance function. To improve the classification accuracy, a distance function with weights is considered. Then, weights of the function are optimized by the genetic algorithm. After the learning of training data, an unknown data is classified by the kNN with distance function. To improve further the performance of the kNN classifier, a relearning method is proposed. The proposed relearning method shows a higher generalization accuracy when compared to the basic kNN with distance function and other conventional learning algorithms. Experiments have been conducted on some benchmark datasets from the UCI Machine Learning Repository.	[Ishii, Naohiro; Hoki, Yuta; Okada, Yuki; Bao, Yongguang] Aichi Inst Technol, Toyota 4700392, Japan	Ishii, N (reprint author), Aichi Inst Technol, Toyota 4700392, Japan.	ishii@aitech.ac.jp					Bao YG, 2002, LECT NOTES COMPUT SC, V2534, P340; Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ishii N, 2006, LECT NOTES COMPUT SC, V4224, P57; Merz C.J., 1998, UCI REPOSITORY MACHI; Wilson DR, 2000, COMPUT INTELL, V16, P1, DOI 10.1111/0824-7935.00103	6	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-04393-2	LECT NOTES COMPUT SC			2009	5788						42	49				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BND11	WOS:000274188700006	
S	Valls, JM; Aler, R		Corchado, E; Yin, H		Valls, Jose M.; Aler, Ricardo			Optimizing Data Transformations for Classification Tasks	INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	10th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL 2009)	SEP 23-26, 2009	Burgos, SPAIN	Junta Castilla Leon, Univ Burgos, Diputac Burgos, Ayuntamiento Burgos, GCI, CSA, FAE, FEC		Data transformations; General Euclidean Distances; Evolutionary Computation; Evolutionary-based Machine Learning		Many classification algorithms use the concept of distance or similarity between patterns. Previous work has shown that it is advantageous to optimize general Euclidean distances (GED). In this paper, data transformations are optimized instead. This is equivalent to searching for GEDs, but can be applied to any learning algorithm, even if it does not use distances explicitly. Two optimization techniques have been used: a simple Local Search (LS) and the Covariance Matrix Adaptation Evolution Strategy (CMA-ES). CMA-ES is an advanced evolutionary method for optimization in difficult continuous domains. Both diagonal and complete matrices have been considered. Results show that in general, complete matrices found by CMA-ES either outperform or match both Local Search, and the classifier working on the original untransformed data.	[Valls, Jose M.; Aler, Ricardo] Univ Carlos III Madrid, E-28903 Getafe, Spain	Valls, JM (reprint author), Univ Carlos III Madrid, E-28903 Getafe, Spain.	jvalls@inf.uc3m.es; aler@inf.uc3m.es					Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Hansen N, 2001, EVOL COMPUT, V9, P159, DOI 10.1162/106365601750190398; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; OSTERMEIER A, 1994, EVOLUTIONARY COMPUTA, V4, P369; Ripley B. D., 1996, PATTERN RECOGNITION; Sierra A, 2006, IEEE T EVOLUT COMPUT, V10, P81, DOI 10.1109/TEVC.2005.856069; Tou J.T., 1974, PATTERN RECOGNITION; Valls JM, 2007, COMPUT INFORM, V26, P33; Weinberger K. Q., 2005, NEURAL INFORM PROCES; Weisberg S., 1985, APPL LINEAR REGRESSI	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-04393-2	LECT NOTES COMPUT SC			2009	5788						176	183				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BND11	WOS:000274188700022	
J	Shao, YN; He, Y; Bao, YD; Mao, JY				Shao, Yongni; He, Yong; Bao, Yidan; Mao, Jingyuan			Near-Infrared Spectroscopy for Classification of Oranges and Prediction of the Sugar Content	INTERNATIONAL JOURNAL OF FOOD PROPERTIES			English	Article						Vis; NIR spectroscopy; Orange; PCA; PLS; WT; BP-ANN	NIR-SPECTROSCOPY; SOLUBLE SOLIDS; REFLECTANCE SPECTROSCOPY; PATTERN-RECOGNITION; WAVELET TRANSFORM; CALIBRATION; REGRESSION; SPECTRA; DISCRIMINATION; CHEMISTRY	A nondestructive method for the classification of orange samples according to their growing conditions and geographic areas was developed using Vis/Near infrared spectroscopy. The results showed that the NIR spectra of the samples were moderately clustered in the principle component space and pattern recognition wavelet transform (WT) combined artificial neural network (BP-ANN) provided satisfactory classification results. Additionally, a partial least square (PLS) method was constructed to predict the sugar content of certain oranges. It showed excellent predictions of the sugar content of oranges, with standard error of prediction (SEP) values of 0.290 and 0.301 for Shatangju and Huangyanbendizao, respectively.	[Shao, Yongni; He, Yong; Bao, Yidan; Mao, Jingyuan] Zhejiang Univ, Coll Biosyst Engn & Food Sci, Hangzhou 310029, Zhejiang, Peoples R China	He, Y (reprint author), Zhejiang Univ, Coll Biosyst Engn & Food Sci, Hangzhou 310029, Zhejiang, Peoples R China.	yhe@zju.edu.cn	He, Yong/E-3218-2010	He, Yong/0000-0001-6752-1757	National Science and Technology Support Program of China [2006BAD10A0403]; Zhejiang Provincial Natural Science Foundation of China [Y307158]; Science and Technology Department of Ningbo [2008C10037]; Scientific Research Fund of Zhejiang Provincial Education Department [20071064]	This study was supported by the National Science and Technology Support Program of China (2006BAD10A0403) Zhejiang Provincial Natural Science Foundation of China (Project No: Y307158), Science and Technology Department of Ningbo (2008C10037) and Scientific Research Fund of Zhejiang Provincial Education Department (20071064).	Carlini P, 2000, J AGR FOOD CHEM, V48, P5236, DOI 10.1021/jf000408f; Cen HY, 2007, TRENDS FOOD SCI TECH, V18, P72, DOI 10.1016/j.tifs.2006.09.003; COOMANS D, 1983, METHOD INFORM MED, V22, P93; COOMANS D, 1982, ANAL CHIM ACTA, V138, P153, DOI 10.1016/S0003-2670(01)85298-3; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DERDE MP, 1987, ANAL CHEM, V59, P1868, DOI 10.1021/ac00141a029; Dinc E, 2003, TALANTA, V59, P707, DOI 10.1016/S0039-9140(02)00611-2; He Y, 2006, SPECTROSC SPECT ANAL, V26, P850; HE YDF, 1998, ANAL BASIC APPL NEAR; HOLST H, 1992, APPL SPECTROSC, V46, P1780, DOI 10.1366/0003702924123601; Jetter K, 2000, ANAL CHIM ACTA, V420, P169, DOI 10.1016/S0003-2670(00)00889-8; KARSTANG TV, 1991, ANAL CHEM, V63, P767, DOI 10.1021/ac00008a006; Kawano S., 1994, NIR NEWS, V5, P10; Lammertyn J, 1998, T ASAE, V41, P1089; LI WJ, 2001, ANAL SCI           S, V117, P429; Liu F, 2009, ANAL CHIM ACTA, V635, P45, DOI 10.1016/j.aca.2009.01.017; LIZUKA K, 1999, J FOOD COMPOS ANAL, V12, P197; Lu R, 2001, T ASAE, V44, P1265; Mittermayr CR, 2001, APPL SPECTROSC, V55, P827, DOI 10.1366/0003702011952848; Miyamoto K., 1995, J NEAR INFRARED SPEC, V3, P227; NAES T, 1990, ANAL CHEM, V62, P664, DOI 10.1021/ac00206a003; Paradkar RP, 1996, APPL SPECTROSC, V50, P753, DOI 10.1366/0003702963905718; Peiris KHS, 1999, HORTSCIENCE, V34, P114; Pontes MJC, 2005, CHEMOMETR INTELL LAB, V78, P11, DOI 10.1016/j.chemolab.2004.12.001; Rodriguez-Saona LE, 2001, CARBOHYD RES, V336, P63, DOI 10.1016/S0008-6215(01)00244-0; Shao XG, 2000, FRESEN J ANAL CHEM, V367, P525, DOI 10.1007/s002160000404; Shao XG, 2003, ACCOUNTS CHEM RES, V36, P276, DOI 10.1021/ar990163w; Shao XG, 1999, SPECTROSC SPECT ANAL, V19, P139; Sjoblom J, 1998, CHEMOMETR INTELL LAB, V44, P229, DOI 10.1016/S0169-7439(98)00112-9; Steuer B, 2001, FOOD CHEM, V72, P113, DOI 10.1016/S0308-8146(00)00209-0; Tang Q.Y., 2002, DPS DATA PROCESSING; Walczak B, 1997, TRAC-TREND ANAL CHEM, V16, P451, DOI 10.1016/S0165-9936(97)00065-4; Wu W, 1996, ANAL CHIM ACTA, V329, P257, DOI 10.1016/0003-2670(96)00142-0	33	6	6	TAYLOR & FRANCIS INC	PHILADELPHIA	325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA	1094-2912		INT J FOOD PROP	Int. J. Food Prop.		2009	12	3					644	658		10.1080/10942910801992991		15	Food Science & Technology	Food Science & Technology	439UP	WOS:000265653100016	
J	Arroyo, J; Mate, C				Arroyo, Javier; Mate, Carlos			Forecasting histogram time series with k-nearest neighbours methods	INTERNATIONAL JOURNAL OF FORECASTING			English	Article						Density forecast; Finance; Nonlinear time series models; Non-parametric forecasting; Symbolic data analysis; Weather forecast	DENSITY FORECASTS; ACCURACY	Histogram time series (HTS) describe situations where a distribution of values is available for each instant of time. These situations usually arise when contemporaneous or temporal aggregation is required. In these cases, histograms provide a summary of the data that is more informative than those provided by other aggregates such as the mean. Some fields where HTS are useful include economy, official statistics and environmental science. This article adapts the k-Nearest Neighbours (k-NN) algorithm to forecast HTS and, more generally, to deal with histogram data. The proposed k-NN relies on the choice of a distance that is used to measure dissimilarities between sequences of histograms and to compute the forecasts. The Mallows distance and the Wasserstein distance are considered. The forecasting ability of the k-NN adaptation is illustrated with meteorological and financial data, and promising results are obtained. Finally, further research issues are discussed. (C) 2008 International Institute of Forecasters. Published by Elsevier B.V. All rights reserved.	[Arroyo, Javier] Univ Complutense, Dept Ingn Software & Inteligencia Artificial, E-28040 Madrid, Spain; [Mate, Carlos] Univ Pontificia Comillas, Inst Invest Tecnol, ETSI, ICAI, Madrid 28015, Spain	Arroyo, J (reprint author), Univ Complutense, Dept Ingn Software & Inteligencia Artificial, Prof Garcia Santesmases S-N, E-28040 Madrid, Spain.	javier.arroyo@fdi.ucm.es					APARICIO T, 2002, APPL FINANCIAL EC, V12, P517, DOI 10.1080/09603100010007986; ARROYO JC, 2008, EXPONENTIAL SMOOTHIN; Billard L, 2003, J AM STAT ASSOC, V98, P470, DOI 10.1198/016214503000242; BILLARD L, 2006, SYMBLIC DATA ANAL CO; BOCK HH, 2000, ANAL SYMBOLIC DATA E, P153; Brath A, 2002, HYDROL EARTH SYST SC, V6, P627; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Diday E., 2008, SYMBOLIC DATA SODAS; Diebold FX, 1998, INT ECON REV, V39, P863, DOI 10.2307/2527342; ENGLE RF, HDB FINANCI IN PRESS; FARMER JD, 1987, PHYS REV LETT, V59, P845, DOI 10.1103/PhysRevLett.59.845; Fernandez-Rodriguez F, 1999, INT J FORECASTING, V15, P383, DOI 10.1016/S0169-2070(99)00003-5; Gibbs AL, 2002, INT STAT REV, V70, P419, DOI 10.2307/1403865; Gonzalez-Rivera G, 2008, J APPL ECONOM, V23, P585, DOI 10.1002/jae.1015; Hall SG, 2007, INT J FORECASTING, V23, P1, DOI 10.1016/j.ijforecast.2006.08.001; Hyndman RJ, 2006, INT J FORECASTING, V22, P679, DOI 10.1016/j.ijforecast.2006.03.001; Irpino A, 2006, ST CLASS DAT ANAL, P185, DOI 10.1007/3-540-34416-0_20; Jayawardena AW, 2002, J HYDROL, V258, P40, DOI 10.1016/S0022-1694(01)00557-1; Levina E., 2001, P IEEE 8 INT C COMP, V2, P251, DOI 10.1109/ICCV.2001.937632; MALLOWS CL, 1972, ANN MATH STAT, V43, P508, DOI 10.1214/aoms/1177692631; Meade N, 2002, INT J FORECASTING, V18, P67, DOI 10.1016/S0169-2070(01)00111-X; Pasley A, 2004, DECIS SUPPORT SYST, V37, P501, DOI 10.1016/S0167-9236(03)00083-6; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Schweizer B, 1984, P MATH FUZZY SYSTEMS, P137; Sorjamaa A, 2005, LECT NOTES COMPUT SC, V3512, P985; Tay AS, 2000, J FORECASTING, V19, P235, DOI 10.1002/1099-131X(200007)19:4<235::AID-FOR772>3.3.CO;2-C; VERDE R, 2007, SELECTED CONTRIBUTIO, P123, DOI 10.1007/978-3-540-73560-1_12; Wand MP, 1997, AM STAT, V51, P59, DOI 10.2307/2684697; Yakowitz S., 1987, J TIME SER ANAL, V8, P235, DOI 10.1111/j.1467-9892.1987.tb00435.x	29	9	10	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-2070		INT J FORECASTING	Int. J. Forecast.	JAN-MAR	2009	25	1					192	207		10.1016/j.ijforecast.2008.07.003		16	Economics; Management	Business & Economics	415OZ	WOS:000263944800017	
J	Papa, JP; Falcao, AX; Suzuki, CTN				Papa, J. P.; Falcao, A. X.; Suzuki, C. T. N.			Supervised Pattern Classification Based on Optimum-Path Forest	INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY			English	Article	12th International Workshop on Combinatorial Image Analysis	APR 07-09, 2008	Buffalo, NY			supervised learning; image foresting transform; pattern recognition; image analysis; graph-search algorithms	FUZZY CONNECTEDNESS; IMAGE SEGMENTATION; ALGORITHMS	We present a supervised classification method which represents each class by one or more optimum-path trees rooted at some key samples, called prototypes. The training samples are nodes of a complete graph, whose arcs are weighted by the distances between the feature vectors of their nodes. Prototypes are identified in all classes and the minimization of a connectivity function by dynamic programming assigns to each training sample a minimum-cost path from its most strongly connected prototype. This competition among prototypes partitions the graph into an optimum-path forest rooted at them. The class of the samples in an optimum-path tree is assumed to be the same of its root. A test sample is classified similarly, by identifying which tree would contain it, if the sample were part of the training set. By choice of the graph model and connectivity function, one can devise other optimum-path forest classifiers. We present one of them, which is fast, simple, multiclass, parameter independent, does not make any assumption about the shapes of the classes, and can handle some degree of overlapping between classes. We also propose a general algorithm to learn from errors on an evaluation set without increasing the training set, and show the advantages of our method with respect to SVM, ANN-MLP, and k-NN classifiers in several experiments with datasets of various types. (C) 2009 Wiley Periodicals, Inc. Int J Imaging Syst Technol, 19, 120-131, 2009; Published online in Wiley InterScience (www.intersciencewiley.com). DOI 10.1002/ima.20188	[Papa, J. P.; Falcao, A. X.; Suzuki, C. T. N.] Univ Estadual Campinas, Inst Comp, Campinas, SP, Brazil	Falcao, AX (reprint author), Univ Estadual Campinas, Inst Comp, Campinas, SP, Brazil.	afalcao@ic.unicamp.br	Falcao, Alexandre/F-8361-2012				Allene C., 2007, MATH MORPHOLOGY ITS, P253; Arica N, 2003, PATTERN RECOGN LETT, V24, P1627, DOI 10.1016/S0167-8655(03)00002-3; AUDIGIER R, 2007, MATH MORPHOLOGY ITS, P277; Audigier Romaric, 2007, 2007 20th Brazilian Symposium on Computer Graphics and Image Processing - SIBGRAPI '07; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; CALLUT J, 2008, P 17 ANN MACH LEARN, P67; CAPPABIANCO FAM, 2008, 5 IEEE INT S BIOM IM, P428; Chang C-C., 2001, LIBSVM LIB SUPPORT V; Cohen J, 1960, EDUC PSYCHOL MEAS, V20, P46; Collins DL, 1998, IEEE T MED IMAGING, V17, P463, DOI 10.1109/42.712135; Collobert R., 2004, P 21 INT C MACH LEAR, P23; Cormen T H, 1990, INTRO ALGORITHMS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duan KB, 2005, LECT NOTES COMPUT SC, V3541, P278; Duda R.O., 2000, PATTERN CLASSIFICATI; Falcao AX, 2004, IEEE T PATTERN ANAL, V26, P19, DOI 10.1109/TPAMI.2004.1261076; FALCAO AX, 2008, Patent No. 2008064442; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; Haykin S., 1994, NEURAL NETWORKS COMP; Herman GT, 2001, IEEE T PATTERN ANAL, V23, P460, DOI 10.1109/34.922705; HU M, 1962, IRE T INFORM THEOR, V8, P179; HUANG SC, 1991, IEEE T NEURAL NETWOR, V2, P47, DOI 10.1109/72.80290; HUBERT LJ, 1974, PSYCHOMETRIKA, V39, P283, DOI 10.1007/BF02291704; Jain A., 1988, ALGORITHMS CLUSTERIN; Joachims T., 1999, P 16 INT C MACH LEAR, P200; Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence; Koza J. R., 1992, GENETIC PROGRAMMING; Kulis B., 2005, ICML, P457; Kumar N, 2008, IEEE T KNOWL DATA EN, V20, P496, DOI 10.1109/TKDE.2007.190715; KUNCHEVA L, 1996, ARTIFICIAL DATA SCH; KUNCHEVA LI, 2004, COMBINING PATTERN CL; LOTUFO RA, 2000, MATH MORPHOLOGY ITS, V18, P341; Martinez JM, 2002, IEEE MULTIMEDIA, V9, P78, DOI 10.1109/93.998074; MIRANDA PAV, 2008, EURASIP J ADV SIG PR, P1; MONTOYAZEGARRA JA, 2008, EURASIP J ADV SIG PR, P1, DOI DOI 10.1155/2008/691924; Nissen S., 2003, IMPLEMENTATION FAST; PANDA N, 2006, P 23 INT C MACH LEAR, P681, DOI 10.1145/1143844.1143930; Papa JP, 2008, PROCEEDINGS OF IWSSIP 2008: 15TH INTERNATIONAL CONFERENCE ON SYSTEMS, SIGNALS AND IMAGE PROCESSING, P249; PAPA JP, 2007, MATH MORPHOLOGY ITS, P337; PAPA JP, 2008, LNCS, P136; PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681; Reyzin Lev, 2006, P 23 INT C MACH LEAR, P753, DOI 10.1145/1143844.1143939; ROCHA LM, 2008, 8 INT WORKSH COMB IM, P29; Saha PK, 2001, COMPUT VIS IMAGE UND, V82, P42, DOI 10.1006/cviu.2000.0902; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; SPADOTTO AA, 2008, P 3 IEEE INT S COMM, P735; Stehling R. O., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Tang B, 2006, P 23 INT C MACH LEAR, P921, DOI 10.1145/1143844.1143960; Torres RD, 2004, PATTERN RECOGN, V37, P1163, DOI 10.1016/j.patcog.2003.10.007; Torres RD, 2009, PATTERN RECOGN, V42, P283, DOI 10.1016/j.patcog.2008.04.010; WANG YP, 1990, IEEE T PATTERN ANAL, V12, P1080, DOI 10.1109/34.61707; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083; Zhou D., 2005, ADV NEURAL INFORM PR, V17, P1633; ZHU X, 2000, 1530 U WISC MAD; *COR CORP, 2007, COR STOCK PHOT IM	58	46	47	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	0899-9457		INT J IMAG SYST TECH	Int. J. Imaging Syst. Technol.		2009	19	2					120	131		10.1002/ima.20188		12	Engineering, Electrical & Electronic; Optics; Imaging Science & Photographic Technology	Engineering; Optics; Imaging Science & Photographic Technology	451YD	WOS:000266505900009	
J	Bo, S; Ding, L; Li, H; Di, F; Zhu, C				Bo, S.; Ding, L.; Li, H.; Di, F.; Zhu, C.			Mean shift-based clustering analysis of multispectral remote sensing imagery	INTERNATIONAL JOURNAL OF REMOTE SENSING			English	Article							PATTERN-CLASSIFICATION; MULTIVARIATE DATA; SCALE; SPACES	In clustering analysis of remote sensing imagery, a commonly held assumption is that the feature space can be modelled as a mixture of Gaussians. However, the assumption is not true for many real data and therefore incorrect classification results are often obtained by parametric methods. Nonparametric methods in feature space analysis can avoid the use of the normality assumption. Arbitrarily structured feature spaces can be analysed only by means of nonparametric methods as these methods do not have embedded assumptions. The mean shift is a basic computational module of the nonparametric technique in pattern recognition. The mean shift procedure can be used to cluster multispectral remote sensing imagery. Earlier clustering techniques based on the mean shift used a single scale over the entire feature space and were not feasible for the analysis of complex multimodal feature spaces. In this paper, we present an adaptive mean shift method in which local scale information is involved. The proposed algorithm can find arbitrary density, size and shape clusters in remote sensing imagery. The method is a simple technique of unsupervised image classification. We demonstrate its advantages in classification accuracy over earlier methods described in this paper.	[Bo, S.] Zhengzhou Inst Aeronaut Ind Management, Dept Comp Sci & Applicat, Zhengzhou 450015, Peoples R China; [Ding, L.; Li, H.; Di, F.; Zhu, C.] Chinese Acad Sci, Inst Remote Sensing Applicat, Beijing 100101, Peoples R China	Bo, S (reprint author), Zhengzhou Inst Aeronaut Ind Management, Dept Comp Sci & Applicat, Zhengzhou 450015, Peoples R China.	bsk586@163.com			National Natural Science Foundation of China [40771140/D0118]; China's Special Funds [2007CB714406]	We gratefully acknowledge support for this work from the National Natural Science Foundation of China (40771140/D0118), China's Special Funds for Major State Basic Research Project (2007CB714406). We thank the referees for their useful comments and Dr C. Cassells for improving the style in our manuscript.	Baatz M., 2004, ECOGNITION PROFESSIO; Bestelmeyer BT, 2006, J ARID ENVIRON, V65, P296, DOI 10.1016/j.jaridenv.2005.06.028; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790; Comaniciu D, 1997, PROC CVPR IEEE, P750, DOI 10.1109/CVPR.1997.609410; Comaniciu D., 2001, Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001, DOI 10.1109/ICCV.2001.937550; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Comaniciu D, 1999, PATTERN ANAL APPL, V2, P22, DOI 10.1007/s100440050011; Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, DOI 10.1109/ICCV.1999.790416; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAVID JM, 2003, PATTERN RECOGN, V36, P45; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; Ghosh AK, 2006, COMPUT STAT DATA AN, V50, P3113, DOI 10.1016/j.csda.2005.06.007; Jalba AC, 2004, PATTERN RECOGN, V37, P901, DOI 10.1016/j.patcog.2003.09.009; Li Xiang-Ru, 2005, Journal of Software, V16, DOI 10.1360/jos160365; Lofy B, 2001, PATTERN RECOGN, V34, P1825, DOI 10.1016/S0031-3203(00)00107-2; Nakamura E, 1998, PATTERN RECOGN LETT, V19, P1265, DOI 10.1016/S0167-8655(98)00099-3; Tran TN, 2006, COMPUT STAT DATA AN, V51, P513, DOI 10.1016/j.csda.2005.10.001; Wang JG, 2006, PATTERN RECOGN, V39, P417, DOI 10.1016/j.patcog.2005.08.009	18	8	8	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0143-1161		INT J REMOTE SENS	Int. J. Remote Sens.		2009	30	4					817	827		10.1080/01431160802395193		11	Remote Sensing; Imaging Science & Photographic Technology	Remote Sensing; Imaging Science & Photographic Technology	436JD	WOS:000265409100001	
B	Nakagawa, T; Shibata, T			IEEE	Nakagawa, Takuki; Shibata, Tadashi			A Real-Time Image Feature Vector Generator Employing Functional Cache Memory for Edge Flags	ISCAS: 2009 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOLS 1-5			English	Proceedings Paper	IEEE International Symposium on Circuits and Systems (ISCAS 2009)	MAY 24-27, 2009	Taipei, TAIWAN	IEEE				A feature-vector-generation VLSI architecture has been developed aiming at building real-time image recognition systems based on the directional edge based algorithm. The functional cache memory developed in the present work cyclically buffers newly extracted edge flags from an input image, while supplying edge flags to a vector generation circuitry. As a result, it has become possible to generate a 64-dimetional feature vector in every cycle of operation. The chip was designed in a 0.18-mu m 5-metal CMOS technology and sent to fabrication, and correct operation of the entire system was confirmed by Nanosim simulation. The architecture enables us to generate 3.9x10(7) feature vectors/sec (@100MHz), which is 5x10(3) times faster than the software processing using 2.16-GHz processor.	[Nakagawa, Takuki] Univ Tokyo, Dept Elect Engn, Tokyo 113, Japan	Nakagawa, T (reprint author), Univ Tokyo, Dept Elect Engn, 7-3-1 Hongo, Tokyo 113, Japan.	takuki@else.k.u-tokyo.ac.jp; shibata@ee.t.u-tokyo.ac.jp					Boser B., 1992, P 5 ANN WORKSH COMP, P144, DOI DOI 10.1145/130385.130401; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dalal Navneet, 2005, INT C COMP VIS PATT, V2, DOI DOI 10.1109/CVPR.2005.177; HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574; Lowe D. G., 2004, INT J COMPUT VISION, V60, P2004; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Shibata T., 1999, P 2 INT C INF FUS SU, V1, P648; Yagi M, 2003, IEEE T NEURAL NETWOR, V14, P1144, DOI 10.1109/TNN.2003.819038; Yamasaki H, 2007, IEEE J SOLID-ST CIRC, V42, P2046, DOI 10.1109/JSSC.2007.903099	10	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-3827-3				2009							3026	3029				4	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BNZ33	WOS:000275929801443	
B	Li, XA; Feng, L; Zhou, LZ			IEEE	Li, Xiang; Feng, Ling; Zhou, Lizhu			Contextual Ranking of Query Results with Incomplete Preferences	JCPC: 2009 JOINT CONFERENCE ON PERVASIVE COMPUTING			English	Proceedings Paper	Joint Conference on Pervasive Computing	DEC 03-05, 2009	Tamsui, TAIWAN		Tamsui & Tamkang Univ	Context-aware; preference; incomplete; ranking		Context-aware database is frequently used in user-centric applications. The users normally tend to express their preferences through comparisons. For example, Bob prefers Cornell to USC. Because the users only compare a small proportion of the products under difference contexts, "incomplete" preferences are a common occurrence. We propose a ranking approach which can contextually rank the query results when the users preferences are incomplete. We empirically evaluate the practical effectiveness of our method.	[Li, Xiang; Feng, Ling; Zhou, Lizhu] Tsinghua Univ, Dept Comp Sci & Technol, Tsinghua Natl Lab Informat Sci & Technol TNList, Beijing 100084, Peoples R China	Li, XA (reprint author), Tsinghua Univ, Dept Comp Sci & Technol, Tsinghua Natl Lab Informat Sci & Technol TNList, Beijing 100084, Peoples R China.	li-xiang06@mails.tsinghua.edu.cn; fengling@tsinghua.edu.cn; dcszlz@tsinghua.edu.cn					BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; BUNNINGEN A, DEXA 2006; Chomicki J, 2003, ACM T DATABASE SYST, V28, P427, DOI 10.1145/958942.958946; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY B, NEAREAST NEIGHOR PAT; Fix E., 1951, 4 USAF SCH AV MED; GENG X, SIGIR 08; INDYK P, P S THEOR COMP 1998; KENDALL MG, 1955, BIOMETRICS, V11, P43, DOI 10.2307/3001479; LI X, 2008, P IEEE 3 EUR C SMART; Omohundro S. M., 1989, TR89063 INT COMP SCI; STEFANIDIS K, 2007, ICDE; STEFANIDIS K, EDBT 2008; STEFANIDIS K, 1 INT WORKSH MAN CON; Wei TH, 1952, ALGEBRAIC FDN RANKIN; You GW, 2008, INFORM SCIENCES, V178, P3925, DOI 10.1016/j.ins.2008.06.009; NATL REPORT 2007 COL	17	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-5227-9				2009							349	354				6	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BQT40	WOS:000281790400061	
J	Varnek, A; Gaudin, C; Marcou, G; Baskin, I; Pandey, AK; Tetko, IV				Varnek, Alexandre; Gaudin, Cedric; Marcou, Gilles; Baskin, Igor; Pandey, Anil Kumar; Tetko, Igor V.			Inductive Transfer of Knowledge: Application of Multi-Task Learning and Feature Net Approaches to Model Tissue-Air Partition Coefficients	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							ASSOCIATIVE NEURAL NETWORKS; STRUCTURE-PROPERTY; COMBINATORIAL LIBRARY; CROSS-VALIDATION; DATA SETS; PREDICTION; DATABASE; BIAS; CLASSIFICATION; LIPOPHILICITY	Two inductive knowledge transfer approaches - multitask learning (MTL) and Feature Net (FN) - have been used to build predictive neural networks (ASNN) and PLS models for I I types of tissue-air partition coefficients (TAPC). Unlike conventional single-task learning (STL) modeling focused only on a single target property without any relations to other properties, in the framework of inductive transfer approach, the individual models are viewed as nodes in the network of interrelated models built in parallel (MTL) or sequentially (FN). It has been demonstrated that MTL and FN techniques are extremely useful in structure-property modeling on small and structurally diverse data sets, when conventional STL modeling is unable to produce any predictive model. The predictive STL individual models were obtained for 4 out of I I TAPC, whereas application of inductive knowledge transfer techniques resulted in models for 9 TAPC. Differences in prediction performances of the models as a function of the machine-learning method, and of the number of properties simultaneously involved in the learning, has been discussed.	[Varnek, Alexandre; Gaudin, Cedric; Marcou, Gilles] Univ Strasbourg 1, CNRS, UMR 7177, Lab Infochim, F-67000 Strasbourg, France; [Baskin, Igor] Moscow MV Lomonosov State Univ, Dept Chem, Moscow 119991, Russia; [Pandey, Anil Kumar; Tetko, Igor V.] Inst Bioinformat & Syst Biol, Helmholtz Zentrum Munchen, German Res Ctr Environm Hlth GmbH, D-85764 Neuherberg, Germany; [Tetko, Igor V.] Natl Ukrainian Acad Sci, Inst Bioorgan & Petrochem, UA-02660 Kiev, Ukraine	Varnek, A (reprint author), Univ Strasbourg 1, CNRS, UMR 7177, Lab Infochim, 4 Rue B Pascal, F-67000 Strasbourg, France.	vamek@chimie.u-strasbg.fr	Tetko, Igor/B-1540-2010; Baskin, Igor/I-2490-2012	Tetko, Igor/0000-0002-6855-0012; 	Go-Bio BMBF [0313883]; ARCUS; Louis Pasteur University	We thank CAMO ASA for providing us a demo version of Unscrambler 9.7 software to perform PLS analysis. This study was partially supported by the Go-Bio BMBF grant 0313883, the ARCUS "Alsace-Russia/Ukraine" project, and Louis Pasteur University for the Invited Professor's position to I.V.T.	Abu-Mostafa Y. S., 1990, Journal of Complexity, V6, DOI 10.1016/0885-064X(90)90006-Y; Balakin KV, 2006, CURR MED CHEM, V13, P223, DOI 10.2174/092986706775197917; BASKIN II, 1993, DOKL AKAD NAUK+, V332, P713; Baxter J, 2000, J ARTIF INTELL RES, V12, P149; Baxter J, 1997, MACH LEARN, V28, P7, DOI 10.1023/A:1007327622663; BAXTER J, 1997, LEARNING LEARN; CARUANA R, 1993, P 10 INT C MACH LEAR, P4148; CARUANA R, 1993, P 1993 CONN MOD SUMM, P372; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Caruana R., 1997, THESIS CARNEGIE MELL; CARUANA R, 1995, ADV NEURAL INFORMATI, V7, P656; Chang C., 2008, LIBSVM LIB SUPPORT V; CLARK T, 2003, EUROQSAR 2002 DESIGN, P111; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAVIS I, 1995, P IEEES INT ROB SYST; Erhan D, 2006, J CHEM INF MODEL, V46, P626, DOI 10.1021/ci050367t; ERIKSSON L, 2001, UMETRICS UMEA, V425; Evgeniou T, 2005, J MACH LEARN RES, V6, P615; FU LM, 1992, CONNECT SCI, V1, P325; GENTNER D, 1989, SIMILARITY AND ANALOGICAL REASONING, P199, DOI 10.1017/CBO9780511529863.011; GRUBBS FE, 1969, TECHNOMETRICS, V11, P1, DOI 10.2307/1266761; HAUSSLER D, 1988, ARTIF INTELL, V36, P177, DOI 10.1016/0004-3702(88)90002-1; Hawkins DM, 2003, J CHEM INF COMP SCI, V43, P579, DOI 10.1021/ci025626i; Heskes T., 2000, P 17 INT C MACH LEAR, P367; JEBARA T., 2004, P 21 INT C MACH LEAR; Katritzky AR, 2005, BIOORGAN MED CHEM, V13, P6450, DOI 10.1016/j.bmc.2005.06.066; Kohavi R., 1995, ARTIF INTELL, V2, P1137; KOVAC K, 2005, THESIS COMPUTER SCI; Lu W.C., 2004, P 7 INT C INF FUS SV, V1, P79; MAHONEY J, 1992, P 1992 MACH LEARN WO; MICCHELLI CA, 2005, P 18 C NEUR INF PROC; MOORE AW, 1992, COMPUTATIONAL LEARNI, V3; MURPHY GL, 1985, PSYCHOL REV, V92, P289, DOI 10.1037//0033-295X.92.3.289; MUSLEA IA, 2002, THESIS; NAKAMURA GV, 1985, MEM COGNITION, V13, P377, DOI 10.3758/BF03198450; Oloff S, 2005, J MED CHEM, V48, P7322, DOI 10.1021/jm049116m; PAZZANI MJ, 1991, J EXP PSYCHOL LEARN, V17, P416, DOI 10.1037/0278-7393.17.3.416; PRESS WH, 1994, NUMERICAL RECIPES C, P998; RANNAR S, 1995, J CHEMOMETR, V9, P459, DOI 10.1002/cem.1180090604; RENDELL L., 1987, P 10 INT JOINT C ART, P308; SCHANK RC, 1986, BEHAV BRAIN SCI, V9, P639; Schmidhuber J, 1997, MACH LEARN, V28, P105, DOI 10.1023/A:1007383707642; Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88; Solov'ev VP, 2003, J CHEM INF COMP SCI, V43, P1703, DOI 10.1021/ci020388c; SUDDARTH SC, 1991, INT J MAN MACH STUD, V35, P291, DOI 10.1016/S0020-7373(05)80130-0; Tetko IV, 2002, J CHEM INF COMP SCI, V42, P1136, DOI 10.1021/ci025515j; Tetko IV, 2004, J MED CHEM, V47, P5601, DOI 10.1021/jm049509l; TETKO IV, 1995, J CHEM INF COMP SCI, V35, P826, DOI 10.1021/ci00027a006; Tetko IV, 2002, NEURAL PROCESS LETT, V16, P187, DOI 10.1023/A:1019903710291; Tetko IV, 2005, J COMPUT AID MOL DES, V19, P453, DOI 10.1007/s10822-005-8694-y; Tetko IV, 2004, J PHARM SCI-US, V93, P3103, DOI 10.1002/jps.20217; Tetko IV, 2008, J INORG BIOCHEM, V102, P1424, DOI 10.1016/j.jinorgbio.2007.12.029; Tetko IV, 2001, J CHEM INF COMP SCI, V41, P1407, DOI 10.1021/ci010368v; Tetko IV, 2002, J CHEM INF COMP SCI, V42, P717, DOI 10.1021/ci010379o; Tetko IV, 2006, J CHEM INF MODEL, V46, P808, DOI 10.1021/ci0504216; THRUN S, 1995, CMUCS95208 COMP SCI; Thrun S., 1998, LEARNING LEARN; Thrun S, 1996, ADV NEUR IN, V8, P640; THRUN S, 1996, INT C MACH LEARN, P489; TOWELL GG, 1994, ARTIF INTELL, V70, P119, DOI 10.1016/0004-3702(94)90105-8; UTGOFF P, 1986, MACHINE LEARNING ART, V2; Vapnik V.N., 1995, NATURE STAT LEARNING; Varnek A, 2004, J CHEM INF COMP SCI, V44, P1365, DOI 10.1021/ci049976b; Varnek A, 2008, CURR COMPUT-AID DRUG, V4, P191, DOI 10.2174/157340908785747465; Tetko IV, 1997, NEURAL NETWORKS, V10, P1361, DOI 10.1016/S0893-6080(97)00005-1; YU K, 2005, NIPS 2005 WORKSH IND; Zhang J, 2006, ADV NEURAL INFORM PR, V18, P1585; *ACC INC, DIVA 2 1 PROGR; *CAMO ASA, UNSCR 9 7 SOFTW	69	11	11	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596		J CHEM INF MODEL	J. Chem Inf. Model.	JAN	2009	49	1					133	144		10.1021/ci8002914		12	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	399SB	WOS:000262818500015	
J	Chuang, LY; Yang, CH; Yang, CH				Chuang, Li-Yeh; Yang, Cheng-Huei; Yang, Cheng-Hong			Tabu Search and Binary Particle Swarm Optimization for Feature Selection Using Microarray Data	JOURNAL OF COMPUTATIONAL BIOLOGY			English	Article						feature selection; K-nearest neighbor; leave-one-out cross-validation; particle swarm optimization; support vector machines; tabu search	SUPPORT VECTOR MACHINES; GENE-EXPRESSION SIGNATURES; MOLECULAR CLASSIFICATION; CANCER-DIAGNOSIS; NEURAL NETWORKS; PREDICTION; ALGORITHMS; CARCINOMAS	Gene expression profiles have great potential as a medical diagnosis tool because they represent the state of a cell at the molecular level. In the classification of cancer type research, available training datasets generally have a fairly small sample size compared to the number of genes involved. This fact poses an unprecedented challenge to some classification methodologies due to training data limitations. Therefore, a good selection method for genes relevant for sample classification is needed to improve the predictive accuracy, and to avoid incomprehensibility due to the large number of genes investigated. In this article, we propose to combine tabu search (TS) and binary particle swarm optimization (BPSO) for feature selection. BPSO acts as a local optimizer each time the TS has been run for a single generation. The K-nearest neighbor method with leave-one-out cross-validation and support vector machine with one-versus-rest serve as evaluators of the TS and BPSO. The proposed method is applied and compared to the 11 classification problems taken from the literature. Experimental results show that our method simplifies features effectively and either obtains higher classification accuracy or uses fewer features compared to other feature selection methods.	[Yang, Cheng-Hong] Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, Kaohsiung 807, Taiwan; [Chuang, Li-Yeh] I Shou Univ, Dept Chem Engn, Kaohsiung, Taiwan; [Yang, Cheng-Huei] Natl Kaohsiung Marine Univ, Dept Elect Commun Engn, Kaohsiung, Taiwan; [Yang, Cheng-Hong] Toko Univ, Dept Network Syst, Chiayi, Taiwan	Yang, CH (reprint author), Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, 415 Chien Kung Rd, Kaohsiung 807, Taiwan.	chyang@cc.kuas.edu.tw	Chuang, Li-Yeh/E-5005-2011		National Science Council in Taiwan [NSC94-2622-E151-025-CC3, NSC94-2311-B037-001, NSC93-2213-E-214-037, NSC92-2213-E-214-036]	This work is partly supported by the National Science Council in Taiwan under grants NSC94-2622-E151-025-CC3, NSC94-2311-B037-001, NSC93-2213-E-214-037, and NSC92-2213-E-214-036.	Ancona N, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S4-S2; Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Berrar D, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-73; Bhattacharjee A, 2001, P NATL ACAD SCI USA, V98, P13790, DOI 10.1073/pnas.191502998; Bottino A, 1994, ASTROPART PHYS, V2, P77, DOI 10.1016/0927-6505(94)90019-1; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Burr Ridge I, 1997, MACHINE LEARNING; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crammer K, 2002, MACH LEARN, V47, P201, DOI 10.1023/A:1013637720281; Dasarathy B., 1991, NEAREST NEIGHBOR NN, P1; Diaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3; Duarte A, 2007, EUR J OPER RES, V178, P71, DOI 10.1016/j.ejor.2006.01.021; FIX E, 1989, INT STAT REV, V57, P238, DOI 10.2307/1403797; Friess T.-T., 1998, P 15 INT C MACH LEAR, P188; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Glover F., 1990, ORSA Journal on Computing, V2; Glover F., 1989, ORSA Journal on Computing, V1; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hastie T, 2001, ELEMENTS STAT LEARNI; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Kennedy J., 1995, IEEE INT C NEUR NETW, V4, P1942, DOI DOI 10.1109/ICNN.1995.488968; Kennedy J., 2001, SWARM INTELLIGENCE; KENNEDY J, 1997, P WORLD MULT SYST CY, P4104, DOI DOI 10.1109/ICSMC.1997.637339; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Kressel UHG, 1999, ADVANCES IN KERNEL METHODS, P255; Lee Y, 2003, BIOINFORMATICS, V19, P1132, DOI 10.1093/bioinformatics/btg102; Liu X, 2005, BMC BIOINFORM, V6, P76; NARENDRA PM, 1977, IEEE T COMPUT, V6, P917; Nutt CL, 2003, CANCER RES, V63, P1602; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; Platt J.C., 2000, LARGE MARGIN DAGS MU, P547; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; Sait SM, 2006, ENG APPL ARTIF INTEL, V19, P257, DOI 10.1016/j.engappai.2005.09.008; Scholkopf B, 2002, LEARNING KERNELS SUP; Shi Y.H., 1998, P IEEE INT C EV COMP, P69, DOI DOI 10.1109/ICEC.1998.699146; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; Staunton JE, 2001, P NATL ACAD SCI USA, V98, P10787, DOI 10.1073/pnas.191368598; STONE M, 1974, J R STAT SOC B, V36, P111; Su AI, 2001, CANCER RES, V61, P7388; Tahir MA, 2007, PATTERN RECOGN LETT, V28, P438, DOI 10.1016/j.patrec.2006.08.016; TAHIR MA, 2005, EURASIP J APPL SIG P, V14, P2241; Tang EK, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-95; WEST MA, 1999, CENTREPIECE, V4, P6; Yang JH, 1998, IEEE INTELL SYST APP, V13, P44, DOI 10.1109/5254.671091; YU B, 1993, PATTERN RECOGN, V26, P883, DOI 10.1016/0031-3203(93)90054-Z; Zhang CY, 2007, COMPUT OPER RES, V34, P3229, DOI 10.1016/j.cor.2005.12.002; Zhang HB, 2002, PATTERN RECOGN, V35, P701, DOI 10.1016/S0031-3203(01)00046-2; Zhou X, 2007, BIOINFORMATICS, V23, P1106, DOI 10.1093/bioinformatics/btm036	57	3	3	MARY ANN LIEBERT INC	NEW ROCHELLE	140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA	1066-5277		J COMPUT BIOL	J. Comput. Biol.		2009	16	12					1689	1703		10.1089/cmb.2007.0211		15	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	545CG	WOS:000273709400005	
J	Cantero, R; Riba, JR; Canals, T; Izquierdo, LL; Iturriaga, H				Cantero, R.; Riba, J. R.; Canals, T.; Izquierdo, L. L.; Iturriaga, H.			CHARACTERIZATION OF LEATHER FINISHING BY IR SPECTROSCOPY AND CANONICAL VARIATE ANALYSIS	JOURNAL OF THE SOCIETY OF LEATHER TECHNOLOGISTS AND CHEMISTS			English	Article							PROCESS ANALYTICAL-CHEMISTRY; REFLECTANCE SPECTROSCOPY; NEAREST-NEIGHBOR; CLASSIFICATION; DISCRIMINATION; CHEMOMETRICS; CALIBRATION; TECHNOLOGY; REGRESSION; OILS	The finishing process is one of the crucial steps in the process by which the tanning industry transforms leather into an end-product. Therefore, ensuring the required quality in the product requires careful control of this step. Traditionally, the leather tanning industry has used polluting processes and slow analytical methods involving time-consuming separations and also, frequently, the use of environmentally unfriendly reagents. In this work, we used a large matrix of spectroscopic data obtained from 63 leather specimens (34 from Pielcolor and 29 from the laboratories of the Leather Technology School of Igualada) to develop a method allowing the finishing method used on a leather (viz. a resin, wax/oil or grain correction treatment) to be expeditiously, non-destructively identified with the need for no sample treatment. To this end, Fourier transform infrared (FTIR) spectra were recorded with the aid of an ATR module and near-infrared (NIR) spectra with a fibre-optic probe. Chemometric processing of the FTIR or NIR spectral information thus obtained by Principal Component Analysis (PCA) and Canonical Variate Analysis (CVA) allowed the identification of the finishing treatment used on the studied leather samples. The results for the external prediction set (80% of hits with the FTIR model and 60% with the NIR model) were of the same order of magnitude than those obtained by leave-one-out cross-validation of the calibration set (85% with FTIR and 72% with NIR).	[Iturriaga, H.] Univ Autonoma Barcelona, Dept Quim, Unitat Quim Analit, E-08193 Bellaterra, Spain; [Cantero, R.; Riba, J. R.; Canals, T.] Univ Politecn Cataluna, EUETII Leather Technol Sch, Barcelona, Spain; [Izquierdo, L. L.] Pielcolor SLU, Barcelona 08291, Spain	Iturriaga, H (reprint author), Univ Autonoma Barcelona, Dept Quim, Unitat Quim Analit, E-08193 Bellaterra, Spain.	hortensia.iturriaga@uab.es			Spain's Ministry of Education and Science [CTQ 2006-12923]	The authors are grateful to Spain's Ministry of Education and Science for funding this research within the framework of Project CTQ 2006-12923.	ADZET JM, 1989, ACABADO PIEL; Alsberg BK, 1997, ANAL CHIM ACTA, V348, P389, DOI 10.1016/S0003-2670(97)00064-0; Alves MR, 2004, J CHEMOMETR, V18, P393, DOI 10.1002/cem.884; Bacardit A., 2000, ACABADO CUERO; Berrueta LA, 2007, J CHROMATOGR A, V1158, P196, DOI 10.1016/j.chroma.2007.05.024; Blanco M, 2000, ANAL CHIM ACTA, V419, P209, DOI 10.1016/S0003-2670(00)00976-4; Blanco M, 1996, J SOC LEATH TECH CH, V80, P110; Cantero R, 2007, TALANTA, V71, P1690, DOI 10.1016/j.talanta.2006.08.005; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUNKIN MJ, 1995, J SOC LEATHER TECHNO, V79, P8; ESTEVEZ J, 1987, AQEIC, V1, P1; ESTEVEZ J, 1986, AQEIC, V12, P481; Geladi P, 2004, SPECTROCHIM ACTA B, V59, P1347, DOI 10.1016/j.sab.2004.06.009; Geladi P, 2003, SPECTROCHIM ACTA B, V58, P767, DOI 10.1016/S0584-8547(03)00037-5; GUZMAN JJ, 2004, CPMC, V80, P155; JUAN L, 2007, JISUANJI YU YINGYONG, V24, P247; KLIVERI HT, 1992, TECHNOMETRICS, V34, P321; KOWALSKI BR, 1991, J CHEMOMETR, V5, P129, DOI 10.1002/cem.1180050303; Krzanowski W.J., 1993, PRINCIPLES MULTIVARI; MARJONIEMI M, 1995, J SOC LEATH TECH CH, V79, P41; Marjoniemi M., 1992, J AM LEATHER CHEM AS, V87, P249; McClure WF, 2003, J NEAR INFRARED SPEC, V11, P487; NAVIGLIO B, 1993, CPMC, V69, P79; Paradkar MM, 2003, J SCI FOOD AGR, V83, P714, DOI 10.1002/jsfa.1332; PLATE D, 2000, LEDER HAUTE MARKT, V2, P25; Plate D., 2003, LEDER HAUTE MARKT, V6, P30; RENCHER AC, 1992, AM STAT, V46, P217, DOI 10.2307/2685219; Shelly DC, 1999, J AM LEATHER CHEM AS, V94, P315; Wichern D. W., 1992, APPL MULTIVARIATE ST; Workman J, 2007, ANAL CHEM, V79, P4345, DOI 10.1021/ac070765q; Workman J, 2005, ANAL CHEM, V77, P3789, DOI 10.1021/ac050620o; Yang H, 2005, FOOD CHEM, V93, P25, DOI 10.1016/j.foodchem.2004.08.039	32	1	1	SOC LEATHER TECHNOL CHEMISTS	MOULTON	8 COPPER LEAF CLOSE, MOULTON NN3 7HS, NORTHAMPTON, ENGLAND	0144-0322		J SOC LEATH TECH CH	J. Soc. Leather Technol. Chem.	JAN-FEB	2009	93	1					12	17				6	Materials Science, Textiles	Materials Science	415LU	WOS:000263936100003	
J	Liou, SW; Wang, CM; Huang, YF				Liou, Sing-Wu; Wang, Chia-Ming; Huang, Yin-Fu			Integrative Discovery of Multifaceted Sequence Patterns by Frame-Relayed Search and Hybrid PSO-ANN	JOURNAL OF UNIVERSAL COMPUTER SCIENCE			English	Article	2nd KES International Symposium on Agent and Multi-Agent Systems	MAR 26-28, 2008	Incheon, SOUTH KOREA	Inha Univ, Sch Comp & Informat Engn, KES Int, KES Focus Grp Agent & Multi Agent Syst		pattern mining; multifaceted sequence patterns; computation-oriented pattern definition model; computational concerns; frame-relayed pattern model	DNA-BINDING SITES; INFORMATION-CONTENT; REGULATORY MOTIFS; PROTEIN; INTRONS; GENOME; GENES; RECOGNITION; SELECTION	For de novo pattern mining in genomic sequences, the main issues are constructing pattern definition model (PDM) and mining sequence patterns (MSP). The representations of PDMs and the discovery of patterns are functionally dependent; the performances thus depend on the adopted PDMs. The popular PDMs provide only descriptive patterns; they lack multifaceted considerations. Many of existing MSP methods are tied up with the exclusively devised PDMs, and the specialized and sophisticated models make the mined results hard to be reused. In this research, an integrative pattern mining system is proposed, which consists of a computation-oriented PDM (CO-PDM) and general-purpose MSP (GP-MSP) methods. The CO-PDM defines four computational concerns (CCs) as facets of MSP: expression (E), location (L), range (R) and weight (W), which are integrated into a frame-relayed pattern model (FRPM). The GP-MSP develops a frame-relayed search strategy to resolve the ELR-CCs firstly, with the aids of critical-parameter automating (CPA) procedure; and then the W-CC is determined by hybridizing particle swarm optimization (PSO) and artificial neural network (ANN). The proposed FRPM and GP-MSP had been implemented and applied to 22,448 human introns; from the results, all the well-known patterns were recovered and some new ones were also discovered. Furthermore, the effectiveness of identified patterns were verified by a two-layered k-nearest neighbor (k-NN) classifier; the average precision and recall are 0.88 and 0.92, respectively. By the case study, the integrative PDM-MSP system is believed to be effective and reliable; it is optimistic the proposed CO-PDM and GP-MSP are both widely applicable and reusable for mining sequence patterns in the eukaryotic protein-coding genes.	[Liou, Sing-Wu; Wang, Chia-Ming; Huang, Yin-Fu] Natl Yunlin Univ Sci & Technol, Yunlin, Taiwan; [Huang, Yin-Fu] Grad Sch Engn Sci & Technol, Yunlin, Taiwan; [Liou, Sing-Wu; Wang, Chia-Ming] Grad Sch Engn Sci & Technol, Yunlin, Taiwan	Huang, YF (reprint author), Natl Yunlin Univ Sci & Technol, Yunlin, Taiwan.	g9110808@yuntech.edu.tw; g9410805@yuntech.edu.tw; huangyf@yuntech.edu.tw					ALTSCHUL SF, 1994, NAT GENET, V6, P119, DOI 10.1038/ng0294-119; Arques DG, 1996, J THEOR BIOL, V182, P45, DOI 10.1006/jtbi.1996.0142; BERG OG, 1987, J MOL BIOL, V193, P723, DOI 10.1016/0022-2836(87)90354-8; Brazma A, 1998, J COMPUT BIOL, V5, P279, DOI 10.1089/cmb.1998.5.279; Burr Ridge I, 1997, MACHINE LEARNING; Che DS, 2005, BIOINFORMATICS, V21, P2909, DOI 10.1093/bioinformatics/bti425; Chen Xin, 2007, Comput Syst Bioinformatics Conf, V6, P249, DOI 10.1142/9781860948732_0027; Coolidge CJ, 1997, NUCLEIC ACIDS RES, V25, P888, DOI 10.1093/nar/25.4.888; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAY WHE, 1992, NUCLEIC ACIDS RES, V20, P1093, DOI 10.1093/nar/20.5.1093; Eberhart RC, 1998, P 7 ANN C EV PROGR, P69, DOI DOI 10.1007/BFB0040753; Fedorov A, 2002, NUCLEIC ACIDS RES, V30, P1192, DOI 10.1093/nar/30.5.1192; FICKETT JW, 1992, NUCLEIC ACIDS RES, V20, P6441, DOI 10.1093/nar/20.24.6441; Fratkin E, 2006, BIOINFORMATICS, V22, pE150, DOI 10.1093/bioinformatics/btl243; Gopalan V, 2004, NUCLEIC ACIDS RES, V32, pD59, DOI 10.1093/nar/gkh051; GOUY M, 1982, NUCLEIC ACIDS RES, V10, P7055, DOI 10.1093/nar/10.22.7055; Hu JJ, 2005, NUCLEIC ACIDS RES, V33, P4899, DOI 10.1093/nar/gki791; Keich U, 2002, BIOINFORMATICS, V18, P1374, DOI 10.1093/bioinformatics/18.10.1374; KENNEDY K, 1995, IEEE INT C NEUR NETW, V4, P1942; Lim LP, 2001, P NATL ACAD SCI USA, V98, P11193, DOI 10.1073/pnas.201407298; Liu X, 2001, Pac Symp Biocomput, P127; MacIsaac KD, 2006, PLOS COMPUT BIOL, V2, P201, DOI 10.1371/journal.pcbi.0020036; Majewski J, 2002, GENOME RES, V12, P1827, DOI 10.1101/gr.606402; McCullough AJ, 1997, MOL CELL BIOL, V17, P4562; MERINO E, 1992, ORIGINS LIFE EVOL B, V21, P251, DOI 10.1007/BF01809860; Montgomery D. C., 2006, APPL STAT PROBABILIT; Moore MJ, 2000, NAT STRUCT BIOL, V7, P14, DOI 10.1038/71207; Patel AA, 2003, NAT REV MOL CELL BIO, V4, P960, DOI 10.1038/nrm1259; PRIBNOW D, 1975, P NATL ACAD SCI USA, V72, P784, DOI 10.1073/pnas.72.3.784; Reddy CK, 2006, ALGORITHM MOL BIOL, V1, DOI 10.1186/1748-7188-1-23; Roth FP, 1998, NAT BIOTECHNOL, V16, P939, DOI 10.1038/nbt1098-939; Rumelhart D. E., 1986, LEARNING INTERNAL RE, P318; SCHNEIDER TD, 1986, J MOL BIOL, V188, P415, DOI 10.1016/0022-2836(86)90165-8; SHARP PA, 1987, SCIENCE, V235, P766, DOI 10.1126/science.3544217; SHEPHERD JCW, 1981, P NATL ACAD SCI-BIOL, V78, P1596, DOI 10.1073/pnas.78.3.1596; Sinha S, 2006, BIOINFORMATICS, V22, pE454, DOI 10.1093/bioinformatics/btl227; Steiger DM, 1996, EUR J OPER RES, V93, P387, DOI 10.1016/0377-2217(96)00036-7; STORMO GD, 1982, NUCLEIC ACIDS RES, V10, P2971, DOI 10.1093/nar/10.9.2971; Stormo GD, 2000, BIOINFORMATICS, V16, P16, DOI 10.1093/bioinformatics/16.1.16; Tomita M, 1996, MOL BIOL EVOL, V13, P1219; Werbos P., 1974, THESIS HARVARD U CAM; Wu YH, 2003, PHYS REV E, V67, DOI 10.1103/PhysRevE.67.061916; Yao ZZ, 2006, BIOINFORMATICS, V22, P445, DOI 10.1093/bioinformatics/btk008; YOON Y, 1994, DECISION SUPPORT SYS	44	2	2	GRAZ UNIV TECHNOLGOY, INST INFORMATION SYSTEMS COMPUTER MEDIA-IICM	GRAZ	INFFELDGASSE 16C, GRAZ, A-8010, AUSTRIA	0948-695X		J UNIVERS COMPUT SCI	J. Univers. Comput. Sci.		2009	15	4					742	764				23	Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	487NF	WOS:000269280700004	
S	Marchiori, E		Buntine, W; Grobelnik, M; Mladenic, D; ShaweTaylor, J		Marchiori, Elena			Graph-Based Discrete Differential Geometry for Critical Instance Filtering	MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES, PT II	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	Joint European Conference on Machine Learning (ECML)/European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)	SEP 07-11, 2009	Bled, SLOVENIA	Inst Jozef Stefan, Pascal2, Google, Microsoft Res, Yahoo Res, QUINTELLIGENCE, LABS hp, ACTIVE, Machine Learning, Data Min & Knowledge Discovery, Nokia			NEAREST-NEIGHBOR CLASSIFICATION; LEARNING ALGORITHMS; PROTOTYPE SELECTION; CLASSIFIERS; NETWORKS	Graph theory has been shown to provide a powerful tool for representing and tackling machine learning problems, such as clustering semi-supervised learning, and feature ranking. This paper proposes a graph-based discrete differential operator for detecting and eliminating competence-critical instances and class label noise from a training set in order to improve classification performance. Results of extensive experiments on artificial and real-life classification problems substantiate the effectiveness of the proposed approach.	Radboud Univ Nijmegen, Dept Comp Sci, NL-6525 ED Nijmegen, Netherlands	Marchiori, E (reprint author), Radboud Univ Nijmegen, Dept Comp Sci, NL-6525 ED Nijmegen, Netherlands.						ANGIULLI F, 2005, ICML 2005, P25; Angiulli F, 2007, IEEE T KNOWL DATA EN, V19, P1593, DOI 10.1109/TKDE.2007.190665; BARNETT V, 1976, J ROY STAT SOC A STA, V139, P318, DOI 10.2307/2344839; Belkin M, 2002, ADV NEUR IN, V14, P585; Beygelzimer A., 2006, ICML 2006, P97; Brighton H, 1999, LECT NOTES ARTIF INT, V1704, P283; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; CAYTON L, 2007, NIPS, V20; Chang C-C., 2001, LIBSVM LIB SUPPORT V; Chapelle O., 2005, P 10 INT WORKSH ART, P57; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; DASARATHY BV, 1995, OPT ENG, V34, P2785, DOI 10.1117/12.210755; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Domeniconi C, 2005, IEEE T NEURAL NETWOR, V16, P899, DOI 10.1109/TNN.2005.849821; Grother PJ, 1997, PATTERN RECOGN, V30, P459, DOI 10.1016/S0031-3203(96)00098-2; He X., 2005, ADV NEURAL INFORM PR, V18; Luxburg Ulrike, 2007, STAT COMPUT, V17, P395, DOI DOI 10.1007/s11222-007-9033-z; Marchiori E, 2008, J MACH LEARN RES, V9, P997; Pekalska E, 2006, PATTERN RECOGN, V39, P189, DOI 10.1016/j.patcog.2005.06.012; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P507, DOI 10.1016/S0167-8655(97)00035-4; SEBBAN M, 2001, ICML, P505; Sebban M., 2002, J MACHINE LEARNING R, V3, P863; SHIN H, 2007, NEURAL COMPUT, P816; TOUSSAINT GT, 2002, INTERFACE 2002, P83; Vapnik V., 1992, COMPUTATIONAL LEARNI, P144; Vezhnevets A, 2007, LECT NOTES ARTIF INT, V4701, P430; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson D.R., 1997, P 14 INT C MACH LEAR, P403; Zhao Z., 2007, ICML, P1151; Zhou D., 2005, ICML 2005 P 22 INT C, P1036; Zhou DY, 2005, LECT NOTES COMPUT SC, V3663, P361	36	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-04173-0	LECT NOTES ARTIF INT			2009	5782						63	78				16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BMF17	WOS:000272076400005	
S	Martin, JA; de Lope, J; Maravall, D		Mira, J; Ferrandez, JM; Alvarez, JR; DelaPaz, F; Toledo, FJ		Antonio Martin H, Jose; de Lope, Javier; Maravall, Dario			The kNN-TD Reinforcement Learning Algorithm	METHODS AND MODELS IN ARTIFICIAL AND NATURAL COMPUTATION, PT I	Lecture Notes in Computer Science		English	Proceedings Paper	3rd International Work-Conference on the Interplay Between Natural and Artificial Computation	JUN 22-26, 2009	Santiago de Compostela, SPAIN					A reinforcement learning algorithm called kNN-TD is introduced. This algorithm has been developed using the classical formulation of temporal difference methods and a k-nearest neighbors scheme as its expectations memory. By means of this kind of memory the algorithm is able to generalize properly over continuous state spaces and also take benefits from collective action selection and learning processes. Furthermore, with the addition of probability traces, we obtain the kNN-TD(A) algorithm which exhibits a state of the art performance. Finally the proposed algorithm has been tested on a series of well known reinforcement learning problems and also at the Second Annual RL Competition with excellent results.	[Antonio Martin H, Jose] Univ Complutense Madrid, Dep Sistemas Informat & Computac, E-28040 Madrid, Spain	Martin, JA (reprint author), Univ Complutense Madrid, Dep Sistemas Informat & Computac, E-28040 Madrid, Spain.	jamartinh@fdi.ucm.es; javier.delope@upm.es; dmaravall@fi.upm.es	Martin H., Jose Antonio/A-2388-2009				Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; BOSMAN S, 1996, THESIS U AMSTERDAM; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Gordon Geoff, 1995, ICML, P261; Indyk P., 1998, STOC, P604; Martin JAH, 2007, LECT NOTES COMPUT SC, V4739, P138; Singh SP, 1996, MACH LEARN, V22, P123, DOI 10.1023/A:1018012322525; Sutton R. S., 1998, REINFORCEMENT LEARNI; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698	11	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-02263-0	LECT NOTES COMPUT SC			2009	5601						305	314				10	Computer Science, Cybernetics; Computer Science, Theory & Methods	Computer Science	BKT63	WOS:000269203400032	
B	Fehlman, WL; Hinders, MK	Fehlman, WL; Hinders, MK			Fehlman, William L., II; Hinders, Mark K.	Fehlman, WL; Hinders, MK		Thermal Feature Selection	MOBILE ROBOT NAVIGATION WITH INTELLIGENT INFRARED IMAGE INTERPRETATION			English	Article; Book Chapter							NEAREST-NEIGHBOR CLASSIFICATION; DENSITY-FUNCTION; RECOGNITION; CHOICE	In this chapter, we evaluate the performance of various classification models to identify the most favorable feature vectors for our extended and compact objects. We will show that there is no single "optimal" feature vector but a set of "most favorable" feature vectors associated with various classifiers for both the extend and compact object classes. Moreover, the most favorable feature vectors are those that contain contributions from all the feature types - meteorological, micro, and macro.	[Fehlman, William L., II] US Mil Acad, Dept Math Sci, West Point, NY 10996 USA; [Hinders, Mark K.] Coll William & Mary, Dept Appl Sci, Williamsburg, VA 23187 USA	Fehlman, WL (reprint author), US Mil Acad, Dept Math Sci, West Point, NY 10996 USA.	william.f'ehlmanii@us.army.mil; hinders@as.wm.edu					Bishop C. M., 1995, NEURAL NETWORKS PATT; BULUSWAR SD, 1998, INT J ENG APPL ARTIF, V1, P245; Buluswar SD, 2002, COMPUT VIS IMAGE UND, V85, P71, DOI 10.1006/cviu.2001.0950; Burnham K. P., 2002, MODEL SELECTION MULT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Devijver P. A., 1982, PATTERN RECOGNITION; Devroye L, 1996, PROBABILISTIC THEORY; Duda R., 1973, PATTERN CLASSIFICATI; Duda R. O., 2001, PATTERN CLASSIFICATI; Duin R.P.W., 2004, PRTOOLS4 MATLAB TOOL; ENAS GG, 1986, COMPUT MATH APPL-A, V12, P235, DOI 10.1016/0898-1221(86)90076-3; FISHER RA, 1922, T ROYAL SOC LONDON A, V222, P309; Fix E, 1951, DISCRIMINATORY ANAL; Fix E., 1952, DISCRIMINATORY ANAL; Fukunaga K., 1990, INTRO STAT PATTERN R; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; Ghosh AK, 2006, COMPUT STAT DATA AN, V50, P3113, DOI 10.1016/j.csda.2005.06.007; Hand D. J., 1981, DISCRIMINATION CLASS; Holst GC, 2000, COMMON SENSE APPROAC; Hyvarinen A., 2001, INDEPENDENT COMPONEN; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; Maldague X., 2001, THEORY PRACTICE INFR; Manduchi R, 2005, AUTON ROBOT, V18, P81, DOI 10.1023/B:AURO.0000047286.62481.1d; MILLIGAN GW, 1988, J CLASSIF, V5, P181, DOI 10.1007/BF01897163; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Patrick E. A., 1972, FUNDAMENTALS PATTERN; Polikar R., 2006, WILEY ENCY BIOMEDICA; Theodoridis S, 2006, PATTERN RECOGNITION, 3RD EDITION, P1; van der Heijden F., 2004, CLASSIFICATION PARAM; Vicente MA, 2007, IEEE T PATTERN ANAL, V29, P896, DOI [10.1109/TPAMI.2007.1074, 10.1109/TPAMI.2007.1025]; Webb A., 2002, STAT PATTERN RECOGNI	33	0	0	SPRINGER-VERLAG LONDON LTD	GODALMING	SWEETAPPLE HOUSE CATTESHALL RD FARNCOMBE, GODALMING GU7 1NH, SURREY, ENGLAND		978-1-84882-508-6				2009							95	159			10.1007/978-1-84882-509-3	65	Computer Science, Artificial Intelligence; Robotics; Physics, Applied	Computer Science; Robotics; Physics	BMH15	WOS:000272325400004	
J	Montagnuolo, M; Messina, A				Montagnuolo, Maurizio; Messina, Alberto			Parallel neural networks for multimodal video genre classification	MULTIMEDIA TOOLS AND APPLICATIONS			English	Article						Video annotation; Genre recognition; Neural network; Feature extraction; Multimedia semantics	CATEGORIZATION; RECOGNITION; MODELS	Improvements in digital technology have made possible the production and distribution of huge quantities of digital multimedia data. Tools for high-level multimedia documentation are becoming indispensable to efficiently access and retrieve desired content from such data. In this context, automatic genre classification provides a simple and effective solution to describe multimedia contents in a structured and well understandable way. We propose in this article a methodology for classifying the genre of television programmes. Features are extracted from four informative sources, which include visual-perceptual information (colour, texture and motion), structural information (shot length, shot distribution, shot rhythm, shot clusters duration and saturation), cognitive information (face properties, such as number, positions and dimensions) and aural information (transcribed text, sound characteristics). These features are used for training a parallel neural network system able to distinguish between seven video genres: football, cartoons, music, weather forecast, newscast, talk show and commercials. Experiments conducted on more than 100 h of audiovisual material confirm the effectiveness of the proposed method, which reaches a classification accuracy rate of 95%.	[Montagnuolo, Maurizio] Univ Turin, Dept Comp Sci, I-10149 Turin, Italy; [Messina, Alberto] RAI Radiotelevis Italiana, Ctr Res & Technol Innovat, I-10135 Turin, Italy	Montagnuolo, M (reprint author), Univ Turin, Dept Comp Sci, Corso Svizzera 185, I-10149 Turin, Italy.	montagnuolo@di.unito.it; a.messina@rai.it					ALBIOL A, 2004, INT WORKSH IM AN MUL; Bellman R., 1961, ADAPTIVE CONTROL PRO; BLUM DW, 1992, Patent No. 5151788; BOGGS J, 2006, ART WATCHING FILMS T; BRUGNARA F, 2000, RIAO CONTENT BASED M; CALIC J, 2004, THESIS U LONDON; CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842; CHENG W, 2006, 8 INT C ADV CONC INT, P1210; Covell M, 2006, IEEE WORKSH MULT SIG, P461; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DIMITROVA N, 2000, EUR C SIGN PROC TAMP; DIMITROVA N, 2002, P 9 INT C INF PROC M, P481; DINH PQ, 2002, ACCV2002; Dorado A, 2004, IEEE T CIRC SYST VID, V14, P622, DOI 10.1109/TCSVT.2004.826764; FISCHER S, 1995, ACM MULTIMEDIA 1995, P295; GLASBERG R, 2005, 13 EUR SIGN PROC C E; GOH KS, 2004, 2004008 MERL; IANEVA TJ, 2003, INT C MULT EXP BALT, P449; Igel C., 2000, P 2 INT S NEUR COMP; Jolliffe I. T., 2002, PRINCIPAL COMPONENT; Liu Z, 1998, IEEE WORKSH MULT SIG, P27; Liu Z., 1997, IEEE 1 WORKSH MULT S, P343; LOIACONO A, 2005, TECHNICAL REV EBU, V303; MESSINA A, 2008, IEEE INT C MULT EXP; Messina A., 2006, IEEE INT C SIGN IM T; MESSINA A, 2008, INT WORKSH AMB MED D; MONTAGNUOLO M, 2008, 2 INT WORKSH MULT DA; Montagnuolo M, 2007, DEXA 2007: 18TH INTERNATIONAL CONFERENCE ON DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS, P99; Montagnuolo M., 2007, Journal of Digital Information Management, V5; NOVAK AP, 1988, Patent No. 4750213; PARNAL S, 2003, TV ANYTIME NEW STAND; POLI JP, 2006, CIMCA 06, P31; Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, DOI 10.1109/MCAS.2006.1688199; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; ROACH M, 2001, INT S INT MULT, P146; ROACH MJ, 2002, THESIS U WALES SWANS; Roach MJ, 2001, INT CONF ACOUST SPEE, P1557, DOI 10.1109/ICASSP.2001.941230; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458; Sanchez J. M., 1999, Visual Information and Information Systems. Third International Conference, VISUAL'99. Proceedings (Lecture Notes in Computer Science Vol.1614); Satterwhite B, 2004, IEEE POTENTIALS, V23, P9, DOI 10.1109/MP.2004.1309790; Snoek CGM, 2005, MULTIMED TOOLS APPL, V25, P5, DOI 10.1023/B:MTAP.0000046380.27575.a5; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; TAKAGI S, 2003, INT C MULT EXP BALT, P461; TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999; Taskiran C. M., 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4676, DOI 10.1117/12.451098; TASKIRAN CM, 2003, 8 INT WORKSH VIS CON, P84; Tekalp M., 1995, DIGITAL VIDEO PROCES; TOMASI C, 2005, ESTIMATING GAUSSIAN; Truong BT, 2000, INT C PATT RECOG, P230; Vakkalanka S., 2005, ICISIP 05, P187; Vapnik V, 1999, NATURE STAT LEARNING; Vasconcelos N, 2000, IEEE T IMAGE PROCESS, V9, P3, DOI 10.1109/83.817595; VROOMEN J, 1993, EUROSPEECH 93 BERL S, P577; Wang J, 2006, J CHEM THEORY COMPUT, V2, P18, DOI 10.1021/ct050118b; Wickenberg-Bolin U, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-127; Xu L.-Q., 2003, IEEE INT C MULT EXP, P485; Yuan X, 2006, IEEE IMAGE PROC, P2905, DOI 10.1109/ICIP.2006.313037; YUAN Y, 2002, IEEE 1 INT C MACH LE, V3, P1153; ZHIWEN Y, 2004, IEEE INT C INF TECHN, P658; *EBU UER, 2007, TECHN REV EBU, V3322	62	9	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1380-7501		MULTIMED TOOLS APPL	Multimed. Tools Appl.	JAN	2009	41	1					125	159		10.1007/s11042-008-0222-3		35	Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	387LJ	WOS:000261953400006	
B	Jo, T			IEEE	Jo, Taeho			Automatic Text Categorization using NTC	NDT: 2009 FIRST INTERNATIONAL CONFERENCE ON NETWORKED DIGITAL TECHNOLOGIES			English	Proceedings Paper	1st International Conference on Networked Digital Technologies (NDT 2009)	JUL 28-31, 2009	Ostrava, CZECH REPUBLIC	IEEE Commun Soc	VSB Tech Univ Ostrava, Fac Elect Engn & Comp Sci		SUPPORT VECTOR MACHINES; CLASSIFICATION	In this research, we propose NTC (Neural Text Categorizer) as the approach to text categorization. Traditional approaches to text categorization require encoding documents into numerical vectors which leads to the two main problems: huge dimensionality and sparse distribution in each numerical vector. In this research, documents are encoded into string vectors instead of numerical vectors, and a new neural network called NTC which receive a string vector as its input vector is used for text categorization. The goal of this research is to avoid the two main problems by encoding documents into alternative structured data to numerical vectors. We will validate the performance of NTC by comparing it with other machine learning algorithms on the standard test bed, Reuter 21578.	Inha Univ, Sch Comp & Informat Engn, Inchon, South Korea	Jo, T (reprint author), Inha Univ, Sch Comp & Informat Engn, Inchon, South Korea.	tjo018@inha.ac.kr					Burr Ridge I, 1997, MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N., 2000, SUPPORT VECTOR MACHI; Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; Estabrooks A, 2004, COMPUT INTELL, V20, P18, DOI 10.1111/j.0824-7935.2004.t01-1-00228.x; Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428; Joachims T., 1998, P 10 EUR C MACH LEAR, P143; Kononenko I., 1989, P 4 EUR WORK SESS LE, P91; Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687; Massand B., 1992, P 15 ACM INT C RES D, P59; McClelland J. L, 1986, PARALLEL DISTRIBUTED, V1; McClelland JL, 1986, PARALLEL DISTRIBUTED, V2; Mladenic D., 1999, P INT C MACH LEARN, P256; Ruiz ME, 2002, INFORM RETRIEVAL, V5, P87, DOI 10.1023/A:1012782908347; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Wiener E.D., 1995, THESIS U COLORADO; Yang Y., 1999, INFORMATION RETRIEVA, V1, P67	17	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-4614-8				2009							26	31				6	Computer Science, Information Systems	Computer Science	BPQ76	WOS:000279656200006	
B	Kam-Art, R; Raicharoen, T; Khera, V			IEEE	Kam-Art, Rojana; Raicharoen, Thanapant; Khera, Varin			Face Recognition using Feature Extraction based on Descriptive Statistics of a Face Image	PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-6			English	Proceedings Paper	International Conference on Machine Learning and Cybernetics	JUL 12-15, 2009	Baoding, PEOPLES R CHINA	Hebei Univ, IEEE Syst, Man & Cybernet Soc, Chongqing Univ, S China Univ Technol, Hong Kong Baptist Univ, Hebei Univ Sci & Technol			EIGENFACES	This paper proposes a new method of feature extraction for face recognition based on descriptive statistics of a face image. Our method works by first converting the face image with all the corresponding face components such as eyes, now, and mouth to a grayscale images. The features are then extracted from the grayscale image, based on a descriptive statistics of the image and its corresponding face components. The edges of a face image and its corresponding face components are detected by using the canny algorithm. In the recognition step, different classifiers such as Multi Layer Perceptron (MLP), Support Vector Machine (SVM), k-Nearest Neighbors (k-NN) and Pairwise Opposite Class-Nearest Neighbor (POC-NN) can be used for face recognition. We evaluated our method with more conventional Eigenface method bawd upon the AT&T and Yale face databases. The evaluation clearly confirm that for both databases our proposed method yields a higher recognition rate and requires less computational time than the Eigenface method.	[Kam-Art, Rojana; Raicharoen, Thanapant] Eartern Asia Univ, Fac Informat Technol, Thanyaburi, Pathumthani, Thailand	Kam-Art, R (reprint author), Eartern Asia Univ, Fac Informat Technol, Thanyaburi, Pathumthani, Thailand.	rojana@eau.ac.th; thanapant@eau.ac.th; varin.khera@nsn.com					Bartlett MS, 1998, P SOC PHOTO-OPT INS, V3299, P528; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679; CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Franc V, 2004, STAT PATTERN RECOGNI; GALTON F, 1888, NATURE          0621, P269; Hakin S., 1999, NEURAL NETWORKS COMP; Hastie T. J., 2001, SPRINGER SERIES STAT; KANADE T, 1973, FACE RECOGNITION PIC; Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195; Moghaddam B., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, DOI 10.1109/ICCV.1999.790407; OMIDVARNIA AH, EIGENFACE FACE RECOG; RAICHAROEN T, 2005, PATTERN RECOGN, V16, P1554; SAMAL A, 1992, PATTERN RECOGN, V25, P65, DOI 10.1016/0031-3203(92)90007-6; SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519; Stonham T., 1984, ASPECTS FACE PROCESS, P426; SUNG KK, 1995, COMPUTER ANAL IMAGES, P432; Tolba A.S., 2006, INT J SIGNAL PROCESS, V2, P88; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; VALENTIN D, 1994, PATTERN RECOGN, V27, P1209, DOI 10.1016/0031-3203(94)90006-X; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; AT T DATABASE FACE; YALE DATABASE	26	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-4705-3				2009							193	197				5	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	BQS31	WOS:000281720400036	
B	Mignani, AG; Cucci, C; Ciaccheri, L; Dall'Asta, C; Galaverna, G; Dossena, A; Marchelli, R		DiNatale, C; DAmico, A; Martinelli, E; Paolesse, R		Mignani, A. G.; Cucci, C.; Ciaccheri, L.; Dall'Asta, C.; Galaverna, G.; Dossena, A.; Marchelli, R.			FLUORESCENCE SPECTROSCOPY FOR THE DETECTION OF M1 AFLATOXIN IN MILK	PROCEEDINGS OF THE 13TH ITALIAN CONFERENCE ON SENSORS AND MICROSYSTEMS			English	Proceedings Paper	13th Italian Conference on Sensors and Microsystems	FEB 19-21, 2008	Rome, ITALY					Fluorescence spectroscopy carried out by means of optical fibers was used for the rapid screening of M1 aflatoxin in milk, enabling the detection of concentrations up to the legal limit, which is 50 ppt. A compact fluorometric device equipped with an LED source, a miniaturized spectrometer, and optical fibers for illumination/detection of the measuring micro-cell was tested for measuring threshold values of AFM1 in pre-treated milk samples. Multivariate processing of the spectral data made it possible to obtain a preliminary screening at the earlier stages of the industrial process, as well as to discard contaminated milk stocks before their inclusion in the production chain.	[Mignani, A. G.; Cucci, C.; Ciaccheri, L.] CNR, IFAC, I-50019 Sesto Fiorentino, FI, Italy	Mignani, AG (reprint author), CNR, IFAC, Via Madonna Piano 10, I-50019 Sesto Fiorentino, FI, Italy.		Dall'Asta, Chiara/C-3173-2008	Dall'Asta, Chiara/0000-0003-0716-8394			Bertran E, 2001, ANAL CHIM ACTA, V431, P303, DOI 10.1016/S0003-2670(00)01328-3; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cucci C, 2007, SENSOR ACTUAT B-CHEM, V126, P467, DOI 10.1016/j.snb.2007.03.036; Magan N., 2004, MYCOTOXINS FOOD DETE; Martens H, 2001, MULTIVARIATE ANAL QU; WEIDENBOMER M, 2001, ENCY FOOD MYCOTOXINS; *FAO, 2003, WORLDW REG MYC FOOD, V81	7	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	PO BOX 128 FARRER RD, SINGAPORE 9128, SINGAPORE		978-981-283-597-0				2009							366	371				6	Engineering, Electrical & Electronic; Nanoscience & Nanotechnology; Remote Sensing	Engineering; Science & Technology - Other Topics; Remote Sensing	BIY69	WOS:000263783800060	
B	Pan, F; Wang, JD; Lin, XH			IEEE	Pan, Feng; Wang, Jiandong; Lin, Xiaohui			Feature Extraction Algorithm Based on K Nearest Neighbor Local Margin	PROCEEDINGS OF THE 2009 CHINESE CONFERENCE ON PATTERN RECOGNITION AND THE FIRST CJK JOINT WORKSHOP ON PATTERN RECOGNITION, VOLS 1 AND 2			English	Proceedings Paper	Chinese Conference on Pattern Recognition/1st CJK Joint Workshop on Pattern Recognition	NOV 04-06, 2009	Nanjing, PEOPLES R CHINA			feature extraction; margin; linear discriminant analysis	FACE RECOGNITION	Feature extraction is the transformation of high-dimensional data into a meaningful representation of reduced dimensionality. The representation extracted are often beneficial to mitigate the computational complexity and improve the accuracy of a particular classifier. In this paper we introduce a novel feature extraction algorithm called K nearest neighbor local margin maximization and apply it to measure the quality of the reduced features in the context of supervised classification problems. Using the concept of the hypothesis margin, we aim to find a discriminant subspace in which each projected point is well separated from the affine hull of its K local nearest neighbors. The experimental results on three high dimensional data sets demonstrate the effectiveness of our algorithm.	[Pan, Feng; Wang, Jiandong] Nanjing Univ Aeronaut & Astronaut, Coll Informat Sci & Technol, Nanjing 210016, Jiangsu, Peoples R China	Pan, F (reprint author), Nanjing Univ Aeronaut & Astronaut, Coll Informat Sci & Technol, Nanjing 210016, Jiangsu, Peoples R China.	stridence@gmail.com					Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Cevikalp H, 2005, IEEE T PATTERN ANAL, V27, P4, DOI 10.1109/TPAMI.2005.9; CEVIKALP H, P 25 INT C MACH LEAR; Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAMMER K, 2003, ADV NEURAL INFORM PR, P462; Fukunaga K., 1990, INTRO STAT PATTERN R; GILADBACHRACH R, 2004, P 21 INT C MACH LEAR, V69, P43; Golub G., 1996, MATRIX COMPUTATIONS; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; Kocsor A, 2004, LECT NOTES COMPUT SC, V3201, P227; Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852; Sun Y., 2006, P 23 ACM INT C MACH, V148, P913; VINCENT P, 2001, ADV NEURAL INFORM PR, P985; WEINBERGER K, ADV NEURAL INFORM PR, P1473; Xing E, 2003, ADV NEURAL INFORM PR, P505; Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X	18	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-4199-0				2009							20	24				5	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BOY30	WOS:000278039800005	
S	Leite, P; Teixeira, JM; Farias, T; Teichrieb, V; Kelner, J			IEEE	Leite, Pedro; Teixeira, Joao M.; Farias, Thiago; Teichrieb, Veronica; Kelner, Judith			Massively Parallel Nearest Neighbor Queries for Dynamic Point Clouds on the GPU	PROCEEDINGS OF THE 21ST INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE AND HIGH PERFORMANCE COMPUTING	International Symposium on Computer Architecture and High Performance Computing		English	Proceedings Paper	21st International Symposium on Computer Architecture and High Performance Computing	OCT 28-31, 2009	Sao Paulo, BRAZIL	Brazilian Comp Soc, IEEE Comp Soc, Tech Comm Comp Architecture, Scalable Comp, IFIP, Brazilian Govt Agcy, CAPES, FAPESP		nearest neighbor query; massive parallel programming; KNN; ANN	ALGORITHM	We introduce a parallel algorithm to solve approximate and exact nearest neighbor queries on the GPU, exploiting its massively parallel processing power. Both data structure construction and nearest neighbor queries are performed on the GPU, avoiding memory copies from system memory to device memory. This algorithm achieves real-time performance, enabling its usage in dynamic scenarios, by minimizing the sorting comparisons needed for a large K value. The underlying data structure for spatial subdivision handles 3D points and is based on grid spatial hashing. Users can specify the grid size interactively. Comparisons were done with other nearest neighbor algorithms implemented on both CPU and GPU. Our approach clearly surpasses CPU implementations regarding processing time, while it presents a competitive solution to GPU ones. Real-time results were obtained with ANN searches (K = 10) for data sets up to 163K points and the potential of our algorithm is demonstrated through a point-based rendering application.	[Leite, Pedro; Teixeira, Joao M.; Farias, Thiago; Teichrieb, Veronica; Kelner, Judith] Univ Fed Pernambuco, Ctr Comp Sci, Virtual Real & Multimedia Res Grp, Recife, PE, Brazil	Leite, P (reprint author), Univ Fed Pernambuco, Ctr Comp Sci, Virtual Real & Multimedia Res Grp, Recife, PE, Brazil.	pjsl@cin.ufpe.br; jmxnt@cin.ufpe.br; tsmcf@cin.ufpe.br; vt@cin.ufpe.br; jk@cin.ufpe.br					Adams B, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276437, 10.1145/1239451.1239499]; Alexa M, 2001, IEEE VISUAL, P21; Alexa M., 2004, SIGGRAPH 04 ACM SIGG, P7; Anderson JA, 2008, J COMPUT PHYS, V227, P5342, DOI 10.1016/j.jcp.2008.01.047; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Botsch M., 2005, Point-Based Graphics 2005 (IEEE Cat. No. 05EX1159), DOI 10.1109/PBG.2005.194059; CLARENZ U, 2004, S POINT BAS GRAPH 20; Connor M., 2008, P VOL POINT BAS GRAP, P25; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CURTIS S, 2008, 13D 08, P61; Harris M., 2009, OPTIMIZING PARALLEL; Jensen H. W., 2001, REALISTIC IMAGE SYNT; Knuth D. E., 1998, ART COMPUTER PROGRAM, V3; Lacoste J, 2007, GRAPHITE 2007: 5TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS AND INTERACTIVE TECHNIQUES IN AUSTRALASIA AND SOUTHERN ASIA, PROCEEDINGS, P87; Levin D, 2003, GEOMETRIC MODELING S, P37; Levoy M., 1985, 85022 U N CAR CHAP H; LIN KI, 2001, DASFAA 01, P174; Losasso F., 2004, SIGGRAPH 04, P457, DOI DOI 10.1145/1186562.1015745; Mitra NJ, 2003, S COMP GEOM, P322; NVIDIA, 2009, COMP UN DEV ARCH PRO; Pantazopoulos I, 2002, J INTELL ROBOT SYST, V35, P123, DOI 10.1023/A:1021175220384; Pauly M, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P163, DOI 10.1109/VISUAL.2002.1183771; Pharr M., 2004, PHYS BASED RENDERING; SAFAR M, 2005, MOB INF SYST, V1; Samet H., 2005, M KAUFMANN SERIES CO; Sankaranarayanan J, 2007, COMPUT GRAPH-UK, V31, P157, DOI 10.1016/j.cag.2006.11.011; SENUPTA S, 2007, GH 07, P97; Teschner M, 2003, VISION, MODELING, AND VISUALIZATION 2003, P47; Zhou K., 2008, SIGGRAPH ASIA 08, P1; GA DYNAMIC SAMPLING	30	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-6533	978-0-7695-3857-0	INT SYM COMP ARCHIT			2009							19	25		10.1109/SBAC-PAD.2009.18		7	Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	BNK61	WOS:000274804600003	
B	Chaudhari, BM; Barhate, AA; Bhole, AA			Allied Publishers PVT LTD	Chaudhari, Bhupendra M.; Barhate, Atul A.; Bhole, Anita A.			Signature Recognition using Fuzzy Min-Max Neural Network	PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION, COMMUNICATION AND ENERGY CONSERVATION INCACEC 2009 VOL 1			English	Proceedings Paper	International Conference on Control, Automation, Communication and Energy Conservation	JUN 04-06, 2009	Perundurai, INDIA	Kongu Vellar Inst Tech Trust, IEEE, Inst Elect Telecomm Engn, Council Sci Indust Res, Freescale Semiconductor Inc, Trident Techlabs Pvt ltd, Mighty Electr Equipment Corp	Kongu Engn Coll	Signature verification; fuzzy min-max neural network; classification; moment invariant; neural network for category learning	PATTERN-CLASSIFICATION	The signature recognition system has been inspired from the human capability to recognize any pattern, which is a very difficult task for normal computer system having computing power of more then billions instructions per second. In this system the input is given in the form of a digital image by using writing pad, optical scanner, or Digital camera. This input image is processed to extract the information by using data acquisition and HU's seven moment invariant [21] to the order of three. Then the fuzzy min-max algorithm can applied to classify the signature pattern and this fuzzy min-max algorithm [1] is totally fit to the neural network framework. The neural network middle layer is work as fuzzified neuron and because of this the output can be correctly classified Use of fuzzy membership function is increase the accuracy of the classification of signature pattern because the decision boundaries are not crisp rather it is fuzzy. The neural network is designed for this work is for the category learning which can increase the speed of recognition because in this fuzzy min-max neural network [1] the supervised learning algorithm is used also it can learn nonlinear class boundaries in a single pass through the data and provides the ability to incorporate new and refute existing classes without retraining. The advantage of our system is its accuracy in recognizing signature is nearly 53% for single signature pattern per class and if the signature pattern per class are increased then the accuracy is increased up to 92% because patterns per class with slighter changes in it can increase the recognition efficiency naturally and there is no increase in training time because the neural network used is for category learning in which the dataset & index of the class is used for training.	[Chaudhari, Bhupendra M.] Dept Godavari COE, E&Tc Engn, Jalgaon, India	Chaudhari, BM (reprint author), Dept Godavari COE, E&Tc Engn, Jalgaon, India.	Bhupendra_scorpion29@rediffmail.com; atbarhate@yahoo.co.in; bholeanita@yahoo.co.in					BELLMAN R, 1964, RM4307PR RAND; BELLMAN R, 1966, J MATH ANAL APPL, V13, P1, DOI 10.1016/0022-247X(66)90071-0; BEZDEK, 1991, PATTERNS RECOGNITION; BEZDEK J, 1991, IEEE C NEUR NET OC E; BEZDEK J, 1996, FUZZY SETS SYSTEMS, V18, P237; Carpenter G, 1991, P INT JOINT C NEUR N, V2, P411; CARPENTER G, NEURAL NETWORKS, V4, P565; COTTER N, 1991, IEEE T NEURAL NETWOR, V1, P290; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; Gabrys B, 2000, IEEE T NEURAL NETWOR, V11, P769, DOI 10.1109/72.846747; HU M, 1962, IRE T INFORM THEOR, V8, P179; NANDEDKAR AV, 2004, P 17 INT C PATT REC, V4, P553, DOI 52228650,12,1; SIMPSON P, P 1991 INT JOINT C N; SIMPSON P, 2002, IEEE T FUZZY S UNPUB; SIMPSON PK, 1992, IEEE T NEURAL NETWOR, V3, P776, DOI 10.1109/72.159066; SIMPSON PK, 1991, HEURISTICS J KNOWLED, V4, P1; Simpson PK, 1990, ARTIFICIAL NEURAL SY; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; YAGER RR, 1979, INT J MAN MACH STUD, V11, P189, DOI 10.1016/S0020-7373(79)80016-4; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	21	0	0	ALLIED PUBLISHERS LTD	NEW DELHI	13-14 ASAF ALI ROAD, NEW DELHI 110002, INDIA		978-81-8424-439-7				2009							242	248				7	Automation & Control Systems; Engineering, Electrical & Electronic	Automation & Control Systems; Engineering	BRI36	WOS:000282769800044	
S	Garcia-Borroto, M; Villuendas-Rey, Y; Carrasco-Ochoa, JA; Martinez-Trinidad, JF		BayroCorrochano, E; Eklundh, JO		Garcia-Borroto, Milton; Villuendas-Rey, Yenny; Ariel Carrasco-Ochoa, Jesus; Fco. Martinez-Trinidad, Jose			Finding Small Consistent Subset for the Nearest Neighbor Classifier Based on Support Graphs	PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS, COMPUTER VISION, AND APPLICATIONS, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	14th Iberoamerican Congress on Pattern Recognition	NOV 15-18, 2009	Guadalajara, MEXICO	Mexican Assoc Comp Vis, Neurocomp & Robot, Int Assoc Pattern Recognit, Cuban Assoc Pattern Recognit, Chilean Assoc Pattern Recognit, Brizilian Comp Soc Special Interest Grp, Spanish Assoc Pattern Recognit, Portuguese Assoc Pattern Recognit, CINVESTAV, IEEE GRSS, CoecytJal, INTEL Educ, Gobierno Municipal, Direcc Turismo Guadalajara, Oficina Vistantes & Convenciones Guadalajara		nearest neighbor; condensing; prototype selection; minimal consistent subset	RULE	Finding a minimal subset of objects that correctly classify the training set for the nearest neighbors classifier has been an active research area in Pattern Recognition and Machine Learning communities for decades. Although finding the Minimal Consistent Subset is not feasible in many real applications, several authors have proposed methods to find small consistent subsets. In this paper, we introduce a novel algorithm for this task, based on support graphs. Experiments over a wide range of repository databases show that our algorithm finds consistent subsets with lower cardinality than traditional methods.	[Garcia-Borroto, Milton] UNICA, Bioplantas Ctr, C De Avila, Cuba	Garcia-Borroto, M (reprint author), UNICA, Bioplantas Ctr, Carretera Moron Km 9 1-2, C De Avila, Cuba.	mil@bioplantas.cu; yennyv@bioplantas.cu; ariel@inaoep.mx; fmartine@inaoep.mx					ATHITSOS V, 2006, THESIS BOSTON U, P156; CHOU CH, 2006, 18 INT C PATT REC IC; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Garcia-Borroto M, 2005, LECT NOTES COMPUT SC, V3773, P450; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Kuncheva L., 2004, COMBINING PATTERN CL; MERZ CJ, 1998, UC1 REPOSITORY MACHI; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; WILFONG G, 1991, 7 ANN ACM S COMP GEO, P224; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	13	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-10267-7	LECT NOTES COMPUT SC			2009	5856						465	472				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BPQ26	WOS:000279629500054	
S	Garcia-Borroto, M; Villuendas-Rey, Y; Carrasco-Ochoa, JA; Martinez-Trinidad, JF		BayroCorrochano, E; Eklundh, JO		Garcia-Borroto, Milton; Villuendas-Rey, Yenny; Ariel Carrasco-Ochoa, Jesus; Fco. Martinez-Trinidad, Jose			Using Maximum Similarity Graphs to Edit Nearest Neighbor Classifiers	PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS, COMPUTER VISION, AND APPLICATIONS, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	14th Iberoamerican Congress on Pattern Recognition	NOV 15-18, 2009	Guadalajara, MEXICO	Mexican Assoc Comp Vis, Neurocomp & Robot, Int Assoc Pattern Recognit, Cuban Assoc Pattern Recognit, Chilean Assoc Pattern Recognit, Brizilian Comp Soc Special Interest Grp, Spanish Assoc Pattern Recognit, Portuguese Assoc Pattern Recognit, CINVESTAV, IEEE GRSS, CoecytJal, INTEL Educ, Gobierno Municipal, Direcc Turismo Guadalajara, Oficina Vistantes & Convenciones Guadalajara		nearest neighbor; error-based editing; prototype selection	PATTERN-CLASSIFICATION; RULES	The Nearest Neighbor classifier is a simple but powerful non-parametric technique for supervised classification. However, it is very sensitive to noise and outliers, which could decrease the classifier accuracy. To overcome this problem, we propose two new editing methods based on maximum similarity graphs. Numerical experiments in several databases show the high quality performance of our methods according to classifier accuracy.	[Garcia-Borroto, Milton] UNICA, Bioplantas Ctr, C De Avila, Cuba	Garcia-Borroto, M (reprint author), UNICA, Bioplantas Ctr, Carretera Moron Km 9 1-2, C De Avila, Cuba.	mil@bioplantas.cu; yennyv@bioplantas.cu; ariel@inaoep.mx; fmartine@inaoep.mx					Caballero Y., 2007, INT J COMPUTATIONAL, V3, P219; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Devijver P.A., 1980, 5TH P INT C PATT REC, P72; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Hattori K, 2000, PATTERN RECOGN, V33, P521, DOI 10.1016/S0031-3203(99)00068-0; KOPLOWITZ J, 1981, PATTERN RECOGN, V13, P251, DOI 10.1016/0031-3203(81)90102-3; Kuncheva L., 2004, COMBINING PATTERN CL; Merz C.J., 1998, UCI REPOSITORY MACHI; Pons-Porrata A, 2007, INFORM PROCESS MANAG, V43, P752, DOI 10.1016/j.ipm.2006.06.001; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; TOUSSAINT G, 2002, 34 S COMP STAT INTER, P1; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	14	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-642-10267-7	LECT NOTES COMPUT SC			2009	5856						489	496				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BPQ26	WOS:000279629500057	
B	Kaya, GT; Ersoy, OK; Kamasak, ME		Kurnaz, S; Ince, F; Onbasioglu, S; Basturk, S		Kaya, Guelsen Taskin; Ersoy, Okan K.; Kamasak, Mustafa E.			Support Vector Selection and Adaptation and Its Application in Remote Sensing	RAST 2009: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN SPACE TECHNOLOGIES			English	Proceedings Paper	4th International Conference on Recent Advances in Space Technologies	JUN 11-13, 2009	Istanbul, TURKEY	turkish Air Force Acad, Istanbul Tech Univ, Bogazici Univ, Marmara Univ, Bahcesehir Univ, Istanbul Commerce Univ, Halic Univ, Yeditepe Univ, IEEE, AIAA		Support Vector Machines; Classification of Remote Sensing Data; Support Vector Machines; Support Vector Selection and Adaptation	CLASSIFICATION	Classification of nonlinearly separable data by nonlinear support vector machines is often a difficult task, especially due to the necessity of a choosing a convenient kernel type. Moreover, in order to get high classification accuracy with the nonlinear SVM, kernel parameters should be determined by using a cross validation algorithm before classification. However, this process is time consuming. In this study, we propose a new classification method that we name Support Vector Selection and Adaptation (SVSA). SVSA does not require any kernel selection and it is applicable to both linearly and nonlinearly separable data. The results show that the SVSA has promising performance that is competitive with the traditional linear and nonlinear SVM methods.	[Kaya, Guelsen Taskin; Kamasak, Mustafa E.] Istanbul Tech Univ, TR-80626 Istanbul, Turkey	Kaya, GT (reprint author), Istanbul Tech Univ, TR-80626 Istanbul, Turkey.	gtaskink@purdue.edu; ersoy@purdue.edu; kamasak@itu.edu.tr					BENEDIKTSSON JA, 1990, IEEE T GEOSCI REMOTE, V28, P540, DOI 10.1109/TGRS.1990.572944; Chang C-C., 2001, LIBSVM LIB SUPPORT V; COURANT R, 1953, METHODS MATH PHYS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Kasapoglu NG, 2007, IEEE T GEOSCI REMOTE, V45, P3880, DOI 10.1109/TGRS.2007.900699; Kaya S, 2005, INT J REMOTE SENS, V26, P2731, DOI 10.1080/01431160500099428; Kohonen T., 1992, P INT JOINT C NEUR N, V1, P725, DOI 10.1109/IJCNN.1992.287101; Kohonen T, 1986, TKKFA601 HELS U TECH; Melgani Farid, 2004, IEEE T GEOSCIENCE RE, V42; SHMILOVICI GA, 2005, DATA MINING KNOWLEDG; [Yue Shihong 岳士弘], 2003, Applied Mathematics. Series B : A Journal of Chinese Universities, V18, P332, DOI 10.1007/s11766-003-0059-5	11	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-3626-2				2009							408	412				5	Engineering, Aerospace	Engineering	BLZ72	WOS:000271613000080	
B	Ma, LT; Wang, SY; Wang, JZ; Fu, BW; Kong, J		Tang, Y; Lawry, J		Ma, Lintian; Wang, Shuyan; Wang, Jianzhong; Fu, Baowei; Kong, Jun			Relative transformation with CamNN applied to isometric embedding	SECOND INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DESIGN, VOL 1, PROCEEDINGS			English	Proceedings Paper	2nd International Symposium on Computational Intelligence and Design	DEC 12-14, 2009	Changsha, PEOPLES R CHINA	IEEE, Hong Kong Computat Intelligence Chapter, Bristol Univ, Zhejiang Univ, Tsinghua Univ		manifold learning; isomap; relative transformation; neighborhood graph; locally linear embedding; cam weighted distance	NONLINEAR DIMENSIONALITY REDUCTION; CLASSIFICATION	Neighborhood selection is one of the most important link in low-dimensional representations of high-dimensional data sets. Also, a good distance measure among the data points is where the shoe pinches. In this paper, we use the cam weighted distance to find a more flexible neighborhood of a data point in a newly-created space of r-isomap algorithm. It is a major advantage of r-isomap to optimize the process of intrinsic structure of the local information in a data set. Short-circuit edges are reduced in a certain extent because of the relative transformation space which is constructed in r-isomap. Furthermore, we can get a well performance on both orientation and scale adaptive side, because we utilize the cam weighted distance to search the neighborhood of a data point. It has been proved that this distance measure is more efficient than the Euclidean distance. Experiments demonstrated that the proposed method can give better results on dimension reduction than r-isomap, Weighted Locally Linear Embedding (WLLE) and some other approaches on the data sets which have obvious classifications. Especially robust to data sets with noise.	[Ma, Lintian; Wang, Shuyan; Wang, Jianzhong; Fu, Baowei; Kong, Jun] NE Normal Univ, Dept Comp Applicat & Technol, Jilin, Peoples R China	Ma, LT (reprint author), NE Normal Univ, Dept Comp Applicat & Technol, Jilin, Peoples R China.	Malt442@nenu.edu.com					ASANO T, 2007, LINEAR SPACE ALGORIT; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Belkin M., 2002, LAPLACIAN EIGENMAPS, DOI 10.1.1.19.9400; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DONOHO DL, HESSIAN EIGENMAPS NE; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P314; GE SS, MACH VISION IN PRESS; Kang P, 2008, PATTERN RECOGN, V41, P3507, DOI 10.1016/j.patcog.2008.04.009; Kokiopoulou E, 2009, PATTERN RECOGN, V42, P2392, DOI 10.1016/j.patcog.2009.04.005; LEWISBECK MS, 2004, MULTIDIMENSIONAL SCA; Pan YZ, 2009, PATTERN RECOGN, V42, P798, DOI 10.1016/j.patcog.2008.08.024; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Samko O, 2006, PATTERN RECOGN LETT, V27, P968, DOI 10.1016/j.patrec.2005.11.017; Saul L. K., 2003, J MACHINE LEARNING R, V4, P119; Tenenbaum J., 2000, SCIENCE, V290; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; WEN GH, 2006, P 2006 IEEE INT C SY, P3491; WENA GH, 2009, PATTERN RECOGN, V30, P203; ZHANG ZY, 2002, ARXIVCS0212008V1CS1G; Zhou CY, 2006, PATTERN RECOGN, V39, P635, DOI 10.1016/j.patocog.2005.09.004	20	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		978-0-7695-3865-5				2009							6	10		10.1109/ISCID.2009.9		5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BOC99	WOS:000276212800002	
B	Zhu, QY; Cao, SQ			IEEE COMPUTER SOC	Zhu, Quanyin; Cao, Suqun			A Novel Classifier-independent Feature Selection Algorithm for Imbalanced Datasets	SNPD 2009: 10TH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCES, NETWORKING AND PARALLEL DISTRIBUTED COMPUTING, PROCEEDINGS			English	Proceedings Paper	3rd International Workshop on e-Activity (IWEA2009)/10th ACIS International Conference on Software Engineering Artificial Intelligence, Networking and Parallel/Distributed Computing	MAY 27-29, 2009	Daegu, SOUTH KOREA	IEEE Comp Soc, ACIS	Catholic Univ	imbalanced datasets; feature selection; posterior probability		A novel classifier-independent feature selection algorithm based on the posterior probability is proposed for imbalanced datasets. First, an imbalanced factor is introduced and computed by Parzen-window estimation. The middle point of Tomek links is chosen as the initial point. Accordingly, this algorithm is iterated to find out the boundary points which have the equality of posterior probability. Through the project computation on the normal vectors of these points, the weight of each feature can be obtained, which actually indicates the importance degree of each feature. The experimental results on 3 real-word datasets demonstrate that this proposed algorithm can not only reduce the computational cost but also overcome the shortcoming that lite majority class may be defected well but the minority class may be ignored in the conventional feature selection algorithm.	[Zhu, Quanyin] Huaiyin Inst Technol, Dept Comp Engn, Huaian, Peoples R China	Zhu, QY (reprint author), Huaiyin Inst Technol, Dept Comp Engn, Huaian, Peoples R China.	zqy@hyit.edu.cn; caosuqun@126.com					Abe N, 2006, PATTERN RECOGN, V39, P737, DOI 10.1016/j.patcog.2005.11.007; Barandela R, 2003, PATTERN RECOGN, V36, P849, DOI 10.1016/S0031-3203(02)00257-1; Blake CL, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Liu Tian-Yu, 2008, International Journal of Computational Biology and Drug Design, V1, P334; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P769; Wang ST, 2005, SOFT COMPUT, V9, P732, DOI [10.1007/s00500-004-0406-3, 10.1007/s00500-004-406-3]	7	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		978-0-7695-3642-2				2009							77	82		10.1109/SNPD.2009.47		6	Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	BNN08	WOS:000275031800014	
B	Wang, XM; Sykora, MD; Archer, R; Parish, D; Bez, HE			IEEE	Wang, Xiaoming; Sykora, Martin D.; Archer, Robert; Parish, David; Bez, Helmut E.			Case Based Reasoning Approach for Transaction Outcomes Prediction on Currency Markets	SOFA 2009: 3RD INTERNATIONAL WORKSHOP ON SOFT COMPUTING APPLICATIONS, PROCEEDINGS			English	Proceedings Paper	3rd International Workshop on Soft Computing Applications	JUL 29-AUG 01, 2009	Szeged, HUNGARY	IEEE Computat Intelligence soc, IEEE Hungary Sect, EUROFUSE, Hungarian Fuzzy Assoc, BMT Resources, Grupul Scolar Transporturi Auto, Henri Coanda Arad			CLASSIFICATION; STRATEGIES	This paper presents a case based reasoning approach for making profit in the foreign exchange (forex) market with controlled risk using k nearest neighbour (kNN) and improving on the results with neural networks (NNs) and a combination of both. Although many professionals have proven that exchange rates can be forecast using neural networks for example, poor trading strategies and unpredictable market fluctuation can inevitably still result in substantial loss. As a result, the method proposed in this paper will focus on predicting the outcome of potential trades with fixed stop loss (ST) and take profit (TP) positions, in terms of a win or loss. With the help of the Monte Carlo method, randomly generated trades together with different traditional technical indicators are fed into the models, resulting in a win or lose output. This is clearly a case based reasoning approach, in terms of searching similar past trade setups for selecting successful trades. There are several advantages over classical forecasting associated with such an approach, and the technique presented in this paper brings a novel perspective to problem of exchange trades predictability. The strategies implemented have not been empirically investigated with such wide a range of time granularities as is done in this paper, in any to the authors known academic literature. The profitability of this approach is back-tested at the end of this paper and highly encouraging results are reported.	[Wang, Xiaoming; Sykora, Martin D.; Archer, Robert; Parish, David; Bez, Helmut E.] Univ Loughborough, Res Sch Informat, Dept Comp Sci, Loughborough LE11 3TU, Leics, England	Wang, XM (reprint author), Univ Loughborough, Res Sch Informat, Dept Comp Sci, Loughborough LE11 3TU, Leics, England.	elxw@lboro.ac.uk; m.d.sykora@lboro.ac.uk; cora3@lboro.ac.uk; d.j.parish@lboro.ac.uk; h.e.bez@lboro.ac.uk					Azoff EM, 1994, NEURAL NETWORK TIME; BACHELIER L, 1900, ANN SCI ECOLE NORM S, V3, P21; BROCK W, 1992, J FINANC, V47, P1731, DOI 10.2307/2328994; BURRELL J, 2007, COMPLETE GUIDE CURRE; Caginalp G., 1998, APPL MATH FINANCE, V5, P181; Chan LKC, 1996, J FINANC, V51, P1681, DOI 10.2307/2329534; Chatfield C., 1996, ANAL TIME SERIES INT; COVEL MW, 2007, COMPLETE TURTLETRADE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DeLurgio S. A, 1998, FORECASTING PRINCIPL; FAMA E, 1965, FINANCIAL ANAL J, V51; Foucault T., 1999, J FINANCIAL MARKETS, V2, P99, DOI 10.1016/S1386-4181(98)00012-3; GARLIAUSKAS A, 1999, IEEE INT C SYST MAN, V2, P638, DOI 10.1109/ICSMC.1999.825335; GEAPA B, 2003, P 2 BRAZ WORKSH BIOI; HELLSTRM T, 1998, THESIS UME U UME SWE; HELLSTRM T, 1998, PREDICTING STOCK MAR; HSIEH DA, 1991, J FINANC, V46, P1839, DOI 10.2307/2328575; Kamruzzaman J, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P793; KAMRUZZAMAN J, 2003, P 3 IEEE INT C DAT M, P557; Leung MT, 2000, INT J FORECASTING, V16, P173, DOI 10.1016/S0169-2070(99)00048-5; LIVERMORE J, 2006, TRADE STOCKS; LO A, 1989, STOCK MARKET PRICES; Lo A., 2004, J PORTFOLIO MANAGE, V30, P15, DOI 10.3905/jpm.2004.442611; Lo AW, 2000, J FINANC, V55, P1705, DOI 10.1111/0022-1082.00265; Malkiel B., 1973, RANDOM WALK DOWN WAL; McNelis P.D., 2004, NEURAL NETWORKS FINA; MURPHY J, 1996, VISUAL INVESTOR SPOT; Murphy JJ, 1999, TECHNICAL ANAL FINAN; Osler CL, 2005, J INT MONEY FINANC, V24, P219, DOI 10.1016/j.jimonfin.2004.12.002; PAN MS, 2004, J EMPIR FINANC, V11, P185, DOI 10.1016/j.jempfin.2003.02.001; Peters E.E., 1991, CHAOS ORDER CAPITAL; Peters E.E., 1994, FRACTAL MARKET ANAL; Refenes Apostolos-Paul, 1995, NEURAL NETWORKS CAPI; Rubinstein M, 2001, FINANC ANAL J, V57, P15, DOI 10.2469/faj.v57.n3.2447; SAMUELSON P, 1965, IND MANAGEMENT REV, V6, P4149; SAMUELSON P, 1955, BROWNIAN MOTION STOC; SCHWAGER JD, 2006, MARKET WIZARDS INTER; Schwager J.D, 2008, NEW MARKET WIZARDS C; Schwager JS, 2008, STOCK MARKET WIZARDS; Shen S, 2001, APPL MATH COMPUT, V119, P317, DOI 10.1016/S0096-3003(99)00229-5; Sullivan R, 1999, J FINANC, V54, P1647, DOI 10.1111/0022-1082.00163; SYKORA MD, 2007, IWAPR 2007 C P; TAYLOR JG, 2002, NEURAL NETWORKS FINA; WILLIAMS GP, 1997, CHAOS THEORTY TAMED, V1; Witten I., 2005, DATA MINING PRACTICA; Yao JT, 2000, NEUROCOMPUTING, V34, P79, DOI 10.1016/S0925-2312(00)00300-3; ZEMKE S, 2003, THESIS ROYAL I TECHN	47	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-5054-1				2009							91	96				6	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	BNO96	WOS:000275159600017	
B	Steinbach, M; Tan, PN		Wu, X; Kumar, V		Steinbach, Michael; Tan, Pang-Ning			kNN: k-Nearest Neighbors	TOP TEN ALGORITHMS IN DATA MINING	Chapman & Hall-CRC Data Mining and Knowledge Discovery Series		English	Article; Book Chapter							CLASSIFICATION; RULES		[Steinbach, Michael] Univ Minnesota, Minneapolis, MN 55455 USA; [Tan, Pang-Ning] Michigan State Univ, E Lansing, MI 48824 USA	Steinbach, M (reprint author), Univ Minnesota, Minneapolis, MN 55455 USA.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Asuncion A., 2007, UCI MACHINE LEARNING; BARTSCHSPORL B, 1999, LECT NOTES COMPUTER, V1570; BEZDEK JC, 1986, FUZZY SET SYST, V18, P237, DOI 10.1016/0165-0114(86)90004-7; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Devroye L, 1996, PROBABILISTIC THEORY; Duda R.O., 2000, PATTERN CLASSIFICATI; Fix E, 1951, DISCRIMINATORY ANAL; Fix E., 1952, DISCRIMINATORY ANAL; Gaede V, 1998, ACM COMPUT SURV, V30, P170, DOI 10.1145/280277.280279; Han E., 2001, P 5 PAC AS C KNOWL D, P53; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Houle ME, 2005, PROC INT CONF DATA, P619; KURAMOCHI M, 2001, BIBE 01, P191; PRICE K, 2008, NEAREST NEIGHBOR CLA; RACHLIN J, 1994, INT C MACH LEARN, P242; SALZBERG S, 1994, PEBLS PARALLEL EXEMP; TAN PN, 2006, INTRO DATA MININING; Toussaint G, 2005, INT J COMPUT GEOM AP, V15, P101, DOI 10.1142/S0218195905001622; TOUSSAINT GT, 2002, INTERFACE 2002; TOUSSAINT GT, 2003, LECT NOTES COMPUTER, V2866, P273; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Witten I., 2005, MORGAN KAUFMANN SERI	26	3	3	CHAPMAN & HALL/CRC PRESS	BOCA RATON	6000 BROKEN SOUND PKWY, NW, STE 300, BOCA RATON, FL 33487 USA		978-1-4200-8964-6	CH CRC DATA MIN KNOW			2009							151	161			10.1201/9781420089653	11	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Computer Science	BJR40	WOS:000267023600008	
B	Steinberg, D		Wu, X; Kumar, V		Steinberg, Dan			CART: Classification and Regression Trees	TOP TEN ALGORITHMS IN DATA MINING	Chapman & Hall-CRC Data Mining and Knowledge Discovery Series		English	Article; Book Chapter							CONSISTENT NONPARAMETRIC REGRESSION		Salford Syst, San Diego, CA USA	Steinberg, D (reprint author), Salford Syst, San Diego, CA USA.						Bloch DA, 2002, J COMPUT GRAPH STAT, V11, P263, DOI 10.1198/106186002760180509; BREIMAN L, 1985, J AM STAT ASSOC, V80, P580, DOI 10.2307/2288473; BREIMAN L, 1998, PASTING SMALL VOTES; BREIMAN L, 1995, P SANT FE I CNLS WOR, P361; Breiman L, 1984, CLASSIFICATION REGRE; BREIMAN L, 1978, PARSIMONIOUS BINARY; COSMAN PC, 1993, IEEE T MED IMAGING, V12, P727, DOI 10.1109/42.251124; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; DOYLE P, 1973, OPER RES QUART, V24, P465, DOI 10.2307/3008131; EINHORN HJ, 1972, PUBLIC OPIN QUART, V36, P367, DOI 10.1086/268019; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; Friedman JH, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P717; FRIEDMAN JH, 1977, IEEE T COMPUT, V26, P404; Friedman J.H., 1999, STOCHASTIC GRADIENT; GORDON L, 1984, J MULTIVARIATE ANAL, V15, P147, DOI 10.1016/0047-259X(84)90022-8; GORDON L, 1985, CANCER TREAT REP, V69, P1065; Hastie T., 1986, STAT SCI, V1, P297, DOI DOI 10.1214/SS/1177013604; Huang J, 2004, P NATL ACAD SCI USA, V101, P10529, DOI 10.1073/pnas.0403794101; Kooperberg C, 1997, J AM STAT ASSOC, V92, P117, DOI 10.2307/2291455; KOOPERBERG C, 1995, J AM STAT ASSOC, V90, P78, DOI 10.2307/2291132; MESSENGE.R, 1972, J AM STAT ASSOC, V67, P768, DOI 10.2307/2284634; MORGAN JN, 1963, J AM STAT ASSOC, V58, P415, DOI 10.2307/2283276; Provost F, 2003, MACH LEARN, V52, P199, DOI 10.1023/A:1024099825458; QUINLAN R, 1989, P 6 INT WORKSH MACH, P164; STONE CJ, 1985, ANN STAT, V13, P689, DOI 10.1214/aos/1176349548; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; Ting KM, 2002, IEEE T KNOWL DATA EN, V14, P659	28	3	3	CHAPMAN & HALL/CRC PRESS	BOCA RATON	6000 BROKEN SOUND PKWY, NW, STE 300, BOCA RATON, FL 33487 USA		978-1-4200-8964-6	CH CRC DATA MIN KNOW			2009							179	201		10.1201/9781420089653.ch10	10.1201/9781420089653	23	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Computer Science	BJR40	WOS:000267023600010	
J	Gigerenzer, G; Brighton, H				Gigerenzer, Gerd; Brighton, Henry			Homo Heuristicus: Why Biased Minds Make Better Inferences	TOPICS IN COGNITIVE SCIENCE			English	Article						Heuristics; Decision-making; Inferences; Rationality; Uncertainity; Induction	REASON DECISION-MAKING; TAKE-THE-BEST; ECOLOGICAL RATIONALITY; BOUNDED RATIONALITY; SENSORIMOTOR SKILLS; EMPIRICAL TESTS; NEURAL-NETWORKS; LINEAR-MODELS; HOT HAND; RECOGNITION	Heuristics are efficient cognitive processes that ignore information. In contrast to the widely held view that less processing reduces accuracy, the study of heuristics shows that less information, computation, and time can in fact improve accuracy. We review the major progress made so far: (a) the discovery of less-is-more effects; (b) the study of the ecological rationality of heuristics, which examines in which environments a given strategy succeeds or fails, and why; (c) an advancement from vague labels to computational models of heuristics; (d) the development of a systematic theory of heuristics that identifies their building blocks and the evolved capacities they exploit, and views the cognitive system as relying on an "adaptive toolbox;'' and (e) the development of an empirical methodology that accounts for individual differences, conducts competitive tests, and has provided evidence for people's adaptive use of heuristics. Homo heuristicus has a biased mind and ignores part of the available information, yet a biased mind can handle uncertainty more efficiently and robustly than an unbiased mind relying on more resource-intensive and general-purpose processing strategies.	[Gigerenzer, Gerd; Brighton, Henry] Max Planck Inst Human Dev, D-14195 Berlin, Germany	Gigerenzer, G (reprint author), Max Planck Inst Human Dev, Lentzeal Lee 94, D-14195 Berlin, Germany.	gigerenzer@mpib-berlin.mpg.de	Brighton, Henry/A-3504-2011; Gigerenzer, Gerd/A-6250-2012				Alpaydin E, 2004, INTRO MACHINE LEARNI; ANDERSON JR, 1991, PSYCHOL REV, V98, P409, DOI 10.1037/0033-295X.98.3.409; Axelrod R., 1984, EVOLUTION COOPERATIO; Ayton P, 2004, MEM COGNITION, V32, P1369, DOI 10.3758/BF03206327; Barbey AK, 2007, BEHAV BRAIN SCI, V30, P241, DOI 10.1017/S0140525X07001653; Beach L. R., 1978, ACAD MANAGE REV, V3, P439, DOI 10.2307/257535; Beilock SL, 2004, PSYCHON B REV, V11, P373, DOI 10.3758/BF03196585; Beilock SL, 2002, J EXP PSYCHOL-APPL, V8, P6, DOI 10.1037/1076-898X.8.1.6; Bergert FB, 2007, J EXP PSYCHOL LEARN, V33, P107, DOI 10.1037/0278-7393.33.1.107; BIRMBAUM MH, 2008, PSYCHOL REV, V115, P253; Bishop C. M., 2006, PATTERN RECOGNITION; Bishop C. M., 1995, NEURAL NETWORKS PATT; BOOKSTABER R, 1985, J THEOR BIOL, V116, P161, DOI 10.1016/S0022-5193(85)80262-9; Boyd R., 2005, ORIGIN EVOLUTION CUL; Brandstatter E, 2008, PSYCHOL REV, V115, P281, DOI 10.1037/0033-295X.115.1.281; Brandstatter E, 2006, PSYCHOL REV, V113, P409, DOI 10.1037/0033-295X.113.2.409; Breiman L., 1994, CLASSIFICATION REGRE; Brighton H, ECOLOGICAL IN PRESS; BRIGHTON H, 2006, AAAI SPRING S COGN S, P17; Broder A, 2003, J EXP PSYCHOL LEARN, V29, P611, DOI 10.1037/0278-7393.29.4.611; Broder A, 2007, PSYCHON B REV, V14, P895, DOI 10.3758/BF03194118; BRODER A, ECOLOGICAL IN PRESS; Bruss F. T., 2000, SPEKTRUM WISSENSCHAF, V6, P106; Carnap R., 1947, PHILOS PHENOMENOLOGI, V8, P133, DOI DOI 10.2307/2102920; Chater N, 2003, ORGAN BEHAV HUM DEC, V90, P63, DOI 10.1016/S0749-5978(02)00508-3; CLUTTONBROCK TH, 1979, BEHAVIOUR, V69, P145, DOI 10.1163/156853979X00449; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Czerlinski J, 1999, SIMPLE HEURISTICS MA, P97; DAWES RM, 1974, PSYCHOL BULL, V81, P95, DOI 10.1037/h0037613; DAWES RM, 1979, AM PSYCHOL, V34, P571, DOI 10.1037//0003-066X.34.7.571; Dawkins R, 1989, SELFISH GENE; DEMIGUEL V, REV FINANCI IN PRESS; Dieckmann A, 2007, MEM COGNITION, V35, P1801, DOI 10.3758/BF03193511; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dudey T., 2002, J BIOECONOMICS, V3, P195; EINHORN HJ, 1975, ORGAN BEHAV HUM PERF, V13, P171, DOI 10.1016/0030-5073(75)90044-6; ELMAN JL, 1993, COGNITION, V48, P71, DOI 10.1016/0010-0277(93)90058-4; Fehr E, 1999, Q J ECON, V114, P817, DOI 10.1162/003355399556151; FISHBURN PC, 1974, MANAGE SCI, V20, P1442, DOI 10.1287/mnsc.20.11.1442; FORD JK, 1989, ORGAN BEHAV HUM DEC, V43, P75, DOI 10.1016/0749-5978(89)90059-9; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Gigerenzer G, 1996, PSYCHOL BULL, V119, P23, DOI 10.1037/0033-2909.119.1.23; Gigerenzer G., 2000, ADAPTIVE THINKING RA; Gigerenzer G., 2001, BOUNDED RATIONALITY; Gigerenzer G, 1996, PSYCHOL REV, V103, P592, DOI 10.1037/0033-295X.103.3.592; Gigerenzer G, 2008, RATIONALITY MORTALS; Gigerenzer G., 1999, SIMPLE HEURISTICS MA, P75; Gigerenzer G., 1999, SIMPLE HEURISTICS MA; GIGERENZER G, ECOLOGICAL IN PRESS; GIGERENZER G, 1991, PSYCHOL REV, V98, P254, DOI 10.1037//0033-295X.98.2.254; Gigerenzer G, 1996, PSYCHOL REV, V103, P650, DOI 10.1037//0033-295X.103.4.650; Gigerenzer Gerd, 2007, GUT FEELINGS INTELLI; Gilbert J. P., 1966, AM STAT ASS J, V61, P35; GILOVICH T, 1985, COGNITIVE PSYCHOL, V17, P295, DOI 10.1016/0010-0285(85)90010-6; GILOVICH T, 2002, PSYCHOL INTUITIVE JU, P1; Goldstein DG, 2002, PSYCHOL REV, V109, P75, DOI 10.1037//0033-295X.109.1.75; Good I., 1967, BRIT J PHILOS SCI, V17, P319, DOI 10.1093/bjps/17.4.319; Griffiths TL, 2006, PSYCHOL SCI, V17, P767, DOI 10.1111/j.1467-9280.2006.01780.x; Guttman L, 1944, AM SOCIOL REV, V9, P139, DOI 10.2307/2086306; Hastie T, 2001, ELEMENTS STAT LEARNI; Hertwig R., 2003, THINKING PSYCHOL PER, P213, DOI DOI 10.1002/047001332X.CH11; HOGARTH RM, ECOLOGICAL IN PRESS; Hogarth RM, 2005, J MATH PSYCHOL, V49, P115, DOI 10.1016/j.jmp.2005.01.001; Hogarth RM, 2006, THEOR DECIS, V61, P205, DOI 10.1007/s11238-006-9000-8; Hutchinson JMC, 2005, BEHAV PROCESS, V69, P97, DOI 10.1016/j.beproc.2005.02.019; JACOBY LL, 1981, J EXP PSYCHOL GEN, V110, P306, DOI 10.1037/0096-3445.110.3.306; Johnson EJ, 2003, SCIENCE, V302, P1338, DOI 10.1126/science.1091721; Johnson JG, 2003, ORGAN BEHAV HUM DEC, V91, P215, DOI 10.1016/S0749-5978(03)00027-X; Jolls C, 1998, STANFORD LAW REV, V50, P1471, DOI 10.2307/1229304; Kahneman D, 1996, PSYCHOL REV, V103, P582, DOI 10.1037//0033-295X.103.3.582; Karelaia N, 2006, ORGAN BEHAV HUM DEC, V100, P128, DOI 10.1016/j.obhdp.2005.09.003; Katsikopoulos KV, 2006, J MATH PSYCHOL, V50, P488, DOI 10.1016/j.jmp.2006.06.001; Katsikopoulos KV, 2008, J RISK UNCERTAINTY, V37, P35, DOI 10.1007/s11166-008-9042-0; Keeney RL, 1993, DECISIONS MULTIPLE O; Lee MD, 2002, AUST J PSYCHOL, V54, P137, DOI 10.1080/00049530412331312704; Luria A. R., 1968, MIND MNEMONIST; Martignon L, 2002, THEOR DECIS, V52, P29, DOI 10.1023/A:1015516217425; Martignon L., 1999, SIMPLE HEURISTICS MA, P119; Martignon L, 2008, J MATH PSYCHOL, V52, P352, DOI 10.1016/j.jmp.2008.04.003; Mugford ST, 2001, BEHAV ECOL, V12, P655, DOI 10.1093/beheco/12.6.655; Newell BR, 2003, ORGAN BEHAV HUM DEC, V91, P82, DOI 10.1016/S0749-5978(02)00525-3; Newell BR, 2003, J EXP PSYCHOL LEARN, V29, P53, DOI 10.1037/0278-7393.29.1.53; Newell BR, 2005, TRENDS COGN SCI, V9, P11, DOI 10.1016/j.tics.2004.11.005; NEWPORT EL, 1990, COGNITIVE SCI, V14, P11, DOI 10.1207/s15516709cog1401_2; Nosofsky RM, 2007, J EXP PSYCHOL LEARN, V33, P999, DOI 10.1037/0278-7393.33.6.999; NOSOFSKY RM, 1990, J MATH PSYCHOL, V34, P393, DOI 10.1016/0022-2496(90)90020-A; Oaksford M., 1998, RATIONAL MODELS COGN; Pachur T, 2008, J BEHAV DECIS MAKING, V21, P183, DOI 10.1002/bdm.581; Payne J. W., 1993, ADAPTIVE DECISION MA; Perlich C., 2003, J MACHINE LEARNING R, V4, P211; PETRIE M, 1994, BEHAV ECOL SOCIOBIOL, V35, P213, DOI 10.1007/BF00167962; Pichert D, 2008, J ENVIRON PSYCHOL, V28, P63, DOI 10.1016/j.jenvp.2007.09.004; Pohl RF, 2006, J BEHAV DECIS MAKING, V19, P251, DOI 10.1002/bdm.522; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Richter T, 2006, J EXP PSYCHOL LEARN, V32, P150, DOI 10.1037/0178-7393.32.1.150; Rieskamp J, 2006, J EXP PSYCHOL GEN, V135, P207, DOI 10.1037/0096-3445.135.2.207; Rieskamp J, 2008, ACTA PSYCHOL, V127, P258, DOI 10.1016/j.actpsy.2007.05.004; Roberts S, 2000, PSYCHOL REV, V107, P358, DOI 10.1037//0033-295X.107.2.358; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; SCHEIBEHENNE B, 2007, INT J FORECASTING, V3, P415; SCHMIDT FL, 1971, EDUC PSYCHOL MEAS, V31, P699, DOI 10.1177/001316447103100310; Schmitt M, 2006, J MACH LEARN RES, V7, P55; Schooler LJ, 2005, PSYCHOL REV, V112, P610, DOI 10.1037/0033-295X.112.3.610; Sedlmeier P, 1998, J EXP PSYCHOL LEARN, V24, P754, DOI 10.1037/0278-7393.24.3.754; Selten R, 2001, DAHL WS ENV, P13; Serwe S, 2006, J BEHAV DECIS MAKING, V19, P321, DOI 10.1002/bdm.530; Shaffer DM, 2004, PSYCHOL SCI, V15, P437, DOI 10.1111/j.0956-7976.2004.00698.x; SHAH AK, 2008, PSYCHOL BULL, V137, P207; SHEPARD RN, 1987, SCIENCE, V237, P1317, DOI 10.1126/science.3629243; SHEPARD RN, 1974, PSYCHOMETRIKA, V39, P373, DOI 10.1007/BF02291665; Simon HA, 1955, Q J ECON, V69, P99, DOI 10.2307/1884852; Simon H. A., 1991, MODELS MY LIFE; SIMON HA, 1992, PSYCHOL SCI, V3, P150, DOI 10.1111/j.1467-9280.1992.tb00017.x; Sloman SA, 1996, PSYCHOL BULL, V119, P3, DOI 10.1037//0033-2909.119.1.3; STIGLER GJ, 1961, J POLIT ECON, V69, P213, DOI 10.1086/258464; STONE M, 1974, J R STAT SOC B, V36, P111; Sunstein Cass R, 2000, BEHAV LAW EC; Tinbergen N, 1958, CURIOUS NATURALISTS; Todd P. M., 1999, SIMPLE HEURISTICS MA, P287; TVERSKY A, 1972, PSYCHOL REV, V79, P281, DOI 10.1037/h0032955; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037//0033-295X.84.4.327; TVERSKY A, 1973, COGNITIVE PSYCHOL, V5, P207, DOI 10.1016/0010-0285(73)90033-9; TVERSKY A, 1974, SCIENCE, V185, P1124, DOI 10.1126/science.185.4157.1124; Volz KG, 2006, J COGNITIVE NEUROSCI, V18, P1924, DOI 10.1162/jocn.2006.18.11.1924; Weisberg S., 1985, APPL LINEAR REGRESSI; Wubben M, 2008, J MARKETING, V72, P82, DOI 10.1509/jmkg.72.3.82; Yee M, 2007, MARKET SCI, V26, P532, DOI 10.1287/mksc.1060.0213	127	104	105	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	1756-8757		TOP COGN SCI	Top. Cogn. Sci.	JAN	2009	1	1					107	143		10.1111/j.1756-8765.2008.01006.x		37	Psychology, Experimental	Psychology	675UG	WOS:000283862000006	
B	Anantapornkit, E; Kruatrachue, B		Ao, SI; Douglas, C; Grundfest, WS; Burgstone, J		Anantapornkit, Ekaphol; Kruatrachue, Boontee			Reinforcement Learning Algorithm for the Minimal Consistent Subset Identification	WCECS 2009: WORLD CONGRESS ON ENGINEERING AND COMPUTER SCIENCE, VOLS I AND II	Lecture Notes in Engineering and Computer Science		English	Proceedings Paper	World Congress on Engineering and Computer Science	OCT 20-22, 2009	San Francisco, CA	Int Assoc Engineers		minimal consistent subset; nearest neighbor rule; prototype selection; reinforcement learning	NEAREST-NEIGHBOR RULE	This paper describes the reinforcement learning (RL) algorithm for the minimal consistent subset identification (MCSI) problem. MCSI is widely used in pattern recognition to select prototypes from a training set to be used in nearest neighbor classification. The RL agent solves the MCSI problem by deselecting a prototype one by one from the original data set to search for the best subset. Because the algorithm rarely descends to the smaller solution via its exploration strategy, a simple modification to the algorithm is proposed. The modification encourages the agent to try as many actions as possible at the current best solution to improve the results obtained. The paper concludes by comparing the performance of the proposed algorithm in handling the MCSI problem with the RL algorithm and the standard MCSI method.	[Anantapornkit, Ekaphol; Kruatrachue, Boontee] King Mongkuts Inst Technol, Dept Comp Engn, Fac Engn, Bangkok, Thailand	Anantapornkit, E (reprint author), King Mongkuts Inst Technol, Dept Comp Engn, Fac Engn, Bangkok, Thailand.	ekreal@yahoo.com; booontee@yahoo.com					Cerveron V, 2001, IEEE T SYST MAN CY B, V31, P408, DOI 10.1109/3477.931531; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KANGKAN K, 2006, ISCIT 2006 OCT; Sutton R. S., 1998, REINFORCEMENT LEARNI; *U CA DEP INF COMP, 1998, UCI MACH LEARN REP	7	0	0	INT ASSOC ENGINEERS-IAENG	HONG KONG	UNIT1, 1-F, 37-39 HUNG TO ROAD, KWUN TONG, HONG KONG, 00000, PEOPLES R CHINA		978-988-17012-6-8	LECT NOTES ENG COMP			2009							848	852				5	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BPZ34	WOS:000280421400160	
B	Yang, CS; Chuang, LY; Li, JC; Yang, CH			IEEE	Yang, Cheng-San; Chuang, Li-Yeh; Li, Jung-Chike; Yang, Cheng-Hong			Chaotic Maps in Binary Particle Swarm Optimization for Feature Selection	2008 IEEE CONFERENCE ON SOFT COMPUTING IN INDUSTRIAL APPLICATIONS SMCIA/08			English	Proceedings Paper	IEEE Conference on Soft Computing in Industrial Applications	JUN 25-28, 2008	Muroran, JAPAN	IEEE Syst, Man & Cybernet Soc, TCIA			CLASSIFIER	Feature selection is a useful pre-processing technique for solving classification problems. The challenge of using evolutionary algorithms lies in solving the feature selection problem caused by the number of features. Classification data may contain useless, redundant or misleading features. To increase the classification accuracy, the primary objective is to remove irrelevant features in the feature space and identify the relevant features. Binary particle swarm optimization (BPSO) has been applied successfully in solving feature selection problem. In this paper, two kinds of chaotic maps are embedded in binary particle swarm optimization (BPSO), a logistic map and a tent map, respectively. The purpose of the chaotic maps is to determine the inertia weight of the BPSO. In this study, we propose the chaotic binary particle swarm optimization (CBPSO) method to implement feature selection, and the K-nearest neighbor (K-NN) method with leave-one-out cross-validation (LOOCV) serves as a classifier to evaluate the classification accuracies. The proposed method showed promising results for feature selection with respect to the number of feature subsets. The classification accuracy obtained by the proposed method is superior to ones obtained by the other methods from the literature.	[Yang, Cheng-San] Natl Cheng Kung Univ, Inst Biomed Engn, Tainan 70101, Taiwan	Yang, CS (reprint author), Natl Cheng Kung Univ, Inst Biomed Engn, Tainan 70101, Taiwan.	p8896117@mail.ncku.edu.tw; chuang@isu.edu.tw; 1095320149@cc.kuas.edu.tw; chyang@cc.kuas.edu.tw					ALATAS B, CHAOS SOLIT IN PRESS; Chuanwen J., 2005, MATH COMPUT SIMULAT, V68, P57, DOI 10.1016/j.matcom.2004.10.003; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Kennedy J., 1995, IEEE INT C NEUR NETW, V4, P1942, DOI DOI 10.1109/ICNN.1995.488968; Kennedy J., 2001, SWARM INTELLIGENCE; Kennedy J, 1997, IEEE SYS MAN CYBERN, P4104; Murphy P. M., 1995, UCI REPOSITORY MACHI; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; Shi Y., 1998, EV COMP P 1998 IEEE, P69; Sivagaminathan RK, 2007, EXPERT SYST APPL, V33, P49, DOI 10.1016/j.eswa.2006.04.010; Tahir MA, 2007, PATTERN RECOGN LETT, V28, P438, DOI 10.1016/j.patrec.2006.08.016; Tan SB, 2006, EXPERT SYST APPL, V30, P290, DOI 10.1016/j.eswa.2005.07.019; Wang XY, 2007, PATTERN RECOGN LETT, V28, P459, DOI 10.1016/j.patrec.2006.09.003	13	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-3782-5				2009							107	112				6	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	BMF96	WOS:000272228200019	
B	Chuang, LY; Wu, KC; Yang, CH			IEEE	Chuang, Li-Yeh; Wu, Kuo-Chuan; Yang, Cheng-Hong			Hybrid Feature Selection Method using Gene Expression Data	2008 IEEE CONFERENCE ON SOFT COMPUTING IN INDUSTRIAL APPLICATIONS SMCIA/08			English	Proceedings Paper	IEEE Conference on Soft Computing in Industrial Applications	JUN 25-28, 2008	Muroran, JAPAN	IEEE Syst, Man & Cybernet Soc, TCIA			FEATURE SUBSET-SELECTION; MICROARRAY DATA; CLASSIFICATION; ALGORITHMS; CLASSIFIERS; MACHINE	Gene expression profiles, which represent the state of a cell at a molecular level, have great potential as a medical diagnosis tool. Compared to the number of genes involved available training data sets generally have a fairly small sample size in cancer type classification. These training data limitations constitute a challenge to certain classification methodologies. The gene (feature) selection can extract genes which influence classification accuracy effectively, to eliminate the useless genes, and to improve the calculate performance and the classification accuracy. This paper presents hybrid feature selection method Taguchi-Genetic algorithm to rind optimal feature subset, to appraise feature set using K-nearest neighbor with leave-one-out cross-validation based on Euclidean distance calculation. Experimental results show that our method simplifies features effectively and obtains a higher classification accuracy compared to other classification methods from the literature.	[Chuang, Li-Yeh] I Shou Univ, Dept Chem Engn, Kaohsiung, Taiwan	Chuang, LY (reprint author), I Shou Univ, Dept Chem Engn, Kaohsiung, Taiwan.	chuang@isu.edu.tw; kuo.chuan.wu@gmail.com; chyang@cc.kuas.edu.tw					BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Cawley GC, 2003, PATTERN RECOGN, V36, P2585, DOI 10.1016/S0031-3203(03)00136-5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B., 1991, NEAREST NEIGHBOR NN, P1; Frank E, 2004, BIOINFORMATICS, V20, P2479, DOI 10.1093/bioinformatics/bth261; Holland JH, 1992, ADAPTATION NATURE AR; Huang HL, 2007, BIOSYSTEMS, V90, P78, DOI 10.1016/j.biosystems.2006.07.002; Inza I, 2004, ARTIF INTELL MED, V31, P91, DOI 10.1016/j.artmed.2004.01.007; Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491; NARENDRA P, 1977, IEEE T COMPUT, V26, P917; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; SAHAMI M, 1998, WS9805 AAAI, V62; SPECHT DF, 1990, PROBABILISTIC NEURAL, V3, P109; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; STONE M, 1974, J R STAT SOC B, V36, P111; Taguchi G, 2000, ROBUST ENG; Tang EK, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-95; Wang Y, 2005, COMPUT BIOL CHEM, V29, P37, DOI 10.1016/j.compbiolchem.2004.11.001; Wu Y., 2000, TAGUCHI METHODS ROBU; Xiong MM, 2001, GENOME RES, V11, P1878; Yang JH, 1998, IEEE INTELL SYST APP, V13, P44, DOI 10.1109/5254.671091; YEANG CH, 2001, MOL CLASSIFICATION T, V17, pS316	24	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-3782-5				2009							199	204				6	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	BMF96	WOS:000272228200035	
B	Goeger, D; Ecker, N; Woern, H			IEEE	Goeger, Dirk; Ecker, Nico; Woern, Heinz			Tactile sensor and algorithm to detect slip in robot grasping processes	2008 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-4			English	Proceedings Paper	IEEE International Conference on Robotics and Biomimetics (ROBIO)	FEB 22-25, 2009	Bangkok, THAILAND	IEEE Robot & Automat Soc		tactile sensor; slip detection algorithm; humanoid robot		In this paper we introduce a tactile slip sensor for an anthropomorphic robot hand, the measurement circuit and the corresponding algorithm to determine slip states. The main slip sensor components consist of a silicone rubber surface which covers a PVDF sensor. After the amplification of the signal it is processed by a discrete short-time Fourier transform. The resulting spectrogram is processed by a principal component analysis to determine the main signal components. For a classification of three states ('slip', 'signal but no slip' and 'noise') a k-nearest neighbour classifier has been trained with the main signal components and serves for discrimination of slip states on the sensor's surface. The build-up of the sensor and the experimental setup will be briefly explained, the signal processing and the results will be discussed in detail.	[Goeger, Dirk; Ecker, Nico; Woern, Heinz] Univ Karlsruhe, Inst Proc Control & Robot, D-76131 Karlsruhe, Germany	Goeger, D (reprint author), Univ Karlsruhe, Inst Proc Control & Robot, Engler Bunte Ring 8, D-76131 Karlsruhe, Germany.	goeger@ira.uka.de					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GOGER D, 2007, IEEE C SENS ATL GA U; HOLWEG E, 1996, IEEE INT C ROB AUT M; JOCKUSCH J, 1997, IEEE INT C ROB AUT A; Schulz A., 2004, MECHATRONICS ROBOTIC, P936; SON J, 1994, IEEE INT C ROB AUT S; TURK M, 1991, COMPUTER VISION PATT; Worn H., 2005, P IEEE INT C MECH AU	8	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-2678-2				2009							1480	1485		10.1109/ROBIO.2009.4913219		6	Engineering, Electrical & Electronic; Instruments & Instrumentation; Robotics	Engineering; Instruments & Instrumentation; Robotics	BME14	WOS:000271966900250	
B	Liu, XS; Liu, Q; Fu, GL		Thalmann, D; Shah, JJ; Peng, QS		Liu Xiaoshan; Liu Qing; Fu Guolan			Texture Analyse Based on Coefficients' Relationship Co-occurrence Histogram	2009 11TH IEEE INTERNATIONAL CONFERENCE ON COMPUTER-AIDED DESIGN AND COMPUTER GRAPHICS, PROCEEDINGS	International Conference on Computer-Aided Design and Computer Graphics-CAD GRAPHICS		English	Proceedings Paper	11th International Conference on Computer-Aided Design and Computer Graphics	AUG 19-21, 2009	Yellow Mountain City, PEOPLES R CHINA	IEEE, Natl Nat Sci Fdn China, Zhejiang Prov			CLASSIFICATION; SEGMENTATION	We propose a novel texture feature extraction technique based on coefficients' co-occurrence histogram of discrete wavelet frame transformed image, which capture the information about relationship between each high frequency subband and the low frequency subband of the decomposed image at the corresponding level. It is not independently utilizing the information of each subband coefficient: The classification performance is analyzed using the k-NN classifier. And the experimental results demonstrate the effectiveness of our proposed texture feature in achieving the improved classification performance. Comparisons with the Gabor filter and a recently proposed approach are also provided.	[Liu Xiaoshan; Fu Guolan] Jiangxi Normal Univ, Sch Phys & Commun Elect, Nanchang 330022, Jiangxi, Peoples R China	Liu, XS (reprint author), Jiangxi Normal Univ, Sch Phys & Commun Elect, Nanchang 330022, Jiangxi, Peoples R China.	xsliu@163.com; liu.qing3@mail.scut.edu.cn; guolanfu@126.com					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25; Daugman J, 1990, COMPUTATIONAL NEUROS, P403; EHRICH RW, 1978, COMPUT VISION GRAPH, V8, P174, DOI 10.1016/0146-664X(78)90048-5; HARALICK RM, 1978, IEEE T SYSTERM MAN C, V8, P460; Hiremath P.S., 2006, GVIP J, V6; Hiremath PS, 2008, PATTERN RECOGN LETT, V29, P1182, DOI 10.1016/j.patrec.2008.01.012; Laine A, 1996, IEEE T IMAGE PROCESS, V5, P771, DOI 10.1109/83.499915; LI XH, 2003, ACTA ELECT SINICA, V31, P2123; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983; UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936; WANG ZY, 2001, J IMAGE GRAPHIC, V6, P1065; WU J, 2001, J REMOTE SENSING, V5, P100	14	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-3700-9	INT C COMP AID DES C			2009							584	587		10.1109/CADCG.2009.5246832		4	Computer Science, Interdisciplinary Applications; Engineering, Manufacturing	Computer Science; Engineering	BNX95	WOS:000275856400113	
B	Zagouras, A; Argiriou, AA; Flocas, HA; Economou, G; Fotopoulos, S			IEEE	Zagouras, A.; Argiriou, A. A.; Flocas, H. A.; Economou, G.; Fotopoulos, S.			A MACHINE VISION BASED METHOD FOR ATMOSPHERIC CIRCULATION CLASSIFICATION	2009 16TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, VOLS 1 AND 2			English	Proceedings Paper	16th International Conference on Digital Signal Processing	JUL 05-07, 2009	Santorini, GREECE			machine vision; chain code; k- nearest neighbors algorithm; synoptic climatology		Weather maps refer to meteorological data that characterize the atmospheric circulation in a region. The classification of weather maps into categories becomes an important task for understanding regional climate. Towards this goal, manual and semiautomatic techniques have been used, requiring manpower and supervision. In this paper, we propose a machine vision based method for the classification of weather maps into distinct classes. The chain code descriptor is applied to extract the feature of isobaric lines and we introduce the Double-Side Chain Code (DSCC) histogram for feature representation. Handling DSCC histograms as multidimensional vectors, the k-nearest neighbors (k-NN) algorithm classifies the objects to an appropriate number of classes, based on closest training set in the feature space. This method provides an automated and more 'objective' classification scheme, applying straightforward to the input weather map's image.	[Zagouras, A.; Economou, G.; Fotopoulos, S.] Univ Patras, Dept Phys, Elect Lab, GR-26110 Patras, Greece	Zagouras, A (reprint author), Univ Patras, Dept Phys, Elect Lab, GR-26110 Patras, Greece.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Freeman H., 1961, Institute of Radio Engineers Transactions on Electronic Computers, VEC-10; HAGELBERG C, 1995, J ATMOS OCEAN TECH, V12, P633, DOI 10.1175/1520-0426(1995)012<0633:TLDIMR>2.0.CO;2; Kassomenos P, 1998, THEOR APPL CLIMATOL, V59, P215, DOI 10.1007/s007040050025; MICHALAKOU G, 2002, J APPL METEOROL, V41, P519; Tenenbaum J. B., 2000, SCIENCE, V290, P5500; Wong K. Y, 2008, EXPERT SYSTEMS APPL, V35, P542, DOI 10.1016/j.eswa.2007.07.032; Wong KY, 2007, METEOROL APPL, V14, P49, DOI 10.1002/met.5; Yarnal B, 1993, SYNOPTIC CLIMATOLOGY	9	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-3297-4				2009							496	500				5	Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BOF71	WOS:000276494500084	
B	Li, Y; Cheng, B		Di, L; Chen, A		Li, Ying; Cheng, Bo			An Improved k-Nearest Neighbor Algorithm and Its Application to High Resolution Remote Sensing Image Classification	2009 17TH INTERNATIONAL CONFERENCE ON GEOINFORMATICS, VOLS 1 AND 2			English	Proceedings Paper	17th International Conference on Geoinformatics	AUG 12-14, 2009	Fairfax, VA		George Mason Univ	KNN classification; high resolution remote sensing image; object-oriented; segmentation		K-nearest neighbor (KNN) is a common classification method for data mining techniques. It has been widely used in many fields because of the implementation simplicity, the clarity of theory and the excellent classification performance. But KNN will increase classification error rate when training samples distribute unevenly or sample number of each class is very different. So, learning from the idea of clipping-KNN, this paper adopts an improved KNN classification algorithm and applies it to object-oriented classification of high resolution remote sensing image. Firstly, as sample points, image objects are obtained through image segmentation. Secondly, original KNN, clipping-KNN and the improved KNN are introduced and used to classify those sample points respectively. Finally, classification results are compared. Experiment shows that in the same training set and testing set, the improved KNN algorithm can achieve higher accuracy in the classification of high resolution remote sensing image.	[Li, Ying; Cheng, Bo] Chinese Acad Sci, Ctr Earth Observat & Digital Earth, Beijing, Peoples R China	Li, Y (reprint author), Chinese Acad Sci, Ctr Earth Observat & Digital Earth, Beijing, Peoples R China.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; Shah J K, 2004, EUR SIGN PROC C VIEN; ZHANG J, 2003, THESIS XIAN JIAOTONG; ZHAO YT, 2002, CHIN J APPL ECOL, V13, P495	5	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-4562-2				2009							1066	1069				4	Computer Science, Information Systems; Engineering, Electrical & Electronic; Remote Sensing	Computer Science; Engineering; Remote Sensing	BOU28	WOS:000277622400202	
B	Liu, ZY; Zhang, QY; Zhang, NT			IEEE	Liu Zhiyong; Zhang Qinyu; Zhang Naitong			Composite Pulse-Multipath Channel Estimation for IR-UWB Communication System	2009 5TH INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, NETWORKING AND MOBILE COMPUTING, VOLS 1-8			English	Proceedings Paper	5th International Conference on Wireless Communications, Networking and Mobile Computing	SEP 24-26, 2009	Beijing, PEOPLES R CHINA	IEEE Commun Soc, Beijing Univ Posts & Telecommun, Tsinghua Univ, Hunan Univ, Wuhan Univ, Sci Res Publishing		Composite Pulse-Multipath Channel Estimation; Nearest Neighbor (NN); Detection; UWB	NEAREST-NEIGHBOR RULE; EQUALIZATION	In this paper, we develop a composite pulse-multipath channel estimation approach for impulse radio-ultra wideband (IR-UWB) system. The approach is realized by means of the nearest neighbor (NN) estimation algorithm. This reconstructed signal is subsequently used as a reference template in a correlator-based detector. The bit error rate (BER) performance of the proposed approach is analyzed and compared to that of traditional correlator-based detector. Extensive simulations show that for different propagation scenarios and transfer rates, detectors based on NN composite pulse-multipath channel estimation outperform traditional correlator-based detector.	[Liu Zhiyong; Zhang Qinyu] Harbin Inst Technol, Shenzhen Grad Sch, Shenzhen, Peoples R China	Liu, ZY (reprint author), Harbin Inst Technol, Shenzhen Grad Sch, Shenzhen, Peoples R China.	liuzhiyong79@yahoo.com.cn; zqy@hit.edu.cn; ntzhang@hit.edu.cn					COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FOERSTER J, 8021502490 IEEE; LI Y, 2003, CHANNEL ESTIMATION S; Sato H, 2006, IEE P-COMMUN, V153, P93, DOI 10.1049/ip-com:20050328; Savazzi P, 1998, IEEE J SEL AREA COMM, V16, P1640, DOI 10.1109/49.737633; XU L, 2006, IEEE J SELETC AREAS, V24, P808; Yang LQ, 2004, IEEE T WIREL COMMUN, V3, P1236, DOI 10.1109/twc.2004.830827; Yang LQ, 2004, IEEE SIGNAL PROC MAG, V21, P26; Zhuang WH, 2003, WIREL COMMUN MOB COM, V3, P663, DOI 10.1002/wcm.149	10	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-3692-7				2009							1769	1773				5	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	BNX02	WOS:000275789400430	
B	Chuang, LY; Wu, KC; Yang, CH			IEEE	Chuang, Li-Yeh; Wu, Kuo-Chuan; Yang, Cheng-Hong			A Hybrid Feature Selection Method Using Gene Expression Data	2009 9TH IEEE INTERNATIONAL CONFERENCE ON BIOINFORMATICS AND BIOENGINEERING			English	Proceedings Paper	9th IEEE International Conference on BioInformatics and BioEngineering	JUN 22-24, 2009	Taichung, TAIWAN	IEEE		Feature selection; Taguchi-genetic algorithm; K-nearest neighbor; Leave-one-out cross-validation	CLASSIFICATION; ALGORITHMS	In this paper, correlation-based feature selection (CFS) and the Taguchi-genetic algorithm (TGA) method were combined in a hybrid method, and the K-nearest neighbor (KNN) method with leave-one-out cross-validation (LOOCV) served as a classifier for eleven classification profiles. With the help of this classifier classification accuracy were calculated. Experimental results show that this method effectively simplifies features selection by reducing the total number of features needed. The proposed method obtained the highest classification accuracy in five out of the six gene expression data set test problems when compared to other classification methods from the literature.	[Chuang, Li-Yeh] I Shou Univ, Kaohsiung, Taiwan	Chuang, LY (reprint author), I Shou Univ, Kaohsiung, Taiwan.	chuang@isu.edu.tw; 1097308101@cc.kuas.edu.tw; chyang@cc.kuas.edu.tw					BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Blake CL, 1998, UCI REPOSITORY MACHI; Cawley GC, 2003, PATTERN RECOGN, V36, P2585, DOI 10.1016/S0031-3203(03)00136-5; Chuang LY, 2008, COMPUT BIOL CHEM, V32, P29, DOI 10.1016/j.compbiolchem.2007.09.005; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Frank E, 2004, BIOINFORMATICS, V20, P2479, DOI 10.1093/bioinformatics/bth261; Hall M.A., 1999, THESIS U WAIKATO; Holland J., 1975, ADAPTATION NATURAL A; Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491; Mitchell M, 1996, INTRO GENETIC ALGORI; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; Taguchi G, 2000, ROBUST ENG; Tsai JT, 2004, IEEE T EVOLUT COMPUT, V8, P365, DOI 10.1109/TEVC.2004.826895; Zhang HB, 2002, PATTERN RECOGN, V35, P701, DOI 10.1016/S0031-3203(01)00046-2; ZHU Z, 2007, SYSTEMS MAN CYBERN B, V37, P70	17	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-4294-2				2009							100	106		10.1109/BIBE.2009.24		7	Engineering, Biomedical	Engineering	BOP23	WOS:000277202300014	
B	Quinzan, I; Sotoca, JM; Pla, F			IEEE	Quinzan, Ianisse; Sotoca, Jose M.; Pla, Filiberto			Clustering-based Feature Selection in Semi-supervised Problems	2009 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS			English	Proceedings Paper	9th International Conference on Intelligent Systems Design and Applications	NOV 30-DEC 02, 2009	Pisa, ITALY	Machine Intelligence Res Lab, IEEE Syst, Man & Cybernet Soc (SMCS), Int Fuzzy Syst Assoc, European Neural Network Soc, European Soc Fuzzy Log & Technol, World Fed Soft Comp	Univ Pisa	Semi-supervised learning; feature selection; information measures	MUTUAL INFORMATION; CLASSIFICATION	In this contribution a feature selection method in semi-supervised problems is proposed. This method selects variables using a feature clustering strategy, using a combination of supervised and unsupervised feature distance measure, which is based on Conditional Mutual Information and Conditional Entropy. Real databases were analyzed with different ratios between labelled and unlabelled samples in the training set, showing the satisfactory behaviour of the proposed approach.	[Quinzan, Ianisse; Sotoca, Jose M.; Pla, Filiberto] Univ Jaume 1, Inst Noves Tecnol Imatge, Dept Llenguatges & Sistemes Informat, Castellon De La Plana, Spain	Quinzan, I (reprint author), Univ Jaume 1, Inst Noves Tecnol Imatge, Dept Llenguatges & Sistemes Informat, Castellon De La Plana, Spain.	ianisseqs@yahoo.es; sotoca@lsi.uji.es; pla@lsi.uji.es					BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Chen Y.H., 2008, 19 INT C PATT REC IC, P1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEMANTARAS RL, 1989, METHODOLOGIES INTELL, V3, P342; Handl J, 2006, IEEE IJCNN, P3319; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Kwak N, 2002, IEEE T NEURAL NETWOR, V13, P143, DOI 10.1109/72.977291; Liu H, 2008, CH CRC DATA MIN KNOW, P3; Martinez-Uso A, 2006, INT C PATT RECOG, P760; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226; Ren JT, 2008, LECT NOTES ARTIF INT, V5012, P970; WANG B, 2008, INT C COMP SCI SOFTW, P210; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Zhao JD, 2008, NEUROCOMPUTING, V71, P1842, DOI 10.1016/j.neucom.2007.06.014; ZHAO Z, 2007, SDM, P641; Zhu X., 2006, 1530 TR U WISC MAD	17	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-4735-0				2009							535	540		10.1109/ISDA.2009.211		6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BTY07	WOS:000288405800092	
B	Valls, JM; Aler, R			IEEE	Valls, Jose M.; Aler, Ricardo			Optimizing Linear and Quadratic Data Transformations for Classification Tasks	2009 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS			English	Proceedings Paper	9th International Conference on Intelligent Systems Design and Applications	NOV 30-DEC 02, 2009	Pisa, ITALY	Machine Intelligence Res Lab, IEEE Syst Man & Cybernetics Soc, Int Fuzzy Syst Assoc, European Neural Network Soc, European Soc Fuzzy Log & Technol, World Fed Soft Comp	Univ Pisa	Data transformations; General Euclidean Distances; Evolutionary Computation; Evolutionary-based Machine Learning	DISCRIMINANT-ANALYSIS	Many classification algorithms use the concept of distance or similarity between patterns. Previous work has shown that it is advantageous to optimize general Euclidean distances (GED). In this paper, we optimize data transformations, which is equivalent to searching for GEDs, but can be applied to any learning algorithm, even if it does not use distances explicitly. Two optimization techniques have been used: a simple Local Search (LS) and the Covariance Matrix Adaptation Evolution Strategy (CMA-ES). CMA-ES is an advanced evolutionary method for optimization in difficult continuous domains. Both diagonal and complete matrices have been considered. The method has also been extended to a quadratic non-linear transformation. Results show that in general, the transformation methods described here either outperform or match the classifier working on the original data.	[Valls, Jose M.; Aler, Ricardo] Univ Carlos III Madrid, Madrid, Spain	Valls, JM (reprint author), Univ Carlos III Madrid, Madrid, Spain.	jvalls@inf.uc3m.es; aler@inf.uc3m.es					Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Bouckaert RR, 2004, LECT NOTES ARTIF INT, V3056, P3; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Hansen N, 2001, EVOL COMPUT, V9, P159, DOI 10.1162/106365601750190398; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; OSTERMEIER A, 1994, EVOLUTIONARY COMPUTA, V4, P369; Ripley B. D., 1996, PATTERN RECOGNITION; Sierra A, 2002, PATTERN RECOGN, V35, P1291, DOI 10.1016/S0031-3203(01)00107-8; Sierra A, 2006, IEEE T EVOLUT COMPUT, V10, P81, DOI 10.1109/TEVC.2005.856069; Tou J.T., 1974, PATTERN RECOGNITION; Valls JM, 2007, COMPUT INFORM, V26, P33; Weisberg S., 1985, APPL LINEAR REGRESSI	12	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-4735-0				2009							1025	1030		10.1109/ISDA.2009.222		6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BTY07	WOS:000288405800175	
S	Tafazzoli, E; Saif, M			IEEE	Tafazzoli, Esmaeil; Saif, Mehrdad			Application of combined support vector machines in process fault diagnosis	2009 AMERICAN CONTROL CONFERENCE, VOLS 1-9	PROCEEDINGS OF THE AMERICAN CONTROL CONFERENCE		English	Proceedings Paper	American Control Conference 2009	JUN 10-12, 2009	St Louis, MO				NEAREST-NEIGHBOR CLASSIFICATION; FISHER DISCRIMINANT-ANALYSIS	The performance of Combined Support Vector Machines, C-SVM, is examined by comparing it's classification results with k-nearest neighbor and simple SVM classifier. For our experiments we use training and testing data obtained from two benchmark industrial processes. The first set is simulated data generated from Tennessee Eastman process simulator and the second set is the data obtained by running experiment on a Three Tank system. Our results show that the C-SVM classifier gives the lowest classification error compared to other methods. However, the complexity and computation time become issues, which depend on the number of faults in the data and the data dimension. We also examined Principal Component Analysis, using PC scores as input features for the classifiers but the performance was not comparable to other classifiers' results. By selecting appropriate number of variables using contribution charts for classification, the performance of the classifiers on Tennessee Eastman data enhances significantly. Therefore, using contribution charts for selecting the most important variables is necessary when the number of variables is large.	[Tafazzoli, Esmaeil; Saif, Mehrdad] Simon Fraser Univ, Sch Engn Sci, Vancouver, BC V5A 1S6, Canada	Saif, M (reprint author), Simon Fraser Univ, Sch Engn Sci, 8888 Univ Dr, Vancouver, BC V5A 1S6, Canada.	saif@ensc.sfu.ca					ATHITSOS V, 2005, IEEE COMPT SOC C COM, V3, P45; Bishop C. M., 2006, PATTERN RECOGNITION; Chiang LH, 2000, CHEMOMETR INTELL LAB, V50, P243, DOI 10.1016/S0169-7439(99)00061-1; Chiang LH, 2004, COMPUT CHEM ENG, V28, P1389, DOI 10.1016/j.compchemeng.2003.10.002; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; DOWNS JJ, 1993, COMPUT CHEM ENG, V17, P245, DOI 10.1016/0098-1354(93)80018-I; Gunn S, 1998, SUPPORT VECTOR MACHI; GUO M, 2003, IEEE P SYST MAN CYBE, V3, P2710; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; HE Q, 2008, IEEE T SEMICONDUCTOR, V20, P345; MORI G, 2008, LECT NOTES; PING L, 2007, P 4 INT S NEUR NETW, P448; PINGPENG Y, 2008, IEEE INT WORKSH SEM, P133; SHUBIN W, 2008, INT C BIOM ENG INF, P240; SONG Y, 2007, IKNN INFORM K NEARES; Zhang H., 2006, IEEE INT C COMP VIS, V2, P2126; ZHAO X, 2005, IEEE T IND ELECT ISI, V4, P1715; *AMIRA, 2002, DTS200 LAB SET 3 TAN	19	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0743-1619	978-1-4244-4523-3	P AMER CONTR CONF			2009							3429	3433		10.1109/ACC.2009.5160577		5	Automation & Control Systems	Automation & Control Systems	BLF29	WOS:000270044901237	
B	Giguere, P; Dudek, G; Prahacs, C; Plamondon, N; Turgeon, K			IEEE	Giguere, Philippe; Dudek, Gregory; Prahacs, Christopher; Plamondon, Nicolas; Turgeon, Katrine			Unsupervised Learning of Terrain Appearance for Automated Coral Reef Exploration	2009 CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION			English	Proceedings Paper	6th Canadian Conference on Computer and Robot Vision	MAY 25-27, 2009	Kelowna, CANADA	Canadian Image Proc & Pattern Recognit Soc, Int Assoc Pattern Recognit			IMAGE SEGMENTATION	We describe a navigation and coverage system based on unsupervised learning driven by visual input. Our objective is to allow a robot to remain continuously, moving above a terrain of interest using visual feedback to avoid leaving this region. As a particular application domain, we are interested in doing this in open water, but the approach makes few domain-specific assumptions. Specifically, our system employed an unsupervised learning technique to train a k-Nearest Neighbor classifier to distinguish between images of different terrain types through image segmentation. A simple random exploration strategy was used with this classifier to allow the robot to collect data while remaining confined above a coral reef without the need to maintain pose estimates. We tested the technique in simulation, and a live deployment was conducted in open water During the latter, the robot successfully navigated autonomously, above a coral reef during a 20 minutes period.	[Giguere, Philippe; Dudek, Gregory; Prahacs, Christopher; Plamondon, Nicolas] McGill Univ, Ctr Intelligent Machines, Montreal, PQ H3A 2A7, Canada	Giguere, P (reprint author), McGill Univ, Ctr Intelligent Machines, Montreal, PQ H3A 2A7, Canada.	philg@cim.mcgill.ca; dudek@cim.mcgill.ca; cprahacs@cim.mcgill.ca; nicola@cim.mcgill.ca; katrine.turgeon@mail.mcgill.ca					BUEHLER M, 2001, RHEX SIMPLE HIGHLY M, V20, P616; Chen CW, 1998, IEEE T IMAGE PROCESS, V7, P1673, DOI 10.1109/83.730379; Corke P, 2007, IEEE INT CONF ROBOT, P4556, DOI 10.1109/ROBOT.2007.364181; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devroye L, 1997, PROBABILISTIC THEORY; DUDEK G, 2005, IEEE RSJ INT C INT R; DUNBABIN M, 2005, SPRINGER TRACTS ADV, V25, P31; Eustice R., 2005, P ROB SCI SYST CAMBR; GIGUERE P, 2009, P IEEE INT C ROB AUT; GIGUERE P, 2008, P ROB SCI SYST ZUR S, V4; PLAMONDON N, 2008, OC 08 MTS IEEE QUEB; SATTAR J, 2008, P 11 INT S EXP ROB I; SATTAR J, 2005, IEEE RSJ INT C INT R; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; THERRIEN CW, 1983, COMPUT VISION GRAPH, V22, P313, DOI 10.1016/0734-189X(83)90079-8; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884	16	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-4211-9				2009							268	275		10.1109/CRV.2009.41		8	Computer Science, Artificial Intelligence; Robotics	Computer Science; Robotics	BPS74	WOS:000279806900037	
B	Celebi, AT; Gullu, MK; Erturk, S			IEEE	Celebi, Aysun Tasyapi; Gullu, M. Kemal; Erturk, Sarp			Low-Complexity Iris Recognition Using One-Bit Transform and Angular Radial Partitioning	2009 IEEE 17TH SIGNAL PROCESSING AND COMMUNICATIONS APPLICATIONS CONFERENCE, VOLS 1 AND 2			Turkish	Proceedings Paper	IEEE 17th Signal Processing and Communications Applications Conference	APR 09-11, 2009	Antalya, TURKEY	IEEE				In this paper, a novel low-complexity iris recognition system based on-bit transform BTg and angular radial partitioning zARPg is proposed. A binary iris image is obtained using BT on iris image. ARP is applied to this binary image and a feature vector is extracted considering the amount of data in the partitions and identification is executed. An important advantage of the proposed approach is its low-complexity. Furthermore, the method gives high identification and verification accuracies.	[Celebi, Aysun Tasyapi; Gullu, M. Kemal; Erturk, Sarp] Kocaeli Univ, Elekt & Haberlesme Muhendisligi Bolumu Veziroglu, TR-41040 Izmir, Turkey	Celebi, AT (reprint author), Kocaeli Univ, Elekt & Haberlesme Muhendisligi Bolumu Veziroglu, TR-41040 Izmir, Turkey.	aysun.tasyapi@gmail.com; kemalg@kou.edu.tr; sertur@kou.edu.tr					BLACK E, DICT ALGORITHMS DATA; Boles WW, 1998, IEEE T SIGNAL PROCES, V46, P1185, DOI 10.1109/78.668573; Chalechale A, 2004, IEE P-VIS IMAGE SIGN, V151, P93, DOI 10.1049/ip-vis:20040332; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAUGMAN, 2002, PREC C C INT C IM PR; Dobes Michal, IRIS DATABASE; Masek L., MATLAB SOURCE CODE B; MURON JP, 2000, HUMAN IRIS STRUCTURE, P87; Natarajan B, 1997, IEEE T CIRC SYST VID, V7, P702, DOI 10.1109/76.611181; VATSA M, 2008, SYSTEMS MAN CYBERN B, P1021; Wildes R. P., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), DOI 10.1109/ACV.1994.341298	11	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-4435-9				2009							910	913				4	Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BMY66	WOS:000273935600228	
S	Register, AH; Mallik, M; Blair, WD; Burton, C; Burns, P			IEEE	Register, Andy H.; Mallik, Mahendra; Blair, W. Dale; Burton, Chris; Burns, Paul			Detection and Diagnosis of Radar Modeling Errors using Covariance Consistency	2009 IEEE AEROSPACE CONFERENCE, VOLS 1-7	IEEE Aerospace Conference Proceedings		English	Proceedings Paper	2009 IEEE Aerospace Conference	MAR 07-14, 2009	Big Sky, MT				RAYLEIGH TARGETS; DATA ASSOCIATION; ALGORITHM; TRACKING; CLASSIFICATION	Often, detection-based tracking algorithms are developed without much regard for the effects of either the radar's analog signal processing or its digital signal-processing algorithms. In this paper, we combine the effects of the radar's signal processing and tracking algorithms to assess the combined effect on covariance consistency of various algorithms. To do this, we first define the terms detection, detection primitive, and measurement. Next, we provide a detailed dataflow diagram for the processing chain of an electronically-scanned radar so that we can examine the propagation of truth data through various coordinate frames relative to radar signal processing. We examine issues related to expressing truth data in different frames and different relationships among targets. We describe in detail many of the algorithms in the signal-processing chain of typical monopulse radar and finally analyze and demonstrate the covariance consistency of various algorithms in the radar processing chain. When properly applied, covariance consistency analysis can be used to detect and correct inconsistent algorithms, invalid assumptions, and coding errors. The techniques described in this paper provide insight in determining system covariance requirements and may be used to ensure that both the design and implementation of radar processing algorithms provide good covariance consistency. The example simulations provide a baseline for algorithm covariance consistency, examine some common approximations used to simplify radar simulations, and demonstrate the effect of implementation errors that actually occurred during model development.(12)	[Register, Andy H.; Mallik, Mahendra; Blair, W. Dale; Burton, Chris; Burns, Paul] Georgia Tech Res Inst, Sensors & Electromagnet Applicat Lab, Air & Missile Def Div, Smyrna, GA 30080 USA	Register, AH (reprint author), Georgia Tech Res Inst, Sensors & Electromagnet Applicat Lab, Air & Missile Def Div, 7220 Richardson Rd, Smyrna, GA 30080 USA.	andy.register@gtri.gatech.edu; mahendra.mallik@gtri.gatech.edu; dale.blair@gtri.gatech.edu; chris.burton@gtri.gatech.edu; paul.burns@gtri.gatech.edu					Anderson B. D. O., 1979, OPTIMAL FILTERING; Bar-Shalom Y., 1995, MULTITARGET MULTISEN; Bar-Shalom Y., 1990, MULTITARGET MULTISEN, V1; BARSHALOM Y, 2001, ESTIMATION APPL TRAC, P166; Bar-Shalom Y, 2005, IEEE T AERO ELEC SYS, V41, P868, DOI 10.1109/TAES.2005.1541436; Blackman S., 1999, DESIGN ANAL MODERN T; Blair WD, 2001, IEEE T AERO ELEC SYS, V37, P452, DOI 10.1109/7.937461; Blair WD, 1998, IEEE T AERO ELEC SYS, V34, P597, DOI 10.1109/7.670340; Blair WD, 1996, PROCEEDINGS OF THE TWENTY-EIGHTH SOUTHEASTERN SYMPOSIUM ON SYSTEM THEORY, P285, DOI 10.1109/SSST.1996.493515; BLAIR WD, 1997, NSWCDDTR97167; BLOM HAP, 1988, IEEE T AUTOMAT CONTR, V33, P780, DOI 10.1109/9.1299; BURNS P, 2004, P 2004 MULT TRACK ON; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Gelb A, 1974, APPL OPTIMAL ESTIMAT; Hotelling H, 1931, ANN MATH STAT, V2, P360, DOI 10.1214/aoms/1177732979; JAIN V, 2006, IEEE 38 SSST P 5 7 M, P85; JONKER R, 1987, COMPUTING, V38, P325, DOI 10.1007/BF02278710; KENDALL M, 1983, ADV THEORY STAT, V3, P290; KURIEN T, 1990, MULTITARGET MULTISEN, P48; LI XR, 2002, P IFAC 15 WORLD C BA; Mahler R., 2007, STAT MULTISOURCE MUL; Mallick M., 2003, P SIGN DAT PROC SMAL; PAPANICOLOPOULO.CD, 2007, P IEEE RAD C; Pattipati K. R., 2001, P WORKSH EST TRACK F; Poore A. B., 1994, Computational Optimization and Applications, V3, DOI 10.1007/BF01299390; POORE AB, 1995, P SOC PHOTO-OPT INS, V2561, P448, DOI 10.1117/12.217718; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; Ristic B., 2004, KALMAN FILTER; Skolnik M., 1990, RADAR HDB; Vo BN, 2006, IEEE T SIGNAL PROCES, V54, P4091, DOI 10.1109/TSP.2006.881190	30	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1095-323X	978-1-4244-2621-8	AEROSP CONF PROC			2009							1654	1670				17	Engineering, Aerospace; Engineering, Electrical & Electronic	Engineering	BME07	WOS:000271964000169	
B	Jo, T			IEEE	Jo, Taeho			Categorization of News Articles using Neural Text Categorizer	2009 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3			English	Proceedings Paper	18th IEEE International Conference on Fuzzy Systems	AUG 20-24, 2009	Jeju Isl, SOUTH KOREA	IEEE			SUPPORT VECTOR MACHINES; CLASSIFICATION	This research proposes the application or NTC (Neural Text Categorizer) for categorizing news articles. Even if the research on text categorization has been progressed very much, documents should be still encoded into numerical vectors. Encoding so causes the two main problems: huge dimensionality and sparse distribution. The idea of this research as the solution to the problems is to encode documents into string vectors and apply the NTC as a string vector based approach to text categorization. The idea will be described in detail and validated.	Inha Univ, Inchon, South Korea	Jo, T (reprint author), Inha Univ, Inchon, South Korea.						Burr Ridge I, 1997, MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N., 2000, SUPPORT VECTOR MACHI; Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; Estabrooks A, 2004, COMPUT INTELL, V20, P18, DOI 10.1111/j.0824-7935.2004.t01-1-00228.x; Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428; Joachims T., 1998, P 10 EUR C MACH LEAR, P143; Kononenko I., 1989, P 4 EUR WORK SESS LE, P91; Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687; Massand B., 1992, P 15 ACM INT C RES D, P59; McClelland J. L, 1986, PARALLEL DISTRIBUTED, V1; McClelland JL, 1986, PARALLEL DISTRIBUTED, V2; Mladenic D., 1999, P INT C MACH LEARN, P256; Ruiz ME, 2002, INFORM RETRIEVAL, V5, P87, DOI 10.1023/A:1012782908347; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Wiener E.D., 1995, THESIS U COLORADO; Yang Y., 1999, INFORMATION RETRIEVA, V1, P67	17	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-3596-8				2009							19	22		10.1109/FUZZY.2009.5277330		4	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	BND85	WOS:000274242600004	
B	Ko, DQ; Oentaryo, RJ; Pasquier, M			IEEE	Ko Dequan; Oentaryo, Richard J.; Pasquier, Michel			An Adaptive History Network Method to Improve the Genetic Optimization of Pattern Recognition Systems	2009 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3			English	Proceedings Paper	18th IEEE International Conference on Fuzzy Systems	AUG 20-24, 2009	Jeju Isl, SOUTH KOREA	IEEE			NEURAL-NETWORKS; ALGORITHM	The existence of many pattern recognition systems (PRSs) and their relative merits and drawbacks highlights the need for a metalearning framework that can find the best PRS method for a given task. To address this issue, a hyperparameter evolutionary optimization (HPEO) framework was previously devised, initially using a genetic algorithm to tune external PRS parameters in a modular fashion, decoupled from its internal components. To further improve the effectiveness of HPEO and improve the diversity of the hyperparameter solutions found, this paper presents an extension that realizes cross-generation learning with an adaptive history network (AHN), which promotes exploring new regions in the search space while avoiding regions that have been searched extensively. The proposed approach, termed HPEO-AHN, is particularly suitable for tuning powerful but complex PRSs such as neuro-fuzzy systems (NFS). Preliminary experiments with two state-of-the-art NFSs optimized using the new approach have shown encouraging results.	[Ko Dequan; Oentaryo, Richard J.; Pasquier, Michel] Nanyang Technol Univ, Ctr Computat Intelligence, Sch Comp Engn, Singapore 639798, Singapore	Ko, DQ (reprint author), Nanyang Technol Univ, Ctr Computat Intelligence, Sch Comp Engn, Nanyang Ave, Singapore 639798, Singapore.	pasquier@ieee.org					Avriel M., 1966, FIBONACCI QUART, V4, P265; Back T., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585888; Bhagat P., 2005, PATTERN RECOGNITION; Coello C. A. C., 1999, Knowledge and Information Systems, V1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fisher RA, 1936, ANN EUGENIC, V7, P179; Goldberg D. E, 1989, GENETIC ALGORITHMS S; Guo XC, 2008, NEUROCOMPUTING, V71, P3211, DOI 10.1016/j.neucom.2008.04.027; HESTENES MR, 1952, J RES NAT BUR STAND, V49, P409, DOI 10.6028/jres.049.044; JACOBS I, 1989, HUM REPROD, V1, P1; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; John G., 1995, P 11 C UNC ART INT, P338; KENNEDY J, 1995, P IEEE INT C NEUR NE, P1942, DOI DOI 10.1109/ICNN.1995.488968; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Leung FHF, 2003, IEEE T NEURAL NETWOR, V14, P79, DOI 10.1109/TNN.2002.804317; Lin CT, 1996, NEURAL FUZZY SYSTEMS; LUMANPAUW E, 2007, P IEEE C EV COMP SIN, P1593; Maguire LP, 1998, INFORM SCIENCES, V112, P125, DOI 10.1016/S0020-0255(98)10026-9; Mark Baldwin J., 1996, AM NAT, V30, P441, DOI DOI 10.1086/276408; Milano M, 2004, IEEE T SYST MAN CY B, V34, P925, DOI 10.1109/TSMCB.2003.818432; OENTARYO RJ, 2008, P IEEE INT JOINT C N, P2660; Oentaryo RJ, 2008, EXPERT SYST APPL, V35, P1825, DOI 10.1016/j.eswa.2007.08.108; Pedrycz W, 2005, IEEE T SYST MAN CY B, V35, P633, DOI 10.1109/TSMCB.2005.843975; Podlena JR, 1998, APPL INTELL, V8, P103, DOI 10.1023/A:1008227606285; QUEK HC, 1999, EXPERT SYSTEMS TECHN; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Seng TL, 1999, IEEE T SYST MAN CY B, V29, P226, DOI 10.1109/3477.752795; Siarry P, 2008, NAT COMPUT SER, P1, DOI 10.1007/978-3-540-72960-0; Smith A., 2000, BAYESIAN THEORY, p[655, 648, 647]; Vilalta R, 2002, ARTIF INTELL REV, V18, P77, DOI 10.1023/A:1019956318069; Wang CH, 2001, IEEE T SYST MAN CY B, V31, P467, DOI 10.1109/3477.931548; Watanabe S., 1985, PATTERN RECOGNITION; Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585893; Yao X, 1999, P IEEE, V87, P1423	34	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-3596-8				2009							23	28				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	BND85	WOS:000274242600005	
B	Chua, T; Tan, W			IEEE	Chua, TeckWee; Tan, WoeiWan			A New Fuzzy Rule-Based Initialization Method for K-Nearest Neighbor Classifier	2009 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3			English	Proceedings Paper	18th IEEE International Conference on Fuzzy Systems	AUG 20-24, 2009	Jeju Isl, SOUTH KOREA	IEEE			ALGORITHM	The performances of conventional crisp and fuzzy K-Nearest neighbor (K-NN) algorithms trained using finite samples tends to be poor [1], [2]. With "holes" in the training data, it is unlikely that the decision area formed can actually represent the underlying data distribution. There is a need to capture more useful information from the limited training samples, therefore we propose a new fuzzy rule-based K-NN algorithm. A fuzzy rule-based initialization procedure differentiates our proposed algorithm from the conventional fuzzy K-NN algorithm. The new initialization procedure allows us to handle the imprecise inputs (neighborhood density and distance) through the natural framework of fuzzy logic system. Unlike conventional K-NN algorithms, the ability to fine tune the membership functions can lead to a highly versatile decision boundary. Thus, the new algorithm can be specifically tuned for different problems to achieve better results. The advantage is demonstrated on a synthetic data set in two-dimensional space. In addition, we also adopt weighted Euclidean distance measurement to overcome the curse of dimensionality [3]. The Euclidean distance weights and the parameters of the fuzzy rule-based system are then optimized with Genetic Algorithm (GA) simultaneously. The practical applicability of the proposed algorithm is verified on four UCI data sets (Bupa liver disorders, Glass, Pima Indians diabetes and Wisconsin breast cancer) and Ford automotive data set with an improvement of 3.42% in classification rate on average.	[Chua, TeckWee; Tan, WoeiWan] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore	Chua, T (reprint author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore.	cteckwee@nus.edu.sg; eletanww@nus.edu.sg					ABOUNASR M, 2007, FORD CLASSIFICATION; Asuncion A., 2007, UCI MACHINE LEARNING; Chua TW, 2008, LECT NOTES COMPUT SC, V5361, P101; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; EAGEN, 2008, Patent No. 7353088; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Kuncheva L., 2000, FUZZY CLASSIFIER DES; Mendel J. M., 2001, UNCERTAIN RULE BASED; Paredes R, 2006, IEEE T PATTERN ANAL, V28, P1100, DOI 10.1109/TPAMI.2006.145; Pedrycz W, 1997, FUZZY SET SYST, V90, P171, DOI 10.1016/S0165-0114(97)00083-3; Shang WQ, 2005, LECT NOTES ARTIF INT, V3801, P741; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403	14	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-3596-8				2009							415	420		10.1109/FUZZY.2009.5277215		6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	BND85	WOS:000274242600072	
S	Teixeira, LA; de Oliveira, ALI			IEEE	Teixeira, Lamartine Almeida; Inacio de Oliveira, Adriano Lorena			Predicting Stock Trends through Technical Analysis and Nearest Neighbor Classification	2009 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS (SMC 2009), VOLS 1-9	IEEE International Conference on Systems Man and Cybernetics Conference Proceedings		English	Proceedings Paper	IEEE International Conference on Systems, Man and Cybernetics	OCT 11-14, 2009	San Antonio, TX	IEEE		stock trend prediction; financial forecasting; machine learning; nearest neighbor prediction	NEURAL-NETWORKS; MARKETS	This paper presents the results of method designed to predict price trends in the stock market. Our first and foremost objective is to study the feasibility of the practical use of an intelligent prediction system exclusively based on the history of daily stock closing prices and volumes. To this end we propose a technique that consists of a combination of a nearest neighbor classifier and some well known tools of technical analysis, namely, stop loss, stop gain and RSI filter. For assessing the potential use of the proposed method in practice we compared the results obtained to the results that would be obtained by adopting a buy-and-hold strategy. The key performance measure in this comparison was profitability. The proposed method was shown to generate considerable higher profits than buy-and-hold for most of the companies, with few buy operations generated and, consequently, minimizing the risk of market exposure.	[Teixeira, Lamartine Almeida] Univ Pernambuco, Dept Comp Syst, Recife, PE, Brazil	Teixeira, LA (reprint author), Univ Pernambuco, Dept Comp Syst, Recife, PE, Brazil.	lat@dsc.upe.br; alio@cin.ufpe.br					AFOLABI MO, 2007, P 40 HAW INT C SYST, P48; Bao DP, 2008, EXPERT SYST APPL, V34, P620, DOI 10.1016/j.eswa.2006.09.043; Cao L. J., 2003, IEEE T NEURAL NETWOR, V14; Chang J, 2007, P 2 INT C INN COMP I, P390; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FAMA EF, 1970, J FINANC, V25, P383, DOI 10.2307/2325486; GUO X, 2007, 3 INT C NAT COMP ICN, P518, DOI 10.1109/ICNC.2007.145; Hassoun M. H., 1995, FUNDAMENTALS ARTIFIC; HAUGEN RA, 1999, NEW FINANCE CASE EFF; Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.121.126; Kim HJ, 2007, APPL SOFT COMPUT, V7, P569, DOI 10.1016/j.asoc.2006.03.004; Kwon YK, 2007, IEEE T NEURAL NETWOR, V18, P851, DOI 10.1109/TNN.2007.891629; Leigh W, 2008, IEEE T SYST MAN CY A, V38, P93, DOI 10.1109/TSMCA.2007.909508; Los CA, 2000, ADV E, V14, P329; MANDZIUK J, 2007, P INT JOINT C NEUR N, P2515; Murphy JJ, 1999, TECHNICAL ANAL FINAN; NAGARAJAN V, 2005, INT C CONTR AUT ICCA, P259; Nanni L, 2006, PATTERN RECOGN LETT, V27, P109, DOI 10.1016/j.patrec.2005.07.008; Saad EW, 1998, IEEE T NEURAL NETWOR, V9, P1456, DOI 10.1109/72.728395; SAI Y, 2007, IEEE INT C GRAN COMP, P659; TAN P, 1994, P 2 SING INT C INT S; TEIXCIRA LA, P 2008 10 BRAZ S NEU, P33; Vanstone B., 2003, Proceedings of the Eighth Australian and New Zealand Intelligent Information Systems Conference (ANZIIS 2003); White H, 1988, IEEE INT C NEURAL NE, P451	25	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X	978-1-4244-2793-2	IEEE SYS MAN CYBERN			2009							3094	3099		10.1109/ICSMC.2009.5345944		6	Computer Science, Cybernetics; Computer Science, Information Systems	Computer Science	BPP02	WOS:000279574601227	
B	Kaya, GT; Ersoy, OK; Kamasak, ME			IEEE	Kaya, G. Taskin; Ersoy, O. K.; Kamasak, M. E.			SUPPORT VECTOR SELECTION AND ADAPTATION FOR CLASSIFICATION OF EARTHQUAKE IMAGES	2009 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM, VOLS 1-5	IEEE International Symposium on Geoscience and Remote Sensing IGARSS		English	Proceedings Paper	IEEE International Geoscience and Remote Sensing Symposium	JUL 12-17, 2009	Cape Town, SOUTH AFRICA	IEEE		Support Vector Machines; Support Vector Selection and Adaptation; Classification of Earthquake Images		In this paper, we propose a new machine learning algorithm that we named Support Vector Selection and Adaptation (SVSA). Our aim is to achieve the classification performance of the nonlinear support vector machines (SVM) by using only the support vectors of the linear SVM. The proposed method does not require any type of kernels, and requires less computation time compared to the nonlinear SVM The SVSA algorithm has two steps. selection and adaptation. In the first step, some of the support vectors obtained from linear SVM are selected. Then the selected support vectors are adapted iteratively in the traning algorithm. The proposed method are compared against the linear and nonlinear SVM on sythetic and real remote sensing data. The results show that the proposed SVSA algorithm achieves very close performance to nonlinear SVM without any kernels in less computation time.	[Kaya, G. Taskin] Istanbul Tech Univ, Inst Informat, TR-80626 Istanbul, Turkey	Kaya, GT (reprint author), Istanbul Tech Univ, Inst Informat, TR-80626 Istanbul, Turkey.	gulsen@be.itu.edu.tr; ersoy@purdue.edu; kamasak@itu.edu.tr					Chang C-C., 2001, LIBSVM LIB SUPPORT V; Cherkassky V, 1998, LEARNING DATA CONCEP; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duin R, 2007, MATLAB TOOLBOX PATTE; Kasapoglu NG, 2007, IEEE T GEOSCI REMOTE, V45, P3880, DOI 10.1109/TGRS.2007.900699; KAYA GT, 2008, TRECE092 PURD U; KOHONEN T, 1986, TKKFA601 HEL U TECHN; [Yue Shihong 岳士弘], 2003, Applied Mathematics. Series B : A Journal of Chinese Universities, V18, P332, DOI 10.1007/s11766-003-0059-5	8	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-3394-0	INT GEOSCI REMOTE SE			2009							1102	1105				4	Geosciences, Multidisciplinary; Remote Sensing	Geology; Remote Sensing	BQI05	WOS:000281054100279	
B	Buondonno, L; Fortino, G; Galzarano, S; Giannantonio, R; Giordano, A; Gravina, R; Guerrieri, A			IEEE	Buondonno, Luigi; Fortino, Giancarlo; Galzarano, Stefano; Giannantonio, Roberta; Giordano, Antonio; Gravina, Raffaele; Guerrieri, Antonio			Programming Signal Processing Applications on Heterogeneous Wireless Sensor Platforms	2009 IEEE INTERNATIONAL WORKSHOP ON INTELLIGENT DATA ACQUISITION AND ADVANCED COMPUTING SYSTEMS: TECHNOLOGY AND APPLICATIONS	IEEE International Workshop on Intelligent Data Acquisition and Advanced Computing Systems-Technology and Applications-IDAACS		English	Proceedings Paper	5th IEEE International Workshop on Intelligent Data Acquisition and Advanced Computing Systems	SEP 21-23, 2009	Rende, ITALY	Res Inst Intelligent Comp Syst & Fac Comp Informat Technologies, Univ Calabria, IEEE, Ukraine Sect		Wireless body sensor networks; software development methodology; task-oriented programming; distributed signal processing; SPINE		This paper proposes the SPINE frameworks (SPINE1.x and SPINE2) for the programming of signal processing applications on heterogeneous wireless sensor platforms. In particular, two integrable approaches based on the proposed frameworks are described that allow to develop applications for wireless body sensor networks (WBSNs) constituted by heterogeneous sensor nodes. The approaches are exemplified through a human activity recognition system based on a WBSN composed of two types of sensor nodes, heterogeneous with respect to base software and hardware.	[Buondonno, Luigi; Fortino, Giancarlo; Galzarano, Stefano; Giordano, Antonio; Gravina, Raffaele; Guerrieri, Antonio] Univ Calabria, Dept Elect Informat & Syst DEIS, I-87036 Arcavacata Di Rende, CS, Italy	Buondonno, L (reprint author), Univ Calabria, Dept Elect Informat & Syst DEIS, I-87036 Arcavacata Di Rende, CS, Italy.	luigi.buondonno@guest.telecomitalia.it; g.fortino@unical.it; galzarano@si.deis.unical.it; roberta.giannantonio@telecomitalia.it; agiordano@si.deis.unical.it; rgravina@deis.unical.it; aguerrieri@deis.unical.it					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FORTINO G., 2009, P IEEE S IND EMB SYS; Fortino G., 2009, P 2009 IEEE INT C SY; GAMA O, 2007, IEEE INT C SENS TECH; Gravina R., 2008, P IEEE INT C SYST MA; Iyengar S., 2008, P 3 INT C BOD AR NET; LOMBRISER C, 2007, P 2 INT C BOD AR NET; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; Selic B, 2003, IEEE SOFTWARE, V20, P19, DOI 10.1109/MS.2003.1231146; Shnayder V., 2005, TR0805 HARV U DIV EN; ZigBee Alliance, ZIGBEE ALL; *SPINE, SPINE DOC SOFTW; CONTIKI DOCUMENTATIO; Z STACK ZIGBEE PROTO	14	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-4881-4	INT WORKSH INT DATA			2009							682	687		10.1109/IDAACS.2009.5342888		6	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BPZ03	WOS:000280406400135	
S	He, W; Wang, Y		Lan, H		He Wei; Wang Yu			Text Representation and Classification Based on Multi-Instance Learning	2009 INTERNATIONAL CONFERENCE ON MANAGEMENT SCIENCE & ENGINEERING (16TH), VOLS I AND II, CONFERENCE PROCEEDINGS	International Conference on Management Science and Engineering-Annual Conference Proceedings		English	Proceedings Paper	16th International Conference on Management Science and Engineering	SEP 14-16, 2009	Moscow, RUSSIA	Natl Nat Sci Fdn China, Harbin Inst Technol, State Univ Management, IEEE Technol Management Council		bag of sentences; multi-instance learning; text classification; text representation		In multi-instance learning, the training set comprises labeled bags which are composed of unlabeled instances, and the task is to predict the labels of unseen bags. In this paper, a text mining problem, i.e. text representation, is investigated from a multi-instance view. In detail, each text is regarded as a bag while each of its sentences is regarded as an instance. Bag can be labeled by its class label and its similarity is defined by sentence similarity The text classification problem is translated into multi-instance learning problem. In order to solve this problem, a Chinese text classifier focusing on bag has been built by KNN algorithm and good average precision 92.12% and recall 92.01% have been achieved in the experiments.	[He Wei; Wang Yu] Dalian Univ Technol, Sch Management, Dalian 116024, Peoples R China	He, W (reprint author), Dalian Univ Technol, Sch Management, Dalian 116024, Peoples R China.						CHENG Y, 2006, COMPUTER ENG DESIGN, V18, P3444; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; FOLTZ PW, 1999, P 16 INT C ICML 99 B, P27; Foltz PW, 1998, DISCOURSE PROCESS, V25, P285; JUN W, 2000, SOLVING MULTIPLE INS; LI RL, 2008, TEXT CLASSIFICATION; Li YH, 2006, IEEE T KNOWL DATA EN, V18, P1138, DOI 10.1109/TKDE.2006.130; LIU JH, 2007, COMPUTER ENG DESIGN, V13, P3213; LIU JH, 2007, COMPUTER ENG DESIGN, V13, P3219; Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687; [吕学强 Lu Xueqiang], 2003, [东北大学学报. 自然科学版, Journal of Northeastern University], V24, P531; MARON O, 1998, FRAMEWORK MULTIPLE I; Meadow C. T., 2000, TEXT INFORM RETRIEVA; Mitra M., 1997, P ACL 97 EACL 97 WOR, P39; Montes-y-Gomez M, 2002, LECT NOTES ARTIF INT, V2393, P122; O Maron, 1998, LEARNING AMBIGUITY; SALTON G, 1968, J ACM, V15, P8, DOI 10.1145/321439.321441; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; WEN YK, 2004, J CHINA SOC SCI TECH, V6, P643; WEN YK, 2005, KNOWLEDGE ELEMENT MI; WEN YK, 2005, J CHINA SOC SCI TECH, V6, P663; YANG SC, 2008, J CHINA SOC SCI TECH, V1, P35; ZHANG HP, ICTCLAS3 0 API OL; ZHANG XL, 2002, J CHINA SOC SCI TECH, V4, P413; Zhou ZH, 2006, J COMPUT SCI TECHNOL, V21, P800, DOI 10.1007/s11390-006-0800-7; TEXT CLASSIFICATION	27	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2155-1847	978-1-4244-3970-6	INT C MANAGE SCI ENG			2009							34	39		10.1109/ICMSE.2009.5317537		6	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Engineering, Industrial; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	BMY95	WOS:000273956800005	
B	Starzacher, A; Rinner, B			IEEE	Starzacher, Andreas; Rinner, Bernhard			Single Sensor Acoustic Feature Extraction for Embedded Realtime Vehicle Classification	2009 INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS AND TECHNOLOGIES (PDCAT 2009)			English	Proceedings Paper	10th International Conference on Parallel and Distributed Computing, Applications and Technologies	DEC 08-11, 2009	Higashi, JAPAN			acoustic feature extraction; signal processing; vehicle classification; embedded sensor fusion	FUSION	Vehicle classification is an important task for various traffic monitoring applications. This paper investigates the capabilities of acoustic feature generation for vehicle classification. Six temporal and spectral features are extracted from the audio recordings and six different classification algorithms are compared using the extracted features. We focus on a single sensor setting to keep the computational effort low and evaluate its classification accuracy and realtime performance. The experimental evaluation is performed on our embedded platform using recorded data of about 150 vehicles. The results are applied in our ongoing research on fusing video, laser and acoustic data for realtime traffic monitoring.	[Starzacher, Andreas; Rinner, Bernhard] Klagenfurt Univ, Inst Networked & Embedded Syst, Vienna, Austria	Starzacher, A (reprint author), Klagenfurt Univ, Inst Networked & Embedded Syst, Vienna, Austria.	andreas.starzacher@uni-klu.ac.at; bernhard.rinner@uni-klu.ac.at					BAOFENG G, 2008, 11 INT C INF FUS COL, P1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duarte MF, 2004, J PARALLEL DISTR COM, V64, P826, DOI 10.1016/j.jpdc.2004.03.020; Geiger D., 1997, MACH LEARN, P131; HU H, 2005, CSM422 U ESS DEP COM; Klausner A, 2008, IEEE J-STSP, V2, P538, DOI 10.1109/JSTSP.2008.925988; KOLAHDOUZAN M, 2004, VLDB 2004, V30, P840; KUSHWAHA M, 2008, IEEE INT C MULT FUS, P14; NECIOGLU BF, 2005, P SPIE C, V14, P409; Nooralahiyan AY, 1998, MATH COMPUT MODEL, V27, P205, DOI 10.1016/S0895-7177(98)00060-0; Ruser H, 2007, TM-TECH MESS, V74, P93, DOI 10.1524/teme.2007.74.3.93; STARZACHER A, 2009, P 12 INT C INF FUS F; STARZACHER A, 2008, P 4 INT C INT SENS S, P85; SULZMANN JN, 2007, P 18 EUR C MACH LEAR, P371; Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560	15	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-5291-0				2009							378	383		10.1109/PDCAT.2009.18		6	Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	BUJ28	WOS:000289503500055	
B	Pradhan, G; Kalyan, GV; Satapathy, SC; Mitra, B; Pattnaik, S		Abraham, A; Herrera, F; Carvalho, A; Pai, V		Pradhan, Gunanidhi; Kalyan, Gadde Vyshnavi; Satapathy, Suresh Chandra; Mitra, Bhabatosh; Pattnaik, Sabyasachi			Minimal ANN (MANN) model for Data Classification	2009 WORLD CONGRESS ON NATURE & BIOLOGICALLY INSPIRED COMPUTING (NABIC 2009)			English	Proceedings Paper	World Congress on Nature and Biologically Inspired Computing	DEC 09-12, 2009	Coimbatore, INDIA			ANN; Genetic Algorithm; Data classification	ARTIFICIAL NEURAL-NETWORKS	Data Classification is a prime task in Data mining. Accurate and simple data classification task can help the clustering of large dataset appropriately. In this paper we have experimented and suggested a simple ANN based classification models called as Minimal ANN ( MANN) for different classification problems. The GA is used for optimally finding out the number of neurons in the single hidden layered model. Further, the model is trained with Back Propagation (BP) algorithm and GA (Genetic Algorithm) and classification accuracies are compared. It is revealed from the simulation that our suggested model can be a very good candidate for many applications as these are simple with good performances.	[Pradhan, Gunanidhi] Bhubanananda Orissa Sch Engn, Cuttack, Orissa, India	Pradhan, G (reprint author), Bhubanananda Orissa Sch Engn, Cuttack, Orissa, India.	gunanidhi_p@rediffmail.com; vyshv.sanjana@gmail.com; sureshsatapathy@ieee.org; bhaba_mit@yahoo.co.uk; spattnaik40@yahoo.co.in					Abraham A, 2004, NEUROCOMPUTING, V56, P1, DOI 10.1016/S0925-2312(03)00369-2; Bishop C. M., 1995, NEURAL NETWORKS PATT; BUNTINE WL, 1992, STAT COMPUT, P63; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; Friedman J.H., 1984, CLASSIFICATION REGRE; Goldberg D. E, 1989, GENETIC ALGORITHMS S; HANSON R, 1992, P 12 INT JOINT C ART, P692; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Michie D, 1994, MACHINE LEARNING NEU; Richard M. D., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.4.461; Tsoi A. C., 1991, ADV NEURAL INFORMATI, V3, P963; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; Yao X, 1999, P IEEE, V87, P1423	14	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-5053-4				2009							1058	1063				6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Mathematical & Computational Biology	Computer Science; Engineering; Mathematical & Computational Biology	BUA82	WOS:000288686500180	
B	Xing, ZZ; Pei, JA; Yu, PS		Boutilier, C		Xing, Zhengzheng; Pei, Jian; Yu, Philip S.			Early Prediction on Time Series: A Nearest Neighbor Approach	21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS			English	Proceedings Paper	21st Internation Joint Conference on Artifical Intelligence (IJCAI-09)	JUL 11-17, 2009	Pasadena, CA					In this paper, we formulate the problem of early classification of time series data, which is important in some time-sensitive applications such as health-informatics. We introduce a novel concept of MPL (Minimum Prediction Length) and develop ECTS (Early Classification on Time Series), an effective 1-nearest neighbor classification method. ECTS makes early predictions and at the same time retains the accuracy comparable to that of a 1NN classifier using the full-length time series. Our empirical study using benchmark time series data sets shows that ECTS works well on the real data sets where 1NN classification is effective.	[Xing, Zhengzheng; Pei, Jian] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada	Xing, ZZ (reprint author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.	zxing@cs.sfu.ca; jpei@cs.sfu.ca; psyu@cs.uic.edu					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ding C, 2004, P 2004 ACM S APPL CO, P584, DOI 10.1145/967900.968021; DING C, 2005, P PKDD 2005, P224; EADS D, 2005, NIPS 05; GONZALEZ CJ, 2002, ECAI 02 WORKSH KNOWL, P51; Griffin MP, 2001, PEDIATRICS, V107, P97, DOI 10.1542/peds.107.1.97; Keogh E., 2002, KDD 02, P102; Keogh E. J., 2006, UCR TIME SERIES CLAS; Lesh N., 1999, P 5 ACM SIGKDD INT C, P342, DOI 10.1145/312129.312275; MYERS CS, 1981, AT&T TECH J, V60, P1389; Nanopoulos A., 2001, INT J COMPUTER RES S, V10, P49; Wei L., 2006, P 12 ACM SIGKDD INT, P748, DOI 10.1145/1150402.1150498; Xi X., 2006, P 23 INT C MACH LEAR, P1033, DOI 10.1145/1143844.1143974; Xing Z., 2008, P SIAM INT C DAT MIN, P644	14	3	3	IJCAI-INT JOINT CONF ARTIF INTELL	FREIBURG	ALBERT-LUDWIGS UNIV FREIBURG GEORGES-KOHLER-ALLEE, INST INFORMATIK, GEB 052, FREIBURG, D-79110, GERMANY		978-1-57735-426-0				2009							1297	1302				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BRU77	WOS:000283727900206	
S	Mennicke, J; Munzenmayer, C; Wittenberg, T; Schmid, U		VanderSloten, J; Verdonck, P; Nyssen, M; Haueisen, J		Mennicke, J.; Muenzenmayer, C.; Wittenberg, T.; Schmid, U.			An optimization framework for classifier learning from image data for computer-assisted diagnosis	4TH EUROPEAN CONFERENCE OF THE INTERNATIONAL FEDERATION FOR MEDICAL AND BIOLOGICAL ENGINEERING	IFMBE Proceedings		English	Proceedings Paper	4th European Conference of the International Federation for Medical and Biological Engineering (ECIFMBE)	NOV 23-27, 2008	Antwerp, BELGIUM			Classifier Learning; Computer-Assisted Diagnosis; Medical Image Data		In computer-assisted medical diagnosis it is often hard or even impossible to obtain a valid set of rules for disease classification by classical knowledge engineering methods. Alternatively, machine learning methods are applied to obtain classifiers from sets of data pre-classified by medical experts. Typically in a medical context, available data sets are imbalanced with respect to the possible classifications. E.g., in dermatology, there are only few data representing cases of malign melanoma vs. many cases representing benign nevi. Furthermore, there are different missclassification costs assigned to different classes. E.g., it is much more critical (i.e. costly) to erroneously classify a malign melanoma as benign than the other way around. We propose a universally applicable optimization framework that successfully corrects the error-based inductive bias of classifier learning methods on image data. The framework integrates several techniques of common optimization techniques, such as modifying the optimization procedure for inducer-specific parameters, modifying input data by an arcing algorithm, combining classifiers of several classifier learning methods (kNN, SVM and C4.5) with different settings according to locally-adaptive, cost-sensitive voting schemes. The framework is designed to make the learning process cost-sensitive and enforcing more balanced missclassification costs between classes. The framework was evaluated on image data for Barrett's esophagus with promising results compared to the base learners.	[Schmid, U.] Univ Bamberg, Fac WIAI, D-96045 Bamberg, Germany	Schmid, U (reprint author), Univ Bamberg, Fac WIAI, Feldkirchenstr 21, D-96045 Bamberg, Germany.	ute.schmid@uni-bamberg.de					Burr Ridge I, 1997, MACHINE LEARNING; Cohen P. R., 1982, HDB ARTIFICIAL INTEL, V3; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cuilen J., 1988, EXPERT SYST, V5, P216; Domingos P., 1999, KNOWLEDGE DISCOVERY, P155; Mennicke J., 2008, THESIS J MENNICKE U; Michie D, 1994, MACHINE LEARNING NEU; Munzenmayer C., 2006, COLOR TEXTURE ANAL M; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Scholkopf B., 1999, ADV KERNEL METHODS S	10	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1680-0737	978-3-540-89207-6	IFMBE PROC			2009	22	1-3					629	632				4	Engineering, Biomedical	Engineering	BYS76	WOS:000299998500150	
J	Tanriverdi, S; Grinberg, A; Chalmers, RM; Hunter, PR; Petrovic, Z; Akiyoshi, DE; London, E; Zhang, LH; Tzipori, S; Tumwine, JK; Widmer, G				Tanriverdi, Sultan; Grinberg, Alex; Chalmers, Rachel M.; Hunter, Paul R.; Petrovic, Zorana; Akiyoshi, Donna E.; London, Eric; Zhang, Linghui; Tzipori, Saul; Tumwine, James K.; Widmer, Giovanni			Inferences about the Global Population Structures of Cryptosporidium parvum and Cryptosporidium hominis	APPLIED AND ENVIRONMENTAL MICROBIOLOGY			English	Article							SUBTYPE ANALYSIS; HEALTHY-ADULTS; SEQUENCE; GENOTYPES; CHILDREN; CALVES; IDENTIFICATION; RECOMBINATION; APICOMPLEXAN; GLYCOPROTEIN	Cryptosporidium parvum and Cryptosporidium hominis are two related species of apicomplexan protozoa responsible for the majority of human cases of cryptosporidiosis. In spite of their considerable public health impact, little is known about the population structures of these species. In this study, a battery of C. parvum and C. hominis isolates from seven countries was genotyped using a nine-locus DNA subtyping scheme. To assess the existence of geographical partitions, the multilocus genotype data were mined using a cluster analysis based on the nearest-neighbor principle. Within each country, the population genetic structures were explored by combining diversity statistical tests, linkage disequilibrium, and eBURST analysis. For both parasite species, a quasi-complete phylogenetic segregation was observed among the countries. Cluster analysis accurately identified recently introduced isolates. Rather than conforming to a strict paradigm of either a clonal or a panmictic population structure, data are consistent with a flexible reproductive strategy characterized by the cooccurrence of both propagation patterns. The relative contribution of each pattern appears to vary between the regions, perhaps dependent on the prevailing ecological determinants of transmission.	[Tanriverdi, Sultan; Akiyoshi, Donna E.; London, Eric; Zhang, Linghui; Tzipori, Saul; Widmer, Giovanni] Tufts Cummings Sch Vet Med, Div Infect Dis, North Grafton, MA 01536 USA; [Grinberg, Alex] Massey Univ, Inst Vet Anim & Biomed Sci, Palmerston North, New Zealand; [Chalmers, Rachel M.] Singleton Hosp, NPHS Microbiol Swansea, United Kingdom Cryptosporidium Reference Unit, Swansea SA2 8QA, W Glam, Wales; [Hunter, Paul R.] Univ E Anglia, Sch Med Hlth Policy & Practice, Norwich NR4 7TJ, Norfolk, England; [Petrovic, Zorana] Univ Belgrade, Fac Vet Med, Belgrade, Serbia; [Tumwine, James K.] Makerere Univ, Dept Pediat & Child Hlth, Sch Med, Kampala, Uganda; [Tumwine, James K.] Mulago Hosp, Kampala, Uganda	Widmer, G (reprint author), Tufts Cummings Sch Vet Med, Div Infect Dis, 200 Westboro Rd, North Grafton, MA 01536 USA.	giovanni.widmer@tufts.edu	Hunter, Paul/A-7172-2008	Hunter, Paul/0000-0002-5608-6144	National Institutes of Allergy and Infectious Diseases [AI052781]	Funding from the National Institutes of Allergy and Infectious Diseases (AI052781) is gratefully acknowledged.	Abrahamsen MS, 2004, SCIENCE, V304, P441, DOI 10.1126/science.1094786; Akiyoshi DE, 2002, INFECT IMMUN, V70, P5670, DOI 10.1128/IAI.70.10.5670-5675.2002; Caccio S, 2000, PARASITOLOGY, V120, P237, DOI 10.1017/S0031182099005508; Caccio S, 2001, INT J PARASITOL, V31, P1082, DOI 10.1016/S0020-7519(01)00233-8; Cevallos AM, 2000, INFECT IMMUN, V68, P5167, DOI 10.1128/IAI.68.9.5167-5175.2000; Chalmers RM, 2008, EMERG INFECT DIS, V14, P496, DOI 10.3201/eid1403.071320; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Elwin K, 2001, APPL ENVIRON MICROB, V67, P5581, DOI 10.1128/AEM.67.12.5581-5584.2001; Enemark HL, 2002, PARASITOLOGY, V125, P331, DOI 10.1017/S0031182002002226; Feil EJ, 2004, J BACTERIOL, V186, P1518, DOI 10.1128/JB.186.5.1518-1530.2004; Feil EJ, 2001, ANNU REV MICROBIOL, V55, P561, DOI 10.1146/annurev.micro.55.1.561; Gatei W, 2006, J EUKARYOT MICROBIOL, V53, pS43, DOI 10.1111/j.1550-7408.2006.00169.x; Gatei W, 2007, INFECT GENET EVOL, V7, P197, DOI 10.1016/j.meegid.2006.08.006; Geurden T, 2007, PARASITOLOGY, V134, P1981, DOI 10.1017/S0031182007003460; Gilbert M, 2005, NATURE, V435, P491, DOI 10.1038/nature03548; Grinberg A, 2008, EPIDEMIOL INFECT, V136, P273, DOI 10.1017/S0950268807008345; HAMMING RW, 1950, AT&T TECH J, V29, P147; Haubold B, 2000, BIOINFORMATICS, V16, P847, DOI 10.1093/bioinformatics/16.9.847; Hughes JB, 2001, APPL ENVIRON MICROB, V67, P4399, DOI 10.1128/AEM.67.10.4399-4406.2001; Hunter PR, 2004, EMERG INFECT DIS, V10, P1241; Hunter PR, 2007, EMERG INFECT DIS, V13, P82; Magurran A., 2004, MEASURING BIOL DIVER; Mallon M, 2003, J MOL EVOL, V56, P407, DOI 10.1007/s00239-002-2412-3; Mallon Marianne E., 2003, Infection Genetics and Evolution, V3, P207, DOI 10.1016/S1567-1348(03)00089-3; Misic Z, 2007, PARASITOLOGY, V134, P351, DOI 10.1017/S0031182006001508; Morrison LJ, 2008, INFECT GENET EVOL, V8, P121, DOI 10.1016/j.meegid.2007.10.010; Ngouanesavanh T, 2006, J EUKARYOT MICROBIOL, V53, pS33, DOI 10.1111/j.1550-7408.2006.00166.x; Okhuysen PC, 1999, J INFECT DIS, V180, P1275, DOI 10.1086/315033; Okhuysen PC, 2002, J INFECT DIS, V185, P1320, DOI 10.1086/340132; SMITH JM, 1993, P NATL ACAD SCI USA, V90, P4384, DOI 10.1073/pnas.90.10.4384; Spano F, 1997, FEMS MICROBIOL LETT, V150, P209, DOI 10.1016/S0378-1097(97)00115-8; Strong WB, 2000, INFECT IMMUN, V68, P4117, DOI 10.1128/IAI.68.7.4117-4134.2000; Tanriverdi S, 2007, MOL MICROBIOL, V63, P1432, DOI 10.1111/j.1365-2958.2007.05594.x; Tanriverdi S, 2006, INFECT GENET EVOL, V6, P113, DOI 10.1016/j.meegid.2005.02.002; Tanriverdi S, 2006, APPL ENVIRON MICROB, V72, P2507, DOI 10.1128/AEM.72.4.2507-2513.2006; Tanriverdi S, 2003, MOL BIOCHEM PARASIT, V130, P13, DOI 10.1016/S0166-6851(03)00138-5; Tumwine JK, 2003, AM J TROP MED HYG, V68, P710; Tumwine JK, 2005, AM J TROP MED HYG, V73, P921; Turner KME, 2007, BMC MICROBIOL, V7, DOI 10.1186/1471-2180-7-30; WHITTAKE.RH, 1965, SCIENCE, V147, P250, DOI 10.1126/science.147.3655.250; Widmer G, 1998, J INFECT DIS, V178, P834; Xiao LH, 2004, CLIN MICROBIOL REV, V17, P72, DOI 10.1128/CMR.17.1.72-97.2004	42	18	18	AMER SOC MICROBIOLOGY	WASHINGTON	1752 N ST NW, WASHINGTON, DC 20036-2904 USA	0099-2240		APPL ENVIRON MICROB	Appl. Environ. Microbiol.	DEC	2008	74	23					7227	7234		10.1128/AEM.01576-08		8	Biotechnology & Applied Microbiology; Microbiology	Biotechnology & Applied Microbiology; Microbiology	374FZ	WOS:000261030400017	
J	Myrick, AJ; Park, KC; Hetling, JR; Baker, TC				Myrick, A. J.; Park, K-C; Hetling, J. R.; Baker, T. C.			Real-time odor discrimination using a bioelectronic sensor array based on the insect electroantennogram	BIOINSPIRATION & BIOMIMETICS			English	Article							BAYES-RISK-ESTIMATION; PATTERN-CLASSIFICATION; RECEPTOR-CELLS; SEX-PHEROMONES; MOTH; ATTRACTANT; OLFACTION; RESPONSES; ERROR; NOSE	Current trends in artificial nose research are strongly influenced by knowledge of biological olfactory systems. Insects have evolved over millions of years to detect and maneuver toward a food source or mate, or away from predators. The insect olfactory system is able to identify volatiles on a time scale that matches their ability to maneuver. Here, biological olfactory sense organs, insect antennae, have been exploited in a hybrid-device biosensor, demonstrating the ability to identify individual strands of odor in a plume passing over the sensor on a sub-second time scale. A portable system was designed to utilize the electrophysiological responses recorded from a sensor array composed of male or female antennae from four or eight different species of insects (a multi-channel electroantennogram, EAG). A computational analysis strategy that allows discrimination between odors in real time is described in detail. Following a training period, both semi-parametric and k-nearest neighbor (k-NN) classifiers with the ability to discard ambiguous responses are applied toward the classification of up to eight odors. EAG responses to individual strands in an odor plume are classified or discarded as ambiguous with a delay (sensor response to classification report) on the order of 1 s. The dependence of classification error rate on several parameters is described. Finally, the performance of the approach is compared to that of a minimal conditional risk classifier.	[Myrick, A. J.; Hetling, J. R.] Univ Illinois, Dept Bioengn, Chicago, IL 60607 USA; [Park, K-C; Baker, T. C.] Penn State Univ, Dept Entomol, Chem Ecol Lab, University Pk, PA 16802 USA	Myrick, AJ (reprint author), Univ Illinois, Dept Bioengn, SEO 232,MC 063,851 S Morgan St, Chicago, IL 60607 USA.				Defense Advanced Research Projects Agency (DARPA); Office of Naval Research (ONR); Defense Threat Reduction Agency (DTRA); Keystone Alliance grant from the State of Pennsylvania	This research was initially funded by the Controlled Biological Systems Program of Defense Advanced Research Projects Agency (DARPA). It was subsequently funded by the Office of Naval Research (ONR) and the Defense Threat Reduction Agency (DTRA), through grants to TCB at Iowa State University (DARPA) and at Penn State University (ONR Counter-IED Program; DTRA). This research was also supported by a Keystone Alliance grant from the State of Pennsylvania, through Penn State University. The authors would like to thank Bryan Banks, Penn State University, for rearing the test insects and for his after-hours assistance in setting up the wind tunnel for humidification. We would also like to thank Emily Kuhns, Penn State University, for insects used in this study.	ANDERSON PAV, 1985, BRAIN RES, V338, P273, DOI 10.1016/0006-8993(85)90157-X; Arshak K., 2003, Sensor Review, V23, DOI 10.1108/02602280310496854; Arshak K., 2004, Sensor Review, V24, DOI 10.1108/02602280410525977; BAKER TC, 1989, PHYSIOL ENTOMOL, V14, P1, DOI 10.1111/j.1365-3032.1989.tb00931.x; BAUM CW, 1992, IEEE T COMMUN, V40, P1231, DOI 10.1109/26.153368; BERGER RS, 1966, ANN ENTOMOL SOC AM, V59, P767; BROWN TA, 1979, IEEE T INFORM THEORY, V25, P617, DOI 10.1109/TIT.1979.1056092; CHEN Z, 1977, IEEE T SYST MAN CYB, V7, P651, DOI 10.1109/TSMC.1977.4309802; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Dickinson TA, 1998, TRENDS BIOTECHNOL, V16, P250, DOI 10.1016/S0167-7799(98)01185-8; Fix E., 1951, 4 USAF SCH AV MED, P261; FRALICK SC, 1971, IEEE T INFORM THEORY, V17, P440, DOI 10.1109/TIT.1971.1054663; French AS, 2007, CHEM SENSES, V32, P681, DOI 10.1093/chemse/bjm035; Galan RF, 2004, NEURAL COMPUT, V16, P999, DOI 10.1162/089976604773135078; GETCHELL TV, 1984, PROG NEUROBIOL, V23, P317, DOI 10.1016/0301-0082(84)90008-X; Gose E, 1996, PATTERN RECOGNITION; Grate JW, 2000, CHEM REV, V100, P2627, DOI 10.1021/cr980094j; Greiner B, 2004, J COMP NEUROL, V475, P202, DOI 10.1002/cne.20173; HETLING JR, 2003, P 1 INT IEEE EMBS C; HILL A, 1974, ENVIRON ENTOMOL, V3, P249; Justus KA, 2005, J NEUROPHYSIOL, V93, P2233, DOI 10.1152/jn.00888.2004; KARAGIANNOPOULO.MG, 2007, MED 07 MED C 27 29 J, P1; KARG G, 1995, J CHEM ECOL, V21, P1299, DOI 10.1007/BF02027563; KRISHNAN T, 2001, PATTERN RECOGN, P25, DOI 10.1142/9789812386533_0002; LILJEFORS T, 1987, J CHEM ECOL, V13, P2023, DOI 10.1007/BF01041729; LILJEFORS T, 1984, J CHEM ECOL, V10, P1661, DOI 10.1007/BF00987353; LILJEFORS T, 1985, J CHEM SOC P2, V12, P1957; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MARTIN EC, 2002, CELL, V102, P243; MILLER JR, 1978, J CHEM ECOL, V4, P178; Murray GM, 2002, IEEE INSTRU MEAS MAG, V5, P12, DOI 10.1109/MIM.2002.1048978; MYRICK AJ, 2005, P 2 INT IEEE EMBS C; Park KC, 2002, CHEM SENSES, V27, P343, DOI 10.1093/chemse/27.4.343; Pearce T.C., 2002, HDB MACHINE OLFACTIO; PERSAUD K, 1982, NATURE, V299, P352, DOI 10.1038/299352a0; POPE MM, 1984, J INSECT PHYSIOL, V30, P943; Principe JC, 1998, IEEE T AERO ELEC SYS, V34, P706, DOI 10.1109/7.705880; ROELOFS W, 1971, SCIENCE, V174, P297, DOI 10.1126/science.174.4006.297; ROELOFS WL, 1985, J CHEM ECOL, V11, P829, DOI 10.1007/BF01012071; SCHILD D, 1988, BIOPHYS J, V54, P1001; Shaffer RE, 1999, ANAL CHIM ACTA, V384, P305, DOI 10.1016/S0003-2670(98)00780-6; SHANMUGA.K, 1971, IEEE T SYST MAN CYB, VSMC1, P223, DOI 10.1109/TSMC.1971.4308289; Shields VDC, 2001, MICROSC RES TECHNIQ, V55, P307, DOI 10.1002/jemt.1180; Silverman B, 1986, DENSITY ESTIMATION; Solis JL, 2005, IEEE SENS J, V5, P1338, DOI 10.1109/JSEN.2005.857882; Tan SL, 2006, IEE P-SCI MEAS TECH, V153, P94, DOI 10.1049/ip-smt:20050035; Tegoni M, 2004, TRENDS BIOCHEM SCI, V29, P257, DOI 10.1016/j.tibs.2004.03.003; Theodoridis S., 1999, PATTERN RECOGNITION; Torre V, 1995, J NEUROSCI, V15, P7757; van der Pers JNC, 1998, ENTOMOL EXP APPL, V87, P209; Ziegler C, 1998, BIOSENS BIOELECTRON, V13, P539, DOI 10.1016/S0956-5663(97)00093-6	53	7	7	IOP PUBLISHING LTD	BRISTOL	DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND	1748-3182		BIOINSPIR BIOMIM	Bioinspir. Biomim.	DEC	2008	3	4							046006	10.1088/1748-3182/3/4/046006		19	Engineering, Multidisciplinary; Materials Science, Biomaterials; Robotics	Engineering; Materials Science; Robotics	377OG	WOS:000261259900006	
J	Chuang, LY; Yang, CS; Li, JC; Yang, CH				Chuang, Li-Yeh; Yang, Cheng-San; Li, Jung-Chike; Yang, Cheng-Hong			COMBAT GA-BASED GENE SELECTION FOR CLASSIFICATION OF MICROARRAY DATA	BIOMEDICAL ENGINEERING-APPLICATIONS BASIS COMMUNICATIONS			English	Article						Feature selection; microarray data; combat genetic algorithm; K-nearest neighbor; leave-one-out cross-validation	MULTIPLE CANCER TYPES; EXPRESSION DATA; BREAST-CANCER; DISCRIMINATION; OPTIMIZATION; PREDICTION; PATTERNS; TUMORS	Microarray data can provide valuable results for a variety of gene expression profile problems and contribute to advances in clinical medicine. The application of microarray data on cancer-type classification has recently gained in popularity. The properties of microarray data contain a large number of features ( genes) with high dimensions, and one in the multi-class category. These facts make testing and training of general classification methods difficult. Reducing the number of genes and achieving lower classification error rates are the main issues to be solved. The classification of microarray data samples can be regarded as a feature selection and classifier design problem. The goal of feature selection is to select those subsets of differentially expressed genes that are potentially relevant for distinguishing the sample classes. Classical genetic algorithms (GAs) may suffer from premature convergence and thus lead to poor experimental results. In this paper, combat genetic algorithm (CGA) is used to implement the feature selection, and a K-nearest neighbor with the leave-one-out cross-validation method serves as a classifier of the CGA fitness function for the classification problem. The proposed method was applied to 10 microarray data sets that were obtained from the literature. The experimental results show that the proposed method not only effectively reduced the number of gene expression levels but also achieved lower classification error rates.	[Li, Jung-Chike; Yang, Cheng-Hong] Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, Kaohsiung 80708, Taiwan; [Chuang, Li-Yeh] I Shou Univ, Dept Chem Engn, Kaohsiung 80041, Taiwan; [Yang, Cheng-San] Natl Cheng Kung Univ, Inst Biomed Engn, Tainan 70101, Taiwan	Yang, CH (reprint author), Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, Kaohsiung 80708, Taiwan.	chyang@cc.kuas.edu.tw	Chuang, Li-Yeh/E-5005-2011		National Science Council in Taiwan [NSC96-2622-E-151-019CC3, NSC96-2622-E214-004-CC3, NSC95-2221-E-151004-MY3, NSC95-2221-E-214-087, NSC95-2622-E214-004]	This work is partly supported by the National Science Council in Taiwan under grant NSC96-2622-E-151-019CC3, NSC96-2622-E214-004-CC3, NSC95-2221-E-151004-MY3, NSC95-2221-E-214-087, and NSC95-2622-E214-004.	Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Berrar D, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-73; Chang JC, 2005, BREAST CANCER RES, V7, P100, DOI 10.1186/bcr1018; CONVER WJ, 1986, PRACTICAL NONPARAMET; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1977, IEEE T SYST MAN CYB, V7, P657, DOI 10.1109/TSMC.1977.4309803; Diaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Eksin I., 2001, IEE Proceedings-Software, V148, DOI 10.1049/ip-sen:20010503; Erol OK, 2006, ADV ENG SOFTW, V37, P106, DOI 10.1016/j.advengsoft.2005.04.005; FIX E, 1989, INT STAT REV, V57, P238, DOI 10.2307/1403797; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Holland J. H., 1992, ADAPTATION NATURAL A; Jeffrey Stefanie S, 2005, J Natl Compr Canc Netw, V3, P291; Jirapech-Umpai T, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-148; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Lee Y, 2003, BIOINFORMATICS, V19, P1132, DOI 10.1093/bioinformatics/btg102; Liu X, 2005, BMC BIOINFORM, V6, P76; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; Ramaswamy S, 2003, NAT GENET, V33, P49, DOI 10.1038/ng1060; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Tahir MA, 2007, PATTERN RECOGN LETT, V28, P438, DOI 10.1016/j.patrec.2006.08.016; Tan SB, 2006, EXPERT SYST APPL, V30, P290, DOI 10.1016/j.eswa.2005.07.019; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Wang XY, 2007, PATTERN RECOGN LETT, V28, P459, DOI 10.1016/j.patrec.2006.09.003	28	1	1	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	1016-2372		BIOMED ENG-APP BAS C	Biomed. Eng.-Appl. Basis Commun.	DEC	2008	20	6					345	352				8	Computer Science, Interdisciplinary Applications; Engineering, Biomedical	Computer Science; Engineering	390BJ	WOS:000262139000002	
J	Kagie, M; van Wezel, M; Groenen, PJF				Kagie, Martijn; van Wezel, Michiel; Groenen, Patrick J. F.			A graphical shopping interface based on product attributes	DECISION SUPPORT SYSTEMS			English	Article						Recommender systems; Multidimensional scaling; Similarity; Electronic commerce; Case-based reasoning	RECOMMENDER SYSTEMS; MAP	Most recommender systems present recommended products in lists to the user. By doing so, much information is lost about the mutual similarity between recommended products. We propose to represent the mutual similarities of the recommended products in a two dimensional map, where similar products are located close to each other and dissimilar products far apart. As a dissimilarity measure we use an adaptation of Gower's similarity coefficient based on the attributes of a product. Two recommender systems are developed that use this approach. The first, the graphical recommender system, uses a description given by the user in terms of product attributes of an ideal product. The second system, the graphical shopping interface, allows the user to navigate towards the product she wants. We show a prototype application of both systems to MP3-players. (c) 2008 Elsevier B.V. All rights reserved.	[Kagie, Martijn; van Wezel, Michiel; Groenen, Patrick J. F.] Erasmus Univ, Inst Econometr, NL-3000 DR Rotterdam, Netherlands	Kagie, M (reprint author), Erasmus Univ, Inst Econometr, NL-3000 DR Rotterdam, Netherlands.	kagie@few.eur.nl; mvanwezel@few.eur.nl; groenen@few.eur.nl	Groenen, Patrick/D-3667-2009	Groenen, Patrick/0000-0001-6683-8971			Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99; Arslan B, 2002, MANAG INFORMAT SYST, V6, P999; Ayanso A, 2007, DECIS SUPPORT SYST, V44, P326, DOI 10.1016/j.dss.2007.04.005; Bettman JR, 1998, J CONSUM RES, V25, P187, DOI 10.1086/209535; Borg I, 2005, SPRINGER SERIES STAT; BURKE R, 2000, ENCY LIB INFORM SYST, V69, P32; Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564; Chaudhuri S., 1999, P 25 INT C VER LARG, P397; Chung WY, 2006, DECIS SUPPORT SYST, V42, P1697, DOI 10.1016/j.dss.2006.02.015; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DELEEUW J, 1988, J CLASSIF, V5, P163; DONALDSON J, 2007, P 23 INT C DAT ENG W, P811; GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867; GOWER JC, 1971, BIOMETRICS, V27, P857, DOI 10.2307/2528823; KAGIE M, 2008, P IUI WORKSH REC COL; Kagie M, 2007, LECT NOTES COMPUT SC, V4655, P89; KELLER I, 2000, P CHI 2000 WORKSH 1; Kohonen T., 2001, SPRINGER SERIES INFO; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565; Lorenzi F, 2005, LECT NOTES ARTIF INT, V3169, P89; MCGINTY L, 2002, LECT NOTES COMPUTER, V2416, P731; Ong TH, 2005, DECIS SUPPORT SYST, V39, P583, DOI 10.1016/j.dss.2004.03.008; PECENOVIC Z, 2000, LECT NOTES COMPUTER, V1929, P173; PRASAD B, 2003, J ELECT COMMERCE RES, V4, P65; Pu P., 2004, P ACM C EL COMM EC 0, P208, DOI 10.1145/988772.988804; RICCI F, 2005, INFORM COMMUNICATION, P172, DOI 10.1007/3-211-27283-6_16; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; Schafer J. B., 2001, Data Mining and Knowledge Discovery, V5, DOI 10.1023/A:1009804230409; Schneiderman B., 1992, ACM Transactions on Graphics, V11; Schwartz B, 2004, PARADOX CHOICE WHY M; Shimazu H, 2002, ARTIF INTELL REV, V18, P223, DOI 10.1023/A:1020757023711; STAPPERS PJ, 2000, P IEA 2000 HFES 2000; STAPPERS PJ, 1999, HUMAN FACTORS COMPUT, P184; TORGERSON WS, 1952, PSYCHOMETRIKA, V17, P401; Turetken O, 2004, DECIS SUPPORT SYST, V37, P415, DOI 10.1016/S0167-9236(03)00047-2; VANGULIK R, 2004, P 5 INT C MUS INF RE; Yang CC, 2003, DECIS SUPPORT SYST, V35, P89, DOI 10.1016/S0167-9236(02)00101-X	37	5	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9236		DECIS SUPPORT SYST	Decis. Support Syst.	DEC	2008	46	1					265	276		10.1016/j.dss.2008.06.011		12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science	Computer Science; Operations Research & Management Science	412EH	WOS:000263706000021	
J	Alippi, C; Roveri, M				Alippi, Cesare; Roveri, Manuel			Just-in-Time Adaptive Classifiers-Part II: Designing the Classifier	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						Intelligent systems; learning systems; neural networks; pattern classification	NEAREST-NEIGHBOR RULE; PATTERN-CLASSIFICATION; SYSTEMS; SURVEILLANCE; NETWORKS; SURFACES	Aging effects, environmental changes, thermal drifts, and soft and hard faults affect physical systems by changing their nature and behavior over time. To cope with a process evolution adaptive solutions must be envisaged to track its dynamics; in this direction, adaptive classifiers are generally designed by assuming the stationary hypothesis for the process generating the data with very few results addressing nonstationary environments. This paper proposes a methodology based on k-nearest neighbor (NN) classifiers for designing adaptive classification systems able to react to changing conditions just-in-time (JIT), i.e., exactly when it is needed. k-NN classifiers have been selected for their computational-free training phase, the possibility to easily estimate the model complexity k and keep under control the computational complexity of the classifier through suitable data reduction mechanisms. A JIT classifier requires a temporal detection of a (possible) process deviation (aspect tackled in a companion paper) followed by an adaptive management of the knowledge base (KB) of the classifier to cope with the process change. The novelty of the proposed approach resides in the general framework supporting the real-time update of the KB of the classification system in response to novel information coming from the process both in stationary conditions (accuracy improvement) and in nonstationary ones (process tracking) and in providing a suitable estimate of k. It is shown that the classification system grants consistency once the change targets the process generating the data in a new stationary state, as it is the case in many real applications.	[Alippi, Cesare; Roveri, Manuel] Politecn Milan, Dipartimento Elettr & Informaz, I-20133 Milan, Italy	Alippi, C (reprint author), Politecn Milan, Dipartimento Elettr & Informaz, I-20133 Milan, Italy.	alippi@elet.polimi.it; roveri@elet.polimi.it					Alippi C, 2006, IEEE T SYST MAN CY C, V36, P649, DOI 10.1109/TSMCC.2005.855508; Alippi C, 2008, IEEE T NEURAL NETWOR, V19, P1145, DOI 10.1109/TNN.2008.2000082; Azimi-Sadjadi MR, 2002, IEEE T NEURAL NETWOR, V13, P1099, DOI 10.1109/TNN.2002.1031942; Blake C, UCI MACHINE LEARNING; Bollani M, 2001, APPL SURF SCI, V175, P379, DOI 10.1016/S0169-4332(01)00129-5; Boult TE, 2001, P IEEE, V89, P1382, DOI 10.1109/5.959337; CARPENTER GA, 1995, IEEE T NEURAL NETWOR, V6, P1330, DOI 10.1109/72.471374; Chernoff H., 1972, SEQUENTIAL ANAL OPTI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devroye L, 1996, PROBABILISTIC THEORY; DEVROYE LP, 1979, IEEE T INFORM THEORY, V25, P601, DOI 10.1109/TIT.1979.1056087; DOHERTY LE, 1998, P INT C KNOWL BAS IN, V3, P303; Fukunaga K, 1972, INTRO STAT PATTERN R; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HAUTAMAKI V, 2004, P 17 C PATT REC CAMB, V3, P430, DOI 52223691,12,1; Iwayama N., 2002, Proceedings Eighth International Workshop on Frontiers in Handwriting Recognition, DOI 10.1109/IWFHR.2002.1030904; Jackson Q, 2001, IEEE T GEOSCI REMOTE, V39, P2664, DOI 10.1109/36.975001; KASABOV N, 2002, P INT C NEUR INF PRO, V2, P590, DOI 10.1109/ICONIP.2002.1198126; KEANS M, 1999, NEURAL COMPUT, V11, P1427; Kohlmorgen J, 2000, BIOL CYBERN, V83, P73, DOI 10.1007/s004220000144; Kuh A, 1997, IEEE T SIGNAL PROCES, V45, P640, DOI 10.1109/78.558480; KUH A, 1999, P IEEE INT JOINT C N, V4, P2406; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; Land W. H.  Jr., 1998, Proceedings. IEEE International Joint Symposia on Intelligence and Systems (Cat. No.98EX174), DOI 10.1109/IJSIS.1998.685413; LI P, 1997, P IEEE NAT RAD C SYR, P372; LINGARKAR R, 1990, IEEE T SYST MAN CYB, V20, P606, DOI 10.1109/21.57273; Narducci D, 2003, APPL SURF SCI, V212, P491, DOI 10.1016/S0169-4332(03)00047-3; NIKIFOROV IV, 1995, IEEE T INFORM THEORY, V41, P171, DOI 10.1109/18.370109; Nozaki K, 1996, IEEE T FUZZY SYST, V4, P238, DOI 10.1109/91.531768; POULSEN RS, 1981, P INT S INF THEOR SA, P1; Rizki MM, 2002, IEEE T EVOLUT COMPUT, V6, P594, DOI 10.1109/TEVC.2002.806167; Robertson P, 1999, IEEE INTELL SYST APP, V14, P30, DOI 10.1109/5254.769882; RUSSEL EL, 2001, FAULT DETECTION DIAG; Rutkowski L, 2004, IEEE T NEURAL NETWOR, V15, P811, DOI 10.1109/TNN.2004.828757; SHAHHOSSEINI H, 2000, P IEEE INT C EL CIRC, V1, P495; Siddique A., 2003, P IEEE INT S DIAGN E, P29; STONE C, 1977, ANN STAT, V8, P1348; TAN SC, 2000, P TENCON SEPT, V1, P13; VIRILI F, 2000, P INT JOINT C NEUR N, V5, P129, DOI 308159105,12,1; Wang JQ, 2004, IEEE T NEURAL NETWOR, V15, P159, DOI 10.1109/TNN.2003.820622; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; ZONGHAI C, 2007, J SYST ENG ELECTRON, V18, P566, DOI 10.1016/S1004-4132(07)60130-3	44	15	16	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	DEC	2008	19	12					2053	2064		10.1109/TNN.2008.2003998		12	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	381OD	WOS:000261544900006	
J	Gil-Pita, R; Yao, X				Gil-Pita, Roberto; Yao, Xin			EVOLVING EDITED k-NEAREST NEIGHBOR CLASSIFIERS	International Journal of Neural Systems			English	Article	8th International Conference on Intelligent Data Engineering and Automated Learning	DEC 16-19, 2007	Birmingham, ENGLAND			Nearest neighbour classifiers; evolutionary algorithms; machine learning; genetic algorithms; classification	ALGORITHM; DESIGN; RULE	The k-nearest neighbor method is a classifier based on the evaluation of the distances to each pattern in the training set. The edited version of this method consists of the application of this classifier with a subset of the complete training set in which some of the training patterns are excluded, in order to reduce the classification error rate. In recent works, genetic algorithms have been successfully applied to determine which patterns must be included in the edited subset. In this paper we propose a novel implementation of a genetic algorithm for designing edited k-nearest neighbor classifiers. It includes the definition of a novel mean square error based fitness function, a novel clustered crossover technique, and the proposal of a fast smart mutation scheme. In order to evaluate the performance of the proposed method, results using the breast cancer database, the diabetes database and the letter recognition database from the UCI machine learning benchmark repository have been included. Both error rate and computational cost have been considered in the analysis. Obtained results show the improvement achieved by the proposed editing method.	[Gil-Pita, Roberto] Univ Alcala de Henares, Signal Theory & Commun Dept, Madrid 28805, Spain; [Yao, Xin] Univ Birmingham, Sch Comp Sci, CERCIA, Birmingham B15 2TT, W Midlands, England; [Yao, Xin] Univ Sci & Technol China, Dept Comp Sci & Technol, NICAL, Hefei 230027, Anhui, Peoples R China	Gil-Pita, R (reprint author), Univ Alcala de Henares, Signal Theory & Commun Dept, Madrid 28805, Spain.	roberto.gil@uah.es; X.Yao@cs.bham.ac.uk					Bishop C. M., 1995, NEURAL NETWORKS PATT; Cerveron V, 2001, IEEE T SYST MAN CY B, V31, P408, DOI 10.1109/3477.931531; Chen JH, 2004, LECT NOTES ARTIF INT, V3157, P262, DOI 10.1109/ISIMP.2004.1434050; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hartigan J. A., 1979, Applied Statistics, V28, DOI 10.2307/2346830; Haupt R.L., 2004, PRACTICAL GENETIC AL; He H., 2000, J ADV COMPUTATIONAL, V4, P130; Ho SY, 2002, PATTERN RECOGN LETT, V23, P1495, DOI 10.1016/S0167-8655(02)00109-5; Islam M, 2003, IEEE T NEURAL NETWOR, V14, P820, DOI 10.1109/TNN.2003.813832; Kuncheva LI, 1997, PATTERN RECOGN, V30, P1041, DOI 10.1016/S0031-3203(96)00134-3; Mollineda RA, 2005, LECT NOTES COMPUT SC, V3523, P27; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Yao X, 1997, IEEE T NEURAL NETWOR, V8, P694, DOI 10.1109/72.572107	14	9	9	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0129-0657		INT J NEURAL SYST	Int. J. Neural Syst.	DEC	2008	18	6					459	467				9	Computer Science, Artificial Intelligence	Computer Science	396NR	WOS:000262598900002	
J	Furao, S; Hasegawa, O				Furao, Shen; Hasegawa, Osamu			A fast nearest neighbor classifier based on self-organizing incremental neural network	NEURAL NETWORKS			English	Article						Self-organizing incremental neural network; Nearest neighbor; Fast; Prototype-based classifier		A fast prototype-based nearest neighbor classifier is introduced. The proposed Adjusted SOINN Classifier (ASC) is based on SOINN (self-organizing incremental neural network), it automatically learns the number of prototypes needed to determine the decision boundary, and learns new information without destroying old learned information. It is robust to noisy training data, and it realizes very fast classification. In the experiment, we use some artificial datasets and real-world datasets to illustrate ASC. We also compare ASC with other prototype-based classifiers with regard to its classification error, compression ratio, and speed up ratio. The results show that ASC has the best performance and it is a very efficient classifier. (C) 2008 Elsevier Ltd. All rights reserved.	[Furao, Shen] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Peoples R China; [Hasegawa, Osamu] Tokyo Inst Technol, Imaging Sci & Engn Lab, Tokyo, Japan	Furao, S (reprint author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Peoples R China.	frshen@nju.edu.cn			NSF [60573157, 60723003, 60775046]	This work was supported in part by the China NSF grant (#60573157, #60723003, and #60775046).	Bezdek JC, 2001, INT J INTELL SYST, V16, P1445, DOI 10.1002/int.1068; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Hastie T, 2001, ELEMENTS STAT LEARNI; Kohonen T, 1990, P INT JOINT C NEUR N, P545; MERZ CJ, 1996, UCI RESPOSITORY MACH; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P734, DOI 10.1109/TPAMI.2002.1008381; PASSERINI A, 2002, P 15 EUR C ART INT; SHEN F, 2005, IEEE COMP SOC INT C; Shen FR, 2006, NEURAL NETWORKS, V19, P90, DOI 10.1016/j.neunet.2005.04.006; Shen F. R., 2007, NEURAL NETWORKS, V20, P893; Veenman CJ, 2005, IEEE T PATTERN ANAL, V27, P1417, DOI 10.1109/TPAMI.2005.187; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	15	2	3	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080		NEURAL NETWORKS	Neural Netw.	DEC	2008	21	10					1537	1547		10.1016/j.neunet.2008.07.001		11	Computer Science, Artificial Intelligence	Computer Science	387BG	WOS:000261926100015	
J	Boutsinas, B; Papastergiou, T				Boutsinas, B.; Papastergiou, T.			On clustering tree structured data with categorical nature	PATTERN RECOGNITION			English	Article						clustering; (dis)similarity measures; data mining	CLASSIFICATION; ALGORITHM	Clustering consists in partitioning a set of objects into disjoint and homogeneous clusters. For many years, clustering methods have been applied in a wide variety of disciplines and they also have been utilized in many scientific areas. Traditionally, clustering methods deal with numerical data, i.e. objects represented by a conjunction of numerical attribute Values. However, nowadays commercial or scientific databases Usually contain categorical data, i.e. objects represented by categorical attributes. In this paper we present a dissimilarity measure which is capable to deal with tree structured categorical data. Thus, it can be used for extending the various versions of the very popular k-means clustering algorithm to deal with Such data. We discuss how such an extension can be achieved. Moreover, we empirically prove that the proposed dissimilarity measure is accurate, compared to other well-known (dis)similarity measures for categorical data. (C) 2008 Elsevier Ltd. All rights reserved.	[Boutsinas, B.] Univ Patras, Dept Business Adm, GR-26500 Rion, Greece; [Boutsinas, B.; Papastergiou, T.] Univ Patras, Artificial Intelligence Res Ctr, GR-26500 Rion, Greece	Boutsinas, B (reprint author), Univ Patras, Dept Business Adm, GR-26500 Rion, Greece.	vutsinas@upatras.gr					Aldenderfer M.S., 1984, QUANTITATIVE APPL SO; Anderberg M. R., 1973, CLUSTER ANAL APPL; BERGE C, 1985, N HOLLAND MATH LIB, V6, P72; BLANCHARD E, 2005, OP INT WORKSH ENT MO; BOCK HH, 2000, STUDIES CLASSIFICATI, V15; Boutsinas B., 2006, Pattern Recognition and Image Analysis, V16, DOI 10.1134/S1054661806020015; BOUTSINAS B, 2008, INT J INF TECHNOL DE; Cheng V, 2004, PATTERN RECOGN, V37, P1471, DOI 10.1016/j.patcog.2003.12.015; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cox T.F., 1994, MULTIDIMENSIONAL SCA; DAI BT, COLUMN HETEROGENEITY; DUBES R, 1980, ADV COMPUT, V19, P113, DOI 10.1016/S0065-2458(08)60034-0; Dunn-Rankin P., 1983, SCALING METHODS; ESPOSITO F, 1992, IEEE T PATTERN ANAL, V14, P390, DOI 10.1109/34.120333; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1023/A:1022852608280; Greenacre M.J., 1984, THEORY APPL CORRESPO; Hirst G., 1998, WORDNET ELECT LEXICA, P305; Huang ZX, 1998, DATA MIN KNOWL DISC, V2, P283, DOI 10.1023/A:1009769707641; Jain A., 1988, ALGORITHMS CLUSTERIN; Jiang J.J, 1997, P INT C RES COMP LIN; Johnson S. C., 1967, PSYCHOMETRIKA, p[2, 241]; JOHNSON T, 2003, SIGMOD; Kalfoglou Y, 2003, KNOWL ENG REV, V18, P1, DOI 10.1017/S0269888903000651; Kaufman L., 1990, WILEY SERIES PROBABI; KODRATOFF Y, 1988, INTRO MACHINE LEARNI; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P115, DOI 10.1007/BF02289694; Leacock C., 1998, WORDNET ELECT LEXICA, P265; Lenat D.B., 1995, COMMUN ACM, V38; Lin D., 1998, P 15 INT C MACH LEAR, P296; MacQueen JB, 1967, P 5 BERK S MATH STAT, P281; Malerba D., 2001, P JOINT C NEW TECHN, P473; MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037//0033-295X.85.3.207; Michalski R. S., 1983, MACHINE LEARNING ART, V1; SOKAL ROBERT R., 1958, UNIV KANSAS SCI BULL, V38, P1409; Niles I., 2001, 2 INT C FORM ONT INF; Quillian M.R., 1968, SEMANTIC INFORM PROC; RADA R, 1989, IEEE T SYST MAN CYB, V19, P17, DOI 10.1109/21.24528; Resnik P., 1995, P 14 INT JOINT C ART, V1, P448; RUSPINI EH, 1969, INFORM CONTROL, V15, P22, DOI 10.1016/S0019-9958(69)90591-9; SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81; Sussna M., 1993, P 2 INT C INF KNOWL, P67, DOI 10.1145/170088.170106; Vrahatis MN, 2002, J COMPLEXITY, V18, P375, DOI 10.1006/jcom.2001.0633; Wache H, 2001, IJCAI WORKSH ONT INF; Warin M., 2005; Wu Z, 1994, P 32 ANN M ASS COMP, P133, DOI 10.3115/981732.981751; ZHANG B, 2003, P INT C COMP VIS PAT	46	7	7	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	DEC	2008	41	12					3613	3623		10.1016/j.patcog.2008.05.023		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	353EC	WOS:000259547900009	
J	Villa, JL; Boque, R; Ferre, J				Villa, Joe Luis; Boque, Ricard; Ferre, Joan			Calculation of the probability of correct classification in probabilistic bagged k-Nearest Neighbours	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS			English	Article						Classification; Nearest neighbours; Bootstrap; Probability of classification; Reliability	PATTERN-RECOGNITION; BOOTSTRAP METHODS; PREDICTION ERROR; CLASSIFIERS; SPECTRA; DESIGN; TREE	This paper presents a new method for computing the probability of correct classification for the k-Nearest Neighbours (kNN) method. The method uses bootstrap to provide the posterior probability which a new object is classified with. This is a measure of the reliability of the classification: it increases as the test object is closer to the training objects of a given class and is more sensitive to the position of the test object in the calibration space than the classical measure of posterior probability in kNN. This reliability of the classification is also used to derive a new rule for classification. (C) 2008 Elsevier B.V. All rights reserved.	[Villa, Joe Luis; Boque, Ricard; Ferre, Joan] Univ Rovira & Virgili, Dept Analyt Chem & Organ Chem, Tarragona 43007, Catalonia, Spain	Boque, R (reprint author), Univ Rovira & Virgili, Dept Analyt Chem & Organ Chem, C Marcel Li Domingo S-N, Tarragona 43007, Catalonia, Spain.	ricard.boque@urv.cat			Department of Universities, Research and information Society of Catalonia - Spain; Spanish Ministry of Education and Science [CTQ2007-66918]	The authors thank support of Department of Universities, Research and information Society of Catalonia - Spain, for providing Joe Luis Villa's doctoral fellowship and project CTQ2007-66918 of the Spanish Ministry of Education and Science.	Alpaydin E, 1997, ARTIF INTELL REV, V11, P115, DOI 10.1023/A:1006563312922; Alsberg BK, 1997, ANAL CHIM ACTA, V348, P389, DOI 10.1016/S0003-2670(97)00064-0; Asuncion A., 2007, UCI MACHINE LEARNING; Beckonert O, 2003, ANAL CHIM ACTA, V490, P3, DOI 10.1016/S0003-2670(03)00060-6; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Caprile B, 2004, LECT NOTES COMPUT SC, V3077, P72; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2001, PATTERN CLASSIFICATI, P654, DOI DOI 10.1007/S00357-007-0015-9; Efron B., 1993, INTRO BOOTSTRAP; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Fisher RA, 1936, ANN EUGENIC, V7, P179; FORINA M, 1986, VITIS, V25, P189; FORINA M, 2008, PARVUS OFFICIAL WEB; Gurov S. I., 2004, Computational Mathematics and Modeling, V15, DOI 10.1023/B:COMI.0000047346.87442.ef; Hall P, 2005, J ROY STAT SOC B, V67, P363, DOI 10.1111/j.1467-9868.2005.00506.x; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814; HINKLEY DV, 1988, J ROY STAT SOC B MET, V50, P321; Holmes CC, 2002, J ROY STAT SOC B, V64, P295, DOI 10.1111/1467-9868.00338; KENNARD RW, 1969, TECHNOMETRICS, V11, P137, DOI 10.2307/1266770; Lei S, 2003, IEEE T SOFTWARE ENG, V29, P996; Lukasiak BM, 2006, ANALYST, V131, P73, DOI 10.1039/b510561g; Molinaro AM, 2005, BIOINFORMATICS, V21, P3301, DOI 10.1093/bioinformatics/bti499; PARTHASARATHY G, 1990, IEEE T SYST MAN CYB, V20, P715, DOI 10.1109/21.57285; Pirogov AV, 1998, ANAL CHIM ACTA, V369, P47, DOI 10.1016/S0003-2670(98)00210-4; Ros F, 1997, J CHEMOMETR, V11, P483, DOI 10.1002/(SICI)1099-128X(199711/12)11:6<483::AID-CEM490>3.0.CO;2-8; Steele BM, 2000, STAT COMPUT, V10, P349, DOI 10.1023/A:1008933626919; TODESCHINI R, 1990, CHEMOMETR INTELL LAB, V9, P201, DOI 10.1016/0169-7439(90)80098-Q; TODESCHINI R, 1992, CHEMOMETR INTELL LAB, V16, P25, DOI 10.1016/0169-7439(92)80075-F; Todeschini R, 2007, CHEMOMETR INTELL LAB, V87, P3, DOI 10.1016/j.chemolab.2005.11.001; Viswanath P, 2005, PATTERN RECOGN, V38, P1187, DOI 10.1016/j.patcog.2004.10.007; Webb A., 2002, STAT PATTERN RECOGNI; Wehrens R, 2000, CHEMOMETR INTELL LAB, V54, P35, DOI 10.1016/S0169-7439(00)00102-7; Wu W, 1997, ANAL CHIM ACTA, V349, P253, DOI 10.1016/S0003-2670(97)00285-7	33	2	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-7439		CHEMOMETR INTELL LAB	Chemometrics Intell. Lab. Syst.	NOV 15	2008	94	1					51	59		10.1016/j.chemolab.2008.06.007		9	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	408OD	WOS:000263443400006	
J	Oentaryo, RJ; Pasquier, M; Quek, C				Oentaryo, R. J.; Pasquier, M.; Quek, C.			GenSoFNN-Yager: A novel brain-inspired generic self-organizing neuro-fuzzy system realizing Yager inference	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						decision support system; declarative knowledge; hippocampus; rule induction; sequential learning; neuro-fuzzy system; Yager inference scheme	NETWORK; IDENTIFICATION; MEMORY; LOGIC	Pattern recognition is increasingly becoming a key component of decision support systems (DSSs) in many application areas, especially when automatically extracting semantic rules from data is a chief concern. Accordingly, this paper presents a novel evolving neuro-fuzzy DSS, the generic self-organizing fuzzy neural network realizing Yager inference (GenSoFNN-Yager), that emulates the sequential learning paradigm of the hippocampus in the brain to synthesize from low-level numerical data to high-level declarative fuzzy rules. The proposed system exhibits simple and conceptually firm computational steps that correspond closely to a plausible human logical reasoning and decision-making. Experimental results on sample benchmark problems and realistic medical diagnosis applications show the potential of the proposed system as a competent DSS. (C) 2007 Elsevier Ltd. All rights reserved.	[Oentaryo, R. J.; Pasquier, M.; Quek, C.] Nanyang Technol Univ, Sch Comp Engn, Ctr Computat Intelligence, Singapore 639798, Singapore	Quek, C (reprint author), Nanyang Technol Univ, Sch Comp Engn, Ctr Computat Intelligence, Nanyang Ave, Singapore 639798, Singapore.	ashcquek@ntu.edu.sg					ALON U, 1999, P NATL ACAD SCI USA, V96, P5745; Anderson J., 1983, ARCHITECTURE COGNITI; Asuncion A., 2007, UCI MACHINE LEARNING; Bishop C. M., 1995, NEURAL NETWORKS PATT; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Damasio A. R., 1996, NEUROBIOLOGY DECISIO; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dubois D, 1996, FUZZY SET SYST, V84, P169, DOI 10.1016/0165-0114(96)00066-8; Eichenbaum H, 2002, COGNITIVE NEUROSCIEN; Fisher RA, 1936, ANN EUGENIC, V7, P179; Gluck MA, 2003, TRENDS COGN SCI, V7, P269, DOI 10.1016/S1364-6613(03)00105-0; KELLER JM, 1992, FUZZY SET SYST, V45, P1, DOI 10.1016/0165-0114(92)90086-J; Kubat M, 1998, MACH LEARN, V30, P195, DOI 10.1023/A:1007452223027; Lin CJ, 1997, IEEE T FUZZY SYST, V5, P477; Lin CT, 1996, NEURAL FUZZY SYSTEMS; Mamdani EH, 1999, INT J HUM-COMPUT ST, V51, P135, DOI 10.1006/ijhc.1973.0303; MANTARAS R, 1990, APPROXIMATE REASONIN; Michalski R. S., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; OENTARYO RJ, 2006, P IEEE INT JOINT C N, P1684; OENTARYO RJ, 2005, C2ITR00205 NAN TECHN; OENTARYO RJ, 2004, P 8 IEEE INT C CONTR, V2, P1005; Pal SK, 1998, IEEE T SYST MAN CY B, V28, P816, DOI 10.1109/3477.735391; PASQUIER M, INT J VEHIC IN PRESS; Pasquier M, 2001, NEURAL NETWORKS, V14, P1099, DOI 10.1016/S0893-6080(01)00048-X; Quek C, 2005, EXPERT SYST APPL, V29, P229, DOI 10.1016/j.eswa.2005.03.001; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; SCOVILLE WB, 1957, J NEUROL NEUROSUR PS, V20, P11, DOI 10.1136/jnnp.20.1.11; Shevade SK, 2003, BIOINFORMATICS, V19, P2246, DOI 10.1093/bioinformatics/btg308; Sim J, 2006, IEEE T NEURAL NETWOR, V17, P1394, DOI 10.1109/TNN.2006.880362; Sprague RH, 1993, DECISION SUPPORT SYS; Squire L, 1984, NEUROBIOLOGY LEARNIN; SUGENO M, 1988, FUZZY SET SYST, V28, P15, DOI 10.1016/0165-0114(88)90113-3; TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116; Tomporowski P. D., 2003, PSYCHOL SKILL LIFE S; Tulving Endel, 1972, ORG MEMORY; Tung WL, 2005, ARTIF INTELL MED, V33, P61, DOI 10.1016/j.artmed.2004.03.009; Tung WL, 2002, IEEE T NEURAL NETWOR, V13, P1075, DOI 10.1109/TNN.2002.1031940; TURKSEN IB, 1990, FUZZY SET SYST, V34, P323, DOI 10.1016/0165-0114(90)90218-U; Zadeh L.A., 1975, FUZZY SETS THEIR APP, P1; Zhou RW, 1996, NEURAL NETWORKS, V9, P1569, DOI 10.1016/S0893-6080(96)00027-5	42	14	14	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	NOV	2008	35	4					1825	1840		10.1016/j.eswa.2007.08.108		16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	351OB	WOS:000259432600034	
J	Kang, P; Cho, S				Kang, Pilsung; Cho, Sungzoon			Locally linear reconstruction for instance-based learning	PATTERN RECOGNITION			English	Article						instance-based learning; memory-based reasoning; k-nearest neighbor; weight allocation; local reconstruction	NEAREST-NEIGHBOR CLASSIFICATION; PATTERN-CLASSIFICATION; FACE RECOGNITION; METRICS	Instance-based learning (IBL), so called memory-based reasoning (MBR), is a commonly used nonparametric learning algorithm. k-nearest neighbor (k-NN) learning is the most popular realization of IBL. Due to its usability and adaptability, k-NN has been Successfully applied to a wide range of applications. However, in practice, one has to set important model parameters only empirically: the number of neighbors (k) and weights to those neighbors. In this paper, we propose structured ways to set these parameters, based on locally linear reconstruction (LLR). We then employed sequential minimal optimization (SMO) for solving quadratic programming step involved in LLR for classification to reduce the computational complexity. Experimental results from 11 classification and eight regression tasks were Promising enough to merit further investigation: not only did LLR Outperform the conventional weight allocation methods without much additional computational cost, but also LLR Was found to be robust to the change of k. (C) 2008 Elsevier Ltd. All rights reserved.	[Kang, Pilsung; Cho, Sungzoon] Seoul Natl Univ, Dept Ind Engn, Seoul 151744, South Korea	Cho, S (reprint author), Seoul Natl Univ, Dept Ind Engn, Sari 56-1, Seoul 151744, South Korea.	xfeel80@snu.ac.kr; zoon@snu.ac.kr			Korea Science and Engineering Foundation (KOSEF); Korea government [R01-2005-000-103900-0]; Engineering Research Institute of SNU	This work was supported by the Korea Science and Engineering Foundation (KOSEF) grant funded by the Korea government (R01-2005-000-103900-0), the Brain Korea 21 program in 2007, and partially supported by Engineering Research Institute of SNU.	AHA DW, 1992, PROCEEDINGS OF THE FOURTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P534; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Burr Ridge I, 1997, MACHINE LEARNING; COPPERSMITH D, 1990, J SYMB COMPUT, V9, P251, DOI 10.1016/S0747-7171(08)80013-2; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DING Y, 2006, P 17 AUSTR DAT C HOB, P99; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Duda R. O., 2001, PATTERN CLASSIFICATI; FAN JQ, 1994, ANN STAT, V22, P867, DOI 10.1214/aos/1176325499; FEDOROV VV, 1993, NONPARAMETRIC STAT, V2, P355; GOWDA KC, 1991, PATTERN RECOGN LETT, V12, P259; GOWDA KC, 1991, PATTERN RECOGN, V24, P567; Han E., 2001, P 5 PAC AS C KNOWL D, P53; Hardle W, 1990, APPL NONPARAMETRIC R; Hastie T, 2001, ELEMENTS STAT LEARNI; Hattori K, 1999, PATTERN RECOGN, V32, P425, DOI 10.1016/S0031-3203(98)00097-1; Hechenbichler K., 2004, 399 LUDW MAX U MUN; HOWE N, 1997, P 2 INT C CAS BAS RE, P455; ICHINO M, 1994, IEEE T SYST MAN CYB, V24, P698, DOI 10.1109/21.286391; Jiang SY, 2006, PATTERN RECOGN LETT, V27, P802, DOI 10.1016/j.patrec.2005.11.007; Jing XY, 2006, PATTERN RECOGN LETT, V27, P1465, DOI 10.1016/j.patrec.2006.02.050; Konstan J., 2000, P 2 ACM C EL COMM, P158, DOI DOI 10.1145/352871.352887; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MOHAN BK, 2006, P ACM C EL COMM, P250, DOI 10.1145/1134707.1134735; OMAHONY M., 2004, ACM T INTERNET TECHN, V4, P344, DOI 10.1145/1031114.1031116; OSUNA E, 1997, P IEEE WORKSH NEUR N, P276; Paredes R, 2006, IEEE T PATTERN ANAL, V28, P1100, DOI 10.1109/TPAMI.2006.145; Platt J. C, 1998, ADV KERNEL METHODS S, P41; Roweis S. T., 2003, J MACHINE LEARNING R, V4, P119; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; RUPRECHT D, 1994, 539 U DORTM; Tan SB, 2005, EXPERT SYST APPL, V28, P667, DOI 10.1016/j.eswa.2004.12.023; Vapnik V., 1982, ESTIMATION DEPENDENC; VIJAYAKUMAR S, 2006, NEAREST NEIGHBOR MET, P103; WAND MP, 1990, CAN J STAT, V18, P197, DOI 10.2307/3315450; WANG ZY, 1994, ANAL CHEM, V66, P249, DOI 10.1021/ac00074a012; Wolberg G., 1990, DIGITAL IMAGE WARPIN; Xue G., 2005, P 28 ANN INT ACM SIG, P114, DOI 10.1145/1076034.1076056; Zhang XX, 2006, PATTERN RECOGN LETT, V27, P1927, DOI 10.1016/j.patrec.2006.03.015	40	17	17	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	NOV	2008	41	11					3507	3518		10.1016/j.patcog.2008.04.009		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	342XV	WOS:000258817800022	
J	Hall, P; Park, BU; Samworth, RJ				Hall, Peter; Park, Byeong U.; Samworth, Richard J.			CHOICE OF NEIGHBOR ORDER IN NEAREST-NEIGHBOR CLASSIFICATION	ANNALS OF STATISTICS			English	Article						Bayes classifier; bootstrap resampling; Edgeworth expansion; error probability; misclassification error; nonparametric classification; Poisson distribution	NONPARAMETRIC DISCRIMINATION; PATTERN-CLASSIFICATION; CONVERGENCE; ERROR; RATES; PROBABILITY; CONSISTENCY; CLASSIFIERS; RULES; RISK	The kth-nearest neighbor rule is arguably the simplest and most intuitively appealing nonparametric classification procedure. However, application of this method is inhibited by lack of knowledge about its properties, in particular, about the manner in which it is influenced by the value of k; and by the absence of techniques for empirical choice of k. In the present paper we detail the way in which the value of k determines the misclassification error. We consider two models, Poisson and Binomial, for the training samples. Under the first model, data are recorded in a Poisson stream and are "assigned" to one or other of the two populations in accordance with the prior probabilities. In particular, the total number of data in both training samples is a Poisson-distributed random variable. Under the Binomial model, however, the total number of data in the training samples is fixed, although again each data value is assigned in a random way. Although the values of risk and regret associated with the Poisson and Binomial models are different, they are asymptotically equivalent to first order, and also to the risks associated with kernel-based classifiers that are tailored to the case of two derivatives. These properties motivate new methods for choosing the value of k.	[Hall, Peter] Univ Melbourne, Dept Math & Stat, Melbourne, Vic 3010, Australia; [Park, Byeong U.] Seoul Natl Univ, Dept Stat, Seoul 151747, South Korea; [Samworth, Richard J.] Univ Cambridge, Ctr Math Sci, Stat Lab, Cambridge CB3 0WB, England	Hall, P (reprint author), Univ Melbourne, Dept Math & Stat, Melbourne, Vic 3010, Australia.	bupark2000@gmail.com			KOSEF [R02-2004-000-10040-0]	Supported by KOSEF (project R02-2004-000-10040-0).	Audibert JY, 2007, ANN STAT, V35, P608, DOI 10.1214/009053606000001217; Bax E, 2000, IEEE T INFORM THEORY, V46, P2746, DOI 10.1109/18.887892; Cover T.M., 1968, P HAW INT C SYST SCI, P413; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE LP, 1977, ANN STAT, V5, P536, DOI 10.1214/aos/1176343851; DEVROYE L, 1981, ANN STAT, V9, P1320, DOI 10.1214/aos/1176345648; Devroye L, 1996, PROBABILISTIC THEORY; DEVROYE L, 1982, HDB STAT, V2, P193, DOI 10.1016/S0169-7161(82)02011-2; DEVROYE L, 1994, ANN STAT, V22, P1371, DOI 10.1214/aos/1176325633; FIX E, 1951, 4 RAND FIELD; FRITZ J, 1975, IEEE T INFORM THEORY, V21, P552, DOI 10.1109/TIT.1975.1055443; GYORFI L, 1978, IEEE T INFORM THEORY, V24, P512, DOI 10.1109/TIT.1978.1055900; GYORFI L, 1981, IEEE T INFORM THEORY, V27, P362, DOI 10.1109/TIT.1981.1056344; GYORFI L, 1978, IEEE T INFORM THEORY, V24, P509, DOI 10.1109/TIT.1978.1055898; Gyorfi L., 2002, DISTRIBUTION FREE TH; HALL P, 2007, CHOICE NEIGHBOUR ORD; Hall P, 2005, ANN STAT, V33, P284, DOI 10.1214/009053604000000959; Holst M, 2001, ANN STAT, V29, P1424; KHARIN YS, 1979, STAT PROBLEMS CONTRO, V38, P77; KHARIN YS, 1982, T 9 PRAG C INF THEOR, P11; KOHLER M, 2006, RATE CONVERGEN UNPUB; KULKARNI SR, 1995, IEEE T INFORM THEORY, V41, P1028, DOI 10.1109/18.391248; Mammen E, 1999, ANN STAT, V27, P1808; MARRON JS, 1983, ANN STAT, V11, P1142; PSALTIS D, 1994, IEEE T INFORM THEORY, V40, P820, DOI 10.1109/18.335893; Raudys S, 2004, J MULTIVARIATE ANAL, V89, P1, DOI 10.1016/S0047-259X(02)00021-0; Snapp RR, 1998, ANN STAT, V26, P850; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698	28	18	20	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	0090-5364		ANN STAT	Ann. Stat.	OCT	2008	36	5					2135	2152		10.1214/07-AOS537		18	Statistics & Probability	Mathematics	367LS	WOS:000260554100005	
J	Morton, KD; Torrione, PA; Throckmorton, CS; Collins, LM				Morton, Kenneth D.; Torrione, Peter A., Jr.; Throckmorton, Chandra S.; Collins, Leslie M.			Mandarin Chinese tone identification in cochlear implants: Predictions from acoustic models	HEARING RESEARCH			English	Article						Cochlear implant; Mandarin Chinese tones; F0 estimation; Particle filter	SPEECH CODING STRATEGY; AUDITORY-PERCEPTION; PITCH PERCEPTION; FINE-STRUCTURE; RECOGNITION; STIMULATION; NOISE; CUES; INFORMATION; AMPLITUDE	It has been established that current cochlear implants do not supply adequate spectral information for perception of tonal languages. Comprehension of a tonal language, such as Mandarin Chinese, requires recognition of lexical tones. New strategies of cochlear stimulation such as variable stimulation rate and current steering may provide the means of delivering more spectral information and thus may provide the auditory fine-structure required for tone recognition. Several cochlear implant signal processing strategies are examined in this study, the continuous interleaved sampling (CIS) algorithm, the frequency amplitude modulation encoding (FAME) algorithm, and the multiple carrier frequency algorithm (MCFA). These strategies provide different types and amounts of spectral information. Pattern recognition techniques can be applied to data from Mandarin Chinese tone recognition tasks using acoustic models as a means of testing the abilities of these algorithms to transmit the changes in fundamental frequency indicative of the four lexical tones. The ability of processed Mandarin Chinese tones to be correctly classified may predict trends in the effectiveness of different signal processing algorithms in cochlear implants. The proposed techniques can predict trends in performance of the signal processing techniques in quiet conditions but fail to do so in noise. (C) 2008 Elsevier B.V. All rights reserved.	[Morton, Kenneth D.; Torrione, Peter A., Jr.; Throckmorton, Chandra S.; Collins, Leslie M.] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA	Collins, LM (reprint author), Duke Univ, Dept Elect & Comp Engn, Box 90291, Durham, NC 27708 USA.	lcollins@ee.duke.edu			NIH [1-R01-DC007994-01]	The authors would like to acknowledge Dr. Zeng at the University of California Irvine for his help in acquiring the speech material used in this research. They would also like to thank the subjects who participated in the experiment. This research was supported in part by NIH Grant 1-R01-DC007994-01.	Arnoldner C, 2007, ACTA OTO-LARYNGOL, V127, P1298, DOI 10.1080/00016480701275261; Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374; BLAMEY PJ, 1984, J ACOUST SOC AM, V76, P104, DOI 10.1121/1.391104; BLAMEY PJ, 1984, J ACOUST SOC AM, V76, P97, DOI 10.1121/1.391012; Clopper CJ, 1934, BIOMETRIKA, V26, P404, DOI 10.2307/2331986; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dorman MF, 1997, J ACOUST SOC AM, V102, P2403, DOI 10.1121/1.419603; Duda R.O., 2004, PATTERN CLASSIFICATI; FEARN R, 2001, 7 S COCHL IMPL CHILD, P51; Fearn R.A., 2001, THESIS U NEW S WALES; FLANAGAN JL, 1966, AT&T TECH J, V45, P1493; Fu QJ, 1998, J ACOUST SOC AM, V104, P505, DOI 10.1121/1.423251; GORDON NJ, 1993, IEE PROC-F, V140, P107; GRAYDEN DB, 2006, P 11 AUSTR INT C SPE, P323; GREENWOOD D, 1961, J ACOUST SOC AM, V33, P1344, DOI 10.1121/1.1908437; GREENWOOD DD, 1990, J ACOUST SOC AM, V87, P2592, DOI 10.1121/1.399052; KOCH DB, 2005, C IMPL AUD PROSTH A; Kong YY, 2006, J ACOUST SOC AM, V120, P2830, DOI 10.1121/1.2346009; Lan N, 2004, IEEE T BIO-MED ENG, V51, P752, DOI 10.1109/TBME.2004.826597; LAROCHE J, 1999, IEEE WORKSH APPL SIG; LI J, 1999, FUZZ SYST C P FUZZ I, V2, P1059; Luo RC, 2004, IEEE T AUTOM SCI ENG, V1, P4, DOI [10.1109/TASE.2004.829344, 10.1109/TASE.2004.839344]; Luo Xin, 2004, Journal of the Acoustical Society of America, V116, P3659, DOI 10.1121/1.1783352; MARKEL JD, 1972, IEEE T ACOUST SPEECH, VAU20, P367, DOI 10.1109/TAU.1972.1162410; McDermott HJ, 1997, J ACOUST SOC AM, V101, P1622, DOI 10.1121/1.418177; Nie KB, 2005, IEEE T BIO-MED ENG, V52, P64, DOI 10.1109/TBME.2004.839799; NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469; NOGUEIRA W, 2007, ENG MED BIOL SOC EMB, P4127; Nogueira W, 2005, EURASIP J APPL SIG P, V2005, P3044, DOI 10.1155/ASP.2005.3044; REMUS J, 2003, C IMPL AUD PROSTH MO; Seneff S., 1988, READINGS SPEECH RECO, P101; SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303; SHI Y, 2003, P IEEE INT C AC SPEE; Smith ZM, 2002, NATURE, V416, P87, DOI 10.1038/416087a; Strope B, 1997, IEEE T SPEECH AUDI P, V5, P451, DOI 10.1109/89.622569; Tchorz J, 1999, J ACOUST SOC AM, V106, P2040, DOI 10.1121/1.427950; THROCKMORTON C, 2006, HEARING RES; TIAN Y, 2004, P ICASSP MONTR CAN, V1, P105; TONG YC, 1985, J ACOUST SOC AM, V77, P1881, DOI 10.1121/1.391939; TOWNSHEND B, 1987, J ACOUST SOC AM, V82, P106, DOI 10.1121/1.395554; Vandali AE, 2005, J ACOUST SOC AM, V117, P3126, DOI 10.1121/1.1874632; van Hoesel RJM, 2003, J ACOUST SOC AM, V113, P1617, DOI 10.1121/1.1539520; WEI CG, 2004, HEARING RES, P57; Whalen A. D., 1971, DETECTION SIGNALS NO; WHALEN DH, 1992, PHONETICA, V49, P25; WILSON BS, 1991, NATURE, V352, P236, DOI 10.1038/352236a0; Xu L, 2003, J ACOUST SOC AM, V114, P3024, DOI 10.1121/1.1623786; Xu L, 2002, J ACOUST SOC AM, V112, P247, DOI 10.1121/1.1487843; Zakis JA, 2007, SPEECH COMMUN, V49, P113, DOI 10.1016/j.specom.2006.12.001; Zeng Fan-Gang, 2004, Trends Amplif, V8, P1, DOI 10.1177/108471380400800102; Zeng FG, 2002, HEARING RES, V174, P101, DOI 10.1016/S0378-5955(02)00644-5; Zeng FG, 2005, P NATL ACAD SCI USA, V102, P2293, DOI 10.1073/pnas.0406460102; ZHENG Y, 2004, P IEEE INT C AC SPEE; ZHENG Y, 2003, IEEE WORKSH STAT SIG	54	3	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0378-5955		HEARING RES	Hear. Res.	OCT	2008	244	1-2					66	76		10.1016/j.heares.2008.07.008		11	Audiology & Speech-Language Pathology; Neurosciences; Otorhinolaryngology	Audiology & Speech-Language Pathology; Neurosciences & Neurology; Otorhinolaryngology	368XC	WOS:000260655200008	
J	Ghosh, AK				Ghosh, Anil K.			Kernel discriminant analysis using case-specific smoothing parameters	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						bandwidth; Bayes risk; bootstrap; cross validation; kernel smoothing; misclassification rate; nearest neighbor; p-value	NEAREST-NEIGHBOR CLASSIFICATION; DENSITY-ESTIMATION; BANDWIDTH CHOICE; NONPARAMETRIC REGRESSION; SELECTION; ESTIMATORS; CURVES; ERROR	In kernel discriminant analysis, one common practice is to use a fixed level of smoothing (estimated from training data) for classifying all unlabeled observations. But, in classification, a good choice of smoothing parameters also depends on the observation to be classified. Therefore, instead of using a fixed level of smoothing over the entire measurement space, it may be more useful to estimate the smoothing parameters depending on that specific observation. Here, we propose a simple method for this case-specific smoothing. Some benchmark data sets are analyzed to illustrate the performance of the proposed method.	[Ghosh, Anil K.] Indian Inst Technol, Dept Math & Stat, Kanpur 208016, Uttar Pradesh, India	Ghosh, AK (reprint author), Indian Stat Inst, Theoret Stat & Math Unit, Calcutta 700108, India.	akghosh@isical.ac.in					ABRAMSON IS, 1982, ANN STAT, V10, P1217, DOI 10.1214/aos/1176345986; BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; Chapelle O., 2006, SEMISUPERVISED LEARN; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; GHOSH AK, 2008, KERNEL DISCRIMINANT; Ghosh AK, 2007, INT J PATTERN RECOGN, V21, P1103, DOI 10.1142/S0218001407005855; Ghosh AK, 2004, STAT SINICA, V14, P457; Ghosh AK, 2007, J COMPUT GRAPH STAT, V16, P482, DOI 10.1198/106186007x208380; HALL P, 1981, BIOMETRIKA, V68, P287, DOI 10.1093/biomet/68.1.287; Hall P, 2005, ANN STAT, V33, P284, DOI 10.1214/009053604000000959; Hand D. J., 1982, KERNEL DISCRIMINANT; HARDLE W, 1985, ANN STAT, V13, P1465, DOI 10.1214/aos/1176349748; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hastie T, 1998, ANN STAT, V26, P451; Jones MC, 1996, J AM STAT ASSOC, V91, P401, DOI 10.2307/2291420; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MULLER HG, 1984, ANN STAT, V12, P766, DOI 10.1214/aos/1176346523; MULLER HG, 1987, ANN STAT, V15, P182, DOI 10.1214/aos/1176350260; PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875; RICE J, 1984, ANN STAT, V12, P1215, DOI 10.1214/aos/1176346788; Ripley B. D., 1996, PATTERN RECOGNITION; Sain SR, 1996, J AM STAT ASSOC, V91, P1525, DOI 10.2307/2291578; SCHUCANY WR, 1995, J AM STAT ASSOC, V90, P535, DOI 10.2307/2291064; Scott D. W., 1992, MULTIVARIATE DENSITY; SHEATHER SJ, 1991, J ROY STAT SOC B MET, V53, P683; Silverman B.W., 1986, DENSITY ESTIMATION S; Sklansky J., 1981, PATTERN CLASSIFIERS; STAINWALIS JG, 1989, J AM STAT ASSOC, V84, P284; TERRELL GR, 1992, ANN STAT, V20, P1236, DOI 10.1214/aos/1176348768; Tukey J. W, 1977, EXPLORATORY DATA ANA; VIEU P, 1991, J ROY STAT SOC B MET, V53, P453; Wand M. P., 1995, KERNEL SMOOTHING; WASSEL GN, 1972, IEEE T SYST MAN CYB, VSMC2, P533, DOI 10.1109/TSMC.1972.4309163; Zhang ZH, 2006, MACH LEARN, V63, P69, DOI 10.1007/s10994-006-6130-8	36	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	OCT	2008	38	5					1413	1418		10.1109/TSMCB.2008.925754		6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	348DT	WOS:000259191900017	
J	Aimeur, E; Brassard, G; Fernandez, JM; Onana, FSM				Aimeur, Esma; Brassard, Gilles; Fernandez, Jose M.; Onana, Flavien Serge Mani			ALAMBIC: a privacy-preserving recommender system for electronic commerce	INTERNATIONAL JOURNAL OF INFORMATION SECURITY			English	Article						privacy protection; recommender system; secure two-party computation; semi-trusted third party; web personalization	WEB; PERSONALIZATION; IDENTIFICATION	Recommender systems enable merchants to assist customers in finding products that best satisfy their needs. Unfortunately, current recommender systems suffer from various privacy-protection vulnerabilities. Customers should be able to keep private their personal information, including their buying preferences, and they should not be tracked against their will. The commercial interests of merchants should also be protected by allowing them to make accurate recommendations without revealing legitimately compiled valuable information to third parties. We introduce a theoretical approach for a system called Alambic, which achieves the above privacy-protection objectives in a hybrid recommender system that combines content-based, demographic and collaborative filtering techniques. Our system splits customer data between the merchant and a semi-trusted third party, so that neither can derive sensitive information from their share alone. Therefore, the system could only be subverted by a coalition between these two parties.	[Fernandez, Jose M.] Ecole Polytech, Dept Genie Informat, Montreal, PQ H3C 3A7, Canada; [Aimeur, Esma; Brassard, Gilles; Onana, Flavien Serge Mani] Univ Montreal, Dept Informat & Rech Operat, Montreal, PQ H3C 3J7, Canada	Fernandez, JM (reprint author), Ecole Polytech, Dept Genie Informat, Montreal, PQ H3C 3A7, Canada.	aimeur@iro.umontreal.ca; brassard@iro.umontreal.ca; jose.fernandez@polymtl.ca; manionaf@iro.umontreal.ca					Ackerman B, 1999, COLUMBIA LAW REV, V99, P1, DOI 10.2307/1123596; AIELLO B, 2001, P ADV CRYPTOLOGY EUR, P119; AIMEUR E, 2006, P ACM S APPL COMP SA, P872, DOI 10.1145/1141277.1141479; AIMEUR E, 2002, P ITS 2002, P718; Aimeur E., 2006, IADIS INT J, V4, P55; Aimeur E., 2006, Journal of Computer Security, V14; ARDISSONO L, 2005, P 10 INT C US MOD ED; Barak B., 2001, P 21 ANN INT CRYPT C, P1; BENOR M, 1988, P 20 ANN ACM S THEOR, P11; BOYAN J, 1997, COMPUT MEDIATED COMM, V4; Breese J. S, 1998, P 14 C UNC ART INT, P43; BURKE R, 2002, CUSTOMER MODELING CU, V4, P331; BURKE R, 2005, P 3 INT WORKSH INT T, P17; CAMENISCH J., 2005, P CRYPT 2005 SANT BA, P169; Canny J., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/564376.564419; Canny J, 2002, P IEEE S SECUR PRIV, P45, DOI 10.1109/SECPRI.2002.1004361; CHANG Y, 2004, SINGLE DATABASE PRIV; CHAUM D, 1985, P CRYPT 85 SANT BARB, P477; Chaum D., 1982, P CRYPTO 82, P199; CHAUM D, 1988, P 20 ANN ACM S THEOR, P1; Chaum D., 1983, P ADV CRYPT 83 NEW Y, P153; CHAUM D, 1985, COMMUN ACM, V28, P1030, DOI 10.1145/4372.4373; CHAUM DL, 1981, COMMUN ACM, V24, P84, DOI 10.1145/358549.358563; Chen Stephen, 2005, STRATEGIC MANAGEMENT; Chor B., 1995, Proceedings. 36th Annual Symposium on Foundations of Computer Science (Cat. No.95CB35834), DOI 10.1109/SFCS.1995.492461; COOLEY T, 1888, TREATISE CONSTITUTIO; Cover T.M., 1968, P HAW INT C SYST SCI, P413; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cramer R, 1997, P INT C THEOR APPL C, P103; FLINN S, 2005, P C PRIV SEC TRUST P, P15; Fox S., 2001, TRUST PRIVACY ONLINE; FREYNE J, 2005, P 3 WORKSH INT TECHN, P73; Gabber E, 1999, COMMUN ACM, V42, P42, DOI 10.1145/293411.293447; Gertner Y., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276723; GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867; Goldreich O., 1987, P 19 ANN ACM S THEOR, P218, DOI 10.1145/28395.28420; Goldschlag D., 1999, COMMUN ACM, V42, P84; GREENSPAN R, 2004, SURFERS PREFER PERSO; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; JHA S, 2005, P 10 EUR S RES COMP; KATZ J, 2004, P CRYPTO, P335; Kilian J., 1988, Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/62212.62215; Kobsa A, 2001, KNOWL ENG REV, V16, P111, DOI 10.1017/S0269888901000108; Kushilevitz E., 1997, Proceedings. 38th Annual Symposium on Foundations of Computer Science (Cat. No.97CB36150), DOI 10.1109/SFCS.1997.646125; Lam S. K., 2004, P 13 INT C WORLD WID, P393, DOI 10.1145/988672.988726; Lynn B., 2004, P EUR 2004, P20; MALKHI D, 2004, P US SEC S SAN DIEG, P9; MEREGU S, 2003, P 3 IEEE INT C DAT M, P211; Miller BN, 2004, ACM T INFORM SYST, V22, P437, DOI 10.1145/1010614.1010618; MOBASHER B, 2005, P 3 INT WORKSH INT T; Mobasher B, 2000, COMMUN ACM, V43, P142, DOI 10.1145/345124.345169; Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943; Pazzani MJ, 1999, ARTIF INTELL REV, V13, P393, DOI 10.1023/A:1006544522159; Pedersen T. P., 1991, P EUR 91, P522; PENNOCK D. M., 2000, P 16 C UNC ART INT S, P473; Perkowitz M., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Pierrakos D, 2003, USER MODEL USER-ADAP, V13, P311, DOI 10.1023/A:1026238916441; Polat H, 2005, INT J ELECTRON COMM, V9, P9; PRETSCHNER A, 1999, FY2000TR1359101 ITTC; Riedl J., 1994, P ACM C COMP SUPP CO, P175, DOI 10.1145/192844.192905; Rucker J, 1997, COMMUN ACM, V40, P73, DOI 10.1145/245108.245125; Salinger JD, 1951, CATCHER RYE; SANDER T, 1998, P IEEE S SEC PRIV OA, P162; Schafer J. B., 2001, Data Mining and Knowledge Discovery, V5, DOI 10.1023/A:1009804230409; SCHAFER JB, 1999, P 1 ACM C EL COMM DE, P158, DOI DOI 10.1145/336992.337035; Spiekermann Sarah, 2001, P 3 ACM C EL COMM TA, P38, DOI 10.1145/501158.501163; SURYAVANSHI BS, 2005, P 3 WORKSH INT TECHN, P1; Teltzrow M., 2004, DESIGNING PERSONALIZ, P315; Turban E., 2006, ELECT COMMERCE MANAG; VERYKIOS VS, 2004, ACM SIGMOD RECORD, V33, P50, DOI DOI 10.1145/974121.974131; Westin A. F., 1967, PRIVACY FREEDOM; Yao A., 1982, P 23 IEEE S FDN COMP, P160; Yao A.C.C., 1986, P 27 IEEE S FDN COMP, P162; Zhu K, 2004, MANAGE SCI, V50, P670, DOI 10.1287/mnsc.1040.0226; *HARR INT, 2000, SURV CONS PRIV ATT B; *HARR INT, 2003, MOST PEOPL AR PRIV P; *ROY MORG RES, 2001, PRIV COMM; *UMR, 2001, PRIV CONC LOOM LARG	78	8	9	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1615-5262		INT J INF SECUR	Int. J. Inf. Secur.	OCT	2008	7	5					307	334		10.1007/s10207-007-0049-3		28	Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	354WV	WOS:000259671500001	
J	Laguia, M; Castro, JL				Laguia, Manuel; Castro, Juan Luis			Local distance-based classification	KNOWLEDGE-BASED SYSTEMS			English	Article						Distance measure; k-NN; Classification; Similarity; Machine learning	NEAREST-NEIGHBOR; LEARNING ALGORITHMS	In this paper, we have introduced a new method in which every training point learns what is happening in its neighborhood. So, a hyperplane is learned and associated to each point. With this hyperplane we can define the bands distance, a distance measure that bring closer or move away points depending on its classes. We have used this new distance in classification tasks and have performed tests over 68 datasets: IS well-known UCI-Repository datasets, one private dataset, and 49 ad hoc synthetic datasets. We have used 10-fold cross-validation and, in order to compare the results of the classifiers, we have considered the mean accuracy and have also performed a paired two-tailored t-Student's test with a significance level of 95%. The results are encouraging and confirm the good behavior of the new proposed classification method. The bands distance has obtained the best overall results with 1-NN and k-NN classifiers when compared with other distances. Finally, we extract conclusions and outline some lines of future work. (c) 2008 Elsevier B.V. All rights reserved.	[Laguia, Manuel] Univ Cadiz, ES Ingn Cadiz, Dept Lenguajes & Sistemas Informat, Cadiz 11002, Spain; [Castro, Juan Luis] Univ Granada, ETS Ingn Informat, Dept C Comp & Inteligencia Artificial, E-18071 Granada, Spain	Laguia, M (reprint author), Univ Cadiz, ES Ingn Cadiz, Dept Lenguajes & Sistemas Informat, Cadiz 11002, Spain.	manuel.laguia@uca.es; castro@decsai.ugr.es	Castro, Juan Luis/C-2403-2012				AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake CL, 1998, UCI REPOSITORY MACHI; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Domingos P, 1997, ARTIF INTELL REV, V11, P227; Fix E, 1951, 4 US AIR FORC SCH AV; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; LAGUIA M, 2001, C EUR SOC FUZZ LOG T; LAGUIA M, 2005, 11 WORLD C INT FUZZ; LAGUIA M, 2007, MATHWARE SOFT COMPUT, V14, P5; PLAZA E, 1996, 3 EUR WORKSH CAS BAS; RICCI F, 1995, 1 INT C ICCBR 95, P301; Ricci F, 1999, IEEE T PATTERN ANAL, V21, P380, DOI 10.1109/34.761268; RITCHER MM, 1995, MATH STAT METHODS AR, P171; RITCHER MM, 1992, 16 JAHR GES KLASS GF; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1023/A:1022661727670; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; WETTSCHERECK D, 1994, THESIS OREGON STATE; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	22	9	9	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051		KNOWL-BASED SYST	Knowledge-Based Syst.	OCT	2008	21	7					692	703		10.1016/j.knosys.2008.03.050		12	Computer Science, Artificial Intelligence	Computer Science	362RC	WOS:000260213800020	
J	Xu, RW; He, L				Xu, Rongwu; He, Lin			GACEM: Genetic Algorithm Based Classifier Ensemble in a Multi-sensor System	SENSORS			English	Article						Genetic algorithm; classifier ensemble; multi-sensor system; optimization; fusion	NEURAL-NETWORKS; DATA FUSION; PERFORMANCE; COMBINATION; TRACKING	Multi-sensor systems (MSS) have been increasingly applied in pattern classification while searching for the optimal classification framework is still an open problem. The development of the classifier ensemble seems to provide a promising solution. The classifier ensemble is a learning paradigm where many classifiers are jointly used to solve a problem, which has been proven an effective method for enhancing the classification ability. In this paper, by introducing the concept of Meta-feature (MF) and Trans-function (TF) for describing the relationship between the nature and the measurement of the observed phenomenon, classification in a multi-sensor system can be unified in the classifier ensemble framework. Then an approach called Genetic Algorithm based Classifier Ensemble in Multi-sensor system (GACEM) is presented, where a genetic algorithm is utilized for optimization of both the selection of features subset and the decision combination simultaneously. GACEM trains a number of classifiers based on different combinations of feature vectors at first and then selects the classifiers whose weight is higher than the pre-set threshold to make up the ensemble. An empirical study shows that, compared with the conventional feature-level voting and decision-level voting, not only can GACEM achieve better and more robust performance, but also simplify the system markedly.	[Xu, Rongwu; He, Lin] Naval Univ Engn, Inst Noise & Vibrat, Wuhan 430033, Peoples R China	He, L (reprint author), Naval Univ Engn, Inst Noise & Vibrat, Wuhan 430033, Peoples R China.	r.xu@ieee.org; helin202@public.wh.hb.cn			National Natural Science Foundation of P. R. China [50775218]	This work was supported by the National Natural Science Foundation of P. R. China under Grant No. 50775218. And the authors would like to thank the anonymous referees for many useful comments and suggestions.	Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Brooks RR, 2003, P IEEE, V91, P1163, DOI 10.1109/JPROC.2003.814923; Buczak AL, 1996, INFORM SCIENCES, V93, P265, DOI 10.1016/0020-0255(96)00078-3; CLOUQUEUR T, 2001, P 4 ANN C INF FUS; COSTA AD, 2003, INT C AC SPEECH SIGN, P832; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich TG, 1997, AI MAG, V18, P97; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Gardner JW, 2005, SENSOR ACTUAT B-CHEM, V106, P114, DOI 10.1016/j.snb.2004.05.043; Hall DL, 1997, P IEEE, V85, P6, DOI 10.1109/5.554205; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; KACALENGA R, 2003, IEEE AEROSPACE ELECT, V18, P13; KITTLER J, 2001, P DERA IEE WORKSH IN, P1; Kittler J, 1997, PATTERN RECOGN LETT, V18, P845, DOI 10.1016/S0167-8655(97)00062-7; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; Kuncheva LI, 2000, IEEE T EVOLUT COMPUT, V4, P327, DOI 10.1109/4235.887233; Lam L, 1997, IEEE T SYST MAN CY A, V27, P553, DOI 10.1109/3468.618255; Lawrence RL, 2001, PHOTOGRAMM ENG REM S, V67, P1137; Lin XF, 2003, PATTERN RECOGN LETT, V24, P1959, DOI 10.1016/S0167-8655(03)00035-7; Luo RC, 2002, IEEE SENS J, V2, P107, DOI 10.1109/JSEN.2002.1000251; Maslov IV, 2006, INFORM FUSION, V7, P304, DOI 10.1016/j.inffus.2005.01.001; Narasimhamurthy A, 2005, IEEE T PATTERN ANAL, V27, P1988, DOI 10.1109/TPAMI.2005.249; PERRONE MP, 1993, IMPROVING REGRESSION; POLIKAR R, 2006, SAS 2006 IEEE SENS A, P180; RAJAGOPAL R, 1990, INT CONF ACOUST SPEE, P2911, DOI 10.1109/ICASSP.1990.116235; ROLI F, 2001, P SPIE IM SIGN PROC, P103; Roli F, 2001, P 2 INT WORKSH MULT, P78; Ruta D., 2005, Information Fusion, V6, DOI 10.1016/j.inffus.2004.04.008; Schapire RE, 1999, P 16 INT JOINT C ART, P1401; SETO ML, 2004, UNDERWATER DEFENCE T, P1; Smith D, 2006, IEEE T KNOWL DATA EN, V18, P1696, DOI 10.1109/TKDE.2006.183; Tumer K., 1999, COMBINING ARTIFICIAL, P127; Ueda N, 2000, IEEE T PATTERN ANAL, V22, P207, DOI 10.1109/34.825759; Worden K, 2001, ENG STRUCT, V23, P885, DOI 10.1016/S0141-0296(00)00118-8; Xu Rongwu, 2008, Chinese Journal of Mechanical Engineering, V44, DOI 10.3901/JME.2008.07.151; Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X	37	1	1	MOLECULAR DIVERSITY PRESERVATION INTERNATIONAL-MDPI	BASEL	KANDERERSTRASSE 25, CH-4057 BASEL, SWITZERLAND	1424-8220		SENSORS-BASEL	Sensors	OCT	2008	8	10					6203	6224		10.3390/s8106203		22	Chemistry, Analytical; Electrochemistry; Instruments & Instrumentation	Chemistry; Electrochemistry; Instruments & Instrumentation	366TB	WOS:000260505200006	
J	Pedreira, CE; Costa, ES; Barrena, S; Lecrevisse, Q; Almeida, J; van Dongen, JJM; Orfao, A				Pedreira, Carlos E.; Costa, Elaine S.; Barrena, Susana; Lecrevisse, Quentin; Almeida, Julia; van Dongen, Jacques J. M.; Orfao, Alberto		EuroFlow Consoritum	Generation of flow cytometry data files with a potentially infinite number of dimensions	CYTOMETRY PART A			English	Article						B-cell chronic lymphoproliferative disorders; flow cytometry; immunophenotyping; FCS files; data calculation; nearest neighbor	CHRONIC LYMPHOCYTIC-LEUKEMIA; CHRONIC LYMPHOPROLIFERATIVE DISORDERS; MINIMAL RESIDUAL DISEASE; MYELODYSPLASTIC SYNDROMES; BONE-MARROW; CELL CLONE; EXPRESSION; LYMPHOMAS; NEOPLASIAS; CLASSIFICATION	Immunophenotypic characterization of B-cell chronic lymphoproliferative disorders (B-CLPD) is associated with the use of increasingly larger panels of multiple combinations of 3 to >= 6 monoclonal antibodies (Mab), data analysis being separately performed for each of the different stained sample aliquots. Here, we describe and validate an automated method for calculation of flow cytometric data from several multicolor stainings of the same cell sample-i.e., the merging of data from different aliquots stained with partially overlapping combinations of Mab reagents (focusing on >= 1 cell populations)-into one data file as if it concerned a single "super" multicolor staining. Evaluation of the performance of the method described was done in a group of 60 B-CLPD studied at diagnosis with 18 different reagents in a panel containing six different 3- and 4-color stainings, which systematically contained CD19 for the identification of B-cells. Our results show a high degree of correlation and agreement between originally measured and calculated data about cell surface stainings, providing a basis for the use of this approach for the generation of flow cytometric data files containing information about a virtually infinite number of stainings for each individual cellular event measured in a sample, using a limited number of fluorochrome stainings. (C) 2008 International Society for Advancement of Cytometry.	[Pedreira, Carlos E.] Univ Fed Rio de Janeiro, Fac Med, Rio De Janeiro, Brazil; [Pedreira, Carlos E.] Univ Fed Rio de Janeiro, COPPE, Engn Grad Program, Rio De Janeiro, Brazil; [Costa, Elaine S.] Univ Fed Rio de Janeiro, Inst Pediat & Puericultura Martagao Gesteira, Rio De Janeiro, Brazil; [Costa, Elaine S.] Univ Fed Rio de Janeiro, Dept Clin Med, Rio De Janeiro, Brazil; [Barrena, Susana; Lecrevisse, Quentin; Almeida, Julia; Orfao, Alberto] Univ Salamanca, Cytometry Serv, Dept Med, E-37008 Salamanca, Spain; Univ Salamanca, Cytometry Serv, Canc Res Ctr, IBMCC,CSIC, E-37008 Salamanca, Spain; [van Dongen, Jacques J. M.] Univ Med Ctr Rotterdam, Dept Immunol, Erasmus MC, Rotterdam, Netherlands	Orfao, A (reprint author), Paseo Univ Coimbra, Ctr Invest Cancer, S-N,Campus Miguel Unamuno, Salamanca 37007, Spain.	orfao@usal.es	2008, Ibsal/A-1268-2012		Departamento de Clinica Medica, Federal University of Rio de Janeiro, Brazil	The authors thank Prof. Nelson Spector (Departamento de Clinica Medica, Federal University of Rio de Janeiro, Brazil) for his helpful support.	Ashman M, 2007, CYTOM PART B-CLIN CY, V72B, P380, DOI 10.1002/cyto.b.20178; Bakke AC, 2006, CYTOM PART B-CLIN CY, V70B, P227, DOI 10.1002/cyto.b.20079; Barlage S, 1999, ANAL CELL PATHOL, V19, P81; Bigos Martin, 1999, Cytometry, V36, P36, DOI 10.1002/(SICI)1097-0320(19990501)36:1<36::AID-CYTO5>3.0.CO;2-9; Braylan RC, 2001, CYTOMETRY, V46, P23, DOI 10.1002/1097-0320(20010215)46:1<23::AID-CYTO1033>3.0.CO;2-Z; Braylan RC, 2004, CYTOM PART A, V58A, P57, DOI 10.1002/cyto.a.10101; Costa ES, 2006, LEUKEMIA, V20, P1221, DOI 10.1038/sj.leu.2404241; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; del Canizo MC, 2003, HAEMATOLOGICA, V88, P402; Del Principe MI, 2006, BLOOD, V108, P853, DOI 10.1182/blood-2005-12-4986; Deneys V, 2001, J IMMUNOL METHODS, V253, P23, DOI 10.1016/S0022-1759(01)00338-6; DiGiuseppe JA, 1998, SEMIN ONCOL, V25, P6; Duda R. O., 2001, PATTERN CLASSIFICATI; Gervasi F, 2004, ANN NY ACAD SCI, V1028, P457, DOI 10.1196/annals.1322.054; Harris NL, 1999, J CLIN ONCOL, V17, P3835; Hayat A, 2006, LEUKEMIA LYMPHOMA, V47, P2371, DOI 10.1080/10428190600947727; Kaleem Z, 2006, ARCH PATHOL LAB MED, V130, P1850; Kappelmayer J, 2000, J IMMUNOL METHODS, V242, P53, DOI 10.1016/S0022-1759(00)00220-9; MACEDO A, 1995, LEUKEMIA, V9, P1896; Matutes E, 2002, J CLIN PATHOL, V55, P180; Montillo M, 2005, CANCER INVEST, V23, P488, DOI 10.1080/07357900500201418; Moreton P, 2005, J CLIN ONCOL, V23, P2971, DOI 10.1200/JCO.2005.04.021; Ortuno F, 1997, HAEMATOLOGICA, V82, P334; Pagnucco G, 2006, ANN NY ACAD SCI, V1089, P383, DOI 10.1196/annals.1386.031; Pantelias A, 2007, BLOOD, V109, P4980, DOI 10.1182/blood-2006-11-056895; Perfetto SP, 2004, NAT REV IMMUNOL, V4, P648, DOI 10.1038/nri1416; Rawstron AC, 2001, BLOOD, V98, P29, DOI 10.1182/blood.V98.1.29; ROBINSON JP, 1991, CYTOMETRY, V12, P82, DOI 10.1002/cyto.990120112; ROBINSON JP, 1992, CYTOMETRY, V13, P75, DOI 10.1002/cyto.990130112; Rossmann E D, 2001, Hematol J, V2, P300, DOI 10.1038/sj.thj.6200119; Sanchez ML, 2006, HAEMATOL-HEMATOL J, V91, P331; Sanchez ML, 2002, LEUKEMIA, V16, P1460, DOI 10.1038/sj.leu.2402584; Sanchez ML, 2003, BLOOD, V102, P2994, DOI 10.1182/blood-2003-01-0045; Stetler-Stevenson M, 2001, SEMIN HEMATOL, V38, P111, DOI 10.1053/shem.2001.21923; Tung JW, 2004, CLIN IMMUNOL, V110, P277, DOI 10.1016/j.clim.2003.11.016; Valent P, 2007, LEUKEMIA RES, V31, P727, DOI 10.1016/j.leukres.2006.11.009; Van Lochem EG, 1997, LEUKEMIA, V11, P2208, DOI 10.1038/sj.leu.2400862; Wang LL, 2006, CYTOM PART B-CLIN CY, V70B, P410, DOI 10.1002/cyto.b.20140	38	31	33	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	1552-4922		CYTOM PART A	Cytom. Part A	SEP	2008	73A	9					834	846		10.1002/cyto.a.20608		13	Biochemical Research Methods; Cell Biology	Biochemistry & Molecular Biology; Cell Biology	343XV	WOS:000258890500009	
J	Rovatti, R; Mazzini, G				Rovatti, Riccardo; Mazzini, Gianluca			On the nearest neighbor of the nearest neighbor in multidimensional continuous and quantized space	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article						dimensionality effect; Euclidean distances; nearest neighbor; Poisson point processes; quantized distances	WIRELESS NETWORKS	The probability that an entity in a set of entities uniformly distributed in space is the nearest neighbor of its nearest neighbor is evaluated for generic distances in a multidimensional environment. Such an expression is then specialized for systems with norm-based distances and for systems with quantized norm-based distance. Examples for scalar products and sup-norm are derived. When appticable, invariances with respect to the underlying distance and entities density are highlighted. Dimensionality effects are investigated.	[Rovatti, Riccardo] Univ Bologna, ARCES, I-40125 Bologna, Italy; [Mazzini, Gianluca] Univ Ferrara, ENDIF, I-44100 Ferrara, Italy	Rovatti, R (reprint author), Univ Bologna, ARCES, I-40125 Bologna, Italy.	riccardo.rovatti@unibo.it; g.mazzini@ieee.org					ANDROUTSOS P, 2006, IEEE SIGNAL PROC MAG, P142; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Csanyi G, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.036131; Helmy A, 2003, IEEE COMMUN LETT, V7, P490, DOI 10.1109/LCOMM.2003.818887; HOLME P, 2001, PHYS REV E, V65, DOI UNSP 026107-026107; Jakllari G, 2007, IEEE J SEL AREA COMM, V25, P484, DOI 10.1109/JSAC.2007.070222; Mauve M, 2001, IEEE NETWORK, V15, P30, DOI 10.1109/65.967595; SLIVNYAK I.M., 1962, THEOR PROBAB APPL, V7, P336, DOI 10.1137/1107034; Tao YF, 2006, IEEE T KNOWL DATA EN, V18, P1239; VICSEK T, 1995, PHYS REV LETT, V75, P1226, DOI 10.1103/PhysRevLett.75.1226; Wang H, 2006, IEEE T PATTERN ANAL, V28, P942; WANG XIAO FAN, 2003, IEEE CIRCUITS SYSTEM, P6	12	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9448		IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	SEP	2008	54	9					4069	4080		10.1109/TIT.2008.928246		12	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	344FX	WOS:000258913400013	
J	Garcia, V; Mollineda, RA; Sanchez, JS				Garcia, V.; Mollineda, R. A.; Sanchez, J. S.			On the k-NN performance in a challenging scenario of imbalance and overlapping	PATTERN ANALYSIS AND APPLICATIONS			English	Article						imbalanced data; nearest neighbour rule; class overlap; local and global learning; overall imbalance ratio; local imbalance ratio	LEARNING ALGORITHMS; CLASSIFIERS	A two-class data set is said to be imbalanced when one (minority) class is heavily under-represented with respect to the other (majority) class. In the presence of a significant overlapping, the task of learning from imbalanced data can be a very difficult problem. Additionally, if the overall imbalance ratio is different from local imbalance ratios in overlap regions, the task can become in a major challenge. This paper explains the behaviour of the k-nearest neighbour (k-NN) rule when learning from such a complex scenario. This local model is compared to other machine learning algorithms, attending to how their behaviour depends on a number of data complexity features (global imbalance, size of overlap region, and its local imbalance). As a result, several conclusions useful for classifier design are inferred.	[Garcia, V.] Inst Tecnol Toluca, Lab Reconocimiento Patrones, Metepec 52140, Mexico; [Mollineda, R. A.; Sanchez, J. S.] Univ Jaume 1, Dept Llenguatges & Sistemes Informat, Castellon de La Plana 12071, Spain	Garcia, V (reprint author), Inst Tecnol Toluca, Lab Reconocimiento Patrones, Av Tecnol S-N, Metepec 52140, Mexico.	vgarciaj@hotmail.com			DPI2006-15542 [Spanish CICYT]; CSD2007-00018 [Spanish Ministry of Science and Education]; SEP-2003C02-44225 [Mexican CONACyT]	This work has been partially supported by grants DPI2006-15542 from the Spanish CICYT, CSD2007-00018 from the Spanish Ministry of Science and Education and SEP-2003C02-44225 from the Mexican CONACyT.	Barandela R, 2003, PATTERN RECOGN, V36, P849, DOI 10.1016/S0031-3203(02)00257-1; Beyer K., 1999, P 7 INT C DAT THEOR, P217; Bishop C. M., 1995, NEURAL NETWORKS PATT; Buhmann MD, 2003, RADIAL BASIS FUNCTIO; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NOR; Daskalaki S, 2006, APPL ARTIF INTELL, V20, P381, DOI 10.1080/08839510500313653; Devijver P., 1992, PATTERN RECOGNITION; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Duda R. O., 2001, PATTERN CLASSIFICATI; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P882, DOI 10.1016/j.patrec.2005.10.012; Fawcett T, 1997, DATA MIN KNOWL DISC, V1, P291, DOI 10.1023/A:1009700419189; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Gordon D., 1989, Computational Intelligence, V5, DOI 10.1111/j.1467-8640.1989.tb00317.x; Hand DJ, 2003, PATTERN RECOGN LETT, V24, P1555, DOI 10.1016/S0167-8655(02)00394-X; Huang J, 2005, IEEE T KNOWL DATA EN, V17, P299; Japkowicz N., 2002, Intelligent Data Analysis, V6; Jo T., 2004, SIGKDD EXPLORATIONS, V6, P40, DOI DOI 10.1145/1007730.1007737; KUBAT M, 1998, P 1 SO S COMP, P27; Kubat M., 1997, P 14 INT C MACH LEAR, P179; LANDGREBE TCW, 2006, P 18 INT C PATT REC, P123; Little RJA, 2002, STAT ANAL MISSING DA; Okamoto S, 2003, THEOR COMPUT SCI, V298, P207, DOI 10.1016/S0304-3975(02)00424-3; Orriols A., 2005, P C GEN EV COMP, P74, DOI 10.1145/1102256.1102271; Pazzani M., 1994, P 11 INT C MACH LEAR, P217; Prati R. C., 2004, P 3 MEX INT C ART IN, P312; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Sanchez JS, 2003, PATTERN RECOGN LETT, V24, P1015, DOI 10.1016/S0167-8655(02)00225-8; VISA S, 2003, P INF PROC MAN UNC K, V2, P97; WEISS GM, 2003, THESIS RUTGERS U; Witten I., 2005, DATA MINING PRACTICA; Zhang J., 2003, P WORKSH LEARN IMB D, P42	35	21	22	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1433-7541		PATTERN ANAL APPL	Pattern Anal. Appl.	SEP	2008	11	3-4					269	280		10.1007/s10044-007-0087-5		12	Computer Science, Artificial Intelligence	Computer Science	339LU	WOS:000258579900005	
J	Garain, U				Garain, Utpal			Prototype reduction using an artificial immune model	PATTERN ANALYSIS AND APPLICATIONS			English	Article						nearest neighbor classification; prototype selection; artificial immune system; clonal selection algorithm; statistical significance	NEAREST-NEIGHBOR RULE; CLONAL SELECTION; LEARNING ALGORITHMS; INSTANCE SELECTION; CLASSIFICATION; RECOGNITION; SYSTEM; SIZE	Artificial immune system (AIS)-based pattern classification approach is relatively new in the field of pattern recognition. The study explores the potentiality of this paradigm in the context of prototype selection task that is primarily effective in improving the classification performance of nearest-neighbor (NN) classifier and also partially in reducing its storage and computing time requirement. The clonal selection model of immunology has been incorporated to condense the original prototype set, and performance is verified by employing the proposed technique in a practical optical character recognition (OCR) system as well as for training and testing of a set of benchmark databases available in the public domain. The effect of control parameters is analyzed and the efficiency of the method is compared with another existing techniques often used for prototype selection. In the case of the OCR system, empirical study shows that the proposed approach exhibits very good generalization ability in generating a smaller prototype library from a larger one and at the same time giving a substantial improvement in the classification accuracy of the underlying NN classifier. The improvement in performance has been statistically verified. Consideration of both OCR data and public domain datasets demonstrate that the proposed method gives results better than or at least comparable to that of some existing techniques.	Indian Stat Inst, Comp Vis & Pattern Recognit Unit, Calcutta, India	Garain, U (reprint author), Indian Stat Inst, Comp Vis & Pattern Recognit Unit, 203 BT Rd, Calcutta, India.	utpal@isical.ac.in					BAIRD HS, 1993, P 2 INT C DOC AN REC, P593; Barandela R, 2005, INT J PATTERN RECOGN, V19, P787, DOI 10.1142/S0218001405004332; Blake C.L., UCI REPOSITORY MACHI; Box GEP, 1978, STAT EXPT; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; BURNET F, 1959, CLONAL SELECTION THE; Cano JR, 2003, IEEE T EVOLUT COMPUT, V7, P561, DOI 10.1109/TEVC.2003.819265; Carter JH, 2000, J AM MED INFORM ASSN, V7, P28; CHAUDHURI BB, 2003, TISICVPR032003; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasgupta D, 1998, ARTIFICIAL IMMUNE SY, P3; DASGUPTA D, 2003, P 2003 IEEE C EV COM, V3, P123; de Castro L. N., 2002, ARTIFICIAL NEURAL NE, P67; de Castro LN, 2002, IEEE T EVOLUT COMPUT, V6, P239, DOI 10.1109/TEVC.2002.1011539; Devi VS, 2002, PATTERN RECOGN, V35, P505; GARAIN U, 2006, P 18 INT C PATT REC, P1046; Garain U, 2006, LECT NOTES COMPUT SC, V4163, P256; Garain U, 1998, P SOC PHOTO-OPT INS, V3305, P90, DOI 10.1117/12.304622; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Huang D, 2006, NEURAL COMPUT, V18, P470, DOI 10.1162/089976606775093927; JERNE NK, 1974, ANN INST PASTEUR IMM, VC125, P373; Ji Z, 2004, LECT NOTES COMPUT SC, V3102, P287; Kim SW, 2003, PATTERN ANAL APPL, V6, P232, DOI 10.1007/s10044-003-0191-0; KOHONEN T, 1990, P IEEE 1, V78, P464; Li YG, 2005, LECT NOTES COMPUT SC, V3610, P528; Mollineda RA, 2002, PATTERN RECOGN, V35, P2771, DOI 10.1016/S0031-3203(01)00208-4; Paredes R, 2006, PATTERN RECOGN, V39, P180, DOI 10.1016/j.patcog.2005.06.001; PEKALSKA E, 2002, P INT C PATT REC, V3, P37; PERELSON AS, 1979, J THEOR BIOL, V81, P645, DOI 10.1016/0022-5193(79)90275-3; Sanchez JS, 2003, PATTERN RECOGN LETT, V24, P1015, DOI 10.1016/S0167-8655(02)00225-8; Sanchez JS, 2004, PATTERN RECOGN, V37, P1561, DOI 10.1016/j.patcog.2003.12.012; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P507, DOI 10.1016/S0167-8655(97)00035-4; SKALAK DB, 1995, THESIS U MASSACHUSET; SWONGER CW, 1972, FRONTIERS PATTERN RE, P511; Tang Z., 2003, Systems and Computers in Japan, V34, DOI 10.1002/scj.10243; Timmis J., 2001, THESIS U WALES ABERY; Watkins A., 2001, THESIS MISSISSIPPI S; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	39	6	6	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1433-7541		PATTERN ANAL APPL	Pattern Anal. Appl.	SEP	2008	11	3-4					353	363		10.1007/s10044-008-0106-1		11	Computer Science, Artificial Intelligence	Computer Science	339LU	WOS:000258579900011	
J	Chen, CH; Ho, PGP				Chen, Chi Hau; Ho, Pei-Gee Peter			Statistical pattern recognition in remote sensing	PATTERN RECOGNITION			English	Article						remote sensing; statistical pattern classification; contextual information; neural networks; support vector machine; vector 2-D autoregressive; time series; Markov random field	SUPPORT VECTOR MACHINES; MARKOV RANDOM-FIELDS; NEURAL-NETWORKS; HYPERSPECTRAL DATA; CLASSIFICATION; IMAGES; SELECTION; CONTEXT; RESTORATION; ALGORITHM	Remote sensing with sensors mounted on satellites or aircrafts is much needed for resource management, environmental monitoring, disaster response, and homeland defense. Remote sensing data considered include those from multispectral, hyperspectral, radar, optical, and infrared sensors. Classification is often one of the major tasks in information processing. For example, we need to identify vegetations, waterways, and man-made structures from remote sensing of earth. The large amount of data available makes remote sensing data uniquely suitable for statistical pattern recognition. This paper will address several issues on statistical pattern recognition that are related to information processing in remote sensing. Though the paper is largely tutorial in nature, some specific issues considered are image models for characterization of contextual information, neural networks for image classification, and the performance measures. Either to supplement the capability of sensors or to effectively utilize the enormous amount of sensor data, many advances in statistical pattern recognition can be very useful in machine recognition of the data. The potentials and opportunities of using statistical pattern recognition in remote sensing are indeed unlimited. (c) 2008 Elsevier Ltd. All rights reserved.	[Chen, Chi Hau; Ho, Pei-Gee Peter] Univ Massachusetts Dartmouth, Elect & Comp Engn Dept, N Dartmouth, MA 02747 USA	Chen, CH (reprint author), Univ Massachusetts Dartmouth, Elect & Comp Engn Dept, 285 Old Westport Rd, N Dartmouth, MA 02747 USA.	cchen@umassd.edu					BENEDIKTSSON JA, 1999, HDB PATTERN RECOGNIT, P507, DOI 10.1142/9789812384737_0016; Bishop C. M., 2006, PATTERN RECOGNITION; BOVOLO F, 2006, P IGARSS DENV; BRUZZONE L, 2005, FRONTIERS REMOTE SEN, P285; Bruzzone L, 1999, IEEE T GEOSCI REMOTE, V37, P1179, DOI 10.1109/36.752239; Carpenter GA, 1997, IEEE T GEOSCI REMOTE, V35, P308, DOI 10.1109/36.563271; Chang CI, 2006, IEEE T GEOSCI REMOTE, V44, P1575, DOI 10.1109/TGRS.2006.864389; Chen C. H, 2000, P INT GEOSC REM SENS; CHEN CH, 2007, SIGNAL PROCESSING RE; CHEN CH, 1999, INFORMATION PROCESSI, P167; CHEN CH, 2003, FRONTIERS REMOTE SEN, P23, DOI 10.1142/9789812796752_0002; Cheriet M, 2007, CHARACTER RECOGNITION SYSTEMS: A GUIDE FOR STUDENTS AND PRACTIONERS, P1, DOI 10.1002/9780470176535; Chow C.K., 1957, Institute of Radio Engineers Transactions on Electronic Computers, VEC-6; CLAUSI DA, 2007, IEEE T GEOSCI REMOTE, V45; CONGALTON RB, REMOTE SENSING THEMA, P73; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P35; DATTATREYA GR, 1991, PATTERN RECOGN, V24, P685, DOI 10.1016/0031-3203(91)90036-5; Del Frate F, 2007, IEEE T GEOSCI REMOTE, V45, P800, DOI 10.1109/TGRS.2007.892009; Duda R, 2003, PATTERN CLASSIFICATI; Duda R.O., 1972, PATTERN CLASSIFICATI; Duin R. P. W., 2005, HDB PATTERN RECOGNIT, P3, DOI 10.1142/9789812775320_0001; Figueiredo MAT, 1997, IEEE T IMAGE PROCESS, V6, P1089, DOI 10.1109/83.605407; FU KS, 1982, APPL PATTERN RECOGNI, pCH4; FU KS, 1980, STAT PATTERN CLASSIF; Fukunaga K., 1990, INTRO STAT PATTERN R; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; Ghosh S, 2007, IEEE T GEOSCI REMOTE, V45, P778, DOI 10.1109/TGRS.2006.888861; GRABOSWKI S, 2003, FRONTIERS REMOTE SEN, P315, DOI 10.1142/9789812796752_0013; Ham J, 2005, IEEE T GEOSCI REMOTE, V43, P492, DOI 10.1109/TGRS.2004.842481; HEERMANN PD, 1992, IEEE T GEOSCI REMOTE, V30, P81, DOI 10.1109/36.124218; HO P, 2008, THESIS U MASSACHUSET; HSU SM, 2005, HDB PATTERN RECOGNIT, P347, DOI 10.1142/9789812775320_0019; Hyvarinen A., 2001, INDEPENDENT COMPONEN; Jain A.K., 1999, BIOMETRICS PERSONAL; JENG FC, 1991, IEEE T SIGNAL PROCES, V39, P683, DOI 10.1109/78.80887; JEON B, 1992, IEEE T GEOSCI REMOTE, V30, P663, DOI 10.1109/36.158859; Jimenez-Rodriguez LO, 2007, IEEE T GEOSCI REMOTE, V45, P469, DOI 10.1109/TGRS.2006.885412; JOELSSON SR, 2006, SIGNAL IMAGE PROCESS, P327; KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532; KASHYAP RL, 1983, IEEE T INFORM THEORY, V29, P60, DOI 10.1109/TIT.1983.1056610; Kindermann R, 1980, MARKOV RANDOM FIELDS; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kumar S, 2001, IEEE T GEOSCI REMOTE, V39, P1368, DOI 10.1109/36.934070; Kuncheva L., 2004, COMBINING PATTERN CL; Kuo BC, 2007, IEEE T GEOSCI REMOTE, V45, P756, DOI 10.1109/TGRS.2006.885074; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; Landgrebe D.A., 2003, SIGNAL THEORY METHOD; Lee J, 2007, IEEE T GEOSCI REMOTE, V45, P2953, DOI 10.1109/TGRS.2007.900675; LEE JS, 1999, REMOTE SENSING INFOR, P113; LILLESAND TM, 1988, REMOTE SENSING IMAGE; MacQueen J. B., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865; MOSER G, 2005, FRONTIERS REMOTE SEN, P405; NISHII R, 2006, SIGNAL IMAGE PROCESS, P345; PAARZEN E, 1962, ANN MATH STAT, V33, P1065; PETROU M, 1999, INFORM PROCESSING RE, P69; RICHARDS J, 2005, P SOC PHOTO-OPT INS, V5982, P1; RICHARDS J, 2003, FRONTIERS REMOTE SEN, P3, DOI 10.1142/9789812796752_0001; Serpico S. B., 2006, SIGNAL IMAGE PROCESS, P305; SERPICO SB, 1995, IEEE T GEOSCI REMOTE, V33, P562, DOI 10.1109/36.387573; Serpico SB, 2001, IEEE T GEOSCI REMOTE, V39, P1360, DOI 10.1109/36.934069; Smits PC, 2002, IEEE T GEOSCI REMOTE, V40, P801, DOI 10.1109/TGRS.2002.1006354; SOLBERG AHS, 2006, SIGNAL IMAGE PROCESS, P515; TOUSSAINT GT, 1978, PATTERN RECOGN, V10, P189, DOI 10.1016/0031-3203(78)90027-4; Vapnik V, 1998, NATURE STAT LEARNING; Waske B, 2007, IEEE T GEOSCI REMOTE, V45, P3858, DOI 10.1109/TGRS.2007.898446; Webb A. R., 2003, STAT PATTERN RECOGNI; WELCH JR, 1971, IEEE T SYST MAN CYB, VSMC1, P24; WHARTON SW, 1982, PATTERN RECOGN, V15, P317, DOI 10.1016/0031-3203(82)90034-6; Wilkinson GG, 2005, IEEE T GEOSCI REMOTE, V43, P433, DOI 10.1109/TGRS.2004.837325; YOSHIOKA M, 2006, SIGNAL IMAGE PROCESS, P607; Zhang B, 2008, IEEE T GEOSCI REMOTE, V46, P159, DOI 10.1109/TGRS.2007.907972; ZHANG X, 2004, J VLSI SIGNAL PROCES, V37	74	29	32	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	SEP	2008	41	9					2731	2741		10.1016/j.patcog.2008.04.013		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	325HW	WOS:000257581000001	
J	Espana, GM; Florez, JM; Torres, HV				Espana, German Morales; Florez, Juan Mora; Torres, Hermann Vargas			k-NN based regression strategy used to estimate the fault distance in radial power systems	REVISTA FACULTAD DE INGENIERIA-UNIVERSIDAD DE ANTIOQUIA			Spanish	Article						faults location; k nearest neighbors (k-NN); radial systems; regression	LOCATION ALGORITHM	A regression strategy based on k nearest neighbors (k-NN) to estimate the fault distance in radial power systems is proposed. This fault location approach uses measurements of the fundamental components of voltage and current measured at the power substation. In addition, the approach is not constrained by the power system modeling and it is easily adaptable to the special characteristics of radial systems. The proposed fault locator is tested in a power distribution system and the obtained mean error is lower than 3%, by considering all fault types, several faulted nodes and fault resistances.	[Florez, Juan Mora] Univ Tecnol Pereira, Program Ingn Elect, GISEL, La Julita, Pereira, Colombia; Univ Tecnol Pereira, Program Ingn Elect, ICE3, La Julita, Pereira, Colombia	Florez, JM (reprint author), Univ Tecnol Pereira, Program Ingn Elect, GISEL, La Julita, Pereira, Colombia.	jjmora@utp.edu.co					Aggarwal RK, 1997, IEE P-GENER TRANSM D, V144, P309, DOI 10.1049/ip-gtd:19971137; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Choi MS, 2004, IEEE T POWER DELIVER, V19, P35, DOI 10.1109/TPWRD.2003.820433; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dagenhart J, 2000, IEEE T IND APPL, V36, P30, DOI 10.1109/28.821792; DAS R, 1998, THESIS U SASKATCHEWA, P16; Girgis A., 1993, IEEE T IND APPL, V26, P1170; Mora-Florez J, 2007, IEEE T POWER DELIVER, V22, P1715, DOI 10.1109/TPWRD.2006.883021; MORALES G, 2005, THESIS U IND SANTAND; MORALES G, 2007, P 12 ENC REG IB CIGR, P52; Morales G., 2006, REV INGENIERIA, V11, P43; MORENO F, 2004, THESIS U ALICANTE, P56; SRINIVASAN K, 1989, IEEE T POWER DELIVER, V4, P1676, DOI 10.1109/61.32658; WARRINGTON A, 1968, PROTECTIVE RELAYS TH, P125; Zhu J, 1997, IEEE T POWER DELIVER, V12, P801; *IEEE, 2004, 37114 IEEE	16	0	0	IMPRENTA UNIV ANTIOQUIA	MEDELLIN	67 N 53-108, BLOQUE 28, CIUDAD UNIV, UNIV ANTIQUIA, MEDELLIN, 00000, COLOMBIA	0120-6230		REV FAC ING-UNIV ANT	Rev. Fac. Ing.-Univ. Antioquia	SEP	2008		45					100	108				9	Engineering, Multidisciplinary	Engineering	330BO	WOS:000257914500010	
J	Liu, HC; Chen, CY; Liu, YT; Chu, CB; Liang, DC; Shih, LY; Lin, CJ				Liu, Hsi-Che; Chen, Chien-Yu; Liu, Yu-Ting; Chu, Cheng-Bang; Liang, Der-Cherng; Shih, Lee-Yung; Lin, Chih-Jen			Cross-generation and cross-laboratory predictions of Affymetrix microarrays by rank-based methods	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						affymetrix microarrays; cross-generation/laboratory prediction; rank-based normalization	GENE-EXPRESSION PROFILES; ACUTE LYMPHOBLASTIC-LEUKEMIA; BREAST-CANCER; MARKER GENES; CLASSIFICATION; OLIGONUCLEOTIDE; PLATFORMS; REPRODUCIBILITY; NORMALIZATION; INFORMATION	Past experiments of the popular Affymetrix (Affy) microarrays have accumulated a huge amount of public data sets. To apply them for more wide studies, the comparability across generations and experimental environments is an important research topic. This paper particularly investigates the issue of cross-generation/laboratory predictions. That is, whether models built upon data of one generation (laboratory) can differentiate data of another. We consider eight public sets of three cancers. They are from different laboratories and are across various generations of Affy human microarrays. Each cancer has certain subtypes, and we investigate if a model trained from one set correctly differentiates another. We propose a simple rank-based approach to make data from different sources more comparable. Results show that it leads to higher prediction accuracy than using expression values. We further investigate normalization issues in preparing training/testing data. In addition, we discuss some pitfalls in evaluating cross-generation/laboratory predictions. To use data from various sources one must be cautious on some important but easily neglected steps. (C) 2007 Elsevier Inc. All rights reserved.	[Chen, Chien-Yu] Natl Taiwan Univ, Dept Bioind Mechatron Engn, Taipei 106, Taiwan; [Liu, Hsi-Che; Liang, Der-Cherng] Mackay Mem Hosp, Dept Pediat, Taipei, Taiwan; [Liu, Yu-Ting; Chu, Cheng-Bang] Yuan Univ, Grad Sch Biotechnol & Bioinformat, Chungli, Taiwan; [Shih, Lee-Yung] Chang Gung Univ, Div Hematol Oncol, Tao Yuan, Taiwan; [Lin, Chih-Jen] Natl Taiwan Univ, Dept Comp Sci, Taipei 10764, Taiwan; [Liu, Hsi-Che] Mackay Med Nursing & Management Coll, Taipei, Taiwan; [Liu, Hsi-Che] Taipei Med Univ, Sch Med, Taipei, Taiwan	Chen, CY (reprint author), Natl Taiwan Univ, Dept Bioind Mechatron Engn, 1 Roosevelt Rd,Sec 4, Taipei 106, Taiwan.	hsiche@msl.mmh.org.tw; cychen@mars.csie.ntu.edu.tw; s938611@mail.yzu.edu.tw; s938613@mail.yzu.edu.tw; dcliang@ms2.mmh.org.tw; sly70l2@adm.cgmh.org.tw; cjlin@csie.ntu.edu.tw					Bammler T, 2005, NAT METHODS, V2, P351; BHATTACHARYA S, 2005, NUCLEIC ACIDS RES, V33, pEL57; Bloom G, 2004, AM J PATHOL, V164, P9, DOI 10.1016/S0002-9440(10)63090-8; Bolstad BM, 2003, BIOINFORMATICS, V19, P185, DOI 10.1093/bioinformatics/19.2.185; Brazma A, 2001, NAT GENET, V29, P365, DOI 10.1038/ng1201-365; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; ELO LL, 2005, NUCLEIC ACIDS RES, V33, pEL93; GEMAN D, 2004, STAT APPL GENET MOL, V3; Gutierrez N. C., 2005, Leukemia (Basingstoke), V19, P402, DOI 10.1038/sj.leu.2403625; Huang E, 2003, LANCET, V361, P1590, DOI 10.1016/S0140-6736(03)13308-9; Hwang KB, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-159; Irizarry RA, 2005, NAT METHODS, V2, P345, DOI 10.1038/nmeth756; Jiang HY, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-81; Kong SW, 2005, BIOINFORMATICS, V21, P2116, DOI 10.1093/bioinformatics/bti288; Kuo WP, 2002, BIOINFORMATICS, V18, P405, DOI 10.1093/bioinformatics/18.3.405; Larkin JE, 2005, NAT METHODS, V2, P337, DOI 10.1038/nmeth757; Maglott D, 2005, NUCLEIC ACIDS RES, V33, pD54, DOI 10.1093/nar/gki031; Mah N, 2004, PHYSIOL GENOMICS, V16, P361, DOI 10.1152/physiolgenomics.00080.2003; Nimgaonkar A, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-27; PONTIUS JU, 2003, NCBI HDB; Qiu X, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-120; R Development Core Team, 2005, R LANG ENV STAT COMP; Rhodes DR, 2004, P NATL ACAD SCI USA, V101, P9309, DOI 10.1073/pnas.0401994101; Ross ME, 2004, BLOOD, V104, P3679, DOI 10.1182/blood-2004-03-1154; Ross ME, 2003, BLOOD, V102, P2951, DOI 10.1182/blood-2003-01-0338; Szabo A, 2002, MATH BIOSCI, V176, P71, DOI 10.1016/S0025-5564(01)00103-1; Tan AC, 2005, BIOINFORMATICS, V21, P3896, DOI 10.1093/bioinformatics/bti631; TODLING J, 2003, ASSESSMENT 5 MICROAR; Tothill RW, 2005, CANCER RES, V65, P4031, DOI 10.1158/0008-5472.CAN-04-3617; TSODIKOV A, 2002, BIOINFORMATICS, V18, P260; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Valk PJM, 2004, NEW ENGL J MED, V350, P1617, DOI 10.1056/NEJMoa040465; Wang YX, 2005, LANCET, V365, P671, DOI 10.1016/S0140-6736(05)17947-1; Warnat P, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-265; West M, 2001, P NATL ACAD SCI USA, V98, P11462, DOI 10.1073/pnas.201162998; Xu L, 2005, BIOINFORMATICS, V21, P3905, DOI 10.1093/bioinformatics/bti647; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6; *AFF, 2003, US GUID PROD COMP SP	38	11	11	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464		J BIOMED INFORM	J. Biomed. Inform.	AUG	2008	41	4					570	579		10.1016/j.jbi.2007.11.005		10	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	330FE	WOS:000257924400006	
J	Rizzi, A; Fioni, A				Rizzi, Andrea; Fioni, Alessandro			Virtual screening using PLS discriminant analysis and ROC curve approach: An application study on PDE4 inhibitors	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							DOCKING; CLASSIFICATION; PREDICTION; DRUGS; SIMILARITY; DATABASE; DESIGN	Virtual screening (VS) represents an important tool for the drug discovery process, in particular for the hit generation phase. Classifiers are often inserted as filters at the beginning of a VS path, and in the present paper the performances of several PLS-DA classifiers (QikProp, Dragon, EVA descriptors) are evaluated in the effort to distinguish PDE4 inhibitors from other druglike molecules. As benchmark also docking scores and the fitness to pharmacophore hypotheses were used to perform the same task, checking in this way if docking or 3D search can be anticipated in the VS process. The visual analysis of the Receiver Operating Characteristic (ROC) curve was useful to have an overall picture of the classification and to select the right threshold that marks the boundary between active and inactive classes. The best classification was obtained by a model based on the Dragon descriptors that are calculated from the molecular 2D structure. Its performance was good for the training set in terms of recall, enrichment factor, and area under the ROC curve and was confirmed in the prediction of the test set.	[Rizzi, Andrea; Fioni, Alessandro] Chiesi Farmaceut, Chem Synth Dept, I-43100 Parma, Italy	Rizzi, A (reprint author), Chiesi Farmaceut, Chem Synth Dept, Via San Leonardo 96, I-43100 Parma, Italy.	a.rizzi@chiesigroup.com					Adenot M, 2004, J CHEM INF COMP SCI, V44, P239, DOI 10.1021/ci034205d; Baurin N, 2004, J CHEM INF COMP SCI, V44, P643, DOI 10.1021/ci034260m; Burnouf C, 2002, CURR PHARM DESIGN, V8, P1255, DOI 10.2174/1381612023394665; Card GL, 2004, STRUCTURE, V12, P2233, DOI 10.1016/j.str.2004.10.004; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dal P., 2000, EUR J MED CHEM, V35, P463; Evers A, 2005, J MED CHEM, V48, P5448, DOI 10.1021/jm050090o; Irwin JJ, 2005, J CHEM INF MODEL, V45, P177, DOI 10.1021/ci049714+; Jacobsson M, 2003, J MED CHEM, V46, P5781, DOI 10.1021/jm030896t; Jorgensen WL, 2002, ADV DRUG DELIVER REV, V54, P355, DOI 10.1016/S0169-409X(02)00008-X; Leach AR, 2006, J MED CHEM, V49, P5851, DOI 10.1021/jm060999m; Li QL, 2007, J CHEM INF MODEL, V47, P1776, DOI 10.1021/ci700107y; Mason JS, 1999, J MED CHEM, V42, P3251, DOI 10.1021/jm9806998; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; Pearlman DA, 2001, J MED CHEM, V44, P502, DOI 10.1021/jm000375v; Pirard B, 2000, J CHEM INF COMP SCI, V40, P1431, DOI 10.1021/ci000386x; Plewczynski D, 2006, J CHEM INF MODEL, V46, P1098, DOI 10.1021/ci050519k; Rella M, 2006, J CHEM INF MODEL, V46, P708, DOI 10.1021/ci0503614; Schneider G, 2002, DRUG DISCOV TODAY, V7, P64, DOI 10.1016/S1359-6446(02)00004-1; Sirois S, 2004, J CHEM INF COMP SCI, V44, P1111, DOI 10.1021/ci034270n; Ståhle L, 1988, Prog Med Chem, V25, P291, DOI 10.1016/S0079-6468(08)70281-9; Sun HM, 2004, J CHEM INF COMP SCI, V44, P748, DOI 10.1021/ci030304f; SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615; Triballeau N, 2005, J MED CHEM, V48, P2534, DOI 10.1021/jm049092j; Turner DB, 1997, J COMPUT AID MOL DES, V11, P409, DOI 10.1023/A:1007988708826; Vandeginste B. G. M., 1997, HDB CHEMOMETRICS QUA; Vapnik V.N., 1995, NATURE STAT LEARNING; Vigers GPA, 2004, J MED CHEM, V47, P80, DOI 10.1021/jm030161o; Walters WP, 1998, DRUG DISCOV TODAY, V3, P160, DOI 10.1016/S1359-6446(97)01163-X; Wang RX, 2003, J MED CHEM, V46, P2287, DOI 10.1021/jm0203783; Wold S., 1993, 3D QSAR DRUG DESIGN, P523; Xue L, 2004, J CHEM INF COMP SCI, V44, P1275, DOI 10.1021/ci040120g; Zupan J., 1999, NEURAL NETWORKS CHEM; *MDL INF SYST INC, 2005, MDL DRUG DAT REP MDD; *SCHR LLC, 2005, GLID VERS 3 5; *SCHR LLC, 2005, QIKPROP VERS 2 1; *SCHR LLC, 2005, PHASS VERS 1 0; *TAL, 2005, DRAGON PLUS VERS 5 4; *UM AB, 2005, SIMCA P VERS 10 0; *WAV INC, 2003, SPART 02 LIN UN; 2005, SCHRODINGER QIKPROP	41	7	9	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596		J CHEM INF MODEL	J. Chem Inf. Model.	AUG	2008	48	8					1686	1692		10.1021/ci800072r		7	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	341EQ	WOS:000258697400014	
J	Cho, KH; Lee, J				Cho, Kwang-Hwi; Lee, Julian			Protein structure prediction using a hybrid energy function and an exact enumeration	JOURNAL OF THE KOREAN PHYSICAL SOCIETY			English	Article						protein folding; protein structure prediction; fragment assembly method; exact enumeration; hybrid energy function	NEAREST-NEIGHBOR METHOD; DOUBLE OPTIMIZATION; SEQUENCES	We develop a protein structure prediction method that utilizes fragment assembly and a hybrid energy function. In a fragment assembly method, the local structure of the backbone is obtained from a structural database by using similarity of sequence features, in contrast to a pure physics-based method in which all dihedral angles are allowed to vary continuously. Since the conformational space for the backbone is finite, we generate all possible conformations and vary only the side-chain dihedral angles for each of them. The conformations are scored using a hybrid energy function, where all the backbone atoms are described explicitly, but the side chain is modeled as a few interaction centers. We perform a test prediction on four proteins, 112y, 1e01, 1bdd and 1bk2, to demonstrate the feasibility of protein structure prediction based on exact enumeration.	Soongsil Univ, Dept Bioinformat & Life Sci, Seoul 156743, South Korea; Soongsil Univ, Bioinformat & Mol Design Res Ctr, Seoul 156743, South Korea	Lee, J (reprint author), Soongsil Univ, Dept Bioinformat & Life Sci, Seoul 156743, South Korea.	jul@ssu.ac.kr			Basic Research Program of the Korea Science & Engineering Foundation [R01-2003-000-10199-0]; Soongsil University Research Fund	This work was supported by grant R01-2003-000-10199-0 from the Basic Research Program of the Korea Science & Engineering Foundation and by the Soongsil University Research Fund.	Aloy P, 2003, PROTEINS, V53, P436, DOI 10.1002/prot.10546; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; ANFINSEN CB, 1973, SCIENCE, V181, P223, DOI 10.1126/science.181.4096.223; Brenner SE, 2000, NUCLEIC ACIDS RES, V28, P254, DOI 10.1093/nar/28.1.254; Chikenji G, 2003, J CHEM PHYS, V119, P6895, DOI 10.1063/1.1597474; CHO KH, SIMPLIFIED POT UNPUB; Cho KH, 2008, J KOREAN PHYS SOC, V52, P143; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; JONES DT, 2001, PROTEINS S5, V45, P127, DOI 10.1002/prot.1171; Joo K, 2004, J KOREAN PHYS SOC, V44, P599; Joo K, 2004, J KOREAN PHYS SOC, V45, P1441; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Kim SY, 2006, J CHEM PHYS, V125, DOI 10.1063/1.2364500; Kim SY, 2006, LECT NOTES COMPUT SC, V4115, P562; Kim TK, 2008, J KOREAN PHYS SOC, V52, P137; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Koradi R, 1996, J MOL GRAPHICS, V14, P51, DOI 10.1016/0263-7855(96)00009-4; Lee J, 2005, J KOREAN PHYS SOC, V46, P707; Lee J, 2008, PROTEINS, V70, P1074, DOI 10.1002/prot.21844; LEST AM, 2001, PROTEINS, V45, P98; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; MOMANY FA, 1975, J PHYS CHEM-US, V79, P2361, DOI 10.1021/j100589a006; Shi XL, 2007, J KOREAN PHYS SOC, V50, P118; Sim J, 2005, BIOINFORMATICS, V21, P2844, DOI 10.1093/bioinformatics/bti423; Simons KT, 1997, J MOL BIOL, V268, P209, DOI 10.1006/jmbi.1997.0959; Vincent JJ, 2005, PROTEINS, V61, P67, DOI 10.1002/prot.20722; Xiang ZX, 2002, P NATL ACAD SCI USA, V99, P7432, DOI 10.1073/pnas.102179699	27	2	2	KOREAN PHYSICAL SOC	SEOUL	635-4, YUKSAM-DONG, KANGNAM-KU, SEOUL 135-703, SOUTH KOREA	0374-4884		J KOREAN PHYS SOC	J. Korean Phys. Soc.	AUG	2008	53	2					873	879				7	Physics, Multidisciplinary	Physics	338CA	WOS:000258481300072	
J	Kietzmann, TC; Lange, S; Riedmiller, M				Kietzmann, Tim C.; Lange, Sascha; Riedmiller, Martin			Incremental GRLVQ: Learning relevant features for 3D object recognition	NEUROCOMPUTING			English	Article						object recognition; relevance learning; feature selection; incremental learning vector quantization; adaptive metric	CLASSIFICATION; INTERPOLATION; RETRIEVAL; SELECTION; NETWORK; FACES	We present a new variant of generalized relevance learning vector quantization (GRLVQ) in a computer vision scenario. A version with incrementally added prototypes is used for the non-trivial case of high-dimensional object recognition. Training is based upon a generic set of standard visual features, the learned input weights are used for iterative feature pruning. Thus, prototypes and input space are altered simultaneously, leading to very sparse and task-specific representations. The effectiveness of the approach and the combination of the incremental variant together with pruning was tested on the COIL100 database, It exhibits excellent performance with regard to codebook size, feature selection and recognition accuracy. (C) 2007 Elsevier B.V. All rights reserved.	[Kietzmann, Tim C.; Lange, Sascha; Riedmiller, Martin] Univ Osnabruck, Inst Cognit Sci, Inst Comp Sci, D-49069 Osnabruck, Germany	Kietzmann, TC (reprint author), Univ Osnabruck, Inst Cognit Sci, Inst Comp Sci, D-49069 Osnabruck, Germany.	tkietzma@uos.de; salange@uos.de; martin.riedmiller@uos.de					ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913; Bishop C. M., 1995, NEURAL NETWORKS PATT; BOJER T, 2003, EUR S ART NEUR NETW, P433; BULTHOFF HH, 1992, P NATL ACAD SCI USA, V89, P60, DOI 10.1073/pnas.89.1.60; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Favata JT, 1996, INT J IMAG SYST TECH, V7, P304, DOI 10.1002/(SICI)1098-1098(199624)7:4<304::AID-IMA5>3.0.CO;2-C; FRITZKE B, 1994, NEURAL NETWORKS, V7, P1441, DOI 10.1016/0893-6080(94)90091-4; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hammer B, 2001, ADVANCES IN SELF-ORGANISING MAPS, P173; Hammer B, 2005, NEURAL PROCESS LETT, V21, P21, DOI 10.1007/s11063-004-3255-2; Hammer B, 2002, NEURAL NETWORKS, V15, P1059, DOI 10.1016/S0893-6080(02)00079-5; HAMMER B, 2005, BIOINFORMATIC USING, P25; HAMMER B, 2002, INT C ART NEUR NETW; Heidemann G., 2000, Proceedings 15th International Conference on Pattern Recognition. ICPR-2000, DOI 10.1109/ICPR.2000.905265; HU M, 1962, IRE T INFORM THEOR, V8, P179; John G. H., 1994, P 11 INT C MACH LEAR, P121; Jolliffe I. T., 1986, PRINCIPLE COMPONENT; Jolliffe I. T., 2002, PRINCIPAL COMPONENT; Kira K., 1992, P 10 NAT C ART INT, P129; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; KIRSTEIN S, 2005, 27 PATT REC S DAGM, P301; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Koller D., 1996, INT C MACH LEARN; Kononenko I., 1994, EUR C MACH LEARN, P171; KORN F, 1996, FAST NEAREST NEIGHBO; KRZANOWSKI WJ, 1987, APPL STAT-J ROY ST C, V36, P22, DOI 10.2307/2347842; Le Cun Y, 1990, ADV NEURAL INFORMATI, V2, P598; Lehmann TM, 2005, COMPUT MED IMAG GRAP, V29, P143, DOI 10.1016/j.compmedimag.2004.09.010; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.415; MCCABE GP, 1984, TECHNOMETRICS, V26, P127; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Neal R.M., 1996, BAYESIAN LEARNING NE; Nene SA, 1996, CUCS00696; OBDRZLEK S, 2002, BMVC, P113; Peng J, 1999, COMPUT VIS IMAGE UND, V75, P150, DOI 10.1006/cviu.1999.0770; PERRETT DI, 1987, TRENDS NEUROSCI, V10, P358, DOI 10.1016/0166-2236(87)90071-3; POGGIO T, 1990, NATURE, V343, P263, DOI 10.1038/343263a0; QI YA, 2004, ACM INT C P SERIES; Roobaert D., 1999, NEURAL NETWORKS SIGN, VIX, P77; Sato A.S., 1995, ADV NEURAL INFORMATI, P423; SCHNEIDER G, 2004, 3 WORKSH SELFORGANIZ, P104; Shokoufandeh A, 1999, IMAGE VISION COMPUT, V17, P445, DOI 10.1016/S0262-8856(98)00124-3; SIMS K, 1993, P 8 SCIA THROMS NORW; Strickert M, 2001, LECT NOTES COMPUT SC, V2130, P677; TARR MJ, 1995, J EXP PSYCHOL HUMAN, V21, P1494, DOI 10.1037//0096-1523.21.6.1494; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Toussaint G, 2005, INT J COMPUT GEOM AP, V15, P101, DOI 10.1142/S0218195905001622; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Warfield S, 1996, PATTERN RECOGN LETT, V17, P713, DOI 10.1016/0167-8655(96)00036-0; WU P, 2001, P ACM MULT 01 ACM MU, P89; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430	51	9	9	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	AUG	2008	71	13-15					2868	2879		10.1016/j.neucom.2007.08.018		12	Computer Science, Artificial Intelligence	Computer Science	347DP	WOS:000259121100047	
J	Farcomeni, A				Farcomeni, Alessio			A review of modern multiple hypothesis testing, with particular attention to the false discovery proportion	STATISTICAL METHODS IN MEDICAL RESEARCH			English	Review							QUANTITATIVE TRAIT LOCI; TRUE NULL HYPOTHESES; END-POINTS; CLINICAL-TRIALS; P-VALUES; TEST STATISTICS; PROBABILITY-INEQUALITIES; BONFERRONI PROCEDURE; MICROARRAY ANALYSIS; VARIABLE SELECTION	In the last decade a growing amount Of statistical research has been devoted to multiple testing, motivated by a variety of applications in medicine, bioinformatics, genomics, brain imaging, etc. Research in this area is focused on developing powerful procedures even when the number of tests is very large. This paper attempts to review research in modern multiple hypothesis testing with particular attention to the false discovery proportion, loosely defined as the number of false rejections divided by the number of rejections. We review the main ideas, stepwise and augmentation procedures; and resampling based testing. We also discuss the problem of dependence among the test statistics. Simulations make a comparison between the procedures and with Bayesian methods. We illustrate the procedures in applications in DNA microarray data analysis. Finally, few possibilities for further research are highlighted.	Univ Roma La Sapienza, I-00185 Rome, Italy	Farcomeni, A (reprint author), Univ Roma La Sapienza, Plazzale Aldo Moro 5, I-00185 Rome, Italy.	alessio.farcomeni@uniroma1.it					Abramovich F, 2006, ANN STAT, V34, P584, DOI 10.1214/009053606000000074; Abramovich F, 1996, COMPUT STAT DATA AN, V22, P351, DOI 10.1016/0167-9473(96)00003-5; AHMED SW, 1991, 1991 ASA P SURV RES, P344; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Amaratunga D, 2004, EXPLORATION ANAL DNA; Bayarri MJ, 2004, STAT SCI, V19, P58, DOI 10.1214/088342304000000116; Bayarri MJ, 2000, J AM STAT ASSOC, V95, P1127, DOI 10.2307/2669749; Benjamini Y, 2000, J EDUC BEHAV STAT, V25, P60, DOI 10.2307/1165312; Benjamini Y, 1997, SCAND J STAT, V24, P407, DOI 10.1111/1467-9469.00072; Benjamini Y, 2006, BIOMETRIKA, V93, P491, DOI 10.1093/biomet/93.3.491; Benjamini Y, 2001, ANN STAT, V29, P1165; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Benjamini Y, 1999, J STAT PLAN INFER, V82, P163, DOI 10.1016/S0378-3758(99)00040-3; Berger JO, 1997, STAT SCI, V12, P133; Bernardo J. M., 1994, BAYESIAN THEORY; Berry D.A., 1988, BAYESIAN STATISTICS, P79; Berry DA, 1999, J STAT PLAN INFER, V82, P215, DOI 10.1016/S0378-3758(99)00044-0; BICKEL DR, 2004, STRONG CONTROL CONSE; Bolsover S., 1997, GENES CELLS; Bovenhuis H, 2000, J DAIRY SCI, V83, P173; Brown PO, 1999, NAT GENET, V21, P33, DOI 10.1038/4462; CABRAS S, 2004, CONTROL FALSE DISCOV; Chi GYH, 1998, DRUG INF J, V32, p1347S; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DIACONIS P, 1985, EXPLORING DATA TABLE; Drigalenko EI, 1997, GENET EPIDEMIOL, V14, P779, DOI 10.1002/(SICI)1098-2272(1997)14:6<779::AID-GEPI36>3.0.CO;2-L; Dudoit S, 2003, STAT SCI, V18, P71, DOI 10.1214/ss/1056397487; DUDOIT S, 2004, STAT APPL GENETICS M, V3; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Duggan DJ, 1999, NAT GENET, V21, P10, DOI 10.1038/4434; DUNCAN DB, 1965, TECHNOMETRICS, V7, P171, DOI 10.2307/1266670; DUNNETT CW, 1992, J AM STAT ASSOC, V87, P162, DOI 10.2307/2290465; Durbin BP, 2004, BIOINFORMATICS, V20, P660, DOI 10.1093/bioinformatics/btg464; Efron B., 1993, INTRO BOOTSTRAP; Efron B, 2001, J AM STAT ASSOC, V96, P1151, DOI 10.1198/016214501753382129; Efron B, 2002, GENET EPIDEMIOL, V23, P70, DOI 10.1002/gepi.01124; Ellis SP, 2000, PSYCHIAT RES-NEUROIM, V99, P111, DOI 10.1016/S0925-4927(00)00051-2; ESARY JD, 1967, ANN MATH STAT, V38, P1466, DOI 10.1214/aoms/1177698701; FARCOMENI A, 2006, STAT METHOD APPL, V15, P43, DOI 10.1007/s10260-006-0002-z; Farcomeni A, 2007, SCAND J STAT, V34, P275, DOI 10.1111/j.1467-9469.2006.00530.x; Ferreira JA, 2006, ANN STAT, V34, P1827, DOI 10.1214/009053606000000425; Finner H, 1998, ANN STAT, V26, P505; Finner H, 2002, ANN STAT, V30, P220; Finner H, 1999, ANN STAT, V27, P274, DOI 10.1214/aos/1018031111; FOLLMANN D, 1995, STAT MED, V14, P1163, DOI 10.1002/sim.4780141103; GARRET RH, 2002, PRINCIPLES BYOCHEMIS; Ge YC, 2003, TEST, V12, P1, DOI 10.1007/BF02595811; Genovese C, 2004, ANN STAT, V32, P1035, DOI 10.1214/009053604000000283; Genovese C, 2002, J ROY STAT SOC B, V64, P499, DOI 10.1111/1467-9868.00347; Genovese CR, 2006, J AM STAT ASSOC, V101, P1408, DOI 10.1198/016214506000000339; Genovese CR, 2006, BIOMETRIKA, V93, P509, DOI 10.1093/biomet/93.3.509; George EI, 2000, BIOMETRIKA, V87, P731, DOI 10.1093/biomet/87.4.731; George EI, 2000, J AM STAT ASSOC, V95, P1304, DOI 10.2307/2669776; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Green P. J., 1994, NONPARAMETRIC REGRES; Greening L, 1997, ADOLESCENCE, V32, P51; Heyen DW, 1999, PHYSIOL GENOMICS, V1, P165; HOCHBERG Y, 1988, BIOMETRIKA, V75, P800, DOI 10.2307/2336325; Hochberg Y., 1987, MULTIPLE COMP PROCED; HOLM S, 1979, SCAND J STAT, V6, P65; Hommel G., 1983, BIOMETR J, V25, P423; Ip EH, 2001, PSYCHOMETRIKA, V66, P109, DOI 10.1007/BF02295736; Jeffreys H., 1961, THEORY PROBABILITY; JOGDEO K, 1977, ANN STAT, V5, P495, DOI 10.1214/aos/1176343846; KASS RE, 1995, J AM STAT ASSOC, V90, P928, DOI 10.2307/2291327; Kaufman L., 1990, FINDING GROUPS DATA; Khatri P, 2001, ANN THORAC SURG, V71, P110, DOI 10.1016/S0003-4975(00)02350-X; Langaas M, 2005, J ROY STAT SOC B, V67, P555, DOI 10.1111/j.1467-9868.2005.00515.x; Lauter J, 1996, BIOMETRICS, V52, P964, DOI 10.2307/2533057; LEHMACHER W, 1991, BIOMETRICS, V47, P511, DOI 10.2307/2532142; Lehmann EL, 2005, ANN STAT, V33, P1138, DOI 10.1214/009053605000000084; LEIBERMANN B, 1971, CONT PROBLEMS STAT; Logan BR, 2004, NEUROIMAGE, V22, P95, DOI 10.1016/j.neuroimage.2003.12.047; Meinert CL, 1986, CLIN TRIALS DESIGN C; Meinshausen N, 2006, ANN STAT, V34, P373, DOI 10.1214/009053605000000741; Merriam EP, 2003, NEURON, V39, P361, DOI 10.1016/S0896-6273(03)00393-3; Miller CJ, 2001, ASTRON J, V122, P3492, DOI 10.1086/324109; Miller RG, 1981, SIMULTANEOUS STAT IN; Mosig MO, 2001, GENETICS, V157, P1683; Moye LA, 1998, ANN EPIDEMIOL, V8, P351, DOI 10.1016/S1047-2797(98)00003-9; Moye LA, 2000, STAT MED, V19, P767, DOI 10.1002/(SICI)1097-0258(20000330)19:6<767::AID-SIM518>3.0.CO;2-U; Muller P, 2004, J AM STAT ASSOC, V99, P990, DOI 10.1198/016214504000001646; NEUHAUS KL, 1992, J AM COLL CARDIOL, V19, P885; OBRIEN PC, 1984, BIOMETRICS, V40, P1079, DOI 10.2307/2531158; OBRIEN PC, 1995, BIOMETRICS, V51, P1580; Ottenbacher KJ, 1998, AM J EPIDEMIOL, V147, P615; Owen AB, 2005, J ROY STAT SOC B, V67, P411, DOI 10.1111/j.1467-9868.2005.00509.x; Parmigiani G., 2003, ANAL GENE EXPRESSION; Pacifico MP, 2004, J AM STAT ASSOC, V99, P1002, DOI 10.1198/0162145000001655; Pesarin F, 2001, MULTIVARIATE PERMUTA; POCOCK SJ, 1987, BIOMETRICS, V43, P487, DOI 10.2307/2531989; Pocock SJ, 1997, CONTROL CLIN TRIALS, V18, P530, DOI 10.1016/S0197-2456(97)00008-1; Pollard KS, 2004, J STAT PLAN INFER, V125, P85, DOI 10.1016/j.jspi.2003.07.019; R Development Core Team, 2004, R LANG ENV STAT COMP; Reiner A, 2003, BIOINFORMATICS, V19, P368, DOI 10.1093/bioinformatics/btf877; Robert C.P., 1999, MONTE CARLO STAT MET; Sarkar SK, 2002, ANN STAT, V30, P239, DOI 10.1214/aos/1015362192; Sarkar SK, 1998, ANN STAT, V26, P494; Sarkar SK, 1997, J AM STAT ASSOC, V92, P1601, DOI 10.2307/2965431; SARKAR SK, 2005, STEPUP PROCEDURES CO; Sarkar SK, 2004, J STAT PLAN INFER, V125, P119, DOI 10.1016/j.jspi.2003.06.019; Schaffer CM, 1998, J MARKET RES SOC, V40, P155; Schervish MJ, 1996, AM STAT, V50, P203, DOI 10.2307/2684655; Schlaeppi M, 1996, BRIT J CLIN PRACT, V50, P14; SCHWEDER T, 1982, BIOMETRIKA, V69, P493; Scott JG, 2006, J STAT PLAN INFER, V136, P2144, DOI 10.1016/j.jspi.2005.08.031; Sebastiani P, 2003, STAT SCI, V18, P33, DOI 10.1214/ss/1056397486; SEEGER P, 1968, TECHNOMETRICS, V10, P586, DOI 10.2307/1267112; SENETA E, 1997, THEORY STOCHASTIC PR, V3, P393; Seneta E, 2005, INT STAT REV, V73, P1; Shaffer JP, 2002, PSYCHOL METHODS, V7, P356, DOI 10.1037//1082-989X.7.3.356; SHAFFER JP, 1995, ANNU REV PSYCHOL, V46, P561, DOI 10.1146/annurev.psych.46.1.561; Shaffer JP, 1999, J STAT PLAN INFER, V82, P197, DOI 10.1016/S0378-3758(99)00042-7; SIDAK Z, 1971, ANN MATH STAT, V42, P169, DOI 10.1214/aoms/1177693504; SIDAK Z, 1967, J AM STAT ASSOC, V62, P626, DOI 10.2307/2283989; SIMES RJ, 1986, BIOMETRIKA, V73, P751, DOI 10.1093/biomet/73.3.751; Storey J. D., 2001, ESTIMATING FALSE DIS; Storey JD, 2002, J ROY STAT SOC B, V64, P479, DOI 10.1111/1467-9868.00346; Storey JD, 2003, ANN STAT, V31, P2013, DOI 10.1214/aos/1074290335; Storey JD, 2004, J ROY STAT SOC B, V66, P187, DOI 10.1111/j.1467-9868.2004.00439.x; Storey JD, 2003, P NATL ACAD SCI USA, V100, P9440, DOI 10.1073/pnas.1530509100; Swanepoel JWH, 1999, ANN STAT, V27, P24, DOI 10.1214/aos/1018031099; Troendle JF, 2004, AM STAT, V58, P25, DOI 10.1198/0003130042845; Tseng GC, 2001, NUCLEIC ACIDS RES, V29, P2549, DOI 10.1093/nar/29.12.2549; Turkheimer FE, 2001, NEUROIMAGE, V13, P920, DOI 10.1006/nimg.2001.0764; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; van der Laan M.J., 2004, STAT APPL GENETICS M, V3; VANDERLAAN MJ, 2000, BIOSTATISTICS, V1, P1; VANDERLAAN MJ, 2005, STAT APPL GENETICS M, V4; Vedantham K, 2001, CAN J PSYCHIAT, V46, P149; WEI LJ, 1989, J AM STAT ASSOC, V84, P1065, DOI 10.2307/2290084; WEI LJ, 1984, J AM STAT ASSOC, V79, P653, DOI 10.2307/2288413; Weller JI, 1998, GENETICS, V150, P1699; Westfall P.H., 2004, IMS LECT NOTES MONOG, V47, P143; Westfall PH, 1993, RESAMPLING BASED MUL; Worsley KJ, 1996, HUM BRAIN MAPP, V4, P58, DOI 10.1002/(SICI)1097-0193(1996)4:1&lt;58::AID-HBM4&gt;3.0.CO;2-O; WRIGHT SP, 1992, BIOMETRICS, V48, P1005, DOI 10.2307/2532694; YANG YH, 2001, SPIE BIOS 2001; Yekutieli D, 2006, STAT NEERL, V60, P414, DOI 10.1111/j.1467-9574.2006.00343.x; Yekutieli D, 1999, J STAT PLAN INFER, V82, P171, DOI 10.1016/S0378-3758(99)00041-5; Zweiger G., 2001, TRANSDUCING GENOME I	141	43	44	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	0962-2802		STAT METHODS MED RES	Stat. Methods Med. Res.	AUG	2008	17	4					347	388		10.1177/0962280206079046		42	Health Care Sciences & Services; Mathematical & Computational Biology; Medical Informatics; Statistics & Probability	Health Care Sciences & Services; Mathematical & Computational Biology; Medical Informatics; Mathematics	341YY	WOS:000258753000001	
J	Labrador, B				Labrador, Boris			Strong pointwise consistency of the k(T)-occupation time density estimator	STATISTICS & PROBABILITY LETTERS			English	Article							NONPARAMETRIC ESTIMATE; UNIFORM CONSISTENCY; CONVERGENCE; RATES	In this paper, we study the k(T)-occupation time density estimator as an extension of the k-nearest neighbor estimator in continuous time. The rates of strong pointwise convergence for a-mixing and bounded processes in both optimal (when i.i.d. rates of density estimation are reached) and superoptimal cases (when parametric rates are reached) are established. (c) 2007 Elsevier B.V. All fights reserved.	Univ Paris 06, LSTA, F-75013 Paris, France	Labrador, B (reprint author), Univ Paris 06, LSTA, 175 Rue Chevaleret,Boite 158, F-75013 Paris, France.	labrador@ccr.jussieu.fr					Blanke D, 1997, STAT PROBABIL LETT, V33, P185, DOI 10.1016/S0167-7152(96)00126-5; BLANKE D, 2004, MATH METHODS STAT, V13, P123; BOENTE G, 1988, J MULTIVARIATE ANAL, V25, P90, DOI 10.1016/0047-259X(88)90154-6; BOENTE G, 1991, SANKHYA SER A, V53, P194; BOSQ D, 1987, COLLECTION EC STAT A; Bosq D., 1998, LECT NOTES STAT, V110; Bosq D, 1997, ANN STAT, V25, P982, DOI 10.1214/aos/1069362734; CASTELLANA JV, 1986, STOCH PROC APPL, V21, P179, DOI 10.1016/0304-4149(86)90095-5; CHEN XR, 1982, SCI SIN A-MATH P A T, V25, P455; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEHEUVELS P, 1992, ANN PROBAB, V20, P1248, DOI 10.1214/aop/1176989691; DEVROYE LP, 1977, ANN STAT, V5, P536, DOI 10.1214/aos/1176343851; DEVROYE L, 1982, HDB STAT, V2, P193, DOI 10.1016/S0169-7161(82)02011-2; Doukhan P., 1994, LECT NOTES STAT, V85; Fix E., 1951, 4 USAF SCH AV MED; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; GEMAN D, 1980, ANN PROBAB, V8, P1, DOI 10.1214/aop/1176994824; Kutoyants Y. A., 2004, SPRINGER SERIES STAT; Labrador B, 2006, CR MATH, V343, P665, DOI 10.1016/j.crma.2006.10.015; LEVALLOIS S, 1998, THESIS U MONTPELLIER; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MACK YP, 1983, J STAT PLAN INFER, V8, P185, DOI 10.1016/0378-3758(83)90037-X; Moore D., 1977, STAT DECISION THEORY, P269; MOORE DS, 1969, ANN MATH STAT, V40, P1499, DOI 10.1214/aoms/1177697524; NGUYEN HT, 1989, PUBL I STAT U PARIS, V34, P69; Pollard D., 1984, SPRINGER SERIES STAT; Rio E., 2000, MATH APPL, V31; TRAN LT, 1993, J MULTIVARIATE ANAL, V44, P23, DOI 10.1006/jmva.1993.1002; WAGNER TJ, 1973, IEEE T SYST MAN CYB, VSMC3, P289	29	2	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-7152		STAT PROBABIL LETT	Stat. Probab. Lett.	JUL 15	2008	78	9					1128	1137		10.1016/j.spl.2007.11.010		10	Statistics & Probability	Mathematics	314YO	WOS:000256845300011	
J	Chen, YF; Wang, RC				Chen Yunfang; Wang Ruchuan			A classification algorithm based on artificial immune	CHINESE JOURNAL OF ELECTRONICS			English	Article						classification; artificial immune system; handwritten digit recognition	SYSTEMS	Based on the natural characteristic of artificial immune system in the field of pattern recognition, the paper proposes a novel Classification algorithm (CAAI). According to the principle of gene revolution, negative selection and clonal selection, a classification algorithm which is based on AIS is designed and implemented. The algorithm consists of two phases. For each word, in the antibody libraries initialization phase, characteristic vectors of the training datasets are extracted and antibody libraries continually evolve using the negative selection. In the classification phase, a clonal selection is introduced to classify the test sample into different categories. Then, the proposed algorithm is validated using classical handwritten digit recognition problem, and the experimental results indicate the robustness and accuracy of the proposed algorithm. Additionally, the comparison with other classification algorithm showed the proposed algorithm has a great competitiveness on recognition rate and recognition performance.	[Chen Yunfang; Wang Ruchuan] Nanjing Univ Posts & Telecommun, Coll Comp, Nanjing 210003, Peoples R China; [Wang Ruchuan] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Peoples R China	Chen, YF (reprint author), Nanjing Univ Posts & Telecommun, Coll Comp, Nanjing 210003, Peoples R China.	wangrc@njupt.edu.cn			National Natural Science Foundation of China [60573141, 60773041]; National 863 High Technology Research Program of China [2006AA01Z439, 2007AA01Z404, 2007AA01Z478]; High Technology Research Programme of Jiangsu Province [BG2006001]; Foundation of National Laboratory for Modern Communications [9140C1101010603]; Key Laboratory of Information Technology Processing of Jiangsu Province [kjs06006]; iangsu Provincial Research Scheme of Natural Science for Higher Education Institutions [07KJB520083]	This work is supported by the National Natural Science Foundation of China (No.60573141, No.60773041), National 863 High Technology Research Program of China (No.2006AA01Z439, No.2007AA01Z404, No.2007AA01Z478), High Technology Research Programme of Jiangsu Province (No.BG2006001), Foundation of National Laboratory for Modern Communications (No.9140C1101010603) and Key Laboratory of Information Technology Processing of Jiangsu Province (No.kjs06006). Project is sponsored by Jiangsu Provincial Research Scheme of Natural Science for Higher Education Institutions (No.07KJB520083).	Bahlmann C., 2002, Proceedings Eighth International Workshop on Frontiers in Handwriting Recognition, DOI 10.1109/IWFHR.2002.1030883; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; DASGUPTA D, 2003, IEEE C EL COMM; Dasgupta D., 1999, P 22 NAT INF SYST SE; DASGUPTA D, 2000, P IEEE INT C SYST MA; de Castro L. N., 2002, ARTIFICIAL NEURAL NE, P67; de Castro LN, 2003, SOFT COMPUT, V7, P526, DOI [10.1007/S00500-002-0237-Z, 10.1007/S00500-002-0237-z]; DEEPU V, 2004, P 17 INT C PATT REC, V2, P23; DEJONG KA, 1993, MACH LEARN, V13, P161, DOI 10.1023/A:1022617912649; DONG JX, 2001, STAT RESULT HUMAN PE; DONG JX, 1999, COMPARISON ALGORITHM; Forrest S, 1993, EVOL COMPUT, V1, P191, DOI 10.1162/evco.1993.1.3.191; Garrett SM, 2005, EVOL COMPUT, V13, P145, DOI 10.1162/1063656054088512; HART E, 2005, ICARIS, P29; HART E, 2005, INT C ART IMM SYST 2; Kegl B, 2002, IEEE T PATTERN ANAL, V24, P59, DOI 10.1109/34.982884; LANGLEY P, 1990, AAAI, P223; Lee SW, 1996, IEEE T PATTERN ANAL, V18, P648; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; OPREA M, 1999, 1999 GEN EV COMP C J; Park Y, 2001, DIABETES METAB RES, V17, P2, DOI 10.1002/1520-7560(2000)9999:9999<::AID-DMRR164>3.0.CO;2-M; PAWLAK Z, 1984, INT J MAN MACH STUD, V20, P469, DOI 10.1016/S0020-7373(84)80022-X; Perelson AS, 1997, REV MOD PHYS, V69, P1219, DOI 10.1103/RevModPhys.69.1219; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Rui Ting, 2005, Mini-Micro Systems, V26; [芮挺 Rui Ting], 2004, [中国图象图形学报. A, Journal of image and graphics], V9, P1008; Rumelhart DE, 1986, LEARNING INTERNAL RE; SCHLAPBACH A, 2004, 17 INT C CAMBR UK, V2, P654; STEPNEY RE, 2004, P 3 INT C ART IMM SY; TIMMIS J, 2004, OVERVIEW ARTIFICIAL, P51; Timmis J., 2002, ARTIFICIAL IMMUNE SY; Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585893	33	0	1	TECHNOLOGY EXCHANGE LIMITED HONG KONG	SHATIN	26-28 AU PUI WAN ST, STE 1102, FO TAN INDUSTRIAL CENTRE, FO TAN, SHATIN, 00000, PEOPLES R CHINA	1022-4653		CHINESE J ELECTRON	Chin. J. Electron.	JUL	2008	17	3					432	436				5	Engineering, Electrical & Electronic	Engineering	340ZR	WOS:000258684000008	
J	Mignani, AG; Ciaccheri, L; Cucci, C; Mencaglia, AA; Cimato, A; Attilio, C; Ottevaere, H; Thienpont, H; Paolesse, R; Mastroianni, M; Monti, D; Gerevini, M; Buonocore, G; Del Nobile, MA; Mentana, A; Grimaldi, MF; Dall'Asta, C; Faccini, A; Galaverna, G; Dossena, A				Mignani, Anna Grazia; Ciaccheri, Leonardo; Cucci, Costanza; Mencaglia, Andrea Azelio; Cimato, Antonio; Attilio, Cristina; Ottevaere, Heidi; Thienpont, Hugo; Paolesse, Roberto; Mastroianni, Marco; Monti, Donato; Gerevini, Marco; Buonocore, Giovanna; Del Nobile, Matteo Alessandro; Mentana, Annalisa; Grimaldi, Maria Francesca; Dall'Asta, Chiara; Faccini, Andrea; Galaverna, Gianni; Dossena, Arnaldo			EAT-by-LIGHT: Fiber-optic and micro-optic devices for food quality and safety assessment	IEEE SENSORS JOURNAL			English	Article						absorption spectroscopy; aflatoxins; beer; fluorescence spectroscopy; food authentication; milk; olive oil; scattered colorimetry	OLIVE OIL; CLASSIFICATION	A selection is presented of fiber-optic and micro-optic devices that have been designed and tested for guaranteeing the quality and safety of typical foods, such as extra virgin olive oil, beer, and milk. Scattered colorimetry is used to authenticate various types of extra virgin olive oil and beer, while a fiber-optic-based device for UV-VIS-NIR absorption spectroscopy is exploited in order to obtain the hyperspectral optical signature of olive oil. This is done not only for authentication purposes, but also so as to correlate the spectral data with the content of fatty acids, which are important nutritional factors. A micro-optic sensor for the detection of olive oil aroma that is capable of distinguishing different ageing levels of extra virgin olive oil is also presented. It shows effective potential for acting as a smart cap of bottled olive oil in order to achieve a nondestructive olfactory perception of oil ageing. Lastly, a compact portable fluorometer for the rapid monitoring of the carcinogenic M1 aflatoxin in milk, is experimented.	[Mignani, Anna Grazia; Ciaccheri, Leonardo; Cucci, Costanza; Mencaglia, Andrea Azelio] CNR IFAC, Sesto Fiorentino, FI, Italy; [Cimato, Antonio; Attilio, Cristina] CNR IVALSA, Sesto Fiorentino, FI, Italy; [Ottevaere, Heidi; Thienpont, Hugo] Vrije Univ Brussels, Dept Appl Phys & Photon, Brussels, Belgium; [Paolesse, Roberto; Mastroianni, Marco; Monti, Donato] Univ Roma Tor Vergata, Dipartimento Sci & Tecnol Chim, Rome, Italy; [Gerevini, Marco] Tecnoalimenti SCpA, Milan, Italy; [Buonocore, Giovanna] CNR IMCB, Naples, Italy; [Del Nobile, Matteo Alessandro; Mentana, Annalisa; Grimaldi, Maria Francesca] Univ Foggia, Dipartimento Sci Alimenti, Foggia, Italy; [Dall'Asta, Chiara; Faccini, Andrea; Galaverna, Gianni; Dossena, Arnaldo] Univ Parma, Dipartimento Chim Organ & Ind, I-43100 Parma, Italy	Mignani, AG (reprint author), CNR IFAC, Sesto Fiorentino, FI, Italy.	a.g.mignani@ifac.cnr.it	Ottevaere, Heidi/A-9294-2010; Mignani, Anna Grazia/B-3281-2010; Dall'Asta, Chiara/C-3173-2008; Paolesse, Roberto/B-8966-2013; Buonocore, Giovanna/G-4860-2013	Dall'Asta, Chiara/0000-0003-0716-8394; Paolesse, Roberto/0000-0002-2380-1404; 	EU.SMT Programme [SMT4-CT972157]; MIUR-FIRB [RBNE01KZZM]; EU FP6 Network of Excellence [003887]	This work was supported by the EU.SM&T Programme, under Contract SMT4-CT972157 "OPTIMO"; Regione Toscana, ITT "CARABIOTEC"; MIUR-FIRB, under Contract RBNE01KZZM "BIOSENS"; EU FP6 Network of Excellence Contract 003887 "NEMO"; CNR Short Term Mobility Program; DWTC-IAP, FWO Vlaanderen and the OZR of the Vrije Universiteit Brussel; and Regione Sicilia, Assessorato Agricoltura e Foreste, Servizio IX degrees, Palermo. The work of H. Ottevaere was supported by the Flemish Fund for Scientific Research (FWO) under the "Postdoctoraal Onderzoeker" Fellowship. The associate editor coordinating the review of this paper and approving it for publication was Prof. Brian Culshaw.	ADAMS MJ, 1995, CHEMOMETRIC ANAL SPE; Buratti S, 2005, ITAL J FOOD SCI, V17, P203; CHIAVARO E, 2001, J CHROMATOGR A, V937, P257; Connolly C., 2005, Sensor Review, V25, DOI 10.1108/02602280510606453; COVE IA, 1985, APPL SPECTROSC, V39, P257; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cucci C, 2007, SENSOR ACTUAT B-CHEM, V126, P467, DOI 10.1016/j.snb.2007.03.036; Di Natale C, 2007, SENSOR ACTUAT B-CHEM, V121, P238, DOI 10.1016/j.snb.2006.09.038; Dolphin D., 1978, PORPHYRINS, V3; Franco CM, 1998, J CHROMATOGR A, V815, P21, DOI 10.1016/S0021-9673(98)00509-3; Harwood JL, 1999, HDB OLIVE OIL; HESTER RE, 2001, FOOD SAFETY FOOD QUA; JACKSONS M, 2001, GREAT BEERS BELGIUM; JAE M, 2002, OILS FATS AUTHENTICA; KELLER JJ, 2000, COMPLIANCE MANUAL FO; Lees M., 2003, FOOD AUTHENTICITY TR; Mencaglia AA, 2003, P SOC PHOTO-OPT INS, V4763, P248, DOI 10.1117/12.508795; Mignani AG, 2005, P SOC PHOTO-OPT INS, V5855, P38, DOI 10.1117/12.623388; Mignani AG, 2005, SENSOR ACTUAT B-CHEM, V111, P363, DOI 10.1016/j.snb.2005.03.023; MIGNANI AG, 2007, P SPIE, V6585; MIGNANI AG, 2006, P SPIE, V6189; Ozaki Y., 2007, NEAR INFRARED SPECTR; PAOLESSE R, 2003, 16 OPT FIB SENS C, P742; Rakow NA, 2000, NATURE, V406, P710, DOI 10.1038/35021028; SERVILI M, 1995, J SCI FOOD AGR, V67, P61, DOI 10.1002/jsfa.2740670111; Siesler H. W., 2002, NEAR INFRARED SPECTR; Vandeginste B.G.M., 1998, HDB CHEMOMETRICS QUA; VANEGMOND HP, 1998, INTRO MYCOTOXINS DAI; WEBB T, 2005, GOOD BEER GUIDE BELG; 1993, AGENCY FOR RES CANC, V56	30	17	18	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1530-437X		IEEE SENS J	IEEE Sens. J.	JUL-AUG	2008	8	7-8					1342	1354		10.1109/JSEN.2008.926971		13	Engineering, Electrical & Electronic; Instruments & Instrumentation; Physics, Applied	Engineering; Instruments & Instrumentation; Physics	338RP	WOS:000258526600044	
J	Samaniego, L; Bardossy, A; Schulz, K				Samaniego, Luis; Bardossy, Andras; Schulz, Karsten			Supervised classification of remotely sensed imagery using a modified k-NN technique	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article						dimensionality reduction; ensemble prediction; k-nearest neighbors (NNs); land cover classification; simulated annealing (SA)	NEAREST-NEIGHBOR CLASSIFICATION; SENSING IMAGES; ACCURACY ASSESSMENT; FUZZY; RULE; SIZE	Nearest neighbor (NN) techniques are commonly used in remote sensing, pattern recognition, and statistics to classify objects into a predefined number of categories based on a given set of predictors. These techniques are particularly useful in those cases exhibiting a highly nonlinear relationship between variables. In most studies, the distance measure is adopted a priori. In contrast, we propose a general procedure to find Euclidean metrics in a low-dimensional space (i.e., one in which the number of dimensions is less than the number of predictor variables) whose main characteristic is to minimize the variance of a given class label of all those pairs of points whose distance is less than a predefined value. k-NN is used in each embedded space to determine the possibility that a query belongs to a given class label. The class estimation is carried out by an ensemble of predictions. To illustrate the application of this technique, a typical land cover classification using a Landsat-5 Thematic Mapper scene is presented. Experimental results indicate substantial improvement with regard to the classification accuracy as compared with approaches such as maximum likelihood, linear discriminant analysis, standard k-NN, and adaptive quasi-conformal kernel k-NN.	[Samaniego, Luis; Schulz, Karsten] UFZ Helmholtz Ctr Environm Res, D-04318 Leipzig, Germany; [Bardossy, Andras] Univ Stuttgart, Inst Hydraul Engn, D-70569 Stuttgart, Germany	Samaniego, L (reprint author), UFZ Helmholtz Ctr Environm Res, D-04318 Leipzig, Germany.		Bardossy, Andras/A-1160-2009; Samaniego, Luis/G-8651-2011				Aarts E., 1989, SIMULATED ANNEALING; Atkinson PM, 1997, INT J REMOTE SENS, V18, P699, DOI 10.1080/014311697218700; Bachmann CM, 2005, IEEE T GEOSCI REMOTE, V43, P441, DOI 10.1109/TGRS.2004.842292; BARDOSSY A, 2005, WATER RESOUR RES, V41, DOI UNSP W08 404-1-W08 404-13; Bardossy A, 2002, IEEE T GEOSCI REMOTE, V40, P362, DOI 10.1109/36.992798; Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P429, DOI 10.1109/36.823938; CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P403; CONGALTON RG, 1991, REMOTE SENS ENVIRON, V37, P35, DOI 10.1016/0034-4257(91)90048-B; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deer PJ, 2003, FUZZY SET SYST, V137, P191, DOI 10.1016/S0165-0114(02)00220-8; Foody GM, 2006, REMOTE SENS ENVIRON, V104, P1, DOI 10.1016/j.rse.2006.03.004; Foody GM, 1996, INT J REMOTE SENS, V17, P1317; Foody GM, 2002, REMOTE SENS ENVIRON, V80, P185, DOI 10.1016/S0034-4257(01)00295-4; Foody GM, 2004, IEEE T GEOSCI REMOTE, V42, P1335, DOI 10.1109/TGRS.2004.827257; Foody GM, 2005, INT J REMOTE SENS, V26, P1217, DOI 10.1080/01431160512331326521; Franco-Lopez H, 2001, REMOTE SENS ENVIRON, V77, P251, DOI 10.1016/S0034-4257(01)00209-7; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Fukunaga K., 1990, INTRO STAT PATTERN R; Goodin DG, 2004, IEEE T GEOSCI REMOTE, V42, P154, DOI 10.1109/TGRS.2003.815674; GOPAL S, 1994, PHOTOGRAMM ENG REM S, V60, P181; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hastie T, 2001, ELEMENTS STAT LEARNI; Isaaks E, 1989, INTRO APPL GEOSTATIS; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; Mahalanobis P., 1936, P NAT I SCI INDIA, V2, P49; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; Mardia K. V., 1979, MULTIVARIATE ANAL, P521; Massa A, 2005, IEEE T GEOSCI REMOTE, V43, P2084, DOI 10.1109/TGRS.2005.853186; MATHER PM, 2004, PROCESSING REMOTELY; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Mercer J, 1909, PHILOS T R SOC LOND, V209, P415, DOI 10.1098/rsta.1909.0016; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Omohundro S. M., 1987, Complex Systems, V1; Peng J, 2004, IEEE T PATTERN ANAL, V26, P656; Poggi G, 2005, IEEE T GEOSCI REMOTE, V43, P1901, DOI 10.1109/TGRS.2005.852163; Richards J. A., 2006, REMOTE SENSING DIGIT; Roweis S. T., 2000, SCIENCE, V290, P5500; SCHOLKOPF B, 2000, NEURAL COMPUT, V12, P1245; Serpico SB, 2007, IEEE T GEOSCI REMOTE, V45, P484, DOI 10.1109/TGRS.2006.886177; Shang WQ, 2006, LECT NOTES COMPUT SC, V3993, P216; SINGLETO.RC, 1969, COMMUN ACM, V12, P185, DOI 10.1145/362875.362901; Song C, 2001, REMOTE SENS ENVIRON, V75, P230, DOI 10.1016/S0034-4257(00)00169-3; Stathakis D, 2006, IEEE T GEOSCI REMOTE, V44, P2305, DOI 10.1109/TGRS.2006.872903; Tenenbaum J. B., 2000, SCIENCE, V290, P5500; van Laarhoven PJM, 1992, SIMULATED ANNEALING; van de Vlag DE, 2007, IEEE T GEOSCI REMOTE, V45, P237, DOI 10.1109/TGRS.2006.885403; VANGENDEREN JL, 1978, REMOTE SENS ENVIRON, V7, P3, DOI 10.1016/0034-4257(78)90003-2; Van Niel TG, 2005, REMOTE SENS ENVIRON, V98, P468, DOI 10.1016/j.rse.2005.08.011; Zhu HW, 2005, IEEE T GEOSCI REMOTE, V43, P1874; ZHUANG X, 1994, INT J REMOTE SENS, V15, P3271; *IMSL, 1997, FORTR SUBR MATH APPL	53	13	13	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0196-2892		IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	JUL	2008	46	7					2112	2125		10.1109/TGRS.2008.916629		14	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing	Geochemistry & Geophysics; Engineering; Remote Sensing	321DP	WOS:000257285200023	
J	Nanni, L; Lumini, A				Nanni, Loris; Lumini, Alessandra			Cluster-based nearest-neighbour classifier and its application on the lightning classification	JOURNAL OF COMPUTER SCIENCE AND TECHNOLOGY			English	Article						nearest-neighbour classifier; clustering; adaptive distance	FEATURE LINE METHOD; PATTERN-CLASSIFICATION; FACE RECOGNITION; RETRIEVAL; RULE	The problem addressed in this paper concerns the prototype generation for a cluster-based nearest-neighbour classifier. It considers, to classify a test pattern, the lines that link the patterns of the training set and a set of prototypes. An efficient method based on clustering is here used for finding subgroups of similar patterns with centroid being used as prototype. A learning method is used for iteratively adjusting both position and local-metric of the prototypes. Finally, we show that a simple adaptive distance measure improves the performance of our nearest-neighbour-based classifier. The performance improvement with respect to other nearest-neighbour-based classifiers is validated by testing our method on a lightning classification task using data acquired from the Fast On-orbit Recording of Transient Events (FORTE) satellite, moreover the performance improvement is validated through experiments with several benchmark datasets. The performance of the proposed methods are also validated using the Wilcoxon Signed-Rank test.	[Nanni, Loris; Lumini, Alessandra] Univ Bologna, DEIS, IEIIT CNR, I-40136 Bologna, Italy	Nanni, L (reprint author), Univ Bologna, DEIS, IEIIT CNR, Viale Risorgimento 2, I-40136 Bologna, Italy.	loris.nanni@unibo.it; alessandra.lumini@unibo.it	Lumini, Alessandra/B-6100-2013	Lumini, Alessandra/0000-0003-0290-7354			Bezdek J., 1981, PATTERN RECOGNITION; BRILES S, 1993, P INT WORKSH ART INT; Chen JH, 2004, PATTERN RECOGN, V37, P1913, DOI 10.1016/j.patcog.2003.12.003; Chen K, 2002, PATTERN RECOGN LETT, V23, P1735, DOI 10.1016/S0167-8655(02)00147-2; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Demsar J, 2006, J MACH LEARN RES, V7, P1; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; EADS D, 2002, P 5 C APPL SCI NEUR, P74; Franco A, 2004, INT C PATT RECOG, P424, DOI 10.1109/ICPR.2004.1333793; FRIEDMAN J, 1994, 113 STANF U; Gao QB, 2007, PATTERN RECOGN, V40, P346, DOI 10.1016/j.patcog.2006.06.033; Ghosh AK, 2006, IEEE T SYST MAN CY B, V36, P1139, DOI 10.1109/TSMCB.2006.873186; Ghosh AK, 2005, IEEE T PATTERN ANAL, V27, P1592, DOI 10.1109/TPAMI.2005.204; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; KELLER JM, 1995, IEEE T SYST MAN CYB, V25, P804; KUNCHEVA LI, 2004, COMBINING PATTERN CL; Li B, 2008, IEEE T SYST MAN CY B, V38, P141, DOI 10.1109/TSMCB.2007.908363; Li SZ, 2000, IEEE T SPEECH AUDI P, V8, P619, DOI 10.1109/89.861383; Li SZ, 2000, IEEE T PATTERN ANAL, V22, P1335, DOI 10.1109/34.888719; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Lumini A, 2006, PATTERN RECOGN, V39, P495, DOI 10.1016/j.patcog.2005.11.004; MOORE K, 1997, P SPIE, V2492; PARADES R, 2006, PATTERN RECOGN, V39, P180; PEDREIRA C, 2006, IEEE T PATTERN ANAL, V18, P157; Rognvaldsson T, 2004, BIOINFORMATICS, V20, P1702, DOI 10.1093/bioinformatics/bth144; Wang JG, 2007, PATTERN RECOGN LETT, V28, P207, DOI 10.1016/j.patrec.2006.07.002; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004; Zhou YL, 2004, LECT NOTES COMPUT SC, V3175, P204; Zhu HW, 2005, IEEE T GEOSCI REMOTE, V43, P1874	32	1	2	SCIENCE PRESS	BEIJING	16 DONGHUANGCHENGGEN NORTH ST, BEIJING 100717, PEOPLES R CHINA	1000-9000		J COMPUT SCI TECH-CH	J. Comput. Sci. Technol.	JUL	2008	23	4					573	581		10.1007/s11390-008-9153-8		9	Computer Science, Hardware & Architecture; Computer Science, Software Engineering	Computer Science	328PI	WOS:000257809900006	
J	Li, XH; Shu, L				Li, Xuehua; Shu, Lan			Kernel based nonlinear dimensionality reduction and classification for genomic microarray	SENSORS			English	Article						manifold learning; dimensionality reduction; locally linear embedding; kernel methods; support vector machine	SUPPORT VECTOR MACHINES; GENE-EXPRESSION DATA; DNA MICROARRAYS; PREDICTION; DISCOVERY	Genomic microarrays are powerful research tools in bioinformatics and modern medicinal research because they enable massively-parallel assays and simultaneous monitoring of thousands of gene expression of biological samples. However, a simple microarray experiment often leads to very high-dimensional data and a huge amount of information, the vast amount of data challenges researchers into extracting the important features and reducing the high dimensionality. In this paper, a nonlinear dimensionality reduction kernel method based locally linear embedding(LLE) is proposed, and fuzzy K-nearest neighbors algorithm which denoises datasets will be introduced as a replacement to the classical LLE's KNN algorithm. In addition, kernel method based support vector machine (SVM) will be used to classify genomic microarray data sets in this paper. We demonstrate the application of the techniques to two published DNA microarray data sets. The experimental results confirm the superiority and high success rates of the presented method.	[Li, Xuehua; Shu, Lan] Univ Elect Sci & Technol China, Sch Appl Math, Chengdu 610054, Peoples R China	Li, XH (reprint author), Univ Elect Sci & Technol China, Sch Appl Math, Chengdu 610054, Peoples R China.	leesoftcom@gmail.com					ALIZADEH, 2000, NATURE, V403, P503; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRISTIANINI N, 2000, INTRO SUPPORT VECTOR, P96; Du PF, 2007, BIOCHEM BIOPH RES CO, V358, P336, DOI 10.1016/j.bbrc.2007.04.130; ELGAMMAL AM, 2004, IEEE COMP SOC C COMP, P478; Ellis M, 2002, CLIN CANCER RES, V8, P1155; HAYKIN S, 1999, NEURAL NETWORKS COMP, P330; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Kouropteva O, 2002, P 1 INT C FUZZ SYST, P359; Lee Y, 2003, BIOINFORMATICS, V19, P1132, DOI 10.1093/bioinformatics/btg102; MARINA M, 2001, ADV NIPS, V13, P873; Mekuz N, 2005, 2nd Canadian Conference on Computer and Robot Vision, Proceedings, P290, DOI 10.1109/CRV.2005.42; NIKHIL RP, 2007, BMC BIOINFORMATICS, V8, P1; Orr MS, 2002, LEUKEMIA, V16, P473, DOI 10.1038/sj/leu/2402413; Qian ZL, 2006, BIOCHEM BIOPH RES CO, V348, P1034, DOI 10.1016/j.bbrc.2006.07.149; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; SAUL L, 2002, CIS0218 MS U PENNS, V37, P134; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Shalon D, 1996, GENOME RES, V6, P639, DOI 10.1101/gr.6.7.639; SHAWETALYOR J, 2004, KERNEL METHODS PATTE; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tibshirani R, 2003, STAT SCI, V18, P104, DOI 10.1214/ss/1056397488; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; VAPNIK VN, 1998, STAT LEARNING THEORY, P157; Vapnik V.N., 1995, NATURE STAT LEARNING; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Wang XC, 2003, PATTERN RECOGN, V36, P2429, DOI 10.1016/S0031-3203(03)00044-X; YEO G, 2001, 2001018 AI; Young RA, 2000, CELL, V102, P9, DOI 10.1016/S0092-8674(00)00005-2; Zhang CS, 2004, PATTERN RECOGN, V37, P325, DOI 10.1016/j.patcog.2003.07.005	33	0	0	MOLECULAR DIVERSITY PRESERVATION INT	BASEL	MATTHAEUSSTRASSE 11, CH-4057 BASEL, SWITZERLAND	1424-8220		SENSORS-BASEL	Sensors	JUL	2008	8	7					4186	4200		10.3390/s8074186		15	Chemistry, Analytical; Electrochemistry; Instruments & Instrumentation	Chemistry; Electrochemistry; Instruments & Instrumentation	333VI	WOS:000258180500010	
J	Zhang, CQ; Ou, YB				Zhang, Cun-Quan; Ou, Yongbin			Clustering, Community Partition and Disjoint Spanning Trees	ACM TRANSACTIONS ON ALGORITHMS			English	Article						Spanning trees; clustering; dense subgraph; polynomial algorithm; community; dynamic density; hierarchical clustering	ALGORITHMS; NETWORK; GRAPH	Clustering method is one of the most important tools in statistics. In a graph theory model, clustering is the process of finding all dense subgraphs. A mathematically well-defined measure for graph density is introduced in this article as follows. Let G = (V, E) be a graph (or multi-graph) and H be a subgraph of G. The dynamic density of H is the greatest integer k such that min(VP){vertical bar E(H/P)vertical bar/vertical bar V(H/P)vertical bar-1} > k where the minimum is taken over all possible partitions P of the vertex set of H, and H/P is the graph obtained from H by contracting each part of P into a single vertex. A subgraph H of G is a level-k community if H is a maximal subgraph of G with dynamic density at least k. An algorithm is designed in this paper to detect all level-h communities of an input multi-graph G. The worst-case complexity of this algorithm is upper bounded by O(vertical bar V(G)vertical bar(2)h(2)). This new method is one of few available clustering methods that are mathematically well-defined, supported by rigorous mathematical proof and able to achieve the optimization goal with polynomial complexity. As a byproduct, this algorithm also can be applied for finding edge-disjoint spanning trees of a multi-graph. The worst-case complexity is lower than all known algorithms for multi-graphs.	[Zhang, Cun-Quan; Ou, Yongbin] W Virginia Univ, Dept Math, Morgantown, WV 26506 USA	Zhang, CQ (reprint author), W Virginia Univ, Dept Math, Morgantown, WV 26506 USA.	cqzhang@math.wvu.edu; ouyb@csbl.bmb.uga.edu			National Security Agency [MDA904-01-1-0022]; WV EPSCoR	C.-Q. Zhang was supported by a grant of the National Security Agency (MDA904-01-1-0022) and a grant of WV EPSCoR.	Anthonisse J. M., 1971, 971 BN STICHT MATH C; BARAHONA F, 1995, MATH OPER RES, V20, P104, DOI 10.1287/moor.20.1.104; BARAHONA F, 2004, NETWORK REINFORCEMEN; Berkhin P, 2002, SURVEY CLUSTERING DA; Bezdek J., 1981, PATTERN RECOGNITION; Bradley P. S., 1998, P 15 INT C MACH LEAR, P91; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CUNNINGHAM WH, 1985, J ACM, V32, P549, DOI 10.1145/3828.3829; CUNNINGHAM WH, 1984, J COMB THEORY B, V36, P161, DOI 10.1016/0095-8956(84)90023-6; D'andrade R., 1978, PSYCHOMETRIKA, V4, P58; Ding C, 2004, P 2004 ACM S APPL CO, P584, DOI 10.1145/967900.968021; Dunn J. C., 1973, Journal of Cybernetics, V3; Faust K., 1994, SOCIAL NETWORK ANAL; Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578; FREEMAN LC, 1977, SOCIOMETRY, V40, P35, DOI 10.2307/3033543; GABOW HN, 1992, ALGORITHMICA, V7, P465, DOI 10.1007/BF01758774; GABOW HN, 1995, PROCEEDINGS OF THE SIXTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P88; Gabow HN, 1998, J ALGORITHM, V26, P48, DOI 10.1006/jagm.1997.0904; GABOW HN, 1995, J COMPUT SYST SCI, V50, P259, DOI 10.1006/jcss.1995.1022; GIRVAN M, 2002, P NATL ACAD SCI USA, V99, P8271; GOLDBERG AV, 1988, J ACM, V35, P921, DOI 10.1145/48014.61051; GUSFIELD D, 1991, SIAM J COMPUT, V20, P639, DOI 10.1137/0220040; Han J., 2000, MORGAN KAUFMANN SERI; Hartigan J., 1975, CLUSTERING ALGORITHM; Hoppner F., 1999, FUZZY CLUSTER ANAL M; Jain A. K., 1999, ACM COMPUT SURV, V31; Johnson S., 1967, PSYCHOMETRIKA, V2, P241; LAMPINEN T, 2002, P INT C FUZZ SYST KN; Lukashin AV, 2001, BIOINFORMATICS, V17, P405, DOI 10.1093/bioinformatics/17.5.405; MacQueen J. B., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; Massart DL, 1983, INTERPRETATION ANAL; Moore Andrew W., 2001, K MEANS HIERARCHICAL; Nash-Williams C. S. J. A., 1961, J LOND MATH SOC, V36, P445; PELLEG D, 1999, C KNOWL DISC DAT P 5, P277; Radicchi F, 2004, P NATL ACAD SCI USA, V101, P2658, DOI 10.1073/pnas.0400054101; Roberts F. S., 2004, APPL COMBINATORICS; ROSKIND J, 1985, MATH OPER RES, V10, P701, DOI 10.1287/moor.10.4.701; SEIDMAN SB, 1983, SOC NETWORKS, V5, P269, DOI 10.1016/0378-8733(83)90028-X; Steinbach M., 2000, TEXTMINING WORKSH KD; STEPHEN SP, 1994, CONNECTIONS, V17, P78; Tutte W. T., 1961, J LOND MATH SOC, V36, P221; Wu F, 2004, EUR PHYS J B, V38, P331, DOI 10.1140/epjb/e2004-00125-x; Xu Y, 2002, BIOINFORMATICS, V18, P536, DOI 10.1093/bioinformatics/18.4.536; Zhang C.-Q, 1997, INTEGER FLOWS CYCLE; Zhang XY, 2005, J MOL EVOL, V60, P677, DOI 10.1007/s00239-004-0259-5; *SAS I INC, SAS STAT US GUID, pCH8	46	1	3	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1549-6325		ACM T ALGORITHMS	ACM Trans. Algorithms	JUN	2008	4	3							35	10.1145/1367064.1367075		26	Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	443AH	WOS:000265882100011	
J	Blanzieri, E; Melgani, F				Blanzieri, Enrico; Melgani, Farid			Nearest neighbor classification of remote sensing images with the maximal margin principle	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article						kernel methods; k-nearest neighbor algorithm; maximal margin principle; support vector machines (SVMs)	SUPPORT VECTOR MACHINES; STRUCTURAL RISK; RULE; MINIMIZATION; ALGORITHM	In this paper, we present a new variant of the k-nearest neighbor (kNN) classifier based on the maximal margin principle. The proposed method relies on classifying a given unlabeled sample by first finding its k-nearest training samples. A local partition of the input feature space is then carried out by means of local support vector machine (SVM) decision boundaries determined after training a multiclass SVM classifier on the considered k training samples. The labeling of the unknown sample is done by looking at the local decision region to which it belongs. The method is characterized by resulting global decision boundaries of the piecewise linear type. However, the entire process can be kernelized through the determination of the k-nearest training samples in the transformed feature space by using a distance function simply reformulated on the basis of the adopted kernel. To illustrate the performance of the proposed method, an experimental analysis on three different remote sensing datasets is reported and discussed.	[Blanzieri, Enrico; Melgani, Farid] Univ Trent, Dept Informat & Commun Technol, I-38050 Trento, Italy	Blanzieri, E (reprint author), Univ Trent, Dept Informat & Commun Technol, I-38050 Trento, Italy.	blanzier@dit.unitn.it; melgani@dit.unitn.it	Melgani, Farid/A-7076-2013				Bazi Y, 2006, IEEE T GEOSCI REMOTE, V44, P3374, DOI 10.1109/TGRS.2006.880628; Blanzieri E., 2006, P IGARSS DENV CO JUL, P3931; Camps-Valls G, 2006, IEEE GEOSCI REMOTE S, V3, P93, DOI 10.1109/LGRS.2005.857031; Camps-Valls G, 2005, IEEE T GEOSCI REMOTE, V43, P1351, DOI 10.1109/TGRS.2005.846154; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Ferecatu M, 2007, IEEE T GEOSCI REMOTE, V45, P818, DOI 10.1109/TGRS.2007.892007; FIX E, 1951, N4 USAF SCH AV MED, P261; Foody GM, 2004, IEEE T GEOSCI REMOTE, V42, P1335, DOI 10.1109/TGRS.2004.827257; Huang C, 2002, INT J REMOTE SENS, V23, P725, DOI 10.1080/01431160110040323; Karacali B, 2003, IEEE T NEURAL NETWOR, V14, P127, DOI 10.1109/TNN.2002.804315; Karacali B, 2004, PATTERN RECOGN LETT, V25, P63, DOI 10.1016/j.patrec.2003.09.002; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Lee CH, 2003, PROC INT C TOOLS ART, P411; Li LS, 2005, Proceedings of the 2005 IEEE International Conference on Natural Language Processing and Knowledge Engineering (IEEE NLP-KE'05), P371; Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865; Serpico SB, 2001, IEEE T GEOSCI REMOTE, V39, P1360, DOI 10.1109/36.934069; Shen XQ, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P149; Vapnik V.N., 1995, NATURE STAT LEARNING; Wohlberg B, 2006, IEEE T GEOSCI REMOTE, V44, P47, DOI 10.1109/TGRS.2005.859953; Zhang B, 2004, IEEE T PATTERN ANAL, V26, P525; Zhang L, 2006, J ALZHEIMERS DIS, V10, P1; Zhu HW, 2005, IEEE T GEOSCI REMOTE, V43, P1874; [Anonymous], AVIRIS NW INDIANAS I	24	29	32	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0196-2892		IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	JUN	2008	46	6					1804	1811		10.1109/TGRS.2008.916090		8	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing	Geochemistry & Geophysics; Engineering; Remote Sensing	303QR	WOS:000256056100024	
J	Maas, MC; Schaart, DR; van der Laan, DJ; van Dam, HT; Huizenga, J; Brouwer, JC; Bruyndonckx, P; Lemaitre, C; van Eijk, CWE				Maas, Marnix C.; Schaart, Dennis R.; van der Laan, D. J. (Jan); van Dam, Herman T.; Huizenga, Jan; Brouwer, J. C.; Bruyndonckx, Peter; Lemaitre, Cedric; van Eijk, Carel W. E.			Signal to noise ratio of APD-based monolithic scintillator detectors for high resolution PET	IEEE TRANSACTIONS ON NUCLEAR SCIENCE			English	Article						avalanche photodiode (APD); monolithic scintillator detector; positron emission tomography (PET); signal to noise ratio (SNR)	SMALL ANIMAL PET; AVALANCHE PHOTODIODES; SPATIAL-RESOLUTION; PERFORMANCE; READOUT; SCANNER; DESIGN; ARRAYS; DEPTH; SENSITIVITY	Monolithic scintillator detectors, consisting of several cm(3) of scintillating material coupled to one or more Hamamatsu S8550 avalanche photodiode (APD) arrays, are proposed as detectors for high resolution positron emission tomography (PET). in this work, the factors contributing to the variance on the signals are investigated, and their effects on the energy, time and spatial resolutions are analyzed. Good agreement was found between a model of the energy resolution and experiments with a 20 x 10 x 10 mm(3) LYSO: Ce crystal coupled to a single channel large-area APD (LAAPD). With the same crystal coupled to an APD array, differences between model and experiment were observed at high APD gain. The measured energy resolution of similar to 11% FWHM was dominated by scintillation photon statistics, with less important roles for the APD excess noise factor and electronic noise. On the other hand, electronic noise was an important factor both for the time and the spatial resolutions. The time resolution was found to depend strongly on the APD bias voltage, and was best at the highest bias. A time resolution of 1.6 ns full width at half maximum (FWHM) was measured against a BaF2-PMT detector. The best spatial resolution measured was 1.64 mm FWHM, without correction for the similar to 0.9 mm FWHM measurement beam. It is estimated that an intrinsic spatial resolution of 1.26 mm FWHM can be achieved at the center of the detector with an infinitely narrow test beam.	[Maas, Marnix C.; Schaart, Dennis R.; van der Laan, D. J. (Jan); van Dam, Herman T.; Huizenga, Jan; Brouwer, J. C.; van Eijk, Carel W. E.] Delft Univ Technol, NL-2629 JB Delft, Netherlands; [Bruyndonckx, Peter; Lemaitre, Cedric] Vrije Univ Brussels, B-1050 Brussels, Belgium	Maas, MC (reprint author), Delft Univ Technol, NL-2629 JB Delft, Netherlands.	m.c.maas@tudelft.nl					Agostinelli S, 2003, NUCL INSTRUM METH A, V506, P250, DOI 10.1016/S0168-9002(03)01368-8; BERTUCCIO G, 1993, REV SCI INSTRUM, V64, P3294, DOI 10.1063/1.1144293; Birks J., 1964, THEORY PRACTICE SCIN; Bloomfield PM, 1997, PHYS MED BIOL, V42, P389, DOI 10.1088/0031-9155/42/2/010; BOISVERT J, 1996, P NUCL SCI S C REC, V1, P16; Bruyndonckx P, 2003, IEEE T NUCL SCI, V50, P1415, DOI 10.1109/TNS.2003.817348; Bruyndonckx P, 2004, IEEE T NUCL SCI, V51, P2520, DOI 10.1109/TNS.2004.835782; CARRICO B, 2006, LIP; CLEMENT D, 1998, P IEEE NSS, V3, P1448; Correia JA, 1999, IEEE T NUCL SCI, V46, P631, DOI 10.1109/23.775590; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Del Guerra A, 1998, NUCL INSTRUM METH A, V409, P537, DOI 10.1016/S0168-9002(97)01311-9; Dorenbos P, 1995, IEEE T NUCL SCI, V42, P2190, DOI 10.1109/23.489415; Fiorini C, 2004, IEEE T NUCL SCI, V51, P1091, DOI 10.1109/TNS.2004.829581; GATTI E, 1990, NUCL INSTRUM METH A, V297, P467, DOI 10.1016/0168-9002(90)91331-5; GOYOT M, 1988, NUCL INSTRUM METH A, V263, P180, DOI 10.1016/0168-9002(88)91032-7; Kapusta M, 2003, NUCL INSTRUM METH A, V504, P139, DOI 10.1016/S0168-9002(03)00809-X; Lecomte R, 1996, IEEE T NUCL SCI, V43, P1952, DOI 10.1109/23.507252; MAAS MC, 2005, PET, V4, P2017; Maas MC, 2006, IEEE T NUCL SCI, V53, P1071, DOI 10.1109/TNS.2006.873711; MAAS MC, 2004, P IEEE NUCL SCI S C, V5, P2942; MAAS MC, MODEL ANAL IN PRESS; McElroy DP, 2005, IEEE T NUCL SCI, V52, P199, DOI 10.1109/TNS.2004.843114; Mosset J-B, 2006, THESIS ECOLE POLYTEC; Mosset JB, 2003, NUCL INSTRUM METH A, V504, P325, DOI 10.1016/S0168-9002(03)00762-9; Moszynski M, 2002, NUCL INSTRUM METH A, V485, P504, DOI 10.1016/S0168-9002(01)02117-9; MOSZYNSKI M, 1979, NUCL INSTRUM METHODS, V158, P1, DOI 10.1016/S0029-554X(79)90170-8; Ochi A, 1996, NUCL INSTRUM METH A, V378, P267, DOI 10.1016/0168-9002(96)00442-1; Pansart JP, 1997, NUCL INSTRUM METH A, V387, P186, DOI 10.1016/S0168-9002(96)00987-4; Seidel J, 2003, IEEE T NUCL SCI, V50, P1347, DOI 10.1109/TNS.2003.817282; Surti S, 2003, IEEE T NUCL SCI, V50, P1357, DOI 10.1109/TNS.2003.817950; Tai YC, 2003, PHYS MED BIOL, V48, P1519, DOI 10.1088/0031-9155/48/11/303; Tsuda T, 2004, IEEE T NUCL SCI, V51, P2537, DOI 10.1109/TNS.2004.835739; VANDERLAAN DJ, SPATIAL RES IN PRESS; van der Laan DJJ, 2006, IEEE T NUCL SCI, V53, P1063, DOI 10.1109/TNS.2006.873710; WEBER S, P IEEE NUCL SCI S ME, V3, P1603; Ziemons K, 2005, NUCL INSTRUM METH A, V537, P307, DOI 10.1016/j.nima.2004.08.032; *GEANT4, 2005, GEANT4 US GUID APPL	38	10	10	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9499		IEEE T NUCL SCI	IEEE Trans. Nucl. Sci.	JUN	2008	55	3	1				842	852		10.1109/TNS.2008.921493		11	Engineering, Electrical & Electronic; Nuclear Science & Technology	Engineering; Nuclear Science & Technology	316RO	WOS:000256967600003	
J	Chen, YH; Chen, F; Yang, JY; Yang, MQ				Chen, Yuehui; Chen, Feng; Yang, Jack Y.; Yang, Mary Qu			Ensemble voting system for multiclass protein fold recognition	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article						protein fold recognition; particle swarm optimization (PSO); Tabu search; k-NN; probabilistic neural networks; ensemble learning	STRUCTURAL CLASS PREDICTION; STATISTICAL-METHOD; MEMBRANE-PROTEINS; SEQUENCE; CLASSIFICATION; PROFILES	Protein structure classification is an important issue in understanding the associations between sequence and structure as well as possible functional and evolutionary relationships. Recently structural genomes initiatives and other high-throughput experiments have populated the biological databases at a rapid pace. In this paper, three types of classifiers, k nearest neighbors, class center and nearest neighbor and probabilistic neural networks and their homogenous ensemble for multiclass protein fold recognition problem are evaluated firstly, and then a heterogenous ensemble Voting System is designed for the same problem. The different features and/or their combinations extracted from the protein fold dataset are used in these classification models. The heterogenous classification results are then put into a voting system to get the final result. The experimental results show that the proposed method can improve prediction accuracy by 4%-10% on a benchmark dataset containing 27 SCOP folds.	[Chen, Yuehui] Univ Jinan, Sch Informat Sci & Engn, Jinan 250022, Peoples R China; [Chen, Feng] Univ Elect Sci & Technol China, Sch Software, Chengdu 610054, Peoples R China; [Yang, Jack Y.] Harvard Univ, Harvard Med Sch, Cambridge, MA 02140 USA; [Yang, Mary Qu] US Dept HHS, Natl Human Genome Res Inst, Natl Inst Hlth, Bethesda, MD 20852 USA	Chen, YH (reprint author), Univ Jinan, Sch Informat Sci & Engn, Jinan 250022, Peoples R China.	yhchen@ujn.edu.cn; chenfeng_ci@163.com; jyang@bwh.harvard.edu; yangma@mail.NIH.gov					Battiti R., 1994, ORSA Journal on Computing, V6; Bonneau R, 2001, ANNU REV BIOPH BIOM, V30, P173, DOI 10.1146/annurev.biophys.30.1.173; Bu WS, 1999, EUR J BIOCHEM, V266, P1043, DOI 10.1046/j.1432-1327.1999.00947.x; Cai YD, 2004, BIOINFORMATICS, V20, P1151, DOI 10.1093/bioinformatics/bth054; Cheng JL, 2006, BIOINFORMATICS, V22, P1456, DOI 10.1093/bioinformatics/btl102; CHINNASAMY A, 2004, P PAC S BIOC, V9, P387; Chou KC, 2000, CURR PROTEIN PEPT SC, V1, P171, DOI 10.2174/1389203003381379; CHOU KC, 1992, AIDS RES HUM RETROV, V8, P1967, DOI 10.1089/aid.1992.8.1967; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ding CHQ, 2001, BIOINFORMATICS, V17, P349, DOI 10.1093/bioinformatics/17.4.349; Du QS, 2006, J BIOMOL STRUCT DYN, V23, P635; Dubchak I, 1999, PROTEINS, V35, P401, DOI 10.1002/(SICI)1097-0134(19990601)35:4<401::AID-PROT3>3.0.CO;2-K; Elofsson A, 1996, FOLD DES, V1, P451, DOI 10.1016/S1359-0278(96)00061-2; Exarchos TP, 2008, J BIOMED INFORM, V41, P165, DOI 10.1016/j.jbi.2007.05.004; Glover F., 1989, ORSA Journal on Computing, V1; GLOVER F, 1990, ORSA J COMPUTING, V2, P14; Goh ATC, 2002, CAN GEOTECH J, V39, P219, DOI 10.1139/T01-073; Gromiha MM, 1999, J PROTEIN CHEM, V18, P565, DOI 10.1023/A:1020603401001; Gromiha MM, 2005, BIOINFORMATICS, V21, P961, DOI 10.1093/bioinformatics/bti126; GROMIHA MM, 1995, INT J PEPT PROT RES, V45, P225; Gromiha MM, 2006, J CHEM INF MODEL, V46, P1503, DOI 10.1021/ci050417u; Hirokawa T, 1998, BIOINFORMATICS, V14, P378, DOI 10.1093/bioinformatics/14.4.378; HOBOHM U, 1992, PROTEIN SCI, V1, P409; HOBOHM U, 1994, PROTEIN SCI, V3, P522; Kennedy J., 2002, P C EV COMP CEC 02, P1671, DOI 10.1109/CEC.2002.1004493; KLEIN P, 1986, BIOCHIM BIOPHYS ACTA, V874, P205, DOI 10.1016/0167-4838(86)90119-6; Kumarevel TS, 2000, BIOPHYS CHEM, V88, P81, DOI 10.1016/S0301-4622(00)00201-5; Nanni L, 2006, NEUROCOMPUTING, V69, P2434, DOI 10.1016/j.neucom.2006.01.026; Okun O., 2004, P 11 FINN ART INT C, P207; Shen HB, 2006, BIOINFORMATICS, V22, P1717, DOI 10.1093/bioinformatics/btl170; Shen HB, 2005, BIOCHEM BIOPH RES CO, V334, P577, DOI 10.1016/j.bbrc.2005.06.128; Shi JY, 2001, J MOL BIOL, V310, P243, DOI 10.1006/jmbi.2001.4762; Sun GM, 2006, NEUROCOMPUTING, V69, P387, DOI 10.1016/j.neucom.2005.04.005; TAGUCHI YH, 2007, BMC BIOINFO IN PRESS; Tan Aik Choon, 2003, Genome Inform, V14, P206; Wang H, 2005, J MATER SCI TECHNOL, V21, P86; Wang ZX, 2000, PROTEINS, V38, P165, DOI 10.1002/(SICI)1097-0134(20000201)38:2<165::AID-PROT5>3.0.CO;2-V; Zhou HY, 2005, PROTEINS, V58, P321, DOI 10.1002/prot.20308	38	3	3	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014		INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	JUN	2008	22	4					747	763		10.1142/S0218001408006454		17	Computer Science, Artificial Intelligence	Computer Science	327XM	WOS:000257761800006	
J	Marchiori, E				Marchiori, Elena			Hit miss networks with applications to instance selection	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						graph-based training set representation; nearest neighbor; instance selection for instance-based learning	NEAREST-NEIGHBOR RULE; COVER CATCH DIGRAPHS; LEARNING ALGORITHMS; PROTOTYPE SELECTION; PROXIMITY GRAPHS; DATA SETS; CLASSIFICATION; CLASSIFIERS	In supervised learning, a training set consisting of labeled instances is used by a learning algorithm for generating a model (classifier) that is subsequently employed for deciding the class label of new instances (for generalization). Characteristics of the training set, such as presence of noisy instances and size, influence the learning algorithm and affect generalization performance. This paper introduces a new network-based representation of a training set, called hit miss network (HMN), which provides a compact description of the nearest neighbor relation over pairs of instances from each pair of classes. We show that structural properties of HMN's correspond to properties of training points related to the one nearest neighbor (1-NN) decision rule, such as being border or central point. This motivates us to use HMN's for improving the performance of a 1-NN classifier by removing instances from the training set (instance selection). We introduce three new HMN-based algorithms for instance selection. HMN-C, which removes instances without affecting accuracy of 1-NN on the original training set, HMN-E, based on a more aggressive storage reduction, and HMN-EI, which applies iteratively HMN-E. Their performance is assessed on 22 data sets with different characteristics, such as input dimension, cardinality, class balance, number of classes, noise content, and presence of redundant variables. Results of experiments on these data sets show that accuracy of 1-NN classifier increases significantly when HMN-EI is applied. Comparison with state-of-the-art editing algorithms for instance selection on these data sets indicates best generalization performance of HMN-EI and no significant difference in storage requirements. In general, these results indicate that HMN's provide a powerful graph-based representation of a training set, which can be successfully applied for performing noise and redundance reduction in instance-based learning.	Radboud Univ Nijmegen, Dept Comp Sci, NL-6525 ED Nijmegen, Netherlands	Marchiori, E (reprint author), Radboud Univ Nijmegen, Dept Comp Sci, NL-6525 ED Nijmegen, Netherlands.	elenam@cs.ru.nl					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Angiulli F, 2007, IEEE T KNOWL DATA EN, V19, P1450, DOI 10.1109/TKDE.2007.190645; BARNETT V, 1976, J ROY STAT SOC A STA, V139, P318, DOI 10.2307/2344839; Bhattacharjee S, 1998, REV CHEM ENG, V14, P1; Bhattacharya B, 2005, LECT NOTES COMPUT SC, V3776, P60; BHATTACHARYA BK, 1982, 823 TR S FRAS U SCH; Brighton H, 1999, LECT NOTES ARTIF INT, V1704, P283; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Cameron-Jones R.M., 1995, P 8 AUSTR JOINT C AR, P99; Chapelle O., 2005, P 10 INT WORKSH ART, P57; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Demsar J, 2006, J MACH LEARN RES, V7, P1; DEVINNEY, 2005, STAT PROBABILITY LET, V73, P37; DeVinney J, 2006, DISCRETE APPL MATH, V154, P1975, DOI 10.1016/j.dam.2006.04.004; Dorogovtsev SN, 2003, EVOLUTION NETWORKS B; Grother PJ, 1997, PATTERN RECOGN, V30, P459, DOI 10.1016/S0031-3203(96)00098-2; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Jankowski N, 2004, LECT NOTES ARTIF INT, V3070, P598; JAROMCZYK JW, 1992, P IEEE, V80, P1502, DOI 10.1109/5.163414; MUKHERJEE K, 2004, M SC PROJECT; Pekalska E, 2006, PATTERN RECOGN, V39, P189, DOI 10.1016/j.patcog.2005.06.012; Priebe CE, 2003, J CLASSIF, V20, P3, DOI 10.1007/s00357-003-0003-7; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P507, DOI 10.1016/S0167-8655(97)00035-4; Sankaranarayanan J, 2007, COMPUT GRAPH-UK, V31, P157, DOI 10.1016/j.cag.2006.11.011; Shin H, 2007, NEURAL COMPUT, V19, P816, DOI 10.1162/neco.2007.19.3.816; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; TOUSSAINT GT, 2002, 34 S COMP STAT, P83; TOUSSAINT GT, 1984, P COMP SCI STAT 16 S, P97; Vezhnevets A, 2007, LECT NOTES ARTIF INT, V4701, P430; WEGMAN DJ, 2005, HDB STAT, V24, P331; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson HR, 1997, VISUAL NEUROSCI, V14, P403; Zighed D. A., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431)	37	17	19	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	JUN	2008	9						997	1017				21	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	340LE	WOS:000258646300002	
J	Verron, S; Tiplica, T; Kobi, A				Verron, Sylvain; Tiplica, Teodor; Kobi, Abdessamad			Fault detection and identification with a new feature selection based on mutual information	JOURNAL OF PROCESS CONTROL			English	Article						FDI; discriminant analysis; mutual information	MULTIVARIATE QUALITY-CONTROL; PRINCIPAL COMPONENT ANALYSIS; STATISTICAL PROCESS-CONTROL; EASTMAN CHALLENGE PROCESS; SUPPORT VECTOR MACHINES; DISCRIMINANT-ANALYSIS; CONTROL CHART; PART I; CLASSIFICATION; DIAGNOSIS	This paper presents a fault diagnosis procedure based on discriminant analysis and mutual information. In order to obtain good classification performances, a selection of important features is done with a new developed algorithm based on the mutual information between variables. The application of the new fault diagnosis procedure on a benchmark problem, the Tennessee Eastman Process, shows better results than other well known published methods. (c) 2007 Elsevier Ltd. All rights reserved.	[Verron, Sylvain; Tiplica, Teodor; Kobi, Abdessamad] Univ Angers, LASQUO ISTIA, F-49000 Angers, France	Verron, S (reprint author), Univ Angers, LASQUO ISTIA, 62 Ave Notre Dame Lac, F-49000 Angers, France.	sylvain.verron@univ-angers.fr					Bakshi BR, 1998, AICHE J, V44, P1596, DOI 10.1002/aic.690440712; Chiang L.H., 2001, FAULT DETECTION DIAG; Chiang LH, 2004, COMPUT CHEM ENG, V28, P1389, DOI 10.1016/j.compchemeng.2003.10.002; Chiang LH, 2004, J PROCESS CONTR, V14, P143, DOI 10.1016/S0959-1524(03)00029-5; CHUA M, 1992, QUALITY RELIABILITY, V8, P37, DOI 10.1002/qre.4680080107; Cover T. M., 1991, ELEMENTS INFORM THEO; COVER TM, 1969, METHODOLOGIES PATTER; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Denoeux T., 1997, J EUROPEEN SYSTEMES, V31, P1509; Dhillon B., 2005, RELIABILITY QUALITY; DOGANAKSOY N, 1991, COMMUN STAT THEORY, V20, P2775, DOI 10.1080/03610929108830667; DOWNS JJ, 1993, COMPUT CHEM ENG, V17, P245, DOI 10.1016/0098-1354(93)80018-I; DUBUISSON B, 2001, SERIE PRODUCTIQUE; Duda R. O., 2001, PATTERN CLASSIFICATI; Dunia R, 1996, AICHE J, V42, P2797, DOI 10.1002/aic.690421011; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; FUCHS C, 1994, TECHNOMETRICS, V36, P182, DOI 10.2307/1270230; Good P, 2004, PERMUTATION PARAMETR; Harkat MF, 2006, J PROCESS CONTR, V16, P625, DOI 10.1016/j.jprocont.2005.09.007; HAWKINS DM, 1993, J QUAL TECHNOL, V25, P170; Hoffbeck JP, 1996, IEEE T PATTERN ANAL, V18, P763, DOI 10.1109/34.506799; Hotelling H., 1947, TECHNIQUES STAT ANAL, P111; Huber P. J., 1981, ROBUST STAT; JACKSON JE, 1985, COMMUN STAT-THEOR M, V14, P2657, DOI 10.1080/03610928508829069; John G.H., 1994, INT C MACH LEARN, P121; Kano M, 2002, COMPUT CHEM ENG, V26, P161, DOI 10.1016/S0098-1354(01)00738-4; KOBI A, 1994, THESIS I NATL POLYTE; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kourti T, 1996, J QUAL TECHNOL, V28, P409; Kruger U, 2004, J PROCESS CONTR, V14, P879, DOI 10.1016/j.jprocont.2004.02.002; Kulkarni A, 2005, COMPUT CHEM ENG, V29, P2128, DOI 10.1016/j.compchemeng.2005.06.006; LANGLEY P, 1992, NAT C ART INT; Lee JM, 2004, CHEM ENG SCI, V59, P2995, DOI 10.1016/j.ces.2004.04.031; LOWRY CA, 1992, TECHNOMETRICS, V34, P46, DOI 10.2307/1269551; LYMAN PR, 1995, COMPUT CHEM ENG, V19, P321, DOI 10.1016/0098-1354(94)00057-U; MACGREGOR JF, 1995, CONTROL ENG PRACT, V3, P403, DOI 10.1016/0967-0661(95)00014-L; MASON RL, 1995, J QUAL TECHNOL, V27, P99; MICHEAUX DLD, 2001, QUALITA, P143; MONTGOMERY D, 1996, COMMUNICATIONS STAT, V25, P2203; Montgomery DC., 1997, INTRO STAT QUALITY C; NOMIKOS P, 1994, AICHE J, V40, P1361, DOI 10.1002/aic.690400809; PAGE ES, 1954, BIOMETRIKA, V41, P100, DOI 10.1093/biomet/41.1-2.100; Patton R.J., 2000, ISSUES FAULT DIAGNOS; Perez A, 2006, INT J APPROX REASON, V43, P1, DOI 10.1016/j.ijar.2006.01.002; PIGNATIELLO JJ, 1990, J QUAL TECHNOL, V22, P173; Ricker NL, 1996, J PROCESS CONTR, V6, P205; Roberts S. W., 1959, TECHNOMETRICS, V1, P239, DOI 10.2307/1266443; Sahami M., 1996, 2 INT C KNOWL DISC D; Shannon E., 1948, BELL SYST TECH J, V27, P623; Shewhart W. A., 1931, EC CONTROL QUALITY M; Singhal A, 2006, J PROCESS CONTR, V16, P601, DOI 10.1016/j.jprocont.2005.10.005; Stamatis D.H., 2003, FAILURE MODE EFFECT; Thomaz CE, 2004, IEEE T CIRC SYST VID, V14, P214, DOI 10.1109/TCSVT.2003.821984; TIPLICA T, 2001, ACT C QUALITA ANN FR, P134; TIPLICA T, 2003, J EUROPEAN SYSTEMES, V37, P477, DOI 10.3166/jesa.37.477-500; TRACY ND, 1995, J QUAL TECHNOL, V27, P370; Vapnik V.N., 1995, NATURE STAT LEARNING; Venkatsubramanian V, 2003, COMPUT CHEM ENG, V27, P293, DOI 10.1016/S0098-1354(02)00160-6; Westerhuis JA, 2000, J CHEMOMETR, V14, P335, DOI 10.1002/1099-128X(200007/08)14:4<335::AID-CEM579>3.0.CO;2-F; Wise BM, 1996, J PROCESS CONTR, V6, P329, DOI 10.1016/0959-1524(96)00009-1; Yoon SY, 2001, J PROCESS CONTR, V11, P387, DOI 10.1016/S0959-1524(00)00008-1; Zhang G.X., 1984, WORLD QUAL C T AM SO, P175	63	16	18	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0959-1524		J PROCESS CONTR	J. Process Control	JUN	2008	18	5					479	490		10.1016/j.jprocont.2007.08.003		12	Automation & Control Systems; Engineering, Chemical	Automation & Control Systems; Engineering	305VA	WOS:000256204700006	
J	Cointault, F; Guerin, D; Guillemin, JP; Chopinet, B				Cointault, F.; Guerin, D.; Guillemin, J-P.; Chopinet, B.			In-field Triticum aestivum ear counting using colour-texture image analysis	NEW ZEALAND JOURNAL OF CROP AND HORTICULTURAL SCIENCE			English	Article						colour images; segmentation and classification methods; hybrid space; wheat counting	WEED DETECTION; CLASSIFICATION; SEGMENTATION; FEATURES	A colour and texture image analysis method based on the determination of a hybrid space was developed for a feasibility study for the (semi-)automatic counting of Triticum aestivum wheat ears to simplify manual counting. To detect ears, five textural and statistic features, and colour analyses were both used to give a new representation of the images within a specific space (hybrid space). This new representation was constructed with a priori knowledge about the images (especially the number of classes and training points), providing better recognition than in the standard RGB space (Red/Green/Blue). Classical methods of image segmentation and classification, combined with morphological information about wheat ears, were then applied to the new images to assist counting. Only 20 images were tested and classification accuracy ranged from 73% to 85%. The counting information, which needs to be validated on numerous images, will be in future combined with grain counting per ear and thousand-seed weight to obtain an estimation of wheat yields. The resulting information could prove to be relevant, for example, to allow French cooperatives to organise their harvest.	[Cointault, F.; Guerin, D.; Chopinet, B.] ENESAD, Dept Engn Sci, Agroengn Lab, F-21079 Dijon, France; [Guillemin, J-P.] ENESAD, Dept Agroenvironm, Weed Biol & Management Res Unit, F-21079 Dijon, France	Cointault, F (reprint author), ENESAD, Dept Engn Sci, Agroengn Lab, 26 Bd Docteur Petitjean,BP 87999, F-21079 Dijon, France.	f.cointault@enesad.fr					Benboudjema D, 2005, COMPUT VIS IMAGE UND, V99, P476, DOI 10.1016/j.cviu.2005.04.003; Burks TF, 2000, T ASAE, V43, P441; CONNERS RW, 1980, IEEE T PATTERN ANAL, V2, P204; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; El-Faki MS, 2000, T ASAE, V43, P1001; FOUCHER P, 2001, SEGMENTATION IMAGES; Foucherot I, 2004, PATTERN RECOGN, V37, P1661, DOI 10.1016/j.patcog.2004.02.010; GERMAIN C, 1995, P 5 INT C IM PROC AP, P435; GUERIN D, 2004, CSIMTA 04, P658; HANSEN MF, 2007, P SPIE MED IMAGING 2, V6512; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Heikkil J, 1997, IEEE COMP SOC C COMP, P1106, DOI DOI 10.1109/CVPR.1997.609468; LuJunWei, 2001, Transactions of the Chinese Society of Agricultural Engineering, V17, P153; MacQueen J. B., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; OMNES G, 2004, FRANCE AGRICOLE, V3023; REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/cviu.1993.1024; SHEARER SA, 1990, T ASAE, V33, P2037; Steward BL, 1999, T ASAE, V42, P1897; STEWARD BL, 1999, P ASAE CSAE SCGR ANN; Tian LF, 1998, COMPUT ELECTRON AGR, V21, P153, DOI 10.1016/S0168-1699(98)00037-4; Vandenbroucke N, 2003, COMPUT VIS IMAGE UND, V90, P190, DOI 10.1016/S1077-3142(03)00025-0; Vioix JB, 2004, J ELECTRON IMAGING, V13, P547, DOI 10.1117/1.1760756; YU W, 2005, P MIPPR 2005 SAR MUL, V6043	23	5	5	RSNZ PUBLISHING	WELLINGTON	PO BOX  598, WELLINGTON, 00000, NEW ZEALAND	0114-0671		NEW ZEAL J CROP HORT	N. Z. J. Crop Hortic. Sci.	JUN	2008	36	2					117	130				14	Agronomy; Horticulture	Agriculture	333SX	WOS:000258173800004	
J	Zipitria, I; Larranaga, P; Armananzas, R; Arruarte, A; Elorriaga, JA				Zipitria, Iraide; Larranaga, Pedro; Armananzas, Ruben; Arruarte, Ana; Elorriaga, Jon A.			What is behind a summary-evaluation decision?	BEHAVIOR RESEARCH METHODS			English	Article							TEXT; COMPREHENSION; KNOWLEDGE; SUMMARIZATION; CLASSIFIERS; REVISION; MEMORY; MODEL	Research in psychology has reported that, among the variety of possibilities for assessment methodologies, summary evaluation offers a particularly adequate context for inferring text comprehension and topic understanding. However, grades obtained in this methodology are hard to quantify objectively. Therefore, we carried out an empirical study to analyze the decisions underlying human summary-grading behavior. The task consisted of expert evaluation of summaries produced in critically relevant contexts of summarization development, and the resulting data were modeled by means of Bayesian networks using an application called Elvira, which allows for graphically observing the predictive power (if any) of the resultant variables. Thus, in this article, we analyzed summary-evaluation decision making in a computational framework.	[Zipitria, Iraide; Larranaga, Pedro; Armananzas, Ruben; Arruarte, Ana; Elorriaga, Jon A.] Univ Basque Country, Dept Social Psychol & Behav Sci Methodol, Donostia San Sebastian 20018, Basque Country, Spain	Zipitria, I (reprint author), Univ Basque Country, Dept Social Psychol & Behav Sci Methodol, Tolosa Etorbidea 70, Donostia San Sebastian 20018, Basque Country, Spain.	iraide.zipitria@ehu.es	Armananzas, Ruben/C-2735-2013; Larranaga, Pedro/F-9293-2013	Armananzas, Ruben/0000-0003-4049-0000; 			Chung GKWK, 2003, AUTOMATED ESSAY SCORING: A CROSS-DISCIPLINARY PERSPECTIVE, P23; Bandura A., 1977, SOCIAL LEARNING THEO; Bartlett F. C, 1932, REMEMBERING STUDY EX; Bayes T., 1763, PHILOS T ROY SOC LON, V53, P370, DOI DOI 10.1098/RSBL.1763.0053; Blanco R, 2005, J BIOMED INFORM, V38, P376, DOI 10.1016/j.jbi.2005.05.004; Bower G. H., 1981, THEORIES LEARNING; Bransford J.D., 1990, DIMENSIONS THINKING, P381; Breiman L, 1984, CLASSIFICATION REGRE; BULL S, 1995, 7 WORLD C ART INT ED; Burstein J, 2003, AUTOMATED ESSAY SCORING: A CROSS-DISCIPLINARY PERSPECTIVE, P209; CASSANY D, 1993, REPARAR ESCRITURA DI; CATLETT J, 1991, LECT NOTES ARTIF INT, V482, P164; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; Cizek GJ, 2003, AUTOMATED ESSAY SCORING: A CROSS-DISCIPLINARY PERSPECTIVE, P125; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Cook R., 1994, 4 INT C US MOD HYANN, P145; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; DIMITROVA V, 2003, INT J ARTIFICIAL INT, V13, P35; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; Elosúa M Rosa, 2002, Span J Psychol, V5, P90; Elvira Consortium, 2002, P 1 EUR WORKSH PROB, P222; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Fisher RA, 1936, ANN EUGENIC, V7, P179; FITZGERALD J, 1987, REV EDUC RES, V57, P481, DOI 10.3102/00346543057004481; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GARNER R, 1982, J EDUC RES, V75, P275; GARNER R, 1987, EDUC PSYCHOL, V22, P299, DOI 10.1207/s15326985ep2203&4_6; Genesee F., 1996, CLASSROOM BASED EVAL; Glazer EM, 2006, TEACH TEACH EDUC, V22, P179, DOI 10.1016/j.tate.2005.09.004; Glymour C., 2001, MINDS ARROWS BAYES N; GOLDBERG GL, 1999, ED ASSESSMENT, V6, P257; HOLLAND JH, 1975, ADAPTATION NATURAL A; Hosmer DW, 1989, APPL LOGISTIC REGRES; INOUE AB, 2005, ASSESSING WRITING, V9, P208; JENSEN F, 2001, BAYESIAN NETWORKS DE; Kerber R., 1992, P 10 NAT C ART INT, P123; KINTSCH W, 1978, PSYCHOL REV, V85, P363, DOI 10.1037//0033-295X.85.5.363; Kirby J. R., 1991, EDUC PSYCHOL, V11, P297, DOI DOI 10.1080/0144341910110306; Kozminsky E., 1986, J RES READ, V9, P3, DOI 10.1111/j.1467-9817.1986.tb00107.x; KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583, DOI 10.2307/2280779; Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037//0033-295X.104.2.211; Langley P., 1994, P 10 C UNC ART INT, P399; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; LEHNERT WG, 1981, COGNITIVE SCI, V5, P293, DOI 10.1207/s15516709cog0504_1; LONG J, 1978, LANGUAGE INTERPRETAT, P273; Lorenzo MAGNANI, 2004, FOUND SCI, V9, P219, DOI 10.1023/B:FODA.0000042841.18507.22; Magnani L., 2001, ABDUCTION REASON SCI; MANELIS L, 1984, J STRUCT LEARN, V8, P29; Mani I., 1999, ADV AUTOMATIC TEXT S; MINSKY M, 1961, P IRE, V49, P8, DOI 10.1109/JRPROC.1961.287775; Neapolitan R, 2003, LEARNING BAYESIAN NE; Page EB, 2003, AUTOMATED ESSAY SCORING: A CROSS-DISCIPLINARY PERSPECTIVE, P43; Pearl J., 1988, PROBABILISTIC REASON, p[505, 506, 507, 524]; PEARL J, 1987, ARTIF INTELL, V33, P173, DOI 10.1016/0004-3702(87)90034-8; Peirce CS, 1955, PHILOS WRITINGS PEIR, P150; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; Robinson B., 1995, COLL TEACHING, V43, P57; Rumelhart D. E., 1975, REPRESENTATION UNDER, P185; SCHANK RC, 1980, AM J COMPUTATIONAL L, V6, P13; Scheines R., 1993, CAUSATION PREDICTION; Sherrard C., 1989, SYSTEM, V17, P1, DOI 10.1016/0346-251X(89)90055-9; SHIMONY SE, 1990, P 6 ANN C UNC ART IN, P185; STONE M, 1974, J R STAT SOC B, V36, P111; SYMONS S, 1993, READ RES QUART, V28, P250, DOI 10.2307/747997; TAYLOR BM, 1982, J EDUC PSYCHOL, V74, P323, DOI 10.1037/0022-0663.74.3.323; THORNDYKE PW, 1977, COGNITIVE PSYCHOL, V9, P77, DOI 10.1016/0010-0285(77)90005-6; VIRVOU M, 2001, INT J ARTIFICIAL INT, V12, P185; Whittaker J., 1990, GRAPHICAL MODELS APP, P507; WINOGRAD PN, 1984, READ RES QUART, V19, P404, DOI 10.2307/747913; ZIPITRIA I, 2006, P 8 INT C INT TUT SY, P595	71	0	0	PSYCHONOMIC SOC INC	AUSTIN	1710 FORTVIEW RD, AUSTIN, TX 78704 USA	1554-351X		BEHAV RES METHODS	Behav. Res. Methods	MAY	2008	40	2					597	612		10.3758/BRM.40.2.597		16	Psychology, Mathematical; Psychology, Experimental	Psychology	320IN	WOS:000257227000028	
J	Li, HQ; Dai, XB; Zhao, XC				Li, Haiquan; Dai, Xinbin; Zhao, Xuechun			A nearest neighbor approach for automated transporter prediction and categorization from protein sequences	BIOINFORMATICS			English	Article							TRANSMEMBRANE TOPOLOGY; COMPREHENSIVE DATABASE; MEMBRANE-PROTEINS; CLASSIFICATION; FAMILY; RECOGNITION; RESOURCE; CHANNELS; PROGRAM; BIOLOGY	Motivation: Membrane transport proteins play a crucial role in the import and export of ions, small molecules or macromolecules across biological membranes. Currently, there are a limited number of published computational tools which enable the systematic discovery and categorization of transporters prior to costly experimental validation. To approach this problem, we utilized a nearest neighbor method which seamlessly integrates homologous search and topological analysis into a machine-learning framework. Results: Our approach satisfactorily distinguished 484 transporter families in the Transporter Classification Database, a curated and representative database for transporters. A five-fold cross-validation on the database achieved a positive classification rate of 72.3 on average. Furthermore, this method successfully detected transporters in seven model and four non-model organisms, ranging from archaean to mammalian species. A preliminary literature-based validation has cross-validated 65.8 of our predictions on the 11 organisms, including 55.9 of our predictions overlapping with 83.6 of the predicted transporters in TransportDB. Availability and Supplementary information: http://www.w3.org/1999/xlink">http://bioinfo.noble.org/manuscript-support/transporter/ Contact: pzhao@noble.org.	[Li, Haiquan; Dai, Xinbin; Zhao, Xuechun] Samuel Roberts Noble Fdn Inc, Div Plant Biol, Bioinformat Lab, Ardmore, OK 73401 USA	Zhao, XC (reprint author), Samuel Roberts Noble Fdn Inc, Div Plant Biol, Bioinformat Lab, 2510 Sam Noble Pkwy, Ardmore, OK 73401 USA.						ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Apweiler R, 2001, Brief Bioinform, V2, P9, DOI 10.1093/bib/2.1.9; Ashburner M, 2000, NAT GENET, V25, P25; Bejerano G, 2001, BIOINFORMATICS, V17, P23, DOI 10.1093/bioinformatics/17.1.23; Busch W, 2002, CRIT REV BIOCHEM MOL, V37, P287, DOI 10.1080/10409230290771528; Chang AB, 2004, MOL MEMBR BIOL, V21, P171, DOI 10.1080/09687680410001720830; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dibrov P, 1998, FEBS LETT, V424, P1, DOI 10.1016/S0014-5793(98)00119-7; DOOLITTLE RF, 1981, SCIENCE, V214, P149, DOI 10.1126/science.7280687; Eskin E, 2003, J COMPUT BIOL, V10, P187, DOI 10.1089/106652703321825964; Haft DH, 2001, NUCLEIC ACIDS RES, V29, P41, DOI 10.1093/nar/29.1.41; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; Heil B, 2006, BIOINFORMATICS, V22, P1562, DOI 10.1093/bioinformatics/btl132; HENIKOFF S, 1994, GENOMICS, V19, P97, DOI 10.1006/geno.1994.1018; Hofmann K., 1993, BIOL CHEM HOPPESEYLE, V374, P166; Horton P, 1997, Proc Int Conf Intell Syst Mol Biol, V5, P147; John B, 2004, PROTEIN SCI, V13, P54, DOI 10.1110/ps.03335004; KROGH A, 1994, J MOL BIOL, V235, P1501, DOI 10.1006/jmbi.1994.1104; Leonardi FG, 2006, BIOINFORMATICS, V22, P1302, DOI 10.1093/bioinformatics/bt/088; Lin HH, 2006, PROTEINS, V62, P218, DOI 10.1002/prot.20605; Paulsen IT, 1998, J MOL BIOL, V277, P573, DOI 10.1006/jmbi.1998.1609; Pruitt KD, 2005, NUCLEIC ACIDS RES, V33, pD501, DOI 10.1093/nar/gki025; Ren QH, 2004, NUCLEIC ACIDS RES, V32, pD284, DOI 10.1093/nar/gkh016; Ren QH, 2007, NUCLEIC ACIDS RES, V35, pD274, DOI 10.1093/nar/gkl925; RIGAUD JL, 1995, BBA-BIOENERGETICS, V1231, P223, DOI 10.1016/0005-2728(95)00091-V; Saier MH, 2000, MICROBIOL MOL BIOL R, V64, P354, DOI 10.1128/MMBR.64.2.354-411.2000; Saier MH, 2006, NUCLEIC ACIDS RES, V34, pD181, DOI 10.1093/nar/gkj001; SAKMANN B, 1984, ANNU REV PHYSIOL, V46, P455, DOI 10.1146/annurev.physiol.46.1.455; SCHAFFER C, 1993, MACH LEARN, V13, P135, DOI 10.1023/A:1022639714137; Schwacke R, 2003, PLANT PHYSIOL, V131, P16, DOI 10.1104/pp.011577; Sonnhammer ELL, 1997, PROTEINS, V28, P405, DOI 10.1002/(SICI)1097-0134(199707)28:3<405::AID-PROT10>3.0.CO;2-L; Tusnady GE, 2001, BIOINFORMATICS, V17, P849, DOI 10.1093/bioinformatics/17.9.849; YAN Q, 2003, MEMBRANE TRANSPORTER, V227; Zdobnov EM, 2001, BIOINFORMATICS, V17, P847, DOI 10.1093/bioinformatics/17.9.847; Zhai YF, 2001, J MOL MICROB BIOTECH, V3, P501; Zhou XF, 2003, J MOL MICROB BIOTECH, V5, P7, DOI 10.1159/000068719	36	12	14	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	MAY 1	2008	24	9					1129	1136		10.1093/bioinformatics/btn099		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	293DB	WOS:000255313900002	
J	Tarakanov, AO				Tarakanov, Alexander O.			Immunocomputing for intelligent intrusion detection	IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE			English	Article							FORMAL IMMUNE NETWORK; PATTERN-RECOGNITION; RECEPTOR MOSAICS; TRANSFORM; SYSTEMS; MODEL	Based on immunocomputing, this paper describes an approach to intrusion detection. The approach includes both low-level signal processing (feature extraction) and high-level (intelligent) pattern recognition. The key model is the formal immune network (FIN) including apoptosis (programmed cell death) and immunization, both controlled by cytokines (messenger proteins). Such FIN can be formed from the network traffic signals using discrete tree transforms, singular value decomposition, and the proposed index of inseparability as a measure of quality of FIN. Recent results suggest that the approach outperforms (by training time and accuracy) state-of-the-art approaches of computational intelligence.	Russian Acad Sci, Moscow 117901, Russia	Tarakanov, AO (reprint author), Russian Acad Sci, Moscow 117901, Russia.						Adamatzky A., 1994, IDENTIFICATION CELLU; Agnati LF, 2005, J MOL NEUROSCI, V26, P193, DOI 10.1385/JMN/26:02:193; Agnati LF, 2005, BIOSYSTEMS, V80, P165, DOI 10.1016/j.biosystems.2004.11.004; AGNATI LF, 2008, BRAIN RES R IN PRESS; Atreas ND, 2004, COMP FUNCT GENOM, V5, P69, DOI 10.1002/cfg.367; Atreas ND, 2003, LECT NOTES COMPUT SC, V2787, P111; BAY SD, 1999, UCI KDD ARCH; Chao DL, 2004, J THEOR BIOL, V228, P227, DOI 10.1016/j.jtbi.2003.12.011; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasgupta D., 1999, ARTIFICIAL IMMUNE SY; DASGUPTA D, 2005, ENHANCING COMPUTER S, P165; Dasgupta D, 2006, IEEE COMPUT INTELL M, V1, P40, DOI 10.1109/MCI.2006.329705; Dasgupta D, 2004, LECT NOTES COMPUT SC, V3239, P1; Goncharova LB, 2005, LECT NOTES COMPUT SC, V3627, P72; Goncharova LB, 2008, CURR MED CHEM, V15, P210; Goncharova LB, 2007, BRAIN RES REV, V55, P155, DOI 10.1016/j.brainresrev.2007.02.003; Horn R.A., 1986, MATRIX ANAL; Johnson JE, 2005, LECT NOTES COMPUT SC, V3685, P129; Karanikas C, 2003, CHAOS SOLITON FRACT, V17, P195, DOI 10.1016/S0960-0779(02)00341-7; Kozyrev S.V., 2002, IZV MATH+, V66, p[149, 367], DOI 10.1070/IM2002v066n02ABEH000381; Renyi A., 1961, P 4 BERK S MATH STAT, V1, P547; Tarakanov A, 2007, INT J UNCONV COMPUT, V3, P123; TARAKANOV A, 2007, ADV APPL SELF ORG SY, P271; Tarakanov A, 2007, J CELL AUTOM, V2, P39; TARAKANOV A, 2007, P 1 IEEE S FDN COMP, P503; TARAKANOV A, 2002, KYBERNETES, V31, P394; TARAKANOV A, 2007, RADIOSYSTEMS, V106, P90; Tarakanov AO, 2005, LECT NOTES COMPUT SC, V3685, P394; TARAKANOV AO, 2007, LNGC, V14, P252; TARAKANOV AO, 2003, IMMUNOCOMPUTING; TARAKANOV AO, 2005, INT J UNCONV COMPUT, V1, P357; Tarakanov AO, 2007, COMM COM INF SC, V1, P308, DOI 10.1007/978-3-540-73986-9_26; Tarakanov AO, 2004, LECT NOTES COMPUT SC, V3239, P236; Tarakanov AO, 2005, LECT NOTES ARTIF INT, V3630, P510; Timmis J., 2002, ARTIFICIAL IMMUNE SY; ZHAO W, 2005, ACM SIGACT NEWS, V36, P14, DOI 10.1145/1107523.1107532	36	5	9	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1556-603X		IEEE COMPUT INTELL M	IEEE Comput. Intell. Mag.	MAY	2008	3	2					22	30		10.1109/MCI.2008.919069		9	Computer Science, Artificial Intelligence	Computer Science	342ES	WOS:000258768000006	
J	Millett, RP				Millett, Ronald P.			Memory-based language processing	JOURNAL OF QUANTITATIVE LINGUISTICS			English	Book Review							CLASSIFICATION		[Millett, Ronald P.] Brigham Young Univ, Dept Linguist, Provo, UT 84602 USA	Millett, RP (reprint author), Brigham Young Univ, Dept Linguist, Provo, UT 84602 USA.						ALLEN J, 1995, NATURAL LANGUAGE UND; Barlow Michael, 2000, USAGE BASED MODELS L; BOD R, 1998, GRAMMER EXPERIENCE B; BUCHHOLZ S, 1999, EMNLP VLC 99 JOINT S; Carl M., 2003, TEXT SPEECH LANGUAGE, V21; Cohen W. W., 1995, P 12 INT C MACH LEAR, P115; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daelemans W., 2005, MEMORY BASED LANGUAG; DAELEMANS W, 2004, TIMBL TILBURG MEMORY; Daelemans W, 1997, ARTIF INTELL REV, V11, P407, DOI 10.1023/A:1006506017891; Daelemans Walter, 2002, ANALOGICAL MODELING, P157; DESAUSSURE F, 1966, COURS LINGUISTIQUE G; EDDINGTON D, 2002, ANALOGICAL MODELING, P141; Fix E., 1952, DISCRIMINATORY ANAL; KROTT A, 2002, ANALOGICAL MODELING, P181; MILLETT R, 2006, AUTOMATIC HOLISTIC S; PALMER FR, 1969, SELECTED PAPERS JR F; RATNAPARKHI A, 1994, WORKSH HUMAN LANGUAG; Skousen R., 1989, ANALOGICAL MODELING; Skousen Royal, 2002, ANALOGICAL MODELING; VANDENBOSCH A, 2002, ANALOGICAL MODELING, P209; *ILK, 0402 ILK TILB U	22	0	0	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXFORDSHIRE, ENGLAND	0929-6174		J QUANT LINGUIST	J. Quant. Linguist.	MAY	2008	15	2					212	219		10.1080/09296170801961934		8	Linguistics; Language & Linguistics	Linguistics	315KL	WOS:000256877500005	
J	Huang, CC; Chang, HY; Yang, CH				Huang, Chi-Chun; Chang, Hsin-Yun; Yang, Cheng-Hong			A novel grey-based feature ranking method for feature subset selection	JOURNAL OF THE CHINESE INSTITUTE OF ENGINEERS			English	Article						pattern classification; feature subset selection; feature ranking method	CLASSIFICATION; ALGORITHMS	In this paper, a novel grey-based feature ranking method for feature subset selection is proposed. The classification effectiveness of each attribute of a specific classification problem is proposed and then each attribute can be ranked. Features with higher classification effectiveness are more important and relevant and thus considered as the final feature subset for pattern classification. Experiments performed on various application domains are reported to demonstrate the performance of the proposed approach. The proposed approach yields better performance than other existing feature subset selection methods and is helpful for improving the classification accuracy in pattern classification.	[Huang, Chi-Chun] Natl Kaohsiung Marine Univ, Dept Informat Management, Kaohsiung 811, Taiwan; [Chang, Hsin-Yun] Chin Min Inst Technol, Dept Business Adm, Tou Fen, Miao Li, Taiwan; [Chang, Hsin-Yun] Natl Kaohsiung Normal Univ, Dept Ind Technol Educ, Kaohsiung 802, Taiwan; [Yang, Cheng-Hong] Natl Kaohsiung Univ Appl Sci, Dept Comp Sci & Informat Engn, Kaohsiung 80778, Taiwan	Huang, CC (reprint author), Natl Kaohsiung Marine Univ, Dept Informat Management, 142 Hai Jhuan RD, Kaohsiung 811, Taiwan.	cchuang@mail.nkmu.edu.tw					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake CL, 1998, UCI REPOSITORY MACHI; Cawley GC, 2003, PATTERN RECOGN, V36, P2585, DOI 10.1016/S0031-3203(03)00136-5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B.V., 1990, NEAREST NEIGHBOR NN; Dash M., 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; DENG J, 1984, SOCIAL SCI CHINA, V6, P47; Deng Julong, 1989, Journal of Grey Systems, V1; DENG JL, 1989, J GREY SYSTEM, V2, P103; Duda R., 1973, PATTERN CLASSIFICATI; Hall M., 1998, THESIS U WAIKATO NZ; Huang CC, 2006, PATTERN RECOGN, V39, P1979, DOI 10.1016/j.patcog.2006.05.013; Huang CC, 2006, APPL INTELL, V25, P243, DOI 10.1007/s10489-006-0105-0; Inza I, 2001, INT J APPROX REASON, V27, P143, DOI 10.1016/S0888-613X(01)00038-X; KOHAVI R, 1997, ARTIF INTELL, V97, P1; Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491; Liu H., 1996, P 13 INT C MACH LEAR, P319; Liu H., 1998, FEATURE SELECTION KN; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; STONE M, 1974, J R STAT SOC B, V36, P111; Su YM, 2000, J CHIN INST ENG, V23, P653, DOI 10.1080/02533839.2000.9670586	21	0	0	CHINESE INST ENGINEERS	TAIPEI	#1, 4TH FL, SEC 2, JEN-AI RD, TAIPEI 10019, TAIWAN	0253-3839		J CHIN INST ENG	J. Chin. Inst. Eng.	MAY	2008	31	3					509	514		10.1080/02533839.2008.9671405		6	Engineering, Multidisciplinary	Engineering	332IN	WOS:000258076800015	
J	Caulier, Y; Spinnler, K; Wittenberg, T; Bourennane, S				Caulier, Yannick; Spinnler, Klaus; Wittenberg, Thomas; Bourennane, Salah			Specific features for the analysis of fringe images	OPTICAL ENGINEERING			English	Article						fringe analysis; nondestructive testing; pattern recognition; illumination	HOLOGRAPHIC-INTERFEROMETRY; CONVOLUTION PROCESSORS; WAVELET FILTERS; FAULT-DETECTION; PATTERNS	In optical nondestructive testing, a novel solution is presented for fault detection based on the interpretation of fringe images. These images can be acquired using different optical methods, such as structured lighting or interferometry. We propose a set of eight special features adapted to the problem of surface inspection using structured illumination. These characteristics are combined with six further features specially developed for the classification of faults using interferometric images. We apply two kinds of decision rules: the Bayesian and the nearest neighbor classifiers. The proposed features are evaluated using a noisy and a noise-free image data set. All patterns were obtained by means of structured lighting. Concerning the noisy data set, we obtain better classification rates when all the 14 features are used in combination with a one-nearest-neighbor classifier. In case of a noise-free data set, we show that similar classification rates are obtained when the 14 features or only the 8 specific features are involved. The methods described are designed to address a broad range of optical nondestructive applications involving the interpretation and classification of fringe patterns. (c) 2008 Society of Photo-Optical Instrumentation Engineers.	[Caulier, Yannick; Spinnler, Klaus; Wittenberg, Thomas] Fraunhofer Inst, D-91058 Erlangen, Germany; [Bourennane, Salah] Fresnel Inst, Ecole Cent Marseille, F-13397 Marseille 20, France	Caulier, Y (reprint author), Fraunhofer Inst, Wolfsmantel 33, D-91058 Erlangen, Germany.	yannick.caulier@iis.fraunhofer.de	Bourennane, Salah/F-2928-2010				CAULIER Y, NEUES SYSTEM ZURSCHN; CAULIER Y, EURASIP J A IN PRESS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; FEIN H, 1997, IND PHYS, V3, P37; Hall-Holt O., 2001, 8 IEEE INT C COMP VI, V2, P359; Juptner WP, 1994, P SOC PHOTO-OPT INS, V2342, P16; Kammel S., 2004, THESIS U KARLSRUHE T; KOZUCHI J, 2002, P 19 IEEE C INSTR ME, V1, P369; Kruger S, 2000, P SOC PHOTO-OPT INS, V3966, P145, DOI 10.1117/12.380068; Kruger S, 2001, J ELECTRON IMAGING, V10, P228, DOI 10.1117/1.1318908; LEENDERT.JA, 1970, J PHYS E SCI INSTRUM, V3, P214, DOI 10.1088/0022-3735/3/3/312; Li XD, 2000, OPT ENG, V39, P2821, DOI 10.1117/1.1308485; MARAGOS PA, 1986, IEEE T ACOUST SPEECH, V34, P1228, DOI 10.1109/TASSP.1986.1164959; MONKS TP, 1992, P IEEE 4 INT C IM PR, P327; Niemann H, 2003, KLASSIFIKATION MUSTE; Osten W., 1993, P SOC PHOTO-OPT INS, V2004, P256; QIAN K, 2005, MEASUREMENT SCI TECH, V15, P1582; SHELLABEAR MC, 1991, OPT LASER ENG, V15, P43, DOI 10.1016/0143-8166(91)90005-E; SIROHI RS, 2005, FRINGE 2005, P2; VIALARD A, 1999, SIMPLIFICATION CONTO; VILLAIN J, 1991, IEEE T COMPON HYBR, V14, P766, DOI 10.1109/33.105131; WANG WN, 1995, P ELECTR C, P835; Winkelbach S., 2002, LECT NOTES COMPUTER, V2449, P240; Witten I. H., 2005, DATA MINING; YAMAGUCHI I, 2005, FRINGE 2005, P396; ZHI H, 1992, 11 INT C PATT REC C, V3, P105	27	0	0	SPIE-SOC PHOTOPTICAL INSTRUMENTATION ENGINEERS	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA	0091-3286		OPT ENG	Opt. Eng.	MAY	2008	47	5							057201	10.1117/1.2927463		11	Optics	Optics	320IO	WOS:000257227100035	
J	Fang, YP; Feng, Y; Li, ML				Fang, Yaping; Feng, Yi; Li, Menglong			Optimal QSAR analysis of the carcinogenic activity of aromatic and heteroaromatic Amines	QSAR & COMBINATORIAL SCIENCE			English	Article						amines; carcinogenic activity; Genetic Algorithm (GA); Quantitative Structure-Activity Relationship (QSAR); Support Vector Regression (SVR)	PROTEIN SUBCELLULAR LOCATION; STRUCTURAL CLASS PREDICTION; PRINCIPAL COMPONENT REGRESSION; LIPOPHILICITY POTENTIAL HMLP; SECONDARY STRUCTURE-CONTENT; SUPPORT VECTOR MACHINES; GENETIC ALGORITHMS; ENSEMBLE CLASSIFIER; FEATURE-SELECTION; HYDROPATHIC FACTORS	Aromatic and heteroaromatic amines are widely used in industrial chemicals and can be found in cooked foods and in tobacco smoke. In this study, Quantitative Structure-Activity Relationships (QSARs) are developed that correlate the observed carcinogenic activities of 80 aromatic and heteroaromatic amines. Principal Component Regression and stepwise linear regression techniques have been applied to construct the QSAR models. The performance of these two models is slightly superior compared to the previous reported based on the same dataset by multiple linear regression techniques. To improve the performance, Support Vector Regression (SVR) has been used to construct the QSARs and Genetic Algorithm (GA) has been used to select the most informational descriptors. Additionally, by introducing the concept of the weighting technique into the model, a new SVR, optimized sample-weighted SVR is proposed. The optimal weighted coefficient is 0.2. The results suggest that approaches using GA selecting descriptors and weighting the descriptors can effectively improve the performance of the SVR models. The optimal Root Mean Square Error in Prediction is 0.799, which is relative smaller than other models. Jackknife-testing procedure has been used to validate the models. The results indicate that the selected descriptors by GA and weighting technique are important and necessary to improve the performance of QSAR models by SVR.	[Fang, Yaping; Feng, Yi; Li, Menglong] Sichuan Univ, Coll Chem, State Key Lab Biotherapy, Chengdu 610064, Peoples R China	Fang, YP (reprint author), Sichuan Univ, Coll Chem, State Key Lab Biotherapy, Chengdu 610064, Peoples R China.	liml@scu.edu.cn					Asikainen AH, 2004, ENVIRON SCI TECHNOL, V38, P6724, DOI 10.1021/es049665h; Barros AS, 1998, CHEMOMETR INTELL LAB, V40, P65, DOI 10.1016/S0169-7439(98)00002-1; Benigni R, 1998, ENVIRON MOL MUTAGEN, V32, P75, DOI 10.1002/(SICI)1098-2280(1998)32:1<75::AID-EM9>3.0.CO;2-A; Benigni R, 2000, CHEM REV, V100, P3697, DOI 10.1021/cr9901079; Bhat KL, 2005, QSAR COMB SCI, V24, P831, DOI 10.1002/qsar.200430921; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2006, J PROTEOME RES, V5, P3420, DOI 10.1021/pr060404b; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; Chou KC, 2007, J CELL BIOCHEM, V100, P665, DOI 10.1002/jcb.21096; Chou K.C., 2006, FRONTIERS MED CHEM, V3, P455; Chou KC, 2006, J PROTEOME RES, V5, P1888, DOI 10.1021/pr060167c; Chou KC, 2007, BIOCHEM BIOPH RES CO, V357, P633, DOI 10.1016/j.bbrc.2007.03.162; Chou KC, 2006, CURR MED CHEM, V13, P3263, DOI 10.2174/092986706778773077; Chou KC, 1996, ANAL BIOCHEM, V233, P1, DOI 10.1006/abio.1996.0001; Chou KC, 2004, CURR MED CHEM, V11, P2105; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 1999, J PROTEIN CHEM, V18, P473, DOI 10.1023/A:1020696810938; Chou KC, 2007, J PROTEOME RES, V6, P1728, DOI 10.1021/pr060635i; Chou KC, 2006, BIOCHEM BIOPH RES CO, V347, P150, DOI 10.1016/j.bbrc.2006.06.059; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Depczynski U, 2000, ANAL CHIM ACTA, V420, P217, DOI 10.1016/S0003-2670(00)00893-X; Du QS, 2006, J BIOMOL STRUCT DYN, V23, P635; Du QS, 2005, J COMPUT CHEM, V26, P461, DOI 10.1002/jcc.20174; DU QS, 2007, J COMPUT CHEM; Du QS, 2007, J COMPUT CHEM, V28, P2043, DOI 10.1002/jcc.20732; Du QS, 2006, J COMPUT CHEM, V27, P685, DOI 10.1002/jcc.20369; Eriksson L, 2000, J CHEMOMETR, V14, P599, DOI 10.1002/1099-128X(200009/12)14:5/6<599::AID-CEM619>3.0.CO;2-8; Felton JS, 1999, CANCER LETT, V143, P127, DOI 10.1016/S0304-3835(99)00141-X; Franke R, 2001, CARCINOGENESIS, V22, P1561, DOI 10.1093/carcin/22.9.1561; Guo YZ, 2006, AMINO ACIDS, V30, P397, DOI 10.1007/s00726-006-0332-z; Hatch FT, 2001, ENVIRON MOL MUTAGEN, V38, P268, DOI 10.1002/em.10028; Haykin S., 1999, NEURAL NETWORKS COMP, P318; Hemmateenejad B, 2004, J CHEMOMETR, V18, P475, DOI 10.1002/cem.891; HSIEH KL, 2007, EXPERT SYS APPL, V34, P717; JOUANRIMBAUD D, 1995, ANAL CHEM, V67, P4295, DOI 10.1021/ac00119a015; Kedarisetti KD, 2006, BIOCHEM BIOPH RES CO, V348, P981, DOI 10.1016/j.bbrc.2006.07.141; Kim D, 2004, BIOCHEMISTRY-US, V43, P981, DOI 10.1021/bi035593f; Knize MG, 2006, ENVIRON MOL MUTAGEN, V47, P132, DOI 10.1002/em.20177; Leardi R, 1998, CHEMOMETR INTELL LAB, V41, P195, DOI 10.1016/S0169-7439(98)00051-3; LEARDI R, 1992, J CHEMOMETR, V6, P267, DOI 10.1002/cem.1180060506; LEARDI R, 1994, J CHEMOMETR, V8, P65, DOI 10.1002/cem.1180080107; Li YK, 2007, TALANTA, V72, P217, DOI 10.1016/j.talanta.2006.10.022; Liu WM, 1999, PROTEIN ENG, V12, P1041, DOI 10.1093/protein/12.12.1041; Liu WM, 1998, J PROTEIN CHEM, V17, P209, DOI 10.1023/A:1022576400291; LU WC, 2005, QSAR COMB SCI, V9, P1021; Lu X., 2007, CHEMOM INTELL LAB SY, V85, P140; Lubec G, 2005, PROG NEUROBIOL, V77, P90, DOI 10.1016/j.pneurobio.2005.10.001; MALINOWSKI ER, 2002, FACTOR ANAL CHEM, P224; Maran U, 1999, QUANT STRUCT-ACT REL, V18, P3, DOI 10.1002/(SICI)1521-3838(199901)18:1<03::AID-QSAR3>3.0.CO;2-P; Martens H., 1996, MULTIVARIATE CALIBRA; Novak M, 2002, CHEM RES TOXICOL, V15, P1495, DOI 10.1021/tx025584s; Rasulev BF, 2005, QSAR COMB SCI, V24, P1056, DOI 10.1002/qsar.200430013; Sasaki JC, 2002, MUTAT RES-FUND MOL M, V506, P79, DOI 10.1016/S0027-5107(02)00154-9; Shen HB, 2007, BIOPOLYMERS, V85, P233, DOI 10.1002/bip.20640; Shen HB, 2007, BIOCHEM BIOPH RES CO, V355, P1006, DOI 10.1016/j.bbrc.2007.02.071; Shen HB, 2007, PROTEIN ENG DES SEL, V20, P39, DOI 10.1093/protein-gzl053; Shen HB, 2006, J THEOR BIOL, V240, P9, DOI 10.1016/j.jtbi.2005.08.016; SUTTER JM, 1992, J CHEMOMETR, V6, P217, DOI 10.1002/cem.1180060406; TAN F, 2006, AMINO ACIDS, P1; Turesky RJ, 2002, MUTAT RES-FUND MOL M, V506, P187, DOI 10.1016/S0027-5107(02)00165-3; Vapnik V., NATURE STAT LEARNING; WEN Z, 2006, AMINO ACIDS, V32, P277; WOLD S, 1983, J CHEM INF COMP SCI, V23, P6, DOI 10.1021/ci00037a002; Xu L, 2007, TALANTA, V71, P561, DOI 10.1016/j.talanta.2006.04.039; Yao XJ, 2004, J CHEM INF COMP SCI, V44, P1257, DOI 10.1021/ci049965i; Zhang W, 2000, J CHEM INF COMP SCI, V40, P185; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365	68	1	1	WILEY-V C H VERLAG GMBH	WEINHEIM	PO BOX 10 11 61, D-69451 WEINHEIM, GERMANY	1611-020X		QSAR COMB SCI	QSAR Comb. Sci.	MAY	2008	27	5					543	554		10.1002/qsar.200710077		12	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Interdisciplinary Applications; Pharmacology & Pharmacy	Pharmacology & Pharmacy; Chemistry; Computer Science	305WQ	WOS:000256208900002	
J	Wu, K; Lu, BL; Utiyama, M; Isahara, H				Wu, Ke; Lu, Bao-Liang; Utiyama, Masao; Isahara, Hitoshi			An empirical comparison of min-max-modular k-NN with different voting methods to large-scale text categorization	SOFT COMPUTING			English	Article; Proceedings Paper	4th International Symposium on Neural Networks (ISNN 2007)	JUN 03-07, 2007	Nanjing, PEOPLES R CHINA	Natl Nat Sci Fdn China, KC Wong Educ Fdn, SE Univ China, Chinese Univ Hong Kong, Univ Illinois, Chicago		text categorization; k-NN algorithm; min-max-modular k-NN; parallel computing	PATTERN-CLASSIFICATION; NEURAL-NETWORK; TASK DECOMPOSITION	Text categorization refers to the task of assigning the pre-defined classes to text documents based on their content. k-NN algorithm is one of top performing classifiers on text data. However, there is little research work on the use of different voting methods over text data. Also, when a huge number of training data is available online, the response speed slows down, since a test document has to obtain the distance with each training data. On the other hand, min-max-modular k-NN (M-3-k-NN) has been applied to large-scale text categorization. M-3-k-NN achieves a good performance and has faster response speed in a parallel computing environment. In this paper, we investigate five different voting methods for k-NN and M-3-k-NN. The experimental results and analysis show that the Gaussian voting method can achieve the best performance among all voting methods for both k-NN and M-3-k-NN. In addition, M-3-k-NN uses less k-value to achieve the better performance than k-NN, and thus is faster than k-NN in a parallel computing environment.	[Wu, Ke; Lu, Bao-Liang] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China; [Utiyama, Masao; Isahara, Hitoshi] Natl Inst Informat & Commun Technol, Knowledge Creating Commun Res Ctr, Kyoto 6190289, Japan	Lu, BL (reprint author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, 800 Dong Chun Rd, Shanghai 200240, Peoples R China.	wuke@sjtu.edu.cn; bllu@sjtu.edu.cn; mutiyama@nict.go.jp; isahara@nict.go.jp					BERGO A, 2007, TEXT CATEGORIZATION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; FAN ZG, 2005, ICNC, P396; FIX E, 1951, RANDOLPH FIELD, V4; Joachims T, 1998, P 10 EUR C MACH LEAR, P137; Joachims T, 1997, P 14 INT C MACH LEAR, P143; Lewis DD, 2004, J MACH LEARN RES, V5, P361; LIAN HC, 2005, ICNC, P438; LIU FY, 2005, IEEE INT JOINT C NEU, V1, P570; LIU TY, 2005, WWW 05, P1106; LU B L, 2004, P INT JOINT C NEUR N, P735; Lu BL, 1997, LECT NOTES COMPUT SC, V1240, P330; LU BL, 2000, P 5 INT C KNOWL BAS, P298; Lu BL, 1999, IEEE T NEURAL NETWOR, V10, P1244, DOI 10.1109/72.788664; Lu BL, 2004, IEEE T BIO-MED ENG, V51, P551, DOI 10.1109/TBME.2003.821023; LUO J, 2006, ISNN, P210; Nigam K, 1999, IJCAI 99 WORKSH MACH, P61; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; WANG K, 2005, ISNN, P887; YANG YM, 1994, ACM T INFORM SYST, V12, P252, DOI 10.1145/183422.183424; YANG Y, 2006, ISNN, P667; Yang Y. M., 1999, INFORM RETRIEVAL, V1, P69, DOI 10.1023/A:1009982220290; Yang Y.M, 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; Zhao H, 2004, LECT NOTES COMPUT SC, V3314, P867; ZHAO H, 2006, ISNN, P537	26	2	3	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	1432-7643		SOFT COMPUT	Soft Comput.	MAY	2008	12	7					647	655		10.1007/s00500-007-0242-3		9	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	265II	WOS:000253351900006	
J	Asselah, T; Bieche, I; Narguet, S; Sabbagh, A; Laurendeau, I; Ripault, MP; Boyer, N; Martinot-Peignoux, M; Valla, D; Vidaud, M; Marcellin, P				Asselah, T.; Bieche, I.; Narguet, S.; Sabbagh, A.; Laurendeau, I.; Ripault, M-P; Boyer, N.; Martinot-Peignoux, M.; Valla, D.; Vidaud, M.; Marcellin, P.			Liver gene expression signature to predict response to pegylated interferon plus ribavirin combination therapy in patients with chronic hepatitis C	GUT			English	Article							ALPHA-REGULATED GENE; VIRAL-INFECTION; VIRUS-INFECTION; PEGINTERFERON; FIBROSIS; IDENTIFICATION; NONRESPONDERS; MICROARRAY; DISEASE; TRIAL	Background and Aims: The gold standard treatment of chronic hepatitis C (CHC) is combined pegylated interferon and ribavirin. Considering side effects and treatment cost, prediction of treatment response before therapy is important. The aim of this study was to identify a liver gene signature to predict sustained virological response in patients with CHC. Methods: Group A (training set) comprised 40 patients with CHC including 14 non-responders (NRs) and 26 sustained virological responders (SVRs). Group B (validation set) comprised 29 patients including 9 NRs and 20 SVRs. Eleven responder-relapsers were also included. A total of 58 genes associated with liver gene expression dysregulation during CHC were selected from the literature. Real-time quantitative RT-PCR assays were used to analyse the mRNA expression of these 58 selected genes in liver biopsy specimens taken from the patients before treatment. Results: From the Group A data, three genes whose expression was significantly increased in NRs compared with SVRs were identified: IFI-6-16/G1P3, IFI27 and ISG15/G1P2. These three genes also showed significant differences in their expression profiles between NRs and SVRs in the independent sample (Group B). Supervised class prediction analysis identified a two-gene (IFI27 and CXCL9) signature, which accurately predicted treatment response in 79.3% (23/29) of patients from the validation set (Group B), with a predictive accuracy of 100% (9/9) and of 70% (14/20) in NRs and SVRs, respectively. The expression profiles of responder-relapsers did not differ significantly from those of NRs and SVRs, and 73% (8/11) of them were predicted as SVRs with the two-gene classifier. Conclusion: NRs and SVRs have different liver gene expression profiles before treatment. The most notable changes occurred mainly in interferon-stimulated genes. Treatment response could be predicted with a two-gene signature (IFI27 and CXCL9).	[Asselah, T.; Ripault, M-P; Boyer, N.; Martinot-Peignoux, M.; Valla, D.; Marcellin, P.] Univ Paris 07, INSERM, AP HP Beaujon Hosp, U773,CRB3, F-92110 Clichy, France; [Asselah, T.; Ripault, M-P; Boyer, N.; Martinot-Peignoux, M.; Valla, D.; Marcellin, P.] Hop Beaujon, Serv Hepatol, Pole Maladies Appareil Digest, F-92110 Clichy, France; [Asselah, T.; Bieche, I.; Narguet, S.; Sabbagh, A.; Laurendeau, I.; Vidaud, M.] Univ Paris 05, INSERM, UMR745, Paris, France; [Bieche, I.; Sabbagh, A.; Vidaud, M.] Hop Beaujon, Serv Biochim & Genet Mol, Clichy, France	Asselah, T (reprint author), Hop Beaujon, Serv Hepatol, Pole Maladies Appareil Digest, F-92110 Clichy, France.	tarik.asselah@bjn.aphp.fr					Asselah T, 2005, GASTROENTEROLOGY, V129, P2064, DOI 10.1053/j.gastro.2005.09.010; Asselah T, 2007, SEMIN LIVER DIS, V27, P13, DOI 10.1055/s-2006-960168; Bedossa P, 1996, HEPATOLOGY, V24, P289, DOI 10.1002/hep.510240201; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Bieche I, 2005, VIROLOGY, V332, P130, DOI 10.1016/j/virol.2004.11.009; BRONOWICKI JP, 2006, GASTROENTEROLOGY, V1040, P1; Butera D, 2005, BLOOD, V106, P1175, DOI 10.1182/blood-2005-01-0126; Chen LM, 2005, GASTROENTEROLOGY, V128, P1437, DOI 10.1053/j.gastro.2005.01.059; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Craxi A, 2003, SEMIN LIVER DIS, V23, P35; DeRisi J, 1996, NAT GENET, V14, P457; Devlin B, 2003, GENET EPIDEMIOL, V25, P36, DOI 10.1002/gepi.10237; Fried MW, 2002, NEW ENGL J MED, V347, P975, DOI 10.1056/NEJMoa020047; Gale M, 2005, NATURE, V436, P939, DOI 10.1038/nature04078; Hadziyannis SJ, 2004, ANN INTERN MED, V140, P346; Hayashida K, 2005, CLIN GASTROENTEROL H, V3, P1253, DOI 10.1016/S1542-3565(05)00412-X; Helbig KJ, 2005, HEPATOLOGY, V42, P702, DOI 10.1002/hep.20844; Honda M, 2001, GASTROENTEROLOGY, V120, P955, DOI 10.1053/gast.2001.22468; Ji XH, 2003, HEPATOLOGY, V37, P610, DOI 10.1053/jhep.2003.50105; Kim IJ, 2005, GASTROENTEROLOGY, V129, P1803, DOI 10.1053/j.gastro.2005.09.047; Lagging M, 2006, HEPATOLOGY, V44, P1617, DOI 10.1002/hep.21407; Li QX, 2001, ENDOCRINOLOGY, V142, P2390, DOI 10.1210/en.142.6.2390; Manns MP, 2001, LANCET, V358, P958, DOI 10.1016/S0140-6736(01)06102-5; Marcellin P, 2002, HEPATOLOGY, V36, pS47, DOI 10.1053/jhep.2002.36993; Mihm S, 2004, LAB INVEST, V84, P1148, DOI 10.1038/labinvest.3700135; Moucari R, 2007, J HEPATOL, V46, P596, DOI 10.1016/j.jhep.2006.10.016; Reich M, 2006, NAT GENET, V38, P500, DOI 10.1038/ng0506-500; Seeff Leonard B, 2003, Clin Liver Dis, V7, P261, DOI 10.1016/S1089-3261(02)00078-8; Smith MW, 2003, HEPATOLOGY, V38, P1458, DOI 10.1016/jhep.2003.09.024; [Anonymous], 1999, J HEPATOL, V30, P956	30	112	114	BMJ PUBLISHING GROUP	LONDON	BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND	0017-5749		GUT	Gut	APR	2008	57	4					516	524		10.1136/gut.2007.128611		9	Gastroenterology & Hepatology	Gastroenterology & Hepatology	272RL	WOS:000253877300018	
J	Reformat, M; Yager, RR				Reformat, Marek; Yager, Ronald R.			Building ensemble classifiers using belief functions and OWA operators	SOFT COMPUTING			English	Article						ensemble systems; rule-based models; belief functions; Dempster-Shafer evidence theory; ordered weighted averaging operator	DEMPSTER-SHAFER THEORY; MULTICRITERIA DECISION-MAKING; PATTERN-CLASSIFICATION; COMBINING CLASSIFIERS; RULE; AGGREGATION; COMBINATION	A pervasive task in many forms of human activity is classification. Recent interest in the classification process has focused on ensemble classifier systems. These types of systems are based on a paradigm of combining the outputs of a number of individual classifiers. In this paper we propose a new approach for obtaining the final output of ensemble classifiers. The method presented here uses the Dempster-Shafer concept of belief functions to represent the confidence in the outputs of the individual classifiers. The combing of the outputs of the individual classifiers is based on an aggregation process which can be seen as a fusion of the Dempster rule of combination with a generalized form of OWA operator. The use of the OWA operator provides an added degree of flexibility in expressing the way the aggregation of the individual classifiers is performed.	[Yager, Ronald R.] Iona Coll, Inst Machine Intelligence, New Rochelle, NY 10801 USA; [Reformat, Marek] Univ Alberta, Thinking Software & Syst Lab ThinkS2, Edmonton, AB T6G 2Y7, Canada	Yager, RR (reprint author), Iona Coll, Inst Machine Intelligence, New Rochelle, NY 10801 USA.	yager@panix.com					Ahmadzadeh MR, 2003, PATTERN ANAL APPL, V6, P41, DOI [10.1007/s10044-002-0176-4, 10.1007/s1004-002-0176-4]; Al-Ani M, 2002, J ARTIF INTELL RES, V17, P333; ALI K, 1995, 9547 U CAL DEP INF C; Ali KM, 1996, MACH LEARN, V24, P173, DOI 10.1007/BF00058611; Altincay H, 2006, APPL INTELL, V25, P73, DOI 10.1007/s10489-006-8867-y; Altincay H, 2003, SPEECH COMMUN, V41, P531, DOI 10.1016/S0167-6393(03)00032-3; Altincay H, 2005, PATTERN ANAL APPL, V8, P287, DOI 10.1007/s10044-005-0010-x; Binaghi E, 1999, INT J INTELL SYST, V14, P559, DOI 10.1002/(SICI)1098-111X(199906)14:6<559::AID-INT2>3.0.CO;2-#; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BUNTINE W, 1990, THESIS U TECHNOLOGY; Cios K., 1998, DATA MINING METHODS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Yager RR, 2008, STUD FUZZ SOFT COMP, V219, P1, DOI 10.1007/978-3-540-44792-4; Denoeux T, 2000, IEEE T SYST MAN CY A, V30, P131, DOI 10.1109/3468.833094; Denoeux T, 1997, PATTERN RECOGN, V30, P1095, DOI 10.1016/S0031-3203(96)00137-9; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Dietterich TG, 2000, LECT NOTES COMPUTER, P1; Duda R. O., 2001, PATTERN CLASSIFICATI; DUNHAM MH, 2003, DATA MINING; Freund Y, 1996, P 13 INT C MACH LEAR; Han J., 2001, DATA MINING CONCEPTS; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Klement EP, 2000, TRIANGULAR NORMS; KONONENKO M, 1992, P 9 INT WORKSH MACH, P257; Kramosil I, 2001, INT J UNCERTAIN FUZZ, V9, P105, DOI 10.1016/S0218-4885(01)00065-X; Kuncheva L., 2004, COMBINING PATTERN CL; Kwok S. W., 1990, UNCERTAINTY ARTIFICI, V4, P327; Laha A, 2006, IEEE T GEOSCI REMOTE, V44, P1633, DOI 10.1109/TGRS.2006.864391; Lin T. Y., 2002, DATA MINING ROUGH SE; Mandler E., 1988, Pattern Recognition and Artificial Intelligence. Towards an Integration. Proceedings of an International Workshop; O'Hagan M., 1990, P 24 ANN IEEE AS C S, P618; Reformat M, 2005, INT J INTELL SYST, V20, P1093, DOI 10.1002/int.20113; ROGOVA G, 1994, NEURAL NETWORKS, V7, P777, DOI 10.1016/0893-6080(94)90099-X; ROLI F, 2006, IOS NATO PUBLICATION, P23; Shafer G., 1976, MATH THEORY EVIDENCE; SMETS P, 1994, ARTIF INTELL, V66, P191, DOI 10.1016/0004-3702(94)90026-4; Smets P., 1988, NONSTANDARD LOGICS A, P253; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; Todorovski L., 2000, Principles of Data Mining and Knowledge Discovery. 4th European Conference, PKDD 2000. Proceedings (Lecture Notes in Artificial Intelligence Vol.1910); Winer B. J., 1991, STAT PRINCIPLES EXPT; YAGER RR, 1988, IEEE T SYST MAN CYB, V18, P183, DOI 10.1109/21.87068; Yager RR, 2006, INFORM SCIENCES, V176, P577, DOI 10.1016/j.ins.2004.12.006; YAGER RR, 1993, FUZZY SET SYST, V59, P125, DOI 10.1016/0165-0114(93)90194-M; Yager RR, 1996, INT J INTELL SYST, V11, P49, DOI 10.1002/(SICI)1098-111X(199601)11:1<49::AID-INT3>3.3.CO;2-L; Yager RR, 2005, INT J INTELL SYST, V20, P453, DOI 10.1002/int.20075; ZADEH LA, 1983, COMPUT MATH APPL, V9, P149, DOI 10.1016/0898-1221(83)90013-5; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565	47	7	8	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1432-7643		SOFT COMPUT	Soft Comput.	APR	2008	12	6					543	558		10.1007/s00500-007-0227-2		16	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	255SJ	WOS:000252677400004	
J	Carrizosa, E; Martin-Barragan, B; Morales, DR				Carrizosa, Emilio; Martin-Barragan, Belen; Morales, Dolores Romero			Multi-group support vector machines with measurement costs: A biobjective approach	DISCRETE APPLIED MATHEMATICS			English	Article						multi-group classification; pareto optimality; biobjective mixed integer programming; feature cost; support vector machines	CLASSIFICATION; FORMULATIONS; SEPARATION; KNOWLEDGE	Support Vector Machine has shown to have good performance in many practical classification settings. In this paper we propose, for multi-group classification, a biobjective optimization model in which we consider not only the generalization ability (modeled through the margin maximization), but also costs associated with the features. This cost is not limited to an economical payment, but can also refer to risk, computational effort, space requirements, etc. We introduce a Biobjective Mixed Integer Problem, for which Pareto optimal solutions are obtained. Those Pareto optimal solutions cot-respond to different classification rules, among which the user would choose the one yielding the most appropriate compromise between the cost and the expected misclassification rate. (C) 2007 Elsevier B.V. All rights reserved.	[Carrizosa, Emilio] Univ Seville, Fac Matemat, Seville, Spain; [Martin-Barragan, Belen] Univ Carlos III Madrid, E-28903 Getafe, Spain; [Morales, Dolores Romero] Univ Oxford, Said Business Sch, Oxford OX1 2JD, England	Carrizosa, E (reprint author), Univ Seville, Fac Matemat, Seville, Spain.	ecarrizosa@us.es; belen.martin@uc3m.es; dolores.romero-morales@sbs.ox.ac.uk					Allwein E.L., 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; APTE C, 2003, OR MS TODAY      FEB; BAYERZUBEK V, 2003, THESIS OREGON STATE; Bennett K. P., 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; Bennett KP, 1999, ADVANCES IN KERNEL METHODS, P307; Blake CL, 1998, UCI REPOSITORY MACHI; BORES E, 1997, MATH PROGRAM, V79, P163; Bradley PS, 1999, INFORMS J COMPUT, V11, P217, DOI 10.1287/ijoc.11.3.217; Bradley PS, 2002, HDB MASSIVE DATASETS, P439; Breiman L, 1984, CLASSIFICATION REGRE; CORTES C, 1995, MACH LEARN, V1, P113; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; Demiriz A, 2002, MACH LEARN, V46, P225, DOI 10.1023/A:1012470815092; SILVA APD, 1994, EUR J OPER RES, V72, P4, DOI 10.1016/0377-2217(94)90324-7; Falk JE, 2001, COMPUT OPER RES, V28, P537, DOI 10.1016/S0305-0548(99)00134-3; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hastie T, 1998, ANN STAT, V26, P451; Herbrich R, 2002, LEARNING THEORY CLAS; Joachims T., 2002, LEARNING CLASSIFY TE; MANGASARIAN O, 1997, DATA MIN KNOWL DISC, V42, P183; MANGASAR.OL, 1965, OPER RES, V13, P444, DOI 10.1287/opre.13.3.444; NORTON S. W., 1989, P 11 INT JOINT C ART, P800; NUNEZ M, 1991, MACH LEARN, V6, P231, DOI 10.1007/BF00114778; Paclik P., 2002, LECT NOTES COMPUTER, V2396, P461; Pedroso JP, 2001, PATTERN RECOGN LETT, V22, P1263, DOI 10.1016/S0167-8655(01)00071-X; RUBINOV AM, 2003, TOP, V11, P1; SMOLA A, 1999, ADV NEURAL INFORM PR, V10, P585; TAN M, 1993, MACH LEARN, V13, P7, DOI 10.1007/BF00993101; Turney P. D., 1995, Journal of Artificial Intelligence Research, V2; Vapnik V.N., 1998, STAT LEARNING THEORY; Vapnik V.N., 1995, NATURE STAT LEARNING; Visee M, 1998, J GLOBAL OPTIM, V12, P139, DOI 10.1023/A:1008258310679; Weston J, 2001, ADV NEUR IN, V13, P668; Weston J, 1999, ADVANCES IN KERNEL METHODS, P293	36	3	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0166-218X		DISCRETE APPL MATH	Discret Appl. Math.	MAR 15	2008	156	6					950	966		10.1016/j.dam.2007.05.060		17	Mathematics, Applied	Mathematics	281FN	WOS:000254482400011	
J	Wang, RL; Bencic, D; Biales, A; Lattier, D; Kostich, M; Villeneuve, D; Ankley, GT; Lazorchak, J; Toth, G				Wang, Rong-Lin; Bencic, David; Biales, Adam; Lattier, David; Kostich, Mitch; Villeneuve, Dan; Ankley, Gerald T.; Lazorchak, Jim; Toth, Greg			DNA microarray-based ecotoxicological biomarker discovery in a small fish model species	ENVIRONMENTAL TOXICOLOGY AND CHEMISTRY			English	Article						algorithm; zebrafish; microarray; ecotoxicology; biomarker	GENE-EXPRESSION DATA; SUPPORT VECTOR MACHINES; MOLECULAR CLASSIFICATION; EXPERIMENTAL-DESIGN; CANCER-DIAGNOSIS; FATHEAD MINNOW; ALGORITHMS; SIGNATURES; SAMPLES	As potential biomarkers, gene classifiers are gene expression signatures or patterns capable of distinguishing biological samples belonging to different classes or conditions. This is the second of two papers on profiling gene expression in zebrafish (Danio rerio) treated with endocrine-disrupting chemicals of different modes of action, with a focus on comparative analysis of microarray data for gene classifier discovery. Various combinations of gene feature selection/class prediction algorithms were evaluated. with the use of microarray data organized by a chemical stressor or tissue type, for their accuracy in determining the class memberships of independent test samples. Two-way clustering of gene classifiers and treatment conditions offered another alternative to assess the performance of these potential biomarkers. Both gene feature selection methods and class prediction algorithms were shown to be important in identifying successful gene classifiers. The genetic algorithm and support vector machine yielded classifiers with the best prediction accuracy, regardless of sample size, nature of class prediction, and data complexity. A chemical stressor significantly altering the expression of a greater number of genes tended to generate gene classifiers with better performance. All combinations of gene feature selection/class prediction algorithms performed similarly well with data of high signal to noise ratio. Gene classifier discovery and application on the basis of individual sampling and sample data pooling, respectively, were found to enhance class predictions. Gene expression profiles of the top gene classifiers, identified from both microarray and quantitative polymerase chain reaction assays, displayed greater similarity between fadrozole and 17 beta-trenbolone than either one to 17 alpha-ethinylestradiol. These gene classifiers could serve as potential biomarkers of exposure to specific classes of endocrine disruptors.	[Wang, Rong-Lin; Bencic, David; Biales, Adam; Lattier, David; Kostich, Mitch; Lazorchak, Jim; Toth, Greg] US EPA, Ecol Exposure Res Div, Natl Exposure Res Lab, Cincinnati, OH 45268 USA; [Villeneuve, Dan; Ankley, Gerald T.] US EPA, Mid Continent Ecol Div, Natl Hlth & Environm Effects Res Lab, Duluth, MN 55804 USA	Wang, RL (reprint author), US EPA, Ecol Exposure Res Div, Natl Exposure Res Lab, 26 W Martine Luther King Dr, Cincinnati, OH 45268 USA.	wang.rong-lin@epa.gov					Agrawal D, 2002, J NATL CANCER I, V94, P513; Allison DB, 2006, NAT REV GENET, V7, P55, DOI 10.1038/nrg1749; Ankley GT, 2002, TOXICOL SCI, V67, P121, DOI 10.1093/toxsci/67.1.121; Ankley GT, 2003, ENVIRON TOXICOL CHEM, V22, P1350, DOI 10.1897/1551-5028(2003)022<1350:EOTAGP>2.0.CO;2; Ankley GT, 2006, ENVIRON SCI TECHNOL, V40, P4055, DOI 10.1021/es0630184; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Churchill GA, 2002, NAT GENET, V32, P490, DOI 10.1038/ng1031; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Fleiss J.L., 1981, STAT METHODS RATES P; Goldberg D. E, 1989, GENETIC ALGORITHMS S; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Kendziorski C, 2005, P NATL ACAD SCI USA, V102, P4252, DOI 10.1073/pnas.0500607102; Lettieri T, 2006, ENVIRON HEALTH PERSP, V114, P4, DOI 10.1289/ehp.8194; Li LP, 2001, COMB CHEM HIGH T SCR, V4, P727; Li T, 2004, BIOINFORMATICS, V20, P2429, DOI 10.1093/bioinformatics/bth267; Liu Huiqing, 2002, Genome Inform, V13, P51; Liu JJ, 2005, BIOINFORMATICS, V21, P2691, DOI 10.1093/bioinformatics/bti419; Mitchell M, 1996, INTRO GENETIC ALGORI; Natsoulis G, 2005, GENOME RES, V15, P724, DOI 10.1101/gr.2807605; Peng SH, 2003, FEBS LETT, V555, P358, DOI 10.1016/S0014-5793(03)01275-4; Peng XJ, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-26; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Reich M, 2006, NAT GENET, V38, P500, DOI 10.1038/ng0506-500; SLONIM DK, 2000, 4 ANN INT C COMP MOL, P263; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; STEGEMAN JJ, 1992, SETAC SP P, P235; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; Villeneuve DL, 2007, ENVIRON SCI TECHNOL, V41, P321, DOI 10.1021/es061739x; Wang RL, 2008, ENVIRON TOXICOL CHEM, V27, P652, DOI 10.1897/07-191.1; Wright GW, 2003, BIOINFORMATICS, V19, P2448, DOI 10.1093/bioinformatics/btg345	32	18	19	SETAC PRESS	PENSACOLA	1010 N 12TH AVE, PENSACOLA, FL 32501-3367 USA	0730-7268		ENVIRON TOXICOL CHEM	Environ. Toxicol. Chem.	MAR	2008	27	3					664	675		10.1897/07-192.1		12	Environmental Sciences; Toxicology	Environmental Sciences & Ecology; Toxicology	265PX	WOS:000253374500022	
J	Bengtsson, T; Cavanaugh, JE				Bengtsson, Thomas; Cavanaugh, Joseph E.			State-space discrimination and clustering of atmospheric time series data based on Kullback information measures	ENVIRONMETRICS			English	Article						classification; pattern recognition; geostatistics; principal component analysis; principal oscillation pattern; state-space process	ENSEMBLE KALMAN FILTER; DATA ASSIMILATION; UNITED-STATES	Statistical problems in atmospheric science are frequently characterized by large spatio-temporal data sets and pose difficult challenges in classification and pattern recognition. Here, we consider the problem of identifying geographically homogeneous regions based on similarities in the temporal dynamics of weather patterns. Two disparity measures are proposed and applied to cluster time series of observed monthly temperatures from locations across Colorado, U.S.A. The two disparity measures are based on state-space models, where the monthly temperature anomaly dynamics and seasonal variation are represented by latent processes. Our disparity measures produce clusters consistent with known atmospheric flow structures. In particular, the temporal anomaly pattern is related to the topography of Colorado, where, separated by the Continental Divide, the flow structures in the western and eastern parts of the state have different dynamics. The results further suggest that seasonal variation may be affected by locally changing solar radiation levels primarily associated with elevation variations across the Rocky Mountains. The general methodology is outlined and developed in the Appendix. We conclude with a discussion of extensions to time varying and non-stationary systems. Copyright (c) 2007 John Wiley & Sons, Ltd.	[Bengtsson, Thomas] Stat & Data Mining Dept, Bell Labs, Summit, NJ 07901 USA; [Cavanaugh, Joseph E.] Univ Iowa, Dept Biostat, Iowa City, IA USA	Bengtsson, T (reprint author), Stat & Data Mining Dept, Bell Labs, Summit, NJ 07901 USA.	tocke@cgd.ucar.edu					Alagon J., 1989, J TIME SER ANAL, V10, P203, DOI 10.1111/j.1467-9892.1989.tb00024.x; Anderson D., 1979, OPTIMAL FILTERING; BENGTSSON T, 2003, J GEOPHYS RES, V108, P1; Brockwell P.J., 1991, TIME SERIES THEORY M; Cavanaugh JE, 1999, BIOMETRIKA, V86, P183, DOI 10.1093/biomet/86.1.183; CHAUDHURI G, 1992, STAT PROBABIL LETT, V15, P277, DOI 10.1016/0167-7152(92)90162-X; Chen R, 2000, J ROY STAT SOC B, V62, P493, DOI 10.1111/1467-9868.00246; Coates D. S., 1986, J TIME SER ANAL, V7, P7, DOI 10.1111/j.1467-9892.1986.tb00482.x; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Durbin J., 2001, TIME SERIES ANAL STA; FOVELL RG, 1993, J CLIMATE, V6, P2103, DOI 10.1175/1520-0442(1993)006<2103:CZOTCU>2.0.CO;2; GERSCH W, 1981, APPL TIME SERIES ANA, V2, P221; GONG XF, 1995, J CLIMATE, V8, P897, DOI 10.1175/1520-0442(1995)008<0897:OTAOCA>2.0.CO;2; Gordon AD, 1999, CLASSIFICATION; Dargahi-Noubary G. R., 1981, Journal of Time Series Analysis, V2, DOI 10.1111/j.1467-9892.1981.tb00313.x; Hartigan J., 1975, CLUSTERING ALGORITHM; Harvey AC, 1989, FORECASTING STRUCTUR; Houtekamer PL, 1998, MON WEATHER REV, V126, P796, DOI 10.1175/1520-0493(1998)126<0796:DAUAEK>2.0.CO;2; Houtekamer PL, 2001, MON WEATHER REV, V129, P123, DOI 10.1175/1520-0493(2001)129<0123:ASEKFF>2.0.CO;2; Janacek G., 1993, TIME SERIES FORECAST; Jazwinski A.H., 1970, STOCHASTIC PROCESSES; JOLLIFFE P, 2002, PRINCIPAL COMPONENT; Jones R.H., 1993, LONGITUDINAL DATA SE; Kakizawa Y, 1998, J AM STAT ASSOC, V93, P328, DOI 10.2307/2669629; Kalman R. E., 1960, T ASME, V82, P35; Kim KY, 1999, J CLIMATE, V12, P185, DOI 10.1175/1520-0442-12.1.185; Kullback S., 1968, INFORM THEORY STAT; LIGGETT WS, 1971, ANN MATH STAT, V42, P1348, DOI 10.1214/aoms/1177693247; MELARD G, 1983, P AM STAT ASS BUS EC; MILLER RN, 1994, J ATMOS SCI, V51, P1037, DOI 10.1175/1520-0469(1994)051<1037:ADAISN>2.0.CO;2; MO KT, 1988, J GEOPHYS RES-ATMOS, V93, P10927, DOI 10.1029/JD093iD09p10927; RICHMAN MB, 1985, J CLIM APPL METEOROL, V24, P1325, DOI 10.1175/1520-0450(1985)024<1325:CPAOTA>2.0.CO;2; Shumway R. H., 2006, TIME SERIES ANAL ITS; SHUMWAY RH, 1974, J AM STAT ASSOC, V69, P948, DOI 10.2307/2286169; SHURNWAY R, 1982, J TIME SER ANAL, V3, P253; STONE RC, 1989, INT J CLIMATOL, V9, P3, DOI 10.1002/joc.3370090103; Wichern D. W., 1992, APPL MULTIVARIATE ST; Wikle C, 2002, ENCY LIFE SUPPORT SY; Wikle CK, 1999, BIOMETRIKA, V86, P815, DOI 10.1093/biomet/86.4.815; *SCI COMP DIV NAT, 1948, TD3200 NCDC SCI COMP	40	7	7	JOHN WILEY & SONS LTD	CHICHESTER	THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND	1180-4009		ENVIRONMETRICS	Environmetrics	MAR	2008	19	2					103	121		10.1002/env.859		19	Environmental Sciences; Mathematics, Interdisciplinary Applications; Statistics & Probability	Environmental Sciences & Ecology; Mathematics	280XL	WOS:000254460000001	
J	Yu, J; Amores, J; Sebe, N; Radeva, P; Tian, Q				Yu, Jie; Amores, Jaume; Sebe, Nicu; Radeva, Petia; Tian, Qi			Distance learning for similarity estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image classification; information retrieval; pattern recognition; artificial intelligence; algorithms	IMAGE RETRIEVAL; CLASSIFICATION; ALGORITHMS; FEATURES	In this paper, we present a general guideline to find a better distance measure for similarity estimation based on statistical analysis of distribution models and distance functions. A new set of distance measures are derived from the harmonic distance, the geometric distance, and their generalized variants according to the Maximum Likelihood theory. These measures can provide a more accurate feature model than the classical euclidean and Manhattan distances. We also find that the feature elements are often from heterogeneous sources that may have different influence on similarity estimation. Therefore, the assumption of single isotropic distribution model is often inappropriate. To alleviate this problem, we use a boosted distance measure framework that finds multiple distance measures, which fit the distribution of selected feature elements best for accurate similarity estimation. The new distance measures for similarity estimation are tested on two applications: stereo matching and motion tracking in video sequences. The performance of boosted distance measure is further evaluated on several benchmark data sets from the UCI repository and two image retrieval applications. In all the experiments, robust results are obtained based on the proposed methods.	[Yu, Jie] Kodak Res Labs, Intelligent Syst Grp, Rochester, NY 14615 USA; [Amores, Jaume] Inst Natl Rech Informat & Automat, IMEDIA Res Grp, Sophia Antipolis, France; [Sebe, Nicu] Univ Amsterdam, Fac Sci, NL-1098 SJ Amsterdam, Netherlands; [Radeva, Petia] Univ Autonoma Barcelona, Dept Informat, Comp Vis Ctr, Catalunya 08193, Spain; [Tian, Qi] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX USA	Yu, J (reprint author), Kodak Res Labs, Intelligent Syst Grp, 1999 Lake Ave,Mail Code 02103, Rochester, NY 14615 USA.	Jerry.J.Yu@gmail.com; Jaume.Amores@inria.fr; nicu@science.uva.nl; petia@cvc.uab.es; qitian@gmail.com					AIGRAIN P, 1987, P I M OPT PUBL STOR, P257; Amores J, 2006, PATTERN RECOGN LETT, V27, P201, DOI 10.1016/j.patrec.2005.08.019; Athitsos V., 2004, P IEEE C COMP VIS PA; Bar-Hillel A., 2003, P 20 INT C MACH LEAR, P11; CHANG NS, 1980, IEEE T SOFTWARE ENG, V6, P519; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Duda R. O., 2001, PATTERN CLASSIFICATI; Flichner M, 1995, IEEE COMPUT, V9, P23; FUKUNAGA K, 1997, IEEE T PATTERN ANAL, V19, P671; GUDIVADA VN, 1995, ACM T INFORM SYST, V13, P115, DOI 10.1145/201040.201041; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Haralick R.M., 1993, COMPUTER ROBOT VISIO; HERTZ T, 2006, P ACM I C MACH LEARN; Hertz T, 2004, PROC CVPR IEEE, P570; Huber P. J., 1981, ROBUST STAT; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; Jolliffe I. T., 2002, PRINCIPAL COMPONENT; KATO K, 1992, P SPIE C IM STOR RET, V1662, P112; LAFFERTY J, 1997, P CAN WORKSH INF THE; LeCun Y., 1998, MNIST DATABASE; LEW MS, 1994, IEEE T PATTERN ANAL, V16, P869, DOI 10.1109/34.310682; Martinez A., 1998, AR FACE DATABASE; MATAS J, 1999, P INT C PATT REC, P858; Mehtre BM, 1997, INFORM PROCESS MANAG, V33, P319, DOI 10.1016/S0306-4573(96)00069-6; Merz C.J., 1998, UCI REPOSITORY MACHI; MOGHADDAM B, 2000, PATTERN RECOGNITION; PENG J, 2001, P IEEEE C COMP VIS P, P940; PHILLIPS PJ, 1998, P ADV NEUR INF PROC, V11; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; RUBNER Y, 2000, I J COMPUTER VISION; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Sebe N, 2000, IEEE T PATTERN ANAL, V22, P1132, DOI 10.1109/34.879793; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; SMITH JR, 1994, P IEEE I C IM PROC; STORK D, 2004, PATTERN CLASSIFICATI; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; TANG L, 1994, P NSF ARPA WORKSH PE; TIAN Q, 2004, P IEEE I C IM PROC; TVERSKY A, 1977, J MATH PSYCHOL, V7, P572; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037//0033-295X.84.4.327; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; WALLACH MA, 1958, PSYCHOL REV, V65, P103, DOI 10.1037/h0042908; Xing EP, 2003, P NIPS, P505; YU J, 2006, P IEEE I C COMP VIS; YU J, 2006, P IEEE I C AC SPEECH; Zakai M., 1964, IEEE T INFORM TH JAN, P94	47	23	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2008	30	3					451	462		10.1109/TPAMI.2007.70714		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	250FT	WOS:000252286100007	
J	Kyperountas, M; Tefas, A; Pitas, L				Kyperountas, Marios; Tefas, Anastasios; Pitas, Loannis			Dynamic training using multistage clustering for face recognition	PATTERN RECOGNITION			English	Article						face recognition; dynamic training; multilevel clustering; discriminant analysis	SAMPLE-SIZE PROBLEM; DISCRIMINANT-ANALYSIS; LDA; REPRESENTATION; ALGORITHMS; CLASSIFICATION; EIGENFACES; IMAGES	A novel face recognition algorithm that uses dynamic training in a multistage clustering scheme is presented and evaluated. This algorithm uses discriminant analysis to project the face classes and a clustering algorithm to partition the projected face data, thus forming a set of discriminant clusters. Then, an iterative process creates subsets, whose cardinality is defined by an entropy-based measure, that contain the most useful clusters. The best match to the test face is found when only a single face class is retained. This method was tested on the ORL, XM2VTS and FERET face databases, whereas the UMIST database was used in order to train the proposed algorithm. Experimental results indicate that the proposed framework provides a promising solution to the face recognition problem. (C) 2007 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Aristotle Univ Thessaloniki, Dept Informat, Artificial Intelligence & Informat Anal Lab, GR-54006 Thessaloniki, Greece; Inst Educ Technol, Dept Informat Management, GR-65404 Kavala, Greece	Kyperountas, M (reprint author), Aristotle Univ Thessaloniki, Dept Informat, Artificial Intelligence & Informat Anal Lab, Box 451, GR-54006 Thessaloniki, Greece.	mkyper@aiia.csd.auth.gr; tefas@aiia.csd.auth.gr; pitas@aiia.csd.auth.gr	Tefas, Anastasios/F-1899-2010				Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bicego M., 2003, Proceedings 12th International Conference on Image Analysis and Processing; BRENNAN V, 1998, P IEEE WORKSH NEUR N, P506; Camastra F, 2005, IEEE T PATTERN ANAL, V27, P801, DOI 10.1109/TPAMI.2005.88; Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAI G, 2004, P INT S CIRC SYST, V2, P109; Daubechies I., 1992, 10 LECT WAVELETS CBM; Er MJ, 2002, IEEE T NEURAL NETWOR, V13, P697, DOI 10.1109/TNN.2002.1000134; Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724; Graham D. B., 1998, NATO ASI SERIES F, V163, P446; GUO GD, 2001, P 8 IEEE INT C COMP, P282; HUANG R, 2004, P 17 INT C PATT REC, V3, P157; Koskela M., 2004, P 17 INT C PATT REC, V2, P1005; Kyperountas M, 2007, IEEE T NEURAL NETWOR, V18, P506, DOI 10.1109/TNN.2006.885038; Lai JH, 2001, PATTERN RECOGN, V34, P95, DOI 10.1016/S0031-3203(99)00200-9; Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195; LEUTTIN J, 1998, IDIAP COMMUNICATION; Li Z., 2004, P IEEE INT C COMP VI, P374; LIAND SZ, 1999, IEEE T NEURAL NETWOR, V10, P439; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; LIU H, 2004, P INT C PATT REC, V4, P344; LU J, 2002, P IEEE INT C IM PROC; Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P117, DOI 10.1109/TNN.2002.806629; Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P195, DOI 10.1109/TNN.2002.806647; Lu JW, 2005, PATTERN RECOGN LETT, V26, P181, DOI 10.1016/j.patrec.2004.09.014; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; MCGILL R, 1978, AM STAT, V32, P12, DOI 10.2307/2683468; Nastar C, 1996, IEEE T PATTERN ANAL, V18, P1067, DOI 10.1109/34.544076; Nguyen T, 1996, WAVELETS FILTER BANK; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Seber G. A. F., 1984, MULTIVARIATE OBSERVA; Swets DL, 1999, IEEE T PATTERN ANAL, V21, P386, DOI 10.1109/34.765652; Tang QS, 2003, LAR MAR ECOSYST, V12, P121; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; WANG X, 2003, P ACM SIGMM 2003 MUL; XIAOJUN WU, 2004, C BRIT MACH VIS KING; Yang J, 2004, IEEE T PATTERN ANAL, V26, P131; Yang M.-H., 2002, P 5 IEEE INT C AUT F, P215, DOI 10.1109/AFGR.2002.4527207; Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X; Zhang BL, 2004, IEEE T NEURAL NETWOR, V15, P166, DOI 10.1109/TNN.2003.820673; ZHENG W, 2004, P IEEE INT C AC SPEE, V5, P725; *AT T LAB CAMBR, DAT FAC	44	4	4	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	MAR	2008	41	3					894	905		10.1016/j.patcog.2007.06.017		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	237EQ	WOS:000251357100011	
J	Kong, XR; Mas, V; Archer, KJ				Kong, Xiangrong; Mas, Valeria; Archer, Kellie J.			A non-parametric meta-analysis approach for combining independent microarray datasets: application using two microarray datasets pertaining to chronic allograft nephropathy	BMC GENOMICS			English	Article							GENE-EXPRESSION PROFILES; CONTROL MAQC PROJECT; INTEGRATIVE ANALYSIS; CANCER; PERFORMANCE; PLATFORMS; NORMALIZATION; PARVALBUMIN; CONSISTENCY	Background: With the popularity of DNA microarray technology, multiple groups of researchers have studied the gene expression of similar biological conditions. Different methods have been developed to integrate the results from various microarray studies, though most of them rely on distributional assumptions, such as the t-statistic based, mixed-effects model, or Bayesian model methods. However, often the sample size for each individual microarray experiment is small. Therefore, in this paper we present a non-parametric meta-analysis approach for combining data from independent microarray studies, and illustrate its application on two independent Affymetrix GeneChip studies that compared the gene expression of biopsies from kidney transplant recipients with chronic allograft nephropathy (CAN) to those with normal functioning allograft. Results: The simulation study comparing the non-parametric meta-analysis approach to a commonly used t-statistic based approach shows that the non-parametric approach has better sensitivity and specificity. For the application on the two CAN studies, we identified 309 distinct genes that expressed differently in CAN. By applying Fisher's exact test to identify enriched KEGG pathways among those genes called differentially expressed, we found 6 KEGG pathways to be over-represented among the identified genes. We used the expression measurements of the identified genes as predictors to predict the class labels for 6 additional biopsy samples, and the predicted results all conformed to their pathologist diagnosed class labels. Conclusion: We present a new approach for combining data from multiple independent microarray studies. This approach is non-parametric and does not rely on any distributional assumptions. The rationale behind the approach is logically intuitive and can be easily understood by researchers not having advanced training in statistics. Some of the identified genes and pathways have been reported to be relevant to renal diseases. Further study on the identified genes and pathways may lead to better understanding of CAN at the molecular level.	[Kong, Xiangrong; Archer, Kellie J.] Virginia Commonwealth Univ, Dept Biostat, Richmond, VA 23298 USA; [Mas, Valeria] Virginia Commonwealth Univ, Dept Surg, Richmond, VA 23298 USA; [Archer, Kellie J.] Virginia Commonwealth Univ, Massey Canc Ctr, Richmond, VA 23298 USA	Archer, KJ (reprint author), Virginia Commonwealth Univ, Dept Biostat, Richmond, VA 23298 USA.	kongx@vcu.edu; vmas@mcvh-vcu.edu; kjarcher@vcu.edu	Kong, Xiangrong/B-5098-2010				Adley BP, 2006, ANAL QUANT CYTOL, V28, P228; AGRESTI A, 2002, WILEY SERIES PROBABI, V15, P710; Benjamini Y, 2001, ANN STAT, V29, P1165; Canales RD, 2006, NAT BIOTECHNOL, V24, P1115, DOI 10.1038/nbt1236; Choi J.K., 2003, BIOINFORMATICS, V19, pi84; Choi JK, 2004, FEBS LETT, V565, P93, DOI 10.1016/j.febslet.2004.03.081; COOPER HM, 1994, HDB RES SYNTHESIS, V14; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ghosh Debashis, 2003, Functional & Integrative Genomics, V3, P180; Grutzmann R, 2005, ONCOGENE, V24, P5079, DOI 10.1038/sj.onc.1208696; Guo L, 2006, NAT BIOTECHNOL, V24, P1162, DOI 10.1038/nbt1238; Hotchkiss H, 2006, TRANSPLANTATION, V81, P342, DOI 10.1097/01.tp.0000195773.24217.95; Hu PZ, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-128; Irizarry RA, 2003, BIOSTATISTICS, V4, P249, DOI 10.1093/biostatistics/4.2.249; Martignoni G, 2001, MODERN PATHOL, V14, P760, DOI 10.1038/modpathol.3880386; Mas V, 2007, TRANSPLANTATION, V83, P448, DOI 10.1097/01.tp.0000251373.17997.9a; Patterson TA, 2006, NAT BIOTECHNOL, V24, P1140, DOI 10.1038/nbt1242; Rhodes DR, 2002, CANCER RES, V62, P4427; Rhodes DR, 2004, P NATL ACAD SCI USA, V101, P9309, DOI 10.1073/pnas.0401994101; RIPLEY BD, 1996, PATTERN RECOGNITION, V11; Rotig A, 2003, J NEPHROL, V16, P286; Shen RL, 2004, BMC GENOMICS, V5, DOI 10.1186/1171-2164-5-94; Shi LM, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S2-S12; Shi LM, 2004, EXPERT REV MOL DIAGN, V4, P761, DOI 10.1586/14737159.4.6.761; Shi LM, 2006, NAT BIOTECHNOL, V24, P1151, DOI 10.1038/nbt1239; Shippy R, 2006, NAT BIOTECHNOL, V24, P1123, DOI 10.1038/nbt1241; Stevens JR, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-57; Tong WD, 2006, NAT BIOTECHNOL, V24, P1132, DOI 10.1038/nbt1237; Hoffman EP, 2004, NAT REV GENET, V5, P229, DOI 10.1038/nrg1297; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Wang J, 2004, BIOINFORMATICS, V20, P3166, DOI 10.1093/bioinformatics/bth381; WATS, 2004, PEARSON BENJAMIN CUM, P732; Wiesel M, 1997, UROLOGE A, V36, P126, DOI 10.1007/s001200050077	33	12	12	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2164		BMC GENOMICS	BMC Genomics	FEB 26	2008	9								98	10.1186/1471-2164-9-98		13	Biotechnology & Applied Microbiology; Genetics & Heredity	Biotechnology & Applied Microbiology; Genetics & Heredity	282ZZ	WOS:000254607600001	
J	Kubota, R; Uchino, E; Suetake, N				Kubotaa, Ryosuke; Uchino, Eiji; Suetake, Noriaki			Hierarchical k-nearest neighbor classification using feature and observation space information	IEICE ELECTRONICS EXPRESS			English	Article						k-nearest neighbor classification; pixel classification; image segmentation; learning vector quantization		A novel hierarchical k-nearest neighbor classification method using the feature and observation space information is proposed. The present method performs a fine classification when a pair of the spatial coordinate of the observation data in the observation space and its corresponding feature vector in the feature space is provided.	[Kubotaa, Ryosuke; Uchino, Eiji; Suetake, Noriaki] Yamaguchi Univ, Grad Sch Sci & Technol, Yamaguchi 7538512, Japan	Kubota, R (reprint author), Yamaguchi Univ, Grad Sch Sci & Technol, 1677-1 Yoshida, Yamaguchi 7538512, Japan.	kubota@ic.sci.yamaguchi-u.ac.jp					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 2001, PATTERN CLASSIFICATI; JAIN AK, 2000, IEEE T PATTERN ANAL, V922, P4; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P103; Kohonen T, 1986, TKKFA601 HELS U TECH; Kohonen T, 1995, SELF ORGANIZING MAPS; LEE JS, 1994, INT J REMOTE SENS, V15, P2299; OKA S, 2006, IEEE T GEOSCI REMOTE, V44, P1642; Schowengerdt R. A, 1997, REMOTE SENSING MODEL; Verhoeye J, 2002, REMOTE SENS ENVIRON, V79, P96, DOI 10.1016/S0034-4257(01)00242-5	10	4	4	IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG	TOKYO	KIKAI-SHINKO-KAIKAN BLDG MINATO-KU SHIBAKOEN 3 CHOME, TOKYO, 105, JAPAN	1349-2543		IEICE ELECTRON EXPR	IEICE Electron. Express	FEB 10	2008	5	3					114	119		10.1587/elex.5.114		6	Engineering, Electrical & Electronic	Engineering	295NR	WOS:000255481700006	
J	Hu, QH; Yu, DR; Me, Z				Hu, Qinghua; Yu, Daren; Me, Zongxia			Neighborhood classifiers	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						metric space; neighborhood; rough set; reduction; classifier; norm	K-NEAREST NEIGHBOR; FEATURE-SELECTION; CLASSIFICATION; ROUGH; REDUCTION; DISTANCE; SEARCH; SPACES	K nearest neighbor classifier (K-NN) is widely discussed and applied in pattern recognition and machine learning, however, as a similar lazy classifier using local information for recognizing a new test, neighborhood classifier, few literatures are reported on. In this paper, we introduce neighborhood rough set model as a uniform framework to understand and implement neighborhood classifiers. This algorithm integrates attribute reduction technique with classification learning. We study the influence of the three norms on attribute reduction and classification, and compare neighborhood classifier with KNN, CART and SVM. The experimental results show that neighborhood-based feature selection algorithm is able to delete most of the redundant and irrelevant features. The classification accuracies based on neighborhood classifier is superior to K-NN, CART in original feature spaces and reduced feature subspaces, and a little weaker than SVM. (c) 2006 Elsevier Ltd. All rights reserved.	[Hu, Qinghua; Yu, Daren; Me, Zongxia] Harbin Inst Technol, Harbin 150001, Peoples R China	Hu, QH (reprint author), Harbin Inst Technol, Harbin 150001, Peoples R China.	huqinghua@hcms.hit.edu.cn	Hu, Qinghua/B-8857-2008				Anil K.G., 2006, COMPUTATIONAL STAT D, V50, P3113; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; Fix E., 1951, 4 USAF SCH AV MED; Fu AW, 2000, VLDB J, V9, P154, DOI 10.1007/PL00010672; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; Girolami M, 2003, IEEE T PATTERN ANAL, V25, P1253, DOI 10.1109/TPAMI.2003.1233899; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hu QH, 2006, PATTERN RECOGN LETT, V27, P414, DOI 10.1016/patrec.2005.09.004; Hu QH, 2006, IEEE T FUZZY SYST, V14, P191, DOI 10.1109/TFUZZ.2005.864086; Jensen R, 2004, IEEE T KNOWL DATA EN, V16, P1457, DOI 10.1109/TKDE.2004.96; Kuncheva LI, 1999, PATTERN RECOGN LETT, V20, P1149, DOI 10.1016/S0167-8655(99)00082-3; Kushilevitz E, 2000, SIAM J COMPUT, V30, P457, DOI 10.1137/S0097539798347177; Lin T. Y., 1997, ADV MACHINE INTELLIG, P132; Lin T.Y., 1988, P 1988 ACM 16 ANN CO; Lindenbaum M, 2004, MACH LEARN, V54, P125, DOI 10.1023/B:MACH.0000011805.60520.fe; Muni DP, 2006, IEEE T SYST MAN CY B, V36, P106, DOI 10.1109/TSMCB.2005.854499; Neumann J, 2005, MACH LEARN, V61, P129, DOI 10.1007/s10994-005-1505-9; OWEN A, 1984, CANADIAN J STATISTIC, V12, P191, DOI 10.2307/3314747; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Salzberg S., 1991, MACH LEARN, V6, P277; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P1179, DOI 10.1016/S0167-8655(97)00112-8; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; Swiniarski RW, 2003, PATTERN RECOGN LETT, V24, P833, DOI 10.1016/S0167-8655(02)00196-4; Tan SB, 2005, EXPERT SYST APPL, V28, P667, DOI 10.1016/j.eswa.2004.12.023; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, DOI 10.1016/0167-8655(86)90013-9; Wang H, 2006, IEEE T PATTERN ANAL, V28, P942; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; Wu WZ, 2002, INFORM SCIENCES, V144, P201, DOI 10.1016/S0020-0255(02)00180-9; Yao YY, 1998, INFORM SCIENCES, V111, P239, DOI 10.1016/S0020-0255(98)10006-3; Zhang B, 2004, IEEE T PATTERN ANAL, V26, P525; Zhou CY, 2006, PATTERN RECOGN, V39, P635, DOI 10.1016/j.patocog.2005.09.004	34	69	87	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	FEB	2008	34	2					866	876		10.1016/j.eswa.2006.10.043		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	263TH	WOS:000253238900008	
J	Solomatine, DP; Maskey, M; Shrestha, DL				Solomatine, Dirnitri P.; Maskey, Mahesh; Shrestha, Durga Lal			Instance-based learning compared to other data-driven methods in hydrological forecasting	HYDROLOGICAL PROCESSES			English	Article						hydrological modelling; floods; data-driven models; instance-based learning; artificial neural networks; locally weighted regression; k-nearest neighbour method	ARTIFICIAL NEURAL-NETWORKS; RAINFALL-RUNOFF MODELS; PREDICTION	Data-driven techniques based on machine learning algorithms are becoming popular in hydrological modelling, in particular for forecasting. Artificial neural networks (ANNs) are often the first choice. The so-called instance-based learning (IBL) has received relatively little attention, and the present paper explores the applicability of these methods in the field of hydrological forecasting. Their performance is compared with that of ANNs, M5 model trees and conceptual hydrological models. Four short-term flow forecasting problems were solved for two catchments. Results showed that the IBL methods often produce better results than ANNs and M5 model trees, especially if used with the Gaussian kernel function. The study showed that IBL is an effective data-driven method that can be successfully used in hydrological forecasting. Copyright (c) 2007 John Wiley & Sons, Ltd.	[Solomatine, Dirnitri P.; Shrestha, Durga Lal] UNESCO, IHE, Inst Water Educ, NL-2601 DA Delft, Netherlands; [Maskey, Mahesh] NepalConsult P Ltd, Civil Engn, Kathmandu, Nepal	Solomatine, DP (reprint author), UNESCO, IHE, Inst Water Educ, POB 3015, NL-2601 DA Delft, Netherlands.	d.solomatine@unesco-ihe.org	Shrestha, Durga/B-5610-2013	Shrestha, Durga/0000-0002-5545-1736			Abrahart RJ, 2000, HYDROL PROCESS, V14, P2157, DOI 10.1002/1099-1085(20000815/30)14:11/12<2157::AID-HYP57>3.0.CO;2-S; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Allegra A, 1998, MAGNESIUM RES, V11, P11; BECKER A, 1987, WATER RESOUR RES, V23, P1043, DOI 10.1029/WR023i006p01043; Bray M, 2004, J HYDROINFORM, V6, P265; Cigizoglu HK, 2003, HYDROLOG SCI J, V48, P349, DOI 10.1623/hysj.48.3.349.45288; CLEVELAND WS, 1994, 953 AT T BELL LAB ST; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dawson CW, 2001, PROG PHYS GEOG, V25, P80, DOI 10.1191/030913301674775671; Dibike YB, 2001, PHYS CHEM EARTH PT B, V26, P1, DOI 10.1016/S1464-1909(01)85005-X; DIBIKE Y, 1999, GEOPH RES ABSTR; FEDOROV VV, 1993, NONPARAMETRIC STAT, V2, P355; Franchini M, 1996, HYDROLOG SCI J, V41, P21, DOI 10.1080/02626669609491476; GALEATI G, 1990, HYDROLOG SCI J, V35, P79, DOI 10.1080/02626669009492406; Gasser T., 1979, LECT NOTES MATH, V757, P23; GOVINDARAJU RS, 2000, ARTIFICIAL NEURAL NE, P329; HAYKIN S, 1999, NEURAL NETWORKS COMP; HSU KL, 1995, WATER RESOUR RES, V31, P2517, DOI 10.1029/95WR01955; KARLSSON M, 1987, WATER RESOUR RES, V23, P1300, DOI 10.1029/WR023i007p01300; KUNCHEVA LI, 2004, COMBINING PATTERN CL; Maier HR, 2000, ENVIRON MODELL SOFTW, V15, P101, DOI 10.1016/S1364-8152(99)00007-9; MARSIGLI M, 2002, MUSIC MULTIPLE SENSO; Minns AW, 1996, HYDROLOG SCI J, V41, P399, DOI 10.1080/02626669609491511; Mitchell T.M., 1997, MACH LEARN, P414; Quinlan J. R, 1992, 5 AUSTR JOINT C ART, P343; QUINLAN JR, 1993, MACH LEARN P 10 INT, P236; REFSGAARD JC, 1996, DISTRIBUTED HYDROLOG, P321; Scott D. W., 1992, MULTIVARIATE DENSITY; Shamseldin AY, 1996, J HYDROL, V179, P353, DOI 10.1016/0022-1694(95)02833-1; Shrestha DL, 2006, NEURAL NETWORKS, V19, P225, DOI 10.1016/j.neunet.2006.01.012; SHRESTHA I, 2003, CONCEPTUAL DATA DRIV; Solomatine D. P., 2004, 6 INT C HYDR; SOLOMATINE DP, 2004, J HYDROLOGIC ENG, V9; Solomatine DP, 2006, NEURAL NETWORKS, V19, P215, DOI 10.1016/j.neunet.2006.01.008; Solomatine DP, 2003, HYDROLOG SCI J, V48, P399, DOI 10.1623/hysj.48.3.399.45291; SOLOMATINE DP, 2005, ENCY HYDROLOGICAL SC; Sugawara M, 1995, COMPUTER MODELS WATE, P165; Todini E, 1996, J HYDROL, V175, P339, DOI 10.1016/S0022-1694(96)80016-3; Toth E, 2000, J HYDROL, V239, P132, DOI 10.1016/S0022-1694(00)00344-9; Weiss SM, 1995, J ARTIF INTELL RES, V3, P383; WITTEN IH, 2000, DATA MINING PRACTICA, P132; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	42	11	11	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0885-6087		HYDROL PROCESS	Hydrol. Process.	JAN 15	2008	22	2					275	287		10.1002/hyp.6592		13	Water Resources	Water Resources	259LE	WOS:000252940000010	
J	Schalk, G; Brunner, P; Gerhardt, LA; Bischof, H; Wolpaw, JR				Schalk, G.; Brunner, P.; Gerhardt, L. A.; Bischof, H.; Wolpaw, J. R.			Brain-computer interfaces (BCIs): Detection instead of classification	JOURNAL OF NEUROSCIENCE METHODS			English	Article						brain-computer interface (BCI); electruencephalography (EEG); electrocorticography (ECoG); augmentative communication; brain-machine interface; Gaussian mixture model; background modeling; SIGFRIED	EEG-BASED DISCRIMINATION; GAUSSIAN MIXTURE-MODELS; EM ALGORITHM; FEATURE-SELECTION; COMPETITION 2003; MOVEMENT SIGNAL; HAND MOVEMENTS; COMMUNICATION; DEVICE; IMAGINATION	Many studies over the past two decades have shown that people can use brain signals to convey their intent to a computer through brain-computer interfaces (BCIs). These devices operate by recording signals from the brain and translating these signals into device commands. They can be used by people who are severely paralyzed to communicate without any use of muscle activity. One of the major impediments in translating this novel technology into clinical applications is the current requirement for preliminary analyses to identify the brain signal features best suited for communication. This paper introduces and validates signal detection, which does not require such analysis procedures, as a new concept in BCI signal processing. This detection concept is realized with Gaussian mixture models (GMMs) that are used to model resting brain activity so that any change in relevant brain signals can be detected. It is implemented in a package called SIGFRIED (SIGnal modeling For Real-time Identification and Event Detection). The results indicate that SIGFRIED produces results that are within the range of those achieved using a common analysis strategy that requires preliminary identification of signal features. They indicate that such laborious analysis procedures could be replaced by merely recording brain signals during rest. In summary, this paper demonstrates how SIGFRIED could be used to overcome one of the present impediments to translation of laboratory BCI demonstrations into clinically practical applications. (C) 2007 Published by Elsevier B.V.	[Schalk, G.; Brunner, P.; Wolpaw, J. R.] New York State Dept Hlth, Wadsworth Ctr Labs & Res, Brain Comp Interface Res & Dev Program, Albany, NY 12237 USA; [Schalk, G.; Gerhardt, L. A.] Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY USA; [Brunner, P.; Bischof, H.] Graz Univ Technol, Inst Comp Graph & Vis, A-8010 Graz, Austria; [Wolpaw, J. R.] SUNY Albany, Sch Publ Hlth, Albany, NY USA	Schalk, G (reprint author), New York State Dept Hlth, Wadsworth Ctr Labs & Res, Brain Comp Interface Res & Dev Program, Albany, NY 12237 USA.	schalk@wadsworth.org					Akaike H, 1973, P 2 INT S INF THEOR, P267; Anderer P, 1999, NEUROPSYCHOBIOLOGY, V40, P150, DOI 10.1159/000026613; Babiloni F, 2000, IEEE T REHABIL ENG, V8, P186, DOI 10.1109/86.847810; Biernacki C, 2003, COMPUT STAT DATA AN, V41, P561, DOI 10.1016/S0167-9473(02)00163-9; Birbaumer N, 1999, NATURE, V398, P297, DOI 10.1038/18581; Blanchard G, 2004, IEEE T BIO-MED ENG, V51, P1062, DOI 10.1109/TBME.2004.826691; Blankertz B, 2004, IEEE T BIO-MED ENG, V51, P1044, DOI 10.1109/TBME.2004.826692; BLANKERTZ B, 2003, BCI COMPETITION 2003; BOZDOGAN H, 1987, PSYCHOMETRIKA, V52, P345, DOI 10.1007/BF02294361; Burg J. P., 1967, P 37 M SOC EXPL GEOP; BURG JP, 1968, NAT ADV STUD I SIGN, P42; CACOULLO.T, 1966, ANN I STAT MATH, V18, P179, DOI 10.1007/BF02869528; CELEUX G, 1992, COMPUT STAT DATA AN, V14, P279; Childers D.G., 1978, MODERN SPECTRUM ANAL; Costa EJX, 2000, MED ENG PHYS, V22, P345, DOI 10.1016/S1350-4533(00)00051-5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Donoghue JP, 2007, J PHYSIOL-LONDON, V579, P603, DOI 10.1113/jphysiol.2006.127209; Duda R.O., 2001, PATTERN CLASSIFICATI; FARWELL LA, 1988, ELECTROEN CLIN NEURO, V70, P510, DOI 10.1016/0013-4694(88)90149-6; FRIEDMAN N, 1997, IEEE P 23 C UNC ART; GARDNER A, 2005, J MACH LEARN RES, V7, P1025; Garrett D, 2003, IEEE T NEUR SYS REH, V11, P141, DOI 10.1109/TNSRE.2003.814441; Goncharova II, 2003, CLIN NEUROPHYSIOL, V114, P1580, DOI 10.1016/S1388-2457(03)00093-2; Gysels E, 2005, SIGNAL PROCESS, V85, P2178, DOI 10.1016/j.sigpro.2005.07.008; Harris KD, 2000, J NEUROPHYSIOL, V84, P401; Harville M, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P3; Haykin S, 1998, NEURAL NETWORKS COMP; Hochberg LR, 2006, NATURE, V442, P164, DOI 10.1038/nature04970; Huan Nai-Jen, 2004, J Neural Eng, V1, P142, DOI 10.1088/1741-2560/1/3/003; Kennedy PR, 2000, IEEE T REHABIL ENG, V8, P198, DOI 10.1109/86.847815; Kubler A, 2005, NEUROLOGY, V64, P1775, DOI 10.1212/01.WNL.0000158616.43002.6D; Kubler A, 1999, EXP BRAIN RES, V124, P223, DOI 10.1007/s002210050617; KUO B, 2003, P GEOSC REM SENS S I, V1, P276; Lal TN, 2004, IEEE T BIO-MED ENG, V51, P1003, DOI 10.1109/TBME.2004.827827; Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827; Liyuan Li, 2004, IEEE Transactions on Image Processing, V13, DOI 10.1109/TIP.2004.836169; Marple L., 1987, DIGITAL SPECTRAL ANA; MCFARLAND DJ, 1993, PSYCHOBIOLOGY, V21, P77; McFarland DJ, 2000, BRAIN TOPOGR, V12, P177, DOI 10.1023/A:1023437823106; McFarland DJ, 2005, IEEE T NEUR SYS REH, V13, P372, DOI 10.1109/TNSRE.2005.848627; McFarland DJ, 2006, IEEE T NEUR SYS REH, V14, P135, DOI 10.1109/TNSRE.2006.875637; McFarland DJ, 1997, ELECTROEN CLIN NEURO, V103, P386, DOI 10.1016/S0013-4694(97)00022-2; McFarland DJ, 1997, BEHAV RES METH INS C, V29, P337, DOI 10.3758/BF03200585; Millan JD, 2004, IEEE T BIO-MED ENG, V51, P1026, DOI 10.1109/TBME.2004.827086; Muller K. R., 2006, IEEE SIGNAL PROCESS, V23, P126; Muller KR, 2003, IEEE T NEUR SYS REH, V11, P165, DOI 10.1109/TNSRE.2003.814484; Neuper C, 2005, COGNITIVE BRAIN RES, V25, P668, DOI 10.1016/j.cogbrainres.2005.08.014; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Pernkopf F, 2005, IEEE T PATTERN ANAL, V27, P1344, DOI 10.1109/TPAMI.2005.162; Pfurtscheller G, 1997, ELECTROEN CLIN NEURO, V103, P642, DOI 10.1016/S0013-4694(97)00080-1; PFURTSCHELLER G, 1993, J MICROCOMPUT APPL, V16, P293, DOI 10.1006/jmca.1993.1030; Pfurtscheller G, 2000, NEUROSCI LETT, V292, P211, DOI 10.1016/S0304-3940(00)01471-3; Pless R., 2003, IEEE C COMP VIS PATT, V2, P73; Priestley M. B., 1981, SPECTRAL ANAL TIME S; Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Schalk G, 2004, IEEE T BIO-MED ENG, V51, P1034, DOI 10.1109/TBME.2004.827072; SCHLOGL A, 1999, SLEEP RES ONLINE S1, V2, P586; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Serruya MD, 2002, NATURE, V416, P141, DOI 10.1038/416141a; Sharbrough F, 1991, J CLIN NEUROPHYSIOL, V8, P200; Stauffer C., 1999, INT C COMP VIS PATT, VII, P246; SUTTER EE, 1992, J MICROCOMPUT APPL, V15, P31, DOI 10.1016/0745-7138(92)90045-7; Taylor DM, 2002, SCIENCE, V296, P1829, DOI 10.1126/science.1070291; Torr PHS, 1997, PROC CVPR IEEE, P47, DOI 10.1109/CVPR.1997.609296; TOYAMA K, 1999, IEEE P 7 INT C COMP, V1, P20; Vapnik V., 1974, AUTOMAT REM CONTR+, V34, P1226; VAPNIK VN, 1974, AUTOMAT REM CONTR, V34, P1403; Vaughan TM, 2006, IEEE T NEUR SYS REH, V14, P229, DOI 10.1109/TNSRE.2006.875577; Wessberg J, 2000, NATURE, V408, P361; WOLPAW JR, 1991, CLIN NEUROPHYSIOL, V78, P252; WOLPAW JR, 2002, ELECTROENCEPHALOGR C, V113, P767; Wolpaw JR, 2004, P NATL ACAD SCI USA, V101, P17849, DOI 10.1073/pnas.0403504101	75	27	28	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0270		J NEUROSCI METH	J. Neurosci. Methods	JAN 15	2008	167	1					51	62		10.1016/j.jneumeth.2007.08.010		12	Biochemical Research Methods; Neurosciences	Biochemistry & Molecular Biology; Neurosciences & Neurology	248OU	WOS:000252164300007	
J	Chen, YH; Yao, YY				Chen, Yaohua; Yao, Yiyu			A multiview approach for intelligent data analysis based on data operators	INFORMATION SCIENCES			English	Article						multiview; intelligent data analysis; modal-style data operators; concept lattice; granular computing	ROUGH SET-THEORY; PATTERN-CLASSIFICATION	Multiview intelligent data analysis explores data from different perspectives to reveal various types of structures and knowledge embedded in the data. Each view may capture a specific aspect of the data and hence satisfy the needs of a particular group of users. Collectively, multiple views provide a comprehensive description and understanding of the data. In this paper, we propose a multiview framework of intelligent data analysis based on modal-style data operators. The classes of the data operators include basic set assignment, sufficiency, dual sufficiency, necessity and possibility operators. They demonstrate various types of data relationships and characterize various features and granulated views of the data. It is shown that different structures of the data can also be constructed based on the different data operators. Crown Copyright (C) 2007 Published by Elsevier Inc. All rights reserved.	Univ Regina, Dept Comp Sci, Regina, SK S4S 0A2, Canada	Chen, YH (reprint author), Univ Regina, Dept Comp Sci, Regina, SK S4S 0A2, Canada.	chen115y@cs.uregina.ca; yyao@cs.uregina.ca	Yao, Yiyu/B-2926-2008				Aleksander I., 1990, INTRO NEURAL COMPUTI; AMARI S, 1990, P IEEE, V78, P1443, DOI 10.1109/5.58324; Anderberg M. R., 1973, CLUSTER ANAL APPL; BAJCSY R, 1989, COMPUT VISION GRAPH, V46, P1, DOI 10.1016/S0734-189X(89)80014-3; Bargiela A, 2002, GRANULAR COMPUTING I; Belkhouche B, 2000, INT J SOFTW ENG KNOW, V10, P557, DOI 10.1142/S021819400000033X; BELKHOUCHE B, 1996, FDN SOFTWARE ENG, P159; Breiman L, 1984, CLASSIFICATION REGRE; BUSZKOWSKI W, 1998, LECT NOTES ARTIF INT, V1424, P115; Chen Y.-H., 2006, P 2006 IEEE INT C GR, P281; Cohn P. M., 1965, UNIVERSAL ALGEBRA; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duntsch I., 2003, THEORY APPL RELATION, P216; Ester M., 1996, P 2 INT C KNOWL DISC, P226; Freitas A. A., 2000, SIGKDD EXPLORATIONS, V2, P65; GANTER B., 1999, FORMAL CONCEPT ANAL; Gediga G., 2002, P 2002 IEEE INT C DA, P155; Grenander U., 1993, GEN PATTERN THEORY; HAN H, 2003, P 26 ANN INT ACM SIG, P445; Hand D.J., 1998, INTELL DATA ANAL, V2, P67, DOI 10.1016/S1088-467X(99)80001-8; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; JEFFRIES V, 1980, SOCIAL STRATIFICATIO; Jeon B, 1999, IEEE T GEOSCI REMOTE, V37, P1073; King B, 1967, J AM STAT ASSOC, V69, P86; KOTSIANTIS S, 2004, T INFORM SCI APPL, V1, P73; Kulkarni SR, 1998, IEEE T INFORM THEORY, V44, P2178, DOI 10.1109/18.720536; Lin CR, 2005, IEEE T KNOWL DATA EN, V17, P628; Liu B, 1998, P 4 INT C KNOWL DISC, P80; LU SY, 1978, IEEE T SYST MAN CYB, V8, P381, DOI 10.1109/TSMC.1978.4309979; McQueen J., 1967, P 5 BERK S MATH STAT, P281; MICHALSKI RS, 1993, MULTISTRATEGY LEARNI; Minsky M., 1988, PERCEPTRONS; Nguyen SH, 2001, COMPUT INTELL, V17, P514, DOI 10.1111/0824-7935.00161; Orlowska E., 1998, INCOMPLETE INFORM RO; Parasuraman R, 1997, HUM FACTORS, V39, P230, DOI 10.1518/001872097778543886; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Pearl J., 1988, PROBABILISTIC REASON, p[505, 506, 507, 524]; Pedrycz W., 2001, Proceedings Joint 9th IFSA World Congress and 20th NAFIPS International Conference (Cat. No. 01TH8569), DOI 10.1109/NAFIPS.2001.943745; Pedrycz W, 2002, INT J INTELL SYST, V17, P173, DOI 10.1002/int.10015; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Sokal RR, 1973, NUMERICAL TAXONOMY; SPRANDEL HZ, 1985, PSYCHOEDUCATIONAL US; Srikant R., 1993, P ACM SIGMOD C MAN D, P207, DOI DOI 10.1145/170035.170072; Vapnik V.N., 1998, STAT LEARNING THEORY; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967; Wille R, 1982, ORDERED SETS, P445; Wolski M., 2003, FUNDAMENTA INFORM CS, P1; WONG SKM, 1995, COMPUT INTELL, V11, P406, DOI 10.1111/j.1467-8640.1995.tb00041.x; Yao Y. Y., 2004, P 2004 ANN M N AM FU, P796; Yao YY, 1998, INFORM SCIENCES, V111, P239, DOI 10.1016/S0020-0255(98)10006-3; Yao YY, 2004, LECT NOTES ARTIF INT, V3066, P59; Yao Y.Y., 2004, COMPUTER SCI, V31, P1; Yao YY, 2003, LECT NOTES ARTIF INT, V2639, P44; Yin XX, 2003, SIAM PROC S, P331; Zadeh LA, 1997, FUZZY SET SYST, V90, P111, DOI 10.1016/S0165-0114(97)00077-8; Zeng H. J., 2003, P IEEE INT C DAT MIN, P443; Zhong N, 2005, LECT NOTES COMPUT SC, V3776, P98; ZHONG N, 2005, P ICDM WORKSH FDN SE, P130; ZHU W, 2007, GEN ROUGH SETS BASED; Zhu W, 2003, INFORM SCIENCES, V152, P217, DOI 10.1016/S0020-0255(03)00056-2; Zhu W, 2007, INFORM SCIENCES, V177, P1499, DOI 10.1016/j.ins.2006.06.009; ZIMMERMANN A, 2004, P 7 INT C DISC SCI D, P60	65	35	38	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255		INFORM SCIENCES	Inf. Sci.	JAN 2	2008	178	1					1	20		10.1016/j.ins.2007.08.011		20	Computer Science, Information Systems	Computer Science	228LJ	WOS:000250731100001	
S	Caulier, Y; Bourennane, S		BlancTalon, J; Bourennane, S; Philips, W; Popescu, D; Scheunders, P		Caulier, Y.; Bourennane, S.			Fourier-Based Inspection of Free-Form Reflective Surfaces	ADVANCED CONCEPTS FOR INTELLIGENT VISION SYSTEMS, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	10th International Conference on Advanced Concepts for Intelligent Vision Systems	OCT 20-24, 2008	Juan les Pins, FRANCE	SEE, Ghent Univ, Philips Res, DGA, NXP Semicond, IEEE Benelux Signal Proc Chapter, Eurasip, Barco, DSP Valley, FWO Res Community Audiovisual Syst			INTERFEROMETRY; TRANSFORM	A general free-form surface inspection approach relying oil the projection of a structured light pattern and the interpretation of the generated stripe structures by means of Fourier-based features is proposed in this paper. The major concerns of this paper are the determination of various refrence sets of stripe patterns, and the detailed investigation oil the subset of Fourier features that best characterizes free-form bright/dark structures. In order to tackle the inspection problem with a general approach, a first part of this paper is dedicated to the definition of different image data sets that correspond to various types of free-form specular shapes recorded with a structured illumination. A second part deals with the optimization of the most appropriate pattern recognition process. The optimization is dedicated to the use of different pattern arrangements, and the evaluation of different Fourier feature subsets. It is shown that with only 10 Fourier features and a certain pattern arrangement, high classification rates of free-form surfaces can be obtained.	[Caulier, Y.] Fraunhofer Inst Integrierte Schaltungen IIS, D-91058 Erlangen, Germany	Caulier, Y (reprint author), Fraunhofer Inst Integrierte Schaltungen IIS, Wolfsmantel 33, D-91058 Erlangen, Germany.	yannick.caulier@iis.fraunhofer.de; salah.bourennane@fresnel.fr; salah.bourennane@fresnel.fr	Bourennane, Salah/F-2928-2010				BABICH GA, 1996, IEEE T PATTERN ANAL, V18; CAULIER Y, 2008, J OPTICAL ENG, V47; CAULIER Y, 2008, EURASIP J IMAGE VIDE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Efron B., 1993, INTRO BOOTSTRAP; Foresti G.L., 2002, IEEE T NEURAL NETWOR, V13; GEVA S, 1991, IEEE T NEURAL NETWOR, V2; GOLDSTEIN M, 1972, IEEE T INFORM THEORY, V18; GRUNDITZ C, 2004, P IJCNN BUD JUL, V3, P1881; GUTIERREZOSUNA R, 2003, IEEE SENS J, V2, P273; KAMMEL K, 2004, DEFLEKTOMETRISCHE UN; Kammel S, 2003, TECH MESS, V70, P193, DOI 10.1524/teme.70.4.193.20181; KNAUER M, 2004, OPTICAL METROLOGY PR, V5457, P366; KOHAVI R, 1995, P IJCAI, V3, P1137; KOHAVI R, 2002, ARTIF INTELL, V2, P189; KRUGER S, 2000, MACHINE VISION APP 8, V3966, P145; Kunttu I, 2006, MACH VISION APPL, V17, P211, DOI 10.1007/s00138-006-0030-6; LI WB, 2005, IEEE T ANTENN PROPAG, V53, P1154; Li XD, 2000, OPT ENG, V39, P2821, DOI 10.1117/1.1308485; OPPENHEIM AV, 1981, P IEEE, V69, P529, DOI 10.1109/PROC.1981.12022; PERNKOPF F, 2002, EURASIP J APPL SIG P, P667; QIAN K, 2005, MEASUREMENT SCI TECH, V15, P1582; QIAN K, 2005, FRINGE 2005 FAULT DE; REINDL I, 2004, GEOMETRIC SURFACE IN, P849; RUIZ A, 2001, IEEE T NEURAL NETWOR, V12; TAKEDA M, 1982, J OPT SOC AM, V72, P156, DOI 10.1364/JOSA.72.000156; TANG WH, 2008, IEEE T POWER DELIVER, V23; Tsai DM, 2003, IMAGE VISION COMPUT, V21, P307, DOI 10.1016/S0262-8856(03)00007-6; UNSALAN C, 1998, PATTERN RECOGNITION; WESKA JS, 1976, IEEE T SYST MAN CYB, V6, P269; Witten I. H., 2005, DATA MINING; *COM AG, 2005, FEINF FOX HIGH RES 2; 2005, ACERIS 3D FC SUBSTRA	33	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-88457-6	LECT NOTES COMPUT SC			2008	5259						125	136				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BIR31	WOS:000262163800012	
S	Yong, Z; Bing, W; Liang, Z; Yang, YP		Huang, DS; Wunsch, DC; Levine, DS; Jo, KH		Yong, Zeng; Bing, Wang; Liang, Zhao; Yang, Yu-Pu			Nonparametric classification based on local mean and class mean	ADVANCED INTELLIGENT COMPUTING THEORIES AND APPLICATIONS, PROCEEDINGS: WITH ASPECTS OF THEORETICAL AND METHODOLOGICAL ISSUES	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	4th International Conference on Intelligent Computing	SEP 15-18, 2008	Shanghai, PEOPLES R CHINA					The k-nearest neighbor classification rule (k-NNR) is a very simple, yet powerful nonparametric classification method. As a variant of the k-NNR, a nonparametric classification method based on the local mean vector has achieved good classification performance. In this paper, a new variant of the k-NNR, a nonparametric classification method based on the local mean vector and the class mean vector has been proposed. Not only the information of the local mean of the k nearest neighbors of the unlabeled pattern in each individual class but also the knowledge of the ensemble mean of each individual class are taken into account in this new classification method. The proposed classification method is compared with the k-NNR, and the local mean-based nonparametric classification in terms of the classification error rate on the unknown patterns. Experimental results confirm the validity of this new classification approach.		Yong, Z (reprint author), Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200240, Peoples R China.						Asuncion A., 2007, UCI MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 2001, PATTERN CLASSIFICATI; Fukunaga K., 1990, INTRO STAT PATTERN R; Jain A. K., 1988, PATTERN RECOGNITION; Mitani Y, 2006, PATTERN RECOGN LETT, V27, P1151, DOI 10.1016/j.patrec.2005.12.016; Rumelhart D E, 1986, PARALLEL DISTRIBUTED	7	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-87440-9	LECT NOTES COMPUT SC			2008	5226						593	600				8	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Computer Science	BIH57	WOS:000259555200074	
S	Fabris, F; Drago, I; Varejao, FM		Geffner, H; Prada, R; Alexandre, IM; David, N		Fabris, Fabio; Drago, Idilio; Varejao, Flavio M.			A Multi-measure Nearest Neighbor Algorithm for Time Series Classification	ADVANCES IN ARTIFICIAL INTELLIGENCE - IBERAMIA 2008, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	11th Ibero-American Conference on Artificial Intelligence	OCT 14-17, 2008	Lisbon, PORTUGAL	ADETTI, ISCTE, FCT, AEPIA, APPIA		Data Mining; Machine Learning; Time Series Classification; Multi-Measure Classifier	CLASSIFIERS	In this paper, we have evaluated some techniques for the time series classification problem. Many distance measures have been proposed as an alternative to the Euclidean Distance in the Nearest Neighbor Classifier. To verify the assumption that the combination of various similarity measures may produce a more accurate classifier, we have proposed an algorithm to combine several measures based on weights. We have carried out a set of experiments to verify the hypothesis that the new algorithm is better than the classical ones. Our results show an improvement over the well-established Nearest-Neighbor with DTW (Dynamic Time Warping), but in general, they were obtained combining few measures in each problem used in the experimental evaluation.	[Fabris, Fabio; Drago, Idilio; Varejao, Flavio M.] Univ Fed Espirito Santo, Dept Comp Sci, BR-29060900 Vitoria, ES, Brazil	Fabris, F (reprint author), Univ Fed Espirito Santo, Dept Comp Sci, BR-29060900 Vitoria, ES, Brazil.	ffabris@inf.ufes.br; idrago@inf.ufes.br; fvarejao@inf.ufes.br	David, Nuno/B-4662-2012				Agrawal R., 1995, P 21 INT C VER LARG, P490; ANTUNES CM, 2001, P WORKSH TEMP DAT MI; Bozkaya T., 1997, CIKM, P128; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daubechies I., 1992, CBMS NSF REG C SERIE; David BL., 1993, P 4 INT C FDN DAT OR, P69; Demsar J, 2006, J MACH LEARN RES, V7, P1; Devijver P. A., 1982, PATTERN RECOGNITION; Duda R. O., 2001, PATTERN CLASSIFICATI; Gusfield D., 1997, ALGORITHMS STRINGS T; HAMMING RW, 1950, AT&T TECH J, V29, P147; Keogh E, 2003, DATA MIN KNOWL DISC, V7, P349, DOI 10.1023/A:1024988512476; Keogh E. J., 2006, UCR TIME SERIES CLAS; KOHAVI R, 1997, 9 EUR C MACH LEARN P; Levenshtein V. I., 1966, SOV PHYS DOKL, V10, P707; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; Salzberg SL, 1997, DATA MIN KNOWL DISC, V1, P317, DOI 10.1023/A:1009752403260; SAVARY L, 2002, ECAI 2002 WORKSH KNO, P63; Sheskin DJ, 2000, HDB PARAMETRIC NONPA; Xi X., 2006, ICML 06, P1033	20	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-88308-1	LECT NOTES COMPUT SC			2008	5290						153	162				10	Computer Science, Artificial Intelligence	Computer Science	BIM81	WOS:000260922300016	
S	Costa, EP; Lorena, AC; Carvalho, ACPLF; Freitas, AA		Bazzan, ALC; Craven, M; Martins, NF		Costa, Eduardo P.; Lorena, Ana C.; Carvalho, Andre C. P. L. F.; Freitas, Alex A.			Top-down hierarchical ensembles of classifiers for predicting G-Protein-Coupled-Receptor functions	ADVANCES IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY, PROCEEDINGS	LECTURE NOTES IN BIOINFORMATICS		English	Proceedings Paper	3rd Brazilian Symposium on Bioinformatics (BSB 2008)	AUG 28-30, 2008	Santo Andre, BRAZIL	UFABC, CMCC, Brazilian Comp Soc, FAPESP, CNPq, CAPES, CLC bio, SGI			CLASSIFICATION; DATABASE; FAMILIES	Despite the recent advances in Molecular Biology, the function of a large amount of proteins is still unknown. An approach that can be used in the prediction of a protein function consists of searching against secondary databases, also known as signature databases. Different strategies can be applied to use protein signatures in the prediction of function of proteins. A sophisticated approach consists of inducing a classification model for this prediction. This paper applies five hierarchical classification methods based on the standard Top-Down approach and one hierarchical classification method based on a new approach named Top-Down Ensembles - based on the hierarchical combination of classifiers - to three different protein functional classification datasets that employ protein signatures. The algorithm based on the Top-Down Ensembles approach presented slightly better results than the other algorithms, indicating that combinations of classifiers can improve the performance of hierarchical classification models.	[Costa, Eduardo P.; Freitas, Alex A.] USP, ICMC, Dept Ciencias Comp, BR-13560970 Sao Carlos, SP, Brazil	Costa, EP (reprint author), USP, ICMC, Dept Ciencias Comp, Caixa Postal 668, BR-13560970 Sao Carlos, SP, Brazil.		Freitas, Alex/H-1249-2011; Lorena, Ana/A-4494-2008				Apweiler R, 2001, NUCLEIC ACIDS RES, V29, P37, DOI 10.1093/nar/29.1.37; Apweiler R, 2004, NUCLEIC ACIDS RES, V32, pD115, DOI 10.1093/nar/gkh131; Attwood Terri K, 2002, Brief Bioinform, V3, P252, DOI 10.1093/bib/3.3.252; Bateman A, 2002, NUCLEIC ACIDS RES, V30, P276, DOI 10.1093/nar/30.1.276; Blockeel H, 2002, P ACM SIGKDD 2002 WO, P21; Burr Ridge I, 1997, MACHINE LEARNING; Cohen W. W., 1995, P 12 INT C MACH LEAR, P115; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; DIMITRIADOU E, 2006, E1071 MISC FUNCTIONS, P1; FILMORE D, 2004, MODERN DRUG DISCOVER, V1, P24; FREITAS AA, 2007, RES TRENDS DATA MINI, P175; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Holden N., 2006, P IEEE SWARM INT S S, P77; HORNIK K, RWEKA R INTERFACE WE; KUNCHEVA LI, 2004, COMBINING PATTERN CL; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Salzberg SL, 1997, DATA MIN KNOWL DISC, V1, P317, DOI 10.1023/A:1009752403260; Sigrist Christian J A, 2002, Brief Bioinform, V3, P265, DOI 10.1093/bib/3.3.265; Sun A, 2003, J AM SOC INF SCI TEC, V54, P1014, DOI 10.1002/asi.10298; SUN A, 2003, COOPERATIVE INTERNET, V256; VENABLES WN, 2006, R DEV CORE TEAM INTR; *E B I, PROT FUNCT; *GPCRDB, 2006, INF SYST G PROT COUP; 1972, E NOMENCLATURE IUPAC, P104; S I BIOINFORMATICS P	28	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-85556-9	LECT N BIOINFORMAT			2008	5167						35	46				12	Biochemical Research Methods; Computer Science, Information Systems; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Computer Science; Mathematical & Computational Biology	BIF67	WOS:000259140500004	
S	Tahir, MA; Smith, JE		Siarry, P; Michalewicz, Z		Tahir, Muhammad A.; Smith, James E.			Feature Selection for Heterogeneous Ensembles of Nearest-neighbour Classifiers Using Hybrid Tabu Search	ADVANCES IN METAHEURISTICS FOR HARD OPTIMIZATION	Natural Computing Series		English	Article; Book Chapter						Nearest Neighbour; Tabu Search; Ensemble Classifier; Feature Selection		The nearest-neighbour (NN) classifier has long been used in pattern recognition, exploratory data analysis, and data mining problems. A vital consideration in obtaining good results with this technique is the choice of distance function, and correspondingly which features to consider when computing distances between samples. In this chapter, a new ensemble technique is proposed to improve the performance of NN classifiers. The proposed approach combines multiple NN classifiers, where each classifier uses a different distance function and potentially a different set of features (feature vector). These feature vectors are determined for each distance metric using a Simple Voting Scheme incorporated in Tabu Search (TS). The proposed ensemble classifier with different distance metrics and different feature vectors (TS-DF/NN) is evaluated using various benchmark data sets from the UCI Machine Learning Repository. Results have indicated a significant increase in the performance when compared with various well-known classifiers. The proposed ensemble method is also compared with an ensemble classifier using different distance metrics but with the same feature vector (with or without Feature Selection (FS)).	[Tahir, Muhammad A.; Smith, James E.] Univ W England, Sch Comp Sci, Bristol BS16 1QY, Avon, England	Tahir, MA (reprint author), Univ W England, Sch Comp Sci, Bristol BS16 1QY, Avon, England.	Muhammad.Tahir@uwe.ac.uk; James.Smith@uwe.ac.uk					Amaldi E, 1998, THEOR COMPUT SCI, V209, P237, DOI 10.1016/S0304-3975(97)00115-1; BAO Y, 2004, LNCS, V3177; Bay S.D., 1998, P 15 INT C MACH LEAR, P37; Blake C.L., UCI REPOSITORY MACHI; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davies S, 1994, P 1994 AAAI FALL S R, P37; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Duda R., 1973, PATTERN CLASSIFICATI; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Glover F., 1990, ORSA Journal on Computing, V2; Glover F., 1993, Annals of Operations Research, V41; Glover F., 1989, ORSA Journal on Computing, V1; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; KOHAVI R, 1995, P 8 EUR C MACH LEARN; KORYCINSKI D, 2003, P IEEE INT GEOSC REM; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Michie D, 1994, MACHINE LEARNING NEU; Okun O., 2005, P ICML WORKSH LEARN, P51; Paredes R, 2006, IEEE T PATTERN ANAL, V28, P1100, DOI 10.1109/TPAMI.2006.145; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; SAIT SM, 1999, GEN ITERATIVE ALGORI; Serpico SB, 2001, IEEE T GEOSCI REMOTE, V39, P1360, DOI 10.1109/36.934069; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; Tahir MA, 2006, IEEE T INF TECHNOL B, V10, P782, DOI 10.1109/TITB.2006.879596; TAHIR MA, 2007, PATTERN RECOGNITION, V28; TAHIR MA, 2006, P IEEE INT C DAT MIN; Wang JG, 2007, PATTERN RECOGN LETT, V28, P207, DOI 10.1016/j.patrec.2006.07.002; WHITNEY AW, 1971, IEEE T COMPUT, VC 20, P1100, DOI 10.1109/T-C.1971.223410; Witten I., 2005, DATA MINING PRACTICA; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Yu SX, 2002, PATTERN RECOGN LETT, V23, P183, DOI 10.1016/S0167-8655(01)00118-0; Zhang HB, 2002, PATTERN RECOGN, V35, P701, DOI 10.1016/S0031-3203(01)00046-2	38	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1619-7127	978-3-540-72959-4	NAT COMPUT SER	Nat. Comput. Ser.		2008							69	85		10.1007/978-3-540-72960-0_4	10.1007/978-3-540-72960-0	17	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Computer Science	BKE57	WOS:000267892800004	
B	Khayat, O; Shahdoosti, HR; Khosravi, MH		Kazovsky, L; Borne, P; Mastorakis, N; KuriMorales, A; Sakellaris, I		Khayat, Omid; Shahdoosti, Hamid Reza; Khosravi, Mohammad Hosetin			Stable Relief in feature weighting	ADVANCES ON ARTIFICIAL INTELLIGENCE, KNOWLEDGE ENGINEERING AND DATA BASES, PROCEEDINGS	Artificial Intelligence Series-WSEAS		English	Proceedings Paper	7th WSEAS International Conference on Artificial Intelligence, Knowledge Engineering and Data Bases	FEB 20-22, 2008	Cambridge, ENGLAND	WSEAS	Univ Cambridge	feature weighting; Relief; Neural Network; Stable Relief	LEARNING ALGORITHMS	Feature weighting algorithms assign weights to features according to their relevance to a particular task. Unfortunately, the best-known feature weighting algorithm, ReliefF, is biased. It decreases the relevance of some features and increases the relevance of others when irrelevant attributes are added to the data set. This paper presents an improved version of the algorithm, Stable Relief, for classification tasks by extracting relevant information. This method, using Stable Relief, is applied to feature weighting for the nearest neighbor classifier and is tested on real-world classification tasks. The results show that it can improve the nearest neighbor classifier on the tested tasks, and also outperforms the Relief. This paper shows that Stable Relief outperforms ReliefF on the task of cat and dog discrimination, using real images.	[Khayat, Omid; Shahdoosti, Hamid Reza; Khosravi, Mohammad Hosetin] Amirkabir Univ, Dept Biomed Engn, Tehran, Iran	Khayat, O (reprint author), Amirkabir Univ, Dept Biomed Engn, Tehran, Iran.						AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; BINS J, 2000, FEATURE SELECTION HU, P156; BINS J, 2001, FEATURE SELECTION HU; Breiman L, 1984, CLASSIFICATION REGRE; Cardie C., 1993, P 10 INT C MACH LEAR, P25; Caruana R., 1994, INT C MACH LEARN; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; ISHIGURO H, 1996, IEEE RSJ INT C INT R; John G. H., 1994, P 11 INT C MACH LEAR, P121; KHAYAT O, 2007, EUR COMP C WSEAS GRE; KIRA K, 1992, 9 INT WORKSH MACH IN; KONONENKO I, 1994, EUR C MACH LEARN CAT; Ling CX, 1997, INT J PATTERN RECOGN, V11, P405, DOI 10.1142/S0218001497000184; Merz C. J., 1996, UCI REPOSITORY MACHI; ROBNIKSIKONJA M, 2001, INT C MACH LEARN WIL; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1023/A:1022661727670; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256	18	0	0	WORLD SCIENTIFIC AND ENGINEERING ACAD AND SOC	ATHENS	AG LOANNOU THEOLOGOU 17-23, 15773 ZOGRAPHOU, ATHENS, GREECE		978-960-6766-41-1	ARTIF INT SER WSEAS			2008							193	197				5	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BHY60	WOS:000257462700027	
J	Tan, SC; Rao, MVC; Lim, CP				Tan, Shing Chiang; Rao, M. V. C.; Lim, Chee Peng			Fuzzy ARTMAP dynamic decay adjustment: An improved fuzzy ARTMAP model with a conflict resolving facility	APPLIED SOFT COMPUTING			English	Article						adaptive resonance theory; classification; dynamic decay adjustment; fuzzy ARTMAP	PROBABILISTIC NEURAL-NETWORKS; PATTERN-RECOGNITION; DENSITY-FUNCTION; FAULT-DETECTION; DECISION TREES; CLASSIFICATION; ARCHITECTURE; CLASSIFIERS; ATTRIBUTES; INDUCTION	This paper presents a hybrid neural network classifier of fuzzy ARTMAP (FAM) and the dynamic decay adjustment (DDA) algorithm. The proposed FAMDDA model is a conflict-resolving classifier that can perform stable and incremental learning while settling overlapping of hyper-rectangular prototypes of different classes in minimizing misclassification rates. The performance of FAMDDA is evaluated using a number of benchmark data sets. The results are analyzed and compared with those from FAM and a number of machine learning classifiers. The outcomes show that FAMDDA has a better generalization capability than FAM, and its performance is comparable with those from other classifiers. The effectiveness of FAMDDA is also demonstrated in an application pertaining to condition monitoring of a circulating water system in a power generation station. Implications on the effectiveness of FAMDDA from the application point of view are discussed. (C) 2007 Elsevier B. V. All rights reserved.	Multimedia Univ, Fac Informat Sci & Technol, Cyberjaya 63100, Selangor, Malaysia; Multimedia Univ, Fac Engn & Technol, Selangor 63100, Malaysia; Univ Sci Malaysia, Sch Elect & Elect Engn, George Town 11800, Malaysia	Tan, SC (reprint author), Multimedia Univ, Fac Informat Sci & Technol, Cyberjaya 63100, Selangor, Malaysia.	sctan@mmu.edu.my					Akaike H., 1954, ANN I STAT MATH, V6, P127, DOI 10.1007/BF02900741; Berthold MR, 1998, NEUROCOMPUTING, V19, P167, DOI 10.1016/S0925-2312(97)00063-5; Berzal F, 2004, INFORM SCIENCES, V165, P73, DOI 10.1016/j.ins.2003.09.018; Carpenter G. A., 1995, Connection Science, V7, DOI 10.1080/09540099508915655; CARPENTER GA, 1992, IEEE T NEURAL NETWOR, V3, P698, DOI 10.1109/72.159059; Carpenter GA, 1997, NEURAL NETWORKS, V10, P1473, DOI 10.1016/S0893-6080(97)00004-X; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; CARPENTER GA, 1995, IEEE T NEURAL NETWOR, V6, P805, DOI 10.1109/72.392245; CARPENTER GA, 1991, NEURAL NETWORKS, V4, P565, DOI 10.1016/0893-6080(91)90012-T; CARPENTER GA, 1987, APPL OPTICS, V26, P4919, DOI 10.1364/AO.26.004919; CARPENTER GA, 1991, NEURAL NETWORKS, V4, P759, DOI 10.1016/0893-6080(91)90056-B; CARPENTER GA, 1988, COMPUTER, V21, P77, DOI 10.1109/2.33; Castellano G, 2004, IEEE T SYST MAN CY B, V34, P725, DOI 10.1109/TSMCB.2003.811291; CHEANG SM, 2003, 2003 C EV COMP CEC 0, V1, P248; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY B, 1991, NEAREST NEIGHBOUR PA; DUDA RO, 1973, PATTERN CLASSIFICAIO; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Fisher RA, 1936, ANN EUGENIC, V7, P179; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Gabrys B, 2000, IEEE T NEURAL NETWOR, V11, P769, DOI 10.1109/72.846747; GILES CL, 1987, APPL OPTICS, V26, P4972, DOI 10.1364/AO.26.004972; Gupta CN, 2007, APPL SOFT COMPUT, V7, P286, DOI 10.1016/j.asoc.2005.06.006; HECKERMAN D, 1995, COMMUN ACM, V38, P27, DOI 10.1145/203330.203336; Hettich S., 1998, UCI REPOSITORY MACHI; Hong TP, 2000, FUZZY SET SYST, V112, P127, DOI 10.1016/S0165-0114(98)00179-1; Huber K.- P., 1995, IEEE INT C NEUR NETW, V3, P1263; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; KOHONEN T, 1988, SELF ORGANIZATION AS; KOSINOV S, 2004, IEEE INT C COMP VIS; Kurgan LA, 2004, IEEE T KNOWL DATA EN, V16, P145, DOI 10.1109/TKDE.2004.1269594; Lam W, 2002, IEEE T PATTERN ANAL, V24, P1075; Last M, 2004, IEEE T KNOWL DATA EN, V16, P203, DOI 10.1109/TKDE.2004.1269598; Ledezma A, 2004, PROC INT C TOOLS ART, P49; Li XB, 2003, IEEE T SYST MAN CY A, V33, P194, DOI 10.1109/TSMCA.2002.806499; Lim CP, 1997, NEURAL NETWORKS, V10, P925, DOI 10.1016/S0893-6080(96)00123-2; Liu H., 1998, FEATURE SELECTION KN; Lopes MLM, 2005, APPL SOFT COMPUT, V5, P235, DOI 10.1016/j.asoc.2004.07.003; MACK YP, 1981, SIAM J ALGEBRA DISCR, V2, P311, DOI 10.1137/0602035; Mangasarian O. L., 1990, SIAM NEWS, V23; Michie D, 1994, MACHINE LEARNING NEU; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; Moshou D, 2005, APPL SOFT COMPUT, V5, P391, DOI 10.1016/j.asoc.2004.09.001; Nauck D, 1999, ARTIF INTELL MED, V16, P149, DOI 10.1016/S0933-3657(98)00070-0; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Quinlan J. R., 1993, PROGRAMS MACHINE LEA; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; REILLY DL, 1982, BIOL CYBERN, V45, P35, DOI 10.1007/BF00387211; Riquelme JC, 2003, INFORM SCIENCES, V156, P173, DOI 10.1016/S0020-0255(03)00175-0; Rizzi A, 2002, IEEE T NEURAL NETWOR, V13, P402, DOI 10.1109/72.991426; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; RUMELHART DE, 1986, PARALLEL DISTRIBUTED, P318; Shi D, 2005, NEURAL NETWORKS, V18, P951, DOI 10.1016/j.neunet.2005.02.006; SIMPSON PK, 1992, IEEE T NEURAL NETWOR, V3, P776, DOI 10.1109/72.159066; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Ster B., 1996, P INT C ENG APPL NEU, P427; Tan SC, 2004, IEEE T ENERGY CONVER, V19, P369, DOI 10.1109/TEC.2003.821826; WANG D, 2007, APPL SOFT COMPUT J, V8, P166; Wu ST, 2004, IEEE T IND ELECTRON, V51, P183, DOI 10.1109/TIE.2003.821897; Yen CW, 2004, PATTERN RECOGN LETT, V25, P725, DOI 10.1016/j.patrec.2004.01.012; Zhang NL, 2004, ARTIF INTELL MED, V30, P283, DOI 10.1016/j.artmed.2003.11.004	61	5	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1568-4946		APPL SOFT COMPUT	Appl. Soft. Comput.	JAN	2008	8	1					543	554		10.1016/j.asoc.2007.03.006		12	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	211FA	WOS:000249508500047	
S	Puteh, M; Hamdan, AR; Omar, K; Abu Bakar, A		Bentley, PJ; Lee, D; Jung, S		Puteh, Mazidah; Hamdan, Abdul Razak; Omar, Khairuddin; Abu Bakar, Azuraliza			Flexible immune network recognition system for mining heterogeneous data	ARTIFICIAL IMMUNE SYSTEMS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	7th International Conference on Artificial Immune Systems	AUG 10-13, 2008	Phuket, THAILAND			artificial immune system (AIS); classification; immune network; heterogeneous; accuracy; significant difference		Artificial Immune System (AIS) is all emerging technique for the classification task and proved to be a reliable technique. In previous studies, many classifiers including AIS classifiers require the data to be in numerical or categorical data. types prior to processing. The transformation of data into any other specific types from their original form call degrade the originality of the data and consume more space and pre processing time. This paper introduces AIS model using immune network for classifying heterogeneous data in its original types. The model is able to process the data with the types as represented in the database and it solves some bias problems highlighted in the AIS review papers. To ensure the consistent conditions and fair comparison, the selected existing algorithms use the same set of data as used in the proposed model. Experimental results show that this network-based model produces a better accuracy rate than the existing population-based immune algorithm and than the standard classifiers on most of the data from University of California, Irvive (UCI) Machine Learning Repository (MLR) and University of California, Riverside (UCR) Time Series Data (TSR).	[Puteh, Mazidah] Univ Teknol MARA, Terengganu, Malaysia	Puteh, M (reprint author), Univ Teknol MARA, Terengganu, Malaysia.						BROWNLEE J, 2005, 102 CISCP SWINB U FA; BROWNLEE J, 2005, 102 CSCA CISCP SWINB; BROWNLEE J, 2005, 102 AIRS SWINB U TEC; CARTER JH, 2000, J AM MED INFORM ASS, V7; Coakes SJ, 2003, SPSS ANAL ANGUISH VE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DASGUPTA D, 2006, IEEE COMPUTATIONAL I; de Castro LN, 2002, IEEE T EVOLUT COMPUT, V6, P239, DOI 10.1109/TEVC.2002.1011539; FREITAS A, 2007, IEEE T EVOLUTIONARY, V11; HAMAKER J, 2004, P CEC 2004; Hart E, 2004, LECT NOTES COMPUT SC, V3239, P413; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hunt JE, 1996, J NETW COMPUT APPL, V19, P189, DOI 10.1006/jnca.1996.0014; Keogh E., 2006, UCR TIME SERIES DATA; MERZ C, 1998, UCI MACHINE LEARNING; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; TIMMIS J, 2001, ARTIFICIAL IMMUNE SY; Timmis J., 2002, ARTIFICIAL IMMUNE SY; Timmis J, 2006, LECT NOTES COMPUT SC, V3931, P355; Ventura D., 1995, P 10 INT S COMP INF, P443; Watkins A, 2004, LECT NOTES COMPUT SC, V3239, P427; Watkins A., 2002, P 1 INT C ART IMM SY, P173; Watkins A., 2001, THESIS MISSISSIPPI S; Watkins A., 2004, Genetic Programming and Evolvable Machines, V5, DOI 10.1023/B:GENP.0000030197.83685.94; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; Witten I., 2005, DATA MINING PRACTICA; ZWITTER M, 1998, I ONCOLOGY	28	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-85071-7	LECT NOTES COMPUT SC			2008	5132						232	241				10	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Computer Science	BID96	WOS:000258852800021	
S	Grudzinski, K		Rutkowski, L; Tadeusiewicz, R; Zadeh, LA; Zurada, JM		Grudzinski, Karol			Towards heterogeneous similarity function learning for the k-nearest neighbors classification	ARTIFICIAL INTELLIGENCE AND SOFT COMPUTING - ICAISC 2008, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	9th International Conference on Artificial Intelligence and Soft Computing (ICAISC 2008)	JUN 22-26, 2008	Zakopane, POLAND	Polish Neural Network Soc, Acad Humanities & Econ, Czestochowa Univ Technol, Dept Comp Engn, IEEE Computat Intelligence Soc, Polish Chapter		machine learning; concept learning; similarity-based methods; k-nearest neighbors data classification	ALGORITHMS	In order to classify an unseen (query) vector q with the k-Nearest Neighbors method (k-NN) one computes a similarity function between q and training vectors in a database. In the basic variant of the k-NN algorithm the predicted class of q is estimated by taking the majority class of the q's k-nearest neighbors. Various similarity functions may be applied leading to different classification results. In this paper a heterogeneous similarity function is constructed out of different 1-component metrics by minimization of the number of classification errors the system makes on a training set. The HSFL-NN system, which has been introduced in this paper, on five tested datasets has given better results on unseen samples than the plain k-NN method with the optimally selected k parameter and the optimal homogeneous similarity function.	[Grudzinski, Karol] Kazimierz Wielki Univ, Dept Phys, PL-85072 Bydgoszcz, Poland	Grudzinski, K (reprint author), Kazimierz Wielki Univ, Dept Phys, Plac Weyssenhoffa 11, PL-85072 Bydgoszcz, Poland.	karol.grudzinski@wp.pl					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Ortega J., 2001, Knowledge and Information Systems, V3, DOI 10.1007/PL00011679; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DUCH W, 2001, KOMPUTEROWE SYSTEMY, P59; Duch W, 2002, ADV SOFT COMP, P13; DUCH W, 2001, P INT C NEUR INF PRO, V1, P235; DUCH W, 2000, CONTROL CYBERN, V29, P1; Duda R., 1973, PATTERN CLASSIFICATI; Fix E, 1951, 4 US AIR FORC SCH AV; GRUDZINSKI K, SBL SIMILARITY BASED; GRUDZINSKI K, 2002, THESIS N COPERNICUS; Grudzinski K, 2004, LECT NOTES ARTIF INT, V3070, P586; HAB SH, SPOLECZNA WYZSZA SZK; Ingber L., 1996, Control and Cybernetics, V25; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; MERTZ CJ, UCI REPOSITORY MACHI; Mierswa I., 2006, P 12 ACM SIGKDD INT; NELDER JA, 1965, COMPUT J, V7, P308; Sebestyen G. S., 1962, DECISION MAKING PROC; STAHL A, THESIS U KAISERSLAUT; Witten I., 2005, DATA MINING PRACTICA; *KNIM, KNIM KONST INF MIN	26	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-69572-1	LECT NOTES ARTIF INT			2008	5097						578	587				10	Computer Science, Artificial Intelligence; Mathematical & Computational Biology; Robotics; Imaging Science & Photographic Technology	Computer Science; Mathematical & Computational Biology; Robotics; Imaging Science & Photographic Technology	BHX32	WOS:000257188100056	
S	Angiulli, F; Basta, S		Bramer, M		Angiulli, Fabrizio; Basta, Stefano			Optimal subset selection for classification through SAT encodings	ARTIFICIAL INTELLIGENCE IN THEORY AND PRACTICE II	INTERNATIONAL FEDERATION FOR INFORMATION PROCESSING		English	Proceedings Paper	20th World Computer Congress	SEP 07-10, 2008	Milano, ITALY	IFIP TC 13			NEAREST-NEIGHBOR RULE; LEARNING ALGORITHMS; RISK	In this work we propose a method for computing a minimum size training set consistent subset for the Nearest Neighbor rule (also said CNN problem) via SAT encodings. We introduce the SAT-CNN algorithm, which exploits a suitable encoding of the CNN problem in a sequence of SAT problems in order to exactly solve it, provided that enough computational resources are available. Comparison of SAT-CNN with well-known greedy methods shows that SAT-CNN is able to return a better solution. The proposed approach can be extended to several hard subset selection classification problems.	[Angiulli, Fabrizio] Univ Calabria, DEIS, I-87036 Arcavacata Di Rende, CS, Italy	Angiulli, F (reprint author), Univ Calabria, DEIS, Via P Bucci 41C, I-87036 Arcavacata Di Rende, CS, Italy.						ANGIULLI F, 2005, 22 INT C MACH LEARN; Angiulli F, 2007, IEEE T KNOWL DATA EN, V19, P1450, DOI 10.1109/TKDE.2007.190645; Angiulli F, 2007, IEEE T PATTERN ANAL, V29, P1746, DOI 10.1109/TPAMI.2007.1086; Cook S.A., 1971, 3RD P ANN ACM S THEO, P151; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DARWICHE A, 2007, D153 UCLA COMP SCI D; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; DAVIS M, 1962, COMMUN ACM, V5, P394, DOI 10.1145/368273.368557; Devi VS, 2002, PATTERN RECOGN, V35, P505; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; Floyd S, 1995, MACH LEARN, V21, P269, DOI 10.1007/BF00993593; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GONZALEZ TF, 1985, THEOR COMPUT SCI, V38, P293, DOI 10.1016/0304-3975(85)90224-5; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Johnson D. S., 1979, COMPUTERS INTRACTABI; Karacali B, 2003, IEEE T NEURAL NETWOR, V14, P127, DOI 10.1109/TNN.2002.804315; Liu CL, 2001, PATTERN RECOGN, V34, P601, DOI 10.1016/S0031-3203(00)00018-2; MADIGAN C, 2001, 39 DES AUT C DAC; MANYA F, 2004, P 7 INT C THEOR APPL, P111; PROSSER P, 2002, P 5 INT C THEOR APPL; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; SORENSSON N, 2005, INT C THEOR APPL SAT; STONE C, 1977, ANN STAT, V8, P1348; TOUSSAINT G, 2002, P S COMP STAT MONTR; Wilfong G., 1992, International Journal of Computational Geometry & Applications, V2, DOI 10.1142/S0218195992000226; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	27	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1571-5736	978-0-387-09694-0	INT FED INFO PROC			2008	276						309	318				10	Computer Science, Artificial Intelligence	Computer Science	BIF11	WOS:000259037000030	
S	Jirina, M; Jirina, M		Kurkova, V; Neruda, R; Koutnik, J		Jirina, Marcel; Jirina, Marcel, Jr.			Correlation integral decomposition for classification	ARTIFICIAL NEURAL NETWORKS - ICANN 2008, PT II	Lecture Notes in Computer Science		English	Proceedings Paper	18th International Conference on Artificial Neural Networks (ICANN 2008)	SEP 03-06, 2008	Prague, CZECH REPUBLIC				CORRELATION DIMENSION; ALGORITHM; SYSTEMS	In this paper we show that the correlation integral can be decomposed into functions each related to a. particular point of data space. For these functions. One can use similar polynomial approximations as used in the correlation integral. The essential difference is that the value of the exponent, which would Correspond to the correlation dimension, differs in accordance to the position of the point in question. Moreover, we show that the multiplicative constant represents the probability density estimation at that point. This finding is used for the construction of a classifier. Tests with some data sets from the Machine Learning Repository show that this classifier can he very effective.	[Jirina, Marcel] AS CR, Inst Comp Sci, Prague 18207 8, Czech Republic	Jirina, M (reprint author), AS CR, Inst Comp Sci, Vodarenskou Vezi 2, Prague 18207 8, Czech Republic.	marcel@cs.cas.cz; marcel@cs.cas.cz					Camastra F, 2001, NEURAL PROCESS LETT, V14, P27, DOI 10.1023/A:1011326007550; Camastra F, 2003, PATTERN RECOGN, V36, P2945, DOI 10.1016/S0031-3203(03)00176-6; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI; DVORAK I, 1990, PHYS LETT A, V145, P225, DOI 10.1016/0375-9601(90)90355-R; FRIEDMANN JH, 1994, FLEXIBLE METRIC NEAR, P32; Gama J, 2003, THEOR COMPUT SCI, V292, P417, DOI 10.1016/S0304-3975(02)00179-2; GRASSBERGER P, 1983, PHYSICA D, V9, P189, DOI 10.1016/0167-2789(83)90298-1; Guerrero A, 2003, PHYS LETT A, V318, P373, DOI 10.1016/j.physleta.2003.09.023; LEV N, 2006, HAUSDORFF DIMENSION; Merz C., 1997, UCI REPOSITORY MACHI; OSBORNE AR, 1989, PHYSICA D, V35, P357, DOI 10.1016/0167-2789(89)90075-4; PAREDES R, 2006, IEEE T PATTERN ANAL, V20, P1100; TAKENS F, 1985, LECT NOTES MATH, V1125, P99	14	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-87558-1	LECT NOTES COMPUT SC			2008	5164						62	71				10	Computer Science, Theory & Methods	Computer Science	BIH71	WOS:000259567200007	
S	Richert, W; Niehorster, O; Klompmaker, F		Hinchey, M; Pagnoni, A; Rammig, FJ; Schmeck, H		Richert, Willi; Niehoerster, Oliver; Klompmaker, Florian			Guiding exploration by combining individual learning and imitation in societies of autonomous robots	BIOLOGICALLY-INSPIRED COLLABORATIVE COMPUTING	INTERNATIONAL FEDERATION FOR INFORMATION PROCESSING		English	Proceedings Paper	2nd International Conference on Biologically-Inspired Collaborative Computing held at the 20th World Computer Congress	SEP 08-09, 2008	Milan, ITALY	IFIP TC 10				Robots have a powerful means to drastically cut down the exploration space with imitation. However, as existing imitation approaches usually require repetitive demonstrations of the skill to learn in order to be useful, those are typically not applicable in groups of robots. In these settings usually each robot has its own task to accomplish and should not be disturbed by teaching others. As a result an imitating robot most of the time has only one observation of a specific skill from which it can learn. We present an approach that allows an individually learning robot to make use of such cases of sporadic imitation which is the normal case in groups of robots. Thereby, a robot can use imitation in order to guide its exploration efforts towards more rewarding areas in the exploration space. This is inspired by imitation often found in nature where animals or humans try to map observations into their own capability space. We show the feasibility by realistic simulation of Pioneer robots.	[Richert, Willi; Niehoerster, Oliver; Klompmaker, Florian] Univ Gesamthsch Paderborn, Intelligent Mobile Syst, LAB C, D-4790 Paderborn, Germany	Richert, W (reprint author), Univ Gesamthsch Paderborn, Intelligent Mobile Syst, LAB C, D-4790 Paderborn, Germany.						Alpaydin E, 2004, INTRO MACHINE LEARNI; Bellman R., 2003, DYNAMIC PROGRAMMING; Bengio Y., 1999, NEURAL COMPUTING SUR, V2, P129; Billard A, 2004, ROBOT AUTON SYST, V47, P69, DOI 10.1016/j.robot.2004.03.002; BILLARD A, 2000, LEARNING MOTOR SKILL; BORENSTEIN E, 2003, 2 INT S IM AN ART; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Demiris J, 2002, FROM ANIM ANIMAT, P327; GASOULIS Y, 2002, P 2 IASTED INT C ART, P485; IJSPEERT AJ, 2002, INT C ROB AUT ICRA20; INAMURA T, 2003, EXPT ROBOTICS 8; INAMURA T, 2001, P 2001 ICRA IEEE INT; KOCHENDERFER MJ, 2006, THESIS U EDINBURGH; RICHERT W, 2008, IEEE INT C AUT AUT S; Sutton R. S., 1998, REINFORCEMENT LEARNI; VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010	16	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1571-5736	978-0-387-09654-4	INT FED INFO PROC			2008	268						233	244				12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BIE74	WOS:000258995700021	
J	Hewett, R; Kijsanayothin, P				Hewett, Rattikorn; Kijsanayothin, Phongphun			Tumor classification ranking from microarray data	BMC GENOMICS			English	Article								Background: Gene expression profiles based on microarray data are recognized as potential diagnostic indices of cancer. Molecular tumor classifications resulted from these data and learning algorithms have advanced our understanding of genetic changes associated with cancer etiology and development. However, classifications are not always perfect and in such cases the classification rankings (likelihoods of correct class predictions) can be useful for directing further research (e.g., by deriving inferences about predictive indicators or prioritizing future experiments). Classification ranking is a challenging problem, particularly for microarray data, where there is a huge number of possible regulated genes with no known rating function. This study investigates the possibility of making tumor classification more informative by using a method for classification ranking that requires no additional ranking analysis and maintains relatively good classification accuracy. Results: Microarray data of 11 different types and subtypes of cancer were analyzed using MDR (Multi-Dimensional Ranker), a recently developed boosting-based ranking algorithm. The number of predictor genes in all of the resulting classification models was at most nine, a huge reduction from the more than 12 thousands genes in the majority of the expression samples. Compared to several other learning algorithms, MDR gives the greatest AUC (area under the ROC curve) for the classifications of prostate cancer, acute lymphoblastic leukemia (ALL) and four ALL subtypes: BCR-ABL, E2A-PBX1, MALL and TALL. SVM (Support Vector Machine) gives the highest AUC for the classifications of lung, lymphoma, and breast cancers, and two ALL subtypes: Hyperdiploid >50 and TEL-AML1. MDR gives highly competitive results, producing the highest average AUC, 91.01%, and an average overall accuracy of 90.01% for cancer expression analysis. Conclusion: Using the classification rankings from MDR is a simple technique for obtaining effective and informative tumor classifications from cancer gene expression data. Further interpretation of the results obtained from MDR is required. MDR can also be used directly as a simple feature selection mechanism to identify genes relevant to tumor classification. MDR may be applicable to many other classification problems for microarray data.	[Hewett, Rattikorn; Kijsanayothin, Phongphun] Texas Tech Univ, Dept Comp Sci, Abilene, TX 79601 USA	Hewett, R (reprint author), Texas Tech Univ, Dept Comp Sci, Abilene, TX 79601 USA.	Rattikorn.Hewett@cs.ttu.edu; kphongph@gmail.com					Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Burges CJC, 1997, ADV NEUR IN, V9, P375; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gordon GJ, 2002, CANCER RES, V62, P4963; GREEN DM, 1989, SIGNAL DETECTION THE; GROSS P, 2006, P 21 NAT C ART INT 8; HUANG J, 2005, USING AUC ACCURACY E, P17; LI J, 2007, KENT RIDGE BIOMEDICA; Li J., 2003, BIOINFORMATICS S2, V19, pii93; LI J, 2003, P 3 IEEE INT C DAT M, P585; LONG, 2005, MARTINGALE BOOSTING; Pedersen A G, 1997, Proc Int Conf Intell Syst Mol Biol, V5, P226; Quilan J. R., 1993, C4 5 PROGRAMS MACHIN; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Witten I.H., 2005, PRACTICAL MACHINE LE; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	18	6	7	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2164		BMC GENOMICS	BMC Genomics		2008	9			2					S21	10.1186/1471-2164-9-S2-S21		11	Biotechnology & Applied Microbiology; Genetics & Heredity	Biotechnology & Applied Microbiology; Genetics & Heredity	V92JQ	WOS:000206244200022	
B	Cai, YD; Zhou, GP			IEEE	Cai, Yu-Dong; Zhou, Guo-Ping			Predicting protein-protein interactions with pseudo amino acid composition	BMEI 2008: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS, VOL 1			English	Proceedings Paper	1st International Conference on Biomedical Engineering and Informatics	MAY 27-30, 2008	Sanya, PEOPLES R CHINA	Tianjin Univ Technol, IEEE Comp Soc		protein network; network biology; fruitfly; pseudo-amino acid composition; NN-PseAA predictor; genomic scale	STRUCTURAL CLASS PREDICTION; SECONDARY STRUCTURE-CONTENT; SUBCELLULAR LOCATION; FOLDING TYPES; DOMAIN; CDK5	Given two proteins in a living system, can we predict whether they are interacting with each other merely according to the information of their sequences? This is an interesting problem because knowledge of protein-protein interactions may be applied to protein subunit aggregation, to computer-aided drug design, and to fundamental problems of cellular signalling and expression. With the explosion of newly-found protein sequences in the post-genomic era, its importance has become self-evident, and the challenge to address it even more urgent. Based on the pseudo amino acid composition (Chou, K.C.: PROTEINS: Structure, Function, and Genetics, 43: 246255, 2001) approach and nearest neighbor rule, a predictor called "NN-PseAA" classifier was developed to deal with this problem. As a showcase, prediction was performed on 8,797 fruitfly protein pairs. To avoid redundancy and homology bias, none of the protein pairs investigated has >= 25% sequence identity with any other. The overall success rate obtained by jackknife cross-validation for such a stringent dataset was 73.74%, indicating a quite promising sign of the new approach in stimulating the development of this important area and other related areas.	[Cai, Yu-Dong] Chinese Acad Sci, Shanghai Inst Biol Sci, CAS MPG Partner Inst Computat Biol, Shanghai 200031, Peoples R China	Cai, YD (reprint author), Chinese Acad Sci, Shanghai Inst Biol Sci, CAS MPG Partner Inst Computat Biol, 320 Yue Yang Rd, Shanghai 200031, Peoples R China.						Ben-Hur A, 2005, BIOINFORMATICS, V21, pI38, DOI 10.1093/bioinformatics/bti1016; Bock JR, 2001, BIOINFORMATICS, V17, P455, DOI 10.1093/bioinformatics/17.5.455; CHOU JJW, 1993, J THEOR BIOL, V161, P251, DOI 10.1006/jtbi.1993.1053; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou K.C., 2002, GENE CLONING EXPRESS, P57; Chou KC, 2004, CURR MED CHEM, V11, P2105; CHOU KC, 1994, J BIOL CHEM, V269, P22014; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2005, J PROTEOME RES, V4, P1681, DOI 10.1021/pr050145a; Chou KC, 1999, J PROTEIN CHEM, V18, P473, DOI 10.1023/A:1020696810938; Chou KC, 1999, BIOCHEM BIOPH RES CO, V259, P420, DOI 10.1006/bbrc.1999.0792; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Feng KY, 2005, BIOCHEM BIOPH RES CO, V334, P213, DOI 10.1016/j.bbrc.2005.06.075; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; Feng Zhi-Ping, 2002, In Silico Biology, V2, P291; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Giot L, 2003, SCIENCE, V302, P1727, DOI 10.1126/science.1090289; HOPP TP, 1981, P NATL ACAD SCI-BIOL, V78, P3824, DOI 10.1073/pnas.78.6.3824; Jansen R, 2003, SCIENCE, V302, P449, DOI 10.1126/science.1087361; Kanehisa M, 2004, NUCLEIC ACIDS RES, V32, pD277, DOI 10.1093/nar/gkh063; Liu WM, 1999, PROTEIN ENG, V12, P1041, DOI 10.1093/protein/12.12.1041; Luo RY, 2002, EUR J BIOCHEM, V269, P4219, DOI 10.1046/j.1432-1033.2002.03115.x; Martin S, 2005, BIOINFORMATICS, V21, P218, DOI 10.1093/bioinformatics/bth483; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; Shen HB, 2005, BIOCHEM BIOPH RES CO, V334, P577, DOI 10.1016/j.bbrc.2005.06.128; Sprinzak E, 2001, J MOL BIOL, V311, P681, DOI 10.1006/jmbi.2001.4920; TANFORD C, 1962, J AM CHEM SOC, V84, P4240, DOI 10.1021/ja00881a009; Vollert CS, 2004, MOL CELL PROTEOMICS, V3, P1053, DOI 10.1074/mcp.M400081-MCP200; Wang M, 2005, J THEOR BIOL, V232, P7, DOI 10.1016/j.jtbi.2004.07.023; YAN C, 2004, BIOINFORMATICS, V20, P1371; Zhang JW, 2002, PROTEINS, V48, P447, DOI 10.1002/prot.10173; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365	36	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		978-0-7695-3118-2				2008							158	163				6	Engineering, Biomedical; Mathematical & Computational Biology	Engineering; Mathematical & Computational Biology	BHW79	WOS:000257096000031	
S	Bagherjeiran, A; Eick, CF		Perner, P		Bagherjeiran, A.; Eick, C. F.			Distance Function Learning for Supervised Similarity Assessment	CASE-BASED REASONING ON IMAGES AND SIGNALS	Studies in Computational Intelligence		English	Article; Book Chapter							ATTRIBUTE SELECTION; FEATURE WEIGHTS; CLASSIFICATION; RETRIEVAL; DIALOGS	Assessing the similarity between cases is a prerequisite for many case-based reasoning tasks. This chapter centers on distance function learning for supervised similarity assessment. First a framework for supervised similarity assessment is introduced. Second, three supervised distance function learning approaches from the areas of pattern classification, supervised clustering, and information retrieval are discussed, and their results for two supervised learning tasks will be explained and visualized. In each of these different areas, we show how the method can be applied to areas of case-based reasoning. Finally, a detailed literature survey will be given.	[Bagherjeiran, A.; Eick, C. F.] Univ Houston, Dept Comp Sci, Houston, TX 77204 USA	Bagherjeiran, A (reprint author), Univ Houston, Dept Comp Sci, Houston, TX 77204 USA.	abagherj@cs.uh.edu; ceick@cs.uh.edu					Arshadi N, 2004, LECT NOTES COMPUT SC, V3155, P17; BAGHERJEIRAN A, 2005, P 5 INT C DAT MIN HO, P565; Balcan M. F., 2006, P 23 INT C MACH LEAR, P73, DOI 10.1145/1143844.1143854; Blake CL, 1998, UCI REPOSITORY MACHI; Bobrowski L, 2004, LECT NOTES COMPUT SC, V3275, P23; Borg I., 1997, MODERN MULTIDIMENSIO; BRIDGE D, 2001, P 12 IR C ART INT CO, P95; Canu S., 2002, ADV NEURAL INFORM PR, V15, P553; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Coyle L, 2004, LECT NOTES COMPUT SC, V3155, P560; Cummins R, 2005, ARTIF INTELL REV, V24, P277, DOI 10.1007/s10462-005-9001-y; Deok Hwan Kim, 2003, P ACM SIGMOD INT C M, P599; Domeniconi C., 2001, ADV NEURAL INFORM PR, V14, P665; DOMENICONI C, 2000, ADV NEURAL INFORM PR, V13, P458; DOULAMIS AD, 2001, P 2001 INT C IM PROC, P741; Duda R. O., 2001, PATTERN CLASSIFICATI; Eick CF, 2006, ENG APPL ARTIF INTEL, V19, P395, DOI 10.1016/j.engappai.2006.01.004; EICK CF, 2005, P 15 INT S METH INT, P248; Globerson A, 2006, ADV NEURAL INFORM PR, V19, P451; Goldberger J., 2004, NEURAL INFORM PROCES, V17, P513; Halkidi M., 2005, P 5 IEEE INT C DAT M, P637; Hastie T, 1996, ADV NEUR IN, V8, P409; HILLEL AB, 2003, P INT C MACH LEARN W, P11; Huang JZX, 2005, IEEE T PATTERN ANAL, V27, P657, DOI 10.1109/TPAMI.2005.95; Jarmulak J., 2000, P EUR WORKSH CAS BAS, P136; KANDOLA J, 2002, ADV NEURAL INFORM PR, V15; Kira K., 1992, P 9 INT C MACH LEARN, P249; Kohlmaier A, 2001, LECT NOTES ARTIF INT, V2080, P306; Kononenko I, 1994, P EUR C MACH LEARN, P171; LOWE DG, 1993, TR9343; NUNEZ H, 2003, LECT NOTES ARTIF INT, V3689, P377; Okabe A., 1992, SPATIAL TESSELLATION; Pan R, 2004, LECT NOTES COMPUT SC, V3155, P361; PELEG D, 2004, ADV NEURAL INFORM PR, V17, P1065; Perner P, 2001, LECT NOTES ARTIF INT, V2080, P27; Rocchio J. J., 1971, SMART RETRIEVAL SYST, P313; Rui Y., 1998, STORAGE RETRIEVAL IM, P25; Salton G, 1983, INTRO MODERN INFORM; Salton G, 1995, P 18 ANN INT ACM SIG, P351, DOI 10.1145/215206.215383; Schmitt S, 2002, LECT NOTES ARTIF INT, V2416, P380; Scholkopf B., 2000, ADV NEURAL INFORM PR, V13, P301; SHIU SCK, 2000, P 5 EUR WORKSH CAS B, P285; Stahl A, 2003, LECT NOTES ARTIF INT, V2689, P537; Stahl A, 2001, LECT NOTES ARTIF INT, V2080, P502; Sun Y., 2006, P 23 INT C MACH LEAR, P913, DOI 10.1145/1143844.1143959; TSANG ECC, 2001, CLUSTERING CLASSIFIC; Weinberger KQ, 2006, ADV NEURAL INFORM PR, V18, P1473; Wilson DC, 2001, COMPUT INTELL-US, V17, P196, DOI 10.1111/0824-7935.00140; Wiratunga N, 2004, LECT NOTES COMPUT SC, V3155, P806; YANG L, 2006, P 21 NAT C ART INT; Yu L., 2003, P 20 INT C MACH LEAR, P856; Zhang Z., 2003, P ICML 2003, P872	52	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1860-949X	978-3-540-73178-8	STUD COMPUT INTELL			2008	73						91	126			10.1007/978-3-540-73180-1	36	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Multidisciplinary; Engineering, Electrical & Electronic	Computer Science; Engineering	BLW79	WOS:000271238500003	
B	Bai, G; Zhu, Y; Ding, ZY		Li, D; Deng, G		Bai, Gang; Zhu, Yi; Ding, Zongyao			A hierarchical face recognition method based on Local Binary Pattern	CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS			English	Proceedings Paper	1st International Congress on Image and Signal Processing	MAY 27-30, 2008	Sanya, PEOPLES R CHINA	Tianjin Univ Technol		hierarchical face recognition; Local Binary Pattern; Multi-Expert Intelligent Decision System; facial pose estimation	CLASSIFICATION	This paper proposes a hierarchical method to deal with the multi-pose face recognition problem. The Local Binary Pattern (LBP) feature is used as the uniform feature throughout the two-hierarchy process. Also, a new method, named Multi-expert Intelligent Decision System, is proposed to improve the performance of the pose estimation process. According to the experiments, the method is proved to be efficient and robust.	[Bai, Gang; Zhu, Yi; Ding, Zongyao] Nankai Univ, Coll Informat & Technol, Tianjin 300071, Peoples R China	Bai, G (reprint author), Nankai Univ, Coll Informat & Technol, Tianjin 300071, Peoples R China.	baigang@nankai.edu.cn; seaeagle@mail.nankai.edu.cn; dzy@mail.nankai.edu.cn					AHONEN T, 2006, IEEE T PATTERN ANAL, P2037; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HU YL, 2005, J COMPUTER RES DEV A, P622; Li S., 2005, HDB FACE RECOGNITION; Liao S., 2007, P IAPR IEEE INT C BI, P828; NG KC, 1990, P 1990 ACM ANN C FEB, P351, DOI 10.1145/100348.100401; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), DOI 10.1109/CVPR.1991.139758; WU JW, PATTERN RECOGNITION, P1138	9	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		978-0-7695-3119-9				2008							610	614		10.1109/CISP.2008.520		5	Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Engineering; Imaging Science & Photographic Technology	BIE07	WOS:000258872400119	
B	Bo, SK; Ding, L; Jing, YJ		Li, D; Deng, G		Bo, Shukui; Ding, Lin; Jing, Yongju			On combining region-growing with non-parametric clustering for color image segmentation	CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS			English	Proceedings Paper	1st International Congress on Image and Signal Processing	MAY 27-30, 2008	Sanya, PEOPLES R CHINA	Tianjin Univ Technol				Region-based and clustering-based techniques are two of the most important segmentation methods, and both of them have their advantages and disadvantages. In this paper, we present a color image segmentation method combining region-growing with non-parametric clustering technique. First, a bottom-up region-merging technique is used to yield an intermediate result. This procedure takes into account simultaneously the spectral properties of pixels as well as their spatial information, which is not fully utilized in clustering technique. Second, a clustering technique based on mean shift algorithm is used to cluster similar image objects in the intermediate result. In the mean shift procedure, we adopt adaptive bandwidths instead of a single one over the entire feature space. The two steps of image segmentation are performed in an unsupervised way. The validity of the proposed method is verified on various color images.	[Bo, Shukui] Zhengzhou Inst Aeronaut Ind Management, Dept Comp Sci & Applicat, Zhengzhou, Peoples R China	Bo, SK (reprint author), Zhengzhou Inst Aeronaut Ind Management, Dept Comp Sci & Applicat, Zhengzhou, Peoples R China.						Baatz M., 2004, ECOGNITION USER GUID; Baatz M, 2000, ANGEW GEOGRAPHISCHE; BO SK, LNCS, V4489; Comaniciu D, 1997, PROC CVPR IEEE, P750, DOI 10.1109/CVPR.1997.609410; Comaniciu D., 2001, Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001, DOI 10.1109/ICCV.2001.937550; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Macaire L, 2006, COMPUT VIS IMAGE UND, V102, P105, DOI 10.1016/j.cviu.2005.12.001; Shih FY, 2005, IMAGE VISION COMPUT, V23, P877, DOI 10.1016/j.imavis.2005.05.015; [Anonymous], 2009, BERKELEY SEGMENTATIO	10	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		978-0-7695-3119-9				2008							715	719				5	Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Engineering; Imaging Science & Photographic Technology	BIE09	WOS:000258872900143	
S	Denoeux, T		Yager, RR; Liu, L		Denoeux, Thierry			A k-Nearest Neighbor Classification Rule Based on Dempster-Shafer Theory	CLASSIC WORKS OF THE DEMPSTER-SHAFER THEORY OF BELIEF FUNCTIONS	Studies in Fuzziness and Soft Computing		English	Article; Book Chapter							RECOGNITION	In this paper, the problem of classifying an unseen pattern on the basis of its nearest neighbors in a recorded data set is addressed from the point of view of Dempster-Shafer theory. Each neighbor of a sample to be classified is considered as an item of evidence that supports certain hypotheses regarding the class membership of that pattern. The degree of support is defined as a function of the distance between the two vectors. The evidence of the k nearest neighbors is then pooled by means of Dempster's rule of combination. This approach provides a global treatment of such issues as ambiguity and distance rejection, and imperfect knowledge regarding the class membership of training patterns. The effectiveness of this classification scheme as compared to the voting and distance-weighted k-NN procedures is demonstrated using several sets of simulated and real-world data.								BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; CASELTON WF, 1992, WATER RESOUR RES, V28, P3071, DOI 10.1029/92WR01818; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NOR; DASARATHY BV, 1980, IEEE T PATTERN ANAL, V2, P67; DEMPSTER AP, 1987, STAT SCI, V2, P32, DOI 10.1214/ss/1177013430; Deterding DH, 1989, THESIS U CAMBRIDGE; DUBUISSON B, 1993, PATTERN RECOGN, V26, P155, DOI 10.1016/0031-3203(93)90097-G; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Fix E., 1951, 4 USAF SCH AV MED; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; Jozwik A., 1983, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(83)90064-8; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; MACLEOD JES, 1987, IEEE T SYST MAN CYB, V17, P689, DOI 10.1109/TSMC.1987.289362; MORIN RL, 1981, IEEE T SYST MAN CYB, V11, P241; Murphy P., 1994, UCI REPOSITORY MACHI; ROBINSON AJ, 1989, THESIS CAMBRIDGE U; Shafer G., 1976, MATH THEORY EVIDENCE; SIGILLITO VG, 1989, J HOPKINS APL TECH D, V10, P262; TESSEM B, 1993, ARTIF INTELL, V61, P315, DOI 10.1016/0004-3702(93)90072-J	21	2	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1434-9922	978-3-540-25381-5	STUD FUZZ SOFT COMP			2008	219						737	760			10.1007/978-3-540-44792-4	24	Computer Science, Artificial Intelligence; Statistics & Probability	Computer Science; Mathematics	BJM01	WOS:000266783600029	
S	Papa, JP; Falcao, AX; Suzuki, CTN; Mascarenhas, NDA		Brimkov, VE; Barneva, RP; Hauptman, HA		Papa, Joao P.; Falcao, Alexandre X.; Suzuki, Celso. T. N.; Mascarenhas, Nelson D. A.			A discrete approach for supervised pattern recognition	COMBINATORIAL IMAGE ANALYSIS	Lecture Notes in Computer Science		English	Proceedings Paper	12th International Workshop on Combinatorial Image Analysis	APR 07-09, 2008	Buffalo, NY			supervised learning; optimum-path forest; image foresting transform; pattern recognition; graph-search algorithms	IMAGE SEGMENTATION; ALGORITHMS	We present an approach for supervised pattern recognition based on combinatorial analysis of optimum paths from key samples (prototypes), which creates a discrete optimal partition of the feature space such that any unknown sample can be classified according to this partition. A training set is interpreted as a complete graph with at least one prototype in each class. They compete among themselves and each prototype defines an optimum-path tree, whose nodes are the samples more strongly connected to it than to any other. The result is an optimum-path forest in the training set. A test sample is assigned to the class of the prototype which offers it the optimum path in the forest. The classifier is designed to achieve zero classification errors in the training set, without over-fitting, and to learn from its errors. A comparison with several datasets shows the advantages of the method in accuracy and efficiency with respect to support vector machines.	[Papa, Joao P.; Falcao, Alexandre X.; Suzuki, Celso. T. N.] Univ Estadual Campinas, Inst Comp, Campinas, SP, Brazil	Papa, JP (reprint author), Univ Estadual Campinas, Inst Comp, Av Albert Einstein 1216, Campinas, SP, Brazil.	papa.joaopaulo@gmail.com; alexandre.falcao@gmail.com; celso.suzuki@gmail.com; nelson@dc.ufscar.br	Falcao, Alexandre/F-8361-2012				Allene C., 2007, MATH MORPHOLOGY ITS, P253; Asuncion A., 2007, UCI MACHINE LEARNING; Beucher S., 1993, MATH MORPHOLOGY IMAG, P433; Boser B., 1992, P 5 ANN WORKSH COMP, P144, DOI DOI 10.1145/130385.130401; Chang C-C., 2001, LIBSVM LIB SUPPORT V; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Collins DL, 1998, IEEE T MED IMAGING, V17, P463, DOI 10.1109/42.712135; Collobert R., 2004, P 21 INT C MACH LEAR, P23; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duan KB, 2005, LECT NOTES COMPUT SC, V3541, P278; Falcao AX, 2004, IEEE T PATTERN ANAL, V26, P19, DOI 10.1109/TPAMI.2004.1261076; Haykin S., 1994, NEURAL NETWORKS COMP; Jain A., 1988, ALGORITHMS CLUSTERIN; KUNCHEVA LI, 2004, COMBINING PATTERN CL; KUNCHEVA LI, 2000, FUZZY CLASSIFIER DES; Lotufo R. A., 2000, Proceedings 13th Brazilian Symposium on Computer Graphics and Image Processing (Cat. No.PR00878), DOI 10.1109/SIBGRA.2000.883922; Martinez JM, 2002, IEEE MULTIMEDIA, V9, P78, DOI 10.1109/93.998074; Montoya-Zegarra JA, 2007, LECT NOTES COMPUT SC, V4842, P193; PANDA N, 2006, P 23 INT C MACH LEAR, P681, DOI 10.1145/1143844.1143930; PAPA JP, 2007, MATH MORPHOLOGY ITS, P337; PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681; Reyzin Lev, 2006, P 23 INT C MACH LEAR, P753, DOI 10.1145/1143844.1143939; ROCHA LM, 2008, IN PRESS 8 INT WORKS; Saha PK, 2001, COMPUT VIS IMAGE UND, V82, P42, DOI 10.1006/cviu.2000.0902; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Tang B, 2006, P 23 INT C MACH LEAR, P921, DOI 10.1145/1143844.1143960; Torres RD, 2004, PATTERN RECOGN, V37, P1163, DOI 10.1016/j.patcog.2003.10.007; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344; COREL COREL STOCK PH	30	11	11	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-78274-2	LECT NOTES COMPUT SC			2008	4958						136	147				12	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BHN76	WOS:000254600100012	
J	Jeng, SL; Huang, YT				Jeng, Shuen-Lin; Huang, Ya-Ti			Time series classification based on spectral analysis	COMMUNICATIONS IN STATISTICS-SIMULATION AND COMPUTATION			English	Article						classification; k-nearest-neighbor; linear discriminant analysis; spectral analysis; time series		For time series data with obvious periodicity (e.g., electric motor systems and cardiac monitor) or vague periodicity (e.g., earthquake and explosion, speech, and stock data), frequency-based techniques using the spectral analysis can usually capture the features of the series. By this approach, we are able not only to reduce the data dimensions into frequency domain but also utilize these frequencies by general classification methods such as linear discriminant analysis (LDA) and k-nearest-neighbor (KNN) to classify the time series. This is a combination of two classical approaches. However, there is a difficulty in using LDA and KNN in frequency domain due to excessive dimensions of data. We overcome the obstacle by using Singular Value Decomposition to select essential frequencies. Two data sets are used to illustrate our approach. The classification error rates of our simple approach are comparable to those of several more complicated methods.	[Jeng, Shuen-Lin] Natl Cheng Kung Univ, Dept Stat, Tainan 701, Taiwan; [Huang, Ya-Ti] Tunghai Univ, Dept Stat, Taichung 40704, Taiwan	Jeng, SL (reprint author), Natl Cheng Kung Univ, Dept Stat, Tainan 701, Taiwan.	sljeng@mail.ncku.edu.tw					Box G. E. P., 1994, TIME SERIES ANAL; Box G.E.P., 1976, TIME SERIES ANAL; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEMERDASH NA, 1997, P NAV S EL MACH NEWP, P235; Demmel J.W., 1997, APPL NUMERICAL LINEA; Fisher RA, 1938, ANN EUGENIC, V8, P376; Gardner W. A., 1988, STAT SPECTRAL ANAL N; Gentle J. E., 1998, NUMERICAL LINEAR ALG; Giudici P, 2003, APPL DATA MINING STA; Harville D. A., 1997, MATRIX ALGEBRA STAT; Hastie T, 2001, ELEMENTS STAT LEARNI; Huang HY, 2004, J AM STAT ASSOC, V99, P763, DOI 10.1198/016214504000001105; KAKIZAWA Y, 1998, J AM STAT ASSOC, V93, P763; Lin CT, 1996, NEURAL FUZZY SYSTEMS; Povinelli RJ, 2004, IEEE T KNOWL DATA EN, V16, P779, DOI 10.1109/TKDE.2004.17; SHUMWAY RH, 1988, APPL STAT TIME SERIE; Wei W. W. S., 1989, TIME SERIES ANAL UNI; ZIVOT E, 2002, MODELLING FIN TIMES	18	3	3	TAYLOR & FRANCIS INC	PHILADELPHIA	325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA	0361-0918		COMMUN STAT-SIMUL C	Commun. Stat.-Simul. Comput.		2008	37	1					132	142		10.1080/03610910701723971		11	Statistics & Probability	Mathematics	250SS	WOS:000252321400010	
S	Hendrickx, I; Hoste, V; Daelemans, W		Gelbukh, A		Hendrickx, Iris; Hoste, Veronique; Daelemans, Walter			Semantic and syntactic features for Dutch coreference resolution	COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	9th International Conference on Intelligent Text Processing and Computational Linguistics	FEB 17-23, 2008	Haifa, ISRAEL	Computat Linguist Grp, Univ Haifa, Caesarea Edmond Benjamin de Rothschild Fdn Inst Interdisciplinary Applicat Comp Sci	Univ Haifa			We investigate the effect of encoding additional semantic and syntactic information sources in a classification-based machine learning approach to the task of coreference resolution for Dutch. We experiment both with a memory-based learning approach and a maximum entropy modeling method. As an alternative to using external lexical resources, such as the low-coverage Dutch EuroWordNet, we evaluate the effect of automatically generated semantic clusters as information source. We compare these clusters, which group together semantically similar nouns, to two semantic features based on EuroWordNet encoding synonym and hypernym relations between nouns. The syntactic function of the anaphor and antecedent in the sentence can be an important clue for resolving coreferential relations. As baseline approach, we encode syntactic information as predicted by a memory-based shallow parser in a set of features. We contrast these shallow parse based features with features encoding richer syntactic information from a dependency parser. We show that using both the additional semantic information and syntactic information lead to small but significant performance improvement of our coreference resolution approach.	[Hendrickx, Iris; Daelemans, Walter] Univ Antwerp, CNTS Language Technol Grp, B-2020 Antwerp, Belgium	Hendrickx, I (reprint author), Univ Antwerp, CNTS Language Technol Grp, Prins Str 13, B-2020 Antwerp, Belgium.						Berger A. L., 1996, COMPUTATIONAL LINGUI, V22; BOUMA G, 2001, COMPUTATIONAL LINGUI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Culotta A, 2007, P HLT NAACL, P81; DAELEMANS A, 2004, ILK0402 TILB U; DAELEMANS W, 2003, 0313 TILB U; Daelemans W, 2003, LECT NOTES ARTIF INT, V2837, P84; Fellbaum C., 1998, WORDNET ELECT LEXICA; Harabagiu S.M., 2001, P 2 M N AM CHAPT ASS, P55; HOSTE V, 2006, 5 INT C LANG RES EV; Ji H., 2005, P HUM LANG TECHN C C, P17, DOI 10.3115/1220575.1220578; Kehler A., 2004, P HLT NAACL, P289; Le Z., 2004, MAXIMUM ENTROPY MODE; Lin D, 1998, COLING ACL, P768; LUO X, 2005, P HUM LANG TECHN C C, P660, DOI 10.3115/1220575.1220658; Markert K, 2005, COMPUT LINGUIST, V31, P367, DOI 10.1162/089120105774321064; MCCARTHY J, 1996, THESIS U MASSACHUSET; Mitkov R., 1998, P 36 ANN M ASS COMP, P869; Ng V, 2002, P 40 ANN M ASS COMP, P104, DOI DOI 10.3115/1073083.1073102; NG V, 2007, P 20 INT JOINT C ART, P1689; Ng V, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P55; NG V, 2007, P 45 ANN M ASS COMP, P536; Poesio M., 2004, P 42 ANN M ASS COMP, P143, DOI 10.3115/1218955.1218974; Ponzetto S. P., 2006, P HUM LANG TECHN C N, P192, DOI 10.3115/1220835.1220860; Rich E, 1988, P 2 C APPL NAT LANG, P18, DOI 10.3115/974235.974239; Soon WM, 2001, COMPUT LINGUIST, V27, P521, DOI 10.1162/089120101753342653; TJONG KS, 2004, COMPUTATIONAL LINGUI, P109; TJONG KS, 2002, P CONLL 2002 TAIP TA, P203; VANDECRUYS T, 2005, P 16 COMP LING NETH, P17; Vilain M, 1995, P 6 MESS UND C MUC 6, P45, DOI 10.3115/1072399.1072405; VOSSEN P, 1998, EURO WORDNET MULTILI; YANG XF, 2006, P 21 INT C COMP LING, P41, DOI 10.3115/1220175.1220181; Yang Xiaofeng, 2007, P 45 ANN M ASS COMP, P528	33	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-78134-9	LECT NOTES COMPUT SC			2008	4919						351	361				11	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BHJ77	WOS:000253658200030	
B	Domeniconi, C; Gunopulos, D		Liu, H; Motoda, H		Domeniconi, Carlotta; Gunopulos, Dimitrios			Local Feature Selection for Classification	COMPUTATIONAL METHODS OF FEATURE SELECTION	Chapman & Hall-CRC Data Mining and Knowledge Discovery Series		English	Article; Book Chapter							NEAREST-NEIGHBOR CLASSIFICATION; CLASSIFIERS		[Domeniconi, Carlotta] George Mason Univ, Fairfax, VA 22030 USA; [Gunopulos, Dimitrios] Univ Calif Riverside, Riverside, CA 92521 USA	Domeniconi, C (reprint author), George Mason Univ, Fairfax, VA 22030 USA.						Aha D. W., 1997, ARTIF INTELL, V11, P1; AKAHO S, 2002, 6 KERN MACH WORKSH L; Amari S, 1999, NEURAL NETWORKS, V12, P783, DOI 10.1016/S0893-6080(99)00032-5; Bellman R., 1961, ADAPTIVE CONTROL PRO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Domeniconi C, 2005, IEEE T NEURAL NETWOR, V16, P899, DOI 10.1109/TNN.2005.849821; FRIEDMAN J. H., 1994, FLEXIBLE METRIC NEAR; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; MYLES JP, 1990, PATTERN RECOGN, V23, P1291, DOI 10.1016/0031-3203(90)90123-3; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; STONE C, 1977, ANN STAT, V5	14	0	0	CHAPMAN & HALL/CRC PRESS	BOCA RATON	6000 BROKEN SOUND PKWY, NW, STE 300, BOCA RATON, FL 33487 USA		978-1-58488-878-9	CH CRC DATA MIN KNOW			2008							211	232				22	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BJR36	WOS:000267023200011	
J	Caulier, Y; Bourennane, S				Caulier, Y.; Bourennane, S.			An Image Content Description Technique for the Inspection of Specular Objects	EURASIP JOURNAL ON ADVANCES IN SIGNAL PROCESSING			English	Article							FEATURE-SELECTION; PATTERN-RECOGNITION; FRINGE PATTERNS; CLASSIFICATION; ENVIRONMENTS; SURFACES; FEATURES; TEXTURE	This paper proposed an image content description method within the context of specular surface inspection. Such a method is based on a preliminary research concerning the generation of specific stripe patterns for the visual enhancement of defective surface parts of cylindrical specular objects. The goal of this paper is to address the stripe pattern interpretation within a general approach. For this purpose, different pattern recognition processes, consisting not only of the combination of different image segmentation, feature retrieval, and classification, but also of feature combination and selection, will be considered. Three top-down and one bottom-up approaches are evaluated for retrieving the most appropriate feature sets in terms of highest classification rates. It will be demonstrated that following a combination and appropriate selection of these feature sets, even better rates can be reached. With only half of the initial features, an increase of more than 2% is observable. Copyright (C) 2008 Y. Caulier and S. Bourennane.	[Caulier, Y.] Fraunhofer Inst, Image Proc & Med Engn Dept, D-91058 Erlangen, Germany; [Bourennane, S.] Ecole Cent Marseille, Fresnel Inst, Multidimens Signal Grp, F-13451 Marseille, France	Caulier, Y (reprint author), Fraunhofer Inst, Image Proc & Med Engn Dept, D-91058 Erlangen, Germany.	cau@iis.fraunhofer.de	Bourennane, Salah/F-2928-2010		Bavarian Research Foundation (Bayerische Forschungsstiftung-BFS)	This work was supported by the Bavarian Research Foundation (Bayerische Forschungsstiftung-BFS).	ASADA M, 1988, IEEE T PATTERN ANAL, V10, P749, DOI 10.1109/34.6787; Caulier Y, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/237459; CAULIER Y, 2008, J OPTICAL ENG, V47; CAULIER Y, NEUES SYSTEM SCHNELL; CHEN YQ, 1995, PATTERN RECOGN, V28, P537, DOI 10.1016/0031-3203(94)00116-4; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dash M., 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; Delcroix G, 2001, J ELECTRON IMAGING, V10, P196, DOI 10.1117/1.1314333; DJOUADI A, 1990, IEEE T PATTERN ANAL, V12, P92, DOI 10.1109/34.41388; Dy JG, 2003, IEEE T PATTERN ANAL, V25, P373, DOI 10.1109/TPAMI.2003.1182100; Efron B., 1993, INTRO BOOTSTRAP; Fisher R. B., 1996, IMAGE TECHNOLOGY ADV, P385; Gutierrez-Lobos K, 2002, BMC PSYCHIATRY, V2, DOI 10.1186/1471-244X-2-3; Hall M. A., 1999, THESIS U WAIKATO HAM; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Jain A. K., 1998, HDB PATTERN RECOGNIT, P207; JOHNSONGENTILE K, 1994, J EDUC COMPUT RES, V11, P121; Juptner WP, 1994, P SOC PHOTO-OPT INS, V2342, P16; KAMMEL S, 2004, THESIS U KARLSRUHE K; Knauer M. C., 2004, German patent, Patent No. [DE 102004020419, 19944354]; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; KRUGER S, 2000, MACHINE VISION APP 8, V3966, P145; Kruger S, 2001, J ELECTRON IMAGING, V10, P228, DOI 10.1117/1.1318908; LAKSHMINARASIMHAN AL, 1975, IEEE T COMPUT, V24, P948, DOI 10.1109/T-C.1975.224346; Leon FP, 1997, P SOC PHOTO-OPT INS, V3208, P394; Li XD, 2000, OPT ENG, V39, P2821, DOI 10.1117/1.1308485; LIU XM, 2003, P 2 INT C MACH LEARN, P2399; MARINO P, 1999, P 25 ANN C IEEE IND, V3, P1330; MATERKA A, 1998, B11 TU LODZ I EL, V18, P90; MUCCIARD.AN, 1971, IEEE T COMPUT, VC 20, P1023, DOI 10.1109/T-C.1971.223398; NAYAR SK, 1990, IEEE T ROBOTIC AUTOM, V6, P208, DOI 10.1109/70.54736; Niemann H, 2003, KLASSIFIKATION MUSTE; PAAKKARI J, 1998, THESIS U OULU OULU; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226; Pernkopf F., 2004, P 17 INT C PATT REC, V3, P223; PETZ M, 2002, OPTICAL 3D MEASUREME; QIAN K, 2005, MEASUREMENT SCI TECH, V15, P1582; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Reindl I, 2007, P IEEE INSTR MEAS TE, P1; SEULIN R, 2001, P 5 INT C QUAL CONTR; Talavera L., 2000, Intelligent Data Analysis, V4; Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046; WAGNER T, 1999, AUTOMATISCHE KONFIGU; WEISS SM, 1991, IEEE T PATTERN ANAL, V13, P285, DOI 10.1109/34.75516; Weska J. S., 1978, COMPUT GRAPHICS IMAG, V7, P259; Witten I. H., 2005, DATA MINING; ZHI H, 1992, P 11 INT C PATT REC, V3, P105	50	1	1	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1687-6180		EURASIP J ADV SIG PR	EURASIP J. Adv. Signal Process.		2008									195263	10.1155/2008/195263		14	Engineering, Electrical & Electronic	Engineering	381XF	WOS:000261568500001	
J	Gomolinska, A				Gomolinska, Anna			Satisfiability of Formulas from the Standpoint of Object Classification: The RST Approach	FUNDAMENTA INFORMATICAE			English	Article; Proceedings Paper	Concurrency Specification and Programming Workshop	SEP 27-29, 2007	Lagow, POLAND			satisfiability of formulas; valuation; object classification; Pawlak's information system; descriptor language; analogy-based reasoning	ROUGH SET APPROACH; APPROXIMATION SPACES; FUZZY LOGIC; PROPOSITIONAL CALCULI; SIMILARITY; MODEL; INDUCTION; SYSTEMS; RULES	In this article we discuss judgment of satisfiability of formulas of it knowledge representation language as an object classification task. Our Viewpoint is that of the rough set theory (RST). and the descriptor language for Pawlak's information systems of a basic kind is taken as the study case. We show how certain analogy-based methods can be employed to judge satisfiability of formulas of that language.	Bialystok Univ, Dept Math, PL-15267 Bialystok, Poland	Gomolinska, A (reprint author), Bialystok Univ, Dept Math, Akad 2, PL-15267 Bialystok, Poland.	anna.gom@math.uwb.edu.pl					AAMODT A, 1994, AI COMMUN, V7, P39; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Albatineh AN, 2006, J CLASSIF, V23, P301, DOI 10.1007/s00357-006-0017-z; BAZAN J, 2006, T ROUGH SETS 5 LNCS, V4100, P39, DOI 10.1007/11847465_3; BAZAN JG, 1998, LNCS, V1424, P521; BAZAN JG, 1998, THESIS WARSAW U; BELNAP N., 1977, MODERN USES MULTIPLE, P8; Bolc L., 1992, MANY VALUED LOGICS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUDA RO, 1973, PATTERN CLASSFICATIO; Dzeroski S., 2001, RELATIONAL DATA MINI; Getoor L, 2007, INTRO STAT RELATIONA; GOMOLINSKA A, 2007, P WORKSH CONC SPEC P, P212; Gomolinska A, 2007, FUND INFORM, V79, P319; Gomolinska A, 2004, FUND INFORM, V60, P159; Gomolinska A, 2005, FUND INFORM, V67, P77; Greco S, 2006, LECT NOTES ARTIF INT, V3885, P7; Grzymala-Busse J. W., 1992, HDB APPL ADV ROUGH S, P3; GRZYMALABUSSE JW, 2005, DATA MIN KNOWL DISC, P255; Guillet F, 2007, QUALITY MEASURES DAT; Honko P, 2007, LECT NOTES ARTIF INT, V4585, P553, DOI 10.1007/978-3-540-73451-2_58; Kleene S. C., 1952, INTRO METAMATHEMATIC; Lin T. Y., 1995, SOFT COMPUTING SIMUL, P18; Lukasiewicz J., 1920, RUCH FILOZOFICZNY, V5, P170; Lukasiewicz J., 1930, CR HEBD ACAD SCI, VIII, P51; MICHALSKI RS, 1993, MACH LEARN, V11, P111, DOI 10.1007/BF00993074; Mitchell Melanie, 2001, P335; MITCHELL M, 1993, ANALOG MAKING PERCEP; NGUYEN HS, 1998, MANY VALUED LOGIC, P451; NGUYEN HS, 1997, THESIS WARSAW U; NGUYEN HS, 2005, LECT NOTES COMPUTER, V3518, P312; OSHERSON DN, 1990, PSYCHOL REV, V97, P185, DOI 10.1037/0033-295X.97.2.185; PAVELKA J, 1979, Z MATH LOGIK, V25, P447, DOI 10.1002/malq.19790252510; PAVELKA J, 1979, Z MATH LOGIK, V25, P119, DOI 10.1002/malq.19790250706; PAVELKA J, 1979, Z MATH LOGIK, V25, P45, DOI 10.1002/malq.19790250304; PAWLAK Z, 1981, RES REPORT CC PAS, V429; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; PAWLAK Z, 1984, INT J MAN MACH STUD, V20, P469, DOI 10.1016/S0020-7373(84)80022-X; PAWLAK Z, 1994, EUR J OPER RES, V72, P443, DOI 10.1016/0377-2217(94)90415-4; Pawlak Z., 1991, ROUGH SETS THEORETIC; Pawlak Z., 1987, B POLISH ACAD SCI TE, P253; Pawlak Z, 2005, LECT NOTES COMPUT SC, V3700, P1; PAWLAK Z, 1981, INFORM SYST, V6, P205, DOI 10.1016/0306-4379(81)90023-5; Pawlak Z, 2007, INFORM SCIENCES, V177, P3, DOI 10.1016/j.ins.2006.06.003; Peters J.F., 2007, P IEEE S SER FDN COM, P1; Peters JF, 2007, FUND INFORM, V79, P497; Peters JF, 2005, ADV SOFT COMP, P13, DOI 10.1007/3-540-32370-8_2; POGORZELSKI WA, 1994, NOTIONS THEOREMS ELE; Rauszer C.M., 1994, LECT NOTES ARTIF INT, V808, P161; Rescher N., 1969, MANY VALUED LOGIC; Rosser J.B., 1958, MANY VALUED LOGICS; Skowron A., 1996, Fundamenta Informaticae, V27; Skowron A, 2005, LECT NOTES COMPUT SC, V3400, P175; Skowron A, 2006, FUND INFORM, V72, P363; Slowinski R, 2007, LECT NOTES ARTIF INT, V4585, P5, DOI 10.1007/978-3-540-73451-2_2; Slowinski Roman, 1997, ADV MACHINE INTELLIG, P17; STEFANOWSKI J, 2001, ALGORITHMS DECISION, V361; STEFANOWSKI J, 1998, MANY VALUED LOGIC, P500; Stepaniuk J, 2004, FUND INFORM, V61, P139; STEPANIUK J, 2007, T ROUGH SETS 6 J SUB, V4374, P351, DOI 10.1007/978-3-540-71200-8_19; SURAJ Z, 1972, FUNDAMENTA INFORM, V72, P393; Synak P, 2005, FUND INFORM, V67, P249; VONLUXBURG U, 2004, THESIS TU BERLIN; Wojna A, 2005, LECT NOTES COMPUT SC, V3700, P277; Wolski M, 2007, LECT NOTES ARTIF INT, V4585, P192, DOI 10.1007/978-3-540-73451-2_21; WROBLEWSKI J, 2002, THESIS WARSAW U; Yao Y., 1997, ROUGH SETS DATA MINI, P47; Zadeh L., 1975, SYNTHESE, V30, P407, DOI DOI 10.1007/BF00485052; ZADEH LA, 1973, IEEE T SYST MAN CYB, VSMC3, P28, DOI 10.1109/TSMC.1973.5408575; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; Ziarko W, 2001, COMPUT INTELL, V17, P593, DOI 10.1111/0824-7935.00165; ZIARKO W, 1993, J COMPUT SYST SCI, V46, P39, DOI 10.1016/0022-0000(93)90048-2	72	1	1	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0169-2968		FUND INFORM	Fundam. Inform.		2008	85	1-4					139	153				15	Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	358PL	WOS:000259929900011	
B	Gruhn, V; Richter, T			IEEE Comp Soc	Gruhn, Volker; Richter, Thomas			A General Model of Mobile Environments: Simulation Support for Strategic Management Decisions	GCC 2008: Seventh International Conference on Grid and Cooperative Computing, Proceedings			English	Proceedings Paper	7th International Conference on Grid and Cooperative Computing	OCT 24-26, 2008	Shenzhen, PEOPLES R CHINA	Chinese Acad Sci, Shenzhen Inst Adv Technol, Dawning Informat Ind Co Ltd, Chinese Natl Grid, European & Chinese Cooperat Grid, Chinese Acad Sci, Chinese Acad Engn		Mobile Environments; Enterprise Simulation; Workforce Management; Resource Modeling; Colored Petri Nets	ARCHITECTURE; WORKFLOW	Since the ability of Workflorce Management Systems to handle mobility induced challenges of mobile environments like data-communication cut-offs, reduced network bandwidth, and security concerns improved recently; the optimization efforts of mobile enterprises increasingly focus on the organizational setup of their mobile environment. This includes issues like, e.g., the dimension and staffing of regional subdivisions, qualification balance of the workforce, and resource allocation strategies. While this multitude of possible adjustment parameters for optimization prevents from the analytical prediction. of organizational change efforts, simulation is a promising approach to analyze mobile environments and their change. In this work we present a formal model representing a generalization of mobile environments. This model can be utilized to examine the cost situation and performance of both real mobile enterprises and projected future development scenarios of such enterprises. The model is developed using colored petri nets (CPN) and the software suite CPN Tools. We show that our model is capable of predicting the outcomes of organizational change projects by the utilization of simulation and present a validation of our model based on real-world data of a German gas and power supply.	[Gruhn, Volker; Richter, Thomas] Univ Leipzig, Dept Comp Sci, Chair Appl Telemat E Business, D-04109 Leipzig, Germany	Gruhn, V (reprint author), Univ Leipzig, Dept Comp Sci, Chair Appl Telemat E Business, Klostergasse 3, D-04109 Leipzig, Germany.	gruhn@ebus.informatik.uni-leipzig.de; richter@ebus.informatik.uni-leipzig.de					AGUILAR M, 1999, P 1999 WINT SIM C WS, V2, P1383, DOI 10.1145/324898.325282; Becker C, 2005, PERS UBIQUIT COMPUT, V9, P20, DOI 10.1007/s00779-004-0270-2; BERIO G, 2005, 16 IFAC WORLD C; BERIO G, 2004, P EMOI WORKSH JOINT; Bolcer GA, 2000, IEEE INTERNET COMPUT, V4, P46, DOI 10.1109/4236.845390; BORREGUERO FJM, 2005, P INT C MOB BUS ICMB, P274; BOWDEN SL, 2004, ECPPM 2004 EWORK EBU, P491; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVREEDE GJ, 2003, SIMULATION, P43; Doumeingts G., 1992, GIM GRAI INTEGRATED; Dustdar S, 2003, J SYST ARCHITECT, V49, P457, DOI 10.1016/S1383-7621(03)00092-4; Giaglis GM, 1999, INT J INFORM MANAGE, V19, P219, DOI 10.1016/S0268-4012(99)00015-8; GRUHN V, 2006, 1 INT WORKSH MOB COL; GRUHN V, 2007, P 3 INT C INT ENT SO; INNES D, 2005, P INT C MOB BUS ICMB, P49; JENSEN K, 1996, COLOURED PETRINETS B, V1; KADYTE V, 2005, P INT C MOB BUS ICMB, P159; Kakihara M., 2002, Proceedings of the 35th Annual Hawaii International Conference on System Sciences, DOI 10.1109/HICSS.2002.994088; Kosanke K, 1999, COMPUT IND, V40, P83, DOI 10.1016/S0166-3615(99)00016-0; Kumar A., 2002, J MANAGE INFORM SYST, V18, P157; Lesaint D, 2003, BT TECHNOL J, V21, P23, DOI 10.1023/A:1027315016892; Luff P., 1998, P 1998 ACM C COMP SU, P305, DOI 10.1145/289444.289505; MAY A, 2005, MOBILEHCI 05, P255; Melao N, 2003, J OPER RES SOC, V54, P2, DOI 10.1057/palgrave.jors.2601477; Nah FFH, 2005, COMMUN ACM, V48, P85, DOI 10.1145/1042091.1042095; NETJES M, 2005, 6 WORKSH TUT PRACT U; Pesic Maja, 2007, International Journal on Software Tools for Technology Transfer, V9, DOI 10.1007/s10009-007-0036-z; PICA D, 2004, P 37 ANN HAW INT C S; POPOVIC A, 2006, INTERDISCIPLINARY J, P1; RAMAMPIARO H, 2003, APPL INFORMATICS, P1153; ROMAN GC, 2000, FUTURE SOFTWARE ENG, P243; ROMAN H, 2007, EWDAS MAGAZIN ENERGI, V106, P56; Russell N, 2005, LECT NOTES COMPUT SC, V3520, P216; Vernadat F, 2002, INT J PROD RES, V40, P4309, DOI 10.1080/00207540210159626; VUKSIC VB, 2003, SIMULATION, V78, P731; VUKSIC VB, 2005, SYSTEMS INTEGRATION, P29; WILLIAMS TJ, 1994, COMPUT IND, V24, P141, DOI 10.1016/0166-3615(94)90017-5; Wilson A. M., 1998, MANAG SERV QUAL, V8, P414, DOI 10.1108/09604529810235123; *I I TASK FORC ARC, 1999, GERAM GEN ENT REF AR	39	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		978-0-7695-3449-7				2008							753	764		10.1109/GCC.2008.25		12	Computer Science, Theory & Methods	Computer Science	BIT11	WOS:000262480400112	
B	Shang, WQ; Dong, HB; Zhu, HB; Wang, YB				Shang, Wenqian; Dong, Hongbin; Zhu, Haibin; Wang, Yongbin			A Novel Feature Weight Algorithm for Text Categorization	IEEE NLP-KE 2008: PROCEEDINGS OF INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE PROCESSING AND KNOWLEDGE ENGINEERING			English	Proceedings Paper	IEEE International Conference on Natural Language Processing and Knowledge Engineering	OCT 19-22, 2008	Beijing, PEOPLES R CHINA	IEEE				With the development of the web, large numbers of documents are put onto the Internet. More and more digital libraries, news sources and inner data of companies are available. Automatic text categorization becomes more and more important for dealing with massive data. However, text preprocessing is still the bottleneck of text categorization based on Vector Space Model (VSM). The result of text preprocessing directly affects the performance and precision of categorization. Moreover, feature selection and feature weight become the major obstacles of text preprocessing. In this paper, we mainly focus on feature weight. We present a novel feature weight algorithm-TF-Gini that can improve the categorization peformance significantly. The experiment results verify the effectiveness of this algorithm.			shangwenqian@hotmail.com; donghongbin@gmail.com; Haibinz@npissingu.ca					APTE C, 1998, P C AUT LEARN DISC W, P487; Breiman L, 1984, CLASSIFICATION REGRE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Debole F., 2003, SAC 03, P784; Gupta S. K., 1998, Proceedings Ninth International Workshop on Database and Expert Systems Applications (Cat. No.98EX130), DOI 10.1109/DEXA.1998.707410; JOACHIMS T, 1997, MACH LEARN, P143; Joachims T, 1998, P 10 EUR C MACH LEAR, P137; Lewis D., 1998, P 10 EUR C MACH LEAR, P4; Lewis D.D., 1994, P 3 ANN S DOC AN INF, P81; [李荣陆 Li Ronglu], 2005, [计算机研究与发展, Journal of Computer Research and Development], V42, P94, DOI 10.1360/crad20050113; LU Y, 2002, J COMPUTER RES DEV, P1205; MASAND B, 1992, 15 ANN INT ACM SIGIR, P59; McCallum A., 1998, AAAI 98 WORKSH LEARN, P41; Mladenic D., 1999, P 16 INT C MACH LEAR, P258; NG HT, 1999, 20 ANN INT ACM SIGIR, P67; Nigam K, 1999, IJCAI 99 WORKSH MACH, P61; SHANG W, 2005, 2005 INT C COMP INT, P741; SHANKAR S, 2000, P KDD 2000; TANG H, 2005, J COMPUTER RES DEV, P47; van Rijsbergen CJ, 1979, INFORM RETRIEVAL; Vapnik V.N., 1995, NATURE STAT LEARNING; Wiener E.D., 1995, P 4 ANN S DOC AN INF, P317; Yang Y, 1997, INFORM RETRIEVAL, V1, P76; YANG Y, 1994, ACM T INFORM SYST, P252; Yang Y, 1997, P 14 INT C MACH LEAR, P412; Yang Y.M, 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647	26	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-2779-6				2008							269	275				7	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BJL58	WOS:000266767300041	
S	Martinez-Uso, A; Pla, F; Sotoca, JM; Garcia-Sevilla, P		Campilho, A; Kamel, M		Martinez-Uso, Adolfo; Pla, Filiberto; Sotoca, Jose M.; Garcia-Sevilla, Pedro			From narrow to broad band design and selection in hyperspectral images	IMAGE ANALYSIS AND RECOGNITION, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	5th International Conference on Image Analysis and Recognition	JUN 25-27, 2008	Povoa de Varzim, PORTUGAL					Selecting the most relevant bands from a hyperspectral image would considerably reduce the amount of data without practically losing relevant information. In addition, if some physical and signal criteria of this selection are taken into account, the obtained results grouping consecutive bands would be useful to design new filters for hyperspectral cameras in order to improve the efficiency of these devices. Starting from certain number of pre-selected bands, intervals of spectrally adjacent instances to these initial bands are considered for calculating new broader bands. Results will show how a weighted average on these intervals can keep, or even improve, the performance respecting to a narrower selection, avoiding, at the same time, common drawbacks from the narrow-band acquisition devices.	[Martinez-Uso, Adolfo; Pla, Filiberto; Sotoca, Jose M.; Garcia-Sevilla, Pedro] Jaume I Univ, Dept Lenguajes & Sistemas Informat, Castellon de La Plana, Spain	Martinez-Uso, A (reprint author), Jaume I Univ, Dept Lenguajes & Sistemas Informat, Castellon de La Plana, Spain.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Landgrebe D.A., 2003, SIGNAL THEORY METHOD; Martinez-Uso A, 2007, LECT NOTES COMPUT SC, V4477, P30; Martinez-Uso A, 2007, IEEE T GEOSCI REMOTE, V45, P4158, DOI 10.1109/TGRS.2007.904951; Price JC, 1997, IEEE T GEOSCI REMOTE, V35, P1277, DOI 10.1109/36.628794; SUN L, 2006, GEOSC REM SENS S 200, P2064	6	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-69811-1	LECT NOTES COMPUT SC			2008	5112						1091	1100				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Biomedical; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BHX79	WOS:000257302500109	
B	Chuang, LY; Li, JC; Yang, CH			IA ENG	Chuang, Li-Yeh; Li, Jung-Chike; Yang, Cheng-Hong			Chaotic binary particle swarm optimization for feature selection using logistic map	IMECS 2008: INTERNATIONAL MULTICONFERENCE OF ENGINEERS AND COMPUTER SCIENTISTS, VOLS I AND II	Lecture Notes in Engineering and Computer Science		English	Proceedings Paper	International Multiconference of Engineers and Computer Scientists	MAR 19-21, 2008	Hong Kong, PEOPLES R CHINA	Int Assoc Engn, Int Assoc Engn, Soc Artificial Intelligence, Int Assoc Engn, Soc Bioinformat, Int Assoc Engn, Soc Comp Sci, Int Assoc Engn, Soc Data Mining, Int Assoc Engn, Soc Elect Engn, Int Assoc Engn, Soc Imaging Engn, Int Assoc Engn, Soc Info Syst Eng, Int Assoc Engn, Soc Internet Comp & Web Serv, Int Assoc Engn, Soc Mech Engn, Int Assoc Engn, Operat Res, Int Assoc Engn, Sci Comp, Int Assoc Engn, Soc Software Engn, Int Assoc Engn, Soc Wireless Networks		feature selection; binary particle swarm optimization; logistic map; K-nearest neighbor; leave-one-out cross-validation	CLASSIFIER	Feature selection is a useful technique for increasing classification accuracy. The primary objective is to remove irrelevant features in the feature space and identify relevant features. Binary particle swarm optimization (BPSO) has been applied successfully in solving feature selection problem. In this paper, chaotic binary particle swarm optimization (CBPSO) with logistic map for determining the inertia weight is used. The K-nearest neighbor (K-NN) method with leave-one-out cross-validation (LOOCV) serves as a classifier for evaluating classification. accuracies. Experimental results indicate that the proposed method not only reduces the number of features, but also achieves higher classification accuracy than other methods.	[Chuang, Li-Yeh] I Shou Univ, Dept Chem Engn, Kaohsiung, Taiwan	Chuang, LY (reprint author), I Shou Univ, Dept Chem Engn, Kaohsiung, Taiwan.						Chuanwen J., 2005, MATH COMPUT SIMULAT, V68, P57, DOI 10.1016/j.matcom.2004.10.003; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1977, IEEE T SYST MAN CYB, V7, P657, DOI 10.1109/TSMC.1977.4309803; FIX E, 1989, INT STAT REV, V57, P238, DOI 10.2307/1403797; Kennedy J., 1995, IEEE INT C NEUR NETW, V4, P1942, DOI DOI 10.1109/ICNN.1995.488968; Kennedy J., 2001, SWARM INTELLIGENCE; Kennedy J, 1997, IEEE SYS MAN CYBERN, P4104; Liu H, 2005, IEEE INTELL SYST, V20, P64, DOI 10.1109/MIS.2005.105; Huan Liu, 2005, IEEE Transactions on Knowledge and Data Engineering, V17, DOI 10.1109/TKDE.2005.66; Murphy P. M., 1995, UCI REPOSITORY MACHI; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; Shi Y.H., 1998, P IEEE INT C EV COMP, P69, DOI DOI 10.1109/ICEC.1998.699146; Sivagaminathan RK, 2007, EXPERT SYST APPL, V33, P49, DOI 10.1016/j.eswa.2006.04.010; Tahir MA, 2007, PATTERN RECOGN LETT, V28, P438, DOI 10.1016/j.patrec.2006.08.016; Tan SB, 2006, EXPERT SYST APPL, V30, P290, DOI 10.1016/j.eswa.2005.07.019; Wang XY, 2007, PATTERN RECOGN LETT, V28, P459, DOI 10.1016/j.patrec.2006.09.003	16	0	0	INT ASSOC ENGINEERS-IAENG	HONG KONG	UNIT1, 1-F, 37-39 HUNG TO ROAD, KWUN TONG, HONG KONG, 00000, PEOPLES R CHINA		978-988-98671-8-8	LECT NOTES ENG COMP			2008							131	136				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Engineering, Manufacturing; Engineering, Electrical & Electronic; Mathematical & Computational Biology; Mathematics, Applied; Telecommunications	Automation & Control Systems; Computer Science; Engineering; Mathematical & Computational Biology; Mathematics; Telecommunications	BHV15	WOS:000256665700026	
B	Farooqi, AH; Munir, A			IEEE	Farooqi, Ashfaq Hussain; Munir, Ali			Intrusion Detection System for IP Multimedia Subsystem Using K-Nearest Neighbor classifier	INMIC: 2008 INTERNATIONAL MULTITOPIC CONFERENCE			English	Proceedings Paper	12th IEEE International Multitopic Conference	DEC 23-24, 2008	Karachi, PAKISTAN	IEEE Karachi Sect, Higher Educ Commiss	Bahria Univ	IMS; 3GPP; PCSCF; DoS; IDS; KNN		IP Multimedia Subsystem (IMS) is a new next generation networking architecture that will provide better quality of service, charging infrastructure and security. The basic idea behind IMS is convergence; providing a single interface to different traditional or modern networking architectures allowing better working environment for the end users. IMS is still not commercially adopted and used but research is in progress to explore it. IMS is an IP based overlay next generation network architecture. It inherent number of security threats of Session Initiation Protocol (SIP), TCP, UDP etc as it uses SIP and IP protocols. Some of them can degrade the performance of IMS seriously and may cause DoS or DDoS attacks. The paper presents a new approach keeping a vision of secure IMS based on Intrusion Detection System (IDS) using K-Nearest Neighbor (KNN) as classifier. The KNN classifier can effectively detect intrusive attacks and achieve a low false positive rate. It can distinguish between the normal behavior of the system or abnormal. In this paper. we have focused on the key element of IMS core known as Proxy Call Session Control Function (PCSCF). Network based anomaly detection mechanism is proposed using KNN as anomaly detector. Experiments are performed on OpenIMS Core and the result shows that IMS is vulnerable to different types of attacks such as UDP flooding, IP spoofing that can cause DoS. KNN classifier effectively distinguishes the behavior of the system as normal or intrusive and achieve low false positive rate.	[Farooqi, Ashfaq Hussain; Munir, Ali] Natl Univ Comp & Emerging Sci, Dept Comp Sci, Islamabad, Pakistan	Farooqi, AH (reprint author), Natl Univ Comp & Emerging Sci, Dept Comp Sci, Islamabad, Pakistan.	i070801@nu.edu.pk; i070811@nu.edu.pk					ANDERSON JP, 1990, COMPUTER SECURITY TH; AXELSSON S, 1999, RES INTRUSION DETECT; BACE R, 2001, NIST; BELLMAN, 2007, BUSINESS COMMUNI JAN; Burr Ridge I, 1997, MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRISCUOLO PJ, 2004, DISTRIBUTED DENIAL S; CUNNINGHAM P, 2007, K NEAREST NEIGHBOUR; DENNING DE, 1987, IEEE T SOFTWARE ENG, V13, P222, DOI 10.1109/TSE.1987.232894; Geneiatakis D, 2006, IEEE COMMUN SURV TUT, V8, P68, DOI 10.1109/COMST.2006.253270; Herrero A, 2007, ADV SOFT COMP, V44, P320; HUNTER MT, 2007, ACM WORKSH MIDDL NEX; Kurapati K, 2006, BUS COMMUN REV, V36, P40; LAING B, 2000, GUIDE IMPLEMENTING N; LI Y, 2008, DETECTING DDOS ATTAC; Liao Y, 2002, P 11 USENIX SEC S, P51; McHugh J, 2000, IEEE SOFTWARE, V17, P42, DOI 10.1109/52.877859; POIKSELK M, 2006, IMS IP MULTIMEDIA CO; RAWAT S, 2006, J INFORM ASSURANCE S, V1, P43; SELVAKANI S, 2007, INT J COMPUTER SCI N, V7; TSAGKAROPOULOS M, 2007, IEEE INT S PIMRC SEP, P1; VELASCO V, 2000, INTRO IP SPOOFING; VINGARZAN D, 2007, IEEE VEHICULAR TECHN, V2, P29; VU NH, 2008, DDOS ATTACK DETECTIO; *MCAF PROV SEC, 2005, COMPL SEC CAS COMB B; OPENIMS CORE CLIENTS	26	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-2823-6				2008							423	428				6	Engineering, Multidisciplinary; Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	BJJ31	WOS:000266371600079	
S	Yang, CH; Huang, CC; Wu, KC; Chang, HY		Fyfe, C; Kim, D; Lee, SY; Yin, H		Yang, Cheng-Hong; Huang, Chi-Chun; Wu, Kuo-Chuan; Chang, Hsin-Yun			A Novel GA-Taguchi-Based Feature Selection Method	INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING - IDEAL 2008	Lecture Notes in Computer Science		English	Proceedings Paper	9th International Conference on Intelligent Data Engineering and Automated Learn	NOV 02-05, 2008	Daejeon, SOUTH KOREA	Dept Bio & Brain Engn, KAIST, Air Force Off Sci Res, Asian Office Aerosp Res & Dev		Genetic Algorithm; Taguchi Method; Orthogonal Array; Feature subset selection; Pattern Classification	FEATURE SUBSET-SELECTION; CLASSIFICATION; ALGORITHMS	This work presents a novel GA-Taguchi-based feature selection method. Genetic algorithms are utilized with randomness for "global search" of the entire search space of the intractable search problem. Various genetic operations. including crossover. Mutation, selection and replacement are performed to assist the search procedure in escaping from sub-optimal Solutions. In each iteration in the proposed nature-inspired method, the Taguchi methods are employed for "local search" of the entire search space and thus can help explore better feature subsets for next iteration. The two-level orthogonal array is utilized for a well-organized and balanced comparison of two levels for features-a feature is or is not selected for pattern classification-and interactions among features. The signal-to-noise ratio (SNR) is then used to determine the robustness of the features. As a result feature subset evaluation efforts call be significantly reduced and a superior feature Subset with high classification performance call be obtained. Experiments arc performed oil different application domains to demonstrate the performance of the proposed nature-inspired method. The proposed hybrid GA-Taguchi-based approach, with wrapper nature, yields superior performance and improves classification accuracy in pattern classification.	[Yang, Cheng-Hong; Wu, Kuo-Chuan] Natl Kaohsiung Univ Appl Sci, Dept Comp Sci & Informat Engn, Kaohsiung 80778, Taiwan	Yang, CH (reprint author), Natl Kaohsiung Univ Appl Sci, Dept Comp Sci & Informat Engn, 415 Chien Kung Rd, Kaohsiung 80778, Taiwan.	chyang@cc.kuas.edu.tw; cchuang@mail.nkmu.edu.tw; hsin@ms.chinmin.edu.tw; hsin@ms.chinmin.edu.tw					Blake CL, 1998, UCI REPOSITORY MACHI; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Cawley GC, 2003, PATTERN RECOGN, V36, P2585, DOI 10.1016/S0031-3203(03)00136-5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1990, NORMS NN PATTERN CLA; DASH M, 1997, INTELL DATA ANAL, V2, P232; DOAK J, 1992, EVALUATION FEATURE S; Duda R., 1973, PATTERN CLASSIFICATI; Goldberg D. E, 1989, GENETIC ALGORITHMS S; Hall M. A., 1998, THESIS U WAIKATO; HOLLAND JH, 1975, ADAPTATION NATURAL A; Inza I, 2001, INT J APPROX REASON, V27, P143, DOI 10.1016/S0888-613X(01)00038-X; JOHNSONGENTILE K, 1994, J EDUC COMPUT RES, V11, P121; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491; Liu H., 1996, P 13 INT C MACH LEAR, P319; Liu H., 1998, FEATURE SELECTION KN; MITCHELL M, 1992, INTRO GENETIC ALGORI; STONE M, 1974, J R STAT SOC B, V36, P111; Taguchi G, 2000, ROBUST ENG; Wu Y., 2000, TAGUCHI METHODS ROBU	21	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-88905-2	LECT NOTES COMPUT SC			2008	5326						112	119				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BIP04	WOS:000261445100015	
S	Bayoudh, I; Bechet, N; Roche, M		Shi, Z; MercierLaurent, E; Leake, D		Bayoudh, Ines; Bechet, Nicolas; Roche, Mathieu			Blog Classification: Adding Linguistic Knowledge to Improve the K-NN Algorithm	INTELLIGENT INFORMATION PROCESSING IV	INTERNATIONAL FEDERATION FOR INFORMATION PROCESSING		English	Proceedings Paper	5th IFIP International Conference on Intelligent Information Processing	OCT 19-22, 2008	Beijing, PEOPLES R CHINA	IFIP TC12, Chinese Assoc Artificial Intelligence, Inst Comp Technol, Chinese Acad Sci		blog; categorization; linguistic knowledge; K-NN		Blogs are interactive and regularly updated websites which can be seen as diaries. These websites are composed by articles based on distinct topics. Thus, it is necessary to develop Information Retrieval approaches for this new web knowledge. The first important step of this process is the categorization of the articles. The paper above compares several methods using linguistic knowledge with k-NN algorithm for automatic categorization of weblogs articles.	[Bayoudh, Ines] Univ 7 Novembre Carthage, INSAT, Ctr Urbain Nord, Tunis, Tunisia	Bayoudh, I (reprint author), Univ 7 Novembre Carthage, INSAT, Ctr Urbain Nord, Tunis, Tunisia.						BERGMAN MJN, 1998, IMPACT, V2, P167; Chen CM, 2006, IEEE S VIS ANAL, P59; CORMACK RM, 1971, REV CLASSIFICATION D, V3, P321; CORNUEJOLS A, 2002, APPRENTISSAGE ARTIFI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Joachims T, 1998, P 10 EUR C MACH LEAR, P137; JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588; Lewis DD, 2004, J MACH LEARN RES, V5, P361; Moulinier I., 1996, Proceedings. Fifth Annual Symposium on Document Analysis and Information Retrieval; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Schmid H., 1995, P ACL SIGDAT WORKSH; Vapnik V.N., 1995, NATURE STAT LEARNING; Weiss S., 2005, TEXT MINING PREDICTI; Yang YM, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P42; Yang Y. M., 1999, INFORM RETRIEVAL, V1, P69, DOI 10.1023/A:1009982220290	17	1	2	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1571-5736	978-0-387-87684-9	INT FED INFO PROC			2008							68	77				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BIK75	WOS:000260431400007	
J	Yang, JY; Yang, MQ				Yang, Jack Y.; Yang, Mary Qu			Identification of Intrinsically Unstructured Proteins using hierarchical classifier	INTERNATIONAL JOURNAL OF DATA MINING AND BIOINFORMATICS			English	Article						intrinsically unstructured regions and proteins; Recursive Maximum Contrast Tree; RMCT; IUP; machine learning; classification; data mining; bioinformatics	SEQUENCES; DISORDER; MEMBRANE	It is suggested, that protein functions only when folded into a particular 3-D structure. Recently, many protein regions and some entire proteins have been identified with no definite tertiary structure, but presenting instead as dynamic, disorder ensembles Under different physiochemical circimstances. These proteins and regions are known as Intrinsically Unstructured regions and Proteins (IUP). We constructcd a Recursive Maximum Contrast Tree (RMCT) based classifier to identify IUP. The classifier has been benchmarked against industrial standard PONDR VLXT on out-of-sample, clata byexternalrrial evaluators. The IUP predictor is a viable alternative software tool for identifying intrinsic unstructured regions and proteins.	[Yang, Jack Y.] Harvard Univ, Massachusetts Gen Hosp, Dept Radiat Oncol, Boston, MA 02114 USA; [Yang, Jack Y.] Harvard Univ, Sch Med, Boston, MA 02114 USA; [Yang, Mary Qu] NHGRI, NIH, US Dept Hlth & Human Serv Bethesda, Rockville, MD 20852 USA	Yang, JY (reprint author), Harvard Univ, Massachusetts Gen Hosp, Dept Radiat Oncol, Boston, MA 02114 USA.	yang@hadron.mgh.harvard.edu; yangma@mail.nih.gov					BEHR JP, 1994, STATE ART 100 YEARS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daughdrill GW, 2005, PROTEIN FOLDING HANDBOOK; Dunker AK, 2001, NAT BIOTECHNOL, V19, P805, DOI 10.1038/nbt0901-805; EISENBERG D, 1984, J MOL BIOL, V179, P125, DOI 10.1016/0022-2836(84)90309-7; ENGELMAN DM, 1986, ANNU REV BIOPHYS BIO, V15, P321, DOI 10.1146/annurev.biophys.15.1.321; Fischer E., 1894, BER DTSCH CHEM GES, V27, P2985, DOI DOI 10.1002/CBER.18940270364; HECKER J, 2007, J COMPUTATI IN PRESS, V1; KOSHLAND DE, 1958, P NATL ACAD SCI USA, V44, P98, DOI 10.1073/pnas.44.2.98; KYTE J, 1982, J MOL BIOL, V157, P105, DOI 10.1016/0022-2836(82)90515-0; lakoucheva LM, 2004, NUCLEIC ACIDS RES, V32, P1037; Li X, 1999, GENOME INFORMATICS, V10, P30; LINDING R, 2003, PROTEIN STRUCTURE, V11, P1316; Linding R, 2003, NUCLEIC ACIDS RES, V31, P3701, DOI 10.1093/nar/gkg519; Liu Li-Ping, 1998, Biopolymers, V47, P41, DOI 10.1002/(SICI)1097-0282(1998)47:1<41::AID-BIP6>3.0.CO;2-X; Peng Kang, 2005, Journal of Bioinformatics and Computational Biology, V3, P35, DOI 10.1142/S0219720005000886; Radivojac P, 2004, PROTEIN SCI, V13, P71, DOI 10.1110/ps.03128904; Romero P, 2000, ARTIF INTELL REV, V14, P447, DOI 10.1023/A:1006678623815; Romero P, 2001, PROTEINS, V42, P38, DOI 10.1002/1097-0134(20010101)42:1<38::AID-PROT50>3.0.CO;2-3; SOLOVYEV VV, 1993, COMPUT APPL BIOSCI, V9, P17; YANG MQ, 2005, THESIS PURDUE U W LA; Yang MQ, 2007, INT J GEN SYST, V36, P91, DOI 10.1080/03081070600950868; YANG MT, 2006, P IEEE PES 2006 GEN, P1, DOI 10.1109/INFOCOM.2006.345	23	3	5	INDERSCIENCE ENTERPRISES LTD	GENEVA	WORLD TRADE CENTER BLDG, 29 ROUTE DE PRE-BOIS, CASE POSTALE 856, CH-1215 GENEVA, SWITZERLAND	1748-5673		INT J DATA MIN BIOIN	Int. J. Data Min. Bioinform.		2008	2	2					121	133		10.1504/IJDMB.2008.019093		13	Mathematical & Computational Biology	Mathematical & Computational Biology	341TZ	WOS:000258739300002	
B		Mitra, S; Datta, S; Perkins, T; Michailidis, G				Mitra, S; Datta, S; Perkins, T; Michailidis, G		Classification Techniques	INTRODUCTION TO MACHINE LEARNING AND BIOINFORMATICS	Chapman & Hall-CRC Computer Science and Data Analysis Series		English	Article; Book Chapter							SUPPORT VECTOR MACHINES; GENE-EXPRESSION; DISCRIMINATION METHODS; CLASS PREDICTION; CANCER; CENTROIDS; DIAGNOSIS; INFERENCE; BAYES; RULE									Allwein E.L., 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; Bickel PJ, 2004, BERNOULLI, V10, P989, DOI 10.3150/bj/1106314847; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Bousquet O, 2004, LECT NOTES ARTIF INT, V3176, P169; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Chen XW, 2005, BIOINFORMATICS, V21, P4394, DOI 10.1093/bioinformatics/bti721; Cheng BYM, 2005, PROTEINS, V58, P955, DOI 10.1002/prot.20373; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crammer K, 2001, J MACHINE LEARNING R, V2, P265; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fix E., 1951, 4 USAF SCH AV MED; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FREUND Y, 1997, P 13 INT C MACH LEAR, P148; FRIEDMAN JH, 1998, ANN STAT, V28, P337; Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hastie T, 2001, ELEMENTS STAT LEARNI; KECK HP, 2003, SILICO BIOL, V3, P23; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Lau AY, 2004, P NATL ACAD SCI USA, V101, P6576, DOI 10.1073/pnas.0305043101; Lee YK, 2004, J AM STAT ASSOC, V99, P67, DOI 10.1198/016214504000000098; Lin Y, 2002, DATA MIN KNOWL DISC, V6, P259, DOI 10.1023/A:1015469627679; Mease D, 2008, J MACH LEARN RES, V9, P131; Michailidis G, 2003, J COMPUT BIOL, V10, P689, DOI 10.1089/106652703322539033; Middendorf M, 2005, P NATL ACAD SCI USA, V102, P3192, DOI 10.1073/pnas.0409515102; MOSTELLER F, 1963, J AM STAT ASSOC, V58, P275, DOI 10.2307/2283270; Nesvizhskii AI, 2005, MOL CELL PROTEOMICS, V4, P1419, DOI 10.1074/mcp.R500012-MCP200; Ripley B. D., 1996, PATTERN RECOGNITION; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Scholkopf B., 2002, LEARNING KERNELS; Scott D. W., 1992, MULTIVARIATE DENSITY; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Ulintz PJ, 2006, MOL CELL PROTEOMICS, V5, P497, DOI 10.1074/mcp.M500233-MCP200; VALIANT LG, 1989, COMMUN ACM, P1134; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vapnik V.N., 1998, STAT LEARNING THEORY; Venables W, 1994, MODERN APPL STAT SPL; Wang SJ, 2007, BIOINFORMATICS, V23, P972, DOI 10.1093/bioinformatics/btm046; ZHANG H, 2003, P NATL ACAD SCI USA, V100, P673; Zhang N, 2002, PROTEOMICS, V2, P1406, DOI 10.1002/1615-9861(200210)2:10<1406::AID-PROT1406>3.0.CO;2-9	47	0	0	CHAPMAN & HALL/CRC PRESS	BOCA RATON	6000 BROKEN SOUND PKWY, NW, STE 300, BOCA RATON, FL 33487 USA		978-1-58488-682-2	CH CRC COMP SCI DATA			2008							101	127				27	Computer Science, Theory & Methods; Mathematical & Computational Biology; Statistics & Probability	Computer Science; Mathematical & Computational Biology; Mathematics	BJW16	WOS:000267295300004	
B	Puteh, M; Omar, K; Hamdan, AR; Abu Bakar, A		Pan, JS; Abraham, A; Chang, CC		Puteh, Mazidah; Omar, Khairuddin; Hamdan, Abdul Razak; Abu Bakar, Azuraliza			Immune Network for Classifying Heterogeneous Data	ISDA 2008: EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 2, PROCEEDINGS			English	Proceedings Paper	8th International Conference on Intelligent Systems Design and Applications (ISDA 2008)	NOV 26-28, 2008	Kaohsiung, TAIWAN	IEEE, IEEE SMC Soc, Natl Sci Council, Minist Educ				In the previous AIS research, most of the AIS classifiers use clonal selection and require the data to be in numerical or categorical data types prior to processing. These classifiers ignore the network feature of the immune system that is suitable for classification. Furthermore, the transformation of data into any other specific types from their original form can degrade the originality of the data and consume more space and pre processing time. This paper introduces resource limited immune network model with hybrid affinity measurement for classifying heterogeneous data in its original types. The model is able to process the data with the types as represented in the database. The paper shows comparisons between the model and the selected existing immune algorithms that also uses the same set of data and parameters. The experimental results show that the immune network model produces a better accuracy rate with shorter classifier on most of the heterogeneous data from University of California, Irvive (UCI) Machine Learning Repository (MLR).	[Puteh, Mazidah] Univ Teknol MARA, FTMSK, Selangor, Malaysia	Puteh, M (reprint author), Univ Teknol MARA, FTMSK, Selangor, Malaysia.						BROWNLEE J, 2005, 102 CISCP SWINB U TE; CARTER JH, 2000, J AM MED INFORM ASS, V7; Coakes SJ, 2003, SPSS ANAL ANGUISH VE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY, 1991, NEAREST NEIGHBOR NN; DASGUPTA D, 2006, IEEE COMPUTATIONAL I; de Castro L. N., 2000, P GECCO 00 WORKSH AR, P36; FREITAS A, 2007, IEEE T EVOLUTIONARY, V11, P4; HAMAKER J, 2004, P CEC2004; HART E, 2008, J APPL SOFT COMPUTIN, V8, P191; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hunt JE, 1996, J NETW COMPUT APPL, V19, P189, DOI 10.1006/jnca.1996.0014; Keogh E., 2006, UCR TIME SERIES DATA; METZ CJ, 1998, UCI MACHINE LEARNING; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Timmis J., 2001, THESIS U WALES ABERY; Timmis J., 2002, ARTIFICIAL IMMUNE SY; Timmis J, 2006, LECT NOTES COMPUT SC, V3931, P355; Ventura D., 1995, P 10 INT S COMP INF, P443; WATKINS A, 2004, P 3 INT C ART IMM SY, P427; Watkins A., 2002, P 1 INT C ART IMM SY, P173; Watkins A., 2001, THESIS MISSISSIPPI S; Watkins A., 2004, Genetic Programming and Evolvable Machines, V5, DOI 10.1023/B:GENP.0000030197.83685.94; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; Witten I. H., 2005, DATA MINING	25	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		978-0-7695-3382-7				2008							373	377		10.1109/ISDA.2008.242		5	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BJB31	WOS:000264422700065	
B	Zhang, QG; Zhang, CZ		Zhao, C; Wu, C; Wang, Y; Liu, Q		Zhang Qingguo; Zhang Chengzhi			Automatic Chinese Keyword Extraction Based on KNN for Implicit Subject Extraction	KAM: 2008 INTERNATIONAL SYMPOSIUM ON KNOWLEDGE ACQUISITION AND MODELING, PROCEEDINGS			English	Proceedings Paper	International Symposium on Knowledge Acquisition and Modeling	DEC 21-22, 2008	Wuhan, PEOPLES R CHINA	IEEE Comp Soc, IEEE				In this paper, a method of automatic Chinese keyword extraction based on KNN is proposed. Firstly, it preprocesses the document by Vector Space Model. Secondly, it constructs a set of candidate keywords based on KNN method and the labeled dataset. Finally, it post-processes on candidate keywords by the character of keyword to meet readers' requirements Experimental results show the method proposed can not only improve the precision and recall of keyword extraction, but also extract implicit subject efficiently.	[Zhang Qingguo] Tongfang Knowledge Network Technol Co Ltd Beijing, Beijing 100084, Peoples R China	Zhang, QG (reprint author), Tongfang Knowledge Network Technol Co Ltd Beijing, Beijing 100084, Peoples R China.	qgzhang@cnki.net; zhangchz@istic.ac.cn					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Edmundson H.P., 1959, R126 PRC, P1; LOIS LE, 1970, INFORM STORAGE RETRI, V6, P313; LUHN HP, 1957, IBM J RES DEV, V1, P309; Nevill-Manning C., 1999, P 16 INT JOINT C ART, P668; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; TURNEY PD, 1997, ERB1051 NAT RES COUN; Turney P.D., 1999, ERB1057 NRC, P1; Zhang Qingguo, 2006, Journal of the China Society for Scientific and Technical Information, V25	9	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		978-0-7695-3488-6				2008							689	692		10.1109/KAM.2008.87		4	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BIV54	WOS:000263156800142	
J	Wu, XD; Kumar, V; Quinlan, JR; Ghosh, J; Yang, Q; Motoda, H; McLachlan, GJ; Ng, A; Liu, B; Yu, PS; Zhou, ZH; Steinbach, M; Hand, DJ; Steinberg, D				Wu, Xindong; Kumar, Vipin; Quinlan, J. Ross; Ghosh, Joydeep; Yang, Qiang; Motoda, Hiroshi; McLachlan, Geoffrey J.; Ng, Angus; Liu, Bing; Yu, Philip S.; Zhou, Zhi-Hua; Steinbach, Michael; Hand, David J.; Steinberg, Dan			Top 10 algorithms in data mining	KNOWLEDGE AND INFORMATION SYSTEMS			English	Article							NEAREST NEIGHBOR RULES; ASSOCIATION RULES; CLASSIFICATION; QUANTIZATION; CLASSIFIERS; CONFIDENCE; REGRESSION; FRAMEWORK; PATTERNS; TREES	This paper presents the top 10 data mining algorithms identified by the IEEE International Conference on Data Mining (ICDM) in December 2006: C4.5, k-Means, SVM, Apriori, EM, PageRank, AdaBoost, kNN, Naive Bayes, and CART. These top 10 algorithms are among the most influential data mining algorithms in the research community. With each algorithm, we provide a description of the algorithm, discuss the impact of the algorithm, and review current and further research on the algorithm. These 10 algorithms cover classification, clustering, statistical learning, association analysis, and link mining, which are all among the most important topics in data mining research and development.	[Wu, Xindong] Univ Vermont, Dept Comp Sci, Burlington, VT USA; [Kumar, Vipin] Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN USA; [Quinlan, J. Ross] Rulequest Res pty Ltd, St Ives, NSW, Australia; [Ghosh, Joydeep] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA; [Yang, Qiang] Hong Kong Univ Sci & Technol, Dept Comp Sci, Hong Kong, Peoples R China; [Motoda, Hiroshi] Osaka Univ, AFORS AOARD, Tokyo 10600326, Japan; [McLachlan, Geoffrey J.] Univ Queensland, Dept Math, Brisbane, Qld, Australia; [Ng, Angus] Griffith Univ, Sch Med, Brisbane, Qld, Australia; [Liu, Bing] Univ Illinois, Dept Comp Sci, Chicago, IL 60607 USA; [Yu, Philip S.] IBM TJ Watson Res Ctr, Hawthorne, NY 10532 USA; [Zhou, Zhi-Hua] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210008, Peoples R China; [Steinbach, Michael] Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA; [Hand, David J.] Univ London Imperial Coll Sci & Technol, Dept Math, London, England; [Steinberg, Dan] Maxwell Labs Inc, Salford Syst, San Diego, CA 92123 USA	Wu, XD (reprint author), Univ Vermont, Dept Comp Sci, Burlington, VT USA.	xwu@cs.uvm.edu; kumar@cs.umn.edu; quinlan@rulequest.com; ghosh@ece.utexas.edu; qyang@cs.ust.hk; motoda@ar.sanken.osaka-u.ac.jp; gjm@maths.uq.edu.au; psyu@us.ibm.com; steinbac@cs.umn.edu; d.j.hand@imperial.ac.uk; dsx@salford-systems.com	Adams, Niall/D-2472-2010; McLachlan, Geoffrey/A-1491-2008				Agrawal R, 1994, P 20 INT C VER LARG, P487; Ahmed S, 2006, KNOWL INF SYST, V10, P315, DOI 10.1007/s10115-006-0010-1; Banerjee A, 2005, J MACH LEARN RES, V6, P1705; BEZDEK JC, 1986, FUZZY SET SYST, V18, P237, DOI 10.1016/0165-0114(86)90004-7; Bloch DA, 2002, J COMPUT GRAPH STAT, V11, P263, DOI 10.1198/106186002760180509; Bonchi F, 2006, KNOWL INF SYST, V9, P180, DOI 10.1007/s10115-005-0201-1; BREIMAN L, 1968, CLASSICS MATH; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1999, NEURAL COMPUT, V11, P1493, DOI 10.1162/089976699300016106; BRIN S., 1998, COMPUTER NETWORKS IS, V30, p[1, 107]; Chen JR, 2007, KNOWL INF SYST, V11, P369, DOI 10.1007/s10115-006-0042-6; CHEUNG DW, 1996, P ACM SIGMOD INT C D, P13; Chi Y, 2006, KNOWL INF SYST, V10, P265, DOI 10.1007/s10115-006-0003-0; COST S, 1993, MACH LEARN, V10; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1991, NN PATTERN CLASSIFIC; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Devroye L, 1996, PROBABILISTIC THEORY; Dhillon I. S., 2004, KDD, P551; Dietterich TG, 1997, AI MAG, V18, P97; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Faust K., 1994, SOCIAL NETWORK ANAL; Fix E., 1951, 4 USAF SCH AV MED; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; Friedman JH, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P717; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Fung G, 2007, KNOWL INF SYST, V11, P243, DOI 10.1007/s10115-006-0043-5; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Golub G. H., 1983, MATRIX COMPUTATIONS; Gondek D, 2007, KNOWL INF SYST, V12, P1, DOI 10.1007/s10115-006-0009-7; Gray RM, 1998, IEEE T INFORM THEORY, V44, P2325, DOI 10.1109/18.720541; Han E.-H., 1999, THESIS U MINNESOTA; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Herbrich R, 2000, ADV NEUR IN, P115; Hu TM, 2006, KNOWL INF SYST, V10, P505, DOI 10.1007/s10115-006-0017-7; Hunt EB, 1966, EXPT INDUCTION; Inokuchi A, 2005, FUND INFORM, V66, P53; Jain A., 1988, ALGORITHMS CLUSTERIN; Jin RM, 2006, KNOWL INF SYST, V10, P17, DOI 10.1007/s10115-005-0210-0; Kobayashi M, 2006, KNOWL INF SYST, V10, P295, DOI 10.1007/s10115-006-0005-y; Koga H, 2007, KNOWL INF SYST, V12, P25, DOI 10.1007/s10115-006-0027-5; Kriegel H.-P., 1998, P ACM SIGMOD INT C M, P154, DOI 10.1145/276304.276319; Kukar M, 2006, KNOWL INF SYST, V9, P364, DOI 10.1007/s10115-005-0203-z; Kuramochi M, 2005, INT J ARTIF INTELL T, V14, P641, DOI 10.1142/S0218213005002302; Leung CKS, 2007, KNOWL INF SYST, V11, P287, DOI 10.1007/s10115-006-0032-8; Leung CWK, 2006, KNOWL INF SYST, V10, P357, DOI 10.1007/s10115-006-0002-1; Li T, 2006, KNOWL INF SYST, V10, P453, DOI 10.1007/s10115-006-0013-y; Liu B, 2007, WEB DATA MINING EXPL; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; McLachlan G, 1997, EM ALGORITHM EXTENSI; MCLACHLAN GJ, 1987, APPL STAT-J ROY ST C, V36, P318, DOI 10.2307/2347790; McLachlan GJ, 2000, FINITE MIXTURE MODEL; MESSENGE.R, 1972, J AM STAT ASSOC, V67, P768, DOI 10.2307/2284634; Meyer C.D., 2006, GOOGLES PAGE RANK SC; Morishita S., 2000, P 19 ACM SIGACT SIGM, P226, DOI 10.1145/335168.335226; Olshen R, 2001, STAT SCI, V16, P184, DOI 10.1214/ss/1009213290; PAGE L, 1999, 19990120 STANF U; Quinlan J. R., 1979, EXPERT SYSTEMS MICRO; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN R, 1989, UNKNOWN ATTRIBUTE VA, P164; Reyzin Lev, 2006, P 23 INT C MACH LEAR, P753, DOI 10.1145/1143844.1143939; Ridgeway G., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; SCHAEFER P, 1990, EARTH ISL J, V5, P2; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; SCHATTEN G, 1998, J LAW MED ETHICS, V26, P5; Scholkopf B., 2002, LEARNING KERNELS; Srikant R., 1995, P 21 INT C VER LARG, P407; STEINBACH M, 2000, P KDD WORKSH TEXT MI; Steinbach M, 2007, KNOWL INF SYST, V12, P279, DOI 10.1007/s10115-006-0041-7; Tan P. N., 2006, INTRO DATA MINING; Tao DC, 2007, KNOWL INF SYST, V13, P1, DOI 10.1007/s10115-006-0050-6; Thabtah FA, 2006, KNOWL INF SYST, V9, P109, DOI 10.1007/s10115-005-0213-x; Ting KM, 2002, IEEE T KNOWL DATA EN, V14, P659; TOUSSAINT G, 2002, INT 2002 34 S COMP S; TOUSSAINT GT, 2002, JCDCG, P273; Tsang IW, 2005, J MACH LEARN RES, V6, P363; Uno T, 2004, LECT NOTES COMPUT SC, V3245, P16; Vapnik V.N., 1995, NATURE STAT LEARNING; Viola P, 2001, PROC CVPR IEEE, P511; Washio T, 2005, LECT NOTES ARTIF INT, V3721, P692; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Yan X, 2002, P 2002 IEEE INT C DA, P721; Yang Q, 2006, INT J INF TECH DECIS, V5, P597, DOI 10.1142/S0219622006002258; YU PS, 2005, P WEB INT WI 05; Zhang J, 2006, KNOWL INF SYST, V9, P157, DOI 10.1007/s10115-005-0211-z	92	221	242	SPRINGER LONDON LTD	ARTINGTON	ASHBOURNE HOUSE, THE GUILDWAY, OLD PORTSMOUTH ROAD, ARTINGTON GU3 1LP, GUILDFORD, ENGLAND	0219-1377		KNOWL INF SYST	Knowl. Inf. Syst.	JAN	2008	14	1					1	37		10.1007/s10115-007-0114-2		37	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	243KS	WOS:000251795900001	
S	Mitani, Y; Sugimura, Y; Hamamoto, Y		Lovrek, I		Mitani, Yoshihiro; Sugimura, Yuuki; Hamamoto, Yoshihiko			A method for reading a resistor by image processing techniques	KNOWLEDGE - BASED INTELLIGENT INFORMATION AND ENGINEERING SYSTEMS, PT 1, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	12th International Conference on Knowledge-Based Intelligent Information and Engineering Systems	SEP 03-05, 2008	Zagreb, CROATIA	KES Int, Innovat Knowledge Based & Intelligent Engn Syst, Univ Zagreb, Fac Elect Engn & Comp, Republic Croatia, Minist Sci, Educ & Sports, Ericsson Nikola Tesla, Croatian Natl Tourist Board, Zagreb Tourist Board				The resistance of a resistor is defined by colored lines printed on the resistor's body. Normally, people read it by sight. Though, if a computer performs this instead, we can reduce the costs. In this paper, we propose a method for reading this resistance by image processing techniques. We extract colors front a real resistor's picture, and classify it, by its colors. The experimental results show the effectiveness of the proposed method.	[Mitani, Yoshihiro; Sugimura, Yuuki] Ube Natl Coll Technol, Ube, Yamaguchi 7558555, Japan	Mitani, Y (reprint author), Ube Natl Coll Technol, Ube, Yamaguchi 7558555, Japan.						Chan KL, 1997, P SOC PHOTO-OPT INS, V3185, P157, DOI 10.1117/12.284040; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 2001, PATTERN CLASSIFICATI; Fukunaga K., 1990, INTRO STAT PATTERN R; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62; Plataniotis K. N., 2000, COLOR IMAGE PROCESSI; Russ John C., 1999, IMAGE PROCESSING HDB	7	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-85562-0	LECT NOTES ARTIF INT			2008	5177						433	439				7	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BIF73	WOS:000259162700050	
S	Panigrahy, R		Laber, ES; Bornstein, C; Nogueira, LT; Faria, L		Panigrahy, Rina			An improved algorithm finding nearest neighbor using kd-trees	LATIN 2008: THEORETICAL INFORMATICS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	8th Latin American Symposium on Theoretical Informatics (LATIN 2008)	APR 07-JUL 11, 2008	Buzios, BRAZIL	Microsoft, UOL, IFIP, HP, Yahoo, FAPERJ, CNPq, CAPES, Springer			IMAGE	We suggest a simple modification to the Kd-tree search algorithm for nearest neighbor search resulting in an improved performance. The Kd-tree data structure seems to work well in finding nearest neighbors in low dimensions but its performance degrades even if the number of dimensions increases to more than two. Since the exact nearest neighbor search problem suffers from the curse of dimensionality we focus on approximate solutions; a c-approximate nearest neighbor is any neighbor within distance at most c times the distance to the nearest neighbor. We show that for a randomly constructed database of points if the query point is chosen close to one of the points in the data base, the traditional Kd-tree search algorithm has a very low probability of finding an approximate nearest neighbor; the probability of success drops exponentially in the number of dimensions d as e(- Omega(d/c)). However, a simple change to the search algorithm results in a much higher chance of success. Instead of searching for the query point in the Kd-tree we search for a random set of points in the neighborhood of the query point. It turns out that searching for e(Omega(d/c)) such points can find the c-approximate nearest neighbor with a much higher chance of success.	Microsoft Res, Mountain View, CA USA	Panigrahy, R (reprint author), Microsoft Res, Mountain View, CA USA.						Andoni A, 2006, P S FDN COMP SCI FOC; ARYA S, 1994, PROCEEDINGS OF THE FIFTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P573; Bentle J.L., 1977, ACM T MATH SOFTWARE, V3, P209; Borodin A., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, DOI 10.1145/301250.301330; CLARKSON KL, 1997, P 29 ANN ACM S THEOR, P609, DOI 10.1145/258533.258655; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Datar M., 2004, P S COMP GEOM; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Devroye L., 1982, HDB STAT, V2; Dolev D., 1993, Proceedings of the 2nd Israel Symposium on Theory and Computing Systems (Cat. No.93TH0520-7), DOI 10.1109/ISTCS.1993.253486; FAGIN R, 1998, P ACM S PRINC DAT SY, V1; FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146; HARPELED S, 2001, P S FDN COMP SCI; INDYK P, 2001, HIGH DIMENSIONAL COM; INDYK P, 2001, EMBEDDING EARTHMOVER; INDYK P, 1997, HDB DISCRETE COMPUTA, pCH39; INDYK P, 2002, HDB DISCRETE; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; INDYK P., 1997, P 29 ANN ACM S THEOR, P618, DOI 10.1145/258533.258656; JAYRAM TS, 2003, P 35 ANN ACM S THEOR, P667; KLEMBERG J, 1997, P 29 ANN ACM SYMPOS, P599; Kushilevitz E., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276877; Linial N., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/237814.237999; MEISER S, 1993, INFORM COMPUT, V106, P286, DOI 10.1006/inco.1993.1057; MOTWANI R, 2006, P 22 ANN ACM S COMP; Panigrahy R., 2006, SODA, P1186; PENTLAND A, 1994, P SOC PHOTO-OPT INS, V2185, P34, DOI 10.1117/12.171786; Salton G., 1989, AUTOMATIC TEXT PROCE; VANRIJSBERGEN CJ, 1990, INFORM RETRIEVAL BUT; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025	30	6	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-78772-3	LECT NOTES COMPUT SC			2008	4957						387	398		10.1007/978-3-540-78773-0_34		12	Computer Science, Theory & Methods	Computer Science	BHM87	WOS:000254390900034	
S	Nguyen, N; Guo, Y		Daelemans, W; Goethals, B; Morik, K		Nguyen, Nam; Guo, Yunsong			Metric Learning: A Support Vector Approach	MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES, PART II, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	European Conference on Principles of Data Mining and Knowledge Discovery	SEP 15-19, 2008	Antwerp, BELGIUM	Univ Antwerp, Computat Linguist Flanders, Google, hp, VADIS, COGNOS, European Off Aerosp, SPSS, textkernel, Data Mining & Knowledge Discovery, IBM, Machine Learning		metric learning; K-nearest neighbor classification; SVM	CLASSIFICATION	In this paper, we address the metric learning problem utilizing a margin-based approach. Our metric learning problem is formulated as a quadratic semi-definite programming problem (QSDP) with local neighborhood constraints, which is based on the Support Vector Machine (SVM) framework. The local neighborhood constraints ensure that examples of the same class are separated from examples of different classes by a margin. In addition to providing an efficient algorithm to solve the metric learning problem, extensive experiments on various data sets show that our algorithm is able to produce a new distance metric to improve the performance of the classical K-nearest neighbor (KNN) algorithm on the classification task. Our performance is always competitive and often significantly better than other state-of-the-art metric learning algorithms.	[Nguyen, Nam; Guo, Yunsong] Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA	Nguyen, N (reprint author), Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA.						Asuncion A., 2007, UCI MACHINE LEARNING; CHANG CC, 2001, LIBSVM DATA; Chopra S., 2005, P IEEE C COMP VIS PA; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crammer K, 2001, J MACHINE LEARNING R, V2, P265; Davis J. V., 2007, P 24 INT C MACH LEAR, P209, DOI DOI 10.1145/1273496.127352; Domeniconi C, 2005, IEEE T NEURAL NETWOR, V16, P899, DOI 10.1109/TNN.2005.849821; Globerson A., 2005, ADV NEURAL INFORM PR; Goldberger J., 2004, ADV NEURAL INFORM PR; Hastie T, 1996, ADV NEUR IN, V8, P409; He H., 2000, J ADV COMPUTATIONAL, V4, P130; Joachims T., 1998, ADV KERNEL METHODS S; Roweis Sam, 2000, SCIENCE, V290; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Schultz Matthew, 2004, ADV NEURAL INFORM PR; SHALEV-SHWARTZ S, 2007, P 24 INT C MACH LEAR, P807, DOI DOI 10.1145/1273496.1273598; Shalev-Shwartz S, 2004, P 21 INT C MACH LEAR; Shental N, 2002, P 7 EUR C COMP VIS, P776; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tsang I., 2003, P INT C ART NEUR NET; Vapnik V.N., 1998, STAT LEARNING THEORY; WEINBERGER KQ, 2006, ADV ING NEURAL INFOR; Xing E. P., 2003, ADV NEURAL INFORM PR	23	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-87480-5	LECT NOTES ARTIF INT			2008	5212		II				125	136				12	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Information Systems	Computer Science	BIJ50	WOS:000260075900009	
S	Jaeger, S; Ma, HF; Doermann, D		Marinai, S; Fujisawa, H		Jaeger, Stefan; Ma, Huanfeng; Doermann, David			Combining Classifiers with Informational Confidence	MACHINE LEARNING IN DOCUMENT ANALYSIS AND RECOGNITION	Studies in Computational Intelligence		English	Article; Book Chapter							INVARIANT IMAGE RECOGNITION; DOCUMENT IMAGES; SCRIPT; CLASSIFICATION; MOMENTS	We propose a new statistical method for learning normalized confidence values in multiple classifier systems. Our main idea is to adjust confidence values so that their nominal values equal the information actually conveyed. In order to do so, we assume that information depends on the actual performance of each confidence value on an evaluation set. As information measure, we use Shannon's well-known logarithmic notion of information. With the confidence values matching their informational content, the classifier combination scheme reduces to the simple sum-rule, theoretically justifying this elementary combination scheme. In experimental evaluations for script identification, and both handwritten and printed character recognition, we achieve a consistent improvement on the best single recognition rate. We cherish the hope that our information-theoretical framework helps fill the theoretical gap we still experience in classifier combination, putting the excellent practical performance of multiple classifier systems on a more solid basis.	[Jaeger, Stefan; Doermann, David] Univ Maryland, Inst Adv Comp Studies, Lab Language & Media Proc, College Pk, MD 20742 USA	Jaeger, S (reprint author), Univ Maryland, Inst Adv Comp Studies, Lab Language & Media Proc, 3451 AV Williams Bldg, College Pk, MD 20742 USA.	jaeger@umiacs.umd.edu; hfma@umiacs.umd.edu; doermann@umiacs.umd.edu					Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; ERP MV, 2002, P 8 INT WORKSH FRONT, P195; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Gader PD, 1996, PATTERN RECOGN LETT, V17, P577, DOI 10.1016/0167-8655(96)00021-9; GUENTER S, 2003, LECT NOTES COMPUTER, P326; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Hochberg J, 1997, IEEE T PATTERN ANAL, V19, P176, DOI 10.1109/34.574802; HUANG YS, 1995, IEEE T PATTERN ANAL, V17, P90, DOI 10.1109/34.368145; IANAKIEV K, 2000, LECT NOTES COMPUTER, P340; JAEGER S, 1998, THESIS U FREIBURG; Jaeger S., 2004, Proceedings. Ninth International Workshop on Frontiers in Handwriting Recognition; Jaeger S, 2001, SIXTH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, PROCEEDINGS, P566; Jaeger S., 2001, International Journal on Document Analysis and Recognition, V3, DOI 10.1007/PL00013559; Jaeger S, 2004, INT C PATT RECOG, P216, DOI 10.1109/ICPR.2004.1334062; Jaeger S., 2005, ICDAR, P416; Jaeger S., 2003, International Journal on Document Analysis and Recognition, V6, DOI 10.1007/s10032-003-0107-y; Joachims T., 1999, ADV KERNEL METHODS S, P41; KANG HJ, 1997, 4 INT C DOC AN REC I, P870; KHOTANZAD A, 1990, PATTERN RECOGN, V23, P1089, DOI 10.1016/0031-3203(90)90005-6; KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Liu CL, 2004, IEEE T PATTERN ANAL, V26, P198, DOI 10.1109/TPAMI.2004.1262182; MA H, 2004, P INT C DOC REC RETR, P178; Mandler E., 1988, Pattern Recognition and Artificial Intelligence. Towards an Integration. Proceedings of an International Workshop; NAKAGAWA M, 1997, 4 INT C DOC AN REC I, P376; NAKAGAWA M, 1996, P 13 ICPR, V3, P269, DOI 10.1109/ICPR.1996.546953; OBERLAENDER M, 1995, Patent No. 4436408; OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677; Pierce J.R., 1980, INTRO INFORM THEORY; SACCO W, 1988, R INFORM THEORY SAVI; SHANNON CE, 1948, AT&T TECH J, V27, P379; SIBUN P, 1994, P 4 C APPL NAT LANG, P115; Sirlantzis K, 2002, LECT NOTES COMPUT SC, V2364, P169; SLOANE NJA, 1993, CLAUDE ELWOOD SHANNO; Spitz AL, 1997, IEEE T PATTERN ANAL, V19, P235, DOI 10.1109/34.584100; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; TAN C, 1999, INT S INT MULT DIST, P59; TEAGUE M, 1979, J OPT SOC AM, V70, P920; TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913; VELEK O, 2003, LECT NOTES COMPUTER, P196; Velek O, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P177; VELEK O, 2002, 16 INT C PATT REC IC, V1, P588; Waked B, 1998, IEEE SYS MAN CYBERN, P4470; WANG W, 2002, P 8 INT WORKSH FRONT, P117; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943; Zhu Y, 2001, IEEE T PATTERN ANAL, V23, P1192	49	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1860-949X	978-3-540-76279-9	STUD COMPUT INTELL			2008	90						163	191			10.1007/978-3-540-76280-5	29	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BMC03	WOS:000271816500007	
B		Huang, K; Yang, H; King, I; Lyu, M				Huang, K; Yang, H; King, I; Lyu, M		Global Learning vs. Local Learning	MACHINE LEARNING: MODELING DATA LOCALLY AND GLOBALLY	Advanced Topics in Science and Technology in China		English	Article; Book Chapter							CLASSIFICATION; ALGORITHM; MODEL									ANAND R, 1993, IEEE T NEURAL NETWOR, V4, P962, DOI 10.1109/72.286891; Bahl LR, 1993, IEEE T SPEECH AUDI P, V1, P77, DOI 10.1109/89.221369; Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821; BEAUFAYS F, 1999, P INT C AC SPEECH SI, P337; BRAND M, 1998, NEURAL INFORM PROCES, V11; Christopher J. C. B., 1998, DATA MIN KNOWL DISC, V2, P121; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; Duda R., 1973, PATTERN CLASSIFICATI; Duda R.O., 2000, PATTERN CLASSIFICATI; Fausett L., 1994, FUNDAMENTALS NEURAL; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Fukunaga K., 1990, INTRO STAT PATTERN R; Gilks W.R., 1996, MARKOV CHAIN MONTE C; GRZEGORZEWSKI P, 2002, SOFT METHODS PROBABI; Hastie T, 1996, J ROY STAT SOC B MET, V58, P155; Haykin S., 1994, NEURAL NETWORKS COMP; HERBRICH R, 2001, ADV NEURAL INFORM PR; HUANG K, 2003, P INT C ART NEUR NET; HUANG K, 2002, P IEEE INT C SYST MA; Huang KZ, 2004, STUD FUZZ SOFT COMP, V152, P94; Iba W., 1992, P 10 NAT C ART INT, P223; JAROMCZYK JW, 1992, P IEEE, V80, P1502, DOI 10.1109/5.163414; Jebara T., 2002, THESIS MIT; Jordan M. I., 1995, 9503 MIT; Kass RE, 1998, AM STAT, V52, P93, DOI 10.2307/2685466; KOHAVI R, 1997, TECHNIQUE REPORT; Laird NM, 1977, J ROYAL STAT SOC B, V39, P1; Lanckriet G. R. G., 2003, J MACHINE LEARNING R, V3, P555; LANCKRIET GRG, 2001, ADV NEURAL INFORM PR; LANCKRIET GRG, 2002, ADV NEURAL INFORM PR; Langley P., 1993, P 1993 EUR C MACH LE, P153; McLachlan G. J., 1988, MIXTURE MODELS INFER; Mehra P., 1992, ARTIFICIAL NEURAL NE; MENG XL, 1993, BIOMETRIKA, V80; Minka T., 2001, THESIS MIT; Neal R. M., 1993, CRGTR931 U TOR DEP C; Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P205; Patterson D., 1996, ARTIFICIAL NEURAL NE; Pearl J., 1988, PROBABILISTIC REASON, p[505, 506, 507, 524]; PINTO RL, 2001, 0101 U TOR DEP STAT; RATHINAVELU C, 1996, P ICSLP; Ripley B. D., 1996, PATTERN RECOGNITION; Rujan P, 1997, NEURAL COMPUT, V9, P99, DOI 10.1162/neco.1997.9.1.99; Scholkopf B, 2002, LEARNING KERNELS SUP; Scholkopf B., 1999, ADV KERNEL METHODS S; Smola A. J., 2000, ADV LARGE MARGIN CLA; Stolcke A., 1993, ADV NEURAL INFORMATI, V5, P11; TIPPING M, 1999, ADV NEURAL INFORM PR, V12; TRIVEDI PK, 1978, ECONOMETRICA, V46, P1181, DOI 10.2307/1911442; Vapnik V, 1999, NATURE STAT LEARNING; Vapnik V.N., 1998, STAT LEARNING THEORY; WOODLAND P, 2000, P ASR 2000; ZHANG W, 2002, P IEEE WORLD C COMP	54	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY		978-3-540-79451-6	ADV TOP SCI TECH CHI			2008							13	27				15	Computer Science, Artificial Intelligence; Multidisciplinary Sciences	Computer Science; Science & Technology - Other Topics	BJS76	WOS:000267110400002	
J	Carson, HS; Morgan, SG; Green, PG				Carson, Henry S.; Morgan, Steven G.; Green, Peter G.			Fine-scale chemical fingerprinting of an open coast crustacean for the assessment of population connectivity	MARINE BIOLOGY			English	Article							MARINE INVERTEBRATE LARVAE; TEMPORAL VARIATION; TRACE-ELEMENTS; CALIFORNIA; DISPERSAL; RETENTION; FISH; HABITATS; OTOLITHS; TRACKING	Chemical fingerprinting techniques recently have been used to track larval dispersal of estuarine species that bear calcified structures, but the applicability of this important approach may be limited on the open coast where chemical signatures may be less distinctive and for the many species that do not retain calcified structures throughout development. Externally brooded embryos of the porcelain crab, Petrolisthes cinctipes, and inductively coupled plasma mass spectrometry were used to determine whether fine-scale variation in trace-elemental composition occurred along an open coast. Embryos were collected from 16 sites from 37.8 degrees to 39.5 degrees north latitude along the Pacific Coast of California, USA during late January and early February 2003. Discriminant function analysis revealed that collection sites, many separated by only a few kilometers along an open coast, could be differentiated with an overall accuracy of 73%, and combining the sites into three regions increased the accuracy to 88%. Thus, distinctive elemental signatures can be detected in open coast species even at a fine scale raising the possibility that larval tags can be developed for many more species than previously thought possible.	San Diego State Univ, Dept Biol, San Diego, CA 92182 USA; Univ Calif Davis, Dept Environm Sci & Policy, Bodega Marine Lab, Davis, CA 94923 USA; Univ Calif Davis, Dept Civil & Environm Engn, Davis, CA 95616 USA	Carson, HS (reprint author), San Diego State Univ, Dept Biol, 5500 Campanilc Dr, San Diego, CA 92182 USA.	hcarson@mail.sdsu.edu					Anastasia JR, 1998, LIMNOL OCEANOGR, V43, P362; Becker BJ, 2007, P NATL ACAD SCI USA, V104, P3267, DOI 10.1073/pnas.0611651104; Becker BJ, 2005, LIMNOL OCEANOGR, V50, P48; Chase Z, 2005, MAR CHEM, V95, P235, DOI 10.1016/j.marchem.2004.09.006; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DiBacco C, 2001, J MAR RES, V59, P53, DOI 10.1357/002224001321237362; DiBacco C, 2000, LIMNOL OCEANOGR, V45, P871; Faure G., 1998, PRINCIPLES APPL GEOC; Flegal AR, 2005, ECOTOXICOLOGY, V14, P645, DOI 10.1007/s10646-005-0016-6; Gillanders BM, 2005, ESTUAR COAST SHELF S, V64, P47, DOI 10.1016/j.ecss.2005.02.005; Gonor S. L., 1970, THESIS OREGON STATE; HUYER A, 1983, PROG OCEANOGR, V12, P259, DOI 10.1016/0079-6611(83)90010-1; JENSEN GC, 1991, J EXP MAR BIOL ECOL, V153, P49, DOI 10.1016/S0022-0981(05)80005-X; LACHENBRUCH PA, 1975, DISCRIMINANT ANAL; Lares ML, 2002, ENVIRON POLLUT, V120, P595; LEVIN LA, 1990, OPHELIA, V32, P115; LEVIN LA, 1993, LIMNOL OCEANOGR, V38, P346; Morris R. H., 1980, INTERTIDAL INVERTEBR; NRIAGU JO, 1989, NATURE, V338, P47, DOI 10.1038/338047a0; SanudoWilhelmy SA, 1996, ENVIRON SCI TECHNOL, V30, P1575, DOI 10.1021/es9505560; Sanudo-Wilhelmy S.A.S., 1991, MAR CHEM, V33, P371, DOI 10.1016/0304-4203(91)90078-B; Shanks AL, 2005, ECOL MONOGR, V75, P505, DOI 10.1890/05-0309; Swearer SE, 1999, NATURE, V402, P799, DOI 10.1038/45533; Thorrold SR, 2002, B MAR SCI, V70, P291; Warner RR, 2005, LIMNOL OCEANOGR, V50, P1529; WEEKS JM, 1992, HYDROBIOLOGIA, V245, P15, DOI 10.1007/BF00008725; Zacherl DC, 2003, MAR ECOL PROG SER, V248, P297, DOI 10.3354/meps248297; Zacherl DC, 2005, MAR ECOL PROG SER, V290, P145, DOI 10.3354/meps290145	28	9	9	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0025-3162		MAR BIOL	Mar. Biol.	JAN	2008	153	3					327	335		10.1007/s00227-007-0808-8		9	Marine & Freshwater Biology	Marine & Freshwater Biology	238ZW	WOS:000251488200010	
S	Depeursinge, A; Lavindrasana, J; Hidki, A; Cohen, G; Geissbuhler, A; Platon, A; Poletti, PA; Muller, H		Andriole, KP; Siddiqui, KM		Depeursinge, Adrien; Lavindrasana, Jimison; Hidki, Asmaa; Cohen, Gilles; Geissbuhler, Antoine; Platon, Alexandra; Poletti, Pierre-Alexandre; Mueller, Henning			A classification framework for lung tissue categorization	MEDICAL IMAGING 2008: PACS AND IMAGING INFORMATICS	Proceedings of SPIE		English	Proceedings Paper	Medical Imaging 2008 Conference	FEB 17-19, 2008	San Diego, CA	SPIE, Amer Assoc Phys Med, Amer Physiol Soc, Comp Assisted Radiol & Surg, Soc Imaging Sci & Technol, Med Image Percept Soc, Radiol Soc N Amer, Soc Imaging Informat Med, Soc Mol Imaging, DICOM Standards Comm		quantitative image analysis; feature extraction; texture analysis; chest high-resolution CT; supervised learning; support vector machines	COMPUTER-AIDED DIAGNOSIS; SUPPORT VECTOR MACHINES; PATTERN-RECOGNITION; FUTURE-DIRECTIONS; DISEASE PATTERNS; RETRIEVAL; SEGMENTATION; TUTORIAL; IMAGES; SYSTEM	We compare five common classifier families in their ability to categorize six lung tissue patterns in high-resolution computed tomography (HRCT) images of patients affected with interstitial lung diseases (ILD) but also normal tissue. The evaluated classifiers are Naive Bayes, k-Nearest Neighbor (k-NN), J48 decision trees, Multi-Layer Perceptron (MLP) and Support Vector Machines (SVM). The dataset used contains 843 regions of interest (ROI) of healthy and five pathologic lung tissue patterns identified by two radiologists at the University Hospitals of Geneva. Correlation of the feature space composed of 39 texture attributes is studied. A grid search for optimal parameters is carried out for each classifier family. Two complementary metrics are used to characterize the performances of classification. Those are based on McNemar's statistical tests and global accuracy. SVM reached best values for each metric and allowed a mean correct prediction rate of 87.9% with high class-specific precision on testing sets of 423 ROIs.	[Depeursinge, Adrien; Lavindrasana, Jimison; Hidki, Asmaa; Cohen, Gilles; Geissbuhler, Antoine; Mueller, Henning] Univ & Hosp Geneva, Serv Med Informat, CH-1211 Geneva 14, Switzerland; [Platon, Alexandra; Poletti, Pierre-Alexandre] Univ & Hosp Geneva, Serv Emergency Radiol, CH-1211 Geneva 14, Switzerland; [Mueller, Henning] Univ Appl Sci Sierre, Sierre, Switzerland	Depeursinge, A (reprint author), Univ & Hosp Geneva, Serv Med Informat, 24 Rue Micheli Crest, CH-1211 Geneva 14, Switzerland.	adrien.depeursinge@sim.hcuge.ch					Aisen AM, 2003, RADIOLOGY, V228, P265, DOI 10.1148/radiol.2281020126; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037//0033-295X.94.2.115; Bishop C. M., 2006, PATTERN RECOGNITION; Bishop C. M., 1995, NEURAL NETWORKS PATT; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Caban JJ, 2007, SPIE MED IMAGING, V6514; Chang C-C., 2001, LIBSVM LIB SUPPORT V; Cohen G, 2006, ARTIF INTELL MED, V37, P7, DOI 10.1016/j.artmed.2005.03.002; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEPEURSINGE A, 2007, SPIE MED IMAGING; DEPEURSINGE A, 2006, SWISS C MED INF SSIM; DEPEURSINGE A, 2007, EMBS 2007 29 ANN INT; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Flaherty KR, 2004, AM J RESP CRIT CARE, V170, P904, DOI 10.1164/rccm.200402-147OC; Frank E, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P1305, DOI 10.1007/0-387-25465-X_62; Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Kubat M., 1997, P 14 INT C MACH LEAR, P179; Muller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024; Nishikawa RA, 2007, COMPUT MED IMAG GRAP, V31, P224, DOI 10.1016/j.compmedimag.2007.02.009; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Shamsheyeva A, 2004, P SOC PHOTO-OPT INS, V5370, P1548, DOI 10.1117/12.534877; SHAMSHEYEVA A, 2006, P 2004 INT SENS SENS; Shyu CR, 1999, COMPUT VIS IMAGE UND, V75, P111, DOI 10.1006/cviu.1999.0768; STARK P, 2007, UPTODATE         SEP; Tourassi GD, 1999, RADIOLOGY, V213, P317; UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936; Uppaluri R, 1999, AM J RESP CRIT CARE, V160, P648; van der Walt C., 2006, P 16 ANN S PATT REC, P166; Van De Ville D, 2005, IEEE T IMAGE PROCESS, V14, P1798, DOI 10.1109/TIP.2005.857249; Vapnik V, 1999, NATURE STAT LEARNING; Witten I., 2005, MORGAN KAUFMANN SERI; Wong JSJ, 2006, LECT NOTES COMPUT SC, V4304, P233; ZAVALETTA V, 2007, SPIE MED IMAGING; Zrimec T, 2007, ST HEAL T, V129, P1324	35	1	1	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	978-0-8194-7103-1	PROC SPIE			2008	6919								69190C	10.1117/12.769190		12	Engineering, Biomedical; Optics; Imaging Science & Photographic Technology; Physiology; Radiology, Nuclear Medicine & Medical Imaging	Engineering; Optics; Imaging Science & Photographic Technology; Physiology; Radiology, Nuclear Medicine & Medical Imaging	BHU33	WOS:000256422200010	
S	Cruz, B; Barron, R; Sossa, H		Gelbukh, A; Morales, EF		Cruz, Benjamin; Barron, Ricardo; Sossa, Humberto			Pattern Classification Based on Conformal Geometric Algebra and Optimization Techniques	MICAI 2008: ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	7th Mexican International Conference on Artificial Intelligence (MICAI 2008)	OCT 27-31, 2008	Atizapan de Zaragoza, MEXICO	Mexican Soc Artificial Intelligence, Tecnol Monterrey, Campus Estado Mexico		Conformal Geometric Algebra; Pattern Classification; Optimization		Conformal Geometric Algebra (CGA) is a high level language commonly used in mathematical, physics and engineering problems. At a top level, CGA is a free coordinate tool for designing and modeling geometric problems; at a low level CGA provides a new coordinate framework for numeric processing in problem solving. In this paper we show how to use quadratic programming and CGA for, given two sets p and g of points in R(n), construct an optimal separation sphere S such that, all points of p are contained inside of it, and all points of g are outside. To classify an unknown pattern x, an inner product must be applied between x and S. Some numerical and real examples to test the proposal are given.	[Cruz, Benjamin; Barron, Ricardo; Sossa, Humberto] IPN, Ctr Invest Computac, Mexico City 07738, DF, Mexico	Cruz, B (reprint author), IPN, Ctr Invest Computac, Av Juan Dios Batiz, Mexico City 07738, DF, Mexico.	benjamincruz@sagitario.cic.ipn.mx; rbarron@cic.ipn.mx; hsossa@cic.ipn.mx					BARRON R, 2008, AGACSE IN PRESS; BARRON R, 2006, RES COMPUTING SCI, V21, P49; Clifford W., 1878, AM J MATH, V1, P350; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DORST L, 2005, 3D EUCLIDEAN GEOMETR; Hestenes D., 1984, CLIFFORD ALGEBRA GEO; HILDEBRAND D, 2005, GEOMETRIC COMPUTING; HILDEBRAND D, 2004, EUROGRAPHICS 2004 TU; PERWASS C, 2003, 0310 CHRIST ALBR U K	9	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-88635-8	LECT NOTES ARTIF INT			2008	5317						273	283				11	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BIQ13	WOS:000261873400026	
S	Potamitis, I; Ganchev, T		Tsihrintzis, GA; Jain, LC		Potamitis, Ilyas; Ganchev, Todor			Generalized Recognition of Sound Events: Approaches and Applications	MULTIMEDIA SERVICES IN INTELLIGENT ENVIRONMENTS: ADVANCED TOOLS AND METHODOLOGIES	Studies in Computational Intelligence		English	Article; Book Chapter							INDEPENDENT SPEAKER IDENTIFICATION; AUTOMATIC SPEECH RECOGNITION; MULTIPLE CLASSIFIER SYSTEMS; ACOUSTIC-EMISSION; TOOL WEAR; NEURAL-NETWORKS; TIME; REPRESENTATIONS; SENSOR; MODEL	This chapter surveys the contemporary approaches of automatic sound recognition and discusses the benefits stemming from real-world applications of this technology. We identify the common aspects and subtle differences among these diverse application areas and review state-of-the-art systems. hi this context; we project that; there is much space for knowledge transfer between the different subfields of sound classification; which seem to evolve independently while achieving different states of maturity. Particular emphasis is given to lessons learned from the speech recognition paradigm, which together with speaker recognition were among the first applications of sound classification that; reached the status of launching commercial products at a large climax. Special attention is paid to new emerging applications such as environmental monitoring and bioacoustic identification and applications to music which have already started altering our everyday life as we, once knew it.	[Potamitis, Ilyas] Technol Educ Inst Crete, Dept Mus Technol & Acoust, Iraklion, Greece; [Ganchev, Todor] Univ Patras, Dept Elect & Comp Engn, GR-26110 Patras, Greece	Potamitis, I (reprint author), Technol Educ Inst Crete, Dept Mus Technol & Acoust, Iraklion, Greece.	potamitis@stef.teicrete.gr; tganchev@wcl.ee.upatras.gr					Abe S., 2005, SUPPORT VECTOR MACHI; ALEXANDER RICHARD D., 1957, OHIO JOUR SCI, V57, P101; Alkoot F.M., 1999, PATTERN RECOGN, V20, P11; ALLAMANCHE E, 2001, P INT C MUS INF RETR; ARRIGONI JE, 2003, THESIS, P21; Ashiya T., 1996, Transactions of the Institute of Electrical Engineers of Japan, Part C, V116-C; AUCKLAND DW, 1995, P IEEE 5 INT C COND, P590, DOI 10.1109/ICSD.1995.523055; Barry Samantha J, 2006, Cough, V2, P8, DOI 10.1186/1745-9974-2-8; BATTLE E, 1998, P INT C SPOK LANG PR, P951; BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147; Bayes T., 1763, PHILOS T ROY SOC LON, V53, P370, DOI DOI 10.1098/RSBL.1763.0053; BENGIO S, 2001, 0040 IDIAP; Bengio Y, 1996, IEEE T NEURAL NETWOR, V7, P1231, DOI 10.1109/72.536317; Bennet-Clark HC, 1999, J EXP BIOL, V202, P3347; Benyassine A, 1997, IEEE COMMUN MAG, V35, P64, DOI 10.1109/35.620527; BERENZWEIG A, 2003, P 2003 IEEE INT C MU, V1, P29; Bishop C. M., 2006, PATTERN RECOGNITION; BOLAT B, 2006, LECT NOTES COMPUTER, V4105; Bourlard H., 1994, CONNECTIONIST SPEECH; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Brown JC, 2001, J ACOUST SOC AM, V109, P1064, DOI 10.1121/1.1342075; Cain B.J., 1990, P SPIE APPL ART NEUR, P354; Carolan TA, 1997, P I MECH ENG B-J ENG, V211, P299, DOI 10.1243/0954405971516275; Casey M., 2001, P WORKSH CONS REL AC; Casey M, 2001, IEEE T CIRC SYST VID, V11, P737, DOI 10.1109/76.927433; Casey M., 2001, ORG SOUND, V6, P153; Chen L, 2006, IEEE INT C MULT EXP, P781; Chesmore ED, 2001, APPL ACOUST, V62, P1359, DOI 10.1016/S0003-682X(01)00009-3; Cho YD, 2001, IEEE SIGNAL PROC LET, V8, P276; CHOLLET G, 1994, FUNDAMENTALS SPEECH, P129; CHORDIA P, 2005, P 6 INT C MUS INF RE; CHU S, 2006, P AAAI 2006 FALL S A; Chu S., 2006, P ICME 06, P885; Clarkson B., 1998, P WORKSH PERC US INT; Coath M, 2005, BIOL CYBERN, V93, P22, DOI 10.1007/s00422-005-0560-4; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cowling M, 2003, PATTERN RECOGN LETT, V24, P2895, DOI 10.1016/S0167-8655(03)00147-8; DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420; Deng L., 2003, SPEECH PROCESSING DY; DIEI EN, 1987, J ENG IND-T ASME, V109, P234; DIETRICH C, 2004, THESIS U ULM; DIETTERICH T, 1998, MACH LEARN, P1; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Dimla DE, 1997, INT J MACH TOOL MANU, V37, P1219, DOI 10.1016/S0890-6955(97)00020-5; DINIZ AE, 1992, WEAR, V152, P395, DOI 10.1016/0043-1648(92)90135-U; DORNFELD DA, 1985, J ACOUST EMISSOIN, V4, P123; DROSOPOULOS S, 2005, CONT TOPICS ENTOMOLO; DUFAUX A, 2000, P EUSIPCO 2000 TAMP; Eggink J., 2004, P ICASSP, V4, P217; Eggink J., 2003, P ICASSP, P553; Eisele T., 1996, Proceedings ICSLP 96. Fourth International Conference on Spoken Language Processing (Cat. No.96TH8206), DOI 10.1109/ICSLP.1996.607092; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1016/0364-0213(90)90002-E; Eronen A, 2003, P 7 INT S SIGN PROC, P133; ERONEN A, 2000, P IEEE INT C AC SPEE, P753; Eronen A. J., 2006, IEEE T AUDIO SPEECH, V14; ESSID S, 2004, P AES 25 INT C LOND; ESSID S, 2006, SEM CNRS LTCI; Fisher RA, 1936, ANN EUGENIC, V7, P179; FitzGerald D., 2002, P INT C DIG AUD EFF, P65; FURUI S, 1996, SURVEY STATE ART HUM; Ganchev T., 2003, P EUROSPEECH, P1673; GANCHEV T, 2002, P 14 INT C DSP JUL, V2, P1081; GANCHEV T, 2004, P ICASSP 2004, V1, P41; Ganchev TD, 2007, NEUROCOMPUTING, V70, P1424, DOI 10.1016/j.neucom.2006.05.012; Garces M, 2003, GEOPHYS RES LETT, V30, DOI 10.1029/2003GL018614; Gaston KJ, 2004, PHILOS T ROY SOC B, V359, P655, DOI 10.1098/rstb.2003.1442; GavidiaCeballos L, 1996, IEEE T BIO-MED ENG, V43, P373, DOI 10.1109/10.486257; GELLERSEN HW, 2005, P 3 IEEE WORKSH MOB, P3; Gish H, 1994, IEEE SIGNAL PROC MAG, V11, P18, DOI 10.1109/79.317924; Goldhor R.S., 1993, P ICASSP NEW YORK NY, V1, P149; GOPALAN K, 1999, IEEE PAC RIM C COMM, P388; GOUYON F, 2004, P AES 25 INT C LOND; GUO X, 2006, J BIOMEDICAL ENG, V23; Guo YB, 2005, INT J MACH TOOL MANU, V45, P1622, DOI 10.1016/j.ijmachtools.2005.02.007; HAEBUMBACH R, 1992, P ICASSP 92, P113; HANSEN JHL, 1995, P ICASSP 95, P836; Hansen JHL, 1998, IEEE T BIO-MED ENG, V45, P300, DOI 10.1109/10.661155; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; HANSEN LP, 1982, ECONOMETRICA, V50, P1029, DOI 10.2307/1912775; HARLOW C, 2002, J INTELL TRANSPORT S, V7, P43, DOI 10.1080/713930746; Hartigan J. A., 1979, Applied Statistics, V28, DOI 10.2307/2346830; HELWEG DA, 2002, BIOACOUSTICS, V13, P96; Hennig RM, 2003, J COMP PHYSIOL A, V189, P589, DOI 10.1007/s00359-003-0438-7; HERRERA P, 2003, NEW MUSIC RES, V32; HERRERA P, 2002, P 2 INT C MUS ART IN; Hinton GE, 1998, NATO ADV SCI I D-BEH, V89, P479; HOGE H, 1999, P EUROSPEECH 99 BUDA, V6, P2699; HONG L, 2004, P EUSIPCO 2004 VIENN; Inasaki I, 1998, ULTRASONICS, V36, P273, DOI 10.1016/S0041-624X(97)00052-8; IRINO T, 1999, P EUR 99 BUD HUNG, P1899; IWATA K, 1977, ANN CIRP, V26, P21; Jordan M. I., 1986, 8604 U CAL I COGN SC; JORDAN MI, 2001, NEURAL COMPUT, P181; Kannatey-Asibu Jr E., 1981, T ASME, V103, P330; Kepesi M, 2006, SPEECH COMMUN, V48, P474, DOI 10.1016/j.specom.2005.08.004; Kim HG, 2004, IEEE T CIRC SYST VID, V14, P716, DOI 10.1109/TCSVT.2004.826766; KIM HG, 2004, P IEEE INT C AC SPEE, V5, P925; Kittler J, 2003, IEEE T PATTERN ANAL, V25, P110, DOI 10.1109/TPAMI.2003.1159950; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Klapuri A., 2006, SIGNAL PROCESSING ME; Kohonen T, 1986, TKKFA601 HELS U TECH; KRAFT F, 2005, P INT 05 LISB PORT; Kwon OW, 2003, P EUROSPEECH, P125; Lang K.J., 1988, CMUCS88152; Lee CH, 2006, PATTERN RECOGN LETT, V27, P93, DOI 10.1016/j.patrec.2005.07.004; LEE TW, 2001, P 2001 IEEE INT C, V1, P105; LI Y, 2004, P IEEE INT C AC SPEE, V5, P897; LIN CC, 2005, IEEE T SPEECH AUD PR, V13; Lister P.M., 1986, P 26 INT MACH TOOL D, P271; Liu M., 2001, P 1 ACM IEEE CS JOIN, P247, DOI 10.1145/379437.379663; LIU MC, 2001, IEEE INT DAT ENG APP, P339; LIVSHIN AA, 2004, P DAFX 04 NAPL IT OC; Martin K. D., 1999, THESIS MIT; McLachlan G., 1997, WILEY SERIES PROBABI; Meisel W, 1972, COMPUTER ORIENTED AP; Mitrovic D, 2006, P IEEE MULT MOD C BE, P339; MOSSING JC, 1996, P 1996 IEEE INT C AC, V5, P2758; MUSAVI M, 1992, P IEEE INT JOINT C N, V1, P595, DOI 10.1109/IJCNN.1992.287147; MUTHUSAMY YK, 1994, IEEE SIGNAL PROC OCT, P33; Neto J., 1995, P EUROSPEECH 1995, P2171; Oba Teruyo, 2004, An Acad Bras Cienc, V76, P446, DOI 10.1590/S0001-37652004000200039; Pai Srinivasa P., 2002, INT J PROD RES, V40, P1081; PEETERS G, 2000, P INT C MUS COMP ICM; PEETERS G, 2003, P AES 115 CONV NEW Y; PEETERS G, 2002, P ICMC 02 GOT SWED S; Peltonen V, 2002, P IEEE INT C AC SPEE, V2, P1941; POTAMITIS I, 2007, P ISSPA 07 FEBR; POTAMITIS J, 2006, P INT ICSLP 06 PITTS; Powell MJD, 1987, ALGORITHMS APPROXIMA, P143; PURAT M, 1996, P IEEE INT C ASSP MA, V2, P1021; Quackenbush S, 2001, IEEE T CIRC SYST VID, V11, P725, DOI 10.1109/76.927430; RAVINDRAN S, 2005, IEEE INT S CIRC SYST, V2, P860; REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; SAMPATH A, 1987, INT J PROD RES, V25, P703, DOI 10.1080/00207548708919872; Saul LK, 2000, IEEE T SPEECH AUDI P, V8, P115, DOI 10.1109/89.824696; SETLUR AR, 1996, P INT C SPOK LANG PR, V2, P602, DOI 10.1109/ICSLP.1996.607433; SITTE R, 2007, P SPPRA 2007 INNSBR; Skowronski MD, 2006, J ACOUST SOC AM, V119, P1817, DOI 10.1121/1.2166948; Slaney M., 2002, P IEEE INT C MULT EX, V1, P345; SOHU J, 1999, IEEE SIGNAL PROCESSI, V6, P1; SPECHT DF, 1967, IEEE TRANS ELECTRON, VEC16, P308, DOI 10.1109/PGEC.1967.264666; Specht D.F., 1988, P IEEE INT C NEURAL, V1, P525; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; Temko A, 2006, PATTERN RECOGN, V39, P682, DOI 10.1016/j.patcog.2005.11.005; TOKUHIRA M, 1999, P EUR 99, V1, P359; TOYADA Y, 2004, P 2 IASTED INT C NEU, P169; TZANETAKIS C, 2001, P WSES INT C AC MUS; Tzanetakis G., 2002, IEEE T SPEECH AUDIO, V10; Vapnik V.N., 1995, NATURE STAT LEARNING; VEMURI S, 2004, P 6 INT C UB COMP, P400; WATSON AT, 2003, SYSTEMATICS BIODIVER, V1; WIDMER G, 2006, MACHINE LEARNING, V65; WOLD T, 1996, P IEEE MULTIMEDIA, V3, P2736; Wolfe PJ, 2004, J ROY STAT SOC B, V66, P575, DOI 10.1111/j.1467-9868.2004.02052.x; XIONG Z, 2003, P ICME, V3, P397; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943; YELLA S, 2006, P ICMLA 06, P3; Yella S., 2006, P AISC 2006 PALM DE, P144; ZERVAS P, 2007, INT J ARTIFICIAL INT; ZUE V, 1997, SURVEY STATE ART HUM, P4	161	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1860-949X	978-3-540-78491-3	STUD COMPUT INTELL			2008	120						41	79			10.1007/978-3-540-78502-6	39	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Telecommunications	Computer Science; Telecommunications	BJL78	WOS:000266772900003	
J	Castellana, L; Biagi, PF				Castellana, L.; Biagi, P. F.			Detection of hydrogeochemical seismic precursors by a statistical learning model	NATURAL HAZARDS AND EARTH SYSTEM SCIENCES			English	Article							OUT PREDICTION ERROR; STRONG EARTHQUAKES; KAMCHATKA RUSSIA; SUPPORT VECTOR; TIME-SERIES; CLASSIFICATION; MACHINES; CANNOT; SIZE	The problem of detecting the occurrence of an earthquake precursor is faced in the general framework of the statistical learning theory. The aim of this work is both to build models able to detect seismic precursors from time series of different geochemical signals and to provide an estimate of number of false positives. The model we used is k-Nearest-Neighbor classifier for discriminating "no-disturbed signal", "seismic precursor" and "co-post seismic precursor" in time series relative to thirteen different hydrogeochemical parameters collected in water samples from a natural spring in Kamchachta (Russia) peninsula. The measurements collected are ion content (Na, Cl, Ca, HCO(3), H(3)BO(3)), parameters (pH, Q, T) and gases (N(2), CO(2), CH(4), O(2), Ag). The classification error is measured by Leave-K-Out-Cross-Validation procedure. Our study shows that the most discriminative ions for detecting seismic precursors are Cl and Na having an error rates of 15%. Moreover, the most discriminative parameters and gases are Q and CH(4) respectively, with error rate of 21%. The ions result the most informative hydrogeochemicals for detecting seismic precursors due to the peculiarities of the mechanisms involved in earthquake preparation. Finally we show that the information collected some month before the event under analysis are necessary to improve the classification accuracy.	[Castellana, L.; Biagi, P. F.] Univ Bari, Dept Phys, I-70126 Bari, Italy	Biagi, PF (reprint author), Univ Bari, Dept Phys, Via Amendola 173, I-70126 Bari, Italy.	biagi@fisica.uniba.it					Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Ancona N, 2006, PHYSICA A, V365, P491, DOI 10.1016/j.physa.2005.09.065; Ancona N, 2005, PHYSIOL MEAS, V26, P363, DOI 10.1088/0967-3334/26/4/003; Ancona N, 2003, IMAGE VISION COMPUT, V21, P675, DOI 10.1016/S0262-8856(03)00063-5; Ancona N, 2006, BMC Bioinformatics, V7, P387, DOI 10.1186/1471-2105-7-387; Biagi P. F., 2001, NAT HAZARD EARTH SYS, V1, P9, DOI [10.5194/nhess-l-9-2001, DOI 10.5194/NHESS-1-9-2001]; Biagi PF, 2006, NAT HAZARD EARTH SYS, V6, P853; Biagi PF, 2000, PURE APPL GEOPHYS, V157, P1359, DOI 10.1007/PL00001123; Biagi PF, 2000, NAT HAZARDS, V21, P263, DOI 10.1023/A:1008178104003; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devroye L, 1996, PROBABILISTIC THEORY; Distante C, 2003, SENSOR ACTUAT B-CHEM, V88, P30, DOI 10.1016/S0925-4005(02)00306-4; DOBROVOLSKY IP, 1979, PURE APPL GEOPHYS, V117, P1025, DOI 10.1007/BF00876083; Duda R.O., 2000, PATTERN CLASSIFICATI; Geller RJ, 1997, SCIENCE, V275, P1616, DOI 10.1126/science.275.5306.1616; Guangcai Wang, 2005, Ground Water, V43, P478, DOI 10.1111/j.1745-6584.2005.0037.x; Hattori K, 2004, PHYS CHEM EARTH, V29, P481, DOI 10.1016/j.pce.2003.09.019; Kingsley SP, 2001, PHYS CHEM EARTH PT C, V26, P769, DOI 10.1016/S1464-1917(01)95023-8; Luntz A, 1969, TECHNICHESKAYA KIBER, V3, P563; Molchanov O. A., 2003, NAT HAZARD EARTH SYS, V3, P203, DOI DOI 10.5194/NHESS-3-203-2003; Mukherjee S, 2003, J COMPUT BIOL, V10, P119, DOI 10.1089/106652703321825928; Rozhnoi A, 2004, PHYS CHEM EARTH, V29, P589, DOI 10.1016/j.pce.2003.08.061; Stephenson RA, 2003, SEDIMENT GEOL, V156, P59, DOI 10.1016/S0037-0738(02)00282-8; Telesca L, 2005, NAT HAZARDS, V34, P177, DOI 10.1007/s11069-004-0687-y; Tibshirani R., 2001, ELEMENTS STAT LEARNI; Toutain JP, 1999, TECTONOPHYSICS, V304, P1, DOI 10.1016/S0040-1951(98)00295-9; Vapnik V.N., 1998, STAT LEARNING THEORY; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; VOROBIEVA IA, 1993, PURE APPL GEOPHYS, V141, P25, DOI 10.1007/BF00876232; Wyss M, 1997, SCIENCE, V278, P487, DOI 10.1126/science.278.5337.487	30	0	0	COPERNICUS PUBLICATIONS	KATHLENBURG-LINDAU	MAX-PLANCK-STR 13, KATHLENBURG-LINDAU, 37191, GERMANY	1561-8633		NAT HAZARD EARTH SYS	Nat. Hazards Earth Syst. Sci.		2008	8	6					1207	1216				10	Geosciences, Multidisciplinary; Meteorology & Atmospheric Sciences; Water Resources	Geology; Meteorology & Atmospheric Sciences; Water Resources	407RF	WOS:000263381300001	
J	Chou, KC; Shen, HB				Chou, Kuo-Chen; Shen, Hong-Bin			Cell-PLoc: a package of Web servers for predicting subcellular localization of proteins in various organisms	NATURE PROTOCOLS			English	Article							AMINO-ACID-COMPOSITION; SUPPORT VECTOR MACHINE; FUNCTIONAL DOMAIN COMPOSITION; STRUCTURAL CLASS PREDICTION; GRAM-NEGATIVE BACTERIA; LOCATION PREDICTION; SIGNAL PEPTIDES; ENSEMBLE CLASSIFIER; GENE ONTOLOGY; HYPOTHETICAL PROTEINS	Information on subcellular localization of proteins is important to molecular cell biology, proteomics, system biology and drug discovery. To provide the vast majority of experimental scientists with a user-friendly tool in these areas, we present a package of Web servers developed recently by hybridizing the 'higher level' approach with the ab initio approach. The package is called Cell-PLoc and contains the following six predictors: Euk-mPLoc, Hum-mPLoc, Plant-PLoc, Gpos-PLoc, Gneg-PLoc and Virus-PLoc, specialized for eukaryotic, human, plant, Gram-positive bacterial, Gram-negative bacterial and viral proteins, respectively. Using these Web servers, one can easily get the desired prediction results with a high expected accuracy, as demonstrated by a series of cross-validation tests on the benchmark data sets that covered up to 22 subcellular location sites and in which none of the proteins included had >= 25% sequence identity to any other protein in the same subcellular-location subset. Some of these Web servers can be particularly used to deal with multiplex proteins as well, which may simultaneously exist at, or move between, two or more different subcellular locations. Proteins with multiple locations or dynamic features of this kind are particularly interesting, because they may have some special biological functions intriguing to investigators in both basic research and drug discovery. This protocol is a step-by-step guide on how to use the Web-server predictors in the Cell-PLoc package. The computational time for each prediction is less than 5 s in most cases. The Cell-PLoc package is freely accessible at http://chou.med.harvard.edu/bioinf/Cell-PLoc.	[Chou, Kuo-Chen] Gordon Life Sci Inst, San Diego, CA 92130 USA; [Shen, Hong-Bin] Harvard Univ, Sch Med, Dept Biol Chem & Mol Pharmacol, Boston, MA 02115 USA	Chou, KC (reprint author), Gordon Life Sci Inst, 13784 Torrey Mar Dr, San Diego, CA 92130 USA.	kcchou@gordonlifescience.org; hbshen@crystal.harvard.edu	Chou, Kuo-Chen/A-8340-2009				Afjehi-Sadat L, 2007, J PROTEOME RES, V6, P711, DOI 10.1021/pr060453o; ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Apweiler R, 2001, NUCLEIC ACIDS RES, V29, P37, DOI 10.1093/nar/29.1.37; Ashburner M, 2000, NAT GENET, V25, P25; Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P31, DOI 10.1093/nar/25.1.31; Becker HF, 1997, NUCLEIC ACIDS RES, V25, P4493, DOI 10.1093/nar/25.22.4493; Bendtsen JD, 2004, J MOL BIOL, V340, P783, DOI 10.1016/j.jmb.2004.05.028; Cao YF, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-20; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; Chen C, 2006, ANAL BIOCHEM, V357, P116, DOI 10.1016/j.ab.2006.07.022; Chen C, 2006, J THEOR BIOL, V243, P444, DOI 10.1016/j.jtbi.2006.06.025; Chen YL, 2007, J THEOR BIOL, V245, P775, DOI 10.1016/j.jtbi.2006.11.010; Chen YL, 2007, J THEOR BIOL, V248, P377, DOI 10.1016/j.jtbi.2007.05.019; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2006, J PROTEOME RES, V5, P3420, DOI 10.1021/pr060404b; Chou KC, 2007, ANAL BIOCHEM, V370, P1, DOI 10.1016/j.ab.2007.07.006; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; Chou KC, 2007, J CELL BIOCHEM, V100, P665, DOI 10.1002/jcb.21096; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2006, J PROTEOME RES, V5, P1888, DOI 10.1021/pr060167c; Chou KC, 2007, BIOCHEM BIOPH RES CO, V357, P633, DOI 10.1016/j.bbrc.2007.03.162; Chou KC, 2004, CURR MED CHEM, V11, P2105; Chou KC, 2004, BIOCHEM BIOPH RES CO, V320, P1236, DOI 10.1016/j.bbrc.2004.06.073; Chou KC, 2006, J CELL BIOCHEM, V99, P517, DOI 10.1002/jcb.20879; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; Chou KC, 2007, BIOCHEM BIOPH RES CO, V360, P339, DOI 10.1016/j.bbrc.2007.06.027; Chou KC, 2007, J PROTEOME RES, V6, P1728, DOI 10.1021/pr060635i; Chou KC, 2006, BIOCHEM BIOPH RES CO, V347, P150, DOI 10.1016/j.bbrc.2006.06.059; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; DIAO Y, 2007, AMINO ACIDS; Du PF, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-518; Ehrlich JS, 2002, DEV CELL, V3, P259, DOI 10.1016/S1534-5807(02)00216-2; Emanuelsson O, 2000, J MOL BIOL, V300, P1005, DOI 10.1006/jmbi.2000.3903; Emanuelsson O, 2007, NAT PROTOC, V2, P953, DOI 10.1038/nprot.2007.131; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; Feng Zhi-Ping, 2002, In Silico Biology, V2, P291; Feng ZP, 2001, INT J BIOL MACROMOL, V28, P255, DOI 10.1016/S0141-8130(01)00121-0; Gao QB, 2006, PROTEIN ENG DES SEL, V19, P511, DOI 10.1093/protein/gzl038; Gao QB, 2005, FEBS LETT, V579, P3444, DOI 10.1016/j.febslet.2005.05.021; Gardy JL, 2003, NUCLEIC ACIDS RES, V31, P3613, DOI 10.1093/nar/gkg602; Garg A, 2005, J BIOL CHEM, V280, P14427, DOI 10.1074/jbc.M411789200; GEIER C, 1989, EUR J BIOCHEM, V183, P611, DOI 10.1111/j.1432-1033.1989.tb21090.x; Glory E, 2007, DEV CELL, V12, P7, DOI 10.1016/j.devcel.2006.12.007; Guo J, 2006, PROTEOMICS, V6, P5099, DOI 10.1002/pmic.200600064; Hill DP, 2002, GENOME RES, V12, P1982, DOI 10.1101/gr.580102; Hiller K, 2004, NUCLEIC ACIDS RES, V32, pW375, DOI 10.1093/nar/gkh378; Ho VSM, 2007, PROTEIN PEPTIDE LETT, V14, P828; Hoglund A, 2006, BIOINFORMATICS, V22, P1158, DOI 10.1093/bioinformatics/btl002; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Huang Y, 2004, BIOINFORMATICS, V20, P21, DOI 10.1093/bioinformatics/btg366; Jackson S, 2006, PLANT CELL, V18, P1100, DOI 10.1105/tpc.106.042192; Jahandideh S, 2007, BIOPHYS CHEM, V128, P87, DOI 10.1016/j.bpc.2007.03.006; Jorgensen R, 2006, PLANT CELL, V18, P1099, DOI 10.1105/tpc.106.180580; Kedarisetti KD, 2006, BIOCHEM BIOPH RES CO, V348, P981, DOI 10.1016/j.bbrc.2006.07.141; Kurgan LA, 2007, J THEOR BIOL, V248, P354, DOI 10.1016/j.jtbi.2007.05.017; Lee K, 2006, NUCLEIC ACIDS RES, V34, P4655, DOI 10.1093/nar/gkl638; Lei ZD, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-291; Lin H, 2007, BIOCHEM BIOPH RES CO, V354, P548, DOI 10.1016/j.bbrc.2007.01.011; Lin H, 2007, J COMPUT CHEM, V28, P1463, DOI 10.1002/jcc.20554; Lubec G, 2007, CHEM REV, V107, P3568, DOI 10.1021/cr068213f; Lubec G, 2005, PROG NEUROBIOL, V77, P90, DOI 10.1016/j.pneurobio.2005.10.001; Matsuda S, 2005, PROTEIN SCI, V14, P2804, DOI 10.1110/ps.051597405; Mondal S, 2006, J THEOR BIOL, V243, P252, DOI 10.1016/j.jtbi.2006.06.014; Mundra P, 2007, PATTERN RECOGN LETT, V28, P1610, DOI 10.1016/j.patrec.2007.04.001; Murphy R F, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P251; Nair R, 2002, PROTEIN SCI, V11, P2836, DOI 10.1110/ps.0207402; NAKAI K, 1992, GENOMICS, V14, P897, DOI 10.1016/S0888-7543(05)80111-9; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; Park KJ, 2003, BIOINFORMATICS, V19, P1656, DOI 10.1093/bioinformatics/btg222; Pierleoni A, 2006, BIOINFORMATICS, V22, pE408, DOI 10.1093/bioinformatics/btl222; Pu Xian, 2007, J Theor Biol, V247, P259, DOI 10.1016/j.jtbi.2007.01.016; Regev-Rudzki N, 2007, BIOESSAYS, V29, P772, DOI 10.1002/bies.20609; Reinhardt A, 1998, NUCLEIC ACIDS RES, V26, P2230, DOI 10.1093/nar/26.9.2230; Shen HB, 2007, BIOPOLYMERS, V85, P233, DOI 10.1002/bip.20640; Shen HB, 2007, BIOCHEM BIOPH RES CO, V363, P297, DOI 10.1016/j.bbrc.2007.08.140; Shen HB, 2007, BIOCHEM BIOPH RES CO, V355, P1006, DOI 10.1016/j.bbrc.2007.02.071; Shen HB, 2007, PROTEIN ENG DES SEL, V20, P39, DOI 10.1093/protein-gzl053; Shen HB, 2007, BIOCHEM BIOPH RES CO, V364, P53, DOI 10.1016/j.bbrc.2007.09.098; SHEN HB, 2007, ANAL BIOCH; Shi JY, 2007, AMINO ACIDS, V33, P69, DOI 10.1007/s00726-006-0475-y; VAPNIK VN, 1998, STAT LEAMING THEORY; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Xiao ZJ, 2006, LEUKEMIA RES, V30, P54, DOI 10.1016/j.leukres.2005.05.012; Yuan Z, 1999, FEBS LETT, V451, P23, DOI 10.1016/S0014-5793(99)00506-2; Zhang SW, 2006, AMINO ACIDS, V30, P461, DOI 10.1007/s00726-006-0263-8; Zhang ZH, 2006, FEBS LETT, V580, P6169, DOI 10.1016/j.febslet.2006.10.017; Zhou GP, 2006, PROTEINS, V63, P681, DOI 10.1002/prot.20898; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou XB, 2007, J THEOR BIOL, V248, P546, DOI 10.1016/j.jtbi.2007.06.001; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565	96	448	454	NATURE PUBLISHING GROUP	LONDON	MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	1754-2189		NAT PROTOC	Nat. Protoc.		2008	3	2					153	162		10.1038/nprot.2007.494		10	Biochemical Research Methods	Biochemistry & Molecular Biology	276JL	WOS:000254137000001	
S	Luo, HE; Sudibyo, Y; Miller, LD; Karuturi, RKM		Chetty, M; Ngom, A; Ahmad, S		Luo, Huaien; Sudibyo, Yuliansa; Miller, Lance D.; Karuturi, R. Krishna Murthy			Weighted Top Score Pair Method for Gene Selection and Classification	PATTERN RECOGNITION IN BIOINFORMATICS, PROCEEDINGS	LECTURE NOTES IN BIOINFORMATICS		English	Proceedings Paper	3rd IAPR International Conference on Pattern Recognition in Bioinformatics	OCT 15-17, 2008	Melbourne, AUSTRALIA	IAPR		Microarray; Gene selection; Classification; Weighted Top Score Pairs; Cross-validation	MICROARRAY DATA; EXPRESSION DATA; CANCER; TUMOR; PREDICTION; DIAGNOSIS; PATTERNS	Gene selection and expression profiles classification are important for diagnosing the disease using microarray technology and revealing the underlying biological processes. This paper proposes a weighted top scoring pair (WTSP) method which is a generalization of the current top scoring pair (TSP) method. By considering the proportions of samples from different classes, the WTSP method aims to minimize the error or misclassification rate. Results from several experimental microarray data have shown the improved performance of classification using the WTSP method.	[Luo, Huaien; Miller, Lance D.; Karuturi, R. Krishna Murthy] Genome Inst Singapore, Singapore, Singapore	Karuturi, RKM (reprint author), Genome Inst Singapore, Singapore, Singapore.						Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Bo TH, 2002, GENOME BIOL, V3; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dai JJ, 2006, STAT APPL GENET MOL, V5; Duda R.O., 2000, PATTERN CLASSIFICATI; Dudoit S, 2002, STAT SINICA, V12, P111; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; GEMAN D, 2004, STAT APPL GENET MOL, V3; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gordon GJ, 2002, CANCER RES, V62, P4963; Hanczar B, 2007, BIOINFORMATICS, V23, P2866, DOI 10.1093/bioinformatics/btm429; KARUTURI RKM, 2004, P 4 IEEE S BIOINF BI; KARUTURI RKM, 2006, P INT C DAT MIN DMIN; KUO WP, 2003, P AM MED INF ASS AMI; Miller LD, 2005, P NATL ACAD SCI USA, V102, P13550, DOI 10.1073/pnas.0506230102; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Price ND, 2007, P NATL ACAD SCI USA, V104, P3414, DOI 10.1073/pnas.0611373104; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Rapaport F., 2007, BMC BIOINFORMATICS, V8; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Stuart RO, 2004, P NATL ACAD SCI USA, V101, P615, DOI 10.1073/pnas.2536479100; Tan AC, 2005, BIOINFORMATICS, V21, P3896, DOI 10.1093/bioinformatics/bti631; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Xiong MM, 2000, BIOTECHNIQUES, V29, P1264; XU L, 2007, BMC BIOINFORMATICS, V8	26	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-88434-7	LECT N BIOINFORMAT			2008	5265						323	333				11	Biochemical Research Methods; Computer Science, Artificial Intelligence; Computer Science, Information Systems; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Computer Science; Mathematical & Computational Biology	BIL87	WOS:000260634000028	
B	Manouselis, N; Costopoulou, C		Uchyigit, G; Ma, MY		Manouselis, Nikos; Costopoulou, Constantina			Experimental Analysis of Multiattribute Utility Collaborative Filtering on a Synthetic Data Set	PERSONALIZATION TECHNIQUES AND RECOMMENDER SYSTEMS			English	Proceedings Paper	International Workshop on Web Personalization, Recommender Systems and Intelligent User Interfaces	OCT, 2005	Reading, ENGLAND				RECOMMENDER SYSTEMS; EMPIRICAL-ANALYSIS; ALGORITHMS; INFORMATION; SIMILARITY	Recommender systems have already been engaging multiple criteria for the production of recommendations. Such systems, referred to as multi-criteria recommenders, early demonstrated the potential of applying Multi-Criteria Decision Making (MCDM) methods to facilitate recommendation in numerous application domains. On the other hand, systematic implementation and testing of multi-criteria recommender systems in the context of real-life applications still remains rather limited. Previous studies dealing with the evaluation of recommender systems have outlined the importance of carrying out careful testing and parameterization of a recommender system, before it is actually deployed in a real setting. In this paper, the experimental analysis of several design options for three proposed multi-attribute utility collaborative filtering algorithms is presented. The data set used is synthetic, with multi-criteria evaluations that have been created using an appropriate simulation environment. This synthetic data set tries to mimic the evaluations that are expected to be collected from users in a particular application setting. The aim of the experiment is to demonstrate how a synthetic data set may be created and used to facilitate the study and selection of an appropriate recommendation algorithm, in the case that multi-criteria evaluations from real users are not available.	[Manouselis, Nikos; Costopoulou, Constantina] Agr Univ Athens, Div Informat Math & Stat, Informat Lab, Athens 11855, Greece	Manouselis, N (reprint author), Agr Univ Athens, Div Informat Math & Stat, Informat Lab, 75 Iera Odos Str, Athens 11855, Greece.	nikosm@ieee.org; tina@aua.gr					Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99; Adomavicius G, 2005, ACM T INFORM SYST, V23, P103, DOI 10.1145/1055709.1055714; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Bakos Y, 1998, COMMUN ACM, V41, P35, DOI 10.1145/280324.280330; Barnes S. J., 2002, J ELECTRON COMMER RE, V3, P114; Breese J, 1998, P 14 C UNC ART INT M; Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564; CARENINI G, 2005, P PERS WORKSH INT US; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DELGADO J, 1999, P ACM SIGIR 99 REC S; Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776; GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867; Guan S., 2002, ELECTRON COMMER R A, V1, P314, DOI 10.1016/S1567-4223(02)00023-6; Ha V, 2003, ARTIF INTELL, V146, P149, DOI 10.1016/S0004-3702(03)000134; Herlocker J, 2002, INFORM RETRIEVAL, V5, P287, DOI 10.1023/A:1020443909834; Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772; JACQUETLAGREZE E, 2001, EUR J OPER RES, V130; Keeney RL, 1992, VALUE FOCUSED THINKI; Konstan JA, 2004, ACM T INFORM SYST, V22, P1, DOI 10.1145/963770.963771; Lee WP, 2004, EXPERT SYST APPL, V27, P665, DOI 10.1016/j.eswa.2004.07.001; Liu DR, 2005, INFORM MANAGE-AMSTER, V42, P387, DOI 10.1016/j.im.2004.01.008; MANOUSELIS N, 2006, 181 TR AGR U ATH INF; MANOUSELIS N, 2006, ENG LETT SPECIAL ISS, V13; MANOUSELIS N, 2005, INFORM SERV USE, V25, P95; MARITZA L, 2004, P 2004 ACM S APPL CO; MASTHOFF J, 2003, LECT NOTES ARTIF INT, P258; Miller BN, 2004, ACM T INFORM SYST, V22, P437, DOI 10.1145/1010614.1010618; MONTANER M, 2004, P 6 INT C ENT INF SY, P303; NGUYEN H, 1998, P AAAI WORKSH REC SY; Papagelis M, 2005, ENG APPL ARTIF INTEL, V18, P781, DOI 10.1016/j.engappai.2005.06.010; PERNY P, 2001, INFORMATION INTERACT, V1, P9; PRICE B, 2005, P INF ANN MED M DENV; Resnick P, 1997, COMMUN ACM, V40, P56, DOI 10.1145/245108.245121; Riedl J., 1994, P ACM C COMP SUPP CO, P175, DOI 10.1145/192844.192905; Roy B., 1996, MULTICRITERIA METHOD; SARWAR B, 2000, P ACM EC 00 MINN MIN; SCHICKELZUBER V, 2005, P WORKSH KNOWL DISC; SCHMITT C, 2002, P ABIS WORKSH AD BEN; STOLZE M, 2003, P 2 WORLD C MASS CUS; Tewari G, 2003, DECIS SUPPORT SYST, V34, P127, DOI 10.1016/S0167-9236(02)00076-3; VINCKE P., 1992, MULTICRITERIA DECISI; Wolfinbarger M, 2003, J RETAILING, V79, P183, DOI 10.1016/S0022-4359(03)00034-4; YU K, 2001, P 2 INT WORKSH MAN I; Zeng C, 2004, INT J ELECTRON COMM, V8, P115	44	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	PO BOX 128 FARRER RD, SINGAPORE 9128, SINGAPORE		978-981-279-701-8				2008							111	134				24	Computer Science, Artificial Intelligence	Computer Science	BQS29	WOS:000281716200005	
S	Tran, HM; Schonwalder, J		Ho, TB; Zhou, ZH		Tran, Ha Manh; Schoenwaelder, Juergen			Fault Resolution in Case-Based Reasoning	PRICAI 2008: TRENDS IN ARTIFICIAL INTELLIGENCE	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	10th Pacific Rim International Conference on Artificial Intelligence (PRICAI 2008)	DEC 15-19, 2008	Hanoi, VIETNAM	Vietnamese Acad Sci & Technol, Minist Sci & Technol Vietnam, Hanoi Univ Technol, Vietnam Natl Univ, Air Force Off Sci Res, Asian Off Aerosp Res & Dev		Case-Based Reasoning; Probabilistic Reasoning; Fault Resolution; Fault Management	DERIVATIONAL ANALOGY	We present a study of reasoning methods in Case-Based Reasoning, which can be applied for the communication system fault domain. Inspired by the reasoning approach of the experts in medical diagnosis, we propose a probabilistic reasoning method which comprises two processes: a ranking process restricting the scope of a problem and a selection process finding promising solutions for the problem. We experimentally evaluate this method and draw lessons from the results to improve it.	[Tran, Ha Manh; Schoenwaelder, Juergen] Jacobs Univ Bremen, Bremen, Germany	Tran, HM (reprint author), Jacobs Univ Bremen, Bremen, Germany.	h.tran@jacobs-university.de; j.schoenwaelder@jacobs-university.de					AAMODT A, 1994, AI COMMUN, V7, P39; BAREISS R, 1989, BASED KNOWLEDGE ACQU; Berry MW, 1999, SIAM REV, V41, P335, DOI 10.1137/S0036144598347035; BLUMENTHAL B, 1994, ARTIF INTELL, V67, P287, DOI 10.1016/0004-3702(94)90055-8; CARBONELL JG, 1986, MACHINE LEARNING ART; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CUNNINGHAM P, 1994, P 1 EUR WORKSH CAS B, P234; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; DINGSOYR T, 1998, P AAAI WORKSH CAS BA; GOMES P, 2004, P 7 EUR C CAS BAS RE, P184; Heckerman D., 1994, MSRTR9407; KOTON PA, 1988, THESIS MIT; Lazkano E, 2003, LECT NOTES ARTIF INT, V2902, P171; Lewis L, 1993, P IFIP IEEE INT S IN, P671; MELCHIORS C, 1999, P 3 INT C CAS BAS RE, P510; Pearl J., 1988, PROBABILISTIC REASON, p[505, 506, 507, 524]; RODRIGUEZ AF, 1997, P 2 INT C CAS BAS RE, P623; SZOLOVITS P, 1978, ARTIF INTELL, V11, P115, DOI 10.1016/0004-3702(78)90014-0; TIRRI H, 1996, P 3 EUR WORKSH CAS B, P413; TRAN HM, 2007, P 1 INT C AUT INFR M, P200; TRAN HM, 2007, P 18 IFIP IEEE INT W, P50; TRAN HM, 2008, P 19 IFIP IEEE INT W, P55; VELOSO MM, 1993, MACH LEARN, V10, P249, DOI 10.1023/A:1022686910523; WINSTON PH, 1980, COMMUN ACM, V23, P689, DOI 10.1145/359038.359042; 2008, NETWORKING FORUM	25	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-89196-3	LECT NOTES ARTIF INT			2008	5351						417	429				13	Computer Science, Artificial Intelligence	Computer Science	BIT57	WOS:000262624600035	
B	Shen, HY; Li, T; Li, Z; Ching, FL			IEEE	Shen, Haiying; Li, Ting; Li, Ze; Ching, Felix			Locality sensitive hashing based searching scheme for a massive database	PROCEEDINGS IEEE SOUTHEASTCON 2008, VOLS 1 AND 2			English	Proceedings Paper	IEEE SoutheastCon 2008	APR 03-06, 2008	Huntsville, AL	IEEE			IMAGE	The rapid growth of information nowadays makes efficient information searching increasingly important for a massive database with tremendous volume of information. Traditional methods either rely on linear searching or depend on a tree structure. These methods search information in the entire database and compare a query with the records in the database during the searching process, which lead to inefficiency. This paper presents a locality sensitive hashing based searching scheme (LSS) to achieve highly efficient information searching in a massive database. LSS classifies information based on their similarities to facilitate fast information location. Based on the study and analysis of LSS, an improved scheme is further proposed to enhance the searching efficiency. Simulation results demonstrate the efficiency and effectiveness of the LSS schemes in searching information. They yield significant improvements over the efficiency of traditional methods. In addition, they guarantee successful location of the queried records.	[Shen, Haiying; Li, Ting; Li, Ze; Ching, Felix] Univ Arkansas, Dept Comp Sci & Comp Engn, Fayetteville, AR 72701 USA	Shen, HY (reprint author), Univ Arkansas, Dept Comp Sci & Comp Engn, Fayetteville, AR 72701 USA.	hshen@uark.edu; tx1005@uark.edu; zx1008@uark.edu; ching@uark.edu					Andoni A, 2005, E2LSH 0 1 USER MANUA; ARYA S, 1994, PROCEEDINGS OF THE FIFTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P573; Bentle J.L., 1977, ACM T MATH SOFTWARE, V3, P209; BRIN S., 1995, P 21 INT C VER LARG, P574; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Datar M., 2003, DIMACS WORKSH STREAM; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Devroye L., 1982, HDB STAT, V2; Fagin R., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, DOI 10.1145/275487.275488; FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146; Fu AW, 2000, VLDB J, V9, P154, DOI 10.1007/PL00010672; HU JJ, 2005, 6 INT C WAIM 2005 HA; Indyk P., 1998, P S THEOR COMP; NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173; PANIGRAHY R, 2006, NEAREST NEIGHBOR SEA; PENTLAND A, 1994, P SOC PHOTO-OPT INS, V2185, P34, DOI 10.1117/12.171786; RIJSBERGEN CJV, 1990, INFORM RETRIEVAL; SALTON G, 1989, READING; WHITE DA, 1996, VCL96101 U CAL; Wish M., 1978, MULTIDIMENSIONAL SCA; YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311; ZOLOTAREV VM, 1986, T MATH MONOGRAPHS, V65; LSH ALGORITHM IMPLEM; HAMMING DISTANCE; 2006, NSA HAS MASSIVE DATA	25	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-1883-1				2008							123	128				6	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BHW78	WOS:000257094700028	
B	Zhang, N; Wang, XZ; Xiao, T			IEEE	Zhang, Ning; Wang, Xi-Zhao; Xiao, Tao			An instance selection algorithm based on contribution	PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7			English	Proceedings Paper	7th International Conference on Machine Learning and Cybernetics	JUL 12-15, 2008	Kunming, PEOPLES R CHINA	Hebei Univ, IEEE Syst, Man & Cybernet Soc, Yunnan Univ, Machine Learning & Cybernet Res Inst		instance selection; nearest neighbor rule; condensed set; MCS; FCNN	NEAREST-NEIGHBOR RULE; CLASSIFICATION	This paper presents an approach to instance selection for the nearest neighbor rule which aims to obtain a condensed set with high condensing rate and prediction accuracy. By making an improvement on MCS algorithm and allowing certain error rate on the training set, a condensed set with high condensing rate and satisfying prediction accuracy is obtained. The condensed set is order-independent of the training instances and insensitive to noise. Comparative experiments have been conducted on real data sets, and the results show its superiority to MCS and FCNN in terms of condensing rate and prediction accuracy.	[Zhang, Ning; Wang, Xi-Zhao] Hebei Univ, Coll Math & Comp Sci, Key Lab Machine Learning & Computat Intelligence, Baoding 071002, Hebei, Peoples R China	Zhang, N (reprint author), Hebei Univ, Coll Math & Comp Sci, Key Lab Machine Learning & Computat Intelligence, Baoding 071002, Hebei, Peoples R China.						Angiulli F, 2007, IEEE T KNOWL DATA EN, V19, P1450, DOI 10.1109/TKDE.2007.190645; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; CANO JR, 2003, IEEE T EVOLUTIONARY, V7; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; JOSEFEDERICO, 2006, IEEE P 15 INT C COMP, P73; LI YG, 2005, IEEE INT C, V14, P950; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1023/A:1022661727670; Vicente C., 2001, IEEE T SYST MAN CY B, V31, P408; Zhang HB, 2002, PATTERN RECOGN, V35, P1481, DOI 10.1016/S0031-3203(01)00137-6	13	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-2095-7				2008							919	923				5	Computer Science, Cybernetics; Engineering, Electrical & Electronic; Robotics	Computer Science; Engineering; Robotics	BII01	WOS:000259604900168	
B	Lou, Z; Jin, Z; Zhao, XC		Gong, QY; Jiang, Y; Yao, DZ		Lou, Zhen; Jin, Zhong; Zhao, Xuecheng			Correlation-Based Local Mean Classifier For Pattern Recognition	PROCEEDINGS OF 2008 INTERNATIONAL PRE-OLYMPIC CONGRESS ON COMPUTER SCIENCE, VOL I: COMPUTER SCIENCE AND ENGINEERING			English	Proceedings Paper	International Pre-Olympic Congress on Computer Science	AUG 04-07, 2008	Nanjing, PEOPLES R CHINA			pattern recognition; local mean classifier; correlation coefficient	FACE RECOGNITION; NEAREST	There is a relatively recent interest in generalizing the representational capacity of available prototypes. In this paper, a correlation-based local mean classifier was proposed. Experiments were performed on UCI machine learning database and CENPAMI handwriting digit database. The proposed correlation-based local mean classifier was shown to be encouraging.	[Lou, Zhen; Jin, Zhong; Zhao, Xuecheng] Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Peoples R China	Zhao, XC (reprint author), Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Peoples R China.						Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fukunaga K., 1990, INTRO STAT PATTERN R; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; LIU CL, 1999, P 5 INT C DOC AN REC, V8, P378; Veenman CJ, 2005, IEEE T PATTERN ANAL, V27, P1417, DOI 10.1109/TPAMI.2005.187; Webb A., 2002, STAT PATTERN RECOGNI; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004	8	0	0	WORLD ACAD UNION-WORLD ACAD PRESS	LIVERPOOL	113, ACADEMIC HOUSE, MILL LANE, WAVERTREE TECHNOLOGY PARK, LIVERPOOL, L13 4 AH, ENGLAND		978-1-84626-051-3				2008							187	192				6	Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering	Computer Science	BII02	WOS:000259605200039	
B	Yang, J; Yang, JY; Jin, Z			IEEE	Yang, Jian; Yang, Jingyu; Jin, Zhong			New Concept for Discriminator Design: From Classifier to Discriminator	PROCEEDINGS OF THE 2008 CHINESE CONFERENCE ON PATTERN RECOGNITION (CCPR 2008)			English	Proceedings Paper	Chinese Conference one Pattern Recognition	DEC 22-24, 2008	Beijing, PEOPLES R CHINA	Chinese Assoc Automat, Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, CAA, Pattern Recognit & Machine Intelligence Comm, IEEE		Classification; classifier; feature extraction; discriminant analysis; dimensionality reduction; pattern recognition	PATTERN-CLASSIFICATION; FACE RECOGNITION	This paper introduces a new concept of designing a discriminant analysis method (discriminator), which starts from a local mean based nearest neighbor (LM-NN) classifier and uses its decision rule to direct the design of a discriminator. The derived discriminator, called local mean based nearest neighbor discriminator (LM-NND), matches the LM-NN classifier optimally in theory. The proposed LM-NND method is evaluated using the CENPARMI handwritten numeral database, the ETH80 object category database and the PolyU Palmprint database. The experimental results demonstrate the effectiveness of LM-NND and the LM-NN classifier based pattern recognition system.	[Yang, Jian; Yang, Jingyu; Jin, Zhong] Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Peoples R China	Yang, J (reprint author), Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Peoples R China.	csjyang@mail.njust.edu.cn; yangjy@mail.njust.edu.cn; zhongjin@mail.njust.edu.cn					Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Du H, 2007, PATTERN RECOGN, V40, P1486, DOI 10.1016/j.patcog.2006.10.021; Fukunaga K., 1990, INTRO STAT PATTERN R; He XF, 2005, IEEE T PATTERN ANAL, V27, P328; Leibe B., 2003, INT C COMP VIS PATT; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554; LOU Z, 2006, P 18 INT C PATT REC, V3, P87; Mika S., 1999, IEEE INT WORKSH NEUR, P41; Mitani Y, 2006, PATTERN RECOGN LETT, V27, P1151, DOI 10.1016/j.patrec.2005.12.016; Vincent P., 2002, ADV NEURAL INFORM PR; Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598; Yang J, 2007, IEEE T PATTERN ANAL, V29, P650, DOI 10.1109/TPAMI.2007.1008; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004	16	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-2316-3				2008							18	23				6	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	BJC58	WOS:000264749900004	
B	Zeng, Y; Wang, B; Zhao, L; Yang, YP		Cheng, D		Zeng Yong; Wang Bing; Zhao Liang; Yang Yupu			The Extended Nearest Neighbor Classification	Proceedings of the 27th Chinese Control Conference, Vol 4			English	Proceedings Paper	27th Chinese Control Conference	JUL 16-18, 2008	Kunming, PEOPLES R CHINA	Chinese Assoc Automat, Tech Comm Control Theory, Kunming Univ Sci & Technol, Yunnan Div, Chinese Assoc Automat, IEEE Control Syst Soc, Soc Instrument & Control Engineers Japan, Inst Control Robot & Syst Korea, IEEE Control Syst Soc, Singapore Chapter, CAS, Inst Syst Sci, Acad Math & Syst Sci, Yunnan Normal Univ, CAI Div, Hong Kong Inst Engineers		k-nearest neighbor classification rule (k-NNR); Local mean vector; Class mean vector	RULE	The k-nearest neighbor classification rule (k-NNR) is among the most popular and successful pattern classification techniques. However, it usually suffers from the existing outliers, and in the small training samples situation, it performed poor. In this paper, a variant of the k-NNR, the extended nearest neighbor classification based on the local mean vector and the class mean Vector has been proposed. The proposed classification method overcomes the influence of the existing outliers and performs obviously well than the traditional k-NNR in terms of the classification error rate on the unknown: patterns.	[Zeng Yong; Zhao Liang; Yang Yupu] Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200240, Peoples R China	Zeng, Y (reprint author), Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200240, Peoples R China.	zeng_yong@sjtu.edu.cn; wangb1009@163.com					Bhattacharyya A., 1943, Bulletin of the Calcutta Mathematical Society, V35; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 2001, PATTERN CLASSIFICATI; Ferri FJ, 1999, IEEE T SYST MAN CY B, V29, P667, DOI 10.1109/3477.790454; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fukunaga K., 1990, INTRO STAT PATTERN R; Hastie T, 1996, ADV NEUR IN, V8, P409; JAIN AK, 1998, PATTERN RECOGNITION; Kohavi R., 1997, P 9 EUR C MACH LEARN; Merz C., 1997, UCI REPOSITORY MACHI; Mitani Y, 2006, PATTERN RECOGN LETT, V27, P1151, DOI 10.1016/j.patrec.2005.12.016; Paredes R, 2006, PATTERN RECOGN, V39, P180, DOI 10.1016/j.patcog.2005.06.001; Paredes R, 2000, PATTERN RECOGN LETT, V21, P1027, DOI 10.1016/S0167-8655(00)00064-7; PENROD C, 1977, IEEE T SYST MAN CYB, P92; Ricci F, 1999, IEEE T PATTERN ANAL, V21, P380, DOI 10.1109/34.761268; Rumelhart DE, 1986, PARALLEL DISTRIBUTED; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; VANNESS J, 1980, PATTERN RECOGN, V12, P355, DOI 10.1016/0031-3203(80)90012-6	18	0	0	BEIJING UNIV AERONAUTICS & ASTRONAUTICS PRESS	HAIDIAN QU DISTRICT	37 XUE YUAN RD, HAIDIAN QU DISTRICT, BEIJING 100083, PEOPLES R CHINA						2008							559	563				5	Automation & Control Systems	Automation & Control Systems	BII51	WOS:000259745300122	
S	Olvera-Lopez, JA; Carrasco-Ochoa, JA; Martinez-Trinidad, JF		RuizShulcloper, J; Kropatsch, WG		Olvera-Lopez, J. Arturo; Carrasco-Ochoa, J. Ariel; Martinez-Trinidad, J. Fco.			Prototype Selection Via Prototype Relevance	PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	13th Iberoamerican Congress on Progress in Pattern Recognition, Image Analysis and Applications	SEP 09-12, 2008	Havana, CUBA	Adv Technol Applicat Ctr, Int Assoc Pattern Recognit, Cuban Assoc Pattern Recognit, Cuban Soc Math & Comp Sci, Mexican Assoc Comp Vis, Neural Comp & Robotics, SIGPR-SBC, Spanish Assoc Pattern Recognit & Image Anal, Portuguese Assoc Pattern Recognit		Prototype selection; border prototypes; supervised classification; data reduction	NEAREST-NEIGHBOR RULE; LEARNING ALGORITHMS	In Pattern recognition, the supervised classifiers use a training set T for classifying new prototypes. In practice, not all information in T is useful for classification therefore it is necessary to discard irrelevant prototypes from T. This process is known as prototype selection, which is an important task for classifiers since through this process the time in the training and/or classification stages could be reduced. Several prototype selection methods have been proposed following the Nearest Neighbor (NN) ruled in this work. we propose a new prototype selection method based oil the prototype relevance and border prototypes, which is faster (over large datasets) than the other tested prototype selection methods. We report experimental results showing the effectiveness of our method and compare accuracy and runtimes against other prototype selection methods.	[Olvera-Lopez, J. Arturo; Carrasco-Ochoa, J. Ariel; Martinez-Trinidad, J. Fco.] Natl Inst Astrophys Opt & Elect, Dept Comp Sci, Puebla 72840, Mexico	Olvera-Lopez, JA (reprint author), Natl Inst Astrophys Opt & Elect, Dept Comp Sci, Luis Enrique Erro 1,Sta Maria Tonantzintla, Puebla 72840, Mexico.						Bezdek JC, 2001, INT J INTELL SYST, V16, P1445, DOI 10.1002/int.1068; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Burr Ridge I, 1997, MACHINE LEARNING; CHIENHSING C, 2006, 18 INT C PATT REC, V2, P556, DOI 10.1109/ICPR.2006.1119; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P.A., 1980, 5TH P INT C PATT REC, P72; Duda R. O., 2001, PATTERN CLASSIFICATI; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; *U CAL SCH INF COM, UCI MACH LEARN REP	14	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-85919-2	LECT NOTES COMPUT SC			2008	5197						153	160				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BII86	WOS:000259899200019	
S	Ribeiro, JHB; Hashimoto, RF			IEEE Computer Society	Burckas Ribeiro, Joao Henrique; Hashimoto, Ronaldo Fumio			A New Training Algorithm for Pattern Recognition Technique Based on Straight Line Segments	SIBGRAPI 2008: XXI BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING	SIBGRAPI - Brazilian Symposium on Computer Graphics and Image Processing		English	Proceedings Paper	21st Brazilian Symposium on Computer Graphics and Image Processing	OCT 12-15, 2008	Campo Grande, BRAZIL	Brazilian Comput Soc			NEAREST FEATURE LINE; FACE RECOGNITION; CLASSIFICATION; CLASSIFIERS	Recently, a new Pattern Recognition technique based oil straight line segments (SLSs) was presented. The key issue in this new technique is to find a function based on distances between points and two sets of SLSs that minimizes a certain error or risk criterion. An algorithm for solving this optimization problem is called training algorithm. Although this technique seems to be very promising, the first presented training algorithm is based on a heuristic. In fact, the search for this best function is a hard nonlinear optimization problem. In this paper we present a new and improved training algorithm for the SLS technique based on gradient descent optimization method. We have applied this new training algorithm to artificial and public data sets and their results confirm the improvement of this methodology.	[Burckas Ribeiro, Joao Henrique; Hashimoto, Ronaldo Fumio] Univ Sao Paulo, Inst Matemat & Estat, Dept Ciencia Computacao, Sao Paulo, Brazil	Ribeiro, JHB (reprint author), Univ Sao Paulo, Inst Matemat & Estat, Dept Ciencia Computacao, Rua Matao 1010, Sao Paulo, Brazil.	burckas@ime.usp.br; ronaldo@ime.usp.br	Hashimoto, Ronaldo/B-6544-2013	Hashimoto, Ronaldo/0000-0002-6399-8790			Asuncion A., 2007, UCI MACHINE LEARNING; Chang C-C., 2001, LIBSVM LIB SUPPORT V; Chen JH, 2004, PATTERN RECOGN, V37, P1913, DOI 10.1016/j.patcog.2003.12.003; Chen K, 2002, PATTERN RECOGN LETT, V23, P1735, DOI 10.1016/S0167-8655(02)00147-2; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Du H, 2007, PATTERN RECOGN, V40, P1486, DOI 10.1016/j.patcog.2006.10.021; Duda R. O., 2001, PATTERN CLASSIFICATI; Gao QB, 2007, PATTERN RECOGN, V40, P346, DOI 10.1016/j.patcog.2006.06.033; Gottfried BS, 1973, INTRO OPTIMIZATION T; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Li SZ, 2000, IEEE T PATTERN ANAL, V22, P1335, DOI 10.1109/34.888719; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Michie D, 1994, MACHINE LEARNING NEU; Ribeiro JHB, 2006, ICMLA 2006: 5th International Conference on Machine Learning and Applications, Proceedings, P10; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004; ZHOU JWY, 2004, EXTENDED NEAREST FEA, V3157	19	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1530-1834	978-0-7695-3358-2	SIBGRAPI			2008							19	26		10.1109/SIBGRAPI.2008.35		8	Computer Science, Software Engineering; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BIN09	WOS:000260989600003	
B	Chong, RM; Tanaka, T			IEEE Computer Society	Chong, Rachel Mabanag; Tanaka, Toshihisa			Image Extrema Analysis and Blur Detection with Identification	SITIS 2008: 4TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY AND INTERNET BASED SYSTEMS, PROCEEDINGS			English	Proceedings Paper	4th International Conference on Signal Image Technology and Internet Bases Systems	NOV 30-DEC 03, 2008	Bali, INDONESIA	IEEE, IEEE Comp Soc, Univ Gunadarma, Univ Bourgogne, ACM SIGAPP				In real image processing applications, images may be blurred or not. When blur is present, the type and degree of degradation vary from one image to another. The process of restoring these images are usually computationally demanding so that there is a need to first detect blurs. If an image is not blurred then it need not undergo the restoration process. In this work, a novel algorithm that simultaneously detects and identifies blurs, is proposed. This method is based on the analysis of extrema values in an image. The extrema histograms are first constructed then analyzed in order to extract feature values. The distinctness of these values in the presence of blur is used. It is computationally, simple and fast thereby making it suitable for preprocessing especially in practical imaging applications. Experimental results on natural images and its synthetically blurred versions show the validity of the proposed method.	[Chong, Rachel Mabanag; Tanaka, Toshihisa] Tokyo Univ Agr & Technol, Dept Elect & Elect Engn, Koganei, Tokyo 1848588, Japan	Chong, RM (reprint author), Tokyo Univ Agr & Technol, Dept Elect & Elect Engn, 2-24-16 Naka Cho, Koganei, Tokyo 1848588, Japan.	chong@sip.tuat.ac.jp; tanakat@cc.tuat.ac.jp					AIZENBERG I, 2006, COMPUTATIONAL INTELL, V17, P441; AIZENBERG I, 2006, SOFT COMPUT, V11, P169; AIZENBERG I, 2002, ICANN 02, P1231; Chung Y.-C., 2004, 2004 IEEE C CYB INT, V1, P356; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; KUNDUR D, 1996, IEEE SIGNAL PROCESSI, V13, P47; LAGENDIJK RL, 2000, HDB IMAGE VIDEO PROC, P125; Marziliano P., 2002, P INT C IM PROC ROCH, V3, P57; TONG H, 2004, 2004 IEEE INT C MULT, V1, P17; Banham MR, 1997, IEEE SIGNAL PROC MAG, V14, P24, DOI 10.1109/79.581363	10	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		978-0-7695-3493-0				2008							320	326		10.1109/SITIS.2008.38		7	Computer Science, Software Engineering; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BIV55	WOS:000263157200043	
S	Ho, TK		DaVitoria Lobo, N; Kasparis, T; Roli, F; Kwok, JT; Georgiopoulos, M; Anagnostopoulos, GC; Loog, M		Ho, Tin Kam			Data Complexity Analysis: Linkage between Context and Solution in Classification	STRUCTURAL, SYNTACTIC, AND STATISTICAL PATTERN RECOGNITION	Lecture Notes in Computer Science		English	Proceedings Paper	Joint International Workshop on Structural, Syntactic, and Statistical Pattern Recognition	DEC 04-16, 2008	Orlando, FL	Int Assoc Pattern Recognit, Tech Committee	Univ Central Florida		PATTERN-RECOGNITION	For a classification problem that is implicitly represented by a training data set, analysis of data complexity provides a linkage between context and solution. Instead of directly optimizing classification accuracy by tuning the learning algorithms, one may seek changes ill the data sources and feature transformations to simplify the data geometry. Simplified class geometry benefits learning in a way common to many methods. We review some early results in data complexity analysis, compare these to recent advances ill manifold learning; and suggest directions for further research.			tkh@research.bell-labs.com					BAIRD HS, COMPLES IMAGE RECOGN, P287; Basu M., 2006, DATA COMPLEXITY PATT; Bengio Y., 2003, NIPS 2003, P177; CARLSSON G, 2008, TOPOLOGY DATA; CHERKASSKY V, DATA COMPLEXITY MARG, P91; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; de Ridder D, 2003, LECT NOTES COMPUT SC, V2714, P333; DEVROYE L, 1988, IEEE T PATTERN ANAL, V10, P530, DOI 10.1109/34.3915; DUIN RPW, OBJECT REPRESENTATIO, P25; He X., 2005, NIPS 2005; Ho TK, 1997, IEEE T PATTERN ANAL, V19, P1067; Ho TK, 2002, IEEE T PATTERN ANAL, V24, P289; HO TK, MEASURES GEOMETRICAL, P3; Ho TK, 2002, PATTERN ANAL APPL, V5, P102, DOI 10.1007/s100440200009; HO TK, CLASSIFIER DOMAINS C, P135; Li XL, 2008, IEEE T SYST MAN CY B, V38, P342, DOI 10.1109/TSMCB.2007.911536; MACIA N, 2008, P 19 INT C PAT REC T; MANSILLA EB, 2005, IEEE T EVOLUT COMPUT, V9, P82; Mansilla E.B., 2004, P 17 INT C PATT REC, V1, P136; PRANCKEVICIENE E, 2006, P 18 INT C PAT REC H, V2; RAUDYS S, MEASURES DATA CLASSI, P59; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Srivastava A, 2000, IEEE T SIGNAL PROCES, V48, P1390, DOI 10.1109/78.839985; Vapnik V., 1982, ESTIMATION DEPENDENC; Vapnik V.N., 1998, STAT LEARNING THEORY; von Ahn L, 2003, LECT NOTES COMPUT SC, V2656, P294; *MECH TURK, 2005, AM	27	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-89688-3	LECT NOTES COMPUT SC			2008	5342						986	995				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BIY10	WOS:000263676700098	
J	Farcomeni, A; Serranti, S; Bonifazi, G				Farcomeni, Alessio; Serranti, Silvia; Bonifazi, Giuseppe			Non-parametric analysis of infrared spectra for recognition of glass and glass ceramic fragments in recycling plants	WASTE MANAGEMENT			English	Article							CLASSIFICATION	Glass ceramic detection in glass recycling plants represents a still unsolved problem, as glass ceramic material looks like normal glass and is usually detected only by specialized personnel. The presence of glass-like contaminants inside waste glass products, resulting from both industrial and differentiated urban waste collection, increases process production costs and reduces final product quality. In this paper an innovative approach for glass ceramic recognition, based on the non-parametric analysis of infrared spectra, is proposed and investigated. The work was specifically addressed to the spectral classification of glass and glass ceramic fragments collected in an actual recycling plant from three different production lines: flat glass, colored container-glass and white container-glass. The analyses, carried out in the near and mid-infrared (NIR-MIR) spectral field (1280-4480 nm), show that glass ceramic and glass fragments can be recognized by applying a wavelet transform, with a small classification error. Moreover, a method for selecting only a small subset of relevant wavelength ratios is suggested, allowing the conduct of a fast recognition of the two classes of materials. The results show how the proposed approach can be utilized to develop a classification engine to be integrated inside a hardware and software sorting architecture for fast "on-line" ceramic glass recognition and separation. (C) 2007 Elsevier Ltd. All rights reserved.	[Serranti, Silvia; Bonifazi, Giuseppe] Univ Roma La Sapienza, Dipartimento Ingn Chim Mat Mat Prime & Met, I-00184 Rome, Italy; [Serranti, Silvia; Bonifazi, Giuseppe] Univ Roma La Sapienza, Dipartimento Stat Probabil & Stat Applicate, I-00185 Rome, Italy	Serranti, S (reprint author), Univ Roma La Sapienza, Dipartimento Ingn Chim Mat Mat Prime & Met, Via Eudossiana 18, I-00184 Rome, Italy.	silvia.serranti@uniromal.it					Bonifazi G, 2006, WASTE MANAGE, V26, P627, DOI 10.1016/j.wasman.2005.06.004; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAUBECHIES I, 1992, CBMS NSF REGIONAL C, V91; FARCOMENI A, 2004, THESIS U ROMA SAPIEN; Hastie T, 2001, ELEMENTS STAT LEARNI; Holand W, 2002, GLASS CERAMIC TECHNO; OGDEN TR, 1997, ESSENTIAL WAVELETS S, P1; Pannhorst W, 1997, J NON-CRYST SOLIDS, V219, P198, DOI 10.1016/S0022-3093(97)00270-6; Serranti S, 2006, WASTE MANAGE RES, V24, P48, DOI 10.1177/0734545X06061017	9	4	4	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0956-053X		WASTE MANAGE	Waste Manage.		2008	28	3					557	564		10.1016/j.wasman.2007.01.019		8	Engineering, Environmental; Environmental Sciences	Engineering; Environmental Sciences & Ecology	261RL	WOS:000253097600012	
B	Parvin, H; Alizadeh, H; Minael-Bidgoli, B			Int Assoc Engineers	Parvin, Hamid; Alizadeh, Hoscin; Minael-Bidgoli, Behrouz			MKNN: Modified K-Nearest Neighbor	WCECS 2008: WORLD CONGRESS ON ENGINEERING AND COMPUTER SCIENCE	Lecture Notes in Engineering and Computer Science		English	Proceedings Paper	World Congress on Engineering and Computer Science (WCECS 2008)	OCT 11-24, 2008	San Francisco, CA	Int Assoc Engineers		MKNN; KNN Classification; Modified K-Nearest Neighbor; Weighted K-Nearest Neighbor	CLASSIFICATION	In this paper, a new classification method for enhancing the performance of K-Nearest Neighbor is proposed which uses robust neighbors in training data. This new classification method is called Modified K-Nearest Neighbor, MKNN. Inspired the traditional KNN algorithm, the main idea is classifying the test samples according to their neighbor tags. This method is a kind of weighted KNN so that these weights are determined using a different procedure. The procedure computes the fraction of the same labeled neighbors to the total number of neighbors. The proposed method is evaluated on five different data sets. Experiments show the excellent improvement in accuracy in comparison with KNN method.	[Parvin, Hamid; Alizadeh, Hoscin; Minael-Bidgoli, Behrouz] Iran Univ Sci & Technol, Dept Comp Engn, Tehran, Iran	Parvin, H (reprint author), Iran Univ Sci & Technol, Dept Comp Engn, Tehran, Iran.	h_parvin@comp.iust.ac.ir; ho_alizadeh@comp.iust.ac.ir; b_minaei@iust.ac.ir					AEBERHARD S, 9202 J COOK U N QUEE; ALIZADEH H, 2008, P INT C CON IN PRESS; BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; Bermejo S, 2000, PATTERN RECOGN, V33, P1999, DOI 10.1016/S0031-3203(99)00186-7; Blake CL, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DARASAY BV, NEAREST NEIGHBOR PAT; Duda R.O., 2000, PATTERN CLASSIFICATI; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Fix E., 1951, 4 USAF SCH AV MED RA; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; Gose E, 1996, PATTERN RECOGNITION; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; Jozwik A., 1983, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(83)90064-8; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KUNCHEVA L, 2005, COMBINING PATTERN CL; PARVIN H, 2008, P INT C CON IN PRESS; PARVIN H, 2008, P INT C NET IN PRESS; SHUNICHI K, 2001, IMPROVING PERFORMANC	19	1	1	INT ASSOC ENGINEERS-IAENG	HONG KONG	UNIT1, 1-F, 37-39 HUNG TO ROAD, KWUN TONG, HONG KONG, 00000, PEOPLES R CHINA		978-988-98671-0-2	LECT NOTES ENG COMP			2008							831	834				4	Computer Science, Interdisciplinary Applications; Engineering, Multidisciplinary	Computer Science; Engineering	BIW70	WOS:000263417100156	
B	Oh, JS; Choi, KS; Kwon, JR; Kim, JY		Callaos, N; Lesso, W; Zinn, CD; Baralt, J; Rutkauskas, AV; Stasytyte, V		Oh, J. S.; Choi, K. S.; Kwon, J. R.; Kim, J. Y.			Identifying the near-Workload in the Mixed database Applications	WMSCI 2008: 12TH WORLD MULTI-CONFERENCE ON SYSTEMICS, CYBERNETICS AND INFORMATICS, VOL VI, PROCEEDINGS			English	Proceedings Paper	12th World Multi-Conference on Systemics, Cybernetics and Informatics/14th International Conference on Information Systems Analysis and Synthesis	JUN 29-JUL 02, 2008	Orlando, FL	Int Inst Informat & System, Int Federat Syst Res		Mixed workloads; k-NN classifier algorithm		Database administrators should be aware of workload characteristics for managing database systems. Workload characteristics can be different depending on database application. In particular, identifying workloads in mixed database applications might be quite difficult. Therefore, a method is necessary for identifying workloads in the mixed database application. This paper aims to identify workloads in the mixed database application using data mining technologies. To construct the mixed database application, we use the TPC-C and TPC-W benchmark. We discriminate between train workloads (workloads using the TPC-C or TPC-W benchmarks) and test workloads (mixed workloads of both benchmarks), and modify the algorithm of k-NN (Nearest Neighbor) classifier in order to satisfy our objectives. The modified k-NN algorithm measures how close the test workloads are to the train workloads. The modified k-NN algorithm is better than others for identifying workloads because its results are lower than others in the oscillation depending on the k parameter and the error rate. This research contributes towards considering flexible tuning methods using workload identification information.	[Oh, J. S.; Choi, K. S.; Kwon, J. R.; Kim, J. Y.] Korea Gas Safety Corp, Inst Gas Safety Technol, Shihung Shi 429712, Gyeonggi Do, South Korea							BAYLIS R, 2002, DATABASE ADM GUIDE R; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CYRAN M, 2001, ORACLE 9I DATABASE P; ELNAFFAR S, 2002, P CASCON C TOR CAN; Elnaffar S., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; Han J., 2001, DATA MINING CONCEPTS; Han J. H., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), DOI 10.1109/CVPR.1999.784711; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Martin P., 2002, International Journal on Digital Libraries, V3, DOI 10.1007/s007990100046; OH JS, 2004, J KISS D, V11, P747; *TPC, 2002, TPC BENCHM W WEB CAM; *TPC, 2001, TPC BENCHM C SPEC RE	12	0	0	INT INST INFORMATICS & SYSTEMICS	ORLANDO	14269 LORD BARCLAY DR, ORLANDO, FL 32837 USA		978-1-934272-36-7				2008							206	211				6	Business, Finance; Computer Science, Information Systems; Computer Science, Theory & Methods; Education & Educational Research; Information Science & Library Science	Business & Economics; Computer Science; Education & Educational Research; Information Science & Library Science	BIZ14	WOS:000263875200038	
S	Mignani, AG; Cucci, C; Ciaccheri, L; Dall'Asta, C; Galaverna, G; Dossena, A; Marchelli, R		Sampson, D; Collins, S; Oh, K; Yamauchi, R		Mignani, A. G.; Cucci, C.; Ciaccheri, L.; Dall'Asta, C.; Galaverna, G.; Dossena, A.; Marchelli, R.			Optical fiber fluorescence spectroscopy for detecting AFM1 in milk	19TH INTERNATIONAL CONFERENCE ON OPTICAL FIBRE SENSORS, PTS 1 AND 2	Proceedings of SPIE		English	Proceedings Paper	19th International Conference on Optical Fibre Sensors	APR 15-18, 2008	Perth, AUSTRALIA	Univ Western Australia, Opt & Biomed Engn Lab, SPIE, Opt Soc Japan, Opt Soc India, Japan Soc Appl Phys, Inst Elect, Informat & Commun Engineers, Japan Elect Soc, Opt Soc Korea, Opt Soc Amer, Australian Opt Soc, Soc Instrument & Control Engineers, Perth Convent Bur		aflatoxin; AFM1; fluorescence; milk; optical fibers	LIQUID-CHROMATOGRAPHY; PASTEURIZED MILK; AFLATOXIN M-1; M1	Fluorescence spectroscopy carried out by means of optical fibers was used for the rapid screening of M1 aflatoxin in milk, enabling the detection of concentrations up to the legal limit, which is 50 ppt. A compact fluorometric device equipped with a LED source, a miniaturized spectrometer, and optical fibers for illumination/detection of the measuring micro-cell was tested for measuring threshold values of AFM1 in pre-treated milk samples. Multivariate processing of the spectral data made it possible to obtain a preliminary screening at the earlier stages of the industrial process, as well as to discard contaminated milk stocks before their inclusion in the production chain.	[Mignani, A. G.; Cucci, C.; Ciaccheri, L.] CNR IFAC, I-50019 Sesto Fiorentino, FI, Italy	Mignani, AG (reprint author), CNR IFAC, Via Madonna del Piano 10, I-50019 Sesto Fiorentino, FI, Italy.	a.g.mignani@ifac.cnr.it					Bertran E, 2001, ANAL CHIM ACTA, V431, P303, DOI 10.1016/S0003-2670(00)01328-3; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cucci C, 2007, SENSOR ACTUAT B-CHEM, V126, P467, DOI 10.1016/j.snb.2007.03.036; Dragacci S, 2001, J AOAC INT, V84, P437; Gilbert J, 2003, J TOXICOL-TOXIN REV, V22, P381, DOI 10.1081/TXR-120024099; Hassouan M, 2007, ANAL LETT, V40, P779, DOI 10.1080/00032710601017912; IGARASHI Y, 1995, INT DAIRY J, V5, P305, DOI 10.1016/0958-6946(94)00004-9; Magan N., 2004, MYCOTOXINS FOOD DETE; Maragos CM, 2004, J TOXICOL-TOXIN REV, V23, P317, DOI 10.1081/TXR-200027859; Markaki P, 1997, FOOD ADDIT CONTAM, V14, P451; Martens H, 2001, MULTIVARIATE ANAL QU; Weidenborner M., 2001, ENCY FOOD MYCOTOXINS; Zinedine A, 2007, INT J FOOD MICROBIOL, V114, P25, DOI 10.1016/j.ijfoodmicro.2006.11.001; *FAO, 2003, WORLDW REG MYC FOOD, V81	14	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	978-0-8194-7204-5	PROC SPIE			2008	7004		1-2						70045S	10.1117/12.786666		4	Engineering, Biomedical; Optics; Physics, Applied	Engineering; Optics; Physics	BIC54	WOS:000258398100194	
S	Wang, SY; Baird, HS			IEEE	Wang, Sui-Yu; Baird, Henry S.			Feature Selection Focused within Error Clusters	19TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, VOLS 1-6	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	19th International Conference on Pattern Recognition (ICPR 2008)	DEC 08-11, 2008	Tampa, FL	IEEE			CLASSIFICATION	We propose a feature selection method that constructs each new feature by analysis of tight error clusters. This is a greedy, time efficient forward selection algorithm that iteratively constructs one feature at a time, until a desired error rate is reached. The algorithm finds error clusters in the current feature space, then projects one tight cluster into the null space of the feature mapping, where a new feature that helps to classify these errors can be discovered. Tight error clusters indicate that the current features are unable to discriminate these samples. The approach is strongly data driven and restricted to linear features, but other wise general. Large scale experiments show that it can achieve a monotonically decreasing error rate within the feature discovery set, and a generally decreasing error rate on a distinct test set.	[Wang, Sui-Yu; Baird, Henry S.] Lehigh Univ, Dept Comp Sci & Engn, Bethlehem, PA 18017 USA	Wang, SY (reprint author), Lehigh Univ, Dept Comp Sci & Engn, 19 Mem Dr W, Bethlehem, PA 18017 USA.	syw2@lehigh.edu; baird@cse.lehigh.edu					Baird H. S., 2006, P SPIE IS T DOC REC; Baird HS, 2006, LECT NOTES COMPUT SC, V3872, P280; Bellman R., 1961, ADAPTIVE CONTROL PRO; BENGIO Y, 2003, FEATURE EXTRACTION F, P519; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Datta B.N., 1994, NUMERICAL LINEAR ALG; Devroye L, 1996, PROBABILISTIC THEORY; DONGARRA J, 2006, HDB LINEAR ALGEBRA; Duda R. O., 2001, PATTERN CLASSIFICATI; ELASHOFF JD, 1967, BIOMETRIKA, V54, P668, DOI 10.2307/2335061; Guyon I., 2006, FEATURE EXTRACTION F; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; HOHN FE, 2003, ELEMENTARY MATRIX AL; Mason L, 2000, ADV NEUR IN, V12, P512; MOMMA M, 2003, FEATURE EXTRACTION F, P551; Shannon C., 1948, BELL SYS TECH J, V27; Watanabe S., 1985, PATTERN RECOGNITION; Wold H., 1981, FIX POINT APPROACH I; Wolpert D. H., 1995, MATH GEN; Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585893; Wolpert D.H., 1995, SFITR9502010	21	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1051-4651	978-1-4244-2174-9	INT C PATT RECOG			2008							2585	2588				4	Computer Science, Artificial Intelligence	Computer Science	BJC36	WOS:000264729001151	
B	Li, FY; Wechsler, H; Tistarelli, M			IEEE	Li, Fayin; Wechsler, Harry; Tistarelli, Massimo			Robust Fusion Using Boosting and Transduction for Component-Based Face Recognition	2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS & VISION: ICARV 2008, VOLS 1-4			English	Proceedings Paper	10th International Conference on Control, Automation, Robotics and Vision	DEC 17-20, 2008	Hanoi, VIETNAM	IEEE		biometrics; boosting; component-based recognition; data fusion; face recognition; disguise; forensics; k-nearest neighbor; likelihood ratio; margin; Neyman-Pearson; occlusion; open set recognition; surveillance; transduction; strangeness; typicality	FORENSIC SPEAKER RECOGNITION; FEATURES	Face recognition performance depends upon the input variability as encountered during biometric data capture including occlusion and disguise. The challenge met in this paper is to expand the scope and utility of biometrics by discarding unwarranted assumptions regarding the completeness and quality of the data captured. Towards that end we propose a model-free and non-parametric component-based face recognition strategy with robust decisions for data fusion that are driven by transduction and boosting. The conceptual framework draws support throughout from discriminative methods using likelihood ratios. It links at the conceptual level forensics and biometrics, while at the implementation level it links the Bayesian framework and statistical learning theory (SLT). Feature selection of local patch instances and their corresponding high-order combinations, exemplar-based clustering (of patches) as components including the sharing (of exemplars) among components, and finally decision-making regarding authentication using boosting driven by components that play the role of weak-learners, are implemented in a similar fashion using transduction driven by a strangeness measure akin to typicality. The feasibility, reliability, and utility of the proposed open set face recognition architecture vis-a-vis adverse image capture conditions are illustrated using FRGC data. The potential for future developments concludes the paper.	[Li, Fayin; Wechsler, Harry] George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA	Li, FY (reprint author), George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA.	fayin.li@gmail.com; wechsler@gmu.edu; tista@uniss.it					Balas B.J., 2006, ACM T APPL PERCEPT, V3, P354, DOI 10.1145/1190036.1190038; Barlow H. B., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.3.295; Champod C, 2000, SPEECH COMMUN, V31, P193, DOI 10.1016/S0167-6393(99)00078-3; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Delorme A, 2001, NEURAL NETWORKS, V14, P795, DOI 10.1016/S0893-6080(01)00049-1; DESSIMOZ D, 2008, HDB BIOMETRICS; Duda R.O., 2000, PATTERN CLASSIFICATI; Freund Y., 1996, 13 INT C MACH LEARN, P148; Gonzalez-Rodriguez J, 2007, IEEE T AUDIO SPEECH, V15, P2104, DOI 10.1109/TASL.2007.902747; GUTTA S, 2004, 1 INT C BIOM AUTH HO; Ho SS, 2008, IEEE T PATTERN ANAL, V30, P1557, DOI 10.1109/TPAMI.2007.70811; KOLLER D, 1996, 13 INT C MACH LEARN; LAI H, 2008, COMPUTER VI IN PRESS; Li F, 2005, IEEE T PATTERN ANAL, V27, P1686; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Melluish T., 2001, TYPICALNESS FRAMEWOR; PHILLIPS PJ, 2005, OVERVIEW FACE RECOGN; Sinha P, 2006, P IEEE, V94, P1948, DOI 10.1109/JPROC.2006.884093; Smith Paul F, 2005, Expert Opin Drug Saf, V4, P443, DOI 10.1517/14740338.4.3.443; Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0; Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055; Tsunoda K, 2001, NAT NEUROSCI, V4, P832, DOI 10.1038/90547; Vapnik V.N., 1998, STAT LEARNING THEORY; Viola P., 2001, RAPID OBJECT DETECTI; VOVK V, 1999, 16 INT C MACH LEARN	25	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-2286-9				2008							434	439				6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Robotics	Computer Science; Engineering; Robotics	BJK70	WOS:000266716600077	
B	Liu, Q; Lin, TS		Li, S; Li, T; Ruan, D		Liu Qing; Lin Tu-sheng			Wavelet-based Coefficients' Relationship Co-occurrence Histogram Algorithm of Texture Teature Extraction	2008 3rd International Conference on Intelligent System and Knowledge Engineering, Vols 1 and 2			English	Proceedings Paper	3rd International Conference on Intelligent System and Knowledge Engineering	NOV 17-19, 2008	Xiamen, PEOPLES R CHINA	Xiamen Univ, Fuzhou Univ, Fujian Agr & Fore Univ, Jimei Univ, Sanming Univ, Hunan Inst Humanities, Sci & Tech, Longyan Univ, IEEE Beijing Sect, Tsinghua Univ, SW Jiaotong Univ, Donghua Univ Ghent Univ, Belgian Nucl Res Ctr, Univ Technol			CLASSIFICATION; SEGMENTATION	We propose a novel texture feature extraction technique based on coefficients' co-occurrence histogram of discrete wavelet frame transformed image, which capture the information about relationship between each high frequency subband and the low frequency subband of the decomposed image at the corresponding level. It is not independently utilizing the information of each subband coefficient. The classification performance is analyzed using the k-NN classifier And the experimental results demonstrate the effectiveness of our proposed texture feature in achieving the improved classification performance. Comparisons with the Gabor filter and a recently proposed approach are also provided.	[Liu Qing; Lin Tu-sheng] S China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510640, Guangdong, Peoples R China	Liu, Q (reprint author), S China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510640, Guangdong, Peoples R China.	liu.qing3@mail.scut.edu.cn; eetshlin@scut.edu.cn					Brodatz P., 1966, TEXTURES PHOTOGRAPHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25; Daugman J, 1990, COMPUTATIONAL NEUROS, P403; EHRICH RW, 1978, COMPUT VISION GRAPH, V8, P174, DOI 10.1016/0146-664X(78)90048-5; HARALICK RM, 1978, IEEE T SYSTERM MAN C, V8, P460; HIREMATH PS, 2008, PATTERN RECOGN; Laine A, 1996, IEEE T IMAGE PROCESS, V5, P771, DOI 10.1109/83.499915; LI XH, 2003, ACTA ELECT SINICA, V31, P2123; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983; UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936; WANG ZY, 2001, J IMAGE GRAPHIC, V6, P1065; WU J, 2001, J REMOTE SENSING, V5, P100	14	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-2196-1				2008							1050	1053		10.1109/ISKE.2008.4731084		4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BIS44	WOS:000262437400197	
B	Wang, B; Zeng, Y; Yang, Y			IEEE	Wang, Bing; Zeng, Yong; Yang, Yupu			Generalized Nearest Neighbor Rule for Pattern Classification	2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23			English	Proceedings Paper	7th World Congress on Intelligent Control and Automation	JUN 25-27, 2008	Chongqing, PEOPLES R CHINA	Chongqing Univ, Chongqing Inst Technol, Chongqing Univ Sci & Technol, Xihua Univ, SW Univ Sci & Technol, IEEE Robot & Automat Soc, IEEE Control Syst Soc, Beijing Chapter, Chinese Assoc Automat, Chinese Assoc Artificial Intell, Natl Nat Sci Fdn, Chongqing Municipal Sci & Technol Comm, Chongqing Municipal Assoc Sci & Technol, KC Wong Educ Fdn		Nearest neighbor rule (NNR); generalized nearest neighbor rule (GNNR); weighted k-nearest neighbor rule; pseudo nearest neighbor (PNN)	ALGORITHM	In this paper, we propose a generalized nearest neighbor classification rule (GNNR). It is similar to but different from the previous nearest neighbor rule (NNR), this new rule utilizes more information of the neighbors of the unclassified sample point except its nearest neighbor. Theoretical analysis and experimental results confirm the validity of this new rule.	[Wang, Bing] Panzhihua Univ, Sch Informat & Elect Engn, Panzhihua, Sichuan, Peoples R China	Wang, B (reprint author), Panzhihua Univ, Sch Informat & Elect Engn, Xue Yuan Rd, Panzhihua, Sichuan, Peoples R China.						BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARTHY BV, 1991, NEAREST NEIGHBOR NOR; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; DEVROYE L, 1996, PROBABILISTIC THEORY, P63; Devroye L., 1996, PROBABILISTIC THEORY, P71; Djouadi A, 1997, IEEE T PATTERN ANAL, V19, P277, DOI 10.1109/34.584107; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Fix E, 1951, 4 US AIR FORC SCH AV; McNames J, 2001, IEEE T PATTERN ANAL, V23, P964, DOI 10.1109/34.955110; MORIN RL, 1981, IEEE T SYST MAN CYB, V11, P241; THEODORIDIS S, 2006, PATTERN RECOGN, P48; ZAVREL J, 1997, P 7 BELG DUTCH C MAC, P139; [Anonymous], UCI Repository of machine learning databases and domain theories	15	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-2113-8				2008							8465	8470		10.1109/WCICA.2008.4594258		6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic; Robotics	Automation & Control Systems; Computer Science; Engineering; Robotics	BIJ02	WOS:000259965706220	
S	Yang, J; Lou, Z; Jin, Z; Yang, JY			IEEE	Yang, Jian; Lou, Zhen; Jin, Zhong; Yang, Jing-yu			Minimal local reconstruction error measure based discriminant feature extraction and classification	2008 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, VOLS 1-12	PROCEEDINGS - IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION		English	Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition	JUN 23-28, 2008	Anchorage, AK	IEEE Comp Soc			FACE-RECOGNITION ALGORITHMS; PATTERN-CLASSIFICATION; NEAREST; CLASSIFIERS; PROJECTION	This paper introduces the minimal local reconstruction error (MLRE) as a similarity measure and presents a MLRE-based classifier. From the geometric meaning of the minimal local reconstruction error, we derive that the MLRE-based classifier is a generalization of the conventional nearest neighbor classifier and the nearest neighbor line and plane classifiers. We further apply the MLRE measure to characterize the within-class and between-class local scatters and then develop a MLRE measure based discriminant feature extraction method. The proposed MLRE-based feature extraction method is in line with the MLRE-based classification method in spirit, thus the two methods can be seamlessly combined in applications. The experimental results on the CENPARMI handwritten numeral database and the FERET face image database show effectiveness of the proposed MLRE-based feature extraction and classification method.	[Yang, Jian; Lou, Zhen; Jin, Zhong; Yang, Jing-yu] Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Peoples R China	Yang, J (reprint author), Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Peoples R China.						Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; He X., 2005, IEEE INT C COMP VIS; He XF, 2005, IEEE T PATTERN ANAL, V27, P328; Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; LOU Z, 2006, P 18 INT C PATT REC, V3, P87; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Saul L. K., 2003, J MACHINE LEARNING R, V4, P119; Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598; Yang J, 2007, IEEE T PATTERN ANAL, V29, P650, DOI 10.1109/TPAMI.2007.1008; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004	14	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1063-6919	978-1-4244-2242-5	PROC CVPR IEEE			2008							173	178				6	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BII46	WOS:000259736800023	
B	Xiong, Y; Yang, Q; Qiu, BR; Zhu, YY		Chen, Y; He, J; Reddy, CK; Yang, J; Yoo, I; Zhang, X; Gao, J; Huang, Y; Song, M; Yang, J; Wu, Z		Xiong, Yun; Yang, Qing; Qiu, Boren; Zhu, Yangyong			An Integrated Approach of Sequence and Text Mining Technology for the Identification of Transcription Factor Binding Sites	2008 IEEE INTERNATIONAL CONFERENCE ON BIOINFORMATICS AND BIOMEDICINE WORKSHOPS, PROCEEDINGS			English	Proceedings Paper	IEEE International Conference on Bioinformatics and Biomedicine	NOV 03-05, 2008	Philadelphia, PA	IEEE		transcription factor; binding site; text mining; sequence mining; data mining; bioinformatics	REGULATORY ELEMENTS; TOOL	The study of the complex mechanisms that regulated gene expression on the level of transcription is an important and challenging issue in post-genomic era. A crucial step is to identify transcription factor binding sites(TFBSs). However, the number of the known TFBSs is limited, and the accuracy of the state-of-the-art identification methods is still far from satisfactory. In this paper a novel integrated method for mining transcription factor binding sites is presented, which combines the sequence data mining method with the text mining method. Therefore, the method can not only obtain the putative TFBSs from the sequence data sets, but also acquire the experimentally verified TFBSs from the literatures. To evaluate the performance of our method, several experiments have been tested on real data sets. The results show that our integrated method outperforms each of the algorithms alone, furthermore, exhibits superior accuracy than existing algorithms.	[Xiong, Yun] Fudan Univ, Sch Comp Sci, Shanghai 200433, Peoples R China	Xiong, Y (reprint author), Fudan Univ, Sch Comp Sci, Shanghai 200433, Peoples R China.	yunx@fudan.edu.cn; yyzhu@fudan.edu.cn					ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Bailey TL, 1995, P 3 INT C INT SYST M, P21; CHEN Y, 2002, IEEE INT C DAT MIN I; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Hughes JD, 2000, J MOL BIOL, V296, P1205, DOI 10.1006/jmbi.2000.3519; JANG B, 2007, BIOINFORMATICS, V21, P2823; Joachims T., 1999, INT C MACH LEARN ICM, P200; Kel AE, 2003, NUCLEIC ACIDS RES, V31, P3576, DOI 10.1093/nar/gkg585; Manevitz LM, 2001, J MACHINE LEARNING R, V2, P139; MARCO DB, 2000, NEW DIRECTIONS QUEST, P138; MATHIAK B, 2004, 5 STEPS TEXT MINING; Sandelin A., 2004, NUCLEIC ACIDS RES, V32, P91; SELVI P, 2007, C COMP INT MULT APPL, V1, P9; STEIN A, 2008, GENOME BIOL, V9, pR31; Thijs G, 2001, BIOINFORMATICS, V17, P1113, DOI 10.1093/bioinformatics/17.12.1113; THOMPA M, 2005, NAT BIOTECHNOL, V23, P137; Vapnik V.N., 1998, STAT LEARNING THEORY; Wang Y, 2005, PATTERN RECOGN LETT, V26, P2187, DOI 10.1016/j.patrec.2005.03.034; Wingender E, 1996, NUCLEIC ACIDS RES, V24, P238, DOI 10.1093/nar/24.1.238; Workman C T, 2000, Pac Symp Biocomput, P467; ZHENG GY, 2008, BMC BIOINFORMATICS, P282	21	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		978-1-4244-2890-8				2008							178	184				7	Engineering, Biomedical	Engineering	BIQ62	WOS:000262067000033	
S	Yang, CS; Chuang, LY; Li, JC; Yang, CH			IEEE	Yang, Cheng-San; Chuang, Li-Yeh; Li, Jung-Chike; Yang, Cheng-Hong			Information Gain with Chaotic Genetic Algorithm for Gene Selection and Classification Problem	2008 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS (SMC), VOLS 1-6	IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, CONFERENCE PROCEEDINGS		English	Proceedings Paper	IEEE International Conference on System, Man, and Cybernetic	OCT 12-15, 2008	Singapore, SINGAPORE	IEEE		microarray data; feature selection; information gain; chaotic genetic algorithm; K-nearest neighbor	MICROARRAY DATA	For microarray data classification problem, selecting relevant genes from microarray data pose a formidable challenge to researchers due to the high-dimensionality of features, multi-class categories being involved and the usually small sample size. In order to correctly analyze microarray data, the goal of feature (gene) selection is to select those subsets of differentially expressed genes that are potentially relevant for distinguishing the sample classes. In this paper, information gain and chaotic genetic algorithm are proposed to select the relevant genes, and a K-nearest neighbor with the leave-one-out cross-validation method serves as a classifier. Chaotic genetic algorithm is modified by using the chaotic mutation operator to increase the population diversity. The experimental results show that the proposed method not only effectively reduced the number of gene expression levels, but also achieved lower classification error rates.	[Yang, Cheng-San] Natl Cheng Kung Univ, Inst Biomed Engn, Tainan 70101, Taiwan	Yang, CS (reprint author), Natl Cheng Kung Univ, Inst Biomed Engn, Tainan 70101, Taiwan.	p8896117@mail.ncku.edu.tw; chuang@isu.edu.tw; 1095320149@cc.kuas.edu.tw; chyang@cc.kuas.edu.tw					ALATAS B, CHAOS SOLIT IN PRESS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davis L, 1991, HDB GENETIC ALGORITH; Deep K, 2007, APPL MATH COMPUT, V193, P211, DOI 10.1016/j.amc.2007.03.046; Diaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3; Herrera F, 2000, APPL INTELL, V13, P187, DOI 10.1023/A:1026531008287; Holland J. H., 1992, ADAPTATION NATURAL A; KODAZ H, EXPERT SYST IN PRESS; Liu X., 2005, BMC BIOINFORMATICS, V6, P76; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; Quinlan J. R., 1986, INDUCTION DECISION T, V1, P81, DOI DOI 10.1007/BF00116251; Tahir MA, 2007, PATTERN RECOGN LETT, V28, P438, DOI 10.1016/j.patrec.2006.08.016; Tan SB, 2006, EXPERT SYST APPL, V30, P290, DOI 10.1016/j.eswa.2005.07.019; VERRON S, J PROCESS C IN PRESS; Wang XY, 2007, PATTERN RECOGN LETT, V28, P459, DOI 10.1016/j.patrec.2006.09.003	15	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X	978-1-4244-2383-5	IEEE SYS MAN CYBERN			2008							1127	1132				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BKT54	WOS:000269197300193	
S	Hartono, P; Saito, A			IEEE	Hartono, Pitoyo; Saito, Aya			Class-Proximity SOM and Its Applications in Classification	2008 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS (SMC), VOLS 1-6	IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, CONFERENCE PROCEEDINGS		English	Proceedings Paper	IEEE International Conference on System, Man, and Cybernetic	OCT 12-15, 2008	Singapore, SINGAPORE	IEEE			SELF-ORGANIZING MAP; VISUALIZATION	In this study, we propose a model of Self-Organizing Map (SOM) capable of mapping high dimensional data into a low dimension space by preserving not only the feature-proximity of the original data but also their class-proximity. A conventional SOM is known to map original high dimensional data with similar features into points located close to each other in the low dimensional map in a so called competitive layer. In addition to this feature, the proposed SOM is also able to map high dimensional data belonging to a same class in each other's proximities. These characteristics retains the ability of. the map to be used as a visualization tool of high dimensional data while also support the execution of high quality pattern classifications in the low dimensional map. In the experiments the classification performance of the proposed SOM is compared to that of MLP with regards to wide varieties of problems.	[Hartono, Pitoyo; Saito, Aya] Future Univ Hakodate, Dept Media Architecture, Hakodate, Hokkaido, Japan	Hartono, P (reprint author), Future Univ Hakodate, Dept Media Architecture, Hakodate, Hokkaido, Japan.	hartono@fun.ac.jp					Barreto GA, 2004, IEEE T NEURAL NETWOR, V15, P1244, DOI 10.1109/TNN.2004.832825; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; KOGA T, 2006, NEURAL NETWORKS, V19; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Kohonen T., 1988, P IEEE INT C NEUR NE, V1, P61; Kohonen T, 1995, SELF ORGANIZING MAPS; Wu ST, 2005, IEEE T NEURAL NETWOR, V16, P1362, DOI 10.1109/TNN.2005.853574; Yamakawa T, 1999, IEICE T FUND ELECTR, VE82A, P1674; Yin HJ, 2002, IEEE T NEURAL NETWOR, V13, P237, DOI 10.1109/72.977314; UCI REPOSITORY	10	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X	978-1-4244-2383-5	IEEE SYS MAN CYBERN			2008							2149	2154				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BKT54	WOS:000269197301049	
S	Gravina, R; Guerrieri, A; Fortino, G; Bellifemine, F; Giannantonio, R; Sgroi, M			IEEE	Gravina, Raffaele; Guerrieri, Antonio; Fortino, Giancarlo; Bellifemine, Fabio; Giannantonio, Roberta; Sgroi, Marco			Development of Body Sensor Network Applications using SPINE	2008 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS (SMC), VOLS 1-6	IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, CONFERENCE PROCEEDINGS		English	Proceedings Paper	IEEE International Conference on System, Man, and Cybernetic	OCT 12-15, 2008	Singapore, SINGAPORE	IEEE		Body Sensor Networks; Domain-Specific Software Frameworks; Activity Monitoring Systems		SPINE (Signal Processing in Node Environment) is a Framework for the development of Body Sensor Network (BSN) applications. It provides developers of signal processing algorithms with APIs and libraries of protocols, utilities and data processing functions. Hence, it offers application developers new abstractions that improve interoperability and allow to reduce development time. This paper presents the architecture and the capabilities of the SPINE framework, and shows its use in the development of a real-time activity monitoring system prototype.	[Gravina, Raffaele; Guerrieri, Antonio; Fortino, Giancarlo] Univ Calabria, DEIS, I-87036 Arcavacata Di Rende, CS, Italy	Gravina, R (reprint author), Univ Calabria, DEIS, I-87036 Arcavacata Di Rende, CS, Italy.	g.fortino@unical.it; fabioluigi.bellifemine@telecomitalia.it; roberta.giannantonio@telecomitalia.it; marco.sgroi@wsnlabberkeley.com					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 2000, PATTERN CLASSIFICATI; GRAVINA R, 2008, P 5 EUR C WIR SENS N; Iyengar S., 2008, P 3 INT C BOD AR NET; LO B, 2005, P INT WORKSH WEAR IM; LOMBRISER C, 2007, P 2 INT C BOD AR NET; LOMBRISER C., 2007, 15 FACHT KOMM VERT S, P127; Najafi B, 2003, IEEE T BIO-MED ENG, V50, P711, DOI 10.1109/TBME.2003.812189; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; RAVI N, P 27 C INN APPL ART, P1541; SHNAYDER V, 2005, TR0805 HARV U DIV EN; WADA H, 2007, P 11 IASTED INT C SO; YU Y, 2004, IEEE NETWORK MAGAZIN; LGPL LICENSE	14	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X	978-1-4244-2383-5	IEEE SYS MAN CYBERN			2008							2809	2814				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BKT54	WOS:000269197301161	
S	Korsrilabutr, T; Kijsirikul, B			IEEE	Korsrilabutr, Teesid; Kijsirikul, Boonserm			Pseudometrics for Time Series Classification by Nearest Neighbor	2008 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-8	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	JUN 01-08, 2008	Hong Kong, PEOPLES R CHINA	IEEE			WORD RECOGNITION	Despite the success of its applications in many areas, the Dynamic Time Warping (DTW) distance does not satisfy the triangle inequality (subadditivity). Once we have a subadditive distance measure for time series, the measure will have at least one significant advantage over DTW; one can directly plug such distance measure into systems which exploit the subadditivity to perform faster similarity search techniques. We propose two frameworks for designing subadditive distance measures and a few examples of distance measures resulting from the frameworks. One framework is more general than the other and can be used to tailor distances from the other framework to gain better classification performance. Experimental results of nearest neighbor classification showed that the designed distance measures am practical for time series classification.	[Korsrilabutr, Teesid; Kijsirikul, Boonserm] Chulalongkorn Univ, Dept Comp Engn, Bangkok 10330, Thailand	Korsrilabutr, T (reprint author), Chulalongkorn Univ, Dept Comp Engn, Phayathai Rd, Bangkok 10330, Thailand.	teesid@gmail.com; boonserm.k@chula.ac.th					AACH J, 2001, BIOINF BIOINFORMATIC, V17; Barros J, 1996, P SOC PHOTO-OPT INS, V2670, P392, DOI 10.1117/12.234778; Chen L., 2004, MARRIAGE LP NORMS ED; CIACCIA P, 1997, VLDB 97, P426; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dohnal V, 2003, MULTIMED TOOLS APPL, V21, P9, DOI 10.1023/A:1025026030880; ITAKURA F, 1975, IEEE T ACOUST SPEECH, VAS23, P67, DOI 10.1109/TASSP.1975.1162641; Keogh E, 2005, KNOWL INF SYST, V7, P358, DOI 10.1007/s10115-004-0154-9; Keogh E. J., 2006, UCR TIME SERIES CLAS; Levenshtein V. I., 1966, SOV PHYS DOKL, V10, P707; RABINER LR, 1978, J ACOUST SOC AM, V63, pS79, DOI 10.1121/1.2016831; Roussopoulos N., 1995, SIGMOD, P71; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; Schmill M, 1999, 7 INT WORKSH ART INT	14	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576	978-1-4244-1820-6	IEEE IJCNN			2008							1382	1389		10.1109/IJCNN.2008.4633978		8	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	BIY81	WOS:000263827200221	
S	Saha, S; Bandyopadhyay, S; Singh, CT			IEEE	Saha, Sriparna; Bandyopadhyay, Sanghamitra; Singh, Chingtham Tejbanta			A New Line Symmetry Distance Based Pattern Classifier	2008 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-8	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	JUN 01-08, 2008	Hong Kong, PEOPLES R CHINA	IEEE		Pattern Classification; Kd-tree; Symmetry based distance; Nearest Neighbor Rule; Line Symmetry	NEAREST-NEIGHBOR CLASSIFICATION; ALGORITHMS	In this paper, a new line symmetry based classifier (LSC) is proposed to deal with pattern classification problems. In order to measure total amount of line symmetry of a particular point in a class, a new definition of line symmetry based distance is also proposed in this paper. The proposed line symmetry based classifier (LSC) utilizes this new definition of tine symmetry distance for classifying an unknown test sample. LSC assigns an unknown test sample pattern to that class with respect to whose major axis it is most symmetric. The mean of all the training patterns belonging to that particular class is taken as the prototype of that class. Thus training constitutes of computing only the class prototypes and the major axes of those classes. Kd-tree based nearest neighbor search is used for reducing complexity of line symmetry distance computation. The performance of LSC is demonstrated in classifying twelve artificial and real-life data sets of varying complexities. Experimental results show that LSC achieves, in general, higher classification accuracy compared to kappa-NN classifier. Results indicate that the proposed novel line symmetry based classifier is well-suited for classifying data sets having symmetrical classes, irrespective of any convexity, overlap and size. Statistical analysis, ANOVA is also performed to compare the performance of these classifications techniques.	[Saha, Sriparna; Bandyopadhyay, Sanghamitra] Indian Stat Inst, Machine Intelligence Unit, Calcutta 700108, India	Saha, S (reprint author), Indian Stat Inst, Machine Intelligence Unit, Calcutta 700108, India.	sriparna_r@isical.ac.in; sangahmi@isical.ac.in; chingtham@gmail.com					ANDERBERG MR, 2000, COMPUTATIONAL GEOMET; Anderson T.W., 1978, INTRO STAT ANAL DATA; Asuncion A., 2007, UCI MACHINE LEARNING; ATTNEAVE F, 1955, Am J Psychol, V68, P209, DOI 10.2307/1418892; Bandyopadhyay S, 2002, PATTERN RECOGN, V35, P2791, DOI 10.1016/S0031-3203(01)00234-5; Bandyopadhyay S, 2007, PATTERN RECOGN, V40, P3430, DOI 10.1016/j.patcog.2007.03.026; BENTLEY JL, 1980, ACM T MATH SOFTWARE, V6, P563, DOI 10.1145/355921.355927; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ferhatosmanoglu H, 2006, INFORM SYST, V31, P512, DOI 10.1016/j.is.2005.01.001; Fix E., 1951, 4 USAF SCH AV MED RA; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; Gao QB, 2007, PATTERN RECOGN, V40, P346, DOI 10.1016/j.patcog.2006.06.033; Ghosh AK, 2006, COMPUT STAT DATA AN, V50, P3113, DOI 10.1016/j.csda.2005.06.007; Gonzalez R., 1992, DIGITAL IMAGE PROCES; Lai JZC, 2007, PATTERN RECOGN, V40, P351, DOI 10.1016/j.patcog.2006.04.024; LIU CL, 1999, ICDAR 99, P378; Mount D., 2005, ANN LIB APPROXIMATE; Pal SK, 1998, IEEE T SYST MAN CY B, V28, P816, DOI 10.1109/3477.735391; PAL SK, 1977, IEEE T SYST MAN CYB, V7, P625; Su MS, 2001, IEEE T PATTERN ANAL, V23, P674; Viswanath P, 2006, PATTERN RECOGN LETT, V27, P1714, DOI 10.1016/j.patrec.2006.04.015; Wang JG, 2007, PATTERN RECOGN LETT, V28, P207, DOI 10.1016/j.patrec.2006.07.002; Zhou CY, 2006, PATTERN RECOGN, V39, P635, DOI 10.1016/j.patocog.2005.09.004	23	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576	978-1-4244-1820-6	IEEE IJCNN			2008							1425	1432		10.1109/IJCNN.2008.4633984		8	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	BIY81	WOS:000263827200227	
S	Yang, CS; Chuang, LY; Li, JC; Yang, CH			IEEE	Yang, Cheng-San; Chuang, Li-Yeh; li, Jung-Chike; Yang, Cheng-Hong			A Novel BPSO Approach for Gene Selection and Classification of Microarray Data	2008 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-8	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	JUN 01-08, 2008	Hong Kong, PEOPLES R CHINA	IEEE			MULTIPLE CANCER TYPES; EXPRESSION DATA; BREAST-CANCER; DISCRIMINATION; MACHINE; NUMBER; TUMORS; SETS	Selecting relevant genes from microarray data poses a huge challenge due to the high-dimensionality of the features multi-class categories and a relatively small sample size. The main task of the classification process is to decrease the microarray data dimensionality. In order to analyze microarray data, an optimal subset of features (genes) which adequately represents the original set of features has to be found. In this study, we used a novel binary particle swarm optimization (NBPSO) algorithm to perform microarray data selection and classification. The K-nearest neighbor (K-NN) method with leave-one-out cross-validation (LOOCV) served as a classifier. The experimental results showed that the proposed method not only effectively reduced the number of gene expression levels, but also achieved lower classification error rates.	[Yang, Cheng-San] Natl Cheng Kung Univ, Inst Biomed Engn, Tainan 70101, Taiwan	Yang, CS (reprint author), Natl Cheng Kung Univ, Inst Biomed Engn, Tainan 70101, Taiwan.	p8896117@mail.ncku.edu.tw; chuang@isu.edu.tw; 1095320149@cc.kuas.edu.tw; chyang@cc.kuas.edu.tw					Berrar D, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-73; Chang JC, 2005, BREAST CANCER RES, V7, P100, DOI 10.1186/bcr1018; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deutsch JM, 2003, BIOINFORMATICS, V19, P45, DOI 10.1093/bioinformatics/19.1.45; Diaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; FIX E, 1989, INT STAT REV, V57, P238, DOI 10.2307/1403797; Hua JP, 2005, BIOINFORMATICS, V21, P1509, DOI 10.1093/bioinformatics/bti171; Huang HL, 2007, BIOSYSTEMS, V90, P516, DOI 10.1016/j.biosystems.2006.12.003; Huang HL, 2007, BIOSYSTEMS, V90, P78, DOI 10.1016/j.biosystems.2006.07.002; Jeffrey Stefanie S, 2005, J Natl Compr Canc Netw, V3, P291; Kennedy J., 1995, IEEE INT C NEUR NETW, V4; Kennedy J., 2001, SWARM INTELLIGENCE; Kennedy J, 1997, IEEE SYS MAN CYBERN, P4104; Lee JW, 2005, COMPUT STAT DATA AN, V48, P869, DOI 10.1016/j.csda.2004.03.017; Lee Y, 2003, BIOINFORMATICS, V19, P1132, DOI 10.1093/bioinformatics/btg102; Li T, 2004, BIOINFORMATICS, V20, P2429, DOI 10.1093/bioinformatics/bth267; Liu X., 2005, BMC BIOINFORMATICS, V6, P76; Lonning PE, 2005, NAT CLIN PRACT ONCOL, V2, P26, DOI 10.1038/ncponc0072; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; Ramaswamy S, 2003, NAT GENET, V33, P49, DOI 10.1038/ng1060; SHI, 1998, EV COMP P IEEE WORLD, P69; Tahir MA, 2007, PATTERN RECOGN LETT, V28, P438, DOI 10.1016/j.patrec.2006.08.016; Tan SB, 2006, EXPERT SYST APPL, V30, P290, DOI 10.1016/j.eswa.2005.07.019; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Wang XY, 2007, PATTERN RECOGN LETT, V28, P459, DOI 10.1016/j.patrec.2006.09.003; Wang Y, 2005, COMPUT BIOL CHEM, V29, P37, DOI 10.1016/j.compbiolchem.2004.11.001	27	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576	978-1-4244-1820-6	IEEE IJCNN			2008							2147	2152				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	BIY81	WOS:000263827201089	
S	Ang, KK; Chin, ZY; Zhang, HH; Guan, CT			IEEE	Ang, Kai Keng; Chin, Zheng Yang; Zhang, Haihong; Guan, Cuntai			Filter Bank Common Spatial Pattern (FBCSP) in Brain-Computer Interface	2008 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-8	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	JUN 01-08, 2008	Hong Kong, PEOPLES R CHINA	IEEE			SINGLE-TRIAL EEG; MOTOR IMAGERY; CLASSIFICATION; MOVEMENT; DESYNCHRONIZATION; COMMUNICATION; SELECTION; ROUGH	In motor imagery-based Brain Computer Interfaces (BCI), discriminative patterns can be extracted from the electroencephalogram (EEG) using the Common Spatial Pattern (CSP) algorithm. However, the performance of this spatial filter depends on the operational frequency band of the EEG. Thus, setting a broad frequency range, or manually selecting a subject-specific frequency range, are commonly used with the CSP algorithm. To address this problem, this paper proposes a novel Filter Bank Common Spatial Pattern (FBCSP) to perform autonomous selection of key temporal-spatial discriminative EEG characteristics. After the EEG measurements have been bandpass-filtered into multiple frequency bands, CSP features are extracted from each of these bands. A feature selection algorithm is then used to automatically select discriminative pairs of frequency bands and corresponding CSP features. A classification algorithm is subsequently used to classify the CSP features. A study is conducted to assess the performance of a selection of feature selection and classification algorithms for use with the FBCSP. Extensive experimental results are presented on a publicly available dataset as well as data collected from healthy subjects and unilaterally paralyzed stroke patients. The results show that FBCSP, using a particular combination feature selection and classification algorithm, yields relatively higher cross-validation accuracies compared to prevailing approaches.	[Ang, Kai Keng; Chin, Zheng Yang; Zhang, Haihong; Guan, Cuntai] ASTAR, Inst Infocomm Res, Singapore 119613, Singapore	Ang, KK (reprint author), ASTAR, Inst Infocomm Res, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.	kkang@i2r.a-star.edu.sg; zychin@i2r.a-star.edu.sg; hhzhang@i2r.a-star.edu.sg; ctguan@i2r.a-star.edu.sg					Ang K. K., 2006, P IJCNN 06, P742; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Birbaumer N, 2006, CLIN NEUROPHYSIOL, V117, P479, DOI 10.1016/j.clinph.2005.11.002; Blankertz B, 2007, NEUROIMAGE, V37, P539, DOI 10.1016/j.neuroimage.2007.01.051; Blankertz B., 2005, BCI COMPETITION 3; Bowman A. W., 1997, APPL SMOOTHING TECHN; Breiman L, 1984, CLASSIFICATION REGRE; Casillas J., 2003, INTERPRETABILITY ISS; Cover T., 2006, ELEMENTS INFORM THEO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dornhege G, 2006, IEEE T BIO-MED ENG, V53, P2274, DOI 10.1109/TBME.2006.883649; Dornhege G, 2004, IEEE T BIO-MED ENG, V51, P993, DOI 10.1109/TBME.2004.827088; Duda R. O., 2001, PATTERN CLASSIFICATI; Fukunaga K., 1990, INTRO STAT PATTERN R; Jensen R, 2004, IEEE T KNOWL DATA EN, V16, P1457, DOI 10.1109/TKDE.2004.96; JENSEN R, 2007, IEEE T FUZZ IN PRESS; Kandel ER, 1995, ESSENTIALS NEURAL SC; Kasabov NK, 2002, IEEE T FUZZY SYST, V10, P144, DOI 10.1109/91.995117; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Lemm S, 2005, IEEE T BIO-MED ENG, V52, P1541, DOI 10.1109/TBME.2005.851521; Muller-Gerking J, 1999, CLIN NEUROPHYSIOL, V110, P787, DOI 10.1016/S1388-2457(98)00038-8; Novi Q., 2007, 3 INT IEEE EMBS C NE, P204; Pawlak Z., 1991, ROUGH SETS THEORETIC; Penfield W, 1950, CEREBRAL CORTEX MAN; Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8; Pfurtscheller G, 2001, P IEEE, V89, P1123, DOI 10.1109/5.939829; PFURTSCHELLER G, 1979, ELECTROEN CLIN NEURO, V46, P138, DOI 10.1016/0013-4694(79)90063-4; Ramoser H, 2000, IEEE T REHABIL ENG, V8, P441, DOI 10.1109/86.895946; Rebsamen B, 2007, IEEE INTELL SYST, V22, P18, DOI 10.1109/MIS.2007.26; Schnitzler A, 1997, NEUROIMAGE, V6, P201, DOI 10.1006/nimg.1997.0286; Swiniarski RW, 2003, PATTERN RECOGN LETT, V24, P833, DOI 10.1016/S0167-8655(02)00196-4; Vapnik V.N., 1998, STAT LEARNING THEORY; Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3	33	25	25	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576	978-1-4244-1820-6	IEEE IJCNN			2008							2390	2397				8	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	BIY81	WOS:000263827201126	
S	Oentaryo, RJ; Pasquier, M			IEEE	Oentaryo, Richard J.; Pasquier, Michel			A Reduced Rule-Based Localist Network for Data Comprehension	2008 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-8	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	JUN 01-08, 2008	Hong Kong, PEOPLES R CHINA	IEEE			YAGER-INFERENCE; FUZZY-LOGIC; CONTROLLER; ALGORITHM; SYSTEM; FCMAC	Localist networks and especially neuro-fuzzy systems constitute promising techniques for data comprehension, but generally exhibit poor system interpretability and generatization ability. This paper aims at addressing the issues through a novel localist Reduced Fuzzy Cerebellar Model Articulation Controller (RFCMAC), that models the two-stage development of cortical memories in the human brain to compress and refine the formulated (fuzzy) rule base respectively. The proposed mechanisms allow the RFCMAC associative memory to induce a concise, interpretable rule base, and at the same time to improve generalization, fostering in turn system scalabitity and robustness. Experimental results on several benchmark tasks have demonstrated the potential of the proposed system as an effective tool for understanding data.	[Oentaryo, Richard J.; Pasquier, Michel] Nanyang Technol Univ, Sch Controller Engn, Ctr Computat Intelligence, Singapore 639798, Singapore	Oentaryo, RJ (reprint author), Nanyang Technol Univ, Sch Controller Engn, Ctr Computat Intelligence, Nanyang Ave, Singapore 639798, Singapore.	asmbpasquier@ntu.edu.sg					ADELSONVELSKII GM, 1962, DOKL AKAD NAUK SSSR+, V146, P263; ALBUS JS, 1975, J DYNAMIC SYSTEMS ME, V97; Ang KK, 2005, NEURAL COMPUT, V17, P205, DOI 10.1162/0899766052530857; Ang KK, 2003, IEEE T SYST MAN CY B, V33, P838, DOI 10.1109/TSMCB.2003.812850; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duch W., 2004, P IEEE, V92; Duda R.O., 2000, PATTERN CLASSIFICATI; Fisher RA, 1936, ANN EUGENIC, V7, P179; Goldman RN, 1985, STAT INTRO; GUO Z, 2006, P IEEE C EV COMP CEC, P2375; Hall M.A., 1999, THESIS U WAIKATO; Hebb D O, 1949, ORG BEHAV; JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541; Juang CF, 1998, IEEE T FUZZY SYST, V6, P12; Kandel E. R., 2000, PRINCIPLES NEURAL SC; Kasabov N, 2001, IEEE T SYST MAN CY B, V31, P902, DOI 10.1109/3477.969494; KELLER JM, 1992, FUZZY SET SYST, V45, P1, DOI 10.1016/0165-0114(92)90086-J; Lin CJ, 1997, IEEE T FUZZY SYST, V5, P477; Lin CT, 1996, NEURAL FUZZY SYSTEMS; Liu F, 2007, NEURAL COMPUT, V19, P1656, DOI 10.1162/neco.2007.19.6.1656; Mamdani EH, 1999, INT J HUM-COMPUT ST, V51, P135, DOI 10.1006/ijhc.1973.0303; NAKANISHI H, 1993, FUZZY SET SYST, V57, P257, DOI 10.1016/0165-0114(93)90024-C; NIE JH, 1994, AUTOMATICA, V30, P655, DOI 10.1016/0005-1098(94)90154-6; OENTARYO RJ, EXPERT SYST IN PRESS; Pal SK, 1998, IEEE T SYST MAN CY B, V28, P816, DOI 10.1109/3477.735391; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Platt J, 1998, ADV KERNEL METHODS S; Powell MJD, 1987, ALGORITHMS APPROXIMA, P143; Quek C, 2005, EXPERT SYST APPL, V29, P229, DOI 10.1016/j.eswa.2005.03.001; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sim J, 2006, IEEE T NEURAL NETWOR, V17, P1394, DOI 10.1109/TNN.2006.880362; Smola A. J., 1998, NEUROCOLT2 TECHNICAL; VUORIMAA P, 1994, FUZZY SET SYST, V66, P223, DOI 10.1016/0165-0114(94)90312-3; WANG ZQ, 1996, P IEEE INT C NEUR NE, V3, P1698; Widrow B., 1985, ADAPTIVE SIGNAL PROC	35	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576	978-1-4244-1820-6	IEEE IJCNN			2008							2660	2667		10.1109/IJCNN.2008.4634171		8	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	BIY81	WOS:000263827201167	
S	Barros, ACA; Cavalcanti, GDC			IEEE	Barros, Adelia C. A.; Cavalcanti, George D. C.			Combining Global Optimization Algorithms with a Simple Adaptive Distance for Feature Selection and Weighting	2008 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-8	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	JUN 01-08, 2008	Hong Kong, PEOPLES R CHINA	IEEE				This work focuses on a study about hybrid optimization techniques for improving feature selection and weighting applications. For this purpose, two global optimization methods were used: Tabu Search(TS) and Simulated Annealing (SA). These methods were combined to k-Nearest Neighbor (k-NN) composing two hybrid approaches: SA/k-NN and TS/k-NN. Those approaches try to use the main advantage from the global optimization methods: they work efficiently in searching for solutions in the global space. In this study, the methodology is proposed by [4]. In the referred work, a hybrid TS/k-NN approach was suggested and successfully applied for feature selection and weighting problems. Based on the later, this analysis indicates a new SA/k-NN combination and compares their results using the classical Euclidean Distance and a Simple Adaptive Distance [8]. The results demonstrate that feature sets optimized by the studied models are very efficient when compared to the well-known k-NN. Both accuracy classification and number of features in the resultant set are considered in the conclusions. Furthermore, the combined use of the Simple Adaptive Distance improves even more the results for all datasets analyzed.	[Barros, Adelia C. A.; Cavalcanti, George D. C.] Univ Fed Pernambuco, CIn, BR-50740540 Recife, PE, Brazil	Barros, ACA (reprint author), Univ Fed Pernambuco, CIn, POB 7851, BR-50740540 Recife, PE, Brazil.	acab@cin.ufpe.br; gdcc@cin.ufpe.br					Asuncion A., UCI MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GLOVER F, 1986, COMPUT OPER RES, V13, P533, DOI 10.1016/0305-0548(86)90048-1; Hansen P., 1986, C NUM METH COMB OPT; Jain A. K., 1996, IEEE COMPUTER    MAR, P31; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Michie D, 1994, MACHINE LEARNING NEU; Pham D. T., 2000, INTELLIGENT OPTIMISA, P1; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; Tahir MA, 2007, PATTERN RECOGN LETT, V28, P438, DOI 10.1016/j.patrec.2006.08.016; Wang JG, 2007, PATTERN RECOGN LETT, V28, P207, DOI 10.1016/j.patrec.2006.07.002; Yao X, 1999, P IEEE, V87, P1423; Zhang HB, 2002, PATTERN RECOGN, V35, P701, DOI 10.1016/S0031-3203(01)00046-2	14	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576	978-1-4244-1820-6	IEEE IJCNN			2008							3518	3523		10.1109/IJCNN.2008.4634300		6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	BIY81	WOS:000263827202060	
S	Alippi, C; Fuhrman, M; Roveri, M			IEEE	Alippi, C.; Fuhrman, M.; Roveri, M.			k-NN classifiers: investigating the k = k (n) relationship	2008 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-8	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	JUN 01-08, 2008	Hong Kong, PEOPLES R CHINA	IEEE				The paper proposes a theory-based method for estimating the optimal value of k in k-NN classifiers based on a n-sized training set. As expected, experiments show that the suggested k is such that k/n -> 0 when both k and n tend to infinity, as required by the asymptotical consistency condition. Interestingly, it appears that the generalization error is robust w.r.t. to k when n becomes large (probably as a consequence of the k/n -> 0 relationship); the immediate consequence is that there is no need to provide an accurate estimate for the optimal k and an approximated coarser value, eg., provided with cross validation, 1-fold cross validation or leave one out is more than adequate.	[Alippi, C.; Roveri, M.] Politecn Milan, Dipartimento Elettron & Informaz, I-20133 Milan, Italy	Alippi, C (reprint author), Politecn Milan, Dipartimento Elettron & Informaz, I-20133 Milan, Italy.	alippi@elet.polimi; marco.fuhrman@polimi.it; roveri@elet.polimi					ALIPPI C, 2007, NEUR NETW 2007 IJCNN, P1008; ALIPPI C, 2008, K NN CLASSIFIERS INV; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devroye L, 1996, PROBABILISTIC THEORY; Fukunaga K, 1972, INTRO STAT PATTERN R; FUKUNAGA K, 1973, IEEE T INF THEORY, V19; Ghosh AK, 2005, IEEE T PATTERN ANAL, V27, P1592, DOI 10.1109/TPAMI.2005.204; KEANS M, 1999, NEURAL COMPUT, V11, P1427; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; Mood A.M., 1963, INTRO THEORY STAT; STONE C, 1977, ANN STAT, V8, P1348	11	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576	978-1-4244-1820-6	IEEE IJCNN			2008							3676	3680		10.1109/IJCNN.2008.4634324		5	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	BIY81	WOS:000263827202084	
S	He, J; Zhao, HZ; Fu, Q			IEEE	He Jun; Zhao Hong-zhong; Fu Qiang			ATR Performance Assessment of Target Type Number for HRR Radar	2008 IEEE RADAR CONFERENCE, VOLS. 1-4	IEEE Radar Conference		English	Proceedings Paper	2008 IEEE Radar Conference	MAY 26-30, 2008	Rome, ITALY	IEEE, FINMECCANICA, SELEX, Agilent Technol, Dappolonia, Gedae, IDS, IET, MBDA, McGraw Hill, Natl Instruments, Off Naval Res, Sci & Technol, ROHDE & SCHWARZ, Tektronix, Thales Alenia, altran, ACCSCO, Raytheon		automatic target recognition (ATR); performance; evaluation	SAR ATR; CLASSIFICATION; MODEL	Automatic target recognition (ATR) performance evaluation has become an important subject in ATR theory community since the last two decades. The extended operation condition (EOC) and system cost are two key aspects in ATR performance evaluation. For the situation of air-to-ground (A-G) ATR using high range resolution (HRR) data, this paper analyzes the influence of target type number on ATR system performance. The system cost is also considered in evaluation process. An experiential performance model of typical ATR systems is given. The performance model and the corresponding conclusions have useful reference to ATR system performance prediction and assessment in the similar A-G applications.	[He Jun; Zhao Hong-zhong; Fu Qiang] Natl Univ Def Technol, ATR Lab, Changsha 410073, Hunan, Peoples R China	He, J (reprint author), Natl Univ Def Technol, ATR Lab, Changsha 410073, Hunan, Peoples R China.	hisjune@163.com					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUBA RO, 2004, PATTERN CLASSIFICATI; EISENBIES CL, 1994, THESIS AIR FORCE I T; Fukunaga K., 1990, INTRO STAT PATTERN R; GAO Q, 2004, INT C RAD SYST TOUL; Jacobs SP, 2000, IEEE T AERO ELEC SYS, V36, P364, DOI 10.1109/7.845214; Mishra AK, 2006, INT CONF ACOUST SPEE, P1104; MITCHELL RA, 1994, OVERVIEW HIGH RANGE; Mossing JC, 1998, P SOC PHOTO-OPT INS, V3370, P554, DOI 10.1117/12.321858; O'Sullivan JA, 2001, IEEE T AERO ELEC SYS, V37, P91, DOI 10.1109/7.913670; Ross TD, 1999, P SOC PHOTO-OPT INS, V3721, P662, DOI 10.1117/12.357681; Ross TD, 2002, P SOC PHOTO-OPT INS, V4727, P310, DOI 10.1117/12.478692; Ross TD, 1997, P SOC PHOTO-OPT INS, V3070, P213, DOI 10.1117/12.281559	13	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1097-5764	978-1-4244-1538-0	IEEE RAD CONF			2008							1399	1403				5	Remote Sensing; Telecommunications	Remote Sensing; Telecommunications	BJC08	WOS:000264663001051	
B	Richert, W; Niehorster, O; Koch, M		Chatila, R; Kelly, A; Merlet, JP		Richert, Willi; Niehoerster, Oliver; Koch, Markus			Layered understanding for sporadic imitation in a multi-robot scenario	2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS			English	Proceedings Paper	IEEE/RSJ International Conference on Intelligent Robots and Systems	SEP 22-26, 2008	Nice, FRANCE	IEEE, Robot Soc Japan, IEEE Robot & Automat Soc, IEEE Ind Elect Soc, Soc Instrument & Control Engineers, Inst Natl Rech Informat & Automat, CNRS, Inst Control, Roibot & Syst				With imitation robots have a powerful means to drastically cut down the exploration space. However, as existing imitation approaches usually require repetitive demonstrations of the skill to learn in order to be useful, those are typically not applicable in groups of robots. In these scenarios usually each robot has its own task to accomplish and should not he disturbed by teaching others. Therefor, most of the time an imitating robot has only one observed performance of the behavior from which it can learn. Utilisation of these sparse observation data has largely been ignored. We present an approach that allows an individually learning robot to make use of such cases of sporadic imitation which is often the only possibility to learn from other robots in a group. The power of the algorithm comes from the fact that it uses the robots already known skills and strategies to understand the observed behavior. Thereby, a robot can use imitation in order to guide its exploration efforts towards more rewarding areas in the exploration space. This is inspired by imitation often found in nature where animals or humans try to map observations into their own capability space. We	[Richert, Willi; Niehoerster, Oliver; Koch, Markus] Univ Paderbom, Fac Comp Sci Elect Engn & Math, Paderborn, Germany	Richert, W (reprint author), Univ Paderbom, Fac Comp Sci Elect Engn & Math, Paderborn, Germany.						Alpaydin E, 2004, INTRO MACHINE LEARNI; ARBIB MA, 2001, MIRROR SYSTEM IMITAT; Bellman R., 2003, DYNAMIC PROGRAMMING; Bengio Y., 1999, NEURAL COMPUTING SUR, V2, P129; Bentivegna DC, 2001, IEEE INT CONF ROBOT, P1988; Billard A, 2004, ROBOT AUTON SYST, V47, P69, DOI 10.1016/j.robot.2004.03.002; BILLARD A, 2000, LEARNING MOTOR SKILL; BORENSTEIN E, 2003, 2 INT S IM AN ART; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Demiris J, 2002, FROM ANIM ANIMAT, P327; Gallese V, 1998, TRENDS COGN SCI, V2, P493, DOI 10.1016/S1364-6613(98)01262-5; Gatsoulis Y., 2002, Proceedings of the Second IASTED International Conference. Artificial Intelligence and Applications; IJSPEERT JA, 2002, INT C ROB AUT ICRA 2; INAMURA T, 2003, EXPT ROBOTICS, V8; KOCHENDERFER MJ, 2006, THESIS U EDINBURGH; NISHI T, 2007, IEEE RSJ INT C INT R, P70; PERERA M, 2007, IEEE RSJ INT C INT R, P1409; RICHERT W, 2008, INT C AUT AUT SYST I; Richert W, 2005, LECT NOTES COMPUT SC, V3644, P1004; Rowels S. T., 2000, NONLINEAR DIMENSIONA; Sutton R. S., 1998, REINFORCEMENT LEARNI; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010	23	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-2057-5				2008							1287	1292		10.1109/IROS.2008.4650817		6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Robotics	Computer Science; Engineering; Robotics	BIJ26	WOS:000259998200202	
S	Remus, JJ; Morton, KD; Torrione, PA; Tantum, SL; Collins, LA			IEEE	Remus, Jeremiah J.; Morton, Kenneth D.; Torrione, Peter A.; Tantum, Stacy L.; Collins, Leslie A.			Comparison of a distance-based likelihood ratio test and k-nearest neighbor classification methods	2008 IEEE WORKSHOP ON MACHINE LEARNING FOR SIGNAL PROCESSING	IEEE Workshop on Machine Learning for Signal Processing		English	Proceedings Paper	IEEE Workshop on Machine Learning for Signal Processing	OCT 16-19, 2008	Cancun, MEXICO	IEEE Signal Processing Soc, IEEE			PATTERN-CLASSIFICATION; RULE	Several studies of the k-nearest neighbor (KNN) classifier have proposed the use of non-uniform weighting on the k neighbors. It has been suggested that the distance to each neighbor can be used to calculate the individual weights in a weighted KNN approach; however, a consensus has not yet been reached on the best method or framework for calculating weights using the distances. In this paper, a distance likelihood ratio test will be discussed and evaluated using simulated data. The distance likelihood ratio test (DLRT) shares several characteristics with the distance-weighted k-nearest neighbor methods but approaches the use of distance from a different perspective. Results illustrate the ability of the distance likelihood ratio test to approximate the likelihood ratio and compare the DLRT to two other k-neighborhood classification rules that utilize distance-weigbting. The DLRT performs favorably in comparisons of the classification performance using the simulated data and provides an alternative non-parametric classification method for consideration when designing a distance-weighted KNN classification rule.	[Remus, Jeremiah J.; Morton, Kenneth D.; Torrione, Peter A.; Tantum, Stacy L.; Collins, Leslie A.] Duke Univ, ECE Dept, Durham, NC 27708 USA	Remus, JJ (reprint author), Duke Univ, ECE Dept, Durham, NC 27708 USA.	jjr6@ee.duke.edu; kdm@ee.duke.edu; pt@ee.duke.edu; slt@ee.duke.edu; lcollins@ee.duke.edu	Tantum, Stacy/E-1830-2011				Cantone D, 2005, IEEE T KNOWL DATA EN, V17, P535, DOI 10.1109/TKDE.2005.53; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Duda R.O., 2000, PATTERN CLASSIFICATI; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; FIX E, 1952, 11 USAF SCH AV MED, P280; Fix E., 1951, 4 USAF SCH AV MED, P261; FUKUNAGA K, 1989, IEEE T PATTERN ANAL, V11, P873, DOI 10.1109/34.31448; FUKUNAGA K, 1982, IEEE T PATTERN ANAL, V4, P427; Hattori K, 1999, PATTERN RECOGN, V32, P425, DOI 10.1016/S0031-3203(98)00097-1; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Kolahdouzan M, 2004, P 30 INT C VER LARG, P840, DOI 10.1016/B978-012088469-8/50074-7; MACLEOD JES, 1987, IEEE T SYST MAN CYB, V17, P689, DOI 10.1109/TSMC.1987.289362; Seidl T., 1998, SIGMOD Record, V27	14	5	5	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1551-2541	978-1-4244-2375-0	MACHINE LEARN SIGN P			2008							362	367		10.1109/MLSP.2008.4685507		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BJK47	WOS:000266687900062	
B	Zhang, L; Ye, N; Zhou, WD; Jiao, LC			IEEE	Zhang, Li; Ye, Ning; Zhou, Weida; Jiao, Licheng			Support Vectors Pre-extracting for Support Vector Machine Based on K Nearest Neighbour Method	2008 INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, VOLS 1-4			English	Proceedings Paper	IEEE International Conference on Information and Automation	JUN 20-23, 2008	Changsha, PEOPLES R CHINA	IEEE Robot & Automat Soc, CHUK NUDT Joint Ctr Intelligent Sensing & Syst, Natl Univ Def Technol, Sch Elect Sci & Engn, Natl Sci Fdn China, CAS, Inst Intelligent Machines, IEEE Hong Kong Joint Chapter Robot & Automat & Control Syst, Natl Univ Def Technol, Sch Mechatron Engn & Automat		support vector machine; K nearest neighbour; pre-extracting		Support vector machine, a universal method for learning from data, gains its development based on statistical learning theory. It shows many advantages in solving nonlinearly small sample and high dimensional problems of pattern recognition. Only a part of samples or support vectors (SVs) plays an important role in the final decision function. But SVs could not be obtained in advance until a quadratic programming is performed. In this paper, we use K-nearest neighbour method to extract a boundary vector set which may contain SVs. The number of the boundary set is smaller than the whole training set. Consequently it reduces the training samples, speeds up the training of support vector machine.	[Zhang, Li] Xidian Univ, Inst Intelligent Informat Proc, Xian 710071, Shaanxi Prov, Peoples R China	Zhang, L (reprint author), Xidian Univ, Inst Intelligent Informat Proc, Xian 710071, Shaanxi Prov, Peoples R China.	zhangli@mail.xidian.edu.cn; ye-ning@hotmail.com; wdzhou@mail.xidian.edu.cn; lchjiao@mail.xidian.edu.cn					Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P1, DOI [DOI 10.1023/A:1009715923555, 10.1023/A:1009715923555]; Cherkassky V, 1997, LEARNING DATA CONCEP; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DING AL, 2002, COMPUTER ENG APPL, V19, P116; EDGAR O, 1997, P IEEE NNSP 97 AM IS, P24; Jiao Li-Cheng, 2001, Acta Electronica Sinica, V29; Li Qing, 2005, Chinese Journal of Computers, V28; [裴继红 Pei Jihong], 2003, [电子与信息学报, Journal of electronics & information technology], V25, P1494; Vapnik V.N., 1995, NATURE STAT LEARNING; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Wu Zhong-dong, 2004, Journal of Fudan University (Natural Science), V43; ZHOU YL, 2006, AERONAUTICAL COMPUTI, V36, P62	12	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-2183-1				2008							1353	1358				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic; Robotics	Automation & Control Systems; Computer Science; Engineering; Robotics	BIQ50	WOS:000262054600256	
B	Kruatrachue, B; Hongsamart, M			IEEE	Kruatrachue, Boontee; Hongsamart, Marut			Prototype Selection based on Minimal Consistent Subset and Genetic Algorithms	2008 PROCEEDINGS OF SICE ANNUAL CONFERENCE, VOLS 1-7			English	Proceedings Paper	Annual Conference of the SICE	AUG 20-22, 2008	Chofu, JAPAN			prototype selection; minimal consistent subset; genetic algorithms; consistency property; nearest neighbor rule	NEAREST-NEIGHBOR RULE; CLASSIFICATION; SEARCH	This paper applies the genetic algorithms to identify the minimal "consistent" prototype subset [1]. This subset can be used as a prototype which correctly recognizes the entire original prototype set. This proposed genetic algorithm tries to find the minimal consistent subset to reduce recognition time in nearest neighbor [2] classification. The main difference from other genetic algorithm (GA) approaches is the hybrid of minimal consistent set identification (MCSI) method [3] and genetic algorithm. The MCSI method provides the local optimal number of prototype while the Genetic performs the global search. The proposed hybrid algorithm has been tested on several problems and compared with the results of MCSI and other GA approach [4].	[Kruatrachue, Boontee; Hongsamart, Marut] King Mongkuts Inst Technol Ladkrabang, Fac Engn, Dept Comp Engn, Bangkok, Thailand	Kruatrachue, B (reprint author), King Mongkuts Inst Technol Ladkrabang, Fac Engn, Dept Comp Engn, Bangkok, Thailand.	booontee@yahoo.com; mnemonic329@hotmail.com					Cerveron V, 2001, IEEE T SYST MAN CY B, V31, P408, DOI 10.1109/3477.931531; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KANGKAN K, 2006, MINIMAL CONSISTENT S; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; MOLLINEDA RA, 2000, P 4 WORLD MULT SYST, P640; *U CA DEP INF COMP, 1998, UCI MACH LEARN REP	8	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-4-907764-30-2				2008							647	651				5	Automation & Control Systems; Instruments & Instrumentation	Automation & Control Systems; Instruments & Instrumentation	BIZ59	WOS:000263966700132	
S	Qi, YN; Atallah, MJ				Qi, Yinian; Atallah, Mikhail J.			Efficient Privacy-Preserving k-Nearest Neighbor Search	28TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS, VOLS 1 AND 2, PROCEEDINGS	INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS - PROCEEDINGS		English	Proceedings Paper	28th International Conference on Distributed Computing Systems	JUN 17-20, 2008	Beijing, PEOPLES R CHINA	IEEE				We give efficient protocols for secure and private k-nearest neighbor (k-NN) search, when the data is distributed between two parties who want to cooperatively compute the answers without revealing to each other their private data. Our protocol for the single-step k-NN search is provably secure and has linear computation and communication complexity Previous work on this problem had a quadratic complexity, and also leaked information about the parties' inputs. We adapt our techniques to also solve the general multi-step k-NN search, and describe a specific embodiment of it for the case of sequence data. The protocols and correctness proofs can be extended to suit other privacy-preserving data mining tasks, such as classification and outlier detection.	[Qi, Yinian; Atallah, Mikhail J.] Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA	Qi, YN (reprint author), Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA.	yqi@cs.purdue.edu; mja@cs.purdue.edu					AGGARWAL CC, SIGMOD 01; Atallah M, 2003, WPES 03, P39; BERCHTOLD S, 1998, IEEE INT C DAT ENG 1, P209; Canetti R, 2000, J CRYPTOL, V13, P143, DOI 10.1007/s001459910006; CLIFTON C, 2002, SIGKDD EXPLORATIONS, P28; Cormen T. H., 2001, INTRO ALGORITHMS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Damgard I, 2006, LECT NOTES COMPUT SC, V3876, P285; DU W, 2001, P 17 ANN COMP SEC AP, P102; Goethals B, 2004, LECT NOTES COMPUT SC, V3506, P104; Goldreich O., 2004, FDN CRYPTOGRAPHY, V2; Goldreich O, 1996, J ACM, V43, P431, DOI 10.1145/233551.233553; Kantarcioglu M, 2004, IEEE T KNOWL DATA EN, V16, P1026, DOI 10.1109/TKDE.2004.45; KANTARCIOGLU M, 2004, PKDD2004, P279; Kleinberg J.M., 1997, STOC 97, P599; LINDELL Y, 2000, CRYPTO; Malkhi D, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE 13TH USENIX SECURITY SYMPOSIUM, P287; NEEDLEMAN S, 1970, J MOL BIOL, P443; Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223; RAMASWAMY S, 2000, SIGMOD, P427; Roussopoulos N., 1995, SIGMOD, P71; Seidl T., 1997, VLDB J, P506; Seidl T., 1998, SIGMOD C, P154; SHANECK M, 2006, ICDMW 06, P541; TENG Z, 2007, PAKDD, P296; VAIDYA J, 2003, PRIVACY PRESERVING K; VAIDYA J, 2004, ICDM 04, P233; Verykios VS, 2004, SIGMOD REC, V33, P50; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; XIONG L, 2007, SAC 07, P435; YAO AC, 1998, P 23 IEEE S FDN COMP, P160; YAO AC, 1986, P 27 IEEE S FDN COMP, V27	32	8	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1063-6927	978-1-4244-3174-8	INT CON DISTR COMP S			2008							311	319		10.1109/ICDCS.2008.79		9	Computer Science, Theory & Methods	Computer Science	BIW60	WOS:000263415700037	
B	Kumar, MS; Selvarajan, S; Balu, S			IEEE	Kumar, M. Sayee; Selvarajan, S.; Balu, S.			ANODR Based Anomaly Detection for Black Hole and Route Disrupt Attacks	ICCN: 2008 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND NETWORKING			English	Proceedings Paper	International Conference on Computing, Communications and Networking	DEC 18-20, 2008	Karur, INDIA					An Anonymous on Demand Routing Protocol (ANODR) was designed based on the previous studies as the countermeasure for preventing passive attacks. ANODR is a purely on demand routing and identity free routing scheme that sets up an anonymous route as needed in real time. The proposed protocol ensures node privacy, route anonymity and location privacy and is robust against several known attacks. This limits the chances of eavesdropping and traffic analyzing to a time-critical on-demand window. Anonymity is one of the important characteristics in securing a wireless adhoc network routing. In this paper we study the unique anonymity threats in wireless adhoc environments. Two design principles of anonymous routing - Anonymous route discovery and Anonymous data forwarding are presented here. In the Anonymous route discovery design, a random route pseudonym for an on demand route is established. In the Anonymous data forwarding design, the source wraps its data packets for each end to end connection. This was implemented and tested using NS-2.0 simulator. The behavior of the proposed system has been studied for analysis like Packet delivery ratio, Packet delay and Overhead along with the existing system.	[Kumar, M. Sayee; Selvarajan, S.; Balu, S.] Paavai Engn Coll, Namakkal, India	Kumar, MS (reprint author), Paavai Engn Coll, Namakkal, India.	contact2sayee@gmail.com; asselvarajan@rediffmail.com; sbalu26@gmail.com					Banerjee S., 2001, P IEEE INFOCOM APR; Basagni S., 1999, INT S PAR ARCH ALG N; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deng H., 2006, P 12 INT C PAR DISTR; Deng HM, 2002, IEEE COMMUN MAG, V40, P70; FALL K, 2000, NS MANUAL FORMELY NS; Huang Y., 2003, P 23 INT C DISTR COM; Huang Y., 2003, P 1 ACM WORKSH SEC A, P135, DOI 10.1145/986858.986877; Krishna P., 1997, ACM SIGCOMM COMPUTER; LI JH, 2005, P INT C MOB AD HOC S; Marti S, 2000, P 6 ANN INT C MOB CO, P255, DOI DOI 10.1145/345910.345955; Sterne D., 2005, P 3 IEEE INT WORKSH, P57; TRAN QA, 2003, P 2003 IEEE INT C SY, P2388; Vapnik N.V., 1998, STAT LEARNING THEORY; Younis Ossama, 2004, IEEE T MOBILE COMPUT, V3	15	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-3594-4				2008							199	203				5	Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BKH76	WOS:000268136000033	
B	Oh, JS; Choi, KS; Kwon, JR; Lee, SH		Lee, G; Ahn, TN; Howard, D; Slezak, D		Oh, Jeong Seok; Choi, Kyung Suhk; Kwon, Jeong Rock; Lee, Sang Ho			Finding the near Workload Type between TPC-C and TPC-W Environments	ICHIT 2008: INTERNATIONAL CONFERENCE ON CONVERGENCE AND HYBRID INFORMATION TECHNOLOGY, PROCEEDINGS			English	Proceedings Paper	International Conference on Convergence and Hybrid Information Technology	AUG 28-29, 2008	Daejeon, SOUTH KOREA	SERC, Korean Informat Assoc Soc				Database system can be performed more than a database application and shown peculiar workload characteristics as a database application. However, as a database system can be performed a lot of database applications, detecting workload characteristics might be more difficult. This paper proposes the method of finding near workload characteristics by mixed workloads. The workload find method is evaluated by the modified k-NN algorithm that is an extension of the existing the fuzzy k-NN algorithm. The modified k-NN algorithm measures how close workloads in TPC-C or TPC-W are to the mixed workloads between TPC-C and TPC-W. Furthermore, the result of our method is better than others for finding near workloads because its results are lower than others in the oscillation depending on the k parameter and the error rate. This study is able to contribute to finding similar information for providing autonomic database analysis and intelligent service in ubiquitous environments.	[Oh, Jeong Seok] Korea Gas Safety Corp, Inst Gas Safety R&D, Shihung, Gyenggi Do, South Korea	Oh, JS (reprint author), Korea Gas Safety Corp, Inst Gas Safety R&D, Shihung, Gyenggi Do, South Korea.						BAYLIS R, 2002, DATABASE ADM GUIDE R; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CYRAN M, 2001, ORACLE 9I DATABASE P; ELNAFFAR S, 2002, P CASCON C TOR CAN; Elnaffar S., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; Han J., 2001, DATA MINING CONCEPTS; Han J. H., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), DOI 10.1109/CVPR.1999.784711; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Martin P., 2002, International Journal on Digital Libraries, V3, DOI 10.1007/s007990100046; OH JS, 2004, J KISS D, V11, P747; *TPC, 2002, TPC BENCHM W WEB COM; *TPC, 2001, TPC BENCHM C SPEC RE	12	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		978-0-7695-3328-5				2008							334	337				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Robotics; Remote Sensing	Computer Science; Engineering; Robotics; Remote Sensing	BIK58	WOS:000260412900057	
B	Puteh, M; Omar, K; Hamdan, AR; Abu Bakar, A		Zaman, HB; Sembok, TMT; VanRijsbergen, K; Zadeh, L; Buza, P; Shih, T; Taib, MN		Puteh, Mazidah; Omar, Khairuddin; Hamdan, Abdul Razak; Abu Bakar, Azuraliza			Classifying Heterogeneous Data With Artificial Immune System	INTERNATIONAL SYMPOSIUM OF INFORMATION TECHNOLOGY 2008, VOLS 1-4, PROCEEDINGS: COGNITIVE INFORMATICS: BRIDGING NATURAL AND ARTIFICIAL KNOWLEDGE			English	Proceedings Paper	International Symposium on Information Technology	AUG 26-29, 2008	Kuala Lumpur, MALAYSIA	IEEE	Univ Kebangsaan, Fac Informat Sci & Technol			Artificial Immune System (AIS) is an emerging technique for the classification task and proved to be a reliable technique. In the previous researches, mainly classifiers including AIS classifiers require the data to be in numerical or categorical data types prior to processing. The transformation of data into any other specific types from their original form can degrade the originality of the data and consume more space and pre processing time. This paper introduces AIS model using clonal selection technique for classifying heterogeneous data in its original types. The model is able to process the data with the types as represented in the database and it solves some problems highlighted in the AIS reviews. To ensure the consistent conditions and fair comparison, the selected algorithms uses the same set of data as used in the proposed model. Experimental results show that this model produces a better accuracy rate than other immune algorithm and comparable to the standard classifiers on most of the benchmark data from UCI Machine Learning Repository.	[Puteh, Mazidah] Univ Teknol MARA, FTMSK, Terenggamu, Malaysia	Puteh, M (reprint author), Univ Teknol MARA, FTMSK, Terenggamu, Malaysia.						BROWNLEE J, 2005, 102 SWINB U TECHN FA; BROWNLEE J, 2005, 102 U TECHN FAC ICT; CARTER JH, 2000, J AM MED INFORM ASS, V7; Coakes SJ, 2003, SPSS ANAL ANGUISH VE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY, 1991, NEAREST NEIGHBOR NN; DASGUPTA D, 2006, IEEE COMPUTATIONAL I; De Castro L.N., 2000, CLONAL SELECTION ALG, P36; FREITAS A, 2007, IEEE T EVOLUTIONARY, V11, P4; HAMAKER J, 2004, P CEC2004; HART E, 2008, J APPL SOFT COMPUTIN, V8, P191; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hunt JE, 1996, J NETW COMPUT APPL, V19, P189, DOI 10.1006/jnca.1996.0014; Keogh E., 2006, UCR TIME SERIES DATA; MERZ C, 1998, UCI MACHINE LEARNING; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Timmis J., 2001, THESIS U WALES ABERY; Timmis J., 2002, ARTIFICIAL IMMUNE SY; Timmis J, 2006, LECT NOTES COMPUT SC, V3931, P355; WALKINS A, 2004, P ICARIS2004, P427; Watkins A., 2002, P 1 INT C ART IMM SY, P173; Watkins A., 2001, THESIS MISSISSIPPI S; Watkins A., 2004, Genetic Programming and Evolvable Machines, V5, DOI 10.1023/B:GENP.0000030197.83685.94; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; Witten I. H., 2005, DATA MINING	25	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-2327-9				2008							1877	1881				5	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Telecommunications	Computer Science; Telecommunications	BIK22	WOS:000260353301065	
B	Meher, SK				Meher, Saroj K.			A New Fuzzy Supervised Classification Method based on Aggregation Operator	SITIS 2007: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGIES & INTERNET BASED SYSTEMS			English	Proceedings Paper	IEEE International Conference on Signal Image Technology and Internet Based Systems	DEC 16-19, 2007	Shanghai, PEOPLES R CHINA	IEEE, IEEE Comp Soc, Shanghai Jiatong Univ, SIGAPP fr		Pattern recognition; fuzzy classifier; aggregation operators	REMOTE-SENSING IMAGES; PATTERN-CLASSIFICATION; ALGORITHM; RULES; SETS	A new fuzzy supervised classification method based on aggregation operator is proposed in the present article. The proposed classifier aggregates the information extracted by exploring feature-wise degree of belonging to classes. It uses a pi-type membership function and MEAN (average) aggregation reasoning rule (operator). The effectiveness of the proposed classifier is verified with four benchmark data sets including a realtime financial domain data. Various performance measures are used for quantitative evaluation of the classifier Experimental results on these data sets illustrate significant improvement in the classification performance of the proposed method compared to three other fuzzy classifiers, namely, explicit fuzzy, fuzzy k-nearest neighbor and fuzzy maximum likelihood.	Satyam Comp Serv Ltd, Appl Res Grp, Entrepreneurship Ctr, Bangalore 560012, Karnataka, India	Meher, SK (reprint author), Satyam Comp Serv Ltd, Appl Res Grp, Entrepreneurship Ctr, SID Block,IISc Campus, Bangalore 560012, Karnataka, India.						ABE S, 1995, IEEE T FUZZY SYST, V3, P18, DOI 10.1109/91.366565; ABONYI J, 2000, SIMPLE FUZZY CLASSIF; BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7; CHEN CF, 1999, P AS C REM SENS ACRS; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI; Haykin S, 1998, NEURAL NETWORKS COMP; ISHIBUCHI H, 1992, FUZZY SET SYST, V52, P21, DOI 10.1016/0165-0114(92)90032-Y; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Klir G.J., 1995, FUZZY SETS FUZZY LOG; KUNCHEVA LI, 2000, FUZZY CLASSIFIER DES; MEHER SK, 2006, P INT C INF TECHN, P209; Melgani F, 2000, IEEE T GEOSCI REMOTE, V38, P287, DOI 10.1109/36.823921; Newman D. J., 1998, UCI REPOSITORY MACHI; PEDRYCZ W, 1990, PATTERN RECOGN, V23, P121, DOI 10.1016/0031-3203(90)90054-O; Peneva V, 2003, FUZZY SET SYST, V139, P615, DOI [10.1016/S0165-0114(03)00141-6, 10.1016/S0165-01114(03)00141-6]; Dubois D, 2004, FUZZY SET SYST, V142, P143, DOI 10.1016/j.fss.2003.10.038; Tveter D. R., 1998, PATTERN RECOGNITION; van der Putten P., 2000, COIL CHALLENGE 2000; WANG F, 1990, IEEE T GEOSCI REMOTE, V28, P194, DOI 10.1109/36.46698; WATSON AB, 1993, DIGITAL IMAGE HUMAN; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	23	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		978-0-7695-3122-9				2008							876	882				7	Computer Science, Information Systems; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BII29	WOS:000259670300115	
B	Rouainia, M; Doghmane, N			IEEE	Rouainia, Mounira; Doghmane, Noureddine			Segmentation of Magnetic Resonance Images : A State of The Art	2008 3RD INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES: FROM THEORY TO APPLICATIONS, VOLS 1-5			English	Proceedings Paper	3rd International Conference on Information and Communication Technologies	APR 07-11, 2008	Damascus, SYRIA			Magnetic resonance image; segmentation; classification; regions of interest	BRAIN MR-IMAGES; AUTOMATIC SEGMENTATION; MULTIPLE-SCLEROSIS; CEREBRAL-CORTEX; TUMOR VOLUME; SURFACE; HEAD; SETS	Images segmentation constitutes a crucial task in magnetic resonance images analysis by automating and facilitating isolation of anatomical structures and other regions of interest. The purpose of this paper is to present a state of the art of current approaches dealing with anatomical magnetic resonance images segmentation. Emphasis will be placed on revealing the advantages and disadvantages of these methods for medical imaging applications.			rouainia_m@yahoo.fr					AMBROISE C, 1997, INTRO RECONNAISSANCE; Baillard C, 2001, MED IMAGE ANAL, V5, P185, DOI 10.1016/S1361-8415(01)00039-1; BAILLARD C, 2000, 1369 IRISA; Barra V, 2001, IEEE T MED IMAGING, V20, P549, DOI 10.1109/42.932740; Bedell BJ, 1998, MAGNET RESON MED, V39, P935, DOI 10.1002/mrm.1910390611; Bensaid AM, 1996, PATTERN RECOGN, V29, P859, DOI 10.1016/0031-3203(95)00120-4; Bezdek J., 1981, PATTERN RECOGNITION; BEZDEK JC, 1993, MED PHYS, V20, P1033, DOI 10.1118/1.597000; BOMANS M, 1990, IEEE T MED IMAGING, V9, P177, DOI 10.1109/42.56342; BOUCHONMEUNIER B, 1999, LOGIQUE FLOUE; BRUMMER ME, 1992, IEEE T MED IMAGING, V12, P90; CLARKE LP, 1995, MAGN RESON IMAGING, V13, P343, DOI 10.1016/0730-725X(94)00124-L; CLARKE LP, 1993, MAGN RESON IMAGING, V11, P95, DOI 10.1016/0730-725X(93)90417-C; COCQUEREZ JP, 1995, ANAL IMAGE FILTRAGE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAI DY, 1993, IEEE T MED IMAGING, V12, P693; DELLEPIANE S, 1991, 13 IEEE ENG MED BIOL, V13, P253; Duda R., 1973, PATTERN CLASSIFICATI; GERAUD T, 1998, THESIS ENST PARIS; GERIG G, 1991, LECT NOTES COMPUT SC, V511, P175; GERIG G, 1992, IMAGE VISION COMPUT, V10, P349, DOI 10.1016/0262-8856(92)90021-T; Ghanei A, 1998, COMPUT MED IMAG GRAP, V22, P203, DOI 10.1016/S0895-6111(98)00026-3; Held K, 1997, IEEE T MED IMAGING, V16, P878, DOI 10.1109/42.650883; Ho S., 2002, Proceedings 16th International Conference on Pattern Recognition, DOI 10.1109/ICPR.2002.1044788; HOJJATOLESLAMI A, 2001, IEEE T MED IMAGING, V20, P660; KAMBERT M, 1995, IEEE T MED IMAGING, P442; Kass M., 1988, INT J COMPUT VISION, P321; KIKINIS R, 1992, JMRI-J MAGN RESON IM, V2, P619, DOI 10.1002/jmri.1880020603; LI C, 1993, SPIE, V1905, P554; LUO S, 2003, WORKSH DIG IM COMP M, P9; MacDonald D, 2000, NEUROIMAGE, V12, P340, DOI 10.1006/nimg.1999.0534; MAHR D, 1980, P ROYAL SOC LOND, P197; MANGIN JF, 1998, P 1 MICCAI, P1230; McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7; PANNIZZO F, 1992, MAGNET RESON MED, V24, P90, DOI 10.1002/mrm.1910240110; Pham DL, 2000, ANNU REV BIOMED ENG, V2, P315, DOI 10.1146/annurev.bioeng.2.1.315; Prewitt J. M. S., 1970, PICTURE PROCESSING P, P75; RANGAYYAN RM, 2005, BIOMEDICAL IMAGE ANA, P363; ROBERTS LG, 1965, MACHINE PERCEPTION 3, P159; ROUAINIA M, 2005, WSEAS T COMPUTERS, V4, P272; Rouainia M, 2006, P 17 INT C COMP INF, P301; Ruan S, 2002, COMPUT VIS IMAGE UND, V85, P54, DOI 10.1006/cviu.2002.0957; Salzenstein F, 1997, GRAPH MODEL IM PROC, V59, P205, DOI 10.1006/gmip.1997.0431; SANDOR S, 1995, P INFORMATION PROCES, P127; Sandor S, 1997, IEEE T MED IMAGING, V16, P41, DOI 10.1109/42.552054; SCHMITT M, 1993, MORPHOLOGIE MATH; Schnack HG, 2001, NEUROIMAGE, V14, P95, DOI 10.1006/nimg.2001.0800; Serra J., 1988, IMAGE ANAL MATH MORP; SHAN Y, 2002, NEUROIMAGE, P1587; SOBEL I, 1978, COMPUT VISION GRAPH, V8, P127, DOI 10.1016/S0146-664X(78)80020-3; STATTUCK DW, 2001, NEUROIMAGE, P856; Tanabe JL, 1997, AM J NEURORADIOL, V18, P115; Thiran JP, 1997, SIGNAL PROCESS, V60, P1, DOI 10.1016/S0165-1684(97)00060-1; Tsai C, 1995, PATTERN RECOGN, V28, P1825; VAIDYANATHAN M, 1995, MAGN RESON IMAGING, V13, P719, DOI 10.1016/0730-725X(95)00012-6; VELTHUIZEN RP, 1995, JMRI-J MAGN RESON IM, V5, P594, DOI 10.1002/jmri.1880050520; Warfield S, 1995, J Image Guid Surg, V1, P326, DOI 10.1002/(SICI)1522-712X(1995)1:6<326::AID-IGS4>3.0.CO;2-C; Wells WM, 1996, IEEE T MED IMAGING, V15, P429, DOI 10.1109/42.511747; Xu CY, 1999, IEEE T MED IMAGING, V18, P467, DOI 10.1109/42.781013; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; Zijdenbos Alex P., 1994, Critical Reviews in Biomedical Engineering, V22, P401	61	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-1751-3				2008							1116	1122				7	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BIP38	WOS:000261578000207	
J	Mjahed, M				Mjahed, Mostafa			LHC data classification using a new morphological boundary detection	INTERNATIONAL JOURNAL OF MODERN PHYSICS A			English	Article; Proceedings Paper	International Symposium on Supersymmetry at LHC: Theoretical and Experimental Perspectives	MAR 11-14, 2007	El Sherouk, EGYPT		British Univ Egypt, Ctr Theoret Phys	morphological boundary; classification; Higgs	WEAK INTERACTIONS; SYMMETRIES	A new morphological boundary detection approach is used to separate the signal from the background in the Standard Model Higgs boson search at LHC. Based on mathematical concepts, this method consists of a fast computation of probabilistic density functions of events and a smoothing using a combination of dilatation and erosion operators. In a binary search approach, the performances are improved and the results compare favourably with other multivariate analysis.	[Mjahed, Mostafa] Ecole Royale Air, Maths & Syst Dept, Marrakech 40000, Morocco; [Mjahed, Mostafa] Fac Sci Semlalia, LPTN, Marrakech 40000, Morocco	Mjahed, M (reprint author), Ecole Royale Air, Maths & Syst Dept, Marrakech 40000, Morocco.	mmjahed@hotmail.com					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; GLASHOW SL, 1961, NUCL PHYS, V22, P579, DOI 10.1016/0029-5582(61)90469-2; GLASHOW SL, 1970, PHYS REV D, V2, P1285, DOI 10.1103/PhysRevD.2.1285; Hartigan J., 1975, CLUSTERING ALGORITHM; HIGGS PW, 1964, PHYS LETT, V12, P132, DOI 10.1016/0031-9163(64)91136-9; Jain A., 1988, ALGORITHMS CLUSTERIN; Kittler J., 1998, IEEE T PATTERN ANAL, V20; MIZOGUCHI R, 1976, IEEE T COMPUT, V25, P1109; Mjahed M, 2002, NUCL PHYS B-PROC SUP, V106, P1094, DOI 10.1016/S0920-5632(01)01939-9; Mjahed M, 2006, NUCL INSTRUM METH A, V559, P172, DOI 10.1016/j.nima.2005.11.137; MJAHED M, P LATTICE 2006 POS L; POSTAIRE JG, 1982, IEEE T PATTERN ANAL, V4, P663; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; Serra J., 1982, IMAGE ANAL MATH MORP; Sjostrand T, 2001, COMPUT PHYS COMMUN, V135, P238, DOI 10.1016/S0010-4655(00)00236-8; VANRYZIN, 1977, CLASSIFICATION CLUST	17	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0217-751X		INT J MOD PHYS A	Int. J. Mod. Phys. A	DEC 20	2007	22	31					6071	6079		10.1142/S0217751X07039249		9	Physics, Nuclear; Physics, Particles & Fields	Physics	261MP	WOS:000253083700039	
J	Kasapoglu, NG; Ersoy, OK				Kasapoglu, N. Goekhan; Ersoy, Okan K.			Border vector detection and adaptation for classification of multispectral and hyperspectral remote sensing images	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article; Proceedings Paper	4th International Workshop on Pattern Recognition in Remote Sensing	AUG   20, 2006	Hong Kong, PEOPLES R CHINA	Int Assoc Pattern Recognit, IEEE Geosci, Remote Sensing Soc		border vector detection and adaptation (BVDA); consensual classification; data classification; decision region borders; remote sensing	NEURAL-NETWORKS; PROJECTION PURSUIT; DECISION FUSION; MACHINES; PARALLEL; ACCURACY	Effective partitioning of the feature space for high classification accuracy with due attention to rare class members is often a difficult task. In this paper, the border vector detection and adaptation (BVDA) algorithm is proposed for this purpose. The BVDA consists of two parts. In the first part of the algorithm, some specially selected training samples are assigned as initial reference vectors called border vectors. In the second part of the algorithm, the border vectors are adapted by moving them toward the decision boundaries. At the end of the adaptation process, the border vectors are finalized. The method next uses the minimum distance to border vector rule for classification. In supervised learning, the training process should be unbiased to reach more accurate results in testing. In the BVDA, decision region borders are related to the initialization of the border vectors and the input ordering of the training samples. Consensus strategy can be applied with cross validation to reduce these dependencies. The performance of the BVDA and consensual BVDA were studied in comparison to other classification algorithms including neural network with backpropagation learning, support vector machines, and some statistical classification techniques.	Tech Univ Istanbul, Dept Elect & Commun Engn, TR-34469 Istanbul, Turkey; Purdue Univ, Dept Elect & Comp Engn, W Lafayette, IN 47907 USA	Kasapoglu, NG (reprint author), Tech Univ Istanbul, Dept Elect & Commun Engn, TR-34469 Istanbul, Turkey.						ALPAYDIN E, 1991, 91032 TR INT COMP SC; ARIKAN M, 2004, P ISPRS S IST INT AR, V34, P1085; Atkinson PM, 1997, INT J REMOTE SENS, V18, P699, DOI 10.1080/014311697218700; Benediktsson JA, 1999, IEEE T GEOSCI REMOTE, V37, P1367, DOI 10.1109/36.763301; Benediktsson JA, 1997, IEEE T NEURAL NETWOR, V8, P54, DOI 10.1109/72.554191; Benediktsson JA, 1997, IEEE T GEOSCI REMOTE, V35, P833, DOI 10.1109/36.602526; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; CHEE HM, 2005, IEEE T GEOSCI REMOTE, V432, P1890; CHO S, 1993, IEEE T CIRCUITS-II, V40, P556, DOI 10.1109/82.257333; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dawson M. S., 1993, Remote Sensing Reviews, V7; Foody GM, 1999, INT J REMOTE SENS, V20, P3549, DOI 10.1080/014311699211192; Foody GM, 1997, INT J REMOTE SENS, V18, P799, DOI 10.1080/014311697218764; Foody GM, 2006, REMOTE SENS ENVIRON, V103, P179, DOI 10.1016/j.rse.2006.04.001; Foody GM, 2004, IEEE T GEOSCI REMOTE, V42, P1335, DOI 10.1109/TGRS.2004.827257; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; FUKUNAGA K, 1990, INTRO STAT PATTERN R, P99; Guttman A., 1984, P ACM SIGMOD INT C M, P47; Hoffsis GF, 1996, COMP CONT EDUC PRACT, V18, P7; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102; Jia XP, 2005, IEEE GEOSCI REMOTE S, V2, P225, DOI 10.1109/LGRS.2005.846437; Jimenez LO, 1999, IEEE T GEOSCI REMOTE, V37, P2653, DOI 10.1109/36.803413; Jimenez LO, 1999, IEEE T GEOSCI REMOTE, V37, P1360, DOI 10.1109/36.763300; Joachims T., 1999, ADV KERNEL METHODS S; KARAKAHYA H, 2003, P 13 INT C ART NEUR, P1011; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; LANDGREBE D, MULTISPEC AVIRIS NW; Landgrebe D.A., 2003, SIGNAL THEORY METHOD; LEE CH, 1993, IEEE T PATTERN ANAL, V15, P388, DOI 10.1109/34.206958; LEE J, 2006, P IGARRS DENV CO JUL, P3915; Mather P. M., 1999, COMPUTER PROCESSING; Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865; Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975; OMOHUNDRO SM, 1991, ADV NEURAL INFORM PR; Preparata F. P., 1985, COMPUTATIONAL GEOMET; SCHWAIGHOFER A, MATLAB INTERFACE SVM; Tadjudin S, 1999, IEEE T GEOSCI REMOTE, V37, P2113, DOI 10.1109/36.774728; UHLMANN JK, 1991, INFORM PROCESS LETT, V40, P175, DOI 10.1016/0020-0190(91)90074-R; VALLS GC, 2006, IEEE GEOSCI REMOTE S, V3, P93; VANNIEL TG, 2005, REMOTE SENS ENVIRON, V98, P416; Vapnik V.N., 1998, STAT LEARNING THEORY; Varshney P. K, 2004, ADV IMAGE PROCESSING; SATIMAGE DATA SET	44	12	12	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0196-2892		IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	DEC	2007	45	12	1				3880	3893		10.1109/TGRS.2007.900699		14	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing	Geochemistry & Geophysics; Engineering; Remote Sensing	236YL	WOS:000251339400004	
J	Martinez-Uso, A; Pla, F; Sotoca, JM; Garcia-Sevilla, P				Martinez-Uso, Adolfo; Pla, Filiberto; Sotoca, Jose Martinez; Garcia-Sevilla, Pedro			Clustering-based hyperspectral band selection using information measures	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article						dimensionality reduction; feature clustering; feature selection; information theory	REMOTE-SENSING IMAGES; DIMENSIONALITY REDUCTION; CLASSIFICATION; EXTRACTION	Hyperspectral imaging involves large amounts of information. This paper presents a technique for dimensionality reduction to deal with hyperspectral images. The proposed method is based on a hierarchical clustering structure to group bands to minimize the intracluster variance and maximize the intercluster variance. This aim is pursued using information measures, such as distances based on mutual information or Kullback-Leibler divergence, in order to reduce data redundancy and nonuseful information among image bands. Experimental results include a comparison among some relevant and recent methods for hyperspectral band selection using no labeled information, showing their performance with regard to pixel image classification tasks. The technique that is presented has a stable behavior for different image data sets and a noticeable accuracy, mainly when selecting small sets of bands.	Univ Jaume 1, Dept Lenguajes & Syst Informat, E-12071 Castellon de La Plana, Spain	Martinez-Uso, A (reprint author), Univ Jaume 1, Dept Lenguajes & Syst Informat, E-12071 Castellon de La Plana, Spain.						Aczel J, 1975, MEASURES INFORM THEI; Breiman L, 1984, CLASSIFICATION REGRE; Bruzzone L, 1995, IEEE T GEOSCI REMOTE, V33, P1318, DOI 10.1109/36.477187; Burr Ridge I, 1997, MACHINE LEARNING; Chang C-C., 2001, LIBSVM LIB SUPPORT V; Chang CI, 1999, IEEE T GEOSCI REMOTE, V37, P2631; Chang C.-I., 2003, HYPERSPECTRAL IMAGIN; Chang CI, 2002, IEEE T GEOSCI REMOTE, V40, P1065; Chang CI, 2006, IEEE T GEOSCI REMOTE, V44, P1575, DOI 10.1109/TGRS.2006.864389; Cover T. M., 1991, ELEMENTS INFORM THEO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; Dhillon I. S., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753661; Dosil R, 2005, LECT NOTES COMPUT SC, V3523, P287; Gersho A., 1992, VECTOR QUANTIZATION; Jain A., 1988, ALGORITHMS CLUSTERIN; Jimenez LO, 1999, IEEE T GEOSCI REMOTE, V37, P2653, DOI 10.1109/36.803413; Jimenez-Rodriguez LO, 2007, IEEE T GEOSCI REMOTE, V45, P469, DOI 10.1109/TGRS.2006.885412; Kumar S, 2001, IEEE T GEOSCI REMOTE, V39, P1368, DOI 10.1109/36.934070; Landgrebe D.A., 2003, SIGNAL THEORY METHOD; MARTINEZUSO A, 2006, P ICPR, P760; Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865; Plaza A, 2005, IEEE T GEOSCI REMOTE, V43, P466, DOI 10.1109/TGRS.2004.841417; Sanchez JS, 1998, PATTERN RECOGN LETT, V19, P1165, DOI 10.1016/S0167-8655(98)00108-1; Serpico SB, 2001, IEEE T GEOSCI REMOTE, V39, P1360, DOI 10.1109/36.934069; Serpico SB, 2007, IEEE T GEOSCI REMOTE, V45, P484, DOI 10.1109/TGRS.2006.886177; Slonim N., 2001, P 23 EUR C INF RETR, P191; Wang J, 2006, IEEE T GEOSCI REMOTE, V44, P1586, DOI 10.1109/TGRS.2005.80297; Ward JJ, 1963, AM STAT ASS J, V58, P236; Webb A., 2002, STAT PATTERN RECOGNI	30	38	40	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0196-2892		IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	DEC	2007	45	12	2				4158	4171		10.1109/TGRS.2007.904951		14	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing	Geochemistry & Geophysics; Engineering; Remote Sensing	236YM	WOS:000251339500012	
J	Angiulli, F; Folino, G				Angiulli, Fabrizio; Folino, Gianluigi			Distributed nearest neighbor-based condensation of very large data sets	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						classification; parallel and distributed algorithms; nearest neighbor rule; data condensation	LEARNING ALGORITHMS; PATTERN-CLASSIFICATION; RULE	In this work, the Parallel Fast Condensed Nearest Neighbor (PFCNN) rule, a distributed method for computing a consistent subset of a very large data set for the nearest neighbor classification rule is presented. In order to cope with the communication overhead typical of distributed environments and to reduce memory requirements, different variants of the basic PFCNN method are introduced. An analysis of spatial cost, CPU cost, and communication overhead is accomplished for all the algorithms. Experimental results, performed on both synthetic and real very large data sets, revealed that these methods can be profitably applied to enormous collections of data. Indeed, they scale up well and are efficient in memory consumption, confirming the theoretical analysis, and achieve noticeable data reduction and good classification accuracy. To the best of our knowledge, this is the first distributed algorithm for computing a training set consistent subset for the nearest neighbor rule.	Univ Calabria, Dipartimento Elettr Informat & Sistemist, I-87036 Arcavacata Di Rende, CS, Italy; Italian Natl Res Council, Inst High Performance Comp & Networking, I-87036 Arcavacata Di Rende, CS, Italy	Angiulli, F (reprint author), Univ Calabria, Dipartimento Elettr Informat & Sistemist, Via P Bucci,41C, I-87036 Arcavacata Di Rende, CS, Italy.	f.angiulli@deis.unical.it; folino@icar.cnr.it					Aha DW, 1997, ARTIF INTELL REV, V11, P7, DOI 10.1023/A:1006538427943; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Angiulli Fabrizio, 2005, P 22 INT C MACH LEAR; APLAYDIN E, 1997, ARTIF INTELL, V11, P115; BAY S, 1998, P 15 INT C MACH LEAR; Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; Beygelzimer A., 2006, P 23 INT C MACH LEAR; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DASARATHY BV, 1995, OPT ENG, V34, P2785, DOI 10.1117/12.210755; Devi VS, 2002, PATTERN RECOGN, V35, P505; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; Foster I., 2003, GRID2 BLUEPRINT NEW; Freitas A. A, 1998, MINING VERY LARGE DA; Furnkranz J, 2002, J MACH LEARN RES, V2, P721, DOI 10.1162/153244302320884605; Gaede V, 1998, ACM COMPUT SURV, V30, P170, DOI 10.1145/280277.280279; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GROOP W, 1996, PARALLEL COMPUT, V22, P789; Han J., 2005, DATA MINING CONCEPTS; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KARACALI B, 2002, IEEE T NEURAL NETWOR, V14, P127; Karonis NT, 2003, J PARALLEL DISTR COM, V63, P551, DOI 10.1016/S0743-7315(03)00002-9; Liu CL, 2001, PATTERN RECOGN, V34, P601, DOI 10.1016/S0031-3203(00)00018-2; Lu BL, 1999, IEEE T NEURAL NETWOR, V10, P1244, DOI 10.1109/72.788664; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STONE C, 1977, ANN STAT, V8, P1348; TOUSSAINT G, 2002, P 34 S INT COMP SCI; Tsang IW, 2005, J MACH LEARN RES, V6, P363; Viswanath P., 2004, INFORM FUSION, V5, P239, DOI 10.1016/j.inffus.2004.02.003; Watson I., 1994, KNOWLEDGE ENG REV, V9; Wilfong G., 1992, International Journal of Computational Geometry & Applications, V2, DOI 10.1142/S0218195992000226; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; ZHAO H, 2004, P 1 INT COMP INF SCI	35	10	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	DEC	2007	19	12					1593	1606		10.1109/TKDE.2007.190665		14	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	221GU	WOS:000250216200001	
J	Cai, WL; Chen, SC; Zhang, DQ				Cai, Weiling; Chen, Songcan; Zhang, Daoqiang			Robust fuzzy relational classifier incorporating the soft class labels	PATTERN RECOGNITION LETTERS			English	Article						fuzzy c-means clustering (FCM); fuzzy relations; fuzzy relational classifier; kernelized FCM (KFCM); soft class label; pattern classification	ALGORITHM	Fuzzy relational classifier (FRC) is a recently proposed two-step nonlinear classifier. At first, the unsupervised fuzzy c-means (FCM) clustering is performed to explore the underlying groups of the given dataset. Then, a fuzzy relation matrix indicating the relationship between the formed groups and the given classes is constructed for subsequent classification. It has been shown that FRC has two advantages: interpretable classification results and avoidance of overtraining. However, FRC not only lacks the robustness which is very important for a classifier, but also fails on the dataset with non-spherical distributions. Moreover, the classification mechanism of FRC is sensitive to the improper class labels of the training samples, thus leading to considerable decline in classification performance. The purpose of this paper is to develop a Robust FRC (RFRC) algorithm aiming at overcoming or mitigating all of the above disadvantages of FRC and maintaining its original advantages. In the proposed RFRC algorithm, we employ our previously proposed robust kernelized FCM (KFCM) to replace FCM to enhance its robustness against outliers and its suitability for the non-spherical data structures. In addition, we incorporate the soft class labels into the classification mechanism to improve its performance, especially for the datasets containing the improper class labels. The experimental results on 2 artificial and I I real-life benchmark datasets demonstrate that RFRC algorithm can consistently outperform FRC in classification performance. (c) 2007 Elsevier B.V. All rights reserved.	Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, Nanjing 210016, Peoples R China	Chen, SC (reprint author), Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, Nanjing 210016, Peoples R China.	caiwl@nuaa.edu.cn; s.chen@nuaa.edu.cn	Zhang, Daoqiang/D-3754-2011	Zhang, Daoqiang/0000-0002-5658-7643			Abe SG, 2005, LECT NOTES COMPUT SC, V3697, P571; Alippi E, 2001, IEEE INSTRU MEAS MAG, V4, P32; Bezdek J., 1981, PATTERN RECOGNITION; Bezdek JC, 1998, PATTERN RECOGN; Blake CL, 1998, UCI REPOSITORY MACHI; Chen SC, 2004, IEEE T SYST MAN CY B, V34, P1907, DOI 10.1109/TSMCB.2004.831165; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264136; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dave RN, 1997, IEEE T FUZZY SYST, V5, P270, DOI 10.1109/91.580801; Girolami M, 2002, IEEE T NEURAL NETWOR, V13, P780, DOI 10.1109/TNN.2002.1000150; Hathaway RJ, 2000, IEEE T FUZZY SYST, V8, P576, DOI 10.1109/91.873580; HAYKIN S, 1999, NEURAL NETWORKS COMP; Huber P. J., 1981, ROBUST STAT; Jain AK, 1999, DATA CLUSTERING REV; JAJUGA K, 1991, FUZZY SET SYST, V39, P43, DOI 10.1016/0165-0114(91)90064-W; Kaufman L., 1990, FINDING GROUPS DATA; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KIM DW, 2004, PATTERN RECOGN, V38, P607; Klawonn F, 1999, LECT NOTES COMPUT SC, V1642, P291; Klir G.J., 1995, FUZZY SETS FUZZY LOG; Krzanowski W. J., 1988, PRINCIPLES MULTIVARI; Leski J, 2003, FUZZY SET SYST, V137, P215, DOI 10.1016/S0165-0114(02)00372-X; MUSAVI MT, 1992, NEURAL NETWORKS, V5, P595, DOI 10.1016/S0893-6080(05)80038-3; Pedrycz W., 2004, PATTERN RECOGN, V37, P1229; PEDRYCZ W, 1994, REASONING ANALOGY FU, P55; PIZZI NJ, 2000, INT JOINT C NEUR NET; RAMIREZ L, 2003, IEEE CANADIAN C ELEC, V3, P1465; Roth V, 2000, ADV NEUR IN, V12, P568; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Setnes M, 1999, IEEE T SYST MAN CY B, V29, P619, DOI 10.1109/3477.790444; Shaw-Taylor J., 2000, INTRO SVMS OTHER KER; SOHN S, 2001, INT JOINT C NEUR NET, V3, P1886, DOI 10.1109/IJCNN.2001.938451; Sung-Bae Cho, 1995, IEEE Transactions on Neural Networks, V6, DOI 10.1109/72.363487; Wu KL, 2002, PATTERN RECOGN, V35, P2267, DOI 10.1016/S0031-3203(01)00197-2; Xie X.L., 1991, IEEE T PAMI, V3, P841; XU L, 1996, P 1996 IEEE INT C NE, V3, P1546; YAO YH, 1999, NEURAL NETWORKS, V2, P1097; Zadeh L.A., 1965, FUZZY SETS INFORM CO, P338, DOI DOI 10.1016/S0019-9958(65)90241-X; Zhang DQ, 2003, NEURAL PROCESS LETT, V18, P155, DOI 10.1023/B:NEPL.0000011135.19145.1b; Zhang SS, 2004, NUCLEIC ACIDS RES, V32, P1, DOI 10.1093/nar/gkg933	40	9	9	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	DEC 1	2007	28	16					2250	2263		10.1016/j.patrec.2007.07.013		14	Computer Science, Artificial Intelligence	Computer Science	230TW	WOS:000250899800009	
J	Besaw, LE; Rizzo, DM				Besaw, Lance E.; Rizzo, Donna M.			Stochastic simulation and spatial estimation with multiple data types using artificial neural networks	WATER RESOURCES RESEARCH			English	Article							MICROBIAL COMMUNITY STRUCTURE; LEACHATE-POLLUTED AQUIFER; JOINT INVERSION; COUNTERPROPAGATION NETWORKS; GROUNDWATER CONTAMINATION; HYDRAULIC CONDUCTIVITY; SOIL; CLASSIFICATION; IDENTIFICATION; HYDROCHEMISTRY	A novel data-driven artificial neural network ( ANN) that quantitatively combines large numbers of multiple types of soft data is presented for performing stochastic simulation and/or spatial estimation. A counterpropagation ANN is extended with a radial basis function to estimate parameter fields that reproduce the spatial structure exhibited in autocorrelated parameters. Applications involve using three geophysical properties measured on a slab of Berea sandstone and the delineation of landfill leachate at a site in the Netherlands using electrical formation conductivity as our primary variable and six types of secondary data ( e. g., hydrochemistry, archaea, and bacteria). The ANN estimation fields are statistically similar to geostatistical methods ( indicator simulation and cokriging) and reference fields ( when available). The method is a nonparametric clustering/ classification algorithm that can assimilate significant amounts of disparate data types with both continuous and categorical responses without the computational burden associated with the construction of positive definite covariance and cross-covariance matrices. The combination of simplicity and computational speed makes the method ideally suited for environmental subsurface characterization and other Earth science applications with spatially autocorrelated variables.	Univ Vermont, Sch Engn, Burlington, VT 05405 USA	Besaw, LE (reprint author), Univ Vermont, Sch Engn, Votey Hall,33 Colchester Ave, Burlington, VT 05405 USA.	lbesaw@cems.uvm.edu; drizzo@cems.uvm.edu					AZERMAN MA, 1964, AUTOMAT REM CONTR, V25, P821; BALLARD JH, 1998, SAGEEP 1998 S APPL G; BASHKIRO.OA, 1964, AUTOMAT REM CONTR+, V25, P629; Bosch M, 2004, GEOPHYSICS, V69, P1272, DOI 10.1190/1.1801944; COPTY N, 1995, WATER RESOUR RES, V31, P1673, DOI 10.1029/95WR00947; COPTY N, 1993, WATER RESOUR RES, V29, P2813, DOI 10.1029/93WR00745; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; de la Vega M, 2003, J APPL GEOPHYS, V54, P97, DOI 10.1016/j.jappgeo.2003.08.020; Fidencio PH, 2001, ANALYST, V126, P2194, DOI 10.1039/b107533k; Garcia LA, 2006, J HYDROL, V318, P215, DOI 10.1016/j.jhydrol.2005.05.028; GELB S, 1998, SAGEEP 1998 S APPL G; Gloaguen E, 2001, J APPL GEOPHYS, V47, P135, DOI 10.1016/S0926-9851(01)00057-X; Goovaerts P, 1998, BIOL FERT SOILS, V27, P315, DOI 10.1007/s003740050439; GOOVAERTS P, 1999, STOCH ENV RES RISK A, V13, P182; Goovaerts P, 2001, GEODERMA, V103, P3, DOI 10.1016/S0016-7061(01)00067-2; Goovaerts P, 2005, WATER RESOUR RES, V41, DOI 10.1029/2004WR003705; HECHTNIELSEN R, 1987, APPL OPTICS, V26, P4979, DOI 10.1364/AO.26.004979; HECHTNIELSEN R, 1988, NEURAL NETWORKS, V1, P131, DOI 10.1016/0893-6080(88)90015-9; Hohmann G.W., 1988, ELECTROMAGNETIC METH, V1, P469; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; HSU KL, 1995, WATER RESOUR RES, V31, P2517, DOI 10.1029/95WR01955; Hsu KL, 1999, WATER RESOUR RES, V35, P1605, DOI 10.1029/1999WR900032; Istok JD, 1996, GROUND WATER, V34, P1050, DOI 10.1111/j.1745-6584.1996.tb02171.x; Journel A. G., 1989, TERRA NOVA, V1, P123, DOI [10.1111/j.1365-3121.1989.tb00344.x, DOI 10.1111/J.1365-3121.1989.TB00344.X]; Kis M, 2002, J APPL GEOPHYS, V50, P401, DOI 10.1016/S0926-9851(02)00167-2; KOHONEN T, 1989, SELF ORG ASSOCIATED; Li BL, 1999, WATER RESOUR RES, V35, P3663, DOI 10.1029/1999WR900268; MENKE W, 1984, GEOPHYS RES LETT, V11, P105, DOI 10.1029/GL011i002p00105; Morshed J, 1998, WATER RESOUR RES, V34, P1101, DOI 10.1029/98WR00006; Mouser PJ, 2005, ENVIRON SCI TECHNOL, V39, P7551, DOI 10.1021/es0502627; Nie JH, 1996, FUZZY SET SYST, V78, P5, DOI 10.1016/0165-0114(95)00118-2; OLDENBURG DW, 1998, LEADING EDGE, V17, P461, DOI 10.1190/1.1437989; Park YS, 2003, WATER RES, V37, P1749, DOI 10.1016/S0043-1354(02)00557-2; Patriarche D, 2005, MATH GEOL, V37, P587, DOI 10.1007/s11004-005-7308-5; PITKIN SE, 1998, S APPL GEOPH ENV ENG; PURDY C, 1998, S APPL GEOPH ENV ENG; RIZZO DM, 1994, WATER RESOUR RES, V30, P483, DOI 10.1029/93WR02477; RIZZO DM, 1994, THESIS U VERMONT BUR; Rizzo DM, 1996, GEOTECH SP, P167; Roling WFM, 2001, APPL ENVIRON MICROB, V67, P4619, DOI 10.1128/AEM.67.10.4619-4629.2001; Roling WFM, 2000, WATER SCI TECHNOL, V41, P47; Roling WFM, 2000, MICROBIAL ECOL, V40, P177; Rossabi J., 2000, Ground Water Monitoring and Remediation, V20, P72, DOI 10.1111/j.1745-6592.2000.tb00291.x; Rumelhart D., 1988, PARALLEL DISTRIBUTED; Tidwell VC, 1997, WATER RESOUR RES, V33, P1607, DOI 10.1029/97WR00804; Tidwell VC, 1999, MATH GEOL, V31, P749, DOI 10.1023/A:1007568632217; VOZOFF K, 1975, GEOPHYS J ROY ASTR S, V42, P977; Wasserman P.D., 1989, NEURAL COMPUTING; WINDROW G, 1960, ADAPTIVE SWITCHING C; YEH WWG, 1986, WATER RESOUR RES, V22, P95, DOI 10.1029/WR022i002p00095; *US EPA, 2000, INN SIT CHAR GLOPH I	51	6	7	AMER GEOPHYSICAL UNION	WASHINGTON	2000 FLORIDA AVE NW, WASHINGTON, DC 20009 USA	0043-1397		WATER RESOUR RES	Water Resour. Res.	NOV 8	2007	43	11							W11409	10.1029/2006WR005509		14	Environmental Sciences; Limnology; Water Resources	Environmental Sciences & Ecology; Marine & Freshwater Biology; Water Resources	230ED	WOS:000250857900001	
J	Chou, KC; Shen, HB				Chou, Kuo-Chen; Shen, Hong-Bin			Recent progress in protein subcellular location prediction	ANALYTICAL BIOCHEMISTRY			English	Review							AMINO-ACID-COMPOSITION; SUPPORT VECTOR MACHINES; FUNCTIONAL DOMAIN COMPOSITION; STRUCTURAL CLASS PREDICTION; NEAREST-NEIGHBOR ALGORITHM; GRAM-NEGATIVE BACTERIA; LOCALIZATION PREDICTION; ENSEMBLE CLASSIFIER; CONOTOXIN SUPERFAMILY; FUSION CLASSIFIER		Gordon Life Sci Inst, San Diego, CA 92130 USA; Harvard Univ, Sch Med, Dept Biol Chem & Mol Pharmacol, Boston, MA 02115 USA	Chou, KC (reprint author), Gordon Life Sci Inst, San Diego, CA 92130 USA.	kcchou@gordonlifescience.org	Chou, Kuo-Chen/A-8340-2009				Alberts B., 2002, MOL BIOL CELL; Alberts B, 1994, MOL BIOL CELL; Altschul SE, 1997, THEORETICAL AND COMPUTATIONAL METHODS IN GENOME RESEARCH, P1; Apweiler R, 2001, NUCLEIC ACIDS RES, V29, P37, DOI 10.1093/nar/29.1.37; Apweiler R, 2004, NUCLEIC ACIDS RES, V32, pD115, DOI 10.1093/nar/gkh131; Ashburner M, 2000, NAT GENET, V25, P25; Cai YD, 2003, BIOCHEM BIOPH RES CO, V305, P407, DOI 10.1016/S0006-291X(03)00775-7; Cai YD, 2003, BIOPHYS J, V84, P3257; Cao YF, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-20; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; Chen C, 2006, ANAL BIOCHEM, V357, P116, DOI 10.1016/j.ab.2006.07.022; Chen C, 2006, J THEOR BIOL, V243, P444, DOI 10.1016/j.jtbi.2006.06.025; Chou KC, 1999, BIOCHEM BIOPH RES CO, V264, P216, DOI 10.1006/bbrc.1999.1325; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2006, J PROTEOME RES, V5, P3420, DOI 10.1021/pr060404b; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; Chou KC, 2007, J CELL BIOCHEM, V100, P665, DOI 10.1002/jcb.21096; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 2000, BIOCHEM BIOPH RES CO, V278, P477, DOI 10.1006/bbrc.2000.3815; Chou KC, 2006, J PROTEOME RES, V5, P1888, DOI 10.1021/pr060167c; Chou KC, 2007, BIOCHEM BIOPH RES CO, V357, P633, DOI 10.1016/j.bbrc.2007.03.162; Chou KC, 2005, BIOINFORMATICS, V21, P944, DOI 10.1093/bioinformatics/bti104; Chou KC, 1996, ANAL BIOCHEM, V233, P1, DOI 10.1006/abio.1996.0001; Chou KC, 2004, CURR MED CHEM, V11, P2105; CHOU KC, 1994, J BIOL CHEM, V269, P22014; Chou KC, 2004, BIOCHEM BIOPH RES CO, V320, P1236, DOI 10.1016/j.bbrc.2004.06.073; Chou KC, 2006, J CELL BIOCHEM, V99, P517, DOI 10.1002/jcb.20879; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; Chou KC, 2007, BIOCHEM BIOPH RES CO, V360, P339, DOI 10.1016/j.bbrc.2007.06.027; Chou KC, 2007, J PROTEOME RES, V6, P1728, DOI 10.1021/pr060635i; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou KC, 2006, BIOCHEM BIOPH RES CO, V347, P150, DOI 10.1016/j.bbrc.2006.06.059; CHOU KC, 1993, J BIOL CHEM, V268, P16938; CHOU PY, PREDICTION PROTEIN S, P549; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Du PF, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-518; Emanuelsson O, 2000, J MOL BIOL, V300, P1005, DOI 10.1006/jmbi.2000.3903; Emanuelsson O, 2007, NAT PROTOC, V2, P953, DOI 10.1038/nprot.2007.131; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; FENG ZP, 2002, IN SILICO BIOL, V2, P291; Feng ZP, 2001, INT J BIOL MACROMOL, V28, P255, DOI 10.1016/S0141-8130(01)00121-0; Gao QB, 2006, PROTEIN ENG DES SEL, V19, P511, DOI 10.1093/protein/gzl038; Gao QB, 2005, FEBS LETT, V579, P3444, DOI 10.1016/j.febslet.2005.05.021; Gardy JL, 2003, NUCLEIC ACIDS RES, V31, P3613, DOI 10.1093/nar/gkg602; Garg A, 2005, J BIOL CHEM, V280, P14427, DOI 10.1074/jbc.M411789200; Glory E, 2007, DEV CELL, V12, P7, DOI 10.1016/j.devcel.2006.12.007; Guo J, 2006, PROTEOMICS, V6, P5099, DOI 10.1002/pmic.200600064; Hoglund A, 2006, BIOINFORMATICS, V22, P1158, DOI 10.1093/bioinformatics/btl002; HOPP TP, 1981, P NATL ACAD SCI-BIOL, V78, P3824, DOI 10.1073/pnas.78.6.3824; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Huang Y, 2004, BIOINFORMATICS, V20, P21, DOI 10.1093/bioinformatics/btg366; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KLEIN P, 1986, BIOCHIM BIOPHYS ACTA, V874, P205, DOI 10.1016/0167-4838(86)90119-6; KLEIN P, 1986, BIOPOLYMERS, V25, P1659, DOI 10.1002/bip.360250909; Lee K, 2006, NUCLEIC ACIDS RES, V34, P4655, DOI 10.1093/nar/gkl638; Lei ZD, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-291; Lin H, 2007, BIOCHEM BIOPH RES CO, V354, P548, DOI 10.1016/j.bbrc.2007.01.011; Lin H, 2007, J COMPUT CHEM, V28, P1463, DOI 10.1002/jcc.20554; Lodish H., 1995, MOL CELL BIOL; Lubec G, 2005, PROG NEUROBIOL, V77, P90, DOI 10.1016/j.pneurobio.2005.10.001; Mahalanobis P., 1936, P NAT I SCI INDIA, V2, P49; Mardia K. V., 1979, MULTIVARIATE ANAL, P521; Matsuda S, 2005, PROTEIN SCI, V14, P2804, DOI 10.1110/ps.051597405; METFESSEL BA, 1993, PROTEIN SCI, V2, P1171; Mondal S, 2006, J THEOR BIOL, V243, P252, DOI 10.1016/j.jtbi.2006.06.014; Murphy R F, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P251; NAKAI K, 1992, GENOMICS, V14, P897, DOI 10.1016/S0888-7543(05)80111-9; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; Park KJ, 2003, BIOINFORMATICS, V19, P1656, DOI 10.1093/bioinformatics/btg222; Pillai K. C. S., 1985, ENCY STATISTICAL SCI, V5, P176; Reinhardt A, 1998, NUCLEIC ACIDS RES, V26, P2230, DOI 10.1093/nar/26.9.2230; Shafer G., 1976, MATH THEORY EVIDENCE; Shen HB, 2007, BIOPOLYMERS, V85, P233, DOI 10.1002/bip.20640; Shen HB, 2007, BIOCHEM BIOPH RES CO, V355, P1006, DOI 10.1016/j.bbrc.2007.02.071; Shen HB, 2007, PROTEIN ENG DES SEL, V20, P39, DOI 10.1093/protein-gzl053; Shi JY, 2007, AMINO ACIDS, V33, P69, DOI 10.1007/s00726-006-0475-y; TANFORD C, 1962, J AM CHEM SOC, V84, P4240, DOI 10.1021/ja00881a009; WOOTTON JC, 1993, COMPUT CHEM, V17, P149, DOI 10.1016/0097-8485(93)85006-X; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Yuan Z, 1999, FEBS LETT, V451, P23, DOI 10.1016/S0014-5793(99)00506-2; Zhang SW, 2006, AMINO ACIDS, V30, P461, DOI 10.1007/s00726-006-0263-8; Zhang ZH, 2006, FEBS LETT, V580, P6169, DOI 10.1016/j.febslet.2006.10.017; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2006, PROTEINS, V63, P681, DOI 10.1002/prot.20898; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565	94	472	482	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0003-2697		ANAL BIOCHEM	Anal. Biochem.	NOV 1	2007	370	1					1	16		10.1016/j.ab.2007.07.006		16	Biochemical Research Methods; Biochemistry & Molecular Biology; Chemistry, Analytical	Biochemistry & Molecular Biology; Chemistry	215FV	WOS:000249794600001	
J	Angiulli, F				Angiulli, Fabrizio			Fast nearest neighbor condensation for large data sets classification	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						classification; large and high-dimensional data; nearest neighbor rule; prototype selection algorithms; training-set-consistent subset	LEARNING ALGORITHMS; RULE; RECOGNITION; RISK	This work has two main objectives, namely, to introduce a novel algorithm, called the Fast Condensed Nearest Neighbor (FCNN) rule, for computing a training-set-consistent subset for the nearest neighbor decision rule and to show that condensation algorithms for the nearest neighbor rule can be applied to huge collections of data. The FCNN rule has some interesting properties: it is order independent, its worst-case time complexity is quadratic but often with a small constant prefactor, and it is likely to select points very close to the decision boundary. Furthermore, its structure allows for the triangle inequality to be effectively exploited to reduce the computational effort. The FCNN rule outperformed even here-enhanced variants of existing competence preservation methods both in terms of learning speed and learning scaling behavior and, often, in terms of the size of the model while it guaranteed the same prediction accuracy. Furthermore, it was three orders of magnitude faster than hybrid instance-based learning algorithms on the MNIST and Massachusetts Institute of Technology (MIT) Face databases and computed a model of accuracy comparable to that of methods incorporating a noise-filtering pass.	Univ Calabria, Dipartimento Elettron Informat & Sistemat, I-87036 Cosenza, Italy	Angiulli, F (reprint author), Univ Calabria, Dipartimento Elettron Informat & Sistemat, Via P Bucci 41C, I-87036 Cosenza, Italy.	f.angiulli@deis.unical.it					Aha DW, 1997, ARTIF INTELL REV, V11, P7, DOI 10.1023/A:1006538427943; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Alpaydin E, 1997, ARTIF INTELL REV, V11, P115, DOI 10.1023/A:1006563312922; Angiulli F., 2005, P 22 INT C MACH LEAR, P25, DOI 10.1145/1102351.1102355; BAY S, 1998, P 15 INT C MACH LEAR; Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; BHATTACHARYA B, 1998, P 14 INT C PATT REC; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Cameron-Jones R.M., 1995, P 8 AUSTR JOINT C AR, P99; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; DASARATHY BV, 1991, NEAREST NEIGHBOUR NN; DASARATHY BV, 1995, OPT ENG, V34, P2785, DOI 10.1117/12.210755; Devi VS, 2002, PATTERN RECOGN, V35, P505; Devijver P. A., 1980, Proceedings of the 5th International Conference on Pattern Recognition; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; Devroye L, 1996, PROBABILISTIC THEORY; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; Gaede V, 1998, ACM COMPUT SURV, V30, P170, DOI 10.1145/280277.280279; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Karacali B, 2003, IEEE T NEURAL NETWOR, V14, P127, DOI 10.1109/TNN.2002.804315; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Liu CL, 2001, PATTERN RECOGN, V34, P601, DOI 10.1016/S0031-3203(00)00018-2; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STONE C, 1977, ANN STAT, V8, P1348; TOUSSAINT G, 2002, P 34 S INT COMP SCI; Watson I., 1994, KNOWLEDGE ENG REV, V9; Wilfong G., 1992, International Journal of Computational Geometry & Applications, V2, DOI 10.1142/S0218195992000226; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	32	30	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	NOV	2007	19	11					1450	1464		10.1109/TKDE.2007.190645		15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	211ZT	WOS:000249563900002	
