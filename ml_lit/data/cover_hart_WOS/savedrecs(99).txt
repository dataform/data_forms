PT	AU	BA	CA	GP	RI	OI	BE	Z2	TI	X1	Y1	Z1	FT	PN	AE	Z3	SO	SE	BS	VL	IS	SI	MA	BP	EP	AR	DI	D2	SU	PD	PY	AB	X4	Y4	Z4	CT	CY	SP	CL	TC	Z8	ZB	ZS	Z9	SN	BN	UT	
J	Triguero, Isaac; Derrac, Joaquin; Garcia, Salvador; Herrera, Francisco				Herrera, Francisco/C-6856-2008	Herrera, Francisco/0000-0002-7283-312X			A Taxonomy and Experimental Study on Prototype Generation for Nearest Neighbor Classification								IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART C-APPLICATIONS AND REVIEWS			42	1			86	100		10.1109/TSMCC.2010.2103939			JAN 2012	2012	The nearest neighbor (NN) rule is one of the most successfully used techniques to resolve classification and pattern recognition tasks. Despite its high classification accuracy, this rule suffers from several shortcomings in time response, noise sensitivity, and high storage requirements. These weaknesses have been tackled by many different approaches, including a good and well-known solution that we can find in the literature, which consists of the reduction of the data used for the classification rule (training data). Prototype reduction techniques can be divided into two different approaches, which are known as prototype selection and prototype generation (PG) or abstraction. The former process consists of choosing a subset of the original training data, whereas PG builds new artificial prototypes to increase the accuracy of the NN classification. In this paper, we provide a survey of PG methods specifically designed for the NN rule. From a theoretical point of view, we propose a taxonomy based on the main characteristics presented in them. Furthermore, from an empirical point of view, we conduct a wide experimental study that involves small and large datasets to measure their performance in terms of accuracy and reduction capabilities. The results are contrasted through nonparametrical statistical tests. Several remarks are made to understand which PG models are appropriate for application to different datasets.								10	1	1	0	11	1094-6977		WOS:000298300200009	
J	Guo, Ling; Rivero, Daniel; Dorado, Julian; Munteanu, Cristian R.; Pazos, Alejandro				Munteanu, Cristian/G-1714-2011				Automatic feature extraction using genetic programming: An application to epileptic EEG classification								EXPERT SYSTEMS WITH APPLICATIONS			38	8			10425	10436		10.1016/j.eswa.2011.02.118			AUG 2011	2011	This paper applies genetic programming (GP) to perform automatic feature extraction from original feature database with the aim of improving the discriminatory performance of a classifier and reducing the input feature dimensionality at the same time. The tree structure of GP naturally represents the features, and a new function generated in this work automatically decides the number of the features extracted. In experiments on two common epileptic EEG detection problems, the classification accuracy on the GP-based features is significant higher than on the original features. Simultaneously, the dimension of the input features for the classifier is much smaller than that of the original features. (C) 2011 Elsevier Ltd. All rights reserved.								10	0	4	0	10	0957-4174		WOS:000290237500156	
J	Arturo Olvera-Lopez, J.; Ariel Carrasco-Ochoa, J.; Francisco Martinez-Trinidad, J.								A new fast prototype selection method based on clustering								PATTERN ANALYSIS AND APPLICATIONS			13	2			131	141		10.1007/s10044-008-0142-x			MAY 2010	2010	In supervised classification, a training set T is given to a classifier for classifying new prototypes. In practice, not all information in T is useful for classifiers, therefore, it is convenient to discard irrelevant prototypes from T. This process is known as prototype selection, which is an important task for classifiers since through this process the time for classification or training could be reduced. In this work, we propose a new fast prototype selection method for large datasets, based on clustering, which selects border prototypes and some interior prototypes. Experimental results showing the performance of our method and comparing accuracy and runtimes against other prototype selection methods are reported.								10	0	2	0	10	1433-7541		WOS:000277023400001	
J	Ghasemzadeh, Hassan; Loseu, Vitali; Jafari, Roozbeh								Structural Action Recognition in Body Sensor Networks: Distributed Classification Based on String Matching								IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE			14	2			425	435		10.1109/TITB.2009.2036722			MAR 2010	2010	Mobile sensor-based systems are emerging as promising platforms for healthcare monitoring. An important goal of these systems is to extract physiological information about the subject wearing the network. Such information can be used for life logging, quality of life measures, fall detection, extraction of contextual information, and many other applications. Data collected by these sensor nodes are overwhelming, and hence, an efficient data processing technique is essential. In this paper, we present a system using inexpensive, off-the-shelf inertial sensor nodes that constructs motion transcripts from biomedical signals and identifies movements by taking collaboration between the nodes into consideration. Transcripts are built of motion primitives and aim to reduce the complexity of the original data. We then label each primitive with a unique symbol and generate a sequence of symbols, known as motion template, representing a particular action. This model leads to a distributed algorithm for action recognition using edit distance with respect to motion templates. The algorithm reduces the number of active nodes during every classification decision. We present our results using data collected from five normal subjects performing transitional movements. The results clearly illustrate the effectiveness of our framework. In particular, we obtain a classification accuracy of 84.13% with only one sensor node involved in the classification process.								10	2	0	0	12	1089-7771		WOS:000275666100030	
J	Niu, Bing; Lu, Lin; Liu, Liang; Gu, Tian Hong; Feng, Kai-Yan; Lu, Wen-Cong; Cai, Yu-Dong								HIV-1 Protease Cleavage Site Prediction Based on Amino Acid Property								JOURNAL OF COMPUTATIONAL CHEMISTRY			30	1			33	39		10.1002/jcc.21024			JAN 15 2009	2009	Knowledge of the polyprotein cleavage sites by HIV protease will refine our understanding of its specificity, and the information thus acquired is useful for designing specific and efficient HIV protease inhibitors. Recently, several works have approached the HIV-1 protease specificity problem by applying a number of classifier creation and combination methods. The pace in searching for the proper inhibitors of HIV protease will be greatly expedited if one can find an accurate, robust, and rapid method for predicting the cleavage sites in proteins by HIV protease. In this article, we selected HIV-1 protease as the Subject of the study. 299 oligopeptides were chosen for the training set, while the other 63 oligopeptides were taken as a test set. The peptides are represented by features constructed by AAIndex (Kawashima et al., Nucleic Acids Res 1999, 27, 368; Kawashima and Kanehisa, Nucleic Acids Res 2000, 28, 374). The mRMR method (Maximum Relevance, Minimum Redundancy; Ding and Peng, Proc Second IEEE Comput Syst Bioinformatics Conf 2003, 523; Peng et al., IEEE Trans Pattern Anal Mach Intell 2005, 27, 1226) combining with incremental feature selection (IFS) and feature forward search (FFS) are applied to find the two important cleavage sites and to select 364 important biochemistry features by jackknife test. Using KNN (K-nearest neighbors) to combine the selected features, the prediction model obtains high accuracy rate of 91.3% for Jackknife cross-validation test and 87.3% for independent-set test. It is expected that our feature selection scheme can be referred to as a useful assistant technique for finding effective inhibitors of HIV protease, especially for the scientists in this field. (C) 2008 Wiley Periodicals, Inc. J Comput Chem 30: 33-39, 2009								10	0	9	0	10	0192-8651		WOS:000261907000003	
J	Maas, Marnix C.; Schaart, Dennis R.; van der Laan, D. J. (Jan); van Dam, Herman T.; Huizenga, Jan; Brouwer, J. C.; Bruyndonckx, Peter; Lemaitre, Cedric; van Eijk, Carel W. E.								Signal to noise ratio of APD-based monolithic scintillator detectors for high resolution PET					1			IEEE TRANSACTIONS ON NUCLEAR SCIENCE			55	3			842	852		10.1109/TNS.2008.921493			JUN 2008	2008	Monolithic scintillator detectors, consisting of several cm(3) of scintillating material coupled to one or more Hamamatsu S8550 avalanche photodiode (APD) arrays, are proposed as detectors for high resolution positron emission tomography (PET). in this work, the factors contributing to the variance on the signals are investigated, and their effects on the energy, time and spatial resolutions are analyzed.Good agreement was found between a model of the energy resolution and experiments with a 20 x 10 x 10 mm(3) LYSO: Ce crystal coupled to a single channel large-area APD (LAAPD). With the same crystal coupled to an APD array, differences between model and experiment were observed at high APD gain.The measured energy resolution of similar to 11% FWHM was dominated by scintillation photon statistics, with less important roles for the APD excess noise factor and electronic noise. On the other hand, electronic noise was an important factor both for the time and the spatial resolutions. The time resolution was found to depend strongly on the APD bias voltage, and was best at the highest bias. A time resolution of 1.6 ns full width at half maximum (FWHM) was measured against a BaF2-PMT detector. The best spatial resolution measured was 1.64 mm FWHM, without correction for the similar to 0.9 mm FWHM measurement beam. It is estimated that an intrinsic spatial resolution of 1.26 mm FWHM can be achieved at the center of the detector with an infinitely narrow test beam.								10	0	5	0	10	0018-9499		WOS:000256967600003	
J	Angiulli, Fabrizio; Folino, Gianluigi								Distributed nearest neighbor-based condensation of very large data sets								IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			19	12			1593	1606		10.1109/TKDE.2007.190665			DEC 2007	2007	In this work, the Parallel Fast Condensed Nearest Neighbor (PFCNN) rule, a distributed method for computing a consistent subset of a very large data set for the nearest neighbor classification rule is presented. In order to cope with the communication overhead typical of distributed environments and to reduce memory requirements, different variants of the basic PFCNN method are introduced. An analysis of spatial cost, CPU cost, and communication overhead is accomplished for all the algorithms. Experimental results, performed on both synthetic and real very large data sets, revealed that these methods can be profitably applied to enormous collections of data. Indeed, they scale up well and are efficient in memory consumption, confirming the theoretical analysis, and achieve noticeable data reduction and good classification accuracy. To the best of our knowledge, this is the first distributed algorithm for computing a training set consistent subset for the nearest neighbor rule.								10	3	0	0	13	1041-4347		WOS:000250216200001	
J	Huang, Wen-Lin; Chen, Hung-Ming; Hwang, Shiow-Fen; Ho, Shinn-Ying								Accurate prediction of enzyme subfamily class using an adaptive fuzzy k-nearest neighbor method								BIOSYSTEMS			90	2			405	413		10.1016/j.biosystems.2006.10.004			SEP-OCT 2007	2007	Amphiphilic pseudo-amino acid composition (Am-Pse-AAC) with extra sequence-order information is a useful feature for representing enzymes. This study first utilizes the k-nearest neighbor (k-NN) rule to analyze the distribution of enzymes in the Am-Pse-AAC feature space. This analysis indicates the distributions of multiple classes of enzymes are highly overlapped. To cope with the overlap problem, this study proposes an efficient non-parametric classifier for predicting enzyme subfamily class using an adaptive fuzzy r-nearest neighbor (AFK-NN) method, where k and a fuzzy strength parameter m are adaptively specified. The fuzzy membership values of a query sample Q are dynamically determined according to the position of Q and its weighted distances to the k nearest neighbors. Using the same enzymes of the oxidoreductases family for comparisons, the prediction accuracy of AFK-NN is 76.6%, which is better than those of Support Vector Machine (73.6%), the decision tree method C5.0 (75.4%) and the existing covariant-discriminate algorithm (70.6%) using a jackknife test. To evaluate the generalization ability of AFK-NN, the datasets for all six families of entirely sequenced enzymes are established from the newly updated SWISS-PROT and ENZYME database. The accuracy of AFK-NN on the new large-scale dataset of oxidoreductases family is 83.3%, and the mean accuracy of the six families is 92.1 %. (c) 2006 Elsevier Ireland Ltd. All rights reserved.								10	1	6	0	11	0303-2647		WOS:000250184500011	
J	Ramamohanarao, Kotagiri; Fan, Hongjian								Patterns based classifiers								WORLD WIDE WEB-INTERNET AND WEB INFORMATION SYSTEMS			10	1			71	83		10.1007/s11280-006-0012-7			MAR 2007	2007	Data mining is one of the most important areas in the 21 century for its applications are wide ranging. This includes medicine, finance, commerce and engineering, to name a few. Pattern mining is amongst the most important and challenging techniques employed in data mining. Patterns are collections of items which satisfy certain properties. Emerging Patterns are those whose frequencies change significantly from one dataset to another. They represent strong contrast knowledge and have been shown very successful for constructing accurate and robust classifiers. In this paper, we examine various kinds of patterns. We also investigate efficient pattern mining techniques and discuss how to exploit patterns to construct effective classifiers.								10	0	0	0	10	1386-145X		WOS:000244955500003	
J	Zitouni, Imed								Backoff hierarchical class n-gram language models: effectiveness to model unseen events in speech recognition								COMPUTER SPEECH AND LANGUAGE			21	1			88	104		10.1016/j.csl.2006.01.001			JAN 2007	2007	In this paper, we introduce the backoff hierarchical class n-gram language models to better estimate the likelihood of unseen n-gram events. This multi-level class hierarchy language modeling approach generalizes the well-known backoff n-gram language modeling technique. It uses a class hierarchy to define word contexts. Each node in the hierarchy,is a class that contains all the words of its descendant nodes. The closer a node to the root, the more general the class (and context) is. We investigate the effectiveness of the approach to model unseen events in speech recognition. Our results illustrate that the proposed technique outperforms backoff n-gram language models. We also study the effect of the vocabulary size and the depth of the class hierarchy on the performance of the approach. Results are presented on Wall Street Journal (WSJ) corpus using two vocabulary set: 5000 words and 20,000 words. Experiments with 5000 word vocabulary, which contain a small numbers of unseen events in the test set, show up to 10% improvement of the unseen event perplexity when using the hierarchical class n-gram language models. With a vocabulary of 20,000 words, characterized by a larger number of unseen events, the perplexity of unseen events decreases by 26%, while the word error rate (WER) decreases by 12% when using the hierarchical approach. Our results suggest that the largest gains in performance are obtained when the test set contains a large number of unseen events. (c) 2006 Elsevier Ltd. All rights reserved.								10	0	0	0	10	0885-2308		WOS:000241794800005	
J	Tahir, Muhammad Atif; Bouridane, Ahmed								Novel round-robin tabu search algorithm for prostate cancer classification and diagnosis using multispectral imagery								IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE			10	4			782	793		10.1109/TITB.2006.879596			OCT 2006	2006	Quantitative cell imagery in cancer pathology has progressed greatly in the last 25 years. The application areas are mainly those in which the diagnosis is still critically reliant upon the analysis of biopsy samples, which remains the only conclusive method for making an accurate diagnosis of the disease. Biopsies are usually analyzed by a trained pathologist who, by analyzing the biopsies under a microscope, assesses the normality or malignancy of the samples submitted. Different grades of malignancy correspond to different structural patterns as well as to apparent textures. In the case Of prostate cancer, four major groups have to be recognized: stroma, benign prostatic hyperplasia, prostatic intraepithelial neoplasia, and prostatic carcinoma. Recently, multispectral imagery has been used to solve this multiclass problem. Unlike conventional RGB color space, multispectral images allow the acquisition of a large number of spectral bands within the visible spectrum, resulting in a large feature vector size. For such a high dimensionality, pattern recognition techniques suffer from the well-known "curse-of-dimensionality" problem. This paper proposes a novel round-robin tabu search (RR-TS) algorithm to address the curse-of-dimensionality for this multiclass problem. The experiments have been carried out on a number of prostate cancer textured multispectral images, and the results obtained have been assessed and compared with previously reported works. The system achieved 98%-100% classification accuracy when testing on two datasets. It outperformed principal component/linear discriminant classifier (PCA-LDA), tabu search/nearest neighbor classifier (TS-1NN), and bagging/boosting with decision tree (C4.5) classifier.								10	1	6	0	11	1089-7771		WOS:000241124900016	
J	Hansen, ME; Carstensen, JM				Hansen, Michael/C-9028-2011	Hansen, Michael/0000-0001-7879-2106			Density-based retrieval from high-similarity image databases								PATTERN RECOGNITION			37	11			2155	2164		10.1016/j.patcog.2004.02.018			NOV 2004	2004	Many image classification problems can fruitfully be thought of as image retrieval in a "high similarity image database" (HSID) characterized by being tuned towards a specific application and having a high degree of visual similarity between entries that should be distinguished. We introduce a method for HSID retrieval using a similarity measure based on a linear combination of Jeffreys-Matusita distances between distributions of local (pixelwise) features estimated from a set of automatically and consistently defined image regions. The weight coefficients are estimated based on optimal retrieval performance. Experimental results on the difficult task of visually identifying clones of fungal colonies grown in a petri dish and categorization of pelts show a high retrieval accuracy of the method when combined with standardized sample preparation and image acquisition. (C) 2004 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.								10	2	6	0	12	0031-3203		WOS:000223501000005	
J	Pan, F; Wang, BY; Hu, X; Perrizo, W								Comprehensive vertical sample-based KNN/LSVM classification for gene expression analysis								JOURNAL OF BIOMEDICAL INFORMATICS			37	4			240	248		10.1016/j.jbi.2004.07.003			AUG 2004	2004	Classification analysis of microarray gene expression data has been widely used to uncover biological features and to distinguish closely related cell types that often appear in the diagnosis of cancer. However, the number of dimensions of gene expression data is often very high, e.g., in the hundreds or thousands. Accurate and efficient classification of such high-dimensional data remains a contemporary challenge. In this paper, we propose a comprehensive vertical sample-based KNN/LSVM classification approach with weights optimized by genetic algorithms for high-dimensional data. Experiments on common gene expression datasets demonstrated that our approach can achieve high accuracy and efficiency at the same time. The improvement of speed is mainly related to the vertical data representation, P-tree,(1) and its optimized logical algebra. The high accuracy is due to the combination of a KNN majority voting approach and a local support vector machine approach that makes optimal decisions at the local level. As a result, our approach could be a powerful tool for high-dimensional gene expression data analysis. (C) 2004 Elsevier Inc. All rights reserved.								10	0	3	0	10	1532-0464		WOS:000224592800003	
J	Sboner, A; Bauer, P; Zumiani, G; Eccher, C; Blanzieri, E; Forti, S; Cristofolini, M				Sboner, Andrea/C-6487-2008	Sboner, Andrea/0000-0001-6915-3070			Clinical validation of an automated system for supporting the early diagnosis of melanoma								SKIN RESEARCH AND TECHNOLOGY			10	3			184	192		10.1111/j.1600-0846.2004.00066.x			AUG 2004	2004	Background: Early diagnosis and surgical excision is the most effective treatment of melanoma. Well-trained dermatologists reach a high level of diagnostic accuracy with good sensitivity and specificity. Their performances increase using some technical aids as digital epiluminescence microscopy. Several studies describe the development of computerized systems whose aim is supporting dermatologists in the early diagnosis of melanoma. In many cases, the performances of those systems were comparable to those of dermatologists. However, this cannot tell us whether a system is able to support dermatologists. Actually, the computerized system might correctly recognize the same lesions that the dermatologist does, without providing them any useful advice and therefore being useless in recognizing early malignant lesions.Purpose: We present a novel approach to enhance dermatologists' performances in the diagnosis of early melanoma. We provide results of our evaluation of a computerized system combined with dermatologists.Methods: A Multiple-Classifier system was developed on a set of 152 cases and combined to a group of eight dermatologists to support them by improving their sensitivity.Results: The eight dermatologists have average sensitivity and specificity values of 0.83 and 0.66, respectively. The Multiple-Classifier system performs as well as the eight dermatologists (sensitivity range: 0.75-0.86; specificity range: 0.64-0.89). The combination with the dermatologists shows an average improvement of 11% (P=0.022) of dermatologists' sensitivity.Conclusion: Our results suggest that an automated system can be effective in supporting dermatologists because it recognizes different malignant melanomas with respect to the dermatologists.								10	0	4	0	10	0909-752X		WOS:000222285600008	
J	Huang, CC; Lee, HM								A grey-based nearest neighbor approach for missing attribute value prediction								APPLIED INTELLIGENCE			20	3			239	252		10.1023/B:APIN.0000021416.41043.0f			MAY-JUN 2004	2004	This paper proposes a grey-based nearest neighbor approach to predict accurately missing attribute values. First, grey relational analysis is employed to determine the nearest neighbors of an instance with missing attribute values. Accordingly, the known attribute values derived from these nearest neighbors are used to infer those missing values. Two datasets were used to demonstrate the performance of the proposed method. Experimental results show that our method outperforms both multiple imputation and mean substitution. Moreover, the proposed method was evaluated using five classification problems with incomplete data. Experimental results indicate that the accuracy of classification is maintained or even increased when the proposed method is applied for missing attribute value prediction.								10	4	3	0	14	0924-669X		WOS:000220411400004	
J	Hullermeier, E								Possibilistic instance-based learning								ARTIFICIAL INTELLIGENCE			148	1-2			335	383		10.1016/S0004-3702(03)00019-5			AUG 2003	2003	A method of instance-based learning is introduced which makes use of possibility theory and fuzzy sets. Particularly, a possibilistic version of the similarity-guided extrapolation principle underlying the instance-based learning paradigm is proposed. This version is compared to the commonly used probabilistic approach from a methodological point of view. Moreover, aspects of knowledge representation such as the modeling of uncertainty are discussed. Taking the possibilistic extrapolation principle as a point of departure, an instance-based learning procedure is outlined which includes the handling of incomplete information, methods for reducing storage requirements and the adaptation of the influence of stored cases according to their typicality. First theoretical and experimental results showing the efficiency of possibilistic instance-based learning are presented as well. (C) 2003 Elsevier B.V. All rights reserved.								10	0	0	0	10	0004-3702		WOS:000184860500011	
J	Sadek, AW; Smith, BL; Demetsky, MJ								A prototype case-based reasoning system for real-time freeway traffic routing								TRANSPORTATION RESEARCH PART C-EMERGING TECHNOLOGIES			9	5			353	380		10.1016/S0968-090X(00)00046-2			OCT 2001	2001	With the recent advances in communications and information technology, real-time traffic routing has emerged as a promising approach to alleviating congestion. Existing approaches to developing real-time routing strategies, however, have limitations. This study examines the potential for using case-based reasoning (CBR). an emerging artificial intelligence paradigm, to overcome such limitations. CBR solves new problems by reusing solutions of similar past problems. To illustrate the feasibility of the approach, the study develops and evaluates a prototype CBR routing system for the interstate network in Hampton Roads, Virginia. Cases for building the system's case-base are generated using a heuristic dynamic traffic assignment (DTA) model designed for the region. Using a second set of cases, the study evaluates the performance of the prototype system by comparing its solutions to those of the DTA model. The evaluation results demonstrate that the prototype system is capable of running in real-time, and of producing high quality solutions using case-bases of reasonable size. (C) 2001 Elsevier Science Ltd. All rights reserved.								10	1	1	0	11	0968-090X		WOS:000170444900004	
J	Priebe, CE				Priebe, Carey E./A-3305-2010				Olfactory classification via interpoint distance analysis								IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			23	4			404	413		10.1109/34.917575			APR 2001	2001	Detection of the presence of a single prespecified chemical analyte at low concentration in complex backgrounds is a difficult application for chemical sensors. This article considers a database of artificial nose observations designed specifically to allow for the investigation of chemical sensor data analysis performance on the problem of trichloroethylene (TCE) detection. We consider an approach to this application which uses an ensemble of subsample classifiers based on interpoint distances. Experimental results are presented indicating that our nonparametric methodology is a useful tool in olfactory classification.								10	0	2	0	10	0162-8828		WOS:000168067900006	
J	Komosinski, M; Krawiec, K								Evolutionary weighting of image features for diagnosing of CNS tumors								ARTIFICIAL INTELLIGENCE IN MEDICINE			19	1			25	38		10.1016/S0933-3657(99)00048-2			MAY 2000	2000	This paper concerns an application of evolutionary feature weighting for diagnosis support in neuropathology. The original data in the classification task are the microscopic images of ten classes of central nervous system (CNS) neuroepithelial tumors. These images are segmented and described by the features characterizing regions resulting from the segmentation process. The final features are in part irrelevant. Thus, we employ an evolutionary algorithm to reduce the number of irrelevant attributes, using the predictive accuracy of a classifier ('wrapper' approach) as an individual's fitness measure. The novelty of our approach consists in the application of evolutionary algorithm for feature weighting, not only for feature selection. The weights obtained give quantitative information about the relative importance of the features. The results of computational experiments show a significant improvement of predictive accuracy of the evolutionarily found feature sets with respect to the original feature set. (C) 2000 Elsevier Science B.V. All rights reserved.								10	3	0	0	13	0933-3657		WOS:000086710600002	
S	Blanzieri, E; Ricci, F				Ricci, Francesco/H-3367-2012		Althoff, KD; Bergmann, R; Branting, LK		Probability based metrics for Nearest Neighbor classification and Case-Based Reasoning								CASE-BASED REASONING RESEARCH AND DEVELOPMENT	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		1650				14	28					1999	1999	This paper is focused on a class of metrics for the Nearest Neighbor classifier, whose definition is based on statistics computed on the case base. We show that these metrics basically rely on a probability estimation phase. In particular, we reconsider a metric proposed in the 80's by Short and Fukunaga, we extend its definition to an input space that includes categorical features and we evaluate empirically its performance. Moreover, we present a novel probability based metric, called Minimum Risk Metric (MRM), i.e. a metric for classification tasks that exploits estimates of the posterior probabilities. MRM is optimal, in the sense that it optimizes the finite misclassification risk, whereas the Short and Fukunaga Metric minimizes the difference between finite risk and asymptotic risk. An experimental comparison of MRM with the Short and Fukunaga Metric, the Value Difference Metric, and Euclidean-Hamming metrics on benchmark datasets shows that MRM outperforms the other metrics. MRM performs comparably to the Bayes Classifier based on the same probability estimates. The results suggest that MRM can be useful in case-based applications where the retrieval of a nearest neighbor is required.				3rd International Conference on Case-Based Reasoning (ICCBR-99)	JUL 27-30, 1999	German Soc Comp Sci; Amer Assoc Artificial Intelligence; AcknoSoft; BSR Consulting; DaimlerChrysler; Fraunhofer Inst Exptl Software Engn, Inference Syst; Fraunhofer Inst Exptl Software Engn, Interact Multimedia Syst; Univ Kaiserslautern; Univ Wyoming	SEEON MONASTERY, GERMANY	10	0	0	0	10	0302-9743	3-540-66237-5	WOS:000084209300002	
J	Mandal, DP								Partitioning of feature space for pattern classification								PATTERN RECOGNITION			30	12			1971	1990		10.1016/S0031-3203(97)00012-5			DEC 1997	1997	The article proposes a simple approach for finding a fuzzy partitioning of a feature space for pattern classification problems. A feature space is initially decomposed into some overlapping hyperboxes depending on the relative positions of the pattern classes found in the training samples. A few fuzzy if-then rules reflecting the pattern classes by the generated hyperboxes are then obtained in terms of a relational matrix. The relational matrix is utilized in the modified compositional rule of inference in order to recognize an unknown pattern. The proposed system is capable of handling imprecise information both in the learning and the processing phases. The imprecise information is considered to be either incomplete or mixed or interval or linguistic in form. Ways of handling such imprecise information are also discussed. The effectiveness of the system is demonstrated on some synthetic data sets in two-dimensional feature space. The practical applicability of the system is verified on four real data such as the Iris data set, an appendicitis data set, a speech data set and a hepatic disease data set. (C) 1997 Pattern Recognition Society. Published by Elsevier Science Ltd.								10	7	0	0	17	0031-3203		WOS:000073087700003	
J	NEIFELD, MA; PSALTIS, D								OPTICAL IMPLEMENTATIONS OF RADIAL BASIS CLASSIFIERS								APPLIED OPTICS			32	8			1370	1379					MAR 10 1993	1993	We describe two optical systems based on the radial basis function approach to pattern classification. An optical-disk-based system for handwritten character recognition is demonstrated. The optical system computes the Euclidean distance between an unknown input and 650 stored patterns at a demonstrated rate of 26,000 pattern comparisons/s. The ultimate performance of this system is limited by optical-disk resolution to 1011 binary operations/s. An adaptive system is also presented that facilitates on-line learning and provides additional robustness.								10	0	0	0	10	0003-6935		WOS:A1993KT61400014	
J	PAZZANI, MJ; SARRETT, W								A FRAMEWORK FOR AVERAGE CASE ANALYSIS OF CONJUNCTIVE LEARNING ALGORITHMS								MACHINE LEARNING			9	4			349	372		10.1007/BF00994111			OCT 1992	1992	We present an approach to modeling the average case behavior of learning algorithms. Our motivation is to predict the expected accuracy of learning algorithms as a function of the number of training examples. We apply this framework to a purely empirical learning algorithm, (the one-sided algorithm for pure conjunctive concepts), and to an algorithm that combines empirical and explanation-based learning. The model is used to gain insight into the behavior of these algorithms on a series of problems. Finally, we evaluate how well the average case model performs when the training examples violate the assumptions of the model.								10	0	0	0	10	0885-6125		WOS:A1992JQ51100003	
J	CASASENT, DP								AN OPTICAL CORRELATOR FEATURE EXTRACTOR NEURAL NET SYSTEM								OPTICAL ENGINEERING			31	5			971	978		10.1117/12.57138			MAY 1992	1992	The three optical information processing techniques of detection, recognition, and identification can and should be combined to achieve the best benefits of each. All methods are required for difficult pattern recognition problems. We consider the identification of multiple objects in the field of view in clutter. A morphological correlator is used to achieve detection. Hierarchical and symbolic pattern recognition correlators can also achieve detection as well as recognition. For very large class problems, feature extractors are required for identification, but first require detection. For difficult multiclass discrimination problems, neural net methods (rather than linear discriminant functions) are needed for identification.								10	0	0	0	10	0091-3286		WOS:A1992HU37000013	
J	GARBER, FD; DJOUADI, A								BOUNDS ON THE BAYES CLASSIFICATION ERROR BASED ON PAIRWISE RISK FUNCTIONS								IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			10	2			281	288		10.1109/34.3891			MAR 1988	1988									10	0	2	0	10	0162-8828		WOS:A1988M297400013	
J	NETO, BB; RAMOS, MN; BRUNS, RE								SIMILARITY TRANSFERENCE OF MOLECULAR-PARAMETERS .1. THE ATOMIC POLAR TENSORS OF CYANOACETYLENE								JOURNAL OF CHEMICAL PHYSICS			85	8			4515	4523		10.1063/1.451772			OCT 15 1986	1986									10	0	0	0	10	0021-9606		WOS:A1986E294400037	
J	CHITTINENI, CB								LEARNING WITH IMPERFECTLY LABELED PATTERNS								PATTERN RECOGNITION			12	5			281	291		10.1016/0031-3203(80)90026-6			1980	1980									10	0	0	0	10	0031-3203		WOS:A1980KQ90500002	
J	PETERSON, KL; PARSONS, ML								SPECTRAL CLASSIFICATION USING PATTERN-RECOGNITION TECHNIQUES .1. FEASIBILITY WITH HYDROGEN AS A MODEL SYSTEM								PHYSICAL REVIEW A			17	1			261	269		10.1103/PhysRevA.17.261			1978	1978									10	0	0	0	10	1050-2947		WOS:A1978EN46200034	
J	GOLDSTEI.M								KN-NEAREST NEIGHBOR CLASSIFICATION								IEEE TRANSACTIONS ON INFORMATION THEORY			18	5			627	+		10.1109/TIT.1972.1054888			1972	1972									10	0	2	0	10	0018-9448		WOS:A1972N420200011	
J	Islam, Tanvir; Rico-Ramirez, Miguel A.; Han, Dawei; Srivastava, Prashant K.				Srivastava, Prashant/B-3215-2012; Han, Dawei/F-9827-2010; Islam, Tanvir/F-6922-2011	Han, Dawei/0000-0002-1858-0491; 			Artificial intelligence techniques for clutter identification with polarimetric radar signatures								ATMOSPHERIC RESEARCH			109				95	113		10.1016/j.atmosres.2012.02.007			JUN 2012	2012	The use of different artificial intelligence (AI) techniques for clutter signals identification in the context of radar based precipitation estimation is presented. The clutter signals considered are because of ground clutter, sea clutter and anomalous propagation whereas the explored AI techniques include the support vector machine (SVM). the artificial neural network (ANN), the decision tree (DT), and the nearest neighbour (NN) systems. Eight different radar measurement combinations comprising of various polarimetric spectral signatures - the reflectivity (Z(H)), differential reflectivity (Z(DR)), differential propagation phase (Phi(DP)), cross-correlation coefficient (rho(HV)), velocity (V) and spectral width (W) from a C-band polarimetric radar are taken into account as input vectors to the AI systems. The results reveal that all four AI classifiers can identify the clutter echoes with around 98-99% accuracy when all radar input signatures are used. As standalone input vectors, the polarimetric textures of the Phi(DP) and the Z(DR) have also demonstrated excellent skills distinguishing clutter echoes with an accuracy of 97-98% approximately. If no polarimetric signature is available, a combination of the texture of Z(H), V and W representing typical measurements from a single-polarization Doppler radar may be used for clutter identification, but with a lower accuracy when compared to the use of polarimetric radar measurements. In contrast, the use of Z(H) or W alone is found less reliable for clutter classification. Among the AI techniques, the SVM has a slightly better score in terms of various clutter identification indicators as compared to the others. Conversely, the NN algorithm has shown a lower performance in identifying the clutter echoes correctly considering the standalone radar signatures as inputs. Despite this, the performance among the different AI techniques is comparable indicating the suitability of the developed systems, and this is further supported when results are compared with the fuzzy logic and Bayes classifiers. (C) 2012 Elsevier B.V. All rights reserved.								9	0	1	0	9	0169-8095		WOS:000303364200009	
J	Cheng, Feixiong; Ikenaga, Yutaka; Zhou, Yadi; Yu, Yue; Li, Weihua; Shen, Jie; Du, Zheng; Chen, Lei; Xu, Congying; Liu, Guixia; Lee, Philip W.; Tang, Yun				Shen, Jie/H-5258-2011; Cheng, Feixiong/D-9922-2013	Cheng, Feixiong/0000-0002-1251-3116			In Silico Assessment of Chemical Biodegradability								JOURNAL OF CHEMICAL INFORMATION AND MODELING			52	3			655	669		10.1021/ci200622d			MAR 2012	2012	Biodegradation is the principal environmental dissipation process. Due to a lack of comprehensive experimental data, high study cost and time-consuming, in silico approaches for assessing the biodegradable profiles of chemicals are encouraged and is an active current research topic. Here we developed in silico methods to estimate chemical biodegradability in the environment. At first 1440 diverse compounds tested under the Japanese Ministry of International Trade and Industry (MITI) protocol were used. Four different methods, namely support vector machine, k-nearest neighbor, naive Bayes, and C4.5 decision tree, were used to build the combinatorial classification probability models of ready versus not ready biodegradability using physicochemical descriptors and fingerprints separately. The overall predictive accuracies of the best models were more than 80% for the external test set of 164 diverse compounds. Some privileged substructures were further identified for ready or not ready biodegradable chemicals by combining information gain and substructure fragment analysis. Moreover, 27 new predicted chemicals were selected for experimental assay through the Japanese MITI test protocols, which validated that all 27 compounds were predicted correctly. The predictive accuracies of our models outperform the commonly used software of the EPI Suite. Our study provided critical tools for early assessment of biodegradability of new organic chemicals in environmental hazard assessment.								9	0	5	0	9	1549-9596		WOS:000301884400003	
J	Derrac, Joaquin; Cornelis, Chris; Garcia, Salvador; Herrera, Francisco				Herrera, Francisco/C-6856-2008; Cornelis, Chris/B-7585-2013	Herrera, Francisco/0000-0002-7283-312X; Cornelis, Chris/0000-0002-7854-6025			Enhancing evolutionary instance selection algorithms by means of fuzzy rough set based feature selection								INFORMATION SCIENCES			186	1			73	92		10.1016/j.ins.2011.09.027			MAR 1 2012	2012	In recent years, fuzzy rough set theory has emerged as a suitable tool for performing feature selection. Fuzzy rough feature selection enables us to analyze the discernibility of the attributes, highlighting the most attractive features in the construction of classifiers. However, its results can be enhanced even more if other data reduction techniques, such as instance selection, are considered.In this work, a hybrid evolutionary algorithm for data reduction, using both instance and feature selection, is presented. A global process of instance selection, carried out by a steady-state genetic algorithm, is combined with a fuzzy rough set based feature selection process, which searches for the most interesting features to enhance both the evolutionary search process and the final preprocessed data set. The experimental study, the results of which have been contrasted through nonparametric statistical tests, shows that our proposal obtains high reduction rates on training sets which greatly enhance the behavior of the nearest neighbor classifier. (C) 2011 Elsevier Inc. All rights reserved.								9	0	0	0	9	0020-0255		WOS:000298460300005	
J	Jiang, Yijia; Li, Cynthia; Xichdao Nguyen; Muzammil, Salman; Towers, Ed; Gabrielson, John; Narhi, Linda								Qualification of FTIR Spectroscopic Method for Protein Secondary Structural Analysis								JOURNAL OF PHARMACEUTICAL SCIENCES			100	11			4631	4641		10.1002/jps.22686			NOV 2011	2011	Fourier transform infrared (FTIR) spectroscopy is widely used to study protein secondary structure both in solution and in the solid state. The FTIR spectroscopic method has also been employed as a characterization method by the biopharmaceutical industry to determine the higher order structure of protein therapeutics, and to determine if any changes in protein conformation have occurred as a result of changes to process, formulation, manufacture, and storage conditions. The results of these studies are often included in regulatory filings; when comparability is assessed, the comparison is often qualitative. To demonstrate that the method can be quantitative, and is suitable for these intended purposes, the precision and sensitivity of the FTIR method were evaluated. The results show that FTIR spectroscopic analysis is reproducible with suitable method precision, that is, spectral similarity of replicate measurements is greater than 90%. The method can detect secondary structural changes caused by pH and denaturant. The sensitivity of the method in detecting structural changes depends on the extent of the changes and their impact on the resulting spectral similarity and characteristic FTIR bands. The results of these assessments are described in this paper. (C) 2011 Wiley-Liss, Inc. and the American Pharmacists Association J Pharm Sci 100:4631-4641, 2011								9	0	8	0	9	0022-3549		WOS:000296369700008	
J	Ryba, Tyrone; Hiratani, Ichiro; Sasaki, Takayo; Battaglia, Dana; Kulik, Michael; Zhang, Jinfeng; Dalton, Stephen; Gilbert, David M.								Replication Timing: A Fingerprint for Cell Identity and Pluripotency								PLOS COMPUTATIONAL BIOLOGY			7	10					e1002225	10.1371/journal.pcbi.1002225			OCT 2011	2011	Many types of epigenetic profiling have been used to classify stem cells, stages of cellular differentiation, and cancer subtypes. Existing methods focus on local chromatin features such as DNA methylation and histone modifications that require extensive analysis for genome-wide coverage. Replication timing has emerged as a highly stable cell type-specific epigenetic feature that is regulated at the megabase-level and is easily and comprehensively analyzed genome-wide. Here, we describe a cell classification method using 67 individual replication profiles from 34 mouse and human cell lines and stem cell-derived tissues, including new data for mesendoderm, definitive endoderm, mesoderm and smooth muscle. Using a Monte-Carlo approach for selecting features of replication profiles conserved in each cell type, we identify "replication timing fingerprints" unique to each cell type and apply a k nearest neighbor approach to predict known and unknown cell types. Our method correctly classifies 67/67 independent replication-timing profiles, including those derived from closely related intermediate stages. We also apply this method to derive fingerprints for pluripotency in human and mouse cells. Interestingly, the mouse pluripotency fingerprint overlaps almost completely with previously identified genomic segments that switch from early to late replication as pluripotency is lost. Thereafter, replication timing and transcription within these regions become difficult to reprogram back to pluripotency, suggesting these regions highlight an epigenetic barrier to reprogramming. In addition, the major histone cluster Hist1 consistently becomes later replicating in committed cell types, and several histone H1 genes in this cluster are downregulated during differentiation, suggesting a possible instrument for the chromatin compaction observed during differentiation. Finally, we demonstrate that unknown samples can be classified independently using site-specific PCR against fingerprint regions. In sum, replication fingerprints provide a comprehensive means for cell characterization and are a promising tool for identifying regions with cell type-specific organization.								9	0	9	0	9	1553-734X		WOS:000297262700046	
J	Yang, Jian; Zhang, Lei; Yang, Jing-yu; Zhang, David								From classifiers to discriminators: A nearest neighbor rule induced discriminant analysis								PATTERN RECOGNITION			44	7			1387	1402		10.1016/j.patcog.2011.01.009			JUL 2011	2011	The current discriminant analysis method design is generally independent of classifiers, thus the connection between discriminant analysis methods and classifiers is loose. This paper provides a way to design discriminant analysis methods that are bound with classifiers. We begin with a local mean based nearest neighbor (LM-NN) classifier and use its decision rule to supervise the design of a discriminator. Therefore, the derived discriminator, called local mean based nearest neighbor discriminant analysis (LM-NNDA), matches the LM-NN classifier optimally in theory. In contrast to that LM-NNDA is a NN classifier induced discriminant analysis method, we further show that the classical Fisher linear discriminant analysis (FLDA) is a minimum distance classifier (i.e. nearest Class-mean classifier) induced discriminant analysis method. The proposed LM-NNDA method is evaluated using the CENPARMI handwritten numeral database, the NUST603 handwritten Chinese character database, the ETH80 object category database and the FERET face image database. The experimental results demonstrate the performance advantage of LM-NNDA over other feature extraction methods with respect to the LM-NN (or NN) classifier. (c) 2011 Elsevier Ltd. All rights reserved.								9	0	1	0	9	0031-3203		WOS:000288841400004	
J	Scheme, Erik J.; Englehart, Kevin B.; Hudgins, Bernard S.								Selective Classification for Improved Robustness of Myoelectric Control Under Nonideal Conditions								IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING			58	6			1698	1705		10.1109/TBME.2011.2113182			JUN 2011	2011	Recent literature in pattern recognition-based myoelectric control has highlighted a disparity between classification accuracy and the usability of upper limb prostheses. This paper suggests that the conventionally defined classification accuracy may be idealistic and may not reflect true clinical performance. Herein, a novel myoelectric control system based on a selective multiclass one-versus-one classification scheme, capable of rejecting unknown data patterns, is introduced. This scheme is shown to outperform nine other popular classifiers when compared using conventional classification accuracy as well as a form of leave-one-out analysis that may be more representative of real prosthetic use. Additionally, the classification scheme allows for real-time, independent adjustment of individual class-pair boundaries making it flexible and intuitive for clinical use.								9	0	0	0	9	0018-9294		WOS:000290732900023	
J	Chuang, Li-Yeh; Yang, Cheng-Hong; Li, Jung-Chike				Chuang, Li-Yeh/E-5005-2011				Chaotic maps based on binary particle swarm optimization for feature selection								APPLIED SOFT COMPUTING			11	1			239	248		10.1016/j.asoc.2009.11.014			JAN 2011	2011	Feature selection is a useful pre-processing technique for solving classification problems. The challenge of solving the feature selection problem lies in applying evolutionary algorithms capable of handling the huge number of features typically involved. Generally, given classification data may contain useless, redundant or misleading features. To increase classification accuracy, the primary objective is to remove irrelevant features in the feature space and to correctly identify relevant features. Binary particle swarm optimization (BPSO) has been applied successfully to solving feature selection problems. In this paper, two kinds of chaotic maps-so-called logistic maps and tent maps-are embedded in BPSO. The purpose of chaotic maps is to determine the inertia weight of the BPSO. We propose chaotic binary particle swarm optimization (CBPSO) to implement the feature selection, in which the K-nearest neighbor (K-NN) method with leave-one-out cross-validation (LOOCV) serves as a classifier for evaluating classification accuracies. The proposed feature selection method shows promising results with respect to the number of feature subsets. The classification accuracy is superior to other methods from the literature. (c) 2009 Elsevier B.V. All rights reserved.								9	2	0	0	11	1568-4946		WOS:000281591300025	
J	Li, Hui; Sun, Jie; Wu, Jian				Li, Hui/G-6408-2011				Predicting business failure using classification and regression tree: An empirical comparison with popular classical statistical methods and top classification mining methods								EXPERT SYSTEMS WITH APPLICATIONS			37	8			5895	5904		10.1016/j.eswa.2010.02.016			AUG 2010	2010	Predicting business failure is a very critical task for government officials, stock holders, managers, employees, investors and researchers, especially in nowadays competitive economic environment. Several top 10 data mining methods have become very popular alternatives in business failure prediction (BFP), e.g., support vector machine and k nearest neighbor. In comparison with the other classification mining methods, advantages of classification and regression tree (CART) methods include: simplicity of results, easy implementation, nonlinear estimation, being non-parametric, accuracy and stable. However, there are seldom researches in the area of BFP that witness the applicability of CART, another method among the top 10 algorithms in data mining. The aim of this research is to explore the performance of BFP using the commonly discussed data mining technique of CART. To demonstrate the effectiveness of BFP using CART, business failure predicting tasks were performed on the data set collected from companies listed in the Shanghai Stock Exchange and Shenzhen Stock Exchange. Thirty times' hold-out method was employed as the assessment, and the two commonly used methods in the top 10 data mining algorithms, i.e., support vector machine and k nearest neighbor, and the two baseline benchmark methods from statistic area, i.e., multiple discriminant analysis (MDA) and logistics regression, were employed as comparative methods. For comparative methods, stepwise method of MDA was employed to select optimal feature subset. Empirical results indicated that the optimal algorithm of CART outperforms all the comparative methods in terms of predictive performance and significance test in short-term BFP of Chinese listed companies. (C) 2010 Elsevier Ltd. All rights reserved.								9	0	0	0	9	0957-4174		WOS:000278376100043	
J	Huang, Yi; Xu, Dong; Cham, Tat-Jen				Xu, Dong/A-3694-2011				Face and Human Gait Recognition Using Image-to-Class Distance								IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY			20	3			431	438		10.1109/TCSVT.2009.2035852			MAR 2010	2010	We propose a new distance measure for face recognition and human gait recognition. Each probe image (a face image or an average human silhouette image) is represented as a set of local features uniformly sampled over a grid with fixed spacing, and each gallery image is represented as a set of local features sampled at each pixel. We formulate an integer programming problem to compute the distance (referred to as the image-to-class distance) from one probe image to all the gallery images belonging to a certain class, in which any feature of the probe image can be matched to only one feature from one of the gallery images. Considering computational efficiency as well as the fact that face images or average human silhouette images are roughly aligned in the preprocessing step, we also enforce a spatial neighborhood constraint by only allowing neighboring features that are within a given spatial distance to be considered for feature matching. The integer programming problem is further treated as a classical minimum-weight bipartite graph matching problem, which can be efficiently solved with the Kuhn-Munkres algorithm. We perform comprehensive experiments on three benchmark face databases: 1) the CMU PIE database; 2) the FERET database; and 3) the FRGC database, as well as the USF Human ID gait database. The experiments clearly demonstrate the effectiveness of our image-to-class distance.								9	0	0	0	9	1051-8215		WOS:000275299600009	
J	Biau, Gerard; Cerou, Frederic; Guyader, Arnaud								On the Rate of Convergence of the Bagged Nearest Neighbor Estimate								JOURNAL OF MACHINE LEARNING RESEARCH			11				687	712					FEB 2010	2010	Bagging is a simple way to combine estimates in order to improve their performance. This method, suggested by Breiman in 1996, proceeds by resampling from the original data set, constructing a predictor from each subsample, and decide by combining. By bagging an n-sample, the crude nearest neighbor regression estimate is turned into a consistent weighted nearest neighbor regression estimate, which is amenable to statistical analysis. Letting the resampling size k(n) grows appropriately with n, it is shown that this estimate may achieve optimal rate of convergence, independently from the fact that resampling is done with or without replacement. Since the estimate with the optimal rate of convergence depends on the unknown distribution of the observations, adaptation results by data-splitting are presented.								9	1	0	0	10	1532-4435		WOS:000277186500010	
J	Qian, Y.; Yao, F.; Jia, S.								Band selection for hyperspectral imagery using affinity propagation								IET COMPUTER VISION			3	4			213	222		10.1049/iet-cvi.2009.0034			DEC 2009	2009	Hyperspectral imagery generally contains enormous amounts of data because of hundreds of spectral bands. Band selection is often adopted to reduce computational cost and accelerate knowledge discovery and other tasks such as subsequent classification. An exemplar-based clustering algorithm termed affinity propagation for band selection is proposed. Affinity propagation is derived from factor graph, and operates by initially considering all data points as potential cluster centres (exemplars) and then exchanging messages between data points until a good set of exemplars and clusters emerges. Affinity propagation has been applied to computer vision and bioinformatics, and shown to be much faster than other clustering methods for large data. By combining the information about the discriminative capability of each individual band and the correlation/similarity between bands, the exemplars generated by affine propagation have higher importance and less correlation/similarity. The performance of band selection is evaluated through a pixel image classification task. Experimental results demonstrate that, compared with some popular band selection methods, the bands selected by affinity propagation best characterise the hyperspectral imagery from the pixel classification standpoint.								9	4	1	0	13	1751-9632		WOS:000273043600005	
J	Batsakis, Sotiris; Petrakis, Euripides G. M.; Milios, Evangelos								Improving the performance of focused web crawlers								DATA & KNOWLEDGE ENGINEERING			68	10			1001	1013		10.1016/j.datak.2009.04.002			OCT 2009	2009	This work addresses issues related to the design and implementation of focused crawlers. Several variants of state-of-the-art crawlers relying on web page content and link information for estimating the relevance of web pages to a given topic are proposed. Particular emphasis is given to crawlers capable of learning not only the content of relevant pages (as classic crawlers do) but also paths leading to relevant pages. A novel learning crawler inspired by a previously proposed Hidden Markov Model (HMM) crawler is described as well. The crawlers have been implemented using the same baseline implementation (only the priority assignment function differs in each crawler) providing an unbiased evaluation framework for a comparative analysis of their performance. All crawlers achieve their maximum performance when a combination of web page content and (link) anchor text is used for assigning download priorities to web pages. Furthermore, the new HMM crawler improved the performance of the original HMM crawler and also outperforms classic focused crawlers in searching for specialized topics. (C) 2009 Elsevier B.V. All rights reserved.								9	1	0	0	9	0169-023X		WOS:000270603900007	
J	Arroyo, Javier; Mate, Carlos								Forecasting histogram time series with k-nearest neighbours methods								INTERNATIONAL JOURNAL OF FORECASTING			25	1			192	207		10.1016/j.ijforecast.2008.07.003			JAN-MAR 2009	2009	Histogram time series (HTS) describe situations where a distribution of values is available for each instant of time. These situations usually arise when contemporaneous or temporal aggregation is required. In these cases, histograms provide a summary of the data that is more informative than those provided by other aggregates such as the mean. Some fields where HTS are useful include economy, official statistics and environmental science.This article adapts the k-Nearest Neighbours (k-NN) algorithm to forecast HTS and, more generally, to deal with histogram data. The proposed k-NN relies on the choice of a distance that is used to measure dissimilarities between sequences of histograms and to compute the forecasts. The Mallows distance and the Wasserstein distance are considered. The forecasting ability of the k-NN adaptation is illustrated with meteorological and financial data, and promising results are obtained. Finally, further research issues are discussed. (C) 2008 International Institute of Forecasters. Published by Elsevier B.V. All rights reserved.								9	1	1	0	10	0169-2070		WOS:000263944800017	
J	Montagnuolo, Maurizio; Messina, Alberto								Parallel neural networks for multimodal video genre classification								MULTIMEDIA TOOLS AND APPLICATIONS			41	1			125	159		10.1007/s11042-008-0222-3			JAN 2009	2009	Improvements in digital technology have made possible the production and distribution of huge quantities of digital multimedia data. Tools for high-level multimedia documentation are becoming indispensable to efficiently access and retrieve desired content from such data. In this context, automatic genre classification provides a simple and effective solution to describe multimedia contents in a structured and well understandable way. We propose in this article a methodology for classifying the genre of television programmes. Features are extracted from four informative sources, which include visual-perceptual information (colour, texture and motion), structural information (shot length, shot distribution, shot rhythm, shot clusters duration and saturation), cognitive information (face properties, such as number, positions and dimensions) and aural information (transcribed text, sound characteristics). These features are used for training a parallel neural network system able to distinguish between seven video genres: football, cartoons, music, weather forecast, newscast, talk show and commercials. Experiments conducted on more than 100 h of audiovisual material confirm the effectiveness of the proposed method, which reaches a classification accuracy rate of 95%.								9	0	0	0	9	1380-7501		WOS:000261953400006	
J	Gil-Pita, Roberto; Yao, Xin								EVOLVING EDITED k-NEAREST NEIGHBOR CLASSIFIERS								International Journal of Neural Systems			18	6			459	467					DEC 2008	2008	The k-nearest neighbor method is a classifier based on the evaluation of the distances to each pattern in the training set. The edited version of this method consists of the application of this classifier with a subset of the complete training set in which some of the training patterns are excluded, in order to reduce the classification error rate. In recent works, genetic algorithms have been successfully applied to determine which patterns must be included in the edited subset. In this paper we propose a novel implementation of a genetic algorithm for designing edited k-nearest neighbor classifiers. It includes the definition of a novel mean square error based fitness function, a novel clustered crossover technique, and the proposal of a fast smart mutation scheme. In order to evaluate the performance of the proposed method, results using the breast cancer database, the diabetes database and the letter recognition database from the UCI machine learning benchmark repository have been included. Both error rate and computational cost have been considered in the analysis. Obtained results show the improvement achieved by the proposed editing method.				8th International Conference on Intelligent Data Engineering and Automated Learning	DEC 16-19, 2007		Birmingham, ENGLAND	9	0	1	0	9	0129-0657		WOS:000262598900002	
J	Laguia, Manuel; Castro, Juan Luis				Castro, Juan Luis/C-2403-2012				Local distance-based classification								KNOWLEDGE-BASED SYSTEMS			21	7			692	703		10.1016/j.knosys.2008.03.050			OCT 2008	2008	In this paper, we have introduced a new method in which every training point learns what is happening in its neighborhood. So, a hyperplane is learned and associated to each point. With this hyperplane we can define the bands distance, a distance measure that bring closer or move away points depending on its classes. We have used this new distance in classification tasks and have performed tests over 68 datasets: IS well-known UCI-Repository datasets, one private dataset, and 49 ad hoc synthetic datasets. We have used 10-fold cross-validation and, in order to compare the results of the classifiers, we have considered the mean accuracy and have also performed a paired two-tailored t-Student's test with a significance level of 95%. The results are encouraging and confirm the good behavior of the new proposed classification method. The bands distance has obtained the best overall results with 1-NN and k-NN classifiers when compared with other distances. Finally, we extract conclusions and outline some lines of future work. (c) 2008 Elsevier B.V. All rights reserved.								9	0	1	0	9	0950-7051		WOS:000260213800020	
J	Kietzmann, Tim C.; Lange, Sascha; Riedmiller, Martin								Incremental GRLVQ: Learning relevant features for 3D object recognition								NEUROCOMPUTING			71	13-15			2868	2879		10.1016/j.neucom.2007.08.018			AUG 2008	2008	We present a new variant of generalized relevance learning vector quantization (GRLVQ) in a computer vision scenario. A version with incrementally added prototypes is used for the non-trivial case of high-dimensional object recognition. Training is based upon a generic set of standard visual features, the learned input weights are used for iterative feature pruning. Thus, prototypes and input space are altered simultaneously, leading to very sparse and task-specific representations. The effectiveness of the approach and the combination of the incremental variant together with pruning was tested on the COIL100 database, It exhibits excellent performance with regard to codebook size, feature selection and recognition accuracy. (C) 2007 Elsevier B.V. All rights reserved.								9	0	2	0	9	0925-2312		WOS:000259121100047	
J	Carson, Henry S.; Morgan, Steven G.; Green, Peter G.								Fine-scale chemical fingerprinting of an open coast crustacean for the assessment of population connectivity								MARINE BIOLOGY			153	3			327	335		10.1007/s00227-007-0808-8			JAN 2008	2008	Chemical fingerprinting techniques recently have been used to track larval dispersal of estuarine species that bear calcified structures, but the applicability of this important approach may be limited on the open coast where chemical signatures may be less distinctive and for the many species that do not retain calcified structures throughout development. Externally brooded embryos of the porcelain crab, Petrolisthes cinctipes, and inductively coupled plasma mass spectrometry were used to determine whether fine-scale variation in trace-elemental composition occurred along an open coast. Embryos were collected from 16 sites from 37.8 degrees to 39.5 degrees north latitude along the Pacific Coast of California, USA during late January and early February 2003. Discriminant function analysis revealed that collection sites, many separated by only a few kilometers along an open coast, could be differentiated with an overall accuracy of 73%, and combining the sites into three regions increased the accuracy to 88%. Thus, distinctive elemental signatures can be detected in open coast species even at a fine scale raising the possibility that larval tags can be developed for many more species than previously thought possible.								9	0	8	0	9	0025-3162		WOS:000251488200010	
J	Cai, Weiling; Chen, Songcan; Zhang, Daoqiang				Zhang, Daoqiang/D-3754-2011	Zhang, Daoqiang/0000-0002-5658-7643			Robust fuzzy relational classifier incorporating the soft class labels								PATTERN RECOGNITION LETTERS			28	16			2250	2263		10.1016/j.patrec.2007.07.013			DEC 1 2007	2007	Fuzzy relational classifier (FRC) is a recently proposed two-step nonlinear classifier. At first, the unsupervised fuzzy c-means (FCM) clustering is performed to explore the underlying groups of the given dataset. Then, a fuzzy relation matrix indicating the relationship between the formed groups and the given classes is constructed for subsequent classification. It has been shown that FRC has two advantages: interpretable classification results and avoidance of overtraining. However, FRC not only lacks the robustness which is very important for a classifier, but also fails on the dataset with non-spherical distributions. Moreover, the classification mechanism of FRC is sensitive to the improper class labels of the training samples, thus leading to considerable decline in classification performance. The purpose of this paper is to develop a Robust FRC (RFRC) algorithm aiming at overcoming or mitigating all of the above disadvantages of FRC and maintaining its original advantages. In the proposed RFRC algorithm, we employ our previously proposed robust kernelized FCM (KFCM) to replace FCM to enhance its robustness against outliers and its suitability for the non-spherical data structures. In addition, we incorporate the soft class labels into the classification mechanism to improve its performance, especially for the datasets containing the improper class labels. The experimental results on 2 artificial and I I real-life benchmark datasets demonstrate that RFRC algorithm can consistently outperform FRC in classification performance. (c) 2007 Elsevier B.V. All rights reserved.								9	0	2	0	9	0167-8655		WOS:000250899800009	
S	Bao, YG; Tsuchiya, E; Ishii, N; Du, XY				ruc, comp_xinxi/E-4212-2012		Gallagher, M; Hogan, J; Maire, F		Classification by instance-based learning algorithm								INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING IDEAL 2005, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		3578				133	140					2005	2005	The basic k-nearest-neighbor classification algorithm works well in many domains but has several shortcomings. This paper proposes a tolerant instance-based learning algorithm TIBL and it ' s combining method by simple voting of TIBL, which is an integration of genetic algorithm, tolerant rough sets and k-nearest neighbor classification algorithm. The proposed algorithms seek to reduce storage requirement and increase generalization accuracy when compared to the basic k-nearest neighbor algorithm and. other learning models. Experiments have been conducted on some benchmark datasets from the UCI Machine Learning Repository. The results show that TIBL algorithm and it ' s combining method, improve the performance of the k-nearest neighbor classification, and also achieves higher generalization accuracy than other popular machine learning algorithms.				6th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL 2005)	JUL 06-08, 2005	Univ Queensland	Brisbane, AUSTRALIA	9	0	0	0	9	0302-9743	3-540-26972-X	WOS:000230878800018	
J	Mechanda, SM; Baum, BR; Johnson, DA; Arnason, JT								Analysis of diversity of natural populations and commercial lines of Echinacea using AFLP								CANADIAN JOURNAL OF BOTANY-REVUE CANADIENNE DE BOTANIQUE			82	4			461	484		10.1139/B04-006			APR 2004	2004	An analysis of diversity of Echinacea native to North America, using amplified fragment length polymorphism (AFLP(R)), was carried out to complement a previously undertaken taxonomic revision of Echinacea that employed multivariate morphometrics. A total of 53 940 AFLP fragments, of which 40 455 were polymorphic, were scored on 435 individual plants from 58 populations consisting of 10 individuals per population. The resulting polymorphism was sufficient to distinguish each plant. A monomorphic AFLP band and a polymorphic AFLP band that migrated a the same position, taken from samples of four species and eight varieties, were cloned, and multiple clones were sequenced. The polymorphic band at the same position across fragments was not identical, with identity as low as 23% compared with 50% identity of the monomorphic band, both of which were at the 100% threshold of sequence similarity. Thus, the AFLP banding profiles, irrespective of their sequence identity, were treated as phenotypes for population genetic, discriminant, and phylogenetic analyses. Variance components within populations and among populations within species were of equal magnitude, but the partitioned variation was slightly higher among varieties than among populations within varieties. Since no species-specific or variety-specific AFLP fingerprints were found, canonical discriminant analysis was conducted, resulting in support for four species but not for the varieties. Similar results were obtained with cluster and principal coordinate analyses, based on genetic distances. To achieve identification using AFLP fingerprints, various classificatory analyses were performed, followed by bootstrapping for validation. An example to identify an unknown plant at the species level with a minimum of 10 AFLP fragments, with greater than 82% overall correct classification, is provided. Phylogenetic analysis of all 435 individuals supported only Echinacea purpurea (L.) Moench and Echinacea laevigata (C.L. Boynton & Beadle) as separate entities, and only the three Echinacea atrorubens varieties and Echinacea pallida var. tennesseensis (Beadle) Binns, B.R. Baum Arnason.								9	0	7	0	9	0008-4026		WOS:000222035300006	
J	Grumberg, O; Livne, S; Markovitch, S								Learning to order BDD variables in verification								JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH			18				83	116					2003	2003	The size and complexity of software and hardware systems have significantly increased in the past years. As a result, it is harder to guarantee their correct behavior. One of the most successful methods for automated verification of finite-state systems is model checking. Most of the current model-checking systems use binary decision diagrams (BDDs) for the representation of the tested model and in the verification process of its properties. Generally, BDDs allow a canonical compact representation of a boolean function (given an order of its variables). The more compact the BDD is, the better performance one gets from the verifier. However, finding an optimal order for a BDD is an NP-complete problem. Therefore, several heuristic methods based on expert knowledge have been developed for variable ordering.We propose an alternative approach in which the variable ordering algorithm gains "ordering experience" from training models and uses the learned knowledge for finding good orders. Our methodology is based on offline learning of pair precedence classifiers from training models, that is, learning which variable pair permutation is more likely to lead to a good order. For each training model, a number of training sequences are evaluated. Every training model variable pair permutation is then tagged based on its performance on the evaluated orders. The tagged permutations are then passed through a feature extractor and are given as examples to a classifier creation algorithm. Given a model for which an order is requested, the ordering algorithm consults each precedence classifier and constructs a pair precedence table which is used to create the order.Our algorithm was integrated with SMV, which is one of the most widely used verification systems. Preliminary empirical evaluation of our methodology, using real benchmark models, shows performance that is better than random ordering and is competitive with existing algorithms that use expert knowledge. We believe that in sub-domains of models (alu, caches, etc.) our system will prove even more valuable. This is because it features the ability to learn sub-domain knowledge, something that no other ordering algorithm does.								9	0	0	0	9	1076-9757		WOS:000180708200001	
J	Stewart, B								Predicting project delivery rates using the Naive-Bayes classifier								JOURNAL OF SOFTWARE MAINTENANCE AND EVOLUTION-RESEARCH AND PRACTICE			14	3			161	179		10.1002/smr.250			MAY-JUN 2002	2002	The importance of accurate estimation of software development effort is well recognized in software engineering. In recent years, machine learning approaches have been studied as possible alternatives to more traditional software cost estimation methods. The objective of this paper is to investigate the utility of the machine learning algorithm known as the Naive-Bayes classifier for estimating software project effort. We present empirical experiments with the Benchmark 6 data set from the International Software Benchmarking Standards Group to estimate project delivery rates and compare the performance of the Naive-Bayes approach to two other machine learning methods model trees and neural networks. A project delivery rate is defined as the number of effort hours per function point. The approach described is general and can be used to analyse not only software development data but also data on software maintenance and other types of software engineering. The paper demonstrates that the Naive-Bayes classifier has a potential to be used as an alternative machine learning tool for software development effort estimation. Copyright (C) 2002 John Wiley Sons, Ltd.								9	1	0	0	10	1532-060X		WOS:000176563100002	
J	Mitchell, HB; Schaefer, PA								A "soft" K-Nearest Neighbor voting scheme								INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS			16	4			459	468		10.1002/int.1018			APR 2001	2001	The K-Nearest Neighbor (K-NN) voting scheme is widely used in problems requiring pattern recognition or classification. In this voting scheme an unknown pattern is classified according to the classifications of its K nearest neighbors. If a majority of the K nearest neighbors have a given classification C*, then the unknown pattern is also given the classification C*. Although the scheme works well it is sensitive to the number of nearest neighbors, K, which is used. In this paper we describe a fuzzy K-NN voting scheme in which effectively the value of K varies automatically according to the local density of known patterns. We find that the new scheme consistently outperforms the traditional K-NN algorithm. (C) 2001 John Wiley & Sons, Inc.								9	1	0	0	10	0884-8173		WOS:000167957300002	
J	Prevost, L; Milgram, M								Modelizing character allographs in omni-scriptor frame: a new non-supervised clustering algorithm								PATTERN RECOGNITION LETTERS			21	4			295	302		10.1016/S0167-8655(99)00159-2			APR 2000	2000	The "problem of the allographs" specific of the dynamic handwriting in omni-scriptor context renders the implementation of "classical" clustering algorithms particularly delicate because it introduces the notion of heterogeneous classes characterized by strongly variable example densities. We propose here a hybrid clustering algorithm combining both a prototype placement stage and an adaptation stage. The process reduces drastically the number of references to be examined during a k-nn classification while preserving to the classifier a high level of performance. The experience has been driven on an extensive alphabet including 80 classes. Recognition rates, evaluated on nearly 35 000 examples from the UNIPEN basis show the reliability of the modelization. (C) 2000 Published by Elsevier Science B.V. All rights reserved.								9	0	0	0	9	0167-8655		WOS:000086149600002	
J	Brusic, V; Zeleznikow, J								Knowledge discovery and data mining in biological databases								KNOWLEDGE ENGINEERING REVIEW			14	3			257	277		10.1017/S0269888999003069			SEP 1999	1999	The new technologies for Knowledge Discovery from Databases (KDD) and data mining promise to bring new insights into a voluminous growing amount of biological data. KDD technology is complementary to laboratory experimentation and helps speed up biological research. This article contains an introduction to KDD, a review of data mining tools, and their biological applications. We discuss the domain concepts related to biological data and databases, as well as current KDD and data mining developments in biology.								9	0	5	0	10	0269-8889		WOS:000084804100003	
J	Zhao, QF								Stable on-line evolutionary learning of NN-MLP								IEEE TRANSACTIONS ON NEURAL NETWORKS			8	6			1371	1378		10.1109/72.641460			NOV 1997	1997	To design the nearest-neighbor-based multilayer perceptron (NN-MLP) efficiently, the author has proposed a nongenetic-based evolutionary algorithm called the R-4-rule, For off-line learning, the R-4-rule can produce the smallest or nearly smallest networks with high generalization ability by iteratively performing four basic operations: recognition, remembrance, reduction, and review, This algorithm, however, cannot be applied directly to on-line learning because its inherent instability, which is caused by over-reduction and over-review, To stabilize the R-4-rule, this paper proposes some improvements for reduction and review, The improved reduction is more robust for on-line learning because the fitness of each hidden neuron is defined by its overall behavior in many learning cycles, The new review is more efficient because hidden neurons are adjusted in a more careful way, The performance of the improved R-4-rule for on-line learning is shown by experimental results.								9	0	0	0	9	1045-9227		WOS:A1997YE46600013	
J	NEUMANN, EK; WHEELER, DA; BERNSTEIN, AS; BURNSIDE, JW; HALL, JC								ARTIFICIAL NEURAL NETWORK CLASSIFICATION OF DROSOPHILA COURTSHIP SONG MUTANTS								BIOLOGICAL CYBERNETICS			66	6			485	496		10.1007/BF00204113			APR 1992	1992	Courtship songs produced by Drosophila males - wild-type, plus the cacophony and dissonance behavioral mutants - were examined with the aid of newly developed strategies for adaptive acoustic analysis and classification. This system used several techniques involving artificial neural networks (a.k.a. parallel distributed processing), including learned vector quantization of signals and non-linear adaption (back-propagation) of data analysis. "Pulse" song from several individual wild-type and mutant males were first vector-quantized according to their frequency spectra. The accumulated quantized data of this kind, for a given song, were then used to "teach" or adapt a multiple-layered feedforward artificial neural network, which classified that song according to its original genotype. Results are presented on the performance of the final adapted system when faced with novel test data and on acoustic features the system decides upon for predicting the song-mutant genotype in question. The potential applications and extensions of this new system are discussed, including how it could be used to screen for courtship mutants, search novel behavior patterns or cause-and-effect relationships associated with reproduction, compress these kinds of data for digital storage, and analyze Drosophila behavior beyond the case of courtship song.								9	0	7	0	9	0340-1200		WOS:A1992HR81500003	
J	BAUMANN, P; JURGENSEN, T; HEUCK, CC								COMPUTERIZED ANALYSIS OF THE INVITRO ACTIVATION OF THE PLASMATIC CLOTTING SYSTEM								HAEMOSTASIS			19	6			309	321					1989	1989									9	0	7	0	9	0301-0147		WOS:A1989CB21800002	
J	GOLIC, JD								ON THE RELATIONSHIP BETWEEN THE INFORMATION MEASURES AND THE BAYES PROBABILITY OF ERROR								IEEE TRANSACTIONS ON INFORMATION THEORY			33	5			681	693		10.1109/TIT.1987.1057357			SEP 1987	1987									9	0	0	0	9	0018-9448		WOS:A1987K769600008	
J	GREBLICKI, W								PATTERN-RECOGNITION PROCEDURES WITH NONPARAMETRIC DENSITY ESTIMATES								IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS			8	11			809	812					1978	1978									9	0	0	0	9	0018-9472		WOS:A1978FX49600005	
J	SCHATZKI, TF; VANDERCOOK, CE								NONPARAMETRIC METHODS FOR DETECTION OF ADULTERATION OF CONCENTRATED ORANGE JUICE FOR MANUFACTURING								JOURNAL OF THE ASSOCIATION OF OFFICIAL ANALYTICAL CHEMISTS			61	4			911	917					1978	1978									9	0	8	0	9	0004-5756		WOS:A1978FJ37400025	
J	GARNETT, JM; YAU, SS								NONPARAMETRIC ESTIMATION OF BAYES ERROR OF FEATURE EXTRACTORS USING ORDERED NEAREST NEIGHBOR SETS								IEEE TRANSACTIONS ON COMPUTERS			26	1			46	54					1977	1977									9	0	0	0	9	0018-9340		WOS:A1977CS75200007	
J	Kalina, T.; Flores-Montero, J.; van der Velden, V. H. J.; Martin-Ayuso, M.; Boettcher, S.; Ritgen, M.; Almeida, J.; Lhermitte, L.; Asnafi, V.; Mendonca, A.; de Tute, R.; Cullen, M.; Sedek, L.; Vidriales, M. B.; Perez, J. J.; te Marvelde, J. G.; Mejstrikova, E.; Hrusak, O.; Szczepanski, T.; van Dongen, J. J. M.; Orfao, A.		EuroFlow Consortium EU-FP6 LSHB-CT						EuroFlow standardization of flow cytometer instrument settings and immunophenotyping protocols								LEUKEMIA			26	9			1986	2010		10.1038/leu.2012.122			SEP 2012	2012	The EU-supported EuroFlow Consortium aimed at innovation and standardization of immunophenotyping for diagnosis and classification of hematological malignancies by introducing 8-color flow cytometry with fully standardized laboratory procedures and antibody panels in order to achieve maximally comparable results among different laboratories. This required the selection of optimal combinations of compatible fluorochromes and the design and evaluation of adequate standard operating procedures (SOPs) for instrument setup, fluorescence compensation and sample preparation. Additionally, we developed software tools for the evaluation of individual antibody reagents and antibody panels. Each section describes what has been evaluated experimentally versus adopted based on existing data and experience. Multicentric evaluation demonstrated high levels of reproducibility based on strict implementation of the EuroFlow SOPs and antibody panels. Overall, the 6 years of extensive collaborative experiments and the analysis of hundreds of cell samples of patients and healthy controls in the EuroFlow centers have provided for the first time laboratory protocols and software tools for fully standardized 8-color flow cytometric immunophenotyping of normal and malignant leukocytes in bone marrow and blood; this has yielded highly comparable data sets, which can be integrated in a single database.								8	0	6	0	8	0887-6924		WOS:000308342900004	
J	Huang, Di; Shan, Caifeng; Ardabilian, Mohsen; Wang, Yunhong; Chen, Liming				Ren, Huorong/C-9810-2012				Local Binary Patterns and Its Application to Facial Image Analysis: A Survey								IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART C-APPLICATIONS AND REVIEWS			41	6			765	781		10.1109/TSMCC.2011.2118750			NOV 2011	2011	Local binary pattern (LBP) is a nonparametric descriptor, which efficiently summarizes the local structures of images. In recent years, it has aroused increasing interest in many areas of image processing and computer vision and has shown its effectiveness in a number of applications, in particular for facial image analysis, including tasks as diverse as face detection, face recognition, facial expression analysis, and demographic classification. This paper presents a comprehensive survey of LBP methodology, including severalmore recent variations. As a typical application of the LBP approach, LBP-based facial image analysis is extensively reviewed, while its successful extensions, which deal with various tasks of facial image analysis, are also highlighted.								8	5	1	0	13	1094-6977		WOS:000296019400001	
J	van Dam, Herman T.; Seifert, Stefan; Vinke, Ruud; Dendooven, Peter; Lohner, Herbert; Beekman, Freek J.; Schaart, Dennis R.								Improved Nearest Neighbor Methods for Gamma Photon Interaction Position Determination in Monolithic Scintillator PET Detectors					1			IEEE TRANSACTIONS ON NUCLEAR SCIENCE			58	5			2139	2147		10.1109/TNS.2011.2150762			OCT 2011	2011	Monolithic scintillator detectors have been shown to provide good performance and to have various practical advantages for use in PET systems. Excellent results for the gamma photon interaction position determination in these detectors have been obtained by means of the k-nearest neighbor (k-NN) method. However, the practical use of monolithic scintillator detectors and the k-NN method is hampered by the extensive calibration measurements and the long computation times. Therefore, several modified k-NN methods are investigated that facilitate as well as accelerate the calibration procedure, make the estimation algorithm more efficient, and reduce the number of reference events needed to obtain a given lateral (x,y)-resolution. These improved methods utilize the information contained in the calibration data more effectively. The alternative approaches were tested on a dataset measured with a SiPM-array-based monolithic LYSO detector. It appears that, depending on the number of reference events, similar to 10% to similar to 25% better spatial resolution can be obtained compared to the standard approach. Moreover, the methods amongst these that are equivalent to calibrating with a line source may allow for much faster and easier collection of the reference data. Finally, some of the improved methods yield essentially the same spatial resolution as the standard method using similar to 200 times less reference data, greatly reducing the time needed for both calibration and interaction position computation. Thus, using the improvements proposed in this work, the high spatial resolution obtainable with the k-NN method may come within practical reach and, furthermore, the calibration may no longer be a limiting factor for the application of monolithic scintillator detectors in PET scanners.								8	0	5	0	8	0018-9499		WOS:000295780100001	
J	Huang, Kaizhu; Ying, Yiming; Campbell, Colin				Ying, Yiming/A-4196-2013				Generalized sparse metric learning with relative comparisons								KNOWLEDGE AND INFORMATION SYSTEMS			28	1			25	45		10.1007/s10115-010-0313-0			JUL 2011	2011	The objective of sparse metric learning is to learn a distance measure from a set of data in addition to finding a low-dimensional representation. Despite demonstrated success, the performance of existing sparse metric learning approaches is usually limited because the methods assumes certain problem relaxations or they target the SML objective indirectly. In this paper, we propose a Generalized Sparse Metric Learning method. This novel framework offers a unified view for understanding many existing sparse metric learning algorithms including the Sparse Metric Learning framework proposed in (Rosales and Fung ACM International conference on knowledge discovery and data mining (KDD), pp 367-373, 2006), the Large Margin Nearest Neighbor (Weinberger et al. in Advances in neural information processing systems (NIPS), 2006; Weinberger and Saul in Proceedings of the twenty-fifth international conference on machine learning (ICML-2008), 2008), and the D-ranking Vector Machine (D-ranking VM) (Ouyang and Gray in Proceedings of the twenty-fifth international conference on machine learning (ICML-2008), 2008). Moreover, GSML also establishes a close relationship with the Pairwise Support Vector Machine (Vert et al. in BMC Bioinform, 8, 2007). Furthermore, the proposed framework is capable of extending many current non-sparse metric learning models to their sparse versions including Relevant Component Analysis (Bar-Hillel et al. in J Mach Learn Res, 6:937-965, 2005) and a state-of-the-art method proposed in (Xing et al. Advances in neural information processing systems (NIPS), 2002). We present the detailed framework, provide theoretical justifications, build various connections with other models, and propose an iterative optimization method, making the framework both theoretically important and practically scalable for medium or large datasets. Experimental results show that this generalized framework outperforms six state-of-the-art methods with higher accuracy and significantly smaller dimensionality for seven publicly available datasets.								8	0	0	0	8	0219-1377		WOS:000292047400002	
J	Pang, Shaoning; Ban, Tao; Kadobayashi, Youki; Kasabov, Nikola								Personalized mode transductive spanning SVM classification tree								INFORMATION SCIENCES			181	11			2071	2085		10.1016/j.ins.2011.01.008			JUN 1 2011	2011	Personalized transductive learning (PTL) builds a unique local model for classification of individual test samples and is therefore practically neighborhood dependant; i.e. a specific model is built in a subspace spanned by a set of samples adjacent to the test sample. While existing PTL methods usually define the neighborhood by a predefined (dis)similarity measure, this paper introduces a new concept of a knowledgeable neighborhood and a transductive Support Vector Machine (SVM) classification tree (t-SVMT) for PTL. The neighborhood of a test sample is constructed over the classification knowledge modelled by regional SVMs, and a set of such SVMs adjacent to the test sample is systematically aggregated into a t-SVMT. Compared to a regular SVM and other SVMTs, a t-SVMT, by virtue of the aggregation of SVMs, has an inherent superiority in classifying class-imbalanced datasets. The t-SVMT has also solved the over-fitting problem of all previous SVMTs since it aggregates neighborhood knowledge and thus significantly reduces the size of the SVM tree. The properties of the t-SVMT are evaluated through experiments on a synthetic dataset, eight bench-mark cancer diagnosis datasets, as well as a case study of face membership authentication. (C) 2011 Elsevier Inc. All rights reserved.								8	0	0	0	8	0020-0255		WOS:000292622100002	
J	Aiello, Francesco; Fortino, Giancarlo; Gravina, Raffaele; Guerrieri, Antonio								A Java-Based Agent Platform for Programming Wireless Sensor Networks								COMPUTER JOURNAL			54	3			439	454		10.1093/comjnl/bxq019			MAR 2011	2011	Wireless sensor networks (WSNs) are emerging as powerful platforms for distributed embedded computing supporting a variety of high-impact applications. However, programming WSN applications is a complex task that requires suitable paradigms and technologies capable of supporting the specific characteristics of such networks which uniquely integrate distributed sensing, computation and communication. Mobile agents are a distributed computing paradigm based on code mobility that has already demonstrated high effectiveness and efficiency in IP-based highly dynamic distributed environments. Due to their intrinsic characteristics, mobile agents may provide more benefits in the context of WSNs than in conventional distributed environments. In this paper we present the design, implementation and experimentation of MAPS ( Mobile Agent Platform for Sun SPOT), an innovative Java-based framework for wireless sensor networks based on Sun SPOT technology which enables agent-oriented programming of WSN applications. The MAPS architecture is based on components that interact through events. Each component offers a minimal set of services to mobile agents that are modeled as multi-plane state machines driven by ECA rules. In particular, the offered services include message transmission, agent creation, agent cloning, agent migration, timer handling and easy access to the sensor node resources ( sensors, actuators, input switches, flash memory and battery). Agent programming with MAPS is presented through both a simple example related to mobile agent-based monitoring of a sensor node and a more complex case study for real-time human activity monitoring based on wireless body sensor networks. Moreover, a performance evaluation of MAPS carried out by computing micro-benchmarks, related to agent communication, creation and migration, is illustrated.								8	0	0	0	8	0010-4620		WOS:000287757100011	
J	Lee, Jong-Seok; Olafsson, Sigurdur								Data clustering by minimizing disconnectivity								INFORMATION SCIENCES			181	4			732	746		10.1016/j.ins.2010.10.028			FEB 15 2011	2011	Identifying clusters of arbitrary shapes remains a challenge in the field of data clustering. We propose a new measure of cluster quality based on minimizing the penalty of disconnection between objects that would be ideally clustered together. This disconnectivity is based on analysis of nearest neighbors and the principle that an object should be in the same cluster as its nearest neighbors. An algorithm called MinDisconnect is proposed that heuristically minimizes disconnectivity and numerical results are presented that indicate that the new algorithm can effectively identify clusters of complex shapes and is robust in finding clusters of arbitrary shapes. (C) 2010 Elsevier Inc. All rights reserved.								8	0	0	0	8	0020-0255		WOS:000286542600003	
J	Shen, Chunhua; Kim, Junae; Wang, Lei								Scalable Large-Margin Mahalanobis Distance Metric Learning								IEEE TRANSACTIONS ON NEURAL NETWORKS			21	9			1524	1530		10.1109/TNN.2010.2052630			SEP 2010	2010	For many machine learning algorithms such as k-nearest neighbor (k-NN) classifiers and k-means clustering, often their success heavily depends on the metric used to calculate distances between different data points. An effective solution for defining such a metric is to learn it from a set of labeled training samples. In this work, we propose a fast and scalable algorithm to learn a Mahalanobis distance metric. The Mahalanobis metric can be viewed as the Euclidean distance metric on the input data that have been linearly transformed. By employing the principle of margin maximization to achieve better generalization performances, this algorithm formulates the metric learning as a convex optimization problem and a positive semidefinite (p.s.d.) matrix is the unknown variable. Based on an important theorem that a p.s.d. trace-one matrix can always be represented as a convex combination of multiple rank-one matrices, our algorithm accommodates any differentiable loss function and solves the resulting optimization problem using a specialized gradient descent procedure. During the course of optimization, the proposed algorithm maintains the positive semidefiniteness of the matrix variable that is essential for a Mahalanobis metric. Compared with conventional methods like standard interior-point algorithms [2] or the special solver used in large margin nearest neighbor [24], our algorithm is much more efficient and has a better performance in scalability. Experiments on benchmark data sets suggest that, compared with state-of-the-art metric learning algorithms, our algorithm can achieve a comparable classification accuracy with reduced computational complexity.								8	0	0	0	8	1045-9227		WOS:000283231200014	
J	Arturo Olvera-Lopez, J.; Ariel Carrasco-Ochoa, J.; Francisco Martinez-Trinidad, J.; Kittler, Josef								A review of instance selection methods								ARTIFICIAL INTELLIGENCE REVIEW			34	2			133	143		10.1007/s10462-010-9165-y			AUG 2010	2010	In supervised learning, a training set providing previously known information is used to classify new instances. Commonly, several instances are stored in the training set but some of them are not useful for classifying therefore it is possible to get acceptable classification rates ignoring non useful cases; this process is known as instance selection. Through instance selection the training set is reduced which allows reducing runtimes in the classification and/or training stages of classifiers. This work is focused on presenting a survey of the main instance selection methods reported in the literature.								8	0	1	0	8	0269-2821		WOS:000279453500003	
J	Lee, Heesung; Hong, Sungjun; Nizami, Imran Fareed; Kim, Euntai								A Noise Robust Gait Representation: Motion Energy Image								INTERNATIONAL JOURNAL OF CONTROL AUTOMATION AND SYSTEMS			7	4			638	643		10.1007/s12555-009-0414-2			AUG 2009	2009	Gait-based human identification aims to discriminate individuals by the way they walk. A unique advantage of gait as a biometric is that it requires no subject contact and is easily acquired at a distance, which stands in contrast to other biometric techniques involving face, fingerprints, iris, etc. This paper proposes a new gait representation called motion energy image (MEI). Compared with other gait features, MEI is more robust against noise that can be included in binary gait silhouette images due to various factors. The effectiveness of the proposed method for gait recognition is demonstrated using experiments performed on the NLPR database.								8	0	0	0	8	1598-6446		WOS:000268509200014	
J	Bo, S.; Ding, L.; Li, H.; Di, F.; Zhu, C.								Mean shift-based clustering analysis of multispectral remote sensing imagery								INTERNATIONAL JOURNAL OF REMOTE SENSING			30	4			817	827		10.1080/01431160802395193			2009	2009	In clustering analysis of remote sensing imagery, a commonly held assumption is that the feature space can be modelled as a mixture of Gaussians. However, the assumption is not true for many real data and therefore incorrect classification results are often obtained by parametric methods. Nonparametric methods in feature space analysis can avoid the use of the normality assumption. Arbitrarily structured feature spaces can be analysed only by means of nonparametric methods as these methods do not have embedded assumptions. The mean shift is a basic computational module of the nonparametric technique in pattern recognition. The mean shift procedure can be used to cluster multispectral remote sensing imagery. Earlier clustering techniques based on the mean shift used a single scale over the entire feature space and were not feasible for the analysis of complex multimodal feature spaces. In this paper, we present an adaptive mean shift method in which local scale information is involved. The proposed algorithm can find arbitrary density, size and shape clusters in remote sensing imagery. The method is a simple technique of unsupervised image classification. We demonstrate its advantages in classification accuracy over earlier methods described in this paper.								8	0	2	0	8	0143-1161		WOS:000265409100001	
J	Aimeur, Esma; Brassard, Gilles; Fernandez, Jose M.; Onana, Flavien Serge Mani								ALAMBIC: a privacy-preserving recommender system for electronic commerce								INTERNATIONAL JOURNAL OF INFORMATION SECURITY			7	5			307	334		10.1007/s10207-007-0049-3			OCT 2008	2008	Recommender systems enable merchants to assist customers in finding products that best satisfy their needs. Unfortunately, current recommender systems suffer from various privacy-protection vulnerabilities. Customers should be able to keep private their personal information, including their buying preferences, and they should not be tracked against their will. The commercial interests of merchants should also be protected by allowing them to make accurate recommendations without revealing legitimately compiled valuable information to third parties. We introduce a theoretical approach for a system called Alambic, which achieves the above privacy-protection objectives in a hybrid recommender system that combines content-based, demographic and collaborative filtering techniques. Our system splits customer data between the merchant and a semi-trusted third party, so that neither can derive sensitive information from their share alone. Therefore, the system could only be subverted by a coalition between these two parties.								8	1	0	0	9	1615-5262		WOS:000259671500001	
S	Qi, Yinian; Atallah, Mikhail J.								Efficient Privacy-Preserving k-Nearest Neighbor Search								28TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS, VOLS 1 AND 2, PROCEEDINGS	INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS - PROCEEDINGS						311	319		10.1109/ICDCS.2008.79			2008	2008	We give efficient protocols for secure and private k-nearest neighbor (k-NN) search, when the data is distributed between two parties who want to cooperatively compute the answers without revealing to each other their private data. Our protocol for the single-step k-NN search is provably secure and has linear computation and communication complexity Previous work on this problem had a quadratic complexity, and also leaked information about the parties' inputs. We adapt our techniques to also solve the general multi-step k-NN search, and describe a specific embodiment of it for the case of sequence data. The protocols and correctness proofs can be extended to suit other privacy-preserving data mining tasks, such as classification and outlier detection.				28th International Conference on Distributed Computing Systems	JUN 17-20, 2008	IEEE	Beijing, PEOPLES R CHINA	8	0	0	0	8	1063-6927	978-1-4244-3174-8	WOS:000263415700037	
J	Chin, Cesar Marquez; Popovic, Milos R.; Thrasher, Adam; Cameron, Tracy; Lozano, Andres.; Chen, Robert				Chen, Robert/B-3899-2009				Identification of arm movements using correlation of electrocorticographic spectral components and kinematic recordings								JOURNAL OF NEURAL ENGINEERING			4	2			146	158		10.1088/1741-2560/4/2/014			JUN 2007	2007	The purpose of this study was to explore the possibility of using electrocorticographic (ECoG) recordings from subdural electrodes placed over the motor cortex to identify the upper limb motion performed by a human subject. More specifically, we were trying to identify features in the ECoG signals that could help us determine the type of movement performed by an individual. Two subjects who had subdural electrodes implanted over the motor cortex were asked to perform various motor tasks with the upper limb contralateral to the site of electrode implantation. ECoG signals and. upper limb kinematics were recorded while the participants were performing the movements. ECoG frequency components were identified that correlated well with the performed movements measured along 6D coordinates (X, Y, Z, roll, yaw and pitch). These frequencies were grouped using histograms. The resulting histograms had consistent and unique shapes that were representative of individual upper limb movements performed by the participants. Thus, it was possible to identify which movement was performed by the participant without prior knowledge of the arm and hand kinematics. To confirm these findings, a nearest neighbour classifier was applied to identify the specific movement that each participant had performed. The achieved classification accuracy was 89%.								8	0	4	0	9	1741-2560		WOS:000247947300020	
S	Jafari, Roozbeh; Li, Wenchao; Bajcsy, Ruzena; Glaser, Steven; Sastry, Shankar						Leonhardt, S; Falck, T; Mahonen, P		Physical activity monitoring for assisted living at home								4th International Workshop on Wearable and Implantable Body Sensor Networks (BSN 2007)	IFMBE Proceedings		13				213	219					2007	2007	We propose a methodology to determine the occurrence of falls from among other common human movements. The source data is collected by wearable and mobile platforms based on three-axis accelerometers to measure subject kinematics. Our signal processing consists of preprocessing, pattern recognition and classification. One problem with data acquisition is the extensive variation in the morphology of acceleration signals of different patients and under various conditions. We explore several effective key features that can be used for classification of physical movements. Our objective is to enhance the accuracy of movement recognition. We employ classifiers based on neural networks and k-nearest neighbors. Our experimental results exhibit an average of 84% accuracy in movement tracking for four distinct activities over several test subjects.				4th International Workshop on Wearable and Implantable Body Sensor Networks (BSN 2007)	MAR 26-28, 2007		RWTH Aachen Univ, Aachen, GERMANY	8	0	0	0	8	1680-0737	978-3-540-70993-0	WOS:000246511700037	
S	Song, Yan; Huang, Jian; Zhou, Ding; Zha, Hongyuan; Giles, C. Lee						Kok, JN; Koronacki, J; DeMantaras, RL; Matwin, S; Mladenic, D; Skowron, A		IKNN: Informative K-nearest neighbor pattern classification								Knowledge Discovery in Databases: PKDD 2007, Proceedings	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		4702				248	264					2007	2007	The K-nearest neighbor (KNN) decision rule has been a ubiquitous classification tool with good scalability. Past experience has shown that the optimal choice of K depends upon the data, making it laborious to tune the parameter for different applications. We introduce a new metric that measures the informativeness of objects to be classified. When applied as a query-based distance metric to measure the closeness between objects, two novel KNN procedures, Locally Informative-KNN (LI-KNN) and Globally Informative-KNN (GI-KNN), are proposed. By selecting a subset of most informative objects from neighborhoods, our methods exhibit stability to the change of input parameters, number of neighbors(K) and informative points (I). Experiments on UCI benchmark data and diverse real-world data sets indicate that our approaches are application-independent and can generally outperform several popular KNN extensions, as well as SVM and Boosting methods.				18th European Conference on Machine Learning (ECML 2007)/11th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD 2007)	SEP 17-21, 2007	Warsaw Univ, Fac Math, Informat & Mech; Polish Acad Sci, Inst Comp Sci; European Off Aerosp Res & Dev; Air Force Off Sci Res; USAF Res Lab	Warsaw Univ, Warsaw, POLAND	8	0	2	0	8	0302-9743	978-3-540-74975-2	WOS:000249743700021	
J	Chang, Fu; Lin, Chin-Chin; Lu, Chi-Jen								Adaptive prototype learning algorithms: Theoretical and experimental studies								JOURNAL OF MACHINE LEARNING RESEARCH			7				2125	2148					OCT 2006	2006	In this paper, we propose a number of adaptive prototype learning (APL) algorithms. They employ the same algorithmic scheme to determine the number and location of prototypes, but differ in the use of samples or the weighted averages of samples as prototypes, and also in the assumption of distance measures. To understand these algorithms from a theoretical viewpoint, we address their convergence properties, as well as their consistency under certain conditions. We also present a soft version of APL, in which a non-zero training error is allowed in order to enhance the generalization power of the resultant classifier. Applying the proposed algorithms to twelve UCI benchmark data sets, we demonstrate that they outperform many instance-based learning algorithms, the k-nearest neighbor rule, and support vector machines in terms of average test accuracy.								8	0	0	0	8	1532-4435		WOS:000245390500007	
J	Matsubara, Yoshiya; Kikuchi, Shinichi; Sugimoto, Masahiro; Tomita, Masaru				Kikuchi, Shinichi/A-1681-2010				Parameter estimation for stiff equations of biosystems using radial basis function networks								BMC BIOINFORMATICS			7						230	10.1186/1471-2105-7-230			APR 27 2006	2006	Background: The modeling of dynamic systems requires estimating kinetic parameters from experimentally measured time-courses. Conventional global optimization methods used for parameter estimation, e. g. genetic algorithms (GA), consume enormous computational time because they require iterative numerical integrations for differential equations. When the target model is stiff, the computational time for reaching a solution increases further.Results: In an attempt to solve this problem, we explored a learning technique that uses radial basis function networks (RBFN) to achieve a parameter estimation for biochemical models. RBFN reduce the number of numerical integrations by replacing derivatives with slopes derived from the distribution of searching points. To introduce a slight search bias, we implemented additional data selection using a GA that searches data-sparse areas at low computational cost. In addition, we adopted logarithmic transformation that smoothes the fitness surface to obtain a solution simply. We conducted numerical experiments to validate our methods and compared the results with those obtained by GA. We found that the calculation time decreased by more than 50% and the convergence rate increased from 60% to 90%.Conclusion: In this work, our RBFN technique was effective for parameter optimization of stiff biochemical models.								8	0	7	0	8	1471-2105		WOS:000240415400001	
B	Blanzieri, Enrico; Melgani, Farid			IEEE					An Adaptive SVM Nearest Neighbor Classifier for Remotely Sensed Imagery								2006 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM, VOLS 1-8	IEEE International Symposium on Geoscience and Remote Sensing (IGARSS)						3931	3934		10.1109/IGARSS.2006.1008			2006	2006	In this paper, we propose an extension of the kNN classifier based on the maximum margin principle. The proposed method is based on the idea to classify a given unlabeled sample by first finding its k nearest training samples. Then, a local partition of the feature space is carried out by means of local SVM decision boundaries determined after training a multiclass SVM classifier on the k training samples considered. The labeling of the unknown sample is done by looking at the local decision region it belongs to. The resulting global decision boundaries throughout the entire feature space are piecewise linear. The entire process can be however kernelized through the determination of the k nearest training samples in the kernel space by using a distance function simply reformulated on the basis of the adopted kernel. To illustrate the performance of the proposed method, an experimental analysis on different remote sensing data sets is reported and discussed.				IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	JUL 31-AUG 04, 2006	IEEE; IEEE Geosci & Remote Sensing Soc; Canadian Remote Sensing Soc; NASA; NOAA; Off Naval Res; Natl Polar Orbiting Operat Environm Satellite Syst; Japan Aerosp Explorat Agcy; Ball Aerosp & Technologies Corp; Cooperat Inst Res Atmosphere; Colorado State Univ; Univ Colorado; Int Union Radio Sci	Denver, CO	8	0	1	0	8		978-0-7803-9509-1	WOS:000260989402194	
J	Raicharoen, T; Lursinsap, C								A divide-and-conquer approach to the pairwise opposite class-nearest neighbor (POC-NN) algorithm								PATTERN RECOGNITION LETTERS			26	10			1554	1567		10.1016/j.patrec.2005.01.003			JUL 15 2005	2005	This paper presents a new method based on divide-and-conquer approach to the selection and replacement of a set of prototypes from the training set for the nearest neighbor rule, This method aims at reducing the computational time and the memory space as well as the sensitivity of the order and the noise of the training data. A reduced prototype set contains Pairwise Opposite Class-Nearest Neighbor (POC-NN) prototypes which are close to the decision boundary and used instead of the training patterns. POC-NN prototypes are obtained by recursively iterative separation and analysis of the training data into two regions until each region is correctly grouped and classified, The separability is determined by the POC-NN prototypes essential to define the locations of all separating hyperplaries, Our method is fast and order independent. The number of prototypes and the overfitting of the model can be reduced by the User, The experimental results signify the effectiveness of this technique and its performance in both accuracy and prototype rate as well as in training time to those obtained by classical nearest neighbor techniques. (c) 2005 Elsevier B.V. All rights reserved.								8	0	0	1	9	0167-8655		WOS:000230006800015	
J	Nitschke, G								Emergence of cooperation: State of the art								ARTIFICIAL LIFE			11	3			367	396		10.1162/1064546054407194			SUM 2005	2005	This review presents a review of prevalent results within research pertaining to emergent cooperation in biologically inspired artificial social systems. Results reviewed maintain particular reference to biologically inspired design principles, given that current mathematical and empirical tools have provided only a partial insight into elucidating mechanisms responsible for emergent cooperation, and then only in systems of an abstract nature. ThiS review, aims to provide an overview of important and disparate research contributions that investigate utilization of biologically inspired concepts such as emergence, evolution, and self-organization as a means of attaining cooperation in artificial social systems. An introduction and overview of emergent cooperation in artificial life is presented, followed by 2 survey of emergent cooperation in swarm-based systems, the pursuit-evasion domain, and RohoCup soccer. The final section draws conclusions regarding future directions of emergent cooperation as a problem-solving methodology that is potentially applicable in a wide range of problem domains. Within each of these sections and their respective themes of research, the mechanisms deemed to he responsible for emergent cooperation are elucidated and their key limitations highlighted. The review concludes that Current studies in emergent cooperative behavior Are limited by a hick of situated and embodied approaches, and I)v the research infancy of current biologically inspired design approaches. Despite these limiting factors, emergent cooperation maintains considerable future potential in a wide variety of application domains where systems composed of many interacting components must cooperatively perform Unanticipated global tasks.								8	0	2	0	8	1064-5462		WOS:000230431600008	
J	Karacali, B; Ramanath, R; Snyder, WE								A comparative analysis of structural risk minimization by support vector machines and nearest neighbor rule								PATTERN RECOGNITION LETTERS			25	1			63	71		10.1016/j.patrec.2003.09.002			JAN 5 2004	2004	Support vector machines (SVMs) are by far the most sophisticated and powerful classifiers available today. However, this robustness and novelty in approach come at a large computational cost. On the other hand, nearest neighbor (NN) classifiers provide a simple yet robust approach that is guaranteed to converge to a result. In this paper, we present a technique that combines these two classifiers by adopting a NN rule-based structural risk minimization classifier. Using synthetic and real data, the classification technique is shown to be more robust to kernel conditions with a significantly lower computational cost than conventional SVMs. Consequently, the proposed method provides a powerful alternative to SVMs in applications where computation time and accuracy are of prime importance. Experimental results indicate that the NNSRM formulation is not only computationally less expensive, but also much more robust to varying data representations than SVMs. (C) 2003 Elsevier B.V. All rights reserved.								8	1	1	0	9	0167-8655		WOS:000187554800006	
J	Luaces, O; Bahamonde, A								Inflating examples to obtain rules								INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS			18	11			1113	1143		10.1002/int.10132			NOV 2003	2003	A new machine learning system is presented in this article. It is called INNER and induces classification rules from a set of training examples. The process followed by this system starts with the random selection of a subset of examples that are iteratively inflated in order to cover the surroundings provided that they are inhabited by examples of the same class, thus becoming rules that will be applied by means of a partial matching mechanism. The rules so obtained can be seen as clusters of examples and represent clear evidence to support explanations about their future classifications and may be used to build intelligent advisors. The whole algorithm can be seen as a set of elastic transformations of examples and rules and produces concise, accurate rule sets, as is experimentally demonstrated in the final section of the article. (C) 2003 Wiley Periodicals, Inc.								8	0	0	0	8	0884-8173		WOS:000185905500002	
J	Singh, S								PRISM - A novel framework for pattern recognition								PATTERN ANALYSIS AND APPLICATIONS			6	2			134	149		10.1007/s10044-002-0186-2			JUL 2003	2003	In this paper, we introduce a new model of solving pattern recognition tasks called PRISM (Pattern Recognition using Information Slicing Method). The main concept behind PRISM is the slicing of information through multiple planes across different feature axes to generate a number of cells. The number of cells created and their volume depends upon the number partitions per axes. In this context we define resolution as the number of partitions per axes. In this paper, we make the following contributions. First, we provide a brief survey of the class separability measures and feature partitioning schemes used for pattern recognition. Secondly, we define the PRISM framework and the algorithm for data assignment to cells. Thirdly, we detail four important concepts in PRISM: purity, neighbourhood separability, collective entropy, and data compactness. The first two measures define the data complexity, the next measure relates to uncertainty, and the last measure defines the alternative to statistical data variance in the PRISM framework. Fourthly, we investigate the variability in the estimates of these measures depending on the placement of partitions on each feature axis. Finally, we give an overview of experimental successes achieved with PRISM in the areas of classification complexity estimation and feature selection.								8	0	1	0	8	1433-7541		WOS:000184757800004	
J	Emrahoglu, N; Yegingil, I; Pestemalci, V; Senkal, O; Kandirmaz, HM								Comparison of a new algorithm with the supervised classifications								INTERNATIONAL JOURNAL OF REMOTE SENSING			24	4			649	655		10.1080/01431160210145597			FEB 20 2003	2003	In this study, a new classification algorithm in which only the selected pixels have been attempted to be classified (selected pixels classification: SPC) has been introduced and compared with the well known supervised classification methods such as maximum likelihood, minimum distance, nearest neighbour and condensed nearest neighbour. To examine the algorithm, Landsat Thematic Mapper (TM) data have been used to classify the crop cover in the selected region. It is clearly demonstrated that the SPC method has the higher accuracy with comparable CPU times.								8	0	2	0	8	0143-1161		WOS:000181422100003	
J	Bagui, SC; Bagui, S; Pal, K; Pal, NR								Breast cancer detection using rank nearest neighbor classification rules								PATTERN RECOGNITION			36	1			25	34	PII S0031-3202(02)00044-4	10.1016/S0031-3203(02)00044-4			JAN 2003	2003	In this article, we propose a new generalization of the rank nearest neighbor (RNN) rule for multivariate data for diagnosis of breast cancer. We study the performance of this rule using two well known databases and compare the results with the conventional k-NN rule. We observe that this rule performed remarkably well, and the computational complexity of the proposed k-RNN is much less than the conventional k-NN rule. (C) 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.								8	0	1	0	8	0031-3203		WOS:000179101000003	
S	del Coz, JJ; Luaces, O; Quevedo, JR; Alonso, J; Ranilla, J; Bahamonde, A						Mira, J; SanchezAndres, JV		Self-organizing cases to find paradigms								FOUNDATIONS AND TOOLS FOR NEURAL MODELING, PROCEEDINGS, VOL I	LECTURE NOTES IN COMPUTER SCIENCE		1606				527	536					1999	1999	Case-based information systems can be seen as lazy machine learning algorithms; they select a number of training instances and then classify unseen cases as the most similar stored instance. One of the main disadvantages of these systems is the high number of patterns retained. In this paper, a new method for extracting just a small set of paradigms from a set of training examples is presented. Additionally, we provide the set of attributes describing the representative examples that are relevant for classification purposes. Our algorithm computes the Kohonen self-organizing maps attached to the training set to then compute the coverage of each map node. Finally, a heuristic procedure selects both the paradigms and the dimensions (or attributes) to be considered when measuring similarity in future classification tasks.				5th International Work-Conference on Artificial and Natural Neural Networks (IWANN 99)	JUN 02-04, 1999	Asociac Espanola Redes Neuronales; Univ Nacl Educ Distancia; Univ Miguel Hernandez; IFIP; Spanish RIG IEEE Neural Networks Council	ALICANTE, SPAIN	8	0	3	0	8	0302-9743	3-540-66069-0	WOS:000165140200056	
B	Nguyen, SH; Skowron, A				Nguyen, Sinh Hoa/G-8901-2013		Komorowski, J; Zytkow, J		Searching for relational patterns in data								PRINCIPLES OF DATA MINING AND KNOWLEDGE DISCOVERY	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		1263				265	276					1997	1997	We consider several basic classes of tolerance relations among objects. These (global) relations are defined from some predefined similarity measures on Values of attributes. A tolerance relation in a given class of tolerance relations is optimal with respect to a given decision table A if it contains only pairs of objects with the same decision and the number of such pairs contained in the relation is maximal among all relations from the class. We present a method for (sub-)optimal tolerance relation learning from data (decision table). The presented method is based on rough set approach. We show that for some basic families of tolerance relations this problem can be transformed to a relative geometrical problem in a real affine space. Hence geometrical computations are becoming useful tools for solving the problem of global tolerance relation construction. The complexity of considered problems can be evaluated by the complexity of the corresponding geometrical problems. We propose some efficient heuristics searching for an approximation of optimal tolerance relations in considered families of tolerance relations. The global tolerance relations can be treated as patterns in the cartesian product of the object set. We show how to apply the relational patterns (global tolerance relations) in clustering and classification of objects.				1st European Symposium on Principles of Data Mining and Knowledge Discovery (PKDD 97)	JUN 24-27, 1997		TRONDHEIM, NORWAY	8	2	0	0	10		3-540-63223-9	WOS:000073947600026	
J	BAGUI, SC; PAL, NR								A MULTISTAGE GENERALIZATION OF THE RANK NEAREST-NEIGHBOR CLASSIFICATION RULE								PATTERN RECOGNITION LETTERS			16	6			601	614		10.1016/0167-8655(95)80006-F			JUN 1995	1995	We consider the problem of classifying an unknown observation from one of s (greater than or equal to 2) univariate classes (or populations) using a multi-stage left and right rank nearest neighbor (RNN) rule. We derive the asymptotic error rate (i.e., total probability of misclassification (TPMC)) of the m-stage univariate RNN (m-URNN) rule, and show that as the number of stages increases, the limiting TPMC of the m-stage univariate rule decreases. Monte Carlo simulations are used to study the behavior of the m-URNN rule and compare it with the conventional R-NN rule. Finally, we incorporate an extension of the m-URNN rule to multivariate observations with empirical results.								8	0	1	0	8	0167-8655		WOS:A1995RD53900006	
J	MCKENZIE, DP; FORSYTH, RS								CLASSIFICATION BY SIMILARITY - AN OVERVIEW OF STATISTICAL-METHODS OF CASE-BASED REASONING								COMPUTERS IN HUMAN BEHAVIOR			11	2			273	288		10.1016/0747-5632(94)00036-H			SUM 1995	1995	There has recently been a great deal of interest in case-based reasoning, the generation of solutions to new problems using methods which have served for similar problems in the past. Much of the commonly available computer software is however concerned with ''case-retrieval.'' The fatter involves the matching of an observation for which the outcome is not known, to a database of examples for which the outcome is known. Various types of case retrieval, or ''classification by similarity'' (CBS), algorithms are discussed. Several CBS algorithms, as well as various other techniques, were applied to two small datasets. Although more comparisons are required the CBS algorithms were found to perform significantly better than a linear discriminant analysis on a predominantly binary dataset. A single-nearest-nsighbor technique, first developed in the 1950s, performed particularly well on this dataset. A more sophisticated CBS algorithm, based upon a type of neural network, performed consistently well on bath datasets. As CBS techniques generally encourage the researcher to work closely with databases, they should be developed further Progress needs to be made in the identification of ''good'' subsets of classifier variables, as well as in bridging the gap between statistical techniques and artificial intelligence.								8	2	1	0	10	0747-5632		WOS:A1995RA12800009	
J	MUNIZ, EC; VASQUEZ, PAM; BRUNS, RE; NUNES, SP; WOLF, BA								POLYMER-POLYMER MISCIBILITY EVALUATION BY ACOUSTIC-EMISSION								MAKROMOLEKULARE CHEMIE-RAPID COMMUNICATIONS			13	1			45	53					JAN 1992	1992									8	0	1	0	8	0173-2803		WOS:A1992HD20500008	
J	JOUSSELLIN, A; DUBUISSON, B								A LINK BETWEEN K-NEAREST NEIGHBOR RULES AND KNOWLEDGE BASED SYSTEMS BY SEQUENCE-ANALYSIS								PATTERN RECOGNITION LETTERS			6	5			287	295		10.1016/0167-8655(87)90011-0			DEC 1987	1987									8	0	0	0	8	0167-8655		WOS:A1987L109600002	
J	HENRY, DR; BLOCK, JH								PATTERN-RECOGNITION OF STEROIDS USING FRAGMENT MOLECULAR CONNECTIVITY								JOURNAL OF PHARMACEUTICAL SCIENCES			69	9			1030	1034		10.1002/jps.2600690913			1980	1980									8	0	3	0	8	0022-3549		WOS:A1980KG72500012	
J	GYORFI, L; GYORFI, Z								UPPER BOUND ON ASYMPTOTIC ERROR PROBABILITY OF K-NEAREST NEIGHBOR RULE FOR MULTIPLE CLASSES								IEEE TRANSACTIONS ON INFORMATION THEORY			24	4			512	514		10.1109/TIT.1978.1055900			1978	1978									8	0	1	0	8	0018-9448		WOS:A1978FJ91500020	
J	DEVIJVER, PA								ENTROPIES OF DEGREE-BETA AND LOWER BOUNDS FOR AVERAGE ERROR RATE								INFORMATION AND CONTROL			34	3			222	226		10.1016/S0019-9958(77)90294-7			1977	1977									8	0	0	0	8	0019-9958		WOS:A1977DQ42800004	
J	Min, Fan; Zhu, William								Attribute reduction of data with error ranges and test costs								INFORMATION SCIENCES			211				48	67		10.1016/j.ins.2012.04.031			NOV 30 2012	2012	In data mining applications, we have a number of measurement methods to obtain a data item with different test costs and different error ranges. Test costs refer to time, money, or other resources spent in obtaining data items related to some object; observational errors correspond to differences in measured and true value of a data item. In supervised learning, we need to decide which data items to obtain and which measurement methods to employ, so as to minimize the total test cost and help in constructing classifiers. This paper studies this problem in four steps. First, data models are built to address error ranges and test costs. Second, error-range-based covering rough set is constructed to define lower and upper approximations, positive regions, and relative reducts. A closely related theory deals with neighborhood rough set, which has been successfully applied to heterogeneous attribute reduction. The major difference between the two theories is the definition of neighborhood. Third, the minimal test cost attribute reduction problem is redefined in the new theory. Fourth, both backtrack and heuristic algorithms are proposed to deal with the new problem. The algorithms are tested on ten UCI (University of California - Irvine) datasets. Experimental results show that the backtrack algorithm is efficient on rational-sized datasets, the weighting mechanism for the heuristic information is effective, and the competition approach can improve the quality of the result significantly. This study suggests new research trends concerning attribute reduction and covering rough set. (C) 2012 Elsevier Inc. All rights reserved.								7	0	1	0	7	0020-0255		WOS:000307326900004	
J	Wen, Jie; Arthur, Kelly; Chemmalil, Letha; Muzammil, Salman; Gabrielson, John; Jiang, Yijia								Applications of differential scanning calorimetry for thermal stability analysis of proteins: Qualification of DSC								JOURNAL OF PHARMACEUTICAL SCIENCES			101	3			955	964		10.1002/jps.22820			MAR 2012	2012	Differential scanning calorimetry (DSC) has been used to characterize protein thermal stability, overall conformation, and domain folding integrity by the biopharmaceutical industry. Recently, there have been increased requests from regulatory agencies for the qualification of characterization methods including DSC. Understanding the method precision can help determine what differences between samples are significant and also establish the acceptance criteria for comparability and other characterization studies. In this study, we identify the parameters for the qualification of DSC for thermal stability analysis of proteins. We use these parameters to assess the precision and sensitivity of DSC and demonstrate that DSC is suitable for protein thermal stability analysis for these purposes. Several molecules from different structural families were studied. The experiments and data analyses were performed by different analysts using different instruments at different sites. The results show that the (apparent) thermal transition midpoint (Tm) values obtained for the same protein by same and different instruments and/or analysts are quite reproducible, and the profile similarity values obtained for the same protein from the same instrument are also high. DSC is an appropriate method for assessing protein thermal stability and conformational changes. (c) 2011 Wiley Periodicals, Inc. and the American Pharmacists Association J Pharm Sci 101:955964, 2012								7	0	6	0	7	0022-3549		WOS:000299074300007	
J	Cao, Jiuwen; Lin, Zhiping; Huang, Guang-Bin; Liu, Nan								Voting based extreme learning machine								INFORMATION SCIENCES			185	1			66	77		10.1016/j.ins.2011.09.015			FEB 15 2012	2012	This paper proposes an improved learning algorithm for classification which is referred to as voting based extreme learning machine. The proposed method incorporates the voting method into the popular extreme learning machine (ELM) in classification applications. Simulations on many real world classification datasets have demonstrated that this algorithm generally outperforms the original ELM algorithm as well as several recent classification algorithms. (C) 2011 Elsevier Inc. All rights reserved.								7	0	2	0	7	0020-0255		WOS:000297611600005	
J	Watanabe, Toshiaki; Kobunai, Takashi; Yamamoto, Yoko; Matsuda, Keiji; Ishihara, Soichiro; Nozawa, Keijiro; Iinuma, Hisae; Ikeuchi, Hiroki; Eshima, Kiyoshi								Differential gene expression signatures between colorectal cancers with and without KRAS mutations: Crosstalk between the KRAS pathway and other signalling pathways								EUROPEAN JOURNAL OF CANCER			47	13			1946	1954		10.1016/j.ejca.2011.03.029			SEP 2011	2011	Purpose: KRAS mutation is an important predictive marker in determining resistance to anti-Epidermal Growth Factor Receptor (EGFR) antibody therapies. In order to clarify whether not only KRAS related signalling pathways but also other signalling pathways are altered in patients with colorectal cancers (CRCs) with KRAS mutations, we examined the differences in the gene expression signatures between CRCs with and without KRAS mutation.Patients and methods: One-hundred and thirteen patients who underwent a surgical resection of a primary CRC were examined. KRAS mutational status was determined using the Peptide Nucleic Acid (PNA)-clamp real-time polymerase chain reaction (PCR) TaqMan assay. Gene expression profiles were compared between CRCs with and without KRAS mutation using the Human Genome GeneChip array U133.Results: Among 113 CRCs, KRAS mutations were present in 35 tumours (31%). We identified 30 genes (probes) that were differentially expressed between CRCs with and without KRAS mutation (False Discovery Rate (FDR), p < 0.01), by which we were able to predict the KRAS status with an accuracy of 90.3%. Thirty discriminating genes included TC21, paired-like homeodomain 1 (PITX1), Sprouty-2, dickkopf homologue 4 (DKK-4), SET and MYND domain containing 3 (SMYD3), mitogen-activated protein kinase kinase kinase 14 (MAP3K14) and c-mer Proto-oncogene tyrosine kinase (MerTK). These genes were related to not only KRAS related signalling pathway but also to other signalling pathways, such as the Wnt-signalling pathway, the NF-kappa B activation pathway and the TGF-beta signalling pathway.Conclusions: KRAS mutant CRCs exhibited a distinct gene expression signature different from wild-type KRAS CRCs. Using human CRC samples, we were able to show that there is crosstalk between the KRAS-mediated pathway and other signalling pathways. These results are necessary to be taken into account in establishing chemotherapeutic strategies for patients with anti-EGFR-refractory KRAS mutant CRCs. (C) 2011 Elsevier Ltd. All rights reserved.								7	0	5	0	7	0959-8049		WOS:000295116600004	
J	Kolodyazhniy, Vitaliy; Kreibig, Sylvia D.; Gross, James J.; Roth, Walton T.; Wilhelm, Frank H.								An affective computing approach to physiological emotion specificity: Toward subject-independent and stimulus-independent classification of film-induced emotions								PSYCHOPHYSIOLOGY			48	7			908	922		10.1111/j.1469-8986.2010.01170.x			JUL 2011	2011	The hypothesis of physiological emotion specificity has been tested using pattern classification analysis (PCA). To address limitations of prior research using PCA, we studied effects of feature selection (sequential forward selection, sequential backward selection), classifier type (linear and quadratic discriminant analysis, neural networks, k-nearest neighbors method), and cross-validation method (subject- and stimulus-(in)dependence). Analyses were run on a data set of 34 participants watching two sets of three 10-min film clips (fearful, sad, neutral) while autonomic, respiratory, and facial muscle activity were assessed. Results demonstrate that the three states can be classified with high accuracy by most classifiers, with the sparsest model having only five features, even for the most difficult task of identifying the emotion of an unknown subject in an unknown situation (77.5%). Implications for choosing PCA parameters are discussed.								7	0	1	0	7	0048-5772		WOS:000291255500004	
J	Przewozniczek, Michal; Walkowiak, Krzysztof; Wozniak, Michal				Wozniak, Michal/A-4806-2008				Optimizing distributed computing systems for k-nearest neighbours classifiers-evolutionary approach								LOGIC JOURNAL OF THE IGPL			19	2			357	372		10.1093/jigpal/jzq034			APR 2011	2011	Since the amount of information is rapidly growing, there is an overwhelming interest in efficient network computing. In this article, we take a detailed look at the problem of modelling and optimization of aforementioned systems for k-nearest neighbour classifier. First, we present a comprehensive discussion on considered classification methods with a special focus on improving classification accuracy or response time through the use of partitions of original data set for the nearest neighbour rule. Next, we propose a generic optimization model of a network computing system that can be used for distributed implementation of aforementioned recognition methods. The objective is to minimize the response time of the computing system applied for tasks related to k-nearest neighbours classifiers. We solve the problem using traditional branch and cut method and original algorithm GReTiMA based on a genetic approach as well. To illustrate our work, we provide results of numerical experiments showing the performance of the evolutionary approach compared against optimal results. Moreover, we show that the distributed approach enables significant improvement of the system response time.								7	0	0	0	7	1367-0751		WOS:000289313000007	
S	Jankowski, Norbert; Grabczewski, Krzysztof						Jankowski, N; Duch, W; Grabczewski, K		Universal Meta-Learning Architecture and Algorithms								META-LEARNING IN COMPUTATIONAL INTELLIGENCE	Studies in Computational Intelligence		358				1	76			10.1007/978-3-642-20980-2		2011	2011	There are hundreds of algorithms within data mining. Some of them are used to transform data, some to build classifiers, others for prediction, etc. Nobody knows well all these algorithms and nobody can know all the arcana of their behavior in all possible applications. How to find the best combination of transformation and final machine which solves given problem?The solution is to use configurable and efficient meta-learning to solve data mining problems. Below, a general and flexible meta-learning system is presented. It can be used to solve different problems with computational intelligence, basing on learning from data.The main ideas of our meta-learning algorithms lie in complexity controlled loop, searching for most adequate models and in using special functional specification of search spaces (the meta-learning spaces) combined with flexible way of defining the goal of meta-searching.								7	0	0	0	7	1860-949X	978-3-642-20979-6	WOS:000292078600001	
J	Antiqueira, Lucas; Rodrigues, Francisco A.; van Wijk, Bernadette C. M.; Costa, Luciano da F.; Daffertshofer, Andreas				Rodrigues, Francisco Aparecido/E-4418-2011; Antiqueira, Lucas/E-9668-2011; Costa, Luciano/H-5475-2011				Estimating complex cortical networks via surface recordings-A critical note								NEUROIMAGE			53	2			439	449		10.1016/j.neuroimage.2010.06.018			NOV 1 2010	2010	We discuss potential caveats when estimating topologies of 3D brain networks from surface recordings. It is virtually impossible to record activity from all single neurons in the brain and one has to rely on techniques that measure average activity at sparsely located (non-invasive) recording sites Effects of this spatial sampling in relation to structural network measures like centrality and assortativity were analyzed using multivariate classifiers A simplified model of 3D brain connectivity incorporating both short- and long-range connections served for testing. To mimic M/EEG recordings we sampled this model via non-overlapping regions and weighted nodes and connections according to their proximity to the recording sites We used various complex network models for reference and tried to classify sampled versions of the "brain-like" network as one of these archetypes It was found that sampled networks may substantially deviate in topology from the respective original networks for small sample sizes For experimental studies this may imply that surface recordings can yield network structures that might not agree with its generating 3D network. (C) 2010 Elsevier Inc All rights reserved								7	0	6	0	7	1053-8119		WOS:000281688000008	
J	Qi, Xin; Pan, Yinsheng; Sivak, Michael V., Jr.; Willis, Joseph E.; Isenberg, Gerard; Rollins, Andrew M.								Image analysis for classification of dysplasia in Barrett's esophagus using endoscopic optical coherence tomography								BIOMEDICAL OPTICS EXPRESS			1	3			825	847					OCT 1 2010	2010	Barrett's esophagus (BE) and associated adenocarcinoma have emerged as a major health care problem. Endoscopic optical coherence tomography is a microscopic sub-surface imaging technology that has been shown to differentiate tissue layers of the gastrointestinal wall and identify dysplasia in the mucosa, and is proposed as a surveillance tool to aid in management of BE. In this work a computer-aided diagnosis (CAD) system has been demonstrated for classification of dysplasia in Barrett's esophagus using EOCT. The system is composed of four modules: region of interest segmentation, dysplasia-related image feature extraction, feature selection, and site classification and validation. Multiple feature extraction and classification methods were evaluated and the process of developing the CAD system is described in detail. Use of multiple EOCT images to classify a single site was also investigated. A total of 96 EOCT image-biopsy pairs (63 non-dysplastic, 26 low-grade and 7 high-grade dysplastic biopsy sites) from a previously described clinical study were analyzed using the CAD system, yielding an accuracy of 84% for classification of non-dysplastic vs. dysplastic BE tissue. The results motivate continued development of CAD to potentially enable EOCT surveillance of large surface areas of Barrett's mucosa to identify dysplasia. (C) 2010 Optical Society of America								7	0	3	0	7	2156-7085		WOS:000208209100009	
J	Liaw, Yi-Ching; Leou, Maw-Lin; Wu, Chien-Min								Fast exact k nearest neighbors search using an orthogonal search tree								PATTERN RECOGNITION			43	6			2351	2358		10.1016/j.patcog.2010.01.003			JUN 2010	2010	The problem of k nearest neighbors (kNN) is to find the nearest k neighbors for a query point from a given data set. In this paper, a novel fast kNN search method using an orthogonal search tree is proposed. The proposed method creates an orthogonal search tree for a data set using an orthonormal basis evaluated from the data set. To find the kNN for a query point from the data set, projection values of the query point onto orthogonal vectors in the orthonormal basis and a node elimination inequality are applied for pruning unlikely nodes. For a node, which cannot be deleted, a point elimination inequality is further used to reject impossible data points. Experimental results show that the proposed method has good performance on finding kNN for query points and always requires less computation time than available kNN search algorithms, especially for a data set with a big number of data points or a large standard deviation. (C) 2010 Elsevier Ltd. All rights reserved.								7	1	2	0	8	0031-3203		WOS:000275987700028	
J	Korfiatis, Panayiotis D.; Karahaliou, Anna N.; Kazantzi, Alexandra D.; Kalogeropoulou, Cristina; Costaridou, Lena I.								Texture-Based Identification and Characterization of Interstitial Pneumonia Patterns in Lung Multidetector CT								IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE			14	3			675	680		10.1109/TITB.2009.2036166			MAY 2010	2010	Identification and characterization of diffuse parenchyma lung disease (DPLD) patterns challenges computer-aided schemes in computed tomography (CT) lung analysis. In this study, an automated scheme for volumetric quantification of interstitial pneumonia (IP) patterns, a subset of DPLD, is presented, utilizing a multidetector CT (MDCT) dataset. Initially, lung-field segmentation is achieved by 3-D automated gray-level thresholding combined with an edge-highlighting wavelet preprocessing step, followed by a texture-based border refinement step. The vessel tree volume is identified and removed from lung field, resulting in lung parenchyma (LP) volume. Following, identification and characterization of IP patterns is formulated as a three-class pattern classification of LP into normal, ground glass, and reticular patterns, by means of k-nearest neighbor voxel classification, exploiting 3-D cooccurrence features. Performance of the proposed scheme in indentifying and characterizing ground glass and reticular patterns was evaluated by means of volume overlap (ground glass: 0.734 +/- 0.057, reticular: 0.815 +/- 0.037), true-positive fraction (ground glass: 0.638 +/- 0.055, reticular: 0.942 +/- 0.023) and false-positive fraction (ground glass: 0.361 +/- 0.027, reticular: 0.147 +/- 0.032) on five MDCT scans.								7	0	1	0	7	1089-7771		WOS:000278538300016	
J	Haouari, Bakhta; Ben Amor, Nahla; Elouedi, Zied; Mellouli, Khaled								Naive possibilistic network classifiers								FUZZY SETS AND SYSTEMS			160	22			3224	3238		10.1016/j.fss.2009.01.009			NOV 16 2009	2009	Naive Bayesian network classifiers have proved their effectiveness to accomplish the classification task, even if they work under the strong assumption of independence of attributes in the context of the class node. However, as all of them are based on probability theory, they run into problems when they are faced with imperfection. This paper proposes a new approach of classification under the possibilistic framework with naive classifiers. To output the naive possibilistic network classifier, two procedures are studied namely the building phase, which deals with imperfect (imprecise/uncertain) dataset attributes and classes, and the classification phase, which is used to classify new instances that may be characterized by imperfect attributes. To improve the performance of our classifier, we propose two extensions namely selective naive possibilistic classifier and semi-naive possibilistic classifier. Experimental study has shown naive Bayes style possibilistic classifier, and is efficient in the imperfect case. (C) 2009 Elsevier B.V. All rights reserved.				8th Conference of the International-Association-for-Fuzzy-Set-Management-and-Economy (SIGEF)	NOV 30-DEC 02, 2006	Int Assoc Fuzzy Set Management & Econ	Hammamet, TUNISIA	7	0	0	0	7	0165-0114		WOS:000270641400004	
J	Chevrefils, Claudia; Cheriet, Farida; Aubin, Carl-Eric; Grimard, Guy								Texture Analysis for Automatic Segmentation of Intervertebral Disks of Scoliotic Spines From MR Images								IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE			13	4			608	620		10.1109/TITB.2009.2018286			JUL 2009	2009	This paper presents a unified framework for automatic segmentation of intervertebral disks of scoliotic spines from different types of magnetic resonance (MR) image sequences. The method exploits a combination of statistical and spectral texture features to discriminate closed regions representing intervertebral disks from background in MR images of the spine. Specific texture features are evaluated for three types of MR sequences acquired in the sagittal plane: 2-D spin echo, 3-D multiecho data image combination, and 3-D fast imaging with steady state precession. A total of 22 texture features (18 statistical and 4 spectral) are extracted from every closed region obtained from an automatic segmentation procedure based on the watershed approach. The feature selection step based on principal component analysis and clustering process permit to decide among all the extracted features which ones resulted in the highest rate of good classification. The proposed method is validated using a supervised k-nearest-neighbor classifier on 505 MR images coming from three different scoliotic patients and three different MR acquisition protocols. Results suggest that the selected texture features and classification can contribute to solve the problem of oversegmentation inherent to existing automatic segmentation methods by successfully discriminating intervertebral disks from the background on MRI of scoliotic spines.				5th IEEE International Special Topic Conference on Information Technology in Biomedicine	OCT, 2006	IEEE Engn Med & Biol Soc; Univ Ioanniana; Natl Tech Univ Athens	Ioannina, GREECE	7	0	2	0	7	1089-7771		WOS:000267835800025	
J	Miao, Duoqian; Duan, Qiguo; Zhang, Hongyu; Jiao, Na								Rough set based hybrid algorithm for text classification								EXPERT SYSTEMS WITH APPLICATIONS			36	5			9168	9174		10.1016/j.eswa.2008.12.026			JUL 2009	2009	Automatic classification of text documents, one of essential techniques for Web mining, has always been a hot topic flue to the explosive growth of digital documents available on-line. In text classification community, k-nearest neighbor (kNN) is a simple and yet effective classifier. However, as being a lazy learning method Without premodelling, kNN has a high cost to classify new documents when training set is large. Rocchio algorithm is another well-known and widely used technique for text classification. One drawback of [tie Rocchio classifier is that it restricts the hypothesis space to the set of linear separable hyperplane regions. When the data does not fit its underlying assumption well, Rocchio classifier suffers. In this paper, a hybrid algorithm based on variable precision rough set is proposed to combine the strength of both kNN and Rocchio techniques and overcome their weaknesses. Art experimental evaluation of different methods is carried out oil two common text corpora, i.e., the Reuters-21578 collection and the 20-newsgroup collection. The experimental results indicate that the novel algorithm achieves significant performance improvement. (C) 2008 Elsevier Ltd. All rights reserved.								7	2	0	0	9	0957-4174		WOS:000264782800050	
J	Guan, Donghai; Yuan, Weiwei; Lee, Young-Koo; Lee, Sungyoung								Nearest neighbor editing aided by unlabeled data								INFORMATION SCIENCES			179	13			2273	2282		10.1016/j.ins.2009.02.011			JUN 13 2009	2009	This paper proposes a novel method for nearest neighbor editing. Nearest neighbor editing aims to increase the classifier's generalization ability by removing noisy instances from the training set. Traditionally nearest neighbor editing edits (removes/retains) each instance by the voting of the instances in the training set (labeled instances). However, motivated by semi-supervised learning, we propose a novel editing methodology which edits each training instance by the voting of all the available instances (both labeled and unlabeled instances). We expect that the editing performance could be boosted by appropriately using unlabeled data. Our idea relies on the fact that in many applications, in addition to the training instances, many unlabeled instances are also available since they do not need human annotation effort. Three popular data editing methods, including edited nearest neighbor, repeated edited nearest neighbor and All k-NN are adopted to verify our idea. They are tested on a set of LICI data sets. Experimental results indicate that all the three editing methods can achieve improved performance with the aid of unlabeled data. Moreover, the improvement is more remarkable when the ratio of training data to unlabeled data is small. (C) 2009 Elsevier Inc. All rights reserved.								7	3	0	0	10	0020-0255		WOS:000266216100016	
J	Wang, Yong; Li, Lin; Ni, Jun; Huang, Shuhong								Feature selection using tabu search with long-term memories and probabilistic neural networks								PATTERN RECOGNITION LETTERS			30	7			661	670		10.1016/j.patrec.2009.02.001			MAY 1 2009	2009	Feature selection is a dimensionality reduction problem in order to reduce measurement costs, shorten computational time, relieve the curse of dimensionality. and improve classification accuracy. In this paper, a hybrid approach using tabu search and probabilistic neural networks is proposed and applied to feature selection problems. The proposed tabu search algorithm differs from previous research by using a long-term memory instead of a short-term memory to avoid the necessity of the delicate tuning of the memory length and to decrease the risk of generating a cycle that traps the search in local optimal Solutions. The probabilistic neural networks integrated in the proposed hybrid approach are an outgrowth of Bayesian classifiers that outperform backpropagation-based neural networks in their global convergence and rapid training. Extensive experiments on real-world data sets are performed and the comparison with previous research indicates that the proposed hybrid approach can select an equal or smaller number of features while improving classification accuracy. (C) 2009 Elsevier B.V. All rights reserved.								7	0	0	0	7	0167-8655		WOS:000265727400002	
J	Mora-Florez, J.; Morales-Espana, G.; Perez-Londono, S.				Morales-Espana, German Andres/B-3713-2012	Morales-Espana, German Andres/0000-0002-6372-6197			Learning-based strategy for reducing the multiple estimation problem of fault zone location in radial power systems								IET GENERATION TRANSMISSION & DISTRIBUTION			3	4			346	356		10.1049/iet-gtd.2008.0164			APR 2009	2009	A learning-based strategy that uses support vector machines and k nearest neighbours is proposed for locating the faulted zone in radial power systems, specifically in distribution networks. The main goal is to reduce the multiple estimation of the fault location, inherent in those methods that use single end measurements. A selection of features obtained from the fundamentals of voltages and currents, measured at the power substation, are analysed and used as inputs of the proposed zone locator. Performance of several combinations of these features considering all fault types, different short-circuit levels and variation of the fault resistance, and the system load is evaluated. An application example illustrates the high precision to locate the faulted zone, obtained with the proposed methodology. The proposal provides appropriate information for the prevention and opportune attention of faults, requires minimum investment and overcomes the multiple estimation problem of the classic impedance based methods.								7	0	0	2	8	1751-8687		WOS:000265258700004	
J	Boutsinas, B.; Papastergiou, T.								On clustering tree structured data with categorical nature								PATTERN RECOGNITION			41	12			3613	3623		10.1016/j.patcog.2008.05.023			DEC 2008	2008	Clustering consists in partitioning a set of objects into disjoint and homogeneous clusters. For many years, clustering methods have been applied in a wide variety of disciplines and they also have been utilized in many scientific areas. Traditionally, clustering methods deal with numerical data, i.e. objects represented by a conjunction of numerical attribute Values. However, nowadays commercial or scientific databases Usually contain categorical data, i.e. objects represented by categorical attributes. In this paper we present a dissimilarity measure which is capable to deal with tree structured categorical data. Thus, it can be used for extending the various versions of the very popular k-means clustering algorithm to deal with Such data. We discuss how such an extension can be achieved. Moreover, we empirically prove that the proposed dissimilarity measure is accurate, compared to other well-known (dis)similarity measures for categorical data. (C) 2008 Elsevier Ltd. All rights reserved.								7	0	0	0	7	0031-3203		WOS:000259547900009	
J	Myrick, A. J.; Park, K-C; Hetling, J. R.; Baker, T. C.								Real-time odor discrimination using a bioelectronic sensor array based on the insect electroantennogram								BIOINSPIRATION & BIOMIMETICS			3	4					046006	10.1088/1748-3182/3/4/046006			DEC 2008	2008	Current trends in artificial nose research are strongly influenced by knowledge of biological olfactory systems. Insects have evolved over millions of years to detect and maneuver toward a food source or mate, or away from predators. The insect olfactory system is able to identify volatiles on a time scale that matches their ability to maneuver. Here, biological olfactory sense organs, insect antennae, have been exploited in a hybrid-device biosensor, demonstrating the ability to identify individual strands of odor in a plume passing over the sensor on a sub-second time scale. A portable system was designed to utilize the electrophysiological responses recorded from a sensor array composed of male or female antennae from four or eight different species of insects (a multi-channel electroantennogram, EAG). A computational analysis strategy that allows discrimination between odors in real time is described in detail. Following a training period, both semi-parametric and k-nearest neighbor (k-NN) classifiers with the ability to discard ambiguous responses are applied toward the classification of up to eight odors. EAG responses to individual strands in an odor plume are classified or discarded as ambiguous with a delay (sensor response to classification report) on the order of 1 s. The dependence of classification error rate on several parameters is described. Finally, the performance of the approach is compared to that of a minimal conditional risk classifier.								7	0	5	0	7	1748-3182		WOS:000261259900006	
J	Rizzi, Andrea; Fioni, Alessandro								Virtual screening using PLS discriminant analysis and ROC curve approach: An application study on PDE4 inhibitors								JOURNAL OF CHEMICAL INFORMATION AND MODELING			48	8			1686	1692		10.1021/ci800072r			AUG 2008	2008	Virtual screening (VS) represents an important tool for the drug discovery process, in particular for the hit generation phase. Classifiers are often inserted as filters at the beginning of a VS path, and in the present paper the performances of several PLS-DA classifiers (QikProp, Dragon, EVA descriptors) are evaluated in the effort to distinguish PDE4 inhibitors from other druglike molecules. As benchmark also docking scores and the fitness to pharmacophore hypotheses were used to perform the same task, checking in this way if docking or 3D search can be anticipated in the VS process. The visual analysis of the Receiver Operating Characteristic (ROC) curve was useful to have an overall picture of the classification and to select the right threshold that marks the boundary between active and inactive classes. The best classification was obtained by a model based on the Dragon descriptors that are calculated from the molecular 2D structure. Its performance was good for the training set in terms of recall, enrichment factor, and area under the ROC curve and was confirmed in the prediction of the test set.								7	1	3	0	9	1549-9596		WOS:000258697400014	
J	Reformat, Marek; Yager, Ronald R.								Building ensemble classifiers using belief functions and OWA operators								SOFT COMPUTING			12	6			543	558		10.1007/s00500-007-0227-2			APR 2008	2008	A pervasive task in many forms of human activity is classification. Recent interest in the classification process has focused on ensemble classifier systems. These types of systems are based on a paradigm of combining the outputs of a number of individual classifiers. In this paper we propose a new approach for obtaining the final output of ensemble classifiers. The method presented here uses the Dempster-Shafer concept of belief functions to represent the confidence in the outputs of the individual classifiers. The combing of the outputs of the individual classifiers is based on an aggregation process which can be seen as a fusion of the Dempster rule of combination with a generalized form of OWA operator. The use of the OWA operator provides an added degree of flexibility in expressing the way the aggregation of the individual classifiers is performed.								7	1	0	0	8	1432-7643		WOS:000252677400004	
J	Bengtsson, Thomas; Cavanaugh, Joseph E.								State-space discrimination and clustering of atmospheric time series data based on Kullback information measures								ENVIRONMETRICS			19	2			103	121		10.1002/env.859			MAR 2008	2008	Statistical problems in atmospheric science are frequently characterized by large spatio-temporal data sets and pose difficult challenges in classification and pattern recognition. Here, we consider the problem of identifying geographically homogeneous regions based on similarities in the temporal dynamics of weather patterns. Two disparity measures are proposed and applied to cluster time series of observed monthly temperatures from locations across Colorado, U.S.A. The two disparity measures are based on state-space models, where the monthly temperature anomaly dynamics and seasonal variation are represented by latent processes. Our disparity measures produce clusters consistent with known atmospheric flow structures. In particular, the temporal anomaly pattern is related to the topography of Colorado, where, separated by the Continental Divide, the flow structures in the western and eastern parts of the state have different dynamics. The results further suggest that seasonal variation may be affected by locally changing solar radiation levels primarily associated with elevation variations across the Rocky Mountains. The general methodology is outlined and developed in the Appendix. We conclude with a discussion of extensions to time varying and non-stationary systems. Copyright (c) 2007 John Wiley & Sons, Ltd.								7	0	2	0	7	1180-4009		WOS:000254460000001	
J	Garrow, Andrew G.; Westhead, David R.								A consensus algorithm to screen genomes for novel families of transmembrane beta barrel proteins								PROTEINS-STRUCTURE FUNCTION AND BIOINFORMATICS			69	1			8	18		10.1002/prot.21439			OCT 2007	2007	The ability to search sequence datasets for membrane spanning proteins is an important requirement for genome annotation. However, the development of algorithms to identify novel types of transmembrane beta-barrel (TMB) protein has proven substantially harder than for transmembrane helical proteins, owing to a shorter TM domain in which only alternate residues are hydrophobic. Although recent reports have described important improvements in the development Of such algorithms, there is still concern over their ability to confidently screen genomes. Here we describe a new algorithm combining composition and hidden Markov model topology based classifiers (called TMB-Hunt2), which achieves a crossvalidation accuracy of > 95%, with 96.7% precision and 94.2% recall. An overview is given of the algorithm design, with a thorough assessment of performance and application to a number of genomes. Of particular note is that TMB/extracellular protein discrimination is significantly more difficult than TMB/cytoplasmic protein discrimination, with the predictor correctly rejecting just 74% of extracellular proteins, in comparison to 98% of cytoplasmic proteins. Focus is given to directions for further improvements in TMB/non-TMB protein discrimination, with a call for the development of standardized tests and assessments of such algorithms. Tools and datasets are made available through a website called TMB-Web.								7	0	6	0	7	0887-3585		WOS:000249189000002	
J	Manouselis, Nikos; Costopoulou, Constantina								Experimental analysis of design choices in multiattribute utility collaborative filtering								INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			21	2			311	331		10.1142/S021800140700548X			MAR 2007	2007	Recommender systems have already been engaging multiple criteria for the production of recommendations. Such systems, referred to as multicriteria recommenders, demonstrated early the potential of applying Multi-Criteria Decision Making (MCDM) methods to facilitate recommendation in numerous application domains. On the other hand, systematic implementation and testing of multicriteria recommender systems in the context of real-life applications still remains rather limited. Previous studies dealing with the evaluation of recommender systems have outlined the importance of carrying out careful testing and parameterization of a recommender system, before it is actually deployed in a real setting. In this paper, the experimental analysis of several design options for three proposed multiattribute utility collaborative filtering algorithms is presented for a particular application context (recommendation of e-markets to online customers), under conditions similar to the ones expected during actual operation. The results of this study indicate that the performance of recommendation algorithms depends on the characteristics of the application context, as these are reflected on the properties of evaluations' data set. Therefore, it is judged important to experimentally analyze various design choices for multicriteria recommender systems, before their actual deployment.				International Workshop on Web Personalization, Recommender Systems and Intelligent User Interfaces	OCT, 2005		Reading, ENGLAND	7	1	0	0	8	0218-0014		WOS:000250955100008	
S	Garcia, Vicente; Sanchez, Jose; Mollineda, Ramon						Rueda, L; Mery, D; Kittler, J		An empirical study of the behavior of classifiers on imbalanced and overlapped data sets								PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		4756				397	406					2007	2007	Class imbalance has been reported as an important obstacle to apply traditional learning algorithms to real-world domains. Recent investigations have questioned whether the imbalance is the unique factor that hinders the performance of classifiers. In this paper, we study the behavior of six algorithms when classifying imbalanced, overlapped data sets under uncommon situations (e.g., when the overall imbalance ratio is different from the local imbalance ratio in the overlap region). This is accomplished by analyzing the accuracy on each individual class, thus devising how those situations affect the majority and minority classes. The experiments corroborate that overlap is more important than imbalance for the classification performance. Also, they show that the classifiers behave differently depending on the nature of each model.				12th Iberoamerican Congress on Pattern Recognition	NOV 13-16, 2007	Univ Santiago Chile, Dept Indormat Ingn; Tech Univ Feder Santa Maria, Dept Informat Tech	Valparaiso, CHILE	7	0	0	0	7	0302-9743	978-3-540-76724-4	WOS:000252725900042	
J	Viswanath, P.; Murty, M. Narasimha; Bhatnagar, Shalabh								Partition based pattern synthesis technique with efficient algorithms for nearest neighbor classification								PATTERN RECOGNITION LETTERS			27	14			1714	1724		10.1016/j.patrec.2006.04.015			OCT 15 2006	2006	Nearest neighbor (NN) classifier is a popular non-parametric classifier. It is conceptually a simple classifier and shows good performance. Due to the curse of dimensionality effect, the size of training set needed by it to achieve a given classification accuracy becomes prohibitively large when the dimensionality of the data is high. Generating artificial patterns can reduce this effect. In this paper, we propose a novel pattern synthesis method called partition based pattern synthesis which can generate an artificial training set of exponential order when compared with that of the given original training set. We also propose suitable faster NN based methods to work with the synthetic training patterns. Theoretically, the relationship between our methods and conventional NN methods is established. The computational requirements of our methods are also theoretically established. Experimental results show that NN based classifiers with synthetic training set can outperform conventional NN classifiers and some other related classifiers. (c) 2006 Elsevier B.V. All rights reserved.								7	0	0	0	7	0167-8655		WOS:000240643200014	
J	Cannas, B.; Cau, F.; Fanni, A.; Sonato, P.; Zedda, M. K.		JET-EFDA Contributors						Automatic disruption classification at JET: comparison of dinerent pattern recognition techniques								NUCLEAR FUSION			46	7			699	708		10.1088/0029-5515/46/7/002			JUL 2006	2006	In this paper, different pattern recognition techniques have been tested in order to implement an automatic tool for disruption classification in a tokamak experiment. The methods considered refer to clustering and classification techniques. In particular, the investigated clustering techniques are self-organizing maps and K-means, while the classification techniques are multi-layer perceptrons, support vector machines, and k- nearest neighbours. Training and testing data have been collected selecting suitable diagnostic signals recorded over 4 years of EFDA-JET experiments. Multi-layer perceptron classifiers exhibited the best performance in classifying mode lock, density limit/high radiated power, H-mode/L-mode transition and internal transport barrier plasma disruptions. This classification performance can be increased using multiple classifiers. In particular the outputs of five multi-layer perceptron classifiers have been combined using multiple classifier techniques in order to obtain a more robust and reliable classification tool, that is presently implemented at JET.				16th Topical Conference on RF Power in Plasmas	APR, 2005		Park City, UT	7	0	0	0	7	0029-5515		WOS:000239478900017	
S	Ben Hariz, Sarra; Elouedi, Zied; Mellouli, Khaled						Euzenat, J; Domingue, J		Clustering approach using belief function theory								ARTIFICIAL INTELLIGENCE: METHODOLOGY, SYSTEMS, AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		4183				162	171					2006	2006	Clustering techniques are considered as efficient tools for partitioning data sets in order to get homogeneous clusters of objects. However, the reality is connected to uncertainty by nature, and these standard algorithms of clustering do not deal with this uncertainty pervaded in their parameters. In this paper we develop a clustering method in an uncertain context based on the K-modes method and the belief function theory. This so-called belief K-modes method (BKM) provides a new clustering technique handling uncertainty in the attribute values of objects in both the clusters' construction task and the classification one.				12th International Conference on Artificial Intelligence - Methodology, Systems, and Applications	SEP 12-15, 2006	Bulgarian Artificial Intelligence Assoc; Inst Informat Technol	Varna, BULGARIA	7	0	0	0	7	0302-9743	3-540-40930-0	WOS:000242122400016	
J	Mille, Alain								From case-based reasoning to traces-based reasoning								ANNUAL REVIEWS IN CONTROL			30	2			223	232		10.1016/j.arcontrol.2006.09.003			2006	2006	CBR is an original At paradigm based on the adaptation of solutions of past problems in order to solve new similar problems. Hence, a case is a problem with its solution and cases are stored in a case library. The reasoning process follows a cycle that facilitates "learning" from new solved cases. This approach can be also viewed as a lazy learning method when applied for task classification. CBR is applied for various tasks as design, planning, diagnosis, information retrieval, etc. The paper is the occasion to go a step further in reusing past Unstructured experience, by considering traces of computer use as experience knowledge containers for situation based problem solving. (C) 2006 Elsevier Ltd. All rights reserved.				9th IFAC Symposium on Automated Systems Based on Human Skill and Knowledge	MAY 22-24, 2006	IFAC Tech Comm 9 2	Nancy, FRANCE	7	0	0	0	7	1367-5788		WOS:000243065900011	
J	Okun, Oleg; Priisalu, Helen								Fast nonnegative matrix factorization and its application for protein fold recognition								EURASIP JOURNAL ON APPLIED SIGNAL PROCESSING									71817	10.1155/ASP/2006/71817			2006	2006	Linear and unsupervised dimensionality reduction via matrix factorization with nonnegativity constraints is studied. Because of these constraints, it stands apart from other linear dimensionality reduction methods. Here we explore nonnegative matrix factorization in combination with three nearest-neighbor classifiers for protein fold recognition. Since typically matrix factorization is iteratively done, convergence, can be slow. To speed up convergence, we perform feature scaling ( normalization) prior to the beginning of iterations. This results in a significantly ( more than 11 times) faster algorithm. Justification of why it happens is provided. Another modification of the standard nonnegative matrix factorization algorithm is concerned with combining two known techniques for mapping unseen data. This operation is typically necessary before classifying the data in low-dimensional space. Combining two mapping techniques can yield better accuracy than using either technique alone. The gains, however, depend on the state of the random number generator used for initialization of iterations, a classifier, and its parameters. In particular, when employing the best out of three classifiers and reducing the original dimensionality by around 30%, these gains can reach more than 4%, compared to the classification in the original, high-dimensional space. Copyright (C) 2006 Hindawi Publishing Corporation. All rights reserved.								7	0	3	0	8	1110-8657		WOS:000242080500001	
J	Graepel, T; Herbrich, R								PAC-Bayesian compression bounds on the prediction error of learning algorithms for classification								MACHINE LEARNING			59	1-2			55	76		10.1007/s10994-005-0462-7			MAY 2005	2005	We consider bounds on the prediction error of classification algorithms based on sample compression. We refine the notion of a compression scheme to distinguish permutation and repetition invariant and nonpermutation and repetition invariant compression schemes leading to different prediction error bounds. Also, we extend known results on compression to the case of non-zero empirical risk.We provide bounds on the prediction error of classifiers returned by mistake-driven online learning algorithms by interpreting mistake bounds as bounds on the size of the respective compression scheme of the algorithm. This leads to a bound on the prediction error of perceptron solutions that depends on the margin a support vector machine would achieve on the same training sample.Furthermore, using the property of compression we derive bounds on the average prediction error of kernel classifiers in the PAC-Bayesian framework. These bounds assume a prior measure over the expansion coefficients in the data-dependent kernel expansion and bound the average prediction error uniformly over subsets of the space of expansion coefficients.								7	0	0	0	7	0885-6125		WOS:000228828700003	
J	Li, J; Manry, MT; Yu, CH; Wilson, DR								Prototype classifier design with pruning								INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS			14	1-2			261	280		10.1142/S0218213005002090			FEB-APR 2005	2005	Algorithms reducing the storage requirement of the nearest neighbor classifier (NNC) can be divided into three main categories: Fast searching algorithms, Instance-based learning algorithms and Prototype based algorithms. We propose an algorithm, LVQPRU, for pruning NNC prototype vectors and a compact classifier with good performance is obtained. The basic condensing algorithm is applied to the initial prototypes to speed up the learning process. The learning vector quantization (LVQ) algorithm is utilized to fine tune the remaining prototypes during each pruning iteration. We evaluate LVQPRU on several data sets along with 12 other algorithms using ten-fold cross-validation. Simulation results show that the proposed algorithm has high generalization accuracy and good storage reduction ratios.				17th International FLAIRS Conference	MAY 17-19, 2004	FLAIRS	Miami Beach, FL	7	0	0	0	7	0218-2130		WOS:000233468800015	
S	Robinson, S; Polak, JW			TRB					Modeling urban link travel time with inductive loop detector data by using the k-NN method								INFORMATION SYSTEMS AND TECHNOLOGY	TRANSPORTATION RESEARCH RECORD			1935			47	56					2005	2005	The need to measure urban link travel time (ULTT) is becoming increasingly important for network management and traveler information provision. This paper proposes the use of the k nearest neighbors (k-NN) technique to estimate ULTT with the use of single loop inductive loop detector (ILD) data. Real-world data from London is used. This paper explores the sensitivity of travel time estimates to various k-NN design parameters. It rinds that the k-NN method is not particularly sensitive to the distance metric, although care must be taken in selecting the right combination of local estimation method (LEM) and value of k. A robust LEM should be used. The optimized k-NN model is found to provide more accurate estimates than other ULTT methods. To obtain a more accurate estimate of ULTT, a potential application of this approach could be to aggregate GPS probe vehicle ULTT records from different times but the same underlying travel time distribution.				84th Annual Meeting of the Transportation-Research-Board	JAN 09-13, 2005	US Dept Transportat; US Fed Aviat Adm; US Fed Highway Adm; US Fed Motor Carrier Safety Adm; US Fed Railroad Adm; US Fed Transit Adm; US Natl Highway Traff Safety Adm; US Res & Innovat Technol Adm; NASA; USA Corps Engineers; US Coast Guard; US DOE; US EPA; Transportat Res Board; Transportat Dept 50 States, Puerto Rico & District Columbia	Washington, DC	7	0	0	0	7	0361-1981	0-309-09409-7	WOS:000237194200006	
J	Yin, TK; Chiu, NT								A computer-aided diagnosis for distinguishing Tourette's syndrome from chronic tic disorder in children by a fuzzy system with a two-step minimization approach								IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING			51	7			1286	1295		10.1109/TBME.2004.827954			JUL 2004	2004	Tourette's syndrome, no longer considered as a rare and unusual disease, is the most severe tic disorder in children. Early differential diagnosis between Tourette's syndrome and chronic tic disorder is difficult but important because proper and early medical therapy can improve the child's condition. Brain single-photon emission computed tomography (SPECT) perfusion imaging with technetium-99m hexamethylpropylene amine oxime is a method to distinguish these two diseases. In this paper, a fuzzy system called characteristic-point-based fuzzy inference system (CPFIS) is proposed to help radiologists perform computer-aided diagnosis (CAD). The CPFIS consists of SPECT-volume processing, input-variables selection, characteristic-points (CPs) derivation, and parameter tuning of the fuzzy system. Experimental results showed that the major fuzzy rules from the obtained CPs match the major patterns of Tourette's syndrome and chronic tic disorder in perfusion imaging. If any case that was diagnosed as chronic tic by the radiologist but as Tourette's syndrome by the CPFIS was taken as Tourette's syndrome, then the accuracy of the radiologist was increased from 87.5% (21 of 24) without the CPFIS to 91.7% (22 of 24) With the CPFIS. All 17 cases of Tourette's syndrome, which is more severe than chronic tic disorder, were correctly classified. Although the construction and application process of the proposed method is complete, more samples should be used and tested in order to design a universally effective CAD without small sample-size concerns in this research.								7	0	1	0	8	0018-9294		WOS:000222132200024	
J	Okamoto, S; Yugami, N								Effects of domain characteristics on instance-based learning algorithms								THEORETICAL COMPUTER SCIENCE			298	1			207	233	PII S0304-3975(02)00424-3	10.1016/S0304-3975(02)00424-3			APR 4 2003	2003	This paper presents average-case analyses of instance-based learning algorithms. The algorithms analyzed employ a variant of k-nearest neighbor classifier (k-NN). Our analysis deals with a monotone m-of-n target concept with irrelevant attributes, and handles three types of noise: relevant attribute noise, irrelevant attribute noise, and class noise. We formally represent the expected classification accuracy of k-NN as a function of domain characteristics including the number of training instances, the number of relevant and irrelevant attributes, the threshold number in the target concept, the probability of each attribute, the noise rate for each type of noise, and k. We also explore the behavioral implications of the analyses by presenting the effects of domain characteristics on the expected accuracy of k-NN and on the optimal value of k for artificial domains. (C) 2002 Elsevier Science B.V. All rights reserved.								7	0	0	0	7	0304-3975		WOS:000181997500010	
J	Chang, DH; Kothari, R; Islam, S								Classification of soil texture using remotely, sensed brightness temperature over the southern great plains								IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			41	3			664	674		10.1109/TGRS.2003.809935			MAR 2003	2003	This study explores the use of artificial neural networks (ANNs) models and brightness temperature from the Southern Great Plains in the United States to classify soil into different textures. Previous studies using ANN models and brightness temperature in a single drying cycle suggested that they might contain sufficient features to classify soil into three categories. To classify soil into more than three groups and to explore the limits of classification accuracy, this paper suggests the use of multiple-drying-cycle brightness temperature data. We have performed several experiments with feed-forward neural network (FFNN) models, and the results suggest that the maximum achievable classification accuracy through the use of multiple-drying-cycle brightness temperature is about 80%. It appears that the rapidly changing space-time evolution of brightness temperature will restrict the FFNN model performance. Motivated by these observations, we have used a simple prototype-based classifier, known as the 1-NN model, and achieved 86% classification accuracy for six textural groups. A comparison of error regions predicted by both models suggests that for the given input representation maximum achievable accuracy for classification into six soil texture types is about 93%.								7	2	1	0	8	0196-2892		WOS:000182871300016	
J	Nugroho, AS; Kuroyanagi, S; Iwata, A								A solution for imbalanced training sets problem by CombNET-II and its application on fog forecasting								IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS			E85D	7			1165	1174					JUL 2002	2002	Studies on artificial neural network have been conducted for a long time, and its contribution has been shown in many fields. However, the application of neural networks in the real world domain is still a challenge, since nature does not always provide the required satisfactory conditions. One example is the class size unbalanced condition in which one class is heavily under-represented compared to another class. This condition is often found in the real world domain and presents several difficulties for algorithms that assume the balanced condition of the classes. In this paper, we propose a method for solving problems posed by imbalanced training sets by applying the modified large-scale neural network "CombNET-II." CombNET-II consists of two types of neural networks. The first type is a one-layer vector quantization neural network to turn the problem into a more balanced condition. The second type consists of several modules of three-layered multilayer perceptron trained by backpropagation for finer classification. CombNET-II combines the two types of neural networks to solve the problem effectively within a reasonable time. The performance is then evaluated by turning the model into a practical application for a fog forecasting problem. Fog forecasting is an imbalanced training sets problem, since the probability of fog appearance in the observation location is very low. Fog events should be predicted every 30 minutes based on the observation of meteorological conditions. Our experiments showed that CombNET-II could achieve a high prediction rate compared to the k-nearest neighbor classifier and the three-layered multilayer perceptron trained with BP. Part of this research was presented in the 1999 Fog Forecasting Contest sponsored by Neurocomputing Technical Croup of IEICE, Japan; and CombNET-II achieved the highest accuracy among the participants.								7	2	1	0	9	0916-8532		WOS:000177323400011	
J	Barkol, O; Rabani, Y								Tighter lower bounds for nearest neighbor search and related problems in the cell probe model								JOURNAL OF COMPUTER AND SYSTEM SCIENCES			64	4			873	896		10.1006/jcss.2002.1831			JUN 2002	2002	We prove new lower bounds for nearest neighbor search in the Hamming cube. Our lower bounds are for randomized, two-sided error, algorithms in Yao's cell probe model. Our bounds are in the form of a tradeoff among the number of cells, the size of a cell, and the search time. For example, suppose we are searching among n points in the d dimensional cube, we use poly(n, d) cells, each containing poly(d, log n) bits. We get a lower bound of Omega(d/log n) on the search time, a significant improvement over the recent bound of Omega(log d) of Borodin et al. This should be contrasted with the upper bound of D(log log d) for approximate search (and O(1) for a decision version of the problem; our lower bounds hold in that case). By previous results, the bounds for the cube imply similar bounds for nearest neighbor search in high dimensional Euclidean space, and for other geometric problems. (C) 2002 Elsevier Science (USA).				32nd Annual ACM Symposium on Theory of Computing	JUN 21-23, 2000		PORTLAND, OREGON	7	0	0	0	7	0022-0000		WOS:000176720500007	
J	Cheng, CB; Lee, ES								Nonparametric fuzzy regression - k-NN and kernel smoothing techniques								COMPUTERS & MATHEMATICS WITH APPLICATIONS			38	3-4			239	251		10.1016/S0898-1221(99)00198-4			AUG 1999	1999	Fuzzy regression without predefined functional form, or nonparametric fuzzy regression, is investigated. The two most basic nonparametric regression techniques in statistics, namely, k-nearest neighbor smoothing and kernel smoothing, are fuzzified and analyzed. Algorithms are proposed to obtain the best smoothing parameters based on the minimization of cross-validation criteria. (C) 1999 Elsevier Science Ltd. All rights reserved.								7	0	0	0	7	0898-1221		WOS:000081855800019	
S	Ishibuchi, H; Nakashima, T				Ishibuchi, Hisao/B-3599-2009	Ishibuchi, Hisao/0000-0001-9186-6472	McKay, B; Yao, X; Newton, CS; Kim, JH; Furuhashi, T		Evolution of reference sets in nearest neighbor classification								SIMULATED EVOLUTION AND LEARNING	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		1585				82	89					1999	1999	This paper proposes a genetic-algorithm-based approach for finding a compact reference set used in nearest neighbor classification. The reference set is designed by selecting a small number of reference patterns from a large number of training patterns using a genetic algorithm. The genetic algorithm also removes unnecessary features. The reference set in our nearest neighbor classification consists of selected patterns with selected features. A binary string is used for representing the inclusion (or exclusion) of each pattern and feature in the reference set. Our goal is to minimize the number of selected patterns, to minimize the number of selected features, and to maximize the classification performance of the reference set. The effectiveness of our approach is examined by computer simulations on commonly used data sets.				2nd Asia-Pacific Conference on Simulated Evolution and Learning (SEAL 98)	NOV 24-27, 1998		CANBERRA, AUSTRALIA	7	0	2	0	7	0302-9743	3-540-65907-2	WOS:000086778800011	
J	Priebe, CE; Cowen, LJ				Priebe, Carey E./A-3305-2010				A generalized Wilcoxon-Mann-Whitney statistic								COMMUNICATIONS IN STATISTICS-THEORY AND METHODS			28	12			2871	2878		10.1080/03610929908832454			1999	1999	We develop a simple but useful generalization of the classical Wilcoxon-Mann-Whitney statistic. A normal approximation and a recurrence for the exact distribution of this generalization are available. The statistic has potential application in nonparametric discriminant analysis.								7	0	1	0	7	0361-0926		WOS:000084122200005	
J	Chowdhury, N; Murthy, CA								Minimal spanning tree based clustering technique: Relationship with Bayes Classifier								PATTERN RECOGNITION			30	11			1919	1929		10.1016/S0031-3203(96)00188-4			NOV 1997	1997	A minimal spanning tree (MST) based clustering technique along with its theoretical formulation is presented in this paper. The proposed technique is compared with Bayes Classifier and it is shown theoretically that the clustering technique, although an unsupervised one, approaches the performance of Bayes Classifier under a condition, as the number of sample points from each class increases. Experimental results with many synthetic data sets in 2-D and 3-D validate the theoretical prediction. (C) 1997 Pattern Recognition Society. Published by Elsevier Science Ltd.								7	0	0	0	7	0031-3203		WOS:000071136400010	
J	Lipman, A; Yang, WW								VLSI hardware for example-based learning								IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS			5	3			320	328		10.1109/92.609875			SEP 1997	1997	Example-based learning, as performed by neural networks and other approximation and classification techniques, is both computationally intensive and I/O intensive, typically involving the optimization of hundreds or thousands of parameters during repeated network evaluations over a database of example vectors, Although there is currently no dominant approach or technique among the various neural networks and learning algorithms, the basic functionality of most neural networks can be conceptually realized as a multidimensional look-up table, While multidimensional look-up tables are clearly impractical due to the exponential memory requirements, we are pursuing an approach using interpolation based only on the sparse data provided by an initial example database, In particular, we have designed prototype VLSI components for searching multidimensional example databases for the k closest examples to an input query as determined by a programmable metric using a massively parallel search, This nearest-neighbor approach can be used directly for classification, or in conjunction with any number of neural network algorithms that exploit local fitting, The hardware removes the I/O bottleneck from the learning task by supplying a reduced set of examples for localized training or classification, Though nearest-neighbor retrieval algorithms have efficient software implementations for low-dimensional databases, exhaustive searching is the only effective approach for handling high-dimensional data, The parallel VLSI hardware we have designed can accelerate the exhaustive search by three orders of magnitude, We believe this special purpose VLSI will have direct application in systems requiring learning functionality and in accelerating learning applications on large, high-dimensional databases.								7	0	0	0	7	1063-8210		WOS:A1997XU13100010	
J	Peng, XTT; Wang, PH; Kandel, A								Knowledge acquisition by random sets								INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS			11	3			113	147		10.1002/(SICI)1098-111X(199603)11:3<113::AID-INT1>3.0.CO;2-T			MAR 1996	1996	In this article we investigate knowledge acquisition (KA) and its relationships to random sets. Based on random set theory, we develop some estimation theorems and procedures for set-valued statistics such as nonparametric estimators. Under random interval assumption, we establish some special possibility distributions that can be easily implemented in KA tools. The knowledge studied here are rules describing relationships between various concepts, as used in diagnosis (pattern recognition) expert systems. (C) 1996 John Wiley & Sons, Inc.								7	3	0	0	10	0884-8173		WOS:A1996TX81000001	
J	VEZJAK, M; STEPHANCIC, M								AN ANTHROPOLOGICAL MODEL FOR AUTOMATIC RECOGNITION OF THE MALE HUMAN FACE								ANNALS OF HUMAN BIOLOGY			21	4			363	380		10.1080/03014469400003362			JUL-AUG 1994	1994	The human face is a characteristic pattern most familiar to us when distinguishing people. Although recognizing human faces is one of our everyday activities, we are mostly not aware how the mechanisms of recognition actually work. Attempts to recognize the human face by machine are rarer (less frequent) than those of the recognition of some other phenomena in everyday life. This paper describes the automated analysis of a human face from the grey level picture, defined as an individual description of a face, given in the form of its sub-objects and the relations among them. The model-based analysis is founded on the anthropological model of a human face that incorporates 19 facial parameters of a male face in norma facialis. On the basis of these parameters it is possible to analyse, recognize and identify the human face. The contour image is used as an input to the pattern analysis program. Some algorithms for the search of characteristic face areas are presented. The Hough transform for an ellipse is used to determine the position of the head in a grey image, and to define the eye region within a face. The integral projections of the contour picture are proved to be useful techniques for picture processing to define the nose and the mouth regions within a face. Furthermore, a few algorithms for the precise determination of the facial parameters based on sharp edge transitions are developed. The method is illustrated using photographs of human faces from our data base and the results obtained are also given. The system is realized on a PC/AT computer.								7	0	0	0	7	0301-4460		WOS:A1994NN57300006	
J	LOIZOU, G; MAYBANK, SJ								THE NEAREST NEIGHBOR AND THE BAYES ERROR RATES								IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			9	2			254	262					MAR 1987	1987									7	2	0	0	9	0162-8828		WOS:A1987G163300006	
J	BYERS, WA; PERONE, SP								COMPUTERIZED PATTERN-RECOGNITION APPLIED TO NI-CD CELL LIFETIME PREDICTION								JOURNAL OF THE ELECTROCHEMICAL SOCIETY			126	5			720	725		10.1149/1.2129127			1979	1979									7	0	0	0	7	0013-4651		WOS:A1979GT75700003	
J	FUKUNAGA, K; SHORT, RD								NON-LINEAR FEATURE EXTRACTION WITH A GENERAL CRITERION FUNCTION								IEEE TRANSACTIONS ON INFORMATION THEORY			24	5			600	607		10.1109/TIT.1978.1055942			1978	1978									7	2	0	0	9	0018-9448		WOS:A1978FQ01000011	
J	TOUSSAINT, GT								PROBABILITY OF ERROR, EXPECTED DIVERGENCE, AND AFFINITY OF SEVERAL DISTRIBUTIONS								IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS			8	6			482	485					1978	1978									7	0	0	0	7	0018-9472		WOS:A1978FC60800007	
J	FRALICK, SC; SCOTT, RW								NONPARAMETRIC BAYES-RISK ESTIMATION								IEEE TRANSACTIONS ON INFORMATION THEORY			17	4			440	+		10.1109/TIT.1971.1054663			1971	1971									7	0	2	0	7	0018-9448		WOS:A1971J629200010	
J	Ang, Kai Keng; Chin, Zheng Yang; Zhang, Haihong; Guan, Cuntai								Mutual information-based selection of optimal spatial-temporal patterns for single-trial EEG-based BCIs								PATTERN RECOGNITION			45	6			2137	2144		10.1016/j.patcog.2011.04.018			JUN 2012	2012	The common spatial pattern (CSP) algorithm is effective in decoding the spatial patterns of the corresponding neuronal activities from electroencephalogram (EEG) signal patterns in brain-computer interfaces (BCIs). However, its effectiveness depends on the subject-specific time segment relative to the visual cue and on the temporal frequency band that is often selected manually or heuristically. This paper presents a novel statistical method to automatically select the optimal subject-specific time segment and temporal frequency band based on the mutual information between the spatial-temporal patterns from the EEG signals and the corresponding neuronal activities. The proposed method comprises four progressive stages: multi-time segment and temporal frequency band-pass filtering, CSP spatial filtering, mutual information-based feature selection and nave Bayesian classification. The proposed mutual information-based selection of optimal spatial-temporal patterns and its one-versus-rest multi-class extension were evaluated on single-trial EEG from the BCI Competition IV Datasets IIb and IIa respectively. The results showed that the proposed method yielded relatively better session-to-session classification results compared against the best submission. (C) 2011 Elsevier Ltd. All rights reserved.								6	0	0	0	6	0031-3203		WOS:000301758400011	
J	Endresen, Dag Terje Filip; Street, Kenneth; Mackay, Michael; Bari, Abdallah; De Pauw, Eddy				Endresen, Dag/G-1284-2010	Endresen, Dag/0000-0002-2352-5497			Predictive Association between Biotic Stress Traits and Eco-Geographic Data for Wheat and Barley Landraces								CROP SCIENCE			51	5			2036	2055		10.2135/cropsci2010.12.0717			SEP 2011	2011	Collections of crop genetic resources are a valuable source of new genetic variation for economically important traits, including resistance to crop diseases. New sources of useful crop traits are often identified through evaluation in field trials. The number of relevant accessions in genebank collections available to be evaluated is often substantially larger than the capacity of the evaluation project. The focused identification of germplasm strategy (FIGS) is an approach used to select subsets of germplasm from genetic resource collections in such a way as to maximize the likelihood of capturing a specific trait. This strategy uses a range of methods to link the expression of a specific trait (of a target crop) with the eco-geographic parameters of the original collection site. This study contributes to the development of the approach by which a FIGS subset could be assembled for biotic traits. We have evaluated trait-specific subset selection methods for two fungal crop diseases, namely stem rust (Puccinia graminis Pers.) in wheat (Triticum aestivum L. and Triticum turgidum L.) and net blotch (Pyrenophora teres Drechs.) in barley (Hordeum vulgare L.). The results indicate that the climate layers from freely available eco-geographic databases are well suited to model and predict the reaction in these crops to biotic stress traits. This result has the potential to improve the efficiency of field screening trials to find novel sources of economically valuable crop traits.								6	0	6	0	6	0011-183X		WOS:000293473800017	
J	Jiang, Zhiting; Sun, Jingbo; Liang, Qionglin; Cai, Yefeng; Li, Shasha; Huang, Yan; Wang, Yiming; Luo, Guoan				Liang, Qionglin/A-2407-2011				A metabonomic approach applied to predict patients with cerebral infarction								TALANTA			84	2			298	304		10.1016/j.talanta.2011.01.015			APR 15 2011	2011	Cerebral infarction is always of sudden onset, and usually leading to serious consequence. It is of therapeutic significance to develop fast and accurate diagnosis methods for cerebral infarction so that patients can be treated timely and properly. A metabonomic approach was then proposed to investigate the potential biomarkers and metabolic pathways associated with cerebral infarction and also establish a prediction model of cerebral infarction for the fast diagnosis. Serum metabolic profiling of sixty-seven cerebral infarction patients and sixty-two controls was obtained using UPLC-TOF MS. The resulting data were then processed by multivariate statistical analysis to graphically demonstrate metabolic variations. The PLS-DA model was validated with cross validation and permutation tests to assure the model's reliability, and significant difference was obtained between the original and hypothetical models (p < 0.0001). A series of endogenous metabolites in the one-carbon cycle, such as folic acid, cysteine, S-adenosyl homocysteine and oxidized glutathione, were determined as potential biomarkers of cerebral infarction. A prediction model developed using PLS-KNN algorithm was established to differentiate cerebral infarction patients from controls, and an average accuracy of 100% was obtained. In conclusion, metabonomic approach is a powerful tool to investigate the pathogenesis of stroke and is expected to be developed as a useful method for the fast diagnosis. (C) 2011 Elsevier B.V. All rights reserved.								6	0	5	0	6	0039-9140		WOS:000289141500007	
J	Lian, Heng				Lian, Heng/J-6300-2012				Convergence of functional k-nearest neighbor regression estimate with functional responses								ELECTRONIC JOURNAL OF STATISTICS			5				31	40		10.1214/11-EJS595			2011	2011	Let (X(1), Y(1)), ..., (X(n), Y(n)) be independent and identically distributed random elements taking values in F x H, where F is a semi-metric space and H is a separable Hilbert space. We investigate the rates of strong (almost sure) convergence of the k-nearest neighbor estimate. We give two convergence results assuming a finite moment condition and exponential tail condition on the noises respectively, with the latter requiring less stringent conditions on k for convergence.								6	0	0	0	6	1935-7524		WOS:000287819400003	
J	Trotter, Matthew W. B.; Sadowski, Pawel G.; Dunkley, Tom P. J.; Groen, Arnoud J.; Lilley, Kathryn S.								Improved sub-cellular resolution via simultaneous analysis of organelle proteomics data across varied experimental conditions								PROTEOMICS			10	23			4213	4219		10.1002/pmic.201000359			DEC 2010	2010	Spatial organisation of proteins according to their function plays an important role in the specificity of their molecular interactions Emerging proteomics methods seek to assign proteins to sub cellular locations by partial separation of organelles and computational analysis of protein abundance distributions among partially separated fractions Such methods permit simultaneous analysis of unpurified organelles and promise proteome wide localisation in scenarios wherein perturbation may prompt dynamic re distribution Resolving organelles that display similar behavior during a protocol designed to provide partial enrichment represents a possible shortcoming We employ the Localisation of Organelle Proteins by Isotope Tagging (LOPIT) organelle proteomics platform to demonstrate that combining information from distinct separations of the same material can improve organelle resolution and assignment of proteins to sub cellular locations Two previously published experiments whose distinct gradients are alone unable to fully resolve six known protei n-organelle groupings are subjected to a rigorous analysis to assess protein organelle association via a contemporary pattern recognition algorithm Upon straightforward combination of single gradient data we observe significant improvement in protein organelle association via both a non linear support vector machine algorithm and partial least squares discriminant analysis The outcome yields suggestions for further improvements to present organelle proteomics platforms and a robust analytical methodology via which to associate proteins with sub cellular organelles								6	0	5	0	6	1615-9853		WOS:000285851900008	
J	Kim, Dong-Ju; Chung, Kwang-Woo; Hong, Kwang-Seok								Person Authentication using Face, Teeth and Voice Modalities for Mobile Device Security								IEEE TRANSACTIONS ON CONSUMER ELECTRONICS			56	4			2678	2685		10.1109/TCE.2010.5681156			NOV 2010	2010	In this paper, we propose an enhanced multimodal personal authentication system for mobile device security. The proposed approach fuses information obtained from face, teeth and voice modalities to improve performance. To integrate three modalities, we employ various fusion techniques such as the weighted-summation rule, K-NN, Fisher and Gaussian classifiers, and we then evaluate the authentication performance of the proposed system. The performance is evaluated on a database consisting of 1000 biometric traits that correspond to the face, teeth and voice modalities of 50 persons, i.e., 20 biometric traits per individual, in which these biometric traits are simultaneously collected by a smart-phone device. The experiment results integrating the three modalities showed the error rates of 1.64%, 4.70%, 3.06% and 1.98% for the weighted-summation rule, K-NN, Fisher and Gaussian classifier, respectively, and that the weight-summation rule outperformed the other classification approaches. In contrast, the error rates regarding a single modality were 5.09%, 7.75% and 8.98% for face, teeth, and voice modalities, respectively. From these results, we confirmed that the proposed method achieved a significant performance improvement over the methods using a single modality, and the results showed that the proposed method was very effective through various fusion experiments.(1)								6	0	0	0	6	0098-3063		WOS:000286111700092	
J	Gao, Yunlong; Gao, Feng								Edited AdaBoost by weighted kNN								NEUROCOMPUTING			73	16-18	SI		3079	3088		10.1016/j.neucom.2010.06.024			OCT 2010	2010	Any realistic model of learning from samples must address the issue of noisy data. AdaBoost is known as an effective method for improving the performance of base classifiers both theoretically and empirically. However, previous studies have shown that AdaBoost is prone to overfitting, especially in noisy domains. On the other hand, the kNN rule is one of the oldest and simplest methods for pattern classification. Nevertheless, it often yields competitive results, and in certain domains, when cleverly combined with prior knowledge, it has significantly advanced the state-of-the-art. In this paper, an edited AdaBoost by weighted kNN (EAdaBoost) is designed where AdaBoost and kNN naturally complement each other. First, AdaBoost is run on the training data to capitalize on some statistical regularity in the data. Then, a weighted kNN algorithm is run on the feature space composed of classifiers produced by AdaBoost to achieve competitive results. AdaBoost is then used to enhance the classification accuracy and avoid overfitting by editing the data sets using the weighted kNN algorithm for improving the quality of training data. Experiments performed on ten different UCI data sets show that the new Boosting algorithm almost always achieves considerably better classification accuracy than AdaBoost. Furthermore, experiments on data with artificially controlled noise indicate that the new Boosting algorithm is robust to noise. (C) 2010 Elsevier B.V. All rights reserved.								6	1	0	0	7	0925-2312		WOS:000294092200029	
J	Ghiassi, M.; Burnley, C.								Measuring effectiveness of a dynamic artificial neural network algorithm for classification problems								EXPERT SYSTEMS WITH APPLICATIONS			37	4			3118	3128		10.1016/j.eswa.2009.09.017			APR 2010	2010	Classification is the process of assigning an object to one of a set of classes based on its attributes. Classification problems have been examined in fields as diverse as biology, medicine, business, image recognition, and forensics. Developing more accurate and widely applicable classification methods has significant implications in these and many other fields.This paper presents a dynamic artificial neural network (DAN2) as an alternate approach for solving classification problems. We show DAN2 to be an effective approach and compare its performance with linear discriminant analysis, quadratic discriminant analysis, k-nearest neighbor algorithms, support vector machines, and traditional artificial neural networks using benchmark and real-world application data sets. These data sets vary in the number of classes (two vs. multiple) and the source of the data (synthetic vs. real-world). We found DAN2 to be a very effective classification method for two-class data sets with accuracy improvements as high as 37.2% when compared to the other methods. We also introduce a hierarchical DAN2 model for multiple class data sets that shows marked improvements (up to 89%) over all other methods, and offers better accuracy in all cases. (C) 2009 Elsevier Ltd. All rights reserved.								6	0	1	1	7	0957-4174		WOS:000274202900047	
J	Yang, Xubing; Chen, Songcan; Chen, Bin; Pan, Zhisong								Proximal support vector machine using local information								NEUROCOMPUTING			73	1-3	SI		357	365		10.1016/j.neucom.2009.08.002			DEC 2009	2009	Instead of standard support vector machines (SVMs) that classify points to one of two disjoint half-spaces by solving a quadratic program, the plane classifier GEPSVM (proximal SVM classification via generalized eigenvalues) classifies points by assigning them to the closest of two nonparallel planes which are generated by their corresponding generalized eigenvalue problems. A simple geometric interpretation of GEPSVM is that each plane is closest to the points of its own class and furthest to the points of the other class. Analysis and experiments have demonstrated its capability in both computation time and test correctness. In this paper, following the geometric intuition of GEPSVM, a new supervised learning method called proximal support vector machine using local information (LIPSVM) is proposed. With the introduction of proximity information (consideration of underlying information such as correlation or similarity between points) between the training points, LIPSVM not only keeps aforementioned characteristics of CEPSVM, but also has its additional advantages: (1) robustness to outliers; (2) each plane is generated from its corresponding standard rather than generalized eigenvalue problem to avoid matrix singularity; (3) comparable classification ability to the eigenvalue-based classifiers GEPSVM and LDA. Furthermore, the idea of LIPSVM can be easily extended to other classifiers, such as LDA. Finally, some experiments on the artificial and benchmark datasets show the effectiveness of LIPSVM. Crown Copyright (C) 2009 Published by Elsevier B.V. All rights reserved.								6	1	1	0	7	0925-2312		WOS:000272607000042	
J	Yang, Haiqin; Huang, Kaizhu; King, Irwin; Lyu, Michael R.								Localized support vector regression for time series prediction								NEUROCOMPUTING			72	10-12			2659	2669		10.1016/j.neucom.2008.09.014			JUN 2009	2009	Time series prediction, especially financial time series prediction, is a challenging task in machine learning. In this issue, the data are usually non-stationary and volatile in nature. Because of its good generalization power, the support vector regression (SVR) has been widely applied in this application. The standard SVR employs a fixed epsilon-tube to tolerate noise and adopts the l(p)-norm (p = 1 or 2) to model the functional complexity of the whole data set. One problem of the standard SVR is that it considers data in a global fashion only. Therefore it may lack the flexibility to capture the local trend of data; this is a critical aspect of volatile data, especially financial time series data. Aiming to attack this issue, we propose the localized support vector regression (LSVR) model. This novel model is demonstrated to provide a systematic and automatic scheme to adapt the margin locally and flexibly; while the margin in the standard SVR is fixed globally. Therefore, the LSVR can tolerate noise adaptively. The proposed LSVR is promising in the sense that it not only captures the local information in data, but more importantly, it establishes connection with several models. More specifically: (1) it can be regarded as the regression extension of a recently proposed promising classification model, the Maxi-Min Margin Machine: (2) it incorporates the standard SVR as a special case under certain mild assumptions. We provide both theoretical justifications and empirical evaluations for this novel model. The experimental results on synthetic data and real financial data demonstrate its advantages over the standard SVR. Crown Copyright (C) 2008 Published by Elsevier B.V. All rights reserved.								6	4	0	0	10	0925-2312		WOS:000266702300064	
J	Sakiyama, Yojiro								The use of machine learning and nonlinear statistical tools for ADME prediction								EXPERT OPINION ON DRUG METABOLISM & TOXICOLOGY			5	2			149	169		10.1517/17425250902753261			FEB 2009	2009	Absorption, distribution, metabolism and excretion (ADME)-related failure of drug candidates is a major issue for the pharmaceutical industry today. Prediction of ADME by in silico tools has now become an inevitable paradigm to reduce cost and enhance efficiency in pharmaceutical research. Recently, machine learning as well as nonlinear statistical tools has been widely applied to predict routine ADME end points. To achieve accurate and reliable predictions, it would be a prerequisite to understand the concepts, mechanisms and limitations of these tools. Here, we have devised a small synthetic nonlinear data set to help understand the mechanism of machine learning by 2D-visualisation. We applied six new machine learning methods to four different data sets. The methods include Naive Bayes classifier, classification and regression tree, random forest, Gaussian process, support vector machine and k nearest neighbour. The results demonstrated that ensemble learning and kernel machine displayed greater accuracy of prediction than classical methods irrespective of the data set size. The importance of interaction with the engineering field is also addressed. The results described here provide insights into the mechanism of machine learning, which will enable appropriate usage in the future.								6	0	4	0	6	1742-5255		WOS:000264233800005	
J	Shao, Yongni; He, Yong; Bao, Yidan; Mao, Jingyuan				He, Yong/E-3218-2010	He, Yong/0000-0001-6752-1757			Near-Infrared Spectroscopy for Classification of Oranges and Prediction of the Sugar Content								INTERNATIONAL JOURNAL OF FOOD PROPERTIES			12	3			644	658	PII 910910637	10.1080/10942910801992991			2009	2009	A nondestructive method for the classification of orange samples according to their growing conditions and geographic areas was developed using Vis/Near infrared spectroscopy. The results showed that the NIR spectra of the samples were moderately clustered in the principle component space and pattern recognition wavelet transform (WT) combined artificial neural network (BP-ANN) provided satisfactory classification results. Additionally, a partial least square (PLS) method was constructed to predict the sugar content of certain oranges. It showed excellent predictions of the sugar content of oranges, with standard error of prediction (SEP) values of 0.290 and 0.301 for Shatangju and Huangyanbendizao, respectively.								6	0	3	0	6	1094-2912		WOS:000265653100016	
J	Garain, Utpal								Prototype reduction using an artificial immune model								PATTERN ANALYSIS AND APPLICATIONS			11	3-4			353	363		10.1007/s10044-008-0106-1			SEP 2008	2008	Artificial immune system (AIS)-based pattern classification approach is relatively new in the field of pattern recognition. The study explores the potentiality of this paradigm in the context of prototype selection task that is primarily effective in improving the classification performance of nearest-neighbor (NN) classifier and also partially in reducing its storage and computing time requirement. The clonal selection model of immunology has been incorporated to condense the original prototype set, and performance is verified by employing the proposed technique in a practical optical character recognition (OCR) system as well as for training and testing of a set of benchmark databases available in the public domain. The effect of control parameters is analyzed and the efficiency of the method is compared with another existing techniques often used for prototype selection. In the case of the OCR system, empirical study shows that the proposed approach exhibits very good generalization ability in generating a smaller prototype library from a larger one and at the same time giving a substantial improvement in the classification accuracy of the underlying NN classifier. The improvement in performance has been statistically verified. Consideration of both OCR data and public domain datasets demonstrate that the proposed method gives results better than or at least comparable to that of some existing techniques.								6	0	1	0	6	1433-7541		WOS:000258579900011	
J	Hewett, Rattikorn; Kijsanayothin, Phongphun								Tumor classification ranking from microarray data								BMC GENOMICS			9						S21	10.1186/1471-2164-9-S2-S21		2	2008	2008	Background: Gene expression profiles based on microarray data are recognized as potential diagnostic indices of cancer. Molecular tumor classifications resulted from these data and learning algorithms have advanced our understanding of genetic changes associated with cancer etiology and development. However, classifications are not always perfect and in such cases the classification rankings (likelihoods of correct class predictions) can be useful for directing further research (e.g., by deriving inferences about predictive indicators or prioritizing future experiments). Classification ranking is a challenging problem, particularly for microarray data, where there is a huge number of possible regulated genes with no known rating function. This study investigates the possibility of making tumor classification more informative by using a method for classification ranking that requires no additional ranking analysis and maintains relatively good classification accuracy.Results: Microarray data of 11 different types and subtypes of cancer were analyzed using MDR (Multi-Dimensional Ranker), a recently developed boosting-based ranking algorithm. The number of predictor genes in all of the resulting classification models was at most nine, a huge reduction from the more than 12 thousands genes in the majority of the expression samples. Compared to several other learning algorithms, MDR gives the greatest AUC (area under the ROC curve) for the classifications of prostate cancer, acute lymphoblastic leukemia (ALL) and four ALL subtypes: BCR-ABL, E2A-PBX1, MALL and TALL. SVM (Support Vector Machine) gives the highest AUC for the classifications of lung, lymphoma, and breast cancers, and two ALL subtypes: Hyperdiploid >50 and TEL-AML1. MDR gives highly competitive results, producing the highest average AUC, 91.01%, and an average overall accuracy of 90.01% for cancer expression analysis.Conclusion: Using the classification rankings from MDR is a simple technique for obtaining effective and informative tumor classifications from cancer gene expression data. Further interpretation of the results obtained from MDR is required. MDR can also be used directly as a simple feature selection mechanism to identify genes relevant to tumor classification. MDR may be applicable to many other classification problems for microarray data.								6	0	5	0	7	1471-2164		WOS:000206244200022	
S	Panigrahy, Rina						Laber, ES; Bornstein, C; Nogueira, LT; Faria, L		An improved algorithm finding nearest neighbor using kd-trees								LATIN 2008: THEORETICAL INFORMATICS	LECTURE NOTES IN COMPUTER SCIENCE		4957				387	398		10.1007/978-3-540-78773-0_34			2008	2008	We suggest a simple modification to the Kd-tree search algorithm for nearest neighbor search resulting in an improved performance. The Kd-tree data structure seems to work well in finding nearest neighbors in low dimensions but its performance degrades even if the number of dimensions increases to more than two. Since the exact nearest neighbor search problem suffers from the curse of dimensionality we focus on approximate solutions; a c-approximate nearest neighbor is any neighbor within distance at most c times the distance to the nearest neighbor. We show that for a randomly constructed database of points if the query point is chosen close to one of the points in the data base, the traditional Kd-tree search algorithm has a very low probability of finding an approximate nearest neighbor; the probability of success drops exponentially in the number of dimensions d as e(- Omega(d/c)). However, a simple change to the search algorithm results in a much higher chance of success. Instead of searching for the query point in the Kd-tree we search for a random set of points in the neighborhood of the query point. It turns out that searching for e(Omega(d/c)) such points can find the c-approximate nearest neighbor with a much higher chance of success.				8th Latin American Symposium on Theoretical Informatics (LATIN 2008)	APR 07-JUL 11, 2008	Microsoft; UOL; IFIP; HP; Yahoo; FAPERJ; CNPq; CAPES; Springer	Buzios, BRAZIL	6	0	0	0	6	0302-9743	978-3-540-78772-3	WOS:000254390900034	
J	Besaw, Lance E.; Rizzo, Donna M.								Stochastic simulation and spatial estimation with multiple data types using artificial neural networks								WATER RESOURCES RESEARCH			43	11					W11409	10.1029/2006WR005509			NOV 8 2007	2007	A novel data-driven artificial neural network ( ANN) that quantitatively combines large numbers of multiple types of soft data is presented for performing stochastic simulation and/or spatial estimation. A counterpropagation ANN is extended with a radial basis function to estimate parameter fields that reproduce the spatial structure exhibited in autocorrelated parameters. Applications involve using three geophysical properties measured on a slab of Berea sandstone and the delineation of landfill leachate at a site in the Netherlands using electrical formation conductivity as our primary variable and six types of secondary data ( e. g., hydrochemistry, archaea, and bacteria). The ANN estimation fields are statistically similar to geostatistical methods ( indicator simulation and cokriging) and reference fields ( when available). The method is a nonparametric clustering/ classification algorithm that can assimilate significant amounts of disparate data types with both continuous and categorical responses without the computational burden associated with the construction of positive definite covariance and cross-covariance matrices. The combination of simplicity and computational speed makes the method ideally suited for environmental subsurface characterization and other Earth science applications with spatially autocorrelated variables.								6	1	2	0	7	0043-1397		WOS:000250857900001	
J	Angiulli, Fabrizio								Condensed nearest neighbor data domain description								IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			29	10			1746	1758		10.1109/TPAMI.2007.1086			OCT 2007	2007	A simple yet effective unsupervised classification rule to discriminate between normal and abnormal data is based on accepting test objects whose nearest neighbors' distances in a reference data set, assumed to model normal behavior, lie within a certain threshold. This work investigates the effect of using a subset of the original data set as the reference set of the classifier. With this aim, the concept of a reference-consistent subset is introduced and it is shown that finding the minimum-cardinality reference-consistent subset is intractable. Then, the Condensed Nearest Neighbor Domain Description (CNNDD) algorithm is described, which computes a reference-consistent subset with only two reference set passes. Experimental results revealed the advantages of condensing the data set and confirmed the effectiveness of the proposed approach. A thorough comparison with related methods was accomplished, pointing out the strengths and weaknesses of one-class nearest-neighbor-based training-set-consistent condensation.								6	5	0	1	12	0162-8828		WOS:000248696100005	
J	Scott, Clayton; Davenport, Mark								Regression level set estimation via cost-sensitive classification					1			IEEE TRANSACTIONS ON SIGNAL PROCESSING			55	6			2752	2757		10.1109/TSP.2007.893758			JUN 2007	2007	Regression level set estimation is an important yet understudied learning task. It lies somewhere between regression function estimation and traditional binary classification, and in many cases is a more appropriate setting for questions posed in these more common frameworks. This note explains how estimating the level set of a regression function from training examples can be reduced to cost-sensitive classification. We discuss the theoretical and algorithmic benefits of this learning reduction, demonstrate several desirable properties of the associated risk, and report experimental results for histograms, support vector machines, and nearest neighbor rules on synthetic and real data.								6	0	0	0	6	1053-587X		WOS:000246705100035	
J	Dragovic, Snezana; Onjia, Antonije								Classification of soil samples according to geographic origin using gamma-ray spectrometry and pattern recognition methods								APPLIED RADIATION AND ISOTOPES			65	2			218	224		10.1016/j.apradiso.2006.07.005			FEB 2007	2007	Multivariate data analysis methods were used to recognize and classify soils of unknown geographic origin. A total of 103 soil samples were differentiated into classes, according to regions in Serbia and Montenegro from which they were collected. Their radionuclide (Ra-226, U-238, U-235, K-40, Cs-134, Cs-137, Th-232 and Be-7) activities detected by gamma-ray spectrometry were then used as the inputs in different pattern recognition methods. For the classification of soil samples using eight selected radionuclides, the prediction ability of linear discriminant analysis (LDA), k-nearest neighbours (kNN), soft independent modelling of class analogy (SIMCA) and artificial neural network (ANN) were 82.8%, 88.6%, 60.0% and 92.1%, respectively. (c) 2006 Elsevier Ltd. All rights reserved.								6	0	2	0	6	0969-8043		WOS:000243670300010	
J	Model, Dmitri; Zibulevsky, Michael								Learning subject-specific spatial and temporal filters for single-trial EEG classification								NEUROIMAGE			32	4			1631	1641		10.1016/j.neuroimage.2006.04.224			OCT 1 2006	2006	There are a wide variety of electroencephalography (EEG) analysis methods. Most of them are based on averaging over multiple trials in order to increase signal-to-noise ratio. The method introduced in this article is a single trial method. Our approach is based on the assumption that the "response of interest" to each task is smooth, and is contained in several sensor channels. We propose a two-stage preprocessing method. In the first stage, we apply spatial filtering by taking weighted linear combinations of the sensor measurements. In the second stage, we perform time-domain filtering. In both steps, we derive filters that maximize a class dissimilarity measure subject to regularizing constraints on the total variation of the average estimated signal (or, alternatively, on the signal's strength in time intervals where it is known to be absent). No other spatial or spectral assumptions with regard to the anatomy or sources were made. (c) 2006 Elsevier Inc. All rights reserved.								6	1	2	0	7	1053-8119		WOS:000240969200012	
J	Tossavainen, T; Toppila, E; Pyykko, M; Forsman, PM; Juhola, M; Starck, J								Virtual reality in posturography								IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE			10	2			282	292		10.1109/TITB.2005.859874			APR 2006	2006	Balance dysfunctions are common, especially among elderly people. Present methods for the diagnosis and evaluation of severity of dysfuntion have limited value. We present a system that makes it easy to implement different visual and mechanical perturbations for clinical investigations of balance and visual-vestibular interaction. The system combines virtual reality visual stimulation with force platform posturography on a moving platform. We evaluate our contruction's utility in a classification task between 33 healthy controls and 77 patients with Meniere's disease, using a series of tests with different visual and mechanical stimuli. Responses of patients and controls differ significantly in parameters computed from stabilograms. We also show that the series of tests achieves a classification accuracy slightly over 80% between controls and patients.								6	0	5	1	8	1089-7771		WOS:000236674400009	
S	Chen, Tung-Shou; Lin, Chih-Chiang; Chiu, Yung-Hsing; Lin, Hsin-Lan; Chen, Rong-Chang						Huang, DS; Li, K; Irwin, GW		A new binary classifier: Clustering-launched classification								COMPUTATIONAL INTELLIGENCE, PT 2, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		4114				278	283					2006	2006	One of the powerful classifiers is Support Vector Machine (SVM), which has been successfully applied to many fields. Despite its remarkable achievement, SVM is time-consuming in many situations where the data distribution is unknown, causing it to spend much time on selecting a suitable kernel and setting parameters. Previous studies proposed understanding the data distribution before classification would assist the classification. In this paper, we exquisitely combined with clustering and classification to develop a novel classifier, Clustering-Launched Classification (CLC), which only needs one parameter. CLC employs clustering to group data to characterize the features of the data and then adopts the one-against-the-rest and nearest-neighbor to find the support vectors. In our experiments, CLC is compared with two well-known SVM tools: LIBSVM and mySVM. The accuracy of CLC is comparable to LIBSVM and mySVM. Furthermore, CLC is insensitive to parameter, while the SVM is sensitive, showing CLC is easier to use.				International Conference on Intelligent Computing (ICIC)	AUG 16-19, 2006	IEEE Computat Intelligence Soc; Int Neural Network Soc; Natl Sci Fdn China	Kunming, PEOPLES R CHINA	6	0	0	0	6	0302-9743	3-540-37274-1	WOS:000240083300035	
B	Panigrahy, Rina			SIAM/ACM					Entropy based Nearest Neighbor Search in High Dimensions								PROCEEDINGS OF THE SEVENTHEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS							1186	1195		10.1145/1109557.1109688			2006	2006	In this paper we study the problem of finding the approximate nearest neighbor of a query point in the high dimensional space, focusing on the Euclidean space. The earlier approaches use locality-preserving hash functions (that tend to map nearby points to the same value) to construct several hash tables to ensure that the query point hashes to the same bucket as its nearest neighbor in at least one table. Our approach is different we use one (or a few) hash table and hash several randomly chosen points in the neighborhood of the query point showing that at least one of them will hash to the bucket containing its nearest neighbor. We show that the number of randomly chosen points in the neighborhood of the query point q required depends on the entropy of the hash value h(p) of a random point p at the same distance from q at its nearest neighbor, given q and the locality preserving hash function h chosen randomly from the hash family. Precisely, we show that if the entropy I (h(p)vertical bar q, h) = M and g is a bound on the probability that two far-off points will hash to the same bucket, then we can find the approximate nearest neighbor in O(n(rho)) time and near linear (O) over tilde (n) space where p = M/log(l/g). Alternatively we can build a data structure of size O(n1/((1-rho)) to answer queries in 0(d) time. By applying this analysis to the locality preserving hash functions in [17, 21, 6] and adjusting the parameters we show that the c nearest neighbor can be computed in time O(nP) and near linear space where rho approximate to 2.06/c as c becomes large.				17th ACM-SIAM Symposium on Discrete Algorithms	JAN, 2006	ACM SIGACT; SIAM	Miami, FL	6	2	0	0	8		978-0-89871-605-4	WOS:000281596300131	
J	Le, SQ; Ho, TB								An association-based dissimilarity measure for categorical data								PATTERN RECOGNITION LETTERS			26	16			2549	2557		10.1016/j.patrec.2005.06.002			DEC 2005	2005	In this paper, we propose a novel method to measure the dissimilarity of categorical data. The key idea is to consider the dissimilarity between two categorical values of an attribute as a combination of dissimilarities between the conditional probability distributions of other attributes given these two values. Experiments with real data show that our dissimilarity estimation method improves the accuracy of the popular nearest neighbor classifier. (c) 2005 Elsevier B.V. All rights reserved.								6	0	0	0	6	0167-8655		WOS:000233307200006	
J	Podsiadlo, P; Stachowiak, GW								Classification of tribological surfaces without surface parameters								TRIBOLOGY LETTERS			16	1-2			163	171		10.1023/B:TRIL.0000009726.17576.b5			FEB 2004	2004	Quantitative measures are obtained from images of tribological surfaces. Based on these data, decisions are made regarding manufacturing and maintenance processes, machine-condition monitoring and failure analysis of engineering components. These decisions are often guided by an automated pattern recognition system. Components of this system are: surface topography data acquisition, surface characterization, surface classification and performance evaluation. The characterization and classification of tribological surfaces are major challenges that make the development of a reliable pattern-recognition system difficult. The reasons are that: (i) tribological surfaces often exhibit a non-stationary and multiscale nature, while most surface characterization methods currently used work well with surface data exhibiting a stationary random process, (ii) changes in topography that might occur between the interacting surfaces usually need to be known in advance, and (iii) the selection of surface parameters that separate different classes of surfaces is usually time-consuming and cumbersome. Because of these difficulties, characterization and classification methods which do not use surface parameters have been developed. In the classification methods, a measure of dissimilarity (e.g., Euclidean distance) calculated between a surface to be classified and already classified surfaces was used, instead of surface parameters. The unclassified surface was assigned to the class ( of classified surfaces) with the lowest value of dissimilarity measure. The suitability of different classifiers; such as k-nearest neighbour classifier, linear-discriminant-analysis based classifiers and different dissimilarity measures; for the classification of tribological surface topographies ( without the need for surface parameters) is investigated in this paper. Recent developments in this area, i. e., a fractal measure and a hybrid fractal-wavelet measure, are also discussed. The most suitable method for the classification of tribological surfaces has been selected.								6	0	0	0	6	1023-8883		WOS:000187516300019	
J	Teoh, A; Samad, SA; Hussain, A				Teoh, Andrew Beng Jin/F-4422-2010; Hussain, Aini/G-4074-2011				Nearest neighbourhood classifiers in a bimodal biometric verification system fusion decision scheme								JOURNAL OF RESEARCH AND PRACTICE IN INFORMATION TECHNOLOGY			36	1			47	62					FEB 2004	2004	Identity verification systems that use a mono modal biometrics always have to contend with sensor noise and limitations of feature extractor and matching. However combining information from different biometrics modalities may well provide higher and more consistent performance levels. A robust yet simple scheme can fuse the decisions produced by the individual biometric experts. In this paper, k-Nearest Neighbourhood (k-NN) based classifiers are adopted in the decision fusion module for the face and speech experts. k-NN rule owes much of its popularity in pattern recognition community to its simplicity and good performance in practical application. Besides that, k-NN may also provide a ternary decision scheme which is rarely found in other classifiers. The fusion decision schemes considered are voting-, modified- and theoretic evidence of k-NN classifiers based on Dempster-Shafer theory. The performances of these k-NN classifiers are evaluated in both balanced and unbalanced conditions and compared with other classification approaches such as sum rule, voting techniques and Multilayer Perceptron on a bimodal database.								6	0	0	0	6	1443-458X		WOS:000220460600005	
S	Bao, YG; Ishii, N; Du, XY						Yang, ZR; Everson, R; Yin, H		Combining multiple k-nearest neighbor classifiers using different distance functions								INTELLIGENT DAA ENGINEERING AND AUTOMATED LEARNING IDEAL 2004, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		3177				634	641					2004	2004	The k-nearest neighbor (KNN) classification is a simple and effective classification approach. However, improving performance of the classifier is still attractive. Combining multiple classifiers is an effective technique for improving accuracy. There are many general combining algorithms, such as Bagging, Boosting, or Error Correcting Output Coding that significantly improve the classifier such as decision trees, rule learners, or neural networks. Unfortunately, these combining methods do not improve the nearest neighbor classifiers. In this paper we present a new approach to combine multiple KNN classifiers based on different distance funtions, in which we apply multiple distance functions to improve the performance of the k-nearest neighbor classifier. The proposed algorithm seeks to increase generalization accuracy when compared to the basic k-nearest neighbor algorithm. Experiments have been conducted on some benchmark datasets from the UCI Machine Learning Repository. The results show that the proposed algorithm improves the performance of the k-nearest neighbor classification.				5th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL 2004)	AUG 25-27, 2004	Execter Univ, Comp Sci Dept; IEEE Neural Networks Soc; Springer Verlag	Execter, ENGLAND	6	0	1	0	6	0302-9743	3-540-22881-0	WOS:000223701300093	
J	Wojna, A								Center-based indexing in vector and metric spaces								FUNDAMENTA INFORMATICAE			56	3			285	310					AUG 2003	2003	The paper addresses the problem of indexing data for k nearest neighbors (k-nn) search. Given a collection of data objects and a similarity measure the searching goal is to find quickly the k most similar objects to a given query object. We present a top-down indexing method that employs a widely used scheme of indexing algorithms. It starts with the whole set of objects at the root of an indexing tree and iteratively splits data at each level of indexing hierarchy. In the paper two different data models are considered. In the first, objects are represented by vectors from a multi-dimensional vector space. The second, more general, is based on an assumption that objects satisfy only the axioms of a metric space. We propose an iterative k-means algorithm for tree node splitting in case of a vector space and an iterative k-approximate-centers algorithm in case when only a metric space is provided. The experiments show that the iterative k-means splitting procedure accelerates significantly k-nn searching over the one-step procedure used in other indexing structures such as GNAT, SS-tree and M-tree and that the relevant representation of a tree node is an important issue for the performance of the search process. We also combine different search pruning criteria used in BST, GHT nad GNAT structures into one and show that such a combination outperforms significantly each single pruning criterion. The experiments are performed for benchmark data sets of the size up to several hundreds of thousands of objects. The indexing tree with the k-means splitting procedure and the combined search criteria is particularly effective for the largest tested data sets for which this tree accelerates searching up to several thousands times.								6	1	0	0	7	0169-2968		WOS:000187177000005	
J	Bloch, DA; Olshen, RA; Walker, MG								Risk estimation for classification trees								JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS			11	2			263	288		10.1198/106186002760180509			JUN 2002	2002	This article is a study of techniques for bias reuction of estimates of risk both globally and within terminal nodes of CART R classification trees. In Section 5.4 of Classification and Regression Trees, Leo Breiman presented an estimator that has two free parameters. An empirical Bayes method was put forth for estimating them. Here we explain why the estimator should be successful in the many examples for which it is. We give numerical evidence from simulations in the two-class case with attention to ordinary resubstitution and seven other methods of estimation. There are 14 sampling distributions, all but one simulated and the remaining concerning E. coli promoter regions. We report on varying minimum node sizes of the trees prior probabilities and misclassification costs; and, when relevant, the numbers of bootstraps or cross-validations. A variation of Breiman's method in which repeated cross-validation is employed to estimate global rates of misclassification was the most accurate from among the eight methods. Exceptions are cases for which the Bayes risk of the Bayes rule is small, For them, either a local bootstrap.632 estimate or Breiman's method modified to use a bootstrap estimate of the global misclassification rate is most accurate.								6	0	1	0	6	1061-8600		WOS:000176157400001	
J	Roy, K; Sengupta, C; De, AU				Roy, Kunal/B-1673-2009	Roy, Kunal/0000-0003-4486-8074			Theoretical aspects of rational drug design - An overview								JOURNAL OF SCIENTIFIC & INDUSTRIAL RESEARCH			60	9			699	716					SEP 2001	2001	The major techniques of drug discovery processes for the past thirty years have been summarized. However, because of rapid advances in information technology and emergence of plethora of newer techniques, e.g., PCMM, UPGMA, MMG, FALS, MMFF, etc., this short review obviously does not give an exhaustive coverage. The paper summarizes different approaches of rational drug design methods with a primary focus on quantitative structure-activity relationship QSAR) and molecular modelling studies. Apart from an overview of classical QSAR tools (Hansch approach, Fujita-Ban modification of Free Wilson model and topological schemes) and different mathematical methods of QSAR, different components of molecular modelling including techniques of computational chemistry (quantum and molecular mechanical approaches) are briefly discussed. Various receptor-dependent and receptor-independent 3-D QSAR methods and techniques like protein modelling, de novo ligand design and receptor mapping are also summarized. Some other trends in recent drug development process like mass ligand screening, recombinant DNA technology, peptidomimetics, oligonucleotide therapeutics, cabohydrate based drug design, and prodrug design are also mentioned.								6	0	4	0	6	0022-4456		WOS:000170894300001	
J	Wong, KD; Cox, DC								Two-state pattern-recognition handoffs for corner-turning situations								IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY			50	2			354	363		10.1109/25.923048			MAR 2001	2001	Handoff algorithms are used in wireless cellular systems to decide when and to which base station to handoff. Traditional handoff algorithms generally cannot keep both the average number of unnecessary handoffs and the handoff decision delay low. They do not exploit the relative constancy of path loss and shadow fading effects at any given location around a base station. However, handoff algorithms with both a negligible number of unnecessary handoffs and a negligible decision delay can be realized by exploiting this information. One example is the set of handoff algorithms using pattern recognition introduced in previous work. In this paper, we describe how pattern-recognition handoff algorithms can be applied to the problem of turning a corner. This can be used as part of an integrated pattern-recognition handoff algorithm or together with a traditional handoff algorithm, in which case the pattern recognition handles only the special cases like turning a corner.								6	0	0	0	6	0018-9545		WOS:000168791000002	
S	Bissacco, A; Chiuso, A; Ma, Y; Soatto, S						Jacobs, A; Baldwin, T		Recognition of human gaits								2001 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, VOL 2, PROCEEDINGS	PROCEEDINGS - IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION						52	57					2001	2001	We pose the problem of recognizing different types of human gait in the space of dynamical systems where each gait is represented Established techniques are employed to track a kinematic model of a human body in motion, and the trajectories of the parameters are used to learn a representation of a dynamical system, which defines a gait.. Various types of distance between models are then computed These computations are non trivial due to the fact that, even for the case of linear systems, the space of canonical realizations is not linear.				Conference on Computer Vision and Pattern Recognition	DEC 08-14, 2001	IEEE Comp Soc	KAUAI, HI	6	1	0	0	7	1063-6919	0-7695-1272-0	WOS:000184694400008	
J	Bermejo, S; Cabestany, J								A batch learning vector quantization algorithm for nearest neighbour classification								NEURAL PROCESSING LETTERS			11	3			173	184		10.1023/A:1009634824627			JUN 2000	2000	We introduce a batch learning algorithm to design the set of prototypes of 1 nearest-neighbour classifiers. Like Kohonen's LVQ algorithms, this procedure tends to perform vector quantization over a probability density function that has zero points at Bayes borders. Although it differs significantly from their online counterparts since: (1) its statistical goal is clearer and better defined; and (2) it converges superlinearly due to its use of the very fast Newton's optimization method. Experiments results using artificial data confirm faster training time and better classification performance than Kohonen's LVQ algorithms.								6	0	0	0	6	1370-4621		WOS:000088039900001	
J	de Bruijn, LM; Hasman, A; Arends, JW				Hasman, Arie/F-1816-2013				Supporting the classification of pathology reports: comparing two information retrieval methods								COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE			62	2			109	113		10.1016/S0169-2607(00)00056-0			JUN 2000	2000	In this contribution two methods from the domain of information retrieval are compared. The goal of the retrieval is to select from a library of pathology reports those ones that are most similar to a given report. The SNOMED codes that accompany these reports are presented to the pathologist who has to code the given report with the aim to improve the quality of coding. The reports were represented either as a vector of words or as a vector of N-grams. Both 4-, 5- and 6-grams were used. The similarity of the reports was determined by comparing the SNOMED terms that were added to the reports. It could be concluded that the word-based method was consistently better than the N-gram method. (C) 2000 Elsevier Science Ireland Ltd. All rights reserved.								6	0	4	0	6	0169-2607		WOS:000086633100005	
J	Hamilton, PW; Bartels, PH; Anderson, N; Thompson, D; Montironi, R; Sloan, JM								Case-based prediction of survival in colorectal cancer patients								ANALYTICAL AND QUANTITATIVE CYTOLOGY AND HISTOLOGY			21	4			283	291					AUG 1999	1999	OBJECTIVE: To develop an approach to the prediction of survival in patients with colorectal cancer using nearest neighbor analysis and case-based reasoning.STUDY DESIGN: A total of 216 patients with full clinicopathologic records and five-year follow-up were the subjects of this study. They were divided into It cove database of 162 cases and a test group of 54 cases, with follow up on all patients. When the patient was still alive at the end of the follow-up period, censored survival time was used. For each of the test cases, the four closest neighbors from the database were retrieved and their median survival time recorded and used as the predicted estimate of survival. Case matching was based on a Euclidean multivariate distance measure for the three best predictor variables: patient age, Dukes stage and tubule configuration . Cases with the smallest distance from the test case were considered to be the most similar. The predicted survival times for the test cases were compared with the actual, observed survival in the test cases to determine the success of this approach.RESULTS: The results showed reasonable concordance between observed and predicted survival figures, although there was a large degree of spread. Classification of cases into less than or equal to 60 and > 60 months' survival showed a correct classification rate of 63%. For the prediction of survival time, the distribution Of differences between observed and predicted survival times for the uncensored test cases had a median value of-5 months but also showed a wide dispersion of values. Correlation of observed and predicted survival times, while not reaching statistical significance at P < .05, did show a strong positive association.CONCLUSION: Case-based approaches to the prediction of survival times in cancer patients are important. The results of the current study illustrate the difficulties in applying this approach to survival data and highlight the complexity of patient information and the inability to accurately predict patient outcome on 17 small subset of clinicopathologic features. While extensive work needs to be carried out to improve prediction power, this study illustrates the potential for case-based analyses. The ability to retrieve feature-matched cases from hospital patient databases has clear, independent advantages in patient management, but the ability to provide reliable, targeted prognostic estimates on individual cases should be a common goal in medical research.								6	0	5	0	6	0884-6812		WOS:000082008300002	
J	Krishna, V; Chandramouli, R; Ranganathan, N								Computation of lower bounds for switching activity using decision theory								IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS			7	1			125	129		10.1109/92.748209			MAR 1999	1999	Accurate switching-activity estimation is crucial for power budgeting. It is impractical to obtain an accurate estimate by simulating the circuit for all possible inputs. An alternate approach would be to compute tight bounds for the switching activity. In this paper, we propose a nonsimulative decision theoretic method to compute the tower bound for switching activity. First, we show that the switching activity can be modeled as the decision error of an abstract two-class problem. It is shown that the Bayes error L* is a lower bound for the switching activity. Further, we improve L* to obtain a tighter bound L-1, which is based on the one-nearest neighbor classification error, The proposed lower bounds are used for switching-activity characterization at the register transfer (RT) level. Experimental results for the RT-level switching-activity estimates for ISCAS'85 circuits are presented. This technique is simple and fast and produces accurate estimates.								6	0	0	0	6	1063-8210		WOS:000078920900015	
S	Luaces, O; del Coz, JJ; Quevedo, JR; Alonso, J; Ranilla, J; Bahamonde, A						Mira, J; SanchezAndres, JV		Autonomous clustering for machine learning								FOUNDATIONS AND TOOLS FOR NEURAL MODELING, PROCEEDINGS, VOL I	LECTURE NOTES IN COMPUTER SCIENCE		1606				497	506					1999	1999	In this paper, starting from a collection of training examples, we show how to produce a very compact set of classification rules. The induction idea is a clustering principle based on Kohonen's self-organizing algorithms. The function to optimize in the aggregation of examples to become rules is a classificatory quality measure called impurity level, which was previously employed in our system called FAN. The rule conditions obtained in this way are densely populated areas in the attribute space. The main goal of our system, in addition to its accuracy, is the high quality of explanations that it can provide attached to the classification decisions.				5th International Work-Conference on Artificial and Natural Neural Networks (IWANN 99)	JUN 02-04, 1999	Asociac Espanola Redes Neuronales; Univ Nacl Educ Distancia; Univ Miguel Hernandez; IFIP; Spanish RIG IEEE Neural Networks Council	ALICANTE, SPAIN	6	0	2	0	6	0302-9743	3-540-66069-0	WOS:000165140200053	
J	Snapp, RR; Venkatesh, SS								Asymptotic expansions of the k nearest neighbor risk								ANNALS OF STATISTICS			26	3			850	878					JUN 1998	1998	The finite-sample risk of the k nearest neighbor classifier that uses a weighted L-p-metric as a measure of class similarity is examined. For a family of classification problems with smooth distributions in R-n, an asymptotic expansion for the risk is obtained in decreasing fractional powers of the reference sample size. An analysis of the leading expansion coefficients reveals that the optimal weighted L-p-metric, that is, the metric that minimizes the finite-sample risk, tends to a weighted Euclidean (i.e., L-2)metric as the sample size is increased. Numerical simulations corroborate this finding for a pattern recognition problem with normal class-conditional densities.								6	1	0	0	7	0090-5364		WOS:000079135500006	
J	El-Kwae, EA; Fishman, JE; Bianchi, MJ; Pattany, PM; Kabuka, MR								Detection of suspected malignant patterns in three-dimensional magnetic resonance breast images								JOURNAL OF DIGITAL IMAGING			11	2			83	93					MAY 1998	1998	In this article, a Boolean Neural Network (BNN) is used for the detection of suspected malignant regions in 3D breast magnetic resonance (MR) images. The BNN is characterized by fast learning and classification, guaranteed convergence, and simple, integer weight calculations. The BNN learning algorithm is incremental, which allows the addition and deletion of training patterns without unlearning those already learned. The incremental learning algorithm automatically reduces the training set and trains the network only with those examples estimated to be useful. The architecture is suitable for parallel hardware implementation using available Very Large Scale Integration (VLSI) technology. The BNN was trained by using a set of malignant, benign, and false-positive patterns, extracted by experts, from selected MR studies, by using an incremental teaming algorithm. After training, the network was tested by means of a consistency checking test, cross validation techniques, and patterns from actual MR breast images. During the consistency test, the BNN was tested by using the same patterns used for training. The BNN classification accuracy in this case was 99.75%, proving the ability of the BNN to select useful patterns from the training set. Then, a leave one out cross-validation (LOOCV) test was done by using patterns from the training set and the classification accuracy was 90%. Next, an extended training set was created by shifting the original patterns in different directions. A cross-validation test was then performed by dividing the set of patterns into a training and a test set. Classification accuracy was compared to the nearest neighbor classifier. Results showed that the BNN achieved an average of 77% classification accuracy while requiring only 34% of the original training set. On the other hand, the nearest neighbor classifier achieved an accuracy of 57.9% while retaining the whole training set. Another test using actual MR slices different from the training set was done and results compared favorably to a radiologist's findings. Test results show the BNN's capability to detect suspected malignant regions in 3D MR images of the breast. The proposed BNN architecture can save the radiologist a great deal of time browsing MR slices searching for suspected malignancies. Copyright (C) 1998 by W.B. Saunders Company.								6	0	2	0	6	0897-1889		WOS:000073695900004	
J	Chen, YQ; Damper, RI; Nixon, MS								On neural-network implementations of k-nearest neighbor pattern classifiers								IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-FUNDAMENTAL THEORY AND APPLICATIONS			44	7			622	629					JUL 1997	1997	The k-nearest neighbor (k-NN) decision rule is the basis of a well-established, high-performance pattern-recognition technique but its sequential implementation is inherently slow. More recently, feedforward neural networks trained on error backpropagation have been widely used to solve a variety of pattern-recognition problems. However, it is arguably unnecessary to learn such a computationally intensive solution when one (i.e., the k-NN rule) is effectively available a priori, especially given the well-known pitfalls of backpropagation. Accordingly, there is some interest in the literature in network implementations of this rule, so as to combine its known, good performance with the speed of a massively parallel realization. In this paper, we present a novel neural-network architecture which implements the L-NN rule and whose distinctive feature relative to earlier work is its synchronous (i.e., clocked) nature. Essentially, it has a layered, feedforward structure but, in its basic form, also incorporates feedback to control sequential selection of the k neighbors. The principal advantages of this new scheme are the avoidance of the stability problems which can arise with alternative asynchronous feedback (lateral-inhibition) circuits, the restriction of analog weights to the first hidden layer and the fact that network design uses noniterative weight calculations rather than iterative backpropagation. Analysis of the network shows that it will converge to the desired solution (faithfully classifying the input pattern according to the k-NN rule) within (2k - 1) clock cycles. Apart from minor changes which can be effected externally, the same design serves for any value of X. The space complexity of the ('brute-force'' network implementation is O(N-2) units, where N is the number of training patterns, and it has O(N(2)d) analog weights where d is the dimensionality of these patterns. Thus, some modifications to reduce the required number of units (and, thereby, weighted connections) are considered. Overall, this paper affords for high-speed, parallel implementations of proven pattern-classification techniques.								6	0	1	0	6	1057-7122		WOS:A1997XH37100006	
J	Klein, HM; Eisele, T; Klose, KC; Stauss, I; Brenner, M; Ameling, W; Gunther, RW								Pattern recognition system for focal liver lesions using ''crisp'' and ''fuzzy'' classifiers								INVESTIGATIVE RADIOLOGY			31	1			6	10		10.1097/00004424-199601000-00002			JAN 1996	1996	RATIONALE AND OBJECTIVES. To determine the diagnostic performance of an artificial intelligence system for classification of focal liver lesions, in comparison to human observers.METHODS. One hundred forty-three focal hepatic lesions were evaluated with dynamic computed tomography. The study comprised 59 hemangiomas, 24 other benign lesions (focal nodular hyperplasia, adenoma), and 60 malignant liver lesions (18 primary, 42 secondary). All lesions but the hemangiomas were histologically examined by needle biopsy.For delineation of the lesion, a region of interest was defined interactively. The pattern recognition was performed in two steps with initial extraction of textural features: training of a classifier and classification of the lesions. The accuracy of classification of hepatic lesions into three groups (hemangioma, other benign processes, malignant lesions) was tested. The results were compared with those achieved by human observers using receiver operating characteristic statistical analysis.RESULTS. The accuracy (total rate of correct diagnoses) was 90.2%. False classifications were found owing to small size, weak contrast enhancement after bolus injection, respiratory movement, and atypical morphology of the lesion. The area under the receiver operating characteristic curve was not significantly different for computer and human observers.CONCLUSIONS. The system demonstrated a diagnostic accuracy comparable to human observers. Further improvement with increasing numbers of typical computed tomographic series for training of the classifier can be expected.								6	0	2	0	6	0020-9996		WOS:A1996TP14900002	
J	HUANG, YS; LIU, K; SUEN, CY								A NEW METHOD OF OPTIMIZING PROTOTYPES FOR NEAREST-NEIGHBOR CLASSIFIERS USING A MULTILAYER NETWORK								PATTERN RECOGNITION LETTERS			16	1			77	82		10.1016/0167-8655(94)00070-J			JAN 1995	1995	This paper proposes a new method of optimizing the prototypes for a nearest neighbor classifier which uses a network with a hidden layer. After training, the neural network is mapped back to a nearest neighbor classifier with optimized prototypes. The main characteristic of the present method is that both the trained neural network and the mapped nearest classifier have the same recognition performance. Experimental results show that this method outperforms the method recently proposed by Yan (1994).								6	0	0	0	6	0167-8655		WOS:A1995QE08000010	
J	OMOHUNDRO, SM								GEOMETRIC LEARNING ALGORITHMS								PHYSICA D			42	1-3			307	321		10.1016/0167-2789(90)90085-4			JUN 1990	1990									6	0	0	0	6	0167-2789		WOS:A1990DR77000024	
J	DEVIJVER, PA								ON THE EDITING RATE OF THE MULTIEDIT ALGORITHM								PATTERN RECOGNITION LETTERS			4	1			9	12		10.1016/0167-8655(86)90066-8			FEB 1986	1986									6	0	0	0	6	0167-8655		WOS:A1986C058500002	
J	BAUM, BR; BAILEY, LG								RELATIONSHIPS BETWEEN HORDEUM-BULBOSUM L SUBSP BULBOSUM AND HORDEUM-BULBOSUM SUBSP NODOSUM COMB ET STAT-NOV								CANADIAN JOURNAL OF BOTANY-REVUE CANADIENNE DE BOTANIQUE			63	4			735	743					1985	1985									6	0	6	0	6	0008-4026		WOS:A1985AHA5400010	
J	DEVIJVER, PA								A MULTICLASS, K-NN APPROACH TO BAYES RISK-ESTIMATION								PATTERN RECOGNITION LETTERS			3	1			1	6		10.1016/0167-8655(85)90035-2			1985	1985									6	0	1	0	6	0167-8655		WOS:A1985ACT2800001	
J	GERSCH, W; MARTINELLI, F; YONEMOTO, J; LOW, MD; MCEWEN, JA								A KULLBACK LEIBLER NEAREST NEIGHBOR RULE CLASSIFICATION OF EEGS - THE EEG POPULATION SCREENING PROBLEM, AN ANESTHESIA LEVEL EEG CLASSIFICATION APPLICATION								COMPUTERS AND BIOMEDICAL RESEARCH			13	3			283	296		10.1016/0010-4809(80)90022-1			1980	1980									6	0	4	0	6	0010-4809		WOS:A1980JY01200006	
J	KOWALSKI, BR; BENDER, CF								SOLVING CHEMICAL PROBLEMS WITH PATTERN-RECOGNITION								NATURWISSENSCHAFTEN			62	1			10	14					1975	1975									6	1	2	0	6	0028-1042		WOS:A1975V497200002	
J	LEVINE, A; LUSTICK, L; SALTZBER.B								NEAREST-NEIGHBOR RULE FOR SMALL SAMPLES DRAWN FROM UNIFORM DISTRIBUTIONS								IEEE TRANSACTIONS ON INFORMATION THEORY			19	5			697	699		10.1109/TIT.1973.1055062			1973	1973									6	0	0	0	6	0018-9448		WOS:A1973Q670400020	
J	Watanabe, Toshiaki; Kobunai, Takashi; Yamamoto, Yoko; Matsuda, Keiji; Ishihara, Soichiro; Nozawa, Keijiro; Iinuma, Hisae; Ikeuchi, Hiroki								Gene Expression of Vascular Endothelial Growth Factor A, Thymidylate Synthase, and Tissue Inhibitor of Metalloproteinase 3 in Prediction of Response to Bevacizumab Treatment in Colorectal Cancer Patients								DISEASES OF THE COLON & RECTUM			54	8			1026	1035		10.1097/DCR.0b013e31821c44af			AUG 2011	2011	BACKGROUND: Regimens containing bevacizumab and 5-fluorouracil have achieved substantial progress in the treatment of colorectal cancer. However, individual responses to bevacizumab vary widely in regard to efficacy and toxicity.OBJECTIVE: To be able to select patients who would benefit from bevacizumab, we aimed to establish a predictor model for response to bevacizumab therapy based on gene expression profiles.DESIGN AND SETTING: Retrospective analysis of tumor samples in the laboratory.PATIENTS: The patient population comprised 25 patients with metastatic colorectal cancer treated with bevacizumab with either modified FOLFOX6 or FOLFIRI, from whom tumor samples were available for gene expression analysis.MAIN OUTCOME MEASURES: Response Evaluation Criteria in Solid Tumors were used to classify patients as responders or nonresponders to chemotherapy. Gene-expression profiles were determined with both microarray analysis and quantitative, real-time reverse-transcriptase polymerase chain reaction, and responders were compared with nonresponders, correcting for multiple comparisons. Genes that discriminated between groups on both analyses with the greatest accuracy were selected for the predictive model. Between-group differences in protein expression were confirmed with polymerase chain reaction and immunohistochemical staining.RESULTS: From 19 probes that differentiated between responders and nonresponders on microarray analyses, we identified 13 genes that were differentially expressed between responders and nonresponders on both microarray and real-time reverse-transcriptase polymerase chain reaction. A model using the genes for vascular endothelial growth factor-A, thymidylate synthase, and tissue inhibitor of metalloproteinase 3 predicted response to bevacizumab therapy with an accuracy of 96%, sensitivity of 90.9% (10/11), specificity of 100% (14/14), positive predictive value of 100% (10/10), and negative predictive value of 93.3% (14/15). The protein expression of vascular endothelial growth factor-A, thymidylate synthase, and tissue inhibitor of metalloproteinase 3 correlated with the findings of mRNA expression analyses.LIMITATIONS: Validation of the model in a different cohort of patients is necessary.CONCLUSIONS: The present predictive model based on quantitative, real-time, reverse-transcriptase polymerase chain reaction assessment of vascular endothelial growth factor-A, thymidylate synthase, and tissue inhibitor of metalloproteinase 3 may enable selection of colorectal cancer patients who would benefit from bevacizumab therapy.								5	0	3	0	5	0012-3706		WOS:000292446800020	
J	Ghaseminezhad, M. H.; Karami, A.								A novel self-organizing map (SOM) neural network for discrete groups of data clustering								APPLIED SOFT COMPUTING			11	4			3771	3778		10.1016/j.asoc.2011.02.009			JUN 2011	2011	The self-organizing map (SOM) neural network, also called Kohonen neural network, is an effective tool for analysis of multidimensional data. This network can be used for cluster analysis while preserving data structure (topology) in such a way that similar inputs (data) remain close together in the output layer of the network. However, no algorithm that can automatically cluster discrete groups of data is presented, and our simulation results show that the classic SOM algorithm cannot cluster discrete data correctly. In this paper, we present a novel SOM-based algorithm that can automatically cluster discrete groups of data using an unsupervised method. This method consists of three phases: at the first phase, an algorithm called "second winner" is performed, in which neurons in the competitive layer of the network find their initial location in the network space. At the second phase, a method called "batch learning" is employed, and at the end of this phase, training of the SOM network is finished. And finally at the third phase, data clustering is completed by removing the wrong links between neurons. Three real world data sets and an example of synthetic data are utilized to illustrate the accurateness and effectiveness of the proposed approach. (C) 2011 Elsevier B.V. All rights reserved.								5	1	0	0	6	1568-4946		WOS:000289508000046	
J	Watanabe, Toshiaki; Kobunai, Takashi; Yamamoto, Yoko; Matsuda, Keiji; Ishihara, Soichiro; Nozawa, Keijiro; Iinuma, Hisae; Konishi, Tsuyoshi; Horie, Hisanaga; Ikeuchi, Hiroki; Eshima, Kiyoshi; Muto, Tetsuichiro								Gene expression signature and response to the use of leucovorin, fluorouracil and oxaliplatin in colorectal cancer patients								CLINICAL & TRANSLATIONAL ONCOLOGY			13	6			419	425		10.1007/s12094-011-0676-z			JUN 2011	2011	Purpose FOLFOX (a combination of leucovorin, fluorouracil and oxaliplatin) has achieved substantial success in the treatment of colorectal cancer (CRC) patients. However, about half of all patients show resistance to this regimen and some develop adverse symptoms such as neurotoxicity. In order to select patients who would benefit most from this therapy, we aimed to build a predictor for the response to FOLFOX using microarray gene expression profiles of primary CRC samples.Patients and methods Forty patients who underwent surgery for primary lesions were examined. All patients had metastatic or recurrent CRC and received modifi ed FOLFOX6. Responders and nonresponders were determined according to the best observed response at the end of the first-line treatment. Gene-expression profiles of primary CRC were determined using Human Genome GeneChip arrays U133. We identified discriminating genes whose expression differed significantly between responders and nonresponders and then carried out supervised class prediction using the k-nearest-neighbour method.Results We identified 27 probes that were differentially expressed between responders and nonresponders at significant levels. Based on the expression of these genes, we constructed a FOLFOX response predictor with an overall accuracy of 92.5%. The sensitivity, specificity, positive and negative predictive values were 78.6%, 100%, 100% and 89.7%, respectively.Conclusion The present model suggests the possibility of selecting patients who would benefit from FOLFOX therapy both in the metastatic and the adjuvant setting. To our knowledge, this is the first study to establish a prediction model for the response to FOLFOX chemotherapy based on gene expression by microarray analysis.								5	0	4	0	5	1699-048X		WOS:000293299700011	
J	Shi, Lei; Ma, Xinming; Xi, Lei; Duan, Qiguo; Zhao, Jingying								Rough set and ensemble learning based semi-supervised algorithm for text classification								EXPERT SYSTEMS WITH APPLICATIONS			38	5			6300	6306		10.1016/j.eswa.2010.11.069			MAY 2011	2011	Text classification has received more and more attention due to the enormous growth of digital content available on-line. This paper investigates the design of two-class text classifiers using positive and unlabeled data only. The specialty of this problem is that there is no labeled negative example for learning, which makes traditional text classification techniques inapplicable. In this paper, a novel semi-supervised classification algorithm based on tolerance rough set and ensemble learning is proposed. Tolerance rough set theory is used to approximate concepts existed in documents and extract an initial set of negative example. Then, SVM, Rocchio and Naive Bayes algorithms are used as base classifiers to construct an ensemble classifier, which runs iteratively and exploits margins between positive and negative data to progressively improve the approximation of negative data. Thus, the class boundary eventually converges to the true boundary of the positive class in the feature space. An experimental evaluation of different methods is carried out on two common text corpora, i.e., the Reuters-21578 collection and the WebKB collection. The experimental results indicate that the proposed method achieves significant performance improvement. (c) 2010 Elsevier Ltd. All rights reserved.								5	0	0	0	5	0957-4174		WOS:000287419900188	
J	Garcia, Salvador; Derrac, Joaquin; Luengo, Julian; Carmona, Cristobal J.; Herrera, Francisco				Herrera, Francisco/C-6856-2008	Herrera, Francisco/0000-0002-7283-312X			Evolutionary selection of hyperrectangles in nested generalized exemplar learning								APPLIED SOFT COMPUTING			11	3			3032	3045		10.1016/j.asoc.2010.11.030			APR 2011	2011	The nested generalized exemplar theory accomplishes learning by storing objects in Euclidean n-space, as hyperrectangles. Classification of new data is performed by computing their distance to the nearest "generalized exemplar" or hyperrectangle. This learning method allows the combination of the distance-based classification with the axis-parallel rectangle representation employed in most of the rule-learning systems. In this paper, we propose the use of evolutionary algorithms to select the most influential hyperrectangles to obtain accurate and simple models in classification tasks. The proposal has been compared with the most representative models based on hyperrectangle learning; such as the BNGE, RISE, INNER, and SIA genetics based learning approach. Our approach is also very competitive with respect to classical rule induction algorithms such as C4.5Rules and RIPPER. The results have been contrasted through non-parametric statistical tests over multiple data sets and they indicate that our approach outperforms them in terms of accuracy requiring a lower number of hyperrectangles to be stored, thus obtaining simpler models than previous NGE approaches. Larger data sets have also been tackled with promising outcomes. (C) 2010 Elsevier B. V. All rights reserved.								5	0	0	0	5	1568-4946		WOS:000287479200009	
S	Moshkov, Mikhail; Zielosko, Beata								Combinatorial Machine Learning: A Rough Set Approach								COMBINATORIAL MACHINE LEARNING: A ROUGH SET APPROACH	Studies in Computational Intelligence		360				1	178		10.1007/978-3-642-20995-6			2011	2011									5	0	0	0	5	1860-949X	978-3-642-20994-9	WOS:000293120700001	
J	Shrivastava, Saurabh; Singh, Manu Pratap								Performance evaluation of feed-forward neural network with soft computing techniques for hand written English alphabets								APPLIED SOFT COMPUTING			11	1			1156	1182		10.1016/j.asoc.2010.02.015			JAN 2011	2011	This paper describes the performance evaluation for the feed forward neural network with three different soft computing techniques to recognition of hand written English alphabets. Evolutionary algorithms for the hybrid neural network are showing the numerous potential in the field of pattern recognition. We have taken five trials and two networks of each of the algorithm: back propagation, Evolutionary algorithm, and Hybrid Evolutionary algorithm respectively. These algorithms have been taken the definite lead on the conventional approaches of neural network for pattern recognition.It has been analyzed that the feed forward neural network by two Evolutionary algorithms makes better generalization accuracy in character recognition problems. The problem of not convergence the weight in conventional backpropagation has also eliminated by using the soft computing techniques. It has been observed that, there are more than one converge weight matrix in character recognition for every training set. The results of the experiments show that the hybrid evolutionary algorithm can solve challenging problem most reliably and efficiently. These algorithms have also been compared on the basis of time and space complexity for the training set. (C) 2010 Elsevier B.V. All rights reserved.								5	0	0	0	5	1568-4946		WOS:000281591300116	
J	Tallon-Ballesteros, Antonio J.; Hervas-Martinez, Cesar								A two-stage algorithm in evolutionary product unit neural networks for classification								EXPERT SYSTEMS WITH APPLICATIONS			38	1			743	754		10.1016/j.eswa.2010.07.028			JAN 2011	2011	This paper presents a procedure to add broader diversity at the beginning of the evolutionary process. It consists of creating two initial populations with different parameter settings, evolving them for a small number of generations, selecting the best individuals from each population in the same proportion and combining them to constitute a new initial population. At this point the main loop of an evolutionary algorithm is applied to the new population. The results show that our proposal considerably improves both the efficiency of previous methodologies and also, significantly, their efficacy in most of the data sets. We have carried out our experimentation on twelve data sets from the UCI repository and two complex real-world problems which differ in their number of instances, features and classes. (C) 2010 Elsevier Ltd. All rights reserved.								5	0	0	0	5	0957-4174		WOS:000282607800084	
J	Haehnke, Volker; Rupp, Matthias; Krier, Mireille; Rippmann, Friedrich; Schneider, Gisbert								Pharmacophore Alignment Search Tool: Influence of Canonical Atom Labeling on Similarity Searching								JOURNAL OF COMPUTATIONAL CHEMISTRY			31	15			2810	2826		10.1002/jcc.21574			NOV 30 2010	2010	Previously, (Hahnke et al., J Comput Chem 2009, 30, 761) we presented the Pharmacophore Alignment Search Tool (PhAST), a ligand-based virtual screening technique representing molecules as strings coding pharmacophoric features and comparing them by global pairwise sequence alignment. To guarantee unambiguity during the reduction of two-dimensional molecular graphs to one-dimensional strings, PhAST employs a graph canonization step. Here, we present the results of the comparison of 11 different algorithms for graph canonization with respect to their impact on virtual screening. Retrospective screenings of a drug-like data set were evaluated using the BED-ROC metric, which yielded averaged values between 0.4 and 0.14 for the best-performing and worst-performing canonization technique. We compared five scoring schemes for the alignments and found preferred combinations of canonization algorithms and scoring functions. Finally, we introduce a performance index that helps prioritize canonization approaches without the need for extensive retrospective evaluation. (C) 2010 Wiley Periodicals, Inc. J Comput Chem 31: 2810-2826, 2010								5	0	2	0	5	0192-8651		WOS:000282309900013	
J	Roh, Seok-Beom; Ahn, Tae-Chon; Pedrycz, Witold								The design methodology of radial basis function neural networks based on fuzzy K-nearest neighbors approach								FUZZY SETS AND SYSTEMS			161	13			1803	1822		10.1016/j.fss.2009.10.014			JUL 1 2010	2010	Various approaches to partitioning of high-dimensional input space have been studied with the intent of developing homogeneous clusters formed over input and output spaces of variables encountered in system modeling. In this study, we propose a new design methodology of a fuzzy model where the input space is partitioned by making use of sonic classification algorithm, especially, fuzzy K-nearest neighbors (K-NN) classifier being guided by some auxiliary information granules formed in the output space. This classifier being regarded in the context of this design as a supervision mechanism is used to capture the distribution of data over the output space. This type of supervision is beneficial when developing the structure in the input space. It is demonstrated that data involved in a partition constructed by the fuzzy K-NN method realized in the input space show a high level of homogeneity with regard to the data present in the output space. This enhances the performance of the fuzzy rule-based model whose premises in the rules involve partitions formed by the fuzzy K-NN. The design is illustrated with the aid of numeric examples that also provide a detailed insight into the performance of the fuzzy models and quantify several crucial design issues. (C) 2009 Elsevier B.V. All rights reserved.								5	0	0	0	5	0165-0114		WOS:000277867500004	
J	Wei, Xuelian; Li, Ker-Chau								Exploring the within- and between-class correlation distributions for tumor classification								PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			107	15			6737	6742		10.1073/pnas.0910140107			APR 13 2010	2010	To many biomedical researchers, effective tumor classification methods such as the support vector machine often appear like a black box not only because the procedures are complex but also because the required specifications, such as the choice of a kernel function, suffer from a clear guidance either mathematically or biologically. As commonly observed, samples within the same tumor class tend to be more similar in gene expression than samples from different tumor classes. But can this well-received observation lead to a useful procedure of classification and prediction? To address this issue, we first conceived a statistical framework and derived general conditions to serve as the theoretical foundation that supported the aforementioned empirical observation. Then we constructed a classification procedure that fully utilized the information obtained by comparing the distributions of within-class correlations with between-class correlations via Kullback-Leibler divergence. We compared our approach with many machine-learning techniques by applying to 22 binary- and multiclass gene-expression datasets involving human cancers. The results showed that our method performed as efficiently as support vector machine and Naive Bayesian and outperformed other learning methods (decision trees, linear discriminate analysis, and k-nearest neighbor). In addition, we conducted a simulation study and showed that our method would be more effective if the arriving new samples are subject to the often-encountered baseline shift or increased noise level problems. Our method can be extended for general classification problems when only the similarity scores between samples are available.								5	0	3	0	5	0027-8424		WOS:000276642100034	
J	Maas, Marnix C.; van der Laan, D. J. (Jan); van Eijk, Carel W. E.; Schaart, Dennis R.; Beekman, Freek J.; Bruyndonckx, Peter; Lemaitre, Cedric								Model of the point spread function of monolithic scintillator PET detectors for perpendicular incidence								MEDICAL PHYSICS			37	4			1904	1913		10.1118/1.3355889			APR 2010	2010	Methods: A PSF model was developed that essentially consists of two convolved components, one accounting for the spatial distribution of the energy deposited by annihilation photons within the crystal, and the other for the influences of statistical signal fluctuations and electronic noise. The model was validated through comparison with spatial resolution measurements on a detector consisting of an LYSO:Ce(3+) crystal read out by two APD arrays.Results: The model is shown to describe the measured detector spatial response well at the noise levels found in the experiments. In addition, it is demonstrated how the model can be used to correct the measured spatial response for the influence of the finite diameter of the annihilation photon beam used in the experiments, thus obtaining an estimate of the intrinsic detector PSF.Conclusions: Despite its simplicity, the proposed model is an accurate tool for analyzing the detector PSF of monolithic scintillator detectors and can be used to estimate the intrinsic detector PSF from the measured one.								5	0	3	0	5	0094-2405		WOS:000276211200055	
J	Toyama, Jun; Kudo, Mineichi; Imai, Hideyuki				Kudo, Mineichi/B-9973-2011				Probably correct k-nearest neighbor search in high dimensions								PATTERN RECOGNITION			43	4			1361	1372		10.1016/j.patcog.2009.09.026			APR 2010	2010	A novel approach for k-nearest neighbor (k-NN) searching with Euclidean metric is described. It is well known that many sophisticated algorithms cannot beat the brute-force algorithm when the dimensionality is high. In this study, a probably correct approach, in which the correct set of k-nearest neighbors is obtained in high probability, is proposed for greatly reducing the searching time. We exploit the marginal distribution of the k th nearest neighbors in low dimensions, which is estimated from the stored data (an empirical percentile approach). We analyze the basic nature of the marginal distribution and show the advantage of the implemented algorithm, which is a probabilistic variant of the partial distance searching. Its query time is sublinear in data size n, that is, O(mn delta) with S=o(1) in n and delta <= 1, for any fixed dimension m. (C) 2009 Elsevier Ltd. All rights reserved.								5	1	1	0	6	0031-3203		WOS:000274954100014	
J	Gertheiss, Jan; Tutz, Gerhard								Feature selection and weighting by nearest neighbor ensembles								CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS			99	1			30	38		10.1016/j.chemolab.2009.07.004			NOV 15 2009	2009	In the field of statistical discrimination nearest neighbor methods are a well known, quite simple but successful nonparametric classification tool If the number of predictors increases, however, predictive power normally deteriorates. In general. if some covariates are assumed to be noise variables. variable selection is a promising approach. The paper's main focus is on the development and evaluation of a nearest neighbor ensemble with implicit variable selection. In contrast to other nearest neighbor approaches we are not primarily interested in classification, but in estimating the (posterior) class probabilities. In simulation studies and for real world data the proposed nearest neighbor ensemble is compared to an extended forward/backward variable selection procedure for nearest neighbor classifiers, and some alternative well established classification tools (that offer probability estimates as well). Despite its simple structure, the proposed method's performance is quite good - especially if relevant covariates can be separated from noise variables. Another advantage of the presented ensemble is the easy identification of interactions that are usually hard to detect. So not simply variable selection but rather some kind of feature selection is performed. (C) 2009 Elsevier B.V. All rights reserved								5	0	0	0	5	0169-7439		WOS:000271254400004	
J	Chuang, Li-Yeh; Yang, Cheng-San; Li, Jung-Chike; Yang, Cheng-Hong				Chuang, Li-Yeh/E-5005-2011				Chaotic Genetic Algorithm for Gene Selection and Classification Problems								OMICS-A JOURNAL OF INTEGRATIVE BIOLOGY			13	5			407	420		10.1089/omi.2009.0007			OCT 2009	2009	Pattern recognition techniques suffer from a well-known curse, the dimensionality problem. The microarray data classification problem is a classical complex pattern recognition problem. Selecting relevant genes from microarray data poses a formidable challenge to researchers due to the high-dimensionality of features, multiclass categories being involved, and the usually small sample size. The goal of feature (gene) selection is to select those subsets of differentially expressed genes that are potentially relevant for distinguishing the sample classes. In this paper, information gain and chaotic genetic algorithm are proposed for the selection of relevant genes, and a K-nearest neighbor with the leave-one-out crossvalidation method serves as a classifier. The chaotic genetic algorithm is modified by using the chaotic mutation operator to increase the population diversity. The enhanced population diversity expands the GA's search ability. The proposed approach is tested on 10 microarray data sets from the literature. The experimental results show that the proposed method not only effectively reduced the number of gene expression levels, but also achieved lower classification error rates than other methods.								5	0	3	0	5	1536-2310		WOS:000270328100005	
J	Babu, V. Suresh; Viswanath, P.								Rough-fuzzy weighted k-nearest leader classifier for large data sets								PATTERN RECOGNITION			42	9			1719	1731		10.1016/j.patcog.2008.11.021			SEP 2009	2009	A leaders set which is derived using the leaders clustering method can be used in place of a large training set to reduce the computational burden of a classifier. Recently, a fast and efficient leader-based classifier called weighted k-nearest leader-based classifier is shown by us to be an efficient and faster classifier. But, there exist some uncertainty while calculating the relative importance (weight) of the prototypes. This paper proposes a generalization over the earlier proposed k-nearest leader-based classifier where a novel soft computing approach is used to resolve the uncertainty. Combined principles of rough set theory and fuzzy set theory are used to analyze the proposed method. The proposed method called rough-fuzzy weighted k-nearest leader classifier (RF-wk-NLC) uses a two level hierarchy of prototypes along with their relative importance. RF-wk-NLC is shown by using some standard data sets to have improved performance and is compared with the earlier related methods. (C)2008 Elsevier Ltd. All rights reserved.								5	0	0	0	5	0031-3203		WOS:000267089000001	
J	Diamantini, Claudia; Potena, Domenico								Bayes Vector Quantizer for Class-Imbalance Problem								IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			21	5			638	651		10.1109/TKDE.2008.187			MAY 2009	2009	The class-imbalance problem is the problem of learning a classification rule from data that are skewed in favor of one class. On these data sets, traditional learning techniques tend to overlook the less numerous classes, at the advantage of the majority class. However, the minority class is often the most interesting one for the task at hand. For this reason, the class-imbalance problem has received increasing attention in the last few years. In the present paper, we point the attention of the reader to a learning algorithm for the minimization of the average misclassification risk. In contrast to some popular class-imbalance learning methods, this method has its roots in statistical decision theory. A particular interesting characteristic is that when class distributions are unknown, the method can work by resorting to stochastic gradient algorithm. We study the behavior of this algorithm on imbalanced data sets, demonstrating that this principled approach allows to obtain better classification performances compared to the principal methods proposed in the literature.								5	1	1	0	6	1041-4347		WOS:000264300600003	
J	Zeng, Yong; Yang, Yupu; Zhao, Liang								Nonparametric classification based on local mean and class statistics								EXPERT SYSTEMS WITH APPLICATIONS			36	4			8443	8448		10.1016/j.eswa.2008.10.041			MAY 2009	2009	The k-nearest neighbor classification rule (k-NNR) is a very simple, yet powerful nonparametric classification method. As a variant of the k-NNR, a nonparametric classification method based on the local mean vector has achieved good classification performance. In pattern classification, the sample mean and sample covariance are the most important statistics related to class discriminatory information. In this paper, a new variant of the k-NNR, a nonparametric classification method based on the local mean vector and class statistics has been proposed. Not only the local information of the k nearest neighbors of the unclassified pattern in each individual class but also the global knowledge of samples in each individual class are taken into account in this new classification method. The proposed classification method is compared with the k-NNR, and the local mean-based nonparametric classification in terms of the classification error rate on the unknown patterns. Experimental results confirm the validity of this new classification approach. (C) 2008 Elsevier Ltd. All rights reserved.								5	0	0	0	5	0957-4174		WOS:000264528600126	
J	Chen, Shyi-Ming; Shie, Jen-Da								Fuzzy classification systems based on fuzzy information gain measures								EXPERT SYSTEMS WITH APPLICATIONS			36	3			4517	4522		10.1016/j.eswa.2008.05.020			APR 2009	2009	In this paper, we present a new method for handling classification problems using a new fuzzy information gain measure. Based on the proposed fuzzy information gain measure, we propose an algorithm for constructing membership functions, calculating the class degree of each subset of training instances with respect to each class and Calculating the fuzzy entropy of each subset of training instances. Based on the constructed membership function of each fuzzy set of each feature, the obtained class degree of each subset of training instances with respect to each class and the obtained fuzzy entropy of each subset of training instances, we propose an evaluating function for classifying testing instances. The proposed method gets higher average classification accuracy rates than the methods presented in [John, G. H., & Langley. P. (1995). Estimating continuous distributions in Bayesian classifiers. In Proceedings of the 11th conference oil uncertainty in artificial intelligence, Montreal, Canada (pp. 338-345): Platt, J. C. (1999). Using analytic QP and sparseness to speed training of support vector machines. In Proceedings of the 13th annual conference on neural information processing systems, Denver, Colorado (pp. 557-563); Quinlan, J. R. (1993). C4.5: Programs for machine learning. San Francisco: Morgan Kaufmann]. (c) 2008 Elsevier Ltd. All rights reserved.								5	2	1	0	7	0957-4174		WOS:000263584100043	
J	Orozco-Alzate, Mauricio; Duin, Robert P. W.; Castellanos-Dominguez, German								A generalization of dissimilarity representations using feature lines and feature planes								PATTERN RECOGNITION LETTERS			30	3			242	254		10.1016/j.patrec.2008.09.010			FEB 1 2009	2009	Even though, under representational restrictions, the nearest feature rules and the dissimilarity-based classifiers are feasible alternatives to the nearest neighbor method; individually, they may not be sufficiently powerful if a very small set of prototypes is required, e.g. when it is computationally expensive to deal with larger sets of prototypes. In this paper, we show that combining both strategies, taking advantage of their individual properties, provides an improvement, particularly for correlated data sets. The combined strategy consists in deriving an enriched (generalized) dissimilarity representation by using the nearest feature rules, namely feature lines and feature planes. On top of that enriched representation, Bayesian classifiers can be constructed in order to obtain a good generalization. (C) 2008 Elsevier B.V. All rights reserved.								5	0	0	0	5	0167-8655		WOS:000263045200008	
B	Ballabio, Davide; Todeschini, Roberto						Sun, DW		Multivariate Classification for Qualitative Analysis								INFRARED SPECTROSCOPY FOR FOOD QUALITY ANALYSIS AND CONTROL							83	104		10.1016/B978-0-12-374136-3.00004-3			2009	2009									5	0	3	0	5		9780-0-80-92087-0	WOS:000316686500005	
J	Halder, Anindya; Ghosh, Ashish; Ghosh, Susmita								Aggregation Pheromone Density Based Pattern Classification								FUNDAMENTA INFORMATICAE			92	4			345	362		10.3233/FI-2009-78			2009	2009	The study of ant colonies behavior and their self-organizing capabilities is of interest to machine learning community, because it provides models of distributed adaptive organization which are useful to solve difficult optimization and classification problems among others. Social insects like ants, bees deposit pheromone (a type of chemical) in order to communicate between the members of their community. Pheromone, that causes clumping behavior in a species and brings individuals into a closer proximity, is called aggregation pheromone. This article presents a new algorithm (called, APC) for pattern classification based on this property of aggregation pheromone found in natural behavior of real ants. Here each data pattern is considered as an ant, and the training patterns (ants) form several groups or colonies depending on the number of classes present in the data set. A new test pattern (ant) will move along the direction where average aggregation pheromone density (at the location of the new ant) formed due to each colony of ants is higher and hence eventually it will join that colony. Thus each individual test pattern (ant) will finally join a particular colony. The proposed algorithm is evaluated with a number of benchmark data sets as well as various kinds of artificially generated data sets using three evaluation measures. Results are compared with four other well known conventional classification techniques. Experimental results show the potentiality of the proposed algorithm in terms of all the evaluation measures compared to other algorithms.								5	0	2	0	5	0169-2968		WOS:000267901400002	
B	Wu, Chung-Hsien; Yeh, Jui-Feng; Chuang, Ze-Jing						Tao, J; Tan, T		Emotion Perception and Recognition from Speech								AFFECTIVE INFORMATION PROCESSING							93	110		10.1007/978-1-84800-306-4_6			2009	2009	With the increasing role of speech interfaces in human-computer interaction applications, automatically recognizing emotions from human speech becomes more and more important. This chapter begins by introducing the correlations between basic speech features such as pitch, intensity, formants, MFCC, and so on, and the emotions. Several recognition methods are then described to illustrate the performance of the previously proposed models, including support vector machine (SVM), K-nearest neighbors (KNN), neural networks, and the like.To give a more practical description of all emotion recognition procedure, a new approach to emotion recognition is provided as a case study. In this case study, the Intonation Groups (IGs) of the input speech signals are first defined and extracted for C feature extraction. With the assumption of linear mapping between feature spaces in different emotional states, a feature compensation approach is proposed to characterize the feature space with better discriminability among emotional states. The compensation vector with respect to each emotional state is estimated using the Minimum Classification Err or (MCE) algorithm. The IG-based feature vectors compensated by the compensation vectors are used to train the Gaussian Mixture Models (GMMs) for each emotional state. The emotional state with the GMM having the maximal likelihood ratio is determined as the emotion state output.				1st International Conference on Affective Computing and Intelligent Interaction	OCT 22-24, 2005	Nokia Ltd; Siemens Ltd; Int Speech Commun Assoc; Natl Nat Sci Fdn China; Chinese Assoc Automat; China Soc Image & Graph; China Comp Federat; Natl High-Tech Res & Dev Program	Beijing, PEOPLES R CHINA	5	0	0	0	5		978-1-84800-305-7	WOS:000264082400006	
J	Kagie, Martijn; van Wezel, Michiel; Groenen, Patrick J. F.				Groenen, Patrick/D-3667-2009	Groenen, Patrick/0000-0001-6683-8971			A graphical shopping interface based on product attributes								DECISION SUPPORT SYSTEMS			46	1			265	276		10.1016/j.dss.2008.06.011			DEC 2008	2008	Most recommender systems present recommended products in lists to the user. By doing so, much information is lost about the mutual similarity between recommended products. We propose to represent the mutual similarities of the recommended products in a two dimensional map, where similar products are located close to each other and dissimilar products far apart. As a dissimilarity measure we use an adaptation of Gower's similarity coefficient based on the attributes of a product. Two recommender systems are developed that use this approach. The first, the graphical recommender system, uses a description given by the user in terms of product attributes of an ideal product. The second system, the graphical shopping interface, allows the user to navigate towards the product she wants. We show a prototype application of both systems to MP3-players. (c) 2008 Elsevier B.V. All rights reserved.								5	0	0	0	5	0167-9236		WOS:000263706000021	
J	Cointault, F.; Guerin, D.; Guillemin, J-P.; Chopinet, B.								In-field Triticum aestivum ear counting using colour-texture image analysis								NEW ZEALAND JOURNAL OF CROP AND HORTICULTURAL SCIENCE			36	2			117	130					JUN 2008	2008	A colour and texture image analysis method based on the determination of a hybrid space was developed for a feasibility study for the (semi-)automatic counting of Triticum aestivum wheat ears to simplify manual counting. To detect ears, five textural and statistic features, and colour analyses were both used to give a new representation of the images within a specific space (hybrid space). This new representation was constructed with a priori knowledge about the images (especially the number of classes and training points), providing better recognition than in the standard RGB space (Red/Green/Blue). Classical methods of image segmentation and classification, combined with morphological information about wheat ears, were then applied to the new images to assist counting. Only 20 images were tested and classification accuracy ranged from 73% to 85%. The counting information, which needs to be validated on numerous images, will be in future combined with grain counting per ear and thousand-seed weight to obtain an estimation of wheat yields. The resulting information could prove to be relevant, for example, to allow French cooperatives to organise their harvest.								5	0	2	0	5	0114-0671		WOS:000258173800004	
J	Tarakanov, Alexander O.								Immunocomputing for intelligent intrusion detection								IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE			3	2			22	30		10.1109/MCI.2008.919069			MAY 2008	2008	Based on immunocomputing, this paper describes an approach to intrusion detection. The approach includes both low-level signal processing (feature extraction) and high-level (intelligent) pattern recognition. The key model is the formal immune network (FIN) including apoptosis (programmed cell death) and immunization, both controlled by cytokines (messenger proteins). Such FIN can be formed from the network traffic signals using discrete tree transforms, singular value decomposition, and the proposed index of inseparability as a measure of quality of FIN. Recent results suggest that the approach outperforms (by training time and accuracy) state-of-the-art approaches of computational intelligence.								5	4	0	0	9	1556-603X		WOS:000258768000006	
S	Remus, Jeremiah J.; Morton, Kenneth D.; Torrione, Peter A.; Tantum, Stacy L.; Collins, Leslie A.			IEEE	Tantum, Stacy/E-1830-2011				Comparison of a distance-based likelihood ratio test and k-nearest neighbor classification methods								2008 IEEE WORKSHOP ON MACHINE LEARNING FOR SIGNAL PROCESSING	IEEE Workshop on Machine Learning for Signal Processing						362	367		10.1109/MLSP.2008.4685507			2008	2008	Several studies of the k-nearest neighbor (KNN) classifier have proposed the use of non-uniform weighting on the k neighbors. It has been suggested that the distance to each neighbor can be used to calculate the individual weights in a weighted KNN approach; however, a consensus has not yet been reached on the best method or framework for calculating weights using the distances. In this paper, a distance likelihood ratio test will be discussed and evaluated using simulated data. The distance likelihood ratio test (DLRT) shares several characteristics with the distance-weighted k-nearest neighbor methods but approaches the use of distance from a different perspective. Results illustrate the ability of the distance likelihood ratio test to approximate the likelihood ratio and compare the DLRT to two other k-neighborhood classification rules that utilize distance-weigbting. The DLRT performs favorably in comparisons of the classification performance using the simulated data and provides an alternative non-parametric classification method for consideration when designing a distance-weighted KNN classification rule.				IEEE Workshop on Machine Learning for Signal Processing	OCT 16-19, 2008	IEEE Signal Processing Soc; IEEE	Cancun, MEXICO	5	0	0	0	5	1551-2541	978-1-4244-2375-0	WOS:000266687900062	
J	Tan, Shing Chiang; Rao, M. V. C.; Lim, Chee Peng								Fuzzy ARTMAP dynamic decay adjustment: An improved fuzzy ARTMAP model with a conflict resolving facility								APPLIED SOFT COMPUTING			8	1			543	554		10.1016/j.asoc.2007.03.006			JAN 2008	2008	This paper presents a hybrid neural network classifier of fuzzy ARTMAP (FAM) and the dynamic decay adjustment (DDA) algorithm. The proposed FAMDDA model is a conflict-resolving classifier that can perform stable and incremental learning while settling overlapping of hyper-rectangular prototypes of different classes in minimizing misclassification rates. The performance of FAMDDA is evaluated using a number of benchmark data sets. The results are analyzed and compared with those from FAM and a number of machine learning classifiers. The outcomes show that FAMDDA has a better generalization capability than FAM, and its performance is comparable with those from other classifiers. The effectiveness of FAMDDA is also demonstrated in an application pertaining to condition monitoring of a circulating water system in a power generation station. Implications on the effectiveness of FAMDDA from the application point of view are discussed. (C) 2007 Elsevier B. V. All rights reserved.								5	0	0	0	5	1568-4946		WOS:000249508500047	
J	Ghosh, Anil Kumar; Bose, Smarajit								Feature extraction for classification using statistical networks								INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			21	7			1103	1126		10.1142/S0218001407005855			NOV 2007	2007	In a classification problem, quite often the dimension of the measurement vector is large. Some of these measurements may not be important for separating the classes. Removal of these measurement variables not only reduces the computational cost but also leads to better understanding of class separability. There are some methods in the existing literature for reducing the dimensionality of a classification problem without losing much of the separability information. However, these dimension reduction procedures usually work well for linear classifiers. In the case where competing classes are not linearly separable, one has to look for ideal "features" which could be some transformations of one or more measurements. In this paper, we make an attempt to tackle both, the problems of dimension reduction and feature extraction, by considering a projection pursuit regression model. The single hidden layer perceptron model and some other popular models can be viewed as special cases of this model. An iterative algorithm based on backfitting is proposed to select the features dynamically, and cross-validation method is used to select the ideal number of features. We carry out an extensive simulation study to show the effectiveness of this fully automatic method.								5	0	0	0	5	0218-0014		WOS:000251720000001	
J	Morrison, Donn; De Silva, Liyanage C.								Voting ensembles for spoken affect classification								JOURNAL OF NETWORK AND COMPUTER APPLICATIONS			30	4			1356	1365		10.1016/j.jnca.2006.09.005			NOV 2007	2007	Affect or emotion classification from speech has much to benefit from ensemble classification methods. In this paper we apply a simple voting mechanism to an ensemble of classifiers and attain a modest performance increase compared to the individual classifiers. A natural emotional speech database was compiled from 11 speakers. Listener-judges were used to validate the emotional content of the speech. Thirty-eight prosody-based features correlating characteristics of speech with emotional states were extracted from the data. A classifier ensemble was designed using a multi-layer perceptron, support vector machine, K* instance-based learner, K-nearest neighbour, and random forest of decision trees. A simple voting scheme determined the most popular prediction. The accuracy of the ensemble is compared with the accuracies of the individual classifiers. (c) 2006 Elsevier Ltd. All rights reserved.				3rd International Conference on Information Technology and Applications	JUL 04-07, 2005	IEEE NSW Sect; Univ Technol, FIT; Univ Technol, IICT	Sydney, AUSTRALIA	5	2	0	0	7	1084-8045		WOS:000249949500009	
J	Omachi, Shinichiro; Omachi, Masako; Aso, Hirotomo								An approximation method of the quadratic discriminant function and its application to estimation of high-dimensional distribution								IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS			E90D	8			1160	1167		10.1093/ietisy/e90-d.8.1160			AUG 2007	2007	In statistical pattern recognition, it is important to estimate the distribution of patterns precisely to achieve high recognition accuracy. In general, precise estimation of the parameters of the distribution requires a great number of sample patterns, especially when the feature vector obtained from the pattern is high-dimensional. For some pattern recognition problems, such as face recognition or character recognition, very high-dimensional feature vectors are necessary and there are always not enough sample patterns for estimating the parameters. In this paper, we focus on estimating the distribution of high-dimensional feature vectors with small number of sample patterns. First, we define a function, called simplified quadratic discriminant function (SQDF). SQDF can be estimated with small number of sample patterns and approximates the quadratic discriminant function (QDF). SQDF has fewer parameters and requires less computational time than QDF. The effectiveness of SQDF is confirmed by three types of experiments. Next, as an application of SQDF, we propose an algorithm for estimating the parameters of the normal mixture. The proposed algorithm is applied to face recognition and character recognition problems which require high-dimensional feature vectors.								5	0	0	0	5	0916-8532		WOS:000248934000005	
J	Srdoc, Alira; Bratko, Ivan; Sluga, Alojzij				Sluga, Alojzij/A-7161-2008				Machine learning applied to quality management - A study in ship repair domain								COMPUTERS IN INDUSTRY			58	5			464	473		10.1016/j.compind.2006.09.013			JUN 2007	2007	The awareness about the importance of knowledge within the quality management community is increasing. For example, the Malcolm Baldrige Criteria for Performance Excellence recently included knowledge management into one of its categories. However, the emphasis in research related to knowledge management is mostly on knowledge creation and dissemination, and not knowledge formalisation process. On the other hand, identifying the expert knowledge and experience as crucial for the output quality, especially in dynamic industries with high share of incomplete and unreliable information such as ship repair, this paper argues how important it is to have such knowledge formalised. The paper demonstrates by example of delivery time estimate how for that purpose the deep quality concept (DQC)-a novel knowledge-focused quality management framework, and machine learning methodology could be effectively used. In the concluding part of the paper, the accuracy of the obtained prediction models is analysed, and the chosen model is discussed. The research indicates that standardisation of problem domain notions and expertly designed databases with possible interface to machine learning algorithms need to be considered as an integral part of any quality management system in the future, in addition to conventional quality management concepts. (C) 2006 Elsevier B.V. All rights reserved.								5	0	1	0	5	0166-3615		WOS:000246549100008	
J	Tripathy, M.; Maheshwari, R. P.; Verma, H. K.								Application of probabilistic neural network for differential relaying of power transformer								IET GENERATION TRANSMISSION & DISTRIBUTION			1	2			218	222		10.1049/iet-gtd:20050273			MAR 2007	2007	Investigations towards the applicability of probabilistic neural networks (PNNs) as core classifiers to discriminate between magnetising inrush and internal fault of power transformer are made. An algorithm has been developed around the theme of conventional differential protection of transformer. It makes use of the ratio of the voltage-to-frequency and the amplitude of differential current for the detection of the operating condition of the transformer. The PNN has a significant advantage in terms of a much faster learning capability because it is constructed with a single pass of exemplar pattern set and without any iteration for weight adaptation. For the evaluation of the developed algorithm, transformer modelling and simulation of fault are carried out in power system computer-aided designing PSCAD/EMTDC. The operating condition detection algorithm is implemented in MATLAB.								5	0	0	0	5	1751-8687		WOS:000246464500003	
J	Bankert, Richard L.; Wade, Robert H.								Optimization of an instance-based GOES cloud classification algorithm								JOURNAL OF APPLIED METEOROLOGY AND CLIMATOLOGY			46	1			36	49		10.1175/JAM2451.1			JAN 22 2007	2007	An instance-based nearest-neighbor algorithm was developed for a Geostationary Operational Environmental Satellite ( GOES) cloud classifier. Expert-labeled samples serve as the training sets for the various GOES image classification scenes. The initial implementation of the classifier using the complete set of available training samples has proven to be an inefficient method for real-time image classifications, requiring long computational run times and significant computer resources. A variety of training-set reduction methods were examined to find smaller training sets that provide quicker classifier run times with minimal reduction in classifier testing set accuracy. General differences within real-time image classifications as a result of using the various reduction methods were also analyzed. The fast condensed nearest-neighbor (FCNN)method reduced the size of the individual training sets by 68.3% ( fourfold cross-validation testing average) while the average overall accuracy of the testing sets decreased by only 4.1%. Training sets resulting from these reduction methods were also applied within a real-time classifier using a one-nearest-neighbor subroutine. Using the FCNN-reduced set, the subroutine run time on a 30 degrees latitude x 30 degrees longitude image (GOES-10 daytime) with 11 289 600 total pixels decreased by an average of 60.7%.								5	0	0	0	5	1558-8424		WOS:000243638900004	
S	Vanderlooy, Stijn; van der Maaten, Laurens; Sprinkhuizen-Kuyper, Ida						Perner, P		Off-line learning with transductive confidence machines: An empirical evaluation								Machine Learning and Data Mining in Pattern Recognition, Proceedings	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		4571				310	323					2007	2007	The recently introduced transductive confidence machines (TCMs) framework allows to extend classifiers such that they satisfy the calibration property. This means that the error rate can be set by the user prior to classification. An analytical proof of the calibration property was given for TCMs applied in the on-line learning setting. However, the nature of this learning setting restricts the applicability of TCMs. In this paper we provide strong empirical evidence that the calibration property also holds in the off-line learning setting. Our results extend the range of applications in which TCMs can be applied. We may conclude that TCMs are appropriate in virtually any application domain.				5th International Conference on Machine Learning and Data Mining in Pattern Recognition	JUL 18-20, 2007		Leipzig, GERMANY	5	0	0	0	5	0302-9743	978-3-540-73498-7	WOS:000248523200023	
J	Huang, Chi-Chun; Lee, Hahn-Ming								An instance-based learning approach based on grey relational structure								APPLIED INTELLIGENCE			25	3			243	251		10.1007/s10489-006-0105-0			DEC 2006	2006	In instance-based learning, the 'nearness' between two instances-used for pattern classification-is generally determined by some similarity functions, such as the Euclidean or Value Difference Metric (VDM). However, Euclidean-like similarity functions are normally only suitable for domains with numeric attributes. The VDM metrics are mainly applicable to domains with symbolic attributes, and their complexity increases with the number of classes in a specific application domain. This paper proposes an instance-based learning approach to alleviate these shortcomings. Grey relational analysis is used to precisely describe the entire relational structure of all instances in a specific domain. By using the grey relational structure, new instances can be classified with high accuracy. Moreover, the total number of classes in a specific domain does not affect the complexity of the proposed approach. Forty classification problems are used for performance comparison. Experimental results show that the proposed approach yields higher performance over other methods that adopt one of the above similarity functions or both. Meanwhile, the proposed method can yield higher performance, compared to some other classification algorithms.								5	0	0	0	5	0924-669X		WOS:000241796600001	
J	Joseph, A.; Fenton, N. E.; Neil, M.								Predicting football results using Bayesian nets and other machine learning techniques								KNOWLEDGE-BASED SYSTEMS			19	7			544	553		10.1016/j.knosys.2006.04.011			NOV 2006	2006	Bayesian networks (BNs) provide a means for representing, displaying, and making available in a usable form the knowledge of experts in a given field. In this paper, we look at the performance of an expert constructed BN compared with other machine learning (ML) techniques for predicting the outcome (win, lose, or draw) of matches played by Tottenham Hotspur Football Club. The period under study was 1995-1997 - the expert BN was constructed at the start of that period, based almost exclusively on subjective judgement. Our objective was to determine retrospectively the comparative accuracy of the expert BN compared to some alternative ML models that were built using data from the two-year period. The additional ML techniques considered were: MC4, a decision tree learner; Naive Bayesian learner; Data Driven Bayesian (a BN whose structure and node probability tables are learnt entirely from data); and a K-nearest neighbour learner. The results show that the expert BN is generally superior to the other techniques for this domain in predictive accuracy. The results are even more impressive for BNs given that, in a number of key respects, the study assumptions place them at a disadvantage. For example, we have assumed that the BN prediction is 'incorrect' if a BN predicts more than one outcome as equally most likely (whereas, in fact, such a prediction would prove valuable to somebody who could place an 'each way' bet on the outcome). Although the expert BN has now long been irrelevant (since it contains variables relating to key players who have retired or left the club) the results here tend to confirm the excellent potential of BNs when they are built by a reliable domain expert. The ability to provide accurate predictions without requiring much learning data are an obvious bonus in any domain where data are scarce. Moreover, the BN was relatively simple for the expert to build and its structure could be used again in this and similar types of problems. (c) 2006 Elsevier B.V. All rights reserved.								5	0	0	0	5	0950-7051		WOS:000242636900011	
J	Ghosh, Anil K.; Chaudhuri, Probal; Murthy, C. A.								Multiscale classification using nearest neighbor density estimates								IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			36	5			1139	1148		10.1109/TSMCB.2006.873186			OCT 2006	2006	Density estimates based on k-nearest neighbors have useful applications in nonparametric discriminant analysis. In classification problems, optimal values of k are usually estimated by minimizing the cross-validated misclassification rates. However, these cross-validation techniques allow only one value of k for each population density estimate, while in a classification problem, the optimum value of k for a class may also depend on its competing population densities. Further, it is computationally difficult to minimize the cross-validated error rate when there are several competing populations. Moreover, in addition to depending on the entire training data set, a good choice of k should also depend on the specific observation to be classified. Therefore, instead of using a single value of k for each population density estimate, it is more useful in practice to consider the results for multiple values of k to arrive at the final decision. This paper presents one such approach along with a graphical device, which gives more information about classification results for various choices of k and the related statistical uncertainties present there. The utility of this proposed methodology has been illustrated I using some benchmark data sets.								5	5	0	0	10	1083-4419		WOS:000240756700014	
J	Vijaya, P. A.; Murty, M. Narasimha; Subramanian, D. K.								Efficient median based clustering and classification techniques for protein sequences								PATTERN ANALYSIS AND APPLICATIONS			9	2-3			243	255		10.1007/s10044-006-0040-z			OCT 2006	2006	In this paper, an efficient K-medians clustering (unsupervised) algorithm for prototype selection and Supervised K-medians (SKM) classification technique for protein sequences are presented. For sequence data sets, a median string/sequence can be used as the cluster/group representative. In K-medians clustering technique, a desired number of clusters, K, each represented by a median string/sequence, is generated and these median sequences are used as prototypes for classifying the new/test sequence whereas in SKM classification technique, median sequence in each group/class of labelled protein sequences is determined and the set of median sequences is used as prototypes for classification purpose. It is found that the K-medians clustering technique outperforms the leader based technique and also SKM classification technique performs better than that of motifs based approach for the data sets used. We further use a simple technique to reduce time and space requirements during protein sequence clustering and classification. During training and testing phase, the similarity score value between a pair of sequences is determined by selecting a portion of the sequence instead of the entire sequence. It is like selecting a subset of features for sequence data sets. The experimental results of the proposed method on K-medians, SKM and Nearest Neighbour Classifier (NNC) techniques show that the Classification Accuracy (CA) using the prototypes generated/used does not degrade much but the training and testing time are reduced significantly. Thus the experimental results indicate that the similarity score does not need to be calculated by considering the entire length of the sequence for achieving a good CA. Even space requirement is reduced during both training and classification.								5	0	0	0	5	1433-7541		WOS:000240830900010	
J	Dounias, G; Bjerregaard, B; Jantzen, J; Tsakonas, A; Ampazis, N; Panagi, G; Panourgias, E				Tsakonas, Athanasios/A-3646-2008				Automated identification of cancerous smears using various competitive intelligent techniques								ONCOLOGY REPORTS			15		SI		1001	1006					2006	2006	In this study the performance of various intelligent methodologies is compared in the task of pap-smear diagnosis. The selected intelligent methodologies are briefly described and explained, and then, the acquired results are presented and discussed for their comprehensibility and usefulness to medical staff, either for fault diagnosis tasks, or for the construction of automated computer-assisted classification of smears. The intelligent methodologies used for the construction of pap-smear classifiers, are different clustering approaches, feature selection, neuro-fuzzy systems, inductive machine learning, genetic programming, and second order neural networks. Acquired results reveal the power of most intelligent techniques to obtain high quality solutions in this difficult problem of medical diagnosis. Some of the methods obtain almost perfect diagnostic accuracy in test data, but the outcome lacks comprehensibility. On the other hand, results scoring high in terms of comprehensibility are acquired from some methods, but with the drawback of achieving lower diagnostic accuracy. The experimental data used in this study were collected at a previous stage, for the purpose of combining intelligent diagnostic methodologies with other existing, computer imaging technologies towards the construction of an automated smear cell classification device.								5	0	2	0	5	1021-335X		WOS:000236066000005	
S	Massie, Stewart; Craw, Susan; Wiratunga, Nirmalie						RothBerghofer, TR; Goker, MH; Guvenir, HA		Complexity profiling for informed case-base editing								ADVANCES IN CASE-BASED REASONING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		4106				325	339					2006	2006	The contents of the case knowledge container is critical to the performance of case-based classification systems. However the knowledge engineer is given little support in the selection of suitable techniques to maintain and monitor the case-base. In this paper we present a novel technique that provides an insight into the structure of a case-base by means of a complexity profile that can assist maintenance decision-making and provide a benchmark to assess future changes to the case-base. We also introduce a complexity-guided redundancy reduction algorithm which uses a local complexity measure to actively retain cases close to boundaries. The algorithm offers control over the balance between maintaining competence and reducing case-base size. The ability of the algorithm to maintain accuracy in a compacted case-base is demonstrated on seven public domain classification datasets.				8th European Conference on Case-Based Reasoning	SEP 04-07, 2006	DaimlerChrysler; DFKI GmbH; Empolis; Kaidara Software; Microsoft; PricewaterhouseCoopers	Fethiye, TURKEY	5	0	0	0	5	0302-9743	3-540-36843-4	WOS:000240904600025	
J	Deshpande, U; Gupta, A; Basu, A								Performance enhancement of a contract net protocol based system through instance-based learning								IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			35	2			345	358		10.1109/TSMCB.2004.842256			APR 2005	2005	The contract net protocol (CNP) is a widely used coordination mechanism in multiagent systems. It has a lot of communication overhead due to the broadcast of the task announcements. The performance of the CNP degrades drastically when the number of communicating agents and the number of tasks announced increases. Hence, it has problems of scalability. In order to overcome this limitation, an instance-based learning (IBL) mechanism is designed that uses previously stored instances in order to select a target agent. This avoids the expensive bidding process. The scheme is implemented in a simulated distributed hospital system where the CNP is used for resource sharing across hospitals. Experimental results demonstrate that with the incorporation of the IBL, the system performance improves significantly. The system is better scalable with respect to the number of tasks.								5	3	0	1	8	1083-4419		WOS:000227747900015	
S	Hendrickx, I; van den Bosch, A						Gama, J; Camacho, R; Brazdil, P; Jorge, A; Torgo, L		Hybrid algorithms with instance-based classification								MACHINE LEARNING: ECML 2005, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		3720				158	169					2005	2005	In this paper we aim to show that instance-based classification can replace the classifier component of a rule learner and of maximum-entropy modeling, thereby improving the generalization accuracy of both algorithms. We describe hybrid algorithms that combine rule learning models and maximum-entropy modeling with instance-based classification. Experimental results show that both hybrids are able to outperform the parent algorithm. We analyze and compare the overlap in errors and the statistical bias and variance of the hybrids, their parent algorithms, and a plain instance-based learner. We observe that the successful hybrid algorithms have a lower statistical bias component in the error than their parent algorithms; the fewer errors they make are also less systematic.				16th European Conference on Machine Learning (ECML)/9th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)	OCT 03-07, 2005	FCT; LIACC NIAAD	Oporto, PORTUGAL	5	0	0	0	5	0302-9743	3-540-29243-8	WOS:000233235200019	
J	Devillez, A								Four fuzzy supervised classification methods for discriminating classes of non-convex shape								FUZZY SETS AND SYSTEMS			141	2			219	240		10.1016/S0165-0114(03)00265-3			JAN 16 2004	2004	Our work deals with modelling and optimising industrial processes such as metal cutting with high-speed machining. In this field we have chosen to use fuzzy supervised classification methods in order to design a diagnosis system or a process-monitoring module. The problem, we currently meet, concerns the shape of the classes, we generally obtain. These shapes are often non-convex and non-separable by a hyperplane. For these reasons, we focus on fuzzy supervised classification methods in order to discriminate these classes. The choice of a method is not obvious and we perform a comparative study. The two classical methods tested were the fuzzy K-nearest-neighbours method and a method based on distributed fuzzy rules. Furthermore, we propose two adaptations of the fuzzy pattern matching algorithm called fuzzy pattern matching with exponential function and fuzzy pattern matching multidensity. After some refresher on supervised classification, the four tested methods are detailed and compared according to the following criteria: quality of the discrimination, computation time and ability to decide. The response of each classifier is illustrated by membership level curves and the quality of diagnosis is studied by the introduction of membership and ambiguity rejects. (C) 2003 Elsevier B.V. All rights reserved.								5	0	0	1	5	0165-0114		WOS:000187914600004	
J	Okazaki, N; Matsuo, Y; Matsumura, N; Ishizuka, M								Sentence extraction by spreading activation through sentence similarity								IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS			E86D	9			1686	1694					SEP 2003	2003	Although there has been a great deal of research on automatic summarization, most methods rely on statistical methods, disregarding relationships between extracted textual segments. We propose a novel method to extract a set of comprehensible sentences which centers on several key points to ensure sentence connectivity. It features a similarity network from documents with a lexical dictionary, and spreading activation to rank sentences. We show evaluation results of a multi-document summarization system based on the method participating in a competition of summarization, TSC (Text Summarization Challenge) task, organized by the third NTCIR project.								5	0	0	0	5	0916-8532		WOS:000185276000027	
J	Apte, CV; Hong, SJ; Natarajan, R; Pednault, EPD; Tipu, FA; Weiss, SM								Data-intensive analytics for predicting modeling								IBM JOURNAL OF RESEARCH AND DEVELOPMENT			47	1			17	23					JAN 2003	2003	The Data Abstraction Research Group was formed in the early 1990s, to bring focus to the work of the Mathematical Sciences Department in the emerging area of knowledge discovery and data mining (KD & DM). Most activities in this group have been performed in the technical area of predictive modeling, roughly at the intersection of machine learning, statistical modeling, and database technology. There has been a major emphasis on using business and industrial problems to motivate the research agenda. Major accomplishments include advances in methods for feature analysis, rule-based pattern discovery, and probabilistic modeling, and novel solutions for insurance risk management, targeted marketing, and text mining. This paper presents an overview of the group's major technical accomplishments.								5	0	0	0	5	0018-8646		WOS:000180478800003	
S	Cardenes, R; Warfield, SK; Macias, EM; Santana, JA; Ruiz-Alzola, J				Warfield, Simon/B-3352-2009		MorenoDiaz, R; Pichler, F		An efficient algorithm for multiple sclerosis lesion segmentation from brain MRI								COMPUTER AIDED SYSTEMS THEORY - EUROCAST 2003	LECTURE NOTES IN COMPUTER SCIENCE		2809				542	551					2003	2003	We propose a novel method for the segmentation of Multiple Sclerosis (MS) lesions in MRI. The method is based on a three-step approach: first a conventional k-NN classifier is applied to pre-classify gray matter (CM), white matter (WM), cerebro-spinal fluid (CSF) and MS lesions from a set of prototypes selected by an expert. Second, the classification of problematic patterns is resolved computing a fast distance transformation (DT) algorithm from the set of prototypes in the Euclidean space defined by the MRI dataset. Finally, a connected component filtering algorithm is used to remove lesion voxels not connected to the real lesions. This method uses distance information together with intensity information to improve the accuracy of lesion segmentation and, thus, it is specially useful when MS lesions have similar intensity values than other tissues. It is also well suited for interactive segmentations due to its efficiency. Results are shown on real MRI data as wall as on a standard database of synthetic images.				9th International Workshop on Computer Aided Systems Theory	FEB 24-28, 2003		LAS PALMAS GC, SPAIN	5	0	2	0	5	0302-9743	3-540-20221-8	WOS:000188006400049	
J	Santinelli, A; Mazzucchelli, R; Colanzi, P; Tinca, A; Montironi, R								Image processing, diagnostic information extraction and quantitative assessment in pathology								JOURNAL OF CELLULAR AND MOLECULAR MEDICINE			6	1			93	106		10.1111/j.1582-4934.2002.tb00314.x			JAN-MAR 2002	2002	As we enter the information age we hold strong beliefs in the benefits of digital technology applied to pathology: numerical representation offers objectivity. Digital knowledge may indeed lead to significant information discovery, and, processing systems might be designed to allow a true evolution of capabilities. Questions arise whether the methodology underlying quantitative analysis provides the information that we need and whether it is appropriate for some of the problems encountered in diagnostic and prognostic histopathology. While one certainly would not dispute the value of statistical procedures, the clinical needs call for individual patient targeted prognosis.								5	0	4	0	5	1582-1838		WOS:000175155300008	
J	Sansone, C; Tortorella, F; Vento, M				Tortorella, Francesco/F-5964-2010				A classification reliability driven reject rule for multi-expert systems								INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			15	6			885	904		10.1142/S0218001401001210			SEP 2001	2001	In this paper we propose a reject rule applicable to a Multi-Expert System (MES). The rule is adaptive to the given domain and allows the achievement of the best trade-off between reject and error rates as a function of the costs attributed to errors and rejects in the considered application. The results of the method axe particularly effective since the method does not rely on particular statistical assumptions, as other reject rules. An experimental analysis carried out on publicly available databases is reported together with a comparison with other methods present in the literature.								5	0	0	0	5	0218-0014		WOS:000171681600001	
J	Baram, Y								A geometric approach to consistent classification								PATTERN RECOGNITION			33	2			177	184		10.1016/S0031-3203(99)00050-3			FEB 2000	2000	A classifier is called consistent with respect to a given set of class-labeled points if it correctly classifies the set. We consider classifiers defined by unions of local separators (e.g., polytopes) and propose algorithms for consistent classifier reduction. The proposed approach yields a consistent reduction of the nearest-neighbor classifier, relating the expected classifier size to a local clustering property of the data and resolving unanswered questions raised by Hart (IEEE Trans. Inform. Theory IT-14(3) (1968)) with respect to the complexity of the condensed nearest neighbor method. (C) 1999 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.								5	0	0	0	5	0031-3203		WOS:000084262800001	
S	Omachi, S; Sun, F; Aso, H						Ferri, FJ; Inesta, JM; Amin, A; Pudil, P		A new approximation method of the quadratic discriminant function								ADVANCES IN PATTERN RECOGNITION	LECTURE NOTES IN COMPUTER SCIENCE		1876				601	610					2000	2000	For many statistical pattern recognition methods, distributions of sample vectors are assumed to be normal, and the quadratic discriminant function derived from the probability density function of multivariate normal distribution is used for classification. However, the computational cost is O(n(2)) for n-dimensional vectors. Moreover, if there are not enough training sample patterns, covariance matrix can not be estimated accurately. In the case that the dimensionality is large, these disadvantages markedly reduce classification performance. In order to avoid these problems, in this paper, a new approximation method of the quadratic discriminant function is proposed. This approximation is done by replacing the values of small eigenvalues by a constant which is estimated by the maximum likelihood estimation. This approximation not only reduces the computational cost but also improves the classification accuracy.				Joint International-Association-of-Pattern-Recognition International Workshops - SSPR 2000 and SPR 2000	AUG 30-SEP 01, 2000	Int Assoc Pattern Recognit; Univ Valencia, Dept Informat	UNIV ALICANTE, ALICANTE, SPAIN	5	0	0	0	5	0302-9743	3-540-67946-4	WOS:000171155700062	
J	Lee, CH; Shin, DG								A multistrategy approach to classification learning in databases								DATA & KNOWLEDGE ENGINEERING			31	1			67	93		10.1016/S0169-023X(99)00018-X			AUG 1999	1999	This paper proposes a hybrid classification learning system for databases that integrates rule induction and lazy learning. For rule induction learning, we use an entropy function based on Hellinger divergence to measure the amount of information each inductive rule contains. For lazy learning, we also use the Hellinger measure to automatically generate attribute weights and to compute similarities between data values of non-numeric data types. Our system has been implemented and tested extensively on a number of well-known machine learning data sets. The performance of our system was favorable compared to those of other well-known classification learning techniques based on monostrategic learning methods. (C) 1999 Elsevier Science B.V. All rights reserved.								5	0	1	0	5	0169-023X		WOS:000082215900003	
J	Zhao, QF								Co-evolutionary learning of neural networks								JOURNAL OF INTELLIGENT & FUZZY SYSTEMS			6	1			83	90					1998	1998	Compared with the conventional approaches, the evolutionary algorithms (EAs) are more efficient for system design in the sense that EAs can provide higher opportunity for obtaining the global optimal solution. However, in most existing EAs, an individual corresponds directly to a possible solution, and a large amount of computations is required for designing large-scaled systems, To solve this problem, this paper proposes a co-evolutionary algorithm (CEA). The basic idea is to divide and conquer: divide the system into many small homogeneous modules, define an individual as a module, find many good individuals using existing EAs, and put them together again to form the whole system. To make the study more concrete, we focus the discussion on the evolutionary learning of neural networks for pattern recognition. Experimental results are provided to show the procedure and the performance of the CEA.				4th International Conference on Soft Computing	SEP 30-OCT 05, 1996		IIZUKA, JAPAN	5	0	0	0	5	1064-1246		WOS:000075494700008	
J	BASSOE, CF								AUTOMATED DIAGNOSES FROM CLINICAL NARRATIVES - A MEDICAL SYSTEM BASED ON COMPUTERIZED MEDICAL RECORDS, NATURAL-LANGUAGE PROCESSING, AND NEURAL-NETWORK TECHNOLOGY								NEURAL NETWORKS			8	2			313	319		10.1016/0893-6080(94)00076-X			1995	1995	A collection of artificial, associative neural networks (PROMNET) interfaced to a computerized medical record is described Clinical narratives were subject to automated natural language processing, and relations were established between 14,323 diagnoses and 31,381 patient findings. Patient diagnoses and findings were counted, grouped into clinical entities, and used to train PROMNET. Training was completed in a few minutes. PROMNET's dictionary contained about 20,000 words, and the neural network recognized more than 2800 disorders. Its performance was evaluated by an automated double-blind Turing test. PROMNET made clinical decisions in a few seconds with sensitivity of 96.6%, and specificity of 95.7%. The most pertinent clinical entity was usually ranked highest. PROMNET is a powerful inference engine that learns from clinical narratives and interacts with medical personnel or patients in natural language.								5	0	0	0	5	0893-6080		WOS:A1995QN84400012	
J	LIN, JH; VITTER, JS								A THEORY FOR MEMORY-BASED LEARNING								MACHINE LEARNING			17	2-3			143	167		10.1007/BF00993469			NOV-DEC 1994	1994	A memory-based learning system is an extended memory management system that decomposes the input space either statistically or dynamically into subregions for the purpose of storing and retrieving functional information. The main generalization techniques employed by memory-based learning systems are the nearest-neighbor search, space decomposition techniques, and clustering. Research on memory-based learning is still in its early stage. In particular, there are very few rigorous theoretical results regarding memory requirement, sample size, expected performance, and computational complexity. In this paper, we propose a model for memory-based learning and use it to analyze several methods-is-an-element-of-covering, hashing, clustering, tree-structured clustering, and receptive-fields-for learning smooth functions. The sample size and system complexity are derived for each method. Our model is built upon the generalized PAC learning model of Haussler (Haussler, 1989) and is closely related to the method of vector quantization in data compression. Our main result is that we can build memory-based learning systems using new clustering algorithms (Lin & Vitter, 1992a) to PAC-learn in polynomial time using only polynomial storage in typical situations.								5	1	0	0	6	0885-6125		WOS:A1994PW04600003	
J	TOUSSAINT, GT								A COUNTEREXAMPLE TO TOMEK CONSISTENCY THEOREM FOR A CONDENSED NEAREST-NEIGHBOR DECISION RULE								PATTERN RECOGNITION LETTERS			15	8			797	801		10.1016/0167-8655(94)90007-8			AUG 1994	1994	The condensed nearest neighbor rule (CNN) was proposed by Hart (1968) as a method to reduce the storage requirements of the original data set D for the efficient implementation of the nearest neighbor decision rule in pattern classification problems. Tomek (1976a) suggested two modifications of CNN in order to improve its performance. As a first step in Tomek's second method he computes a subset C of D, for subsequent use in CNN, and claims that C is training-set-consistent, i.e., that all data points in D are correctly classified by the nearest neighbor rule using C. In this note we provide a counterexample to this claim. We also analyze Tomek's algorithm in the context of more recent graph-theoretical condensing schemes.								5	0	0	0	5	0167-8655		WOS:A1994PB48400007	
B	BAUM, EB						ALMEIDA, LB; WELLEKENS, CJ		WHEN ARE K-NEAREST NEIGHBOR AND BACK PROPAGATION ACCURATE FOR FEASIBLE SIZED SETS OF EXAMPLES								NEURAL NETWORKS /	LECTURE NOTES IN COMPUTER SCIENCE		412				2	25					1990	1990					WORKSHOP ON NEURAL NETWORKS	FEB 15-17, 1990	EUROPEAN ASSOC SIGNAL PROC; PHILIPS RES LAB BRUSSELS; BELL COMMUN RES	SESIMBRA, PORTUGAL	5	0	2	0	5		3-540-52255-7	WOS:A1990BQ42C00001	
J	DAVIES, ER								TRAINING SETS AND A-PRIORI PROBABILITIES WITH THE NEAREST NEIGHBOR METHOD OF PATTERN-RECOGNITION								PATTERN RECOGNITION LETTERS			8	1			11	13		10.1016/0167-8655(88)90017-7			JUL 1988	1988									5	0	0	0	5	0167-8655		WOS:A1988P914000003	
J	ZAKI, FW; ELFATTAH, AIA; ENAB, YM; ELKONYALY, SH								AN ENSEMBLE AVERAGE CLASSIFIER FOR PATTERN-RECOGNITION MACHINES								PATTERN RECOGNITION			21	4			327	332		10.1016/0031-3203(88)90046-5			1988	1988									5	0	1	0	5	0031-3203		WOS:A1988P538800006	
J	LUK, A; MACLEOD, JES								AN ALTERNATIVE NEAREST NEIGHBOR CLASSIFICATION SCHEME								PATTERN RECOGNITION LETTERS			4	5			375	381		10.1016/0167-8655(86)90059-0			OCT 1986	1986									5	0	0	0	5	0167-8655		WOS:A1986F111200008	
J	COBURN, JT; FORBES, RA; FREISER, BS; BECKER, L; LYTLE, FE; HUBER, DM								THE APPLICATION OF PATTERN-RECOGNITION TO THE IDENTIFICATION OF PATHOGENS BY LASER-EXCITED FLUOROMETRY								ANALYTICA CHIMICA ACTA			184				65	76		10.1016/S0003-2670(00)86470-3			JUN 30 1986	1986									5	0	4	0	5	0003-2670		WOS:A1986D964700005	
J	GERSCH, W; BROTHERTON, T; BRAUN, S								NEAREST NEIGHBOR TIME-SERIES ANALYSIS CLASSIFICATION OF FAULTS IN ROTATING MACHINERY								JOURNAL OF VIBRATION ACOUSTICS STRESS AND RELIABILITY IN DESIGN-TRANSACTIONS OF THE ASME			105	2			178	184					1983	1983									5	0	0	0	5	0739-3717		WOS:A1983QP11000007	
J	GOWDA, KC; KRISHNA, G								LEARNING WITH A MUTUALISTIC TEACHER								PATTERN RECOGNITION			11	5-6			383	390					1979	1979									5	0	1	0	5	0031-3203		WOS:A1979HZ68500011	
J	PETERS, C								FEATURE-SELECTION FOR BEST MEAN-SQUARE APPROXIMATION OF CLASS DENSITIES								PATTERN RECOGNITION			11	5-6			361	364		10.1016/0031-3203(79)90048-7			1979	1979									5	0	0	0	5	0031-3203		WOS:A1979HZ68500009	
J	BOYD, JC; LEWIS, JW; MARR, JJ; HARPER, AM; KOWALSKI, BR								EFFECT OF ATYPICAL ANTIBIOTIC-RESISTANCE ON MICROORGANISM IDENTIFICATION BY PATTERN-RECOGNITION								JOURNAL OF CLINICAL MICROBIOLOGY			8	6			689	694					1978	1978									5	1	3	0	6	0095-1137		WOS:A1978GA93200012	
J	DASARATHY, B; WHITE, LJ								CHARACTERIZATION OF NEAREST-NEIGHBOR RULE DECISION SURFACES AND A NEW APPROACH TO GENERATE THEM								PATTERN RECOGNITION			10	1			41	46		10.1016/0031-3203(78)90047-X			1978	1978									5	0	0	0	5	0031-3203		WOS:A1978EY49000006	
J	DUEWER, DL; KOWALSKI, BR; CLAYSON, KJ; ROBY, RJ				Duewer, David/B-7410-2008				ELUCIDATING THE STRUCTURE OF SOME CLINICAL DATA								COMPUTERS AND BIOMEDICAL RESEARCH			11	6			567	580		10.1016/0010-4809(78)90035-6			1978	1978									5	0	3	0	5	0010-4809		WOS:A1978GE04200004	
J	ANDERSON, MW; BENNING, RD								A DISTRIBUTION-FREE DISCRIMINATION PROCEDURE BASED ON CLUSTERING								IEEE TRANSACTIONS ON INFORMATION THEORY			16	5			541	+		10.1109/TIT.1970.1054532			1970	1970									5	0	0	0	5	0018-9448		WOS:A1970H046200004	
J	PETERSON, DW								SOME CONVERGENCE PROPERTIES OF A NEAREST NEIGHBOR DECISION RULE								IEEE TRANSACTIONS ON INFORMATION THEORY			16	1			26	+		10.1109/TIT.1970.1054408			1970	1970									5	0	2	0	5	0018-9448		WOS:A1970F082400004	
J	Mazilu, Michael; Mourka, Areti; Vettenburg, Tom; Wright, Ewan M.; Dholakia, Kishan				Mourka, Areti/E-7978-2012; Wright, Ewan/A-2358-2009				Simultaneous determination of the constituent azimuthal and radial mode indices for light fields possessing orbital angular momentum								APPLIED PHYSICS LETTERS			100	23					231115	10.1063/1.4728111			JUN 4 2012	2012	A wide array of diffractive structures such as arrays of pinholes, triangular apertures, slits, and holograms have all recently been used to measure the azimuthal index of individual Laguerre-Gaussian beams. Here, we demonstrate a powerful approach to simultaneously measure both the radial and azimuthal indices of pure Laguerre-Gaussian light fields using the method of principal component analysis. We find that the shape of the diffracting element used to measure the mode indices is in fact of little importance and the crucial step is training any diffracting optical system and transforming the observed pattern into uncorrelated variables. The method is generic and may be extended to other families of light fields such as Bessel or Hermite-Gaussian beams. (C) 2012 American Institute of Physics. [http://dx.doi.org/10.1063/1.4728111]								4	0	1	0	4	0003-6951		WOS:000305089900015	
J	Hu, Xintao; Li, Kaiming; Han, Junwei; Hua, Xiansheng; Guo, Lei; Liu, Tianming								Bridging the Semantic Gap via Functional Brain Imaging								IEEE TRANSACTIONS ON MULTIMEDIA			14	2			314	325		10.1109/TMM.2011.2172201			APR 2012	2012	The multimedia content analysis community has made significant efforts to bridge the gaps between low-level features and high-level semantics perceived by humans. Recent advances in brain imaging and neuroscience in exploring the human brain's responses during multimedia comprehension demonstrated the possibility of leveraging cognitive neuroscience knowledge to bridge the semantic gaps. This paper presents our initial effort in this direction by using functional magnetic resonance imaging (fMRI). Specifically, task-based fMRI (T-fMRI) was performed to accurately localize the brain regions involved in video comprehension. Then, natural stimulus fMRI (N-fMRI) data were acquired when subjects watched the multimedia clips selected from the TRECVID datasets. The responses in the localized brain regions were measured and used to extract high-level features as the representation of the brain's comprehension of semantics in the videos. A novel computational framework was developed to learn the most relevant low-level feature sets that best correlate the fMRI-derived semantic features based on the training videos with fMRI scans, and then the learned model was applied to larger scale TRECVID video datasets without fMRI scans for category classification. Our experimental results demonstrate: 1) there are meaningful couplings between brain's fMRI-derived responses and video stimuli, suggesting the validity of linking semantics and low-level features via fMRI and 2) the computationally learned low-level features can significantly (p < 0.01) improve video classification in comparison with original low-level features and extracted low-level features resulted from well-known feature projection algorithms.								4	0	2	0	4	1520-9210		WOS:000302702500007	
J	Piro, Paolo; Nock, Richard; Nielsen, Frank; Barlaud, Michel								Leveraging k-NN for generic classification boosting								NEUROCOMPUTING			80		SI		3	9		10.1016/j.neucom.2011.07.026			MAR 15 2012	2012	Voting rules relying on k-nearest neighbors (k-NN) are an effective tool in countless many machine learning techniques. Thanks to its simplicity, k-NN classification is very attractive to practitioners, as it enables very good performances in several practical applications. However, it suffers from various drawbacks, like sensitivity to "noisy" instances and poor generalization properties when dealing with sparse high-dimensional data.In this paper, we tackle the k-NN classification problem at its core by providing a novel k-NN boosting approach. Namely, we propose a supervised learning algorithm, called Universal Nearest Neighbors (UNN), that induces a leveraged k-NN rule by globally minimizing a surrogate risk upper bounding the empirical misclassification rate over training data. Interestingly, this surrogate risk can be arbitrary chosen from a class of Bregman loss functions, including the familiar exponential, logistic and squared losses. Furthermore, we show that UNN allows to efficiently filter a dataset of instances by keeping only a small fraction of data.Experimental results on the synthetic Ripley's dataset show that such a filtering strategy is able to reject "noisy" examples, and yields a classification error close to the optimal Bayes error. Experiments on standard UCI datasets show significant improvements over the current state of the art. (C) 2011 Elsevier B.V. All rights reserved.								4	0	0	0	4	0925-2312		WOS:000300817200002	
J	Shen, Linlin; Jia, Sen				Shen, Linlin/B-1968-2009				Three-Dimensional Gabor Wavelets for Pixel-Based Hyperspectral Imagery Classification					2			IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			49	12			5039	5046		10.1109/TGRS.2011.2157166			DEC 2011	2011	The rich information available in hyperspectral imagery not only poses significant opportunities but also makes big challenges for material classification. Discriminative features seem to be crucial for the system to achieve accurate and robust performance. In this paper, we propose a 3-D Gabor-wavelet-based approach for pixel-based hyperspectral imagery classification. A set of complex Gabor wavelets with different frequencies and orientations is first designed to extract signal variances in space, spectrum, and joint spatial/spectral domains. The magnitude of the response at each sampled location (x, y) for spectral band b contains rich information about the signal variances in the local region. Each pixel can be well represented by the rich information extracted by Gabor wavelets. A feature selection and fusion process has also been developed to reduce the redundancy among Gabor features and make the fused feature more discriminative. The proposed approach was fully tested on two real-world hyperspectral data sets, i.e., the widely used Indian Pine site and Kennedy Space Center. The results show that our method achieves as high as 96.04% and 95.36% accuracies, respectively, even when only few samples, i.e., 5% of the total samples per class, are labeled.								4	0	0	0	4	0196-2892		WOS:000297282300008	
J	Kaya, Gulsen Taskin; Musaoglu, Nebiye; Ersoy, Okan K.								Damage Assessment of 2010 Haiti Earthquake with Post-Earthquake Satellite Image by Support Vector Selection and Adaptation								PHOTOGRAMMETRIC ENGINEERING AND REMOTE SENSING			77	10			1025	1035					OCT 2011	2011	Remote sensing technology is a powerful tool to extract regions damaged after an earthquake. There are two methodological approaches in detection of earthquake damage: mono-temporal and multi-temporal. Especially for providing effective emergency management, the monotemporal approach is generally preferred in extraction of earthquake damage as it does not depend on availability of pre-earthquake imagery. For this purpose, a novel method called support vector selection and adaptation (SVSA) has been introduced to detect the damaged regions from a post-earthquake image. In this study, the SVSA method was applied to the region where the Haiti Presidential Palace and Cathedral is located, and the damaged regions were identified. The performance of the SVSA method in identification of the damaged regions was evaluated by comparing the thematic maps obtained by classifying pre- and post-earthquake images. Additionally, the damage patterns for the city of Port-au-Prince were estimated by the SVSA.								4	0	0	0	4	0099-1112		WOS:000295818000009	
J	Lee, Chun-Yao; Shen, Yi-Xing								Optimal Feature Selection for Power-Quality Disturbances Classification								IEEE TRANSACTIONS ON POWER DELIVERY			26	4			2342	2351		10.1109/TPWRD.2011.2149547			OCT 2011	2011	This paper proposes an optimal feature selection approach, namely, probabilistic neural network-based feature selection (PFS), for power-quality disturbances classification. The PFS combines a global optimization algorithm with an adaptive probabilistic neural network (APNN) to gradually remove redundant and irrelevant features in noisy environments. To validate the practicability of the features selected by the proposed PFS approach, we employed three common classifiers: multilayer perceptron, k-nearest neighbor and APNN. The results indicate that this PFS approach is capable of efficiently eliminating nonessential features to improve the performance of classifiers, even in environments with noise interference.								4	0	0	0	4	0885-8977		WOS:000298981800031	
J	Hejazi, M. A.; Gharehpetian, G. B.; Moradi, G.; Alehosseini, H. A.; Mohammadi, M.								Online monitoring of transformer winding axial displacement and its extent using scattering parameters and k-nearest neighbour method								IET GENERATION TRANSMISSION & DISTRIBUTION			5	8			824	832		10.1049/iet-gtd.2010.0802			AUG 2011	2011	The online monitoring of the transformer winding using scattering parameters fingerprint is presented. As a test object, a simplified model of transformer is used. The winding axial displacement is modelled on this test object. The scattering parameters of the test object are calculated using the high-frequency simulation software and measured using a network analyser. Two indices are defined based on the magnitude and phase of scattering parameters for the detection of the axial displacement. A new algorithm for the estimation of the axial displacement extent is presented using the proposed indices and high-frequency modelling of the transformer. To detect this mechanical defect and its extent, the k-nearest neighbour (k-NN) regression is suggested.								4	0	0	0	4	1751-8687		WOS:000293171700005	
J	Gagliardi, Francesco								Instance-based classifiers applied to medical databases: Diagnosis and knowledge extraction								ARTIFICIAL INTELLIGENCE IN MEDICINE			52	3			123	139		10.1016/j.artmed.2011.04.002			JUL 2011	2011	Objective: The aim of this paper is to study the feasibility and the performance of some classifier systems belonging to family of instance-based (IB) learning as second-opinion diagnostic tools and as tools for the knowledge extraction phase in the process of knowledge discovery in clinical databases.Materials and methods: We consider three clinical databases: one relating to the differential diagnosis of erythemato-squamous diseases, the second to the diagnosis of the onset of diabetes mellitus and the third dealing with a problem of diagnostic imaging in nuclear cardiology. We apply five IB classifiers to each database: two are based on exemplars, one is based on prototypes and two are hybrid. One of the latter classifiers is a new classifier introduced here and is called prototype exemplar learning classifier (PEL-C). We use cross-validation techniques to evaluate and compare the performances of several classifier systems as diagnostic tools, considering indexes such as accuracy, sensitivity, specificity, and conciseness of class representations. Moreover we analyze the number and the type of instances that represent the diagnostic classes learnt by each classifier to evaluate and compare their knowledge extraction capabilities.Results: An examination of the experimental results shows that classifiers with the best classification performances are the optimized k-nearest neighbour classifier (k-NNC) and PEL-C. The k-NNC uses the highest number of representative instances, 100% of the entire database, whereas PEL-C uses a far lesser number of representative instances: equal, on the average, to the 3% of the database. As tools for knowledge extraction, we interpret the kind of class representations obtained by IB classifiers as a form of nosological knowledge. Additionally, we report the most interesting diagnostic class representations to be those extracted by PEL-C because they are composed of a mixture of abstracted prototypical cases (syndromes) and selected atypical clinical cases.Conclusion: This study shows that IB methods - most notably, the optimized k-NNC and the PEL-C - can be used and may be advantageous for clinical decision support systems and that IB classifiers can be used for nosological knowledge extraction. Because PEL-C uses more compact and potentially meaningful class descriptions, it is preferable when the diagnostic problem at-hand needs smaller storage space or for knowledge extraction itself. The complexity and responsibility of diagnostic practice requires that these results be confirmed further within other clinical domains. (C) 2011 Elsevier B.V. All rights reserved.								4	1	0	0	5	0933-3657		WOS:000293209000001	
J	Kaya, Gulsen Taskin; Ersoy, Okan K.; Kamasak, Mustafa E.								Support Vector Selection and Adaptation for Remote Sensing Classification					1			IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			49	6			2071	2079		10.1109/TGRS.2010.2096822			JUN 2011	2011	Classification of nonlinearly separable data by nonlinear support vector machines (SVMs) is often a difficult task, particularly due to the necessity of choosing a convenient kernel type. Moreover, in order to get the optimum classification performance with the nonlinear SVM, a kernel and its parameters should be determined in advance. In this paper, we propose a new classification method called support vector selection and adaptation (SVSA) which is applicable to both linearly and nonlinearly separable data without choosing any kernel type. The method consists of two steps: selection and adaptation. In the selection step, first, the support vectors are obtained by a linear SVM. Then, these support vectors are classified by using the K-nearest neighbor method, and some of them are rejected if they are misclassified. In the adaptation step, the remaining support vectors are iteratively adapted with respect to the training data to generate the reference vectors. Afterward, classification of the test data is carried out by 1-nearest neighbor with the reference vectors. The SVSA method was applied to some synthetic data, multisource Colorado data, post-earthquake remote sensing data, and hyperspectral data. The experimental results showed that the SVSA is competitive with the traditional SVM with both linearly and nonlinearly separable data.								4	1	1	0	5	0196-2892		WOS:000290997600023	
J	Zhu, Zhi-Bo; Song, Zhi-Huan								A novel fault diagnosis system using pattern classification on kernel FDA subspace								EXPERT SYSTEMS WITH APPLICATIONS			38	6			6895	6905		10.1016/j.eswa.2010.12.034			JUN 2011	2011	Recently, pattern recognition techniques have been applied for fault diagnosis. Principal component analysis (PCA) and kernel principal component analysis (KPCA) are introduced for feature extraction. However, those unsupervised learning methods have not incorporated the prior knowledge of process patterns. This paper proposes a novel fault diagnosis system to improve the performance of fault diagnosis. Kernel Fisher discriminant analysis (KFDA) is used in the first step for feature extraction, then Gaussian mixture model (GMM) and k-nearest neighbor (kNN) are applied for fault detection and isolation on the KFDA subspace. Since the performance of fault diagnosis system would be degraded in the fault detection stage, fault detection and identification are presented in a holistic manner without an intermediate step in the novel system. A case study of the Tennessee Eastman (TE) benchmark process indicates that the proposed methods are more efficient, compared to the traditional ones. Furthermore, as the performances of GMM and kNN are comparable, the data structure of the process should be checked beforehand, depending on which the optimal classifier can be selected. (C) 2010 Elsevier Ltd. All rights reserved.								4	1	0	0	5	0957-4174		WOS:000288343900058	
J	Fu, Zhouyu; Lu, Guojun; Ting, Kai Ming; Zhang, Dengsheng								A Survey of Audio-Based Music Classification and Annotation								IEEE TRANSACTIONS ON MULTIMEDIA			13	2			303	319		10.1109/TMM.2010.2098858			APR 2011	2011	Music information retrieval (MIR) is an emerging research area that receives growing attention from both the research community and music industry. It addresses the problem of querying and retrieving certain types of music from large music data set. Classification is a fundamental problem in MIR. Many tasks in MIR can be naturally cast in a classification setting, such as genre classification, mood classification, artist recognition, instrument recognition, etc. Music annotation, a new research area in MIR that has attracted much attention in recent years, is also a classification problem in the general sense. Due to the importance of music classification in MIR research, rapid development of new methods, and lack of review papers on recent progress of the field, we provide a comprehensive review on audio-based classification in this paper and systematically summarize the state-of-the-art techniques for music classification. Specifically, we have stressed the difference in the features and the types of classifiers used for different classification tasks. This survey emphasizes on recent development of the techniques and discusses several open issues for future research.								4	2	0	0	6	1520-9210		WOS:000288661800012	
J	Castro, Juan L.; Navarro, Maria; Sanchez, Jose M.; Zurita, Jose M.				Castro, Juan Luis/C-2403-2012; Zurita , Jose Manuel/E-1037-2012				Introducing attribute risk for retrieval in case-based reasoning								KNOWLEDGE-BASED SYSTEMS			24	2			257	268		10.1016/j.knosys.2010.09.002			MAR 2011	2011	One of the major assumptions in case-based reasoning is that similar experiences can guide future reasoning, problem solving and learning. This assumption shows the importance of the method used for choosing the most suitable case, especially when dealing with the class of problems in which risk, is relevant concept to the case retrieval process. This paper argues that traditional similarity assessment methods are not sufficient to obtain the best case; an additional step with new information must be performed necessary, after applying similarity measures in the retrieval stage. When a case is recovered from the case base, one must take into account not only the specific value of the attribute but also whether the case solution is suitable for solving the problem, depending on the risk produced in the final decision. We introduce this risk, as new information through a new concept called risk information that is entirely different from the weight of the attributes. Our article presents this concept locally and measures it for each attribute independently. (C) 2010 Elsevier B.V. All rights reserved.								4	0	0	0	4	0950-7051		WOS:000287287500005	
J	Oh, Sejong								A new dataset evaluation method based on category overlap								COMPUTERS IN BIOLOGY AND MEDICINE			41	2			115	122		10.1016/j.compbiomed.2010.12.006			FEB 2011	2011	The quality of dataset has a profound effect on classification accuracy, and there is a clear need for some method to evaluate this quality. In this paper, we propose a new dataset evaluation method using the R-value measure. This proposed method is based on the ratio of overlapping areas among categories in a dataset. A high R-value for a dataset indicates that the dataset contains wide overlapping areas among its categories, and classification accuracy on the dataset may become low. We can use the R-value measure to understand the characteristics of a dataset, the feature selection process, and the proper design of new classifiers. (C) 2010 Elsevier Ltd. All rights reserved.								4	0	4	0	4	0010-4825		WOS:000287621800006	
S	Batliner, Anton; Schuller, Bjoern; Seppi, Dino; Steidl, Stefan; Devillers, Laurence; Vidrascu, Laurence; Vogt, Thurid; Aharonson, Vered; Amir, Noam						Petta, P; Pelachaud, C; Cowie, R		The Automatic Recognition of Emotions in Speech								EMOTION-ORIENTED SYSTEMS: THE HUMAINE HANDBOOK	Cognitive Technologies						71	99		10.1007/978-3-642-15184-2_6	10.1007/978-3-642-15184-2		2011	2011	In this chapter, we focus on the automatic recognition of emotional states using acoustic and linguistic parameters as features and classifiers as tools to predict the 'correct' emotional states. We first sketch history and state of the art in this field; then we describe the process of 'corpus engineering', i.e. the design and the recording of databases, the annotation of emotional states, and further processing such as manual or automatic segmentation. Next, we present an overview of acoustic and linguistic features that are extracted automatically or manually. In the section on classifiers, we deal with topics such as the curse of dimensionality and the sparse data problem, classifiers, and evaluation. At the end of each section, we point out important aspects that should be taken into account for the planning or the assessment of studies. The subject area of this chapter is not emotions in some narrow sense but in a wider sense encompassing emotion-related states such as moods, attitudes, or interpersonal stances as well. We do not aim at an in-depth treatise of some specific aspects or algorithms but at an overview of approaches and strategies that have been used or should be used.								4	0	0	0	4	1611-2482	978-3-642-15183-5	WOS:000294382700006	
J	Guerra, Luis; McGarry, Laura M.; Robles, Victor; Bielza, Concha; Larranaga, Pedro; Yuste, Rafael				Larranaga, Pedro/F-9293-2013; Bielza, Concha/F-9277-2013				Comparison Between Supervised and Unsupervised Classifications of Neuronal Cell Types: A Case Study								DEVELOPMENTAL NEUROBIOLOGY			71	1	SI		71	82		10.1002/dneu.20809			JAN 2011	2011	In the study of neural circuits, it becomes essential to discern the different neuronal cell types that build the circuit. Traditionally, neuronal cell types have been classified using qualitative descriptors. More recently, several attempts have been made to classify neurons quantitatively, using unsupervised clustering methods. While useful, these algorithms do not take advantage of previous information known to the investigator, which could improve the classification task. For neocortical GABAergic interneurons, the problem to discern among different cell types is particularly difficult and better methods are needed to perform objective classifications. Here we explore the use of supervised classification algorithms to classify neurons based on their morphological features, using a database of 128 pyramidal cells and 199 interneurons from mouse neocortex. To evaluate the performance of different algorithms we used, as a "benchmark," the test to automatically distinguish between pyramidal cells and interneurons, defining "ground truth" by the presence or absence of an apical dendrite. We compared hierarchical clustering with a battery of different supervised classification algorithms, finding that supervised classifications outperformed hierarchical clustering. In addition, the selection of subsets of distinguishing features enhanced the classification accuracy for both sets of algorithms. The analysis of selected variables indicates that dendritic features were most useful to distinguish pyramidal cells from interneurons when compared with somatic and axonal morphological variables. We conclude that supervised classification algorithms are better matched to the general problem of distinguishing neuronal cell types when some information on these cell groups, in our case being pyramidal or interneuron, is known a priori. As a spin-off of this methodological study, we provide several methods to automatically distinguish neocortical pyramidal cells from interneurons, based on their morphologies. (C) 2010 Wiley Periodicals, Inc. Develop Neurobiol 71: 71-82, 2011								4	0	2	0	4	1932-8451		WOS:000285258800008	
J	Kutlu, Yakup; Kuntalp, Damla								A multi-stage automatic arrhythmia recognition and classification system								COMPUTERS IN BIOLOGY AND MEDICINE			41	1			37	45		10.1016/j.compbiomed.2010.11.003			JAN 2011	2011	This paper describes an automatic classification system based on combination of diverse features for the purpose of automatic heartbeat recognition. The method consists of three stages. At the first stage, heartbeats are classified into 5 main groups defined by AAMI using optimal feature sets for each main group. At the second stage, main groups are classified into subgroups using optimal features for each subgroup. Then the third stage is added to the system for classifying beats that are labeled as unclassified beats in the first two classification stages. A diverse set of features including higher order statistics, morphological features, Fourier transform coefficients, and higher order statistics of the wavelet package coefficients are extracted for each different type of ECG beat. At the first stage, optimal features for main groups are determined by using a wrapper type feature selection algorithm. At the second stage, optimal features are similarly selected for discriminating each subgroup of the main groups. Then at the third stage, only raw data is used for classifying beats. In all stages, the classifiers are based on the k-nearest neighbor algorithm. ECG records used in this study are obtained from the MIT-BIH arrhythmia database. The classification accuracy of the proposed system is measured by sensitivity, selectivity, and specificity measures. The system is classified 16 heartbeat types. The measures of proposed system are 85.59%, 95.46%, and 99.56%, for average sensitivity, average selectivity, and average specificity, respectively. (C) 2010 Elsevier Ltd. All rights reserved.								4	0	0	0	4	0010-4825		WOS:000287004500005	
J	Yuan, YouLang; Shi, XiaoHe; Li, XinLei; Lu, WenCong; Cai, YuDong; Gu, Lei; Liu, Liang; Li, MinJie; Kong, XiangYin; Xing, Meng								Prediction of interactiveness of proteins and nucleic acids based on feature selections								MOLECULAR DIVERSITY			14	4			627	633		10.1007/s11030-009-9198-9			NOV 2010	2010	It is important to identify which proteins can interact with nucleic acids for the purpose of protein annotation, since interactions between nucleic acids and proteins involve in numerous cellular processes such as replication, transcription, splicing, and DNA repair. This research tries to identify proteins that can interact with DNA, RNA, and rRNA, respectively. mRMR (Minimum redundancy and maximum relevance), with its elegant mathematical formulation, has been applied widely in processing biological data and feature analysis since its introduction in 2005. mRMR plus incremental feature selection (IFS) is known to be very efficient in feature selection and analysis, and able to improve both effectiveness and efficiency of a prediction model. IFS is applied to decide how many features should be selected from feature list provided by mRMR. In the end, the selected features of mRMR and IFS are further refined by a conventional feature selection method-forward feature wrapper (FFW), by reordering the features. Each protein is coded by 132 features including amino acid compositions and physicochemical properties. After the feature selection, k-Nearest Neighbor algorithm, the adopted prediction model, is trained and tested. As a result, the optimized prediction accuracies for the DNA, RNA, and rRNA are 82.0, 83.4, and 92.3%, respectively. Furthermore, the most important features that contribute to the prediction are identified and analyzed biologically. The predictor, developed for this research, is available for public access at http://chemdata.shu.edu.cn/protein_na_mrmr/.								4	0	4	0	4	1381-1991		WOS:000284598600003	
J	Samsudin, Noor A.; Bradley, Andrew P.				Bradley, Andrew/C-5685-2009	Bradley, Andrew/0000-0003-0109-6844			Nearest neighbour group-based classification								PATTERN RECOGNITION			43	10			3458	3467		10.1016/j.patcog.2010.05.010			OCT 2010	2010	The purpose of group-based classification (GBC) is to determine the class label for a set of test samples, utilising the prior knowledge that the samples belong to same, but unknown class. This can be seen as a simplification of the well studied, but computationally complex, non-sequential compound classification problem. In this paper, we extend three variants of the nearest neighbour algorithm to develop a number of non-parametric group-based classification techniques. The performances of the proposed techniques are then evaluated on both synthetic and real-world data sets and their performance compared with techniques that label test samples individually. The results show that, while no one algorithm clearly outperforms all others on all data sets, the proposed group-based classification techniques have the potential to outperform the individual-based techniques, especially as the (group) size of the test set increases. In addition, it is shown that algorithms that pool information from the whole test set perform better than two-stage approaches that undertake a vote based on the class labels of individual test samples. (C) 2010 Elsevier Ltd. All rights reserved.								4	0	1	0	4	0031-3203		WOS:000280006700024	
J	Zhang, Shu; Jank, Wolfgang; Shmueli, Galit								Real-time forecasting of online auctions via functional K-nearest neighbors								INTERNATIONAL JOURNAL OF FORECASTING			26	4			666	683		10.1016/j.ijforecast.2009.08.006			OCT-DEC 2010	2010	Forecasting prices in online auctions is important for both buyers and sellers. With good forecasts, bidders can make informed bidding decisions and sellers can select the right time and place to list their products. While information from other auctions can help forecast an ongoing auction, it should be weighted by its relevance to the auction of interest. We propose a novel functional K-nearest neighbor (fKNN) forecaster for real-time forecasting of online auctions. The forecaster uses information from other auctions and weights their contributions by their relevance in terms of auction, seller and product features, and by the similarity of the price paths. We capture an auction's price path by borrowing ideas from functional data analysis. We propose a novel Beta growth model, and then measure the distances between two price paths via the Kullback-Leibler distance. Our resulting fKNN forecaster incorporates a mixture of functional and non-functional distances. We apply the forecaster to several large datasets of eBay auctions, showing an improved predictive performance over several competing models. We also investigate the performance across various levels of data heterogeneity, and find that fKNN is particularly effective for forecasting heterogeneous auction populations. (C) 2009 International Institute of Forecasters. Published by Elsevier B.V. All rights reserved.								4	0	0	0	4	0169-2070		WOS:000282902600007	
J	Sarac, Oemer Sinan; Atalay, Volkan; Cetin-Atalay, Rengul				Atalay, Rengul/F-5780-2013				GOPred: GO Molecular Function Prediction by Combined Classifiers								PLOS ONE			5	8					e12382	10.1371/journal.pone.0012382			AUG 31 2010	2010	Functional protein annotation is an important matter for in vivo and in silico biology. Several computational methods have been proposed that make use of a wide range of features such as motifs, domains, homology, structure and physicochemical properties. There is no single method that performs best in all functional classification problems because information obtained using any of these features depends on the function to be assigned to the protein. In this study, we portray a novel approach that combines different methods to better represent protein function. First, we formulated the function annotation problem as a classification problem defined on 300 different Gene Ontology (GO) terms from molecular function aspect. We presented a method to form positive and negative training examples while taking into account the directed acyclic graph (DAG) structure and evidence codes of GO. We applied three different methods and their combinations. Results show that combining different methods improves prediction accuracy in most cases. The proposed method, GOPred, is available as an online computational annotation tool (http://kinaz.fen.bilkent.edu.tr/gopred).								4	0	4	0	4	1932-6203		WOS:000281405300006	
J	Wang, Yu; Xu, Xiaoyan; Zhao, Haifeng; Hua, Zhongsheng								Semi-supervised learning based on nearest neighbor rule and cut edges								KNOWLEDGE-BASED SYSTEMS			23	6			547	554		10.1016/j.knosys.2010.03.012			AUG 2010	2010	In this paper, we propose a novel semi-supervised learning approach based on nearest neighbor rule and cut edges In the first step of our approach, a relative neighborhood graph based on all training samples is constructed for each unlabeled sample, and the unlabeled samples whose edges are all connected to training samples from the same class are labeled. These newly labeled samples are then added into the training samples In the second step, standard self-training algorithm using nearest neighbor rule is applied for classification until a predetermined stopping criterion is met. In the third step, a statistical test is applied for label modification, and in the last step, the remaining unlabeled samples are classified using standard nearest neighbor rule The main advantages of the proposed method are: (1) it reduces the error reinforcement by using relative neighborhood graph for classification in the initial stages of semi-supervised learning: (2) it introduces a label modification mechanism for better classification performance. Experimental results show the effectiveness of the proposed approach (C) 2010 Elsevier B.V. All rights reserved.								4	1	0	0	5	0950-7051		WOS:000280532400007	
J	Farcomeni, Alessio								BAYESIAN CONSTRAINED VARIABLE SELECTION								STATISTICA SINICA			20	3			1043	1062					JUL 2010	2010	By building on the stochastic search approach (George and McCulloch (1993)) we propose a strategy for performing constrained variable selection. We discuss hierarchical and grouping constraints, and introduce anti-hierarchical constraints in which the inclusion of a variable forces another to be excluded from the model. We prove consistency results about models receiving maximal posterior probability, and about the median model (Barbieri and Berger (2004)), and discuss extensions to generalized linear models.								4	0	1	0	4	1017-0405		WOS:000280533600014	
J	Gu, Suicheng; Tan, Ying; He, Xingui								Discriminant analysis via support vectors								NEUROCOMPUTING			73	10-12	SI		1669	1675		10.1016/j.neucom.2009.09.021			JUN 2010	2010	In this paper, we show how support vector machine (SVM) can be employed as a powerful tool for k-nearest neighbor (kNN) classifier. A novel multi-class dimensionality reduction approach, discriminant analysis via support vectors (SVDA), is proposed. First, the SVM is employed to compute an optimal direction to discriminant each two classes. Then, the criteria of class separability is constructed. At last, the projection matrix is computed. The kernel mapping idea is used to derive the non-linear version, kernel discriminant via support vectors (SVKD). In SVDA, only support vectors are involved to compute the transformation matrix. Thus, the computational complexity can be greatly reduced for kernel based feature extraction. Experiments carried out on several standard databases show a clear improvement on LDA-based recognition. (C) 2010 Elsevier B.V. All rights reserved.								4	0	1	0	4	0925-2312		WOS:000279134100017	
J	Gobena, A. K.; Gan, T. Y.								Incorporation of seasonal climate forecasts in the ensemble streamflow prediction system								JOURNAL OF HYDROLOGY			385	1-4			336	352		10.1016/j.jhydrol.2010.03.002			MAY 7 2010	2010	A technique for incorporating 0-3 months lead temperature and precipitation forecasts from two Canadian numerical weather prediction (NWP) models into the ensemble streamflow prediction (ESP) system is presented. The technique involves downscaling monthly NWP forecast outputs to station locations using the model output statistics (MOS) approach and then temporally disaggregating the monthly forecasts into daily input weather data suitable for driving a hydrologic model. The daily weather sequence for a desired month is generated by a nearest neighbor re-sampling of one of the years in the historical record, and then modifying the daily weather data for the same month of the re-sampled year so as to reproduce the MOS-based monthly forecast value. Streamflow forecasts from the MOS-based scheme are compared to pre-ESP and post-ESP re-sampling schemes without seasonal climate forecast guidance. In the pre-ESP scheme, daily weather inputs for the hydrologic model were conditionally re-sampled from historical records. In the post-ESP scheme, streamflow traces produced by the climatic ESP system were conditionally re-sampled. The three schemes were applied to the Bow and Castle rivers, both located in the headwaters of the South Saskatchewan River basin in the province of Alberta, Canada. Correlations between the MOS-based median forecast and observed flow for the Castle River were consistently higher than those based on the pre-ESP and post-ESP schemes. Other skill measures showed mixed results, with the MOS-based forecasts being more skillful in some cases and less skillful in others. All three schemes exhibited better skill for above-normal flow categories than for below-normal categories. It is also shown that considerable improvement in the ESP forecast skill could be achieved through more accurate simulation of streamflow, particularly for forecast issue dates late in the water year. (C) 2010 Elsevier B.V. All rights reserved.								4	0	1	0	4	0022-1694		WOS:000277802100031	
J	Biau, Gerard; Cerou, Frederic; Guyader, Arnaud								Rates of Convergence of the Functional k-Nearest Neighbor Estimate								IEEE TRANSACTIONS ON INFORMATION THEORY			56	4			2034	2040		10.1109/TIT.2010.2040857			APR 2010	2010	Let F be a separable Banach space, and let (X,Y) be a random pair taking values in F x R. Motivated by a broad range of potential applications, we investigate rates of convergence of the k-nearest neighbor estimate r(n)(x) of the regression function r(x) = E[Y vertical bar X = x], based on n independent copies of the pair (X, Y). Using compact embedding theory, we present explicit and general finite sample bounds on the expected squared difference E[r(n)(X) - r(X)](2) and particularize our results to classical function spaces such as Sobolev spaces, Besov spaces, and reproducing kernel Hilbert spaces.								4	0	0	0	4	0018-9448		WOS:000275999500042	
J	Cheng, Haibin; Tan, Pang-Ning; Jin, Rong								Efficient Algorithm for Localized Support Vector Machine								IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			22	4			537	549		10.1109/TKDE.2009.116			APR 2010	2010	This paper presents a framework called Localized Support Vector Machine (LSVM) for classifying data with nonlinear decision surfaces. Instead of building a sophisticated global model from the training data, LSVM constructs multiple linear SVMs, each of which is designed to accurately classify a given test example. A major limitation of this framework is its high computational cost since a unique model must be constructed for each test example. To overcome this limitation, we propose an efficient implementation of LSVM, termed Profile SVM (PSVM). PSVM partitions the training examples into clusters and builds a separate linear SVM model for each cluster. Our empirical results show that 1) LSVM and PSVM outperform nonlinear SVM for all 20 of the evaluated data sets and 2) PSVM achieves comparable performance as LSVM in terms of model accuracy but with significant computational savings. We also demonstrate the efficacy of the proposed approaches in terms of classifying data with spatial and temporal dependencies.								4	0	0	0	4	1041-4347		WOS:000274654800006	
J	Depeursinge, Adrien; Iavindrasana, Jimison; Hidki, Asmaa; Cohen, Gilles; Geissbuhler, Antoine; Platon, Alexandra; Poletti, Pierre-Alexandre; Mueller, Henning								Comparative Performance Analysis of State-of-the-Art Classification Algorithms Applied to Lung Tissue Categorization								JOURNAL OF DIGITAL IMAGING			23	1			18	30		10.1007/s10278-008-9158-4			FEB 2010	2010	In this paper, we compare five common classifier families in their ability to categorize six lung tissue patterns in high-resolution computed tomography (HRCT) images of patients affected with interstitial lung diseases (ILD) and with healthy tissue. The evaluated classifiers are naive Bayes, k-nearest neighbor, J48 decision trees, multilayer perceptron, and support vector machines (SVM). The dataset used contains 843 regions of interest (ROI) of healthy and five pathologic lung tissue patterns identified by two radiologists at the University Hospitals of Geneva. Correlation of the feature space composed of 39 texture attributes is studied. A grid search for optimal parameters is carried out for each classifier family. Two complementary metrics are used to characterize the performances of classification. These are based on McNemar's statistical tests and global accuracy. SVM reached best values for each metric and allowed a mean correct prediction rate of 88.3% with high class-specific precision on testing sets of 423 ROIs.								4	0	1	0	4	0897-1889		WOS:000273853400004	
J	Chuang, L. -Y.; Yang, C. -S.; Wu, K. -C.; Yang, C. -H.								Correlation-based Gene Selection and Classification Using Taguchi-BPSO								METHODS OF INFORMATION IN MEDICINE			49	3			254	268		10.3414/ME09-01-0010			2010	2010	Background: Microarray data with reference to gene expression profiles have provided some valuable results related to a variety of problems, and contributed to advances in clinical medicine. Microarray data characteristically have a high dimension and small sample size, which makes it difficult for a general classification method to obtain correct data for classification. However, not every gene is potentially relevant for distinguishing the sample class. Thus, in order to analyze gene expression profiles correctly, feature (gene) selection is crucial for the classification process, and an effective gene extraction method is necessary for eliminating irrelevant genes and decreasing the classification error rate.Objective: The purpose of gene expression analysis is to discriminate between classes of samples, and to predict the relative importance of each gene for sample classification.Method: In this paper, correlation-based feature selection (CFS) and Taguchi-binary particle swarm optimization (TBPSO) were combined into a hybrid method, and the K-nearest neighbor (K-NN) with leave-one-out cross-validation (LOOCV) method served as a classifier for ten gene expression profiles.Results: Experimental results show that this hybrid method effectively simplifies feature selection by reducing the number of features needed. The classification error rate obtained by the proposed method had the lowest classification error rate for all of the ten gene expression data set problems tested. For six of the gene expression profile data sets a classification error rate of zero could be reached.Conclusion: The introduced method outperformed five other methods from the literature in terms of classification error rate. It could thus constitute a valuable tool for gene expression analysis in future studies.								4	0	1	0	4	0026-1270		WOS:000278818400006	
S	Sreenivasulu, Nese; Sunkar, Ramanjulu; Wobus, Ulrich; Strickert, Marc						Sunkar, R		Array Platforms and Bioinformatics Tools for the Analysis of Plant Transcriptome in Response to Abiotic Stress								PLANT STRESS TOLERANCE: METHODS AND PROTOCOLS	Methods in Molecular Biology		639				71	93		10.1007/978-1-60761-702-0_5	10.1007/978-1-60761-702-0		2010	2010	Current microarray technologies allow high-density in situ synthesis of oligonucleotides or ex situ spotting of target molecules (cDNA) for conducting genome-wide comparative gene expression profiling studies. The avalanche of available microarray gene expression data from model plant species covering cell-related, tissue-specific, and developmental events, as well as perturbations to a variety of environmental stimuli has triggered many activities regarding the development of adequate bioinformatics tools for the analysis of these complex data sets. In this chapter we summarize the technical issues of different microarray technologies, discuss the availability of bioinformatics tools, and present approaches to extract biologically meaningful knowledge. For case studies of abiotic stress transcriptome analysis we highlight the unprecedented opportunities provided by these high-throughput technologies to understand networks of regulatory and metabolic pathway responses of plant cells to the application of abiotic stress stimuli.								4	1	4	0	5	1064-3745	978-1-60761-701-3	WOS:000278106400005	
J	Chaudhuri, Probal; Ghosh, Anil K.; Oja, Hannu								Classification Based on Hybridization of Parametric and Nonparametric Classifiers								IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			31	7			1153	1164		10.1109/TPAMI.2008.149			JUL 2009	2009	Parametric methods of classification assume specific parametric models for competing population densities (e. g., Gaussian population densities can lead to linear and quadratic discriminant analysis) and they work well when these model assumptions are valid. Violation in one or more of these parametric model assumptions often leads to a poor classifier. On the other hand, nonparametric classifiers (e. g., nearest-neighbor and kernel-based classifiers) are more flexible and free from parametric model assumptions. But, the statistical instability of these classifiers may lead to poor performance when we have small numbers of training sample observations. Nonparametric methods, however, do not use any parametric structure of population densities. Therefore, even when one has some additional information about population densities, that important information is not used to modify the nonparametric classification rule. This paper makes an attempt to overcome these limitations of parametric and nonparametric approaches and combines their strengths to develop some hybrid classification methods. We use some simulated examples and benchmark data sets to examine the performance of these hybrid discriminant analysis tools. Asymptotic results on their misclassification rates have been derived under appropriate regularity conditions.								4	1	1	0	5	0162-8828		WOS:000266188900001	
J	Kodell, Ralph L.; Pearce, Bruce A.; Baek, Songjoon; Moon, Hojin; Ahn, Hongshik; Young, John F.; Chen, James J.								A model-free ensemble method for class prediction with application to biomedical decision making								ARTIFICIAL INTELLIGENCE IN MEDICINE			46	3			267	276		10.1016/j.artmed.2008.11.001			JUL 2009	2009	Objective: A classification algorithm that utilizes two-dimensional convex hulls of training-set samples is presented.Methods and material: For each pair of predictor variables, separate convex hulls of positive and negative samples in the training set are formed, and these convex hulls are used to classify test points according to a nearest-neighbor criterion. An ensemble of these two-dimensional convex-hull classifiers is formed by trimming the (m)C(2) possible classifiers derived from the m predictors to a set of classifiers comprised of only unique predictor variables. Because only two-dimensional spaces are required to be populated by training-set samples, the "curse of dimensionality" is not an issue. At the same time, the power of ensemble voting is exploited by combining the classifications of the unique two-dimensional classifiers to reach a final classification.Results: The algorithm is illustrated by application to three publicly available biomedical data sets with genomic predictors and is shown to have prediction accuracy that is competitive with a number of published classification procedures.Conclusion: Because of its superior performance in terms of sensitivity and negative predictive value compared to its competitors, the convex-hull ensemble classifier demonstrates good potential for medical screening, where often the major emphasis is placed on having reliable negative predictions. (C) 2008 Elsevier B.V. All rights reserved.								4	0	1	0	4	0933-3657		WOS:000268043000006	
J	Li, Fayin; Wechsler, Harry								FACE AUTHENTICATION USING RECOGNITION-BY-PARTS, BOOSTING AND TRANSDUCTION								INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			23	3			545	573					MAY 2009	2009	The paper describes an integrated recognition-by-parts architecture for reliable and robust face recognition. Reliability and robustness are characteristic of the ability to deploy full-fledged and operational biometric engines, and handling adverse image conditions that include among others uncooperative subjects, occlusion, and temporal variability, respectively. The architecture proposed is model-free and non-parametric. The conceptual framework draws support from discriminative methods using likelihood ratios. At the conceptual level it links forensics and biometrics, while at the implementation level it links the Bayesian framework and statistical learning theory (SLT). Layered categorization starts with face detection using implicit rather than explicit segmentation. It proceeds with face authentication that involves feature selection of local patch instances including dimensionality reduction, exemplar-based clustering of patches into parts, and data fusion for matching using boosting driven by parts that play the role of weak-learners. Face authentication shares the same implementation with face detection. The implementation, driven by transduction, employs proximity and typicality (ranking) realized using strangeness and p-values, respectively. The feasibility and reliability of the proposed architecture are illustrated using FRGC data. The paper concludes with suggestions for augmenting and enhancing the scope and utility of the proposed architecture.								4	0	0	0	4	0218-0014		WOS:000267114600009	
J	Kianmehr, Keivan; Alhajj, Reda								Calling communities analysis and identification using machine learning techniques								EXPERT SYSTEMS WITH APPLICATIONS			36	3			6218	6226		10.1016/j.eswa.2008.07.072			APR 2009	2009	The analysis of social communities related logs has recently received considerable attention for its importance in shedding light on social concerns by identifying different groups, and hence helps in resolving issues like predicting terrorist groups. In the customer analysis domain, identifying calling communities can be used for determining a particular customer's value according to the general pattern behavior of the community that the customer belongs to; this helps the effective targeted marketing design, which is Significantly important for increasing profitability. In telecommunication industry, machine learning techniques have been applied to the Call Detail Record (CDR) for predicting customer behavior such as churn prediction. In this paper, we pursue identifying the calling communities and demonstrate how cluster analysis can be used to effectively identify communities using information derived from the CDR data. We use the information extracted from the cluster analysis to identify customer calling patterns. Customers calling patterns are then given to a classification algorithm to generate a classifier model for predicting the calling communities of a customer. We apply different machine learning techniques to build classifier models and compare them in terms of classification accuracy and computational performance. The reported test results demonstrate the applicability and effectiveness of the proposed approach. (C) 2008 Elsevier Ltd. All rights reserved.								4	0	0	0	4	0957-4174		WOS:000263817100058	
J	Satapathy, Suresh Chandra; Murthy, J. V. R.; Reddy, P. V. G. D. Prasad; Misra, B. B.; Dash, P. K.; Panda, G.								Particle swarm optimized multiple regression linear model for data classification								APPLIED SOFT COMPUTING			9	2			470	476		10.1016/j.asoc.2008.05.007			MAR 2009	2009	This paper presents a new data classification method based on particle swarm optimization (PSO) techniques. The paper discusses the building of a classifier model based on multiple regression linear approach. The coefficients of multiple regression linear models (MRLMs) are estimated using least square estimation technique and PSO techniques for percentage of correct classification performance comparisons. The mathematical models are developed for many real world datasets collected from UCI machine repository. The mathematical models give the user an insight into how the attributes are interrelated to predict the class membership. The proposed approach is illustrated on many real data sets for classification purposes. The comparison results on the illustrative examples show that the PSO based approach is superior to traditional least square approach in classifying multi-class data sets. (c) 2008 Elsevier B.V. All rights reserved.								4	0	0	0	4	1568-4946		WOS:000262888100003	
J	Steele, Brian M.								Exact bootstrap k-nearest neighbor learners								MACHINE LEARNING			74	3			235	255		10.1007/s10994-008-5096-0			MAR 2009	2009	Bootstrap aggregation, or bagging, is a method of reducing the prediction error of a statistical learner. The goal of bagging is to construct a new learner which is the expectation of the original learner with respect to the empirical distribution function. In nearly all cases, the expectation cannot be computed analytically, and bootstrap sampling is used to produce an approximation. The k-nearest neighbor learners are exceptions to this generalization, and exact bagging of many k-nearest neighbor learners is straightforward. This article presents computationally simple and fast formulae for exact bagging of k-nearest neighbor learners and extends exact bagging methods from the conventional bootstrap sampling (sampling n observations with replacement from a set of n observations) to bootstrap sub-sampling schemes (with and without replacement). In addition, a partially exact k-nearest neighbor regression learner is developed. The article also compares the prediction error associated with elementary and exact bagging k-nearest neighbor learners, and several other ensemble methods using a suite of publicly available data sets.								4	0	1	0	4	0885-6125		WOS:000263382900001	
J	Vaidya, Jaideep; Clifton, Christopher W.								Privacy-Preserving Kth Element Score over Vertically Partitioned Data								IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			21	2			253	258		10.1109/TKDE.2008.167			FEB 2009	2009	Given a large integer data set shared vertically by two parties, we consider the problem of securely computing a score separating the kth and the (k+1)th element. An efficient secure protocol is developed to compute such a score while revealing little additional information. The proposed protocol is implemented using the Fairplay system and experimental results are reported. We show a real application of this protocol as a component used in the secure processing of top-k queries over vertically partitioned data.								4	1	0	0	5	1041-4347		WOS:000261813800007	
J	Kyperountas, Marios; Tefas, Anastasios; Pitas, Loannis				Tefas, Anastasios/F-1899-2010				Dynamic training using multistage clustering for face recognition								PATTERN RECOGNITION			41	3			894	905		10.1016/j.patcog.2007.06.017			MAR 2008	2008	A novel face recognition algorithm that uses dynamic training in a multistage clustering scheme is presented and evaluated. This algorithm uses discriminant analysis to project the face classes and a clustering algorithm to partition the projected face data, thus forming a set of discriminant clusters. Then, an iterative process creates subsets, whose cardinality is defined by an entropy-based measure, that contain the most useful clusters. The best match to the test face is found when only a single face class is retained. This method was tested on the ORL, XM2VTS and FERET face databases, whereas the UMIST database was used in order to train the proposed algorithm. Experimental results indicate that the proposed framework provides a promising solution to the face recognition problem. (C) 2007 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.								4	0	2	0	4	0031-3203		WOS:000251357100011	
J	Kubotaa, Ryosuke; Uchino, Eiji; Suetake, Noriaki								Hierarchical k-nearest neighbor classification using feature and observation space information								IEICE ELECTRONICS EXPRESS			5	3			114	119		10.1587/elex.5.114			FEB 10 2008	2008	A novel hierarchical k-nearest neighbor classification method using the feature and observation space information is proposed. The present method performs a fine classification when a pair of the spatial coordinate of the observation data in the observation space and its corresponding feature vector in the feature space is provided.								4	0	0	0	4	1349-2543		WOS:000255481700006	
J	Farcomeni, Alessio; Serranti, Silvia; Bonifazi, Giuseppe								Non-parametric analysis of infrared spectra for recognition of glass and glass ceramic fragments in recycling plants								WASTE MANAGEMENT			28	3			557	564		10.1016/j.wasman.2007.01.019			2008	2008	Glass ceramic detection in glass recycling plants represents a still unsolved problem, as glass ceramic material looks like normal glass and is usually detected only by specialized personnel. The presence of glass-like contaminants inside waste glass products, resulting from both industrial and differentiated urban waste collection, increases process production costs and reduces final product quality. In this paper an innovative approach for glass ceramic recognition, based on the non-parametric analysis of infrared spectra, is proposed and investigated. The work was specifically addressed to the spectral classification of glass and glass ceramic fragments collected in an actual recycling plant from three different production lines: flat glass, colored container-glass and white container-glass. The analyses, carried out in the near and mid-infrared (NIR-MIR) spectral field (1280-4480 nm), show that glass ceramic and glass fragments can be recognized by applying a wavelet transform, with a small classification error. Moreover, a method for selecting only a small subset of relevant wavelength ratios is suggested, allowing the conduct of a fast recognition of the two classes of materials. The results show how the proposed approach can be utilized to develop a classification engine to be integrated inside a hardware and software sorting architecture for fast "on-line" ceramic glass recognition and separation. (C) 2007 Elsevier Ltd. All rights reserved.								4	0	0	0	4	0956-053X		WOS:000253097600012	
J	Tang, Yaohua; Gao, Jinghuai								Improved classification for problem involving overlapping patterns								IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS			E90D	11			1787	1795		10.1093/ietisy/e90-d.11.1787			NOV 2007	2007	The support vector machine has received wide acceptance for its high generalization ability in real world classification applications. But a drawback is that it uniquely classifies each pattern to one class or none. This is not appropriate to be applied in classification problem involves overlapping patterns. In this paper, a novel multi-model classifier (DR-SVM) which combines SVM classifier with kNN algorithm under rough set technique is proposed. Instead of classifying the patterns directly, patterns lying in the overlapped region are extracted firstly. Then, upper and lower approximations of each class are defined on the basis of rough set technique. The classification operation is carried out on these new sets. Simulation results on synthetic data set and benchmark data sets indicate that, compared with conventional classifiers, more reasonable and accurate information about the pattern's category could be obtained by use of DR-SVM.								4	1	0	0	5	0916-8532		WOS:000251226900007	
J	Aluja-Banet, Tomas; Daunis-i-Estadella, Josep; Pellicer, David								GRAFT, a complete system for data fusion								COMPUTATIONAL STATISTICS & DATA ANALYSIS			52	2			635	649		10.1016/j.csda.2006.11.029			OCT 15 2007	2007	Data fusion concerns the problem of merging information coming from independent sources. Also known as statistical matching, file grafting or microdata merging, it is a challenging problem for statisticians. The increasing growth of collected data makes combining different sources of information an attractive alternative to single source data. The interest in data fusion derives, in certain cases, from the impossibility of attaining specific information from one source of data and the reduction of the cost entailed by this operation and, in all cases, from taking greater advantage of the available collected information. The GRAFT system is presented. It is a multipurpose data fusion system based on the k-nearest neighbor (k-nn) hot deck imputation method. The system aim is to cope with many data fusion problems and domains. The k-nn is a very demanding algorithm. The solutions envisaged and their cost, which allow this methodology to be used in a wide range of real problems, are presented. (C) 2006 Elsevier B.V. All rights reserved.								4	0	1	0	4	0167-9473		WOS:000253365300003	
J	Read, Ian; Cox, Stephen								Stochastic and syntactic techniques for predicting phrase breaks								COMPUTER SPEECH AND LANGUAGE			21	3			519	542		10.1016/j.csl.2006.09.004			JUL 2007	2007	Determining the position of breaks in a sentence is a key task for a text-to-speech system. A synthesized sentence containing incorrect breaks at best requires increased listening effort, and at worst, may have lower intelligibility and different semantics from a correctly phrased sentence. In addition, the position of breaks must be known before other components of the sentence's prosodic structure can be determined. We consider here some methods for phrase break prediction in which the whole sentence is analysed, in contrast to most previous work which has focused on analysing an area around an individual juncture. One of the main features we use is part-of-speech tags. First, we report an algorithm that reduces the number of tags in the tagset whilst improving break prediction accuracy. We then describe three approaches to break prediction: by analogy, in which we find the best-matching sentence in our training data to the unseen sentence; by phrase modelling, in which we build stochastic models of phrases and use these, together with a "phrase grammar", to segment the unseen sentence; and finally, using features derived from a syntactic parse of the sentence. All techniques achieve well above our baseline performance, which used punctuation symbols to determine break positions, and performance increased with each successive technique. Our best result, obtained on the MARSEC corpus and using a combination of parse tree derived features and a local feature, gave an F score of 81.6%, which we believe to be the highest published on this dataset. (c) 2006 Published by Elsevier Ltd.								4	1	0	0	5	0885-2308		WOS:000245355600006	
J	Carrizosa, Emilio; Martin-Barragan, Belen; Plastria, Frank; Morales, Dolores Romero								On the selection of the globally optimal prototype subset for nearest-neighbor classification								INFORMS JOURNAL ON COMPUTING			19	3			470	479		10.1287/ijoc.1060.0183			SUM 2007	2007	The nearest-neighbor classifier has been shown to be a powerful tool for multiclass classification. We explore both theoretical properties and empirical behavior of a variant method, in which the nearest-neighbor rule is applied to a reduced set of prototypes. This set is selected a priori by fixing its cardinality and minimizing the empirical misclassification cost. In this way we alleviate the two serious drawbacks of the nearest-neighbor method: high storage requirements and time-consuming queries. Finding this reduced set is shown to be NP-hard. We provide mixed integer programming (MIP) formulations, which are theoretically compared and solved by a standard MIP solver for small problem instances. We show that the classifiers derived from these formulations are comparable to benchmark procedures. We solve large problem instances by a metaheuristic that yields good classification rules in reasonable time. Additional experiments indicate that prototype-based nearest-neighbor classifiers remain quite stable in the presence of missing values.								4	0	0	0	4	1091-9856		WOS:000248990800014	
J	Yang, Mary Q.; Yang, Jack Y.; Ersoy, Okan K.				jia, lp/H-5750-2011				Classification of proteins multiple-labelled and single-labelled with protein functional classes								INTERNATIONAL JOURNAL OF GENERAL SYSTEMS			36	1			91	109		10.1080/03081070600950868			FEB 2007	2007	Advances in high-throughput genome sequencing technology have led to an explosion in the amount of sequence data that are available. The determination of protein function using experimental techniques is time-consuming and expensive; the use of machine-learning techniques rapidly to assess protein function may be useful in streamlining this process. The problem of assigning functional classes to proteins is complicated by the fact that a single protein can participate in several different pathways and thus can have multiple functions. We have developed a tree-based classifier that is capable of handling multiple-labelled data and gaining an insight into the multi-functional nature of proteins. We call the resulting tree a recursive maximum contrast tree (RMCT) and the resulting classifier a multiple-labelled instance classifier (MLIC). We investigate the synergy of machine-learning-based ensemble methods and physiochemical-based feature augments. We test our algorithm on protein phylogenetic profiles generated from 60 completely sequenced genomes and we compare our results with those achieved by algorithms such as support vector machines and decision trees.								4	0	4	0	5	0308-1079		WOS:000242767200005	
S	Bosin, Andrea; Dessi, Nicoletta; Pes, Barbara						Yin, H; Tino, P; Corchado, E; Byrne, W; Yao, X		Capturing heuristics and intelligent methods for improving micro-array data classification								INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING - IDEAL 2007	LECTURE NOTES IN COMPUTER SCIENCE		4881				790	799					2007	2007	Classification of micro-array data has been studied extensively but only a small amount of research work has been done on classification of micro-array data involving more than two classes. This paper proposes a learning strategy that deals with building a multi-target classifier and takes advantage from well known data mining techniques. To address the intrinsic difficulty of selecting features in order to promote the classification accuracy, the paper considers the use of a set of binary classifiers each of ones is devoted to predict a single class of the multi-classification problem. These classifiers are similar to local experts whose knowledge (about the features that are most correlated to each class value) is taken into account by the learning strategy for selecting an optimal set of features. Results of the experiments performed on a publicly available dataset demonstrate the feasibility of the proposed approach.				8th International Conference on Intelligent Data Engineering and Automated Learning	DEC 16-19, 2007		Birmingham, ENGLAND	4	0	0	0	4	0302-9743	978-3-540-77225-5	WOS:000252394900079	
S	Massie, Stewart; Craw, Susan; Wiratunga, Nirmalie						Weber, RO; Richter, MM		When similar problems don't have similar solutions								CASE-BASED REASONING RESEARCH AND DEVELOPMENT, PROCEEDINGS	Lecture Notes in Computer Science		4626				92	106					2007	2007	The performance of a Case-Based Reasoning system relies on the integrity of its case base but in real life applications the available data used to construct the case base invariably contains erroneous, noisy cases. Automated removal of these noisy cases can improve system accuracy. In addition, error rates for nearest neighbour classifiers can often be reduced by removing cases to give smoother decision boundaries between classes. In this paper we argue that the optimal level of boundary smoothing is domain dependent and, therefore, our approach to error reduction reacts to the characteristics of the domain to set an appropriate level of smoothing. We present a novel, yet transparent algorithm, Threshold Error Reduction, which identifies and removes noisy and boundary cases with the aid of a local complexity measure. Evaluation results confirm it to be superior to benchmark algorithms.				7th International Conference on Case-Based Reasoning	AUG 13-16, 2007	DFKI; Drexel iSch; empolis; Univ Ulster; Zerosolution	Belfast, NORTH IRELAND	4	0	0	0	4	0302-9743	978-3-540-74138-1	WOS:000249814900007	
J	Huang, Chi-Chun								A novel gray-based reduced NN classification method								PATTERN RECOGNITION			39	11			1979	1986		10.1016/j.patcog.2006.05.013			NOV 2006	2006	In pattern recognition, instance-based learning (also known as nearest neighbor rule) has become increasingly popular and can yield excellent performance. In instance-based learning, however, the storage of training set rises along with the number of training instances. Moreover, in such a case, a new, unseen instance takes a long time to classify because all training instances have to be considered when determining the 'nearness' or 'similarity' among instances. This study presents a novel reduced classification method for instance-based learning based on the gray relational structure. Here, only some training instances in the original training set are adopted for the pattern classification tasks. The relationships among instances are first determined according to the gray relational structure. In the relational structure, the inward edoes of each training instance, indicating how many times each instance is considered as the nearest neighbor or neighbors in determining the class labels of other instances can be obtained. This method excludes training instances with no or few inward edges for the pattern classification tasks. By using the proposed instance pruning approach, new instances can be classified with a few training instances. Nine data sets are adopted to demonstrate the performance of the proposed learning approach. Experimental results indicate that the classification accuracy can be maintained when most of the training instances are pruned before learning. Additionally, the number of remained training instances in the proposal presented here is comparable to that of other existing instance pruning techniques. (c) 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.								4	0	0	0	4	0031-3203		WOS:000240156500003	
J	Hammouche, K; Diaf, M; Postaire, JG								A clustering method based on multidimensional texture analysis								PATTERN RECOGNITION			39	7			1265	1277		10.1016/j.patcog.2005.11.024			JUL 2006	2006	Considering the analogy between image segmentation and cluster analysis, the aim of this paper is to adapt statistical texture measures to describe the spatial distribution of multidimensional observations. The main idea is to consider the cluster cores as domains characterized by their specific textures in the data space. The distribution of the data points is first described as a multidimensional histogram defined on a multidimensional regular array of sampling points. In order to evaluate locally a multidimensional texture, a co-occurrence matrix is introduced, which characterizes the local distribution of the data points in the multidimensional data space. Several local texture features can be computed from this co-occurrence matrix, which accumulates spatial and statistical information on the data distribution in the neighborhoods of the sampling points. Texture features are selected according to their ability to discriminate different distributions of data points. The sampling points where the local underlying texture is evaluated are categorized into different texture classes. The points assigned to these classes tend to form connected components in the data space, which are considered as the cores of the clusters. (c) 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.								4	0	0	0	4	0031-3203		WOS:000237588800005	
J	Gombar, Vijay K.; Alberts, James J.; Cassidy, Kenneth C.; Mattioni, Brian E.; Mohutsky, Michael A.								In Silico Metabolism Studies in Drug Discovery: Prediction of Metabolic Stability								CURRENT COMPUTER-AIDED DRUG DESIGN			2	2			177	188		10.2174/157340906777441726			JUN 2006	2006	The strategy to screen compounds solely for pharmacological potency and selectivity in the early stages of drug discovery brought the pharmaceutical industry to face the stark reality of disproportionate attrition later in the development stage due to poor drug disposition characteristics. This attrition contributed to the exorbitant costs of discovering and developing drugs. Considering ADME (Absorption, Distribution, Metabolism, and Excretion) characteristics of compounds early in the discovery process can wisely direct resources to compounds that have greater potential to survive the clinical trial stages of drug development. However, experimental determination of ADME characteristics is not practical for large numbers of compounds. Therefore, focus is being centered on bringing in silico approaches earlier in the discovery process to assess ADME properties solely from molecular structure. Given that metabolism is one of the most important of the ADME properties, in this paper we review a number of metabolism in silico tools and models that have potential applications in drug discovery. We then describe a step-by-step process, as practiced in our laboratories, to construct and deploy reliable in silico metabolic stability and other ADME screens. Additionally, we give examples of the application of our metabolic stability in silico screens in scaffold selection, ADME space enrichment, and rationalizing synthesis and testing of compounds in the drug discovery process. Agreements between the experimental and in silico metabolic stability values ranging from 84% to 100% have convinced many discovery project teams to routinely use these in silico models. Finally, we present our ideas on the successful implementation of in silico models and tools for significant impact on drug discovery and development.								4	0	3	0	5	1573-4099		WOS:000207959000008	
J	Liu, Ting; Moore, Andrew W.; Gray, Alexander								New algorithms for efficient high-dimensional nonparametric classification								JOURNAL OF MACHINE LEARNING RESEARCH			7				1135	1158					JUN 2006	2006	This paper is about non-approximate acceleration of high-dimensional nonparametric operations such as k nearest neighbor classifiers. We attempt to exploit the fact that even if we want exact answers to nonparametric queries, we usually do not need to explicitly find the data points close to the query, but merely need to answer questions about the properties of that set of data points. This offers a small amount of computational leeway, and we investigate how much that leeway can be exploited. This is applicable to many algorithms in nonparametric statistics, memory-based learning and kernel-based learning. But for clarity, this paper concentrates on pure k-NN classification. We introduce new ball-tree algorithms that on real-world data sets give accelerations from 2-fold to 100-fold compared against highly optimized traditional ball-tree-based k-NN. These results include data sets with up to 106 dimensions and 105 records, and demonstrate non-trivial speed-ups while giving exact answers.								4	1	2	0	5	1532-4435		WOS:000245388400010	
S	Guillas, Stephanie; Bertet, Karell; Ogier, Jean-Marc						Liu, W; Llados, J		A generic description of the concept lattices' classifier: Application to symbol recognition								GRAPHICS RECOGNITION: TEN YEARS REVIEW AND FUTURE PERSPECTIVES	LECTURE NOTES IN COMPUTER SCIENCE		3926				47	60					2006	2006	In this paper, we present the problem of noisy images recognition and in particular the stage of primitives selection in a classification process. We suppose that segmentation and statistical features extraction on documentary images are realized. We describe precisely the use of concept lattice and compare it with a decision tree in a recognition process. From the experimental results, it appears that concept lattice is more adapted to the context of noisy images.				6th International Workshop on Graphic Recognition	AUG 25-26, 2005	City Univ Hong Kong; IAPR; K C Wong Educ Fdn; Hong Kong Web Soc	Hong Kong, PEOPLES R CHINA	4	0	0	0	4	0302-9743	3-540-34711-9	WOS:000240036000005	
S	Zhang, Ying; Wu, Ke; Gao, Jianfeng; Vines, Phil						Lalmas, M; MacFarlane, A; Ruger, S; Tombros, A; Tsikrika, T; Yavlinsky, A		Automatic acquisition of Chinese-English parallel corpus from the web								ADVANCES IN INFORMATION RETRIEVAL	LECTURE NOTES IN COMPUTER SCIENCE		3936				420	431					2006	2006	Parallel corpora are a valuable resource for tasks such as cross-language information retrieval and data-driven natural language processing systems. Previously only small scale corpora have been available, thus restricting their practical use. This paper describes a system that overcomes this limitation by automatically collecting high quality parallel bilingual corpora from the web. Previous systems used a single principle feature for parallel web page verification, whereas we use multiple features to identify parallel texts via a k-nearest-neighbor classifier. Our system was evaluated using a data set containing 6500 Chinese-English candidate parallel pairs that have been manually annotated. Experiments show that the use of a k-nearest-neighbors classifier with multiple features achieves substantial improvements over the systems that use any one of these features. The system achieved a precision rate of 95% and a recall rate of 97%, and thus is a significant improvement over earlier work.				28th European Conference on Information Retrieval (ECIR 2006)	APR   10, 2005-APR 12, 2006	Queen Mary Univ London; City Univ; Engn & Phys Sci Res Council; CEPIS; Google; GCHQ; Microsoft Res; Yahoo Res; Sharp; Apriorie; Lemur Consulting; MMKM; Elsevier	Imperial Coll London, S Kensington, London, ENGLAND	4	1	1	0	5	0302-9743	3-540-33347-9	WOS:000238083200037	
J	Allouche, MK; Moulin, B				Wright, Dawn/A-4518-2011	Wright, Dawn/0000-0002-2997-7611			Amalgamation in cartographic generalization using Kohonen's feature nets								INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE			19	8-9			899	914		10.1080/13658810500161211			SEP-OCT 2005	2005	Empirical observations of the way cartographers deal with generalization problems lead to the hypothesis that they first detect patterns of anomalies in the cartographic data set and then eliminate anomalies by transforming the data. Automatically identifying patterns of anomalies on the map is a difficult task when using GIS functions or traditional algorithmic approaches. Techniques based on the use of neural networks have been widely used in artificial intelligence in order to solve pattern-recognition problems. In this paper, we explore how Kohonen-type neural networks can be used to deal with map generalization applications in which the main problem is to identify high-density regions that include cartographic elements of the same type. We also propose an algorithm to replace cartographic elements located in a region by its surrounding polygon. The use of this type of neural network permitted us to generate different levels of grouping according to the chosen zoom-scale on the map. These levels correspond to a multiple representation of the generalized cartographic elements. As an illustration, we apply our approach to the automatic replacement of a group of houses represented as a set of very close points in the original data set, by a polygon representing the corresponding urban area in the generalized map.								4	2	0	0	6	1365-8816		WOS:000232661400003	
J	Viswanath, P; Murty, MN; Bhatnagar, S								Overlap pattern synthesis with an efficient nearest neighbor classifier								PATTERN RECOGNITION			38	8			1187	1195		10.1016/j.patcog.2004.10.007			AUG 2005	2005	Nearest neighbor (NN) classifier is the most popular non-parametric classifier. It is a simple classifier with no design phase and shows good performance. Important factors affecting the efficiency and performance of NN classifier are (i) memory required to store the training set, (ii) classification time required to search the nearest neighbor of a given test pattern, and (iii) due to the curse of dimensionality the number of training patterns needed by it to achieve a given classification accuracy becomes prohibitively large when the dimensionality of the data is high. In this paper, we propose novel techniques to improve the performance of NN classifier and at the same time to reduce its computational burden. These techniques are broadly based on: (i) overlap based pattern synthesis which can generate a larger number of artificial patterns than the number of input patterns and thus can reduce the curse of dimensionality effect, (ii) a compact representation of the given set of training patterns called overlap pattern graph (OLP-graph) which can be incrementally built by scanning the training set only once and (iii) an efficient NN classifier called OLP-NNC which directly works with OLP-graph and does implicit overlap based pattern synthesis. A comparison based on experimental results is given between some of the relevant classifiers. The proposed schemes are suitable for applications dealing with large and high dimensional datasets like those in data mining. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.								4	0	1	0	4	0031-3203		WOS:000229669900004	
B	Marchiori, E; Heegaard, NHH; West-Nielsen, M; Jimenez, CR			IEEE					Feature selection for classification with proteomic data of mixed quality								Proceedings of the 2005 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology							385	391					2005	2005	In this paper we assess experimentally the performance of two state-of-the-art feature selection methods, called RFE and RELIEF, when used for classifying pattern proteomic samples of mixed quality. The data are generated by spiking human sera to artificially create differentiable sample groups, and by handling samples at different storage temperature. We consider two type of classifiers: support vector machines (SVM) and k-nearest neighbour (kNN). Results of leave-one-out cross validation (LOOCV) experiments indicate that RELIEF selects more stable feature subsets than RFE over the runs, where the selected features are mainly spiked ones. However, RFE outperforms RELIEF in terms of (average LOOCV) accuracy, both when combined with SVM and kNN. Perfect LOOCV accuracy is obtained by RFE combined with INN. Almost all the samples that are wrongly classified by the algorithms have high storage temperature. The results of experiments on this data indicate that when samples of mixed quality are analyzed computationally, feature selection of only relevant (spiked) features does not necessarily correspond to highest accuracy of classification.				2nd IEEE Symposium on Computational Intelligence in Bioformatics and Computational Biology	NOV 14-15, 2005	IEEE Computat Intelligence Soc	La Jolla, CA	4	0	2	0	4		0-7803-9387-2	WOS:000235518600054	
S	Mignani, AG; Ciaccheri, L; Smith, PR; Cimato, A; Attilio, C; Huertas, R; Latorre, MM; Bertho, AC; O'Rourke, B; McMillan, ND						Voet, M; Willsch, R; Ecke, W; Jones, J; Culshaw, B		Scattered colorimetry and multivariate data processing as an objective tool for liquid mapping					1-2			17th International Conference on Optical Fibre Sensors, Pts 1 and 2	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		5855				38	41		10.1117/12.623388			2005	2005	Scattered colorimetry, i.e., multi-angle and multi-wavelength absorption spectroscopy performed in the visible spectral range, was used to map three kinds of liquids: extra virgin olive oils, frying oils, and detergents in water. By multivariate processing of the spectral data, the liquids could be classified according to their intrinisic characteristics: geographic area of extra virgin olive oils, degradation of frying oils, and surfactant types and mixtures in water.				17th International Conference on Optical Fibre Sensors	MAY 23-27, 2005	I D FOS Res; Fibre Opt Sensors & Sensing Syst; European Off Aerosp Res & Dev; USAF Res Lab; Network Excellence Micro Opt; SCK CEN, Belgian Nucl Res Ctr; FWO; FNRS; Export Flanders; Flanders Foreign Investment Off; ESF; European Opt Soc; Inst Phys; IEEE; SPIE; Inst Measurement & Control UK; IEEE LEOS; Opt Soc Amer; AMA German Sensor Technol Assoc; DGaO German Soc Appl Opt; OptecNet German Network Competence Opt Photon Technologies; Sensors Web Portal	Brugge, BELGIUM	4	0	0	0	4	0277-786X	0-8194-5855-4	WOS:000231443000009	
S	Milner, GM						Carapezza, EM		Detection/classification/quantification of chemical agents using an array of surface acoustic wave (SAW) devices					1-2			Sensors, and Command, Control, Communications, and Intelligence (C31) Technologies for Homeland Security and Homeland Defense IV, Pts 1 and 2	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		5778				305	316		10.1117/12.611372			2005	2005	ChemSentry (TM) is a portable system used to detect, identify, and quantify chemical warfare (CW) agents. Electro chemical (EC) cell sensor technology is used for blood agents and an array of surface acoustic wave (SAW) sensors is used for nerve and blister agents. The combination of the EC cell and the SAW array provides sufficient sensor information to detect, classify and quantify all CW agents of concern using smaller, lighter, lower cost units.Initial development of the SAW array and processing was a key challenge for ChemSentry (TM) requiring several years of fundamental testing of polymers and coating methods to finalize the sensor array design in 2001. Following the finalization of the SAW array, nearly three (3) years of intensive testing in both laboratory and field environments were required in order to gather sufficient data to fully understand the response characteristics. Virtually unbounded permutations of agent characteristics and environmental characteristics must be considered in order to operate against all agents and all environments of interest to the U.S. military and other potential users of ChemSentry (TM). The resulting signal processing design matched to this extensive body of measured data (over 8,000 agent challenges and 10,000 hours of ambient data) is considered to be a significant advance in state-of-the-art for CW agent detection.				Conference on Sensors, and Command, Control, Communications, and Intelligence (C31) Technologies for Homeland Security and Homeland Defense IV	MAR 28-APR 01, 2005		Orlando, FL	4	0	0	0	4	0277-786X	0-8194-5763-9	WOS:000230925700032	
J	Linnell, TA; Deravi, F				Deravi, Farzin/E-7190-2013	Deravi, Farzin/0000-0003-0885-437X			Mapping vector accumulator: fractal domain feature for character recognition								ELECTRONICS LETTERS			40	22			1406	1407		10.1049/el:20046478			OCT 28 2004	2004	A new feature is presented which is calculated directly from the fractal-compressed form of images. The performance of this feature is analysed by using it in the training of standard classifiers for a character recognition problem. The feature is shown to be translation invariant, giving it an advantage over methods that use pixels or compressed data directly.								4	0	0	0	4	0013-5194		WOS:000225106800014	
J	Wyns, B; Boullart, L; Sette, S; Baeten, D; Hoffman, I; De Keyser, F								Prediction of arthritis using a modified Kohonen mapping and case based reasoning								ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE			17	2			205	211		10.1016/j.engappai.2004.02.007			MAR 2004	2004	Rheumatoid arthritis and spondyloarthropathy are the two most frequent forms of chronic autoimmune arthritis. These diseases lead to important inflammatory symptoms resulting in an important functional impairment. In this paper we apply a topological mapping combined with a case based reasoning evaluation criterion to predict early arthritis. The first part presents a brief introduction to the problem and self-learning neural networks while the second part of this paper will apply this technique together with a case based reasoning evaluation criterion to diagnostic classification. Finally the paper shows that the Kohonen neural network achieves good performance that exceeds the results of other neural network approaches and decision trees. (C) 2004 Elsevier Ltd. All rights reserved.								4	0	1	0	4	0952-1976		WOS:000221434400008	
S	Everson, RM; Fieldsend, JE						Yang, ZR; Everson, R; Yin, H		A variable metric probabilistic k-nearest-neighbours classifier								INTELLIGENT DAA ENGINEERING AND AUTOMATED LEARNING IDEAL 2004, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		3177				654	659					2004	2004	k-nearest neighbour (k-nn) model is a simple, popular classifier. Probabilistic k-nn is a more powerful variant in which the model is cast in a Bayesian framework using (reversible jump) Markov chain Monte Carlo methods to average out the uncertainy over the model parameters.The k-nn classifier depends crucially on the metric used to determine distances between data points. However, scalings between features, and indeed whether some subset of features is redundant, are seldom known a priori. Here we introduce a variable metric extension to the probabilistic k-nn classifier, which permits averaging over all rotations and scalings of the data. In addition, the method permits automatic rejection of irrelevant features. Examples are provided on synthetic data, illustrating how the method can deform feature space and select salient features, and also on real-world data.				5th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL 2004)	AUG 25-27, 2004	Execter Univ, Comp Sci Dept; IEEE Neural Networks Soc; Springer Verlag	Execter, ENGLAND	4	0	1	0	4	0302-9743	3-540-22881-0	WOS:000223701300096	
S	Okazaki, N; Matsuo, Y; Ishizuka, M						Zhang, C; Guesgen, HW; Yeap, WK		Coherent arrangement of sentences extracted from multiple newspaper articles								PRICAI 2004: TRENDS IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		3157				882	891					2004	2004	Multi-document summarization is a challenge to information overload problem to provide a condensed text for a number of documents. Most multi-document summarization systems make use of extraction techniques (e.g., important sentence extraction) and compile a summary from the selected information. However, sentences gathered from multiple sources are not organized as a comprehensible text. Therefore, it is important to consider sentence ordering of extracted sentences in order to reconstruct discourse structure in a summary. We propose a novel method to plan a coherent arrangement of sentences extracted from multiple newspaper articles. Results of our experiment show that sentence reordering has a discernible effect on summary readability. The results also shows significant improvement on sentence arrangement compared to former methods.				8th Pacific Rim International Conference on Artificial Intelligence (PRICAI 2004)	AUG 09-13, 2004	Univ Auckland, Inst Informat Technol Res; USAF Off Sci Res; Asian Off Aerosp Res & Dev; Auckland Univ Technol; Franz Inc	Auckland, NEW ZEALAND	4	0	0	0	4	0302-9743	3-540-22817-9	WOS:000223633300093	
S	Kim, YS; Chang, JH; Zhang, BT						Whang, KY; Jeon, J; Shim, K; Srivastava, J		An empirical study on dimensionality optimization in text mining for linguistic knowledge acquisition								ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		2637				111	116					2003	2003	In this paper, we try to find empirically the optimal dimensionality in data-driven models, Latent Semantic Analysis (LSA) model and Probabilistic Latent Semantic Analysis (PLSA) model. These models are used for building linguistic semantic knowledge which could be used in estimating contextual semantic similarity for the target word selection in English-Korean machine translation. We also facilitate k-Nearest Neighbor learning algorithm. We diversify our experiments by analyzing the covariance between the value of k in k-NN learning and accuracy of selection, in addition to that between the dimensionality and the accuracy. While we could not find regular tendency of relationship between the dimensionality and the accuracy, however, we could find the optimal dimensionality having the most sound distribution of data during experiments.				7th Pacific-Asia Conference on Knowledge Discovery and Data Mining	APR 30-MAY 02, 2003	Adv Informat Technol Res Ctr, KAIST; Stat Res Ctr Complex Syst, SNU; Korea Informat Sci Soc; Korean Datamining Soc; USAF, Off Sci Res; Asian Off Aerosp Res & Dev; ACM SIGKDD	SEOUL, SOUTH KOREA	4	0	0	0	4	0302-9743	3-540-04760-3	WOS:000184716000011	
S	Sanchez, JS; Barandela, R; Ferri, FJ						Escrig, MT; Toledo, F; Golobardes, E		On filtering the training prototypes in nearest neighbour classification								TOPICS IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		2504				239	248					2002	2002	Filtering (or editing) is mainly effective in improving the classification accuracy of the Nearest Neighbour (NN) rule, and also in reducing its storage and computational requirements. This work reviews some well-known editing algorithms for NN classification and presents alternative approaches based on combining the NN and the, Nearest Centroid Neighbourhood of a sample. Finally, an empirical analysis over real data sets is provided.				5th Catalonian Conference on Artificial Intelligence	OCT 24-25, 2002	Asociacio Catalana Intelligencia Artificial; British Petr Oil Castellon; Univ Jaume I, Dept Ingn Ciencia Computadores; Fdn Caixa Castello Bancaixa; Generalitat Valenciana; Minist Educ & Ciencia	CASTELLON, SPAIN	4	0	0	0	4	0302-9743	3-540-00011-9	WOS:000182749300021	
J	Skubalska-Rafajlowicz, E								Data compression for pattern recognition based on space-filling curve pseudo-inverse mapping					1			NONLINEAR ANALYSIS-THEORY METHODS & APPLICATIONS			47	1			315	326		10.1016/S0362-546X(01)00179-1			AUG 2001	2001	A new class of methods of data compression for pattern recognition in multidimensional space is discussed. These methods combine the space-filling curve based transformation of multidimensional data into the unit interval and pattern recognition algorithms in one dimension. This transformation yield the powerful reduced complexity pattern recognition method.				3rd World Congress of Nonlinear Analysts Catania	JUL 19-26, 2000		SICILY, ITALY	4	0	0	0	4	0362-546X		WOS:000170625400030	
J	Bax, E								Validation of nearest neighbor classifiers								IEEE TRANSACTIONS ON INFORMATION THEORY			46	7			2746	2752		10.1109/18.887892			NOV 2000	2000	This correspondence presents a method to bound the out-of-sample error rate of a nearest neighbor classifier.(1) The bound is based only on the examples that comprise the classifier. Thus all available examples can be used in the classifier; no examples need to be withheld to compute error bounds.The estimate used in the bound is an extension of the holdout estimate. The difference in error rates between the holdout classifier and the classifier consisting of all available examples is estimated using truncated inclusion and exclusion.								4	0	0	0	4	0018-9448		WOS:000165606900049	
J	Cardie, C								A cognitive bias approach to feature selection and weighting for case-based learners								MACHINE LEARNING			41	1			85	116		10.1023/A:1007665204628			OCT 2000	2000	Research in psychology, psycholinguistics, and cognitive science has discovered and examined numerous psychological constraints on human information processing. Short term memory limitations, a focus of attention bias, and a preference for the use of temporally recent information are three examples. This paper shows that psychological constraints such as these can be used effectively as domain-independent sources of bias to guide feature set selection and weighting for case-based learning algorithms.We first show that cognitive biases can be automatically and explicitly encoded into the baseline instance representation: each bias modifies the representation by changing features, deleting features, or modifying feature weights. Next, we investigate the related problems of cognitive bias selection and cognitive bias interaction for the feature weighting approach. In particular, we compare two cross-validation algorithms for bias selection that make different assumptions about the independence of individual component biases. In evaluations on four natural language learning tasks, we show that the bias selection algorithms can determine which cognitive bias or biases are relevant for each learning task and that the accuracy of the case-based learning algorithm improves significantly when the selected bias(es) are incorporated into the baseline instance representation.								4	0	0	0	4	0885-6125		WOS:000088654300004	
J	Benitez, MC; Rubio, A; Garcia, P; de la Torre, A				de la Torre, Angel/C-6618-2012; Benitez Ortuzar, M Del Carmen/C-2424-2012; Prieto, Ignacio/B-5361-2013				Different confidence measures for word verification in speech recognition								SPEECH COMMUNICATION			32	1-2			79	94		10.1016/S0167-6393(00)00025-X			SEP 2000	2000	Recent research in Automatic Speech Recognition (ASR) technologies has shown the key-word spotting (KWS) systems as one of the most interesting options for accessing information using speech. KWS systems can accept spontaneous speech, which allows potential users to ask for information without learning complex protocols for the human-machine communication. One of the most relevant aspects in KWS systems is the verification of key-word candidates. Utterances detected as key-words could be either 'false alarms' (non-key-words or incorrectly recognized key-words) or 'correct key-words'. The use of confidence measurements allows (by additional processing of the spoken sentence) the verification of the candidates and the decision as to whether each utterance must be accepted as a correctly recognized key-word or rejected as a false alarm.In this work we propose a novel method for verification in those KWS systems based on phone models. Under our new approach, a phonematic speech recognizer decodes the spoken sentence in parallel with the KWS recognizer. The first one produces a phone string as output while the second one generates a key-word/filler-model string. By aligning both strings, a set of characteristics is extracted which are used to verify the putatives key-word. For that we have built two classifiers; in the first one the euclidean metric is modified and adapted in a local and iterative way in order to give greater importance to the most discriminate directions between the classes. The second is a vector quantizer which was trained using adaptative technique learning. We have applied the proposed method to several KWS tasks. Experimental results presented in this paper show that the proposed verification method improves the performance of the KWS systems by reducing the false alarm rate without a significant increase in the rejection of correctly detected keywords. (C) 2000 Elsevier Science B.V. All rights reserved.								4	0	0	0	4	0167-6393		WOS:000089095100007	
S	Domeniconi, C; Peng, J; Gunopulos, D			IEEE; IEEE; IEEE					Adaptive metric nearest neighbor classification								IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, VOL I	PROCEEDINGS - IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION						517	522					2000	2000	Nearest neighbor classification assumes locally constant class conditional probabilities. This assumption becomes invalid in high dimensions with finite samples due to the curse of dimensionality. Severe bias can be introduced under these conditions when using the nearest neighbor rule. We propose a local adaptive nearest neighbor classification method to try to minimize bias. We use a Chi-squared distance analysis to compute a flexible metric for producing neighborhoods that are highly adaptive to query locations. Neighborhoods are elongated along less relevant feature dimensions and constricted along most influential ones. As a result, the class conditional probabilities tend to be smoother in the modified neighborhoods, whereby better classification performance can be achieved. The efficacy of our method is validated and compared against other techniques using a variety of simulated and real world data.				IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2000)	JUN 13-15, 2000	IEEE Comp Soc; IEEE Comp Soc, Tech Comm Pattern Anal & Machine Intelligence	HILTON HEAD ISL, SC	4	0	0	0	4	1063-6919	0-7695-0662-3	WOS:000088804500073	
J	Li, Jinyan; Dong, Guozhu; Ramamohanarao, Kotagiri								Instance-Based Classification by Emerging Patterns								LECTURE NOTES IN COMPUTER SCIENCE <D>			1910				191	200					2000	2000	Emerging patterns (EPs), namely itemsets whose supports change significantly from one class to another, capture discriminating features that sharply contrast instances between the classes. Recently, EP-based classifiers have been proposed, which first mine as many EPs as possible (called eager-learning) from the training data and then aggregate the discriminating power of the mined EPs for classifying new instances. We propose here a new, instance-based classifier using EPs, called DeEPs, to achieve much better accuracy and efficiency than the previously proposed EP-based classifiers. High accuracy is achieved because the instance-based approach enables DeEPs to pinpoint all EPs relevant to a test instance, some of which are missed by the eager-learning approaches. High efficiency is obtained using a series of data reduction and concise data-representation techniques. Experiments show that DeEPs' decision time is linearly scalable over the number of training instances and nearly linearly over the number of attributes. Experiments on 40 datasets also show that DeEPs is superior to other classifiers on accuracy.								4	0	0	0	4	0302-9743		WOS:000207632900020	
J	Ekin, O; Hammer, PL; Kogan, A; Winter, P								Distance-based classification methods								INFOR			37	3			337	352					AUG 1999	1999	Given a set of points in a Euclidean space, and a partitioning of this "training set" into two or more subsets ("classes"), we consider the problem of identifying a "reasonable" assignment of another point in the Euclidean space ("query point") to one of these classes. The various classifications proposed in this paper are determined by the distances between the query point and the points in the training set. We report results of extensive computational experiments comparing the new methods with two well-known distance-based classification methods (k-nearest neighbors and Parzen windows) on data sets commonly used in the literature. The results show that the performance of both new and old distance-based methods is on par with and often better than that of the other best classification methods known. Moreover, the new classification procedures proposed in this paper are: (i) easy to implement, (ii) extremely fast, and (iii) very robust (i.e. their performance is insignificantly affected by the choice of parameter values).								4	0	0	0	4	0315-5986		WOS:000082166900009	
S	Talukder, A; Casasent, D						Casasent, DP; Chao, TH		Nonlinear features for product inspection								OPTICAL PATTERN RECOGNITION X	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		3715				32	43		10.1117/12.341305			1999	1999	Classification of real-time X-ray images of randomly oriented touching pistachio nuts is discussed. The ultimate objective is the development of a system for automated non-invasive detection of defective product items on a conveyor belt. We discuss the extraction of new features that allow better discrimination between damaged and clean items (pistachio nuts). This feature extraction and classification stage is the new aspect of this paper; our new maximum representation and discriminating feature (MRDF) extraction method computes nonlinear features that are used as inputs to a new modified k nearest neighbor classifier. In this work, the MRDF is applied to standard features (rather than iconic data). The MRDF is robust to various probability distributions of the input class and is shown to provide good classification and new ROC (receiver operating characteristic) data.				Conference on Optical Pattern Recognition X	APR 07-08, 1999	SPIE - Int Soc Opt Engn	ORLANDO, FL	4	0	0	0	4	0277-786X	0-8194-3189-3	WOS:000080212700003	
J	Yang, MS; Chen, CH								On the edited fuzzy kappa-nearest neighbor rule								IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			28	3			461	466					JUN 1998	1998	Classification of objects is an important area in a variety of fields and applications. In the presence of full knowledge of the underlying joint distributions, Bayes analysis yields an optimal decision procedure and produces optimal error rates. Many different methods are available to make a decision in those cases where information of the underlying joint distributions is not presented. The k nearest neighbor rule (k-NNR) is a well-known nonparametric decision procedures. Many classification rules based on the k-NNR have already been proposed and applied in diverse substantive areas. The edited k-NNR proposed by Wilson [11] would be an important one. Fuzzy theory, originated by Zadeh [16], is widely used to represent the uncertainty of class membership. The fuzzy k-NNR has been proposed by several investigators. In this paper an edited type-of the fuzzy k-NNR is developed. Next, some asymptotic properties of the proposed edited fuzzy k-NNR are created. Moreover, numerical comparisons are made between the proposed edited fuzzy k-NNR and the other fuzzy k-NNR. Those results confirm that the edited fuzzy k-NNR has a better performance than the fuzzy k-NNR.								4	0	0	0	4	1083-4419		WOS:000073729800015	
J	Djouadi, A								On the reduction of the nearest-neighbor variation for more accurate classification and error estimates								IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			20	5			567	571		10.1109/34.682188			MAY 1998	1998	In designing the nearest-neighbor (NN) classifier, a method is presented to produce a finite sample size risk close to the asymptotic one. It is based on an attempt to eliminate the first-order effects of the sample size, as well as all higher odd terms. This method uses the 2-NN rule without the rejection option and utilizes a polarization scheme. Simulation results are included as a means of verifying this analysis.								4	0	0	0	4	0162-8828		WOS:000073955600014	
B	Ramscar, M; Hahn, U						Gernsbacher, MA; Derry, SJ		What family resemblances are not: The continuing relevance of Wittgenstein to the study of concepts and categories								PROCEEDINGS OF THE TWENTIETH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY							865	870					1998	1998	We argue that common interpretations of Wittgenstein's philosophical Investigations within Cognitive Science misrepresent his account, underplaying its radical content. Appropriately interpreted, this account continues to challenge contemporary theories of concepts and categorisation. We illustrate the continued relevance of his position by directly applying its critique to current approaches to categorisation.				20th Annual Conference of the Cognitive-Science-Society	AUG 01-04, 1998	Cognit Sci Soc	UNIV WISCONSIN, MADISON, WI	4	0	0	0	4		0-8058-3231-9	WOS:000168193500156	
J	Ling, CX; Parry, JJ; Wang, HD								Setting attribute weights for nearest neighbor learning algorithms using C4.5								INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			11	3			405	415		10.1142/S0218001497000184			MAY 1997	1997	Nearest Neighbour (NN) learning algorithms utilize a distance function to determine the classification of testing examples. The attribute weights in the distance function should be set appropriately. We study situations where a simple approach of setting attribute weights using decision trees does not work well, and design three improvements. We test these new methods thoroughly using artificially generated datasets and datasets from the machine learning repository.								4	0	0	0	4	0218-0014		WOS:A1997XQ59300004	
J	Chen, LH; Kao, C; Kuo, S; Wang, TY; Jang, YC								Productivity diagnosis via fuzzy clustering and classification: An application to machinery industry								OMEGA-INTERNATIONAL JOURNAL OF MANAGEMENT SCIENCE			24	3			309	319		10.1016/0305-0483(96)00002-3			JUN 1996	1996	Business units are always faced with intensifying pressure in a competitive economy, Increasing productivity is an effective solution for a firm to survive and prosper, The relative productivity in an industry has evolved into a significant determinant of the competitive position for a firm, This paper proposes a productivity diagnosis process for a firm on the basis of the productivity characters of an industry to gain an insight into the firm's relative productivity and to find the shortcomings in its management of resources, Firstly, productivity structure is determined, Pattern recognition technologies, namely fuzzy clustering and fuzzy classification, are then employed, After fuzzily clustering a training set according to three feature spares, the productivity characters of the industry can be determined, A business unit can be diagnosed through fuzzily classifying its productivity features in a particular feature space and productivity indications can be furnished based on the associated productivity characters, As an illustration, data from 23 machinery firms in Taiwan are collected as a training set to analyze the productivity characters in each space, and two hypothetical firms are diagnosed. Copyright (C) 1996 Elsevier Science Ltd.								4	0	0	0	4	0305-0483		WOS:A1996UU41200006	
J	Cardillo, J; SidAhmed, MA								Target recognition in a cluttered scene using mathematical morphology								PATTERN RECOGNITION			29	1			27	49		10.1016/0031-3203(95)00065-8			JAN 1996	1996	This paper deals with the problem of locating targets within a cluttered gray-level digital image. The proposed new method is derived from principles in mathematical morphology. Basic morphological operations combined with some statistical techniques are used to generate a target recognition error function whose surface is minimized to estimate the probable location of a target. An automatic training procedure accompanies the new algorithm. The training provides the means by which the algorithm may automatically learn to deal with subtle differences in a target's appearance. A novel decomposition technique that provides some size invariance is also presented.								4	0	0	0	4	0031-3203		WOS:A1996TQ84900003	
S	Tirri, H; Kontkanen, P; Myllymaki, P						Smith, I; Faltings, B		A Bayesian framework for case-based reasoning								ADVANCES IN CASE-BASED REASONING	Lecture Notes in Artificial Intelligence		1168				413	427					1996	1996	In this paper we present a probabilistic framework for case-based reasoning in data-intensive domains, where only weak prior knowledge is available. In such a probabilistic viewpoint the attributes are interpreted as random variables, and the case base is used to approximate the underlying joint probability distribution of the attributes. Consequently structural case adaptation (and parameter adjustment in particular) can be viewed as prediction based on the full probability model constructed from the case history. The methodology addresses several problems encountered in building case-based reasoning systems. It provides a computationally efficient structural adaptation algorithm, avoids over-fitting by using Bayesian model selection and uses directly probabilities as measures of similarity. The methodology described has been implemented in the D-SIDE software package, and the approach is validated by presenting empirical results of the method's classification prediction performance for a set of public domain data sets.				3rd European Workshop on Case-Based Reasoning	NOV 14-16, 1996		LAUSANNE, SWITZERLAND	4	1	0	0	5	0302-9743	3-540-61955-0	WOS:000073946100030	
J	IFTEKHARUDDIN, KM; SCHECHINGER, TD; JEMILI, K; KARIM, MA								FEATURE-BASED NEURAL WAVELET OPTICAL CHARACTER-RECOGNITION SYSTEM								OPTICAL ENGINEERING			34	11			3193	3199		10.1117/12.213654			NOV 1995	1995	A hybrid character recognition system that uses a feature-extraction method is proposed. The features are extracted using a wavelet transform, preclassified using a k-nearest-neighbor-based neural net and subsequently postprocessed using an optical correlator. This feature-based neural wavelet optical architecture is then tested on blurred character images.								4	0	0	0	4	0091-3286		WOS:A1995TF30700015	
J	YANG, MS; CHEN, CT								ON STRONG CONSISTENCY OF THE FUZZY GENERALIZED NEAREST-NEIGHBOR RULE								FUZZY SETS AND SYSTEMS			60	3			273	281		10.1016/0165-0114(93)90438-N			DEC 24 1993	1993	The k nearest neighbor rule (k-NNR) is a well-known nonparametric decision rule in pattern classification. Fuzzy set theory has been widely used to represent the uncertainty of class membership. Several researchers extended conventional k-NNR to fuzzy k-NNR, such as Bezdek et al. [Fuzzy Sets and Systems 18 (1986) 237-256], Keller et al. [IEEE Trans. Syst. Man, and Cybern. 15(4) (1985) 580-585], Bereau and Dubuisson [Fuzzy Sets and Systems 44 (1991) 17-32]. In this paper, we describe a fuzzy generalized k-NN algorithm. This algorithm is a unified approach to a variety of fuzzy k-NNR's. Then we create the strong consistency of posterior risk of the fuzzy generalized NNR.								4	0	0	0	4	0165-0114		WOS:A1993MR45700003	
J	STEIGSTRA, H; JANSEN, AP; KATEMAN, G								SOLOMON, A CLASSIFICATION PROGRAM BASED ON A STATISTICAL MULTIVARIATE DISJOINT MODEL								ANALYTICA CHIMICA ACTA			193				269	276		10.1016/S0003-2670(00)86158-9			FEB 14 1987	1987									4	0	1	0	4	0003-2670		WOS:A1987J283900026	
J	FORBES, RA; TEWS, EC; FREISER, BS; WISE, MB; PERONE, SP								DEVELOPMENT OF A NOVEL WEIGHTING SCHEME FOR THE K-NEAREST-NEIGHBOR ALGORITHM								JOURNAL OF CHEMICAL INFORMATION AND COMPUTER SCIENCES			26	3			93	98		10.1021/ci00051a002			AUG 1986	1986									4	0	0	0	4	0095-2338		WOS:A1986D988000003	
J	ROSENTHAL, RJ; LOWRY, SR								EFFECTS OF SAMPLING METHODOLOGIES ON FT-IR DATABASE SEARCHING								MIKROCHIMICA ACTA			2	1-6			291	302					1986	1986									4	0	1	0	4	0026-3672		WOS:A1986J532700021	
J	BRODER, AZ; BRUCKSTEIN, AM; KOPLOWITZ, J								ON THE PERFORMANCE OF EDITED NEAREST NEIGHBOR RULES IN HIGH DIMENSIONS								IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS			15	1			136	139					1985	1985									4	0	0	0	4	0018-9472		WOS:A1985AFX0900013	
J	GUNDEL, A								EEG BACKGROUND ACTIVITY IN CHILDHOOD EPILEPSY - VALID PARAMETERIZATION BY THE PARTIAL AUTO-CORRELATION FUNCTION								NEUROPEDIATRICS			14	3			166	169		10.1055/s-2008-1059572			1983	1983									4	0	1	0	4	0174-304X		WOS:A1983RD41300007	
J	HECHTNIELSEN, R								NEURAL ANALOG PROCESSING								PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS			360				180	189					1982	1982									4	0	0	0	4	0361-0748		WOS:A1982QV53900024	
J	COCHRANE, TT; JONES, PG								SAVANNAS, FORESTS AND WET SEASON POTENTIAL EVAPO-TRANSPIRATION IN TROPICAL SOUTH-AMERICA								TROPICAL AGRICULTURE			58	3			185	190					1981	1981									4	0	3	0	4	0041-3216		WOS:A1981LW40400001	
J	BENBASSAT, M								EPSILON-EQUIVALENCE OF FEATURE SELECTION-RULES								IEEE TRANSACTIONS ON INFORMATION THEORY			24	6			769	772		10.1109/TIT.1978.1055952			1978	1978									4	0	0	0	4	0018-9448		WOS:A1978GA42300018	
J	TOUSSAINT, GT								GENERALIZATION OF SHANNONS EQUIVOCATION AND FANO BOUND								IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS			7	4			300	302					1977	1977									4	0	0	0	4	0018-9472		WOS:A1977DB91500011	
J	GOLDMAN, J								APPROACH TO ESTIMATION AND EXTRAPOLATION WITH POSSIBLE APPLICATIONS IN AN INCOMPLETELY SPECIFIED ENVIRONMENT								INFORMATION AND CONTROL			30	3			203	233		10.1016/S0019-9958(76)90497-6			1976	1976									4	0	0	0	4	0019-9958		WOS:A1976BL97700001	
J	Garcia Moreno-Torres, Jose; Saez, Jose A.; Herrera, Francisco				Herrera, Francisco/C-6856-2008	Herrera, Francisco/0000-0002-7283-312X			Study on the Impact of Partition-Induced Dataset Shift on k-fold Cross-Validation								IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS			23	8			1304	1312		10.1109/TNNLS.2012.2199516			AUG 2012	2012	Cross-validation is a very commonly employed technique used to evaluate classifier performance. However, it can potentially introduce dataset shift, a harmful factor that is often not taken into account and can result in inaccurate performance estimation. This paper analyzes the prevalence and impact of partition-induced covariate shift on different k-fold cross-validation schemes. From the experimental results obtained, we conclude that the degree of partition-induced covariate shift depends on the cross-validation scheme considered. In this way, worse schemes may harm the correctness of a single-classifier performance estimation and also increase the needed number of repetitions of cross-validation to reach a stable performance estimation.								3	0	0	0	3	2162-237X		WOS:000308965200011	
J	Edelman, Shimon; Shahbazi, Reza								Renewing the respect for similarity								FRONTIERS IN COMPUTATIONAL NEUROSCIENCE			6						45	10.3389/fncom.2012.00045			JUL 13 2012	2012	In psychology, the concept of similarity has traditionally evoked a mixture of respect, stemming from it subiquity and intuitive appeal, and concern, due to its dependence on the framing of the problem at hand and on its context. We argue for a renewed focus on similarity as an explanatory concept, by surveying established results and new developments in the theory and methods of similarity-preserving associative lookup and dimensionality reduction critical components of many cognitive functions, as well as of intelligent data management in computer vision. We focus in particular on the growing family of algorithms that support associative memory by performing hashing that respects local similarity, and on the uses of similarity in representing structured objects and scenes. Insofar as these similarity-based ideas and methods are useful in cognitive modeling and in AI applications, they should be included in the core conceptual toolkit of computational neuroscience. In support of this stance, the present paper (1) offers a discussion of conceptual, mathematical, computational, and empirical aspects of similarity, as applied to the problems of visual object and scene representation, recognition, and interpretation, (2) mentions some key computational problems arising in attempts to put similarity to use, along with their possible solutions, (3) briefly states a previously developed similarity based framework for visual object representation, the Chorus of Prototypes, along with the empirical support it enjoys, (4) presents new mathematical insights into the effectiveness of this framework, derived from its relationship to locality-sensitive hashing (LSH) and to concomitant statistics, (5) introduces a new model, the Chorus of Relational Descriptors (ChoRD), that extends this framework to scene representation and interpretation, (6) describes its implementation and testing, and finally (7) suggests possible directions in which the present research program can be extended in the future.								3	0	2	0	3	1662-5188		WOS:000306355300001	
J	Shinjo, Keiko; Okamoto, Yasuyuki; An, Byonggu; Yokoyama, Toshihiko; Takeuchi, Ichiro; Fujii, Makiko; Osada, Hirotaka; Usami, Noriyasu; Hasegawa, Yoshinori; Ito, Hidemi; Hida, Toyoaki; Fujimoto, Nobukazu; Kishimoto, Takumi; Sekido, Yoshitaka; Kondo, Yutaka								Integrated analysis of genetic and epigenetic alterations reveals CpG island methylator phenotype associated with distinct clinical characters of lung adenocarcinoma								CARCINOGENESIS			33	7			1277	1285		10.1093/carcin/bgs154			JUL 2012	2012	DNA methylation affects the aggressiveness of human malignancies. Cancers with CpG island methylator phenotype (CIMP), a distinct group with extensive DNA methylation, show characteristic features in several types of tumors. In this study, we initially defined the existence of CIMP in 41 lung adenocarcinomas (AdCas) through genome-wide DNA methylation microarray analysis. DNA methylation status of six CIMP markers newly identified by microarray analysis was further estimated in a total of 128 AdCas by bisulfite pyrosequencing analysis, which revealed that 10 (7.8%), 40 (31.3%) and 78 (60.9%) cases were classified as CIMP-high (CIMP-H), CIMP-low and CIMP-negative (CIMP-N), respectively. Notably, CIMP-H AdCas were strongly associated with wild-type epidermal growth factor receptor (EGFR), males and heavy smokers (P = 0.0089, P = 0.0047 and P = 0.0036, respectively). In addition, CIMP-H was significantly associated with worse prognosis; especially among male smokers, CIMP-H was an independent prognostic factor (hazard ratio 1.7617, 95% confidence interval 1.0030-2.9550, P = 0.0489). Compellingly, the existence of CIMP in AdCas was supported by the available public datasets, such as data from the Cancer Genome Atlas. Intriguingly, analysis of AdCa cell lines revealed that CIMP-positive AdCa cell lines were more sensitive to a DNA methylation inhibitor than CIMP-N ones regardless of EGFR mutation status. Our data demonstrate that CIMP in AdCas appears to be a unique subgroup that has distinct clinical traits from other AdCas. CIMP classification using our six-marker panel has implications for personalized medical strategies for lung cancer patients; in particular, DNA methylation inhibitor might be of therapeutic benefit to patients with CIMP-positive tumors.								3	0	3	0	3	0143-3334		WOS:000306925600004	
J	D'Antonio, Jennifer; Murphy, Brian M.; Manning, Mark Cornell; Al-Azzam, Wasfi A.								Comparability of protein therapeutics: Quantitative comparison of second-derivative amide I infrared spectra								JOURNAL OF PHARMACEUTICAL SCIENCES			101	6			2025	2033		10.1002/jps.23133			JUN 2012	2012	Comparability determination for protein therapeutics requires an assessment of their higher order structure, usually by using spectroscopic methods. One of the most common techniques used to determine secondary structure composition of proteins is analysis of the second derivative of the amide I region of Fourier transform infrared (FTIR) spectra. A number of algorithms have been described for quantitative comparison of second-derivative amide I FTIR spectra, but no systematic evaluation has been conducted to assess these approaches. In this study, the two most common methods, spectral correlation coefficient and area of overlap (AO), are compared for their ability to determine spectral comparability of a protein as a function of changes in pH or temperature. Two other algorithms were considered as well. Recently, a QC compare similarity function found in OMNIC software has been reported as being useful in comparing amide I FTIR spectra. In addition, a new algorithm, termed modified AO, is described herein. These four methods were evaluated for their ability to determine comparability for second-derivative amide I FTIR spectra of four model proteins. The result is a framework for quantitative determination of whether any two spectra differ significantly. (C) 2012 Wiley Periodicals, Inc. and the American Pharmacists Association J Pharm Sci 101:20252033, 2012								3	0	2	0	3	0022-3549		WOS:000302800300008	
J	Hu, Le-Le; Feng, Kai-Yan; Cai, Yu-Dong; Chou, Kuo-Chen				Chou, Kuo-Chen/A-8340-2009				Using Protein-protein Interaction Network Information to Predict the Subcellular Locations of Proteins in Budding Yeast								PROTEIN AND PEPTIDE LETTERS			19	6			644	651					JUN 2012	2012	The information of protein subcellular localization is vitally important for in-depth understanding the intricate pathways that regulate biological processes at the cellular level. With the rapidly increasing number of newly found protein sequence in the Post-Genomic Age, many automated methods have been developed attempting to help annotate their subcellular locations in a timely manner. However, very few of them were developed using the protein-protein interaction (PPI) network information. In this paper, we have introduced a new concept called "tethering potential" by which the PPI information can be effectively fused into the formulation for protein samples. Based on such a network frame, a new predictor called Yeast-PLoc has been developed for identifying budding yeast proteins among their 19 subcellular location sites. Meanwhile, a purely sequence-based approach, called the "hybrid-property" method, is integrated into Yeast-PLoc as a fall-back to deal with those proteins without sufficient PPI information. The overall success rate by the jackknife test on the 4,683 yeast proteins in the training dataset was 70.25%. Furthermore, it was shown that the success rate by Yeast-PLoc on an independent dataset was remarkably higher than those by some other existing predictors, indicating that the current approach by incorporating the PPI information is quite promising. As a user-friendly web-server, Yeast-PLoc is freely accessible at http://yeastloc.biosino.org/.								3	0	3	0	3	0929-8665		WOS:000304442400010	
J	Nicolas, Violaine; Schaeffer, Brigitte; Missoup, Alain Didier; Kennis, Jan; Colyn, Marc; Denys, Christiane; Tatard, Caroline; Cruaud, Corinne; Laredo, Catherine								Assessment of Three Mitochondrial Genes (16S, Cytb, CO1) for Identifying Species in the Praomyini Tribe (Rodentia: Muridae)								PLOS ONE			7	5					e36586	10.1371/journal.pone.0036586			MAY 4 2012	2012	The Praomyini tribe is one of the most diverse and abundant groups of Old World rodents. Several species are known to be involved in crop damage and in the epidemiology of several human and cattle diseases. Due to the existence of sibling species their identification is often problematic. Thus an easy, fast and accurate species identification tool is needed for non-systematicians to correctly identify Praomyini species. In this study we compare the usefulness of three genes (16S, Cytb, CO1) for identifying species of this tribe. A total of 426 specimens representing 40 species (sampled across their geographical range) were sequenced for the three genes. Nearly all of the species included in our study are monophyletic in the neighbour joining trees. The degree of intra-specific variability tends to be lower than the divergence between species, but no barcoding gap is detected. The success rate of the statistical methods of species identification is excellent (up to 99% or 100% for statistical supervised classification methods as the k-Nearest Neighbour or Random Forest). The 16S gene is 2.5 less variable than the Cytb and CO1 genes. As a result its discriminatory power is smaller. To sum up, our results suggest that using DNA markers for identifying species in the Praomyini tribe is a largely valid approach, and that the CO1 and Cytb genes are better DNA markers than the 16S gene. Our results confirm the usefulness of statistical methods such as the Random Forest and the 1-NN methods to assign a sequence to a species, even when the number of species is relatively large. Based on our NJ trees and the distribution of all intraspecific and interspecific pairwise nucleotide distances, we highlight the presence of several potentially new species within the Praomyini tribe that should be subject to corroboration assessments.								3	1	3	0	4	1932-6203		WOS:000305349800083	
J	Jia, Sen; Ji, Zhen; Qian, Yuntao; Shen, Linlin								Unsupervised Band Selection for Hyperspectral Imagery Classification Without Manual Band Removal								IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING			5	2	SI		531	543		10.1109/JSTARS.2012.2187434			APR 2012	2012	The rich information available in hyperspectral imagery has provided significant opportunities for material classification and identification. Due to the problem of the "curse of dimensionality" (called Hughes phenomenon) posed by the high number of spectral channels along with small amounts of labeled training samples, dimensionality reduction is a necessary preprocessing step for hyperspectral data. Generally, in order to improve the classification accuracy, noise bands generated by various sources (primarily the sensor and the atmosphere) are often manually removed in advance. However, the removal of these bands may discard some important discriminative information, eventually degrading the classification accuracy. In this paper, we propose a new strategy to automatically select bands without manual band removal. Firstly, wavelet shrinkage is applied to denoise the spatial images of the whole data cube. Then affinity propagation, which is a recently proposed feature selection approach, is used to choose representative bands from the noise-reduced data. Experimental results on three real hyperspectral data collected by two different sensors demonstrate that the bands selected by our approach on the whole data (containing noise bands) could achieve higher overall classification accuracies than those by other state-of-the-art feature selection techniques on the manual-band-removal (MBR) data, even better than the bands identified by the proposed approach on the MBR data, indicating that the removed "noise" bands are valuable for hyperspectral classification, which should not be eliminated.								3	0	0	0	3	1939-1404		WOS:000304612300017	
J	Vos, P. C.; Barentsz, J. O.; Karssemeijer, N.; Huisman, H. J.				Barentsz, Jelle/D-3515-2009				Automatic computer-aided detection of prostate cancer based on multiparametric magnetic resonance image analysis								PHYSICS IN MEDICINE AND BIOLOGY			57	6			1527	1542		10.1088/0031-9155/57/6/1527			MAR 21 2012	2012	In this paper, a fully automatic computer-aided detection (CAD) method is proposed for the detection of prostate cancer. The CAD method consists of multiple sequential steps in order to detect locations that are suspicious for prostate cancer. In the initial stage, a voxel classification is performed using a Hessian-based blob detection algorithm at multiple scales on an apparent diffusion coefficient map. Next, a parametricmulti-object segmentation method is applied and the resulting segmentation is used as a mask to restrict the candidate detection to the prostate. The remaining candidates are characterized by performing histogram analysis on multiparametric MR images. The resulting feature set is summarized into a malignancy likelihood by a supervised classifier in a two-stage classification approach. The detection performance for prostate cancer was tested on a screening population of 200 consecutive patients and evaluated using the free response operating characteristic methodology. The results show that the CAD method obtained sensitivities of 0.41, 0.65 and 0.74 at false positive (FP) levels of 1, 3 and 5 per patient, respectively. In conclusion, this study showed that it is feasible to automatically detect prostate cancer at a FP rate lower than systematic biopsy. The CAD method may assist the radiologist to detect prostate cancer locations and could potentially guide biopsy towards the most aggressive part of the tumour.								3	0	2	0	3	0031-9155		WOS:000301358000005	
J	Kutlu, Yakup; Kuntalp, Damla								Feature extraction for ECG heartbeats using higher order statistics of WPD coefficients								COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE			105	3			257	267		10.1016/j.cmpb.2011.10.002			MAR 2012	2012	This paper describes feature extraction methods using higher order statistics (HOS) of wavelet packet decomposition (WPD) coefficients for the purpose of automatic heartbeat recognition. The method consists of three stages. First, the wavelet package coefficients (WPC) are calculated for each different type of ECG beat. Then, higher order statistics of WPC are derived. Finally, the obtained feature set is used as input to a classifier, which is based on k-NN algorithm. The MIT-BIH arrhythmia database is used to obtain the ECG records used in this study. All heartbeats in the arrhythmia database are grouped into five main heartbeat classes. The classification accuracy of the proposed system is measured by average sensitivity of 90%, average selectivity of 92% and average specificity of 98%. The results show that HOS of WPC as features are highly discriminative for the classification of different arrhythmic ECG beats. (C) 2011 Elsevier Ireland Ltd. All rights reserved.								3	0	0	0	3	0169-2607		WOS:000300603700007	
J	Lutu, Patricia E. N.; Engelbrecht, Andries P.								Using OVA modeling to improve classification performance for large datasets								EXPERT SYSTEMS WITH APPLICATIONS			39	4			4358	4376		10.1016/j.eswa.2011.09.156			MAR 2012	2012	One-Versus-All (OVA) classification is a classifier construction method where a k-class prediction task is decomposed into k 2-class sub-problems. One base model is constructed for each sub-problem and the base models are then combined into one model. Aggregate model implementation is the process of constructing several base models which are then combined into a single model for prediction. In essence, OVA classification is a method of aggregate modeling. This paper reports studies that were conducted to establish whether OVA classification can provide predictive performance gains when large volumes of data are available for modeling as is commonly the case in data mining. It is demonstrated in this paper that firstly, OVA modeling can be used to increase the amount of training data while at the same time using base model training sets whose size is much smaller than the total amount of available training data. Secondly, OVA models created from large datasets provide a higher level of predictive performance compared to single k-class models. Thirdly, the use of boosted OVA base models can provide higher predictive performance compared to un-boosted OVA base models. Fourthly, when the combination algorithm for base model predictions is able to resolve tied predictions, the resulting aggregate models provide a higher level of predictive performance. (C) 2011 Elsevier Ltd. All rights reserved.								3	0	2	0	3	0957-4174		WOS:000299583700049	
J	Ursani, Ahsan Ahmad; Kpalma, Kidiyo; Lelong, Camille C. D.; Ronsin, Joseph				Lelong, Camille/A-6140-2011	Lelong, Camille/0000-0002-4850-1010			Fusion of Textural and Spectral Information for Tree Crop and Other Agricultural Cover Mapping With Very-High Resolution Satellite Images								IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING			5	1	SI		225	235		10.1109/JSTARS.2011.2170289			FEB 2012	2012	A new procedure is proposed for agricultural land-use mapping that addresses a known weakness of classical per-pixel methods in situations involving mixed tree crops. The proposed scheme uses a pair of very-high resolution satellite-borne panchromatic and multispectral images and integrates classification results of two parallel and independent analyses, respectively based on spectral and textural information. The multispectral image is divided into spectrally homogeneous but non-contiguous segments using unsupervised classification. In parallel, the panchromatic image is split into a grid of square blocks on which is performed a texture-driven supervised classification. Finally, the spectral and the textural classifications are fused to generate the land-use map. This method contrasts with object-based methods that sequentially perform image segmentation and classification. Results are evaluated both quantitatively and qualitatively, based on field survey ground-truth data. The quantitative assessment is presented in terms of overall accuracy (from 80% to 100% depending on the area) and Kappa coefficients. Visual comparison of the resulting map with the ground-truth is performed, with the analysis of the binary error maps. Merging spectral and textural classifications results in finer border delimitation and improves the overall classification accuracy of agricultural land-use by 27% as compared to textural classification alone.								3	0	0	0	3	1939-1404		WOS:000300844400021	
J	Sanchez, Clara I.; Niemeijer, Meindert; Isgum, Ivana; Dumitrescu, Alina; Suttorp-Schulten, Maria S. A.; Abramoff, Michael D.; van Ginneken, Bram				Abramoff, Michael/A-5836-2009; van Ginneken, Bram/A-3728-2012	van Ginneken, Bram/0000-0003-2028-8972			Contextual computer-aided detection: Improving bright lesion detection in retinal images and coronary calcification identification in CT scans								MEDICAL IMAGE ANALYSIS			16	1			50	62		10.1016/j.media.2011.05.004			JAN 2012	2012	Contextual information plays an important role in medical image understanding. Medical experts make use of context to detect and differentiate pathologies in medical images, especially when interpreting difficult cases. The majority of computer-aided diagnosis (CAD) systems, however, employ only local information to classify candidates, without taking into account global image information or the relation of a candidate with neighboring structures. In this paper, we present a generic system for including contextual information in a CAD system. Context is described by means of high-level features based on the spatial relation between lesion candidates and surrounding anatomical landmarks and lesions of different classes (static contextual features) and lesions of the same type (dynamic contextual features). We demonstrate the added value of contextual CAD for two real-world CAD tasks: the identification of exudates and drusen in 2D retinal images and coronary calcifications in 3D computed tomography scans. Results show that in both applications contextual CAD is superior to a local CAD approach with a significant increase of the figure of merit of the Free Receiver Operating Characteristic curve from 0.84 to 0.92 and from 0.88 to 0.98 for exudates and drusen, respectively, and from 0.87 to 0.93 for coronary calcifications. (C) 2011 Elsevier B.V. All rights reserved.								3	0	1	0	3	1361-8415		WOS:000299405500005	
J	Tung, Sau Wai; Quek, Chai; Guan, Cuntai								SaFIN: A Self-Adaptive Fuzzy Inference Network					1			IEEE TRANSACTIONS ON NEURAL NETWORKS			22	12			1928	1940		10.1109/TNN.2011.2167720			DEC 2011	2011	There are generally two approaches to the design of a neural fuzzy system: 1) design by human experts, and 2) design through a self-organization of the numerical training data. While the former approach is highly subjective, the latter is commonly plagued by one or more of the following major problems: 1) an inconsistent rulebase; 2) the need for prior knowledge such as the number of clusters to be computed; 3) heuristically designed knowledge acquisition methodologies; and 4) the stability-plasticity tradeoff of the system. This paper presents a novel self-organizing neural fuzzy system, named Self-Adaptive Fuzzy Inference Network (SaFIN), to address the aforementioned deficiencies. The proposed SaFIN model employs a new clustering technique referred to as categorical learning-induced partitioning (CLIP), which draws inspiration from the behavioral category learning process demonstrated by humans. By employing the one-pass CLIP, SaFIN is able to incorporate new clusters in each input-output dimension when the existing clusters are not able to give a satisfactory representation of the incoming training data. This not only avoids the need for prior knowledge regarding the number of clusters needed for each input-output dimension, but also allows SaFIN the flexibility to incorporate new knowledge with old knowledge in the system. In addition, the self-automated rule formation mechanism proposed within SaFIN ensures that it obtains a consistent resultant rulebase. Subsequently, the proposed SaFIN model is employed in a series of benchmark simulations to demonstrate its efficiency as a self-organizing neural fuzzy system, and excellent performances have been achieved.								3	0	0	0	3	1045-9227		WOS:000298051400008	
J	Li, Shengqiao; Harner, E. James; Adjeroh, Donald A.								Random KNN feature selection - a fast and stable alternative to Random Forests								BMC BIOINFORMATICS			12						450	10.1186/1471-2105-12-450			NOV 18 2011	2011	Background: Successfully modeling high-dimensional data involving thousands of variables is challenging. This is especially true for gene expression profiling experiments, given the large number of genes involved and the small number of samples available. Random Forests (RF) is a popular and widely used approach to feature selection for such "small n, large p problems." However, Random Forests suffers from instability, especially in the presence of noisy and/or unbalanced inputs.Results: We present RKNN-FS, an innovative feature selection procedure for "small n, large p problems." RKNN-FS is based on Random KNN (RKNN), a novel generalization of traditional nearest-neighbor modeling. RKNN consists of an ensemble of base k-nearest neighbor models, each constructed from a random subset of the input variables. To rank the importance of the variables, we define a criterion on the RKNN framework, using the notion of support. A two-stage backward model selection method is then developed based on this criterion. Empirical results on microarray data sets with thousands of variables and relatively few samples show that RKNN-FS is an effective feature selection approach for high-dimensional data. RKNN is similar to Random Forests in terms of classification accuracy without feature selection. However, RKNN provides much better classification accuracy than RF when each method incorporates a feature-selection step. Our results show that RKNN is significantly more stable and more robust than Random Forests for feature selection when the input data are noisy and/or unbalanced. Further, RKNN-FS is much faster than the Random Forests feature selection method (RF-FS), especially for large scale problems, involving thousands of variables and multiple classes.Conclusions: Given the superiority of Random KNN in classification performance when compared with Random Forests, RKNN-FS's simplicity and ease of implementation, and its superiority in speed and stability, we propose RKNN-FS as a faster and more stable alternative to Random Forests in classification problems involving feature selection for high-dimensional datasets.								3	0	3	0	3	1471-2105		WOS:000300426100001	
J	Aiello, F.; Bellifemine, F. L.; Fortino, G.; Galzarano, S.; Gravina, R.								An agent-based signal processing in-node environment for real-time human activity monitoring based on wireless body sensor networks								ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE			24	7			1147	1161		10.1016/j.engappai.2011.06.007			OCT 2011	2011	Nowadays wireless body sensor networks (WBSNs) have great potential to enable a broad variety of assisted living applications such as human biophysical/biochemical control and activity monitoring for health care, e-fitness, emergency detection, emotional recognition for social networking, security, and highly interactive games. It is therefore important to define design methodologies and programming frameworks which enable rapid prototyping of WBSN applications. Several effective application development frameworks have been already proposed for WBSNs designed for TinyOS-based sensor platforms, e.g. CodeBlue, SPINE, and Titan. In this paper we present an application of MAPS, an agent framework for wireless sensor networks based on the Java-programmable Sun SPOT sensor platform, for the development of a real-time WBSN-based system for human activity monitoring. The agent-oriented programming abstractions provided by MAPS allow effective and rapid prototyping of the sensor-side software. In particular, the architecture of the developed system is a typical star-based WBSN composed of a coordinator node and two sensor nodes located respectively on the waist and the thigh of the monitored assisted living. The coordinator relies on a JADE-based enhancement of the SPINE coordinator and allows configuring sensors, receiving their data, and recognizing pre-defined human activities. On the other hand, each sensor node runs a MAPS-based agent that performs sensing of the 3-axial accelerometer sensor, computation of significant features on the acquired data, feature aggregation and transmission to the coordinator. The experimentation phase of the prototype, which allows evaluating the obtainable monitoring performances and activity recognition accuracy, is described. Moreover, a comparison of the monitoring system based on MAPS, AFME and SPINE in terms of programming effectiveness and system performances is discussed. (C) 2011 Elsevier Ltd. All rights reserved.								3	0	0	0	3	0952-1976		WOS:000295151200007	
J	Gao, Ming; Hong, Xia; Chen, Sheng; Harris, Chris J.				Chen, Sheng/F-7835-2011				A combined SMOTE and PSO based RBF classifier for two-class imbalanced problems								NEUROCOMPUTING			74	17			3456	3466		10.1016/j.neucom.2011.06.010			OCT 2011	2011	This contribution proposes a powerful technique for two-class imbalanced classification problems by combining the synthetic minority over-sampling technique (SMOTE) and the particle swarm optimisation (PSO) aided radial basis function (RBF) classifier. In order to enhance the significance of the small and specific region belonging to the positive class in the decision region, the SMOTE is applied to generate synthetic instances for the positive class to balance the training data set. Based on the over-sampled training data, the RBF classifier is constructed by applying the orthogonal forward selection procedure, in which the classifier's structure and the parameters of RBF kernels are determined using a PSO algorithm based on the criterion of minimising the leave-one-out misclassification rate. The experimental results obtained on a simulated imbalanced data set and three real imbalanced data sets are presented to demonstrate the effectiveness of our proposed algorithm. (C) 2011 Elsevier B.V. All rights reserved.								3	0	0	0	3	0925-2312		WOS:000296212400077	
J	Shi, Ping; Ray, Surajit; Zhu, Qifu; Kon, Mark A.								Top scoring pairs for feature selection in machine learning and applications to cancer outcome prediction								BMC BIOINFORMATICS			12						375	10.1186/1471-2105-12-375			SEP 23 2011	2011	Background: The widely used k top scoring pair (k-TSP) algorithm is a simple yet powerful parameter-free classifier. It owes its success in many cancer microarray datasets to an effective feature selection algorithm that is based on relative expression ordering of gene pairs. However, its general robustness does not extend to some difficult datasets, such as those involving cancer outcome prediction, which may be due to the relatively simple voting scheme used by the classifier. We believe that the performance can be enhanced by separating its effective feature selection component and combining it with a powerful classifier such as the support vector machine (SVM). More generally the top scoring pairs generated by the k-TSP ranking algorithm can be used as a dimensionally reduced subspace for other machine learning classifiers.Results: We developed an approach integrating the k-TSP ranking algorithm (TSP) with other machine learning methods, allowing combination of the computationally efficient, multivariate feature ranking of k-TSP with multivariate classifiers such as SVM. We evaluated this hybrid scheme (k-TSP+SVM) in a range of simulated datasets with known data structures. As compared with other feature selection methods, such as a univariate method similar to Fisher's discriminant criterion (Fisher), or a recursive feature elimination embedded in SVM (RFE), TSP is increasingly more effective than the other two methods as the informative genes become progressively more correlated, which is demonstrated both in terms of the classification performance and the ability to recover true informative genes. We also applied this hybrid scheme to four cancer prognosis datasets, in which k-TSP+SVM outperforms k-TSP classifier in all datasets, and achieves either comparable or superior performance to that using SVM alone. In concurrence with what is observed in simulation, TSP appears to be a better feature selector than Fisher and RFE in some of the cancer datasetsConclusions: The k-TSP ranking algorithm can be used as a computationally efficient, multivariate filter method for feature selection in machine learning. SVM in combination with k-TSP ranking algorithm outperforms k-TSP and SVM alone in simulated datasets and in some cancer prognosis datasets. Simulation studies suggest that as a feature selector, it is better tuned to certain data characteristics, i.e. correlations among informative genes, which is potentially interesting as an alternative feature ranking method in pathway analysis.								3	0	3	0	3	1471-2105		WOS:000296096500001	
J	Castellini, C.; Tommasi, T.; Noceti, N.; Odone, F.; Caputo, B.				Caputo, Barbara/F-3928-2011				Using Object Affordances to Improve Object Recognition								IEEE TRANSACTIONS ON AUTONOMOUS MENTAL DEVELOPMENT			3	3			207	215		10.1109/TAMD.2011.2106782			SEP 2011	2011	The problem of object recognition has not yet been solved in its general form. The most successful approach to it so far relies on object models obtained by training a statistical method on visual features obtained from camera images. The images must necessarily come from huge visual datasets, in order to circumvent all problems related to changing illumination, point of view, etc. We hereby propose to also consider, in an object model, a simple model of how a human being would grasp that object (its affordance). This knowledge is represented as a function mapping visual features of an object to the kinematic features of a hand while grasping it. The function is practically enforced via regression on a human grasping database. After describing the database (which is publicly available) and the proposed method, we experimentally evaluate it, showing that a standard object classifier working on both sets of features (visual and motor) has a significantly better recognition rate than that of a visual-only classifier.								3	0	0	0	3	1943-0604		WOS:000294906800003	
J	Sela, Yehonatan; Freiman, Moti; Dery, Elia; Edrei, Yifat; Safadi, Rifaat; Pappo, Orit; Joskowicz, Leo; Abramovitch, Rinat				Freiman, Moti/B-2016-2013				fMRI-Based Hierarchical SVM Model for the Classification and Grading of Liver Fibrosis								IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING			58	9			2574	2581		10.1109/TBME.2011.2159501			SEP 2011	2011	We present a novel method for the automatic classification and grading of liver fibrosis based on hepatic hemodynamic changes measured noninvasively from functional MRI (fMRI) scans combined with hypercapnia and hyperoxia. The supervised learning method automatically creates a classification and grading model for liver fibrosis grade from training datasets. It constructs a statistical model of liver fibrosis by evaluating the signal intensity time course and local variance in T2*-W fMRI scans acquired during the breathing of air, air-carbon dioxide, and carbogen with a hierarchical multiclass binary-based support vector machine (SVM) classifier. Two experimental studies on 162 slices from 34 mice with the hierarchical multiclass binary-based SVM classifier yield 96.9% separation accuracy between healthy and histological-based fibrosis graded subjects, and an overall accuracy of 75.3% for healthy, fibrotic, and cirrhotic subjects. These results outperform existing image-based methods that can discriminate between healthy and mild-grade fibrosis subjects.								3	0	1	0	3	0018-9294		WOS:000294127700017	
J	Xu, J.; Yang, J.								Mean representation based classifier with its applications								ELECTRONICS LETTERS			47	18			1024	U1558		10.1049/el.2011.2420			SEP 1 2011	2011	Based on a fundamental concept that most similar properties of samples from a single-object class should be congregated on their class mean, an efficient and simple approach for pattern identification, called the mean representation based classifier (MRC), is presented. MRC is a linear model representing a testing sample as a linear combination of all class means and the class associating the biggest item of the linear combination coefficient is favoured. MRC is easy to employ with a least squares estimator. In addition, MRC need not tune any parameter and avoids mistaking the local optimum value as the global optimal one. MRC is evaluated on three standard databases. The experimental results show MRC is superior to other state-of-the-art nonparametric classifiers.								3	0	0	0	3	0013-5194		WOS:000294457600013	
J	Bourlai, Thirimachos; Ross, Arun; Jain, Anil K.								Restoring Degraded Face Images: A Case Study in Matching Faxed, Printed, and Scanned Photos								IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY			6	2			371	384		10.1109/TIFS.2011.2109951			JUN 2011	2011	We study the problem of restoring severely degraded face images such as images scanned from passport photos or images subjected to fax compression, downscaling, and printing. The purpose of this paper is to illustrate the complexity of face recognition in such realistic scenarios and to provide a viable solution to it. The contributions of this work are two-fold. First, a database of face images is assembled and used to illustrate the challenges associated with matching severely degraded face images. Second, a preprocessing scheme with low computational complexity is developed in order to eliminate the noise present in degraded images and restore their quality. An extensive experimental study is performed to establish that the proposed restoration scheme improves the quality of the ensuing face images while simultaneously improving the performance of face matching.								3	0	0	0	3	1556-6013		WOS:000290737100011	
J	Lanata, A.; Valenza, G.; Mancuso, C.; Scilingo, E. P.								Robust multiple cardiac arrhythmia detection through bispectrum analysis								EXPERT SYSTEMS WITH APPLICATIONS			38	6			6798	6804		10.1016/j.eswa.2010.12.066			JUN 2011	2011	This paper investigates the use of Higher Order Spectra parameters to identify the most common multiple cardiac arrhythmias. In detail, we calculated magnitude of bispectrum, three values of bispectrum entropy, mean and variance of the phase of bispectrum integrated over a particular region wherein no bispectrum aliasing is assumed. This set of features is used to distinguish normal QRS from five different classes of arrhythmia over a large amount of normal and pathologic ECG signals. An accurate parametric and non-parametric analysis of these feature distributions is also performed in order to identify the optimum classifier. Experimental tests were performed on signals gathered from the MIT-BIH Arrhythmias Database, and mean and standard deviation of all confusion matrixes obtained from 20 steps of cross validation are shown. Results showed that the bispectrum is high performance, reliable and robust method to identify arrhythmias. (C) 2010 Elsevier Ltd. All rights reserved.								3	0	0	0	3	0957-4174		WOS:000288343900047	
J	McSherry, David								Conversational case-based reasoning in medical decision making								ARTIFICIAL INTELLIGENCE IN MEDICINE			52	2	SI		59	66		10.1016/j.artmed.2011.04.007			JUN 2011	2011	Objectives: Balancing the trade-offs between solution quality, problem-solving efficiency, and transparency is an important challenge in medical applications of conversational case-based reasoning (CCBR). For example, test selection in CCBR is often based on strategies in which the absence of a specific hypothesis (e.g., diagnosis) to be confirmed makes it difficult to explain the relevance of test results that users are asked to provide. In this paper, we present an approach to CCBR in medical classification and diagnosis that aims to increase transparency while also providing high levels of accuracy and efficiency.Methods: We present an algorithm for CCBR called iNN(k) in which feature selection is driven by the goal of confirming a target class and informed by a measure of a feature's discriminating power in favor of the target class. As we demonstrate in a CCBR system called CBR-Confirm, this enables a CCBR system to explain the relevance of any question it asks the user. We evaluate the algorithm's accuracy and efficiency on a selection of datasets related to medicine and health care.Results: The performance of iNN(k) on a given dataset is shown to depend on the value of k and on whether local or global feature selection is used in the algorithm. The combination of these parameters for which iNN(k) is most effective in addressing the trade-off between accuracy and efficiency is identified for each of the selected datasets. For example, only 42% and 51% on average of features in a complete problem description were needed by iNN(k) to provide accuracy levels of 86.5% and 84.3% respectively on the lymphography and SPECT heart datasets from the UCI machine learning repository.Conclusion: Our results demonstrate the ability of iNN(k) to provide high levels of accuracy on most of the selected datasets, while often requiring the user to provide only a small subset of the features in a complete problem description, and enabling a CCBR system to explain the relevance of any question it asks the user. (C) 2011 Elsevier B.V. All rights reserved.								3	1	0	0	3	0933-3657		WOS:000293101100003	
J	Ong, Meng Sang; Kuang, Ye Chow; Ooi, Melanie Po-Leen; Demidenko, Serge; Liam, Poon Shern								Optimal Dual-Tone Frequency Selection for ADC Sine-Wave Tests								IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT			60	5			1533	1545		10.1109/TIM.2010.2102393			MAY 2011	2011	An automated frequency selection algorithm for dual-tone analog-to-digital converter sine-wave test that guarantees optimal test coverage in the phase-plane is presented. The proposed method relaxes some constraints of the existing phase-space design methodology. This enables wider application of the phase-space method in test frequency selection. The proposed algorithm also extends the previous works by generating a good frequency pair while taking into account various hardware constraints in the production environment. Quality measures for phase-plane coverage is proposed and evaluated, followed by the theoretical analysis and description of the phase-plane uniformity. Extensive computer simulation is carried out to validate the proposed technique.								3	0	0	0	3	0018-9456		WOS:000289204400005	
J	Hafemeister, Christoph; Costa, Ivan G.; Schonhuth, Alexander; Schliep, Alexander								Classifying short gene expression time-courses with Bayesian estimation of piecewise constant functions								BIOINFORMATICS			27	7			946	952		10.1093/bioinformatics/btr037			APR 1 2011	2011	Motivation: Analyzing short time-courses is a frequent and relevant problem in molecular biology, as, for example, 90% of gene expression time-course experiments span at most nine time-points. The biological or clinical questions addressed are elucidating gene regulation by identification of co-expressed genes, predicting response to treatment in clinical, trial-like settings or classifying novel toxic compounds based on similarity of gene expression time-courses to those of known toxic compounds. The latter problem is characterized by irregular and infrequent sample times and a total lack of prior assumptions about the incoming query, which comes in stark contrast to clinical settings and requires to implicitly perform a local, gapped alignment of time series. The current state-of-the-art method (SCOW) uses a variant of dynamic time warping and models time series as higher order polynomials (splines).Results: We suggest to model time-courses monitoring response to toxins by piecewise constant functions, which are modeled as left-right Hidden Markov Models. A Bayesian approach to parameter estimation and inference helps to cope with the short, but highly multivariate time-courses. We improve prediction accuracy by 7% and 4%, respectively, when classifying toxicology and stress response data. We also reduce running times by at least a factor of 140; note that reasonable running times are crucial when classifying response to toxins. In conclusion, we have demonstrated that appropriate reduction of model complexity can result in substantial improvements both in classification performance and running time.								3	0	3	0	3	1367-4803		WOS:000289162000009	
B	Amatriain, Xavier; Jaimes, Alejandro; Oliver, Nuria; Pujol, Josep M.						Ricci, F; Rokach, L; Shapira, B; Kantor, PB		Data Mining Methods for Recommender Systems								RECOMMENDER SYSTEMS HANDBOOK							39	71		10.1007/978-0-387-85820-3_2	10.1007/978-0-387-85820-3		2011	2011	In this chapter, we give an overview of the main Data Mining techniques used in the context of Recommender Systems. We first describe common preprocessing methods such as sampling or dimensionality reduction. Next, we review the most important classification techniques, including Bayesian Networks and Support Vector Machines. We describe the k-means clustering algorithm and discuss several alternatives. We also present association rules and related algorithms for an efficient training process. In addition to introducing these techniques, we survey their uses in Recommender Systems and present cases where they have been successfully applied.								3	0	0	0	3		978-0-387-85819-7	WOS:000293099300002	
J	Karacali, Bilge								Quasi-supervised learning for biomedical data analysis								PATTERN RECOGNITION			43	10			3674	3682		10.1016/j.patcog.2010.04.024			OCT 2010	2010	We present a novel formulation for pattern recognition in biomedical data. We adopt a binary recognition scenario where a control dataset contains samples of one class only, while a mixed dataset contains an unlabeled collection of samples from both classes. The mixed dataset samples that belong to the second class are identified by estimating posterior probabilities of samples for being in the control or the mixed datasets. Experiments on synthetic data established a better detection performance against possible alternatives. The fitness of the method in biomedical data analysis was further demonstrated on real multi-color flow cytometry and multi-channel electroencephalography data. (C) 2010 Elsevier Ltd. All rights reserved.								3	0	2	0	3	0031-3203		WOS:000280006700041	
J	Guo, Yu; Graber, Armin; McBurney, Robert N.; Balasubramanian, Raji								Sample size and statistical power considerations in high-dimensionality data settings: a comparative study of classification algorithms								BMC BIOINFORMATICS			11						447	10.1186/1471-2105-11-447			SEP 3 2010	2010	Background: Data generated using 'omics' technologies are characterized by high dimensionality, where the number of features measured per subject vastly exceeds the number of subjects in the study. In this paper, we consider issues relevant in the design of biomedical studies in which the goal is the discovery of a subset of features and an associated algorithm that can predict a binary outcome, such as disease status. We compare the performance of four commonly used classifiers (K-Nearest Neighbors, Prediction Analysis for Microarrays, Random Forests and Support Vector Machines) in high-dimensionality data settings. We evaluate the effects of varying levels of signal-to-noise ratio in the dataset, imbalance in class distribution and choice of metric for quantifying performance of the classifier. To guide study design, we present a summary of the key characteristics of 'omics' data profiled in several human or animal model experiments utilizing high-content mass spectrometry and multiplexed immunoassay based techniques.Results: The analysis of data from seven 'omics' studies revealed that the average magnitude of effect size observed in human studies was markedly lower when compared to that in animal studies. The data measured in human studies were characterized by higher biological variation and the presence of outliers. The results from simulation studies indicated that the classifier Prediction Analysis for Microarrays (PAM) had the highest power when the class conditional feature distributions were Gaussian and outcome distributions were balanced. Random Forests was optimal when feature distributions were skewed and when class distributions were unbalanced. We provide a free open-source R statistical software library (MVpower) that implements the simulation strategy proposed in this paper.Conclusion: No single classifier had optimal performance under all settings. Simulation studies provide useful guidance for the design of biomedical studies involving high-dimensionality data.								3	0	4	0	4	1471-2105		WOS:000282655600002	
J	El-Yaniv, Ran; Wiener, Yair								On the Foundations of Noise-free Selective Classification								JOURNAL OF MACHINE LEARNING RESEARCH			11				1605	1641					MAY 2010	2010	We consider selective classification, a term we adopt here to refer to 'classification with a reject option.' The essence in selective classification is to trade-off classifier coverage for higher accuracy. We term this trade-off the risk-coverage (RC) trade-off. Our main objective is to characterize this trade-off and to construct algorithms that can optimally or near optimally achieve the best possible trade-offs in a controlled manner. For noise-free models we present in this paper a thorough analysis of selective classification including characterizations of RC trade-offs in various interesting settings.								3	0	0	0	3	1532-4435		WOS:000282522000002	
J	Caulier, Yannick								Inspection of complex surfaces by means of structured light patterns								OPTICS EXPRESS			18	7			6642	6660					MAR 29 2010	2010	This paper addresses the generalization of a surface inspection methodology developed within an industrial context for the characterization of specular cylindrical surfaces. The principle relies on the interpretation of a stripe pattern, obtained after projecting a structured light onto the surface to be inspected. The main objective of this paper is to apply this technique to a broader range of surface geometries and types, i.e. to free-form rough and free-form specular shapes. One major purpose of this paper is to propose a general free-form stripe image interpretation approach on the basis of a four step procedure: (i) comparison of different feature-based image content description techniques, (ii) determination of optimal feature sub-groups, (iii) fusion of the most appropriate ones, and (iv) selection of the optimal features. The first part of this paper is dedicated to the general problem statement with the definition of different image data sets that correspond to various types of free-form rough and specular shapes recorded with a structured illumination. The second part deals with the definition and optimization of the most appropriate pattern recognition process. It is shown that this approach leads to an increase in the classification rates of more than 2 % between the initial fused set and the selected one. Then, it is demonstrated that with approximately a fourth of the initial features, similar high classification rates of free-form surfaces can be obtained. (C) 2010 Optical Society of America								3	1	0	0	4	1094-4087		WOS:000276602000024	
J	Wei, Jin-Mao; Wang, Shu-Qin; Yuan, Xiao-Jie								Ensemble Rough Hypercuboid Approach for Classifying Cancers								IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			22	3			381	391		10.1109/TKDE.2009.114			MAR 2010	2010	Cancer classification is the critical basis for patient-tailored therapy. Conventional histological analysis tends to be unreliable because different tumors may have similar appearance. The advances in microarray technology make individualized therapy possible. Various machine learning methods can be employed to classify cancer tissue samples based on microarray data. However, few methods can be elegantly adopted for generating accurate and reliable as well as biologically interpretable rules. In this paper, we introduce an approach for classifying cancers based on the principle of minimal rough fringe. For training rough hypercuboid classifiers from gene expression data sets, the method dynamically evaluates all available genes and sifts the genes with the smallest implicit regions as the dimensions of implicit hypercuboids. An unseen object is predicted to be a certain class if it falls within the corresponding class hypercuboid. Based upon the method, ensemble rough hypercuboid classifiers are subsequently constructed. Experimental results on some open cancer gene expression data sets show that the proposed method is capable of generating accurate and interpretable rules compared with some other machine learning methods. Hence, it is a feasible way of classifying cancer tissues in biomedical applications.								3	0	0	0	3	1041-4347		WOS:000273707000006	
J	da Costa, Elaine Sobral; Peres, Rodrigo Tosta; Almeida, Julia; Lecrevisse, Quentin; Elena Arroyo, Maria; Teodosio, Cristina; Pedreira, Carlos Eduardo; van Dongen, Jacques J. M.; Orfao, Alberto		EuroFlow Consortium		IBSAL, Secretaria/H-3719-2011				Harmonization of Light Scatter and Fluorescence Flow Cytometry Profiles Obtained After Staining Peripheral Blood Leucocytes for Cell Surface-Only Versus Intracellular Antigens with the Fix & Perm (TM) Reagent								CYTOMETRY PART B-CLINICAL CYTOMETRY			78B	1			11	20		10.1002/cyto.b.20486			JAN 2010	2010	Staining for intracellular markers with the Fix & PerM (TM) reagent is associated with variations in the scatter properties of leucocytes, limiting automated analysis of flow cytometry (FCM) data. Here, we investigated those variables significantly contributing to changes in the light scatter, autofluorescence, and bcl2 staining characteristics of peripheral blood (PB) leucocytes, after fixation with Fix & Perm (TM). Our major aim was to evaluate a new mathematical approach for automated harmonization of FCM data from datafiles corresponding to aliquots of a sample treated with cell-surface-only versus Fix & Perm intracellular staining techniques. Overall, neither the anticoagulant used nor sample storage for <24 h showed significant impact on the light scatter and fluorescence properties of PB leucocytes; similarly, the duration of the fixation period (once >15 min were used) had a minimum impact on the FCM properties of PB leucocytes. Conversely, changes in cell/protein concentrations and the fixative/sample (vol/vol) ratio had a clear impact on the light scatter features of some populations of leucocytes. Accordingly, lower cell/protein concentrations were associated with lower scatter values, particularly for the neutrophils. Such changes could be partially corrected through the use of higher fixative to sample volume ratios. Despite the variable changes detected between aliquots of the same sample treated with cell surface-only versus intracellular staining procedures, the new mathematical approach here proposed and evaluated for automated harmonization of common parameters in both datafiles, could correct the FCM profiles of leucocytes derived from cells undergoing conventional fixation/permeabilization procedures, and made them indistinguishable from those corresponding to aliquots of the same sample treated with cell-surface-only staining techniques.								3	0	3	0	3	1552-4949		WOS:000273168100003	
J	Gayer, Gabrielle								Perception of probabilities in situations of risk: A case based approach								GAMES AND ECONOMIC BEHAVIOR			68	1			130	143		10.1016/j.geb.2009.05.002			JAN 2010	2010	This paper provides a description of a possible mental process individuals go through in their attempt to comprehend stated probabilities in simple lotteries. The evaluation of probabilities is based on the following main components: lotteries encountered in the past, the realizations of these lotteries, and the similarity between stated probabilities. A probability is evaluated based on the experienced relative frequencies of outcomes that had that stated probability, as well as outcomes of other lotteries that had similar stated probabilities. This process may result in distortion of probabilities as observed in the literature, and in particular, in overvaluing low probabilities and undervaluing high probabilities. If the decision maker uses a less permissive similarity function as the size of memory grows, she will learn the real value of the stated probabilities. If, however, the similarity function is independent of memory, biases persist even when data are accumulated. (C) 2009 Elsevier Inc. All rights reserved.								3	0	0	0	3	0899-8256		WOS:000273928700010	
J	Marini, Federico								Classification Methods in Chemometrics								CURRENT ANALYTICAL CHEMISTRY			6	1			72	79					JAN 2010	2010	Pattern recognition methods, i.e. the methods concentrating on the possibility of assigning an object to a class based on the result of a set of measurements are ubiquitous in chemometrics.In this paper, the main chemometric classification methods are discussed in terms of their nature, behavior, advantages and drawbacks. Both parametric and non parametric or discriminant and modeling techniques are illustrated together with a discussion of some applications to real world problems.								3	0	1	0	3	1573-4110		WOS:000273601800011	
J	Yang, Lei; Xia, Jun-Feng; Gui, Jie								Prediction of Protein-Protein Interactions from Protein Sequence Using Local Descriptors								PROTEIN AND PEPTIDE LETTERS			17	9			1085	1090					2010	2010	With a huge amount of protein sequence data, the computational method for protein-protein interaction (PPI) prediction using only the protein sequences information have drawn increasing interest. In this article, we propose a sequence-based method based on a novel representation of local protein sequence descriptors. Local descriptors account for the interactions between residues in both continuous and discontinuous regions of a protein sequence, so this method enables us to extract more PPI information from the sequence. A series of elaborate experiments are performed to optimize the prediction model by varying the parameter k and the distance measuring function of the k-nearest neighbors learning system and the ways of coding a protein pair. When performed on the PPI data of Saccharomyces cerevisiae, the method achieved 86.15% prediction accuracy with 81.03% sensitivity at the precision of 90.24%. An independent data set of 986 Escherichia coli PPIs was used to evaluate this prediction model and the prediction accuracy is 73.02%. Given the complex nature of PPIs, the performance of our method is promising, and it can be a helpful supplement for PPIs prediction.				5th International Conference on Intelligent Computing	SEP 16-19, 2009	IEEE Computat Intelligence Soc; Int Neural Network Soc; Natl Nat Sci Fdn China	Ulsan, SOUTH KOREA	3	0	2	0	3	0929-8665		WOS:000281421500004	
J	Eskofier, B.; Oleson, M.; DiBenedetto, C.; Hornegger, J.								Embedded surface classification in digital sports								PATTERN RECOGNITION LETTERS			30	16			1448	1456		10.1016/j.patrec.2009.08.004			DEC 1 2009	2009	In this presentation, we give a detailed analysis of the considerations needed for mapping the complete pattern classification chain to the restricted embedded system hardware environment. We describe the methodology of the design, realization and testing process that takes these hardware limitations into account. For this purpose, we consider a particular embedded application from the field of digital sports: a novel running shoe that is capable of sensing run-specific parameters and adapting the cushioning setting accordingly. Of utmost importance in this context is the classification of the current surface condition in order to enable optimal adaptation to the prevailing situation. Following our design approach, we provide a classification system with a runner-independent surface classification rate of more than 80%. This system is implemented in the current version of the aforementioned running shoe. The presented methodology is quite general as it makes no system-dependent assumptions and can thus be transferred to many other embedded classification applications. (C) 2009 Elsevier B.V. All rights reserved.								3	0	2	0	3	0167-8655		WOS:000271849300002	
J	Li, Jing; Allinson, Nigel M.								Subspace learning-based dimensionality reduction in building recognition								NEUROCOMPUTING			73	1-3	SI		324	330		10.1016/j.neucom.2009.08.016			DEC 2009	2009	Building recognition is a relatively specific recognition task in object recognition, which is challenging since it encounters rotation, scaling, illumination changes, occlusion. etc. Subspace learning, which dominates dimensionality reduction, has been widely exploited in computer vision research in recent years. it consists of classical linear dimensionality reduction methods, manifold learning, etc. To explore how different subspace learning algorithms affect building recognition, some representative algorithms, i.e., principal component analysis, linear discriminant analysis, locality preserving projections (unsupervised/supervised), and semi-supervised discriminant analysis, are applied for dimensionality reduction. Moreover, a building recognition scheme based on biologically-inspired feature extraction is proposed in this paper. Experiments undertaken on our own building database demonstrate that the proposed scheme embedded with subspace learning can achieve satisfactory results. (C) 2009 Elsevier B.V. All rights reserved.								3	2	0	0	5	0925-2312		WOS:000272607000038	
J	Chen, Zesheng; Ji, Chuanyi								An Information-Theoretic View of Network-Aware Malware Attacks								IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY			4	3			530	541		10.1109/TIFS.2009.2025847			SEP 2009	2009	This work provides an information-theoretic view to better understand the relationships between aggregated vulnerability information viewed by attackers and a class of randomized epidemic scanning algorithms. In particular, this work investigates three aspects: 1) a network vulnerability as the nonuniform vulnerable-host distribution, 2) threats, i.e., intelligent malwares that exploit such a vulnerability, and 3) defense, i.e., challenges for fighting the threats. We first study five large data sets and observe consistent clustered vulnerable-host distributions. We then present a new metric, referred to as the nonuniformity factor, that quantifies the unevenness of a vulnerable-host distribution. This metric is essentially the Renyi information entropy that unifies the nonuniformity of a vulnerable-host distribution with different malware-scanning methods. Next, we draw a relationship between Renyi entropies and randomized epidemic scanning algorithms. We find that the infection rates of malware-scanning methods are characterized by the Renyi entropies that relate to the information bits in a nonunform vulnerable-host distribution extracted by a randomized scanning algorithm. Meanwhile, we show that a representative network-aware malware can increase the spreading speed by exactly or nearly a nonuniformity factor when compared to a random-scanning malware at an early stage of malware propagation. This quantifies that how much more rapidly the Internet can be infected at the early stage when a malware exploits an uneven vulnerable-host distribution as a network-wide vulnerability. Furthermore, we analyze the effectiveness of defense strategies on the spread of network-aware malwares. Our results demonstrate that counteracting network-aware malwares is a significant challenge for the strategies that include host-based defenses and IPv6.								3	1	1	0	4	1556-6013		WOS:000269155900022	
J	Dalton, Lori; Ballarin, Virginia; Brun, Marcel				Dalton, Lori/G-7254-2012				Clustering Algorithms: On Learning, Validation, Performance, and Applications to Genomics								CURRENT GENOMICS			10	6			430	445					SEP 2009	2009	The development of microarray technology has enabled scientists to measure the expression of thousands of genes simultaneously, resulting in a surge of interest in several disciplines throughout biology and medicine. While data clustering has been used for decades in image processing and pattern recognition, in recent years it has joined this wave of activity as a popular technique to analyze microarrays. To illustrate its application to genomics, clustering applied to genes from a set of microarray data groups together those genes whose expression levels exhibit similar behavior throughout the samples, and when applied to samples it offers the potential to discriminate pathologies based on their differential patterns of gene expression. Although clustering has now been used for many years in the context of gene expression microarrays, it has remained highly problematic. The choice of a clustering algorithm and validation index is not a trivial one, more so when applying them to high throughput biological or medical data. Factors to consider when choosing an algorithm include the nature of the application, the characteristics of the objects to be analyzed, the expected number and shape of the clusters, and the complexity of the problem versus computational power available. In some cases a very simple algorithm may be appropriate to tackle a problem, but many situations may require a more complex and powerful algorithm better suited for the job at hand. In this paper, we will cover the theoretical aspects of clustering, including error and learning, followed by an overview of popular clustering algorithms and classical validation indices. We also discuss the relative performance of these algorithms and indices and conclude with examples of the application of clustering to computational biology.								3	0	2	0	3	1389-2029		WOS:000269241500007	
J	Jung, Sabum; Lim, Taesoo; Kim, Dongsoo								Integrating radial basis function networks with case-based reasoning for product design								EXPERT SYSTEMS WITH APPLICATIONS			36	3			5695	5701		10.1016/j.eswa.2008.06.099			APR 2009	2009	This paper presents a case-based design expert system that automatically determines the design values of a product. We focus on the design problem of a shadow mask which is a core component of monitors in the electronics industry. In case-based reasoning (CBR), it is important to retrieve similar cases and adapt them to meet design specifications exactly. Notably, difficulties in automating the adaptation process have prevented designers from being able to use design expert systems easily and efficiently. In this paper, we present a hybrid approach combining CBR and artificial neural networks in order to solve the problems Occurring during the adaptation process. We first constructed a radial basis function network (RBFN) composed of representative cases created by K-means clustering. Then, the representative case most similar to the current problem was adjusted using the network. The rationale behind the proposed approach is discussed, and experimental results acquired from real shadow mask design are presented. Using the design expert system, designers can reduce design time and errors and enhance the total quality of design. Furthermore, the expert system facilitates effective sharing of design knowledge among designers. (C) 2008 Elsevier Ltd. All rights reserved.								3	1	0	0	4	0957-4174		WOS:000263584100186	
J	Chuang, Li-Yeh; Yang, Cheng-Huei; Yang, Cheng-Hong				Chuang, Li-Yeh/E-5005-2011				Tabu Search and Binary Particle Swarm Optimization for Feature Selection Using Microarray Data								JOURNAL OF COMPUTATIONAL BIOLOGY			16	12			1689	1703		10.1089/cmb.2007.0211			2009	2009	Gene expression profiles have great potential as a medical diagnosis tool because they represent the state of a cell at the molecular level. In the classification of cancer type research, available training datasets generally have a fairly small sample size compared to the number of genes involved. This fact poses an unprecedented challenge to some classification methodologies due to training data limitations. Therefore, a good selection method for genes relevant for sample classification is needed to improve the predictive accuracy, and to avoid incomprehensibility due to the large number of genes investigated. In this article, we propose to combine tabu search (TS) and binary particle swarm optimization (BPSO) for feature selection. BPSO acts as a local optimizer each time the TS has been run for a single generation. The K-nearest neighbor method with leave-one-out cross-validation and support vector machine with one-versus-rest serve as evaluators of the TS and BPSO. The proposed method is applied and compared to the 11 classification problems taken from the literature. Experimental results show that our method simplifies features effectively and either obtains higher classification accuracy or uses fewer features compared to other feature selection methods.								3	0	1	0	3	1066-5277		WOS:000273709400005	
S	Salmeri, Alessia; Licciardi, Carlo Alberto; Lamorte, Luca; Valla, Massimo; Giannantonio, Roberta; Sgroi, Marco						Mokhtari, M; Khalil, I; Bauchet, J; Zhang, D; Nugent, C		An Architecture to Combine Context Awareness and Body Sensor Networks for Health Care Applications								AMBIENT ASSISTIVE HEALTH AND WELLNESS MANAGEMENT IN THE HEART OF THE CITY, PROCEEDING	Lecture Notes in Computer Science		5597				90	97					2009	2009	Information derived from wearable sensors, such as illness/fall alarms, can be enhanced with context information to provide advanced health care and assisted living applications. In this paper we describe an architecture that combines sensor and context data into a telecommunication service to detect emergency situations and generate alarm calls according to user's preferences and contacts geographic proximity.				7th International Conference on Smart Homes and Health Telematics	JUL 01-03, 2009		Tour, FRANCE	3	0	0	0	3	0302-9743	978-3-642-02867-0	WOS:000270130800012	
B	Steinbach, Michael; Tan, Pang-Ning						Wu, X; Kumar, V		kNN: k-Nearest Neighbors								TOP TEN ALGORITHMS IN DATA MINING	Chapman & Hall-CRC Data Mining and Knowledge Discovery Series						151	161			10.1201/9781420089653		2009	2009									3	0	1	0	3		978-1-4200-8964-6	WOS:000267023600008	
B	Steinberg, Dan						Wu, X; Kumar, V		CART: Classification and Regression Trees								TOP TEN ALGORITHMS IN DATA MINING	Chapman & Hall-CRC Data Mining and Knowledge Discovery Series						179	201		10.1201/9781420089653.ch10	10.1201/9781420089653		2009	2009									3	0	1	0	3		978-1-4200-8964-6	WOS:000267023600010	
B	Xing, Zhengzheng; Pei, Jian; Yu, Philip S.						Boutilier, C		Early Prediction on Time Series: A Nearest Neighbor Approach								21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS							1297	1302					2009	2009	In this paper, we formulate the problem of early classification of time series data, which is important in some time-sensitive applications such as health-informatics. We introduce a novel concept of MPL (Minimum Prediction Length) and develop ECTS (Early Classification on Time Series), an effective 1-nearest neighbor classification method. ECTS makes early predictions and at the same time retains the accuracy comparable to that of a 1NN classifier using the full-length time series. Our empirical study using benchmark time series data sets shows that ECTS works well on the real data sets where 1NN classification is effective.				21st Internation Joint Conference on Artifical Intelligence (IJCAI-09)	JUL 11-17, 2009		Pasadena, CA	3	0	1	0	3		978-1-57735-426-0	WOS:000283727900206	
J	Morton, Kenneth D.; Torrione, Peter A., Jr.; Throckmorton, Chandra S.; Collins, Leslie M.								Mandarin Chinese tone identification in cochlear implants: Predictions from acoustic models								HEARING RESEARCH			244	1-2			66	76		10.1016/j.heares.2008.07.008			OCT 2008	2008	It has been established that current cochlear implants do not supply adequate spectral information for perception of tonal languages. Comprehension of a tonal language, such as Mandarin Chinese, requires recognition of lexical tones. New strategies of cochlear stimulation such as variable stimulation rate and current steering may provide the means of delivering more spectral information and thus may provide the auditory fine-structure required for tone recognition. Several cochlear implant signal processing strategies are examined in this study, the continuous interleaved sampling (CIS) algorithm, the frequency amplitude modulation encoding (FAME) algorithm, and the multiple carrier frequency algorithm (MCFA). These strategies provide different types and amounts of spectral information. Pattern recognition techniques can be applied to data from Mandarin Chinese tone recognition tasks using acoustic models as a means of testing the abilities of these algorithms to transmit the changes in fundamental frequency indicative of the four lexical tones. The ability of processed Mandarin Chinese tones to be correctly classified may predict trends in the effectiveness of different signal processing algorithms in cochlear implants. The proposed techniques can predict trends in performance of the signal processing techniques in quiet conditions but fail to do so in noise. (C) 2008 Elsevier B.V. All rights reserved.								3	0	1	0	3	0378-5955		WOS:000260655200008	
J	Chen, Yuehui; Chen, Feng; Yang, Jack Y.; Yang, Mary Qu								Ensemble voting system for multiclass protein fold recognition								INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			22	4			747	763		10.1142/S0218001408006454			JUN 2008	2008	Protein structure classification is an important issue in understanding the associations between sequence and structure as well as possible functional and evolutionary relationships. Recently structural genomes initiatives and other high-throughput experiments have populated the biological databases at a rapid pace. In this paper, three types of classifiers, k nearest neighbors, class center and nearest neighbor and probabilistic neural networks and their homogenous ensemble for multiclass protein fold recognition problem are evaluated firstly, and then a heterogenous ensemble Voting System is designed for the same problem. The different features and/or their combinations extracted from the protein fold dataset are used in these classification models. The heterogenous classification results are then put into a voting system to get the final result. The experimental results show that the proposed method can improve prediction accuracy by 4%-10% on a benchmark dataset containing 27 SCOP folds.								3	0	0	0	3	0218-0014		WOS:000257761800006	
J	Carrizosa, Emilio; Martin-Barragan, Belen; Morales, Dolores Romero								Multi-group support vector machines with measurement costs: A biobjective approach								DISCRETE APPLIED MATHEMATICS			156	6			950	966		10.1016/j.dam.2007.05.060			MAR 15 2008	2008	Support Vector Machine has shown to have good performance in many practical classification settings. In this paper we propose, for multi-group classification, a biobjective optimization model in which we consider not only the generalization ability (modeled through the margin maximization), but also costs associated with the features. This cost is not limited to an economical payment, but can also refer to risk, computational effort, space requirements, etc. We introduce a Biobjective Mixed Integer Problem, for which Pareto optimal solutions are obtained. Those Pareto optimal solutions cot-respond to different classification rules, among which the user would choose the one yielding the most appropriate compromise between the cost and the expected misclassification rate. (C) 2007 Elsevier B.V. All rights reserved.								3	0	0	0	3	0166-218X		WOS:000254482400011	
S	Bagherjeiran, A.; Eick, C. F.						Perner, P		Distance Function Learning for Supervised Similarity Assessment								CASE-BASED REASONING ON IMAGES AND SIGNALS	Studies in Computational Intelligence		73				91	126			10.1007/978-3-540-73180-1		2008	2008	Assessing the similarity between cases is a prerequisite for many case-based reasoning tasks. This chapter centers on distance function learning for supervised similarity assessment. First a framework for supervised similarity assessment is introduced. Second, three supervised distance function learning approaches from the areas of pattern classification, supervised clustering, and information retrieval are discussed, and their results for two supervised learning tasks will be explained and visualized. In each of these different areas, we show how the method can be applied to areas of case-based reasoning. Finally, a detailed literature survey will be given.								3	0	0	0	3	1860-949X	978-3-540-73178-8	WOS:000271238500003	
S	Costa, Eduardo P.; Lorena, Ana C.; Carvalho, Andre C. P. L. F.; Freitas, Alex A.				Freitas, Alex/H-1249-2011; Lorena, Ana/A-4494-2008		Bazzan, ALC; Craven, M; Martins, NF		Top-down hierarchical ensembles of classifiers for predicting G-Protein-Coupled-Receptor functions								ADVANCES IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY, PROCEEDINGS	LECTURE NOTES IN BIOINFORMATICS		5167				35	46					2008	2008	Despite the recent advances in Molecular Biology, the function of a large amount of proteins is still unknown. An approach that can be used in the prediction of a protein function consists of searching against secondary databases, also known as signature databases. Different strategies can be applied to use protein signatures in the prediction of function of proteins. A sophisticated approach consists of inducing a classification model for this prediction. This paper applies five hierarchical classification methods based on the standard Top-Down approach and one hierarchical classification method based on a new approach named Top-Down Ensembles - based on the hierarchical combination of classifiers - to three different protein functional classification datasets that employ protein signatures. The algorithm based on the Top-Down Ensembles approach presented slightly better results than the other algorithms, indicating that combinations of classifiers can improve the performance of hierarchical classification models.				3rd Brazilian Symposium on Bioinformatics (BSB 2008)	AUG 28-30, 2008	UFABC, CMCC; Brazilian Comp Soc; FAPESP; CNPq; CAPES; CLC bio; SGI	Santo Andre, BRAZIL	3	0	0	0	3	0302-9743	978-3-540-85556-9	WOS:000259140500004	
S	Ho, Tin Kam						DaVitoria Lobo, N; Kasparis, T; Roli, F; Kwok, JT; Georgiopoulos, M; Anagnostopoulos, GC; Loog, M		Data Complexity Analysis: Linkage between Context and Solution in Classification								STRUCTURAL, SYNTACTIC, AND STATISTICAL PATTERN RECOGNITION	Lecture Notes in Computer Science		5342				986	995					2008	2008	For a classification problem that is implicitly represented by a training data set, analysis of data complexity provides a linkage between context and solution. Instead of directly optimizing classification accuracy by tuning the learning algorithms, one may seek changes ill the data sources and feature transformations to simplify the data geometry. Simplified class geometry benefits learning in a way common to many methods. We review some early results in data complexity analysis, compare these to recent advances ill manifold learning; and suggest directions for further research.				Joint International Workshop on Structural, Syntactic, and Statistical Pattern Recognition	DEC 04-16, 2008	Int Assoc Pattern Recognit, Tech Committee	Univ Central Florida, Orlando, FL	3	0	0	0	3	0302-9743	978-3-540-89688-3	WOS:000263676700098	
J	Jeng, Shuen-Lin; Huang, Ya-Ti								Time series classification based on spectral analysis								COMMUNICATIONS IN STATISTICS-SIMULATION AND COMPUTATION			37	1			132	142		10.1080/03610910701723971			2008	2008	For time series data with obvious periodicity (e.g., electric motor systems and cardiac monitor) or vague periodicity (e.g., earthquake and explosion, speech, and stock data), frequency-based techniques using the spectral analysis can usually capture the features of the series. By this approach, we are able not only to reduce the data dimensions into frequency domain but also utilize these frequencies by general classification methods such as linear discriminant analysis (LDA) and k-nearest-neighbor (KNN) to classify the time series. This is a combination of two classical approaches. However, there is a difficulty in using LDA and KNN in frequency domain due to excessive dimensions of data. We overcome the obstacle by using Singular Value Decomposition to select essential frequencies. Two data sets are used to illustrate our approach. The classification error rates of our simple approach are comparable to those of several more complicated methods.								3	0	0	0	3	0361-0918		WOS:000252321400010	
S	Olvera-Lopez, J. Arturo; Carrasco-Ochoa, J. Ariel; Martinez-Trinidad, J. Fco.						RuizShulcloper, J; Kropatsch, WG		Prototype Selection Via Prototype Relevance								PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		5197				153	160					2008	2008	In Pattern recognition, the supervised classifiers use a training set T for classifying new prototypes. In practice, not all information in T is useful for classification therefore it is necessary to discard irrelevant prototypes from T. This process is known as prototype selection, which is an important task for classifiers since through this process the time in the training and/or classification stages could be reduced. Several prototype selection methods have been proposed following the Nearest Neighbor (NN) ruled in this work. we propose a new prototype selection method based oil the prototype relevance and border prototypes, which is faster (over large datasets) than the other tested prototype selection methods. We report experimental results showing the effectiveness of our method and compare accuracy and runtimes against other prototype selection methods.				13th Iberoamerican Congress on Progress in Pattern Recognition, Image Analysis and Applications	SEP 09-12, 2008	Adv Technol Applicat Ctr; Int Assoc Pattern Recognit; Cuban Assoc Pattern Recognit; Cuban Soc Math & Comp Sci; Mexican Assoc Comp Vis, Neural Comp & Robotics; SIGPR-SBC; Spanish Assoc Pattern Recognit & Image Anal; Portuguese Assoc Pattern Recognit	Havana, CUBA	3	0	0	0	3	0302-9743	978-3-540-85919-2	WOS:000259899200019	
S	Yang, Cheng-Hong; Huang, Chi-Chun; Wu, Kuo-Chuan; Chang, Hsin-Yun						Fyfe, C; Kim, D; Lee, SY; Yin, H		A Novel GA-Taguchi-Based Feature Selection Method								INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING - IDEAL 2008	Lecture Notes in Computer Science		5326				112	119					2008	2008	This work presents a novel GA-Taguchi-based feature selection method. Genetic algorithms are utilized with randomness for "global search" of the entire search space of the intractable search problem. Various genetic operations. including crossover. Mutation, selection and replacement are performed to assist the search procedure in escaping from sub-optimal Solutions. In each iteration in the proposed nature-inspired method, the Taguchi methods are employed for "local search" of the entire search space and thus can help explore better feature subsets for next iteration. The two-level orthogonal array is utilized for a well-organized and balanced comparison of two levels for features-a feature is or is not selected for pattern classification-and interactions among features. The signal-to-noise ratio (SNR) is then used to determine the robustness of the features. As a result feature subset evaluation efforts call be significantly reduced and a superior feature Subset with high classification performance call be obtained. Experiments arc performed oil different application domains to demonstrate the performance of the proposed nature-inspired method. The proposed hybrid GA-Taguchi-based approach, with wrapper nature, yields superior performance and improves classification accuracy in pattern classification.				9th International Conference on Intelligent Data Engineering and Automated Learn	NOV 02-05, 2008	Dept Bio & Brain Engn; KAIST; Air Force Off Sci Res; Asian Office Aerosp Res & Dev	Daejeon, SOUTH KOREA	3	0	0	0	3	0302-9743	978-3-540-88905-2	WOS:000261445100015	
J	Yang, Jack Y.; Yang, Mary Qu								Identification of Intrinsically Unstructured Proteins using hierarchical classifier								INTERNATIONAL JOURNAL OF DATA MINING AND BIOINFORMATICS			2	2			121	133		10.1504/IJDMB.2008.019093			2008	2008	It is suggested, that protein functions only when folded into a particular 3-D structure. Recently, many protein regions and some entire proteins have been identified with no definite tertiary structure, but presenting instead as dynamic, disorder ensembles Under different physiochemical circimstances. These proteins and regions are known as Intrinsically Unstructured regions and Proteins (IUP). We constructcd a Recursive Maximum Contrast Tree (RMCT) based classifier to identify IUP. The classifier has been benchmarked against industrial standard PONDR VLXT on out-of-sample, clata byexternalrrial evaluators. The IUP predictor is a viable alternative software tool for identifying intrinsic unstructured regions and proteins.								3	2	2	0	5	1748-5673		WOS:000258739300002	
J	Ghosh, Anil K.								On nearest neighbor classification using adaptive choice of k								JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS			16	2			482	502		10.1198/106186007x208380			JUN 2007	2007	Nearest neighbor classification is one of the simplest and popular methods for statistical pattern recognition. It classifies an observation x to the class, which is the most frequent in the neighborhood of x. The size of this neighborhood is usually determined by a predefined parameter k. Normally, one uses cross-validation techniques to estimate the optimum value of this parameter, and that estimated value is used for classifying all observations. However, in classification problems, in addition to depending on the training sample, a good choice of k depends on the specific observation to be classified. Therefore, instead of using a fixed value of k over the entire measurement space, a spatially adaptive choice of k may be more useful in practice. This article presents one such adaptive nearest neighbor classification technique, where the value of k is selected depending on the distribution of competing classes in the vicinity of the observation to be classified. The utility of the proposed method has been illustrated using some simulated examples and well-known benchmark datasets. Asymptotic optimality of its misclassification rate has been derived under appropriate regularity conditions.								3	0	0	0	3	1061-8600		WOS:000247056300011	
J	Kohler, Michael; Krzyzak, Adam								On the rate of convergence of local averaging plug-in classification rules under a margin condition								IEEE TRANSACTIONS ON INFORMATION THEORY			53	5			1735	1742		10.1109/TIT.2007.894625			MAY 2007	2007	The rates of convergence of plug-in kernel, partitioning, and nearest neighbors classification rules are analyzed. A margin condition, which measures how quickly the a posteriori probabilities cross the decision boundary, smoothness conditions on the a posteriori probabilities, and boundedness of the feature vector are imposed. The rates of convergence of the plug-in classifiers shown in this paper are faster than previously known.				IEEE International Symposium on Information Theory	JUL 09-14, 2006	IEEE Informat Theory Soc; USN, Dept Navy Sci & Technol; Microsoft; Natl Sci Fdn	Seattle, WA	3	0	1	0	3	0018-9448		WOS:000246034600008	
S	Antonio Martin, Jose H.; de Lope, Javier				Martin H., Jose Antonio/A-2388-2009		Diaz, RM; Pichler, F; Arencibia, AQ		A k-NN based perception scheme for Reinforcement Learning								COMPUTER AIDED SYSTEMS THEORY- EUROCAST 2007	LECTURE NOTES IN COMPUTER SCIENCE		4739				138	145					2007	2007	A perception scheme for Reinforcement Learning (RL) is developed as a function approximator. The main motivation for the development of this scheme is the need for generalization when the problem to be solved has continuous state variables. We propose a solution to the generalization problem in RL algorithms using a k-nearest-neighbor pattern classification (k-NN). By means of the k-NN technique we investigate the effect of collective decision making as a mechanism of perception and action-selection and a sort of back-propagation of its proportional influence in the action-selection process as the factor that moderate the learning of each decision making unit. A very well known problem is presented as a case study to illustrate the results of this k-NN based perception scheme.				11th International Conference on Computer Aided Systems Theory	FEB 12-16, 2007		Elder Museum Sci & Technol, Las Palmas, SPAIN	3	0	0	0	3	0302-9743	978-3-540-75866-2	WOS:000251543000018	
S	Babu, V. Suresh; Viswanath, P.						Ghosh, A; De, RK; Pal, SK		Weighted k-nearest leader classifier for large data sets								PATTERN RECOGNITION AND MACHINE INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		4815				17	24					2007	2007	Leaders clustering method is a fast one and can be used to derive prototypes called leaders from a large training set which can be used in designing a classifier. Recently nearest leader based classifier is shown to be a faster version of the nearest neighbor classifier, but its performance can be a degraded one since the density information present in the training set is lost while deriving the prototypes. In this paper we present a generalized weighted k-nearest leader based classifier which is a faster one and also an on-par classifier with the k-nearest neighbor classifier. The method is to find the relative importance of each prototype which is called its weight and to use them in the classification. The design phase is extended to eliminate some of the noisy prototypes to enhance the performance of the classifier. The method is empirically verified using some standard data sets and a comparison is drawn with some of the earlier related methods.				2nd International Conference on Pattern Recognition and Machine Intelligence	DEC 18-22, 2007	Indian Stat Inst, Machine Intelligence Univ; ISI Ctr Soft Comp Res; Int Assoc Pattern Recognit; Int Ctr Pure & Appl Math; Web Intelligence Consortium; Yahoo India Res & Dev; Philips Res Asia	Calcutta, INDIA	3	0	0	0	3	0302-9743	978-3-540-77045-9	WOS:000252140200003	
S	Hernandez-Rodriguez, Selene; Martinez-Trinidad, J. Fco.; Ariel Carrasco-Ochoa, J.						Rueda, L; Mery, D; Kittler, J		Fast k most similar neighbor classifier for mixed data based on a tree structure								PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		4756				407	416					2007	2007	In this work, a fast k most similar neighbor (k-MSN) classifier for mixed data is presented. The k nearest neighbor (k-NN) classifier has been a widely used nonparametric technique in Pattern Recognition. Many fast k-NN classifiers have been developed to be applied on numerical object descriptions, most of them based on metric properties to avoid object comparisons. However, in some sciences as Medicine, Geology, Sociology, etc., objects are usually described by numerical and non numerical features (mixed data). In this case, we can not assume the comparison function satisfies metric properties. Therefore, our classifier is based on search algorithms suitable for mixed data and non-metric comparison functions. Some experiments and a comparison against other two fast k-NN methods, using standard databases, are presented.				12th Iberoamerican Congress on Pattern Recognition	NOV 13-16, 2007	Univ Santiago Chile, Dept Indormat Ingn; Tech Univ Feder Santa Maria, Dept Informat Tech	Valparaiso, CHILE	3	0	0	0	3	0302-9743	978-3-540-76724-4	WOS:000252725900043	
J	Plaza, Enric; Ontanon, Santiago								Learning collaboration strategies for committees of learning agents								AUTONOMOUS AGENTS AND MULTI-AGENT SYSTEMS			13	3			429	461		10.1007/s10458-006-0015-x			NOV 2006	2006	A main issue in cooperation in multi-agent systems is how an agent decides in which situations is better to cooperate with other agents, and with which agents does the agent cooperate. Specifically in this paper we focus on multi-agent systems composed of learning agents, where the goal of the agents is to achieve a high accuracy on predicting the correct solution of the problems they encounter. For that purpose, when encountering a new problem each agent has to decide whether to solve it individually or to ask other agents for collaboration. We will see that learning agents can collaborate forming committees in order to improve performance. Moreover, in this paper we will present a proactive learning approach that will allow the agents to learn when to convene a committee and with which agents to invite to join the committee. Our experiments show that learning results in smaller committees while maintaining (and sometimes improving) the problem solving accuracy than forming committees composed of all agents.								3	0	0	0	3	1387-2532		WOS:000240316500006	
J	Zhao, QF								Inducing NNC-Trees with the R-4-rule								IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			36	3			520	533		10.1109/TSMCB.2005.861868			JUN 2006	2006	An NNC-Tree is a decision tree (DT) with each non-terminal node containing a nearest neighbor classifier (NNC). Compared with the conventional axis-parallel DTs (APDTs), the NNC-Trees can be more efficient, because the decision boundary made by an NNC is more complex than an axis-parallel hyperplane. Compared with single-layer NNCs, the NNC-Trees can classify given data in a hierarchical structure that is often useful for many applications. This paper proposes an algorithm for inducing NNC-Trees based on the R-4-rule, which was proposed by tine author for finding the smallest nearest neighbor based multilayer perceptrons (NN-MLPs). There are mainly two contributions here. 1) A heuristic but effective method is given to define the teacher signals (group labels) for the data assigned to each nonterminal node. 2) The R-4-rule is modified so that an NNC with proper size can be designed automatically in each nonterminal node. Experiments with several public databases show that the proposed algorithm can produce NNC-Trees effectively and efficiently.								3	0	0	0	3	1083-4419		WOS:000238069200004	
S	Shang, Wenqian; Huang, Houkuan; Zhu, Haibin; Lin, Yongmin; Qu, Youli; Dong, Hongbin						Alexandrov, VN; VanAlbada, GD; Sloot, PMA; Dongarra, J		An adaptive fuzzy kNN text classifier								COMPUTATIONAL SCIENCE - ICCS 2006, PT 3, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		3993				216	223					2006	2006	In recent years, kNN algorithm is paid attention by many researchers and is proved one of the best text categorization algorithms. Text categorization is according to training set which is assigned class label to decide a new document which is not assigned class label belongs to some kind of document. Until now, kNN algorithm has still some issues to need to study further. Such as: improvement of decision rule; selection of k value; selection of dimensions (i.e. feature set selection); problems of multiclass text categorization; the algorithm's executive efficiency (time and space) etc. In this paper, we mainly focus on improvement of decision rule and dimension selection. We design an adaptive fuzzy kNN text classifier. Here the adaptive indicate the adaptive of dimension selection. The experiment results show that our algorithm is effective and feasible.				6th International Conference on Computational Science (ICCS 2006)	MAY 28-31, 2006	Intel Corp; IBM; SGI; Microsoft Res; EPSRC; Springer; ACET Ctr; Univ Reading; SIAM; IMACS; UK e Sci Programme	Reading, ENGLAND	3	0	0	0	3	0302-9743	3-540-34383-0	WOS:000238417300030	
S	Srisawat, Anantaporn; Phienthrakul, Tanasanee; Kijsirikul, Boonserm						Yang, Q; Webb, G		SV-kNNC: An algorithm for improving the efficiency of k-nearest neighbor								PRICAI 2006: TRENDS IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		4099				975	979					2006	2006	This paper proposes SV-kNNC, a new algorithm for k-Nearest Neighbor (kNN). This algorithm consists of three steps. First, Support Vector Machines (SVMs) are applied to select some important training data. Then, k-mean clustering is used to assign the weight to each training instance. Finally, unseen examples are classified by kNN. Fourteen datasets from the UCI repository were used to evaluate the performance of this algorithm. SV-kNNC is compared with conventional kNN and kNN with two instance reduction techniques: CNN and ENN. The results show that our algorithm provides the best performance, both predictive accuracy and classification time.				9th Pacific Rim International Conference on Artificial Intelligence (PRICAI 2006)	AUG 07-11, 2006		Guilin, PEOPLES R CHINA	3	0	0	0	3	0302-9743	3-540-36667-9	WOS:000240091500117	
B	Yamada, Takahiro; Yamashita, Kyohei; Ishii, Naohiro; Iwata, Kazunori			IEEE			Song, YT; Lu, C		Text classification by combining different distance functions with weights								SNPD 2006: Seventh ACIS International Conference on Software Engineering Artificial Intelligence, Networking, and Parallel/Distributed Computing, Proceedings							85	90					2006	2006	Since data is becoming greatly large in the networks, the machine classification of the text data, is not easy under these computing circumstances. Though the k-nearest neighbor (kNN) classification is a simple and effective classification approach, the improving performance of the classifier is still attractive to cope with the high accuracy processing. In this paper, the WN is improved by applying the different distance functions with weights to measure data from the multi-view points. Then, the weights for the optimization, are computed by the genetic algorithms. After the learning of the trained data, the unknown data is classified by combining the multiple distance functions and ensemble computations of the kNN. In this paper we present a new approach to combine multiple kNN classifiers based on different distance functions, which improve the performance of the k-nearest neighbor method. The proposed combining algorithm shows the higher generalization accuracy when compared to other conventional learning algorithms.				7th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel and Distributed Computing/7th ACIS International Workshop on Self-Assembling Networks	JUN 19-20, 2006	Int Assoc Comp & Informat Sci; Towson Univ; Cent Michigan Univ	Las Vegas, NV	3	0	0	0	3		0-7695-2611-X	WOS:000238913400013	
J	Li, XR; Wu, FC; Hu, ZY; Luo, AL								A novel spectral classifier based on coherence measure								SPECTROSCOPY AND SPECTRAL ANALYSIS			25	11			1889	1892					NOV 2005	2005	Classification and discovery of new types of celestial bodies from voluminous celestial spectra are two important issues in astronomy, and these two issues are treated separately in the literature to our knowledge. In the present paper, a novel coherence measure is introduced which can effectively measure the coherence of a new spectrum of unknown type with the training samples located within its neighbourhood, then a novel classifier is designed based on this coherence measure. The proposed classifier is capable of carrying out spectral classification and knowledge discovery simultaneously. In particular, it can effectively deal with the situation where different types of training spectra exist within the neighbourhood of a new spectrum, and the traditional k-nearest neighbour method usually fails to reach a correct classification. The satisfactory performance for classification. and knowledge discovery has been obtained by the proposed novel classifier over active galactic nucleus(AGNs) and active galaxies(AGs) data.								3	4	0	0	4	1000-0593		WOS:000233750500040	
J	Wong, JWH; Cartwright, HM				Wong, Jason/A-9466-2008	Wong, Jason/0000-0003-2953-7728			Deterministic projection by growing cell structure networks for visualization of high-dimensionally datasets								JOURNAL OF BIOMEDICAL INFORMATICS			38	4			322	330		10.1016/j.jbi.2005.02.002			AUG 2005	2005	Recent advances in clinical proteomics data acquisition have led to the generation of datasets of high complexity and dimensionality. We present here a visualization method for high-dimensionality datasets that makes use of neuronal vectors of a trained growing cell structure (GCS) network for the projection of data points onto two dimensions. The use of a GCS network enables the generation of the projection matrix deterministically rather than randomly as in random projection. Three datasets were used to benchmark the performance and to demonstrate the use of this deterministic projection approach in real-life scientitic applications. Comparisons are made to an existing self-organizing map projection method and random projection. The results suggest that deterministic projection outperforms existing methods and is suitable for the visualization of datasets of very high dimensionality. (c) 2005 Elsevier Inc. All rights reserved.								3	0	2	0	4	1532-0464		WOS:000231514200010	
J	Yang, CY; Chou, JJ								A comparative evaluation approach for the classification of rotifers with modified non-parametric kNN								IMAGE AND VISION COMPUTING			23	4			427	439		10.1016/j.imavis.2004.11.004			APR 1 2005	2005	In this study-aimed to achieve optimal accuracy in the classification of rotifers according to the number of eggs carried-several modifications to the basic kNN method have been proposed and assessed. Six distinct kNN rules as well as several additional hybrid models were, in fact, devised or employed and their precision compared. Meanwhile, the data sets used in the evaluation of each of these methods were acquired from rotifer images generated via the shape moments approach. Both the original data sets and the edited ones, formed by removing outliers from the originals, were used in the evaluation of these adjusted models. Through a process of comparative evaluation, several of the modified algorithms proposed-comprising both individual and hybrid models-were found to perform better overall than the classical kNN method. Refinements related to class-size weighting, in particular, were shown to heighten the accuracy of the classical kNN model considerably. Close evaluation of the various models created revealed kNN-CCS and F-kNN-CCS, in their application to the edited data sets, to be the most reliable individual modified and hybrid models respectively, with levels of accuracy greater than 95%. (C) 2004 Elsevier B.V. All rights reserved.								3	0	0	0	3	0262-8856		WOS:000227222100006	
J	Sanz, PJ; Marin, R; Sanchez, JS								Including efficient object recognition capabilities in online robots: From a statistical to a neural-network classifier								IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART C-APPLICATIONS AND REVIEWS			35	1			87	96		10.1109/TSMCC.2004.840055			FEB 2005	2005	For those situations in which the user wants to interact with the system by using, for example, voice commands, it would be convenient to refer to the objects by their names (e.g., "cube") instead of other types of interactions (e.g., "grasp object 1"). Thus, automatic object recognition is the first step in order to acquire a higher level of interaction between the user and the robot. Nevertheless, applying object recognition techniques when the camera images are being transmitted through the web is not an easy task. In this situation, images cannot have a very high resolution, which affects enormously the recognition process due to the inclusion of more errors while digitalizing the real image. Some experiments with the Universitat Jaume I Online Robot evaluate the performance of different neural-network implementations, comparing it to that of some distance-based object recognition algorithms. Results will show which combination of object features, and algorithms (both statistical and neural networks) is more appropriate to our purpose in terms of both effectiveness and computing time.								3	0	1	0	3	1094-6977		WOS:000226479600009	
S	Ferrandiz, S; Boulle, M						Perner, P; Imilya, A		Multivariate discretization by recursive supervised bipartition of graph								MACHINE LEARNING AND DATA MINING IN PATTERN RECOGNITION, PROCEEDINGS	Lecture Notes in Artificial Intelligence		3587				253	264					2005	2005	In supervised learning, discretization of the continuous explanatory attributes enhances the accuracy of decision tree induction algorithms and naive Bayes classifier. Many discretization methods have been developped, leading to precise and comprehensible evaluations of the amount of information contained in one single attribute with respect to the target one.In this paper, we discuss the multivariate notion of neighborhood, extending the univariate notion of interval. We propose an evaluation criterion of bipartitions, which is based on the Minimum Description Length (MDL) principle [1], and apply it recursively. The resulting discretization method is thus able to exploit correlations between continuous attributes. Its accuracy and robustness are evaluated on real and synthetic data sets.				4th International Conference on Machine Learning and Data Mining in Pattern Recognition	JUL 09-11, 2005		Leipzig, GERMANY	3	0	0	0	3	0302-9743	3-540-26923-1	WOS:000230895100025	
J	Gibert, K; Sanchez-Marre, M; Flores, X				Sanchez-Marre, Miquel/A-8569-2011				Cluster discovery in environmental databases using GESCONDA: The added value of comparisons								AI COMMUNICATIONS			18	4			319	331					2005	2005	Clustering techniques have a great importance in knowledge discovery because they can find out new groups or clusters of objects within databases. Thus, they are unsupervised learning methods, very useful when facing unknown, unlabelled and ill-structured databases, as environmental databases are. In this paper, different clustering algorithms are analyzed and compared. They are used on a real environmental data set in order to study their impact in characterizing states in this kind of domains. The comparison of the methods is undertaken using the system GESCONDA, which is a prototype of a data mining tool. Environmental data used in this paper are from a Catalan wastewater treatment plant and refers to different variables of the plant at different spatial points along 149 days.				4th Workshop on Binding Environmental Sciences and Artificial Intelligence	AUG 22-23, 2004		Valencia, SPAIN	3	0	0	0	3	0921-7126		WOS:000233439900008	
J	Wang, H; Bell, D								Extended k-nearest neighbours based on evidence theory								COMPUTER JOURNAL			47	6			662	672		10.1093/comjnl/47.6.662			NOV 2004	2004	An evidence theoretic classification method is proposed in this paper. In order to classify a pattern we consider its neighbours, which are taken as parts of a single source of evidence to support the class membership of the pattern. A single mass function or basic belief assignment is then derived, and the belief function and the pignistic ('betting rates') probability function can be calculated. Then the (posterior) conditional pignistic probability function is calculated and used to decide the class label for the pattern. It is shown that such a classifier extends the standard majority voting based k-nearest neighbour classifier, and it is an approximation to the optimal Bayes classifier. In experiments this classifier performed as well as or better than the voting and distance weighted k-nearest neighbours classifiers with best k, and its performance became stable when the number of neighbours considered was >4.								3	0	0	0	3	0010-4620		WOS:000224703800004	
J	Levendovszky, J; Fancsali, A				Levendovszky, Janos/F-5062-2013				Real-time call admission control for packet-switched networking by cellular neural networks								IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS			51	6			1172	1183		10.1109/TCSI.2004.826207			JUN 2004	2004	In this paper, novel call admission control (CAC) algorithms are developed based on cellular neural networks. These algorithms can achieve high network utilization by performing CAC in real-time, which is imperative in supporting quality of service (QoS) communication over packet-switched networks. The proposed solutions are of basic significance in access technology where a subscriber population (connected to the Internet via an access module) needs to receive services. In this case, QoS can only be preserved by admitting those user configurations which will not overload the access module. The paper treats CAC as a set separation problem where the separation surface is approximated based on a training set. This casts CAC as an image processing task in which a complex admission pattern is to be recognized from a couple of initial points belonging to the training set. Since CNNs can implement any propagation models to explore complex patterns, CAC can then be carried out by a CNN. The major challenge is to find the proper template matrix which yields high network utilization. On the other hand, the proposed method is also capable of handling three-dimensional separation surfaces, as in a typical access scenario there are three traffic classes (e.g., two type of Internet access and one voice over asymmetric digital subscriber line.								3	0	0	0	3	1057-7122		WOS:000222010900013	
J	Garcia-Gomez, JM; Vidal, U; Marti-Bonmati, L; Galant, J; Sans, N; Robles, M; Casacuberta, F								Benign/malignant classifier of soft tissue tumors using MR imaging								MAGNETIC RESONANCE MATERIALS IN PHYSICS BIOLOGY AND MEDICINE			16	4			194	201		10.1007/s10334-003-0023-7			MAR 2004	2004	This article presents a pattern-recognition approach to the soft tissue tumors (STT) benign/ malignant character diagnosis using magnetic resonance (MR) imaging applied to a large multicenter database.Objective: To develop and test an automatic classifier of STT into benign or malignant by using classical MR imaging findings and epidemiological information.Materials and methods: A database of 430 patients (62% benign and 38% malignant) from several European multicenter registers. There were 61 different histologies (36 with benign and 25 with malignant nature). Three pattern-recognition methods (artificial neural networks, support vector machine, k-nearest neighbor) were applied to learn the discrimination between benignity and malignancy based on a defined MR imaging findings protocol. After the systems had learned by using training samples (with 302 cases), the clinical decision support system was tested in the diagnosis of 128 new STT cases. Results: An 88-92% efficacy was obtained in a not-viewed set of tumors using the pattern-recognition techniques. The best results were obtained with a back-propagation artificial neural network. Conclusion: Benign vs. malignant STT discrimination is accurate by using pattern-recognition methods based on classical MR image findings. This objective tool will assist radiologists in STT grading.								3	0	0	0	3	0968-5243		WOS:000221219900006	
S	Kosar, K; Lhotska, L; Krajca, V						Barreiro, JM; MartinSanchez, F; Maojo, V; Sanz, F		Classification of long-term EEG recordings								BIOLOGICAL AND MEDICAL DATA ANALYSIS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		3337				322	332					2004	2004	Computer assisted processing of long-term EEG recordings is gaining a growing importance. To simplify the work of a physician, that must visually evaluate long recordings, we present a method for automatic processing of EEG based on learning classifier. This method supports the automatic search of long-term EEG recording and detection of graphoelements - signal parts with characteristic shape and defined diagnostic value. Traditional methods of detection show great percent of error caused by the great variety of non-stationary EEG. The idea of this method is to break down the signal into stationary sections called segments using adaptive segmentation and create a set of normalized discriminative features representing segments. The groups of similar patterns of graphoelements form classes used for the learning of a classifier. Weighted features are used for classification performed by modified learning classifier fuzzy k-Nearest Neighbours. Results of classification describe classes of unknown segments. The implementation of this method was experimentally verified on a real EEG with the diagnosis of epilepsy.				5th International Symposium on Biological and Medical Data Analysis (ISBMDA)	NOV   18, 2004		Barcelona, SPAIN	3	0	0	0	3	0302-9743	3-540-23964-2	WOS:000226129700033	
S	Liu, W; Wang, YH; Li, SZ; Tan, TN						Kittler, J; Petrou, M; Nixon, M		Nearest intra-class space classifier for face recognition								PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, VOL 4	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION						495	498					2004	2004	In this paper we propose a novel classification method, called nearest intra-class space (NICS), for face recognition. In our method, the distribution of face patterns of each person is represented by the intra-class space to capture all intra-class variations. Then, a regular principal subspace is derived from each intra-class space using principal component analysis. The classification is based on the nearest weighted distance, combining distance-from-subspace and distance-in-subspace, between the query face and each intra-class subspace. Experimental results show that the NICS classifier outperforms other classifiers in terms of recognition performance.				17th International Conference on Pattern Recognition (ICPR)	AUG 23-26, 2004	Int Assoc Pattern Recognit; Univ Surrey; UniS; IEEE Comp Soc; HP Res Labs Bristol	British Machine Vis Assoc, Cambridge, ENGLAND	3	0	1	0	3	1051-4651	0-7695-2128-2	WOS:000223878400119	
S	Yang, Y; Zheng, CX; Lin, P						Sanfeliu, A; Trinidad, JFM; Ochoa, JAC		Image thresholding via a modified fuzzy c-means algorithm								PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS AND APPLICATIONS	LECTURE NOTES IN COMPUTER SCIENCE		3287				589	596					2004	2004	In this paper, a modified fuzzy c-means (FCM) algorithm named weighted fuzzy c-means (WFCM) algorithm for image thresholding is presented. The algorithm is developed by incorporating the spatial neighborhood information into the standard FCM clustering algorithm. The weight indicates the spatial influence of the neighboring pixels on the centre pixel, which is derived from the k-nearest neighbor (k-NN) algorithm and is modified in two aspects so as to improve its property in the WFCM algorithm. To speed up the algorithm, the iteration in FCM algorithm is carried out with the statistical gray level histogram of image instead of the conventional whole data of image. The performance of the algorithm is compared with those of an existing fuzzy thresholding algorithm and widely applied between variance and entropy methods. Experimental results on both synthetic and real images are given to demonstrate the proposed algorithm is effective and efficient. In addition, due to the neighborhood model, our method is more tolerant to noise.				9th Iberoamerican Congress on Pattern Recognition	OCT 16-29, 2004	Inst Cybernet, Math & Phys Cuba; Ctr Applicat Adv Technol Cuba; Univ La Salle, Mexico; Autonomous Univ Puebla; Int Assoc Patern Recognit; Cuban Assoc Pattern Recognit; Portuguese Assoc Pattern Recognit; Spanish Assoc Pattern Recognit & Image Anal; SIGPR SBC; Mexican Assoc Comp Vis, Neurocomp & Robit	Puebla, MEXICO	3	0	0	0	3	0302-9743	3-540-23527-2	WOS:000225085900074	
J	Nock, R; Sebban, M; Bernard, D								A simple locally adaptive nearest neighbor rule with application to pollution forecasting								INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			17	8			1369	1382		10.1142/S0218001403002952			DEC 2003	2003	In this paper, we propose a thorough investigation of a nearest neighbor rule which we call the "Symmetric Nearest Neighbor (sNN) rule". Basically, it symmetrises the classical nearest neighbor relationship from which are computed the points voting for some instances. Experiments on 29 datasets, most of which are readily available, show that the method significantly outperforms the traditional Nearest Neighbors methods. Experiments on a domain of interest related to tropical pollution normalization also show the greater potential of this method. We finally discuss the reasons for the rule's efficiency, provide methods for speeding-up the classification time, and derive from the sNN rule a reliable and fast algorithm to fix the parameter k in the k-NN rule, a longstanding problem in this field.								3	0	0	0	3	0218-0014		WOS:000188376000005	
J	Kudo, M; Masuyama, N; Toyama, J; Shimbo, M				Kudo, Mineichi/B-9973-2011				Simple termination conditions for k-nearest neighbor method								PATTERN RECOGNITION LETTERS			24	9-10			1203	1213	PII S0167-8655(02)00302-1	10.1016/S0167-8655(02)00302-1			JUN 2003	2003	The main problem with k-nearest neighbor (k-NN) method is that the computational cost in the search process is proportional to the size of the training samples. Many search algorithms have been proposed to cope with this problem. In this study, we consider some conditions for terminating the search procedure when the true k-NNs have been found in the middle of the search, and we present, as an example, a procedure in the branch-and-bound algorithm. These conditions do not always work for a certain sample, but they reduce the computational cost on average. (C) 2002 Elsevier Science B.V. All rights reserved.								3	2	0	0	5	0167-8655		WOS:000181368900009	
B	Gupta, MR; Gray, RM			IEEE					Reducing bias in supervised learning								PROCEEDINGS OF THE 2003 IEEE WORKSHOP ON STATISTICAL SIGNAL PROCESSING							482	485					2003	2003	Nonparametric statistical supervised learning methods often suffer from bias caused by non-uniformity of the probability distribution of training samples. We discuss this problem and propose a new nonparametric neighborhood method for classification and estimation that significantly reduces the bias. Simulations exemplify the advantages, and theoretical results are noted.				12th IEEE Workshop on Statistical Signal Processing	SEP 28-OCT 01, 2003	IEEE Signal Proc Soc; DARPA; USAF Res Lab; Off Naval Res; Natl Sci Fdn	St Louis, MO	3	0	0	0	3		0-7803-7997-7	WOS:000189451000134	
S	Domeniconi, C; Peng, J; Gunopulos, D						Leen, TK; Dietterich, TG; Tresp, V		An adaptive metric machine for pattern classification								ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 13	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS		13				458	464					2001	2001	Nearest neighbor classification assumes locally constant class conditional probabilities. This assumption becomes invalid in high dimensions with finite samples due to the curse of dimensionality. Severe bias can be introduced under these conditions when using the nearest neighbor rule. We propose a locally adaptive nearest neighbor classification method to try to minimize bias. We use a Chi-squared distance analysis to compute a flexible metric for producing neighborhoods that axe elongated along less relevant feature dimensions and constricted along most influential ones. As a result, the class conditional probabilities tend to be smoother in the modified neighborhoods, whereby better classification performance can be achieved. The efficacy of our method is validated and compared against other techniques using a variety of real world data.				14th Annual Neural Information Processing Systems Conference (NIPS)	NOV 27-DEC 02, 2000		DENVER, CO	3	0	0	0	3	1049-5258	0-262-12241-3	WOS:000171891800065	
J	Azuaje, F; Dubitzky, W; Black, N; Adamson, K								Retrieval strategies for case-based reasoning: a categorised bibliography								KNOWLEDGE ENGINEERING REVIEW			15	4			371	379					DEC 2000	2000	The retrieval of relevant cases plays a crucial role in case-based reasoning. There are three major methods for the retrieval of relevant cases: computational approaches (based upon measures of similarity), representational approaches (based upon indexing structures) and hybrid approaches. This paper looks at recent successful implementations of case retrieval with regard to this classification framework. Similarly it emphasises computational and representational models applied to feature-vector case representations.								3	0	0	0	3	0269-8889		WOS:000169494800003	
J	Yakowitz, S; Gyorfi, L; Kieffer, J; Morvai, G				Morvai, Gusztav/H-8854-2012				Strongly consistent nonparametric forecasting and regression for stationary ergodic sequences								JOURNAL OF MULTIVARIATE ANALYSIS			71	1			24	41		10.1006/jmva.1999.1825			OCT 1999	1999	Let {(X(i), Y(i))} be a stationary ergodic time series with (X, Y) values in the product space R(d) x R. This study offers what is believed to be the first strongly consistent (with respect to pointwise, least-squares, and uniform distance) algorithm for inferring m(x) = E[Y(0)\X(0) = x] under the presumption that m(x) is uniformly Lipschitz continuous. Auto-regression, or forecasting, is an important special case, and as such our work extends the literature of nonparametric. nonlinear forecasting by circumventing customary mixing assumptions. The work is motivated by a time series model in stochastic finance and by perspectives of its contribution to the issues of universal time series estimation. (C) 1999 Academic Press.								3	0	0	0	3	0047-259X		WOS:000083185800002	
J	Foggia, P; Sansone, C; Tortorella, F; Vento, M				Tortorella, Francesco/F-5964-2010				Definition and validation of a distance measure between structural primitives								PATTERN ANALYSIS AND APPLICATIONS			2	3			215	227		10.1007/s100440050030			1999	1999	This paper proposes a structural description scheme using second order primitives, in particular circular arcs. In this framework, a distance measure between pairs of circular arcs and relations among them is introduced, and its main properties are discussed. This measure accomplishes some perceptive criteria for increasing its efficiency: it proved applicable in a wide class of application domains characterised by high variability in the shape of the visual patterns, where a structural approach is particularly useful. The description method together with the distance have been experimentally validated in the context of the recognition of handwritten digits coming from a standard character database.								3	0	0	0	3	1433-7541		WOS:000083707500002	
J	Zupan, B; Dzeroski, S								Acquiring background knowledge for machine learning using function decomposition: a case study in rheumatology								ARTIFICIAL INTELLIGENCE IN MEDICINE			14	1-2			101	117		10.1016/S0933-3657(98)00018-9			SEP-OCT 1998	1998	Domain or background knowledge is often needed in order to solve difficult problems of learning medical diagnostic rules. Earlier experiments have demonstrated the utility of background knowledge when learning rules for early diagnosis of rheumatic diseases. A particular form of background knowledge comprising typical co-occurrences of several groups of attributes was provided by a medical expert. This paper explores the possibility of automating the process of acquiring background knowledge of this kind and studies the utility of such methods in the problem domain of rheumatic diseases. A method based on function decomposition is proposed that identifies typical co-occurrences for a given set of attributes. The method is evaluated by comparing the typical co;occurrences it identifies as well as their contribution to the performance of machine learning algorithms, to the ones provided by a medical expert. (C) 1998 Elsevier Science B.V. All rights reserved.				6th Conference on Artificial Intelligence in Medicine Europe (AIME 97)	MAR 23-26, 1997	Univ Joseph fourier, Grenoble; CNRS; Grenoble Isere Dev, France; Assoc Francaise Intelligence Artificielle	GRENOBLE, FRANCE	3	0	0	0	3	0933-3657		WOS:000076193000006	
J	Fuchs, M; Fuchs, M								Feature-based learning of search-guiding heuristics for theorem proving								AI COMMUNICATIONS			11	3-4			175	189					1998	1998	Automated reasoning or theorem proving essentially amounts to solving search problems. Despite significant progress in recent years theorem provers still have many shortcomings. The use of machine-learning techniques is acknowledged as promising, but difficult to apply in the area of theorem proving. We propose here to learn search-guiding heuristics by employing features in a simple, yet effective manner. Features are used to adapt a heuristic to a solved source problem. The adapted heuristic can then be utilized profitably for solving related target problems. Experiments have demonstrated that the approach allows a theorem prover to prove hard problems that were out of reach before.								3	0	0	0	3	0921-7126		WOS:000079436200002	
J	Zakarauskas, P; Ozard, JM								Complexity analysis for partitioning nearest neighbor searching algorithms								IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			18	6			663	668		10.1109/34.506419			JUN 1996	1996	In this paper we present cost estimates for finding the k-nearest neighbors to a test pattern according to a Minkowski p-metric, as a function of the size of the buckets in partitioning searching algorithms. The asymptotic expected number of operations to find the nearest neighbor is presented as a function of the average number of patterns per bucket n and is shown to contain a global minimum.								3	0	0	0	3	0162-8828		WOS:A1996UR25400012	
J	ROVATTI, R; RAGAZZONI, R; KOVACS, ZM; GUERRIERI, R								ADAPTIVE VOTING RULES FOR K-NEAREST NEIGHBORS CLASSIFIERS								NEURAL COMPUTATION			7	3			594	605		10.1162/neco.1995.7.3.594			MAY 1995	1995	A simple form of cooperation between the k-nearest neighbors (NN) approach to classification and the neural-like property of adaptation is explored. A tunable, high level k-nearest neighbors decision rule is defined that comprehends most previous generalizations of the common majority rule. A learning procedure is developed that applies to this rule and exploits those statistical features that can be induced from the training set. The overall approach is tested on a problem of handwritten character recognition. Experiments show that adaptivity in the decision rule may improve the recognition and rejection capability of standard k-NN classifiers.								3	0	0	0	3	0899-7667		WOS:A1995QQ86600010	
J	GURGEN, F; ALPAYDIN, R; UNLUAKIN, U; ALPAYDIN, E				ALPAYDIN, ETHEM/E-6127-2013				DISTRIBUTED AND LOCAL NEURAL CLASSIFIERS FOR PHONEME RECOGNITION								PATTERN RECOGNITION LETTERS			15	11			1111	1118		10.1016/0167-8655(94)90126-0			NOV 1994	1994	The comparative performances of distributed and local neural networks for the speech recognition problem are investigated. We consider a feed-forward network with one or more hidden layers. Depending on the response characteristics of the hidden units, we name the network distributed or local. If the hidden units use the sigmoid non-linearity, then hidden units have a global response and we call such networks distributed. If each hidden unit responds only to inputs in a certain local region in the input space, then the network is local. Neighbor and prototype based approaches are of this type. As examples of the distributed approach with sigmoidal units, we employ the back-propagation rule with three error measures: mean square error, cross entropy, and combinational performance. As for the local methods, we use k-nearest neighbor, learning Vector quantization, grow and learn, and Gaussian-based weighted approximation methods. Phoneme recognition experiments are conducted using the /b, d, g, m, n, N/ set of the Japanese vocabulary for the speaker dependent case. Three criteria are taken for comparison: correct classification of the test set, network size, and learning time. We found that distributed networks generalize better than local networks but require longer training and more precise computation. Local networks learn very quickly, but do not generalize well and use more memory.								3	0	0	0	3	0167-8655		WOS:A1994PQ22400006	
J	BAGUI, SC								CLASSIFICATION USING 1ST-STAGE RANK NEAREST-NEIGHBOR RULE FOR MULTIPLE CLASSES								PATTERN RECOGNITION LETTERS			14	7			537	544		10.1016/0167-8655(93)90102-J			JUL 1993	1993	In this article, the first-stage rank nearest neighbor (RNN) rule is used to classify an unknown observation into one of the s (greater-than-or-equal-to 2) populations (or classes). We derive the asymptotic risk (i.e., the total probability of misclassification) (TPMC)) of this rule, which turns out to be exactly the same as the limiting risk of the 1-NN rule of Cover and Hart (1967) for s classes. The proposed estimate of the limiting TPMC of the first-stage RNN rule is shown to be asymptotically unbiased and consistent. Finally, Monte Carlo results are reported to learn the performance of the first-stage RNN rule in comparison with the 1-NN rule in a small sample situation.								3	0	0	0	3	0167-8655		WOS:A1993LL59100002	
J	MAZZOLA, S								A K-NEAREST NEIGHBOR-BASED METHOD FOR THE RESTORATION OF DAMAGED IMAGES								PATTERN RECOGNITION			23	1-2			179	184		10.1016/0031-3203(90)90058-S			1990	1990									3	0	0	0	3	0031-3203		WOS:A1990CY74200014	
J	PATRICK, EA								THE OUTCOME ADVISER								PATTERN RECOGNITION			23	12			1427	1439		10.1016/0031-3203(90)90088-3			1990	1990									3	0	1	0	3	0031-3203		WOS:A1990EJ79500012	
J	GOLIC, JD								ON THE RELATIONSHIP BETWEEN THE EFFICIENCY MEASURES OF MULTICATEGORY INFORMATION-SYSTEMS								IEEE TRANSACTIONS ON INFORMATION THEORY			33	4			531	538		10.1109/TIT.1987.1057332			JUL 1987	1987									3	0	0	0	3	0018-9448		WOS:A1987J668400005	
J	BODA, K; PAP, A								DIAGNOSTICS OF PANCREATIC INSUFFICIENCY USING MULTIVARIATE STATISTICAL AND PATTERN-RECOGNITION METHODS								COMPUTERS IN BIOLOGY AND MEDICINE			14	1			91	97		10.1016/0010-4825(84)90023-4			1984	1984									3	0	2	0	3	0010-4825		WOS:A1984SN11100009	
J	PALIWAL, KK; RAO, PVS								APPLICATION OF K-NEAREST-NEIGHBOR DECISION RULE IN VOWEL RECOGNITION								IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			5	2			229	231					1983	1983									3	0	0	0	3	0162-8828		WOS:A1983QJ97400015	
J	COOMANS, D; MASSART, DL								ALTERNATIVE K-NEAREST NEIGHBOR RULES IN SUPERVISED PATTERN-RECOGNITION .3. CONDENSED NEAREST NEIGHBOR RULES								ANALYTICA CHIMICA ACTA			138	JUN			167	176		10.1016/S0003-2670(01)85299-5			1982	1982									3	0	1	0	3	0003-2670		WOS:A1982NV63600020	
J	DUBUISSON, B; LAVISON, P								SURVEILLANCE OF A NUCLEAR-REACTOR BY USE OF A PATTERN-RECOGNITION METHODOLOGY								IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS			10	10			603	609		10.1109/TSMC.1980.4308364			1980	1980									3	0	0	0	3	0018-9472		WOS:A1980KW19400002	
J	PENROD, CS; WAGNER, TJ								RISK ESTIMATION FOR NONPARAMETRIC DISCRIMINATION AND ESTIMATION RULES - SIMULATION STUDY								IEEE TRANSACTIONS ON INFORMATION THEORY			25	6			753	758		10.1109/TIT.1979.1056101			1979	1979									3	0	0	0	3	0018-9448		WOS:A1979HW43300023	
J	DEVIJVER, PA								NOTE ON TIES IN VOTING WITH K-NN RULE								PATTERN RECOGNITION			10	4			297	298		10.1016/0031-3203(78)90039-0			1978	1978									3	0	0	0	3	0031-3203		WOS:A1978FS91900009	
J	NAKACHE, JP; LORENTE, P; CHASTANG, C								EVALUATION OF PROGNOSIS AND DETERMINATION OF THERAPY USING MULTIVARIATE METHODS								BIOMEDICINE			28		SI		19	24					1978	1978									3	0	2	0	3	0300-0893		WOS:A1978FS62600004	
J	CHEN, Z; FU, KS								NONPARAMETRIC BAYES RISK ESTIMATION FOR PATTERN-CLASSIFICATION								IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS			7	9			651	656		10.1109/TSMC.1977.4309802			1977	1977									3	0	1	0	3	0018-9472		WOS:A1977DS38100003	
J	Chattopadhyay, Subhagata; Banerjee, Suvendu; Rabhi, Fethi A.; Acharya, U. Rajendra								A Case-Based Reasoning system for complex medical diagnosis								EXPERT SYSTEMS			30	1			12	20		10.1111/j.1468-0394.2012.00618.x			FEB 2013	2013	A Case-Based Reasoning (CBR) system for medical diagnosis mimics the way doctors make a diagnosis. Given a new case, its accuracy in practice depends on successful retrieval of similar cases. CBR systems have had some success in dealing with simple diseases because of the robustness of their case base. However, their diagnostic accuracy suffers when dealing with complex diseases particularly those that involve multiple domains in medicine. An example of such a condition is Premenstrual syndrome (PMS) as it falls under both gynaecology and psychiatry. To address this issue, the paper proposes a CBR-based expert system that uses the K-nearest neighbour (KNN) algorithm to search k similar cases based on the Euclidean distance measure. The novelty of the system is in the design of a flexible auto-set tolerance (T), which serves as a threshold to extract cases for which similarities are greater than the assigned value of T. A prototype software tool with a menu-driven Graphical User Interface (GUI) has been developed for case input, analysis of results, and case adaptation within the system. Finally, the performance of the tool has been checked on a set of real-world PMS cases.								2	0	0	0	2	0266-4720		WOS:000314217800003	
J	Reyes, J.; Morales-Esteban, A.; Martinez-Alvarez, F.								Neural networks to predict earthquakes in Chile								APPLIED SOFT COMPUTING			13	2			1314	1328		10.1016/j.asoc.2012.10.014			FEB 2013	2013	A new earthquake prediction system is presented in this work. This method, based on the application of artificial neural networks, has been used to predict earthquakes in Chile, one of the countries with larger seismic activity. The input values are related to the b-value, the Bath's law, and the Omori-Utsu's law, parameters that are strongly correlated with seismicity, as shown in solid previous works. Two kind of prediction are provided in this study: The probability that an earthquake of magnitude larger than a threshold value happens, and the probability that an earthquake of a limited magnitude interval might occur, both during the next five days in the areas analyzed. For the four Chile's seismic regions examined, with epicenters placed on meshes with dimensions varying from 0.5 degrees x 0.5 degrees to 1 degrees x 1 degrees, a prototype of neuronal network is presented. The prototypes predict an earthquake every time the probability of an earthquake of magnitude larger than a threshold is sufficiently high. The threshold values have been adjusted with the aim of obtaining as few false positives as possible. The accuracy of the method has been assessed in retrospective experiments by means of statistical tests and compared with well-known machine learning classifiers. The high success rate achieved supports the suitability of applying soft computing in this field and poses new challenges to be addressed. (C) 2012 Elsevier B.V. All rights reserved.								2	0	0	0	2	1568-4946		WOS:000313011600048	
J	Clark, Alexander; Lappin, Shalom								Complexity in Language Acquisition								TOPICS IN COGNITIVE SCIENCE			5	1			89	110		10.1111/tops.12001			JAN 2013	2013	Learning theory has frequently been applied to language acquisition, but discussion has largely focused on information theoretic problemsin particular on the absence of direct negative evidence. Such arguments typically neglect the probabilistic nature of cognition and learning in general. We argue first that these arguments, and analyses based on them, suffer from a major flaw: they systematically conflate the hypothesis class and the learnable concept class. As a result, they do not allow one to draw significant conclusions about the learner. Second, we claim that the real problem for language learning is the computational complexity of constructing a hypothesis from input data. Studying this problem allows for a more direct approach to the object of studythe language acquisition devicerather than the learnable class of languages, which is epiphenomenal and possibly hard to characterize. The learnability results informed by complexity studies are much more insightful. They strongly suggest that target grammars need to be objective, in the sense that the primitive elements of these grammars are based on objectively definable properties of the language itself. These considerations support the view that language acquisition proceeds primarily through data-driven learning of some form.								2	0	0	0	2	1756-8757		WOS:000313754300006	
J	Wu, H.; Fang, H.; Stanhope, S. J.								Exploiting Online Discussions to Discover Unrecognized Drug Side Effects								METHODS OF INFORMATION IN MEDICINE			52	2			152	159		10.3414/ME12-02-0004			2013	2013	Background: Drugs can treat human diseases through chemical interactions between, the ingredients and intended targets in the human body. However, the ingredients could unexpectedly interact with off-targets, which may cause adverse drug side effects. Notifying patients and physicians of potential drug effects is an important step in improving healthcare quality and delivery. Objective: With the increasing popularity of Web 2.0 applications, more and more patients start discussing drug side effects in many online sources. These online discussions form a valuable source for mining interesting knowledge about side effects. The main goal of this paper is to investigate the feasibility of exploiting these discussions to discover unrecognized drug side effects.Methods: We propose methods that can 1) build a knowledge base for drug side effects by automatically integrating the information related to drug side effects from different sources; and 2) monitor online discussions about drugs and discover potential unrecognized drug side effects.Results: Experiment results show that the online discussions indeed provide useful information discovering unrecognized drug side effects. We find that the integrated, knowledge base contains more information than individual online sources. Moreover, both proposed detection methods can identify the side effects related to the four recently recalled drugs, and the information from online discussions makes it possible to make the detection much earlier than official announcements. Finally, the proposed generative modeling method is shown to be more effective than the discriminative method.Conclusions: We find that it is possible to monitor online discussions to detect unrecognized drug side effects. The developed system is expected to serve as a complementary tool for drug companies and FDA to receive feedbacks from the patients, and it has the potentials to expedite the discovery process of unrecognized drug side effects and to improve the quality of healthcare.								2	0	0	0	2	0026-1270		WOS:000316841400007	
J	Li, Cynthia H.; Narhi, Linda O.; Wen, Jie; Dimitrova, Mariana; Wen, Zai-qing; Li, Jenny; Pollastrini, Joseph; Nguyen, Xichdao; Tsuruda, Trace; Jiang, Yijia								Effect of pH, Temperature, and Salt on the Stability of Escherichia coli- and Chinese Hamster Ovary Cell-Derived IgG1 Fc								BIOCHEMISTRY			51	50			10056	10065		10.1021/111300702e			DEC 18 2012	2012	The circulation half-life of a potential therapeutic can be increased by fusing the molecule of interest (an active peptide, the extracellular domain of a receptor, an enzyme, etc.) to the Fc fragment of a monoclonal antibody. For the fusion protein to be a successful therapeutic, it must be stable to process and long-term storage conditions, as well as to physiological conditions. The stability of the Fc used is critical for obtaining a successful therapeutic protein. The effects of pH, temperature, and salt on the stabilities of Escherichia coil- and Chinese hamster ovary cell (CHO)-derived IgG1 Fc high-order structure were probed using a variety of biophysical techniques. Fe molecules derived from both E. coil and CHO were compared. The IgG1 Fc molecules from both sources (glycosylated and aglycosylated) are folded at neutral pH and behave similarly upon heat- and low pH-induced unfolding. The unfolding of both IgG1 Fc molecules occurs via a multistep unfolding process, with the tertiary structure and C(H)2 domain unfolding first, followed by changes in the secondary structure and C(H)3 domain. The acid-induced unfolding of IgG1 Fc molecules is only partially reversible, with the formation of high-molecular weight species. The CHO-derived Fc protein (glycosylated) is more compact (smaller hydrodynamic radius) than the E. coli- derived protein (aglycosylated) at neutral pH. Unfolding is dependent on pH and salt concentration. The glycosylated C(H)2 domain melts at a temperature 4-5 degrees C higher than that of the aglycosylated domain, and the low-pH-induced unfolding of the glycosylated Fc molecule occurs at a pH similar to 0.5 pH unit lower than that of the aglycosylated protein. The difference observed between E. coil- and CHO-derived Fc molecules primarily involves the C(H)2 domain, where the glycosylation of the Fc resides.								2	0	2	0	2	0006-2960		WOS:000312430100011	
J	Corne, David; Dhaenens, Clarisse; Jourdan, Laetitia								Synergies between operations research and data mining: The emerging use of multi-objective approaches								EUROPEAN JOURNAL OF OPERATIONAL RESEARCH			221	3			469	479		10.1016/j.ejor.2012.03.039			SEP 16 2012	2012	Operations research and data mining already have a long-established common history. Indeed, with the growing size of databases and the amount of data available, data mining has become crucial in modern science and industry. Data mining problems raise interesting challenges for several research domains, and in particular for operations research, as very large search spaces of solutions need to be explored. Hence, many operations research methods have been proposed to deal with such challenging problems. But the relationships between these two domains are not limited to these natural applications of operations research approaches. The counterpart is also important to consider, since data mining approaches have also been applied to improve operations research techniques. The aim of this article is to highlight the interplay between these two research disciplines. A particular emphasis will be placed on the emerging theme of applying multi-objective approaches in this context. (c) 2012 Elsevier B.V. All rights reserved.								2	0	0	0	2	0377-2217		WOS:000305768700001	
J	Yan, Donghui; Wang, Pei; Linden, Michael; Knudsen, Beatrice; Randolph, Timothy								STATISTICAL METHODS FOR TISSUE ARRAY IMAGES-ALGORITHMIC SCORING AND CO-TRAINING								ANNALS OF APPLIED STATISTICS			6	3			1280	1305		10.1214/12-AOAS543			SEP 2012	2012	Recent advances in tissue microarray technology have allowed immunohistochemistry to become a powerful medium-to-high throughput analysis tool, particularly for the validation of diagnostic and prognostic biomarkers. However, as study size grows, the manual evaluation of these assays becomes a prohibitive limitation; it vastly reduces throughput and greatly increases variability and expense. We propose an algorithm-Tissue Array Co-Occurrence Matrix Analysis (TACOMA)-for quantifying cellular phenotypes based on textural regularity summarized by local inter-pixel relationships. The algorithm can be easily trained for any staining pattern, is absent of sensitive tuning parameters and has the ability to report salient pixels in an image that contribute to its score. Pathologists' input via informative training patches is an important aspect of the algorithm that allows the training for any specific marker or cell type. With co-training, the error rate of TACOMA can be reduced substantially for a very small training sample (e.g., with size 30). We give theoretical insights into the success of co-training via thinning of the feature set in a high-dimensional setting when there is "sufficient" redundancy among the features. TACOMA is flexible, transparent and provides a scoring process that can be evaluated with clarity and confidence. In a study based on an estrogen receptor (ER) marker, we show that TACOMA is comparable to, or outperforms, pathologists' performance in terms of accuracy and repeatability.								2	1	0	0	3	1932-6157		WOS:000314457400020	
J	Leon, Florin; Piuleac, Ciprian George; Curteanu, Silvia; Poulios, Ioannis				Piuleac, Ciprian/C-3848-2012				Instance-based regression with missing data applied to a photocatalytic oxidation process								CENTRAL EUROPEAN JOURNAL OF CHEMISTRY			10	4			1149	1156		10.2478/s11532-012-0038-x			AUG 2012	2012	In this paper, a modified nearest-neighbor regression method (kNN) is proposed to model a process with incomplete information of the measurements. This technique is based on the variation of the coefficients used to weight the distances of the instances. The case study selected for testing this algorithm was the photocatalytic degradation of Reactive Red 184 (RR184), a dye belonging to the group of azo compounds, which is widely used in manufacturing paint paper, leather and fabrics. The process is conducted with TiO2 as catalyst (an inexpensive semiconductor material, completely inert chemically and biologically), in the presence of H2O2 (with the role of increasing the rate of photo-oxidation), at different pH values. The final concentration of RR184 is predicted accurately with the modified kNN regression method developed in this article. A comparison with other machine learning methods (sequential minimal optimization regression, decision table, reduced error pruning tree, M5 pruned model tree) proves the superiority and efficiency of the proposed algorithm, not only for its results, but for its simplicity and flexibility in manipulating incomplete experimental data.								2	0	0	0	2	1895-1066		WOS:000304618900018	
J	Li, Chaoqun; Li, Hongwei								A Modified Short and Fukunaga Metric based on the attribute independence assumption								PATTERN RECOGNITION LETTERS			33	9			1213	1218		10.1016/j.patrec.2012.01.011			JUL 1 2012	2012	It is well known that the naive Bayesian classifier assumes the attribute independence given the class. According to our observation, some distance functions also assume the attribute independence, such as Value Difference Metric (VDM). Short and Fukunaga Metric (SFM) is another widely used distance function, which does not assume the attribute independence. In this paper, we investigate the attribute independence assumption in VDM, and propose a Modified Short and Fukunaga Metric (MSFM) based on the attribute independence assumption. We find that MSFM is surprisingly similar to VDM. In fact, based on some assumptions, our MSFM can be regarded as a logarithmic modification of VDM. That is to say, in some sense, a logarithmic modification of SFM is equivalent to a logarithmic modification of VDM. Our experimental results on a large number of UCI benchmark datasets show that MSFM significantly outperforms SFM and SF2LOG (another improved version of SFM), and almost ties VDM. (C) 2012 Elsevier B.V. All rights reserved.								2	0	0	0	2	0167-8655		WOS:000304235500023	
J	Dutta, Subhajit; Ghosh, Anil K.								On robust classification using projection depth								ANNALS OF THE INSTITUTE OF STATISTICAL MATHEMATICS			64	3			657	676		10.1007/s10463-011-0324-y			JUN 2012	2012	This article uses projection depth (PD) for robust classification of multivariate data. Here we consider two types of classifiers, namely, the maximum depth classifier and the modified depth-based classifier. The latter involves kernel density estimation, where one needs to choose the associated scale of smoothing. We consider both the single scale and the multi-scale versions of kernel density estimation, and investigate the large sample properties of the resulting classifiers under appropriate regularity conditions. Some simulated and real data sets are analyzed to evaluate the finite sample performance of these classification tools.								2	0	0	0	2	0020-3157		WOS:000299171100009	
J	Lopez, Victoria; Fernandez, Alberto; Moreno-Torres, Jose G.; Herrera, Francisco				Herrera, Francisco/C-6856-2008	Herrera, Francisco/0000-0002-7283-312X			Analysis of preprocessing vs. cost-sensitive learning for imbalanced classification. Open problems on intrinsic data characteristics								EXPERT SYSTEMS WITH APPLICATIONS			39	7			6585	6608		10.1016/j.eswa.2011.12.043			JUN 1 2012	2012	Class imbalance is among the most persistent complications which may confront the traditional supervised learning task in real-world applications. The problem occurs, in the binary case, when the number of instances in one class significantly outnumbers the number of instances in the other class. This situation is a handicap when trying to identify the minority class, as the learning algorithms are not usually adapted to such characteristics.The approaches to deal with the problem of imbalanced datasets fall into two major categories: data sampling and algorithmic modification. Cost-sensitive learning solutions incorporating both the data and algorithm level approaches assume higher misclassification costs with samples in the minority class and seek to minimize high cost errors. Nevertheless, there is not a full exhaustive comparison between those models which can help us to determine the most appropriate one under different scenarios.The main objective of this work is to analyze the performance of data level proposals against algorithm level proposals focusing will show, by means of a statistical comparative analysis, that we cannot highlight an unique approach among the rest. This will lead to a discussion about the data intrinsic characteristics of the imbalanced classification problem which will help to follow new paths that can lead to the improvement of current models mainly focusing on class overlap and dataset shift in imbalanced classification. (C) 2011 Elsevier Ltd. All rights reserved.								2	0	0	0	2	0957-4174		WOS:000301025300032	
J	Kybic, Jan; Vnucko, Ivan								Approximate all nearest neighbor search for high dimensional entropy estimation for image registration								SIGNAL PROCESSING			92	5			1302	1316		10.1016/j.sigpro.2011.11.027			MAY 2012	2012	Information theoretic criteria such as mutual information are often used as similarity measures for inter-modality image registration. For better performance, it is useful to consider vector-valued pixel features. However, this leads to the task of estimating entropy in medium to high dimensional spaces, for which standard histogram entropy estimator is not usable. We have therefore previously proposed to use a nearest neighbor-based Kozachenko-Leonenko (KL) entropy estimator.Here we address the issue of determining a suitable all nearest neighbor (NN) search algorithm for this relatively specific task.We evaluate several well-known state-of-the-art standard algorithms based on k-d trees (FLANN), balanced box decomposition (BBD) trees (ANN), and locality sensitive hashing (LSH), using publicly available implementations. In addition, we present our own method, which is based on k-d trees with several enhancements and is tailored for this particular application.We conclude that all tree-based methods perform acceptably well, with our method being the fastest and most suitable for the all-NN search task needed by the KL estimator on image data, while the ANN and especially FLANN methods being most often the fastest on other types of data. On the other hand, LSH is found the least suitable, with the brute force search being the slowest. (C) 2011 Elsevier B.V. All rights reserved.								2	0	0	0	2	0165-1684		WOS:000300204200011	
J	Lages, Nuno F.; Cordeiro, Carlos; Silva, Marta Sousa; Freire, Ana Ponces; Ferreira, Antonio E. N.				Cordeiro, Carlos/A-6617-2012; Ferreira, Antonio/E-6488-2012; Sousa Silva, Marta/D-7318-2012				Optimization of Time-Course Experiments for Kinetic Model Discrimination								PLOS ONE			7	3					e32749	10.1371/journal.pone.0032749			MAR 5 2012	2012	Systems biology relies heavily on the construction of quantitative models of biochemical networks. These models must have predictive power to help unveiling the underlying molecular mechanisms of cellular physiology, but it is also paramount that they are consistent with the data resulting from key experiments. Often, it is possible to find several models that describe the data equally well, but provide significantly different quantitative predictions regarding particular variables of the network. In those cases, one is faced with a problem of model discrimination, the procedure of rejecting inappropriate models from a set of candidates in order to elect one as the best model to use for prediction. In this work, a method is proposed to optimize the design of enzyme kinetic assays with the goal of selecting a model among a set of candidates. We focus on models with systems of ordinary differential equations as the underlying mathematical description. The method provides a design where an extension of the Kullback-Leibler distance, computed over the time courses predicted by the models, is maximized. Given the asymmetric nature this measure, a generalized differential evolution algorithm for multiobjective optimization problems was used. The kinetics of yeast glyoxalase I (EC 4.4.1.5) was chosen as a difficult test case to evaluate the method. Although a single-substrate kinetic model is usually considered, a two-substrate mechanism has also been proposed for this enzyme. We designed an experiment capable of discriminating between the two models by optimizing the initial substrate concentrations of glyoxalase I, in the presence of the subsequent pathway enzyme, glyoxalase II (EC 3.1.2.6). This discriminatory experiment was conducted in the laboratory and the results indicate a two-substrate mechanism for the kinetics of yeast glyoxalase I.								2	0	2	0	2	1932-6203		WOS:000303017700100	
J	Endresen, Dag Terje Filip; Street, Kenneth; Mackay, Michael; Bari, Abdallah; Amri, Ahmed; De Pauw, Eddy; Nazari, Kumarse; Yahyaoui, Amor								Sources of Resistance to Stem Rust (Ug99) in Bread Wheat and Durum Wheat Identified Using Focused Identification of Germplasm Strategy								CROP SCIENCE			52	2			764	773		10.2135/cropsci2011.08.0427			MAR-APR 2012	2012	The focused identification of germplasm strategy (FIGS) has been validated using predictive computer models in simulation studies to predict a priori known trait scores. This study was designed as a "blind" study where the person calculating the computer model did not know the actual trait scores. This study design provides a more realistic test of the predictive capacity of the FIGS approach compared to previous studies. Furthermore this study also explored the suitability of FIGS for the identification of resistance in bread wheat (Triticum aestivum L. subsp. aestivum) and durum wheat [Triticum turgidum L. subsp. durum (Desf.) Husn.] to Ug99-a strain of stem rust (Puccinia graminis Pers. f. sp. tritici Eriks. & Henn.) and typified to race TTKSK. The predictions were validated against a dataset with the screening of wheat accessions conducted in Yemen in 2008. Only a small training set representing 20% of the trait screening results was disclosed to the person conducting the data analysis for the calibration of the prediction model. The hit rate for identification of Ug99-resistant accessions was more than two times higher when using the FIGS approach compared to a random selection of accessions. These results suggested that FIGS was well suited for the identification of samples with resistance to fungal pathogens. It is therefore recommended that FIGS approach be used as a complement to expert knowledge and experience when selecting accessions for plant breeding and crop research activities.								2	0	2	0	2	0011-183X		WOS:000300800400032	
J	Wu, Lei; Hoi, Steven C. H.; Jin, Rong; Zhu, Jianke; Yu, Nenghai				Zhang, JinYuan/C-1542-2010				Learning Bregman Distance Functions for Semi-Supervised Clustering								IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			24	3			478	491		10.1109/TKDE.2010.215			MAR 2012	2012	Learning distance functions with side information plays a key role in many data mining applications. Conventional distance metric learning approaches often assume that the target distance function is represented in some form of Mahalanobis distance. These approaches usually work well when data are in low dimensionality, but often become computationally expensive or even infeasible when handling high-dimensional data. In this paper, we propose a novel scheme of learning nonlinear distance functions with side information. It aims to learn a Bregman distance function using a nonparametric approach that is similar to Support Vector Machines. We emphasize that the proposed scheme is more general than the conventional approach for distance metric learning, and is able to handle high-dimensional data efficiently. We verify the efficacy of the proposed distance learning method with extensive experiments on semi-supervised clustering. The comparison with state-of-the-art approaches for learning distance functions with side information reveals clear advantages of the proposed technique.								2	0	0	0	2	1041-4347		WOS:000299384600008	
J	Niu, Shen; Hu, Le-Le; Zheng, Lu-Lu; Huang, Tao; Feng, Kai-Yan; Cai, Yu-Dong; Li, Hai-Peng; Li, Yi-Xue; Chou, Kuo-Chen				Chou, Kuo-Chen/A-8340-2009				Predicting protein oxidation sites with feature selection and analysis approach								JOURNAL OF BIOMOLECULAR STRUCTURE & DYNAMICS			29	6			650	658		10.1080/07391102.2011.672629			2012	2012	Protein oxidation is a ubiquitous post-translational modification that plays important roles in various physiological and pathological processes. Owing to the fact that protein oxidation can also take place as an experimental artifact or caused by oxygen in the air during the process of sample collection and analysis, and that it is both time-consuming and expensive to determine the protein oxidation sites purely by biochemical experiments, it would be of great benefit to develop in silico methods for rapidly and effectively identifying protein oxidation sites. In this study, we developed a computational method to address this problem. Our method was based on the nearest neighbor algorithm in which, however, the maximum relevance minimum redundancy and incremental feature selection approaches were incorporated. From the initial 735 features, 16 features were selected as the optimal feature set. Of such 16 optimized features, 10 features were associated with the position-specific scoring matrix conservation scores, three with the amino acid factors, one with the propensity of conservation of residues on protein surface, one with the side chain count of carbon atom deviation from mean, and one with the solvent accessibility. It was observed that our prediction model achieved an overall success rate of 75.82%, indicating that it is quite encouraging and promising for practical applications. Also, the 16 optimal features obtained through this study may provide useful clues and insights for in-depth understanding the action mechanism of protein oxidation.								2	1	2	0	3	0739-1102		WOS:000303566400006	
J	Golugula, Abhishek; Lee, George; Master, Stephen R.; Feldman, Michael D.; Tomaszewski, John E.; Speicher, David W.; Madabhushi, Anant								Supervised Regularized Canonical Correlation Analysis: integrating histologic and proteomic measurements for predicting biochemical recurrence following prostate surgery								BMC BIOINFORMATICS			12						483	10.1186/1471-2105-12-483			DEC 19 2011	2011	Background: Multimodal data, especially imaging and non-imaging data, is being routinely acquired in the context of disease diagnostics; however, computational challenges have limited the ability to quantitatively integrate imaging and non-imaging data channels with different dimensionalities and scales. To the best of our knowledge relatively few attempts have been made to quantitatively fuse such data to construct classifiers and none have attempted to quantitatively combine histology (imaging) and proteomic (non-imaging) measurements for making diagnostic and prognostic predictions. The objective of this work is to create a common subspace to simultaneously accommodate both the imaging and non-imaging data (and hence data corresponding to different scales and dimensionalities), called a metaspace. This metaspace can be used to build a meta-classifier that produces better classification results than a classifier that is based on a single modality alone. Canonical Correlation Analysis (CCA) and Regularized CCA (RCCA) are statistical techniques that extract correlations between two modes of data to construct a homogeneous, uniform representation of heterogeneous data channels. In this paper, we present a novel modification to CCA and RCCA, Supervised Regularized Canonical Correlation Analysis (SRCCA), that (1) enables the quantitative integration of data from multiple modalities using a feature selection scheme, (2) is regularized, and (3) is computationally cheap. We leverage this SRCCA framework towards the fusion of proteomic and histologic image signatures for identifying prostate cancer patients at the risk of 5 year biochemical recurrence following radical prostatectomy.Results: A cohort of 19 grade, stage matched prostate cancer patients, all of whom had radical prostatectomy, including 10 of whom had biochemical recurrence within 5 years of surgery and 9 of whom did not, were considered in this study. The aim was to construct a lower fused dimensional metaspace comprising both the histological and proteomic measurements obtained from the site of the dominant nodule on the surgical specimen. In conjunction with SRCCA, a random forest classifier was able to identify prostate cancer patients, who developed biochemical recurrence within 5 years, with a maximum classification accuracy of 93%.Conclusions: The classifier performance in the SRCCA space was found to be statistically significantly higher compared to the fused data representations obtained, not only from CCA and RCCA, but also two other statistical techniques called Principal Component Analysis and Partial Least Squares Regression. These results suggest that SRCCA is a computationally efficient and a highly accurate scheme for representing multimodal (histologic and proteomic) data in a metaspace and that it could be used to construct fused biomarkers for predicting disease recurrence and prognosis.								2	0	0	0	2	1471-2105		WOS:000299824700001	
J	Paiva, Jose Gustavo S.; Florian-Cruz, Laura; Pedrini, Helio; Telles, Guilherme P.; Minghim, Rosane				Minghim, Rosane/E-5703-2011; Pedrini, Helio/A-7556-2012; Telles, Guilherme/E-6620-2011				Improved Similarity Trees and their Application to Visual Data Classification								IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS			17	12			2459	2468					DEC 2011	2011	An alternative form to multidimensional projections for the visual analysis of data represented in multidimensional spaces is the deployment of similarity trees, such as Neighbor Joining trees. They organize data objects on the visual plane emphasizing their levels of similarity with high capability of detecting and separating groups and subgroups of objects. Besides this similarity-based hierarchical data organization, some of their advantages include the ability to decrease point clutter; high precision; and a consistent view of the data set during focusing, offering a very intuitive way to view the general structure of the data set as well as to drill down to groups and subgroups of interest. Disadvantages of similarity trees based on neighbor joining strategies include their computational cost and the presence of virtual nodes that utilize too much of the visual space. This paper presents a highly improved version of the similarity tree technique. The improvements in the technique are given by two procedures. The first is a strategy that replaces virtual nodes by promoting real leaf nodes to their place, saving large portions of space in the display and maintaining the expressiveness and precision of the technique. The second improvement is an implementation that significantly accelerates the algorithm, impacting its use for larger data sets. We also illustrate the applicability of the technique in visual data mining, showing its advantages to support visual classification of data sets, with special attention to the case of image classification. We demonstrate the capabilities of the tree for analysis and iterative manipulation and employ those capabilities to support evolving to a satisfactory data organization and classification.				IEEE Visualization Conference (Vis)/IEEE Information Visualization Conference (InfoVis)	OCT 23-28, 2011	IEEE	Providence, RI	2	0	1	0	2	1077-2626		WOS:000296241900079	
J	Zhu, Xingquan				Zhang, JinYuan/C-1542-2010				Cross-Domain Semi-Supervised Learning Using Feature Formulation								IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			41	6			1627	1638		10.1109/TSMCB.2011.2157999			DEC 2011	2011	Semi-Supervised Learning (SSL) traditionally makes use of unlabeled samples(1) by including them into the training set through an automated labeling process. Such a primitive Semi-Supervised Learning (pSSL) approach suffers from a number of disadvantages including false labeling and incapable of utilizing out-of-domain samples. In this paper, we propose a formative Semi-Supervised Learning (fSSL) framework which explores hidden features between labeled and unlabeled samples to achieve semi-supervised learning. fSSL regards that both labeled and unlabeled samples are generated from some hidden concepts with labeling information partially observable for some samples. The key of the fSSL is to recover the hidden concepts, and take them as new features to link labeled and unlabeled samples for semi-supervised learning. Because unlabeled samples are only used to generate new features, but not to be explicitly included in the training set like pSSL does, fSSL overcomes the inherent disadvantages of the traditional pSSL methods, especially for samples not within the same domain as the labeled instances. Experimental results and comparisons demonstrate that fSSL significantly outperforms pSSL-based methods for both within-domain and cross-domain semi-supervised learning.								2	0	0	0	2	1083-4419		WOS:000297342100015	
J	Hu, Qinghua; An, Shuang; Yu, Xiao; Yu, Daren								Robust fuzzy rough classifiers								FUZZY SETS AND SYSTEMS			183	1			26	43		10.1016/j.fss.2011.01.016			NOV 16 2011	2011	Fuzzy rough sets, generalized from Pawlak's rough sets, were introduced for dealing with continuous or fuzzy data. This model has been widely discussed and applied these years. It is shown that the model of fuzzy rough sets is sensitive to noisy samples, especially sensitive to mislabeled samples. As data are usually contaminated with noise in practice, a robust model is desirable. We introduce a new model of fuzzy rough set model, called soft fuzzy rough sets, and design a robust classification algorithm based on the model. Experimental results show the effectiveness of the proposed algorithm. (C) 2011 Elsevier B.V. All rights reserved.								2	1	0	0	3	0165-0114		WOS:000295444200002	
J	Zacharaki, Evangelia I.; Kanas, Vasileios G.; Davatzikos, Christos								Investigating machine learning techniques for MRI-based classification of brain neoplasms								INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY			6	6			821	828		10.1007/s11548-011-0559-3			NOV 2011	2011	Diagnosis and characterization of brain neoplasms appears of utmost importance for therapeutic management. The emerging of imaging techniques, such as Magnetic Resonance (MR) imaging, gives insight into pathology, while the combination of several sequences from conventional and advanced protocols (such as perfusion imaging) increases the diagnostic information. To optimally combine the multiple sources and summarize the information into a distinctive set of variables however remains difficult. The purpose of this study is to investigate machine learning algorithms that automatically identify the relevant attributes and are optimal for brain tumor differentiation.Different machine learning techniques are studied for brain tumor classification based on attributes extracted from conventional and perfusion MRI. The attributes, calculated from neoplastic, necrotic, and edematous regions of interest, include shape and intensity characteristics. Attributes subset selection is performed aiming to remove redundant attributes using two filtering methods and a wrapper approach, in combination with three different search algorithms (Best First, Greedy Stepwise and Scatter). The classification frameworks are implemented using the WEKA software.The highest average classification accuracy assessed by leave-one-out (LOO) cross-validation on 101 brain neoplasms was achieved using the wrapper evaluator in combination with the Best First search algorithm and the KNN classifier and reached 96.9% when discriminating metastases from gliomas and 94.5% when discriminating high-grade from low-grade neoplasms.A computer-assisted classification framework is developed and used for differential diagnosis of brain neoplasms based on MRI. The framework can achieve higher accuracy than most reported studies using MRI.								2	0	1	0	2	1861-6410		WOS:000295680700009	
J	Polat, Kemal; Kirmaci, Volkan								Determining of gas type in counter flow vortex tube using pairwise fisher score attribute reduction method								INTERNATIONAL JOURNAL OF REFRIGERATION-REVUE INTERNATIONALE DU FROID			34	6			1372	1386		10.1016/j.ijrefrig.2011.05.010			SEP 2011	2011	This paper focused on the determining of gas types in counter flow type vortex tubes. In the present study, four different gas types including air, oxygen, nitrogen, and argon in the vortex tube with different inlet pressures and nozzle numbers have been used. The main aims of this paper are to investigate the correlations between gas types and input parameters comprising nozzle numbers, inlet pressures, inlet mass flow rate, temperature of cold outlet, temperature of hot outlet, and cold mass fraction and to select the most important attributes using correlation based attribute reduction and pairwise fisher score attribute reduction (PFSAR). After attribute reduction methods applied to dataset, k-nearest neighbor and C4.5 decision tree classifiers have been used to determine the gas type in the RHVT. The results have demonstrated that the PFSAR is a robust and efficient method in the reduction of attributes belonging to vortex tube. (C) 2011 Elsevier Ltd and IIR. All rights reserved.								2	0	0	0	2	0140-7007		WOS:000294398000007	
J	Saez, Carlos; Miguel Garcia-Gomez, Juan; Vicente, Javier; Tortajada, Salvador; Luts, Jan; Dupplaw, David; Van Huffel, Sabine; Robles, Montserrat								A generic and extensible automatic classification framework applied to brain tumour diagnosis in HealthAgents								KNOWLEDGE ENGINEERING REVIEW			26	3	SI		283	301		10.1017/S0269888911000129			SEP 2011	2011	New biomedical technologies enable the diagnosis of brain tumours by using non-invasive methods. HealthAgents is a European Union-funded research project that aims to build an agent-based distributed decision support system (dDSS) for the diagnosis of brain tumours. This is achieved using the latest biomedical knowledge, information and communication technologies and pattern recognition (PR) techniques. As part of the PR development of HealthAgents, an independent and automatic classification framework (CF) has been developed. This framework has been integrated with the HealthAgents dDSS using the HealthAgents agent platform. The system offers (1) the functionality to search for distributed classifiers to solve specific questions; (2) automatic classification of new cases; (3) instant deployment of new validated classifiers; and (4) the ability to rank a set of classifiers according to their performance and suitability for the case in hand. The CF enables both the deployment of new classifiers using the provided Extensible Markup Language(1) classifier specification, and the inclusion of new PR techniques that make the system extensible. These features may enable the rapid integration of PR laboratory results into industrial or research applications, such as the HealthAgents dDSS. Two classification nodes have been deployed and they currently offer classification services by means of dedicated servers connected to the HealthAgents agent platform: one node being located at the Katholieke Universiteit Leuven, Belgium and the other at the Universidad Politecnica de Valencia, Spain. These classification nodes share the current set of brain tumour classifiers that have been trained from in vivo magnetic resonance spectroscopy data. The combination of the CF with a distributed agent system constitutes the basis of the brain tumour dDSS developed in HealthAgents.								2	0	2	0	2	0269-8889		WOS:000294345800004	
J	Tuana, Giacomo; Volpato, Viola; Ricciardi-Castagnoli, Paola; Zolezzi, Francesca; Stella, Fabio; Foti, Maria								Classification of dendritic cell phenotypes from gene expression data								BMC IMMUNOLOGY			12						50	10.1186/1471-2172-12-50			AUG 29 2011	2011	Background: The selection of relevant genes for sample classification is a common task in many gene expression studies. Although a number of tools have been developed to identify optimal gene expression signatures, they often generate gene lists that are too long to be exploited clinically. Consequently, researchers in the field try to identify the smallest set of genes that provide good sample classification. We investigated the genome-wide expression of the inflammatory phenotype in dendritic cells. Dendritic cells are a complex group of cells that play a critical role in vertebrate immunity. Therefore, the prediction of the inflammatory phenotype in these cells may help with the selection of immune-modulating compounds.Results: A data mining protocol was applied to microarray data for murine cell lines treated with various inflammatory stimuli. The learning and validation data sets consisted of 155 and 49 samples, respectively. The data mining protocol reduced the number of probe sets from 5,802 to 10, then from 10 to 6 and finally from 6 to 3. The performances of a set of supervised classification models were compared. The best accuracy, when using the six following genes -II12b, Cd40, Socs3, Irgm1, Plin2 and Lgals3bp- was obtained by Tree Augmented Naive Bayes and Nearest Neighbour (91.8%). Using the smallest set of three genes -II12b, Cd40 and Socs3- the performance remained satisfactory and the best accuracy was with Support Vector Machine (95.9%). These data mining models, using data for the genes II12b, Cd40 and Socs3, were validated with a human data set consisting of 27 samples. Support Vector Machines (71.4%) and Nearest Neighbour (92.6%) gave the worst performances, but the remaining models correctly classified all the 27 samples.Conclusions: The genes selected by the data mining protocol proposed were shown to be informative for discriminating between inflammatory and steady-state phenotypes in dendritic cells. The robustness of the data mining protocol was confirmed by the accuracy for a human data set, when using only the following three genes: II12b, Cd40 and Socs3. In summary, we analysed the longitudinal pattern of expression in dendritic cells stimulated with activating agents with the aim of identifying signatures that would predict or explain the dentritic cell response to an inflammatory agent.								2	0	1	0	2	1471-2172		WOS:000295286400001	
J	Chen, Lifei; Guo, Gongde; Wang, Kaijun								Class-dependent projection based method for text categorization								PATTERN RECOGNITION LETTERS			32	10			1493	1501		10.1016/j.patrec.2011.01.018			JUL 15 2011	2011	Text categorization presents unique challenges to traditional classification methods due to the large number of features inherent in the datasets from real-world applications of text categorization, and a great deal of training samples. In high-dimensional document data, the classes are typically categorized only by subsets of features, which are typically different for the classes of different topics. This paper presents a simple but effective classifier for text categorization using class-dependent projection based method. By projecting onto a set of individual subspaces, the samples belonging to different document classes are separated such that they are easily to be classified. This is achieved by developing a new supervised feature weighting algorithm to learn the optimized subspaces for all the document classes. The experiments carried out on common benchmarking corpuses showed that the proposed method achieved both higher classification accuracy and lower computational costs than some distinguishing classifiers in text categorization, especially for datasets including document categories with overlapping topics. (C) 2011 Elsevier B.V. All rights reserved.								2	0	0	0	2	0167-8655		WOS:000292236500008	
J	Torres, Jenice; Enriquez-de-Salamanca, Amalia; Fernandez, Itziar; Teresa Rodriguez-Ares, Maria; Quadrado, Maria J.; Murta, Joaquim; Benitez del Castillo, Jose M.; Stern, Michael E.; Calonge, Margarita				Enriquez-de-Salamanca, Amalia/F-2163-2011	Enriquez-de-Salamanca, Amalia/0000-0003-1274-7796			Activation of MAPK Signaling Pathway and NF-kappa B Activation in Pterygium and Ipsilateral Pterygium-Free Conjunctival Specimens								INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE			52	8			5842	5852		10.1167/iovs.10-6673			JUL 2011	2011	PURPOSE. To evaluate mitogen-activated protein kinases (MAPKs) and nuclear factor-kappa B (NF-kappa B) signaling pathways in pterygium and pterygium-free conjunctivas.METHODS. Primary pterygia (n = 21), ipsilateral superior-temporal bulbar conjunctivas (n = 8), and healthy conjunctival (n = 5) biopsy specimens were analyzed. Total and phosphorylated (phospho) levels of extracellular-regulated 1/2 (ERK1/2), p38, and c-jun N-terminal (JNK) MAPKs and NF-kappa B inhibitor-alpha (I kappa B-alpha) were analyzed by immunobead-based assay. Tissue phospho-, total protein, and activation values determined by phospho/total ratios were compared. Correlation among those values and clinical parameters were determined. Average-linkage hierarchical cluster analysis identified patients with similar protein activation values. The k-nearest neighbor classifier predicted the origin of specimens based on protein levels.RESULTS. Pterygium samples had significantly lower total JNK and I kappa B-alpha levels than did healthy conjunctivas. Decreased total JNK and I kappa B-alpha and increased phospho-I kappa B-alpha levels and phospho/total ratio of JNK and I kappa B-alpha were present in ipsilateral conjunctivas compared with healthy conjunctivas. Protein levels were correlated among them in pterygium, ipsilateral, and healthy conjunctivas and with sun exposure, pterygium grade, and pterygium measurements. Cluster analysis of activation values and ratios in pterygium and ipsilateral-conjunctiva revealed different groups of patients with similar values. Prediction accuracy was 70% to 80% for the classifiers phospho-and total protein levels and phospho/total ratio.CONCLUSIONS. Pterygium and pterygium-free ipsilateral conjunctivas had alterations in MAPK and NF-kappa B pathways not present in healthy conjunctivas. The high prediction accuracy based on phospho-and total protein levels and phospho/total ratio of ERK1/2, p38, JNK, and I kappa B-alpha suggests these molecules as potential biomarkers of inflammation in pterygia. (Invest Ophthalmol Vis Sci. 2011;52:5842-5852) DOI: 10.1167/iovs.10-6673								2	0	1	0	2	0146-0404		WOS:000293377400107	
J	Day, Peter; Nandi, Asoke K.				Nandi, Asoke/C-4572-2011				Evolution of superFeatures through genetic programming								EXPERT SYSTEMS			28	2			167	184		10.1111/j.1468-0394.2010.00547.x			MAY 2011	2011	The success of automatic classification is intricately linked with an effective feature selection. Previous studies on the use of genetic programming (GP) to solve classification problems have highlighted its benefits, principally its inherent feature selection (a process that is often performed independent of a learning method). In this paper, the problem of classification is recast as a feature generation problem, where GP is used to evolve programs that allow non-linear combination of features to create superFeatures, from which classification tasks can be achieved fairly easily. In order to generate superFeatures robustly, the binary string fitness characterization along with the comparative partner selection strategy is introduced with the aim of promoting optimal convergence. The techniques introduced are applied to two illustrative problems first and then to the real-world problem of audio source classification, with competitive results.								2	0	0	0	2	0266-4720		WOS:000289684100005	
J	Liu, Hsi-Che; Shih, Lee-Yung; Chen, Mei-Ju May; Wang, Chien-Chih; Yeh, Ting-Chi; Lin, Tung-Huei; Chen, Chien-Yu; Lin, Chih-Jen; Liang, Der-Cherng								Expression of HOXB genes is significantly different in acute myeloid leukemia with a partial tandem duplication of MLL vs. a MLL translocation: a cross-laboratory study								CANCER GENETICS			204	5			252	259		10.1016/j.cancergen.2011.02.003			MAY 2011	2011	In acute myeloid leukemia (AML), the mixed lineage leukemia (MLL) gene may be rearranged to generate a partial tandem duplication (PTD), or fused to partner genes through a chromosomal translocation (tMLL). In this study, we first explored the differentially expressed genes between MLL-PTD and tMLL using gene expression profiling of our cohort (15 MLL-PTD and 10 tMLL) and one published data set. The top 250 probes were chosen from each set, resulting in 29 common probes (21 unique genes) to both sets. The selected genes include four HOXB genes, HOXB2, B3, B5, and B6. The expression values of these HOXB genes significantly differ between MLL-PTD and tMLL cases. Clustering and classification analyses were thoroughly conducted to support our gene selection results. Second, as MLL-PTD, FLT3-ITD, and NPM1 mutations are identified in AML with normal karyotypes, we briefly studied their impact on the HOXB genes. Another contribution of this study is to demonstrate that using public data from other studies enriches samples for analysis and yields more conclusive results.								2	1	2	0	3	2210-7762		WOS:000292020700003	
J	Chuang, Li-Yeh; Yang, Cheng-Huei; Wu, Kuo-Chuan; Yang, Cheng-Hong				Chuang, Li-Yeh/E-5005-2011				A hybrid feature selection method for DNA microarray data								COMPUTERS IN BIOLOGY AND MEDICINE			41	4			228	237		10.1016/j.compbiomed.2011.02.004			APR 2011	2011	Gene expression profiles, which represent the state of a cell at a molecular level, have great potential as a medical diagnosis tool. In cancer classification, available training data sets are generally of a fairly small sample size compared to the number of genes involved. Along with training data limitations, this constitutes a challenge to certain classification methods. Feature (gene) selection can be used to successfully extract those genes that directly influence classification accuracy and to eliminate genes which have no influence on it. This significantly improves calculation performance and classification accuracy. In this paper, correlation-based feature selection (CFS) and the Taguchi-genetic algorithm (TGA) method were combined into a hybrid method, and the K-nearest neighbor (KNN) with the leave-one-out cross-validation (LOOCV) method served as a classifier for eleven classification profiles to calculate the classification accuracy. Experimental results show that the proposed method reduced redundant features effectively and achieved superior classification accuracy. The classification accuracy obtained by the proposed method was higher in ten out of the eleven gene expression data set test problems when compared to other classification methods from the literature. (C) 2011 Elsevier Ltd. All rights reserved.								2	0	2	0	2	0010-4825		WOS:000289917200008	
J	Antonio Martin H, Jose; de Lope, Javier; Maravall, Dario				Martin H., Jose Antonio/A-2388-2009				Robust high performance reinforcement learning through weighted k-nearest neighbors								NEUROCOMPUTING			74	8	SI		1251	1259		10.1016/j.neucom.2010.07.027			MAR 15 2011	2011	The aim of this paper is to present (jointly) a series of robust high performance (award winning) implementations of reinforcement learning algorithms based on temporal-difference learning and weighted k- nearest neighbors for linear function approximation. These algorithms, named kNN-TD(lambda) methods, where rigorously tested at the Second and Third Annual Reinforcement Learning Competitions (RLC2008 and RCL2009) held in Helsinki and Montreal respectively, where the kNN-TD(A) method (JAMH team) won in the PolyAthlon 2008 domain, obtained the second place in 2009 and also the second place in the Mountain-Car 2008 domain showing that it is one of the state of the art general purpose reinforcement learning implementations. These algorithms are able to learn quickly, to generalize properly over continuous state spaces and also to be robust to a high degree of environmental noise. Furthermore, we describe a derivation of kNN-TD(A) algorithm for problems where the use of continuous actions have clear advantages over the use of fine grained discrete actions: the Ex < a > reinforcement learning algorithm. (C) 2010 Elsevier B.V. All rights reserved.				3rd International Work-Conference on the Interplay Between Natural and Artificial Computation	JUN 22-26, 2009		Santiago de Compostela, SPAIN	2	1	0	0	3	0925-2312		WOS:000289453500012	
J	Alfatni, Meftah Salem; Shariff, Abdul Rashid Mohamed; Abdullah, Mohd Zaid; Ben Saeed, Osama Mohamed; Ceesay, Omar M.								Recent Methods and Techniques of External Grading Systems for Agricultural Crops Quality Inspection - Review								INTERNATIONAL JOURNAL OF FOOD ENGINEERING			7	3					10	10.2202/1556-3758.1932			2011	2011	In recent years, due to increasing necessity and the rise in agricultural production worldwide, an efficient, uncomplicated and precise classification mechanism of agricultural crops is indeed an important endeavor for high quality products. This paper reviews the recent techniques and features of external grading systems for the non-destructive operation and performance of automated quality verification systems for agricultural products. The grading systems utilize highly technical engineering designs and image processing techniques to convey information and grade the products. The most common methods and techniques involved in the grading system's external inspection stages such as color, size, shape and texture are highlighted.								2	0	1	0	2	1556-3758		WOS:000291217700004	
B	Alippi, Cesare; Boracchi, Giacomo; Roveri, Manuel			IEEE					An Effective Just-in-Time Adaptive Classifier for Gradual Concept Drifts								2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)							1675	1682					2011	2011	Classification systems designed to work in nonstationary conditions rely on the ability to track the monitored process by detecting possible changes and adapting their knowledge-base accordingly. Adaptive classifiers present in the literature are effective in handling abrupt concept drifts (i.e., sudden variations), but, unfortunately, they are not able to adapt to gradual concept drifts (i.e., smooth variations) as these are, in the best case, detected as a sequence of abrupt concept drifts. To address this issue we introduce a novel adaptive classifier that is able to track and adapt its knowledge base to gradual concept drifts (modeled as polynomial trends in the expectations of the conditional probability density functions of input samples), while maintaining its effectiveness in dealing with abrupt ones. Experimental results show that the proposed classifier provides high classification accuracy both on synthetically generated datasets and measurements from real sensors.				International Joint Conference on Neural Networks (IJCNN)	JUL 31-AUG 05, 2011	Int Neural Network Soc (INNS); IEEE Computat Intelligence Soc (CIS); Natl Sci Fdn (NSF); Cognimem Technol, Inc; Univ Cincinnati Coll Engn & Appl Sci; Toyota Res Inst N Amer; Univ Cincinnati, Sch Elect & Compu Syst	San Jose, CA	2	0	0	0	2		978-1-4244-9636-5	WOS:000297541201113	
J	Hejazi, M. A.; Gharehpetian, G. B.; Moradi, G. R.; Mohammadi, M.; Alehoseini, H. A.								Application of Classifiers for On-line Monitoring of Transformer Winding Axial Displacement by Electromagnetic Non-destructive Testing								ELECTRIC POWER COMPONENTS AND SYSTEMS			39	4			387	403	PII 933722533	10.1080/15325008.2010.528537			2011	2011	Transformer winding on-line monitoring using electromagnetic non-destructive testing has been suggested in this article. As a test object, a simplified model of transformer has been used. The winding axial displacement can be modeled on the test object. The scattering parameters of the test object can be measured and stored in a database. To detect the axial displacement, two indices have been defined using the magnitude and phase of scattering parameters. The k-nearest neighbor and decision tree classifiers have been used for the detection of the winding axial displacement and its value. The accuracy of the k-nearest neighbor method to find the axial displacement value has been improved by using a proposed k-nearest neighbor regression algorithm. The comparison of the average error of two classifiers shows the superiority of the k-nearest neighbor regression over the decision tree classifier.								2	0	0	0	2	1532-5008		WOS:000287495600006	
J	Sedano, Javier; Berzosa, Alba; Villar, Jose R.; Corchado, Emilio; de la Cal, Enrique				2011, Secribsal/D-9425-2012				Optimising operational costs using Soft Computing techniques								INTEGRATED COMPUTER-AIDED ENGINEERING			18	4			313	325		10.3233/ICA-2011-0379			2011	2011	A Manufacturing Execution System (MES) consists of high-cost, large-scale, multi-task software systems. Companies and factories apply these complex applications for the purposes of production management to monitor and track all aspects of factory-based manufacturing processes. Nevertheless, companies seek to control the production process with even greater rigour. Improvements associated with an MES involve the identification of new knowledge within the data set and its integration in the system, which implies a step forward to Business Process Management (BPM) systems, from which the users of an MES may gain relevant information, not only on execution procedures but to decide on the best scheduled arrangement. This work studies the data gathered from a real MES that is used in a plastic products factory. Several Artificial Intelligence and Soft Computing modelling methods based on fuzzy rules assist in the calculation of manufacturing costs and decisions over shift work rotas: two decisions that are of relevance for the improvement of the execution system. The results of the study, which identify the most suitable models to facilitate execution-related decision-making, are presented and discussed.								2	0	0	0	2	1069-2509		WOS:000295356300002	
J	Zurada, Jozef; Karwowski, Waldemar								Knowledge Discovery Through Experiential Learning From Business and Other Contemporary Data Sources: A Review and Reappraisal								INFORMATION SYSTEMS MANAGEMENT			28	3	SI		258	274		10.1080/10580530.2010.493846			2011	2011	Every day massive amount of data is generated, collected, and stored in information repositories such as databases and data warehouses. Current information technology is sufficiently mature and powerful to store any amount of raw data in an organized manner. However, finding useful patterns, trends, rules, correlations, and deviations in large amount of data, and/or making meaningful predictions from it still remains one of the main challenges of the information era. The more data one has, the more difficult it is to analyze and draw meaningful conclusions. Knowledge discovery in databases (KDD) and data mining (DM) is a field, which uses computer-based and analytic technologies to efficiently extract intelligence from data that humans need. In this article, we review the process of knowledge discovery in databases, and describe selected methodologies, methods and tools, tasks, basic learning paradigms, and applications for knowledge generation by computer learning from data instances. We also examine the current trends in the field with respect to the data types mined, data mining methods used, classes of data mining applications, as well as the data mining software used.								2	0	0	0	2	1058-0530		WOS:000299960000007	
J	Du, Qian; Wei, Wei; May, Daniel; Younan, Nicolas H.								Noise-Adjusted Principal Component Analysis for Buried Radioactive Target Detection and Classification								IEEE TRANSACTIONS ON NUCLEAR SCIENCE			57	6			3760	3767		10.1109/TNS.2010.2084105			DEC 2010	2010	We present a noise-adjusted principal component analysis (NAPCA)-based approach to the detection and classification of buried radioactive targets with short sensor dwell time. The data used in the experiments is the gamma spectroscopy collected by a Sodium Iodide (NAI) scintillation detector. Spectral transformation methods are first applied to the data, followed by NAPCA. Then kappa-nearest neighbor (kappa NN) clustering is applied to the NAPCA-transformed feature subspace to achieve detection or classification. This method is evaluated using a database of 240 spectral measurements consisting of background (construction sand), benign material measurements (uranium ore), and target measurements (depleted uranium) at various depths. Compared to other widely used algorithms for depleted uranium, the proposed technique can provide better performance.								2	0	0	0	2	0018-9499		WOS:000285356200017	
J	Ferrandiz, Sylvain; Boulle, Marc								Bayesian instance selection for the nearest neighbor rule								MACHINE LEARNING			81	3			229	256		10.1007/s10994-010-5170-2			DEC 2010	2010	The nearest neighbors rules are commonly used in pattern recognition and statistics. The performance of these methods relies on three crucial choices: a distance metric, a set of prototypes and a classification scheme. In this paper, we focus on the second, challenging issue: instance selection. We apply a maximum a posteriori criterion to the evaluation of sets of instances and we propose a new optimization algorithm. This gives birth to Eva, a new instance selection method. We benchmark this method on real datasets and perform a multi-criteria analysis: we evaluate the compression rate, the predictive accuracy, the reliability and the computational time. We also carry out experiments on synthetic datasets in order to discriminate the respective contributions of the criterion and the algorithm, and to illustrate the advantages of Eva over the state-of-the-art algorithms. The study shows that Eva outputs smaller and more reliable sets of instances, in a competitive time, while preserving the predictive accuracy of the related classifier.								2	1	0	0	3	0885-6125		WOS:000282427700002	
J	Giacco, Ferdinando; Thiel, Christian; Pugliese, Luca; Scarpetta, Silvia; Marinaro, Maria								Uncertainty Analysis for the Classification of Multispectral Satellite Images Using SVMs and SOMs								IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			48	10			3769	3779		10.1109/TGRS.2010.2047863			OCT 2010	2010	Classification of multispectral remotely sensed data with textural features is investigated with a special focus on uncertainty analysis in the produced land-cover maps. Much effort has already been directed into the research of satisfactory accuracy-assessment techniques in image classification, but a common approach is not yet universally adopted. We look at the relationship between hard accuracy and the uncertainty on the produced answers, introducing two measures based on maximum probability and a quadratic entropy. Their impact differs depending on the type of classifier. In this paper, we deal with two different classification strategies, based on support vector machines (SVMs) and Kohonen's self-organizingmaps (SOMs), both suitably modified to give soft answers. Once the multiclass probability answer vector is available for each pixel in the image, we studied the behavior of the overall classification accuracy as a function of the uncertainty associated with each vector, given a hard-labeled test set. The experimental results show that the SVM with one-versus-one architecture and linear kernel clearly outperforms the other supervised approaches in terms of overall accuracy. On the other hand, our analysis reveals that the proposed SOM-based classifier, despite its unsupervised learning procedure, is able to provide soft answers which are the best candidates for a fusion with supervised results.								2	0	0	0	2	0196-2892		WOS:000283349400016	
J	Teixeira, Lamartine Almeida; Inacio de Oliveira, Adriano Lorena								A method for automatic stock trading combining technical analysis and nearest neighbor classification								EXPERT SYSTEMS WITH APPLICATIONS			37	10			6885	6890		10.1016/j.eswa.2010.03.033			OCT 2010	2010	In this paper we propose and analyze a novel method for automatic stock trading which combines technical analysis and the nearest neighbor classification. Our first and foremost objective is to study the feasibility of the practical use of an intelligent prediction system exclusively based on the history of daily stock closing prices and volumes. To this end we propose a technique that consists of a combination of a nearest neighbor classifier and some well known tools of technical analysis, namely, stop loss, stop gain and RSI filter. For assessing the potential use of the proposed method in practice we compared the results obtained to the results that would be obtained by adopting a buy-and-hold strategy. The key performance measure in this comparison was profitability. The proposed method was shown to generate considerable higher profits than buy-and-hold for most of the companies, with few buy operations generated and, consequently, minimizing the risk of market exposure. (C) 2010 Elsevier Ltd. All rights reserved.								2	0	0	0	2	0957-4174		WOS:000279408200018	
J	Bounhas, Ibrahim; Elayeb, Bilel; Evrard, Fabrice; Slimani, Yahya								Toward a Computer Study of the Reliability of Arabic Stories								JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY			61	8			1686	1705		10.1002/asi.21356			AUG 2010	2010	The Arabic storytelling methodology provides solutions to the problem of information reliability. The reliability of a story depends on the credibility of its narrators. To insure reliability verification, the narrators' names are explicitly cited at the head of the story, which constitute its chain of narrators. Stories were reported from a generation to another to insure the reliable transmission of historical knowledge. We present a set of tools based on the Arabic storytelling methodology. We start by presenting this methodology as a set of principles for information-reliability assessment. Then, we detail an architecture designed to support the study of the reliability of Arabic stories. Indeed, we developed grammars for parsing Arabic full names and chains of narrators of Arabic stories. After that, an intelligent identity recognizer links names found in chains of narrators to the biographies of the corresponding persons. We model this step as a possibilistic information retrieval task. Finally, chains are analyzed through metadata available in biographies to help the user identify sources of unreliability. We propose to identify the class of reliability of a story with a possibilistic classifier. The achieved results in named entity and identity recognition were satisfactory and confirm to the targets set for the precision, recall, and F-measure metrics. The developed tools also are reusable components that can be used to study the reliability of other types of Arabic texts.								2	0	0	0	2	1532-2882		WOS:000280019100013	
J	Rodriguez, Rosa M.; Martinez, Luis; Ruan, Da; Liu, Jun				Rodriguez, Rosa M./B-9618-2011; Liu, Jun/C-1338-2011; Martinez, Luis/A-1746-2009; Research Group, Sinbad2/D-2448-2011	Rodriguez, Rosa M./0000-0002-1736-8915; Martinez, Luis/0000-0003-4245-8813; 			USING COLLABORATIVE FILTERING FOR DEALING WITH MISSING VALUES IN NUCLEAR SAFEGUARDS EVALUATION								INTERNATIONAL JOURNAL OF UNCERTAINTY FUZZINESS AND KNOWLEDGE-BASED SYSTEMS			18	4			431	449		10.1142/S0218488510006635			AUG 2010	2010	Nuclear safeguards evaluation aims to verify that countries are not misusing nuclear programs for nuclear weapons purposes. Experts of the International Atomic Energy Agency (IAEA) carry out an evaluation process in which several hundred so findicat ors are assessed according to the information obtained from different sources, such as State declarations, on-site inspections, IAEA non-safeguards databases and other open sources. These assessments are synthesized in a hierarchical way to obtain a global assessm ent. Much information and many sources of information related to nuclear safeguards the imputed values.								2	0	0	0	2	0218-4885		WOS:000279640100006	
J	Tahir, Muhammad Atif; Smith, Jim								Creating diverse nearest-neighbour ensembles using simultaneous metaheuristic feature selection								PATTERN RECOGNITION LETTERS			31	11			1470	1480		10.1016/j.patrec.2010.01.030			AUG 1 2010	2010	The nearest-neighbour (1NN) classifier has long been used in pattern recognition, exploratory data analysis, and data mining problems. A vital consideration in obtaining good results with this technique is the choice of distance function, and correspondingly which features to consider when computing distances between samples. In recent years there has been an increasing interest in creating ensembles of classifiers in order to improve classification accuracy. This paper proposes a new ensemble technique which combines multiple 1NN classifiers, each using a different distance function, and potentially a different set of features (feature vector).These feature vectors are determined for each distance metric simultaneously using Tabu Search to minimise the ensemble error rate. We show that this approach implicitly selects for a diverse set of classifiers, and by doing so achieves greater performance improvements than can be achieved by treating the classifiers independently, or using a single feature set. Naturally, optimising the level of ensembles necessitates a much larger solution space, to make this approach tractable, we show how Tabu Search at the ensemble level can be hybridised with local search at the level of individual classifiers. The proposed ensemble classifier with different distance metrics and different feature vectors is evaluated using various benchmark datasets from UCI Machine Learning Repository and a real-world machine-vision application. Results have indicated a significant increase in the performance when compared with various well-known classifiers. Furthermore, the proposed ensemble method is also compared with ensemble classifier using different distance metrics but with same feature vector (with or without feature selection (FS)). (C) 2010 Elsevier B.V. All rights reserved.								2	0	0	0	2	0167-8655		WOS:000279834800029	
J	Vauclin, S.; Gardin, I.; Doyeux, K.; Hapdey, S.; Edet-Sanson, A.; Vera, P.								F-18-FDG PET image segmentation. Principles and literature reviewing								MEDECINE NUCLEAIRE-IMAGERIE FONCTIONNELLE ET METABOLIQUE			34	6			358	369		10.1016/j.mednuc.2010.03.005			JUN 2010	2010	Several segmentation methods of lesion uptake in F-18-FDG PET imaging have been proposed in the literature. Their principles are presented along with their clinical results. The main approach proposed in the literature is the thresholding method. The most commonly used is a constant threshold around 40% of the maximum uptake within the lesion. This simple approach is not valid for small (<4 or 5 mL), poorly contrasted positive tissue (SUV < 2) or lesion in movement. To limit these problems, more complex thresholding algorithms have been proposed to define the optimal threshold value to be applied to segment the lesion. The principle is to adapt the threshold following a fitting model according to one or two characteristic image parameters. Those algorithms based on iterative approaches to find the optimal threshold value are preferred as they take into account patient data. The main drawback is the need of a calibration step depending on the PET device, the acquisition conditions and the algorithm used for image reconstruction. To avoid this problem, some more sophisticated segmentation methods have been proposed in the literature: derivative methods, watershed and pattern recognition algorithms. The delineation of positive tissue on FDG-PET images is a complex problem, always under investigation. (C) 2010 Elsevier Masson SAS. All rights reserved.								2	0	0	0	2	0928-1258		WOS:000279132300005	
