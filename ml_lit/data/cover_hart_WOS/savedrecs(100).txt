PT	AU	BA	CA	GP	RI	OI	BE	Z2	TI	X1	Y1	Z1	FT	PN	AE	Z3	SO	SE	BS	VL	IS	SI	MA	BP	EP	AR	DI	D2	SU	PD	PY	AB	X4	Y4	Z4	CT	CY	SP	CL	TC	Z8	ZB	ZS	Z9	SN	BN	UT	
J	Roh, Seok-Beom; Ahn, Tae-Chon; Pedrycz, Witold								The Refinement of Models With the Aid of the Fuzzy k-Nearest Neighbors Approach								IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT			59	3			604	615		10.1109/TIM.2009.2025070			MAR 2010	2010	In this paper, we propose a new design methodology that supports the development of hybrid incremental models. These models result through an iterative process in which a parametric model and a nonparametric model are combined so that their underlying and complementary functionalities become fully exploited. The parametric component of the hybrid model captures some global relationships between the input variables and the output variable. The nonparametric model focuses on capturing local input-output relationships and thus augments the behavior of the model being formed at the global level. In the underlying design, we consider linear and quadratic regression to be a parametric model, whereas a fuzzy k-nearest neighbors model serves as the nonparametric counterpart of the overall model. Numeric results come from experiments that were carried out on some low-dimensional synthetic data sets and several machine learning data sets from the University of California-Irvine Machine Learning Repository.								2	0	0	0	2	0018-9456		WOS:000274383500014	
J	Mariolis, I. G.; Dermatas, E. S.								Automated assessment of textile seam quality based on surface roughness estimation								JOURNAL OF THE TEXTILE INSTITUTE			101	7			653	659	PII 923153509	10.1080/00405000902732883			2010	2010	In this paper the issue of automated seam quality control is addressed, focusing especially on seam pucker evaluation. Currently this task is accomplished by human experts considering five grades of quality. The proposed method estimates surface roughness of seam specimens producing robust and efficient novel features highly correlated to quality grades (QGs). At the initial stage, oblique illumination is applied and two-dimensional images of the specimens are acquired. The images are automatically rotated and centered in respect to the seam line and segmented into four regions. Each region produces an intensity curve through averaging, and roughness estimation is performed based on intensity mean deviation. Finally, a QG is assigned to each specimen using a k-nearest neighbor classifier (kNNc). A data set containing 211 seam specimens, created by two different kinds of fabric, has been used for testing and a correct classification rate of 81.04% has been produced matching up to the performance of human experts.								2	0	0	0	2	0040-5000		WOS:000278924800008	
S	Narvaez, Fabian; Diaz, Gloria; Romero, Eduardo						Marti, J; Oliver, A; Freixenet, J; Marti, R		Automatic BI-RADS Description of Mammographic Masses								DIGITAL MAMMOGRAPHY	Lecture Notes in Computer Science		6136				673	681					2010	2010	This paper presents a Call (Content Based Information Retrieval) framework for automatic description of mammographic masses according to the well known BI-RADS lexicon. Unlike other approaches, we do not attempt to segment masses but instead, we describe the regions an expert selects, after the series of rules defined in the BI-RADS lexicon. The content based retrieval strategy searches similar regions by automatically computing the Mahalanobis distance of feature vectors that describe main shape and texture characteristics of the selected regions. A description of a. test region is based on the BI-RADS description associated to the retrieved regions. The strategy was assessed in a set of 444 masses with different shapes and margins. Suggested descriptions were compared with a ground truth already provided by the data base, showing a precision rate of 82.6% for the retrieval task and a sensitivity rate of 80% for the annotation task.				10th International Workshop on Digital Mammography	JUN 16-18, 2010	Univ Girona, Comp Vision & Robot Grp	Girona, SPAIN	2	0	0	0	2	0302-9743	978-3-642-13665-8	WOS:000285030000091	
S	Wu, Qiong; Tan, Songbo; Duan, Miyi; Cheng, Xueqi				Cheng, Xueqi/F-1706-2010; Tan, Songbo/A-7450-2012		Cheng, PJ; Kan, MY; Lam, W; Nakov, P		A Two-Stage Algorithm for Domain Adaptation with Application to Sentiment Transfer Problems								INFORMATION RETRIEVAL TECHNOLOGY	Lecture Notes in Computer Science		6458				443	453					2010	2010	Classification systems are typically domain-specific, and the performance decreases sharply when transferred from one domain to another domain. Building these systems involves annotating a large amount of data for every domain, which needs much human labor. So, a reasonable way is to utilize labeled data in one existing (or called source) domain for classification in target domain. To address this problem, we propose a two-stage algorithm for domain adaptation. At the first transition stage, we share the information between the source domain and the target domain to get some most confidently labeled documents in the target domain, and at the second transmission stage, we exploit them to label the target-domain data via following the intrinsic structure revealed by the target domain. The experimental results on sentiment data indicate that the proposed approach could improve the performance of domain adaptation dramatically.				6th Asia Information Retrieval Societies Conference	DEC 01-03, 2010	Natl Taiwan Univ; Natl Sci Council, Republ China; Minist Educ, Republ China	Taipei, TAIWAN	2	0	0	0	2	0302-9743	978-3-642-17186-4	WOS:000289174800043	
S	Yang, Tao; Cao, Longbing; Zhang, Chengqi						Zaki, MJ; Yu, JX; Ravindran, B; Pudi, V		A Novel Prototype Reduction Method for the K-Nearest Neighbor Algorithm with K >= 1					II			ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PT II, PROCEEDINGS	Lecture Notes in Artificial Intelligence		6119				89	100					2010	2010	In this paper, a novel prototype reduction algorithm is proposed, which aims at reducing the storage requirement and enhancing the online speed while retaining the same level of accuracy for a K-nearest neighbor (KNN) classifier. To achieve this goal, our proposed algorithm learns the weighted similarity function for a KNN classifier by maximizing the leave-one-out cross-validation accuracy. Unlike the classical methods PW, LPD and WDNN which can only work with K = 1 our developed algorithm can work with K >= 1. This flexibility allows our lean it algorithm to have superior classification accuracy and noise robustness. The proposed approach is assessed through experiments with twenty real world benchmark data sets. In all these experiments, the proposed approach shows it can dramatically reduce the storage requirement and online time for KNN while having equal or better accuracy than KNN, and it also shows comparable results to several prototype reduction methods proposed in literature.				14th Pacific-Asia Conference on Knowledge Discovery and Data Mining	JUN 21-24, 2010	IIIT Hyderbad; AFOSR; AOARD; ONRG	Hyderabad, INDIA	2	0	0	0	2	0302-9743	978-3-642-13671-9	WOS:000281629400010	
J	Chong, Rachel Mabanag; Tanaka, Toshihisa								Detection and Classification of Invariant Blurs								IEICE TRANSACTIONS ON FUNDAMENTALS OF ELECTRONICS COMMUNICATIONS AND COMPUTER SCIENCES			E92A	12			3313	3320		10.1587/transfun.E92.A.3313			DEC 2009	2009	A new algorithm for simultaneously detecting and identifying invariant blurs is proposed. This is mainly based on the behavior of extrema values in an image. It is computationally simple and fast thereby making it suitable for preprocessing especially fit practical imaging applications. Benefits of employing this method includes the elimination of unnecessary processes since unblurred images will be separated from the blurred ones which require deconvotution. Additionally, it can improve reconstruction performance by proper identification of blur type so that a more effective blur specific deconvolution algorithm can be applied. Experimental results on natural images and its synthetically blurred versions show the characteristics and validity of the proposed method. Furthermore, it can be observed that feature selection makes the method more efficient and effective.								2	0	0	0	2	0916-8508		WOS:000273190700045	
J	Samaniego, Luis; Schulz, Karsten								Supervised Classification of Agricultural Land Cover Using a Modified k-NN Technique (MNN) and Landsat Remote Sensing Imagery								REMOTE SENSING			1	4			875	895		10.3390/rs1040875			DEC 2009	2009	Nearest neighbor techniques are commonly used in remote sensing, pattern recognition and statistics to classify objects into a predefined number of categories based on a given set of predictors. These techniques are especially useful for highly nonlinear relationship between the variables. In most studies the distance measure is adopted a priori. In contrast we propose a general procedure to find an adaptive metric that combines a local variance reducing technique and a linear embedding of the observation space into an appropriate Euclidean space. To illustrate the application of this technique, two agricultural land cover classifications using mono-temporal and multi-temporal Landsat scenes are presented. The results of the study, compared with standard approaches used in remote sensing such as maximum likelihood (ML) or k-Nearest Neighbor (k-NN) indicate substantial improvement with regard to the overall accuracy and the cardinality of the calibration data set. Also, using MNN in a soft/fuzzy classification framework demonstrated to be a very useful tool in order to derive critical areas that need some further attention and investment concerning additional calibration data.								2	0	0	0	2	2072-4292		WOS:000208401000013	
J	Villa Medina, Joe L.; Boque, Ricard; Ferre, Joan								Bagged k-nearest neighbours classification with uncertainty in the variables								ANALYTICA CHIMICA ACTA			646	1-2			62	68		10.1016/j.aca.2009.05.016			JUL 30 2009	2009	An analytical result should be expressed as x +/- U, where x is the experimental result obtained for a given variable and U is its uncertainty. This uncertainty is rarely taken into account in supervised classification. In this paper, we propose to include the information about the uncertainty of the experimental results to compute the reliability of classification. The method combines k-nearest neighbours (M) with a nested bootstrap scheme, in which a new bootstrap training set is generated using the classical bootstrap in the first level (B times) and a new bootstrap method, called U-bootstrap, in the second level (D times). Two bootstraps are used to reduce the effect of sampling in the first level and the effect of the uncertainty in the second one. These B x D new training bootstrap sets are used to compute the reliability of classification for an unknown object using kNN. The object is classified into the class with the highest reliability. In this method, unlike the classical kNN and Probabilistic Bagged k-nearest neighbours (PBkNN), the reliability of classification changes (increases or decreases) when the uncertainty is increased. These changes depend on the position of the unknown object with respect to the training objects. For the benchmark Wine dataset, we found similar values of classification error rate (CER) than for kNN (5.57%), but lower than Probabilistic Bagged k-nearest neighbours using Hamamoto's bootstrap (7.96%) or Efron's bootstrap (8.97%). (C) 2009 Elsevier B.V. All rights reserved.								2	2	1	0	4	0003-2670		WOS:000267525000008	
J	Wang, Liwei; Sugiyama, Masashi; Yang, Cheng; Hatano, Kohei; Feng, Jufu								Theory and Algorithm for Learning with Dissimilarity Functions								NEURAL COMPUTATION			21	5			1459	1484		10.1162/neco.2008.08-06-805			MAY 2009	2009	We study the problem of classification when only a dissimilarity function between objects is accessible. That is, data samples are represented not by feature vectors but in terms of their pairwise dissimilarities. We establish sufficient conditions for dissimilarity functions to allow building accurate classifiers. The theory immediately suggests a learning paradigm: construct an ensemble of simple classifiers, each depending on a pair of examples; then find a convex combination of them to achieve a large margin. We next develop a practical algorithm referred to as dissimilarity-based boosting (DBoost) for learning with dissimilarity functions under theoretical guidance. Experiments on a variety of databases demonstrate that the DBoost algorithm is promising for several dissimilarity measures widely used in practice.								2	0	0	0	2	0899-7667		WOS:000266106800010	
J	van den Bosch, Antal; van Erp, Marieke; Sporleder, Caroline								Making a Clean Sweep of Cultural Heritage								IEEE INTELLIGENT SYSTEMS			24	2			54	63					MAR-APR 2009	2009									2	0	0	0	2	1541-1672		WOS:000264397500011	
J	Zeng, Yong; Yang, Yupu; Zhao, Liang								Pseudo nearest neighbor rule for pattern classification								EXPERT SYSTEMS WITH APPLICATIONS			36	2			3587	3595		10.1016/j.eswa.2008.02.003			MAR 2009	2009	In this paper, we propose a new pseudo nearest neighbor classification rule (PNNR). It is different from the previous nearest neighbor rule (NNR), this new rule utilizes the distance weighted local learning in each class to get a new nearest neighbor of the unlabeled pattern-pseudo nearest neighbor (PNN), and then assigns the label associated with the PNN for the unlabeled pattern using the NNR. The proposed PNNR is compared with the k-NNR, distance weighted k-NNR, and the local mean-based nonparametric classification [Mitani, Y., & Hamamoto, Y. (2006). A local mean-based nonparametric classifier. Pattern Recognition Letters, 27, 1151-1159] in terms of the classification accuracy oil the unknown patterns. Experimental results confirm the validity of this new classification rule even in practical situations. (C) 2008 Elsevier Ltd. All rights reserved.								2	0	0	0	2	0957-4174		WOS:000262178100105	
J	Lozano, Angelica; Manfredi, Giuseppe; Nieddu, Luciano								An algorithm for the recognition of levels of congestion in road traffic problems								MATHEMATICS AND COMPUTERS IN SIMULATION			79	6			1926	1934		10.1016/j.matcom.2007.06.008			FEB 2009	2009	Detection and recognition of the level of congestion at an intersection is a very important problem and a valuable source of information in traffic management. Although it is just one of all the aspects that make up a traffic management system, it seems to be a crucial point for gathering information. In this paper, we present a technique based on a k-means clustering algorithm for classification, which has been already successfully used in a number of pattern recognition problems, namely: as an algorithm for face recognition problems and in a number of medical diagnosis problems and it compares very well with the state of the art techniques. (C) 2007 IMACS. Published by Elsevier B.V. All rights reserved.				6th Pan-American Workshop on Applied and Computational Mathematics	JUL 23-28, 2006	Third PanAmer Adv Studies Inst, Computat Sci & Engn; USA Natl Sci Fdn; DOE	Oaxaca, MEXICO	2	1	0	0	3	0378-4754		WOS:000264093700011	
J	Nassiri-Mofakham, Faria; Nematbakhsh, Mohammad Ali; Baraani-Dastjerdi, Ahmad; Ghasem-Aghaee, Nasser								Electronic promotion to new customers using mkNN learning								INFORMATION SCIENCES			179	3			248	266		10.1016/j.ins.2008.09.019			JAN 16 2009	2009	In recent years, several techniques have been proposed to model electronic promotions for existing customers. However, these techniques are not applicable for new customers with no previous profile or behavior data. This study models promotions to new customers in an electronic marketplace. We introduce a multi-valued k-Nearest Neighbor (mkNN) learning capability for modeling promotions to new customers. In this modified learning algorithm, instead of a single product category, the seller sends the new customer a promotion on a variable set of In categories (where m is a variable) with the highest rank of desirability among the most similar previous customers. Previous studies consider sellers' profits in promotion and marketing models. In addition to the sellers' profits, three important factors annoyance of customers, sellers' reputations, and customers' anonymity - are considered in this study. Without considering the customer's profile, we minimize unrelated and disliked offers to reduce the customer's annoyance and elevate the seller's reputation. The promotion models are evaluated in two separate experiments on populations with different degrees of optimism: (1) with fixed number of customers; and (2) in a fixed period of time. The evaluation is based on the parameters of customer population size and behavior as well as time interval. seller payoff, seller reputation, and the number of promotions canceled by the customers. The simulation results demonstrate that the proposed mkNN-based promotion strategies are moderately efficient with respect to all parameters for providing services in a large population. In addition, purchasing preferences of past customers, which are based on periodic promotions that a seller sends to customers, can generate future rapidly expanding demands in the market. By using these approaches, an advertising company can send acceptable promotions to customers without having specific profile information. (c) 2008 Elsevier Inc. All rights reserved.								2	0	0	0	2	0020-0255		WOS:000263708600004	
S	Caises, Yoel; Gonzalez, Antonio; Leyva, Enrique; Perez, Raul				Leyva, Enrique/H-5244-2011; Gonzalez Munoz, Antonio/C-2427-2012	Gonzalez Munoz, Antonio/0000-0001-8889-7593	Corchado, E; Yin, H		SCIS: Combining Instance Selection Methods to Increase Their Effectiveness over a Wide Range of Domains								INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING, PROCEEDINGS	Lecture Notes in Computer Science		5788				17	24					2009	2009	Instance selection is a feasible strategy to solve the problem of dealing with large databases in inductive learning. There are several proposals in this area, but none of them consistently outperforms the others over it wide range of domains. In this paper(1) we present a set of measures to characterize the databases, as well as a new algorithm that uses these measures and, depending on the data characteristics, it applies the method or combination of methods expected to produce the best results. This approach was evaluated over 20 databases and with six different learning paradigms. The results have been compared with those achieved by five well-known state-of-the-art methods.				10th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL 2009)	SEP 23-26, 2009	Junta Castilla Leon; Univ Burgos; Diputac Burgos; Ayuntamiento Burgos; GCI; CSA; FAE; FEC	Burgos, SPAIN	2	0	0	0	2	0302-9743	978-3-642-04393-2	WOS:000274188700003	
B	Chuang, Li-Yeh; Wu, Kuo-Chuan; Yang, Cheng-Hong			IEEE					A Hybrid Feature Selection Method Using Gene Expression Data								2009 9TH IEEE INTERNATIONAL CONFERENCE ON BIOINFORMATICS AND BIOENGINEERING							100	106		10.1109/BIBE.2009.24			2009	2009	In this paper, correlation-based feature selection (CFS) and the Taguchi-genetic algorithm (TGA) method were combined in a hybrid method, and the K-nearest neighbor (KNN) method with leave-one-out cross-validation (LOOCV) served as a classifier for eleven classification profiles. With the help of this classifier classification accuracy were calculated. Experimental results show that this method effectively simplifies features selection by reducing the total number of features needed. The proposed method obtained the highest classification accuracy in five out of the six gene expression data set test problems when compared to other classification methods from the literature.				9th IEEE International Conference on BioInformatics and BioEngineering	JUN 22-24, 2009	IEEE	Taichung, TAIWAN	2	0	0	0	2		978-1-4244-4294-2	WOS:000277202300014	
S	Garcia-Borroto, Milton; Villuendas-Rey, Yenny; Ariel Carrasco-Ochoa, Jesus; Fco. Martinez-Trinidad, Jose						BayroCorrochano, E; Eklundh, JO		Finding Small Consistent Subset for the Nearest Neighbor Classifier Based on Support Graphs								PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS, COMPUTER VISION, AND APPLICATIONS, PROCEEDINGS	Lecture Notes in Computer Science		5856				465	472					2009	2009	Finding a minimal subset of objects that correctly classify the training set for the nearest neighbors classifier has been an active research area in Pattern Recognition and Machine Learning communities for decades. Although finding the Minimal Consistent Subset is not feasible in many real applications, several authors have proposed methods to find small consistent subsets. In this paper, we introduce a novel algorithm for this task, based on support graphs. Experiments over a wide range of repository databases show that our algorithm finds consistent subsets with lower cardinality than traditional methods.				14th Iberoamerican Congress on Pattern Recognition	NOV 15-18, 2009	Mexican Assoc Comp Vis, Neurocomp & Robot; Int Assoc Pattern Recognit; Cuban Assoc Pattern Recognit; Chilean Assoc Pattern Recognit; Brizilian Comp Soc Special Interest Grp; Spanish Assoc Pattern Recognit; Portuguese Assoc Pattern Recognit; CINVESTAV; IEEE GRSS; CoecytJal; INTEL Educ; Gobierno Municipal, Direcc Turismo Guadalajara; Oficina Vistantes & Convenciones Guadalajara	Guadalajara, MEXICO	2	0	0	0	2	0302-9743	978-3-642-10267-7	WOS:000279629500054	
S	Lee, Yen-Hsien; Tsao, Wan-Jung; Chu, Tsai-Hsin						Weinhardt, C; Luckner, S; Stober, J		Use of Ontology to Support Concept-Based Text Categorization								DESIGNING E-BUSINESS SYSTEMS	Lecture Notes in Business Information Processing		22				201	213					2009	2009	Huge volumes of worldwide accessible information have led to the tool necessity for better handling of massive information to overcome the conventional manual method. Thus, automated text categorization technique serves to Support a more effective document organization management. Fundamentally. conventional text categorization techniques concentrate on the analysis of document contents and and measure the similarity based on the overlap among the features Of unlabeled documents and that of pre-classified documents. However, Such feature-based approach will be confront with the problems of word mismatch and word ambiguity. To lessen these problems, this study proposes an ontology-based text categorization technique. It employs the specific domain ontology to enable documents to be classified in accordance to their range of relevant concepts. The effectiveness of the proposed technique is measured and compared with its benchmark technique. The evaluation results Suggest Our proposed technique is more effective than the benchmarks.				7th Workshop on e-Business (WeB 2008)	DEC 13, 2008	AIS SIGeBIZ; Karlsruhe Inst Technol; Natl Sun Yat Sen Univ; Univ Illinois, Ctr IT & eBusiness Manage; IESEG Sch Manage	Univ Karlsruhe, Inst Informat Syst & Manage, Paris, FRANCE	2	0	0	0	2	1865-1348	978-3-642-01255-6	WOS:000268378000017	
S	Leite, Pedro; Teixeira, Joao M.; Farias, Thiago; Teichrieb, Veronica; Kelner, Judith			IEEE					Massively Parallel Nearest Neighbor Queries for Dynamic Point Clouds on the GPU								PROCEEDINGS OF THE 21ST INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE AND HIGH PERFORMANCE COMPUTING	International Symposium on Computer Architecture and High Performance Computing						19	25		10.1109/SBAC-PAD.2009.18			2009	2009	We introduce a parallel algorithm to solve approximate and exact nearest neighbor queries on the GPU, exploiting its massively parallel processing power. Both data structure construction and nearest neighbor queries are performed on the GPU, avoiding memory copies from system memory to device memory. This algorithm achieves real-time performance, enabling its usage in dynamic scenarios, by minimizing the sorting comparisons needed for a large K value. The underlying data structure for spatial subdivision handles 3D points and is based on grid spatial hashing. Users can specify the grid size interactively. Comparisons were done with other nearest neighbor algorithms implemented on both CPU and GPU. Our approach clearly surpasses CPU implementations regarding processing time, while it presents a competitive solution to GPU ones. Real-time results were obtained with ANN searches (K = 10) for data sets up to 163K points and the potential of our algorithm is demonstrated through a point-based rendering application.				21st International Symposium on Computer Architecture and High Performance Computing	OCT 28-31, 2009	Brazilian Comp Soc; IEEE Comp Soc; Tech Comm Comp Architecture; Scalable Comp; IFIP; Brazilian Govt Agcy; CAPES; FAPESP	Sao Paulo, BRAZIL	2	0	0	0	2	1550-6533	978-0-7695-3857-0	WOS:000274804600003	
J	Liou, Sing-Wu; Wang, Chia-Ming; Huang, Yin-Fu								Integrative Discovery of Multifaceted Sequence Patterns by Frame-Relayed Search and Hybrid PSO-ANN								JOURNAL OF UNIVERSAL COMPUTER SCIENCE			15	4			742	764					2009	2009	For de novo pattern mining in genomic sequences, the main issues are constructing pattern definition model (PDM) and mining sequence patterns (MSP). The representations of PDMs and the discovery of patterns are functionally dependent; the performances thus depend on the adopted PDMs. The popular PDMs provide only descriptive patterns; they lack multifaceted considerations. Many of existing MSP methods are tied up with the exclusively devised PDMs, and the specialized and sophisticated models make the mined results hard to be reused. In this research, an integrative pattern mining system is proposed, which consists of a computation-oriented PDM (CO-PDM) and general-purpose MSP (GP-MSP) methods. The CO-PDM defines four computational concerns (CCs) as facets of MSP: expression (E), location (L), range (R) and weight (W), which are integrated into a frame-relayed pattern model (FRPM). The GP-MSP develops a frame-relayed search strategy to resolve the ELR-CCs firstly, with the aids of critical-parameter automating (CPA) procedure; and then the W-CC is determined by hybridizing particle swarm optimization (PSO) and artificial neural network (ANN). The proposed FRPM and GP-MSP had been implemented and applied to 22,448 human introns; from the results, all the well-known patterns were recovered and some new ones were also discovered. Furthermore, the effectiveness of identified patterns were verified by a two-layered k-nearest neighbor (k-NN) classifier; the average precision and recall are 0.88 and 0.92, respectively. By the case study, the integrative PDM-MSP system is believed to be effective and reliable; it is optimistic the proposed CO-PDM and GP-MSP are both widely applicable and reusable for mining sequence patterns in the eukaryotic protein-coding genes.				2nd KES International Symposium on Agent and Multi-Agent Systems	MAR 26-28, 2008	Inha Univ, Sch Comp & Informat Engn; KES Int; KES Focus Grp Agent & Multi Agent Syst	Incheon, SOUTH KOREA	2	0	2	0	2	0948-695X		WOS:000269280700004	
J	Vanderlooy, Stijn; Sprinkhuizen-Kuyper, Ida G.; Smirnov, Evgueni N.; van den Herik, H. Jaap				Sprinkhuizen-Kuyper, Ida/E-2829-2010	Sprinkhuizen-Kuyper, Ida/0000-0003-0273-9354			The ROC isometrics approach to construct reliable classifiers								INTELLIGENT DATA ANALYSIS			13	1			3	37		10.3233/IDA-2009-0354			2009	2009	We address the problem of applying machine-learning classifiers in domains where incorrect classifications have severe consequences. In these domains we propose to apply classifiers only when their performance can be defined by the domain expert prior to classification. The classifiers so obtained are called reliable classifiers. In the article we present three main contributions. First, we establish the effect on an ROC curve when ambiguous instances are left unclassified. Second, we propose the ROC isometrics approach to tune and transform a classifier in such a way that it becomes reliable. Third, we provide an empirical evaluation of the approach. From our analysis and experimental evaluation we may conclude that the ROC isometrics approach is an effective and efficient approach to construct reliable classifiers. In addition, a discussion about related work clearly shows the benefits of the approach when compared with existing approaches that also have the option to leave ambiguous instances unclassified.								2	1	0	0	3	1088-467X		WOS:000265627000001	
S	Vo, Nhat; Moran, Bill; Challa, Subhash						Yu, W; He, HB; Zhang, N		Nonnegative-Least-Square Classifier for Face Recognition								ADVANCES IN NEURAL NETWORKS - ISNN 2009, PT 3, PROCEEDINGS	Lecture Notes in Computer Science		5553				449	456					2009	2009	In this paper, we propose a novel classification method, based on Nonnegative-Least-Square, (NNLS) algorithm, for face, recognition. Different from traditional classifiers, in our classifier, we consider each new sample (face) as a nonnegative linear combination of training samples (faces). By forcing the nonnegative constraint on linear coefficients, we obtain the nonnegative sparse representation that automatically discriminates between those classes present in the training set, Experimental results show the promising aspects of new classifier when comparing with the most popular classifiers such as Nearest Neighborhood (NN), Nearest Centroid (NC), and Nearest, Subspace (NS) in terms of recognition accuracy, efficiency, and numerical stability. Eigenfaces Fisherfaces, and Laplacianfaces are performed on Yale and ORL databases as feature extraction in these experiments				6th International Symposium on Neural Networks	MAY 26-29, 2009	Huazhong Univ Sci & Technol; Chinese Univ Hong Kong; Natl Nat Sci Fdn; IEEE Wuhan Sect; IEEE Computat Intel Soc; Int Neural Network Soc	Wuhan, PEOPLES R CHINA	2	0	0	0	2	0302-9743	978-3-642-01512-0	WOS:000268029200049	
J	Furao, Shen; Hasegawa, Osamu								A fast nearest neighbor classifier based on self-organizing incremental neural network								NEURAL NETWORKS			21	10			1537	1547		10.1016/j.neunet.2008.07.001			DEC 2008	2008	A fast prototype-based nearest neighbor classifier is introduced. The proposed Adjusted SOINN Classifier (ASC) is based on SOINN (self-organizing incremental neural network), it automatically learns the number of prototypes needed to determine the decision boundary, and learns new information without destroying old learned information. It is robust to noisy training data, and it realizes very fast classification. In the experiment, we use some artificial datasets and real-world datasets to illustrate ASC. We also compare ASC with other prototype-based classifiers with regard to its classification error, compression ratio, and speed up ratio. The results show that ASC has the best performance and it is a very efficient classifier. (C) 2008 Elsevier Ltd. All rights reserved.								2	1	0	0	3	0893-6080		WOS:000261926100015	
J	Villa, Joe Luis; Boque, Ricard; Ferre, Joan								Calculation of the probability of correct classification in probabilistic bagged k-Nearest Neighbours								CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS			94	1			51	59		10.1016/j.chemolab.2008.06.007			NOV 15 2008	2008	This paper presents a new method for computing the probability of correct classification for the k-Nearest Neighbours (kNN) method. The method uses bootstrap to provide the posterior probability which a new object is classified with. This is a measure of the reliability of the classification: it increases as the test object is closer to the training objects of a given class and is more sensitive to the position of the test object in the calibration space than the classical measure of posterior probability in kNN. This reliability of the classification is also used to derive a new rule for classification. (C) 2008 Elsevier B.V. All rights reserved.								2	0	1	0	2	0169-7439		WOS:000263443400006	
J	Ghosh, Anil K.								Kernel discriminant analysis using case-specific smoothing parameters								IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			38	5			1413	1418		10.1109/TSMCB.2008.925754			OCT 2008	2008	In kernel discriminant analysis, one common practice is to use a fixed level of smoothing (estimated from training data) for classifying all unlabeled observations. But, in classification, a good choice of smoothing parameters also depends on the observation to be classified. Therefore, instead of using a fixed level of smoothing over the entire measurement space, it may be more useful to estimate the smoothing parameters depending on that specific observation. Here, we propose a simple method for this case-specific smoothing. Some benchmark data sets are analyzed to illustrate the performance of the proposed method.								2	0	0	0	2	1083-4419		WOS:000259191900017	
J	Cho, Kwang-Hwi; Lee, Julian								Protein structure prediction using a hybrid energy function and an exact enumeration								JOURNAL OF THE KOREAN PHYSICAL SOCIETY			53	2			873	879					AUG 2008	2008	We develop a protein structure prediction method that utilizes fragment assembly and a hybrid energy function. In a fragment assembly method, the local structure of the backbone is obtained from a structural database by using similarity of sequence features, in contrast to a pure physics-based method in which all dihedral angles are allowed to vary continuously. Since the conformational space for the backbone is finite, we generate all possible conformations and vary only the side-chain dihedral angles for each of them. The conformations are scored using a hybrid energy function, where all the backbone atoms are described explicitly, but the side chain is modeled as a few interaction centers. We perform a test prediction on four proteins, 112y, 1e01, 1bdd and 1bk2, to demonstrate the feasibility of protein structure prediction based on exact enumeration.								2	0	1	0	2	0374-4884		WOS:000258481300072	
J	Labrador, Boris								Strong pointwise consistency of the k(T)-occupation time density estimator								STATISTICS & PROBABILITY LETTERS			78	9			1128	1137		10.1016/j.spl.2007.11.010			JUL 15 2008	2008	In this paper, we study the k(T)-occupation time density estimator as an extension of the k-nearest neighbor estimator in continuous time. The rates of strong pointwise convergence for a-mixing and bounded processes in both optimal (when i.i.d. rates of density estimation are reached) and superoptimal cases (when parametric rates are reached) are established. (c) 2007 Elsevier B.V. All fights reserved.								2	0	0	0	2	0167-7152		WOS:000256845300011	
J	Wu, Ke; Lu, Bao-Liang; Utiyama, Masao; Isahara, Hitoshi								An empirical comparison of min-max-modular k-NN with different voting methods to large-scale text categorization								SOFT COMPUTING			12	7			647	655		10.1007/s00500-007-0242-3			MAY 2008	2008	Text categorization refers to the task of assigning the pre-defined classes to text documents based on their content. k-NN algorithm is one of top performing classifiers on text data. However, there is little research work on the use of different voting methods over text data. Also, when a huge number of training data is available online, the response speed slows down, since a test document has to obtain the distance with each training data. On the other hand, min-max-modular k-NN (M-3-k-NN) has been applied to large-scale text categorization. M-3-k-NN achieves a good performance and has faster response speed in a parallel computing environment. In this paper, we investigate five different voting methods for k-NN and M-3-k-NN. The experimental results and analysis show that the Gaussian voting method can achieve the best performance among all voting methods for both k-NN and M-3-k-NN. In addition, M-3-k-NN uses less k-value to achieve the better performance than k-NN, and thus is faster than k-NN in a parallel computing environment.				4th International Symposium on Neural Networks (ISNN 2007)	JUN 03-07, 2007	Natl Nat Sci Fdn China; KC Wong Educ Fdn; SE Univ China; Chinese Univ Hong Kong; Univ Illinois, Chicago	Nanjing, PEOPLES R CHINA	2	1	0	0	3	1432-7643		WOS:000253351900006	
B	Bo, Shukui; Ding, Lin; Jing, Yongju						Li, D; Deng, G		On combining region-growing with non-parametric clustering for color image segmentation								CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS							715	719					2008	2008	Region-based and clustering-based techniques are two of the most important segmentation methods, and both of them have their advantages and disadvantages. In this paper, we present a color image segmentation method combining region-growing with non-parametric clustering technique. First, a bottom-up region-merging technique is used to yield an intermediate result. This procedure takes into account simultaneously the spectral properties of pixels as well as their spatial information, which is not fully utilized in clustering technique. Second, a clustering technique based on mean shift algorithm is used to cluster similar image objects in the intermediate result. In the mean shift procedure, we adopt adaptive bandwidths instead of a single one over the entire feature space. The two steps of image segmentation are performed in an unsupervised way. The validity of the proposed method is verified on various color images.				1st International Congress on Image and Signal Processing	MAY 27-30, 2008	Tianjin Univ Technol	Sanya, PEOPLES R CHINA	2	0	0	0	2		978-0-7695-3119-9	WOS:000258872900143	
B	Chong, Rachel Mabanag; Tanaka, Toshihisa			IEEE Computer Society					Image Extrema Analysis and Blur Detection with Identification								SITIS 2008: 4TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY AND INTERNET BASED SYSTEMS, PROCEEDINGS							320	326		10.1109/SITIS.2008.38			2008	2008	In real image processing applications, images may be blurred or not. When blur is present, the type and degree of degradation vary from one image to another. The process of restoring these images are usually computationally demanding so that there is a need to first detect blurs. If an image is not blurred then it need not undergo the restoration process. In this work, a novel algorithm that simultaneously detects and identifies blurs, is proposed. This method is based on the analysis of extrema values in an image. The extrema histograms are first constructed then analyzed in order to extract feature values. The distinctness of these values in the presence of blur is used. It is computationally, simple and fast thereby making it suitable for preprocessing especially in practical imaging applications. Experimental results on natural images and its synthetically blurred versions show the validity of the proposed method.				4th International Conference on Signal Image Technology and Internet Bases Systems	NOV 30-DEC 03, 2008	IEEE; IEEE Comp Soc; Univ Gunadarma; Univ Bourgogne; ACM SIGAPP	Bali, INDONESIA	2	0	0	0	2		978-0-7695-3493-0	WOS:000263157200043	
S	Denoeux, Thierry						Yager, RR; Liu, L		A k-Nearest Neighbor Classification Rule Based on Dempster-Shafer Theory								CLASSIC WORKS OF THE DEMPSTER-SHAFER THEORY OF BELIEF FUNCTIONS	Studies in Fuzziness and Soft Computing		219				737	760			10.1007/978-3-540-44792-4		2008	2008	In this paper, the problem of classifying an unseen pattern on the basis of its nearest neighbors in a recorded data set is addressed from the point of view of Dempster-Shafer theory. Each neighbor of a sample to be classified is considered as an item of evidence that supports certain hypotheses regarding the class membership of that pattern. The degree of support is defined as a function of the distance between the two vectors. The evidence of the k nearest neighbors is then pooled by means of Dempster's rule of combination. This approach provides a global treatment of such issues as ambiguity and distance rejection, and imperfect knowledge regarding the class membership of training patterns. The effectiveness of this classification scheme as compared to the voting and distance-weighted k-NN procedures is demonstrated using several sets of simulated and real-world data.								2	1	0	0	3	1434-9922	978-3-540-25381-5	WOS:000266783600029	
S	Luo, Huaien; Sudibyo, Yuliansa; Miller, Lance D.; Karuturi, R. Krishna Murthy						Chetty, M; Ngom, A; Ahmad, S		Weighted Top Score Pair Method for Gene Selection and Classification								PATTERN RECOGNITION IN BIOINFORMATICS, PROCEEDINGS	LECTURE NOTES IN BIOINFORMATICS		5265				323	333					2008	2008	Gene selection and expression profiles classification are important for diagnosing the disease using microarray technology and revealing the underlying biological processes. This paper proposes a weighted top scoring pair (WTSP) method which is a generalization of the current top scoring pair (TSP) method. By considering the proportions of samples from different classes, the WTSP method aims to minimize the error or misclassification rate. Results from several experimental microarray data have shown the improved performance of classification using the WTSP method.				3rd IAPR International Conference on Pattern Recognition in Bioinformatics	OCT 15-17, 2008	IAPR	Melbourne, AUSTRALIA	2	0	2	0	2	0302-9743	978-3-540-88434-7	WOS:000260634000028	
S	Nguyen, Nam; Guo, Yunsong						Daelemans, W; Goethals, B; Morik, K		Metric Learning: A Support Vector Approach					II			MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES, PART II, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		5212				125	136					2008	2008	In this paper, we address the metric learning problem utilizing a margin-based approach. Our metric learning problem is formulated as a quadratic semi-definite programming problem (QSDP) with local neighborhood constraints, which is based on the Support Vector Machine (SVM) framework. The local neighborhood constraints ensure that examples of the same class are separated from examples of different classes by a margin. In addition to providing an efficient algorithm to solve the metric learning problem, extensive experiments on various data sets show that our algorithm is able to produce a new distance metric to improve the performance of the classical K-nearest neighbor (KNN) algorithm on the classification task. Our performance is always competitive and often significantly better than other state-of-the-art metric learning algorithms.				European Conference on Principles of Data Mining and Knowledge Discovery	SEP 15-19, 2008	Univ Antwerp; Computat Linguist Flanders; Google; hp; VADIS; COGNOS; European Off Aerosp; SPSS; textkernel; Data Mining & Knowledge Discovery; IBM; Machine Learning	Antwerp, BELGIUM	2	0	0	0	2	0302-9743	978-3-540-87480-5	WOS:000260075900009	
S	Potamitis, Ilyas; Ganchev, Todor						Tsihrintzis, GA; Jain, LC		Generalized Recognition of Sound Events: Approaches and Applications								MULTIMEDIA SERVICES IN INTELLIGENT ENVIRONMENTS: ADVANCED TOOLS AND METHODOLOGIES	Studies in Computational Intelligence		120				41	79			10.1007/978-3-540-78502-6		2008	2008	This chapter surveys the contemporary approaches of automatic sound recognition and discusses the benefits stemming from real-world applications of this technology. We identify the common aspects and subtle differences among these diverse application areas and review state-of-the-art systems. hi this context; we project that; there is much space for knowledge transfer between the different subfields of sound classification; which seem to evolve independently while achieving different states of maturity. Particular emphasis is given to lessons learned from the speech recognition paradigm, which together with speaker recognition were among the first applications of sound classification that; reached the status of launching commercial products at a large climax. Special attention is paid to new emerging applications such as environmental monitoring and bioacoustic identification and applications to music which have already started altering our everyday life as we, once knew it.								2	0	0	0	2	1860-949X	978-3-540-78491-3	WOS:000266772900003	
S	Saha, Sriparna; Bandyopadhyay, Sanghamitra; Singh, Chingtham Tejbanta			IEEE					A New Line Symmetry Distance Based Pattern Classifier								2008 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-8	IEEE International Joint Conference on Neural Networks (IJCNN)						1425	1432		10.1109/IJCNN.2008.4633984			2008	2008	In this paper, a new line symmetry based classifier (LSC) is proposed to deal with pattern classification problems. In order to measure total amount of line symmetry of a particular point in a class, a new definition of line symmetry based distance is also proposed in this paper. The proposed line symmetry based classifier (LSC) utilizes this new definition of tine symmetry distance for classifying an unknown test sample. LSC assigns an unknown test sample pattern to that class with respect to whose major axis it is most symmetric. The mean of all the training patterns belonging to that particular class is taken as the prototype of that class. Thus training constitutes of computing only the class prototypes and the major axes of those classes. Kd-tree based nearest neighbor search is used for reducing complexity of line symmetry distance computation. The performance of LSC is demonstrated in classifying twelve artificial and real-life data sets of varying complexities. Experimental results show that LSC achieves, in general, higher classification accuracy compared to kappa-NN classifier. Results indicate that the proposed novel line symmetry based classifier is well-suited for classifying data sets having symmetrical classes, irrespective of any convexity, overlap and size. Statistical analysis, ANOVA is also performed to compare the performance of these classifications techniques.				International Joint Conference on Neural Networks	JUN 01-08, 2008	IEEE	Hong Kong, PEOPLES R CHINA	2	0	0	0	2	1098-7576	978-1-4244-1820-6	WOS:000263827200227	
S	Yang, Cheng-San; Chuang, Li-Yeh; li, Jung-Chike; Yang, Cheng-Hong			IEEE					A Novel BPSO Approach for Gene Selection and Classification of Microarray Data								2008 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-8	IEEE International Joint Conference on Neural Networks (IJCNN)						2147	2152					2008	2008	Selecting relevant genes from microarray data poses a huge challenge due to the high-dimensionality of the features multi-class categories and a relatively small sample size. The main task of the classification process is to decrease the microarray data dimensionality. In order to analyze microarray data, an optimal subset of features (genes) which adequately represents the original set of features has to be found. In this study, we used a novel binary particle swarm optimization (NBPSO) algorithm to perform microarray data selection and classification. The K-nearest neighbor (K-NN) method with leave-one-out cross-validation (LOOCV) served as a classifier. The experimental results showed that the proposed method not only effectively reduced the number of gene expression levels, but also achieved lower classification error rates.				International Joint Conference on Neural Networks	JUN 01-08, 2008	IEEE	Hong Kong, PEOPLES R CHINA	2	0	0	0	2	1098-7576	978-1-4244-1820-6	WOS:000263827201089	
J	Zhu, Mu; Chen, Wenhong; Hirdes, John P.; Stolee, Paul								The K-nearest neighbor algorithm predicted rehabilitation potential better than current Clinical Assessment Protocol								JOURNAL OF CLINICAL EPIDEMIOLOGY			60	10			1015	1021		10.1016/j.jclinepi.2007.06.001			OCT 2007	2007	Objective: There may be great potential for using computer-modeling techniques and machine-learning algorithms in clinical decision making, if these can be shown to produce results superior to clinical protocols currently in use. We aim to explore the potential to use an automatic, data-driven, machine-learning algorithm in clinical decision making.Study Design and Setting: Using a database containing comprehensive health assessment information (the interRAI-HC) on home care clients (N = 24,724) from eight community-care regions in Ontario, Canada, we compare the performance of the K-nearest neighbor (KNN) algorithm and a Clinical Assessment Protocol (the "ADLCAP") currently used to predict rehabilitation potential. For our purposes, we define a patient as having rehabilitation potential if the patient had functional improvement or remained at home over a follow-up period of approximately 1 year.Results: The KNN algorithm has a lower false positive rate in all but one of the eight regions in the sample, and lower false negative rates in all regions. Compared using likelihood ratio statistics, KNN is uniformly more informative than the ADLCAP.Conclusion: This article illustrates the potential for a machine-learning algorithm to enhance clinical decision making. (C) 2007 Elsevier Inc. All rights reserved.								2	0	1	0	2	0895-4356		WOS:000249956500005	
J	Alfo, Marco; Farcomeni, Alessio; Tardella, Luca								Robust semiparametric mixing for detecting differentially expressed genes in microarray experiments								COMPUTATIONAL STATISTICS & DATA ANALYSIS			51	11			5253	5265		10.1016/j.csda.2006.08.009			JUL 15 2007	2007	An important goal of microarray studies is the detection of genes that show significant changes in observed expressions when two or more classes of biological samples such as treatment and control are compared. Using the c-fold rule, a gene is declared to be differentially expressed if its average expression level varies by more than a constant factor c between treatment and control (typically c = 2). While often used, however, this simple rule is not completely convincing. By modeling this filter, a binary variable is defined at the gene x experiment level, allowing for a more powerful treatment of the corresponding information. A gene-specific random term is introduced to control for both dependence among genes and variability with respect to the c-fold threshold. Inference is carried out via a two-level finite mixture model under a likelihood approach. Then, parameter estimates are also derived using the counting distribution under a Bayesian nonparametric approach which allows to keep under control some error rate of erroneous discoveries. The effectiveness of both proposed approaches is illustrated through a large-scale simulation study and a well known benchmark data set. (C) 2006 Elsevier B.V. All rights reserved.				Conference on Computational Statistics and Data Analysis	OCT 28-31, 2005	IASC-CSDA	Limassol, CYPRUS	2	0	2	0	2	0167-9473		WOS:000248207700006	
S	Duin, Robert P. W.; Pekalska, Elzbieta						Duch, W; Mandziuk, J		The Science of Pattern Recognition. Achievements and Perspectives								CHALLENGES FOR COMPUTATIONAL INTELLIGENCE	Studies in Computational Intelligence		63				221	259			10.1007/978-3-540-71984-7		2007	2007	Automatic pattern recognition is usually considered as an engineering area which focusses on the development and evaluation of systems that imitate or assist humans in their ability of recognizing patterns. It may, however, also be considered as a science that studies the faculty of human beings (and possibly other biological systems) to discover, distinguish, characterize patterns in their environment and accordingly identify new observations. The engineering approach to pattern recognition is in this view an attempt to build systems that simulate this phenomenon. By doing that, scientific understanding is gained of what is needed in order to recognize patterns, in general.Like in any science understanding can be built from different, sometimes even opposite viewpoints. We will therefore introduce the main approaches to the science of pattern recognition as two dichotomies of complementary scenarios. They give rise to four different schools, roughly defined under the terms of expert systems, neural networks, structural pattern recognition and statistical pattern recognition. We will briefly describe what has been achieved by these schools, what is common and what is specific, which limitations are encountered and which perspectives arise for the future. Finally, we will focus on the challenges facing pattern recognition in the decennia to come. They mainly deal with weaker assumptions of the models to make the corresponding procedures for learning and recognition wider applicable. In addition, new formalisms need to be developed.								2	2	0	0	4	1860-949X	978-3-540-71983-0	WOS:000271240200011	
S	Elghazel, Haytham; Kheddouci, Hamamache; Deslandres, Veronique; Dussauchoy, Alain						Corruble, V; Takeda, M; Suzuki, E		A partially dynamic clustering algorithm for data insertion and removal								Discovery Science, Proceedings	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		4755				78	90					2007	2007	We consider the problem of dynamic clustering which has been addressed in many contexts and applications including dynamic information retrieval, Web documents classification, etc. The goal is to efficiently maintain homogenous and well-separated clusters as new data are inserted or existing data are removed. We propose a framework called dynamic b-coloring clustering based solely on pairwise dissimilarities among all pairs of data and on cluster dominance. In experiments on benchmark data sets, we show improvements in the performance of clustering solution in terms of quality and computational complexity.				10th International Conference on Discovery Science	OCT 01-04, 2007	AF Off Sci Res; Asian Off Aerosp Res & Dev; Grad Sch Informat Sci	Sendai, JAPAN	2	0	0	0	2	0302-9743	978-3-540-75487-9	WOS:000250717900009	
S	Hwang, Seongseob; Cho, Sungzoon						Liu, DR; Fei, SM; Hou, ZG; Zhang, HG; Sun, CY		Clustering-based reference set reduction for k-nearest neighbor								Advances in Neural Networks - ISNN 2007, Pt 2, Proceedings	LECTURE NOTES IN COMPUTER SCIENCE		4492				880	888					2007	2007	Response Modeling is concerned with computing the likelihood of a customer to respond to a marketing campaign. A major problem encountered in response modeling is huge volume of data or patterns. The k-NN has been used in various classification problems for its simplicity and ease of implementation. However, it has not been applied to problems for which fast classification is needed since the classification time rapidly increases as the size of reference set increases. In this paper, we propose a clustering-based preprocessing step in order to reduce the size of reference set. The experimental results showed an 85% decrease in classification time without a loss of accuracy.				4th International Symposium on Neural Networks (ISNN 2007)	JUN 03-07, 2007	Natl Nat Sci Fdn China; KC Wong Educ Fdn; SE Univ China; Chinese Univ Hong Kong; Univ Illinois, Chicago	Nanjing, PEOPLES R CHINA	2	0	0	0	2	0302-9743	978-3-540-72392-9	WOS:000247831300105	
S	Smith, J. E.; Tahir, M. A.						Yin, H; Tino, P; Corchado, E; Byrne, W; Yao, X		Stop wasting time: On predicting the success or failure of learning for industrial applications								INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING - IDEAL 2007	LECTURE NOTES IN COMPUTER SCIENCE		4881				673	683					2007	2007	The successful application of machine learning techniques to industrial problems places various demands on the collaborators. The system designers must possess appropriate analytical skills and technical expertise, and the management of the industrial or commercial partner must be sufficiently convinced of the potential benefits that they are prepared to invest in money and equipment. Vitally, the collaboration also requires a significant investment in time from the end-users in order to provide training data from which the system can (hopefully) learn. This poses a problem if the developed Machine Learning system is not sufficiently accurate, as the users and management; may view their input as wasted effort, and lose faith with the process. In this paper we investigate techniques for making early predictions of the error rate achievable after further interactions. In particular we show how decomposing the error in different components can lead to useful predictors of achievable accuracy, but; that this is dependent on the choice of an appropriate sampling methodology.				8th International Conference on Intelligent Data Engineering and Automated Learning	DEC 16-19, 2007		Birmingham, ENGLAND	2	0	0	0	2	0302-9743	978-3-540-77225-5	WOS:000252394900068	
S	Stiglic, Gregor; Kokol, Peter				Stiglic, Gregor/E-5286-2011		Kokol, P; Podgorelec, V; MiceticTurk, D; Zorman, M; Verlic, M		Effectiveness of rotation forest in meta-learning based gene expression classification								Twentieth IEEE International Symposium on Computer-Based Medical Systems, Proceedings	COMPUTER-BASED MEDICAL SYSTEMS : PROCEEDINGS OF THE ANNUAL IEEE SYMPOSIUM						243	248		10.1109/CBMS.2007.43			2007	2007	A lot of research has been done in the field of assembling classifiers in ensembles and on the other hand selecting the most appropriate single classifiers for a given problem which was solved by ineta-learning techniques. This paper presents application of recently proposed ensemble of classifiers called Rotation Forest to Grading ineta-learning scheme, where it is used as one of the base classifiers and meta-level classifier at the same time. Our proposed Grading variation is compared to four widely used classifiers on 14 datasets from the domain of gene expression classification problems. Experimental evaluations show that using Rotation Forest at meta-level most significantly impacts the accuracy of Grading scheme and confirms that it can be used for estimation of classifiers regions of strong and weak classification.				20th IEEE International Symposium on Computer-Based Medical Systems	JUN 20-22, 2007	IEEE Comp Soc TCCM; Fac Elect Engn & Comp Sci; Fac Hlth Sci	Maribor, SLOVENIA	2	0	2	0	2	1063-7125	978-0-7695-2905-9	WOS:000248094800041	
B	Wedge, David C.; Kell, Douglas B.; Gaskell, Simon J.; Lau, King Wai; Hubbard, Simon J.; Eyers, Claire			ACM	Hubbard, Simon/B-9006-2009; Kell, Douglas/E-8318-2011				Peptide Detectability following ESI Mass Spectrometry: Prediction using Genetic Programming								GECCO 2007: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2							2219	2225					2007	2007	The accurate quantification of proteins is important in several areas of cell biology, biotechnology and medicine. Both relative and absolute quantification of proteins is often determined following mass spectrometric analysis of one or more of their constituent peptides. However, in order for quantification to be successful, it is important that the experimenter knows which peptides are readily detectable under the mass spectrometric conditions used for analysis. In this paper, genetic programming is used to develop a function which predicts the delectability of peptides from their calculated physico-chemical properties. Classification is carried out in two stages: the selection of a good classifier using the AUROC objective function and the setting of an appropriate threshold. This allows the user to select the balance point between conflicting priorities in an intuitive way. The success of this method is found to be highly dependent on the initial selection of input parameters. The use of brood recombination and a modified version of the multi-objective FOCUS method are also investigated. While neither has a significant effect on predictive accuracy, the use of the FOCUS method leads to considerably more compact Solutions.				Annual Conference of Genetic and Evolutionary Computation Conference	JUL 07-11, 2007	ACM	London, ENGLAND	2	0	2	0	2		978-1-59593-697-4	WOS:000268226900397	
J	Park, Seong-Bae								Combining rule-based learning and memory-based learning for automatic word spacing in simple message service								APPLIED SOFT COMPUTING			6	4			406	416		10.1016/j.asoc.2005.11.006			AUG 2006	2006	Short message service (SMS) is a widely used service in modern mobile phones that allows users to send or receive short text messages. Current SMS, however, has two problems of inconvenient input and short message length. These problems can be resolved if a phone has an ability of automatic word spacing. This is because users need not put spaces in sending messages and longer messages are possible as they contain no space. Thus, automatic word spacing will be a very useful tool for SMS, if it can be commercially served. The practical issues of implementing it on the devices such as mobile phones are small memory and low computing power of the devices. To tackle these problems, this paper proposes a combined model of rule-based learning and memory-based learning. According to the experimental results, the model shows higher accuracy than rule-based learning or memory-based learning alone. In addition, the generated rules are so small and simple that the proposed model is appropriate for small memory devices. (C) 2005 Elsevier B.V. All rights reserved.								2	0	0	0	2	1568-4946		WOS:000242169800008	
J	Chien, BC; Lin, JY; Yang, WP								A classification tree based on discriminant functions								JOURNAL OF INFORMATION SCIENCE AND ENGINEERING			22	3			573	594					MAY 2006	2006	The classification problem is an important topic in knowledge discovery and machine learning. Traditional classification tree methods and their improvements have been discussed widely. This work proposes a new approach to construct decision trees based on discriminant functions which are learned using genetic programming. A discriminant function is a mathematical function for classifying data into a specific class. To learn discriminant functions effectively and efficiently, a distance-based fitness function for genetic programming is designed. After the set of discriminant functions for all classes is generated. a classifier is created as a binary decision tree with the Z-value measure to resolve the problem of ambiguity among discriminant functions. Several popular datasets from the UCI Repository were selected to illustrate the effectiveness of the proposed classifiers by comparing with previous methods. The results show that the proposed classification tree demonstrates high accuracy on the selected datasets.				Workshop on Computer Vision, Graphics and Image Processing (CVGIP)	2004		TAIWAN	2	0	0	0	2	1016-2364		WOS:000237907900008	
J	Davidov, Dmitry; Markovitch, Shaul								Multiple-goal heuristic search								JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH			26				417	451					2006	2006	This paper presents a new framework for anytime heuristic search where the task is to achieve as many goals as possible within the allocated resources. We show the inadequacy of traditional distance-estimation heuristics for tasks of this type and present alternative heuristics that are more appropriate for multiple-goal search. In particular, we introduce the marginal-utility heuristic, which estimates the cost and the benefit of exploring a subtree below a search node. We developed two methods for online learning of the marginal-utility heuristic. One is based on local similarity of the partial marginal utility of sibling nodes, and the other generalizes marginal-utility over the state feature space. We apply our adaptive and non-adaptive multiple-goal search algorithms to several problems, including focused crawling, and show their superiority over existing methods.								2	0	0	0	2	1076-9757		WOS:000240024500002	
S	Naiman, Daniel Q.						Kimmel, A; Oluver, B		Random data set generation to support microarray analysis								DNA MICROARRAYS, PART B: DATABASES AND STATISTICS	Methods in Enzymology		411				312	325		10.1016/S0076-6879(06)11016-2			2006	2006	As microarray analyses become increasingly routine, involving the simultaneous investigation of huge numbers of genes, researchers can easily search for and uncover what appear to be promising patterns in their data. In such circumstances tools are needed to help decide the extent to which these patterns are meaningful or can be explained by chance alone. The purpose of this chapter is to describe examples of the use of microarray analysis for inferential purposes and how validation of inference is addressed by Monte-Carlo techniques, which essentially amounts to investigation of statistical methods on synthetic or random data sets.								2	0	0	0	2	0076-6879	978-0-12-182816-5	WOS:000244506300016	
S	Pham, Tuan D.; Ran, Dat T.						Gabrys, B; Howlett, RJ; Jain, LC		Image classification by fusion for high-content cell-cycle screening								KNOWLEDGE-BASED INTELLIGENT INFORMATION AND ENGINEERING SYSTEMS, PT 1, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		4251				524	531					2006	2006	We present a fuzzy fusion approach for combining cell-phase identification results obtained from multiple classifiers. This approach can improve the classification rates and allows the task of high-content cell-cycle screening more effective for biomedical research in the study of structures and functions of cells and molecules. Conventionally such study requires the processing and analysis of huge amounts of image data, and manual image analysis is very time consuming, thus costly, and also potentially inaccurate and poorly reproducible. The proposed method has been used to combine the results from three classifiers, and the combined result is superior to any of the results obtained from a single classifier.				10th International Conference on Knowledge-Based and Intelligent Information and Engineering Systems	OCT 09-11, 2006		Bournemouth, ENGLAND	2	0	0	0	2	0302-9743	3-540-46535-9	WOS:000242122000064	
J	Sobanski, T; Modrak, I; Nitsch, K; Licznerski, BW								Application of sensor dynamic response analysis to improve the accuracy of odour-measuring systems								MEASUREMENT SCIENCE & TECHNOLOGY			17	1			1	5		10.1088/0957-0233/17/1/001			JAN 2006	2006	A system consisting of a matrix of three semiconductor gas sensors was applied to the classification of different orange juices. The sensor matrix responses were sampled in short time intervals. Such responses were processed by discrete wavelet transform (DWT) together with the k-nearest neighbour (kNN) classification algorithm or by the probabilistic neural network (PNN). The obtained results show that both types of signal processing (DWT + kNN and PNN) applied provide very good class separation for time response analysis, while in the case of the static response analysis the correct classification coefficients are much lower. It is shown that the analysis of the sensor's time response can be an efficient way of increasing both the accuracy level and the immunity to external noise in e-nose systems. The possibility of reducing the number of sensors without decreasing the system performance is also demonstrated. Additional experiments have shown that for both processing methods, the results obtained with the dynamic response of a single sensor were better than those reached with the three-sensor array measured in static conditions.				8th Optoelectronic and Electronic Sensors Conference	JUN 27-30, 2004		Wroclaw, POLAND	2	0	1	0	2	0957-0233		WOS:000234953600002	
S	Xiao, Song-Shan; Wu, Yong-Xing						Tan, J		Rotation-invariant texture analysis using radon and Fourier transforms					1-2			4th International Symposium on Instrumentation Science and Technology (ISIST' 2006)	JOURNAL OF PHYSICS CONFERENCE SERIES		48				1459	1464		10.1088/1742-6596/48/1/268			2006	2006	Texture analysis is a basic issue in image processing and computer vision, and how to attain the Rotation-invariant texture characterization is a key problem. This paper proposes a rotation-invariant texture analysis technique using Radon and Fourier transform. This method uses Radon transform to convert rotation to translation, then utilizes the Fourier transform and takes the modules of the Fourier transform of these functions to make the translation invariant. A k-nearest-neighbor rule is employed to classify textures images. The proposed method is robust to additive white noise as a result of summing pixel values to generate projections in the Radon transform step. To test and evaluate the method, several different kinds of experiments are employed. Experiments results show the feasibility of the proposed method and its robustness to additive white noise.				4th International Symposium on Instrumentation Science and Technology (ISIST '2006)	AUG 08-12, 2006	ICMI; NSFC; CSM; CIS; HIT; IC-CSM	Harbin, PEOPLES R CHINA	2	0	1	0	2	1742-6588	*****************	WOS:000250567100267	
J	Yin, TK								A characteristic-point-based fuzzy inference classifier by a closeness matrix								IEEE TRANSACTIONS ON FUZZY SYSTEMS			13	5			673	687		10.1109/TFUZZ.2005.856558			OCT 2005	2005	In this paper, a characteristic-point-based fuzzy inference classifier (CPFIC) is proposed to perform two-class classification. Through fuzzy interpolation, a subset of classified samples can be taken as representatives of all samples. They are called characteristic points (CPs). A closeness matrix representing the closeness of two samples in a same class is proposed in selecting CPs. By solving a number of constrained minimizations, the CPFIC is systematically built. Experiments were conducted on four classification problems with known Bayes errors, two benchmark classification problems, and a real-world application used in our research. The CPFIC performs well in accuracy evaluations in all the seven experiments. The summarizing abilities from the CPs into the linguistic descriptions of the fuzzy rule bases were also demonstrated in these examples.								2	0	0	0	2	1063-6706		WOS:000232604600009	
J	Pati, PB; Ramakrishnan, AG								OCR in Indian scripts: A survey								IETE TECHNICAL REVIEW			22	3			217	227					MAY-JUN 2005	2005	India is a multi-lingual country. A significantly large number of scripts are used to represent these languages. A desire of vision researchers is to develop an integrated Optical Character Recognition (OCR) system which will be able to process all such scripts. Such a development, if objectified, will not only enable faster flow of information across the country, but also have a profound impact on its scientific and economic development. Courageous endeavors have been successfully made towards the development of a system capable of recognizing machine-printed, or hand-written characters and/or numerals. However, most Indian scripts do not have an integrated OCR system. Further the development of a unified system which is capable of processing all Indian scripts is still a dream. This article presents a survey of the current literature on the development of OCR's in Indian scripts. Reviewing the basics of and the motivation towards the development of OCR system, the article analyzes the various methodologies employed in general purpose pattern recognition system. A critical analysis of the work towards OCR system in Indian languages, with pointers towards possible future work is also presented.								2	0	0	0	2	0256-4602		WOS:000233297700007	
S	Pham, TD						Singh, S; Singh, M; Apte, C; Perner, P		An optimally weighted fuzzy k-NN algorithm								PATTERN RECOGNITION AND DATA MINING, PT 1, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		3686				239	247					2005	2005	The nearest neighbor rule is a non-parametric approach and has been widely used for pattern classification. The k-nearest neighbor (k-NN) rule assigns crisp memberships of samples to class labels; whereas the fuzzy k-NN neighbor rule replaces crisp memberships with fuzzy memberships. The membership assignment by the conventional fuzzy k-NN algorithm has a disadvantage in that it depends on the choice of some distance function, which is not based on any principle of optimality. To overcome this problem, we introduce in this paper a computational scheme for determining optimal weights to be combined with different fuzzy membership grades for classification by the fuzzy k-NN approach. We show how this optimally weighted fuzzy k-NN algorithm can be effectively applied for the classification of microarray-based cancer data.				3rd International Conference on Advances in Pattern Recognition	AUG 22-25, 2005		Bath, ENGLAND	2	0	1	0	2	0302-9743	3-540-28757-4	WOS:000232247900026	
S	Wang, C; Chen, YQ						Wang, L; Chen, K; Ong, YS		Improving Nearest Neighbor classification with simulated gravitational collapse								ADVANCES IN NATURAL COMPUTATION, PT 3, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		3612				845	854					2005	2005	The performance of the Nearest Neighbor classifier drops significantly with the increase of the overlapping of the distribution of different classes. To overcome this drawback, we propose to simulate the physical process of gravitational collapse to trim the boundaries of the distribution of each class to reduce overlapping. The proposed simulated gravitational collapse(SGC) algorithm is tested on 7 real-world data sets. Experimental results show that the nearest prototype classifier based on SGC outperforms conventional NN and k-NN classifiers.				1st International Conference on Natural Computation (ICNC 2005)	AUG 27-29, 2005	Xiangtang Univ; IEEE Circuits & Syst Soc; IEEE Computat Intelligence Soc; IEEE Control Syst Soc; Int Neural Network Soc; European Neural Network Soc; Chinese Assoc Artificial Intelligence; Japanese Neural Network Soc; Int Fuzzy Syst Assoc; Asia Pacific Neural Network Assembly; Fuzzy Math & Syst Assoc China; Hunan Comp Federat	Changsha, PEOPLES R CHINA	2	0	0	0	2	0302-9743	3-540-28320-X	WOS:000232246700104	
S	Woon, FL; Knight, B; Petridis, M; Patel, M						MunozAvila, H; Ricci, F		CBE-conveyor: A case-based reasoning system to assist engineers in designing conveyor systems								CASE-BASED REASONING RESEARCH AND DEVELOPMENT, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		3620				640	651					2005	2005	In this paper, we address the use of CBR in collaboration with numerical engineering models. This collaborative combination has a particular application in engineering domains where numerical models are used. We term this domain "Case Based Engineering" (CBE), and present the general architecture of a CBE system. We define and discuss the general characteristics of CBE and the special problems which arise. These are: the handling of engineering constraints of both continuous and nominal kind; interpolation over both continuous and nominal variables, and conformability for interpolation. In order to illustrate the utility of the method proposed, and to provide practical examples of the general theory, the paper describes a practical application of the CBE architecture, known as CBE-CONVEYOR, which has been implemented by the authors. Pneumatic conveying is an important transportation technology in the solid bulks conveying industry. One of the major industry concerns is the attrition of powders and granules during pneumatic conveying. To minimize the fraction of particles during pneumatic conveying, engineers want to know what design parameters they should use in building a conveyor system. To do this, engineers often run simulations in a repetitive manner to find appropriate input parameters. CBE-Conveyor is shown to speed up conventional methods for searching for solutions, and to solve problems directly that would otherwise require considerable intervention from the engineer.				6th International Conference on Case-Based Reasoning	AUG 23-26, 2005	Kaidara Software; Empolis; Naval Res Lab; PricewaterhouseCooper; AAAI	Chicago, IL	2	0	0	0	2	0302-9743	3-540-28174-6	WOS:000233274900048	
S	Chakrabarti, A; Regev, O			ieee computer society					An optimal randomised cell probe lower bound for approximate nearest neighbour searching								45TH ANNUAL IEEE SYMPOSIUM ON FOUNDATIONS OF COMPUTER SCIENCE, PROCEEDINGS	ANNUAL IEEE SYMPOSIUM ON FOUNDATIONS OF COMPUTER SCIENCE						473	482		10.1109/FOCS.2004.12			2004	2004	We consider the approximate nearest neighbour search problem on the Hamming Cube {0, 1}(d). We show that a randomised cell probe algorithm that uses polynomial storage and word size d(O(1)) requires a worst case query time of Omega (log log d/log log log d). The approximation factor may be as loose as 2(log1-eta) (d) for any fixed eta > 0. This generalises an earlier result [5] on the deterministic complexity of the same problem and, more importantly, fills a major gap in the study of this problem since all earlier lower bounds either did not allow randomisation [5, 18] or did not allow approximation [4, 2, 15]. We also give a cell probe algorithm which proves that our lower bound is optimal.Our proof uses a lower bound on the round complexity of the related communication problem. We show, additionally, that considerations of bit complexity alone cannot prove any nontrivial cell probe lower bound for the problem. This shows that the Richness Technique [20] used in a lot of recent research around this problem would not have helped here.Our proof is based on information theoretic techniques for communication complexity, a theme that has been prominent in recent research [6, 1, 23, 14]. In particular we make heavy use of the round elimination and message compression ideas in the recent work of Sen [23] and Jain, Radhakrishnan, and Sen [14], and also introduce a new technique which we call message switching.				45th Annual IEEE Symposium on Foundations of Computer Science	OCT 17-19, 2004	IEEE Comp Soc, Tech Soc Fdn Comp	Rome, ITALY	2	0	0	0	2	0272-5428	0-7695-2228-9	WOS:000225221700049	
S	Moon, J; Shon, T; Seo, J; Kim, J; Seo, J						Aykanat, C; Dayar, T; Korpeoglu, I		An approach for spam E-mail detection with support vector machine and n-gram indexing								COMPUTER AND INFORMATION SCIENCES - ISCIS 2004, PROCEEDINGS	Lecture Notes in Computer Science		3280				351	362					2004	2004	Many solutions have been deployed to prevent harmful effects from spam mail. Typical methods are either pattern matching using the keyword or method using the probability such as naive Bayesian method. In this paper, we proposed a classification method of spam mail from normal mail using support vector machine, which has excellent performance in binary pattern classification problems. Especially, the proposed method efficiently practices a learning procedure with a word dictionary by the n-gram. In the conclusion, we showed our proposed method being superior to others in the aspect of comparing performance.				19th International Symposium on Computer and Information Sciences (ISCIS 2004)	OCT 27-29, 2004	Bilkent Univ, Dept Comp Engn; Inst Elect & Elect Engineers Turkey Sect; Working Grp, Int Federat Informat Proc; Sci & Tech Res Council Turkey	Kemer Antalya, TURKEY	2	0	0	0	2	0302-9743	3-540-23526-4	WOS:000225096700036	
S	Skowron, A; Wojna, A						Tsumoto, S; Slowinski, R; Komorowski, J; GrzymalaBusse, JW		K nearest neighbor classification with local induction of the simple value difference metric								ROUGH SETS AND CURRENT TRENDS IN COMPUTING	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		3066				229	234					2004	2004	The classical k nearest neighbor (k-nn) classification assumes that a fixed global metric is defined and searching for nearest neighbors is always based on this global metric. In the paper we present a model with local induction of a metric. Any test object induces a local metric from the neighborhood of this object and selects k nearest neighbors according to this locally induced metric. To induce both the global and the local metric we use the weighted Simple Value Difference Metric (SVDM). The experimental results show that the proposed classification model with local induction of a metric reduces classification error up to several times in comparison to the classical k-nn method.				4th International Conference on Routh Sets and Current Trends in Computing	JUN 01-05, 2004		Uppsala Univ, Uppsala, SWEDEN	2	0	0	0	2	0302-9743	3-540-22117-4	WOS:000222323600027	
S	Sucahyo, YG; Gopalan, RP						Webb, GI; Yu, X		Building a more accurate classifier based on strong frequent patterns								AI 2004: ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		3339				1036	1042					2004	2004	The classification problem in data mining is to discover models from training data for classifying unknown instances. Associative classification builds the classifier rules using association rules and it is more accurate compared to previous methods. In this paper, a new method named CSFP that builds a classifier from strong frequent patterns without the need to generate association rules is presented. We address the rare item problem by using a partitioning method. Rules generated are stored using a compact data structure named CP-Tree and a series of pruning methods are employed to discard weak frequent patterns. Experimental results show that our classifier is more accurate than previous associative classification methods as well as other state-of-the-art non-associative classifiers.				17th Annual Australian Conference on Artificial Intelligence	DEC 04-06, 2004		Cent Queensland Univ, Cairns, AUSTRALIA	2	0	0	0	2	0302-9743	3-540-24059-4	WOS:000226133600098	
J	Sebban, M; Nock, R; Lallich, S								Stopping criterion for boosting-based data reduction techniques: From binary to multiclass problems								JOURNAL OF MACHINE LEARNING RESEARCH			3	4-5			863	885		10.1162/jmlr.2003.3.4-5.863			MAY 15 2003	2003	So far, boosting has been used to improve the quality of moderately accurate learning algorithms, by weighting and combining many of their weak hypotheses into a final classifier with theoretically high accuracy. In a recent work (Sebban, Nock and Lallich, 2001), we have attempted to adapt boosting properties to data reduction techniques. In this particular context, the objective was not only to improve the success rate, but also to reduce the time and space complexities due to the storage requirements of some costly learning algorithms, such as nearest-neighbor classifiers. In that framework, each weak hypothesis, which is usually built and weighted from the learning set, is replaced by a single learning instance. The weight given by boosting defines in that case the relevance of the instance, and a statistical test allows one to decide whether it can be discarded without damaging further classification tasks. In Sebban, Nock and Lallich (2001), we addressed problems with two classes. It is the aim of the present paper to relax the class constraint, and extend our contribution to multiclass problems. Beyond data reduction, experimental results are also provided on twenty-three datasets, showing the benefits that our boosting-derived weighting rule brings to weighted nearest neighbor classifiers.				18th International Conference on Machine Learning	JUN 28-JUL 01, 2001		WILLIAMSTOWN, MASSACHUSETTS	2	0	0	0	2	1532-4435		WOS:000184926200011	
S	Barandela, R; Sanchez, JS; Garcia, V; Ferri, FJ						Perales, FJ		Learning from imbalanced sets through resampling and weighting								PATTERN RECOGNITION AND IMAGE ANALYSIS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		2652				80	88					2003	2003	The problem of imbalanced training sets in supervised pattern recognition methods is receiving growing attention. Imbalanced training sample means that one class is represented by a large number of examples while the other is represented by only a few. It has been observed that this situation, which arises in several practical situations, may produce an important deterioration of the classification accuracy, in particular with patterns belonging to the less represented classes. In the present paper, we introduce a new approach to design an instance-based classifier in such imbalanced environments.				1st Iberian Conference on Pattern Recognition and Image Analysis	JUN 04-06, 2003	MCyT; Int Assoc Pattern Recognit; European Union; Conselleria Innovacio Energia	UNIV ILLES BALEARS, DEPT CIENCIES MATH & INFORMAT, MALLORCA, SPAIN	2	0	0	0	2	0302-9743	3-540-40217-9	WOS:000184832300010	
S	Bremner, D; Demaine, E; Erickson, J; Iacono, J; Langerman, S; Morin, P; Toussaint, G						Dehne, F; Sack, JR; Smid, M		Output-sensitive algorithms for computing nearest-neighbour decision boundaries								ALGORITHMS AND DATA STRUCTURES, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		2748				451	461					2003	2003	Given a set R of red points and a set, B of blue points, the nearest-neighbour decision rule classifies a new point q as red (respectively, blue) if the closest point to q in R U B comes from R (respectively, B). This rule implicitly partitions space into a red set and a blue set that are separated by a red-blue decision boundary. In this paper we develop output-sensitive algorithms for computing this decision boundary for point sets on the line and in R-2. Both algorithms run in time O(n log k), where k is the number of points that contribute to the decision boundary. This running time is the best possible when parameterizing with respect to n and k.				8th International Workshop on Algorithms and Data Structures (WADS 2003)	JUL 30-AUG 01, 2003		CARLETON UNIV, OTTAWA, CANADA	2	0	0	0	2	0302-9743	3-540-40545-3	WOS:000185605300039	
S	Jankowski, N			IEEE; IEEE					Discrete feature weighting & selection algorithm								PROCEEDINGS OF THE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS 2003, VOLS 1-4	IEEE International Joint Conference on Neural Networks (IJCNN)						636	641					2003	2003	A new method of feature weighting, useful also for feature selection has been described. It is quite efficient and gives quite accurate results. In general weighting algorithm may be used with any kind of learning algorithm. The weighting algorithm with k-nearest neighbors model was used to estimate the optimal feature base for a given distance measure. Results obtained with this algorithm clearly show its superior performance in several benchmark tests.				International Joint Conference on Neural Networks	JUL 20-24, 2003	Int Neural Network Soc; IEEE Neural Networks Soc	PORTLAND, OR	2	0	0	0	2	1098-7576	0-7803-7898-9	WOS:000184903300116	
S	Timar, G; Balya, D; Szatmari, I; Rekeczky, C			IEEE; IEEE					Feature guided visual attention with topographic array processing and neural network-based classification								PROCEEDINGS OF THE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS 2003, VOLS 1-4	IEEE International Joint Conference on Neural Networks (IJCNN)						1492	1496					2003	2003	Biological systems are constantly engulfed in sensory input that must be processed. Attention has evolved to cut down on the magnitude of the input and enable the agent to analyze the most important parts of the information. This is especially true for the visual system where the appropriate field of view and scale must be determined. Our system receives a video flow with considerably higher resolution than the resolution of the cellular neural net based visual microprocessor that computes the topographic features of the input. This process requires a dynamic positioning of the processing window in the video flow. We have developed a fast attention and selection algorithm that allows the system to choose the field of view and scale (zoom) level for the next frame based on the features computed from the current frame and the output of the ART or NNC-based classifiers. The algorithmic framework and the hardware architecture of the system are presented along with experimental chip results for several video flows recorded in flying vehicles.				International Joint Conference on Neural Networks	JUL 20-24, 2003	Int Neural Network Soc; IEEE Neural Networks Soc	PORTLAND, OR	2	0	0	0	2	1098-7576	0-7803-7898-9	WOS:000184903300272	
S	Vogt, P						Banzhaf, W; Christaller, T; Dittrich, P; Kim, JT; Ziegler, J		THSim v3.2: The talking heads simulation tool								ADVANCES IN ARTIFICIAL LIFE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		2801				535	544					2003	2003	The field of language evolution and computation may benefit from using efficient and robust simulation tools that are based on widely exploited principles within the field. The tool presented in this paper is one that could fulfil such needs. The paper presents an overview of the tool - THSim v3.2 - and discusses some research questions that can be investigated with it.				7th European Conference on Artifical Life	SEP 14-17, 2003	Deutsch Forsch Gemeinsch; European Network Excellence Evolut Computat; Univ Dortmund e V, Gesell Freunde; Gesell Informat e V; Univ Dortmund; Westfal Ind Museum	DORTMUND, GERMANY	2	0	1	0	2	0302-9743	3-540-20057-6	WOS:000187009400057	
J	Lazzerini, B; Marcelloni, F								Classification based on neural similarity								ELECTRONICS LETTERS			38	15			810	812		10.1049/el:20020549			JUL 18 2002	2002	Following the approach of extracting similarity metrics directly from labelled data, a standard back-propagation neural network is adopted to determine a degree of similarity between pairs of input points. The similarity computed by the network is then used to guide a k-NN classifier, which associates a label with an unknown pattern based on the k most similar points. Experimental results on both synthetic and real-world data sets show that the similarity-based k-NN rule outperforms the Euclidean distance-based k-NN rule.								2	0	0	0	2	0013-5194		WOS:000177339100031	
S	Domeniconi, C; Gunopulos, D						Dietterich, TG; Becker, S; Ghahramani, Z		Adaptive nearest neighbor classification using support vector machines								ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 14, VOLS 1 AND 2	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS		14				665	672					2002	2002	The nearest neighbor technique is a simple and appealing method to address classification problems. It relies on the assumption of locally constant class conditional probabilities. This assumption becomes invalid in high dimensions with a finite number of examples due to the curse of dimensionality. We propose a technique that computes a locally flexible metric by means of Support Vector Machines (SVMs). The maximum margin boundary found by the SVM is used to determine the most discriminant direction over the query's neighborhood. Such direction provides a local weighting scheme for input features. We present experimental evidence of classification performance improvement over the SVM algorithm alone and over a variety of adaptive learning schemes, by using both simulated and real data sets.				15th Annual Conference on Neural Information Processing Systems (NIPS)	DEC 03-08, 2001		VANCOUVER, CANADA	2	0	0	0	2	1049-5258	0-262-04208-8	WOS:000180520100083	
S	Paredes, R; Vidal, E; Keysers, D						Kasturi, R; Laurendeau, D; Suen, C		An evaluation of the WPE algorithm using tangent distance.								16TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITON, VOL IV, PROCEEDINGS	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION						48	51					2002	2002	Weighting Prototype Editing (WPE) is a novel approach to edit a given set of prototypes so that the resulting set can outperform the original one in terms of the Nearest Neighbor (NN) classification accuracy This technique is applied in this work along with tin interesting dissimilarity measure between pixel maps, known as Tangent Distance (TD). Experiments on the USPS handwriting digits benchmark corpus are presented, with results showing the capability of the WPE to improve the already good results based on TD NN classification.				16th International Conference on Pattern Recognition (ICPR)	AUG 11-15, 2002	Int Assoc Pattern Recognit; Canadian Image Processing & Pattern Recognit Soc; Ctr Rech Informat Montreal; Matrox Imaging; Ind & Commerce Quebec; Rech, Sci & Technol Quebec; Microsoft Res; Bell; Lab Vis & Syst Numer; Comp Vis & Syst Lab; Ctr Pattern Recognit & Machine Intelligence; Ctr Etudes Reconnaissance Formes & Intelligence Artificielle; Scribers; Coreco Imaging; Precarn	QUEBEC CITY, CANADA	2	0	1	0	2	1051-4651	0-7695-1695-X	WOS:000177887500011	
B	Zanardelli, WG; Strangas, EG; Khalil, HK; Miller, JM			IEEE; IEEE					Comparison of wavelet-based methods for the prognosis of failures in electric motors								IEEE POWER ELECTRONICS IN TRANSPORATION							61	67					2002	2002	The ability to give a prognosis for failure of a system is an invaluable tool and can be applied to electric motors. In this paper, three wavelet based methods have been developed that achieve this goal. Wavelet and filter bank theory, the nearest neighbor rule, and linear discriminant functions are reviewed. A framework for the development of a fault detection and classification algorithm based on the coefficients calculated from the discrete wavelet transform and using clustering is described. An experimental setup based on RT-Linux is described and results from testing are presented, verifying the analysis.				7th Workshop on Power Electronics in Transportation	OCT 24-25, 2002	IEEE Power Electr Soc; IEEE SE Michigan Sect; Soc Automot Engineers; IEEE Vehicular Technol Soc	AUBURN HILL, MI	2	0	0	0	2		0-7803-7492-4	WOS:000181178100009	
J	Holst, M; Irle, A								Nearest neighbor classification with dependent training sequences								ANNALS OF STATISTICS			29	5			1424	1442					OCT 2001	2001	The asymptotic classification risk for nearest neighbor procedures is well understood in the case of i.i.d. training sequences. In this article, we generalize these results to a class of dependent models including hidden Markov models. In the case where the observed patterns have Lebesgue densities, the asymptotic risk takes the same expression as in the i.i.d. case. For discrete distributions, we show that the asymptotic risk depends on the rule used for breaking ties of equal distances.								2	0	0	0	2	0090-5364		WOS:000173361700010	
J	Sbai, EH								Cluster analysis by adaptive rank-order filters								PATTERN RECOGNITION			34	10			2015	2027		10.1016/S0031-3203(00)00130-8			OCT 2001	2001	An adaptive filter is proposed for detecting the modes of underlying probability density function of the data. The adaptive procedure is based on the selection of an appropriate rank order according to the local measurements of the entropy of the density function. The approach requires no a priori information about the structure of the data set but it is governed by the sampling parameter. Experiments demonstrate the usefulness of the filter. (C) 2001 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.								2	0	0	0	2	0031-3203		WOS:000170417200012	
J	Pal, NR; Ghosh, S								Some classification algorithms integrating Dempster-Shafer theory of evidence with the rank nearest neighbor rules								IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART A-SYSTEMS AND HUMANS			31	1			59	66		10.1109/3468.903867			JAN 2001	2001	We propose five different ways of integrating Dempster-Shafer theory of evidence and the rank nearest neighbor classification rules with a view to exploiting the benefits of both. These algorithms have been tested on both real and synthetic data sets and compared with the k-NN, m-MRNN, and k-NNDST, which is an algorithm that also combines Dempster-Shafer theory with the le-NN rule. If different features have widely different variances then the distance-based classifier, algorithms like Ic-NN and k-NNDST may not perform weil, but in this case the proposed algorithms are expected to perform better. Our simulation results indeed reveal this. Moreover, the proposed algorithms are found to exhibit significant improvement over the m-MRNN rule.								2	1	0	0	3	1083-4427		WOS:000167063000006	
J	Ferrari, A; Borgatti, M; Guerrieri, R								A complete system for NN classification based on a VLSI array processor								PATTERN RECOGNITION			33	12			2083	2093		10.1016/S0031-3203(99)00192-2			DEC 2000	2000	This paper describes a VLSI array processor system designed and built for classification problems based on the k-nearest-neighbors approach. This architecture is suitable for different pattern recognition applications and is very efficient for high-dimensional databases. The architecture is scalable with the size of the recognition problem making the system effectively applicable to computational intensive application like on-line pattern recognition. A system prototype composed of a board with two processors, the software driver and a test application have been built and evaluated. For handwritten character recognition task the complete system shows a speed up of 260 times over a sequential algorithm running on a Sun SPARC20 workstation. (C) 2000 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.								2	0	0	0	2	0031-3203		WOS:000089473700013	
B	Frosini, G; Lazzerini, B; Marcelloni, F						Whalen, T		A modified fuzzy C-means algorithm for feature selection								PEACHFUZZ 2000 : 19TH INTERNATIONAL CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS							148	152		10.1109/NAFIPS.2000.877409			2000	2000	In this paper we propose a novel method for feature selection based on a modified fuzzy C-means algorithm with supervision (MFCMS). MFCMS adopts an appropriately modified version of the objective function used by the classic fuzzy C-means. We applied MFCMS to some real-world pattern classification benchmarks. To test the effectiveness of MFCMS as feature selector, we used the well-known k-nearest neighbor as learning algorithm. In our experiments we found that the classification performance using the set of features selected by MFCMS is better than that using all the original features. Furthermore, our approach proved to be less time-consuming than other feature selection methods.				19th International Conference of the North-American-Fuzzy-Information-Processing-Society	JUL 13-15, 2000	N Amer Fuzzy Informat Proc Soc	ATLANTA, GA	2	0	0	0	2		0-7803-6274-8	WOS:000089942800028	
J	Zheng, GL; Billings, SA								An enhanced sequential fuzzy clustering algorithm								INTERNATIONAL JOURNAL OF SYSTEMS SCIENCE			30	3			295	307		10.1080/002077299292443			MAR 1999	1999	A sequential fuzzy clustering algorithm is proposed based on a modification to the objective function used in the fuzzy competitive learning algorithm. The new learning algorithm can be used to enhance the excitation on the non-winning centroids and to reduce the excitation on the winning centroid when the fuzziness parameter is close to unit. The excitation on the winning centroid can be further reduced when the input pattern is far away from the winning centroid. An excitation-inhibition mechanism can also be introduced into the learning such that the non-winning centroids move towards the input pattern while the winning centroid moves away from the input pattern when the winning centroid is far away from the input pattern. The new algorithm overcomes the problem of underutilization of centroids found in the k-means or related clustering algorithms and in the fuzzy competitive learning algorithm when the fuzziness parameter is close to unity. The performance of the new algorithm is demonstrated on the IRIS data set.								2	0	1	0	2	0020-7721		WOS:000079041200006	
J	Gascuel, O; Bouchon-Meunier, B; Caraux, G; Gallinari, P; Guenoche, A; Guermeur, Y; Lechevallier, Y; Marsala, C; Miclet, L; Nicolas, J; Nock, R; Ramdani, M; Sebag, M; Tallur, B; Venturini, G; Vitte, P								Twelve numerical symbolic and hybrid supervised classification methods								INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			12	5			517	571		10.1142/S0218001498000336			AUG 1998	1998	Supervised classification has already been the subject of numerous studies in the fields of Statistics, Pattern Recognition and Artificial Intelligence under various appellations which include discriminant analysis, discrimination and concept learning. Many practical applications relating to this field have been developed. New methods have appeared in recent years, due to developments concerning Neural Networks and Machine Learning. These "hybrid" approaches share one common factor in that they combine symbolic and numerical aspects. The former are characterized by the representation of knowledge, the latter by the introduction of frequencies and probabilistic criteria. In the present study, we shall present a certain number of hybrid methods, conceived (or improved) by members of the SYMENU research group. These methods issue mainly from Machine Learning and from research on Classification Trees done in Statistics, and they may also be qualified as "rule-based". They shall be compared with other more classical approaches. This comparison will be based on a detailed description of each of the twelve methods envisaged, and on the results obtained concerning the "Waveform Recognition Problem" proposed by Breiman et al.,(4) which is difficult for rule based approaches.								2	0	0	0	2	0218-0014		WOS:000075814400001	
J	Huet, F; Philipp, S								Fusion of images interpreted by a new fuzzy classifier								PATTERN ANALYSIS AND APPLICATIONS			1	4			231	247		10.1007/BF01234770			1998	1998	This paper presents a global system for the fusion of images segmented by various methods and interpreted by a fuzzy classifier. A set of complementary segmentation operators is applied to the image. Each region of the segmented images is interpreted by the fuzzy classifier, through membership degrees to classes. The fuzzy classifier builds the classes automatically from examples, even in the case of complex data sets. Interpreted images are then merged by a fusion operator from the fuzzy set: theory. Several fusion operators are compared. They trust mure high membership degrees to classes, which are considered as reliability degrees. The fusion of the interpreted images improves the segmentation, and gives solutions to segmentation and interpretation evaluation.								2	0	0	0	2	1433-7541		WOS:000083707300003	
J	Ros, F; Guillaume, S; Rabatel, G; Sevila, F; Bertrand, D				Guillaume, Serge/H-2112-2011				Combining global and individual image features to characterize granular product populations								JOURNAL OF CHEMOMETRICS			11	6			483	500		10.1002/(SICI)1099-128X(199711/12)11:6<483::AID-CEM490>3.0.CO;2-8			NOV-DEC 1997	1997	The characterization of granular product populations using image analysis is a difficult problem because it often requires the extraction and combination of many different features. We propose to study in a general way these problems of granular product classification, considering the image analysis phase, the processing of the information extracted and the decision making, In this paper we focus rather on the decision system development. It is based on a hierarchical approach to the problem, in eluding a generalist system whose outputs are ambiguous (an approximative solution), connected to specialist systems trained to give non-ambiguous solutions, The inputs of the generalist system are the components of a vector containing the most important information for discriminating all the decision classes, while the inputs of the specialist systems are those which best distinguish a given class from another. This strategy enables us to overcome the multiclass aspect of the problem. It is independent of the choice of the techniques to select the pertinent information and to take the decision, This method is applied in the framework of a meal classification where three types of classifier (discriminant analysis, k nearest neighbours and multilayer neural networks) are compared. (C) 1997 John Wiley & Sons, Ltd.								2	0	0	0	2	0886-9383		WOS:A1997YJ41900002	
J	Zhao, QF; Higuchi, T								Efficient learning of NN-MLP based on individual evolutionary algorithm								NEUROCOMPUTING			13	2-4			201	215		10.1016/0925-2312(95)00088-7			OCT 1996	1996	The nearest neighbor based multilayer perceptron (NN-MLP) is a suitable model for self-organization, and has been studied by many authors in different forms. However, a large number of neurons are usually required in this kind of networks. To obtain smaller or the smallest NN-MLP, this paper introduces the concept of individual evolutionary algorithm (IEA), and proposes a new method for NN-MLP learning, There are four basic operations in the IEA: competition, gain, loss and retraining. The basic rule is: all individuals compete for surviving, winners gain more, losers lose more, and the individuals are retrained to function better than before. The learning algorithm based on the IEA is simple and suitable for parallel realization, and is able to produce the 'smallest-at-present' networks from random ones in an evolutionary manner, Its efficiency is shown by experimental results.								2	0	1	0	3	0925-2312		WOS:A1996VN05600009	
J	Tzionas, P; Thanailakis, A; Tsalides, P								A hybrid cellular automaton neural network classifier for multi-valued patterns and its VLSI implementation								INTEGRATION-THE VLSI JOURNAL			20	2			211	237		10.1016/0167-9260(95)00025-9			MAR 1996	1996	A multi-valued pattern classifier with high discrimination sensitivity and its VLSI implementation proposal on a single chip are presented in this paper. The classification scheme is based on the combination of a reconfigurable Cellular Automaton and a Neural Network architecture. A 2-D Reconfigurable Hybrid Additive Cellular Automaton (RHACA) architecture amplifies the Hamming distance between patterns, whereas a neural network architecture, implemented in digital form, assigns vectors of weighing coefficients which take into account the relative significance of the sites on the 2-D lattice. The proposed classifier is able to operate successfully even for pattern classes of small difference, or for patterns that lie on the decision boundaries between classes. If the training and processing phases are not partitioned, the proposed classification scheme is able to operate in partially exposed environments. With the proper setting of admittance levels into the classes of multi-valued patterns involved, the proposed classifier can also operate on patterns with partly missing data.The proposed multi-valued pattern classifier can be realized on a single VLSI chip with dimensions 7.73 mm x 8.14 mm = 62.96 mm(2) and the expected frequency of operation for the chip is 50 MHz.								2	0	0	0	2	0167-9260		WOS:A1996UC33000005	
J	Zhao, Q; Higuchi, T								Minimization of nearest neighbor classifiers based on individual evolutionary algorithm								PATTERN RECOGNITION LETTERS			17	2			125	131		10.1016/0167-8655(95)00102-6			FEB 8 1996	1996	This paper proposes the individual evolutionary algorithm (IEA). Using IEA, the minimum or nearly minimum nearest neighbor classifiers can be obtained iteratively by performing four operations: competition, gain, loss and retraining. The efficiency of IEA is verified by experimental results.								2	0	1	0	3	0167-8655		WOS:A1996TV87400003	
J	VAMOS, T; KOCH, P; KATONA, F								A STRATEGY OF KNOWLEDGE REPRESENTATION FOR UNCERTAIN PROBLEMS - EXPERIMENTS AND RELATIONS TO SIMILAR CONCEPTS								IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS			25	10			1371	1383		10.1109/21.464444			OCT 1995	1995	The companion paper outlined the general schemes of pattern representation of knowledge. Extensive experiments proved the feasibility of the methods, e.g., a twelve-year project in early brain developmental problems, a sociolegal project and a search for patterns in economy. All these are characterized by overwhelming soft-type knowledge, The paper presents an overview of these research efforts, discussing similarities to and differences from the pattern method.								2	0	0	0	2	0018-9472		WOS:A1995RW04500003	
J	ALPAYDIN, E; GURGEN, F				ALPAYDIN, ETHEM/E-6127-2013				COMPARISON OF KERNEL ESTIMATORS, PERCEPTRONS AND RADIAL-BASIS FUNCTIONS FOR OCR AND SPEECH CLASSIFICATION								NEURAL COMPUTING & APPLICATIONS			3	1			38	49		10.1007/BF01414175			1995	1995	We compare kernel estimators, single and multi-layered perceptrons and radial-basis functions for the problems of classification of handwritten digits and speech phonemes. By taking two different applications and employing many techniques, we report here a two-dimensional study whereby a domain-independent assessment of these learning methods can be possible. We consider a feed-forward network with one hidden layer. As examples of the local methods, we use kernel estimators like k-nearest neighbour (k-nn), Parzen windows, generalised k-nn, and Grow and Learn (Condensed Nearest Neighbour). We have also considered fuzzy k-nn due to its similarity. As distributed networks, we use linear perceptron, pairwise separating linear perceptron and multi-layer perceptrons with sigmoidal hidden units. We also tested the radial-basis function network, which is a combination of local and distributed networks. Four criteria are taken for comparison: correct classification of the test set; network size; learning time; and the operational complexity. We found that perceptrons, when the architecture is suitable, generalise better than local, memory-based kernel estimators, but require a longer training and more precise computation. Local networks are simple, learn very quickly and acceptably, but use more memory.								2	0	0	0	2	0941-0643		WOS:A1995RK32400005	
J	TURNEY, P								THEORETICAL ANALYSES OF CROSS-VALIDATION ERROR AND VOTING IN INSTANCE-BASED LEARNING								JOURNAL OF EXPERIMENTAL & THEORETICAL ARTIFICIAL INTELLIGENCE			6	4			331	360		10.1080/09528139408953793			OCT-DEC 1994	1994	This paper begins with a general theory of error in cross-validation testing of algorithms for supervised learning from examples. It is assumed that the examples are described by attribute-value pairs, where the values are symbolic. Cross-validation requires a set of training examples and a set of testing examples. The value of the attribute that is to be predicted is known to the learner in the training set, but unknown in the testing set. The theory demonstrates that cross-validation error has two components: error on the training set (inaccuracy) and sensitivity to noise (instability). This general theory is then applied to voting in instance-based learning. Given an example in the testing set, a typical instance-based learning algorithm predicts the designated attribute by voting among the k nearest neighbours (the k most similar examples) to the testing example in the training set. Voting is intended to increase the stability (resistance to noise) of instance-based learning, but a theoretical analysis shows that there are circumstances in which voting can be destabilising. The theory suggests ways to minimize cross-validation error, by insuring that voting is stable and does not adversely affect accuracy.								2	0	0	0	2	0952-813X		WOS:A1994PT79400002	
J	STAMPER, R; TODD, BS; MACPHERSON, P								CASE-BASED EXPLANATION FOR MEDICAL DIAGNOSTIC PROGRAMS, WITH AN EXAMPLE FROM GYNECOLOGY								METHODS OF INFORMATION IN MEDICINE			33	2			205	213					MAY 1994	1994	One of the most accountable methods of providing machine assistance in medical diagnosis is to retrieve and display similar previously diagnosed cases from a database. In practice, however, classifying cases according to the diagnoses of their nearest neighbours is often significantly less accurate than other statistical classifiers. In this paper the transparency of the nearest neighbours method is combined with the accuracy of another statistical method. This is achieved by using the other statistical method to define a measure of similarity between the presentations of two cases. The diagnosis of abdominal pain of suspected gynaecological origin is used as a case study to evaluate this method. Bayes' theorem, with the usual assumption of conditional independence, is used to define a metric on cases. This new metric was found to correspond as well as Hamming distance to the clinical notion of ''similarity'' between cases, while significantly increasing accuracy to that of the Bayes' method itself.								2	0	0	0	2	0026-1270		WOS:A1994NN17200009	
J	WHITE, AP								CROSS-VALIDATION OF NEAREST-NEIGHBOR DISCRIMINANT-ANALYSIS - A WARNING TO SAS USERS								JOURNAL OF STATISTICAL COMPUTATION AND SIMULATION			49	3-4			129	140		10.1080/00949659408811566			1994	1994	The SAS statistical package contains a general-purpose discriminant procedure, DISCRIM. Among the options available for this procedure are ones for performing nearest-neighbour discriminant analysis and cross-validation. Each of these works well enough when used separately but, when the two options are used together, an optimistic bias in cross-validated performance emerges. For certain parameter values, this bias can be dramatically large. The cause of the problem is analyzed mathematically for the two-class case with uniformly distributed data and demonstrated by simulation for normal data. The corresponding misbehaviour for multiple classes is also demonstrated by Monte Carlo simulation. A modification to the procedure, which would remove the bias, is proposed.								2	0	0	0	2	0094-9655		WOS:A1994PM04000001	
J	DIZENZO, S; BURGESS, N; FERRAGINA, P; GRANIERI, MN				Burgess, Neil/B-2420-2009				RECOGNITION BY CONSTRUCTIVE NEURAL ALGORITHMS								PATTERN RECOGNITION LETTERS			14	12			997	1007		10.1016/0167-8655(93)90008-2			DEC 1993	1993	The usability of the constructive neural algorithms as pattern classifiers is investigated. It is pointed out that the unboundedness of the decision regions formed by most neural recognizers leads to substantial limitations of the generalization capabilities of these nets. We specify a constructive neural recognizer that forms bounded decision regions, and report the results of this algorithm on a series of benchmark problems that resemble the usual pattern recognition problems.								2	0	0	0	2	0167-8655		WOS:A1993MQ73100008	
J	ROMANIUK, SG; HALL, LO								SC-NET - A HYBRID CONNECTIONIST, SYMBOLIC SYSTEM								INFORMATION SCIENCES			71	3			223	268		10.1016/0020-0255(93)90058-T			JUL 1993	1993	This paper describes the SC-net system that has been developed to provide expert systems capability augmented with learning in a hybrid connectionist/symbolic approach. A distributed connectionist representation of cells connected by links is used to represent symbolic knowledge. Rules may be directly encoded in the connectionist network or learned from examples. The learning method is a form of instance-based learning in which some of the individual instances in the training set are encoded by adding structure to the network and others cause modifications to biases in the network. Both continuous and nominal attributes are directly represented in the network structure. A limited form of variables in the form of attribute value bindings on the right-hand side of rules is supported. Relational comparators in the form of cell groups are also supported. Relational comparators and attribute value structures are represented by groups of connected cells in the network. The learning algorithm is presented and methods for providing generalization in an instance-based connectionist environment are presented. Empirical results are presented, which include learning in domains (fevers and gems) that contain uncertainty and the well-known iris, and soybean data sets together with a real world domain for semiconductor wafer fault diagnosis. The generalization ability of the learned network is shown to be good in several domains including iris. The system is shown to compare favorably with a nonneural instance-based learning algorithm IBL.								2	0	0	0	2	0020-0255		WOS:A1993LG80000001	
J	JANG, GS; DOWLA, F; VEMURI, V								A COMPARISON OF NEURAL-NETWORK PERFORMANCE FOR SEISMIC PHASE IDENTIFICATION								JOURNAL OF THE FRANKLIN INSTITUTE-ENGINEERING AND APPLIED MATHEMATICS			330	3			505	524		10.1016/0016-0032(93)90096-D			MAY 1993	1993	Traditional techniques of analysis and interpretation of seismic events involve a series of complex steps involving sophisticated signal processing as well as many manual tasks. Automating each of these steps is an important goal of this ongoing research. The paper discusses the use of neural networks in performing phase identification, namely the discrimination of distinct seismic waves within a seismogram. The scope is further restricted to the identification of only two of the regional principal phases, Pg and Lg, among the signals collected in the western United States. Using a database of 75 earthquakes and 75 underground nuclear explosions, the performance of several types of neural networks was compared. The performance of probabilistic neural network (PNN), radial basis function (RBF) network and learning vector quantization (LVQ) network is compared with a back-propagation network that combines the conjugate-gradient method with a weight-elimination strategy. The results indicate that the latter outperformed all other methods tested.								2	0	0	0	2	0016-0032		WOS:A1993LB38400007	
J	CASASENT, D								MULTIFUNCTIONAL HYBRID NEURAL NET								NEURAL NETWORKS			5	3			361	370		10.1016/0893-6080(92)90001-Y			1992	1992	New associative processor, optimization, and adaptive learning neural net algorithms are presented. A new symbolic correlator and production system optical neural net to handle multiple objects in the field of view is also reviewed. Attention is given to optically-generated input neuron representation spaces and to the implementation of a wide variety of neural net functions on a multifunctional hybrid optical/digital neural net system.								2	0	0	0	2	0893-6080		WOS:A1992HY50800001	
J	FARAGO, A; LINDER, T; LUGOSI, G								NEAREST NEIGHBOR SEARCH AND CLASSIFICATION IN O(1) TIME								PROBLEMS OF CONTROL AND INFORMATION THEORY-PROBLEMY UPRAVLENIYA I TEORII INFORMATSII			20	6			383	395					1991	1991	A method of finding the nearest neighbor is presented. The effectiveness of the algorithm has been shown in computer simulations. This paper gives a probabilistic analysis of the performance. The algorithm is shown to have O(1) expected asymptotic complexity, measured in the number of distance calculations for n sample points. A reduced complexity classification rule is derived which has the same error probability as that of the nearest neighbor discrimination rule.								2	0	0	0	2	0370-2529		WOS:A1991KF21200002	
J	GEYER, ALM; MOREIRA, JC; FAIGLE, JF; BRUNS, RE; CURTIUS, AJ								LOCAL AND TEMPORAL VARIATIONS IN ESSENTIAL ELEMENTS AND AGAR OF THE MARINE-ALGAE PTEROCLADIA-CAPILLACEA								HYDROBIOLOGIA			194	2			143	148		10.1007/BF00028415			APR 17 1990	1990									2	0	1	0	2	0018-8158		WOS:A1990DB76200005	
J	GOLIC, JD								ON THE RELATIONSHIP BETWEEN THE SEPARABILITY MEASURES AND THE BAYES PROBABILITY OF ERROR								IEEE TRANSACTIONS ON INFORMATION THEORY			33	5			694	701		10.1109/TIT.1987.1057349			SEP 1987	1987									2	0	0	0	2	0018-9448		WOS:A1987K769600009	
J	GOIN, JE								CLASSIFICATION BIAS OF THE K-NEAREST NEIGHBOR ALGORITHM								IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			6	3			379	381					1984	1984									2	0	0	0	2	0162-8828		WOS:A1984SR54200016	
J	NAGY, G								ADVANCES IN INFORMATION EXTRACTION TECHNIQUES								REMOTE SENSING OF ENVIRONMENT			15	2			167	175		10.1016/0034-4257(84)90044-0			1984	1984									2	0	0	0	2	0034-4257		WOS:A1984SK15200005	
J	TAKIYAMA, R								A 2-LEVEL COMMITTEE MACHINE - A REPRESENTATION AND A LEARNING PROCEDURE FOR GENERAL PIECEWISE LINEAR DISCRIMINANT FUNCTIONS								PATTERN RECOGNITION			13	3			269	274		10.1016/0031-3203(81)90104-7			1981	1981									2	0	0	0	2	0031-3203		WOS:A1981LM68000010	
J	YOUNG, TY; LIU, PS; RONDON, RJ								STATISTICAL PATTERN-CLASSIFICATION WITH BINARY VARIABLES								IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			3	2			155	163					1981	1981									2	0	0	0	2	0162-8828		WOS:A1981MN96800005	
J	RICHETIN, M; RIVES, G; NARANJO, M								THE USE OF RAPID ALGORITHM DEDUCTION IN ASCERTAINING THE K NEAREST NEIGHBORS								RAIRO-INFORMATIQUE-COMPUTER SCIENCE			14	4			369	378					1980	1980									2	0	0	0	2	0752-4072		WOS:A1980LF18500003	
J	FOWLER, HG								SEED PREDATOR RESPONSES								OECOLOGIA			41	3			361	363		10.1007/BF00377440			1979	1979									2	0	1	0	2	0029-8549		WOS:A1979HL35000011	
J	HESS, CF; BRODDA, K								OPTIMUM CHOICE OF CATEGORIES FOR THE CLASSIFICATION OF BIOMEDICAL DATA PATTERNS								METHODS OF INFORMATION IN MEDICINE			18	4			222	227					1979	1979									2	0	1	0	2	0026-1270		WOS:A1979HU04000006	
J	KITTLER, J; YOUNG, PC								DISCRIMINANT FUNCTION IMPLEMENTATION OF A MINIMUM RISK CLASSIFIER								BIOLOGICAL CYBERNETICS			18	3-4			169	179		10.1007/BF00326687			1975	1975									2	0	0	0	2	0340-1200		WOS:A1975AF61400004	
J	Li, Jing; Allinson, Nigel								Building Recognition Using Local Oriented Features								IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS			9	3			1697	1704		10.1109/TII.2013.2245910			AUG 2013	2013	Building recognition is an important task for a wide range of computer vision applications, e. g., surveillance and intelligent navigation aid. However, it is also challenging since each building can be viewed from different angles or under different lighting conditions, for example, resulting in a large variability among building images. A number of building recognition systems have been proposed in recent years. However, most of them are based on a complex feature extraction process. In this paper, we present a new building recognition model based on local oriented features with an arbitrary orientation. Although the newly proposed model is very simple, it offers a modular, computationally efficient, and effective alternative to other building recognition techniques. According to a comparison of experimental results with the state-of-the-art building recognition systems, it is shown that the newly proposed SFBR model can obtain very satisfactory recognition accuracy despite its simplicity.								1	0	0	0	1	1551-3203		WOS:000323569900051	
J	de Figueiredo, J. J. S.; Oliveira, F.; Esmi, E.; Freitas, L.; Schleicher, J.; Novais, A.; Sussner, P.; Green, S.								Automatic detection and imaging of diffraction points using pattern recognition								GEOPHYSICAL PROSPECTING			61		SI		368	379		10.1111/j.1365-2478.2012.01123.x		1	JUN 2013	2013	Hydrocarbon reservoirs are generally located beneath complex geological structures. Frequently, such areas contain seismic diffractors that carry detailed structure information in the order of the seismic wavelength. Therefore, the development of computational facilities capable of detecting diffractor points with a good resolution is desirable but has been a challenge in the area of seismic processing. In this work, we present a method for the detection of diffraction points in the common-offset-gather domain. The method applies a two-class k nearest neighbours (kNN) pattern recognition technique to amplitudes along diffraction traveltime curves to distinguish between diffractions and reflections or noise. While the method, in principle, requires knowledge of the migration velocity field, it is very robust with respect to an erroneous model. Numerical examples using synthetic seismic and field ground-penetrating-radar (GPR) data demonstrate the feasibility of the technique and show its usefulness for automatically mapping diffraction points in a seismic section. In our applications, the method was able to detect all diffractions present in the data and did not produce any false positives.								1	0	0	0	1	0016-8025		WOS:000320136500025	
J	Orsenigo, Carlotta; Vercellis, Carlo								A comparative study of nonlinear manifold learning methods for cancer microarray data classification								EXPERT SYSTEMS WITH APPLICATIONS			40	6			2189	2197		10.1016/j.eswa.2012.10.044			MAY 2013	2013	The paper presents an empirical comparison of the most prominent nonlinear manifold learning techniques for dimensionality reduction in the context of high-dimensional microarray data classification. In particular, we assessed the performance of six methods: isometric feature mapping, locally linear embedding, Laplacian eigenmaps, Hessian eigenmaps, local tangent space alignment and maximum variance unfolding. Unlike previous studies on the subject, the experimental framework adopted in this work properly extends to dimensionality reduction the supervised learning paradigm, by regarding the test set as an out-of-sample set of new points which are excluded from the manifold learning process. This in order to avoid a possible overestimate of the classification accuracy which may yield misleading comparative results. The different empirical approach requires the use of a fast and effective out-of-sample embedding method for mapping new high-dimensional data points into an existing reduced space. To this aim we propose to apply multi-output kernel ridge regression, an extension of linear ridge regression based on kernel functions which has been recently presented as a powerful method for out-of-sample projection when combined with a variant of isometric feature mapping. Computational experiments on a wide collection of cancer microarray data sets show that classifiers based on Isomap, LLE and LE were consistently more accurate than those relying on HE, LTSA and MVU. In particular, under different experimental conditions LLE-based classifier emerged as the most effective method whereas Isomap algorithm turned out to be the second best alternative for dimensionality reduction. (C) 2012 Elsevier Ltd. All rights reserved.								1	0	0	0	1	0957-4174		WOS:000315607200029	
J	Pestov, Vladimir								Is the k-NN classifier in high dimensions affected by the curse of dimensionality?								COMPUTERS & MATHEMATICS WITH APPLICATIONS			65	10			1427	1437		10.1016/j.camwa.2012.09.011			MAY 2013	2013	There is an increasing body of evidence suggesting that exact nearest neighbour search in high-dimensional spaces is affected by the curse of dimensionality at a fundamental level. Does it necessarily mean that the same is true for k nearest neighbours based learning algorithms such as the k-NN classifier? We analyse this question at a number of levels and show that the answer is different at each of them. As our first main observation, we show the consistency of a k approximate nearest neighbour classifier. However, the performance of the classifier in very high dimensions is provably unstable. As our second main observation, we point out that the existing model for statistical learning is oblivious of dimension of the domain and so every learning problem admits a universally consistent deterministic reduction to the one-dimensional case by means of a Bore! isomorphism. (C) 2012 Elsevier Ltd. All rights reserved.								1	0	0	0	1	0898-1221		WOS:000320903000002	
J	Bao, Jiangfeng; Chi, Mingmin; Benediktsson, Jon Atli								Spectral Derivative Features for Classification of Hyperspectral Remote Sensing Images: Experimental Evaluation					2			IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING			6	2	SI		594	601		10.1109/JSTARS.2013.2237758			APR 2013	2013	Derivatives of spectral reflectance signatures can capture salient features of different land-cover classes. Such information has been used for supervised classification of remote sensing data along with spectral reflectance. In the paper, we study how supervised classification of hyperspectral remote sensing data can benefit from the use of derivatives of spectral reflectance without the aid of other techniques, such as dimensionality reduction and data fusion. An empirical conclusion is given based on a large amount of experimental evaluations carried out on three real hyperspectral remote sensing data sets. The experimental results show that when a training data set is of a small size or the quality of the data is poor, the use of additional first order derivatives can significantly improve classification accuracies along with original spectral features when using classifiers which can avoid the "curse of dimensionality," such as the SVM algorithm.								1	0	0	0	1	1939-1404		WOS:000319278000013	
J	Aguiar-Pulido, Vanessa; Seoane, Jose A.; Gestal, Marcos; Dorado, Julian								Exploring Patterns of Epigenetic Information with Data Mining Techniques								CURRENT PHARMACEUTICAL DESIGN			19	4			779	789					FEB 2013	2013	Data mining, a part of the Knowledge Discovery in Databases process (KDD), is the process of extracting patterns from large data sets by combining methods from statistics and artificial intelligence with database management. Analyses of epigenetic data have evolved towards genome-wide and high-throughput approaches, thus generating great amounts of data for which data mining is essential. Part of these data may contain patterns of epigenetic information which are mitotically and/or meiotically heritable determining gene expression and cellular differentiation, as well as cellular fate. Epigenetic lesions and genetic mutations are acquired by individuals during their life and accumulate with ageing. Both defects, either together or individually, can result in losing control over cell growth and, thus, causing cancer development. Data mining techniques could be then used to extract the previous patterns. This work reviews some of the most important applications of data mining to epigenetics.								1	0	0	0	1	1381-6128		WOS:000316448200015	
J	Banos, Oresti; Damas, Miguel; Pomares, Hector; Rojas, Fernando; Delgado-Marquez, Blanca; Valenzuela, Olga				Damas Hermoso, Miguel/D-9979-2012; Pomares, Hector/B-1841-2012	Pomares, Hector/0000-0002-8528-828X			Human activity recognition based on a sensor weighting hierarchical classifier								SOFT COMPUTING			17	2			333	343		10.1007/s00500-012-0896-3			FEB 2013	2013	The analysis of daily living human behavior has proven to be of key importance to prevent unhealthy habits. The diversity of activities and the individuals' particular execution style determine that several sources of information are normally required. One of the main issues is to optimally combine them to guarantee performance, scalability and robustness. In this paper we present a fusion classification methodology which takes into account the potential of the individual decisions yielded at both activity and sensor classification levels. Particularly tested on a wearable sensors based system, the method reinforces the idea that some parts of the body (i.e., sensors) may be specially informative for the recognition of each particular activity, thus supporting the ranking of the decisions provided by each associated sensor decision entity. Our method systematically outperforms the results obtained by traditional multiclass models which otherwise may require a high-dimensional feature space to acquire a similar performance. The comparison with other activity-recognition fusion approaches also demonstrates our model scales significantly better for small sensor networks.								1	0	1	0	1	1432-7643		WOS:000313969400012	
J	Guo, Zhongmei; Yang, Sheng; Hu, Qingming; Peng, Lihong								A Transverse and Longitudinal Encoding of Protein Sequence and Its Application								JOURNAL OF COMPUTATIONAL AND THEORETICAL NANOSCIENCE			10	2			271	275		10.1166/jctn.2013.2690			FEB 2013	2013	Basis on the intrinsic relationship between protein function and its subcellular location, further understanding the function of protein, and identifying the subcellular location becomes the important research area of cell biology and proteomics. In this paper, based on the amino acid composition, we propose a new feature extraction method, which contains Chou's amino acid composition, and also includes the position distribution information of the amino acid residues and Local order information in protein sequence. Then we use a classifiers, which is NN (the nearest neighbor classifier), to predict two standard sequence datasets, Both of these two methods achieve higher predictive success rates by the jackknife tests, Compared with existing models, the experiment result show that overall prediction effect on two datasets are improved.								1	0	0	0	1	1546-1955		WOS:000315749000002	
J	Saha, Indrajit; Mazzocco, Giovanni; Plewczynski, Dariusz								Consensus classification of human leukocyte antigen class II proteins								IMMUNOGENETICS			65	2			97	105		10.1007/s00251-012-0665-6			FEB 2013	2013	Class II human leukocyte antigens (HLA II) are proteins involved in the human immunological adaptive response by binding and exposing some pre-processed, non-self peptides in the extracellular domain in order to make them recognizable by the CD4+ T lymphocytes. However, the understanding of HLA-peptide binding interaction is a crucial step for designing a peptide-based vaccine because the high rate of polymorphisms in HLA class II molecules creates a big challenge, even though the HLA II proteins can be grouped into supertypes, where members of different class bind a similar pool of peptides. Hence, first we performed the supertype classification of 27 HLA II proteins using their binding affinities and structural-based linear motifs to create a stable group of supertypes. For this purpose, a well-known clustering method was used, and then, a consensus was built to find the stable groups and to show the functional and structural correlation of HLA II proteins. Thus, the overlap of the binding events was measured, confirming a large promiscuity within the HLA II-peptide interactions. Moreover, a very low rate of locus-specific binding events was observed for the HLA-DP genetic locus, suggesting a different binding selectivity of these proteins with respect to HLA-DR and HLA-DQ proteins. Secondly, a predictor based on a support vector machine (SVM) classifier was designed to recognize HLA II-binding peptides. The efficiency of prediction was estimated using precision, recall (sensitivity), specificity, accuracy, F-measure, and area under the ROC curve values of random subsampled dataset in comparison with other supervised classifiers. Also the leave-one-out cross-validation was performed to establish the efficiency of the predictor. The availability of HLA II-peptide interaction dataset, HLA II-binding motifs, high-quality amino acid indices, peptide dataset for SVM training, and MATLAB code of the predictor is available at http://sysbio.icm.edu.pl/HLA.								1	0	1	0	1	0093-7711		WOS:000313483700002	
J	Sarro, L. M.; Debosscher, J.; Neiner, C.; Bello-Garcia, A.; Gonzalez-Marcos, A.; Prendes-Gero, B.; Ordieres, J.; Leon, G.; Aerts, C.; de Batz, B.				Gonzalez Marcos, Ana/C-9640-2013	Gonzalez Marcos, Ana/0000-0003-4684-659X			Improved variability classification of CoRoT targets with Giraffe spectra								ASTRONOMY & ASTROPHYSICS			550						A120	10.1051/0004-6361/201220184			FEB 2013	2013	Aims. We present an improved method for automated stellar variability classification, using fundamental parameters derived from high resolution spectra, with the goal to improve the variability classification obtained using information derived from CoRoT light curves only. Although we focus on Giraffe spectra and CoRoT light curves in this work, the methods are much more widely applicable.Methods. In order to improve the variability classification obtained from the photometric time series, only rough estimates of the stellar physical parameters (T-eff and log (g)) are needed because most variability types that overlap in the space of time series parameters, are well separated in the space of physical parameters (e. g. gamma Dor/SPB or delta Sct/beta Cep). In this work, several state-of-the-art machine learning techniques are combined to estimate these fundamental parameters from high resolution Giraffe spectra. Next, these parameters are used in a multi-stage Gaussian-Mixture classifier to perform an improved supervised variability classification of CoRoT light curves. The variability classifier can be used independently of the regression module that estimates the physical parameters, so that non-spectroscopic estimates derived e. g. from photometric colour indices can be used instead.Results. T-eff and log (g) are derived from Giraffe spectra, for 6832 CoRoT targets. The use of those parameters in addition to information extracted from the CoRoT light curves, significantly improves the results of our previous automated stellar variability classification. Several new pulsating stars are identified with high confidence levels, including hot pulsators such as SPB and beta Cep, and several gamma Dor-delta Sct hybrids. From our samples of new gamma Dor and delta Sct stars, we find strong indications that the instability domains for both types of pulsators are larger than previously thought.								1	0	0	0	1	0004-6361		WOS:000314879700120	
J	Carrizosa, Emilio; Romero Morales, Dolores								Supervised classification and mathematical optimization								COMPUTERS & OPERATIONS RESEARCH			40	1			150	165		10.1016/j.cor.2012.05.015			JAN 2013	2013	Data mining techniques often ask for the resolution of optimization problems. Supervised classification, and, in particular, support vector machines, can be seen as a paradigmatic instance. In this paper, some links between mathematical optimization methods and supervised classification are emphasized. It is shown that many different areas of mathematical optimization play a central role in off-the-shelf supervised classification methods. Moreover, mathematical optimization turns out to be extremely useful to address important issues in classification, such as identifying relevant variables, improving the interpretability of classifiers or dealing with vagueness/noise in the data. (C) 2012 Elsevier Ltd. All rights reserved.								1	0	0	0	1	0305-0548		WOS:000309623100015	
J	Chen, Hui-Ling; Huang, Chang-Cheng; Yu, Xin-Gang; Xu, Xin; Sun, Xin; Wang, Gang; Wang, Su-Jing								An efficient diagnosis system for detection of Parkinson's disease using fuzzy k-nearest neighbor approach								EXPERT SYSTEMS WITH APPLICATIONS			40	1			263	271		10.1016/j.eswa.2012.07.014			JAN 2013	2013	In this paper, we present an effective and efficient diagnosis system using fuzzy k-nearest neighbor (FKNN) for Parkinson's disease (PD) diagnosis. The proposed FKNN-based system is compared with the support vector machines (SVM) based approaches. In order to further improve the diagnosis accuracy for detection of PD, the principle component analysis was employed to construct the most discriminative new feature sets on which the optimal FKNN model was constructed. The effectiveness of the proposed system has been rigorously estimated on a PD data set in terms of classification accuracy, sensitivity, specificity and the area under the receiver operating characteristic (ROC) curve (AUC). Experimental results have demonstrated that the FKNN-based system greatly outperforms SVM-based approaches and other methods in the literature. The best classification accuracy (96.07%) obtained by the FKNN-based system using a 10-fold cross validation method can ensure a reliable diagnostic model for detection of PD. Promisingly, the proposed system might serve as a new candidate of powerful tools for diagnosing PD with excellent performance. (C) 2012 Elsevier Ltd. All rights reserved.								1	0	0	0	1	0957-4174		WOS:000309378200025	
J	Labbe, Cyril; Labbe, Dominique								Duplicate and fake publications in the scientific literature: how many SCIgen papers in computer science?								SCIENTOMETRICS			94	1			379	396		10.1007/s11192-012-0781-y			JAN 2013	2013	Two kinds of bibliographic tools are used to retrieve scientific publications and make them available online. For one kind, access is free as they store information made publicly available online. For the other kind, access fees are required as they are compiled on information provided by the major publishers of scientific literature. The former can easily be interfered with, but it is generally assumed that the latter guarantee the integrity of the data they sell. Unfortunately, duplicate and fake publications are appearing in scientific conferences and, as a result, in the bibliographic services. We demonstrate a software method of detecting these duplicate and fake publications. Both the free services (such as Google Scholar and DBLP) and the charged-for services (such as IEEE Xplore) accept and index these publications.								1	0	0	0	1	0138-9130		WOS:000313016300022	
J	Saez, Jose A.; Luengo, Julian; Herrera, Francisco				Herrera, Francisco/C-6856-2008	Herrera, Francisco/0000-0002-7283-312X			Predicting noise filtering efficacy with data complexity measures for nearest neighbor classification								PATTERN RECOGNITION			46	1			355	364		10.1016/j.patcog.2012.07.009			JAN 2013	2013	Classifier performance, particularly of instance-based learners such as k-nearest neighbors, is affected by the presence of noisy data. Noise filters are traditionally employed to remove these corrupted data and improve the classification performance. However, their efficacy depends on the properties of the data, which can be analyzed by what are known as data complexity measures. This paper studies the relation between the complexity metrics of a dataset and the efficacy of several noise filters to improve the performance of the nearest neighbor classifier. A methodology is proposed to extract a rule set based on data complexity measures that enables one to predict in advance whether the use of noise filters will be statistically profitable. The results obtained show that noise filtering efficacy is to a great extent dependent on the characteristics of the data analyzed by the measures. The validation process carried out shows that the final rule set provided is fairly accurate in predicting the efficacy of noise filters before their application and it produces an improvement with respect to the indiscriminate usage of noise filters. (C) 2012 Elsevier Ltd. All rights reserved.								1	0	0	0	1	0031-3203		WOS:000309785000031	
J	Hadjidimitriou, Stelios K.; Hadjileontiadis, Leontios J.								Toward an EEG-Based Recognition of Music Liking Using Time-Frequency Analysis								IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING			59	12			3498	3510		10.1109/TBME.2012.2217495			DEC 2012	2012	Affective phenomena, as reflected through brain activity, could constitute an effective index for the detection of music preference. In this vein, this paper focuses on the discrimination between subjects' electroencephalogram (EEG) responses to self-assessed liked or disliked music, acquired during an experimental procedure, by evaluating different feature extraction approaches and classifiers to this end. Feature extraction is based on time-frequency (TF) analysis by implementing three TF techniques, i.e., spectrogram, Zhao-Atlas-Marks distribution and Hilbert-Huang spectrum (HHS). Feature estimation also accounts for physiological parameters that relate to EEG frequency bands, reference states, time intervals, and hemispheric asymmetries. Classification is performed by employing four classifiers, i.e., support vector machines, k-nearest neighbors (k-NN), quadratic and Mahalanobis distance-based discriminant analyses. According to the experimental results across nine subjects, best classification accuracy {86.52 (+/-0.76)%} was achieved using k-NN and HHS-based feature vectors (FVs) representing a bilateral average activity, referred to a resting period, in beta (13-30 Hz) and gamma (30-49 Hz) bands. Activity in these bands may point to a connection between music preference and emotional arousal phenomena. Furthermore, HHS-based FVs were found to be robust against noise corruption. The outcomes of this study provide early evidence and pave the way for the development of a generalized brain computer interface for music preference recognition.								1	0	0	0	1	0018-9294		WOS:000311843500027	
J	Park, Man-Woo; Brilakis, Ioannis				Brilakis, Ioannis/H-5369-2013	Brilakis, Ioannis/0000-0003-1829-2083			Construction worker detection in video frames for initializing vision trackers								AUTOMATION IN CONSTRUCTION			28				15	25		10.1016/j.autcon.2012.06.001			DEC 2012	2012	Monitoring the location of resources on large scale, congested, outdoor sites can be performed more efficiently with vision tracking, as this approach does not require any pre-tagging of resources. However, the greatest impediment to the use of vision tracking in this case is the lack of detection methods that are needed to automatically mark the resources of interest and initiate the tracking. This paper presents such a novel method for construction worker detection that localizes construction workers in video frames. The proposed method exploits motion, shape, and color cues to narrow down the detection regions to moving objects, people, and finally construction workers, respectively. The three cues are characterized by using background subtraction, the histogram of oriented gradients (HOG), and the HSV color histogram. The method has been tested on videos taken in various environments. The results demonstrate its suitability for automatic initialization of vision trackers. Published by Elsevier B.V.								1	0	0	0	1	0926-5805		WOS:000309642700002	
J	Tung, S. W.; Quek, C.; Guan, C.								SoHyFIS-Yager: A self-organizing Yager based Hybrid neural Fuzzy Inference System								EXPERT SYSTEMS WITH APPLICATIONS			39	17			12759	12771		10.1016/j.eswa.2012.02.056			DEC 1 2012	2012	The Hybrid neural Fuzzy Inference System (HyFIS) is a multilayer adaptive neural fuzzy system for building and optimizing fuzzy models using neural networks. In this paper, the fuzzy Yager inference scheme. which is able to emulate the human deductive reasoning logic, is integrated into the HyFIS model to provide it with a firm and intuitive logical reasoning and decision-making framework. In addition, a self-organizing gaussian Discrete Incremental Clustering (gDIC) technique is implemented in the network to automatically form fuzzy sets in the fuzzification phase. This clustering technique is no longer limited by the need to have prior knowledge about the number of clusters present in each input and output dimensions. The proposed self-organizing Yager based Hybrid neural Fuzzy Inference System (SoHyFIS-Yager) introduces the learning power of neural networks to fuzzy logic systems, while providing linguistic explanations of the fuzzy logic systems to the connectionist networks. Extensive simulations were conducted using the proposed model and its performance demonstrates its superiority as an effective neuro-fuzzy modeling technique. (c) 2012 Published by Elsevier Ltd.								1	0	0	0	1	0957-4174		WOS:000308449300003	
J	Hasan, Muhammad A.; Abbott, Derek; Baumert, Mathias				Baumert, Mathias/A-8324-2008	Baumert, Mathias/0000-0003-2984-2167			Beat-to-Beat Vectorcardiographic Analysis of Ventricular Depolarization and Repolarization in Myocardial Infarction								PLOS ONE			7	11					e49489	10.1371/journal.pone.0049489			NOV 14 2012	2012	Objectives: Increased beat-to-beat variability in the QT interval has been associated with heart disease and mortality. The purpose of this study was to investigate the beat-to-beat spatial and temporal variations of ventricular depolarization and repolarization in vectorcardiogram (VCG) for characterising myocardial infarction (MI) patients.Methods: Standard 12-lead ECGs of 84 MI patients (22 f, 63 +/- 12 yrs; 62 m, 56 +/- 10 yrs) and 69 healthy subjects (17 f, 42 +/- 18 yrs; 52 m, 40 +/- 13 yrs) were investigated. To extract the beat-to-beat QT intervals, a template-matching algorithm and the singular value decomposition method have been applied to synthesise the ECG data to VCG. Spatial and temporal variations in the QRS complex and T-wave loops were studied by investigating several descriptors (point-to-point distance variability, mean loop length, T-wave morphology dispersion, percentage of loop area, total cosine R-to-T).Results: Point-to-point distance variability of QRS and T-loops (0.13 +/- 0.04 vs. 0.10 +/- 0.04, p<0.0001 and 0.16 +/- 0.07 vs. 0.13 +/- 0.06, p<0.05) were significantly larger in the MI group than in the control group. The average T-wave morphology dispersion was significantly higher in the MI group than in the control group (62 degrees +/- 8 degrees vs. 38 degrees +/- 16 degrees, p<0.0001). Further, its beat-to-beat variability appeared significantly lower in the MI group than in the control group (12 degrees +/- 5 degrees vs. 15 degrees +/- 6 degrees, p<0.005). Moreover, the average percentage of the T-loop area was found significantly lower in the MI group than the controls (46 +/- 17 vs. 55 +/- 15, p<0.001). Finally, the average and beat-to-beat variability of total cosine R-to-T were not found statistically significant between both groups.Conclusions: Beat-to-beat assessment of VCG parameters may have diagnostic attributes that might help in identifying MI patients.								1	0	1	0	1	1932-6203		WOS:000311151900150	
J	DeWaard, Jack; Kim, Keuntae; Raymer, James								Migration Systems in Europe: Evidence From Harmonized Flow Data								DEMOGRAPHY			49	4			1307	1333		10.1007/s13524-012-0117-9			NOV 2012	2012	Empirical tests of migration systems theory require consistent and complete data on international migration flows. Publicly available data, however, represent an inconsistent and incomplete set of measurements obtained from a variety of national data collection systems. We overcome these obstacles by standardizing the available migration reports of sending and receiving countries in the European Union and Norway each year from 2003-2007 and by estimating the remaining missing flows. The resulting harmonized estimates are then used to test migration systems theory. First, locating thresholds in the size of flows over time, we identify three migration systems within the European Union and Norway. Second, examining the key determinants of flows with respect to the predictions of migration systems theory, our results highlight the importance of shared experiences of nation-state formation, geography, and accession status in the European Union. Our findings lend support to migration systems theory and demonstrate that knowledge of migration systems may improve the accuracy of migration forecasts toward managing the impacts of migration as a source of social change in Europe.								1	0	0	0	1	0070-3370		WOS:000310954300007	
J	Ye, Qiaolin; Zhao, Chunxia; Gao, Shangbing; Zheng, Hao								Weighted Twin Support Vector Machines with Local Information and its application								NEURAL NETWORKS			35				31	39		10.1016/j.neunet.2012.06.010			NOV 2012	2012	A Twin Support Vector Machine (TWSVM), as a variant of a Multisurface Proximal Support Vector Machine via Generalized Eigenvalues (GEPSVM), attempts to improve the generalization of GEPSVM, whose solution follows from solving two quadratic programming problems (QPPs), each of which is smaller than in a standard SVM. Unfortunately, the two QPPs still lead to rather high computational costs. Moreover, although TWSVM has better classification performance than GEPSVM, a major disadvantage is it fails to exploit the underlying correlation or similarity information between any pair of data points with the same labels that may be important for classification performance as much as possible. To mitigate the above deficiencies, in this paper, we propose a novel nonparallel plane classifier, called Weighted Twin Support Vector Machines with Local Information (WLTSVM). WLTSVM mines as much underlying similarity information within samples as possible. This method not only retains the superior characteristics of TWSVM, but also has its additional advantages: (1) comparable or better classification accuracy compared to SVM, GEPSVM and TWSVM; (2) taking motivation from standard SVM, the concept of support vectors is retained; (3) more efficient than TWSVM in terms of computational costs; and (4) only one penalty parameter is considered as opposed to two in TWSVM. Finally, experiments on both simulated and real problems confirm the effectiveness of our method. (C) 2012 Elsevier Ltd. All rights reserved.								1	0	0	0	1	0893-6080		WOS:000310824700004	
J	van der Laan, D. J. (Jan); Maas, Marnix C.; Bruyndonckx, Peter; Schaart, Dennis R.								Limits on the spatial resolution of monolithic scintillators read out by APD arrays								PHYSICS IN MEDICINE AND BIOLOGY			57	20			6479	6496		10.1088/0031-9155/57/20/6479			OCT 21 2012	2012	Cramer-Rao theory can be used to derive the lower bound on the spatial resolution achievable with position-sensitive scintillation detectors as a function of the detector geometry and the pertinent physical properties of the scintillator, the photosensor and the readout electronics. Knowledge of the Cramer-Rao lower bound (CRLB) can for example be used to optimize the detector design and to test the performance of the method used to derive position information from the detector signals. Here, this approach is demonstrated for monolithic scintillator detectors for positron emission tomography. Two detector geometries are investigated: a 20 x 10 x 10 mm(3) and a 20 x 10 x 20 mm(3) monolithic LYSO:Ce3+ crystal read out by one or two Hamamatsu S8550SPL avalanche photodiode (APD) arrays, respectively. The results indicate that in these detectors the CRLB is primarily determined by the APD excess noise factor and the number of scintillation photons detected. Furthermore, it is shown that the use of a k-nearest neighbor (k-NN) algorithm for position estimation allows the experimentally obtained spatial resolution to closely approach the CRLB. The approach outlined in this work can in principle be applied to any scintillation detector in which position information is encoded in the distribution of the scintillation light over multiple photosensor elements.								1	0	1	0	1	0031-9155		WOS:000309549600012	
J	Zhao, Li; Wang, Lei; Xu, Qingzheng								Data stream classification with artificial endocrine system								APPLIED INTELLIGENCE			37	3			390	404		10.1007/s10489-011-0334-8			OCT 2012	2012	Due to concept drifts, maintaining an up-to-date model is a challenging task for most of the current classification approaches used in data stream mining. Both the incremental classifiers and the ensemble classifiers spend most of their time in updating their temporary models and at the same time, a big sample buffer for training a classifier is necessary for most of them. These two drawbacks constrain further application in classifying a data stream. In this paper, we present a hormone based nearest neighbor classification algorithm for data stream classification, in which the classifier is updated every time a new record arrives. The records could be seen as locations in the feature space, and each location can accommodate only one endocrine cell. The classifier consists of endocrine cells on the boundaries of different classes. Every time a new record arrives, the cell that resides in the most unfit location will move to the new arrived record. In this way, the changing boundaries between different classes are recorded by the locations where endocrine cells reside in. The main advantages of the proposed method are the saving of the sample buffer and the improving of the classification accuracy. It is very important for conditions where the hardware resources are very expensive or the main memory is limited. Experiments on synthetic and real life data sets show that the proposed algorithm is able to classify data streams with less memory space and classification error.								1	0	0	0	1	0924-669X		WOS:000308252700006	
J	Gou, Jianping; Yi, Zhang; Du, Lan; Xiong, Taisong								A Local Mean-Based k-Nearest Centroid Neighbor Classifier								COMPUTER JOURNAL			55	9			1058	1071		10.1093/comjnl/bxr131			SEP 2012	2012	K-nearest neighbor (KNN) rule is a simple and effective algorithm in pattern classification. In this article, we propose a local mean-based k-nearest centroid neighbor classifier that assigns to each query pattern a class label with nearest local centroid mean vector so as to improve the classification performance. The proposed scheme not only takes into account the proximity and spatial distribution of k neighbors, but also utilizes the local mean vector of k neighbors from each class in making classification decision. In the proposed classifier, a local mean vector of k nearest centroid neighbors from each class for a query pattern is well positioned to sufficiently capture the class distribution information. In order to investigate the classification behavior of the proposed classifier, we conduct extensive experiments on the real and synthetic data sets in terms of the classification error. Experimental results demonstrate that our proposed method performs significantly well, particularly in the small sample size cases, compared with the state-of-the-art KNN-based algorithms.								1	0	0	0	1	0010-4620		WOS:000308233900004	
J	Beliakov, Gleb; Li, Gang								Improving the speed and stability of the k-nearest neighbors method								PATTERN RECOGNITION LETTERS			33	10			1296	1301		10.1016/j.patrec.2012.02.016			JUL 15 2012	2012	We present an efficient technique to accelerate the classical k-nearest neighbors method. The idea is to replace the sort operation with calculating the order statistics. This makes the kNN method not only more efficient, but also increases its stability with respect to the order in which the data is presented to the algorithm. We illustrate the gain in performance on numerical examples. We compare the efficiency of the brute force approach to kNN on Graphics Processing Units with kd-trees, and confirm superiority of the proposed approach. (C) 2012 Elsevier B.V. All rights reserved.								1	0	0	0	1	0167-8655		WOS:000305771400006	
J	Ghosh, Anil K.								A probabilistic approach for semi-supervised nearest neighbor classification								PATTERN RECOGNITION LETTERS			33	9			1127	1133		10.1016/j.patrec.2011.12.015			JUL 1 2012	2012	In supervised classification, we learn from a training set of labeled observations to form a decision rule for classifying all unlabeled test cases. But if the training sample is small, one may fail to extract sufficient information from that sample to develop a good classifier. Because of the statistical instability of nonparametric methods, this problem becomes more evident in the case of nonparametric classification. In such cases, if one can extract useful information also from unlabeled test cases and use that to modify the classification rule, the performance of the resulting classifier can be improved substantially. In this article, we use a probabilistic framework to develop such methods for nearest neighbor classification. The resulting classifiers, called semi-supervised or transductive classifiers, usually perform better than supervised methods, especially when the training sample is small. Some benchmark data sets are analyzed to show the utility of these proposed methods. (C) 2011 Elsevier B.V. All rights reserved.								1	0	0	0	1	0167-8655		WOS:000304235500013	
J	Preininger, Bernd; Hesse, Bernhard; Rohrbach, Daniel; Varga, Peter; Gerigk, Hinnerk; Langer, Max; Peyrin, Francoise; Perka, Carsten; Raum, Kay				Varga, Peter/H-6181-2012; Raum, Kay/A-5576-2013; Peyrin, Francoise/G-2823-2013				Histogram Feature-Based Classification Improves Differentiability of Early Bone Healing Stages From Micro-Computed Tomographic Data								JOURNAL OF COMPUTER ASSISTED TOMOGRAPHY			36	4			469	476		10.1097/RCT.0b013e31825eae8a			JUL-AUG 2012	2012	Objective: Contrast between not fully mineralized tissues is weak and limits conventional computed tomography (CT). An automated grayscale histogram-based analysis features could improve the sensitivity to tissue alterations during early bone healing.Materials and Methods: Tissue formation in a rat osteotomy model was analyzed using in vivo micro-CT and classified histologically (mineralized, cartilage, and connective tissues). A conventional threshold-based method including manual contouring was compared to a novel moment-based method: after removing the background peak, the histograms of each slice were characterized by their moments and analyzed as a function of the position along the long bone axis.Results: The threshold-based method could differentiate between the mineralized and connective tissue (R-2 = 0.73). The moment-based approach yielded a clear distinction between all 3 groups with a classification accuracy up to R-2 = 0.93.Conclusions: The moment-based evaluation outperforms the conventional threshold-based CT analysis in sensitivity to the healing stage, user independence, and time consumption.								1	0	1	0	1	0363-8715		WOS:000306562200019	
J	Yang, Bill Huajian; Tkachenko, Mykola								Modeling exposure at default and loss given default: empirical approaches and technical implementation								JOURNAL OF CREDIT RISK			8	2			81	102					SUM 2012	2012	The Basel Accords have created the need to develop and implement models for probability of default (PD), loss given default (LGD) and exposure at default (EAD). Although PD is quite well researched, LGD and EAD lag behind in terms of both theoretical and practical insight. This paper proposes some empirical approaches for EAD/LGD modeling and provides technical insights into their implementation. It is expected that approaches proposed in the paper will be helpful for modelers and risk managers in their risk modeling and management practice.								1	0	0	0	1	1744-6619		WOS:000317654700004	
J	Antonio Iglesias, Jose; Angelov, Plamen; Ledezma, Agapito; Sanchis, Araceli								Creating Evolving User Behavior Profiles Automatically								IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			24	5			854	867		10.1109/TKDE.2011.17			MAY 2012	2012	Knowledge about computer users is very beneficial for assisting them, predicting their future actions or detecting masqueraders. In this paper, a new approach for creating and recognizing automatically the behavior profile of a computer user is presented. In this case, a computer user behavior is represented as the sequence of the commands she/he types during her/his work. This sequence is transformed into a distribution of relevant subsequences of commands in order to find out a profile that defines its behavior. Also, because a user profile is not necessarily fixed but rather it evolves/changes, we propose an evolving method to keep up to date the created profiles using an Evolving Systems approach. In this paper, we combine the evolving classifier with a trie-based user profiling to obtain a powerful self-learning online scheme. We also develop further the recursive formula of the potential of a data point to become a cluster center using cosine distance, which is provided in the Appendix. The novel approach proposed in this paper can be applicable to any problem of dynamic/evolving user behavior modeling where it can be represented as a sequence of actions or events. It has been evaluated on several real data streams.								1	0	0	0	1	1041-4347		WOS:000301746800007	
J	Benton, Cristina S.; Miller, Brooke H.; Skwerer, Sean; Suzuki, Oscar; Schultz, Laura E.; Cameron, Michael D.; Marron, J. S.; Pletcher, Mathew T.; Wiltshire, Tim								Evaluating genetic markers and neurobiochemical analytes for fluoxetine response using a panel of mouse inbred strains								PSYCHOPHARMACOLOGY			221	2			297	315		10.1007/s00213-011-2574-z			MAY 2012	2012	Identification of biomarkers that establish diagnosis or treatment response is critical to the advancement of research and management of patients with depression.Our goal was to identify biomarkers that can potentially assess fluoxetine response and risk to poor treatment outcome.We measured behavior, gene expression, and the levels of 36 neurobiochemical analytes across a panel of genetically diverse mouse inbred lines after chronic treatment with water or fluoxetine.Glyoxylase 1 (GLO1) and guanine nucleotide-binding protein 1 (GNB1) mostly account for baseline anxiety-like and depressive-like behavior, indicating a common biological link between depression and anxiety. Fluoxetine-induced biochemical alterations discriminated positive responders, while baseline neurobiochemical differences differentiated negative responders (p < 0.006). Results show that glial fibrillary acidic protein, S100 beta protein, GLO1, and histone deacetylase 5 contributed most to fluoxetine response. These proteins are linked within a cellular growth/proliferation pathway, suggesting the involvement of cellular genesis in fluoxetine response. Furthermore, a candidate genetic locus that associates with baseline depressive-like behavior contains a gene that encodes for cellular proliferation/adhesion molecule (Cadm1), supporting a genetic basis for the role of neuro/gliogenesis in depression.We provided a comprehensive analysis of behavioral, neurobiochemical, and transcriptome data across 30 mouse inbred strains that has not been accomplished before. We identified biomarkers that influence fluoxetine response, which, altogether, implicate the importance of cellular genesis in fluoxetine treatment. More broadly, this approach can be used to assess a wide range of drug response phenotypes that are challenging to address in human samples.								1	0	1	0	1	0033-3158		WOS:000303457600011	
J	Destercke, Sebastien								A K-nearest neighbours method based on imprecise probabilities								SOFT COMPUTING			16	5	SI		833	844		10.1007/s00500-011-0773-5			MAY 2012	2012	K-nearest neighbours algorithms are among the most popular existing classification methods, due to their simplicity and good performances. Over the years, several extensions of the initial method have been proposed. In this paper, we propose a K-nearest neighbours approach that uses the theory of imprecise probabilities, and more specifically lower previsions. We show that the proposed approach has several assets: it can handle uncertain data in a very generic way, and decision rules developed within this theory allow us to deal with conflicting information between neighbours or with the absence of close neighbour to the instance to classify. We show that results of the basic k-NN and weighted k-NN methods can be retrieved by the proposed approach. We end with some experiments on the classical data sets.								1	0	0	0	1	1432-7643		WOS:000302414800009	
J	Liu, Hairong; Yang, Xingwei; Latecki, Longin Jan; Yan, Shuicheng				Zhang, JinYuan/C-1542-2010; Liu, Hairong/I-6695-2012				Dense Neighborhoods on Affinity Graph								INTERNATIONAL JOURNAL OF COMPUTER VISION			98	1			65	82		10.1007/s11263-011-0496-1			MAY 2012	2012	In this paper, we study the problem of how to reliably compute neighborhoods on affinity graphs. The k-nearest neighbors (kNN) is one of the most fundamental and simple methods widely used in many tasks, such as classification and graph construction. Previous research focused on how to efficiently compute kNN on vectorial data. However, most real-world data have no vectorial representations, and only have affinity graphs which may contain unreliable affinities. Since the kNN of an object o is a set of k objects with the highest affinities to o, it is easily disturbed by errors in pairwise affinities between o and other objects, and also it cannot well preserve the structure underlying the data. To reliably analyze the neighborhood on affinity graphs, we define the k-dense neighborhood (kDN), which considers all pairwise affinities within the neighborhood, i.e., not only the affinities between o and its neighbors but also between the neighbors. For an object o, its kDN is a set kDN(o) of k objects which maximizes the sum of all pairwise affinities of objects in the set {o}a(a)kDN(o). We analyze the properties of kDN, and propose an efficient algorithm to compute it. Both theoretic analysis and experimental results on shape retrieval, semi-supervised learning, point set matching and data clustering show that kDN significantly outperforms kNN on affinity graphs, especially when many pairwise affinities are unreliable.								1	0	1	0	1	0920-5691		WOS:000302341900004	
J	Liu, Huawen; Zhang, Shichao								Noisy data elimination using mutual k-nearest neighbor for classification mining								JOURNAL OF SYSTEMS AND SOFTWARE			85	5			1067	1074		10.1016/j.jss.2011.12.019			MAY 2012	2012	k nearest neighbor (kNN) is an effective and powerful lazy learning algorithm, notwithstanding its easy-to-implement. However, its performance heavily relies on the quality of training data. Due to many complex real-applications, noises coming from various possible sources are often prevalent in large scale databases. How to eliminate anomalies and improve the quality of data is still a challenge. To alleviate this problem, in this paper we propose a new anomaly removal and learning algorithm under the framework of kNN. The primary characteristic of our method is that the evidence of removing anomalies and predicting class labels of unseen instances is mutual nearest neighbors, rather than k nearest neighbors. The advantage is that pseudo nearest neighbors can be identified and will not be taken into account during the prediction process. Consequently, the final learning result is more creditable. An extensive comparative experimental analysis carried out on UCI datasets provided empirical evidence of the effectiveness of the proposed method for enhancing the performance of the k-NN rule. (C) 2011 Elsevier Inc. All rights reserved.								1	0	0	0	1	0164-1212		WOS:000301828800004	
J	Bunkhumpornpat, Chumphol; Sinapiromsaran, Krung; Lursinsap, Chidchanok								DBSMOTE: Density-Based Synthetic Minority Over-sampling TEchnique								APPLIED INTELLIGENCE			36	3			664	684		10.1007/s10489-011-0287-y			APR 2012	2012	A dataset exhibits the class imbalance problem when a target class has a very small number of instances relative to other classes. A trivial classifier typically fails to detect a minority class due to its extremely low incidence rate. In this paper, a new over-sampling technique called DBSMOTE is proposed. Our technique relies on a density-based notion of clusters and is designed to over-sample an arbitrarily shaped cluster discovered by DBSCAN. DBSMOTE generates synthetic instances along a shortest path from each positive instance to a pseudo-centroid of a minority-class cluster. Consequently, these synthetic instances are dense near this centroid and are sparse far from this centroid. Our experimental results show that DBSMOTE improves precision, F-value, and AUC more effectively than SMOTE, Borderline-SMOTE, and Safe-Level-SMOTE for imbalanced datasets.								1	0	0	0	1	0924-669X		WOS:000303479800011	
J	Giotis, Ioannis; Petkov, Nicolai								Cluster-based adaptive metric classification								NEUROCOMPUTING			81				33	40		10.1016/j.neucom.2011.10.018			APR 1 2012	2012	Introducing adaptive metric has been shown to improve the results of distance-based classification algorithms. Existing methods are often computationally intensive, either in the training or in the classification phase. We present a novel algorithm that we call Cluster-Based Adaptive Metric (CLAM) classification. It first determines the number of clusters in each class of a training set and then computes the parameters of a Mahalanobis distance for each cluster. The derived Mahalanobis distances are then used to estimate the probability of cluster- and, subsequently, class-membership. We compare the proposed algorithm with other classification algorithms using 10 different data sets. The proposed CLAM algorithm is as effective as other adaptive metric classification algorithms yet it is simpler to use and in many cases computationally more efficient. (C) 2011 Elsevier B.V. All rights reserved.								1	0	0	0	1	0925-2312		WOS:000301009000004	
J	Goltsev, Alexander; Gritsenko, Vladimir								Investigation of efficient features for image recognition by neural networks								NEURAL NETWORKS			28				15	23		10.1016/j.neunet.2011.12.002			APR 2012	2012	In the paper, effective and simple features for image recognition (named LiRA-features) are investigated in the task of handwritten digit recognition. Two neural network classifiers are considered-a modified 3-layer perceptron LiRA and a modular assembly neural network. A method of feature selection is proposed that analyses connection weights formed in the preliminary learning process of a neural network classifier. In the experiments using the MNIST database of handwritten digits, the feature selection procedure allows reduction of feature number (from 60 000 to 7000) preserving comparable recognition capability while accelerating computations. Experimental comparison between the LIRA perceptron and the modular assembly neural network is accomplished, which shows that recognition capability of the modular assembly neural network is somewhat better. (C) 2011 Elsevier Ltd. All rights reserved.								1	0	1	0	1	0893-6080		WOS:000302514700002	
J	Meo, Rosa; Bachar, Dipankar; Ienco, Dino				Meo, Rosa/E-9345-2012				LODE: A distance-based classifier built on ensembles of positive and negative observations								PATTERN RECOGNITION			45	4			1409	1425		10.1016/j.patcog.2011.10.015			APR 2012	2012	Current work on assembling a set of local patterns such as rules and class association rules into a global model for the prediction of a target usually focuses on the identification of the minimal set of patterns that cover the training data. In this paper we present a different point of view: the model of a class has been built with the purpose to emphasize the typical features of the examples of the class. Typical features are modeled by frequent itemsets extracted from the examples and constitute a new representation space of the examples of the class. Prediction of the target class of test examples occurs by computation of the distance between the vector representing the example in the space of the itemsets of each class and the vectors representing the classes.It is interesting to observe that in the distance computation the critical contribution to the discrimination between classes is given not only by the itemsets of the class model that match the example but also by itemsets that do not match the example. These absent features constitute some pieces of information on the examples that can be considered for the prediction and should not be disregarded. Second, absent features are more abundant in the wrong classes than in the correct ones and their number increases the distance between the example vector and the negative class vectors. Furthermore, since absent features are frequent features in their respective classes, they make the prediction more robust against over-fitting and noise. The usage of features absent in the test example is a novel issue in classification: existing learners usually tend to select the best local pattern that matches the example and do not consider the abundance of other patterns that do not match it. We demonstrate the validity of our observations and the effectiveness of LODE, our learner, by means of extensive empirical experiments in which we compare the prediction accuracy of LODE with a consistent set of classifiers of the state of the art. In this paper we also report the methodology that we adopted in order to determine automatically the setting of the learner and of its parameters. (C) 2011 Elsevier Ltd. All rights reserved.								1	0	0	0	1	0031-3203		WOS:000300459000016	
J	Ramon Rico-Juan, Juan; Manuel Inesta, Jose								New rank methods for reducing the size of the training set using the nearest neighbor rule								PATTERN RECOGNITION LETTERS			33	5			654	660		10.1016/j.patrec.2011.07.019			APR 1 2012	2012	Some new rank methods to select the best prototypes from a training set are proposed in this paper in order to establish its size according to an external parameter, while maintaining the classification accuracy. The traditional methods that filter the training set in a classification task like editing or condensing have some rules that apply to the set in order to remove outliers or keep some prototypes that help in the classification. In our approach, new voting methods are proposed to compute the prototype probability and help to classify correctly a new sample. This probability is the key to sorting the training set out, so a relevance factor from 0 to 1 is used to select the best candidates for each class whose accumulated probabilities are less than that parameter. This approach makes it possible to select the number of prototypes necessary to maintain or even increase the classification accuracy. The results obtained in different high dimensional databases show that these methods maintain the final error rate while reducing the size of the training set. (C) 2011 Elsevier B.V. All rights reserved.								1	0	0	0	1	0167-8655		WOS:000301212400020	
J	Kodell, Ralph L.; Zhang, Chuanlei; Siegel, Eric R.; Nagarajan, Radhakrishnan								Selective voting in convex-hull ensembles improves classification accuracy								ARTIFICIAL INTELLIGENCE IN MEDICINE			54	3			171	179		10.1016/j.artmed.2011.10.003			MAR 2012	2012	Objective: Classification algorithms can be used to predict risks and responses of patients based on genomic and other high-dimensional data. While there is optimism for using these algorithms to improve the treatment of diseases, they have yet to demonstrate sufficient predictive ability for routine clinical practice. They generally classify all patients according to the same criteria, under an implicit assumption of population homogeneity. The objective here is to allow for population heterogeneity, possibly unrecognized, in order to increase classification accuracy and further the goal of tailoring therapies on an individualized basis.Methods and materials: A new selective-voting algorithm is developed in the context of a classifier ensemble of two-dimensional convex hulls of positive and negative training samples. Individual classifiers in the ensemble are allowed to vote on test samples only if those samples are located within or behind pruned convex hulls of training samples that define the classifiers.Results: Validation of the new algorithm's increased accuracy is carried out using two publicly available datasets having cancer as the outcome variable and expression levels of thousands of genes as predictors. Selective voting leads to statistically significant increases in accuracy from 86.0% to 89.8% (p < 0.001) and 63.2% to 67.8% (p < 0.003) compared to the original algorithm.Conclusion: Selective voting by members of convex-hull classifier ensembles significantly increases classification accuracy compared to one-size-fits-all approaches. (C) 2011 Elsevier B.V. All rights reserved.								1	0	0	0	1	0933-3657		WOS:000302840300004	
J	Viswanath, Satish; Madabhushi, Anant								Consensus embedding: theory, algorithms and application to segmentation and classification of biomedical data								BMC BIOINFORMATICS			13						26	10.1186/1471-2105-13-26			FEB 8 2012	2012	Background: Dimensionality reduction (DR) enables the construction of a lower dimensional space (embedding) from a higher dimensional feature space while preserving object-class discriminability. However several popular DR approaches suffer from sensitivity to choice of parameters and/or presence of noise in the data. In this paper, we present a novel DR technique known as consensus embedding that aims to overcome these problems by generating and combining multiple low-dimensional embeddings, hence exploiting the variance among them in a manner similar to ensemble classifier schemes such as Bagging. We demonstrate theoretical properties of consensus embedding which show that it will result in a single stable embedding solution that preserves information more accurately as compared to any individual embedding (generated via DR schemes such as Principal Component Analysis, Graph Embedding, or Locally Linear Embedding). Intelligent sub-sampling (via mean-shift) and code parallelization are utilized to provide for an efficient implementation of the scheme.Results: Applications of consensus embedding are shown in the context of classification and clustering as applied to: (1) image partitioning of white matter and gray matter on 10 different synthetic brain MRI images corrupted with 18 different combinations of noise and bias field inhomogeneity, (2) classification of 4 high-dimensional gene-expression datasets, (3) cancer detection (at a pixel-level) on 16 image slices obtained from 2 different high-resolution prostate MRI datasets. In over 200 different experiments concerning classification and segmentation of biomedical data, consensus embedding was found to consistently outperform both linear and non-linear DR methods within all applications considered.Conclusions: We have presented a novel framework termed consensus embedding which leverages ensemble classification theory within dimensionality reduction, allowing for application to a wide range of high-dimensional biomedical data classification and segmentation problems. Our generalizable framework allows for improved representation and classification in the context of both imaging and non-imaging data. The algorithm offers a promising solution to problems that currently plague DR methods, and may allow for extension to other areas of biomedical data analysis.								1	0	0	0	1	1471-2105		WOS:000304911500001	
J	Bhattacharya, Gautam; Ghosh, Koushik; Chowdhury, Ananda S.								An affinity-based new local distance function and similarity measure for kNN algorithm								PATTERN RECOGNITION LETTERS			33	3			356	363		10.1016/j.patrec.2011.10.021			FEB 1 2012	2012	In this paper, we propose a modified version of the k-nearest neighbor (kNN) algorithm. We first introduce a new affinity function for distance measure between a test point and a training point which is an approach based on local learning. A new similarity function using this affinity function is proposed next for the classification of the test patterns. The widely used convention of k, i.e., k = [root N] is employed, where N is the number of data used for training purpose. The proposed modified kNN algorithm is applied on fifteen numerical datasets from the UCI machine learning data repository. Both 5-fold and 10-fold cross-validations are used. The average classification accuracy, obtained from our method is found to exceed some well-known clustering algorithms. (C) 2011 Elsevier B.V. All rights reserved.								1	0	0	0	1	0167-8655		WOS:000300135300016	
J	Ferreira, Marcos; Moreira, Antonio Paulo; Neto, Pedro				Neto, Pedro/D-4656-2009				A low-cost laser scanning solution for flexible robotic cells: spray coating								INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY			58	9-12			1031	1041		10.1007/s00170-011-3452-x			FEB 2012	2012	In this paper, an adaptive and low-cost robotic coating platform for small production series is presented. This new platform presents a flexible architecture that enables fast/automatic system adaptive behaviour without human intervention. The concept is based on contactless technology, using artificial vision and laser scanning to identify and characterize different workpieces travelling on a conveyor. Using laser triangulation, the workpieces are virtually reconstructed through a simplified cloud of three-dimensional (3D) points. From those reconstructed models, several algorithms are implemented to extract information about workpieces profile (pattern recognition), size, boundary and pose. Such information is then used to on-line adjust the "base" robot programmes. These robot programmes are off-line generated from a 3D computer-aided design model of each different workpiece profile. Finally, the robotic manipulator executes the coating process after its "base" programmes have been adjusted. This is a low-cost and fully autonomous system that allows adapting the robot's behaviour to different manufacturing situations. It means that the robot is ready to work over any piece at any time, and thus, small production series can be reduced to as much as a one-object series. No skilled workers and large setup times are needed to operate it. Experimental results showed that this solution proved to be efficient and can be applied not only for spray coating purposes but also for many other industrial processes (automatic manipulation, pick-and-place, inspection, etc.).								1	0	0	0	1	0268-3768		WOS:000300089400018	
S	Ceccato, Mariano; Marchetto, Alessandro; Mariani, Leonardo; Nguyen, Cu D.; Tonella, Paolo						Glinz, M; Murphy, G; Pezze, M		An Empirical Study about the Effectiveness of Debugging When Random Test Cases Are Used								2012 34TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE)	International Conference on Software Engineering						452	462					2012	2012	Automatically generated test cases are usually evaluated in terms of their fault revealing or coverage capability. Beside these two aspects, test cases are also the major source of information for fault localization and fixing. The impact of automatically generated test cases on the debugging activity, compared to the use of manually written test cases, has never been studied before.In this paper we report the results obtained from two controlled experiments with human subjects performing debugging tasks using automatically generated or manually written test cases. We investigate whether the features of the former type of test cases, which make them less readable and understandable (e.g., unclear test scenarios, meaningless identifiers), have an impact on accuracy and efficiency of debugging. The empirical study is aimed at investigating whether, despite the lack of readability in automatically generated test cases, subjects can still take advantage of them during debugging.				34th International Conference on Software Engineering (ICSE)	JUN 02-09, 2012	ACM Special Interest Grp Software Engn (SIGSOFT); IEEE Comp Soc Tech Council Software Engn (TCSE); Special Interest Grp Software Engn Swiss Informat Soc (SI-SE); Univ Zurich, Dept Informat; ACM; IEEE Comp Soc	Zurich, SWITZERLAND	1	0	0	0	1	0270-5257	978-1-4673-1067-3	WOS:000312908700042	
J	Kim, Namwon; Li, Zhenguo; Hurth, Cedric; Zenhausern, Frederic; Chang, Shih-Fu; Attinger, Daniel				attinger, daniel/I-7509-2012				Identification of fluid and substrate chemistry based on automatic pattern recognition of stains								ANALYTICAL METHODS			4	1			50	57		10.1039/c1ay05338h			JAN 2012	2012	This study proposes that images of stains from 100-nanolitre drops can be automatically identified as signatures of fluid composition and substrate chemistry, for e. g. rapid biological testing. Two datasets of stain images are produced and made available online, one with consumable fluids, and the other with biological fluids. Classification algorithms are used to identify an unknown stain by measuring its similarity to representative examples of predefined categories. The accuracy ranges from 80 to 94%, compared to an accuracy by random assignment of 3 to 4%. Clustering algorithms are also applied to group unknown stain images into a number of clusters each likely to correspond to similar combinations of fluids and substrates. The clustering accuracy ranges from 62 to 80%, compared to an accuracy by random assignment of 3 or 4%. The algorithms were also remarkably accurate at determining the presence or absence of biotin and streptavidin respectively in the liquid and on the glass, the salt composition, or the pH of the solution.								1	0	0	0	1	1759-9660		WOS:000298883800006	
J	Lileikyte, R.; Telksnys, L.								Quality Measurement of Speech Recognition Features in Context of Nearest Neighbour Classifier								ELEKTRONIKA IR ELEKTROTECHNIKA				2			9	12		10.5755/j01.eee.118.2.1165			2012	2012	R. Lileikyte, L. Telksnys. Quality Measurement of Speech Recognition Features in Context of Nearest Neighbour Classifier // Electronics and Electrical Engineering. - Kaunas: Technologija, 2012. - No. 2(118). - P. 9-12.The quality feature set is a key of importance of successful speech recognition system. The quality of features is estimated by classification error. Yet, this method is limited as the classification experiments must be run with each feature system. The major issue of this paper is to propose the method for quality estimation of speech recognition features that is based on metrics and does not require classification experiments. Experimental researches were made in context of Nearest neighbour classifier usage. Within the proposed method PLP was established to have the higher quality comparing to LFCC. The adequateness of the method was validated by Nearest neighbour classification error. Ill. 3, bibl. 25, tabl. I (in English; abstracts in English and Lithuanian).								1	0	0	0	1	1392-1215		WOS:000300916300002	
S	Luque, R. M.; Elizondo, D.; Lopez-Rubio, E.; Palomo, E. J.						Elizondo, DA; Solanas, A; MartinezBalleste, A		Feature Selection of Hand Biometrical Traits Based on Computational Intelligence Techniques								COMPUTATIONAL INTELLIGENCE FOR PRIVACY AND SECURITY	Studies in Computational Intelligence		394				159	180					2012	2012	This chapter presents a novel methodology for using feature selection in hand biometric systems, based on genetic algorithms and mutual information. The aim is to provide a standard features dataset which diminishes the number of features to extract and decreases the complexity of the whole identification process. The experimental results show that it is not always necessary to apply sophisticated and complex classifiers to obtain good accuracy rates. This methodology approach manages to discover the most suitable geometric hand features, among all the extracted data, to perform the classification task. Simple classifiers like K-Nearest Neighbour (kNN) or Linear Discriminant Analysis (LDA) in combination with this strategy, getting even better results than other more complicated approaches.				2010 IEEE World Congress on Computational Intelligence	JUL 18-23, 2010	IEEE; IEEE Computat Intelligence Soc; Int Neural Network Soc; Evolut Program Soc; IET	Barcelona, SPAIN	1	0	0	0	1	1860-949X	978-3-642-25236-5	WOS:000309694300010	
J	Peng, Chun-Rong; Lu, Wen-Cong; Niu, Bing; Li, Ya-Jun; Hu, Le-Le								Prediction of the Functional Roles of Small Molecules in Lipid Metabolism Based on Ensemble Learning								PROTEIN AND PEPTIDE LETTERS			19	1			108	112					JAN 2012	2012	As many diseases like high cholesterol are referred to lipid metabolism, studying the lipid metabolic pathway has a positive effect on finding the knowledge about interactions between different elements within high complex living systems. Here, we employed a typical ensemble learning method, Bagging learner, to study and predict the possible sub lipid metabolic pathway of small molecules based on physical and chemical features of the compounds. As a result, jackknife cross validation test and independent set test on the model reached 89.85% and 91.46%, respectively. Therefore, our predictor may be used for finding the new compounds which participate in lipid metabolic procedures.								1	0	1	0	1	0929-8665		WOS:000300282800015	
J	Satapathy, Suresh Chandra; Chittineni, Suresh; Krishna, S. Mohan; Murthy, J. V. R.; Reddy, P. V. G. D. Prasad								Kalman particle swarm optimized polynomials for data classification								APPLIED MATHEMATICAL MODELLING			36	1			115	126		10.1016/j.apm.2011.05.033			JAN 2012	2012	Data classification is an important area of data mining. Several well known techniques such as decision tree, neural network, etc. are available for this task. In this paper we propose a Kalman particle swarm optimized (KPSO) polynomial equation for classification for several well known data sets. Our proposed method is derived from some of the findings of the valuable information like number of terms, number and combination of features in each term, degree of the polynomial equation etc. of our earlier work on data classification using polynomial neural network. The KPSO optimizes these polynomial equations with a faster convergence speed unlike PSO. The polynomial equation that gives the best performance is considered as the model for classification. Our simulation result shows that the proposed approach is able to give competitive classification accuracy compared to PNN in many datasets. (C) 2011 Elsevier Inc. All rights reserved.								1	0	0	0	1	0307-904X		WOS:000296113400009	
J	Sierra, B.; Lazkano, E.; Irigoien, I.; Jauregi, E.; Mendialdua, I.								K Nearest Neighbor Equality: Giving equal chance to all existing classes								INFORMATION SCIENCES			181	23			5158	5168		10.1016/j.ins.2011.07.024			DEC 1 2011	2011	The nearest neighbor classification method assigns an unclassified point to the class of the nearest case of a set of previously classified points. This rule is independent of the underlying joint distribution of the sample points and their classifications. An extension to this approach is the k-NN method, in which the classification of the unclassified point is made by following a voting criteria within the k nearest points.The method we present here extends the k-NN idea, searching in each class for the k nearest points to the unclassified point, and classifying it in the class which minimizes the mean distance between the unclassified point and the k nearest points within each class. As all classes can take part in the final selection process, we have called the new approach k Nearest Neighbor Equality (k-NNE).Experimental results we obtained empirically show the suitability of the k-NNE algorithm, and its effectiveness suggests that it could be added to the current list of distance based classifiers. (C) 2011 Elsevier Inc. All rights reserved.								1	0	0	0	1	0020-0255		WOS:000295760600003	
J	Sountsov, Pavel; Santucci, David M.; Lisman, John E.								A biologically plausible transform for visual recognition that is invariant to translation, scale, and rotation								FRONTIERS IN COMPUTATIONAL NEUROSCIENCE			5						53	10.3389/fncom.2011.00053			NOV 22 2011	2011	Visual object recognition occurs easily despite differences in position, size, and rotation of the object, but the neural mechanisms responsible for this invariance are not known. We have found a set of transforms that achieve invariance in a neurally plausible way. We find that a transform based on local spatial frequency analysis of oriented segments and on logarithmic mapping, when applied twice in an iterative fashion, produces an output image that is unique to the object and that remains constant as the input image is shifted, scaled, or rotated.								1	0	1	0	1	1662-5188		WOS:000299568300001	
J	Caises, Yoel; Gonzalez, Antonio; Leyva, Enrique; Perez, Raul				Leyva, Enrique/H-5244-2011; Perez Rodriguez, F.G. Raul/C-2440-2012; Gonzalez Munoz, Antonio/C-2427-2012	Gonzalez Munoz, Antonio/0000-0001-8889-7593			Combining instance selection methods based on data characterization: An approach to increase their effectiveness								INFORMATION SCIENCES			181	20			4780	4798		10.1016/j.ins.2011.06.013			OCT 15 2011	2011	Although there are several proposals in the instance selection field, none of them consistently outperforms the others over a wide range of domains. In recent years many authors have come to the conclusion that data must be characterized in order to apply the most suitable selection criterion in each case. In light of this hypothesis, herein we propose a set of measures to characterize databases. These measures were used in decision rules which, given their values for a database, select from some pre-selected methods, the method, or combination of methods, that is expected to produce the best results. The rules were extracted based on an empirical analysis of the behaviors of several methods on several data sets, then integrated into an algorithm which was experimentally evaluated over 20 databases and with six different learning paradigms. The results were compared with those of five well-known state-of-the-art methods. (C) 2011 Elsevier Inc. All rights reserved.								1	0	0	0	1	0020-0255		WOS:000293548900026	
J	Herranz, Javier; Nin, Jordi; Sole, Marc				Herranz, Javier/J-9700-2012				Optimal Symbol Alignment Distance: A New Distance for Sequences of Symbols								IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			23	10			1541	1554		10.1109/TKDE.2010.190			OCT 2011	2011	Comparison functions for sequences (of symbols) are important components of many applications, for example, clustering, data cleansing, and integration. For years, many efforts have been made to improve the performance of such comparison functions. Improvements have been done either at the cost of reducing the accuracy of the comparison, or by compromising certain basic characteristics of the functions, such as the triangular inequality. In this paper, we propose a new distance for sequences of symbols (or strings) called Optimal Symbol Alignment distance (OSA distance, for short). This distance has a very low cost in practice, which makes it a suitable candidate for computing distances in applications with large amounts of (very long) sequences. After providing a mathematical proof that the OSA distance is a real distance, we present some experiments for different scenarios (DNA sequences, record linkage, etc.), showing that the proposed distance outperforms, in terms of execution time and/or accuracy, other well-known comparison functions such as the Edit or Jaro-Winkler distances.								1	0	0	0	1	1041-4347		WOS:000293916500008	
J	Somorjai, R. L.; Dolenko, B.; Nikulin, A.; Roberson, W.; Thiessen, N.								Class proximity measures - Dissimilarity-based classification and display of high-dimensional data								JOURNAL OF BIOMEDICAL INFORMATICS			44	5			775	788		10.1016/j.jbi.2011.04.004			OCT 2011	2011	For two-class problems, we introduce and construct mappings of high-dimensional instances into dissimilarity (distance)-based Class-Proximity Planes. The Class Proximity Projections are extensions of our earlier relative distance plane mapping, and thus provide a more general and unified approach to the simultaneous classification and visualization of many-feature datasets. The mappings display all L-dimensional instances in two-dimensional coordinate systems, whose two axes represent the two distances of the instances to various pre-defined proximity measures of the two classes. The Class Proximity mappings provide a variety of different perspectives of the dataset to be classified and visualized. We report and compare the classification and visualization results obtained with various Class Proximity Projections and their combinations on four datasets from the UCI data base, as well as on a particular high-dimensional biomedical dataset. Crown Copyright (C) 2011 Published by Elsevier Inc. All rights reserved.								1	0	0	0	1	1532-0464		WOS:000295492000006	
J	Chuang, Li-Yeh; Tsai, Sheng-Wei; Yang, Cheng-Hong				Chuang, Li-Yeh/E-5005-2011				Improved binary particle swarm optimization using catfish effect for feature selection								EXPERT SYSTEMS WITH APPLICATIONS			38	10			12699	12707		10.1016/j.eswa.2011.04.057			SEP 15 2011	2011	The feature selection process constitutes a commonly encountered problem of global combinatorial optimization. This process reduces the number of features by removing irrelevant, noisy, and redundant data, thus resulting in acceptable classification accuracy. Feature selection is a preprocessing technique with great importance in the fields of data analysis and information retrieval processing, pattern classification, and data mining applications. This paper presents a novel optimization algorithm called catfish binary particle swarm optimization (CatfishBPSO), in which the so-called catfish effect is applied to improve the performance of binary particle swarm optimization (BPSO). This effect is the result of the introduction of new particles into the search space ("catfish particles"), which replace particles with the worst fitness by the initialized at extreme points of the search space when the fitness of the global best particle has not improved for a number of consecutive iterations. In this study, the K-nearest neighbor (K-NN) method with leave-one-out cross-validation (LOOCV) was used to evaluate the quality of the solutions. CatfishBPSO was applied and compared to 10 classification problems taken from the literature. Experimental results show that CatfishBPSO simplifies the feature selection process effectively, and either obtains higher classification accuracy or uses fewer features than other feature selection methods. (C) 2011 Elsevier Ltd. All rights reserved.								1	1	0	0	2	0957-4174		WOS:000292169500076	
J	Chuang, Li-Yeh; Yang, Cheng-San; Wu, Kuo-Chuan; Yang, Cheng-Hong				Chuang, Li-Yeh/E-5005-2011				Gene selection and classification using Taguchi chaotic binary particle swarm optimization								EXPERT SYSTEMS WITH APPLICATIONS			38	10			13367	13377		10.1016/j.eswa.2011.04.165			SEP 15 2011	2011	The purpose of gene expression analysis is to discriminate between classes of samples, and to predict the relative importance of each gene for sample classification. Microarray data with reference to gene expression profiles have provided some valuable results related to a variety of problems and contributed to advances in clinical medicine. Microarray data characteristically have a high dimension and a small sample size. This makes it difficult for a general classification method to obtain correct data for classification. However, not every gene is potentially relevant for distinguishing the sample class. Thus, in order to analyze gene expression profiles correctly, feature (gene) selection is crucial for the classification process, and an effective gene extraction method is necessary for eliminating irrelevant genes and decreasing the classification error rate.In this paper, correlation-based feature selection (CFS) and the Taguchi chaotic binary particle swarm optimization (TCBPSO) were combined into a hybrid method. The K-nearest neighbor (K-NN) with leave-one-out cross-validation (LOOCV) method served as a classifier for ten gene expression profiles. Experimental results show that this hybrid method effectively simplifies features selection by reducing the number of features needed. The classification error rate obtained by the proposed method had the lowest classification error rate for all of the ten gene expression data set problems tested. For six of the gene expression profile data sets a classification error rate of zero could be reached. The introduced method outperformed five other methods from the literature in terms of classification error rate. It could thus constitute a valuable tool for gene expression analysis in future studies. (C) 2011 Elsevier Ltd. All rights reserved.								1	1	0	0	2	0957-4174		WOS:000292169500149	
J	Choi, Jinhyuk; Jang, Bongkyu; Kim, Gerard J.								Organizing and presenting geospatial tags in location-based augmented reality								PERSONAL AND UBIQUITOUS COMPUTING			15	6	SI		641	647		10.1007/s00779-010-0343-3			AUG 2011	2011	Recent improvements in the capabilities of smart phones are making the location-based augmented reality services a reality. When widely used, such a system is expected to produce many user-created geospatial tags concentrated at popular and important sites. In this paper, we describe a way to organize and group such geospatial tags (manually or automatically using a nearest neighbor algorithm) and how to efficiently interact to search and find the tag that the user might be interested in. The proposed method was implemented on an Apple iPhone, and an experiment was carried out to verify the improved usability. The results do indicate the advantage of the principle of hierarchical organization of data. We also further found that the "automatic-but-less-accurate" approach is more suitable than "precise-but-manual" due to the dynamic nature of the mobile interaction and less than perfect sensing.								1	0	0	0	1	1617-4909		WOS:000292999900009	
J	Li, Yun; Tu, Kang; Zheng, Siyuan; Wang, Jingfang; Li, Yixue; Hao, Pei; Li, Xuan				jia, lp/H-5750-2011				ASSOCIATION OF FEATURE GENE EXPRESSION WITH STRUCTURAL FINGERPRINTS OF CHEMICAL COMPOUNDS								JOURNAL OF BIOINFORMATICS AND COMPUTATIONAL BIOLOGY			9	4			503	519		10.1142/S0219720011005446			AUG 2011	2011	Exploring the relationship between a chemical structure and its biological function is of great importance for drug discovery. For understanding the mechanisms of drug action, researchers traditionally focused on the molecular structures in the context of interactions with targets. The newly emerged high-throughput "omics" technology opened a new dimension to study the structure-function relationship of chemicals. Previous studies made attempts to introduce transcriptomics data into chemical function investigation. But little effort has been made to link structural fingerprints of compounds with defined intracellular functions, i.e. expression of particular genes and altered pathways. By integrating the chemical structural information with the gene expression profiles of chemical-treated cells, we developed a novel method to associate the structural difference between compounds with the expression of a definite set of genes, which were called feature genes. A subtraction protocol was designed to extract a minimum gene set related to chemical structural features, which can be utilized in practice as markers for drug screening. Case studies demonstrated that our approach is capable of finding feature genes associated with chemical structural fingerprints.								1	0	1	0	1	0219-7200		WOS:000297095500005	
J	Broseus, Julian; Vallat, Morgan; Esseiva, Pierre								Multi-class differentiation of cannabis seedlings in a forensic context								CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS			107	2			343	350		10.1016/j.chemolab.2011.05.004			JUL 2011	2011	This article presents an experimental study about the classification ability of several classifiers for multi-class classification of cannabis seedlings. As the cultivation of drug type cannabis is forbidden in Switzerland law enforcement authorities regularly ask forensic laboratories to determinate the chemotype of a seized cannabis plant and then to conclude if the plantation is legal or not. This classification is mainly performed when the plant is mature as required by the EU official protocol and then the classification of cannabis seedlings is a time consuming and costly procedure. A previous study made by the authors has investigated this problematic Ill and showed that it is possible to differentiate between drug type (illegal) and fibre type (legal) cannabis at an early stage of growth using gas chromatography interfaced with mass spectrometry (GC MS) based on the relative proportions of eight major leaf compounds. The aims of the present work are on one hand to continue former work and to optimize the methodology for the discrimination of drug- and fibre type cannabis developed in the previous study and on the other hand to investigate the possibility to predict illegal cannabis varieties. Seven classifiers for differentiating between cannabis seedlings are evaluated in this paper, namely Linear Discriminant Analysis (LDA). Partial Least Squares Discriminant Analysis (PLS-DA), Nearest Neighbour Classification (NNC), Learning Vector Quantization (LVQ), Radial Basis Function Support Vector Machines (RBF SVMs), Random Forest (RF) and Artificial Neural Networks (ANN). The performance of each method was assessed using the same analytical dataset that consists of 861 samples split into drug- and fibre type cannabis with drug type cannabis being made up of 12 varieties (i.e. 12 classes). The results show that linear classifiers are not able to manage the distribution of classes in which some overlap areas exist for both classification problems. Unlike linear classifiers. NNC and RBF SVMs best differentiate cannabis samples both for 2-class and 12-class classifications with average classification results up to 99% and 98%, respectively. Furthermore, RBF SVMs correctly classified into drug type cannabis the independent validation set, which consists of cannabis plants coming from police seizures. In forensic case work this study shows that the discrimination between cannabis samples at an early stage of growth is possible with fairly high classification performance for discriminating between cannabis chemotypes or between drug type cannabis varieties. (C) 2011 Elsevier B.V. All rights reserved.								1	0	0	0	1	0169-7439		WOS:000293263600014	
J	Zeng, Qiangguang; Yue, Guangxue; Li, Renfa								Prediction of Protein Functional Class from Pseudo-Amino Acid Composition								JOURNAL OF COMPUTATIONAL AND THEORETICAL NANOSCIENCE			8	7			1247	1251		10.1166/jctn.2011.1805			JUL 2011	2011	Pseudo-amino acid composition approach has been successfully applied to prediction of protein subcellular localization and protein structure class and so on. In this paper, pseudo-amino acid composition is used to express a protein as a non-zero vector. The machine learning method K nearest neighbor method (K-NNA) is proposed for predicting protein functional classes from this information. The Euclidean distance and Mahalanobis distance are used to measure the similarity in K-NNA classification algorithm. Good results show that pseudo-amino acid composition of protein sequences used to predict other nature of protein can also be applied to the prediction of protein functional classes.								1	0	0	0	1	1546-1955		WOS:000291846800022	
J	Huang, Shian-Chang; Wu, Cheng-Feng								Customer credit quality assessments using data mining methods for banking industries								AFRICAN JOURNAL OF BUSINESS MANAGEMENT			5	11			4438	4445					JUN 4 2011	2011	Personal credit scoring on credit cards has been a critical issue in the banking industry. The bank with the most accurate estimation of its customer credit quality will be the most profitable. The study aims to compare quality prediction models from data mining methods, and improve traditional models by using boosting and genetic algorithms (GA). The predicting models used are instant-based classifiers (such as k-nearest neighbors), Bayesian networks, decision trees, decision tables, logistic regressions, radial basis function neural networks, and support vector machines. Three boosting (or ensemble) algorithms used for performance enhancement are AdaBoost, LogitBoost, and MultiBoost. The mentioned algorithms are optimized by GA for input features. Empirical results indicated that GA substantially improves the performance of underlying classifiers. Considering robustness and reliability, combining GA with ensemble classifiers is better than traditional models. Especially, integrating GA with LogitBoost (C4.5) is the most effective and compact model for credit quality evaluations.								1	0	0	0	1	1993-8233		WOS:000294951200045	
J	Chan, W. K.; Chiu, Yuen Yau; Yu, Yuen Tak								A web search-centric approach to recommender systems with URLs as minimal user contexts								JOURNAL OF SYSTEMS AND SOFTWARE			84	6			930	941		10.1016/j.jss.2011.01.032			JUN 2011	2011	In service-oriented computing, a recommender system can be wrapped as a web service with machine-readable interface. However, owing to the cross-organizational privacy issue, the internal dataset of an organization is seldom exposed to external services. In this paper, we propose a higher level recommender strategy INSERT that guides the underlying external universal recommender to suggest a set of indexes. INSERT then matches the title of each top-ranked index entry with the domain-specific keywords in the organization's internal dataset, and further directs the universal recommender to verify the popularity of such matching. INSERT finally makes recommendation based on the verification results. INSERT also employs URLs taken from a client as user contexts, which is challenging because URLs contain little content. Our experiment shows that this strategy is feasible and effective. (C) 2011 Elsevier Inc. All rights reserved.								1	0	0	0	1	0164-1212		WOS:000290073600004	
J	Haehnke, Volker; Klenner, Alexander; Rippmann, Friedrich; Schneider, Gisbert								Pharmacophore Alignment Search Tool: Influence of the Third Dimension on Text-Based Similarity Searching								JOURNAL OF COMPUTATIONAL CHEMISTRY			32	8			1618	1634		10.1002/jcc.21742			JUN 2011	2011	Previously (Hahnke et al., J Comput Chem 2010, 31, 2810) we introduced the concept of nonlinear dimensionality reduction for canonization of two-dimensional layouts of molecular graphs as foundation for text-based similarity searching using our Pharmacophore Alignment Search Tool (PhAST), a ligand-based virtual screening method. Here we apply these methods to three-dimensional molecular conformations and investigate the impact of these additional degrees of freedom on virtual screening performance and assess differences in ranking behavior. Best-performing variants of PhAST are compared with 16 state-of-the-art screening methods with respect to significance estimates for differences in screening performance. We show that PhAST sorts new chemotypes on early ranks without sacrificing overall screening performance. We succeeded in combining PhAST with other virtual screening techniques by rank-based data fusion, significantly improving screening capabilities. We also present a parameterization of double dynamic programming for the problem of small molecule comparison, which allows for the calculation of structural similarity between compounds based on one-dimensional representations, opening the door to a holistic approach to molecule comparison based on textual representations. (C) 2011 Wiley Periodicals, Inc. J Comput Chem 32: 1618-1634, 2011								1	0	1	0	1	0192-8651		WOS:000289429200013	
J	Yu, Guang; Yang, Dong-Hui; He, Hui-Xin								An automatic recognition method of journal impact factor manipulation								JOURNAL OF INFORMATION SCIENCE			37	3			235	245		10.1177/0165551511400954			JUN 2011	2011	Journal impact factor (IF) manipulation has unhealthy effects on the academic community and is attracting more attention from scholars. In this paper, an intelligent method is proposed to identify manipulative self-citation behaviour in journals using pattern recognition. Data on IFs, age distributions of total citations, and numbers of self-citations were collected for 18 journals from 1998 to 2007 in Journal Citation Reports (JCR); these journals include known manipulated journals. The feature variables of the citation distribution functions of the known manipulated journals were extracted using the k-nearest neighbour classifier, and a feature attribute space was established for pattern recognition. The MATLAB software was used to process, train, and test the data and to develop a suitable matrix model which can provide an original model for identifying other manipulated journals. To verify the validity and reliability of this method, the authors randomly collected citation distribution data from several journals in JCR, analysed the results of the verification, and proved the effectiveness of pattern recognition in this context.								1	0	1	0	1	0165-5515		WOS:000291476000002	
J	Li, Wen; Miao, Duoqian; Wang, Weili								Two-level hierarchical combination method for text classification								EXPERT SYSTEMS WITH APPLICATIONS			38	3			2030	2039		10.1016/j.eswa.2010.07.139			MAR 2011	2011	Text classification has been recognized as one of the key techniques in organizing digital data. The intuition that each algorithm has its bias data and build a high performance classifier via some combination of different algorithm is a long motivation. In this paper, we proposed a two-level hierarchical algorithm that systematically combines the strength of support vector machine (SVM) and k nearest neighbor (KNN) techniques based on variable precision rough sets (VPRS) to improve the precision of text classification. First, an extension of regular SVM named variable precision rough SVM (VPRSVM), which partitions the feature space into three kinds of approximation regions, is presented. Second, a modified KNN algorithm named restrictive k nearest neighbor (RKNN) is put forward to reclassify texts in boundary region effectively and efficiently. The proposed algorithm overcomes the drawbacks of sensitive to noises of SVM and low efficiency of KNN. Experimental results compared with traditional algorithms indicate that the proposed method can improve the overall performance significantly. (C) 2010 Elsevier Ltd. All rights reserved.								1	0	0	0	1	0957-4174		WOS:000284863200083	
J	Syed, Zeeshan; Guttag, John								Unsupervised Similarity-Based Risk Stratification for Cardiovascular Events Using Long-Term Time-Series Data								JOURNAL OF MACHINE LEARNING RESEARCH			12				999	1024					MAR 2011	2011	In medicine, one often bases decisions upon a comparative analysis of patient data. In this paper, we build upon this observation and describe similarity-based algorithms to risk stratify patients for major adverse cardiac events. We evolve the traditional approach of comparing patient data in two ways. First, we propose similarity-based algorithms that compare patients in terms of their long-term physiological monitoring data. Symbolic mismatch identifies functional units in long-term signals and measures changes in the morphology and frequency of these units across patients. Second, we describe similarity-based algorithms that are unsupervised and do not require comparisons to patients with known outcomes for risk stratification. This is achieved by using an anomaly detection framework to identify patients who are unlike other patients in a population and may potentially be at an elevated risk. We demonstrate the potential utility of our approach by showing how symbolic mismatch-based algorithms can be used to classify patients as being at high or low risk of major adverse cardiac events by comparing their long-term electrocardiograms to that of a large population. We describe how symbolic mismatch can be used in three different existing methods: one-class support vector machines, nearest neighbor analysis, and hierarchical clustering. When evaluated on a population of 686 patients with available long-term electrocardiographic data, symbolic mismatch-based comparative approaches were able to identify patients at roughly a two-fold increased risk of major adverse cardiac events in the 90 days following acute coronary syndrome. These results were consistent even after adjusting for other clinical risk variables.								1	0	1	0	1	1532-4435		WOS:000289635000008	
J	Jin, Xin; Guo, Yin; Sarkar, Soumik; Ray, Asok; Edwards, Robert M.				Jin, Xin/H-5022-2012				Anomaly Detection in Nuclear Power Plants via Symbolic Dynamic Filtering					2			IEEE TRANSACTIONS ON NUCLEAR SCIENCE			58	1			277	288		10.1109/TNS.2010.2088138			FEB 2011	2011	Tools of sensor-data-driven anomaly detection facilitate condition monitoring of dynamical systems especially if the physics-based models are either inadequate or unavailable. Along this line, symbolic dynamic filtering (SDF) has been reported in literature as a real-time data-driven tool of feature extraction for pattern identification from sensor time series. However, an inherent difficulty for a data-driven tool is that the quality of detection may drastically suffer in the event of sensor degradation. This paper proposes an anomaly detection algorithm for condition monitoring of nuclear power plants, where symbolic feature extraction and the associated pattern classification are optimized by appropriate partitioning of (possibly noise-contaminated) sensor time series. In this process, the system anomaly signatures are identified by masking the sensor degradation signatures. The proposed anomaly detection methodology is validated on the International Reactor Innovative & Secure (IRIS) simulator of nuclear power plants, and its performance is evaluated by comparison with that of principal component analysis (PCA).								1	0	0	0	1	0018-9499		WOS:000287086200015	
S	Chen, Hui-Ling; Liu, Da-You; Yang, Bo; Liu, Jie; Wang, Gang; Wang, Su-Jing						Huang, JZ; Cao, L; Srivastava, J		An Adaptive Fuzzy k-Nearest Neighbor Method Based on Parallel Particle Swarm Optimization for Bankruptcy Prediction					1			ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PT I: 15TH PACIFIC-ASIA CONFERENCE, PAKDD 2011	Lecture Notes in Artificial Intelligence		6634				249	264					2011	2011	This study proposes an efficient non-parametric classifier for bankruptcy prediction using an adaptive fuzzy k-nearest neighbor (FKNN) method, where the nearest neighbor k and the fuzzy strength parameter m are adaptively specified by the particle swarm optimization (PSO) approach. In addition to performing the parameter optimization for FKNN, PSO is utilized to choose the most discriminative subset of features for prediction as well. Time varying acceleration coefficients (TVAC) and inertia weight (TVIW) are employed to efficiently control the local and global search ability of PSO. Moreover, both the continuous and binary PSO are implemented in parallel on a multi-core platform. The resultant bankruptcy prediction model, named PTVPSO-FKNN, is compared with three classification methods on a real-world case. The obtained results clearly confirm the superiority of the developed model as compared to the other three methods in terms of Classification accuracy, Type I error, Type II error and AUC (area under the receiver operating characteristic (ROC) curve) criterion. It is also observed that the PTVPSO-FKNN is a powerful feature selection tool which has indentified a subset of best discriminative features. Additionally, the proposed model has gained a great deal of efficiency in terms of CPU time owing to the parallel implementation.				15th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD)	MAY 24-27, 2011	Shenzhen Inst Adv Technol; Chinese Acad Sci; Univ Hong Kong; Univ Technol Sydney	Shenzhen, PEOPLES R CHINA	1	0	0	0	1	0302-9743	978-3-642-20840-9	WOS:000312259200021	
S	Dai, Bi-Ru; Hsu, Shu-Ming						Huang, JZ; Cao, L; Srivastava, J		An Instance Selection Algorithm Based on Reverse Nearest Neighbor					1			ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PT I: 15TH PACIFIC-ASIA CONFERENCE, PAKDD 2011	Lecture Notes in Artificial Intelligence		6634				1	12					2011	2011	Data reduction is to extract a subset from a dataset. The advantages of data reduction are decreasing the requirement of storage and increasing the efficiency of classification. Using the subset as training data is possible to maintain classification accuracy; sometimes, it can be further improved because of eliminating noises. The key is how to choose representative samples while ignoring noises at the same time. Many instance selection algorithms are based on nearest neighbor decision rule (NN). Some of these algorithms select samples based on two strategies, incremental and decremental. The first type of algorithms select some instances as samples and iteratively add instances which do not have the same class label with their nearest sample to the sample set. The second type of algorithms remove instances which do not have the same class label with their majority of kNN. However, we propose an algorithm based on Reverse Nearest Neighbor (RNN), called the Reverse Nearest Neighbor Reduction (RNNR). RNNR selects samples which can represent other instances in the same class. In addition, RNNR does not need to iteratively scan a dataset which takes much processing time. Experimental results show that RNNR achieves comparable accuracy and selects fewer samples than comparators.				15th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD)	MAY 24-27, 2011	Shenzhen Inst Adv Technol; Chinese Acad Sci; Univ Hong Kong; Univ Technol Sydney	Shenzhen, PEOPLES R CHINA	1	0	0	0	1	0302-9743	978-3-642-20840-9	WOS:000312259200001	
S	Garcia, Vicente; Sanchez, J. Salvador; Mollineda, Ramon A.						Vitria, J; Sanches, JM; Hernandez, M		Classification of High Dimensional and Imbalanced Hyperspectral Imagery Data								PATTERN RECOGNITION AND IMAGE ANALYSIS: 5TH IBERIAN CONFERENCE, IBPRIA 2011	Lecture Notes in Computer Science		6669				644	651					2011	2011	The present paper addresses the problem of the classification of hyperspectral images with multiple imbalanced classes and very high dimensionality. Class imbalance is handled by resampling the data set, whereas PCA is applied to reduce the number of spectral bands. This is a preliminary study that pursues to investigate the benefits of using together these two techniques, and also to evaluate the application order that leads to the best classification performance. Experimental results demonstrate the significance of combining these preprocessing tools to improve the performance of hyperspectral imagery classification. Although it seems that the most effective order of application corresponds to first a resampling algorithm and then PCA, this is a question that still needs a much more thorough investigation.				5th Iberian Conference on Pattern Recognition and Image Analysis (IbPRIA)	JUN 08-10, 2011	Asociacion Espanola Reconocimiento Formas Analisis Imagenes (AERFAI); Assoc Portuguesa Reconhecimento Padroes (APRP)	Univ Las Palmas Gran Canaria (ULPGC), Las Palmas, SPAIN	1	0	0	0	1	0302-9743	978-3-642-21256-7	WOS:000300552200080	
J	Hu, Qinghua; Zhu, Pengfei; Yang, Yongbin; Yu, Daren								Large-margin nearest neighbor classifiers via sample weight learning								NEUROCOMPUTING			74	4			656	660		10.1016/j.neucom.2010.09.006			JAN 2011	2011	The nearest neighbor classification is a simple and yet effective technique for pattern recognition. Performance of this technique depends significantly on the distance function used to compute similarity between examples. Some techniques were developed to learn weights of features for changing the distance structure of samples in nearest neighbor classification. In this paper, we propose an approach to learning sample weights for enlarging margin by using a gradient descent algorithm to minimize margin based classification loss. Experimental analysis shows that the distances trained in this way reduce the loss of the margin and enlarge the hypothesis margin on several datasets. Moreover, the proposed approach consistently outperforms nearest neighbor classification and some other state-of-the-art methods. (c) 2010 Elsevier B.V. All rights reserved.								1	0	0	0	1	0925-2312		WOS:000286697800018	
S	Jiang, Hao; Hallstrom, Jason O.						Marron, PJ; Whitehouse, K		Fast, Accurate Event Classification on Resource-Lean Embedded Sensors								WIRELESS SENSOR NETWORKS	Lecture Notes in Computer Science		6567				65	80					2011	2011	In wireless sensing applications, it is often necessary to identify high-level events based on low-level sensor signals. Due to the limited computing and energy resources available on existing hardware platforms, achieving high precision classification of high-level events in-network is a challenge, hi this paper, we present a new classification technique for identifying events of interest on resource-lean sensors. The approach introduces an innovative condensed kd-tree data structure to represent processed sensor data and uses a fast nearest neighbor search to determine the likelihood of class membership for incoming samples. The classifier consumes limited resources and provides high precision classification. To evaluate the approach, two case studies are considered, in the contexts of human movement and vehicle navigation, respectively. The classification accuracy is above 85% across the two case studies.				8th European Conference on Wireless Sensor Networks	FEB 23-25, 2011	Univ Duisburg Essen,Networked Embedded Syst Grp; CONET, Network of Excellence; Boeing; Libelium	Bonn, GERMANY	1	0	0	0	1	0302-9743	978-3-642-19185-5	WOS:000296829600005	
B	Luque, R. M.; Elizondo, D.; Lopez-Rubio, E.; Palomo, E. J.			IEEE					GA-based Feature Selection Approach in Biometric Hand Systems								2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)							246	253					2011	2011	In this paper, a novel methodology for using feature selection in hand biometric systems, based on genetic algorithms and mutual information is presented. A hand segmentation algorithm based on adaptive threshold and active contours is also applied, in order to deal with complex backgrounds and non-homogeneous illumination.The aim of this methodology is two-fold. On the one hand, getting robust features in biometric systems with no restriction in the hand-pose and in its orientation with regard to the camera. On the other hand, providing a subset of features which reduce the complexity of the identification process and maximize the generalization rate of the classifiers.By using the IITD Palmprint Database, which is an example of such free hand-pose biometric systems, the experimental results show that it is not always necessary to apply sophisticated classification methods to obtain good accuracy results. Simple classifiers such as kNN and LDA together with this feature selection approach, get even better generalisation rates than other more elaborate and complex methods.				International Joint Conference on Neural Networks (IJCNN)	JUL 31-AUG 05, 2011	Int Neural Network Soc (INNS); IEEE Computat Intelligence Soc (CIS); Natl Sci Fdn (NSF); Cognimem Technol, Inc; Univ Cincinnati Coll Engn & Appl Sci; Toyota Res Inst N Amer; Univ Cincinnati, Sch Elect & Compu Syst	San Jose, CA	1	0	1	0	1		978-1-4244-9636-5	WOS:000297541200038	
S	Paulson, Christopher; Wu, Dapeng						Zelnio, EG; Garber, FD		Feature phenomenology and feature extraction of civilian vehicles from SAR images								ALGORITHMS FOR SYNTHETIC APERTURE RADAR IMAGERY XVIII	Proceedings of SPIE		8051						80510X	10.1117/12.887594			2011	2011	Being able to recognize one object from another is vital research to our society because it can save lives, improve national security, and improve existing technology such as object avoidance, tracking, etc. In this research we are trying to classify Synthetic Aperture Radar (SAR) images of vehicles from one another no matter if the vehicle is rotated or occluded. The dataset that is being used for this research is the Commercial Vehicle (CV) Data Domes obtained from Wright Patterson Air Force Base (WPAFB). To accomplish this task we used Local Feature Extraction (LFE) to extract the features and then K-nearest neighbor (KNN) was used to classify the vehicles. Overall this method performed well in that the algorithm was able to correctly identify the vehicles 97.6% to 100% accuracy. Currently the algorithm can not handle translation, so the next step of this research is to be able to use the glint information to register the vehicles to a desired location and then perform our algorithm which we believe that registering the image would have a significant improvement to the current results.				Conference on Algorithms for Synthetic Aperture Radar Imagery XVIII	APR 27-28, 2011	SPIE	Orlando, FL	1	0	0	0	1	0277-786X	978-0-81948-625-7	WOS:000295118700027	
B	Pu, Pearl; Faltings, Boi; Chen, Li; Zhang, Jiyong; Viappiani, Paolo						Ricci, F; Rokach, L; Shapira, B; Kantor, PB		Usability Guidelines for Product Recommenders Based on Example Critiquing Research								RECOMMENDER SYSTEMS HANDBOOK							511	545		10.1007/978-0-387-85820-3_16	10.1007/978-0-387-85820-3		2011	2011	Over the past decade, our group has developed a suite of decision tools based on example critiquing to help users find their preferred products in e-commerce environments. In this chapter, we survey important usability research work relative to example critiquing and summarize the major results by deriving a set of usability guidelines. Our survey is focused on three key interaction activities between the user and the system: the initial preference elicitation process, the preference revision process, and the presentation of the systems recommendation results. To provide a basis for the derivation of the guidelines, we developed a multi-objective framework of three interacting criteria: accuracy, confidence, and effort (ACE). We use this framework to analyze our past work and provide a specific context for each guideline: when the system should maximize its ability to increase users' decision accuracy, when to increase user confidence, and when to minimize the interaction effort for the users. Due to the general nature of this multi-criteria model, the set of guidelines that we propose can be used to ease the usability engineering process of other recommender systems, especially those used in e-commerce environments. The ACE framework presented here is also the first in the field to evaluate the performance of preference-based recommenders from a user-centric point of view.Designers can use these guidelines for the implementation of an effective and successful product recommender.								1	0	0	0	1		978-0-387-85819-7	WOS:000293099300016	
J	Pughineanu, C.; Balan, I.				Suceava, USV/E-8611-2011				Parallel Algorithm Evaluation in the Image and Clustering Processing								ELEKTRONIKA IR ELEKTROTECHNIKA				4			89	92					2011	2011	C. Pughineanu, I. Balan. Parallel Algorithm Evaluation in the Image and Clustering Processing // Electronics and Electrical Engineering. - Kaunas: Technologija, 2011. - No. 4(110). - P. 89-92.The increase of the information volume of the image type in the greatest part of the domains asks for the introduction of some storage and efficient recovery methods of the available data due to content. Unfortunately, the progress registered in the field of the multimedia databases with digital images is not remarkable as being outdated by info explosion. The article proposes compression algorithms aiming to reduce the quantity of data necessary to represent an image and the necessary clustering algorithms, namely the k-means algorithm and ISODATA, which were parallelized both from the point of view of the extracted areas and the execution time. The experimental results were obtained by the implementation of the algorithms using the MPI standard and their execution on a cluster. Ill. 12, bibl. 16 (in English; abstracts in English and Lithuanian).								1	0	0	0	1	1392-1215		WOS:000290422000020	
J	Reischl, Markus; Groell, Lutz; Mikut, Ralf				Mikut, Ralf /A-5949-2013				Evaluation of data mining approaches for the control of multifunctional arm prostheses								INTEGRATED COMPUTER-AIDED ENGINEERING			18	3			235	249		10.3233/ICA-2011-0374			2011	2011	Commercially available hand prostheses are controlled by myoelectric signals, biosignals that must be accurately interpreted if a prosthesis is to work effectively. We propose the use of standardized muscle contractions to select grasp types; these are taught to the prosthesis using data mining methods and parameters individually adapted from the patient. Embedded systems in medical devices often restrict the application of classification algorithms due to a lack of computational power and memory; therefore, important issues for the design of medical devices are not only classification accuracy, but also computational complexity and low assignment of memory. This paper introduces a new method for feature selection and examines techniques for feature dimension reduction, namely feature selection and aggregation. Wrapper approaches with modified measures were introduced to improve classification results; the effects of this approach are discussed using a synthetic benchmark. Our analysis of measured biosignals, obtained from the control of hand prosthesis by seven different subjects, demonstrates that the proposed approach works for real-world problems.								1	0	0	0	1	1069-2509		WOS:000292915800004	
S	Triguero, Isaac; Garcia, Salvador; Herrera, Francisco				Herrera, Francisco/C-6856-2008	Herrera, Francisco/0000-0002-7283-312X	Corchado, E; Kurzynski, M; Wozniak, M		Enhancing IPADE Algorithm with a Different Individual Codification								HYBRID ARTIFICIAL INTELLIGENT SYSTEMS, PART II	Lecture Notes in Artificial Intelligence		6679				262	270					2011	2011	Nearest neighbor is one of the most used techniques for performing classification tasks. However, its simplest version has several drawbacks, such as low efficiency, storage requirements and sensitivity to noise. Prototype generation is an appropriate process to alleviate these drawbacks that allows the fitting of a data set for nearest neighbor classification. In this work, we present an extension of our previous proposal called IPADE, a methodology to learn iteratively the positioning of prototypes using a differential evolution algorithm. In this extension, which we have called IPADECS, a complete solution is codified in each individual. The results are contrasted with non-parametrical statistical tests and show that our proposal outperforms previously proposed methods.				6th International Conference on Hybrid Artificial Intelligence Systems (HAIS 2011)	MAY 23-25, 2011	Wroclaw Univ Technol; IEEE Systems, Man & Cybernet Soc, Spanish Chapter; IEEE Systems, Man & Cybernet Soc, Czech Republ Chapter; Spanish Assoc Artificial Intelligence; MIR LABS; Int Federat Computat Logic	Wroclaw Univ Technol, Wroclaw, POLAND	1	0	0	0	1	0302-9743	978-3-642-21221-5	WOS:000297712800032	
S	Wang, Wenmin						AbdManaf, A; Sahibuddin, S; Ahmad, R; Daud, SM; ElQawasmeh, E		Taxonomical Classification of Closely Related Reads of Genus Bacillus								INFORMATICS ENGINEERING AND INFORMATION SCIENCE, PT IV	Communications in Computer and Information Science		254				395	404					2011	2011	The genus Bacillus contain spore-forming gram-positive/variable rodshaped bacteria. Species of the Bacillus genus have long believed to have medical, veterinary and agricultural importance. In agricultural biotechnology and its applications, discriminating short environmental Bacillus DNA fragments into its various species members plays a crucial role in the pipeline of agronomic trait discovery and insect control. We here constructed a classification model for this challenging task based on consensus decision-making of support vector machines and BLAST hit strategies. We first took advantage of both the hexamer signatures of Bacillus genomes and the Bacillus species-specific toxin signatures to build the attribute space. We then explored and filtered the otherwise high dimensional attribute space with a weighted version of principal component analysis to mitigate computational cost and avoid possible overfitting of the classification model for discriminating Bacillus species. Our extensive experimental results showed that our method can perform well on differentiating Bacillus species.				International Conference on Informatics Engineering and Information Science (ICIEIS 2011)	NOV 14-16, 2011	Springer	Univ Teknol Malaysia, Kuala Lumpur, MALAYSIA	1	0	1	0	1	1865-0929	978-3-642-25482-6	WOS:000310937500032	
J	Xu, Chao; Mager, Donald E.				xu, chao/J-3781-2013	xu, chao/0000-0002-4574-0059			Quantitative structure-pharmacokinetic relationships								EXPERT OPINION ON DRUG METABOLISM & TOXICOLOGY			7	1			63	77		10.1517/17425255.2011.537257			JAN 2011	2011	Areas covered in this review: Empirical and mechanism-based QSPKR models are discussed, including specific examples for oral absorption, nonspecific protein binding, volume of distribution, total metabolic stability and specific interactions with drug metabolizing enzymes. Emphasis is placed on state-of-the-art techniques, including new approaches for the direct simulation of concentration-time profiles from molecular descriptors (temporal QSPKR).What the reader will gain: Reviewing the application of current QSPKR modeling techniques will place these methods in context and highlight their respective advantages and limitations, as well as opportunities for further refinement.Take home message: The expansion of readily available molecular descriptors and advanced algorithms has improved empirical models and enabled the development of robust models for non-congeneric series. Empirical models focus on point estimates of global PK processes and physiologically-based models may be more desirable than data-driven methods. Further integration of relevant biological and pharmacological mechanisms will improve the ability to predict the full time course of drug concentration and effect profiles for diverse compounds and experimental conditions.								1	0	1	0	1	1742-5255		WOS:000285415300005	
J	Doderer, Mark S.; Yoon, Kihoon; Robbins, Kay A.								SIDEKICK: Genomic data driven analysis and decision-making framework								BMC BIOINFORMATICS			11						611	10.1186/1471-2105-11-611			DEC 30 2010	2010	Background: Scientists striving to unlock mysteries within complex biological systems face myriad barriers in effectively integrating available information to enhance their understanding. While experimental techniques and available data sources are rapidly evolving, useful information is dispersed across a variety of sources, and sources of the same information often do not use the same format or nomenclature. To harness these expanding resources, scientists need tools that bridge nomenclature differences and allow them to integrate, organize, and evaluate the quality of information without extensive computation.Results: Sidekick, a genomic data driven analysis and decision making framework, is a web-based tool that provides a user-friendly intuitive solution to the problem of information inaccessibility. Sidekick enables scientists without training in computation and data management to pursue answers to research questions like "What are the mechanisms for disease X" or "Does the set of genes associated with disease X also influence other diseases." Sidekick enables the process of combining heterogeneous data, finding and maintaining the most up-to-date data, evaluating data sources, quantifying confidence in results based on evidence, and managing the multi-step research tasks needed to answer these questions. We demonstrate Sidekick's effectiveness by showing how to accomplish a complex published analysis in a fraction of the original time with no computational effort using Sidekick.Conclusions: Sidekick is an easy-to-use web-based tool that organizes and facilitates complex genomic research, allowing scientists to explore genomic relationships and formulate hypotheses without computational effort. Possible analysis steps include gene list discovery, gene-pair list discovery, various enrichments for both types of lists, and convenient list manipulation. Further, Sidekick's ability to characterize pairs of genes offers new ways to approach genomic analysis that traditional single gene lists do not, particularly in areas such as interaction discovery.								1	0	1	0	1	1471-2105		WOS:000286189400001	
J	Quirino, Thiago; Kubat, Miroslav; Bryan, Nicholas J.								Instinct-Based Mating in Genetic Algorithms Applied to the Tuning of 1-NN Classifiers								IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			22	12			1724	1737		10.1109/TKDE.2009.211			DEC 2010	2010	The behavior of the genetic algorithm (GA), a popular approach to search and optimization problems, is known to depend, among other factors, on the fitness function formula, the recombination operator, and the mutation operator. What has received less attention is the impact of the mating strategy that selects the chromosomes to be paired for recombination. Existing GA implementations mostly choose them probabilistically, according to their fitness function values, but we show that more sophisticated mating strategies can not only accelerate the search, but perhaps even improve the quality of the GA-generated solution. In our implementation, we took inspiration from the "opposites-attract" principle that is so common in nature. As a testbed, we chose the problem of 1-NN classifier tuning where genetic solutions have been employed before, and are thus well-understood by the research community. We propose three "instinct-based" mating strategies and experimentally investigate their behaviors.								1	0	0	0	1	1041-4347		WOS:000283133800006	
J	Franco, Annalisa; Maltoni, Davide; Nanni, Loris								Data pre-processing through reward-punishment editing								PATTERN ANALYSIS AND APPLICATIONS			13	4			367	381		10.1007/s10044-010-0182-x			NOV 2010	2010	The nearest neighbor (NN) classifier represents one of the most popular non-parametric classification approaches and has been successfully applied in several pattern recognition problems. The two main limitations of this technique are its computational complexity and its sensitivity to the presence of outliers in the training set. Though the first problem has been partially overcome thanks to the availability of inexpensive memory and high processing speeds, the second one still persists, and several editing and condensing techniques have been proposed, aimed at selecting a proper set of prototypes from the training set. In this work, an editing technique is proposed, based on the idea of rewarding the patterns that contribute to a correct classification and punishing those that provide a wrong one. The analysis is carried out both at local and at global level, by analyzing the training set at different scales. A score is calculated for each pattern, and the patterns whose score is lower than a predefined threshold are edited out. An extensive experimentation has been conducted on several classification problems both to evaluate the efficacy of the proposed technique with respect to other editing approaches and to investigate the advantage of using reward-punishment editing in combination with condensing techniques or as a pre-processing stage when classifiers different from the NN are adopted.								1	0	0	0	1	1433-7541		WOS:000283304500001	
J	Lee, Heesung; Hong, Sungjun; Nizami, Imran Fareed; Kim, Euntai								An efficient design of a nearest neighbor classifier for various-scale problems								PATTERN RECOGNITION LETTERS			31	9			1020	1027		10.1016/j.patrec.2010.01.001			JUL 1 2010	2010	By appropriate editing of the reference set and judicious selection of features, we can obtain an optimal nearest neighbor (NN) classifier that maximizes the accuracy of classification and saves computational time and memory resources. In this paper, we propose a new method for simultaneous reference set editing and feature selection for a nearest neighbor classifier. The proposed method is based on the genetic algorithm and employs different genetic encoding strategies according to the size of the problem, such that it can be applied to classification problems of various scales. Compared with the conventional methods, the classifier uses some of the considered references and features, not all of them, but demonstrates better classification performance. To demonstrate the performance of the proposed method, we perform experiments on various databases. (C) 2010 Elsevier B.V. All rights reserved.								1	0	0	0	1	0167-8655		WOS:000278186200029	
J	Zhu, Xiaoyan; Song, Qinbao; Jia, Zihan								A Weighted Voting-Based Associative Classification Algorithm								COMPUTER JOURNAL			53	6			786	801		10.1093/comjnl/bxp074			JUL 2010	2010	A new associative classification algorithm based on weighted voting (ACWV) is presented. ACWV takes advantage of two methods: the optimal rule method preferring high-quality rules and the voting method considering the majority of the rules. Moreover, the method takes into account both the length and convictions of rules to calculate their weights. First, ACWV builds a class-count FP-tree (called CCFP-tree) from the given historical data. After that, the weighted voting result for a new instance can be obtained from the CCFP-tree directly without storing, retrieving and sorting rules explicitly. The label of the class with maximal sum of weighted votes is then that of the new instance. Results of the experiments with 36 data sets selected from the UCI machine learning repository show that the proposed method has its advantages in comparison with previous methods in terms of classification accuracy.								1	1	1	0	2	0010-4620		WOS:000279185400012	
J	Whiting, Jeffrey S.; Dinerstein, Jonathan; Egbert, Parris K.; Ventura, Dan								COGNITIVE AND BEHAVIORAL MODEL ENSEMBLES FOR AUTONOMOUS VIRTUAL CHARACTERS								COMPUTATIONAL INTELLIGENCE			26	2			142	159					MAY 2010	2010	Cognitive and behavioral models have become popular methods for creating autonomous self-animating characters. Creating these models present the following challenges: (1) creating a cognitive or behavioral model is a time-intensive and complex process that must be done by an expert programmer and (2) the models are created to solve a specific problem in a given environment and because of their specific nature cannot be easily reused. Combining existing models together would allow an animator, without the need for a programmer, to create new characters in less time and to leverage each model's strengths, resulting in an increase in the character's performance and in the creation of new behaviors and animations. This article provides a framework that can aggregate existing behavioral and cognitive models into an ensemble. An animator has only to rate how appropriately a character performs in a set of scenarios and the system then uses machine learning to determine how the character should act given the current situation. Empirical results from multiple case studies validate the approach.								1	0	0	0	1	0824-7935		WOS:000277083200002	
J	Zheng, Wenming; Lin, Zhouchen; Tang, Xiaoou				Tang, Xiaoou/G-6509-2012				A Rank-One Update Algorithm for Fast Solving Kernel Foley-Sammon Optimal Discriminant Vectors								IEEE TRANSACTIONS ON NEURAL NETWORKS			21	3			393	403		10.1109/TNN.2009.2037149			MAR 2010	2010	Discriminant analysis plays an important role in statistical pattern recognition. A popular method is the Foley-Sammon optimal discriminant vectors (FSODVs) method, which aims to find an optimal set of discriminant vectors that maximize the Fisher discriminant criterion under the orthogonal constraint. The FSODVs method outperforms the classic Fisher linear discriminant analysis (FLDA) method in the sense that it can solve more discriminant vectors for recognition. Kernel Foley-Sammon optimal discriminant vectors (KFSODVs) is a nonlinear extension of FSODVs via the kernel trick. However, the current KFSODVs algorithm may suffer from the heavy computation problem since it involves computing the inverse of matrices when solving each discriminant vector, resulting in a cubic complexity for each discriminant vector. This is costly when the number of discriminant vectors to be computed is large. In this paper, we propose a fast algorithm for solving the KFSODVs, which is based on rank-one update (ROU) of the eigensytems. It only requires a square complexity for each discriminant vector. Moreover, we also generalize our method to efficiently solve a family of optimally constrained generalized Rayleigh quotient (OCGRQ) problems which include many existing dimensionality reduction techniques. We conduct extensive experiments on several real data sets to demonstrate the effectiveness of the proposed algorithms.								1	0	0	0	1	1045-9227		WOS:000275040300003	
J	Boostani, Reza; Dehzangi, Omid; Jarchi, Delaram; Zolghadri, Mansoor J.								AN EFFICIENT PATTERN CLASSIFICATION APPROACH: COMBINATION OF WEIGHTED LDA WITH WEIGHTED NEAREST NEIGHBOR								NEURAL NETWORK WORLD			20	5			621	635					2010	2010	Linear discriminant analysis (LDA) is a versatile method in all pattern recognition fields but it suffers from some limitations. In a multi-class problem, when samples of a class are far from other classes samples, it leads to bias of the whole decision boundaries of LDA in favor of the farthest class. To overcome this drawback, this study is aimed at minimizing this bias by redefining the between- and within-class scatter matrices via incorporating weight vectors derived from Fisher value of classes pairs. After projecting the input patterns into a lower-dimensional space in which the class samples are more separable, a new version of nearest neighbor (NN) method with an adaptive distance measure is employed to classify the transformed samples. To speed up the adaptive distance routine, an iterative learning algorithm that minimizes the error rate is presented. This efficient method is applied to six standard datasets driven from the UCI repository dataset and test results are evaluated from three aspects in terms of accuracy, robustness, and complexity. Results show the supremacy of the proposed two-layer classifier in comparison with the combination of different versions of LDA and NN methods from the three points of view. Moreover, the proposed classifier is assessed in the noisy environment of those datasets and the achieved results confirm the high robustness of the introduced scheme when compared to others.								1	0	0	0	1	1210-0552		WOS:000284915500004	
S	Caballero, Yaile; Bello, Rafael; Arco, Leticia; Garcia, Maria; Ramentol, Enislay						Koronacki, J; Ras, ZW; Wierzchon, ST; Kacprzyk, J		Knowledge Discovery Using Rough Set Theory								ADVANCES IN MACHINE LEARNING I: DEDICATED TO THE MEMORY OF PROFESSOR RYSZARD S. MICHALSKI	Studies in Computational Intelligence		262				367	383			10.1007/978-3-642-05177-7		2010	2010	Rough Set Theory (RST) opened a new direction in the development of incomplete information theories and is a powerful data analysis tool. In this investigation, the possibility of using this theory to generate a priori knowledge about a dataset is demonstrated. A proposal is developed for previous characterization of training sets, using RST estimation measurements. This characterization offers an assessment of the quality of data in order to use them as a training set in machine learning techniques. The proposal has been experimentally studied using international databases and some known classifiers such as MLP, C4.5 and K-NN, and satisfactory results have been obtained.								1	0	0	0	1	1860-949X	978-3-642-05176-0	WOS:000274200800018	
S	Coelho, Frederico; Braga, Antonio Padua; Verleysen, Michel				Braga, Antonio/A-2912-2008	Braga, Antonio/0000-0002-9007-0920	Bloch, I; Cesar, RM		Multi-Objective Semi-Supervised Feature Selection and Model Selection Based on Pearson's Correlation Coefficient								PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS, COMPUTER VISION, AND APPLICATIONS	Lecture Notes in Computer Science		6419				509	516					2010	2010	This paper presents a Semi-Supervised Feature Selection Method based on a univariate relevance measure applied to a multiobjective approach of the problem. Along the process of decision of the optimal solution within Pareto-optimal set, atempting to maximize the relevance indexes of each feature, it is possible to determine a minimum set of relevant features and, at the same time, to determine the optimal model of the neural network.				15th Iberoamerican Congress on Pattern Recognition	NOV 08-11, 2010	Brazilian Bioethanol Sci & Technol Lab; Brazilian Neural Networks Soc; Coordenacao Aperfeicoamento Pessoal Nivel Superior; Chilean Assoc Pattern Recognit; Natl Council Technol & Sci Dev; Cuban Assoc Pattern Recognit; Fundacao Amparo Pesquisa Estado Sao Paulo; Fed Univ ABC; Int Assoc Pattern Recognit; Inst Telecom, Telecom ParisTech; Mexican Assoc Comp Vision, Neural Comp & Robot; Portuguese Assoc Pattern Recognition; Spanish Assoc Pattern Recognit & Image Anal; Brazilian Comp Soc, Special Interest Grp Pattern Recognit; Univ Sao Paulo	Sao Paulo, BRAZIL	1	0	0	0	1	0302-9743	978-3-642-16686-0	WOS:000290420500067	
S	Ghorbani, Ali A.; Onut, Iosif-Viorel						Romay, MG; Corchado, E; GarciaSebastian, MT		Y-Means: An Autonomous Clustering Algorithm								HYBRID ARTIFICIAL INTELLIGENCE SYSTEMS, PT 1	Lecture Notes in Artificial Intelligence		6076				1	13					2010	2010	This paper proposes an unsupervised clustering technique for data classification based on the K-means algorithm. The K-means algorithm is well known for its simplicity and low time complexity. However, the algorithm has three main drawbacks: dependency on the initial centroids, dependency on the number of clusters, and degeneracy. Our solution accommodates these three issues, by proposing an approach to automatically detect a semi-optimal number of clusters according to the statistical nature of the data. As a side effect; the method also makes choices of the initial centroid-seeds not critical to the clustering results. The experimental results show the robustness of the Y-means algorithm as well as its good performance against a set of other well known unsupervised clustering techniques. Furthermore, we study the performance of our proposed solution against different distance and outlier-detection functions and recommend the best combinations.				5th International Conference on Hybrid Artificial Intelligence Systems	JUN 23-25, 2010		Univ Pais Vasco, San Sebastian, SPAIN	1	0	0	0	1	0302-9743	978-3-642-13768-6	WOS:000286842000001	
J	Govindarajan, M.; Chandrasekaran, R. M.								Evaluation of k-Nearest Neighbor classifier performance for direct marketing								EXPERT SYSTEMS WITH APPLICATIONS			37	1			253	258		10.1016/j.eswa.2009.04.055			JAN 2010	2010	Text data mining is a process of exploratory data analysis. Classification maps data into predefined groups or classes. It is often referred to as supervised learning because the classes are determined before examining the data. This paper describes the proposed k-Nearest Neighbor classifier that performs comparative cross-validation for the existing k-Nearest Neighbor classifier. The feasibility and the benefits of the proposed approach are demonstrated by means of data mining problem: direct marketing. Direct marketing has become an important application field of data mining. Comparative cross-validation involves estimation of accuracy by either stratified k-fold cross-validation or equivalent repeated random subsampling. While the proposed method may have a high bias; its performance (accuracy estimation in our case) may be poor due to a high variance. Thus the accuracy with the proposed k-Nearest Neighbor classifier was less than that with the existing k-Nearest Neighbor classifier, and the smaller the improvement in runtime the larger the improvement in precision and recall. In our proposed method we have determined the classification accuracy and prediction accuracy where the prediction accuracy is comparatively high. (C) 2009 Elsevier Ltd. All rights reserved.								1	1	0	0	2	0957-4174		WOS:000271571000029	
S	Jagannathan, Rupa; Petrovic, Sanja; McKenna, Angela; Newton, Louise						Papadopoulos, H; Andreou, AS; Bramer, M		A Fuzzy Non-linear Similarity Measure for Case-Based Reasoning Systems for Radiotherapy Treatment Planning								ARTIFICIAL INTELLIGENCE APPLICATIONS AND INNOVATIONS	IFIP Advances in Information and Communication Technology		339				112	119					2010	2010	This paper presents a decision support system for treatment planning in brain cancer radiotherapy. The aim of a radiotherapy treatment plan is to apply radiation in a way that destroys tumour cells but minimizes the damage to healthy tissue and organs at risk. Treatment planning for brain cancer patients is a complex decision-making process that relies heavily on the subjective experience and expert domain knowledge of clinicians. We propose to capture this experience by using case-based reasoning. Central to the working of our case-based reasoning system is a novel similarity measure that takes into account the non-linear effect of the individual case attributes on the similarity measure. The similarity measure employs fuzzy sets. Experiments, which were carried out to evaluate the similarity measure using real brain cancer patient cases show promising results.				6th IFIP Conference on Artificial Intelligence Applications and Innovations	OCT 06-07, 2010	Univ Cyprus; Cyprus Univ Technol; Frederick Univ; Cyprus Tourism Org	Larnaca, CYPRUS	1	0	0	0	1	1868-4238	978-3-642-16238-1	WOS:000293683700017	
B	Jia, Sen; Qian, Yuntao; Li, Jiming; Liu, Weixiang; Ji, Zhen			IEEE					FEATURE EXTRACTION AND SELECTION HYBRID ALGORITHM FOR HYPERSPECTRAL IMAGERY CLASSIFICATION								2010 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM	IEEE International Symposium on Geoscience and Remote Sensing IGARSS						72	75		10.1109/IGARSS.2010.5652463			2010	2010	Due to the enormous amounts of data contained in hyper-spectral imagery, the main challenge for hyperspectral image classification is to improve the accuracy with less computation complexity. Hence, dimensionality reduction (DR) is often adopted, which includes two different kinds of methods, feature extraction and feature selection. In this paper, discrete wavelet transform (DWT) and affinity propagation (AP), which belong to feature extraction and feature selection respectively, are combined together to accomplish the DR task. Firstly, DWT-based features are extracted from the original hyperspectral data; secondly, AP is applied to select representative features from the obtained ones. Experimental results demonstrate that, compared with some other DR methods which only make use of feature extraction or feature selection, the features acquired by the hybrid technique make the classification results more accurate.				IEEE International Geoscience and Remote Sensing Symposium	JUN 25-30, 2010	IEEE	Honolulu, HI	1	0	0	0	1		978-1-4244-9566-5	WOS:000287933800019	
B	Kaya, G. Taskin; Ersoy, O. K.; Kamasak, M. E.			IEEE					HYBRID SVM AND SVSA METHOD FOR CLASSIFICATION OF REMOTE SENSING IMAGES								2010 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM	IEEE International Symposium on Geoscience and Remote Sensing IGARSS						2828	2831					2010	2010	A linear support vector machine (LSVM) is based on determining an optimum hyperplane that separates the data into two classes with the maximum margin. The LSVM typically has high classification accuracy for linearly separable data. However, for nonlinearly separable data, it usually has poor performance. For this type of data, the Support Vector Selection and Adaptation (SVSA) method was developed, but its classification accuracy is not very high for linearly separable data in comparison to LSVM. In this paper, we present a new classifier that combines the LSVM with the SVSA, to be called the Hybrid SVM and SVSA method (HSVSA), for classification of both linearly and nonlinearly separable data and remote sensing images as well. The experimental results show that the HSVSA has higher classification accuracy than the traditional LSVM, the nonlinear SVM (NSVM) with the radial basis kernel, and the previous SVSA.				30th IEEE International Geoscience and Remote Sensing Symposium (IGARSS) on Remote Sensing - Global Vision for Local Action	JUN 25-30, 2010	IEEE	Honolulu, HI	1	0	0	0	1		978-1-4244-9566-5	WOS:000287933802250	
S	Laranjeiro, Nuno; Oliveira, Rui; Vieira, Marco			IEEE					Applying Text Classification Algorithms in Web Services Robustness Testing								2010 29TH IEEE INTERNATIONAL SYMPOSIUM ON RELIABLE DISTRIBUTED SYSTEMS SRDS 2010	Symposium on Reliable Distributed Systems Proceedings						255	264		10.1109/SRDS.2010.36			2010	2010	Testing web services for robustness is an effective way of disclosing software bugs. However, when executing robustness tests, a very large amount of service responses has to be manually classified to distinguish regular responses from responses that indicate robustness problems. Besides requiring a large amount of time and effort, this complex classification process can easily lead to errors resulting from the human intervention in such a laborious task. Text classification algorithms have been applied successfully in many contexts (e.g., spam identification, text categorization, etc) and are considered a powerful tool for the successful automation of several classification-based tasks. In this paper we present a study on the applicability of five widely used text classification algorithms in the context of web services robustness testing. In practice, we assess the effectiveness of Support Vector Machines, Naive Bayes, Large Linear Classification, K-nearest neighbor (Ibk), and Hyperpipes in classifying web services responses. Results indicate that these algorithms can be effectively used to automate the identification of robustness issues while reducing human intervention. However, in all mechanisms there are cases of misclassified responses, which means that there is space for improvement.				29th IEEE International Symposium on Reliable Distributed Systems	OCT 31-NOV 03, 2010	IEEE Comp Soc Tech Comm; Micrisoft Res; IBM; NSF	New Delhi, INDIA	1	0	0	0	1	1060-9857	978-0-7695-4250-8	WOS:000287486100028	
S	Perkovic, Toni; Cagalj, Mario; Saxena, Nitesh						Sion, R		Shoulder-Surfing Safe Login in a Partially Observable Attacker Model								FINANCIAL CRYPTOGRAPHY AND DATA SECURITY	Lecture Notes in Computer Science		6052				351	358					2010	2010	Secure login methods based on human cognitive skills can be classified into two categories based on information available to a passive attacker: (i) the attacker fully observes the entire input and output of a login procedure, (ii) the attacker only partially observes the input and output. Login methods secure in the fully observable model imply very long secrets and/or complex calculations. In this paper, we study three simple PIN-entry methods designed for the partially observable attacker model. A notable feature of the first method is that the user needs to perform a very simple mathematical operation, whereas, in the other two methods, the user performs a simple table lookup. Our usability study shows that all the methods have reasonably low login times and minimal error rates. These results, coupled with low-cost hardware requirements (only earphones), are a significant improvement over existing approaches for this model [9,10]. We also show that side-channel timing attacks present a real threat to the security of login schemes based on human cognitive skills.				14th Financial Cryptography and Data Security International Conference	JAN 25-28, 2010		Tenerife, SPAIN	1	0	0	0	1	0302-9743	978-3-642-14576-6	WOS:000286416700029	
S	Rathi, Yogesh; Malcolm, James; Michailovich, Oleg; Goldstein, Jill; Seidman, Larry; McCarley, Robert W.; Westin, Carl-Fredrik; Shenton, Martha E.						Jiang, T; Navab, N; Pluim, JPW; Viegever, MA		Biomarkers for Identifying First-Episode Schizophrenia Patients Using Diffusion Weighted Imaging								MEDICAL IMAGE COMPUTING AND COMPUTER-ASSISTED INTERVENTION - MICCAI 2010, PT I	Lecture Notes in Computer Science		6361				657	665					2010	2010	Recent advances in diffusion weighted MR imaging (dMRI) has made it a tool of choice for investigating white matter abnormalities of the brain and central nervous system. In this work, we design a system that detects abnormal features (biomarkers) of first-episode schizophrenia patients and then classifies them using these features. We use two different models of the dMRI data, namely, spherical harmonics and the two-tensor model. The algorithm works by first computing several diffusion measures from each model. An affine-invariant representation of each subject is then computed, thus avoiding the need for registration. This representation is used within a kernel based feature selection algorithm to determine the biomarkers that are statistically different between the two populations. Confirmation of how well these biomarkers identify each population is obtained by using several classifiers such as, k-nearest neighbors, Parzen window classifier, and support vector machines to separate 21 first-episode patients from 20 age-matched normal controls. Classification results using leave-manyout cross-validation scheme are given for each representation. This algorithm is a first step towards early detection of schizophrenia.				13th International Conference on Medical Image Computing and Computer-Assisted Intervention	SEP 20-24, 2010	MICCAI Soc	China Natl Convent Ctr, Beijing, PEOPLES R CHINA	1	0	0	0	1	0302-9743	978-3-642-15704-2	WOS:000287946100080	
B	Walters-Williams, Janett; Li, Yan						Elleithy, K		Comparative Study of Distance Functions for Nearest Neighbors								ADVANCES TECHNIQUES IN COMPUTING SCIENCES AND SOFTWARE ENGINEERING							79	84		10.1007/978-90-481-3660-5_14			2010	2010	Many learning algorithms rely on distance metrics to receive their input data. Research has shown that these metrics can improve the performance of these algorithms. Over the years an often popular function is the Euclidean function. In this paper, we investigate a number of different metrics proposed by different communities, including Mahalanobis, Euclidean, Kullback-Leibler and Hamming distance. Overall, the best-performing method is the Mahalanobis distance metric.				International Conference on Systems, Computing Sciences and Software Engineering	2008		Bridgeport, CT	1	0	0	0	1		978-90-481-3659-9	WOS:000281650200014	
J	Yang, Cheng-Huei; Chuang, Li-Yeh; Yang, Cheng-Hong				Chuang, Li-Yeh/E-5005-2011				IG-GA: A Hybrid Filter/Wrapper Method for Feature Selection of Microarray Data								JOURNAL OF MEDICAL AND BIOLOGICAL ENGINEERING			30	1			23	28					2010	2010	Gene expression profiles have great potential as a medical diagnostic tool since they represent the state of a cell at the molecular level. Available training data sets for classification of cancer types generally have a fairly small sample size compared to the number of genes involved. This fact poses an insurmountable problem to some classification methodologies due to training data limitations. Feature selection is considered a problem of global combinatorial optimization in machine learning, which reduces the number of features, removes irrelevant, noisy and redundant data, and results in acceptable classification accuracy. Hence, selecting relevant genes from the microarray data poses a formidable challenge to researchers due to the high-dimensionality of features, multi-class categories being involved, and the usually small sample size. To overcome this difficulty, a good selection method for genes relevant for sample classification is needed in order to improve prediction accuracy, and to avoid incomprehensibility due to the large number of genes investigated. In this paper, we proposed a filter method (information gain, IG) and a wrapper method (genetic algorithm, GA) for feature selection in microarray data sets. IG was used to select important feature subsets (genes) from all features in the gene expression data, and a GA was employed for actual feature selection. The K-nearest neighbor (K-NN) method with leave-one-out cross-validation (LOOCV) served as an evaluator of the IG-GA. The proposed method was applied and compared to eleven classification problems taken from the literature. Experimental results show that our method simplifies the number of gene expression levels effectively and either obtains higher classification accuracy or uses fewer features compared to other feature selection methods.								1	0	0	0	1	1609-0985		WOS:000275743700003	
S	Yu, Xiao; Wei, Xu; Lin, Xia						Wang, FL; Gong, ZG; Luo, XF; Lei, JS		Algorithms of BBS Opinion Leader Mining Based on Sentiment Analysis								WEB INFORMATION SYSTEMS AND MINING	Lecture Notes in Computer Science		6318				360	369					2010	2010	Opinion leaders play a crucial role in online communities, which can guide the direction of public opinion. Most proposed algorithms on opinion leaders mining in internet social network are based on network structure and usually omit the fact that opinion leaders are field-limited and the opinion sentiment orientation analysis is the vital factor of one's authority. We propose a method to find the interest group based on topic content analysis, which combine the advantages of clustering and classification algorithms. Then we use the method of sentiment analysis to define the authority value as the weight of the link between users. On this basis, an algorithm named LeaderRank is proposed to identify the opinion leaders in BBS, and experiments indicate that LeaderRank algorithm can effectively improve the accuracy of leaders mining.				International Conference on Web Information Systems and Mining	OCT 23-24, 2010	Hainan Province Inst Comp; Qiongzhou Univ	Sanya, PEOPLES R CHINA	1	0	0	0	1	0302-9743	978-3-642-16514-6	WOS:000286404600045	
J	Chan, Yao-Ban; Hall, Peter								ROBUST NEAREST-NEIGHBOR METHODS FOR CLASSIFYING HIGH-DIMENSIONAL DATA								ANNALS OF STATISTICS			37	6A			3186	3203		10.1214/08-AOS591			DEC 2009	2009	We suggest a robust nearest-neighbor approach to classifying high-dimensional data. The method enhances sensitivity by employing a threshold and truncates to a sequence of zeros and ones in order to reduce the deleterious impact of heavy-tailed data. Empirical rules are suggested for choosing the threshold. They require the bare minimum of data only one data vector is needed from each population. Theoretical and numerical aspects of performance are explored, paying particular attention to the impacts of correlation and heterogeneity among data components. On the theoretical side, it is shown that our truncated, thresholded, nearest-neighbor classifier enjoys the same classification boundary as more conventional, nonrobust approaches, which require finite moments in order to achieve good performance. In particular, the greater robustness of our approach does not come at the price of reduced effectiveness. Moreover, when both training sample sizes equal 1, our new method can have performance equal to that of optimal classifiers that require independent and identically distributed data with known marginal distributions; yet, our classifier does not itself need conditions of this type.								1	0	0	0	1	0090-5364		WOS:000271673500004	
J	Fayed, Hatem A.; Atiya, Amir F.; Hashem, Sherif M. R.								HYPERSPHERICAL PROTOTYPES FOR PATTERN CLASSIFICATION								INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			23	8			1549	1575		10.1142/S0218001409007740			DEC 2009	2009	The nearest neighbor method is one of the most widely used pattern classification methods. However its major drawback in practice is the curse of dimensionality. In this paper, we propose a new method to alleviate this problem significantly. In this method, we attempt to cover the training patterns of each class with a number of hyperspheres. The method attempts to design hyperspheres as compact as possible, and we pose this as a quadratic optimization problem. We performed several simulation experiments, and found that the proposed approach results in considerable speed-up over the k-nearest-neighbor method while maintaining the same level of accuray. It also significantly beats other prototype classification methods (Like LVQ, RCE and CCCD) in most performance aspects.								1	0	0	0	1	0218-0014		WOS:000273425500002	
J	Dekel, Ofer; Shalev-Shwartz, Shai; Singer, Yoram								Individual Sequence Prediction Using Memory-Efficient Context Trees								IEEE TRANSACTIONS ON INFORMATION THEORY			55	11			5251	5262		10.1109/TIT.2009.2030460			NOV 2009	2009	Context trees are a popular and effective tool for tasks such as compression, sequential prediction, and language modeling. We present an algebraic perspective of context trees for the task of individual sequence prediction. Our approach stems from a generalization of the notion of margin used for linear predictors. By exporting the concept of margin to context trees, we are able to cast the individual sequence prediction problem as the task of finding a linear separator in a Hilbert space, and to apply techniques from machine learning and online optimization to this problem. Our main contribution is a memory efficient adaptation of the perceptron algorithm for individual sequence prediction. We name our algorithm the shallow perceptron and prove a shifting mistake bound, which relates its performance with the performance of any sequence of context trees. We also prove that the shallow perceptron grows a context tree at a rate that is upper bounded by its mistake rate, which imposes an upper bound on the size of the trees grown by our algorithm.								1	0	0	0	1	0018-9448		WOS:000271019700033	
J	Farcomeni, Alessio								Generalized Augmentation to Control the False Discovery Exceedance in Multiple Testing								SCANDINAVIAN JOURNAL OF STATISTICS			36	3			501	517		10.1111/j.1467-9469.2008.00633.x			SEP 2009	2009	A new multiple testing procedure, the generalized augmentation procedure (GAUGE), is introduced. The procedure is shown to control the false discovery exceedance and to be competitive in terms of power. It is also shown how to apply the idea of GAUGE to achieve control of other error measures. Extensions to dependence are discussed, together with a modification valid under arbitrary dependence. We present an application to an original study on prostate cancer and on a benchmark data set on colon cancer.								1	0	0	0	1	0303-6898		WOS:000268988600008	
J	Giguere, Philippe; Dudek, Gregory				Dudek, Gregory/H-3567-2012				Clustering sensor data for autonomous terrain identification using time-dependency								AUTONOMOUS ROBOTS			26	2-3			171	186		10.1007/s10514-009-9114-2			APR 2009	2009	In this paper we are interested in autonomous vehicles that can automatically develop terrain classifiers without human interaction or feedback. A key issue is the clustering of time-series data collected by the sensors of a ground-based vehicle moving over several terrain surfaces (e.g. concrete or soil). In this context, we present a novel off-line windowless clustering algorithm that exploits time-dependency between samples. In terrain coverage, sets of sensory measurements are returned that are spatially, and hence temporally, correlated. Our algorithm works by finding a set of parameter values for a user-specified classifier that minimize a cost function. This cost function is related to the change in classifier probability estimates over time. The main advantage over other existing methods is its ability to cluster data for fast-switching systems that either have high process or observation noise, or complex distributions that cannot be properly characterized within the time interval that the system stays in a single state. The algorithm was evaluated using three different classifiers (linear separator, mixture of Gaussians and k-Nearest Neighbor), over both synthetic data sets and two different mobile robotic platforms, with success. Comparisons are provided against a window-based algorithm and against a hidden Markov model trained with Expectation-Maximization, with positive results.				4th Robotics Science and Systems Conference	JUN, 2008		Zurich, SWITZERLAND	1	0	0	0	1	0929-5593		WOS:000265684000006	
J	Jarchi, Delaram; Boostani, Reza; Taheri, Mohammad; Sanei, Saeid								Seizure source localization using a hybrid second order blind identification and extended rival penalized competitive learning algorithm								BIOMEDICAL SIGNAL PROCESSING AND CONTROL			4	2			108	117		10.1016/j.bspc.2009.01.004			APR 2009	2009	Localization of seizure sources prior to neurosurgery is crucial. In this paper, a new method is proposed to localize the seizure sources from multi-channel electroencephalogram (EEG) signals. Blind source separation based on second order blind identification (SOBI) is primarily applied to estimate the brain source signals in each window of the EEG signals. A new clustering method based on rival penalized competitive learning (RPCL) is then developed to cluster the rows of the estimated unmixing matrices in all the windows. The algorithm also includes pre and post-processing stages. By multiplying each cluster center to the EEG signals, the brain signal sources are approximated. According to a complexity value measure, the main seizure source signal is separated from the others. This signal is projected back to the electrodes' space and is subjected to the dipole source localization using a single dipole model. The simulation results verify the accuracy of the system. in addition, correct localization of the seizure source is consistent with the clinical tests derived using the simultaneous intracranial recordings. (C) 2009 Elsevier Ltd. All rights reserved.								1	0	0	0	1	1746-8094		WOS:000265704900005	
J	Yang, Chan-Yun; Hsu, Che-Chang; Yang, Jr-Syu								Stray Example Sheltering by Loss Regularized SVM and kNN Preprocessor								NEURAL PROCESSING LETTERS			29	1			7	27		10.1007/s11063-008-9092-y			FEB 2009	2009	This paper presents a new model developed by merging a non-parametric k-nearest-neighbor (kNN) preprocessor into an underlying support vector machine (SVM) to provide shelters for meaningful training examples, especially for stray examples scattered around their counterpart examples with different class labels. Motivated by the method of adding heavier penalty to the stray example to attain a stricter loss function for optimization, the model acts to shelter stray examples. The model consists of a filtering kNN emphasizer stage and a classical classification stage. First, the filtering kNN emphasizer stage was employed to collect information from the training examples and to produce arbitrary weights for stray examples. Then, an underlying SVM with parameterized real-valued class labels was employed to carry those weights, representing various emphasized levels of the examples, in the classification. The emphasized weights given as heavier penalties changed the regularization in the quadratic programming of the SVM, and brought the resultant decision function into a higher training accuracy. The novel idea of real-valued class labels for conveying the emphasized weights provides an effective way to pursue the solution of the classification inspired by the additional information. The adoption of the kNN preprocessor as a filtering stage is effective since it is independent of SVM in the classification stage. Due to its property of estimating density locally, the kNN method has the advantage of distinguishing stray examples from regular examples by merely considering their circumstances in the input space. In this paper, detailed experimental results and a simulated application are given to address the corresponding properties. The results show that the model is promising in terms of its original expectations.								1	0	0	0	1	1370-4621		WOS:000263384200002	
S	Antonio Martin H, Jose; de Lope, Javier; Maravall, Dario				Martin H., Jose Antonio/A-2388-2009		Mira, J; Ferrandez, JM; Alvarez, JR; DelaPaz, F; Toledo, FJ		The kNN-TD Reinforcement Learning Algorithm								METHODS AND MODELS IN ARTIFICIAL AND NATURAL COMPUTATION, PT I	Lecture Notes in Computer Science		5601				305	314					2009	2009	A reinforcement learning algorithm called kNN-TD is introduced. This algorithm has been developed using the classical formulation of temporal difference methods and a k-nearest neighbors scheme as its expectations memory. By means of this kind of memory the algorithm is able to generalize properly over continuous state spaces and also take benefits from collective action selection and learning processes. Furthermore, with the addition of probability traces, we obtain the kNN-TD(A) algorithm which exhibits a state of the art performance. Finally the proposed algorithm has been tested on a series of well known reinforcement learning problems and also at the Second Annual RL Competition with excellent results.				3rd International Work-Conference on the Interplay Between Natural and Artificial Computation	JUN 22-26, 2009		Santiago de Compostela, SPAIN	1	0	0	0	1	0302-9743	978-3-642-02263-0	WOS:000269203400032	
B	Babu, T. Ravindra; Murty, M. Narasimha; Subrahmanya, S. V.						Cao, L		Multiagent Systems for Large Data Clustering								DATA MINING AND MULTI-AGENT INTEGRATION							219	238		10.1007/978-1-4419-0522-2_15	10.1007/978-1-4419-0522-2		2009	2009	Multiagent system is an applied research area encompassing many disciplines. With increasing computing power and easy availability of storage devices vast volumes of data is available containing enormous amount of hidden information. Generating abstractions froth such large data is a challenging data mining task. Efficient large data clustering schemes are important in dealing with such large data. In the current work we provide two different efficient approaches of multiagent based large pattern clustering that would generate abstraction with single database scan, integrating domain knowledge, multiagent systems, data mining and intelligence through agent-mining interaction. We illustrate the approaches based on implementation on practical data.								1	0	0	0	1		978-1-4419-0521-5	WOS:000269462600015	
S	Brahnam, Sheryl; Nanni, Loris						Mumford, CL; Jain, LC		Predicting Trait Impressions of Faces Using Classifier Ensembles								COMPUTATIONAL INTELLIGENCE: COLLABORATION, FUSION AND EMERGENCE	Intelligent Systems Reference Library		1				403	439			10.1007/978-3-642-01799-5		2009	2009	In the experiments presented in this chapter, single classifier systems and ensembles are trained to detect the social meanings people perceive in facial morphology. Exploring machine models of people's impressions of faces has value in the fields of social psychology and human-computer interaction. Our first concern in designing this study was developing a sound ground truth for this problem domain. We accomplished this by collecting a large number of faces that exhibited strong human consensus in a comprehensive set of trait categories. Several single classifier systems and ensemble systems composed of Levenberg-Marquardt neural networks using different methods of collaboration were then trained to match the human perception of the faces in the six trait dimensions of intelligence, maturity, warmth, sociality, dominance, and trustworthiness. Our results show that machine learning methods employing ensembles are as capable as most individual human beings are in their ability to predict the social impressions certain faces make on the average human observer. Single classifier systems did not match human performance as well as the ensembles did. Included in this chapter is a tutorial, suitable for the novice, on the single classifier systems and collaborative methods used in the experiments reported in the study.								1	0	0	0	1	1868-4394	978-3-642-01798-8	WOS:000268703100012	
J	Cantero, R.; Riba, J. R.; Canals, T.; Izquierdo, L. L.; Iturriaga, H.								CHARACTERIZATION OF LEATHER FINISHING BY IR SPECTROSCOPY AND CANONICAL VARIATE ANALYSIS								JOURNAL OF THE SOCIETY OF LEATHER TECHNOLOGISTS AND CHEMISTS			93	1			12	17					JAN-FEB 2009	2009	The finishing process is one of the crucial steps in the process by which the tanning industry transforms leather into an end-product. Therefore, ensuring the required quality in the product requires careful control of this step. Traditionally, the leather tanning industry has used polluting processes and slow analytical methods involving time-consuming separations and also, frequently, the use of environmentally unfriendly reagents. In this work, we used a large matrix of spectroscopic data obtained from 63 leather specimens (34 from Pielcolor and 29 from the laboratories of the Leather Technology School of Igualada) to develop a method allowing the finishing method used on a leather (viz. a resin, wax/oil or grain correction treatment) to be expeditiously, non-destructively identified with the need for no sample treatment. To this end, Fourier transform infrared (FTIR) spectra were recorded with the aid of an ATR module and near-infrared (NIR) spectra with a fibre-optic probe. Chemometric processing of the FTIR or NIR spectral information thus obtained by Principal Component Analysis (PCA) and Canonical Variate Analysis (CVA) allowed the identification of the finishing treatment used on the studied leather samples. The results for the external prediction set (80% of hits with the FTIR model and 60% with the NIR model) were of the same order of magnitude than those obtained by leave-one-out cross-validation of the calibration set (85% with FTIR and 72% with NIR).								1	0	0	0	1	0144-0322		WOS:000263936100003	
S	Gagliardi, Francesco						Serra, R; Cucchiara, R		The Necessity of Machine Learning and Epistemology in the Development of Categorization Theories: A Case Study in Prototype-Exemplar Debate								AI (ASTERISK) IA 2009: EMERGENT PERSPECTIVES IN ARTIFICIAL INTELLIGENCE	Lecture Notes in Artificial Intelligence		5883				182	191					2009	2009	In the present paper we discuss some aspects of the development of categorization theories concerning cognitive psychology and machine learning. We consider the thirty-year debate between prototype-theory and exemplartheory in the studies of cognitive psychology regarding the categorization processes. We propose this debate is ill-posed, because it neglects some theoretical and empirical results of machine learning about the bias-variance theorem and the existence of some instance-based classifiers which can embed models subsuming both prototype and exemplar theories. Moreover this debate lies on a epistemological error of pursuing a, so called, experimentum crucis. Then we present how an interdisciplinary approach, based on synthetic method for cognitive modelling, can be useful to progress both the fields of cognitive psychology and machine learning.				11th Congress of the Italian-Association-for-Artificial-Intelligence	DEC 09-12, 2009	Italian Assoc Artificial Intelligence; Univ Modena Reggio Emilia	Reggio Emilia, ITALY	1	0	0	0	1	0302-9743	978-3-642-10290-5	WOS:000279047900019	
S	Garcia-Borroto, Milton; Villuendas-Rey, Yenny; Ariel Carrasco-Ochoa, Jesus; Fco. Martinez-Trinidad, Jose						BayroCorrochano, E; Eklundh, JO		Using Maximum Similarity Graphs to Edit Nearest Neighbor Classifiers								PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS, COMPUTER VISION, AND APPLICATIONS, PROCEEDINGS	Lecture Notes in Computer Science		5856				489	496					2009	2009	The Nearest Neighbor classifier is a simple but powerful non-parametric technique for supervised classification. However, it is very sensitive to noise and outliers, which could decrease the classifier accuracy. To overcome this problem, we propose two new editing methods based on maximum similarity graphs. Numerical experiments in several databases show the high quality performance of our methods according to classifier accuracy.				14th Iberoamerican Congress on Pattern Recognition	NOV 15-18, 2009	Mexican Assoc Comp Vis, Neurocomp & Robot; Int Assoc Pattern Recognit; Cuban Assoc Pattern Recognit; Chilean Assoc Pattern Recognit; Brizilian Comp Soc Special Interest Grp; Spanish Assoc Pattern Recognit; Portuguese Assoc Pattern Recognit; CINVESTAV; IEEE GRSS; CoecytJal; INTEL Educ; Gobierno Municipal, Direcc Turismo Guadalajara; Oficina Vistantes & Convenciones Guadalajara	Guadalajara, MEXICO	1	0	0	0	1	0302-9743	978-3-642-10267-7	WOS:000279629500057	
S	Goeger, Dirk; Gorges, Nicolas; Woern, Heinz			IEEE					Tactile Sensing for an Anthropomorphic Robotic Hand: Hardware and Signal Processing								ICRA: 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-7	IEEE International Conference on Robotics and Automation ICRA						2972	2978					2009	2009	In this paper, a tactile sensing system for an anthropomorphic robot hand is presented. The tactile sensing system is designed as a construction kit making it very versatile. The sensor data preprocessing is embedded into the hand's hardware structure and is fully integrated. The sensor system is able to gather tactile pressure profiles and to measure vibrations in the sensor's cover. Additionally to the introduction of the hardware, the signal processing and the classification of the acquired sensor data will be explained in detail. These algorithms make the tactile sensing system capable to detect contact points, to classify contact patterns and to detect slip conditions during object manipulation and grasping.				IEEE International Conference on Robotics and Automation	MAY 12-17, 2009	IEEE	Kobe, JAPAN	1	0	0	0	1	1050-4729	978-1-4244-2788-8	WOS:000276080401166	
S	Gu, Suicheng; Tan, Ying; He, Xhigui						Yu, W; He, HB; Zhang, N		Orthogonal Quadratic Discriminant Functions for Face Recognition								ADVANCES IN NEURAL NETWORKS - ISNN 2009, PT 3, PROCEEDINGS	Lecture Notes in Computer Science		5553				466	475					2009	2009	Small sample size (SSS) problem is usually a limit, to the robustness of learning methods hi face recognition. Especially in the quadratic discriminant functions (QDF), too many parameters need to be estimated and covariance matrix Of a Class is usually singular. In order to overcome the SSS problems, we proposed a, novel approach called orthogonal quadratic discriminate functions (C)QDF). The OQDF assumes probability distribution Functions of each two classes of face images have a uniform shape. Then, three OQDF models are developed. The Laplacian smoothing transform (LST) and Fisher's linear discriminant (FLD) are employed to preprocess the face images for the OQDF classifier. Finally, we evaluate, our proposed algorithms on two face databases, ORL and Yale.				6th International Symposium on Neural Networks	MAY 26-29, 2009	Huazhong Univ Sci & Technol; Chinese Univ Hong Kong; Natl Nat Sci Fdn; IEEE Wuhan Sect; IEEE Computat Intel Soc; Int Neural Network Soc	Wuhan, PEOPLES R CHINA	1	0	0	0	1	0302-9743	978-3-642-01512-0	WOS:000268029200051	
B	Kaya, Guelsen Taskin; Ersoy, Okan K.; Kamasak, Mustafa E.						Kurnaz, S; Ince, F; Onbasioglu, S; Basturk, S		Support Vector Selection and Adaptation and Its Application in Remote Sensing								RAST 2009: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN SPACE TECHNOLOGIES							408	412					2009	2009	Classification of nonlinearly separable data by nonlinear support vector machines is often a difficult task, especially due to the necessity of a choosing a convenient kernel type. Moreover, in order to get high classification accuracy with the nonlinear SVM, kernel parameters should be determined by using a cross validation algorithm before classification. However, this process is time consuming. In this study, we propose a new classification method that we name Support Vector Selection and Adaptation (SVSA). SVSA does not require any kernel selection and it is applicable to both linearly and nonlinearly separable data. The results show that the SVSA has promising performance that is competitive with the traditional linear and nonlinear SVM methods.				4th International Conference on Recent Advances in Space Technologies	JUN 11-13, 2009	turkish Air Force Acad; Istanbul Tech Univ; Bogazici Univ; Marmara Univ; Bahcesehir Univ; Istanbul Commerce Univ; Halic Univ; Yeditepe Univ; IEEE; AIAA	Istanbul, TURKEY	1	0	0	0	1		978-1-4244-3626-2	WOS:000271613000080	
S	Matsushita, Yusuke; Wada, Toshikazu						Wada, T; Huang, F; Lin, S		Principal Component Hashing: An Accelerated Approximate Nearest Neighbor Search								ADVANCES IN IMAGE AND VIDEO TECHNOLOGY, PROCEEDINGS	Lecture Notes in Computer Science		5414				374	385					2009	2009	Nearest Neighbor (NN) search is a basic algorithm for data mining and machine learning applications. However, its acceleration in high dimensional space is a difficult problem. For solving this problem, approximate NN search algorithms have been investigated. Especially, LSH is getting highlighted recently, because it has a clear relationship between relative error ratio and the computational complexity. However, the p-stable LSH computes hash values independent of the data distributions, and hence, sometimes the search fails or consumes considerably long time. For solving this problem, we propose Principal Component Hashing (PCH), which exploits the distribution of the stored data. Through experiments, we confirmed that PCH is faster than ANN and LSH at the same accuracy.				3rd Pacific-Rim Symposium on Image and Video Technology (PSIVT 2009)	JAN 13-16, 2009	Natl Inst Informat; Microsoft Res; Forum Image Informat Japan; ACM SIG Multimedia; IEEE Japan Council; IEEE Comp Soc Japan Chapter; IPSJ SIG Comp Vis & Image Media; IEICE TG Pattern Recognit & Media Understanding; Int Informat Sci Fdn; Tateisi Sci & Technol Fdn; Telecommun Advancement Fdn	Tokyo, JAPAN	1	0	0	0	1	0302-9743	978-3-540-92956-7	WOS:000263213300033	
J	Nanni, Loris; Lumini, Alessandra				Lumini, Alessandra/B-6100-2013	Lumini, Alessandra/0000-0003-0290-7354			Genetic nearest feature plane								EXPERT SYSTEMS WITH APPLICATIONS			36	1			838	843		10.1016/j.eswa.2007.10.009			JAN 2009	2009	The problem addressed in this paper concerns the complexity reduction of the nearest feature plane classifier, so that it may be applied also in dataset where the training set contains many patterns. This classifier considers, to classify a test pattern, the subspaces created by each combination of three training patterns. The main problem is that in dataset of high cardinality this method is unfeasible.A genetic algorithm is here used for dividing the training patterns in several clusters which centroids are used to build the feature planes used to classify the test set.The performance improvement with respect to other nearest neighbor based classifiers is validated through experiments with several benchmark datasets. (C) 2007 Elsevier Ltd. All rights reserved.								1	0	0	0	1	0957-4174		WOS:000264182800082	
J	Olvera-Lopez, J. A.; Martinez-Trinidad, J. Fco.; Carrasco-Ochoa, J. A.; Kittler, J.								Prototype selection based on sequential search								INTELLIGENT DATA ANALYSIS			13	4			599	631		10.3233/IDA-2009-0383			2009	2009	In this paper, we propose and explore the use of the sequential search for solving the prototype selection problem since this kind of search has shown good performance for solving selection problems. We propose three prototype selection methods based on sequential search. The main goal of our methods is to reduce the training data without losing too much classification accuracy. Experiments and results are reported showing the effectiveness of the proposed methods and comparing their performance against other prototype selection methods.								1	0	0	0	1	1088-467X		WOS:000269802800005	
S	Schumacher, Tobias; Plessl, Christian; Platzner, Marco						Danek, M; Kadlec, J		AN ACCELERATOR FOR K-TH NEAREST NEIGHBOR THINNING BASED ON THE IMORC INFRASTRUCTURE								FPL: 2009 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE LOGIC AND APPLICATIONS	International Conference on Field Programmable Logic and Applications						338	344					2009	2009	The creation and optimization of FPGA accelerators comprising several compute cores and memories are challenging tasks in high performance reconfigurable computing. In this paper, we present the design of such an accelerator for the k-th nearest neighbor thinning problem on an XD1000 reconfigurable computing system. The design leverages IMORC, an architectural template and highly versatile on-chip interconnect, to achieve speedups of 74 x over a 2.2GHz Opteron. Using IMORC with its asynchronous FIFOs and bitwidth conversion in the links between the cores, we are able to quickly create acclerator versions with varying degrees of core-level parallelism and memory mappings. Through the performance monitoring infrastructure of IMORC we gain insight into the data-dependent behavior of the accelerator which facilitates further performance optimizations.				International Conference on Field Programmable Logic and Applications	AUG 31-SEP 02, 2009	UTIA; AV; CR	ASCR, Informat Theory & Automat, Prague, CZECH REPUBLIC	1	0	0	0	1	1946-1488	978-1-4244-3891-4	WOS:000277506300052	
S	Tafazzoli, Esmaeil; Saif, Mehrdad			IEEE					Application of combined support vector machines in process fault diagnosis								2009 AMERICAN CONTROL CONFERENCE, VOLS 1-9	PROCEEDINGS OF THE AMERICAN CONTROL CONFERENCE						3429	3433		10.1109/ACC.2009.5160577			2009	2009	The performance of Combined Support Vector Machines, C-SVM, is examined by comparing it's classification results with k-nearest neighbor and simple SVM classifier. For our experiments we use training and testing data obtained from two benchmark industrial processes. The first set is simulated data generated from Tennessee Eastman process simulator and the second set is the data obtained by running experiment on a Three Tank system. Our results show that the C-SVM classifier gives the lowest classification error compared to other methods. However, the complexity and computation time become issues, which depend on the number of faults in the data and the data dimension. We also examined Principal Component Analysis, using PC scores as input features for the classifiers but the performance was not comparable to other classifiers' results. By selecting appropriate number of variables using contribution charts for classification, the performance of the classifiers on Tennessee Eastman data enhances significantly. Therefore, using contribution charts for selecting the most important variables is necessary when the number of variables is large.				American Control Conference 2009	JUN 10-12, 2009		St Louis, MO	1	0	0	0	1	0743-1619	978-1-4244-4523-3	WOS:000270044901237	
J	Chuang, Li-Yeh; Yang, Cheng-San; Li, Jung-Chike; Yang, Cheng-Hong				Chuang, Li-Yeh/E-5005-2011				COMBAT GA-BASED GENE SELECTION FOR CLASSIFICATION OF MICROARRAY DATA								BIOMEDICAL ENGINEERING-APPLICATIONS BASIS COMMUNICATIONS			20	6			345	352					DEC 2008	2008	Microarray data can provide valuable results for a variety of gene expression profile problems and contribute to advances in clinical medicine. The application of microarray data on cancer-type classification has recently gained in popularity. The properties of microarray data contain a large number of features ( genes) with high dimensions, and one in the multi-class category. These facts make testing and training of general classification methods difficult. Reducing the number of genes and achieving lower classification error rates are the main issues to be solved. The classification of microarray data samples can be regarded as a feature selection and classifier design problem. The goal of feature selection is to select those subsets of differentially expressed genes that are potentially relevant for distinguishing the sample classes. Classical genetic algorithms (GAs) may suffer from premature convergence and thus lead to poor experimental results. In this paper, combat genetic algorithm (CGA) is used to implement the feature selection, and a K-nearest neighbor with the leave-one-out cross-validation method serves as a classifier of the CGA fitness function for the classification problem. The proposed method was applied to 10 microarray data sets that were obtained from the literature. The experimental results show that the proposed method not only effectively reduced the number of gene expression levels but also achieved lower classification error rates.								1	0	0	0	1	1016-2372		WOS:000262139000002	
J	Xu, Rongwu; He, Lin								GACEM: Genetic Algorithm Based Classifier Ensemble in a Multi-sensor System								SENSORS			8	10			6203	6224		10.3390/s8106203			OCT 2008	2008	Multi-sensor systems (MSS) have been increasingly applied in pattern classification while searching for the optimal classification framework is still an open problem. The development of the classifier ensemble seems to provide a promising solution. The classifier ensemble is a learning paradigm where many classifiers are jointly used to solve a problem, which has been proven an effective method for enhancing the classification ability. In this paper, by introducing the concept of Meta-feature (MF) and Trans-function (TF) for describing the relationship between the nature and the measurement of the observed phenomenon, classification in a multi-sensor system can be unified in the classifier ensemble framework. Then an approach called Genetic Algorithm based Classifier Ensemble in Multi-sensor system (GACEM) is presented, where a genetic algorithm is utilized for optimization of both the selection of features subset and the decision combination simultaneously. GACEM trains a number of classifiers based on different combinations of feature vectors at first and then selects the classifiers whose weight is higher than the pre-set threshold to make up the ensemble. An empirical study shows that, compared with the conventional feature-level voting and decision-level voting, not only can GACEM achieve better and more robust performance, but also simplify the system markedly.								1	0	0	0	1	1424-8220		WOS:000260505200006	
J	Nanni, Loris; Lumini, Alessandra				Lumini, Alessandra/B-6100-2013	Lumini, Alessandra/0000-0003-0290-7354			Cluster-based nearest-neighbour classifier and its application on the lightning classification								JOURNAL OF COMPUTER SCIENCE AND TECHNOLOGY			23	4			573	581		10.1007/s11390-008-9153-8			JUL 2008	2008	The problem addressed in this paper concerns the prototype generation for a cluster-based nearest-neighbour classifier. It considers, to classify a test pattern, the lines that link the patterns of the training set and a set of prototypes. An efficient method based on clustering is here used for finding subgroups of similar patterns with centroid being used as prototype. A learning method is used for iteratively adjusting both position and local-metric of the prototypes. Finally, we show that a simple adaptive distance measure improves the performance of our nearest-neighbour-based classifier. The performance improvement with respect to other nearest-neighbour-based classifiers is validated by testing our method on a lightning classification task using data acquired from the Fast On-orbit Recording of Transient Events (FORTE) satellite, moreover the performance improvement is validated through experiments with several benchmark datasets. The performance of the proposed methods are also validated using the Wilcoxon Signed-Rank test.								1	1	0	0	2	1000-9000		WOS:000257809900006	
J	Zhang, Cun-Quan; Ou, Yongbin								Clustering, Community Partition and Disjoint Spanning Trees								ACM TRANSACTIONS ON ALGORITHMS			4	3					35	10.1145/1367064.1367075			JUN 2008	2008	Clustering method is one of the most important tools in statistics. In a graph theory model, clustering is the process of finding all dense subgraphs. A mathematically well-defined measure for graph density is introduced in this article as follows. Let G = (V, E) be a graph (or multi-graph) and H be a subgraph of G. The dynamic density of H is the greatest integer k such that min(VP){vertical bar E(H/P)vertical bar/vertical bar V(H/P)vertical bar-1} > k where the minimum is taken over all possible partitions P of the vertex set of H, and H/P is the graph obtained from H by contracting each part of P into a single vertex. A subgraph H of G is a level-k community if H is a maximal subgraph of G with dynamic density at least k. An algorithm is designed in this paper to detect all level-h communities of an input multi-graph G. The worst-case complexity of this algorithm is upper bounded by O(vertical bar V(G)vertical bar(2)h(2)). This new method is one of few available clustering methods that are mathematically well-defined, supported by rigorous mathematical proof and able to achieve the optimization goal with polynomial complexity. As a byproduct, this algorithm also can be applied for finding edge-disjoint spanning trees of a multi-graph. The worst-case complexity is lower than all known algorithms for multi-graphs.								1	2	0	0	3	1549-6325		WOS:000265882100011	
J	Fang, Yaping; Feng, Yi; Li, Menglong								Optimal QSAR analysis of the carcinogenic activity of aromatic and heteroaromatic Amines								QSAR & COMBINATORIAL SCIENCE			27	5			543	554		10.1002/qsar.200710077			MAY 2008	2008	Aromatic and heteroaromatic amines are widely used in industrial chemicals and can be found in cooked foods and in tobacco smoke. In this study, Quantitative Structure-Activity Relationships (QSARs) are developed that correlate the observed carcinogenic activities of 80 aromatic and heteroaromatic amines. Principal Component Regression and stepwise linear regression techniques have been applied to construct the QSAR models. The performance of these two models is slightly superior compared to the previous reported based on the same dataset by multiple linear regression techniques. To improve the performance, Support Vector Regression (SVR) has been used to construct the QSARs and Genetic Algorithm (GA) has been used to select the most informational descriptors. Additionally, by introducing the concept of the weighting technique into the model, a new SVR, optimized sample-weighted SVR is proposed. The optimal weighted coefficient is 0.2. The results suggest that approaches using GA selecting descriptors and weighting the descriptors can effectively improve the performance of the SVR models. The optimal Root Mean Square Error in Prediction is 0.799, which is relative smaller than other models. Jackknife-testing procedure has been used to validate the models. The results indicate that the selected descriptors by GA and weighting technique are important and necessary to improve the performance of QSAR models by SVR.								1	0	0	0	1	1611-020X		WOS:000256208900002	
S	Barros, Adelia C. A.; Cavalcanti, George D. C.			IEEE					Combining Global Optimization Algorithms with a Simple Adaptive Distance for Feature Selection and Weighting								2008 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-8	IEEE International Joint Conference on Neural Networks (IJCNN)						3518	3523		10.1109/IJCNN.2008.4634300			2008	2008	This work focuses on a study about hybrid optimization techniques for improving feature selection and weighting applications. For this purpose, two global optimization methods were used: Tabu Search(TS) and Simulated Annealing (SA). These methods were combined to k-Nearest Neighbor (k-NN) composing two hybrid approaches: SA/k-NN and TS/k-NN. Those approaches try to use the main advantage from the global optimization methods: they work efficiently in searching for solutions in the global space. In this study, the methodology is proposed by [4]. In the referred work, a hybrid TS/k-NN approach was suggested and successfully applied for feature selection and weighting problems. Based on the later, this analysis indicates a new SA/k-NN combination and compares their results using the classical Euclidean Distance and a Simple Adaptive Distance [8]. The results demonstrate that feature sets optimized by the studied models are very efficient when compared to the well-known k-NN. Both accuracy classification and number of features in the resultant set are considered in the conclusions. Furthermore, the combined use of the Simple Adaptive Distance improves even more the results for all datasets analyzed.				International Joint Conference on Neural Networks	JUN 01-08, 2008	IEEE	Hong Kong, PEOPLES R CHINA	1	0	0	0	1	1098-7576	978-1-4244-1820-6	WOS:000263827202060	
S	Bayoudh, Ines; Bechet, Nicolas; Roche, Mathieu						Shi, Z; MercierLaurent, E; Leake, D		Blog Classification: Adding Linguistic Knowledge to Improve the K-NN Algorithm								INTELLIGENT INFORMATION PROCESSING IV	INTERNATIONAL FEDERATION FOR INFORMATION PROCESSING						68	77					2008	2008	Blogs are interactive and regularly updated websites which can be seen as diaries. These websites are composed by articles based on distinct topics. Thus, it is necessary to develop Information Retrieval approaches for this new web knowledge. The first important step of this process is the categorization of the articles. The paper above compares several methods using linguistic knowledge with k-NN algorithm for automatic categorization of weblogs articles.				5th IFIP International Conference on Intelligent Information Processing	OCT 19-22, 2008	IFIP TC12; Chinese Assoc Artificial Intelligence; Inst Comp Technol; Chinese Acad Sci	Beijing, PEOPLES R CHINA	1	1	0	0	2	1571-5736	978-0-387-87684-9	WOS:000260431400007	
J	Caulier, Y.; Bourennane, S.				Bourennane, Salah/F-2928-2010				An Image Content Description Technique for the Inspection of Specular Objects								EURASIP JOURNAL ON ADVANCES IN SIGNAL PROCESSING									195263	10.1155/2008/195263			2008	2008	This paper proposed an image content description method within the context of specular surface inspection. Such a method is based on a preliminary research concerning the generation of specific stripe patterns for the visual enhancement of defective surface parts of cylindrical specular objects. The goal of this paper is to address the stripe pattern interpretation within a general approach. For this purpose, different pattern recognition processes, consisting not only of the combination of different image segmentation, feature retrieval, and classification, but also of feature combination and selection, will be considered. Three top-down and one bottom-up approaches are evaluated for retrieving the most appropriate feature sets in terms of highest classification rates. It will be demonstrated that following a combination and appropriate selection of these feature sets, even better rates can be reached. With only half of the initial features, an increase of more than 2% is observable. Copyright (C) 2008 Y. Caulier and S. Bourennane.								1	0	0	0	1	1687-6180		WOS:000261568500001	
S	Cruz, Benjamin; Barron, Ricardo; Sossa, Humberto						Gelbukh, A; Morales, EF		Pattern Classification Based on Conformal Geometric Algebra and Optimization Techniques								MICAI 2008: ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	Lecture Notes in Artificial Intelligence		5317				273	283					2008	2008	Conformal Geometric Algebra (CGA) is a high level language commonly used in mathematical, physics and engineering problems. At a top level, CGA is a free coordinate tool for designing and modeling geometric problems; at a low level CGA provides a new coordinate framework for numeric processing in problem solving. In this paper we show how to use quadratic programming and CGA for, given two sets p and g of points in R(n), construct an optimal separation sphere S such that, all points of p are contained inside of it, and all points of g are outside. To classify an unknown pattern x, an inner product must be applied between x and S. Some numerical and real examples to test the proposal are given.				7th Mexican International Conference on Artificial Intelligence (MICAI 2008)	OCT 27-31, 2008	Mexican Soc Artificial Intelligence; Tecnol Monterrey, Campus Estado Mexico	Atizapan de Zaragoza, MEXICO	1	0	0	0	1	0302-9743	978-3-540-88635-8	WOS:000261873400026	
S	Depeursinge, Adrien; Lavindrasana, Jimison; Hidki, Asmaa; Cohen, Gilles; Geissbuhler, Antoine; Platon, Alexandra; Poletti, Pierre-Alexandre; Mueller, Henning						Andriole, KP; Siddiqui, KM		A classification framework for lung tissue categorization								MEDICAL IMAGING 2008: PACS AND IMAGING INFORMATICS	Proceedings of SPIE		6919						69190C	10.1117/12.769190			2008	2008	We compare five common classifier families in their ability to categorize six lung tissue patterns in high-resolution computed tomography (HRCT) images of patients affected with interstitial lung diseases (ILD) but also normal tissue. The evaluated classifiers are Naive Bayes, k-Nearest Neighbor (k-NN), J48 decision trees, Multi-Layer Perceptron (MLP) and Support Vector Machines (SVM). The dataset used contains 843 regions of interest (ROI) of healthy and five pathologic lung tissue patterns identified by two radiologists at the University Hospitals of Geneva. Correlation of the feature space composed of 39 texture attributes is studied. A grid search for optimal parameters is carried out for each classifier family. Two complementary metrics are used to characterize the performances of classification. Those are based on McNemar's statistical tests and global accuracy. SVM reached best values for each metric and allowed a mean correct prediction rate of 87.9% with high class-specific precision on testing sets of 423 ROIs.				Medical Imaging 2008 Conference	FEB 17-19, 2008	SPIE; Amer Assoc Phys Med; Amer Physiol Soc; Comp Assisted Radiol & Surg; Soc Imaging Sci & Technol; Med Image Percept Soc; Radiol Soc N Amer; Soc Imaging Informat Med; Soc Mol Imaging; DICOM Standards Comm	San Diego, CA	1	0	0	0	1	0277-786X	978-0-8194-7103-1	WOS:000256422200010	
S	Fabris, Fabio; Drago, Idilio; Varejao, Flavio M.				David, Nuno/B-4662-2012		Geffner, H; Prada, R; Alexandre, IM; David, N		A Multi-measure Nearest Neighbor Algorithm for Time Series Classification								ADVANCES IN ARTIFICIAL INTELLIGENCE - IBERAMIA 2008, PROCEEDINGS	Lecture Notes in Computer Science		5290				153	162					2008	2008	In this paper, we have evaluated some techniques for the time series classification problem. Many distance measures have been proposed as an alternative to the Euclidean Distance in the Nearest Neighbor Classifier. To verify the assumption that the combination of various similarity measures may produce a more accurate classifier, we have proposed an algorithm to combine several measures based on weights. We have carried out a set of experiments to verify the hypothesis that the new algorithm is better than the classical ones. Our results show an improvement over the well-established Nearest-Neighbor with DTW (Dynamic Time Warping), but in general, they were obtained combining few measures in each problem used in the experimental evaluation.				11th Ibero-American Conference on Artificial Intelligence	OCT 14-17, 2008	ADETTI; ISCTE; FCT; AEPIA; APPIA	Lisbon, PORTUGAL	1	0	0	0	1	0302-9743	978-3-540-88308-1	WOS:000260922300016	
B	Farooqi, Ashfaq Hussain; Munir, Ali			IEEE					Intrusion Detection System for IP Multimedia Subsystem Using K-Nearest Neighbor classifier								INMIC: 2008 INTERNATIONAL MULTITOPIC CONFERENCE							423	428					2008	2008	IP Multimedia Subsystem (IMS) is a new next generation networking architecture that will provide better quality of service, charging infrastructure and security. The basic idea behind IMS is convergence; providing a single interface to different traditional or modern networking architectures allowing better working environment for the end users. IMS is still not commercially adopted and used but research is in progress to explore it. IMS is an IP based overlay next generation network architecture. It inherent number of security threats of Session Initiation Protocol (SIP), TCP, UDP etc as it uses SIP and IP protocols. Some of them can degrade the performance of IMS seriously and may cause DoS or DDoS attacks. The paper presents a new approach keeping a vision of secure IMS based on Intrusion Detection System (IDS) using K-Nearest Neighbor (KNN) as classifier. The KNN classifier can effectively detect intrusive attacks and achieve a low false positive rate. It can distinguish between the normal behavior of the system or abnormal. In this paper. we have focused on the key element of IMS core known as Proxy Call Session Control Function (PCSCF). Network based anomaly detection mechanism is proposed using KNN as anomaly detector. Experiments are performed on OpenIMS Core and the result shows that IMS is vulnerable to different types of attacks such as UDP flooding, IP spoofing that can cause DoS. KNN classifier effectively distinguishes the behavior of the system as normal or intrusive and achieve low false positive rate.				12th IEEE International Multitopic Conference	DEC 23-24, 2008	IEEE Karachi Sect; Higher Educ Commiss	Bahria Univ, Karachi, PAKISTAN	1	0	0	0	1		978-1-4244-2823-6	WOS:000266371600079	
J	Gomolinska, Anna								Satisfiability of Formulas from the Standpoint of Object Classification: The RST Approach								FUNDAMENTA INFORMATICAE			85	1-4			139	153					2008	2008	In this article we discuss judgment of satisfiability of formulas of it knowledge representation language as an object classification task. Our Viewpoint is that of the rough set theory (RST). and the descriptor language for Pawlak's information systems of a basic kind is taken as the study case. We show how certain analogy-based methods can be employed to judge satisfiability of formulas of that language.				Concurrency Specification and Programming Workshop	SEP 27-29, 2007		Lagow, POLAND	1	0	0	0	1	0169-2968		WOS:000259929900011	
B	Parvin, Hamid; Alizadeh, Hoscin; Minael-Bidgoli, Behrouz			Int Assoc Engineers					MKNN: Modified K-Nearest Neighbor								WCECS 2008: WORLD CONGRESS ON ENGINEERING AND COMPUTER SCIENCE	Lecture Notes in Engineering and Computer Science						831	834					2008	2008	In this paper, a new classification method for enhancing the performance of K-Nearest Neighbor is proposed which uses robust neighbors in training data. This new classification method is called Modified K-Nearest Neighbor, MKNN. Inspired the traditional KNN algorithm, the main idea is classifying the test samples according to their neighbor tags. This method is a kind of weighted KNN so that these weights are determined using a different procedure. The procedure computes the fraction of the same labeled neighbors to the total number of neighbors. The proposed method is evaluated on five different data sets. Experiments show the excellent improvement in accuracy in comparison with KNN method.				World Congress on Engineering and Computer Science (WCECS 2008)	OCT 11-24, 2008	Int Assoc Engineers	San Francisco, CA	1	0	0	0	1		978-988-98671-0-2	WOS:000263417100156	
S	Tran, Ha Manh; Schoenwaelder, Juergen						Ho, TB; Zhou, ZH		Fault Resolution in Case-Based Reasoning								PRICAI 2008: TRENDS IN ARTIFICIAL INTELLIGENCE	Lecture Notes in Artificial Intelligence		5351				417	429					2008	2008	We present a study of reasoning methods in Case-Based Reasoning, which can be applied for the communication system fault domain. Inspired by the reasoning approach of the experts in medical diagnosis, we propose a probabilistic reasoning method which comprises two processes: a ranking process restricting the scope of a problem and a selection process finding promising solutions for the problem. We experimentally evaluate this method and draw lessons from the results to improve it.				10th Pacific Rim International Conference on Artificial Intelligence (PRICAI 2008)	DEC 15-19, 2008	Vietnamese Acad Sci & Technol; Minist Sci & Technol Vietnam; Hanoi Univ Technol; Vietnam Natl Univ, Air Force Off Sci Res, Asian Off Aerosp Res & Dev	Hanoi, VIETNAM	1	0	0	0	1	0302-9743	978-3-540-89196-3	WOS:000262624600035	
B	Yang, Jian; Yang, Jingyu; Jin, Zhong			IEEE					New Concept for Discriminator Design: From Classifier to Discriminator								PROCEEDINGS OF THE 2008 CHINESE CONFERENCE ON PATTERN RECOGNITION (CCPR 2008)							18	23					2008	2008	This paper introduces a new concept of designing a discriminant analysis method (discriminator), which starts from a local mean based nearest neighbor (LM-NN) classifier and uses its decision rule to direct the design of a discriminator. The derived discriminator, called local mean based nearest neighbor discriminator (LM-NND), matches the LM-NN classifier optimally in theory. The proposed LM-NND method is evaluated using the CENPARMI handwritten numeral database, the ETH80 object category database and the PolyU Palmprint database. The experimental results demonstrate the effectiveness of LM-NND and the LM-NN classifier based pattern recognition system.				Chinese Conference one Pattern Recognition	DEC 22-24, 2008	Chinese Assoc Automat; Chinese Acad Sci, Inst Automat; Natl Lab Pattern Recognit; CAA, Pattern Recognit & Machine Intelligence Comm; IEEE	Beijing, PEOPLES R CHINA	1	0	0	0	1		978-1-4244-2316-3	WOS:000264749900004	
S	Yang, Jian; Lou, Zhen; Jin, Zhong; Yang, Jing-yu			IEEE					Minimal local reconstruction error measure based discriminant feature extraction and classification								2008 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, VOLS 1-12	PROCEEDINGS - IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION						173	178					2008	2008	This paper introduces the minimal local reconstruction error (MLRE) as a similarity measure and presents a MLRE-based classifier. From the geometric meaning of the minimal local reconstruction error, we derive that the MLRE-based classifier is a generalization of the conventional nearest neighbor classifier and the nearest neighbor line and plane classifiers. We further apply the MLRE measure to characterize the within-class and between-class local scatters and then develop a MLRE measure based discriminant feature extraction method. The proposed MLRE-based feature extraction method is in line with the MLRE-based classification method in spirit, thus the two methods can be seamlessly combined in applications. The experimental results on the CENPARMI handwritten numeral database and the FERET face image database show effectiveness of the proposed MLRE-based feature extraction and classification method.				IEEE Conference on Computer Vision and Pattern Recognition	JUN 23-28, 2008	IEEE Comp Soc	Anchorage, AK	1	0	0	0	1	1063-6919	978-1-4244-2242-5	WOS:000259736800023	
J	Nicoletti, Maria do Carmo; Figueira, Lucas Baggio; Hruschka, Estevarn R., Jr.				Hruschka Jr., Estevam/B-1073-2008				Transferring neural network based knowledge into an exemplar-based learner								NEURAL COMPUTING & APPLICATIONS			16	3			257	265		10.1007/s00521-007-0088-8			MAY 2007	2007	This paper investigates knowledge transfer from a neural network based system into an exemplar-based learning system. In order to examine the possibilities of such transfer, it proposes and evaluates a system that implements a collaborative scheme, where a particular type of neural network induced by the neural system RuleNet is used by an exemplar-based system (NGE) to carry on a learning task. The proposed collaboration between the two learning models implemented as the hybrid system RuleNet -> NGE is feasible due to the similarity of the concept description languages employed by both. The paper also describes a few experiments conducted; results show that the RuIeNet-NGE collaboration is plausible and, in some domains, it improves the performance of NGE on its own.								1	0	0	0	1	0941-0643		WOS:000247004800006	
S	Angiulli, Fabrizio; Folino, Gianluigi						Kermarrec, AM; Bouge, L; Priol, T		Efficient distributed data condensation for nearest neighbor classification								Euro-Par 2007 Parallel Processing, Proceedings	LECTURE NOTES IN COMPUTER SCIENCE		4641				338	347					2007	2007	In this work, PFCNN, a distributed method for computing a consistent subset of very large data sets for the nearest neighbor decision rule is presented. In order to cope with the communication overhead typical of distributed environments and to reduce memory requirements, different variants of the basic PFCNN method are introduced. Experimental results, performed on a class of synthetic datasets revealed that these methods can be profitably applied to enormous collections of data. Indeed, they scale-up well and are efficient in memory consumption and achieve noticeable data reduction and good classification accuracy. To the best of our knowledge, this is the first distributed algorithm for computing a training set consistent subset for the nearest neighbor rule.				13th International Euro-Par Conference on Parallel Processing	AUG 28-31, 2007	Int Federat Informat Proc; ACM	Rennes, FRANCE	1	0	0	0	1	0302-9743	978-3-540-74465-8	WOS:000250368200036	
S	Barry, M.; Granger, E.			IEEE					Face recognition in video using a what-and-where fusion neural network								2007 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-6	IEEE International Joint Conference on Neural Networks (IJCNN)						2256	2261		10.1109/IJCNN.2007.4371309			2007	2007	A What-and-Where fusion neural network is applied to the recognition of human faces from video sequences. ne spatio-temporal information contained in successive video frames allows to effectively accumulate a classifier's predictions for each person being tracked in an environment. In a particular realization of this network, a fuzzy ARTMAP neural network is used to classify faces detected in each frame, while a bank of Kalman filters; is used to track blobs that contain the extracted faces moving in the environment. Performance of the What-and-Where fusion neural network is compared to that of the fuzzy ARTMAP and k-Nearest-Neighbor (k-NN) classifiers in terms of classification rate, convergence time and compression. In this paper, the impact on performance of setting different region of interest (ROI), of optimizing fuzzy ARTMAP parameters, and of selecting different training subset sizes, is assessed. Simulation results on real-world video sequences indicate that this network can achieve a classification rate that is significantly higher (by approximately 50% in some cases) than that of fuzzy ARTMAP alone, and than that of the k-NN.				International Joint Conference on Neural Networks	AUG 12-17, 2007	IEEE	Orlando, FL	1	0	0	0	1	1098-7576	978-1-4244-1379-9	WOS:000254291102030	
S	Bosin, Andrea; Dessi, Nicoletta; Pes, Barbara						Masulli, F; Mitra, S; Pasi, G		A cost-sensitive approach to feature selection in micro-array data classification								Applications of Fuzzy Sets Theory	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		4578				571	579					2007	2007	In analyzing gene expression data from rnicro-array, a major challenge is the definition of a feature selection criterion to judge the goodness of a subset of features with respect to a particular classification model. This paper presents a cost-sensitive approach feature selection that focuses on two fundamental requirements: (1) the quality of the features in order to promote the classifier accuracy and (2) the cost of computation due to the complexity that occurs during training and testing the classifier. The paper describes the approach in detail and includes a case study for a publicly available micro-array dataset. Results show that the proposed process yields state-of-art performance and uses only a small fraction of features that are generally used in competitive approaches on the same dataset.				7th International Workshop on Fuzzy Logic and Applications	JUL 07-10, 2007	Univ Genova, DISI; IEEE Computat Intelligence Soc, Italian Chapter; Int Neural Network Soc, SIGs Italy & Bioinformat; Bioinformat Italian Soc; Italian Neural Networks Soc; SCIP Working Grp; Univ Studi Milano, DSI; Univ Salerno, DMI; Gruppo Nazl Calcolo Sci	Camogli, ITALY	1	0	0	0	1	0302-9743	978-3-540-73399-7	WOS:000248082000073	
S	Chen, Tung-Shou; Lin, Chih-Chiang; Chiu, Yung-Hsing						Xu, AP; Zhu, H; Chen, SY; Yan, B; Meng, QG; Miao, D; Fang, Y		A new parameter-free classification algorithm based on nearest neighbor rule and K-means for mobile devices								Proceedings of the 6th WSEAS International Conference on Applied Computer Science	ELECTRICAL AND COMPUTER ENGINEERING						152	155					2007	2007	This paper proposes a parameter-free classifier which combines K-means with Nearest Neighbor Rule (NNR) - called Incremental Cluster-based Classification (ICC). The classifier is used in low power and capacity devices such as Personal Digital Assistant (PDA) and Smartphone. In the training phase, ICC employs K-means to group instances into several clusters, and then incrementally separates the cluster into two clusters until the cluster members belong to the same type within each cluster. Thus instances have uniform class label within each cluster. In the predicting phase, ICC adopts NNR to find a centroid which is the nearest neighbor of the unlabeled instance. Since the training data are substituted by the cluster centroids; memory and computation requirements are decreased. K-means and NNR are both simple and efficient methods. ICC is easy to redo and have efficient performance and is, hence, suitable for low capacity hardware. In this paper, the prediction accuracy of ICC is evaluated and compared with those of NNR and Support Vector Machine (SVM). Our experimental results show that the prediction accuracy of ICC is comparable to NNR. Although NNR is the easiest to use and redo, it is sensitive to noises and consumes time and memory for a large dataset. Despite the higher accuracy of LIBSVM, it is time-consuming to select an appropriate kernel function and related parameters. ICC is parameter-free, simple to operate and easy to implement. Mobile users can complete their work more conveniently and accurately.				6th WSEAS International Conference on Applied Computer Science (ACOS 07)	APR 15-17, 2007	WSEAS	Hangzhou, PEOPLES R CHINA	1	0	0	0	1	1790-5117	978-960-8457-66-9	WOS:000249798700028	
B	Cheng, Haibin; Tan, Pang-Ning; Jin, Rong						Apte, C; Liu, B; Parthasarathy, S; Skillicorn, D		Localized Support Vector Machine and Its Efficient Algorithm								PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING							461	466					2007	2007	Nonlinear Support Vector Machines employ sophisticated kernel functions to classify data sets with complex decision surfaces. Determining the right parameters of such functions is not only computationally expensive, the resulting models are also susceptible to overfitting due to their large VC dimensions. Instead of fitting a nonlinear model, this paper presents a framework called Localized Support Vector Machine (LSVM), which builds multiple linear SVM models from the training data. Since each model is designed to classify a particular test example, it has high computational cost. To overcome this limitation, we propose an efficient implementation of LSVM, termed Profile SVM (PSVM). PSVM partitions the training examples into clusters and builds a separate linear SVM model for each cluster. Our empirical results show that (1) Both LSVM and PSVM outperform nonlinear SVM on the majority of the evaluated data sets; and (2) PSVM achieves comparable accuracy as LSVM but with significant computational savings.				7th SIAM International Conference on Data Mining	APR 26-28, 2007	Amer Stat Assoc	Minneapolis, MN	1	1	0	0	2		978-0-898716-30-6	WOS:000289220200045	
S	Dion, Juanita; Kumar, Mrityunjay; Ramuhalli, Pradeep						Thompson, DO; Chimenti, DE		Multi-sensor data fusion for high-resolution material characterization								Review of Progress in Quantitative Nondestructive Evaluation, Vols 26A and 26B	AIP CONFERENCE PROCEEDINGS		894				1189	1196					2007	2007	In typical nondestructive evaluation (NDE) of materials, the material tinder test is inspected using one or more NDE techniques to evaluate its condition. However, measurement data from different inspection techniques are often complementary in nature and higher accuracy may be achieved by fusing information from these different inspection modes. This paper proposes a classifier-fusion based approach to combine multifrequency eddy current and ultrasound data for material characterization. The proposed algorithm uses a hierarchy of classifiers to determine the material state (e.g. stress, heat treatment etc.) and level of exposure to this condition, with classifier fusion achieved through a majority-voting rule. Preliminary results on applying the proposed algorithm to data from Inconel 600 samples are presented.				33rd Annual Review of Progress in Quantitative Nondestructive Evaluation	JUL 30-AUG 04, 2006		Portland, OR	1	0	0	0	1	0094-243X	978-0-7354-0399-4	WOS:000245889000153	
S	Fayyaz, Mudassir; Khan, Asifullah; Mujahid, Adrian; Kavokin, Alex						Mandoiu, I; Zelikovsky, A		Using multi level nearest neighbor classifiers for G-protein coupled receptor sub-families prediction								Bioinformatics Research and Applications, Proceedings	LECTURE NOTES IN BIOINFORMATICS		4463				564	576					2007	2007	Prediction based on the hydrophobicity of the protein yields potentially good classification rate as compared to the other compositions for G-Proteins coupled receptor (GPCR's) families and their respective subfamilies. In the current study, we make use of the hydrophobicity of the proteins in order to obtain a fourier spectrum of the protein sequence, which is then used for classification purpose. The classification of 17 GPCR subfamilies is based on Nearest Neighbor (NN) method, which is employed at two levels. At level-1 classification, the GPCR super-family is recognized and at level-2, the respective sub-families for the predicted super-family are classified. As against Support Vector Machine (SVM), NN approach has shown better performance using both jackknife and independent data set testing. The results are formulated using three performance measures, the Mathew's Correlation Coefficient (MCC), overall accuracy (ACC) and reliability (R) on both training and independent data sets. Comparison of our results is carried out with the overall class accuracies obtained for super-families using existing technique. The multilevel classifier has shown promising performance and has achieved overall ACC and MCC of 97.02% and 0.95 using jackknife test, and 87.50 % and 0.85 for independent data set test respectively.				3rd International Symposium on Bioinformatics Research and Applications	MAY 07-10, 2007		Atlanta, GA	1	0	0	0	1	0302-9743	978-3-540-72030-0	WOS:000246369100051	
S	Gomez, Octavio; Morales, Eduardo F.; Gonzalez, Jesus A.						Gelbukh, A; Morales, AFK		Weighted instance-based learning using representative intervals								MICAI 2007: ADVANCES IN ARTIFICIAL INTELLIGENCE	Lecture Notes in Artificial Intelligence		4827				420	430					2007	2007	Instance-based learning algorithms are widely used due to their capacity to approximate complex target functions; however; the performance of this kind of algorithms degrades significantly in the presence of irrelevant features. This paper introduces a new noise tolerant instance-based learning algorithm, called WIB-K, that uses one or more weights, per feature per class, to classify integer-valued databases. A set of intervals that represent the rank of values of all the features is automatically created for each class, and the nonrepresentative intervals are discarded. The remaining intervals (representative intervals) of each feature are compared against the representative intervals of the same feature in the other classes to assign a weight. The weight represents the discriminative power of the interval, and is used in the similarity function to improve the classification accuracy. The algorithm was tested on several datasets, and compared against other representative machine learning algorithms showing very competitive results.				6th Mexican International Conference on Artificial Intelligence (MICAI 2007)	NOV 04-10, 2007	Mexican Soc Artificial Intelligence	Aguascalientes, MEXICO	1	0	0	0	1	0302-9743	978-3-540-76630-8	WOS:000251037900040	
J	Jung, Jason J.				Jung, Jason J./B-9622-2012	Jung, Jason J./0000-0003-0050-7445			Semantic co-browsing system based on contextual synchronization on peer-to-peer environment								COMPUTING AND INFORMATICS			26	5			469	488					2007	2007	In this paper, we focus on a personalized information retrieval system based on multi-agent platform. Especially, they are capable of sharing information between them, for supporting collaborations between people. Personalization module has to be exploited to be aware of the corresponding user's browsing contexts (e.g., purposes, intention, and goals) at the specific moment. We want to recommend as relevant information to the estimated user context as possible, by analyzing the interaction results (e.g., clickstreams or query results). Thereby, we propose a novel approach to self-organizing agent groups based on contextual synchronization. Synchronization is an important requirement for online collaborations among them. This synchronization method exploits contextual information extracted from a set of personal agents in the same group, for real-time information sharing. Through semantically tracking of the users' information searching behaviors, we model the temporal dynamics of personal and group context. More importantly, in a certain moment, the contextual outliers can be detected, so that the groups can be automatically organized again with the same context. The cobrowsing system embedding our proposed method was shown 52.7% and 11.5% improvements of communication p, erformance, compared to single browsing system and asynchronous collaborative browsing system, respectively.								1	0	0	0	1	1335-9150		WOS:000251450100002	
S	Lu, Bao-Liang; Li, Jing						Chen, K; Wang, L		A min-max modular network with Gaussian-zero-crossing function								TRENDS IN NEURAL COMPUTATION	Studies in Computational Intelligence		35				285	313					2007	2007	This chapter presents a min-max modular neural network with Gaussian-zero-crossing function (M(3)-GZC). This modular network has the following attractive features: the highly modular structure, the ability of incremental learning; the guarantee of learning convergence, and the ability of saying 'unknown' to unfamiliar inputs. Its relationships with two traditional models, the nearest neighbor algorithm and the radius-basis function network are discussed for better understanding of M(3)-GZC network. Since the number of modules in a M(3)-GZC network is quadratic complexity with the number of training instances, two redundancy pruning strategies, instance pruning and structure pruning, are proposed to reduce the number of modules and speed up the responding time. Experimental results on several benchmark data sets and a practical industry application show the properties of M(3)-GZC network and the validity of the two redundancy pruning strategies.				1st International Conference on Natural Computation (ICNC 2005)	AUG 27-29, 2005	Xiangtang Univ; IEEE Circuits & Syst Soc; IEEE Computat Intelligence Soc; IEEE Control Syst Soc; Int Neural Network Soc; European Neural Network Soc; Chinese Assoc Artificial Intelligence; Japanese Neural Network Soc; Int Fuzzy Syst Assoc; Asia Pacific Neural Network Assembly; Fuzzy Math & Syst Assoc China; Hunan Comp Federat	Changsha, PEOPLES R CHINA	1	1	0	0	2	1860-949X	3-540-36121-9	WOS:000243355000012	
S	Mignani, A. G.; Ciaccheri, L.; Cucci, C.; Mencaglia, A. A.; Cimato, A.; Attilio, C.; Thienpont, H.; Ottevaere, H.; Paolesse, R.; Mastroianni, M.; Monti, D.; Buonocore, G.; Del Nobile, A.; Mentana, A.; Grimaldi, M. F.; Dall'Asta, C.; Faccini, A.; Galaverna, G.; Dossena, A.				Ottevaere, Heidi/A-9294-2010; Dall'Asta, Chiara/C-3173-2008	Dall'Asta, Chiara/0000-0003-0716-8394	Matvienko, GG; Ivanov, AP; Nikitin, PI; Voropay, ES; Khodasevich, MA; Panchenko, VY; Golubev, VS		EAT-by-LIGHT fiber-optic and micro-optic devices for food quality and safety assessment								INTERNATIONAL CONFERENCE ON LASERS, APPLICATIONS, AND TECHNOLOGIES 2007: ENVIRONMENTAL MONITORING AND ECOLOGICAL APPLICATIONS; OPTICAL SENSORS IN BIOLOGICAL, CHEMICAL, AND ENGINEERING TECHNOLOGIES; AND FEMTOSECOND LASER PULSE FILAMENTATION	Proceedings of SPIE		6733						67331K	10.1117/12.753315			2007	2007	A selection is presented of fiber-optic and micro-optic devices that have been designed and tested for guaranteeing the quality and safety of typical foods, such as extra virgin olive oil, beer, and milk. Scattered colorimetry is used to authenticate various types of extra virgin olive oil and beer, while a fiber-optic-based device for UV-VIS-NIR absorption spectroscopy is exploited in order to obtain the hyperspectral optical signature of olive oil. This is done not only for authentication purposes, but also so as to correlate the spectral data with the content of fatty acids, which are important nutritional factors. A micro-optic sensor for the detection of olive oil aroma that is capable of distinguishing different ageing levels of extra virgin olive oil is also presented. It shows effective potential for acting as a smart cap of bottled olive oil in order to achieve a non-destructive olfactory perception of oil ageing. Lastly, compact portable fluorometer for the rapid monitoring of the carcinogenic M1 aflatoxin in milk, is experimented.				International Conference on Lasers, Applications, and Technologies	MAY 28-JUN 01, 2007	Natl Acad Sci; Russian Acad Sci; Moscow State Univ, M V Lomonosov; BI Stepanov Inst Phys; Int Sci & Technol Ctr; Belarus Fdn Basic Res; Belarus Phys Soc; Russian Phys Soc; SPIE Russian Chapter	Minsk, BYELARUS	1	0	0	0	1	0277-786X	978-0-8194-6891-8	WOS:000251495000018	
J	Santos de Sa Lisboa, Flavia O.; Nicoletti, Maria do Carmo; Ramere, Arthur				Lisboa, Flavia/I-6767-2012				A version of the NGE model suitable for fuzzy domains								JOURNAL OF INTELLIGENT & FUZZY SYSTEMS			18	1			1	17					2007	2007	The Nested Generalized Exemplar (NGE) model is an incremental form of inductive learning that generalizes a given training set into hypotheses represented as a set of hyperrectangles in an n-dimensional Euclidean space. The NGE algorithm can be considered a descendent of either Nearest Neighbor (NN) or K-Nearest Neighbor (KNN) algorithms. NGE based systems classify new instances by calculating their similarity to the nearest generalized exemplar (i.e. hyperrectangle). Similarity in an NGE model is implemented by a distance metric namely the Euclidean distance. This paper describes a version of the NGE model suitable for fuzzy domains called Fuzzy NGE (F-NGE). F-NGE learns fuzzy rules for classifying instances into crisp classes. An implementation of F-NGE has been tested in several different knowledge domains for which results are presented and discussed. Results of fuzzy versions of NN and KNN using the same domains are also presented, for comparison.								1	0	0	0	1	1064-1246		WOS:000247860500001	
S	Suri, N. Rama; Srinivas, V. S.; Murty, M. Narasimha						Kok, JN; Koronacki, J; DeMantaras, RL; Matwin, S; Mladenic, D; Skowron, A		A cooperative game theoretic approach to prototype selection								Knowledge Discovery in Databases: PKDD 2007, Proceedings	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		4702				556	564					2007	2007	In this paper we consider the task of prototype selection whose primary goal is to reduce the storage and computational requirements of the Nearest Neighbor classifier while achieving better classification accuracies. We propose a solution to the prototype selection problem using techniques from cooperative game theory and show its efficacy experimentally.				18th European Conference on Machine Learning (ECML 2007)/11th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD 2007)	SEP 17-21, 2007	Warsaw Univ, Fac Math, Informat & Mech; Polish Acad Sci, Inst Comp Sci; European Off Aerosp Res & Dev; Air Force Off Sci Res; USAF Res Lab	Warsaw Univ, Warsaw, POLAND	1	0	0	0	1	0302-9743	978-3-540-74975-2	WOS:000249743700054	
S	Wang, Jinjia; Hong, Wenxue; Li, Xin						Huang, DS; Heutte, L; Loog, M		The new graphical features of star plot for K nearest neighbor classifier								ADVANCED INTELLIGENT COMPUTING THEORIES AND APPLICATIONS, PROCEEDINGS: WITH ASPECTS OF ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		4682				926	933					2007	2007	The graphical representation or graphical analysis for multidimensional data in multivariate analysis is a very useful method. But it rarely is used to the pattern recognition field. The paper we use the stat plot to represent one observation or sample with multi variances and extract the new graphical features of star plot: sub-area features and sub-barycentre features. The new features are used for the K nearest neighbor classifier (KNN) with leave one out cross validation. Experiments with several standard benchmark data sets show the effectiveness of the new graphical features.				3rd International Conference on Intelligent Computing	AUG 21-24, 2007	IEEE Computat Intelligence Soc; Int Neural Network Soc; Natl Sci Fdn China	Qingdao, PEOPLES R CHINA	1	1	0	0	2	0302-9743	978-3-540-74201-2	WOS:000250577100096	
J	Chindaro, S.; Sirlantzis, K.; Fairhurst, M. C.								ICA-based multi-colour space texture classification system								ELECTRONICS LETTERS			42	21			1208	1210		10.1049/el:20062197			OCT 12 2006	2006	Presented is a novel method which uses independent component analysis (ICA) for systematically partitioning and combining textural features extracted from different colour spaces, in a multiple classifier based system, for colour texture classification. Results obtained illustrate that the proposed ICA-based feature-partitioning and classifier combination system produces more accurate results compared to a system that combines classifiers applied to features extracted from individual colour spaces.								1	0	0	0	1	0013-5194		WOS:000242233400011	
J	Alvarado, GJ; Pedrycz, W; Reformat, M; Kwak, KC								Deterioration of visual information in face classification using Eigenfaces and Fisherfaces								MACHINE VISION AND APPLICATIONS			17	1			68	82		10.1007/s00138-006-0016-4			APR 2006	2006	In the area of biometrics, face classification becomes one of the most appealing and commonly used approaches for personal identification. There has been an ongoing quest for designing systems that exhibit high classification rates and portray significant robustness. This feature becomes of paramount relevance when dealing with noisy and uncertain images. The design of face recognition classifiers capable of operating in presence of deteriorated (noise affected) face images requires a careful quantification of deterioration of the existing approaches vis-a-vis anticipated form and levels of image distortion. The objective of this experimental study is to reveal some general relationships characterizing the performance of two commonly used face classifiers (that is Eigenfaces and Fisherfaces) in presence of deteriorated visual information. The findings obtained in our study are crucial to identify at which levels of noise the face classifiers can still be considered valid. Prior knowledge helps us develop adequate face recognition systems. We investigate several typical models of image distortion such as Gaussian noise, salt and pepper, and blurring effect and demonstrate their impact on the performance of the two main types of the classifiers. Several distance models derived from the Minkowski family of distances are investigated with respect to the produced classification rates. The experimental environment concerns a well-known standard in this area of face biometrics such as the FERET database. The study reports on the performance of the classifiers, which is based on a comprehensive suite of experiments and delivers several design hints supporting further developments of face classifiers.								1	0	0	0	1	0932-8092		WOS:000236382400006	
S	Dai, Wenyuan; Yu, Yong; Zhang, Cong-Le; Han, Jie; Xue, Gui-Rong						Yu, JX; Kitsuregawa, M; VaLeong, H		A novel web page categorization algorithm based on block propagation using query-log information								ADVANCES IN WEB-AGE INFORMATION MANAGEMENT, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		4016				435	446					2006	2006	Most existing web page classification algorithms, including content-based, link-based, or query-log analysis methods, treat the pages as smallest units. However, web pages usually contain some noisy or biased information which could affect the performance of classification. In this paper, we propose a Block Propagation Categorization (BPC) algorithm which deep mines web structure and views blocks as basic semantic units. Moreover, with query log information, BPC propagates only suitable information (block) among web pages to emphasize their topics. We also optimize the BPC algorithm to significantly speed up the block propagation process, without losing any precision. Our experiments on ODP and MSN search engine log show that BPC achieves a great improvement over traditional approaches.				7th International Conference on Web-Age Information Management	JUN 17-19, 2006	Chinese Univ Hong Kong; City Univ Hong Kong; Hong Kong Baptist Univ; Hong Kong Polytech Univ; Hong Kong Univ Sci & Technol; Univ Hong Kong; Hong Kong Web Soc; Hong Kong Pei Hua Educ Fdn Ltd; IEEE Hong Kong Sect Comp Sci Chapter	Hong Kong, PEOPLES R CHINA	1	0	0	0	1	0302-9743	3-540-35225-2	WOS:000239658700037	
S	Lou, Zhen; Jin, Zhong						Tang, YY; Wang, SP; Lorette, G; Yeung, DS; Yan, H		Novel adaptive nearest neighbor classifiers based on hit-distance								18th International Conference on Pattern Recognition, Vol 3, Proceedings	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION						87	90					2006	2006	In this paper a novel idea of distance, Hit-Distance, was firstly introduced to generalize the representational capacity of available prototypes. Novel adaptive nearest neighbor classifiers based on Hit-Distance were then proposed Experiments were performed on 8 benchmark datasets from the UCI Machine Learning Repository. It was shown that the proposed classifiers performed much better than the classical nearest neighbor classifier (NN) and the nearest feature line method (NFL), the nearest feature plane method (NFP), the nearest neighbor line method (NNL) and the nearest neighbor plane method (NNP).				18th International Conference on Pattern Recognition (ICPR 2006)	AUG 20-24, 2006	IAPR; CAA; Hong Kong Baptist Univ	Hong Kong, PEOPLES R CHINA	1	0	0	0	1	1051-4651	0-7695-2521-0	WOS:000240705600021	
S	van der Laan, D. J. (Jan); Maas, Marnix C.; Schaart, Dennis R.; Bruyndonckx, Peter; Lamaitre, Cedric; van Eijk, Carel W. E.			IEEE					Spatial Resolution in Position-Sensitive Monolithic Scintillation Detectors								2006 IEEE NUCLEAR SCIENCE SYMPOSIUM CONFERENCE RECORD, VOL 1-6	IEEE Nuclear Science Symposium Conference Record						2506	2510		10.1109/NSSMIC.2006.354420			2006	2006	Monolithic scintillation detectors are very promising for high resolution and high sensitivity positron emission tomography. These detectors consist of a few cubic centimeters of scintillating material coupled to one or more position-sensitive APD arrays. The entry point of an impinging annihilation photon is estimated from the light distribution on the APD pixels. In this paper, a model will be derived that predicts the line spread function of these detectors. This model includes the influences of the finite width of the measurement beam, scatter of radiation inside the detector, light yield and intrinsic energy resolution of the scintillator, quantum efficiency, gain and excess noise factor of the avalanche photo-diode arrays, and electronic noise. With this model a better understanding of the behavior of the detector is possible, which can make optimization more efficient.				15th International Workshop on Room-Temperature Semiconductor X- and Gamma-Ray Detectors/ 2006 IEEE Nuclear Science Symposium	OCT 29-NOV 04, 2006	IEEE	San Diego, CA	1	0	1	0	1	1082-3654	978-1-4244-0561-9	WOS:000288875602124	
B	Wang, Qing; Kulkarni, Sanjeev R.; Verdu, Sergio			IEEE					A nearest-neighbor approach to estimating divergence between continuous random vectors								2006 IEEE International Symposium on Information Theory, Vols 1-6, Proceedings							242	246		10.1109/ISIT.2006.261842			2006	2006	A method for divergence estimation between multidimensional distributions based on nearest neighbor distances is proposed. Given i.i.d. samples, both the bias and the variance of this estimator are proven to vanish as sample sizes go to infinity. In experiments on high-dimensional data, the nearest neighbor approach generally exhibits faster convergence compared to previous algorithms based on partitioning.				IEEE International Symposium on Information Theory	JUL 09-14, 2006	IEEE Informat Theory Soc; USN, Dept Navy Sci & Technol; Microsoft; Natl Sci Fdn	Seattle, WA	1	0	0	0	1		978-1-4244-0505-3	WOS:000245289700051	
S	Yu, Jie; Amores, Jaume; Sebe, Nicu; Tian, Qi						Hawkes, PW		Ranking metrics and evaluation measures								ADVANCES IN IMAGING AND ELECTRON PHYSICS, VOL 144	Advances in Imaging and Electron Physics		144				291	316		10.1016/S1076-5670(06)44004-0			2006	2006									1	0	0	0	1	1076-5670	0-12-014786-6	WOS:000241587000004	
J	Agrawal, M; Gupta, N; Shreelekshmi, R; Murty, MN								Efficient pattern synthesis for nearest neighbour classifier								PATTERN RECOGNITION			38	11			2200	2203		10.1016/j.patcog.2005.03.029			NOV 2005	2005	Synthetic pattern generation is one of the strategies to overcome the curse of dimensionality, but it has its own drawbacks. Most of the synthetic pattern generation techniques take more time than simple classification. In this paper, we propose a new strategy to reduce the time and memory requirements by applying prototyping as an intermediate step in the synthetic pattern generation technique. Results show that through the proposed strategy, classification can be done much faster without compromising much in terms of classification accuracy, in fact for some cases it gives better accuracy in lesser time. The classification time and accuracy can be balanced according to available memory and computing power of a system to get the best possible results. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.								1	0	0	0	1	0031-3203		WOS:000232113000034	
J	Prank, K; Schulze, E; Eckert, O; Nattkemper, TW; Bettendorf, M; Maser-Gluth, C; Sejnowski, TJ; Grote, A; Penner, E; von zur Muhlen, A; Brabant, G								Machine learning approaches for phenotype-genotype mapping: predicting heterozygous mutations in the CYP21B gene from steroid profiles								EUROPEAN JOURNAL OF ENDOCRINOLOGY			153	2			301	305		10.1530/eje.1.01957			AUG 2005	2005	Objective: Non-linear relations between multiple biochemical parameters are the basis for the diagnosis of many diseases. Traditional linear analytical methods are not reliable predictors. Novel nonlinear techniques are increasingly used to improve the diagnostic accuracy of automated data interpretation. This has been exemplified in particular for the classification and diagnostic prediction of cancers based on expression profiling data. Our objective was to predict the genotype from complex biochemical data by comparing the performance of experienced clinicians to traditional linear analysis, and to novel non-linear analytical methods.Design and methods: As a model, we used a well-defined set of interconnected data consisting of unstimulated serum levels of steroid intermediates assessed in 54 subjects heterozygous for a mutation of the 21-hydroxylase gene (CYP21B) and in 43 healthy controls.Results: The genetic alteration was predicted from the pattern of steroid levels with an accuracy of 39% by clinicians and of 64% by linear analysis. In contrast, non-linear analysis, such as self-organizing artificial neural networks, support vector machines, and nearest neighbour classifiers, allowed for higher accuracy up to 83%.Conclusions: The successful application of these non-linear adaptive methods to capture specific biochemical problems may have generalized implications for biochemical testing in many areas. Nonlinear analytical techniques such as neural networks, support vector machines, and nearest neighbour classifiers may serve as an important adjunct to the decision process of a human investigator not ' trained ' in a specific complex clinical or laboratory setting and may aid them to classify the problem more directly.								1	0	1	0	1	0804-4643		WOS:000231698400016	
J	Amador, JJ								Markov random field approach to region extraction using Tabu Search								JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION			16	2			134	158		10.1016/j.vcir.2004.06.002			APR 2005	2005	This paper describes a region extraction algorithm based on the concept of Markov random fields. Markov random fields (MRFs) are characterized by using a Gibbs Distribution which equates back to the MRF. A heuristically developed energy functional is presented and used with the MRF in an efficient and accurate manner. Since the MRF used in this work is defined using the polar coordinate system, a very large search space exists for radial lengths and sites. To aid in pursuing these radial sites, a combinatorial optimization technique known as Tabu Search is exploited. Also provided is an extensive empirical study on aerial imagery and parts detection, in addition to a final discussion and description of future work. (c) 2004 Elsevier Inc. All rights reserved.								1	0	0	0	1	1047-3203		WOS:000228340700002	
S	Angiulli, F						Famili, AF; Kok, JN; Pena, JM; Siebes, A; Feelders, A		Condensed nearest neighbor data domain description								ADVANCES IN INTELLIGENT DATA ANALYSIS VI, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		3646				12	23					2005	2005	A popular method to discriminate between normal and abnormal data is based on accepting test objects whose nearest neighbors distances in a reference data set lie within a certain threshold. In this work we investigate the possibility of using as reference set a subset of the original data set. We discuss relationship between reference set size and generalization, and show that finding the minimum cardinality reference consistent subset is intractable. Then, we describe an algorithm that computes a reference consistent subset with only two reference set passes. Experimental results confirm the effectiveness of the approach.				6th International Symposium on Intelligent Data Analysis	SEP 08-10, 2005		Madrid, SPAIN	1	0	0	0	1	0302-9743	3-540-28795-7	WOS:000232273600002	
S	Ferrandiz, S; Boulle, M						Perner, P; Imilya, A		Supervised evaluation of dataset partitions: Advantages and practice								MACHINE LEARNING AND DATA MINING IN PATTERN RECOGNITION, PROCEEDINDS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		3587				600	609					2005	2005	In the context of large databases, data preparation takes a greater importance : instances and explanatory attributes have to be carefully selected. In supervised learning, instances partitioning techniques have been developped for univariate representations, leading to precise and comprehensible evaluations of the amount of information contained in an attribute, with respect to the target attribute. Still, the multivariate case remains unstated.In this paper, we describe the partitioning intrinsic convenience for data preparation and we settle a framework for supervised partitioning. A new evaluation criterion of labelled objects partitions, which is based on Minimum Description Length principle, is then set and tested on real and synthetic data sets.				4th International Conference on Machine Learning and Data Minining in Pattern Recognition	JUL 09-11, 2005		Leipzig, GERMANY	1	0	0	0	1	0302-9743	3-540-26923-1	WOS:000230895100059	
S	Hsu, CC; Yang, CY; Yang, JS								Associating kNN and SVM for higher classification accuracy								COMPUTATIONAL INTELLIGENCE AND SECURITY, PT 1, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		3801				550	555					2005	2005	The paper proposed a hybrid two-stage method of support vector machines (SVM) to increase its performance in classification accuracy. In this model, a filtering stage of the k nearest neighbor (kNN) rule was employed to collect information from training observations and re-evaluate balance weights for the observations based on their influences. The balance weights changed the policy of the discrete class label. A novel idea of real-valued class labels for transferring the balance weights was therefore proposed. Embedded in the class label, the weights given as the penalties of the uncertain outliers in the classification were considered in the quadratic programming of SVM, and produced a different hyperplane with higher accuracy. The adoption of kNN rule in the filtering stage has the advantage to distinguish the uncertain outliers in an independent way. The results showed that the classification accuracy of the hybrid model was higher than that of the classical SVM.				International Conference on Computational Intelligence and Security	DEC 15-19, 2005	IEEE Computat Intelligence, Hong Kong Chapter; Xidian Univ; Hong Kong Baptist Univ; Natl Nat Sci Fdn China; Guangdong Univ Technol	Xi'an, PEOPLES R CHINA	1	0	0	0	1	0302-9743	3-540-30818-0	WOS:000234873700080	
B	Jaeger, S; Ma, HF; Doermann, D			IEEE Computer Society					Identifying script on word-level with informational confidence								EIGHTH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, VOLS 1 AND 2, PROCEEDINGS							416	420		10.1109/ICDAR.2005.134			2005	2005	In this paper we present a multiple classifier system for script identification. Applying a Gabor filter analysis of textures on word-level, our system identifies Latin and non-Latin words in bilingual printed documents. The classfier system comprises four different architectures based on nearest neighbors, weighted Euclidean distances, Gaussian mixture models, and support vector machines. We report results for Arabic, Chinese, Hindi, and Korean script. Moreover we show that combining informational confidence values using sum-rule can consistently outperform the best single recognition rate.				8th International Conference on Document Analysis and Recognition (ICDAR 2005)	AUG 29-SEP 01, 2005	ABBYY Software House; BK 21 Sch Informat Technol KAIST; Elect & Telecommun Res Inst; Hitachi Cent Res Lab; IBM Corp; Int Assoc Pattern Recognit; Korea Adv Inst Sci & Technol; Korea Informat Sci Soc; Korea Sci & Engn Fdn; Minist Informat & Commun; Inst Informat Assessment; Microsoft	Seoul, SOUTH KOREA	1	0	0	0	1		0-7695-2420-6	WOS:000232022600082	
S	Li, YG; Hu, ZH; Cai, YZ; Zhang, WD						Wang, L; Chen, K; Ong, YS		Support vector based prototype selection method for nearest neighbor rules								ADVANCES IN NATURAL COMPUTATION, PT 1, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		3610				528	535					2005	2005	The Support vector machines derive the class decision hyper planes from a few, selected prototypes, the support vectors (SVs) according to the principle of structure risk minimization, so they have good generalization ability. We proposed a new prototype selection method based on support vectors for nearest neighbor rules. It selects prototypes only from support vectors. During classification, for unknown example, it can be classified into the same class as the nearest neighbor in feature space among all the prototypes. Computational results show that our method can obtain higher reduction rate and accuracy than popular condensing or editing instance reduction method.				1st International Conference on Natural Computation (ICNC 2005)	AUG 27-29, 2005	Xiangtang Univ; IEEE Circuits & Syst Soc; IEEE Computat Intelligence Soc; IEEE Control Syst Soc; Int Neural Network Soc; European Neural Network Soc; Chinese Assoc Artificial Intelligence; Japanese Neural Network Soc; Int Fuzzy Syst Assoc; Asia Pacific Neural Network Assembly; Fuzzy Math & Syst Assoc China; Hunan Comp Federat	Changsha, PEOPLES R CHINA	1	0	0	0	1	0302-9743	3-540-28323-4	WOS:000232222400068	
S	Shang, WQ; Huang, HK; Zhu, HB; Lin, YM; Wang, ZH; Qu, YL								An improved kNN algorithm - Fuzzy kNN								COMPUTATIONAL INTELLIGENCE AND SECURITY, PT 1, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		3801				741	746					2005	2005	As a simple, effective and nonparametric classification method, kNN algorithm is widely used in text classification. However, there is an obvious problem: when the density of training data is uneven it may decrease the precision of classification if we only consider the sequence of first k nearest neighbors but do not consider the differences of distances. To solve this problem, we adopt the theory of fuzzy sets, constructing a new membership function based on document similarities. A comparison between the proposed method and other existing kNN methods is made by experiments. The experimental results show that the algorithm based on the theory of fuzzy sets (fkNN) can promote the precision and recall of text categorization to a certain degree.				International Conference on Computational Intelligence and Security	DEC 15-19, 2005	IEEE Computat Intelligence, Hong Kong Chapter; Xidian Univ; Hong Kong Baptist Univ; Natl Nat Sci Fdn China; Guangdong Univ Technol	Xi'an, PEOPLES R CHINA	1	0	0	0	1	0302-9743	3-540-30818-0	WOS:000234873700109	
S	Shi, ZZ; Luo, P; Hao, YL; Li, GH; Stumptner, M; He, Q; Quirchmayr, G				Stumptner, Markus/B-5558-2009		Shi, Z; He, Q		Intelligent technology for well logging analysis								INTELLIGENT INFORMATION PROCESSING II	INTERNATIONAL FEDERATION FOR INFORMATION PROCESSING		163				373	382		10.1007/0-387-23152-8_48			2005	2005	Well logging analysis plays an essential role in petroleum exploration and exploitation. It is used to identify the pay zones of gas or oil in the reservoir formations. This paper applies intelligent technology for well logging analysis, particular combining data mining and expert system together, and proposes an intelligent system for well log analysis called IntWeL Analyzer in terms of data mining platform MSMiner and expert system tool OKPS. The architecture of IntWeL Analyzer and data mining algorithms, including Ripper algorithm and MOUCLAS algorithm are also presented. MOUCLAS is based on the concept of the fuzzy set membership function that gives the new approach a solid mathematical foundation and compact mathematical description of classifiers. The aim of the study is the use of intelligent technology to interpret the pay zones from well logging data for the purpose of reservoir characterization. This approach is better than conventional techniques for well logging interpretation that cannot discover the correct relation between the well logging data and the underlying property of interest.				2nd International Conference on Intelligent Information Processing	OCT 21-23, 2004	IFIP TC12, WG12 3	Beijing, PEOPLES R CHINA	1	0	0	0	1	1571-5736	0-387-23151-X	WOS:000225784400048	
B	Wang, JG; Neskovic, P; Cooper, LN			IEEE					An adaptive nearest neighbor algorithm for classification								Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9							3069	3074					2005	2005	The k-nearest neighbor rule is one of the simplest and most attractive pattern classification algorithms. It can be interpreted as an empirical Bayes classifier based on the estimated a posteriori probabilities from the k nearest neighbors. The performance of the k-nearest neighbor rule relies on the locally constant a posteriori probability assumption. This assumption, however, becomes problematic in high dimensional spaces due to the curse of dimensionality. In this paper we introduce a locally adaptive nearest neighbor rule. Instead of using the Euclidean distance to locate the nearest neighbors, the proposed method takes into account the effective influence size of each training example and the statistical confidence with which the label of each training example can be trusted. We test the new method on real-world benchmark datasets and compare it with the standard k-nearest neighbor rule and the support vector machines. The experimental results confirm the effectiveness of the propose method.				4th International Conference on Machine Learning and Cybernetics	AUG 18-21, 2005	IEEE Systems, Man & Cybernet TCC; Hong Kong Polytechn Univ; Hebei Univ; S China Univ Technol; Chongqing Univ; Sun Yatsen Univ; Harbin Inst Technol; Int Univ Germany	Canton, PEOPLES R CHINA	1	2	0	0	3		0-7803-9091-1	WOS:000235325604089	
J	Roncaglia, A; Elmi, I; Dori, L; Rudan, M								Adaptive K-NN for the detection of air pollutants with a sensor array								IEEE SENSORS JOURNAL			4	2			248	256		10.1109/JSEN.2004.823653			APR 2004	2004	The field of air-quality monitoring is gaining increasing interest, with regard to both indoor environment and air-pollution control in open space. This work introduces a pattern recognition technique based on adaptive K-nn applied to a multisensor system, optimized for the recognition of some relevant tracers for air pollution in outdoor environment, namely benzene, toluene, and xylene (BTX), NO2, and CO. The pattern-recognition technique employed aims at recognizing the target gases within an air sample of unknown composition and at estimating their concentrations. It is based on PCA and K-nn classification with an adaptive vote technique based on the gas concentrations of the training samples associated to the K-neighbors. The system is tested in a controlled environment composed of synthetic air with a fixed humidity rate (30%) at concentrations in the ppm range for BTX and NO2, in the range of 10 ppm for CO. The pattern recognition technique is experimented on a knowledge base composed of a limited number of samples (130), with the adoption of a leave-one-out procedure in order to estimate the classification probability. In these conditions, the system demonstrates the capability to recognize the presence of the target gases in controlled conditions with a high hit-rate. Moreover, the concentrations of the individual components of the test samples are successfully estimated for BTX and NO2 in more than 80% of the considered cases, while a lower hit-rate (69%) is reached for CO.								1	1	0	0	2	1530-437X		WOS:000220157800012	
S	Franco, A; Maltoni, D; Nanni, L						Kittler, J; Petrou, M; Nixon, M		Reward-punishment editing								PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, VOL 4	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION						424	427		10.1109/ICPR.2004.1333793			2004	2004	In this work a novel editing technique is proposed. The basic idea of the algorithm is to reward patterns that contribute to a correct classification and to punish those that provide a wrong one. Reward-punishment is performed according to two criteria: the former operates at very local level while the latter analyses the training set at coarser scales in a multi-resolution fashion. A score is calculated for each pattern according to the two criteria and patterns whose score is lower than a predefined threshold are edited out. Experiments carried out on two difficult classification problems show the superiority of this method with respect to other well known approaches.				17th International Conference on Pattern Recognition (ICPR)	AUG 23-26, 2004	Int Assoc Pattern Recognit; Univ Surrey; UniS; IEEE Comp Soc; HP Res Labs Bristol	British Machine Vis Assoc, Cambridge, ENGLAND	1	1	0	0	2	1051-4651	0-7695-2128-2	WOS:000223878400103	
S	Park, SB; Chang, JH; Zhang, BT						Gelbukh, A		Korean compound noun decomposition using syllabic information only								COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING	LECTURE NOTES IN COMPUTER SCIENCE		2945				146	157					2004	2004	The compound nouns are freely composed in Korean, since it is possible to concatenate independent nouns without a postposition. Therefore, the systems that handle compound nouns such as machine translation and information retrieval have to decompose them into single nouns for the further correct analysis of texts. This paper proposes the GECORAM (GEneralized COmbination of Rule-based learning And Memory-based learning) algorithm for Korean compound noun decomposition using only syllabic information. The merit of rule-based learning algorithms is high comprehensibility, but they shows low performance in many application tasks. To tackle this problem, GECORAM combines the rule-based learning and memory-based learning. According to the experimental results, GECORAM shows higher accuracy than rule-based learning or memory-based learning alone.				5th International Conference on Intelligent Text Processing and Computational Linguistics	FEB 15-21, 2004	Assoc Computat Linguist	Seoul, SOUTH KOREA	1	0	0	0	1	0302-9743	3-540-21006-7	WOS:000189417900018	
S	Viswanath, P; Murty, MN; Bhatnagar, S						Kittler, J; Petrou, M; Nixon, M		A pattern synthesis technique with an efficient nearest neighbor classifier for binary pattern recognition								PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, VOL 4	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION						416	419					2004	2004	Important factors affecting the efficiency and performance of the nearest neighbor classifier (NNC) are space, classification time requirements and for high dimensional data, due to the curse of dimensionality, the training set size should be large. In this paper we propose novel techniques to improve the performance of NNC and at the same time to reduce its computational burden. A compact representation of the training set along with an efficient NNC which does implicit pattern synthesis is presented. A comparison of empirical results is made with relevant methods.				17th International Conference on Pattern Recognition (ICPR)	AUG 23-26, 2004	Int Assoc Pattern Recognit; Univ Surrey; UniS; IEEE Comp Soc; HP Res Labs Bristol	British Machine Vis Assoc, Cambridge, ENGLAND	1	0	0	0	1	1051-4651	0-7695-2128-2	WOS:000223878400101	
B	Vogt, P						Pollack, J; Bedau, M; Husbands, P; Ikegami, T; Watson, RA		Minimum cost and the emergence of the Zipf-Mandelbrot law								Artificial Life IX							214	219					2004	2004	This paper illustrates how the Zipf-Mandelbrot law can emerge in language as a result of minimising the cost of categorising sensory images. The categorisation is based on the discrimination game in which sensory stimuli are categorised at different hierarchical layers of increasing density. The discrimination game is embedded in a variant of the language game model, called the selfish game, which in turn is embedded in the framework of iterated learning. The results indicate that a tendency to communicate in general terms, which is less costly, can contribute to the emergence of the Zipf-Mandelbrot law.				9th International Conference on the Simulation and Synthesis of Artificial Life (ALIFE9)	SEP 12-15, 2004	Int Soc Artificial Life; Brandeis Univ	Boston, MA	1	0	0	0	1		0-262-66183-7	WOS:000231382900035	
B	Yang, Y; Zheng, CX; Lin, P						Wei, D; Wang, H; Peng, ZY; Kara, A		Image thresholding based on spatially weighted fuzzy C-means clustering								FOURTH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY, PROCEEDINGS							184	189					2004	2004	In this paper, a novel spatially weighted fuzzy c-means (SWFCM) clustering algorithm for image thresholding is presented. The algorithm is formulated by incorporating the spatial neighborhood information into the standard FCM clustering algorithm. Two improved implementations of the k-nearest neighbor (k-NN) algorithm are developed for calculating the weight in the SWFCM algorithm so as to improve the performance of image thresholding. To speed up the FCM algorithm, the iteration is carried out with the statistical gray level histogram of image instead of the conventional whole data of image. Some comparisons with classical thresholding algorithm and fuzzy thresholding algorithm are also given in this paper. Experimental results on both synthetic and real images are given to demonstrate the effectiveness of the proposed algorithm. In addition, due to the neighborhood model, the proposed method is more tolerant to noise.				4th International Conference on Computer and Information Technology	SEP 14-16, 2004	Wuhan Univ; Univ Aizu; Natl Nat Sci Fdn China; IEEE Engn Med & Biol Soc	Wuhan, PEOPLES R CHINA	1	1	0	0	2		0-7695-2216-5	WOS:000224461900029	
S	Zeng, XC; Martinez, TR			ieee					Feature weighting using neural networks								2004 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-4, PROCEEDINGS	IEEE International Joint Conference on Neural Networks (IJCNN)						1327	1330					2004	2004	In this work we propose a feature weighting method for classification tasks by extracting relevant information from a trained neural network. This method weights an attribute based on strengths (weights) of related links in the neural network, in which an important feature is typically connected to strong links and has more impact on the outputs. This method is applied to feature weighting for the nearest neighbor classifier and is tested on 15 real-world classification tasks. The results show that it can improve the nearest neighbor classifier on 14 of the 15 tested tasks, and also outperforms the neural network on 9 tasks.				IEEE International Joint Conference on Neural Networks (IJCNN)	JUL 25-29, 2004	IEEE; IEEE Neural Networks Soc; Hungarian Acad Sci, Comp & Automat Res Inst; Katholieke Univ Leuven; Republic Hungary, Natl Commun & Informat Council	Budapest, HUNGARY	1	0	0	0	1	1098-7576	0-7803-8359-1	WOS:000224941900230	
S	Behnke, S				Behnke, Sven/B-5509-2013	Behnke, Sven/0000-0002-5040-7525			Hierarchical neural networks for image interpretation - Introduction								HIERARCHICAL NEURAL NETWORKS FOR IMAGE INTERPRETATION	Lecture Notes in Computer Science		2766				1	+					2003	2003									1	0	0	0	1	0302-9743	3-540-40722-7	WOS:000185939800001	
B	Bian, HY; Mazlack, L						Walker, EL		Fuzzy-rough nearest-neighbor classification approach								NAFIPS'2003: 22ND INTERNATIONAL CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS PROCEEDINGS							500	505					2003	2003	This paper proposes a new fuzzy-rough nearest-neighbor (NN1) approach based on the fuzzy-rough sets theory. This approach is more suitable to be used under partially exposed and unbalanced data set compared with crisp NN and fuzzy NN approach. Then the new method is applied to China listed company financial distress prediction, a typical classification task under partially exposed and unbalanced learning space. Results suggest that the compared with crisp and fuzzy nearest neighbor classification methods, this method provides more accurate prediction result under this research design.				22nd International Conference of the North-American-Fuzzy-Information-Processing-Society (NAFIPS)	JUL 24-26, 2003	IEEE Syst, Man & Cybernet Soc; IEEE; N Amer Fuzzy Informat Proc Soc	CHICAGO, IL	1	0	0	0	1		0-7803-7918-7	WOS:000185095000089	
S	Huang, CC; Lee, HM						Berthold, MR; Lenz, HJ; Bradley, E; Kruse, R; Borgelt, C		A novel partial-memory learning algorithm based on grey relational structure								ADVANCES IN INTELLIGENT DATA ANALYSIS V	LECTURE NOTES IN COMPUTER SCIENCE		2810				68	75					2003	2003	In instance-based learning, the storage of instances must increase along with the number of training instances. In addition, it usually takes too much time to classify an unseen instance because all training instances have to be considered in determining the 'nearness' between instances. This paper proposes a novel partial-memory learning method based on the grey relational structure. That is, only some of the training instances are adopted for classification. The relationships among instances are first determined according to the grey relational structure. In this relational structure, the inward edges of each training instance, indicating how many times each instance is used as the nearest neighbor or neighbors in determining the class labels of other instances, can be found. This approach excludes the training instances with no or few inward edges for learning. By using the proposed approach, new instances can be classified with a few training instances. Five datasets are used for demonstrating the performance of the proposed approach. Experimental results indicate that the classification accuracy can be maintained when most of the training instances are pruned prior to learning. Meanwhile, the number of remained training instances is comparable to that of other existing pruning techniques.				5th International Symposium on Intelligent Data Analysis	AUG 28-30, 2003		BERLIN, GERMANY	1	0	0	0	1	0302-9743	3-540-40813-4	WOS:000186104900007	
S	Li, JY; Ng, SK; Wong, LS				Wong, Limsoon/E-5033-2010		Calvanese, D; Lenzerini, M; Motwani, R		Bioinformatics adventures in database research								DATABASE THEORY ICDT 2003, PROCEEDINGS	Lecture Notes in Computer Science		2572				31	46					2003	2003	Informatics has helped launch molecular biology into the genomic era. It appears certain that informatics will remain a major contributor to molecular biology in the post-genome era. We discuss here data integration and datamining in bioinformatics, as well as the role that database theory played in these topics. We also describe LIMS as a third key topic in bioinformatics where advances in database system and theory can be very relevant.				9th International Conference on Database Theory (ICDT)	JAN 08-10, 2003	Univ Roma, Dipartimento Informat Sistemist	SIENA, ITALY	1	0	0	0	1	0302-9743	3-540-00323-1	WOS:000181548600003	
S	Mountrakis, G; Agouris, P						Hadzilacos, T; Manolopoulos, Y; Roddick, JF; Theodoridis, Y		Learning similarity with fuzzy functions of adaptable complexity								ADVANCES IN SPATIAL AND TEMPORAL DATABASES, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		2750				412	429					2003	2003	A common approach in database queries involves the multidimensional representation of objects by a set of features. These features are compared to the query representation and then combined together to produce a total similarity metric. In this paper we introduce a novel technique for similarity learning within features (attributes) by manipulating fuzzy membership functions (FMFs) of different complexity. Our approach is based on a gradual complexity increase adaptable to problem requirements. The underlying idea is that less adaptable functions will act as approximations for more complex ones. We begin by interpolating a set of planes in the training dataset and due to linearity we get a fast first impression of the underlying complexity. We proceed to interpolate two asymmetrical sigmoidal functions whose initial approximations are calculated from the plane properties. If satisfactory accuracy is not achieved we provide advanced modeling capabilities by investigating FMFs parameters and convolving their output with additional functions.				8th International Symposium on Advances in Spatial and Temporal Databases	JUL 24-27, 2003	Microsoft; MDS Marathon Data Syst; Comp Technol Inst; Univ Piraeus	SANTORINI ISL, GREECE	1	0	0	0	1	0302-9743	3-540-40535-6	WOS:000185178500024	
B	Shibata, T; Kato, T; Wada, T						Wu, XD; Tuzhilin, A; Shavlik, J		K-D decision tree: An accelerated and memory efficient nearest neighbor classifier								THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS							641	644					2003	2003	Most nearest neighbor (NN) classifiers employ NN search algorithms for the acceleration. However, NN classification does not always require the NN search. Based on this idea, we propose a novel algorithm named k-d decision tree (KDDT). Since KDDT uses Voronoi condensed prototypes, it is less memory consuming than naive NN classifiers. We have confirmed that KDDT is much faster than NN search based classifiers through the comparative, experiment (from 9 to 369 times faster).				3rd IEEE International Conference on Data Mining	NOV 19-22, 2003	IEEE Comp Soc TCCI; IEEE Comp Soc TCPAMI	MELBOURNE, FL	1	0	0	0	1		0-7695-1978-4	WOS:000188999400102	
S	Yang, JY; Yang, MQ; Ersoy, OK						Kaynak, O; Alpaydin, E; Oja, E; Xu, L		Exploring protein functional relationships using genomic information and data mining techniques								ARTIFICAIL NEURAL NETWORKS AND NEURAL INFORMATION PROCESSING - ICAN/ICONIP 2003	LECTURE NOTES IN COMPUTER SCIENCE		2714				1073	1080					2003	2003	An approach that uses both supervised and unsupervised learning methods for exploring protein functional relationships is reported; we refer to this as Maximum Contrast (MC) tree. The tree is constructed by performing a hierarchical decomposition of the feature space; this step is performed regardless of complex nature of protein functions, i.e. it performs this decomposition even without knowledge of the protein functional class labels. In order to test our algorithm, we have constructed a library of Protein Phylogenetic Profiles for the proteins in the yeast Saccharomyces Cerevisiae with 60 species. Results showed our algorithm compares favorably to other classification algorithms such as the decision tree algorithms C4.5, C5, and to support vector machines.				Joint International Conference on Artificial Neural Networks (ICANN)/International on Neural Information Processing (ICONIP)	JUN 26-29, 2002	Bogazici Univ Fdn; USAF, European Off Aerosp Res & Dev; Turkish Sci & Tech Res Council	ISTANBUL, TURKEY	1	0	1	0	1	0302-9743	3-540-40408-2	WOS:000185378100128	
J	Gyorfi, L; Schafer, D; Walk, H								Relative stability of global errors of nonparametric function estimators								IEEE TRANSACTIONS ON INFORMATION THEORY			48	8			2230	2242		10.1109/TIT.2002.800491			AUG 2002	2002	This paper presents relative stability properties of various nonparametric density estimators (histogram, kernel estimates) and of regression estimators (partitioning, kernel, and nearest neighbor estimates). In density estimation, let E(n) denote the L(1) error of an estimate calculated from n data, whereas in regression estimation, the L(2) error of the estimate is used.Sufficient conditions forE(n)/E{E(n)} --> 1in probability are provided. If this limit holds, the asymptotic behavior of the random error E(n) can be characterized by its expectation E{E(n)}, and one may apply, for example, the established rate-of-convergence results for E{E(n)}.								1	0	0	0	1	0018-9448		WOS:000177000400008	
S	Bao, YG; Du, XY; Ishii, N				ruc, comp_xinxi/E-4212-2012		Yin, H; Allinson, N; Freeman, R; Keane, J; Hubbard, S		Combining feature selection with feature weighting for k-NN classifier								INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING - IDEAL 2002	LECTURE NOTES IN COMPUTER SCIENCE		2412				461	468					2002	2002	The k-nearest neighbor (k-NN) classification is a simple and effective classification approach. However, it suffers from over-sensitivity problem due to irrelevant and noisy features. In this paper, we propose an algorithm to improve the effectiveness of k-NN by combining these two approaches. Specifically, we select all relevant features firstly, and then assign a weight to each one. Experimental results show that our algorithm achieves the highest accuracy or near to the highest accuracy on all test datasets. It also achieves higher generalization accuracy compared with the well-known algorithms IB1-4 and C4.5.				3rd International Conference on Intelligent Data Engineering and Automated Learning	AUG 12-14, 2002	Univ Manchester Inst Sci & Technol	MANCHESTER, ENGLAND	1	0	0	0	1	0302-9743	3-540-44025-9	WOS:000187252500069	
J	Al-Ammar, AS; Barnes, RM								Supervised cluster classification using the original n-dimensional space without transformation into lower dimension								JOURNAL OF CHEMOMETRICS			15	1			49	67		10.1002/1099-128X(200101)15:1<49::AID-CEM631>3.0.CO;2-2			JAN 2001	2001	A novel supervised classification algorithm, direct clustering in n-dimensional space (DCNS), was developed for difficult data sets where conventional methods of supervised clustering are expected to fail. The method is based, when applied on >3-dimensional spaces, on an algorithm that performs special treatment on the measurement space, so that the treated space can allow a computer-aided clustering methodology similar to that used by human vision, However, unlike other techniques that reduce the dimensionality of the space, the proposed method preserves the original dimensions while performing a computer-simulated human vision clustering in the original n-dimensional space. Thus the overlap between clusters that results from the dimensionality reduction is eliminated. The proposed method was applied to two real data sets. The results are compared with those obtained using principal component analysis (PCA), an artificial neural network (ANN), and the k-nearest-neighbor (KNN) technique. On one data set containing only two clusters, the DCNS algorithm gives better cluster separation than the other three methods. However, when all four methods were applied on the second data set, containing eight different clusters, PCA, ANN and KNN were unable to give useful cluster separation, while the DCNS method was able to separate all clusters and classify the unknown points successfully with their corresponding clusters. The DCNS technique is able to perform other important cluster analysis tasks, such as testing the discriminatory power of a variable, selecting one variable from many, and conducting preliminary unsupervised clustering. Copyright (C) 2000 John Wiley & Sons, Ltd.								1	1	0	0	2	0886-9383		WOS:000166718900005	
J	Brasini, F; Rovatti, R; Hermle, T; Rudan, M								Cluster translation for concentration estimation								SENSORS AND ACTUATORS B-CHEMICAL			69	3			219	222		10.1016/S0925-4005(00)00492-5			OCT 25 2000	2000	A method to estimate the concentration of samples acquired by means of nonlinear sensors is proposed. It is tested using data provided by the MOSES system and shows improvement upon pure nearest-neighbour (N-N) estimation when data are not available for all concentrations. (C) 2000 Elsevier Science S.A. All rights reserved.				6th International Symposium on Electronic Noses (ISOEN 99)	SEP 20-22, 1999		TUBINGEN, GERMANY	1	0	0	0	1	0925-4005		WOS:000090043400003	
S	Holz, HJ; Loew, MH						Ferri, FJ; Inesta, JM; Amin, A; Pudil, P		Design choices and theoretical issues for relative feature importance, a metric for nonparametric discriminatory power								ADVANCES IN PATTERN RECOGNITION	LECTURE NOTES IN COMPUTER SCIENCE		1876				696	705					2000	2000	We have developed relative feature importance (RFI), a metric for the classifier-independent ranking of features. Previously, we have shown the metric to rank accurately features for a wide variety of artificial and natural problems, for both two-class and multi-class problems. In this paper, we present the design of the metric, including both theoretical considerations and statistical analysis of the possible components.				Joint International-Association-of-Pattern-Recognition International Workshops - SSPR 2000 and SPR 2000	AUG 30-SEP 01, 2000	Int Assoc Pattern Recognit; Univ Valencia, Dept Informat	UNIV ALICANTE, ALICANTE, SPAIN	1	0	0	0	1	0302-9743	3-540-67946-4	WOS:000171155700072	
S	Latourrette, M						LaopezDeMantaras, R; Plaza, E		Toward an explanatory similarity measure for nearest-neighbor classification								MACHINE LEARNING: ECML 2000	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		1810				238	245					2000	2000	In this paper, a new similarity measure for nearest-neighbor classification is introduced. This measure is an approximation of a theoretical similarity that has some interesting properties. In particular, this latter is a step toward a theory of concepts formation. It renders identical some examples that have distinct representations. Moreover, these examples share some properties relevant for the concept undertaken. Hence, a rule-based representation of the concept can be inferred from the theoretical similarity. Moreover, in this paper, the approximation is validated by some preliminary experiments on non-noisy datasets.				11th European Conference on Machine Learning	MAY 31-JUN 02, 2000	European Network Excellence Machine Learn; CSIC; Spanish Sci & Technol Council; Catalan Assoc Artifical Intell; Inst Invest Intell Artif	BARCELONA, SPAIN	1	0	0	0	1	0302-9743	3-540-67602-3	WOS:000166853300025	
S	Mitani, Y; Hamamoto, Y						Sanfeliu, A; Villanueva, JJ; Vanrell, M; Alquezar, R; Jain, AK; Kittler, J		Classifier design based on the use of nearest neighbor samples								15TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, VOL 2, PROCEEDINGS: PATTERN RECOGNITION AND NEURAL NETWORKS	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION						769	772					2000	2000	A considerable amount of effort has been devoted to design a classifier in small training sample size situations. In this paper, we propose to design a nonparametric classifier based on the use of nearest neighbor samples. In the experiments, both the artificial and real data sets were used. The proposed classifier is compared with the 1-NN, k-NN, and Euclidcan distance classifiers in terms of the error rate, in small training sample size situations. Experimental results show that the proposed classifier is very effective, even in practical situations.				15th International Conference on Pattern Recognition (ICPR-2000)	SEP 03-07, 2000	Int Assoc Pattern Recognit; Assoc Pattern Recognit & Image Anal; Ctr Visio Comp; Univ Autonoma Barcelona; Univ Politecn Catalunya; Comissionat Universitats Recerca, Generalitat Catalunya Dept Presidencia; Minist Ciencia Tecnol; Fdn Catalana Recerca; HP Invent	BARCELONA, SPAIN	1	0	0	0	1	1051-4651	0-7695-0751-4	WOS:000166814800181	
S	Pierson, WE; Ross, T						Zelnio, EG		Automatic target recognition (ATR) evaluation theory: a survey								ALGORITHMS FOR SYNTHETIC APERTURE RADAR IMAGERY VII	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		4053				666	676					2000	2000	Proper evaluation of a pattern recognition system in the lab is paramount to its success in the field. In most commercial pattern recognition applications, such as breast cancer detection, optical character recognition, and industrial quality assurance, the boundaries and expectation of the system are well defined. This is due, at least in part, to an excellent understanding of the problem and data space for these applications. For these functions, a method for rigorous evaluation is well understood.However, the size and complexity of the data and problem spaces for automatic target recognition (ATR) systems is enormous. The consequences are that a complete understanding of how an ATR system will perform in practice is extraordinarily difficult to estimate. Thus the act of evaluating an ATR system becomes as important as its design.This paper compiles and reports the techniques used to evaluate ATR system performance. It surveys the specific difficulties associated with ATR performance estimation as well as approaches used to mitigate these obstacles.				Conference on Algorithms for Synthetic Aperture Radar Imagery VII	APR 24-28, 2000	SPIE	ORLANDO, FL	1	0	0	0	1	0277-786X	0-8194-3679-8	WOS:000089706700064	
S	Sebban, M; Nock, R						Hamilton, HJ		Identifying and eliminating irrelevant instances using information theory								ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		1822				90	101					2000	2000	While classical approaches deal with prototype selection (PS) using accuracy maximization, we investigate PS in this paper as an information preserving problem. We use information theory to build a statistical criterion from the nearest-neighbor topology. This statistical framework is used in a backward prototype selection algorithm (PSRCG). It consists in identifying and eliminating uninformative instances, and then reducing the global uncertainty of the learning set. We draw from experimental results and rigorous comparisons two main conclusions: (i) our approach provides a good compromise solution based on the requirement to keep a small number of prototypes, while not compromising the classification accuracy; (ii) our PSRCG algorithm seems to be robust in the presence of noise. Performances on several benchmarks tend to show the relevance and the effectiveness of our method in comparison with the classic PS algorithms based on the accuracy.				13th Biennial Conference of the Canadian-Society-for-Computational-Studies-of-Intelligence (AI 2000)	MAY 14-17, 2000	Univ Regina; Simon Fraser Univ; Canadian Soc Computat Studies Intelligence	MONTREAL, CANADA	1	0	0	0	1	0302-9743	3-540-67557-4	WOS:000166853200008	
J	Bagui, SC; Mehra, KL								Classification of multiple observations using multi-stage rank nearest neighbor rule								JOURNAL OF STATISTICAL PLANNING AND INFERENCE			76	1-2			163	183		10.1016/S0378-3758(98)00137-2			FEB 1 1999	1999	In this article, a multi-stage (M-stage) rank nearest-neighbor (MRNN)-type rule is proposed and studied for the classification of a sample of multiple (m) independent univariate observations between two populations. The asymptotic total probability of misclassification (TPMC) - viz., the asymptotic risk R-(M)(m) - for the proposed MRNN rule is derived. It is shown firstly that (i) the asymptotic risk R-(1)(2) of the 1st stage RNN rule for m = 2 is lower than the corresponding risk R-(1)(1) for m = 1, by a factor less than one, and secondly that (ii) for m = 2, the M-stage rule asymptotic risk R(M)(2) decreases as the number M of the stages employed increases. The former result leads to an improved upper bound on R-(1)(2) in terms of Bayes risk R*(1) (cf Cover and Hart (1967) IEEE Trans. Inform. Theory, Das Gupta and Lin (1980) Sankhya A). Also, a cross-validation-type estimator for the asymptotic risk R-(1)(m) is shown to be asymptotically unbiased and L-2-consistent. Finally, some comparative Monte-Carlo results are reported to illuminate the performance characteristics of the proposed rule in small sample situations. (C) 1999 Elsevier Science B.V. All rights reserved.								1	0	0	0	1	0378-3758		WOS:000078424300011	
S	El-Maleh, K; Samouelian, A; Kabal, P			IEEE; IEEE					Frame level noise classification in mobile environments								ICASSP '99: 1999 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, PROCEEDINGS VOLS I-VI	International Conference on Acoustics Speech and Signal Processing (ICASSP)						237	240					1999	1999	Background environmental noises degrade the performance of speech-processing systems (e.g. speech coding, speech recognition). By modifying the processing according to the type of background noise, the performance can be enhanced. This requires noise classification. In this paper, four pattern-recognition frameworks have been used to design noise classification algorithms. Classification is done on a frame-by-frame basis (e.g. once every 20 ms). Five commonly encountered noises in mobile telephony (i.e. car, street, babble, factory, and bus) have been considered in our study. Our experimental results show that the Line Spectral Frequencies (LSF's) are robust features in distinguishing the different classes of noises.				IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 99)	MAR 15-19, 1999	IEEE; IEEE Signal Proc Soc	PHOENIX, AZ	1	0	0	0	1	1520-6149	0-7803-5041-3	WOS:000079690700060	
S	Talukder, A; Casasent, D; Lee, HW; Keagy, PM; Schatzki, TF						Meyer, GE; DeShazer, JA		A new feature extraction method for classification of agricultural products from X-ray images								PRECISION AGRICULTURE AND BIOLOGICAL QUALITY	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		3543				119	130		10.1117/12.336874			1999	1999	Classification of real-time X-ray images of randomly oriented touching pistachio nuts is discussed. The ultimate objective is the development of a system for automated non-invasive detection of defective product items on a conveyor belt. We discuss the extraction of new features that allow better discrimination between damaged and clean items (pistachio nuts). This feature extraction and classification stage is the new aspect of this paper; our new maximum representation and discriminating feature (MRDF) extraction method computes nonlinear features that are used as inputs to a new modified k nearest neighbor classifier. In this work, the MRDF is applied to standard features (rather than iconic data). The MRDF is robust to various probability distributions of the input class and is shown to provide good classification and new ROC (receiver operating characteristic) data.				Conference on Precision Agriculture and Biological Quality	NOV 03-04, 1998	SPIE-Int Soc Opt Engn	BOSTON, MA	1	0	0	0	1	0277-786X	0-8194-3155-9	WOS:000078921900014	
J	Couvreur, C; Bresler, Y								Automatic classification of environmental noise sources by statistical methods								NOISE CONTROL ENGINEERING JOURNAL			46	4			167	182		10.3397/1.2828469			JUL-AUG 1998	1998	This paper shows how the tools of statistical pattern recognition can be used to create an "intelligent" noise monitoring system able to distinguish between the acoustic signals of different types of environmental noise sources, e.g., airplanes, cars, or trucks. The basics of statistical pattern recognition theory are reviewed in a tutorial fashion and illustrated on simple acoustical noise recognition examples. Guidelines for the design, training, and utilization of a pattern classification system are provided, The pitfalls of an intuitive, heuristic approach to these tasks are highlighted. Experimental results obtained by an automatic noise recognition system based on a statistical pattern recognition framework are presented. Finally, possible improvements of this system which are currently being investigated further are discussed. (C) 1998 Institute of Noise Control Engineering.								1	0	0	0	1	0736-2501		WOS:000076119800004	
J	Echanobe, J; de Mendivil, JRG; Garitagoitia, JR; Alastruey, CF								Deformed systems for contextual postprocessing								FUZZY SETS AND SYSTEMS			96	3			335	341		10.1016/S0165-0114(96)00304-1			JUN 16 1998	1998	In this paper a fuzzy method for contextual postprocessing, able to deal with the measurement level output that an isolated character classifier (ICC) can provide for every input letter, is introduced. The ICC information, is expressed as a fuzzy character which is then post-processed, by a deformed system, together with the rest of the fuzzy characters from a word. This deformed system implicitly contains the contextual knowledge provided by a dictionary and it is defined as an extension, for fuzzy inputs, of a classic automaton. Therefore, in the method, the classification of a character is postponed until the context is taken into account. This means that the classification and contextual processes are computed together. The formulation of the deformed systems makes possible the utilization of different strategies for the evidences composition. The method and also the composition strategies are evaluated in a text recognition experiment and high rates are obtained in correcting the characters miss-recognized by the ICC. Moreover, the results are compared with one of the best postprocessing methods and a clear improvement is achieved. (C) 1998 Elsevier Science B.V. All rights reserved.								1	0	0	0	1	0165-0114		WOS:000073252800004	
J	Bagui, SC; Mehra, KL; Vaughn, BK								An M-stage version of the k-RNN rule in statistical discrimination								JOURNAL OF STATISTICAL PLANNING AND INFERENCE			65	2			323	333		10.1016/S0378-3758(97)00055-4			DEC 15 1997	1997	In this article a multi-stage (M-stage) k-rank nearest-neighbor (k-RNN) rule is used to discriminate an unknown observation into one of two populations (or classes). The asymptotic risk (i.e., the total probability of misclassification (TPMC)) of this rule is derived and shown that, as the number of stages increases, the limiting TPMC of the M-stage k-RNN rule decreases. (C) 1997 Elsevier Science B.V.								1	0	0	0	1	0378-3758		WOS:000071508600010	
J	Ros, F; Guillaume, S; BellonMaurel, V				Guillaume, Serge/H-2112-2011				Classification of a granular product using high-level fusion of vision features								JOURNAL OF AGRICULTURAL ENGINEERING RESEARCH			68	2			115	124		10.1006/jaer.1997.0189			OCT 1997	1997	The characterization of a granular product based on image analysis can be a difficult problem because it often requires the combination of a large number of features of different natures extracted from the image. This problem of classification can be solved by two approaches. One of these approaches consists of aggregating the qualitative information which is obtained by considering each individual feature, as a virtual sensor. This is a triple-step system: first, for each feature (i.e. virtual sensor), the samples are given a probability of belonging to a class (clustering); second, these probabilities are aggregated in order to give a global probability of the sample of belonging to each class (supervised neural network); third, the sample is assigned to the class which shows the maximal global probability. This procedure was applied to classify semolina samples. These were obtained by grinding wheat grains. Three classes were defined using three grinding roll gaps of 0.3, 0.4 and 0.5 mm, respectively. The average of correct classification was better than 80%. This methodology is particularly interesting because it gives a very satisfactory result and is quite versatile new features added to the classification process require an update of one part of the procedure only. (C) 1997 Silsoe Research Institute.								1	0	0	0	1	0021-8634		WOS:A1997YF25600005	
J	Dommermuth, F								Target classification using radar range Profiles								FREQUENZ			50	7-8			157	164					JUL-AUG 1996	1996	Based on the large amount of data provided by a measurement campaign in 1992, it has been examined whether high resolution radar range profiles are suitable tools in order to discriminate between different types of aircraft. The nearest-neighbour-type, correlation-based classification rule proposed in this paper already supports optimistic expectations. A conspicous finding is the pronounced dependence of the classification error on target aspect, which is attributed to the dependence of the range profiles on target bank angle.								1	0	0	0	1	0016-1136		WOS:A1996VG31300003	
J	RONG, YM; TZOU, HS								DIAGNOSTIC MONITORING AND SENSITIVITY ANALYSIS OF CONTACT DYNAMICS IN JOINTED STRUCTURES								AIAA JOURNAL			29	12			2215	2221		10.2514/3.10862			DEC 1991	1991	The operation and performance of elastically jointed structures can be degraded by dynamic contacts arising from a number of factors including excessive levels of vibration, inadequate lubrication, and improper joint clearance. In many applications, such as a space structure, periodic disassembly and inspection are impractical; thus, a monitoring and diagnosis system is desired to automatically detect and diagnose significant changes in the dynamic contact state of jointed structures. A time-series-based monitoring and diagnosis system has been formulated to address this need. The system incorporates a cross-entropy minimization method, based on the nearest neighbor classification rule, and a cross-entropy dissimilarity measure to classify a new observation of vibration states into one of a set of prestudied "standard" vibration patterns. The approach is applied to a unit truss cell, representative of space structures, and laboratory experiments are conducted to evaluate its performance and assess its sensitivities. The experimental results indicate that the system can satisfactorily detect and classify changes in the vibration states of such structures.								1	0	0	0	1	0001-1452		WOS:A1991GX69200028	
J	ELSHEIKH, TS; SYIAM, MM								AN EFFICIENT TECHNIQUE FOR LITHOLOGY CLASSIFICATION								IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			27	5			629	632		10.1109/TGRS.1989.35946			SEP 1989	1989									1	0	0	0	1	0196-2892		WOS:A1989AL20700019	
J	NIESSNER, R; HEMMERICH, B; PANNE, U				Niessner, Reinhard/C-1414-2010; Niessner, Reinhard/D-1502-2010; Panne, Ulrich/C-7136-2009				POSSIBILITIES AND LIMITATIONS OF THE PHOTOELECTRIC AEROSOL SENSOR ARRAY APPLIED TO HEAVY-METAL AEROSOLS								FRESENIUS ZEITSCHRIFT FUR ANALYTISCHE CHEMIE			335	7			728	737		10.1007/BF01204077			1989	1989									1	0	0	0	1	0016-1152		WOS:A1989CC28800017	
J	KELLER, JM; QIU, HJ								FUZZY SET METHODS IN PATTERN-RECOGNITION								LECTURE NOTES IN COMPUTER SCIENCE			301				173	182					1988	1988									1	0	0	0	1	0302-9743		WOS:A1988N258400016	
J	DUCHENE, J								A NEW FORM OF DISCRIMINANT SURFACES USING POLAR COORDINATES								PATTERN RECOGNITION			20	4			437	442		10.1016/0031-3203(87)90070-7			1987	1987									1	0	1	0	1	0031-3203		WOS:A1987J359300010	
J	LAHART, MJ								ESTIMATION OF ERROR RATES IN CLASSIFICATION OF DISTORTED IMAGERY								IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			6	4			535	542					1984	1984									1	0	0	0	1	0162-8828		WOS:A1984SY28900016	
J	LEVINSON, SE								A NOTE ON SOME STATISTICAL ASPECTS OF SPEAKER-INDEPENDENT RECOGNITION OF ISOLATED WORDS USING CLUSTERING-TECHNIQUES - REPLY								IEEE TRANSACTIONS ON ACOUSTICS SPEECH AND SIGNAL PROCESSING			29	3			450	452		10.1109/TASSP.1981.1163593			1981	1981									1	0	0	0	1	0096-3518		WOS:A1981LV08000017	
J	SOM, A; DAS, TK; TALUKDER, AK; NATH, AK								ON A METHOD OF SELECTION OF REPRESENTATIVE PATTERNS USING BINARY DISTANCE MATRIX								IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS			10	8			524	529					1980	1980									1	0	1	0	1	0018-9472		WOS:A1980KH94800016	
J	SRIHARI, SN								RECURSIVE IMPLEMENTATION OF A 2-STEP NONPARAMETRIC DECISION RULE								IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			1	1			90	94					1979	1979									1	0	0	0	1	0162-8828		WOS:A1979HA30300012	
J	SRIHARI, SN; WHITE, LJ; SNABB, T								IDENTITY CONDITIONS FOR NEAREST-NEIGHBOR AND POTENTIAL-FUNCTION CLASSIFIERS								INFORMATION SCIENCES			19	1			21	31		10.1016/0020-0255(79)90030-6			1979	1979									1	0	0	0	1	0020-0255		WOS:A1979HK71200002	
J	SAXBERG, BEH; DUEWER, DL; BOOKER, JL; KOWALSKI, BR				Duewer, David/B-7410-2008				PATTERN-RECOGNITION AND BLIND ASSAY TECHNIQUES APPLIED TO FORENSIC SEPARATION OF WHISKIES								ANALYTICA CHIMICA ACTA-COMPUTER TECHNIQUES AND OPTIMIZATION			2	3			201	212					1978	1978									1	0	0	0	1	0003-2670		WOS:A1978GD90900001	
J	LIGGETT, TM								EXTENSIONS OF ERDOS-KO-RADO THEOREM AND A STATISTICAL APPLICATION								JOURNAL OF COMBINATORIAL THEORY SERIES A			23	1			15	21		10.1016/0097-3165(77)90075-9			1977	1977									1	0	0	0	1	0097-3165		WOS:A1977DN75600002	
J	BACHIRI, M; MOUVIER, G								COMPUTERIZED INTERPRETATION OF MASS-SPECTRA OF ORGANIC-COMPOUNDS								ORGANIC MASS SPECTROMETRY			11	12			1272	1280		10.1002/oms.1210111209			1976	1976									1	0	1	0	1	0030-493X		WOS:A1976CX35800008	
J	DUDANI, SA								DISTANCE-WEIGHTED K-NEAREST-NEIGHBOR RULE								IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS			6	4			327	327					1976	1976									1	0	0	0	1	0018-9472		WOS:A1976BL27800011	
J	WOLVERTO.CT				Wolverton, Christopher/B-7542-2009				STRONG CONSISTENCY OF AN ESTIMATE OF ASYMPTOTIC ERROR PROBABILITY OF NEAREST NEIGHBOR RULE								IEEE TRANSACTIONS ON INFORMATION THEORY			19	1			119	120		10.1109/TIT.1973.1054947			1973	1973									1	0	0	0	1	0018-9448		WOS:A1973O347500020	
J	Kang, Pilsung								Locally linear reconstruction based missing value imputation for supervised learning								NEUROCOMPUTING			118				65	78		10.1016/j.neucom.2013.02.016			OCT 22 2013	2013	Most learning algorithms generally assume that data is complete so each attribute of all instances is filled with a valid value. However, missing values are very common in real datasets for various reasons. In this paper, we propose a new single imputation method based on locally linear reconstruction (LLR) that improves the prediction performance of supervised learning (classification & regression) with missing values. First, we investigate how missing values degrade the prediction performance with various missing ratios. Next, we compare the proposed missing value imputation method (LLR) with six well-known single imputation methods for five different learning algorithms based on 13 classification and nine regression datasets. The experimental results showed that (1) all imputation methods helped to improve the prediction accuracy, although some were very simple; (2) the proposed LLR imputation method enhanced the modeling performance more than all other imputation methods, irrespective of the learning algorithms and the missing ratios; and (3) LLR was outstanding when the missing ratio was relatively high and its prediction accuracy was similar to that of the complete dataset. (C) 2013 Elsevier B.V. All rights reserved.								0	0	0	0	0	0925-2312		WOS:000323693700007	
J	Wen, Guihua; Wei, Jia; Wang, Jiabing; Zhou, Tiangang; Chen, L.								Cognitive gravitation model for classification on small noisy data								NEUROCOMPUTING			118				245	252		10.1016/j.neucom.2013.02.033			OCT 22 2013	2013	When performing the classification on the high dimensional, the sparse, or the noisy data, many approaches easily lead to the dramatic performance degradation. To deal with this issue from the different perspective, this paper proposes a cognitive gravitation model (CGM) based on both the law of gravitation in physics and the cognitive laws, where the self-information of each sample instead of mass is applied. Subsequently, a new classifier is designed which utilizes CGM to find k nearest neighbors from each class for the query sample and then classifies this query sample to the class whose cognitive gravitation is largest. The cognitive gravitation of the class is defined as the sum of the cognitive gravitation between its each nearest neighbor and the query sample. The advantage of our approach is that it has a firm and simple mathematical basis while it has good classification performance. The conducted experiments on challenging benchmark data sets validate the proposed model and the classification approach. (C) 2013 Elsevier B.V. All rights reserved.								0	0	0	0	0	0925-2312		WOS:000323693700025	
J	Huang, Xiaolin; Mehrkanoon, Siamak; Suykens, Johan A. K.								Support vector machines with piecewise linear feature mapping								NEUROCOMPUTING			117				118	127		10.1016/j.neucom.2013.01.023			OCT 6 2013	2013	As the simplest extension to linear classifiers, piecewise linear (PWL) classifiers have attracted a lot of attention, because of their simplicity and classification capability. In this paper, a PWL feature mapping is introduced by investigating the property of the PWL classification boundary. Then support vector machines (SVM) with PWL feature mappings are proposed, called PWL-SVMs. In this paper, it is shown that some widely used PWL classifiers, such as k-nearest-neighbor, adaptive boosting of linear classifier and intersection kernel support vector machine, can be represented by the proposed feature mapping. That means the proposed PWL-SVMs at least can achieve the performance of the above PWL classifiers. Moreover, PWL-SVMs enjoy good properties of SVM and the performance on numerical experiments illustrates the effectiveness. Then some extensions are discussed and the application of PWL-SVMs can be expected. (C) 2013 Elsevier B.V. All rights reserved.								0	0	0	0	0	0925-2312		WOS:000321408200014	
J	Fang, Xiao								Inference-Based Naive Bayes: Turning Naive Bayes Cost-Sensitive								IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			25	10			2302	2313		10.1109/TKDE.2012.196			OCT 2013	2013	A fundamental challenge for developing a cost-sensitive Naive Bayes method is how to effectively classify an instance based on the cost-sensitive threshold computed under the assumption of knowing the instance's true classification probabilities and the highly biased estimations of these probabilities by the Naive Bayes method. To address this challenge, we develop a cost-sensitive Naive Bayes method from a novel perspective of inferring the order relation (e. g., greater than or equal to, less than) between an instance's true classification probability of belonging to the class of interest and the cost-sensitive threshold. Our method learns and infers the order relation from the training data and classifies the instance based on the inferred order relation. We empirically show that our proposed method significantly outperforms major existing methods for turning Naive Bayes cost-sensitive through experiments with UCI data sets and a real-world case study.								0	0	0	0	0	1041-4347		WOS:000323503100010	
J	Ogul, Hasan; Kalkan, Alper T.; Umu, Sinan U.; Akkaya, Mahinur S.								TRAINER: A General-Purpose Trainable Short Biosequence Classifer								PROTEIN AND PEPTIDE LETTERS			20	10			1108	1114					OCT 2013	2013	Classifying sequences is one of the central problems in computational biosciences. Several tools have been released to map an unknown molecular entity to one of the known classes using solely its sequence data. However, all of the existing tools are problem-specific and restricted to an alphabet constrained by relevant biological structure. Here, we introduce TRAINER, a new online tool designed to serve as a generic sequence classification platform to enable users provide their own training data with any alphabet therein defined. TRAINER allows users to select among several feature representation schemes and supervised machine learning methods with relevant parameters. Trained models can be saved for future use without retraining by other users. Two case studies are reported for effective use of the system for DNA and protein sequences; candidate effector prediction and nucleolar localization signal prediction. Biological relevance of the results is discussed.								0	0	0	0	0	0929-8665		WOS:000323042100004	
J	Verbiest, Nele; Cornelis, Chris; Herrera, Francisco				Herrera, Francisco/C-6856-2008	Herrera, Francisco/0000-0002-7283-312X			FRPS: A Fuzzy Rough Prototype Selection method								PATTERN RECOGNITION			46	10			2770	2782		10.1016/j.patcog.2013.03.004			OCT 2013	2013	The k Nearest Neighbour (k NN) method is a widely used classification method that has proven to be very effective. The accuracy of k NN can be improved by means of Prototype Selection (PS), that is, we provide k NN with a reduced but reinforced dataset to pick its neighbours from. We use fuzzy rough set theory to express the quality of the instances, and use a wrapper approach to determine which instances to prune. We call this method Fuzzy Rough Prototype Selection (FRPS) and evaluate its effectiveness on a variety of datasets. A comparison of FRPS with state-of-the-art PS methods confirms that our method performs very well with respect to accuracy. (C) 2013 Elsevier Ltd. All rights reserved.								0	0	0	0	0	0031-3203		WOS:000320477400013	
J	Zhang, Yanning; Zhang, Haichao; Nasrabadi, Nasser M.; Huang, Thomas S.								Multi-metric learning for multi-sensor fusion based classification								INFORMATION FUSION			14	4			431	440		10.1016/j.inffus.2012.05.002			OCT 2013	2013	In this paper, we propose a multiple-metric learning algorithm to learn jointly a set of optimal homogenous/heterogeneous metrics in order to fuse the data collected from multiple sensors for joint classification. The learned metrics have the potential to perform better than the conventional Euclidean metric for classification. Moreover, in the case of heterogenous sensors, the learned multiple metrics can be quite different, which are adapted to each type of sensor. By learning the multiple metrics jointly within a single unified optimization framework, we can learn better metrics to fuse the multi-sensor data for a joint classification. Furthermore, we also exploit multi-metric learning in a kernel induced feature space to capture the non-linearity in the original feature space via kernel mapping. (c) 2012 Elsevier B.V. All rights reserved.								0	0	0	0	0	1566-2535		WOS:000321480800010	
J	Li, Jiang; Lu, Can-Yi								A new decision rule for sparse representation based classification for face recognition								NEUROCOMPUTING			116		SI		265	271		10.1016/j.neucom.2012.04.034			SEP 20 2013	2013	The sparse representation based classification (SRC) method attracts much attention in recent years, due to its promising result and robustness for face recognition. Different from the previous improved versions of SRC which emphasize more on sparsity, we focus on the decision rule of SRC. SRC predicts the label of a given test sample based on the residual which measures the representational capability of the training data of each class. Such decision rule is the same as the nearest feature classifiers (NFCs), but not optimal for SRC which is based on the mechanism of sparsity. In this paper, we first review the NFCs, and rewrite them in a unified formulation. We found that the objective of NFCs is different from SRC but they use the same decision rule. In order to capture more discriminative information from the sparse coding coefficient, we propose a new decision rule, sum of coefficient (SoC), which matches well with SRC. SoC is based on the fact that the sparse coefficient reflects the similarities between data, which are able to take full advantage of sparsity for classification. SoC can be regarded as the voting decision rule which is widely used in ensemble learning, i.e. Adaboost, Bagging. We compare our method with the original SRC on three representative face databases and show that SoC is much more discriminative and accurate. Crown Copyright (C) 2012 Published by Elsevier B.V. All rights reserved.				7th International Conference on Intelligent Computing (ICIC)	AUG 11-14, 2011	IEEE Computat Intelligence Soc; Int Neural Network Soc; Natl Sci Fdn China	Zhengzhou, PEOPLES R CHINA	0	0	0	0	0	0925-2312		WOS:000320971900030	
J	Prasartvit, Thananan; Banharnsakun, Anan; Kaewkamnerdpong, Boonserm; Achalakul, Tiranee								Reducing bioinformatics data dimension with ABC-kNN								NEUROCOMPUTING			116		SI		367	381		10.1016/j.neucom.2012.01.045			SEP 20 2013	2013	Analyzing a large amount of data often consumes extensive computational resources and execution time. However, sometime all data features do not equally contribute to the end results. Thus, it is plausible to identify the major contributing features and use them as representatives of the data. Other features with low contribution can be eliminated to reduce the time/resource consumption in data analysis. One of the promising application domains for such a feature selection process is bioinformatics. The need for dimension reduction, which is the process to reduce unnecessary features from the original data, arises because biological data can be massive, with tens of thousands of features to be explored. The objective of this study is to design an effective algorithm that can selectively remove irrelevant dimensions from data describing complex biological processes while preserving the semantics of the original data. This research proposes the adoption of the Artificial Bee Colony (ABC) as a novel method for data dimension reduction in classification problems. ABC, an efficient heuristic method based on swarm intelligence, is used to select the optimal subset of dimensions from the original high-dimensional data while retaining a subset that satisfies the defined objective. The k-Nearest Neighbor (kNN) method is then used for fitness evaluation within the ABC framework. In this research, ABC and kNN have been modified and bundled together to create an effective dimension reduction method. The proposed algorithm is validated in two distinct application domains: Gene expression analysis, and autistic behaviors study. The experimental results exhibit good solution quality as well as good computational performance. (C) 2012 Elsevier B.V. All rights reserved.				7th International Conference on Intelligent Computing (ICIC)	AUG 11-14, 2011	IEEE Computat Intelligence Soc; Int Neural Network Soc; Natl Sci Fdn China	Zhengzhou, PEOPLES R CHINA	0	0	0	0	0	0925-2312		WOS:000320971900041	
J	Li, Zechao; Liu, Jing; Lu, Hanqing								Structure preserving non-negative matrix factorization for dimensionality reduction								COMPUTER VISION AND IMAGE UNDERSTANDING			117	9			1175	1189		10.1016/j.cviu.2013.04.003			SEP 2013	2013	The problem of dimensionality reduction is to map data from high dimensional spaces to low dimensional spaces. In the process of dimensionality reduction, the data structure, which is helpful to discover the latent semantics and simultaneously respect the intrinsic geometric structure, should be preserved. In this paper, to discover a low-dimensional embedding space with the nature of structure preservation and basis compactness, we propose a novel dimensionality reduction algorithm, called Structure Preserving Non-negative Matrix Factorization (SPNMF). In SPNMF, three kinds of constraints, namely local affinity, distant repulsion, and embedding basis redundancy elimination, are incorporated into the NMF framework. SPNMF is formulated as an optimization problem and solved by an effective iterative multiplicative update algorithm. The convergence of the proposed update solutions is proved. Extensive experiments on both synthetic data and six real world data sets demonstrate the encouraging performance of the proposed algorithm in comparison to the state-of-the-art algorithms, especially some related works based on NMF. Moreover, the convergence of the proposed updating rules is experimentally validated. (C) 2013 Elsevier Inc. All rights reserved.								0	0	0	0	0	1077-3142		WOS:000321724300019	
J	Xia, Wei; Wang, Bin; Zhang, Liming								Band Selection for Hyperspectral Imagery: A New Approach Based on Complex Networks								IEEE GEOSCIENCE AND REMOTE SENSING LETTERS			10	5			1229	1233		10.1109/LGRS.2012.2236819			SEP 2013	2013	In recent years, band selection is becoming a popular approach to reduce the dimensionality of hyperspectral data while preserving the desired information for target detection and classification analysis. This letter presents a new method for unsupervised band selection by transforming the hyperspectral data into complex networks. By analyzing the networks' topological feature corresponding to each band, one can easily evaluate the statistical characteristics and intrinsic properties of the signals. The proposed method searches for the network set which is most qualified for demarcating and identifying different substance signatures, and then, the network set's corresponding bands are regarded as the descried output results. This network measure is a new criterion for band selection. Experimental results demonstrate that the proposed method can acquire satisfactory results when compared with traditional methods.								0	0	0	0	0	1545-598X		WOS:000320993900054	
J	Zhang, Jianfei; Chen, Lifei; Guo, Gongde								Projected-prototype based classifier for text categorization								KNOWLEDGE-BASED SYSTEMS			49				179	189		10.1016/j.knosys.2013.05.013			SEP 2013	2013	Currently, the explosive increasing of data stimulates a greater demand for text categorization. The existing prototype-based classifiers, including k-NN, kNNModel and Centroid classifier, are receiving wide interest from the text mining community because of their simplicity and efficiency. However, they usually perform less effectively on document data sets due to high dimensionality and complex class structures these sets involve. In most cases a single document category actually contains multiple subtopics, indicating that the documents in the same class may comprise multiple subclasses, each associated with its individual term subspace. In this paper, a novel projected-prototype based classifier is proposed for text categorization, in which a document category is represented by a set of prototypes, each assembling a representative for the documents in a subclass and its corresponding term subspace. In the classifier's training process, the number of prototypes and the prototypes themselves are learned using a newly developed feature-weighting algorithm, in order to ensure that the documents belonging to different subclasses are separated as much as possible when projected onto their own subspaces. Then, in the testing process, each test document is classified in terms of its weighted distances from the different prototypes. Experimental results on the Reuters-21578 and 20-Newsgroups corpora show that the proposed classifier based on the multi-representative-dependent projection method can achieve higher classification accuracy at a lower computational cost than the conventional prototype-based classifiers, especially for data sets that include overlapping document categories. (C) 2013 Elsevier B.V. All rights reserved.								0	0	0	0	0	0950-7051		WOS:000322428100017	
J	Memarian, Hadi; Balasundram, Siva K.; Khosla, Raj								Comparison between pixel- and object-based image classification of a tropical landscape using Systeme Pour l'Observation de la Terre-5 imagery								JOURNAL OF APPLIED REMOTE SENSING			7						073512	10.1117/1.JRS.7.073512			AUG 28 2013	2013	Based on the Systeme Pour l'Observation de la Terre-5 imagery, two main techniques of classifying land-use categories in a tropical landscape are compared using two supervised algorithms: maximum likelihood classifier (MLC) and K-nearest neighbor object-based classifier. Nine combinations of scale level (SL10, SL30, and SL50) and the nearest neighbor (NN3, NN5, and NN7) are investigated in the object-based classification. Accuracy assessment is performed using two main disagreement components, i.e., quantity disagreement and allocation disagreement. The MLC results in a higher total disagreement in total landscape as compared with object-based image classification. The SL30-NN5 object-based classifier reduces allocation error by 250% as compared with the MLC. Therefore, this classifier shows a higher performance in land-use classification of the Langat basin. (C) The Authors. Published by SPIE under a Creative Commons Attribution 3.0 Unported License. Distribution or reproduction of this work in whole or in part requires full attribution of the original publication, including its DOI.								0	0	0	0	0	1931-3195		WOS:000323598600001	
J	Pizzi, Nick J.								A fuzzy classifier approach to estimating software quality								INFORMATION SCIENCES			241				1	11		10.1016/j.ins.2013.04.027			AUG 20 2013	2013	With the increasing sophistication of today's software systems, it is often difficult to estimate the overall quality of underlying software components with respect to attributes such as complexity, utility, and extensibility. Many metrics exist in the software engineering literature that attempt to quantify, with varying levels of accuracy, a large swath of qualitative attributes. However, the overall quality of a software object may manifest itself in ways that the simple interpretation of metrics fails to identify. A better strategy is to determine the best, possibly non-linear, subset of many software metrics for accurately estimating software quality. This strategy may be couched in terms of a problem of classification, that is, determine a mapping from a set of software metrics to a set of class labels representing software quality.We implement this strategy using a fuzzy classification approach. The software metrics are automatically computed and presented as features (input) to a classifier, while the class labels (output) are assigned via an expert's (software architect) thorough assessment of the quality of individual software objects. A large collection of classifiers is presented with subsets of the software metric features. Subsets are selected stochastically using a fuzzy logic based sampling method. The classifiers then predict the quality, specifically the class label, of each software object. Fuzzy integration is applied to the results from the most accurate individual classifiers. We empirically evaluate this approach using software objects from a sophisticated algorithm development framework used to develop biomedical data analysis systems. We demonstrate that the sampling method attenuates the effects of confounding features, and the aggregated classification results using fuzzy integration are superior to the predictions from the respective best individual classifiers. (C) 2013 Elsevier Inc. All rights reserved.								0	0	0	0	0	0020-0255		WOS:000320678200001	
J	Tallon-Ballesteros, Antonio J.; Hervas-Martinez, Cesar; Riquelme, Jose C.; Ruiz, Roberto								Feature selection to enhance a two-stage evolutionary algorithm in product unit neural networks for complex classification problems								NEUROCOMPUTING			114		SI		107	117		10.1016/j.neucom.2012.08.041			AUG 19 2013	2013	This paper combines feature selection methods with a two-stage evolutionary classifier based on product unit neural networks. The enhanced methodology has been tried out with four filters using 18 data sets that report test error rates about 20 % or above with reference classifiers such as C4.5 or 1-NN. The proposal has also been evaluated in a liver-transplantation real-world problem with serious troubles in the data distribution and classifiers get low performance. The study includes an overall empirical comparison between the models obtained with and without feature selection using different kind of neural networks, like RBF, MLP and other state-of-the-art classifiers. Statistical tests show that our proposal significantly improves the test accuracy of the previous models. The reduction percentage in the number of inputs is, on average, above 55 %, thus a greater efficiency is achieved. (C) 2012 Elsevier B.V. All rights reserved.								0	0	0	0	0	0925-2312		WOS:000320419400016	
J	Mi, Jian-Xun; Huang, De-Shuang; Wang, Bing; Zhu, Xingjie				Wang, Bing/J-7812-2012				The nearest-farthest subspace classification for face recognition								NEUROCOMPUTING			113				241	250		10.1016/j.neucom.2013.01.003			AUG 3 2013	2013	The nearest subspace (NS) classification is an efficient method to solve face recognition problem by using the linear regression technique. This method is based on the assumption that face images from a specific subject class tend to span a unique subspace, i.e. a class-specific subspace. Then, a test image has the shortest distance from its own class-specific subspace. In this paper, we present a novel idea for face recognition. This idea considers that a test face image should be far from the farthest subspace (FS) spanned by all training images except the images from the class of this test image. Based on this idea, we propose the FS classifier for face recognition. In our opinion, NS and FS classifiers take advantages of different characteristics of the class-specific subspace. NS classifier exploits the relationship between a test image and a single class while FS classifier measures relationship between this test image and the rest classes. Consequently, we propose the nearest-farthest subspace (NFS) classifier which exploits the both relationships to classify a test image. The comparisons with NS classifier and other state-of-the-art methods on four famous public face databases demonstrate the good performance of FS and NFS. (C) 2013 Elsevier B.V. All rights reserved.								0	0	0	0	0	0925-2312		WOS:000319952700024	
J	Fernandez Luque, Ismael; Aguilar, Fernando J.; Flor Alvarez, M.; Angel Aguilar, Manuel				Aguilar, Fernando /I-7491-2013				Non-Parametric Object-Based Approaches to Carry Out ISA Classification From Archival Aerial Orthoimages								IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING			6	4			2058	2071		10.1109/JSTARS.2013.2240265			AUG 2013	2013	In order to map the impervious surfaces for a coastal area, three non-parametric approaches: Classification and Regression Trees, Nearest Neighbor (NN), and Support Vector Machines (SVM)- were applied to a dataset of very high resolution archival orthoimages which had poor radiometry, with only red, green and blue spectral information. An object-based image analysis was carried out and four feature vectors were defined as input data for the classifier: 1) red, green and blue spectral information plus four relative spectral indices; 2) Dataset 1 plus texture indices based on the grey level co-occurrence matrix (GLCM); 3) Dataset 1 plus texture indices based on the local variance; and 4) the vector defined by 1), 2) and 3). Two classification strategies were developed in order to identify the pervious/impervious target classes (aggregation of all the subclasses and binary classification). The separability matrix was used to present the statistical comparative results clearly and concisely. The results obtained from this work showed that 1) "GLCM" texture indices did not lead to more accurate results; 2) the incorporation of the local variance texture index significantly increased the accuracy of the classification; 3) the classification results were not significantly affected by the classification strategy employed; 4) SVM and NN achieved statistically more accurate classification results than CARTs; 5) the SVM classifier was more efficient than the NN classifier, while NN was less dependent on the feature vector, and 6) suitable accuracy results were obtained for the most accurate approaches (SVM) which achieved a 89.4% overall accuracy.								0	0	0	0	0	1939-1404		WOS:000322453800024	
J	Liu, Yiguang; Cao, Xiaochun; Liu, Jian Guo								Classification using distances from samples to linear manifolds								PATTERN ANALYSIS AND APPLICATIONS			16	3			417	430		10.1007/s10044-011-0242-x			AUG 2013	2013	A classifier is proposed wherein the distances from samples to linear manifolds (DSL) are used to perform classification. For each class, a linear manifold is built, whose dimension is high enough to pass all the training samples of the class. The distance from a query sample to a linear manifold is converted to the distance from a point to a linear subspace. And a simple and stable formula is derived to calculate the distance by virtue of the geometrical fundamental of the Gram matrix as well as the regularization technique. The query sample is assigned into the class whose linear manifold is the nearest. On one synthetic data set, thirteen binary-class data sets as well as six multi-class data sets, the experimental results show that the classification performance of DSL is of competence. On most of the data sets, DSL outperforms the comparing classifiers based on k nearest samples or subspaces, and is even superior to support vector machines on some data sets. Further experiment demonstrates that the test efficiency of DSL is also competitive to kNN and the related state-of-the-art classifiers on many data sets.								0	0	0	0	0	1433-7541		WOS:000321918600011	
J	Sanchetta, Alexandre Cruz; Leite, Emilson Pereira; Zanardo Honorio, Bruno Cesar								Facies recognition using a smoothing process through Fast Independent Component Analysis and Discrete Cosine Transform								COMPUTERS & GEOSCIENCES			57				175	182		10.1016/j.cageo.2013.03.021			AUG 2013	2013	We propose a preprocessing methodology for well-log geophysical data based on Fast Independent Component Analysis (FastICA) and Discrete Cosine Transform (DCT), in order to improve the success rate of the K-NN automatic classifier. The K-NN have been commonly applied to fades recognition in well-log geophysical data for hydrocarbon reservoir modeling and characterization.The preprocess was made in two different levels. In the first level, a FastICA based dimenstion reduction was applied, maintaining much of the information, and its results were classified; In second level, FastICA and DCT were applied in smoothing level, where the data points are modified, so individual points have their distance reduced, keeping just the primordial information. The results were compared to identify the best classification cases. We have applied the proposed methodology to well-log data from a petroleum field of Campos Basin, Brazil. Sonic, gamma-ray, density, neutron porosity and deep induction logs were preprocessed with FastICA and DCT, and the product was classified with K-NN. The success rates in recognition were calculated by appling the method to log intervals where core data were available. The results were compared to those of automatic recognition of the original well-log data set with and without the removal of high frequency noise. We conclude that the application of the proposed methodology significantly improves the success rate of fades recognition by K-NN. (C) 2013 Elsevier Ltd. All rights reserved.								0	0	0	0	0	0098-3004		WOS:000320825400019	
J	Thach Nguyen Huy; Tong, Bin; Shao, Hao; Suzuki, Einoshin								Transfer learning by centroid pivoted mapping in noisy environment								JOURNAL OF INTELLIGENT INFORMATION SYSTEMS			41	1	SI		39	60		10.1007/s10844-012-0226-3			AUG 2013	2013	Transfer learning is a widely investigated learning paradigm that is initially proposed to reuse informative knowledge from related domains, as supervised information in the target domain is scarce while it is sufficiently available in the multiple source domains. One of the challenging issues in transfer learning is how to handle the distribution differences between the source domains and the target domain. Most studies in the research field implicitly assume that data distributions from the source domains and the target domain are similar in a well-designed feature space. However, it is often the case that label assignments for data in the source domains and the target domain are significantly different. Therefore, in reality even if the distribution difference between a source domain and a target domain is reduced, the knowledge from multiple source domains is not well transferred to the target domain unless the label information is carefully considered. In addition, noisy data often emerge in real world applications. Therefore, considering how to handle noisy data in the transfer learning setting is a challenging problem, as noisy data inevitably cause a side effect during the knowledge transfer. Due to the above reasons, in this paper, we are motivated to propose a robust framework against noise in the transfer learning setting. We also explicitly consider the difference in data distributions and label assignments among multiple source domains and the target domain. Experimental results on one synthetic data set, three UCI data sets and one real world text data set in different noise levels demonstrate the effectiveness of our method.								0	0	0	0	0	0925-9902		WOS:000322922100003	
J	Yang, Shuyuan; Ma, Yonggang; Wang, Min; Xie, Dongmei; Wu, Yun; Jiao, Licheng								Compressive feature and kernel sparse coding-based radar target recognition								IET RADAR SONAR AND NAVIGATION			7	7			755	763		10.1049/iet-rsn.2012.0034			AUG 2013	2013	In this study, the authors exploit the sparse nature of radar targets, and propose a universal, target-oriented 'compressive feature' and kernel sparse coding-based radar target recognition approach via the recent developed compressive sensing theory. Inspired by the visual attention mechanism, pulse contourlet transform is proposed to derive the target-oriented compressive features, and a kernel sparse coding classifier is advanced inspired by the fact that kernel trick can make the features more clustered in higher dimensional space, so resulting in accurate and robust recognition of targets. Some experiments are taken on recognising three types of ground vehicles in the moving and stationary target acquisition and recognition public release database, to compare the performance of the proposed scheme with its counterparts, and the results prove its efficiency.								0	0	0	0	0	1751-8784		WOS:000323565100005	
J	Zahedi, M.; Sorkhi, A. Ghanbari								Improving Text Classification Performance Using PCA and Recall-Precision Criteria								ARABIAN JOURNAL FOR SCIENCE AND ENGINEERING			38	8			2095	2102		10.1007/s13369-013-0569-2			AUG 2013	2013	Persian text is usually associated with a wide range of important or useless features. This is the main reason why feature extraction process is one of the difficult tasks in the field of Persian text analysis and understanding. While few research works have focused on this problem, the aim of this paper is to introduce a novel approach for extracting the most relevant features and classification of Persian text. Experimental results show that utilizing the principle component analysis along with recall and precision criteria and employing term frequency and category relevancy factor can result in considerable improvement in running time of the classification process while accuracy and precision criteria are improved a little or are not decreased as much as affecting classification performance.								0	0	0	0	0	1319-8025		WOS:000322114200015	
J	Gilboa, Itzhak; Samuelson, Larry; Schmeidler, David								Dynamics of inductive inference in a unified framework								JOURNAL OF ECONOMIC THEORY			148	4			1399	1432		10.1016/j.jet.2012.11.004			JUL 2013	2013	We present a model of inductive inference that includes, as special cases, Bayesian reasoning, case-based reasoning, and rule-based reasoning. This unified framework allows us to examine how the various modes of inductive inference can be combined and how their relative weights change endogenously. For example, we establish conditions under which an agent who does not know the structure of the data generating process will decrease, over the course of her reasoning, the weight of credence put on Bayesian vs. non-Bayesian reasoning. We illustrate circumstances under which probabilistic models are used until an unexpected outcome occurs, whereupon the agent resorts to more basic reasoning techniques, such as case-based and rule-based reasoning, until enough data are gathered to formulate a new probabilistic model. (C) 2013 Elsevier Inc. All rights reserved.								0	0	0	0	0	0022-0531		WOS:000321086700004	
J	Jiang, Hao; Hallstrom, Jason O.								Fast, Accurate Event Classification on Resource-Lean Embedded Sensors								ACM TRANSACTIONS ON AUTONOMOUS AND ADAPTIVE SYSTEMS			8	2					11	10.1145/2491465.2491470			JUL 2013	2013	Due to the limited computational and energy resources available on existing wireless sensor platforms, achieving high-precision classification of high-level events in-network is a challenge. In this article, we present in-network implementations of a Bayesian classifier and a condensed kd-tree classifier for identifying events of interest on resource-lean embedded sensors. The first approach uses preprocessed sensor readings to derive a multidimensional Bayesian classifier used to classify sensor data in real time. The second introduces an innovative condensed kd-tree to represent preprocessed sensor data and uses a fast nearest-neighbor search to determine the likelihood of class membership for incoming samples. Both classifiers consume limited resources and provide high-precision classification. To evaluate each approach, two case studies are considered, in the contexts of human movement and vehicle navigation, respectively. The classification accuracy is above 85% for both classifiers across the two case studies.								0	0	0	0	0	1556-4665		WOS:000321905200005	
J	Leyva, Enrique; Gonzalez, Antonio; Perez, Raul								Knowledge-based instance selection: A compromise between efficiency and versatility								KNOWLEDGE-BASED SYSTEMS			47				65	76		10.1016/j.knosys.2013.04.005			JUL 2013	2013	Traditionally, each instance selection proposal applies the same selection criterion to any problem. However, the performance of such criteria depends on the input data and a single one is not sufficient to guarantee success over a wide range of environments. An option to adapt the selection criteria to the input data is the use of meta-learning to build knowledge-based systems capable to choose the most appropriate selection strategy among several available candidates. Nevertheless, there is not in the literature a theoretical framework that guides the design of instance selection techniques based on meta-learning. This paper presents a framework for this purpose as well as a case study in which the framework is instantiated and an experimental study is carried out to show that the meta-learning approach offers a good compromise between efficiency and versatility in instance selection. (C) 2013 Elsevier B.V. All rights reserved.								0	0	0	0	0	0950-7051		WOS:000320351100006	
J	Luque-Baena, Rafael M.; Elizondo, David; Lopez-Rubio, Ezequiel; Palomo, Esteban J.; Watson, Tim								Assessment of geometric features for individual identification and verification in biometric hand systems								EXPERT SYSTEMS WITH APPLICATIONS			40	9			3580	3594		10.1016/j.eswa.2012.12.065			JUL 2013	2013	This paper studies the reliability of geometric features for the identification of users based on hand biometrics. Our methodology is based on genetic algorithms and mutual information. The aim is to provide a system for user identification rather than a classification. Additionally, a robust hand segmentation method to extract the hand silhouette and a set of geometric features in hard and complex environments is described. This paper focuses on studying how important and discriminating the hand geometric features are, and if they are suitable in developing a robust and reliable biometric identification. Several public databases have been used to test our method. As a result, the number of required features have been drastically reduced from datasets with more than 400 features. In fact, good classification rates with about 50 features on average are achieved, with a 100% accuracy using the GA-LDA strategy for the GPDS database and 97% for the CASIA and IITD databases, approximately. For these last contact-less databases, reasonable EER rates are also obtained. (C) 2012 Elsevier Ltd. All rights reserved.								0	0	0	0	0	0957-4174		WOS:000316581300025	
J	Meng, Yuxin; Kwok, Lam-For								Enhancing False Alarm Reduction Using Voted Ensemble Selection in Intrusion Detection								INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS			6	4			626	638					JUL 2013	2013	Network intrusion detection systems (NIDSs) have become an indispensable component for the current network security infrastructure. However, a large number of alarms especially false alarms are a big problem for these systems which greatly lowers the effectiveness of NIDSs and causes heavier analysis workload. To address this problem, a lot of intelligent methods (e.g., machine learning algorithms) have been proposed to reduce the number of false alarms, but it is hard to determine which one is the best. We argue that the performance of different machine learning algorithms is very fluctuant with regard to distinct contexts (e.g., training data). In this paper, we propose an architecture of intelligent false alarm filter by employing a method of voted ensemble selection aiming to maintain the accuracy of false alarm reduction. In particular, there are four components in the architecture: data standardization, data storage, voted ensemble selection and alarm filtration. In the experiment, we conduct a study involved three machine learning algorithms such as support vector machine, decision tree and k-nearest neighbor, and use Snort, which is an open source signature-based NIDS, to explore the effectiveness of our proposed architecture. The experimental results show that our intelligent false alarm filter is effective and encouraging to maintain the performance of reducing false alarms at a high and stable level.								0	0	0	0	0	1875-6883		WOS:000319191800004	
J	Orsenigo, C.; Vercellis, C.								Linear versus nonlinear dimensionality reduction for banks' credit rating prediction								KNOWLEDGE-BASED SYSTEMS			47				14	22		10.1016/j.knosys.2013.03.001			JUL 2013	2013	Dimensionality reduction methods have shown their usefulness for both supervised and unsupervised tasks in a wide range of application domains. Several linear and nonlinear approaches have been proposed in order to derive meaningful low-dimensional representations of high-dimensional data. Among nonlinear algorithms manifold learning methods, such as isometric feature mapping (Isomap), have recently attracted great attention by providing noteworthy results on artificial and real world data sets.The paper presents an empirical evaluation of two linear and nonlinear techniques, namely principal component analysis (PCA) and double-bounded tree-connected Isomap (dbt-Isomap), in order to assess their effectiveness for dimensionality reduction in banks' credit rating prediction, and to determine the key financial variables endowed with the most explanatory power. Extensive computational tests concerning the classification of six banks' rating data sets showed that the use of dimensionality reduction accomplished by nonlinear projections often induced an improvement in the classification accuracy, and that dbt-Isomap outperformed PCA by consistently providing more accurate predictions. (C) 2013 Elsevier B.V. All rights reserved.								0	0	0	0	0	0950-7051		WOS:000320351100002	
J	Pedreira, Carlos E.; Costa, Elaine S.; Lecrevisse, Quentin; van Dongen, Jacques J. M.; Orfao, Alberto		EuroFlow Consortium						Overview of clinical flow cytometry data analysis: recent advances and future challenges								TRENDS IN BIOTECHNOLOGY			31	7			415	425		10.1016/j.tibtech.2013.04.008			JUL 2013	2013	Major technological advances in flow cytometry (FC), both for instrumentation and reagents, have emerged over the past few decades. These advances facilitate simultaneous evaluation of more parameters in single cells analyzed at higher speed. Consequently, larger and more complex data files that contain information about tens of parameters for millions of cells are generated. This increasing complexity has challenged pre-existing data analysis tools and promoted the development of new algorithms and tools for data analysis and visualization. Here, we review the currently available (conventional and newly developed) data analysis and visualization strategies that aim for easier, more objective, and robust interpretation of FC data both in biomedical research and clinical diagnostic laboratories.								0	0	0	0	0	0167-7799		WOS:000321175200006	
J	Peng, Jing; Seetharaman, Guna; Fan, Wei; Varde, Aparna								Exploiting Fisher and Fukunaga-Koontz Transforms in Chernoff Dimensionality Reduction								ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			7	2					UNSP 8	10.1145/2499907.2499911			JUL 2013	2013	Knowledge discovery from big data demands effective representation of data. However, big data are often characterized by high dimensionality, which makes knowledge discovery more difficult. Many techniques for dimensionality reudction have been proposed, including well-known Fisher's Linear Discriminant Analysis (LDA). However, the Fisher criterion is incapable of dealing with heteroscedasticity in the data. A technique based on the Chernoff criterion for linear dimensionality reduction has been proposed that is capable of exploiting heteroscedastic information in the data. While the Chernoff criterion has been shown to outperform the Fisher's, a clear understanding of its exact behavior is lacking. In this article, we show precisely what can be expected from the Chernoff criterion. In particular, we show that the Chernoff criterion exploits the Fisher and Fukunaga-Koontz transforms in computing its linear discriminants. Furthermore, we show that a recently proposed decomposition of the data space into four subspaces is incomplete. We provide arguments on how to best enrich the decomposition of the data space in order to account for heteroscedasticity in the data. Finally, we provide experimental results validating our theoretical analysis.								0	0	0	0	0	1556-4681		WOS:000322479200004	
J	Rajini, N. Hema; Bhavani, R.								Computer aided detection of ischemic stroke using segmentation and texture features								MEASUREMENT			46	6			1865	1874		10.1016/j.measurement.2013.01.010			JUL 2013	2013	Computed tomography images are widely used in the diagnosis of ischemic stroke because of its faster acquisition and compatibility with most life support devices. This paper presents a new approach to automated detection of ischemic stroke using segmentation, midline shift and image feature characteristics, which separate the ischemic stroke region from healthy tissues in computed tomography images. The proposed method consists of five stages namely, pre-processing, segmentation, tracing midline of the brain, extraction of texture features and classification. The application of the proposed method for early detection of ischemic stroke is demonstrated to improve efficiency and accuracy of clinical practice. The results are quantitatively evaluated by a human expert. The average overlap metric, average precision and average recall between the results obtained using the proposed approach and the ground truth are 0.98, 0.99 and 0.98, respectively. A classification with accuracy of 98%, 97%, 96% and 92% has been obtained by SVM, k-NN, ANN and decision tree. (C) 2013 Elsevier Ltd. All rights reserved.								0	0	0	0	0	0263-2241		WOS:000319369800010	
J	Scalzo, Fabien; Alger, Jeffry R.; Hu, Xiao; Saver, Jeffrey L.; Dani, Krishna A.; Muir, Keith W.; Demchuk, Andrew M.; Coutts, Shelagh B.; Luby, Marie; Warach, Steven; Liebeskind, David S.		STIR VISTA Imaging Investigators						Multi-center prediction of hemorrhagic transformation in acute ischemic stroke using permeability imaging features								MAGNETIC RESONANCE IMAGING			31	6			961	969		10.1016/j.mri.2013.03.013			JUL 2013	2013	Permeability images derived from magnetic resonance (MR) perfusion images are sensitive to blood brain barrier derangement of the brain tissue and have been shown to correlate with subsequent development of hemorrhagic transformation (HT) in acute ischemic stroke. This paper presents a multi-center retrospective study that evaluates the predictive power in terms of HT of six permeability MRI measures including contrast slope (CS), final contrast (FC), maximum peak bolus concentration (MPB), peak bolus area (PB), relative recirculation (rR), and percentage recovery (%R). Dynamic T2*-weighted perfusion MR images were collected from 263 acute ischemic stroke patients from four medical centers. An essential aspect of this study is to exploit a classifier-based framework to automatically identify predictive patterns in the overall intensity distribution of the permeability maps. The model is based on normalized intensity histograms that are used as input features to the predictive model. Linear and nonlinear predictive models are evaluated using a cross-validation to measure generalization power on new patients and a comparative analysis is provided for the different types of parameters. Results demonstrate that perfusion imaging in acute ischemic stroke can predict HT with an average accuracy of more than 85% using a predictive model based on a nonlinear regression model. Results also indicate that the permeability feature based on the percentage of recovery performs significantly better than the other features. This novel model may be used to refine treatment decisions in acute stroke. (c) 2013 Elsevier Inc. All rights reserved.								0	0	0	0	0	0730-725X		WOS:000320818600020	
J	Xu, Yong; Zhu, Qi; Fan, Zizhu; Qiu, Minna; Chen, Yan; Liu, Hong								Coarse to fine K nearest neighbor classifier								PATTERN RECOGNITION LETTERS			34	9			980	986		10.1016/j.patrec.2013.01.028			JUL 1 2013	2013	In this paper, we propose a coarse to fine K nearest neighbor (KNN) classifier (CFKNNC). CFKNNC differs from the conventional KNN classifier (CKNNC) as follows: CFKNNC first coarsely determines a small number of training samples that are "close" to the test sample and then finely identifies the K nearest neighbors of the test sample. The main difference between CFKNNC and CKNNC is that they exploit the "representation-based distances" and Euclidean distances to determine the nearest neighbors of the test sample from the set of training samples, respectively. The analysis shows that the "representation-based distances" are able to take into account the dependent relationship between different training samples. Actually, the nearest neighbors determined by the proposed method are optimal from the point of view of representing the test sample. Moreover, the nearest neighbors obtained using our method contain less redundant information than those obtained using CKNNC. The experimental results show that CFKNNC can classify much more accurately than CKNNC and various improvements to CKNNC such as the nearest feature line (NFL) classifier, the nearest feature space (NFS) classifier, nearest neighbor line classifier (NNLC) and center-based nearest neighbor classifier (CBNNC). (C) 2013 Elsevier B.V. All rights reserved.								0	0	0	0	0	0167-8655		WOS:000318889800004	
J	Aguiar-Pulido, Vanessa; Gestal, Marcos; Cruz-Monteagudo, Maykel; Rabunal, Juan R.; Dorado, Julian; Munteanu, Cristian R.								Evolutionary Computation and QSAR Research								CURRENT COMPUTER-AIDED DRUG DESIGN			9	2			206	225					JUN 2013	2013	The successful high throughput screening of molecule libraries for a specific biological property is one of the main improvements in drug discovery. The virtual molecular filtering and screening relies greatly on quantitative structure-activity relationship (QSAR) analysis, a mathematical model that correlates the activity of a molecule with molecular descriptors. QSAR models have the potential to reduce the costly failure of drug candidates in advanced (clinical) stages by filtering combinatorial libraries, eliminating candidates with a predicted toxic effect and poor pharmacokinetic profiles, and reducing the number of experiments. To obtain a predictive and reliable QSAR model, scientists use methods from various fields such as molecular modeling, pattern recognition, machine learning or artificial intelligence. QSAR modeling relies on three main steps: molecular structure codification into molecular descriptors, selection of relevant variables in the context of the analyzed activity, and search of the optimal mathematical model that correlates the molecular descriptors with a specific activity. Since a variety of techniques from statistics and artificial intelligence can aid variable selection and model building steps, this review focuses on the evolutionary computation methods supporting these tasks. Thus, this review explains the basic of the genetic algorithms and genetic programming as evolutionary computation approaches, the selection methods for high-dimensional data in QSAR, the methods to build QSAR models, the current evolutionary feature selection methods and applications in QSAR and the future trend on the joint or multi-task feature selection methods.								0	0	0	0	0	1573-4099		WOS:000320374200006	
J	Bouhana, Amna; Fekih, Afef; Abed, Mourad; Chabchoub, Habib								An integrated case-based reasoning approach for personalized itinerary search in multimodal transportation systems								TRANSPORTATION RESEARCH PART C-EMERGING TECHNOLOGIES			31		SI		30	50		10.1016/j.trc.2013.02.014			JUN 2013	2013	Suggesting personalized itinerary search for travelers in a multimodal transportation system is a challenging problem. This is due to the increased complexity and diversity of transportation means, the intricacy and multitude of destinations along with the amount of rapidly changing information available to the traveler. Providing the transportation user with the relevant information that only meets his needs, preferences and personal profile is of foremost importance in efficiently supporting passenger mobility requirements in a large urban agglomeration.In this paper, we propose a multi-criteria approach for suggesting personalized itinerary to transportation users based on their preferences and needs. The proposed approach integrates case-based reasoning with Choquet integral to suggest the itinerary that best matches the user's preferences. Further, the proposed method predicts the user's behavior by comparing his preferences to those of other users with the same preferences for a given context. This will help the user to adopt the best action when facing a new situation in his itinerary search.This will help the user adopt the best action facing a new situation. Personalized information retrieval is processed based on criteria which weights are determined using the two-additive Choquet integral. The performance of the proposed algorithm was assessed by solving a real-life itinerary planning problem defined in the Tunisian urban public transit network. A comparison study involving both qualitative and quantitative assessment of the proposed approach as compared to two other methods was also carried out. Based on the performance analysis, as well as the comparison study, our new approach provides the best solutions for applications requiring personalization based user's preferences in a multi-criteria setting. (C) 2013 Elsevier Ltd. All rights reserved.								0	0	0	0	0	0968-090X		WOS:000319542200003	
J	Cara, Ana Belen; Wagner, Christian; Hagras, Hani; Pomares, Hector; Rojas, Ignacio								Multiobjective Optimization and Comparison of Nonsingleton Type-1 and Singleton Interval Type-2 Fuzzy Logic Systems								IEEE TRANSACTIONS ON FUZZY SYSTEMS			21	3	SI		459	476		10.1109/TFUZZ.2012.2236096			JUN 2013	2013	Singleton interval type-2 fuzzy logic systems (FLSs) have been widely applied in several real-world applications, where it was shown that the singleton interval type-2 FLSs outperform their singleton type-1 counterparts in applications with high uncertainty levels. However, one of the main criticisms of singleton interval type-2 FLSs is the fact that they outperform singleton type-1 FLSs solely based on their use of extra degrees of freedom (extra parameters) and that type-1 FLSs with a sufficiently large number of parameters may provide the same performance as interval type-2 FLSs. In addition, most works on type-2 FLSs only compare their results with singleton type-1 FLSs but fail to consider nonsingleton type-1 systems. In this paper, we aim to directly address and investigate this criticism. In order to do so, we will perform a comparative study between optimized singleton type-1, nonsingleton type-1, and singleton interval type-2 FLSs under the presence of noise. We will also present a multiobjective evolutionary algorithm (MOEA) for the optimization of singleton type-1, nonsingleton type-1, and singleton interval type-2 fuzzy systems for function approximation problems. The MOEA will aim to satisfy two objectives to maximize the accuracy of the FLS and minimize the number of rules in the FLS, thus improving its interpretability. Furthermore, we will present a methodology to obtain "optimal" consequents for the FLSs. Hence, this paper has two main contributions: First, it provides a common methodology to learn the three types of FLSs (i.e., singleton type-1, nonsingleton type-1, and singleton interval type-2 FLSs) from data samples. The second contribution is the creation of a common framework for the comparison of type-1 and type-2 FLSs that allows us to address the aforementioned criticism. We provide details of a series of experiments and include statistical analysis showing that the type-2 FLS is able to handle higher levels of noise than its nonsingleton and singleton type-1 counterparts.								0	0	0	0	0	1063-6706		WOS:000319930000006	
J	Chen, Yi; Li, Zhenzhen; Jin, Zhong								Feature Extraction Based on Maximum Nearest Subspace Margin Criterion								NEURAL PROCESSING LETTERS			37	3			355	375		10.1007/s11063-012-9252-y			JUN 2013	2013	Based on the classification rule of sparse representation-based classification (SRC) and linear regression classification (LRC), we propose the maximum nearest subspace margin criterion for feature extraction. The proposed method can be seen as a preprocessing step of SRC and LRC. By maximizing the inter-class reconstruction error and minimizing the intra-class reconstruction error simultaneously, the proposed method significantly improves the performances of SRC and LRC. Compared with linear discriminant analysis, the proposed method avoids the small sample size problem and can extract more features. Moreover, we extend LRC to overcome the potential singular problem. The experimental results on the extended Yale B (YALE-B), AR, PolyU finger knuckle print and the CENPARMI handwritten numeral databases demonstrate the effectiveness of the proposed method.								0	0	0	0	0	1370-4621		WOS:000319016400007	
J	Lutu, Patricia E. N.; Engelbrecht, Andries P.								Base Model Combination Algorithm for Resolving Tied Predictions for K-Nearest Neighbor OVA Ensemble Models								INFORMS JOURNAL ON COMPUTING			25	3			517	526		10.1287/ijoc.1120.0518			SUM 2013	2013	Model aggregation is the process of constructing several base models that are then combined into a single model for prediction. Ensemble classification has been studied by many researchers and found to provide significant performance improvements over single models. This paper presents a new base model combination algorithm for K-nearest neighbor (KNN) ensemble models based on One-Versus-All (OVA) classification. The proposed algorithm uses two decision functions to determine the best prediction among the many predictions provided by the base models. It is demonstrated in this paper that tied or conflicting predictions can be effectively resolved when a probabilistic function and a distance function are used by a combination algorithm for OVA KNN base model predictions. The resolution of tied predictions leads to improvements in predictive performance.								0	0	0	0	0	1091-9856		WOS:000322424000011	
J	Pham, Tuan D.; Truong Cong Thang; Oyama-Higa, Mayumi; Sugiyama, Masahide								Mental-disorder detection using chaos and nonlinear dynamical analysis of photoplethysmographic signals								CHAOS SOLITONS & FRACTALS			51				64	74		10.1016/j.chaos.2013.03.010			JUN 2013	2013	Mental disorder can be defined as a psychological disturbance of thought or emotion. In particular, depression is a mental disease which can ultimately lead to death from suicide. If depression is identified, it can be treated with medication and psychotherapy. However, the diagnosis of depression is difficult and there are currently no any quick and reliable medical tests to detect if someone is depressed. This is because the exact cause of depression is still unknown given the belief that depression results in chemical brain changes, genetic disorder, stress, or the combination of these problems. Photoplethysmography has recently been realized as a non-invasive optical technique that can give new insights into the physiology and pathophysiology of the central and peripheral nervous systems. We present in this paper an automated mental-disorder detection approach in a general sense based on a novel synergy of chaos and nonlinear dynamical methods for the analysis of photoplethysmographic finger pulse waves of mental and control subjects. Such an approach can be applied for automated detection of depression as a special case. Because of the computational effectiveness of the studied methods and low cost of generation of the physiological signals, the proposed automated detection of mental illness is feasible for real-life applications including self-assessment, self-monitoring, and computerized health care. (C) 2013 Elsevier Ltd. All rights reserved.								0	0	0	0	0	0960-0779		WOS:000319485800007	
J	Sanchez-Diaz, Guillermo; Escobar-Franco, Uriel E.; Morales-Manilla, Luis R.; Piza-Davila, Ivan; Aguirre-Salado, Carlos; Franco-Arcega, Anilu				Aguirre-Salado, Carlos Arturo/E-4499-2012				Incremental k most similar neighbor classifier for mixed data								REVISTA FACULTAD DE INGENIERIA-UNIVERSIDAD DE ANTIOQUIA				67			19	30					JUN 2013	2013	This paper presents an incremental k-most similar neighbor classifier, for mixed data and similarity functions that are not necessarily distances. The algorithm presented is suitable for processing large data sets, because it only stores in main memory the k most similar neighbors processed until step t, traversing only once the training data set. Several experiments with synthetic and real data are presented.								0	0	0	0	0	0120-6230		WOS:000321680800002	
J	Senaras, Caglar; Ozay, Mete; Vural, Fatos T. Yarman								Building Detection With Decision Fusion								IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING			6	3	SI		1295	1304		10.1109/JSTARS.2013.2249498			JUN 2013	2013	A novel decision fusion approach to building detection problem in VHR optical satellite images is proposed. The method combines the detection results of multiple classifiers under a hierarchical architecture, called Fuzzy Stacked Generalization (FSG). After an initial segmentation and pre-processing step, a large variety of color, texture and shape features are extracted from each segment. Then, the segments, represented in different feature spaces are classified by different base-layer classifiers of the FSG architecture. The class membership values of the segments, which represent the decisions of different base-layer classifiers in a decision space, are aggregated to form a fusion space which is then fed to a meta-layer classifier of the FSG to label the vectors in the fusion space. The paper presents the performance results of the proposed decision fusion model by a comparison with the state of the art machine learning algorithms. The results show that fusing the decisions of multiple classifiers improves the performance, when they are ensembled under the suggested hierarchical learning architecture.								0	0	0	0	0	1939-1404		WOS:000320871800027	
J	Xu, Dong; Zhang, Yang				xu, dong/I-7737-2013	xu, dong/0000-0002-6616-1427			Ab Initio structure prediction for Escherichia coli: towards genome-wide protein structure modeling and fold assignment								SCIENTIFIC REPORTS			3						1895	10.1038/srep01895			MAY 30 2013	2013	Genome-wide protein structure prediction and structure-based function annotation have been a long-term goal in molecular biology but not yet become possible due to difficulties in modeling distant-homology targets. We developed a hybrid pipeline combining ab initio folding and template-based modeling for genome-wide structure prediction applied to the Escherichia coli genome. The pipeline was tested on 43 known sequences, where QUARK-based ab initio folding simulation generated models with TM-score 17% higher than that by traditional comparative modeling methods. For 495 unknown hard sequences, 72 are predicted to have a correct fold (TM-score > 0.5) and 321 have a substantial portion of structure correctly modeled (TM-score > 0.35). 317 sequences can be reliably assigned to a SCOP fold family based on structural analogy to existing proteins in PDB. The presented results, as a case study of E. coli, represent promising progress towards genome-wide structure modeling and fold family assignment using state-of-the-art ab initio folding algorithms.								0	0	0	0	0	2045-2322		WOS:000319652900002	
J	Zhang, Dandan; Luo, Wenbo; Luo, Yuejia								Single-trial ERP analysis reveals facial expression category in a three-stage scheme								BRAIN RESEARCH			1512				78	88		10.1016/j.brainres.2013.03.044			MAY 28 2013	2013	Emotional faces are salient stimuli that play a critical role in social interactions. Following up on previous research suggesting that the event-related potentials (ERPs) show differential amplitudes in response to various facial expressions, the current study used trial-to-trial variability assembled from six discriminating ERP components to predict the facial expression categories in individual trials. In an experiment involved 17 participants, fearful trials were differentiated from non-fearful trials as early as the intervals of N1 and P1, with a mean predictive accuracy of 87%. Single-trial features in the occurrence of N170 and vertex positive potential could distinguish between emotional and neutral expressions (accuracy=90%). Finally, the trials associated with fearful, happy, and neutral faces were completely separated during the window of N3 and P3 (accuracy=83%). These categorization findings elucidated the temporal evolution of facial expression extraction, and demonstrated that the spatio-temporal characteristics of single-trial ERPs can distinguish facial expressions according to a three-stage scheme, with "fear popup," "emotional/unemotional discrimination," and "complete separation" as processing stages. This work constitutes the first examination of neural processing dynamics beyond multitrial ERP averaging, and directly relates the prediction performance of single-trial classifiers to the progressive brain functions of emotional face discrimination. (C) 2013 Elsevier B.V. All rights reserved.								0	0	0	0	0	0006-8993		WOS:000320087800008	
J	Lee, Jong-Seok; Olafsson, Sigurdur								A meta-learning approach for determining the number of clusters with consideration of nearest neighbors								INFORMATION SCIENCES			232				208	224		10.1016/j.ins.2012.12.033			MAY 20 2013	2013	An important and challenging problem in data clustering is the determination of the best number of clusters. A variety of estimation methods has been proposed over the years to address this problem. Most of these methods depend on several nontrivial assumptions about the data structure; and such methods may thus fail to discover the true clusters in a dataset that does not satisfy those assumptions. We develop a new approach that takes as a starting point the simple and intuitive observation that close objects should fall within the same cluster, whereas distant ones should not. Based on this simple notion we utilize a new measurement of good clustering called disconnectivity as well as existing goodness measurements; and we embed these measures into a meta-learning approach for estimating the number of clusters. A simulation experiment based on 13 representative models and an application to real world datasets are conducted to show the effectiveness of the proposed method. (C) 2013 Elsevier Inc. All rights reserved.								0	0	0	0	0	0020-0255		WOS:000316774700013	
J	Bounhas, Myriam; Mellouli, Khaled; Prade, Henri; Serrurier, Mathieu								Possibilistic classifiers for numerical data								SOFT COMPUTING			17	5			733	751		10.1007/s00500-012-0947-9			MAY 2013	2013	Naive Bayesian Classifiers, which rely on independence hypotheses, together with a normality assumption to estimate densities for numerical data, are known for their simplicity and their effectiveness. However, estimating densities, even under the normality assumption, may be problematic in case of poor data. In such a situation, possibility distributions may provide a more faithful representation of these data. Naive Possibilistic Classifiers (NPC), based on possibility theory, have been recently proposed as a counterpart of Bayesian classifiers to deal with classification tasks. There are only few works that treat possibilistic classification and most of existing NPC deal only with categorical attributes. This work focuses on the estimation of possibility distributions for continuous data. In this paper we investigate two kinds of possibilistic classifiers. The first one is derived from classical or flexible Bayesian classifiers by applying a probability-possibility transformation to Gaussian distributions, which introduces some further tolerance in the description of classes. The second one is based on a direct interpretation of data in possibilistic formats that exploit an idea of proximity between data values in different ways, which provides a less constrained representation of them. We show that possibilistic classifiers have a better capability to detect new instances for which the classification is ambiguous than Bayesian classifiers, where probabilities may be poorly estimated and illusorily precise. Moreover, we propose, in this case, an hybrid possibilistic classification approach based on a nearest-neighbour heuristics to improve the accuracy of the proposed possibilistic classifiers when the available information is insufficient to choose between classes. Possibilistic classifiers are compared with classical or flexible Bayesian classifiers on a collection of benchmarks databases. The experiments reported show the interest of possibilistic classifiers. In particular, flexible possibilistic classifiers perform well for data agreeing with the normality assumption, while proximity-based possibilistic classifiers outperform others in the other cases. The hybrid possibilistic classification exhibits a good ability for improving accuracy.								0	0	0	0	0	1432-7643		WOS:000317786400002	
J	Jalalian, Afsaneh; Mashohor, Syamsiah B. T.; Mahmud, Hajjah Rozi; Saripan, M. Iqbal B.; Ramli, Abdul Rahman B.; Karasfi, Babak				Saripan, M. Iqbal  /A-9582-2010				Computer-aided detection/diagnosis of breast cancer in mammography and ultrasound: a review								CLINICAL IMAGING			37	3			420	426		10.1016/j.clinimag.2012.09.024			MAY-JUN 2013	2013	Breast cancer is the most common form of cancer among women worldwide. Early detection of breast cancer can increase treatment options and patients' survivability. Mammography is the gold standard for breast imaging and cancer detection. However, due to some limitations of this modality such as low sensitivity especially in dense breasts, other modalities like ultrasound and magnetic resonance imaging are often suggested to achieve additional information. Recently, computer-aided detection or diagnosis (CAD) systems have been developed to help radiologists in order to increase diagnosis accuracy. Generally, a CAD system consists of four stages: (a) preprocessing, (b) segmentation of regions of interest, (c) feature extraction and selection, and finally (d) classification. This paper presents the approaches which are applied to develop CAD systems on mammography and ultrasound images. The performance evaluation metrics of CAD systems are also reviewed. (C) 2013 Elsevier Inc. All rights reserved.								0	0	0	0	0	0899-7071		WOS:000318458500002	
J	Li, Yan; Ye, Yunming; Sun, Zhaocai; Hung, Edward; Huang, Joshua; Li, Yueping								An ensemble of decision cluster crotches for classification of high dimensional data								KNOWLEDGE-BASED SYSTEMS			43				63	73		10.1016/j.knosys.2013.01.009			MAY 2013	2013	This paper presents a Crotch Ensemble classification model for high dimensional data. A Crotch Ensemble is obtained from a decision cluster tree built by calling a clustering algorithm recursively. A crotch is an inner node of the tree together with its direct children. If the children of a crotch have more than one dominant class, the crotch is defined as a crotch predictor. Each crotch predictor constructs a classifier by itself. A Crotch Ensemble consists of a set of crotch predictors. When classifying a new object, a subset of crotch predictors is selected according to the distances between the object and the crotch predictors. A classification is made on the object as the class predicted by the crotch predictors with the maximum accumulative weights. The experimental results on both synthetic and real data have shown that the Crotch Ensemble model can get better classification results on high dimensional data than other classification methods. (C) 2013 Elsevier B.V. All rights reserved.								0	0	0	0	0	0950-7051		WOS:000317163100006	
J	Monteith, Kristine; Martinez, Tony								AGGREGATE CERTAINTY ESTIMATORS								COMPUTATIONAL INTELLIGENCE			29	2			207	232		10.1111/j.1467-8640.2012.00433.x			MAY 2013	2013	Selecting an effective method for combining the votes of base inducers in a multiclassifier system can have a significant impact on the system's overall classification accuracy. Some methods cannot even achieve as high a classification accuracy as the most accurate base classifier. To address this issue, we present the strategy of aggregate certainty estimators, which uses multiple measures to estimate a classifier's certainty in its predictions on an instance-by-instance basis. Use of these certainty estimators for vote-weighting allows the system to achieve a higher overall average in classification accuracy than the most accurate base classifier. Weighting with these aggregate measures also results in higher average classification accuracy than weighting with single certainty estimates. Aggregate certainty estimators outperform three baseline strategies, as well as the methods of modified stacking and arbitration, in terms of average accuracy over 36 data sets.								0	0	0	0	0	0824-7935		WOS:000318564800002	
J	Niu, Bing; Lu, Wencong								Using Cheminformatics for the Identification of Biological Functions of Small Molecules in Metabolic Pathway								CURRENT TOPICS IN MEDICINAL CHEMISTRY			13	10			1201	1210					MAY 2013	2013	Small molecules are involved in metabolic pathways responsible for many biological activities. Therefore it is essential to study them to uncover the unknown biological function of highly complex living systems. It is a crucial step in modern drug discovery to correctly and effectively discover small molecules' biological function since small molecules are related to many protein functions and biological processes. This paper presents the application of cheminformatics approaches in predicting small molecule's (ligand's) biological function in metabolic pathway. Many examples of success in identification and prediction in the area of small molecule metabolic pathway mapping and small molecule-protein interaction prediction have been discussed.								0	0	0	0	0	1568-0266		WOS:000319974500007	
J	Norousi, Ramin; Wickles, Stephan; Leidig, Christoph; Becker, Thomas; Schmid, Volker J.; Beckmann, Roland; Tresch, Achim				Schmid, Volker/F-3251-2010	Schmid, Volker/0000-0003-2195-8130			Automatic post-picking using MAPPOS improves particle image detection from cryo-EM micrographs								JOURNAL OF STRUCTURAL BIOLOGY			182	2			59	66		10.1016/j.jsb.2013.02.008			MAY 2013	2013	Cryo-electron microscopy (cryo-EM) studies using single particle reconstruction are extensively used to reveal structural information on macromolecular complexes. Aiming at the highest achievable resolution, state of the art electron microscopes automatically acquire thousands of high-quality micrographs. Particles are detected on and boxed out from each micrograph using fully- or semi-automated approaches. However, the obtained particles still require laborious manual post-picking classification, which is one major bottleneck for single particle analysis of large datasets. We introduce MAPPOS, a supervised post-picking strategy for the classification of boxed particle images, as additional strategy adding to the already efficient automated particle picking routines. MAPPOS employs machine learning techniques to train a robust classifier from a small number of characteristic image features. In order to accurately quantify the performance of MAPPOS we used simulated particle and non-particle images. In addition, we verified our method by applying it to an experimental cryo-EM dataset and comparing the results to the manual classification of the same dataset Comparisons between MAPPOS and manual post-picking classification by several human experts demonstrated that merely a few hundred sample images are sufficient for MAPPOS to classify an entire dataset with a human-like performance. MAPPOS was shown to greatly accelerate the throughput of large datasets by reducing the manual workload by orders of magnitude while maintaining a reliable identification of non-particle images. (c) 2013 Elsevier Inc. All rights reserved.								0	0	0	0	0	1047-8477		WOS:000318391100001	
J	Gual-Arnau, X.; Herold-Garcia, S.; Simo, A.								Shape description from generalized support functions								PATTERN RECOGNITION LETTERS			34	6			619	626		10.1016/j.patrec.2012.12.016			APR 15 2013	2013	The generalized support function is considered to be a representation of shape properties of compact connected sets in R-2. Some interesting properties are studied and several parameters are defined for use in shape description and classification. When these parameters are applied to describe convex figures, they are closely related with the measure of congruent segments of fixed length within the convex figure. Finally, an experimental study is conducted to show the goodness obtained when using the generalized support function in shape classification. (C) 2013 Elsevier B.V. All rights reserved.								0	0	0	0	0	0167-8655		WOS:000317451100003	
J	Hadjidimitriou, Stelios K.; Hadjileontiadis, Leontios J.								EEG-Based Classification of Music Appraisal Responses Using Time-Frequency Analysis and Familiarity Ratings								IEEE TRANSACTIONS ON AFFECTIVE COMPUTING			4	2			161	172		10.1109/T-AFFC.2013.6			APR-JUN 2013	2013	A time-windowing feature extraction approach based on time-frequency (TF) analysis is adopted here to investigate the time-course of the discrimination between musical appraisal electroencephalogram (EEG) responses, under the parameter of familiarity. An EEG data set, formed by the responses of nine subjects during music listening, along with self-reported ratings of liking and familiarity, is used. Features are extracted from the beta (13-30 Hz) and gamma (30-49 Hz) EEG bands in time windows of various lengths, by employing three TF distributions (spectrogram, Hilbert-Huang spectrum, and Zhao-Atlas-Marks transform). Subsequently, two classifiers (k-NN and SVM) are used to classify feature vectors in two categories, i.e., "like" and "dislike," under three cases of familiarity, i.e., regardless of familiarity (LD), familiar music (LDF), and unfamiliar music (LDUF). Key findings show that best classification accuracy (CA) is higher and it is achieved earlier in the LDF case {91.02 +/- 1.45% (7.5-10.5 s)} as compared to the LDUF case {87.10 +/- 1.84% (10-15 s)}. Additionally, best CAs in LDF and LDUF cases are higher as compared to the general LD case {85.28 +/- 0.77%}. The latter results, along with neurophysiological correlates, are further discussed in the context of the existing literature on the time-course of music-induced affective responses and the role of familiarity.								0	0	0	0	0	1949-3045		WOS:000323644200004	
J	Jirina, Marcel; Jirina, Marcel, Jr.								Utilization of singularity exponent in nearest neighbor based classifier								JOURNAL OF CLASSIFICATION			30	1			3	29		10.1007/s00357-013-9121-z			APR 2013	2013	Classifiers serve as tools for classifying data into classes. They directly or indirectly take a distribution of data points around a given query point into account. To express the distribution of points from the viewpoint of distances from a given point, a probability distribution mapping function is introduced here. The approximation of this function in a form of a suitable power of the distance is presented. How to state this power-the distribution mapping exponent-is described. This exponent is used for probability density estimation in high-dimensional spaces and for classification. A close relation of the exponent to a singularity exponent is discussed. It is also shown that this classifier exhibits better behavior (classification accuracy) than other kinds of classifiers for some tasks.								0	0	0	0	0	0176-4268		WOS:000315441300002	
J	Kennedy, K.; Mac Namee, B.; Delany, S. J.								Using semi-supervised classifiers for credit scoring								JOURNAL OF THE OPERATIONAL RESEARCH SOCIETY			64	4			513	529		10.1057/jors.2011.30			APR 2013	2013	In credit scoring, low-default portfolios (LDPs) are those for which very little default history exists. This makes it problematic for financial institutions to estimate a reliable probability of a customer defaulting on a loan. Banking regulation (Basel II Capital Accord), and best practice, however, necessitate an accurate and valid estimate of the probability of default. In this article the suitability of semi-supervised one-class classification (OCC) algorithms as a solution to the LDP problem is evaluated. The performance of OCC algorithms is compared with the performance of supervised two-class classification algorithms. This study also investigates the suitability of over sampling, which is a common approach to dealing with LDPs. Assessment of the performance of one-and two-class classification algorithms using nine real-world banking data sets, which have been modified to replicate LDPs, is provided. Our results demonstrate that only in the near or complete absence of defaulters should semi-supervised OCC algorithms be used instead of supervised two-class classification algorithms. Furthermore, we demonstrate for data sets whose class labels are unevenly distributed that optimising the threshold value on classifier output yields, in many cases, an improvement in classification performance. Finally, our results suggest that oversampling produces no overall improvement to the best performing two-class classification algorithms. Journal of the Operational Research Society (2013) 64, 513-529. doi:10.1057/jors.2011.30								0	0	0	0	0	0160-5682		WOS:000315819600004	
J	Queiroz, F. A. A.; Vieira, D. A. G.; Travassos, X. L.								Analyzing the Relevant Features of GPR Scattered Waves in Time- and Frequency-Domain								RESEARCH IN NONDESTRUCTIVE EVALUATION			24	2			105	123		10.1080/09349847.2012.752889			APR 1 2013	2013	The current work studies the relevance of features in time- and frequency-domain given a scattered Ground Penetrating Radar (GPR) wave. This wave is used to identify inclusions, such as reinforcement bars and fissures, in concrete structures. The right choice of features is fundamental to the design of intelligent machines to support the detection, qualification, and quantification of fissures in concrete. Although the extension of its results to other types of materials is expected to be possible, this work focuses on the analysis of the problem of discovering the characteristics of cylindrical materials inside a concrete structure, which may be conductor, water, or air. Both noiseless and features selected given a white Gaussian noise are considered in simulated data. Some features were extracted, and those selected are presented, indicating that the features in time- and frequency-domain are complementary and relevant. Classification and regression models with different number of features indicate that not all features available are needed to achieve satisfactory performance. Moreover, decreasing the number of features also decreases the computational burden.								0	0	0	0	0	0934-9847		WOS:000317832500003	
J	Wang, Tian; Krim, Hamid; Viniotis, Yannis								A Generalized Markov Graph Model: Application to Social Network Analysis								IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING			7	2			318	332		10.1109/JSTSP.2013.2246767			APR 2013	2013	In this paper we propose a generalized Markov Graph model for social networks and evaluate its application in social network synthesis, and in social network classification. The model reveals that the degree distribution, the clustering coefficient distribution as well as a newly discovered feature, a crowding coefficient distribution, are fundamental to characterizing a social network. The application of this model to social network synthesis leads to a capacity to generate networks dominated by the degree distribution and the clustering coefficient distribution. Another application is a new social network classification method based on comparing the statistics of their degree distributions and clustering coefficient distributions as well as their crowding coefficient distributions. In contrast to the widely held belief that a social network graph is solely defined by its degree distribution, the novelty of this paper consists in establishing the strong dependence of social networks on the degree distribution, the clustering coefficient distribution and the crowding coefficient distribution, and in demonstrating that they form minimal information to classify social networks as well as to design a new social network synthesis tool. We provide numerous experiments with published data and demonstrate very good performance on both counts.								0	0	0	0	0	1932-4553		WOS:000318437000015	
J	Qian, Liwei; Zheng, Haoran; Zhou, Hong; Qin, Ruibin; Li, Jinlong								Classification of Time Series Gene Expression in Clinical Studies via Integration of Biological Network								PLOS ONE			8	3					e58383	10.1371/journal.pone.0058383			MAR 13 2013	2013	The increasing availability of time series expression datasets, although promising, raises a number of new computational challenges. Accordingly, the development of suitable classification methods to make reliable and sound predictions is becoming a pressing issue. We propose, here, a new method to classify time series gene expression via integration of biological networks. We evaluated our approach on 2 different datasets and showed that the use of a hidden Markov model/Gaussian mixture models hybrid explores the time-dependence of the expression data, thereby leading to better prediction results. We demonstrated that the biclustering procedure identifies function-related genes as a whole, giving rise to high accordance in prognosis prediction across independent time series datasets. In addition, we showed that integration of biological networks into our method significantly improves prediction performance. Moreover, we compared our approach with several state-of-the-art algorithms and found that our method outperformed previous approaches with regard to various criteria. Finally, our approach achieved better prediction results on early-stage data, implying the potential of our method for practical prediction.								0	0	0	0	0	1932-6203		WOS:000316849200061	
J	Mourka, A.; Mazilu, M.; Wright, E. M.; Dholakia, K.				Wright, Ewan/A-2358-2009				Modal Characterization using Principal Component Analysis: application to Bessel, higher-order Gaussian beams and their superposition								SCIENTIFIC REPORTS			3						1422	10.1038/srep01422			MAR 12 2013	2013	The modal characterization of various families of beams is a topic of current interest. We recently reported a new method for the simultaneous determination of both the azimuthal and radial mode indices for light fields possessing orbital angular momentum. The method is based upon probing the far-field diffraction pattern from a random aperture and using the recorded data as a 'training set'. We then transform the observed data into uncorrelated variables using the principal component analysis (PCA) algorithm. Here, we show the generic nature of this approach for the simultaneous determination of the modal parameters of Hermite-Gaussian and Bessel beams. This reinforces the widespread applicability of this method for applications including information processing, spectroscopy and manipulation. Additionally, preliminary results demonstrate reliable decomposition of superpositions of Laguerre-Gaussians, yielding the intensities and relative phases of each constituent mode. Thus, this approach represents a powerful method for characterizing the optical multi-dimensional Hilbert space.								0	0	0	0	0	2045-2322		WOS:000315938000003	
J	An, Fengwei; Mattausch, Hans Juergen								K-means clustering algorithm for multimedia applications with flexible HW/SW co-design								JOURNAL OF SYSTEMS ARCHITECTURE			59	3			155	164		10.1016/j.sysarc.2012.11.004			MAR 2013	2013	In this paper, we report a hardware/software (MW/SW) co-designed K-means clustering algorithm with high flexibility and high performance for machine learning, pattern recognition and multimedia applications. The contributions of this work can be attributed to two aspects. The first is the hardware architecture for nearest neighbor searching, which is used to overcome the main computational cost of a K-means clustering algorithm. The second aspect is the high flexibility for different applications which comes from not only the software but also the hardware. High flexibility with respect to the number of training data samples, the dimensionality of each sample vector, the number of clusters, and the target application, is one of the major shortcomings of dedicated hardware implementations for the K-means algorithm. In particular, the HW/SW K-means algorithm is extendable to embedded systems and mobile devices. We benchmark our multi-purpose K-means system against the application of handwritten digit recognition, face recognition and image segmentation to demonstrate its excellent performance, high flexibility, fast clustering speed, short recognition time, good recognition rate and versatile functionality. (c) 2012 Elsevier B.V. All rights reserved.								0	0	0	0	0	1383-7621		WOS:000318889500004	
J	Angiulli, Fabrizio; Fassetti, Fabio								Nearest Neighbor-Based Classification of Uncertain Data								ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			7	1					1	10.1145/2435209.2435210			MAR 2013	2013	This work deals with the problem of classifying uncertain data. With this aim we introduce the Uncertain Nearest Neighbor (UNN) rule, which represents the generalization of the deterministic nearest neighbor rule to the case in which uncertain objects are available. The UNN rule relies on the concept of nearest neighbor class, rather than on that of nearest neighbor object. The nearest neighbor class of a test object is the class that maximizes the probability of providing its nearest neighbor. The evidence is that the former concept is much more powerful than the latter in the presence of uncertainty, in that it correctly models the right semantics of the nearest neighbor decision rule when applied to the uncertain scenario. An effective and efficient algorithm to perform uncertain nearest neighbor classification of a generic (un)certain test object is designed, based on properties that greatly reduce the temporal cost associated with nearest neighbor class probability computation. Experimental results are presented, showing that the UNN rule is effective and efficient in classifying uncertain data.								0	0	0	0	0	1556-4681		WOS:000316415700001	
J	Asensio, C.; Moschioni, G.; Ruiz, M.; Tarabini, M.; Recuero, M.								Implementation of a thrust reverse noise detection system for airports								TRANSPORTATION RESEARCH PART D-TRANSPORT AND ENVIRONMENT			19				42	47		10.1016/j.trd.2012.12.003			MAR 2013	2013	A thrust reverse noise detection methodology for airports is developed and tested in terms of meeting the restrictions at Madrid-Barajas airport. The detection is based on thresholds applied to the sound power level time histories estimated using a microphone array and an inverse sound propagation model. The two sound events detected are classified as landing and thrust reverse to complete the identification of thrust reverse activation. The methodology performs well especially in the detection stage because the estimation of sound power level enhances the sound events and their separation, even if landing and thrust reverse are close to each other. The implementation of the TREND tool has error rates lower than 10%. (c) 2013 Elsevier Ltd. All rights reserved.								0	0	0	0	0	1361-9209		WOS:000316520800007	
J	Banda, J. M.; Angryk, R. A.; Martens, P. C. H.								On Dimensionality Reduction for Indexing and Retrieval of Large-Scale Solar Image Data								SOLAR PHYSICS			283	1			113	141		10.1007/s11207-012-0027-4			MAR 2013	2013	This work investigates the applicability of several dimensionality reduction techniques for large-scale solar data analysis. Using a solar benchmark dataset that contains images of multiple types of phenomena, we investigate linear and nonlinear dimensionality reduction methods in order to reduce our storage and processing costs and maintain a good representation of our data in a new vector space. We present a comparative analysis of several dimensionality reduction methods and different numbers of target dimensions by utilizing different classifiers in order to determine the degree of data dimensionality reduction that can be achieved with these methods, and to discover the method that is the most effective for solar images. After determining the optimal number of dimensions, we then present preliminary results on indexing and retrieval of the dimensionally reduced data.								0	0	0	0	0	0038-0938		WOS:000314984700008	
J	Brito-Sanchez, Y.; Castillo-Garit, J. A.; Le-Thi-Thu, H.; Gonzalez-Madariaga, Y.; Torrens, F.; Marrero-Ponce, Y.; Rodriguez-Borges, J. E.								Comparative study to predict toxic modes of action of phenols from molecular structures								SAR AND QSAR IN ENVIRONMENTAL RESEARCH			24	3			235	251		10.1080/1062936X.2013.766260			MAR 1 2013	2013	Quantitative structureactivity relationship models for the prediction of mode of toxic action (MOA) of 221 phenols to the ciliated protozoan Tetrahymena pyriformis using atom-based quadratic indices are reported. The phenols represent a variety of MOAs including polar narcotics, weak acid respiratory uncouplers, pro-electrophiles and soft electrophiles. Linear discriminant analysis (LDA), and four machine learning techniques (ML), namely k-nearest neighbours (k-NN), support vector machine (SVM), classification trees (CTs) and artificial neural networks (ANNs), have been used to develop several models with higher accuracies and predictive capabilities for distinguishing between four MOAs. Most of them showed global accuracy of over 90%, and false alarm rate values were below 2.9% for the training set. Cross-validation, complementary subsets and external test set were performed, with good behaviour in all cases. Our models compare favourably with other previously published models, and in general the models obtained with ML techniques show better results than those developed with linear techniques. We developed unsupervised and supervised consensus, and these results were better than our ML models, the results of rule-based approach and other ensemble models previously published. This investigation highlights the merits of ML-based techniques as an alternative to other more traditional methods for modelling MOA.								0	0	0	0	0	1062-936X		WOS:000316078400004	
J	Liu, Liang; Lu, Wen-Cong; Cai, Yu-Dong; Feng, Kai-Yan; Peng, Chunrong; Zhu, Yubei								Prediction of Protein-protein Interactions Based on Feature Selection and Data Balancing								PROTEIN AND PEPTIDE LETTERS			20	3			336	345					MAR 2013	2013	Computational approaches are able to analyze protein-protein interactions (PPIs) from a different angle of view by complementing the experimental ones. And they are very efficient in determining whether two proteins can interact with each other. In this paper, KNNs (K-nearest neighbors) is applied to predict the PPIs by coding each protein with the physical and chemical properties of its residues, predicted secondary structures and amino acid compositions. mRMR (minimum-redundancy maximum-relevance) feature selection is adopted to select a compact feature set, features of which are considered to be important for the determination of PPI-nesses. Because the size of the negative dataset (containing non-interactive protein pairs) is much larger than that of the positive dataset (containing interactive protein pairs), the negative dataset is divided into 5 portions and each portion is combined with the positive dataset for one prediction. Thus 5 predictions are performed and the final results are obtained through voting. As a result, the prediction achieves an overall accuracy of 0.8369 with sensitivity of 0.7356. The predictor, developed by this research for the prediction of the fruit fly PPI-nesses, is available for public use at http://chemdata.shu.edu.cn/ppip.								0	0	0	0	0	0929-8665		WOS:000316860900012	
J	Liu, Ming; Wu, Yan; Zhang, Peng; Zhang, Qiang; Li, Yanxin; Li, Ming								SAR Target Configuration Recognition Using Locality Preserving Property and Gaussian Mixture Distribution								IEEE GEOSCIENCE AND REMOTE SENSING LETTERS			10	2			268	272		10.1109/LGRS.2012.2198610			MAR 2013	2013	Feature extraction is the key step of synthetic aperture radar (SAR) target configuration recognition. A statistical model embedding the locality preserving property is presented to extract the maximum amount of desired information from the data, which is of crucial help to recognition. The noise, or error, of the SAR image samples is described by a Gaussian mixture distribution, and the locality preserving property is embedded into the statistical model to focus on the problem of configuration recognition. Along with the extraction of the information of interest through the use of the statistical model, also, the preservation of the local structure of the data set is achieved. Parameter estimation is implemented through the expectation-maximization algorithm. Experimental results on the Moving and Stationary Target Acquisition and Recognition data set validate the effectiveness of the proposed method. SAR target configuration recognition is realized with satisfactory accuracy.								0	0	0	0	0	1545-598X		WOS:000310901600013	
J	Liu, Zhun-ga; Pan, Quan; Dezert, Jean								A new belief-based K-nearest neighbor classification method								PATTERN RECOGNITION			46	3			834	844		10.1016/j.patcog.2012.10.001			MAR 2013	2013	The K-nearest neighbor (K-NN) classification method originally developed in the probabilistic framework has serious difficulties to classify correctly the close data points (objects) originating from different classes. To cope with such difficult problem and make the classification result more robust to misclassification errors, we propose a new belief-based K-nearest neighbor (BK-NN) method that allows each object to belong both to the specific classes and to the sets of classes with different masses of belief. BK-NN is able to provide a hyper-credal classification on the specific classes, the rejection classes and the meta-classes as well. Thus, the objects hard to classify correctly are automatically committed to a meta-class or to a rejection class, which can reduce the misclassification errors. The basic belief assignment (bba) of each object is defined from the distance between the object and its neighbors and from the acceptance and rejection thresholds. The bba's are combined using a new combination method specially developed for the BK-NN. Several experiments based on simulated and real data sets have been carried out to evaluate the performances of the BK-NN method with respect to several classical K-NN approaches. Crown Copyright (C) 2012 Published by Elsevier Ltd. All rights reserved.								0	0	0	0	0	0031-3203		WOS:000313385700019	
J	Manor, Ohad; Segal, Eran								Robust Prediction of Expression Differences among Human Individuals Using Only Genotype Information								PLOS GENETICS			9	3					e1003396	10.1371/journal.pgen.1003396			MAR 2013	2013	Many genetic variants that are significantly correlated to gene expression changes across human individuals have been identified, but the ability of these variants to predict expression of unseen individuals has rarely been evaluated. Here, we devise an algorithm that, given training expression and genotype data for a set of individuals, predicts the expression of genes of unseen test individuals given only their genotype in the local genomic vicinity of the predicted gene. Notably, the resulting predictions are remarkably robust in that they agree well between the training and test sets, even when the training and test sets consist of individuals from distinct populations. Thus, although the overall number of genes that can be predicted is relatively small, as expected from our choice to ignore effects such as environmental factors and trans sequence variation, the robust nature of the predictions means that the identity and quantitative degree to which genes can be predicted is known in advance. We also present an extension that incorporates heterogeneous types of genomic annotations to differentially weigh the importance of the various genetic variants, and we show that assigning higher weights to variants with particular annotations such as proximity to genes and high regional G/C content can further improve the predictions. Finally, genes that are successfully predicted have, on average, higher expression and more variability across individuals, providing insight into the characteristics of the types of genes that can be predicted from their cis genetic variation.								0	0	0	0	0	1553-7404		WOS:000316866700067	
J	Wong, Andrew; Shatkay, Hagit								Protein Function Prediction using Text-based Features extracted from the Biomedical Literature: The CAFA Challenge								BMC BIOINFORMATICS			14						S14	10.1186/1471-2105-14-S3-S14		3	FEB 28 2013	2013	Background: Advances in sequencing technology over the past decade have resulted in an abundance of sequenced proteins whose function is yet unknown. As such, computational systems that can automatically predict and annotate protein function are in demand. Most computational systems use features derived from protein sequence or protein structure to predict function. In an earlier work, we demonstrated the utility of biomedical literature as a source of text features for predicting protein subcellular location. We have also shown that the combination of text-based and sequence-based prediction improves the performance of location predictors. Following up on this work, for the Critical Assessment of Function Annotations (CAFA) Challenge, we developed a text-based system that aims to predict molecular function and biological process (using Gene Ontology terms) for unannotated proteins. In this paper, we present the preliminary work and evaluation that we performed for our system, as part of the CAFA challenge.Results: We have developed a preliminary system that represents proteins using text-based features and predicts protein function using a k-nearest neighbour classifier (Text-KNN). We selected text features for our classifier by extracting key terms from biomedical abstracts based on their statistical properties. The system was trained and tested using 5-fold cross-validation over a dataset of 36,536 proteins. System performance was measured using the standard measures of precision, recall, F-measure and overall accuracy. The performance of our system was compared to two baseline classifiers: one that assigns function based solely on the prior distribution of protein function (Base-Prior) and one that assigns function based on sequence similarity (Base-Seq). The overall prediction accuracy of Text-KNN, Base-Prior, and Base-Seq for molecular function classes are 62%, 43%, and 58% while the overall accuracy for biological process classes are 17%, 11%, and 28% respectively. Results obtained as part of the CAFA evaluation itself on the CAFA dataset are reported as well.Conclusions: Our evaluation shows that the text-based classifier consistently outperforms the baseline classifier that is based on prior distribution, and typically has comparable performance to the baseline classifier that uses sequence similarity. Moreover, the results suggest that combining text features with other types of features can potentially lead to improved prediction performance. The preliminary results also suggest that while our text-based classifier can be used to predict both molecular function and biological process in which a protein is involved, the classifier performs significantly better for predicting molecular function than for predicting biological process. A similar trend was observed for other classifiers participating in the CAFA challenge.								0	0	0	0	0	1471-2105		WOS:000317187500014	
J	Griffin, Lewis D.; Wahab, M. Husni; Newell, Andrew J.								Distributional Learning of Appearance								PLOS ONE			8	2					e58074	10.1371/journal.pone.0058074			FEB 27 2013	2013	Opportunities for associationist learning of word meaning, where a word is heard or read contemperaneously with information being available on its meaning, are considered too infrequent to account for the rate of language acquisition in children. It has been suggested that additional learning could occur in a distributional mode, where information is gleaned from the distributional statistics (word co-occurrence etc.) of natural language. Such statistics are relevant to meaning because of the Distributional Principle that 'words of similar meaning tend to occur in similar contexts'. Computational systems, such as Latent Semantic Analysis, have substantiated the viability of distributional learning of word meaning, by showing that semantic similarities between words can be accurately estimated from analysis of the distributional statistics of a natural language corpus. We consider whether appearance similarities can also be learnt in a distributional mode. As grounds for such a mode we advance the Appearance Hypothesis that 'words with referents of similar appearance tend to occur in similar contexts'. We assess the viability of such learning by looking at the performance of a computer system that interpolates, on the basis of distributional and appearance similarity, from words that it has been explicitly taught the appearance of, in order to identify and name objects that it has not been taught about. Our experiment tests with a set of 660 simple concrete noun words. Appearance information on words is modelled using sets of images of examples of the word. Distributional similarity is computed from a standard natural language corpus. Our computation results support the viability of distributional learning of appearance.								0	0	0	0	0	1932-6203		WOS:000315519000182	
J	Sun, Jigang; Crowe, Malcolm; Fyfe, Colin								Incorporating visualisation quality measures to curvilinear component analysis								INFORMATION SCIENCES			223				75	101		10.1016/j.ins.2012.09.047			FEB 20 2013	2013	Curvilinear Component Analysis (CCA) is a useful data visualisation method. CCA has the technical property that its optimisation surface, as defined by its stress function, changes during the optimisation according to a decreasing parameter. CCA uses a variant of the stochastic gradient descent method to create a mapping of data. In the optimisation method of CCA, the stress function is only a general guide towards an acceptable mapping. In other multidimensional scaling methods such as Sammon's mapping, the best mapping among multiple runs from different initialisations can be chosen by selecting the mapping with the lowest stress, whereas in CCA the embedding is simply the result of one run, surely we can have multiple starts. As a consequence of the absence of an objective function to be used as a selection criterion, embedding made by CCA can be poorly optimised. In this paper we present a new way of improving the optimisation of CCA by integrating non-stress data visualisation quality measures into the existing algorithm. We first use data visualisation quality measures to select the best mapping from multiple runs of a standard stochastic gradient descent implementation; then we tune various parameters involved to achieve further enhancement. A brief comparison with other dimensionality reduction methods is included. (C) 2012 Elsevier Inc. All rights reserved.								0	0	0	0	0	0020-0255		WOS:000312915400005	
J	Barranquero, Jose; Gonzalez, Pablo; Diez, Jorge; Jose del Coz, Juan								On the study of nearest neighbor algorithms for prevalence estimation in binary problems								PATTERN RECOGNITION			46	2			472	482		10.1016/j.patcog.2012.07.022			FEB 2013	2013	This paper presents a new approach for solving binary quantification problems based on nearest neighbor (NN) algorithms. Our main objective is to study the behavior of these methods in the context of prevalence estimation. We seek for NN-based quantifiers able to provide competitive performance while balancing simplicity and effectiveness. We propose two simple weighting strategies, PWK and PWW alpha, which stand out among state-of-the-art quantifiers. These proposed methods are the only ones that offer statistical differences with respect to less robust algorithms, like CC or AC. The second contribution of the paper is to introduce a new experiment methodology for quantification. (C) 2012 Elsevier Ltd. All rights reserved.								0	0	0	0	0	0031-3203		WOS:000310820800002	
J	Derrac, J.; Verbiest, N.; Garcia, S.; Cornelis, C.; Herrera, F.				Cornelis, Chris/B-7585-2013; Herrera, Francisco/C-6856-2008	Cornelis, Chris/0000-0002-7854-6025; Herrera, Francisco/0000-0002-7283-312X			On the use of evolutionary feature selection for improving fuzzy rough set based prototype selection								SOFT COMPUTING			17	2			223	238		10.1007/s00500-012-0888-3			FEB 2013	2013	The k-nearest neighbors classifier is a widely used classification method that has proven to be very effective in supervised learning tasks. In this paper, a fuzzy rough set method for prototype selection, focused on optimizing the behavior of this classifier, is presented. The hybridization with an evolutionary feature selection method is considered to further improve its performance, obtaining a competent data reduction algorithm for the 1-nearest neighbors classifier. This hybridization is performed in the training phase, by using the solution of each preprocessing technique as the starting condition of the other one, within a cycle. The results of the experimental study, which have been contrasted through nonparametric statistical tests, show that the new hybrid approach obtains very promising results with respect to classification accuracy and reduction of the size of the training set.								0	0	0	0	0	1432-7643		WOS:000313969400004	
J	Lu, Can-Yi; Min, Hai; Gui, Jie; Zhu, Lin; Lei, Ying-Ke								Face recognition via Weighted Sparse Representation								JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION			24	2	SI		111	116		10.1016/j.jvcir.2012.05.003			FEB 2013	2013	Face recognition using Sparse Representation based Classification (SRC) is a new hot technique in recent years. SRC can be regarded as a generalization of Nearest Neighbor and Nearest Feature Subspace. This paper first reviews the Nearest Feature Classifiers (NFCs), including Nearest Neighbor (NN), Nearest Feature Line (NFL), Nearest Feature Plane (NFP) and Nearest Feature Subspace (NFS), and formulates them as general optimization problems, which provides a new perspective for understanding NFCs and SRC. Then a locality Weighted Sparse Representation based Classification (WSRC) method is proposed. WSRC utilizes both data locality and linearity; it can be regarded as extensions of SRC, but the coding is local. Experimental results on the Extended Yale B, AR databases and several data sets from the UCI repository show that WSRC is more effective than SRC. Crown Copyright (C) 2012 Published by Elsevier Inc. All rights reserved.								0	0	0	0	0	1047-3203		WOS:000314859000004	
J	Sarro, L. M.; Berihuete, A.; Carrion, C.; Barrado, D.; Cruz, P.; Isasi, Y.								Properties of ultra-cool dwarfs with Gaia An assessment of the accuracy for the temperature determination								ASTRONOMY & ASTROPHYSICS			550						A44	10.1051/0004-6361/201219867			FEB 2013	2013	Context. The Gaia catalogue will contain observations and physical parameters of a vast number of objects, including ultra-cool dwarf stars, which we define here as stars with a temperature below 2500 K.Aims. We aimed to assess the accuracy of the Gaia T-eff and log (g) estimates as derived with current models and observations.Methods. We assessed the validity of several inference techniques for deriving the physical parameters of ultra-cool dwarf stars: Gaussian processes, support vector machines, k-nearest neighbours, kernel partial least squares and Bayesian estimation. In addition, we tested the potential benefits of data compression for improving robustness and speed. We used synthetic spectra derived from ultra-cool dwarf models to construct (train) the regression models. We derived the intrinsic uncertainties of the best inference models and assessed their validity by comparing the estimated parameters with the values derived in the bibliography for a sample of ultra-cool dwarf stars observed from the ground.Results. We estimated the total number of ultra-cool dwarfs per spectral subtype, and obtained values that can be summarised (in orders of magnitude) as 400 000 objects in the M5-L0 range, 600 objects between L0 and L5, 30 objects between L5 and T0, and 10 objects between T0 and T8. A bright ultra-cool dwarf (with T-eff = 2500 K and log (g) = 3.5) will be detected by Gaia out to approximately 220 pc, while for T-eff = 1500 K (spectral type L5) and the same surface gravity, this maximum distance reduces to 10 20 pc. We found the cross-validation RMSE prediction error to be 10 K for regression models based on the k-nearest neighbours and 62 K for Gaussian process models in the faintest limit (Gaia magnitude G = 20). However, these values correspond to the evaluation of the regression models with independent test sets of synthetic spectra of the same model families as used in the training phase (internal errors). For the k-nearest neighbours model, this seems an overly optimistic error estimate due to the use of a dense grid of examples in the training set, together with a relatively high signal-to-noise ratio for the end-of-mission data. The RMSE of the prediction deduced from ground-based spectra of ultra-cool dwarfs simulated at the Gaia spectral range and resolution, and for a Gaia magnitude G = 20 is 213 K and 266 K for the models based on k-nearest neighbours and Gaussian process regression, respectively. These are total errors in the sense that they include the internal and external errors, with the latter caused by the inability of the synthetic spectral models (used for the construction of the regression models) to exactly reproduce the observed spectra, and by the large uncertainties in the current calibrations of spectral types and effective temperatures. We found maximum-likelihood methods (minimum chi(2), k-nearest neighbours, and Bayesian estimation with flat priors) to be biased in the L0-T0 range in that they systematically assign a temperature around 1700 K. Finally, the likelihood landscape is significantly multimodal in spectra with realistic noise.								0	0	0	0	0	0004-6361		WOS:000314879700044	
J	Xu, Jie; Yin, Jun								Kernel least absolute shrinkage and selection operator regression classifier for pattern classification								IET COMPUTER VISION			7	1			48	55		10.1049/iet-cvi.2011.0193			FEB 2013	2013	The feature vectors in feature space are more likely to be linearly separable than the observations in input space. To enhance the separability of the feature vectors, the authors perform least absolute shrinkage and selection operator (LASSO) regression in the reproducing kernel Hilbert space and develop a kernel LASSO regression classifier (LASSO-KRC). Based on the theory of calculus, least squares optimisation with L1-norm regularised constraints can be reformulated into another equivalent form. Without an explicit mapping function, the solution to the optimisation problem can be obtained by solving a convex optimisation problem with any symmetric kernel function. LASSO-KRC is applied to pattern classification and appears to outperform nearest neighbour classifier, minimum distance classifier, sparse representation classifier and linear regression classifier.								0	0	0	0	0	1751-9632		WOS:000320878900006	
J	Lee, Sanguk; Lee, Hyeseon; Chung, Hoeil								New discrimination method combining hit quality index based spectral matching and voting								ANALYTICA CHIMICA ACTA			758				58	65		10.1016/j.aca.2012.10.058			JAN 3 2013	2013	A new discrimination method, called hit quality index (HQI)-voting, that uses the HQI for discriminant analysis has been developed. HQI indicates the degree of spectral matching between two spectra as known. In this method, a library sample yielding the highest HQI value for an unknown sample was initially searched and a group containing this sample was chosen as the group for the unknown sample. When overall spectral features of two groups are quite close to each other, many library samples with similar HQI values could be available for an unknown sample. In this situation, the simultaneous consideration of multiple votes (several library samples with close HQI values) for final decision would be more robust. In order to evaluate the discrimination performance of HQI-voting, three different near-infrared (NIR) spectroscopic datasets composed of two sample groups were used: (1) domestic and imported sesame samples, (2) domestic and imported Angelica gigas samples, and (3) diesel and light gas oil (LGO) samples. For the purpose of comparison, principal component analysis-linear discriminant analysis (PCA-LDA), partial least squares-discriminant analysis (PLS-DA) as well as k-nearest neighbor (k-NN) were also performed using the same datasets and the resulting accuracies were compared. The discrimination performances improved with the use of HQI-voting in comparison with those resulted from PCA-LDA and PLS-DA. The overall results support that HQI-voting is a comparable discrimination method to that of existing factor-based multivariate methods. (C) 2012 Elsevier B.V. All rights reserved.				13th Conference on Chemometrics in Analytical Chemistry (CAC)	JUN 25-29, 2012	Coordenacao Aperfeicoamento Pessoal Nivel Super (CAPES); Minist Sci & Technol, Conselho Nacl Desenvolvimento Cientifico & Tecnologico (CNPq); Fundacao Amparo Pesquisa Estado Sao Paulo (FAPESP)	Budapest, HUNGARY	0	0	0	0	0	0003-2670		WOS:000313861700006	
J	Dan, Jingpei; Shi, Weiren; Dong, Fangyan; Hirota, Kaoru								Piecewise Trend Approximation: A Ratio-Based Time Series Representation								ABSTRACT AND APPLIED ANALYSIS									603629	10.1155/2013/603629			2013	2013	A time series representation, piecewise trend approximation (PTA), is proposed to improve efficiency of time series data mining in high dimensional large databases. PTA represents time series in concise form while retaining main trends in original time series; the dimensionality of original data is therefore reduced, and the key features are maintained. Different from the representations that based on original data space, PTA transforms original data space into the feature space of ratio between any two consecutive data points in original time series, of which sign and magnitude indicate changing direction and degree of local trend, respectively. Based on the ratio-based feature space, segmentation is performed such that each two conjoint segments have different trends, and then the piecewise segments are approximated by the ratios between the first and last points within the segments. To validate the proposed PTA, it is compared with classical time series representations PAA and APCA on two classical datasets by applying the commonly used K-NN classification algorithm. For ControlChart dataset, PTA outperforms them by 3.55% and 2.33% higher classification accuracy and 8.94% and 7.07% higher for Mixed-BagShapes dataset, respectively. It is indicated that the proposed PTA is effective for high dimensional time series data mining.								0	0	0	0	0	1085-3375		WOS:000319589600001	
J	David, Gil; Bernstein, Larry Howard; Coifman, Ronald R.								The automated malnutrition assessment								NUTRITION			29	1			113	121		10.1016/j.nut.2012.04.017			JAN 2013	2013	Objective: We propose an automated nutritional assessment algorithm that provides a method for malnutrition risk prediction with high accuracy and reliability.Methods: The database used for this study was a file of 432 patients, where each patient was described by 4 laboratory parameters and 11 clinical parameters. A malnutrition risk assessment of low (1), moderate (2), or high (3) was assigned by a dietitian for each patient. An algorithm for data organization and classification using characteristic metrics for each patient was developed. For each patient, the algorithm characterized the patients' unique profile and built a characteristic metric to identify similar patients who were mapped into a classification. For each patient, the algorithm characterized the patients' classification.Results: The algorithm assigned a malnutrition risk level for different training sizes that were taken from the data. Our method resulted in average errors (distance between the automated score and the real score) of 0.386, 0.3507, 0.3454, 0.34, and 0.2907 for the 10%, 30%, 50%, 70%, and 90% training sizes, respectively. Our method outperformed the compared method even when our method used a smaller training set than the compared method. In addition, we showed that the laboratory parameters themselves were sufficient for the automated risk prediction and organized the patients into clusters that corresponded to low-, low-moderate-, moderate-, moderate-high-, and high-risk areas. The organization and visualization methods provided a tool for the exploration and navigation of the data points.Conclusion: The problem of rapidly identifying risk and severity of malnutrition is crucial for minimizing medical and surgical complications. These are not easily performed or adequately expedited. We characterized for each patient a unique profile and mapped similar patients into a classification. We also found that the laboratory parameters were sufficient for the automated risk prediction. (C) 2013 Elsevier Inc. All rights reserved.								0	0	0	0	0	0899-9007		WOS:000313138200019	
J	Fujita, Osamu								Metrics based on average distance between sets								JAPAN JOURNAL OF INDUSTRIAL AND APPLIED MATHEMATICS			30	1			1	19		10.1007/s13160-012-0089-6			2013	2013	This paper presents a distance function between sets based on an average of distances between their elements. The distance function is a metric if the sets are non-empty finite subsets of a metric space. It includes the Jaccard distance as a special case, and can be generalized by using the power mean so as to also include the Hausdorff metric on finite sets. It can be extended to deal with non-null measurable sets, and applied for measuring distances between fuzzy sets and between probability distributions. These distance functions are useful for measuring similarity between data in computer science and information science. In instructional systems design and information retrieval, for example, they are likely to be useful for analyzing and processing text documents that are modeled as hierarchical collections of sets of terms. A distance measure of learners' knowledge is also discussed in connection with quantities of information.								0	0	0	0	0	0916-7005		WOS:000316433000001	
J	Gu, Qingyi; Takaki, Takeshi; Ishii, Idaku				Ishii, Idaku/D-7393-2011				Fast FPGA-Based Multiobject Feature Extraction								IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY			23	1			30	45		10.1109/TCSVT.2012.2202195			JAN 2013	2013	This paper describes a high-frame-rate (HFR) vision system that can extract locations and features of multiple objects in an image at 2000 f/s for 512x512 images by implementing a cell-based multiobject feature extraction algorithm as hardware logic on a field-programmable gate array-based high-speed vision platform. In the hardware implementation of the algorithm, 25 higher-order local autocorrelation features of 1024 objects in an image can be simultaneously extracted for multiobject recognition by dividing the image into 8x8 cells concurrently with calculation of the zeroth and first-order moments to obtain the sizes and locations of multiple objects. Our developed HFR multiobject extraction system was verified by performing several experiments: tracking for multiple objects rotating at 16 r/s, recognition for multiple patterns projected at 1000 f/s, and recognition for human gestures with quick finger motion.								0	0	0	0	0	1051-8215		WOS:000317387800003	
J	Hernandez-Leal, Pablo; Ariel Carrasco-Ochoa, J.; Fco Martinez-Trinidad, J.; Arturo Olvera-Lopez, J.								InstanceRank based on borders for instance selection								PATTERN RECOGNITION			46	1			365	375		10.1016/j.patcog.2012.07.007			JAN 2013	2013	Instance selection algorithms are used for reducing the number of training instances. However, most of them suffer from long runtimes which results in the incapability to be used with large datasets. In this work, we introduce an Instance Ranking per class using Borders (instances near to instances belonging to different classes), using this ranking we propose an instance selection algorithm (IRB). We evaluated the proposed algorithm using k-NN with small and large datasets, comparing it against state of the art instance selection algorithms. In our experiments, for large datasets IRB has the best compromise between time and accuracy. We also tested our algorithm using SVM, LWLR and C4.5 classifiers, in all cases the selection computed by our algorithm obtained the best accuracies in average. (C) 2012 Elsevier Ltd. All rights reserved.								0	0	0	0	0	0031-3203		WOS:000309785000032	
J	Hou, Tao; Liu, Fu; Lin, Caixia X.; Li, Dingyuan Y.								A New Vector for Identification of Prokaryotes and Their Variable-Size Genomes								CURRENT MICROBIOLOGY			66	1			96	101		10.1007/s00284-012-0246-9			JAN 2013	2013	A large number of prokaryotes have been produced, so how to provide a means to describe and distinguish them accurately is becoming a key issue of prokaryotic taxonomy. We proposed an efficient algorithm to filter out most genome fragments that are horizontally transferred, and extracted a new genome vector (GV). To highlight the power of GV, we applied it to identify prokaryotes and their variable-size genome fragments. The result indicated that the new vector as species tags can accurately identify genome fragments as short as 3,000 bp at species level.								0	0	0	0	0	0343-8651		WOS:000312659500014	
S	Karymy, Ali; Qian, Zhiyu; Wang, Xiao						Lee, G		Classification of Independent Alcohol and Healthy Individuals by Electroencephalogram Signals								PSYCHOLOGY, MANAGEMENT AND SOCIAL SCIENCE	Advances in Education Research		16				239	244					2013	2013	Alcohol abuse causes many economical and social losses. In this paper, we discussed how to separate the alcoholic from healthy individuals by classify of electroencephalogram (EEG) signals. The visual evoked potential (VEP) was used to classify the two groups. We also extracted event related potential (ERP) and gamma band visual evoked potential (VEP) from the raw (EEG) signals to improve the classification rate.				International Conference on Psychology, Management and Social Science (PMSS 2013)	JAN 23-24, 2013	Informat Engn Res Inst; Trans Tech Publicat Inc; Int Mat Sci Soc	Shenzhen, PEOPLES R CHINA	0	0	0	0	0	2160-1070	978-1-61275-053-8	WOS:000319084500051	
J	Lucey, Simon; Ashraf, Ahmed Bilal								Nearest neighbor classifier generalization through spatially constrained filters								PATTERN RECOGNITION			46	1			325	331		10.1016/j.patcog.2012.06.009			JAN 2013	2013	It is widely understood that the performance of the nearest neighbor (NN) rule is dependent on: (i) the way distances are computed between different examples, and (ii) the type of feature representation used. Linear filters are often used in computer vision as a pre-processing step, to extract useful feature representations. In this paper we demonstrate an equivalence between (i) and (ii) for NN tasks involving weighted Euclidean distances. Specifically, we demonstrate how the application of a bank of linear filters can be re-interpreted, in the form of a symmetric weighting matrix, as a manipulation of how distances are computed between different examples for NN classification. Further, we argue that filters fulfill the role of encoding local spatial constraints into this weighting matrix. We then demonstrate how these constraints can dramatically increase the generalization capability of canonical distance metric learning techniques in the presence of unseen illumination and viewpoint change. (C) 2012 Elsevier Ltd. All rights reserved.								0	0	0	0	0	0031-3203		WOS:000309785000028	
S	Mignani, A. G.; Ciaccheri, L.; Mencaglia, A. A.; Cichelli, A.; Xing, J.; Yang, X.; Sun, W.; Yuan, L.						Jaroszewicz, LR		Detection and quantification of hogwash oil in soybean oils using low-cost spectroscopy and chemometrics								FIFTH EUROPEAN WORKSHOP ON OPTICAL FIBRE SENSORS	Proceedings of SPIE		8794						UNSP 879415	10.1117/12.2025833			2013	2013	This paper presents the detection and quantification of hogwash oil in soybean oils by means of absorption spectroscopy. Three types of soybean oils were adulterated with different concentrations of hogwash oil. The spectra were measured in the visible band using a white LED and a low-cost spectrometer. The measured spectra were processed by means of multivariate analysis to distinguish the adulteration and, for each soybean oil, to quantify the adulterant concentration. Then the visible spectra were sliced into two bands for modeling a simple setup made of two LEDs only. The successful results indicate potentials for implementing a smartphone-compatible device for self-assessment of soybean oil quality.				5th European Workshop on Optical Fibre Sensors	MAY 19-22, 2013	Photon Soc Poland; Mil Univ Technol; Warsaw Univ Technol; Jagiellonian Univ; Innovat Econ Natl Cohes Strategy; InPhoTech Ltd; AMS Technologies; PHOENIX	Krakow, POLAND	0	0	0	0	0	0277-786X	978-0-8194-9634-8	WOS:000323497600041	
S	Pan, Julong; Hu, Linglong; Li, Wenjin; Cui, Hui; Li, Ziyin						Zhang, J; Wang, ZJ; Zhu, SR; Meng, XM		Weighted k Nearest Neighbour-based Cooperation Intrusion Detection System for Wireless Sensor Networks					1-4			INFORMATION TECHNOLOGY APPLICATIONS IN INDUSTRY, PTS 1-4	Applied Mechanics and Materials		263-266				2972	2978		10.4028/www.scientific.net/AMM.263-266.2972			2013	2013	To identify the malicious nodes timely in wireless sensor networks(WSNs), a cooperation intrusion detection scheme based on weighted k Nearest Neighbour(kNN) is proposed. Given a few types of sensor nodes, the test model extracts the properties of sensor nodes related with the known types of malicious nodes, and establishes sample spaces of all sensor nodes which participate in network activities. According to the known node's attributes sampled, the unknown type sensor nodes are classified based on weighted INN. Considering of energy consumption, an intrusion detection system selection algorithm is joined in the sink node. Simulation results show that the scheme has a lower false detection rate and a higher detection rate at the same time, and it can preserve energy of detection nodes compared with an existing intrusion detection scheme.				International Conference on Information Technology and Management Innovation (ICITMI2012)	NOV 10-11, 2012	Guangdong Univ Business Studies, Informat Sci Sch	Guangzhou, PEOPLES R CHINA	0	0	0	0	0	1660-9336	978-3-03785-574-4	WOS:000318818701233	
B	Pour, Golsa Moayeri; Troped, Philip J.; Evans, Jeffrey J.			IEEE					Environment Feature Extraction and Classification for Context Aware Physical Activity Monitoring								2013 IEEE SENSORS APPLICATIONS SYMPOSIUM (SAS)							123	128					2013	2013	Context aware Physical Activity (PA) monitoring of humans is important for the study of diseases associated with obesity and lack of physical activity. This paper introduces a wearable context aware PA monitoring device which determines if the user is indoors or outside in situations of disrupted Global Positioning System (GPS) reception. In addition to a GPS sensor, multiple light and temperature sensors were added to our PA monitoring device. Differences in inside and outside temperature and the intensity of light are used to distinguish the context of location. Location, Light and temperature values were recorded using a controlled route during a period of 20 days in January and February. One of the non-parametric pattern recognition techniques (K-nearest neighbors) was used to classify indoor and outdoor conditions based on the combination of sensor values. Results show that the K-nearest neighbors algorithm could distinguish indoor and outdoor conditions during daytime and nighttime with the error of 0.003.				8th IEEE Sensors Applications Symposium (SAS)	FEB 19-21, 2013	IEEE; IEEE Instrumentat & Measurement Soc (I&M)	Galveston, TX	0	0	0	0	0		978-1-4673-4635-1	WOS:000319392200023	
J	Scanlon, Patricia; Kavanagh, Darren F.; Boland, Francis M.								Residual Life Prediction of Rotating Machines Using Acoustic Noise Signals								IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT			62	1			95	108		10.1109/TIM.2012.2212508			JAN 2013	2013	While automated condition monitoring of rotating machines often use vibration signals for defect detection, diagnosis, and residual life predictions, in this paper, the acoustic noise signal (< 25 kHz), acquired via non-contact microphone sensors, is used to predict the remaining useful life (RUL). Modulation spectral (MS) analysis of acoustic signals has the potential to provide additional long-term information over more conventional short-term signal spectral components. However, the high dimensionality of MS features has been cited as a limitation to their applicability in this area in the literature. Therefore, in this study, a novel approach is proposed which employs an information theoretic approach to feature subset selection of modulation spectra features. This approach does not require information regarding the spectral location of defect frequencies to be known or pre-estimated and leverages information regarding the chronological order of data samples for dimensionality reduction. The results of this study show significant improvements for this proposed approach over the other commonly used spectral-based approaches for the task of predicting RUL by up to 19% relative over the standard envelope analysis approach used in the literature. A further 16% improvement was achieved by applying a more rigorous approach to labeling of acoustic samples acquired over the lifetime of the machines over a fixed length class labeling approach. A detailed misclassification analysis is provided to interpret the relative cost of system errors for the task of residual life predictions of rotating machines used in industrial applications.								0	0	0	0	0	0018-9456		WOS:000312451500010	
J	Shen, Linlin; Zhu, Zexuan; Jia, Sen; Zhu, Jiasong; Sun, Yiwen								Discriminative Gabor Feature Selection for Hyperspectral Image Classification								IEEE GEOSCIENCE AND REMOTE SENSING LETTERS			10	1			29	33		10.1109/LGRS.2012.2191761			JAN 2013	2013	Three-dimensional Gabor wavelets have recently been successfully applied for hyperspectral image classification due to their ability to extract joint spatial and spectrum information. However, the dimension of the extracted Gabor feature is incredibly huge. In this letter, we propose a symmetrical-uncertainty-based and Markov-blanket-based approach to select informative and nonredundant Gabor features for hyperspectral image classification. The extracted Gabor features with large dimension are first ranked by their information contained for classification and then added one by one after investigating the redundancy with already selected features. The proposed approach was fully tested on the widely used Indian Pine site data. The results show that the selected features are much more efficient and can achieve similar performance with previous approach using only hundreds of features.								0	0	0	0	0	1545-598X		WOS:000310899700006	
B	Thomas, Shyju; Wilson, Jobin; Chaudhury, Santanu			IEEE					Best-Fit Mobile Recharge Pack Recommendation								2013 NATIONAL CONFERENCE ON COMMUNICATIONS (NCC)	National Conference on Communications NCC												2013	2013	In today's competitive market, mobile service providers are very keen on improving the customer satisfaction by providing personalized services. Recommending recharge packs to the subscribers that suits their personal profile is an important such personalized service. But a solution to this problem is not that simple as it requires careful analysis of the subscribers' usage behavior and involves very large volume of data generated by the subscribers' frequent interaction with the telecom network. Also, this solution needs to ensure a fine balance between customer satisfaction and profitability of service providers. This paper discusses about an adaptive recommendation model which overcomes various deficiencies associated with existing solutions. The model recommends suitable recharge packs to subscribers based on their usage history and affordability. Further, it accommodates a configurable fairness parameter that ensures a balance between the profitability factor, conversion probability and relevance of the recommendations. Due to the sheer volume of the data involved, the model is implemented using a distributed framework. The validity of the model is evaluated on the basis of statistical properties and conversion factor.				19th National Conference on Communications (NCC)	FEB 15-17, 2013	Joint Telemat Grp	Indian Inst Technol, Delhi, INDIA	0	0	0	0	0		978-1-4673-5952-8	WOS:000318553200013	
J	Vandekerckhove, Bram; Sandra, Dominiek; Daelemans, Walter				Vandekerckhove, Bram/A-3113-2013	Vandekerckhove, Bram/0000-0001-9152-849X			Selective impairment of adjective order constraints as overeager abstraction: An elaboration on Kemmerer et al. (2009)								JOURNAL OF NEUROLINGUISTICS			26	1			46	72		10.1016/j.jneuroling.2012.04.001			JAN 2013	2013	Kemmerer, Tranel, and Zdanczyk (2009) reported patients who failed to discriminate between preferred and dispreferred orders of prenominal adjectives, yet were sensitive to the order of adjectives in relation to other parts of speech, and able to judge which of two adjectives was most similar to a cue adjective. The authors concluded that knowledge of the semantic constraints on prenominal adjective order can be impaired without an impairment of purely syntactic adjective order knowledge, or knowledge of semantic adjective classes. Using simulation studies, we demonstrate that the impairment of these patients can be characterized as overeager abstraction. Over-smoothing a similarity-based bigram language model with a similarity metric based on word co-occurrence distributions resulted in the same performance dissociation between tasks as reported for Kemmerer et al.'s selectively impaired patients. Additionally, the strength with which the patients preferred a specific adjective order for a given stimulus was predicted by the stimulus' robustness to overeager abstraction. Our results provide a general cognitive account based on the online creation of temporary summary representations that is supported by current neurocognitive views on verbal cognition. This account lends a more insightful explanation for impairments of linguistic knowledge than an explanation relying solely on linguistic abstractions. (C) 2012 Elsevier Ltd. All rights reserved.								0	0	0	0	0	0911-6044		WOS:000310413400004	
S	Wigdahl, J.; Agurto, C.; Murray, V.; Barriga, S.; Soliz, P.						Novak, CL; Aylward, S		Training Set Optimization and Classifier Performance in a Top-Down Diabetic Retinopathy Screening System								MEDICAL IMAGING 2013: COMPUTER-AIDED DIAGNOSIS	Proceedings of SPIE		8670						86702K	10.1117/12.2007931			2013	2013	Diabetic retinopathy (DR) affects more than 4.4 million Americans age 40 and over. Automatic screening for DR has shown to be an efficient and cost-effective way to lower the burden on the healthcare system, by triaging diabetic patients and ensuring timely care for those presenting with DR. Several supervised algorithms have been developed to detect pathologies related to DR, but little work has been done in determining the size of the training set that optimizes an algorithm's performance. In this paper we analyze the effect of the training sample size on the performance of a top-down DR screening algorithm for different types of statistical classifiers. Results are based on partial least squares (PLS), support vector machines (SVM), k-nearest neighbor (kNN), and Naive Bayes classifiers. Our dataset consisted of digital retinal images collected from a total of 745 cases (595 controls, 150 with DR). We varied the number of normal controls in the training set, while keeping the number of DR samples constant, and repeated the procedure 10 times using randomized training sets to avoid bias. Results show increasing performance in terms of area under the ROC curve (AUC) when the number of DR subjects in the training set increased, with similar trends for each of the classifiers. Of these, PLS and k-NN had the highest average AUC. Lower standard deviation and a flattening of the AUC curve gives evidence that there is a limit to the learning ability of the classifiers and an optimal number of cases to train on.				Conference on Medical Imaging - Computer-Aided Diagnosis	FEB 12-14, 2013	SPIE; Aeroflex Inc; Univ Cent Florida, CREOL Coll Opt & Photon; DQE Instruments Inc; Medtronic Inc; PIXELTEQ	Lake Buena Vista, FL	0	0	0	0	0	0277-786X	978-0-8194-9444-3	WOS:000322261500088	
J	Xu, Jie; Yang, Jian								A nonnegative sparse representation based fuzzy similar neighbor classifier								NEUROCOMPUTING			99				76	86		10.1016/j.neucom.2012.06.018			JAN 1 2013	2013	This paper presents a new classification technique by combining the well-known Sparse Representation based algorithm with the theory of Fuzzy Set. The basic idea of this work is that samples with the same class-labels should be more similar to each other than those with different class-labels. Based on this similarity rule, we first impose the nonnegative coefficient constraints on the sparse representation based algorithm and obtain the desirable similar neighbors. Then by introducing the theory of Fuzzy Set into our work, we construct the fuzzy class membership matrix and then assign the decision membership of the query sample to each class. The class assigned with the dominant decision membership is wanted. The proposed approach is called the Nonnegative Sparse Representation based Fuzzy Similar Neighbor Classification (FSNC). FSNC has the following properties: (a) the neighbor parameter K is not needed to be set in advance, and K is adaptively set by the algorithm itself; (b) similar neighbors are also generated adaptively and contain much more similar properties of the query sample; (c) the degree of similarity of data is clearly recorded in the sparse nonnegative coefficient vector: (d) the fuzzy decision rule is effective and the proposed classifier FSNC is simple. Experimental results conducted on the Wine database from UCI, the AR face database, the CENPARMI handwritten numeral database, and the PolyU palmprint database show that the new proposed classification technique outperforms some other state-of-the-art classifiers. (C) 2012 Elsevier B.V. All rights reserved.								0	0	0	0	0	0925-2312		WOS:000311129300008	
J	Zhai, Junhai; Zhai, Mengyao; Bai, Chenyan								An improved algorithm for calculating fuzzy attribute reducts								JOURNAL OF INTELLIGENT & FUZZY SYSTEMS			25	2			303	313		10.3233/IFS-2012-0637			2013	2013	Fuzzy rough attribute reduct has been widely used to remove redundant real-valued attributes without discretizing. By now, there are two existing fuzzy rough attribute reduct methods, one is based on dependency function and another based on discernibility matrix. The former proposed by Shen in 2002 can deal with fuzzy decision table (FDT) with real-valued condition attributes and fuzzy decision attributes. However, this algorithm is not convergent on many real datasets, and the computational complexity of the algorithm increases exponentially with the number of input variables. The latter proposed by Tsang in 2008 can only deal with fuzzy decision table with real-valued condition attributes and symbol-valued decision attributes. In this paper, we extend the latter method and propose two algorithms for calculating all fuzzy rough attribute reducts to deal with fuzzy decision table with real-valued condition and decision attributes. The first algorthim is designed for computing all fuzzy attribute reducts, yet the computational complexity of this algorithm increases exponentially with the number of attributes. The second one which can find one near-optimal reduct is a heuristic variant of the first algorithm. The experimental results show the proposed method is feasible and effective.								0	0	0	0	0	1064-1246		WOS:000319616400005	
J	Cadag, Eithon; Tarczy-Hornoch, Peter; Myler, Peter J.								Learning virulent proteins from integrated query networks								BMC BIOINFORMATICS			13						321	10.1186/1471-2105-13-321			DEC 2 2012	2012	Background: Methods of weakening and attenuating pathogens' abilities to infect and propagate in a host, thus allowing the natural immune system to more easily decimate invaders, have gained attention as alternatives to broad-spectrum targeting approaches. The following work describes a technique to identifying proteins involved in virulence by relying on latent information computationally gathered across biological repositories, applicable to both generic and specific virulence categories.Results: A lightweight method for data integration is used, which links information regarding a protein via a path-based query graph. A method of weighting is then applied to query graphs that can serve as input to various statistical classification methods for discrimination, and the combined usage of both data integration and learning methods are tested against the problem of both generalized and specific virulence function prediction.Conclusions: This approach improves coverage of functional data over a protein. Moreover, while depending largely on noisy and potentially non-curated data from public sources, we find it outperforms other techniques to identification of general virulence factors and baseline remote homology detection methods for specific virulence categories.								0	0	0	0	0	1471-2105		WOS:000314339500001	
J	Cao, Jingjing; Kwong, Sam; Wang, Ran								A noise-detection based AdaBoost algorithm for mislabeled data								PATTERN RECOGNITION			45	12			4451	4465		10.1016/j.patcog.2012.05.002			DEC 2012	2012	Noise sensitivity is known as a key related issue of AdaBoost algorithm. Previous works exhibit that AdaBoost is prone to be overfitting in dealing with the noisy data sets due to its consistent high weights assignment on hard-to-learn instances (mislabeled instances or outliers). In this paper, a new boosting approach, named noise-detection based AdaBoost (ND-AdaBoost), is exploited to combine classifiers by emphasizing on training misclassified noisy instances and correctly classified non-noisy instances. Specifically, the algorithm is designed by integrating a noise-detection based loss function into AdaBoost to adjust the weight distribution at each iteration. A k-nearest-neighbor (k-NN) and an expectation maximization (EM) based evaluation criteria are both constructed to detect noisy instances. Further, a regeneration condition is presented and analyzed to control the ensemble training error bound of the proposed algorithm which provides theoretical support. Finally, we conduct some experiments on selected binary UCI benchmark data sets and demonstrate that: the proposed algorithm is more robust than standard and other types of AdaBoost for noisy data sets. (C) 2012 Elsevier Ltd. All rights reserved.								0	1	0	0	1	0031-3203		WOS:000308271000032	
J	Kavousi, Kaveh; Sadeghi, Mehdi; Moshiri, Behzad; Araabi, Babak N.; Moosavi-Movahedi, Ali Akbar								Evidence theoretic protein fold classification based on the concept of hyperfold								MATHEMATICAL BIOSCIENCES			240	2			148	160		10.1016/j.mbs.2012.07.001			DEC 2012	2012	In current computational biology, assigning a protein domain to a fold class is a complicated and controversial task. It can be more challenging in the much harder task of correct identification of protein domain fold pattern solely through using extracted information from protein sequence. To deal with such a challenging problem, the concepts of hyperfold and interlaced folds are introduced for the first time. Each hyperfold is a set of interlaced folds with a centroid fold. These concepts are used to construct a framework for handling the uncertainty involved with the fold classification problem. In this approach, an unknown query protein is assigned to a hyperfold rather than a single fold. Ten different sequence based features are used to predicting the correct hyperfold. This architecture is featured by the Dempster-Shafer theory of evidence through the bodies of evidence and Dempster's rule of combination to combine the hyperfolds. The classification architecture thus developed was applied for identifying protein folds among the 27 famous SCOP fold patterns from a stringent well-known dataset. Compared with the existing predictors tested by the same benchmark dataset, our approach might achieve the better results. (C) 2012 Elsevier Inc. All rights reserved.								0	0	0	0	0	0025-5564		WOS:000311070600008	
J	Pylarinos, Dionisios; Theofilatos, Konstantinos; Siderakis, Kiriakos; Thalassinakis, Emmanuel; Vitellas, Isidoros; Alexandridis, Antonio T.; Pyrgioti, Eleftheria								Investigation and Classification of Field Leakage Current Waveforms								IEEE TRANSACTIONS ON DIELECTRICS AND ELECTRICAL INSULATION			19	6			2111	2118					DEC 2012	2012	Leakage current (LC) monitoring is a widely employed tool for the investigation of surface electrical activity and the performance of high voltage insulators. Surface activity is correlated to the shape of LC waveforms. Although field monitoring is necessary in order to acquire an exact view of activity and insulators' performance, field waveforms are not often recorded due to the required long term monitoring and the accumulation of data. Instead, extracted values, such as the peak value, charge and number of pulses exceeding predefined thresholds, are recorded, with actual waveforms either being recorded occasionally or not at all. However, a fully representative extracted value is yet to be determined. In this paper, 1540 field waveforms are investigated to acquire a detailed image of the waveforms' shape in the field. Simple classification rules are employed to distinguish between basic groups. Discharge waveforms are further classified based on the duration of discharges. Twenty different features, from time and frequency domain, two feature extraction algorithms (student t-test and mRMR) and three classification algorithms (knn, Naive Bayes, Support Vector Machines) are employed for the classification. Results described in this paper can be used to maximize the efficiency of field LC monitoring.								0	0	0	0	0	1070-9878		WOS:000313457200033	
J	Soguero-Ruiz, Cristina; Gimeno-Blanes, Francisco-Javier; Mora-Jimenez, Inmaculada; Pilar Martinez-Ruiz, Maria; Rojo-Alvarez, Jose-Luis				Martinez-Ruiz, Maria Pilar/B-7200-2012	Martinez-Ruiz, Maria Pilar/0000-0002-5890-5174			On the differential benchmarking of promotional efficiency with machine learning modeling (I): Principles and statistical comparison								EXPERT SYSTEMS WITH APPLICATIONS			39	17			12772	12783		10.1016/j.eswa.2012.04.017			DEC 1 2012	2012	Sales promotions have become in recent years a paramount issue in the marketing strategies of many companies, and they have even more relevance in the present economic situation. Currently, the empirical models, aimed at assessing consumers behavior in response to certain sales promotions activities such as temporary price reductions, are receiving growing attention in this relevant research field, due to two reasons mainly: (1) the complexity of the interactions among the different elements incorporated inside promotions campaigns attracts growing attention; and (2) the increased availability of electronic records on sales history. Hence, it will become important that the performance description and comparison among all available machine learning promotion models, as well as their design parameters selection, will be performed using a robust and statistically rigorous procedure, while keeping functionality and usefulness. In this paper, we first propose a simple nonparametric statistical tool, based on the paired bootstrap resampling, to allow an operative result comparison among different learning-from-samples promotional models. Secondly, we use the bootstrap statistical description to evaluate the models in terms of average and scatter measurements, for a more complete efficiency characterization of the promotional sales models. These statistical characterizations allow us to readily work with the distribution of the actual risk, in order to avoid overoptimistic performance evaluation in the machine learning based models. We also present the analysis performed to determinate whether the figure of merit has a significant impact on final result, together with an in depth design parameter selection to optimize final results during the promotion evaluation using statistical learning techniques. No significant difference was obtained in terms of figure of merit choice, and Mean Absolute Error was selected for performance measurement. As a summary, the applied technique allows clarifying the design of the promotional sales models for a real database (milk category), according to the influence of the figure of merit used for design parameters selection, showing the robustness of the machine learning techniques in this setting. Results obtained in this paper will be subsequently applied, and presented in the companion paper, devoted to a more detailed quality analysis, to evaluate four well-known machine learning algorithms in real databases for two categories with different promotional behavior. (c) 2012 Elsevier Ltd. All rights reserved.								0	0	0	0	0	0957-4174		WOS:000308449300004	
J	Tehrani, Ali Fallah; Cheng, Weiwei; Huellermeier, Eyke								Preference Learning Using the Choquet Integral: The Case of Multipartite Ranking								IEEE TRANSACTIONS ON FUZZY SYSTEMS			20	6			1102	1113		10.1109/TFUZZ.2012.2196050			DEC 2012	2012	We propose a novel method for preference learning or, more specifically, learning to rank, where the task is to learn a ranking model that takes a subset of alternatives as input and produces a ranking of these alternatives as output. Just like in the case of conventional classifier learning, training information is provided in the form of a set of labeled instances, with labels or, say, preference degrees taken from an ordered categorical scale. This setting is known as multipartite ranking in the literature. Our approach is based on the idea of using the (discrete) Choquet integral as an underlying model for representing ranking functions. Being an established aggregation function in fields such as multiple criteria decision making and information fusion, the Choquet integral offers a number of interesting properties that make it attractive from a machine learning perspective, too. The learning problem itself comes down to properly specifying the fuzzy measure on which the Choquet integral is defined. This problem is formalized as a margin maximization problem and solved by means of a cutting plane algorithm. The performance of our method is tested on a number of benchmark datasets.								0	0	0	0	0	1063-6706		WOS:000311853200009	
J	Wang, Mingyang; Yu, Guang; An, Shuang; Yu, Daren								Discovery of factors influencing citation impact based on a soft fuzzy rough set model								SCIENTOMETRICS			93	3			635	644		10.1007/s11192-012-0766-x			DEC 2012	2012	In this paper, the machine learning tools were used to identify key features influencing citation impact. Both the papers' external and quality information were considered in constructing papers' feature space. Based on the feature space, the soft fuzzy rough set was used to generate a series of associated feature subsets. Then, the KNN classifier was used to find the feature subset with the best classification performance. The results show that citation impact could be predicted by objectively assessed factors. Both the papers' quality and external features, mainly represented as the reputation of the first author, are contributed to future citation impact.								0	0	0	0	0	0138-9130		WOS:000310964500004	
J	Masetti, Giuseppe; Calder, Brian								Remote identification of a shipwreck site from MBES backscatter								JOURNAL OF ENVIRONMENTAL MANAGEMENT			111				44	52		10.1016/j.jenvman.2012.06.037			NOV 30 2012	2012	The method described attempts to remotely identify the shape of an anthropogenic object, such as a wreck of a modern vessel, using reflectivity data from Multi-Beam Echosounder (MBES) systems. In the beam domain, the backscatter strength values - geometrically and radiometrically corrected - are used to extract a large number of Gray Level Co-occurrence Matrix (GLCM) features with different input parameters. Principal Component Analysis (PCA) is applied in order to achieve dimensionality reduction whilst a K-means algorithm clusters as "shipwreck site" a large number of beams for each line. After the geo-referencing process, a K-nearest-neighbors (K-NN) technique is applied as a filter for possible misclassifications. Finally, the shape of the shipwreck site is defined from the georeferenced beams using the alpha-shape method, constructing an output compatible with Geographic Information Systems (GIS). (C) 2012 Elsevier Ltd. All rights reserved.								0	0	0	0	0	0301-4797		WOS:000311005200006	
J	Cervellera, C.; Gaggero, M.; Maccio, D.								Efficient kernel models for learning and approximate minimization problems								NEUROCOMPUTING			97				74	85		10.1016/j.neucom.2012.04.023			NOV 15 2012	2012	This paper investigates techniques for reducing the computational burden of local learning methods relying on kernel functions in the framework of approximate minimization, i.e., when they are employed to find the minimum of a given cost functional. The considered approach is based on an optimal choice of the kernel width parameters through the minimization of an empirical cost and can provide a solution to important problems, such as function approximation and multistage optimization. However, when the stored data are too many, the kernel model output evaluation can take a long time, making local learning unsuited to contexts where a fast function evaluation is required. At the same time, the training procedure to obtain the kernel widths can become too demanding as well. Here it is shown that a large saving in the computational effort can be achieved by considering subsets of the available data suitably chosen according to different criteria. An analysis of the performance of the new approach is provided. Then, simulation results show in practice the effectiveness of the proposed techniques when applied to learning and approximate minimization problems. (C) 2012 Elsevier B.V. All rights reserved.								0	0	0	0	0	0925-2312		WOS:000309318200009	
J	Triguero, Isaac; Derrac, Joaquin; Garcia, Salvador; Herrera, Francisco				Herrera, Francisco/C-6856-2008	Herrera, Francisco/0000-0002-7283-312X			Integrating a differential evolution feature weighting scheme into prototype generation								NEUROCOMPUTING			97				332	343		10.1016/j.neucom.2012.06.009			NOV 15 2012	2012	Prototype generation techniques have arisen as very competitive methods for enhancing the nearest neighbor classifier through data reduction. Within the prototype generation methodology, the methods of adjusting the prototypes' positioning have shown an outstanding performance. Evolutionary algorithms have been used to optimize the positioning of the prototypes with promising results. However, these results can be improved even more if other data reduction techniques, such as prototype selection and feature weighting, are considered.In this paper, we propose a hybrid evolutionary scheme for data reduction, incorporating a new feature weighting scheme within two different prototype generation methodologies. Specifically, we will focus on a self-adaptive differential evolution algorithm in order to optimize feature weights and the placement of the prototypes. The results are contrasted with nonparametric statistical tests, showing that our proposal outperforms previously proposed methods, thus showing itself to be a suitable tool in the task of enhancing the performance of the nearest neighbor classifier. (c) 2012 Elsevier B.V. All rights reserved.								0	0	0	0	0	0925-2312		WOS:000309318200033	
J	Wen, Guihua; Jiang, Lijun; Wen, Jun; Wei, Jia; Yu, Zhiwen								Perceptual relativity-based local hyperplane classification								NEUROCOMPUTING			97				155	163		10.1016/j.neucom.2012.03.018			NOV 15 2012	2012	The k-local hyperplane distance nearest neighbors classification (HKNN) builds a non-linear decision surface with maximal local margin in the input space, with invariance inferred from the local neighborhood rather than the prior knowledge, so that it performs very well in many applications. However, it still cannot be comparable with human being in classification on the noisy, the sparse, and the imbalance data. This paper proposes a new approach,called relative local hyperplane classifier(RLHC), to overcome this problem by utilizing the perceptual relativity to HKNN. It finds k nearest neighbors for the query sample from each class and then performs the relative transformation over all these nearest neighbors to build the relative space. Subsequently, each local hyperplane is constructed in the relative space, which is then applied to perform the classification. Experimental results on both real and simulated data suggest that the proposed approach often gives the better results in classification and robustness. (C) 2012 Elsevier B.V. All rights reserved.								0	0	0	0	0	0925-2312		WOS:000309318200018	
J	Biau, Gerard; Devroye, Luc; Dujmovic, Vida; Krzyzak, Adam								An affine invariant k-nearest neighbor regression estimate								JOURNAL OF MULTIVARIATE ANALYSIS			112				24	34		10.1016/j.jmva.2012.05.020			NOV 2012	2012	We design a data-dependent metric in lie and use it to define the k-nearest neighbors of a given point. Our metric is invariant under all affine transformations. We show that, with this metric, the standard k-nearest neighbor regression estimate is asymptotically consistent under the usual conditions on k, and minimal requirements on the input data. (C) 2012 Elsevier Inc. All rights reserved.								0	0	0	0	0	0047-259X		WOS:000308281900002	
J	Huo, Hong; Qing, Jianjun; Fang, Tao; Li, Nan								Land Cover Classification Using Local Softened Affine Hull					1			IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			50	11			4369	4383		10.1109/TGRS.2012.2191970			NOV 2012	2012	Training samples are usually very scarce in land cover classification, which challenges many supervised classifiers. To deal with this problem, this work presents a new learning approach, called local softened affine hull (LSAH). One of the most attractive characters of this classifier is its ability to expand the training set through exploiting "virtual" prototypes. During classification, this method utilizes some local prototypes around the query sample to construct SAH manifolds for each class, which are then employed to determine the label ownership of the query by the nearest neighbor rule. Because each SAH represents infinite "virtual" samples that approximate the "underlying" or "possible" variants of the real prototypes, the representational capacity of the training set is greatly enlarged; LSAH thus avoids the sample scarce problem. Meanwhile, as the number of the local prototypes is usually very small relative to the total training samples of each class, LSAH can run efficiently in classification tasks. LSAH's performance is demonstrated on some land cover classification tasks using three remote sensing images, in comparison with several popular algorithms, including maximum likelihood classifier, K-nearest neighbor, backpropagation neural network, and support vector machine. Experimental results show that the accuracy of LSAH is significantly higher than those of most of others, with the classification speed being quite comparable.								0	0	0	0	0	0196-2892		WOS:000310888000013	
J	Xu, Wenyao; Zhang, Mi; Sawchuk, Alexander A.; Sarrafzadeh, Majid								Robust Human Activity and Sensor Location Corecognition via Sparse Signal Representation								IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING			59	11			3169	3176		10.1109/TBME.2012.2211355			NOV 2012	2012	Human activity recognition with wearable body sensors receives lots of attentions in both research and industrial communities due to the significant role in ubiquitous and mobile health monitoring. One of the most concerned issues related to this wearable technology is that the sensor signals significantly depends on where the sensors are worn on the human body. Existing research work either extracts location information from the activity signals or takes advantage of the sensor location information as a priori information to achieve better activity recognition performance. In this paper, we present a sparse signal-based approach to corecognize human activity and sensor location in a single framework. Therefore, the wearable sensor is not necessarily constrained to fixed body position and the deployment is much easier although the recognition difficulty becomes much more challenging. To validate the effectiveness of our approach, we run a pilot study in the lab, which includes 14 human activities and seven on-body locations to recognize. The experimental results show that our approach achieves an 87.72% classification accuracy (the mean of precision and recall), which outperforms classical classification methods.								0	0	0	0	0	0018-9294		WOS:000310154700023	
J	Ye, Qiaolin; Ye, Ning; Gao, Shangbing								Density-based weighting multi-surface least squares classification with its applications								KNOWLEDGE AND INFORMATION SYSTEMS			33	2			289	308		10.1007/s10115-012-0499-4			NOV 2012	2012	Traditionally, multi-plane support vector machines (SVM), including twin support vector machine (TWSVM) and least squares twin support vector machine (LSTSVM), consider all of points and view them as equally important points. In real cases, most of the samples of a dataset are highly correlated. These samples generally lie in the high-density regions and may be important for performances of classifiers. This motivates the rush toward new classifiers that can sufficiently take advantage of the points in the high-density regions. Illuminated by several new geometrically motivated algorithms, we propose density-based weighting multi-surface least squares classification (DWLSC) method, which is designed for classification. Considering the special features of multi-plane SVMs, DWLSC can measure the importance of points sharing the same labels by density weighting method and sufficiently make the full use of margin point information between pairs of points from different classes. It also includes naturally an extension of the non-linear case. In addition to keeping the respective advantages of both TWSVM and LSTSVM, our method improves the separation of the points sharing different classes and is shown to be better than other multi-plane classifiers in favor of reduction in space complexity, especially when confronted with the non-linear case. In addition, experimental evidence suggests that our method is effective in performing classification tasks.								0	0	0	0	0	0219-1377		WOS:000309874800003	
J	Zhang, Shichao								Nearest neighbor selection for iteratively kNN imputation								JOURNAL OF SYSTEMS AND SOFTWARE			85	11			2541	2552		10.1016/j.jss.2012.05.073			NOV 2012	2012	Existing kNN imputation methods for dealing with missing data are designed according to Minkowski distance or its variants, and have been shown to be generally efficient for numerical variables (features, or attributes). To deal with heterogeneous (i.e., mixed-attributes) data, we propose a novel kNN (k nearest neighbor) imputation method to iteratively imputing missing data, named GkNN (gray kNN) imputation. GkNN selects k nearest neighbors for each missing datum via calculating the gray distance between the missing datum and all the training data rather than traditional distance metric methods, such as Euclidean distance. Such a distance metric can deal with both numerical and categorical attributes. For achieving the better effectiveness, GkNN regards all the imputed instances (i.e., the missing data been imputed) as observed data, which with complete instances (instances without missing values) together to iteratively impute other missing data. We experimentally evaluate the proposed approach, and demonstrate that the gray distance is much better than the Minkowski distance at both capturing the proximity relationship (or nearness) of two instances and dealing with mixed attributes. Moreover, experimental results also show that the GkNN algorithm is much more efficient than existent kNN imputation methods. (c) 2012 Elsevier Inc. All rights reserved.								0	0	0	0	0	0164-1212		WOS:000309315500011	
J	Higashi, Susan; Salles Barreto, Andre da Motta; Cantao, Mauricio Egidio; Ribeiro de Vasconcelos, Ana Tereza								Analysis of composition-based metagenomic classification								BMC GENOMICS			13						S1	10.1186/1471-2164-13-S5-S1		5	OCT 19 2012	2012	Background: An essential step of a metagenomic study is the taxonomic classification, that is, the identification of the taxonomic lineage of the organisms in a given sample. The taxonomic classification process involves a series of decisions. Currently, in the context of metagenomics, such decisions are usually based on empirical studies that consider one specific type of classifier. In this study we propose a general framework for analyzing the impact that several decisions can have on the classification problem. Instead of focusing on any specific classifier, we define a generic score function that provides a measure of the difficulty of the classification task. Using this framework, we analyze the impact of the following parameters on the taxonomic classification problem: (i) the length of n-mers used to encode the metagenomic sequences, (ii) the similarity measure used to compare sequences, and (iii) the type of taxonomic classification, which can be conventional or hierarchical, depending on whether the classification process occurs in a single shot or in several steps according to the taxonomic tree.Results: We defined a score function that measures the degree of separability of the taxonomic classes under a given configuration induced by the parameters above. We conducted an extensive computational experiment and found out that reasonable values for the parameters of interest could be (i) intermediate values of n, the length of the n-mers; (ii) any similarity measure, because all of them resulted in similar scores; and (iii) the hierarchical strategy, which performed better in all of the cases.Conclusions: As expected, short n-mers generate lower configuration scores because they give rise to frequency vectors that represent distinct sequences in a similar way. On the other hand, large values for n result in sparse frequency vectors that represent differently metagenomic fragments that are in fact similar, also leading to low configuration scores. Regarding the similarity measure, in contrast to our expectations, the variation of the measures did not change the configuration scores significantly. Finally, the hierarchical strategy was more effective than the conventional strategy, which suggests that, instead of using a single classifier, one should adopt multiple classifiers organized as a hierarchy.				X Meeting / International Conference on the Brazilian-Association-for-Bioinformatics-and-Computational-Biology	OCT 12-15, 2011	Brazilian Assoc Bioinformat & Computat Biol	Florianopolis, BRAZIL	0	0	0	0	0	1471-2164		WOS:000310699900001	
J	Nappi, Michele; Wechsler, Harry								Robust re-identification using randomness and statistical learning: Quo vadis								PATTERN RECOGNITION LETTERS			33	14	SI		1820	1827		10.1016/j.patrec.2012.02.005			OCT 15 2012	2012	The re-identification problem is to match objects across multiple but possibly disjoint fields of view for the purpose of sequential authentication over space and time. Detection and seeding for initialization do not presume known identity and allow for re-identification of objects and/or faces whose identity might remain unknown. Specific functionalities involved in re-identification include clustering and selection, recognition-by-parts, anomaly and change detection, sampling and tracking, fast indexing and search, sensitivity analysis, and their integration for the purpose of identity management. As re-identification processes data streams and involves change detection and on-line adaptation three complementary statistical learning frameworks, driven by randomness for the purpose of robust prediction, are advanced here to support the functionalities listed earlier and their combination thereof. The intertwined learning frameworks employed are those of (a) semi-supervised learning (SSL); (b) transduction; and (c) conformal prediction. The overall architecture proposed is data-driven and modular, on one side, and discriminative and progressive, on the other side. The architecture is built around autonomic computing and W5+. Autonomic computing or self-management provides for closed-loop control. W5+ answers questions related to What data to consider for sampling and collection, When to capture the data and from Where, and How to best process the data. The Who (is) query is about identity for biometrics, and the Why question for explanation purposes. The challenge addressed throughout is that of evidence-based management to progressively collect and add value to data in order to generate knowledge that leads to purposeful and gainful action including active learning for the overall purpose of re-identification. A venue for future research includes adversarial learning when re-identification is possibly "distracted" using deliberate corrupt information. (c) 2012 Elsevier B.V. All rights reserved.								0	0	0	0	0	0167-8655		WOS:000309085100002	
J	Adankon, Mathias M.; Dansereau, Jean; Labelle, Hubert; Cheriet, Farida								Non invasive classification system of scoliosis curve types using least-squares support vector machines								ARTIFICIAL INTELLIGENCE IN MEDICINE			56	2			99	107		10.1016/j.artmed.2012.07.002			OCT 2012	2012	Objective: To determine scoliosis curve types using non invasive surface acquisition, without prior knowledge from X-ray data.Methods: Classification of scoliosis deformities according to curve type is used in the clinical management of scoliotic patients. In this work, we propose a robust system that can determine the scoliosis curve type from non invasive acquisition of the 3D back surface of the patients. The 3D image of the surface of the trunk is divided into patches and local geometric descriptors characterizing the back surface are computed from each patch and constitute the features. We reduce the dimensionality by using principal component analysis and retain 53 components using an overlap criterion combined with the total variance in the observed variables. In this work, a multi-class classifier is built with least-squares support vector machines (LS-SVM). The original LS-SVM formulation was modified by weighting the positive and negative samples differently and a new kernel was designed in order to achieve a robust classifier. The proposed system is validated using data from 165 patients with different scoliosis curve types. The results of our non invasive classification were compared with those obtained by an expert using X-ray images.Results: The average rate of successful classification was computed using a leave-one-out cross-validation procedure. The overall accuracy of the system was 95%. As for the correct classification rates per class, we obtained 96%, 84% and 97% for the thoracic, double major and lumbar/thoracolumbar curve types, respectively.Conclusion: This study shows that it is possible to find a relationship between the internal deformity and the back surface deformity in scoliosis with machine learning methods. The proposed system uses non invasive surface acquisition, which is safe for the patient as it involves no radiation. Also, the design of a specific kernel improved classification performance. (C) 2012 Elsevier B.V. All rights reserved.								0	0	0	0	0	0933-3657		WOS:000311766300003	
J	Boubezoul, Abderrahmane; Paris, Sebastien								Application of global optimization methods to model and feature selection								PATTERN RECOGNITION			45	10			3676	3686		10.1016/j.patcog.2012.04.015			OCT 2012	2012	Many data mining applications involve the task of building a model for predictive classification. The goal of this model is to classify data instances into classes or categories of the same type. The use of variables not related to the classes can reduce the accuracy and reliability of classification or prediction model. Superfluous variables can also increase the costs of building a model particularly on large datasets. The feature selection and hyper-parameters optimization problem can be solved by either an exhaustive search over all parameter values or an optimization procedure that explores only a finite subset of the possible values. The objective of this research is to simultaneously optimize the hyper-parameters and feature subset without degrading the generalization performances of the induction algorithm. We present a global optimization approach based on the use of Cross-Entropy Method to solve this kind of problem. (C) 2012 Elsevier Ltd. All rights reserved.								0	0	0	0	0	0031-3203		WOS:000305845300009	
J	Chen, Eli; Haik, Oren; Yitzhaky, Yitzhak				YITZHAKY, YITZHAK/F-1446-2012				Classification of moving objects in atmospherically degraded video								OPTICAL ENGINEERING			51	10					101710	10.1117/1.OE.51.10.101710			OCT 2012	2012	Classification of moving objects in imaging through long-distance atmospheric path may be affected by distortions such as blur and spatiotemporal movements caused by air turbulence. This work aims to study and quantify the effects of these distortions on the ability to classify moving objects in atmospherically degraded video signals. For this purpose, we perform simulations and examine real long-range thermal video cases. In the simulation, we evaluate various geometrical (shape-based) object features for classification at different distortion levels. Furthermore, we examine the influence of image restoration on the classification performances in the real-degraded videos, using geometrical and textural features (combined and in separate) of the objects. Principal component analysis together with both k-nearest neighbor and support vector machines is used for the classification process. Results show how classification performances decrease as the level of blur increases, and how successful digital image restoration for real cases can significantly improve the classification performances. (C) 2012 Society of Photo-Optical Instrumentation Engineers (SPIE). [DOI: 10.1117/1.OE.51.10.101710]								0	0	0	0	0	0091-3286		WOS:000309915400011	
J	Derrac, Joaquin; Triguero, Isaac; Garcia, Salvador; Herrera, Francisco				Herrera, Francisco/C-6856-2008	Herrera, Francisco/0000-0002-7283-312X			Integrating Instance Selection, Instance Weighting, and Feature Weighting for Nearest Neighbor Classifiers by Coevolutionary Algorithms								IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			42	5			1383	1397		10.1109/TSMCB.2012.2191953			OCT 2012	2012	Cooperative coevolution is a successful trend of evolutionary computation which allows us to define partitions of the domain of a given problem, or to integrate several related techniques into one, by the use of evolutionary algorithms. It is possible to apply it to the development of advanced classification methods, which integrate several machine learning techniques into a single proposal. A novel approach integrating instance selection, instance weighting, and feature weighting into the framework of a coevolutionary model is presented in this paper. We compare it with a wide range of evolutionary and nonevolutionary related methods, in order to show the benefits of the employment of coevolution to apply the techniques considered simultaneously. The results obtained, contrasted through nonparametric statistical tests, show that our proposal outperforms other methods in the comparison, thus becoming a suitable tool in the task of enhancing the nearest neighbor classifier.								0	0	0	0	0	1083-4419		WOS:000308995500007	
J	Hamidzadeh, Javad; Monsefi, Reza; Yazdi, Hadi Sadoghi								DDC: distance-based decision classifier								NEURAL COMPUTING & APPLICATIONS			21	7			1697	1707		10.1007/s00521-011-0762-8			OCT 2012	2012	This paper presents a new classification method utilizing distance-based decision surface with nearest neighbor projection approach, called DDC. Kernel type of DDC has been extended to take into account the effective nonlinear structure of the data. DDC has some properties: (1) does not need conventional learning procedure (as k-NN algorithm), (2) does not need searching time to locate the k-nearest neighbors, and (3) does not need optimization process unlike some classification methods such as Support Vector Machine (SVM). In DDC, we compute the weighted average of distances to all the training samples. Unclassified sample will be classified as belonging to a class that has the minimum obtained distance. As a result, by such a rule we can derive a formula that can be used as the decision surface. DDC is tested on both synthetic and real-world data sets from the UCI repository, and the results were compared with k-NN, RBF Network, and SVM. The experimental results indicate DDC outperforms k-NN in the most experiments and the results are comparable to or better than SVM with some data sets.								0	0	0	0	0	0941-0643		WOS:000308825000019	
J	Mirowski, Piotr; LeCun, Yann								Statistical Machine Learning and Dissolved Gas Analysis: A Review								IEEE TRANSACTIONS ON POWER DELIVERY			27	4			1791	1799		10.1109/TPWRD.2012.2197868			OCT 2012	2012	Dissolved gas analysis (DGA) of the insulation oil of power transformers is an investigative tool to monitor their health and to detect impending failures by recognizing anomalous patterns of DGA concentrations. We handle the failure prediction problem as a simple data-mining task on DGA samples, optionally exploiting the transformer's age, nominal power and voltage, and consider two approaches: 1) binary classification and 2) regression of the time to failure. We propose a simple logarithmic transform to preprocess DGA data in order to deal with long-tail distributions of concentrations. We have reviewed and evaluated 15 standard statistical machine-learning algorithms on that task, and reported quantitative results on a small but published set of power transformers and on proprietary data from thousands of network transformers of a utility company. Our results confirm that nonlinear decision functions, such as neural networks, support vector machines with Gaussian kernels, or local linear regression can theoretically provide slightly better performance than linear classifiers or regressors. Software and part of the data are available at http://www.mirowski.info/pub/dga.								0	0	0	0	0	0885-8977		WOS:000309200900011	
J	Rozza, Alessandro; Lombardi, Gabriele; Casiraghi, Elena; Campadelli, Paola								Novel Fisher discriminant classifiers								PATTERN RECOGNITION			45	10			3725	3737		10.1016/j.patcog.2012.03.021			OCT 2012	2012	At the present, several applications need to classify high dimensional points belonging to highly unbalanced classes. Unfortunately, when the training set cardinality is small compared to the data dimensionality ("small sample size" problem) the classification performance of several well-known classifiers strongly decreases. Similarly, the classification accuracy of several discriminative methods decreases when non-linearly separable, and unbalanced, classes are treated. In this paper we firstly survey state of the art methods that employ improved versions of Linear Discriminant Analysis (LDA) to deal with the above mentioned problems; secondly, we propose a family of classifiers based on the Fisher subspace estimation, which efficiently deal with the small sample size problem, non-linearly separable classes, and unbalanced classes. The promising results obtained by the proposed techniques on benchmark datasets and the comparison with state of the art predictors show the efficacy of the proposed techniques. (C) 2012 Elsevier Ltd. All rights reserved.								0	0	0	0	0	0031-3203		WOS:000305845300014	
J	Samworth, Richard J.								OPTIMAL WEIGHTED NEAREST NEIGHBOUR CLASSIFIERS								ANNALS OF STATISTICS			40	5			2733	2763		10.1214/12-AOS1049			OCT 2012	2012	We derive an asymptotic expansion for the excess risk (regret) of a weighted nearest-neighbour classifier. This allows us to find the asymptotically optimal vector of nonnegative weights, which has a rather simple form. We show that the ratio of the regret of this classifier to that of an unweighted k-nearest neighbour classifier depends asymptotically only on the dimension d of the feature vectors, and not on the underlying populations. The improvement is greatest when d = 4, but thereafter decreases as d -> infinity. The popular bagged nearest neighbour classifier can also be regarded as a weighted nearest neighbour classifier, and we show that its corresponding weights are somewhat suboptimal when d is small (in particular, worse than those of the unweighted k-nearest neighbour classifier when d = 1), but are close to optimal when d is large. Finally, we argue that improvements in the rate of convergence are possible under stronger smoothness assumptions, provided we allow negative weights. Our findings are supported by an empirical performance comparison on both simulated and real data sets.								0	0	0	0	0	0090-5364		WOS:000321844300013	
J	Zhang, Nan; Yang, Jian; Qian, Jian-jun								Component-based global k-NN classifier for small sample size problems								PATTERN RECOGNITION LETTERS			33	13			1689	1694		10.1016/j.patrec.2012.05.020			OCT 1 2012	2012	The classical k-NN classifier has been widely used in pattern recognition. However, it does not take into account the structural information of local samples. This paper presents a novel classifier named component-based global k-NN classifier (CG-k-NN), which takes advantage of the structural information of the local neighbors for enhancing the classification performance. We choose k nearest neighbors of a given testing sample globally at first, and then use these neighbors to represent the testing sample via ridge regression. In the further step, we construct the component image of each class by using the intra-class images from the k nearest neighbors and the corresponding representation coefficients. Finally, the testing sample is assigned to the class that minimizes reconstruction residual. The proposed method CG-k-NN is evaluated using the ORL, FERET, AR face image database and PolyU palmprint databases. The experiment results demonstrate that our method is more efficient and effective than the state-of-the-art methods such as sparse representation based classifier (SRC) and linear regression based classifier (LRC). (c) 2012 Elsevier B.V. All rights reserved.								0	0	0	0	0	0167-8655		WOS:000308385800003	
J	An, Fengwei; Koide, Tetsushi; Mattausch, Hans Juergen								A K-Means-Based Multi-Prototype High-Speed Learning System with FPGA-Implemented Coprocessor for 1-NN Searching								IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS			E95D	9			2327	2338		10.1587/transinf.E95.D.2327			SEP 2012	2012	In this paper. we propose a hardware solution for overcoming the problem of high computational demands in a nearest neighbor (NN) based multi-prototype learning system. The multiple prototypes are obtained by a high-speed K-means clustering algorithm utilizing a concept of software-hardware cooperation that takes advantage of the flexibility of the software and the efficiency of the hardware. The one nearest neighbor (1-NN) classifier is used to recognize an object by searching for the nearest Euclidean distance among the prototypes. The major deficiency in conventional implementations for both K-means and 1-NN is the high computational demand of the nearest neighbor searching. This deficiency is resolved by an FPGA-implemented coprocessor that is a VLSI circuit for searching the nearest Euclidean distance. The coprocessor requires 12.9% logic elements and 58% block memory bits of an Altera Stratix III E110 FPGA device. The hardware communicates with the software by a PCI Express (x4) local-bus-compatible interface. We benchmark our learning system against the popular case of handwritten digit recognition in which abundant previous works for comparison are available. In the case of the MNIST database, we could attain the most efficient accuracy rate of 97.91% with 930 prototypes, the learning speed of 1.3 x 10(-4) s/sample and the classification speed of 3.94 x 10(-8) s/character.								0	0	0	0	0	0916-8532		WOS:000309043000019	
J	James, Alex Pappachen; Dimitrijev, Sima				Griffith University, QMNC/I-5498-2013				Nearest Neighbor Classifier Based on Nearest Feature Decisions								COMPUTER JOURNAL			55	9			1072	1087		10.1093/comjnl/bxs001			SEP 2012	2012	High feature dimensionality of realistic datasets adversely affects the recognition accuracy of nearest neighbor (NN) classifiers. To address this issue, we introduce a nearest feature classifier that shifts the NN concept from the global-decision level to the level of individual features. Performance comparisons with 12 instance-based classifiers on 13 benchmark University of California Irvine classification datasets show average improvements of 6 and 3.5% in recognition accuracy and area under curve performance measures, respectively. The statistical significance of the observed performance improvements is verified by the Friedman test and by the post hoc Bonferroni-Dunn test. In addition, the application of the classifier is demonstrated on face recognition databases, a character recognition database and medical diagnosis problems for binary and multi-class diagnosis on databases including morphological and gene expression features.								0	0	0	0	0	0010-4620		WOS:000308233900005	
J	Joshi, Vinayak S.; Maude, Richard J.; Reinhardt, Joseph M.; Tang, Li; Garvin, Mona K.; Abu Sayeed, Abdullah; Ghose, Aniruddha; Hassan, Mahtab Uddin; Abramoff, Michael D.								Automated Detection of Malarial Retinopathy-Associated Retinal Hemorrhages								INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE			53	10			6582	6588		10.1167/iovs.12-10191			SEP 2012	2012	PURPOSE. To develop an automated method for the detection of retinal hemorrhages on color fundus images to characterize malarial retinopathy, which may help in the assessment of patients with cerebral malaria.METHODS. A fundus image dataset from 14 patients (200 fundus images, with an average of 14 images per patient) previously diagnosed with malarial retinopathy was examined. We developed a pattern recognition-based algorithm, which extracted features from image watershed regions called splats (tobogganing). A reference standard was obtained by manual segmentation of hemorrhages, which assigned a label to each splat. The splat features with the associated splat label were used to train a linear k-nearest neighbor classifier that learnt the color properties of hemorrhages and identified the splats belonging to hemorrhages in a test dataset. In a crossover design experiment, data from 12 patients were used for training and data from two patients were used for testing, with 14 different permutations; and the derived sensitivity and specificity values were averaged.RESULTS. The experiment resulted in hemorrhage detection sensitivities in terms of splats as 80.83%, and in terms of lesions as 84.84%. The splat-based specificity was 96.67%, whereas for the lesion-based analysis, an average of three false positives was obtained per image. The area under the receiver operating characteristic curve was reported as 0.9148 for splat-based, and as 0.9030 for lesion-based analysis.CONCLUSIONS. The method provides an automated means of detecting retinal hemorrhages associated with malarial retinopathy. The results matched well with the reference standard. With further development, this technique may provide automated assistance for screening and quantification of malarial retinopathy. (Invest Ophthalmol Vis Sci. 2012; 53:6582-6588) DOI:10.1167/iovs.12-10191								0	0	0	0	0	0146-0404		WOS:000309526200076	
J	Lazaro-Gredilla, Miguel; Gomez-Verdejo, Vanessa; Parrado-Hernandez, Emilio								Low-cost model selection for SVMs using local features								ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE			25	6			1203	1211		10.1016/j.engappai.2012.05.021			SEP 2012	2012	Many practical engineering applications require the usage of accurate automatic decision systems, usually operating under tight computational constraints. Support Vector Machines (SVMs) endowed with a Radial Basis Function (RBF) as kernel are broadly accepted as the current state of the art for decision problems, but require cross-validation to select the free parameters, which is computationally costly. In this work we investigate low-cost methods to select the spread parameter in SVMs with an RBF kernel. Our proposal relies on the use of simple local methods that gather information about the local structure of each dataset. Empirical results in UCI datasets show that the proposed methods can be used as a fast alternative to the standard cross-validation procedure, with the additional advantage of avoiding the (often heuristic) task of a priori fixing the values of the spread parameter to be explored. (C) 2012 Elsevier Ltd. All rights reserved.								0	0	0	0	0	0952-1976		WOS:000308122700010	
J	Liao, Bo; Li, Xiong; Zhu, Wen; Cao, Zhi								A Novel Method to Select Informative SNPs and Their Application in Genetic Association Studies								IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS			9	5			1529	1534		10.1109/TCBB.2012.70			SEP-OCT 2012	2012	The association studies between complex diseases and single nucleotide polymorphisms (SNPs) or haplotypes have recently received great attention. However, these studies are limited by the cost of genotyping all SNPs. Therefore, it is essential to find a small subset of tag SNPs representing the rest of the SNPs. The presence of linkage disequilibrium between tag SNPs and the disease variant (genotyped or not), may allow fine mapping study. In this paper, we combine a nearest-means classifier (NMC) and ant colony algorithm to select tags. Results show that our method (ACO/NMC) can get a similar prediction accuracy with method BPSO/SVM and is better than BPSO/STAMPA for small data sets. For large data sets, although the prediction accuracy of our method is lower than BPSO/SVM, ACO/NMC can reach a high accuracy (>99 percent) in a relatively short time. when the number of tags increases, the time complexity of NMC is nearly linear growth. To find out that the ability of tags to locate disease locus, we simulate a case-control study and use two-locus haplotype analysis to quantitatively assess the power. The result showed that 20 percent of all SNPs selected by NMC have about 10 percent higher power than random tags, on average.								0	0	0	0	0	1545-5963		WOS:000307299200027	
J	Lin, Jun-Feng; Liaw, Yi-Ching; Chan, Kwan-Yee; Wu, Song-Chan								Fast exact local-mean based classification algorithm using class rejection and initial distance assigning processes								PATTERN RECOGNITION LETTERS			33	12			1507	1512		10.1016/j.patrec.2012.04.013			SEP 1 2012	2012	The local-mean based classification (LMC) algorithm is an effective classification method. It can reduce the influence of outliers and can achieve better result than most classification algorithms. To classify a test sample with unknown class using the LMC algorithm is very time consuming. To overcome this problem, this paper presents a fast exact LMC method to reduce the computation time of the LMC algorithm using a class rejection process. When the proposed method cooperates with fast nearest k neighbors finding algorithms, an initial distance assigning process is also applied to improve the performance of rejecting impossible samples. Experimental results show that the proposed method can effectively reduce the computation time of the LMC method and can improve the capability of rejecting impossible samples when a fast kNN search method is applied to the LMC algorithm. (C) 2012 Elsevier B.V. All rights reserved.								0	0	0	0	0	0167-8655		WOS:000307134100001	
J	Sugaya, Yoshihiro; Omachi, Shinichiro; Takeuchi, Akira; Nozaki, Yousuke								A Statistical Analysis on Operation Scheduling for an Energy Network Project								IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS			23	9	SI		1583	1592		10.1109/TPDS.2012.52			SEP 2012	2012	Distributed power generation, using renewable energy, has been attracting attention to cope with global environment issues; a microgrid is a promising configuration for distributed power generation. To augment the stability and efficiency of the microgrid, an intelligent control, which considers the restrictions and characteristics of each unit, is indispensable. It can be achieved by constructing an efficient operation schedule for each power plant in the microgrid, depending on energy demand, and predicting passive power generation. The operation scheduling is regarded as a constrained optimization problem, which must have nonlinear characteristics in case of actual systems. Although several methods using metaheuristic optimization have been proposed, it would be trapped into a local minimum in some cases. In this paper, we statistically analyze operation schedules, computed for an actual power network of the demonstrative project. In addition, we conduct an investigation of the relationship between the input parameter space and the solution space, which can be exploited to obtain more appropriate initial solutions leading to better and faster converging solutions.								0	0	0	0	0	1045-9219		WOS:000306807200003	
J	Zhu, Chun; Sheng, Weihua								Realtime Recognition of Complex Human Daily Activities Using Human Motion and Location Data								IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING			59	9			2422	2430		10.1109/TBME.2012.2190602			SEP 2012	2012	Daily activity recognition is very useful in robot-assisted living systems. In this paper, we proposed a method to recognize complex human daily activities which consist of simultaneous body activities and hand gestures in an indoor environment. A wireless power-aware motion sensor node is developed which consists of a commercial orientation sensor, a wireless communication module, and a power management unit. To recognize complex daily activities, three motion sensor nodes are attached to the right thigh, the waist, and the right hand of a human subject, while an optical motion capture system is used to obtain his/her location information. A three-level dynamic Bayesian network (DBN) is implemented to model the intratemporal and intertemporal constraints among the location, body activity, and hand gesture. The body activity and hand gesture are estimated using a Bayesian filter and a short-time Viterbi algorithm, which reduces the computational complexity and memory usage. We conducted experiments in a mock apartment environment and the obtained results showed the effectiveness and accuracy of our method.								0	0	0	0	0	0018-9294		WOS:000307895000005	
J	Feng, Q.; Pan, J. S.; Yan, L.								Nearest feature centre classifier for face recognition								ELECTRONICS LETTERS			48	18			1120	U1122		10.1049/el.2012.2080			AUG 30 2012	2012	A novel classifier based on feature line, called the nearest feature centre (NFC) classifier, is proposed for face recognition. NFC uses the new metric, called the feature centre metric, which is different from the classical feature line metric of the nearest feature line (NFL). The experimental results on the ORL face database show that NFC outperforms NFL and the other classifiers based on feature line.								0	0	0	0	0	0013-5194		WOS:000308552200022	
J	Gelman, L.; Petrunin, I.								Novel anomaly detection technique based on the nearest neighbour and sequential methods								INSIGHT			54	8			433	435		10.1784/insi.2012.54.8.433			AUG 2012	2012	A novel anomaly detection technique based on the nearest neighbour method and the sequential majority method is proposed, developed and validated for damage diagnosis and pattern recognition.								0	0	0	0	0	1354-2575		WOS:000308388900003	
J	Jagannathan, Rupa; Petrovic, Sanja; Mckenna, Angela; Newton, Louise								A NOVEL TWO PHASE RETRIEVAL MECHANISM FOR A CLINICAL CASE BASED REASONING SYSTEM FOR RADIOTHERAPY TREATMENT PLANNING								INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS			21	4	SI				1240017	10.1142/S0218213012400179			AUG 2012	2012	This paper presents a decision support system for radiotherapy treatment planning for head, neck and brain cancer. The aim of a treatment plan is to apply radiation to kill tumor cells, while minimizing the damage to healthy tissue and critical organs. Since treatment planning is a complex decision-making process that relies heavily on the subjective experience of clinicians, we propose the use of case-based reasoning (CBR), in which problems are solved based on the solutions of similar past problems. This paper focuses on the case retrieval process of a CBR system. The attributes, which describe the cases, are selected by assessing their effect on the performance of the CBR system. We have developed a context sensitive local weighting scheme that assigns weights to attributes based on their value and the values of other attributes in the target case. A novel two phase retrieval mechanism is developed, in which each phase is optimized to retrieve a particular part of the solution. We also present an original use of fuzzy logic in order to represent nonlinearity in the similarity measure. Experiments, which evaluate the similarity measure using real brain cancer patient cases, show promising results.								0	0	0	0	0	0218-2130		WOS:000308105000004	
J	LeDell, Erin; Prabhat; Zubarev, Dmitry Yu.; Austin, Brian; Lester, William A., Jr.								Classification of nodal pockets in many-electron wave functions via machine learning								JOURNAL OF MATHEMATICAL CHEMISTRY			50	7			2043	2050		10.1007/s10910-012-0019-5			AUG 2012	2012	Accurate treatment of electron correlation in quantum chemistry requires solving the many-electron problem. If the nodal surface of amany-electron wave function is available even in an approximate form, the fixed-node diffusion Monte Carlo (FNDMC) approach from the family of quantum Monte Carlo methods can be successfully used for this purpose. The issue of description and classification of nodal surfaces of fermionic wave functions becomes central for understanding the basic properties of many-electron wave functions and for the control of accuracy and computational efficiency of FNDMC computations. In this work, we approach the problem of automatic classification of nodal pockets of many-electron wave functions. We formulate this problem as that of binary classification and apply a number of techniques from the machine learning literature. We apply these techniques on a range of atoms of light elements and demonstrate varying degrees of success. We observe that classifiers with relatively simple geometry perform poorly on the classification task; methods based on a random collection of tree-based classifiers appear to perform best. We conclude with thoughts on computational challenges and complexity associated with applying these techniques to heavier atoms.								0	0	0	0	0	0259-9791		WOS:000307266900019	
J	Lee, Wan-Jui; Cheplygina, Veronika; Tax, David M. J.; Loog, Marco; Duin, Robert P. W.								BRIDGING STRUCTURE AND FEATURE REPRESENTATIONS IN GRAPH MATCHING								INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			26	5	SI				1260005	10.1142/S0218001412600051			AUG 2012	2012	Structures and features are opposite approaches in building representations for object recognition. Bridging the two is an essential problem in pattern recognition as the two opposite types of information are fundamentally different. As dissimilarities can be computed for both the dissimilarity representation can be used to combine the two. Attributed graphs contain structural as well as feature-based information. Neglecting the attributes yields a pure structural description. Isolating the features and neglecting the structure represents objects by a bag of features. In this paper we will show that weighted combinations of dissimilarities may perform better than these two extremes, indicating that these two types of information are essentially different and strengthen each other. In addition we present two more advanced integrations than weighted combining and show that these may improve the classification performances even further.								0	0	0	0	0	0218-0014		WOS:000314402300005	
J	Li, Hui; Sun, Jie; Wu, Jian; Wu, Xian-Jun				Li, Hui/G-6408-2011				Supply chain trust diagnosis (SCTD) using inductive case-based reasoning ensemble (ICBRE): The case of general competence trust diagnosis								APPLIED SOFT COMPUTING			12	8			2312	2321		10.1016/j.asoc.2012.03.029			AUG 2012	2012	General competence trust among supply chain partners, referring to the trust that a partner holds the general ability of fulfilling contracts, is a critical factor to ensure effective cooperation in a supply chain, especially in the current financial crisis. The method of supply chain trust diagnosis (SCTD) is to evaluate whether or not a partner holds such competence. This research devotes to an early investigation on diagnosing competence trust of supply chain with the method of inductive case-based reasoning ensemble (ICBRE). The so-called supply chain trust diagnosis with inductive case-based reasoning ensemble consists of five levels, that is, information level, the level of ratios of general competence states, the level of inductive case-based reasoning, ensemble level, and diagnosis result level. Knowledge for diagnosing competence trust, which composes of a case base, is hidden in data represented by ratios of general competence states. Inductive approach is combined with randomness to construct diverse and good member methods of inductive case-based reasoning. Finally, simple voting is used to integrate outputs of member inductive case-based reasoning methods in order to produce the final diagnosis on whether or not a partner holds the general ability of fulfilling contracts. We statistically validated results of the method of supply chain trust diagnosis with inductive case-based reasoning ensemble by comparing them with those of multivariate discriminant analysis, logistic regression, single Euclidean case-based reasoning, and single inductive case-based reasoning. The results indicate that the method of supply chain trust diagnosis with inductive case-based reasoning ensemble significantly improves predictive capability of case-based reasoning in this problem and outperforms all the comparative models by group decision of several decision-making agents and non-strict assumptions like statistical methods. (C) 2012 Elsevier B. V. All rights reserved.								0	0	0	0	0	1568-4946		WOS:000305275800035	
J	Savchenko, A. V.								Directed enumeration method in image recognition								PATTERN RECOGNITION			45	8			2952	2961		10.1016/j.patcog.2012.02.011			AUG 2012	2012	The article is devoted to the problem of image recognition in real-time applications with a large database containing hundreds of classes. The directed enumeration method as an alternative to exhaustive search is examined. This method has two advantages. First, it could be applied with measures of similarity which do not satisfy metric properties (chi-square distance, Kullback-Leibler information discrimination, etc.). Second, the directed enumeration method increases recognition speed even in the most difficult cases which seem to be very important in practical terms. In these cases many neighbors are located at very similar distances. In this paper we present the results of an experimental study of the directed enumeration method with comparison of color- and gradient-orientation histograms in solving the problem of face recognition with well-known datasets (Essex, FERET). It is shown that the proposed method is characterized by increased computing efficiency of automatic image recognition (3-12 times in comparison with a conventional nearest neighbor classifier). (C) 2012 Elsevier Ltd. All rights reserved.								0	0	0	0	0	0031-3203		WOS:000303294500008	
J	Wei, Shuning; Wang, Yaonan; Tang, Yong								KNN-Q(lambda) algorithm-based line-grasping control of a de-icing robot								PROCEEDINGS OF THE INSTITUTION OF MECHANICAL ENGINEERS PART I-JOURNAL OF SYSTEMS AND CONTROL ENGINEERING			226	I7			936	946		10.1177/0959651812444240			AUG 2012	2012	Flexible mechanical characteristics of power lines and the complex environment induce difficulties for line-grasping control of a de-icing robot when crossing obstacles. An online learning supported line-grasping control method for a de-icing robot based on the KNN-Q(lambda) algorithm is presented in this paper. The proposed KNN-Q(lambda) algorithm combines reinforcement learning with the k-nearest neighbor algorithm to perceive continuous states and uses a collective decision making mechanism in the action selection process to output continuous actions. Benefiting from the ability of online learning, the KNN-Q(lambda)-based line-grasping control method may tolerate possible robot model errors, robot arm attitude errors and environment interferences to line-grasping control. Simulation experiment results show that as a continuous-states-continuous-actions reinforcement learning algorithm, the KNN-Q(lambda) algorithm outperforms traditional reinforcement learning algorithms for the application of line-grasping control in terms of leaning rate and robustness.								0	0	0	0	0	0959-6518		WOS:000309208800008	
J	Wei, Wei; Du, Qian; Younan, Nicolas H.								Optimized Spectral Transformation for Detection and Classification of Buried Radioactive Materials					3			IEEE TRANSACTIONS ON NUCLEAR SCIENCE			59	4			1702	1710		10.1109/TNS.2012.2202919			AUG 2012	2012	We investigate the detection and classification of buried radioactive materials of interest using data collected by a sodium iodide (NaI) detector with a short sensor dwell time (i.e., less than or equal to 1 s). The objective of detection is to detect a target from background and nontarget materials, while the objective of classification is to classify targets buried at different depths. Binned energy windows can reduce data dimensionality, help alleviate the negative impact from background, and suppress trivial spectral variations. However, the performance is sensitive to bin partition parameters including the number of bins and their bin widths. We have developed a particle swarm optimization (PSO)-based automatic system to determine these parameters. We also propose to apply a multiobjective PSO to optimize both the detection and classification accuracy simultaneously. The experimental results show that the PSO-based algorithm can outperform the Powell's direction set optimization method. The multiobjective PSO can achieve the balance between the two objectives, and it may provide even better individual accuracy than a single-objective PSO.								0	0	0	0	0	0018-9499		WOS:000307893900029	
J	Seo, Minseok; Oh, Sejong								CBFS: High Performance Feature Selection Algorithm Based on Feature Clearness								PLOS ONE			7	7					e40419	10.1371/journal.pone.0040419			JUL 6 2012	2012	Background: The goal of feature selection is to select useful features and simultaneously exclude garbage features from a given dataset for classification purposes. This is expected to bring reduction of processing time and improvement of classification accuracy.Methodology: In this study, we devised a new feature selection algorithm (CBFS) based on clearness of features. Feature clearness expresses separability among classes in a feature. Highly clear features contribute towards obtaining high classification accuracy. CScore is a measure to score clearness of each feature and is based on clustered samples to centroid of classes in a feature. We also suggest combining CBFS and other algorithms to improve classification accuracy.Conclusions/Significance: From the experiment we confirm that CBFS is more excellent than up-to-date feature selection algorithms including FeaLect. CBFS can be applied to microarray gene selection, text categorization, and image classification.								0	0	0	0	0	1932-6203		WOS:000306461800079	
J	Chen, Yi; Yin, Jun; Zhu, Jie; Jin, Zhong								Dimensionality reduction via locally reconstructive patch alignment								OPTICAL ENGINEERING			51	7					077208	10.1117/1.OE.51.7.077208			JUL 2012	2012	Based on the local patch concept, we proposed locally reconstructive patch alignment (LRPA) for dimensionality reduction. For each patch, LRPA aims to find the low-dimensional subspace in which the reconstruction error of the within-class nearest neighbors is minimized and the reconstruction error of the between-class nearest neighbors is maximized. LRPA preserves the local structure hidden in the high-dimensional space. More importantly, LRPA has natural connections with linear regression classification (LRC). While LRC uses reconstruction errors as the classification rule, a sample can be classified correctly when the within-class reconstruction error is minimal. The goal of LRPA makes it cooperate well with LRC. The experimental results on the extended Yale B (YALE-B), AR, PolyU finger knuckle print, and the palm print databases demonstrate LRPA plus LRC is an effective and robust pattern-recognition system. (C) 2012 Society of Photo-Optical Instrumentation Engineers (SPIE). [DOI: 10.1117/1.OE.51.7.077208]								0	0	0	0	0	0091-3286		WOS:000308361200068	
J	de Souza Moraes, Luiz Eduardo; Gherardi, Douglas Francisco Marcolino; Katsuragawa, Mario; Paes, Eduardo Tavares								Brazilian sardine (Sardinella brasiliensis Steindachner, 1879) spawning and nursery habitats: spatial-scale partitioning and multiscale relationships with thermohaline descriptors								ICES JOURNAL OF MARINE SCIENCE			69	6			939	952		10.1093/icesjms/fss061			JUL 2012	2012	We provide a detailed account of the spatial structure of the Brazilian sardine (Sardinella brasiliensis) spawning and nursery habitats, using ichthyoplankton data from nine surveys (1976-1993) covering the Southeastern Brazilian Bight (SBB). The spatial variability of sardine eggs and larvae was partitioned into predefined spatial-scale classes (broad scale, 200-500 km; medium scale, 50-100 km; and local scale, <50 km). The relationship between density distributions at both developmental stages and environmental descriptors (temperature and salinity) was also explored within these spatial scales. Spatial distributions of sardine eggs were mostly structured on medium and local scales, while larvae were characterized by broad-and medium-scale distributions. Broad-and medium-scale surface temperatures were positively correlated with sardine densities, for both developmental stages. Correlations with salinity were predominantly negative and concentrated on a medium scale. Broad-scale structuring might be explained by mesoscale processes, such as pulsing upwelling events and Brazil Current meandering at the northern portion of the SBB, while medium-scale relationships may be associated with local estuarine outflows. The results indicate that processes favouring vertical stability might regulate the spatial extensions of suitable spawning and nursery habitats for the Brazilian sardine.								0	0	0	0	0	1054-3139		WOS:000305461200002	
J	Yang, Jieming; Liu, Yuanning; Zhu, Xiaodong; Liu, Zhen; Zhang, Xiaoxu								A new feature selection based on comprehensive measurement both in inter-category and intra-category for text categorization								INFORMATION PROCESSING & MANAGEMENT			48	4			741	754		10.1016/j.ipm.2011.12.005			JUL 2012	2012	The feature selection, which can reduce the dimensionality of vector space without sacrificing the performance of the classifier, is widely used in text categorization. In this paper, we proposed a new feature selection algorithm, named CMFS, which comprehensively measures the significance of a term both in inter-category and intra-category. We evaluated CMFS on three benchmark document collections, 20-Newsgroups. Reuters-21578 and WebKB, using two classification algorithms, Naive Bayes (NB) and Support Vector Machines (SVMs). The experimental results, comparing CMFS with six well-known feature selection algorithms, show that the proposed method CMFS is significantly superior to Information Gain (IC), Chi statistic (CHI), Document Frequency (DF), Orthogonal Centroid Feature Selection (OCFS) and DIA association factor (DIA) when Nave Bayes classifier is used and significantly outperforms IC, DF, OCFS and DIA when Support Vector Machines are used. (C) 2011 Elsevier Ltd. All rights reserved.								0	0	0	0	0	0306-4573		WOS:000305170900009	
J	Cordoba, Mariano; Balzarini, Monica; Bruno, Cecilia; Luis Costa, Jose								Principal component analysis with georeferenced data An application in precision agriculture								REVISTA DE LA FACULTAD DE CIENCIAS AGRARIAS			44	1			27	39					JUN 2012	2012	New precision agriculture technologies allow collecting information from several variables at many georeferenced locations within crop fields. The spatial covariation of soil properties and crop yield data can be evaluated by principal component analysis (PCA). Nevertheless, PCA has not been explicitly developed for spatial data as other multivariate descriptive methods. Other multivariate techniques that include spatial autocorrelation among data of neighborhood sites have been recently developed. In this paper, we apply and compare two multivariate analyses, PCA and spatially constrained multivariate analysis methods (MULTISPATI-PCA). The latter incorporates the spatial information into multivariate analysis calculating Moran's index between the data at one location and the mean values of its neighbors. The results showed that MULTISPATI-PCA detected relations in the data that were not detected with PCA. The mapping of spatial variability from the first principal component was similar between PCA and MULTISPATI-PCA, but maps from the second component were different due to the variance correction by spatial autocorrelation. MULTISPATI-PCA method represents a crucial tool to map spatial variability within afield, and to identify homogeneous zones in a multivariate sense.								0	0	0	0	0	0370-4661		WOS:000307910100003	
J	Ghosh, Anil K.; Godtliebsen, Fred								On hybrid classification using model assisted posterior estimates								PATTERN RECOGNITION			45	6			2288	2298		10.1016/j.patcog.2011.12.002			JUN 2012	2012	Traditional parametric and nonparametric classifiers used for statistical pattern recognition have their own strengths and limitations. While parametric methods assume some specific parametric models for density functions or posterior probabilities of competing classes, nonparametric methods are free from such assumptions. So, when these model assumptions are correct, parametric methods outperform nonparametric classifiers, especially when the training sample is small. But, violations of these assumptions often lead to poor performance by parametric classifiers, where nonparametric methods work well. In this article, we make an attempt to overcome these limitations of parametric and nonparametric approaches and combine their strengths. The resulting classifiers, denoted the hybrid classifiers, perform like parametric classifiers when the model assumptions are valid, but unlike parametric classifiers, they also provide safeguards against possible deviations from parametric model assumptions. In this article, we propose some multiscale methods for hybrid classification, and their performance is evaluated using several simulated and benchmark data sets. (C) 2011 Elsevier Ltd. All rights reserved.								0	0	0	0	0	0031-3203		WOS:000301758400023	
J	Leite, Pedro; Teixeira, Joao Marcelo; Farias, Thiago; Reis, Bernardo; Teichrieb, Veronica; Kelner, Judith								Nearest Neighbor Searches on the GPU A Massively Parallel Approach for Dynamic Point Clouds								INTERNATIONAL JOURNAL OF PARALLEL PROGRAMMING			40	3	SI		313	330		10.1007/s10766-011-0184-3			JUN 2012	2012	We introduce a GPU grid-based data structure for massively parallel nearest neighbor searches for dynamic point clouds. The implementation provides real-time performance and it is executed on GPU, both grid construction and nearest neighbors (approximate or exact) searches. This minimizes the memory transfer between device and system memories, improving overall performance. The proposed algorithm may be used across different applications with static and dynamic scenarios. Moreover, our data structure supports three-dimensional point clouds and given its dynamic nature, the user can change the data structure's parameters at runtime. The same applies to the number of neighbors to be found. Performance comparisons were made against previous works, endorsing the benefits of our solution. Finally, we were able to develop a real-time Point-Based Rendering application for validation of the data structure. Its drawbacks and data distribution's impact on performance were analysed and some directions for further investigation are given.								0	0	0	0	0	0885-7458		WOS:000302286100004	
J	Lin, Aijing; Shang, Pengjian; Feng, Guochen; Zhong, Bo								APPLICATION OF EMPIRICAL MODE DECOMPOSITION COMBINED WITH k-NEAREST NEIGHBORS APPROACH IN FINANCIAL TIME SERIES FORECASTING								FLUCTUATION AND NOISE LETTERS			11	2					1250018	10.1142/S0219477512500186			JUN 2012	2012	The purpose of this paper is to forecast the daily closing prices of stock markets based on the past sequences. In this paper, keeping in mind the recent trends and the limitations of previous researches, we proposed a new technique, called empirical mode decomposition combined with k-nearest neighbors (EMD-KNN) method, in forecasting the stock index. EMD-KNN takes the advantages of the KNN and EMD. To demonstrate that our EMD-KNN method is robust, we used the new technique to forecast four stock index time series at a specific time. Detailed experiments are implemented for both of the proposed forecasting models, in which EMD-KNN, KNN method and ARIMA are compared. The results demonstrate that the proposed EMD-KNN model is more successful than KNN method and ARIMA in predicting the stock closing prices.								0	0	0	0	0	0219-4775		WOS:000307119100018	
J	Saraf, Santosh S.; Udupi, G. R.; Hajare, Santosh D.								Analysis of Endoscopy Video Using Machine Learning Techniques								JOURNAL OF MEDICAL IMAGING AND HEALTH INFORMATICS			2	2			97	101		10.1166/jmihi.2012.1070			JUN 2012	2012	Upper Gastro-Intestinal (GI) Endoscopy is used to observe the organs esophagus, stomach and duodenum. With the push endoscopy the video length is short with the quality of video dependent on the patient comfort compared to a fairly smooth video of Wireless Capsule Endoscopy (WCE). We present a method to identify organs using low level image features like color and texture using classifiers like Support Vector Machine, Neural Network etc. We report results comparable to that of WCE video. The scheme could be coupled with image based decision support systems for diagnosis of the respective organs.								0	0	0	0	0	2156-7018		WOS:000313219600001	
J	Tomasev, Nenad; Mladenic, Dunja								Nearest Neighbor Voting in High Dimensional Data: Learning from Past Occurrences								COMPUTER SCIENCE AND INFORMATION SYSTEMS			9	2			691	712		10.2298/CSIS111211014T			JUN 2012	2012	Hubness is a recently described aspect of the curse of dimensionality inherent to nearest-neighbor methods. This paper describes a new approach for exploiting the hubness phenomenon in k-nearest neighbor classification. We argue that some of the neighbor occurrences carry more information than others, by the virtue of being less frequent events. This observation is related to the hubness phenomenon and we explore how it affects high-dimensional k-nearest neighbor classification. We propose a new algorithm, Hubness Information k-Nearest Neighbor (HIKNN), which introduces the k-occurrence informativeness into the hubness-aware k-nearest neighbor voting framework. The algorithm successfully overcomes some of the issues with the previous hubness-aware approaches, which is shown by performing an extensive evaluation on several types of high-dimensional data.								0	0	0	0	0	1820-0214		WOS:000306542400011	
J	Bax, Eric								Validation of k-Nearest Neighbor Classifiers								IEEE TRANSACTIONS ON INFORMATION THEORY			58	5			3225	3234		10.1109/TIT.2011.2180887			MAY 2012	2012	This paper presents a method to compute probably approximately correct error bounds for k-nearest neighbor classifiers. The method withholds some training data as a validation set to bound the error rate of the holdout classifier that is based on the remaining training data. Then, the method uses the validation set to bound the difference in error rates between the holdout classifier and the classifier based on all training data. The result is a bound on the out-of-sample error rate for the classifier based on all training data.								0	1	0	0	1	0018-9448		WOS:000303204900043	
J	Krejnik, Milos; Klema, Jiri								Empirical Evidence of the Applicability of Functional Clustering through Gene Expression Classification								IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS			9	3			788	798		10.1109/TCBB.2012.23			MAY-JUN 2012	2012	The availability of a great range of prior biological knowledge about the roles and functions of genes and gene-gene interactions allows us to simplify the analysis of gene expression data to make it more robust, compact, and interpretable. Here, we objectively analyze the applicability of functional clustering for the identification of groups of functionally related genes. The analysis is performed in terms of gene expression classification and uses predictive accuracy as an unbiased performance measure. Features of biological samples that originally corresponded to genes are replaced by features that correspond to the centroids of the gene clusters and are then used for classifier learning. Using 10 benchmark data sets, we demonstrate that functional clustering significantly outperforms random clustering without biological relevance. We also show that functional clustering performs comparably to gene expression clustering, which groups genes according to the similarity of their expression profiles. Finally, the suitability of functional clustering as a feature extraction technique is evaluated and discussed.								0	0	0	0	0	1545-5963		WOS:000301293900014	
J	Rivero, D.; Guo, L.; Seoane, J. A.; Dorado, J.								Using genetic algorithms and k-nearest neighbour for automatic frequency band selection for signal classification								IET SIGNAL PROCESSING			6	3			186	194		10.1049/iet-spr.2010.0215			MAY 2012	2012	The classification of signals is usually based on the extraction of various features that subsequently will be used as an input to a classifier. These features are extracted as a result of the experts' prior knowledge, which may often involve a lack of the information necessary for an accurate classification in all cases. This study proposes a new technique, in which a genetic algorithm is used to automatically extract frequency-domain features from a set of signals, with no need of prior knowledge. This allows, first, to achieve greater accuracy in the classification of signals, and, secondly, to discover new data on the signals to be classified. This system was used to solve a well-known problem: classification of electroencephalogram (EEG) signals, and its results show a better performance in comparison with other works on the same problem.								0	0	0	0	0	1751-9675		WOS:000306104500003	
J	Li, Guo-Zheng; Sun, Sheng; You, Mingyu; Wang, Ya-Lei; Liu, Guo-Ping								Inquiry diagnosis of coronary heart disease in Chinese medicine based on symptom-syndrome interactions								CHINESE MEDICINE			7						UNSP 9	10.1186/1749-8546-7-9			APR 5 2012	2012	Background: There is a long history of coronary heart disease (CHD) diagnosis and treatment in Chinese medicine (CM), but a formalized description of CM knowledge is still unavailable. This study aims to analyze a set of CM clinical data, which is important and urgent.Methods: Relative associated density (RAD) was used to analyze the one-way links between the symptoms or syndromes or both. RAD results were further used in symptom selection.Results: Analysis of a dataset of clinical CHD diagnosis revealed some significant relationships, not only between syndromes but also between symptoms and syndromes. Using RAD to select symptoms based on different classifiers improved the accuracy of syndrome prediction. Compared with other traditional symptom selection methods, RAD provided a higher interpretability of the CM data.Conclusion: The RAD method is effective for CM clinical data analysis, particular for analysis of relationships between symptoms in diagnosis and generation of compact and comprehensible symptom feature subsets.								0	0	0	0	0	1749-8546		WOS:000320460600001	
J	Ge, Shuzhi Sam; He, Hongsheng; Shen, Chengyao								Geometrically local embedding in manifolds for dimension reduction								PATTERN RECOGNITION			45	4			1455	1470		10.1016/j.patcog.2011.09.022			APR 2012	2012	In this paper, geometrically local embedding (GLE) is presented to discover the intrinsic structure of manifolds as a method in nonlinear dimension reduction. GLE is able to reveal the inner features of the input data in the lower dimension space while suppressing the influence of outliers in the local linear manifold. In addition to feature extraction and representation, GLE behaves as a clustering and classification method by projecting the feature data into low-dimensional separable regions. Through empirical evaluation, the performance of GLE is demonstrated by the visualization of synthetic data in lower dimension, and the comparison with other dimension reduction algorithms with the same data and configuration. Experiments on both pure and noisy data prove the effectiveness of GLE in dimension reduction, feature extraction, data visualization as well as clustering and classification. (C) 2011 Elsevier Ltd. All rights reserved.								0	0	0	0	0	0031-3203		WOS:000300459000019	
J	Lee, Yen-Hsien; Wei, Chih-Ping; Cheng, Tsang-Hsiang; Yang, Ching-Ting								Nearest-neighbor-based approach to time-series classification								DECISION SUPPORT SYSTEMS			53	1			207	217		10.1016/j.dss.2011.12.014			APR 2012	2012	Many interesting applications involve predictions based on a time-series sequence or a set of time-series sequences, which are referred to as time-series classification problems. Prior classification analysis research predominately focuses on constructing a classification model from training instances that involve non-time-series attributes. Direct application of traditional classification analysis techniques to time-series classification problems requires the transformation of time-series attributes into non-time-series ones by applying some statistical operations (e.g., average, sum, variance). However, such statistical-transformation-based approach often results in information loss and, in turn, imperils classification effectiveness. In this study, we propose a time-series classification technique based on the k-nearest-neighbor (kNN) classification approach. Using churn prediction of the mobile telecommunications industry as an evaluation application, our empirical evaluation results show that the proposed kNN-based time-series classification (kNN-TSC) technique achieves better performance (measured by miss and false alarm rates) than the statistical-transformation-based approach does. (C) 2012 Elsevier B.V. All rights reserved.								0	0	0	0	0	0167-9236		WOS:000302982300019	
J	Liu Xue-Song; Ge Liang; Wang Bin; Zhang Li-Ming								An unsupervised band selection algorithm for hyperspectral imagery based on maximal information								JOURNAL OF INFRARED AND MILLIMETER WAVES			31	2			166	+					APR 2012	2012	An unsupervised band selection algorithm for hyperspectral imagery based on maximal information is proposed in this paper. The objective of the method is to preserve the maximal information from original data in the selected bands. The bands with less information are removed one by one from the original data. K-L divergence is used to quantify the information amount and its distribution over all the dataset is considered to judge the specific band which needs to be removed. Compared with traditional methods, the proposed approach has an explicit physical meaning and its computational process is very simple. It is an unsupervised method and can perform automatically.								0	0	0	0	0	1001-9014		WOS:000303782400014	
J	Lyamine, Hedjazi; Aguilar-Martin, Joseph; Le Lann, Marie-Veronique; Kempowsky, Tatiana								TOWARDS A UNIFIED PRINCIPLE FOR REASONING ABOUT HETEROGENEOUS DATA: A FUZZY LOGIC FRAMEWORK								INTERNATIONAL JOURNAL OF UNCERTAINTY FUZZINESS AND KNOWLEDGE-BASED SYSTEMS			20	2			281	302		10.1142/S0218488512500146			APR 2012	2012	Human knowledge about monitoring process variables is usually incomplete. To deal with this partial knowledge many types of representation other than the quantitative one are used to describe process variables (qualitative, symbolic interval). Thus, the development of automatic reasoning mechanisms about the process is faced with this problem of multiple data representations. In this paper, a unified principle for reasoning about heterogeneous data is introduced. This principle is based on a simultaneous mapping of data from initially heterogeneous spaces into only one homogeneous space based on a relative measure using appropriate characteristic functions. Once the heterogeneous data are represented in a unified space, a single processing for various analysis purposes can be performed using simple reasoning mechanisms. An application of this principle within a fuzzy logic framework is performed here to demonstrate its effectiveness. We show that simple fuzzy reasoning mechanisms can be used to reason in a unified way about heterogeneous data in three well known machine learning problems.								0	0	0	0	0	0218-4885		WOS:000302474100007	
J	Ontanon, Santiago; Plaza, Enric								Similarity measures over refinement graphs								MACHINE LEARNING			87	1			57	92		10.1007/s10994-011-5274-3			APR 2012	2012	Similarity also plays a crucial role in support vector machines. Similarity assessment plays a key role in lazy learning methods such as k-nearest neighbor or case-based reasoning. In this paper we will show how refinement graphs, that were originally introduced for inductive learning, can be employed to assess and reason about similarity. We will define and analyze two similarity measures, S (lambda) and S (pi) , based on refinement graphs. The anti-unification-based similarity, S (lambda) , assesses similarity by finding the anti-unification of two instances, which is a description capturing all the information common to these two instances. The property-based similarity, S (pi) , is based on a process of disintegrating the instances into a set of properties, and then analyzing these property sets. Moreover these similarity measures are applicable to any representation language for which a refinement graph that satisfies the requirements we identify can be defined. Specifically, we present a refinement graph for feature terms, in which several languages of increasing expressiveness can be defined. The similarity measures are empirically evaluated on relational data sets belonging to languages of different expressiveness.								0	0	0	0	0	0885-6125		WOS:000301795900003	
J	Xing, Zhengzheng; Pei, Jian; Yu, Philip S.								Early classification on time series								KNOWLEDGE AND INFORMATION SYSTEMS			31	1			105	127		10.1007/s10115-011-0400-x			APR 2012	2012	In this paper, we formulate the problem of early classification of time series data, which is important in some time-sensitive applications such as health informatics. We introduce a novel concept of MPL (minimum prediction length) and develop ECTS (early classification on time series), an effective 1-nearest neighbor classification method. ECTS makes early predictions and at the same time retains the accuracy comparable with that of a 1NN classifier using the full-length time series. Our empirical study using benchmark time series data sets shows that ECTS works well on the real data sets where 1NN classification is effective.								0	0	0	0	0	0219-1377		WOS:000303129500005	
J	Berwald, Jesse; Gedeon, Tomas; Sheppard, John								Using machine learning to predict catastrophes in dynamical systems								JOURNAL OF COMPUTATIONAL AND APPLIED MATHEMATICS			236	9			2235	2245		10.1016/j.cam.2011.11.006			MAR 2012	2012	Nonlinear dynamical systems, which include models of the Earth's climate, financial markets and complex ecosystems, often undergo abrupt transitions that lead to radically different behavior. The ability to predict such qualitative and potentially disruptive changes is an important problem with far-reaching implications. Even with robust mathematical models, predicting such critical transitions prior to their occurrence is extremely difficult. In this work, we propose a machine learning method to study the parameter space of a complex system, where the dynamics is coarsely characterized using topological invariants. We show that by using a nearest neighbor algorithm to sample the parameter space in a specific manner, we are able to predict with high accuracy the locations of critical transitions in parameter space. (C) 2011 Elsevier B.V. All rights reserved.								0	0	0	0	0	0377-0427		WOS:000300863800001	
J	Chou, Chien-Hsing; Hsieh, Yi-Zeng; Tsai, Chi-Yi								MODIFIED SEQUENTIAL FLOATING SEARCH ALGORITHM WITH A NOVEL RANKING METHOD								INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL			8	3B			2089	2100					MAR 2012	2012	Feature selection plays a critical role in pattern classification. Of the various feature selection methods, the sequential floating search (SFS) method is perhaps the most well-known and widely adopted. This paper proposes a feature selection method combining feature ranking and SFS. The proposed feature ranking approach adopts the new idea of false features to rank features based on their importance, and then applies SFS to features that are less important or of lower rank. This approach overcomes issues with the original SFS and extracts more critical features. In addition, most feature selection methods do not consider the problem of multi-class classification. As a result, these methods have difficulty achieving good performance when dealing with a greater variety of classes. Therefore, this study adopts a one-against-all strategy to address this issue. The proposed approach divides multi-class classification into several binary classifications and adopts feature selection to derive individual feature subsets. This strategy achieves satisfactory performance in experimental simulations.								0	0	0	0	0	1349-4198		WOS:000301405400006	
J	Li, Yan; Hung, Edward; Chung, Korris; Huang, Joshua								USING A VARIABLE WEIGHTING k-MEANS METHOD TO BUILD A DECISION CLUSTER CLASSIFICATION MODEL								INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			26	2					1250003	10.1142/S0218001412500036			MAR 2012	2012	In this paper, a new classification method (ADCC) for high-dimensional data is proposed. In this method, a decision cluster classification (DCC) model consists of a set of disjoint decision clusters, each labeled with a dominant class that determines the class of new objects falling in the cluster. A cluster tree is first generated from a training data set by recursively calling a variable weighting k-means algorithm. Then, the DCC model is extracted from the tree. Various tests including Anderson-Darling test are used to determine the stopping condition of the tree growing. A series of experiments on both synthetic and real data sets have been conducted. Their results show that the new classification method (ADCC) performed better in accuracy and scalability than existing methods like k-NN, decision tree and SVM. ADCC is particularly suitable for large, high-dimensional data with many classes.								0	0	0	0	0	0218-0014		WOS:000308104300001	
J	Schumacher, Tobias; Plessl, Christian; Platzner, Marco								IMORC: An infrastructure and architecture template for implementing high-performance reconfigurable FPGA accelerators								MICROPROCESSORS AND MICROSYSTEMS			36	2	SI		110	126		10.1016/j.micpro.2011.04.002			MAR 2012	2012	The design, implementation and optimization of FPGA accelerators is a challenging task, especially when the accelerator comprises multiple compute cores distributed across CPU and FPGA resources and memories and exhibits data-dependent runtime behavior. In order to simplify the development of FPGA accelerators we propose IMORC, an infrastructure and architecture template that helps raising the level of abstraction. The IMORC development flow bases on a modeling technique for visualizing an application's communication demand and an architecture template that aids the developer in implementing the design. The architectural template consists of a versatile on-chip interconnect with asynchronous FIFOs and bitwidth conversion placed into the communication links, a performance monitoring infrastructure for collecting performance information during runtime and a set of generic infrastructure cores which are frequently needed in accelerator designs. We demonstrate the usefulness of the IMORC development flow by means of the case study of accelerating the kth nearest neighbor thinning problem, where IMORC greatly helps us in understanding the communication demand and in implementing the application. With the integrated performance monitoring infrastructure, we gain insights into the data-dependent behavior of the accelerator that helps us in identifying bottlenecks and optimizing the accelerator to achieve a speedup of 10x to 40x over an optimized CPU implementation. (C) 2011 Elsevier B.V. All rights reserved.								0	0	0	0	0	0141-9331		WOS:000301685200006	
J	Echeverria, A.; Valls, J. M.; Aler, R.								Evolving linear transformations with a rotation-angles/scaling representation								EXPERT SYSTEMS WITH APPLICATIONS			39	3			3276	3282		10.1016/j.eswa.2011.09.015			FEB 15 2012	2012	Similarity between patterns is commonly used in many distance-based classification algorithms like KNN or RBF. Generalized Euclidean Distances (GED) can be optimized in order to improve the classification success rate in distance-based algorithms. This idea can be extended to any classification algorithm, because it can be shown that a GEDs is equivalent to a linear transformations of the dataset. In this paper, the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) is applied to the optimization of linear transformations represented as matrices. The method has been tested on several domains and results show that the classification success rate can be improved for some of them. However, in some domains. diagonal matrices get higher accuracies than full square ones. In order to solve this problem, we propose in the second part of the paper to represent linear transformations by means of rotation angles and scaling factors, based on the Singular Value Decomposition theorem (SVD). This new representation solves the problems found in the former part. (C) 2011 Elsevier Ltd. All rights reserved.								0	0	0	0	0	0957-4174		WOS:000297823300111	
J	Lang, Congyan; Feng, Songhe; Cheng, Bing; Ni, Bingbing; Yan, Shuicheng								A unified supervised codebook learning framework for classification								NEUROCOMPUTING			77	1			281	288		10.1016/j.neucom.2011.09.010			FEB 1 2012	2012	In this paper, we investigate a discriminative visual dictionary learning method for boosting the classification performance. Tied to the K-means clustering philosophy, those popular algorithms for visual dictionary learning cannot guarantee the well-separation of the normalized visual word frequency vectors from distinctive classes or large label distances. The rationale of this work is to harness sample label information for learning visual dictionary in a supervised manner, and this target is then formulated as an objective function, where each sample element, e.g., SIFT descriptor, is expected to be close to its assigned visual word, and at the same time the normalized aggregative visual word frequency vectors are expected to possess the property that kindred samples shall be close to each other while inhomogeneous samples shall be far away. By relaxing the hard binary constraints to soft nonnegative ones, a multiplicative nonnegative update procedure is proposed to optimize the objective function along with theoretic convergence proof. Extensive experiments on classification tasks (i.e., natural scene and sports event classifications) all demonstrate the superiority of this proposed framework over conventional clustering based visual dictionary learning. (C) 2011 Elsevier B.V. All rights reserved.								0	0	0	0	0	0925-2312		WOS:000298206400030	
J	Mharib, Ahmed M.; Ramli, Abdul Rahman; Mashohor, Syamsiah; Mahmood, Rozi Binti								Survey on liver CT image segmentation methods								ARTIFICIAL INTELLIGENCE REVIEW			37	2			83	95		10.1007/s10462-011-9220-3			FEB 2012	2012	The segmentation of liver using computed tomography (CT) data has gained a lot of importance in the medical image processing field. In this paper, we present a survey on liver segmentation methods and techniques using CT images, recent methods presented in the literature to obtain liver segmentation are viewed. Generally, liver segmentation methods are divided into two main classes, semi-automatic and fully automatic methods, under each of these two categories, several methods, approaches, related issues and problems will be defined and explained. The evaluation measurements and scoring for the liver segmentation are shown, followed by the comparative study for liver segmentation methods, pros and cons of methods will be accentuated carefully. In this paper, we concluded that automatic liver segmentation using CT images is still an open problem since various weaknesses and drawbacks of the proposed methods can still be addressed.								0	0	0	0	0	0269-2821		WOS:000300283700001	
J	Tu, Tao; Xin, Yi; Gao, Xiaorong; Gao, Shangkai								Chirp-modulated visual evoked potential as a generalization of steady state visual evoked potential								JOURNAL OF NEURAL ENGINEERING			9	1					016008	10.1088/1741-2560/9/1/016008			FEB 2012	2012	Visual evoked potentials (VEPs) are of great concern in cognitive and clinical neuroscience as well as in the recent research field of brain-computer interfaces (BCIs). In this study, a chirp-modulated stimulation was employed to serve as a novel type of visual stimulus. Based on our empirical study, the chirp stimuli visual evoked potential (Chirp-VEP) preserved frequency features of the chirp stimulus analogous to the steady state evoked potential (SSVEP), and therefore it can be regarded as a generalization of SSVEP. Specifically, we first investigated the characteristics of the Chirp-VEP in the time-frequency domain and the fractional domain via fractional Fourier transform. We also proposed a group delay technique to derive the apparent latency from Chirp-VEP. Results on EEG data showed that our approach outperformed the traditional SSVEP-based method in efficiency and ease of apparent latency estimation. For the recruited six subjects, the average apparent latencies ranged from 100 to 130 ms. Finally, we implemented a BCI system with six targets to validate the feasibility of Chirp-VEP as a potential candidate in the field of BCIs.								0	0	0	0	0	1741-2560		WOS:000300618700010	
J	Vujic, Nikola; Cabarcas, Felipe; Gonzalez, Marc; Ramirez, Alex; Martorell, Xavier; Ayguade, Eduard								DMA++: On the Fly Data Realignment for On-Chip Memories								IEEE TRANSACTIONS ON COMPUTERS			61	2			237	250		10.1109/TC.2010.255			FEB 2012	2012	Multimedia extensions based on Single-Instruction Multiple-Data (SIMD) units are widespread. They have been used, for some time, in processors and accelerators (e.g., the Cell SPEs). SIMD units usually have significant memory alignment constraints in order to meet power requirements and design simplicity. This increases the complexity of the code generated by the compiler as, in the general case, the compiler cannot be sure of the proper alignment of data. For that, the ISA provides either unaligned memory load and store instructions, or a special set of instructions to perform realignments in software. In this paper, we propose a hardware realignment unit that takes advantage of the DMA transfers needed in accelerators with local memories. While the data are being transferred, it is realigned on the fly by our realignment unit, and stored at the desired alignment in the accelerator memory. This mechanism can help programmers to better organize data in the accelerator memory so that the accelerator can possibly access the data with no special instructions. Finally, the data are realigned properly also when put back to main memory. Our experiments with nine applications show that with our approach, the bandwidth of the DMA transfers is not penalized.								0	0	0	0	0	0018-9340		WOS:000298560500009	
S	Abouelenien, Mohamed; Yuan, Xiaohui; Duraisamy, Prakash; Yuan, Xiaojing			IEEE					Improving Classification Performance for the Minority Class in Highly Imbalanced Dataset using Boosting								2012 THIRD INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION & NETWORKING TECHNOLOGIES (ICCCNT)	International Conference on Computing Communication and Network Technologies												2012	2012	Data imbalance is a common property in many medical and biological data and usually results in degraded generalization performance. In this article, we present a novel boosting method to address two important questions in learning from imbalanced dataset: how to maximize the performance of classifying the minority instances without compromising the performance for the majority instances? and how to select training instances to achieve a comprehensive representation of the data distribution and avoid high computational time? Our method maximizes the usage of the available samples with priority given to the minority samples. The base classifiers are weighted with their sensitivities derived from the training examples. Using synthetic and real-world datasets, we demonstrated the performance improvement of our method in both sensitivity and accuracy without major reduction in specificity. In contrast to AdaBoost, our method took much less time, which makes it applicable in real-world problems that have large amount of data.				3rd International Conference on Computing Communication and Networking Technologies (ICCCNT)	JUL 26-28, 2012		Coimbatore, INDIA	0	0	0	0	0	2162-7665	*****************	WOS:000320608600249	
B	Abroudi, Ali; Farokhi, Fardad			IEEE					Prototype Selection for Training Artificial Neural Networks based on Fast Condensed Nearest Neighbor Rule								2012 IEEE CONFERENCE ON OPEN SYSTEMS (ICOS 2012)							112	115					2012	2012	This paper presents new method for training intelligent networks such as Multi-Layer Perceptron (MLP) and Neuro-Fuzzy Networks (NFN) with prototypes selected via Fast Condensed Nearest Neighbor (FCNN) rule. By applying FCNN, condensed subsets with instances close to the decision boundary are obtained. We call these points High-Priority Prototypes (HPPs) and the network is trained by them. The main objective of this approach is to improve the performance of the classification by boosting the quality of the training-set. The experimental results on several standard classification databases illustrated the power of the proposed method. In comparison to previous approaches which select prototypes randomly, training with HPPs performs better in terms of classification accuracy.				IEEE Conference on Open Systems (ICOS) / IEEE Symposium on e-Learning, e-Management and e-Services (IS3e)	OCT 21-24, 2012	IEEE; IEEE Comp Soc; IEEE Malaysia Sect; IEEE Malaysia Comp Chapter	Kuala Lumpur, MALAYSIA	0	0	0	0	0		978-1-4673-1046-8	WOS:000316560200021	
B	Ahmadvand, Payam; Ramin, Marjan; Sepas-Moghaddam, Alireza; Ahmadvand, Pouya			IEEE					Expression of Antigens in Immunocytochemical Images Utilizing an Image Analysis Method								2012 16TH IEEE MEDITERRANEAN ELECTROTECHNICAL CONFERENCE (MELECON)	IEEE Mediterranean Electrotechnical Conference-MELECON						895	898					2012	2012	Immunocytochemistry is a common laboratory technique in which the quality of interaction between antibody antigen is evaluated on a cell surface. The amount of binding between antibodies and cancerous cells in Immunocytochemical images indicates how much the antibody is effective for treating the cancerous cell. In this paper, an automated system has been proposed for the first time, to measure such binding, utilizing well-known image processing methods. The experiments are simulated using the collected reference images in this research which can be used as a benchmark in the future researches. Proposing this method leads to an accurate and fast evaluation of the antigens' expression along with more reduced human-error factors. (Abstract)				16th IEEE Mediterranean Electrotechnical Conference (MELECON)	MAR 25-28, 2012	IEEE; IEEE, Reg 08; IEEE Tunisia Sect; Ecole Nationale dIngenieurs sfax (ENIS); Ecole Nationale dIngenieurs Tunis (ENIT); Ecole Nationale Sci LInformatique (ENSI); Ecole Nationale dIngenieurs Sousse (ENIS)	Hammamet, TUNISIA	0	0	0	0	0		978-1-4673-0784-0	WOS:000309215000190	
B	Al-Badarneh, Amer; Najadat, Hassan; Alraziqi, Ali M.			IEEE					A Classifier to Detect Tumor Disease in MRI Brain Images								2012 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM)							784	787		10.1109/ASONAM.2012.142			2012	2012	The traditional method for detecting the tumor diseases in the human MRI brain images is done manually by physicians. Automatic classification of tumors of MRI images requires high accuracy, since the non-accurate diagnosis and postponing delivery of the precise diagnosis would lead to increase the prevalence of more serious diseases. To avoid that, an automatic classification system is proposed for tumor classification of MRI images. This work shows the effect of neural network (NN) and K-Nearest Neighbor (K-NN) algorithms on tumor classification. We used a benchmark dataset MRI brain images. The experimental results show that our approach achieves 100% classification accuracy using K-NN and 98.92% using NN.				IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining	AUG 26-29, 2012	ACM; IEEE; ACM Sigmod; IEEE Comp Soc; Springer; TCDE; TUBiTAK; TUBiTAK BiLGEM; ACTC SMCS; IEEE Tech Comm Data Engn; Univ Calgary; Hellen Amer Univ; sbtanaliz; EX tra Foreign Trade Co Ltd; inforcept; FNSS Savunma Sistemleri A S; raccoonize; Huawei	Kadir Has Univ, Istanbul, TURKEY	0	0	0	0	0		978-0-7695-4799-2	WOS:000320443500125	
J	Al-Kofahi, Salman; Steele, Caiti; VanLeeuwen, Dawn; St Hilaire, Rolston								Mapping land cover in urban residential landscapes using very high spatial resolution aerial photographs								URBAN FORESTRY & URBAN GREENING			11	3			291	301		10.1016/j.ufug.2012.05.001			2012	2012	Accurate information on existing residential landscapes is essential for framing ordinances and monitoring residential water use in the Urban Greenspace Ecosystem. We classified residential landscapes of New Mexico's largest city, Albuquerque, to explore the spatial distribution of residential greenspace and its composition among zip codes and median incomes. Geographic Information System (GIS) vector files including parcels, city limits, zip codes and land-use maps, were integrated with ownership information. The database was stratified by Albuquerque's 16 zip codes. Four hundred eighty residential landscapes were selected randomly for study. Very high spatial resolution (0.15 m) 2008 true color aerial photographs and the object-oriented supervised classification module in ENVI EX were used to identify residential features. Spatial and textural variables, created by image segmentation, were classified using the K-Nearest Neighbor (K-NN) algorithm embedded in ENVI EX. Classification accuracy was 89%. Larger greenspace, tree, shrub, and grass areas were in larger parcels. Landscapes in lower income groups and older zip codes include larger greenspace and tree cover because of mature tree sizes, while grass dominated landscapes of higher income groups and newer zip codes. This knowledge of residential vegetation distribution could serve as a basis for policy makers, planners, and water conservation officers wishing to enact ordinances and regulations that govern the urban residential landscape. (c) 2012 Elsevier GmbH. All rights reserved.								0	0	0	0	0	1618-8667		WOS:000308902100007	
J	Allano, Lorene; Dorizzi, Bernadette; Garcia-Salicetti, Sonia				Allano, Lorene/D-9208-2012				A new protocol for multi-biometric systems' evaluation maintaining the dependencies between biometric scores								PATTERN RECOGNITION			45	1			119	127		10.1016/j.patcog.2011.07.001			JAN 2012	2012	We address the problem of measuring the dependency of multibiometric systems' scores, using Kolmogorov-Smirnov and Mutual Information criteria, and studying the validity of performance evaluation on chimeric persons. On the NIST-BSSR1 database, we formalize a common assumption in the literature: for independent scores, multibiometric systems can be evaluated on "random chimeric" persons. We show that this is not valid for dependent scores and propose a novel protocol for building "cluster-based chimeric" persons maintaining the level of dependency between scores. Finally, we show that performance evaluation for dependent modalities on such persons is equivalent to that obtained on "real" persons. (C) 2011 Elsevier Ltd. All rights reserved.								0	0	0	0	0	0031-3203		WOS:000295760700010	
S	Bae, Seung-Hee; Qiu, Judy; Fox, Geoffrey						Ali, H; Shi, Y; Khazanchi, D; Lees, M; VanAlbada, GD; Dongarra, J; Sloot, PMA		Adaptive Interpolation of Multidimensional Scaling								PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE, ICCS 2012	Procedia Computer Science		9				393	402		10.1016/j.procs.2012.04.042			2012	2012	The recent explosion of publicly available biology gene sequences and chemical compounds offers an unprecedented opportunity for data mining. To make data analysis feasible for such vast volume and high-dimensional scientific data, we apply high performance dimension reduction algorithms. It facilitates the investigation of unknown structures in a three dimensional visualization. Among the known dimension reduction algorithms, we utilize the multidimensional scaling (MDS) algorithm to configure the given high-dimensional or abstract data into a target dimension. However, the MDS algorithm requires large physical memory as well as computational resources. In order to reduce computational complexity and memory requirement effectively, the interpolation method of the MDS was proposed in 2010. With minor trade-off of approximation, the MDS interpolation method enables us to process millions of data points with modest amounts of computation and memory requirement. In this paper, we would like to improve the mapping quality of the MDS interpolation approach by adapting the original dissimilarity based on the ratio between the original dissimilarity and the corresponding mapping distances. Our experimental results illustrate that the quality of interpolated mapping results are improved by adding the adaptation step without runtime loss compared to the original interpolation method. With the proposed adaptive interpolation method, we construct a better configuration of millions of out-of-sample data into a target dimension than the previous interpolation method.				International Conference on Computational Science (ICCS)	JUN 04-06, 2012	Univ Nebraska; Universiteit Amsterdam; Univ Tennessee; Nanyang Technol Univ; Chinese Acad Sci Res Ctr Fictitious Econ & Data Sci; Elsevier; Univ Nebraska, Coll Informat Sci & Technol; Gallup Org; Union Pacific Railroad; Interpubl Grp Co (IPG)	Omaha, NE	0	0	0	0	0	1877-0509	*****************	WOS:000306288400041	
B	Biau, Gerard; Devroye, Luc; Dujmovic, Vida; Krzyzak, Adam			IEEE					An Affine Invariant k-Nearest Neighbor Regression Estimate								2012 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY PROCEEDINGS (ISIT)	IEEE International Symposium on Information Theory												2012	2012	We propose a new k-NN regression estimate based on a data-dependent metric in R-d which is used to define the k-nearest neighbors of a given point. The metric is invariant under all affine transformations. With this metric, the standard k-nearest neighbor regression estimate is asymptotically consistent under the usual conditions on k, and minimal requirements on the input data.				IEEE International Symposium on Information Theory	JUL 01-06, 2012	IEEE	Cambridge, MA	0	0	0	0	0		978-1-4673-2579-0	WOS:000312544301109	
S	Biehl, Michael; Bunte, Kerstin; Schleif, Frank-Michael; Schneider, Petra; Villmann, Thomas			IEEE					Large Margin Linear Discriminative Visualization by Matrix Relevance Learning								2012 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)	IEEE International Joint Conference on Neural Networks (IJCNN)												2012	2012	We suggest and investigate the use of Generalized Matrix Relevance Learning (GMLVQ) in the context of discriminative visualization. This prototype-based, supervised learning scheme parameterizes an adaptive distance measure in terms of a matrix of relevance factors. By means of a few benchmark problems, we demonstrate that the training process yields low rank matrices which can be used efficiently for the discriminative visualization of labeled data. Comparison with well known standard methods illustrate the flexibility and discriminative power of the novel approach. The mathematical analysis of GMLVQ shows that the corresponding stationarity condition can be formulated as an eigenvalue problem with one or several strongly dominating eigenvectors. We also study the inclusion of a penalty term which enforces non-singularity of the relevance matrix and can be used to control the role of higher order eigenvalues, efficiently.				IEEE International Conference on Fuzzy Systems (FUZZ-IEEE) / International Joint Conference on Neural Networks (IJCNN) / IEEE Congress on Evolutionary Computation (IEEE-CEC) / IEEE World Congress on Computational Intelligence (IEEE-WCCI)	JUN 10-15, 2012	IEEE	Brisbane, AUSTRALIA	0	0	0	0	0	1098-7576	978-1-4673-1490-9	WOS:000309341301127	
S	Castro-Melchor, Marlene; Le, Huong; Hu, Wei-Shou						Hu, WS; Zeng, AP		Transcriptome Data Analysis for Cell Culture Processes								GENOMICS AND SYSTEMS BIOLOGY OF MAMMALIAN CELL CULTURE	Advances in Biochemical Engineering-Biotechnology		127				27	70		10.1007/10_2011_116	10.1007/978-3-642-28350-5		2012	2012	In the past decade, DNA microarrays have fundamentally changed the way we study complex biological systems. By measuring the expression levels of thousands of transcripts, the paradigm of studying organisms has shifted from focusing on the local phenomena of a few genes to surveying the whole genome. DNA microarrays are used in a variety of ways, from simple comparisons between two samples to more intricate time-series studies. With the large number of genes being studied, the dimensionality of the problem is inevitably high. The analysis of microarray data thus requires specific approaches. In the case of time-series microarray studies, data analysis is further complicated by the correlation between successive time points in a series.In this review, we survey the methodologies used in the analysis of static and time-series microarray data, covering data pre-processing, identification of differentially expressed genes, profile pattern recognition, pathway analysis, and network reconstruction. When available, examples of their use in mammalian cell cultures are presented.								0	0	0	0	0	0724-6145	978-3-642-28350-5	WOS:000321104000004	
S	Cavalcanti, George D. C.; Ren, Tsang Ing; Vale, Breno A.			IEEE					Data complexity measures and nearest neighbor classifiers: a practical analysis for meta-learning								2012 IEEE 24TH INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE (ICTAI 2012), VOL 1	Proceedings-International Conference on Tools With Artificial Intelligence						1065	1069		10.1109/ICTAI.2012.150			2012	2012	The classifier accuracy is affected by the properties of the data sets used to train it. Nearest neighbor classifiers are known for being simple and accurate in several domains, but their behavior is strongly dependent on data complexity. On the other hand, there are data complexity measures which aim to describe properties of the data sets. This work aims to show how data complexity measures can be efficiently used to predict the behavior of the Nearest Neighbor classifier. Seven data complexity measures and seventeen real datasets are used in the experimental study. Each data complexity measure is analyzed individually in order to find a relationship between its value and the accuracy of the classifier on a given dataset. No single measure used is good enough to predict the behavior of the Nearest Neighbor classifier. However, the combination of these measures provides a powerful tool to predict the accuracy of the Nearest Neighbor classifier.				IEEE 24th International Conference on Tools with Artificial Intelligence (ICTAI)	NOV 07-09, 2012	IEEE; IEEE Comp Soc; Biol & Artificial Intelligence Fdn (BAIF); Hellen Artificial Intelligence Soc (EETN); Univ Piraeus; Univ Piraeus Res Ctr	Athens, GREECE	0	0	0	0	0	1082-3409	978-0-7695-4915-6	WOS:000320861900146	
S	Chuang, Fang-Chen; Wang, Jeen-Shing; Yang, Ya-Ting; Kao, Tzu-Ping			IEEE					A Wearable Activity Sensor System and Its Physical Activity Classification Scheme								2012 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)	IEEE International Joint Conference on Neural Networks (IJCNN)												2012	2012	This paper presents a wearable activity sensor system and a systematic activity classification scheme for the classification of human daily physical activities. The wearable activity sensor system, consisting of two activity sensor modules worn on users' dominant hand wrists and ankles, is used for collecting activity acceleration signals. The proposed activity classification scheme, including static/dynamic activity analysis, posture recognition, exercise classification, and ambulation classification, is capable of classifying time-series activity acceleration signals. The collected acceleration signals are classify into two categories by means of static/dynamic activity analysis. Posture recognition is applied for partitioning static signals into sitting and standing. Exercise classification and ambulation classification algorithms were used to classify dynamic activity signals. Our experimental results have successfully validated the effectiveness of the proposed wearable sensor system and the scheme of activity classification algorithms with an overall classification accuracy of 96% for seven types of daily activities.				IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)/International Joint Conference on Neural Networks (IJCNN)/IEEE Congress on Evolutionary Computation (IEEE-CEC)/IEEE World Congress on Computational Intelligence (IEEE-WCCI)	JUN 10-15, 2012	IEEE	Brisbane, AUSTRALIA	0	0	0	0	0	1098-7576	978-1-4673-1490-9	WOS:000309341301081	
J	Chuang, Li-Yeh; Yang, Cheng-Hong; Tsai, Sheng-Wei								Complementary distribution BPSO for feature selection								INTELLIGENT DATA ANALYSIS			16	2			183	198		10.3233/IDA-2012-0518			2012	2012	Feature selection is a preprocessing technique in the field of data analysis, which is used to reduce the number of features by removing irrelevant, noisy, and redundant data, thus resulting in acceptable classification accuracy. This process constitutes a commonly encountered problem of global combinatorial optimization. This paper presents a novel optimization algorithm called complementary distribution binary particle swarm optimization (CD-BPSO). CD-BPSO uses a complementary distribution strategy to improve the search capability of binary particle swarm optimization (BPSO) by facilitating global exploration and local exploitation via complementary particles and original particles, respectively. This complementary approach introduces new "complementary particles" into the search space. These new particles are generated by using half of all particles selected at random, and replace the selected particles when the fitness of the global best particle has not improved for a number of consecutive iterations. The K-nearest neighbor (K-NN) method with leave-one-out cross-validation (LOOCV) was used to evaluate the quality of the solutions. The proposed method was applied and compared to ten classification problems taken from the literature. Experimental results indicate that CD-BPSO improves on the BPSO algorithm with a complementary strategy that prevents entrapment in a local optimum. In the feature selection problem, BPSO preserves knowledge of good feature selection combinations in all the particles and thus the swarm can find optimum combinations of solutions by following the best particle, and either obtains higher classification accuracy or uses fewer features than other feature selection methods.								0	0	0	0	0	1088-467X		WOS:000301366100003	
J	Chuang, Li-Yeh; Yang, Cheng-Huei; Li, Jung-Chike; Yang, Cheng-Hong								A Hybrid BPSO-CGA Approach for Gene Selection and Classification of Microarray Data								JOURNAL OF COMPUTATIONAL BIOLOGY			19	1			68	82		10.1089/cmb.2010.0064			JAN 2012	2012	Microarray analysis promises to detect variations in gene expressions, and changes in the transcription rates of an entire genome in vivo. Microarray gene expression profiles indicate the relative abundance of mRNA corresponding to the genes. The selection of relevant genes from microarray data poses a formidable challenge to researchers due to the high-dimensionality of features, multiclass categories being involved, and the usually small sample size. A classification process is often employed which decreases the dimensionality of the microarray data. In order to correctly analyze microarray data, the goal is to find an optimal subset of features (genes) which adequately represents the original set of features. A hybrid method of binary particle swarm optimization (BPSO) and a combat genetic algorithm (CGA) is to perform the microarray data selection. The K-nearest neighbor (K-NN) method with leave-one-out cross-validation (LOOCV) served as a classifier. The proposed BPSO-CGA approach is compared to ten microarray data sets from the literature. The experimental results indicate that the proposed method not only effectively reduce the number of genes expression level, but also achieves a low classification error rate.								0	0	0	0	0	1066-5277		WOS:000298969900006	
S	Dhoble, Kshitij; Nuntalid, Nuttapod; Indiveri, Giacomo; Kasabov, Nikola			IEEE	Ramage, Robyn/G-3083-2010				Online Spatio-Temporal Pattern Recognition with Evolving Spiking Neural Networks utilising Address Event Representation, Rank Order, and Temporal Spike Learning								2012 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)	IEEE International Joint Conference on Neural Networks (IJCNN)												2012	2012	Evolving spiking neural networks (eSNN) are computational models that evolve new spiking neurons and new connections from incoming data to learn patterns from them in an on-line mode. With the development of new techniques to capture spatio- and spectro-temporal data in a fast on-line mode, using for example address event representation (AER) such as the implemented one in the artificial retina and the artificial cochlea chips, and with the available SNN hardware technologies, new and more efficient methods for spatio-temporal pattern recognition (STPR) are needed. The paper introduces a new eSNN model dynamic eSNN (deSNN), that utilises both rank-order spike coding (ROSC), also known as time to first spike, and temporal spike coding (TSC). Each of these representations are implemented through different learning mechanisms - RO learning, and temporal spike learning - spike driven synaptic plasticity (SDSP) rule. The deSNN model is demonstrated on a small scale moving object classification problem when AER data is collected with the use of an artificial retina camera. The new model is superior in terms of learning time and accuracy for learning. It makes use of the order of spikes input information which is explicitly present in the AER data, while a temporal spike learning rule accounts for any consecutive spikes arriving on the same synapse that represent temporal components in the learned spatio-temporal pattern.				International Joint Conference on Neural Networks (IJCNN)	JUN 10-15, 2012		Brisbane, AUSTRALIA	0	0	0	0	0	1098-7576	978-1-4673-1490-9	WOS:000309341300077	
J	Ding, Yong; Banitalebi, Behnam; Miyaki, Takashi; Beigl, Michael								RFTraffic: a study of passive traffic awareness using emitted RF noise from the vehicles								EURASIP JOURNAL ON WIRELESS COMMUNICATIONS AND NETWORKING									8	10.1186/1687-1499-2012-8			2012	2012	In this article, a new traffic sensing and monitoring technique is introduced which works based on the emitted RF noise from the vehicles. In comparison with the current traffic sensing systems, our light-weight technique has simpler structure in both terms of hardware and software. An antenna installed to the roadside or the inside of a car receives the signal generated during electrical activity of the vehicles' sub-systems. This signal feeds the feature extraction and classification blocks which recognize different classes of traffic situation in terms of density, flow and location. Different classifiers like and are applied in real-world scenarios and performances for instance of traffic situation detection are reported with higher than 95%. Although the electrical noises of the various vehicles do not have the same statistical characteristics, results from two experiments with an implementation on RF receiver illustrate that our approach is practically feasible for traffic monitoring goals. Due to the acceptable classification results and the differences between the proposed and current traffic monitoring techniques in terms of interfering factors, advantages and disadvantages, we propose it to work in parallel with the current systems to improve the coverage and efficiency of the traffic control network.								0	0	0	0	0	1687-1499		WOS:000303874500001	
