PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	PG	WC	SC	GA	UT	PM
J	Walker, I; Milne, S				Walker, I; Milne, S			Exploring function estimators as an alternative to regression in psychology	BEHAVIOR RESEARCH METHODS			English	Article							ARTIFICIAL NEURAL-NETWORKS	Most forms of regression analysis make assumptions about the relationships between the variables being modeled. As a consequence, it can be difficult to know which form of analysis is most appropriate for a given data set. In this article, we explore the idea that function estimators might provide a better alternative in many situations. Function estimators discover the best function to link dependent and independent variables, no matter what form this takes. Four studies demonstrate that one type of function estimator (a neural network) not only performs the same tasks as linear regression and nonlinear regression, but often performs these tasks better and with more flexibility. Moreover, neural networks allow a useful secondary analysis in which useful groups of people can be identified. We recommend that function estimators be used in preference to regression-based techniques for many analyses. The Matlab script used to write this article may be downloaded from www.psychonomic.org/archive/.	Univ Bath, Dept Psychol, Bath BA2 7AY, Avon, England	Walker, I (reprint author), Univ Bath, Dept Psychol, Bath BA2 7AY, Avon, England.	i.walker@bath.ac.uk					BISHOP C.M., 1995, NEURAL NETWORKS PATT; CALLAN R., 1999, ESSENCE NEURAL NETWO; CARUANA R, 2000, NEUR INF PROC SYST D; *DASL PROJ, 2004, DAT STORY LIB; DAWSON CK, 2002, PDP SOFTWARE USERS M; Elman J. L., 1996, RETHINKING INNATENES; Elman J. L, 1997, EXERCISES RETHINKING; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Gigerenzer G., 2000, ADAPTIVE THINKING RA; Hastie T., 2001, ELEMENTS STAT LEARNI; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; LAWRENCE S, 2000, INT JOINT C NEUR NET; Lawrence S, 1997, P 14 NAT C ART INT A, P540; *MATHW, 2001, NEUR NETW TOOLB US G; *MATHW, 2001, MATL VERS 6 1; McLeod P, 1998, INTRO CONNECTIONIST; Nigrin A., 1993, NEURAL NETWORKS PATT; NIKZAS D, 1990, EUR UROL, V18, P242; ROBINSON T, 1993, VISUAL REPRESENTATIO, P83; Rogers R. W., 1983, SOCIAL PSYCHOPHYSIOL, P153; ROGERS RW, 1975, J PSYCHOL, V91, P93; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, VI; SEIDENBERG MS, 1989, PSYCHOL REV, V96, P523, DOI 10.1037/0033-295X.96.4.523; Setiono R, 2002, IEEE T NEURAL NETWOR, V13, P564, DOI 10.1109/TNN.2002.1000125; STERNBER.S, 1966, SCIENCE, V153, P652, DOI 10.1126/science.153.3736.652; STONE M, 1974, J R STAT SOC B, V36, P111; Sutton Stephen R., 1982, SOCIAL PSYCHOL BEHAV, P303; Tabachnick B. G., 2001, USING MULTIVARIATE S; Tickle AB, 1998, IEEE T NEURAL NETWOR, V9, P1057, DOI 10.1109/72.728352; Westbury C, 2003, BEHAV RES METH INS C, V35, P202, DOI 10.3758/BF03202543; Yerkes RM, 1908, J COMP NEUROL PSYCHO, V18, P459, DOI 10.1002/cne.920180503	31	3	3	PSYCHONOMIC SOC INC	AUSTIN	1710 FORTVIEW RD, AUSTIN, TX 78704 USA	1554-351X			BEHAV RES METHODS	Behav. Res. Methods	FEB	2005	37	1					23	36		10.3758/BF03206395		14	Psychology, Mathematical; Psychology, Experimental	Psychology	954ID	WOS:000231147600004	16097341	
J	Ghosh, AK; Chaudhuri, P				Ghosh, AK; Chaudhuri, P			On data depth and distribution-free discriminant analysis using separating surfaces	BERNOULLI			English	Article						Bayes risk; elliptic symmetry; generalized U-statistic; half-space depth; linear discriminant analysis; location-shift models; misclassification rates; optimal Bayes classifier; quadratic discriminant analysis; regression depth; robustness; Vapnik-Chervonenkis dimension	LOGISTIC-REGRESSION MODELS; MULTIVARIATE; CLASSIFICATION; CONVERGENCE; LOCATION; INFERENCE; EXISTENCE; CONTOURS	A very well-known traditional approach in discriminant analysis is to use some linear (or nonlinear) combination of measurement variables which can enhance class separability. For instance, a linear (or a quadratic) classifier finds the linear projection (or the quadratic function) of the measurement variables that will maximize the separation between the classes. These techniques are very useful in obtaining good lower dimensional view of class separability. Fisher's discriminant analysis, which is primarily motivated by the multivariate normal distribution, uses the first- and second-order moments of the training sample to build such classifiers. These estimates, however, are highly sensitive to outliers, and they are not reliable for heavy-tailed distributions. This paper investigates two distribution-free methods for linear classification, which are based on the notions of statistical depth functions. One of these classifiers is closely related to Tukey's half-space depth, while the other is based on the concept of regression depth. Both these methods can be generalized for constructing nonlinear surfaces to discriminate among competing classes. These depth-based methods assume some finite-dimensional parametric form of the discriminating surface and use the distributional geometry of the data cloud to build the classifier. We use a few simulated and real data sets to examine the performance of these discriminant analysis tools and study their asymptotic properties under appropriate regularity conditions.	Indian Stat Inst, Theoret Stat & Math Unit, Kolkata 700108, W Bengal, India	Ghosh, AK (reprint author), Indian Stat Inst, Theoret Stat & Math Unit, 203,BT Rd, Kolkata 700108, W Bengal, India.	res9812@isical.ac.in; probal@isical.ac.in					ALBERT A, 1984, BIOMETRIKA, V71, P1; Bai ZD, 1999, ANN STAT, V27, P1616; CAMPBELL NA, 1974, AUST J ZOOL, V22, P417, DOI 10.1071/ZO9740417; CHAUDHURI P, 1993, J AM STAT ASSOC, V88, P1363, DOI 10.2307/2291278; CHRISTMANN A, 2002, STAT DATA ANAL BASED, P341; Christmann A, 2001, COMPUT STAT DATA AN, V37, P65, DOI 10.1016/S0167-9473(00)00063-3; Christmann A, 2002, COMPUTATION STAT, V17, P273, DOI 10.1007/s001800200106; Cox L, 1982, ASA P STAT COMP SECT, P55; DONOHO DL, 1992, ANN STAT, V20, P1803, DOI 10.1214/aos/1176348890; Duda R. O., 2000, PATTERN CLASSIFICATI; FANG K. T., 1989, SYMMETRIC MULTIVARIA; Fisher RA, 1936, ANN EUGENIC, V7, P179; Friedman J., 1996, ANOTHER APPROACH POL; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Fukunaga K, 1990, INTRO STAT PATTERN R; GHOSH AK, 2004, UNPUB; Hand D. J., 1981, DISCRIMINATION CLASS; Hastie T., 2001, ELEMENTS STAT LEARNI; HASTIE T, 1994, J AM STAT ASSOC, V89, P1255, DOI 10.2307/2290989; Hastie T, 1998, ANN STAT, V26, P451; He XM, 1997, ANN STAT, V25, P495; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; Jornsten R, 2004, J MULTIVARIATE ANAL, V90, P67, DOI 10.1016/j.jmva.2004.02.013; JORNSTEN R, 2002, STAT DATA ANAL BASED, P353; LIU RY, 1990, ANN STAT, V18, P405, DOI 10.1214/aos/1176347507; Liu RY, 1999, ANN STAT, V27, P783; McLachlan G., 1992, DISCRIMINANT ANAL ST; Mosler K., 2002, MULTIVARIATE DISPERS; NOLAN D, 1992, STOCH PROC APPL, V42, P157, DOI 10.1016/0304-4149(92)90032-L; PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875; Pollard D., 1984, CONVERGENCE STOCHAST; REAVEN GM, 1979, DIABETOLOGIA, V16, P17, DOI 10.1007/BF00423145; RIPLEY BD, 1994, J ROY STAT SOC B MET, V56, P409; Ripley BD, 1996, PATTERN RECOGNITION; Rousseeuw PJ, 1996, APPL STAT-J ROY ST C, V45, P516, DOI 10.2307/2986073; Rousseeuw PJ, 1999, J AM STAT ASSOC, V94, P388, DOI 10.2307/2670155; Rousseeuw PJ, 1998, STAT COMPUT, V8, P193, DOI 10.1023/A:1008945009397; SANTNER TJ, 1986, BIOMETRIKA, V73, P755; Serfling R., 2002, STAT DATA ANAL BASED, P25; Serfling R. J., 1980, APPROXIMATION THEORE; Tukey J.W., 1975, P INT C MATH, V2, P523; Vapnik V., 1998, STAT LEARNING THEORY; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; Vardi Y, 2000, P NATL ACAD SCI USA, V97, P1423, DOI 10.1073/pnas.97.4.1423; Zhu M, 2003, J COMPUT GRAPH STAT, V12, P101, DOI 10.1198/1061860031220; Zuo YJ, 2000, ANN STAT, V28, P483; Zuo YJ, 2000, ANN STAT, V28, P461	47	21	21	INT STATISTICAL INST	VOORBURG	428 PRINSES BEATRIXLAAN, 2270 AZ VOORBURG, NETHERLANDS	1350-7265	1573-9759		BERNOULLI	Bernoulli	FEB	2005	11	1					1	27		10.3150/bj/1110228239		27	Statistics & Probability	Mathematics	917AO	WOS:000228428400001		
J	del Pozo, JAF; Bielza, C; Gomez, M				del Pozo, JAF; Bielza, C; Gomez, M			A list-based compact representation for large decision tables management	EUROPEAN JOURNAL OF OPERATIONAL RESEARCH			English	Article; Proceedings Paper	19th EURO Summer Institute on Decision Analysis and Artificial Intelligence	SEP 09-21, 2001	Toulouse, FRANCE			combinatorial optimisation; decision analysis; decision support systems; heuristics; learning and explanation	INFLUENCE DIAGRAMS	Due to the huge size of the tables we manage when dealing with real decision-making problems under uncertainty, we propose turning them into minimum storage space multidimensional matrices. The process involves searching for the best order of the matrix dimensions, which is a NP-hard problem. Moreover, during the search, the computation of the new storage space that each order requires and copying the table with respect to the new order may be too time consuming or even intractable if we want a process to work in a reasonable time on an ordinary PC. In this paper, we provide efficient heuristics to solve all these problems. The optimal table includes the same knowledge as the original table, but it is compacted, which is very valuable for knowledge retrieval, learning and expert reasoning explanation purposes. (C) 2003 Elsevier B.V. All rights reserved.	Tech Univ Madrid, Decis Anal Grp, Artificial Intelligence Dept, Madrid 28660, Spain; Univ Granada, Comp Sci & Artificial Intelligence Dept, E-18071 Granada, Spain	del Pozo, JAF (reprint author), Tech Univ Madrid, Decis Anal Grp, Artificial Intelligence Dept, Campus Montegancedo, Madrid 28660, Spain.	jafernandez@fi.upm.es; mcbielza@fi.upm.es; mgomez@decsai.ugr.es	Gomez-Olmedo, Manuel/C-2415-2012; Bielza, Concha/F-9277-2013	Gomez-Olmedo, Manuel/0000-0002-3817-8723; Bielza, Concha/0000-0001-7109-2668			ALANDER JT, 1992, COMPUTER SYSTEMS AND SOFTWARE ENGINEERING, P65, DOI 10.1109/CMPEUR.1992.218485; Bielza C, 2000, COMPUT OPER RES, V27, P725, DOI 10.1016/S0305-0548(99)00113-6; Boutilier C, 1996, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P115; Breiman L., 1993, CLASSIFICATION REGRE; DELPOZO JAF, 2001, LECT NOTES COMPUTER, V2199, P88; DELPOZO JAF, 2002, ADV ARTIFICIAL INTEL, V2527, P254; Duda R.O., 2001, PATTERN CLASSIFICATI; Ezawa KJ, 1998, OPER RES, V46, P73, DOI 10.1287/opre.46.1.73; Fagiuoli E, 1998, INT J APPROX REASON, V19, P351, DOI 10.1016/S0888-613X(98)10015-4; Fayyad U.M., 1996, ADV KNOWLEDGE DISCOV, P1; Hand David J, 2001, PRINCIPLES DATA MINI; Hastie T., 2001, ELEMENTS STAT LEARNI; HENRION M, 1991, AI MAG, V12, P64; Keeney R.L., 1993, DECISIONS MULTIPLE O; Kirkpatrick S, 1983, SCIENCE, V220, P621; KNUTH D, 1968, ART COMPUTER PROGRAM, V1; Lauritzen SL, 2001, MANAGE SCI, V47, P1235, DOI 10.1287/mnsc.47.9.1235.9779; Mannila H., 2000, SIGKDD EXPLORATIONS, V1, P30; Mitchell M., 1998, INTRO GENETIC ALGORI; Hansen P, 2001, EUR J OPER RES, V130, P449, DOI 10.1016/S0377-2217(00)00100-4; Nielsen TD, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P502; Pawlak Z, 1997, EUR J OPER RES, V99, P48, DOI 10.1016/S0377-2217(96)00382-7; Pawlak Z., 1991, ROUGH SETS THEORETIC; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Raiffa H, 1968, DECISION ANAL; SHACHTER RD, 1986, OPER RES, V34, P871, DOI 10.1287/opre.34.6.871; VOMVELOVA M, 2002, P 1 EUR WORKSH PROB, P186; Wong S. K. M., 1986, INT J MAN MACH STUD, V24, P53	29	6	6	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0377-2217			EUR J OPER RES	Eur. J. Oper. Res.	FEB 1	2005	160	3					638	662		10.1016/j.ejor.2003.10.005		25	Management; Operations Research & Management Science	Business & Economics; Operations Research & Management Science	858LM	WOS:000224193300005		
J	De Vito, E; Caponnetto, A; Rosasco, L				De Vito, E; Caponnetto, A; Rosasco, L			Model selection for regularized least-squares algorithm in learning theory	FOUNDATIONS OF COMPUTATIONAL MATHEMATICS			English	Article						model selection; optimal choice of parameters; regularized least-squares algorithm	NETWORKS	We investigate the problem of model selection for learning algorithms depending on a continuous parameter. We propose a model selection procedure based on a worst-case analysis and on a data-independent choice of the parameter. For the regularized least-squares algorithm we bound the generalization error of the solution by a quantity depending on a few known constants and we show that the corresponding model selection procedure reduces to solving a bias-variance problem. Under suitable smoothness conditions on the regression function, we estimate the optimal parameter as a function of the number of data and we prove that this choice ensures consistency of the algorithm.	Univ Modena, Dipartimento Matemat, I-41100 Modena, Italy; Ist Nazl Fis Nucl, Sez Genova, I-16146 Genoa, Italy; Univ Genoa, DISI, I-16146 Genoa, Italy; INFM, Sez Genova, I-16146 Genoa, Italy	De Vito, E (reprint author), Univ Modena, Dipartimento Matemat, Via Campi 213-B, I-41100 Modena, Italy.	devito@unimo.it; caponnetto@disi.unige.it; rosasco@disi.unige.it					Alon N, 1997, J ACM, V44, P615, DOI 10.1145/263867.263927; ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI DOI 10.2307/1990404; Bartlett PL, 2002, MACH LEARN, V48, P85, DOI 10.1023/A:1013999503812; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; Cucker F, 2002, B AM MATH SOC, V39, P1; Cucker F, 2002, FOUND COMPUT MATH, V2, P413, DOI 10.1007/s102080010030; Devroye L., 1996, PROBABILISTIC THEORY; Dudley R. M., 2002, REAL ANAL PROBABILIT; Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316; GIROSI F, 1995, NEURAL COMPUT, V7, P219, DOI 10.1162/neco.1995.7.2.219; Hastie T., 2001, ELEMENTS STAT LEARNI; Mendelson S., 2003, Advanced Lectures on Machine Learning. Machine Learning Summer School 2002. Revised Lectures. (Lecture Notes in Artificial Intelligence Vol.2600); Niyogi P., 1999, Advances in Computational Mathematics, V10, DOI 10.1023/A:1018966213079; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Poggio T, 2004, NATURE, V428, P419, DOI 10.1038/nature02341; Rosasco L, 2004, NEURAL COMPUT, V16, P1063, DOI 10.1162/089976604773135104; MCDIARMID C, 1989, LOND MATH S, V141, P148; Smale S, 2003, ANAL APPL, V1, P17, DOI 10.1142/S0219530503000089; STEINWART I, 2002, 0203 U JEN DEP MATH; Taylor JS, 2000, INTRO SUPPORT VECTOR; Vapnik V., 1998, STAT LEARNING THEORY; Wahba G, 1990, SPLINE MODELS OBSERV; Zhang T, 2003, NEURAL COMPUT, V15, P1397, DOI 10.1162/089976603321780326; Zhou DX, 2002, J COMPLEXITY, V18, P739, DOI 10.1006/jcom.2002.0635	24	65	67	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1615-3375	1615-3383		FOUND COMPUT MATH	Found. Comput. Math.	FEB	2005	5	1					59	85		10.1007/s10208-004-0134-1		27	Computer Science, Theory & Methods; Mathematics, Applied; Mathematics	Computer Science; Mathematics	911NS	WOS:000228011900002		
J	Viviani, R; Gron, G; Spitzer, M				Viviani, R; Gron, G; Spitzer, M			Functional principal component analysis of fMRI data	HUMAN BRAIN MAPPING			English	Article						principal component analysis (PCA); functional data analysis; independent component analysis (ICA); multivariate linear models (MLM); explorative methods	GENERALIZED CROSS-VALIDATION; SPATIAL WORKING-MEMORY; BLIND SEPARATION; SPLINE FUNCTIONS; CURVES; MODELS; PET	We describe a principal component analysis (PCA) method for functional magnetic resonance imaging (fMRI) data based on functional data analysis, an advanced nonparametric approach. The data delivered by the fMRI scans are viewed as Continuous functions of time sampled at the interscan interval and subject to observational noise, and are used accordingly to estimate an image in which Smooth functions replace the voxels. The techniques of functional data analysis are used to carry out PCA directly on these functions. We show that functional PCA is more effective than is its ordinary counterpart in recovering the signal of interest, even if limited or no prior knowledge of the form of hemodynamic function or the structure of the experimental design is specified. We discuss the rationale and advantages of the proposed approach relative to other exploratory methods, such as clustering or independent component analysis, as well as the differences from methods based on expanded design matrices. (C) 2004 Wiley-Liss, Inc.	Univ Ulm, Dept Psychiat 3, D-89075 Ulm, Germany	Viviani, R (reprint author), Univ Ulm, Dept Psychiat 3, Leimgrubenweg 12, D-89075 Ulm, Germany.	roberto.viviani@medizin.uni-ulm.de					Anderson T. W., 1984, INTRO MULTIVARIATE S; Ashburner J, 1997, HUMAN BRAIN FUNCTION, P43; BADDELEY A, 1992, SCIENCE, V255, P556, DOI 10.1126/science.1736359; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; BRETT M, 2000, SLICE DISPLAY SOFTWA; CALLICOTT JH, 1999, FUNCTIONAL MRI, P501; Carew JD, 2003, NEUROIMAGE, V18, P950, DOI 10.1016/S1053-8119(03)00013-2; Cohen J D, 1994, Hum Brain Mapp, V1, P293, DOI 10.1002/hbm.460010407; CRAVEN P, 1979, NUMER MATH, V31, P377; de Boor C., 1978, PRACTICAL GUIDE SPLI; DEMMLER A, 1975, NUMER MATH, V24, P375, DOI 10.1007/BF01437406; Desgranges B, 1998, NEUROIMAGE, V8, P198, DOI 10.1006/nimg.1998.0359; Draper NR, 1998, APPL REGRESSION ANAL; Eubank R.L., 1988, SPLINE SMOOTHING NON; FRISTON KJ, 1997, HUMAN BRAIN FUNCTION, P107; Friston KJ, 1994, HUMAN BRAIN MAPPING, V2, P189, DOI DOI 10.1002/HBM.460020402; FRISTON KJ, 1995, NEUROIMAGE, V2, P166, DOI 10.1006/nimg.1995.1019; FRISTON KJ, 1993, J CEREBR BLOOD F MET, V13, P5; Gabrieli JDE, 1998, ANNU REV PSYCHOL, V49, P87, DOI 10.1146/annurev.psych.49.1.87; Green PJ, 1994, NONPARAMETRIC REGRES; Gron G, 2001, LEARN MEMORY, V8, P336, DOI 10.1101/lm.42901; Hastie T., 2001, ELEMENTS STAT LEARNI; HASTIE T, 1995, ANN STAT, V23, P73, DOI 10.1214/aos/1176324456; HOERL AE, 1970, TECHNOMETRICS, V12, P55; HOLMES A, 1997, HUMAN BRAIN FUNCTION, P141; Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; Jolliffe IT, 1986, PRINCIPAL COMPONENT; Kherif F, 2002, NEUROIMAGE, V16, P1068, DOI 10.1006/nimg.2002.1094; KIMELDOR.GS, 1970, ANN MATH STAT, V41, P495, DOI 10.1214/aoms/1177697089; KOLMOGOROV AN, 1968, INTRO REAL ANAL; LEE TW, 1999, NEURAL COMPUT, V10, P2103; McIntosh AR, 1996, NEUROIMAGE, V3, P143, DOI 10.1006/nimg.1996.0016; McKeown MJ, 1998, HUM BRAIN MAPP, V6, P160, DOI 10.1002/(SICI)1097-0193(1998)6:3<160::AID-HBM5>3.0.CO;2-1; Petersson KM, 1999, PHILOS T R SOC B, V354, P1239, DOI 10.1098/rstb.1999.0477; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Press W., 1988, NUMERICAL RECIPES C; Ramsay J. O., 1997, FUNCTIONAL DATA ANAL; Ramsay JO, 2001, FUNCTIONAL DATA ANAL; RAO CR, 1958, BIOMETRICS, V14, P1, DOI 10.2307/2527726; RICE JA, 1991, J ROY STAT SOC B MET, V53, P233; SCHOENBERG IJ, 1964, P NATL ACAD SCI USA, V52, P947, DOI 10.1073/pnas.52.4.947; Talairach J., 1998, COPLANAR STEREOTAXIC; TURNER R, 1997, HUMAN BRAIN FUNCTION, P467; Wahba G, 1990, SPLINE MODELS OBSERV; Walter H, 2003, CORTEX, V39, P897, DOI 10.1016/S0010-9452(08)70869-4; Walter H, 2003, SCHIZOPHR RES, V61, P175, DOI 10.1016/S0920-9964(02)00225-6; WISMULLER A, 2002, INT J COMPUT VISION, V46, P102; Worsley KJ, 1997, NEUROIMAGE, V6, P305, DOI 10.1006/nimg.1997.0294	48	41	42	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	1065-9471			HUM BRAIN MAPP	Hum. Brain Mapp.	FEB	2005	24	2					109	129		10.1002/hbm.20074		21	Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical Imaging	Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging	892VC	WOS:000226677100004	15468155	
J	Villacci, D; Bontempi, G; Vaccaro, A; Birattari, M				Villacci, D; Bontempi, G; Vaccaro, A; Birattari, M			The role of learning methods in the dynamic assessment of power components loading capability	IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS			English	Article						intelligent systems; learning systems; power system monitoring; power transformers protection	THERMAL OVERLOAD PROTECTION; MODEL	The need for dynamic loading of power components in the deregulated electricity market demands reliable assessment models that should be able to predict the thermal behavior when the load exceeds the nameplate value. When assessing network load capability, the hot-spot temperature of the components is known to be the most critical factor. The knowledge of the evolution of the hot-spot temperature during overload conditions is essential to evaluate the loss of insulation life and to evaluate the consequent risks of both technical and economical nature. This paper discusses an innovative grey-box architecture for integrating physical knowledge modeling (a.k.a. white-box) with machine learning techniques (a.k.a. black-box). In particular, we focus on the problem of forecasting the hot-spot temperature of a mineral-oil-immersed transformer. We perform a set of experiments and we compare the predictions obtained by the grey-, white-, and black-box approaches.	Univ Sannio, Dept Engn, Power Syst Res Grp, I-82100 Benevento, Italy; Free Univ Brussels, Dept Informat, B-1050 Brussels, Belgium; Free Univ Brussels, IRIDIA, B-1050 Brussels, Belgium	Villacci, D (reprint author), Univ Sannio, Dept Engn, Power Syst Res Grp, I-82100 Benevento, Italy.	villacci@unisannio.it; gbonte@ulb.ac.be; mbiro@ulb.ac.be	Birattari, Mauro/D-2597-2009	Birattari, Mauro/0000-0003-3309-2194			Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; BERTOLISSI E, 2001, FUZZY SETS SYST, V28, P3; Birattari M., 1999, LAZY LEARNING TOOLBO; Birattari M, 1999, ADV NEUR IN, V11, P375; Bontempi G, 2001, FUZZY SET SYST, V121, P59, DOI 10.1016/S0165-0114(99)00172-4; BONTEMPI G, 1999, P EUFIT 99; BONTEMPI G, 1999, MACH LEARN, V1, P32; Bontempi G, 2000, AI COMMUN, V13, P41; Bontempi G., 1999, THESIS U LIBRE BRUXE; BUONANNO G, 1995, IEE P-GENER TRANSM D, V142, P436, DOI 10.1049/ip-gtd:19951956; Daponte P., 1996, Measurement, V18, DOI 10.1016/0263-2241(96)00043-7; Galdi V, 2001, ELECTR POW SYST RES, V60, P107, DOI 10.1016/S0378-7796(01)00173-0; Galdi V, 2001, IEE P-ELECT POW APPL, V148, P163, DOI 10.1049/ip-epa:20010086; Galdi V, 2000, IEE P-ELECT POW APPL, V147, P415, DOI 10.1049/ip-epa:20000519; HANNAN E, 1998, EARTH ISL J, V13, P2; Hastie T., 2001, ELEMENTS STAT LEARNI; *IEE STD, 1993, CALC BAR OV COND TEM, P783; *IEEE STD, GUID LOAD MIN OIL IM; LINDSKOG P, 1995, INT J ADAPT CONTROL, V9, P509, DOI 10.1002/acs.4480090605; Ljung L., 1987, SYSTEM IDENTIFICATIO; LOSI A, 1993, P POW SYST C TEHR IR, P416; LYALL JS, 2000, P POW ENG SOC SUMM M, P457; Mitchell T., 1997, MACHINE LEARNING; Nokes G, 1999, POWER ENG J, V13, P291, DOI 10.1049/pe:19990608; *STUD COMM 23 CIGR, 2002, ELECTRA, P63; Swift GW, 2001, IEEE T POWER DELIVER, V16, P516, DOI 10.1109/61.956730; VANDERVEKEN W, 2001, P IEEE PES TRANSMISS, P147; WILLIAMS JA, 1999, P IEEE PES TRANSM DI, P128	28	14	14	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0278-0046			IEEE T IND ELECTRON	IEEE Trans. Ind. Electron.	FEB	2005	52	1					280	290		10.1109/TIE.2004.841072		11	Automation & Control Systems; Engineering, Electrical & Electronic; Instruments & Instrumentation	Automation & Control Systems; Engineering; Instruments & Instrumentation	893YB	WOS:000226755900032		
J	Kang, YS; Weber, KD; Yu, Q; Kiley, PJ; Blattner, FR				Kang, YS; Weber, KD; Yu, Q; Kiley, PJ; Blattner, FR			Genome-wide expression analysis indicates that FNR of Escherichia coli K-12 regulates a large number of genes of unknown function	JOURNAL OF BACTERIOLOGY			English	Article							LAC OPERON FUSIONS; TRANSCRIPTIONAL REGULATION; NUCLEOTIDE-SEQUENCE; ANAEROBIC REGULATION; AEROBIC REGULATION; SALMONELLA-TYPHIMURIUM; COORDINATE REGULATION; TRANSPORT-SYSTEM; ADHE GENE; OXYGEN	The major regulator controlling the physiological switch between aerobic and anaerobic growth conditions in Escherichia coli is the DNA binding protein FNR. To identify genes controlled by FNR, we used Affymetrix Antisense GeneChips to compare global gene expression profiles from isogenic MG1655 wild-type and Deltafnr strains grown in glucose minimal media under aerobic or anaerobic conditions. We found that 297 genes contained within 184 operons were regulated by FNR and/or by O-2 levels. The expression of many genes known to be involved in anaerobic respiration and fermentation was increased under anaerobic growth conditions, while that of genes involved in aerobic respiration and the tricarboxylic acid cycle were repressed as expected. The expression of nine operons associated with acid resistance was also increased under anaerobic growth conditions, which may reflect the production of acidic fermentation products. Ninety-one genes with no presently defined function were also altered in expression, including seven of the most highly anaerobically induced genes, six of which we found to be directly regulated by FNR. Classification of the 297 genes into eight groups by k-means clustering analysis indicated that genes with common gene expression patterns also had a strong functional relationship, providing clues for studying the function of unknown genes in each group. Six of the eight groups showed regulation by FNR; while some expression groups represent genes that are simply activated or repressed by FNR, others, such as those encoding functions for chemotaxis and motility, showed a more complex pattern of regulation. A computer search for FNR DNA binding sites within predicted promoter regions identified 63 new sites for 54 genes. We suggest that E. coli MG1655 has a larger metabolic potential under anaerobic conditions than has been previously recognized.	Univ Wisconsin, Dept Genet, Madison, WI 53706 USA; Univ Wisconsin, Dept Biomol Chem, Madison, WI 53706 USA	Blattner, FR (reprint author), Univ Wisconsin, Dept Genet, 425 Henry Hall, Madison, WI 53706 USA.	fred@genome.wisc.edu					Alexeeva S, 2000, J BACTERIOL, V182, P4934, DOI 10.1128/JB.182.17.4934-4940.2000; ANDREWS JC, 1986, J BACTERIOL, V165, P434; BHRIAIN NN, 1989, MOL MICROBIOL, V3, P933, DOI 10.1111/j.1365-2958.1989.tb00243.x; BILOUS PT, 1988, MOL MICROBIOL, V2, P785, DOI 10.1111/j.1365-2958.1988.tb00090.x; BIRKMANN A, 1987, ARCH MICROBIOL, V148, P44, DOI 10.1007/BF00429646; Blankenhorn D, 1999, J BACTERIOL, V181, P2209; Blattner FR, 1997, SCIENCE, V277, P1453, DOI 10.1126/science.277.5331.1453; Bockhorst J, 2003, BIOINFORMATICS, V19, pi34, DOI 10.1093/bioinformatics/btg1003; BOLIVAR F, 1977, GENE, V2, P95; CALHOUN MW, 1993, J BACTERIOL, V175, P3013; Casado C, 1991, FEMS Microbiol Lett, V67, P153; Cavicchioli R, 1996, J BACTERIOL, V178, P6968; CECCHINI G, 1986, P NATL ACAD SCI USA, V83, P8898, DOI 10.1073/pnas.83.23.8898; CHANG YY, 1994, MOL MICROBIOL, V11, P1019, DOI 10.1111/j.1365-2958.1994.tb00380.x; Chao GL, 1997, J BACTERIOL, V179, P4299; CHEN YM, 1991, J BACTERIOL, V173, P8009; COLE ST, 1988, J BACTERIOL, V170, P2448; Cotter P A, 1992, FEMS Microbiol Lett, V70, P31; Cotter PA, 1997, MOL MICROBIOL, V25, P605, DOI 10.1046/j.1365-2958.1997.5031860.x; Cunningham L, 1998, MICROBIOL-UK, V144, P2113; Cunningham L, 1997, MICROBIOL-UK, V143, P3795; Datsenko KA, 2000, P NATL ACAD SCI USA, V97, P6640, DOI 10.1073/pnas.120163297; EIGLMEIER K, 1989, MOL MICROBIOL, V3, P869, DOI 10.1111/j.1365-2958.1989.tb00236.x; ERICKSON JW, 1989, GENE DEV, V3, P1462, DOI 10.1101/gad.3.9.1462; FELLAY R, 1987, GENE, V52, P147, DOI 10.1016/0378-1119(87)90041-2; Georgellis D, 2001, SCIENCE, V292, P2314, DOI 10.1126/science.1059361; Green J, 1998, MOL MICROBIOL, V29, P1113, DOI 10.1046/j.1365-2958.1998.01002.x; Green J, 1996, MOL MICROBIOL, V19, P125, DOI 10.1046/j.1365-2958.1996.353884.x; GUNSALUS RP, 1994, RES MICROBIOL, V145, P437, DOI 10.1016/0923-2508(94)90092-2; Hartigan J.A., 1975, CLUSTERING ALGORITHM; HASSAN HM, 1992, P NATL ACAD SCI USA, V89, P3217, DOI 10.1073/pnas.89.8.3217; Hastie T., 2001, ELEMENTS STAT LEARNI; Hughes JD, 2000, J MOL BIOL, V296, P1205, DOI 10.1006/jmbi.2000.3519; Ihssen J, 2004, MICROBIOL-SGM, V150, P1637, DOI 10.1099/mic.0.26849-0; Imlay JA, 2002, ADV MICROB PHYSIOL, V46, P111, DOI 10.1016/S0065-2911(02)46003-1; JAYARAMAN PS, 1989, NUCLEIC ACIDS RES, V17, P135, DOI 10.1093/nar/17.1.135; JONES HM, 1985, J BACTERIOL, V164, P1100; Kaiser M, 1997, MICROBIOL-UK, V143, P775; KAMMLER M, 1993, J BACTERIOL, V175, P6212; Kiley PJ, 2003, CURR OPIN MICROBIOL, V6, P181, DOI 10.1016/S1369-5274(03)00039-0; Kim SJ, 1999, IUBMB LIFE, V48, P215, DOI 10.1080/713803496; KOLESNIKOW T, 1992, J BACTERIOL, V174, P7104; KWAN HS, 1988, MOL GEN GENET, V211, P183, DOI 10.1007/BF00338411; Lacourciere GM, 2002, P NATL ACAD SCI USA, V99, P9150, DOI 10.1073/pnas.142291199; Lamark T, 1996, J BACTERIOL, V178, P1655; Lamberg KE, 2000, MOL MICROBIOL, V38, P817, DOI 10.1046/j.1365-2958.2000.02172.x; Lee JH, 2004, MOL MICROBIOL, V51, P1745, DOI 10.1111/j.1365-2958.2003.03946.x; LEONARDO MR, 1993, J BACTERIOL, V175, P870; Li B, 1998, NUCLEIC ACIDS RES, V26, P2075, DOI 10.1093/nar/26.9.2075; LI J, 1992, J BACTERIOL, V174, P4935; LI SF, 1987, J BACTERIOL, V169, P4614; Liu XQ, 2004, J BIOL CHEM, V279, P12588, DOI 10.1074/jbc.M313454200; Loewen PC, 1998, CAN J MICROBIOL, V44, P707, DOI 10.1139/cjm-44-8-707; Lubitz SP, 2003, ARCH BIOCHEM BIOPHYS, V418, P205, DOI 10.1016/j.abb.2003.08.008; LUTZ S, 1991, MOL MICROBIOL, V5, P123, DOI 10.1111/j.1365-2958.1991.tb01833.x; Melville SB, 1996, P NATL ACAD SCI USA, V93, P1226, DOI 10.1073/pnas.93.3.1226; MELVILLE SB, 1990, J BIOL CHEM, V265, P18733; Meng WM, 1997, MICROBIOL-UK, V143, P1521; Messenger SL, 2003, FEMS MICROBIOL LETT, V228, P81, DOI 10.1016/S0378-1097(03)00726-2; Miller JH, 1972, EXPT MOL GENETICS; NAVARRO C, 1993, MOL MICROBIOL, V9, P1181, DOI 10.1111/j.1365-2958.1993.tb01247.x; PAGE L, 1990, ARCH MICROBIOL, V154, P349; PARK SJ, 1995, J BACTERIOL, V177, P6652; PARK SJ, 1995, J BACTERIOL, V177, P6255; PARK SJ, 1994, J BACTERIOL, V176, P5086; Park SJ, 1997, J BACTERIOL, V179, P4138; Patschkowski T, 2000, BACTERIAL STRESS RESPONSES, P61; Pellicer MT, 1999, MOL GEN GENET, V261, P170; Peters JE, 2003, J BACTERIOL, V185, P2017, DOI 10.1128/JB.185.6.2017-2021.2003; QUAIL MA, 1994, MOL MICROBIOL, V12, P95, DOI 10.1111/j.1365-2958.1994.tb00998.x; Richard DJ, 1999, MICROBIOL-SGM, V145, P2903; Rosenow C, 2001, NUCLEIC ACIDS RES, V29, part. no., DOI 10.1093/nar/29.22.e112; Salmon K, 2003, J BIOL CHEM, V278, P29837, DOI 10.1074/jbc.M213060200; SAWERS G, 1988, J BACTERIOL, V170, P5330; SAWERS RG, 1988, ARCH MICROBIOL, V149, P240, DOI 10.1007/BF00422011; SCHELLHORN HE, 1988, J BACTERIOL, V170, P4286; SERRSE MH, 2001, GENOME BIOL, V2; SIMONS RW, 1987, GENE, V53, P85, DOI 10.1016/0378-1119(87)90095-3; SIX S, 1994, J BACTERIOL, V176, P6470; Sledjeski DD, 1996, EMBO J, V15, P3993; Soupene E, 2003, J BACTERIOL, V185, P5611, DOI 10.1128/JB.185.18.5611-5626.2003; SPIRO S, 1987, J GEN MICROBIOL, V133, P3279; SPIRO S, 1991, TRENDS BIOCHEM SCI, V16, P310, DOI 10.1016/0968-0004(91)90125-F; Stewart V, 2002, J BACTERIOL, V184, P1314, DOI 10.1128/JB.184.5.1314-1323.2002; Stewart V, 2003, BIOCHEM SOC T, V31, P1; Storey JD, 2003, P NATL ACAD SCI USA, V100, P9440, DOI 10.1073/pnas.1530509100; Storz G, 2000, BACTERIAL STRESS RES; STRAUCH KL, 1985, J BACTERIOL, V161, P673; SUN XY, 1993, P NATL ACAD SCI USA, V90, P577, DOI 10.1073/pnas.90.2.577; SUPPMANN B, 1994, MOL MICROBIOL, V11, P965, DOI 10.1111/j.1365-2958.1994.tb00375.x; Tucker DL, 2002, J BACTERIOL, V184, P6551, DOI 10.1128/JB.184.23.6551-6558.2002; TYSON KL, 1994, MOL MICROBIOL, V13, P1045, DOI 10.1111/j.1365-2958.1994.tb00495.x; Unden G, 2002, J MOL MICROB BIOTECH, V4, P263; Unden G, 1997, BBA-BIOENERGETICS, V1320, P217, DOI 10.1016/S0005-2728(97)00034-0; van der Rest ME, 2000, J BACTERIOL, V182, P6892, DOI 10.1128/JB.182.24.6892-6899.2000; YAMADA M, 1993, J BACTERIOL, V175, P568	96	133	141	AMER SOC MICROBIOLOGY	WASHINGTON	1752 N ST NW, WASHINGTON, DC 20036-2904 USA	0021-9193			J BACTERIOL	J. Bacteriol.	FEB	2005	187	3					1135	1160		10.1128/JB.187.3.1135-1160.2005		26	Microbiology	Microbiology	893FR	WOS:000226705200033	15659690	
J	Kristensen, NR; Madsen, H; Ingwersen, SH				Kristensen, NR; Madsen, H; Ingwersen, SH			Using stochastic differential equations for PK/PD model development	JOURNAL OF PHARMACOKINETICS AND PHARMACODYNAMICS			English	Article						stochastic differential equations; parameter estimation; extended Kalman filtering; smoothing; random walk; nonparametric modelling	GREY-BOX MODELS	A method for PK/PD model development based on stochastic differential equation models is proposed. The new method has a number of advantages compared to conventional methods. In particular, the new method avoids the exhaustive trial-and-error based search often conducted to determine the most appropriate model structure, because it allows information about the appropriate model structure to be extracted directly from data. This is accomplished through quantification of the uncertainty of the individual parts of an initial model, by means of which tools for performing model diagnostics can be constructed and guidelines for model improvement provided. Furthermore, the new method allows time-variations in key parameters to be tracked and visualized graphically, which allows important functional relationships to be revealed. Using simulated data, the performance of the new method is demonstrated by means of two examples. The first example shows how, starting from a simple assumption of linear PK, the method can be used to determine the correct nonlinear model for describing the PK of a drug following an oral dose. The second example shows how, starting from a simple assumption of no drug effect, the method can be used to determine the correct model for the nonlinear effect of a drug with known PK in an indirect response model.	Novo Nordisk AS, Pharmacokinet & Biomodelling, DK-2760 Malov, Denmark; Tech Univ Denmark, DK-2800 Lyngby, Denmark	Kristensen, NR (reprint author), Novo Nordisk AS, Pharmacokinet & Biomodelling, Novo Nordisk Pk, DK-2760 Malov, Denmark.	nikr@novonordisk.com					Cobelli C, 1980, AM J PHYSIOL, V239, P7; DeNicolao G, 1997, AUTOMATICA, V33, P851, DOI 10.1016/S0005-1098(96)00254-3; Gelb A., 1974, APPL OPTIMAL ESTIMAT; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T, 1990, GEN ADDITIVE MODELS; Jazwinski A. H., 1970, STOCHASTIC PROCESSES; JONSSON EN, 2000, AAPS PHARM SCI, V2; Karlsson MO, 1995, J PHARMACOKINET BIOP, V23, P651, DOI 10.1007/BF02353466; Kloeden P., 1992, NUMERICAL SOLUTION S; Kotz S., 1985, ENCY STAT SCI; Kristensen N. R., 2003, CONTINUOUS TIME STOC; Kristensen NR, 2004, COMPUT CHEM ENG, V28, P1431, DOI 10.1016/j.compchemeng.2003.10.003; Kristensen NR, 2004, AUTOMATICA, V40, P225, DOI 10.1016/j.automatica.2003.10.001; Oksendal B., 1998, STOCHASTIC DIFFERENT; OVERGAARD RV, 2005, IN PRESS J PHARMACOK; *PHARS CORP, 2002, WINNONLIN 4 0 EX GUI; *PHARS CORP, 2002, WINNONLIN 4 0 REF GU; SPARACINO G, 2001, COMPUTER MED PROGRAM, V67, P67; Tornoe CW, 2005, PHARM RES, V22, P1247, DOI 10.1007/s11095-005-5269-5	19	20	21	SPRINGER/PLENUM PUBLISHERS	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1567-567X			J PHARMACOKINET PHAR	J. Pharmacokinet. Pharmacodyn.	FEB	2005	32	1					109	141		10.1007/s10928-005-2105-9		33	Pharmacology & Pharmacy	Pharmacology & Pharmacy	980UL	WOS:000233043600005	16215845	
J	Mierswa, I; Morik, K				Mierswa, I; Morik, K			Automatic feature extraction for classifying audio data	MACHINE LEARNING			English	Article						analysis of audio data; feature extraction; time series transformations; music recommender systems	RETRIEVAL	Today, many private households as well as broadcasting or film companies own large collections of digital music plays. These are time series that differ from, e.g., weather reports or stocks market data. The task is normally that of classification, not prediction of the next value or recognizing a shape or motif. New methods for extracting features that allow to classify audio data have been developed. However, the development of appropriate feature extraction methods is a tedious effort, particularly because every new classification task requires tailoring the feature set anew. This paper presents a unifying framework for feature extraction from value series. Operators of this framework can be combined to feature extraction methods automatically, using a genetic programming approach. The construction of features is guided by the performance of the learning classifier which uses the features. Our approach to automatic feature extraction requires a balance between the completeness of the methods on one side and the tractability of searching for appropriate methods on the other side. In this paper, some theoretical considerations illustrate the trade-off. After the feature extraction, a second process learns a classifier from the transformed data. The practical use of the methods is shown by two types of experiments: classification of genres and classification according to user preferences.	Univ Dortmund, Artificial Intelligence Unit, Dortmund, Germany	Mierswa, I (reprint author), Univ Dortmund, Artificial Intelligence Unit, Dortmund, Germany.						Back T., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585888; COOLEY JW, 1965, MATH COMPUT, V19, P297, DOI 10.2307/2003354; DROSTE S, 1998, 2198 531 CI SFB; FISCHER S, 2002, 13602 531 CI SFB; Ghias A., 1995, P ACM MULT, P231, DOI 10.1145/217279.215273; Guo GD, 2003, IEEE T NEURAL NETWOR, V14, P209, DOI 10.1109/TNN.2002.806626; Hastie T., 2001, ELEMENTS STAT LEARNI; Holland J. H., 1986, MACHINE LEARNING ART, V2, P593; Jayant N. S., 1984, DIGITAL CODING WAVEF; Joachims T., 2002, LEARNING CLASSIFY TE; Kahveci T., 2001, P 27 VLDB; Keogh E. J., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Keogh E., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; KLINKENBERG R, 2004, IN PRESS SPECIAL ISS, V8, P3; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; KOZA JR, 1992, GENETIC PROGR PROGR; KURTH F, 2001, 110 CONV AUD ENG SOC; LIU Z, 1998, J VLSI SIGNAL PROCES; LOY G, 1989, COMPUT MUSIC J, V9, P4; Morik K, 1999, MAKING ROBOTS SMARTER, P185; PICKENS J, 1996, SURVEY FEATURE SELEC; Ruping S., 2000, MYSVM MANUAL, P8; Takens F., 1980, DYNAMICAL SYSTEMS TU, V898, P366; Tzanetakis G., 2001, P INT S MUS INF RETR, P205; TZANETAKIS G, 2002, THESIS PRINCETION U; Yi BK, 1998, PROC INT CONF DATA, P201; ZHANG T, 1998, SPIE 43 ANN M C ADV	27	36	37	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	FEB-MAR	2005	58	2-3					127	149		10.1007/s10994-005-5824-7		23	Computer Science, Artificial Intelligence	Computer Science	904CS	WOS:000227474300003		
J	Wang, DL; Huang, J; Xie, HH; Manzella, L; Soares, MB				Wang, DL; Huang, J; Xie, HH; Manzella, L; Soares, MB			A robust two-way semi-linear model for normalization of cDNA microarray data	BMC BIOINFORMATICS			English	Article								Background: Normalization is a basic step in microarray data analysis. A proper normalization procedure ensures that the intensity ratios provide meaningful measures of relative expression values. Methods: We propose a robust semiparametric method in a two- way semi- linear model ( TWSLM) for normalization of cDNA microarray data. This method does not make the usual assumptions underlying some of the existing methods. For example, it does not assume that: ( i) the percentage of differentially expressed genes is small; or ( ii) the numbers of up- and down- regulated genes are about the same, as required in the LOWESS normalization method. We conduct simulation studies to evaluate the proposed method and use a real data set from a specially designed microarray experiment to compare the performance of the proposed method with that of the LOWESS normalization approach. Results: The simulation results show that the proposed method performs better than the LOWESS normalization method in terms of mean square errors for estimated gene effects. The results of analysis of the real data set also show that the proposed method yields more consistent results between the direct and the indirect comparisons and also can detect more differentially expressed genes than the LOWESS method. Conclusions: Our simulation studies and the real data example indicate that the proposed robust TW- SLM method works at least as well as the LOWESS method and works better when the underlying assumptions for the LOWESS method are not satisfied. Therefore, it is a powerful alternative to the existing normalization methods.	Univ Alabama, Ctr Comprehens Canc, Biostat & Bioinformat Unit, Birmingham, AL 35294 USA; Univ Iowa, Dept Stat & Actuarial Sci, Iowa City, IA 52242 USA; Univ Iowa, Program Publ Hlth Genet, Iowa City, IA 52242 USA; Univ Iowa, Dept Pediat, Iowa City, IA 52242 USA; Univ Iowa, Dept Biochem, Iowa City, IA 52242 USA; Univ Iowa, Dept Orthopaed, Iowa City, IA 52242 USA; Univ Iowa, Dept Physiol & Biophys, Iowa City, IA 52242 USA	Huang, J (reprint author), Univ Alabama, Ctr Comprehens Canc, Biostat & Bioinformat Unit, Birmingham, AL 35294 USA.	deli.wang@ccc.uab.edu; jian@stat.uiowa.edu; hehuang-xie@uiowa.edu; liliana-manzella@uiowa.edu; bento-soares@uiowa.edu					Abramowitz M., 1974, HDB MATH FUNCTIONS F; Balagurunathan Y, 2002, J BIOMED OPT, V7, P507, DOI 10.1117/1.1486246; Bilban Martin, 2002, Current Issues in Molecular Biology, V4, P57; Brown PO, 1999, NAT GENET, V21, P33, DOI 10.1038/4462; Chen Y, 1997, J Biomed Opt, V2, P364, DOI 10.1117/1.429838; CLEVELAND WS, 1979, J AM STAT ASSOC, V74, P829, DOI 10.2307/2286407; de Boor C., 1978, PRACTICAL GUIDE SPLI; FAN J, 2005, IN PRESS J AM STAT A; Fan JQ, 2004, P NATL ACAD SCI USA, V101, P1135, DOI 10.1073/pnas.0307557100; Hastie T., 2001, ELEMENTS STAT LEARNI; Hedge P., 2000, BIOTECHNIQUES, V29, P548; HUANG J, 2005, IN PRESS J AM STAT A; Huber P., 1981, ROBUST STAT; HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732; KEPLER TB, 2002, GENOME BIOL, V3, P1; Park T, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-33; Quackenbush J, 2002, NAT GENET, V32, P496, DOI 10.1038/ng1032; SCHENA M, 1995, SCIENCE, V270, P467, DOI 10.1126/science.270.5235.467; Tseng GC, 2001, NUCLEIC ACIDS RES, V29, P2549, DOI 10.1093/nar/29.12.2549; Wang Y, 2002, IEEE T INF TECHNOL B, V6, P29; Wolfinger RD, 2001, J COMPUT BIOL, V8, P625, DOI 10.1089/106652701753307520; Workman C, 2002, GENOME BIOL, V3, P1; XIE H, 2004, PROBE SET COMMON REF; YANG YH, 2001, MICROARRAYS OPTICAL, V4266	24	13	15	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	JAN 21	2005	6								14	10.1186/1471-2105-6-14		22	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	900CT	WOS:000227193700001	15663789	
J	Shanmugasundaram, V; Maggiora, GM; Lajiness, MS				Shanmugasundaram, V; Maggiora, GM; Lajiness, MS			Hit-directed nearest-neighbor searching	JOURNAL OF MEDICINAL CHEMISTRY			English	Article							SEQUENTIAL SCREENING PROCESS; COMPOUND SELECTION; DIVERSITY ANALYSIS; BCUT DESCRIPTORS; LIBRARY DESIGN; DATA FUSION; COMBINATION; INHIBITORS; METRICS; QSAR	This work describes a practical strategy used at Pharmacia for identifying compounds for follow-up screening following an initial HTS campaign against targets where no 3-D structural information is available and preliminary SAR models do not exist. The approach explicitly takes into account different representations of chemistry space and identifies compounds for follow-up screening that are likely to provide the best overall coverage of the chemistry spaces considered. Specifically, the work employs hit-directed nearest-neighbor (HDNN) searching of compound databases based upon a set of "probe compounds" obtained as hits in the preliminary high-throughput screens. Four different molecular representations that generate nearly unique chemistry spaces are used. The representations include 3-D, 2-D, 2-D topological BCUTs (2-DT) and molecular fingerprints derived from substructural fragments. In the case of the BCUT representations the NN searching is distance based, while in the case of molecular fingerprints a similarity-based measure is used. Generally, the results obtained differ significantly among all four methods, that is, the sets of NN compounds have surprisingly little overlap. Moreover, in all of the four chemistry space representations, a minimum of 3- to 4-fold enrichment in actives over random screening is observed even though the actives identified in each of the sets of NNs are in large measure unique. These results suggest that use of multiple searches based upon a variety of molecular representations provides an effective way of identifying more hits in HDNN searches of chemistry spaces than can be realized with single searches.	Pharmacia Corp, Struct & Computat Chem, Kalamazoo, MI 49007 USA	Shanmugasundaram, V (reprint author), Pfizer Global Res & Dev, Comp Assisted Drug Discovery, 2800 Plymouth Rd, Ann Arbor, MI 48105 USA.	Veerabahu.Shanmugasundaram@pfizer.com					Bajorath Jürgen, 2002, Nat Rev Drug Discov, V1, P882, DOI 10.1038/nrd941; Beno BR, 2001, DRUG DISCOV TODAY, V6, P251, DOI 10.1016/S1359-6446(00)01665-2; BURDEN FR, 1989, J CHEM INF COMP SCI, V29, P225, DOI 10.1021/ci00063a011; DEAN P.M., 1994, MOL SIMILARITY DRUG; Engels MFM, 2000, J CHEM INF COMP SCI, V40, P241, DOI 10.1021/ci990435; Gao H, 2001, J CHEM INF COMP SCI, V41, P402, DOI 10.1021/ci000306p; Ginn CMR, 2000, PERSPECT DRUG DISCOV, V20, P1, DOI 10.1023/A:1008752200506; Guner OF, 2000, PHARMACOPHORE PERCEP; HAGADONE T. R., 1993, P 2 INT CHEM STRUCT, P257; Hastie T., 2001, ELEMENTS STAT LEARNI; Jenkins JL, 2003, PROTEINS, V50, P81, DOI 10.1002/prot.10270; Johnson M. A., 1990, CONCEPTS APPL MOL SI; Jones-Hertzog DK, 1999, J PHARMACOL TOXICOL, V42, P207, DOI 10.1016/S1056-8719(00)00073-3; Lajiness MS, 1997, PERSPECT DRUG DISCOV, V7-8, P65; LEACH A, 2003, INTRO CHEMINFORMATIC; Lyne PD, 2002, DRUG DISCOV TODAY, V7, P1047, DOI 10.1016/S1359-6446(02)02483-2; Maggiora G.M., 2004, CHEMINFORMATICS ASPE, P317; Maggiora Gerald M, 2004, Methods Mol Biol, V275, P1; Martin YC, 2002, J MED CHEM, V45, P4350, DOI 10.1021/jm020155c; Menard PR, 1998, J CHEM INF COMP SCI, V38, P1204, DOI 10.1021/ci9801062; PEARLMAN R. S., 1995, DIVERSE SOLUTIONS US; Pearlman RS, 1999, J CHEM INF COMP SCI, V39, P28, DOI 10.1021/ci980137x; Pearlman RS, 1998, PERSPECT DRUG DISCOV, V9-11, P339, DOI 10.1023/A:1027232610247; Pirard B, 2000, J CHEM INF COMP SCI, V40, P1431, DOI 10.1021/ci000386x; Raymond JW, 2004, J CHEM INF COMP SCI, V44, P601, DOI 10.1021/ci034234o; Salim N, 2003, J CHEM INF COMP SCI, V43, P435, DOI 10.1021/ci025596j; Schnur D, 1999, J CHEM INF COMP SCI, V39, P36, DOI 10.1021/ci980138p; SHANMUGASUNDARA.V, 2001, 222 AM CHEM SOC NAT; SHANMUGASUNDARA.V, 2004, 227 AM CHEM SOC NAT; Sheridan RP, 2002, DRUG DISCOV TODAY, V7, P903, DOI 10.1016/S1359-6446(02)02411-X; Stanton DT, 1999, J CHEM INF COMP SCI, V39, P11, DOI 10.1021/ci980102x; Stanton DT, 1999, J CHEM INF COMP SCI, V39, P21, DOI 10.1021/ci9801015; TOEDSCHINI R, 2000, METHODS PRINCIPLES M, V11, P667; Van Drie JH, 1998, DRUG DISCOV TODAY, V3, P274, DOI 10.1016/S1359-6446(98)01186-6; van Rhee AM, 2003, J CHEM INF COMP SCI, V43, P941, DOI 10.1021/ci034023j; Walters WP, 1998, DRUG DISCOV TODAY, V3, P160, DOI 10.1016/S1359-6446(97)01163-X; Willett P, 1987, SIMILARITY CLUSTERIN	37	41	41	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0022-2623			J MED CHEM	J. Med. Chem.	JAN 13	2005	48	1					240	248		10.1021/jm0493515		9	Chemistry, Medicinal	Pharmacology & Pharmacy	886FS	WOS:000226212900023	15634017	
S	Sampson, DD; Murphy, BW		Voet, M; Willsch, R; Ecke, W; Jones, J; Culshaw, B		Sampson, DD; Murphy, BW			How can optics be used to sense skin cancer?	17th International Conference on Optical Fibre Sensors, Pts 1 and 2	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	17th International Conference on Optical Fibre Sensors	MAY 23-27, 2005	Brugge, BELGIUM	I D FOS Res, Fibre Opt Sensors & Sensing Syst, European Off Aerosp Res & Dev, USAF Res Lab, Network Excellence Micro Opt, SCK CEN, Belgian Nucl Res Ctr, FWO, FNRS, Export Flanders, Flanders Foreign Investment Off, ESF, European Opt Soc, Inst Phys, IEEE, SPIE, Inst Measurement & Control UK, IEEE LEOS, Opt Soc Amer, AMA German Sensor Technol Assoc, DGaO German Soc Appl Opt, OptecNet German Network Competence Opt Photon Technologies, Sensors Web Portal		diffuse reflectance spectroscopy; diffuse reflectance; white light spectroscopy; tissue optics; fiber optics; melanoma; skin cancer	CUTANEOUS MALIGNANT-MELANOMA; SCATTERING SPECTROSCOPY; DIGITAL DERMOSCOPY; LESIONS; DIAGNOSIS; ACCURACY; NEVI; AUTOFLUORESCENCE; DIFFERENTIATION; ULTRAVIOLET	We survey attempts to accurately diagnose skin cancer in vivo and in real time through the use of optics and automatic computation without the intervention of the clinician. Although no system has yet been shown to have such a capability, commercialization of a variety of diagnostic aids has taken place. We describe our own research into the diagnosis of malignant melanoma, the most lethal form of skin cancer, based on the spectroscopy of diffuse white light reflectance collected with a single multimode fiber after delivery with a multimode fiber bundle. Our clinical study, which collected 82 melanomas and 277 lesions in total, highlights the complexity of this challenging application.	Univ Western Australia, Sch Elect Elect & Comp Engn, Opt Biomed Engn Lab, Nedlands, WA 6009, Australia	Sampson, DD (reprint author), Univ Western Australia, Sch Elect Elect & Comp Engn, Opt Biomed Engn Lab, M018,35 Stirling Highway, Nedlands, WA 6009, Australia.		Sampson, David/B-2931-2011	Sampson, David/0000-0001-6724-3873			Abbasi NR, 2004, JAMA-J AM MED ASSOC, V292, P2771, DOI 10.1001/jama.292.22.2771; ANDERSON RR, 1981, J INVEST DERMATOL, V77, P13, DOI 10.1111/1523-1747.ep12479191; Anikijenko P, 2001, J INVEST DERMATOL, V117, P1442, DOI 10.1046/j.0022-202x.2001.01592.x; [Anonymous], COMMUNICATION; Argenziano G, 2001, Lancet Oncol, V2, P443, DOI 10.1016/S1470-2045(00)00422-8; Bafounta ML, 2001, ARCH DERMATOL, V137, P1343; Bechara FG, 2004, SKIN RES TECHNOL, V10, P169, DOI 10.1111/j.1600-0846.2004.00038.x; Bigio IJ, 1997, PHYS MED BIOL, V42, P803, DOI 10.1088/0031-9155/42/5/005; Chwirot BW, 1998, EUR J CANCER, V34, P1730, DOI 10.1016/S0959-8049(98)00210-X; Ebert B, 1998, LASER MED SCI, V13, P204, DOI 10.1007/s101030050075; Elbaum M, 2001, J AM ACAD DERMATOL, V44, P207, DOI 10.1067/mjd.2001.110395; FRITSCH C, 2004, FLUORESCENCE DIAGNOS; Garcia-Uribe A, 2004, APPL OPTICS, V43, P2643, DOI 10.1364/AO.43.002643; GRIN CM, 1990, ARCH DERMATOL, V126, P763, DOI 10.1001/archderm.126.6.763; Gurjar RS, 2001, NAT MED, V7, P1245, DOI 10.1038/nm1101-1245; Hastie T., 2001, ELEMENTS STAT LEARNI; Hoffmann K, 2003, BRIT J DERMATOL, V149, P801, DOI 10.1046/j.1365-2133.2003.05547.x; Jemal A, 2000, J NATL CANCER I, V92, P811, DOI 10.1093/jnci/92.10.811; Konig K, 2003, J BIOMED OPT, V8, P432, DOI 10.1117/1.1577349; Lim HW, 1993, CLIN PHOTOMEDICINE; LOHMANN W, 1991, NATURWISSENSCHAFTEN, V78, P456, DOI 10.1007/BF01134381; MARCHESINI R, 1992, PHOTOCHEM PHOTOBIOL, V55, P515, DOI 10.1111/j.1751-1097.1992.tb04272.x; MARCHESINI R, 1993, SPIE, V2081, P168; Marghoob AA, 2003, J AM ACAD DERMATOL, V49, P777, DOI 10.1067/S0190-9622(03)02470-8; McIntosh LM, 2001, J INVEST DERMATOL, V116, P175, DOI 10.1046/j.1523-1747.2001.00212.x; Menzies SW, 2001, ARCH DERMATOL, V137, P1583; Menzies SW, 1996, ATLAS SURFACE MICROS; Moncrieff M, 2002, BRIT J DERMATOL, V146, P448, DOI 10.1046/j.1365-2133.2002.04569.x; Morton CA, 1998, BRIT J DERMATOL, V138, P283; Parslew RAG, 1997, J EUR ACAD DERMATOL, V9, P137, DOI 10.1016/S0926-9959(97)00116-5; STOLZ W, 1994, EUR J DERMATOL, V4, P521; Tannous ZS, 2002, J AM ACAD DERMATOL, V46, P260, DOI 10.1067/mjd.2002.118345; Wallace VP, 2000, PHYS MED BIOL, V45, P735, DOI 10.1088/0031-9155/45/3/312; ZENG HS, 1993, PHYS MED BIOL, V38, P231, DOI 10.1088/0031-9155/38/2/002	34	1	1	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		0-8194-5855-4	P SOC PHOTO-OPT INS			2005	5855		1-2				30	37		10.1117/12.623383		8	Instruments & Instrumentation; Optics	Instruments & Instrumentation; Optics	BCV71	WOS:000231443000008		
J	Guo, YH; Greiner, R; Schuurmans, D		Kaelbling, LP; Saffotti, A		Guo, Yuhong; Greiner, Russell; Schuurmans, Dale			Learning Coordination Classifiers	19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05)			English	Proceedings Paper	19th International Joint Conference on Artificial Intelligence (IJCAI 05)	JUL 30-AUG 05, 2005	Edinburgh, SCOTLAND	BCS, Scottish Enterprise, QinetiQ, BTO, Foresight, Microsoft Research, ERCIM, Intelligent Applications Ltd, IBM, CologNET, Intel, Google				We present a new approach to ensemble classification that requires learning only a single base classifier. The idea is to learn a classifier that simultaneously predicts pairs of test labels-as opposed to learning multiple predictors for single test labels-then coordinating the assignment of individual labels by propagating beliefs on a graph over the data. We argue that the approach is statistically well motivated, even for independent identically distributed (iid) data. In fact, we present experimental results that show improvements in classification accuracy over single-example classifiers, across a range of iid data sets and over a set of base classifiers. Like boosting, the technique increases representational capacity while controlling variance through a principled form of classifier combination.	[Guo, Yuhong; Greiner, Russell; Schuurmans, Dale] Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2M7, Canada	Guo, YH (reprint author), Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2M7, Canada.	yuhong@cs.ualberta.ca; greiner@cs.ualberta.ca; dale@cs.ualberta.ca					Anthony M., 1999, NEURAL NETWORK LEARN; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y., 1996, P 13 INT C MACH LEAR, P148; FRIEDMAN N, 1997, MACH LEARN, V29, P121; Getoor L., 2002, J MACHINE LEARNING R, V3, P679; Getoor L., 2001, IJCAI01 WORKSH TEXT; Greiner R., 2002, P 18 NAT C ART INT, P167; Hastie T., 2001, ELEMENTS STAT LEARNI; LAFFERTY J, 2001, P 18 INT C MACH LEAR, P282; Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27; Murphy K.P., 1999, P UNC AI, P467; Nabney I. T., 2001, NETLAB ALGORITHMS PA; Neal R. M., 1996, BAYESIAN LEARNING NE; Platt JC, 2000, ADV NEUR IN, P61; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Taskar B, 2002, P 18 C UNC ART INT, P485; Taskar B, 2004, ADV NEUR IN, V16, P25; Vapnik V., 1998, STAT LEARNING THEORY; Xu L., 2004, ADV NEURAL INFORM PR, V17, P1537; Zhu J., 2001, ADV NEURAL INFORM PR, V14, P1081; Zhu X., 2003, P 20 INT C MACH LEAR, P912, DOI DOI 10.1109/18.850663	21	0	0	IJCAI-INT JOINT CONF ARTIF INTELL	FREIBURG	ALBERT-LUDWIGS UNIV FREIBURG GEORGES-KOHLER-ALLEE, INST INFORMATIK, GEB 052, FREIBURG, D-79110, GERMANY							2005							714	721				8	Computer Science, Artificial Intelligence	Computer Science	BUS48	WOS:000290233000115		
B	Qiu, XP; Wu, LD		Kaelbling, LP; Saffotti, A		Qiu, Xipeng; Wu, Lide			Stepwise Nearest Neighbor Discriminant Analysis	19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05)			English	Proceedings Paper	19th International Joint Conference on Artificial Intelligence (IJCAI 05)	JUL 30-AUG 05, 2005	Edinburgh, SCOTLAND	BCS, Scottish Enterprise, QinetiQ, BTO, Foresight, Microsoft Research, ERCIM, Intelligent Applications Ltd, IBM, CologNET, Intel, Google			FACE-RECOGNITION; LDA; EIGENFACES	Linear Discriminant Analysis (LDA) is a popular feature extraction technique in statistical pattern recognition. However, it often suffers from the small sample size problem when dealing with the high dimensional data. Moreover, while LDA is guaranteed to find the best directions when each class has a Gaussian density with a common covariance matrix, it can fail if the class densities are more general. In this paper, a new nonparametric feature extraction method, stepwise nearest neighbor discriminant analysis(SNNDA), is proposed from the point of view of the nearest neighbor classification. SNNDA finds the important discriminant directions without assuming the class densities belong to any particular parametric family. It does not depend on the nonsingularity of the within-class scatter matrix either. Our experimental results demonstrate that SNNDA outperforms the existing variant LDA methods and the other state-of-art face recognition approaches on three datasets from ATT and FERET face databases.	[Qiu, Xipeng; Wu, Lide] Fudan Univ, Media Comp & Web Intelligence Lab, Dept Comp Sci & Engn, Shanghai 200433, Peoples R China	Qiu, XP (reprint author), Fudan Univ, Media Comp & Web Intelligence Lab, Dept Comp Sci & Engn, Shanghai 200433, Peoples R China.	xpqiu@fudan.edu.cn; ldwu@fudan.edu.cn	Qiu, Xipeng/G-4071-2011				Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; BRESSAN M, 2003, PATTERN RECOGN, V24; Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9; Duda R.O., 2001, PATTERN CLASSIFICATI; FUKUNAGA K, 1983, IEEE T PATTERN ANAL, V5; Fukunaga K, 1990, INTRO STAT PATTERN R; Hastie T., 2001, ELEMENTS STAT LEARNI; HASTIE T, 1996, IEEE T PATTERN ANAL, V18; LI HF, 2003, P NEURAL INFORM PROC; LIU K, 1992, PATTERN RECOGN, V25; Moghaddam B, 2000, PATTERN RECOGN, V33, P1771, DOI 10.1016/S0031-3203(99)00179-X; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Samaria Ferdinando, 1994, P 2 IEEE WORKSH APPL; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Yang H, 2003, PATTERN RECOGN, V36, P563; Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X	16	0	0	IJCAI-INT JOINT CONF ARTIF INTELL	FREIBURG	ALBERT-LUDWIGS UNIV FREIBURG GEORGES-KOHLER-ALLEE, INST INFORMATIK, GEB 052, FREIBURG, D-79110, GERMANY							2005							829	834				6	Computer Science, Artificial Intelligence	Computer Science	BUS48	WOS:000290233000133		
S	Pan, T; Huang, K			IEEE	Pan, Tony; Huang, Kun			Virtual mouse placenta: Tissue layer segmentation	2005 27th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, Vols 1-7	PROCEEDINGS OF ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY		English	Proceedings Paper	27th Annual International Conference of the IEEE-Engineering-in-Medicine-and-Biology-Society	AUG 31-SEP 03, 2005	Shanghai, PEOPLES R CHINA	IEEE Engn Med & Biol Soc, Chinese Acad Engn Sci				Microscopic imaging is an important phenotyping tool to characterize the phenotype (e.g., morphology and behavior) change caused by genotype manipulation such as mutation and gene knockout. Recently we use high resolution microscopic imaging to study the morphological change on mouse placenta induced by retinoblast (Rb) gene knockout. In order to assess the morphological change we first segment each microscopic image into regions corresponding to different tissue types. Due to the complex structure of these tissues and large variation among the more than 2,000 images, we design a Bayesian supervised segmentation method which utilizing image features of all levels. The method has been applied to the entire data set and generated satisfactory results that is essential for further analysis on 3-D morphological change of the tissue types.	Ohio State Univ, Dept Biomed Informat, Columbus, OH 43210 USA	Pan, T (reprint author), Ohio State Univ, Dept Biomed Informat, Columbus, OH 43210 USA.						BELONGIE S, 1998, P 6 INT C COMP VIS; BOLDYS J, 2003, P INT S IM SIGN PROC, P1054; HARALICK RM, 1979, P IEEE, V67, P86804, DOI UNSP 786804; Hastie T., 2001, ELEMENTS STAT LEARNI; Murphy RF, 2003, J VLSI SIG PROC SYST, V35, P311, DOI 10.1023/B:VLSI.0000003028.71666.44; PERLAN ZE, 2004, SCIENCE, V303, P1194; Rinkenberger J, 2000, NAT GENET, V25, P248, DOI 10.1038/76985; Wu LZ, 2003, NATURE, V421, P942, DOI 10.1038/nature01417	8	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1094-687X		0-7803-8740-6	P ANN INT IEEE EMBS			2005							3112	3116				5	Engineering, Biomedical	Engineering	BER00	WOS:000238998402236		
S	Pelckmans, K; Goethals, I; Suykens, JAK; De Moor, B			IEEE	Pelckmans, K.; Goethals, I.; Suykens, J. A. K.; De Moor, B.			On model complexity control in identification of Hammerstein systems	2005 44th IEEE Conference on Decision and Control & European Control Conference, Vols 1-8	IEEE CONFERENCE ON DECISION AND CONTROL - PROCEEDINGS		English	Proceedings Paper	44th IEEE Conference on Decision Control/European Control Conference (CCD-ECC)	DEC 12-15, 2005	Seville, SPAIN	IEEE Control Syst Soc, European Union Control Assoc, IFAC, INFORMS, SIAM, SICE, Honeywell, MathWorks		identification; Hammerstein systems; model complexity and regularization; kernel methods	SUBSPACE IDENTIFICATION; REGRESSION; ALGORITHM; REGULARIZATION	Model complexity control and regularization play a crucial role in statistical learning theory and also for problems in system identification. This text discusses the potential of the issue of regularization in identification of Hammerstein systems in the context of primal-dual kernel machines and Least Squares Support Vector Machines (LS-SVMs) and proposes an extension of the Hammerstein class to finite order Volterra series and methods resulting in structure detection.	Katholieke Univ Leuven, ESAT, SCD SISTA, B-3001 Louvain, Belgium	Pelckmans, K (reprint author), Katholieke Univ Leuven, ESAT, SCD SISTA, Kasteelpk Arenberg 10, B-3001 Louvain, Belgium.		Pelckmans, Kristiaan/A-3118-2013; Suykens, Johan/C-9781-2014				Antoniadis A, 2001, J AM STAT ASSOC, V96, P939, DOI 10.1198/016214501753208942; Bai EW, 1998, AUTOMATICA, V34, P333, DOI 10.1016/S0005-1098(97)00198-2; Boyd S., 2004, CONVEX OPTIMIZATION; Boyd S, 1984, IMA J MATH CONTROL I, V1, P243, DOI 10.1093/imamci/1.3.243; DAVIDSON TN, 2000, IEEE T SIGNAL PROCES, V50, P2702; FRIEDMAN JH, 1981, J AM STAT ASSOC, V76, P817, DOI 10.2307/2287576; GOETHALS I, 2004, SUBSPACE IDENTIFICAT; Goethals I, 2003, IEEE T AUTOMAT CONTR, V48, P1843, DOI [10.1109/TAC.2003.817940, 10.1109/TAC.203.817940]; GOETHALS I, 2005, IN PRESS AUTOMATICA; GREBLICKI W, 1986, IEEE T AUTOMAT CONTR, V31, P74, DOI 10.1109/TAC.1986.1104096; Hansen P.C., 1998, RANK DEFICIENT DISCR; Hastie T., 2001, ELEMENTS STAT LEARNI; HOERL AE, 1970, TECHNOMETRICS, V12, P55; Lang ZQ, 1997, IEEE T AUTOMAT CONTR, V42, P1435; LANG ZQ, 1993, AUTOMATICA, V29, P767; Ljung L., 1987, SYSTEM IDENTIFICATIO; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; Mari J, 2000, IEEE T SIGNAL PROCES, V48, P2092, DOI 10.1109/78.847793; PELCKMANS K, 2003, 03184 ESATSISTA KU L; PELCKMANS K, 2005, IN PRESS NEUROCOMPUT; PELCKMANS K, 2004, IN PRESS SUPPORT VEC; PELCKMANS K, 2004, P 11 INT C NEUR INF; STOICA P, 1981, IEEE T AUTOMAT CONTR, V26, P967, DOI 10.1109/TAC.1981.1102761; Suykens J. A. K., 2002, LEAST SQUARES SUPPOR; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tikhonov AN, 1977, SOLUTION ILL POSED P; Van Gestel T, 2001, IEEE T AUTOMAT CONTR, V46, P1416, DOI 10.1109/9.948469; Vapnik V., 1998, STAT LEARNING THEORY; Wahba G, 1990, SPLINE MODELS OBSERV	29	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0191-2216		0-7803-9567-0	IEEE DECIS CONTR P			2005							1203	1208				6	Automation & Control Systems	Automation & Control Systems	BFB21	WOS:000240653701033		
B	Quost, B; Denoeux, T; Masson, M			IEEE	Quost, B; Denoeux, T; Masson, M			Pairwise classifier combination in the transferable belief model	2005 7th International Conference on Information Fusion (FUSION), Vols 1 and 2			English	Proceedings Paper	7th International Conference on Information Fusion (FUSION)	JUL 25-28, 2005	Philadelphia, PA	IEEE		belief functions; Dempster-Shafer theory; transferable belief model; pattern recognition; classification		Classifier combination constitutes an interesting approach when solving multi-class classification problems. We propose to carry out this combination in the belief functions framework. Our approach, similar to a method proposed by Hastie and Tibshirani in a probabilistic framework, is first presented. The performances obtained on various datasets are then analyzed, showing a gain of classification accuracy using the belief functions approach.	Univ Technol Compiegne, CNRS, UMR 6599, F-60205 Compiegne, France	Quost, B (reprint author), Univ Technol Compiegne, CNRS, UMR 6599, BP 20529, F-60205 Compiegne, France.						Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; DIETTERICH TG, 1998, NEURAL COMPUT, V10, P7; Friedman J., 1996, ANOTHER APPROACH POL; Furnkranz J., 2001, P 18 INT C MACH LEAR, P146; Hastie T., 2001, ELEMENTS STAT LEARNI; HASTIE T, 1998, ADV NEURAL INFORM PR, V10; KOONTZ WLG, 1972, IEEE T COMPUT, VC 21, P967; KUNCHEVA LI, 2004, COMBINING PATTERN CL; MOREIRA M, 1998, EUR C MACH LEARN, P160; PLATT J, LARGE MARGIN DAGS MU; Scholkopf B, 2002, LEARNING KERNELS; Shafer G., 1976, MATH THEORY EVIDENCE; SMETS P, 1994, ARTIF INTELL, V66, P191, DOI 10.1016/0004-3702(94)90026-4; Smets P, 2002, INT J APPROX REASON, V31, P1, DOI 10.1016/S0888-613X(02)00066-X; Wu TF, 2004, J MACH LEARN RES, V5, P975; YAGER RR, 1987, INFORM SCIENCES, V41, P93, DOI 10.1016/0020-0255(87)90007-7	16	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9286-8				2005							437	444				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BDP88	WOS:000234830400060		
B	Kumar, S; Ramos, F; Upcroft, B; Ridley, M; Ong, L; Sakkarieh, S; Durrant-Whyte, H			IEEE	Kumar, S; Ramos, F; Upcroft, B; Ridley, M; Ong, L; Sakkarieh, S; Durrant-Whyte, H			A sochastic model for natural feature representation	2005 7th International Conference on Information Fusion (FUSION), Vols 1 and 2			English	Proceedings Paper	7th International Conference on Information Fusion (FUSION)	JUL 25-28, 2005	Philadelphia, PA	IEEE			NONLINEAR DIMENSIONALITY REDUCTION; IMAGES	This paper presents a robust stochastic model for the incorporation of natural features within data fusion algorithms. The representation combines Isomap, a non-linear manifold learning algorithm, with Expectation Maximization, a statistical learning scheme. The representation is computed offline and results in a non-linear, non-Gaussian likelihood model relating visual observations such as color and texture to the underlying visual states. The likelihood model can be used online to instantiate likelihoods corresponding to observed visual features in real-time. The likelihoods are expressed as a Gaussian Mixture Model so as to permit convenient integration within existing nonlinear filtering algorithms. The resulting compactness of the representation is especially suitable to decentralized sensor networks. Real visual data consisting of natural imagery acquired from an Unmanned Aerial Vehicle is used to demonstrate the versatility of the feature representation.	Univ Sydney, ARC Ctr Excellence Res Autonomous Syst, Sydney, NSW 2006, Australia	Kumar, S (reprint author), Univ Sydney, ARC Ctr Excellence Res Autonomous Syst, Sydney, NSW 2006, Australia.						Bailey T, 2002, THESIS U SYDNEY; Belkin M., 2002, LAPLACIAN EIGENMAPS, DOI 10.1.1.19.9400; BRAND M, 2004, EUR C COMP VIS ECCV; Cox T.F., 1994, MULTIDIMENSIONAL SCA; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Dijkstra E, 1959, NUMER MATH, V1, P269, DOI DOI 10.1007/BF01386390; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; Foster I, 1995, DESIGNING BUILDING P; Ghahramani Z, 1996, CRGTR961 U TOR DEP C; Hastie T., 2001, ELEMENTS STAT LEARNI; Karklin Y, 2003, NETWORK-COMP NEURAL, V14, P483, DOI 10.1088/0954-898X/14/3/306; Lee TW, 2002, VISION RES, V42, P2095, DOI 10.1016/S0042-6989(02)00122-0; MACKAY DJC, 2003, INFORMATION THEORY L; Nettleton E., 2003, THESIS U SYDNEY; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; UPCROFT B, 2004, UNPUB AUSTR C ROB AU; Williams S.B., 2001, THESIS U SYDNEY	19	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9286-8				2005							1030	1037				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BDP88	WOS:000234830400138		
S	Wolf, L; Martin, I		Schmid, C; Soatto, S; Tomasi, C		Wolf, L; Martin, I			Robust boosting for learning from few examples	2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Vol 1, Proceedings	PROCEEDINGS - IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION		English	Proceedings Paper	Conference on Computer Vision and Pattern Recognition	JUN 20-25, 2005	San Diego, CA	IEEE Comp Soc				We present and analyze a novel regularization technique based on enhancing our dataset with corrupted copies of our original data. The motivation is that since the learning algorithm lacks information about which parts of the data are reliable, it has to make more robust classification functions. Using this framework, we propose a simple addition to the gentle boosting algorithm which enables it to work with only a few examples. We test this new algorithm on a variety of datasets and show convincing results.	MIT, Ctr Biol & Computat Learning, McGovern Inst Brain Res, Cambridge, MA 02139 USA	Wolf, L (reprint author), MIT, Ctr Biol & Computat Learning, McGovern Inst Brain Res, Cambridge, MA 02139 USA.						BISHOP CM, 1995, NEURAL COMPUTATION; BREIMAN L, 1996, ANN STAT; DOMINGOS P, 2000, P INT C AI; FEIFEI L, ICCV03; FERGUS R, CVPR 2003; Friedman J., 2000, ANN STAT; Hastie T., 2001, ELEMENTS STAT LEARNI; Lowe D. G., 2004, IJCV; Neumaier A., 1998, SIAM REV; SCHAPIRE RE, 1999, P INT JOINT C AI; Serre T, 2005, CVPR; Torralba A., 2004, CVPR; Viola P., 2001, CVPR; WESTON J, 2001, NIPS; WOLF L, 2004, CBCL242 MIT CSAIL TR	15	5	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1063-6919		0-7695-2372-2	PROC CVPR IEEE			2005							359	364				6	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BCR44	WOS:000230923100049		
S	Figueiredo, MAT		Schmid, C; Soatto, S; Tomasi, C		Figueiredo, MAT			Bayesian image segmentation using wavelet-based priors	2005 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, VOL 1, PROCEEDINGS	IEEE Conference on Computer Vision and Pattern Recognition		English	Proceedings Paper	Conference on Computer Vision and Pattern Recognition	JUN 20-25, 2005	San Diego, CA	IEEE Comp Soc			TEXTURE CLASSIFICATION; MODELS	This paper introduces a formulation which allows using wavelet-based priors for image segmentation. This formulation can be used in supervised, unsupervised, or semisupervised modes, and with any probabilistic observation model (intensity, multispectral, texture). Our main goal is to exploit the well-known ability of wavelet-based priors to model piece-wise smoothness (which underlies state-of-theart methods for denoising, coding, and restoration) and the availability of fast algorithms for wavelet-basedprocessing. The main obstacle to using wavelet-based priors for segmentation is that they're aimed at representing real values, rather than discrete labels, as needed for segmentation. This difficulty is sidestepped by the introduction of realvalued hidden fields, to which the labels are probabilistically related. These hidden fields, being unconstrained and real-valued, can be given any type of spatial prior, such as one based on wavelets. Under this model, Bayesian MAP segmentation is carried out by a (generalized) EM algorithm. Experiments on synthetic and real data testify for the adequacy of the approach.	Univ Tecn Lisboa, Dept Elect & Comp Engn, Inst Super Tecn, P-1049001 Lisbon, Portugal	Figueiredo, MAT (reprint author), Univ Tecn Lisboa, Dept Elect & Comp Engn, Inst Super Tecn, P-1049001 Lisbon, Portugal.	mario.figueiredo@lx.it.pt	Figueiredo, Mario/C-5428-2008	Figueiredo, Mario/0000-0002-0970-7745			BOHNING D, 1992, ANN I STAT MATH, V44, P197, DOI 10.1007/BF00048682; BOHNING D, 1988, ANN I STAT MATH, V40, P641, DOI 10.1007/BF00049423; Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633; Choi H, 2001, IEEE T IMAGE PROCESS, V10, P1309, DOI 10.1109/83.941855; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39; FIGUEIREDO M, 2005, WAVELET BASED LOGIST; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Hastie T., 2001, ELEMENTS STAT LEARNI; JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S; KRISHNAPURAM B, 2005, IEEE TPAMI, V27; Lange K, 2000, J COMPUT GRAPH STAT, V9, P1, DOI 10.2307/1390605; Li S.Z., 2001, MARKOV RANDOM FIELD; Mallat S., 1998, WAVELET TOUR SIGNAL; Marroquin JL, 2003, IEEE T PATTERN ANAL, V25, P1380, DOI 10.1109/TPAMI.2003.1240112; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; McLachlan GJ, 1997, EM ALGORITHM EXTENSI; Moulin P, 1999, IEEE T INFORM THEORY, V45, P909, DOI 10.1109/18.761332; Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936; Weiss Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, DOI 10.1109/ICCV.1999.790354; Williams CKI, 1998, IEEE T PATTERN ANAL, V20, P1342, DOI 10.1109/34.735807; WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673; ZABIH R, 2004, P IEEE C COMP VIS PA, V2, P437, DOI 10.1109/CVPR.2004.1315196	25	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1063-6919		0-7695-2372-2	PROC CVPR IEEE			2005							437	443				7	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BCR44	WOS:000230923100059		
S	Vasilescu, MAO; Terzopoulos, D		Schmid, C; Soatto, S; Tomasi, C		Vasilescu, MAO; Terzopoulos, D			Multilinear independent components analysis	2005 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, VOL 1, PROCEEDINGS	IEEE Conference on Computer Vision and Pattern Recognition		English	Proceedings Paper	Conference on Computer Vision and Pattern Recognition	JUN 20-25, 2005	San Diego, CA	IEEE Comp Soc				Independent Components Analysis (ICA) maximizes the statistical independence of the representational components Of a training image ensemble, but it cannot distinguish between the different factors, or modes, inherent to image formation, including scene structure, illumination, and imaging. We introduce a nonlinear multifactor model that generalizes ICA. Our Multilinear ICA (MICA) model of image ensembles learns the statistically independent components of multiple factors. Whereas ICA employs linear (matrix) algebra, MICA exploits multilinear (tensor) algebra. We furthermore introduce a multilinear projection algorithm which projects an unlabeled test image into the N constituent mode spaces to simultaneously infer its mode labels. In the context of facial image ensembles, where the mode labels are person, viewpoint, illumination, expression, etc., we demonstrate that the statistical regularities learned by MICA capture information that, in conjunction with our multilinear projection algorithm, improves automatic face recognition.	Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada	Vasilescu, MAO (reprint author), Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada.						Bartlett MS, 2001, FACE IMAGE ANAL UNSU; Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287; Blanz V, 1999, COMP GRAPH, P187; De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1324, DOI 10.1137/S0895479898346995; Friedman J., 2001, ELEMENTS STAT LEARNI; Hyvarinen A, 2001, INDEPENDENT COMPONEN; KROONENBERG PM, 1980, PSYCHOMETRIKA, V45, P69, DOI 10.1007/BF02293599; SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), DOI 10.1109/CVPR.1991.139758; Vasilescu M., 2002, P INT C PATT REC, V2, P511; Vasilescu M. A. O., 2002, P EUR C COMP VIS, P447	11	14	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1063-6919		0-7695-2372-2	PROC CVPR IEEE			2005							547	553				7	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BCR44	WOS:000230923100074		
S	Papandreou, G; Maragos, P		Schmid, C; Soatto, S; Tomasi, C		Papandreou, G; Maragos, P			A cross-validatory statistical approach to scale selection for image denoising by nonlinear diffusion	2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Vol 1, Proceedings	PROCEEDINGS - IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION		English	Proceedings Paper	Conference on Computer Vision and Pattern Recognition	JUN 20-25, 2005	San Diego, CA	IEEE Comp Soc			ANISOTROPIC DIFFUSION; EDGE-DETECTION; ERROR	Scale-spaces induced by diffusion processes play an important role in many computer vision tasks. Automatically selecting the most appropriate scale for a particular problem is a central issue for the practical applicability of such scale-space techniques. This paper concentrates on automatic scale selection when nonlinear diffusion scale-spaces are utilized for image denoising. The problem is studied in a statistical model selection framework and cross-validation techniques are utilized to address it in a principled way. The proposed novel algorithms do not require knowledge of the noise variance and have acceptable computational cost. Extensive experiments on natural images show that the proposed methodology leads to robust algorithms, which outperform existing techniques for a wide range of noise types and noise levels.	Natl Tech Univ Athens, Sch Elect & Comp Engn, GR-15773 Athens, Greece	Papandreou, G (reprint author), Natl Tech Univ Athens, Sch Elect & Comp Engn, GR-15773 Athens, Greece.						ALTMAN NS, 1990, J AM STAT ASSOC, V85, P749, DOI 10.2307/2290011; Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192; BREIMAN L, 1992, J AM STAT ASSOC, V87, P738, DOI 10.2307/2290212; CATTE F, 1992, SIAM J NUMER ANAL, V29, P182; EFRON B, 1986, J AM STAT ASSOC, V81, P461, DOI 10.2307/2289236; GILBOA G, 2001, P INT C IM PROC ICIP, V3, P134; Hastie T., 2001, ELEMENTS STAT LEARNI; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; Mrazek P, 2003, INT J COMPUT VISION, V52, P189, DOI 10.1023/A:1022908225256; Nason GP, 1996, J ROY STAT SOC B MET, V58, P463; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; SOLO V, 2001, P INT C AC SPEECH SI, V6, P3929; STEIN CM, 1981, ANN STAT, V9, P1135, DOI 10.1214/aos/1176345632; STONE M, 1974, J R STAT SOC B, V36, P111; Weickert J, 1999, IMAGE VISION COMPUT, V17, P201, DOI 10.1016/S0262-8856(98)00102-4; Weickert J., 1998, ANISOTROPIC DIFFUSIO; Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI [10.1109/TIP.2002.804276, 10.1109/TIP.2002.804279]	18	4	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1063-6919		0-7695-2372-2	PROC CVPR IEEE			2005							625	630				6	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BCR44	WOS:000230923100085		
S	Zhang, L; Samaras, D; Tomasi, D; Volkow, N; Goldstein, R		Schmid, C; Soatto, S; Tomasi, C		Zhang, L; Samaras, D; Tomasi, D; Volkow, N; Goldstein, R			Machine learning for clinical diagnosis from functional magnetic resonance Imaging	2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Vol 1, Proceedings	PROCEEDINGS - IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION		English	Proceedings Paper	Conference on Computer Vision and Pattern Recognition	JUN 20-25, 2005	San Diego, CA	IEEE Comp Soc				Functional Magnetic Resonance Imaging (fMRI) has enabled scientists to look into the active human brain. FMRI provides a sequence of 3D brain images with intensities representing brain activations. Standard techniques for fMRI analysis traditionally focused on finding the area of most significant brain activation for different sensations or activities. In this paper, we explore a new application of machine learning methods to a more challenging problem: classifying subjects into groups based on the observed 3D brain images when the subjects are performing the same task. Here we address the separation of drug-addicted subjects from healthy non-drug-using controls. In this paper we explore a number of classification approaches. We introduce a novel algorithm that integrates side information into the use of boosting. Our algorithm clearly outperformed well-established classifiers as documented in extensive experimental results. This is the first time that machine learning techniques based on 3D brain images are applied to a clinical diagnosis that currently is only performed through patient self-report. Our tools can therefore provide information not addressed by traditional analysis methods and substantially improve diagnosis.(1).	SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11790 USA	Zhang, L (reprint author), SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11790 USA.						Aguirre GK, 1998, NEUROIMAGE, V8, P302, DOI 10.1006/nimg.1998.0367; BANDETTINI PA, 1993, MAGN RESON MED; Burges C.J.C., 1998, J DATA MINING KNOWLE, V2, P121; Collins M., 2002, ACL; FORD J, 2003, MICCAI03; Freund Y, 1995, COMPUTATIONAL LEARNI; Friston KJ, 1994, HUMAN BRAIN MAPPING, V2, P189, DOI DOI 10.1002/HBM.460020402; GOLDSTEIN RZ, 2004, HUM BRAIN MAPP C; Hastie T., 2001, ELEMENTS STAT LEARNI; Hutchinson M, 1999, MAGN RESON IMAGING, V17, P1427, DOI 10.1016/S0730-725X(99)00093-4; KWONG KK, 1992, P NATL ACAD SCI USA, V89, P5675, DOI 10.1073/pnas.89.12.5675; Levi K, 2004, CVPR; Liow JS, 2000, J NUCL MED, V41, P612; Mitchell T., 1997, MACHINE LEARNING; MITCHELL TM, 2003, MACHINE LEARNING SPE; SHUSHUA A, 2004, ECCV; VIDAL R, 2004, CVPR, P510; VIOLA P, 2004, INT J COMPUT VISION, P57; Wang X., 2003, NIPS03; WU Y, 2004, CVPR	20	12	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1063-6919		0-7695-2372-2	PROC CVPR IEEE			2005							1211	1217				7	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BCR44	WOS:000230923100163		
S	Georgescu, B; Zhou, XS; Comaniciu, D; Gupta, A		Schmid, C; Soatto, S; Tomasi, C		Georgescu, B; Zhou, XS; Comaniciu, D; Gupta, A			Database-guided segmentation of anatomical structures with complex appearance	2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Vol 2, Proceedings	PROCEEDINGS - IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION		English	Proceedings Paper	Conference on Computer Vision and Pattern Recognition	JUN 20-25, 2005	San Diego, CA	IEEE Comp Soc			IMAGE SEGMENTATION; MODELS	The segmentation of anatomical structures has been traditionally formulated as a perceptual grouping task, and solved through clustering and variational approaches. However, such strategies require the a priori knowledge to be explicitly defined in the optimization criterion, e.g., "high-gradient border", "smoothness", or "similar intensity or texture". This approach is limited by the validity of underlying assumptions and cannot capture complex structure appearance. This paper introduces database-guided segmentation as a new data-driven paradigm that directly exploits expert annotation of interest structures in large medical databases. Segmentation is formulated as a two-step learning problem. The first step is structure detection where we learn how to discriminate between the object of interest and background. The resulting classifier based on a boosted cascade of simple features also provides a global rigid transformation of the structure. The second step is shape inference where we use a sample-based representation of the joint distribution of appearance and shape annotations. To learn the association between the complex appearance and shape we propose a feature selection mechanism and the corresponding metric. We show that the selected features are better than using directly the appearance and illustrate the performance of the proposed method on a large set of ultrasound heart images.	Siemens Corp Res, Integrated Data Syst Dept, Princeton, NJ 08540 USA	Georgescu, B (reprint author), Siemens Corp Res, Integrated Data Syst Dept, Princeton, NJ 08540 USA.						BARTLETT MS, 2003, IEEE WORKSH COMP VIS; Borenstein E., 2002, P EUR C COMP VIS, P109; Bosch JG, 2002, IEEE T MED IMAGING, V21, P1374, DOI 10.1109/TMI.2002.806427; Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, DOI 10.1109/ICCV.1999.790416; COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004; Cootes TF, 1998, P EUR C COMP VIS, V2, P484; Cristinacce D., 2004, BRIT MACH VIS C, V1, P231; Freund Y., 1996, INT C MACH LEARN, P148; GOWER JC, 1975, PSYCHOMETRIKA, V40, P33, DOI 10.1007/BF02291478; Hastie T., 2001, ELEMENTS STAT LEARNI; Heisele B., 2001, P IEEE C COMP VIS PA, V1, P657; Kass M, 1988, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Mitchell S. C., 2001, Proceedings of the SPIE - The International Society for Optical Engineering, DOI 10.1117/12.431094; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; OKUMA K, 2004, 2004 EUR C COMP VIS, V1, P28; Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689; REN X, 2003, 2003 INT C COMP VIS, V1, P10; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; Staib LH, 1996, IEEE T MED IMAGING, V15, P720, DOI 10.1109/42.538949; Viola P., 2001, P IEEE C COMP VIS PA; Yang J, 2003, LECT NOTES COMPUT SC, V2878, P573; Zhou XS, 2005, IEEE T PATTERN ANAL, V27, P115; ZHOU XS, 2004, 2004 IEEE C COMP VIS, V1, P872	23	15	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1063-6919		0-7695-2372-2	PROC CVPR IEEE			2005							429	436				8	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BCR47	WOS:000230925500059		
S	Yu, K; Yu, SP; Tresp, V		Schmid, C; Soatto, S; Tomasi, C		Yu, K; Yu, SP; Tresp, V			Multi-output regularized projection	2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Vol 2, Proceedings	PROCEEDINGS - IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION		English	Proceedings Paper	Conference on Computer Vision and Pattern Recognition	JUN 20-25, 2005	San Diego, CA	IEEE Comp Soc				Dimensionality reduction via feature projection has been widely used in pattern recognition and machine learning. It is often beneficial to derive the projections not only based on the inputs but also on the target values in the training data set. This is of particular importance in predicting multivariate or structured outputs. which is an area of growing interest. In this paper we introduce a novel projection framework which is sensitive to both input features and outputs. Based on the derived features prediction accuracy can be greatly improved. We validate our approach in two applications. The first is to model users ' preferences on a set of paintings. The second application is concerned with image categorization where each image may belong to multiple categories. The proposed algorithm produces very encouraging results in both settings.								HARDOON DR, 2003, CSDTR0302 U LOND ROY; Hastie T., 2001, ELEMENTS STAT LEARNI; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.2307/2333955; Rosipal R., 2001, J MACHINE LEARNING R, V2, P97; Scholkopf B, 1999, ADVANCES IN KERNEL METHODS, P327; Shawe-Taylor J., 2004, KERNAL METHODS PATTE; Tikhonov A.N., 1977, SOLUTIONS ILL POSED; WESTON J, ADV NEURAL INFORMATI, V15; Wold H., 1975, PERSPECTIVES PROBABI	9	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1063-6919		0-7695-2372-2	PROC CVPR IEEE			2005							597	602				6	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BCR47	WOS:000230925500081		
S	Wolf, L; Bileschi, S		Schmid, C; Soatto, S; Tomasi, C		Wolf, L; Bileschi, S			Combining variable selection with dimensionality reduction	2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Vol 2, Proceedings	PROCEEDINGS - IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION		English	Proceedings Paper	Conference on Computer Vision and Pattern Recognition	JUN 20-25, 2005	San Diego, CA	IEEE Comp Soc				This paper bridges the gap between variable selection methods (e.g., Pearson coefficients, KS test) and dimensionality reduction algorithms (e.g., PCA, LDA). Variable selection algorithms encounter difficulties dealing with highly correlated data, since many features are similar in quality. Dimensionality reduction algorithms tend to combine all variables and cannot select a subset of significant variables. Our approach combines both methodologies by applying variable selection followed by dimensionality reduction. This combination makes sense only when using the same utility function in both stages, which we do. The resulting algorithm benefits from complex features as variable selection algorithms do, and at the same time enjoys the benefits of dimensionality reduction.	MIT, McGovern Inst Brain Res, Ctr Biol & Computat Learning, Cambridge, MA 02139 USA	Wolf, L (reprint author), MIT, McGovern Inst Brain Res, Ctr Biol & Computat Learning, Cambridge, MA 02139 USA.						Agarwal S., 2002, ECCV; BELHUMEUR PN, 1992, PAMI, V19; BOUSQUET O, 2003, NIPS; GEMAN S, 1980, ANN PROBAB, V8; Hastie T., 2001, ELEMENTS STAT LEARNI; JEBARA T, 2003, AISTAT; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Martinez Aleix, 1998, 24 CVC; Mika S., 1999, NEURAL NETWORKS SIGN; Ng A. Y., 2004, ICML; Oren M., 1997, CVPR; SCHNEIDERMAN H, 2003, CAIP; SUNG KK, 1995, ACCV; Torralba A., 2003, ICCV; TURK M, 1991, ICPR; ULLMAN S, 2002, NATURE NEUROSCIENCE; Viola P., 2001, CVPR; WOLF L, 2005, AIM2005009CBCL247 MI; WOLF L, 2003, ICCV	19	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1063-6919		0-7695-2372-2	PROC CVPR IEEE			2005							801	806				6	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BCR47	WOS:000230925500110		
B	Ho, NB; Tay, JC			IEEE	Ho, NB; Tay, JC			LEGA: An architecture for learning and evolving flexible job-shop schedules	2005 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION, VOLS 1-3, PROCEEDINGS	IEEE Congress on Evolutionary Computation		English	Proceedings Paper	IEEE Congress on Evolutionary Computation	SEP 02-05, 2005	Edinburgh, SCOTLAND	IEEE, IEEE Computat Intelligence Soc, IEE, Evolut Programming Soc			ALGORITHMS	The interaction between evolution and learning has received much attention with recent studies in machine learning showing that it can significantly improve the efficiency of evolutionary strategies for job-shop scheduling. We propose a tripartite architecture called LEGA; comprising a Population Generator that improves the quality of the initial population for subsequent evolution while training a Schemata Learning Module to modify the fitnesses of it's offsprings aided by a memory of conserved schemas resolved from sampled schedules received dynamically during evolution. Experimental results indicate that an instantiation of LEGA outperforms current approaches using canonical EAs in computational time and quality of schedules.	Nanyang Technol Univ, Sch Comp Engn, Evolutionary & Complex Syst Lab, Singapore 639798, Singapore	Ho, NB (reprint author), Nanyang Technol Univ, Sch Comp Engn, Evolutionary & Complex Syst Lab, Singapore 639798, Singapore.	honhubinh@pmail.ntu.edu.sg; asjctay@ntu.edu.sg					Branke J., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), DOI 10.1109/CEC.1999.785502; CARLIER J, 1989, MANAGE SCI, V35, P164, DOI 10.1287/mnsc.35.2.164; Chen H, 1999, P IEEE INT C ROB AUT, V2, P1120, DOI 10.1109/ROBOT.1999.772512; Cheng RW, 1996, COMPUT IND ENG, V30, P983, DOI 10.1016/0360-8352(96)00047-2; Garey M. R., 1976, Mathematics of Operations Research, V1, DOI 10.1287/moor.1.2.117; Goldberg D.E., 1989, GENETIC ALGORITHMS S; Grefenstette J. J., 1992, P 9 INT C MACH LEARN, P189; Grefenstette J. J., 1991, P 4 INT C GEN ALG SA, P303; Hastie T., 2001, ELEMENTS STAT LEARNI; Ho N. B., 2004, Proceedings of the 2004 Congress on Evolutionary Computation (IEEE Cat. No.04TH8753), DOI 10.1109/CEC.2004.1331108; Jain AS, 1999, EUR J OPER RES, V113, P390, DOI 10.1016/S0377-2217(98)00113-1; Kacem I, 2002, IEEE T SYST MAN CY C, V32, P1, DOI 10.1109/TSMCC.2002.1009117; Kacem I, 2002, MATH COMPUT SIMULAT, V60, P245, DOI 10.1016/S0378-4754(02)00019-8; Kolonko M, 1999, EUR J OPER RES, V113, P123, DOI 10.1016/S0377-2217(97)00420-7; Louis S.J., 2004, IEEE T EVOLUTIONARY, V8; MESGHOUNI K, 1997, P IEEE INT C COMP CY, V1, P720; Michalski RS, 2000, MACH LEARN, V38, P9, DOI 10.1023/A:1007677805582; MICHALSKI RS, 2001, MACHINE LEARNING APP; Nowicki E, 1996, MANAGE SCI, V42, P797, DOI 10.1287/mnsc.42.6.797; PINEDO M, 1999, OPERATIONS SCHEDULIN, pCH2; Reynolds RG, 1994, P 3 ANN C EV PROGR, P131; TAY JC, 2004, P GEN EV COMP GECCO2, P210	22	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9363-5	IEEE C EVOL COMPUTAT			2005							1380	1387				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCZ86	WOS:000232173100184		
B	Zhu, Y; Comaniciu, D; Ramesh, V; Pellkofer, M; Koehler, T			IEEE	Zhu, Y; Comaniciu, D; Ramesh, V; Pellkofer, M; Koehler, T			An integrated framework of vision-based vehicle detection with knowledge fusion	2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS			English	Proceedings Paper	IEEE Intelligent Vechicles Symposium	JUN 06-08, 2005	Las Vegas, NV	IEEE ITSS			RECOGNITION; SYSTEM	This paper describes an integrated framework of on-road vehicle detection through knowledge fusion. In contrast to appearance-based detectors that make instant decisions, the proposed detection framework fuses appearance, geometry and motion information over multiple image frames. The knowledge of vehicle/non-vehicle appearance, scene geometry and vehicle motion is utilized through prior models obtained by learning, modeling and estimation algorithms. It is shown that knowledge fusion largely improves the robustness and reliability of the detection system.	Siemens Corp Res, Princeton, NJ USA	Zhu, Y (reprint author), Siemens Corp Res, Princeton, NJ USA.	ying.zhu@scr.siemens.com; dorin.comaniciu@scr.siemens.com; visvanathan.ramesh@scr.siemens.com; martin.pellkofer@siemens.com; thorsten.koehier@siemens.com					AVIDAN S, 2001, IEEE C COMP VIS PATT; BENSRHAIR A, 2001, IEEE INTELLIGENT TRA, P209; Betke M., 1996, IEEE INT VEH S, P351; Broggi A., 2004, IEEE INT VEH S, P310, DOI 10.1109/IVS.2004.1336400; COMANICIU D, 2003, IEEE INT C COMP VIS, P59; Friedman J., 2000, ANN STAT, V28; GIACHETTI A, 1998, IEEE T ROBOTICS AUTO, V14; Goerick C, 1996, PATTERN RECOGN LETT, V17, P335, DOI 10.1016/0167-8655(95)00129-8; Handmann U, 2000, IMAGE VISION COMPUT, V18, P367, DOI 10.1016/S0262-8856(99)00032-3; Hastie T., 2001, ELEMENTS STAT LEARNI; Kato T, 2002, IEEE T INTELL TRANSP, V3, P252, DOI 10.1109/TITS.2002.804752; Kruger W., 1995, IEEE INT VEH S; Matthews ND, 1996, CONTROL ENG PRACT, V4, P473, DOI 10.1016/0967-0661(96)00028-7; Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895; Srinivasa N., 2002, IEEE INT VEH S; SUN Z, 2002, IEEE INT WORKSH APPL, P171; Sun ZH, 2004, ITSC 2004: 7TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, PROCEEDINGS, P585; Viola P., 2001, IEEE C COMP VIS PATT; WILLERSINN D, 1997, IEEE C INT TRANSP SY	21	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-8961-1				2005							199	204				6	Computer Science, Artificial Intelligence; Transportation Science & Technology	Computer Science; Transportation	BDU92	WOS:000235518700033		
S	Li, X; Gunawardana, A; Acero, A			IEEE	Li, X; Gunawardana, A; Acero, A			Unsupervised semantic intent discovery from call log acoustics	2005 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOLS 1-5: SPEECH PROCESSING	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	30th IEEE International Conference on Acoustics, Speech, and Signal Processing	MAR 19-23, 2005	Philadelphia, PA	IEEE				Unforeseen user intents can account for a significant portion of unsuccessful calls in an automatic voice response system. Discovering these unforeseen semantic intents usually requires expensive manual transcriptions. We propose a method to cluster the acoustics from logged calls by their estimated semantic intents. This is achieved through training a mixture of language models in an unsupervised manner. Each cluster is presented to the application developer with a suggested language model to cover the semantic intent of the data in that cluster. The application developer validates the cluster and its suggested language model, and then updates the application. A quantative evaluation on a corporate voice-dialer application shows that updating the application in this manner yields a relative 13.4% reduction in semantic error rate.	Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA	Li, X (reprint author), Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.						AGGARWAL CC, 2004, IEEE T KNOWLEDGE DAT, V16; BEGEJA L, 2004, NAACL; Cover T. M., 1991, ELEMENTS INFORMATION; Cutting D.R., 1992, P ACM SIGIR; HACIOGLU K, 2001, IEEE ICASSP; Hastie T., 2001, ELEMENTS STAT LEARNI; WANG Y, 2000, IEEE ICASSP; WU W, 2004, CLUSTERING INFORMATI	8	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		0-7803-8874-7	INT CONF ACOUST SPEE			2005							45	48				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BCI02	WOS:000229404200012		
S	Solo, V			IEEE	Solo, V			Selection of tuning parameters for support vector machines	2005 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOLS 1-5: SPEECH PROCESSING	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	30th IEEE International Conference on Acoustics, Speech, and Signal Processing	MAR 19-23, 2005	Philadelphia, PA	IEEE				Support Vector machines have become important in classification, biometrics, machine learning and pattern recognition. But successful application requires selection of various tuning parameters such as kernel parameters and penalty or margin parameters. We apply a new technique for this problem which provides very simple structure for the automatic selector.	Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA	Solo, V (reprint author), Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA.	vsolo@umich.edu					Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Hastie T., 2001, ELEMENTS STAT LEARNI; Linhart H., 1986, MODEL SELECTION; Ng L, 2001, IEEE T IMAGE PROCESS, V10, P1528, DOI 10.1109/83.951538; Rissanen J., 1989, STOCHASTIC COMPLEXIT; SCHOLKOPF B, 2000, LEARNING KERNELS; SHI M, 2003, UNPUB IEEE ICASS APR; SOLO V, 1996, P IEEE ICIP96 IEEE; SOLO V, 1999, P ICASSP99; SOLO V, 1998, P 37 IEEE CDC TAMP F; SOLO V, 2002, P ICASSP02; SOLO V, 2001, P ICASSP2001; SOLO V, 2000, P ICASSP2000; Vapnik V., 1982, ESTIMATION DEPENDENC; Vapnik VN, 1995, NATURE STAT LEARNING; Wahba G, 2000, ADV NEUR IN, P297	16	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		0-7803-8874-7	INT CONF ACOUST SPEE			2005							237	240				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BCI02	WOS:000229404204060		
S	Sakai, S			IEEE	Sakai, S			Additive modeling of English F0 contour for speech synthesis	2005 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOLS 1-5: SPEECH PROCESSING	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	30th IEEE International Conference on Acoustics, Speech, and Signal Processing	MAR 19-23, 2005	Philadelphia, PA	IEEE				In this paper, we present an approach to fundamental frequency contour modeling of English for speech synthesis, based on a statistical learning technique called Additive Models that was successfully applied to the modeling of Japanese F(0) contour previously. In an attempt to model English F(0) contour, we defined a three-layer additive model consisting of an intonational phrase component, a word-level component representing lexical stress types, and a pitch-accent component related to accented syllables. These component functions are estimated simultaneously using a backfitting algorithm derived from a regularized least-squares error criterion specified on the model with regard to the training data. The proposed method was trained and tested using the widely used ToBI-labeled speech corpus and promising results were obtained.	MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA	Sakai, S (reprint author), MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	sakai@sls.csail.mit.edu					ABE M, P ICASSP92, P53; BLACK AW, P ICSLP 96, P1385; CHU M, P ICASSP 2003, pI264; Dominici F, 2002, AM J EPIDEMIOL, V156, P193, DOI 10.1093/aje/kwf062; DUSTERHOFF K, P EUR 99, P1627; EIDE E, P ICASSP 2003, pI708; Fujisaka H., 1984, Journal of the Acoustical Society of Japan (E), V5; Glass JR, 2003, COMPUT SPEECH LANG, V17, P137, DOI 10.1016/S0885-2308(03)00006-8; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T, 1990, GEN ADDITIVE MODELS; Hunt A., 1996, P ICASSP 96, P373; Ostendorf M., 1995, ECS95001 BOST U; Ross KN, 1999, IEEE T SPEECH AUDI P, V7, P295, DOI 10.1109/89.759037; Sakai S., 2004, P SSW5, P151; SAKAI S, P ASRU 2003, P712; SILVERMAN K, P ICSLP 92, P867; SUN X, P ICSLP 02, P2077; VISLOCKY RL, 1995, WEATHER FORECAST, V10, P669, DOI 10.1175/1520-0434(1995)010<0669:GAMVLR>2.0.CO;2	18	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		0-7803-8874-7	INT CONF ACOUST SPEE			2005							277	280				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BCI02	WOS:000229404200070		
S	Napoletani, D; Berenstein, CA; Sauer, T; Struppa, DC; Walnut, D			IEEE	Napoletani, D; Berenstein, CA; Sauer, T; Struppa, DC; Walnut, D			Attenuated embedding estimators for speech signals	2005 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOLS 1-5: SPEECH PROCESSING	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	30th IEEE International Conference on Acoustics, Speech, and Signal Processing	MAR 19-23, 2005	Philadelphia, PA	IEEE				In an earlier paper we utilized techniques from the theory of nonlinear dynamical systems to define a notion of embedding threshold estimators. These estimators were based on the analysis of delay-coordinates embeddings of sets of coefficients of the measured signal in some chosen frame. One of the motivations behind the method was the desire of building an estimator that would perform equally well regardless of the type of white noise contamination. In this paper we explicitely write the structure of one particular algorithm, the attenuated embedding threshold estimator, and we show the performance of the algorithm when different types of white noise are added to speech time series.	George Mason Univ, Sch Computat Sci, Fairfax, VA 22030 USA	Napoletani, D (reprint author), George Mason Univ, Sch Computat Sci, Fairfax, VA 22030 USA.	dnapolet@gmu.edu					Alligood K., 1996, CHAOS INTRO DYNAMICA; Hastie T., 2001, ELEMENTS STAT LEARNI; NAPOLETANI D, 2004, UNPUB THRESHOLD ESTI; SAUER T, 1991, J STAT PHYS, V65, P579, DOI 10.1007/BF01053745; Strohmer Thomas, 1998, GABOR ANAL ALGORITHM	5	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		0-7803-8874-7	INT CONF ACOUST SPEE			2005							445	448				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BCI02	WOS:000229404203112		
S	Mao, MZ; Vanhoucke, V; Strope, B			IEEE	Mao, MZ; Vanhoucke, V; Strope, B			Automatic training set segmentation for multi-pass speech recognition	2005 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOLS 1-5: SPEECH PROCESSING	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	30th IEEE International Conference on Acoustics, Speech, and Signal Processing	MAR 19-23, 2005	Philadelphia, PA	IEEE			MAXIMUM-LIKELIHOOD; MODELS	A common approach to automatic speech recognition uses two recognition passes to decode an utterance: the first pass limits the search to a smaller set of likely hypotheses; and the second pass rescores the limited set using more detailed acoustic models which may target gender or specific channels. A question raised by this architecture is how to define and train the second pass models. Here we describe an extensible automatic solution that requires no manual gender or channel labeling. To train the second pass models, we cluster the training data into datasets containing utterances whose acoustics are most similar across the entire utterance. The clustering is based on which regions of a more general acoustic model are activated during forced alignments. Experiments with commercial English-American digit strings show 9.3% relative error rate reductions over a gender-based two pass system with similar numbers of model parameters.	Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA	Mao, MZ (reprint author), Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA.	markmao@stanford.edu; vincent@nuance.com; bps@nuance.com					Abdulla W., 2001, P 5 BIANN C ART NEUR, P218; Cover T. M., 1991, ELEMENTS INFORMATION; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Digalakis VV, 1996, IEEE T SPEECH AUDI P, V4, P281, DOI 10.1109/89.506931; GALES MJF, 2001, P IEEE ASRU WORKSH M; Gersho A., 1992, VECTOR QUANTIZATION; Hastie T., 2001, ELEMENTS STAT LEARNI; LEGGETTER CJ, 1995, COMPUT SPEECH LANG, V9, P171, DOI 10.1006/csla.1995.0010; MAO MZ, 2004, IN PRESS P INT 04 JE; Ostendorf M, 1996, IEEE T SPEECH AUDI P, V4, P360, DOI 10.1109/89.536930; TEUNEN R, 2002, THESIS STANFORD U; UEBEL LF, 1999, P EUR 99 BUD, P2519; VERGIN R, 1996, P INT C SPOK LANG, V2, P1081, DOI 10.1109/ICSLP.1996.607793; Woodland P.C., 1999, P IEEE WORKSH AUT SP, P85	14	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		0-7803-8874-7	INT CONF ACOUST SPEE			2005							685	688				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BCI02	WOS:000229404200172		
B	Ma, YQ; Yu, YZ; Lu, GH; Zhang, ZL			IEEE	Ma, Yunqian; Yu, Yinzhe; Lu, Guor-Huar; Zhang, Zhi-Li			Improving wireless link delivery ratio classification with packet SNR	2005 IEEE INTERNATIONAL CONFERENCE ON ELECTRO/INFORMATION TECHNOLOGY (EIT 2005)	International Conference on Electro Information Technology		English	Proceedings Paper	IEEE International Conference on Electro/Information Technology (EIT 2005)	MAY 22-25, 2005	Lincoln, NE	IEEE		mesh network; link quality prediction; packet SNR; Support Vector Machines; Kernel Methods		Accurate link delivery ratio prediction is crucial to routing protocols in wireless mesh network. Since predicting delivery ratio directly usually requires excessive probing packets, it has been suggested to use packet SNR to predict delivery ratio, as SNR is a measure easy to obtain and "free" with every received packet. Unfortunately, several previous studies have shown that a simple direct mapping between SNR and delivery ratio values is often impossible. In this paper, we formulate the delivery ratio prediction problem as a classification problem (predicting link to be "good" or "bad"), and apply various statistical classification algorithms (k-NN, Kernel Methods, and Support Vector Machines) to it. We obtain the temporal data of link delivery ratios and SNR's from a measurement trace of a live wireless mesh network, and analyze the effectiveness of using SNR to enhance delivery ratio classification. Contrary to the pessimistic conclusion of previous works, we find that by incorporating SNR information in addition to historical delivery ratio data, the classification accuracy is improved in all the algorithms we used, with an average reduction of 8-10% of errors compared with using delivery ratio data alone. We therefore conclude that adding SNR can be an attractive alternative when designing a wireless link delivery ratio prediction protocol.	Honeywell Labs, Minneapolis, MN 55418 USA	Ma, YQ (reprint author), Honeywell Labs, 3660 Technol Dr, Minneapolis, MN 55418 USA.	yunqian.ma@honeywell.com; yyu@cs.umn.edu; ghlu@ece.umn.edu; zhzhang@cs.umn.edu					AGUAYO D, 2004, P ACM SIGCOMM C AUG; CASS S, 2005, IEEE SPECTRUM MA JAN; Cherkassky V, 2003, NEURAL COMPUT, V15, P1691, DOI 10.1162/089976603321891864; CHERKASSKY V, 2003, NEURAL NETWORKS 2003, V2, P1143; Cherkassky V., 1998, LEARNING DATA CONCEP; CHIN KW, 2002, ACM SIGCOMMM COMPUTE, V32; DECOUTO D, 2003, P ACM MOB C SEPT; DRAVES R, 2004, P ACM SIGCOMM C AUG; Hastie T., 2001, ELEMENTS STAT LEARNI; Johnson DB, 2003, DYNAMIC SOURCE ROUTI; KOTZ D, TR2003467 DARTM COLL; MA Y, 2003, NEURAL NETWORKS 2003, V2, P1581; NELAKUDITI S, 2005, UNPUB DISRUPTION TOL; PERSKINS CE, 1994, P ACM SIGCOMM C AUG; QIAN L, 2003, P 36 HAW INT C SYST; Vapnik VN, 1995, NATURE STAT LEARNING	16	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9232-9	INT CONF ELECTRO INF			2005							22	27				6	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Computer Science	BEW88	WOS:000239912500005		
B	Kubota, N; Kamijima, S; Taniguchi, K		Gu, J; Liu, PX		Kubota, Naoyuki; Kamijima, Shinichi; Taniguchi, Kazuhiko			Teleoperation of a vision-based mobile robot under office automation floors	2005 IEEE International Conference on Mechatronics and Automations, Vols 1-4, Conference Proceedings			English	Proceedings Paper	IEEE International Conference on Mechatronics Automation	JUL 29-AUG 01, 2005	Niagara Falls, CANADA	IEEE Robot & Automat Soc, Harbin Engn Univ, Kagawa Univ, Univ Elect Sci & Technol China, Robot Soc Japan, Japan Soc Mech Engineers, Japan Soc Precis Engn		computational intelligence; mobile robot; visual perception		This paper discusses human interface between a human operator and a vision-based mobile robot used under office automation floors. First, we explain the hardware of tele-operation system of the mobile robot, and the display system of the measured information of the robot. There are many supporting poles in the under floor, and the robot should estimate the self-location according to the layout of the surrounding poles. We apply a K-means algorithm and a steady-state genetic algorithm (SSGA) for extracting poles from an image. Next, We apply the proposed method for the control of a mobile robot used under an office automation floor. Furthermore, we propose an attention mechanism to the human operator. Experimental results show the effectiveness of the proposed method.	Tokyo Metropolitan Univ, Dept Syst Design, Tokyo 1920397, Japan	Kubota, N (reprint author), Tokyo Metropolitan Univ, Dept Syst Design, 1-1 Minami Osawa, Tokyo 1920397, Japan.						Brooks R., 1999, CAMBRIAN INTELLIGENC; Fogel DB, 1995, EVOLUTIONARY COMPUTA; Fukuda T, 1999, P IEEE, V87, P1448, DOI 10.1109/5.784220; Hastie T., 2001, ELEMENTS STAT LEARNI; Jang J.-S. R., 1997, NEUROFUZZY SOFT COMP; KAMIJIMA S, 2004, P KES JAP, P51; KAMIJIMA S, 2004, P SCI2004, P631; KAMIJIMA S, 2004, P SICE SI2004 CD ROM, P197; Klir GJ, 1996, FUZZY SETS FUZZY LOG; Kohonen T., 1984, SELF ORG ASS MEMORY; KUBOTA N, 2003, P 12 YAL WORKSH AD L, P199; KUBOTA N, 2004, P CD ROM WORLD AUT C; KUBOTA N, 2004, 5 INT C SIM EV LEARN, P337; KUBOTA N, 2004, WORLD AUT C CD ROM I; Kubota N., 2003, J MULT-VALUED LOG S, V9, P221; Pfeifer R., 1999, UNDERSTANDING INTELL; Russell SJ, 1995, ARTIFICIAL INTELLIGE; Sutton R. S., 1998, REINFORCEMENT LEARNI; Syswerda G., 1991, FDN GENETIC ALGORITH	19	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9044-X				2005							614	619				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Engineering, Mechanical; Robotics	Automation & Control Systems; Computer Science; Engineering; Robotics	BEQ03	WOS:000238860801010		
B	Zhang, Z; Xu, X; Huang, T			IEEE	Zhang, Z; Xu, X; Huang, T			Indecisive classifier	2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2			English	Proceedings Paper	IEEE International Conference on Multimedia and Expo (ICME)	JUL 06-08, 2005	Amsterdam, NETHERLANDS	IEEE				Nearest neighbor classification expects the class conditional probabilities to be locally constant. The assumption becomes invalid in high dimension due to the curse-of-dimensionality. Severe bias can be introduced under this condition when using nearest neighbor rule. We propose an adaptive nearest neighbor classification method "indecisive classifier" to minimize bias and variance by avoiding decision making in some hard-decision region. As a result, better classification performance can be expected in some scenario such as video based face recognition.	Univ Illinois, Urbana, IL 61801 USA	Zhang, Z (reprint author), Univ Illinois, Urbana, IL 61801 USA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DJOUADI A, 1998, PAMI, V20; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Fix E, 1952, 11 USAF SCH AV MED; FUKUNAGA K, 1973, INFORM THEORY, V19; HASTIE T, 1996, PAMI, V18; HASTIE T, 2001, ELEMENTS STAT LEARNI, P427; PENG J, 2004, PAMI, V26; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), DOI 10.1109/CVPR.1991.139758	9	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9331-7				2005							570	573				4	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BDO93	WOS:000234623800143		
S	Deng, G; Ng, WY			IEEE	Deng, G; Ng, WY			Model-based approach for the development of LMS algorithms	2005 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS), VOLS 1-6, CONFERENCE PROCEEDINGS	IEEE International Symposium on Circuits and Systems		English	Proceedings Paper	IEEE International Symposium on Circuits and Systems (ISCAS)	MAY 23-26, 2005	Kobe, JAPAN	IEEE Circuits & Syst Soc, Sci Council Japan, Inst Elect, Informat & Commun Engineers, Inst Elect Engineers Japan, Informat Proc Soc Japan			ADAPTIVE FILTER	The LMS algorithm is one of the most popular adaptive filter algorithms. Many variants of the algorithm have been developed for different applications. In this paper, we propose a unified model-based approach for developing LMS algorithms. We use a number of probability density functions to model the filtering error and the filter coefficients. The filter coefficients are determined by maximizing the posterior distribution function. We demonstrate that using this approach, we can not only develop existing LMS algorithms with further insights, we can also explore a number of new algorithms with certain desired properties such as robustness and sparseness.	La Trobe Univ, Dept Elect Engn, Bundoora, Vic 3086, Australia	Deng, G (reprint author), La Trobe Univ, Dept Elect Engn, Bundoora, Vic 3086, Australia.	d.deng@latrobe.edu.au; w.ng@acm.org					Antoniadis A, 2001, J AM STAT ASSOC, V96, P939, DOI 10.1198/016214501753208942; Bang SC, 1996, IEEE T CIRCUITS-I, V43, P361; BENESTY J, 2003, ADAPTIVE SIGNAL PROC, P1; Boyd S., 2004, CONVEX OPTIMIZATION; Chambers J, 1997, IEEE SIGNAL PROC LET, V4, P46, DOI 10.1109/97.554469; Douglas SC, 1994, IEEE SIGNAL PROC LET, V1, P49, DOI 10.1109/97.295321; Duttweiler DL, 2000, IEEE T SPEECH AUDI P, V8, P508, DOI 10.1109/89.861368; Gay S. L., 2002, P IEEE ICASSP, V2, P1405; Gelman A, 2004, BAYESIAN DATA ANAL; Gonin R., 1989, NONLINEAR LP NORM ES; Hastie T., 2001, ELEMENTS STAT LEARNI; Haykin S., 1996, ADAPTIVE FILTER THEO; Huber P., 1981, ROBUST STAT; Karvanen J., 2003, 4 INT S IND COMP AN, P125; Martin RK, 2002, IEEE T SIGNAL PROCES, V50, P1883, DOI 10.1109/TSP.2002.800414; NIKOLOVA M, 1996, P IEEE INT C IM PROC, V2, P457; OSBORNE EE, 1985, FINITE ALGORITHMS OP; Petrus P, 1999, IEEE T SIGNAL PROCES, V47, P1129, DOI 10.1109/78.752610; Rao B. D., 2003, P IEEE ICASSP, P361; SETHARES WA, 1993, ADAPTIVE SYSTEM IDEN, P84	20	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0271-4302		0-7803-8834-8	IEEE INT SYMP CIRC S			2005							2267	2270				4	Engineering, Electrical & Electronic	Engineering	BCZ06	WOS:000232002402090		
S	Li, ZY; Tan, YP			IEEE	Li, ZY; Tan, YP			Event detection using multimodal feature analysis	2005 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS), VOLS 1-6, CONFERENCE PROCEEDINGS	IEEE International Symposium on Circuits and Systems		English	Proceedings Paper	IEEE International Symposium on Circuits and Systems (ISCAS)	MAY 23-26, 2005	Kobe, JAPAN	IEEE Circuits & Syst Soc, Sci Council Japan, Inst Elect, Informat & Commun Engineers, Inst Elect Engineers Japan, Informat Proc Soc Japan			VIDEO	This paper presents an event detection framework using multimodal feature analysis. In this framework, multimodal features are extracted from video data and then analyzed to generate various mid-level concepts, such as video shot, face appearance and so on. Two schemes, the logistic regression and Bayesian belief network, are then employed to fuse the information obtained from multimodal feature analysis and detect the video events of interest. We aim to use this framework as a general template for event detection in different video domains. Experimental results on various test videos in different video domains suggest that the proposed event detection framework is promising.	Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 2263, Singapore	Li, ZY (reprint author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 2263, Singapore.						Babaguchi N, 2002, IEEE T MULTIMEDIA, V4, P68, DOI 10.1109/6046.985555; Hastie T., 2001, ELEMENTS STAT LEARNI; IYENGAR G, 2002, P IEEE ICME, V2, P369, DOI 10.1109/ICME.2002.1035607; LI Z, 2004, IEEE ICME; Medioni G, 2001, IEEE T PATTERN ANAL, V23, P873, DOI 10.1109/34.946990; MONCRIEFF S, 2001, P 2 IEEE INT C MULT, P989; Nefian AV, 1999, INT CONF ACOUST SPEE, P3553; Rui Y., 2000, Proceedings ACM Multimedia 2000, DOI 10.1145/354384.354443; Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P12; XU M, 2003, IEEE ICASSP, V3, P189	10	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0271-4302		0-7803-8834-8	IEEE INT SYMP CIRC S			2005							3845	3848				4	Engineering, Electrical & Electronic	Engineering	BCZ06	WOS:000232002403207		
S	Feng, J; Potkonjak, M			IEEE	Feng, J; Potkonjak, M			Transitive statistical sensor error characterization and calibration	2005 IEEE SENSORS, VOLS 1 AND 2	IEEE Sensors		English	Proceedings Paper	4th IEEE Conference on Sensors	OCT 31-NOV 03, 2005	Irvine, CA	IEEE Sensors Council				Calibration is the process of identifying and correcting for the systematic bias component of the error in the sensor measurements. On-line and in-field sensor measurement calibration is particularly crucial since manual calibration is expensive and sometimes infeasible. We have developed an on-line and in-field error modeling technique, which is a generalization of the calibration problem, that relies on a small number of inaccurate sensors with known error distributions to develop error models for the deployed in-field sensors. We demonstrate the applicability of our transitive error modeling technique and evaluate its performance in various scenarios by conducting experiments using traces of the light intensity measurements recorded by in-field deployed light sensors. In addition, statistical validation and evaluation methods such as resubsitution are used in order to establish the interval of confidence.	Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90024 USA	Feng, J (reprint author), Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90024 USA.	jessicaf@cs.ucla.edu; miodrag@cs.ucla.edu					Belsley David A., 1980, REGRESSION DIAGNOSTI; Bychkovskiy V, 2003, LECT NOTES COMPUT SC, V2634, P301; Chatterjee S., 1977, REGRESSION ANAL EXAM; Davison A, 1997, BOOTSTRAP METHODS TH; Efron B., 1982, JACKKNIFE BOOTSTRAP; Efron Bradley, 1993, INTRO BOOTSTRAP; Fan J., 1996, LOCAL POLYNOMIAL MOD; FENG J, 2004, SENSOR CALIBRATION U; Good P.I., 1999, RESAMPLING METHODS; Green PJ, 1994, NONPARAMETRIC REGRES; Hastie T., 2001, ELEMENTS STAT LEARNI; HIGHTOWER J, 2001, DESIGN CALIBRATION; Ihler AT, 2004, IPSN '04: THIRD INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING IN SENSOR NETWORKS, P225; Kahaner D., 1989, NUMERICAL METHODS SO; LAMARCA A, 2002, IEEE INT C PERVASIVE; Thisted R.A., 1988, ELEMENTS STAT COMPUT; WHITEHOUSE K, 2004, ACM INT WORKSH WIR S	17	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1930-0395		0-7803-9056-3	IEEE SENSOR			2005							572	575				4	Instruments & Instrumentation; Remote Sensing	Instruments & Instrumentation; Remote Sensing	BEE80	WOS:000237003500142		
B	Gtipta, M; Cazzanti, L; Srivastava, S			IEEE	Gtipta, Maya; Cazzanti, Luca; Srivastava, Santosh			Minimum expected risk probability estimates for nonparametric neighborhood classifiers	2005 IEEE/SP 13th Workshop on Statistical Signal Processing (SSP), Vols 1 and 2			English	Proceedings Paper	13th IEEE Workshop on Statistical Signal Processing	JUL 17-20, 2005	Bordeaux, FRANCE	IEEE		Laplace correction; k-nearest neighbors; non-parametric classification; mininium expected risk; LIME		We consider the problem of estimating class probabilities for a given feature vector using flowparametric neighborhood methods, such as k-nearest neighbors (k-NN). This paper's contribution is the application of minimum expected risk estimates for neighborhood learning methods, an analytic formula for the minimum expected risk estimate for weighted k-NN classifiers, and examples showing that the difference can be significant.	Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA	Gtipta, M (reprint author), Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.						Bernardo J.M., 2000, WILEY SERIES PROBABI; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Gupta M.K, UNPUB; Gupta MR, 2003, PROCEEDINGS OF THE 2003 IEEE WORKSHOP ON STATISTICAL SIGNAL PROCESSING, P482; Hastie T., 2001, ELEMENTS STAT LEARNI; Kay S.M., 1993, FUNDAMENTALS STAT SI; Lehmann E. L., 1998, THEORY POINT ESTIMAT; MacKay D., 2003, INFORMATION THEORY I; Provost F., 2003, MACHINE LEARNING, V52; ROSENFIELD R, 2000, P IEEE, V88	10	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9403-8				2005							586	590				5	Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic	Computer Science; Engineering	BEU24	WOS:000239515900105		
B	Cazzanti, L; Gupta, M; Malmstrom, L; Baker, D			IEEE	Cazzanti, L; Gupta, M; Malmstrom, L; Baker, D			Quality assessment of low free-energy protein structure predictions	2005 IEEE Workshop on Machine Learning for Signal Processing (MLSP)			English	Proceedings Paper	IEEE Workshop on Machine Learning for Signal Processing (MLSP)	SEP 28-30, 2005	Mystic, CT	IEEE			ROSETTA	Analyzing and engineering cellular signaling processes requires accurate estimation of cellular subprocesses such as protein-folding. We apply parametric and nonparametric classification to the problem of assessing three-dimensional protein domain structure predictions generated by the Rosetta ab initio structure prediction method. The assessment is based on whether the predicted structure is similar enough to a known protein structure to be classified as being in the same protein superfamily. We develop appropriate features and apply Gaussian mixture models, K-nearest-neighbors, and the recently developed linear interpolation with maximum entropy method (LIME). The proposed learning methods outperform a previous quality assessment method based on generalized linear models. Results show that the proposed methods reject the vast majority of poor structural predictions while identifying a useful number of good predictions.	Univ Washington, Dept Elect Engn, Seattle, WA 98105 USA	Cazzanti, L (reprint author), Univ Washington, Dept Elect Engn, Seattle, WA 98105 USA.						*BAK LAB, US ROS AB IN STRUCT; Baldi P, 2001, BIOINFORMATICS MACHI; Bonneau R, 2002, J MOL BIOL, V322, P65, DOI 10.1016/S0022-2836(02)00698-8; BONNEAU R, 2001, PROTEIN-STRUCT FUNCT, V455, P119; Bradley P, 2003, PROTEINS, V53, P457, DOI 10.1002/prot.10552; Cover T. M., 1991, ELEMENTS INFORM THEO; Devroye L., 1996, PROBABILISTIC THEORY; Gupta MR, 2003, PROCEEDINGS OF THE 2003 IEEE WORKSHOP ON STATISTICAL SIGNAL PROCESSING, P482; GUPTA MR, 2004, UNPUB J PUBLICATION; Hastie T., 2001, ELEMENTS STAT LEARNI; Lesk AM, 2001, INTRO PROTEIN ARCHIT; MALMSTROM L, 2005, UNPUB COLLECTED DATA; MURZIN AG, 1995, J MOL BIOL, V247, P563; ORTIZ AR, 2002, PROTEIN SCI, V1, P2606; Reynolds D. A., 1995, IEEE T SPEECH AUDIO, V3; Simons KT, 1999, PROTEINS, P171; LNKNET PATTERN CLASS	17	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9517-4				2005							375	380		10.1109/MLSP.2005.1532932		6	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology; Statistics & Probability	Computer Science; Engineering; Imaging Science & Photographic Technology; Mathematics	BDP08	WOS:000234650300060		
S	Kale, A; Jaynes, C			IEEE	Kale, A; Jaynes, C			Shape space sampling distributions and their impact on visual tracking	2005 International Conference on Image Processing (ICIP), Vols 1-5	IEEE International Conference on Image Processing (ICIP)		English	Proceedings Paper	IEEE International Conference on Image Processing (ICIP 2005)	SEP 11-14, 2005	Genoa, ITALY	IEEE				Object motions can be represented as a sequence of shape deformations and translations which can be interpretated as a sequence of points in N-dimensibnal shape space. These spaces range from simple 2D translations to more inclusive spaces such as the affine. In this case, tracking is the problem of inferring the most likely point in the space for the next frame given a current set of hypotheses. A robust method for achieving this is the particle filter. In this case, likely points within shape space are selected in a two step process. First, image measurements assign likelihoods to proposed points. Likely points are then propagated forward using an dynamical model to derive a set of new points that are perturbed according to some sampling distribution. These distributions play an important role in tracking performance because dynamical models are seldom known and a Gauss Markov model is often assumed for the model dynamics. This paper address the problems inherent in utilizing uninformed sampling distributions for visual tracking. We introduce a principled adaptive sampling approach that takes into account constraints on each component of the shape vector. Further a more appropriate sampling distribution that takes place in a linear subspace representing the predominant motion in the shape space. Results demonstrate improved tracking performance in challenging conditions where targets exhibit changing motion models.	Univ Kentucky, Ctr Visualizat & Virtual Environm, Lexington, KY 40506 USA	Kale, A (reprint author), Univ Kentucky, Ctr Visualizat & Virtual Environm, Lexington, KY 40506 USA.						Hastie T., 2001, ELEMENTS STAT LEARNI; ISARD M, 1998, IJCV, V21, P695; ISARD M, 1998, P ECCV; Li BX, 2002, IEEE T IMAGE PROCESS, V11, P530, DOI 10.1109/TIP.2002.1006400; Liu JS, 1998, J AM STAT ASSOC, V93, P1032, DOI 10.2307/2669847; Mardia KV, 1979, MULTIVARIATE ANAL; North B, 2000, IEEE T PATTERN ANAL, V22, P1016, DOI 10.1109/34.877523; SULLIVAN J, 2001, P ICCV; ZHOU S, 2004, IEEE T IMAGE PRO NOV	9	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1522-4880		0-7803-9134-9	IEEE IMAGE PROC			2005							613	616				4	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BDW08	WOS:000235773300154		
S	Papandreou, G; Maragos, P			IEEE	Papandreou, G; Maragos, P			Image denoising in nonlinear scale-spaces: Automatic scale selection via cross-validation	2005 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING (ICIP), VOLS 1-5	IEEE International Conference on Image Processing ICIP		English	Proceedings Paper	IEEE International Conference on Image Processing (ICIP 2005)	SEP 11-14, 2005	Genoa, ITALY	IEEE			ANISOTROPIC DIFFUSION; EDGE-DETECTION; ERROR	Multiscale, i.e. scale-space image analysis is a powerful framework for many image processing tasks. A fundamental issue with such scale-space techniques is the automatic selection of the most salient scale for a particular application. This paper consider optimal scale selection when nonlinear diffusion and morphological scale-spaces are utilized for image denoising. The problem is studied from a statistical model selection viewpoint and cross-validation techniques are utilized to address it in a principled way. The proposed novel algorithms do not require knowledge of the noise variance, have acceptable computational cost and are readily integrated with a wide class of scale-space inducing processes which require setting of a scale parameter. Our experiments show that this methodology leads to robust algorithms, which outperform existing scale-selection techniques for a wide range of noise types and noise levels.	Natl Tech Univ Athens, Sch ECE, Athens 15773, Greece	Papandreou, G (reprint author), Natl Tech Univ Athens, Sch ECE, Athens 15773, Greece.	gpapan@cs.ntua.gr; maragos@cs.ntua.gr					ALTMAN NS, 1990, J AM STAT ASSOC, V85, P749, DOI 10.2307/2290011; Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192; Bovik A, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, P1; BREIMAN L, 1992, J AM STAT ASSOC, V87, P738, DOI 10.2307/2290212; CATTE F, 1992, SIAM J NUMER ANAL, V29, P182; EFRON B, 1986, J AM STAT ASSOC, V81, P461, DOI 10.2307/2289236; GILBOA G, 2001, P INT C IM PR; Hastie T., 2001, ELEMENTS STAT LEARNI; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; Maragos P, 2003, INT J COMPUT VISION, V52, P121, DOI 10.1023/A:1022999923439; MEYER F, 2000, J VISUAL COMMUNIC IM, V11; Mrazek P, 2003, INT J COMPUT VISION, V52, P189, DOI 10.1023/A:1022908225256; Nason GP, 1996, J ROY STAT SOC B MET, V58, P463; PAPANDREOU G, 2005, P INT C CVPR; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; SALEMBIER P, 1995, IEEE T IMAGE PROCESS, V4, P1153, DOI 10.1109/83.403422; Serra J., 1998, IMAGE ANAL MATH MORP, V2; SOLO V, 2001, P INT C AC SPEECH SI, V6, P3929; STONE M, 1974, J R STAT SOC B, V36, P111; Weickert J, 1999, IMAGE VISION COMPUT, V17, P201, DOI 10.1016/S0262-8856(98)00102-4; Weickert J., 1998, ANISOTROPIC DIFFUSIO; Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI [10.1109/TIP.2002.804276, 10.1109/TIP.2002.804279]	23	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1522-4880		0-7803-9134-9	IEEE IMAGE PROC			2005							1033	1036				4	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BDW08	WOS:000235773301065		
S	Qiu, XP; Wu, LD			IEEE	Qiu, XP; Wu, LD			Nonparametric maximum margin criterion for face recognition	2005 International Conference on Image Processing (ICIP), Vols 1-5	IEEE International Conference on Image Processing (ICIP)		English	Proceedings Paper	IEEE International Conference on Image Processing (ICIP 2005)	SEP 11-14, 2005	Genoa, ITALY	IEEE			LDA; EIGENFACES	Linear discriminant analysis (LDA) is a popular feature extraction technique in statistical pattern recognition. However, it often suffers from the small sample size problem when dealing with the high dimensional image data. Moreover, while LDA is guaranteed to find the best directions when each class has a Gaussian density with a common covariance matrix, it can fail if the class densities are more general. In this paper, a new feature extraction method, nonparametric maximum margin criterion (NMMC), is proposed. NMMC finds the important discriminant directions without assuming the class densities belong to any particular parametric family, and it does not depend on the nonsingularity of the within-class scatter matrix. Our experimental results on the ATT and FERET face databases demonstrate that NMMC outperforms the existing variant LDA methods and the other state-of-art face recognition approaches.	Fudan Univ, Dept Comp Sci & Engn, Media Comp & Web Intelligence Lab, Shanghai 200433, Peoples R China	Qiu, XP (reprint author), Fudan Univ, Dept Comp Sci & Engn, Media Comp & Web Intelligence Lab, Shanghai 200433, Peoples R China.		Qiu, Xipeng/G-4071-2011				Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9; Fukunaga K, 1990, INTRO STAT PATTERN R; FUKUNAGA K, 1983, IEEE T PATTERN ANAL, V5, P671; Hastie T., 2001, ELEMENTS STAT LEARNI; LI HF, 2003, P NEURAL INFORM PROC; LIU K, 1992, PATTERN RECOGN, V25, P731, DOI 10.1016/0031-3203(92)90136-7; Moghaddam B, 2000, PATTERN RECOGN, V33, P1771, DOI 10.1016/S0031-3203(99)00179-X; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Samaria Ferdinando, 1994, P 2 IEEE WORKSH APPL; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Wang X., 2004, P IEEE C COMP VIS PA; Yang H, 2003, PATTERN RECOGN, V36, P563; Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X	14	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1522-4880		0-7803-9134-9	IEEE IMAGE PROC			2005							1413	1416				4	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BDW08	WOS:000235773301160		
S	Gupta, MR			IEEE	Gupta, MR			Custom color enhancements by statistical learning	2005 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING (ICIP), VOLS 1-5	IEEE International Conference on Image Processing ICIP		English	Proceedings Paper	IEEE International Conference on Image Processing (ICIP 2005)	SEP 11-14, 2005	Genoa, ITALY	IEEE				We consider the problem of automatically learning color enhancements from a small set of sample color pairs, and then describing the enhancement by a three-dimensional lookup-table that can be stored and implemented as an ICC profile. We propose a new method for automatically learning a neighborhood for local statistical learning methods such as local linear regression, and show that this leads to relatively accurate descriptions of the desired color transformation and results in images that appear smooth and have natural depth of detail. In a previous work we showed that learning arbitrary color enhancements can result in colored specular highlights, causing images to look unnatural. We show that this can be solved by adding a null sample that maps white to white.	Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA	Gupta, MR (reprint author), Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.	gupta@ee.washington.edu					GUPTA MR, 2005, P SPIE C COMP IM 3 J; Hastie T., 2001, ELEMENTS STAT LEARNI; Hertzmann A, 2001, COMP GRAPH, P327; Kang H. R., 1997, COLOR TECHNOLOGY ELE; Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629	5	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1522-4880		0-7803-9134-9	IEEE IMAGE PROC			2005							2949	2952				4	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BDW08	WOS:000235773303156		
B	Datia, N; Moura-Pires, J; Cardoso, A; Pita, H		Bento, C; Cardoso, A; Dias, G		Datia, N.; Moura-Pires, J.; Cardoso, A.; Pita, H.			Temporal patterns of TV watching for Portuguese viewers	2005 Portuguese Conference on Artificial Intelligence, Proceedings			English	Proceedings Paper	Portuguese Conference on Artificial Intelligence	2005	Covilha, PORTUGAL	APPIA, DIUBI, CISUC, Microsoft Res, FCT, Camara Municipal Coviha, Parkurbis, IMB-Hoteis, Caixa Geral Depositos, AUTO JARDIM Automoveis S A, TAP Air Portugal, SEMMAIS Programac Design Interact, OmniSys Tecnol Informacao Lda, Regisfund Maquinas Escritor Lda, Costa & Costa Topograf Informat Lda, Eurobit - Sistemas Informat Manutenc Lda, Opt S Vicente, IEEE, ECCAI, AAAI, ACM	Univ Beira Interior	clustering; data reduction; people meter data; temporal visualization patterns; TV		Audiometer systems provide enormous amounts of detailed TV watching data. Several relevant and interdependent factors may influence TV viewers' behavior. In this work we focus on the time factor and derive Temporal Patterns of TV watching, based on panel data. Clustering base attributes are originated from 1440 binary minute-related attributes, capturing the TV watching status (watch/not watch). Since there are around 2500 panel viewers a data reduction procedure is first performed. K-Means algorithm is used to obtain daily clusters of viewers. Weekly patterns are then derived which rely on daily patterns. The obtained solutions are tested for consistency and stability. Temporal TV watching patterns provide new insights concerning Portuguese TV viewers' behavior.	ISEL, Dept Elect Telecommun & Comp, P-1959007 Lisbon, Portugal	Datia, N (reprint author), ISEL, Dept Elect Telecommun & Comp, Rua Conselheiro Emidio Navarro 1, P-1959007 Lisbon, Portugal.						ATIA N, 2002, CCTE 2002 C CIENT TE; Bishop YMM, 1975, DISCRETE MULTIVARIAT; DEING WE, 1940, ANN MATH STAT; FIGUEIREDO V, 2005, IEEE T POWER SYSTEMS; GONCALVES T, 1999, AIDA; HARA Y, 2004, CATEGORIZATION JAPAN; Hastie T., 2001, ELEMENTS STAT LEARNI; MACQEEN JB, 1967, P 5 BERK S MATH STAT; Mirkin B., 1996, MATH CLASSIFICATION; WEBER R, 2003, COMM RES EUR ABR CHA; Witten IH, 2000, DATA MINING PRACTICA; 2003, WEKA MACHINE LEARNIN	12	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-0-7803-9365-3				2005							151	158		10.1109/EPIA.2005.341286		8	Computer Science, Artificial Intelligence	Computer Science	BFY02	WOS:000245387100026		
B	Enachescu, D; Enachescu, C		Bento, C; Cardoso, A; Dias, G		Enachescu, Denis; Enachescu, Cornelia			Learning Vector Quantization for breast cancer prediction	2005 Portuguese Conference on Artificial Intelligence, Proceedings			English	Proceedings Paper	Portuguese Conference on Artificial Intelligence	2005	Covilha, PORTUGAL	APPIA, DIUBI, CISUC, Microsoft Res, FCT, Camara Municipal Coviha, Parkurbis, IMB-Hoteis, Caixa Geral Depositos, AUTO JARDIM Automoveis S A, TAP Air Portugal, SEMMAIS Programac Design Interact, OmniSys Tecnol Informacao Lda, Regisfund Maquinas Escritor Lda, Costa & Costa Topograf Informat Lda, Eurobit - Sistemas Informat Manutenc Lda, Opt S Vicente, IEEE, ECCAI, AAAI, ACM	Univ Beira Interior	artificial intelligence; neural networks; genetic algorithms; spiking neuron models; JASTAP		Electrical impedance spectroscopy is a minimal invasive technique that has clear advantages for living tissue characterization owing to its low cost and eases of use. The present paper describes how this technique can be applied to breast tissue classification and breast cancer detection. Based on the features derived from the electrical impedance spectra a Learning Vector Quantization (LVQ) network is trained to discriminate several classes of breast tissue. Results of LVQ classification obtained from a data set of 106 cases representing six classes of excised breast tissue show an overall classification efficiency varying from 77% to 100% depending on the parameters of the LVQ network.	Univ Bucharest, Fac Math & Comp Sci, Bucharest 010014 1, Romania	Enachescu, D (reprint author), Univ Bucharest, Fac Math & Comp Sci, Str Acad 14, Bucharest 010014 1, Romania.						Demuth H, 2000, NEURAL NETWORK TOOLB; Hastie T., 2002, ELEMENTS STAT LEARNI; Kohonen T., 1989, SELF ORG ASS MEMORY; Marques de Sa J.P., 2003, APPL STAT USING SPSS; Silva J E, 2000, MED BIOL ENG COMPUT, V38, P26	5	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-0-7803-9365-3				2005							177	180		10.1109/EPIA.2005.341290		4	Computer Science, Artificial Intelligence	Computer Science	BFY02	WOS:000245387100030		
B	Dudek, D; Kubisz, M; Zgrzywa, A		Kwasnicka, H; Paprzycki, M		Dudek, D; Kubisz, M; Zgrzywa, A			APS: Agent's learning with imperfect recall	5th International Conference on Intelligent Systems Design and Applications, Proceedings			English	Proceedings Paper	5th International Conference on Intelligent Systems Design and Applications (ISDA 2005)	SEP 08-10, 2005	Wroclaw, POLAND	World Federat Soft Comp, European Soc Fuzzy Log & Technol, European Neural Network Soc, Warsaw Sch Social Psychol, Polish Minist Sci Res & Informat Technol				We present a new method of incremental, statistical learning, which is suitable for knowledge-based systems, especially software agents. The method is based on the imperfect recall assumption, according to which an agent does not store all the past observations. However it does preserve general rules concerning the past, that can be potentially useful for improving agent's action. During its performance an agent stores observations in the history. When system resources are idle and the size of the history is sufficient as for its statistical significance, the stored facts are analysed by means of data mining techniques, and disposed afterwards. The discovered rules are combined with the former rule base, so that the final rule set is approximately the same, as if it was obtained on the whole history.	Wroclaw Tech Univ, Inst Appl Informat, PL-50370 Wroclaw, Poland	Dudek, D (reprint author), Wroclaw Tech Univ, Inst Appl Informat, Wybrzeze Wyspianskiego 27, PL-50370 Wroclaw, Poland.						Agrawal R., 1994, P 20 INT C VER LARG; Bacchus F, 1996, ARTIF INTELL, V87, P75, DOI 10.1016/S0004-3702(96)00003-3; CHICHOSZ P, 2000, LEARNING SYSTEMS; DUDEK D, 2005, P 4 INT C COMP REC S, P153; DUDEK D, 2003, KNOWLEDGE ENG EXPERT, V2, P237; Fagin R., 1995, REASONING KNOWLEDGE; GOETHALS B, 2003, IMPLEMENTATION APRIO; Hastie T., 2001, ELEMENTS STAT LEARNI; KATARZYNIAK R, 1999, MULTIAGENT MANAGEMEN; Kazakov D, 2001, LECT NOTES ARTIF INT, V2086, P246; Ribeiro C, 2002, ARTIF INTELL REV, V17, P223, DOI 10.1023/A:1015008417172; Sen S., 1999, LEARNING MULTIAGENT, P259; SYMEONIDIS AL, 2002, P 6 IASTED INT C ART, P17; Yao YY, 2002, LECT NOTES ARTIF INT, V2475, P506	14	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2286-6				2005							172	177		10.1109/ISDA.2005.26		6	Computer Science, Artificial Intelligence	Computer Science	BDE37	WOS:000233058700030		
S	Wang, XD; Syrmos, VL			IEEE	Wang, XD; Syrmos, VL			Optimal cluster selection based on Fisher class separability measure	ACC: Proceedings of the 2005 American Control Conference, Vols 1-7	PROCEEDINGS OF THE AMERICAN CONTROL CONFERENCE		English	Proceedings Paper	American Control Conference 2005 (ACC)	JUN 08-10, 2005	Portland, OR	Amer Automat Control Council, IFAC, AIAA, AIChE, AIST, ASCE, ASME, IEEE, ISA, SCS				In this paper, a novel hierarchical clustering algorithm is proposed, where the number of clusters is optimally determined according to the Fisher class separability measure. The clustering algorithm consists of two phases: (1) Generation of sub-clusters based on the similarity metric; (2) Merging of sub-clusters based on the Fisher class separability measure. The proximity matrices are constructed. Each subcluster comprises patterns close to each other in proximity metric. The trellis diagram is used for searching of subclusters. Connections between consecutive layers in the trellis diagram are weighted by the similarity metric. The threshold for the merge of sub-clusters is numerically designed according to Fisher class separability measure. The proposed algorithm can pre-process the data for the supervised learning. It also can be applied for the optimal determination of basis functions for radial basis function (RBF) networks.	Univ Hawaii, Dept Elect Engn, Honolulu, HI 96822 USA	Wang, XD (reprint author), Univ Hawaii, Dept Elect Engn, Honolulu, HI 96822 USA.						BISHOP C.M., 1995, NEURAL NETWORKS PATT; Duda R. O., 1973, PATTERN CLASSIFICATI; Ester M., 1996, P 2 INT C KNOWL DISC; Fayyad U.M., 1996, ADV KNOWLEDGE DISCOV; FUKUNAGA K, 1996, INTRO STAT PATTERN R; Gersho A., 1992, VECTOR QUANTIZATION; GUHA S, 1998, P 1998 ACM SIGMOD IN; Hastie T., 2001, ELEMENTS STAT LEARNI; INABA M, 1996, P 12 ANN ACM S COMP; Jain A, 1988, ALGORITHMS CLUSTERIN; Kaufman L., 1990, FINDING GROUPS DATA; NG RT, 1994, P 20 VLDB C; SKALA H, 1972, TRELLIS THEORY; WANG SD, 2004, P 12 MED C CONTR AUT	14	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0743-1619		0-7803-9098-9	P AMER CONTR CONF			2005							1929	1934				6	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	BCY93	WOS:000231947702074		
S	Larimore, WE			IEEE	Larimore, WE			Maximum likelihood subspace identification for linear, nonlinear, and closed-loop systems	ACC: Proceedings of the 2005 American Control Conference, Vols 1-7	PROCEEDINGS OF THE AMERICAN CONTROL CONFERENCE		English	Proceedings Paper	American Control Conference 2005 (ACC)	JUN 08-10, 2005	Portland, OR	Amer Automat Control Council, IFAC, AIAA, AIChE, AIST, ASCE, ASME, IEEE, ISA, SCS		subspace system identification; closed-loop; linear; nonlinear; maximum likelihood estimation; optimal estimation	ORDER-RECURSIVE FACTORIZATION; CANONICAL VARIATE ANALYSIS; COVARIANCE-MATRIX; PSEUDOINVERSE	This tutorial paper presents a first principles development of subspace system identification (ID) using a fundamental statistical approach. This includes basic concepts of reduced rank modeling of ill-conditioned data to obtain the most appropriate statistical model structure and order using optimal maximum likelihood methods. These principles are first applied to the well developed subspace ID of linear dynamic models; and using recent results, it is extended to closed-loop linear systems and then general nonlinear closed-loop systems. The fundamental statistical approach gives expressions of the multistep likelihood function for subspace identification of both linear and nonlinear systems. This leads to direct estimation of the parameters using singular value decomposition type methods that avoid iterative nonlinear parameter optimization. The result is statistically optimal maximum likelihood parameter estimates and likelihood ratio tests of hypotheses. The parameter estimates have optimal Cramer-Rao lower bound accuracy, and the likelihood ratio hypothesis tests on model structure, model change, and process faults produce optimal decisions. The extension to general nonlinear systems determines optimal nonlinear functions of the past and future using the theory of maximal correlation. This gives the nonlinear canonical variate analysis. New results show that to avoid redundancy and obtain gaussian variables, it is necessary to determine independent canonical variables that are then used in the likelihood function evaluation. These new results greatly extend the possible applications of subspace ID to closed-loop linear and nonlinear systems for monitoring, fault detection, control design, and robust and adaptive control. Potential applications include system fault detection for control reconfiguration, autonomous system monitoring and teaming control, and highly nonlinear processes in emerging fields such as bioinformatics and nano technology. Applications are discussed to identification of vibrating structures under feedback including online adaptive control of aircraft wing flutter, and identification of the chaotic Lorenz attractor.	Adapt Inc, Mclean, VA 22101 USA	Larimore, WE (reprint author), Adapt Inc, 1717 Briar Ridge Rd, Mclean, VA 22101 USA.						Akaike H., 1973, 2 INT S INF THEOR, P267; Akaike H., 1976, SYSTEM IDENTIFICATIO, P27; Anderson T. W., 1984, INTRO MULTIVARIATE S; Aoki M, 1987, STATE SPACE MODELING; Bach F.R., 2002, J MACHINE LEARNING R, V3, P1; Bauer D, 2002, AUTOMATICA, V38, P763, DOI 10.1016/S0005-1098(01)00261-8; BAUER D, 1998, THESIS TU WIEN AUSTR; BAUER D, 2005, IN PRESS J TIME SERI; BOLLERSLEV T, 1986, J ECONOMETRICS, V31, P307, DOI 10.1016/0304-4076(86)90063-1; BRIEMAN L, 1985, J AM STAT ASSOC, V80, P580; CANDY JV, 1979, AUTOMATICA, V15, P493, DOI 10.1016/0005-1098(79)90026-8; CONNER JS, 2004, P 2004 AM CONTR C JU; Cox DR, 1974, THEORETICAL STAT; CSAKI P, 1960, PUBL MATH I HUNG, V5, P325; Csaki P., 1963, MAGYAR TUD AKAD MAT, V8, P27; Dahlen A, 1998, SYST CONTROL LETT, V34, P303, DOI 10.1016/S0167-6911(98)00020-6; Dahlen A., 2001, THESIS ROYAL I TECHN; DeCicco J, 2000, P AMER CONTR CONF, P2265, DOI 10.1109/ACC.2000.878583; Deistler M, 1995, AUTOMATICA, V31, P1865, DOI 10.1016/0005-1098(95)00089-6; ENGLE RF, 1982, ECONOMETRICA, V50, P987, DOI 10.2307/1912773; FRIEDMAN JH, 2004, SLACPUB10321, V31, P1317; GOLUB GH, 1969, MATRIX DECOMPOSITION, P365; GUSTAVSSON I, 1977, AUTOMATICA, V13, P59, DOI 10.1016/0005-1098(77)90009-7; Hall AJ, 2001, CLIN EXP OPHTHALMOL, V29, P1, DOI 10.1046/j.1442-9071.2001.00369.x; Hastie T., 2001, ELEMENTS STAT LEARNI; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.2307/2333955; JURICEK BC, 2005, P AM CONTR C PORTL O; Juricek BC, 2001, CONTROL ENG PRACT, V9, P1337, DOI 10.1016/S0967-0661(01)00124-1; Juricek BC, 2002, IND ENG CHEM RES, V41, P2185, DOI 10.1021/ie000740g; Juricek BC, 2004, IND ENG CHEM RES, V43, P458, DOI 10.1021/ie0301684; KUSS M, 2003, 108 MAX PLANK I BIOL; LACY SL, 2005, P AM CONTR C PORTL O; Lancaster H. O, 1969, CHISQUARED DISTRIBUT; LANCASTE.HO, 1966, BIOMETRIKA, V53, P585, DOI 10.2307/2333663; Larimore W., 1984, P C DEC CONTR, V2, P675; Larimore W., 1990, P 29 IEEE C DEC CONT, V1, P635; LARIMORE WE, 1985, BYTE, V10, P167; Larimore W. E., 1999, Proceedings of the 1999 American Control Conference (Cat. No. 99CH36251), DOI 10.1109/ACC.1999.783221; LARIMORE WE, 1989, SYSTEM IDENTIFICATIO; LARIMORE WE, 1985, AM CONTR C, V1, P18; LARIMORE WE, 1988, P 27 IEEE C DEC CONT, V3, P1720; LARIMORE WE, 2004, IN PRESS IFAC DYCOPS; LARIMORE WE, 1997, IFAC INT S ADV CONTR; LARIMORE WE, 1996, P 13 IFAC WORLD C SA, V1, P151; LARIMORE WE, 1993, P 1993 AM CONTR C SA, V2, P1995; LARIMORE WE, 2003, 13 IFAC S SYST ID HE; LARIMORE WE, 1992, ADAPTX AUTOMATED SYS; Larimore WE, 2002, IEEE T AUTOMAT CONTR, V47, P1953, DOI 10.1109/TAC.2002.804454; Larimore WE, 1996, SIGNAL PROCESS, V52, P131, DOI 10.1016/0165-1684(96)00049-7; LARIMORE WE, 1984, AFWALTR743052; Larimore W. E., 1983, Proceedings of the 1983 American Control Conference; LARIMORE WE, 1990, IEEE T AUTOMAT CONTR, V35, P1299, DOI 10.1109/9.61005; LARIMORE WE, 1997, 11 IFAC S SYST ID HE, V3, P1101; LARIMORE WE, 1983, BIOMETRIKA, V70, P175; LARIMORE WE, 1992, NONLINEAR MODELING F, P283; Ljung L, 1996, SIGNAL PROCESS, V52, P209, DOI 10.1016/0165-1684(96)00054-0; LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2; Lutkepohl Helmut, 1993, INTRO MULTIPLE TIME; PALANTHANDALAMM.H, 2005, P AM CONTR C PORTL O; Peternell K, 1996, SIGNAL PROCESS, V52, P161, DOI 10.1016/0165-1684(96)00051-5; PILGRAM B, 2002, 6907 WA U W AUSTR DE; Renyi A., 1959, ACTA MATH ACAD SCI H, V10, P441, DOI 10.1007/BF02024507; SCHAFFE H, 1959, ANAL VARIANCE; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B, 2002, LEARNING KERNELS; SCHWEPPE FC, 1965, IEEE T INFORM THEORY, V11, P61, DOI 10.1109/TIT.1965.1053737; Shi R., 2001, THESIS MCMASTER U; Shi RJ, 2001, P AMER CONTR CONF, P3678, DOI 10.1109/ACC.2001.946206; Van Overschee P, 1994, AM CONTR C BALT MD J, P1645; Van Overschee P, 1996, SUBSPACE IDENTIFICAT; Verhoeven P, 2002, MATH COMPUT SIMULAT, V59, P233, DOI 10.1016/S0378-4754(01)00411-6; Wang Y., 1997, P IFAC ADCHEM 97 S B, P523; WHITTLE P, 1954, BIOMETRIKA, V41, P434	73	6	6	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0743-1619		0-7803-9098-9	P AMER CONTR CONF			2005							2305	2319		10.1109/ACC.2005.1470313		15	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	BCY93	WOS:000231947703011		
J	Adomavicius, G; Sankaranarayanan, R; Sen, S; Tuzhilin, A				Adomavicius, G; Sankaranarayanan, R; Sen, S; Tuzhilin, A			Incorporating contextual information in recommender systems using a multidimensional approach	ACM TRANSACTIONS ON INFORMATION SYSTEMS			English	Article						recommender systems; collaborative filtering; personalization; multidimensional recommender systems; context-aware recommender systems; rating estimation; multidimensional data models	FRAMEWORK; NEWS	The article presents a multidimensional (MD) approach to recommender systems that can provide recommendations based on additional contextual information besides the typical information on users and items used in most of the current recommender systems. This approach supports multiple dimensions, profiling information, and hierarchical aggregation of recommendations. The article also presents a multidimensional rating estimation method capable, of selecting two-dimensional segments of ratings pertinent to the recommendation context and applying standard collaborative filtering or other traditional two-dimensional rating estimation techniques to these segments. A comparison of the multidimensional and two-dimensional rating estimation approaches is made, and the tradeoffs between the two are studied. Moreover, the article introduces a combined rating estimation method, which identifies the situations where the MD approach outperforms the standard two-dimensional approach and uses the MD approach in those situations and the standard two-dimensional approach elsewhere. Finally, the article presents a pilot empirical study of the combined approach, using a multidimensional movie recommender system that was developed for implementing this approach and testing its performance.	Univ Minnesota, Dept Informat & Decis Sci, Carlson Sch Management, Minneapolis, MN 55455 USA; Univ Connecticut, Dept Operat & Informat Management, Sch Business, Storrs, CT 06269 USA; Fairleigh Dickinson Univ, Dept Mkt & Entrepreneurship, Silberman Coll Business, Teaneck, NJ 07666 USA; NYU, Dept Informat Operat & Management Sci, Stern Sch Business, New York, NY 10012 USA	Adomavicius, G (reprint author), Univ Minnesota, Dept Informat & Decis Sci, Carlson Sch Management, 321 19th Ave S, Minneapolis, MN 55455 USA.	gedas@umn.edu; rsankaran@business.uconn.edu; sen@fdu.edu; atuzhili@stern.nyu.edu					Adomavicius G., 2001, LECT NOTES COMPUTER, V2232, P180; Adomavicius G, 2001, DATA MIN KNOWL DISC, V5, P33, DOI 10.1023/A:1009839827683; Aggarwal C.C., 1999, P 5 ACM SIGKDD INT C; Ansari A, 2000, J MARKETING RES, V37, P363, DOI 10.1509/jmkr.37.3.363.18779; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; BAEZAYATES R, 1999, MODERN INFORMATIONRE; Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124; BASU C, 1998, RECOMMENDER SYSTEMS; BETIMAN JR, 1991, HDB CONSUMER BEHAV, P50; Billsus D, 2000, USER MODEL USER-ADAP, V10, P147, DOI 10.1023/A:1026501525781; Billsus D., 1998, P 15 INT C MACH LEAR; BRESSE JS, 1998, P 14 C UNC ART INT M; Caglayan A, 1997, APPL ARTIF INTELL, V11, P393, DOI 10.1080/088395197118109; Chatterjee S., 2000, REGRESSION ANAL EXAM; CHAURET N, 1997, DRUG METAB DISPOS, V26, P1; Chien Y.H., 1999, P 7 INT WORKSH ART I; Claypool M., 1999, ACM SIGIR 99 WORKSH; Condliff M, 1999, ACM SIGIR 99 WORKSH; Cortes C., 2000, P 6 ACM SIGKDD INT C; Delgado J., 1999, ACM SIGIR 99 WORKSH; Dietterich T., 2000, LECT NOTES COMPUTER, P1; Duda R.O., 2001, PATTERN CLASSIFICATI; FAN J, 2003, ADV MED STAT, P885, DOI 10.1142/9789812388759_0024; GETOOR L, 1999, WORKSH WEB US AN US; Goldberg K, 2001, INFORM RETRIEVAL, V4, P133, DOI 10.1023/A:1011419012209; Han Jiawei, 2001, DATA MINING; Hand David J, 2001, PRINCIPLES DATA MINI; Hastie T., 2001, ELEMENTS STAT LEARNI; Herlocker J. L., 1999, Proceedings of SIGIR '99. 22nd International Conference on Research and Development in Information Retrieval, DOI 10.1145/312624.312682; Herlocker JL, 2001, IEEE INTERNET COMPUT, V5, P40, DOI 10.1109/4236.968830; Hill W., 1995, P ACM CHI 95 C HUM F, P194, DOI 10.1145/223904.223929; Huang Z, 2004, ACM T INFORM SYST, V22, P116, DOI 10.1145/963770.963775; IM I, 2001, P 22 INT C INF SYST; Kachigan S, 1986, STAT ANAL; Kelly D., 2003, SIGIR Forum, V37; Kimball R., 1996, DATA WAREHOUSE TOOLK; KLEIN NM, 1989, J CONSUM RES, V16, P410; KOLLER D, 2006, P 13 INT C MACH LEAR; Konstan JA, 1997, COMMUN ACM, V40, P77, DOI 10.1145/245108.245126; Kotler P, 2003, MARKETING MANAGEMENT; Kumar R, 2001, J COMPUT SYST SCI, V63, P42, DOI 10.1006/jcss.2001.1757; Lang K., 1995, P 12 INT C MACH LEAR; LEE WS, 2001, P INT C MACH LEARN; LILLIEN GI, 1992, MARKETING MODELS, P22; Liu H., 1998, FEATURE SELECTION KN; LUSSIER DA, 1979, J CONSUM RES, V6, P154, DOI 10.1086/208758; Mitchell T., 1997, MACHINE LEARNING; Mobasher B, 2002, P IEEE INT C DAT MIN; Mood A. M., 1974, INTRO THEORY STAT; MOONEY RJ, 1998, RECOMMENDER SYSTEMS; Mooney R.J., 1999, ACM SIGIR 99 WORKSH; Nakamura A., 1998, P 15 INT C MACH LEAR; OARD DW, 2001, P AM SO INF SCI TECH; Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943; Pazzani MJ, 1999, ARTIF INTELL REV, V13, P393, DOI 10.1023/A:1006544522159; PENNOCK DM, 1999, IJCAI 99 WORKSH MACH; Ramakrishnan R., 2000, DATABASE MANAGEMENT; Resnick P., 1994, P 1994 COMP SUPP COO; Salton G., 1989, AUTOMATIC TEXT PROCE; Sarwar B., 2000, P ACM WEBKDD WORKSH; SARWAR B, P 10 INT WWW C; Shardanand U., 1995, P C HUM FACT COMP SY; SOBOROFF I, 1999, IJCAI 99 WORKSH MACH; SPARCK-JONES K, 1974, J DOC, V30, P393; Spiliopoulou M, 2003, INFORMS J COMPUT, V15, P171, DOI 10.1287/ijoc.15.2.171.14445; Terveen L, 1997, COMMUN ACM, V40, P59, DOI 10.1145/245108.245122; TRAN T, 2000, KNOWLEDGE BASED ELEC; UNGAR LH, 1998, RECOMMENDER SYSTEMS; WADE W, 2003, NY TIMES        0116; Winston PH, 1992, ARTIFICIAL INTELLIGE	70	197	209	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	1046-8188			ACM T INFORM SYST	ACM Trans. Inf. Syst.	JAN	2005	23	1					103	145		10.1145/1055709.1055714		43	Computer Science, Information Systems	Computer Science	896KT	WOS:000226933700005		
S	Xu, X; Wang, XN		Li, X; Wang, S; Dong, ZY		Xu, X; Wang, XN			An adaptive network intrusion detection method based on PCA and support vector machines	ADVANCED DATA MINING AND APPLICATIONS, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	1st International Conference on Advanced Data Mining and Applications	JUL 22-24, 2005	Wuhan, PEOPLES R CHINA					Network intrusion detection is an important technique in computer security. However, the performance of existing intrusion detection systems (IDSs) is unsatisfactory since new attacks are constantly developed and the speed of network traffic volumes increases fast. To improve the performance of IDSs both in accuracy and speed, this paper proposes a novel adaptive intrusion detection method based on principal component analysis (PCA) and support vector machines (SVMs). By making use of PCA, the dimension of network data patterns is reduced significantly. The multi-class SVMs are employed to construct classification models based on training data processed by PCA. Due to the generalization ability of SVMs, the proposed method has good classification performance without tedious parameter tuning. Dimension reduction using PCA may improve accuracy further. The method is also superior to SVNIs without PCA in fast training and detection speed. Experimental results on KDD-Cup99 intrusion detection data illustrate the effectiveness of the proposed method.	Natl Univ Def Technol, Sch Comp, Changsha 410073, Peoples R China; Natl Univ Defense Technol, Inst Automat, Changsha 410073, Peoples R China	Xu, X (reprint author), Natl Univ Def Technol, Sch Comp, Changsha 410073, Peoples R China.	xuxin_mail@263.net					Cannady J., 1998, P 21 NAT INF SYST SE; FAN RE, 2005, SET SELECTION USING; Hastie T., 2001, ELEMENTS STAT LEARNI; Jolliffe I., 2002, PRINCIPAL COMPONENT; Lee W., 1998, P 1998 USENIX SEC S; Lee WK, 2000, ARTIF INTELL REV, V14, P533, DOI 10.1023/A:1006624031083; Lin CJ, 2001, NEURAL COMPUT, V13, P307, DOI 10.1162/089976601300014547; Lippmann RP, 2000, COMPUT NETW, V34, P597, DOI 10.1016/S1389-1286(00)00140-7; LUO J, 2000, INT J INTELL SYST, P687; Mahoney M V, 2002, P 8 ACM SIGKDD INT C, P376; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Shah H, 2003, IEEE INT CONF FUZZY, P1274; Vapnik V., 1998, STAT LEARNING THEORY	13	14	14	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-27894-X	LECT NOTES ARTIF INT			2005	3584						696	703				8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BCR26	WOS:000230895000082		
S	Dash, M; Kolippakkam, D		Ho, TB; Cheung, D; Liu, H		Dash, M; Kolippakkam, D			Automatic view selection: An application of image mining	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	9th Pacific/Asia Conference on Knowledge Discovery and Data Mining	MAY 18-20, 2005	Hanoi, VIETNAM			view; feature selection; image classification		In this paper we discuss an image mining application of Egeria detection. Egeria is a type of weed found in various lands and water regions over San Joaquin and Sacramento deltas. The challenge is to find a view to accurately detect the weeds in new images. Our solution contributes two new aspects to image mining. (1) Application of view selection to image mining: View selection is appropriate when a specific learning task is to be learned. For example, to look for an object in a set of images, it is useful to select the appropriate views (a view is a set of features and their assigned values). (2) Automatic view selection for accurate detection: Usually classification problems rely on user-defined views. But in this work we use association rule mining to automatically select the best view. Results show that the selected view outperforms other views including the full view.	Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore; Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85387 USA	Dash, M (reprint author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.	asmdash@ntu.edu.sg; n.kolippakkam@asu.edu					BLUM A, 1997, ARTIF INTELL, V1, P245; Dash M, 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; Han J., 2000, SIGMOD 00, P1, DOI DOI 10.1145/342009.335372; Hastie T., 2001, ELEMENTS STAT LEARNI; KOLIPPAKKAM N, 2002, EGERIA DENSA MINING; Muslea I., 2002, P ICML2002, P443	6	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-26076-5	LECT NOTES ARTIF INT			2005	3518						107	113				7	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BCL84	WOS:000229956700013		
S	De Veaux, R; Hoang, T		Ho, TB; Cheung, D; Liu, H		De Veaux, R; Hoang, T			Comparison of tree based methods on mammography data	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	9th Pacific/Asia Conference on Knowledge Discovery and Data Mining	MAY 18-20, 2005	Hanoi, VIETNAM				MICROCALCIFICATIONS; BREAST	X-ray film mammography and physical examination of the breast are the mainstays for early detection of breast cancer. Unfortunately, error rates for mammograms read by radiologists are high. We examine a particularly difficult to read series of 1618 mammograms where in order to achieve a false positive rate lower than 50%, the false negative rate of radiologists is nearly 25%. We examine a variety of automatic data mining tools in an attempt to improve the accuracy of the diagnosis. Our results suggest that roughly the same or higher accuracy rate than the radiologists can be attained at a much reduced cost. This potential cost savings could have a major financial impact for health care in developing nations.	Williams Coll, Williamstown, MA 01267 USA; UFR Biomed, Lab MAP5, CNRS, F-75006 Paris, France; Univ Paris 05, F-75006 Paris, France	De Veaux, R (reprint author), Williams Coll, Williamstown, MA 01267 USA.	deveaux@williams.edu; hoang@biomedicale.univ-paris5.fr					ALAGARATNAM TT, 1985, CLIN RADIOL, V36, P1757; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Christiansen CL, 2000, J NATL CANCER I, V92, P1657, DOI 10.1093/jnci/92.20.1657; DEVEAUX RD, 2004, ENCY BIOSTASTICS; Gulsun M, 2003, EUR J RADIOL, V47, P227, DOI 10.1016/S0720-048X(02)00181-X; Hastie T., 2001, ELEMENTS STAT LEARNI; *I MED NAT RES COU, 2001, MAMM, P39; LangerCherbit A, 1997, EUR J RADIOL, V24, P48, DOI 10.1016/S0720-048X(96)01115-1; Laya MB, 1996, J NATL CANCER I, V88, P643, DOI 10.1093/jnci/88.10.643; LEGAL M, 1984, B CANCER, V71, P57; LEGAL M, 1976, NOUV PRESSE MED, V5, P1623; Poplack SP, 2000, RADIOLOGY, V217, P832; Shapire R. E., 1990, MACH LEARN, V5, P197; Tan Yah-Yuen, 2004, Asian J Surg, V27, P186, DOI 10.1016/S1015-9584(09)60030-0; VOGEL V, 1994, J NATL CANCER I, V16, P55	15	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-26076-5	LECT NOTES ARTIF INT			2005	3518						186	191				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BCL84	WOS:000229956700023		
S	Han, G; Lee, D; Lee, J		Wang, J; Liao, X; Wang, J		Han, G; Lee, D; Lee, J			Estimating the yield curve using calibrated radial basis function networks	ADVANCES IN NEURAL NETWORKS - ISNN 2005, PT 2, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	2nd International Symposium on Neural Networks	MAY 30-JUN 01, 2005	Chongqing, PEOPLES R CHINA	Chongqing Univ, SW Normal Univ, Chongqing Univ, Posts& Telecommun, SW Agr Univ, Chongqing Educ Coll, Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, European Neural Network Soc, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, Natl Nat Sci Fdn China, K C Wong Educ Fdn Hong Kong			NEURAL-NETWORK	Nonparametric approaches of estimating the yield curve have been widely used as alternative approaches that supplement parametric approaches. In this paper, we propose a novel yield curve estimating algorithm based on radial basis function networks, which is a nonparametric approach. The proposed method is devised to improve accuracy and smoothness of the fitted curve. Numerical experiments are conducted for 57 U.S. Treasury securities with different maturities and demonstrate a significant performance improvement to reduce test error compared to other existing algorithms.	Pohang Univ Sci & Technol, Dept Ind & Management Engn, Pohang 790784, Kyungbuk, South Korea	Han, G (reprint author), Pohang Univ Sci & Technol, Dept Ind & Management Engn, Pohang 790784, Kyungbuk, South Korea.	swallow@postech.ac.kr; woosuhan@postech.ac.kr; jaewook@postech.ac.kr					BLISS RR, 1997, ADV FUT OPT, V9, P197; Choi HJ, 2004, LECT NOTES COMPUT SC, V3174, P988; de Boor C., 1978, PRACTICAL GUIDE SPLI; DIERCKX P, 1995, CURVE SURFACE SPLINE; FISHER M, 1995, 951 FED RES BOARD FI; Hastie T., 2001, ELEMENTS STAT LEARNI; Haykin S., 1999, NEURAL NETWORKS COMP; Hou J, 2003, ELECTRON LETT, V39, P71, DOI 10.1049/el:20030066; JAMES J., 2000, INTEREST RATE MODELI; Lee DW, 2004, LECT NOTES COMPUT SC, V3173, P239; Lee J, 2004, IEEE T AUTOMAT CONTR, V49, P888, DOI 10.1109/TAC.2004.829603; MCCULLOCH JH, 1975, J FINANC, V30, P811, DOI 10.2307/2326860; NELSON CR, 1987, J BUS, V60, P473, DOI 10.1086/296409; Nocedal J., 1999, NUMERICAL OPTIMIZATI	14	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-25913-9	LECT NOTES COMPUT SC			2005	3497						885	890				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCN40	WOS:000230167200142		
S	Liu, L; Meng, G		Wang, J; Liao, X; Yi, Z		Liu, L; Meng, G			Crack detection in supported beams - Based on neural network and support vector machine	ADVANCES IN NEURAL NETWORKS - ISNN 2005, PT 3, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	2nd International Symposium on Neural Networks	MAY 30-JUN 01, 2005	Chongqing, PEOPLES R CHINA	Chongqing Univ, SW Normal Univ, Chongqing Univ, Posts& Telecommun, SW Agr Univ, Chongqing Educ Coll, Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, European Neural Network Soc, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, Natl Nat Sci Fdn China, K C Wong Educ Fdn Hong Kong			DAMAGE	A study is presented to compare the performance of crack detection using neural network(NN) and support vector machine (SVM) based on natural frequencies. The SVM is a machine learning algorithm based on statistical learning theory, and it is also a class of regression method with the good generalization ability. Firstly, the basic theory of the back-propagation neural network and support vector regression is briefly reviewed. Then the feasibility of the crack detection using these methods are investigated by locating and sizing cracks in supported beams for which a few natural frequencies are available. It is observed that crack's location and depth can be estimated with a relatively small size error. The results show that the SVM is a powerful and effective method for crack identification.	Shanghai Jiao Tong Univ, State Key Lab Vibrat Shock & Noise, Shanghai 200240, Peoples R China	Liu, L (reprint author), Shanghai Jiao Tong Univ, State Key Lab Vibrat Shock & Noise, Shanghai 200240, Peoples R China.	Liu_long@sjtu.edu.cn					Chang C, 2001, LIBSVM LIB SUPPORT V; CHENG CZ, 2001, STRUCTURE DAMAGE MON; Ge M, 2004, MECH SYST SIGNAL PR, V18, P143, DOI 10.1016/S0888-3270(03)00071-2; Hastie T., 2001, ELEMENTS STAT LEARNI; *NAT MA, 1998, MATHW NEUR NETW TOOL; Salawu OS, 1997, ENG STRUCT, V19, P718, DOI 10.1016/S0141-0296(96)00149-6; SAMANTA KR, 2003, ENG APPL ARTIF INTEL, V16, P657; Smola A., 1998, NCTR98030 U LOND ROY; VAPNIK V, 1996, ADV NEURAL INFORMATI; VAPNIK VN, 1981, ESTIMATION DEPENDECE; YUN CB, 1998, NEURAL NETWORK APPRO, P19; Zapico JL, 2003, MECH SYST SIGNAL PR, V17, P119, DOI 10.1006/mssp.2002.1547	12	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-25914-7	LECT NOTES COMPUT SC			2005	3498						597	602				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCN43	WOS:000230167700095		
S	Mouratidis, K; Papadias, D; Papadimitriou, S		Medeiros, CB; Egenhofer, M; Bertino, E		Mouratidis, K; Papadias, D; Papadimitriou, S			Medoid queries in large spatial databases	ADVANCES IN SPATIAL AND TEMPORAL DATABASES, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	9th International Symposium on Advances in Spatial and Temporal Databases	AUG 22-24, 2005	Angra dos Reis, BRAZIL	Natl Inst Space Res, Dept Image Proc			TREES	Assume that a franchise plans to open k branches in a city, so that the average distance from each residential block to the closest branch is minimized. This is an instance of the k-medoids problem, where residential blocks constitute the input dataset and the k branch locations correspond to the medoids. Since the problem is NP-hard, research has focused on approximate solutions. Despite an avalanche of methods for small and moderate size datasets, currently there exists no technique applicable to very large databases. In this paper, we provide efficient algorithms that utilize an existing data-partition index to achieve low CPU and I/O cost. In particular, we exploit the intrinsic grouping properties of the index in order to avoid reading the entire dataset. Furthermore, we apply our framework to solve medoid-aggregate queries, where k is not known in advance; instead, we are asked to compute a medoid set that leads to an average distance close to a user-specified parameter T. Compared to previous approaches, we achieve results of comparable or better quality at a small fraction of the CPU and I/O costs (seconds as opposed to hours, and tens of node accesses instead of thousands).	Hong Kong Univ Sci & Technol, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China; Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA	Mouratidis, K (reprint author), Hong Kong Univ Sci & Technol, Dept Comp Sci, Clear Water Bay, Hong Kong, Hong Kong, Peoples R China.	kyriakos@cs.ust.hk; dimitris@cs.ust.hk; spapadim@cs.cmu.edu	MOURATIDIS, Kyriakos/E-8568-2012	MOURATIDIS, Kyriakos/0000-0002-8835-430X			Ankerst M, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P49; Arora S, 1998, STOC, P106; Beckmann N., 1990, SIGMOD, P322, DOI DOI 10.1145/93597.98741; Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining; Ester M., 1995, KDD-95 Proceedings. First International Conference on Knowledge Discovery and Data Mining; ESTER M, 1995, SSD 95, P67; Fayyad U.M., 1996, ADV KNOWLEDGE DISCOV; Guha S, 1998, SIGMOD, P73; Hamerly G., 2003, NIPS; Hartigan J.A., 1975, CLUSTERING ALGORITHM; Hastie T., 2001, ELEMENTS STAT LEARNI; Hjaltason GR, 1999, ACM T DATABASE SYST, V24, P265, DOI 10.1145/320248.320255; Kamel I., 1993, CIKM 93. Proceedings of the Second International Conference on Information and Knowledge Management; Kaufman L., 1990, FINDING GROUPS DATA; Lo ML, 1998, IEEE T KNOWL DATA EN, V10, P136; LO ML, 1995, SSD 95 PORTL ME, P328; Mamoulis N, 2003, IEEE T KNOWL DATA EN, V15, P211, DOI 10.1109/TKDE.2003.1161591; Moon B, 2001, IEEE T KNOWL DATA EN, V13, P124, DOI 10.1109/69.908985; Ng R., 1994, VLDB, P144; Pelleg D., 2000, INT C MACH LEARN, P727; Pelleg Dan, 1999, KNOWLEDGE DISCOVERY, P277; Roussopoulos N., 1995, SIGMOD, P71; Theodoridis Y, 2000, IEEE T KNOWL DATA EN, V12, P19, DOI 10.1109/69.842247; Zhang T., 1996, SIGMOD 96, P103	24	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-28127-4	LECT NOTES COMPUT SC			2005	3633						55	72				18	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BCV61	WOS:000231416800004		
J	Lobell, DB; Ortiz-Monasterio, JI; Asner, GP; Naylor, RL; Falcon, WP				Lobell, DB; Ortiz-Monasterio, JI; Asner, GP; Naylor, RL; Falcon, WP			Combining field surveys, remote sensing, and regression trees to understand yield variations in an irrigated wheat landscape	AGRONOMY JOURNAL			English	Article							ON-FARM ASSESSMENT; CROP PRODUCTION; GRAIN-YIELD; MANAGEMENT; SOIL; SATELLITE; MEXICO; VARIABILITY; CONSTRAINTS; SYSTEMS	Improved understanding of the factors that limit crop yields in farmers' fields will play an important role in increasing regional food production while minimizing environmental impacts. However, causes of spatial variability in crop yields are poorly known in many regions because of limited data availability and analysis methods. In this study, we assessed sources of between-field wheat (Triticum aestivum L.) yield variability for two growing seasons in the Yaqui Valley, Mexico. Field surveys conducted in 2001 and 2003 provided data on management practices for 68 and 80 wheat fields throughout the Valley, respectively, while yields on these fields were estimated using concurrent Landsat satellite imagery. Management-yield relationships were analyzed with t tests, linear regression, and regression trees, all of which revealed significant but year-dependent impacts of management on yields. In 2001, an unusually cool year that favored high yields, N fertilizer was the most important source of between-field variability. In 2003, a warmer year with reduced irrigation water allocations, the timing of the first postplanting irrigation was found to be the most important control. Management explained at least 50% of spatial yield variability in both years. Regression tree models, which were able to capture important nonlinearities and interactions, were more appropriate for analyzing yield controls than traditional linear models. The results of this study indicate that adjustments in management can significantly improve wheat production in the Yaqui Valley but that the relevant controls change from year to year.	Carnegie Inst Washington, Dep Global Ecol, Stanford, CA 94305 USA; Stanford Univ, Dep Geol & Environ Sci, Stanford, CA 94305 USA; CIMMYT, Int Maize & Wheat Improvement Cent, Wheat Progr, Mexico City 06600, DF, Mexico; Stanford Univ, Cent Environ Sci & Policy, Inst Int Studies, Stanford, CA 94305 USA	Lobell, DB (reprint author), Carnegie Inst Washington, Dep Global Ecol, 290 Panama St, Stanford, CA 94305 USA.	dlobell@stanford.edu					Baez-Gonzalez AD, 2002, CROP SCI, V42, P1943; Breiman L., 1984, CLASSIFICATION REGRE; Calvino P, 2002, FIELD CROP RES, V74, P1, DOI 10.1016/S0378-4290(01)00193-9; Cassman KG, 1999, P NATL ACAD SCI USA, V96, P5952, DOI 10.1073/pnas.96.11.5952; Conover WJ., 1999, PRACTICAL NONPARAMET; Corwin DL, 2003, AGRON J, V95, P352; De'ath G, 2000, ECOLOGY, V81, P3178, DOI 10.1890/0012-9658(2000)081[3178:CARTAP]2.0.CO;2; FISCHER RA, 1985, J AGR SCI, V105, P447; FLORES D, 2001, EL CULTIVO TRIGO VAL; Haining R., 2003, SPATIAL DATA ANAL TH; Hastie T., 2001, ELEMENTS STAT LEARNI; Ihaka R, 2005, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Landau S, 2000, AGR FOREST METEOROL, V101, P151, DOI 10.1016/S0168-1923(99)00166-5; LAPEN DR, 2001, SOIL TILL RES, V58, P3; Lark RM, 2001, SOIL TILL RES, V58, P99, DOI 10.1016/S0167-1987(00)00161-6; Lobell DB, 2004, FIELD CROP RES, V87, P155, DOI 10.1016/j.fcr.2003.10.004; Lobell DB, 2003, AGR ECOSYST ENVIRON, V94, P205, DOI 10.1016/S0167-8809(02)00021-X; Lobell DB, 2002, AGR FOREST METEOROL, V114, P31, DOI 10.1016/S0168-1923(02)00138-7; Long DS, 1998, GEODERMA, V85, P181, DOI 10.1016/S0016-7061(98)00019-6; MAAS SJ, 1988, AGRON J, V80, P655; Matson PA, 1998, SCIENCE, V280, P112, DOI 10.1126/science.280.5360.112; MEISNER CA, 1992, WHEAT PRODUCTION GO; Moulin S, 1998, INT J REMOTE SENS, V19, P1021, DOI 10.1080/014311698215586; ORTIZMONASTERIO JI, 2002, BREAD WHEAT IMPROVEM, P433; PINGALI PL, 1999, CIMMYT 1998 1999 WOR; Plant RE, 2001, COMPUT ELECTRON AGR, V30, P9, DOI 10.1016/S0168-1699(00)00152-6; Plant RE, 1999, T ASAE, V42, P1187; Sadras V, 2002, AUST J AGR RES, V53, P587, DOI 10.1071/AR01150; Shanahan JF, 2001, AGRON J, V93, P583; White JW, 2002, FIELD CROP RES, V76, P45, DOI 10.1016/S0378-4290(02)00041-2; WIEGAND CL, 1994, REMOTE SENS ENVIRON, V49, P212, DOI 10.1016/0034-4257(94)90017-5; WIESE MV, 1982, ANNU REV PHYTOPATHOL, V20, P419, DOI 10.1146/annurev.py.20.090182.002223	32	50	53	AMER SOC AGRONOMY	MADISON	677 S SEGOE RD, MADISON, WI 53711 USA	0002-1962			AGRON J	Agron. J.	JAN-FEB	2005	97	1					241	249				9	Agronomy	Agriculture	894IB	WOS:000226783300033		
S	Caragea, D; Zhang, J; Bao, J; Pathak, J; Honavar, V		Jain, S; Simon, HU; Tomita, E		Caragea, D; Zhang, J; Bao, J; Pathak, J; Honavar, V			Algorithms and software for collaborative discovery from autonomous, semantically heterogeneous, distributed information sources	ALGORITHMIC LEARNING THEORY	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	16th Annual International Conference on Algorithmic Learning Theory (ALT 2005)	OCT 08-11, 2005	Singapore, SINGAPORE	Lee Fdn, USAF, Asian Off Aerosp Res & Dev, Natl Univ Singapore, Sch Comp, Ruhr Univ Bochum, Fak Math, Hokkaido Univ, Div Comp Sci, Univ Lubeck, Inst Theoret Comp Sci, MBZ Marketing Buro Zeugmann				Development of high throughput data acquisition technologies, together with advances in computing, and communications have resulted in an explosive growth in the number, size, and diversity of potentially useful information sources. This has resulted in unprecedented opportunities in data-driven knowledge acquisition and decision-making in a number of emerging increasingly data-rich application domains such as bioinformatics, environmental informatics, enterprise informatics, and social informatics (among others). However, the massive size, semantic heterogeneity, autonomy, and distributed nature of the data repositories present significant hurdles in acquiring useful knowledge from the available data. This paper introduces some of the algorithmic and statistical problems that arise in such a setting, describes algorithms for learning classifiers from distributed data that offer rigorous performance guarantees (relative to their centralized or batch counterparts). It also describes how this approach can be extended to work with autonomous, and hence, inevitably semantically heterogeneous data sources, by making explicit, the ontologies (attributes and relationships between attributes) associated with the data sources and reconciling the semantic differences among the data sources from a user's point of view. This allows user or context-dependent exploration of semantically heterogeneous data sources. The resulting algorithms have been implemented in INDUS - an open source software package for collaborative discovery from autonomous, semantically heterogeneous, distributed data sources.	Iowa State Univ, Ctr Computat Intelligence Learning & Discovery, Dept Comp Sci, Artificial Intelligence Res Lab, Ames, IA 50011 USA	Caragea, D (reprint author), Iowa State Univ, Ctr Computat Intelligence Learning & Discovery, Dept Comp Sci, Artificial Intelligence Res Lab, Ames, IA 50011 USA.	honavar@cs.iastate.edu					AKIBA Y, 1995, P 12 INT C MACH LEAR; ANDORF C, 2004, 5 INT C KNOWL BAS CO; Arens Y., 1993, International Journal of Intelligent & Cooperative Information Systems, V2, DOI 10.1142/S0218215793000071; ARONIS J, 1996, ISL966 U PITTSB DEP; ARONIS J, 1997, P 3 INT C KNOWL DISC; Ashburner M, 2000, NAT GENET, V25, P25; Atramentov A, 2003, LECT NOTES ARTIF INT, V2835, P38; Baldi P, 2003, MODELING INTERNET WE; BALDI P, 2003, BIOINFORMATICS MACHI; BAO J, 2005, IN PRESS EFFICIENT A; BAO J, 2004, P 3 INT WORKSH EV ON; BARSALOU T, 1992, IEEE DATA ENG; BERGADANO F, 1990, MACHINE LEARNING ART, V3; BHATNAGAR R, 1997, P AAAI 97 C PROV, P503; BISHOP C.M., 1995, NEURAL NETWORKS PATT; Bonatti P, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION, P192, DOI 10.1109/IRI.2003.1251413; Bouquet P., 2003, LNCS, V2870; Bradley PS, 2000, OPTIM METHOD SOFTW, V13, P1, DOI 10.1080/10556780008805771; Breiman L., 1984, CLASSIFICATION REGRE; BRIGHT M, 1992, COMPUT J, V25, P5; CARAGEA C, 2005, P 22 NAT C ART INT A; CARAGEA D, 2005, P 2 INT WORKSH DAT I; Caragea D., 2004, THESIS IOWA STATE U; CARAGEA D, 2004, P INT C ONT DAT APPL; CARAGEA D, 2003, P INT C INT SYST DES; CARAGEA D, 2004, INT J HYBRID INTELLI, V1; CARAGEA D, 2000, P 4 INT C AUT AG BAR, P53; CARAGEA D, 2005, IN PRESS LEARNING CL; Casella G., 2001, STAT INFERENCE; CHANG CK, 1999, ACM SIGMOD INT C MAN; CHEN ALP, 1996, IEEE T KNOWLEDGE DAT, V8; CHEN J, 2003, BIOINFORMATICS, P147; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cristianini N, 2000, INTRO SUPPORT VECTOR; DAVIDSON AC, 2003, STAT MODELS; DAVIDSON S, 2001, IBM J, V40; DEMICHIEL L, 1989, IEEE T KNOWL DATA EN, V1; DESJARDINS M, 2000, LECT NOTES ARTIF INT, V1864, P260; DHAR V, 1993, IEEE T KNOWLEDGE DAT, V5; Domingos P., 1997, P 14 INT C MACH LEAR, P98; Draper D., 2001, ICDE, P155; Duda R.O., 2000, PATTERN RECOGNITION; Dzeroski S., 2001, RELATIONAL DATA MINI; ECKMAN B, 2003, BIOINFORMATICS, P3; ETZOLD T, 2003, BIOINFORMATICS MANAG, P35; Friedman N., 1999, P 16 INT JOINT C ART, P1300; Friedman Nir, 1997, MACHINE LEARNING, V29; Garcia-Molina Hector, 1997, J INTELLIGENT INFORM, V8; Getoor L., 2001, RELATIONAL DATA MINI; Graefe G., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; GROSSMAN L., 2001, HDB DATA MINING KNOW; HAAS L, 1997, P 23 VLDB C ATH GREE, P267; HAAS LM, 2001, IBM SYSTEM J, V40; Han J., 1996, ADV KNOWLEDGE DISCOV; Hastie T., 2001, ELEMENTS STAT LEARNI; HAUSSLER D, 1988, ARTIF INTELL, V36, P177, DOI 10.1016/0004-3702(88)90002-1; HENDLER J, 1996, ADV HIGH PERFORMANCE; Hull R., 1997, Proceedings of the Sixteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, PODS 1997, DOI 10.1145/263661.263668; JUNNINEN H, 2004, ATMOSPHERIC ENV, V38; Kargupta H, 1999, ADV DISTRIBUTED PARA; Kearns M, 1998, J ACM, V45, P983, DOI 10.1145/293347.293351; Knoblock CA, 2001, INT J COOP INF SYST, V10, P145, DOI 10.1142/S0218843001000291; LAMBRECHT E, 1999, P 16 INT JOINT C ART, P1204; Levy A. Y., 1998, IEEE INTELLIGENT SYS, V13; Levy AY, 2000, SPRINGER INT SER ENG, V597, P575; Little R. J. A., 2002, STAT ANAL MISSING DA; LONGFORD N, 2004, J ROYAL STAT SOC A, V167; LU J, 1995, P 1995 ACM SIGMOD C; Madow W. G., 1983, INCOMPLETE DATA SAMP, V2; Madow W. G., 1983, INCOMPLETE DATA SAMP, V1; MALUF D, 1997, LECT NOTES AI, V1315; MANSOUR J, 1994, THEORETICAL ADV NEUR; MCCLEAN S, 2001, IEEE T KNOWLEDGE DAT, V6; Mitchell T., 1997, MACHINE LEARNING; Moore A, 1998, J ARTIF INTELL RES, V8, P67; NEVILLE J, 2003, ICDM 2003; NUNEZ M, 1991, MACHINE LEARNING, V6; Park B.S., 2002, P 7 WORKSH RES ISS D, P18; PAZZANI M, 1997, P 4 INT C KNOWL DISC; PAZZANI M, 1997, P COGN SCI C; PAZZANI M, 1992, MACHINE LEARNING, V9; Prodromidis A., 2000, ADV DISTRIBUTED DATA; Provost F, 1999, DATA MIN KNOWL DISC, V3, P131, DOI 10.1023/A:1009876119989; Quinlan R., 1986, MACH LEARN, V1, P81; RAGHUNATHAN T, 2004, ANN REV PUBLIC HLTH, V25; REINOSOCASTILLO J, 2003, IEEE INT C INF INT R; Rodriguez-Martinez M., 2000, P 2000 ACM SIGMOD IN, P213, DOI 10.1145/342009.335413; RUBIN D, 1996, J AM STAT ASS, V91; RUBIN D, 1978, P AM STAT ASS SECT S; Sheth A., 1990, ACM COMPUT SURV, V22, P183, DOI 10.1145/96602.96604; Sowa JF, 1999, KNOWLEDGE REPRESENTA; Srivastava A, 1999, DATA MIN KNOWL DISC, V3, P237, DOI 10.1023/A:1009832825273; STEVENS R, 2003, BIOINFORMATICS MANAG, P189; TANNEN V, 2003, BIOINFORMATICS, P255; TAYLOR M, 1997, SIGMOD DATA MINING K; THRUN S, 1999, AI MAGAZINE; Tomasic A, 1998, IEEE T KNOWL DATA EN, V10, P808, DOI 10.1109/69.729736; TOWELL G, 1994, ARTIFIICAL INTELLIGE, V70; WALKER A, 1989, VLDB C 1989; WANG X, 2002, P C COMP BIOL GEN IN; Wiederhold G, 1997, IEEE INTELL SYST APP, V12, P38, DOI 10.1109/64.621227; Yan Changhui, 2004, Bioinformatics, V20 Suppl 1, pi371, DOI 10.1093/bioinformatics/bth920; Yan CH, 2004, NEURAL COMPUT APPL, V13, P123, DOI 10.1007/s00521-004-0414-3; Zhang J., 2003, P 20 INT C MACH LEAR, P880; ZHANG J, 2004, P 4 ICMD	105	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29242-X	LECT NOTES ARTIF INT			2005	3734						13	44				32	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	BDH68	WOS:000233583800004		
S	Har-Peled, S; Koltun, V		Deng, X; Du, D		Har-Peled, S; Koltun, V			Separability with outliers	ALGORITHMS AND COMPUTATION	Lecture Notes in Computer Science		English	Article; Proceedings Paper	16th International Symposium on Algorithms and Computations (ISAAC 2005)	DEC 19-21, 2005	Hainan, PEOPLES R CHINA	Chinese Acad Sci, Acad Math & Syst Sci, City Univ Hong Kong, Univ Hong Kong			APPROXIMATION ALGORITHMS; 3 DIMENSIONS; WIDTH; ARRANGEMENTS; POINTS; SHELLS; LINES	We develop exact and approximate algorithms for computing optimal separators and measuring the extent to which two point sets in d-dimensional space are separated, with respect to different classes of separators and various extent measures. This class of geometric problems generalizes two widely studied problem families, namely separability and the computation of statistical estimators.	Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA	Har-Peled, S (reprint author), Univ Illinois, Dept Comp Sci, 201 N Goodwin Ave, Urbana, IL 61801 USA.	sariel@cs.uiuc.edu; vladlen@cs.stanford.edu					Agarwal PK, 1998, DISCRETE COMPUT GEOM, V19, P315, DOI 10.1007/PL00009348; AGARWAL PK, 2005, IN PRESS ACM T ALGOR; Agarwal PK, 2004, J ACM, V51, P606, DOI 10.1145/1008731.1008736; Agarwal PK, 1999, DISCRETE COMPUT GEOM, V21, P373, DOI 10.1007/PL00009427; Agarwal PK, 2001, DISCRETE COMPUT GEOM, V26, P307, DOI 10.1007/s00454-001-0039-6; Agarwal PK, 2000, DISCRETE COMPUT GEOM, V24, P687, DOI 10.1007/s004540010062; Agarwal P. K., 2000, Nordic Journal of Computing, V7; ARKIN EM, 2001, 11 FALL WORKSH COMP; ARONOV B, 2005, P 16 ACM SIAM S DISC; Brodal G. S., 2002, Proceedings 43rd Annual IEEE Symposium on Foundations of Computer Science, DOI 10.1109/SFCS.2002.1181985; Chan TM, 2002, INT J COMPUT GEOM AP, V12, P67, DOI 10.1142/S0218195902000748; Chan TM, 1996, DISCRETE COMPUT GEOM, V16, P369, DOI 10.1007/BF02712874; CHAN TM, 2004, P 20 ANN ACM S COMP, P152, DOI 10.1145/997817.997843; Chan T. M., 2002, Proceedings 43rd Annual IEEE Symposium on Foundations of Computer Science, DOI 10.1109/SFCS.2002.1181981; Charikar M, 2001, SIAM PROC S, P642; CHAZELLE B, 1993, DISCRETE COMPUT GEOM, V10, P377, DOI 10.1007/BF02573985; Cristianini N., 2000, SUPPORT VECTOR MACHI; Dudley R. M., 1974, Journal of Approximation Theory, V10, DOI 10.1016/0021-9045(74)90120-8; Duncan CA, 1997, PROCEEDINGS OF THE EIGHTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P121; EDELSBRUNNER H, 1986, SIAM J COMPUT, V15, P341, DOI 10.1137/0215024; EDELSBRUNNER H, 1987, EATCS MONOGRAPHS THE, V10; EDELSBRUNNER H, 1988, INFORM COMPUT, V77, P218, DOI 10.1016/0890-5401(88)90049-1; Everett H, 1996, INT J COMPUT GEOM AP, V6, P247, DOI 10.1142/S0218195996000186; FEKETE SP, 1992, UNPUB SUNY STONY BRO; Har-Peled S, 2004, SIAM J COMPUT, V33, P269, DOI 10.1137/S0097539703427963; HARPELED S, 2003, P 19 ANN ACM S COMP, P39; Hastie T., 2001, ELEMENTS STAT LEARNI; HURTADO F, 1999, P 15 EUR WORKSH COMP, P33; Hurtado F, 2001, DISCRETE APPL MATH, V109, P109, DOI 10.1016/S0166-218X(00)00230-4; HURTADO F, 2003, P 3 INT C COMP SCI I, P766; MATOUSEK J, 1995, DISCRETE COMPUT GEOM, V14, P365, DOI 10.1007/BF02570713; MEGIDDO N, 1984, J ACM, V31, P114, DOI 10.1145/2422.322418; Mitchell J.S.B., 1993, APPROXIMATION ALGORI; OROURKE J, 1986, DISCRETE COMPUT GEOM, V1, P105, DOI 10.1007/BF02187688; Sharir M, 2001, DISCRETE COMPUT GEOM, V26, P195, DOI 10.1007/s00454-001-0005-3; Vapnik VN, 1996, NATURE STAT LEARNING; Yamamoto P., 1988, Proceedings of the Fourth Annual Symposium on Computational Geometry, DOI 10.1145/73393.73429	37	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-30935-7	LECT NOTES COMPUT SC			2005	3827						28	39				12	Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	BDQ35	WOS:000234885900005		
S	Waagen, D; Shah, N; Ordaz, M; Cassabaum, M		Zeinio, EG; Garber, FD		Waagen, D; Shah, N; Ordaz, M; Cassabaum, M			Random subspaces and SAR classification efficacy	Algorithms for Synthetic Aperture Radar Imagery XII	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Conference on Algorithms for Symthetic Aperture Radar Imagery XII	MAR 28-31, 2005	Orlando, FL			random projections; dimensionality reduction; distance preserving projections; synthetic aperture radar; classification	SET	The 'curse of dimensionality' has limited the application of statistical modeling techniques to low-dimensional spaces, but typical data usually resides in high-dimensional spaces (at least initially, for instance images represented as arrays of pixel values). Indeed, approaches such as Principal Component Analysis and Independent Component Analysis attempt to extract a set of meaningful linear projections while minimizing interpoint distance distortions. The counterintuitive yet effective random projections approach of Johnson and Lindenstrauss defines a sample-based dimensionality reduction technique with probabilistically provable distortion bounds. We investigate and report on the relative efficacy of two random projection techniques for Synthetic Aperture Radar images in a classification setting.								Bingham E., 2001, P 7 ACM SIGKDD INT C, P245, DOI 10.1145/502512.502546; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASGUPTA S, 1999, TR99066; DASGUPTA S, 2000, P UNCERTAINTY ARTIFI; DEYROYE L, 1996, PROBABILISITIC THEOR; DUDA RO, 2001, PATTERN CALSSIFICATI; FOLEY DH, 1975, IEEE T COMPUT, VC 24, P281, DOI 10.1109/T-C.1975.224208; FOLEY DH, 1972, IEEE T INFORM THEORY, V18, P618, DOI 10.1109/TIT.1972.1054863; FRIEDMAN J, 1979, ANAL STAT, V7; Fukunaga K, 1990, INTRO STAT PATTERN R; Han P, 2003, P IEEE ICASSP, VII, P429; Hastie T., 2001, ELEMENTS STAT LEARNI; HERO AO, 2002, IEEE SIGNAL PROC SEP, P85; Johnson W. B., 1984, CONT MATH, V26, P189; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; LINIAL N, 1995, COMBINATORICA, V15, P215, DOI 10.1007/BF01200757; Ross T, 1998, P SOC PHOTO-OPT INS, V3370, P566, DOI 10.1117/12.321859; Scott D. W., 1992, MULTIVARIATE DENSITY; SILVERMAN BW, 1986, DENISTY ESTIMATION; Zhao Q, 2001, IEEE T AERO ELEC SYS, V37, P643, DOI 10.1109/7.937475	20	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		0-8194-5793-0	P SOC PHOTO-OPT INS			2005	5808						257	268		10.1117/12.602523		12	Computer Science, Interdisciplinary Applications; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BCU80	WOS:000231335900026		
J	Parmee, IC				Parmee, IC			Human-centric intelligent systems for exploration and knowledge discovery	ANALYST			English	Article							DESIGN	This speculative article discusses research and development relating to computational intelligence (CI) technologies comprising powerful machine-based search and exploration techniques that can generate, extract, process and present high-quality information from complex, poorly understood biotechnology domains. The integration and capture of user experiential knowledge within such CI systems in order to support and stimulate knowledge discovery and increase scientific and technological understanding is of particular interest. The manner in which appropriate user interaction can overcome problems relating to poor problem representation within systems utilising evolutionary computation (EC), machine-learning and software agent technologies is investigated. The objective is the development of user-centric intelligent systems that support an improving knowledge-base founded upon gradual problem re-definition and reformulation. Such an approach can overcome initial lack of understanding and associated uncertainty.	Univ W England, Adv Computat Design & Decis Making CEMS, Bristol BS16 1QY, Avon, England	Parmee, IC (reprint author), Univ W England, Adv Computat Design & Decis Making CEMS, Bristol BS16 1QY, Avon, England.	ian.parmee@uwe.ac.uk					Back T, 1997, HDB EVOLUTIONARY COM; CORNEC D, 1999, NEW IDEAS OPTIMIZATI; CVETKOVIC D, 2003, IN PRESS ARTIF INTEL; CVETKOVIC D, 2001, IEEE T EVOLUTIONARY, V6, P42; Duda R.O., 2001, PATTERN CLASSIFICATI; FODOR J, 1994, SYTEM THEORY KNOWLED, V14; Gillet VJ, 2002, J CHEM INF COMP SCI, V42, P375, DOI 10.1021/ci010375j; Goel AK, 1997, IEEE EXPERT, V12, P62; Goldberg D.E., 1989, GENETIC ALGORITHMS S; Hastie T., 2001, ELEMENTS STAT LEARNI; Pahl G., 1984, ENG DESIGN DESIGN CO; Parmee I., 2001, EVOLUTIONARY ADAPTIV; Parmee IC, 2000, EVOL COMPUT, V8, P197, DOI 10.1162/106365600568176; PARMEE IC, 2002, AI EDAM, V16, P3; PARMEE IC, 1999, ARTIF INTELL, V14, P3; Parmee IC, 2004, IEEE C EVOL COMPUTAT, P395; SPIETH C, 2004, P IEEE C EV COMP, V1, P152; SU NP, 1990, PRINCIPLES DESIGN; Woodridge M, 1995, KNOWL ENG REV, V10, P115	19	3	3	ROYAL SOC CHEMISTRY	CAMBRIDGE	THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND	0003-2654			ANALYST	Analyst		2005	130	1					29	34		10.1039/b307211h		6	Chemistry, Analytical	Chemistry	881JY	WOS:000225865000003	15614348	
J	Kalivas, JH				Kalivas, JH			Multivariate calibration, an overview	ANALYTICAL LETTERS			English	Review						multivariate calibration; bias; variance; harmony; parsimony; regularization	PARTIAL LEAST-SQUARES; INFRARED REFLECTANCE SPECTROSCOPY; PRINCIPAL COMPONENTS REGRESSION; CROSS-VALIDATION; STANDARD ERROR; WAVELENGTH SELECTION; MAXIMUM-LIKELIHOOD; AGRICULTURAL SOILS; PARETO CALIBRATION; PREDICTION ERROR	Numerous methods of multivariate calibration methods exist with ridge regression, principal component regression, and partial least squares being the most popular methods in analytical chemistry. This mini-review overviews multivariate calibration and provides a common theme with respect to the bias/variance tradeoff (harmony) and the harmony/parsimony tradeoff for model selection. Other multivariate calibration considerations are briefly reviewed. A few applications are noted.	Idaho State Univ, Dept Chem, Pocatello, ID 83209 USA	Kalivas, JH (reprint author), Idaho State Univ, Dept Chem, Pocatello, ID 83209 USA.	kalijohn@isu.edu					Andersen CM, 2004, CHEMOMETR INTELL LAB, V72, P43, DOI 10.1016/j.chemolab.2003.12.014; Anderson CE, 1999, APPL SPECTROSC, V53, P1268, DOI 10.1366/0003702991945515; Anderson KJ, 2003, APPL SPECTROSC, V57, P309, DOI 10.1366/000370203321558227; Andersson C, 2000, J CHEMOMETR, V14, P103, DOI 10.1002/1099-128X(200005/06)14:3<103::AID-CEM624>3.0.CO;2-L; [Anonymous], 1998, ANN BOOK ASTM STAND; Apruzzese F, 2002, APPL SPECTROSC, V56, P1268, DOI 10.1366/000370202760354713; Bakshi BR, 1999, ANAL CHIM ACTA, V384, P227, DOI 10.1016/S0003-2670(98)00776-4; Baumann K, 2003, TRAC-TREND ANAL CHEM, V22, P395, DOI 10.1016/S0165-9936(03)00607-1; BEEBE KR, 1998, CHEMOMETRISC PRACTIC; BELLON V, 1993, APPL SPECTROSC, V47, P1079, DOI 10.1366/0003702934415255; Blanco M, 2002, TRAC-TREND ANAL CHEM, V21, P240, DOI 10.1016/S0165-9936(02)00404-1; Boque R, 1999, CHEMOMETR INTELL LAB, V45, P397, DOI 10.1016/S0169-7439(98)00195-6; Boschetti CE, 2001, J NEAR INFRARED SPEC, V9, P245; BRERETON RG, 2003, CHEMOMETRICS DATA AN; Brown CD, 2004, ANAL CHEM, V76, P4364, DOI 10.1021/ac049953w; Burnham AJ, 1996, J CHEMOMETR, V10, P31, DOI 10.1002/(SICI)1099-128X(199601)10:1<31::AID-CEM398>3.0.CO;2-1; Burnham AJ, 1999, J CHEMOMETR, V13, P49, DOI 10.1002/(SICI)1099-128X(199901/02)13:1<49::AID-CEM531>3.0.CO;2-K; CAPRON X, 2005, CHEMOMETRICS INTELL, V67, P205; Centner V, 2000, APPL SPECTROSC, V54, P608, DOI 10.1366/0003702001949816; Ciavarella S., 1998, J NEAR INFRARED SPEC, V6, P63; Cogdill RP, 2004, J NEAR INFRARED SPEC, V12, P93; Confalonieri M, 2001, J NEAR INFRARED SPEC, V9, P123; Cruz SC, 2005, ANAL CHEM, V77, P2227, DOI 10.1021/ac048421c; DEVIRES S, 1995, CHEMOMETRICS INTELL, V30, P239; Ding Q, 2000, APPL SPECTROSC, V54, P1047, DOI 10.1366/0003702001950553; do Nascimento PC, 2001, ANAL LETT, V34, P1967, DOI 10.1081/AL-100106126; Dyrby M, 2002, APPL SPECTROSC, V56, P579, DOI 10.1366/0003702021955358; Eysel HH, 1997, BIOSPECTROSCOPY, V3, P161, DOI 10.1002/(SICI)1520-6343(1997)3:2<161::AID-BSPY9>3.0.CO;2-A; Faber K, 1997, J CHEMOMETR, V11, P181, DOI 10.1002/(SICI)1099-128X(199705)11:3<181::AID-CEM459>3.0.CO;2-7; Faber K, 1996, CHEMOMETR INTELL LAB, V34, P283, DOI 10.1016/0169-7439(96)00022-6; Faber NM, 2002, CHEMOMETR INTELL LAB, V61, P133, DOI 10.1016/S0169-7439(01)00204-0; Olivieri AC, 2004, CHEMOMETR INTELL LAB, V70, P75, DOI 10.1016/j.chemolab.2003.10.005; Faber NM, 1999, J CHEMOMETR, V13, P185, DOI 10.1002/(SICI)1099-128X(199903/04)13:2<185::AID-CEM538>3.0.CO;2-N; Faber NM, 2003, TRAC-TREND ANAL CHEM, V22, P352, DOI 10.1016/S0165-9936(03)00604-6; Faber NM, 2003, TRAC-TREND ANAL CHEM, V22, P330, DOI 10.1016/S0165-9936(03)00503-X; Faber NM, 2002, CHEMOMETR INTELL LAB, V64, P169, DOI 10.1016/S0169-7439(02)00102-8; Fearn T, 2001, J NEAR INFRARED SPEC, V9, P229; Pierna JAF, 2003, CHEMOMETR INTELL LAB, V65, P281; Ferre J, 2003, CHEMOMETR INTELL LAB, V69, P123, DOI 10.1016/S0169-7439(03)00118-7; FERRE J, 2000, J CHEMOMETR, V15, P537; Feudale R.N., 2002, CHEMOM INTELL LAB SY, V64, P181, DOI DOI 10.1016/S0169-7439(02)00085-0; Forrester JB, 2004, J CHEMOMETR, V18, P372, DOI 10.1002/cem.883; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Geladi P, 2002, CHEMOMETR INTELL LAB, V60, P211, DOI 10.1016/S0169-7439(01)00197-6; GUSANTO A, 2003, J CHEMOMETR, V17, P174; Hancock T, 2005, CHEMOMETR INTELL LAB, V76, P185, DOI 10.1016/j.chemolab.2004.11.001; HANSEN PC, 2001, COMPUTATIONAL INVERS; Hanson P. C., 1998, RANK DEFICIENT DISCR; Hastie T., 2001, ELEMENTS STAT LEARNI; HOSKULDSSON A, 1992, CHEMOMETR INTELL LAB, V14, P139, DOI 10.1016/0169-7439(92)80099-P; Hoy M, 1998, CHEMOMETR INTELL LAB, V44, P123, DOI 10.1016/S0169-7439(98)00163-4; Huang J, 2002, CHEMOMETR INTELL LAB, V62, P25, DOI 10.1016/S0169-7439(01)00211-8; Jiang JH, 2002, ANAL CHEM, V74, P3555, DOI 10.1021/ac011177u; Kalivas JH, 2004, ANAL CHIM ACTA, V505, P9, DOI 10.1016/S0003-2670(02)01603-3; Kalivas JH, 2001, APPL SPECTROSC, V55, P1645, DOI 10.1366/0003702011953955; Kalivas JH, 1999, J CHEMOMETR, V13, P111, DOI 10.1002/(SICI)1099-128X(199903/04)13:2<111::AID-CEM532>3.3.CO;2-E; Kalivas JH, 2001, ANAL CHIM ACTA, V428, P31, DOI 10.1016/S0003-2670(00)01225-3; Kalivas JH, 1994, MATH ANAL SPECTRAL O; Kalivas JH, 2004, J COMPUT AID MOL DES, V18, P537, DOI 10.1007/s10822-004-4063-5; KRAMMER R, 1998, CHEMOMETRIC TECHNIQU; Lang PM, 1998, J MULTIVARIATE ANAL, V65, P58, DOI 10.1006/jmva.1997.1727; LANG PM, 1993, J CHEMOMETR, V7, P153, DOI 10.1002/cem.1180070303; Lavine B., 2000, ANAL CHEM, V72, P91, DOI 10.1021/a1000016x; Lavine B, 2004, ANAL CHEM, V76, P3365, DOI 10.1021/ac040053p; Lavine BK, 2002, ANAL CHEM, V74, P2763, DOI 10.1021/ac020224v; Leger MN, 2004, APPL SPECTROSC, V58, P855, DOI 10.1366/0003702041389382; LIU K, 2000, AM J OBSTET GYNECOL, V183, P81; Lorber A., 1988, J CHEMOMETR, V2, P93, DOI 10.1002/cem.1180020203; MANTSCH HH, 1998, P SPIE INFR SPECTR N, V3257; Martens H., 1991, MULTIVARIATE CALIBRA; Marx BD, 2002, J CHEMOMETR, V16, P129, DOI 10.1002/cem.701; Melgaard DK, 2002, APPL SPECTROSC, V56, P615, DOI 10.1366/0003702021955178; Myers RH, 1990, CLASSICAL MODERN REG; Naes T., 2002, USER FRIENDLY GUIDE; Niemczyk TM, 2001, APPL SPECTROSC, V55, P1053, DOI 10.1366/0003702011952956; OLIVIERI AC, UNPUB IUPAC; Olivieri AC, 2002, J CHEMOMETR, V16, P207, DOI 10.1002/cem.716; Reeves JB, 2001, J NEAR INFRARED SPEC, V9, P25; Roussel SA, 2001, APPL SPECTROSC, V55, P1425, DOI 10.1366/0003702011953586; SCHOLKOPF B, 2002, LEARNING KERNALS; Seipel HA, 2004, J CHEMOMETR, V18, P306, DOI 10.1002/cem.874; Sekulic S., 1993, ANAL CHEM, V65, P835; SHAO J, 1993, J AM STAT ASSOC, V88, P486, DOI 10.2307/2290328; Stallard BR, 1996, APPL SPECTROSC, V50, P334, DOI 10.1366/0003702963906221; STOUT F, UNPUB J CHEMOMETRIC; TILLMANN P, 2000, J NEAR INFRARED SPEC, V8, P103; Vaidyanathan S, 2001, APPL SPECTROSC, V55, P444, DOI 10.1366/0003702011951957; Weisberg S., 2005, APPL LINEAR REGRESSI; Wentzell PD, 2003, CHEMOMETR INTELL LAB, V65, P257, DOI 10.1016/S0169-7439(02)00138-7; WESTERHAUS MO, 1990, P 3 INT C NEAR INFR; Xu QS, 2001, J CHEMOMETR, V15, P135, DOI 10.1002/cem.605; Xu QS, 2001, CHEMOMETR INTELL LAB, V56, P1, DOI 10.1016/S0169-7439(00)00122-2; Ye JM, 1998, J AM STAT ASSOC, V93, P120, DOI 10.2307/2669609; Yeow YL, 2005, APPL SPECTROSC, V59, P584, DOI 10.1366/0003702053946056	94	19	21	TAYLOR & FRANCIS INC	PHILADELPHIA	325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA	0003-2719			ANAL LETT	Anal. Lett.		2005	38	14					2259	2279		10.1080/0032710500315904		21	Chemistry, Analytical	Chemistry	992KL	WOS:000233882700001		
S	Verduijn, M; Peek, N; Voorbraak, F; de Jonge, E; de Mol, B		Miksch, S; Hunter, J; Keravnou, E		Verduijn, M; Peek, N; Voorbraak, F; de Jonge, E; de Mol, B			Dichotomization of ICU length of stay based on model calibration	ARTIFICIAL INTELLIGENCE IN MEDICINE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	10th Conference on Artificial Intelligence in Medicine (AIME 2005)	JUL 23-27, 2005	Aberdeen, SCOTLAND	Soc Artificial Intelligence Med	Univ Aberdeen		INTENSIVE-CARE-UNIT; CARDIAC-SURGERY; PROLONGED VENTILATION; SURVIVAL; BYPASS	This paper presents a method to choose the threshold for dichotomization of survival outcomes in a structured fashion based on data analysis. The method is illustrated with an application to the prediction problem of the outcome length of stay at Intensive Care Unit (ICU LOS). Threshold selection is based on comparing the calibration of predictive models for dichotomized outcomes with increasing threshold values. To quantify model calibration a measure insensitive to class unbalance is used. The threshold value for which the associated predictive model has superior calibration is selected, and the corresponding model is used in practice. Using this method to select the threshold for ICU LOS, the best model calibration is found at a threshold of five days.	Univ Amsterdam, Acad Med Ctr, Dept Med Informat, NL-1105 AZ Amsterdam, Netherlands; Univ Amsterdam, Acad Med Ctr, Dept Intens Care Med, NL-1105 AZ Amsterdam, Netherlands; Univ Amsterdam, Acad Med Ctr, Dept Cardiothorac Surg, NL-1105 AZ Amsterdam, Netherlands; Eindhoven Univ Technol, Dept Biomed Engn, NL-5600 MB Eindhoven, Netherlands	Verduijn, M (reprint author), Univ Amsterdam, Acad Med Ctr, Dept Med Informat, Meibergdreef 9, NL-1105 AZ Amsterdam, Netherlands.						Ash A, 1999, STAT MED, V18, P375, DOI 10.1002/(SICI)1097-0258(19990228)18:4<375::AID-SIM20>3.0.CO;2-J; Bashour CA, 2000, CRIT CARE MED, V28, P3847, DOI 10.1097/00003246-200012000-00018; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L., 1984, CLASSIFICATION REGRE; Brier G. W, 1950, MONTHLY WEATHER REVI, V78, P1, DOI DOI 10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2; Christakis G T, 1996, Cardiovasc Surg, V4, P29, DOI 10.1016/0967-2109(96)83780-X; COX DR, 1972, J R STAT SOC B, V34, P187; DAWID AP, 1982, J AM STAT ASSOC, V77, P605, DOI 10.2307/2287720; Dunning J, 2003, EUR J CARDIO-THORAC, V24, P270, DOI 10.1016/S1010-7940(03)00269-0; Efron Bradley, 1993, INTRO BOOTSTRAP; HAND D.J., 1997, CONSTRUCTION ASSESSM; Hastie T., 2001, ELEMENTS STAT LEARNI; Hugot P, 2003, INTENS CARE MED, V29, P257, DOI 10.1007/s00134-002-1587-9; Janssen DPB, 2004, EUR J CARDIO-THORAC, V25, P203, DOI 10.1016/j.ejcts.2003.11.005; Keles S, 2002, STAT MED, V21, P313, DOI 10.1002/sim.981; Kern H, 2001, INTENS CARE MED, V27, P407, DOI 10.1007/s001340000802; Marcin JP, 2001, CRIT CARE MED, V29, P652, DOI 10.1097/00003246-200103000-00035; METZ CE, 1978, SEMIN NUCL MED, V8, P283, DOI 10.1016/S0001-2998(78)80014-2; Murphy A. H., 1973, Journal of Applied Meteorology, V12, DOI 10.1175/1520-0450(1973)012<0595:ANVPOT>2.0.CO;2; Stein PK, 2001, CRIT CARE MED, V29, P1738, DOI 10.1097/00003246-200109000-00014; Therneau TM, 1997, INTRO RECURSIVE PART; TU JV, 1995, CIRCULATION, V91, P677; VERDUIJN M, 2005, 200501 U AMSTR DEP M; WYATT JC, 1995, BRIT MED J, V311, P1539	24	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-27831-1	LECT NOTES ARTIF INT			2005	3581						67	76				10	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical	Computer Science; Engineering	BCS45	WOS:000231040400010		
S	Pruneda, RE; Lacruz, B; Solares, C		Duch, W; Kacprzyk, J; Oja, E; Zadrozny, S		Pruneda, RE; Lacruz, B; Solares, C			A first approach to solve classification problems based on functional networks	ARTIFICIAL NEURAL NETWORKS: FORMAL MODELS AND THEIR APPLICATIONS - ICANN 2005, PT 2, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	15th International Conference on Artificial Neural Networks (ICANN 2005)	SEP 11-15, 2005	Warsaw, POLAND	European Neural Network Soc, Int Neural Network Soc, Japanese Neural Network Soc, IEEE Computat Intelligence Soc				In this paper the ability of the functional networks approach to solve classification problems is explored. Functional networks were introduced by Castillo et al. [1] as an alternative to neural networks. They have the same purpose, but unlike neural networks, neural functions are learned instead of weights, using families of linear independent functions. This is illustrated by applying several models of functional networks to a set of simulated data and to the well-known Iris data and Pima Indian data sets.	Univ Castilla La Mancha, E-13071 Ciudad Real, Spain; Univ Zaragoza, Zaragoza, Spain	Pruneda, RE (reprint author), Univ Castilla La Mancha, E-13071 Ciudad Real, Spain.	rosa.pruneda@uclm.es; lacruz@unizar.es; cristina.solares@uclm.es	Pruneda, Rosa/M-1120-2014	Pruneda, Rosa/0000-0003-3923-7745			Castillo E., 1998, INTRO FUNCTIONAL NET; Castillo E, 1992, FUNCTIONAL EQUATIONS; Hastie T., 2001, ELEMENT STAT LEARNIN; Ripley Brian D., 2002, PATTERN RECOGNITION	4	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-28755-8	LECT NOTES COMPUT SC			2005	3697						313	318				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCZ97	WOS:000232196000050		
S	Fierascu, C		Duch, W; Kacprzyk, J; Oja, E; Zadrozny, S		Fierascu, C			Counterpropagation with delays with applications in time series prediction	ARTIFICIAL NEURAL NETWORKS: FORMAL MODELS AND THEIR APPLICATIONS - ICANN 2005, PT 2, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	15th International Conference on Artificial Neural Networks (ICANN 2005)	SEP 11-15, 2005	Warsaw, POLAND	European Neural Network Soc, Int Neural Network Soc, Japanese Neural Network Soc, IEEE Computat Intelligence Soc			NETWORKS	The paper presents a method for time series prediction using a complete counterpropagation network with delay kernels. Our network takes advantage of the clustering and mapping capability of the original CPN combined with dynamical elements and become able to discover and approximate the strongest topological and temporal relationships among the fields in the data. Experimental results using two chaotic time series and a set of astrophysical data validate the performance of the proposed method.	Salzburg Univ, Inst Comp Sci, A-5020 Salzburg, Austria	Fierascu, C (reprint author), Salzburg Univ, Inst Comp Sci, A-5020 Salzburg, Austria.	cfierasc@cosy.sbg.ac.at					Abarbanel HDI, 1996, ANAL OBSERVED CHAOTI; Binney J., 1987, GALACTIC DYNAMICS; BUTA R, 1987, ASTROPHYS J SUPPL S, V64, P1, DOI 10.1086/191190; CASDAGLI M, 1989, PHYSICA D, V35, P335, DOI 10.1016/0167-2789(89)90074-2; FIERASCU C, 2004, P IEEE INT JOINT C N; Hastie T., 2001, ELEMENTS STAT LEARNI; HECHTNIELSEN R, 1988, NEURAL NETWORKS, V1, P131, DOI 10.1016/0893-6080(88)90015-9; HECHTNIELSEN R, 1987, APPL OPTICS, V26, P4979, DOI 10.1364/AO.26.004979; Kohonen T., 2001, SELF ORGANIZING MAPS; Wan Eric, 1993, THESIS STANFORD U; Weigend A. S., 1993, TIME SERIES PREDICTI	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-28755-8	LECT NOTES COMPUT SC			2005	3697						533	539				7	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCZ97	WOS:000232196000084		
S	Shah, N; Waagen, D; Ordaz, M; Cassabaum, M; Coit, A		Sadjadi, FA		Shah, N; Waagen, D; Ordaz, M; Cassabaum, M; Coit, A			Exploration of high-dimensional data manifolds for object classification	Automatic Target Recogniton XV	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	15th Conference on Automatic Target Recognition	MAR 29-31, 2005	Orlando, FL	SPIE		manifold extraction; dimensionality reduction; nonlinear Principal Component Analysis; ISOMAP; Synthetic Aperture Radar; classification; Automatic Target Recognition	RECOGNITION; REDUCTION	This investigation discusses the challenge of target classification in terms of intrinsic dimensionality estimation and selection of appropriate feature manifolds with object-specific classifier optimization. The feature selection process will be developed via nonlinear characterization and extraction of the target-conditional manifolds derived from the training data. We investigate defining the feature space used for classification as a class-conditioned nonlinear embedding, i.e., each training and test image is embedded in a target-specific embedding and the resultant embeddings are used for statistical characterization. We compare and contrast this novel embedding technique with Principal Component Analysis. The alpha-Jensen Entropy Difference measure is used to quantify the object-conditioned separation between the target distributions in the feature spaces. We discuss and demonstrate the effect of feature space extraction on classification efficacy.								BELKIN M, 2001, NEURAL COMPUT, V15, P1373; Bengio Y., 2003, P NEUR INF PROC SYST; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264136; Devroye L., 1996, PROBABILISTIC THEORY; FOLEY DH, 1972, IEEE T INFORM THEORY, V18, P618, DOI 10.1109/TIT.1972.1054863; Fukunaga K, 1990, INTRO STAT PATTERN R; HAM J, 2003, 110 MAXPL I BIOL CYB; Han P, 2003, P IEEE ICASSP, VII, P429; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Hastie T., 2001, ELEMENTS STAT LEARNI; HERO AO, 2002, IEEE SIGNAL PROC SEP, P85; Ross T, 1998, P SOC PHOTO-OPT INS, V3370, P566, DOI 10.1117/12.321859; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Zhao Q, 2001, IEEE T AERO ELEC SYS, V37, P643, DOI 10.1109/7.937475	16	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		0-8194-5792-2	P SOC PHOTO-OPT INS			2005	5807						400	408		10.1117/12.602500		9	Automation & Control Systems; Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Automation & Control Systems; Computer Science; Imaging Science & Photographic Technology	BCV38	WOS:000231409200039		
B	Oba, S; Kato, K; Ishii, S			IEEE Computer Society	Oba, S; Kato, K; Ishii, S			Multi-scale clustering for gene expression profiling data	BIBE 2005: 5th IEEE Symposium on Bioinformatics and Bioengineering			English	Proceedings Paper	5th IEEE Symposium on Bioinformatics and Bioengineering	OCT 19-21, 2005	Minneapolis, MN	IEEE Comp Soc, Biol & Artificial Intelligence Soc, Univ Minnesota, Digital Technol Ctr, Wright State Univ, ITRI, IEEE				In cluster analyses, setting the scale parameter which is implicitly related to the complexity of the data distribution is an important issue; different scale values lead to different results and hence cause different interpretation. In this study, we discuss a framework of multi-scale clustering, where clustering is done with multiple scale values and then the obtained results are compiled into a visually appropriate form to observe overall structures of the clusters. For such purpose, a brick view method is proposed in this study. The construction of a brick view diagram consists of a re-indexing procedure of clusters obtained with various scale values and a sorting procedure of samples so as to minimize the distortion defined based on the multiple clustering results. Although some popular clustering methods, such as K-means, spherical K-means, and hierarchical clustering, have been used within the multi-scale framework we introduce mean-shift clustering based on the kernel density estimation for directional data. We evaluate our approach and existing hierarchical clustering by using an artificial data set and a real data set of gene expression profiles. The results show global structures of distributions can be observed well and in a stable manner, in the brick view diagram.	Nara Inst Sci & Technol, Grad Sch Informat Sci, Ikoma, Japan	Oba, S (reprint author), Nara Inst Sci & Technol, Grad Sch Informat Sci, Takayama 8916-5, Ikoma, Japan.						Bar-Joseph Z, 2001, Bioinformatics, V17 Suppl 1, pS22; Chakravarthy SV, 1996, IEEE T NEURAL NETWOR, V7, P1250, DOI 10.1109/72.536318; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; DHILLON IS, 2002, BIOINFORMATICS, V19, P1612; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; HALL P, 1987, BIOMETRIKA, V74, P751, DOI 10.1093/biomet/74.4.751; Hastie T., 2001, ELEMENTS STAT LEARNI; Liu XL, 2003, BIOINFORMATICS, V19, P1937, DOI 10.1093/bioinformatics/btg257; Ohira M, 2005, CANCER CELL, V7, P337, DOI 10.1016/j.ccr.2005.03.019; Rose K, 1998, P IEEE, V86, P2210, DOI 10.1109/5.726788; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Venet D, 2003, BIOINFORMATICS, V19, P659, DOI 10.1093/bioinformatics/btg046	12	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2476-1				2005							210	217				8	Biochemical Research Methods; Engineering, Biomedical	Biochemistry & Molecular Biology; Engineering	BDM77	WOS:000234335200027		
J	Wang, P; Kim, Y; Pollack, J; Narasimhan, B; Tibshirani, R				Wang, P; Kim, Y; Pollack, J; Narasimhan, B; Tibshirani, R			A method for calling gains and losses in array CGH data	BIOSTATISTICS			English	Article						array CGH; CLAC; cluster; DNA copy number	MICROARRAYS	Array CGH is a powerful technique for genomic studies of cancer, It enables one to carry out genome-wide screening for regions of genetic alterations, such as chromosome gains and losses. or localized amplifications and deletions. In this paper, we propose a new algorithm 'Cluster along chromosomes' (CLAC) for the analysis of array CGH data. CLAC builds hierarchical clustering-style trees along each chromosome arm (or chromosome), and then selects the 'interesting' clusters by controlling the False Discovery Rate (FDR) at a certain level. In addition, it provides a consensus summary across a set of arrays, as well as an estimate of the corresponding FDR. We illustrate the method using an application of CLAC on a lung cancer microarray CGH data set as well as a BAC array CGH data set of aneuploid cell strains.	Stanford Univ, Dept Stat, Stanford, CA 94305 USA; Stanford Univ, Dept Pathol, Stanford, CA 94305 USA; Stanford Univ, Dept Hlth Res & Policy, Stanford, CA 94305 USA	Wang, P (reprint author), Stanford Univ, Dept Stat, Stanford, CA 94305 USA.	wp57@stanford.edu					Autio R, 2003, BIOINFORMATICS, V19, P1714, DOI 10.1093/bioinformatics/btg230; BENJAMINI Y, 1985, J ROYAL STAT SOC B, P289; Cheng C, 2003, GENOMICS, V82, P122, DOI 10.1016/S0888-7543(03)00122-8; EPRON B, 2002, GENETIC EPIDEMIOLOGY; Hastie T., 2001, ELEMENTS STAT LEARNI; Hodgson G, 2001, NAT GENET, V29, P491, DOI 10.1038/ng1201-491b; JONG K, 2003, CHROMOSOMAL BREAKPOI, V2611, P54; LENGAUER C, 1998, NATURE, V396; PINKEL D, 1998, NATURE GENETICS, V20; Pollack JR, 2002, P NATL ACAD SCI USA, V99, P12963, DOI 10.1073/pnas.162471999; Snijders AM, 2001, NAT GENET, V29, P263, DOI 10.1038/ng754; Snijders AM, 2003, ONCOGENE, V22, P4370, DOI 10.1038/sj.onc.1206482; STOREY J, 2002, J ROY STAT SOC, P479; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498	14	122	127	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1465-4644			BIOSTATISTICS	Biostatistics	JAN	2005	6	1					45	58		10.1093/biostatistics/kxh017		14	Mathematical & Computational Biology; Statistics & Probability	Mathematical & Computational Biology; Mathematics	888AJ	WOS:000226346300005	15618527	
J	Sharma, P; Sahni, NS; Tibshirani, R; Skaane, P; Urdal, P; Berghagen, H; Jensen, M; Kristiansen, L; Moen, C; Sharma, P; Zaka, A; Arnes, J; Sauer, T; Akslen, LA; Schlichting, E; Borresen-Dale, AL; Lonneborg, A				Sharma, P; Sahni, NS; Tibshirani, R; Skaane, P; Urdal, P; Berghagen, H; Jensen, M; Kristiansen, L; Moen, C; Sharma, P; Zaka, A; Arnes, J; Sauer, T; Akslen, LA; Schlichting, E; Borresen-Dale, AL; Lonneborg, A			Early detection of breast cancer based on gene-expression patterns in peripheral blood cells	BREAST CANCER RESEARCH			English	Article							NEUTROPHILS; PROFILES; CORE	Introduction Existing methods to detect breast cancer in asymptomatic patients have limitations, and there is a need to develop more accurate and convenient methods. In this study, we investigated whether early detection of breast cancer is possible by analyzing gene-expression patterns in peripheral blood cells. Methods Using macroarrays and nearest-shrunken-centroid method, we analyzed the expression pattern of 1,368 genes in peripheral blood cells of 24 women with breast cancer and 32 women with no signs of this disease. The results were validated using a standard leave-one-out cross-validation approach. Results We identified a set of 37 genes that correctly predicted the diagnostic class in at least 82% of the samples. The majority of these genes had a decreased expression in samples from breast cancer patients, and predominantly encoded proteins implicated in ribosome production and translation control. In contrast, the expression of some defense-related genes was increased in samples from breast cancer patients. Conclusion The results show that a blood-based gene-expression test can be developed to detect breast cancer early in asymptomatic patients. Additional studies with a large sample size, from women both with and without the disease, are warranted to confirm or refute this finding.	DiaGen ASA, Oslo, Norway; Stanford Univ, Dept Hlth, Stanford, CA 94305 USA; Stanford Univ, Dept Res & Policy, Stanford, CA 94305 USA; Stanford Univ, Dept Stat, Stanford, CA 94305 USA; Ullevaal Univ Hosp, Dept Radiol, Oslo, Norway; Ullevaal Univ Hosp, Dept Clin Chem, Oslo, Norway; Haukeland Univ Hosp, Gade Inst, Dept Pathol, N-5021 Bergen, Norway; Ullevaal Univ Hosp, Dept Pathol, Oslo, Norway; Ullevaal Univ Hosp, Dept Surg, Oslo, Norway; Norwegian Radium Hosp, Dept Genet, Oslo, Norway; Univ Oslo, Fac Div, Norwegian Radium Hosp, Oslo, Norway	Sharma, P (reprint author), DiaGen ASA, Oslo, Norway.	praveen.sharma@diagenic.com					Ahmad K, 2002, P NATL ACAD SCI USA, V99, P16477, DOI 10.1073/pnas.172403699; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Bertucci F, 2002, HUM MOL GENET, V11, P863, DOI 10.1093/hmg/11.8.863; Ceci M, 2003, NATURE, V426, P579, DOI 10.1038/nature02160; Ellis M, 2002, CLIN CANCER RES, V8, P1155; Hastie T., 2001, ELEMENTS STAT LEARNI; Kolb TM, 2002, RADIOLOGY, V225, P165, DOI 10.1148/radiol.2251011667; NICODEMUS CF, 1990, J BIOL CHEM, V265, P5889; Nisapakultorn K, 2001, INFECT IMMUN, V69, P3692, DOI 10.1128/IAI.69.6.3692-3696.2001; Orino K, 2001, BIOCHEM J, V357, P241, DOI 10.1042/0264-6021:3570241; Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; Sorlie T, 2001, P NATL ACAD SCI USA, V98, P10869, DOI 10.1073/pnas.191367098; Sorlie T, 2003, P NATL ACAD SCI USA, V100, P8418, DOI 10.1073/pnas.0932692100; Subrahmanyam YVBK, 2001, BLOOD, V97, P2457, DOI 10.1182/blood.V97.8.2457; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; West M, 2001, P NATL ACAD SCI USA, V98, P11462, DOI 10.1073/pnas.201162998; Whitney AR, 2003, P NATL ACAD SCI USA, V100, P1896, DOI 10.1073/pnas.252784499; Zhang XQ, 2004, J LEUKOCYTE BIOL, V75, P358, DOI 10.1189/jlb.0903412	19	62	62	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1465-542X			BREAST CANCER RES	Breast Cancer Res.		2005	7	5					R634	R644		10.1186/bcr1203		11	Oncology	Oncology	970TJ	WOS:000232332200021	16168108	
S	Arshadi, N; Jurisica, I		MunozAvila, H; Ricci, F		Arshadi, N; Jurisica, I			An ensemble of case-based classifiers for high-dimensional biological domains	CASE-BASED REASONING RESEARCH AND DEVELOPMENT, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	6th International Conference on Case-Based Reasoning	AUG 23-26, 2005	Chicago, IL	Kaidara Software, Empolis, Naval Res Lab, PricewaterhouseCooper, AAAI			GENE-EXPRESSION; OVARIAN-CANCER; KNOWLEDGE; PREDICTION; PATTERNS; SERUM	It. has been shown that an ensemble of classifiers increases the accuracy compared to the member classifiers provided they are diverse. One way to produce this diversity is to base the classifiers on different case-bases. In this paper, we propose the mixture of experts for case-based reasoning (MOE4CBR), where clustering techniques are applied to cluster the case-base into kappa groups, and each cluster is used as a case-base for our kappa CBR classifiers. To further improve the prediction accuracy, each CBR classifier applies feature selection techniques to select a subset of features. Therefore, depending on the cases of each case-base, we would have different subsets of features for member classifiers. Our proposed method is applicable to any CBR system; however, in this paper, we demonstrate the improvement achieved by applying the method to a computational framework of a CBR system called TA3. We evaluated the system on two publicly available data sets on mass-to-charge intensities for two ovarian data sets with different number of clusters. The highest classification accuracy is achieved with three and two clusters for the ovarian data set 8-7-02 and data set 4-3-02, respectively. The proposed ensemble method improves the classification accuracy of TA3 from 90% to 99.2% on the ovarian data set 8-7-02, and from 79.2% to 95.4% on the ovarian data set 4-3-02. We also evaluate how individual components in MOE4CBR contribute to accuracy improvement, and we show that feature selection is the most important component followed by the ensemble of classifiers and clustering.	Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada; Univ Toronto, Hlth Network, Princess Margaret Hosp, Ontario Canc Inst,Div Canc Informat, Toronto, ON M5G 2M9, Canada	Arshadi, N (reprint author), Univ Toronto, Dept Comp Sci, 10 Kings Coll Rd, Toronto, ON M5S 3G4, Canada.	niloofar@cs.toronto.edu; juris@ai.utoronto.ca					Aha D.W., 1994, P AAAI 94 WORKSH CAS, P106; ARSHADI N, 2005, IN PRESS IEEE T KNOW; Arshadi N, 2004, LECT NOTES COMPUT SC, V3155, P17; ARSHADI N, 2005, IN PRESS FLAIRS 2005; Baggerly KA, 2005, J NATL CANCER I, V97, P307, DOI 10.1093/jnci/dji008; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Cunningham P, 2001, LECT NOTES ARTIF INT, V2080, P146; Ester M., 1996, P 2 INT C KNOWL DISC, P226; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; HAN J., 2000, DATA MINING CONCEPTS; Hastie T., 2001, ELEMENTS STAT LEARNI; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; Jaeger J., 2003, PAC S BIOC, V8, P53; John G., 1994, P 11 INT C MACH LEAR, P121; Jurisica I, 2001, IBM SYST J, V40, P394; Jurisica I, 2004, AI MAG, V25, P85; Jurisica I, 1998, ARTIF INTELL MED, V12, P1, DOI 10.1016/S0933-3657(97)00037-7; JURISICA I, 2000, INT J APPL INTELLIGE, V12, P251; Kohonen T., 1995, SELF ORGANIZING MAPS; Lenz M., 1998, CASE BASED REASONING; Mitchell T., 1997, MACHINE LEARNING; Molla M, 2004, AI MAG, V25, P23; MYLOPOULOS J, 1990, ACM T INFORM SYST, V8, P325, DOI 10.1145/102675.102676; Ng A. Y., 2002, ADV NEURAL INFORM PR, P14; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Quackenbush J, 2001, NAT REV GENET, V2, P418, DOI 10.1038/35076576; Ricci F., 1998, P 10 EUR C MACH LEAR, P280; Shiu SCK, 2001, COMPUT INTELL, V17, P295, DOI 10.1111/0824-7935.00146; SMYTH B, 1999, P 3 INT C CAS BAS RE, P329; SORACE JM, 2003, BMC BIOINFORMATICS, V4, P14666; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; XING EP, 2003, PRACTICAL APPROACH M, P110, DOI 10.1007/0-306-47815-3_6; Xing EP, 2001, P 18 INT C MACH LEAR, P601; Yang Q, 2000, LECT NOTES ARTIF INT, V1822, P102; Zhu W, 2003, P NATL ACAD SCI USA, V100, P14666, DOI 10.1073/pnas.2532248100	36	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-28174-6	LECT NOTES ARTIF INT			2005	3620						21	34				14	Computer Science, Artificial Intelligence	Computer Science	BDF64	WOS:000233274900005		
J	Kovar, K; Friedli, TK; Roubicek, D; Langenegger, DS; Keller, M; Meyer, HP				Kovar, K; Friedli, TK; Roubicek, D; Langenegger, DS; Keller, M; Meyer, HP			Process optimisation based on large databases of routinely monitored industrial process data	CHIMIA			English	Article						computer-intensive methods; data-driven statistical methods; intervention-impact analysis; large database		Huge amounts of data are routinely logged and stored during the monitoring of biotechnological production processes. A concept is described to extract and analyse the information these data contain and to subsequently apply it for process improvement. In total, roughly 100,000 time series of raw and derived signals which stemmed from 173 high-cell-density processes with recombinant microorganisms at 50 m(3) scale (working volume) were processed. As is often the case, no mathematical process models were readily available and therefore data-driven, computer-intensive methods were applied. These endeavours helped to stimulate a change in manufacturing strategy, which in turn has led to an increase in the final product titre of 26% on average.	Univ Appl Sci Zurich, CH-8820 Wadenswil, Switzerland; Inst Math Stat & Actuarial Sci, CH-3012 Bern, Switzerland; Lonza Biotech Sro, CZ-28161 Kourim, Czech Republic; Lonza AG, CH-3930 Visp, Switzerland	Kovar, K (reprint author), Univ Appl Sci Zurich, Postfach 335, CH-8820 Wadenswil, Switzerland.	k.kovar@hsw.ch					CLEVELAND WS, 1979, J AM STAT ASSOC, V74, P829, DOI 10.2307/2286407; Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.2307/2291512; Efron B., 1986, STAT SCI, V1, P54, DOI DOI 10.1214/SS/1177013815; EUBANK RL, 1988, SMOOTHING SPLINES NO; FRIEDLI TK, 2004, PROPRIETARY DEV; Hastie T., 2001, ELEMENTS STAT LEARNI; KOVAR K, 2004, 55412 CTI FHS; Tukey J.W., 1977, EXPLORATORY DATA ANA; Venables W.N., 2002, MODERN APPL STAT S	9	1	1	SWISS CHEMICAL SOC	BERN	SCHWARZTORSTRASSE 9, CH-3007 BERN, SWITZERLAND	0009-4293			CHIMIA	Chimia		2005	59	10					753	755		10.2533/000942905777675688		3	Chemistry, Multidisciplinary	Chemistry	980SN	WOS:000233038600008		
S	Hechenbichler, K; Tutz, G		Weihs, C; Gaul, W		Hechenbichler, K; Tutz, G			Bagging, boosting and ordinal classification	Classification - the Ubiquitous Challenge	STUDIES IN CLASSIFICATION, DATA ANALYSIS, AND KNOWLEDGE ORGANIZATION		English	Proceedings Paper	28th Annual Conference of the Gesellschaft-fur-Klassifikation	MAR 09-11, 2004	Dortmund, GERMANY	Gesell Klassifikat, Deutsch Forsch Gemeinsch, Dortmund-Project, Univ Dortmund, Fachbereich Statistik, NRW Beneluxstaaten, Landesbeauftragter Bezieh Zwischen Hochschulen, NOVARTIS, Roche Diagnost, sas Deutschland, Sonderforsch Bereich 475, Springer- Verlag, John Wiley & Sons	Univ Dortmund			Since the introduction of bagging and boosting many new techniques have been developed within the field of classification via aggregation methods. Most of them have in common that the class indicator is treated as a nominal response without any structure. Since in many practical situations the class must be considered as an ordered categorical variable, it seems worthwhile to take this additional information into account. We propose several variants of bagging and boosting, which make use of the ordinal structure and it is shown how the predictive power might be improved. Comparisons are based not only on misclassification rates but also on general distance measures, which reflect the difference between true and predicted class.	Univ Munich, Inst Stat, D-80539 Munich, Germany	Hechenbichler, K (reprint author), Univ Munich, Inst Stat, Marchioninistr 15, D-80539 Munich, Germany.						Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BUHLMANN P, 2002, IN PRESS J AM STAT A; FREUND Y, 1996, P 13 INT C; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Hastie T., 2001, ELEMENTS STAT LEARNI; SCHAPIRE R, 2002, MSRI WORKSHOP NONLIN; TUTZ G, 2003, AGGREGATING CLASSIFI	9	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1431-8814		3-540-25677-6	ST CLASS DAT ANAL			2005							145	152		10.1007/3-540-28084-7_14		8	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Computer Science	BDI52	WOS:000233600100014		
S	Bailer-Jones, CAL		Weihs, C; Gaul, W		Bailer-Jones, CAL			Astronomical object classification and parameter estimation with the Gaia galactic survey satellite	Classification - the Ubiquitous Challenge	STUDIES IN CLASSIFICATION, DATA ANALYSIS, AND KNOWLEDGE ORGANIZATION		English	Proceedings Paper	28th Annual Conference of the Gesellschaft-fur-Klassifikation	MAR 09-11, 2004	Dortmund, GERMANY	Gesell Klassifikat, Deutsch Forsch Gemeinsch, Dortmund-Project, Univ Dortmund, Fachbereich Statistik, NRW Beneluxstaaten, Landesbeauftragter Bezieh Zwischen Hochschulen, NOVARTIS, Roche Diagnost, sas Deutschland, Sonderforsch Bereich 475, Springer- Verlag, John Wiley & Sons	Univ Dortmund		NEURAL-NETWORKS; STELLAR SPECTRA; GALAXY	Gaia is a cornerstone mission of the European Space Agency (ESA) which will undertake a detailed survey of over 10(9) stars in our Galaxy. This will generate an extensive, multivariate, heterogeneous data set which presents numerous problems in classification, regression and time series analysis. I give a brief overview of the characteristics and requirements of this project and the challenges it provides.	Max Planck Inst Astron, D-69117 Heidelberg, Germany	Bailer-Jones, CAL (reprint author), Max Planck Inst Astron, Konigstuhl 17, D-69117 Heidelberg, Germany.						Prieto CA, 2003, MON NOT R ASTRON SOC, V339, P1111; Bailer-Jones CAL, 2002, ASTROPHYS SPACE SCI, V280, P21, DOI 10.1023/A:1015527705755; Bailer-Jones C. A. L., 2002, AUTOMATED DATA ANAL, P83; Bailer-Jones CAL, 1998, MON NOT R ASTRON SOC, V298, P361, DOI 10.1046/j.1365-8711.1998.01596.x; *ESA, 2000, ESASCI, P4; Folkes SR, 1996, MON NOT R ASTRON SOC, V283, P651; Hastie T., 2001, ELEMENTS STAT LEARNI; NAIM A, 1995, MON NOT R ASTRON SOC, V275, P567; Perryman MAC, 2001, ASTRON ASTROPHYS, V369, P339, DOI 10.1051/0004-6361:20010085	9	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1431-8814		3-540-25677-6	ST CLASS DAT ANAL			2005							325	329		10.1007/3-540-28084-7_36		5	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Computer Science	BDI52	WOS:000233600100036		
S	Schwarz, A; Arminger, G		Weihs, C; Gaul, W		Schwarz, A; Arminger, G			Credit scoring using global and local statistical models	Classification - the Ubiquitous Challenge	STUDIES IN CLASSIFICATION, DATA ANALYSIS, AND KNOWLEDGE ORGANIZATION		English	Proceedings Paper	28th Annual Conference of the Gesellschaft-fur-Klassifikation	MAR 09-11, 2004	Dortmund, GERMANY	Gesell Klassifikat, Deutsch Forsch Gemeinsch, Dortmund-Project, Univ Dortmund, Fachbereich Statistik, NRW Beneluxstaaten, Landesbeauftragter Bezieh Zwischen Hochschulen, NOVARTIS, Roche Diagnost, sas Deutschland, Sonderforsch Bereich 475, Springer- Verlag, John Wiley & Sons	Univ Dortmund			This paper compares global and local statistical models that are used for the analysis of a complex data set of credit risks. The global model for discriminating clients with good or bad credit status depending on various customer attributes is based on logistic regression. In the local model, unsupervised learning algorithms are used to identify clusters of customers with homogeneous behavior. Afterwards, a model for credit scoring can be applied separately in the identified clusters. Both methods are evaluated with respect to practical constraints and asymmetric cost functions. It can be shown that local models are of higher discriminatory power which leads to more transparent and convincing decision rules for credit assessment.	Univ Wuppertal, Dept Econ & Social Sci, D-42097 Wuppertal, Germany	Schwarz, A (reprint author), Univ Wuppertal, Dept Econ & Social Sci, D-42097 Wuppertal, Germany.						Arminger G, 1997, COMPUTATION STAT, V12, P293; Bacher J., 1996, CLUSTERANALYSE; Bonne T., 2000, KOSTENORIENTIERTE KL; Hastie T., 2001, ELEMENTS STAT LEARNI; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; KOHONEN T, 1998, VISUAL EXPLORATIONS, P159; Kohonen T., 1984, SELF ORG ASSOCIATIVE; Kohonen T., 1995, SELF ORG MAPS; PODDIG T, 2001, HDB DATA MINING MARK, P363; SCHMITT B, 1998, VISUAL EXPLORATIONS, P141	10	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1431-8814		3-540-25677-6	ST CLASS DAT ANAL			2005							442	449		10.1007/3-540-28084-7_51		8	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Computer Science	BDI52	WOS:000233600100051		
S	Steel, SJ; Hechter, GK		Weihs, C; Gaul, W		Steel, SJ; Hechter, GK			Application of support vector machines in a life assurance environment	Classification - the Ubiquitous Challenge	STUDIES IN CLASSIFICATION, DATA ANALYSIS, AND KNOWLEDGE ORGANIZATION		English	Proceedings Paper	28th Annual Conference of the Gesellschaft-fur-Klassifikation	MAR 09-11, 2004	Dortmund, GERMANY	Gesell Klassifikat, Deutsch Forsch Gemeinsch, Dortmund-Project, Univ Dortmund, Fachbereich Statistik, NRW Beneluxstaaten, Landesbeauftragter Bezieh Zwischen Hochschulen, NOVARTIS, Roche Diagnost, sas Deutschland, Sonderforsch Bereich 475, Springer- Verlag, John Wiley & Sons	Univ Dortmund			Since its introduction in Boser et al. (1992), the support vector machine has become a popular tool in a variety of classification and regression applications. In this paper we compare support vector machines and several more traditional statistical classification techniques when these techniques are applied to data from a life assurance environment. A measure proposed by Louw and Steel (2004) for ranking the input variables in a kernel method application is also applied to the data. We find that support vector machines are superior in terms of generalisation error to the traditional techniques, and that the information provided by the proposed measure of input variable importance can be utilised for reducing the number of input variables.	Univ Stellenbosch, Dept Stat & Actuarial Sci, ZA-7602 Matieland, South Africa; SANLAM, ZA-7532 Sanlamhof, South Africa	Steel, SJ (reprint author), Univ Stellenbosch, Dept Stat & Actuarial Sci, Private Bag X1, ZA-7602 Matieland, South Africa.						Boser B. E., 1992, 5 ANN ACM WORKSH COL; CRISTIANINI N, 2002, NEURAL INFORM PROCES, V14; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hastie T., 2001, ELEMENTS STAT LEARNI; Herbrich R., 2001, LEARNING KERNEL CLAS; LOUW N, 2004, UNPUB 19 INT WORKSH; R Development Core Team, 2003, R LANG ENV STAT COMP; Scholkopf B., 2002, LEARNING KERNELS SUP	8	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1431-8814		3-540-25677-6	ST CLASS DAT ANAL			2005							458	465		10.1007/3-540-28084-7_53		8	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Computer Science	BDI52	WOS:000233600100053		
S	Rover, C; Klefenz, R; Weihs, C		Weihs, C; Gaul, W		Rover, C; Klefenz, R; Weihs, C			Identification of musical instruments by means of the Hough-Transformation	Classification - the Ubiquitous Challenge	STUDIES IN CLASSIFICATION, DATA ANALYSIS, AND KNOWLEDGE ORGANIZATION		English	Proceedings Paper	28th Annual Conference of the Gesellschaft-fur-Klassifikation	MAR 09-11, 2004	Dortmund, GERMANY	Gesell Klassifikat, Deutsch Forsch Gemeinsch, Dortmund-Project, Univ Dortmund, Fachbereich Statistik, NRW Beneluxstaaten, Landesbeauftragter Bezieh Zwischen Hochschulen, NOVARTIS, Roche Diagnost, sas Deutschland, Sonderforsch Bereich 475, Springer- Verlag, John Wiley & Sons	Univ Dortmund			In order to distinguish between the sounds of different musical instruments, certain instrument-specific sound features have to be extracted from the time series representing a given recorded sound. The Hough Transform is a pattern recognition procedure that is usually applied to detect specific curves or shapes in digital pictures (Shapiro (1978)). Due to some similarity between pattern recognition and statistical curve fitting problems, it may as well be applied to sound data (as a special case of time series data). The transformation is parameterized to detect sinusoidal curve sections in a digitized sound, the motivation being that certain sounds might be identified by certain oscillation patterns. The returned (transformed) data is the timepoints and amplitudes of detected sinusoids, so the result of the transformation is another 'condensed' time series. This specific Hough Transform is then applied to sounds played by different musical instruments. The generated data is investigated for features that are specific for the musical instrument that played the sound. Several classification methods are tried out to distinguish between the instruments and it turns out that RDA (a hybrid method combining LDA and QDA) (Friedman (1989)) performs best. The resulting error rate is better than those achieved by humans (Bruderer (2003)).	Univ Dortmund, Dept Stat, D-44221 Dortmund, Germany; Fraunhofer Inst Digitale Medientechnol, D-98693 Ilmenau, Germany	Rover, C (reprint author), Univ Dortmund, Dept Stat, D-44221 Dortmund, Germany.						BRUDERER MJ, 2003, THESIS ECOLE POLYTEC; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Hastie T., 2001, ELEMENTS STAT LEARNI; OPOLKO F, 1987, MCGILL U MASTER SAMP; ROVER C, 2003, THESIS U DORTMUND; SHAPIRO SD, 1978, PATTERN RECOGN, V10, P129, DOI 10.1016/0031-3203(78)90022-5; Venables W.N., 2002, MODERN APPL STAT S	7	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1431-8814		3-540-25677-6	ST CLASS DAT ANAL			2005							608	615		10.1007/3-540-28084-7_72		8	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Computer Science	BDI52	WOS:000233600100072		
S	Busse, AM		Weihs, C; Gaul, W		Busse, AM			Classification of processes by the Lyapunov exponent	Classification - the Ubiquitous Challenge	STUDIES IN CLASSIFICATION, DATA ANALYSIS, AND KNOWLEDGE ORGANIZATION		English	Proceedings Paper	28th Annual Conference of the Gesellschaft-fur-Klassifikation	MAR 09-11, 2004	Dortmund, GERMANY	Gesell Klassifikat, Deutsch Forsch Gemeinsch, Dortmund-Project, Univ Dortmund, Fachbereich Statistik, NRW Beneluxstaaten, Landesbeauftragter Bezieh Zwischen Hochschulen, NOVARTIS, Roche Diagnost, sas Deutschland, Sonderforsch Bereich 475, Springer- Verlag, John Wiley & Sons	Univ Dortmund			This paper deals with the problem of the discrimination between well-predictable and not-well-predictable time series. One criterion for the separation is given by the size of the Lyapunov exponent, which was originally defined for deterministic systems. However, the Lyapunov exponent can also be analyzed and used for stochastic time series. Experimental results illustrate the classification between well-predictable and not-well-predictable time series.	Univ Dortmund, Dept Stat, D-44221 Dortmund, Germany	Busse, AM (reprint author), Univ Dortmund, Dept Stat, D-44221 Dortmund, Germany.						Abarbanel HDI, 1996, ANAL OBSERVED CHAOTI; Arnold VI, 1968, ERGODIC PROBLEMS CLA; Beck C., 1993, THERMODYNAMICS CHAOT; BUSSE AM, 2004, 37 SFB U DORTM; BUSSE AM, 2001, 12 SFB U DORTM; BUSSE AM, 2003, THESIS U DORTMUND; Casdagli M., 1991, J R STAT SOC B, V54, P303; Hastie T., 2001, ELEMENTS STAT LEARNI; Kantz H, 1997, NONLINEAR TIME SERIE; SANO M, 1985, PHYS REV LETT, V55, P1082, DOI 10.1103/PhysRevLett.55.1082; Stout W. F., 1974, ALMOST SURE CONVERGE; *VDI, 1974, 3210 VDI	12	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1431-8814		3-540-25677-6	ST CLASS DAT ANAL			2005							632	639		10.1007/3-540-28084-7_75		8	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Computer Science	BDI52	WOS:000233600100075		
J	Bowers, AL; Spindler, KP; McCarty, EC; Arrigain, S				Bowers, AL; Spindler, KP; McCarty, EC; Arrigain, S			Height, weight, and BMI predict intra-articular injuries observed during ACL reconstruction: Evaluation of 456 cases from a prospective ACL database	CLINICAL JOURNAL OF SPORT MEDICINE			English	Article						knee; ACL; weight; body mass index; epidemiology; statistical assessment	ANTERIOR CRUCIATE LIGAMENT; ACUTE KNEE INJURIES; RISK-FACTORS; OSTEOARTHRITIS; OBESITY; HEMARTHROSIS; ARTHROSCOPY; CONSCRIPTS; TEARS; MODEL	Objective: To identify demographic and anthropometric risk factors for intra-articular (IA) injuries observed during ACL reconstruction. We hypothesize that significant associations exist among height, weight, and body mass index (BMI) with IA injuries when ACL tear occurs. Design: This observational study of a prospective multi-investigator ACL database used logistic and Poisson regression analysis to assess independent predictors of IA injuries. Setting: Vanderbilt Sports Medicine and affiliated tertiary care center. Patients: Patients undergoing unilateral ACL reconstruction without prior injury to either knee were identified from a detailed prospective ACL reconstruction database. Four hundred fifty-six patients met inclusion/exclusion criteria. Interventions: Per inclusion criteria, all patients underwent unilateral ACL reconstruction after assessment of injury profile. Main Outcome Measurements: The ACL database was initiated in 1990 to identify demographic, anthropometric, and mechanistic variables associated with intra-articular injury. Results: Height best predicted tibial and patellar damage. BMI better predicted medial femoral condyle lesions, whereas weight better predicted lateral and patellofemoral injury. BMI and weight equally predicted injury to menisci and medial tibial plateau. Through different outcomes, age (odd ratio [OR], 1.49; 95% Cl, 1.02-2.16), height (OR, 2.66; 95% Cl, 1.52-4.65), weight (OR, 1.02; 95% CI, 1.01-1.04), and BMI (OR, 1.24; 95% Cl, 1.004-1.53) were all significant predictors of intra-articular injury. Conclusions: This is the first report using multivariable analysis of age, height, weight, and BMI to evaluate associations with IA injuries after ACL rupture observed during ACL reconstruction. We hypothesize that athletes possibly could reduce risk of certain IA pathologies with maintenance of lower body weight and BMI and thus potentially improve long-term functional outcomes after ACL reconstruction.	Vanderbilt Univ, Sports Med Ctr, Nashville, TN 37212 USA; Cleveland Clin Fdn, Dept Biostat & Epidemiol, Cleveland, OH 44195 USA	Spindler, KP (reprint author), Vanderbilt Univ, Sports Med Ctr, 2601 Jess Neely Dr, Nashville, TN 37212 USA.	kurt.spindler@vanderbilt.edu					ANGEL K R, 1989, Arthroscopy, V5, P197, DOI 10.1016/0749-8063(89)90171-0; Buckwalter JA, 1997, AM J SPORT MED, V25, P873, DOI 10.1177/036354659702500624; Coggon D, 2001, INT J OBESITY, V25, P622, DOI 10.1038/sj.ijo.0801585; DEHAVEN KE, 1980, AM J SPORT MED, V8, P9, DOI 10.1177/036354658000800102; DONOHUE JM, 1983, J BONE JOINT SURG AM, V65, P948; DOUGADOS M, 1992, J RHEUMATOL, V19, P378; Felson DT, 1997, ARTHRITIS RHEUM, V40, P728, DOI 10.1002/art.1780400420; FELSON DT, 1988, ANN INTERN MED, V109, P18; Hagino RT, 1998, J VASC SURG, V28, P458, DOI 10.1016/S0741-5214(98)70131-4; Hastie T, 2001, ELEMENTS STAT LEARNI, P193; Heir T, 1996, SCAND J MED SCI SPOR, V6, P222; Higuchi H, 2000, CLIN ORTHOP RELAT R, P161; KUJALA UM, 1986, CLIN ORTHOP RELAT R, P203; Manninen P, 1996, INT J OBESITY, V20, P595; MARIN EL, 1990, AM J PHYS MED REHAB, V69, P132, DOI 10.1097/00002060-199006000-00006; MITSOU A, 1988, INJURY, V19, P429, DOI 10.1016/0020-1383(88)90140-4; Moskowitz RW, 1992, OSTEOARTHRITIS DIAGN, P213; NIELSEN AB, 1991, J TRAUMA, V31, P1644, DOI 10.1097/00005373-199112000-00014; NOYES FR, 1980, J BONE JOINT SURG AM, V62, P687; Richmond John C, 2002, J Bone Joint Surg Am, V84-A, P323; ROOS H, 1995, OSTEOARTHR CARTILAGE, V3, P267; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SPINDLER KP, 1993, AM J SPORT MED, V21, P551, DOI 10.1177/036354659302100412; THOMPSON RC, 1991, J BONE JOINT SURG AM, V73A, P990	24	20	20	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	530 WALNUT ST, PHILADELPHIA, PA 19106-3621 USA	1050-642X			CLIN J SPORT MED	Clin. J. Sport Med.	JAN	2005	15	1					9	13		10.1097/00042752-200501000-00003		5	Orthopedics; Physiology; Sport Sciences	Orthopedics; Physiology; Sport Sciences	943CE	WOS:000230328600003	15654185	
S	Gupta, MR; Upton, S; Bowen, J		Bouman, CA; Miller, EL		Gupta, MR; Upton, S; Bowen, J			Simulating the effect of illumination using color transformations	COMPUTATIONAL IMAGING III	Proceedings of SPIE		English	Proceedings Paper	Conference on Computational Imaging III	JAN 17-18, 2005	San Jose, CA	Soc Imaging Sci & Technol, SPIE		ICC profile; custom color enhancement; LIME; color mapping; 3D LUT		We investigate design and estimation issues for using the standard color management profile architecture for general custom image enhancement. Color management profiles are a flexible architecture for describing a mapping from an original colorspace to a new colorspace. We investigate use of this same architecture for describing color enhancements that could be defined by a non-technical user using samples of the mapping, just as color management is based on samples of a mapping between an original colorspace and a new colorspace. As an example enhancement, we work with photos of the 24 color patch Macbeth chart under different illuminations, with the goal of defining transformations that would take, for example, a studio D65 image and reproduce it as though it had been taken during a particular sunset. The color management profile architecture includes a lookup-table and interpolation. We concentrate on the estimation of the look-up-table points from minimal number of color enhancement samples (comparing interpolative and extrapolative statistical learning techniques), and evaluate the feasibility of using the color management architecture for custom enhancement definitions.	Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA	Gupta, MR (reprint author), Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.	gupta@ee.washington.edu; upton@chromix.com					Chang Y., 2004, P 1 S APPL PERC GRAP, P91, DOI 10.1145/1012551.1012567; GATTA DMA, P SPIE, V5293; GUPTA MR, 2004, P SPIE C COMP IM; Hastie T., 2001, ELEMENTS STAT LEARNI; HASTIE T, 1993, STAT SCI, V8, P120, DOI 10.1214/ss/1177011002; Hertzmann A, 2001, COMP GRAPH, P327; Kang H. R., 1997, COLOR TECHNOLOGY ELE; LI Y, 2004, P 17 INT C PATT REC; Postrel VI, 2003, SUBSTANCE STYLE RISE; Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629; RIZZI DMA, 2002, MACHINE GRAPHICS VIS; Schmitt B., 1997, MARKETING AESTHETICS	12	3	3	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		0-8194-5647-0	PROC SPIE			2005	5674						248	258		10.1117/12.598888		11	Imaging Science & Photographic Technology	Imaging Science & Photographic Technology	BCD94	WOS:000228796600024		
S	La Rocca, M; Perna, C		Cabestany, J; Prieto, A; Sandoval, F		La Rocca, M; Perna, C			Neural network modeling by subsampling	COMPUTATIONAL INTELLIGENCE AND BIOINSPIRED SYSTEMS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	8th International Work-Conference on Artificial Neural Networks	JUN 08-10, 2005	Barcelona, SPAIN				TIME-SERIES; VARIABLE SELECTION	The aim of the paper is to develop hypothesis testing procedures both for variable selection and model adequacy to facilitate a model selection strategy for neural networks. The approach, based on statical inference tools, uses the subsampling to overcome the analytical and probabilistic difficulties related to the estimation of the sampling distribution of the test statistics involved. Some illustrative examples are also discussed.	Univ Salerno, Dept Econ & Stat, I-84084 Fisciano, SA, Italy	La Rocca, M (reprint author), Univ Salerno, Dept Econ & Stat, Via Ponte Melillo, I-84084 Fisciano, SA, Italy.	larocca@unisa.it; perna@unisa.it					Anders U, 1999, NEURAL NETWORKS, V12, P309, DOI 10.1016/S0893-6080(98)00117-8; BARRON AR, 1993, IEEE T INFORM THEORY, V39, P930, DOI 10.1109/18.256500; COTTRELL M, 1995, IEEE T NEURAL NETWOR, V6, P1355, DOI 10.1109/72.471372; Fukumizu K, 2003, ANN STAT, V31, P833, DOI 10.1214/aos/1056562464; Hastie T, ELEMENTS STAT LEARNI; La Rocca M, 2005, COMPUT STAT DATA AN, V48, P415, DOI 10.1016/j.csda.2004.01.004; LEE TH, 1993, J ECONOMETRICS, V56, P269, DOI 10.1016/0304-4076(93)90122-L; Politis Dmitris N., 1999, SUBSAMPLING; Politis DN, 1997, J ECONOMETRICS, V81, P281, DOI 10.1016/S0304-4076(97)86569-4; REED R, 1993, IEEE T NEURAL NETWOR, V4, P740, DOI 10.1109/72.248452; Refenes APN, 1999, J FORECASTING, V18, P299, DOI 10.1002/(SICI)1099-131X(199909)18:5<299::AID-FOR725>3.0.CO;2-T; Terasvirta T., 1993, J TIME SER ANAL, V14, P209, DOI 10.1111/j.1467-9892.1993.tb00139.x; White H, 2001, IEEE T NEURAL NETWOR, V12, P657, DOI 10.1109/72.935080	13	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-26208-3	LECT NOTES COMPUT SC			2005	3512						200	207				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCO15	WOS:000230384000025		
S	de Graaf, JM; de Menezes, RX; Boer, JM; Kosters, WA		Berthold, MR; Glen, R; Diederichs, K; Kohlbacher, O; Fischer, I		de Graaf, JM; de Menezes, RX; Boer, JM; Kosters, WA			Frequent itemsets for genomic profiling	COMPUTATIONAL LIFE SCIENCES, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st International Symposium on Computational Life Sciences	SEP 25-27, 2005	Konstanz, GERMANY	Univ Gesell, Konstanzee V, ALTANA, Pharma AG, Boehringer Ingellheim, Tripos, BioLAGO			HIGH-RESOLUTION ANALYSIS; HYBRIDIZATION	Frequent itemset mining is a promising approach to the study of genomic profiling data. Here a dataset consists of real numbers describing the relative level in which a clone occurs in human DNA for given patient samples. One can then mine, for example, for sets of samples that share some common behavior on the clones, i.e., gains or losses. Frequent itemsets show promising biological expressiveness, can be computed efficiently, and are very flexible. Their visualization provides the biologist with useful information for the discovery of patterns. Also it turns out that the use of (larger) frequent itemsets tends to filter out noise.	Leiden Univ, Leiden Inst Adv Comp Sci, Leiden, Netherlands; Leiden Univ, Med Ctr, Ctr Human & Clin Genet, Leiden, Netherlands; Erasmus Univ, Med Ctr, Pediat Lab, Rotterdam, Netherlands	de Graaf, JM (reprint author), Leiden Univ, Leiden Inst Adv Comp Sci, Leiden, Netherlands.	graaf@liacs.nl; r.x.menezes@lumc.nl; j.m.boer@lumc.nl; kosters@liacs.nl	Boer, Judith/A-7546-2010				CARDOSO J, 2004, NUC ACIDS RES, V32; Hastie T., 2001, ELEMENTS STAT LEARNI; KOSTERS WA, 2002, E COMMERCE INTELLIGE, P41; KOSTERS WA, 2003, WORKSH FREQ IN MIN I; Lengauer C, 1998, NATURE, V396, P643, DOI 10.1038/25292; Nakao K, 2004, CARCINOGENESIS, V25, P1345, DOI 10.1093/carcin/bgh134; Pinkel D, 1998, NAT GENET, V20, P207, DOI 10.1038/2524; ROUVEIROL C, 2005, IN PRESS LECT NOTES; SolinasToldo S, 1997, GENE CHROMOSOME CANC, V20, P399, DOI 10.1002/(SICI)1098-2264(199712)20:4<399::AID-GCC12>3.0.CO;2-I; Tuzhilin A., 2002, P 8 ACM SIGKDD INT C, P396; ZHANG C, 2002, LECT NOTES ARTIFICAL, V2307	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29104-0	LECT NOTES COMPUT SC			2005	3695						104	116				13	Biochemical Research Methods; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Biochemistry & Molecular Biology; Computer Science	BDF94	WOS:000233331500010		
S	Dudek, D; Zgrzywa, A		Kurzynski, M; Puchala, E; Wozniak, M; Zolnierek, A		Dudek, D; Zgrzywa, A			The incremental method for discovery of association rules	Computer Recognition Systems, Proceedings	ADVANCES IN SOFT COMPUTING		English	Proceedings Paper	4th International Conference on Computer Recognition Systems (CORES 05)	MAY 22-25, 2005	Rydzyna Castle, POLAND				ALGORITHMS	We present a new method for incremental discovery of association rules, which is highly general and independent of a mining algorithm. The heart of the method is the rule maintenance algorithm, which keeps the base of discovered rules as if they were mined in a single run through the whole transaction database. For more general and flexible results we take into account, thresholds of rules statistical significance and influence of time. The method can be used as a learning model in knowledge-based systems with bounded resources, e.g. software agents.	Wroclaw Tech Univ, Inst Appl Informat, PL-50370 Wroclaw, Poland	Dudek, D (reprint author), Wroclaw Tech Univ, Inst Appl Informat, Wybrzeze Wyspianskiego 27, PL-50370 Wroclaw, Poland.						Agrawal R., 1994, P 20 INT C VER LARG; Agrawal R., 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; AUMANN Y, 1999, J INTELL INF SYST, V21, P61; Bayardo RJ, 2000, DATA MIN KNOWL DISC, V4, P217; Chen GQ, 2002, COMPUT IND ENG, V43, P721, DOI 10.1016/S0360-8352(02)00135-3; CICHOSZ P, 2000, LEARNING SYSTEMS SCI; DUDEK D, 2003, KNOWLEDGE ENG EXPERT, V2, P237; Fong J, 2003, KNOWL-BASED SYST, V16, P91, DOI 10.1016/S0950-7051(02)00076-X; GOETHALS B, 2002, THESIS TRANSNATIONAL; Harms SK, 2004, J INTELL INF SYST, V22, P7, DOI 10.1023/A:1025824629047; Hastie T., 2001, ELEMENTS STAT LEARNI; LEE G, 2001, KNOWL INF SYST, V3, P338, DOI 10.1007/PL00011672; Lee SD, 1998, DATA MIN KNOWL DISC, V2, P233, DOI 10.1023/A:1009703019684; MANNILA H, 1997, P INT C DAT THEOR, P41; Shen L, 1999, INFORM SCIENCES, V118, P251, DOI 10.1016/S0020-0255(99)00035-3; TSAI LS, 1999, LECT NOTES ARTIF INT, V1575, P74; Zaki MJ, 2000, IEEE T KNOWL DATA EN, V12, P372, DOI 10.1109/69.846291; ZHOU Z, 2001, LECT NOTES ARTIF INT, V2056, P26	18	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1615-3871		3-540-25054-9	ADV SOFT COMP			2005							153	160				8	Computer Science, Artificial Intelligence	Computer Science	BCW32	WOS:000231535500016		
S	Maciejewski, H; Jasinska, A		Kurzynski, M; Puchala, E; Wozniak, M; Zolnierek, A		Maciejewski, H; Jasinska, A			Clustering DNA microarray data	Computer Recognition Systems, Proceedings	ADVANCES IN SOFT COMPUTING		English	Proceedings Paper	4th International Conference on Computer Recognition Systems (CORES 05)	MAY 22-25, 2005	Rydzyna Castle, POLAND				GENE-EXPRESSION; PATTERNS		Wroclaw Tech Univ, Inst Engn Cybernet, PL-50370 Wroclaw, Poland	Maciejewski, H (reprint author), Wroclaw Tech Univ, Inst Engn Cybernet, Ul Wybrzeze Wyspianskiego 27, PL-50370 Wroclaw, Poland.		Maciejewski, Henryk/B-1836-2008				ART D, 1982, UTILITAS MATHEMATICA, V21, P75; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Everitt B. S., 1980, CLUSTER ANAL; Ewens W., 2001, STAT METHODS BIOINFO; Faller D, 2003, J COMPUT BIOL, V10, P751, DOI 10.1089/106652703322539079; Hastie T., 2002, ELEMENTS STAT LEARNI; HOFFMANN R, 2002, GENOME BIOL; Quackenbush J, 2001, NAT REV GENET, V2, P418, DOI 10.1038/35076576; Shannon W, 2003, PHARMACOGENOMICS, V4, P41, DOI 10.1517/phgs.4.1.41.22581; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1615-3871		3-540-25054-9	ADV SOFT COMP			2005							595	601				7	Computer Science, Artificial Intelligence	Computer Science	BCW32	WOS:000231535500070		
S	Mhamdi, F; Rakotomalala, R; Elloumi, M		Kurzynski, M; Puchala, E; Wozniak, M; Zolnierek, A		Mhamdi, F; Rakotomalala, R; Elloumi, M			Feature ranking for protein classification	Computer Recognition Systems, Proceedings	ADVANCES IN SOFT COMPUTING		English	Proceedings Paper	4th International Conference on Computer Recognition Systems (CORES 05)	MAY 22-25, 2005	Rydzyna Castle, POLAND					In this paper, a knowledge discovery framework is used for protein classification. The processing is achieved in three steps: feature extraction, feature ranking and feature selection. Inspirited from text mining results for the first step, we use n-grams descriptors; descriptors are ranked from chi-2 statistical indices in the second step; and in the final step, the subset of descriptors is selected which will minimize the prediction error rate using a k-nearest neighbor classifier. Experiments show that this framework gives good results: the dimensionality reduction is effective and increases the classifier performances.	URPAH, Fac Sci Tunis, Tunis, Tunisia	Mhamdi, F (reprint author), URPAH, Fac Sci Tunis, Tunis, Tunisia.						Duch W., 2004, P INT JOINT C NEUR N, P1415; Fayyad U.M., 1996, ADV KNOWLEDGE DISCOV, P1; HASTIE T, 2001, ELEMENTS STATICAL LE; Isabelle G., 2003, J MACHINE LEARNING R, V3, P1157; MHAMDI F, 2004, IEEE ICTTA04 DAM SYR; MOLINA LC, 2002, ICDM02; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Venturi G., 2001, DATA MINING GESTION	9	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1615-3871		3-540-25054-9	ADV SOFT COMP			2005							611	617				7	Computer Science, Artificial Intelligence	Computer Science	BCW32	WOS:000231535500072		
J	Berg, EL; Hytopoulos, E; Plavec, I; Kunkel, EJ				Berg, EL; Hytopoulos, E; Plavec, I; Kunkel, EJ			Approaches to the analysis of cell signalling networks and their application in drug discovery	CURRENT OPINION IN DRUG DISCOVERY & DEVELOPMENT			English	Review						computational models; drug mechanism; expression profiling; gene networks; proteomics	PROTEIN-PROTEIN INTERACTIONS; EXPRESSION PATTERNS; BAYESIAN NETWORKS; GENE-EXPRESSION; BREAST-CANCER; MICROARRAYS; PROTEOMICS; ARRAYS; MODEL; MAP	The ability to predict the safety and efficacy of novel drugs prior to clinical testing is a key goal in pharmaceutical drug discovery. Gaining a mechanistic understanding of the complex cell signaling networks (CSNs) underlying disease processes promises to help reduce the number of clinical failures by identifying points of intervention as well as redundancies and feedback mechanisms that contribute to toxicities, lack of efficacy and unexpected biological activities. Experimental and computational approaches to analyzing and modeling CSNs are currently being validated using simple organisms and cell lines. In vitro cell systems of sufficient complexity to resemble human disease physiology, but which are also amenable to chemical and genetic perturbations on a large scale, are now required for deciphering the signaling networks operating in human disease. In this review, experimental and computational methods for modeling complex CSNs and the applications of these approaches to pharmaceutical drug discovery are discussed.	BioSeek Inc, Burlingame, CA 94010 USA	Berg, EL (reprint author), BioSeek Inc, 863-C Mitten Rd, Burlingame, CA 94010 USA.	eberg@bioseekinc.com	Berg, Ellen/D-9076-2014	Berg, Ellen/0000-0001-5149-6665			Adalsteinsson D, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-24; Akutsu T, 1999, PAC S BIOC, V4, P17; Bair E, 2004, PLOS BIOL, V2, P511, DOI 10.1371/journal.pbio.00200108; Batada NN, 2004, P NATL ACAD SCI USA, V101, P6445, DOI 10.1073/pnas.0401314101; Blagoev B, 2004, NAT BIOTECHNOL, V22, P1139, DOI 10.1038/nbt1005; Bledi Yaniv, 2003, Briefings in Functional Genomics & Proteomics, V2, P254, DOI 10.1093/bfgp/2.3.254; Bouwmeester T, 2004, NAT CELL BIOL, V6, P97, DOI 10.1038/ncb1086; Butcher EC, 2004, NAT BIOTECHNOL, V22, P1253, DOI 10.1038/nbt1017; Christopher R, 2004, ANN NY ACAD SCI, V1020, P132, DOI 10.1196/annals.1310.014; DiMasi JA, 2001, CLIN PHARMACOL THER, V69, P297, DOI 10.1067/mcp.2001.115446; Dunkley TPJ, 2004, MOL CELL PROTEOMICS, V3, P1128, DOI 10.1074/mcp.T400009-MCP200; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Eungdamrong NJ, 2004, BIOL CELL, V96, P355, DOI 10.1016/j.biolcel.2004.03.004; Everley PA, 2004, MOL CELL PROTEOMICS, V3, P729, DOI 10.1074/mcp.M400021-MCP200; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Gardner TS, 2003, SCIENCE, V301, P102, DOI 10.1126/science.1081900; Gygi SP, 1999, NAT BIOTECHNOL, V17, P994, DOI 10.1038/13690; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T., 2001, GENOME BIOL, V2; Hastie Trevor, 2000, GENOME BIOL, V1; Ibarrola N, 2004, J BIOL CHEM, V279, P15805, DOI 10.1074/jbc.M311714200; Ideker T.E., 2000, PAC S BIOCOMPUT, V5, P305; Imoto Seiya, 2003, J Bioinform Comput Biol, V1, P459, DOI 10.1142/S0219720003000290; Imoto Seiya, 2004, J Bioinform Comput Biol, V2, P77, DOI 10.1142/S021972000400048X; Ito T, 2000, P NATL ACAD SCI USA, V97, P1143, DOI 10.1073/pnas.97.3.1143; Ito T, 2001, P NATL ACAD SCI USA, V98, P4569, DOI 10.1073/pnas.061034498; Jansen R, 2003, SCIENCE, V302, P449, DOI 10.1126/science.1087361; Kumar A, 2002, NATURE, V415, P123, DOI 10.1038/415123a; Kunkel EJ, 2004, FASEB J, V18, P1279, DOI 10.1096/fj.04-1538fje; Liang S, 1998, PAC S BIOCOMPUT, V3, P18; Lockhart DJ, 1996, NAT BIOTECHNOL, V14, P1675, DOI 10.1038/nbt1296-1675; Luscombe NM, 2004, NATURE, V431, P308, DOI 10.1038/nature02782; Michalides R, 2004, CANCER CELL, V5, P597, DOI 10.1016/j.ccr.2004.05.016; Morozov VN, 2003, RAPID COMMUN MASS SP, V17, P2430, DOI 10.1002/rcm.1213; Nielsen UB, 2003, P NATL ACAD SCI USA, V100, P9330, DOI 10.1073/pnas.1633513100; Parsons AB, 2004, NAT BIOTECHNOL, V22, P62, DOI 10.1038/nbt919; Plavec I, 2004, P NATL ACAD SCI USA, V101, P1223, DOI 10.1073/pnas.0308221100; Resat H, 2003, BIOPHYS J, V85, P730, DOI 10.1016/S0006-3495(03)74516-0; Rigaut G, 1999, NAT BIOTECHNOL, V17, P1030, DOI 10.1038/13732; Rosenwald A, 2002, NEW ENGL J MED, V346, P1937, DOI 10.1056/NEJMoa012914; SCHENA M, 1995, SCIENCE, V270, P467, DOI 10.1126/science.270.5235.467; Schoeberl B, 2002, NAT BIOTECHNOL, V20, P370, DOI 10.1038/nbt0402-370; Shmulevich I, 2002, BIOINFORMATICS, V18, P261, DOI 10.1093/bioinformatics/18.2.261; SYDOR JR, 2003, PROTEOME SCI, V1, P3, DOI 10.1186/1477-5956-1-3; Tian Q, 2004, MOL CELL PROTEOMICS, V3, P960, DOI 10.1074/mcp.M400055-MCP200; Torres FE, 2004, P NATL ACAD SCI USA, V101, P9517, DOI 10.1073/pnas.0403573101; Troester MA, 2004, CANCER RES, V64, P4218, DOI 10.1158/0008-5472.CAN-04-0107; Tyers M, 2003, NATURE, V422, P193, DOI 10.1038/nature01510; Uetz P, 2000, NATURE, V403, P623; Wang WX, 2003, ANAL CHEM, V75, P4818, DOI 10.1021/ac026468x; Watkins SM, 2004, CURR OPIN DRUG DISC, V7, P112; Xia Y, 2004, ANNU REV BIOCHEM, V73, P1051, DOI 10.1146/annurev.biochem.73.011303.073950; Yan W, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-8-r54; Yook SH, 2004, PROTEOMICS, V4, P928, DOI 10.1002/pmic.200300636; Zhu H, 2001, CURR OPIN CHEM BIOL, V5, P40, DOI 10.1016/S1367-5931(00)00170-8	55	7	8	THOMSON SCIENTIFIC	LONDON	34-42 CLEVELAND STREET, LONDON, W1T 4JE, ENGLAND	1367-6733			CURR OPIN DRUG DISC	Curr. Opin. Drug Discov. Dev.	JAN	2005	8	1					107	114				8	Pharmacology & Pharmacy	Pharmacology & Pharmacy	889II	WOS:000226436300012	15679178	
S	Lakshminarayan, C; Yu, QF; Benson, A		Bhalla, S		Lakshminarayan, C; Yu, QF; Benson, A			Improving customer experience via text mining	DATABASES IN NETWORKED INFORMATION SYSTEMS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	4th International Workshop on Databases in Networked Information Systems	MAR 28-30, 2005	Aizu Wakamatsu, JAPAN	Univ Aizu, Int Affairs Comm, Aiza Wakamatsu City			CATEGORIZATION	Improving customer experience on company web sites is an important aspect of maintaining a competitive edge in the technology industry. To better understand customer behavior, e-commerce sites provide online surveys for individual web site visitors to record their feedback with site performance. This paper describes some areas where text mining appears to have useful applications. For comments from web site visitors, we implemented automated analysis to discover emerging problems on the web site using clustering methods and furthermore devised procedures to assign comments to pre-defined categories using statistical classification. Statistical clustering was based on a Gaussian mixture model and hierarchical clustering to uncover new issues related to customer care-abouts. Statistical classification of comments was studied extensively by applying a variety of popular algorithms. We benchmarked their performance and make some recommendations based on our evaluations.			choudur.lakshminarayan@hp.com; qingfeng.yu@hp.com; alan.benson@hp.com					Abramowitz, 1972, HDB MATH FUNCTIONS; APTE C, 1994, ACM T INFORM SYST, V12, P233, DOI 10.1145/183422.183423; Baldi P., 2003, PROBABILISTIC METHOD; Berger JO, 1985, STAT DECISION THEORY; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R.O., 2001, PATTERN CLASSIFICATI; Effron B, 1993, INTRO BOOTSTRAP; Johnson R. A., 1992, APPL MULTIVARIATE ST; Laird N.M., 1977, J ROYAL STAT SOC B, V39, P1; Letsche TA, 1997, INFORM SCIENCES, V100, P105, DOI 10.1016/S0020-0255(97)00044-3; McLachlan G., 1992, DISCRIMINANT ANAL ST; MITCHELL T, 1997, MACHINE LEANING; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; *SAS I INC, SAS STAT 9 9 1 US GU; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Schutze H., 1995, P 18 ANN INT ACM SIG, P229, DOI 10.1145/215206.215365; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Tibshirani R., 2001, ELEMENTS STAT LEARNI; Vapnik V., 1998, STAT LEARNING THEORY; Yang Y., 1997, P 14 INT C MACH LEAR, P412, DOI DOI 10.1016/J.ESWA.2008.05.026	22	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-25361-0	LECT NOTES COMPUT SC			2005	3433						288	299				12	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BCF82	WOS:000229113000023		
S	Jorge, AM; Azevedo, PJ		Carbonell, JG; Motoda, H; Hoffmann, A		Jorge, AM; Azevedo, PJ			An experiment with association rules and classification: Post-bagging and conviction	DISCOVERY SCIENCE, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	8th International Conference on Discovery Science	OCT 08-11, 2005	Singapore, SINGAPORE	AF Off Sci Res, Asian Off Aerosp Res & Dev, AFOSR, AOARD				In this paper we study a new technique we call post-bagging, which consists in resampling parts of a classification model rather then the data. We do this with a particular kind of model: large sets of classification association rules, and in combination with ordinary best rule and weighted voting approaches. We empirically evaluate the effects of the technique in terms of classification accuracy. We also discuss the predictive power of different metrics used for association rule mining, such as confidence, lift, conviction and chi(2). We conclude that, for the described experimental conditions, post-bagging improves classification results and that the best metric is conviction.	Univ Porto, Fac Econ, LIACC, P-4050090 Oporto, Portugal; Univ Minho, Dept Informat, P-4719 Braga, Portugal	Jorge, AM (reprint author), Univ Porto, Fac Econ, LIACC, Rua Ceuta 118, P-4050090 Oporto, Portugal.	amjorge@fep.up.pt; pja@di.uminho.pt	Jorge, Alipio/A-1721-2008; Azevedo, Paulo/B-6086-2009	Jorge, Alipio/0000-0002-5475-1382; 			Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Ali K., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; AZEVEDO PJ, CLASS PROJECT; AZEVEDO PJ, 2005, DATA STRUCTURE REPRE; Bayardo RJ, 2000, DATA MIN KNOWL DISC, V4, P217; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L., 1984, CLASSIFICATION REGRE; BRIN S, 1997, P ACM SIGMOD INT C M; DOMINGOS P, 1997, P 3 ACM SIGKDD INT C, P115; Fayyad UM, 1993, P 13 INT JOINT C ART, P1022; Hastie T., 2001, ELEMENTS STAT LEARNI; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; Ihaka R, 2005, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; JORGE A, 2000, LNAI, V1925; Jovanoski V., 2001, LNCS LNAI, V2258, P44; KONONENKO I, 1992, ARTIFICIAL INTELLIGE, V5; LI WM, 2001, IEEE INT C DAT MIN; LIU B, 1998, P 4 ACM SIGKDD INT C; Liu B., 1999, P 5 ACM SIGKDD INT C, P125, DOI 10.1145/312129.312216; MERA CJ, 1996, P UCI REPOSITORY MAC; Meretakis D., 1999, P 5 ACM SIGKDD INT C, P165, DOI 10.1145/312129.312222; Neave H.R., 1988, DISTRIBUTION FREE TE; QUINLAN J.R., 1993, C 4 5 PROGRAMS MACHI; WITTEN IH, 1999, DATA MINING PRACTIC; Zaki MJ, 2000, IEEE T KNOWL DATA EN, V12, P372, DOI 10.1109/69.846291	25	6	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29230-6	LECT NOTES COMPUT SC			2005	3735						137	149				13	Computer Science, Artificial Intelligence	Computer Science	BDP62	WOS:000234794000013		
S	Kumar, NP; Rao, MV; Krishna, PR; Bapi, RS		Chakraborty, G		Kumar, NP; Rao, MV; Krishna, PR; Bapi, RS			Using sub-sequence information with kNN for classification of sequential data	DISTRIBUTED COMPUTING AND INTERNET TECHNOLOGY, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	2nd International Conference on Distributed Computing and Internet Technology	DEC 22-24, 2005	Bhubaneswar, INDIA			sequence mining; k-Nearest Neighbor classification; Similarity/Distance metric; intrusion detection		With the enormous growth of data, which exhibit sequentiality, it has become important to investigate the impact of embedded sequential information within the data. Sequential data are growing enormously, hence an efficient classification of sequential data is needed. k-Nearest Neighbor (kNN) has been used and proved to be an efficient classification technique for two-class problems. This paper uses sliding window approach to extract sub-sequences of various lengths and classification using kNN. We conducted experiments on DARPA 98 IDS dataset using various distance/similarity measures such as Jaccard similarity, Cosine similarity, Euclidian distance and Binary Weighted Cosine (BWC) measure. Our results demonstrate that sub-sequence information enhances kNN classification accuracy for sequential data, irrespective of the distance/similarity metric used.	IDRBT, Hyderabad 500057, Andhra Pradesh, India; Univ Hyderabad, Hyderabad 500046, Andhra Pradesh, India	Kumar, NP (reprint author), IDRBT, Castle Hills,Masab Tank, Hyderabad 500057, Andhra Pradesh, India.	pradeepkumar@idrbt.ac.in; mvrao@mtech.idrbt.ac.in; prkrishna@idrbt.ac.in; bapics@uohyd.ernet.in					Agrawal R., 1993, P 4 INT C FDN DAT OR, P69; Bace R. G., 2000, INTRUSION DETECTION; Buckinx W, 2004, EXPERT SYST APPL, V26, P509, DOI 10.1016/j.eswa.2003.10.009; Dasarathy B., 1991, NEAREST NEIGHBOR CLA; Forrest S, 1996, P IEEE S SECUR PRIV, P120, DOI 10.1109/SECPRI.1996.502675; Gludici P., 2003, APPL DATA MINING STA; Han J., 2001, DATA MINING CONCEPTS; Hastie T., 2001, ELEMENTS STAT LEARNI; Hofmeyr S. A., 1998, Journal of Computer Security, V6; KEOGH E, 2003, P ACM SIGMOD C MAN D, P151; KHAN M, 2002, P 6 PAC AS C ADV KNO; Liao YH, 2002, USENIX ASSOCIATION PROCEEDINGS OF THE 11TH USENIX SECURITY SYMPOSIUM, P51; Marques de Sa J. P., 2001, PATTERN RECOGNITION; Mitchell T., 1997, MACHINE LEARNING; Pujari AK, 2001, DATA MINING TECHNIQU; QIAN G, SAC 2004, P1232; Ratanamahatana CA, 2004, SIAM PROC S, P11; RAWAT S, 2004, INT J INFORM SECURIT; *SAMS, SAMS STRING METR; SHOLOM M, 1991, MACHINE LEARNING SER; Wang J., 2005, DATA MINING BIOINFOR	21	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-30999-3	LECT NOTES COMPUT SC			2005	3816						536	546				11	Computer Science, Theory & Methods	Computer Science	BDW25	WOS:000235804200060		
B	Shen, XP; Gao, J		Arabnia, HR		Shen, XP; Gao, J			Statistical modeling for bankruptcy prediction: A brief survey and new examples	EEE '05: Proceedings of the 2005 International Conference on E-Business, Enterprise Information Systems, E-Government, and Outsourcing			English	Proceedings Paper	International Conference on E-Business, Enterprise Information Systems, E-Government and Outsourcing	JUN 20-23, 2005	Las Vegas, NV	CSREA, Int Technol Inst, World Acad Sci Informat Technol			SMALL BUSINESS FAILURE; FINANCIAL RATIOS	In this article, we start with a brief literature review about using Multivariate Discriminant Analysis (MDA) in bankruptcy prediction. We restrict our attention to the MDA models based on financial ratios. We then designed a group of statistical experiments to test the classic MDA model and its modified version. Both linear discriminant analysis and quadratic discriminant analysis are considered. Experiments are also designed for testing the parameter sensitivity and the stability of the MDA models. Observations from these experiments provide some empirical insights for some of the key issues using MDA in context of bankruptcy prediction, including reducing number of ratios used in the model, and the optimal accounting review intervals. Noise contamination is also taken into account;. The MDA models are also compared with one of the Neural-Networking based model - the SOLAR algorithm. By the end, we remark on how MDA models should be modified to fit in the bankruptcy prediction for e-commerce companies.	Ohio Univ, Dept Math, Athens, OH 45701 USA	Shen, XP (reprint author), Ohio Univ, Dept Math, Athens, OH 45701 USA.						ALTMAN E, 1968, J FINANC, V13, P589; Altman E. I., 2000, PREDICTING FINANCIAL; Altman E. I., 1993, CORPORATE FINANCIAL; ALTMAN EI, 1976, ACCOUNT REV, V51, P408; ALTMAN EI, 1984, J FINANC, V39, P1067, DOI 10.2307/2327613; ALTMAN EI, 1977, ZETA ANAL NEW MODEL, P29; Atiya A., 2001, IEEE T NEURAL NETWOR, V12; BEAVER WH, 1966, J ACCOUNTING RES, V4, P71, DOI 10.2307/2490171; Dahlhaus R, 1996, ANN STAT, V24, P1934; DAMBOLENA IG, 1980, J FINANC, V35, P1017, DOI 10.2307/2327217; DEAKIN EB, 1972, J ACCOUNTING RES, V10, P167, DOI 10.2307/2490225; EDMISTER RO, 1972, J FINANC QUANT ANAL, V7, P1477, DOI 10.2307/2329929; EDMISTER RO, 1972, J FINANC, V27, P139, DOI 10.2307/2978517; ELAM R, 1975, ACCOUNT REV, V50, P25; GATES S, 1993, 101 BUSINESS RATIOS; GHOSAL V, 1991, REV ECON STAT, V73, P157, DOI 10.2307/2109699; Gilson SC, 2000, REV FINANC STUD, V13, P43, DOI 10.1093/rfs/13.1.43; HAIR JF, 1995, MULTIVARIATE DATA AN; Hastie T., 2002, ELEMENTS STAT LEARNI; Hosmer DW, 1999, APPL SURVIVAL ANAL; HUBERTY C, 1994, APPL DISCRIMINANT AN; Mardia K.V., 1980, MULTIVARIATE ANAL; Merwin C, 1942, FINANCING SMALL CORP; PATRICK F, 1932, COMPARISON RATIS SUC; Shirata C., 1998, P 2 AS PAC INT RES A, P437; Shumway T, 2001, J BUS, V74, P101, DOI 10.1086/209665; STARZYK JA, 2004, SELF ORG LEARNING AR; STEFFY W, 1974, FINANCIAL RATIO ANAL; WINAKOR A, 1935, B U ILLINOIS BUR BUS, V51	29	0	0	C S R E A PRESS	ATHENS	115 AVALON DR, ATHENS, GA 30606 USA							2005							3	9				7	Computer Science, Information Systems	Computer Science	BEA09	WOS:000236396400001		
B	Zhang, HZ; Hamprecht, F; Amann, A		Martin, DC	IEEE	Zhang Huaizhong; Hamprecht, Fred; Amann, Anton			Report about VOCs dataset's analysis based on randomForests method	Eighth International Conference on High-Performance Computing in Asia-Pacific Region, Proceedings			English	Proceedings Paper	8th International Conference on High-Performance Computing in Asia-Pacific Region	NOV 30-DEC 03, 2005	Beijing, PEOPLES R CHINA	Chinese Acad Sci, China Comp Federat, IEEE Comp Soc, TC Scalable Comp				Volatile organic compounds (VOCs) play an important role in diagnosis and therapy of various diseases. We compare several main classifiers for data classification and point out the advantages of randomForests on supervising learning. So, in this project, we take the randomForests approach to analyze and appraise the VOCs data originally coming from the medical test. According to actual situation, combining the unsupervising and supervising methods, the important components and outliers are given. The evaluation for the classifying results has been acquired due to the cross-validation sampling methods.	Nanjing Normal Univ, Math & Comp Sci Sch, Nanjing 210097, Peoples R China	Zhang, HZ (reprint author), Nanjing Normal Univ, Math & Comp Sci Sch, Nanjing 210097, Peoples R China.						AMANN A, APPL BREATH GAS ANAL; Breiman L., 2004, RFTOOLS PREDICTING U; Breiman L, 2001, RANDOM FORESTS; DUBOIT S, 2003, CLASSIFICATION MICR; Duda R., PATTERN CLASSIFICATI; Hastie T., 2001, ELEMENTS STAT LEARNI; REMLINGER KS, INTRO APPL RANDOM FO; RIEDER J, 2001, MIDDLE EUROPEAN J ME, P181; TAO S, 2004, UNSUPERVISED LEARNIN	9	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7695-2486-9				2005							603	607		10.1109/HPCASIA.2005.85		5	Computer Science, Hardware & Architecture; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BFB23	WOS:000240654500085		
S	Figueiredo, MAT		Rangarajan, A; Vemuri, B; Yuille, AL		Figueiredo, MAT			Bayesian image segmentation using Gaussian field priors	ENERGY MINIMIZATION METHODS IN COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	5th International Workshop on Energy Minimization Methods in Computer Vision and Pattern Recognition	NOV 09-11, 2005	St Augustine, FL	Univ Florida, Int Assoc Pattern Recongnit			UNSUPERVISED TEXTURE SEGMENTATION; CLASSIFICATION; MODELS; CUTS	The goal of segmentation is to partition an image into a finite set of regions, homogeneous in some (e.g., statistical) sense, thus being an intrinsically discrete problem. Bayesian approaches to segmentation use priors to impose spatial coherence; the discrete nature of segmentation demands priors defined on discrete-valued fields, thus leading to difficult combinatorial problems. This paper presents a formulation which allows using continuous priors, namely Gaussian fields, for image segmentation. Our approach completely avoids the combinatorial nature of standard Bayesian approaches to segmentation. Moreover, it's completely general, i.e., it can be used in supervised, unsupervised, or semi-supervised modes, with any probabilistic observation model (intensity, multispectral, or texture features). To use continuous priors for image segmentation, we adopt a formulation which is common in Bayesian machine learning: introduction of hidden fields to which the region labels are probabilistically related. Since these hidden fields are real-valued, we can adopt any type of spatial prior for continuous-valued fields, such as Gaussian priors. We show how, under this model, Bayesian MAP segmentation is carried out by a (generalized) EM algorithm. Experiments on synthetic and real data shows that the proposed approach performs very well at a low computational cost.	Univ Tecn Lisboa, Inst Telecomun, Inst Super Tecn, P-1049001 Lisbon, Portugal; Univ Tecn Lisboa, Dept Elect & Comp Engn, Inst Super Tecn, P-1049001 Lisbon, Portugal	Figueiredo, MAT (reprint author), Univ Tecn Lisboa, Inst Telecomun, Inst Super Tecn, P-1049001 Lisbon, Portugal.	mario.figueiredo@lx.it.pt	Figueiredo, Mario/C-5428-2008	Figueiredo, Mario/0000-0002-0970-7745			BALRAM N, 1993, IEEE T INFORM THEORY, V39, P1333, DOI 10.1109/18.243450; Bernardo JM, 1994, BAYESIAN THEORY; BOHNING D, 1992, ANN I STAT MATH, V44, P197, DOI 10.1007/BF00048682; BOHNING D, 1988, ANN I STAT MATH, V40, P641, DOI 10.1007/BF00049423; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Chung F., 1997, SPECTRAL GRAPH THEOR; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39; FIGUEIREDO M, 2005, P IEEE CVPR 2005; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Hastie T., 2001, ELEMENTS STAT LEARNI; Hermes L, 2003, IEEE T IMAGE PROCESS, V12, P1243, DOI 10.1109/TIP.2003.817240; Hofmann T, 1998, IEEE T PATTERN ANAL, V20, P803, DOI 10.1109/34.709593; Jain A., 1989, FUNDAMENTALS DIGITAL; JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S; KIM J, 2005, IN PRESS IEEE T IMAG; KRISHNAPURAM B, 2005, IEEE TPAMI, V27; Lange K, 2000, J COMPUT GRAPH STAT, V9, P1, DOI 10.2307/1390605; Li S.Z., 2001, MARKOV RANDOM FIELD; Magnus J. R., 1988, MATRIX DIFFERENTIAL; Marroquin JL, 2003, IEEE T PATTERN ANAL, V25, P1380, DOI 10.1109/TPAMI.2003.1240112; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; McLachlan GJ, 1997, EM ALGORITHM EXTENSI; NOWAK RD, 1999, P ICIP, V2, P26, DOI 10.1109/ICIP.1999.822848; Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261; SHARON E, 2001, P IEEE C COMP VIS PA, V1, P469; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936; Weiss Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, DOI 10.1109/ICCV.1999.790354; Williams CKI, 1998, IEEE T PATTERN ANAL, V20, P1342, DOI 10.1109/34.735807; WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673; ZABIH R, 2004, P IEEE C COMP VIS PA, V2, P437, DOI 10.1109/CVPR.2004.1315196; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884	34	5	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-30287-5	LECT NOTES COMPUT SC			2005	3757						74	89				16	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDL83	WOS:000234193000006		
J	Avcibas, I; Kharrazi, M; Memon, N; Sankur, B				Avcibas, I; Kharrazi, M; Memon, N; Sankur, B			Image steganalysis with binary similarity measures	EURASIP JOURNAL ON APPLIED SIGNAL PROCESSING			English	Article						steganography; steganalysis; universal steganalysis		We present a novel technique for steganalysis of images that have been subjected to embedding by steganographic algorithms. The seventh and eighth bit planes in an image are used for the computation of several binary similarity measures. The basic idea is that the correlation between the bit planes as well as the binary texture characteristics within the bit planes will differ between a stego image and a cover image. These telltale marks are used to construct a classifier that can distinguish between stego and cover images. We also provide experimental results using some of the latest steganographic algorithms. The proposed scheme is found to have complementary performance vis-a-vis Farid's scheme in that they outperform each other in alternate embedding techniques.	Uludag Univ, Dept Elect Engn, TR-16059 Bursa, Turkey; Polytech Univ, Dept Elect & Comp Engn, Brooklyn, NY 11201 USA; Polytech Univ, Dept Comp & Informat Sci, Brooklyn, NY 11201 USA; Bogazici Univ, Dept Elect & Elect Engn, TR-34342 Istanbul, Turkey	Avcibas, I (reprint author), Uludag Univ, Dept Elect Engn, TR-16059 Bursa, Turkey.	avcibas@uludag.edu.tr; mehdi@isis.poly.edu; memon@poly.edu.tr; bulent.sankur@boun.edu.tr					Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363; BATAGELJ V, 1992, P INT M DIST AN DIST; Farid H., 2002, P IEEE INT C IM PROC, V2, p905 , DOI DOI 10.1109/ICIP.2002.1040098; Fridrich J., 2002, P 5 INT WORKSH INF H, P310; Fridrich J., 2001, IEEE Multimedia, V8, DOI 10.1109/93.959097; Fridrich J, 2001, P SOC PHOTO-OPT INS, V4518, P275, DOI 10.1117/12.448213; Harmsen JJ, 2003, P SOC PHOTO-OPT INS, V5020, P131, DOI 10.1117/12.476813; Hastie T., 2001, ELEMENTS STAT LEARNI; KHARRAZI M, 2004, LECT NOTES SERIES I; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; Ozer H, 2003, P SOC PHOTO-OPT INS, V5020, P55, DOI 10.1117/12.477313; Simmons GJ, 1983, P CRYPTO 83, P51; Sneath PHA, 1973, NUMERICAL TAXONOMY P; Sullivan K, 2005, P SOC PHOTO-OPT INS, V5681, P38, DOI 10.1117/12.588121; Vapnik VN, 1995, NATURE STAT LEARNING; Westfeld A, 2001, LNCS, P289	16	16	16	HINDAWI PUBLISHING CORPORATION	NEW YORK	410 PARK AVENUE, 15TH FLOOR, #287 PMB, NEW YORK, NY 10022 USA	1110-8657			EURASIP J APPL SIG P	EURASIP J Appl. Signal Process.		2005	2005	17					2749	2757		10.1155/ASP.2005.2749		9	Engineering, Electrical & Electronic	Engineering	018YR	WOS:000235801900001		
J	Peterson, DA; Knight, JN; Kirby, MJ; Anderson, CW; Thaut, MH				Peterson, DA; Knight, JN; Kirby, MJ; Anderson, CW; Thaut, MH			Feature selection and blind source separation in an EEG-based brain-computer interface	EURASIP JOURNAL ON APPLIED SIGNAL PROCESSING			English	Article						electroencephalogram; brain-computer interface; feature selection; independent components analysis; support vector machine; genetic algorithm	INDEPENDENT COMPONENT ANALYSIS; SUPPORT VECTOR MACHINES; CLASSIFICATION; ALGORITHMS; COMMUNICATION; RECOGNITION; MOVEMENTS; BCI	Most EEG-based BCl systems make use of well-studied patterns of brain activity. However, those systems involve tasks that indirectly map to simple binary commands such as "yes" or "no" or require many weeks of biofeedback training. We hypothesized that signal processing and machine learning methods can be used to discriminate EEG in a direct "yes"/"no" BCI from a single session. Blind source separation (BSS) and spectral transformations of the EEG produced a 180-dimensional feature space. We used a modified genetic algorithm (GA) wrapped around a support vector machine (SVM) classifier to search the space of feature subsets. The GA-based search found feature subsets that outperform full feature sets and random feature subsets. Also, BSS transformations of the EEG outperformed the original time series, particularly in conjunction with a subset search of both spaces. The results suggest that BSS and feature selection can be used to improve the performance of even a "direct," single-session BCl.	Colorado State Univ, Ctr Biomed Res Mus, Mol Cellular & Integrat Neurosci Program, Dept Comp Sci, Ft Collins, CO 80523 USA; Colorado State Univ, Dept Psychol, Ft Collins, CO 80523 USA; Colorado State Univ, Dept Math, Ft Collins, CO 80523 USA	Peterson, DA (reprint author), Colorado State Univ, Ctr Biomed Res Mus, Mol Cellular & Integrat Neurosci Program, Dept Comp Sci, Ft Collins, CO 80523 USA.	petersod@cs.colostate.edu; nate@cs.colostate.edu; kirby@math.colostate.edu; anderson@cs.colostate.edu; michael.thaut@colostate.edu					ANDERLE MG, 2001, P 5 INT C MATH SIGN; Anderson C.W., 2003, P 1 IEEE C COMP VIS, V5; Babiloni F, 2000, IEEE T REHABIL ENG, V8, P186, DOI 10.1109/86.847810; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; Birbaumer N, 2000, IEEE T REHABIL ENG, V8, P190, DOI 10.1109/86.847812; BLANKERTZ B, 2001, NEURAL INFORMATION P, V14, P157; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009; Ferri F., 1994, PATTERN RECOGN, P403; Garrett D, 2003, IEEE T NEUR SYS REH, V11, P141, DOI 10.1109/TNSRE.2003.814441; Goldberg D.E., 1989, GENETIC ALGORITHMS S; Greenberger D. B., 1988, J SMALL BUS MANAGE, V26, P1; Guerra-Salcedo C., 1999, P GECCO 99, P236; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hand D. J., 1981, DISCRIMINATION CLASS; Hastie T., 2001, ELEMENTS STAT LEARNI; HOLLAND JH, 1975, ADAPTATION NATURAL A; Hundley DR, 2002, SIGNAL PROCESS, V82, P1505, DOI 10.1016/S0165-1684(02)00342-0; Hyvarinen A, 2001, INDEPENDENT COMPONEN; Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Jung TP, 2001, HUM BRAIN MAPP, V14, P166, DOI 10.1002/hbm.1050; Jung TP, 2001, P IEEE, V89, P1107, DOI 10.1109/5.939827; KIRBY M, 2003, SPRINGER APPL MATH S, P263; KNIGHT JN, 2003, SIGNAL FRACTION ANAL; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Lal TN, 2004, IEEE T BIO-MED ENG, V51, P1003, DOI 10.1109/TBME.2004.827827; Ma J., 2002, OSU SVM CLASSIFIER M; Makeig S, 1999, J NEUROSCI, V19, P2665; Miner LA, 1998, ARCH PHYS MED REHAB, V79, P1029, DOI 10.1016/S0003-9993(98)90165-4; Nunez PL, 1997, ELECTROEN CLIN NEURO, V103, P499, DOI 10.1016/S0013-4694(97)00066-7; Penny WD, 2000, IEEE T REHABIL ENG, V8, P214, DOI 10.1109/86.847820; Peterson DA, 2004, PROCEEDINGS OF THE 2004 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY, P56; Pfurtscheller G, 2000, IEEE T REHABIL ENG, V8, P216, DOI 10.1109/86.847821; Pontil M, 1998, IEEE T PATTERN ANAL, V20, P637, DOI 10.1109/34.683777; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; RAMAN B, ENHANCING LEARNING U; Reunanen J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753715; Scholkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565; Scholkopf Bernard, 1999, ADV KERNEL METHODS S; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; Tang AC, 2003, MAGNETIC SOURCE IMAGING OF THE HUMAN BRAIN, P159; COVER TM, 1974, IEEE T SYST MAN CYB, VSMC4, P116; Vapnik V., 1998, STAT LEARNING THEORY; Vigario R, 2000, IEEE T BIO-MED ENG, V47, P589, DOI 10.1109/10.841330; Weston J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753751; WHITLEY LD, 1997, P 7 INT C GEN ALG IC, P568; WOLPAW JR, 1991, ELECTROEN CLIN NEURO, V78, P252, DOI 10.1016/0013-4694(91)90040-B; Wolpaw JR, 2000, IEEE T REHABIL ENG, V8, P222, DOI 10.1109/86.847823; Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3; Yang J., 1998, FEATURE EXTRACTION C, P117; Yom-Tov E, 2002, IEEE T NEUR SYS REH, V10, P170, DOI 10.1109/TNSRE.2002.802875	56	5	5	HINDAWI PUBLISHING CORPORATION	NEW YORK	410 PARK AVENUE, 15TH FLOOR, #287 PMB, NEW YORK, NY 10022 USA	1110-8657			EURASIP J APPL SIG P	EURASIP J Appl. Signal Process.		2005	2005	19					3128	3140		10.1155/ASP.2005.3128		13	Engineering, Electrical & Electronic	Engineering	019LF	WOS:000235836500006		
B	Pan, F; Wang, W; Tung, AKH; Yang, J		Han, J; Wah, BW; Raghavan, V; Wu, X; Rastogi, R		Pan, F; Wang, W; Tung, AKH; Yang, J			Finding representative set from massive data	Fifth IEEE International Conference on Data Mining, Proceedings			English	Proceedings Paper	5th IEEE International Conference on Data Mining	NOV 27-30, 2005	Houston, TX	IEEE Comp Soc, TCII, IEEE Comp Soc, TCPAMI, IBM Res, Knowledge & Informat Syst, Web Intelligence Consortium, Univ Louisiana Lafayette, Ctr Adv Comp Studies, Amer Discount ADS Inc, Univ Houston, Dept Comp Sci, Elder Res Inc				In the information age, data is pervasive. In some applications, data explosion is a significant phenomenon. The massive data volume poses challenges to both human users and computers. In this project, we propose a new model for identifying representative set from a large database. A representative set is a special subset of the original dataset, which has three main characteristics: It is significantly smaller in size compared to the original dataset. It captures the most information from the original dataset compared to other subsets of the same size. It has low redundancy among the representatives it contains. We use information-theoretic measures such as mutual information and relative entropy to measure the representativeness of the representative set. We first design a greedy algorithm and then present a heuristic algorithm that delivers much better performance. We run experiments on two real datasets and evaluate the effectiveness of our representative set in terms of coverage and accuracy. The experiments show that our representative set attains expected characteristics and captures information more efficiently.	Univ N Carolina, Chapel Hill, NC 27599 USA	Pan, F (reprint author), Univ N Carolina, Chapel Hill, NC 27599 USA.						ANDRITSOS P, 2003, HELL DAT S; BASU S, 2004, KDD 04 P; Cover T. M., 1991, ELEMENTS INFORMATION; DHILLON IS, 2003, J MACHINE LEARNING R, P1265; Hastie T., 2001, ELEMENTS STAT LEARNI; HOCHBAUM DS, 1998, NAVAL RES Q, P615; KANNAN SVR, 2000, IEEE ANN S FDN COMP; KUMAR R, 2004, KDD 04 P; PAN F, 2005, TR05014; SLONIM N, 2000, ACM SIGIR 2000; WANG J, 2004, ICDM 04 P	11	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2278-5				2005							338	345				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BDS21	WOS:000235162400043		
B	Papadimitriou, S; Gionis, A; Tsaparas, P; Vaisanen, RA; Mannila, H; Faloutsos, C		Han, J; Wah, BW; Raghavan, V; Wu, X; Rastogi, R		Papadimitriou, S; Gionis, A; Tsaparas, P; Vaisanen, RA; Mannila, H; Faloutsos, C			Parameter-free spatial data mining using MDL	Fifth IEEE International Conference on Data Mining, Proceedings			English	Proceedings Paper	5th IEEE International Conference on Data Mining	NOV 27-30, 2005	Houston, TX	IEEE Comp Soc, TCII, IEEE Comp Soc, TCPAMI, IBM Res, Knowledge & Informat Syst, Web Intelligence Consortium, Univ Louisiana Lafayette, Ctr Adv Comp Studies, Amer Discount ADS Inc, Univ Houston, Dept Comp Sci, Elder Res Inc				Consider spatial data consisting of a set of binary features taking values over a collection of spatial extents (grid cells). We propose a method that simultaneously finds spatial correlation and feature co-occurrence patterns, without any parameters. In particular we employ the Minimum Description Length (MDL) principle coupled with a natural way of compressing regions. This defines what "good" means: a feature co-occurrence pattern is good, if it helps its better compress the set of locations for these features. Conversely, a spatial correlation is good, if it helps us better compress the set of features in the corresponding region. Our approach is scalable for large datasets (both number of locations and of features). We evaluate our method on both real and synthetic datasets.	Carnegie Mellon Univ, Pittsburgh, PA 15213 USA	Papadimitriou, S (reprint author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.		Gionis, Aristides/G-2225-2013	Gionis, Aristides/0000-0002-5211-112X			ANDRITSOS P, 2004, EDBT; Basu S., 2004, KDD; Chakrabarti D., 2004, KDD; Cover T. M., 1991, ELEMENTS INFORMATION; Dhillon I. S., 2003, KDD; DHILLON IS, 2001, MACH LEARNING, V42; Grunwald P. D., 2005, ADV MINIMUM DESCRIPT; Guha S., 1998, SIGMOD; Hamerly G., 2003, NIPS; HAN J., 2000, DATA MINING CONCEPTS; Han JW, 2004, DATA MIN KNOWL DISC, V8, P53, DOI 10.1023/B:DAMI.0000005258.31418.83; Hastie T., 2001, ELEMENTS STAT LEARNI; HINNEBURG A, 1998, KDD; HUANG Y, 2003, SAC; KARYPIS G, 1998, SC98; Karypis George, 1999, IEEE COMPUTER, V32; KEOGH E, 2004, KDD; Kleinberg J, 2002, J ACM, V49, P616, DOI 10.1145/585265.585268; RISSANEN J, 1979, IBM J RES DEV, V23, P149; LEINO A, 2003, PKDD; MISHRA N, 2003, COLT; Ng A., 2001, NIPS; Pelleg D., 2000, INT C MACH LEARN, P727; POTTS RB, 1952, P CAMB PHILOS SOC, V48, P106; Rakesh Agrawal and Ramakrishnan Srikant, 1994, VLDB; REDDY PK, 2001, WISE; SALMENKIVI M, 2004, ICDM; VAISEY DJ, 1987, ICASSP; ZABIH R, 2004, CVPR; ZHANG B, 2000, TSDM; Zhang T., 1996, SIGMOD; ZHANG X, 2004, KDD	32	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2278-5				2005							346	353		10.1109/ICDM.2005.117		8	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BDS21	WOS:000235162400044		
B	Steinbach, M; Kumar, V		Han, J; Wah, BW; Raghavan, V; Wu, X; Rastogi, R		Steinbach, M; Kumar, V			Generalizing the notion of confidence	FIFTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS			English	Proceedings Paper	5th IEEE International Conference on Data Mining	NOV 27-30, 2005	Houston, TX	IEEE Comp Soc, TCII, IEEE Comp Soc, TCPAMI, IBM Res, Knowledge & Informat Syst, Web Intelligence Consortium, Univ Louisiana Lafayette, Ctr Adv Comp Studies, Amer Discount ADS Inc, Univ Houston, Dept Comp Sci, Elder Res Inc				In this paper we explore extending association analysis to non-traditional types of patterns and non-binary data by generalizing the notion of confidence. The key idea is to regard confidence as a measure of the extent to which the strength of one association pattern provides information about the strength of another This approach provides a framework that encompasses the traditional concept of confidence as a special case and can be used as the basis for designing a variety of new confidence measures. Besides discussing such confidence measures, we provide examples that illustrate the potential usefulness of a generalized notion of confidence. In particular, we describe an approach to defining confidence for error tolerant itemsets that preserves the interpretation of confidence as a conditional probability and derive a confidence measure for continuous data that agrees with the standard confidence measure when applied to binary transaction data.	Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA	Steinbach, M (reprint author), Univ Minnesota, Dept Comp Sci & Engn, 4-192 EE CSi Bldg 200 Union St SE, Minneapolis, MN 55455 USA.	steinbach@cs.umn.edu; kumar@cs.umn.edu					Agrawal R., 1993, SIGMOD, P207; Agrawal R., 1994, VLDB, P487; Aumann Y., 1999, KNOWLEDGE DISCOVERY, P261; Banerjee A, 2004, SIAM PROC S, P234; BOLLMANNSDORRA P, 2001, DAT WAR KNOWL DISC 3, P21; Brin S, 1997, SIGMOD, P265; Demmel J. W., 1997, APPL NUMERICAL LINEA; Friedman JH, 1999, STAT COMPUT, V9, P123, DOI 10.1023/A:1008894516817; HAN EW, 1997, 97068 TR U MINN DEP; Hastie T., 2001, ELEMENTS STAT LEARNI; JAROSEWICZ S, 2002, P WORKSH DISCR MATH; NG R, 1998, SIGMOD 98; OKONIEWSKI M, 2003, LCNS, V2543; OZGUR A, 2004, SIAM 2004; Srikant R., 1997, KDD 97, P67; SRIKANT R, 1996, SIGMOD 96; Steinbach M, 2004, KDD, P689; Tan P.-N., 2002, KDD, P32; Tan P.-N., 2005, INTRO DATA MINING; Webb G. I., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; YANG C, 2001, KDD 2001, P194; ZAKI MJ, 1998, DMKD 98, P7	22	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2278-5				2005							402	409		10.1109/ICDM.2005.72		8	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BDS21	WOS:000235162400051		
B	Komarek, P; Moore, AW		Han, J; Wah, BW; Raghavan, V; Wu, X; Rastogi, R		Komarek, P; Moore, AW			Making logistic regression a core data mining tool with TR-IRLS	Fifth IEEE International Conference on Data Mining, Proceedings			English	Proceedings Paper	5th IEEE International Conference on Data Mining	NOV 27-30, 2005	Houston, TX	IEEE Comp Soc, TCII, IEEE Comp Soc, TCPAMI, IBM Res, Knowledge & Informat Syst, Web Intelligence Consortium, Univ Louisiana Lafayette, Ctr Adv Comp Studies, Amer Discount ADS Inc, Univ Houston, Dept Comp Sci, Elder Res Inc				Binary classification is a core data mining task. For large datasets or real-time applications, desirable classifiers are accurate, fast, and need no parameter timing. We present a simple implementation of logistic regression that meets these requirements. A combination of regularization, truncated Newton methods, and iteratively re-weighted least squares make it faster and more accurate than modern SVM implementations, and relatively insensitive to parameters. It is robust to linear dependencies and some scaling problems, making most data preprocessing unnecessary.	Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA	Komarek, P (reprint author), Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.						Chang C, 2001, LIBSVM LIB SUPPORT V; Gentle JE, 2002, ELEMENTS COMPUTATION; Hastie T., 2001, ELEMENTS STAT LEARNI; Hosmer D. W. J. R., 2000, APPL LOGISTIC REGRES; JOACHIMS T, 2002, SVMLIGHT; Komarek P, 2003, ARTIFICIAL INTELLIGE; KOMAREK P, 2005, DATASETS; KOMAREK P, 2004, TR0434 ROB I; Kubica J., 2003, KDD WORKSH LINK AN D, P8; Liu T., 2003, P NEUR INF PROC SYST; McCullagh P, 1989, MONOGRAPHS STAT APPL, V37; MCINTOSH A, 1982, LECT NOTES STAT, V10; MINKA TP, 2001, TECHNICAL REPORT STA, V758; MOORE A, 2004, ACTIVITY PREDICTION; Nash S., 1996, LINEAR NONLINEAR PRO; Orr M. J. L., 1996, INTRO RADIAL BASIS F; Shewchuk J., 1994, CS94125 CARN MELL U; ZHANG T, 2001, TEXT CATEGORIZATION; Zhu J, 2005, J COMPUT GRAPH STAT, V14, P185, DOI 10.1198/106186005X25619	19	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2278-5				2005							685	688		10.1109/ICDM.2005.90		4	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BDS21	WOS:000235162400103		
S	Matloff, N		Lin, TY; Ohsuga, S; Liau, CJ; Hu, X; Tsumoto, S		Matloff, N			A careful look at the use of statistical methodology in data mining	Foundations of Data Mining and Knowledge Discovery	STUDIES IN COMPUTATIONAL INTELLIGENCE		English	Proceedings Paper	Workshop on Foundation of Data Mining and Knowledge Discovery	MAY   06, 2002	Taipei, TAIWAN	IEEE				Knowledge discovery in databases (KDD) is an inherently statistical activity, with a considerable literature drawing upon statistical science. However, the usage has typically been vague and informal at best, and at worst of a seriously misleading nature. In addition, much of the classical statistical methodology was designed for goals which can be very different from those of KDD. The present paper seeks to take a first step in remedying this problem by pairing precise mathematical descriptions of some of the concepts in KDD with practical interpretations and implications for specific KDD issues.	Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA	Matloff, N (reprint author), Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA.						BENDEL R, 1974, JOINT ASA IMS M ST L; Breiman L., 1984, CLASSIFICATION REGRE; DOMINGOS P, E4 MACHINE LEARNING; Fabris C., 1999, RES DEV INTELLIGENT, P148; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; GLYMOUR C, 1996, DATA MIN KNOWL DISC, V1, P25; HAN J., 2000, DATA MINING CONCEPTS; Hastie T., 2001, ELEMENTS STAT LEARNI; Hochberg Y, 1987, MULTIPLE COMP PROCED; MATLOFF NS, 1991, ENVIRON ENTOMOL, V20, P1246; PADMANABHAN B, 2001, DATA MINING ROUGH SE; SERFLING RJ, 1969, AM STAT, V23, P24	12	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1860-949X		3-540-26257-1	STUD COMP INTELL			2005	6						101	117				17	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BDD39	WOS:000232911000006		
S	Gruzdz, A; Ihnatowicz, A; Slezak, D		Murray, NV; Ras, ZW; Tsumoto, S		Gruzdz, A; Ihnatowicz, A; Slezak, D			Interactive SOM-based gene grouping: An approach to gene expression data analysis	FOUNDATIONS OF INTELLIGENT SYSTEMS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	15th International Symposium on Methodologies for Intelligent Systems	MAY 25-28, 2005	Saratoga Springs, NY	SUNY Albany, USA Res Off		self-organizing maps; gene expression data; interactive visualization of dependencies; mutual information entropy measures	PATTERNS; MAPS	We propose an approach to clustering and visualization of the DNA microarray-based gene expression data. We implement the self-organizing map (SOM) handling similarities between genes in terms of their expression characteristics. The resulting algorithmic toolkit is enriched with graphical interface enabling the user to interactively support the entire learning process. Preliminary calculations and consultations with biomedical experts positively verify applicability of our method.	Univ Regina, Dept Comp Sci, Regina, SK S4S 0A2, Canada; Polish Japanese Inst Informat Technol, PL-02008 Warsaw, Poland	Gruzdz, A (reprint author), Univ Regina, Dept Comp Sci, Regina, SK S4S 0A2, Canada.						Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Baldi P., 2002, DNA MICROARRAYS GENE; BURGER M, 1998, NEUROCOMPUTING, V20, P173; Cooper GM., 1995, ONCOGENES; Draghici S, 2003, DATA ANAL TOOLS DNA; El-Deiry WS, 2003, TUMOR SUPPRESSOR GEN; Eriksen Kasper Astrup, 2004, Functional & Integrative Genomics, V4, P241; Friedman J., 2001, ELEMENTS STAT LEARNI; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Kapur J.N., 1992, ENTROPY OPTIMIZATION; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Liu J. S., 2003, BAYESIAN STAT, V7, P249; Oja E., 1999, KOHONEN MAPS; Pawlak Z., 1991, ROUGH SETS THEORETIC; RAMPAL JB, 2001, METHODS MOL BIOL; Rebhan M, 1997, GENECARDS ENCY GENES; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; Safran M, 2003, NUCLEIC ACIDS RES, V31, P142, DOI 10.1093/nar/gkg050; Schena M, 2000, MICROARRAY BIOCHIP T; SENN HJ, 2003, RECENT RESULTS CANC; SLEZAK D, UNPUB ROUGH ENTROPY; SPELLMAN PT, 1999, NATURE GENETICS, V23; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Zimmer DP, 2004, GENETICS, V167, P2111, DOI 10.1534/genetics.104.027532	25	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-25878-7	LECT NOTES COMPUT SC			2005	3488						514	523				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BCM02	WOS:000229964000053		
J	Skowron, A				Skowron, A			Rough sets and vague concepts	FUNDAMENTA INFORMATICAE			English	Article						vague concept approximation; reasoning about vague concepts; approximation spaces; rough sets; inductive extensions; granulation of approximation spaces; adaptive learning	FUZZY LOGIC; PROPOSITIONAL CALCULI; RULES	The approximation space definition has evolved in rough set theory over the last 15 years. The aim was to build a unified framework for concept approximations. We present in overview of this evolution together with some operations on approximation spaces that are used in searching for relevant approximation spaces. Among such operations are inductive extensions and granulations of approximation spaces. We emphasize important consequences of the paper for research on approximation of vague concepts and reasoning about them in the framework of adaptive learning. This requires developing new approach to vague concepts going beyond the traditional rough or fuzzy approaches.	Warsaw Univ, Math Inst, PL-02097 Warsaw, Poland	Skowron, A (reprint author), Warsaw Univ, Math Inst, Banacha 2, PL-02097 Warsaw, Poland.	skowron@mimuw.edu.pl					Banerjee M, 2004, COG TECH, P157; Cattaneo G., 1998, STUDIES FUZZINESS SO, V18, P59; Friedman J., 2001, ELEMENTS STAT LEARNI; KEEFE R, 1997, VAUGENESS READER; Keefe R, 2000, CAMBRIDGE STUDIES PH; KLOESGEN E, 2002, HDB KNOWLEDGE DISCOV; Lin YZ, 1998, ACTA MATH SCI, V18, P107; LUKASIEWICZ J, 1913, J LUKASIEWICZ SELECT; Marcus S., 1994, B POLISH ACAD SCI TE, V42, P471; MARCUS S, 1998, LECT NOTES ARTIF INT, V1424, P19; PAVELKA J, 1979, Z MATH LOGIK, V25, P45, DOI 10.1002/malq.19790250304; PAVELKA J, 1979, Z MATH LOGIK, V25, P447, DOI 10.1002/malq.19790252510; PAVELKA J, 1979, Z MATH LOGIK, V25, P119, DOI 10.1002/malq.19790250706; Pawlak Z, 1991, SYSTEM THEORY KNOWLE, V9; PAWLAK Z, 1990, MACHINE LEARNING UNC, V3, P227; Pawlak Z., 1994, ADV DEMPSTER SHAFER, P251; Peters JF, 2003, LECT NOTES ARTIF INT, V2715, P370; Polkowski L., 2002, ROUGH SETS MATH FDN; Polkowski L, 2004, FUND INFORM, V61, P37; Polkowski L, 1996, INT J APPROX REASON, V15, P333, DOI 10.1016/S0888-613X(96)00072-2; Polkowski L, 2001, COMPUT INTELL, V17, P472, DOI 10.1111/0824-7935.00159; Polkowski L., 1994, SOFT COMPUT, P55; Read Stephen, 1995, THINKING LOGIC INTRO; SKOWRON A, 2004, LECT NOTES ARTIF INT, V3066, P114; Skowron A, 2004, FUND INFORM, V60, P351; SKOWRON A, 2004, ROUGH NEURAL COMPUTI, P43; Skowron A., 1996, Fundamenta Informaticae, V27; Slowinski R., 1997, ADV MACHINE INTELLIG, P17; Stone P., 2000, LAYERED LEARNING MUT; Sutton R. S., 1998, REINFORCEMENT LEARNI; Vapnik V., 1998, STAT LEARNING THEORY; Wojna A., 2001, LECT NOTES ARTIF INT, V2005, P428; YAO YY, 1998, STUDIES FUZZINESS SO, V18, P286; Zadeh L, 1996, IEEE T FUZZY SYST, V2, P103, DOI DOI 10.1109/91.493904; Zadeh L. A., 1965, INFORM CONTR, V8, P333; ZIARKO W, 1993, J COMPUT SYST SCI, V46, P39, DOI 10.1016/0022-0000(93)90048-2	36	24	25	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0169-2968			FUND INFORM	Fundam. Inform.	JAN	2005	64	1-4					417	431				15	Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	020XX	WOS:000235947800035		
B	Gao, DQ; Zhu, SM		Krishnapuram, R; Pal, N		Gao, DQ; Zhu, SM			A kind of fuzzily combinative classifiers for solving large-scale learning problems	FUZZ-IEEE 2005: Proceedings of the IEEE International Conference on Fuzzy Systems: BIGGEST LITTLE CONFERENCE IN THE WORLD	IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)		English	Proceedings Paper	IEEE International Conference on Fuzzy Systems	MAY 22-25, 2005	Reno, NV	IEEE, IEEE Neural Networks Soc			NEURAL-NETWORK; COMBINING CLASSIFIERS; CLASSIFICATION; DECOMPOSITION; RECOGNITION; FUSION	In order to use combinative classifiers to effectively solve large-scale learning problems, this paper focuses on the following aspects. (A) Decomposition of large-scale learning problems. (B) Selection of units of combinative classifiers. (C) Transformation of outputs of single classifiers into the grades of membership. We select improved kernel Fisher, Mahalanobis distance, and 10-nearest-neighbor classifier, as the combinative units, only let the most relative part of the original datasets to take part in training a single classifier, and then transform the outputs of each classifier into the same grades of membership. The experiment for letter recognition shows that the proposed method is effective.	E China Univ Sci & Technol, Dept Comp Sci, State Key Lab Bioreactor Engn, Shanghai 200237, Peoples R China	Gao, DQ (reprint author), E China Univ Sci & Technol, Dept Comp Sci, State Key Lab Bioreactor Engn, Shanghai 200237, Peoples R China.						Alexandre LA, 2001, PATTERN RECOGN LETT, V22, P1283, DOI 10.1016/S0167-8655(01)00073-3; ANAND R, 1995, IEEE T NEURAL NETWOR, V6, P117, DOI 10.1109/72.363444; Bermejo S, 2001, NEURAL NETWORKS, V14, P1447, DOI 10.1016/S0893-6080(01)00106-X; Blake C., UCI REPOSITORY MACHI; BOLLIVIER D, 1991, P INT JOINT C NEUR N, V2, P845; Collobert R, 2002, NEURAL COMPUT, V14, P1105, DOI 10.1162/089976602753633402; Duda R. O., 2000, PATTERN CLASSIFICATI; FREY PW, 1991, MACH LEARN, V6, P161, DOI 10.1007/BF00114162; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Hastie T., 2001, ELEMENTS STAT LEARNI; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; JENKINS RE, 1993, IEEE T NEURAL NETWOR, V4, P718, DOI 10.1109/72.238326; Ji CY, 1997, IEEE T NEURAL NETWOR, V8, P32; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kuncheva LI, 2002, IEEE T PATTERN ANAL, V24, P281, DOI 10.1109/34.982906; Lu BL, 1999, IEEE T NEURAL NETWOR, V10, P1244, DOI 10.1109/72.788664; PARKER JR, 2001, INFORM FUSION, V3, P113; ROVERSO D, 2002, INT J KNOWLEDGE BASE, V6; Shipp C. A., 2002, Information Fusion, V3, DOI 10.1016/S1566-2535(02)00051-9; UDA G, 1998, J INTELLIGENT ROBOTI, V21, P117; Williamson JR, 1996, NEURAL NETWORKS, V9, P881, DOI 10.1016/0893-6080(95)00115-8; Windridge D, 2003, IEEE T PATTERN ANAL, V25, P343, DOI 10.1109/TPAMI.2003.1182097; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943	23	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9158-6	IEEE INT CONF FUZZY			2005							424	429				6	Computer Science, Artificial Intelligence	Computer Science	BCR92	WOS:000230981000073		
S	Sulistijono, IA; Kubota, N		Wang, L; Jin, Y		Sulistijono, IA; Kubota, N			Human clustering for a partner robot based on computational intelligence	FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, PT 1, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	2nd International Conference on Fuzzy Systems and Knowledge Discovery	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtan Univ, IEEE Circuits & Syst Soc, IEEE Computat IntelligenceSoc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artifiical Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia-Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc Chine, Hunan Comp Federat				This paper proposes computational intelligence for a perceptual system of a partner robot. The robot requires the capability of visual perception to interact with a human, Basically, a robot should perform moving object extraction, clustering, and classification for visual perception used in the interaction with human. In this paper, we propose a total system for human clustering for a partner robot by using long-term memory, k-means, self-organizing map and fuzzy controller is used for the motion output. The experimental results show that the partner robot can perform the human clustering.	Tokyo Metropolitan Univ, Dept Mech Engn, Tokyo 1920397, Japan; ITS, EEPIS, Surabaya 60111, Indonesia	Sulistijono, IA (reprint author), Tokyo Metropolitan Univ, Dept Mech Engn, 1-1 Minami Osawa, Tokyo 1920397, Japan.	indra-adji@ed.tmu.ac.jp; kubota@comp.metro-u.ac.jp					Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614; BISSACCO A, 2002, 020046 UCLA CSD; Brooks R., 1999, CAMBRIAN INTELLIGENC; EYSENCK M, 1998, PSYCHOLOGY, P139; Fukuda T, 1999, P IEEE, V87, P1448, DOI 10.1109/5.784220; Gibson J. J., 1986, ECOLOGICAL APPROACH; Hastie T., 2001, ELEMENTS STAT LEARNI; Jang J.-S. R., 1997, NEUROFUZZY SOFT COMP; Kohonen T., 1984, SELF ORG ASS MEMORY; KUBOTA N, 2003, P 12 YAL WORKSH AD L, P199; KUBOTA N, 2004, P INT S COMP INT IND; Kubota N., 2003, J MULT-VALUED LOG S, V9, P221; Marr D., 1982, VISION; Russell SJ, 1995, ARTIFICIAL INTELLIGE; SHANAHAN M, 2004, JI AM ASS ARTIFICIAL; Turvey M. T., 1999, J CONSCIOUSNESS STUD, V6, P95; TURVEY MT, 1999, J CONSCIOUSNESS STUD, V6, P111	17	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-28312-9	LECT NOTES ARTIF INT			2005	3613						1001	1010				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BDA15	WOS:000232217900124		
J	Coffman, CJ; Wayne, ML; Nuzhdin, SV; Higgins, LA; McIntyre, LM				Coffman, CJ; Wayne, ML; Nuzhdin, SV; Higgins, LA; McIntyre, LM			Identification of co-regulated transcripts affecting male body size in Drosophila	GENOME BIOLOGY			English	Article							EXPLORATORY FACTOR-ANALYSIS; NONLINEAR FACTOR-ANALYSIS; GENE-EXPRESSION DATA; DOUBLE-STRANDED-RNA; MATING SUCCESS; MICROARRAY EXPERIMENTS; MELANOGASTER; EVOLUTION; SEQUENCE; NUMBER	Factor analysis is an analytic approach that describes the covariation among a set of genes through the estimation of ' factors', which may be, for example, transcription factors, microRNAs ( miRNAs), and so on, by which the genes are co- regulated. Factor analysis gives a direct mechanism by which to relate gene networks to complex traits. Using simulated data, we found that factor analysis clearly identifies the number and structure of factors and outperforms hierarchical cluster analysis. Noise genes, genes that are not correlated with any factor, can be distinguished even when factor structure is complex. Applied to body size in Drosophila simulans, an evolutionarily important complex trait, a factor was directly associated with body size.	Duke Univ, Med Ctr, Dept Biostat & Bioinformat, Durham, NC 27710 USA; Vet Adm Med Ctr, Hlth Serv Res & Dev Biostat Unit, Durham, NC 27705 USA; Univ Florida, Dept Zool, Gainesville, FL 32611 USA; Univ Calif Davis, Dept Ecol & Evolut, Davis, CA 95616 USA; Purdue Univ, Dept Agron, W Lafayette, IN 47907 USA	McIntyre, LM (reprint author), Duke Univ, Med Ctr, Dept Biostat & Bioinformat, Durham, NC 27710 USA.	lmcintyre@purdue.edu	McIntyre, Lauren/J-8414-2012	McIntyre, Lauren/0000-0002-0077-3359			Adams MD, 2002, NAT REV GENET, V3, P189, DOI 10.1038/nrg752; *AFF, 2000, AFF GENECHIP EXPR AN; Andersson M., 1994, SEXUAL SELECTION; Black MA, 2002, BIOINFORMATICS, V18, P1609, DOI 10.1093/bioinformatics/18.12.1609; CABOLI F, 2003, EVOLUTION INT J ORG, V57, P2653; Caldo RA, 2004, PLANT CELL, V16, P2514, DOI 10.1105/tpc.104.023382; Cohen J., 1988, STAT POWER ANAL BEHA; Delneri D, 2004, CURR GENOMICS, V5, P59, DOI 10.2174/1389202043490032; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Enright AJ, 2004, GENOME BIOL, V5; Fabrigar LR, 1999, PSYCHOL METHODS, V4, P272, DOI 10.1037//1082-989X.4.3.272; Falconer Mackay, 1996, INTRO QUANTITATIVE G; Fellenberg K, 2001, P NATL ACAD SCI USA, V98, P10781, DOI 10.1073/pnas.181597298; Fokoue E, 2003, MACH LEARN, V50, P73, DOI 10.1023/A:1020297828025; GIBSON G, 2004, GENETICS, V167, P179; Gildea JJ, 2000, GENETICS, V156, P645; Gorsuch RL, 1983, FACTOR ANAL; Goto A, 2003, NUCLEIC ACIDS RES, V31, P6619, DOI 10.1093/nar/gkg852; Hammond SM, 2001, NAT REV GENET, V2, P110, DOI 10.1038/35052556; Hastie T., 2001, ELEMENTS STAT LEARNI; HATCHER L, 1994, STEP BY STEP APPROAC; Huey RB, 2000, SCIENCE, V287, P308, DOI 10.1126/science.287.5451.308; Jansen RC, 2003, NAT REV GENET, V4, P145, DOI 10.1038/nrg996; Kalidas S, 2002, NEURON, V33, P177, DOI 10.1016/S0896-6273(02)00560-3; Lee SY, 2002, PSYCHOMETRIKA, V67, P189, DOI 10.1007/BF02294842; Lynch M, 1998, GENETICS ANAL QUANTI; Mackay TFC, 2004, CURR OPIN GENET DEV, V14, P253, DOI 10.1016/j.gde.2004.04.003; MCDONALD RP, 1967, BRIT J MATH STAT PSY, V20, P205; MOLENAAR PCM, 1987, BEHAV GENET, V17, P71, DOI 10.1007/BF01066011; Neter J., 1996, APPL LINEAR STAT MET; Nuzhdin SV, 2004, MOL BIOL EVOL, V21, P1308, DOI 10.1093/molbev/msh128; Olshen AB, 2002, BIOINFORMATICS, V18, P961, DOI 10.1093/bioinformatics/18.7.961; Parmigiani G, 2003, ANAL GENE EXPRESSION, P1, DOI 10.1007/0-387-21679-0_1; PARTRIDGE L, 1985, GENET RES, V46, P279; PARTRIDGE L, 1983, ANIM BEHAV, V31, P871, DOI 10.1016/S0003-3472(83)80242-5; PARTRIDGE L, 1987, ANIM BEHAV, V35, P468, DOI 10.1016/S0003-3472(87)80272-5; Partridge L., 1996, ANIMALS TEMPERATURE, P265, DOI 10.1017/CBO9780511721854.012; Peterson LE, 2002, COMPUT METH PROG BIO, V69, P179, DOI 10.1016/S0169-2607(01)00189-4; PETERSON LE, 2002, GENOME BIOL, V3; Preacher KJ, 2002, BEHAV GENET, V32, P153, DOI 10.1023/A:1015210025234; Singh AK, 2003, PLANT PHYSIOL, V132, P1825, DOI 10.1104/pp.103.024018; St Johnston D., 2002, NAT REV GENET, V3, P176; Stern DL, 2000, EVOLUTION, V54, P1079, DOI 10.1554/0014-3820(2000)054[1079:PEDBAT]2.0.CO;2; Stevens J, 1996, APPL MULTIVARIATE ST; Tibshirani R, 2002, STAT SINICA, V12, P47; Tseng GC, 2005, BIOMETRICS, V61, P10, DOI 10.1111/j.0006-341X.2005.031032.x; Wayne ML, 1997, EVOLUTION, V51, P1156, DOI 10.2307/2411045; Wayne ML, 2004, GENETICS, V168, P1413, DOI 10.1534/genetics.104.030973; WILLIAMS G, 2005, LINEAR ALGEBRA APPL; Wouters L, 2003, BIOMETRICS, V59, P1131, DOI 10.1111/j.0006-341X.2003.00130.x; Wright S, 1934, ANN MATH STAT, V5, P161, DOI 10.1214/aoms/1177732676	51	15	15	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1474-7596			GENOME BIOL	Genome Biol.		2005	6	6							R53	10.1186/gb-2005-6-6-r53		15	Biotechnology & Applied Microbiology; Genetics & Heredity	Biotechnology & Applied Microbiology; Genetics & Heredity	941IP	WOS:000230208800012	15960805	
J	Henderson, SR; Guiliano, D; Presneau, N; McLean, S; Frow, R; Vujovic, S; Anderson, J; Sebire, N; Whelan, J; Athanasou, N; Flanagan, AM; Boshoff, C				Henderson, SR; Guiliano, D; Presneau, N; McLean, S; Frow, R; Vujovic, S; Anderson, J; Sebire, N; Whelan, J; Athanasou, N; Flanagan, AM; Boshoff, C			A molecular map of mesenchymal tumors	GENOME BIOLOGY			English	Article							GENE-EXPRESSION PROFILES; SOFT-TISSUE SARCOMAS; NERVE SHEATH TUMORS; EWINGS-SARCOMA; SYNOVIAL SARCOMA; HUMAN OSTEOSARCOMA; CDNA MICROARRAYS; COPY NUMBER; CELL-LINES; TRANSLOCATION	Background: Bone and soft tissue tumors represent a diverse group of neoplasms thought to derive from cells of the mesenchyme or neural crest. Histological diagnosis is challenging due to the poor or heterogenous differentiation of many tumors, resulting in uncertainty over prognosis and appropriate therapy. Results: We have undertaken a broad and comprehensive study of the gene expression profile of 96 tumors with representatives of all mesenchymal tissues, including several problem diagnostic groups. Using machine learning methods adapted to this problem we identify molecular fingerprints for most tumors, which are pathognomonic (decisive) and biologically revealing. Conclusion: We demonstrate the utility of gene expression profiles and machine learning for a complex clinical problem, and identify putative origins for certain mesenchymal tumors.	UCL, Canc Res UK, Viral Oncol Grp, Wolfson Inst Biomed Res, London WC1E 6BT, England; Univ London Imperial Coll Sci Technol & Med, Fac Life Sci, Div Cell & Mol Biol, London SW7 2AZ, England; Royal Natl Orthopaed Hosp, Dept Pathol, Stanmore HA7 4LP, Middx, England; Royal Natl Orthopaed Hosp, Inst Orthopaed, Stanmore HA7 4LP, Middx, England; Inst Child Hlth, Unit Mol Haematol & Canc Biol, London WC1N 1EH, England; Great Ormond St Hosp Sick Children, London WC1N 1EH, England; Great Ormond St Hosp Sick Children, Dept Pathol, London WC1N 3JH, England; UCL Hosp, London Bone & Soft Tissue Tumour Serv, London, England; Nuffield Orthopaed Ctr, Nuffield Dept Orthopaed Surg, Dept Pathol, Oxford OX3 7LD, England	Henderson, SR (reprint author), UCL, Canc Res UK, Viral Oncol Grp, Wolfson Inst Biomed Res, Gower St, London WC1E 6BT, England.	s.henderson@ucl.ac.uk	sebire, neil/C-4960-2008				Adib TR, 2004, BRIT J CANCER, V90, P686, DOI 10.1038/sj.bjc.6601603; Allander SV, 2002, AM J PATHOL, V161, P1587, DOI 10.1016/S0002-9440(10)64437-9; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; AURIAS A, 1984, CANCER GENET CYTOGEN, V12, P21, DOI 10.1016/0165-4608(84)90003-7; Baer C, 2004, INT J CANCER, V110, P687, DOI 10.1002/ijc.20171; Brazma A, 2003, NUCLEIC ACIDS RES, V31, P68, DOI 10.1093/nar/gkg091; Carroll SL, 2004, J NEUROPATH EXP NEUR, V63, P1115; Dupin E, 2000, P NATL ACAD SCI USA, V97, P7882, DOI 10.1073/pnas.97.14.7882; Edwards YH, 1996, GENOME RES, V6, P226, DOI 10.1101/gr.6.3.226; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Fletcher C, 2002, WHO CLASSIFICATION T; Fritz B, 2002, CANCER RES, V62, P2993; Gentleman RC, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-10-r80; Hand David J, 2001, PRINCIPLES DATA MINI; Hastie T., 2001, ELEMENTS STAT LEARNI; Helman LJ, 2003, NAT REV CANCER, V3, P685, DOI 10.1038/nrc1168; Holtkamp N, 2004, BRAIN PATHOL, V14, P258; Irizarry RA, 2003, BIOSTATISTICS, V4, P249, DOI 10.1093/biostatistics/4.2.249; Irizarry RA, 2003, NUCLEIC ACIDS RES, V31, pe15; Khan J, 1998, CANCER RES, V58, P5009; Le Douarin NM, 2004, DEVELOPMENT, V131, P4637, DOI 10.1242/dev.01350; Lee YF, 2004, CANCER RES, V64, P7201, DOI 10.1158/0008-5472.CAN-04-1673; Lee YF, 2003, BRIT J CANCER, V88, P510, DOI 10.1038/sj.bjc.6600766; Leonard P, 2003, BRIT J CANCER, V89, P2284, DOI 10.1038/sj.bjc.6601389; Linn SC, 2003, AM J PATHOL, V163, P2383, DOI 10.1016/S0002-9440(10)63593-6; Longley DB, 2005, J PATHOL, V205, P275, DOI 10.1002/path.1706; Mackall CL, 2002, CANCER CELL, V2, P175, DOI 10.1016/S1535-6108(02)00132-0; Nagayama S, 2002, CANCER RES, V62, P5859; Nakano T, 2003, CLIN EXP METASTAS, V20, P665, DOI 10.1023/A:1027355610603; Nielsen TO, 2002, LANCET, V359, P1301, DOI 10.1016/S0140-6736(02)08270-3; Nilbert M, 2004, ACTA ORTHOP SCAND, V75, P35; Nilbert M, 2004, ACTA ORTHOP SCAND, V75, P29; Ochi K, 2004, INT J ONCOL, V24, P647; Ohali A, 2004, ONCOGENE, V23, P8997, DOI 10.1038/sj.onc.1208060; Peters A., 2002, R NEWS, V2, P33; Ramaswamy S, 2003, NAT GENET, V33, P49, DOI 10.1038/ng1060; Ransohoff DF, 2005, NAT REV CANCER, V5, P142, DOI 10.1038/nrc1550; Ren BG, 2003, HUM PATHOL, V34, P549, DOI 10.1016/S0046-8177(03)00000-0; SALISBURY JR, 1993, J PATHOL, V171, P59, DOI 10.1002/path.1711710112; SALISBURY JR, 1993, J PATHOL, V171, P253, DOI 10.1002/path.1711710404; Segal NH, 2003, J CLIN ONCOL, V21, P1775, DOI 10.1200/JCO.2003.10.108; Segal Neil H, 2005, Cancer Immun, V5, P2; Shmulevich I, 2002, CANCER, V94, P2069, DOI 10.1002/cncr.10425; Skubitz KM, 2004, J LAB CLIN MED, V143, P89, DOI 10.1016/j.lab.2003.10.002; Skubitz KM, 2003, CANCER, V98, P1029, DOI 10.1002/cncr.11586; Smyth GK, 2004, STAT APPL GENET MOL, V3; Tagawa K, 2000, J EXP ZOOL, V288, P23, DOI 10.1002/(SICI)1097-010X(20000415)288:1<23::AID-JEZ3>3.0.CO;2-H; Tomescu Oana, 2001, Trends in Molecular Medicine, V7, P554, DOI 10.1016/S1471-4914(01)02244-4; Trentin A, 2004, P NATL ACAD SCI USA, V101, P4495, DOI 10.1073/pnas.0400629101; TURCCAREL C, 1987, P NATL ACAD SCI USA, V84, P1981, DOI 10.1073/pnas.84.7.1981; TURCCAREL C, 1986, CANCER GENET CYTOGEN, V23, P93, DOI 10.1016/0165-4608(86)90153-6; TURCCAREL C, 1984, CANCER GENET CYTOGEN, V12, P1, DOI 10.1016/0165-4608(84)90002-5; TURCCAREL C, 1983, CR ACAD SCI III-VIE, V296, P1101; Venables W.N., 2002, MODERN APPL STAT S; Wang HW, 2004, NAT GENET, V36, P687, DOI 10.1038/ng1384; Weeraratna AT, 2002, CANCER CELL, V1, P279, DOI 10.1016/S1535-6108(02)00045-4	56	72	75	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1474-760X			GENOME BIOL	Genome Biol.		2005	6	9							R76	10.1186/gb-2005-6-9-r76		11	Biotechnology & Applied Microbiology; Genetics & Heredity	Biotechnology & Applied Microbiology; Genetics & Heredity	970JJ	WOS:000232301600010	16168083	
B	Boucher, A; Seto, K; Journel, A		Leuangthong, O; Deutsch, VC		Boucher, A; Seto, K; Journel, A			Mapping land cover changes with landsat imagery and spatio-temporal geostatistics	Geostatistics Banff 2004, Vols 1 and 2	QUANTITATIVE GEOLOGY AND GEOSTATISTICS		English	Proceedings Paper	7th International Geostatistics Congress	SEP 26-OCT 01, 2004	Banff, CANADA	DeBeers Canada, Earth Decis Sci, Maptek Chile Ltda, Mira Geosci, Nexen Inc, Petro Canada, Placer Dome Inc, Statios LLC, Total			PEARL RIVER DELTA; TM	Satellite images are the principal medium to detect and map changes in the landscape, both in space and time. Current image processing techniques do not fully exploit the data in that they do not take simultaneously into account the spatial and the temporal relations between the various land cover types. The method proposed here aims to accomplish that. At each pixel of the landscape, the time series of land cover type is modeled as a Markov Chain. That time series at any specific location is estimated jointly from the local satellite information, the neighboring ground truth land cover data, and any, neighboring previously estimated time series deemed well-informed by the satellite measurements. The method is applied to detect anthropogenic changes in the Pearl River Delta, China. The prediction accuracy of the time series improves significantly, the accuracy almost double, when both spatial and temporal information are considered in the estimation process. The introduction of spatial continuity through indicator kriging also reduced unwanted speckles in the classified images, removing the need for post-processing.	Stanford Univ, Dept Geol & Environm Sci, Stanford, CA 94305 USA	Boucher, A (reprint author), Stanford Univ, Dept Geol & Environm Sci, Stanford, CA 94305 USA.						Atkinson PM, 2000, COMPUT GEOSCI-UK, V26, P361, DOI 10.1016/S0098-3004(99)00117-X; Brown DG, 2002, PHOTOGRAMM ENG REM S, V68, P1051; Canny J, 1986, COMPUTATIONAL APPROA, P679; GOOVAERTS P., 1997, GEOSTATISTICS NATURA; Hastie T., 2001, ELEMENT STAT LEARNIN; Journel AG, 2002, MATH GEOL, V34, P573, DOI 10.1023/A:1016047012594; Kaufmann RK, 2001, AGR ECOSYST ENVIRON, V85, P95, DOI 10.1016/S0167-8809(01)00190-6; KRISHNAN S, P GEOST C 2004 BANFF; Richards J. A., 1999, REMOTE SENSING DIGIT; Seto KC, 2002, INT J REMOTE SENS, V23, P1985, DOI 10.1080/01431160110075532; Tso B, 2001, CLASSIFICATION METHO, DOI 10.4324/9780203303566; Wang GX, 2004, IEEE T GEOSCI REMOTE, V42, P632, DOI 10.1109/TGRS.2004.823450	12	0	0	SPRINGER	DORDRECHT	PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS			1-4020-3515-2	QUANT GEO G			2005	14		1-2				809	818				10	Geosciences, Multidisciplinary; Statistics & Probability	Geology; Mathematics	BDQ82	WOS:000234961400084		
B	Jankowski, N; Grabczewski, K		Nedjah, N; Mourelle, LM; Vellasco, MMB; Abraham, A; Koppen, M		Jankowski, N; Grabczewski, K			Heterogenous committees with competence analysis	HIS 2005: 5th International Conference on Hybrid Intelligent Systems, Proceedings			English	Proceedings Paper	5th International Conference on Hybrid Intelligent Systems	NOV 06-09, 2005	Rio de Janeiro, BRAZIL	Operador Nacl Sistema Eletr, Coordenac Aperfeicoament Pessoal Nivel Super, Brazilian Comp Soc, Brazilian Soc Automat, IEEE Syst Man & Cygernet Soc, Int Fuzzy Syst Assoc, European Neural Network Soc, European Soc Fuzzy Log & Technol, World Federat Soft Comp, Pontific Univ Catol Rio deJaneiro				We explore some new types of committees in search of hybrid models successful in many different classification benchmarks. To provide a reliable comparison of the ensembles we restrict the task to some constant configuration of committee members for each benchmark. We were looking for new types of committees which, in such configuration, would be as much accurate and stable as possible. The paper focuses on some ideas of heterogenous committees with different ways of their members competence estimation. Heterogenous committee members adapt in different ways and are able to solve different problems. Measuring the competence of committee members helps in making competent and accurate decisions.	Nicholas Copernicus Univ, Dept Informat, PL-87100 Torun, Poland	Jankowski, N (reprint author), Nicholas Copernicus Univ, Dept Informat, Grudziadzka 5, PL-87100 Torun, Poland.		Grabczewski, Krzysztof/F-3574-2014; Jankowski, Norbert/H-1071-2014				BISHOP C.M., 1995, NEURAL NETWORKS PATT; Boser B. E., 1992, P 5 ANN ACM WORKSH C; Breiman L, 1996, MACH LEARN, V24, P49; Breiman L., 1998, Neural Networks and Machine Learning. Proceedings; Breiman L., 1984, CLASSIFICATION REGRE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUCH W, 2002, ADV SOFT COMPUTING, P412; Duda R. O., 1997, PATTERN CLASSIFICATI; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J., 2001, ELEMENTS STAT LEARNI; GRABCZEWSKI K, 2004, FEATURE EXTRACTION F; Grabczewski K, 1999, P 4 C NEUR NETW THEI, P203; Grabczewski K, 2000, P 5 C NEUR NETW THEI, P201; JACOBS RA, 1991, NEURAL COMPUTATION, V79; Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493; Kuncheva L.I., 2003, MACHINE LEARNING, V51; MACLIN R, 1998, P AAAI; Merz C., 1998, UCI REPOSITORY MACHI; Mitchell T., 1997, MACHINE LEARNING; Quinlan J. R., 1993, PROGRAMS MACHINE LEA; SCHATTEN G, 1998, J LAW MED ETHICS, V26, P5; SEEWALD AK, 2001, ADV INTELLIGENT DATA; TING KM, 1997, P 15 INT JOIN C ART; Vapnik VN, 1995, NATURE STAT LEARNING; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Zenko B., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989601	26	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2457-5				2005							417	422				6	Computer Science, Artificial Intelligence	Computer Science	BDN06	WOS:000234402500069		
B	Cerchiello, P; Giudici, P		Vituland, S; DiGesu, V; Cantoni, V; Marmo, R; Setti, A		Cerchiello, P; Giudici, P			Sequence rule models for Web usage mining	Human & Machine Perception: Communication, Interaction, and Integration			English	Proceedings Paper	6th International Workshop on Human and Machine Perception	SEP 06-09, 2004	Oristano, ITALY					Every time a user links tip to a web site, the server keeps track of all the actions accomplished in a log file. What is captured is the "click flow" (clickstream) of the mouse and the keys used by the user during the navigation inside the site. Usually every click of the mouse corresponds to the viewing of a web page. Therefore, we can define the clickstream as the sequence of the web pages requested. The objective of this chapter is to show how web clickstream data can be used to understand the most likely paths of navigation in a web site, with the aim of predicting, possibly on-line, which pages will be seen, having seen a specific path of other pages before. Such analysis can be very useful to understand, for instance, what is the probability of seeing a page of interest (such as the buying page in an e-commerce site) coming from another page. Or what is the probability of entering (or exiting) the web site from any particular page. From a methodological viewpoint, our aim is to present new associative models, obtained by means of statistical graphical Markov models, and compare them with classical association rules, direct or embodied in classification tree models. More specifically, as web pages are ordered in time, we shall consider sequence rules.	Univ Milan, Dept Stat, Milan, Italy	Cerchiello, P (reprint author), Univ Milan, Dept Stat, Milan, Italy.						GIUDICI P, 2002, ASS MODELS WEB MININ, P329; Giudici P., 2003, APPL DATA MINING STA; Han J., 2001, DATA MINING CONCEPTS; Hand David J, 2001, PRINCIPLES DATA MINI; Hastie T., 2001, ELEMENTS STAT LEARNI; Lauritzen S.L, 1996, GRAPHICAL MODELS	6	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	PO BOX 128 FARRER RD, SINGAPORE 9128, SINGAPORE			981-238-431-6				2005							71	75		10.1142/9789812703095_0005		5	Computer Science, Artificial Intelligence	Computer Science	BDN92	WOS:000234539300005		
B	Stahlbock, R; Lessmann, S; Crone, SF		Arabnia, HR; Joshua, R		Stahlbock, R; Lessmann, S; Crone, SF			Evolutionary neural classification approaches for strategic and operational decision support in retail store planning	ICAI '05: PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2			English	Proceedings Paper	International Conference on Artificial Intelligence (ICAI 05)	JUN 27-30, 2005	Las Vegas, NV	CSREA, Int Technol Inst, World Acad Sci Informat Technol, HPCwire, GRIDtoday		artificial neural networks; classification; genetic algorithm; data mining; decision support	LEARNING VECTOR QUANTIZATION; DENSITY	In the domain of classification tasks, artificial neural nets (ANNs) are prominent data mining methods. Paradigms like learning vector quantization (LVQ) and probabilistic neural net (PNN) are suitable classifiers. In this paper, new approaches of evolutionary optimized LVQs and PNNs are proposed. Their classification accuracy is compared with results of standard PNN and LVQ. The complex real-world scenario includes planning of retail stores. Branch locations are classified in terms of revenue and profit. Results are based on data reflecting external infrastructure and internal aspects of existing branches. They support decisions about establishing, modifying or closing down a store.	Univ Hamburg, Inst Business Informat Syst, D-20146 Hamburg, Germany	Stahlbock, R (reprint author), Univ Hamburg, Inst Business Informat Syst, D-20146 Hamburg, Germany.						BISHOP C.M., 1995, NEURAL NETWORKS PATT; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CACOULLO.T, 1966, ANN I STAT MATH, V18, P179, DOI 10.1007/BF02869528; CRONE SF, 2002, P 9 INT C NEUR INF P, V5, P2374; Derigs U., 1997, OR Spektrum, V19; DeSieno D, 1988, P IEEE INT C NEURAL, V1, P117; Duda R.O., 2001, PATTERN CLASSIFICATI; Fausett L., 1994, FUNDAMENTALS NEURAL; Goldberg D.E., 1989, GENETIC ALGORITHMS S; Hammer B, 2002, LECT NOTES COMPUT SC, V2415, P370; Hastie T., 2001, ELEMENTS STAT LEARNI; Haykin S., 1999, NEURAL NETWORKS COMP; HOLLAND JH, 1994, ADAPTATION NATURAL A; Jutten C., 1993, New Trends in Neural Computation. International Workshop on Artificial Neural Networks. IWANN '93 Proceedings; KITAJIMA N, 1995, P INT C NEUR NETW IE, V5, P2775, DOI 10.1109/ICNN.1995.488170; KOHONEN T, 1997, SELFORGANIZING MAPS, V30; LAAKSONEN JT, 1992, ARTIFICIAL NEURAL NE, V2, P1181; Merelo JJ, 1995, ARTIFICIAL NEURAL NETS AND GENETIC ALGORITHMS, P92; Michalewicz Z, 1994, GENETIC ALGORITHMS D; NeuralWare Inc, 1993, NEUR COMP TECHN HDB; Odorico R, 1997, NEURAL NETWORKS, V10, P1083, DOI 10.1016/S0893-6080(97)00012-9; PAL NR, 1993, IEEE T NEURAL NETWOR, V3, P546; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Patterson D, 1996, ARTIFICIAL NEURAL NE; PREGENZER M, 1994, P IEEE INT C NEURAL, V5, P2890, DOI 10.1109/ICNN.1994.374690; SATO A, 1999, C PUBL, V470, P928; Schurmann Jurgen, 1996, PATTERN CLASSIFICATI; Seo S, 2003, NEURAL COMPUT, V15, P1589, DOI 10.1162/089976603321891819; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Specht D F, 1990, IEEE Trans Neural Netw, V1, P111, DOI 10.1109/72.80210; Specht D.F., 1988, P IEEE INT C NEURAL, V1, P525; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; STAHLBOCK R, 2002, EVOLUTIONARE ENTWICK; STAHLBOCK R, 2004, P INT C ART INT IC A, V1, P228; Vakil-Baghmisheh MT, 2003, PATTERN RECOGN, V36, P1901, DOI 10.1016/S0031-3203(02)00291-1; Vapnik VN, 1995, NATURE STAT LEARNING; Verleysen M., 1993, New Trends in Neural Computation. International Workshop on Artificial Neural Networks. IWANN '93 Proceedings; YOU SJ, 1995, P ICNN 95 P IEEE INT, V5, P2763; Young T. Y., 1974, CLASSIFICATION ESTIM; ZELL ANDREAS, 1994, SIMULATION NEURONALE	40	0	0	C S R E A PRESS	ATHENS	115 AVALON DR, ATHENS, GA 30606 USA			1-932415-68-8				2005							60	66				7	Computer Science, Artificial Intelligence	Computer Science	BDY19	WOS:000236070700009		
B	Cocianu, C; State, L; Vlamos, P; Stefanescu, V			China Sci & Technol Press	Cocianu, C; State, L; Vlamos, P; Stefanescu, V			A new noise reduction method in developing image restoration applications	ICMH' 2005: Proceedings of the 5th International Conference on Material Handling			English	Proceedings Paper	5th International Conference on Material Handling	NOV 01-03, 2005	Chongqing, PEOPLES R CHINA	Chinese Mech Engn Soc, Chongqing Inst Technol, CMES, Logist Engn Inst, Mat Handling Ind Amer, Japanese Mat Handling Soc, Amer Soc Mech Engineers, Mat Handling Engn Div, Inst Asia Pacific Studies, Waseda Univ, Inst Elect Engineers, Ryuken Co Ltd, Korean Inst Ind Engineers, Korean Logist Assoc, Asia-Pacific Logist Federat		image restoration; one-step prediction; binomial filtering; PCA restoration; innovations algorithm		Basically, there are two classes of approaches to the modelling of image degradation effects: a priori modelling and a posteriori modelling. In the former case, measurements are made on the physical imaging system, digitiser, and display to determine their response for an arbitrary image field. In some instances it will be possible to model the system response deterministically, while in other situation it will only be possible to determine the system response in a stochastic sense. Our approach of image restoration is based on an adapted version of the innovations algorithm. The input samples X-(1) of noisy versions of a given image X-0 is filtered using a binomial mask B-3 and a method based on PCA and shrinkage technique yielding to new samples X-(2), X-(3). Next, an approximation scheme for the matrix K(4, j) is developed and, according to the innovations algorithm, the estimation z((4)) is obtained. The reconstruction scheme is defined in terms of the estimation z((4)) and the samples X-(3), z((3)). A PCA based shrinkage method to noise removal is presented and an adapted version of the innovations algorithm in solving image restoration task together with the results of the performed tests are reported in the final section of the paper.	Acad Econ Studies, Bucharest, Romania	Cocianu, C (reprint author), Acad Econ Studies, Bucharest, Romania.		Cocianu, Catalina Lucia/C-1819-2012	Cocianu, Catalina Lucia/0000-0003-2078-0158			BROCKWELL P, 1985, TIME SERIES THEORY M; CHATTERJEE C, 1998, IEEE T NEURAL NETWOR, V9; COCIANU C, P IE 2005 BUCH ROM; COCIANU C, P ICINCO 2004; DECO C, 1996, INFORMATION THEORETI; Devroye L., 1996, PROBABILISTIC THEORY; Diamantaras K. I., 1996, PRINCIPAL COMPONENT; Gonzales R C, 2002, DIGITAL IMAGE PROCES; Hastie T., 2001, ELEMENTS STAT LEARNI; Haykin S., 2001, INTELLIGENT SIGNAL P; Haykin S., 1999, NEURAL NETWORKS COMP; Hyvarinen A, 2001, INDEPENDENT COMPONEN; HYVARINEN A, 1999, IMAGE DENOISING SPAR; OJA E, 1992, NEURAL NETWORKS, V5; Pratt W., 2001, DIGITAL IMAGE PROCES; Russ J. C., 1999, IMAGE PROCESSING HDB; Schervish M., 1995, THEORY STAT; Sklar B., 2001, DIGITAL COMMUNICATIO; STATE L, 2001, P SCI2001 ORL US JUL; STATE L, 2001, P SYNASC 2001 3 INT; Stergiopoulos S., 2001, ADV SIGNAL PROCESSIN; Umbaugh S. E., 1998, COMPUTER VISION IMAG; VASEGHI SV, 2001, ADV DIGITAL SIGNAL P	23	0	0	CHINA SCIENCE TECHNOLOGY PRESS	BEIJING	32 BAISHIQIAOLU, BEIJING 100081, PEOPLES R CHINA			7-5046-4205-3				2005							206	211				6	Engineering, Industrial; Engineering, Manufacturing	Engineering	BDT65	WOS:000235246100039		
B	Jaudet, M; Iqbal, N; Hussain, A; Sharif, K			IEEE	Jaudet, M; Iqbal, N; Hussain, A; Sharif, K			Temporal classification for fault-prediction in a real-world telecommunications network	IEEE: 2005 International Conference on Emerging Technologies, Proceedings			English	Proceedings Paper	International Conference on Emerging Technologies	SEP 17-18, 2005	Islamabad, PAKISTAN	IEEE, Ctr Adv Studies Engn		network management; classification; prediction and decision tree tree induction		This paper presents a new temporal classification approach for fault-prediction in a Telecommunications Network. The countrywide data network of Pakistan Telecom (PTCL) has been selected as a basis for the investigation of classification algorithms to predict faults before they stop a large number of users circuits from normal operation. The main problems addressed are the evaluation of alarms and development of new machine learning tools to help overcome the interoperability issues. The motivation behind this work is to assist human operators and minimize the cost of the alarm evaluation process.	PIEAS, Dept Elect Engn, Islamabad, Pakistan	Jaudet, M (reprint author), PIEAS, Dept Elect Engn, Islamabad, Pakistan.						Bloomfield P., 2000, FOURIER ANAL TIME SE; Brockwell PJ, 2002, INTRO TIME SERIES FO; Cohen W.W., 1995, P 12 INT C MACH LEAR, P115; Dunham M., 2003, DATA MINING INTRO AD; Han J., 2001, DATA MINING CONCEPTS; Hand D.J., 2000, PRINCIPLES DATA MINI; Hastie T., 2001, ELEMENTS STAT LEARNI; Haykin S, 1998, NEURAL NETWORKS COMP; JAUDET M, IEEE INMIC 2004; KARIMI K, 2002, 15 CAN C ART INT AI; KARIMI K, 2003, 16 CAN ART INT C AI, P175; KARIMI K, 2002, 14 IEEE INT C TOOLS; KENNETT RJ, 2001, P 5 PAC AS C KNOWL D; Klemettinen M., 1999, THESIS U HELSINKI; LIANG H, 2002, THESIS VIRGINIA POLY; Luo F.-L., 1998, APPL NEURAL NETWORKS; Mandic D. P., 2001, RECURRENT NEURAL NET; MATHIAS A, 2004, J STAT SOFTWARE, V11; Michie D., 1994, MACHINE LEARNING NEU; Mitchell T., 1997, MACHINE LEARNING; PARZEN E, 1984, TIM SER AN IRR OBS D; Pearl J., 2000, CAUSALITY MODELS REA; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Scheines R., 1994, TETRAD; VILALTA R, 2002, IBM SYSTEMS J, V41; VILALTA R, 2001, P 12 IFIP IEEE INT W; WALLACE CS, 1999, LEARNING LINEAR CAUS; Weigend A.S., 1994, TIME SERIES PREDICTI; Weiss G. M., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; WEISS GM, P GEN EV COMP C ORL, P719; Wietgrefe H, 1997, INT WORKSH APPL NEUR	31	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9247-7				2005							209	214				6	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BDP11	WOS:000234650800039		
J	Steinwart, I				Steinwart, I			Consistency of support vector machines and other regularized kernel classifiers	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article						computational learning theory; kernel methods; pattern recognition; regularization; support vector machines (SVMs); universal consistency	GENERALIZATION PERFORMANCE; ENTROPY NUMBERS; CONVEX HULLS; CLASSIFICATION; NETWORKS; OPERATORS; CONVERGENCE; STABILITY	It is shown that various classifiers that are based on minimization of a regularized risk are universally consistent, i.e., they can asymptotically learn in every classification task. The role of the loss functions used in these algorithms is considered in detail. As an application of our general framework, several types of support vector machines (SVMs) as well as regularization networks are treated. Our methods combine techniques from stochastics, approximation theory, and functional analysis.	Los Alamos Natl Lab, Los Alamos, NM 87545 USA	Steinwart, I (reprint author), Los Alamos Natl Lab, POB 1663, Los Alamos, NM 87545 USA.	ingo@lanl.gov					Alon N, 1997, J ACM, V44, P615, DOI 10.1145/263867.263927; ARONSZAJN N, 1950, T AM MATH SOC, V68, P337; Barbu V., 1986, CONVEXITY OPTIMIZATI; Berg C., 1984, HARMONIC ANAL SEMIGR; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; Bousquet O, 2001, ADV NEUR IN, V13, P196; Carl B, 1999, J LOND MATH SOC, V60, P871, DOI 10.1112/S0024610799008005; Carl B., 1990, ENTROPY COMPACTNESS; CARL B, 1988, J FUNCT ANAL, V81, P54, DOI 10.1016/0022-1236(88)90112-7; CARL B, 1988, INVENT MATH, V94, P479, DOI 10.1007/BF01394273; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COX DD, 1990, ANN STAT, V18, P1676, DOI 10.1214/aos/1176347872; Cristianini N, 2000, INTRO SUPPORT VECTOR; Cucker F, 2002, B AM MATH SOC, V39, P1; Devroye L., 1997, PROBABILISTIC THEORY; DUDLEY RM, 1978, ANN PROBAB, V6, P899, DOI 10.1214/aop/1176995384; Edmunds D.E., 1996, FUNCTION SPACES ENTR; Evgeniou T, 2000, ADV NEUR IN, P171; GIROSI F, 1995, NEURAL COMPUT, V7, P219, DOI 10.1162/neco.1995.7.2.219; Hastie T., 2001, ELEMENTS STAT LEARNI; Hoffgen K.-U., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130431; Johnson D. S., 1978, Theoretical Computer Science, V6, DOI 10.1016/0304-3975(78)90006-3; Lee YJ, 2001, COMPUT OPTIM APPL, V20, P5, DOI 10.1023/A:1011215321374; Lin Y, 2004, STAT PROBABIL LETT, V68, P73, DOI 10.1016/j.spl.2004.03.002; Lin Y, 2002, DATA MIN KNOWL DISC, V6, P259, DOI 10.1023/A:1015469627679; Mangasaian OL, 2001, J MACH LEARN RES, V1, P161, DOI 10.1162/15324430152748218; PHELPS R, 1986, LECT NOTES MATH, V1364; Ritter K., 2000, LECT NOTES MATH, V1733; Rockafellar R.T., 1970, CONVEX ANAL; SAUNDERS C, 1998, CSDTR9803 U LOND ROY; Scholkopf B, 2001, LECT NOTES ARTIF INT, V2111, P416; Scholkopf B, 2002, LEARNING KERNELS; Steinwart I, 2003, ARCH MATH, V80, P310, DOI 10.1007/s00013-003-0476-y; Steinwart I, 2003, IEEE T PATTERN ANAL, V25, P1274, DOI 10.1109/TPAMI.2003.1233901; Steinwart I., 2001, J MACHINE LEARNING R, V2, P67, DOI 10.1162/153244302760185252; Steinwart I, 2000, J APPROX THEORY, V103, P302, DOI 10.1006/jath.1999.3428; STEINWART I, 2002, WHICH DATA DEPENDENT; Steinwart I, 2002, J COMPLEXITY, V18, P768, DOI 10.1006/jcom.2002.0642; Steinwart Ingo, 2003, J MACHINE LEARNING R, V4, P1071, DOI 10.1162/jmlr.2003.4.6.1071; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Triebel H., 1983, THEORY FUNCTION SPAC; Vapnik V., 1998, STAT LEARNING THEORY; Williamson RC, 2001, IEEE T INFORM THEORY, V47, P2516, DOI 10.1109/18.945262; Zhang T, 2001, ADV NEUR IN, V13, P357; Zhang T, 2004, ANN STAT, V32, P56; Zhou DX, 2002, J COMPLEXITY, V18, P739, DOI 10.1006/jcom.2002.0635	46	61	62	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9448			IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	JAN	2005	51	1					128	142		10.1109/TIT.2004.839514		15	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	885TH	WOS:000226179300009		
J	Carvalho, AX; Tanner, MA				Carvalho, AX; Tanner, MA			Mixtures-of-experts of autoregressive time series: Asymptotic normality and model specification	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						asymptotic properties; maximum likelihood estimation; mixture-of-experts (ME); nonlinear time series	GENERALIZED LINEAR-MODELS; HIERARCHICAL MIXTURES; APPROXIMATION; PROBABILITY; LIKELIHOOD; ALGORITHM	We consider a class of nonlinear models based on mixtures of local autoregressive time series. At any given time point, we have a certain number of linear models, denoted as experts, where the vector of covariates may include lags of the dependent variable. Additionally, we assume the existence of a latent multinomial variable, whose distribution depends on the same covariates; as the experts, that determines which linear Process is observed. This structure, denoted as mixture-of-experts (ME), is considerably flexible in modeling the conditional mean function, as shown by Jiang and Tanner. In this paper, we present a formal treatment of conditions to guarantee the asymptotic normality of the maximum likelihood estimator (MLE), under stationarity and nonstationarity, and under correct model specification and model misspecification. The performance of common model selection criteria in selecting the number of experts is explored via Monte Carlo simulations. Finally, we present applications to simulated and real data sets, to illustrate the ability of the proposed structure to model not only the conditional mean, but also the whole conditional density.	Univ British Columbia, Vancouver, BC V6T 1Z4, Canada; Inst Appl Econ Res, BR-70076900 Brasilia, DF, Brazil; Northwestern Univ, Evanston, IL 60201 USA	Carvalho, AX (reprint author), Univ British Columbia, Vancouver, BC V6T 1Z4, Canada.	carvalho@stat.ubc.ca					Akaike H, 1973, P 2 INT S INF THEOR, P267; AKAIKE H, 1981, J ECONOMETRICS, V16, P3, DOI 10.1016/0304-4076(81)90071-3; Amemiya T., 1985, ADV ECONOMETRICS; BERKOWITZ J, 2000, TESTING DENSITY FORE; BIERENS H, 1996, TOPICS ADV ECONOMETR; BROCKWELL P, 1996, INTRO TIMES SERIES F; CARVALHO A, 2002, THESIS NW U EVANSTON; CARVALHO A, 2003, ERGODICITY EXISTENCE; CARVALHO A, 2003, P IEEE C COMP INT FI, P285; Chipman HA, 2002, MACH LEARN, V48, P299, DOI 10.1023/A:1013916107446; DAVIDSON J, 1994, STOCHASTIC LIMIT THE; Diebold FX, 1998, INT ECON REV, V39, P863, DOI 10.2307/2527342; Durret R., 1996, PROBABILITY THEORY E; Ghahramani Z., 1996, EM ALGORITHM MIXTURE; Gutta S, 2000, IEEE T NEURAL NETWOR, V11, P948, DOI 10.1109/72.857774; Hamilton J. D., 1994, TIME SERIES ANAL; Harvey AC, 1994, FORECASTING STRUCTUR; Hastie T., 2001, ELEMENTS STAT LEARNI; Huerta G, 2001, J COMPUT GRAPH STAT, V10, P82, DOI 10.1198/10618600152418755; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; Jeffries N, 2001, ENVIRONMETRICS, V12, P1, DOI 10.1002/1099-095X(200102)12:1<1::AID-ENV425>3.0.CO;2-N; Jiang W, 1999, NEURAL NETWORKS, V12, P1253, DOI 10.1016/S0893-6080(99)00066-0; Jiang WX, 2000, IEEE T INFORM THEORY, V46, P1005; Jiang WX, 1999, NEURAL COMPUT, V11, P1183, DOI 10.1162/089976699300016403; Jiang WX, 1999, ANN STAT, V27, P987; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Kurnik RT, 1999, SENSOR ACTUAT B-CHEM, V60, P19, DOI 10.1016/S0925-4005(99)00239-7; Lin HQ, 2000, STAT MED, V19, P1303, DOI 10.1002/(SICI)1097-0258(20000530)19:10<1303::AID-SIM424>3.0.CO;2-E; MCCULLAGH M, 1998, MONOGRAPHS STAT APPL, V37; Meyn S.P., 1993, MARKOV CHAINS STOCHA; NEWEY WK, 1991, ECONOMETRICA, V59, P1161, DOI 10.2307/2938179; NEWEY WK, 1987, ECONOMETRICA, V55, P703, DOI 10.2307/1913610; QUINN B, 1987, J R STAT SOC B, V39, P311; ROSENBLATT M, 1952, ANN MATH STAT, V23, P470, DOI 10.1214/aoms/1177729394; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; Tong H., 1983, THRESHOLD MODELS NON; Weigend AS, 1995, INT J NEURAL SYST, V6, P373, DOI 10.1142/S0129065795000251; White H., 2001, ASYMPTOTIC THEORY EC; White H., 1996, ESTIMATION INFERENCE; Wong CS, 2001, BIOMETRIKA, V88, P833, DOI 10.1093/biomet/88.3.833; WONG DL, 1988, PAEDIAT NURSING, V14, P1; WOOD S, 2001, BIOMETRIKA, V89, P513; Wooldridge Jeffrey M., 2002, ECONOMETRIC ANAL CRO; ZEEVI A, 1996, NEURAL NETWORKS, V10, P99; ZEEVI A, 1999, NONLINEAR MODELS TIM	47	9	9	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1045-9227			IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	JAN	2005	16	1					39	56		10.1109/TNN.2004.839356		18	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	892AK	WOS:000226621900004	15732388	
B	Nishii, R; Eguchi, S			IEEE	Nishii, R; Eguchi, S			Spatio-temporal contextual image classification based on Spatial AdaBoost	IGARSS 2005: IEEE International Geoscience and Remote Sensing Symposium, Vols 1-8, Proceedings	IEEE International Symposium on Geoscience and Remote Sensing (IGARSS)		English	Proceedings Paper	25th IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2005)	JUL 25-29, 2005	Seoul, SOUTH KOREA	IEEE, IEEE Geosci & Remote Sensing Soc, NASA, NOAA, USN Off Res, Japan Aerosp Explorat Agcy, Natl Polar orbiting Operat Environm Satellite Syst, Ball Aerosp & Technologies Corp, Int Union Radio Sci, Elect & Telecommun Res Inst, Korea Sci & Engn Fdn, Korea Natl Tourism Org, Korea Telecommun				Spatial AdaBoost proposed by Nishii and Eguchi (TGRS 2005) is a contextual supervised classifier of land-cover categories of geostatistical data. It shows an excellent performance similar to that of the MRF-based classifier with much less computational cost. In this paper, we extend the method to the setup with multi spatio-temporal images. We take classification functions by the averages of log posterior probabilities derived by respective training data sets. The functions are sequentially combined by minimizing the empirical exponential risk calculated over samples in all the training data sets. Thus, we obtain a classifier based on a convex combination of the functions. The proposed method is applied to artificial data, and it shows performance similar to that of Spatial AdaBoost based on much larger training data.	Kyushu Univ, Fac Math, Higashi Ku, Fukuoka 8128581, Japan	Nishii, R (reprint author), Kyushu Univ, Fac Math, Higashi Ku, Fukuoka 8128581, Japan.						Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Hastie T., 2001, ELEMENTS STAT LEARNI; *IEEE, 2003, IEEE T GEOSC REM SEN, V41; NISHII R, 2005, IEEE T GEOSCIENCE RE; Takenouchi T, 2004, NEURAL COMPUT, V16, P767, DOI 10.1162/089976604322860695	6	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9050-4	INT GEOSCI REMOTE SE			2005							172	175				4	Geosciences, Multidisciplinary; Remote Sensing	Geology; Remote Sensing	BEG75	WOS:000237237600045		
S	Marcal, ARS; Borges, JS		Kamel, M; Campilho, A		Marcal, ARS; Borges, JS			Estimating the natural number of classes on hierarchically clustered multi-spectral images	IMAGE ANALYSIS AND RECOGNITION	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	2nd International Conference on Image Analysis and Recognition	SEP 28-30, 2005	Toronto, CANADA	Univ Waterloo, Pattern Anal & Machine Intelligence Grp, Univ Porto, FEUP, INEB, IEEE Toronto Sect, IEEE Kitchener Waterloo Sect				Image classification is often used to extract information from multi-spectral satellite images. Unsupervised methods can produce results well adjusted to the data, but that are usually difficult to assess. The purpose of this work was to evaluate the Xu internal similarity index ability to estimate the natural number of classes in multi-spectral satellite images. The performance of the index was initially tested with data produced synthetically. Four Landsat TM image sections were then used to evaluate the index. The test images were classified into a large number of classes, using the unsupervised algorithm ISODATA, which were subsequently structured hierarchically. The Xu index was used to identify the optimum partition for each test image. The results were analysed in the context of the land cover types expected for each location.	Univ Porto, Fac Ciencias, DMA, P-4169007 Oporto, Portugal	Marcal, ARS (reprint author), Univ Porto, Fac Ciencias, DMA, Rua Campo Alegre 687, P-4169007 Oporto, Portugal.		MARCAL, ANDRE/F-6230-2013	MARCAL, ANDRE/0000-0002-8501-0974			*CNIG, 1990, CENTR NAC INF GEOGRF; DUBES RC, 1987, PATTERN RECOGN, V20, P645, DOI 10.1016/0031-3203(87)90034-3; Hastie T., 2001, ELEMENTS STAT LEARNI; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Lillesand T.M., 2000, REMOTE SENSING IMAGE; *MATLAB, 2000, MATLAB LANG TECHN CO; MILLIGAN GW, 1985, PSYCHOMETRIKA, V50, P159, DOI 10.1007/BF02294245; *PCI, 2001, PCI GEOM XPAC REF MA; Ripley BD, 1996, PATTERN RECOGNITION; Tou JT, 1974, PATTERN RECOGNITION; XU S, 1993, PATTERN RECOGN LETT, V14, P7, DOI 10.1016/0167-8655(93)90127-Y	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29069-9	LECT NOTES COMPUT SC			2005	3656						447	455				9	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BDK43	WOS:000233991100056		
S	Fujino, A; Ueda, N; Saito, K		Lee, GG; Yamada, A; Meng, H; Myaeng, SH		Fujino, A; Ueda, N; Saito, K			A classifier design based on combining multiple components by maximum entropy principle	INFORMATION RETRIEVAL TECHNOLOGY, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	2nd Asia Information Retrieval Symposium	OCT 13-15, 2005	Jeju Isl, SOUTH KOREA				EM	Designing high performance classifiers for structured data consisting of multiple components is an important and challenging research issue in the field of machine learning. Although the main component of structured data plays an important role when designing classifiers, additional components may contain beneficial information for classification. This paper focuses on a probabilistic classifier design for multiclass classification based on the combination of main and additional components. Our formulation separately considers component generative models and constructs the classifier by combining these trained models based on the maximum entropy principle. We use naive Bayes models as the component generative models for text and link components so that we can apply our classifier design to document and web page classification problems. Our experimental results for three test collections confirmed that the proposed method effectively combined the main and additional components to improve classification performance.	NTT Corp, NTT Commun Sci Labs, Kyoto 6190237, Japan	Fujino, A (reprint author), NTT Corp, NTT Commun Sci Labs, 2-4,Hikaridai,Seika Cho, Kyoto 6190237, Japan.	a.fujino@cslab.kecl.ntt.co.jp; ueda@cslab.kecl.ntt.co.jp; saito@cslab.kecl.ntt.co.jp					Allwein E. L., 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; Berger AL, 1996, COMPUT LINGUIST, V22, P39; BROCHU E, 2003, ADV NEURAL INFORM PR, V15, P1505; Chakrabarti S, 1998, P ACM SIGMOD INT C M, P307, DOI 10.1145/276304.276332; Chen S. F., 1999, GAUSSIAN PRIOR SMOOT; Cohn D, 2001, ADV NEUR IN, V13, P430; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Hastie T., 2001, ELEMENTS STAT LEARNI; LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116; LU Q, 2003, IJFAI WORKSH TEXT MI; Nigam K, 1999, IJCAI 99 WORKSH MACH, P61; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Raina R., 2004, ADV NEURAL INFORM PR, V16; Rifkin R, 2004, J MACH LEARN RES, V5, P101; Salton G., 1983, INTRO MODERN INFORM; Sun A., 2002, P 4 INT WORKSH WEB I, P96	16	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29186-5	LECT NOTES COMPUT SC			2005	3689						423	438				16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BDF93	WOS:000233302700033		
B	Johansson, J; Ljung, P; Jern, M; Cooper, M		Stasko, J; Stasko, J; Ward, M		Johansson, J; Ljung, P; Jern, M; Cooper, M			Revealing structure within clustered parallel coordinates displays	INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS			English	Proceedings Paper	IEEE Symposium on Information Visualization (InfoVis 05)	OCT 23-25, 2005	Minneapolis, MN	IEEE, IEEE Comp Soc, Kitware, Pacific NW Natl Lab, Chevron, Digital Technol Ctr, IBM Res, MK, 3M, Mitsubishi Elect, Minesota Supercomp Inst, Natl Lib Med, nVIDIA, Unisyst, Sun Microsyst, VITAL, A K Peters Ltd, Palgrave		parallel coordinates; clustering; transfer function; feature animation		In order to gain insight into multivariate data, complex structures must be analysed and understood. Parallel coordinates is an excellent tool for visualizing this type of data but has its limitations. This paper deals with one of its main limitations - how to visualize a large number of data items without hiding the inherent structure they constitute. We solve this problem by constructing clusters and using high-precision textures to represent them. We also use transfer functions that operate on the high-precision textures in order to highlight different aspects of the cluster characteristics. Providing pre-defined transfer functions as well as the support to draw customized transfer functions makes it possible to extract different aspects of the data. We also show how feature animation can be used as guidance when simultaneously analysing several clusters. This technique makes it possible to visually represent statistical information about clusters and thus guides the user, making the analysis process more efficient.	Linkoping Univ, NVIS, S-58183 Linkoping, Sweden	Johansson, J (reprint author), Linkoping Univ, NVIS, S-58183 Linkoping, Sweden.	jimjo@itn.liu.se; plg@itn.liu.se; mikje@itn.liu.se; matco@itn.liu.se					Andrienko G., 2004, Proceedings. Second International Conference on Coordinated & Multiple Views in Exploratory Visualization, DOI 10.1109/CMV.2004.1319530; ARTERO AO, 2004, 10 IEEE S INF VIS, P81; Barlow N, 2004, IEEE INFOR VIS, P725; BASALAJ W, 2000, THESIS U CAMBRIDGE; Berthold MR, 2003, IEEE T FUZZY SYST, V11, P369, DOI 10.1109/TFUZZ.2003.812696; Fua Y.-H., 1999, IEEE VISUALIZATION, P43; Gonzales R. C., 2001, DIGITAL IMAGE PROCES; Han J., 2001, DATA MINING CONCEPTS; Hand David J, 2001, PRINCIPLES DATA MINI; Hastie T., 2001, ELEMENTS STAT LEARNI; Inselberg A., 1990, IEEE VISUALIZATION, P361; Miller J. J., 1991, COMPUTING GRAPHICS S, P107; Novotny M., 2004, P 8 CENTR EUR SEM CO, P41; Pyle D., 1999, DATA PREPARATION DAT; Rodrigues JF, 2003, XVI BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P117, DOI 10.1109/SIBGRA.2003.1240999; WEGMAN EJ, 1996, HIGH DIMENSIONAL CLU	16	18	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7803-9464-X				2005							125	132		10.1109/INFVIS.2005.1532138		8	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	BDP03	WOS:000234641900017		
S	Pao, HK; Chang, SC; Lee, YJ		Gallagher, M; Hogan, J; Maire, F		Pao, HK; Chang, SC; Lee, YJ			Model trees for classification of hybrid data types	INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING IDEAL 2005, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	6th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL 2005)	JUL 06-08, 2005	Brisbane, AUSTRALIA	Univ Queensland			MULTIVARIATE DECISION TREES	In the task of classification, most learning methods are suitable only for certain data types. For the hybrid dataset consists of nominal and numeric attributes, to apply the learning algorithms, some attributes must be transformed into the appropriate types. This procedure could damage the nature of dataset. We propose a model tree approach to integrate several characteristically different learning methods to solve the classification problem. We employ the decision tree as the classification framework and incorporate support vector machines into the tree construction process. This design removes the discretization procedure usually necessary for tree construction while decision tree induction itself can deal with nominal attributes which may not be handled well by e.g., SVM methods. Experiments show that our purposed method has better performance than that of other competing learning methods.	Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei, Taiwan	Pao, HK (reprint author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei, Taiwan.	pao@mail.ntust.edu.tw; M9115009@mail.ntust.edu.tw; yuh-jye@mail.ntust.edu.tw					Bennett K.P., 1997, SUPPORT VECTOR MACHI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L., 1984, CLASSIFICATION REGRE; BRODLEY CE, 1995, MACH LEARN, V19, P45, DOI 10.1007/BF00994660; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; Fayyad UM, 1993, P 13 INT JOINT C ART, P1022; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Gama J, 1998, LECT NOTES ARTIF INT, V1484, P160; Hastie T., 2001, ELEMENTS STAT LEARNI; Heath D. G., 1993, P 13 INT JOINT C ART, P1002; Ittner A., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Kohavi R., 1996, P 2 INT C KNOWL DISC, P114; Lee YJ, 2001, COMPUT OPTIM APPL, V20, P5, DOI 10.1023/A:1011215321374; Li XB, 2003, IEEE T SYST MAN CY A, V33, P194, DOI 10.1109/TSMCA.2002.806499; MURPHY SK, 1994, J ARTIFICIAL INTELLI, V2, P1; MURTHY S, 1993, PROCEEDINGS OF THE ELEVENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P322; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; UTGOFF P, 1991, 9110 COINS U MASS; Vapnik VN, 1995, NATURE STAT LEARNING	22	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-26972-X	LECT NOTES COMPUT SC			2005	3578						32	39				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BCR09	WOS:000230878800005		
S	Kon, M; Plaskota, L; Przybyszewski, A		Klopotek, MA; Wierzchon, ST; Trojanowski, K		Kon, M; Plaskota, L; Przybyszewski, A			Machine learning and statistical MAP methods	Intelligent Information Processing and Web Mining, Proceedings	ADVANCES IN SOFT COMPUTING		English	Proceedings Paper	International Conference on Intelligent Information Processing and Web Mining IIS	JUN 13-16, 2005	Gdansk, POLAND	Polish Acad Sci, Inst Comp Sci				For machine learning of an input-output function f from examples, we show it is possible to define an a priori probability density function on the hypothesis space to represent knowledge of the probability distribution of f, even when the hypothesis space H is large (i.e., nonparametric). This allows extension of maximum a posteriori (MAP) estimation methods nonparametric function estimation. Among other things, the resulting MAPN (MAP for nonparametric machine learning) procedure easily reproduces spline and radial basis function solutions of learning problems.	Boston Univ, Boston, MA 02215 USA	Kon, M (reprint author), Boston Univ, Boston, MA 02215 USA.						FRIEDMAN N, 1996, 13 NAT C ART INT; Hastie T., 2001, ELEMENTS STAT LEARNI; JORDAN M, 2000, J MACHINE LEARNING R, V1, P1; KON M, 2004, DENSITY FUNCTIONS MA; MICCHELLI CA, 1985, LECT NOTES MATH, V1129, P21; Mitchell T., 1997, MACHINE LEARNING; PLASKOTA L, 1996, NOISY INFORMATION CO; Poggio T, 1999, AI MAG, V20, P37; Traub J. F., 1988, INFORMATION BASED CO; TRAUB JF, 1980, GEN THEORY OPTIMAL A; TRAUB JF, 2001, COMPLEXITY INFORMATI; Vapnik V. N., 1998, STAT LEARNING THEOR; Wahba G, 1999, ADVANCES IN KERNEL METHODS, P69	13	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1615-3871		3-540-25056-5	ADV SOFT COMP			2005							441	445		10.1007/3-540-32392-9_49		5	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BCU94	WOS:000231358900049		
S	Gruzdz, A; Ihnatowicz, A; Slezak, D		Klopotek, MA; Wierzchon, ST; Trojanowski, K		Gruzdz, A; Ihnatowicz, A; Slezak, D			Gene expression clustering: Dealing with the missing values	Intelligent Information Processing and Web Mining, Proceedings	ADVANCES IN SOFT COMPUTING		English	Proceedings Paper	International Conference on Intelligent Information Processing and Web Mining IIS	JUN 13-16, 2005	Gdansk, POLAND	Polish Acad Sci, Inst Comp Sci		gene expression data; self-organizing maps; rank-based distances	MICROARRAYS; PATTERNS; MAPS	We propose a new method to deal with missing values in the gene expression data. It is applied to improve the quality of clustering genes with respect to their functionality. Calculations are run against real-life data, within the framework of self-organizing maps. The applied gene distances correspond to the rank-based Spearman correlation and entropy-based information measure.	Univ Regina, Dept Comp Sci, Regina, SK S4S 0A2, Canada	Gruzdz, A (reprint author), Univ Regina, Dept Comp Sci, Regina, SK S4S 0A2, Canada.						Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Baldi P., 2002, DNA MICROARRAYS GENE; de Brevern AG, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-114; Dembele D, 2003, BIOINFORMATICS, V19, P973, DOI 10.1093/bioinformatics/btg119; Friedman J., 2001, ELEMENTS STAT LEARNI; GRUZDZ A, 2005, P ISMIS 2005; Kapur J.N., 1992, ENTROPY OPTIMIZATION; Khan AH, 2003, GENOMICS, V81, P157, DOI 10.1016/S0888-7543(02)00032-0; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Liu J. S., 2003, BAYESIAN STAT, V7, P249; Oba S, 2003, BIOINFORMATICS, V19, P2088, DOI 10.1093/bioinformatics/btg287; Pawlak Z., 1991, ROUGH SETS THEORETIC; Rebhan M, 1997, GENECARDS ENCY GENES; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; Safran M, 2003, NUCLEIC ACIDS RES, V31, P142, DOI 10.1093/nar/gkg050; SLEZAK D, 2005, UNPUB ROUGH ENTROPY; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520	19	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1615-3871		3-540-25056-5	ADV SOFT COMP			2005							521	530		10.1007/3-540-32392-9_63		10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BCU94	WOS:000231358900063		
S	Ng, WWY; Chan, APF; Yeung, DS; Tsang, ECC			IEEE	Ng, WWY; Chan, APF; Yeung, DS; Tsang, ECC			Quantitative study on the generalization error of Multiple Classifier Systems	INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS, VOL 1-4, PROCEEDINGS	IEEE International Conference on Systems Man and Cybernetics Conference Proceedings		English	Proceedings Paper	IEEE International Conference on Systems, Man and Cybernetics	OCT 10-12, 2005	Waikoloa, HI	IEEE Syst, Man & Cybernet Soc		Multiple Classifier System; radial basis function neural network (RBFNN); model evaluation; classifier performance assessment; ensemble of classifiers; fusion of classifiers and generalization error		Multiple Classifier System (MCS) has been one of the hot research topics in machine learning field A MCS merges an ensemble of different or same type of classifiers together to enhance the problem solving performance of machine learning. However, the choice of the number of classifiers and the fusion method are usually based on ad-hoc selection. In this paper, we propose a novel quantitative measure of the generalization error for MCS. The localized generalization error model bounds above the mean square error (MSE) of a MCS for unseen samples located within a neighborhood of the training samples. The relationship between the proposed model and classification accuracy is also discussed in this paper. This model quantitatively measures the goodness of the MCS in approximating the unknown input-output mapping hidden in the training dataset. The localized generalization error model is applied to select a MCS, among different choices of number of classifiers and fusion methods, for a given classification problem. Experimental results on three real world datasets are performed to show promising results.	Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China	Ng, WWY (reprint author), Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China.	cswyng@comp.polyu.edu.hk; csaki@comp.polyu.edu.hk; csdaniel@comp.polyu.edu.hk; csetsang@comp.polyu.edu.hk					CHAKRABORTY D, 2003, IEEE T NEURAL NETWOR, P1; DRUCKER H, 1994, NEURAL COMPUT, V6, P1289, DOI 10.1162/neco.1994.6.6.1289; Freund Y., 1996, P 13 INT C MACH LEAR, P148; GIORGIO G, 2003, PATTERN RECOGN, V24, P1795; Hastie T., 2001, ELEMENT STAT LEARNIN; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; NG WWY, 2005, IN PRESS P INT C MAC; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; SHUANG Y, 2004, EXPERT SYST, V21, P279; TSOUMAKAS G, 2005, INTELLIGENT DATA ANA; Tumer K., 1996, Connection Science, V8, DOI 10.1080/095400996116839; Yager R.R., 1997, ORDERED WEIGHTED AVE	13	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X		0-7803-9298-1	IEEE SYS MAN CYBERN			2005							889	894				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	BDT16	WOS:000235210800147		
S	Inada, M; Terano, T			IEEE	Inada, M; Terano, T			QC chart mining: Extracting systematic error patterns from quality control charts	INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS, VOL 1-4, PROCEEDINGS	IEEE International Conference on Systems Man and Cybernetics Conference Proceedings		English	Proceedings Paper	IEEE International Conference on Systems, Man and Cybernetics	OCT 10-12, 2005	Waikoloa, HI	IEEE Syst, Man & Cybernet Soc		time series decomposition; quality control chart; quality management; laboratory medicine		This paper presents a novel method: "QC Chart Mining", which extracts systematic error patterns from quality control charts in order to manage clinical test data at a medical laboratory. In this paper we describe the basic principle of a time series decomposition mechanism for QC Chart Mining. QC Chart Mining is used to recognize quality problems such as long-term trends and/or daily cyclic variations in analytical processes of clinical tests, then to improve the quality level over clinical laboratory medicine. Intensive experiments from both actual quality-control data and artificial data have revealed the validity of the proposed method Our results have shown that the proposed method is useful and effective for quality management in a medical laboratory.	Toranomon Gen Hosp, Dept Clin Lab, Tokyo, Japan	Inada, M (reprint author), Toranomon Gen Hosp, Dept Clin Lab, Tokyo, Japan.	m-inada@pg8.so-net.ne.jp; terano@dis.titech.ac.jp					Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; Cleveland RC, 1990, J OFF STAT, V6, P3; CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P596, DOI 10.2307/2289282; Hastie T., 2001, ELEMENTS STAT LEARNI; LEVEY S, 1950, AM J CLIN PATHOL, V20, P1059; *NIST SEMATECH, 2004, E HDB STAT METH; Pal Sankar K., 2000, SOFT COMPUTING CASE; SHEHART WA, 1939, STAT METHOD VIEW POI; Simonoff JS, 1996, SMOOTHING METHODS ST; Westgard JO, 1986, COST EFFECTIVE QUALI	10	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X		0-7803-9298-1	IEEE SYS MAN CYBERN			2005							3781	3787				7	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	BDT16	WOS:000235210803130		
J	Hurtado, JE; Zarate, F; Onate, E				Hurtado, JE; Zarate, F; Onate, E			Reliability estimation of the sheet stamping process using support vector machines	INTERNATIONAL JOURNAL OF VEHICLE DESIGN			English	Article						sheet stamping; pattern recognition; artificial intelligence; support vector machines; Monte Carlo simulation		An important concern in sheet stamping is the risk of obtaining brittle final products that can be affected by fracture. Monte Carlo simulations presented herein show that this is governed by two main factors, namely static and dynamic friction coefficients. Whereas the latter correlates in a non-linear manner with minimum and maximum end thickness, the relationship of these design parameters to the former exhibits a bifurcation that is typical of highly non-linear phenomena, in which there is a sensitivity to small perturbations of the input values (chaos). In order to estimate the reliability of the process (i.e., the probability of obtaining brittle products due to low minimum and maximum thicknesses) with a reduced number of Monte Carlo runs, it is proposed to assimilate the problem to a pattern recognition task, due to the existence of two classes, namely robust and brittle. Among many pattern recognition algorithm that are useful to this end, use is made of support vector machines, as this incorporates the powerful tool of class margins that allow a drastic reduction of the number of simulations.	Univ Nacl Colombia, Colombes, France	Hurtado, JE (reprint author), Univ Nacl Colombia, Colombes, France.	jhurtado14@epm.net.co; zarate@cimne.upc.es; onate@cimne.upc.es	ONATE, EUGENIO/I-2758-2014	ONATE, EUGENIO/0000-0002-0804-7095			Belytschko T., 2000, NONLINEAR FINITE ELE; Cristianini N, 2000, INTRO SUPPORT VECTOR; Duda R.O., 2001, PATTERN CLASSIFICATI; Fine T.L., 1999, FEEDFORWARD NEURAL N; Hastie T., 2001, ELEMENTS STAT LEARNI; Hurtado JE, 2003, J STRUCT ENG-ASCE, V129, P1141, DOI 10.1061/(ASCE)0733-9445(2003)129:8(1141); HURTADO JE, 2004, STRUCTURAL RELIABILT; Hurtado JE, 2001, COMPUT METHOD APPL M, V191, P113, DOI 10.1016/S0045-7825(01)00248-1; Kall P., 1995, STOCHASTIC PROGRAMMI; ONATE E, 1996, 3 INT C NUM SIM 3D S; ONATE E, 1999, 4 INT C NUM SIM 3D S; Pradlwarter HJ, 1999, PROBABILIST ENG MECH, V14, P213, DOI 10.1016/S0266-8920(98)00009-5; Vapnik V., 1998, STAT LEARNING THEORY	13	0	0	INDERSCIENCE ENTERPRISES LTD	GENEVA	WORLD TRADE CENTER BLDG, 29 ROUTE DE PRE-BOIS, CASE POSTALE 896, CH-1215 GENEVA, SWITZERLAND	0143-3369			INT J VEHICLE DES	Int. J. Veh. Des.		2005	39	1-2					110	124		10.1504/IJVD.2005.007223		15	Engineering, Mechanical; Transportation Science & Technology	Engineering; Transportation	971JQ	WOS:000232380500010		
B	Liu, L; Meng, G		Wen, TD		Liu, L; Meng, G			Structure damage severity prediction based on Support Vector Machine	ISTM/2005: 6th International Symposium on Test and Measurement, Vols 1-9, Conference Proceedings			English	Proceedings Paper	6th International Symposium on Test and Measurement (ISTM)	JUN 01-04, 2005	Dalian, PEOPLES R CHINA	Chinese Soc Modern Tech Equipment, Chinese Assoc Higher Educ, CSMTE, Test & Measurement Sect, Soc Instrumentat, Measurement & Control, N Univ China, Key Lab Instrumentat Sci & Dynam Measurement, Minist Educ, Natl Key Lab Elect Measurement Technol, Taiyuan Div, Candidate State Key Lab Dynam Measurement, Dalian Univ Tehnol, State Key Lab Coastal & Offshore Engn, NUC, Dept Elect Sci & Technol				This paper concerns a vibration-based method for non-destructive detection in,structures, particularly in beams. The SVM(Support Vector Machine) is a machine learning algorithm based on statistical learning theory, which also,has the good regression ability. Firstly the SVM regression algorithms are briefly reviewed. Then a method for the quantification of the damage using the SVM is investigated. Moreover, computer-simulated results for a cantilever beam with cracks are presented. The results clearly demonstrate the effectiveness of this method for determining the size of cracks.	Shanghai Jiao Tong Univ, State Key Lab Vibrat Shock & Noise, Shanghai 200240, Peoples R China	Liu, L (reprint author), Shanghai Jiao Tong Univ, State Key Lab Vibrat Shock & Noise, Shanghai 200240, Peoples R China.		Peng, Z/B-3875-2012				Chang C, 2001, LIBSVM LIB SUPPORT V; Ge M, 2004, MECH SYST SIGNAL PR, V18, P143, DOI 10.1016/S0888-3270(03)00071-2; Hastie T., 2001, ELEMENTS STAT LEARNI; Salawu OS, 1997, ENG STRUCT, V19, P718, DOI 10.1016/S0141-0296(96)00149-6; Smola A. J., 1998, TUTORIAL SUPPORT VEC; Vapnik V., 1982, ESTIMATION DEPENDENC	6	0	0	INTERNATIONAL ACADEMIC PUBLISHERS LTD	HONG KONG	UNIT 1205, 12 FLOOR, SINO PLAZA, 255 GLOUCESTER ROAD, HONG KONG 00000, CAUSEWAY BAY, PEOPLES R CHINA			7-5062-7445-0				2005							2291	2294				4	Instruments & Instrumentation	Instruments & Instrumentation	BCZ22	WOS:000232030702066		
J	Raghavan, N; Amaratunga, D; Nie, AY; McMillian, M				Raghavan, N; Amaratunga, D; Nie, AY; McMillian, M			Class prediction in toxicogenomics	JOURNAL OF BIOPHARMACEUTICAL STATISTICS			English	Article						classification; cross validation; gene expression; gene selection; hepatotoxicity; linear discriminant analysis; microarray; normalization; toxicogenomics	RAT-LIVER	The intent of this article is to discuss some of the complexities of toxicogenomics data and the statistical design and analysis issues that arise in the course of conducting a toxicogenomics study. We also describe a procedure for classifying compounds into various hepatotoxicity classes based on gene expression data. The methodology involves first classifying a compound as toxic or nontoxic and subsequently classifying the toxic compounds into the hepatotoxicity classes, based on votes by binary classifiers. The binary classifiers are constructed by using genes selected to best elicit differences between the two classes. We show that the gene selection strategy improves the misclassification error rates and also delivers gene pathways that exhibit biological relevance.	Johnson & Johnson Pharmaceut Res & Dev LLC, Dept Nonclin Biostat, Raritan, NJ 08869 USA; Johnson & Johnson Pharmaceut Res & Dev LLC, Mech Toxicol Grp, Raritan, NJ 08869 USA	Raghavan, N (reprint author), Johnson & Johnson Pharmaceut Res & Dev LLC, Dept Nonclin Biostat, 1000 Rt 202 S,Room G004, Raritan, NJ 08869 USA.	nraghava@prdus.jnj.com					Amaratunga D, 2004, EXPLORATION ANAL DNA; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Friedman J., 1996, ANOTHER APPROACH POL; HAND DJ, 1997, CONSTRUCTION ASSIGNM; Hastie T., 2001, ELEMENTS STAT LEARNI; HOSACK DA, 2003, GNOME BIOL, V4, pR60; McMillian M, 2004, BIOCHEM PHARMACOL, V68, P2249, DOI 10.1016/j.bcp.2004.08.003; McMillian M, 2004, BIOCHEM PHARMACOL, V67, P2141, DOI 10.1016/j.bcp.2004.01.029; Nuwaysir EF, 1999, MOL CARCINOGEN, V24, P153, DOI 10.1002/(SICI)1098-2744(199903)24:3<153::AID-MC1>3.0.CO;2-P; Speed T, 2003, STAT ANAL GENE EXPRE	10	8	9	TAYLOR & FRANCIS INC	PHILADELPHIA	325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA	1054-3406			J BIOPHARM STAT	J. Biopharm. Stat.		2005	15	2					327	341		10.1081/BIP-200048836		15	Pharmacology & Pharmacy; Statistics & Probability	Pharmacology & Pharmacy; Mathematics	024YK	WOS:000236232300011	15796298	
J	Spycher, S; Pellegrini, E; Gasteiger, J				Spycher, S; Pellegrini, E; Gasteiger, J			Use of structure descriptors to discriminate between modes of toxic action of phenols	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							TETRAHYMENA-PYRIFORMIS; NEURAL-NETWORKS; AQUATIC ORGANISMS; AUTO-CORRELATION; RAPID ACCESS; MECHANISMS; CLASSIFICATION; QSAR; ELECTRONEGATIVITY; QUANTIFICATION	Two classification models were developed based on a data set of 220 phenols with four associated Modes of Toxic Action (MOA). Counter-propagation neural networks (CPG NN) and multinomial logistic regression (multinom) were used as classification methods. The combination of topological autocorrelation of empirical pi-charge and sigma-electronegativity and of surface autocorrelation of hydrogen-bonding potential resulted in a 21-dimensional model that successfully discriminated between the four MOAs. Its overall predictive power was estimated to 92% using 5-fold cross-validation. Subsequently, a simple score for the distance to the training data was used to determine the prediction space of the model and used in an exploratory study on the phenols contained in the open NCI database. The use of a prediction space metric proved indispensable for the screening of such a diverse database. The prediction space covered by the proposed model is still of rather local nature which is either caused by the limited diversity and size of the training set or by the high dimensionality of the descriptors.	Univ Erlangen Nurnberg, Comp Chem Ctr, D-91052 Erlangen, Germany; Univ Erlangen Nurnberg, Inst Organ Chem, D-91052 Erlangen, Germany	Gasteiger, J (reprint author), Univ Erlangen Nurnberg, Comp Chem Ctr, Nagelsbachstr 25, D-91052 Erlangen, Germany.	Gasteiger@chemie.uni-erlangen.de					Aires-de-Sousa J, 2002, ANAL CHEM, V74, P80, DOI 10.1021/ac010737m; ALLEN MP, 1987, COMPUTER SIMULATION, P450; Aptula AO, 2002, QUANT STRUCT-ACT REL, V21, P12, DOI 10.1002/1521-3838(200205)21:1<12::AID-QSAR12>3.0.CO;2-M; *AUTOCORR, VERS 1 1 MOLN GMBH; Basak SC, 1998, ENVIRON TOXICOL CHEM, V17, P1056; Bradbury S P, 1994, SAR QSAR Environ Res, V2, P89, DOI 10.1080/10629369408028842; LECESSIE S, 1992, APPL STAT-J ROY ST C, V41, P191; *CORINA, VERS 2 4 MOLN GMBH; Cronin MTD, 2002, CHEMOSPHERE, V49, P1201, DOI 10.1016/S0045-6535(02)00508-8; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; ERIKSSON L, 2000, INTRO MULTI MEGAVARI; Escher BI, 2002, AQUAT SCI, V64, P20, DOI 10.1007/s00027-002-8052-2; Escher BI, 1999, ENVIRON SCI TECHNOL, V33, P560, DOI 10.1021/es980545h; Garg R, 2001, CRIT REV TOXICOL, V31, P223, DOI 10.1080/20014091111686; GASTEIGER J, 1980, TETRAHEDRON, V36, P3219, DOI 10.1016/0040-4020(80)80168-2; GASTEIGER J, 1984, J CHEM SOC PERK T 2, P559, DOI 10.1039/p29840000559; GASTEIGER J, 1990, J CHEM INF COMP SCI, V30, P467, DOI 10.1021/ci00068a019; GASTEIGER J, 1985, ANGEW CHEM, V97, P699, DOI 10.1002/ange.19850970818; Gasteiger J., 2003, HDB CHEMOINFORMATICS, P1034, DOI 10.1002/9783527618279.ch38; HANSCH C, 1969, ACCOUNTS CHEM RES, V2, P232, DOI 10.1021/ar50020a002; Harder A, 2003, ENVIRON SCI TECHNOL, V37, P4955, DOI 10.1021/es0341992; Harrell FE, 2001, REGRESSION MODELING; Hastie T., 2001, ELEMENTS STAT LEARNI; Hosmer D. W. J. R., 2000, APPL LOGISTIC REGRES; HUTCHINGS MG, 1983, TETRAHEDRON LETT, V24, P2541, DOI 10.1016/S0040-4039(00)81976-0; Karelson M, 1996, CHEM REV, V96, P1027, DOI 10.1021/cr950202r; KARLE J, 1994, J CHEM INF COMP SCI, V34, P381, DOI 10.1021/ci00018a025; Katritzky AR, 2003, J PHYS ORG CHEM, V16, P811, DOI 10.1003/poc.643; Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence; KRAJCSI P, 2002, HIGH ADME TOX ESTIMA, P75; LIPNICK RL, 1991, SCI TOTAL ENVIRON, V109, P131, DOI 10.1016/0048-9697(91)90175-E; Mekenyan O G, 1994, SAR QSAR Environ Res, V2, P129, DOI 10.1080/10629369408028844; MOREAU G, 1980, NOUV J CHIM, V4, P757; MOREAU G, 1980, NOUV J CHIM, V4, P359; Nendza M., 2000, QUANT STRUCT-ACT REL, V19, P581, DOI 10.1002/1521-3838(200012)19:6<581::AID-QSAR581>3.0.CO;2-A; Netzeva TI, 2003, QSAR COMB SCI, V22, P575, DOI 10.1002/qsar.200330816; Rand GM, 1995, FUNDAMENTALS AQUATIC, P3; Ren S, 2002, ENVIRON TOXICOL, V17, P119, DOI 10.1002/tox.10040; Ren SJ, 2003, J CHEM INF COMP SCI, V43, P2106, DOI 10.1021/ci034092y; Ripley BD, 1996, PATTERN RECOGNITION; ROBERTS DW, 1987, QSAR ENV TOXICOLOGY, V2, P295; Russom CL, 1997, ENVIRON TOXICOL CHEM, V16, P948, DOI 10.1897/1551-5028(1997)016<0948:PMOTAF>2.3.CO;2; SCHULTZ TW, 1997, P QSAR 96 ELS DK JUN, P329; Schuurmann G, 1996, ENVIRON TOXICOL CHEM, V15, P1702, DOI 10.1897/1551-5028(1996)015<1702:SARFCA>2.3.CO;2; Schuurmann G, 2003, CHEM RES TOXICOL, V16, P974, DOI 10.1021/tx0340504; Selzer P, 2000, CHEM-EUR J, V6, P920, DOI 10.1002/(SICI)1521-3765(20000303)6:5<920::AID-CHEM920>3.0.CO;2-W; *SONNIA, SELF ORGANIZING NEUR; Spycher S, 2004, QSAR COMB SCI, V23, P779, DOI 10.1002/qsar.200430877; *SURFACE, VERS 1 1 MOLN GMBH; TERADA H, 1990, ENVIRON HEALTH PERSP, V87, P213, DOI 10.2307/3431027; Terfloth L., 2003, CHEMOINFORMATICS, P401, DOI 10.1002/3527601643.ch8; VANWEZEL AP, 1995, CRIT REV TOXICOL, V25, P255, DOI 10.3109/10408449509089890; VEDANI A, 1990, J AM CHEM SOC, V112, P4759, DOI 10.1021/ja00168a021; WAGENER M, 1995, J AM CHEM SOC, V117, P7769, DOI 10.1021/ja00134a023; Wang JS, 1999, J MOL MODEL, V5, P252, DOI 10.1007/s0089490050252; Zupan J., 1999, NEURAL NETWORKS CHEM; ZUPAN J, 1994, ANAL CHIM ACTA, V292, P219, DOI 10.1016/0003-2670(94)00085-9; LANGUAGE ENV STAT CO	58	22	22	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596			J CHEM INF MODEL	J. Chem Inf. Model.	JAN-FEB	2005	45	1					200	208		10.1021/ci0497915		9	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Pharmacology & Pharmacy; Chemistry; Computer Science	911DU	WOS:000227982800024	15667146	
J	Indahl, U				Indahl, U			A twist to partial least squares regression	JOURNAL OF CHEMOMETRICS			English	Article						PLS1; powers of correlations and standard deviations; cross-validation; model selection; model interpretation	NEAR-INFRARED SPECTRA; PRINCIPAL COMPONENTS; CALIBRATION; SPECTROSCOPY; SELECTION	A modification of the PLS1 algorithm is presented. Stepwise optimization over a set of candidate loading weights obtained by taking powers of the y-X correlations and X standard deviations generalizes the classical PLS1 based on y-X covariances and hence adds flexibility to the modelling. When good linear predictions can be obtained, the suggested approach often finds models with fewer and more interpretable components. Good performance is demonstrated when compared with the classical PLS1 on calibration benchmark data sets. An important part of the comparisons is managed by a novel model selection strategy. The selection is based on choosing the simplest model among those with a cross-validation error smaller than the pre-specified significance limit of a chi(2)-statistic. Copyright (C) 2005 John Wiley & Sons, Ltd.	Norwegian Univ Life Sci, Sect Bioinformat, N-1432 As, Norway; Ctr Biospect & Data Modelling, N-1430 As, Norway	Indahl, U (reprint author), Norwegian Univ Life Sci, Sect Bioinformat, POB 5003, N-1432 As, Norway.	ulf.indahl@umb.no					Brent R.P., 1973, ALGORITHMS MINIMIZAT; BROWN PJ, 1992, J CHEMOMETR, V6, P151, DOI 10.1002/cem.1180060306; Brown PJ, 2001, J AM STAT ASSOC, V96, P398, DOI 10.1198/016214501753168118; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Hastie T., 2001, ELEMENTS STAT LEARNI; HOSKULDSSON A, 2001, CHEMOMETRICS INTELL, V55, P151; Indahl UG, 1998, J CHEMOMETR, V12, P261, DOI 10.1002/(SICI)1099-128X(199807/08)12:4<261::AID-CEM513>3.3.CO;2-Q; Kalivas JH, 1997, CHEMOMETR INTELL LAB, V37, P255, DOI 10.1016/S0169-7439(97)00038-5; Langsrud O, 2003, CHEMOMETR INTELL LAB, V68, P61, DOI 10.1016/S0169-7439(03)00088-l; Lindh M, 2001, J VIRAL HEPATITIS, V8, P349, DOI 10.1046/j.1365-2893.2001.00306.x; Martens H., 1989, MULTIVARIATE CALIBRA; NORREGAARD L, 2000, APPL SPECTROSC, V54, P413; Ojelund H, 2001, J CHEMOMETR, V15, P497; OSBORNE BG, 1984, J SCI FOOD AGR, V35, P99, DOI 10.1002/jsfa.2740350116; STONE M, 1990, J ROY STAT SOC B MET, V52, P237; Trygg J, 2002, J CHEMOMETR, V16, P119, DOI 10.1002/cem.695; Westad F, 2000, J NEAR INFRARED SPEC, V8, P117; Wold S, 1983, P C MATR PENC, P286; Wold S, 1998, CHEMOMETR INTELL LAB, V44, P175, DOI 10.1016/S0169-7439(98)00109-9	19	36	36	JOHN WILEY & SONS LTD	CHICHESTER	THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND	0886-9383			J CHEMOMETR	J. Chemometr.	JAN	2005	19	1					32	44		10.1002/cem.904		13	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	951AJ	WOS:000230900800005		
J	Eveland, CK; Socolinsky, DA; Priebe, CE; Marchette, DJ				Eveland, CK; Socolinsky, DA; Priebe, CE; Marchette, DJ			A hierarchical methodology for class detection problems with skewed priors	JOURNAL OF CLASSIFICATION			English	Article						classification; boosting; prototype selection; face detection		We describe a novel extension to the Class-Cover-Catch-Digraph (CCCD) classifier, specifically tuned to detection problems. These are two-class classification problems where the natural priors on the classes are skewed by several orders of magnitude. The emphasis of the proposed techniques is in computationally efficient classification for real-time applications. Our principal contribution consists of two boosted classifiers built upon the CCCD structure, one in the form of a sequential decision process and the other in the form of a tree. Both of these classifiers achieve performances comparable to that of the original CCCD classifiers, but at drastically reduced computational expense. An analysis of classification performance and computational cost is performed using data from a face detection application. Comparisons are provided with Support Vector Machines (SVM) and reduced SVMs. These comparisons show that while some SVMs may achieve higher classification performance, their computational burden can be so high as to make them unusable in real-time applications. On the other hand, the proposed classifiers combine high detection performance with extremely fast classification.	Equinox Corp, Baltimore, MD 21202 USA; Johns Hopkins Univ, Dept Math Sci, Baltimore, MD 21218 USA; USN, Ctr Surface Warfare, Dahlgren, VA 22448 USA	Eveland, CK (reprint author), Equinox Corp, 207 Redwood St,Suite 205, Baltimore, MD 21202 USA.	diego@equinoxsensors.com; cep@jhu.edu; david.marchette@navy.mil	Priebe, Carey E./A-3305-2010				Breiman L, 1998, ANN STAT, V26, P801; Burges C. J. C., 1996, P 13 INT C MACH LEAR, P71; DEVINNEY J, 2002, COMPUT SCI STAT, P34; Duda R. O., 2000, PATTERN CLASSIFICATI; Duda R. O., 1973, PATTERN CLASSIFICATI; Fleuret F, 2001, INT J COMPUT VISION, V41, P85, DOI 10.1023/A:1011113216584; Fukunaga K, 1990, INTRO STAT PATTERN R; Hastie T., 2001, ELEMENTS STAT LEARNI; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Kulkarni SR, 1998, IEEE T INFORM THEORY, V44, P2178, DOI 10.1109/18.720536; McLachlan GJ, 2000, FINITE MIXTURE MODEL; PRIEBE C, 2003, J CLASSIF, V20, P2; Ripley BD, 1996, PATTERN RECOGNITION; Scholkopf B, 1999, IEEE T NEURAL NETWOR, V10, P1000, DOI 10.1109/72.788641; Scott D. W., 1992, MULTIVARIATE DENSITY; Silverman BW, 1986, DENSITY ESTIMATION S; SOCOLINSKY DA, 2003, COMPUTING SCI STAT, V35; Vapnik V., 1998, STAT LEARNING THEORY; Viola P., 2001, C COMP VIS PATT REC, P511; Viola P., 2001, ICCV01, P747; Zuo YJ, 2000, ANN STAT, V28, P461	21	5	5	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0176-4268			J CLASSIF	J. Classif.		2005	22	1					17	48		10.1007/s00357-005-0004-9		32	Mathematics, Interdisciplinary Applications; Psychology, Mathematical	Mathematics; Psychology	938UF	WOS:000230028200003		
J	Szekely, GJ; Rizzo, ML				Szekely, GJ; Rizzo, ML			Hierarchical clustering via joint between-within distances: Extending Ward's minimum variance method	JOURNAL OF CLASSIFICATION			English	Article						cluster analysis; hierarchical classification; Ward's minimum variance method	ALGORITHMS	We propose a hierarchical clustering method that minimizes a joint between-within measure of distance between clusters. This method extends Ward's minimum variance method, by defining a cluster distance and objective function in terms of Euclidean distance, or any power of Euclidean distance in the interval (0,2]. Ward's method is obtained as the special case when the power is 2. The ability of the proposed extension to identify clusters with nearly equal centers is an important advantage over geometric or cluster center methods. The between-within distance statistic determines a clustering method that is ultrametric and space.-dilating; and for powers strictly less than 2, determines a consistent test of homogeneity and a consistent clustering procedure. The clustering procedure is applied to three problems: classification of tumors by microarray gene expression data, classification of dermatology diseases by clinical and histopathological attributes, and classification of simulated multivariate normal data.	Bowling Green State Univ, Dept Math & Stat, Bowling Green, OH 43403 USA; Ohio Univ, Dept Math, Athens, OH 45701 USA	Szekely, GJ (reprint author), Bowling Green State Univ, Dept Math & Stat, Bowling Green, OH 43403 USA.	gabors@bgnet.bgsu.edu; rizzo@math.ohiou.edu					Anderberg M. R., 1973, CLUSTER ANAL APPL; Benzecri J.-P., 1992, CORRESPONDENCE ANAL; Blake C.L., 1998, UCI REPOSITORY MACHI; Breiman L., 1996, 460 U CAL STAT DEP; Chen ZM, 1996, J CLASSIF, V13, P157, DOI 10.1007/BF01202586; CORMACK RM, 1971, J R STAT SOC SER A-G, V134, P321, DOI 10.2307/2344237; DUBIEN JL, 1979, CANAD J STAT, V7, P29, DOI 10.2307/3315012; DUDOIT S, 2000, 576 U CAL DEP STAT; EVERITT BS, 1979, BIOMETRICS, V35, P169, DOI 10.2307/2529943; Everitt BS, 2001, CLUSTER ANAL; Gordon A. D., 1999, CLASSIFICATION; Guvenir HA, 1998, ARTIF INTELL MED, V13, P147, DOI 10.1016/S0933-3657(98)00028-1; HARTIGAN JA, 1985, J CLASSIF, V2, P67; HARTIGAN JA, 1967, J AM STAT ASSOC, V62, P1140, DOI 10.2307/2283766; Hartigan J.A., 1975, CLUSTERING ALGORITHM; Hastie T., 2001, ELEMENTS STAT LEARNI; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Jain A, 1988, ALGORITHMS CLUSTERIN; JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588; Kaufman L., 1990, FINDING GROUPS DATA; LANCE GN, 1967, COMPUT J, V9, P373; LEISCH F, 2004, ORIGINAL DATA SETS V; MILLIGAN GW, 1979, PSYCHOMETRIKA, V44, P343, DOI 10.1007/BF02294699; MILLIGAN GW, 1980, PATTERN RECOGN, V12, P41, DOI 10.1016/0031-3203(80)90001-1; MORGAN BJT, 1995, APPL STAT-J ROY ST C, V44, P117, DOI 10.2307/2986199; Murtagh F., 1985, COMPSTAT LECT, V4; Prudnikov A. P., 1986, INTEGRALS SERIES; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; Spath H., 1980, CLUSTER ANAL ALGORIT; TIBSHIRANI R, 1999, CLUSTERING METHODS A; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967	32	40	42	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0176-4268			J CLASSIF	J. Classif.		2005	22	2					151	183		10.1007/s00357-005-0012-9		33	Mathematics, Interdisciplinary Applications; Psychology, Mathematical	Mathematics; Psychology	993EW	WOS:000233938400001		
J	Skowron, A; Stepaniuk, J				Skowron, A; Stepaniuk, J			Hierarchical modelling in searching for complex patterns: constrained sums of information systems	JOURNAL OF EXPERIMENTAL & THEORETICAL ARTIFICIAL INTELLIGENCE			English	Article						rough sets; information granules; concept approximation; hierarchichal modelling; informorphisms; information nets		This paper outlines an approach to hierarchical modelling of complex patterns that is based on operations of sums with constraints on information systems. It is shown that such operations can be treated as a universal tool in hierarchical modelling of complex patterns.	Warsaw Univ, Inst Math, PL-02097 Warsaw, Poland; Bialystok Tech Univ, Dept Comp Sci, PL-15351 Bialystok, Poland	Skowron, A (reprint author), Warsaw Univ, Inst Math, Banacha 2, PL-02097 Warsaw, Poland.	skowron@mimuw.edu.pl					BARWISE J, 1997, INFORMATION FLOW LOG, P44; Bazan J., 1998, ROUGH SETS KNOWLEDGE, V1, P321; BAZAN J, 2004, 4 INT C ROUGH SETS C, P346; Bazan J.G., 2000, ROUGH SET METHODS AP, P49; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Friedman J., 2001, ELEMENTS STAT LEARNI; Garcia-Molina H, 2002, DATABASE SYSTEMS COM; Kloesgen Willi, 2002, HDB KNOWLEDGE DISCOV; LUKASIEWICZ J, 1913, J LUKASIEWICZ SELECT; Nguyen H. S., 1998, ROUGH SETS KNOWLEDGE, V1, P451; NGUYEN HS, 1998, FUNDAMENTA INFORMATI, V34, P129; Nguyen SH, 1997, LECT NOTES ARTIF INT, V1263, P265; Nguyen S.H., 1998, ROUGH SETS KNOWLEDGE, P55; Nguyen SH, 2000, STUD FUZZ SOFT COMP, V56, P289; Pal S.K., 2004, ROUGH NEURAL COMPUTI; Pawlak Z., 1991, ROUGH SETS THEORETIC; PETERS JF, 2003, 10 INT FUZZ SYST ASS, P370; Poggio T., 2003, NOTICES AMS, V50, P537; Polkowski L, 1996, INT J APPROX REASON, V15, P333, DOI 10.1016/S0888-613X(96)00072-2; POLKOWSKI L, 1999, COMPUTING WORDS INFO, V1, P201; Skowron A, 2003, FUND INFORM, V54, P263; SKOWRON A, 2004, ROUGH NEURAL COMPUTI, P43; Skowron A, 2001, INT J INTELL SYST, V16, P57, DOI 10.1002/1098-111X(200101)16:1<57::AID-INT6>3.0.CO;2-Y; Skowron A., 1996, Fundamenta Informaticae, V27; STEPANIUK J, 2000, ROUGH SET METHODS AP, P137; Stone P., 2000, LAYERED LEARNING MUL; Vapnik V., 1998, STAT LEARNING THEORY; Zadeh L. A., 1965, INFORM CONTR, V8, P333; Zadeh L. A., 1999, COMPUTING WORDS INFO, V1; Zadeh LA, 1997, FUZZY SET SYST, V90, P111, DOI 10.1016/S0165-0114(97)00077-8; Zadeh LA, 2001, AI MAG, V22, P73	31	5	5	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0952-813X			J EXP THEOR ARTIF IN	J. Exp. Theor. Artif. Intell.	JAN-JUN	2005	17	1-2					83	102		10.1080/09528130512331315873		20	Computer Science, Artificial Intelligence	Computer Science	896KH	WOS:000226932500007		
J	Feng, CXJ; Yu, ZG; Kingi, U; Baig, MP				Feng, Chang-Xue Jack; Yu, Zhi-Guang (Samuel); Kingi, Unnati; Baig, M. Pervaiz			Threefold vs. fivefold cross validation in one-hidden-layer and two-hidden-layer predictive neural network modeling of machining surface roughness data	JOURNAL OF MANUFACTURING SYSTEMS			English	Article						data mining; cross validation; neural networks; predictive modeling; machining surface roughness; ISO 13565	LEARNING-TESTING METHODS; VARIABLE SELECTION; REGRESSION; ERROR; VARIANCE; CHOICE; BIAS	Predictability of a manufacturing process or system is vital in virtual manufacturing. Various data mining techniques are available in developing predictive models. Cross validation is critical in determining the quality of a predictive model and the costs in data collection and data mining. Several cross-validation (CV) techniques are available, including the v-fold CV, leave-one-out CV, and the bootstrap type of CV. Some past studies have not revealed any statistical advantages of using tenfold cross validation over fivefold cross validation. Determining the number of hidden layers is important in predictive modeling with neural networks. This study attempts to compare the performance of fivefold over threefold CV and that of one-hidden-layer over two-hidden-layer neural nets in predictive modeling for surface roughness parameters defined in ISO 13565 for turning and honing. Statistical hypothesis tests and different prediction errors are employed to compare the competitive models. This study does not reveal any significant statistical advantages of using fivefold CV over threefold CV and of using two-hidden-layer neural nets over one-hidden-layer neural nets for the cases under study. Furthermore, the procedure presented here is applicable in comparing competitive data modeling or data mining methods.	Bradley Univ, Dept Ind & Mfg Engn & Technol, Peoria, IL 61625 USA	Feng, CXJ (reprint author), Bradley Univ, Dept Ind & Mfg Engn & Technol, Peoria, IL 61625 USA.	cfeng@bradley.edu					ALLEN DM, 1974, TECHNOMETRICS, V16, P125, DOI 10.2307/1267500; [Anonymous], 1996, 135652 ISO; BISHOP C.M., 1995, NEURAL NETWORKS PATT; BOUNDS DG, 1988, P 2 IEEE ANN INT C N; Box G., 1987, EMPIRICAL MODEL BUIL; BREIMAN L, 1992, INT STAT REV, V60, P291, DOI 10.2307/1403680; BREIMAN L, 1992, J AM STAT ASSOC, V87, P738, DOI 10.2307/2290212; BURKE L, 1993, PC AI            MAR, P20; BURMAN P, 1989, BIOMETRIKA, V76, P503, DOI 10.1093/biomet/76.3.503; BURMAN P, 1990, SANKHYA SER A, V52, P314; Chester D. L., 1990, P INT JOINT C NEUR N, P265; Coit DW, 1998, INT J PROD RES, V36, P2953, DOI 10.1080/002075498192229; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; FENG CX, 2003, T NAMRI SME, V31, P467; Feng CX, 2003, IIE TRANS, V35, P11, DOI 10.1080/07408170390116634; Feng CX, 2002, J MANUF SYST, V21, P419, DOI 10.1016/S0278-6125(02)80049-8; Feng CX, 2002, J MANUF SYST, V21, P395, DOI 10.1016/S0278-6125(02)80037-1; Feng CXJ, 2004, IIE TRANS, V36, P253, DOI 10.1080/07408170490274214; Feng CXJ, 2006, IIE TRANS, V38, P13, DOI 10.1080/07408170500346378; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; George EI, 2000, J AM STAT ASSOC, V95, P1304, DOI 10.2307/2669776; Gershenfeld N., 1999, NATURE MATH MODELING; GOX GEP, 2005, STAT EXPT DESIGN INN; GROTH R, 1998, DATA MINING HANDS AP; Hastie T., 2001, ELEMENTS STAT LEARNI; Ingrassia S, 2005, TECHNOMETRICS, V47, P297, DOI 10.1198/004017005000000058; Kolen J. F., 1990, Complex Systems, V4; Kusiak A., 2000, COMPUTATIONAL INTELL; Lawrence J., 1994, INTRO NEURAL NETWORK; Lawrence J., 1998, BRAINMAKER USERS GUI; LI KC, 1987, ANN STAT, V15, P958, DOI 10.1214/aos/1176350486; Marchandani G, 1989, IEEE T CIRCUITS SYST, V36, P661; *MIN INC, 2000, MIN REL 13 US MAN; Mitchell T., 1997, MACHINE LEARNING; Montgomery DC, 2005, DESIGN ANAL EXPT; Montgomery D.C., 2003, APPL STAT PROBABILIT, V3; SHAO J, 1993, J AM STAT ASSOC, V88, P486, DOI 10.2307/2290328; SNEE RD, 1977, TECHNOMETRICS, V19, P415, DOI 10.2307/1267881; STONE M, 1977, J R STAT SOC B, V39, P44; STONE M, 1974, J R STAT SOC B, V36, P111; Swingler K., 1996, APPL NEURAL NETWORKS; Tibshirani R, 1996, NEURAL COMPUT, V8, P152, DOI 10.1162/neco.1996.8.1.152; Tibshirani R. J., 1998, INTRO BOOTSTRAP; Twomey JM, 1998, IEEE T SYST MAN CY C, V28, P417, DOI 10.1109/5326.704579; Wasserman P.D., 1989, NEURAL COMPUTING; Witten IH, 2000, DATA MINING PRACTICA; WU CFJ, 1998, EXPT PLANNING ANAL P; YU ZG, 2003, THESIS BRADLEY U PEO; ZHANG P, 1993, ANN STAT, V21, P299, DOI 10.1214/aos/1176349027; Zhu HY, 1996, NEURAL COMPUT, V8, P1421, DOI 10.1162/neco.1996.8.7.1421	51	9	9	SOC MANUFACTURING ENGINEERS	DEARBORN	ONE SME DRIVE, PO BOX 930, DEARBORN, MI 48121-0930 USA	0278-6125			J MANUF SYST	J. Manuf. Syst.		2005	24	2					93	107				15	Engineering, Industrial; Engineering, Manufacturing; Operations Research & Management Science	Engineering; Operations Research & Management Science	061VR	WOS:000238901600003		
J	Sahni, NS; Aastveit, AH; Naes, T				Sahni, NS; Aastveit, AH; Naes, T			In-line process and product control using spectroscopy and multivariate calibration	JOURNAL OF QUALITY TECHNOLOGY			English	Article						in-line Spectroscopy; longitudinal response data; mixture-process variable design; multivariate statistical process control; split-plot designs	PROCESS VARIABLES; DESIGN	The quality of a product is dynamic in nature and develops over time. We present a case study from the food industry in which the concept of measuring the end-product quality is extended to incorporate the shelf-life period of the product with practical examples showing the harm of ignoring the changes that occur in the product quality as a function of time. The article also addresses the use of in-line spectroscopy to relate the variations in the input parameters, such as the raw materials, and the process variables to the final product quality over the entire shelf-life of the product. We also discuss multivariate statistical process control and monitoring issues.	Mills DA, Res & Dev, N-0506 Oslo, Norway; Agr Univ Norway, Dept Chem Biotechnol & Food Sci, N-1432 As, Norway; Norwegian Food Res Inst, MATFORSK, N-1400 As, Norway	Sahni, NS (reprint author), Mills DA, Res & Dev, Sofienberggt 19,POB 4644 Sof, N-0506 Oslo, Norway.	naes@matforsk.no					CORNELL JA, 1988, J QUAL TECHNOL, V20, P2; Cornell J.A., 1990, EXPT MIXTURES DESIGN; Diggle P. J., 1996, ANAL LONGITUDINAL DA; GELADI P, 1986, ANAL CHIM ACTA, V185, P1, DOI 10.1016/0003-2670(86)80028-9; Hall P, 2001, TECHNOMETRICS, V43, P1, DOI 10.1198/00401700152404273; Hastie T., 2001, ELEMENTS STAT LEARNI; Indahl UG, 1999, CHEMOMETR INTELL LAB, V49, P19, DOI 10.1016/S0169-7439(99)00023-4; Jackson JE, 1991, USERS GUIDE PRINCIPL; JOHNSON DE, 1972, J AM STAT ASSOC, V67, P862, DOI 10.2307/2284651; Kourti T, 1996, J QUAL TECHNOL, V28, P409; KOWALSKI BR, 1991, J CHEMOMETR, V5, P129, DOI 10.1002/cem.1180050303; LORENZEN JT, 1993, DESIGN EXPT NONAME A; MACGREGOR JF, 1994, IFAC ADV CONTROL CHE; Martens H., 1989, MULTIVARIATE CALIBRA; Milliken G. A., 1989, ANAL MESSY DATA, V2; Naes T, 1998, CHEMOMETR INTELL LAB, V41, P221, DOI 10.1016/S0169-7439(98)00056-2; NAES T, 1996, DATA HANDLING SCI TE, V16, P135; Nair VN, 2002, J QUAL TECHNOL, V34, P355; Osborne B. G., 1993, PRACTICAL NIR SPECTR; Sahni NS, 2004, J NEAR INFRARED SPEC, V12, P77; Sahni NS, 2001, CHEMOMETR INTELL LAB, V56, P105, DOI 10.1016/S0169-7439(01)00113-7; Williams P., 1987, NEAR INFRARED TECHNO; Woodall WH, 2004, J QUAL TECHNOL, V36, P309; Wurl RC, 2001, QUAL RELIAB ENG INT, V17, P269, DOI 10.1002/qre.401	24	7	9	AMER SOC QUALITY CONTROL-ASQC	MILWAUKEE	600 N PLANKINTON AVE, MILWAUKEE, WI 53203 USA	0022-4065			J QUAL TECHNOL	J. Qual. Technol.	JAN	2005	37	1					1	20				20	Engineering, Industrial; Operations Research & Management Science; Statistics & Probability	Engineering; Operations Research & Management Science; Mathematics	882EN	WOS:000225921800001		
J	Tibshirani, R; Saunders, M; Rosset, S; Zhu, J; Knight, K				Tibshirani, R; Saunders, M; Rosset, S; Zhu, J; Knight, K			Sparsity and smoothness via the fused lasso	JOURNAL OF THE ROYAL STATISTICAL SOCIETY SERIES B-STATISTICAL METHODOLOGY			English	Article						fused lasso; gene expression; lasso; least squares regression; protein mass spectroscopy; sparse solutions; support vector classifier	GENE-EXPRESSION; CANCER; REGRESSION; SHRINKAGE	The lasso penalizes a least squares regression by the sum of the absolute values (L-1-norm) of the coefficients. The form of this penalty encourages sparse solutions (with many coefficients equal to 0). We propose the 'fused lasso', a generalization that is designed for problems with features that can be ordered in some meaningful way. The fused lasso penalizes the L-1-norm of both the coefficients and their successive differences. Thus it encourages sparsity of the coefficients and also sparsity of their differences-i.e. local constancy of the coefficient profile. The fused lasso is especially useful when the number of features p is much greater than N, the sample size. The technique is also extended to the 'hinge' loss function that underlies the support vector classifier. We illustrate the methods on examples from protein mass spectroscopy and gene expression data.	Stanford Univ, Dept Hlth Res & Policy, Stanford, CA 94305 USA; IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA; Univ Michigan, Ann Arbor, MI 48109 USA; Univ Toronto, Toronto, ON, Canada	Tibshirani, R (reprint author), Stanford Univ, Dept Hlth Res & Policy, HRP Redwood Bldg, Stanford, CA 94305 USA.	tibs@stat.stanford.edu					ADAM B.L, 2003, CANCER RES, V63, P3609; BOSER B, 1992, P COMPUTATIONAL LEAR, V2; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S003614450037906X; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; EFRON B, 2002, LEAST ANGLE REGRESSI; GEYER CJ, 1996, ASYMPTOTICS CONVEX S; GILL PE, 1997, 974 NA U CAL; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hastie T., 2001, ELEMENTS STAT LEARNI; HOERL AE, 1970, TECHNOMETRICS, V12, P55; Knight K, 2000, ANN STAT, V28, P1356; Land S. R., 1996, VARIABLE FUSION NEW; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; ROSSET S, 2003, ADAPTABLE EFFICIENT; Rosset S, 2004, J MACH LEARN RES, V5, P941; STEIN C, 1981, ANN STAT, V9, P1131; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; TIBSHIRANI R, 2004, SPARSITY SMOOTHNESS; Vapnik VN, 1996, NATURE STAT LEARNING; Wold H, 1975, PERSPECTIVES PROBABI, P117; Yoonkyung Lee, 2002, MULTICATEGORY SUPPOR; ZHU J, 2003, L1 NORM SUPPORT VECT	23	277	281	BLACKWELL PUBL LTD	OXFORD	108 COWLEY RD, OXFORD OX4 1JF, OXON, ENGLAND	1369-7412			J ROY STAT SOC B	J. R. Stat. Soc. Ser. B-Stat. Methodol.		2005	67		1				91	108		10.1111/j.1467-9868.2005.00490.x		18	Statistics & Probability	Mathematics	878ZT	WOS:000225686900006		
J	Zou, H; Hastie, T				Zou, H; Hastie, T			Regularization and variable selection via the elastic net	JOURNAL OF THE ROYAL STATISTICAL SOCIETY SERIES B-STATISTICAL METHODOLOGY			English	Article						grouping effect; LARS algorithm; Lasso; penalization; p >> n problem; variable selection	GENE-EXPRESSION; MICROARRAY DATA; REGRESSION; CANCER; CLASSIFICATION; SHRINKAGE; LASSO	We propose the elastic net, a new regularization and variable selection method. Real world data and a simulation study show that the elastic net often outperforms the lasso, while enjoying a similar sparsity of representation. In addition, the elastic net encourages a grouping effect, where strongly correlated predictors tend to be in or out of the model together. The elastic net is particularly useful when the number of predictors (p) is much bigger than the number of observations (n). By contrast, the lasso is not a very satisfactory variable selection method in the p>n case. An algorithm called LARS-EN is proposed for computing elastic net regularization paths efficiently, much like algorithm LARS does for the lasso.	Stanford Univ, Dept Stat, Stanford, CA 94305 USA	Hastie, T (reprint author), Stanford Univ, Dept Stat, Stanford, CA 94305 USA.	hastie@stanford.edu					Breiman L, 1996, ANN STAT, V24, P2350; Dettling M, 2004, J MULTIVARIATE ANAL, V90, P106, DOI 10.1016/j.jmva.2004.02.012; DIAZURIARTE R, 2003, SIMPLE METHOD FINDIN; DONOHO DL, 1995, J ROY STAT SOC B MET, V57, P301; Efron B, 2004, ANN STAT, V32, P407; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; FRIEDMAN J, 1989, J AM STAT ASSOC, V84, P249; Friedman J, 2004, ANN STAT, V32, P102; Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Golub G. H., 1983, MATRIX COMPUTATIONS; Golub T., 1999, SCIENCE, V286, P513; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; HASTIE T, 2003, GENOME BIOL, V2; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T, 2000, GENOME BIOL, V1, P1, DOI DOI 10.1186/GB-2000-1-2-RESEARCH0003; Hoerl A., 1988, ENCY STAT SCI, V8, P129; Rosset S, 2004, J MACH LEARN RES, V5, P941; Segal MR, 2003, J COMPUT BIOL, V10, P961, DOI 10.1089/106652703322756177; Stamey T., 1989, J UROLOGY, V16, P1076; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; West M, 2001, P NATL ACAD SCI USA, V98, P11462, DOI 10.1073/pnas.201162998; Zhang T., 2004, ANN STAT, V32, P469; Zhu J, 2004, BIOSTATISTICS, V5, P427, DOI 10.1093/biostatistics/kxg046	26	1255	1293	BLACKWELL PUBL LTD	OXFORD	108 COWLEY RD, OXFORD OX4 1JF, OXON, ENGLAND	1369-7412			J ROY STAT SOC B	J. R. Stat. Soc. Ser. B-Stat. Methodol.		2005	67		2				301	320		10.1111/j.1467-9868.2005.00503.x		20	Statistics & Probability	Mathematics	904KZ	WOS:000227498200007		
J	Verzilli, CJ; Whittaker, JC; Stallard, N; Chasman, D				Verzilli, CJ; Whittaker, JC; Stallard, N; Chasman, D			A hierarchical Bayesian model for predicting the functional consequences of amino-acid polymorphisms	JOURNAL OF THE ROYAL STATISTICAL SOCIETY SERIES C-APPLIED STATISTICS			English	Article						Bayesian inference; hierarchical model; multivariate adaptive regression splines; protein site-directed mutagenesis; supervised learning	SINGLE-NUCLEOTIDE POLYMORPHISMS; PROTEIN; MUTATION; DISEASE; REGRESSION; SEQUENCE; RESIDUES; DOMAIN; MARS	Genetic polymorphisms in deoxyribonucleic acid coding regions may have a phenotypic effect on the carrier, e.g. by influencing susceptibility to disease. Detection of deleterious mutations via association studies is hampered by the large number of candidate sites; therefore methods are needed to narrow down the search to the most promising sites. For this, a possible approach is to use structural and sequence-based information of the encoded protein to predict whether a mutation at a particular site is likely to disrupt the functionality of the protein itself. We propose a hierarchical Bayesian multivariate adaptive regression spline (BMARS) model for supervised learning in this context and assess its predictive performance by using data from mutagenesis experiments on lac repressor and lysozyme proteins. In these experiments, about 12 amino-acid substitutions were performed at each native amino-acid position and the effect on protein functionality was assessed. The training data thus consist of repeated observations at each position, which the hierarchical framework is needed to account for. The model is trained on the lac repressor data and tested on the lysozyme mutations and vice versa. In particular, we show that the hierarchical BMARS model, by allowing for the clustered nature of the data, yields lower out-of-sample misclassification rates compared with both a BMARS and a frequen-tist MARS model, a support vector machine classifier and an optimally pruned classification tree.	Univ London Imperial Coll Sci & Technol, Dept Epidemiol & Publ Hlth, London W2 1PG, England; Univ Reading, Reading RG6 2AH, Berks, England; Variagenics, Cambridge, MA USA	Whittaker, JC (reprint author), Univ London Imperial Coll Sci & Technol, Dept Epidemiol & Publ Hlth, St Marys Campus,Norfolk Pl, London W2 1PG, England.	j.whittaker@imperial.ac.uk					Adams RM, 1996, PROTEIN SCI, V5, P1240; Albert J, 1996, BAYESIAN BIOSTATISTI, P577; Cargill M, 1999, NAT GENET, V22, P231; Caronia G, 2003, DEVELOPMENT, V130, P1701, DOI 10.1242/dev.00396; Chasman D, 2001, J MOL BIOL, V307, P683, DOI 10.1006/jmbi.2001.4510; Mesa AD, 2003, J MOL BIOL, V326, P1289, DOI 10.1016/S0022-2836(02)01451-1; Denison D. G. T., 2002, BAYESIAN METHODS NON; Denison DGT, 1998, STAT COMPUT, V8, P337, DOI 10.1023/A:1008824606259; Duga S, 2003, BLOOD, V101, P173, DOI 10.1182/blood-2002-06-1928; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711; Gunther J, 2003, J MOL BIOL, V326, P621, DOI 10.1016/S0022-2836(02)01409-2; Hastie T., 2001, ELEMENTS STAT LEARNI; HOLMES C, 2003, BAYESIAN AUXILIARY V; Holmes CC, 2003, MACH LEARN, V50, P159, DOI 10.1023/A:1020254013004; Kooperberg C, 1997, J AM STAT ASSOC, V92, P117, DOI 10.2307/2291455; Lesk A. M., 1999, INTRO PROTEIN ARCHIT; MADIGAN D, 1994, J AM STAT ASSOC, V89, P1535, DOI 10.2307/2291017; MARKIEWICZ P, 1994, J MOL BIOL, V240, P421, DOI 10.1006/jmbi.1994.1458; Ng PC, 2002, GENOME RES, V12, P436, DOI 10.1101/gr/212802; Pilz DT, 1999, HUM MOL GENET, V8, P1757, DOI 10.1093/hmg/8.9.1757; Platt JC, 2000, ADV NEUR IN, P61; R Development Core Team, 2004, R LANG ENV STAT COMP; RENNELL D, 1991, J MOL BIOL, V222, P67, DOI 10.1016/0022-2836(91)90738-R; Richardson S, 1997, J ROY STAT SOC B MET, V59, P731, DOI 10.1111/1467-9868.00095; SANDER C, 1991, PROTEINS, V9, P56, DOI 10.1002/prot.340090107; Saunders CT, 2002, J MOL BIOL, V322, P891, DOI 10.1016/S0022-2836(02)00813-6; Stitziel NO, 2003, J MOL BIOL, V327, P1021, DOI 10.1016/S0022-2836(03)00240-7; Sunyaev S, 2001, HUM MOL GENET, V10, P591, DOI 10.1093/hmg/10.6.591; Sunyaev S, 2000, TRENDS GENET, V16, P198, DOI 10.1016/S0168-9525(00)01988-0; Terp BN, 2002, HUM MUTAT, V20, P98, DOI 10.1002/humu.10095; TIERNEY L, 1994, ANN STAT, V22, P1701, DOI 10.1214/aos/1176325750; Wang Z, 2001, HUM MUTAT, V17, P263, DOI 10.1002/humu.22	34	15	15	BLACKWELL PUBL LTD	OXFORD	108 COWLEY RD, OXFORD OX4 1JF, OXON, ENGLAND	0035-9254			J ROY STAT SOC C-APP	J. R. Stat. Soc. Ser. C-Appl. Stat.	JAN	2005	54		1				191	206		10.1111/j.1467-9876.2005.00478.x		16	Statistics & Probability	Mathematics	864PL	WOS:000224645300013		
J	Rigby, RA; Stasinopoulos, DM				Rigby, RA; Stasinopoulos, DM			Generalized additive models for location, scale and shape	JOURNAL OF THE ROYAL STATISTICAL SOCIETY SERIES C-APPLIED STATISTICS			English	Article						beta-binomial distribution; Box-Cox transformation; centile estimation; cubic smoothing splines; generalized linear mixed model; LMS method; negative binomial distribution; non-normality; nonparametric models; overdispersion; penalized likelihood; random effects; skewness and kurtosis	LINEAR MIXED MODELS; BODY-MASS INDEX; INFORMATION CRITERION; PENALIZED LIKELIHOOD; SMOOTHING PARAMETER; CROSS-VALIDATION; CENTILE CURVES; BAYES FACTORS; INFERENCE; UNCERTAINTY	A general class of statistical models for a univariate response variable is presented which we call the generalized additive model for location, scale and shape (GAMLSS). The model assumes independent observations of the response variable y given the parameters, the explanatory variables and the values of the random effects. The distribution for the response variable in the GAMLSS can be selected from a very general family of distributions including highly skew or kurtotic continuous and discrete distributions. The systematic part of the model is expanded to allow modelling not only of the mean (or location) but also of the other parameters of the distribution of y, as parametric and/or additive nonparametric (smooth) functions of explanatory variables and/or random-effects terms. Maximum (penalized) likelihood estimation is used to fit the (non)parametric models. A Newton-Raphson or Fisher scoring algorithm is used to maximize the (penalized) likelihood. The additive terms in the model are fitted by using a backfitting algorithm. Censored data are easily incorporated into the framework. Five data sets from different fields of application are analysed to emphasize the generality of the GAMLSS class of models.	London Metropolitan Univ, Stat OR & Math STORM Res Ctr, London N7 8DB, England	Rigby, RA (reprint author), London Metropolitan Univ, Stat OR & Math STORM Res Ctr, 166-220 Holloway Rd, London N7 8DB, England.	r.rigby@londonmet.ac.uk					Aitkin M, 1999, BIOMETRICS, V55, P117, DOI 10.1111/j.0006-341X.1999.00117.x; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Akaike H., 1983, B INT STAT I, V50, P277; Benjamin MA, 2003, J AM STAT ASSOC, V98, P214, DOI 10.1198/S016214503388619238; Berger JO, 1985, STAT DECISION THEORY; BESAG J, 1991, ANN I STAT MATH, V43, P1, DOI 10.1007/BF00116466; Besag J, 1999, J ROY STAT SOC B, V61, P691, DOI 10.1111/1467-9868.00201; Box G., 1973, BAYESIAN INFERENCE S; BOX GEP, 1964, J ROY STAT SOC B, V26, P211; BRESLOW NE, 1993, J AM STAT ASSOC, V88, P9, DOI 10.2307/2290687; BRESLOW NE, 1995, BIOMETRIKA, V82, P81; Claeskens G, 2003, J AM STAT ASSOC, V98, P900, DOI 10.1198/016214503000000819; Hjort NL, 2003, J AM STAT ASSOC, V98, P879, DOI 10.1198/016214503000000828; Cleveland W. S., 1993, STAT MODELS S, P309; Cole TJ, 1999, ANN HUM BIOL, V26, P303; Cole TJ, 1998, STAT MED, V17, P407, DOI 10.1002/(SICI)1097-0258(19980228)17:4<407::AID-SIM742>3.0.CO;2-L; COLE TJ, 1992, STAT MED, V11, P1305, DOI 10.1002/sim.4780111005; Cook RD, 2000, STAT SCI, V15, P213; COX DR, 1987, J ROY STAT SOC B MET, V49, P1; CRISP A, 1994, BIOMETRIKA, V81, P585; *CYTEL SOFTW CORP, 2001, EGRET WIND; de Boor C., 1978, PRACTICAL GUIDE SPLI; Diggle PJ, 2002, ANAL LONGITUDINAL DA; DRAPER D, 1995, J R STAT SOC B, V57, P45; Dunn P. K., 1996, J COMPUTATIONAL GRAP, V5, P236, DOI DOI 10.2307/1390802; Eilers PHC, 1996, STAT SCI, V11, P89, DOI 10.1214/ss/1038425655; Fahrmeir L, 2001, MULTIVARIATE STAT MO; Fahrmeir L, 2001, J ROY STAT SOC C-APP, V50, P201, DOI 10.1111/1467-9876.00229; Gange SJ, 1996, APPL STAT-J ROY ST C, V45, P371, DOI 10.2307/2986094; GREEN PJ, 1985, BIOMETRIKA, V72, P527; Green PJ, 1994, NONPARAMETRIC REGRES; Harvey A.C., 1989, FORECASTING STRUCTUR; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T, 1990, GEN ADDITIVE MODELS; HASTIE T, 1993, J ROY STAT SOC B MET, V55, P757; Hodges JS, 2001, BIOMETRIKA, V88, P367, DOI 10.1093/biomet/88.2.367; Hodges JS, 1998, J ROY STAT SOC B, V60, P497, DOI 10.1111/1467-9868.00137; Ihaka R, 2005, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Johnson N. L., 1994, CONTINUOUS UNIVARIAT, V1; Johnson NL, 1995, CONTINUOUS UNIVARIAT, V2; JOHNSON NL, 1949, BIOMETRIKA, V36, P149, DOI 10.2307/2332539; Johnson NL, 1993, UNIVARIATE DISCRETE; KOHN R, 1998, BAYESIAN ANAL TIME S, P393; KOHN R, 1991, J AM STAT ASSOC, V86, P1042, DOI 10.2307/2290523; Lange K., 1999, NUMERICAL ANAL STAT; LANGE KL, 1989, J AM STAT ASSOC, V84, P881, DOI 10.2307/2290063; Lee Y, 2001, BIOMETRIKA, V88, P987, DOI 10.1093/biomet/88.4.987; Lee Y, 1996, J ROY STAT SOC B MET, V58, P619; Lee Y., 2001, STAT MODEL, V1, P3, DOI 10.1191/147108201128050; LEE Y, 2000, APPL STAT, V49, P591; Lin XH, 1999, J ROY STAT SOC B, V61, P381, DOI 10.1111/1467-9868.00183; LOPATATZIDIS A, 2000, IN PRESS NONPARAMETR; MADIGAN D, 1994, J AM STAT ASSOC, V89, P1535, DOI 10.2307/2291017; McCulloch CE, 1997, J AM STAT ASSOC, V92, P162, DOI 10.2307/2291460; NELDER JA, 1972, J R STAT SOC SER A-G, V135, P370, DOI 10.2307/2344614; NELSON DB, 1991, ECONOMETRICA, V59, P347, DOI 10.2307/2938260; Ortega J.M., 1970, ITERATIVE SOLUTION N; Pawitan Y., 2001, ALL LIKELIHOOD STAT; Raftery AE, 1996, BIOMETRIKA, V83, P251, DOI 10.1093/biomet/83.2.251; REINSCH CH, 1967, NUMER MATH, V10, P177, DOI 10.1007/BF02162161; Rigby RA, 1996, STAT THEORY COMPUTAT, P215; RIGBY RA, 2004, 0104 LOND METR U STO; Rigby RA, 2004, STAT MED, V23, P3053, DOI 10.1002/sim.1861; Rigby RA, 1996, STAT COMPUT, V6, P57, DOI 10.1007/BF00161574; Ripley BD, 1996, PATTERN RECOGNITION; ROYSTON P, 1994, APPL STAT-J ROY ST C, V43, P429, DOI 10.2307/2986270; Schumaker L. L., 1993, SPLINE FUNCTIONS BAS; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SILVERMAN BW, 1985, J R STAT SOC B, V47, P1; SMITH PL, 1979, AM STAT, V33, P57, DOI 10.2307/2683222; Speed TP, 1991, STAT SCI, V6, P42, DOI 10.1214/ss/1177011930; STASINOPOULOS DM, 1992, COMPUT STAT DATA AN, V13, P461, DOI 10.1016/0167-9473(92)90119-Z; STASINOPOULOS DM, 2000, STATISTICIAN, V49, P479; STASINOPOULOS DM, 2004, 0204 LOND METR U STO; THALL PF, 1990, BIOMETRICS, V46, P657, DOI 10.2307/2532086; TIERNEY L, 1986, J AM STAT ASSOC, V81, P82, DOI 10.2307/2287970; Tong H., 1990, NONLINEAR TIME SERIE; Verbyla A.P., 1997, APPL STAT, V48, P269, DOI DOI 10.1111/1467-9876.00154; WAHBA G, 1978, J ROY STAT SOC B MET, V40, P364; WAHBA G, 1985, ANN STAT, V13, P1378, DOI 10.1214/aos/1176349743; Wood S. N., 2001, R NEWS, V1, P20; Wood SN, 2000, J ROY STAT SOC B, V62, P413, DOI 10.1111/1467-9868.00240; Raftery AE, 1999, SOCIOL METHOD RES, V27, P411, DOI 10.1177/0049124199027003005; ZEGER SL, 1991, J AM STAT ASSOC, V86, P79, DOI 10.2307/2289717	84	242	246	BLACKWELL PUBL LTD	OXFORD	108 COWLEY RD, OXFORD OX4 1JF, OXON, ENGLAND	0035-9254			J ROY STAT SOC C-APP	J. R. Stat. Soc. Ser. C-Appl. Stat.		2005	54		3				507	544		10.1111/j.1467-9876.2005.00510.x		38	Statistics & Probability	Mathematics	915UJ	WOS:000228336500003		
J	Whittaker, J; Whitehead, C; Somers, M				Whittaker, J; Whitehead, C; Somers, M			The neglog transformation and quantile regression for the analysis of a large credit scoring database	JOURNAL OF THE ROYAL STATISTICAL SOCIETY SERIES C-APPLIED STATISTICS			English	Article						collections; large data sets; missed payment database; profit scoring; training sample; validation sample; Yeo-Johnson power transformation		A statistical analysis of a bank's credit card database is presented. The database is a snapshot of accounts whose holders have missed a payment on a given month but who do not subsequently default. The variables on which there is information are observable measures on the account (such as profit and activity), and whether actions that are available to the bank (such as letters and telephone calls) have been taken. A primary objective for the bank is to gain insight into the effect that collections activity has on on-going account usage. A neglog transformation that highlights features that are hidden on the original scale and improves the joint distribution of the covariates is introduced. Quantile regression, a novel methodology to the credit scoring industry, is used as it is relatively assumption free, and it is suspected that different relationships may be manifest in different parts of the response distribution. The large size is handled by selecting relatively small subsamples for training and then building empirical distributions from repeated samples for validation. In the application to the database of clients who have missed a single payment a substantive finding is that the predictor of the median of the target variable contains different variables from those of the predictor of the 30% quantile. This suggests that different mechanisms may be at play in different parts of the distribution.	Univ Lancaster, Fylde Coll, Dept Math & Stat, Lancaster LA1 4YF, England; Scimetr Ltd, Reading, Berks, England	Whittaker, J (reprint author), Univ Lancaster, Fylde Coll, Dept Math & Stat, Lancaster LA1 4YF, England.	joe.whittaker@lancaster.ac.uk					BOX GEP, 1964, J ROY STAT SOC B, V26, P211; Hastie T., 2001, ELEMENTS STAT LEARNI; KOENKER R, 1978, ECONOMETRICA, V46, P33, DOI 10.2307/1913643; Koenker R, 1999, J AM STAT ASSOC, V94, P1296, DOI 10.2307/2669943; Koenker R, 2001, J ECON PERSPECT, V15, P143, DOI 10.1257/jep.15.4.143; McNab H, 2000, PRINCIPLES PRACTICE; Yeo IK, 2000, BIOMETRIKA, V87, P954, DOI 10.1093/biomet/87.4.954; Yu K., 2003, STATISTICIAN, V52, P331, DOI DOI 10.1111/1467-9984.00363	8	10	10	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	0035-9254			J ROY STAT SOC C-APP	J. R. Stat. Soc. Ser. C-Appl. Stat.		2005	54		5				863	878		10.1111/j.1467-9876.2005.00520.x		16	Statistics & Probability	Mathematics	968NM	WOS:000232169200004		
S	Ding, C; He, XF		Jorge, A; Torgo, L; Brazdil, P; Camacho, R; Gama, J		Ding, C; He, XF			Cluster aggregate inequality and multi-level hierarchical clustering	KNOWLEDGE DISCOVERY IN DATABASES: PKDD 2005	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	16th European Conference on Machine Learning (ECML)/9th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)	OCT 03-07, 2005	Oporto, PORTUGAL	FCT, LIACC NIAAD				We show that (1) in hierarchical clustering, many linkage functions satisfy a cluster aggregate inequality, which allows an exact O(N-2) multi-level (using mutual nearest neighbor) implementation of the standard O(N-3) agglomerative hierarchical clustering algorithm. (2) a desirable close friends cohesion of clusters can be translated into kNN consistency which is guaranteed by the multi-level algorithm; (3) For similarity-based linkage functions, the multi-level algorithm is naturally implemented as graph contraction. The effectiveness of our algorithms is demonstrated on a number of real life applications.	Univ Calif Berkeley, Lawrence Berkeley Lab, Berkeley, CA 94720 USA	Ding, C (reprint author), Univ Calif Berkeley, Lawrence Berkeley Lab, Berkeley, CA 94720 USA.						Duda R. O., 2000, PATTERN CLASSIFICATI; FUNG B, 2003, P SIAM DAT MIN C; Hastie T., 2001, ELEMENTS STAT LEARNI; Jain A, 1988, ALGORITHMS CLUSTERIN; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; JUNG SY, 2001, P 2001 IEEE INT C DA, P265; KARYPIS G, 1999, IEEE COMPUT, V32, P68, DOI DOI 10.1109/2.781637; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; Theodoridis S, 1999, PATTERN RECOGNITION; VOORHEES EM, 1986, INFORM PROCESS MANAG, V22, P465, DOI 10.1016/0306-4573(86)90097-X; Xiong H, 2004, SIAM PROC S, P279; Yu H., 2003, P 9 ACM SIGKDD INT C, P306, DOI DOI 10.1145/956750.956786; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324	13	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29244-6	LECT NOTES ARTIF INT			2005	3721						71	83				13	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BDF43	WOS:000233235600012		
S	Cai, D; Shao, Z; He, XF; Yan, XF; Han, JW		Jorge, A; Torgo, L; Brazdil, P; Camacho, R; Gama, J		Cai, D; Shao, Z; He, XF; Yan, XF; Han, JW			Community mining from multi-relational networks	KNOWLEDGE DISCOVERY IN DATABASES: PKDD 2005	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	16th European Conference on Machine Learning (ECML)/9th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)	OCT 03-07, 2005	Oporto, PORTUGAL	FCT, LIACC NIAAD				Social network analysis has attracted much attention in recent years. Community mining is one of the major directions in social network analysis. Most of the existing methods on community mining assume that there is only one kind of relation in the network, and moreover, the mining results are independent of the users' needs or preferences. However, in reality, there exist multiple, heterogeneous social networks, each representing a particular kind of relationship, and each kind of relationship may play a distinct role in a particular task. In this paper, we systematically analyze the problem of mining hidden communities on heterogeneous social networks. Based on the observation that different relations have different importance with respect to a certain query, we propose a new method for learning an optimal linear combination of these relations which can best meet the user's expectation. With the obtained relation, better performance can be achieved for community mining.	Univ Illinois, Dept Comp Sci, Champaign, IL 61820 USA; Univ Chicago, Dept Comp Sci, Chicago, IL 60637 USA	Cai, D (reprint author), Univ Illinois, Dept Comp Sci, Champaign, IL 61820 USA.	dengcai2@cs.uiuc.edu; zshao1@cs.uiuc.edu; xiaofei@cs.uchicago.edu; xyan@cs.uiuc.edu; hanj@cs.uiuc.edu					BJORCK A, 1996, NUMERICAL METHODS LE; CAI D, 2005, UIUCDCSR20052538; Domingos P., 2001, P 7 ACM SIGKDD INT C, P57, DOI 10.1145/502512.502525; Hastie T., 2001, ELEMENTS STAT LEARNI; Kautz H, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P3; Milgram S., 1967, PSYCHOL TODAY, V2, P60, DOI DOI 10.1145/335305.335325; SCHWARTZ MF, 1993, COMMUN ACM, V36, P78, DOI 10.1145/163381.163402; Wasserman S., 1994, SOCIAL NETWORK ANAL	8	10	10	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29244-6	LECT NOTES ARTIF INT			2005	3721						445	452				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BDF43	WOS:000233235600044		
S	Kalousis, A; Prados, J; Rexhepaj, E; Hilario, M		Jorge, A; Torgo, L; Brazdil, P; Camacho, R; Gama, J		Kalousis, A; Prados, J; Rexhepaj, E; Hilario, M			Feature extraction from mass spectra for classification of pathological states	KNOWLEDGE DISCOVERY IN DATABASES: PKDD 2005	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	16th European Conference on Machine Learning (ECML)/9th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)	OCT 03-07, 2005	Oporto, PORTUGAL	FCT, LIACC NIAAD				Mass spectrometry is becoming an important tool in proteomics. The representation of mass spectra is characterized by very high dimensionality and a high level of redundancy. Here we present a feature extraction method for mass spectra that directly models for domain knowledge, reduces the dimensionality and redundancy of the initial representation and controls for the level of granularity of feature extraction by seeking to optimize classification accuracy. A number of experiments are performed which show that the feature extraction preserves the initial discriminatory content of the learning examples.	Univ Geneva, Dept Comp Sci, CH-1211 Geneva, Switzerland	Kalousis, A (reprint author), Univ Geneva, Dept Comp Sci, Rua Gen Dufour, CH-1211 Geneva, Switzerland.	kalousis@cui.unige.ch; prados@cui.unige.ch; hilario@cui.unige.ch; rexhepaj@unil.ch					Hastie T., 2001, ELEMENTS STAT LEARNI; LEE KR, 2003, PROTEOMICS, V3; Mallat S. G., 1999, WAVELET TOUR SIGNAL; MORRIS JS, 2005, BIOINFORMATICS; PETRICOIN E, 2002, J NCI, V94; PETRICOIN E, 2002, LANCET, V94; PETRICOIN E, 2002, LANCET, V395, P572; Prados J, 2004, PROTEOMICS, V4, P2320, DOI 10.1002/pmic.200400857; Qu YS, 2003, BIOMETRICS, V59, P143, DOI 10.1111/1541-0420.00017; Struzik Z. R., 1999, 3 EUR C PRINC KNOWL, P12; Witten I.H., 1999, DATA MINING PRACTICA	11	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29244-6	LECT NOTES ARTIF INT			2005	3721						536	543				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BDF43	WOS:000233235600055		
S	Knuteson, B; Vilalta, R		Jorge, A; Torgo, L; Brazdil, P; Camacho, R; Gama, J		Knuteson, B; Vilalta, R			Testing theories in particle physics using maximum likelihood and adaptive bin allocation	KNOWLEDGE DISCOVERY IN DATABASES: PKDD 2005	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	16th European Conference on Machine Learning (ECML)/9th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)	OCT 03-07, 2005	Oporto, PORTUGAL	FCT, LIACC NIAAD				We describe a methodology to assist scientists in quantifying the degree of evidence in favor of a new proposed theory compared to a standard baseline theory. The figure of merit is the log-likelihood ratio of the data given each theory. The novelty of the proposed mechanism lies in the likelihood estimations; the central idea is to adaptively allocate histogram bins that emphasize regions in the variable space where there is a clear difference in the predictions made by the two theories. We describe a software system that computes this figure of merit in the context of particle physics, and describe two examples conducted at the Tevatron Ring at the Fermi National Accelerator Laboratory. Results show how two proposed theories compare to the Standard Model and how the likelihood ratio varies as a function of a physical parameter (e.g., by varying the particle mass).	MIT, Nucl Sci Lab, Cambridge, MA 02139 USA; Univ Houston, Dept Comp Sci, Houston, TX 77204 USA	Knuteson, B (reprint author), MIT, Nucl Sci Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	knuteson@mit.edu; vilalta@cs.uh.edu					Duda R.O., 2001, PATTERN CLASSIFICATI; Hastie T., 2001, ELEMENTS STAT LEARNI; KNUTESON B, SYSTEMATIC ANAL HEP; KOCABAS S, 2001, P 4 INT C DISC SCI, P182; Scott D. W., 1992, WILEY SERIES PROBABI	5	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29244-6	LECT NOTES ARTIF INT			2005	3721						552	560				9	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BDF43	WOS:000233235600057		
S	Sumner, M; Frank, E; Hall, M		Jorge, A; Torgo, L; Brazdil, P; Camacho, R; Gama, J		Sumner, M; Frank, E; Hall, M			Speeding up logistic model tree induction	KNOWLEDGE DISCOVERY IN DATABASES: PKDD 2005	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	16th European Conference on Machine Learning (ECML)/9th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)	OCT 03-07, 2005	Oporto, PORTUGAL	FCT, LIACC NIAAD				Logistic Model Trees have been shown to be very accurate and compact classifiers [8]. Their greatest disadvantage is the computational complexity of inducing the logistic regression models in the tree. We address this issue by using the AIC criterion [1] instead of cross-validation to prevent overfitting these models. In addition, a weight trimming heuristic is used which produces a significant speedup. We compare the training time and accuracy of the new induction process with the original one on various datasets and show that the training time often decreases while the classification accuracy diminishes only slightly.	Univ Freiburg, Inst Comp Sci, Freiburg, Germany; Univ Waikato, Dept Comp Sci, Hamilton, New Zealand	Sumner, M (reprint author), Univ Freiburg, Inst Comp Sci, Hugstetter Str 55, Freiburg, Germany.	sumner@informatik.uni-freiburg.de; eibe@cs.waikato.ac.nz; mhall@cs.waikato.ac.nz	Frank, Eibe/A-1434-2008				AKAIKE J, 1973, 2 INT S INF THEOR AK, P267; Blake C.L., 1998, UCI REPOSITORY MACHI; Breiman L., 1984, CLASSIFICATION REGRE; BUHLMANN P, 2005, SEM STAT ETH ZUR; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Hastie T., 2001, ELEMENTS STAT LEARNI; Landwehr N, 2005, MACH LEARN, V59, P161, DOI 10.1007/s10994-005-0466-3; Nadeau C., 1999, ADV NEURAL INFORMATI, P307; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; Witten IH, 2000, DATA MINING PRACTICA	11	20	20	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29244-6	LECT NOTES ARTIF INT			2005	3721						675	683				9	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BDF43	WOS:000233235600072		
J	Webb, GI; Boughton, JR; Wang, ZH				Webb, GI; Boughton, JR; Wang, ZH			Not so naive Bayes: Aggregating one-dependence estimators	MACHINE LEARNING			English	Article						naive Bayes; semi-naive Bayes; attribute independence assumption; probabilistic prediction		Of numerous proposals to improve the accuracy of naive Bayes by weakening its attribute independence assumption, both LBR and Super-Parent TAN have demonstrated remarkable error performance. However, both techniques obtain this outcome at a considerable computational cost. We present a new approach to weakening the attribute independence assumption by averaging all of a constrained class of classifiers. In extensive experiments this technique delivers comparable prediction accuracy to LBR and Super-Parent TAN with substantially improved computational efficiency at test time relative to the former and at training time relative to the latter. The new algorithm is shown to have low variance and is suited to incremental learning.	Monash Univ, Sch Comp Sci & Software Engn, Clayton, Vic 3800, Australia	Webb, GI (reprint author), Monash Univ, Sch Comp Sci & Software Engn, Clayton, Vic 3800, Australia.	geoff.webb@infotec.monash.edu	Webb, Geoffrey/A-1347-2008				ALI K, 1994, PROC INT C TOOLS ART, P476, DOI 10.1109/TAI.1994.346454; Brain D., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431); Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Domingos P., 1996, P 13 INT C MACH LEAR, P105; Fayyad UM, 1993, P 13 INT JOINT C ART, P1022; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Hastie T., 2001, ELEMENTS STAT LEARNI; Keogh E, 1999, P 7 INT WORKSH ART I, P225; Kohavi R., 1996, P 13 INT C MACH LEAR, P275; Kohavi R., 1996, P 2 INT C KNOWL DISC, P202; KONONENKO I., 1991, P 6 EUR WORK SESS LE, P206; Langley P., 1994, P 10 C UNC ART INT, P399; LANGLEY P, 1993, P 1993 EUR C MACH LE, V153; NOCK R, 1995, P 12 INT C MACH LEAR, P413; OLIVER JJ, 1995, P 12 INT C MACH LEAR, P430; Pazzani M. J, 1996, ISIS INFORM STAT IND, P66; Sahami M., 1996, P 2 INT C KNOWL DISC, P334; Singh M., 1996, P 13 INT C MACH LEAR, P453; WANG Z, 2002, P IEEE INT C DAT MIN, P75; Webb G I, 1998, P 11 AUSTR JOINT C A, P285; WEBB GI, 2001, P 14 AUSTR JOINT C A, P545; Witten IH, 2000, DATA MINING PRACTICA; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; XIE Z, 2002, ADV KNOWLEDGE DISCOV, P104; YANG Y, 2003, 2003131 SCH COMP SCI; Zheng Z., 1999, P 16 INT C MACH LEAR, P493; Zheng ZJ, 2000, MACH LEARN, V41, P53, DOI 10.1023/A:1007613203719	28	165	178	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	JAN	2005	58	1					5	24		10.1007/s10994-005-4258-6		20	Computer Science, Artificial Intelligence	Computer Science	897XV	WOS:000227041100001		
S	Szepannek, G; Luebke, K; Weihs, C		Perner, P; Imilya, A		Szepannek, G; Luebke, K; Weihs, C			Understanding patterns with different subspace classification	MACHINE LEARNING AND DATA MINING IN PATTERN RECOGNITION, PROCEEDINDS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th International Conference on Machine Learning and Data Minining in Pattern Recognition	JUL 09-11, 2005	Leipzig, GERMANY					By identifying characteristic regions in which classes are dense and also relevant for discrimination a new, intuitive classification method is set up. This method enables a visualized result so the user is provided with an insight into the data with respect to discrimination for an easy interpretation. Additionally, it outperforms Decision trees in a lot of situations and is robust against outliers and missing values.	Univ Dortmund, Dept Stat, Dortmund, Germany	Szepannek, G (reprint author), Univ Dortmund, Dept Stat, Dortmund, Germany.	szepannek@statistik.uni-dortmund.de					Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; FREEDMAN D, 1981, Z WAHRSCHEINLICHKEIT, V57, P453, DOI 10.1007/BF01025868; Hastie T., 2001, ELEMENTS STAT LEARNI	5	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-26923-1	LECT NOTES ARTIF INT			2005	3587						110	119				10	Computer Science, Artificial Intelligence	Computer Science	BCR27	WOS:000230895100012		
S	Wang, G; Zhang, ZH; Lochovsky, RH		Gama, J; Camacho, R; Brazdil, P; Jorge, A; Torgo, L		Wang, G; Zhang, ZH; Lochovsky, RH			Annealed discriminant analysis	MACHINE LEARNING: ECML 2005, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	16th European Conference on Machine Learning (ECML)/9th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)	OCT 03-07, 2005	Oporto, PORTUGAL	FCT, LIACC NIAAD			CLASSIFICATION; REGRESSION; DISTRIBUTIONS; DESIGN	Motivated by the analogies to statistical physics, the deterministic annealing (DA) method has successfully been demonstrated in a variety of applications. In this paper, we explore a new methodology to devise the classifier under the DA method. The differential cost function is derived subject to a constraint on the randomness of the solution, which is governed by the temperature T. While gradually lowering the temperature, we can always find a good solution which can both solve the overfitting problem and avoid poor local optima. Our approach is called annealed discriminant analysis (ADA). It is a general approach, where we elaborate two classifiers, i.e., distance-based and inner product-based, in this paper. The distance-based classifier is an annealed version of linear discriminant analysis (LDA) while the inner product-based classifier is a generalization of penalized logistic regression (PLR). As such, ADA provides new insights into the workings of these two classification algorithms. The experimental results show substantial performance gains over standard learning methods.	Hong Kong Univ Sci & Technol, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China	Wang, G (reprint author), Hong Kong Univ Sci & Technol, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.	wanggang@cs.ust.hk; zhzhang@cs.ust.hk; fred@cs.ust.hk					GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; Hastie T., 2001, ELEMENTS STAT LEARNI; Hofmann T, 1997, IEEE T PATTERN ANAL, V19, P1, DOI 10.1109/34.566806; McLachlan G., 1992, DISCRIMINANT ANAL ST; Miller D, 1996, IEEE T SIGNAL PROCES, V44, P3108, DOI 10.1109/78.553484; Nabney I. T., 2001, NETLAB ALGORITHMS PA; Rao AV, 1999, IEEE T PATTERN ANAL, V21, P159, DOI 10.1109/34.748824; Rose K, 1998, P IEEE, V86, P2210, DOI 10.1109/5.726788; ROSE K, 1990, PHYS REV LETT, V65, P945, DOI 10.1103/PhysRevLett.65.945; Wahba G, 2002, P NATL ACAD SCI USA, V99, P16524, DOI 10.1073/pnas.242574899; YUILLE AL, 1994, NEURAL COMPUT, V6, P334, DOI 10.1162/neco.1994.6.2.334; Zhang T, 2004, J MACH LEARN RES, V5, P1225; Zhu J, 2004, BIOSTATISTICS, V5, P427, DOI 10.1093/biostatistics/kxg046	13	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29243-8	LECT NOTES ARTIF INT			2005	3720						449	460				12	Computer Science, Artificial Intelligence	Computer Science	BDF41	WOS:000233235200043		
S	Yildiz, OT; Alpaydin, E		Gama, J; Camacho, R; Brazdil, P; Jorge, A; Torgo, L		Yildiz, OT; Alpaydin, E			Model selection in omnivariate decision trees	MACHINE LEARNING: ECML 2005, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	16th European Conference on Machine Learning (ECML)/9th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)	OCT 03-07, 2005	Oporto, PORTUGAL	FCT, LIACC NIAAD			CLASSIFICATION TREES; ALGORITHMS	We propose an omnivariate decision tree architecture which contains univariate, multivariate linear or nonlinear nodes, matching the complexity of the node to the complexity of the data reaching that node. We compare the use of different model selection techniques including AIC, BIC, and CV to choose between the three types of nodes on standard datasets from the UCI repository and see that such omnivariate trees with a small percentage of multivariate nodes close to the root generalize better than pure trees with the same type of node everywhere. CV produces simpler trees than AIC and BIC without sacrificing from expected error. The only disadvantage of CV is its longer training time.	Bogazici Univ, Dept Comp Engn, TR-34342 Istanbul, Turkey	Yildiz, OT (reprint author), Bogazici Univ, Dept Comp Engn, TR-34342 Istanbul, Turkey.	yildiz@cmpe.boun.edu.tr; alpaydin@boun.edu.tr	YILDIZ, OLCAY/K-3869-2012; ALPAYDIN, ETHEM/E-6127-2013				Akaike H., 1973, 2 INT S INF THEOR, P267; Alpaydm E., 2004, INTRO MACHINE LEARNI; Blake C., 2000, UCI REPOSITORY MACHI; BREIMAN L, 1984, CLASSIFICATINO REGRE; BRESLOW LA, 1997, AIC96014 NAV CTR APP; BRODLEY CE, 1995, MACH LEARN, V19, P45, DOI 10.1007/BF00994660; Cohen W, 1995, 12 INT C MACH LEARN, P115; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; FRIEDMAN JH, 1977, IEEE T COMPUT, V26, P404; GAMA J, 1999, 16 INT C MACH LEARN, P134; Gama J, 2004, MACH LEARN, V55, P219, DOI 10.1023/B:MACH.0000027782.67192.13; GUO H, 1992, IEEE T NEURAL NETWOR, V3, P923, DOI 10.1109/72.165594; Hastie T., 2001, ELEMENTS STAT LEARNI; Kim H, 2001, J AM STAT ASSOC, V96, P589, DOI 10.1198/016214501753168271; LANDWEHR N, 2003, P 14 EUR C MACH LEAR, P241; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; Loh WY, 1997, STAT SINICA, V7, P815; LOH WY, 1988, J AM STAT ASSOC, V83, P715, DOI 10.2307/2289295; Murthy SK, 1998, DATA MIN KNOWL DISC, V2, P345, DOI 10.1023/A:1009744630224; Murthy S.K., 1994, J ARTIFICIAL INTELLI, V2, P1; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Yildiz OT, 2001, IEEE T NEURAL NETWOR, V12, P1539; Yildiz OT, 2005, INT J PATTERN RECOGN, V19, P323, DOI 10.1142/S0218001405004125	23	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29243-8	LECT NOTES ARTIF INT			2005	3720						473	484				12	Computer Science, Artificial Intelligence	Computer Science	BDF41	WOS:000233235200045		
S	Suen, YL; Melville, P; Mooney, RJ		Gama, J; Camacho, R; Brazdil, P; Jorge, A; Torgo, L		Suen, YL; Melville, P; Mooney, RJ			Combining bias and variance reduction techniques for regression trees	MACHINE LEARNING: ECML 2005, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	16th European Conference on Machine Learning (ECML)/9th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)	OCT 03-07, 2005	Oporto, PORTUGAL	FCT, LIACC NIAAD				Gradient Boosting and bagging applied to regressors can reduce the error due to bias and variance respectively. Alternatively, Stochastic Gradient Boosting (SGB) and Iterated Bagging (IB) attempt to simultaneously reduce the contribution of both bias and variance to error. We provide an extensive empirical analysis of these methods, along with two alternate bias-variance reduction approaches-bagging Gradient Boosting (BagGB) and bagging Stochastic Gradient Boosting (BagSGB). Experimental results demonstrate that SGB does not perform as well as IB or the alternate approaches. Furthermore, results show that, while BagGB and BagSGB perform competitively for low-bias learners, in general, Iterated Bagging is the most effective of these methods.	Univ Texas, Dept Elect & Comp Engn, Austin, TX 78712 USA; Univ Texas, Dept Comp Sci, Austin, TX 78712 USA	Suen, YL (reprint author), Univ Texas, Dept Elect & Comp Engn, Austin, TX 78712 USA.	suen@ece.utexas.edu; melville@cs.utexas.edu; mooney@cs.utexas.edu					Blake C.L., 1998, UCI REPOSITORY MACHI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L., 1984, CLASSIFICATION REGRE; BREIMAN L, 1999, USING ADAPTIVE BAGGI; Breiman L, 2001, MACH LEARN, V45, P261, DOI 10.1023/A:1017934522171; Dietterich T. G., 2003, P 20 INT C MACH LEAR, P752; FRIEDMAN J, 2000, ADDITIVE LOGISTIC RE; Friedman J, 1999, STOCHASTIC GRADIENT; Friedman JH, 1999, GREEDY FUNCTION APPR; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Hastie T., 2001, ELEMENTS STAT LEARNI; Kohavi R., 1996, P 13 INT C MACH LEAR; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; SUEN YL, 2005, UTAITR05321; Wang Y., 1997, EUR C MACH LEARN PRA, P128; Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849	16	5	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29243-8	LECT NOTES ARTIF INT			2005	3720						741	749				9	Computer Science, Artificial Intelligence	Computer Science	BDF41	WOS:000233235200076		
J	Cappo, M; De'ath, G; Boyle, S; Aumend, J; Olbrich, R; Hoedt, F; Perna, C; Brunskill, G				Cappo, M; De'ath, G; Boyle, S; Aumend, J; Olbrich, R; Hoedt, F; Perna, C; Brunskill, G			Development of a robust classifier of freshwater residence in barramundi (Lates calcarifer) life histories using elemental ratios in scales and boosted regression trees	MARINE AND FRESHWATER RESEARCH			English	Article; Proceedings Paper	3rd International Symposium on Fish Otolith Research and Application	JUL 11-16, 2004	Townsville, AUSTRALIA			environmental flows; fish scales; geochemical markers; statistical discrimination	STRIPED BASS; STRONTIUM; RIVER; FISH; OTOLITHS; BARIUM; ESTUARIES; MOVEMENTS; CHEMISTRY; WEAKFISH	Field and experimental studies showed that solution-based analysis of scales could be used to discriminate the long-term freshwater residents in the coastal fishery for catadromous barramundi. A new, robust classification technique was developed using boosted regression trees ( MART) and its performance was compared with traditional linear discriminant analysis (LDA). The non-parametric MART had errors 33 - 81% less than LDA, and could account for non-linear relationships and interactions among elemental ratios. The best model used Sr : Ca, Ba : Ca, Fe : Ca and Mn: Ca in scales as predictors of salinity regime. Analysis of scales collected repeatedly from sub-adult fish of known environmental history showed the MART classifier could identify fish of freshwater origin until at least 10 months residence in seawater, and possibly several years, but scale growth rate could affect the temporal stability of the classifier after that time. The experiment indicated an approximate fourfold rise in Sr : Ba ratios in new scale margins, which were strongly classified by the MART as coming from saltwater fish, but inner scale sections of the same scales were still correctly classified as coming from freshwater fish. We conclude that solution-based elemental analyses of whole scales, and also annuli within scales, could offer a cost-effective, non-destructive technique to help understand the mechanisms causing enhanced year-class strength following high freshwater outflows.	Australian Inst Marine Sci, Townsville, Qld 4810, Australia; James Cook Univ N Queensland, Australian Ctr Trop Freshwater Res, Townsville, Qld 4811, Australia	Cappo, M (reprint author), Australian Inst Marine Sci, PMB 3, Townsville, Qld 4810, Australia.	mcappo@aims.gov.au					BELANGER SE, 1987, T AM FISH SOC, V116, P594, DOI 10.1577/1548-8659(1987)116<594:DOFVSS>2.0.CO;2; Breiman L., 1984, CLASSIFICATION REGRE; Coffey M, 1997, ESTUAR COAST SHELF S, V45, P113, DOI 10.1006/ecss.1996.0157; COUTANT CC, 1993, CAN J FISH AQUAT SCI, V50, P1318, DOI 10.1139/f93-149; De'ath G, 2000, ECOLOGY, V81, P3178, DOI 10.1890/0012-9658(2000)081[3178:CARTAP]2.0.CO;2; FOUDA MM, 1979, J FISH BIOL, V15, P173, DOI 10.1111/j.1095-8649.1979.tb03581.x; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Gillanders BM, 2001, FISH B-NOAA, V99, P410; Hastie T., 2001, ELEMENTS STAT LEARNI; LI YH, 1979, EARTH PLANET SC LETT, V43, P343, DOI 10.1016/0012-821X(79)90089-X; Mc Dougall A, 2004, FISH RES, V67, P129, DOI 10.1016/j.fishres.2003.09.044; Milton DA, 2000, ESTUAR COAST SHELF S, V50, P855, DOI 10.1006/ecss.2000.0608; MUGIYA Y, 1977, COMP BIOCHEM PHYS A, V57, P197, DOI 10.1016/0300-9629(77)90455-8; PALMER MR, 1989, EARTH PLANET SC LETT, V92, P11, DOI 10.1016/0012-821X(89)90017-4; Pender PJ, 1996, T AM FISH SOC, V125, P679, DOI 10.1577/1548-8659(1996)125<0679:HHOBCI>2.3.CO;2; R Development Core Team, 2004, R LANG ENV STAT COMP; Ridd PV, 2002, ESTUAR COAST SHELF S, V54, P1039, DOI 10.1006/ecss.2001.0876; Ripley BD, 1996, PATTERN RECOGNITION; Russell D., 1997, DEV SUSTAINING WORLD, P498; Sire JY, 2004, INT J DEV BIOL, V48, P233, DOI 10.1387/ijdb.15272389; Staunton-Smith J, 2004, MAR FRESHWATER RES, V55, P787, DOI 10.1071/MF03198; STONE M, 1977, BIOMETRIKA, V64, P29; Wells BK, 2003, CAN J FISH AQUAT SCI, V60, P361, DOI 10.1139/F03-028; Wells BK, 2000, CAN J FISH AQUAT SCI, V57, P2122, DOI 10.1139/cjfas-57-10-2122; Wells BK, 2000, T AM FISH SOC, V129, P889, DOI 10.1577/1548-8659(2000)129<0889:GVITEC>2.3.CO;2; Wells BK, 2003, T AM FISH SOC, V132, P409, DOI 10.1577/1548-8659(2003)132<0409:RBWOAS>2.0.CO;2; Wells BK, 2003, MAR ECOL PROG SER, V262, P293, DOI 10.3354/meps262293	29	15	15	C S I R O PUBLISHING	COLLINGWOOD	150 OXFORD ST, PO BOX 1139, COLLINGWOOD, VICTORIA 3066, AUSTRALIA	1323-1650			MAR FRESHWATER RES	Mar. Freshw. Res.		2005	56	5					713	723		10.1071/MF04218		11	Fisheries; Limnology; Marine & Freshwater Biology; Oceanography	Fisheries; Marine & Freshwater Biology; Oceanography	947WW	WOS:000230679000023		
J	Scheidtmann, J; Frantzen, A; Frenzer, G; Maier, WF				Scheidtmann, J; Frantzen, A; Frenzer, G; Maier, WF			A combinatorial technique for the search of solid state gas sensor materials	MEASUREMENT SCIENCE & TECHNOLOGY			English	Article						gas sensor; electrochemical sensor; high throughput; combinatorial; IR-thermography; resistivity; data mining; clustering; database	NO2	A complete high throughput assembly for the search for electrochemical sensor materials is described. It is a primary screening device, whose sole purpose is to locate most efficiently new materials with potential sensor properties. The set-up consists of a gas tight reactor for the sensor libraries. an IR-camera, a switching multimeter for dc-resistance measurements. a test gas supply array for different test gases, software for control of experimental flow, data recording, data evaluation, data mining and a database. The sensor libraries consist of a ceramic alumina plate with 64 interdigital electrodes and associated contact pads arranged on the outer rim of the library. The materials are deposited on top of the electrodes and calcined before use. The reactor houses 128 spring loaded electrodes for electrochemical monitoring and a sapphire plate for IR-monitoring of materials responses to exposure to test gases. Data are evaluated automatically and stored in a database for visualization and data mining.	Univ Saarland, Lehrstuhl Tech Chem, D-66123 Saarbrucken, Germany	Scheidtmann, J (reprint author), Univ Saarland, Lehrstuhl Tech Chem, D-66123 Saarbrucken, Germany.	w.f.maier@mx.uni-saarland					Ball P., 2002, NATURE, V417, P11; Barsan N, 2001, J ELECTROCERAM, V7, P143, DOI 10.1023/A:1014405811371; BECKER RA, 1996, SPLUS TRELLIS GRAPHI; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Frantzen A, 2004, ANGEW CHEM INT EDIT, V43, P752, DOI 10.1002/anie.200352424; Gurlo A, 1998, SENSOR ACTUAT B-CHEM, V47, P92, DOI 10.1016/S0925-4005(98)00033-1; Hastie T., 2001, ELEMENTS STAT LEARNI; Holzwarth A., 1998, ANGEW CHEM, V110, P2788, DOI 10.1002/(SICI)1521-3757(19981002)110:19<2788::AID-ANGE2788>3.0.CO;2-5; Jandeleit B., 1999, ANGEW CHEM INT EDIT, V38, P2494; JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588; Maier WF, 1999, ANGEW CHEM INT EDIT, V38, P1216, DOI 10.1002/(SICI)1521-3773(19990503)38:9<1216::AID-ANIE1216>3.0.CO;2-V; SCHEIDTMANN J, 2003, THESIS U SAARLANDES; Seo J, 2002, COMPUTER, V35, P80; Simon U, 2002, J COMB CHEM, V4, P511, DOI 10.1021/cc020025p; SPOTFIRE AB, FORSTA LANGGATAN; Steffes H, 2001, SENSOR ACTUAT B-CHEM, V77, P352, DOI 10.1016/S0925-4005(01)00733-X; Tufte E.R., 1983, VISUAL DISPLAY QUANT; Venables W. N., 2003, INTRO R; Witten I.H., 1999, DATA MINING PRACTICA	19	16	16	IOP PUBLISHING LTD	BRISTOL	DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND	0957-0233			MEAS SCI TECHNOL	Meas. Sci. Technol.	JAN	2005	16	1					119	127		10.1088/0957-0233/16/1/016		9	Engineering, Multidisciplinary; Instruments & Instrumentation	Engineering; Instruments & Instrumentation	892MX	WOS:000226655800017		
S	Wei, LY; Yang, YY; Nishikawa, RM; Jiang, YL		Fitzpatrick, JM; Reinhardt, JM		Wei, LY; Yang, YY; Nishikawa, RM; Jiang, YL			A study of several CAD methods for classification of clustered microcalcifications	Medical Imaging 2005: Image Processing, Pt 1-3	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Medical Imaging 2005 Conference	FEB 15-17, 2005	San Diego, CA	SPIE		computer-aided diagnosis; mammography; clustered microcalcifications; kernel method	COMPUTER-AIDED DIAGNOSIS; BREAST-CANCER; MAMMOGRAPHY; LIKELIHOOD; BENIGN; MASSES; ROC	In this paper we investigate several state-of-the-art machine-learning methods for automated classification of clustered microcalcifications (MCs), aimed to assisting radiologists for more accurate diagnosis of breast cancer in a computer-aided diagnosis (CADx) scheme. The methods we consider include: support vector machine (SVM), kernel Fisher discriminant (KFD), and committee machines (ensemble averaging and AdaBoost), most of which have been developed recently in statistical learning theory. We formulate differentiation of malignant from benign MCs as a supervised learning problem, and apply these learning methods to develop the classification algorithms. As input, these methods use image features automatically extracted from clustered MCs. We test these methods using a database of 697 clinical mammograms from 386 cases, which include a wide spectrum of difficult-to-classify cases. We use receiver operating characteristic (ROC) analysis to evaluate and compare the classification performance by the different methods. In addition, we also investigate how to combine information from multiple-view mammograms of the same case so that the best decision can be made by a classifier. In our experiments, the kernel-based methods (i.e., SVM, KFD) yield the best performance, significantly outperforming a well-established CADx approach based on neural network learning.	IIT, Dept Biomed Engn, Chicago, IL 60616 USA	Wei, LY (reprint author), IIT, Dept Biomed Engn, 3301 S Dearborn St, Chicago, IL 60616 USA.						Baker JA, 1996, RADIOLOGY, V198, P131; Chan HP, 1999, RADIOLOGY, V212, P817; DORSI CJ, 1992, RADIOLOGY, V184, P619; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Hastie T., 2001, ELEMENTS STAT LEARNI; Haykin S, 1999, NEURAL NETWORK COMPR; Huo ZM, 2000, ACAD RADIOL, V7, P1077, DOI 10.1016/S1076-6332(00)80060-4; Jiang YL, 1996, RADIOLOGY, V198, P671; Jiang YL, 1999, ACAD RADIOL, V6, P22, DOI 10.1016/S1076-6332(99)80058-0; KNUTZEN AM, 1993, MAYO CLIN PROC, V68, P454; KOPANS DB, 1992, AM J ROENTGENOL, V158, P521; Metz CE, 1998, STAT MED, V17, P1033, DOI 10.1002/(SICI)1097-0258(19980515)17:9<1033::AID-SIM784>3.3.CO;2-Q; Mika S., 1999, NEURAL NETWORKS SIGN, P41; Ripley BD, 1996, PATTERN RECOGNITION; Scholkopf B., 2002, LEARNING KERNELS SUP; SCHWENK H, 1997, INT C ART NEUR NETW, P967; Vapnik V., 1998, STAT LEARNING THEORY; Viola P, 2001, INT C COMP VIS PATT; WU YZ, 1993, RADIOLOGY, V187, P81	19	1	1	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		0-8194-5721-3	P SOC PHOTO-OPT INS			2005	5747		1-3				1	8		10.1117/12.594734		8	Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging	Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging	BCN01	WOS:000230109600001		
S	Hernandez, M; Frangi, AF		Fitzpatrick, JM; Reinhardt, JM		Hernandez, M; Frangi, AF			Brain aneurysm segmentation in CTA and 3DRA using Geodesic Active Regions based on second order prototype features and non parametric density estimation	Medical Imaging 2005: Image Processing, Pt 1-3	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Medical Imaging 2005 Conference	FEB 15-17, 2005	San Diego, CA	SPIE		brain aneurysm; CTA; 3DRA; segmentation; Geodesic Active Regions; level set method; second order structure; prototype features; non parametric; density estimation	ANISOTROPIC DIFFUSION; CEREBRAL ANEURYSMS; IMAGE SEGMENTATION; ANGIOGRAPHY; ALGORITHMS; EFFICIENT; CONTOURS	Coupling the geodesic active contours model with statistical information based on regions introduces robustness in the segmentation of images with weak or inhomogeneous gradients. In the estimation of the probability density function for each region take part the definition of the features that describe the image inside the different regions and the method of density estimation itself. A Gaussian Mixture Model is frequently proposed for density estimation. This approach is based on the assumption that the intensity distribution of the image is the most discriminant feature in a region. However, the use of second order features provides a better discrimination of the different regions, as these features represent more accurately the local properties of the image manifold. Due to the high dimensionality of the problem, the use of non parametric density estimation methods becomes necessary. In this article, we present a novel method of introducing the second order information of an image for non parametric estimation of the probability density functions of the different tissues that are present in medical images. The novelty of the method stems on the use of the response of the image under an orthogonal harmonic operator set projected onto a prototype space for feature generation. The technique described here is applied to the segmentation of brain aneurysms in Computed Tomography Angiography (CTA) and 3D Rotational Angiography (3DRA) showing a qualitative improvement from the Gaussian Mixture Model approach.	Univ Zaragoza, Aragon Inst Engn Res 13A, Zaragoza, Spain	Hernandez, M (reprint author), Univ Zaragoza, Aragon Inst Engn Res 13A, Zaragoza, Spain.		Hernandez Gimenez, Monica/A-9855-2013; Frangi, A/C-6500-2008	Frangi, A/0000-0002-2675-528X			ADALSTEINSSON D, 1995, J COMPUT PHYS, V118, P269, DOI 10.1006/jcph.1995.1098; Aubert G, 2003, SIAM J APPL MATH, V63, P2128, DOI 10.1137/S0036139902408928; Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; DANIELSSON PE, 2001, LECT NOTES COMPUTER, V2059, P145; Danielsson PE, 2001, J VIS COMMUN IMAGE R, V12, P255, DOI 10.1006/jvci.2000.0472; Deschamps T., 2001, THESIS U PARIS DAUPH; DUDA RO, 1908, PATTERN CLASSIFICATI; Frangi AF, 1998, LECT NOTES COMPUT SC, V1496, P130; Hastie T., 2001, ELEMENTS STAT LEARNI; Hochmuth A, 2002, AM J NEURORADIOL, V23, P1199; HOLTZMANGAZIT H, 2003, LECT NOTES COMPUTER, V2, P562; Kass M, 1988, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Krissian K, 2000, COMPUT VIS IMAGE UND, V80, P130, DOI 10.1006/cviu.2000.0866; Krissian K, 1997, LECT NOTES COMPUT SC, V1252, P345; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Lindeberg T., 1998, INT J COMPUT VISION, V2, P77; MA B, 2004, IN PRESS J NEUROSURG; Ma BS, 2004, ANN BIOMED ENG, V32, P264, DOI 10.1023/B:ABME.0000012746.31343.92; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Osher S., 2002, LEVEL SET METHODS DY; PARAGIOS N. K., 2000, THESIS U NICE SOPHIA; Pardo A, 2001, IEEE SIGNAL PROC LET, V8, P106, DOI 10.1109/97.911471; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Sato Y, 1998, Med Image Anal, V2, P143, DOI 10.1016/S1361-8415(98)80009-1; Sussman M, 1999, SIAM J SCI COMPUT, V20, P1165, DOI 10.1137/S1064827596298245; Teo PC, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P675; Vapnik V., 1998, STAT LEARNING THEORY; White PM, 2001, RADIOLOGY, V219, P739; YEZZI A, 1999, COMPUTER VISION 1999, P898; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884	31	1	1	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		0-8194-5721-3	P SOC PHOTO-OPT INS			2005	5747		1-3				514	525		10.1117/12.596237		12	Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging	Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging	BCN01	WOS:000230109600052		
J	Das, SK; Baydush, AH; Zhou, SM; Miften, M; Yu, XL; Craciunescu, O; Oldham, M; Light, K; Wong, T; Blazing, M; Borges-Neto, S; Dewhirst, MW; Marks, LB				Das, SK; Baydush, AH; Zhou, SM; Miften, M; Yu, XL; Craciunescu, O; Oldham, M; Light, K; Wong, T; Blazing, M; Borges-Neto, S; Dewhirst, MW; Marks, LB			Predicting radiotherapy-induced cardiac perfusion defects	MEDICAL PHYSICS			English	Article						ventricle; perfusion; defect; radiation	RELATIVE SERIALITY MODEL; SIDED BREAST-CANCER; RADIATION-THERAPY; HODGKINS-DISEASE; COMPLICATION PROBABILITIES; CHEST-WALL; FOLLOW-UP; IRRADIATION; MORTALITY; HEART	The purpose of this work is to compare the efficacy of mathematical models in predicting the occurrence of radiotherapy-induced left ventricular perfusion defects assessed using single-photon emission computed tomography (SPECT). The basis of this study is data from 73 left-sided breast/chestwall patients treated with tangential photon fields. The mathematical models compared were three commonly used parametric models [Lyman normal tissue complication probability (LNTCP), relative serialty (RS), generalized equivalent uniform dose (gEUD)] and a nonparametric model (Linear discriminant analysis-LDA). Data used by the models were the left ventricular dose-volume histograms, or SPECT-based dose-function histograms, and the presence/absence of SPECT perfusion defects 6 months postradiation therapy (21 patients developed defects). For the parametric models, maximum likelihood estimation and F-tests were used to fit the model parameters. The nonparametric LDA model step-wise selected features (volumes/function above dose levels) using a method based on receiver operating characteristics (ROC) analysis to best separate the groups with and without defects. Optimistic (upper bound) and pessimistic (lower bound) estimates of each model's predictive capability were generated using ROC curves. A higher area under the ROC curve indicates a more accurate model (a model that is always accurate has area = 1). The areas under these curves for different models were used to statistically test for differences between them. Pessimistic estimates of areas under the ROC curve using dose-volume histogram/dose-function histogram inputs, in order of increasing prediction accuracy, were LNTCP (0.79/0.75), RS (0.80/0.77), gEUD (0.81/0.78), and LDA (0.84/0.86). Only the LDA model benefited from SPECT-based regional functional information. In general, the LDA model was statistically superior to the parametric models. The LDA model selected as features the left ventricular volumes above approximately 23 Gy (V-23), essentially volume in field, and 33 Gy (V-33), as best separating the groups with and without defects. In conclusion, the nonparametric LDA model appears to be a more accurate predictor of radiotherapy-induced left ventricular perfusion defects than commonly used parametric models. (C) 2005 American Association of Physicists in Medicine.	Duke Univ, Med Ctr, Dept Radiat Oncol, Durham, NC 27710 USA; Duke Univ, Med Ctr, Dept Radiol, Durham, NC 27710 USA; Duke Univ, Med Ctr, Dept Med, Durham, NC 27710 USA; Duke Univ, Dept Radiat Oncol, Durham, NC 27710 USA	Das, SK (reprint author), Duke Univ, Med Ctr, Dept Radiat Oncol, Durham, NC 27710 USA.	shiva@radonc.duke.edu					Adams MJ, 2003, CRIT REV ONCOL HEMAT, V45, P55, DOI 10.1016/S1040-8428(01)00227-X; Avriel M, 1976, NONLINEAR PROGRAMMIN; Basavaraju SR, 2002, MED PHYS, V29, P2391, DOI 10.1118/1.1509442; Canney PA, 2001, BRIT J RADIOL, V74, P262; Catarious DM, 2004, MED PHYS, V31, P1512, DOI 10.1118/1.1738960; Chang SX, 2002, MED PHYS, V29, P1130, DOI 10.1118/1.1478560; Chen MH, 2002, J CARDIOV MAGN RESON, V4, P265, DOI 10.1081/JCMR-120003952; CUZICK J, 1994, J CLIN ONCOL, V12, P447; De Gersem WRT, 1999, INT J RADIAT ONCOL, V44, P461, DOI 10.1016/S0360-3016(98)00464-7; Eriksson F, 2000, RADIOTHER ONCOL, V55, P153, DOI 10.1016/S0167-8140(00)00166-3; Gagliardi G, 1996, BRIT J RADIOL, V69, P839; Gyenes G, 1996, INT J RADIAT ONCOL, V36, P899, DOI 10.1016/S0360-3016(96)00125-3; Hardenbergh PH, 2001, INT J RADIAT ONCOL, V49, P1023, DOI 10.1016/S0360-3016(00)01531-5; Hastie T., 2001, ELEMENTS STAT LEARNI; Hurkmans CW, 2002, RADIOTHER ONCOL, V62, P163, DOI 10.1016/S0167-8140(01)00473-X; KALLMAN P, 1992, INT J RADIAT BIOL, V62, P249, DOI 10.1080/09553009214552071; Krueger EA, 2003, INT J RADIAT ONCOL, V56, P1023, DOI 10.1016/S0360-3016(03)00183-4; Lind PA, 2003, INT J RADIAT ONCOL, V55, P914, DOI 10.1016/S0630-3016(02)04156-1; LO JY, 1995, ACAD RADIOL, V2, P841, DOI 10.1016/S1076-6332(05)80057-1; Lyman J. T., 1985, Radiation Research, V104; Marks L. B., 2002, International Journal of Radiation Oncology Biology Physics, V54, P3, DOI 10.1016/S0360-3016(02)03061-4; Marks LB, 1999, MED PHYS, V26, P196, DOI 10.1118/1.598503; MARKS LD, UNPUB; Metz CE, 1998, MED DECIS MAKING, V18, P110, DOI 10.1177/0272989X9801800118; Muren LP, 2002, RADIOTHER ONCOL, V62, P173, DOI 10.1016/S0167-8140(01)00468-6; Niemierko A, 1999, MED PHYS, V26, P1100; OSBORNE D, 1985, J COMPUT ASSIST TOMO, V9, P73, DOI 10.1097/00004728-198501000-00015; OSBORNE D, 1982, J NUCL MED, V23, P446; Pierce LJ, 2002, INT J RADIAT ONCOL, V52, P1220, DOI 10.1016/S0360-3016(01)02760-2; PIOVACCARI G, 1995, INT J CARDIOL, V49, P39, DOI 10.1016/0167-5273(95)02276-3; Reinders JG, 1999, RADIOTHER ONCOL, V51, P35, DOI 10.1016/S0167-8140(99)00026-2; Remouchamps VM, 2003, INT J RADIAT ONCOL, V55, P392, DOI 10.1016/S0360-3016(02)04143-3; Rencher A. C., 2002, METHODS MULTIVARIATE; RUTQVIST LE, 1992, INT J RADIAT ONCOL, V22, P887; Seddon B, 2002, RADIOTHER ONCOL, V64, P53, DOI 10.1016/S0167-8140(02)00133-0; STEWART JR, 1995, INT J RADIAT ONCOL, V31, P1205, DOI 10.1016/0360-3016(94)00656-6; Swets JA, 1982, EVALUATION DIAGNOSTI; YU X, 51 M RAD RES SOC ST; Zinzani PL, 1996, HAEMATOLOGICA, V81, P132	39	13	14	AMER ASSOC PHYSICISTS MEDICINE AMER INST PHYSICS	MELVILLE	STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA	0094-2405			MED PHYS	Med. Phys.	JAN	2005	32	1					19	27		10.1118/1.1823571		9	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	891QM	WOS:000226595600004	15719950	
J	Ittrich, C				Ittrich, C			Normalization for two-channel microarray data	METHODS OF INFORMATION IN MEDICINE			English	Article						cDNA microarrays; two-color microarrays; normalization; loess regression; data preprocessing	VARIANCE; MODELS	Objectives. In two-channel microarroy experiments the measured gene expression levels are affected by many sources of systematic variation. Normalization refers to the process of removing such systematic sources of variation, to make measured intensities within and between slides comparable. Some commonly used normalization methods removing intensity-dependent dye bias and adjusting differences in variability between slides will be reviewed with the main focus on intensity-dependent normalization methods. Methods: This article describes different intensity-dependent within-slide normalization methods for the log ratios of red and green channel intensities but also refers to single channel normalization methods incorporating all single channels of the slides at once. Results. The described procedures provide a useful approach to remove systematic sources of variation like intensity-dependent dye bias and variability between slides in cDNA microarray experiments. This is illustrated by an experimental data set. Conclusions. Several reasonable normalization procedures for two-channel microorray data have recently been proposed. Deciding on which method would perform well for a concrete experiment is difficult. Designed spike-in experiments or dilution series with known differences for some selected genes would be helpful to assess the different methods, but may be impractical for most laboratories due to the high costs.	German Canc Res Ctr, Cent Unit Biostat, D-69120 Heidelberg, Germany	Ittrich, C (reprint author), German Canc Res Ctr, Cent Unit Biostat, Neuenheimer Feld 280, D-69120 Heidelberg, Germany.	c.ittrich@dkfz.de					Bolstad BM, 2003, BIOINFORMATICS, V19, P185, DOI 10.1093/bioinformatics/19.2.185; Bretz F, 2005, METHOD INFORM MED, V44, P423; CLEVELAND WS, 1979, J AM STAT ASSOC, V74, P829, DOI 10.2307/2286407; CLEVELAND WS, 1992, PACIFIC GROVE CALIFO; COPE LM, 2003, BIOINFORMATICS, V20, P323; CUI X, 2002, STAT APPL GENETICS M, V2; Dudoit S, 2002, STAT SINICA, V12, P111; Durbin B P, 2002, Bioinformatics, V18 Suppl 1, pS105; Hastie T., 2001, ELEMENTS STAT LEARNI; Huber W, 2002, BIOINFORMATICS, V18, P96; Kerr MK, 2000, J COMPUT BIOL, V7, P819, DOI 10.1089/10665270050514954; Nguyen DV, 2002, BIOMETRICS, V58, P701, DOI 10.1111/j.0006-341X.2002.00701.x; Parmigiani G., 2003, ANAL GENE EXPRESSION; Repsilber D, 2005, METHOD INFORM MED, V44, P400; Rocke DM, 2001, J COMPUT BIOL, V8, P557, DOI 10.1089/106652701753307485; Rocke DM, 2003, BIOINFORMATICS, V19, P966, DOI 10.1093/bioinformatics/btg107; Schadt EE, 2001, J CELL BIOCHEM, V84, P120, DOI 10.1002/jcb.10073; Simon RM, 2003, DESIGN ANAL DNA MICR; Speed T, 2003, STAT ANAL GENE EXPRE; Tseng GC, 2001, NUCLEIC ACIDS RES, V29, P2549, DOI 10.1093/nar/29.12.2549; Wolfinger RD, 2001, J COMPUT BIOL, V8, P625, DOI 10.1089/106652701753307520; Yang YH, 2002, NUCLEIC ACIDS RES, V30, DOI 10.1093/nar/30.4.e15; Yang YH, 2003, INST MATH S, V40, P403	23	5	6	SCHATTAUER GMBH-VERLAG MEDIZIN NATURWISSENSCHAFTEN	STUTTGART	HOLDERLINSTRASSE 3, D-70174 STUTTGART, GERMANY	0026-1270			METHOD INFORM MED	Methods Inf. Med.		2005	44	3					418	422				5	Computer Science, Information Systems; Health Care Sciences & Services; Medical Informatics	Computer Science; Health Care Sciences & Services; Medical Informatics	948RY	WOS:000230734600012	16113767	
J	Markowetz, F; Spang, R				Markowetz, F; Spang, R			Molecular diagnosis - Classification, model selection and performance evaluation	METHODS OF INFORMATION IN MEDICINE			English	Article						microarrays; statistical classification; generalization error; model assessment; gene selection	GENE-EXPRESSION DATA; SHRUNKEN CENTROIDS; BREAST-CANCER; PREDICTION; VALIDATION; REGRESSION; DISCOVERY; LEUKEMIA	Objectives. We discuss supervised classification techniques applied to medical diagnosis based on gene expression profiles. Our focus lies on strategies of adaptive model selection to avoid overfitting in high-dimensional spaces. Methods: We introduce likelihood-based methods, classification trees, support vector machines and regularized binary regression. For regularization by dimension reduction, we describe feature selection methods: feature filtering, feature shrinkage and wrapper approaches. In small sample-size situations efficient methods of data re-use are needed to assess the predictive power of a model. We discuss two issues in using cross-validation: the difference between in-loop and out-of-loop feature selection, and estimating model parameters in nested-loop cross-validation. Results: Gene selection does not reduce the dimensionality of the model. Tuning parameters enable adaptive model selection. The feature selection bias is a common pitfall in performance evaluation. Model selection and performance evaluation can be combined by nested-loop cross-validation. Conclusions. Classification of microarrays is prone to overfitting. A rigorous and unbiased assessment of the predictive power of the model is a must.	Max Planck Inst Mol Genet, Computat Diagnost Grp, D-14195 Berlin, Germany	Markowetz, F (reprint author), Max Planck Inst Mol Genet, Computat Diagnost Grp, Ihnestr 63-73, D-14195 Berlin, Germany.	florian.markowetz@molgen.mpg.de					Altman DG, 2000, STAT MED, V19, P453, DOI 10.1002/(SICI)1097-0258(20000229)19:4<453::AID-SIM350>3.3.CO;2-X; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; BISHOP C.M., 1995, NEURAL NETWORKS PATT; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cheok MH, 2003, NAT GENET, V34, P85, DOI 10.1038/ng1151; Duda R.O., 2001, PATTERN CLASSIFICATI; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Eilers PHC, 2001, P SOC PHOTO-OPT INS, V2, P187; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Gelman A., 2003, BAYESIAN DATA ANAL; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hastie T, 2004, J MACH LEARN RES, V5, P1391; Hastie T., 2001, ELEMENTS STAT LEARNI; Hochreiter S., 2004, KERNEL METHODS COMPU; Huang E, 2003, RECENT PROG HORM RES, V58, P55, DOI 10.1210/rp.58.1.55; Jager J., 2003, P PAC S BIOC, P53; Johnson V., 1999, ORDINAL DATA MODELIN; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Krishnapuram B., 2004, KERNEL METHODS COMPU; R Development Core Team, 2004, R LANG ENV STAT COMP; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Ransohoff DF, 2004, NAT REV CANCER, V4, P309, DOI 10.1038/nrc1322; Ripley BD, 1996, PATTERN RECOGNITION; ROTH V, 2004, IEEE T NEURAL NETWOR, V15; Scholkopf B., 2001, LEARNING KERNELS; SIMON R, 2003, J NATL CANC I, V95; Spang Rainer, 2002, In Silico Biology, V2, P369; Tibshirani R, 2003, STAT SCI, V18, P104, DOI 10.1214/ss/1056397488; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik VN, 1995, NATURE STAT LEARNING; West M, 2001, P NATL ACAD SCI USA, V98, P11462, DOI 10.1073/pnas.201162998; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	39	28	28	SCHATTAUER GMBH-VERLAG MEDIZIN NATURWISSENSCHAFTEN	STUTTGART	HOLDERLINSTRASSE 3, D-70174 STUTTGART, GERMANY	0026-1270			METHOD INFORM MED	Methods Inf. Med.		2005	44	3					438	443				6	Computer Science, Information Systems; Health Care Sciences & Services; Medical Informatics	Computer Science; Health Care Sciences & Services; Medical Informatics	948RY	WOS:000230734600015	16113770	
S	Rouil, R; Chevrollier, N; Golmie, N			IEEE	Rouil, Richard; Chevrollier, Nicolas; Golmie, Nada			Unsupervised anomaly detection system using next-generation router architecture	MILCOM 2005 - 2005 IEEE MILITARY COMMUNICATIONS CONFERENCE, VOLS 1-5	IEEE Military Communications Conference		English	Proceedings Paper	IEEE Military Communications Conference (MILCOM 2005)	OCT, 2005	Atlantic City, NJ	IEEE				Unlike many intrusion detection systems that rely mostly on labeled training data, we propose a novel technique for anomaly detection based on unsupervised learning. We apply this technique to counter denial-of-service attacks. Initial simulation results suggest that significant improvements can be obtained. We discuss an implementation of our anomaly detection system in the ForCES router architecture and evaluate it using recorded attack traffic.	Natl Inst Stand & Technol, Gaithersburg, MD 20899 USA	Rouil, R (reprint author), Natl Inst Stand & Technol, Gaithersburg, MD 20899 USA.						BLACKERT WJ, 2003, P DISCEX 3, P22; CHEVROLLIER N, 2004, P CISS PRINC NJ MARC; ESKIN E, 2002, DATA MINING SECURITY; Hastie T., 2001, ELEMENTS STAT LEARNI; HUSSAIN A, 2003, ACM SIGCOMM 03 KARSL; MAHAJAN R, 2002, COMPUTER COMMUNICATI, V32; MIRKOVIC J, CSDTR020018; MIRKOVIC J, 2003, THESIS; Paxson V, 1999, COMPUT NETW, V31, P2435, DOI 10.1016/S1389-1286(99)00112-7; Savage S., 2000, P 2000 ACM SIGCOMM C, P295, DOI DOI 10.1145/347057.347560; ZANERO S, 2004, P 2004 ACM S APPLCOM	11	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2155-7578		0-7803-9393-7	IEEE MILIT COMMUN C			2005							1654	1659				6	Telecommunications	Telecommunications	BFL76	WOS:000242920502050		
B	Cortez, P; Portelinha, M; Rodrigues, S; Cadavez, V; Teixeira, A		FelizTeixeira, JM; Brito, AEC		Cortez, P; Portelinha, M; Rodrigues, S; Cadavez, V; Teixeira, A			Lamb meat tenderness prediction using neural networks and sensitivity analysis	Modelling and Simulation 2005			English	Proceedings Paper	European Simulation and Modelling Conference (ESM 2005)	OCT 24-26, 2005	Oporto, PORTUGAL	Ghent Univ, DII, Seconda Univ Studi Napoli, ISA, Porto Camera Municipal, SIMULA	Univ Porto	regression; multilayer perceptrons; multiple regression; meat quality; ensembles; data mining		The assessment of quality is a key factor for the meat industry. where the aim is to fulfill the consumer's needs. In particular, tenderness is considered the most important characteristic affecting consumer perception of taste. In this paper, a Neural Network Ensemble, with feature selection based on a Sensitivity Analysis procedure, is proposed to predict lamb meat tenderness. This difficult real-world problem is defined in terms of two regression tasks, by using instrumental measurements and a sensory panel. In both cases, the proposed solution Outperformed other neural approaches and the Multiple Regression method.	Univ Minho, Dept Sistemas Informacao, P-4800058 Guimaraes, Portugal	Cortez, P (reprint author), Univ Minho, Dept Sistemas Informacao, P-4800058 Guimaraes, Portugal.		Cortez, Paulo/A-2674-2008; Cadavez, Vasco/A-3958-2010; Teixeira, Alfredo/G-4118-2011; Rodrigues, Sandra/C-6486-2008	Cortez, Paulo/0000-0002-7991-2090; Cadavez, Vasco/0000-0002-3077-7414; Teixeira, Alfredo/0000-0003-4607-4796; Rodrigues, Sandra/0000-0003-3301-1729			Arvanitoyannis IS, 2003, CRIT REV FOOD SCI, V43, P173, DOI 10.1080/10408690390826482; Dietterich T.G., 2001, LNCS, V1857, P1; DIEZ J, 2004, P EUR C ART INT ECAI, P993; Efron Bradley, 1993, INTRO BOOTSTRAP; Hastie T., 2001, ELEMENTS STAT LEARNI; Haykin S., 1999, NEURAL NETWORKS COMP; HILL B, 2000, CANADIAN J ANIMAL SC, P311; HUFFMAN K, 1997, J ANIM SCI, V74, P91; Kewley RH, 2000, IEEE T NEURAL NETWOR, V11, P668, DOI 10.1109/72.846738; R Development Core Team, 2004, R LANG ENV STAT COMP; Turban E., 2004, DECISION SUPPORT SYS; Venables W.N., 2002, MODERN APPL STAT S	12	0	0	EUROSIS	GHENT	GHENT UNIV, COUPURE LINKS 653, GHENT, B-9000, BELGIUM			90-77381-22-8				2005							177	181				5	Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering; Mathematics, Interdisciplinary Applications	Computer Science; Mathematics	BDU79	WOS:000235515700028		
J	Accad, A; Choy, SL; Pullar, D; Rochester, W		Zerger, A; Argent, RM		Accad, A.; Choy, S. Low; Pullar, D.; Rochester, W.			Bioregion Classification Using Model-Based Clustering: A Case Study In North Eastern Queensland	MODSIM 2005: INTERNATIONAL CONGRESS ON MODELLING AND SIMULATION: ADVANCES AND APPLICATIONS FOR MANAGEMENT AND DECISION MAKING: ADVANCES AND APPLICATIONS FOR MANAGEMENT AND DECISION MAKING			English	Proceedings Paper	International Congress on Modelling and Simulation (MODSIM05)	DEC 12-15, 2005	Melbourne, AUSTRALIA			biogeography; bioregions; subregion; statistical modelling; GIS; finite mixture models; clustering	INFERENCE	The Interim Biogeographic Regionalisation of Australia (IBRA; Environment Australia, 2000) is a planning framework defining land areas comprised of interacting ecosystems repeated across the landscape. In many states these bioregions are currently arrived at by consensus of an expert panel (Neldner et al. 2004) and well accepted as a spatial unit for planning and environmental management. This work was motivated by the need to define these regions in a scientifically defensible way to justify any decisions made on the basis that they are representative of broad environmental assets. The present bioregional boundaries of Queensland version 4.3 are shown in Figure 1. The case study is situated in North Eastern Queensland in an area where a boundary change was proposed. This research investigates at the meso-scale the success of broad climate and soil variables in identifying patterns and processes. We report results based on three bioclimate and soil variables, suggested through exploratory analysis and model sensitivity: temperature seasonality (bc04); annual precipitation (bc12); and B horizon available water holding capacity (baw). This paper compares a range of statistical methods for bioregion classification, within a continuum of data-driven to expert-driven, including Bayesian methods. Model-based clustering moves away from traditional methods which delineate boundaries, instead assessing similarity between and within geographic regions and environmental envelopes. Bayesian statistical modelling enables explicit input of expert prior knowledge during development of bioregions. We assessed two alternative prior knowledge bases: vegetation communities or existing bioregion boundaries. In data poor areas expert defined boundaries are feasible, but subjective. Vegetation-based priors can be considered more objective, although they require subjective identification of communities, and are a useful alternative to expert boundaries. This study confirmed that experts contribute knowledge beyond what is currently mapped on bioclimate and soils. The Bayesian model-based approach has significant benefits in assessing impact of different types of expert knowledge for bioregions-either mapped communities or boundaries-as well as for quantifying precision of modelled regions. Practically we found that the Frequentist model-based approach was useful in initial stages of modelling. The distance-metric based approaches to clustering though relatively simple to implement provide qualitatively different boundaries, and require an unwieldy process for obtaining predictions, for which no assessment of uncertainty is available. For bioregionalisation of new areas, expert-defined boundaries may still play a role, although this has now been demonstrated to be more useful when combined with bioclimate and soils datasets in a Bayesian framework. In data-rich areas, the Frequentist model-based approach may suffice. [GRAPHICS] .	[Accad, A.] US EPA, Queensland Herbarium, Brisbane, Qld, Australia	Accad, A (reprint author), US EPA, Queensland Herbarium, Brisbane, Qld, Australia.	arnon.accad@epa.qld.gov.au	Low Choy, Samantha/A-7161-2012	Low Choy, Samantha/0000-0002-1722-4428			AUSTIN M, 2002, ECOLOGICAL MODELLING, V57, P101; Bensmail H, 1997, STAT COMPUT, V7, P1, DOI 10.1023/A:1018510926151; CHOY SJL, 2005, BAYESIAN MODEL UNPUB; Ellison AM, 1996, ECOL APPL, V6, P1036, DOI 10.2307/2269588; Environment Australia, 2000, REV INT BIOG REG AUS; Fraley C., 2002, MCLUST SOFTWARE MODE; Hartigan J.A., 1975, CLUSTERING ALGORITHM; Hastie T., 2001, ELEMENTS STAT LEARNI; KYNN M, 2005, THESIS QUT; Neldner V. J., 2004, METHODOLOGY SURVEY M; Neldner VJ, 1995, VEGETATION SURVEY MA; PULLAR D, 2005, DATA ANAL METH UNPUB; Rochester W, 2004, FINAL REPORT UQ EPA; Sattler P. S., 1999, CONSERVATION STATUS; Venables WN, 1994, MODERN APPL STAT S P	15	3	3	UNIV WESTERN AUSTRALIA	NEDLANDS	NEDLANDS, WA, AUSTRALIA			978-0-9758400-2-3				2005							1326	1332				7	Computer Science, Interdisciplinary Applications; Operations Research & Management Science; Mathematics, Applied; Mathematics, Interdisciplinary Applications	Computer Science; Operations Research & Management Science; Mathematics	BUQ81	WOS:000290114101054		
S	Bazan, J; Skowron, A		DuninKeplicz, B; Jankowski, A; Skowron, A; Szczuka, M		Bazan, J; Skowron, A			Classifiers based on approximate reasoning schemes	Monitoring, Security, and Rescue Techniques in Multiagent Systems	ADVANCES IN SOFT COMPUTING		English	Proceedings Paper	International Workshop on Monitoring, Security, and Rescue Techniques in Multiagent Systems	JUN 07-09, 2004	Plock, POLAND					We discuss classifiers [3] for complex concepts constructed from data sets and domain knowledge using approximate reasoning schemes (AR schemes). The approach is based on granular computing methods developed using rough set and rough mereological approaches [9, 13, 7]. In experiments we use a road simulator (see [15]) making it possible to collect data, e.g., on vehicle-agents movement on the road, at the crossroads, and data from different sensor-agents. We compare the quality of two classifiers: the standard rough set classifier based on the set of minimal decision rules and the classifier based on AR schemes.	Univ Rzeszow, Inst Math, PL-35959 Rzeszow, Poland	Bazan, J (reprint author), Univ Rzeszow, Inst Math, Rejtana 16A, PL-35959 Rzeszow, Poland.						BAZAN J, 1998, COMPARISON DYNAMIC N, P321; Bazan J, 2003, LECT NOTES ARTIF INT, V2639, P181; Friedman J., 2001, ELEMENTS STAT LEARNI; KLOESGEN W, 2002, HDB KDD; Michie D., 1994, MACHINE LEARNING NEU; PAL SK, 2004, ROUGH NEURO COMPUTIN; Pawlak Z., 1991, ROUGH SETS THEORETIC; POLKOWSKI L, 1998, ROUGH SETS KNOWLED 2, P1; Polkowski L, 2000, STUD FUZZ SOFT COMP, V56, P89; POLKOWSKI L, 1999, ADAPTIVE CALCULUS GR, P201; SKOWRON A, 2002, INFORMATION GRANULES, P43; Skowron A, 2001, INT J INTELL SYST, V16, P57, DOI 10.1002/1098-111X(200101)16:1<57::AID-INT6>3.0.CO;2-Y; Skowron A., 2001, B INT ROUGH SET SOC, V5, P9; Stone P., 2000, LAYERED LEARNING MUL; ZADEH L, 1999, COMPUTING WORDS INFO, P1	15	20	20	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1615-3871		3-540-23245-1	ADV SOFT COMP			2005							191	202		10.1007/3-540-32370-8_13		12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCA70	WOS:000228476800013		
S	Marszal-Paszek, B; Paszek, P		DuninKeplicz, B; Jankowski, A; Skowron, A; Szczuka, M		Marszal-Paszek, B; Paszek, P			Extracting minimal templates in a decision table	Monitoring, Security, and Rescue Techniques in Multiagent Systems	ADVANCES IN SOFT COMPUTING		English	Proceedings Paper	International Workshop on Monitoring, Security, and Rescue Techniques in Multiagent Systems	JUN 07-09, 2004	Plock, POLAND			templates; rough sets; evidence theory		In 1991 there were defined basic functions of the evidence theory based on the concepts of the rough set theory. In this paper we use these functions in specifying minimal templates of decision tables. The problem of finding such templates is NP-hard. Hence, we propose some heuristics based on genetic algorithms.	Silesian Univ, Inst Comp Sci, PL-41200 Sosnowiec, Poland	Marszal-Paszek, B (reprint author), Silesian Univ, Inst Comp Sci, Bedzinska 39, PL-41200 Sosnowiec, Poland.						Friedman J., 2001, ELEMENTS STAT LEARNI; Pawlak Z., 1991, ROUGH SETS THEORETIC; Shafer G., 1976, MATH THEORY EVIDENCE; Skowron A., 1994, ADV DEMPSTER SHAFER, P193	4	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1615-3871		3-540-23245-1	ADV SOFT COMP			2005							339	344		10.1007/3-540-32370-8_27		6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCA70	WOS:000228476800027		
S	Nishida, K; Kurita, T		Oza, NC; Polikar, R; Kittler, J; Roli, F		Nishida, K; Kurita, T			Boosting soft-margin SVM with feature selection for pedestrian detection	MULTIPLE CLASSIFIER SYSTEMS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th Intenational Workshop on Multiple Classifier Systems	JUN 13-15, 2005	Seaside, CA	NASA Ames Res Ctr, Intelligent Syst Div, Rowan Univ, Dept Elect & Comp Engn, Puresence Environm, Int Assoc Pattern Recognit, IAPR Tech Comm TC1				We present an example-based algorithm for detecting objects in images by integrating component-based classifiers, which automaticaly select the best feature for each classifier and are combined according to the AdaBoost algorithm. The system employs a soft-margin SVM for the base learner, which is trained for all features and the optimal feature is selected at each stage of boosting. We employed two features such as a histogram-equalization and an edge feature in our experiment. The proposed method was applied to the MIT CBCL pedestrian image database, and 100 sub-regions were extracted from each image as local-features. The experimental results showed fairly good classification ratio with selecting sub-regions, while some improvement attained by combining the two features, histogram-equalization and edge. However, the combination of features could to select good local-features for base learners.	AIST, Neurosci Res Inst, Tsukuba, Ibaraki 3058568, Japan	Nishida, K (reprint author), AIST, Neurosci Res Inst, Cent 2,1-1-1 Umezono, Tsukuba, Ibaraki 3058568, Japan.	kenji.nishida@aist.go.jp	Kurita, Takio/D-8674-2012	Kurita, Takio/0000-0003-3982-6750			chung Chang C., 2001, LIBSVM LIB SUPPORT V; Cristianini N, 2000, INTRO SUPPORT VECTOR; GAVLIRA DM, 2000, P EUR C COMP VIS, P37; Hastie T., 2001, ELEMENTS STAT LEARNI; Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571; Scholkopf Bernard, 1999, ADV KERNEL METHODS S; SCHWENK H, 2000, NEURAL COMPUT, V12, P1889; SHAPIRE RE, 2002, MRSI WORKSH NONLINEA; VAPNIK B, 1998, STAT LEARNING THEORY; Viola P., 2003, Proceedings Ninth IEEE International Conference on Computer Vision	10	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-26306-3	LECT NOTES COMPUT SC			2005	3541						22	31				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCN51	WOS:000230171500003		
S	Chen, L; Kamel, MS		Oza, NC; Polikar, R; Kittler, J; Roli, F		Chen, L; Kamel, MS			Design of multiple classifier systems for time series data	MULTIPLE CLASSIFIER SYSTEMS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th Intenational Workshop on Multiple Classifier Systems	JUN 13-15, 2005	Seaside, CA	NASA Ames Res Ctr, Intelligent Syst Div, Rowan Univ, Dept Elect & Comp Engn, Puresence Environm, Int Assoc Pattern Recognit, IAPR Tech Comm TC1				In previous work, we showed that the use of Multiple Input Representation(MIR) for the classification of time series data provides complementary information that leads to better accuracy. [4]. In this paper, we introduce the Static Minimization-Maximization approach to build Multiple Classifier Systems(MCSs) using MIR. SMM consists of two steps. In the minimization step, a greedy algorithm is employed to iteratively select the classifiers from the knowledge space to minimize the training error of MCSs. In the maximization step, a modified version of Behavior Knowledge Space(BKS), Balanced Behavior Knowledge Space(BBKS), is used to maximize the expected accuracy of the whole system given that the training error is minimized. Several popular techniques including AdaBoost, Bagging and Random Subspace are used as the benchmark to evaluate the proposed approach on four time series data sets. The results obtained from our experiments show that the performance of the proposed approach is effective as well as robust for the classification of time series data. In addition, this approach could be further extended to other applications in our future research.	Univ Waterloo, Pattern Anal & Machine Intelligence Lab, Waterloo, ON N2L 3G1, Canada	Chen, L (reprint author), Univ Waterloo, Pattern Anal & Machine Intelligence Lab, Waterloo, ON N2L 3G1, Canada.		Kamel, Mohamed/D-9323-2011				Breiman L., 1993, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chen L, 2004, LECT NOTES COMPUT SC, V3077, P134; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Diez JJR, 2000, LECT NOTES COMPUT SC, V1857, P210; Duda R. O., 2000, PATTERN CLASSIFICATI; GHOSH J, 1992, SPIE P, V1706, P266; GHOSH J, 1992, IEEE J OCEANIC ENG, V17, P351, DOI 10.1109/48.180304; GIANCINTO G, 2001, PATTERN RECOGN, V34, P1879; GONZALEZ CJA, 2000, REV IBEROAMERICANA I, V11, P2; Hastie T., 2001, ELEMENTS STAT LEARNI; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; HSU WH, 1999, P INT JOINT C NEUR N, V3, P1574; HUANG YS, 1995, IEEE T PATTERN ANAL, V17, P90, DOI 10.1109/34.368145; Saito N, 1994, THESIS YALE U; SANCHO Q, 2001, ARTIFICIAL NEURAL NE, P43	17	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-26306-3	LECT NOTES COMPUT SC			2005	3541						216	225				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCN51	WOS:000230171500022		
S	Prior, M; Windeatt, T		Oza, NC; Polikar, R; Kittler, J; Roli, F		Prior, M; Windeatt, T			Over-fitting in ensembles of neural network classifiers within ECOC frameworks	MULTIPLE CLASSIFIER SYSTEMS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th Intenational Workshop on Multiple Classifier Systems	JUN 13-15, 2005	Seaside, CA	NASA Ames Res Ctr, Intelligent Syst Div, Rowan Univ, Dept Elect & Comp Engn, Puresence Environm, Int Assoc Pattern Recognit, IAPR Tech Comm TC1			ERROR	We have investigated the performance of a generalisation error predictor, G(est), in the context of error correcting output coding ensembles based on multi-layer perceptrons. An experimental evaluation on benchmark datasets with added classification noise shows that over-fitting can be detected and a comparison is made with the Q measure of ensemble diversity. Each dichotomy associated with a column of an ECOC code matrix is presented with a bootstrap sample of the training set. G(est) uses the out-of-bootstrap samples to efficiently estimate the mean column error for the independent test set and hence the test error. This estimate can then be used select a suitable complexity for the base classifiers in the ensemble.	Univ Surrey, CVSSP, Guildford GU2 5XH, Surrey, England	Prior, M (reprint author), Univ Surrey, CVSSP, Guildford GU2 5XH, Surrey, England.	m.prior@surrey.ac.uk; t.windeatt@surrey.ac.uk					BANFIELD R, 2003, P MCS 4 INT WORKSH G; BERGER B, 1999, IJCAI 99; BISHOP C.M., 1995, NEURAL NETWORKS PATT; BREIMAN L, 1994, 421 U CAL BERK; Bylander T, 2002, MACH LEARN, V48, P287, DOI 10.1023/A:1013964023376; DIETTERICH T, 1995, J ARTIFICIAL INTELLI, V2, P236; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; EFRON B, 1993, MONOGRAPHS STAT APPL, V57, P47; Ghani R., 2000, P 17 INT C MACH LEAR, P303; Hastie T., 2001, ELEMENTS STAT LEARNI; JAMES G, 1998, THEORY STANFORD U; James G, 1998, J COMPUT GRAPH STAT, V7, P377, DOI 10.2307/1390710; KUNCHEVA L, 2002, MACH LEARN, V51, P187; PAASS G, 1993, ADV NEURAL INFORMATI, V5, P196; Rifkin R, 2004, J MACH LEARN RES, V5, P101; Windeatt T, 2003, PATTERN RECOGN, V36, P2743, DOI 10.1016/S0031-3203(03)00191-2; Windeatt T., 2003, Information Fusion, V4, DOI 10.1016/S1566-2535(02)00101-X; WINSTON W, 1994, OPERATIONS RES APPL, P628	18	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-26306-3	LECT NOTES COMPUT SC			2005	3541						286	295				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCN51	WOS:000230171500029		
S	Okanohara, D; Tsujii, J		Dale, R; Wong, KF; Su, J; Kwong, OY		Okanohara, D; Tsujii, J			Assigning polarity scores to reviews using machine learning techniques	NATURAL LANGUAGE PROCESSING - IJCNLP 2005, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	2nd International Joint Conference on Natural Language Processing	OCT 11-13, 2005	Jeju Isl, SOUTH KOREA	Jeju Provine Local Govt, Korea Adv Inst Sci & Technol, Korea Inst Sci & Technol Informat, Elet & Telecomm Res Inst, Microsoft Korea, Microsoft Japan, Mobico & Sysmeta				We propose a novel type of document classification task that quantifies how much a given document (review) appreciates the target object using not binary polarity (good or bad) but a continuous measure called sentiment polarity score (sp-score). An sp-score gives a very concise summary of a review and provides more information than binary classification. The difficulty of this task lies in the quantification of polarity. In this paper we use support vector regression (SVR) to tackle the problem. Experimentson book reviews with five-point scales show that SVR outperforms a multi-class classification method using support vector machines and the results are close to human performance.	Univ Tokyo, Dept Comp Sci, Bunkyo Ku, Tokyo 1130013, Japan; Univ Manchester, Sch Informat, Manchester M60 1QD, Lancs, England	Okanohara, D (reprint author), Univ Tokyo, Dept Comp Sci, Bunkyo Ku, Hongo 7-3-1, Tokyo 1130013, Japan.	hillbig@is.s.u-tokyo.ac.jp; tsujii@is.s.u-tokyo.ac.jp					APTE C, 1994, INFORM SYST, V12, P233; Cristianini N, 2000, INTRO SUPPORT VECTOR; Hastie T., 2001, ELEMENTS STAT LEARNI; Herbrich R, 2000, ADV NEUR IN, P115; Joachims T., 2002, LEARNING CLASSIFY TE; KOPPEL M, 2005, WORKSH AN INF FORM I; KRESEL U, 1999, PAIRWISE CLASSIFICAT; Kudo T., 2004, P 2004 C EMP METH NA, P301; LEWIS K, 1992, CAREER DEV EXCEPTION, V15, P37; MULLEN A, 2004, P 42 M ASS COMP LING; Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79; PANG B, 2005, P 43 M ASS COMP LING; Pang B., 2004, P 42 ANN M ASS COMP, P271, DOI DOI 10.3115/1218955.1218990; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Smola' AJ, 1998, NC2TR1998030; Sorace A, 2005, LINGUA, V115, P1497, DOI 10.1016/j.lingua.2004.07.002; Taskar B., 2004, THESIS STANFORD U; TSOCHANTARIDIS I, 2004, MACH LEARN P 21 INT; Turney P., 2002, P 40 ANN M ASS COMP, P417, DOI DOI 10.3115/1073083.1073153; Vapnik VN, 1995, NATURE STAT LEARNING	21	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29172-5	LECT NOTES ARTIF INT			2005	3651						314	325				12	Computer Science, Artificial Intelligence	Computer Science	BDF92	WOS:000233302600028		
S	El Khayat, I; Geurts, P; Leduc, G		Boutaba, R; Almeroth, K; Puigjaner, R; Shen, S; Black, JP		El Khayat, I; Geurts, P; Leduc, G			Improving TCP in wireless networks with an adaptive machine-learnt classifier of packet loss causes	NETWORKING 2005: NETWORKING TECHNOLOGIES, SERVICES, AND PROTOCOLS; PERFORMANCE OF COMPUTER AND COMMUNICATION NETWORKS; MOBILE AND WIRELESS COMMUNICATIONS SYSTEMS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	4th International IFIP-TC6 Networking Conference	MAY 02-06, 2005	Waterloo, CANADA	Bell Canada, Res Motion, Sun Microsyst, IFIP, Int Federat Informat Proc, Tech Comm 6 Commun Syst, Univ Waterloo, Nortel Networks Inst, Software Telecommun Grp				TCP understands all packet losses as buffer overflows and reacts to such congestions by reducing its rate. In hybrid wired/wireless networks where a non negligible number of packet losses are due to link errors, TCP is unable to sustain a reasonable rate. In this paper, we propose to extend TCP Newreno with a packet loss classifier built by a supervised learning algorithm called 'decision tree boosting'. The learning set of the classifier is a database of 25,000 packet loss events in a thousand of random topologies. Since a limited percentage of wrong classifications of congestions as link errors is allowed to preserve TCP-Friendliness, our protocol computes this constraint dynamically and tunes a parameter of the classifier accordingly to maximise the TCP rate. Our classifier outperforms the Veno and Westwood classifiers by achieving a higher rate in wireless networks while remaining TCP-Friendly.	Univ Liege, Dept Elect Engn & Comp Sci, Inst Montefiore, B-4000 Liege, Belgium	El Khayat, I (reprint author), Univ Liege, Dept Elect Engn & Comp Sci, Inst Montefiore, B28,Sart Tilman, B-4000 Liege, Belgium.						Bakre A., 1995, P 15 INT C DISTR COM; BIAZ S, 1998, P IC3N NEW ORL; Breiman L., 1984, CLASSIFICATION REGRE; ELKHAYAT I, 2005, UNPUB ENHANCEMENT TC; Floyd S., 2000, P ACM SIGCOMM STOCKH, P43, DOI 10.1145/347059.347397; FLOYD S, 2001, IEEE COMMUNICATI APR, V39; Freund Y., 1995, P 2 EUR C COMP LEARN, P23; Fu CP, 2003, IEEE J SEL AREA COMM, V21, P216, DOI 10.1109/JSAC.2002.807336; GEURTS P, 2004, P IEEE INT C DAT MIN, P383; Gurtov A, 2004, ACM SIGCOMM COMP COM, V34, P85, DOI 10.1145/997150.997159; Hastie T., 2001, ELEMENTS STAT LEARNI; LIU J, 2003, MODELING OPTIMIZATIO; Medina A., 2000, BRITE FLEXIBLE GENER; Padhye J, 2000, IEEE ACM T NETWORK, V8, P133, DOI 10.1109/90.842137; WANG R, 2002, P 7 IEEE S COMP COMM	15	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-25809-4	LECT NOTES COMPUT SC			2005	3462						549	560				12	Computer Science, Information Systems; Computer Science, Theory & Methods; Telecommunications	Computer Science; Telecommunications	BCN18	WOS:000230113900044		
J	Micchelli, CA; Pontil, M				Micchelli, CA; Pontil, M			On learning vector-valued functions	NEURAL COMPUTATION			English	Article								In this letter, we provide a study of learning in a Hilbert space of vector-valued functions. We motivate the need for extending learning theory of scalar-valued functions by practical considerations and establish some basic results for learning vector-valued functions that should prove useful in applications. Specifically, we allow an output space gamma to be a Hilbert space, and we consider a reproducing kernel Hilbert space of functions whose values lie in gamma. In this setting, we derive the form of the minimal norm interpolant to a finite set of data and apply it to study some regularization functionals that are important in learning theory. We consider specific examples of such functionals corresponding to multiple-output regularization networks and support vector machines, for both regression and classification. Finally, we provide classes of operator-valued kernels of the dot product and translation-invariant type.	SUNY Albany, Dept Math & Stat, Albany, NY 12222 USA; UCL, Dept Comp Sci, London WC1E, England	Micchelli, CA (reprint author), SUNY Albany, Dept Math & Stat, Albany, NY 12222 USA.	charles_Micchelli@hotmail.com; m.pontil@cs.uclac.uk					Akhiezer N. I., 1993, THEORY LINEAR OPERAT, V1; AMODEI L, 1997, CURVES SURFACES P CH; ARONSZAJN N, 1950, T AM MATH SOC, V68, P337; BALDI P, 2002, ARTIFICIAL INTELLIGE; Bennett K, 2003, ADV LEARNING THEORY, P227; BENNETT KP, 1993, OPTIMIZATION METHODS, V3, P722; Berberian S., 1966, NOTES SPECTRAL THEOR; Beymer D, 1996, SCIENCE, V272, P1905, DOI 10.1126/science.272.5270.1905; Breiman L, 1997, J ROY STAT SOC B MET, V59, P3, DOI 10.1111/1467-9868.00054; Burbea J., 1984, BANACH HILBERT SPACE; Cherkassky V., 1998, LEARNING DATA CONCEP; CORNFORD D, 2004, J ROYAL STAT SOC B, V66, P1; Crammer K., 2001, J MACHINE LEARNING R, V2, P265; Cressie N. A., 1993, STAT SPATIAL DATA; Cristianini N, 2000, INTRO SUPPORT VECTOR; Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316; EVGENIOU T, 2004, P 10 ACM SIGKOD INT; Fillmore P. A., 1970, NOTES OPERATOR THEOR; FITZGERALD CH, 1995, LINEAR ALGEBRA APPL, V221, P83, DOI 10.1016/0024-3795(93)00232-O; Franke U, 1998, IEEE INTELL SYST APP, V13, P40, DOI 10.1109/5254.736001; Hastie T., 2002, ELEMENTS STAT LEARNI; Mangasarian O. L., 1994, NONLINEAR PROGRAMMIN; MELKMAN AA, 1979, SIAM J NUMER ANAL, V16, P87, DOI 10.1137/0716007; MICCHELLI CA, 2004, P 17 ANN C LEARN THE; MICCHELLI CA, 2003, RN0308 U COLL LOND D; MICCHELLI CA, 1995, MATH ASPECTS GEOMETR; Rosipal R., 2001, J MACHINE LEARNING R, V2, P97; Scholkopf B, 2002, LEARNING KERNELS; Sejnowski T. J., 1987, Complex Systems, V1; Tikhonov A N, 1997, SOLUTIONS ILL POSED; Vapnik V., 1998, STAT LEARNING THEORY; Wahba G., 1990, SPLINES MODELS OBSER; Weston J., 1998, CSDTR9804 ROYAL HOLL; WESTON J, 2003, ADV NEURAL INFORMATI, V15; Williams CKI, 1998, IEEE T PATTERN ANAL, V20, P1342, DOI 10.1109/34.735807	35	67	69	MIT PRESS	CAMBRIDGE	55 HAYWARD STREET, CAMBRIDGE, MA 02142 USA	0899-7667			NEURAL COMPUT	Neural Comput.	JAN	2005	17	1					177	204		10.1162/0899766052530802		28	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	893AM	WOS:000226691300009	15563752	
J	Rossi, F; Conan-Guez, B				Rossi, F; Conan-Guez, B			Functional multi-layer perceptron: a non-linear tool for functional data analysis	NEURAL NETWORKS			English	Article						functional data analysis; multi-layer perceptron; universal approximation; supervised learning; curves discrimination; learning consistency; non-linear functional model; spectrometric data	NEURAL-NETWORK APPROXIMATION; SLICED INVERSE REGRESSION; FEEDFORWARD NETWORKS; DIMENSION REDUCTION; LINEAR-MODEL; CURVES	In this paper, we study a natural extension of multi-layer perceptrons (MLP) to functional inputs. We show that fundamental results for classical MLP can be extended to functional MLP. We obtain universal approximation results that show the expressive power of functional MLP is comparable to that of numerical MLP. We obtain consistency results, which imply that the estimation of optimal parameters for functional MLP is statistically well defined. We finally show on simulated and real world data that the proposed model performs in a very satisfactory way. (C) 2004 Elsevier Ltd. All rights reserved.	INRIA Rocquencourt, Projet AxIS, F-78153 Le Chesnay, France; Univ Paris 09, CEREMADE, UMR 7534, CNRS, F-75016 Paris, France	Rossi, F (reprint author), INRIA Rocquencourt, Projet AxIS, Domaine Voluceau,BP 105, F-78153 Le Chesnay, France.	fabtice.rossi@inria.fr; brieuc.conan-guez@inria.fr					Abraham C, 2003, SCAND J STAT, V30, P581, DOI 10.1111/1467-9469.00350; ANDREWS DWK, 1987, ECONOMETRICA, V55, P1465, DOI 10.2307/1913568; BESSE P, 2000, SCANDINAVIAN J STAT, V4, P673; BESSE P, 2004, IN PRESS APPL STOCHA; BESSE P, 2003, ANAL DONNEES HERMES, P167; Besse PC, 1997, COMPUT STAT DATA AN, V24, P255, DOI 10.1016/S0167-9473(96)00067-9; Breiman L., 1984, CLASSIFICATION REGRE; Cardot H, 2003, STAT SINICA, V13, P571; Cardot H, 1999, STAT PROBABIL LETT, V45, P11, DOI 10.1016/S0167-7152(99)00036-X; CHEN TP, 1995, IEEE T NEURAL NETWOR, V6, P911; Chen TP, 1998, NEURAL NETWORKS, V11, P981, DOI 10.1016/S0893-6080(98)00075-6; Cristianini N, 2000, INTRO SUPPORT VECTOR; Ferraty F, 2002, TEST, V11, P317, DOI 10.1007/BF02595710; FERRATY F, 2002, COMPUTATIONAL STAT, V17; Ferraty F, 2003, COMPUT STAT DATA AN, V44, P161, DOI 10.1016/S0167-9473(03)00032-X; Ferre L, 2003, STATISTICS, V37, P475, DOI 10.1080/0233188031000112845; Hastie T., 2001, ELEMENTS STAT LEARNI; HASTIE T, 1993, TECHNOMETRICS, V35, P140, DOI 10.2307/1269658; HORNIK K, 1993, NEURAL NETWORKS, V6, P1069; HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T; James GM, 2002, J ROY STAT SOC B, V64, P411, DOI 10.1111/1467-9868.00342; James GM, 2001, J ROY STAT SOC B, V63, P533, DOI 10.1111/1467-9868.00297; LESHNO M, 1993, NEURAL NETWORKS, V6, P861, DOI 10.1016/S0893-6080(05)80131-5; LI KC, 1991, J AM STAT ASSOC, V86, P316, DOI 10.2307/2290563; MARX BD, 1996, STAT MODELLING; Ramsay J. O., 1997, FUNCTIONAL DATA ANAL; Rudin W., 1974, REAL COMPLEX ANAL; Sandberg IW, 1996, IEEE T CIRCUITS-I, V43, P600, DOI 10.1109/81.508182; Sandberg IW, 1996, CIRC SYST SIGNAL PR, V15, P711, DOI 10.1007/BF01190124; Stinchcombe MB, 1999, NEURAL NETWORKS, V12, P467, DOI 10.1016/S0893-6080(98)00108-7; White H., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.425	31	23	24	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080			NEURAL NETWORKS	Neural Netw.	JAN	2005	18	1					45	60		10.1016/j.neunet.2004.07.001		16	Computer Science, Artificial Intelligence	Computer Science	893FB	WOS:000226703600005	15649661	
J	Martin-Merino, M; Munoz, A				Martin-Merino, M; Munoz, A			Visualizing asymmetric proximities with SOM and MDS models	NEUROCOMPUTING			English	Article; Proceedings Paper	11th European Symposium on Artificial Neural Networks (ESANN)	APR, 2003	Bruges, BELGIUM			multidimensional scaling; self organizing maps; textual data analysis; asymmetric proximities; DNA microarray processing	SELF-ORGANIZATION	Multidimensional scaling (MDS) and self organizing maps (SOM) algorithms are useful to visualize object relationships in a data set. These algorithms rely on the use of symmetric distances or similarity measures; for instance the Euclidean distance. There are a number of relevant applications, such as text mining and DNA microarray processing for which it is worth considering non symmetric similarity measures, that allow us to properly represent hierarchical relationships. In this paper we present asymmetric versions of SOM and MDS algorithms able to deal with asymmetric proximity matrices. We also compare these approaches to the corresponding symmetric versions. Experimental work on text databases and gene expression data sets show that the asymmetric proposed algorithms outperform their symmetric counterparts. (C) 2004 Elsevier B.V. All rights reserved.	Univ Salamanca, Dept Comp Sci, Salamanca 37002, Spain; Univ Carlos III Madrid, Dept Stat, Madrid, Spain	Martin-Merino, M (reprint author), Univ Salamanca, Dept Comp Sci, C-Compania 5, Salamanca 37002, Spain.	mmerino@ieee.org; albmun@est-econ.uc3m.es					Aggarwal CC, 2002, IEEE T KNOWL DATA EN, V14, P210, DOI 10.1109/69.991713; BAEZAYATES R, 1999, MODERN INFORMATION B; Beyer K, 1999, LECT NOTES COMPUT SC, V1540, P217; BEZDEK JC, 1995, PATTERN RECOGN, V28, P381, DOI 10.1016/0031-3203(94)00111-X; BUJA A, 1994, ANN STAT, V22, P406, DOI 10.1214/aos/1176325376; BUJA A, 2003, UNPUB J COMPU GRAPHI; Chung YM, 2001, J AM SOC INF SCI TEC, V52, P283, DOI 10.1002/1532-2890(2000)9999:9999<::AID-ASI1073>3.3.CO;2-X; Constantine A. G., 1978, APPLIED STATISTICS, V27, P297, DOI 10.2307/2347165; Cox T. F., 2001, MULTIDIMENSIONAL SCA; CUTSEM BV, 1994, LECT NOTES STAT; DEANTONIO OR, 2002, THESIS U VALLADOLID; Goodhill GJ, 1997, NEURAL COMPUT, V9, P1291, DOI 10.1162/neco.1997.9.6.1291; Hastie T., 2001, ELEMENTS STAT LEARNI; Heskes T, 2001, IEEE T NEURAL NETWOR, V12, P1299, DOI 10.1109/72.963766; Kaufman L., 1990, INTRO CLUSTER ANAL; KIERS HAL, 1994, J CLASSIF, V11, P79, DOI 10.1007/BF01201024; Kohonen T, 1997, SELF ORG MAPS; Kohonen T, 2000, IEEE T NEURAL NETWOR, V11, P574, DOI 10.1109/72.846729; Konig A, 2000, IEEE T NEURAL NETWOR, V11, P615, DOI 10.1109/72.846733; Kopcsa A, 1998, J AM SOC INFORM SCI, V49, P7; Kosko B., 1991, NEURAL NETWORKS FUZZ; Lebart L, 1984, MULTIVARIATE DESCRIP; Martin-Merino M, 2001, LECT NOTES COMPUT SC, V2130, P429; MULIER F, 1995, NEURAL COMPUT, V7, P1165, DOI 10.1162/neco.1995.7.6.1165; Munoz A., 2002, P INT C TEXT DAT STA, P593; Munoz A, 2003, LECT NOTES COMPUT SC, V2714, P217; MUNOZ A, 1997, J INTELLIGENT DATA A, V1, P25; MUNOZ A, 2003, P EUR S ART NEUR NET, P51; MUNOZ A, 1994, THESIS; Okada A, 1997, J CLASSIF, V14, P195, DOI 10.1007/s003579900010; Pal NR, 1998, IEEE T NEURAL NETWOR, V9, P1142, DOI 10.1109/72.728358; Rorvig M, 1999, J AM SOC INFORM SCI, V50, P639, DOI 10.1002/(SICI)1097-4571(1999)50:8<639::AID-ASI2>3.0.CO;2-C; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; Strehl A., 2000, P AAAI WORKSH AI WEB, P58; Takane Y, 1997, J CLASSIF, V14, P225, DOI 10.1007/s003579900011; Wind Y., 1982, MARKET SCI, V1, P205, DOI 10.1287/mksc.1.2.205; Yang Y., 1997, P 14 INT C MACH LEAR, P412, DOI DOI 10.1016/J.ESWA.2008.05.026; Zielman B, 1996, BRIT J MATH STAT PSY, V49, P127	38	15	15	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312			NEUROCOMPUTING	Neurocomputing	JAN	2005	63						171	192		10.1016/j.neucom.2004.04.010		22	Computer Science, Artificial Intelligence	Computer Science	893FW	WOS:000226705700009		
S	Scarpa, B; Torelli, N		Vichi, M; Monari, P; Mignani, S; Montanari, A		Scarpa, B; Torelli, N			Selecting the training set in classification problems with rare events	New Developments in Classification and Data Analysis	STUDIES IN CLASSIFICATION, DATA ANALYSIS, AND KNOWLEDGE ORGANIZATION		English	Proceedings Paper	Meeting of the Classification and Data Analysis Group of the Italian-Statistical-Society	SEP 22-24, 2003	Bologna, ITALY	Italian Statist Soc, Classificat & Data Analy Grp	Univ Bologna			Binary classification algorithms are often used in situations when one of the two classes is extremely rare. A common practice is to oversample units of the rare class when forming the training set. For some classification algorithms, like logistic classification, there are theoretical results that justify such an approach. Similar results are not available for other popular classification algorithms like classification trees. In this paper the use of balanced datasets, when dealing with rare classes, for tree classifiers and boosting algorithms is discussed and results from analyzing a real dataset and a simulated dataset are reported.	Univ Pavia, Dipartimento Stat & Econ Appl, I-27100 Pavia, Italy	Scarpa, B (reprint author), Univ Pavia, Dipartimento Stat & Econ Appl, Via Palestro 3, I-27100 Pavia, Italy.						Berry M., 2000, MASTERING DATA MININ; COSSLETT SR, 1981, ECONOMETRICA, V49, P1289, DOI 10.2307/1912755; Hastie T., 2001, ELEMENTS STAT LEARNI; Japkowicz N., 2000, Proceedings of the International Conference on Artificial Intelligence. IC-AI'2000; JOSHI M, 2002, EVALUATING PERFORMAN; PRENTICE RL, 1979, BIOMETRIKA, V66, P403, DOI 10.1093/biomet/66.3.403; *SAS, 1998, SAS I BEST PRACT PAP	7	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1431-8814		3-540-23809-3	ST CLASS DAT ANAL			2005							39	46		10.1007/3-540-27373-5_5		8	Statistics & Probability	Mathematics	BCG02	WOS:000229183400005		
B	Mulvey, JM; Thompson, AJ		Golden, BL; Raghavan, S; Wasil, E		Mulvey, JM; Thompson, AJ			Statistical learning theory in equity return forecasting	NEXT WAVE IN COMPUTING, OPTIMIZATION, AND DECISION TECHNOLOGIES	OPERATIONS RESEARCH/COMPUTER SCIENCE INTERFACES SERIES		English	Proceedings Paper	9th INFORMS-Computing-Society Conference	JAN 05-07, 2005	Annapolis, MD	INFORMS Comp Soc		statistical learning theory; data mining; financial forecasting; financial optimization; market-neutral investing; hedge fund investing		We apply Mangasarian and Bennett's multi-surface method to the problem of allocating financial capital to individual stocks. The strategy constructs market neutral portfolios wherein capital exposure to long positions equals exposure to short positions at the beginning of each weekly period. The optimization model generates excess returns above the S&P 500, even in the presence of reasonable transaction costs. The trading strategy generates statistical arbitrage for trading costs below 10 basis points per transaction.	Princeton Univ, Bendheim Ctr Finance, Princeton, NJ 08544 USA	Mulvey, JM (reprint author), Princeton Univ, Bendheim Ctr Finance, Princeton, NJ 08544 USA.						Bennett K. P., 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; Bradley P. S., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98); Cristianini N, 2000, INTRO SUPPORT VECTOR; *DASH OPT INC, XPRESS MP OPT; Fung GM, 2004, COMPUT OPTIM APPL, V28, P185, DOI 10.1023/B:COAP.0000026884.66338.df; Hastie T., 2001, ELEMENTS STAT LEARNI; HOGAN S, IN PRESS J FINANCIAL; HONG H, 2003, DO IND LEAD STOCK MA; *ILOG CPLEX DIV, CPLEX OPT; Bi J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753643; JARROW B, 1988, FINANCE THEORY; LEHMANN BN, 1990, Q J ECON, V105, P1, DOI 10.2307/2937816; MANGASARIAN OL, 1995, OPER RES, V43, P570, DOI 10.1287/opre.43.4.570; Sharpe W.F, 1992, J PORTFOLIO MANA WIN, P7; Vapnik V., 1999, NATURE STAT LEARNING	15	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES			0-387-23528-0	OPERAT RES COMP SCI			2005	29						213	228				16	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Operations Research & Management Science	Computer Science; Operations Research & Management Science	BBY57	WOS:000228326300015		
B	Johansson, J; Cooper, M; Jern, M		Banissi, E; Sarfraz, M; Roberts, JC; Loften, B; Ursyn, A; Burkhard, RA; Lee, A; Andrienko, G		Johansson, J; Cooper, M; Jern, M			3-dimensional display for clustered multi-relational parallel coordinates	Ninth International Conference on Information Visualisation, Proceedings			English	Proceedings Paper	9th International Conference on Information Visualisation	JUL 06-08, 2005	London, ENGLAND	Univ Greenwich, Dept Informat Syst & Multimedia, CCGV, VGRU, BCIM, London S Bank Univ, ICR, BCIM, London S Bank Univ, Bournemouth Univ, Natl Ctr Comp Animat, Univ No Colorado, Dept Visual Art, Indiana Univ Sch Informat, HCI Grad Program, Sch Lib & Informat Sci, Indiana Univ, Informat & Comp Sci Dept, KFUPM, SA, Drexel Univ, Coll Informat Sci & Technol, Univ Kent Canterbury, Univ St Gallen, Inst Media & Commun Management, Univ Oregon, Univ Plymouth, Visualizat Lab				Analysing multivariate data is a difficult task. Extensive interaction with the data is often necessary and, hence, the analysis can be quite time consuming. In this paper, we introduce a method to allow the user to simultaneously examine the relationships of a single dimension with many others in the data. The single dimension can then be interactively changed to allow the user to quickly examine all possible combinations. This method is achieved by extending the standard parallel coordinate approach to a 3-dimensional clustered multi-relational parallel coordinate representation (CMRPC). To aid this method, we use a technique called relation spacing which is used to position the axes according to how 'interesting' the different relations are. We also propose a number of interaction techniques to further facilitate the analysis process.	Linkoping Univ, NVIS, S-58183 Linkoping, Sweden	Johansson, J (reprint author), Linkoping Univ, NVIS, S-58183 Linkoping, Sweden.						Andrienko G., 2004, Proceedings. Second International Conference on Coordinated & Multiple Views in Exploratory Visualization, DOI 10.1109/CMV.2004.1319530; BASALAJ W, 2001, THESIS U CAMBRIDGE; BERTHOLD M, 2003, IEEE T FUZZY SYST, P369; BUJA A, 1991, IEEE VISUALIZATION, P156; FALKMAN G, 2003, THESIS CHALMERS U TE; Fayyad U., 1996, P 2 INT C KNOWL DISC, P82; Fua Y.-H., 1999, IEEE VISUALIZATION, P43; Gonzales R. C., 2001, DIGITAL IMAGE PROCES; Graham M., 2001, IEEE 5 INT C INF VIS, P425; Hand David J, 2001, PRINCIPLES DATA MINI; Hastie T., 2001, ELEMENTS STAT LEARNI; HOFFMAN P, 1999, NPIVM 99, P9; Inselberg A., 1985, VISUAL COMPUT, V1, P69, DOI DOI 10.1007/BF01898350; Inselberg A., 1990, IEEE VISUALIZATION, P361; Kincaid R., 2004, P 2004 ACM S APPL CO, P167, DOI 10.1145/967900.967935; MACKAY WE, 1998, P CHI 98, P416, DOI 10.1145/274644.274701; Novotny M., 2004, P 8 CENTR EUR SEM CO, P41; Wegenkittl R, 1997, VISUALIZATION '97 - PROCEEDINGS, P119; WEGMAN EJ, 1996, HIGH DIMENSIONAL CLU; Yang J, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P105	20	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2397-8				2005							188	193		10.1109/IV.2005.1		6	Computer Science, Information Systems	Computer Science	BCR94	WOS:000230984100026		
J	Dzwinel, W; Yuen, DA; Boryczko, K; Ben-Zion, Y; Yoshioka, S; Ito, T				Dzwinel, W; Yuen, DA; Boryczko, K; Ben-Zion, Y; Yoshioka, S; Ito, T			Nonlinear multidimensional scaling and visualization of earthquake clusters over space, time and feature space	NONLINEAR PROCESSES IN GEOPHYSICS			English	Article							LARGE DATA SETS; THRESHOLD SYSTEMS; FAULT SYSTEMS; SEISMICITY; ALGORITHM; DYNAMICS; PATTERNS; BEHAVIOR; STRESS; MODELS	We present a novel technique based on a multiresolutional clustering and nonlinear multi-dimensional scaling of earthquake patterns to investigate observed and synthetic seismic catalogs. The observed data represent seismic activities around the Japanese islands during 1997-2003. The synthetic data were generated by numerical simulations for various cases of a heterogeneous fault governed by 3-D elastic dislocation and power-law creep. At the highest resolution, we analyze the local cluster structures in the data space of seismic events for the two types of catalogs by using an agglomerative clustering algorithm. We demonstrate that small magnitude events produce local spatiotemporal patches delineating neighboring large events. Seismic events, quantized in space and time, generate the multidimensional feature space characterized by the earthquake parameters. Using a non-hierarchical clustering algorithm and nonlinear multi-dimensional scaling, we explore the multitudinous earthquakes by real-time 3-D visualization and inspection of the multivariate clusters. At the spatial resolutions characteristic of the earthquake parameters, all of the ongoing seismicity both before and after the largest events accumulates to a global structure consisting of a few separate clusters in the feature space. We show that by combining the results of clustering in both low and high resolution spaces, we can recognize precursory events more precisely and unravel vital information that cannot be discerned at a single resolution.	Univ Minnesota, Minnesota Supercomp Inst, Minneapolis, MN 55455 USA; AGH Inst Comp Sci, PL-30059 Krakow, Poland; Univ So Calif, Dept Earth Sci, Los Angeles, CA 90089 USA; Kyushu Univ, Dept Earth & Planetary Sci, Fukuoka 8128581, Japan; Nagoya Univ, Grad Sch Environm Studies, Nagoya, Aichi 4648602, Japan	Yuen, DA (reprint author), Univ Minnesota, Minnesota Supercomp Inst, Minneapolis, MN 55455 USA.	davey@krissy.geo.umn.edu	Dzwinel, Witold/C-3872-2008				Amelung F, 2000, NATURE, V407, P993; Andenberg M, 1973, CLUSTERS ANAL APPL; Anghel M, 2004, PURE APPL GEOPHYS, V161, P2023, DOI 10.1007/s00024-004-2547-9; BEN-ZION Y, 1995, J GEOPHYS RES-SOL EA, V100, P12959, DOI 10.1029/94JB03037; Ben-Zion Y, 1996, J GEOPHYS RES-SOL EA, V101, P5677, DOI 10.1029/95JB03534; Ben-Zion Y, 2002, PURE APPL GEOPHYS, V159, P2385, DOI 10.1007/s00024-002-8740-9; Boryczko K, 2003, CONCURR COMP-PRACT E, V15, P101, DOI 10.1002/cpe.711; Briceno C, 2001, SCIENCE, V291, P93, DOI 10.1126/science.291.5501.93; Dowla F.U., 1995, NATO ASI SERIES E, V303, P777; Dzwinel W, 1999, FUTURE GENER COMP SY, V15, P365, DOI 10.1016/S0167-739X(98)00081-8; DZWINEL W, 1994, PATTERN RECOGN, V27, P949, DOI 10.1016/0031-3203(94)90160-0; DZWINEL W, 2003, VIS GEOSC, V8, P12; ENESU B, 2002, P AM GEOPHYS UN FALL; ENEVA M, 1997, J GEOPHYS RES, V102, P85; ENEVA M, 1997, J GEOPHYS RES, V102, P513; ERLEBACHER G, 2001, ELECTR GEOSC, P4; Erlebacher G, 2004, PURE APPL GEOPHYS, V161, P2215, DOI 10.1007/s00024-004-2259-5; ERTOZ L, 2003, FINDING CLUSTERS DIF; Freed AM, 2001, NATURE, V411, P180, DOI 10.1038/35075548; Geller RJ, 1997, SCIENCE, V275, P1616, DOI 10.1126/science.275.5306.1616; GOWDA KC, 1978, PATTERN RECOGN, V10, P105; Grossman R.L., 2001, DATA MINING SCI ENG; Guha S., 1998, P ACM SIGMOD INT C M, P73, DOI 10.1145/276304.276312; Gutenberg B., 1944, B SEISMOL SOC AM, V34, P185; Haile P, 1992, MOL DYNAMICS SIMULAT; Hand David J, 2001, PRINCIPLES DATA MINI; Hastie T., 2001, ELEMENTS STAT LEARNI, P533; Holschneider M., 1995, WAVELETS ANAL TOOL; HONG H, 2004, EOS T AGU FALL M, V85, P47; ISMAIL MA, 1989, PATTERN RECOGN, V22, P77; Ito T, 2002, TECTONOPHYSICS, V359, P171, DOI 10.1016/S0040-1951(02)00510-3; JAIN D, 1988, ALGORTIHMS CLUSTERIN; JONES NC, 2004, INTRO BIOINFORMATICS, P435; JOSWIG M, 1990, B SEISMOL SOC AM, V80, P170; KARYPIS G, 1999, IEEE COMPUT, V32, P68, DOI DOI 10.1109/2.781637; KARYPIS G, 1998, MULTILEVEL ALGORITHM; KEILISBOROK VI, 1990, PHYS EARTH PLANET IN, V61, P73, DOI 10.1016/0031-9201(90)90096-G; KURAMOCHI M, 2001, P 2 IEEE S BIO BIOEN; Miller SA, 1999, J GEOPHYS RES-SOL EA, V104, P10621, DOI 10.1029/1998JB900084; MITRA S, 2003, DATA MINING MULTIMED, P424; Rundle JB, 2002, P NATL ACAD SCI USA, V99, P2514, DOI 10.1073/pnas.012581899; Rundle JB, 1997, TECTONOPHYSICS, V277, P147, DOI 10.1016/S0040-1951(97)00083-8; RUNDLE JB, 2000, GEOCOMPLEXITY PHYS E, P284; Rundle JB, 2000, PHYS REV E, V61, P2418, DOI 10.1103/PhysRevE.61.2418; Sander J, 1998, DATA MIN KNOWL DISC, V2, P169, DOI 10.1023/A:1009745219419; SIEDLECKI W, 1988, PATTERN RECOGN, V21, P411, DOI 10.1016/0031-3203(88)90001-5; Song TRA, 2003, SCIENCE, V301, P630, DOI 10.1126/science.1085557; Strang G, 1996, WAVELETS FILTER BANK; THEODORIS S, 1998, PATTERN RECOGN; Tiampo KF, 2002, EUROPHYS LETT, V60, P481, DOI 10.1209/epl/i2002-00289-y; Tiampo KF, 2002, J GEOPHYS RES-SOL EA, V107, DOI 10.1029/2001JB000562; Tiira T, 1999, COMPUT GEOSCI, V25, P929, DOI 10.1016/S0098-3004(99)00056-4; Toda S, 2002, NATURE, V419, P58, DOI 10.1038/nature00997; WANG W, 1996, NEW GENERATION EXPER, P222; WESNOUSKY SG, 1994, B SEISMOL SOC AM, V84, P1940; Wiemer S, 2002, ADV GEOPHYS, V45, P259; Xiaowei Xu, 1999, Data Mining and Knowledge Discovery, V3; ZHANG QW, 1991, PATTERN RECOGN, V24, P835, DOI 10.1016/0031-3203(91)90003-N	58	12	12	EUROPEAN  GEOSCIENCES UNION	KATLENBURG-LINDAU	MAX-PLANCK-STR 13, 37191 KATLENBURG-LINDAU, GERMANY	1023-5809			NONLINEAR PROC GEOPH	Nonlinear Process Geophys.		2005	12	1					117	128				12	Geochemistry & Geophysics; Meteorology & Atmospheric Sciences	Geochemistry & Geophysics; Meteorology & Atmospheric Sciences	910QE	WOS:000227946100012		
J	Harman, G				Harman, G			Moral particularism and transduction	NOUS			English	Article; Proceedings Paper	15th SOFIA Conference	JAN, 2005	Huatulco, MEXICO	SOFIA					Princeton Univ, Princeton, NJ 08544 USA	Harman, G (reprint author), Princeton Univ, Princeton, NJ 08544 USA.						Dancy J, 1993, MORAL REASONS; Foot Philippa, 1978, VIRTUES VICES OTHER; GOUTTE C, 2004, 7 JOURN INT AN STAT; Haidt J, 2001, PSYCHOL REV, V108, P814, DOI 10.1037//0033-295X.108.4.814; Hare R. M, 1952, LANGUAGE MORALS; Hastie T., 2001, ELEMENTS STAT LEARNI; Joachims T., 1999, P 16 INT C MACH LEAR, P200; KIHLBOM U, 2002, STOCKHOLD STUDIES PH, V23; Korsgaard C., 1996, SOURCES NORMATIVITY; Little M., 2000, MORAL PARTICULARISM; McDowell John, 1998, MIND VALUE REALITY; Sartre J. P., 1956, EXISTENTIALISM DOSTO, P287; Scanlon T., 1998, WHAT WE OWE EACH OTH; Sinnott-Armstrong W, 1999, METAPHILOSOPHY, V30, P1, DOI 10.1111/1467-9973.00108; Thomson J., 1986, RIGHTS RESTITUTION R, P78; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik VN, 2000, NATURE STAT LEARNING; Vayrynen P, 2004, ETHICAL THEORY MORAL, V7, P53, DOI 10.1023/B:ETTA.0000019980.79568.2f; WESTON J, 2003, BIOINFORMATICS; Wiggins D., 1998, NEEDS VALUES TRUTH	20	0	0	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	0029-4624			NOUS	Nous		2005				15			44	55				12	Philosophy	Philosophy	010XQ	WOS:000235231600004		
J	Wu, HW; Su, ZC; Mao, FL; Olman, V; Xu, Y				Wu, HW; Su, ZC; Mao, FL; Olman, V; Xu, Y			Prediction of functional modules based on comparative genome analysis and Gene Ontology application	NUCLEIC ACIDS RESEARCH			English	Article							NETWORKS; IMPLEMENTATION; ENCYCLOPEDIA; EVOLUTION; SEARCH	We present a computational method for the prediction of functionalmodules encoded in microbial genomes. In this work, we have also developed a formal measure to quantify the degree of consistency between the predicted and the known modules, and have carried out statistical significance analysis of consistency measures. We first evaluate the functional relationship between two genes from three different perspectives-phylogenetic profile analysis, gene neighborhood analysis and Gene Ontology assignments. We then combine the three different sources of information in the framework of Bayesian inference, and we use the combined information to measure the strength of gene functional relationship. Finally, we apply athreshold-based method to predict functional modules. By applying this method to Escherichia coli K12, we have predicted 185 functional modules. Our predictions are highly consistent with the previously known functional modules in E. coli. The application results have demonstrated that our approach is highly promising for the prediction of functional modules encoded in a microbial genome.	Univ Georgia, Dept Biochem & Mol Biol, Athens, GA 30602 USA; Oak Ridge Natl Lab, Computat Biol Inst, Oak Ridge, TN 37831 USA	Xu, Y (reprint author), Univ Georgia, Dept Biochem & Mol Biol, 120 Green St, Athens, GA 30602 USA.	xyn@bmb.uga.edu					Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Camon E, 2003, GENOME RES, V13, P662, DOI 10.1101/gr.461403; Casella G., 2001, STAT INFERENCE; Chen X, 2004, NUCLEIC ACIDS RES, V32, P2147, DOI 10.1093/nar/gkh510; CHEN Y, 2004, THESIS U TENNESSEE K; DUSA RO, 2001, PATTERN CLASSIFICATI; Gelfand MS, 2000, NUCLEIC ACIDS RES, V28, P695, DOI 10.1093/nar/28.3.695; Ashburner M, 2001, GENOME RES, V11, P1425; Hastie T., 2001, ELEMENTS STAT LEARNI; Jansen R, 2003, SCIENCE, V302, P449, DOI 10.1126/science.1087361; Kanehisa M, 2000, NUCLEIC ACIDS RES, V28, P27, DOI 10.1093/nar/28.1.27; Karp PD, 1999, NUCLEIC ACIDS RES, V27, P55, DOI 10.1093/nar/27.1.55; Kremling A, 2000, METAB ENG, V2, P190, DOI 10.1006/mben.2000.0159; Lee I, 2004, SCIENCE, V306, P1555, DOI 10.1126/science.1099511; LORD PW, 2002, BIOINFORMATICS, V19, P1275; McGuire AM, 2000, NUCLEIC ACIDS RES, V28, P4523, DOI 10.1093/nar/28.22.4523; Moreno-Hagelsieb Gabriel, 2002, Bioinformatics, V18 Suppl 1, pS329; Muller F, 2002, BIOESSAYS, V24, P564, DOI 10.1002/bies.10096; Pellegrini M, 1999, P NATL ACAD SCI USA, V96, P4285, DOI 10.1073/pnas.96.8.4285; Press W.H., 1992, NUMERICAL RECIPES C; Spirin V, 2003, P NATL ACAD SCI USA, V100, P12123, DOI 10.1073/pnas.2032324100; Stephanopoulos G.N., 1998, METABOLIC ENG PRINCI; Strauss EJ, 1997, SCIENCE, V276, P707, DOI 10.1126/science.276.5313.707; Tatusov RL, 1997, SCIENCE, V278, P631, DOI 10.1126/science.278.5338.631; Voet D., 1995, BIOCHEMISTRY; von Mering C, 2003, P NATL ACAD SCI USA, V100, P15428, DOI 10.1073/pnas.2136809100; Wagner R, 2000, TRANSCRIPTION REGULA; Wall DP, 2003, BIOINFORMATICS, V19, P1710, DOI 10.1093/bioinformatics/btg213; WHITTAM TS, 2002, CURR OPIN GENE DEV, V12, P718; Wolf YI, 2001, GENOME RES, V11, P356, DOI 10.1101/gr.GR-1619R; Yamada Takuji, 2004, Genome Inform, V15, P249; YANAI I, 2002, GENOME BIOL, V3, P12; Zhou J, 2004, MICROBIAL FUNCTIONAL	33	68	74	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0305-1048			NUCLEIC ACIDS RES	Nucleic Acids Res.		2005	33	9					2822	2837		10.1093/nar/gki573		16	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	932HK	WOS:000229544600015	15901854	
J	Yilmaz, FB; Oktem, H; Weber, GW		Fleuren, H; denHertog, D; Kort, P		Yilmaz, F. B.; Oktem, H.; Weber, G. -W.			Mathematical Modeling and Approximation of Gene Expression Patterns	OPERATIONS RESEARCH PROCEEDINGS 2004	Operations Research Proceedings		English	Proceedings Paper	Annual International Conference of the German-Operations-Research-Society	SEP 01-03, 2004	Tilburg, NETHERLANDS	German Operat Res Soc, Netherlands Soc Operat Res		Gene Expression; Gene Regulation; Mathematical Modeling; Gene Network; Inference; Optimization; Dynamical Systems	DIFFERENTIAL-EQUATIONS; NETWORKS	This study concerns modeling, approximation and inference of gene regulatory dynamics on the basis of gene expression patterns. The dynamical behavior of gene expressions is represented by a system of ordinary differential equations. We introduce a gene-interaction matrix with some nonlinear entries, in particular, quadratic polynomials of the expression levels to keep the system solvable. The model parameters are determined by using optimization. Then, we provide the time-discrete approximation of our time-continuous model. Finally, from the considered models we derive gene regulatory networks, discuss their qualitative features and provide a basis for analyzing networks with nonlinear connections.	[Yilmaz, F. B.; Oktem, H.; Weber, G. -W.] Middle E Tech Univ, Inst Appl Math, TR-06531 Ankara, Turkey							AKHMET MU, 2004, J COMPUTATI IN PRESS; Aster R. C., 2004, PARAMETER ESTIMATION; Baldi P., 2002, DNA MICROARRAYS GENE; Chen T, 1999, P PAC S BIOC, V4, P29; de Hoon M, 2002, LECT NOTES COMPUT SC, V2534, P267; Diestel R., 1997, GRAPH THEORY; Dijkstra E, 1959, NUMER MATH, V1, P269, DOI DOI 10.1007/BF01386390; Gebert J, 2004, AIP CONF PROC, V718, P474; Hastie T., 2001, ELEMENTS STAT LEARNI; Sakamoto E, 2001, IEEE C EVOL COMPUTAT, P720, DOI 10.1109/CEC.2001.934462; Yilmaz F.B., 2004, THESIS METU	11	12	12	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0721-5924		978-3-540-27679-1	OPERAT RES PROCEED			2005							280	287		10.1007/3-540-27679-3_35		8	Business; Management; Operations Research & Management Science	Business & Economics; Operations Research & Management Science	BLA32	WOS:000269743500036		
S	Perez, JM; Muguerza, J; Arbelaitz, O; Gurrutxaga, I; Martin, JI		Singh, S; Singh, M; Apte, C; Perner, P		Perez, JM; Muguerza, J; Arbelaitz, O; Gurrutxaga, I; Martin, JI			Consolidated trees: Classifiers with stable explanation. A model to achieve the desired stability in explanation	PATTERN RECOGNITION AND DATA MINING, PT 1, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	3rd International Conference on Advances in Pattern Recognition	AUG 22-25, 2005	Bath, ENGLAND					In real world problems solved with machine learning techniques, achieving small error rates is important, but there are situations where an explanation is compulsory. In these situations the stability of the given explanation is crucial. We have presented a methodology for building classification trees, Consolidated Trees Construction Algorithm (CTC). CTC is based on subsampling techniques, therefore it is suitable to face class imbalance problems, and it improves the error rate of standard classification trees and has larger structural stability. The built trees are more steady as the number of subsamples used for induction increases, and therefore also the explanation related to the classification is more steady and wider. In this paper a model is presented for estimating the number of subsamples that would be needed to achieve the desired structural convergence level. The values estimated using the model and the real values are very similar, and there are not statistically significant differences.	Univ Basque Country, Dept Comp Architecture & Technol, Donostia San Sebastian 20018, Spain	Perez, JM (reprint author), Univ Basque Country, Dept Comp Architecture & Technol, M Lardizabal,1, Donostia San Sebastian 20018, Spain.	txus.perez@ehu.es; j.muguerza@ehu.es; olatz.arbelaitz@ehu.es; ibai.gurrutxaga@ehu.es; j.martin@ehu.es	Muguerza, Javier/G-6075-2012; Perez, Jesus/G-8065-2012; Gurrutxaga, Ibai/N-1674-2014	Perez, Jesus/0000-0003-1728-3249; Gurrutxaga, Ibai/0000-0003-1830-1058			Blake C.L., 1998, UCI REPOSITORY MACHI; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Domingos P., 1997, P 14 INT C MACH LEAR, P98; Drummond C, 2000, P 17 INT C MACH LEAR, P239; Hastie T., 2001, ELEMENTS STAT LEARNI; PEREZ JM, 2004, P 4 INT WORKSH PATT, P139; PEREZ JM, 2004, P 3 AUSTR DAT MIN C, P9; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; TURNEY P, 1995, MACH LEARN, V20, P23, DOI 10.1007/BF00993473	9	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-28757-4	LECT NOTES COMPUT SC			2005	3686						99	107				9	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDA34	WOS:000232247900011		
S	Venkataramani, K; Kumar, BV		Singh, S; Singh, M; Apte, C; Perner, P		Venkataramani, K; Kumar, BV			Conditionally dependent classifier fusion using AND rule for improved biometric verification	PATTERN RECOGNITION AND IMAGE ANALYSIS, PT 2, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	3rd International Conference on Advances in Pattern Recognition	AUG 22-25, 2005	Bath, ENGLAND				ACCURACY; COMBINATION; DIVERSITY; SYSTEMS	Statistical dependence of classifiers has recently been shown to improve accuracy over statistically independent classifiers. In this paper, we focus on the verification application and theoretically analyze the AND fusion rule to find the favorable conditional dependence that improves the fusion accuracy over conditionally independent classifiers. Based on this analysis, we come with a method to design such classifiers by training the classifiers on different partitions of the training data. The AR face database is used for performance evaluation and the proposed method has a false rejection rate (FRR) of 2.4% and a false acceptance rate of 3.3% on AND fusion, which is better than an FRR of 3.8% and FAR of 4.3% when classifiers are designed without taking account the AND fusion rule.	Carnegie Mellon Univ, Dept Elect & Comp Engn, CyLab, Pittsburgh, PA 15213 USA	Venkataramani, K (reprint author), Carnegie Mellon Univ, Dept Elect & Comp Engn, CyLab, Pittsburgh, PA 15213 USA.	krithika@ece.cmu.edu; kumar@ece.cmu.edu					Giacinto G, 2001, PATTERN RECOGN LETT, V22, P25, DOI 10.1016/S0167-8655(00)00096-9; Hastie T., 2001, ELEMENTS STAT LEARNI; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kleinberg EM, 1996, ANN STAT, V24, P2319; Kuncheva LI, 2003, PATTERN ANAL APPL, V6, P22, DOI 10.1007/s10044-002-0173-7; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; Martinez Aleix, 1998, 24 CVC; Phillips P. J., 2003, FRVT 2002 EVALUATION; Shin HW, 2005, PATTERN RECOGN, V38, P191, DOI 10.1016/j.patcog.2004.06.008; Varshney P., 1997, DISTRIBUTED DETECTIO; XU L, 1992, IEEE T SYSTEMS MAN C, V22; ZHENG W, 2004, ICPR, P403	13	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-28833-3	LECT NOTES COMPUT SC			2005	3687						277	286				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BDA36	WOS:000232249700031		
S	Skowron, A		Pal, SK; Bandyopadhyay, S; Biswas, S		Skowron, A			Rough sets in perception-based computing	PATTERN RECOGNITION AND MACHINE INTELLIGENCE, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	1st International Conference on Pattern Recognition and Machine Intelligence	DEC 20-22, 2005	Calcutta, INDIA	Indian Statist Inst, ISI, Ctr Soft Comp Res-A Natl Fac, Govt India, Dept Sci & Technol, Int Ctr Pure & Appl Math, Int Assoc Pattern Recognit, Web Intelligence Consortium, Webel, Govt West Bengal IT Comp, Govt India, Council Sci & Ind Res, IEEE	Statist Inst Kolkata		APPROXIMATION; SYSTEMS		Warsaw Univ, Inst Math, PL-02097 Warsaw, Poland	Skowron, A (reprint author), Warsaw Univ, Inst Math, Banacha 2, PL-02097 Warsaw, Poland.	skowron@mimuw.edu.pl					Anderson J. R., 1998, ATOMIC COMPONENTS TH; Barsalou LW, 1999, BEHAV BRAIN SCI, V22, P577; Bar-Yam Y, 1997, DYNAMICS COMPLEX SYS; BAZAN J, 2005, IN PRESS P RSFDGRC 2; Bazan J, 2005, ADV SOFT COMP, P191, DOI 10.1007/3-540-32370-8_13; BEHNKE S, 2003, LNCS, V2766; Bonabeau E., 1999, SWARM INTELLIGENCE N; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Brown F. N., 1990, BOOLEAN REASONING; Duda R.O., 2001, PATTERN CLASSIFICATI; DUNINKEPLICZ B, 2005, ADV SOFT COMPUTING; Fahle M, 2002, PERCEPTUAL LEARNING; FREGE G, 1893, GRUNDLAGEN ARITHMETI; Friedman J., 2001, ELEMENTS STAT LEARNI; Gell-Mann M, 1994, QUARK JAGUAR ADVENTU; Harnad S.R., 1987, CATEGORICAL PERCEPTI; Kloesgen Willi, 2002, HDB KNOWLEDGE DISCOV; Lesniewski S., 1929, FUND MATH, Vxiv, P1; Luck M, 2003, AGENT TECHNOLOGY ENA; Lukasiewicz J., 1970, J LUKASIEWICZ SELECT; Newell A., 1990, UNIFIED THEORIES COG; Nguyen SH, 2004, LECT NOTES COMPUT SC, V3100, P187; Nguyen TT, 2003, LECT NOTES ARTIF INT, V2639, P221; PAINE RW, 2004, IN PRESS HUMAN MOVEM; Pal S.K., 1999, ROUGH FUZZY HYBRIDIZ; Pal S.K., 2004, ROUGH NEURAL COMPUTI; Pawlak Z., 1991, ROUGH SETS THEORETIC; Peters JF, 2003, LECT NOTES ARTIF INT, V2715, P370; Peters JF, 2005, LECT NOTES COMPUT SC, V3400, P153; Poggio T., 2003, NOTICES AMS, V50, P537; Polkowski L, 1996, INT J APPROX REASON, V15, P333, DOI 10.1016/S0888-613X(96)00072-2; Skowron A, 2004, FUND INFORM, V60, P351; Skowron A, 2004, FUND INFORM, V59, P241; Skowron A., 2001, B INT ROUGH SET SOC, V5, P9; Skowron A, 2004, INTELLIGENT TECHNOLOGIES FOR INFORMATION ANALYSIS, P433; Skowron A., 2000, 16th World Computer Congress 2000. Proceedings of Conference on Intelligent Information Processing; Skowron A, 2004, COG TECH, P43; Staab S, 2004, HDB ONTOLOGIES; Stone P., 2000, LAYERED LEARNING MUL; Urmson C., 2004, CMURITR0437; Vapnik V., 1998, STAT LEARNING THEORY; Zadeh LA, 2001, AI MAG, V22, P73; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	43	8	8	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-30506-8	LECT NOTES COMPUT SC			2005	3776						21	29				9	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDQ09	WOS:000234856700003		
S	Ghosh, AK; Bose, S		Pal, SK; Bandyopadhyay, S; Biswas, S		Ghosh, AK; Bose, S			Feature extraction for nonlinear classification	PATTERN RECOGNITION AND MACHINE INTELLIGENCE, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	1st International Conference on Pattern Recognition and Machine Intelligence	DEC 20-22, 2005	Calcutta, INDIA	Indian Statist Inst, ISI, Ctr Soft Comp Res-A Natl Fac, Govt India, Dept Sci & Technol, Int Ctr Pure & Appl Math, Int Assoc Pattern Recognit, Web Intelligence Consortium, Webel, Govt West Bengal IT Comp, Govt India, Council Sci & Ind Res, IEEE	Statist Inst Kolkata		REGRESSION	Following the idea of neural networks, multi-layer statistical classifier [3] was designed to capture interactions between measurement variables using nonlinear transformation of additive models. However, unlike neural nets, this statistical method can not readjust the initial features, and as a result it often leads to poor classification when those features are not adequate. This article presents an iterative algorithm based on backfitting which can modify these features dynamically. The resulting method can be viewed as an approach for estimating posterior class probabilities by projection pursuit regression, and the associated model can be interpreted as a generalized version of the neural network and other statistical models.	Indian Stat Inst, Theoret Stat & Math Unit, Kolkata 700108, W Bengal, India	Ghosh, AK (reprint author), Indian Stat Inst, Theoret Stat & Math Unit, 203,BT rd, Kolkata 700108, W Bengal, India.	anilkghosh@rediffmail.com; smarajit@isical.ac.in					Anderson T. W., 1984, INTRO MULTIVARIATE S; Bose S, 1996, COMPUT STAT DATA AN, V22, P505, DOI 10.1016/0167-9473(96)00009-6; Bose S, 2003, COMPUT STAT DATA AN, V42, P685, DOI 10.1016/S0167-9473(02)00171-8; Breiman L., 1984, CLASSIFICATION REGRE; BREIMAN L, 1993, COMPUT STAT DATA AN, V15, P13, DOI 10.1016/0167-9473(93)90217-H; Duda R. O., 2000, PATTERN CLASSIFICATI; FRIEDMAN JH, 1981, J AM STAT ASSOC, V76, P817, DOI 10.2307/2287576; Ghosh AK, 2004, COMPUTATION STAT, V19, P193, DOI 10.1007/BF02892056; Ghosh AK, 2005, BERNOULLI, V11, P1, DOI 10.3150/bj/1110228239; GHOSH AK, 2005, P 5 INT C ADV PATT R, P89; Hand D, 1982, KERNEL DISCRIMINANT; Hastie T., 2001, ELEMENTS STAT LEARNI; Kooperberg C, 1997, J AM STAT ASSOC, V92, P117, DOI 10.2307/2291455; Ripley BD, 1996, PATTERN RECOGNITION; Silverman BW, 1986, DENSITY ESTIMATION S	15	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-30506-8	LECT NOTES COMPUT SC			2005	3776						170	175				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDQ09	WOS:000234856700021		
S	Skowron, A; Stepaniuk, J; Swiniarski, R		Pal, SK; Bandyopadhyay, S; Biswas, S		Skowron, A; Stepaniuk, J; Swiniarski, R			Approximation spaces in machine learning and pattern recognition	PATTERN RECOGNITION AND MACHINE INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st International Conference on Pattern Recognition and Machine Intelligence	DEC 20-22, 2005	Kolkata, INDIA	Indian Statist Inst, ISI, Ctr Soft Comp Res-A Natl Fac, Govt India, Dept Sci & Technol, Int Ctr Pure & Appl Math, Int Assoc Pattern Recognit, Web Intelligence Consortium, Webel, Govt West Bengal IT Comp, Govt India, Council Sci & Ind Res, IEEE	Statist Inst Kolkata	rough sets; approximation spaces; concept approximation		Approximation spaces are fundamental for the rough set approach. We discuss their application in machine learning and pattern recognition.	Univ Warsaw, Inst Math, PL-02097 Warsaw, Poland; Bialystok Univ Technol, Dept Comp Sci, PL-15351 Bialystok, Poland; Polish Acad Sci, Inst Comp Sci, PL-01237 Warsaw, Poland; San Diego State Univ, Dept Comp Sci, San Diego, CA 92182 USA	Skowron, A (reprint author), Univ Warsaw, Inst Math, Banacha 2, PL-02097 Warsaw, Poland.	skowron@mimuw.edu.pl; jstepan@ii.pb.bialystok.pl; rswiniar@sciences.sdsu.edu					Hastie T, 2003, ELEMENTS STAT LEARNI; Lukasiewicz J., 1970, J LUKASIEWICZ SELECT; Pawlak Z., 1991, ROUGH SETS THEORETIC; Polkowski L., 2002, ROUGH SETS MATH FDN; Polkowski L, 1996, INT J APPROX REASON, V15, P333, DOI 10.1016/S0888-613X(96)00072-2; Skowron A, 2004, FUND INFORM, V60, P351; Skowron A., 1996, Fundamenta Informaticae, V27; Skowron A, 2005, LECT NOTES COMPUT SC, V3400, P175; Staab S., 2004, INT HDB INFORM SYSTE; ZIARKO W, 1993, J COMPUT SYST SCI, V46, P39, DOI 10.1016/0022-0000(93)90048-2	10	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-30506-8	LECT NOTES COMPUT SC			2005	3776						750	755				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDQ09	WOS:000234856700121		
S	Bauckhage, C; Tsotsos, JK		Kropatsch, WG; Sablatnig, R; Hanbury, A		Bauckhage, C; Tsotsos, JK			Separable linear discriminant classification	PATTERN RECOGNITION, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	27th Annual Meeting of the German-Association-for-Pattern-Recognition	AUG 31-SEP 02, 2005	Vienna, AUSTRIA	Pattern Recognit & Image Proc Grp	Vienna Univ Technol			Linear discriminant analysis is a popular technique in computer vision, machine learning and data mining. It has been successfully applied to various problems, and there are numerous variations of the original approach. This paper introduces the idea of separable LDA. Towards the problem of binary classification for visual object recognition, we derive an algorithm for training separable discriminant classifiers. Our approach provides rapid training and runtime behavior and also tackles the small sample size problem. Experimental results show that the method performs robust and allows for online learning.	York Univ, Ctr Vis Res, N York, ON M3J 1P3, Canada	Bauckhage, C (reprint author), York Univ, Ctr Vis Res, N York, ON M3J 1P3, Canada.		Tsotsos, John/G-3436-2011; Bauckhage, Christian/M-7872-2014	Bauckhage, Christian/0000-0001-6615-2128			Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108; Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264136; Deriche R., 1992, P 2 INT C IM PROC SI, P263; Fergus R., 2003, P IEEE C COMP VIS PA, V2, P264; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fukunaga K, 1990, INTRO STAT PATTERN R; GARG A, 2002, P ICPR, V3, P723; Hastie T., 2001, ELEMENTS STAT LEARNI; Leibe B, 2004, LECT NOTES COMPUT SC, V3175, P145; SHASHUA A, 2001, P CVPR, V1, P42; Viola P., 2001, P IEEE C COMP VIS PA, V1, P511; Ye J., 2004, ADV NEURAL INFORM PR, V17, P1569	13	5	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-28703-5	LECT NOTES COMPUT SC			2005	3663						318	325				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDA31	WOS:000232246500040		
S	Kahsay, L; Schwenker, F; Palm, G		Kropatsch, WG; Sablatnig, R; Hanbury, A		Kahsay, L; Schwenker, F; Palm, G			Comparison of multiclass SVM decomposition schemes for visual object recognition	PATTERN RECOGNITION, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	27th Annual Meeting of the German-Association-for-Pattern-Recognition	AUG 31-SEP 02, 2005	Vienna, AUSTRIA	Pattern Recognit & Image Proc Grp	Vienna Univ Technol		CLASSIFICATION	We consider the problem of multiclass decomposition schemes for Support Vector Machines with Linear, Polynomial and RBF kernels. Our aim is to compare and discuss popular multiclass decomposing approaches such as the One versus the Rest, One versus One, Decision Directed Acyclic Graphs, Tree Structured, Error Correcting Output Codes. We conducted our experiments on benchmark datastes consisting of camera images of 3D objects. In our experiments we found that all the multiclass decomposing schemes for SVMs performed comparably very well with no significant statistical differences in cases of nonlinear kernels. In case of linear kernels the multiclass schemes OvR, OvO and DDAG outperform Tree Structured and ECOC.	Univ Ulm, Dept Neural Informat Proc, D-89069 Ulm, Germany	Kahsay, L (reprint author), Univ Ulm, Dept Neural Informat Proc, Albert Einstein Allee 11, D-89069 Ulm, Germany.	kahsay@neuro.informatik.uni-ulm.de; fschwenker@neuro.informatik.uni-ulm.de; Palm@neuro.informatik.uni-ulm.de					Allwein E. L., 2000, P 17 INT C MACH LEAR, P9; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Duda R.O., 2001, PATTERN CLASSIFICATI; FAY R, 2004, 3 WORKSH SELF AD BEH, P198; Freeman W.T., 1995, INT WORKSH AUT FAC G, P296; Friedman J., 1996, ANOTHER APPROACH POL; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T, 1998, ANN STAT, V26, P451; Kressel UHG, 1999, ADVANCES IN KERNEL METHODS, P255; Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195; Mel BW, 1997, NEURAL COMPUT, V9, P777, DOI 10.1162/neco.1997.9.4.777; Nene S. A., 1996, CUCS00696; Nene S.A., 1996, CUCS00596; Nilsback M., 2004, CVPR, V2, P578; Platt J. C., 1998, MSRTR9814; Platt JC, 2000, ADV NEUR IN, V12, P547; Rifkin R, 2004, J MACH LEARN RES, V5, P101; Scholkopf B., 2002, LEARNING KERNELS SUP; SCHWENKER F, 2001, MUSTERERKENNUNG 2001, P283; Vapnik VN, 1995, NATURE STAT LEARNING	21	6	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-28703-5	LECT NOTES COMPUT SC			2005	3663						334	341				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDA31	WOS:000232246500042		
J	Young, SS; Ge, NX				Young, SS; Ge, NX			Recursive partitioning analysis of complex disease pharmacogenetic studies. I. Motivation and overview	PHARMACOGENOMICS			English	Article						complex disease; pharmacogenctics; recursive partitioning	UNRELATED INDIVIDUALS; GENOTYPE DATA; ASSOCIATION; SUSCEPTIBILITY; REGRESSION; LINKAGE; TRAITS	Identifying genetic variation predictive of important phenotypes, including disease susceptibility, drug efficacy, and adverse events, is a challenging task, and theory and computer science work is being carried out in an attempt to tackle this issue. For many important diseases, such as diabetes, schizophrenia, and depression, the etiology is complex; either the disease is a result of several multiple mechanisms or is caused by an interaction among multiple genes or gene-environment interactions, or both. There is a need for statistical methods to deal with the large, complex data sets that will be used to disentangle these diseases. Each putative genetic polymorphism can be tested for association sequentially. The most difficult problem, however, is the identification of combinations of polymorphisms or genetic markers with increased predictive characteristics. Data from clinical trials, where patients with a particular disease are treated with certain drugs, can be retrospectively assembled using a case-control design. Such data will typically include treatment assignment, demographics, medical history, and genotypes for a large number of genetic markers. The number of variables in such data is expected to be much larger than the number of subjects. This report focuses on some of the methods being employed to deal with this complex data and covers, in some detail, a data-mining method - recursive partitioning - to analyze such data. The methods are demonstrated using a complex simulated data set, as there are few available public data sets. This explication of recursive partitioning should provide researchers with a better idea of the current available analysis techniques, in order to allow them to plan their experiments more effectively.	Natl Inst Stat Sci, Res Triangle Pk, NC 27709 USA; Aventis Pharmaceut, Drug Discovery Biostat, Bridgewater, NJ 08807 USA	Young, SS (reprint author), Natl Inst Stat Sci, Res Triangle Pk, NC 27709 USA.	young@niss.org; nanxiang.ge@aventis.com					Bell J, 2004, NATURE, V429, P453, DOI 10.1038/nature02624; Breiman L., 1984, CLASSIFICATION REGRE; BURMAN P, 1989, BIOMETRIKA, V76, P503, DOI 10.1093/biomet/76.3.503; Cook Nancy R., 2004, Statistics in Medicine, V23, P1439, DOI 10.1002/sim.1749; Cox NJ, 1999, NAT GENET, V21, P213, DOI 10.1038/6002; CURRAN MD, 2003, STAT MODELING GENETI; Devlin B, 2001, THEOR POPUL BIOL, V60, P155, DOI 10.1006/tpbi.2001.1542; Epstein MP, 2003, AM J HUM GENET, V73, P1316, DOI 10.1086/380204; Evans WE, 2004, NATURE, V429, P464, DOI 10.1038/nature02626; Foulkes AS, 2004, J ROY STAT SOC C-APP, V53, P311, DOI 10.1046/j.1467-9876.2003.05094.x; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Hallberg P., 2004, Current Pharmacogenomics, V2, P83, DOI 10.2174/1570160043476123; Hastie T., 2001, ELEMENTS STAT LEARNI; Hawkins D. M., 1982, TOPICS APPL MULTIVAR, P269; LANDER E, 1995, NAT GENET, V11, P241, DOI 10.1038/ng1195-241; Lin DY, 2004, GENET EPIDEMIOL, V26, P255, DOI 10.1002/gepi.10317; Merikangas KR, 2003, SCIENCE, V302, P599, DOI 10.1126/science.1091468; Morris RW, 2002, GENET EPIDEMIOL, V23, P221, DOI 10.1002/gepi.10200; Province MA, 2001, ADV GENET, V42, P273, DOI 10.1016/S0065-2660(01)42028-1; Quilan J., 1993, C4 5 PROGRAMS MACHIN; RAO DC, 1998, GENET EPIDEMIOL, V151, P1; Rothman K., 1998, MODERN EPIDEMIOLOGY; Rothman K J, 1990, Epidemiology, V1, P43, DOI 10.1097/00001648-199001000-00010; Ruczinski I, 2004, J MULTIVARIATE ANAL, V90, P178, DOI 10.1016/j.jmva.2004.02.010; Rusinko A, 1999, J CHEM INF COMP SCI, V39, P1017, DOI 10.1021/ci9903049; Schaid DJ, 2002, GENET EPIDEMIOL, V23, P426, DOI 10.1002/gepi.10184; Shannon WD, 2001, GENET EPIDEMIOL, V20, P293, DOI 10.1002/gepi.1; Stram DO, 2003, HUM HERED, V55, P179, DOI 10.1159/000073202; WESTFALL PH, 1993, RASAMPLING BASED MUL; Wilcox MA, 1999, GENET EPIDEMIOL, V17, pS391; Wright A, 2003, TRENDS GENET, V19, P97, DOI 10.1016/S0168-9525(02)00033-1; Zaykin DV, 2002, HUM HERED, V53, P79, DOI 10.1159/000057986; Zaykin DV, 2004, BMC GENET, V5, DOI 10.1186/1471-2156-5-9; Zaykin DV, 2005, PHARMACOGENOMICS, V6, P77, DOI 10.1517/14622416.6.1.77; Zhang HP, 2000, GENET EPIDEMIOL, V19, P323, DOI 10.1002/1098-2272(200012)19:4<323::AID-GEPI4>3.0.CO;2-5	35	10	10	FUTURE MEDICINE LTD	LONDON	UNITEC HOUSE, 3RD FLOOR, 2 ALBERT PLACE, FINCHLEY CENTRAL, LONDON, N3 1QB, ENGLAND	1462-2416			PHARMACOGENOMICS	Pharmacogenomics	JAN	2005	6	1					65	75		10.1517/14622416.6.1.65		11	Pharmacology & Pharmacy	Pharmacology & Pharmacy	911CU	WOS:000227979900012	15723607	
S	Diagaradjane, P; Yaseen, MA; Yu, J; Wong, MS; Anvari, B		Bartels, KE; Bass, LA; DeRiese, WTW; Gregory, KW; Hirschberg, H; Katzir, A; Kollias, N; Madsen, SJ; Malek, RS; McNallyHeintzelman, KM; Tate, LP; Trowers, EA; Wong, BJF		Diagaradjane, P; Yaseen, MA; Yu, J; Wong, MS; Anvari, B			Autofluorescence characterization of DMBA-TPA induced two-stage carcinogenesis in mouse skin for the early detection of tissue transformation	Photonic Therapeutics and Diagnostics	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Conference on Photonic Therapeutics and Diagnostics	JAN 22-25, 2005	San Jose, CA	SPIE		squamous cell carcinoma; autofluorescence; DMBA; mouse skin; fluorescence spectroscopy; 7,12-dimethylbenz (a) anthrance (DMBA); carcinogenesis	FLUORESCENCE SPECTROSCOPY; MULTIEXCITATION FLUORESCENCE; EXCITATION WAVELENGTHS; DIAGNOSIS; NEOPLASIA; SYSTEM; BREAST	The use of autofluorescence technique in the characterization of the sequential tissue transformation process in 7,12dimethylbenz(a)anthracene and 12-O-tetradecanoylphorbol-13-acetate (DMBA & TPA) induced two-stage mouse skin carcinogenesis model in conjunction with a suitable statistical method is being explored. The fluorescence excitation emission matrix (EEM) from experimental group (n=40; DMBA/TPA application), control group (n=6; acetone application) and the blank group (n=6; no application of DMBA/TPA or acetone) were measured every week using Fluoromax3 spectrofluorometer coupled with a waveguide fiber optic bundle (JY Horiba, NJ). The EEM Was recorded for 19 excitation wavelengths from 280 to 460 nm at 10 nm. intervals and the fluorescence emission was scanned from 300 to 750 m. During the tissue transfomation the epithelial tissues underwent biochemical and structural changes that are manifested in the tissue fluorescence. To correlate the tissue morphology with the observed fluorescence differences in the fluorescence emission, animals were sacrificed and the tissue biopsies were subjected to histopathological evaluation. The fluorescence emission corresponding to different fluorophores was extracted from the EEM, and the spectral data were used in multivariate statistical algorithm for the earliest diagnosis of the onset of tissue transformation. The intrinsic fluorescence from tryptophan, NADH and prophyrins showed distinct differences in the spectral signature during the tissue transformation, due to the altered metabolic activities of the cells. The statistical analysis of the spectral data corresponding to each excitation wavelength showed better classification accuracy at 280, 320, 350 and 405 nm excitations, corresponding to tryptophan, collagen, NADH and porphyrins with the classification accuracy of 74.3, 68. 1, 64.6 and 74.7% respectively. The variations in the spectral signature and the results of the statistical analysis suggest that porphyrins, tryptophan and NADH can be targeted as potential tumor markers in the early detection of the tissue transformation process.	Rice Univ, Dept Bioengn, Houston, TX 77005 USA	Anvari, B (reprint author), Rice Univ, Dept Bioengn, Houston, TX 77005 USA.						ALFANO RR, 1984, IEEE J QUANTUM ELECT, V20, P1507, DOI 10.1109/JQE.1984.1072322; ALFANO RR, 1987, IEEE J QUANTUM ELECT, V23, P1806, DOI 10.1109/JQE.1987.1073234; Coghlan L, 2000, OPT EXPRESS, V7, P436; GASCOYNE PRC, 2002, TUMOR MARKERS PHYSL, pCH53; Green P. E., 1978, ANAL MULTIVARIATE DA; Hastie T, 2001, ELEMENTS STAT LEARNI, P193; Heintzelman DL, 2000, PHOTOCHEM PHOTOBIOL, V72, P103, DOI 10.1562/0031-8655(2000)072<0103:OEWFIV>2.0.CO;2; MAHADEVAN A, 1993, LASER SURG MED, V13, P647, DOI 10.1002/lsm.1900130609; Mycek MA, 1998, GASTROINTEST ENDOSC, V48, P390, DOI 10.1016/S0016-5107(98)70009-4; Palmer G.M., 2003, MED LASER APPL, V18, P233, DOI 10.1078/1615-1615-00106; Palmer GM, 2003, IEEE T BIO-MED ENG, V50, P1233, DOI [10.1109/TBME.2003.818488, 10.1109/TMBE.2003.818488]; Ramanujam N, 2000, NEOPLASIA, V2, P89, DOI 10.1038/sj.neo.7900077; Ramanujam N., 2000, ENCY ANAL CHEM, P20; RichardsKortum R, 1996, ANNU REV PHYS CHEM, V47, P555, DOI 10.1146/annurev.physchem.47.1.555; Sandby-Moller J, 2003, PHOTOCHEM PHOTOBIOL, V77, P616, DOI 10.1562/0031-8655(2003)077<0616:IOETPA>2.0.CO;2; Slaga T.J., 1984, MECHANISMS TUMOR PRO, V2, P1; SSCHANTZ SP, 1998, CLIN CANCER RES, V4, P1177; TEALE FWJ, 1960, BIOCHEM J, V76, P381; Zangaro RA, 1996, APPL OPTICS, V35, P5211, DOI 10.1364/AO.35.005211; ZENG W, 2003, INT J CANCER, V104, P477; Zuluaga AF, 1999, APPL SPECTROSC, V53, P302, DOI 10.1366/0003702991946695	21	2	2	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		0-8194-5659-4	P SOC PHOTO-OPT INS			2005	5686						41	50		10.1117/12.589328		10	Engineering, Biomedical; Optics	Engineering; Optics	BCI71	WOS:000229607700007		
J	Ziv, E; Koytcheff, R; Middendorf, M; Wiggins, C				Ziv, E; Koytcheff, R; Middendorf, M; Wiggins, C			Systematic identification of statistically significant network measures	PHYSICAL REVIEW E			English	Article							ESCHERICHIA-COLI; TRANSCRIPTIONAL REGULATION; COMPLEX NETWORKS; PROTEIN; ORGANIZATION; SPECIFICITY; GRAPHS; MOTIFS; OPERON	We present a graph embedding space (i.e., a set of measures on graphs) for performing statistical analyses of networks. Key improvements over existing approaches include discovery of "motif hubs" (multiple overlapping significant subgraphs), computational efficiency relative to subgraph census, and flexibility (the method is easily generalizable to weighted and signed graphs). The embedding space is based on scalars, functionals of the adjacency matrix representing the network. Scalars are global, involving all nodes; although they can be related to subgraph enumeration, there is not a one-to-one mapping between scalars and subgraphs. Improvements in network randomization and significance testing-we learn the distribution rather than assuming Gaussianity-are also presented. The resulting algorithm establishes a systematic approach to the identification of the most significant scalars and suggests machine-learning techniques for network classification.	Columbia Univ, Coll Phys & Surg, New York, NY 10027 USA; Columbia Univ, Dept Biomed Engn, New York, NY 10027 USA; Columbia Univ, Dept Appl Phys & Appl Math, New York, NY 10027 USA; Columbia Univ, Dept Phys, New York, NY 10027 USA; Columbia Univ, Ctr Computat Biol & Bioinformat, New York, NY 10027 USA	Ziv, E (reprint author), Columbia Univ, Coll Phys & Surg, New York, NY 10027 USA.						Barabasi AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509; BENDER EA, 1978, J COMB THEORY A, V24, P296, DOI 10.1016/0097-3165(78)90059-6; Bohen SP, 2003, P NATL ACAD SCI USA, V100, P1926, DOI 10.1073/pnas.0437875100; COOK S, 1971, C REC 3 ANN ACM S TH, P151; Costanzo MC, 2000, NUCLEIC ACIDS RES, V28, P73, DOI 10.1093/nar/28.1.73; Cristianini N, 2000, INTRO SUPPORT VECTOR; Davis J. A., 1972, SOCIOLOGICAL THEORIE, V2, P218; DOBRIN R, 2004, BMC BIOINFORMATICS, V5, P1471; Harary F., 1955, T AM MATH SOC, V78, P445, DOI 10.2307/1993073; Hastie T., 2001, ELEMENTS STAT LEARNI; Holland Paul W., 1976, SOCIOL METHODOL, V7, P1, DOI 10.2307/270703; HOLLAND PW, 1970, AM J SOCIOL, V76, P492, DOI 10.1086/224954; Husmeier D, 2003, BIOINFORMATICS, V19, P2271, DOI 10.1093/bioinformatics/btg313; KATZ L, 1957, ANN MATH STAT, V28, P442, DOI 10.1214/aoms/1177706972; Krapivsky PL, 2000, PHYS REV LETT, V85, P4629, DOI 10.1103/PhysRevLett.85.4629; Lee TI, 2002, SCIENCE, V298, P799, DOI 10.1126/science.1075090; Maslov S, 2002, SCIENCE, V296, P910, DOI 10.1126/science.1065103; MIDDENDORF M, IN PRESS P NATL ACAD; Middendorf M, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-181; Milo R, 2002, SCIENCE, V298, P824, DOI 10.1126/science.298.5594.824; MOLLOY M, 1995, RANDOM STRUCT ALGOR, V6, P161, DOI 10.1002/rsa.3240060204; Newman MEJ, 2003, SIAM REV, V45, P167, DOI 10.1137/S003614450342480; PRICE DJD, 1965, SCIENCE, V149, P510; Rao AR, 1996, SANKHYA A, V58, P225; Roberts JM, 2000, SOC NETWORKS, V22, P273, DOI 10.1016/S0378-8733(00)00026-5; Salgado H, 2001, NUCLEIC ACIDS RES, V29, P72, DOI 10.1093/nar/29.1.72; Shen-Orr SS, 2002, NAT GENET, V31, P64, DOI 10.1038/ng881; SJNIDERS T, 1991, PSYCHOMETRIKA, V56, P397; SLOANE NJA, 2004, ONLINE ENCY INTEGER; Soutourina O, 1999, J BACTERIOL, V181, P7500; Spirin V, 2003, P NATL ACAD SCI USA, V100, P12123, DOI 10.1073/pnas.2032324100; Wasserman S., 1994, SOCIAL NETWORK ANAL; Wuchty S, 2003, NAT GENET, V35, P176, DOI 10.1038/ng1242; ZIV E, CONDMAT0306610	34	13	14	AMERICAN PHYSICAL SOC	COLLEGE PK	ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA	1063-651X			PHYS REV E	Phys. Rev. E	JAN	2005	71	1	2						016110	10.1103/PhysRevE.71.016110		8	Physics, Fluids & Plasmas; Physics, Mathematical	Physics	903XR	WOS:000227459400023	15697661	
J	Preisler, HK; Grulke, NE; Bytnerowicz, A; Esperanza, A				Preisler, H. K.; Grulke, N. E.; Bytnerowicz, A.; Esperanza, A.			Analyzing effects of forest fires on diurnal patterns of ozone concentrations	PHYTON-ANNALES REI BOTANICAE			English	Article; Proceedings Paper	6th International Symposium on Plant Responses to Air Pollution and Global Changes	OCT 19-22, 2004	Tsukuba, JAPAN	Tsukuba Ctr Inst & Epochal Tsukuba		autoregressive model; hourly ozone; nonparametric regression; spline functions		Monitoring and predicting ozone concentrations are a matter of special concern because ozone is one of the most important plant-damaging air pollutants in the world. High ozone concentrations have been shown to be harmful to plants not only within urban areas but also in remote regions such as national forests and parks in the USA. While meteorological stations collecting hourly data are available in many remote areas, there are only a handful of locations with continuous ozone monitors in the Sierra Nevada. This necessitates the need for a statistical model that predicts ozone concentrations from meteorological data. In this paper we develop an autoregressive model that uses nonparametric smoothing splines to estimate the nonlinear effects of meteorological data and fire history on diurnal ozone levels. The estimated relationships may be useful, among other things, as input to dynamic ozone forecasting models (e.g. MM5) to estimate ozone levels at locations or times with no active monitor data or to study effects of nearby prescribed and wild fires on ambient ozone levels.	WAB, USDA, Forest Serv, Pacific SW Res STn, Albany, CA 94710 USA; USDA, Forest Serv, Pacific SW Res Stn, Riverside, CA 92507 USA; Sequoia Natl Pk, Resource Management Off, Three Rivers, CA 93271 USA	Preisler, HK (reprint author), WAB, USDA, Forest Serv, Pacific SW Res STn, 800 Buchanan St, Albany, CA 94710 USA.	hpreisler@fs.fed.us					Bytnerowicz A, 2002, ENVIRON POLLUT, V118, P187, DOI 10.1016/S0269-7491(01)00312-8; Green PJ, 1994, NONPARAMETRIC REGRES; Grulke NE, 2003, TREES-STRUCT FUNCT, V17, P292, DOI 10.1007/s00468-002-0237-8; Hastie T., 2001, ELEMENTS STAT LEARNI; *INS CORP, S PLUS 6 WIND GUID S; Krupa S, 2003, ENVIRON POLLUT, V124, P173, DOI 10.1016/S0269-7491(02)00407-4; UNGER CD, 1978, P C SIERR NEV MET BO, P38	7	2	2	FERDINAND BERGER SOEHNE	HORN	WIENER STRASSE 21-23, A-3580 HORN, AUSTRIA	0079-2047			PHYTON-ANN REI BOT A	Phyton-Ann. REI Bot.		2005	45	4			SI		33	39				7	Plant Sciences	Plant Sciences	104PN	WOS:000241970700005		
J	Baranzini, SE; Mousavi, P; Rio, J; Caillier, SJ; Stillman, A; Villoslada, P; Wyatt, MM; Comabella, M; Greller, LD; Somogyi, R; Montalban, X; Oksenberg, JR				Baranzini, SE; Mousavi, P; Rio, J; Caillier, SJ; Stillman, A; Villoslada, P; Wyatt, MM; Comabella, M; Greller, LD; Somogyi, R; Montalban, X; Oksenberg, JR			Transcription-based prediction of response to IFN beta using supervised computational methods	PLOS BIOLOGY			English	Article							MULTIPLE-SCLEROSIS PATIENTS; GENE-EXPRESSION; INTERFERON-BETA; I INTERFERONS; APOPTOSIS; CELLS; MECHANISM; TRIALS; ALPHA; PCR	Changes in cellular functions in response to drug therapy are mediated by specific transcriptional profiles resulting from the induction or repression in the activity of a number of genes, thereby modifying the preexisting gene activity pattern of the drug- targeted cell( s). Recombinant human interferon beta ( rIFNbeta) is routinely used to control exacerbations in multiple sclerosis patients with only partial success, mainly because of adverse effects and a relatively large proportion of nonresponders. We applied advanced data- mining and predictive modeling tools to a longitudinal 70- gene expression dataset generated by kinetic reverse- transcription PCR from 52 multiple sclerosis patients treated with rIFNbeta to discover higher- order predictive patterns associated with treatment outcome and to define the molecular footprint that rIFNbeta engraves on peripheral blood mononuclear cells. We identified nine sets of gene triplets whose expression, when tested before the initiation of therapy, can predict the response to interferon beta with up to 86% accuracy. In addition, time- series analysis revealed potential key players involved in a good or poor response to interferon beta. Statistical testing of a random outcome class and tolerance to noise was carried out to establish the robustness of the predictive models. Large- scale kinetic reverse- transcription PCR, coupled with advanced data- mining efforts, can effectively reveal preexisting and drug- induced gene expression signatures associated with therapeutic effects.	Univ Calif San Francisco, Sch Med, Dept Neurol, San Francisco, CA 94143 USA; Queens Univ, Sch Comp, Kingston, ON, Canada; Hosp Gen Valle Hebron, Dept Neuroimmunol, Barcelona, Spain; Univ Navarra, Univ Navarra Clin, Dept Neurol, E-31080 Pamplona, Spain; Biosystemix, Sydenham, ON, Canada	Baranzini, SE (reprint author), Univ Calif San Francisco, Sch Med, Dept Neurol, San Francisco, CA 94143 USA.	sebaran@cgl.ucsf.edu	Baranzini, Sergio/A-9422-2013	Baranzini, Sergio/0000-0003-0067-194X			Akbar AN, 2000, IMMUNOL TODAY, V21, P337, DOI 10.1016/S0167-5699(00)01652-2; Arnason BGW, 1996, CLIN IMMUNOL IMMUNOP, V81, P1, DOI 10.1006/clin.1996.0149; Baranzini SE, 2000, J IMMUNOL, V165, P6576; Bertolotto A, 2001, J IMMUNOL METHODS, V256, P141, DOI 10.1016/S0022-1759(01)00434-3; Chawla-Sarkar M, 2003, APOPTOSIS, V8, P237, DOI 10.1023/A:1023668705040; D'haeseleer P, 2000, BIOINFORMATICS, V16, P707, DOI 10.1093/bioinformatics/16.8.707; Dupont SA, 2002, J INTERF CYTOK RES, V22, P491, DOI 10.1089/10799900252952280; Efron Bradley, 1993, INTRO BOOTSTRAP; Gniadek P, 2003, J NEUROIMMUNOL, V137, P187, DOI 10.1016/S0165-5728(03)00074-2; Grumont RJ, 2000, J EXP MED, V191, P1281, DOI 10.1084/jem.191.8.1281; Hastie T., 2001, ELEMENTS STAT LEARNI; JACOBS L, 1986, LANCET, V2, P1411; Kayagaki N, 1999, J EXP MED, V189, P1451, DOI 10.1084/jem.189.9.1451; Lehner M, 2001, BLOOD, V98, P736, DOI 10.1182/blood.V98.3.736; Mohr DC, 1998, MULT SCLER, V4, P487, DOI 10.1191/135245898678845160; Olshen AB, 2002, BIOINFORMATICS, V18, P961, DOI 10.1093/bioinformatics/18.7.961; Rengarajan J, 2002, J EXP MED, V195, P1003, DOI 10.1084/jem.20011128; Rio J, 2002, ANN NEUROL, V52, P400, DOI 10.1002/ana.10290; ROERS A, 1994, J INFECT DIS, V169, P807; SAMUEL CE, 1983, VIROLOGY, V130, P474, DOI 10.1016/0042-6822(83)90101-0; Schmittgen TD, 2000, J BIOCHEM BIOPH METH, V46, P69, DOI 10.1016/S0165-022X(00)00129-9; Sriram U, 2003, GENES IMMUN, V4, P147, DOI 10.1038/sj.gene.6363946; Sturzebecher S, 2003, BRAIN, V126, P1419, DOI 10.1093/brain/awg147; Thellin O, 1999, J BIOTECHNOL, V75, P291, DOI 10.1016/S0168-1656(99)00163-7; Tompkins WA, 1999, J INTERF CYTOK RES, V19, P817, DOI 10.1089/107999099313325; Van Weyenbergh J, 2001, J LEUKOCYTE BIOL, V70, P745; Weinstock-Guttman B, 2003, J IMMUNOL, V171, P2694; Wen XL, 1998, P NATL ACAD SCI USA, V95, P334, DOI 10.1073/pnas.95.1.334; Wiendl H, 2002, BIODRUGS, V16, P183, DOI 10.2165/00063030-200216030-00003; Zhang X, 1991, J Tongji Med Univ, V11, P126	30	101	103	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	185 BERRY ST, STE 1300, SAN FRANCISCO, CA 94107 USA	1544-9173			PLOS BIOL	PLoS. Biol.	JAN	2005	3	1					166	176	e2	10.1371/journal.pbio.0030002		11	Biochemistry & Molecular Biology; Biology	Biochemistry & Molecular Biology; Life Sciences & Biomedicine - Other Topics	899UC	WOS:000227169800019	15630474	
B	Chen, DW; Zhang, JP			IEEE	Chen, DW; Zhang, JP			Time series prediction based on ensemble ANFIS	Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9			English	Proceedings Paper	4th International Conference on Machine Learning and Cybernetics	AUG 18-21, 2005	Canton, PEOPLES R CHINA	IEEE Systems, Man & Cybernet TCC, Hong Kong Polytechn Univ, Hebei Univ, S China Univ Technol, Chongqing Univ, Sun Yatsen Univ, Harbin Inst Technol, Int Univ Germany		time series prediction; ANFIS; ensemble learning; bootstrap; traffic flow		In this paper, random and bootstrap sampling method and ANFIS (Adaptive Network based Fuzzy Inference System) are integrated into En-ANFIS (an ensemble ANFIS) to predict chaotic and traffic flow time series. The prediction results of En-ANFIS are compared with an ANFIS using all training data and each ANFIS unit in En-ANFIS. Experimental results show that the prediction accuracy of the En-ANFIS is higher than that of single ANFIS unit, while the number of training sample and training time of the En-ANFIS are less than that of the ANFIS using all training data. So, En-ANFIS is an effective method to achieve both high accuracy and less computational complexity for time series prediction.	Beijing Jiaotong Univ, Sch Elect & Informat Engn, Beijing 100044, Peoples R China	Chen, DW (reprint author), Beijing Jiaotong Univ, Sch Elect & Informat Engn, Beijing 100044, Peoples R China.						Chen DW, 2004, IEEE T INTELL TRANSP, V5, P246, DOI 10.1109/TITS.2004.838226; Crowder R. S., 1990, P 1990 CONN MOD SUMM, P117; Dietterieg T., 1998, AI MAG, V18, P97; Hastie T., 2001, ELEMENTS STAT LEARNI; JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541; KANDEL, 1992, FUZZY EXPERT SYSTEMS; MA J, 2004, P 3 INT C MACH LEARN, P867; MACKEY MC, 1997, SCIENCE, V197; Shumway R. H., 2000, TIMES SERIES ANAL IT; Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X	10	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9091-1				2005							3552	3556				5	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Information Systems	Computer Science	BDT94	WOS:000235325605052		
B	Ng, WWY; Yeung, DS; Wang, DF; Tsang, ECC; Wang, XZ			IEEE	Ng, WWY; Yeung, DS; Wang, DF; Tsang, ECC; Wang, XZ			Localized generalization error and its application to RBFNN training	Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9			English	Proceedings Paper	4th International Conference on Machine Learning and Cybernetics	AUG 18-21, 2005	Canton, PEOPLES R CHINA	IEEE Systems, Man & Cybernet TCC, Hong Kong Polytechn Univ, Hebei Univ, S China Univ Technol, Chongqing Univ, Sun Yatsen Univ, Harbin Inst Technol, Int Univ Germany		generalization error; model selection; neural networks; radial basis function NN; network architecture		The generalization error bounds for the entire input space found by current error models using the number of effective parameters of a classifier and the number of training samples are usually very loose. But classifiers such as SVM, RBFNN and MLPNN, are really local learning machines used for many application problems which consider unseen samples close to the training samples more important. In this paper, we propose a localized generalization error model which bounds above the generalization error within a neighborhood of the training samples using stochastic sensitivity measure (expectation of the squared output perturbations). It is then used to develop a model selection technique for a classifier with maximal coverage of unseen samples by specifying a generalization error threshold. Experiments by using eight real world datasets show that, in comparing with cross-validation, sequential learning, and two other ad-hoc methods, our technique consistently yields the best testing classification accuracy with fewer hidden neurons and less training time.	Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China	Ng, WWY (reprint author), Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China.						AKAIKE H, 1978, ANN I STAT MATH, P9; CHAKRABORTY D, 2003, IEEE T NEURAL NETWOR, P1; CHERKASSKY V, 1909, LEARNING DATA; Cherkassky V, 1999, IEEE T NEURAL NETWOR, V10, P1075, DOI 10.1109/72.788648; Hastie T., 2001, ELEMENT STAT LEARNIN; Haykin S., 1998, NEURAL NETWORKS; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; HUANG GB, 2004, IEEE T SYST MAN CY B, P2284; Jain L.C., 1999, IND APPL NEURAL NETW; Mitchell T., 1997, MACHINE LEARNING; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; NG WWY, 2003, IEE ELECT LETT, P787; Ng WWY, 2004, IEEE SYS MAN CYBERN, P3692, DOI 10.1109/ICSMC.2004.1400917; Ng WWY, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P4283; PARK H, 2004, NEURAL COMPUT, P355; Vapnik V., 1998, STAT LEARNING THEORY; Watanabe S, 2001, NEURAL COMPUT, V13, P899, DOI 10.1162/089976601300014402	17	5	5	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9091-1				2005							4667	4673				7	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Information Systems	Computer Science	BDT94	WOS:000235325607017		
B	Chen, WN; Zhang, HB		Zhu, Q		Chen, WN; Zhang, HB			Weighted projection approach for small sample size problem	Proceedings of the 11th Joint International Computer Conference			English	Proceedings Paper	11th Joint International Computer Conference (JICC 2005)	NOV 10-12, 2005	Chongqing, PEOPLES R CHINA	China Comp Federat, Hong Kong Comp Soc, Chongqing Informat Ind Bur, Chongqing Univ, Chongqing Univ Post & Telecommun		Weighted Projection Approach; null space based LDA; Bayesian method; Parameterized Weighted Projection Approach	FACE-RECOGNITION	In dealing with small sample size problem, such as face recognition from images, Null space based LDA and Bayesian method are two effective algorithms. In this paper, we analysis the two algorithms mentioned above from the view of Weighted Projection Approach, and show that they both can be viewed as special cases of Weighted Projection Approach. Then a Parameterized Weighted Projection Approach is proposed. It can combine the advantage of those two algorithms analyzed above and also exhibit good flexibility. Experiments show that the new algorithm is more flexible and can reach better performance.	Beijing Univ Technol, Coll Comp Sci, Beijing 100022, Peoples R China	Chen, WN (reprint author), Beijing Univ Technol, Coll Comp Sci, 100 Ping Le Yuan, Beijing 100022, Peoples R China.						Belhumeur P., 1996, ECCV, P45; CHEN LF, 2000, PATTERN RECOGNITION, V33; Hastie T., 2001, ELEMENT STAT LEARNIN; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Moghaddam B, 2000, PATTERN RECOGN, V33, P1771, DOI 10.1016/S0031-3203(99)00179-X; RUI H, 2002, PATTERN RECOGN, V3, P29; STAN Z, 2004, P 8 EUR C COMP VIS B; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; TEIXEIRA M, 2003, THESIS CSU; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; WANG X, 2003, P IEEE INT C COMP VI, P679	11	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	PO BOX 128 FARRER RD, SINGAPORE 9128, SINGAPORE			981-256-532-9				2005							884	887		10.1142/9789812701534_0197		4	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering; Imaging Science & Photographic Technology; Telecommunications	Computer Science; Imaging Science & Photographic Technology; Telecommunications	BDF35	WOS:000233230700197		
B	Tang, EK; Suganthan, PN; Yao, X			IEEE	Tang, EK; Suganthan, PN; Yao, X			Feature selection for microarray data using least squares SVM and particle swarm optimization	Proceedings of the 2005 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology			English	Proceedings Paper	2nd IEEE Symposium on Computational Intelligence in Bioformatics and Computational Biology	NOV 14-15, 2005	La Jolla, CA	IEEE Computat Intelligence Soc			SUPPORT VECTOR MACHINES/; GENE SELECTION; CLASSIFICATION; CANCER	Feature selection is an important preprocessing technique for many pattern recognition problems. When the number of features is very large while the number of samples is relatively small as in the micro-array data analysis, feature selection is even more important. This paper proposes a novel feature selection method to perform gene selection from DNA microarray data. The method originates from the least squares support vector machine (LSSVM). The particle swarm optimization (PSO) algorithm is also employed to perform optimization. Experimental results clearly demonstrate good and stable performance of the proposed method.	Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore	Tang, EK (reprint author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.		 Suganthan, .Ponnuthurai /A-5023-2011				Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Devijver P. A., 1982, PATTERN RECOGNITION; Eberhart R., 1995, P 6 INT S MICR HUM S, P39, DOI DOI 10.1109/MHS.1995.494215; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hastie T., 2001, ELEMENTS STAT LEARNI; Platt J., 2000, ADV LARGE MARGIN CLA; Rakotomamonjy A., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753706; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; Suykens J. A. K., 2002, LEAST SQUARES SUPPOR; Zhou X, 2005, BIOINFORMATICS, V21, P1559, DOI 10.1093/bioinformatics/bti216	11	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9387-2				2005							9	16				8	Biochemical Research Methods; Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Biochemistry & Molecular Biology; Computer Science	BDU91	WOS:000235518600002		
B	Ye, JK; Kulikowski, C; Muchnik, I			IEEE	Ye, JK; Kulikowski, C; Muchnik, I			Protein-protein interaction prediction based on sequence data by support vector machine with probability assignment	Proceedings of the 2005 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology			English	Proceedings Paper	2nd IEEE Symposium on Computational Intelligence in Bioformatics and Computational Biology	NOV 14-15, 2005	La Jolla, CA	IEEE Computat Intelligence Soc			2-HYBRID SYSTEM; SCALE	In this paper, we investigate the sequence-based protein-protein interaction prediction by machine learning methods. Specifically, we propose to build classifiers in the space of domain pairs, which are purely based on sequence data. We designed a novel way to select negative samples using a classification-based iterative voting procedure, and systematically compared the effects of negative sample selection on the performance of classification. We also propose an approach to estimate the probabilities for the predictions by SVM. Based on the selected negative samples, we compared nonlinear SVM based on gaussian kernel, linear SVM and linear logistic regression for both classification performance and probability assignments. Our results show that the probability assigned by SVM is more natural than logistic regression, and SVM also outperforms logistic regression for prediction.	Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA	Ye, JK (reprint author), Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA.						Bateman A, 2002, NUCLEIC ACIDS RES, V30, P276, DOI 10.1093/nar/30.1.276; Bock JR, 2001, BIOINFORMATICS, V17, P455, DOI 10.1093/bioinformatics/17.5.455; Chang C. C., LIBSVM LIB SUPPORT V; Dandekar T, 1998, TRENDS BIOCHEM SCI, V23, P324, DOI 10.1016/S0968-0004(98)01274-2; Enright AJ, 1999, NATURE, V402, P86; GENKIN A, BBR BAYESIAN LOGISTI; Gough J, 2002, NUCLEIC ACIDS RES, V30, P268, DOI 10.1093/nar/30.1.268; Han DS, 2004, NUCLEIC ACIDS RES, V32, P6312, DOI 10.1093/nar/gkh972; Hastie T., 2001, ELEMENTS STAT LEARNI; Huang Y, 2004, COMPUT BIOL CHEM, V28, P291, DOI 10.1016/j.compbiolchem.2004.07.003; Jansen R, 2004, CURR OPIN MICROBIOL, V7, P535, DOI 10.1016/j.mib.2004.08.012; Kim Wan Kyu, 2002, Genome Inform, V13, P42; Kleinbaum DG, 2002, LOGISTIC REGRESSION, DOI New York; Luban Jeremy, 1995, Current Opinion in Biotechnology, V6, P59, DOI 10.1016/0958-1669(95)80010-7; Pazos F, 2001, PROTEIN ENG, V14, P609, DOI 10.1093/protein/14.9.609; Pazos F, 2002, PROTEINS, V47, P219, DOI 10.1002/prot.10074; Platt J. C., 1999, ADV LARGE MARGIN CLA, P61; Sharan R, 2005, P NATL ACAD SCI USA, V102, P1974, DOI 10.1073/pnas.0409522102; Vapnik V. N., 1998, NATURE STAT LEARNING; von Mering C, 2002, NATURE, V417, P399	20	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9387-2				2005							318	324				7	Biochemical Research Methods; Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Biochemistry & Molecular Biology; Computer Science	BDU91	WOS:000235518600045		
B	Wu, Y; Fyfe, C		Zhao, MS; Shi, ZZ		Wu, Y; Fyfe, C			Pre-processing using topographic mappings	PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS AND BRAIN, VOLS 1-3			English	Proceedings Paper	International Conference on Neural Networks and Brain (ICNN&B 2005)	OCT 13-15, 2005	Beijing, PEOPLES R CHINA	China Neural Networks Council, IEEE Computat Intelligence Soc, Beijing Chapter, Chinese Inst Elect, Chinese Assoc Artificial Intelligence				We review two recently developed methods which are used to improve classifier accuracy, bagging and the random subspace method. Both of these methods (and other similar methods) may be characterized as deleting some of the information in the training set and creating classifiers which, though themselves sub-optimal, may be combined to create a better classifier than that created using the original data. We pre-process the data using an unsupervised method which creates topographic mappings and show that the resulting classifiers exhibit diversity and better performance.	Univ Paisley, Sch Comp, Paisley PA1 2BE, Renfrew, Scotland	Wu, Y (reprint author), Univ Paisley, Sch Comp, Paisley PA1 2BE, Renfrew, Scotland.	wuyingmm@yahoo.com.cn; colin.fyfe@paisley.ac.uk					Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BREIMEN L, ARCING EDGE, P486; FYFE C, 2005, INT C ART NEUR NETW; Hastie T., 2001, ELEMENTS STAT LEARNI; Kohonen T., 1995, SELF ORG MAPS; PENA M, 2005, WSEAS T COMPUTERS; YING W, 2005, UNPUB; Zhang B., 1999, K HARMONIC MEANS DAT; Zhang B, 2000, GEN K HARMONIC MEANS	9	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9422-4				2005							1881	1884				4	Computer Science, Artificial Intelligence	Computer Science	BEB63	WOS:000236575102121		
B	Poggio, T; Smale, S		Zhao, MS; Shi, ZZ		Poggio, T; Smale, S			The mathematics of learning: Dealing with data	PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS AND BRAIN, VOLS 1-3			English	Proceedings Paper	International Conference on Neural Networks and Brain (ICNN&B 2005)	OCT 13-15, 2005	Beijing, PEOPLES R CHINA	China Neural Networks Council, IEEE Computat Intelligence Soc, Beijing Chapter, Chinese Inst Elect, Chinese Assoc Artificial Intelligence			SUPPORT VECTOR MACHINES; REGULARIZATION THEORY; UNIFORM-CONVERGENCE; NEURAL NETWORKS; VISION; APPROXIMATION	Learning is key to developing systems tailored to a broad range of data analysis and information extraction tasks. We outline the mathematical foundations of learning theory and describe a key algorithm of it.	MIT, BCS, Artificial Intelligence Lab, CBCL,McGovern Inst, Cambridge, MA 02139 USA	Poggio, T (reprint author), MIT, BCS, Artificial Intelligence Lab, CBCL,McGovern Inst, Cambridge, MA 02139 USA.		Smale, Stephen/C-2908-2013				Alon N, 1997, J ACM, V44, P615, DOI 10.1145/263867.263927; ARONSZAJN N, 1950, T AM MATH SOC, V68, P337; BARRON AR, 1994, MACH LEARN, V14, P115, DOI 10.1023/A:1022650905902; BERTERO M, 1988, P IEEE, V76, P869, DOI 10.1109/5.5962; Beymer D, 1996, SCIENCE, V272, P1905, DOI 10.1126/science.272.5270.1905; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; Broomhead D. S., 1988, Complex Systems, V2; BRUNELLI R, 1991, P IJCAI SYDN AUSTR; Cortes C., 1995, MACH LEARN, V20, P1; Cucker F., 2001, B AM MATH SOC, V39, P1, DOI 10.1090/S0273-0979-01-00923-5; Cucker F, 2002, FOUND COMPUT MATH, V2, P413, DOI 10.1007/s102080010030; Daubechies I, 1992, CMBS NSF REGIONAL C; DEVORE R, 1989, UNPUB MATHEMATIKA; DeVore R. A., 1998, Acta Numerica, V7, DOI 10.1017/S0962492900002816; Devroye L., 1996, APPL MATH, V31; Donoho DL, 1998, IEEE T INFORM THEORY, V44, P2435, DOI 10.1109/18.720544; DUDLEY RM, 1987, ANN PROBAB, V15, P1306, DOI 10.1214/aop/1176991978; Dudley R.M., 1991, J THEORET PROBAB, V4, P485, DOI 10.1007/BF01210321; Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316; Ezzat T., 2002, P ACM SIGGRAPH 2002, P388, DOI 10.1145/566570.566594; FUNG G, 2001, KDD 2001 7 ACM SIGKD; GIROSI F, 1995, NEURAL COMPUT, V7, P219, DOI 10.1162/neco.1995.7.2.219; POGGIO T, 1990, SCIENCE, V247, P978, DOI 10.1126/science.247.4945.978; Girosi F, 1998, NEURAL COMPUT, V10, P1455, DOI 10.1162/089976698300017269; Hastie T., 2001, ELEMENTS STAT LEARNI; Heisele B, 2002, P IEEE, V90, P1164, DOI 10.1109/JPROC.2002.801450; Heisele B, 2002, ADV NEUR IN, V14, P1239; HUTCHINSON J, 1994, J FINANCE, V49; Karp R, 2002, NOT AM MATH SOC, V49, P544; KUTIN S, 2002, TR200203 U CHIC; Mendelson S, 2002, IEEE T INFORM THEORY, V48, P1977, DOI 10.1109/TIT.2002.1013137; MENDELSON S, 2003, UNPUB GEOMETRIC PARA; MICCHELLI CA, 1976, OPTIMAL ESTIMATION A, P1; MICCHELLI CA, 1986, CONSTR APPROX, V2, P11, DOI 10.1007/BF01893414; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; Niyogi P., 1999, Advances in Computational Mathematics, V10, DOI 10.1023/A:1018966213079; PAPAGEORGIOU C, 1998, P INT C COMP VIS BOM; PARZEN E, 1961, ANN MATH STAT, V32, P951, DOI 10.1214/aoms/1177704840; POGGIO T, 2000, INT J COMPUT VISION, P38; POGGIO T, 1990, P IEEE, V78, P9; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; POGGIO T, 1992, 1354 MIT ART INT LAB; POGGIO T, 1990, NATURE, V343, P263, DOI 10.1038/343263a0; Powell M. J., 1987, ALGORITHMS APPROXIMA; Powell M. J. D., 1992, ADV NUMERICAL ANAL, P105; RAMASWAMY T, 2001, P NAT AC SCI DEC; Rifkin R.M., 2002, THESIS MIT; SMALE S, 2003, ANAL APPL, V1, P1; Suykens J. A. K., 2002, LEAST SQUARES SUPPOR; Vapnik V., 1998, STAT LEARNING THEORY; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; WAHBA G, 1979, SOLUTIONS METHODS IN, P183; Wahba G., 1990, SERIES APPL MATH, V59; ZHOU D, 2001, REGULARITY REPROD KE; Zhou DX, 2002, J COMPLEXITY, V18, P739, DOI 10.1006/jcom.2002.0635	55	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9422-4				2005							PL5	PL23				19	Computer Science, Artificial Intelligence	Computer Science	BEB63	WOS:000236575100002		
B	Kang, WM; Shahabuddin, P		Kuhl, ME; Steiger, NM; Armstrong, FB; Joines, JA		Kang, WM; Shahabuddin, P			Fast simulation for multifactor portfolio credit risk in the t-copula model	Proceedings of the 2005 Winter Simulation Conference, Vols 1-4			English	Proceedings Paper	2005 Winter Simulation Conference (WSC 05)	DEC 04-07, 2005	Orlando, FL	Amer Stat Assoc, ACM SIGSIM, IEEE Comp Soc, IEEE SMC, Inst Ind Engineers, INFORMS SIM, NIST, Soc Modeling & Simulat Int				We present an importance sampling procedure for the estimation of multifactor portfolio credit risk for the t-copula model, i.e, the case where the risk factors have the multivariate t distribution. We use a version of the multivariate t that can be expressed as a ratio of a multivariate normal and a scaled chi-square random variable. The procedure consists of two steps. First, using the large deviations result for the Gaussian model in Glassenman, Kang, and Shahabuddin (2005a), we devise and apply a change of measure to the chi-square random variable. Then, conditional on the chi-square random variable, we apply the importance sampling procedure developed for the Gaussian copula model in Glasserman, Kano, Sliallabuddin (2005b). We support our importance sampling procedure by numerical examples.	Moodys KMV, New Prod Res, New York, NY 10007 USA	Kang, WM (reprint author), Moodys KMV, New Prod Res, 99 Church St, New York, NY 10007 USA.						Breymann W, 2003, QUANT FINANC, V3, P1, DOI 10.1088/1469-7688/3/1/301; Demarta S, 2004, T COPULA RELATED COP; EMBRECHTS P, 2001, MODELING DEPENDENCE; GLASSERMAN P, 2003, IN PRESS MANAGEMENT; GLASSERMAN P, 2005, LARGE DEVIATIONS MUL; Glasserman P., 2005, FAST SIMULATION MULT; Hastie T, 2001, ELEMENTS STAT LEARN; KOSTADINOV K, 2005, TAIL APPROXIMATION C; KUHN G, 2004, TAILS CREDIT DEFAULT; Lucas A, 2001, J BANK FINANC, V25, P1635, DOI 10.1016/S0378-4266(00)00147-3; Lucas A, 2003, APPL MATH FINANCE, V10, P337; Mashal R., 2002, CORRELATION EXTREME; Morokoff WJ, 2004, PROCEEDINGS OF THE 2004 WINTER SIMULATION CONFERENCE, VOLS 1 AND 2, P1668	13	7	7	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9519-0				2005							1859	1868				10	Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering; Operations Research & Management Science	Computer Science; Operations Research & Management Science	BDY77	WOS:000236253402065		
B	Skowron, A		Blair, S; Chakraborty, U; Chen, SH; Cheng, HD; Chiu, DKY; Das, S; Denker, G; Duro, R; Romay, MG; Hung, D; Kerre, EE; VaLeong, H; Lu, CT; Lu, J; Maguire, L; Ngo, CW; Sarfraz, M; Tseng, C; Tsumoto, S; Ventura, D; Wang, PP; Yao, X; Zhang, CN; Zhang, K		Skowron, A			Perception logic in intelligent systems	PROCEEDINGS OF THE 8TH JOINT CONFERENCE ON INFORMATION SCIENCES, VOLS 1-3			English	Proceedings Paper	8th Joint Conference on Information Sciences (JCIS 2005)	JUL 21-26, 2005	Salt Lake City, UT	Duke Univ, Utah State Univ, San Jose State Univ, Harbin Inst Technol			APPROXIMATION		Warsaw Univ, Inst Math, PL-02097 Warsaw, Poland	Skowron, A (reprint author), Warsaw Univ, Inst Math, Banacha 2, PL-02097 Warsaw, Poland.						Barsalou LW, 1999, BEHAV BRAIN SCI, V22, P577; Bar-Yam Y, 1997, DYNAMICS COMPLEX SYS; BAZAN J, 2005, IN PRESS P RSFDGRC 2; Bazan J, 2005, ADV SOFT COMP, P191, DOI 10.1007/3-540-32370-8_13; Bonabeau E., 1999, SWARM INTELLIGENCE N; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Brown F. N., 1990, BOOLEAN REASONING; Duda R.O., 2001, PATTERN CLASSIFICATI; DUNINKEPLICZ B, 2005, MONITORING SECURITY; Fahle M, 2002, PERCEPTUAL LEARNING; FREGE G, 1893, GRUNDLAGEN ARITHMETI, V2; Friedman J., 2001, ELEMENTS STAT LEARNI; Gell-Mann M, 1994, QUARK JAGUAR ADVENTU; Harnad S.R., 1987, CATEGORICAL PERCEPTI; Kloesgen Willi, 2002, HDB KNOWLEDGE DISCOV; Lesniewski S., 1929, FUND MATH, Vxiv, P1; Luck M, 2003, AGENT TECHNOLOGY ENA; Lukasiewicz J., 1970, J LUKASIEWICZ SELECT; Nguyen SH, 2004, LECT NOTES COMPUT SC, V3100, P187; Nguyen TT, 2003, LECT NOTES ARTIF INT, V2639, P221; Pal S.K., 1999, ROUGH FUZZY HYBRIDIZ; Pal S.K., 2004, ROUGH NEURAL COMPUTI; Pawlak Z., 1991, ROUGH SETS THEORETIC; Peters JF, 2005, LECT NOTES COMPUT SC, V3400, P153; Poggio T., 2003, NOTICES AMS, V50, P537; Polkowski L, 1996, INT J APPROX REASON, V15, P333, DOI 10.1016/S0888-613X(96)00072-2; SKOWRON A, 2004, ROUGH NEURAL COMPUTI, P43; Skowron A., 2001, B INT ROUGH SET SOC, V5, P9; Skowron A., 2000, 16th World Computer Congress 2000. Proceedings of Conference on Intelligent Information Processing; Stone P., 2000, LAYERED LEARNING MUL; Urmson C., 2004, CMURITR0437; Vapnik V., 1998, STAT LEARNING THEORY; Zadeh LA, 2001, AI MAG, V22, P73; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	34	0	0	JOINT CONFERENCE INFORMATION SCIENCES	DURHAM	2709 MONTGOMERY ST, DURHAM, NC 27705 USA							2005							2	6				5	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Computer Science	BDI96	WOS:000233670800001		
B	Gavrishchaka, VV		Blair, S; Chakraborty, U; Chen, SH; Cheng, HD; Chiu, DKY; Das, S; Denker, G; Duro, R; Romay, MG; Hung, D; Kerre, EE; VaLeong, H; Lu, CT; Lu, J; Maguire, L; Ngo, CW; Sarfraz, M; Tseng, C; Tsumoto, S; Ventura, D; Wang, PP; Yao, X; Zhang, CN; Zhang, K		Gavrishchaka, VV			Boosting frameworks in financial applications: From volatility forecasting to portfolio strategy optimization	Proceedings of the 8th Joint Conference on Information Sciences, Vols 1-3			English	Proceedings Paper	8th Joint Conference on Information Sciences (JCIS 2005)	JUL 21-26, 2005	Salt Lake City, UT	Duke Univ, Utah State Univ, San Jose State Univ, Harbin Inst Technol				Increasing availability of the multi-scale market data exposes limitations of the existing quantitative models such as low accuracy of the simplified analytical and statistical frameworks as well as insufficient interpretability and stability of the best machine learning algorithms. Boosting was recently proposed as a simple and efficient framework for intelligent combination of the clarity and stability of the analytical and parsimonious statistical models with accuracy of the adaptive data-driven models. Encouraging results of the boosting application to symbolic volatility forecasting have also been reported. However, accurate volatility modeling does not always warranty optimal decision making that leads to acceptable performance of the portfolio strategy. In this work, a boosting-based framework for a direct trading strategy and portfolio optimization is introduced. Due to inherent adaptive control of the parameter space dimensionality, this technique can work with very large pools of base strategies and financial instruments that are usually prohibitive for other portfolio optimization frameworks. Unlike existing approaches, this framework can be effectively used for the coupled optimization of the portfolio capital/asset allocation and dynamic trading strategies. Generated portfolios of trading strategies not only exhibit stable and robust performance but also remain interpretable. Encouraging preliminary results based on real market data are presented and discussed.	Alexandra Investment Management, New York, NY 10017 USA	Gavrishchaka, VV (reprint author), Alexandra Investment Management, New York, NY 10017 USA.						Bai DW, 1997, MANAGE SCI, V43, P895, DOI 10.1287/mnsc.43.7.895; BISHOP C.M., 1995, NEURAL NETWORKS PATT; Burgess A. N., 2003, APPL QUANTITATIVE ME; DRUCKER H, 1994, NEURAL COMPUTING, P6; ENGLE RF, 1987, ECONOMETRICA, V55, P251, DOI 10.2307/1913236; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; GAVRISHCHAKA VV, 2005, IN PRESS ADV ECONOME, P20; Hastie T., 2001, ELEMENTS STAT LEARNI; HILLER RS, 1993, MANAGE SCI, V39, P1422, DOI 10.1287/mnsc.39.11.1422; Katz J. O., 2000, ENCY TRADING STRATEG; KAUFMAN PJ, 1998, TRADINGY SYSTEMS MET; Markowitz H. M., 1959, PORTFOLIO SELECTION; Opitz D., 1999, J ARTIFICIAL INTELLI, V11, P169; RATSCH G, 2001, THESIS POTSDAM U; SCHAPIRE RE, 1992, THESIS MIT; TAY F, 2003, ORDINARY SHARES EXOT; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Vapnik V., 1998, STAT LEARNING THEORY; Witten IH, 2000, DATA MINING	19	0	0	JOINT CONFERENCE INFORMATION SCIENCES	DURHAM	2709 MONTGOMERY ST, DURHAM, NC 27705 USA							2005							1052	1058				7	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Computer Science	BDI96	WOS:000233670801121		
B	Tirenni, G; Labbi, A; Elisseeff, A; Berrospi, C		Kargupta, H; Srivastava, J; Kamath, C; Goodman, A		Tirenni, Giuliano; Labbi, Abderrahim; Elisseeff, Andre; Berrospi, Cesar			Efficient Allocation of Marketing Resources using Dynamic Programming	PROCEEDINGS OF THE FIFTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING	SIAM Proceedings Series		English	Proceedings Paper	5th SIAM International Conference on Data Mining	APR 21-23, 2005	Newport Beach, CA	SIAM, Lawrence Livermore Natl Lab, Ctr Appl Sci Comp, Amer Stat Assoc			CUSTOMER LIFETIME VALUE; MODELS	In this paper we address the following question: how to estimate a Markov Decision Process modeling the dynamics of customer relationships. Once the model is estimated, we discuss how to efficiently allocate marketing resources and instruments in order to maximize the long-term value generated by customers in a given future time horizon using dynamic programming. Our methodology allows us both to predict and to optimize the future value generated by customers. We show our approach using a case study involving a major European airline.	[Tirenni, Giuliano; Labbi, Abderrahim; Elisseeff, Andre; Berrospi, Cesar] IBM Zurich Res Lab, Dept Comp Sci, CH-8803 Ruschlikon, Switzerland	Tirenni, G (reprint author), IBM Zurich Res Lab, Dept Comp Sci, Saeumerstr 4, CH-8803 Ruschlikon, Switzerland.	tir@zurich.ibm.com; abl@zurich.ibm.com; ael@zurich.ibm.com; ceb@zurich.ibm.com					Bitran GR, 1996, MANAGE SCI, V42, P1364, DOI 10.1287/mnsc.42.9.1364; Breiman L., 1984, CLASSIFICATION REGRE; Ching WK, 2004, J OPER RES SOC, V55, P860, DOI 10.1057/palgrave.jors.2601755; Drew J. H., 2001, J SERV RES-US, V3, P205, DOI 10.1177/109467050133002; Gonul F, 1998, MANAGE SCI, V44, P1249, DOI 10.1287/mnsc.44.9.1249; Gupta S, 2004, J MARKETING RES, V41, P7, DOI 10.1509/jmkr.41.1.7.25084; Hastie T., 2001, ELEMENTS STAT LEARNI; Howard RA, 2002, OPER RES, V50, P100, DOI 10.1287/opre.50.1.100.17788; Jain D., 2002, J INTERACT MARK, V16, P34, DOI DOI 10.1002/DIR.10032; Kohonen T, 1997, SELF ORG MAPS; KOTLER P., 2000, MARKETING MANAGEMENT; Mitchell T., 1997, MACHINE LEARNING; PEDNAULT E, 2002, P 8 ACM SIGKDD INT C; Pfeifer P.E., 2000, J INTERACT MARK, V14, P43, DOI 10.1002/(SICI)1520-6653(200021)14:2<43::AID-DIR4>3.0.CO;2-H; Puterman M.L., 1994, MARKOV DECISION PROC; Rosset S, 2003, DATA MIN KNOWL DISC, V7, P321, DOI 10.1023/A:1024036305874; Rust RT, 2004, J MARKETING, V68, P109, DOI 10.1509/jmkg.68.1.109.24030; SIMESTER DI, 2003, DYNAMIC CATALO UNPUB; TIRENNI G, 2004, THESIS U ST GALLEN S	19	0	0	SIAM	PHILADELPHIA	3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA			978-0-89871-593-4	SIAM PROC S			2005							581	585				5	Computer Science, Artificial Intelligence	Computer Science	BUJ08	WOS:000289491000065		
S	Duch, W; Jankowski, N; Grabczewski, K		Zhao, X; Nguyen, HT		Duch, Wlodzislaw; Jankowski, Norbert; Grabczewski, Krzysztof			Computational intelligence methods for information understanding and information management	PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON INFORMATION AND MANAGEMENT SCIENCES	Series of Information and Management Sciences		English	Proceedings Paper	4th International Conference on Information and Management Sciences	JUL 01-10, 2005	Kunming, PEOPLES R CHINA			data understanding; knowledge extraction; decision support; data mining; computational intelligence; machine learning; neural networks; feature extraction; decision trees.	CLASSIFICATION; SIMILARITY	Information management relies on knowledge acquisition methods for extraction of knowledge from data. Statistical methods traditionally used for data analysis are satisfied with predictions, while understanding of data and extraction of knowledge from data are challenging tasks that have been pursued using computational intelligence (CI) methods. Recent advances in applications of CI methods to data understanding are presented, implementation of methods in the GhostMiner data mining package [1] developed in our laboratory described, new directions outlined and challenging open problems posed. To illustrate the advantages of different techniques, a single dataset is exposed to the many-sided analysis.	Nicholas Copernicus Univ, Dept Informat, PL-87100 Torun, Poland	Duch, W (reprint author), Nicholas Copernicus Univ, Dept Informat, PL-87100 Torun, Poland.		Grabczewski, Krzysztof/F-3574-2014; Jankowski, Norbert/H-1071-2014				Duch W, 2004, LECT NOTES COMPUT SC, V3316, P912; Duch W, 2001, IEEE T NEURAL NETWOR, V12, P277, DOI 10.1109/72.914524; Duch W, 2000, CONTROL CYBERN, V29, P937; Duch W, 2004, P IEEE, V92, P771, DOI 10.1109/JPROC.2004.826605; Duch W., 2004, P INT JOINT C NEUR N, P1415; Duch W., 2003, INT C ART NEUR NETW, P251; DUDA RO, 2001, PETTERN CLASSIFICATI; Grabczewski K, 2002, LECT NOTES COMPUT SC, V2415, P504; GRABCZEWSKI K, 2000, 5 C NEUR NETW SOFT C, P201; GRABCZEWSKI K, 2005, FEATURE EXTRACTION F; Grochowski M, 2004, LECT NOTES ARTIF INT, V3070, P580; Guyon I., 2005, FEATURE EXTRACTION F; Hastie T., 2001, ELEMENTS STAT LEARNI; Jambu M., 1991, EXPLORATORY MULTIVAR; Jankowski N, 2004, LECT NOTES ARTIF INT, V3070, P598; Jordan M.I., 2001, GRAPHICAL MODELS FDN; NAUD A, 2001, THESIS N COPERNICUS; Scholkopf B, 2002, LEARNING KERNELS; Walker AJ, 1999, LANCET, V354, P1518, DOI 10.1016/S0140-6736(99)02186-8	19	0	0	CALIFORNIA POLYTECHNIC STATE UNIV	SAN LUIS OBISPO	CAL POLY, SAN LUIS OBISPO, CA 93407 USA	1539-2023			SER INF MANAGE SCI			2005	4						281	287				7	Computer Science, Interdisciplinary Applications; Engineering, Industrial; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	BEI22	WOS:000237308600054		
B	Chacon, OL; Padilla, NR; Vazquez, E		Hamza, MH		Chacon, OL; Padilla, NR; Vazquez, E			Support vector classification through a clustering process	Proceedings of the IASTED International Conference on Computational Intelligence			English	Proceedings Paper	IASTED International Conference on Computational Intelligence	JUL 04-06, 2005	Calgary, CANADA	Int Assoc Sci & Technol Dev		classification; vector support; fuzzy clustering	VALIDITY; NUMBER	The support vector machine SVM has exhibited excellent generalization as classifier for linearly and non-linearly separable data sets. One drawback in using nonlinear SVM is the steep growth of the number of support vectors with increasing size of the training sets requiring long computational time and large amount of memory. In this work an initial data set reduction through a clustering process is proposed to overcome this problem.	Univ Autonoma Nuevo Leon, Grad Program Syst Engn, Monterrey, Nuevo Leon, Mexico	Chacon, OL (reprint author), Univ Autonoma Nuevo Leon, Grad Program Syst Engn, Monterrey, Nuevo Leon, Mexico.						BEZDEK JC, 1974, NUMERICAL TAXONOMY F, V1, P5771; Bharath R., 1994, NEURAL NETWORK COMPU; Burges C.J.C., 1998, TUTORIAL SUPPORT VEC; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Duda R.O., 2001, PATTERN CLASSIFICATI; Hastie T., 2001, ELEMENTS STAT LEARNI; Jain A., 1998, ALGORITHMS CLUSTERIN; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Kim DW, 2004, PATTERN RECOGN, V37, P2009, DOI 10.1016/j.patcog.2004.04.007; Osuna E, 1997, P IEEE NEUR NETW SIG; Platt J. C., 1998, MSRTR9814 MICR; Russell EL, 2000, DATA DRIVEN TECHNIQU; Scholkopf B., 2002, LEARNING KERNELS SUP; SMOLA AJ, NC2TR1998030 COLT2; Sun HJ, 2004, PATTERN RECOGN, V37, P2027, DOI 10.1016/j.patcog.2004.03.012; Tsekouras GE, 2004, ADV ENG SOFTW, V35, P567, DOI 10.1016/j.advengsoft.2004.05.001; Vapnik V., 1982, ESTIMATION DEPENDENC	17	0	0	ACTA PRESS	CALGARY	B6, STE 101, 2509 DIEPPE AVE SW, CALGARY, ALBERTA T3E 7J9, CANADA			0-88986-479-9				2005							97	103				7	Computer Science, Artificial Intelligence	Computer Science	BDE98	WOS:000233166400017		
S	Ma, YQ; Cherkassky, V			IEEE	Ma, YQ; Cherkassky, V			Characterization of data complexity for SVM methods	PROCEEDINGS OF THE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), VOLS 1-5	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Networks (IJCNN 2005)	JUL 31-AUG 04, 2005	Montreal, CANADA	Int Neural Network Soc, IEEE Computat Intelligence Soc				This paper provides new characterization of data complexity for margin-based methods also known as SVMs, kernel methods etc. Under the predictive learning setting, the complexity of a given data set is directly related to model complexity, i.e. the flexibility of it set of admissible models used to describe this data. There are two distinct approaches to model complexity control: traditional model-based where complexity is controlled via parameterization of admissible models, and margin-based where complexity is controlled by the size of margin (in a specially designed empirical loss function). This paper emphasizes the role of margin for complexity control, and proposes it simple index for data complexity suitable for classification and regression problems.	Honeywell Int Inc, Honeywell Labs, Minneapolis, MN 55418 USA	Ma, YQ (reprint author), Honeywell Int Inc, Honeywell Labs, 3660 Technol Dr, Minneapolis, MN 55418 USA.	yunqian.ma@honeywell.com; cherkass@ece.umn.edu					BARRON A, 1999, RISK BOUNDS MODEL SE, P301; CHERKASSKY V, 2004, 2004 IEEE INT JOINT, V1, P395; CHERKASSKY V, 2005, IN PRESS DATA COMPLE; Cherkassky V., 1998, LEARNING DATA CONCEP; Cherkassky V, 2004, NEURAL NETWORKS, V17, P113, DOI 10.1016/S0893-6080(03)00169-2; Duda R. O., 2000, PATTERN CLASSIFICATI; Hastie T., 2001, ELEMENTS STAT LEARNI; Mattera D., 1999, ADV KERNEL METHODS S; MIKA S, 2002, THESIS TU BERLIN; POGGIO T, 2002, MATH LEARNING DEALIN; RIPLEY BD, 1994, J ROY STAT SOC B MET, V56, P409; Ripley BD, 1996, PATTERN RECOGNITION; Scholkopf B., 2002, LEARNING KERNELS SUP; Suykens J. A. K., 2002, LEAST SQUARES SUPPOR; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Vapnik V., 1982, ESTIMATION DEPENDENC; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik VN, 1995, NATURE STAT LEARNING	18	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		0-7803-9048-2	IEEE IJCNN			2005							919	924				6	Computer Science, Artificial Intelligence	Computer Science	BDS40	WOS:000235178001045		
S	Bagotskaya, N; Lossev, I; Losseva, N; Parakhin, M			IEEE	Bagotskaya, N; Lossev, I; Losseva, N; Parakhin, M			Prediction of time to event for censored data: Ridge Regression with linear constraints in kernel space	Proceedings of the International Joint Conference on Neural Networks (IJCNN), Vols 1-5	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Networks (IJCNN 2005)	JUL 31-AUG 04, 2005	Montreal, CANADA	Int Neural Network Soc, IEEE Computat Intelligence Soc			BREAST-CANCER; SURVIVAL	We propose a new method for analyzing time to event in case of partially censored data and compare its performance for the particular task of breast cancer metastasis prediction with the performance of several known methods trained on the same data. In our approach, we use Ridge Regression for uncensored data, treating censored samples as constraints. Instead of initial feature space we use feature space defined by a kernel function. We reduce dimensionality by using coefficient of variation for each regression coefficient as a criterion for eliminating corresponding dimension.	Parascript LLC, Boulder, CO 80301 USA	Bagotskaya, N (reprint author), Parascript LLC, Boulder, CO 80301 USA.						AYAT NE, 2001, ICDAR, P1215; BISHOP C.M., 1995, NEURAL NETWORKS PATT; Chang C. C., LIBSVM LIB SUPPORT V; FARAGGI D, 1995, STAT MED, V14, P73, DOI 10.1002/sim.4780140108; Hastie T., 2001, ELEMENTS STAT LEARNI; Klein JP, 2003, SURVIVAL ANAL TECHNI; Kohler M, 2002, J MULTIVARIATE ANAL, V80, P73, DOI 10.1006/jmva.2000.1973; Nocedal J., 1999, NUMERICAL OPTIMIZATI; ONHOMAGHADO L, 1997, COMPUT BIOL MED, V27, P55; RIPLEY RM, 1998, SURVNNET NEURAL NETW; Sargent D.J., 2001, CANCER, V91; STUTE W, 1993, J MULTIVARIATE ANAL, V45, P89, DOI 10.1006/jmva.1993.1028; Tipping M. E., 2000, ADV NEURAL INFORM PR, V12; van de Vijver MJ, 2002, NEW ENGL J MED, V347, P1999, DOI 10.1056/NEJMoa021967; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vapnik V., 1998, STAT LEARNING THEORY; WESTON J, 2001, ADV INFORM PROCESSIN, V13	17	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		0-7803-9048-2	IEEE IJCNN			2005							1033	1038				6	Computer Science, Artificial Intelligence	Computer Science	BDS40	WOS:000235178001065		
S	Gao, DQ; Wang, Z; Li, YL			IEEE	Gao, DQ; Wang, Z; Li, YL			An improved kernel fisher discriminant classifier and its applications	Proceedings of the International Joint Conference on Neural Networks (IJCNN), Vols 1-5	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Networks (IJCNN 2005)	JUL 31-AUG 04, 2005	Montreal, CANADA	Int Neural Network Soc, IEEE Computat Intelligence Soc			NEURAL-NETWORK; DECOMPOSITION; RECOGNITION; ALGORITHM	In order to use kernel Fisher discriminant (KFD) classifiers to solve large-scale learning problems, this paper decomposes an n-class dataset into n two-class subsets, and use a subset only composed of a small part of the original dataset in determining the structure of a sing-le KFD classifier. The large number of samples in a class can be further represented by only a small number of prototypes with changeable widths, which are on behalf of kernels. Training samples are not certainly linearly separable in the kernel space, so additional expansive and contractive transformation is needed. Sigmoid functions call be use to implement such tasks. The results of two-spirals and letter recognition show that the proposed method is quite effective.	E China Univ Sci & Technol, State Key Lab Bioreactor Engn, Dept Comp Sci, Shanghai 200237, Peoples R China	Gao, DQ (reprint author), E China Univ Sci & Technol, State Key Lab Bioreactor Engn, Dept Comp Sci, Shanghai 200237, Peoples R China.						ANAND R, 1995, IEEE T NEURAL NETWOR, V6, P117, DOI 10.1109/72.363444; Bermejo S, 2001, NEURAL NETWORKS, V14, P1447, DOI 10.1016/S0893-6080(01)00106-X; Billings SA, 2002, NEURAL NETWORKS, V15, P263, DOI 10.1016/S0893-6080(01)00142-3; Blake C.L., 1998, UCI REPOSITORY MACHI; BOLLIVIER D, 1991, P INT JOINT C NEUR N, V2, P845; Cawley GC, 2003, PATTERN RECOGN, V36, P2585, DOI 10.1016/S0031-3203(03)00136-5; Collobert R, 2002, NEURAL COMPUT, V14, P1105, DOI 10.1162/089976602753633402; Duda R. O., 2000, PATTERN CLASSIFICATI; FREY PW, 1991, MACH LEARN, V6, P161, DOI 10.1007/BF00114162; Hastie T., 2001, ELEMENTS STAT LEARNI; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; JENKINS RE, 1993, IEEE T NEURAL NETWOR, V4, P718, DOI 10.1109/72.238326; Lang K. J., 1989, P 1988 CONN MOD SUMM, P52; Lu BL, 1999, IEEE T NEURAL NETWOR, V10, P1244, DOI 10.1109/72.788664; MIKE S, 1999, NEURAL NETWORKS SIGN, V9, P41; MONIRUL M, 2003, IEEE T NEURAL NETWOR, V14, P820; Park CH, 2004, PATTERN RECOGN, V37, P801, DOI 10.1016/j.patcog.2003.07.011; Scholkopf B, 1999, IEEE T NEURAL NETWOR, V10, P1000, DOI 10.1109/72.788641; UDA G, 1998, J INTELLIGENT ROBOTI, V21, P117; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Williamson JR, 1996, NEURAL NETWORKS, V9, P881, DOI 10.1016/0893-6080(95)00115-8; Yang J, 2004, NEUROCOMPUTING, V56, P415, DOI 10.1016/S0925-2312(03)00444-2	22	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		0-7803-9048-2	IEEE IJCNN			2005							1274	1279				6	Computer Science, Artificial Intelligence	Computer Science	BDS40	WOS:000235178001107		
S	Xiong, T; Cherkassky, V			IEEE	Xiong, T; Cherkassky, V			A combined SVM and LDA approach for classification	Proceedings of the International Joint Conference on Neural Networks (IJCNN), Vols 1-5	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Networks (IJCNN 2005)	JUL 31-AUG 04, 2005	Montreal, CANADA	Int Neural Network Soc, IEEE Computat Intelligence Soc				This paper describes a new large margin classifier, named SVM/LDA. This classifier can be viewed as an extension of support vector machine (SVM) by incorporating some global information about the data. The SVM/LDA classifier can be also seen as a generalization of linear discriminant analysis (LDA) by incorporating the idea of (local) margin maximization into standard LDA formulation. We show that existing SVM software can be used to solve the SVM/LDA formulation. We also present empirical comparisons of the proposed algorithm with SVM and LDA using both synthetic and real world benchmark data.	Univ Minnesota, Dept Elect & Comp Engn, Minneapolis, MN 55455 USA	Xiong, T (reprint author), Univ Minnesota, Dept Elect & Comp Engn, Minneapolis, MN 55455 USA.						Belhumeur P., 1996, ECCV, P45; Blake C.L., 1998, UCI REPOSITORY MACHI; Breiman L, 1998, ANN STAT, V26, P801; Cherkassky V., 1998, LEARNING DATA CONCEP; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Fukunaga K., 1990, INTRO STAT PATTERN C; Golub G.N., 1996, MATRIX COMPUTATIONS; Hastie T., 2001, ELEMENTS STAT LEARNI; Howland P, 2003, SIAM J MATRIX ANAL A, V25, P165, DOI 10.1137/S0895479801393666; Mika S, 2002, THESIS U TECHNOLOGY; Suykens J. A. K., 2002, LEAST SQUARES SUPPOR; Vapnik VN, 1995, NATURE STAT LEARNING; XIONG T, 2005, ADV NEURAL INFORM PR, V17; ZHANG X, 2001, INT JOINT C NEUR NET, P1486	14	10	11	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		0-7803-9048-2	IEEE IJCNN			2005							1455	1459				5	Computer Science, Artificial Intelligence	Computer Science	BDS40	WOS:000235178002022		
S	Stahlbock, R; Crone, SF			IEEE	Stahlbock, R; Crone, SF			Evolutionary neural classification for evaluation of retail stores and decision support	Proceedings of the International Joint Conference on Neural Networks (IJCNN), Vols 1-5	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Networks (IJCNN 2005)	JUL 31-AUG 04, 2005	Montreal, CANADA	Int Neural Network Soc, IEEE Computat Intelligence Soc			LEARNING VECTOR QUANTIZATION	The neural network paradigm of learning vector quantization (LVQ) and several enhancements of the standard algorithms have demonstrated improved predictive accuracy when applied to simple 'toy' problems. In this paper, we propose a novel approach of evolutionary optimized LVQ classification applied in real-world business decision support. We predict the success of retail outlets of a multinational German company in terms of revenue and profit. The predictions are used to support investment decisions, establishing new stores or closing down existing ones with limited prospective profits. In addition, the predictions provide information to change in-store design or product lines of existing stores. The LVQ networks are trained on data retlecting the macroscopic socio-demographic infrastructure and microscopic in-store aspects of existing outlets. Results of numerous computational experiments in a parallelized PC network are compared with standard neural networks, demonstrating pre-eminent results of the novel method.	Univ Hamburg, Inst Business Informat Syst, D-20146 Hamburg, Germany	Stahlbock, R (reprint author), Univ Hamburg, Inst Business Informat Syst, D-20146 Hamburg, Germany.						CRONE SF, 2002, P 9 INT C NEUR INF P, V5, P2374; DERIGS U, 1997, OR SPEKTRUM, P285; DeSieno D, 1988, P IEEE INT C NEURAL, V1, P117; Fausett L., 1994, FUNDAMENTALS NEURAL; Goldberg DE, 1989, GENETIC ALGORITHMS; Hastie T., 2001, ELEMENTS STAT LEARNI; HOLLAND JH, 1994, ADAPTATION NATURAL A; KITAJIMA N, 1995, P INT C NEUR NETW IE, V5, P2775, DOI 10.1109/ICNN.1995.488170; Kohonen T, 1997, SELF ORG MAPS; LAAKSONEN JT, 1992, ARTIFICIAL NEURAL NE, V2, P1181; Merelo JJ, 1995, ARTIFICIAL NEURAL NETS AND GENETIC ALGORITHMS, P92; Michalewicz Z, 1994, GENETIC ALGORITHMS D; *NEUR INC, 1993, NEUR COMP TECHN HDB; Odorico R, 1997, NEURAL NETWORKS, V10, P1083, DOI 10.1016/S0893-6080(97)00012-9; PAL NR, 1993, IEEE T NEURAL NETWOR, V3, P546; Patterson D, 1996, ARTIFICIAL NEURAL NE; PREGENZER M, 1994, P IEEE INT C NEURAL, V5, P2890, DOI 10.1109/ICNN.1994.374690; SATO A, 1999, C PUBL, V470, P928; Schurmann Jurgen, 1996, PATTERN CLASSIFICATI; Seo S, 2003, NEURAL COMPUT, V15, P1589, DOI 10.1162/089976603321891819; STAHLBOCK R, 2002, EVOLUTIONARE ENTWICK; STRICKERT M, 2004, THESIS U OSNABRUCK G; Vakil-Baghmisheh MT, 2003, PATTERN RECOGN, V36, P1901, DOI 10.1016/S0031-3203(02)00291-1; Verleysen M., 1993, New Trends in Neural Computation. International Workshop on Artificial Neural Networks. IWANN '93 Proceedings; YOU SJ, 1995, P ICNN 95 P IEEE INT, V5, P2763; ZELL ANDREAS, 1994, SIMULATION NEURONALE	26	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		0-7803-9048-2	IEEE IJCNN			2005							1499	1504				6	Computer Science, Artificial Intelligence	Computer Science	BDS40	WOS:000235178002031		
S	Fournier, PA; Brault, JJ			IEEE	Fournier, PA; Brault, JJ			Harmonic envelope prediction for realistic speech synthesis using kernel interpolation	Proceedings of the International Joint Conference on Neural Networks (IJCNN), Vols 1-5	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Networks (IJCNN 2005)	JUL 31-AUG 04, 2005	Montreal, CANADA	Int Neural Network Soc, IEEE Computat Intelligence Soc				Harmonic and noise diphone concatenation is a proven method to obtain high-quality speech synthesis, but cannot be used when the basis corpus does not contain all the diphones needed. We propose a method to complete an individual's corpus using examples from other corpora. Parametrisation of five vowels from different speakers is done with an harmonic and noise model (HNM). We use multi-frame analysis (MFA) and smoothing kernels to estimate the harmonic power spectrum envelopes. Different kernels are compared to predict the harmonic envelopes of vowels using training data. We use euclidian distance to measure similarity between the real envelopes and the predicted ones. Synthesis of the interpolated vowels are then performed using learned optimal parameters. Our results show Gaussian kernels can achieve a 1.8 dB (34.4%) reduction of harmonic distorsion compared to the mean harmonic envelope estimator. As far as we know, there is no other litterature on phoneme prediction for realistic speech synthesis.	Ecole Polytech, Dept Elect Engn, Montreal, PQ H3C 3A7, Canada	Fournier, PA (reprint author), Ecole Polytech, Dept Elect Engn, Montreal, PQ H3C 3A7, Canada.						Hastie T., 2001, ELEMENTS STAT LEARNI; Quatieri T, 2001, DISCRETE TIME SPEECH; Serra Xavier, 1997, MUSICAL SIGNAL PROCE; SHIGA Y, EUROSPEECH 2003 GENE; STYLIANOU Y, 1998, 3 ESCA COCOSDA WORKS; STYLIANOU Y, 1996, P ICSLP PHIL PA; WOUTERS J, 2000, SPECTRAL MODIFICATIO	7	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		0-7803-9048-2	IEEE IJCNN			2005							2059	2063				5	Computer Science, Artificial Intelligence	Computer Science	BDS40	WOS:000235178003011		
S	Plagianakos, VP; Tasoulis, DK; Vrahatis, MN			IEEE	Plagianakos, VP; Tasoulis, DK; Vrahatis, MN			Computational intelligence techniques for acute leukemia gene expression data classification	PROCEEDINGS OF THE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), VOLS 1-5	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Networks (IJCNN 2005)	JUL 31-AUG 04, 2005	Montreal, CANADA	Int Neural Network Soc, IEEE Computat Intelligence Soc			CLUSTER-ANALYSIS; PATTERNS; SEARCH	Recent advances in microarray technologies have allowed scientists to discover and monitor the mRNA transcript levels of thousands of genes in a single experiment. The data obtained from microarray studies present a challenge to data analysis. In this paper, we design an expression-based classification method for acute leukemia. Different dimension reduction techniques are considered to tackle the very high dimensionality of this kind of data. Subsequently, the classification system employs Artificial Neural Networks. The comparative results reported, indicate that high classification rates are possible and moreover that subsets of features that contribute significantly to the success of the neural classifiers can be identified.	Univ Patras, Dept Math, GR-26110 Patras, Greece	Plagianakos, VP (reprint author), Univ Patras, Dept Math, GR-26110 Patras, Greece.	vpp@math.upatras.gr; dtasf@math.upatras.gr; vrahatisf@math.upatras.gr					Aggarwal C., 1999, P 1999 ACM SIGMOD IN, P61, DOI 10.1145/304182.304188; Agrawal R., 1998, P ACM SIGMOD INT C M, P94, DOI 10.1145/276304.276314; Aldenderfer M.S., 1984, QUANTITATIVE APPL SO, V44; Alevizos P., 1998, P 14 EUR WORKSH COMP; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Becker R. W., 1970, Proceedings of the 8th annual Allerton conference on circuit and system theory; BENTLEY JL, 1980, ACTA INFORM, V13, P1551; Bezdek JC, 1981, PATTERN RECOGNITION; CHAZELLE B, 1986, SIAM J COMPUT, V15, P703, DOI 10.1137/0215051; DING CHQ, 2002, 6 ANN INT C COMP BIO, P127; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Fayyad U.M., 1996, ADV KNOWLEDGE DISCOV; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hartigan J. A., 1979, Applied Statistics, V28, DOI 10.2307/2346830; Hastie T., 2001, ELEMENTS STAT LEARNI; Haykin S., 1999, NEURAL NETWORKS; Jiang DX, 2004, IEEE T KNOWL DATA EN, V16, P1370; John G., 1994, P 11 INT C MACH LEAR, P121; Kohonen T, 1997, SELF ORG MAPS; MAGOULAS GD, 2001, P IEEE INT JOINT C N; PLAGIANAKOS VP, 2000, P 2 INT ICSC S NEUR; Preparata F P, 1985, COMPUTATIONAL GEOMET; RAMASUBRAMANIAN V, 1992, IEEE T SIGNAL PROCES, V40, P518, DOI 10.1109/78.120795; SHAMIR R, 2000, 8 INT C INT SYST MOL; Sutton R.S., 1993, P 10 INT C MACH LEAR, P314; Tasoulis D. K., 2004, EUR S INT TECHN HYBR, P47; Tavazoie S, 1999, NAT GENET, V22, P281; Thomas JG, 2001, GENOME RES, V11, P1227, DOI 10.1101/gr.165101; TORN A, 1989, LECT NOTES COMPUT SC, V350, P1; Vrahatis MN, 2002, J COMPLEXITY, V18, P375, DOI 10.1006/jcom.2001.0633; Wall M E, 2003, PRACTICAL APPROACH M, P91, DOI 10.1007/0-306-47815-3_5; Wen XL, 1998, P NATL ACAD SCI USA, V95, P334, DOI 10.1073/pnas.95.1.334; XING EP, 2001, BIOINFORMATICS, V1, P1	33	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		0-7803-9048-2	IEEE IJCNN			2005							2469	2474				6	Computer Science, Artificial Intelligence	Computer Science	BDS40	WOS:000235178003084		
S	Pelckmans, K; Suykens, JAK; De Moor, B			IEEE	Pelckmans, K; Suykens, JAK; De Moor, B			Maximal variation and missing values for componentwise support vector machines	Proceedings of the International Joint Conference on Neural Networks (IJCNN), Vols 1-5	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Networks (IJCNN 2005)	JUL 31-AUG 04, 2005	Montreal, CANADA	Int Neural Network Soc, IEEE Computat Intelligence Soc			REGRESSION; PURSUIT; LASSO	This paper proposes primal-dual kernel machine classifiers based on worst-case analysis of a finite set of observations including missing values of the inputs. Key ingredients are the use of a componentwise Support Vector Machine (cSVM) and an empirical measure of maximal variation of the components to bound the influence of the component which can not be evaluated due to missing values. A regularization term based on the L, norm of the maximal variation is used to obtain a mechanism for structure detection in that context. An efficient implemtation using the hierarchical kernel machines framework is elaborated.	Katholieke Univ Leuven, ESAT, SCD, SISTA, B-3001 Heverlee, Belgium	Pelckmans, K (reprint author), Katholieke Univ Leuven, ESAT, SCD, SISTA, Kasteelpk Arenberg 10, B-3001 Heverlee, Belgium.		Pelckmans, Kristiaan/A-3118-2013; Suykens, Johan/C-9781-2014				Antoniadis A, 2001, J AM STAT ASSOC, V96, P939, DOI 10.1198/016214501753208942; Boyd S., 2004, CONVEX OPTIMIZATION; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S003614450037906X; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; FRANK LE, 1993, TECHNOMETRICS, P109; FRIEDMAN JH, 1981, J AM STAT ASSOC, V76, P817, DOI 10.2307/2287576; Friedman JH, 1999, STAT COMPUT, V9, P123, DOI 10.1023/A:1008894516817; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Gunn SR, 2002, MACH LEARN, V48, P137, DOI 10.1023/A:1013903804720; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T. J., 1990, GENERALIZED ADDITIVE; Little RJA, 1987, STAT ANAL MISSING DA; PELCKMANS K, 2003, 03184 ESAT SISTA KU; PELCKMANS K, 2004, IN PRESS NEUROCOMPUT; PELECKMANS K, 2005, IN PRESS SUPPORT VEC; Rubin D. B., 1987, MULTIPLE IMPUTATION; RUBIN DB, 1976, BIOMETRIKA, V63, P581, DOI 10.1093/biomet/63.3.581; Scholkopf B, 2002, LEARNING KERNELS; Suykens J. A. K., 2002, LEAST SQUARES SUPPOR; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Vapnik V., 1998, STAT LEARNING THEORY	23	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		0-7803-9048-2	IEEE IJCNN			2005							2814	2819				6	Computer Science, Artificial Intelligence	Computer Science	BDS40	WOS:000235178004027		
S	Bailer-Jones, CAL		Turon, C; OFlaherty, KS; Perryman, MAC		Bailer-Jones, CAL			Object classification and the determination of stellar parameters	Proceedings of the Symposium the Three-Dimensional Universe with Gaia	ESA SPECIAL PUBLICATIONS		English	Proceedings Paper	Symposium on the Three-Dimensional Universe with Gaia	OCT 04-07, 2004	Paris, FRANCE	European Space Agcy, EADS Astrium, Alcatel Space, Alenia Spazio, CNES, CNRS, INSU, Obser Paris	Observ Paris Meudon	Gaia; classification; stellar parameters; data processing; multi-dimensional data analysis	GAIA	Gaia will observe more than one billion objects brighter than G = 20, including stars, asteroids, galaxies and quasars. As Gaia performs real time detection (i.e., without an input catalogue) the intrinsic properties of most of these objects will not be known a priori. An integral part of the Gaia data processing is therefore to classify everything observed. This will be based primarily on multi-band photometry provided by Gaia, but should also make optimal use of the high resolution spectroscopy (for brighter stars) and the parallaxes. In addition to a broad classification, we can also determine fundamental stellar parameters, in particular effective temperature, metallicity and the line-of-sight interstellar extinction. Such information will be essential for fully exploiting the astrometric part of the Gaia catalogue for stellar population studies. However, extracting this information is a significant challenge, and will need to make use of appropriate multi-dimensional data analysis techniques. I outline some of the problems and the strategies being developed to tackle them.	Max Planck Inst Astron, D-69117 Heidelberg, Germany	Bailer-Jones, CAL (reprint author), Max Planck Inst Astron, Konigstuhl 17, D-69117 Heidelberg, Germany.						Bailer-Jones CAL, 2002, ASTROPHYS SPACE SCI, V280, P21, DOI 10.1023/A:1015527705755; Bailer-Jones CAL, 2004, ASTRON ASTROPHYS, V419, P385, DOI 10.1051/0004-6361:20035779; Hastie T., 2001, ELEMENTS STAT LEARNI	3	2	2	ESA PUBLICATIONS DIVISION C/O ESTEC	2200 AG NOORDWIJK	PO BOX 299, 2200 AG NOORDWIJK, NETHERLANDS	0379-6566		92-9092-887-5	ESA SP PUBL			2005	576						393	399				7	Engineering, Aerospace; Astronomy & Astrophysics	Engineering; Astronomy & Astrophysics	BCI88	WOS:000229610000073		
J	Bermani, E; Boni, A; Kerhet, A; Massa, A				Bermani, E.; Boni, A.; Kerhet, A.; Massa, A.			Kernels evaluation of SVM-based estimators for inverse scattering problems	PROGRESS IN ELECTROMAGNETICS RESEARCH-PIER			English	Article							BURIED OBJECT DETECTION	Buried object detection by means of microwave-based sensing techniques is faced in biomedical imaging, mine detection, and many other practical tasks. Whereas conventional methods used for such a problem consist in solving nonlinear integral equations, this article considers a recently proposed learning by examples approach [1] based on Support Vector Machines, the techniques that proved to be theoretically justified and effective in real world domains. The article considers the approach performance for two different kernel functions: Gaussian and polynomial. The obtained results demonstrate that using polynomial kernels along with slightly sophisticated model selection criterion allow to outperform the Gaussian kernels. Simulations have been carried out for synthetic data generated by Finite Element code and a PML technique; noisy environments are considered as well. The results obtained by means of polynomial and Gaussian kernels are presented and discussed.	Univ Trent, Dept Informat & Commun Technol, I-38050 Trento, Italy	Bermani, E (reprint author), Univ Trent, Dept Informat & Commun Technol, Via Sommarive 14, I-38050 Trento, Italy.						Aizerman M, 1964, AUTOMAT REM CONTR, V25, P821; Anguita D, 2003, NEUROCOMPUTING, V55, P109, DOI 10.1016/S0925-2312(03)00430-2; Bermani E, 2004, PROG EL RES, V48, P185, DOI 10.2528/PIER03110701; Bermani E, 2003, IEEE T GEOSCI REMOTE, V41, P927, DOI 10.1109/TGRS.2003.810928; Bertsekas D.P., 1982, CONSTRAINED OPTIMIZA; CAORSI S, 2003, ACES J, V18; Chang C. C., 2003, LIBSVM LIB SUPPORT V; Cristianini N, 2000, INTRO SUPPORT VECTOR; Hastie T., 2001, ELEMENTS STAT LEARNI; Hsu C.-W., 2003, PRACTICAL GUIDE SUPP; Lin CJ, 2002, IEEE T NEURAL NETWOR, V13, P248, DOI 10.1109/72.977319; Platt J., 1999, ADV KERNEL METHODS S; Scholkopf B, 2002, LEARNING KERNELS; SMOLA A, 2000, NEURAL COMNPUTATION, V12, P1207; Vapnik V., 1999, NATURE STAT LEARNING	15	27	27	E M W PUBLISHING	CAMBRIDGE	PO BOX 425517, KENDALL SQUARE, CAMBRIDGE, MA 02142 USA	1559-8985			PROG ELECTROMAGN RES	Prog. Electromagn. Res.		2005	53						167	188		10.2528/PIER04090801		22	Engineering, Electrical & Electronic; Physics, Applied; Telecommunications	Engineering; Physics; Telecommunications	073QI	WOS:000239757300009		
S	Mora, M; Sbarbaro, D		Sanfeliu, A; Cortes, ML		Mora, M; Sbarbaro, D			A robust footprint detection using color images and neural networks	PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS AND APPLICATIONS, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	10th Iberoamerican Congress on Pattern Recognition	NOV 15-18, 2005	Havana, CUBA				SEGMENTATION	The automatic detection of different foot's diseases requires the analysis of a footprint, obtained from a digital image of the sole. This paper shows that optical monochromatic images are not suitable for footprint segmentation purposes, while color images provide enough information for carrying out an efficient segmentation. It is shown that a multiplayer perceptron trained with bayesian regularization backpropagation allows to adequately classify the pixels on the color image of the footprint and in this way, to segment the footprint without fingers. The footprint is improved by using a classical smoothing filter, and segmented by performing erosion and dilation operations. This result is very important for the development of a low cost system designed to diagnose pathologies related to the footprint form.	Univ Catolica Maule, Dept Comp Sci, Talca 617, Chile; Univ Concepcion, Dept Elect Engn, Concepcion 160C, Chile	Mora, M (reprint author), Univ Catolica Maule, Dept Comp Sci, Talca 617, Chile.	marco.mora@enseeiht.fr; dsbarbar@die.udec.cl	Sbarbaro, Daniel/J-9772-2012				Borsotti M, 1998, PATTERN RECOGN LETT, V19, P741, DOI 10.1016/S0167-8655(98)00052-X; Carron T., 1994, Proceedings ICIP-94 (Cat. No.94CH35708), DOI 10.1109/ICIP.1994.413699; Cheng HD, 2001, PATTERN RECOGN, V34, P2259, DOI 10.1016/S0031-3203(00)00149-7; DEMUHT H, 2003, NEURAL NETWORKS TOOL; DONY R, 1999, P IEEE CCECE99; Foresee D., 1997, P INT JOINT C NEUR N; FUNAHASHI K, 1989, NEURAL NETWORKS, V2, P183, DOI 10.1016/0893-6080(89)90003-8; GEVERS T, 1991, P 7 SCAND C IM AN; Gonzalez R. C., 1992, DIGITAL IMAGE PROCES; Hastie T., 2001, ELEMENTS STAT LEARNI; Haykin S., 1999, NEURAL NETWORKS COMP; HINTON GE, 1989, ARTIF INTELL, V40, P185, DOI 10.1016/0004-3702(89)90049-0; LIU JQ, 1994, IEEE T PATTERN ANAL, V16, P689; Littmann E, 1997, IEEE T NEURAL NETWOR, V8, P175, DOI 10.1109/72.554203; Lucchese L., 2001, PINSA-A (Proceedings of the Indian National Science Academy) Part A (Physical Sciences), V67; Luenberger D, 1984, LINEAR NONLINEAR PRO; MACKAY D, 1992, BAYESIAN INTERPOLATI; MCCLELLAND R, 1986, MIT PRESS, V1; Moody JE, 1997, ADV NEUR IN, V9, P585; MOREIRA J, 1996, ANAIS 9 SIBGRAPI; Nguyen D., 1990, P INT JOINT C NEUR N, V3, P21, DOI DOI 10.1109/IJCNN.1990.137819; VALENTI V, 1979, ORTHOTIC TREATMENT W; Weigand AS, 1991, ADV NEURAL INFORMATI, V3, P875	23	5	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29850-9	LECT NOTES COMPUT SC			2005	3773						311	318				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BDM81	WOS:000234341500033		
S	Bern, M; Chen, JD; Wong, HC		Miyano, S; Mesirov, J; Kasif, S; Istrail, S; Pevzner, P; Waterman, M		Bern, M; Chen, JD; Wong, HC			Avoiding local optima in single particle reconstruction	RESEARCH IN COMPUTATIONAL MOLECULAR BIOLOGY, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	9th Annual International Conference on Research in Computational Molecular Biology (RECOMB 2005)	MAY 14-18, 2005	Cambridge, MA	Broad Inst MIT & Harvard, Boston Univ Ctr Adv Geonom Technol			ELECTRON CRYOMICROSCOPY; MAXIMUM-LIKELIHOOD; MICROSCOPY; RESOLUTION; MODEL	In single-particle reconstruction, a 3D structure is reconstructed from a large number of randomly oriented 2D projections, using techniques related to computed tomography. Unlike in computed tomography, however, the orientations of the projections must be estimated at the same time as the 3D structure, and hence the reconstruction process can be error-prone, converging to an incorrect local optimum rather than the true 3D structure. In this paper, we discuss and further develop a maximum-likelihood approach to reconstruction, and demonstrate that this approach can help avoid incorrect local optima for both 2D and 3D reconstructions.	Xerox Corp, Palo Alto Res Ctr, Palo Alto, CA 94304 USA; Univ Fed Minas Gerais, Dept Ciencia Computacao, Belo Horizonte, MG, Brazil	Bern, M (reprint author), Xerox Corp, Palo Alto Res Ctr, 3333 Coyote Hill Rd, Palo Alto, CA 94304 USA.	bern@parc.com; jchen@parc.com; hcwong@parc.com					Abbott A, 2002, NATURE, V417, P894, DOI 10.1038/417894a; BROWN LG, 1992, ACM COMPUT SURV, V24, P325, DOI DOI 10.1145/146370.146374; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Efron B., 1982, CBMS NSF REGIONAL C, V38; FRANK J, 1996, 3 DIMENSIONAL ELECT; Frank J, 1996, J STRUCT BIOL, V116, P190, DOI 10.1006/jsbi.1996.0030; Hastie T., 2001, ELEMENTS STAT LEARNI; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Koster AJ, 1997, J STRUCT BIOL, V120, P276, DOI 10.1006/jsbi.1997.3933; Ludtke SJ, 1999, J STRUCT BIOL, V128, P82, DOI 10.1006/jsbi.1999.4174; Orlova EV, 1997, J MOL BIOL, V271, P417, DOI 10.1006/jmbi.1997.1182; PENCZEK P, 1992, ULTRAMICROSCOPY, V40, P33, DOI 10.1016/0304-3991(92)90233-A; Rouiller I, 2002, NAT STRUCT BIOL, V9, P950, DOI 10.1038/nsb872; Ruprecht J, 2001, PROG BIOPHYS MOL BIO, V75, P121, DOI 10.1016/S0079-6107(01)00004-9; SAXTON WO, 1977, ULTRAMICROSCOPY, V2, P219; Sigworth FJ, 1998, J STRUCT BIOL, V122, P328, DOI 10.1006/jsbi.1998.4014; STARK H, 3D ELECT CRYOMICROSC; van Heel M, 2000, Q REV BIOPHYS, V33, P307, DOI 10.1017/S0033583500003644; Wong HC, 2004, J STRUCT BIOL, V145, P157, DOI 10.1016/j.jsb.2003.05.001; Yonekura K, 2003, NATURE, V424, P643, DOI 10.1038/nature01830	20	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-25866-3	LECT NOTES COMPUT SC			2005	3500						118	132				15	Biochemical Research Methods; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Biochemistry & Molecular Biology; Computer Science	BCK44	WOS:000229741100010		
S	Frank, A; Tanner, S; Pevzner, P		Miyano, S; Mesirov, J; Kasif, S; Istrail, S; Pevzner, P; Waterman, M		Frank, A; Tanner, S; Pevzner, P			Peptide sequence tags for fast database search in mass-spectrometry	RESEARCH IN COMPUTATIONAL MOLECULAR BIOLOGY, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	9th Annual International Conference on Research in Computational Molecular Biology (RECOMB 2005)	MAY 14-18, 2005	Cambridge, MA	Broad Inst MIT & Harvard, Boston Univ Ctr Adv Geonom Technol			AMINO-ACID-SEQUENCES; PROTEIN IDENTIFICATION; SPECTRAL DATA; ALGORITHM; MODEL; VALIDATION	Filtration techniques, in the form of rapid elimination of candidate sequences while retaining the true one, are key ingredients of database searches in genomics. Although SEQUEST and Mascot are sometimes referred to as "BLAST for mass-spectrometry", the key algorithmic idea of BLAST (filtration) was never implemented in these tools. As a result MS/MS protein identification tools are becoming too time-consuming for many applications including search for post-translationally modified peptides. Moreover, matching millions of spectra against all known proteins will soon make these tools too slow in the same way that "genome vs. genome" comparisons instantly made BLAST too slow. We describe the development of filters for MS/MS database searches that dramatically reduce the running time and effectively remove the bottlenecks in searching the huge space of protein modifications. Our approach, based on a probability model for determining the accuracy of sequence tags, achieves superior results compared to GutenTag, a popular tag generation algorithm.	Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA; Univ Calif San Diego, Dept Bioinformat, La Jolla, CA 92093 USA	Frank, A (reprint author), Univ Calif San Diego, Dept Comp Sci & Engn, 9500 Gilman Dr, La Jolla, CA 92093 USA.	arf@cs.ucsd.edu; stanner@ucsd.edu; ppevzner@cs.ucsd.edu; ppevzner@cs.ucsd.edu					Aebersold R, 2003, NATURE, V422, P198, DOI 10.1038/nature01511; AHO AV, 1975, COMMUN ACM, V18, P333, DOI 10.1145/360825.360855; Bafna V., 2003, P 7 ANN INT C COMP M, P9, DOI 10.1145/640075.640077; Bafna V., 2001, BIOINFORMATICS S1, V17, P13; Chen T, 2001, J COMPUT BIOL, V8, P325, DOI 10.1089/10665270152530872; Colinge J, 2003, PROTEOMICS, V3, P1454, DOI 10.1002/pmic.200300485; Cormen T, 2001, INTRO ALGORITHMS; Creasy DM, 2002, PROTEOMICS, V2, P1426, DOI 10.1002/1615-9861(200210)2:10<1426::AID-PROT1426>3.0.CO;2-5; Dancik V, 1999, J COMPUT BIOL, V6, P327, DOI 10.1089/106652799318300; Day R. M., 2004, Proceedings. 2004 IEEE Computational Systems Bioinformatics Conference; Elias JE, 2004, NAT BIOTECHNOL, V22, P214, DOI 10.1038/nbt930; ENG JK, 1994, J AM SOC MASS SPECTR, V5, P976, DOI 10.1016/1044-0305(94)80016-2; Frank A, 2005, ANAL CHEM, V77, P964, DOI 10.1021/ac048788h; Hastie T., 2001, ELEMENTS STAT LEARNI; Havilio M, 2003, ANAL CHEM, V75, P435, DOI 10.1021/ac0258913; Hernandez P, 2003, PROTEOMICS, V3, P870, DOI 10.1002/pmic.200300402; Keller Andrew, 2002, OMICS A Journal of Integrative Biology, V6, P207, DOI 10.1089/153623102760092805; Lu B, 2004, DRUG DISCOV TODAY, V2, P85, DOI 10.1016/S1741-8364(04)02387-X; Lu B., 2003, BIOINFORMATICS S2, V19, pii113; Lu BW, 2003, J COMPUT BIOL, V10, P1, DOI 10.1089/106652703763255633; Lubeck O, 2002, P IEEE, V90, P1868, DOI 10.1109/JPROC.2002.805301; Ma B, 2003, RAPID COMMUN MASS SP, V17, P2337, DOI 10.1002/rcm.1196; MacCoss MJ, 2002, ANAL CHEM, V74, P5593, DOI 10.1021/ac025826t; Mann M, 2003, NAT BIOTECHNOL, V21, P255, DOI 10.1038/nbt0303-255; MANN M, 1994, ANAL CHEM, V66, P4390, DOI 10.1021/ac00096a002; Nesvizhskii AI, 2003, ANAL CHEM, V75, P4646, DOI 10.1021/ac0341261; Perkins DN, 1999, ELECTROPHORESIS, V20, P3551, DOI 10.1002/(SICI)1522-2683(19991201)20:18<3551::AID-ELPS3551>3.0.CO;2-2; Pevzner PA, 2001, GENOME RES, V11, P290, DOI 10.1101/gr.154101; PRINCE JT, 2004, NATURE BIOTECHNO APR; Razumovskaya J, 2004, PROTEOMICS, V4, P961, DOI 10.1002/pmic.200300656; Sadygov RG, 2003, ANAL CHEM, V75, P3792, DOI 10.1021/ac034157w; Schutz F, 2003, BIOCHEM SOC T, V31, P1479; Searle BC, 2004, ANAL CHEM, V76, P2220, DOI 10.1021/ac035258x; Shevchenko Anna, 2003, Methods Mol Biol, V211, P221; Shewchuk J. R., 1994, INTRO CONJUGATE GRAD; Sunyaev S, 2003, ANAL CHEM, V75, P1307, DOI 10.1021/ac026199a; Tabb DL, 2003, ANAL CHEM, V75, P1155, DOI 10.1021/ac026122m; Tabb DL, 2003, ANAL CHEM, V75, P6415, DOI 10.1021/ac0347462; TANNER S, 2005, UNPUB INSPECT FAST A; Taylor JA, 2001, ANAL CHEM, V73, P2594, DOI 10.1021/ac001196o; Taylor JA, 1997, RAPID COMMUN MASS SP, V11, P1067, DOI 10.1002/(SICI)1097-0231(19970615)11:9<1067::AID-RCM953>3.0.CO;2-L; YATES JR, 1995, ANAL CHEM, V67, P1426, DOI 10.1021/ac00104a020; YATES JR, 1995, ANAL CHEM, V67, P3202, DOI 10.1021/ac00114a016	43	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-25866-3	LECT NOTES COMPUT SC			2005	3500						326	341				16	Biochemical Research Methods; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Biochemistry & Molecular Biology; Computer Science	BCK44	WOS:000229741100025		
S	Skowron, A; Swiniarski, R		Slezak, D; Wang, G; Szczuka, M; Duntsch, I; Yao, Y		Skowron, A; Swiniarski, R			Rough sets and higher order vagueness	ROUGH SETS, FUZZY SETS, DATA MINING, AND GRANULAR COMPUTING, PRT 1, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	10th International Conference on Rough Sets, Fuzzy Sets, Data Mining and Granular Computing (RSFDGrC 2005)	AUG 31-SEP 03, 2005	Regina, CANADA		Univ Regina	vagueness; rough sets; higher order vagueness; adaptive learning	FUZZY LOGIC; PROPOSITIONAL CALCULI	We present a rough set approach to vague concept approximation within the adaptive learning framework. In particular, the role of extensions of approximation spaces in searching for concept approximation is emphasized. Boundary regions of approximated concepts within the adaptive learning framework are satisfying the higher order vagueness condition, i.e., the boundary regions of vague concepts are not crisp. There are important consequences of the presented framework for research on adaptive approximation of vague concepts and reasoning about approximated concepts. An illustrative example is included showing the application of Boolean reasoning in adaptive learning.	Warsaw Univ, Inst Math, PL-02097 Warsaw, Poland; Polish Acad Sci, Inst Comp Sci, PL-01237 Warsaw, Poland; San Diego State Univ, Dept Math & Comp Sci, San Diego, CA 92182 USA	Skowron, A (reprint author), Warsaw Univ, Inst Math, Banacha 2, PL-02097 Warsaw, Poland.	skowron@mimuw.edu.pl; rswiniar@sciences.sdsu.edu					Friedman J., 2001, ELEMENTS STAT LEARNI; Keefe R., 2000, THEORIES VAGUENESS; PAVELKA J, 1979, Z MATH LOGIK, V25, P45, DOI 10.1002/malq.19790250304; PAVELKA J, 1979, Z MATH LOGIK, V25, P447, DOI 10.1002/malq.19790252510; PAVELKA J, 1979, Z MATH LOGIK, V25, P119, DOI 10.1002/malq.19790250706; Pawlak Z, 1991, SYSTEM THEORY KNOWLE, V9; Pawlak Z., 1994, ADV DEMPSTER SHAFER, P251; Polkowski L., 2002, ROUGH SETS MATH FDN; Polkowski L, 1996, INT J APPROX REASON, V15, P333, DOI 10.1016/S0888-613X(96)00072-2; Read Stephen, 1995, THINKING LOGIC INTRO; SKOWRON A, 2005, FUNDAMENTA INFORM, V4, P417; SKOWRON A, 2004, LECT NOTES ARTIF INT, V3066, P114; SKOWRON A, 2004, ROUGH NEURAL COMPUTI, P43; Skowron A., 2000, P 16 WORLD COMP C IF, P1; Skowron A., 1996, Fundamenta Informaticae, V27; Stone P., 2000, LAYERED LEARNING MUL; Suraj Z., 1998, ROUGH SETS KNOWLEDGE, P418; Sutton R. S., 1998, REINFORCEMENT LEARNI; Vapnik V., 1998, STAT LEARNING THEORY; WOJNA A, 2005, LECT NOTES ARTIF INT, V2005, P428; Zadeh L, 1996, IEEE T FUZZY SYST, V2, P103, DOI DOI 10.1109/91.493904; Zadeh L. A., 1965, INFORM CONTR, V8, P333; ZIARKO W, 1993, J COMPUT SYST SCI, V46, P39, DOI 10.1016/0022-0000(93)90048-2	23	6	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-28653-5	LECT NOTES ARTIF INT			2005	3641						33	42				10	Computer Science, Artificial Intelligence	Computer Science	BCZ92	WOS:000232188600004		
S	Nishino, T; Nagamachi, M; Tanaka, H		Slezak, D; Wang, G; Szczuka, M; Duntsch, I; Yao, Y		Nishino, T; Nagamachi, M; Tanaka, H			Variable precision bayesian rough set model and its application to human evaluation data	ROUGH SETS, FUZZY SETS, DATA MINING, AND GRANULAR COMPUTING, PRT 1, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	10th International Conference on Rough Sets, Fuzzy Sets, Data Mining and Granular Computing (RSFDGrC 2005)	AUG 31-SEP 03, 2005	Regina, CANADA		Univ Regina		RULES	This paper focuses on a rough set method to analyze human evaluation data with much ambiguity such as sensory and feeling data. In order to handle totally ambiguous and probabilistic human evaluation data, we propose a probabilistic approximation based on information gains of equivalent classes. Furthermore, we propose a two-stage method to simply extract uncertain if - then rules using decision functions of approximate regions. Finally, we applied the proposed method to practical human sensory evaluation data and examined the effectiveness of the proposed method. The result shown that our proposed rough set method is more applicable to human evaluation data.	Hiroshima Univ, Fac Human & Social Environm, Dept Kansei Informat, Higashihiroshima, Hiroshima 7240695, Japan	Nishino, T (reprint author), Hiroshima Univ, Fac Human & Social Environm, Dept Kansei Informat, 555-36 Kurose, Higashihiroshima, Hiroshima 7240695, Japan.	t-nishi@he.hirokoku-u.ac.jp; m-nagama@he.hirokoku-u.ac.jp; h-tanaka@he.hirokoku-u.ac.jp					HASTIE T, 2001, ELEMENTS STAT LEARNI, P440; MORI N, 2004, ROUGH SETS KANSEI; Nagamachi M., 1996, INTRO KANSEI ENG; NISHINO T, 2003, P 14 TRIENN C INT ER, V3, P515; Pawlak Z, 1999, LECT NOTES ARTIF INT, V1711, P1; Slezak D, 2003, LECT NOTES ARTIF INT, V2639, P312; Slezak D, 2004, LECT NOTES ARTIF INT, V3066, P384; SLEZAK D, IN PRESS INT J APPRO; STEPANIUK J, 2000, ROUGH SET METHODS AP, P137; Tsumoto S, 1999, LECT NOTES ARTIF INT, V1711, P29; ZIARKO W, 1993, J COMPUT SYST SCI, V46, P39, DOI 10.1016/0022-0000(93)90048-2	11	9	10	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-28653-5	LECT NOTES ARTIF INT			2005	3641						294	303				10	Computer Science, Artificial Intelligence	Computer Science	BCZ92	WOS:000232188600031		
B	Sun, FS; Tzeng, CH		Arabnia, HR		Sun, FS; Tzeng, CH			A learning model for intrusion detection using tolerance relation	SAM '05: Proceedings of the 2005 International Conference on Security and Management			English	Proceedings Paper	International Conference on Security and Management	JUN 20-23, 2005	Las Vegas, NV					This paper introduces a learning model that generates rules for network intrusion detection purpose. Using conventional statistical tools, the model first induces simple detection rules to separate obvious network traffic and reduces the size of training data simultaneously. The model then applies tolerance relation on the remaining dataset to learn the conditional probabilities of normal network traffic and attack data. Based on these probabilities, the system generates the uncertain rules to predict a new network connection as either a normal type or an attack attempt.	Ball State Univ, Comp Sci Dept, Muncie, IN 47306 USA	Sun, FS (reprint author), Ball State Univ, Comp Sci Dept, Muncie, IN 47306 USA.						Barbara D, 2001, P 2001 IEEE WORKSH I; Berger JO, 1985, STAT DECISION THEORY; DENNING DE, 1986, P 1986 IEEE S SEC PR; GOOD IJ, 1983, FDN PROBABILITY ITS; Hastie T., 2001, ELEMENTS STAT LEARNI; DARPA 1998 NETWORK I	6	0	0	C S R E A PRESS	ATHENS	115 AVALON DR, ATHENS, GA 30606 USA			1-932415-82-3				2005							460	466				7	Computer Science, Theory & Methods	Computer Science	BDZ99	WOS:000236385400067		
S	Elad, A; Keller, Y; Kimmel, R		Kimmel, R; Sochen, N; Weickert, J		Elad, A; Keller, Y; Kimmel, R			Texture mapping via spherical multi-dimensional scaling	SCALE SPACE AND PDE METHODS IN COMPUTER VISION, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	5th International Conference on Scale-Space and PDE Methods in Computer Vision	APR 07-09, 2005	Hofgeismar, GERMANY	German Pattern Recognit Soc			POLYHEDRAL SURFACES; PARAMETERIZATION	We present a technique for texture mapping arbitrary sphere-like surfaces with minimal distortions by spherical embedding. The embedding is computed using spherical multi-dimensional scaling (MDS). MDS is a family of methods that map a set of points into a finite dimensional domain by minimizing the difference in distances between every pair of points in the original and the new embedding domains. In this paper spherical embedding is derived using geodesic distances on triangulated domains, computed by the fast marching method. The MDS is formulated as a non-linear optimization problem and a fast multi-resolution solution is derived. Finally, we show that the embedding of complex objects which are not sphere-like, can be improved by defining a texture dependent scale factor. This scale is the maximal distance to be preserved by the embedding and can be estimated using spherical harmonics. Experimental results show the benefits of the proposed approach.	Yale Univ, New Haven, CT 06520 USA; Technion Israel Inst Technol, IL-32000 Haifa, Israel	Elad, A (reprint author), Yale Univ, New Haven, CT 06520 USA.						Arad N, 1997, COMPUT GRAPH FORUM, V16, P247, DOI 10.1111/1467-8659.00192; Azariadis PN, 2000, COMPUT GRAPH-UK, V24, P539, DOI 10.1016/S0097-8493(00)00057-1; Borg I., 1997, MODERN MULTIDIMENSIO; Cox M. A., 1994, MULTIDIMENSIONAL SCA; Eck M., 1995, COMPUTER GRAPHICS, V29, P173; ELAD A, 2002, GEOMETRIC METHODS BI, V2191, P77; Gill PE, 1982, PRACTICAL OPTIMIZATI; Grossmann R, 2002, IEEE T PATTERN ANAL, V24, P433, DOI 10.1109/34.993552; Gu X., 2004, IEEE T MED IMAGING, V23; Haker S, 2000, IEEE T VIS COMPUT GR, V6, P181, DOI 10.1109/2945.856998; Hastie T., 2002, ELEMENTS STAT LEARNI; Kimmel R, 1998, P NATL ACAD SCI USA, V95, P8431, DOI 10.1073/pnas.95.15.8431; Kruskal J. B., 1978, MULTIDIMENSIONAL SCA; Maillot J, 1993, P SIGGRAPH 93, P27, DOI 10.1145/166117.166120; MANN S, 1984, IEEE INT C IM PROC, P363; Melax S., 1998, GAME DEV J; NEYRET PN, 1999, SIGGRAPH, P235; Praun E., 2000, P SIGGRAPH 2000, P465, DOI 10.1145/344779.344987; Schroeder W, 1997, OBJECT ORIENTED APPR; SCHWARTZ EL, 1989, IEEE T PATTERN ANAL, V11, P1005, DOI 10.1109/34.35506; SETHIAN J, 1996, REV THEORY ALGORITHM; Sheffer A, 2001, ENG COMPUT-GERMANY, V17, P326, DOI 10.1007/PL00013391; Sheffer A., 2002, Proceedings SMI. Shape Modeling International 2002, DOI 10.1109/SMI.2002.1003529; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; WANDELL BA, 2000, J COGNITIVE NEUROSCI; WOLFSON E, 1989, IEEE T PATTERN ANAL, V11, P1001, DOI 10.1109/34.35505; Zigelman G, 2002, IEEE T VIS COMPUT GR, V8, P198, DOI 10.1109/2945.998671	27	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-25547-8	LECT NOTES COMPUT SC			2005	3459						443	455				13	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCG59	WOS:000229214200038		
S	Schafer, J; Strimmer, K		Mendes, JFF; Dorogovtsev, SN; Povolotsky, A; Abreu, FV; Oliveira, JG		Schafer, J; Strimmer, K			Learning large-scale graphical Gaussian models from genomic data	Science of Complex Networks: From Biology to the Internet and WWW	AIP CONFERENCE PROCEEDINGS		English	Proceedings Paper	International Conference on Sciences of Complex Networks - From Biology to the Internet and WWW	AUG 29-SEP 02, 2004	Aveiro, PORTUGAL	Fund Cienc Tecnol*, COST P10 - Phys Risk, Fund Luso-Amer, Governo Civil Aveiro, Embaixada Franca, Embaixada Espanha, Caixa Geral Despositos, Lusitaniagas, Delta Cofes, Fund Calouste Gulbenk, Univ Aveiro		gene association network; systems biology; graphical Gaussian model; microarray; regularization; empirical Bayes; small-sample inference	EMPIRICAL BAYES; COVARIANCE-SELECTION; EXPRESSION PROFILES; GENETIC NETWORK; DISCOVERY	The inference and modeling of network-like structures in genomic data is of prime importance in systems biology. Complex stochastic associations and interdependencies can very generally be described as a graphical model. However, the paucity of available samples in current high-throughput experiments renders learning graphical models from genome data, such as microarray expression profiles, a challenging and very hard problems Here we review several recently developed approaches to small-sample inference of graphical Gaussian modeling and discuss strategies to cope with the high dimensionality of functional genomics data. Particular emphasis is put on regularization methods and an empirical Bayes network inference procedure.	Univ Munich, Dept Stat, D-80539 Munich, Germany	Schafer, J (reprint author), Univ Munich, Dept Stat, Ludwigstr 33, D-80539 Munich, Germany.						BAY SD, 2002, J BIOMED INFORMATICS, V35, P298; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; de la Fuente A, 2004, BIOINFORMATICS, V20, P3565, DOI 10.1093/bioinformatics/bth445; DEMPSTER AP, 1972, BIOMETRICS, V28, P157, DOI 10.2307/2528966; Dobra A, 2004, J MULTIVARIATE ANAL, V90, P196, DOI 10.1016/j.jmva.2004.02.009; Edwards D., 1995, INTRO GRAPHICAL MODE; Efron B, 2001, J AM STAT ASSOC, V96, P1151, DOI 10.1198/016214501753382129; Efron B, 2003, ANN STAT, V31, P366, DOI 10.1214/aos/1051027871; Hastie T., 2001, ELEMENTS STAT LEARNI; HOTELLING H, 1953, J ROY STAT SOC B, V15, P193; Husmeier D, 2003, BIOINFORMATICS, V19, P2271, DOI 10.1093/bioinformatics/btg313; Kishino H, 2000, Genome Inform Ser Workshop Genome Inform, V11, P83; Lauritzen S.L, 1996, GRAPHICAL MODELS; Magwene PM, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-12-r100; NEYMAN J, 1956, P 3 BERK S MATH STAT; Penrose R., 1955, P CAMBRIDGE PHILOS S, V51, P406, DOI DOI 10.1017/S0305004100030401; Raudys S, 1998, PATTERN RECOGN LETT, V19, P385, DOI 10.1016/S0167-8655(98)00016-6; SAPIR M, 2000, ESTIMATING POSTERIOR; Schafer J, 2005, BIOINFORMATICS, V21, P754, DOI 10.1093/bioinformatics/bti062; Skurichina M, 2002, PATTERN ANAL APPL, V5, P121, DOI 10.1007/s100440200011; Toh H, 2002, BIOINFORMATICS, V18, P287, DOI 10.1093/bioinformatics/18.2.287; Toh H, 2002, J BIOL PHYS, V28, P449, DOI 10.1023/A:1020337311471; Waddell P J, 2000, Genome Inform Ser Workshop Genome Inform, V11, P129; Wang JB, 2003, BIOINFORMATICS, V19, P2210, DOI 10.1093/bioinformatics/btg298; West M, 2001, P NATL ACAD SCI USA, V98, P11462, DOI 10.1073/pnas.201162998; WHITTAKER J, 1990, GRAPHICAL MODELS MUL; Wille A, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-11-r92; Wong F, 2003, BIOMETRIKA, V90, P809, DOI 10.1093/biomet/90.4.809; Wu X., 2003, ACM SIGKDD WORKSH DA, V3, P63	30	9	9	AMER INST PHYSICS	MELVILLE	2 HUNTINGTON QUADRANGLE, STE 1NO1, MELVILLE, NY 11747-4501 USA	0094-243X		0-7354-0262-0	AIP CONF PROC			2005	776						263	276				14	Multidisciplinary Sciences	Science & Technology - Other Topics	BCS10	WOS:000230988700021		
B	Cherkassky, V; Ma, YQ		Marcellin, MW		Cherkassky, V; Ma, YQ			Support vector machines and regularization	Seventh IASTED International Conference on Signal and Image Processing			English	Proceedings Paper	7th IASTED International Conference on Signal and Image Processing	AUG 15-17, 2005	Honolulu, HI	Int Assoc Sci & Technol Dev		function approximation; regularization; structural risk minimization	SELECTION; REGRESSION; PARAMETERS; NETWORKS	Recently, there has been a growing interest in Statistical Learning Theory, aka VC theory, due to many successful applications of Support Vector Machines (SVMs). Even though most theoretical results in VC-theory (including all main concepts underlying SVM methodology) have been developed over 25 years ago, these concepts are occasionally misunderstood in the research community. This paper compares standard SVM regression and the regularization for learning dependencies from data. We point out that SVM approach has been developed in VC-theory under risk minimization approach, whereas the regularization approach has been developed under function approximation setting. This distinction is especially important since regularization-based learning is often presented as a purely constructive methodology (with no clearly stated problem setting), even though original regularization theory has been introduced under clearly stated function approximation setting. Further, we present empirical comparisons illustrating the effect of different mechanisms for complexity control (i.e., epsilon-insensitive loss vs standard ridge regression) on the generalization performance, under very simple settings using synthetic data sets. These comparisons suggest that the SVM approach to complexity control (via epsilon-loss) is more appropriate for learning under sparse high-dimensional settings.	Univ Minnesota, Dept Elect & Comp Engn, Minneapolis, MN 55455 USA	Cherkassky, V (reprint author), Univ Minnesota, Dept Elect & Comp Engn, Minneapolis, MN 55455 USA.						Barron A, 1999, PROBAB THEORY REL, V113, P301, DOI 10.1007/s004400050210; Cherkassky V, 2002, LECT NOTES COMPUT SC, V2415, P687; Cherkassky V., 1998, LEARNING DATA CONCEP; Cherkassky V, 2004, NEURAL NETWORKS, V17, P113, DOI 10.1016/S0893-6080(03)00169-2; Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316; POGGIO T, 1990, SCIENCE, V247, P978, DOI 10.1126/science.247.4945.978; Hastie T., 2001, ELEMENTS STAT LEARNI; Scholkopf B., 2002, LEARNING KERNELS SUP; TIKHONOV N, 1963, DOKL AKAD NAUK SSSR, V153, P501; Tikhonov N A, 1977, SOLUTION ILL POSED P; Vapnik V., 1982, ESTIMATION DEPENDENC; Vapnik V., 1998, STAT LEARNING THEORY; VAPNIK VN, 1974, THEORY PATTERN RECOG; Vapnik VN, 1995, NATURE STAT LEARNING	14	0	0	ACTA PRESS	CALGARY	B6, STE 101, 2509 DIEPPE AVE SW, CALGARY, ALBERTA T3E 7J9, CANADA			0-88986-516-7				2005							166	171				6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BDF42	WOS:000233235300031		
J	Chu, M; Del Buono, N; Lopez, L; Politi, T				Chu, M; Del Buono, N; Lopez, L; Politi, T			On the low-rank approximation of data on the unit sphere	SIAM JOURNAL ON MATRIX ANALYSIS AND APPLICATIONS			English	Article						standardized data; linear model; factor analysis; low-rank approximation; latent semantic indexing; projected gradient	LEAST-SQUARES; MATRICES	In various applications, data in multidimensional space are normalized to unit length. This paper considers the problem of best fitting given points on the m-dimensional unit sphere Sm-1 by k-dimensional great circles with k much less than m. The task is cast as an algebraically constrained low-rank matrix approximation problem. Using the fidelity of the low-rank approximation to the original data as the cost function, this paper offers an analytic expression of the projected gradient which, on one hand, furnishes the first order optimality condition and, on the other hand, can be used as a numerical means for solving this problem.	N Carolina State Univ, Dept Math, Raleigh, NC 27695 USA; Univ Bari, Dipartimento Matemat, I-70125 Bari, Italy; Politecn Bari, Dipartimento Matemat, I-70126 Bari, Italy	Chu, M (reprint author), N Carolina State Univ, Dept Math, Raleigh, NC 27695 USA.	chu@math.ncsu.edu; delbuono@dm.uniba.it; lopezl@dm.uniba.it; politi@poliba.it	Lopez, Luciano/I-3415-2013				Antoulas A. C., 2001, International Journal of Applied Mathematics and Computer Science, V11; Berry M.W., 2001, COMPUTATIONAL INFORM; BURG JP, 1982, P IEEE, V70, P963, DOI 10.1109/PROC.1982.12427; CHAHLAOUI Y., 2003, THESIS U CATHOLIQUE; Chill R, 2003, J FUNCT ANAL, V201, P572, DOI 10.1016/S0022-1236(02)00102-7; CHU MT, 2000, STAT MEANING TRUNCAT; Chu MT, 2003, LINEAR ALGEBRA APPL, V366, P157, DOI 10.1016/S0024-3795(02)00505-0; CHU MT, 1990, SIAM J NUMER ANAL, V27, P1050, DOI 10.1137/0727062; DEBEER R, 1995, QUANTITATIVE VIVO NM; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; DEMOOR B, 1994, IEEE T SIGNAL PROCES, V42, P3104, DOI 10.1109/78.330370; DENDRINOS M, 1991, SPEECH COMMUN, V10, P45, DOI 10.1016/0167-6393(91)90027-Q; Dhillon IS, 2001, MACH LEARN, V42, P143, DOI 10.1023/A:1007612920971; Dhillon IS, 2003, BIOINFORMATICS, V19, P1612, DOI 10.1093/bioinformatics/btg209; Duda R.O., 2001, PATTERN CLASSIFICATI; Gill P. E., 1981, PRACTICAL OPTIMIZATI; Hastie T., 2001, ELEMENTS STAT LEARNI; Horst P., 1965, FACTOR ANAL DATA MAT; Hubert L, 2000, SIAM REV, V42, P68, DOI 10.1137/S0036144598340483; Iserles A., 2000, Acta Numerica, V9, DOI 10.1017/S0962492900002154; Iusem AN, 2003, COMPUT APPL MATH, V22, P37; Jolliffe I., 2002, PRINCIPAL COMPONENT; Kleinberg J, 1998, DATA MIN KNOWL DISC, V2, P311, DOI 10.1023/A:1009726428407; Kolda TG, 1998, ACM T INFORM SYST, V16, P322, DOI 10.1145/291128.291131; Lojasiewicz S., 1963, C INT CNRS, V117, P87; Mitra M., 1996, P 19 ANN INT ACM SIG, P21, DOI 10.1145/243199.243206; Paatero P, 1997, CHEMOMETR INTELL LAB, V37, P23, DOI 10.1016/S0169-7439(96)00044-5; Park H, 2001, COMPUTATIONAL INFORMATION RETRIEVAL, P3; SALTON G, 1983, INTRO MODERN INFORMA; Shampine LF, 1997, SIAM J SCI COMPUT, V18, P1, DOI 10.1137/S1064827594276424; SIMON L, 1983, ANN MATH, V118, P525, DOI 10.2307/2006981; STIEFEL E., 1935, COMMENT MATH HELV, V8, P305, DOI 10.1007/BF01199559; Stoica P, 1996, IEEE T SIGNAL PROCES, V44, P3069, DOI 10.1109/78.553480; Tropp JA, 2005, IEEE T INFORM THEORY, V51, P188, DOI 10.1109/TIT.2004.839492	34	9	9	SIAM PUBLICATIONS	PHILADELPHIA	3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA	0895-4798			SIAM J MATRIX ANAL A	SIAM J. Matrix Anal. Appl.		2005	27	1					46	60		10.1137/S0895479803433295		15	Mathematics, Applied	Mathematics	966OC	WOS:000232028400003		
S	Tenmoto, H; Kudo, M		Abraham, A; Dote, Y; Furuhashi, T; Koppen, M; Ohuchi, A; Ohsawa, Y		Tenmoto, H; Kudo, M			Density- and complexity-regularization in Gaussian mixture Bayesian classifier	Soft Computing as Transdisciplinary Science and Technology	ADVANCES IN SOFT COMPUTING		English	Proceedings Paper	4th IEEE International Workshop on Soft Computing as Transdisciplinary Science and Technology (WSTST 05)	2005	Muroran, JAPAN	IEEEE Syst Man & Cybernet Soc, World Federat Soft Comp, European Soc Fuzzy Log & Technol, Japan Soc Promot Sci, Soc Instrumentat & Control Engineers, Transdisciplinary Federat Sci & Technol, JSPS Int Meeting Series, Life Oriented Software Lab	Muroran Inst Technol		LIKELIHOOD; ALGORITHM	We regularize Gaussian mixture Bayesian (GMB) classifier in terms of the following two points: 1) class-conditional probability density functions, and 2) complexity as a classifier. For the former, we employ the Bayesian regularization method proposed by Ormoneit and Tresp, which is derived from the maximum a posteriori (MAP) estimation framework. For the latter, we use a discriminative MDL-based model selection method proposed by us. In this paper, we optimize the hyperparameters in 1) and 2) simultaneously with respect to the discriminative MDL criterion, aiming to auto-configure the hyperparameter setting for the best classification performance. We show the effectiveness of the proposed method through some experiments on real datasets.	Kushiro Natl Coll Technol, Dept Informat Engn, Kushiro, Hokkaido 0840916, Japan	Tenmoto, H (reprint author), Kushiro Natl Coll Technol, Dept Informat Engn, Otanoshike Nishi 2-32-1, Kushiro, Hokkaido 0840916, Japan.						DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Hastie T., 2001, ELEMENTS STAT LEARNI; Kudo M., 1996, Proceedings of the 13th International Conference on Pattern Recognition, DOI 10.1109/ICPR.1996.547203; Murphy P.M., 1996, UCI REPOSITORY MACHI; Ormoneit D, 1998, IEEE T NEURAL NETWOR, V9, P639, DOI 10.1109/72.701177; PARK Y, 1989, J CLASSIF, V6, P195, DOI 10.1007/BF01908599; Tenmoto H, 2000, LECT NOTES COMPUT SC, V1876, P511	7	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1615-3871		3-540-25055-7	ADV SOFT COMP			2005							391	399				9	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Computer Science	BCV56	WOS:000231416200046		
S	Berman, M; Phatak, A; Lagerstrom, R		Bearman, GH; MahadevanJansen, A; Leveson, RM		Berman, M; Phatak, A; Lagerstrom, R			ICE: A statistical approach to identifying constituents of biomedical hyperspectral images	Spectral Imaging: Instrumentation, Applications, and Analysis III	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Conference on Spectral Imaging - Instrumentation. Applications and Analysis III	JAN   23, 2005	San Jose, CA	SPIE, Cambridge Res & Instrumentat Inc, Carl Zeiss Jena		convex geometry; endmember; hyperspectral; mixture; simplex		A problem of considerable interest in the hyperspectral and chemical imaging communities in recent years has been the automated identification and mapping of the constituent materials ("endmembers") present in a hyperspectral image. Several of the more important endmember-finding algorithms are discussed and some of their shortcomings highlighted. A relatively new algorithm, ICE, which attempts to address these shortcomings, is introduced. Although ICE was originally developed for exploration applications of airborne hyperspectral data, its performance on two biomedical data sets is investigated. Possible future research directions are outlined.	CSIRO, N Ryde, NSW 2113, Australia	Berman, M (reprint author), CSIRO, Macquarie Univ Campus, N Ryde, NSW 2113, Australia.		Lagerstrom, Ryan/A-3642-2009; Whitford, Linda/C-2470-2009; Berman, Mark/D-3411-2009				Berman M, 2004, IEEE T GEOSCI REMOTE, V42, P2085, DOI 10.1109/TGRS.2004.835299; Berman M., 1999, P 13 INT C APPL GEOL, V1, P222; BOARDMAN E, 1995, JPL PUBL, V951, P23; Boardman JW, 1993, JPL PUBLICATION, V93-26, P11; Box G., 1979, ROBUSTNESS STAT, P201; CRAIG MD, 1994, IEEE T GEOSCI REMOTE, V32, P542, DOI 10.1109/36.297973; de Juan A, 2004, TRAC-TREND ANAL CHEM, V23, P70, DOI 10.1016/S0165-9936(04)00101-3; *ENVI, 2000, ENV VIS IM US GUID V; GREEN AA, 1988, IEEE T GEOSCI REMOTE, V26, P65, DOI 10.1109/36.3001; Hastie T., 2001, ELEMENTS STAT LEARNI; HAZEWINKEL M, 1995, ENCY MATH, V5; LEE JB, 1990, IEEE T GEOSCI REMOTE, V28, P295, DOI 10.1109/36.54356; Nocedal J., 1999, NUMERICAL OPTIMIZATI; Press W.H., 1992, NUMERICAL RECIPES C; Weibel E.R., 1980, STEREOLOGICAL METHOD; Winter M., 1999, P 13 INT C APPL GEOL, V2, P337	16	2	2	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		0-8194-5668-3	P SOC PHOTO-OPT INS			2005	5694						62	73		10.1117/12.600291		12	Spectroscopy	Spectroscopy	BCH87	WOS:000229357000008		
J	Thorsson, V; Hornquist, M; Siegel, AF; Hood, L				Thorsson, V; Hornquist, M; Siegel, AF; Hood, L			Reverse engineering galactose regulation in yeast through model selection	STATISTICAL APPLICATIONS IN GENETICS AND MOLECULAR BIOLOGY			English	Article						model selection; regression; AIC; BIC; MDL; Cp; bootstrap; Lasso	GENE NETWORKS; REGRESSION; LASSO	We examine the application of statistical model selection methods to reverse-engineering the control of galactose utilization in yeast from DNA microarray experiment data. In these experiments, relationships among gene expression values are revealed through modifications of galactose sugar level and genetic perturbations through knockouts. For each gene variable, we select predictors using a variety of methods, taking into account the variance in each measurement. These methods include maximization of log-likelihood with Cp, AIC, and BIC penalties, bootstrap and cross-validation error estimation, and coefficient shrinkage via the Lasso.	Linkoping Univ, S-58183 Linkoping, Sweden; Univ Washington, Seattle, WA 98195 USA		thorsson@systemsbiology.org; micho@itn.liu.se; asiegel@u.washington.edu; lhood@systemsbiology.org					Arkin A, 1997, SCIENCE, V277, P1275, DOI 10.1126/science.277.5330.1275; Bickel DR, 2005, BIOINFORMATICS, V21, P1121, DOI 10.1093/bioinformatics/bti140; BREIMAN L, 1992, J AM STAT ASSOC, V87, P738, DOI 10.2307/2290212; D'haeseleer P, 1999, PAC S BIOC, V4, P41; de Hoon M., 2003, PACIFIC S BIOCOMPUTI, V8, P17; Draper NR, 1998, APPL REGRESSION ANAL; FARKAS IJ, 2003, PHYSICA A, V381, P601; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Gardner TS, 2003, SCIENCE, V301, P102, DOI 10.1126/science.1081900; George EI, 2000, J AM STAT ASSOC, V95, P1304, DOI 10.2307/2669776; Hansen MH, 2001, J AM STAT ASSOC, V96, P746, DOI 10.1198/016214501753168398; Hastie T., 2001, ELEMENTS STAT LEARNI; Ideker T., 2000, PAC S BIOC, V5, P302; Ideker T, 2000, J COMPUT BIOL, V7, P805, DOI 10.1089/10665270050514945; Ideker T, 2001, SCIENCE, V292, P929, DOI 10.1126/science.292.5518.929; Jong HD, 2002, J COMPUT BIOL, V9, P67; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; Miller A., 2002, SUBSET SELECTION REG; Mitchell M., 1998, INTRO GENETIC ALGORI; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; Pournara I, 2004, BIOINFORMATICS, V20, P2934, DOI 10.1093/bioinformatics/bth337; Rung J, 2002, BIOINFORMATICS, V18, pS202; Schafer J, 2005, BIOINFORMATICS, V21, P754, DOI 10.1093/bioinformatics/bti062; Shao J, 1997, STAT SINICA, V7, P221; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; VONSOMEREN EP, 2000, P 8 INT C INT SYST M, P355; Wahde M, 2001, J COMPUT BIOL, V8, P429, DOI 10.1089/106652701752236223; Weaver D. C., 1999, PAC S BIOCOMPUT, V4, P112; Wuensche A, 1998, PAC S BIOCOMPUT, V3, P89; Yeung MKS, 2002, P NATL ACAD SCI USA, V99, P6163, DOI 10.1073/pnas.092576199; Yoo C., 2002, P PAC S BIOC, V7, P498; Yu J, 2004, BIOINFORMATICS, V20, P3594, DOI 10.1093/bioinformatics/bth448; Zheng WJ, 1997, J BIOL CHEM, V272, P30350, DOI 10.1074/jbc.272.48.30350	33	7	8	BERKELEY ELECTRONIC PRESS	BERKELEY	2809 TELEGRAPH AVENUE, STE 202, BERKELEY, CA 94705 USA	1544-6115			STAT APPL GENET MO B	Stat. Appl. Genet. Mol. Biol.		2005	4								28			24	Biochemistry & Molecular Biology; Statistics & Probability	Biochemistry & Molecular Biology; Mathematics	055VG	WOS:000238478100010		
J	Xiao, YY; Segal, MR				Xiao, YY; Segal, MR			Prediction of genomewide conserved epitope profiles of HIV-1: Classifier choice and peptide representation	STATISTICAL APPLICATIONS IN GENETICS AND MOLECULAR BIOLOGY			English	Article						MHC; peptide binding prediction; learning; ensemble methods	T-CELL EPITOPES; ARTIFICIAL NEURAL-NETWORK; MHC-BINDING PEPTIDES; HLA-DR ALLELES; PROLIFERATIVE RESPONSES; LYMPHOCYTE EPITOPES; INDEPENDENT BINDING; SYNTHETIC PEPTIDES; NATURAL INFECTION; HLA-DR4 MOLECULES	Identification of peptides binding to Major Histocompatibility Complex (MHC) molecules is important for accelerating vaccine development and improving immunotherapy. Accordingly, a wide variety of prediction methods have been applied in this context. In this paper, we introduce (tree-based) ensemble classifiers for such problems and contrast their predictive performance with forefront existing methods for both MHC class I and class II molecules. In addition, we investigate the impact of differing peptide representation schemes on performance. Finally, classifier predictions are used to conduct genomewide scans of a diverse collection of HIV-1 strains, enabling assessment of epitope conservation. We investigated all combinations of six classification methods (classification trees, artificial neural networks, support vector machines, as well as the more recently devised ensemble methods (bagging, random forests, boosting) with four peptide representation schemes (amino acid sequence, select biophysical properties, select quantitative structure-activity relationship (QSAR) descriptors, and the combination of the latter two) in predicting peptide binding to an MHC class I molecule (HLA-A2) and MHC class II molecule (HLA-DR4). Our results show that the ensemble methods are consistently more accurate than the other three alternatives. Furthermore, they are robust with respect to parameter tuning. Among the four representation schemes, the amino acid sequence representation gave consistently (across classifiers) best results. This finding obviates the need for feature selection strategies incurred by use of biophysical and/or QSAR properties. We obtained, and aligned, a diverse set of 32 HIV-1 genomes and pursued genomewide HLA-DR4 epitope profiling by querying with respect to classifier predictions, as obtained under each of the four peptide representation schemes. We validated those epitopes conserved across strains against known T-cell epitopes. Once again, amino acid sequence representation was at least as effective as using properties. Assessment of novel epitope predictions awaits experimental verification.	Univ Calif San Francisco, San Francisco, CA 94143 USA	Xiao, YY (reprint author), Univ Calif San Francisco, San Francisco, CA 94143 USA.	yxiao@itsa.ucsf.edu; mark@biostat.ucsf.edu					Adams SL, 1997, J ACQ IMMUN DEF SYND, V15, P257; Bedford PA, 1997, J ACQ IMMUN DEF SYND, V14, P301; Bhasin M, 2004, BIOINFORMATICS, V20, P421, DOI 10.1093/bioinformatics/btg424; BISHOP C.M., 1995, NEURAL NETWORKS PATT; Blythe MJ, 2002, BIOINFORMATICS, V18, P434, DOI 10.1093/bioinformatics/18.3.434; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brusic V, 1996, NUCLEIC ACIDS RES, V24, P242, DOI 10.1093/nar/24.1.242; Brusic V, 1998, BIOINFORMATICS, V14, P121, DOI 10.1093/bioinformatics/14.2.121; Buhlmann P, 2003, J AM STAT ASSOC, V98, P324, DOI 10.1198/016214503000125; BUUS S, 1987, SCIENCE, V235, P1353, DOI 10.1126/science.2435001; CalvoCalle JM, 1997, J IMMUNOL, V159, P1362; Carmichael A, 1996, J VIROL, V70, P8468; CHICZ RM, 1993, J EXP MED, V178, P27, DOI 10.1084/jem.178.1.27; Christianini N., 2000, SUPPORT VECTOR MACHI; Congia M, 1998, P NATL ACAD SCI USA, V95, P3833, DOI 10.1073/pnas.95.7.3833; de Lalla C, 1999, J IMMUNOL, V163, P1725; Diepolder HM, 1997, J VIROL, V71, P6011; Dong X, 2000, J IMMUNOL, V164, P129; Donnes P, 2002, BMC BIOINFORMATICS, V3, DOI 10.1186/1471-2105-3-25; Doytchinova IA, 2003, BIOINFORMATICS, V19, P2263, DOI 10.1093/bioinformatics/btg312; Efron Bradley, 1993, INTRO BOOTSTRAP; EMMERT DB, 1994, NUCLEIC ACIDS RES, V22, P3445, DOI 10.1093/nar/22.17.3445; Endl J, 1997, J CLIN INVEST, V99, P2405, DOI 10.1172/JCI119423; FALK K, 1991, NATURE, V351, P290, DOI 10.1038/351290a0; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Fugger L, 1996, EUR J IMMUNOL, V26, P928, DOI 10.1002/eji.1830260431; Gahery-Segard H, 2000, J VIROL, V74, P1694, DOI 10.1128/JVI.74.4.1694-1703.2000; Gaston JSH, 1996, J RHEUMATOL, V23, P130; GERETTI AM, 1994, SCAND J IMMUNOL, V39, P355, DOI 10.1111/j.1365-3083.1994.tb03386.x; GOUDEBOUT P, 1997, J ACQ IMMUN DEF SYND, V14, P91; Gross DM, 1998, SCIENCE, V281, P703, DOI 10.1126/science.281.5377.703; HAMMER J, 1995, J EXP MED, V181, P1847, DOI 10.1084/jem.181.5.1847; Hastie T., 2001, ELEMENTS STAT LEARNI; Honeyman MC, 1998, MOL MED, V4, P231; Hsu C., 2010, PRACTICAL GUIDE SUPP; KIDERA A, 1985, J PROTEIN CHEM, V4, P23, DOI 10.1007/BF01025492; Kovats S, 1997, EUR J IMMUNOL, V27, P1014, DOI 10.1002/eji.1830270431; KUBO RT, 1994, J IMMUNOL, V152, P3913; Li K, 1998, CANCER IMMUNOL IMMUN, V47, P32, DOI 10.1007/s002620050501; Lin ZH, 2004, J COMPUT BIOL, V11, P683; Livingston B, 2002, J IMMUNOL, V168, P5499; Mallios RR, 2001, BIOINFORMATICS, V17, P942, DOI 10.1093/bioinformatics/17.10.942; Mamitsuka H, 1998, PROTEINS, V33, P460, DOI 10.1002/(SICI)1097-0134(19981201)33:4<460::AID-PROT2>3.0.CO;2-M; MANCA F, 1995, J ACQ IMMUN DEF SYND, V9, P227; MCNICHOLL JM, 1995, J IMMUNOL, V155, P1951; Milik M, 1998, NAT BIOTECHNOL, V16, P753, DOI 10.1038/nbt0898-753; Muntasesll A, 2002, J IMMUNOL, V169, P5052; Muraro PA, 1997, J CLIN INVEST, V100, P339, DOI 10.1172/JCI119539; Nehete PN, 1998, VIRAL IMMUNOL, V11, P147, DOI 10.1089/vim.1998.11.147; PARKER KC, 1992, J IMMUNOL, V149, P3580; PARKER KC, 1994, J IMMUNOL, V152, P163; Peters B, 2003, BIOINFORMATICS, V19, P1765, DOI 10.1093/bioinformatics/btg24; REECE JC, 1993, J IMMUNOL, V151, P6175; Ripley BD, 1996, PATTERN RECOGNITION; Rosenberg ES, 1997, SCIENCE, V278, P1447, DOI 10.1126/science.278.5342.1447; RUDENSKY AY, 1991, NATURE, V353, P622, DOI 10.1038/353622a0; RUPPERT J, 1993, CELL, V74, P929, DOI 10.1016/0092-8674(93)90472-3; SCHRIER RD, 1989, J IMMUNOL, V142, P1166; Segal MR, 2001, BIOMETRICS, V57, P632, DOI 10.1111/j.0006-341X.2001.00632.x; SEGAL MR, 2004, STAT APPL GENETICS M, V3; Sitz KV, 1999, J INFECT DIS, V179, P817, DOI 10.1086/314685; Sung MH, 2004, J COMPUT BIOL, V11, P125, DOI 10.1089/106652704773416920; Therneau TM, 1997, INTRO RECURSIVE PART; THOMPSON JD, 1994, NUCLEIC ACIDS RES, V22, P4673, DOI 10.1093/nar/22.22.4673; Topalian SL, 1996, J EXP MED, V183, P1965, DOI 10.1084/jem.183.5.1965; van der Burg SH, 1999, J IMMUNOL, V162, P152; WAHREN B, 1989, J ACQ IMMUN DEF SYND, V2, P448; Wilson CC, 2001, J VIROL, V75, P4195, DOI 10.1128/JVI.75.9.4195-4207.2001; Yu K, 2002, MOL MED, V8, P137; Zhao YD, 2003, BIOINFORMATICS, V19, P1978, DOI 10.1093/bioinformatics/btg255	75	5	6	BERKELEY ELECTRONIC PRESS	BERKELEY	2809 TELEGRAPH AVENUE, STE 202, BERKELEY, CA 94705 USA	1544-6115			STAT APPL GENET MO B	Stat. Appl. Genet. Mol. Biol.		2005	4								25			36	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Mathematics	055VG	WOS:000238478100013		
S	Zhou, SHK; Georgescu, B; Zhou, XS; Comaniciu, D			IEEE COMPUTER SOC	Zhou, SHK; Georgescu, B; Zhou, XS; Comaniciu, D			Image based regression using boosting method	TENTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS 1 AND 2, PROCEEDINGS	IEEE International Conference on Computer Vision		English	Proceedings Paper	10th IEEE International Conference on Computer Vision (ICCV 2005)	OCT 17-20, 2005	Beijing, PEOPLES R CHINA	IEEE, IEEE Comp Soc, Microsoft, intel, OMRON, SIEMENS, Mitsubishi Elect, Sarnoff Corp, Point Grey Res				We present a general algorithm of image based regression that is applicable to many vision problems. The proposed regressor that targets a multiple-output setting is learned using boosting method. We formulate a multiple-output regression problem in such a way that over fitting is decreased and an analytic solution is admitted. Because we represent the image via a set of highly redundant Haar-like features that can be evaluated very quickly and select relevant features through boosting to absorb the knowledge of the training data, during testing we require no storage of the training data and evaluate the regression function almost in no time. We also propose an efficient training algorithm that breaks the computational bottleneck in the greedy feature selection process. We validate the efficiency of the proposed regressor using three challenging tasks of age estimation, tumor detection, and endocardial wall localization and achieve the best performance with a dramatic speed, e.g., more than 1000 times faster than conventional data-driven techniques such as support vector regressor in the experiment of endocardial wall localization.	Siemens AG, Corp Res, Integrated Data Syst Dept, Princeton, NJ 08540 USA	Zhou, SHK (reprint author), Siemens AG, Corp Res, Integrated Data Syst Dept, 755 Coll Rd E, Princeton, NJ 08540 USA.	shaohua.zhou@siemens.com; bogdan.georgescu@siemens.com; xiang.zhou@siemens.com; dorin.comaniciu@siemens.com					Agarwal A, 2004, CVPR; COPAS JB, 1983, J R STAT SOC B, V45, P311; Duffy N, 2002, MACH LEARN, V47, P153, DOI 10.1023/A:1013685603443; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; FRIEDMAN J, 2001, ANN STAT, V28; Hastie T., 2001, ELEMENTS STAT LEARNI; Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553; OKADA K, 2004, SCALE SELECTION ANIS; Otto CM, 2000, TXB CLIN ECHOCARDIOG; Schapire RE, 1998, ANN STAT, V26, P1651; Vapnik VN, 1995, NATURE STAT LEARNING; Viola P., 2001, RAPID OBJECT DETECTI; WANG S, 2001, SVM REGRESSION APPL; ZHOU X, 2004, UNIFIED FRAMEWORK UN	15	10	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-5499		0-7695-2334-X	IEEE I CONF COMP VIS			2005							541	548				8	Computer Science, Artificial Intelligence	Computer Science	BDE75	WOS:000233155100070		
S	Ren, XF; Fowlkes, CC; Malik, J			IEEE COMPUTER SOC	Ren, XF; Fowlkes, CC; Malik, J			Scale-invariant contour completion using conditional random fields	TENTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS 1 AND 2, PROCEEDINGS	IEEE International Conference on Computer Vision		English	Proceedings Paper	10th IEEE International Conference on Computer Vision (ICCV 2005)	OCT 17-20, 2005	Beijing, PEOPLES R CHINA	IEEE, IEEE Comp Soc, Microsoft, intel, OMRON, SIEMENS, Mitsubishi Elect, Sarnoff Corp, Point Grey Res			IMAGES	We present a model of curvilinear grouping using piecewise linear representations of contours and a conditional random field to capture continuity and the frequency of different junction types. Potential completions are generated by building a constrained Delaunay triangulation (CDT) over the set of contours found by a local edge detector. Maximum likelihood parameters for the model are learned from human labeled ground truth. Using held out test data, we measure how the model, by incorporating continuity structure, improves boundary detection over the local edge detector We also compare performance with a baseline local classifier that operates on pairs of edgels. Both algorithms consistently dominate the low-level boundary detector at all thresholds. To our knowledge, this is the first time that curvilinear continuity has been shown quantitatively useful for a large variety of natural images. Better boundary detection has immediate application in the problem of object detection and recognition.	Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA	Ren, XF (reprint author), Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA.	xren@cs.berkeley.edu; fowlkes@cs.berkeley.edu; malik@cs.berkeley.edu					August J, 1999, COMPUT VIS IMAGE UND, V76, P146, DOI 10.1006/cviu.1998.0795; Belongie S., 2001, ICCV, VI, P454; BORENSTEIN E, 2002, ECCV, V2, P109; BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; Elder James H, 2002, J Vis, V2, P324, DOI 10.1167/2.4.5; ELDER JH, 1996, ECCV, V1, P399; Geisler WS, 2001, VISION RES, V41, P711, DOI 10.1016/S0042-6989(00)00277-7; Hastie T., 2001, ELEMENTS STAT LEARNI; HE X, 2004, CVPR, V2, P695; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Kumar S., 2003, ICCV, P1150; Lafferty J., 2001, P 18 INT C MACH LEAR; Mahamud S, 2003, IEEE T PATTERN ANAL, V25, P433, DOI 10.1109/TPAMI.2003.1190570; MARTIN D, 2002, ADV NEURAL INFORMATI, P15; MARTIN D, 2003, EUR C VIS PERC, V32; Mori G., 2004, CVPR, V2, pII; Mumford D., 1994, ALGEBRAIC GEOMETRY I, P491; Palmer S. E., 1999, VISION SCI PHOTONS P; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; REN X, 2002, ECCV, V1, P312; SHASHUA A, 1988, ICCV, P321; SHENTAL N, 2003, ICCV, P1243; Shewchuk J.R., 1996, 1 WORKSH APPL COMP G, P124; Tu Z., 2003, ICCV, P18; WEISS Y, 2000, NEURAL COMPUT, P1; Williams L, 1995, INT C COMP VIS, P408; Williams LR, 1999, INT J COMPUT VISION, V34, P81, DOI 10.1023/A:1008187804026; Wu Q., 2003, P DICTA, P957	28	10	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-5499		0-7695-2334-X	IEEE I CONF COMP VIS			2005							1214	1221				8	Computer Science, Artificial Intelligence	Computer Science	BDE75	WOS:000233155100160		
S	Qiu, XP; Wu, LD			IEEE COMPUTER SOC	Qiu, XP; Wu, LD			Face recognition by stepwise nonparametric margin maximum criterion	TENTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS 1 AND 2, PROCEEDINGS	IEEE International Conference on Computer Vision		English	Proceedings Paper	10th IEEE International Conference on Computer Vision (ICCV 2005)	OCT 17-20, 2005	Beijing, PEOPLES R CHINA	IEEE, IEEE Comp Soc, Microsoft, intel, OMRON, SIEMENS, Mitsubishi Elect, Sarnoff Corp, Point Grey Res			DISCRIMINANT-ANALYSIS; LDA; EIGENFACES	Linear Discriminant Analysis (LDA) is a popular feature extraction technique in face recognition. However it often suffers from the small sample size problem when dealing with the high dimensional data. Moreover while LDA is guaranteed to find the best directions when each class has a Gaussian density with a common covariance matrix, it can fail if the class densities are more general. In this paper a new nonparametric linear feature extraction method, stepwise nonparametric margin maximum criterion(SNMMC), is proposed to find the most discriminant directions, which does not assume that the class densities belong to any particular parametric family and does not depend on the nonsingularity of the within-class scatter matrix either On three datasets from ATT and FERET face databases, our experimental results demonstrate that SNMMC outperforms other methods and is robust to variations of pose, illumination and expression.	Fudan Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China	Qiu, XP (reprint author), Fudan Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.	xpqiu@fudan.edu.cn; ldwu@fudan.edu.cn	Qiu, Xipeng/G-4071-2011				Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bressan M, 2003, PATTERN RECOGN LETT, V24, P2743, DOI 10.1016/S0167-8655(03)00117-X; Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9; Fukunaga K, 1990, INTRO STAT PATTERN R; FUKUNAGA K, 1983, IEEE T PATTERN ANAL, V5, P671; Hastie T., 2001, ELEMENTS STAT LEARNI; LI HF, 2003, P NEURAL INFORMATION; LIU K, 1992, PATTERN RECOGN, V25, P731, DOI 10.1016/0031-3203(92)90136-7; Moghaddam B, 2000, PATTERN RECOGN, V33, P1771, DOI 10.1016/S0031-3203(99)00179-X; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Samaria Ferdinando, 1994, P 2 IEEE WORKSH APPL; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Wang X., 2004, P IEEE C COMP VIS PA; Yang H, 2003, PATTERN RECOGN, V36, P563; Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342	16	5	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-5499		0-7695-2334-X	IEEE I CONF COMP VIS			2005							1567	1572				6	Computer Science, Artificial Intelligence	Computer Science	BDE75	WOS:000233155100205		
J	Peters, JF				Peters, JF			Rough ethology: Towards a biologically-inspired study of collective behavior in intelligent systems with approximation spaces	TRANSACTIONS ON ROUGH SETS III	LECTURE NOTES IN COMPUTER SCIENCE		English	Article						approximation space; behavior; ethology; intelligent systems; learning; rough sets; swarm	INFORMATION GRANULES; SETS; GRANULATION	This article introduces an ethological approach to evaluating biologically-inspired collective behavior in intelligent systems. This is made possible by considering ethology (ways to explain agent behavior) in the context of approximation spaces. The aims and methods of ethology in the study of the behavior of biological organisms were introduced by Niko Tinbergen in 1963. The rough set approach introduced by Zdzislaw Pawlak provides a ground for concluding to what degree a particular behavior for an intelligent system is a part of a set of behaviors representing a norm or standard. A rough set approach to ethology in studying the behavior of cooperating agents is introduced. Approximation spaces are used to derive action-based reference rewards for a swarm. Three different approaches to projecting rewards are considered as a part of a study of learning in real-time by a swarm. The contribution of this article is the introduction of an approach to rewarding swarm behavior in the context of an approximation space.	Univ Manitoba, Dept Elect & Comp Engn, Winnipeg, MB R3T 5V6, Canada	Peters, JF (reprint author), Univ Manitoba, Dept Elect & Comp Engn, Winnipeg, MB R3T 5V6, Canada.	jfpeters@ee.umanitoba.ca					ALPIGINI JJ, 2002, LECT NOTES ARTIFICIA; APPLEWHITE A, 2004, IEEE SPECTRUM    NOV, P36; Bonabeau E., 1999, SWARM INTELLIGENCE N; Cheng K, 2001, BEHAV BRAIN SCI, V24, P660; DORIGO M, 2004, WIRED            FEB, P119; Duda R.O., 2001, PATTERN CLASSIFICATI; Fahle M, 2002, PERCEPTUAL LEARNING; GEPPERT L, 2004, IEEE SPECTRUM    FEB; Harnad S.R., 1987, CATEGORICAL PERCEPTI; Hastie T., 2001, ELEMENTS STAT LEARNI; HOLT J, 2001, UML SYSTEMS ENG WATC; Keplicz B. D., 2004, ADV SOFT COMPUTING, P13; Kruuk H, 2003, NIKOS NATURE LIFE N; Lehner P.N., 1996, HDB ETHOLOGICAL METH; Martin P, 1993, MEASURING BEHAV; MARTIN P, 1996, HDB ETHOLOGICAL METH; MONDADA F, 2004, P 8 C INT AUT SYST I, P53; NGUYEN SH, 2004, T ROUGH SETS, V1, P187; *OBJ MAN GROUP, OMG UN MOD LANG UML; Pal S.K., 2004, ROUGH NEURAL COMPUTI; PAWLAK Z, 1987, B EATCS, V33, P85; PAWLAK Z, 1986, B POLISH ACAD SCI TE, V34, P553; PAWLAK Z, 1985, B POLISH ACAD SCI TE, V33, P551; Pawlak Z, 2003, LECT NOTES ARTIF INT, V2639, P1; Pawlak Z., 2004, ROUGH NEURAL COMPUTI, P5; PAWLAK Z, 1994, ROUGH SETS THEORETIC; PAWLAK Z, 2004, T ROUGH SETS, V1, P1; PAWLAK Z, 2001, LECT NOTES ARTIF INT, P30; Pawlak Z., 1994, ADV DEMPSTER SHAFER, P251; Pawlak Z., 1985, LECT NOTES COMPUTER, V208, P186; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; PAWLAK Z, 2002, LECT NOTES ARTIF INT, P1; Peters J. F., 2004, ENG APPL ARTIF INTEL, V17, P1; Peters JE, 2002, FUND INFORM, V51, P157; PETERS JF, 2003, P IEEE PAC RIM C COM, P808; Peters JF, 2003, LECT NOTES ARTIF INT, V2715, P370; PETERS JF, 2002, LECT NOTES ARTIF INT, V2475, P595; PETERS JF, 2004, T ROUGH SETS, V1, P338; Peters JF, 2004, LECT NOTES COMPUT SC, V3213, P764; Peters JF, 2003, STUD FUZZ SOFT COMP, V116, P141; Peters JF, 2003, LECT NOTES ARTIF INT, V2871, P262; Polkowski L., 2002, ROUGH SETS MATH FDN; Polkowski L., 1998, STUDIES FUZZINESS SO, V19; Polkowski L, 1996, INT J APPROX REASON, V15, P333, DOI 10.1016/S0888-613X(96)00072-2; Polkowski L, 2001, COMPUT INTELL, V17, P472, DOI 10.1111/0824-7935.00159; Polkowski L., 1998, STUDIES FUZZINESS SO, V18; Quinlan J. R., 1988, C4 5 PROGRAMS MACHIN; Skoworon A., 1995, SOFT COMPUTING SIMUL, P18; Skowron A, 2004, LECT NOTES ARTIF INT, V3066, P300; Skowron A, 2004, LECT NOTES ARTIF INT, V3066, P116; Skowron A, 2003, FUND INFORM, V54, P263; SKOWRON A, 2004, ROUGH NEURAL COMPUTI, P43; SKOWRON A, 2004, ROUGH NEURAL COMPUTI, P599; Skowron A, 1999, LECT NOTES ARTIF INT, V1711, P357; Skowron A., 1994, P 3 INT WORKSH ROUGH, P156; SKOWRON A, 1998, P 7 INT C INF PROC M, P1354; Skowron A, 2001, INT J INTELL SYST, V16, P57, DOI 10.1002/1098-111X(200101)16:1<57::AID-INT6>3.0.CO;2-Y; Skowron A., 2001, B INT ROUGH SET SOC, V5, P9; Skowron A, 1999, LECT NOTES ARTIF INT, V1704, P542; Skowron A, 2003, LECT NOTES ARTIF INT, V2639, P25; SKOWRON A, 2004, P WORKSH CONC SPEC P, V1; SKOWRON A, 2004, P WORKSH CONC SPEC P, V1, P358; Skowron A., 1996, Fundamenta Informaticae, V27; SON NH, 2001, B INT ROUGH SET SOC, V5, P185; STEPANIUK J, 1998, STUDIES FUZZINESS SO, V19, P109; Stone P., 2000, LAYERED LEARNING MUL; Sutton R. S., 1998, REINFORCEMENT LEARNI; Tinbergen N., 1963, Zeitschrift fuer Tierpsychologie, V20, P410; WANG G, 2003, P 9 INT C ROUGH SETS; Watanabe S., 1985, PATTERN RECOGNITION; ZIARKO W, 2000, LECT NOTES ARTIFICIA	71	26	26	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743			LECT NOTES COMPUT SC			2005	3400						153	174				22	Computer Science, Theory & Methods	Computer Science	BDE97	WOS:000233166300007		
J	Skowron, A; Swiniarski, R; Synak, P				Skowron, A; Swiniarski, R; Synak, P			Approximation spaces and information granulation	TRANSACTIONS ON ROUGH SETS III	LECTURE NOTES IN COMPUTER SCIENCE		English	Article								In this paper, we discuss approximation spaces in a granular computing framework. Such approximation spaces generalise the approaches to concept approximation existing in rough set theory. Approximation spaces are constructed as higher level information granules and are obtained as the result of complex modelling. We present illustrative examples of modelling approximation spaces that include approximation spaces for function approximation, inducing concept approximation, and some other information granule approximations. In modelling of such approximation spaces we use an important assumption that not only objects but also more complex information granules involved in approximations are perceived using only partial information about them.	Univ Warsaw, Inst Math, PL-02097 Warsaw, Poland; Polish Acad Sci, Inst Comp Sci, PL-01237 Warsaw, Poland; San Diego State Univ, Dept Math & Computat Sci, San Diego, CA 92182 USA; Polish Japanese Inst Informat Technol, PL-02008 Warsaw, Poland	Skowron, A (reprint author), Univ Warsaw, Inst Math, Banacha 2, PL-02097 Warsaw, Poland.	skowron@mimuw.edu.pl; rswiniar@sciences.sdsu.edu; synak@pjwstk.edu.pl					Duda R.O., 2001, PATTERN CLASSIFICATI; Hastie T., 2001, ELEMENTS STAT LEARNI; Kloesgen Willi, 2002, HDB KNOWLEDGE DISCOV; Lin YZ, 1998, ACTA MATH SCI, V18, P107; Pal S.K., 2003, ROUGH NEURAL COMPUTI; Pawlak Z, 1991, SYSTEM THEORY KNOWLE, V9; Peters JF, 2003, LECT NOTES ARTIF INT, V2715, P370; Polkowski L, 1996, INT J APPROX REASON, V15, P333, DOI 10.1016/S0888-613X(96)00072-2; Polkowski L., 1999, COMPUTING WORDS INFO, P201; Skowron A., 2003, ROUGH NEURAL COMPUTI, P43; Skowron A., 2001, B INT ROUGH SET SOC, V5, P9; Skowron A., 1996, Fundamenta Informaticae, V27; Slowinski R, 2002, LECT NOTES ARTIF INT, V2475, P44; Zadeh LA, 2001, AI MAG, V22, P73; ZIARKO W, 1993, J COMPUT SYST SCI, V46, P39, DOI 10.1016/0022-0000(93)90048-2	15	39	39	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743			LECT NOTES COMPUT SC			2005	3400						175	189				15	Computer Science, Theory & Methods	Computer Science	BDE97	WOS:000233166300008		
J	Moshkov, MJ				Moshkov, MJ			Time complexity of decision trees	TRANSACTIONS ON ROUGH SETS III	LECTURE NOTES IN COMPUTER SCIENCE		English	Article						decision tree; rough set theory; test theory; time complexity	INFINITE INFORMATION-SYSTEMS; ROUGH SETS; KNAPSACK-PROBLEM; CLASSIFICATION; MINIMIZATION; ALGORITHMS; SELECTION; NETWORKS	The research monograph is devoted to the study of bounds on time complexity in the worst case of decision trees and algorithms for decision tree construction. The monograph is organized in four parts. In the first part (Sects. 1 and 2) results of the monograph are discussed in context of rough set theory and decision tree theory. In the second part (Sect. 3) some tools for decision tree investigation based on the notion of decision table are described. In the third part (Sects. 4-6) general results about time complexity of decision trees over arbitrary (finite and infinite) information systems are considered. The fourth part (Sects. 7-11) contains a collection of mathematical results on decision trees in areas of rough set theory and decision tree theory applications such as discrete optimization, analysis of acyclic programs, pattern recognition, fault diagnosis and probabilistic reasoning.	Nizhny Novgorod State Univ, Fac Comp Math & Cybernet, Nizhnii Novgorod 603950, Russia; Univ Silesia, Inst Comp Sci, PL-41200 Sosnowiec, Poland	Moshkov, MJ (reprint author), Nizhny Novgorod State Univ, Fac Comp Math & Cybernet, 23,Gagarina Ave, Nizhnii Novgorod 603950, Russia.	moshkov@unn.ac.ru					Ahlswede R., 1979, SUCHPROBLEME; ALEXEYEV VE, 1987, COMBINATORIAL ALGEBR, P5; Angluin D., 1988, Machine Learning, V2, DOI 10.1007/BF00116828; ARMSTRON.DB, 1966, IEEE TRANS ELECTRON, VEC15, P66, DOI 10.1109/PGEC.1966.264375; BAZAN J, 2000, STUDIES FUZZINESS SO, V56, P48; BENOR M, 2003, P 15 ACM ANN S THEOR, P80; BLUMER A, 1989, J ACM, V36, P929, DOI 10.1145/76359.76371; BONDARENKO VA, 1993, RUSSIAN ACAD SCI DOK, V328, P22; Bondarenko V. A., 1996, Fundamenta Informaticae, V25; BONDARENKO VA, 1983, AUTOMATION TELEMECHA, V9, P45; Breiman L., 1984, CLASSIFICATION REGRE; BRODLEY CE, 1995, MACH LEARN, V19, P45, DOI 10.1007/BF00994660; Buntine W., 1992, Statistics and Computing, V2, DOI 10.1007/BF01889584; Chegis I.A., 1958, T MATEM I AN SSSR, V51, P270; Chernikov S. N., 1968, LINEAR INEQUALITIES; CHIKALOV I, 1998, LNCS, V1424, P506; Chikalov I., 1999, Fundamenta Informaticae, V39; CHIKALOV IV, 1998, P 7 INT C INF PROC M, V2, P1190; CHIKALOV IV, 2000, P 8 INT C INF PROC M, V1, P376; CHIKALOV IV, 2000, P 2 INT C ROUGH SETS, P107; DIETTERICH TG, 1990, READINGS MACHINE LEA; Dobkin D., 1976, SIAM Journal on Computing, V5, DOI 10.1137/0205015; DOBKIN D, 1978, J COMPUT SYST SCI, V16, P413, DOI 10.1016/0022-0000(78)90026-0; DOBKIN DP, 1979, J COMPUT SYST SCI, V18, P86, DOI 10.1016/0022-0000(79)90054-0; Duda R.O., 2000, PATTERN RECOGNITION; DUDINA JV, 1998, MATH SIMULATION OPTI, V2, P214; ELDRED RD, 1959, J ACM, V6, P33, DOI 10.1145/320954.320957; Feige U., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/237814.237977; Garey M.R., 1979, COMPUTERS INTRACTABI; Goldman R.S., 1969, DISCRETE ANAL, V14, P3; Grigoriev D., 1995, Proceedings. 36th Annual Symposium on Foundations of Computer Science (Cat. No.95CB35834), DOI 10.1109/SFCS.1995.492481; Hastie T., 2001, ELEMENTS STAT LEARNI; Hegedus T., 1995, Proceedings of the Eighth Annual Conference on Computational Learning Theory, DOI 10.1145/225298.225311; HEIDE FMA, 1988, J ACM, V35, P740; HEIDE FMAD, 1984, J ACM, V31, P668; Hellerstein L, 1996, J ACM, V43, P840, DOI 10.1145/234752.234755; HUMBY E, 1973, PROGRAMS DECISION TA; IMAM IF, 1993, J INTELL INF SYST, V2, P279, DOI 10.1007/BF00962072; INIGUCHI M, 2003, STUDIES FUZZINESS SO, V125; JOHNSON DS, 1974, J COMPUT SYST SCI, V9, P256; Jordan M., 1999, LEARNING GRAPHICAL M; KARAVAI MF, 1973, AUTOMATION TELEMECHN, V1, P173; KNYAZEV AN, 1999, P 12 C PROBL THEOR 1, P96; KNYAZEV AN, 2000, P 8 INT C INF PROC M, V1, P1945; KNYAZEV AN, 1998, LECT NOTES ARTIF INT, V1424, P111; Komorowski J., 1999, ROUGH FUZZY HYBRIDIZ, P3; KOSPANOV ES, 1966, DISCRETE ANAL, V8, P43; Kurosh A., 1975, HIGHER ALGEBRA; LASKOWSKI MC, 1992, J LOND MATH SOC, V45, P377; Liu H., 1998, FEATURE EXTRACTION C; Liu H., 1998, FEATURE SELECTION KN; Loh WY, 1997, STAT SINICA, V7, P815; LUND C, 1994, J ACM, V41, P960, DOI 10.1145/185675.306789; MADATYAN CA, 1970, PROBLEMS CYBERNETICS, V23, P103; MARKOV AA, 1992, DISCRETE MATH, V4, P29; MARKOV AA, 1982, INTRO CODING THEORY; MATIYASEVICH JV, 1970, ACAD SCI DOKLADY, V191, P279; Michalski RS, 1973, P 3 INT JOINT C ART, P162; Moore E. F., 1956, AUTOMATA STUDIES, P129; MORAVEK J, 1969, APPL MAT, V14, P442; Moravek J., 1972, Kybernetika, V8; MORZHAKOV NM, 1988, COMBINATORIAL ALGEBR, P22; MORZHAKOV NM, 1986, COMBINATORIAL ALGEBR, P84; MORZHAKOV NM, 1985, COMBINATORIAL ALGEBR, P83; MORZHAKOV NM, 1996, MATH PROBLEMS CYBERN, V6, P215; MOSHINSKII AI, 1997, TEOR OSN KHIM TEKHNO, V31, P157; MOSHKOV M, 2001, P INT SCH SEM DISCR, P6; Moshkov M, 1997, LECT NOTES ARTIF INT, V1263, P335; Moshkov M., 2000, Fundamenta Informaticae, V41; Moshkov M. Yu., 1982, Soviet Physics - Doklady, V27; Moshkov M, 2002, LECT NOTES ARTIF INT, V2475, P156; Moshkov M., 2000, MATH PROBLEMS CYBERN, V9, P79; MOSHKOV M, 2001, ELEMENTS MATH THEORY; MOSHKOV MJ, 1995, ACTUAL PROBLEMS MODE, V1, P109; Moshkov M., 1996, Fundamenta Informaticae, V27; MOSHKOV MJ, 1996, P 4 INT WORKSH ROUGH, P142; MOSHKOV MJ, 1985, COMBINATORIAL ALGEBR, P98; MOSHKOV MJ, 1999, P 9 INT WORKSH DES C, P52; MOSHKOV MJ, 2001, P 7 INT WORKSH DIS 1, P21; MOSHKOV MJ, 1996, ACTUAL PROBLEMS MODE, V2, P110; Moshkov M., 1996, Foundations of Computing and Decision Sciences, V21; MOSHKOV MJ, 1979, COMBINATORIAL ALGEBR, P70; MOSHKOV MJ, 1998, P INT SIB C OP RES N, P28; MOSHKOV MJ, 1997, P 3 JOINT C INF SYST, P353; MOSHKOV MJ, 1996, INTELLECTUAL SYSTEMS, V1, P199; MOSHKOV MJ, 1997, ACTUAL PROBLEMS MODE, V3, P117; MOSHKOV MJ, 2000, P 2 INT C ROUGH SETS, P167; MOSHKOV MJ, 1997, P 5 EUR C INT TECHN, P226; MOSHKOV MJ, 2003, ELECT NOTES THEORETI, V82; Moshkov MJ, 2003, FUND INFORM, V55, P51; MOSHKOV MJ, 1998, LECT NOTES ARTIF INT, V1424, P499; MOSHKOV MJ, 2001, COLLECTION LECT YOUG, V2, P35; MOSHKOV MJ, 1998, LECT NOTES ARTIF INT, V1424, P513; MOSHKOV MJ, 1981, COMBINATORIAL ALGEBR, P97; MOSHKOV MJ, 2001, P 11 INT WORKSH DE 1, P109; MOSHKOV MJ, 1998, MATH PROBLEMS CYBERN, V7, P162; MOSHKOV MJ, 2000, P 8 INT C INF PROC M, V3, P1932; MOSHKOV MJ, 1996, P 4 INT WORKSH ROUGH, P325; MOSHKOV MJ, 1996, DISCRETE MATH, V8, P98; Moshkov M., 1995, Fundamenta Informaticae, V22; MOSHKOV MJ, 2000, DISCRET ANAL OPERATI, V7, P6; MOSHKOV MJ, 1999, ROUGH FUZZY HYBRIDIZ, P163; MOSHKOV MJ, 1996, P 11 INT C PROBL THE, P146; MOSHKOV MJ, 1997, P 5 EUR C INT TECHN, P1643; Moshkov MJ, 2003, FUND INFORM, V54, P345; MOSHKOV MJ, 1996, P 4 EUR C INT TECHN, V1, P220; Moshkov M., 1997, Proceedings of the 3rd International Conference Developments in Language Theory; MOSHKOV MJ, 1996, P 4 INT WORKSH ROUGH, P139; Moshkov MJ, 2003, LECT NOTES ARTIF INT, V2639, P611; MOSHKOV MJ, 1982, THESIS GORKY U; MOSHKOV MJ, 1996, P C INF PROC MAN UNC, P885; MOSHKOV MJ, 1996, DOKL MATH, V54, P662; MOSHKOV MJ, 2000, P 4 INT C DISCR MOD, P83; MOSHKOV MJ, 2002, P 13 INT C PROBL T 2, P128; Moshkov MJ, 2002, FUND INFORM, V50, P57; Moshkov M., 2000, Fundamenta Informaticae, V41; Moshkov M.J., 1994, DECISION TREES THEOR; MOSHKOV MJ, 1997, P 5 EUR C INT TECHN, P231; MOSHKOV MJ, 1998, MATH SIMULATION OPTI, V2, P204; MOSHKOV MJ, 1988, BANACH CTR PUBLICATI, V21, P523; MOSHKOV MJ, 1989, P WORKSH DISCR MATH, P156; MOSHKOV MJ, 2002, P 6 INT C SOFT COMP, P53; MOSHKOV MJ, 1990, P 9 ALL UN C PROBL T, P81; MOSHKOV MJ, 1988, P 8 ALL UN C PROBL T, P50; MOSHKOV MJ, 1989, COMBINATORIAL ALGEBR, P78; MOSHKOV MJ, 1995, P WORLD C FUND AI PA, P275; MOSHKOV MJ, 2001, P 12 INT WORKSH DE 2, P157; MOSHKOV MJ, 1995, P 2 INT C DEV LANG T; Moshkov M., 1996, Fundamenta Informaticae, V25; Moshkov M., 2000, Fundamenta Informaticae, V41; MOSHKOV MJ, 1994, T IM SO RAN, V27, P108; MOSHKOV MJ, 1999, P 12 INT C PROBL T 2, P164; Moshkov M., 1997, Fundamenta Informaticae, V31; Moshkov M., 1994, Fundamenta Informaticae, V21; MOSHKOV MJ, 2000, P 8 INT C INF PROC M, V1, P372; MOSHKOV MJ, 1998, RUSSIAN ACAD SCI DOK, V358, P26; MOSHKOV MJ, 2002, P 13 INT WORKSH DE 2, P165; MOSHKOV MJ, 1983, PROBLEMY KYBERNETIKI, V40, P131; MOSHKOV MJ, 1999, P 12 INT C PROBL T 2, P165; MOSHKOV MJ, 1998, STUDIES FUZZZINESS S, V18, P160; Muller W., 1994, Annals of Operations Research, V52, DOI 10.1007/BF02032305; Murthy S.K., 1994, J ARTIFICIAL INTELLI, V2, P1; NGUYEN H, 1998, STUDIES FUZZINNESS S, V18, P451; Nguyen H. S., 1998, Fundamenta Informaticae, V34; NGUYEN HS, 1998, FUNDAMENTA INFORMATI, V34, P129; Nguyen HS, 1999, LECT NOTES ARTIF INT, V1711, P137; Nguyen H.S., 2001, FUNDAMENTA INFORM, V48, P61; NIGMATULLIN RG, 1969, MEMOIRS S PROBLEMS P, V5, P116; OKOLNISHNIKOVA EA, 1991, METODY DISKRET ANAL, V51, P61; Pal S.K., 2003, ROUGH NEURAL COMPUTI; PARCHOMENKO PP, 1981, FUNDAMENTAL TECHNICA; PARCHOMENKO PP, 1970, AUTOMATION TELEMECHA, V4, P140; PAWLAK Z, 1987, B EATCS, V33, P85; PAWLAK Z, 1986, B POLISH ACAD SCI TE, V34, P553; PAWLAK Z, 1985, B POLISH ACAD SCI TE, V33, P551; PAWLAK Z, 1985, FUZZY SET SYST, V17, P99; Pawlak Z., 1987, B POLISH ACAD SCI TE, V35, P253; PAWLAK Z, 1983, REPORT COMPUTING CTR, V506; Pawlak Z., 1991, ROUGH SETS THEORETIC; PAWLAK Z, 1981, INFORM SYSTEMS THEOR; Pawlak Z., 1985, LECT NOTES COMPUTER, V208, P186; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Pearl J., 1988, PROBABILISTIC INFERE; Peters JE, 2002, FUND INFORM, V51, P157; Peters JF, 2003, LECT NOTES ARTIF INT, V2715, P370; PICARD CF, 1965, THEORIE QUESTIONNAIR; PICARD CF, 1972, GRAPHES QUESTIONNAIR, V1; Polkowski L., 2000, STUDIES FUZZINESS SO, V56; Polkowski L., 2002, ROUGH SETS MATH FDN; Pollack S., 1971, DECISION TABLES THEO; Post E. L, 1941, ANN MATH STUDIES, Vno. 5; Post EL, 1921, AM J MATH, V43, P163, DOI 10.2307/2370324; Preparata F P, 1985, COMPUTATIONAL GEOMET; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan JR, 1987, P 10 INT JOINT C ART, P304; Quinlan J.R., 1979, EXPERT SYSTEMS MICRO; REDKIN NP, 1992, RELIABILITY DIAGNOSI; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; ROTH JP, 1966, J RES DEV, P278; SAPOZHENKO AA, 1969, P 1 ALL UN C PROBL T, P103; Sauer N., 1972, Journal of Combinatorial Theory, Series A, V13, DOI 10.1016/0097-3165(72)90019-2; SHELAH S, 1972, PAC J MATH, V41, P241; SHEVTCHENKO VI, 1989, COMBINATORIAL ALGEBR, P129; SHEVTCHENKO VI, 1995, 3 INT WORKSH ROUGH S, P200; SHEVTCHENKO VI, 1990, COMBINATORIAL ALGEBR, P125; SHEVTCHENKO VI, 2001, P 11 INT WORKSH DE 2, P228; SHEVTCHENKO VI, 1996, P 4 INT WORKSH ROUGH, P328; SHEVTCHENKO VI, 1996, INTELLECTUAL SYSTEMS, V1, P247; SHEVTCHENKO VI, 1988, COMBINATORIAL ALGEBR, P86; SHEVTCHENKO VI, 1994, SIBERIAN J OPERATION, V1, P63; SHEVTCHENKO VI, 1998, LECT NOTES ARTIF INT, V1424, P517; SKOWRON A, 1997, ROUGH SETS DATA MINI, P259; Skowron A., 1992, HDB APPL ADV ROUGH S, P331; Skowron A., 2000, P 16 WORLD COMP C IF, P1; Skowron A., 2003, PATTERN RECOGN, V24, P829; SKOWRON A, 2003, ROUGH NEURO COMPUTIN, P599; Slezak D, 2003, STUD FUZZ SOFT COMP, V125, P109; SLEZAK D, 2002, THESIS WARSAW U; SLOWINSKI R, 1999, HDB APPL ADV ROUGH S; SOLOVIEV NA, 1968, DISCRETE ANAL, V12, P91; SOLOVIEV NA, 1978, TESTS THEORY CONSTRU; STEELE JM, 1982, J ALGORITHM, V3, P1; Swiniarski RW, 2003, PATTERN RECOGN LETT, V24, P833, DOI 10.1016/S0167-8655(02)00196-4; TARASOVA VP, 1988, OPPONENT STRATEGY ME; TARSKI A, 1949, B AM MATH SOC, V55, P63; Ufnarovski V.A., 1982, MAT ZAMETKI, V31, P465; UGOLNIKOV AB, 1987, MATH NOTES, V42, P603; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; Vasilevskii M.P., 1973, KIBERNETIKA, V4, P98; VASILEVSKY MP, 1974, CYBERNETICS, V2, P19; Wegener I., 1987, COMPLEXITY BOOLEAN F; Yablonskii S. V., 1966, FUNCTIONS ALGEBRA LO; YABLONSKII SV, 1975, TESTS ENCY KYBERNETI, P431; YABLONSKII SV, 1988, MATH PROBLEMS CYBERN, V1, P5; Yablonskii S.V., 1955, USP MAT NAUK, V10, P182; YAO A, 1992, P IEEE S FDN COMP SC, P268; Yao A. C. C., 1994, Proceedings of the Twenty-Sixth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/195058.195414; ZHURAVLEV JI, 1964, DISCRETE ANAL, V2, P23	219	9	9	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743			LECT NOTES COMPUT SC			2005	3400						244	459				216	Computer Science, Theory & Methods	Computer Science	BDE97	WOS:000233166300012		
J	Pawlak, Z				Pawlak, Z			A treatise on rough sets	TRANSACTIONS ON ROUGH SETS IV	LECTURE NOTES IN COMPUTER SCIENCE		English	Article						sets; fuzzy sets; rough sets; antinomies; vagueness	INFORMATION GRANULATION	This article presents some general remarks on rough sets and their place in general picture of research on vagueness and uncertainty - concepts of utmost interest, for many years, for philosophers, mathematicians, logicians and recently also for computer scientists and engineers particularly those working in such areas as AI, computational intelligence, intelligent systems, cognitive science, data mining and machine learning. Thus this article is intended to present some philosophical observations rather than to consider technical details or applications of rough set theory. Therefore we also refrain from presentation of many interesting applications and some generalizations of the theory.	Polish Acad Sci, Inst Theoret & Appl Informat, PL-44100 Gliwice, Poland; Warsaw Sch Informat Technol, PL-01447 Warsaw, Poland	Pawlak, Z (reprint author), Polish Acad Sci, Inst Theoret & Appl Informat, Ul Baltycka 5, PL-44100 Gliwice, Poland.	zpw@ii.pw.edu.p1					APOSTOLI P, 1999, TECHNICAL REPORTS PH, V96; Banerjee M., 1994, Rough Sets, Fuzzy Sets and Knowledge Discovery. Proceedings of the International Workshop on Rough Sets and Knowledge Discovery (RSKD'93); Banerjee M, 2004, LECT NOTES ARTIF INT, V3066, P95; BAZAN JG, 2005, IN PRESS LNCS; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; CANTOR G, 1883, GRUNDLAGEN EINER ALL; Casati R., 1999, PARTS PLACES STRUCTU; CHAKRABORTY MK, 1993, B POLISH ACAD SCI MA, V41, P299; DOHERTY P, 2005, IN PRESS KNOWLEDGE E; Dubois D., 1991, ROUGH SETS THEORETIC, pix; FREGE G, 1893, GRUNDLAGEN ARITHMETI, V2; Friedman J., 2001, ELEMENTS STAT LEARNI; GABBAY DM, 1994, HDB LOGIC ARETIFICIA, V3; Greco S, 2001, EUR J OPER RES, V129, P1, DOI 10.1016/S0377-2217(00)00167-3; GRZYMALABUSSE JW, 1990, MANAGING UNCERTAINTY; Keefe R., 2000, THEORIES VAGUENESS; Keefe R., 1997, VAGUENESS READER; Lesniewski S., 1929, FUND MATH, Vxiv, P1; Lukasiewicz J., 1970, J LUKASIEWICZ SELECT; MARCUS S, 1998, LECT NOTES ARTIF INT, V1424, P19; Nguyen SH, 2004, LECT NOTES COMPUT SC, V3100, P187; ORLOWSKA E, 1987, B POLISH ACAD SCI MA, V35, P643; ORLOWSKA E, 1984, FDN LOGIC LINGUISTIC, P465; Pal S.K., 1999, ROUGH FUZZY HYBRIDIZ; Pal S.K., 2004, ROUGH NEURAL COMPUTI; Pal S.K., 2004, PATTERN RECOGNITION; Pawlak Z, 1991, SYSTEM THEORY KNOWLE, V9; Pawlak Z., 1987, B POLISH ACAD SCI TE, V35, P253; Pawlak Z., 1994, ADV DEMPSTER SHAFER, P251; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Peters JF, 2003, LECT NOTES ARTIF INT, V2715, P370; Polkowski L., 2002, ROUGH SETS MATH FDN; Polkowski L, 1996, INT J APPROX REASON, V15, P333, DOI 10.1016/S0888-613X(96)00072-2; Polkowski L, 2001, COMPUT INTELL, V17, P472, DOI 10.1111/0824-7935.00159; Read Stephen, 1995, THINKING LOGIC INTRO; RUSSELL B, 1940, INQUIRY MEANING TRUG; Russell B., 1903, PRINCIPLES MATH; Skowron A, 2005, FUND INFORM, V64, P417; Skowron A, 2004, INTELLIGENT TECHNOLOGIES FOR INFORMATION ANALYSIS, P433; Skowron A., 2000, 16th World Computer Congress 2000. Proceedings of Conference on Intelligent Information Processing; Skowron A., 1996, Fundamenta Informaticae, V27; Skowron A, 2005, LECT NOTES COMPUT SC, V3400, P175; SKOWRON A, 2003, LECT NOTES ARTIF INT, V2639, P55; Slowinski R., 1997, ADV MACHINE INTELLIG, VIV, P17; SWIFT J, 1726, GULLIVERS TRAVELS SE; Vapnik V., 1998, STAT LEARNING THEORY; VITORIA A, 2005, IN PRESS J SUBLINE L, pR4; Vopenka P., 1979, MATH ALTERNATIVE SET; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; ZIARKO W, 1993, J COMPUT SYST SCI, V46, P39, DOI 10.1016/0022-0000(93)90048-2	50	10	10	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743			LECT NOTES COMPUT SC			2005	3700						1	17				17	Computer Science, Theory & Methods	Computer Science	BDN26	WOS:000234424800001		
S	Wojna, A		Peters, JF; Skowron, A		Wojna, A			Analogy-based reasoning in classifier construction	TRANSACTIONS ON ROUGH SETS IV	Lecture Notes in Computer Science		English	Article						analogy-based reasoning; case-based reasoning; k nearest neighbors; similarity measure; distance based indexing; hybrid decision system; local metric induction	NEAREST-NEIGHBOR CLASSIFICATION; COMBINING RULE INDUCTION; LEARNING ALGORITHMS; SCIENCE; SYSTEM; RIONA; TREES	Analogy-based reasoning methods in machine learning make it possible to reason about properties of objects on the basis of similarities between objects. A specific similarity based method is the k nearest neighbors (k-nn) classification algorithm. In the k-nn algorithm, a decision about a new object x is inferred on the basis of a fixed number k of the objects most similar to x in a given set of examples. The primary contribution of the dissertation is the introduction of two new classification models based on the k-nn algorithm. The first model is a hybrid combination of the k-nn algorithm with rule induction. The proposed combination uses minimal consistent rules defined by local reducts of a set of examples. To make this combination possible the model of minimal consistent rules is generalized to a metric-dependent form. An effective polynomial algorithm implementing the classification model based on minimal consistent rules has been proposed by Bazan. We modify this algorithm in such a way that after addition of the modified algorithm to the k-nn algorithm the increase of the computation time is inconsiderable. For some tested classification problems the combined model was significantly more accurate than the classical k-nn classification algorithm. For many real-life problems it is impossible to induce relevant global mathematical models from available sets of examples. The second model proposed in the dissertation is a method for dealing with such sets based on locally induced metrics. This method adapts the notion of similarity to the properties of a given test object. It makes it possible to select the correct decision in specific fragments of the space of objects. The method with local metrics improved significantly the classification accuracy of methods with global models in the hardest tested problems. The important issues of quality and efficiency of the k-nn based methods are a similarity measure and the performance time in searching for the most similar objects in a given set of examples, respectively. In this dissertation both issues are studied in detail and some significant improvements are proposed for the similarity measures and for the search methods found in the literature.	Warsaw Univ, Inst Informat, PL-02097 Warsaw, Poland	Wojna, A (reprint author), Warsaw Univ, Inst Informat, Banacha 2, PL-02097 Warsaw, Poland.	wojna@mimuw.edu.pl					Aggarwal C.C., 2001, P 8 INT C DAT THEOR, P420; AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; Aha DW, 1998, KNOWL-BASED SYST, V11, P261, DOI 10.1016/S0950-7051(98)00066-5; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Ajdukiewicz K., 1974, LOGIKA PRAGMATYCZNA; Bazan Jan G., 2001, LECT NOTES ARTIF INT, V2005, P106; BAZAN JG, 1998, LNCS, V1424, P521; Bazan JG, 2004, LECT NOTES ARTIF INT, V3066, P592; BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93597.98741; Bellman Richard, 1957, DYNAMIC PROGRAMMING; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28; Beyer K., 1999, P 7 INT C DAT THEOR, P217; Biberman Y., 1994, P 9 EUR C MACH LEARN, P49; BISHOP CM, 1996, NEURAL NETWORKSH PAT; Blake C.L., 1998, UCI REPOSITORY MACHI; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Brin S., 1995, P 21 INT C VER LARG, P574; CHAVEZ E, TRDCC993 U CHILE; Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Cosset W.S., 1908, BIOMETRIKA, V6, P1, DOI DOI 10.1093/BIOMET/6.1.1; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOMENICONI C, 2002, P 2 SIAM INT C DAT M; Domingos P, 1996, MACH LEARN, V24, P141; Duda R. O., 1973, PATTERN CLASSIFICATI; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; FIKES RE, 1971, ARTIF INTELL, V2, P189, DOI 10.1016/0004-3702(71)90010-5; Finkel R. A., 1974, Acta Informatica, V4, DOI 10.1007/BF00288933; FISHER RA, 1925, METRON, V5, P3; Fix E., 1951, 4 USAF SCH AV MED RA; Friedman J., 2001, ELEMENTS STAT LEARNI; FRIEDMAN J, 1997, 113 STANF U DEP STAT; Friedman JH, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P717; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; Gaede V, 1998, ACM COMPUT SURV, V30, P170, DOI 10.1145/280277.280279; Golding AR, 1996, ARTIF INTELL, V87, P215, DOI 10.1016/0004-3702(95)00120-4; Gora G, 2002, FUND INFORM, V51, P369; Gora G, 2002, LECT NOTES ARTIF INT, V2475, P405; Gora G, 2002, LECT NOTES ARTIF INT, V2430, P111; Grzymala-Busse J.W, 1992, HDB APPL ADV ROUGH S, P3; Guttman A, 1984, P ACM SIGMOD INT C M, P47; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Jensen F.V., 1996, INTRO BAYESIAN NETWO; KALANTARI I, 1983, IEEE T SOFTWARE ENG, V9, P631, DOI 10.1109/TSE.1983.235263; Katayama N., 1997, P ACM SIGMOD INT C M, P369, DOI 10.1145/253260.253347; Kira K., 1992, P 9 INT C MACH LEARN; Kleinberg J, 2004, J ACM, V51, P263, DOI 10.1145/972639.972644; Klosgen W., 2002, HDB DATA MINING KNOW; Kononenko I., 1994, LECT NOTES ARTIF INT, V784, P171; Leake D., 1996, CASE BASED REASONING; LI J, 2001, P 5 PAC AS C KNOWL D, P455; LI J, 2003, IN PRESS MACHINE LEA; Lin K.-I., 1994, VLDB J, V3, P517, DOI 10.1007/BF01231606; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; Luce D., 1957, GAMES DECISIONS; MACLEOD JES, 1987, IEEE T SYST MAN CYB, V17, P689, DOI 10.1109/TSMC.1987.289362; Michalski R. S., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; MICHALSKI RS, 1983, ARTIF INTELL, V20, P111, DOI 10.1016/0004-3702(83)90016-4; Mitchell T., 1997, MACHINE LEARNING; NIEVERGELT J, 1984, ACM T DATABASE SYST, V9, P38, DOI 10.1145/348.318586; Pawlak Z., 1991, ROUGH SETS THEORETIC; POLKOWSKI L, 1997, ROUGH SETS DATA MINI, P259; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Robinson J. J., 1981, Paper, 32nd Annual Meeting of the European Association for Animal Production; Rosenblueth A., 1943, PHILOS SCI, V10, P18, DOI DOI 10.1086/286788; RUSSELL SJ, 1989, USE KNOWLEDGE ANALOG; SALZBERG S, 1991, MACH LEARN, V2, P229; Savaresi S.M., 2001, P 1 SIAM INT C DAT M, P1; SELLIS T, 1987, P 13 INT C VER LARG, P574; SHEPARD RN, 1987, SCIENCE, V237, P1317, DOI 10.1126/science.3629243; Skowron A, 2004, LECT NOTES ARTIF INT, V3066, P229; Skowron A., ROUGH SET EXPLORATIO; Skowron A., 2003, ROUGH NEURAL COMPUTI, P43; Skowron A., 1992, INTELLIGENT DECISION, P331; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; UHLMANN JK, 1991, INFORM PROCESS LETT, V40, P175, DOI 10.1016/0020-0190(91)90074-R; Vapnik V., 1998, STAT LEARNING THEORY; VELOSO M, 1994, PLANNING LEARNING AN; von Neumann J., 1944, THEORY GAMES EC BEHA; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967; Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; Wettschereck D., 1994, THESIS OREGON STATE; White DA, 1996, PROC INT CONF DATA, P516, DOI 10.1109/ICDE.1996.492202; Wiener N., 1948, CYBERNETICS; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; Wilson DR, 2000, COMPUT INTELL, V16, P1, DOI 10.1111/0824-7935.00103; Wojna A, 2003, FUND INFORM, V56, P285; WOJNA AG, 2000, THESIS WARSAW U; WOJNA AG, 2003, P 3 IEEE INT C DAT M, P681; WOLPERT D, 1989, NEURAL NETWORKS, V3, P445; Wroblewski J., 1998, LECT NOTES ARTIF INT, V1424, P402; YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311; Zavrel J., 1997, P 7 BELG DUTCH C MAC, P139	96	19	19	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29830-4	LECT NOTES COMPUT SC			2005	3700						277	374				98	Computer Science, Theory & Methods	Computer Science	BDN26	WOS:000234424800011		
J	Elmer, SP; Pande, VS				Elmer, SP; Pande, VS			Foldamer simulations: Novel computational methods and applications to poly-phenylacetylene oligomers	JOURNAL OF CHEMICAL PHYSICS			English	Article							HELIX-COIL TRANSITION; NONBIOLOGICAL HELIX; MOLECULAR-DYNAMICS; PEPTIDE BACKBONE; BETA-PEPTIDES; FOLDING RATE; PROTEIN; MECHANISM; CONFORMATIONS; ETHYNYLENE)S	We apply several methods to probe the ensemble kinetic and structural properties of a model system of poly-phenylacetylene (pPA) oligomer folding trajectories. The kinetic methods employed included a brute force accounting of conformations, a Markovian state matrix method, and a nonlinear least squares fit to a minimalist kinetic model used to extract the folding time. Each method gave similar measures for the folding time of the 12-mer chain, calculated to be on the order of 7 ns for the complete folding of the chain from an extended conformation. Utilizing both a linear and a nonlinear scaling relationship between the viscosity and the folding time to correct for a low simulation viscosity, we obtain an upper and a lower bound for the approximate folding time within the range 70 ns<tau<350 ns. This is in agreement with the experimentally measured folding time on the order of 160 ns. The kinetic model used to fit the kinetic behavior of the ensemble of trajectories provides a framework to describe the bulk folding mechanism. We were able to identify two unique clusters of conformations that provide a structural basis to account for the appearance of a kinetic intermediate in the mechanism. We discuss the implications of these findings in the context of helix-coil theory. (C) 2004 American Institute of Physics.	Stanford Univ, Dept Chem, Stanford, CA 94305 USA	Elmer, SP (reprint author), Stanford Univ, Dept Chem, Stanford, CA 94305 USA.						Armand P, 1997, FOLD DES, V2, P369, DOI 10.1016/S1359-0278(97)00051-5; Barron AE, 1999, CURR OPIN CHEM BIOL, V3, P681, DOI 10.1016/S1367-5931(99)00026-5; BERENDSEN HJC, 1995, COMPUT PHYS COMMUN, V91, P43, DOI 10.1016/0010-4655(95)00042-E; Cheng RP, 2001, CHEM REV, V101, P3219, DOI 10.1021/cr000045i; CHO CY, 1993, SCIENCE, V261, P1303, DOI 10.1126/science.7689747; *CRC, 1985, CRC HDB CHEM PHYS, pF37; Daggett V, 2003, NAT REV MOL CELL BIO, V4, P497, DOI 10.1038/nrm1126; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100; Du R, 1998, J CHEM PHYS, V108, P334, DOI 10.1063/1.475393; EGHOLM M, 1992, J AM CHEM SOC, V114, P1895, DOI 10.1021/ja00031a062; Elmer S, 2001, J PHYS CHEM B, V105, P482, DOI 10.1021/jp0019761; ELMER S, UNPUB; Fersht A., 1999, STRUCTURE MECH PROTE; Fersht AR, 2002, P NATL ACAD SCI USA, V99, P14122, DOI 10.1073/pnas.182542699; Gellman SH, 1998, ACCOUNTS CHEM RES, V31, P173, DOI 10.1021/ar960298r; Gin MS, 2000, ORG LETT, V2, P135, DOI 10.1021/ol9912074; GREEN MM, 1995, SCIENCE, V268, P1860, DOI 10.1126/science.268.5219.1860; Gutfreund H., 1995, KINETICS LIFE SCI RE; HAGIHARA M, 1992, J AM CHEM SOC, V114, P6568, DOI 10.1021/ja00042a052; Hastie T., 2001, ELEMENTS STAT LEARNI; Hill DJ, 2001, CHEM REV, V101, P3893, DOI 10.1021/cr990120t; Hill DJ, 2002, P NATL ACAD SCI USA, V99, P5053, DOI 10.1073/pnas.072642799; LIFSON S, 1961, J CHEM PHYS, V34, P1963, DOI 10.1063/1.1731802; Lindahl E, 2001, J MOL MODEL, V7, P306; Lotan I, 2004, J COMPUT BIOL, V11, P299, DOI 10.1089/1066527041410355; MENDES P, 1993, COMPUT APPL BIOSCI, V9, P563; Mendes P, 1997, TRENDS BIOCHEM SCI, V22, P361, DOI 10.1016/S0968-0004(97)01103-1; Nelson JC, 1997, SCIENCE, V277, P1793, DOI 10.1126/science.277.5333.1793; Oh K, 2001, NATURE, V414, P889, DOI 10.1038/414889a; Prince RB, 1999, J AM CHEM SOC, V121, P3114, DOI 10.1021/ja983995i; Prince RB, 2000, J AM CHEM SOC, V122, P2758, DOI 10.1021/ja993830p; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Seebach D, 1997, CHEM COMMUN, P2015, DOI 10.1039/a704933a; Seebach D, 2002, CHEM-EUR J, V8, P573, DOI 10.1002/1521-3765(20020201)8:3<573::AID-CHEM573>3.0.CO;2-H; SHENKIN PS, 1994, J COMPUT CHEM, V15, P899, DOI 10.1002/jcc.540150811; Singhal N, 2004, J CHEM PHYS, V121, P415, DOI 10.1063/1.1738647; Sorin EJ, 2004, J MOL BIOL, V337, P789, DOI 10.1016/j.jmb.2004.02.024; SORIN EJ, UNPUB; Soth MJ, 1997, CURR OPIN CHEM BIOL, V1, P120, DOI 10.1016/S1367-5931(97)80118-4; STRANG G, 1988, LINEAR ALGEBRA ITS A; Tanatani A, 2001, J AM CHEM SOC, V123, P1792, DOI 10.1021/ja003678n; TENNENBAUM JB, 2000, SCIENCE, V290, P2319; ten Wolde PR, 2002, P NATL ACAD SCI USA, V99, P6539, DOI 10.1073/pnas.052153299; Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293; Yang WY, 2000, J AM CHEM SOC, V122, P3248, DOI 10.1021/ja993343+; Zagrovic B, 2003, NAT STRUCT BIOL, V10, P955, DOI 10.1038/nsb995; Zagrovic B, 2003, J COMPUT CHEM, V24, P1432, DOI 10.1002/jcc.10297; ZIMM BH, 1959, J CHEM PHYS, V31, P526, DOI 10.1063/1.1730390; ZUCKERMANN RN, 1994, J MED CHEM, V37, P2678, DOI 10.1021/jm00043a007	49	22	23	AMER INST PHYSICS	MELVILLE	CIRCULATION & FULFILLMENT DIV, 2 HUNTINGTON QUADRANGLE, STE 1 N O 1, MELVILLE, NY 11747-4501 USA	0021-9606			J CHEM PHYS	J. Chem. Phys.	DEC 22	2004	121	24					12760	12771		10.1063/1.1812272		12	Physics, Atomic, Molecular & Chemical	Physics	879JQ	WOS:000225714500073	15606301	
J	Jenkins, JL; Glick, M; Davies, JW				Jenkins, JL; Glick, M; Davies, JW			A 3D similarity method for scaffold hopping from the known drugs or natural ligands to new chemotypes	JOURNAL OF MEDICINAL CHEMISTRY			English	Article							3-DIMENSIONAL CHEMICAL STRUCTURES; MOLECULAR SIMILARITY; COMBINATORIAL LIBRARIES; LEAD DISCOVERY; DATA FUSION; DESIGN; DESCRIPTORS; IDENTIFICATION; GENERATION; INHIBITORS	A primary goal of 3D similarity searching is to find compounds with similar bioactivity to a reference ligand but with different chemotypes, i.e., "scaffold hopping". However, an adequate description of chemical structures in 3D conformational space is difficult due to the high-dimensionality of the problem. We present an automated method that simplifies flexible 3D chemical descriptions in which clustering techniques traditionally used in data mining are exploited to create "fuzzy" molecular representations called FEPOPS (feature point pharmacophores). The representations can be used for flexible 3D similarity searching given one or more active compounds without a priori knowledge of bioactive conformations or pharmacophores. We demonstrate that similarity searching with FEPOPS significantly enriches for actives taken from in-house high-throughput screening datasets and from MDDR activity classes COX-2, 5-HT3A, and HIV-RT, while also scaffold or ring-system hopping to new chemical frameworks. Further, inhibitors of target proteins (dopamine 2 and retinoic acid receptor) are recalled by FEPOPS by scaffold hopping from their associated endogenous ligands (dopamine and retinoic acid). Importantly, the method excels in comparison to commonly used 2D similarity methods (DAYLIGHT, MACCS, Pipeline Pilot fingerprints) and a commercial 3D method (Pharmacophore Distance Triplets) at finding novel scaffold classes given a single query molecule.	Novartis Inst Biomed Res Inc, Lead Discovery Ctr, Cambridge, MA 02139 USA	Jenkins, JL (reprint author), Novartis Inst Biomed Res Inc, Lead Discovery Ctr, 250 Massachusetts Ave, Cambridge, MA 02139 USA.	jeremy.jenkins@pharma.novartis.com					ABOLMAALI SFB, 2003, J MOL MODEL, V9, P6; Abrahamian E, 2003, J CHEM INF COMP SCI, V43, P458, DOI 10.1021/ci025595r; Andrews KM, 2000, J MED CHEM, V43, P1723, DOI 10.1021/jm000003m; APAYA RP, 1995, J COMPUT AID MOL DES, V9, P33, DOI 10.1007/BF00117276; Azam M, 2003, CELL, V112, P831, DOI 10.1016/S0092-8674(03)00190-9; Bemis GW, 1996, J MED CHEM, V39, P2887, DOI 10.1021/jm9602928; Bohl M, 2002, QUANT STRUCT-ACT REL, V21, P590, DOI 10.1002/qsar.200290001; Brown RD, 1996, J CHEM INF COMP SCI, V36, P572, DOI 10.1021/ci9501047; Chen X, 1999, J CHEM INF COMP SCI, V39, P887, DOI 10.1021/ci990327n; Cramer RD, 2002, J MOL GRAPH MODEL, V20, P447, DOI 10.1016/S1093-3263(01)00146-2; Emilien G, 1999, PHARMACOL THERAPEUT, V84, P133, DOI 10.1016/S0163-7258(99)00029-7; Feher M, 2003, J CHEM INF COMP SCI, V43, P810, DOI 10.1021/ci0200671; Feher M, 2003, J CHEM INF COMP SCI, V43, P218, DOI 10.1021/ci0200467; GASTEIGER J, 1980, TETRAHEDRON, V36, P3219, DOI 10.1016/0040-4020(80)80168-2; Gasteiger J., 2003, CHEMOINFORMATICS; Gillet VJ, 2003, J CHEM INF COMP SCI, V43, P338, DOI 10.1021/ci025592e; Ginn CMR, 2000, PERSPECT DRUG DISCOV, V20, P1, DOI 10.1023/A:1008752200506; Ginn CMR, 1997, J CHEM INF COMP SCI, V37, P23, DOI 10.1021/ci960466u; Glick M, 2002, J AM CHEM SOC, V124, P2337, DOI 10.1021/ja016490s; GLICK M, 2003, Patent No. 0024120030120; Glick M, 2002, J MED CHEM, V45, P4639, DOI 10.1021/jm020830i; HAHN M, 1995, J MED CHEM, V38, P2080, DOI 10.1021/jm00012a007; Hastie T., 2001, ELEMENTS STAT LEARNI; JENKINS JL, 2004, Patent No. 60546835; JENKINS JL, 2004, Patent No. 60559602; Kaufman L., 1990, FINDING GROUPS DATA; Kearsley SK, 1996, J CHEM INF COMP SCI, V36, P118, DOI 10.1021/ci950274j; Kier L.B., 1971, MOL ORBITAL THEORY D; Kurumbail RG, 1996, NATURE, V384, P644, DOI 10.1038/384644a0; Lee ML, 2001, J COMB CHEM, V3, P284, DOI 10.1021/cc0000971; Lemmen C, 2000, PERSPECT DRUG DISCOV, V20, P43, DOI 10.1023/A:1008712519162; Lemmen C, 2000, J COMPUT AID MOL DES, V14, P215, DOI 10.1023/A:1008194019144; Lewell XQ, 2003, J MED CHEM, V46, P3257, DOI 10.1021/jm0300429; Lipkus AH, 1999, J CHEM INF COMP SCI, V39, P582, DOI 10.1021/ci980151+; Lipkus AH, 2001, J CHEM INF COMP SCI, V41, P430, DOI 10.1021/ci000144x; Lloyd DG, 2004, J MED CHEM, V47, P493, DOI 10.1021/jm034222u; Maggiora G. M, 1990, CONCEPTS APPL MOL SI, P99; Makara GM, 2001, J MED CHEM, V44, P3563, DOI 10.1021/jm010036h; Martin YC, 2002, J MED CHEM, V45, P4350, DOI 10.1021/jm020155c; Mason JS, 1999, J MED CHEM, V42, P3251, DOI 10.1021/jm9806998; Mason J.S., 1999, PAC S BIOCOMPUT, V4, P456; Matter H, 1999, J CHEM INF COMP SCI, V39, P1211, DOI 10.1021/ci980185h; Mestres J, 1997, J COMPUT CHEM, V18, P934, DOI 10.1002/(SICI)1096-987X(199705)18:7<934::AID-JCC6>3.0.CO;2-S; Miller MD, 1999, J MED CHEM, V42, P1505, DOI 10.1021/jm9806143; MORGAN HL, 1965, J CHEM DOC, V5, P107, DOI 10.1021/c160017a018; Mount J, 1999, J MED CHEM, V42, P60, DOI 10.1021/jm970775r; Naerum L, 2002, BIOORG MED CHEM LETT, V12, P1525; Natesh R, 2003, NATURE, V421, P551, DOI 10.1038/nature01370; NILAKANTAN R, 1990, J CHEM INF COMP SCI, V30, P65, DOI 10.1021/ci00065a015; PARIS CG, 1997, ANN REV INFORMATION; Pearson K., 1896, PHILOS T R SOC A, V187, P253, DOI DOI 10.1098/RSTA.1896.0007; Pickett SD, 1998, J CHEM INF COMP SCI, V38, P144, DOI 10.1021/ci970060x; Pirard B, 2000, J CHEM INF COMP SCI, V40, P1431, DOI 10.1021/ci000386x; R Development Core Team, 2003, R LANG ENV STAT COMP; Rarey M, 2001, J COMPUT AID MOL DES, V15, P497, DOI 10.1023/A:1011144622059; Rarey M, 1998, J COMPUT AID MOL DES, V12, P471, DOI 10.1023/A:1008068904628; Raymond JW, 2003, J CHEM INF COMP SCI, V43, P908, DOI 10.1021/ci034002p; Rhodes N, 2003, J CHEM INF COMP SCI, V43, P443, DOI 10.1021/ci025605o; Schapira Matthieu, 2001, BMC Structural Biology, V1, P1, DOI 10.1186/1472-6807-1-1; Schneider G, 1999, ANGEW CHEM INT EDIT, V38, P2894, DOI 10.1002/(SICI)1521-3773(19991004)38:19<2894::AID-ANIE2894>3.0.CO;2-F; Schuffenhauer A, 2002, J CHEM INF COMP SCI, V42, P947, DOI 10.1021/co010385k; Schuffenhauer A, 2003, J CHEM INF COMP SCI, V43, P391, DOI 10.1021/ci025569t; Sheridan RP, 2002, DRUG DISCOV TODAY, V7, P903, DOI 10.1016/S1359-6446(02)02411-X; Sheridan RP, 2001, J CHEM INF COMP SCI, V41, P1395, DOI 10.1021/ci0100144; Silverman BD, 1996, J MED CHEM, V39, P2129, DOI 10.1021/jm950589q; Silverman BD, 2000, J CHEM INF COMP SCI, V40, P1470, DOI 10.1021/ci000457s; Stanton DT, 1999, J CHEM INF COMP SCI, V39, P21, DOI 10.1021/ci9801015; Thorner DA, 1996, J CHEM INF COMP SCI, V36, P900, DOI 10.1021/ci960002w; Wang RX, 1997, J CHEM INF COMP SCI, V37, P615, DOI 10.1021/ci960169p; Willett P, 1998, J CHEM INF COMP SCI, V38, P983, DOI 10.1021/ci9800211; Xu J, 2002, J MED CHEM, V45, P5311, DOI 10.1021/jm010520k; Xu YJ, 2001, J CHEM INF COMP SCI, V41, P181, DOI 10.1021/ci0003911; Xu YJ, 2002, J CHEM INF COMP SCI, V42, P912, DOI 10.1021/ci0255351	73	81	82	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0022-2623			J MED CHEM	J. Med. Chem.	DEC 2	2004	47	25					6144	6159		10.1021/jm049654z		16	Chemistry, Medicinal	Pharmacology & Pharmacy	875GX	WOS:000225409400007	15566286	
J	Monks, SA; Leonardson, A; Zhu, H; Cundiff, P; Pietrusiak, P; Edwards, S; Phillips, JW; Sachs, A; Schadt, EE				Monks, SA; Leonardson, A; Zhu, H; Cundiff, P; Pietrusiak, P; Edwards, S; Phillips, JW; Sachs, A; Schadt, EE			Genetic inheritance of gene expression in human cell lines	AMERICAN JOURNAL OF HUMAN GENETICS			English	Article							TRAIT LINKAGE ANALYSIS; REGULATORY VARIATION; HUMAN GENOME; MICROARRAYS; MOUSE; MAP	Combining genetic inheritance information, for both molecular profiles and complex traits, is a promising strategy not only for detecting quantitative trait loci (QTLs) for complex traits but for understanding which genes, pathways, and biological processes are also under the influence of a given QTL. As a primary step in determining the feasibility of such an approach in humans, we present the largest survey to date, to our knowledge, of the heritability of gene-expression traits in segregating human populations. In particular, we measured expression for 23,499 genes in lymphoblastoid cell lines for members of 15 Centre d'Etude du Polymorphisme Humain ( CEPH) families. Of the total set of genes, 2,340 were found to be expressed, of which 31% had significant heritability when a false-discovery rate of 0.05 was used. QTLs were detected for 33 genes on the basis of at least one P value <.000005. Of these, 13 genes possessed a QTL within 5 Mb of their physical location. Hierarchical clustering was performed on the basis of both Pearson correlation of gene expression and genetic correlation. Both reflected biologically relevant activity taking place in the lymphoblastoid cell lines, with greater coherency represented in Kyoto Encyclopedia of Genes and Genomes database (KEGG) pathways than in Gene Ontology database pathways. However, more pathway coherence was observed in KEGG pathways when clustering was based on genetic correlation than when clustering was based on Pearson correlation. As more expression data in segregating populations are generated, viewing clusters or networks based on genetic correlation measures and shared QTLs will offer potentially novel insights into the relationship among genes that may underlie complex traits.	Oklahoma State Univ, Dept Stat, Stillwater, OK 74078 USA; Univ Washington, Dept Biostat, Seattle, WA 98195 USA; Univ Washington, Dept Pharmacol, Seattle, WA 98195 USA; Rosetta Inpharmat LLC, Seattle, WA USA; Johns Hopkins Univ, Dept Epidemiol, Baltimore, MD USA; Merck & Co Inc, Merck Res Labs, Rahway, NJ 07065 USA	Monks, SA (reprint author), Oklahoma State Univ, Dept Stat, 301G Math Stat & Comp Sci Bldg, Stillwater, OK 74078 USA.	stephanie.monks@okstate.edu					Almasy L, 1998, AM J HUM GENET, V62, P1198, DOI 10.1086/301844; Almasy L, 1997, GENET EPIDEMIOL, V14, P953, DOI 10.1002/(SICI)1098-2272(1997)14:6<953::AID-GEPI65>3.0.CO;2-K; Belmaker RH, 2002, BIPOLAR DISORD, V4, P67, DOI 10.1034/j.1399-5618.2002.00108.x; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; BOTSTEIN D, 1980, AM J HUM GENET, V32, P314; Brem RB, 2002, SCIENCE, V296, P752, DOI 10.1126/science.1069516; Cheung VG, 2003, NAT GENET, V33, P422, DOI 10.1038/ng1094; Cowles CR, 2002, NAT GENET, V32, P432, DOI 10.1038/ng992; DAUSSET J, 1990, GENOMICS, V6, P575, DOI 10.1016/0888-7543(90)90491-C; FULKER DW, 1995, AM J HUM GENET, V56, P1224; Hastie T., 2001, ELEMENTS STAT LEARNI; Hughes TR, 2001, NAT BIOTECHNOL, V19, P342, DOI 10.1038/86730; Hughes TR, 2000, NAT GENET, V25, P333; Jansen RC, 2001, TRENDS GENET, V17, P388, DOI 10.1016/S0168-9525(01)02310-1; Jin W, 2001, NAT GENET, V29, P389, DOI 10.1038/ng766; Kong A, 2002, NAT GENET, V31, P241, DOI 10.1038/ng917; Marton MJ, 1998, NAT MED, V4, P1293, DOI 10.1038/3282; Schadt EE, 2003, NATURE, V422, P297, DOI 10.1038/nature01482; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Whitney AR, 2003, P NATL ACAD SCI USA, V100, P1896, DOI 10.1073/pnas.252784499; Williams JT, 1999, AM J HUM GENET, V65, P1134, DOI 10.1086/302570; Yan H, 2002, SCIENCE, V297, P1143, DOI 10.1126/science.1072545; Yvert G, 2003, NAT GENET, V35, P57, DOI 10.1038/ng1222; Zhu J, 2004, CYTOGENET GENOME RES, V105, P363, DOI 10.1159/000078209	24	255	264	UNIV CHICAGO PRESS	CHICAGO	1427 E 60TH ST, CHICAGO, IL 60637-2954 USA	0002-9297			AM J HUM GENET	Am. J. Hum. Genet.	DEC	2004	75	6					1094	1105		10.1086/426461		12	Genetics & Heredity	Genetics & Heredity	867TW	WOS:000224866400013	15514893	
J	Patrick, ME; Christiansen, LE; Waino, M; Ethelberg, S; Madsen, H; Wegener, HC				Patrick, ME; Christiansen, LE; Waino, M; Ethelberg, S; Madsen, H; Wegener, HC			Effects of climate on incidence of Campylobacter spp. in humans and prevalence in broiler flocks in Denmark	APPLIED AND ENVIRONMENTAL MICROBIOLOGY			English	Article							FETUS SUBSP JEJUNI; RISK-FACTORS; THERMOTOLERANT CAMPYLOBACTER; THERMOPHILIC CAMPYLOBACTERS; AMBIENT-TEMPERATURE; NEW-ZEALAND; EL-NINO; INFECTIONS; SALMONELLA; NORWAY	Campylobacter infections are increasing and pose a serious public health problem in Denmark. Infections in humans and broiler flocks show similar seasonality, suggesting that climate may play a role in infection. We examined the effects of temperature, precipitation, relative humidity, and hours of sunlight on Campylobacter incidence in humans and broiler flocks by using lag dependence functions, locally fitted linear models, and cross validation methods. For humans, the best model included average temperature and sunlight 4 weeks prior to infection; the maximum temperature lagged at 4 weeks was the best single predictor. For broilers, the average and maximum temperatures 3 weeks prior to slaughter gave the best estimate; the average temperature lagged at 3 weeks was the best single predictor. The combined effects of temperature and sunlight or the combined effects of temperature and relative humidity predicted the incidence in humans equally well. For broiler flock incidence these factors explained considerably less. Future research should focus on elements within the broiler environment that may be affected by climate, as well as the interaction of microclimatic factors on and around broiler farms. There is a need to quantify the contribution of broilers as a source of campylobacteriosis in humans and to further examine the effect of temperature on human incidence after this contribution is accounted for. Investigations should be conducted into food consumption and preparation practices and poultry sales that may vary by season.	Danish Inst Food & Vet Res, DK-2860 Soborg, Denmark; Tech Univ Denmark, Kongens Lyngby, Denmark; Danish Inst Food & Vet Res, Aarhus, Denmark; Statens Serum Inst, DK-2300 Copenhagen, Denmark	Wegener, HC (reprint author), Danish Inst Food & Vet Res, Morkhoj Bygade 19, DK-2860 Soborg, Denmark.	hcw@dfvf.dk					Berndtson E, 1996, PREV VET MED, V26, P167, DOI 10.1016/0167-5877(95)01008-4; BRENNHOVD O, 1992, INT J FOOD MICROBIOL, V15, P327, DOI 10.1016/0168-1605(92)90066-C; CABRITA J, 1992, J APPL BACTERIOL, V73, P279, DOI 10.1111/j.1365-2672.1992.tb04978.x; Chan KF, 2001, APPL ENVIRON MICROB, V67, P4186, DOI 10.1128/AEM.67.9.4186-4191.2001; Checkley W, 2000, LANCET, V355, P442; DACKOWSKAKOZON E, 2001, INT J HYG ENVIR HEAL, V203, P435; DOYLE MP, 1984, APPL ENVIRON MICROB, V47, P533; Eberhart-Phillips J, 1997, J EPIDEMIOL COMMUN H, V51, P686, DOI 10.1136/jech.51.6.686; Engberg J, 1998, CLIN MICROBIOL INFEC, V4, P648, DOI 10.1111/j.1469-0691.1998.tb00348.x; Friedman CR, 2000, CAMPYLOBACTER, P121; GLUNDER G, 1992, J VET MED B, V39, P119; Hald B, 1997, J CLIN MICROBIOL, V35, P3351; Hald T, 2001, BERL MUNCH TIERARZTL, V114, P346; Hastie T., 2001, ELEMENTS STAT LEARNI; HOPKINS RS, 1983, J INFECT DIS, V148, P770; JACOBSREITSMA WF, 1995, EPIDEMIOL INFECT, V114, P413; JACOBSREITSMA WF, 1994, POULTRY SCI, V73, P1260; KAPPERUD G, 1992, APMIS, V100, P883; KAPPERUD G, 1992, J CLIN MICROBIOL, V30, P3117; KAPPERUD G, 1993, EPIDEMIOL INFECT, V111, P245; LUECHTEFELD NAW, 1980, J CLIN MICROBIOL, V12, P406; MADSEN H, 1997, STAT FINANCE; MELBY K, 1990, J INFECTION, V21, P309, DOI 10.1016/0163-4453(90)94125-J; NEAL KR, 1995, J PUBLIC HEALTH MED, V17, P98; Neimann J, 2003, EPIDEMIOL INFECT, V130, P353; Nielsen HA, 2001, COMPUT STAT DATA AN, V37, P13, DOI 10.1016/S0167-9473(00)00061-X; Norval M, 2001, J PHOTOCH PHOTOBIO B, V63, P28, DOI 10.1016/S1011-1344(01)00200-7; Nylen G, 2002, EPIDEMIOL INFECT, V128, P383, DOI 10.1017/S0950268802006830; Obiri-Danso K, 2001, J APPL MICROBIOL, V90, P256, DOI 10.1046/j.1365-2672.2001.01239.x; Rautelin H, 2000, ANN MED, V32, P440, DOI 10.3109/07853890009002018; Rodrigues LC, 2001, EPIDEMIOL INFECT, V127, P185; ROSEF O, 1983, APPL ENVIRON MICROB, V45, P381; Speelmon EC, 2000, JAMA-J AM MED ASSOC, V283, P3072, DOI 10.1001/jama.283.23.3072-a; Stanley KN, 1998, J APPL MICROBIOL, V85, P472, DOI 10.1046/j.1365-2672.1998.853511.x; Studahl A, 2000, EPIDEMIOL INFECT, V125, P269, DOI 10.1017/S0950268899004562; Tenkate TD, 2001, EPIDEMIOL INFECT, V127, P399; Tong SL, 1998, LANCET, V351, P1100, DOI 10.1016/S0140-6736(05)79379-X; Wallace JS, 1997, J APPL MICROBIOL, V82, P219, DOI 10.1111/j.1365-2672.1997.tb02854.x; Wedderkopp A, 2001, INT J FOOD MICROBIOL, V68, P53, DOI 10.1016/S0168-1605(01)00463-9; 2001, ANN REPORT ZOONOSIS; 2000, INCREASING INCIDENCE	41	64	64	AMER SOC MICROBIOLOGY	WASHINGTON	1752 N ST NW, WASHINGTON, DC 20036-2904 USA	0099-2240			APPL ENVIRON MICROB	Appl. Environ. Microbiol.	DEC	2004	70	12					7474	7480		10.1128/AEM.70.12.7474-7480.2004		7	Biotechnology & Applied Microbiology; Microbiology	Biotechnology & Applied Microbiology; Microbiology	879LM	WOS:000225719300065	15574950	
J	Maunder, MN; Punt, AE				Maunder, MN; Punt, AE			Standardizing catch and effort data: a review of recent approaches	FISHERIES RESEARCH			English	Article						abundance; catch; CPUE; effort; GAM; GLM; GLMM	NORTHERN PRAWN FISHERY; ZERO-INFLATED POISSON; STOCK ASSESSMENT; UNIT-EFFORT; RELATIVE ABUNDANCE; LONGLINE FISHERY; COMMERCIAL CATCH; LINEAR-MODELS; BLUEFIN TUNA; AGE DATA	The primary indices of abundance for many of the world's most valuable species (e.g. tunas) and vulnerable species (e.g. sharks) are based on catch and effort data collected from commercial and recreational fishers. These indices can, however, be misleading because changes over time in catch rates can occur because of factors other than changes in abundance. Catch-effort standardization is used to attempt to remove the impact of these factors. This paper reviews the current state of the art in the methods for standardizing catch and effort data. It outlines the major estimation approaches being applied, the methods for dealing with zero observations, how to identify and select appropriate explanatory variables, and how standardized catch rate data can be used when conducting stock assessments. (C) 2004 Elsevier B.V. All rights reserved.	Interamer Trop Tuna Commiss, La Jolla, CA 92037 USA; Univ Washington, Sch Aquat & Fishery Sci, Seattle, WA 98195 USA	Maunder, MN (reprint author), Interamer Trop Tuna Commiss, 8904 La Jolla Shores Dr, La Jolla, CA 92037 USA.	mmaunder@iattc.org					AITCHISON J, 1955, J AM STAT ASSOC, V50, P901, DOI 10.2307/2281175; AKAKE H, 1973, P 2 INT S INF THEOR, P268; ANDERSON OF, 2003, 200324 NZ FISH ASS; AYERS D, 2003, 200334 NZ FISH ASS; BANNEROT SP, 1983, T AM FISH SOC, V112, P608, DOI 10.1577/1548-8659(1983)112<608:UFDOCP>2.0.CO;2; Battaile BC, 2004, FISH RES, V70, P161, DOI 10.1016/j.fishres.2004.08.029; BERRY DA, 1987, BIOMETRICS, V43, P439, DOI 10.2307/2531826; Beverton R.J.H., 1957, DYNAMICS EXPLOITED F; Bigelow KA, 1999, FISH OCEANOGR, V8, P178, DOI 10.1046/j.1365-2419.1999.00105.x; Bishop J, 2000, AUST NZ J STAT, V42, P159, DOI 10.1111/1467-842X.00116; BRANDAO A, 2004, FISH RES, V70, P335; BREEN PA, 2003, 200335 NZ FISH ASS; Burnham K.P., 2002, MODEL SELECTION MULT; Butterworth D. S., 1996, ICCAT COL VOL SCI PA, V45, P123; BUTTERWORTH DS, 1984, INT COMM SE ATL FISH, V11, P29; Butterworth DS, 2003, AFR J MAR SCI, V25, P331, DOI 10.2989/18142320309504021; Campbell R, 1998, LOW WAKE FI, V15, P75; Campbell RA, 2004, FISH RES, V70, P209, DOI 10.1016/j.fishres.2004.08.026; Casella G., 1990, STAT INFERENCE; Chang Shui-Kai, 2003, International Commission for the Conservation of Atlantic Tunas Collective Volume of Scientific Papers, V55, P453; Cooke J G, 1985, REP INT WHALING COMM, V35, P511; Cooke J.G., 1996, International Commission for the Conservation of Atlantic Tunas Collective Volume of Scientific Papers, V45, P125; COOKE JG, 1984, IMA J MATH APPL MED, V1, P291; COPE JM, 2003, STATUS FUTURE PROSPE; CRAGG JG, 1971, ECONOMETRICA, V39, P829, DOI 10.2307/1909582; DERISO RB, 1985, CAN J FISH AQUAT SCI, V42, P815, DOI 10.1139/f85-104; Dichmont CM, 2003, FISH RES, V65, P335, DOI 10.1016/j.fishres.200309.024; DICK EJ, 2004, FISH RES, V70, P347; DOBSON AJ, 1991, INTRO GEN LINEAR MOD; Dong Q., 1996, International Commission for the Conservation of Atlantic Tunas Collective Volume of Scientific Papers, V45, P158; DUNN A, 2000, 20001 NZ FISH ASS; FOURNIER D, 1982, CAN J FISH AQUAT SCI, V39, P1195, DOI 10.1139/f82-157; Fournier DA, 1998, CAN J FISH AQUAT SCI, V55, P2105, DOI 10.1139/cjfas-55-9-2105; FRANCIS RIC, 2001, 200242 NZ FISH ASS; FRANCIS RIC, 1999, 9942 NZ FISH ASS; Francis RICC, 2003, FISH B-NOAA, V101, P293; GAVARIS S, 1980, CAN J FISH AQUAT SCI, V37, P2272; Guisan A, 2002, ECOL MODEL, V157, P89, DOI 10.1016/S0304-3800(02)00204-1; GULLAND JA, 1956, FISH INVEST 2, V20, P1; Hall DB, 2000, BIOMETRICS, V56, P1030, DOI 10.1111/j.0006-341X.2000.01030.x; Harley SJ, 2001, CAN J FISH AQUAT SCI, V58, P1760, DOI 10.1139/cjfas-58-9-1760; Hastie T., 2001, ELEMENTS STAT LEARNI; HILBORN R, 2000, 0001 FRIUW; Hilborn R, 1997, ECOLOGICAL DETECTIVE; Hilborn R., 1992, QUANTITATIVE FISHERI; Hinton M. G., 2003, SCRS2003034 ICCAT; Hinton M.G., 1996, B INT AM TROP TUNA C, V21, P171; HONMA M, 1974, B FAR SEAS FISH RES, V10, P63; Horn P.L., 2003, 200313 NZ FISH ASS; KIMURA DK, 1981, J CONSEIL, V39, P211; LAMBERT D, 1992, TECHNOMETRICS, V34, P1, DOI 10.2307/1269547; Liang K. Y., 1992, BIOMETRIKA, V73, P12; LO NCH, 1992, CAN J FISH AQUAT SCI, V49, P2515, DOI 10.1139/f92-278; Maunder MN, 2001, CAN J FISH AQUAT SCI, V58, P795, DOI 10.1139/cjfas-58-4-795; MAUNDER MN, 2004, FISH RES, V70, P385; MAUNDER MN, 2003, MWG2 SCTB16 INT AM T; Maunder MN, 2003, FISH RES, V63, P43, DOI 10.1016/S0165-7836(03)00002-X; McCullagh P., 1989, GEN LINEAR MODELS; Methot R., 2000, NMFSNWFSC43 NOAA; METHOT RD, 1993, B INT N PAC FISH COM, V50, P259; Miyabe N., 2003, International Commission for the Conservation of Atlantic Tunas Collective Volume of Scientific Papers, V55, P1190; MULLAHY J, 1986, J ECONOMETRICS, V33, P341, DOI 10.1016/0304-4076(86)90002-3; MYERS RA, 1995, CAN J FISH AQUAT SCI, V52, P1265; MYERS RA, 1990, BIOMETRICS, V46, P1185, DOI 10.2307/2532460; NELDER JA, 1972, J R STAT SOC SER A-G, V135, P370, DOI 10.2307/2344614; NRC (National Research Council), 1994, ASS ATL BLUEF TUN; Ortiz M, 2004, FISH RES, V70, P275, DOI 10.1016/j.fishres.2004.08.028; Pinheiro J., 2000, MIXED EFFECTS MODELS; PORCH CE, 1994, ICCAT COL VOL SCI PA, V42, P241; Porter J.M., 2003, International Commission for the Conservation of Atlantic Tunas Collective Volume of Scientific Papers, V55, P1005; Prince Jeremy, 1998, Canadian Special Publication of Fisheries and Aquatic Sciences, V125, P187; Punt A.E., 2003, International Commission for the Conservation of Atlantic Tunas Collective Volume of Scientific Papers, V55, P1041; Punt AE, 1997, MAR FRESHWATER RES, V48, P967, DOI 10.1071/MF97070; Punt AE, 2000, FISH RES, V45, P129, DOI 10.1016/S0165-7836(99)00106-X; Punt AE, 2000, MAR FRESHWATER RES, V51, P205, DOI 10.1071/MF99124; PUNT AE, 2001, POPULATION MODELING; Punt AE, 2001, MAR FRESHWATER RES, V52, P701, DOI 10.1071/MF99136; QUINN TJ, 1982, CAN J FISH AQUAT SCI, V39, P837; Ralston S, 2003, STATUS BLACK ROCKFIS; Ridout MS, 1998, P 19 INT BIOM C CAP, P179; Robins CM, 1998, CAN J FISH AQUAT SCI, V55, P1645, DOI 10.1139/cjfas-55-7-1645; ROBSON D. S., 1966, INT COM NORTHWEST ATL FISH RES BULL, V3, P5; Rodriguez-Marin E, 2003, ICES J MAR SCI, V60, P1216, DOI 10.1016/S1054-3139(03)00139-5; Rousseeuw P., 1987, ROBUST REGRESSION OU; SCHNUTE J, 1977, J FISH RES BOARD CAN, V34, P583; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Stefansson G, 1996, ICES J MAR SCI, V53, P577, DOI 10.1006/jmsc.1996.0079; STEPHENS A, 2004, FISH RES, V70, P295; Syrjala SE, 2000, ICES J MAR SCI, V57, P831, DOI 10.1006/jmsc.2000.0571; TAYLOR PR, 2003, 200332 NZ FISH ASS; Vignaux M, 1996, CAN J FISH AQUAT SCI, V53, P963, DOI 10.1139/cjfas-53-5-963; VIGNAUX M, 1994, 97411 NZ FISH ASS RE; Walters C, 2003, CAN J FISH AQUAT SCI, V60, P1433, DOI 10.1139/F03-152; WATTERS G, 2000, B INT AM TROP TUNA C, V21, P527; ZEGER SL, 1986, BIOMETRICS, V42, P121, DOI 10.2307/2531248	95	301	329	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-7836			FISH RES	Fish Res.	DEC	2004	70	2-3					141	159		10.1016/j.fishres.2004.08.002		19	Fisheries	Fisheries	882MT	WOS:000225943700002		
J	Osei-Bryson, KM; Ko, M				Osei-Bryson, KM; Ko, M			Exploring the relationship between information technology investments and firm performance using regression splines analysis	INFORMATION & MANAGEMENT			English	Article						IT investments; productivity; productivity paradox; regression splines; multivariate adaptive regression splines (MARS); data mining	TECHNICAL EFFICIENCY; PRODUCTIVITY; SYSTEMS; PARADOX	Identifying the business value of information technology (IT) investments has been a major concern of managers and researchers. Various studies have addressed this issue but have provided contradictory results. Here, we explore the relationship between IT investments and firm performance using a relatively new, technique, multivatiate adaptive regression splines (MARS), and attempt to answer two questions: (1) do investments in IT have a positive impact on organizational productivity? and (2) for a given level of investment, what portion of the total should be invested in IT to maximize organizational productivity? Our results suggest that depending on the conditions that applied, an unbiased observer could either conclude that investments in IT has a positive statistically significant effect on productivity, or that there is a 'productivity' paradox. This suggests that the relationship between IT investments and organizational performance is much more complex than that found in some other studies. Our results could also provide guidance to managers who are responsible for determining the allocation of organizational resources. (C) 2003 Elsevier B.V. All rights reserved.	Virginia Commonwealth Univ, Dept Informat Syst, Richmond, VA 23284 USA; Virginia Commonwealth Univ, Informat Syst Res Inst, Richmond, VA 23284 USA; Univ Texas, Coll Business, Dept Informat Syst, San Antonio, TX 78249 USA	Osei-Bryson, KM (reprint author), Virginia Commonwealth Univ, Dept Informat Syst, Med Coll Virginia Campus, Richmond, VA 23284 USA.	kweku.muata@isy.vcu.edu; mko@utsa.edu					Bharadwaj AS, 2000, MIS QUART, V24, P169, DOI 10.2307/3250983; Brynjolfsson E, 1996, MANAGE SCI, V42, P541, DOI 10.1287/mnsc.42.4.541; Brynjolfsson E., 1993, Communications of the ACM, V36, DOI 10.1145/163298.163309; DENNISON DGT, 1997, BAYESIAN MARS; Dewan S, 1997, MANAGE SCI, V43, P1660, DOI 10.1287/mnsc.43.12.1660; Eubank R.L., 1988, SPLINE SMOOTHING NON; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; GARRETSON R, 1999, INFOWORLD, V21, P32; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T, 1990, GEN ADDITIVE MODELS; Hitt LM, 1996, MIS QUART, V20, P121, DOI 10.2307/249475; JURISON J, 1997, REEVALUATING PRODUCT, P30; KING WR, 1998, INFORMATION SYSTEMS, P64; KIVIJARVI H, 1995, INFORM MANAGE, V28, P143, DOI 10.1016/0378-7206(95)94022-5; Lee B, 2000, J MANAGE INFORM SYST, V16, P99; Lee CS, 2001, INFORM MANAGE, V39, P191, DOI 10.1016/S0378-7206(01)00090-8; Lichtenberg F, 1995, EC INNOVATION NEW TE, V3, P201, DOI DOI 10.1080/10438599500000003; Loveman G. W., 1994, INFORMATION TECHNOLO, P84; Mahmood M. A., 1993, Journal of Management Information Systems, V10; MCGEE MK, 2000, INFORMATION WEEK, P42; Rai A, 1997, COMMUN ACM, V40, P89, DOI 10.1145/256175.256191; *SALF SYST, 2000, MARS WIND VERS 2 0; *SALF SYST, 1999, MARS US GUID; SHAO B, 2000, THESIS STATE U NEW Y; Shao BBM, 2000, J COMPUT INFORM SYST, V41, P25; Shao BBM, 2002, INFORM MANAGE-AMSTER, V39, P391, DOI 10.1016/S0378-7206(01)00105-7; Shao BBM, 2001, INFORM SOFTWARE TECH, V43, P447, DOI 10.1016/S0950-5849(01)00150-1; SHU W, 2001, J ASS INFORMATION SY, V2, P1; Sircar S, 1998, J ENG VALUATION COST, V1, P171; Sircar S, 2000, J MANAGE INFORM SYST, V16, P69; Stratopoulos T, 2000, INFORM MANAGE, V38, P103, DOI 10.1016/S0378-7206(00)00058-6; Weill P., 1992, INFORMATION SYSTEMS, V3, P307, DOI DOI 10.1287/ISRE.3.4.307	32	24	27	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0378-7206			INFORM MANAGE-AMSTER	Inf. Manage.	DEC	2004	42	1					1	13		10.1016/j.im.2003.09.002		13	Computer Science, Information Systems; Information Science & Library Science; Management	Computer Science; Information Science & Library Science; Business & Economics	862KO	WOS:000224489700001		
J	Reis, MS; Saraiva, PM				Reis, MS; Saraiva, PM			A comparative study of linear regression methods in noisy environments	JOURNAL OF CHEMOMETRICS			English	Article						measurement uncertainty; multivariate least squares; maximum likelihood principal component regression; partial least squares; principal component regression	PARTIAL LEAST-SQUARES; PRINCIPAL COMPONENT ANALYSIS; MEASUREMENT ERRORS; PREDICTION; AXES; CALIBRATION; EXTRACTION	With the development of measurement instrumentation methods and metrology, one is very often able to rigorously specify the uncertainty associated with each measured value (e.g. concentrations, spectra, process sensors). The use of this information, along with the corresponding raw measurements, should, in principle, lead to more sound ways of performing data analysis, since the quality of data can be explicitly taken into account. This should be true, in particular, when noise is heteroscedastic and of a large magnitude. In this paper we focus on alternative multivariate linear regression methods conceived to take into account data uncertainties. We critically investigate their prediction and parameter estimation capabilities and suggest some modifications of well-established approaches. All alternatives are tested under simulation scenarios that cover different noise and data structures. The results thus obtained provide guidelines on which methods to use and when. Interestingly enough, some of the methods that explicitly incorporate uncertainty information in their formulations tend to present not as good performances in the examples studied, whereas others that do not do so present an overall good performance. Copyright (C) 2005 John Wiley & Sons, Ltd.	Univ Coimbra, GEPSI, PSE Grp, Dept Chem Engn, P-3030290 Coimbra, Portugal	Reis, MS (reprint author), Univ Coimbra, GEPSI, PSE Grp, Dept Chem Engn, Polo 2, P-3030290 Coimbra, Portugal.	marco@eq.uc.pt					Bro R, 2002, J CHEMOMETR, V16, P387, DOI 10.1002/cem.734; Burnham AJ, 1999, CHEMOMETR INTELL LAB, V48, P167, DOI 10.1016/S0169-7439(99)00018-0; Draper NR, 1998, APPL REGRESSION ANAL; Faber K, 1997, J CHEMOMETR, V11, P181, DOI 10.1002/(SICI)1099-128X(199705)11:3<181::AID-CEM459>3.0.CO;2-7; Faber NM, 2002, CHEMOMETR INTELL LAB, V61, P133, DOI 10.1016/S0169-7439(01)00204-0; Faber NM, 2000, CHEMOMETR INTELL LAB, V52, P123, DOI 10.1016/S0169-7439(00)00076-9; Pierna JAF, 2003, CHEMOMETR INTELL LAB, V65, P281; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; GELADI P, 1986, ANAL CHIM ACTA, V185, P1, DOI 10.1016/0003-2670(86)80028-9; GOODMAN LA, 1990, J AM STAT ASSOC, V85, P109; HAALAND DM, 1988, ANAL CHEM, V60, P1193, DOI 10.1021/ac00162a020; Hastie T., 2001, ELEMENTS STAT LEARNI; HELLAND IS, 1988, COMMUN STAT SIMULAT, V17, P581, DOI 10.1080/03610918808812681; Helland IS, 2001, CHEMOMETR INTELL LAB, V58, P97, DOI 10.1016/S0169-7439(01)00154-X; Hoskuldsson A, 1988, J CHEMOMETR, V2, P211, DOI DOI 10.1002/CEM.1180020306; Hoskuldsson A., 1996, PREDICTION METHODS S; Indahl UG, 1998, J CHEMOMETR, V12, P261, DOI 10.1002/(SICI)1099-128X(199807/08)12:4<261::AID-CEM513>3.3.CO;2-Q; ISO, 1993, GUID EXPR UNC; Jackson J. E., 1991, USER GUIDE PRINCIPAL; Kendall Maurice, 1983, ADV THEORY STAT, V3; Lira I., 2002, EVALUATING MEASUREME; Magnus J. R., 1988, MATRIX DIFFERENTIAL; Martens H., 1989, MULTIVARIATE CALIBRA; MARTENS H, 2001, J CHEMOMETR, V15, P413; Martinez A, 2000, CHEMOMETR INTELL LAB, V54, P61, DOI 10.1016/S0169-7439(00)00104-0; Martinez A, 2002, J CHEMOMETR, V16, P41, DOI 10.1002/cem.669; Martinez A, 2002, J CHEMOMETR, V16, P189, DOI 10.1002/cem.710; PHATAK A, 1993, ANAL CHIM ACTA, V277, P495, DOI 10.1016/0003-2670(93)80461-S; RIO FJ, 2001, J CHEMOMETR, V15, P773; Riu J, 1996, ANAL CHEM, V68, P1851, DOI 10.1021/ac951217s; Scheffe H., 1959, ANAL VARIANCE; Wentzell PD, 1997, ANAL CHEM, V69, P2299, DOI 10.1021/ac961029h; Wentzell PD, 1997, J CHEMOMETR, V11, P339, DOI 10.1002/(SICI)1099-128X(199707)11:4<339::AID-CEM476>3.0.CO;2-L; Wentzell PD, 1999, CHEMOMETR INTELL LAB, V45, P65, DOI 10.1016/S0169-7439(98)00090-2; Wold S, 2001, CHEMOMETR INTELL LAB, V58, P109, DOI 10.1016/S0169-7439(01)00155-1	35	8	8	JOHN WILEY & SONS LTD	CHICHESTER	THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND	0886-9383			J CHEMOMETR	J. Chemometr.	DEC	2004	18	12					526	536		10.1002/cem.897		11	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	934FK	WOS:000229692100002		
J	Gelman, A				Gelman, A			Exploratory data analysis for complex models	JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS			English	Article						Bayesian inference; bootstrap; graphs; multiple imputation; posterior predictive checks	GRAPHICAL METHODS; STATISTICS; REGRESSION	"Exploratory" and "confirmatory" data analysis can both be viewed as methods for comparing observed data to what Would be obtained tinder an implicit or explicit statistical model. For example, many of Tukey's methods can be interpreted as checks against hypothetical linear models and Poisson distributions. In more complex situations. Bayesian methods can be useful for constructing reference distributions for various plots that are useful in exploratory data analysis. This article proposes an approach to unify exploratory data analysis with more formal statistical methods based on probability models. These ideas are developed in the context of examples front fields including psychology. medicine. and social science.	Columbia Univ, Dept Stat, New York, NY 10027 USA; Columbia Univ, Dept Polit Sci, New York, NY 10027 USA	Gelman, A (reprint author), Columbia Univ, Dept Stat, New York, NY 10027 USA.	gelman@stat.columbia.edu					Atkinson A.C, 1985, PLOTS TRANSFORMATION; ATKINSON AC, 1981, BIOMETRIKA, V68, P13, DOI 10.1093/biomet/68.1.13; Bayarri M. J., 1998, BAYESIAN STAT, P53; BERKHOF J, 2002, POSTERIOR PREDICTIVE; Billard L, 2003, J AM STAT ASSOC, V98, P470, DOI 10.1198/016214503000242; Bryk A. S., 2002, HIERARCHICAL LINEAR; Buja A., 1988, DYNAMIC GRAPHICS STA, P277; Buja A., 1996, J COMPUTATIONAL GRAP, V5, P78, DOI 10.2307/1390754; BUJA A, 2003, CALIBRATION SIMULTAE; BUJA A, 1999, INFERENCE DATA VISUL; BUSH RR, 1955, STOCHASTIC MODELS LE, pCH11; Carlin B.P., 1996, BAYES EMPIRICAL BAYE; CHALONER K, 1988, BIOMETRIKA, V75, P651; Chambers J., 1983, GRAPHICAL METHODS DA; Chambers JM, 1998, PROGRAMMING DATA; Chambers JM, 1992, STAT MODELS S LONDON; Cleveland W. S., 1985, ELEMENTS GRAPHING DA; CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531; CLEVELAND WS, 1993, ENVISIONING INFORMAT; Denison D. G. T., 2002, BAYESIAN METHODS NON; Efron Bradley, 1993, INTRO BOOTSTRAP; Ehrenberg A. S. C, 1975, DATA REDUCTION ANAL; FINCH PD, 1979, BIOMETRIKA, V66, P195; FRIENDLY M, 2002, COMPUTATIONAL STAT D, V43, P509; GELFAND A. E., 1992, BAYESIAN STATISTICS, V4, P147; Gelman A, 1996, STAT SINICA, V6, P733; GELMAN A, 2003, INT STAT REV; GELMAN A, 1997, J AM STAT ASS; GELMAN A, 2002, BAG TRICKS; Gelman A, 2001, J ROY STAT SOC A STA, V164, P101, DOI 10.1111/1467-985X.00190; GELMAN A, 2000, APPL STAT, V49, P247; Gelman A, 1999, STAT MED, V18, P3221; Gelman A, 2002, AM STAT, V56, P121, DOI 10.1198/000313002317572790; Gelman A, 1995, BAYESIAN DATA ANAL; GELMAN A, IN PRESS BIOMETRICS; Gelman Andrew, 2004, J EMPIR LEGAL STUD, V1, P209, DOI 10.1111/j.1740-1461.2004.00007.x; GUTTMAN, 1967, J ROY STATIST SOC  B, V29, P83; Hastie T., 2002, ELEMENTS STAT LEARNI; Inselberg A., 1985, VISUAL COMPUT, V1, P69, DOI DOI 10.1007/BF01898350; LANDWEHR JM, 1984, J AM STAT ASSOC, V79, P61, DOI 10.2307/2288334; *MATHSOFT, 2000, S PLUS; MENG XL, 1994, ANN STAT, V22, P1142, DOI 10.1214/aos/1176325622; MILLER JJ, 1991, COMPUTING GRAPHICS S, P219; MORRIS CN, 1983, J AM STAT ASSOC, V78, P47, DOI 10.2307/2287098; *PROJ R, 2000, R PROJ STAT COMP; RIPLEY B.D., 1988, STAT INFERENCE SPATI; RUBIN DB, 1984, ANN STAT, V12, P1151, DOI 10.1214/aos/1176346785; Rubin DB, 1996, J AM STAT ASSOC, V91, P473; SCOTT DW, 1979, BIOMETRIKA, V66, P605, DOI 10.1093/biomet/66.3.605; SHEINER LB, 1997, J AM STAT ASS; SMITH AFM, 1993, J ROY STAT SOC B MET, V55, P3; Spiegelhalter D., 1994, BUGS BAYESIAN INFERE; STONE M, 1974, J R STAT SOC B, V36, P111; TUFTE ER, 1990, EVNISIONING INFORMAT; Tufte E.R., 1983, VISUAL DISPLAY QUANT; Tukey J.W., 1977, EXPLORATORY DATA ANA; TUKEY JW, 1972, STAT PAPERS HONOR G; VANBUUREN S, 2000, MICE MULTIVARIATE IM; Vansteelandt K, 1998, J PERS SOC PSYCHOL, V75, P751, DOI 10.1037/0022-3514.75.3.751; WAINER H, 2001, CHANCE, V14, P43; Wainer H, 1997, VISUAL REVELATIONS; WANG MP, 1997, STAT COMPUTING GRAPH, V51, P59; WEGMAN EJ, 1990, J AM STAT ASSOC, V85, P664, DOI 10.2307/2290001; WILDINSON L, 1999, GRAMMAR GRAPHICS; WILK MB, 1968, BIOMETRIKA, V55, P1	65	36	37	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	1061-8600			J COMPUT GRAPH STAT	J. Comput. Graph. Stat.	DEC	2004	13	4					755	779		10.1198/106186004X11435		25	Statistics & Probability	Mathematics	879SO	WOS:000225739400001		
J	Nason, M; Emerson, S; LeBlanc, M				Nason, M; Emerson, S; LeBlanc, M			CARTscans: A tool for visualizing complex models	JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS			English	Article						bagging; boosting; classification and regression trees; color coding; graphics; linear regression; random forests; visualization		We present CARTscans, a graphical tool that displays predicted values across. a four-dimensional subspace. We show how these plots are useful for understanding the structure and relationships between variables in a wide variety of models. including (but not limited to) regression trees, ensembles of trees, and linear regressions with varving degrees of interactions. In addition, the common visualization framework allows diverse complex models to be visually compared in a way that illuminates the similarities and differences in the underlying methods, facilitates the choice of a particular model structure, and provided a useful check for implausible predictions of future observations in regions With little or no data.	NIAID, Biostat Res Branch, Bethesda, MD 20892 USA; Univ Washington, Dept Biostat, Seattle, WA 98195 USA	Nason, M (reprint author), NIAID, Biostat Res Branch, 6700B Rockledge Dr,MSC 7609, Bethesda, MD 20892 USA.	mnason@niaid.nih.gov					Becker RA, 1996, J COMPUTATIONAL GRAP, V5, P123, DOI DOI 10.2307/1390777; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brewer C.A., 1999, P SECT STAT GRAPH AM, P55; Chipman HA, 1998, J AM STAT ASSOC, V93, P935, DOI 10.2307/2669832; Efron Bradley, 1993, INTRO BOOTSTRAP; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Hastie T., 2001, ELEMENTS STAT LEARNI; Rosner B., 1990, FUNDAMENTALS BIOSTAT; Swayne DF, 1998, J COMPUT GRAPH STAT, V7, P113, DOI 10.2307/1390772; Tukey PA, 1981, INTERPRETING MULTIVA, P189; URBANEK S, 2002, P 14 C COMP STAT, P303	13	4	4	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	1061-8600			J COMPUT GRAPH STAT	J. Comput. Graph. Stat.	DEC	2004	13	4					807	825		10.1198/106186004X11417		19	Statistics & Probability	Mathematics	879SO	WOS:000225739400005		
J	Hennig, C				Hennig, C			Asymmetric linear dimension reduction for classification	JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS			English	Article						canonical coordinates; cluster validation; discriminant coordinates; MCD estimator; nearest neighbor; projection pursuit; quasars; visualization	DISCRIMINANT-ANALYSIS; PROJECTION PURSUIT; HAMBURG/ESO SURVEY; CLUSTERS	This article discusses methods to project a p-dimensional dataset with classified points from s known classes onto a lower dimensional hyperplane so that the classes appear optimally separated. Such projections can be used, for example, for data visualization and classification in lower dimensions. New methods, which are asymmetric with respect to the numbering of the groups, are introduced for s = 2. They aim at generating data projections where one class is homogeneous and optimally separated from the other class, while the other class may be widespread. They are compared to classical discriminant coordinates and other symmetric methods from the literature by a simulation study, the application to a 12-dimensional dataset of 74,159 spectra of stellar objects, and to land snails distribution data. Neighborhood-based methods are also investigated, where local information about the separation of the classes is averaged. The use of robust MCD-covariance matrices is suggested.	Univ Hamburg, Fachbereich Math, D-20146 Hamburg, Germany	Hennig, C (reprint author), Univ Hamburg, Fachbereich Math, Bundesstr 55, D-20146 Hamburg, Germany.	hennig@math.uni-hamburg.de					ASIMOV D, 1985, SIAM J SCI STAT COMP, V6, P128, DOI 10.1137/0906011; Buja A., 1996, J COMPUTATIONAL GRAP, V5, P78, DOI 10.2307/1390754; CARR DB, 1996, 129 G MASON U CTR CO; Christlieb N, 2001, ASTRON ASTROPHYS, V366, P898, DOI 10.1051/0004-6361:20000269; Cleveland WS, 1988, DYNAMIC GRAPHICS STA; COOK D., 1995, J COMPUTATIONAL GRAP, V4, P155, DOI 10.2307/1390844; FEIGELSON ED, 2003, P SCMA, V3; Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578; Fukunaga K, 1990, INTRO STAT PATTERN R; Gnanadesikan R, 1977, METHODS STAT DATA AN; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hawkins DM, 1997, J AM STAT ASSOC, V92, P136, DOI 10.2307/2291457; Hennig C, 2004, COMPUT STAT DATA AN, V45, P875, DOI 10.1016/S0167-9473(03)00091-4; Hennig C, 2002, COMPUT STAT DATA AN, V40, P723, DOI 10.1016/S0167-9473(02)00077-4; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; HURLEY C, 1990, SIAM J SCI STAT COMP, V11, P1193, DOI 10.1137/0911068; KIERS HAL, 2000, DATA ANAL, P207; KRZANOWSKI WJ, 1995, J CHEMOMETR, V9, P509, DOI 10.1002/cem.1180090608; Pires AM, 2003, DEVELOPMENTS IN ROBUST STATISTICS, P317; POLZEHL J, 1995, COMPUT STAT DATA AN, V20, P141, DOI 10.1016/0167-9473(94)00035-H; Rao C. R., 1993, HDB STAT, V9; Rao C R, 1952, ADV STAT METHODS BIO; Ripley BD, 1996, PATTERN RECOGNITION; Rohl MC, 1999, ST CLASS DAT ANAL, P252; ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718; Rousseeuw PJ, 1999, TECHNOMETRICS, V41, P212, DOI 10.2307/1270566; Seber G. A. F., 1984, MULTIVARIATE OBSERVA; Strecker U, 2002, CYBIUM, V26, P301; WEGMAN EJ, 1993, HDB STAT; WEGMAN EJ, 1991, COMP SCI STAT P 22 S, P127; Wilhelm AFX, 1999, COMPUTATION STAT, V14, P109; Wisotzki L, 2000, ASTRON ASTROPHYS, V358, P77; YOUNG DM, 1987, J STAT PLAN INFER, V17, P307, DOI 10.1016/0378-3758(87)90122-4	34	9	9	AMER STATISTICAL ASSOC	ALEXANDRIA	732 N WASHINGTON ST, ALEXANDRIA, VA 22314-1943 USA	1061-8600	1537-2715		J COMPUT GRAPH STAT	J. Comput. Graph. Stat.	DEC	2004	13	4					930	945		10.1198/106186004X12740		16	Statistics & Probability	Mathematics	879SO	WOS:000225739400011		
J	Bhattacharyya, C; Grate, LR; Jordan, MI; El Ghaoui, L; Mian, IS				Bhattacharyya, C; Grate, LR; Jordan, MI; El Ghaoui, L; Mian, IS			Robust sparse hyperplane classifiers: Application to uncertain molecular profiling data	JOURNAL OF COMPUTATIONAL BIOLOGY			English	Article						robust sparse hyperplanes; second-order cone program; linear programming; breast cancer; molecular profiling; two-class high-dimensional data	GENE-EXPRESSION SIGNATURES; CLASSIFICATION; ADENOCARCINOMA; CARCINOMAS; CANCER; SUBCLASSES; PREDICTION; LUNG	Molecular profiling studies can generate abundance measurements for thousands of transcripts, proteins, metabolites, or other species in, for example, normal and tumor tissue samples. Treating such measurements as features and the samples as labeled data points, sparse hyperplanes provide a statistical methodology for classifying data points into one of two categories ( classification and prediction) and defining a small subset of discriminatory features ( relevant feature identification). However, this and other extant classification methods address only implicitly the issue of observed data being a combination of underlying signals and noise. Recently, robust optimization has emerged as a powerful framework for handling uncertain data explicitly. Here, ideas from this field are exploited to develop robust sparse hyperplanes, i.e., classification and relevant feature identification algorithms that are resilient to variation in the data. Specifically, each data point is associated with an explicit data uncertainty model in the form of an ellipsoid parameterized by a center and covariance matrix. The task of learning a robust sparse hyperplane from such data is formulated as a second order cone program (SOCP). Gaussian and distribution-free data uncertainty models are shown to yield SOCPs that are equivalent to the SCOP based on ellipsoidal uncertainty. The real-world utility of robust sparse hyperplanes is demonstrated via retrospective analysis of breast cancer related transcript profiles. Data-dependent heuristics are used to compute the parameters of each ellipsoidal data uncertainty model. The generalization performance of a specific implementation, designated "robust Liknon," is better than its nominal counterpart. Finally, the strengths and limitations of robust sparse hyperplanes are discussed.	Univ Calif Berkeley, Dept EECS, Berkeley, CA 94720 USA; Univ Calif Berkeley, Lawrence Berkeley Lab, Div Life Sci, Berkeley, CA 94720 USA; Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA	Bhattacharyya, C (reprint author), Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India.	chiru@csa.iisc.ernet.in					Amaldi E, 1998, THEOR COMPUT SCI, V209, P237, DOI 10.1016/S0304-3975(97)00115-1; Bennet K.P, 2000, SIGKDD EXPLORATIONS, V2, P1; Bennett KP, 1999, ADV NEUR IN, V11, P368; BENTAL A, 2000, ROBUST SEMIDEFINITE; Bhattacharjee A, 2001, P NATL ACAD SCI USA, V98, P13790, DOI 10.1073/pnas.191502998; Bhattacharyya C, 2003, SIGNAL PROCESS, V83, P729, DOI 10.1016/S0165-1684(02)00474-7; Boyd S., 2003, CONVEX OPTIMIZATION; Chow ML, 2001, PHYSIOL GENOMICS, V5, P99; Cristianini N., 2000, SUPPORT VECTOR MACHI; DHANESEKARAN S, 2001, NATURE, V432, P822; Donoho D. L., 1999, UNCERTAINTY PRINCIPL; Garber ME, 2001, P NATL ACAD SCI USA, V98, P13784, DOI 10.1073/pnas.241500798; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; GRAEPEL T, 1999, P 9 INT C ART NEUR N, V470, P304; GRATE L, 2002, WORKSH ALG BIOINF WA, P1; Grate LR, 2003, MECH AGEING DEV, V124, P109, DOI 10.1016/S0047-6374(02)00174-4; HASTIE T., 2000, ELEMENTS STAT LEARNI; Hedenfalk I, 2001, NEW ENGL J MED, V344, P539, DOI 10.1056/NEJM200102223440801; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Kim S, 2002, J COMPUT BIOL, V9, P127, DOI 10.1089/10665270252833226; Lanckriet G. R. G., 2002, J MACHINE LEARNING R, V3, P555; LIOTTA L, 2001, JAMA-J AM MED ASSOC, V14, P2211; MARSHALL AW, 1960, ANN MATH STAT, V31, P1001, DOI 10.1214/aoms/1177705673; Notterman DA, 2001, CANCER RES, V61, P3124; Novak JP, 2002, GENOMICS, V79, P104, DOI 10.1006/geno.2001.6675; POPESCU I, 2001, 62 TB INSEAD; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; SMOLA A, 1999, NEURAL INFORMATION P, V11; Sorlie T, 2001, P NATL ACAD SCI USA, V98, P10869, DOI 10.1073/pnas.191367098; Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766; Su AI, 2001, CANCER RES, V61, P7388; Weston J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753751	32	11	12	MARY ANN LIEBERT INC	LARCHMONT	2 MADISON AVENUE, LARCHMONT, NY 10538 USA	1066-5277			J COMPUT BIOL	J. Comput. Biol.	DEC	2004	11	6					1073	1089		10.1089/cmb.2004.11.1073		17	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	893WD	WOS:000226750300005	15662199	
J	Kane, M; Holt, J; Allen, B				Kane, M; Holt, J; Allen, B			Results concerning the generalized partially linear single-index model	JOURNAL OF STATISTICAL COMPUTATION AND SIMULATION			English	Article						generalized linear models; non-parametric regression; single-index models		The central topic of this article is the estimation of parameters of the generalized partially linear single-index model (GPLSIM). Two numerical optimization procedures are presented and an S-plus program based on these procedures is compared to a program by Wand in a simulation setting. The results from these simulations indicate that the estimates for the new procedures are as good, if not better, than Wand's. Also, this program is much more flexible than Wand's since it can handle more general models. Other simulations are also conducted. The first compares the effects of using linear interpolation versus spline interpolation in an optimization procedure. The results indicate that by using spline interpolation one gets more stable estimates at a cost of increased computational time. A second simulation was conducted to assess the performance of a method for estimating the variance of alpha. A third set of simulations is carried out to determine the best criterion for testing that one of the elements of alpha is equal to zero. The GPLSIM is applied to a water quality data set and the results indicate an interesting relationship between gastrointestinal illness and turbidity (cloudiness) of drinking water.	Univ Toronto, Dept Stat, Toronto, ON M5S 3G3, Canada; Univ Guelph, Dept Math & Stat, Guelph, ON N1G 2W1, Canada	Kane, M (reprint author), Univ Toronto, Dept Stat, Toronto, ON M5S 3G3, Canada.	kane@utstat.toronto.edu					AITCHISON J, 1960, J ROY STAT SOC B, V22, P154; ARAMINI J, 2002, CANADIAN COMMUNICABL, P2; Carroll RJ, 1997, J AM STAT ASSOC, V92, P477, DOI 10.1080/01621459.1997.10474001; FRIEDMAN JH, 1981, J AM STAT ASSOC, V76, P817, DOI 10.2307/2287576; HARDLE W, 1993, ANN STAT, V21, P157, DOI 10.1214/aos/1176349020; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T, 1990, GEN ADDITIVE MODELS; Hertz J., 1991, INTRO THEORY NEURAL; Horowitz J. L., 1998, SEMIPARAMETRIC METHO; KANE M, 2002, THESIS U GUELPH; Lingjaerde O. C., 1999, SIAM Journal on Scientific Computing, V20; MANGAL B, 2000, TRANSITIONAL GEN ADD; McCullagh P., 1989, GEN LINEAR MODELS; ROOSEN CB, 1994, J COMPUTA GRAPHICAL, V3, P235, DOI 10.2307/1390909; SMALE G, 2001, THESIS U GUELPH; WAND MP, 1998, GPLSIM 1 1; WEISBERG S, 1994, ANN STAT, V22, P1674, DOI 10.1214/aos/1176325749	17	0	0	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0094-9655			J STAT COMPUT SIM	J. Stat. Comput. Simul.	DEC	2004	74	12					897	912		10.1080/00949650410001653133		16	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	855MD	WOS:000223976500004		
J	Binley, JA; Wrin, T; Korber, B; Zwick, MB; Wang, M; Chappey, C; Stiegler, G; Kunert, R; Zolla-Pazner, S; Katinger, H; Petropoulos, CJ; Burton, DR				Binley, JA; Wrin, T; Korber, B; Zwick, MB; Wang, M; Chappey, C; Stiegler, G; Kunert, R; Zolla-Pazner, S; Katinger, H; Petropoulos, CJ; Burton, DR			Comprehensive cross-clade neutralization analysis of a panel of anti-human immunodeficiency virus type 1 monoclonal antibodies	JOURNAL OF VIROLOGY			English	Review							CD4 BINDING-SITE; VACCINE EVALUATION SITES; HIV TYPE-1; ENVELOPE GLYCOPROTEIN; SYNERGISTIC NEUTRALIZATION; V3 LOOP; SUBTYPE-C; IN-VITRO; INTERNATIONAL COLLABORATION; BROAD NEUTRALIZATION	Broadly neutralizing monoclonal antibodies (MAbs) are potentially important tools in human immunodeficiency virus type 1 (HIV-1) vaccine design. A few rare MAbs have been intensively studied, but we still have a limited appreciation of their neutralization breadth. Using a pseudovirus assay, we evaluated MAbs from clade B-infected donors and a clade B HIV+ plasma against 93 viruses from diverse backgrounds. Anti-gp120 MAbs exhibited greater activity against clade B than non-B viruses, whereas anti-gp4l MAbs exhibited broad interclade activity. Unexpectedly, MAb 4E10 (directed against the C terminus of the gp41 ectodomain) neutralized all 90 viruses with moderate potency. MAb 2F5 (directed against an epitope adjacent to that of 4E10) neutralized 67% of isolates, but none from clade C. Anti-gp120 MAb b12 (directed against an epitope overlapping the CD4 binding site) neutralized 50% of viruses, including some from almost every clade. 2G12 (directed against a high-mannose epitope on gp120) neutralized 41% of the viruses, but none from clades C or E. MAbs to the gp120 V3 loop, including 447-52D, neutralized a subset of clade B viruses (up to 45%) but infrequently neutralized other clades (less than or equal to7%). MAbs b6 (directed against the CD4 binding site) and X5 (directed against a CD4-induced epitope of gp120) neutralized only sensitive primary clade B viruses. The HIV+ plasma neutralized 70% of the viruses, including some from all major clades. Further analysis revealed five neutralizing immunotypes that were somewhat associated with clades. As well as the significance for vaccine design, our data have implications for passive-immunization studies in countries where clade C viruses are common, given that only MAbs b12 and 4E10 were effective against viruses from this clade.	Scripps Res Inst, Dept Immunol, La Jolla, CA 92037 USA; Scripps Res Inst, Dept Mol Biol, La Jolla, CA 92037 USA; ViroLogic Inc, San Francisco, CA USA; Los Alamos Natl Lab, Div Theory, Los Alamos, NM USA; Santa Fe Inst, Santa Fe, NM 87501 USA; Univ Agr Sci, Inst Appl Microbiol, Vienna, Austria; NYU, Dept Pathol, Med Ctr, New York, NY 10016 USA; VA Med Ctr, Res Ctr AIDS & HIV Infect, New York, NY USA	Burton, DR (reprint author), Scripps Res Inst, Dept Immunol, 10550 N Torrey Pines Rd,IMM2, La Jolla, CA 92037 USA.	burton@scripps.edu					Abrahamyan LG, 2003, J VIROL, V77, P5829, DOI 10.1128/JVI.77.10.5829-5836.2003; ALLAWAY GP, 1993, AIDS RES HUM RETROV, V9, P581, DOI 10.1089/aid.1993.9.581; Baba TW, 2000, NAT MED, V6, P200; BARBAS CF, 1992, P NATL ACAD SCI USA, V89, P9339; Barin F, 2004, J INFECT DIS, V189, P322, DOI 10.1086/380099; Barnet SW, 2001, J VIROL, V75, P5526, DOI 10.1128/JVI.75.12.5526-5540.2001; Beaumont T, 2004, J VIROL, V78, P5651, DOI 10.1128/JVI.78.11.5651-5657.2004; Beddows S, 1998, J GEN VIROL, V79, P77; Beirnaert E, 2000, J MED VIROL, V62, P14, DOI 10.1002/1096-9071(200009)62:1<14::AID-JMV3>3.0.CO;2-L; Binley JM, 2003, J VIROL, V77, P5678, DOI 10.1128/JVI.77.10.5678-5684.2003; Binley JM, 1997, J VIROL, V71, P2799; BOUHABIB DC, 1994, J VIROL, V68, P6006; BUCHACHER A, 1994, AIDS RES HUM RETROV, V10, P359, DOI 10.1089/aid.1994.10.359; BUCHBINDER A, 1992, AIDS RES HUM RETROV, V8, P1395; Bures R, 2000, AIDS RES HUM RETROV, V16, P2019, DOI 10.1089/088922200750054756; Bures R, 2002, J VIROL, V76, P2233, DOI 10.1128/JVI.76.5.2233-2244.2002; Burton DR, 1997, P NATL ACAD SCI USA, V94, P10018, DOI 10.1073/pnas.94.19.10018; Burton DR, 1997, AIDS, V11, pS87; BURTON DR, 1991, P NATL ACAD SCI USA, V88, P10134, DOI 10.1073/pnas.88.22.10134; Burton DR, 2002, NAT REV IMMUNOL, V2, P706, DOI 10.1038/nri891; BURTON DR, 1994, SCIENCE, V266, P1024, DOI 10.1126/science.7973652; Calarese DA, 2003, SCIENCE, V300, P2065, DOI 10.1126/science.1083182; Chen MS, 1997, AIDS RES HUM RETROV, V13, P743, DOI 10.1089/aid.1997.13.743; CHENGMAYER C, 1990, J VIROL, V64, P4390; Cleghorn FR, 2000, P NATL ACAD SCI USA, V97, P10532, DOI 10.1073/pnas.97.19.10532; Coeffier E, 2000, VACCINE, V19, P684, DOI 10.1016/S0264-410X(00)00267-X; CONLEY AJ, 1994, P NATL ACAD SCI USA, V91, P3348, DOI 10.1073/pnas.91.8.3348; CONLEY AJ, 1994, J VIROL, V68, P6994; Connor RI, 1998, J VIROL, V72, P1552; Cormier EG, 2002, J VIROL, V76, P8953, DOI 10.1128/JVI.76.17.8953-8957.2002; Donners H, 2003, VACCINE, V22, P104, DOI 10.1016/S0264-410X(03)00530-9; DSOUZA MP, 1991, AIDS, V5, P1061, DOI 10.1097/00002030-199109000-00001; DSOUZA MP, 1995, AIDS, V9, P867, DOI 10.1097/00002030-199508000-00006; DSOUZA MP, 1993, AIDS RES HUM RETROV, V9, P415, DOI 10.1089/aid.1993.9.415; DSouza MP, 1997, J INFECT DIS, V175, P1056; Earl PL, 2001, J VIROL, V75, P645, DOI 10.1128/JVI.75.2.645-653.2001; EARL PL, 1994, J VIROL, V68, P3015; Eckhart L, 1996, J GEN VIROL, V77, P2001, DOI 10.1099/0022-1317-77-9-2001; Gao F, 1996, J VIROL, V70, P1651; GAO F, 1994, AIDS RES HUM RETROV, V10, P1359, DOI 10.1089/aid.1994.10.1359; Gaschen B, 2002, SCIENCE, V296, P2354, DOI 10.1126/science.1070441; GASCHEN B, 1999, HUMAN RETROVIRUSES A, P594; Gauduin MC, 1997, NAT MED, V3, P1389, DOI 10.1038/nm1297-1389; Gorny MK, 1997, J IMMUNOL, V159, P5114; Gorny MK, 2002, J VIROL, V76, P9035, DOI 10.1128/JVI.76.18.9035-9045.2002; GORNY MK, 1992, J VIROL, V66, P7538; Gorny MK, 2004, J VIROL, V78, P2394, DOI 10.1128/JVI.78.5.2394-2404.2004; GORNY MK, 1994, J VIROL, V68, P8312; GORNY MK, 1993, J IMMUNOL, V150, P635; Hastie T, 2001, ELEMENTS STAT LEARNI, P453; Heyndrickx L, 2000, J VIROL, V74, P363; Hill CM, 1997, J VIROL, V71, P6296; HWANG SS, 1992, SCIENCE, V257, P535, DOI 10.1126/science.1636088; Ihaka R, 2005, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; JELLIS CL, 1993, GENE, V137, P63, DOI 10.1016/0378-1119(93)90252-X; Kessler JA, 1997, AIDS RES HUM RETROV, V13, P575, DOI 10.1089/aid.1997.13.575; Kitabwalla M, 2003, AIDS RES HUM RETROV, V19, P125, DOI 10.1089/088922203762688630; Kostrikis LG, 1996, J VIROL, V70, P445; Kostrikis LG, 1996, AIDS RES HUM RETROV, V12, P1667, DOI 10.1089/aid.1996.12.1667; Kuiken C, 2000, AM J EPIDEMIOL, V152, P814, DOI 10.1093/aje/152.9.814; Kuiken CL, 1996, AIDS, V10, P31, DOI 10.1097/00002030-199601000-00005; Kunert R, 1998, AIDS RES HUM RETROV, V14, P1115, DOI 10.1089/aid.1998.14.1115; Kwong PD, 2002, NATURE, V420, P678, DOI 10.1038/nature01188; Kwong PD, 1998, NATURE, V393, P648, DOI 10.1038/31405; LAAL S, 1994, J VIROL, V68, P4001; Labrijn AF, 2003, J VIROL, V77, P10557, DOI 10.1128/JVI.77.19.10557-10565.2003; Li A, 1997, AIDS RES HUM RETROV, V13, P647, DOI 10.1089/aid.1997.13.647; Li A, 1998, J VIROL, V72, P3235; Liang XP, 1999, VACCINE, V17, P2862, DOI 10.1016/S0264-410X(99)00125-5; Lole KS, 1999, J VIROL, V73, P152; LOUISIRIROTCHANAKU, 1998, J ACQ IMMUN DEF SYND, V19, P315; MARKOWITZ MT, 2003, AIDS VACCINE; Mascola JR, 2000, NAT MED, V6, P207, DOI 10.1038/72318; Mascola JR, 1997, J VIROL, V71, P7198; Mascola JR, 1996, J INFECT DIS, V173, P340; Mascola JR, 1996, AIDS RES HUM RETROV, V12, P1319, DOI 10.1089/aid.1996.12.1319; Mascola JR, 2002, J VIROL, V76, P4810, DOI 10.1128/JVI.76.10.4810-4821.2002; Mascola JR, 1999, J VIROL, V73, P4009; Mascola JR, 2002, VACCINE, V20, P1922, DOI 10.1016/S0264-410X(02)00068-3; McCutchan FE, 1996, J VIROL, V70, P3331; McCutchan FE, 1999, VIROLOGY, V254, P226, DOI 10.1006/viro.1998.9505; McCutchan FE, 2000, AIDS, V14, pS31; MCKEATING JA, 1992, VIROLOGY, V191, P732, DOI 10.1016/0042-6822(92)90249-O; McMichael AJ, 2003, NAT MED, V9, P874, DOI 10.1038/nm0703-874; Mochizuki N, 1999, AIDS RES HUM RETROV, V15, P1321, DOI 10.1089/088922299310223; MONTEFIORI DC, 1993, J CLIN INVEST, V92, P840, DOI 10.1172/JCI116658; Moog C, 1997, J VIROL, V71, P3734; Moore JP, 2001, J VIROL, V75, P5721, DOI 10.1128/JVI.75.13.5721-5729.2001; MOORE JP, 1994, J VIROL, V68, P8350; MOORE JP, 1994, J VIROL, V68, P469; MOORE JP, 1990, SCIENCE, V250, P1139, DOI 10.1126/science.2251501; Moore JP, 1996, J VIROL, V70, P427; Moore JP, 1996, J VIROL, V70, P1863; MOORE RC, 1995, LIBR J, V120, P120; Moulard M, 2002, P NATL ACAD SCI USA, V99, P6913, DOI 10.1073/pnas.102562599; MUSTER T, 1995, J VIROL, V69, P6678; MUSTER T, 1994, J VIROL, V68, P4031; MUSTER T, 1993, J VIROL, V67, P6642; Nadas A, 2004, AIDS RES HUM RETROV, V20, P55, DOI 10.1089/088922204322749503; Nagashima KA, 2001, J INFECT DIS, V183, P1121, DOI 10.1086/319284; Nyambi PN, 1996, J VIROL, V70, P6235; Nyambi PN, 2000, J VIROL, V74, P10670, DOI 10.1128/JVI.74.22.10670-10680.2000; OBRIEN WA, 1990, NATURE, V348, P69, DOI 10.1038/348069a0; Painter SL, 2003, J VIROL, V77, P8448, DOI 10.1128/JVI.77.15.848-8461.2003; Park EJ, 1998, J VIROL, V72, P7099; Parker CE, 2001, J VIROL, V75, P10906, DOI 10.1128/JVI.75.22.10906-10911.2001; Parren PWHI, 1999, AIDS, V13, pS137; Parren PWHI, 1998, J VIROL, V72, P10270; Parren PWHI, 2001, J VIROL, V75, P8340, DOI 10.1128/JVI.75.17.8340-8347.2001; Petropoulos CJ, 2000, ANTIMICROB AGENTS CH, V44, P920, DOI 10.1128/AAC.44.4.920-928.2000; Pitisuttithum P, 2003, J INFECT DIS, V188, P219, DOI 10.1086/376506; Poignard P, 1996, J EXP MED, V183, P473, DOI 10.1084/jem.183.2.473; Pugach P, 2004, VIROLOGY, V321, P8, DOI 10.1016/j.virol.2003.12.012; PURTSCHER M, 1994, AIDS RES HUM RETROV, V10, P1651, DOI 10.1089/aid.1994.10.1651; Purtscher M, 1996, AIDS, V10, P587, DOI 10.1097/00002030-199606000-00003; Quinones-Mateu ME, 2000, J VIROL, V74, P9222, DOI 10.1128/JVI.74.19.9222-9233.2000; RATNER L, 1985, NATURE, V313, P277, DOI 10.1038/313277a0; Reeves JD, 2002, P NATL ACAD SCI USA, V99, P16249, DOI 10.1073/pnas.252469399; Richardson TM, 1996, J VIROL, V70, P753; Richman DD, 2003, P NATL ACAD SCI USA, V100, P4144, DOI 10.1073/pnas.0630530100; ROBEN P, 1994, J VIROL, V68, P4821; Robertson DL, 2000, SCIENCE, V288, P55; Rodenburg CM, 2001, AIDS RES HUM RETROV, V17, P161, DOI 10.1089/08892220150217247; Ruprecht RM, 2003, VACCINE, V21, P3370, DOI 10.1016/S0264-410X(03)00335-9; SALMINEN MO, 1995, VIROLOGY, V213, P80, DOI 10.1006/viro.1995.1548; Sanders RW, 2002, J VIROL, V76, P7293, DOI 10.1128/JVI.76.14.7293-7305.2002; Saphire EO, 2001, SCIENCE, V293, P1155, DOI 10.1126/science.1061692; SAWYER LSW, 1994, J VIROL, V68, P1342; Scanlan CN, 2002, J VIROL, V76, P7306, DOI 10.1128/JVI.76.14.7306-7321.2002; Shankarappa R, 1999, J VIROL, V73, P10489; Sharon M, 2003, STRUCTURE, V11, P225, DOI 10.1016/S0969-2126(03)00011-X; Srivastava IK, 2003, J VIROL, V77, P11244, DOI 10.1128/JVI.77.20.11244-11259.2003; Stanfield RL, 2004, STRUCTURE, V12, P193, DOI 10.1016/j.str.2004.01.003; Stiegler G, 2001, AIDS RES HUM RETROV, V17, P1757, DOI 10.1089/08892220152741450; THALI M, 1992, J ACQ IMMUN DEF SYND, V5, P591; TILLEY SA, 1992, AIDS RES HUM RETROV, V8, P461, DOI 10.1089/aid.1992.8.461; Trkola A, 1996, NATURE, V384, P184, DOI 10.1038/384184a0; TRKOLA A, 1995, J VIROL, V69, P6609; Trkola A, 1996, J VIROL, V70, P1100; VANCOTT TC, 1995, J IMMUNOL METHODS, V183, P103, DOI 10.1016/0022-1759(95)00038-C; Verrier F, 2000, J VIROL, V74, P10025, DOI 10.1128/JVI.74.21.10025-10033.2000; Verrier F, 2001, J VIROL, V75, P9177, DOI 10.1128/JVI.75.19.9177-9186.2001; VijhWarrier S, 1996, J VIROL, V70, P4466; WARRIER SV, 1994, J VIROL, V68, P5636; Weber J, 1996, J VIROL, V70, P7827; Wei XP, 2003, NATURE, V422, P307, DOI 10.1038/nature01470; OSMANOV S, 1994, AIDS RES HUM RETROV, V10, P1327, DOI 10.1089/aid.1994.10.1327; Wu LJ, 1996, NATURE, V384, P179, DOI 10.1038/384179a0; Xu WD, 2001, J HUMAN VIROL, V4, P55; ZHANG MY, IN PRESS GLYCOBIOLOG; Zinkernagel RM, 2001, ADV IMMUNOL, V79, P1, DOI 10.1016/S0065-2776(01)79001-3; Zolla-Pazner S, 1999, J VIROL, V73, P4042; ZOLLAPAZNER S, 1995, J VIROL, V69, P3807; Zwick MB, 2001, J VIROL, V75, P10892, DOI 10.1128/JVI.75.22.10892-10905.2001; Zwick MB, 2001, J VIROL, V75, P12198, DOI 10.1128/JVI.75.24.12198-12208.2001	155	484	502	AMER SOC MICROBIOLOGY	WASHINGTON	1752 N ST NW, WASHINGTON, DC 20036-2904 USA	0022-538X			J VIROL	J. Virol.	DEC	2004	78	23					13232	13252		10.1128/JVI.78.23.13232-13252.2004		21	Virology	Virology	870VT	WOS:000225087500051	15542675	
J	Heiser, WJ				Heiser, WJ			Geometric representation of association between categories	PSYCHOMETRIKA			English	Editorial Material						categorical data; simplex; triangular plot; paired comparisons; rank orders; permutation polytope; center of gravity; BTL model; Rasch model; inertia; association model; variation; multidimensional unfolding; biplot; multinomial response model; loglinear model; forced classification; classification tree	LATENT TRAIT MODEL; CONTINGENCY-TABLES; RANKING MODELS; SPATIAL REPRESENTATION; POLYTOMOUS RESPONSES; UNFOLDING MODEL; BINARY CHOICE; PREFERENCES	Categories can be counted, rated, or ranked, but they cannot be measured. Likewise, persons or individuals can be counted, rated, or ranked, but they cannot be measured either. Nevertheless, psychology has realized early on that it can take an indirect road to measurement: What can be measured is the strength of association between categories in samples or populations, and what can be quantitatively compared are counts, ratings, or rankings made under different circumstances, or originating from different persons. The strong demand for quantitative analysis of categorical data has thus created a variety of statistical methods, with substantial contributions from psychometrics and sociometrics. What is the common basis of these methods dealing with categories? The basic element they share is that the sample space has a special geometry, in which categories (or persons) are point masses forming a simplex, while distributions of counts or profiles of ratings are centers of gravity, which are also point masses. Rankings form a discrete subset in the interior of the simplex, known as the permutation polytope, and paired comparisons form another subset on the edges of the simplex. Distances between point masses form the basic tool of analysis. The paper gives some history of major concepts, which naturally leads to a new concept: the shadow point. It is then shown how loglinear models, Luce and Rasch models, unfolding models, correspondence analysis and homogeneity analysis, forced classification and classification trees, as well as other models and methods, fit into this particular geometrical framework.	Leiden Univ, Dept Psychol, NL-2300 RB Leiden, Netherlands	Heiser, WJ (reprint author), Leiden Univ, Dept Psychol, POB 9555, NL-2300 RB Leiden, Netherlands.	Heiser@fsw.leidenuniv.nl					AGRESTA A, 1990, CATEGORICAL DATA ANA; AICHISON J, 2002, APPL STAT, V51, P375; Andrich D, 1995, APPL PSYCH MEAS, V19, P269, DOI 10.1177/014662169501900306; ANDRICH D, 1988, APPL PSYCH MEAS, V12, P33, DOI 10.1177/014662168801200105; Andrich D, 1996, BRIT J MATH STAT PSY, V49, P347; ANGLIN MD, 1981, AM J DRUG ALCOHOL AB, V8, P153, DOI 10.3109/00952998108999122; BARTHOLOMEW DJ, 1980, J ROY STAT SOC B MET, V42, P293; Benzecri J.-P., 1992, CORRESPONDENCE ANAL; BENZECRI JP, 1973, AN DONNEES LANAN COR, V2; BLASIUS J, 1998, VIZUALIZATION CATEGO; BOCKENHOLT U, 1993, PROBABILITY MODELS S, P157; Bockenholt U, 2002, J MATH PSYCHOL, V46, P300, DOI 10.1006/jmps.2001.1389; Boring EG, 1942, SENSATION PERCEPTION; BRADLEY RA, 1952, BIOMETRIKA, V39, P324, DOI 10.1093/biomet/39.3-4.324; Breiman L., 1984, CLASSIFICATION REGRE; BUSING FMT, 2005, IN PRESS PSYCHOMETRI, P70; CLIFF N, 1988, APPL PSYCH MEAS, V12, P83, DOI 10.1177/014662168801200108; COHEN A, 1983, STATISTICIAN, V32, P361, DOI 10.2307/2987538; COHEN A, 1980, ANAL RANKING DATA; COOMBS CH, 1950, PSYCHOL REV, V57, P145, DOI 10.1037/h0060984; Coombs C.H., 1964, THEORY DATA; Cox DR, 1970, ANAL BINARY DATA; COXETER HSM, 1973, REGULAR POLTOPES; Critchlow D. E., 1985, METRIC METHODS ANAL; DANIELS HE, 1950, J ROY STAT SOC B, V12, P171; DELBEKE L, 1968, CONSTRUCTION PREFERE; DEROOIJ M, 2005, IN PRESS PSYCHOMETRI, V70; DESARBO WS, 1989, PSYCHOMETRIKA, V54, P105, DOI 10.1007/BF02294452; DESARBO WS, 1986, APPL PSYCH MEAS, V10, P247, DOI 10.1177/014662168601000304; DESARBO WS, 1984, J CLASSIF, V1, P147, DOI 10.1007/BF01890122; DESOETE G, 1993, PSYCHOMETRIKA, V58, P545; DIJKSTERHUIS EJ, 1987, ARCHLNEDES; DINCONIS P, 1982, GROUP THEORY STAT; DINCONIS P, 1988, GROUP REPRESENTATION; EMBRETSON S, 1984, PSYCHOMETRIKA, V49, P175, DOI 10.1007/BF02294171; ESCHER BG, 1934, METHODS GRAFISCHE VO; FEIGIN PD, 1978, J R STAT SOC B, V40, P203; FIENBERG SE, 1976, BIOMETRIKA, V63, P245, DOI 10.1093/biomet/63.2.245; FIENBERG SE, 1970, J AM STAT ASSOC, V65, P694, DOI 10.2307/2284580; FIENBERG SE, 1973, J AM STAT ASSOC, V68, P683, DOI 10.2307/2284799; FIENBERG SE, 1970, ANN MATH STAT, V41, P907, DOI 10.1214/aoms/1177696968; FISCHER GH, 1973, ACTA PSYCHOL, V37, P359, DOI 10.1016/0001-6918(73)90003-6; Fligner MA, 1993, PROBABILITY MODELS S; FLIGNER MA, 1986, J ROY STAT SOC B MET, V48, P359; FLIGNER MA, 1988, J AM STAT ASSOC, V83, P892, DOI 10.2307/2289322; Galton F, 1888, P ROYAL SOC, V45, P135, DOI 10.1098/rspl.1888.0082; Gibbs JW, 1876, T CONNECTICUT ACADEM, V3, P108; Gifi A., 1990, NONLINEAR MULTIVARIA; GOODMAN LA, 1985, ANN STAT, V13, P10, DOI 10.1214/aos/1176346576; Greenacre M, 1993, J APPL STAT, V20, P251, DOI 10.1080/02664769300000021; GREENACRE MJ, 1988, J CLASSIF, V5, P39, DOI 10.1007/BF01901670; Hastie T., 2001, ELEMENTS STAT LEARNI; HEATH TL, 1925, 13 BOOKS ELEMENTS; Heiser W. J, 1989, NEW DEV PSYCHOL CHOI, P3; HEISER WJ, 1983, J ECONOMETRICS, V22, P139, DOI 10.1016/0304-4076(83)90097-0; HEISER WJ, 2003, MEASUREMENTS INTERDI, V1, P264; HEISER WJ, 2003, DIMAC WORKSH ALG MUL; HEISER WJ, 1981, UNFOLDGIN ANAL PROXI; HEISER WJ, 2001, INT ENCY SOCIAL BEHA, P2820; HEISER WJ, 2004, SAGE HDB QUANTITATIV, P25; ISRAELS AZ, 1987, EIGENVALUE TECHNIQUE; Johnson MS, 2003, J EDUC BEHAV STAT, V28, P195, DOI 10.3102/10769986028003195; KELDERMAN H, 1994, PSYCHOMETRIKA, V59, P149, DOI 10.1007/BF02295181; KENDAL MG, 1948, RANK CORRELATION MET; KIM C, 1999, MULTIVARIATE BEHAV R, V34, P134; Kruskal J. B., 1969, MULTIVARIATE ANAL, P639; KRUSKAL JB, 1974, PSYCHOMETRIKA, V39, P123, DOI 10.1007/BF02291465; LEBART L, 1998, DATA SCI CLASSIFICAT, P423; LEE SY, 1992, PSYCHOMETRIKA, V57, P89, DOI 10.1007/BF02294660; LEWIS C, 1986, PSYCHOMETRIKA, V51, P11, DOI 10.1007/BF02293995; LOVIE AD, 1995, BRIT J MATH STAT PSY, V48, P255; Luce R. D., 1959, INDIVIDUAL CHOICE BE; Magidson J, 2001, SOCIOL METHODOL, V31, P223, DOI 10.1111/0081-1750.00096; MALLOWS CL, 1957, BIOMETRIKA, V44, P114, DOI 10.2307/2333244; Marden J.I., 1995, ANAL MODELING RANK D; MAXWELL J. C., 1857, T ROY SOC EDINBURGH, V21, P275; MAXWELL JC, 1860, T ROYAL SOC LONDON, V150, P57; McFadden D., 1974, FRONTIERS ECONOMETRI, P105; Meulman J, 2004, SAGE HDB QUANTITATIV, P49; MEULMAN JJ, 1998, VISUALIZATION CATEGO, P277, DOI 10.1016/B978-012299045-8/50022-X; Michell J, 1999, MEASUREMENT PSYCHOL; Mirkin B, 2001, AM STAT, V55, P111, DOI 10.1198/000313001750358428; MIRKIN B, 1995, J CLASSIF, V12, P243; NISHISATO S, 1984, PSYCHOMETRIKA, V49, P25, DOI 10.1007/BF02294203; Pearson K., 1900, GRAMMAR SCI; Pearson K., 1896, PHILOS T R SOC A, V187, P253, DOI DOI 10.1098/RSTA.1896.0007; Plackett R. L., 1975, Applied Statistics, V24, DOI 10.2307/2346567; Post W. J., 1992, NONPARAMETRIC UNFOLD; RASCH G, 1966, BRIT J MATH STAT PSY, V19, P49; Roberts JS, 2000, APPL PSYCH MEAS, V24, P3, DOI 10.1177/01466216000241001; Roberts JS, 1996, APPL PSYCH MEAS, V20, P231, DOI 10.1177/014662169602000305; ROOZEBOOM BHW, 1894, Z PHYS CHEM, V15, P145; ROSKAM E, 1968, METRIC ANAL ORDINAL; ROSS J, 1964, PSYCHOMETRIKA, V29, P167, DOI 10.1007/BF02289698; SCHONEMA.PH, 1970, PSYCHOMETRIKA, V35, P349, DOI 10.1007/BF02310794; SCHOUTE PH, 1911, VERHANDELINGEN KONIN, V11, P1; Shepard RN, 1972, MULTIDIMENSIONAL SCA, VI, P105; SLATER P, 1960, BRIT J STATIST PSYCH, V13, P119; Spearman C, 1906, BRIT J PSYCHOL, V2, P89; Spearman C, 1904, AM J PSYCHOL, V15, P72, DOI 10.2307/1412159; Spearman C, 1904, AM J PSYCHOL, V15, P201, DOI 10.2307/1412107; STEIN S, 1999, ARCHIMEDES WHAT BESI; Stevens S. S., 1951, HDB EXPT PSYCHOL, P1; TAKANE Y, 1991, PSYCHOMETRIKA, V56, P667, DOI 10.1007/BF02294498; Takane Y., 1998, VISUALIZATION CATEGO, P441, DOI 10.1016/B978-012299045-8/50034-6; TAKANE Y, 1987, PSYCHOMETRIKA, V52, P493, DOI 10.1007/BF02294815; TERBRAAK CJF, 1986, ECOLOGY, V67, P1167; THOMPSON GL, 1993, ANN STAT, V21, P1401, DOI 10.1214/aos/1176349265; Tucker L. R., 1960, PSYCHOL SCALING THEO, P155; UHM P, 1975, J ECOL, V63, P767; van de GEER J. P., 1993, MULTIVARIATE ANAL CA; VANDEAN K, 2004, UNPUB MULTIDIMENSIOL; VANDERARK LA, 1998, VISUALIZATION CATEGO, P489; van der Ark LA, 1999, J CLASSIF, V16, P117; VANDEUN K, 2005, IN PRESS PSYCHOMETRI, V70; Wickens T. D., 1989, MULTIWAY CONTINGENCY; Wilkinson L., 1999, GRAMMAR GRAPHICS; YOUNG FW, 1978, PSYCHOMETRIKA, V43, P279, DOI 10.1007/BF02293871; Yule GU, 1900, PHILOS T R SOC LOND, V194, P257, DOI 10.1098/rsta.1900.0019; Zhang J, 2004, J MATH PSYCHOL, V48, P107, DOI 10.1016/j.jmp.2003.12.002; Ziegler G.M., 1995, LECT POLYTOPES; Zumbo B. D., 2003, HUMAN NATURE REV, V3, P114	122	9	9	PSYCHOMETRIC SOC	WILLIAMSBURG	COLLEGE OF WILLIAM AND MARY DEPT PSYCHOLOGY, WILLIAMSBURG, VA 23185 USA	0033-3123			PSYCHOMETRIKA	Psychometrika	DEC	2004	69	4					513	545		10.1007/BF02289854		33	Mathematics, Interdisciplinary Applications; Social Sciences, Mathematical Methods; Psychology, Mathematical	Mathematics; Mathematical Methods In Social Sciences; Psychology	898VV	WOS:000227105200001		
J	Asefa, T; Kemblowski, MW; Urroz, G; McKee, M; Khalil, A				Asefa, T; Kemblowski, MW; Urroz, G; McKee, M; Khalil, A			Support vectors-based groundwater head observation networks design	WATER RESOURCES RESEARCH			English	Article						Support Vector Machines; groundwater monitoring networks; statistical learning theory	OPTIMAL MONITORING NETWORK; WASTE MANAGEMENT SITES; ENGINEERING DESIGN; GENETIC ALGORITHM; REGULATORY POLICY; SAMPLING DESIGN; CONTAMINATION; UNCERTAINTY; WELLS; WATER	This study presents a methodology for designing long-term groundwater head monitoring networks in order to reduce spatial redundancy. A spatially redundant well does not change the potentiometric surface estimation error appreciably, if not sampled. This methodology, based on Support Vector Machines, makes use of a uniquely solvable quadratic optimization problem that minimizes the bound on generalized risk, rather than just the mean square error of differences between measured and "predicted" groundwater head values. The nature of the optimization problem results in sparse approximation of the function defining the potentiometric surface that was utilized to select the number and locations of long-term monitoring wells and guide future data collection efforts, which is a prerequisite in building and calibrating regional flow and transport models. The methodology is applied to the design of regional groundwater monitoring networks in the Water Resources Inventory Area (WRIA) 1, Whatcom County, northern Washington State, USA.	Utah State Univ, Dept Civil & Environm Engn, Logan, UT 84322 USA; Utah State Univ, Utah Water Res Lab, Logan, UT 84322 USA	Asefa, T (reprint author), Utah State Univ, Dept Civil & Environm Engn, Logan, UT 84322 USA.	tasefa@cc.usu.edu; mkem@cc.usu.edu; gurro@cc.usu.edu; mmckee@cc.usu.edu; akhalil@cc.usu.edu					Angulo M, 1999, J GEOTECH GEOENVIRON, V125, P510, DOI 10.1061/(ASCE)1090-0241(1999)125:6(510); Asefa T, 2002, EOS T AGU S, V83; *ASS EARTH SCI INC, 1994, WELLH PROT PLAN CIT; *ASS EARTH SCI INC, 1995, WELLH PROT PROGR SUM; BENJEMAA F, 1994, J WATER RES PL-ASCE, V120, P505, DOI 10.1061/(ASCE)0733-9496(1994)120:4(505); Cameron K., 2000, OPTIMIZATION LTM NET; CIENIAWSKI SE, 1995, WATER RESOUR RES, V31, P399, DOI 10.1029/94WR02039; Cox S.E., 1999, 984195 US GEOL SURV; Datta B, 1996, J WATER RES PL-ASCE, V122, P180, DOI 10.1061/(ASCE)0733-9496(1996)122:3(180); Dibike YB, 2001, J COMPUT CIVIL ENG, V15, P208, DOI 10.1061/(ASCE)0887-3801(2001)15:3(208); Gangopadhyay S, 2001, GROUND WATER, V39, P181, DOI 10.1111/j.1745-6584.2001.tb02299.x; *GEOENG HYDR SERV, 1994, WELLH PROT STUD DODS; Girosi F, 1998, NEURAL COMPUT, V10, P1455, DOI 10.1162/089976698300017269; Govindaraju RS, 2000, ARTIFICIAL NEURAL NE; Hastie T., 2001, ELEMENTS STAT LEARNI; HUDAK PF, 1992, WATER RESOUR RES, V28, P643, DOI 10.1029/91WR02851; Jardine K, 1996, GROUND WATER, V34, P504, DOI 10.1111/j.1745-6584.1996.tb02032.x; Jones M.A, 1999, 1424C US GEOL SURV, P1424; Journel AG, 1978, MINING GEOSTATISTICS; KANEVISKI M, 2000, INT J FUZZY SYST, V4, P606; KNOPMAN DS, 1991, WATER RESOUR RES, V27, P925, DOI 10.1029/90WR02657; LIONG SY, 2000, J AM WATER RESOUR AS, V38, P173; LOAICIGA HA, 1992, J HYDRAUL ENG-ASCE, V118, P11, DOI 10.1061/(ASCE)0733-9429(1992)118:1(11); Mahar PS, 1997, J WATER RES PL-ASCE, V123, P199, DOI 10.1061/(ASCE)0733-9496(1997)123:4(199); MASSMANN J, 1987, WATER RESOUR RES, V23, P368, DOI 10.1029/WR023i002p00368; MASSMANN J, 1987, WATER RESOUR RES, V23, P351, DOI 10.1029/WR023i002p00351; MEYER PD, 1988, WATER RESOUR RES, V24, P1277, DOI 10.1029/WR024i008p01277; MEYER PD, 1994, WATER RESOUR RES, V30, P2647, DOI 10.1029/94WR00872; Minsker B, 2003, LONG TERM GROUNDWATE, P40678; Moline GR, 1996, GROUND WATER, V34, P579, DOI 10.1111/j.1745-6584.1996.tb02043.x; Montas HJ, 2000, J CONTAM HYDROL, V43, P271, DOI 10.1016/S0169-7722(99)00108-4; MORISAWA S, 1991, J CONTAM HYDROL, V7, P337, DOI 10.1016/0169-7722(91)90002-I; Muller KR, 1999, ADVANCES IN KERNEL METHODS, P243; Nunes LM, 2004, J WATER RES PL-ASCE, V130, P33, DOI 10.1061/(ASCE)0733-9496(2004)130:1(33); Nunes LM, 2004, WATER RESOUR RES, V40, DOI 10.1029/2003WR002469; POGGIO T, 1989, 1632 CBCI MIT AI; Poggio T, 1998, NEURAL COMPUT, V10, P1445, DOI 10.1162/089976698300017250; Reed P, 2003, WATER RESOUR RES, V39, DOI 10.1029/2002WR001483; Reed P, 2000, WATER RESOUR RES, V36, P3731, DOI 10.1029/2000WR900232; Reed P., 2001, J HYDROINFORM, V3, P71; Reed PM, 2004, J WATER RES PL-ASCE, V130, P140, DOI 10.1061/(ASCE)0733-9496(2004)130:2(140); ROUHANI S, 1985, WATER RESOUR RES, V21, P837, DOI 10.1029/WR021i006p00837; Saunders C., 1998, CSDTR9803 ROYAL HOLL; Scholkopf Bernard, 1999, ADV KERNEL METHODS S; Storck P, 1997, WATER RESOUR RES, V33, P2081, DOI 10.1029/97WR01704; Tikhonov AN, 1977, SOLUTION ILL POSED P; VANDERBEI RJ, 1994, TRSOR9415 PRINC U ST; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik VN, 1995, NATURE STAT LEARNING; WAGNER BJ, 1995, WATER RESOUR RES, V31, P2581, DOI 10.1029/95WR02107; WAHBA G, 1990, SER APPL MATH, V59; *WAT RES CONS LLC, 1997, WELLH PROT PROGR REP	52	30	30	AMER GEOPHYSICAL UNION	WASHINGTON	2000 FLORIDA AVE NW, WASHINGTON, DC 20009 USA	0043-1397			WATER RESOUR RES	Water Resour. Res.	NOV 25	2004	40	11							W11509	10.1029/2004WR003304		14	Environmental Sciences; Limnology; Water Resources	Environmental Sciences & Ecology; Marine & Freshwater Biology; Water Resources	875OY	WOS:000225431400003		
J	Jeffries, NO				Jeffries, NO			Performance of a genetic algorithm for mass spectrometry proteomics	BMC BIOINFORMATICS			English	Article							LASER DESORPTION/IONIZATION-TIME; OVARIAN-CANCER; PROSTATE-CANCER; SERUM; PATTERNS; IDENTIFICATION; BIOMARKERS	Background: Recently, mass spectrometry data have been mined using a genetic algorithm to produce discriminatory models that distinguish healthy individuals from those with cancer. This algorithm is the basis for claims of 100% sensitivity and specificity in two related publicly available datasets. To date, no detailed attempts have been made to explore the properties of this genetic algorithm within proteomic applications. Here the algorithm's performance on these datasets is evaluated relative to other methods. Results: In reproducing the method, some modifications of the algorithm as it is described are necessary to get good performance. After modification, a cross-validation approach to model selection is used. The overall classification accuracy is comparable though not superior to other approaches considered. Also, some aspects of the process rely upon random sampling and thus for a fixed dataset the algorithm can produce many different models. This raises questions about how to choose among competing models. How this choice is made is important for interpreting sensitivity and specificity results as merely choosing the model with lowest test set error rate leads to overestimates of model performance. Conclusions: The algorithm needs to be modified to reduce variability and care must be taken in how to choose among competing models. Results derived from this algorithm must be accompanied by a full description of model selection procedures to give confidence that the reported accuracy is not overstated.	NINDS, Off Clin Director, Bethesda, MD 20892 USA	Jeffries, NO (reprint author), NINDS, Off Clin Director, Bldg 36,Rm 4D04, Bethesda, MD 20892 USA.	neal.jeffries@nih.gov					Adam BL, 2002, CANCER RES, V62, P3609; Baggerly KA, 2004, BIOINFORMATICS, V20, P777, DOI 10.1093/bioinformatics/btg484; Baggerly KA, 2003, PROTEOMICS, V3, P1667, DOI 10.1002/pmic.200300522; Conrads TP, 2004, ENDOCR-RELAT CANCER, V11, P163, DOI 10.1677/erc.0.0110163; Efron Bradley, 1993, INTRO BOOTSTRAP; FUNG E, 2002, BIOTECHNIQUES COMPUT, V34, pS34; Grizzle WE, 2004, CLIN CHEM, V50, P1475, DOI 10.1373/clinchem.2004.033456; Hastie T., 2001, ELEMENTS STAT LEARNI; Li JN, 2002, CLIN CHEM, V48, P1296; Petricoin EF, 2004, CURR OPIN BIOTECH, V15, P24, DOI 10.1016/j.copbio.2004.01.005; Petricoin EF, 2004, CLIN CHEM, V50, P1476, DOI 10.1373/clinchem.2004.035097; Petricoin EF, 2002, J NATL CANCER I, V94, P1576; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Qu YS, 2002, CLIN CHEM, V48, P1835; Qu YS, 2003, BIOMETRICS, V59, P143, DOI 10.1111/1541-0420.00017; Reeves C. R., 2003, GENETIC ALGORITHMS P; Sorace JM, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-24; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210	19	20	24	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	NOV 19	2004	5								180	10.1186/1471-2105-5-180		13	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	891YX	WOS:000226618000002	15555060	
J	Das, D; Banerjee, N; Zhang, MQ				Das, D; Banerjee, N; Zhang, MQ			Interacting models of cooperative gene regulation	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article						cooperativity; correlation; expression data; transcription regulation	CELL-CYCLE; SACCHAROMYCES-CEREVISIAE; TRANSCRIPTIONAL REGULATORS; YEAST; EXPRESSION; IDENTIFICATION; GENOME; DISCOVERY; ELEMENTS; PROGRESSION	Cooperativity between transcription factors is critical to gene regulation. Current computational methods do not take adequate account of this salient aspect. To address this issue, we present a computational method based on multivariate adaptive regression splines to correlate the occurrences of transcription factor binding motifs in the promoter DNA and their interactions to the logarithm of the ratio of gene expression levels. This allows us to discover both the individual motifs and synergistic pairs of motifs that are most likely to be functional, and enumerate their relative contributions at any arbitrary time point for which mRNA expression data are available. We present results of simulations and focus specifically on the yeast cell-cycle data. Inclusion of synergistic interactions can increase the prediction accuracy over linear regression to as much as 1.5- to 3.5-fold. Significant motifs and combinations of motifs are appropriately predicted at each stage of the cell cycle. We believe our multivariate adaptive regression splines-based approach will become more significant when applied to higher eukaryotes, especially mammals, where cooperative control of gene regulation is absolutely essential.	Cold Spring Harbor Lab, Cold Spring Harbor, NY 11724 USA; George Mason Univ, Sch Computat Sci, Manassas, VA 20110 USA	Zhang, MQ (reprint author), Cold Spring Harbor Lab, POB 100, Cold Spring Harbor, NY 11724 USA.	mzhang@cshl.edu					Ahn SH, 1999, MOL BIOL CELL, V10, P3301; Banerjee N, 2003, NUCLEIC ACIDS RES, V31, P7024, DOI 10.1093/nar/gkg894; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Bussemaker HJ, 2001, NAT GENET, V27, P167, DOI 10.1038/84792; Carey M, 1998, CELL, V92, P5, DOI 10.1016/S0092-8674(00)80893-4; Chiang DY, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-7-r43; Cho RJ, 1998, MOL CELL, V2, P65, DOI 10.1016/S1097-2765(00)80114-8; Conlon EM, 2003, P NATL ACAD SCI USA, V100, P3339, DOI 10.1073/pnas.0630591100; Djordjevic M, 2003, GENOME RES, V13, P2381, DOI 10.1101/gr.1271603; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Hastie T., 2001, ELEMENTS STAT LEARNI; Keles S, 2002, BIOINFORMATICS, V18, P1167, DOI 10.1093/bioinformatics/18.9.1167; Kellis M, 2003, NATURE, V423, P241, DOI 10.1038/nature01644; Levine M, 2003, NATURE, V424, P147, DOI 10.1038/nature01763; Mai B, 2002, MOL CELL BIOL, V22, P430, DOI 10.1128/MCB.22.2.430-441.2002; OCHLEN LJ, 1996, MOL CELL BIOL, V16, P2830; Phuong TM, 2004, BIOINFORMATICS, V20, P750, DOI 10.1093/bioinformatics/btg480; Pilpel Y, 2001, NAT GENET, V29, P153, DOI 10.1038/ng724; Pramila T, 2002, GENE DEV, V16, P3034, DOI 10.1101/gad.1034302; Press W.H., 1992, NUMERICAL RECIPES C; Simon I, 2001, CELL, V106, P697, DOI 10.1016/S0092-8674(01)00494-9; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; STEINBERG D, 1999, MARS INTRO; Sudarsanam P, 2002, GENOME RES, V12, P1723, DOI 10.1101/gr.301202; TOONE WM, 1995, EMBO J, V14, P5824; Willis KA, 2003, GENETICS, V165, P1017; Yu Q, 2003, NUCLEIC ACIDS RES, V31, P1224, DOI 10.1093/nar/gkg200; Zhong HL, 1999, GENOME RES, V9, P1040, DOI 10.1101/gr.9.11.1040; Zhu GF, 2000, NATURE, V406, P90	29	67	71	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424			P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	NOV 16	2004	101	46					16234	16239		10.1073/pnas.0407365101		6	Multidisciplinary Sciences	Science & Technology - Other Topics	872RO	WOS:000225226200028	15534222	
J	Alexandridis, R; Lin, SL; Irwin, M				Alexandridis, R; Lin, SL; Irwin, M			Class discovery and classification of tumor samples using mixture modeling of gene expression data - a unified approach	BIOINFORMATICS			English	Article							MICROARRAY EXPERIMENTS; CANCER	Motivation: The DNA microarray technology has been increasingly used in cancer research. In the literature, discovery of putative classes and classification to known classes based on gene expression data have been largely treated as separate problems. This paper offers a unified approach to class discovery and classification, which we believe is more appropriate, and has greater applicability, in practical situations. Results: We model the gene expression profile of a tumor sample as from a finite mixture distribution, with each component characterizing the gene expression levels in a class. The proposed method was applied to a leukemia dataset, and good results are obtained. With appropriate choices of genes and preprocessing method, the number of leukemia types and subtypes is correctly inferred, and all the tumor samples are correctly classified into their respective type/subtype. Further evaluation of the method was carried out on other variants of the leukemia data and a colon dataset.	Ohio State Univ, Dept Stat, Columbus, OH 43210 USA	Lin, SL (reprint author), Ohio State Univ, Dept Stat, 1958 Neil Ave, Columbus, OH 43210 USA.	shili@stat.ohio-state.edu					Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Broet P, 2002, J COMPUT BIOL, V9, P671, DOI 10.1089/106652702760277381; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Ghosh D, 2002, BIOINFORMATICS, V18, P275, DOI 10.1093/bioinformatics/18.2.275; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hastie T., 2001, ELEMENTS STAT LEARNI; Kaufman L., 1990, FINDING GROUPS DATA; KELLER AD, 2000, UWCSE20000801 U WASH; Lee Y, 2003, BIOINFORMATICS, V19, P1132, DOI 10.1093/bioinformatics/btg102; Lin SL, 2003, INST MATH S, V40, P419; McLachlan GJ, 2002, BIOINFORMATICS, V18, P413, DOI 10.1093/bioinformatics/18.3.413; McLachlan GJ, 2000, FINITE MIXTURE MODEL; SOUKUP M, 2003, J BIOINFORM COMPUT B, V1, P681	13	17	18	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	NOV 1	2004	20	16					2545	2552		10.1093/bioinformatics/bth281		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	873AD	WOS:000225250100008	15117753	
J	Adem, J; Gochet, W				Adem, J; Gochet, W			Aggregating classifiers with mathematical programming	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article						supervised classification; bagging; boosting; mathematical programming; computational efficiency	DISCRIMINANT-ANALYSIS; CLASSIFICATION; MODELS	Bagging and boosting are popular and often successful ways to improve the performance of a classifier by means of aggregation. Classifiers can also be aggregated by means of an efficient and flexible mathematical programming model. This data-based approach guarantees that the aggregated classifier will be at least as good as the best predictor on the design data set for a user-defined criterion function. The mathematical programming approach is evaluated on real-world data sets from different contexts such as medical diagnosis, image segmentation and handwritten digit recognition. The real-world examples show that the approach can outperform both bagging and boosting. (C) 2003 Elsevier B.V. All rights reserved.	Katholieke Univ Leuven, Dept Appl Econ, B-3000 Louvain, Belgium	Adem, J (reprint author), Katholieke Univ Leuven, Dept Appl Econ, Naamsestr 69, B-3000 Louvain, Belgium.	jan.adem@econ.kuleuven.ac.be					BENNETT KP, 1993, OPTIMIZATION METHODS, V3, P27; Blake C.L., 1998, UCI REPOSITORY MACHI; Bose S, 2003, COMPUT STAT DATA AN, V42, P685, DOI 10.1016/S0167-9473(02)00171-8; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Buttrey SE, 2002, COMPUT STAT DATA AN, V40, P27, DOI 10.1016/S0167-9473(01)00098-6; Duda R., 2001, PATTERN RECOGNITION; ERENGUC SS, 1990, MANAGE DECIS ECON, V11, P215, DOI 10.1002/mde.4090110403; Fodor IK, 2002, COMPUT STAT DATA AN, V41, P91, DOI 10.1016/S0167-9473(02)00061-0; Gillick L., 1989, P ICASSP, P532; Gochet W, 1997, OPER RES, V45, P213, DOI 10.1287/opre.45.2.213; HAND D.J., 1997, CONSTRUCTION ASSESSM; Hastie T., 2002, ELEMENTS STAT LEARNI; *SAS I INC, 1998, SAS STATTM US GUID R; Schrage L, 1995, LINDO OPTIMIZATION S; THOMAS L, 2002, CREDIT SCORING ITS A; Vermunt JK, 2003, COMPUT STAT DATA AN, V41, P531, DOI 10.1016/S0167-9473(02)00179-2; Webb A., 1999, STAT PATTERN RECOGNI	17	3	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473			COMPUT STAT DATA AN	Comput. Stat. Data Anal.	NOV 1	2004	47	4					791	807		10.1016/j.csda.2003.11.015		17	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	872OE	WOS:000225215700010		
J	Kammann, U; Biselli, S; Huhnerfuss, H; Reineke, N; Theobald, N; Vobach, M; Wosniok, W				Kammann, U; Biselli, S; Huhnerfuss, H; Reineke, N; Theobald, N; Vobach, M; Wosniok, W			Genotoxic and teratogenic potential of marine sediment extracts investigated with comet assay and zebrafish test	ENVIRONMENTAL POLLUTION			English	Article						marine sediment; toxicity; comet assay; fractionation; embryo	DANIO-RERIO; LIFE STAGES; DNA-DAMAGE; CELL-LINE; EMBRYOS; FISH; TOXICITY; RIVER; IDENTIFICATION; SENSITIVITY	Organic extracts of marine sediments from the North Sea and the Baltic Sea were investigated with two toxicity assays. The comet assay based on the fish cell line Epithelioma papulosum cyprini (EPC) was applied to determine the genotoxic potential; zebrafish embryos (Danio rerio) were used to quantify the teratogenic potential of the samples. EC50 values were calculated from dose-response curves for both test systems. Highest teratogenic and genotoxic effects normalised to total organic carbon (TOC) content were detected in sediment samples of different origins. Polychlorinated biphenyls (PCBs) and polycyclic aromatic hydrocarbons (PAHs) are not likely to be the causes of the observed effects, as demonstrated by a two-step fractionation procedure of selected extracts. The toxic potential was more pronounced in fractions having polarity higher than those possessed by PAHs and PCBs. The suitability of the two in vitro test systems for assessing genotoxic and teratogenic effects of marine sediment extracts could be demonstrated. (C) 2004 Elsevier Ltd. All rights reserved.	Fed Res Ctr Fisheries, Inst Fishery Ecol, D-22767 Hamburg, Germany; Fed Maritime & Hydrog Agcy, D-20359 Hamburg, Germany; Univ Hamburg, Inst Organ Chem, D-20146 Hamburg, Germany; Univ Bremen, Inst Stat, D-28334 Bremen, Germany	Kammann, U (reprint author), Fed Res Ctr Fisheries, Inst Fishery Ecol, Palmaille 9, D-22767 Hamburg, Germany.	ulrike.kammann@ifo.bfa-fisch.de					Agresti A., 1990, CATEGORICAL DATA ANA; Akcha F, 2003, MUTAT RES-GEN TOX EN, V534, P21, DOI 10.1016/S1383-5718(02)00244-9; ANDERSON D, 1994, MUTAT RES, V307, P261, DOI 10.1016/0027-5107(94)90300-X; BISELLI S, IN PRESS J SOILS SEI; Bishop YMM, 1975, DISCRETE MULTIVARIAT; BRACK W, 2002, Z UMWELTCHEM OKOTOX, V14, P213; Brack W, 1999, ARCH ENVIRON CON TOX, V37, P164, DOI 10.1007/s002449900502; Carls MG, 1999, ENVIRON TOXICOL CHEM, V18, P481, DOI 10.1897/1551-5028(1999)018<0481:SOFETW>2.3.CO;2; *DIN, 2001, 38415T6 DIN; ENSENBACH U, 1995, ECOTOX ENVIRON SAFE, V30, P151, DOI 10.1006/eesa.1995.1019; Geffard O, 2002, ENVIRON TOXICOL CHEM, V21, P2310, DOI 10.1897/1551-5028(2002)021<2310:RBCLIM>2.0.CO;2; Hastie T., 2001, ELEMENTS STAT LEARNI; Heemken OP, 2000, ARCH ENVIRON CON TOX, V38, P11, DOI 10.1007/s002449910003; Hollert Henner, 2003, Journal of Soils and Sediments, V3, P197, DOI 10.1065/jss2003.09.085; JOHNSON L, 1993, MAR ENVIRON RES, V35, P165, DOI 10.1016/0141-1136(93)90032-U; Kamer I, 2002, TOXICOL IN VITRO, V16, P177, DOI 10.1016/S0887-2333(01)00118-7; Kammann U, 2001, MUTAT RES-GEN TOX EN, V498, P67, DOI 10.1016/S1383-5718(01)00268-6; KAMMANN U, IN PRESS J SOILS SEI; Kammann U, 2000, MUTAT RES-GEN TOX EN, V467, P161, DOI 10.1016/S1383-5718(00)00030-9; Luckenbach T, 2001, CHEMOSPHERE, V45, P571, DOI 10.1016/S0045-6535(00)00595-6; Marvin CH, 2000, CHEMOSPHERE, V41, P989, DOI 10.1016/S0045-6535(99)00493-2; Mattingly CJ, 2001, DEV DYNAM, V222, P645, DOI 10.1002/dvdy.1215; Meinelt T, 2001, AQUAT TOXICOL, V54, P205, DOI 10.1016/S0166-445X(01)00145-X; MUELLER C, 1991, ENVIRON TOXICOL CHEM, V10, P1149, DOI 10.1897/1552-8618(1991)10[1149:GEOCMS]2.0.CO;2; Nagel R, 2002, ALTEX-ALTERN TIEREXP, V19, P38; Oberemm A, 1999, ENVIRON TOXICOL, V14, P77, DOI 10.1002/(SICI)1522-7278(199902)14:1<77::AID-TOX11>3.0.CO;2-F; *OSPAR COMM, 1998, OSPAR STRAT REG HAZ, P34; Roex EWM, 2002, ENVIRON POLLUT, V120, P355, DOI 10.1016/S0269-7491(02)00118-5; *SAS I, 2001, SAS STAT VERS 8 2; Schwarzbauer J, 2000, ORG GEOCHEM, V31, P1713, DOI 10.1016/S0146-6380(00)00076-0; SINGH NP, 1988, EXP CELL RES, V175, P184, DOI 10.1016/0014-4827(88)90265-0; Sisinno CLS, 2000, B ENVIRON CONTAM TOX, V64, P107, DOI 10.1007/s001289910017; SMOLAREK TA, 1987, CARCINOGENESIS, V8, P1501, DOI 10.1093/carcin/8.10.1501; Strmac M, 2002, J FISH BIOL, V61, P24, DOI 10.1006/jfbi.2002.1919; Thomas KV, 2002, CHEMOSPHERE, V49, P247, DOI 10.1016/S0045-6535(02)00316-8; Wiegand C, 2001, ECOTOX ENVIRON SAFE, V49, P199, DOI 10.1006/eesa.2001.2073; YANG H, 1999, MUTAT RES, V23, P23	37	36	38	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0269-7491			ENVIRON POLLUT	Environ. Pollut.	NOV	2004	132	2					279	287		10.1016/j.envpol.2004.04.021		9	Environmental Sciences	Environmental Sciences & Ecology	852LX	WOS:000223757900008	15312940	
J	Preisler, HK; Ager, AA; Johnson, BK; Kie, JG				Preisler, HK; Ager, AA; Johnson, BK; Kie, JG			Modeling animal movements using stochastic differential equations	ENVIRONMETRICS			English	Article						cervus elaphus; diffusion process; potential functions; random vector field; splines; telemetry data	CORRELATED RANDOM-WALK; TELEMETRY DATA; HOME-RANGE; MULE DEER; SYSTEM; SPACE; SELECTION; MOTION; ELK	We describe the use of bivariate stochastic differential equations (SDE) for modeling movements of 216 radio-collared female Rocky Mountain elk at the Starkey Experimental Forest and Range in northeastern Oregon. Spatially and temporally explicit vector fields were estimated using approximating difference equation: and nonparametric regression techniques. Estimated vector fields of movement were mapped onto the project area at selected times of the day to examine spatial Patterns of movement in relation to topography. Using the concept of a potential function. we were able to study the influence of roads and grassland foraging area: on elk movements. Doing so we identified broad spatial patterns of elk movements and showed the time dependent effect: of habitat features within the habitat mosaic at Starkey. Our analyses quantify the cycle: of movements in spring and summer in terms of attraction or repulsion to specific habitat features. and illustrate the magnitude. timing and direction of these movements. An extensive list of references is included. Published in 2004 by John Wiles Sons. Lid.	US Forest Serv, SW Res Stn, Albany, CA 94710 USA; US Forest Serv, Pacific NW Res Stn, La Grande, OR 97850 USA; Oregon Dept Fish & Wildlife, La Grande, OR 97850 USA	Preisler, HK (reprint author), US Forest Serv, SW Res Stn, 800 Buchanan St, Albany, CA 94710 USA.	hpreisler@fs.fed.us					AGER AA, 2003, J MAMMAL, V83, P1076; ANDERSONSPRECHER R, 1991, J AM STAT ASSOC, V86, P596, DOI 10.2307/2290387; BENGTSSON G, 2002, THEORETICAL POPULATI, V21, P97; Bergman CM, 2000, OECOLOGIA, V123, P364, DOI 10.1007/s004420051023; Blackwell PG, 1997, ECOL MODEL, V100, P87, DOI 10.1016/S0304-3800(97)00153-1; BOWYER RT, 2001, ENCY ENV, P2381; Brillinger DR, 1997, J THEOR PROBAB, V10, P429, DOI 10.1023/A:1022869817770; Brillinger DR, 1998, CAN J STAT, V26, P431, DOI 10.2307/3315767; BRILLINGER DR, 2001, UCB STAT TECH REP, V610; Brillinger D.R., 2001, DATA ANAL STAT FDN, P369; BRILLINGER DR, 2002, B BRAZ MATH SOC, V33, P93; Carter J, 1999, ECOL MODEL, V119, P29, DOI 10.1016/S0304-3800(99)00044-7; CLARK JD, 1993, J WILDLIFE MANAGE, V57, P519, DOI 10.2307/3809276; Cleveland W. S., 1992, STAT MODELS S, P309; Coe P. K., 2001, J RANGE MANAGE, V54, P205; Coe P. K., 2001, Journal of Range Management, V54, pA51; DUNN JE, 1977, BIOMETRICS, V33, P85, DOI 10.2307/2529305; Dunn J.E., 1985, STAT THEORY DATA ANA, P181; Findholt SL, 1996, NORTHWEST SCI, V70, P273; Focardi S, 1996, J ANIM ECOL, V65, P606, DOI 10.2307/5740; Goldstein H., 1950, CLASSICAL MECH; GROSS JE, 1995, LANDSCAPE ECOL, V10, P209, DOI 10.1007/BF00129255; Hastie T., 2001, ELEMENTS STAT LEARNI, P533; HASTIE TJ, 1992, STAT MODELS S, P195; Johnson BK, 2000, J WILDLIFE MANAGE, V64, P685, DOI 10.2307/3802738; KAREIVA PM, 1983, OECOLOGIA, V56, P234, DOI 10.1007/BF00379695; Karlin S., 1981, 2 COURSE STOCHASTIC; KENDALL DG, 1974, J ROY STAT SOC B MET, V36, P365; Kie JG, 2002, ECOLOGY, V83, P530, DOI 10.2307/2680033; Kie JG, 1999, J MAMMAL, V80, P1004, DOI 10.2307/1383271; Lima SL, 1996, TRENDS ECOL EVOL, V11, P131, DOI 10.1016/0169-5347(96)81094-9; MINTA SC, 1992, ECOL APPL, V2, P178, DOI 10.2307/1941774; Mladenoff DJ, 1999, ECOL APPL, V9, P37, DOI 10.2307/2641166; Moorcroft PR, 1999, ECOLOGY, V80, P1656, DOI 10.1890/0012-9658(1999)080[1656:HRAUAM]2.0.CO;2; MOORE M, 1985, CAN J STAT, V13, P88, DOI 10.2307/3314870; *NAT CTR ATM RES, 2002, GEOPH STAT PROJ; Newman KB, 1998, BIOMETRICS, V54, P1290, DOI 10.2307/2533659; Niwa HS, 1996, J THEOR BIOL, V181, P47, DOI 10.1006/jtbi.1996.0114; PREISLER HK, 1995, BIOMETRICS, V51, P259, DOI 10.2307/2533331; PREISLER HK, 1999, P ASA SECT STAT ENV, P100; PREISLER HK, 2001, P IUFRO 4 11 C FOR B; PROHOROW YV, 1969, PROBABILITY THEORY; ROWLAND MM, 1997, PNWGTR396 USDA FOR S; Rowland MM, 2000, J WILDLIFE MANAGE, V64, P672, DOI 10.2307/3802737; *S PLUS, 2001, S PLUS 2001 US GUID; TURCHIN P, 2001, S PLUS 2001 USERS GU; TURNER MG, 1993, ECOL MODEL, V69, P163, DOI 10.1016/0304-3800(93)90026-O; WAGNER H, 1986, PHILOS T ROY SOC B, V312, P581, DOI 10.1098/rstb.1986.0019; White KAJ, 1996, P ROY SOC B-BIOL SCI, V263, P299, DOI 10.1098/rspb.1996.0046; Wu H, 2000, ECOL MODEL, V132, P115, DOI 10.1016/S0304-3800(00)00309-4; Zollner PA, 1999, ECOLOGY, V80, P1019, DOI 10.1890/0012-9658(1999)080[1019:SSFLLI]2.0.CO;2; ZWIERS FW, 1985, CANADIAN J STAT, V1, P94; 2002, ENVIROMETRICS, V13, P1	53	34	34	JOHN WILEY & SONS LTD	CHICHESTER	THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND	1180-4009			ENVIRONMETRICS	Environmetrics	NOV	2004	15	7					643	657		10.1002/env.636		17	Environmental Sciences; Mathematics, Interdisciplinary Applications; Statistics & Probability	Environmental Sciences & Ecology; Mathematics	879IW	WOS:000225711200001		
J	Moore, JH				Moore, JH			Computational analysis of gene-gene interactions using multifactor dimensionality reduction	EXPERT REVIEW OF MOLECULAR DIAGNOSTICS			English	Review						data mining; epistasis; genetic architecture; machine learning; software	CASE-CONTROL ASSOCIATION; GRAMMATICAL EVOLUTION; HUMAN-DISEASES; LOGISTIC-REGRESSION; MODEL VALIDATION; CYSTIC-FIBROSIS; COMPLEX DISEASE; MODIFIER GENES; SYSTEMS; EPISTASIS	Understanding the relationship between DNA sequence variations and biologic traits Is expected to Improve the diagnosis, prevention and treatment of common human diseases. Success in characterizing genetic architecture will depend on our ability to address nonlinearttles In the genotype-to-phenotype mapping relationship as a result of gone-gene Interactions, or epistasis. This review addresses the challenges associated with the detection and characterization of epistasis. A novel strategy known as muttifactor dimensionality reduction that was specifically designed for the Identification of multilocus genetic effects Is presented. Several case studies that demonstrate the detection of gene-gene Interactions In common diseases such as atrial fibrillation, Type 11 diabetes and essential hypertension are also discussed.	Dartmouth Coll Sch Med, Frank Lane Res Scholar Computat Genet, Computat Genet Lab, Lebanon, NH 03756 USA	Moore, JH (reprint author), Dartmouth Hitchcock Med Ctr, 706 Rubin Bldg,HB7937, Lebanon, NH 03756 USA.	Jason.h.moore@dartmouth.edu					Altmuller J, 2001, AM J HUM GENET, V69, P936, DOI 10.1086/324069; Bateson W., 1909, MENDELS PRINCIPLES H; Bellman R., 1961, ADAPTIVE CONTROL PRO; Cho YM, 2004, DIABETOLOGIA, V47, P549, DOI 10.1007/s00125-003-1321-3; Coffey CS, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-49; Coffey CS, 2004, NUTRITION, V20, P69, DOI 10.1016/j.nut.2003.09.012; CONCATO J, 1993, ANN INTERN MED, V118, P201; CORDELL HJ, 1995, TRENDS GENET, V11, P499, DOI 10.1016/S0168-9525(00)89160-X; Cordell HJ, 2001, GENETICS, V158, P357; Dipple KM, 2000, MOL GENET METAB, V71, P43, DOI 10.1006/mgme.2000.3052; Fisher R. A., 1918, T ROY SOC EDINBURGH, V52, P399; Frankel WN, 1996, NAT GENET, V14, P371, DOI 10.1038/ng1296-371; Freitas AA, 2001, ARTIF INTELL REV, V16, P177, DOI 10.1023/A:1011996210207; Good PI., 2000, PERMUTATION TESTS; Hahn LW, 2003, BIOINFORMATICS, V19, P376, DOI 10.1093/bioinformatics/btf869; HAHN LW, 2004, SILICO BIOL, V4; Hastie T., 2001, ELEMENTS STAT LEARNI; Hirschhorn JN, 2002, GENET MED, V4, P45, DOI 10.1097/00125817-200203000-00002; Hoh J, 2001, GENOME RES, V11, P2115, DOI 10.1101/gr.204001; Hosmer D. W. J. R., 2000, APPL LOGISTIC REGRES; Jansen RC, 2003, NAT REV GENET, V4, P145, DOI 10.1038/nrg996; KEREM E, 1990, NEW ENGL J MED, V323, P1517, DOI 10.1056/NEJM199011293232203; Li WT, 2000, HUM HERED, V50, P334, DOI 10.1159/000022939; MCKINNEY B, IN PRESS APPL BIOINF; Moore J, 2002, PAC S BIOCOMPUT, V7, P53; Moore JH, 2004, JAMA-J AM MED ASSOC, V291, P1642, DOI 10.1001/jama.291.13.1642; MOORE JH, 2002, P GEN EV COMP C; Moore JH, 2004, LECT NOTES COMPUT SC, V3102, P392; Moore JH, 2003, HUM HERED, V56, P73, DOI 10.1159/000073735; Moore JH, 2002, ANN MED, V34, P88, DOI 10.1080/07853890252953473; MOORE JH, 2002, LECT NOTES COMPUTER, V2439, P821; Moore JH, 2004, APPL SOFT COMPUT, V4, P79, DOI 10.1016/j.asoc.2003.08.003; Moore JH, 2003, LECT NOTES COMPUT SC, V2724, P2412; MOORE JH, 2004, LECT NOTES COMPUTER, V3005, P62; Moore JH, 2004, DISCRETE CONT DYN-B, V4, P275; Moore JH, 2003, BIOSYSTEMS, V72, P177, DOI 10.1016/S0303-2647(03)00142-4; Moore JH, 2002, GENET EPIDEMIOL, V23, P57, DOI 10.1002/gepi.01117; Moore JH, 2003, AM J HUM GENET, V73, P606; MOORE JH, 2003, LECT NOTES COMP SCI, P99; Peduzzi P, 1996, J CLIN EPIDEMIOL, V49, P1373, DOI 10.1016/S0895-4356(96)00236-3; Ritchie MD, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-28; Ritchie MD, 2001, AM J HUM GENET, V69, P138, DOI 10.1086/321276; Ritchie MD, 2003, GENET EPIDEMIOL, V24, P150, DOI 10.1002/gepi.10218; Ritchie MD, 2004, LECT NOTES COMPUT SC, V3102, P438; Salvatore F, 2002, AM J MED GENET, V111, P88, DOI 10.1002/ajmg.10461; Sing CF, 2003, ARTERIOSCL THROM VAS, V23, P1190, DOI 10.1161/01.ATV.0000075081.51227.86; Templeton AR, 2000, EPISTASIS EVOLUTIONA; THORNTONWELLS TA, IN PRESS TRENDS GENE; CORDELL HJ, 1995, AM J HUM GENET, V57, P920; Tsai CT, 2004, CIRCULATION, V109, P1640, DOI 10.1161/01.CIR.0000124487.36586.26; WHITE BC, 2004, ARTIF LIFE, V9, P581; Wille A, 2003, GENET EPIDEMIOL, V25, P350, DOI 10.1002/gepi.10263; Williams SM, 2004, BIOESSAYS, V26, P170, DOI 10.1002/bies.10401; Williams SM, 2004, HUM HERED, V57, P28, DOI 10.1159/000077387; Yang YN, 2003, J COMPUT BIOL, V10, P157, DOI 10.1089/106652703321825946	55	125	136	FUTURE DRUGS LTD	LONDON	UNITEC HOUSE, 3RD FL, 2 ALBERT PLACE, FINCHLEYY CENTRAL, LONDON N3 1QB, ENGLAND	1473-7159			EXPERT REV MOL DIAGN	Expert Rev. Mol. Diagn.	NOV	2004	4	6					795	803		10.1586/14737159.4.6.795		9	Pathology	Pathology	942QI	WOS:000230296500005	15525222	
J	Merkwirth, C; Mauser, HA; Schulz-Gasch, T; Roche, O; Stahl, M; Lengauer, T				Merkwirth, C; Mauser, HA; Schulz-Gasch, T; Roche, O; Stahl, M; Lengauer, T			Ensemble methods for classification in cheminformatics	JOURNAL OF CHEMICAL INFORMATION AND COMPUTER SCIENCES			English	Article							ATOMIC PHYSICOCHEMICAL PARAMETERS; NEURAL-NETWORK ENSEMBLES; QUANTITATIVE STRUCTURE; COMPOUND LIBRARIES; IDENTIFICATION; PREDICTION; QSAR	We describe the application of ensemble methods to binary classification problems on two pharmaceutical compound data sets. Several variants of single and ensembles models of k-nearest neighbors classifiers, support vector machines (SVMs), and single ridge regression models are compared. All methods exhibit robust classification even when more features are given than observations. On two data sets dealing with specific properties of drug-like substances (cytochrome P450 inhibition and "Frequent Hitters", i.e., unspecific protein inhibition), we achieve classification rates above 90%. We are able to reduce the cross-validated misclassification rate for the Frequent Hitters problem by a factor of 2 compared to previous results obtained for the same data set with different modeling techniques.	Max Planck Inst Informat, Computat Biol & Appl Algorithm Grp, D-66123 Saarbrucken, Germany; Roche Pharma Res, Basel, Switzerland	Merkwirth, C (reprint author), Max Planck Inst Informat, Computat Biol & Appl Algorithm Grp, Stuhlsatzenhauseg 85, D-66123 Saarbrucken, Germany.	emerk.lengauer@mpi-sb.mpg.de					Agrafiotis DK, 2002, J CHEM INF COMP SCI, V42, P903, DOI 10.1021/ci0203702; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2000, MACH LEARN, V40, P229, DOI 10.1023/A:1007682208299; BREUND Y, 1999, J JPN SOC ARTIF INTE, V15, P771; CHANG C.C., 2001, LIBSVM LIBRARY SUPPO; *CHEM COMP GROUP I, 200302 MOE; DOMINGOS P, 2000, AAAI IAAI; GHOSE AK, 1987, J CHEM INF COMP SCI, V27, P21, DOI 10.1021/ci00053a005; Hastie T., 2001, ELEMENTS STAT LEARNI; KROGH AS, 1995, ADV NEURAL INFORMATI, V7; Lucic B, 2003, J CHEM INF COMP SCI, V43, P1094, DOI 10.1021/ci025636j; Mattioni BE, 2003, J CHEM INF COMP SCI, V43, P949, DOI 10.1021/ci034013i; Merkwirth C, 2000, PHYS REV E, V62, P2089, DOI 10.1103/PhysRevE.62.2089; Perrone M.P., 1993, NEURAL NETWORKS SPEE; Roche O, 2002, J MED CHEM, V45, P137, DOI 10.1021/jm010934d; Seidler J, 2003, J MED CHEM, V46, P4477, DOI 10.1021/jm030191r; Vapnik V., 1999, NATURE STAT LEARNING; VISWANADHAN VN, 1989, J CHEM INF COMP SCI, V29, P163, DOI 10.1021/ci00063a006; Warmuth MK, 2003, J CHEM INF COMP SCI, V43, P667, DOI 10.1021/ci025620t; Zuegge J, 2002, QUANT STRUCT-ACT REL, V21, P249, DOI 10.1002/1521-3838(200208)21:3<249::AID-QSAR249>3.0.CO;2-S	20	47	49	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0095-2338			J CHEM INF COMP SCI	J. Chem. Inf. Comput. Sci.	NOV-DEC	2004	44	6					1971	1978		10.1021/ci049850e		8	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	875HQ	WOS:000225411300010	15554666	
J	Mirkin, S; Nikas, G; Hsiu, JG; Diaz, J; Oehninger, S				Mirkin, S; Nikas, G; Hsiu, JG; Diaz, J; Oehninger, S			Gene expression profiles and structural/functional features of the peri-implantation endometrium in natural and gonadotropin-stimulated cycles	JOURNAL OF CLINICAL ENDOCRINOLOGY & METABOLISM			English	Article							IN-VITRO FERTILIZATION; HUMAN CHORIONIC-GONADOTROPIN; LUTEAL-PHASE; IMPLANTATION WINDOW; INTEGRIN EXPRESSION; EMBRYO IMPLANTATION; UTERINE RECEPTIVITY; GNRH ANTAGONISTS; INVITRO FERTILIZATION; HORMONE ANTAGONISTS	It has been speculated that controlled ovarian hyperstimulation (COH), as performed during in vitro fertilization therapy, may negatively affect embryo implantation. The objective of this prospective and randomized study was to investigate gene expression profiles of the human endometrium during the window of implantation of gonadotropin-stimulated COH cycles compared with temporally matched natural cycles (d 21). Analysis was performed with high-density oligonucleotide microarrays. In addition, other structural and functional features of the endometrium were investigated. Results corroborated that COH cycles depicted advancement of pinopodes appearance, histological features, and steroid receptor down-regulation when compared with natural cycles. These changes were associated with significant, albeit small, variations in gene expression (18 genes/expressed sequence tags and -1.55- to +3.40-fold changes). Second, there were significant changes in gene expression when comparing cycles using a GnRH agonist vs. a GnRH antagonist (13 genes/expressed sequence tags and +1.42- to +2.10-fold changes). This is the first attempt to elucidate gene expression profiles of the endometrium during COH cycles. The observed differences in gene expression in COH cycles using state-of-the-art protocols may not have a major functional impact on embryo implantation.	Eastern Virginia Med Sch, Jones Inst Reprod Med, Dept Obstet & Gynecol, Norfolk, VA 23507 USA; Eastern Virginia Med Sch, Dept Pathol, Norfolk, VA 23507 USA; Aretaieio Univ Hosp, Dept Obstet & Gynecol 2, Athens 16675, Greece	Oehninger, S (reprint author), Eastern Virginia Med Sch, Jones Inst Reprod Med, Dept Obstet & Gynecol, 601 Colley Ave, Norfolk, VA 23507 USA.	oehninsc@evms.edu					Acosta AA, 2000, FERTIL STERIL, V73, P788, DOI 10.1016/S0015-0282(99)00605-6; Al-Inany H, 2002, HUM REPROD, V17, P874, DOI 10.1093/humrep/17.4.874; Beckers NGM, 2003, J CLIN ENDOCR METAB, V88, P4186, DOI 10.1210/jc.2002-021953; BERGH PA, 1992, FERTIL STERIL, V58, P537; Boklage CE, 1990, INT J FERTIL, V35, P79; Borthwick JM, 2003, MOL HUM REPROD, V9, P19, DOI 10.1093/humrep/gag004; Bourgain C, 2003, HUM REPROD UPDATE, V9, P515, DOI 10.1093/humupd/dmg045; BOURGAIN C, 1994, HUM REPROD, V9, P32; Brown SE, 2000, FERTIL STERIL, V74, P130, DOI 10.1016/S0015-0282(00)00586-0; Bustin SA, 2002, J MOL ENDOCRINOL, V29, DOI 10.1677/jme.0.0290023; Carson DD, 2002, MOL HUM REPROD, V8, P871, DOI 10.1093/molehr/8.9.871; *CDCP, 2001, ASS REPR TECHN SUCC, P1; Creus M, 2003, HUM REPROD, V18, P683, DOI 10.1093/humrep/deg177; De Neubourg Diane, 2003, Reprod Biomed Online, V7, P615; Develioglu OH, 1999, FERTIL STERIL, V71, P1040, DOI 10.1016/S0015-0282(99)00137-5; DRAGHICI S, 2003, DATA ANAL TOOLS DNA, P215; Fernandez N, 1999, HUM REPROD UPDATE, V5, P234, DOI 10.1093/humupd/5.3.234; Fielden MR, 2002, ENDOCRINOLOGY, V143, P3044, DOI 10.1210/en.143.8.3044; FROST RA, 1993, BIOL REPROD, V49, P104, DOI 10.1095/biolreprod49.1.104; GARCIA JE, 1984, FERTIL STERIL, V41, P31; Giudice LC, 1999, SEMIN REPROD ENDOCR, V17, P13, DOI 10.1055/s-2007-1016207; Giudice LC, 2003, HUM REPROD UPDATE, V9, P223, DOI 10.1093/humupd/dmg019; Gordon K, 2001, ANN NY ACAD SCI, V943, P49; HALILA R, 1986, BIOCHEM J, V239, P47; HASTIE T, 2001, ELEMENTS STAT LEARNI, P15; Hattula K, 2000, CURR BIOL, V10, P1603, DOI 10.1016/S0960-9822(00)00864-2; Hernandez ER, 2000, HUM REPROD, V15, P1211, DOI 10.1093/humrep/15.6.1211; Iwahashi M, 1996, J REPROD FERTIL, V108, P147; Kao LC, 2002, ENDOCRINOLOGY, V143, P2119, DOI 10.1210/en.143.6.2119; Kim JW, 1999, GYNECOL ONCOL, V73, P368, DOI 10.1006/gyno.1999.5398; Kol S, 2000, HUM REPROD, V15, P1881, DOI 10.1093/humrep/15.9.1881; Kolb BA, 1997, AM J OBSTET GYNECOL, V176, P1262, DOI 10.1016/S0002-9378(97)70344-2; Kolibianakis EM, 2003, FERTIL STERIL, V80, P464, DOI 10.1016/S0015-0282(03)00663-0; Lass A, 2001, FERTIL STERIL, V76, P1091, DOI 10.1016/S0015-0282(01)02878-3; Lessey BA, 2002, J REPROD IMMUNOL, V55, P101, DOI 10.1016/S0165-0378(01)00139-5; Lessey BA, 2000, BEST PRACT RES CL OB, V14, P775, DOI 10.1053/beog.2000.0118; Macklon N S, 2000, J Reprod Fertil Suppl, V55, P101; Mannaerts B, 2000, HUM REPROD, V15, P1882, DOI 10.1093/humrep/15.9.1882; Meyer WR, 1999, FERTIL STERIL, V71, P109, DOI 10.1016/S0015-0282(98)00390-2; Mirkin S, 2003, J ASSIST REPROD GEN, V20, P400, DOI 10.1023/A:1026236726568; Nardo LG, 2003, J REPROD MED, V48, P355; Nikas G, 2003, ANN NY ACAD SCI, V997, P120, DOI 10.1196/annuals.1290.042; Nikas G, 1999, HUM REPROD, V14, P787, DOI 10.1093/humrep/14.3.787; NOYES RW, 1950, FERTIL STERIL, V1, P3; Okulicz WC, 2003, BIOL REPROD, V69, P1593, DOI 10.1095/biolreprod.103.017525; Petroff MG, 2002, J REPROD IMMUNOL, V56, P3, DOI 10.1016/S0165-0378(02)00024-4; Pritts EA, 2002, HUM REPROD, V17, P2287, DOI 10.1093/humrep/17.9.2287; PSYCHOYOS A, 1994, FRONT ENDOCRINOL, V4, P57; Raychaudhuri S, 2001, TRENDS BIOTECHNOL, V19, P189, DOI 10.1016/S0167-7799(01)01599-2; Reese J, 2001, J BIOL CHEM, V276, P44137, DOI 10.1074/jbc.M107563200; Riesewijk A, 2003, MOL HUM REPROD, V9, P253, DOI 10.1093/molehr/gag037; Rutanen EM, 2000, HUM REPROD, V15, P173; Salamonsen LA, 2001, REPROD FERT DEVELOP, V13, P41, DOI 10.1071/RD00046; SEIF MW, 1992, HUM REPROD, V7, P6; Seppala M, 1995, HUM REPROD, V10, P67; Soderstrom-Antilla V, 2003, HUM REPROD, V18, P1858, DOI 10.1093/humrep/deg384; Spencer TE, 1995, REPROD FERT DEVELOP, V7, P1053, DOI 10.1071/RD9951053; Stavreus-Evers A, 2001, FERTIL STERIL, V76, P782, DOI 10.1016/S0015-0282(01)01993-8; Tabibzadeh S, 1998, HUM REPROD UPDATE, V4, P465, DOI 10.1093/humupd/4.5.465; Tavaniotou A, 2003, EUR J OBSTET GYN R B, V108, P67, DOI 10.1016/S0301-2115(02)00428-1; Tavaniotou A, 2001, ANN NY ACAD SCI, V943, P55; Thomas K, 2003, FERTIL STERIL, V80, P502, DOI 10.1016/S0015-0282(03)00792-1; VANGELDER RN, 1990, P NATL ACAD SCI USA, V87, P1663; Vigano P, 2002, J CLIN ENDOCR METAB, V87, P5730, DOI 10.1210/jc.2002-020435; Vilska S, 1999, HUM REPROD, V14, P2392, DOI 10.1093/humrep/14.9.2392; Wilcox AJ, 1999, NEW ENGL J MED, V340, P1796, DOI 10.1056/NEJM199906103402304; Zimmermann N, 2003, J CLIN INVEST, V111, P1863, DOI 10.1172/JCI200317912	67	78	86	ENDOCRINE SOC	CHEVY CHASE	8401 CONNECTICUT AVE, SUITE 900, CHEVY CHASE, MD 20815-5817 USA	0021-972X			J CLIN ENDOCR METAB	J. Clin. Endocrinol. Metab.	NOV	2004	89	11					5742	5752		10.1210/jc.2004-0605		11	Endocrinology & Metabolism	Endocrinology & Metabolism	868XL	WOS:000224946300072	15531538	
J	Coppejans, M				Coppejans, M			On Kolmogorov's representation of functions of several variables by functions of one variable	JOURNAL OF ECONOMETRICS			English	Article						dimensionality reduction; non-parametric regression; B-splines; monotonicity	NONPARAMETRIC REGRESSION; CONVERGENCE; APPROXIMATION; MODEL; RATES	This paper proposes a multivariate nonparametric regression estimator. Motivated by Kolmogorov (Doklady 114 (1957) 679), we consider functions of the form Sigma(k=1)(t)g(k)(lambda(k,1)phi(k)(x(1)) + (...) + lambda(k,d)phi(k)(x(d))), 1 less than or equal to t < infinity, where g(k)((.)) and phik((.)) are three times continuously differentiable and phi(k)((.)) is nondecreasing. These functions are approximated by cubic B-splines. Optimal univariate convergence rates are obtained. A small number of necessary and sufficient monotonicity constraints are developed. Furthermore, we directly bound the bias of this estimator when the underlying function is smooth, and not necessarily taking the above form. This bias can be made arbitrarily small. These contributions allow for a better understanding of the approximating properties of the estimator. (C) 2003 Elsevier B.V. All rights reserved.	Duke Univ, Dept Econ, Durham, NC 27708 USA	Coppejans, M (reprint author), Duke Univ, Dept Econ, Durham, NC 27708 USA.	mtc@econ.duke.edu					BARRON AR, 1993, IEEE T INFORM THEORY, V39, P930, DOI 10.1109/18.256500; Bloch DA, 1997, J AM STAT ASSOC, V92, P144, DOI 10.2307/2291458; Chen XH, 1998, ECONOMETRICA, V66, P289, DOI 10.2307/2998559; Coppejans M, 2001, J ECONOMETRICS, V102, P231, DOI 10.1016/S0304-4076(01)00054-9; de Boor C., 1978, PRACTICAL GUIDE SPLI; DIACONIS P, 1984, SIAM J SCI STAT COMP, V5, P175, DOI 10.1137/0905013; DONOHO DL, 1989, ANN STAT, V17, P58, DOI 10.1214/aos/1176347004; Eubank R.L., 1988, SPLINE SMOOTHING NON; Fan J., 1996, LOCAL POLYNOMIAL MOD; Fenton VM, 1996, ECONOMETRICA, V64, P719, DOI 10.2307/2171869; FRIEDMAN JH, 1981, J AM STAT ASSOC, V76, P817, DOI 10.2307/2287576; Gill P. E., 1986, USERS GUIDE NPSOL VE; Hastie T, 1986, STAT SCI, V1, P297, DOI DOI 10.1214/SS/1177013604; Hastie T., 2001, ELEMENT STAT LEARNIN; Horowitz JL, 2001, ECONOMETRICA, V69, P499, DOI 10.1111/1468-0262.00200; Judd K. L., 1998, NUMERICAL METHODS EC; Kolmogorov A. N., 1961, AM MATH SOC TRANSL, V17, P277; Kolmogorov A.N., 1957, DOKL AKAD NAUK, V114, P679; LINTON O, 1995, BIOMETRIKA, V82, P93, DOI 10.1093/biomet/82.1.93; Lorentz G. G., 1996, CONSTRUCTIVE APPROXI; Lorentz G.G., 1966, APPROXIMATION FUNCTI; Powell M. J. D., 1981, APPROXIMATION THEORY; Ramsay J. O., 1988, STAT SCI, V3, P425, DOI DOI 10.1214/SS/1177012761; SCHUMAKER LL, 1983, SIAM J NUMER ANAL, V20, P854, DOI 10.1137/0720057; Schumaker L.L., 1981, SPLINE FUNCTIONS BAS; SHEN XT, 1994, ANN STAT, V22, P580, DOI 10.1214/aos/1176325486; Silverman BW, 1986, DENSITY ESTIMATION S; STONE CJ, 1982, ANN STAT, V10, P1040, DOI 10.1214/aos/1176345969; WRIGHT IW, 1980, ANN STAT, V8, P1023, DOI 10.1214/aos/1176345140	29	3	3	ELSEVIER SCIENCE SA	LAUSANNE	PO BOX 564, 1001 LAUSANNE, SWITZERLAND	0304-4076			J ECONOMETRICS	J. Econom.	NOV	2004	123	1					1	31		10.1016/j.jeconom.2003.10.026		31	Economics; Mathematics, Interdisciplinary Applications; Social Sciences, Mathematical Methods	Business & Economics; Mathematics; Mathematical Methods In Social Sciences	855WV	WOS:000224006500001		
J	Rupp, B; Wang, JW				Rupp, B; Wang, JW			Predictive models for protein crystallization	METHODS			English	Article						high throughput crystallization; statistical analysis; machine learning; structural genomics; predictive models	STRUCTURAL GENOMICS; MACROMOLECULAR CRYSTALLIZATION; VAPOR-DIFFUSION; BIOLOGICAL MACROMOLECULES; CRYSTAL-GROWTH; MICROBATCH; DATABASE; DISCOVERY; STRATEGY; FACILITY	Crystallization of proteins is a nontrivial task, and despite the substantial efforts in robotic automation, crystallization screening is still largely based on trial-and-error sampling of a limited subset of suitable reagents and experimental parameters. Funding of high throughput crystallography pilot projects through the NIH Protein Structure Initiative provides the opportunity to collect crystallization data in a comprehensive and statistically valid form. Data mining and machine learning algorithms thus have the potential to deliver predictive models for protein crystallization. However, the underlying complex physical reality of crystallization, combined with a generally ill-defined and sparsely populated sampling space, and inconsistent scoring and annotation make the development of predictive models non-trivial. We discuss the conceptual problems, and review strengths and limitations of current approaches towards crystallization prediction, emphasizing the importance of comprehensive and valid sampling protocols. In view of limited overlap in techniques and sampling parameters between the publicly funded high throughput crystallography initiatives, exchange of information and standardization should be encouraged, aiming to effectively integrate data mining and machine learning efforts into a comprehensive predictive framework for protein crystallization. Similar experimental design and knowledge discovery strategies should be applied to valid analysis and prediction of protein expression, solubilization, and purification, as well as crystal handling and cryo-protection. (C) 2004 Elsevier Inc. All rights reserved.	Lawrence Livermore Natl Lab, Macromol Crystallog & TB Struct Genom Consortium, Livermore, CA 94551 USA; Temple Univ, Ctr Biotechnol, Philadelphia, PA 19122 USA; Temple Univ, Dept Chem, Philadelphia, PA 19122 USA	Rupp, B (reprint author), Lawrence Livermore Natl Lab, Macromol Crystallog & TB Struct Genom Consortium, Livermore, CA 94551 USA.	br@llnl.gov	Wang, Junwen/C-4432-2009; Wang, Junwen/D-3700-2011	Wang, Junwen/0000-0002-4432-4707			Anand K, 2002, ACTA CRYSTALLOGR D, V58, P1722, DOI 10.1107/S0907444902014610; Baldock P, 1996, J CRYST GROWTH, V168, P170, DOI 10.1016/0022-0248(96)00350-8; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; BODENSTAFF ER, 2002, ACTA CRYSTALLOGR D, V59, P1901; Box G.E.P., 1978, STAT EXPT INTRO DESI; Brzozowski AM, 2001, J APPL CRYSTALLOGR, V34, P97, DOI 10.1107/S0021889800017362; BRZOZOWSKI AM, 1994, ACTA CRYSTALLOGR D, V50, P466, DOI 10.1107/S090744499400199X; CARTER CWJ, 1999, CRYSTALLIZATION NUCL; CARTER CW, 1979, J BIOL CHEM, V254, P2219; CARTER C W JR, 1990, Methods (Orlando), V1, P12, DOI 10.1016/S1046-2023(05)80142-2; Carugo O, 1997, PROTEIN SCI, V6, P2261; Chayen Naomi E., 2003, Journal of Structural and Functional Genomics, V4, P115, DOI 10.1023/A:1026174727482; Chayen NE, 1998, ACTA CRYSTALLOGR D, V54, P8, DOI 10.1107/S0907444997005374; COX MJ, 1988, J CRYST GROWTH, V90, P318, DOI 10.1016/0022-0248(88)90327-2; Cudney R, 1994, Acta Crystallogr D Biol Crystallogr, V50, P414, DOI 10.1107/S0907444994002660; Dale GE, 2003, J STRUCT BIOL, V142, P88, DOI 10.1016/S1047-8477(03)00041-8; Dalgaard P, 2002, INTRO STAT; DARCY A, 1994, ACTA CRYSTALLOGR D, V50, P469, DOI 10.1107/S0907444993014362; D'Arcy A, 2003, ACTA CRYSTALLOGR D, V59, P396, DOI 10.1107/S0907444902022011; Day R, 2003, PROTEIN SCI, V12, P2150, DOI 10.1110/ps.0306803; DELONG KA, 1993, MACH LEARN, V13, P161; DeLucas LJ, 2003, J STRUCT BIOL, V142, P188, DOI 10.1016/S1047-8477(03)00050-9; Drenth J, 1998, ACTA CRYSTALLOGR D, V54, P867, DOI 10.1107/S0907444998002297; DRENTH J, 1992, J CRYST GROWTH, V122, P107, DOI 10.1016/0022-0248(92)90233-9; Dunlop KV, 2003, ACTA CRYSTALLOGR D, V59, P1797, DOI 10.1107/S0907444903017414; Edwards AM, 2000, NAT STRUCT BIOL, V7, P970, DOI 10.1038/80751; Farr RG, 1998, J CRYST GROWTH, V183, P653, DOI 10.1016/S0022-0248(97)00492-2; Garman E, 1999, ACTA CRYSTALLOGR D, V55, P1641, DOI 10.1107/S0907444999008653; GILLILAND G L, 1990, Methods (Orlando), V1, P6, DOI 10.1016/S1046-2023(05)80141-0; GILLILAND GL, 1994, ACTA CRYSTALLOGR D, V50, P408, DOI 10.1107/S0907444994002003; Goh CS, 2004, J MOL BIOL, V336, P115, DOI 10.1016/j.jmb.2003.11.053; Han J., 2001, DATA MINING CONCEPTS; Hansen CL, 2002, P NATL ACAD SCI USA, V99, P16531, DOI 10.1073/pnas.262485199; Hastie T., 2001, ELEMENTS STAT LEARNI; Hennessy D, 2000, ACTA CRYSTALLOGR D, V56, P817, DOI 10.1107/S0907444900004261; Hosfield D, 2003, J STRUCT BIOL, V142, P207, DOI 10.1016/S1047-8477(03)00051-0; Hui R, 2003, J STRUCT BIOL, V142, P154, DOI 10.1016/S1047-8477(03)00046-7; JANCARIK J, 1991, J APPL CRYSTALLOGR, V24, P409, DOI 10.1107/S0021889891004430; JURISCA I, 2001, IBM SYST J, V402, P248; KANTARDJIEFF K, 2004, IN PRESS BIOINFORMAT; Kimber MS, 2003, PROTEINS, V51, P562, DOI 10.1002/prot.10340; Klaholz BP, 2000, ACTA CRYSTALLOGR D, V56, P933, DOI 10.1107/S090744490000634X; Lamers MH, 2000, NATURE, V407, P711; Liu AH, 2001, IBM SYST J, V40, P379; Loll PJ, 2003, J STRUCT BIOL, V142, P144, DOI 10.1016/S1047-8477(03)00045-5; Luecke H, 1999, SCIENCE, V286, P255, DOI 10.1126/science.286.5438.255; Luft JR, 2003, J STRUCT BIOL, V142, P170, DOI 10.1016/S1047-8477(03)00048-0; Marcotte EM, 1999, NATURE, V402, P83; MCPHERSON A, 2001, PROTEIN SCI, V10, P414; MCPHERSON A, 1976, J BIOL CHEM, V251, P6300; McPherson A., 1999, CRYSTALLIZATION BIOL; McPherson A., 1982, PREPARATION ANAL PRO; Mitchell T., 1997, MACHINE LEARNING; Norvell JC, 2000, NAT STRUCT BIOL, V7, P931, DOI 10.1038/80694; Page R, 2003, ACTA CRYSTALLOGR D, V59, P1028, DOI 10.1107/S0907444903007790; Patterson SD, 2003, NAT BIOTECHNOL, V21, P221, DOI 10.1038/nbt0303-221; Prater BD, 1999, J CRYST GROWTH, V196, P674, DOI 10.1016/S0022-0248(98)00862-8; ROUSSEL A, 1990, J CRYST GROWTH, P405; Rupp B, 2003, ACCOUNTS CHEM RES, V36, P173, DOI 10.1021/ar020021t; Rupp B, 2002, ACTA CRYSTALLOGR D, V58, P1514, DOI 10.1107/S0907444902014282; Rupp B, 2003, J STRUCT BIOL, V142, P162, DOI 10.1016/S1047-8477(03)00047-9; SAMUDZI CT, 1992, J CRYST GROWTH, V123, P47, DOI 10.1016/0022-0248(92)90009-8; Santarsiero BD, 2002, J APPL CRYSTALLOGR, V35, P278, DOI 10.1107/S0021889802001474; Segelke B., 1998, ACA M SERIES, V25, P78; Segelke Brent W., 2004, Journal of Structural and Functional Genomics, V5, P147, DOI 10.1023/B:JSFG.0000029193.82120.d1; Segelke BW, 2001, J CRYST GROWTH, V232, P553, DOI 10.1016/S0022-0248(01)01154-X; SIVIA DS, 1996, BAYESIAN TUTORIAL; Spraggon G, 2002, ACTA CRYSTALLOGR D, V58, P1915, DOI 10.1107/S0907444902016840; Stewart PDS, 1999, J CRYST GROWTH, V196, P665, DOI 10.1016/S0022-0248(98)00854-9; STURA EA, 1992, J CRYST GROWTH, V122, P273, DOI 10.1016/0022-0248(92)90256-I; Teri PERL, 1979, HIST MATH, V6, P36, DOI 10.1016/0315-0860(79)90103-4; van der Woerd M, 2003, J STRUCT BIOL, V142, P180, DOI 10.1016/S1047-8477(03)00049-2; Waldo GS, 1999, NAT BIOTECHNOL, V17, P691, DOI 10.1038/10904; Wiener MC, 2000, PROTEIN SCI, V9, P1407; Wilson J, 2002, ACTA CRYSTALLOGR D, V58, P1907, DOI 10.1107/S0907444902016633; Witten I.H., 1999, DATA MINING PRACTICA; Yeates TO, 2002, CURR OPIN STRUC BIOL, V12, P464, DOI 10.1016/S0959-440X(02)00350-0; ZEDZIK J, 1997, J APPL CRYSTALLOGR, V30, P502	78	36	37	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1046-2023			METHODS	Methods	NOV	2004	34	3					390	407		10.1016/j.ymeth.2004.03.031		18	Biochemical Research Methods; Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	868YX	WOS:000224950300013	15325656	
J	Simon, R				Simon, Richard			When is a genomic classifier ready for prime time?	NATURE CLINICAL PRACTICE ONCOLOGY			English	Editorial Material									NCI, Biometr Res Branch, Div Canc Treatment & Diag, Bethesda, MD 20892 USA	Simon, R (reprint author), NCI, Biometr Res Branch, Div Canc Treatment & Diag, 9000 Rockville Pike, Bethesda, MD 20892 USA.	rsimon@nih.gov					Hastie T., 2001, ELEMENTS STAT LEARNI; HAYES DF, 1998, BREAST CANC RES TREA, V52, P304; HILSENBECK SG, 1992, BREAST CANCER RES TR, V22, P197, DOI 10.1007/BF01840833; Justice AC, 1999, ANN INTERN MED, V130, P515; Pepe MS, 2003, STAT EVALUATION MED; Rosenwald A, 2002, NEW ENGL J MED, V346, P1937, DOI 10.1056/NEJMoa012914; Simon R, 2003, J NATL CANCER I, V95, P14; Simon R, 2003, BRIT J CANCER, V89, P1599, DOI 10.1038/sj.bjc.6601326; SIMON R, 1994, BRIT J CANCER, V69, P979, DOI 10.1038/bjc.1994.192; Simon RM, 2003, DESIGN ANAL DNA MICR	10	13	14	NATURE PUBLISHING GROUP	NEW YORK	75 VARICK STREET, 9TH FLOOR, NEW YORK, NY 10013-1917 USA	1743-4254			NAT CLIN PRACT ONCOL	Nat. Clin. Pract. Oncol.	NOV	2004	1	1					4	5		10.1038/ncponc0006		2	Oncology	Oncology	V43JJ	WOS:000202931100003	16264774	
J	Pharoah, PDP; Dunning, AM; Ponder, BAJ; Easton, DF				Pharoah, PDP; Dunning, AM; Ponder, BAJ; Easton, DF			Association studies for finding cancer-susceptibility genetic variants	NATURE REVIEWS CANCER			English	Review							BREAST-CANCER; LINKAGE DISEQUILIBRIUM; COMMON DISEASE; POPULATION STRATIFICATION; MULTIETHNIC COHORT; BRCA2 MUTATIONS; POOLED ANALYSIS; BLADDER-CANCER; RISK; POLYMORPHISMS	Cancer is the result of complex interactions between inherited and environmental factors. Known genes account for a small proportion of the heritability of cancer, and it is likely that many genes with modest effects are yet to be found. Genetic-association studies have been widely used in the search for such genes, but success has been limited so far. Increased knowledge of the function of genes and the architecture of human genetic variation combined with new genotyping technologies herald a new era of gene mapping by association.	Strangeways Res Lab, Canc Res UK Human Canc Genet Grp, Dept Oncol, Cambridge CB1 8RN, England; Strangeways Res Lab, Genet Epidemiol Grp, Dept Publ Hlth & Primary Care, Cambridge CB1 8RN, England	Ponder, BAJ (reprint author), Strangeways Res Lab, Canc Res UK Human Canc Genet Grp, Dept Oncol, Worts Causeway, Cambridge CB1 8RN, England.	bruce.ponder@srl.cam.ac.uk					Antoniou AC, 2002, BRIT J CANCER, V86, P76, DOI 10.1038/sj/bjc/6600008; Antoniou AC, 2003, GENET EPIDEMIOL, V25, P190, DOI 10.1002/gepi.10261; Barratt BJ, 2002, ANN HUM GENET, V66, P393, DOI 10.1017/S0003480002001252; Botstcin IJ, 2003, NAT GENET, V33, pS228; Boyd NF, 2002, NEW ENGL J MED, V347, P886, DOI 10.1056/NEJMoa013390; Cardon LR, 2001, NAT REV GENET, V2, P91, DOI 10.1038/35052543; Cardon LR, 2003, LANCET, V361, P598, DOI 10.1016/S0140-6736(03)12520-2; Carlson CS, 2004, NATURE, V429, P446, DOI 10.1038/nature02623; Carlson CS, 2004, AM J HUM GENET, V74, P106, DOI 10.1086/381000; Chakravarti A, 1999, NAT GENET, V21, P56, DOI 10.1038/4482; Chapman JM, 2003, HUM HERED, V56, P18, DOI 10.1159/000073729; Colhoun HM, 2003, LANCET, V361, P865, DOI 10.1016/S0140-6736(03)12715-8; Dahlman I, 2002, NAT GENET, V30, P149, DOI 10.1038/ng825; Devlin B, 1999, BIOMETRICS, V55, P997, DOI 10.1111/j.0006-341X.1999.00997.x; Dunning AM, 1999, CANCER EPIDEM BIOMAR, V8, P843; Dunning AM, 2000, AM J HUM GENET, V67, P1544, DOI 10.1086/316906; Easton D F, 1999, Breast Cancer Res, V1, P14, DOI 10.1186/bcr6; Engel LS, 2002, AM J EPIDEMIOL, V156, P95, DOI 10.1093/aje/kwf018; Freedman ML, 2004, NAT GENET, V36, P388, DOI 10.1038/ng1333; Gabriel SB, 2002, SCIENCE, V296, P2225, DOI 10.1126/science.1069424; GLOBER GA, 1971, GUT, V12, P570, DOI 10.1136/gut.12.7.570; Gonzalez CA, 2002, INT J CANCER, V100, P249, DOI 10.1002/ijc.10466; Haiman CA, 2003, HUM MOL GENET, V12, P2679, DOI 10.1093/hmg/ddg294; Hastie T., 2001, ELEMENTS STAT LEARNI; Hildesheim A, 2002, J NATL CANCER I, V94, P1780; Houlston Richard S., 1996, P208; Hugot JP, 2001, NATURE, V411, P599, DOI 10.1038/35079107; Ioannidis JPA, 2001, NAT GENET, V29, P306, DOI 10.1038/ng749; Johnson GCL, 2001, NAT GENET, V29, P233, DOI 10.1038/ng1001-233; Ke XY, 2003, BIOINFORMATICS, V19, P287, DOI 10.1093/bioinformatics/19.2.287; Kruglyak L, 1999, NAT GENET, V22, P139, DOI 10.1038/9642; Kuschel B, 2003, CANCER EPIDEM BIOMAR, V12, P809; Lakhani SR, 1998, J NATL CANCER I, V90, P1138, DOI 10.1093/jnci/90.15.1138; Lichtenstein P, 2000, NEW ENGL J MED, V343, P78, DOI 10.1056/NEJM200007133430201; Lohmueller KE, 2003, NAT GENET, V33, P177, DOI 10.1038/ng1071; Marchini J, 2004, NAT GENET, V36, P512, DOI 10.1038/ng1337; Marron MP, 1997, HUM MOL GENET, V6, P1275, DOI 10.1093/hmg/6.8.1275; Meijers-Heijboer H, 2002, NAT GENET, V31, P55, DOI 10.1038/ng879; Meng ZL, 2003, AM J HUM GENET, V73, P115, DOI 10.1086/376561; Neale BM, 2004, AM J HUM GENET, V75, P353, DOI 10.1086/423901; Patil N, 2001, SCIENCE, V294, P1719, DOI 10.1126/science.1065573; Pritchard JK, 1999, AM J HUM GENET, V65, P220, DOI 10.1086/302449; Risch N, 1996, SCIENCE, V273, P1516, DOI 10.1126/science.273.5281.1516; Risch N, 2001, CANCER EPIDEM BIOMAR, V10, P733; Risch NJ, 2000, NATURE, V405, P847, DOI 10.1038/35015718; Ritchie MD, 2001, AM J HUM GENET, V69, P138, DOI 10.1086/321276; Sham P, 2002, NAT REV GENET, V3, P862, DOI 10.1038/nrg930; Stram DO, 2003, HUM HERED, V55, P27, DOI 10.1159/000071807; Tabor HK, 2002, NAT REV GENET, V3, P391, DOI 10.1038/nrg796; Thomas DC, 2004, J NATL CANCER I, V96, P421, DOI 10.1093/jnci/djh094; Vineis P, 2001, CANCER EPIDEM BIOMAR, V10, P1249; Wacholder S, 2004, J NATL CANCER I, V96, P434, DOI 10.1093/jnci/djh075; Zhang K, 2003, BIOINFORMATICS, V19, P1300, DOI 10.1093/bioinformatics/btg142; Zhang K, 2002, AM J HUM GENET, V71, P1386, DOI 10.1086/344780	54	231	236	NATURE PUBLISHING GROUP	LONDON	MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	1474-175X			NAT REV CANCER	Nat. Rev. Cancer	NOV	2004	4	11					850	860		10.1038/nrc1476		11	Oncology	Oncology	867AY	WOS:000224815700012	15516958	
J	Gautama, T; Van Hulle, MM				Gautama, T; Van Hulle, MM			Optimal spatial regularisation of autocorrelation estimates in fMRI analysis	NEUROIMAGE			English	Article						spatial regularisation; autocorrelation; prewhitening	TIME-SERIES ANALYSIS; FUNCTIONAL MRI; TEMPORAL AUTOCORRELATION; RESAMPLING METHODS; STATISTICS; INFERENCE; NOISE; MODEL; BIAS	In the General Linear Model (GLM) framework for the statistical analysis of fMRI data, the problem of temporal autocorrelations in the residual signal (after regression) has been frequently addressed in the open literature. There exist various methods for correcting the ensuing bias in the statistical testing, among which the prewhitening strategy, which uses a prewhitening matrix for rendering the residual signal white (i.e., without temporal autocorrelations). This correction is only exact when the autocorrelation structure of the noise-generating process is accurately known, and the estimates derived from the fMRI data are too noisy to be used for correction. Recently, Worsley and coworkers proposed to spatially smooth the noisy autocorrelation estimates, effectively reducing their variance and allowing for a better correction. In this article, a systematic study into the effect of the smoothing kernel width is performed and a method is introduced for choosing this bandwidth in an -optimar, manner. Several aspects of the prewhitening strategy are investigated, namely the choice of the autocorrelation estimate (biased or unbiased), the accuracy of the estimates, the degree of spatial regularisation and the order of the autoregressive model used for characterising the noise. The proposed method is extensively evaluated on both synthetic and real fMRI data. (C) 2004 Elsevier Inc. All rights reserved.	Katholieke Univ Leuven, Neuro & Psychofysiol Lab, Campus Gasthuisberg,Herestr 49,Bus 801, B-3000 Louvain, Belgium	Gautama, T (reprint author), Katholieke Univ Leuven, Neuro & Psychofysiol Lab, Campus Gasthuisberg,Herestr 49,Bus 801, B-3000 Louvain, Belgium.	temu@neuro.kuleuven.ac.be; marc@neuro.kuleuven.ac.be					BISWAL B, 1995, MAGNET RESON MED, V34, P537, DOI 10.1002/mrm.1910340409; Bullmore E, 1996, MAGN RESON MED, V35, P261, DOI 10.1002/mrm.1910350219; Bullmore ET, 2001, HUM BRAIN MAPP, V12, P61, DOI 10.1002/1097-0193(200102)12:2<61::AID-HBM1004>3.0.CO;2-W; Friston KJ, 2000, NEUROIMAGE, V12, P466, DOI 10.1006/nimg.2000.0630; Friston KJ, 2000, NEUROIMAGE, V12, P196, DOI 10.1006/nimg.2000.0609; FRISTON KJ, 1995, NEUROIMAGE, V2, P45, DOI 10.1006/nimg.1995.1007; Hastie T., 2001, ELEMENTS STAT LEARNI; Kiebel SJ, 2003, NEUROIMAGE, V20, P591, DOI 10.1016/S1053-8119(03)00308-2; Locascio JJ, 1997, HUM BRAIN MAPP, V5, P168, DOI 10.1002/(SICI)1097-0193(1997)5:3&lt;168::AID-HBM3&gt;3.0.CO;2-1; Marchini JL, 2003, NEUROIMAGE, V18, P83, DOI 10.1006/nimg.2002.1321; Marchini JL, 2000, NEUROIMAGE, V12, P366, DOI 10.1006/nimg.2000.0628; Press W.H., 1992, NUMERICAL RECIPES C; Purdon PL, 2001, NEUROIMAGE, V14, P912, DOI 10.1006/nimg.2001.0870; Purdon PL, 1998, HUM BRAIN MAPP, V6, P239, DOI 10.1002/(SICI)1097-0193(1998)6:4<239::AID-HBM4>3.0.CO;2-4; Solo V, 2001, IEEE T MED IMAGING, V20, P26, DOI 10.1109/42.906422; Wicker B, 2003, NEUROIMAGE, V18, P588, DOI 10.1016/S1053-8119(02)00022-8; Woolrich MW, 2001, NEUROIMAGE, V14, P1370, DOI 10.1006/nimg.2001.0931; Worsley KJ, 2002, NEUROIMAGE, V15, P1, DOI 10.1006/nimg.2001.0933; WORSLEY KJ, 1995, NEUROIMAGE, V2, P173, DOI 10.1006/nimg.1995.1023; Xiong JH, 1996, HUM BRAIN MAPP, V4, P153, DOI 10.1002/(SICI)1097-0193(1996)4:3&lt;153::AID-HBM1&gt;3.0.CO;2-2; Zarahn E, 1997, NEUROIMAGE, V5, P179, DOI 10.1006/nimg.1997.0263	21	14	14	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1053-8119			NEUROIMAGE	Neuroimage	NOV	2004	23	3					1203	1216		10.1016/j.neuroimage.2004.07.048		14	Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical Imaging	Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging	873BP	WOS:000225254100042	15528120	
J	Zanation, AM; Yin, XY; Shores, C; Yarbrough, WG				Zanation, AM; Yin, XY; Shores, C; Yarbrough, WG			Phenotypic and microarray gene expression analysis of tri-dimensional raft-modeled human head and neck squamous cell carcinoma	OTOLARYNGOLOGY-HEAD AND NECK SURGERY			English	Article							BREAST-CANCER; EPITHELIUM; KERATINOCYTES; CULTIVATION; PATTERNS; CULTURE	OBJECTIVES: To describe the phenotypic and gene expression differences in monolayer and tri-dimensional cultures systems. METHODS: Normal oral epithelial cells (NOEC), primary head and neck squamous cell carcinoma (HNSCC), and HNSCC cell lines were used to create and study modeled tri-dimensional tissue. Using cDNA microarray analysis, monolayer and raft-modeled tri-dimensional HNSCC cell lines were compared. RESULTS: NOEC, HNSCC, and both together can be modeled with tri-dimensional differentiation and cytokeratin characteristics analogous to in vivo tissue. Modeling of primary HNSCC resulted in a morphology of invasive HNSCC with areas of direct collagen invasion and MMP2 expression. Gene array analysis suggests that the individual cell lines themselves are the primary gene expression predictor and not the presence of tri-dimensional tissue architecture. CONCLUSIONS. This tissue culture modeling system approximates the differentiation and tri-dimensional structure of in vivo tissues, and that raft modeled tri-dimensional HNSCC does not have a significantly different gene expression profile than the corresponding monolayer culture.	Univ N Carolina, Dept Otolaryngol Head & Neck Surg, Univ N Carolina Hosp, Lineberger Comprehens Canc Ctr,Sch Med, Chapel Hill, NC 27599 USA; Vanderbilt Univ, Dept Otolaryngol & Canc Biol, Nashville, TN USA	Zanation, AM (reprint author), Univ N Carolina, Dept Otolaryngol Head & Neck Surg, Univ N Carolina Hosp, Lineberger Comprehens Canc Ctr,Sch Med, CB 7070, Chapel Hill, NC 27599 USA.	Adam_Zanation@med.unc.edu					Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Clayman GL, 1999, CLIN CANCER RES, V5, P1715; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Hastie T., 2001, ELEMENTS STAT LEARNI, P533; Huang E, 2003, LANCET, V361, P1590, DOI 10.1016/S0140-6736(03)13308-9; Hutchin ME, 2000, HUM GENE THER, V11, P2365, DOI 10.1089/104303400750038471; KAWATA R, 1996, J OTO RHINOL LARYNGO, V99, P299; KNOWLES MR, 1995, NEW ENGL J MED, V333, P823, DOI 10.1056/NEJM199509283331302; LANDIS SH, 1999, CA CANC J CLIN, V49, P18; Liggett WH, 1996, CANCER RES, V56, P4119; LILLIE JH, 1980, EXP CELL RES, V125, P153, DOI 10.1016/0014-4827(80)90199-8; LINDBERG K, 1990, DIFFERENTIATION, V45, P230, DOI 10.1111/j.1432-0436.1990.tb00477.x; Oda D, 1998, IN VITRO CELL DEV-AN, V34, P46; Parker S, 1996, CA CANC J CLIN, V45, P5; Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; RHEINWALD JG, 1975, CELL, V6, P331, DOI 10.1016/S0092-8674(75)80001-8; TAICHMAN L, 1979, ARCH ORAL BIOL, V24, P335, DOI 10.1016/0003-9969(79)90099-2; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a	19	2	2	MOSBY, INC	ST LOUIS	11830 WESTLINE INDUSTRIAL DR, ST LOUIS, MO 63146-3318 USA	0194-5998			OTOLARYNG HEAD NECK	Otolaryngol. Head Neck Surg.	NOV	2004	131	5					577	584		10.1016/j.otohns.2004.05.023		8	Otorhinolaryngology; Surgery	Otorhinolaryngology; Surgery	870HC	WOS:000225047200003	15523429	
J	Hansen, ME; Carstensen, JM				Hansen, ME; Carstensen, JM			Density-based retrieval from high-similarity image databases	PATTERN RECOGNITION			English	Article						density based; identification; density estimation; image retrieval	COLOR	Many image classification problems can fruitfully be thought of as image retrieval in a "high similarity image database" (HSID) characterized by being tuned towards a specific application and having a high degree of visual similarity between entries that should be distinguished. We introduce a method for HSID retrieval using a similarity measure based on a linear combination of Jeffreys-Matusita distances between distributions of local (pixelwise) features estimated from a set of automatically and consistently defined image regions. The weight coefficients are estimated based on optimal retrieval performance. Experimental results on the difficult task of visually identifying clones of fungal colonies grown in a petri dish and categorization of pelts show a high retrieval accuracy of the method when combined with standardized sample preparation and image acquisition. (C) 2004 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Tech Univ Denmark, DK-2800 Lyngby, Denmark	Hansen, ME (reprint author), Tech Univ Denmark, Bldg 321, DK-2800 Lyngby, Denmark.	meh@imm.dtu.dk	Hansen, Michael/C-9028-2011	Hansen, Michael/0000-0001-7879-2106			ANDROUTSOS D, 1998, DISTANCE MEASURES CO; BISHOP C.M., 1995, NEURAL NETWORKS PATT; CARSON C, 1997, CVPR97 WORKSH CONT B; CINQUE L, 1999, COLOR BASED IMAGE RE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deng YN, 2001, IEEE T IMAGE PROCESS, V10, P140, DOI 10.1109/83.892450; Dorge T, 2000, J MICROBIOL METH, V41, P121, DOI 10.1016/S0167-7012(00)00142-1; FUKANAGA K, 1990, INTRO PATTERN RECOGN; Hastie T., 2002, ELEMENTS STAT LEARNI; IZENMAN AJ, 1991, J AM STAT ASSOC, V86, P205, DOI 10.2307/2289732; Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3; Kankanhalli MS, 1999, PATTERN RECOGN LETT, V20, P109, DOI 10.1016/S0167-8655(98)00100-7; Mirmehdi M, 2000, IEEE T PATTERN ANAL, V22, P142, DOI 10.1109/34.825753; Pitt J.I., 1979, GENUS PENICILLIUM IT; Raper K. B., 1949, MANUAL PENICILLIA; Ripley BD, 1996, PATTERN RECOGNITION; Roussopoulos N., 1995, P ACM SIGMOD INT C M, P71, DOI DOI 10.1145/223784.223794; Sonka M, 1994, IMAGE PROCESSING ANA	18	10	12	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	NOV	2004	37	11					2155	2164		10.1016/j.patcog.2004.02.018		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	848XI	WOS:000223501000005		
J	Langer, G; Parlitz, U				Langer, G; Parlitz, U			Modeling parameter dependence from time series	PHYSICAL REVIEW E			English	Article							RECONSTRUCTING BIFURCATION DIAGRAMS; WAVE-FORMS; ENSEMBLES	Two approaches for modeling of parameter dependence of dynamical systems from time series are investigated and applied to different examples. For both methods it is assumed that a few Lime series are available that have been measured for different (known) parameter values of the underlying (experimental) dynamical System. The objective is to model the changing dynamics of the system as a function of its parameters and to use this for experimental bifurcation analysis. Using parametrized families the tasks of modeling the dynamics and of modeling its parameter dependence are separated. Technical difficulties that may occur with this approach are discussed and illustrated. An alternative are extended state space models where both modeling, tasks are treated simultaneously. To obtain reliable models from a few time series only, ensembles of models are employed that show very good extrapolation and generalization properties.	Univ Gottingen, Drittes Phys Inst, D-37073 Gottingen, Germany	Langer, G (reprint author), Univ Gottingen, Drittes Phys Inst, Burgerstr 42-44, D-37073 Gottingen, Germany.	gerrit@dpi.physik.uni-goettingen.de; parlitz@dpi.physik.uni-goettingen.de					Avnimelech R, 1999, NEURAL COMPUT, V11, P499, DOI 10.1162/089976699300016746; Bagarinao E, 1999, PHYSICA D, V130, P211, DOI 10.1016/S0167-2789(99)00017-2; Bagarinao E, 1998, PHYSICA D, V124, P258, DOI 10.1016/S0167-2789(98)00200-0; Bagarinao E, 1999, PHYS REV E, V60, P1073, DOI 10.1103/PhysRevE.60.1073; Breiman L., 1994, 421 U CAL DEP STAT; CASDAGLI M, 1989, PHYSICA D, V35, P335, DOI 10.1016/0167-2789(89)90074-2; Dietterich T., 2000, LECT NOTES COMPUTER, P1; Dietterich T. G., 2002, HDB BRAIN THEORY NEU; Efron B., 1982, JACKKNIFE BOOTSTRAP; Freund Y., 1996, 13 INT C MACH LEARN, P148; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Hastie T., 2001, ELEMENTS STAT LEARNI; Jaeger L, 1996, CHAOS, V6, P440, DOI 10.1063/1.166196; Judd K, 1996, PHYSICA D, V92, P221, DOI 10.1016/0167-2789(95)00287-1; KORENBERG MJ, 1989, BIOL CYBERN, V60, P267, DOI 10.1007/BF00204124; KROGH A, 1995, ADV NEURAL INFORMATI, V7, P650; Krogh A, 1997, PHYS REV E, V55, P811, DOI 10.1103/PhysRevE.55.811; Merz CJ, 1999, MACH LEARN, V36, P9, DOI 10.1023/A:1007507221352; PACKARD NH, 1980, PHYS REV LETT, V45, P712, DOI 10.1103/PhysRevLett.45.712; Parlitz U, 1992, INT J BIFURCAT CHAOS, V2, P155, DOI 10.1142/S0218127492000148; Perrone MP, 1993, NEURAL NETWORKS SPEE, P126; Press W.H., 1994, NUMERICAL RECIPES C; SAUER T, 1991, J STAT PHYS, V65, P579, DOI 10.1007/BF01053745; Sollich P, 1996, ADV NEUR IN, V8, P190; Takens F., 1981, DYNAMICAL SYSTEMS TU, P366, DOI DOI 10.1007/BFB0091924; Tokuda I, 1996, PHYSICA D, V95, P380, DOI 10.1016/0167-2789(96)00063-2; Tokuda I, 2002, PHYS REV LETT, V88, DOI 10.1103/PhysRevLett.88.014101; TOKUNAGA R, 1994, PHYSICA D, V79, P348, DOI 10.1016/0167-2789(94)90092-2; Vapnik VN, 1995, NATURE STAT LEARNING; Zhou Z. H., 2001, INT J COMPUTATIONAL, V1, P341, DOI 10.1142/S1469026801000287	31	3	3	AMER PHYSICAL SOC	COLLEGE PK	ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA	1539-3755			PHYS REV E	Phys. Rev. E	NOV	2004	70	5	2						056217	10.1103/PhysRevE.70.056217		9	Physics, Fluids & Plasmas; Physics, Mathematical	Physics	882WI	WOS:000225970700065		
J	Spycher, S; Nendza, M; Gasteiger, J				Spycher, S; Nendza, M; Gasteiger, J			Comparison of different classification methods applied to a mode of toxic action data set	QSAR & COMBINATORIAL SCIENCE			English	Article						classification; variable selection; mode of action; toxicity; cross-validation; counter-propagation neural networks	NEURAL-NETWORKS; CROSS-VALIDATION; BOOTSTRAP; STRATEGY; DESIGN; QSAR	Successful discrimination of compounds by mode of toxic action (MOA) is a prerequisite for process-based quantitative structure- activity relationship (QSAR) approaches. A data set of 115 compounds comprising nine MOA classes and 24 descriptors has been studied with several classification methods: multinomial logistic regression (multinom), linear discriminant analysis (LDA), partial least squares (PLS), and counter-propagation neural networks (CPG NN). Variables were selected with stepwise methods and with a genetic algorithm (GA) for the CPG NN. Five-fold cross-validation was used for validating the models and the advantages and disadvantages of this validation method are critically discussed. Without variable selection the predictive power of the models ranges between 51% and 53% cross-validated overall correct classification. With appropriate parameter selection the predictive power slightly increased to 52-59%. The experimental data showed that a number of compounds were active in more than one MOA. Multinom and CPG NN models for multiple MOAs were derived for both single and multiple MOA data. The consideration of multiple MOAs resulted in a slight increase in predictive power even when all MOAs were modeled at the same time.	Univ Erlangen Nurnberg, Comp Chem Centrum, D-91052 Erlangen, Germany; Univ Erlangen Nurnberg, Inst Organ Chem, D-91052 Erlangen, Germany; Analyt Lab, D-24816 Luhnstedt, Germany	Gasteiger, J (reprint author), Univ Erlangen Nurnberg, Comp Chem Centrum, Nagelsbachstr 25, D-91052 Erlangen, Germany.	Gasteiger@chemie.uni-erlangen.de					Aptula AO, 2002, QUANT STRUCT-ACT REL, V21, P12, DOI 10.1002/1521-3838(200205)21:1<12::AID-QSAR12>3.0.CO;2-M; Basak Subhash C., 1998, Environmental Toxicology and Chemistry, V17, P1056, DOI 10.1897/1551-5028(1998)017<1056:ACSOMS>2.3.CO;2; Bradbury S P, 1994, SAR QSAR Environ Res, V2, P89, DOI 10.1080/10629369408028842; Carpenter J, 2000, STAT MED, V19, P1141, DOI 10.1002/(SICI)1097-0258(20000515)19:9<1141::AID-SIM479>3.0.CO;2-F; LECESSIE S, 1992, APPL STAT-J ROY ST C, V41, P191; Corbett J.R., 1984, BIOCH MODE ACTION PE; Cronin MTD, 2003, J MOL STRUC-THEOCHEM, V622, P39, DOI 10.1016/S0166-1280(02)00616-4; Devine MD, 1993, PHYSL HERBICIDE ACTI; Dillon W., 1984, MULTIVARIATE ANAL ME; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; ERIKSSON L, 2003, HDB CHEMOINFORMATICS, P1134, DOI 10.1002/9783527618279.ch39d; ERIKSSON L, 2000, INTRO MULTI MEGAVARI; Eriksson L, 1996, CHEMOMETR INTELL LAB, V34, P1, DOI 10.1016/0169-7439(96)00023-8; Escher BI, 2002, AQUAT SCI, V64, P20, DOI 10.1007/s00027-002-8052-2; FORBES AD, 1995, J CLIN MONITOR, V11, P189, DOI 10.1007/BF01617722; Gasteiger J, 2003, J PHYS ORG CHEM, V16, P232, DOI 10.1002/poc.597; Golbraikh A, 2002, J MOL GRAPH MODEL, V20, P269, DOI 10.1016/S1093-3263(01)00123-1; Harrell FE, 2001, REGRESSION MODELING; Hastie T., 2001, ELEMENTS STAT LEARNI; Hawkins DM, 2003, J CHEM INF COMP SCI, V43, P579, DOI 10.1021/ci025626i; HAYES WJ, 1991, HDB PESTICIDE TOXICO, P1350; Hosmer D. W. J. R., 2000, APPL LOGISTIC REGRES; KLEINODER T, 2003, CHEMOINFORMATICS, P487, DOI 10.1002/3527601643.ch10; Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence; KRAJCSI P, 2002, HIGH ADME TOX ESTIMA, P75; Manel S, 2001, J APPL ECOL, V38, P921, DOI 10.1046/j.1365-2664.2001.00647.x; Nendza M., 2000, QUANT STRUCT-ACT REL, V19, P581, DOI 10.1002/1521-3838(200012)19:6<581::AID-QSAR581>3.0.CO;2-A; Nouwen J, 1997, ENVIRON SCI TECHNOL, V31, P2313, DOI 10.1021/es9609213; *R FDN STAT COMP, 2003, R DEV COR TEAM R LAN; Rand GM, 1995, FUNDAMENTALS AQUATIC, P3; Ripley BD, 1996, PATTERN RECOGNITION; Russom CL, 1997, ENVIRON TOXICOL CHEM, V16, P948, DOI 10.1897/1551-5028(1997)016<0948:PMOTAF>2.3.CO;2; SAUERBREI W, 1999, APPL STAT, V48, P313; Schmidt RR, 1997, PROC BRIGHTON CROP, P1133; SIMCA P, 2001, VERSION 9 0; *SONNIA, 2002, VERSION 4 1; SPSS, 2002, SPSS WIND VERS 11 5; Steyerberg EW, 2001, MED DECIS MAKING, V21, P45; TECKENTRUP A, 2000, THESIS FRIEDRICH ALE; TERADA H, 1990, ENVIRON HEALTH PERSP, V87, P213, DOI 10.2307/3431027; Wehrens R, 2000, CHEMOMETR INTELL LAB, V54, P35, DOI 10.1016/S0169-7439(00)00102-7; Wenzel A, 1997, CHEMOSPHERE, V35, P307, DOI 10.1016/S0045-6535(97)00157-4; Worth AP, 1998, ATLA-ALTERN LAB ANIM, V26, P241; ZUPAN J, 1995, CHEMOMETR INTELL LAB, V27, P175, DOI 10.1016/0169-7439(94)00016-C; Zupan J., 1999, NEURAL NETWORKS CHEM; ZUPAN J, 1994, ANAL CHIM ACTA, V292, P219, DOI 10.1016/0003-2670(94)00085-9	47	26	26	WILEY-V C H VERLAG GMBH	WEINHEIM	BOSCHSTRASSE 12, D-69469 WEINHEIM, GERMANY	1611-020X	1611-0218		QSAR COMB SCI	QSAR Comb. Sci.	NOV	2004	23	9					779	791		10.1002/qsar.200430877		13	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Interdisciplinary Applications; Pharmacology & Pharmacy	Pharmacology & Pharmacy; Chemistry; Computer Science	875MZ	WOS:000225425800007		
J	Elmore, RT; Hettmansperger, TP; Xuan, F				Elmore, RT; Hettmansperger, TP; Xuan, F			The sign statistic, one-way layouts and mixture models	STATISTICAL SCIENCE			English	Article						binomial mixtures; cut-point models; EM algorithm; Bayesian information criterion; Mood's test		We consider the use of sign statistics in two different types of one-way layouts. The first layout is for data collected to compare several treatments. The second layout is for independent repeated measures on several subjects. In the first case we discuss hypothesis testing and multiple comparisons. In the second case we fit mixture models. We then show how fitting mixture models can be helpful in follow-up multiple comparisons in the first case.	Penn State Univ, Dept Stat, University Pk, PA 16802 USA	Elmore, RT (reprint author), Australian Natl Univ, Canberra, ACT, Australia.	tph@stat.psu.edu					Cruz-Medina IR, 2004, J ROY STAT SOC C-APP, V53, P463, DOI 10.1111/j.1467-9876.2004.05203.x; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Efron Bradley, 1993, INTRO BOOTSTRAP; ELMORE RT, 2003, THESISPENNSYLVANIA S; Hastie T., 2001, ELEMENTS STAT LEARNI; Hettmansperger T. P., 1998, ROBUST NONPARAMETRIC; Hettmansperger TP, 2000, J ROY STAT SOC B, V62, P811, DOI 10.1111/1467-9868.00266; McLachlan GJ, 2000, FINITE MIXTURE MODEL; McLachlan GJ, 1997, EM ALGORITHM EXTENSI; Mood AM, 1950, INTRO THEORY STAT; Schafer JL, 1997, ANAL INCOMPLETE MULT; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136	12	1	1	INST MATHEMATICAL STATISTICS	BEACHWOOD	PO BOX 22718, BEACHWOOD, OH 44122 USA	0883-4237			STAT SCI	Stat. Sci.	NOV	2004	19	4					579	587		10.1214/088342304000000459		9	Statistics & Probability	Mathematics	921SD	WOS:000228784100004		
J	Schucany, WR				Schucany, WR			Kernel smoothers: An overview of curve estimators for the first graduate course in nonparametric statistics	STATISTICAL SCIENCE			English	Article						local polynomial regression; AIC; variable bandwidths; cross validation; windows	PROBABILITY DENSITY; CROSS-VALIDATION; REGRESSION; SELECTION; EFFICIENCY; SPLINE	An introduction to nonparametric regression is accomplished with selected real data sets, statistical graphics and simulations from known functions. It is pedagogically effective for many to have some initial intuition about what the techniques are and why they work. Visual displays of small examples along with the plots of several types of smoothers are a good beginning. Some students benefit from a brief historical development of the topic, provided that they are familiar with other methodology, such as linear regression. Ultimately, one must engage the formulas for some of the linear curve estimators. These mathematical expressions for local smoothers are more easily understood after the student has seen a graph and a description of what the procedure is actually doing. In this article there are several such figures. These are mostly scatterplots of a single response against one predictor. Kernel smoothers have series expansions for bias and variance. The leading terms of those expansions yield approximate expressions for asymptotic mean squared error. In turn these provide one criterion for selection of the bandwidth. This choice of a smoothing parameter is done a rich variety of ways in practice. The final sections cover alternative approaches and extensions. The survey is supplemented with citations to some excellent books and articles. These provide the student with an entry into the literature, which is rapidly developing in traditional print media as well as on line.	So Methodist Univ, Dept Stat Sci, Dallas, TX 75275 USA	Schucany, WR (reprint author), So Methodist Univ, Dept Stat Sci, Dallas, TX 75275 USA.	schucany@smu.edu					ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209; Bartlett MS, 1963, SANKHYA A, V25, P245; BENEDETTI JK, 1977, J ROY STAT SOC B MET, V39, P248; Chu CK, 1992, STAT SCI, V6, P404, DOI 10.1214/ss/1177011586; CLEVELAND WS, 1979, J AM STAT ASSOC, V74, P829, DOI 10.2307/2286407; EPANECHN.VA, 1969, THEOR PROBAB APPL+, V14, P153, DOI 10.1137/1114019; Eubank R.L., 1999, NONPARAMETRIC REGRES; Fan J., 1996, LOCAL POLYNOMIAL MOD; FAN JQ, 1995, J ROY STAT SOC B MET, V57, P371; FAN JQ, 1992, J AM STAT ASSOC, V87, P998, DOI 10.2307/2290637; Gasser T., 1979, LECT NOTES MATH, V757, P23; Gerard P. D., 1997, Journal of Agricultural, Biological, and Environmental Statistics, V2, P255, DOI 10.2307/1400445; Hart JD, 2005, J MULTIVARIATE ANAL, V92, P77, DOI 10.1016/j.jmva.2003.08.005; Hart JD, 1997, NONPARAMETRIC SMOOTH; Hastie T., 2001, ELEMENTS STAT LEARNI; HODGES JL, 1956, ANN MATH STAT, V27, P324, DOI 10.1214/aoms/1177728261; HURVICH CM, 1989, BIOMETRIKA, V76, P297, DOI 10.1093/biomet/76.2.297; Hurvich CM, 1998, J ROY STAT SOC B, V60, P271, DOI 10.1111/1467-9868.00125; JIA A, 2004, UNPUB; Lin XH, 2004, BIOMETRIKA, V91, P177, DOI 10.1093/biomet/91.1.177; Loader C., 1999, LOCAL REGRESSION LIK; Loader CR, 1996, ANN STAT, V24, P1667; MULLER HG, 1987, J AM STAT ASSOC, V82, P231, DOI 10.2307/2289159; MULLER HG, 1992, ANN STAT, V20, P737, DOI 10.1214/aos/1176348654; Nadaraya E. A., 1964, THEOR PROBAB APPL, V10, P186; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PITBLADO J, 2000, THESIS DEP STAT SCI; PRIESTLE.MB, 1972, J ROY STAT SOC B, V34, P385; Ramsay J. O., 1997, FUNCTIONAL DATA ANAL; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; RUPPERT D, 2003, SEMI PARAMETRIC REGR; Ruppert D, 1997, J AM STAT ASSOC, V92, P1049, DOI 10.2307/2965570; SCHLEE W, 1988, ENCY STAT SCI, V8, P1; Scott D. W., 1992, MULTIVARIATE DENSITY; SHEATHER S, 2005, STAT SCI, V19, P588; Signorini DF, 2004, J AM STAT ASSOC, V99, P119, DOI 10.1198/016214504000000115; Silverman BW, 1986, DENSITY ESTIMATION S; Spencer J., 1904, J I ACT, V38, P334; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; Tukey J., 1961, P 4 BERK S MATH STAT, V1, P681; Ullah A., 1985, J QUANTITATIVE EC, V1, P187; WAHBA G, 1975, COMMUN STAT, V4, P1; Wand MP, 1995, KERNEL SMOOTHING; WATSON G., 1964, SANKHYA A, V26, P359; Welsh AH, 2002, J AM STAT ASSOC, V97, P482, DOI 10.1198/016214502760047014	45	13	13	INST MATHEMATICAL STATISTICS	BEACHWOOD	PO BOX 22718, BEACHWOOD, OH 44122 USA	0883-4237			STAT SCI	Stat. Sci.	NOV	2004	19	4					663	675		10.1214/088342304000000756		13	Statistics & Probability	Mathematics	921SD	WOS:000228784100013		
J	Schaap, MG; Nemes, A; van Genuchten, MT				Schaap, MG; Nemes, A; van Genuchten, MT			Comparison of models for indirect estimation of water retention and available water in surface soils	VADOSE ZONE JOURNAL			English	Article							PEDO-TRANSFER FUNCTIONS; PEDOTRANSFER FUNCTIONS; HYDRAULIC CONDUCTIVITY; NEURAL NETWORKS; PREDICTION; CURVES; ACCURACY; DATABASE	Quantitative knowledge of the unsaturated soil hydraulic properties is required in most studies involving water flow and solute transport in the vadose zone. Unfortunately, direct measurement of such properties is often difficult, expensive and time-consuming. Pedotransfer functions (PTFs) offer a means to estimate soil hydraulic properties based on predictors like texture, bulk density, and other soil variables. In this study, we focus on PTFs for water retention and show that systematic errors in five existing PTFs can be reduced by using water content - based objective functions, instead of parameter value - based objective functions. The alternative analysis was accomplished by establishing offset and slope coefficients for each estimated hydraulic parameter. Subsequently we evaluated these and six other PTFs for estimating water retention parameters using the NRCS soils database. A total of 47 435 records containing 113 970 observed water contents were used to test the PTFs for mean errors and root mean square errors. No overall superior model was found. Models with many calibration parameters or more input variables were not necessarily better than more simple models. All models underestimated water contents, with values ranging from - 0.0086 to - 0.0279 cm(3) cm(-3). Average root mean square errors ranged from 0.0687 cm(3) cm(-3) for a PTF that provided textural class average parameters to 0.0315 cm(3) cm(-3) for a model that also used two water retention points as predictors. Available soil water content for vegetation was estimated with errors ranging from 0.058 to 0.080 cm(3) cm(-3), depending on the model and the definition of available water.	ARS, George E Brown Jr Salin Lab, USDA, Riverside, CA 92507 USA; Hungarian Acad Sci, Res Inst Soil Sci & Agr Chem, H-1525 Budapest, Hungary	Schaap, MG (reprint author), ARS, George E Brown Jr Salin Lab, USDA, 450 W Big Springs Rd, Riverside, CA 92507 USA.	mschaap@ussl.ars.usda.gov	van Genuchten, Martinus/K-6892-2013	van Genuchten, Martinus/0000-0003-1654-8858			Brooks R. J., 1964, 3 COL STAT U; CAMPBELL GS, 1974, SOIL SCI, V117, P311; CARSEL RF, 1988, WATER RESOUR RES, V24, P755, DOI 10.1029/WR024i005p00755; COSBY BJ, 1984, WATER RESOUR RES, V20, P683; Hastie T., 2001, ELEMENTS STAT LEARNI; HOLTAN HN, 1968, 41144 ARS USDA; KERN JS, 1995, SOIL SCI SOC AM J, V59, P1134; MEYER PD, 1999, P INT WORKSH CHAR ME, P1439; Minasny B, 2002, SOIL SCI SOC AM J, V66, P352; Minasny B, 1999, GEODERMA, V93, P225, DOI 10.1016/S0016-7061(99)00061-0; Nelson D. W., 1982, Methods of soil analysis. Part 2. Chemical and microbiological properties, P539; Pachepsky YA, 1996, SOIL SCI SOC AM J, V60, P727; Rawls W. J., 1985, Watershed management in the eighties., P293; RAWLS WJ, 1976, USDAARSS113; Rawls W. J., 1991, Advances in Soil Science, V16, P213; Schaap MG, 1998, SOIL SCI, V163, P765, DOI 10.1097/00010694-199810000-00001; Schaap MG, 1996, WATER RESOUR RES, V32, P3033, DOI 10.1029/96WR02278; Schaap MG, 2001, J HYDROL, V251, P163, DOI 10.1016/S0022-1694(01)00466-8; Schaap MG, 2000, SOIL SCI SOC AM J, V64, P843; Schaap MG, 1998, SOIL SCI SOC AM J, V62, P847; Scheinost AC, 1997, GEODERMA, V78, P129, DOI 10.1016/S0016-7061(97)00046-3; *SOIL SURV STAFF, 1996, 42 NATL SOIL SURV CT; *SOIL SURV STAFF, 1995, 45 NATL SOIL SURV CT; TIETJE O, 1993, SOIL SCI SOC AM J, V57, P1088; Tietje O, 1996, GEODERMA, V69, P71, DOI 10.1016/0016-7061(95)00050-X; VANGENUCHTEN MT, 1980, SOIL SCI SOC AM J, V44, P892; VEREECKEN H, 1989, SOIL SCI, V148, P389; Wosten JHM, 1999, GEODERMA, V90, P169, DOI 10.1016/S0016-7061(98)00132-3; Wosten JHM, 2001, J HYDROL, V251, P123, DOI 10.1016/S0022-1694(01)00464-4	29	17	17	SOIL SCI SOC AMER	MADISON	677 SOUTH SEGOE ROAD, MADISON, WI 53711 USA	1539-1663			VADOSE ZONE J	Vadose Zone J.	NOV	2004	3	4					1455	1463				9	Environmental Sciences; Soil Science; Water Resources	Environmental Sciences & Ecology; Agriculture; Water Resources	904BD	WOS:000227469200040		
J	Wiles, L; Brodahl, M				Wiles, L; Brodahl, M			Exploratory data analysis to identify factors influencing spatial distributions of weed seed banks	WEED SCIENCE			English	Article						classification and regression tree analysis; seed bank dynamics; spatial dynamics; anisotropy; spatial dependence; geostatistics; spatial correlation; correlograms; seed dispersal; seed longevity; irrigation	IRRIGATION WATER; PATTERN-ANALYSIS; SOIL; MODEL; POPULATIONS; CULTIVATION; DEPENDENCE; STABILITY; PRECISION; MOVEMENT	Comparing distributions among fields, species, and management practices will help us understand the spatial dynamics of weed seed banks, but analyzing observational data requires nontraditional statistical methods. We used cluster analysis and classification and regression tree analysis (CART) to investigate factors that influence spatial distributions of seed banks. CART is a method for developing predictive models, but it is also used to explain variation in a response variable from a set of possible explanatory variables. With cluster analysis, we identified patterns of variation with direction of the distance over which seed bank density was correlated (range of spatial dependence) with single-species seed banks in corn. Then we predicted patterns of the seed banks with CART using field and species characteristics and seed bank density as explanatory variables. Patterns differed by magnitude of variation in the range of spatial dependence (strength of anisotropy) and direction of the maximum range. Density and type of irrigation explained the most variation in pattern. Long ranges were associated with large seed banks and stronger anisotropy with furrow than center pivot irrigation. Pattern was also explained by seed size and longevity, characteristics for natural dispersal, species, soil texture, and whether the weed was a grass or broadleaf, Significance of these factors depended on density or type of irrigation, and some patterns were predicted for more than one combination of factors. Dispersal was identified as a primary process of spatial dynamics and pattern varied for seed spread by tillage, wind, or natural dispersal. However, demographic characteristics and density were more important in this research than in previous research. Impact of these factors may have been clearer because interactions were modeled. Lack of data will be the greatest obstacle to using comparative studies and CART to understand the spatial dynamics of weed seed banks.	USDA ARS, Water Management Res Unit, Ft Collins, CO 80526 USA	Wiles, L (reprint author), USDA ARS, Water Management Res Unit, Ft Collins, CO 80526 USA.	lori.wiles@ars.usda.gov					Ambrosio L, 1997, WEED RES, V37, P129, DOI 10.1046/j.1365-3180.1997.d01-22.x; AUDSLEY E, 1996, ASPECTS APPL BIOL, V46, P11; BENOIT DL, 1989, CAN J BOT, V67, P2833; BIGWOOD DW, 1988, ECOLOGY, V69, P497, DOI 10.2307/1940448; BURGESS TM, 1981, J SOIL SCI, V32, P643; BURROUGH P. A., 1991, SSSA SPECIAL PUBLICA, P89; Cardina J, 1996, WEED SCI, V44, P298; Cardina J, 1997, WEED SCI, V45, P364; CHAUVEL B, 1989, WEED RES, V29, P213, DOI 10.1111/j.1365-3180.1989.tb00861.x; Clark LA, 1992, STAT MODELS S, P377; Colbach N, 2000, WEED SCI, V48, P366, DOI 10.1614/0043-1745(2000)048[0366:SATSOW]2.0.CO;2; COUSENS R, 1995, DYNAMICS WEED POPULA, P217, DOI 10.1017/CBO9780511608629.008; Cousens RD, 1997, PROC BRIGHTON CROP, P613; DALE MRT, 2000, SPATIAL PATTERN ANAL, P1; DASTGHEIB F, 1989, WEED RES, V29, P113, DOI 10.1111/j.1365-3180.1989.tb00848.x; De'ath G, 2000, ECOLOGY, V81, P3178, DOI 10.1890/0012-9658(2000)081[3178:CARTAP]2.0.CO;2; Dessaint F, 1996, WEED RES, V36, P143, DOI 10.1111/j.1365-3180.1996.tb01810.x; DESSAINT F, 1991, J APPL ECOL, V28, P721, DOI 10.2307/2404578; DEUTSCH CV, 1998, GSLIB GEOSTATISTICAL, P24; Dieleman J. A., 1999, Precision agriculture '99, Part 1 and Part 2. Papers presented at the 2nd European Conference on Precision Agriculture, Odense, Denmark, 11-15 July 1999, P517; Dobbertin M, 1998, FOREST SCI, V44, P507; FLATMAN GT, 1988, PRINCIPLES ENV SAMPL, P73; FORD ED, 1984, VEGETATIO, V56, P113; GHERSA CM, 1993, BIOSCIENCE, V43, P104, DOI 10.2307/1311971; Gotway C. A., 1996, Precision agriculture. Proceedings of the 3rd International Conference, Minneapolis, Minnesota, USA, 23-26 June 1996., P321; Grundy AC, 1999, J APPL ECOL, V36, P663, DOI 10.1046/j.1365-2664.1999.00438.x; Hallam M, 2000, HDB APPL MULTIVARIAT, P125, DOI 10.1016/B978-012691360-6/50006-9; HALSTEAD S. J., 1990, P N CENT WEED SCI SO, V45, P123; Hastie T, 2001, ELEMENTS STAT LEARNI, P453; Häusler A., 1999, Precision agriculture '99, Part 1 and Part 2. Papers presented at the 2nd European Conference on Precision Agriculture, Odense, Denmark, 11-15 July 1999, P463; Heisel T., 1999, Precision agriculture '99, Part 1 and Part 2. Papers presented at the 2nd European Conference on Precision Agriculture, Odense, Denmark, 11-15 July 1999, P759; HOWARD CL, 1991, 1991 P BRIGHT CROP P, V5, P821; Isaaks E.H., 1989, INTRO APPL GEOSTATIS, P140; JOHNSON GA, 1997, STATE SITE SPECIFIC, P131; JONES NE, 1998, ASPECTS APPL BIOL, V51, P1; KELLEY AD, 1975, WEED SCI, V23, P486; MARSHALL EJP, 1989, J APPL ECOL, V26, P247, DOI 10.2307/2403665; Mead A., 1998, ASPECTS APPL BIOL, P91; MORTENSEN DA, 1993, P SOIL SPEC CROP MAN; NORDMEYER H, 1997, PRECISION AGR 97, V1, P307; Oliver M. A., 1997, Precision agriculture '97. Volume I. Spatial variability in soil and crop. Papers presented at the First European Conference on Precision Agriculture, Warwick University, UK, 7-10 September 1997., P155; OLIVER MA, 1999, P 2 EUR C PREC AGR O, P463; Paice MER, 1998, WEED RES, V38, P373; Rew LJ, 2001, WEED RES, V41, P1, DOI 10.1046/j.1365-3180.2001.00215.x; Rew LJ, 1997, WEED RES, V37, P247, DOI 10.1046/j.1365-3180.1997.d01-39.x; REY LJ, 1995, P 1995 BRIGHT CROP P, P1059; ROSSI RE, 1992, ECOL MONOGR, V62, P277, DOI 10.2307/2937096; *STAT AN SYST I, 1988, SAS STAT US GUID, P283; Venables W. N., 1999, MODERN APPL STAT S P, P303; Walter A. M., 1997, Precision agriculture '97. Volume II. Technology, IT and management. Papers presented at the First European Conference on Precision Agriculture, Warwick University, UK, 7-10 September 1997., P777; WEISZ R, 1995, J ECON ENTOMOL, V88, P1069; Wiles L, 2002, WEED SCI, V50, P595, DOI 10.1614/0043-1745(2002)050[0595:SDOWSB]2.0.CO;2; Wiles LJ, 1996, WEED TECHNOL, V10, P35; WILSON BJ, 1991, WEED RES, V31, P367, DOI 10.1111/j.1365-3180.1991.tb01776.x; 1999, SPATIAL GEOSTATISTIC, P27	55	18	18	WEED SCI SOC AMER	LAWRENCE	810 EAST 10TH ST, LAWRENCE, KS 66044-8897 USA	0043-1745			WEED SCI	Weed Sci.	NOV-DEC	2004	52	6					936	947		10.1614/WS-03-068R		12	Agronomy; Plant Sciences	Agriculture; Plant Sciences	871RF	WOS:000225150300005		
J	Thissen, U; Pepers, M; Ustun, B; Melssen, WJ; Buydens, LMC				Thissen, U; Pepers, M; Ustun, B; Melssen, WJ; Buydens, LMC			Comparing support vector machines to PLS for spectral regression applications	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS			English	Article						support vector machines (SVM); Partial Least Squares (PLS); quality control; nonlinear regression; near-infrared (NIR) spectroscopy; Raman spectroscopy	MULTIVARIATE CALIBRATION; RAMAN-SPECTROSCOPY; TEMPERATURE; MODELS	In order to on-line control the quality of industrial products, often spectroscopic methods are used in combination with regression tools. Partial Least Squares (PLS) is the most used regression technique for this task whereas Support Vector Machines (SVMs) are hardly known and used in chemometrics. Theoretically, regression by SVMs (SVR) can be very useful due to its ability to find nonlinear, global solutions and its ability to work with high dimensional input vectors. This paper compares the use and the performance of PLS and SVR for two spectral regression applications. The first application is the use of both high-resolution Raman spectra and low-resolution Raman spectra (which are cheaper to measure) for the determination of two monomer masses during a copolymerisation reaction. In the second application near-infrared (NIR) spectra are used to determine ethanol, water, and iso-propanol mole fractions in a ternary mixture. The NIR spectra used suffer from nonlinear temperature-induced variation which can affect the predictions. Clearly, for both applications, SVR outperformed PLS. With SVR, the usage of the cheaper low-resolution Raman spectra becomes more feasible in industrial applications. Furthermore, regression by SVR appears to be more robust with respect to nonlinear effects induced by variations in temperature. (C) 2004 Elsevier B.V. All rights reserved.	Univ Nijmegen, Analyt Chem Lab, NL-6525 ED Nijmegen, Netherlands; Eindhoven Univ Technol, Dept Polymer Chem & Coating Technol, NL-5600 MB Eindhoven, Netherlands	Buydens, LMC (reprint author), Univ Nijmegen, Analyt Chem Lab, Toernooiveld 1, NL-6525 ED Nijmegen, Netherlands.		Buydens, Lutgarde/D-4338-2012				BARNES RJ, 1989, APPL SPECTROSC, V43, P772, DOI 10.1366/0003702894202201; Belousov AI, 2002, CHEMOMETR INTELL LAB, V64, P15, DOI 10.1016/S0169-7439(02)00046-1; Belousov AI, 2002, J CHEMOMETR, V16, P482, DOI 10.1002/cem.744; Brookes A, 1997, SPECTROCHIM ACTA A, V53, P2303, DOI 10.1016/S1386-1425(97)00170-4; Centner V, 2000, APPL SPECTROSC, V54, P608, DOI 10.1366/0003702001949816; Cristianini N, 2000, INTRO SUPPORT VECTOR; Despagne F, 2000, ANAL CHEM, V72, P1657, DOI 10.1021/ac991076k; Estienne F, 2001, ANAL CHIM ACTA, V450, P123, DOI 10.1016/S0003-2670(01)01372-1; Geladi P, 2003, SPECTROCHIM ACTA B, V58, P767, DOI 10.1016/S0584-8547(03)00037-5; Gunn S.R., 1997, SUPPORT VECTOR MACHI; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hastie T., 2001, ELEMENTS STAT LEARNI; KROGH A, 1995, ADV NEURAL INFORMATI, V4; PEPERS M, 2004, THESIS EINDHOVEN U T; Rakotomamonjy A., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753706; SAVITZKY A, 1964, ANAL CHEM, V36, P1627, DOI 10.1021/ac60214a047; Scholkopf B, 2002, LEARNING KERNELS; Song MH, 2002, J CHEM INF COMP SCI, V42, P1347, DOI 10.1021/ci025580t; Suykens J. A. K., 2002, LEAST SQUARES SUPPOR; Swierenga H, 2000, ANAL CHIM ACTA, V411, P121, DOI 10.1016/S0003-2670(00)00718-2; Thissen U., 2003, Chemometrics and Intelligent Laboratory Systems, V69, DOI 10.1016/S0169-7439(03)00111-4; Van den Brink M, 2001, J APPL POLYM SCI, V79, P426; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik VN, 1995, NATURE STAT LEARNING; WESTON J, 2000, ADV NEURAL INF PROCE, V13; Witjes H, 2000, CHEMOMETR INTELL LAB, V52, P105, DOI 10.1016/S0169-7439(00)00085-X; Wulfert F, 2000, ANAL CHEM, V72, P1639, DOI 10.1021/ac9906835; Wulfert F, 2000, CHEMOMETR INTELL LAB, V51, P189, DOI 10.1016/S0169-7439(00)00069-1; Wulfert F, 1998, ANAL CHEM, V70, P1761, DOI 10.1021/ac9709920; Zhu J., 1 NORM SUPPORT VECTO	30	120	130	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-7439			CHEMOMETR INTELL LAB	Chemometrics Intell. Lab. Syst.	OCT 28	2004	73	2					169	179		10.1016/j.chemolab.2004.01.002		11	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	860TB	WOS:000224365000002		
J	Frederiksen, SL; Jacobsen, KW; Brown, KS; Sethna, JP				Frederiksen, SL; Jacobsen, KW; Brown, KS; Sethna, JP			Bayesian ensemble approach to error estimation of interatomic potentials	PHYSICAL REVIEW LETTERS			English	Article							METALS	Using a Bayesian approach a general method is developed to assess error bars on predictions made by models fitted to data. The error bars are estimated from fluctuations in ensembles of models sampling the model-parameter space with a probability density set by the minimum cost. The method is applied to the development of interatomic potentials for molybdenum using various potential forms and databases based on atomic forces. The calculated error bars on elastic constants, gamma-surface energies, structural energies, and dislocation properties are shown to provide realistic estimates of the actual errors for the potentials.	Tech Univ Denmark, Dept Phys, CAMP, DK-2800 Lyngby, Denmark; Cornell Univ, Atom & Solid State Phys Lab, Ithaca, NY 14853 USA	Frederiksen, SL (reprint author), Tech Univ Denmark, Dept Phys, CAMP, DK-2800 Lyngby, Denmark.		Jacobsen, Karsten/B-3602-2009				Bahn SR, 2002, COMPUT SCI ENG, V4, P56, DOI 10.1109/5992.998641; BASKES MI, 1992, PHYS REV B, V46, P2727, DOI 10.1103/PhysRevB.46.2727; Brown KS, 2003, PHYS REV E, V68, DOI 10.1103/PhysRevE.68.021904; ERCOLESSI F, 1994, EUROPHYS LETT, V26, P583, DOI 10.1209/0295-5075/26/8/005; Finnis M. W., 2003, INTERATOMIC FORCES C; FINNIS MW, 1984, PHILOS MAG A, V50, P45; FREDERIKSEN SL, IN PRESS; Hammer B, 1999, PHYS REV B, V59, P7413, DOI 10.1103/PhysRevB.59.7413; Hastie T., 2001, ELEMENTS STAT LEARNI; Hollang L, 1997, PHYS STATUS SOLIDI A, V160, P329, DOI 10.1002/1521-396X(199704)160:2<329::AID-PSSA329>3.0.CO;2-O; Jacobsen KW, 1996, SURF SCI, V366, P394, DOI 10.1016/0039-6028(96)00816-3; Jaynes E, 2003, PROBABILITY THEORY; Li YH, 2003, PHYS REV B, V67, DOI 10.1103/PhysRevB.67.125101; Mishin Y, 1999, PHYS REV B, V59, P3393, DOI 10.1103/PhysRevB.59.3393; PERDEW JP, 1992, PHYS REV B, V46, P6671, DOI 10.1103/PhysRevB.46.6671; Simmons G., 1971, SINGLE CRYSTAL ELAST; VANDERBILT D, 1990, PHYS REV B, V41, P7892, DOI 10.1103/PhysRevB.41.7892	17	26	26	AMERICAN PHYSICAL SOC	COLLEGE PK	ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA	0031-9007			PHYS REV LETT	Phys. Rev. Lett.	OCT 15	2004	93	16							165501	10.1103/PhysRevLett.93.165501		4	Physics, Multidisciplinary	Physics	863AT	WOS:000224533300044	15525000	
J	Poggio, T; Bizzi, E				Poggio, T; Bizzi, E			Generalization in vision and motor control	NATURE			English	Article							INFERIOR TEMPORAL NEURONS; VISUAL-CORTEX; OBJECT RECOGNITION; RECEPTIVE-FIELDS; MODULAR ORGANIZATION; SIMPLE CELLS; FORCE-FIELD; MACAQUE; MONKEYS; REPRESENTATION	Learning is more than memory. It is not simply the building of a look-up table of labelled images, or a phone-directory-like list of motor acts and the corresponding sequences of muscle activation. Central to learning and intelligence is the ability to predict, that is, to generalize to new situations, beyond the memory of specific examples. The key to generalization, in turn, is the architecture of the system, more than the rules of synaptic plasticity. We propose a specific architecture for generalization for both the motor and the visual systems, and argue for a canonical microcircuit underlying visual and motor learning.	MIT, McGovern Inst,Ctr Biol & Computat Learning, Dept Brain & Cognit Sci, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02142 USA; European Brain Res Inst, I-00143 Rome, Italy	Poggio, T (reprint author), MIT, McGovern Inst,Ctr Biol & Computat Learning, Dept Brain & Cognit Sci, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02142 USA.	tp@ai.mit.edu; ebizzi@mit.edu					Amirikian B, 2003, P NATL ACAD SCI USA, V100, P12474, DOI 10.1073/pnas.2037719100; Aoyagi Y, 2004, IEEE T NEUR SYS REH, V12, P12, DOI 10.1109/TNSRE.2003.823265; BELKIN M, 2004, TR200405 U CHIC; BIZZI E, 1991, SCIENCE, V253, P287, DOI 10.1126/science.1857964; Booth MCA, 1998, CEREB CORTEX, V8, P510, DOI 10.1093/cercor/8.6.510; Borg-Graham LJ, 1998, NATURE, V393, P369; BRUCE C, 1981, J NEUROPHYSIOL, V46, P369; BULTHOFF HH, 1992, P NATL ACAD SCI USA, V89, P60, DOI 10.1073/pnas.89.1.60; CARANDINI M, 1994, SCIENCE, V264, P1333, DOI 10.1126/science.8191289; Carandini M, 1997, J NEUROSCI, V17, P8621; Chance FS, 1999, NAT NEUROSCI, V2, P277; d'Avella A, 2003, NAT NEUROSCI, V6, P300, DOI 10.1038/nn1010; DiCarlo JJ, 2000, NAT NEUROSCI, V3, P814, DOI 10.1038/77722; DOUGLAS RJ, 1991, J PHYSIOL-LONDON, V440, P735; Douglas RJ, 2004, ANNU REV NEUROSCI, V27, P419, DOI 10.1146/annurev.neuro.27.070203.144152; Gandolfo F, 2000, P NATL ACAD SCI USA, V97, P2259, DOI 10.1073/pnas.040567097; GEORGOPOULOS AP, 1982, J NEUROSCI, V2, P1527; Giese MA, 2003, NAT REV NEUROSCI, V4, P179, DOI 10.1038/nrn1057; Gribble PL, 2002, NATURE, V417, P938, DOI 10.1038/nature00834; Grillner S., 1981, HDB PHYSL 1, VII, P1179; GRILLNER S, 1985, ANNU REV NEUROSCI, V8, P233, DOI 10.1146/annurev.ne.08.030185.001313; GROSS CG, 1973, HDB SENSORY PHYSL, V7; Hastie T., 2001, ELEMENTS STAT LEARNI; HIETANEN JK, 1992, EXP BRAIN RES, V89, P157; HOGAN N, 1984, J NEUROSCI, V4, P2745; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; HUBEL DH, 1965, J NEUROPHYSIOL, V28, P229; Jing J, 2004, J NEUROSCI, V24, P6315, DOI 10.1523/JNEUROSCI.0965-04.2004; Kargo WJ, 2000, J NEUROSCI, V20, P409; KOBATAKE E, 1994, J NEUROPHYSIOL, V71, P856; Kobatake E, 1998, J NEUROPHYSIOL, V80, P324; Lemay MA, 2001, IEEE T NEUR SYS REH, V9, P12, DOI 10.1109/7333.918272; Li CSR, 2001, NEURON, V30, P593, DOI 10.1016/S0896-6273(01)00301-4; LOEB GE, 1985, J EXP BIOL, V115, P137; LOGOTHETIS NK, 1995, CURR BIOL, V5, P552, DOI 10.1016/S0960-9822(95)00108-4; Logothetis NK, 1996, ANNU REV NEUROSCI, V19, P577, DOI 10.1146/annurev.ne.19.030196.003045; MARUYAMA M, 1992, 1291 GRBF MLP MIT; MERZENIC.MM, 1973, BRAIN RES, V50, P275, DOI 10.1016/0006-8993(73)90731-2; Missal M, 1997, CEREB CORTEX, V7, P758, DOI 10.1093/cercor/7.8.758; MOUNTCASTLE VB, 1957, J NEUROPHYSIOL, V20, P408; Mussa-Ivaldi F. A., 1997, Proceedings. 1997 IEEE International Symposium on Computational Intelligence in Robotics and Automation CIRA'97. `Towards New Computational Principles for Robotics and Automation' (Cat. No.97TB100176), DOI 10.1109/CIRA.1997.613842; MUSSAIVALDI FA, 1994, P NATL ACAD SCI USA, V91, P7534, DOI 10.1073/pnas.91.16.7534; Mussa-Ivaldi FA, 2000, PHILOS T ROY SOC B, V355, P1755; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Palmeri TJ, 2004, NAT REV NEUROSCI, V5, P291, DOI 10.1038/nrn1364; Paz R, 2003, NAT NEUROSCI, V6, P882, DOI 10.1038/nn1097; PERRETT DI, 1993, IMAGE VISION COMPUT, V11, P317, DOI 10.1016/0262-8856(93)90011-5; PERRETT DI, 1991, EXP BRAIN RES, V86, P159; Poggio T., 2003, NOTICES AMS, V50, P537; POGGIO TA, 1990, COLD SPRING HARB SYM, V4, P899; Pouget A, 2003, ANNU REV NEUROSCI, V26, P381, DOI 10.1146/annurev.neuro.26.041002.131112; Pouget A, 1997, J COGNITIVE NEUROSCI, V9, P222, DOI 10.1162/jocn.1997.9.2.222; REICHARDT W, 1983, BIOL CYBERN, V46, P1, DOI 10.1007/BF00595226; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Riesenhuber M., 2003, VISUAL NEUROSCIENCES, V2, P1640; RODMAN HR, 1993, J NEUROPHYSIOL, V70, P1115; SALINAS E, 1995, J NEUROSCI, V15, P6461; Saltiel P, 1998, J NEUROPHYSIOL, V80, P2323; SATO T, 1989, EXP BRAIN RES, V77, P23; SHADMEHR R, 1994, J NEUROSCI, V14, P3208; STEIN PSG, 1995, J NEUROSCI, V15, P4343; TANAKA K, 1993, SCIENCE, V262, P685, DOI 10.1126/science.8235589; THOROUGHMAN K, 2000, NATURE, V407, P740; Tresch MC, 1999, EXP BRAIN RES, V129, P401, DOI 10.1007/s002210050908; Vapnik V., 1998, STAT LEARNING THEORY; Wise SP, 1998, EXP BRAIN RES, V121, P285, DOI 10.1007/s002210050462; Yu AJ, 2002, NEURAL COMPUT, V14, P2857, DOI 10.1162/089976602760805313	67	144	148	NATURE PUBLISHING GROUP	LONDON	MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	0028-0836			NATURE	Nature	OCT 14	2004	431	7010					768	774		10.1038/nature03014		7	Multidisciplinary Sciences	Science & Technology - Other Topics	861RE	WOS:000224435500032	15483597	
J	Li, T; Zhang, CL; Ogihara, M				Li, T; Zhang, CL; Ogihara, M			A comparative study of feature selection and multiclass classification methods for tissue classification based on gene expression	BIOINFORMATICS			English	Article							SUPPORT VECTOR MACHINES; DNA ARRAYS; CANCER; PREDICTION; PROFILES; PATTERNS; IDENTIFICATION; SIGNATURES; DISCOVERY; NETWORKS	This paper studies the problem of building multiclass classifiers for tissue classification based on gene expression. The recent development of microarray technologies has enabled biologists to quantify gene expression of tens of thousands of genes in a single experiment. Biologists have begun collecting gene expression for a large number of samples. One of the urgent issues in the use of microarray data is to develop methods for characterizing samples based on their gene expression. The most basic step in the research direction is binary sample classification, which has been studied extensively over the past few years. This paper investigates the next step-multiclass classification of samples based on gene expression. The characteristics of expression data (e.g. large number of genes with small sample size) makes the classification problem more challenging. The process of building multiclass classifiers is divided into two components: (i) selection of the features (i.e. genes) to be used for training and testing and (ii) selection of the classification method. This paper compares various feature selection methods as well as various state-of-the-art classification methods on various multiclass gene expression datasets. Our study indicates that multiclass classification problem is much more difficult than the binary one for the gene expression datasets. The difficulty lies in the fact that the data are of high dimensionality and that the sample size is small. The classification accuracy appears to degrade very rapidly as the number of classes increases. In particular, the accuracy was very low regardless of the choices of the methods for large-class datasets (e.g. NCI60 and GCM). While increasing the number of samples is a plausible solution to the problem of accuracy degradation, it is important to develop algorithms that are able to analyze effectively multiple-class expression data for these special datasets.	Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA	Ogihara, M (reprint author), Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA.	ogihara@cs.rochester.edu					Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Allwein E. L., 2000, P 17 INT C MACH LEAR, P9; Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765; Bagirov AM, 2003, BIOINFORMATICS, V19, P1800, DOI 10.1093/bioinformatics/btg238; Ben-Dor A, 2000, J COMPUT BIOL, V7, P559, DOI 10.1089/106652700750050943; BIJLANI R, 2003, BIOINFORMATICS, V19, P69; BOTTOU L, 1994, INT C PATT RECOG, P77, DOI 10.1109/ICPR.1994.576879; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Chee M, 1996, SCIENCE, V274, P610, DOI 10.1126/science.274.5287.610; Crammer K., 2000, P 13 ANN C COMP LEAR, P35; Der SD, 1998, P NATL ACAD SCI USA, V95, P15623, DOI 10.1073/pnas.95.26.15623; DIETTERICH TG, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P572; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Dorris DR, 2002, GENOME RES, V12, P976, DOI 10.1101/gr.227402; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Eisen MB, 1999, METHOD ENZYMOL, V303, P179; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; FODOR SPA, 1991, SCIENCE, V251, P767, DOI 10.1126/science.1990438; Friedman J., 1996, ANOTHER APPROACH POL; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hall M., 1999, THESIS WAIKATO U WAI; Hastie T., 2001, ELEMENTS STAT LEARNI; HASTIE T, 1998, ADV NEURAL INFORMATI, V10; Hedenfalk I, 2001, NEW ENGL J MED, V344, P539, DOI 10.1056/NEJM200102223440801; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Kreel U H G, 1999, ADV KERNEL METHODS S, P255; Lee Y, 2003, BIOINFORMATICS, V19, P1132, DOI 10.1093/bioinformatics/btg102; Li T., 2003, P 12 INT C INF KNOWL, P317; Liu Huiqing, 2002, Genome Inform, V13, P51; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Raychaudhuri S, 2002, GENOME RES, V12, P203, DOI 10.1101/gr.199701; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; Scholkopf B, 2002, LEARNING KERNELS; Su Y, 2003, BIOINFORMATICS, V19, P1578, DOI 10.1093/bioinformatics/btg179; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Vapnik V., 1998, STAT LEARNING THEORY; Welsh JB, 2001, P NATL ACAD SCI USA, V98, P1176, DOI 10.1073/pnas.98.3.1176; Weston J., 1998, MULTICLASS SUPPORT V; Witten IH, 2000, DATA MINING PRACTICA; YEANG CH, 2001, BIOINFORMATICS, V11, P1; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	42	236	244	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	OCT 12	2004	20	15					2429	2437		10.1093/bioinformatics/bth267		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	862HP	WOS:000224481900013	15087314	
J	Nagai, MA; Da Ros, N; Neto, MM; Junior, SRD; Brentani, MM; Hirata, R; Neves, EJ				Nagai, MA; Da Ros, N; Neto, MM; Junior, SRD; Brentani, MM; Hirata, R; Neves, EJ			Gene expression profiles in breast tumors regarding the presence or absence of estrogen and progesterone receptors	INTERNATIONAL JOURNAL OF CANCER			English	Article						breast cancer; gene expression; estrogen receptor; progesterone receptor	CDNA MICROARRAY; CANCER PATIENTS; MOLECULAR-MECHANISMS; ALZHEIMERS-DISEASE; CELLS; PROTEINS; ELEMENTS; DNAJ; IDENTIFICATION; NORMALIZATION	Estrogen acts via its receptor (ER) to stimulate cell growth and differentiation in the mammary gland. ER and progesterone receptor (PR), which is regulated by estrogen via ER, have been used as prognostic markers in clinical management of breast cancer patients. Patients with ER- breast tumors have a poorer prognosis than patients with ER+ tumors. The aim of the present study was the identification of tumor-associated genes differentially expressed in breast tumors regarding the presence or absence of ER and PR hybridized with cDNA microarrays containing 4,500 tumor-derived expressed sequence tags generated using the ORESTES technique. Samples of human primary breast carcinomas from 38 patients were analyzed. The experiments were performed in triplicates and data from each element were acquired by phosphoimage scanning. Data acquisition was performed using the ArrayVision software. After normalization statistical analysis was applied. In a preliminary analysis, 98 differentially expressed transcripts were identified, 46 were found to be more expressed in ER+/PR+ and 52 were found to be more expressed in ER-/PR- breast tumors. The biochemical functions of the genes in the reported expression profile are diverse and include metabolic enzymes, protein kinases, helicases, transcription factors, cell cycle regulators and apoptotic factors. ER-/PR- breast tumors displayed increased levels of transcripts of genes associated with neurodegeneration and genes associated with proliferation were found in ER+/PR+ tumors. (C) 2004 Wiley-Liss, Inc.	Univ Sao Paulo, Fac Med, Dept Radiol, Discipline Oncol, BR-01296903 Sao Paulo, Brazil; Hosp Canc AC Camargo, Dept Mastol, Sao Paulo, Brazil; Univ Sao Paulo, Inst Matemat & Estat, Sao Paulo, Brazil; SENAC, Coll Comp Sci & Technol, Sao Paulo, Brazil	Nagai, MA (reprint author), Univ Sao Paulo, Fac Med, Dept Radiol, Discipline Oncol, Av Dr Arnaldo,455,4 Andar, BR-01296903 Sao Paulo, Brazil.	nagai@usp.br	Hirata Jr., Roberto/E-4436-2011; Nagai, Maria/C-6162-2012	Hirata Jr., Roberto/0000-0003-3861-7260; 			Ahr A, 2002, LANCET, V359, P131, DOI 10.1016/S0140-6736(02)07337-3; Bertucci F, 2000, HUM MOL GENET, V9, P2981, DOI 10.1093/hmg/9.20.2981; Bouras T, 2002, CANCER RES, V62, P1289; BRENTANI MM, 1981, J SURG ONCOL, V18, P431, DOI 10.1002/jso.2930180411; CAPLAN AJ, 1993, MOL BIOL CELL, V4, P555; Castro-Rivera E, 2001, J BIOL CHEM, V276, P30853, DOI 10.1074/jbc.M103339200; Chang J, 2000, CLIN CANCER RES, V6, P616; CHOMCZYNSKI P, 1987, ANAL BIOCHEM, V162, P156, DOI 10.1006/abio.1987.9999; Cruts M, 1998, HUM MOL GENET, V7, P43, DOI 10.1093/hmg/7.1.43; CYR DM, 1994, TRENDS BIOCHEM SCI, V19, P176, DOI 10.1016/0968-0004(94)90281-X; DESJARDINS E, 1993, MOL CELL BIOL, V13, P5710; Edwards D, 2003, BIOINFORMATICS, V19, P825, DOI 10.1093/bioinformatics/btg083; Fan SJ, 2001, ONCOGENE, V20, P77, DOI 10.1038/sj.onc.1204073; Green PS, 1996, NEUROSCI LETT, V218, P165, DOI 10.1016/S0304-3940(96)13148-7; Greeve I, 2000, J NEUROSCI, V20, P7345; HAHNEL R, 1979, CANCER, V44, P671, DOI 10.1002/1097-0142(197908)44:2<671::AID-CNCR2820440238>3.0.CO;2-V; Hall JM, 2001, J BIOL CHEM, V276, P36869, DOI 10.1074/jbc.R100029200; Hastie T., 2001, ELEMENTS STAT LEARNI; Heinemeyer T, 1999, NUCLEIC ACIDS RES, V27, P318, DOI 10.1093/nar/27.1.318; Inestrosa NC, 1998, MOL NEUROBIOL, V17, P73, DOI 10.1007/BF02802025; Johnson JL, 2000, MOL CELL BIOL, V20, P3027, DOI 10.1128/MCB.20.9.3027-3036.2000; Kato S, 1998, ONCOLOGY-BASEL, V55, P5, DOI 10.1159/000055253; Khan S, 2003, ENDOCRINOLOGY, V144, P2325, DOI 10.1210/en.2002-0149; Kudoh K, 2000, CANCER RES, V60, P4161; Kushner PJ, 2000, J STEROID BIOCHEM, V74, P311, DOI 10.1016/S0960-0760(00)00108-4; Lemieux P, 1996, J STEROID BIOCHEM, V56, P87, DOI 10.1016/0960-0760(95)00269-3; Li XJ, 1998, P NATL ACAD SCI USA, V95, P7109, DOI 10.1073/pnas.95.12.7109; Lonning PE, 2001, ENDOCR-RELAT CANCER, V8, P259, DOI 10.1677/erc.0.0080259; Mandal M, 2001, J BIOL CHEM, V276, P9699, DOI 10.1074/jbc.M008514200; Manthey D, 2001, EUR J BIOCHEM, V268, P4285, DOI 10.1046/j.1432-1327.2001.02346.x; NAGAI MA, 1994, INT J CANCER, V59, P351, DOI 10.1002/ijc.2910590310; Nagai MA, 2003, INT J ONCOL, V23, P1425; Neto ED, 2000, P NATL ACAD SCI USA, V97, P3491; Nilsson S, 2001, PHYSIOL REV, V81, P1535; Nomura N, 1994, DNA Res, V1, P27, DOI 10.1093/dnares/1.1.27; Osborne CK, 1998, BREAST CANCER RES TR, V51, P227, DOI 10.1023/A:1006132427948; OSBORNE CK, 1980, CANCER, V46, P2884, DOI 10.1002/1097-0142(19801215)46:12+<2884::AID-CNCR2820461429>3.0.CO;2-U; Perou CM, 1999, P NATL ACAD SCI USA, V96, P9212, DOI 10.1073/pnas.96.16.9212; Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; Ritchie SA, 2003, NUCLEIC ACIDS RES, V31, P1502, DOI 10.1093/nar/gkg246; Robertson JFR, 1996, BRIT J CANCER, V73, P5, DOI 10.1038/bjc.1996.2; Russo IH, 1998, J MAMMARY GLAND BIOL, V3, P49, DOI 10.1023/A:1018770218022; Sabbah M, 1999, P NATL ACAD SCI USA, V96, P11217, DOI 10.1073/pnas.96.20.11217; Saville B, 2000, J BIOL CHEM, V275, P5379, DOI 10.1074/jbc.275.8.5379; Schnaider T, 2000, LIFE SCI, V67, P1455, DOI 10.1016/S0024-3205(00)00735-9; SHEIKH MS, 1994, INVAS METAST, V14, P329; Sommer S, 2001, SEMIN CANCER BIOL, V11, P339, DOI 10.1006/scbi.2001.0389; Sorlie T, 2001, P NATL ACAD SCI USA, V98, P10869, DOI 10.1073/pnas.191367098; SWANSON MS, 1988, MOL CELL BIOL, V8, P2237; TSAI MJ, 1994, ANNU REV BIOCHEM, V63, P451, DOI 10.1146/annurev.biochem.63.1.451; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Waterham HR, 2001, AM J HUM GENET, V69, P685, DOI 10.1086/323473; Webb P, 1999, MOL ENDOCRINOL, V13, P1672, DOI 10.1210/me.13.10.1672; WELSCH PL, 2002, P NATL ACAD SCI USA, V99, P7560; YANG J, 2000, INVIVO, V15, P239; Yang YH, 2002, NUCLEIC ACIDS RES, V30, DOI 10.1093/nar/30.4.e15	56	14	15	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0020-7136			INT J CANCER	Int. J. Cancer	OCT 10	2004	111	6					892	899		10.1002/ijc.20329		8	Oncology	Oncology	847MT	WOS:000223397700010	15300801	
J	Neumann, A; Holstein, J; Le Gall, JR; Lepage, E				Neumann, A; Holstein, J; Le Gall, JR; Lepage, E			Measuring performance in health care: case-mix adjustment by boosted decision trees	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						prognostic models; decision trees; boosting; quality of care; mortality; hospital readmission	LOGISTIC-REGRESSION; MODEL; READMISSIONS; VALIDATION	Objective: The purpose of this paper is to investigate the suitability of boosted decision trees for the case-mix adjustment involved in comparing the performance of various health care entities. Methods: First, we present logistic regression, decision trees, and boosted decision trees in a unified framework. Second, we study in detail their application for two common performance indicators, the mortality rate in intensive care and the rate of potentially avoidable hospital readmissions. Results: For both examples the technique of boosting decision trees outperformed standard prognostic models, in particular linear logistic regression models, with regard to predictive power. On the other hand, boosting decision trees was computationally demanding and the resulting models were rather complex and needed additional tools for interpretation. Conclusion: Boosting decision trees represents a powerful tool for case-mix adjustment in health care performance measurement. Depending on the specific priorities set in each context, the gain in predictive power might compensate for the inconvenience in the use of boosted decision trees. (C) 2004 Elsevier B.V. All rights reserved.	Assistance Publ Hosp Paris, Direct Polit Med, F-75184 Paris 04, France; Hop St Louis, Serv Reanimat Med, F-75475 Paris, France	Neumann, A (reprint author), Assistance Publ Hosp Paris, Direct Polit Med, 3 Av Victoria, F-75184 Paris 04, France.	anke.neumann@sap.ap-hop-paris.fr					Abu-Hanna A, 2003, ARTIF INTELL MED, V29, P5, DOI 10.1016/S0933-3657(03)00047-2; Agresti A, 2002, CATEGORICAL DATA ANA; Ashton CM, 1997, MED CARE, V35, P1044; Breiman L., 1984, CLASSIFICATION REGRE; Breslow N., 1987, STAT METHODS CANC RE; COX DR, 1958, BIOMETRIKA, V45, P562, DOI 10.1093/biomet/45.3-4.562; DESHARNAIS SI, 1990, MED CARE, V28, P1127, DOI 10.1097/00005650-199012000-00002; FAGON JY, 1993, INTENS CARE MED, V19, P137, DOI 10.1007/BF01720528; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Goldstein H, 1996, J ROY STAT SOC A STA, V159, P385, DOI 10.2307/2983325; Halfon P, 2002, J CLIN EPIDEMIOL, V55, P573, DOI 10.1016/S0895-4356(01)00521-2; HAND D.J., 1997, CONSTRUCTION ASSESSM; Hanley JA, 1997, ACAD RADIOL, V4, P49, DOI 10.1016/S1076-6332(97)80161-4; Hastie T., 2001, ELEMENTS STAT LEARNI; Hosmer D. W. J. R., 2000, APPL LOGISTIC REGRES; Hosmer DW, 1997, STAT MED, V16, P965; KONONENKO I, 1991, MACH LEARN, V6, P67, DOI 10.1007/BF00153760; LEGALL JR, 1993, JAMA-J AM MED ASSOC, V270, P2957, DOI 10.1001/jama.270.24.2957; MILLER ME, 1991, STAT MED, V10, P1213, DOI 10.1002/sim.4780100805; Ridley S., 2002, OUTCOMES CRITICAL CA; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Schapire RE, 1998, ANN STAT, V26, P1651; Zheng BY, 2000, STAT MED, V19, P1771, DOI 10.1002/1097-0258(20000715)19:13<1771::AID-SIM485>3.3.CO;2-G	25	10	10	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657			ARTIF INTELL MED	Artif. Intell. Med.	OCT	2004	32	2					97	113		10.1016/j.artmed.2004.06.001		17	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	857SN	WOS:000224138700003	15364094	
J	Fabricius, KE; De'Ath, G				Fabricius, KE; De'Ath, G			Identifying ecological change and its causes: A case study on coral reefs	ECOLOGICAL APPLICATIONS			English	Article						Bayesian analysis; biodiversity; bootstrap; causality; community structure; environmental impact; epidemiology; Great Barrier Reef; model averaging; model selection; pollution; terrestrial runoff	GREAT-BARRIER-REEF; MODEL SELECTION; SEDIMENTATION; MANAGEMENT; PHOTOSYNTHESIS; UNCERTAINTY; HYPOTHESIS; AUSTRALIA; NUTRIENTS; INFERENCE	The successful management of ecosystems depends on early detection of change and identification of factors causing such change. Determination of change and causality in ecosystems is difficult, both philosophically and practically, and these difficulties increase with the scale and complexity of ecosystems. Management also depends on the communication of scientific results to the broader public, and this can fail if the evidence of change and causality is not synthesized in a transparent manner. We developed a framework to address these problems when assessing the effects of agricultural runoff on coral reefs of the Australian Great Barrier Reef (GBR). The framework is based on improved methods of statistical estimation (rejecting the use of statistical tests to detect change), and the use of epidemiological causal criteria that are both scientifically rigorous and under-stood by nonspecialists. Many inshore reefs of the GBR are exposed to terrestrial runoff from agriculture. However, detecting change and attributing it to the increasing loads of nutrients, sediments, and pesticides is complicated by the large spatial scale, presence of additional disturbances, and lack of historical data. Three groups of ecological attributes, namely, benthos cover, octocoral richness, and community structure, were used to discriminate between potential causes of change. Ecological surveys were conducted along water quality gradients in two regions: one that receives river flood plumes from agricultural areas and one exposed to runoff from catchments with little or no agriculture. The surveys showed increasing macroalgal cover and decreasing octocoral biodiversity along the gradients within each of the regions, and low hard coral and octocoral cover in the region exposed to terrestrial runoff. Effects were strong and ecologically relevant, occurred independently in different populations, agreed with known biological facts of organism responses to pollution, and were consistent with pollution effects found in other parts of the world. The framework enabled us to maximize the information derived from observational data and other sources, weigh the evidence of changes across potential causes, make decisions in a coherent and transparent manner, and communicate information and conclusions to the broader public. The framework is applicable to a wide range of ecological assessments.	Australian Inst Marine Sci, Townsville, Qld 4810, Australia	Fabricius, KE (reprint author), Australian Inst Marine Sci, PMB 3, Townsville, Qld 4810, Australia.	k.fabricius@aims.gov.au	Fabricius, Katharina/F-1759-2010	Fabricius, Katharina/0000-0001-7671-4358			AYLING AM, 2002, DYNAMICS CAIRNS SECT; BELL PRF, 1991, MAR POLLUT B, V22, P89; BERGER J. O., 2001, MODEL SELECTION, DOI 10.1214/lnms/1215540968; Berger JO, 1997, STAT SCI, V12, P133; BERGER JO, 1987, J AM STAT ASSOC, V82, P112, DOI 10.2307/2289131; Berkelmans R, 1999, CORAL REEFS, V18, P55, DOI 10.1007/s003380050154; Bodansky Daniel, 1991, ENVIRONMENT, V33, P43; BOZDOGAN H, 1987, PSYCHOMETRIKA, V52, P345, DOI 10.1007/BF02294361; Brodie J, 2001, WATER SCI TECHNOL, V43, P203; BRODIE JE, 2003, P 9 INT COR REEF S I, P705; BRYANT D, 1998, RREFS RISK MAP BASED; Burnham K. P., 1998, MODEL SELECTION INFE; BURNHAM KP, 2003, J WILDLIFE MANAGMENT, V64, P912; COHEN J, 1994, AM PSYCHOL, V49, P997, DOI 10.1037/0003-066X.50.12.1103; Cohen J., 1988, STAT POWER ANAL BEHA; Davison A, 1997, BOOTSTRAP METHODS TH; Dayton PK, 1998, SCIENCE, V279, P821, DOI 10.1126/science.279.5352.821; De'ath G, 1998, J EXP MAR BIOL ECOL, V220, P107, DOI 10.1016/S0022-0981(97)00100-7; DEVANTIER LM, 1994, THESIS QUEENSLAND U; DEVLIN M, 2002, P 2 NAT C AQ ENV SUS; DEVLIN MJ, 2001, FLOOD PLUMES GREAT B; Diaz-Pulido G, 2003, ECOLOGY, V84, P2026, DOI 10.1890/01-3127; DINESEN Z D, 1983, Coral Reefs, V1, P229, DOI 10.1007/BF00304420; DRAPER D, 1995, J R STAT SOC B, V57, P45; Dubinsky Z, 1996, GLOBAL CHANGE BIOL, V2, P511, DOI 10.1111/j.1365-2486.1996.tb00064.x; Edinger EN, 2000, MAR POLLUT BULL, V40, P404, DOI 10.1016/S0025-326X(99)00237-4; Edinger EN, 1998, MAR POLLUT BULL, V36, P617, DOI 10.1016/S0025-326X(98)00047-2; EFRON B, 1993, KNTRO BOOTSTRAP; Ellison AM, 1996, ECOL APPL, V6, P1036, DOI 10.2307/2269588; Fabricius K, 2001, SOFT CORALS SEA FANS; Fabricius K, 2001, OCEANOGRAPHIC PROCESSES OF CORAL REEFS : PHYSICAL AND BIOLOGICAL LINKS IN THE GREAT BARRIER REEF, P127; FABRICIUS KE, 1995, MAR ECOL PROG SER, V125, P195, DOI 10.3354/meps125195; FOX GA, 1991, J TOXICOL ENV HEALTH, V33, P359; FREEDMAN DA, 1983, AM STAT, V37, P152, DOI 10.2307/2685877; Furnas M., 2003, CATCHMENTS CORALS TE; Furnas M, 2001, OCEANOGRAPHIC PROCESSES OF CORAL REEFS : PHYSICAL AND BIOLOGICAL LINKS IN THE GREAT BARRIER REEF, P37; Furnas MA, 1997, P 8 INT COR REEF S S, P809; Furnas MJ, 1996, CONT SHELF RES, V16, P1127, DOI 10.1016/0278-4343(95)00060-7; Gillies D, 2001, BRIT J PHILOS SCI, V52, P613, DOI 10.1093/bjps/52.3.613; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T, 1990, GEN ADDITIVE MODELS; Haynes D, 2000, MAR POLLUT BULL, V41, P428, DOI 10.1016/S0025-326X(00)00150-8; HILL AB, 1965, P ROY SOC MED, V58, P295; Hodgson G., 1997, P459; Hoenig JM, 2001, AM STAT, V55, P19, DOI 10.1198/000313001300339897; Hopley D., 1983, CORAL REEFS, V1, P151, DOI 10.1007/BF00571192; HUNTER CL, 1995, B MAR SCI, V57, P501; TERBRAAK CJF, 1992, LECT NOTES ECON MATH, V376, P79; Johnson DH, 1999, J WILDLIFE MANAGE, V63, P763, DOI 10.2307/3802789; Jones RJ, 2003, MAR ECOL PROG SER, V251, P153, DOI 10.3354/meps251153; Jongman R.H.G., 1995, DATA ANAL COMMUNITY; Larcombe P, 1999, CORAL REEFS, V18, P163, DOI 10.1007/s003380050174; MADIGAN D, 1994, J AM STAT ASSOC, V89, P1535, DOI 10.2307/2291017; McCook LJ, 1999, CORAL REEFS, V18, P357, DOI 10.1007/s003380050213; McCullagh P., 1989, GEN LINEAR MODELS; McCulloch M, 2003, NATURE, V421, P727, DOI 10.1038/nature01361; Mitchell AW, 2001, WATER SCI TECHNOL, V43, P99; Nelder JA, 1999, J ROY STAT SOC D-STA, V48, P257, DOI 10.1111/1467-9884.00187; NEWMAN MC, 2002, COASTAL ESTUARINE RI, P73; Pearl J., 2000, CAUSALITY MODELS REA; Philipp E, 2003, J EXP MAR BIOL ECOL, V287, P57, DOI 10.1016/S0022-0981(02)00495-1; Raftery AE, 1995, SOCIOL METHODOL, V25, P111, DOI 10.2307/271063; RAFTERY AE, 1988, 121 U WASH DEP STAT; Rao C.R., 1964, SANKHYA A, V26, P329, DOI DOI 10.2307/25049339); RIEGL B, 1995, J EXP MAR BIOL ECOL, V186, P259, DOI 10.1016/0022-0981(94)00164-9; ROGERS CS, 1990, MAR ECOL PROG SER, V62, P185, DOI 10.3354/meps062185; ROTH LH, 1982, PRINCIPLES EPIDEMIOL; SAKAMOTO Y, 1986, AKAIKE INFORMATION C; Schaffelke B, 1998, MAR ECOL PROG SER, V170, P95, DOI 10.3354/meps170095; SCHROETER SC, 1993, ECOL APPL, V3, P331, DOI 10.2307/1941836; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Smith S. V., 1981, PAC SCI, V35, P270; SPEED T, 1990, INFLUENCE DIAGRAMS B, P361; *STAT SCI, 1999, S PLUS VERS 2000 WIN; Stewart-Oaten Allan, 1996, P109, DOI 10.1016/B978-012627255-0/50009-4; Stewart-Oaten Allan, 1996, P17, DOI 10.1016/B978-012627255-0/50004-5; Strong A, 1997, P 8 INT COR REEF S P, V2, P1495; SZMANT AM, 2002, ESTUARIES, V25, P753; TOMASCIK T, 1993, GLOBAL ASPECTS CORAL, P26; TORGERSEN T, 1983, BMR J AUST GEOL GEOP, V8, P191; U. S. Department of Health Education and Welfare, 1964, PUBL HLTH SERV PUBL; *US EPA, 1998, FEDERAL REG, V63; van Woesik R, 1999, MAR FRESHWATER RES, V50, P427; West K, 2001, MAR POLLUT BULL, V42, P864, DOI 10.1016/S0025-326X(01)00040-6; WITTENBERG M, 1992, MAR BIOL, V112, P131, DOI 10.1007/BF00349736; Fabricius KE, 2003, ESTUAR COAST SHELF S, V57, P613, DOI 10.1016/S0272-7714(02)00400-6	86	81	83	ECOLOGICAL SOC AMER	WASHINGTON	1990 M STREET NW, STE 700, WASHINGTON, DC 20036 USA	1051-0761			ECOL APPL	Ecol. Appl.	OCT	2004	14	5					1448	1465		10.1890/03-5320		18	Ecology; Environmental Sciences	Environmental Sciences & Ecology	863NN	WOS:000224568800012		
J	Ye, JP; Li, T; Xiong, T; Janardan, R				Ye, JP; Li, T; Xiong, T; Janardan, R			Using uncorrelated discriminant analysis for tissue classification with gene expression data	IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS			English	Article; Proceedings Paper	4th International Workshop on Algorithms in Bioinformatics (WABI 2004)	SEP 17-21, 2004	Bergen, NORWAY		Univ Bergen	microarray data analysis; discriminant analysis; generalized singular value decomposition; classification	SUPPORT VECTOR MACHINES; MULTIPLE CANCER TYPES; CLUSTERING ANALYSIS; PREDICTION; PATTERNS; RECOGNITION; DISCOVERY; DIAGNOSIS; NETWORKS; ARRAYS	The classification of tissue samples based on gene expression data is an important problem in medical diagnosis of diseases such as cancer. In gene expression data, the number of genes is usually very high (in the thousands) compared to the number of data samples (in the tens or low hundreds); that is, the data dimension is large compared to the number of data points (such data is said to be undersampled). To cope with performance and accuracy problems associated with high dimensionality, it is commonplace to apply a preprocessing step that transforms the data to a space of significantly lower dimension with limited loss of the information present in the original data. Linear Discriminant Analysis (LDA) is a well-known technique for dimension reduction and feature extraction, but it is not applicable for undersampled data due to singularity problems associated with the matrices in the underlying representation. This paper presents a dimension reduction and feature extraction scheme, called Uncorrelated Linear Discriminant Analysis (ULDA), for undersampled problems and illustrates its utility on gene expression data. ULDA employs the Generalized Singular Value Decomposition method to handle undersampled data and the features that it produces in the transformed space are uncorrelated, which makes it attractive for gene expression data. The properties of ULDA are established rigorously and extensive experimental results on gene expression data are presented to illustrate its effectiveness in classifying tissue samples. These results provide a comparative study of various state-of-the-art classification methods on well-known gene expression data sets.	Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA; Florida Int Univ, Sch Comp Sci, Miami, FL 33199 USA; Univ Minnesota, Dept Elect & Comp Engn, Minneapolis, MN 55455 USA	Ye, JP (reprint author), Univ Minnesota, Dept Comp Sci & Engn, Twin Cities 4-192 EE CSci Bldg,200 Union St SE, Minneapolis, MN 55455 USA.	jieping@cs.umn.edu; taoli@cs.fiu.edu; txiong@ece.umn.edu; janardan@cs.umn.edu					Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Ben-Dor A, 2000, J COMPUT BIOL, V7, P559, DOI 10.1089/106652700750050943; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chee M, 1996, SCIENCE, V274, P610, DOI 10.1126/science.274.5287.610; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; FODOR SPA, 1991, SCIENCE, V251, P767, DOI 10.1126/science.1990438; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Fukunaga K, 1990, INTRO STAT PATTERN R; Getz G, 2000, P NATL ACAD SCI USA, V97, P12079, DOI 10.1073/pnas.210134797; Golub G. H., 1991, MATRIX COMPUTATIONS; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hastie T., 2001, ELEMENTS STAT LEARNI; Howland P, 2003, SIAM J MATRIX ANAL A, V25, P165, DOI 10.1137/S0895479801393666; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; KRZANOWSKI WJ, 1995, APPL STAT-J ROY ST C, V44, P101, DOI 10.2307/2986198; Lee Y, 2003, BIOINFORMATICS, V19, P1132, DOI 10.1093/bioinformatics/btg102; Li T, 2004, BIOINFORMATICS, V20, P2429, DOI 10.1093/bioinformatics/bth267; Ooi CH, 2003, BIOINFORMATICS, V19, P37, DOI 10.1093/bioinformatics/19.1.37; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; STATNIKOV A., 2004, BIOINFORMATICS; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Vapnik V., 1998, STAT LEARNING THEORY; Ye J., 2004, P 21 INT C MACH LEAR, P895; YE J, UNPUB CHARACTERIZATI; Ye JP, 2004, IEEE T PATTERN ANAL, V26, P982; YEANG CH, 2001, BIOINFORMATICS, V11, P1; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6; Yeung KY, 2001, BIOINFORMATICS, V17, P763, DOI 10.1093/bioinformatics/17.9.763	35	75	76	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1545-5963			IEEE ACM T COMPUT BI	IEEE-ACM Trans. Comput. Biol. Bioinform.	OCT-DEC	2004	1	4					181	190				10	Biochemical Research Methods; Computer Science, Interdisciplinary Applications; Mathematics, Interdisciplinary Applications; Statistics & Probability	Biochemistry & Molecular Biology; Computer Science; Mathematics	013ZJ	WOS:000235448200006	17051700	
J	Wei, G; Cosman, P; Berry, CC; Feng, ZY; Schafer, WR				Wei, G; Cosman, P; Berry, CC; Feng, ZY; Schafer, WR			Automatic tracking, feature extraction and classification of C-elegans phenotypes	IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING			English	Article; Proceedings Paper	37th Asilomar Conference on Signals, Systems and Computers	NOV 09-12, 2003	Pacific Grove, CA			C. elegans; classification; computer vision; data mining; feature extraction; image processing; Random Forests; tracking	NEMATODE CAENORHABDITIS-ELEGANS; BEHAVIOR; DROSOPHILA; RESPONSES; SEROTONIN; COCAINE; GENES	This paper presents a method for automatic tracking of the head, tail, and entire body movement of the nematode Caenorhabditis elegans (C. elegans) using computer vision and digital image analysis techniques. The characteristics of the worm's movement, posture and texture information were extracted from a 5-min image sequence. A Random Forests classifier was then used to identify the worm type, and the features that best describe the data. A total of 1597 individual worm video sequences, representing wild type and 15 different mutant types, were analyzed. The average correct classification ratio, measured by out-of-bag (OOB) error rate, was 90.9%. The features that have most discrimination ability were also studied. The algorithm developed will be an essential part of a completely automated C elegans tracking and identification system.	Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA; Univ Calif San Diego, Div Biostat, Dept Family & Prevent Med, La Jolla, CA 92093 USA; Univ Calif San Diego, Div Biol, La Jolla, CA 92093 USA	Wei, G (reprint author), ID Analyt Inc, San Diego, CA 92193 USA.	wei_geng@yahoo.com					BAEK J, 2002, J NEUROSCI METH, V118, P921; Bainton RJ, 2000, CURR BIOL, V10, P187, DOI 10.1016/S0960-9822(00)00336-5; Breiman L., 2002, MANUAL SETTING UP US; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BRENNER S, 1974, GENETICS, V77, P77; Bylander T, 2002, MACH LEARN, V48, P287, DOI 10.1023/A:1013964023376; de Bono M, 1998, CELL, V94, P679, DOI 10.1016/S0092-8674(00)81609-8; Dhawan R, 1999, J TOXICOL ENV HEAL A, V58, P451, DOI 10.1080/009841099157179; Duda R.O., 2002, PATTERN CLASSIFICATI; FRASER A, 2001, NATURE, V408, P325; Geng W, 2003, GENETICS, V165, P1117; GENG W, EUROSIP J APPL SIGNA; Gonzalez R. C., 2002, DIGITAL IMAGE PROCES; Hardaker LA, 2001, J NEUROBIOL, V49, P303, DOI 10.1002/neu.10014; Hastie T., 2002, ELEMENTS STAT LEARNI; HODGKIN J, 1983, GENETICS, V103, P43; Jain R, 1995, MACHINE VISION; Kim J, 2001, GENETICS, V157, P1599; Liaw A, 2002, CLASSIFICATION REGRE; McClung C, 1998, CURR BIOL, V8, P109, DOI 10.1016/S0960-9822(98)70041-7; Pierce-Shimomura JT, 1999, J NEUROSCI, V19, P9557; SULSTON JE, 1983, DEV BIOL, V100, P64, DOI 10.1016/0012-1606(83)90201-4; SULSTON JE, 1977, DEV BIOL, V56, P110, DOI 10.1016/0012-1606(77)90158-0; Waggoner LE, 1998, NEURON, V21, P203, DOI 10.1016/S0896-6273(00)80527-9; WHITEHEAD PJP, 1986, FISHES NE ATLANTIC M, V3, P1; ZHANG TY, 1984, COMMUN ACM, V27, P236, DOI 10.1145/357994.358023; Zhou GT, 1998, IEEE T SIGNAL PROCES, V46, P2698, DOI 10.1109/78.720372; Zipperlen P, 2001, EMBO J, V20, P3984, DOI 10.1093/emboj/20.15.3984	29	7	7	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9294			IEEE T BIO-MED ENG	IEEE Trans. Biomed. Eng.	OCT	2004	51	10					1811	1820		10.1109/TBME.2004.831532		10	Engineering, Biomedical	Engineering	855VB	WOS:000224001900012		
J	Berman, M; Kiiveri, H; Lagerstrom, R; Ernst, A; Dunne, R; Huntington, JF				Berman, M; Kiiveri, H; Lagerstrom, R; Ernst, A; Dunne, R; Huntington, JF			ICE: A statistical approach to identifying endmembers in hyperspectral images	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article; Proceedings Paper	23rd International Geoscience and Remote Sensing Symposium (IGARSS 2003)	JUL 21-25, 2003	TOULOUSE, FRANCE	IEE, IEEE Geosci & Remote Sensing Soc, Ctr Natl Etudes Spatiales, NASA, Natl Ocean & Atmospher Adm, US Dept Commerce, Off Naval Res, eesa, NPOESS, NASDA, Ball Aerosp & Technol Corp, uRSi		convex geometry; endmember; hyperspectral; normalization; simplex	ALGORITHM	Several of the more important endmember-finding algorithms for hyperspectral data are discussed and some of their shortcomings highlighted. A new algorithm-iterated constrained endmembers (ICE)-which attempts to address these shortcomings is introduced. An example of its use is given. There is also a discussion of the advantages and disadvantages of normalizing spectra before the application of ICE or other endmember-finding algorithms.	CSIRO, Explorat & Min, N Ryde, NSW 2113, Australia; CSIRO, Floreat, WA USA; CSIRO, Clayton, Vic 3168, Australia	Berman, M (reprint author), CSIRO, Explorat & Min, Macquarie Univ Campus, N Ryde, NSW 2113, Australia.	mark.berman@csiro.au; harri.kiiveri@csiro.au; ryan.lagerstrom@csiro.au; andreas.ernst@csiro.au; rob.dunne@csiro.au; jon.huntington@csiro.au	Ernst, Andreas/B-4298-2008; Lagerstrom, Ryan/A-3642-2009; Whitford, Linda/C-2470-2009; Berman, Mark/D-3411-2009; Kiiveri, Harri/E-5309-2010; Dunne, Robert/A-7322-2010	Ernst, Andreas/0000-0002-1101-8359; 			BOARDMAN J, 1998, JPL PUBL, V981, P53; Boardman J. W., 1995, JPL PUBLICATION, V95-1, P23; Boardman JW, 1993, JPL PUBLICATION, V93-26, P11; BOLAND NL, 1994, APPL MATH LETT, V7, P23, DOI 10.1016/0893-9659(94)90066-3; Boland NL, 1997, MATH PROGRAM, V78, P1; CRAIG MD, 1994, IEEE T GEOSCI REMOTE, V32, P542, DOI 10.1109/36.297973; EVERITT B, 1987, INTRO OPTIMIZATION M; GAO B, 1996, ATMOSPHERIC REMOVAL; GAO BC, 1990, J GEOPHYS RES-ATMOS, V95, P3549, DOI 10.1029/JD095iD04p03549; GREEN AA, 1988, IEEE T GEOSCI REMOTE, V26, P65, DOI 10.1109/36.3001; Hastie T., 2001, ELEMENTS STAT LEARNI; HAZEWINKEL M, 1995, ENCY MATH, V5; LEE JB, 1990, IEEE T GEOSCI REMOTE, V28, P295, DOI 10.1109/36.54356; Neville R. A., 1999, P 4 INT AIRB REM SEN, P891; Nocedal J., 1999, NUMERICAL OPTIMIZATI; *RES SYST INC, 2000, ENVI ENV VIS IM US G, P930; Richards J. A., 1993, REMOTE SENSING DIGIT; Seber G. A. F., 1984, MULTIVARIATE OBSERVA; Van der Meer F, 1999, INT J REMOTE SENS, V20, P3431, DOI 10.1080/014311699211462; VANE G, 1993, REMOTE SENS ENVIRON, V44, P127, DOI 10.1016/0034-4257(93)90012-M; Wahba G, 1990, SPLINE MODELS OBSERV; Winter M., 1999, P 13 INT C APPL GEOL, V2, P337	22	115	124	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0196-2892			IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	OCT	2004	42	10					2085	2095		10.1109/TGRS.2004.835299		11	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing; Imaging Science & Photographic Technology	Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science & Photographic Technology	863ZP	WOS:000224602600009		
J	Winkler, WE				Winkler, WE			Methods for evaluating and creating data quality	INFORMATION SYSTEMS			English	Article; Proceedings Paper	Workshop on Data Quality in Cooperative Information Systems	JAN 10-11, 2003	Siena, ITALY			integer programming; set covering; data cleaning; approximate string comparison; unsupervised and supervised learning	RECORD-LINKAGE; INFORMATION	This paper provides a survey of two classes of methods that can be used in determining and improving the quality of individual files or groups of files. The first are edit/imputation methods for maintaining business rules and for imputing for missing data. The second are methods of data cleaning for finding duplicates within files or across files. Published by Elsevier Ltd.	US Bur Census, Div Stat Res, Washington, DC 20233 USA	Winkler, WE (reprint author), US Bur Census, Div Stat Res, Room 3000-4, Washington, DC 20233 USA.	william.e.winkler@census.gov					ANANTHAKRISHNA R, 2003, VERY LARGE DATA BASE; BARCAROLI G, 1993, P 49 SESS INT STAT I; BARCAROLI G, 1997, STAT DATA EDITING, V2; BELIN TR, 1995, J AM STAT ASSOC, V90, P694; BERTOLAZZI P, 2003, IEEE WORKSH DAT QUAL; BORTHWICK A, 2002, MEDD 2 0 C PRES NEW; Bruni R., 2001, LOGIC OPTIMIZATION T; BURKARD RE, 1980, ASSIGNMENT MATCHING; CHEN BC, 1998, AM STAT ASS P SECT S; Christen P., 2002, AUSTR DAT MIN WORKSH; Churches T., 2002, BIOMED CENTRAL MED I, V2; COHEN WW, 2002, ASS COMPUTING MACHIN; COOPER WS, 1978, J ACM, V25, P67, DOI 10.1145/322047.322053; DELLAPIETRA S, 1977, IEEE T PATTERN ANAL, V39, P1; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V19, P380; DEWAAL T, 2003, IN PRESS J OFFICIAL, V19; ELFEKEY M, 2002, IEEE INT C DAT ENG 0; English L.P., 1999, IMPROVING DATA WAREH; FELLEGI IP, 1969, J AM STAT ASSOC, V64, P1183, DOI 10.2307/2286061; FELLEGI IP, 1976, J AM STAT ASSOC, V71, P17, DOI 10.2307/2285726; Ferragina P, 1999, J ACM, V46, P236, DOI 10.1145/301970.301973; Garcia M., 2000, P INT C EST SURV, P777; GARFINKEL RS, 1969, OPER RES, V34, P744; Getoor L., 2001, RELATIONAL DATA MINI; Hall PAV, 1980, ACM COMPUT SURV, V18, P381, DOI 10.1145/356827.356830; Hastie T., 2001, ELEMENTS STAT LEARNI; JARO MA, 1989, J AM STAT ASSOC, V84, P414, DOI 10.2307/2289924; KOLLER D, 1998, P 15 NAT C ART INT A, P157; KOVAR JG, 1996, AM STAT ASS P SECT S; LAHIRI PA, 2003, J AM STAT ASS, V81; LARSEN MD, 1989, J AM STAT ASSOC, V79, P32; LIANG J, 2003, 8 ANN INT C DAT SYST; Loshin D., 2001, ENTERPRISE KNOWLEDGE; MANZARI A, 2002, UN EC COMM EUR WORKS; MANZARI A, 2001, INT STAT I M SEOUL K; MCCALLUM A, 2000, ASS COMP MACH SIGKDD; McLachlan GJ, 1997, EM ALGORITHM EXTENSI; MECELLA M, 2002, VERY LARGE DATA BASE; Mitchell T., 1997, MACHINE LEARNING; Navarro G, 2001, ACM COMPUT SURV, V33, P31, DOI 10.1145/375360.375365; NEILING M, 2003, IEEE WORKSH DAT QUAL; NEWCOMBE HB, 1959, SCIENCE, V130, P954, DOI 10.1126/science.130.3381.954; Newcombe HB, 1988, HDB RECORD LINKAGE M; NEWCOMBE HB, 1962, COMMUN ACM, V5, P563, DOI 10.1145/368996.369026; Ohanekwu T., 2003, IEEE WORKSH DAT QUAL; POLLOCK JJ, 1984, COMMUN ACM, V27, P358, DOI 10.1145/358027.358048; Rahm E, 2001, VLDB J, V10, P334, DOI 10.1007/s007780100057; Rahm E., 2000, B TECHNICAL COMMITTE, V23, P3; REDMAN TC, 1996, DATA QUALITY INFORMA; SARAWAGI S, 2002, VERY LARGE DATA BASE; Scheuren F, 1997, SURV METHODOL, V23, P157; Scheuren F, 1993, SURV METHODOL, V19, P39; SCHOPIUKRATINA I, 1989, 89001E BSMD STAT CAN; TEJADA S, 2002, ACM SIGKDD 02; Tejada S, 2001, INFORM SYST, V26, P607, DOI 10.1016/S0306-4379(01)00042-4; Vapnik VN, 2000, NATURE STAT LEARNING; Winkler W. E., 1995, BUSINESS SURVEY METH; WINKLER WE, 2003, P SECT SURV RES METH; WINKLER WE, 1997, P SECT SURV RES METH, P564; WINKLER WE, 1997, STAT DATA EDITING, V2, P56; Winkler W.E., 1993, P SECT SURV RES METH, P274; Winkler W.E., 1988, P SECT SURV RES METH, P667; Winkler W.E., 2000, P SECT SURV RES METH, P20; WINKLER WE, 1999, P SECT GOV STAT SOC, P262; WINKLER WE, 1988, P 5 CENS BUR ANN RES, P145; WINKLER WE, 2001, P QUAL OFF STAT 2001; WINKLER WE, 1990, P SECT SURV RES METH, P778; WINKLER WE, 1999, STAT SOC CAN P SURV, P73; WINKLER WE, 1995, P SECT SURV RES METH, P108; Winkler W.E, 2002, P SECT SURV RES METH; Winkler William, 1999, STAT DATA EDITING, P169; Winkler William E., 1994, P SECT SURV RES METH, P467; YANCEY WE, 2002, RRC200201; YANCEY WE, 2002, IN PRESS P SECT SURV; YU CT, 1979, J ASSOC COMPUT MACH, V29, P152	75	24	24	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0306-4379			INFORM SYST	Inf. Syst.	OCT	2004	29	7					531	550		10.1016/j.is.2003.12.003		20	Computer Science, Information Systems	Computer Science	838XR	WOS:000222747200002		
J	Yu, L; Liu, H				Yu, L; Liu, H			Efficient feature selection via analysis of relevance and redundancy	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						supervised learning; feature selection; relevance; redundancy; high dimensionality	FEATURE SUBSET-SELECTION	Feature selection is applied to reduce the number of features in many applications where data has hundreds or thousands of features. Existing feature selection methods mainly focus on finding relevant features. In this paper, we show that feature relevance alone is insufficient for efficient feature selection of high-dimensional data. We define feature redundancy and propose to perform explicit redundancy analysis in feature selection. A new framework is introduced that decouples relevance analysis and redundancy analysis. We develop a correlation-based method for relevance and redundancy analysis, and conduct an empirical study of its efficiency and effectiveness comparing with representative methods.	Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA	Yu, L (reprint author), Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA.	LEIYU@ASU.EDU; HLIU@ASU.EDU					ALMUALLIM H, 1994, ARTIF INTELL, V69, P279, DOI 10.1016/0004-3702(94)90084-1; Bell DA, 2000, MACH LEARN, V41, P175, DOI 10.1023/A:1007612503587; BLUM AL, 1992, NEURAL NETWORKS, V5, P117, DOI 10.1016/S0893-6080(05)80010-3; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Dash M., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183893; Dash M, 2003, ARTIF INTELL, V151, P155, DOI 10.1016/S0004-3702(03)00079-1; Dash M, 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; Dy JG, 2003, IEEE T PATTERN ANAL, V25, P373, DOI 10.1109/TPAMI.2003.1182100; Fayyad UM, 1993, P 13 INT JOINT C ART, P1022; Forman G., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753670; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hall M. A., 2000, P 17 INT C MACH LEAR, P359; Hastie T., 2001, ELEMENTS STAT LEARNI; Jensen DD, 2000, MACH LEARN, V38, P309, DOI 10.1023/A:1007631014630; John G., 1994, P 11 INT C MACH LEAR, P121; KIM Y, 2002, P 6 ACM SIGKDD INT C, P365; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Koller D., 1996, P 13 INT C MACH LEAR, P284; Lee WK, 2000, ARTIF INTELL REV, V14, P533, DOI 10.1023/A:1006624031083; Liu H., 1996, P 13 INT C MACH LEAR, P319; Liu H, 2002, DATA MIN KNOWL DISC, V6, P393, DOI 10.1023/A:1016304305535; Liu H., 1998, FEATURE SELECTION KN; Liu H, 2002, P 19 INT C MACH LEAR, P395; Miller A., 2002, SUBSET SELECTION REG; Mitchell T., 1997, MACHINE LEARNING; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133; Ng K, 2000, ARTIF INTELL REV, V14, P569, DOI 10.1023/A:1006676015154; Press W., 1988, NUMERICAL RECIPES C; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714; SWETS DL, 1995, IEEE INT S COMP VIS, P85; Witten IH, 2000, DATA MINING PRACTICA; Xing EP, 2001, P 18 INT C MACH LEAR, P601; Yang Y., 1997, P 14 INT C MACH LEAR, P412, DOI DOI 10.1016/J.ESWA.2008.05.026; Yu L., 2004, P 10 ACM SIGKDD INT, P737, DOI 10.1145/1014052.1014149; Yu L., 2003, P 20 INT C MACH LEAR, P856	36	384	430	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	OCT	2004	5						1205	1224				20	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026GV	WOS:000236328300001		
J	Hastie, T; Rosset, S; Tibshirani, R; Zhu, J				Hastie, T; Rosset, S; Tibshirani, R; Zhu, J			The entire regularization path for the support vector machine	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						support vector machines; regularization; coefficient path		The support vector machine (SVM) is a widely used tool for classification. Many efficient implementations exist for fitting a two-class SVM model. The user has to supply values for the tuning parameters: the regularization cost parameter, and the kernel parameters. It seems a common practice is to use a default value for the cost parameter, often leading to the least restrictive model. In this paper we argue that the choice of the cost parameter can be critical. We then derive an algorithm that can fit the entire path of SVM solutions for every value of the cost parameter, with essentially the same computational cost as fitting one SVM model. We illustrate our algorithm on some examples, and use our representation to give further insight into the range of SVM solutions.	Stanford Univ, Dept Stat, Stanford, CA 94305 USA; IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA; Univ Michigan, Dept Stat, Ann Arbor, MI 48109 USA	Hastie, T (reprint author), Stanford Univ, Dept Stat, Stanford, CA 94305 USA.	HASTIE@STANFORD.EDU; SROSSET@US.IBM.COM; TIBS@STANFORD.EDU; JIZHU@UMICH.EDU					Allgower Eugene L., 1992, ACTA NUMERICA, P1; Bach F.R., 2002, J MACHINE LEARNING R, V3, P1; Cauwenberghs G., 2001, ADV NEURAL INFORM PR, V13; DeCoste D., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347165; Diehl CP, 2003, IEEE IJCNN, P2685; EFRON B, 2002, LEAST ANGLE REGRESSI; EFRON B, 2004, IN PRESS ANN STAT; Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316; FINE S, 2002, INCAS INCREMENTAL AC; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T, 1990, GEN ADDITIVE MODELS; HASTIE T, 2003, EFFICIENT QUADRATIC; Hsu C.-W., 2003, PRACTICAL GUIDE SUPP; JOACHIMS T, 1999, PRACTICAL ADV KERNEL; MARRON S, 2003, OVERVIEW SUPPORT VEC; Pontil M, 1998, NEURAL COMPUT, V10, P955, DOI 10.1162/089976698300017575; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Ripley BD, 1996, PATTERN RECOGNITION; ROSSET S, 2005, IN PRESS ADV NEURAL, V17; ROSSET S, 2004, ADV NEURAL INFORM PR, V16; Rosset S., 2003, PIECEWISE LINEAR REG; Scholkopf Bernard, 2001, LEARNING KERNELS SUP; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Vapnik VN, 1996, NATURE STAT LEARNING; Wahba G, 2000, ADV NEUR IN, P297; Wahba G, 1990, SPLINE MODELS OBSERV; WESTON J, 1998, MULTI CLASS SUPPORT; Williams C., 2000, P 17 INT C MACH LEAR, P1159; ZHU J, 2004, IN PRESS BIOSTATISTI; ZHU J, 2003, L1 NORM SUPPORT VECT	30	207	220	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	OCT	2004	5						1391	1415				25	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026GV	WOS:000236328300007		
J	Bach, FR; Jordan, MI				Bach, FR; Jordan, MI			Beyond independent components: Trees and clusters	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						independent component analysis; graphical models; blind source separation; time series; semiparametric models	BLIND SEPARATION; MODELS; DISTRIBUTIONS	We present a generalization of independent component analysis (ICA), where instead of looking for a linear transform that makes the data components independent, we look for a transforrn that makes the data components well fit by a tree-structured graphical model. This tree-dependent component analysis (TCA) provides a tractable and flexible approach to weakening the assumption of independence in ICA. In particular, TCA allows the underlying graph to have multiple connected components, and thus the method is able to find "clusters" of components such that components are dependent within a cluster and independent between clusters. Finally, we make use of a notion of graphical models for time series due to Brillinger (1996) to extend these ideas to the temporal setting. In particular, we are able to fit models that incorporate tree-structured dependencies among multiple time series.	Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA; Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA	Bach, FR (reprint author), Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA.	FBACH@CS.BERKELEY.EDU; JORDAN@CS.BERKELEY.EDU					AKAHO S, 1999, P INT JOINT C NEURAL; AMARI S, 1996, ADV NEURAL INFORMATI, V8; Attias H, 1999, NEURAL COMPUT, V11, P803, DOI 10.1162/089976699300016458; Bach F.R., 2002, J MACHINE LEARNING R, V3, P1; BACH FR, 2003, ADV NEURAL INFORMATI, V15; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; Belouchrani A, 1997, IEEE T SIGNAL PROCES, V45, P434, DOI 10.1109/78.554307; Bertsimas D, 1997, INTRO LINEAR OPTIMIZ; Bickel P. J., 1998, EFFICIENT ADAPTIVE E; Brillinger D., 1996, REV ECONOMETRICA, V16, P1; Brockwell P. J., 1991, TIME SERIES THEORY M; CARDOSO JF, 1998, P IEEE INT C ACOUSTI; Cardoso JF, 1999, NEURAL COMPUT, V11, P157, DOI 10.1162/089976699300016863; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; CICHOCKI A, 2002, ICALAB TOOLBOXES; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; COMON P, 1989, SIGNAL PROCESSING; Cormen T.H., 1989, INTRO ALGORITHMS; Cover T. M., 1991, ELEMENTS INFORMATION; Dahlhaus R, 2000, METRIKA, V51, P157, DOI 10.1007/s001840000055; DAWID AP, 1993, ANN STAT, V21, P1272, DOI 10.1214/aos/1176349260; Friedman N., 1998, LEARNING BAYESIAN NE; FUKUMIZU K, 2003, 641 CALTECH DEP STAT; Hannan E. J, 1970, MULTIPLE TIME SERIES; Hastie T., 2001, ELEMENTS STAT LEARNI; HASTIE T, 2003, ADV NEURAL INFORMATI, V15; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; Hyvarinen A, 2001, INDEPENDENT COMPONEN; HYVARINEN A, 2001, NEURAL COMPUT, V13, P1525; Hyvarinen A, 2000, NEURAL COMPUT, V12, P1705, DOI 10.1162/089976600300015312; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; JIROUSEK R, 1991, KYBERNETIKA, V27, P403; JORDAN MI, 2002, IN PRESS STAT SCI SP; Lauritzen S.L, 1996, GRAPHICAL MODELS; LODHI H, 2001, ADV NEURAL INFORMATI, V13; LUETTGEN MR, 1994, IEEE T IMAGE PROCESS, V3, P41, DOI 10.1109/83.265979; MILLER EG, 2003, P 4 S IND COMP AN BL; Murphy SA, 2000, J AM STAT ASSOC, V95, P449, DOI 10.2307/2669386; Ombao HC, 2001, BIOMETRIKA, V88, P1186, DOI 10.1093/biomet/88.4.1186; Pearl J., 2000, CAUSALITY MODELS REA; Pham D. T., 2001, P ICA 2001 C; Pham D.T., 2001, SIGNAL PROCESS, V81, P850; PHAM DT, 2003, P 4 S IND COMP AN BL; PHAM DT, 2003, IEEE T INFORMATION T; Pham DT, 2002, IEEE T INFORM THEORY, V48, P1935; PHGAM DT, 1995, IEEE T SIGNAL PROCES, V44, P225; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Scholkopf B., 2001, LEARNING KERNELS; Silverman B.W., 1985, DENSITY ESTIMATION S; Welling M, 2001, NEURAL COMPUT, V13, P677, DOI 10.1162/089976601300014510; Willsky AS, 2002, P IEEE, V90, P1396, DOI 10.1109/JPROC.2002.800717; ZIEHE A, 1998, P INT C ARTIFICIAL N	52	3	3	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	OCT 1	2004	4	7-8					1205	1233				29	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	866YC	WOS:000224808300003		
J	Ping, L; Napel, S; Acar, B; Paik, DS; Jeffrey, RB; Beaulieu, CF				Ping, L; Napel, S; Acar, B; Paik, DS; Jeffrey, RB; Beaulieu, CF			Registration of central paths and colonic polyps between supine and prone scans in computed tomography colonography: Pilot study	MEDICAL PHYSICS			English	Article						CT colonography; computer aided detection; prone and supine registration; statistics; dynamic programming	CT COLONOGRAPHY; VIRTUAL ENDOSCOPY; AIDED DETECTION; DISTENSION	Computed tomography colonography (CTC) is a minimally invasive method that allows the evaluation of the colon wall from CT sections of the abdomen/pelvis. The primary goal of CTC is to detect colonic polyps, precursors to colorectal cancer. Because imperfect cleansing and distension can cause portions of the colon wall to be collapsed, covered with water, and/or covered with retained stool, patients are scanned in both prone and supine positions. We believe that both reading efficiency and computer aided detection (CAD) of CTC images can be improved by accurate registration of data from the supine and prone positions. We developed a two-stage approach that first registers the colonic central paths using a heuristic and automated algorithm and then matches polyps or polyp candidates (CAD hits) by a statistical approach. We evaluated the registration algorithm on 24 patient cases. After path registration, the mean misalignment distance between prone and supine identical anatomic landmarks was reduced from 47.08 to 12.66 mm, a 73% improvement. The polyp registration algorithm was specifically evaluated using eight patient cases for which radiologists identified polyps separately for both supine and prone data sets, and then manually registered corresponding pairs. The algorithm correctly matched 78% of these pairs without user input. The algorithm was also applied to the 30 highest-scoring CAD hits in the prone and supine scans and showed a success rate of 50% in automatically registering corresponding polyp pairs. Finally, we computed the average number of CAD hits that need to be manually compared in order to find the correct matches among the top 30 CAD hits. With polyp registration, the average number of comparisons was 1.78 per polyp, as opposed to 4.28 comparisons without polyp registration. (C) 2004 American Association of Physicists in Medicine.	Stanford Univ, Dept Stat, Stanford, CA 94305 USA; Stanford Univ, Dept Radiol, Stanford, CA 94305 USA; Bogazici Univ, Dept Elect & Elect Engn, TR-34342 Istanbul, Turkey	Ping, L (reprint author), Stanford Univ, Dept Stat, Stanford, CA 94305 USA.	pingli@stat.stanford.edu	Acar, Burak/C-7904-2009				ACAR B, 2001, P 23 ANN INT C IEEE; Acar B, 2002, IEEE T MED IMAGING, V21, P1461, DOI 10.1109/TMI.2002.806405; Chen SC, 1999, AM J ROENTGENOL, V172, P595; COIN CG, 1983, COMPUT RADIOL, V7, P215; Cormen T, 2001, INTRO ALGORITHMS; Dachman A. H., 2003, ATLAS VIRTUAL COLONO; Efron Bradley, 1993, INTRO BOOTSTRAP; Fletcher JG, 2000, RADIOLOGY, V216, P704; Fletcher JG, 1999, AM J ROENTGENOL, V172, P1271; GOKTURK SB, 2000, 2 INT S VIRT COL OCT; Gokturk SB, 2001, IEEE T MED IMAGING, V20, P1251, DOI 10.1109/42.974920; Hastie T., 2001, ELEMENTS STAT LEARNI; Hung PW, 2002, RADIOLOGY, V222, P543, DOI 10.1148/radiol.2222010600; JEREBKO RM, 2003, MED PHYS, V30, P52; LI P, 2002, RADIOLOGY SOC N AM, P406; Paik DS, 1998, MED PHYS, V25, P629, DOI 10.1118/1.598244; Paik DS, 2004, IEEE T MED IMAGING, V23, P661, DOI 10.1109/TMI.2004.826362; PAIK DS, 2001, THESIS STANFORD U; Summers RM, 2000, RADIOLOGY, V216, P284; Vining DJ, 1996, RADIOLOGY, V200, P30; Vining D J, 1997, Gastrointest Endosc Clin N Am, V7, P285; Westin RCF, 2002, P 5 INT C MED IM COM, P573; Wyatt CL, 2000, COMPUT MED IMAG GRAP, V24, P1, DOI 10.1016/S0895-6111(99)00039-7; YAMADA T, 1995, TXB GASTROENTEROL; Yee J, 1999, AM J ROENTGENOL, V173, P169; Yoshida H, 2002, RADIOLOGY, V222, P327, DOI 10.1148/radiol.2222010506; Yoshida H, 2001, IEEE T MED IMAGING, V20, P1261, DOI 10.1109/42.974921; Zalis ME, 2001, AM J ROENTGENOL, V176, P646	28	18	18	AMER ASSOC PHYSICISTS MEDICINE AMER INST PHYSICS	MELVILLE	STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA	0094-2405			MED PHYS	Med. Phys.	OCT	2004	31	10					2912	2923		10.1118/1.1796171		12	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	865ZR	WOS:000224743200025		
J	Tseng, CL; Chen, YH; Xu, YY; Pao, HT; Fu, HC				Tseng, CL; Chen, YH; Xu, YY; Pao, HT; Fu, HC			A self-growing probabilistic decision-based neural network with automatic data clustering	NEUROCOMPUTING			English	Article; Proceedings Paper	2nd International Conference on Hybrid Intelligent Systems	DEC 01-04, 2002	Santiago, CHILE		Univ Chile	self-growing probabilistic decision-based neural networks (SPDNN); supervised learning; automatic data clustering; validity measure; Bayesian information criterion	VECTOR QUANTIZER DESIGN; COMPUTER VISION; EM ALGORITHM	In this paper, we propose a new clustering algorithm for a mixture of Gaussian-based neural network and self-growing probabilistic decision-based neural networks (SPDNN). The proposed self-growing cluster learning (SGCL) algorithm is able to find the natural number of prototypes based on a self-growing validity measure, Bayesian information criterion (BIC). The learning process starts from a single prototype randomly initialized in the feature space and grows adaptively during the learning process until most appropriate number of prototypes are found. We have conducted numerical and real-world experiments to demonstrate the effectiveness of the SGCL algorithm. In the results of using SGCL to train the SPDNN for data clustering and speaker identification problems, we have observed a noticeable improvement among various model-based or vector quantization-based classification schemes. (C) 2004 Elsevier B.V. All rights reserved.	Natl Chiao Tung Univ, Dept Comp Sci & Informat Engn, Hsinchu, Taiwan; Natl Chiao Tung Univ, Dept Management Sci, Hsinchu, Taiwan	Tseng, CL (reprint author), Natl Chiao Tung Univ, Dept Comp Sci & Informat Engn, Hsinchu, Taiwan.						ATLAS L, 1990, P IEEE, V78, P1614, DOI 10.1109/5.58347; CHUNG FL, 1994, NEURAL NETWORKS, V7, P539; DACAESTECKER C, 1988, P IEEE INT NEUR NETW, V2, P833; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Farrell KR, 1994, IEEE T SPEECH AUDI P, V2, P194, DOI 10.1109/89.260362; FORGY EW, 1965, BIOMETRICS, V21, P768; Frigui H, 1999, IEEE T PATTERN ANAL, V21, P450, DOI 10.1109/34.765656; FRITZKE B, 1994, NEURAL PROCESS LETT, V1, P2, DOI 10.1007/BF02312392; FRITZKE B, 1994, NEURAL NETWORKS, V7, P1441, DOI 10.1016/0893-6080(94)90091-4; Fu HC, 2000, IEEE T NEURAL NETWOR, V11, P1373, DOI 10.1109/72.883451; HASTIE T, 2001, ELEMENTS STAT LEARNI, P206; Hertz J., 1991, INTRO THEORY NEURAL; HOU FL, 2000, P WCCC ICSP, V2, P710; *I INF SCI AC SIN, TCC 300 SPAC DAT; JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588; JOLION JM, 1991, IEEE T PATTERN ANAL, V13, P791, DOI 10.1109/34.85669; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572; KUNG SY, 1995, IEEE T NEURAL NETWOR, V6, P170, DOI 10.1109/72.363439; Lin SH, 1997, IEEE T NEURAL NETWOR, V8, P114; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; LIU ZQ, 2000, SOFT COMPUTING HUMAN, P131; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; Macqueen J.B., 1967, P 5 BERK S MATH STAT, P281; MARTINETZ TM, 1993, IEEE T NEURAL NETWOR, V4, P558, DOI 10.1109/72.238311; Raftery AE, 1995, SOCIOL METHODOL, V25, P111, DOI 10.2307/271063; Ripley BD, 1996, PATTERN RECOGNITION; RUMELHART DE, 1985, COGNITIVE SCI, V9, P75, DOI 10.1207/s15516709cog0901_5; WANG HC, 2000, P OR COCOSDA WORKSH; XU L, 1993, IEEE T NEURAL NETWOR, V4, P636, DOI 10.1109/72.238318; YAIR E, 1992, IEEE T SIGNAL PROCES, V40, P294, DOI 10.1109/78.124940; Zhang YJ, 2002, IEEE T NEURAL NETWOR, V13, P369, DOI 10.1109/72.991422	32	6	6	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312			NEUROCOMPUTING	Neurocomputing	OCT	2004	61				SI		21	38		10.1016/j.neucom.2004.03.002		18	Computer Science, Artificial Intelligence	Computer Science	862SO	WOS:000224511500003		
J	Alacam, B; Yazici, B; Bilgutay, N; Forsberg, F; Piccoli, C				Alacam, B; Yazici, B; Bilgutay, N; Forsberg, F; Piccoli, C			Breast tissue characterization using FARMA modeling of ultrasonic RF echo	ULTRASOUND IN MEDICINE AND BIOLOGY			English	Article						ultrasound RF echo modeling; fractional differencing; tissue characterization; breast cancer; computer aided diagnosis	NON-RAYLEIGH STATISTICS; K-DISTRIBUTION; SPECKLE; IMAGES; NOISE	A number of empirical and analytical studies demonstrated that the ultrasound RF echo reflected from tissue exhibits 1/f characteristics. In this paper, we propose to model 1/f characteristics of the ultrasonic RF echo by a novel parsimonious model, namely the fractional differencing auto regressive moving average (FARMA) process, and evaluated diagnostic value of model parameters for breast cancer malignancy differentiation. FARMA model captures the fractal and long term correlated nature of the backscattered speckle texture and facilitates robust efficient estimation of fractal parameters. In our study, in addition to the computer generated FARMA model parameters, we included patient age and radiologist's prebiopsy level of suspicion (LOS) as potential indicators of malignant and benign masses. We evaluated the performance of the proposed set of features using various classifiers and training methods using 120 in vivo breast images. Our study shows that the area under the receiver operating characteristics (ROC) curve of FARMA model parameters alone is superior to the area under the ROC curve of the radiologist's prebiopsy LOS. The area under the ROC curve of the three sets of features yields a value of 0.87, with a confidence interval of [0.85, 0.89], at a significance level of 0.05. Our results suggest that the proposed method of ultrasound RF echo model leads to parameters that can differentiate breast tumors with a relatively high precision. This set of RF echo features can be incorporated into a comprehensive computer-aided diagnostic system to aid physicians in breast cancer diagnosis. (C) 2004 World Federation for Ultrasound in Medicine Biology.	Rensselaer Polytech Inst Elect Comp & Syst Engn, Troy, NY 12180 USA; Drexel Univ, Philadelphia, PA 19104 USA; Thomas Jefferson Univ, Dept Radiol, Philadelphia, PA 19107 USA	Yazici, B (reprint author), Rensselaer Polytech Inst Elect Comp & Syst Engn, 110 8th St,Johnsson Engn Bldg JEC 7008, Troy, NY 12180 USA.	yazici@ecsc.rpi.edu	Bhatt, Jay/A-1333-2007				Abeyratne UR, 1997, IEEE T ULTRASON FERR, V44, P1409, DOI 10.1109/58.656646; Abeyratne UR, 1997, PROCEEDINGS OF THE IEEE SIGNAL PROCESSING WORKSHOP ON HIGHER-ORDER STATISTICS, P72, DOI 10.1109/HOST.1997.613490; AKAIKE H, 1970, ANN I STAT MATH, V22, P203, DOI 10.1007/BF02506337; American Cancer Society, 2003, CANC FACTS FIG; ANDERSON O, 1976, ANAL FORECASTING BOX; Bonanno G., 2001, Proceedings of the 16th International Conference. Noise in Physical Systems and 1/f Fluctuations. ICNF 2001; Box GEP, 1976, TIME SERIES ANAL; Brockwell P. J., 1991, TIME SERIES THEORY M; CETIN M, 1998, P IEEE C IM PROC OCT, V1, P587, DOI 10.1109/ICIP.1998.723570; CHATFIELD C, 1975, ANAL TIME SERIES THE, V2, P488; COHEN FS, 1995, P IEEE INT C IM PROC, V2, P488, DOI 10.1109/ICIP.1995.537522; Cohen FS, 1997, IEEE T ULTRASON FERR, V44, P460, DOI 10.1109/58.585131; DONOHUE KD, 2001, P IEEE INT C AC SPEE, V6, P3401; Duda R. O., 2000, PATTERN CLASSIFICATI; Dumane VA, 2001, IEEE T ULTRASON FERR, V48, P1139, DOI 10.1109/58.935733; DUTT V, 1994, ULTRASONIC IMAGING, V16, P265, DOI 10.1006/uimg.1994.1016; Fukunaga K, 1990, INTRO STAT PATTERN R; Hastie T., 2001, ELEMENTS STAT LEARNI; HOSKING JRM, 1981, BIOMETRIKA, V68, P165, DOI 10.1093/biomet/68.1.165; *IARC, 2001, CANC INC MORT PREV W; ILOW J, 2000, IEEE T COM, P505; KARAOGUZ M, 2000, IEEE ULTRASONICS S, V1, P793; KASHYAP RL, 1984, IEEE T PATTERN ANAL, V6, P800; KASHYAP RL, 1989, IEEE T PATTERN ANAL, V11, P58, DOI 10.1109/34.23113; KASHYAP RL, 1988, J TIME SER ANAL, V9, P35, DOI 10.1111/j.1467-9892.1988.tb00451.x; Kutay MA, 2001, IEEE T ULTRASON FERR, V48, P953, DOI 10.1109/58.935712; KUTAY MA, 2000, IEEE ULTR S, P1383; Langer MS, 2000, J OPT SOC AM A, V17, P28, DOI 10.1364/JOSAA.17.000028; MANDELBR.BB, 1968, SIAM REV, V10, P422, DOI 10.1137/1010093; NARAYANAN VM, 1994, IEEE T ULTRASON FERR, V41, P845, DOI 10.1109/58.330265; *NAT CANC I, 2002, CANC FACTS LIF PROB; Rainville SJM, 1999, J OPT SOC AM A, V16, P2112, DOI 10.1364/JOSAA.16.002112; ROGER EK, 1999, STAT INTRO; SHANKAR PM, 1995, PHYS MED BIOL, V40, P1633, DOI 10.1088/0031-9155/40/10/006; Shankar PM, 2001, IEEE T ULTRASON FERR, V48, P569, DOI 10.1109/58.911740; Shankar PM, 1996, ULTRASOUND MED BIOL, V22, P873, DOI 10.1016/0301-5629(96)00080-4; TUTHILL TA, 1988, ULTRASONIC IMAGING, V10, P81, DOI 10.1016/0161-7346(88)90051-X; WAGNER RF, 1983, IEEE T SON ULTRASON, V30, P156, DOI 10.1109/T-SU.1983.31404; WEN CY, 1998, IM PROC INT C LAUS S, P165; Xiong HD, 2002, IEEE T NUCL SCI, V49, P2718, DOI 10.1109/TNS.2002.805354; YAZICI B, 1996, P ICASSP 96, P2841	41	6	6	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0301-5629			ULTRASOUND MED BIOL	Ultrasound Med. Biol.	OCT	2004	30	10					1397	1407		10.1016/j.ultra.medbio.2004.08.023		11	Acoustics; Radiology, Nuclear Medicine & Medical Imaging	Acoustics; Radiology, Nuclear Medicine & Medical Imaging	877GY	WOS:000225557100016	15582240	
J	Cummings, MP; Segal, MR				Cummings, MP; Segal, MR			Few amino acid positions in rpoB are associated with most of the rifampin resistance in Mycobacterium tuberculosis	BMC BIOINFORMATICS			English	Article							SUSCEPTIBILITY; MUTATIONS	Background: Mutations in rpoB, the gene encoding the beta subunit of DNA-dependent RNA polymerase, are associated with rifampin resistance in Mycobacterium tuberculosis. Several studies have been conducted where minimum inhibitory concentration ( MIC, which is defined as the minimum concentration of the antibiotic in a given culture medium below which bacterial growth is not inhibited) of rifampin has been measured and partial DNA sequences have been determined for rpoB in different isolates of M. tuberculosis. However, no model has been constructed to predict rifampin resistance based on sequence information alone. Such a model might provide the basis for quantifying rifampin resistance status based exclusively on DNA sequence data and thus eliminate the requirements for time consuming culturing and antibiotic testing of clinical isolates. Results: Sequence data for amino acid positions 511-533 of rpoB and associated MIC of rifampin for different isolates of M. tuberculosis were taken from studies examining rifampin resistance in clinical samples from New York City and throughout Japan. We used tree-based statistical methods and random forests to generate models of the relationships between rpoB amino acid sequence and rifampin resistance. The proportion of variance explained by a relatively simple tree-based cross-validated regression model involving two amino acid positions (526 and 531) is 0.679. The first partition in the data, based on position 531, results in groups that differ one hundredfold in mean MIC (1.596 mug/ml and 159.676 mug/ml). The subsequent partition based on position 526, the most variable in this region, results in a > 354-fold difference in MIC. When considered as a classification problem ( susceptible or resistant), a cross-validated tree-based model correctly classified most (0.884) of the observations and was very similar to the regression model. Random forest analysis of the MIC data as a continuous variable, a regression problem, produced a model that explained 0.861 of the variance. The random forest analysis of the MIC data as discrete classes produced a model that correctly classified 0.942 of the observations with sensitivity of 0.958 and specificity of 0.885. Conclusions: Highly accurate regression and classification models of rifampin resistance can be made based on this short sequence region. Models may be better with improved ( and consistent) measurements of MIC and more sequence data.	Univ Maryland, Ctr Bioinformat & Computat Biol, College Pk, MD 20742 USA; Univ Calif San Francisco, Dept Epidemiol & Biostat, San Francisco, CA 94143 USA	Cummings, MP (reprint author), Univ Maryland, Ctr Bioinformat & Computat Biol, College Pk, MD 20742 USA.	mike@umiacs.umd.edu; mark@biostat.ucsf.edu					BASS JB, 1994, AM J RESP CRIT CARE, V149, P1359; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BREIMAN L, 2004, RPART PACKAGE RECURS; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Clark LA, 1993, STAT MODELS S, P377; CUMMINGS MP, 2004, CSTR4581; Cummings MP, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-132; Efron Bradley, 1993, INTRO BOOTSTRAP; Espinal MA, 2001, NEW ENGL J MED, V344, P1294, DOI 10.1056/NEJM200104263441706; Hastie T., 2001, ELEMENTS STAT LEARNI; HEIFETS L, 1988, AM REV RESPIR DIS, V137, P1217; Ihaka R, 2005, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Moghazeh SL, 1996, ANTIMICROB AGENTS CH, V40, P2655; MYERS DS, 2004, CSTR4584; Ohno H, 1997, AM J RESP CRIT CARE, V155, P2057; Segal MR, 2001, BIOMETRICS, V57, P632, DOI 10.1111/j.0006-341X.2001.00632.x; SEGAL MR, 2004, STAT APPL GENETICS M, V3; Siddiqi N, 2002, ANTIMICROB AGENTS CH, V46, P443, DOI 10.1128/AAC.46.2.443-450.2002; Taniguchi H, 1996, FEMS MICROBIOL LETT, V144, P103, DOI 10.1111/j.1574-6968.1996.tb08515.x; Therneau TM, 1997, INTRO RECURSIVE PART; THERNEAU TM, 2003, RPART PACKAGE RECURS; Williams DL, 1998, ANTIMICROB AGENTS CH, V42, P1853	25	15	17	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	SEP 28	2004	5								137	10.1186/1471-2105-5-137		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	868VC	WOS:000224940100001	15453919	
J	Cummings, MP; Myers, DS				Cummings, MP; Myers, DS			Simple statistical models predict C-to-U edited sites in plant mitochondrial RNA	BMC BIOINFORMATICS			English	Article							WHEAT MITOCHONDRIA; LAND PLANTS; CHLOROPLASTS; RECOGNITION; SEQUENCE; EVOLUTION; ELEMENTS; GENOME; L.	Background: RNA editing is the process whereby an RNA sequence is modified from the sequence of the corresponding DNA template. In the mitochondria of land plants, some cytidines are converted to uridines before translation. Despite substantial study, the molecular biological mechanism by which C-to-U RNA editing proceeds remains relatively obscure, although several experimental studies have implicated a role for cis-recognition. A highly non-random distribution of nucleotides is observed in the immediate vicinity of edited sites (within 20 nucleotides 5' and 3'), but no precise consensus motif has been identified. Results: Data for analysis were derived from the the complete mitochondrial genomes of Arabidopsis thaliana, Brassica napus, and Oryza sativa; additionally, a combined data set of observations across all three genomes was generated. We selected datasets based on the 20 nucleotides 5' and the 20 nucleotides 3' of edited sites and an equivalently sized and appropriately constructed null-set of non-edited sites. We used tree-based statistical methods and random forests to generate models of C-to-U RNA editing based on the nucleotides surrounding the edited/non-edited sites and on the estimated folding energies of those regions. Tree-based statistical methods based on primary sequence data surrounding edited/non-edited sites and estimates of free energy of folding yield models with optimistic re-substitution-based estimates of similar to0.71 accuracy, similar to0.64 sensitivity, and similar to0.88 specificity. Random forest analysis yielded better models and more exact performance estimates with similar to0.74 accuracy, similar to0.72 sensitivity, and similar to0.81 specificity for the combined observations. Conclusions: Simple models do moderately well in predicting which cytidines will be edited to uridines, and provide the first quantitative predictive models for RNA edited sites in plant mitochondria. Our analysis shows that the identity of the nucleotide -1 to the edited C and the estimated free energy of folding for a 41 nt region surrounding the edited C are the most important variables that distinguish most edited from non-edited sites. However, the results suggest that primary sequence data and simple free energy of folding calculations alone are insufficient to make highly accurate predictions.	Univ Maryland, Ctr Bioinformat & Computat Biol, College Pk, MD 20742 USA	Cummings, MP (reprint author), Univ Maryland, Ctr Bioinformat & Computat Biol, College Pk, MD 20742 USA.	mike@umiacs.umd.edu; dmyers@umiacs.umd.edu					ARYA A, 1995, BIOCHIMIE, V77, P87; Benson DA, 2004, NUCLEIC ACIDS RES, V32, pD23, DOI 10.1093/nar/gkh045; BLANC V, 1995, FEBS LETT, V373, P56, DOI 10.1016/0014-5793(95)00991-H; BREIMAN L, 2001, 567 U CAL DEP STAT; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Carrillo C, 1997, NUCLEIC ACIDS RES, V25, P403, DOI 10.1093/nar/25.2.403; Chateigner-Boutin AL, 2002, MOL CELL BIOL, V22, P8448, DOI 10.1128/MCB.22.24.8448-8456.2002; Clark L.A., 1993, STAT MODELS S; CUMMINGS MP, 2004, CSTR4581 U MAR I ADV; Farre JC, 2001, MOL CELL BIOL, V21, P6731, DOI 10.1128/MCB.21.20.6731-6737.2001; Freyer R, 1997, P NATL ACAD SCI USA, V94, P6285, DOI 10.1073/pnas.94.12.6285; Giege P, 1999, P NATL ACAD SCI USA, V96, P15324, DOI 10.1073/pnas.96.26.15324; GRAY MW, 1993, FASEB J, V7, P64; Gray MW, 2003, IUBMB LIFE, V55, P227, DOI 10.1080/1521654031000119425; Gray MW, 1996, P NATL ACAD SCI USA, V93, P8157, DOI 10.1073/pnas.93.16.8157; GUALBERTO JM, 1989, NATURE, V341, P660, DOI 10.1038/341660a0; Handa H, 2003, NUCLEIC ACIDS RES, V31, P5907, DOI 10.1093/nar/gkg795; Hastie T., 2001, ELEMENTS STAT LEARNI; HIESEL R, 1994, P NATL ACAD SCI USA, V91, P629, DOI 10.1073/pnas.91.2.629; HIESEL R, 1989, SCIENCE, V246, P1632, DOI 10.1126/science.2480644; Ihaka R, 2005, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Maier RM, 1996, PLANT MOL BIOL, V32, P343, DOI 10.1007/BF00039390; Malek O, 1996, EMBO J, V15, P1403; MATHEWS DH, 1999, J MOL BIOL, V288, P910; Mulligan RM, 1999, J HERED, V90, P338, DOI 10.1093/jhered/90.3.338; Notsu Y, 2002, MOL GENET GENOMICS, V268, P434, DOI 10.1007/s00438-002-0767-1; RAJASEKHAR VK, 1993, PLANT CELL, V5, P1843; Segal MR, 2001, BIOMETRICS, V57, P632, DOI 10.1111/j.0006-341X.2001.00632.x; Smith HC, 1997, RNA, V3, P1105; Therneau TM, 1997, INTRO RECURSIVE PART; Wakasugi T, 1996, P NATL ACAD SCI USA, V93, P8766, DOI 10.1073/pnas.93.16.8766; Williams MA, 1998, PLANT MOL BIOL, V36, P229, DOI 10.1023/A:1005961718612; YU W, 1995, J BIOL CHEM, V270, P18227; YU W, 1995, BIOCHIMIE, V77, P79, DOI 10.1016/0300-9084(96)88108-9; Zuker M, 1999, NATO SCI PARTNERSHIP, V70, P11	37	26	27	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	SEP 16	2004	5								132	10.1186/1471-2105-5-132		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	863PZ	WOS:000224575400001	15373947	
J	Lu, XH; Zhai, CX; Gopalakrishnan, V; Buchanan, BG				Lu, XH; Zhai, CX; Gopalakrishnan, V; Buchanan, BG			Automatic annotation of protein motif function with Gene Ontology terms	BMC BIOINFORMATICS			English	Article							DATABASE; ALIGNMENT; FAMILIES; DOMAINS; PRODOM; TOOL; CDD	Background: Conserved protein sequence motifs are short stretches of amino acid sequence patterns that potentially encode the function of proteins. Several sequence pattern searching algorithms and programs exist foridentifying candidate protein motifs at the whole genome level. However, amuch needed and importanttask is to determine the functions of the newly identified protein motifs. The Gene Ontology ( GO) project is an endeavor to annotate the function of genes or protein sequences with terms from a dynamic, controlled vocabulary and these annotations serve well as a knowledge base. Results: This paperpresents methods to mine the GO knowledge base and use the association between the GO terms assigned to a sequence and the motifs matched by the same sequence as evidence for predicting the functions of novel protein motifs automatically. The task of assigning GO terms to protein motifsis viewed as both a binary classification and information retrieval problem, where PROSITE motifs are used as samples for mode training and functional prediction. The mutual information of a motif and aGO term association isfound to be a very useful feature. We take advantageof the known motifs to train a logistic regression classifier, which allows us to combine mutual information with other frequency-based features and obtain a probability of correctassociation. The trained logistic regression model has intuitively meaningful and logically plausible parameter values, and performs very well empirically according to our evaluation criteria. Conclusions: In this research, different methods for automatic annotation of protein motifs have been investigated. Empirical result demonstrated that the methods have a great potential for detecting and augmenting information about thefunctions of newly discovered candidate protein motifs.	Med Univ S Carolina, Dept Biostat Bioinformat & Epidemiol, Charleston, SC 29425 USA; Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; Univ Pittsburgh, Ctr Biomed Informat, Pittsburgh, PA 15213 USA	Lu, XH (reprint author), Med Univ S Carolina, Dept Biostat Bioinformat & Epidemiol, 135 Cannon St Suite 303, Charleston, SC 29425 USA.	lux@musc.edu; czhai@cs.uiuc.edu; vanathi@cbmi.pitt.edu; buchanan@cs.pitt.edu					ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Bateman A, 2002, NUCLEIC ACIDS RES, V30, P276, DOI 10.1093/nar/30.1.276; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Brazma A, 1998, J COMPUT BIOL, V5, P279, DOI 10.1089/cmb.1998.5.279; Brejova B., 2000, CS200022 U WAT; Califano A, 2000, BIOINFORMATICS, V16, P341, DOI 10.1093/bioinformatics/16.4.341; *CONS TGO, 2001, GENOME RES, P1425; Corpet F, 2000, NUCLEIC ACIDS RES, V28, P267, DOI 10.1093/nar/28.1.267; Cover T. M., 1991, ELEMENTS INFORMATION; Falquet L, 2002, NUCLEIC ACIDS RES, V30, P235, DOI 10.1093/nar/30.1.235; Hastie T., 2001, ELEMENTS STAT LEARNI; Henikoff JG, 2000, NUCLEIC ACIDS RES, V28, P228, DOI 10.1093/nar/28.1.228; Hosmer DW, 1989, APPL LOGISTIC REGRES; LAWRENCE CE, 1993, SCIENCE, V262, P208, DOI 10.1126/science.8211139; Marchler-Bauer A, 2003, NUCLEIC ACIDS RES, V31, P383, DOI 10.1093/nar/gkg087; Raychaudhuri S, 2002, GENOME RES, V12, P203, DOI 10.1101/gr.199701; Rigoutsos I, 1998, BIOINFORMATICS, V14, P229; Rigoutsos I, 2002, NUCLEIC ACIDS RES, V30, P3901, DOI 10.1093/nar/gkf464; Schug J, 2002, GENOME RES, V12, P648, DOI 10.1101/gr.222902; Schultz J, 1998, P NATL ACAD SCI USA, V95, P5857, DOI 10.1073/pnas.95.11.5857; Xie HQ, 2002, GENOME RES, V12, P785, DOI 10.1101/gr.86902; YANG Y, 1999, J INFORMATION RETRIE, V1	22	16	17	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	SEP 2	2004	5								122	10.1186/1471-2105-5-122		11	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	856KK	WOS:000224043900002	15345032	
J	Mansouri, H; Paige, RL; Surles, JG				Mansouri, H; Paige, RL; Surles, JG			Aligned rank transform techniques for analysis of variance and multiple comparisons	COMMUNICATIONS IN STATISTICS-THEORY AND METHODS			English	Article; Proceedings Paper	Conference on Non/Semi-Parametric Models and Sequential Analysis held in honor of Z Govindarajulu	JUN   28, 2003	Lexington, KY		Univ Kentucky, Young Lib	aligned ranking; rank transformation; analysis of variance; multiple comparison; simulation	LINEAR-MODELS; NONPARAMETRIC HYPOTHESES; FACTORIAL-DESIGNS; TESTS; MULTIVARIATE; ROBUST; STATISTICS	The aligned rank transform (ART) technique for testing linear hypotheses and performing multiple comparisons is known to provide a powerful and robust nonparametric alternative to the usual classical analysis techniques where a normal error distribution is assumed. ART procedures are also known to provide results that are more powerful and robust when compared with other procedures. In this paper, we review the ART testing procedures in linear models. We pay special attention to the two-way layout and multiple comparison techniques, and attempt to show the ease with which the ART methods can be implemented by researchers desiring a nonparametric alternative to the usual least squares methods. Some examples are given for analyzing a two-way layout and performing multiple comparisons. The results of a small-scale simulation study are also presented to show that the ART testing procedures may be quite robust against violations of the assumption of a continuous error distribution.	Texas Tech Univ, Dept Math & Stat, Lubbock, TX 79409 USA	Mansouri, H (reprint author), Texas Tech Univ, Dept Math & Stat, Lubbock, TX 79409 USA.	mansouri@koch.math.ttu.edu					ADICHIE JN, 1978, ANN STAT, V6, P1021; AKRITAS MG, 1990, J AM STAT ASSOC, V85, P73, DOI 10.2307/2289527; AKRITAS MG, 1994, J AM STAT ASSOC, V89, P336, DOI 10.2307/2291230; Akritas MG, 1997, J AM STAT ASSOC, V92, P258, DOI 10.2307/2291470; Anderson VL, 1974, DESIGN EXPT REALISTI; Barefield EW, 2001, J NONPARAMETR STAT, V13, P591, DOI 10.1080/10485250108832867; CHIANG CY, 1984, ANN I STAT MATH, V36, P35, DOI 10.1007/BF02481951; CONOVER WJ, 1981, AM STAT, V35, P124, DOI 10.2307/2683975; Cox DR, 1974, THEORETICAL STAT; Draper N.R., 1966, APPL REGRESSION ANAL; Hastie T., 2002, ELEMENTS STAT LEARNI; HETTMANSPERGER TP, 1983, J AM STAT ASSOC, V78, P885, DOI 10.2307/2288200; HETTMANSPERGER TP, 1977, TECHNOMETRICS, V19, P275, DOI 10.2307/1267697; Hollander M., 1999, NONPARAMETRIC STAT M; JAECKEL LA, 1997, ANN MATH STAT, V42, P1449; Mansouri H, 1998, J STAT PLAN INFER, V74, P353, DOI 10.1016/S0378-3758(98)00108-6; MANSOURI H, 1995, COMPUT STAT DATA AN, V19, P85, DOI 10.1016/0167-9473(93)E0045-6; Mansouri H., 1999, COMPUT STAT DATA AN, V29, P177; Mansouri H, 1999, J STAT PLAN INFER, V79, P141, DOI 10.1016/S0378-3758(98)00229-8; Rice J, 1988, MATH STAT DATA ANAL; SALTER KC, 1993, COMMUN STAT SIMULAT, V22, P137, DOI 10.1080/03610919308813085; SALTER KC, 1985, COMMUN STAT SIMULAT, V14, P807, DOI 10.1080/03610918508812475; SEN PK, 1977, Z WAHRSCHEINLICHKEIT, V39, P175, DOI 10.1007/BF00535470; THOMPSON GL, 1991, J AM STAT ASSOC, V86, P410, DOI 10.2307/2290586; Westfall P.H., 1999, MULTIPLE COMPARISONS	25	4	4	MARCEL DEKKER INC	NEW YORK	270 MADISON AVE, NEW YORK, NY 10016 USA	0361-0926			COMMUN STAT-THEOR M	Commun. Stat.-Theory Methods	SEP	2004	33	9					2217	2232		10.1081/STA-200026599		16	Statistics & Probability	Mathematics	865ZK	WOS:000224742500016		
J	Williams, RD; Hing, SN; Greer, BT; Whiteford, CC; Wei, JS; Natrajan, R; Kelsey, A; Rogers, S; Campbell, C; Pritchard-Jones, K; Khan, J				Williams, RD; Hing, SN; Greer, BT; Whiteford, CC; Wei, JS; Natrajan, R; Kelsey, A; Rogers, S; Campbell, C; Pritchard-Jones, K; Khan, J			Prognostic classification of relapsing favorable histology Wilms tumor using cDNA microarray expression profiling and support vector machines	GENES CHROMOSOMES & CANCER			English	Article							GENE-EXPRESSION; BREAST-CANCER; DIFFERENTIAL EXPRESSION; NEPHROBLASTOMA; RECEPTOR; COMPARTMENTS; PREDICTION; PROTEINS; SURVIVAL; SYSTEM	Treatment of Wilms tumor has a high success rate, with some 85% of patients achieving long-term survival. However, late effects of treatment and management of relapse remain significant clinical problems. If accurate prognostic methods were available, effective risk-adapted therapies could be tailored to individual patients at diagnosis. Few molecular prognostic markers for Wilms tumor are currently defined, though previous studies have linked allele loss on 1p or 16q, genomic gain of 1q, and overexpression from 1q with an increased risk of relapse. To identify specific patterns of gene expression that are predictive of relapse, we used high-density (30 k) cDNA microarrays to analyze RNA samples from 27 favorable histology Wilms tumors taken from primary nephrectomies at the time of initial diagnosis. Thirteen of these tumors relapsed within 2 years. Genes differentially expressed between the relapsing and nonrelapsing tumor classes were identified by statistical scoring (t test). These genes encode proteins with diverse molecular functions, including transcription factors, developmental regulators, apoptotic factors, and signaling molecules. Use of a support vector machine classifier, feature selection, and test evaluation using cross-validation led to identification of a generalizable expression signature, a small subset of genes whose expression potentially can be used to predict tumor outcome in new samples. Similar methods were used to identify genes that are differentially expressed between tumors with and without genomic 1q gain. This set of discriminators was highly enriched in genes on 1q, indicating close agreement between data obtained from expression profiling with data from genomic copy number analyses. (C) 2004 Wiley-Liss, Inc.	Inst Canc Res, Sect Paediat Oncol, Sutton SM2 5NG, Surrey, England; NCI, Oncogenom Sect, Pediat Oncol Branch, Ctr Adv Technol, Gaithersburg, MD USA; Royal Manchester Childrens Hosp, Dept Paediat Pathol, Manchester M27 1HA, Lancs, England; Univ Bristol, Dept Engn Math, Bristol BS8 1TH, Avon, England	Williams, RD (reprint author), Inst Canc Res, Sect Paediat Oncol, 15 Cotswold Rd, Sutton SM2 5NG, Surrey, England.	richardw@icr.ac.uk	Pritchard-Jones, Kathy/F-4286-2014	Pritchard-Jones, Kathy/0000-0002-2384-9475			Arcellana-Panlilio MY, 2000, GENE CHROMOSOME CANC, V29, P63; BARDEESY N, 1994, NAT GENET, V7, P91, DOI 10.1038/ng0594-91; Beer DG, 2002, NAT MED, V8, P816, DOI 10.1038/nm733; BENGTSSON H, 2002, OBJECT ORIENTED MICR; Camassei FD, 2003, MED PEDIATR ONCOL, V40, P302, DOI 10.1002/mpo.10274; Chapoval AI, 2001, NAT IMMUNOL, V2, P269, DOI 10.1038/85339; Chen YD, 2002, BIOINFORMATICS, V18, P1207, DOI 10.1093/bioinformatics/18.9.1207; Dhanasekaran SM, 2001, NATURE, V412, P822, DOI 10.1038/35090585; Dome JS, 1999, CANCER RES, V59, P4301; Dome JS, 2002, CURR OPIN PEDIATR, V14, P5, DOI 10.1097/00008480-200202000-00002; DONOVAN MJ, 1994, AM J PATHOL, V145, P792; DUDOIT S, 2003, STAT ANAL GENE EXPRE, P115; Dyrskjot L, 2003, NAT GENET, V33, P90, DOI 10.1038/ng1061; Efferth T, 2001, INT J ONCOL, V19, P367; Efferth T, 2001, ANTICANCER RES, V21, P2915; Eggert A, 2001, J CLIN ONCOL, V19, P689; Franzon VL, 1999, INT J BIOCHEM CELL B, V31, P613, DOI 10.1016/S1357-2725(98)00155-1; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Ghanems MA, 2001, BRIT J CANCER, V85, P1557, DOI 10.1054/bjoc.2001.2146; Ghanem MA, 2003, J CLIN PATHOL, V56, P107, DOI 10.1136/jcp.56.2.107; Ghanem MA, 2000, CLIN CANCER RES, V6, P4265; Ghanem MA, 2002, J UROLOGY, V168, P681, DOI 10.1016/S0022-5347(05)64723-4; Ghanem MA, 2001, CANCER, V92, P3120, DOI 10.1002/1097-0142(20011215)92:12<3120::AID-CNCR10173>3.0.CO;2-2; Hastie T, 2001, ELEMENTS STAT LEARNI, P193; Hegde P, 2000, BIOTECHNIQUES, V29, P548; Hing S, 2001, AM J PATHOL, V158, P393, DOI 10.1016/S0002-9440(10)63982-X; Kent WJ, 2002, GENOME RES, V12, P656, DOI [10.1101/gr.229202, 10.1101/gr.229202. Article published online before March 2002]; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Li CM, 2002, AM J PATHOL, V160, P2181, DOI 10.1016/S0002-9440(10)61166-2; Lu YJ, 2002, LANCET, V360, P385, DOI 10.1016/S0140-6736(02)09596-X; NISEN PD, 1986, CANCER RES, V46, P6217; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; PRITCHARDJONES K, 1991, ONCOGENE, V6, P2211; Re GG, 1997, MODERN PATHOL, V10, P129; REEVE AE, 1985, NATURE, V317, P258, DOI 10.1038/317258a0; Saeed AI, 2003, BIOTECHNIQUES, V34, P374; Saikali Z, 2000, INT J CANCER, V89, P418; Sakamoto K, 2002, J BIOL CHEM, V277, P29399, DOI 10.1074/jbc.M203727200; Schuler GD, 1996, SCIENCE, V274, P540, DOI 10.1126/science.274.5287.540; Schulz S, 2000, J PATHOL, V191, P162; SCOTT J, 1985, NATURE, V317, P260, DOI 10.1038/317260a0; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Skotnicka-Klonowicz G, 2002, EUR J SURG ONCOL, V28, P67, DOI 10.1053/ejso.2001.1208; Sorlie T, 2001, P NATL ACAD SCI USA, V98, P10869, DOI 10.1073/pnas.191367098; Sredni ST, 2001, MED PEDIATR ONCOL, V37, P455, DOI 10.1002/mpo.1229; Sturn A, 2002, BIOINFORMATICS, V18, P207, DOI 10.1093/bioinformatics/18.1.207; Takahashi M, 2002, CANCER RES, V62, P6598; Toretsky JA, 2001, J PEDIAT HEMATOL ONC, V23, P496, DOI 10.1097/00043426-200111000-00006; Udtha M, 2003, ONCOGENE, V22, P3821, DOI 10.1038/sj.onc.1206597; van de Vijver MJ, 2002, NEW ENGL J MED, V347, P1999, DOI 10.1056/NEJMoa021967; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; WeberHall SR, 1996, CANCER RES, V56, P3220; West M, 2001, P NATL ACAD SCI USA, V98, P11462, DOI 10.1073/pnas.201162998	53	34	37	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	1045-2257			GENE CHROMOSOME CANC	Gene Chromosomes Cancer	SEP	2004	41	1					65	79		10.1002/gcc.20060		15	Oncology; Genetics & Heredity	Oncology; Genetics & Heredity	840PA	WOS:000222870200007	15236318	
J	Manette, OFL; Maier, MA				Manette, OFL; Maier, MA			Temporal processing in primate motor control: Relation between cortical and EMG activity	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						backpropagation; biological motor system; biological system modeling; brain modeling; electromyography; neural network applications; perceptron; transfer function	TASK-DEPENDENT MODULATION; CORTICOMOTONEURONAL CELLS; PRECISION GRIP; VOLUNTARY MOVEMENT; RESPONSE PATTERNS; PREMOTOR NEURONS; MONKEY; MOTONEURONS; CORTEX; SYNCHRONIZATION	We investigated spatio-temporal information processing in the primate motor system. Corticomotoneuronal (CM) cells provide monosynaptic excitatory connections from motor cortex to spinal motoneurons and contribute causally to the time-varying electromyogram (EMG) of their target muscle. A multilayer perceptron (MLP) was used to evaluate the transfer function between neural activity of single CM cells and their target muscle EMG, using data from in-vivo recordings in primate motor cortex. For an optimal MLP performance, i.e., minimal error between recorded target EMG and MLP-derived EMG, the CM cell input period had to span the latency observed between CM cell peak activity and EMG peak activity. We argue that the same spike train may code two types of information: 1) rate coding within the input window accounted for large-amplitude variations in the EMG signal and 2) temporal coding within a window of 40 ms just prior to the EMG output signal accounted for EMG variations of small amplitude. The transfer function of the MLP, thus, combines rate and temporal coding and suggests that CM cell output may also combine these two forms of coding. We predict that mutual constraints of rate and temporal coding would, however, would limit the CM output to code for particular temporal profiles of EMG, possibly adapted to bio-mechanical constraints.	Univ Paris 06, INSERM, U483, F-75005 Paris, France	Manette, OFL (reprint author), Univ Paris 06, INSERM, U483, F-75005 Paris, France.	Marc.Maier@snv.jussieu.fr					Baker SN, 2001, J NEUROPHYSIOL, V85, P869; Baker SN, 1997, J PHYSIOL-LONDON, V501, P225, DOI 10.1111/j.1469-7793.1997.225bo.x; BIGGS N L, 1976, GRAPH THEORY; BREMNER FD, 1991, J PHYSIOL-LONDON, V432, P381; CARP JS, 1992, J NEUROPHYSIOL, V68, P1121; CHENEY PD, 1980, J NEUROPHYSIOL, V44, P773; DATTA AK, 1991, J PHYSIOL-LONDON, V432, P401; EVARTS EV, 1968, J NEUROPHYSIOL, V31, P14; FETZ EE, 1989, PROG BRAIN RES, V80, P437; Fetz EE, 1996, CAN J PHYSIOL PHARM, V74, P531, DOI 10.1139/cjpp-74-4-531; FETZ EE, 1980, J NEUROPHYSIOL, V44, P751; FU QG, 1995, J NEUROPHYSIOL, V73, P836; GEORGOPOULOS AP, 1982, J NEUROSCI, V2, P1527; Hastie T., 2001, ELEMENTS STAT LEARNI; HOFFER JA, 1987, J NEUROPHYSIOL, V57, P530; Jackson A, 2003, NEURON, V38, P115, DOI 10.1016/S0896-6273(03)00162-4; Kilner JM, 2000, J NEUROSCI, V20, P8838; Kohn AF, 2002, BIOSYSTEMS, V67, P113, DOI 10.1016/S0303-2647(02)00069-2; LEMON RN, 1986, J PHYSIOL-LONDON, V381, P497; MAIER MA, 1993, J NEUROPHYSIOL, V69, P772; Moran DW, 1999, J NEUROPHYSIOL, V82, P2676; MUIR RB, 1983, BRAIN RES, V261, P312, DOI 10.1016/0006-8993(83)90635-2; NAGAI T, 1992, NEUROREPORT, V3, P745, DOI 10.1097/00001756-199209000-00006; Porter R., 1993, CORTICOSPINAL FUNCTI; Powers RK, 2001, REV PHYSIOL BIOCH P, V143, P137, DOI 10.1007/BFb0115594; SINGER W, 1995, ANNU REV NEUROSCI, V18, P555, DOI 10.1146/annurev.ne.18.030195.003011; SMITH WS, 1989, NEUROSCI LETT, V96, P76, DOI 10.1016/0304-3940(89)90246-2	27	8	8	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1045-9227			IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	SEP	2004	15	5					1260	1267		10.1109/TNN.2004.833127		8	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	853AN	WOS:000223798400029	15484899	
J	Lee, JM; Lee, JH				Lee, JM; Lee, JH			Approximate dynamic programming strategies and their applicability for process control: A review and future directions	INTERNATIONAL JOURNAL OF CONTROL AUTOMATION AND SYSTEMS			English	Review						approximate dynamic programming; reinforcement learning; neuro-dynamic programming; optimal control; function approximation	MODEL-PREDICTIVE CONTROL; NEURAL NETWORKS; TD-GAMMON; OPTIMIZATION; CONVERGENCE; ROBOTS; AGENTS; SPACES; STATE; TIME	This paper reviews dynamic programming (DP), surveys approximate solution methods for it, and considers their applicability to process control problems. Reinforcement Learning (RL) and Neuro-Dynamic Programming (NDP), which can be viewed as approximate DP techniques, are already established techniques for solving difficult multi-stage decision problems in the fields of operations research, computer science, and robotics. Owing to the significant disparity of problem formulations and objective, however, the algorithms and techniques available from these fields are not directly applicable to process control problems, and reformulations based on accurate understanding of these techniques are needed. We categorize the currently available approximate solution techniques for dynamic programming and identify those most suitable for process control problems. Several open issues are also identified and discussed.	Georgia Inst Technol, Sch Chem & Biomol Engn, Atlanta, GA 30332 USA	Lee, JH (reprint author), Georgia Inst Technol, Sch Chem & Biomol Engn, Atlanta, GA 30332 USA.	Jongmin.Lee@chbe.gatech.edu; JayLee@chbe.gatech.edu	Lee, Jong Min/A-3198-2011; Lee, Jay Hyung/C-1808-2011	Lee, Jay Hyung/0000-0001-6134-6118			Ahamed TPI, 2002, ELECTR POW SYST RES, V63, P9, DOI 10.1016/S0378-7796(02)00088-3; Albus J. S., 1975, J DYNAMIC SYSTEMS ME, V97, P220; ALBUS JS, 1975, J DYNAMIC SYSTEMS ME, P228; Anderson C. W., 1989, IEEE Control Systems Magazine, V9, DOI 10.1109/37.24809; Anderson CW, 1997, ARTIF INTELL ENG, V11, P421, DOI 10.1016/S0954-1810(97)00004-6; Asada M, 1996, MACH LEARN, V23, P279, DOI 10.1007/BF00117447; ASTROM KJ, 1986, COMPUT MATH APPL-A, V12, P653; Atkeson C., 1997, P INT C ROB AUT; Atkeson C. G., 1997, P 14 INT C MACH LEAR, P12; Baird L. C., 1995, P 12 INT C MACH LEAR, P30; BARTO AG, 1995, ARTIF INTELL, V72, P81, DOI 10.1016/0004-3702(94)00011-O; BARTO AG, 1983, IEEE T SYST MAN CYB, V13, P834; Bellman Richard, 1957, DYNAMIC PROGRAMMING; Bertsekas D. P., 1992, DATA NETWORKS; Bertsekas D. P., 1996, NEURODYNAMIC PROGRAM; Bertsekas D. P., 2000, DYNAMIC PROGRAMMING; Bertsekas D.P., 1989, PARALLEL DISTRIBUTED; BERTSEKAS DP, 2001, P 6 INT C CHEM PROC; BERTSEKAS DP, 1989, IEEE T AUTOMAT CONTR, V34, P589, DOI 10.1109/9.24227; BORKAR VS, 1988, PROBAB THEORY REL, V78, P583, DOI 10.1007/BF00353877; BOYAN JA, 1995, ADV NEURAL INFORAMTI, V7; BRADTKE SJ, 1993, ADV NEURAL INFORMATI, V5; CRITES R, 1996, ADV NEURAL INFORMATI, V8; Crites RH, 1998, MACH LEARN, V33, P235, DOI 10.1023/A:1007518724497; DAYAN P, 1992, MACH LEARN, V8, P341, DOI 10.1007/BF00992701; De Farias DP, 2003, OPER RES, V51, P850, DOI 10.1287/opre.51.6.850.24925; Denardo E. V., 1970, MANAGE SCI, V16, P282, DOI 10.1287/mnsc.16.5.281; Gordon G. J., 1995, P 12 INT C MACH LEAR, P261; Hastie T., 2001, ELEMENTS STAT LEARNI; HORDIJK A, 1979, MANAGE SCI, V25, P352, DOI 10.1287/mnsc.25.4.352; HOSKINS JC, 1992, COMPUT CHEM ENG, V16, P241, DOI 10.1016/0098-1354(92)80045-B; Howard R. A., 1960, DYNAMIC PROGRAMMING; JAAKKOLA T, 1994, NEURAL COMPUT, V6, P1185, DOI 10.1162/neco.1994.6.6.1185; KAELBLING LP, 1996, H ARTIFICIAL INTELLI, V4, P237; KAISARE NS, 2002, INT J ROBUST NONLIN, V13, P347; KOENIG S, 1993, PROCEEDINGS OF THE ELEVENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P99; KONDA VR, 2000, ADV NEURAL INFORMATI, V12; KROSE BJA, 1992, P 1992 IEEE RSI C IN; Kumar P., 1986, STOCHASTIC SYSTEMS E; LEE JM, 2001, AICHE ANN M REN NV, pE276; LEE JM, 2004, UNPUB AUTOMATICA; LEE JM, 2003, AICHE ANN M SAN FRAN, pC438; Lee YH, 2002, COMPUT IND ENG, V43, P1, DOI 10.1016/S0360-8352(02)00059-1; LEONARD JA, 1992, COMPUT CHEM ENG, V16, P819, DOI 10.1016/0098-1354(92)80035-8; LIN LJ, 1992, MACH LEARN, V8, P293, DOI 10.1007/BF00992699; Mahadevan S., 1997, P 14 INT C MACH LEAR, P202; MAHADEVAN S, 1992, ARTIF INTELL, V55, P311, DOI 10.1016/0004-3702(92)90058-6; MANNE AS, 1960, MANAGE SCI, V6, P259, DOI 10.1287/mnsc.6.3.259; Marbach P, 2001, IEEE T AUTOMAT CONTR, V46, P191, DOI 10.1109/9.905687; Martinez EC, 2000, COMPUT CHEM ENG, V24, P1187, DOI 10.1016/S0098-1354(00)00354-9; MILLER S, 1995, APPL ARTIFICIAL NEUR; MOORE AW, 1991, THESIS CAMBRIDGE U; Moore AW, 1995, MACH LEARN, V21, P199, DOI 10.1007/BF00993591; MOORE AW, 1993, MACH LEARN, V13, P103, DOI 10.1023/A:1022635613229; Morari M, 1999, COMPUT CHEM ENG, V23, P667, DOI 10.1016/S0098-1354(98)00301-9; Munos R, 2000, MACH LEARN, V40, P265, DOI 10.1023/A:1007686309208; MUNOS R, 1997, P INT JOINT C ART IN; NEUNEIER R, 1997, ADV NEURAL INFORMATI, V10; Ormoneit D, 2002, MACH LEARN, V49, P161, DOI 10.1023/A:1017928328829; Ormoneit D, 2002, IEEE T AUTOMAT CONTR, V47, P1624, DOI 10.1109/TAC.2002.803530; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PENG J, 1993, THESIS NE U BOSTON; Peng J., 1993, ADAPT BEHAV, V1, P437; Prokhorov DV, 1997, IEEE T NEURAL NETWOR, V8, P997, DOI 10.1109/72.623201; Puterman M.L., 1994, MARKOV DECISION PROC; Qin SJ, 2003, CONTROL ENG PRACT, V11, P733, DOI 10.1016/S0967-0661(02)00186-7; Rude U., 1993, MATH COMPUTATIONAL T; RUMMERY GA, 1994, 166 CUED FINFENG TR; SABES P, 1993, P 4 CONN MOD SUMM SC; Samuel A.L., 1959, IBM Journal of Research and Development, V3; SAMUEL AL, 1967, IBM J RES DEV, V11, P601; Santamaria JC, 1997, ADAPT BEHAV, V6, P163, DOI 10.1177/105971239700600201; Schaal S, 1997, ADV NEUR IN, V9, P1040; SCHAAL S, 1994, IEEE CONTR SYST MAG, V14, P57, DOI 10.1109/37.257895; Schraudolph N. N., 1994, ADV NEURAL INFORMATI, P817; Singh SP, 1996, MACH LEARN, V22, P123; Singh S, 1997, ADV NEUR IN, V9, P974; Smart W. D., 2000, P 17 INT C MACH LEAR, P903; Sutton R. S., 1984, THESIS U MASSACHUSET; Sutton R. S., 1990, P 7 INT C MACH LEARN; Sutton R. S., 1988, Machine Learning, V3, DOI 10.1007/BF00115009; Sutton R. S., 1998, REINFORCEMENT LEARNI; Sutton RS, 1996, ADV NEUR IN, V8, P1038; Sutton RS, 2000, ADV NEUR IN, V12, P1057; SUTTON RS, 1981, PSYCHOL REV, V88, P135, DOI 10.1037/0033-295X.88.2.135; Takeda M, 2000, ADV ROBOTICS, V14, P439, DOI 10.1163/156855300741852; TESAURO G, 1992, MACH LEARN, V8, P257, DOI 10.1007/BF00992697; TESAURO G, 1994, NEURAL COMPUT, V6, P215, DOI 10.1162/neco.1994.6.2.215; TESAURO G, 1995, COMMUN ACM, V38, P58, DOI 10.1145/203330.203343; Thrun S., 1993, P 4 CONN MOD SUMM SC; THRUN S, 1995, ADV NEURAL INFORAMTI, V7; TSITSIKLIS JN, 1994, MACH LEARN, V16, P185, DOI 10.1023/A:1022689125041; Tsitsiklis JN, 1997, IEEE T AUTOMAT CONTR, V42, P674, DOI 10.1109/9.580874; Van Roy B, 2001, HDB MARKOV DECISION; Watkins C, 1989, THESIS U CAMBRIDGE E; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1023/A:1022676722315; Werbos P. J., 1992, HDB INTELLIGENT CONT; WERBOS PJ, 1977, GEN SYST, V22, P25; WHITEHEAD SD, 1991, P 8 INT WORKSH MACH; WILLIAMS RJ, 1993, NUCCS9314; Wilson JA, 1997, COMPUT CHEM ENG, V21, pS1233; WONHAM M, 1968, STOCHASTIC PROBLEMS; ZHANG W, 1996, ADV NEURAL INFORMATI, V8; Zhang W., 1995, P 14 INT JOINT C ART, P1114; ZHANG W, 1996, CS96301 OR STAT U	105	29	29	INST CONTROL AUTOMATION & SYSTEMS ENGINEERS	BUCHEON	BUCHEON TECHNO PARK 401-5906, 193 YAKDAE-DONG WONMI-GU, BUCHEON, GYEONGGI-DO 420-734, SOUTH KOREA	1598-6446			INT J CONTROL AUTOM	Int. J. Control Autom. Syst.	SEP	2004	2	3					263	278				16	Automation & Control Systems	Automation & Control Systems	885MV	WOS:000226162300001		
J	Focardi, SM; Kolm, PN; Fabozzi, FJ				Focardi, SM; Kolm, PN; Fabozzi, FJ			New kids on the block	JOURNAL OF PORTFOLIO MANAGEMENT			English	Article							STOCK RETURNS; VOLATILITY; MOMENTUM; PRICES; MODELS; RISK	The evolution of quantitative methods in finance is changing the investment management industry. With an altered focus in finance and investment theory, theoretical concepts such as market efficiency and market equilibrium have ceded ground to econometric methods that allow a more pragmatic investigation of asset predictability. Mean-variance optimization, one of the cornerstones of classic finance theory, presents some problems in practice, and recent developments in Bayesian modeling and robust optimization techniques circumvent some of its weaknesses. Beyond the classic framework, we must model the feedback mechanisms that we know to operate in financial markets, with caution as to model risk, data snooping, and overfitting biases.	Intertek Grp, Paris, France; Yale Univ, Sch Management, New Haven, CT USA	Focardi, SM (reprint author), Intertek Grp, Paris, France.	interteksf@aol.com; pkolm@nye.rr.com; fabozzi321@aol.com					AGUILAR O, 1998, BAYESIAN DYNAMIC FAC; Andersen TG, 2001, J FINANC ECON, V61, P43, DOI 10.1016/S0304-405X(01)00055-1; Antweiler W, 2004, J FINANC, V59, P1259, DOI 10.1111/j.1540-6261.2004.00662.x; Aoki M, 1998, NEW APPROACHES MACRO; Aoki M., 2004, MODELING AGGREGATE B; Athayde G, 2004, J ECON DYN CONTROL, V28, P1335; Ben-Tal A, 1998, MATH OPER RES, V23, P769, DOI 10.1287/moor.23.4.769; BENTAL A, 1999, OPERATIONS RES LETT; Black F., 1990, ASSET ALLOCATION COM; Black F., 1991, GLOBAL ASSET ALLOCAT; Campbell J. Y., 1996, ECONOMETRICS FINANCI; CARLIN BP, 1992, J AM STAT ASSOC, V87, P493, DOI 10.2307/2290282; CARTER CK, 1994, BIOMETRIKA, V81, P541; CERIA S, 2003, CHIC QUANT ALL C LAS; CHOPRA VK, 1993, J PORTFOLIO MANAGE, V19, P6, DOI 10.3905/jpm.1993.409440; Cutler DM, 1989, J PORTFOLIO MGMT SPR, P4; ENGLE RF, 1987, ECONOMETRICA, V55, P391, DOI 10.2307/1913242; FOCARDI S, 2002, LEVERAGING UNSTRUCTU; Focardi S. M., 2004, MATH FINANCIAL MODEL; FRENCH KR, 1987, J FINANC ECON, V19, P3, DOI 10.1016/0304-405X(87)90026-2; Fruehwirth-Schnatter S., 1994, J TIME SER ANAL, V15, P183; Ghaoui LE, 1997, SIAM J MATRIX ANAL A, V18, P1035; GLOSTEN L, 1993, J FINANC, V38, P1179; Goldfarb D, 2003, MATH OPER RES, V28, P1, DOI 10.1287/moor.28.1.1.14260; HARRISON M, 1979, J ECON THEORY, V30, P381; Hastie T., 2001, ELEMENTS STAT LEARNI; JEGADEESH N, 1993, J FINANC, V48, P65, DOI 10.2307/2328882; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Jobson J. D., 1981, J PORTFOLIO MANAGE, V7, P70, DOI 10.3905/jpm.1981.408816; JORION P, 1985, J BUS, V58, P259, DOI 10.1086/296296; Lewellen J, 2002, REV FINANC STUD, V15, P533, DOI 10.1093/rfs/15.2.533; LO AW, 1990, REV FINANC STUD, V3, P175, DOI 10.1093/rfs/3.2.175; LO AW, 1990, REV FINANC STUD, V3, P431, DOI 10.1093/rfs/3.3.431; Lo AW, 1988, REV FINANC STUD, V1, P41, DOI 10.1093/rfs/1.1.41; MANDELBROT B, 1963, J BUS, V36, P394, DOI 10.1086/294632; Mantegna R.N., 1999, INTRO ECONOPHYSICS C; Markowitz H, 1952, J FINANC, V7, P77, DOI 10.2307/2975974; Markowitz H., 1987, MEAN VARIANCE ANAL P; Muller P, 2003, PORTFOLIO SELECTION; Rachev S. T., 2000, STABLE PARETIAN MODE; Rachev Svetlozar T., 2001, HDB HEAVY TAILED DIS; Rouwenhorst KG, 1998, J FINANC, V53, P267, DOI 10.1111/0022-1082.95722; SAMUELSON PA, 1965, IMR-IND MANAG REV, V6, P41; SORENSEN E, 1998, ACTIVE EQUITY PORTFO, pCH12; West M., 1989, BAYESIAN FORECASTING; White H, 2000, ECONOMETRICA, V68, P1097, DOI 10.1111/1468-0262.00152; Wysocki P. D., 1999, CHEAP TALK WEB DETER	47	1	1	INSTITUTIONAL INVESTOR INC	NEW YORK	225 PARK AVENUE SOUTH, NEW YORK, NY 10003 USA	0095-4918			J PORTFOLIO MANAGE	J. Portf. Manage.	SEP	2004					SI		42	+				14	Business, Finance	Business & Economics	867IL	WOS:000224836200005		
J	Ishwaran, H; Blackstone, EH; Pothier, CE; Lauer, MS				Ishwaran, H; Blackstone, EH; Pothier, CE; Lauer, MS			Relative risk forests for exercise heart rate recovery as a predictor of mortality	JOURNAL OF THE AMERICAN STATISTICAL ASSOCIATION			English	Article						cox regression; MARS; proportional hazards; random forests; relative risk trees; stochastic variable selection.	PRACTICE GUIDELINES COMMITTEE; ADAPTIVE REGRESSION SPLINES; ASSOCIATION TASK-FORCE; ALL-CAUSE MORTALITY; BAROREFLEX SENSITIVITY; TREADMILL EXERCISE; AMERICAN-COLLEGE; RATE-VARIABILITY; MODEL SELECTION; INFARCTION	Recent studies have confirmed heart rate fall after treadmill exercise testing, or heart rate recovery, as a powerful predictor of mortality from heart disease. Heart rate recovery depends on central reactivation of vagal tone and decreased vagal activity is a risk factor for death. If heart rate recovery is defined as the fall in heart rate after I minute following peak exercise, then a heart rate recovery value of 12 beats per minute (bpm) or lower has been shown to be a good prognostic threshold for identifying patients at high risk. Although this finding establishes a simple, useful relationship between heart recovery and mortality, a working understanding of how heart rate recovery interacts with other characteristics of a patient in determining risk of death is still largely unexplored. Such knowledge, addressed in this article, could improve the prognostic value of the exercise test. Our analysis is based on over 23,000 patients who underwent exercise testing. A rich assortment of data was collected on these patients, including clinical and physiological information, heart rate recovery, and other exercise test performance measures. Our approach was to grow relative risk forests, a novel method that combines random forest methodology with survival trees grown using Poisson likelihoods. Our analysis reveals a complex relationship between peak heart rate, age, level of fitness, heart rate recovery, and risk of death.	Cleveland Clin Fdn, Dept Biostat & Epidemiol, Cleveland, OH 44195 USA; Cleveland Clin Fdn, Dept Thorac & Cardiac Surg, Cleveland, OH 44195 USA; Cleveland Clin Fdn, Dept Cardiovasc Med, Cleveland, OH 44195 USA	Ishwaran, H (reprint author), Cleveland Clin Fdn, Dept Biostat & Epidemiol, 9500 Euclid Ave, Cleveland, OH 44195 USA.	ishwaran@bio.ri.ccf.org	Lauer, Michael/L-9656-2013	Lauer, Michael/0000-0002-9217-8177			AALEN O, 1978, ANN STAT, V6, P701, DOI 10.1214/aos/1176344247; Aitkin M., 1980, Applied Statistics, V29, DOI 10.2307/2986301; Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Arai Y, 1989, AM J PHYSIOL, V256, P132; Breiman L, 1996, ANN STAT, V24, P2350; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breslow N.E., 1972, J R STAT SOC B, V34, P216; CLAYTON D, 1985, APPL STAT-J ROY ST C, V34, P148, DOI 10.2307/2347367; Cole CR, 2000, ANN INTERN MED, V132, P552; Cole CR, 1999, NEW ENGL J MED, V341, P1351, DOI 10.1056/NEJM199910283411804; COX DR, 1972, J R STAT SOC B, V34, P187; Diaz LA, 2001, J AM COLL CARDIOL, V37, P1558, DOI 10.1016/S0735-1097(01)01205-0; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Gibbons RJ, 2002, J AM COLL CARDIOL, V40, P1531, DOI 10.1016/S0735-1097(02)02164-2; Gibbons RJ, 2002, CIRCULATION, V106, P1883, DOI 10.1161/01.CIR.0000034670.06526.15; Gibbons RJ, 1997, J AM COLL CARDIOL, V30, P260; HAMMOND HK, 1985, PROG CARDIOVASC DIS, V27, P271, DOI 10.1016/0033-0620(85)90010-6; Hastie T., 2001, ELEMENTS STAT LEARNI; IMAI K, 1994, J AM COLL CARDIOL, V24, P1529; ISHWARAN H, 2000, UNPUB BAYESIAN NONPA; Ishwaran H, 2003, J AM STAT ASSOC, V98, P438, DOI 10.1198/016214503000224; KOOPERBERG C, 1995, J AM STAT ASSOC, V90, P78, DOI 10.2307/2291132; La Rovere MT, 1998, LANCET, V351, P478; La Rovere MT, 2001, CIRCULATION, V103, P2072; Lauer MS, 1996, CIRCULATION, V93, P1520; Lauer MS, 1999, JAMA-J AM MED ASSOC, V281, P524, DOI 10.1001/jama.281.6.524; Lauer Michael S., 2001, Cardiology Clinics, V19, P401, DOI 10.1016/S0733-8651(05)70225-3; Lauer MS, 2002, CIRCULATION, V106, P685, DOI 10.1161/01.CIR.0000024410.15081.FD; LeBlanc M, 1999, BIOMETRICS, V55, P204, DOI 10.1111/j.0006-341X.1999.00204.x; LEBLANC M, 1992, BIOMETRICS, V48, P411, DOI 10.2307/2532300; Nishime EO, 2000, JAMA-J AM MED ASSOC, V284, P1392, DOI 10.1001/jama.284.11.1392; SCHWARTZ PJ, 1992, CIRCULATION, V85, P77; Shetler K, 2001, J AM COLL CARDIOL, V38, P1980, DOI 10.1016/S0735-1097(01)01652-7; Snader CE, 1997, J AM COLL CARDIOL, V30, P641, DOI 10.1016/S0735-1097(97)00217-9; Therneau T, 1997, TECHNICAL REPORT SER, V61; Watanabe J, 2001, CIRCULATION, V104, P1911; Williams SV, 2001, ANN INTERN MED, V135, P530	38	11	12	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	0162-1459			J AM STAT ASSOC	J. Am. Stat. Assoc.	SEP	2004	99	467					591	600		10.1198/016214504000000638		10	Statistics & Probability	Mathematics	853VR	WOS:000223857500006		
J	Sano, N; Suzuki, H; Koda, M				Sano, N; Suzuki, H; Koda, M			A robust boosting method for mislabeled data	JOURNAL OF THE OPERATIONS RESEARCH SOCIETY OF JAPAN			English	Article						data analysis; data mining; machine learning; boosting; AdaBoost; sigmoidal function	LEARNING ALGORITHM; MARGINS	We propose a new, robust boosting method by using a sigmoidal function as a loss function. In deriving the method, the stagewise additive modelling methodology is blended with the gradient descent algorithms. Based on intensive numerical experiments, we show that the proposed method is actually better than AdaBoost and other regularized method in test error rates in the case of noisy, mislabeled situation.	Univ Tsukuba, Grad Sch Syst & Informat Engn, Tsukuba, Ibaraki 3058573, Japan	Koda, M (reprint author), Univ Tsukuba, Grad Sch Syst & Informat Engn, 1-1-1 Tennondai, Tsukuba, Ibaraki 3058573, Japan.	koda@sk.tsukuba.ac.jp					BREIMAN L, 1998, COMBINING PREDICTORS; Duda R.O., 2001, PATTERN CLASSIFICATI; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Grove A. J., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Hastie T., 2001, ELEMENTS STAT LEARNI; Koda M, 2000, J OPER RES SOC JPN, V43, P469; Mason L, 2000, MACH LEARN, V38, P243, DOI 10.1023/A:1007697429651; Press W.H., 1992, NUMERICAL RECIPES C; QUINLAN J, 1996, P 7 INT WORKSH ALG L, V1160, P143; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760	14	3	3	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0453-4514			J OPER RES SOC JPN	J. Oper. Res. Soc. Jpn.	SEP	2004	47	3					182	196				15	Operations Research & Management Science	Operations Research & Management Science	870HY	WOS:000225049400004		
J	Garczarek, U; Weihs, C				Garczarek, U; Weihs, C			Incorporating background knowledge for better prediction of cycle phases	KNOWLEDGE AND INFORMATION SYSTEMS			English	Article						background knowledge; classification; time		When predicting the state of a system, we sometimes know that the succession of states is cyclic. This is for example true for the prediction of business cycle phases, where an upswing is always followed by upper turning points, and the subsequent downswing passes via lower turning points over to the next upswing and so on. We present several ideas of how to implement this background knowledge in popular static classification methods. Additionally, we present a full dynamic model. The usefulness for the prediction of business cycles is investigated, revealing pitfalls and potential benefits of ideas.	Univ Dortmund, Dept Stat, D-44221 Dortmund, Germany	Weihs, C (reprint author), Univ Dortmund, Dept Stat, Vogelpothsweg 87, D-44221 Dortmund, Germany.	weihs@statistik.unidortmund.de; garczarek@statistik.unidortmund.de					AALEN OO, 1991, STAT MED, V10, P1227, DOI 10.1002/sim.4780100806; BELSEY EM, 1991, STAT MED, V10, P267, DOI 10.1002/sim.4780100210; Bengio Y, 1999, NEURAL COMPUTING SUR, V2, P129; Diebold FX, 1996, REV ECON STAT, V78, P67, DOI 10.2307/2109848; Friedman J., 1996, ANOTHER APPROACH POL; FUKUNAGA K, 1990, INTRO STAT PATTERN; GARCZAREK UM, 2002, CLASSIFICATION RULES; Gelman A, 1995, BAYESIAN DATA ANAL; Guimaraes G, 2001, ARTIF INTELL MED, V23, P211, DOI 10.1016/S0933-3657(01)00089-6; HAMILTON JD, 1989, ECONOMETRICA, V57, P357, DOI 10.2307/1912559; Hampshire II J.B., 1990, P 1990 CONN MOD SUMM; Hastie T., 2001, ELEMENTS STAT LEARNI; HEILEMANN U, 1996, CIRET C SINGAPORE CI; HOLM S, 1979, SCAND J STAT, V6, P65; Ihaka R, 2005, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; KOSKINEN L, 1998, HIDDEN MARKOV MODEL, P59; Lucas Jr Robert E., 1987, MODELS BUSINESS CYCL; McLachlan G., 1992, DISCRIMINANT ANAL ST; MEYER JR, 1975, EXPLORATIONS EC RES, V2, P167; Platt JC, 2000, ADV NEUR IN, V12, P547; Platt John C., 1999, PROBABILISTIC OUTPUT; Rabiner L. R., 1993, FUNDAMENTALS SPEECH; Scholkopf B, 1995, P 1 INT C KNOWL DISC, P252; SCHWAIGHOFER A, 2002, SYM TOOLBOX MATLAB; Siegel S., 1988, NONPARAMETRIC STAT B; SONDHAUSS UM, 2001, 475 SFB U DORTM; SONDHAUSS UM, 1999, 475 SFB U DORTM; Vapnik VN, 1995, NATURE STAT LEARNING; WEIHS C, 1999, 475 SFB U DORTM	29	0	0	SPRINGER LONDON LTD	GODALMING	SWEETAPPLE HOUSE CATTESHALL ROAD, GODALMING GU7 3DJ, SURREY, ENGLAND	0219-1377			KNOWL INF SYST	Knowl. Inf. Syst.	SEP	2004	6	5					544	569		10.1007/s10115-003-0129-2		26	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	885LX	WOS:000226159300003		
J	Gomez-Perez, A; Manzano-Macho, D				Gomez-Perez, A; Manzano-Macho, D			An overview of methods and tools for ontology learning from texts	KNOWLEDGE ENGINEERING REVIEW			English	Review							SEMANTIC WEB; CLASSIFICATION	Ontology learning aims at reducing the time and efforts in the ontology development process. In recent years, several methods and tools have been proposed to speed up this process using different sources of information and different techniques. In this paper, we have reviewed 13 methods and 14 tools for semi-automatically building ontologies from texts and their relationships with the techniques each method follows. The methods have been grouped according to the main techniques followed and three groups have been identified: one based on linguistics, one on statistics, and one on machine learning. Regarding the tools, the criterion for grouping them, which has been the main aim of the tool, is to distinguish what elements of the ontology can be learned with each tool. According to this, we have identified three kinds of tools: tools for learning relations, tools for learning new concepts, and assisting tools for building up taxonomies.				Lavbic, Dejan/G-1405-2010; Gomez-Perez, Asuncion/I-9382-2012	Gomez-Perez, Asuncion/0000-0002-3037-0331			Adriaans P., 1996, DATA MINING; AGIRRE E, 2000, WORKSH ONT LEARN EUR, P25; Agrawal R., 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; AGUADODECEA G, 2002, SEMANTIC WEB MEETS L, P20; ALFONSECA E, 2002, P 1 INT C GEN WORDN; ALFONSECA E, 2002, P 3 INT C LANG RES E, P235; Alfonseca E, 2002, LECT NOTES ARTIF INT, V2473, P1; AUSSENACGILLES N, 2000, PRESSE UTM, V25, P175; Aussenac-Gilles N, 2000, LECT NOTES ARTIF INT, V1937, P172; AUSSENACGILLES N, 2003, RENCONTRES TERMINOLO, P41; AUSSENACGILLES N, 2000, EUR KNOWL ACQ WORKSH; AUSSENAC-GILLES Nathalie, 1999, TERMINOLOGIES NOUVEL, V19, P111; Berners-Lee T., 1999, WEAVING WEB ORIGINAL; Biebow B, 1999, P 11 EUR WORKSH KNOW, P49; BISSON G, 2000, WORKSH ONT LEARN EUR, P13; BISSON G, 1992, P 10 EUR C ART INT V, P458; BISSON G, 1992, P 10 AM ASS ART INT; Bourigault D., 1996, P 7 EURALEX INT C GO; CHAELANDER G, 2000, WORKSH ONT LEARN EUR, P19; ENERY TMC, 2001, CORPUS LINGUISTICS I; FAATZ A, 2002, P 2 WORKSH SEM WEB M, P20; FAURE D, 1998, ADAPTING LEXICAL COR, P1; Faure D., 1999, P 11 EUR WORKSH KNOW, P329; FAURE D, 2000, WORKSH ONT LEARN EUR, P7; Fayyad U.M., 1996, ADV KNOWLEDGE DISCOV, P1; GUPTA KM, 2002, P 1 INT C GLOB WORDN, P207; Hahn U., 2001, Proceedings of the First International Conference on Knowledge Capture; Hahn U., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Hahn U, 2000, LECT NOTES ARTIF INT, V1822, P176; HAMP B, 1997, P AUT INF EXTR BUILD; Harabagiu SM, 2000, NATURAL LANGUAGE PROCESSING AND KNOWLEDGE REPRESENTATION, P301; Hastie T., 2001, ELEMENTS STAT LEARNI; Hearst M. A., 1992, P 14 C COMP LING, V2, P539, DOI 10.3115/992133.992154; Hearst Marti A., 1998, WORDNET ELECT LEXICA, P132; HOVY EH, 1999, ADV AUTOMATIC TEXT S, P18; HSU WL, 2001, NAT LANG PROC KNOWL; HWANG CH, 1999, P 6 INT WORKSH KNOWL, P14; Joachims T., 1997, P 14 INT C MACH LEAR, P143; Khan LF, 2002, PROC INT C TOOLS ART, P122, DOI 10.1109/TAI.2002.1180796; KIETZ JU, 2000, EUR KNOWL ACQ WORKSH; Lin YHE, 2000, J MICROENCAPSUL, V17, P1; Liu WZ, 1996, KNOWL ENG REV, V11, P245; Maedche A, 2001, IEEE INTELL SYST APP, V16, P72, DOI 10.1109/5254.920602; MAEDCHE A, 2001, P INT DAT MIN KNOWL; Maedche A., 2004, HDB ONTOLOGIES, P173; Maedche A., 2000, P 14 EUR C ART INT, P321; MARTIENNE E, 1998, P 13 EUR C ART INT E, P351; Mikheev A., 1997, P 5 C APPL NAT LANG, P372, DOI DOI 10.3115/974557.974611; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; Missikoff M, 2002, LECT NOTES COMPUT SC, V2342, P39; Mitchell T., 1997, MACHINE LEARNING; Modica G.A., 2001, LECT NOTES COMPUTER, V2172, P433; Moldovan D, 2000, P 13 INT FLOR ART IN, P224; Moldovan D. I., 2001, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V10, DOI 10.1142/S0218213001000428; MOLDOVAN EI, 2000, P APPL NAT LANG PROC, P268; MORI S, 1993, CONF PR LECT NOT ALG, V1, P1; Morin E., 1999, P 5 INT C TERM KNOWL, P268; MORIN E, 1998, 5 NAT C TRAIT AUT LA, P172; NAVIGLI R, 2003, IEEE INTELLIGENT SYS, V18; OLIVEIRA A, 2001, P ISAI 2001 KOLH IND; PEREIRA F., 2000, P ARG S ART INT ASAI; PEREIRA FC, 1998, 13 EUR C ART INT ECA, P131; RIGAU G, 1998, P 17 INT C COMP LING, V2, P1289; ROUX C, 2000, WORKSH ONT LEARN EUR, P49; SALTON G, 1991, SCIENCE, V253, P974, DOI 10.1126/science.253.5023.974; SEGUELA P, 1999, ACTES TIA 99 TERM IN, P52; SOWA JF, 1984, INFORMATION PROCESSI; Srikant R., 1995, P 21 INT C VER LARG, P407; Studer R, 1998, DATA KNOWL ENG, V25, P161, DOI 10.1016/S0169-023X(97)00056-6; Sure Y, 2002, LECT NOTES COMPUT SC, V2342, P221; SZULMAN S, 2002, NUMERO SPECIAL STRUC, V43, P103; THOMPSON CA, 1997, SEMANTIC LEXICON ACQ; Velardi P., 2001, P INT C FORM ONT INF, P270; VELARDI P, 2002, IEEE COMPUT, V35, P60; WEBB GI, 2002, EXPERT SYST, V3, P937, DOI 10.1016/B978-012443880-4/50070-3; WU SH, 2002, P 19 INT C COMP LING, P289; Xu F., 2002, P 3 INT C LANG RES E; YAMAGUCHI T, 1999, P WORKSH ONT PROBL S; ZELLE JM, 1995, 96249 AI ART INT LAB	79	13	13	CAMBRIDGE UNIV PRESS	NEW YORK	40 WEST 20TH ST, NEW YORK, NY 10011-4211 USA	0269-8889			KNOWL ENG REV	Knowl. Eng. Rev.	SEP	2004	19	3					187	212		10.1017/s0269888905000251		26	Computer Science, Artificial Intelligence	Computer Science	943QP	WOS:000230369400001		
J	Heim, S; Hahn, K; Samann, PG; Fahrmeir, L; Auer, DP				Heim, S; Hahn, K; Samann, PG; Fahrmeir, L; Auer, DP			Assessing DTI data quality using bootstrap analysis	MAGNETIC RESONANCE IN MEDICINE			English	Article						bootstrap; DTI quality; anisotropy; reliability; motion; noise	DIFFUSION-TENSOR MRI; WHITE-MATTER; ACQUISITION SCHEMES; PYRAMIDAL TRACT; FIBER TRACKING; IN-VIVO; NOISE; ANISOTROPY; MICROSTRUCTURE; MODELS	Diffusion tensor imaging (DTI) is an established method for characterizing and quantifying ultrastructural brain tissue properties. However, DTI-derived variables are affected by various sources of signal uncertainty. The goal of this study was to establish an objective quality measure for DTI based on the non-parametric bootstrap methodology. The confidence intervals (CIs) of white matter (WM) fractional anisotropy (FA) and C-linear were determined by bootstrap analysis and submitted to histogram analysis. The effects of artificial noising and edge-preserving smoothing, as well as enhanced and reduced motion were studied in healthy volunteers. Gender and age effects on data quality as potential confounds in group comparison studies were analyzed. Additional noising showed a detrimental effect on the mean, peak position, and height of the respective CIs at 10% of the original background noise. Inverse changes reflected data improvement induced by edge-preserving smoothing. Motion-dependent impairment was also well depicted by bootstrap-derived parameters. Moreover, there was a significant gender effect, with females displaying less dispersion (attributable to elevated SNR). In conclusion, the bootstrap procedure is a useful tool for assessing DTI data quality. It is sensitive to both noise and motion effects, and may help to exclude confounding effects in group comparisons. (C) 2004 Wiley-Liss, Inc.	Max Planck Inst Psychiat, Res Grp NMR, D-80804 Munich, Germany; Natl Res Ctr Environm & Hlth, GSF, Inst Biomath & Biometry, Neuherberg, Germany; Univ Munich, Dept Stat, Munich, Germany	Heim, S (reprint author), Kraepelinstr 10, D-80804 Munich, Germany.	sheim@mpipsykl.mpg.de					Abe O, 2002, NEUROBIOL AGING, V23, P433, DOI 10.1016/S0197-4580(01)00318-9; Anderson AW, 2001, MAGNET RESON MED, V46, P1174, DOI 10.1002/mrm.1315; Andersson JLR, 2002, NEUROIMAGE, V16, P177, DOI 10.1006/nimg.2001.1039; Basser PJ, 1996, J MAGN RESON SER B, V111, P209, DOI 10.1006/jmrb.1996.0086; Basser PJ, 2002, NMR BIOMED, V15, P456, DOI 10.1002/nbm.783; Basser PJ, 2000, MAGNET RESON MED, V44, P625, DOI 10.1002/1522-2594(200010)44:4<625::AID-MRM17>3.0.CO;2-O; Bastin ME, 1998, MAGN RESON IMAGING, V16, P773, DOI 10.1016/S0730-725X(98)00098-8; Cercignani M, 2001, J NEUROL NEUROSUR PS, V70, P311, DOI 10.1136/jnnp.70.3.311; Chabriat H, 1999, STROKE, V30, P2637; Dietrich O, 2001, MAGNET RESON MED, V45, P448, DOI 10.1002/1522-2594(200103)45:3<448::AID-MRM1059>3.0.CO;2-W; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Efron B., 1994, INTRO BOOTSTRAP; Frank LR, 2002, MAGNET RESON MED, V47, P1083, DOI 10.1002/mrm.10156; FREEDMAN DA, 1981, ANN STAT, V9, P1218, DOI 10.1214/aos/1176345638; Gossl C, 2002, NEUROIMAGE, V16, P378, DOI 10.1006/nimg.2002.1055; GUDBJARTSSON H, 1995, MAGNET RESON MED, V34, P910, DOI 10.1002/mrm.1910340618; HAHN K, 2001, P 4 INT C MED IM COM, P195; HASTIE T, 2001, ELEMENTS STAT LEARNI, P235; Jones DK, 2003, MAGNET RESON MED, V49, P7, DOI 10.1002/mrm.10331; Lori NF, 2002, NMR BIOMED, V15, P493, DOI 10.1002/nbm.779; O'Sullivan M, 2001, NEUROLOGY, V57, P632; Pajevic S, 2003, J MAGN RESON, V161, P1, DOI 10.1016/S1090-7807(02)00178-7; Papadakis NG, 2003, J MAGN RESON, V164, P1, DOI 10.1016/S1090-7807(03)00202-7; Papadakis NG, 1999, J MAGN RESON, V137, P67, DOI 10.1006/jmre.1998.1673; Parker GJM, 2000, J MAGN RESON IMAGING, V11, P702, DOI 10.1002/1522-2586(200006)11:6<702::AID-JMRI18>3.0.CO;2-A; Pierpaoli C, 1996, MAGNET RESON MED, V36, P893, DOI 10.1002/mrm.1910360612; Skare S, 2000, MAGN RESON IMAGING, V18, P659, DOI 10.1016/S0730-725X(00)00153-3; Skare S, 2000, J MAGN RESON, V147, P340, DOI 10.1006/jmre.2000.2209; Sullivan EV, 2001, NEUROREPORT, V12, P99, DOI 10.1097/00001756-200101220-00027; Virta A, 1999, MAGN RESON IMAGING, V17, P1121, DOI 10.1016/S0730-725X(99)00048-X; Westerhausen R, 2003, NEUROSCI LETT, V351, P99, DOI 10.1016/S0304-3940(03)00946-7; Westin CF, 2002, MED IMAGE ANAL, V6, P93, DOI 10.1016/S1361-8415(02)00053-1; Winkler G, 1999, J PATTERN RECOGNITIO, V9, P749	33	24	24	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0740-3194			MAGN RESON MED	Magn. Reson. Med.	SEP	2004	52	3					582	589		10.1002/mrm.20169		8	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	849HL	WOS:000223529200019	15334578	
J	Hibbard, LS				Hibbard, LS			Region segmentation using information divergence measures	MEDICAL IMAGE ANALYSIS			English	Article; Proceedings Paper	6th International Conference on Medical Image Computing and Computer-Assisted Intervention	NOV 15-18, 2003	MONTREAL, CANADA	Robarts Res Inst, No Digital Inc		image segmentation; likelihood ratio test; Kullback-Leibler divergence; Renyi entropy; Jensen-Renyi divergence	NONNEGATIVITY CONSTRAINTS; DEBLURRING SUBJECT	Image segmentations based on maximum likelihood or maximum a posteriori analyses of object textures usually assume parametric models (e.g., Gaussian) for distributions of these features. For real images, parameter accuracy and model stationarity may be elusive, so that model-free inference methods ought to have an advantage over those that are model-dependent. Functions of the relative entropy (RE) from information theory can produce minimum error, model-free inferences, and can detect the boundary of an image object by maximizing the RE between the pixel distributions inside and outside a flexible curve contour. A generalization of the RE - the Jensen-Renyi divergence (JRD) - computes optimal n-way decisions and can contour multiple objects in an image simultaneously. Seed regions expand naturally and multiple contours tend not to overlap. An edge detector based on the JRD, combined with multivariate pixel segmentation, generally improved the error of the segmentation. We apply these functions to contour patient anatomy in X-ray computed tomography for radiotherapy treatment planning. (C) 2004 Elsevier B.V. All rights reserved.	Res CMS Inc, St Louis, MO 63132 USA	Hibbard, LS (reprint author), Res CMS Inc, 1145 Corp Lake Dr, St Louis, MO 63132 USA.	lyn@cmsrtp.com					Amit Y., 2002, 2 D OBJECT DETECTION; Chakraborty A, 1996, IEEE T MED IMAGING, V15, P859, DOI 10.1109/42.544503; Collignon A, 1995, LECT NOTES COMPUTER, V905, P195; Cover T. M., 1991, ELEMENTS INFORMATION; Devroye L., 1996, PROBABILISTIC THEORY; Duda R.O., 2001, PATTERN CLASSIFICATI; Fukunaga K, 1990, INTRO STAT PATTERN R; Garcia JA, 2001, IEEE T PATTERN ANAL, V23, P362, DOI 10.1109/34.917572; GIARDIAN CR, 1977, COMPUTER GRAPHICS IM, V21, P277; Gokcay E, 2002, IEEE T PATTERN ANAL, V24, P158, DOI 10.1109/34.982897; Gomez-Lopera JF, 2000, J MATH IMAGING VIS, V13, P35, DOI 10.1023/A:1008325607354; GRENANDER U, 1981, ABSTR INFERENCE; Grimmett G., 1992, PROBABILITY RANDOM P; Hastie T., 2001, ELEMENTS STAT LEARNI; He Y, 2003, IEEE T SIGNAL PROCES, V51, P1211, DOI 10.1109/TSP.2003.810305; HE Y, 2001, P IEEE WORKSH STAT S; KAPUR J, 1994, MEASURES INFORMATION; KUHL FP, 1982, COMPUT VISION GRAPH, V18, P236, DOI 10.1016/0146-664X(82)90034-X; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; KULLBACK S, 1959, INFORMATION THEORY S; LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115; Meas F, 1997, IEEE T MED IMAGING, V16, P187; NELDER JA, 1965, COMPUT J, V7, P308; Nocedal J., 1999, NUMERICAL OPTIMIZATI; O'Sullivan JA, 1998, IEEE T INFORM THEORY, V44, P2094, DOI 10.1109/18.720533; Press WH, 2002, NUMERICAL RECIPES C; PRINCIPE JC, 1999, UNSUPERVISED ADAPTIV, P265; Renyi A, 1961, 4TH P BERK S MATH ST, V1, P547; SHANNON CE, 1948, AT&T TECH J, V27, P379; SNYDER DL, 1992, IEEE T SIGNAL PROCES, V40, P1143, DOI 10.1109/78.134477; Snyder DL, 2001, IEEE T MED IMAGING, V20, P1009, DOI 10.1109/42.959298; Studholme C, 1996, Med Image Anal, V1, P163, DOI 10.1016/S1361-8415(96)80011-9; VIOLA PA, 1995, P 5 INT C COMP VIS C; WELLS W, 1996, MED IMAGE ANAL, V1, P33	34	12	12	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1361-8415			MED IMAGE ANAL	Med. Image Anal.	SEP	2004	8	3					233	244		10.1016/j.media.2004.06.003		12	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging	Computer Science; Engineering; Radiology, Nuclear Medicine & Medical Imaging	857AS	WOS:000224088300008	15450218	
J	Gutierrez, JM; Cofino, AS; Cano, R; Rodriguez, MA				Gutierrez, JM; Cofino, AS; Cano, R; Rodriguez, MA			Clustering methods for statistical downscaling in short-range weather forecasts	MONTHLY WEATHER REVIEW			English	Article							KALMAN FILTER ESTIMATION; DAILY STREAM FLOWS; CIRCULATION PATTERNS; MODEL OUTPUT; PRECIPITATION; PREDICTION; REGRESSION; ALGORITHM	In this paper an application of clustering algorithms for statistical downscaling in short-range weather forecasts is presented. The advantages of this technique compared with standard nearest-neighbors analog methods are described both in terms of computational efficiency and forecast skill. Some validation results of daily precipitation and maximum wind speed operative downscaling (lead time 1-5 days) on a network of 100 stations in the Iberian Peninsula are reported for the period 1998-99. These results indicate that the weighting clustering method introduced in this paper clearly outperforms standard analog techniques for infrequent, or extreme, events (precipitation > 20 mm; wind > 80 km h(-1)). Outputs of an operative circulation model on different local-area or large-scale grids are considered to characterize the atmospheric circulation patterns, and the skill of both alternatives is compared.	Univ Cantabria, ETSI CAminos, Dept Matemat Aplicada, E-39005 Santander, Spain; CMT CAS, Inst Nacl Meteorol, Santander, Spain; CSIC, Inst Fis Cantabria, Santander, Spain	Gutierrez, JM (reprint author), Univ Cantabria, ETSI CAminos, Dept Matemat Aplicada, E-39005 Santander, Spain.	gutierjm@unican.es	Cofino, Antonio/G-6247-2010; Gutierrez, Jose/C-5754-2009; Rodriguez, Miguel A./J-9697-2014	Rodriguez, Miguel A./0000-0003-4184-0463			BARNETT TP, 1987, MON WEATHER REV, V115, P1825, DOI 10.1175/1520-0493(1987)115<1825:OALOMA>2.0.CO;2; BERGMAN MJ, 1985, WATER RESOUR BULL, V21, P815; BERGMAN MJ, 1985, WATER RESOUR BULL, V21, P827; Billet J, 1997, WEATHER FORECAST, V12, P154, DOI 10.1175/1520-0434(1997)012<0154:UORTTP>2.0.CO;2; Cavazos T, 1997, INT J CLIMATOL, V17, P1069, DOI 10.1002/(SICI)1097-0088(199708)17:10<1069::AID-JOC183>3.0.CO;2-I; Duda R. O., 2000, PATTERN CLASSIFICATI; Enke W, 1997, CLIMATE RES, V8, P195, DOI 10.3354/cr008195; Gardner MW, 1998, ATMOS ENVIRON, V32, P2627, DOI 10.1016/S1352-2310(97)00447-0; Hastie T., 2001, ELEMENTS STAT LEARNI; HUGHES JP, 1993, WATER RESOUR RES, V29, P3303, DOI 10.1029/93WR01066; KATZ RW, 1997, EC VALUE WEATHER CLI; KLEIN WH, 1974, B AM METEOROL SOC, V55, P1217, DOI 10.1175/1520-0477(1974)055<1217:FLWBMO>2.0.CO;2; LORENZ EN, 1969, J ATMOS SCI, V26, P636, DOI 10.1175/1520-0469(1969)26<636:APARBN>2.0.CO;2; McGinnis D. L., 1994, NEURAL NETS APPL GEO, P79; Pena JM, 1999, PATTERN RECOGN LETT, V20, P1027, DOI 10.1016/S0167-8655(99)00069-0; Preisendorfer R.W., 1988, PRINCIPAL COMPONENT; TOTH Z, 1991, MON WEATHER REV, V119, P1501, DOI 10.1175/1520-0493(1991)119<1501:CPIPSA>2.0.CO;2; VANDENDOOL HM, 1989, MON WEATHER REV, V117, P2230, DOI 10.1175/1520-0493(1989)117<2230:ANLAWF>2.0.CO;2; von Storch H, 1999, J CLIMATE, V12, P3505, DOI 10.1175/1520-0442(1999)012<3505:OTUOII>2.0.CO;2; Wilby RL, 1997, PROG PHYS GEOG, V21, P530, DOI 10.1177/030913339702100403; ZORITA E, 1995, J CLIMATE, V8, P1023, DOI 10.1175/1520-0442(1995)008<1023:SCORCP>2.0.CO;2; Zorita E, 1999, J CLIMATE, V12, P2474, DOI 10.1175/1520-0442(1999)012<2474:TAMAAS>2.0.CO;2	22	35	35	AMER METEOROLOGICAL SOC	BOSTON	45 BEACON ST, BOSTON, MA 02108-3693 USA	0027-0644			MON WEATHER REV	Mon. Weather Rev.	SEP	2004	132	9					2169	2183		10.1175/1520-0493(2004)132<2169:CMFSDI>2.0.CO;2		15	Meteorology & Atmospheric Sciences	Meteorology & Atmospheric Sciences	850JA	WOS:000223606000002		
J	Feng, Z; Prentice, R; Srivastava, S				Feng, Z; Prentice, R; Srivastava, S			Research issues and strategies for genomic and proteomic biornarker discovery and validation: a statistical perspective	PHARMACOGENOMICS			English	Article						biomarker; validation; disease association; early detection; genomics; molecular profiling; proteomics	PROSTATE-CANCER; LOGISTIC-REGRESSION; BREAST-CANCER; SERUM; CLASSIFICATION; AMPLIFICATION; ASSOCIATION; MORTALITY; PATTERNS; ERROR	The development and validation of clinically useful biomarkers from high-dimensional genomic and proteomic information pose great research challenges. Present bottlenecks include: that few of the biomarkers showing promise in initial discovery were found to warrant subsequent validation; and biomarker validation is expensive and time consuming. Biomarker evaluation should proceed in an orderly fashion to enhance rigor and efficiency. A molecular profiling approach, although promising, has a high chance of yielding biased results and overfitted models. Specimens from cohorts or intervention trials are essential to eliminate biases. The high cost for biomarker validation motivates some novel study design features, including sequential filtering and DNA pooling. For data analysis, logistic regression (in particular, boosting logistic regression) has features of robustness against model misspecification, and has resistance to model overfitting. Model assessment and cross-validation are critical components of data analysis. Having an independent test set is a vital feature of study design.	Fred Hutchinson Canc Res Ctr, Div Publ Hlth Sci, Seattle, WA 98104 USA; NCI, Div Canc Prevent, Bethesda, MD 20892 USA	Feng, Z (reprint author), Fred Hutchinson Canc Res Ctr, Div Publ Hlth Sci, 1124 Columbia St, Seattle, WA 98104 USA.	zfeng@fhcrc.org					Baker SG, 2000, BIOMETRICS, V56, P1082, DOI 10.1111/j.0006-341X.2000.01082.x; Barratt BJ, 2002, ANN HUM GENET, V66, P393, DOI 10.1017/S0003480002001252; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Copas JB, 2002, BIOMETRIKA, V89, P315, DOI 10.1093/biomet/89.2.315; Dean FB, 2002, P NATL ACAD SCI USA, V99, P5261, DOI 10.1073/pnas.082089499; Diamandis EP, 2004, J NATL CANCER I, V96, P353, DOI 10.1093/jnci/djh056; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; EFRON B, 1986, J AM STAT ASSOC, V81, P461, DOI 10.2307/2289236; Faruqi A F, 2001, BMC Genomics, V2, P4, DOI 10.1186/1471-2164-2-4; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Hastie T., 2001, ELEMENTS STAT LEARNI; Katz MH, 2003, ANN INTERN MED, V138, P644; Le Hellard S, 2002, NUCLEIC ACIDS RES, V30, DOI 10.1093/nar/gnf070; McIntosh MW, 2002, BIOMETRICS, V58, P657, DOI 10.1111/j.0006-341X.2002.00657.x; Mohlke KL, 2002, P NATL ACAD SCI USA, V99, P16928, DOI 10.1073/pnas.262661399; Nallur G, 2001, NUCLEIC ACIDS RES, V29, part. no., DOI 10.1093/nar/29.23.e118; Oliver S, 2000, LANCET, V355, P1788, DOI 10.1016/S0140-6736(00)02269-8; Oliver SE, 2000, LANCET, V356, P1278; Pepe MS, 2003, BIOMETRICS, V59, P133, DOI 10.1111/1541-0420.00016; Pepe MS, 2001, J NATL CANCER I, V93, P1054, DOI 10.1093/jnci/93.14.1054; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Qu YS, 2002, CLIN CHEM, V48, P1835; Ransohoff DF, 2004, NAT REV CANCER, V4, P309, DOI 10.1038/nrc1322; Ripley BD, 1996, PATTERN RECOGNITION; Sham P, 2002, NAT REV GENET, V3, P862, DOI 10.1038/nrg930; Shibata A, 1998, J NATL CANCER I, V90, P1230, DOI 10.1093/jnci/90.16.1230; Simon R, 2003, J NATL CANCER I, V95, P14; SRIVASTAVA S, 1999, DIS MARKERS, V15, P213; STONE M, 1974, J R STAT SOC B, V36, P111; THOMPSON IM, 2004, J ENGL J MED, V350, P2239; Tibshirani RJ, 2002, STAT APPL GENET MOL, V1; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; VALLE R, 2002, CURRENT DRUG DISCOVE, P35; van de Vijver MJ, 2002, NEW ENGL J MED, V347, P1999, DOI 10.1056/NEJMoa021967; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Yasui Y, 2003, BIOSTATISTICS, V4, P449, DOI 10.1093/biostatistics/4.3.449; ZHENG Y, 2004, UNPUB APPL TIME DEPE	38	55	58	FUTURE MEDICINE LTD	LONDON	UNITEC HOUSE, 3RD FLOOR, 2 ALBERT PLACE, FINCHLEY CENTRAL, LONDON, N3 1QB, ENGLAND	1462-2416			PHARMACOGENOMICS	Pharmacogenomics	SEP	2004	5	6					709	719		10.1517/14622416.5.6.709		11	Pharmacology & Pharmacy	Pharmacology & Pharmacy	864CT	WOS:000224611400015	15335291	
J	Vinayagam, A; Konig, R; Moormann, J; Schubert, F; Eils, R; Glatting, KH; Suhai, S				Vinayagam, A; Konig, R; Moormann, J; Schubert, F; Eils, R; Glatting, KH; Suhai, S			Applying support vector machines for gene ontology based gene function prediction	BMC BIOINFORMATICS			English	Article							SEQUENCE-ANALYSIS; GENOME SEQUENCE; ANNOTATION; GO; IMPLEMENTATION; BIOINFORMATICS; INTERFACE; FRAMEWORK; DATABASE; TOOL	Background: The current progress in sequencing projects calls for rapid, reliable and accurate function assignments of gene products. A variety of methods has been designed to annotate sequences on a large scale. However, these methods can either only be applied for specific subsets, or their results are not formalised, or they do not provide precise confidence estimates for their predictions. Results: We have developed a large-scale annotation system that tackles all of these shortcomings. In our approach, annotation was provided through Gene Ontology terms by applying multiple Support Vector Machines (SVM) for the classification of correct and false predictions. The general performance of the system was benchmarked with a large dataset. An organism-wise cross-validation was performed to define confidence estimates, resulting in an average precision of 80% for 74% of all test sequences. The validation results show that the prediction performance was organism-independent and could reproduce the annotation of other automated systems as well as high-quality manual annotations. We applied our trained classification system to Xenopus laevis sequences, yielding functional annotation for more than half of the known expressed genome. Compared to the currently available annotation, we provided more than twice the number of contigs with good quality annotation, and additionally we assigned a confidence value to each predicted GO term. Conclusions: We present a complete automated annotation system that overcomes many of the usual problems by applying a controlled vocabulary of Gene Ontology and an established classification method on large and well-described sequence data sets. In a case study, the function for Xenopus laevis contig sequences was predicted and the results are publicly available at ftp://genome.dkfz-heidelberg.de/pub/agd/gene_association.agd_Xenopus.	Deutsch Krebsforschungszentrum, Dept Mol Biophys, D-69120 Heidelberg, Germany; Univ Mainz, Inst Med Biometrie Epidemiol & Informat, D-55101 Mainz, Germany	Vinayagam, A (reprint author), Deutsch Krebsforschungszentrum, Dept Mol Biophys, Neuenheimer Feld 580,TP3, D-69120 Heidelberg, Germany.	A.Vinayagam@dkfz-heidelberg.de; R.Koenig@dkfz-heidelberg.de; moormann@imbei.uni-mainz.de; F.Schubert@dkfz-heidelberg.de; R.Eils@dkfz-heidelberg.de; Glatting@dkfz-heidelberg.de; S.Suhai@dkfz-heidelberg.de	Arunachalam, Vinayagam/J-7925-2012; Eils, Roland/B-6121-2009	Arunachalam, Vinayagam/0000-0003-0091-4497; 			Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Andrade MA, 1999, BIOINFORMATICS, V15, P391, DOI 10.1093/bioinformatics/15.5.391; Ashburner M, 2000, NAT GENET, V25, P25; Bailey LC, 1998, GENOME RES, V8, P234; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Bork P, 1998, NAT GENET, V18, P313, DOI 10.1038/ng0498-313; Bork P, 1996, TRENDS GENET, V12, P425, DOI 10.1016/0168-9525(96)60040-7; Bork P, 1996, METHOD ENZYMOL, V266, P162; Camon E, 2003, GENOME RES, V13, P662, DOI 10.1101/gr.461403; del Val C, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-39; Ernst P, 2003, BIOINFORMATICS, V19, P278, DOI 10.1093/bioinformatics/19.2.278; Frishman D, 2001, BIOINFORMATICS, V17, P44, DOI 10.1093/bioinformatics/17.1.44; Gaasterland T, 1996, TRENDS GENET, V12, P76, DOI 10.1016/0168-9525(96)81406-5; GALPERIN MY, 1998, SILICO BIOL, V1, P7; Ashburner M, 2001, GENOME RES, V11, P1425; Hand David J, 2001, PRINCIPLES DATA MINI; Harris NL, 1997, GENOME RES, V7, P754; Hastie T., 2001, ELEMENTS STAT LEARNI; Hennig S, 2003, NUCLEIC ACIDS RES, V31, P3712, DOI 10.1093/nar/gkg582; Hill DP, 2002, GENOME RES, V12, P1982, DOI 10.1101/gr.580102; Jensen LJ, 2003, BIOINFORMATICS, V19, P635, DOI 10.1093/bioinformatics/btg036; Kitson David H, 2002, Brief Bioinform, V3, P32, DOI 10.1093/bib/3.1.32; Lewis S, 2000, CURR OPIN STRUC BIOL, V10, P349, DOI 10.1016/S0959-440X(00)00095-6; Peiffer Daniel A., 2003, Current Genomics, V4, P665, DOI 10.2174/1389202033490097; Sakata K, 2002, NUCLEIC ACIDS RES, V30, P98, DOI 10.1093/nar/30.1.98; Schug J, 2002, GENOME RES, V12, P648, DOI 10.1101/gr.222902; Searls DB, 2000, DRUG DISCOV TODAY, V5, P135, DOI 10.1016/S1359-6446(99)01457-9; Senger M, 1998, BIOINFORMATICS, V14, P452, DOI 10.1093/bioinformatics/14.5.452; Smith TF, 1998, TRENDS GENET, V14, P291, DOI 10.1016/S0168-9525(98)01508-X; Xie HQ, 2002, GENOME RES, V12, P785, DOI 10.1101/gr.86902; Zehetner G, 2003, NUCLEIC ACIDS RES, V31, P3799, DOI 10.1093/nar/gkg555; LIBSVM VERS 2 4	32	44	45	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	AUG 26	2004	5								116	10.1186/1471-2105-5-116		14	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	855RX	WOS:000223992500002	15333146	
J	Bern, M; Goldberg, D; McDonald, WH; Yates, JR				Bern, Marshall; Goldberg, David; McDonald, W. Hayes; Yates, John R., III			Automatic Quality Assessment of Peptide Tandem Mass Spectra	BIOINFORMATICS			English	Article								Motivation: A powerful proteomics methodology couples high-performance liquid chromatography (HPLC) with tandem mass spectrometry and database-search software, such as SEQUEST. Such a set-up, however, produces a large number of spectra, many of which are of too poor quality to be useful. Hence a filter that eliminates poor spectra before the database search can significantly improve throughput and robustness. Moreover, spectra judged to be of high quality, but that cannot be identified by database search, are prime candidates for still more computationally intensive methods, such as de novo sequencing or wider database searches including post-translational modifications. Results: We report on two different approaches to assessing spectral quality prior to identification: binary classification, which predicts whether or not SEQUEST will be able to make an identification, and statistical regression, which predicts a more universal quality metric involving the number of b- and y-ion peaks. The best of our binary classifiers can eliminate over 75% of the unidentifiable spectra while losing only 10% of the identifiable spectra. Statistical regression can pick out spectra of modified peptides that can be identified by a de novo program but not by SEQUEST. In a section of independent interest, we discuss intensity normalization of mass spectra.	[Bern, Marshall; Goldberg, David] Xerox Corp, Palo Alto Res Ctr, Palo Alto, CA 94304 USA; [McDonald, W. Hayes; Yates, John R., III] Scripps Res Inst, La Jolla, CA 92037 USA	Goldberg, D (reprint author), Xerox Corp, Palo Alto Res Ctr, 3333 Coyote Hill Rd, Palo Alto, CA 94304 USA.	goldberg@parc.com					Aebersold R, 2001, CHEM REV, V101, P269, DOI 10.1021/cr990076h; Bafna V, 2001, Bioinformatics, V17 Suppl 1, pS13; Dancik V, 1999, J COMPUT BIOL, V6, P327, DOI 10.1089/106652799318300; ENG JK, 1994, J AM SOC MASS SPECTR, V5, P976, DOI 10.1016/1044-0305(94)80016-2; Field HI, 2002, PROTEOMICS, V2, P36, DOI 10.1002/1615-9861(200201)2:1<36::AID-PROT36>3.3.CO;2-N; Hastie T., 2001, ELEMENTS STAT LEARNI; Havilio M, 2003, ANAL CHEM, V75, P435, DOI 10.1021/ac0258913; Joachims T., 1999, ADV KERNEL METHODS S; Keller Andrew, 2002, OMICS A Journal of Integrative Biology, V6, P207, DOI 10.1089/153623102760092805; Kinter M, 2000, PROTEIN SEQUENCING I; Liebler D. C, 2001, INTRO PROTEOMICS TOO; MacCoss MJ, 2002, P NATL ACAD SCI USA, V99, P7900, DOI 10.1073/pnas.122231399; MacCoss MJ, 2002, ANAL CHEM, V74, P5593, DOI 10.1021/ac025826t; Perkins DN, 1999, ELECTROPHORESIS, V20, P3551, DOI 10.1002/(SICI)1522-2683(19991201)20:18<3551::AID-ELPS3551>3.0.CO;2-2; Sadygov RG, 2002, J PROTEOME RES, V1, P211, DOI 10.1021/pr015514r; Tabb D. L., 2001, PROTEOME RES MASS SP; Tabb DL, 2003, ANAL CHEM, V75, P1155, DOI 10.1021/ac026122m; Tabb DL, 2003, ANAL CHEM, V75, P6415, DOI 10.1021/ac0347462; Taylor JA, 2001, ANAL CHEM, V73, P2594, DOI 10.1021/ac001196o; Vapnik VN, 1996, NATURE STAT LEARNING; Washburn MP, 2001, NAT BIOTECHNOL, V19, P242, DOI 10.1038/85686	21	60	65	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	AUG 4	2004	20			1			49	54		10.1093/bioinformatics/bth947		6	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	V24DZ	WOS:000208392400007		
J	de Hoon, MJL; Makita, Y; Imoto, S; Kobayashi, K; Ogasawara, N; Nakai, K; Miyano, S				de Hoon, M. J. L.; Makita, Y.; Imoto, S.; Kobayashi, K.; Ogasawara, N.; Nakai, K.; Miyano, S.			Predicting gene regulation by sigma factors in Bacillus subtilis from genome-wide data	BIOINFORMATICS			English	Article								Motivation: Sigma factors regulate the expression of genes in Bacillus subtilis at the transcriptional level. We assess the accuracy of a fold-change analysis, Bayesian networks, dynamic models and supervised learning based on coregulation in predicting gene regulation by sigma factors from gene expression data. To improve the prediction accuracy, we combine sequence information with expression data by adding their log-likelihood scores and by using a logistic regression model. We use the resulting score function to discover currently unknown gene regulations by sigma factors. Results: The coregulation-based supervised learning method gave the most accurate prediction of sigma factors from expression data. We found that the logistic regression model effectively combines expression data with sequence information. In a genome-wide search, highly significant logistic regression scores were found for several genes whose transcriptional regulation is currently unknown. We provide the corresponding RNA polymerase binding sites to enable a straightforward experimental verification of these predictions.	[de Hoon, M. J. L.; Makita, Y.; Imoto, S.; Nakai, K.; Miyano, S.] Univ Tokyo, Ctr Human Genome, Inst Med Sci, Minato Ku, Tokyo 1088639, Japan; [Kobayashi, K.; Ogasawara, N.] Nara Inst Sci & Technol, Grad Sch Biol Sci, Nara 6300101, Japan	de Hoon, MJL (reprint author), Univ Tokyo, Ctr Human Genome, Inst Med Sci, Minato Ku, 4-6-1 Shirokanedai, Tokyo 1088639, Japan.	mdehoon@ims.u-tokyo.ac.jp	de Hoon, Michiel/A-6443-2013; Ogasawara, Naotake/B-7971-2011				Akutsu T, 1999, PAC S BIOC, V4, P17; Chen T, 1999, P PAC S BIOC, V4, P29; de Hoon M., 2003, PACIFIC S BIOCOMPUTI, V8, P17; De Hoon M.J.L., 2004, PAC S BIOCOMPUT, V9, P276; Durbin R, 1998, BIOL SEQUENCE ANAL P; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Hastie T., 2001, ELEMENTS STAT LEARNI; Imoto Seiya, 2003, J Bioinform Comput Biol, V1, P231, DOI 10.1142/S0219720003000071; Imoto S, 2002, P PAC S BIOC, V7, P175; KIM SY, 2003, SPRINGER VERLAG LECT, V2602, P104; Liang S, 1998, PAC S BIOCOMPUT, V3, P18; Liu X., 2001, PAC S BIOCOMPUT, V6, P127; Makita Y, 2004, NUCLEIC ACIDS RES, V32, pD75, DOI 10.1093/nar/gkh074; Murphy K, 1999, MODELLING GENE EXPRE; Ong Irene M, 2002, Bioinformatics, V18 Suppl 1, pS241; Segal E, 2003, BIOINFORMATICS S1, V19, pi271; Tamada Y., 2003, BIOINFORMATICS, V19, pii227; van Someren E. P., 2000, Proceedings. Eighth International Conference on Intelligent Systems for Molecular Biology; Yada T., 1997, P 5 INT C INT SYST M, P354	19	11	11	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	AUG 4	2004	20			1			101	108		10.1093/bioinformatics/bth927		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	V24DZ	WOS:000208392400014		
J	Schliep, A; Steinhoff, C; Schonhuth, A				Schliep, Alexander; Steinhoff, Christine; Schoenhuth, Alexander			Robust inference of groups in gene expression time-courses using mixtures of HMMs	BIOINFORMATICS			English	Article								Motivation: Genetic regulation of cellular processes is frequently investigated using large-scale gene expression experiments to observe changes in expression over time. This temporal data poses a challenge to classical distance-based clustering methods due to its horizontal dependencies along the time-axis. We propose to use hidden Markov models (HMMs) to explicitly model these time-dependencies. The HMMs are used in a mixture approach that we show to be superior over clustering. Furthermore, mixtures are a more realistic model of the biological reality, as an unambiguous partitioning of genes into clusters of unique functional assignment is impossible. Use of the mixture increases robustness with respect to noise and allows an inference of groups at varying level of assignment ambiguity. A simple approach, partially supervised learning, allows to benefit from prior biological knowledge during the training. Our method allows simultaneous analysis of cyclic and non-cyclic genes and copes well with noise and missing values. Results: We demonstrate biological relevance by detection of phase-specific groupings in HeLa time-course data. A benchmark using simulated data, derived using assumptions independent of those in our method, shows very favorable results compared to the baseline supplied by k-means and two prior approaches implementing model-based clustering. The results stress the benefits of incorporating prior knowledge, whenever available.	[Schliep, Alexander; Steinhoff, Christine] Max Planck Inst Mol Genet, Dept Computat Mol Biol, D-14195 Berlin, Germany; [Schoenhuth, Alexander] Univ Cologne, Ctr Appl Comp Sci, D-50937 Cologne, Germany	Schliep, A (reprint author), Max Planck Inst Mol Genet, Dept Computat Mol Biol, Ihnestr 73, D-14195 Berlin, Germany.	schliep@molgen.mpg.de					Bar-Joseph Z., 2002, P 6 ANN INT C RES CO, P39, DOI 10.1145/565196.565202; Belkin M, 2003, THESIS U CHICAGO; Bilmes J., 1998, TR97021 INT COMP SCI; Blum A., 2001, P 18 INT C MACH LEAR, P19; BOYLES RA, 1983, J ROY STAT SOC B MET, V45, P47; CASTELLI V, 1995, PATTERN RECOGN LETT, V16, P105, DOI 10.1016/0167-8655(94)00074-D; Chen T., 1999, P 3 ANN INT C COMP M, P94, DOI 10.1145/299432.299462; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Gasch AP, 2000, MOL BIOL CELL, V11, P4241; Hastie T., 2001, ELEMENTS STAT LEARNI; KNAB B, 2003, DATA SCI APPL DATA A, P561; KRAUS B, 1994, GENOMICS, V24, P27, DOI 10.1006/geno.1994.1578; MacDonald IL, 1997, HIDDEN MARKOV OTHER; MCLACHLAN G., 2000, WILEY SERIES PROBABI; McLachlan G. J., 1988, MIXTURE MODELS INFER; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; PEDRYCZ W, 1990, PATTERN RECOGN, V23, P121, DOI 10.1016/0031-3203(90)90054-O; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Ramoni MF, 2002, P NATL ACAD SCI USA, V99, P9121, DOI 10.1073/pnas.132656399; Rifkin SA, 2002, BIOINFORMATICS, V18, P1176, DOI 10.1093/bioinformatics/18.9.1176; Schliep A, 2003, BIOINFORMATICS, V19, pi255, DOI 10.1093/bioinformatics/btg1036; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Szummer M., 2002, ADV NEURAL INFORM PR, V14; Tavazoie S, 1999, NAT GENET, V22, P281; Whitfield ML, 2002, MOL BIOL CELL, V13, P1977, DOI 10.1091/mbc.02-02-0030; WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060	28	14	14	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	AUG 4	2004	20			1			283	289		10.1093/bioinformatics/bth937		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	V24DZ	WOS:000208392400037		
J	Morrison, C; Farrar, W; Kneile, J; Williams, N; Liu-Stratton, Y; Bakaletz, A; Aldred, MA; Eng, C				Morrison, C; Farrar, W; Kneile, J; Williams, N; Liu-Stratton, Y; Bakaletz, A; Aldred, MA; Eng, C			Molecular classification of parathyroid neoplasia by gene expression profiling	AMERICAN JOURNAL OF PATHOLOGY			English	Article							COMPARATIVE GENOMIC HYBRIDIZATION; PRIMARY HYPERPARATHYROIDISM; CLASS PREDICTION; SURGICAL-TREATMENT; DOUBLE ADENOMAS; TUMORS; MICROARRAY; CANCER; CARCINOMAS; DISCOVERY	The current classification of sporadic parathyroid neoplasia, specifically the distinction of adenoma from multiple gland neoplasia (double adenoma and nonfamilial primary hyperplasia) is problematic and results in a relatively high rate of clinical error. Oligonucleotide microarrays (Affymetrix U133A) were used to evaluate parathyroid samples from 61 patients; 35 adenomas, 10 nonfamilial multiple gland neoplasia, 3 familial primary hyperplasia, 8 renal-induced hyperplasia, and 5 from patients without parathyroid disease (normals). A multiclass comparison using supervised clustering identified distinct gene signatures for each class of parathyroid samples. We developed a predictor model that correctly identified 34 of 35 cases of adenoma, 9 of 10 cases of nonfamilial multiple gland neoplasia, and identified a minimum set of 11 genes for the distinction of adenoma versus multiple gland neoplasia. All methods of unsupervised clustering showed two related but different types of parathyroid adenomas that we have arbitrarily designated as type 1 and type 2 adenomas. Multiple gland parathyroid neoplasia, which represents either synchronous or asynchronous autonomous growth in two, three, or all four parathyroid glands, is a distinct molecular entity and does not represent the molecular pathogenesis of adenoma occurring in multiple glands.	Ohio State Univ, Human Canc Genet Program, Columbus, OH 43210 USA; Ohio State Univ, Clin Canc Genet Program, Columbus, OH 43210 USA; Ohio State Univ, Ctr Comprehens Canc, Columbus, OH 43210 USA; Ohio State Univ, Dept Internal Med, Columbus, OH 43210 USA; Ohio State Univ, Div Human Genet, Columbus, OH 43210 USA; Ohio State Univ, Dept Pathol, Columbus, OH 43210 USA; Ohio State Univ, Dept Surg, Columbus, OH 43210 USA; Ohio State Univ, Div Surg Oncol, Columbus, OH 43210 USA; Ohio State Univ, Microarray Core Facil, Columbus, OH 43210 USA; Ohio State Univ, Bioinformat Core Facil, Columbus, OH 43210 USA; Ohio State Univ, Dorothy M Davis Heart & Lung Res Inst, Columbus, OH 43210 USA; Univ Leicester, Div Med Genet, Leicester, Leics, England	Morrison, C (reprint author), Ohio State Univ, Dept Atom Pathol, 310 W 10th Ave,M-417 Starling Loving Hall, Columbus, OH 43210 USA.	morrison-4@medctr.osu.edu					Agarwal SK, 1998, CANCER GENET CYTOGEN, V106, P30, DOI 10.1016/S0165-4608(98)00049-1; Alaiya AA, 2002, INT J CANCER, V98, P895, DOI 10.1002/ijc.10288; Albright F, 1934, ARCH INTERN MED, V54, P315; Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; ATTIE JN, 1990, SURGERY, V108, P1014; Baloch ZW, 2001, ARCH PATHOL LAB MED, V125, P178; Barden CB, 2003, CLIN CANCER RES, V9, P1792; Bhattacharjee A, 2001, P NATL ACAD SCI USA, V98, P13790, DOI 10.1073/pnas.191502998; Bloom G, 2004, AM J PATHOL, V164, P9, DOI 10.1016/S0002-9440(10)63090-8; Castleman B, 1935, AM J PATHOL, V11, P1; Correa P, 2002, CLIN ENDOCRINOL, V56, P113, DOI 10.1046/j.0300-0664.2001.01436.x; Denizot A, 2001, AM J SURG, V182, P15, DOI 10.1016/S0002-9610(01)00664-X; El-Naggar AK, 2002, ONCOGENE, V21, P8206, DOI 10.1038/sj.onc.1206021; Garcia JL, 2002, EUR J ENDOCRINOL, V146, P209, DOI 10.1530/eje.0.1460209; Giordano TJ, 2003, AM J PATHOL, V162, P521, DOI 10.1016/S0002-9440(10)63846-1; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Goodman WG, 2000, NEW ENGL J MED, V342, P1478, DOI 10.1056/NEJM200005183422003; HASTIE T, 2001, ELEMENTS STAT LEARNI, P1; HEATH DA, 1989, ENDOCRIN METAB CLIN, V18, P631; Imanishi Y, 2002, J AM SOC NEPHROL, V13, DOI 10.1097/01.ASN.0000018148.50109.C0; KNUDSEN S, 2002, BIOL GUIDE ANAL DNA, P41; Larian B, 2001, HEAD NECK-J SCI SPEC, V23, P134, DOI 10.1002/1097-0347(200102)23:2<134::AID-HED1008>3.0.CO;2-J; Mischel PS, 2003, ONCOGENE, V22, P2361, DOI 10.1038/sj.onc.1206344; Nielsen TO, 2002, LANCET, V359, P1301, DOI 10.1016/S0140-6736(02)08270-3; PALMER M, 1988, EUR J CLIN INVEST, V18, P39, DOI 10.1111/j.1365-2362.1988.tb01163.x; Parmigiani G, 2003, ANAL GENE EXPRESSION, P1, DOI 10.1007/0-387-21679-0_1; Qunibi WY, 2002, KIDNEY INT S, V82, pS73; Radmacher MD, 2002, J COMPUT BIOL, V9, P505, DOI 10.1089/106652702760138592; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; RUDBERG C, 1986, SURGERY, V99, P643; Sackett WR, 2002, ARCH SURG-CHICAGO, V137, P1055, DOI 10.1001/archsurg.137.9.1055; Schwartz DR, 2002, CANCER RES, V62, P4722; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Simon R, 2003, J NATL CANCER I, V95, P14; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Somorjai RL, 2003, BIOINFORMATICS, V19, P1484, DOI 10.1093/bioinformatics/btg182; Sorlie T, 2001, P NATL ACAD SCI USA, V98, P10869, DOI 10.1073/pnas.191367098; Sosa JA, 1998, J CLIN ENDOCR METAB, V83, P2658, DOI 10.1210/jc.83.8.2658; TEZELMAN S, 1993, ANN SURG, V218, P300, DOI 10.1097/00000658-199309000-00009; TEZELMAN S, 1995, SURGERY, V118, P1115, DOI 10.1016/S0039-6060(05)80122-9; VERDONK CA, 1981, SURGERY, V90, P523; Vestergaard P, 2003, WORLD J SURG, V27, P216, DOI 10.1007/s00268-002-6541-z; Wang Y, 2000, GENE DEV, V14, P927; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	44	15	15	AMER SOC INVESTIGATIVE PATHOLOGY, INC	BETHESDA	9650 ROCKVILLE PIKE, BETHESDA, MD 20814-3993 USA	0002-9440			AM J PATHOL	Am. J. Pathol.	AUG	2004	165	2					565	576		10.1016/S0002-9440(10)63321-4		12	Pathology	Pathology	840XL	WOS:000222893400020	15277230	
J	Hutter, B; Schaab, C; Albrecht, S; Borgmann, M; Brunner, NA; Freiberg, C; Ziegelbauer, K; Rock, CO; Ivanov, I; Loferer, H				Hutter, B; Schaab, C; Albrecht, S; Borgmann, M; Brunner, NA; Freiberg, C; Ziegelbauer, K; Rock, CO; Ivanov, I; Loferer, H			Prediction of mechanisms of action of antibacterial compounds by gene expression profiling	ANTIMICROBIAL AGENTS AND CHEMOTHERAPY			English	Article							SUPPORT VECTOR MACHINES; BACILLUS-SUBTILIS; ESCHERICHIA-COLI; MICROARRAY DATA; DATA QUALITY; CLASSIFICATION; TRANSCRIPTION; INHIBITION; TRICLOSAN; DISCOVERY	We have generated a database of expression profiles carrying the transcriptional responses of the model organism Bacillus subtilis following treatment with 37 well-characterized antibacterial compounds of different classes. The database was used to build a predictor for the assignment of the mechanisms of action (MoAs) of antibacterial compounds by the use of support vector machines. This predictor was able to correctly classify the MoA class for most compounds tested. Furthermore, we provide evidence that the in vivo MoA of hexachlorophene does not match the MoA predicted from in vitro data, a situation frequently faced in drug discovery. A database of this kind may facilitate the prioritization of novel antibacterial entities in drug discovery programs. Potential applications and limitations are discussed.	GPC Biotech AG, D-8152 Munich, Germany; Bayer AG, Wuppertal, Germany; St Jude Childrens Res Hosp, Dept Infect Dis, Memphis, TN 38105 USA	Loferer, H (reprint author), GPC Biotech AG, Fraunhoferstr 20, D-8152 Munich, Germany.	hannes.loferer@gpc-biotech.com	Schaab, Christoph/C-6098-2008				Amon P, 2003, BIOTECHNIQUES, V34, P700; Bandow JE, 2003, ANTIMICROB AGENTS CH, V47, P948, DOI 10.1128/AAC.47.3.948-955.2003; Ben-Dor A, 2000, J COMPUT BIOL, V7, P559, DOI 10.1089/106652700750050943; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Finkelstein D, 2002, PLANT MOL BIOL, V48, P119, DOI 10.1023/A:1013765922672; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Gmuender H, 2001, GENOME RES, V11, P28, DOI 10.1101/gr.157701; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Haas M, 2001, MICROBIOL-SGM, V147, P1783; Hastie T., 2001, ELEMENTS STAT LEARNI; Heath RJ, 2000, J BIOL CHEM, V275, P4654, DOI 10.1074/jbc.275.7.4654; Heath RJ, 1999, J BIOL CHEM, V274, P11110, DOI 10.1074/jbc.274.16.11110; Heath RJ, 2000, J BIOL CHEM, V275, P40128, DOI 10.1074/jbc.M005611200; Hooper DC, 1999, DRUGS, V58, P6, DOI 10.2165/00003495-199958002-00002; Hughes TR, 2000, CELL, V102, P109, DOI 10.1016/S0092-8674(00)00015-5; Hutter B, 2004, ANTIMICROB AGENTS CH, V48, P2588, DOI 10.1128/AAC.48.7.2588-2594.2004; Kostoryz EL, 2001, MUTAT RES-GEN TOX EN, V490, P131, DOI 10.1016/S1383-5718(00)00158-3; KUBITSCHEK HE, 1982, MUTAT RES, V94, P31, DOI 10.1016/0027-5107(82)90166-X; Kunst F, 1997, NATURE, V390, P249, DOI 10.1038/36786; LAWSON T, 1989, ANTICANCER RES, V9, P483; Machl AW, 2002, NUCLEIC ACIDS RES, V30, DOI 10.1093/nar/gnf127; Mirkin B., 1996, NONCONVEX OPTIMIZATI, V11; Novak JP, 2002, GENOMICS, V79, P104, DOI 10.1006/geno.2001.6675; Planet PJ, 2001, GENOME RES, V11, P1149, DOI 10.1101/gr.187601; Potter AJ, 2002, CARCINOGENESIS, V23, P389, DOI 10.1093/carcin/23.3.389; Richmond CS, 1999, NUCLEIC ACIDS RES, V27, P3821, DOI 10.1093/nar/27.19.3821; Scholkopf B., 2002, LEARNING KERNELS SUP; Schujman GE, 2003, DEV CELL, V4, P663, DOI 10.1016/S1534-5807(03)00123-0; Schujman GE, 2001, J BACTERIOL, V183, P3032, DOI 10.1128/JB.183.10.3032-3040.2001; Shaw KJ, 2003, J MOL MICROB BIOTECH, V5, P105, DOI 10.1159/000069981; STULKE J, 1993, J GEN MICROBIOL, V139, P2041; Valentini G, 2002, ARTIF INTELL MED, V26, P281, DOI 10.1016/S0933-3657(02)00077-5; Vapnik V., 1999, NATURE STAT LEARNING; WIGLEY DB, 1995, ANNU REV BIOPH BIOM, V24, P185, DOI 10.1146/annurev.biophys.24.1.185	34	91	93	AMER SOC MICROBIOLOGY	WASHINGTON	1752 N ST NW, WASHINGTON, DC 20036-2904 USA	0066-4804			ANTIMICROB AGENTS CH	Antimicrob. Agents Chemother.	AUG	2004	48	8					2838	2844		10.1128/AAC.48.8.2838-2844.2004		7	Microbiology; Pharmacology & Pharmacy	Microbiology; Pharmacology & Pharmacy	842IV	WOS:000222998300008	15273089	
J	Navarro, DJ; Pitt, MA; Myung, IJ				Navarro, DJ; Pitt, MA; Myung, IJ			Assessing the distinguishability of models and the informativeness of data	COGNITIVE PSYCHOLOGY			English	Article						model distinguishability; retention models; landscaping; data informativeness	LONG-TERM-MEMORY; SPEECH-PERCEPTION; FORGETTING CURVES; RETENTION; SELECTION; RECOGNITION; SIMILARITY; DISTRIBUTIONS; COGNITION; PICTURES	A difficulty in the development and testing of psychological models is that they are typically evaluated solely on their ability to fit experimental data, with little consideration given to their ability to fit other possible data patterns. By examining how well model A fits data generated by model B, and vice versa (a technique that we call landscaping), much safer inferences can be made about the meaning of a model's fit to data. We demonstrate the landscaping technique using four models of retention and 77 historical data sets, and show how the method can be used to: (1) evaluate the distinguishability of models, (2) evaluate the informativeness of data in distinguishing between models, and (3) suggest new ways to distinguish between models. The generality of the method is demonstrated in two other research areas (information integration and categorization), and its relationship to the important notion of model complexity is discussed. (C) 2004 Elsevier Inc. All rights reserved.	Ohio State Univ, Dept Psychol, Columbus, OH 43210 USA	Navarro, DJ (reprint author), Ohio State Univ, Dept Psychol, 1827 Neil Ave, Columbus, OH 43210 USA.	navarro.20@osu.edu; pitt.2@osu.edu; myung.1@osu.edu					ALIN L, 1997, GOTEBOTG PSYCHOL REP, V27; ANDERSON JR, 1991, PSYCHOL SCI, V2, P396, DOI 10.1111/j.1467-9280.1991.tb00174.x; ANDERSON NH, 1981, FDN INFORMATION INTE; ASHBY FG, 1994, PSYCHOL SCI, V5, P144, DOI 10.1111/j.1467-9280.1994.tb00651.x; BAHRICK HP, 1975, J EXP PSYCHOL GEN, V104, P54, DOI 10.1037//0096-3445.104.1.54; BALASUBRAMANIAN V, 1997, NEURAL COMPUT, V9, P347; BOX GEP, 1976, J AM STAT ASSOC, V71, P791, DOI 10.2307/2286841; BREGMAN AS, 1968, J EXP PSYCHOL, V78, P539, DOI 10.1037/h0026635; Brown S, 2003, BEHAV RES METH INS C, V35, P11, DOI 10.3758/BF03195493; Burtt HE, 1925, J APPL PSYCHOL, V9, P5, DOI 10.1037/h0073966; CONWAY MA, 1991, J EXP PSYCHOL GEN, V120, P395; DEBRUIJN NG, 1958, ASYMPTOTIC METHODS A; ESTES WK, 1956, PSYCHOL BULL, V53, P134, DOI 10.1037/h0045156; GEHRING RE, 1976, MEM COGNITION, V4, P256, DOI 10.3758/BF03213172; Geweke J., 1999, ECONOMET REV, V18, P1, DOI 10.1080/07474939908800428; Geweke J., 1999, BAYESIAN STAT, V6, P275; Gilks W. R., 1995, MARKOV CHAIN MONTE C; Gill J., 2002, BAYESIAN METHODS SOC; Grunwald P, 2000, J MATH PSYCHOL, V44, P133, DOI 10.1006/jmps.1999.1280; Hastie T., 2001, ELEMENTS STAT LEARNI; Jeffreys H., 1961, THEORY PROBABILITY; Kass RE, 1996, J AM STAT ASSOC, V91, P1343, DOI 10.2307/2291752; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572; KIM W, 2004, ADV NEURAL INFORMATI, P16; Krueger WCF, 1929, J EXP PSYCHOL, V12, P71, DOI 10.1037/h0072036; Lee MD, 2003, J MATH PSYCHOL, V47, P32, DOI 10.1016/S0022-2496(02)00019-6; LONGMORE BE, 1988, J ABNORM PSYCHOL, V97, P448, DOI 10.1037/0021-843X.97.4.448; LUH CW, 2002, PSYCHOL MONOGRAPHS, V31; MACLEOD CM, 1988, J EXP PSYCHOL LEARN, V14, P195, DOI 10.1037/0278-7393.14.2.195; MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0; Minda JP, 2002, J EXP PSYCHOL LEARN, V28, P275, DOI 10.1037//0278-7393.28.2.275; MURDOCK BB, 1961, J EXP PSYCHOL, V62, P618, DOI 10.1037/h0043657; Murray M., 1993, DIFFERENTIAL GEOMETR; Myung IJ, 2003, J MATH PSYCHOL, V47, P90, DOI 10.1016/S0022-2496(02)00028-7; Myung IJ, 2000, MEM COGNITION, V28, P832, DOI 10.3758/BF03198418; Myung IJ, 2000, P NATL ACAD SCI USA, V97, P11170, DOI 10.1073/pnas.170283897; Myung IJ, 1997, PSYCHON B REV, V4, P79, DOI 10.3758/BF03210778; Navarro D. J., 2003, P 25 ANN C COGN SCI; NAVARRO DJ, IN PRESS NEURAL COMP; Nocedal J., 1999, NUMERICAL OPTIMIZATI; Norris D, 2000, BEHAV BRAIN SCI, V23, P299, DOI 10.1017/S0140525X00003241; NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39; ODEN GC, 1978, PSYCHOL REV, V85, P172, DOI 10.1037/0033-295X.85.3.172; PETERSON LR, 1959, J EXP PSYCHOL, V58, P193, DOI 10.1037/h0049234; Pitt MA, 2002, PSYCHOL REV, V109, P472, DOI 10.1037//0033-295X.109.3.472; Pitt MA, 2003, PSYCHON B REV, V10, P29, DOI 10.3758/BF03196467; Raftery AE, 1995, SOCIOL METHODOL, V25, P111, DOI 10.2307/271063; RATCLIFF R, IN PRESS PSYCHOL REV; Rissanen J, 2001, IEEE T INFORM THEORY, V47, P1712, DOI 10.1109/18.930912; Rissanen JJ, 1996, IEEE T INFORM THEORY, V42, P40, DOI 10.1109/18.481776; Robert CP, 2001, BAYESIAN CHOICE; Rubin DC, 1996, PSYCHOL REV, V103, P734, DOI 10.1037/0033-295X.103.4.734; Rubin DC, 1999, J EXP PSYCHOL LEARN, V25, P1161, DOI 10.1037//0278-7393.25.5.1161; RUNQUIST WN, 1983, MEM COGNITION, V11, P641, DOI 10.3758/BF03198289; SHEPARD RN, 1987, SCIENCE, V237, P1317, DOI 10.1126/science.3629243; SHIN HJ, 1992, J EXP PSYCHOL GEN, V121, P278, DOI 10.1037/0096-3445.121.3.278; Sikstrom S, 2002, COGNITIVE PSYCHOL, V45, P95, DOI 10.1016/S0010-0285(02)00012-9; SLOMAN SA, 1988, J EXPT PSYCHOL LEARN, V77, P812; SQUIRE LR, 1989, J EXP PSYCHOL LEARN, V15, P241, DOI 10.1037/0278-7393.15.2.241; Steyvers M, 2003, COGNITIVE SCI, V27, P453, DOI 10.1016/S0364-0213(03)00010-7; STRONG EK, 1913, PSYCHOL REV, P339; SU Y, IN PRESS ADV MINIMUM; THOMPSON CP, 1982, MEM COGNITION, V10, P324, DOI 10.3758/BF03202424; WAGENMAKERS EJ, IN PRESS J MATH PSYC; WICKELGR.WA, 1968, NEUROPSYCHOLOGIA, V6, P235, DOI 10.1016/0028-3932(68)90022-5; WICKELGR.WA, 1972, J MATH PSYCHOL, V9, P418, DOI 10.1016/0022-2496(72)90015-6; Wixted JT, 1997, MEM COGNITION, V25, P731, DOI 10.3758/BF03211316; WIXTED JT, 1991, PSYCHOL SCI, V2, P409, DOI 10.1111/j.1467-9280.1991.tb00175.x	68	43	43	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0010-0285			COGNITIVE PSYCHOL	Cogn. Psychol.	AUG	2004	49	1					47	84		10.1016/j.cogpsych.2003.11.001		38	Psychology; Psychology, Experimental	Psychology	834JI	WOS:000222407000002	15193972	
J	Bach, FR; Jordan, MI				Bach, FR; Jordan, MI			Learning graphical models for stationary time series	IEEE TRANSACTIONS ON SIGNAL PROCESSING			English	Article						frequency domain analysis; modeling; sparse matrices; spectral analysis; statistics; time series	MULTIVARIATE STOCHASTIC PROCESSES; PREDICTION THEORY; TOEPLITZ-SYSTEMS; PRECONDITIONERS	Probabilistic graphical models can be extended to time series by considering probabilistic dependencies between entire time series. For stationary Gaussian time series, the graphical model semantics can be expressed naturally in the frequency domain, leading to interesting families of structured time series models that are complementary to families defined in the time domain. In this paper, we present an algorithm to learn the structure from data for directed graphical models for stationary Gaussian time series. We describe an algorithm for efficient forecasting for stationary Gaussian time series whose spectral densities factorize in a graphical model. We also explore the relationships between graphical model structure and sparsity, comparing and contrasting the notions of sparsity in the time domain and the frequency domain. Finally, we show how to make use of Mercer kernels in this setting, allowing our ideas to be extended to nonlinear models.	Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94114 USA; Univ Calif Berkeley, Dept Stat, Berkeley, CA 94114 USA	Bach, FR (reprint author), Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94114 USA.	fbach@cs.berkeley.edu					BACH F, 2003, ADV NEURAL INFORM PR, V15; Bloomfield P., 2000, FOURIER ANAL TIME SE; Brillinger D., 1996, REV ECONOMETRICA, V16, P1; Brillinger D R, 2001, TIME SERIES DATA ANA; Brockwell P. J., 1991, TIME SERIES THEORY M; CHAN RH, 1991, IMA J NUMER ANAL, V11, P333, DOI 10.1093/imanum/11.3.333; Chan RH, 1996, SIAM REV, V38, P427, DOI 10.1137/S0036144594276474; CHAN RH, 1993, SIAM J NUMER ANAL, V30, P1740, DOI 10.1137/0730089; Chickering D., 1996, LEARNING DATA ARTIFI; Cover T. M., 1991, ELEMENTS INFORMATION; Dahlhaus R, 2000, METRIKA, V51, P157, DOI 10.1007/s001840000055; Dean T., 1989, Computational Intelligence, V5, DOI 10.1111/j.1467-8640.1989.tb00324.x; FRIEDMAN N, 1998, LEARNING GRAPHICAL M; GEIGER D, 1994, P UNCERTAINTY ARTIFI; Giudici P, 2003, MACH LEARN, V50, P127, DOI 10.1023/A:1020202028934; Golub G.N., 1996, MATRIX COMPUTATIONS; Gray R. M., 2002, TOEPLITZ CIRCULANT M; Hannan E. J, 1970, MULTIPLE TIME SERIES; Hastie T., 2001, ELEMENTS STAT LEARNI; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; JORDAN MI, 2003, IN PRESS STAT SCI; KAZAKOS D, 1980, IEEE T AUTOMAT CONTR, V25, P950, DOI 10.1109/TAC.1980.1102475; Lam W., 1994, COMPUT INTELL, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x; Lauritzen S.L, 1996, GRAPHICAL MODELS; MURPHY K, 2002, THESIS COMPUT SCI DI, V5; PARZEN E, 1983, TIME SERIES ANAL IRR; Richardson TJ, 2001, IEEE T INFORM THEORY, V47, P599, DOI 10.1109/18.910577; Scholkopf B., 2001, LEARNING KERNELS; SHACHTER RD, 1989, MANAGE SCI, V35, P527, DOI 10.1287/mnsc.35.5.527; SPEED TP, 1986, ANN STAT, V14, P138, DOI 10.1214/aos/1176349846; WESTON J, 2003, ADV NIPS, V15; WIENER N, 1958, ACTA MATH-DJURSHOLM, V99, P93, DOI 10.1007/BF02392423; WIENER N, 1957, ACTA MATH-DJURSHOLM, V98, P111, DOI 10.1007/BF02404472	33	17	17	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1053-587X			IEEE T SIGNAL PROCES	IEEE Trans. Signal Process.	AUG	2004	52	8					2189	2199		10.1109/TSP.2004.831032		11	Engineering, Electrical & Electronic	Engineering	839CI	WOS:000222760500005		
J	Deng, G				Deng, G			Iterative learning algorithms for linear Gaussian observation models	IEEE TRANSACTIONS ON SIGNAL PROCESSING			English	Article						adaptive prediction; denoising; hyperparameters; iterative algorithm; supervised learning	WAVELET APPROXIMATIONS; IMAGE-RESTORATION; NATURAL IMAGES; REGULARIZATION; COMPRESSION; DISCUSSION/	In this paper, we consider a signal/parameter estimation problem that is based on a linear model structure and a given setting of statistical models with unknown hyperparameters. We consider several combinations of Gaussian and Laplacian models. We develop iterative algorithms based on two typical machine learning methods-the evidence-based method and the integration-based method-to deal with the hyperparameters. We have applied the proposed algorithms to adaptive prediction and wavelet denoising. In linear prediction, we show that the proposed algorithms are efficient tools for tackling a difficult problem of adapting simultaneously the. order and the coefficients of the predictor. In wavelet denoising, we show that by using the proposed algorithms, the noisy wavelet coefficients are subject to shrinkage and thresholding.	La Trobe Univ, Dept Elect Engn, Bundoora, Vic 3083, Australia	Deng, G (reprint author), La Trobe Univ, Dept Elect Engn, Bundoora, Vic 3083, Australia.	d.deng@latrobe.edu.au					Antoniadis A, 2001, J AM STAT ASSOC, V96, P939, DOI 10.1198/016214501753208942; ARCHER G, 1995, IEEE T IMAGE PROCESS, V4, P989, DOI 10.1109/83.392339; Besag J., 1989, J APPL STAT, V16, P395, DOI 10.1080/02664768900000049; BISHOP C.M., 1995, NEURAL NETWORKS PATT; Bloomfield P., 1983, LEAST ABSOLUTE DEVIA; Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633; Chen S. S., 1995, THESIS STANFORD U ST; Combettes PL, 2002, IEEE T IMAGE PROCESS, V11, P1295, DOI 10.1109/TIP.2002.804527; DIAS J, 2003, IEEE INT C IMAGE PRO, V2, P961; Figueiredo MAT, 2003, IEEE T IMAGE PROCESS, V12, P906, DOI 10.1109/TIP.2003.814255; Figueiredo MAT, 2001, IEEE T IMAGE PROCESS, V10, P1322, DOI 10.1109/83.941856; Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Galatsanos NP, 1992, IEEE T IMAGE PROCESS, V1, P322, DOI 10.1109/83.148606; Gonin R., 1989, NONLINEAR LP NORM ES; GRANDVALET Y, 1998, P 8 INT C ART NEUR N, P201; Hastie T., 2001, ELEMENTS STAT LEARNI; KASS RE, 1994, 583 CARN MELL U; Kay S.M., 1993, FUNDAMENTALS STAT SI; Lewicki MS, 1999, J OPT SOC AM A, V16, P1587, DOI 10.1364/JOSAA.16.001587; Li X, 2001, IEEE T IMAGE PROCESS, V10, P813; MacKay D, 1994, ASHRAE T, V100, P1053; MacKay DJC, 1999, NEURAL COMPUT, V11, P1035, DOI 10.1162/089976699300016331; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.415; Mackay DJC, 1995, ENSEMBLE LEARNING EV; Meyer B., 2001, Proceedings DCC 2001. Data Compression Conference; Moulin P, 2001, J AM STAT ASSOC, V96, P959; Moulin P, 1999, IEEE T INFORM THEORY, V45, P909, DOI 10.1109/18.761332; NIKOLOVA M, 2003, SIAM J APPL MATH, V12, P906; Nikolova M, 2000, SIAM J APPL MATH, V61, P633, DOI 10.1137/S0036139997327794; NIKOLOVA M, 1996, P IEEE INT C IM PROC, V2, P457; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; OLSHAUSEN BA, 2000, P NEUR INF PROC SYST, P887; Portilla J., 2001, P IEEE INT C IM PROC, V2, P37, DOI 10.1109/ICIP.2001.958418; SILIA DS, 1996, DATA ANAL BAYESIAN T; Simoncelli E. P., 1999, BAYESIAN INFERENCE W, V141, p291 ; TIBSHIRANI R, 1995, J R STAT SOC B, V57, P257; Vidakovic B, 2001, J AM STAT ASSOC, V96, P956; WILLIAMS TF, 1995, AGING-CLIN EXP RES, V7, P1; Yang R., 1996, CATALOG NONINFORMATI	39	4	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1053-587X			IEEE T SIGNAL PROCES	IEEE Trans. Signal Process.	AUG	2004	52	8					2286	2297		10.1109/TSP.2004.830984		12	Engineering, Electrical & Electronic	Engineering	839CI	WOS:000222760500013		
J	Schettini, R; Brambilla, C; Cusano, C; Ciocca, G				Schettini, R; Brambilla, C; Cusano, C; Ciocca, G			Automatic classification of digital photographs based on decision forests	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article						CART; decision forest; digital images; image classification; low-level features	IMAGE CLASSIFICATION; RETRIEVAL	Annotating photographs with broad semantic labels can be useful in both image processing and content-based image retrieval. We show here how low-level features can be related to semantic photo categories, such as indoor, outdoor and close-up, using decision forests consisting of trees constructed according to CART methodology. We also show how the results can be improved by introducing a rejection option in the classification process. Experimental results on a test set of 4,500 photographs are reported and discussed.	Univ Milano Bicocca, DISCo, I-20126 Milan, Italy; IMATI, CNR, I-20133 Milan, Italy; ITC, CNR, I-20133 Milan, Italy	Schettini, R (reprint author), Univ Milano Bicocca, DISCo, Via Bicocca Arcimboldi 8, I-20126 Milan, Italy.	schettini@disco.unimib.it					AMADASUN M, 1989, IEEE T SYST MAN CYB, V19, P1264, DOI 10.1109/21.44046; Athitsos V., 1997, Proceedings. IEEE Workshop on Content-Based Access of Image and Video Libraries (Cat. No.97TB100175), DOI 10.1109/IVL.1997.629715; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L., 1984, CLASSIFICATION REGRE; Buhlmann P, 2002, ANN STAT, V30, P927; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679; Ciocca G, 1999, INFORM PROCESS MANAG, V35, P605, DOI 10.1016/S0306-4573(99)00021-7; Dietterich T., 2000, LECT NOTES COMPUTER, P1; FISCHER S, 2001, LECT NOTES ARTIF INT, P173; Gagliardi I., 1997, New Review of Hypermedia and Multimedia, V3, DOI 10.1080/13614569708914690; Gasparini F, 2002, P SOC PHOTO-OPT INS, V4672, P280; GEVERS T, 2000, IEEET IMAG PROCESS, V19, P102; HAND D.J., 1997, CONSTRUCTION ASSESSM; Hastie T., 2001, ELEMENTS STAT LEARNI; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Idris F, 1997, J VISUAL LANG COMPUT, V8, P289, DOI 10.1006/jvlc.1997.0041; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Lienhart R, 2002, J ELECTRON IMAGING, V11, P445, DOI 10.1117/1.1502259; McLachlan G., 1992, DISCRIMINANT ANAL ST; MIYAKE Y, 1990, J IMAGING TECHNOL, V16, P165; Rui Y, 1998, INT CONF ACOUST SPEE, P3785; Schettini R, 2002, PATTERN RECOGN, V35, P1759, DOI 10.1016/S0031-3203(01)00168-6; SCHETTINI R, 2001, P 1 INT WORKSH PATT, P161; Schettini R, 2001, COLOR IMAGING SCI EX, P183; SCHEUNDERS P, 1997, WAVELET BASED TEXTUR; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Stricker M, 1997, MACH VISION APPL, V10, P66, DOI 10.1007/s001380050060; Stricker M, 1996, P SOC PHOTO-OPT INS, V2670, P29, DOI 10.1117/12.234802; Stricker M., 1995, Proceedings of the SPIE - The International Society for Optical Engineering, V2420, DOI 10.1117/12.205308; Szummer M., 1998, Proceedings. 1998 IEEE International Workshop on Content-Based Access of Image and Video Database (Cat. No.98EX125), DOI 10.1109/CAIVD.1998.646032; VAILAYA A, 2000, 15 INT C PATT REC BA; Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448; Vailaya A, 1998, PATTERN RECOGN, V31, P1921, DOI 10.1016/S0031-3203(98)00079-X; YIU EC, 1996, THESIS MIT	34	20	21	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014			INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	AUG	2004	18	5					819	845		10.1142/S0218001404003435		27	Computer Science, Artificial Intelligence	Computer Science	857ZM	WOS:000224159700005		
J	Estivill-Castro, V; Lee, IJ				Estivill-Castro, V; Lee, IJ			Clustering with obstacles for geographical data mining	ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING			English	Article						large spatial databases; geographical data mining; clustering; delaunay triangulation; association analysis	SPATIAL DATA; PATTERNS; DISCOVERY; BOUNDARY; GESTALT	Clustering algorithms typically use the Euclidean distance. However, spatial proximity is dependent on obstacles, caused by related information in other layers of the spatial database. We present a clustering algorithm suitable for large spatial databases with obstacles. The algorithm is free of user-supplied arguments and incorporates global and local variations. The algorithm detects clusters in complex scenarios and successfully supports association analysis between layers. All this occurs within O(n log n+[s + t] log n) expected time, where n is the number of points, s is the number of line segments that determine the obstacles and t is the number of Delaunay edges intersecting the obstacles. (C) 2004 Elsevier B.V. All rights reserved.	Griffith Univ, Sch Comp & Informat Technol, Brisbane, Qld 4111, Australia; James Cook Univ N Queensland, Sch Informat Technol, Townsville, Qld 4181, Australia	Estivill-Castro, V (reprint author), Griffith Univ, Sch Comp & Informat Technol, Nathan Campus, Brisbane, Qld 4111, Australia.	v.estivill-castro@griffith.edu.au					Aho A.V., 1974, DESIGN ANAL COMPUTER; AHUJA N, 1989, COMPUT VISION GRAPH, V48, P304, DOI 10.1016/0734-189X(89)90146-1; Bezdek JC, 1981, PATTERN RECOGNITION; CELEUX G, 1995, PATTERN RECOGN, V28, P781, DOI 10.1016/0031-3203(94)00125-6; Cherkassky V., 1998, LEARNING DATA CONCEP; Eldershaw C., 1997, P COMP TECHN APPL CT, P201; Ester M., 1996, P 2 INT C KNOWL DISC, P226; ESTIVILLCASTRO V, 1999, LECT NOTES COMPUTER, V1574, P327; ESTIVILLCASTRO V, 2001, LECT NOTES COMPUTER, V2007, P133; ESTIVILLCASTRO V, 2001, P 6 INT C GEOC U QUE; Estivill-Castro V., 2002, SIGKDD EXPLORATIONS, V4, P65; Estivill-Castro V., 2002, Computers, Environment and Urban Systems, V26, DOI 10.1016/S0198-9715(01)00044-8; Estivill-Castro V, 1998, LECT NOTES ARTIF INT, V1394, P110; ESTIVILLCASTRO V, 2000, LECT NOTES ARTIF INT, V1886, P424; Estivill-Castro V, 2002, GEOINFORMATICA, V6, P123, DOI 10.1023/A:1015279009755; Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578; Gold C. M., 1991, CISM J ACSGC, V45, P65; GOLD CM, 1992, LECT NOTES COMPUT SC, V639, P220; Grabmeier J, 2002, DATA MIN KNOWL DISC, V6, P303, DOI 10.1023/A:1016308404627; Guha S., 1998, P 1998 ACM SIGMOD IN, V27, P73; Hastie T., 2001, ELEMENTS STAT LEARNI; Kang I., 1997, P 5 INT WORKSH ADV G, P35, DOI 10.1145/267825.267836; Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637; KEIL M, 1989, LECT NOTES COMPUTER, V382, P47; Knorr EM, 1997, LECT NOTES COMPUT SC, V1262, P29; Koperski K, 1995, LECT NOTES COMPUT SC, V951, P47; Kuhn H W, 1973, MATH PROGRAM, V4, P98, DOI 10.1007/BF01584648; LEE I, 2001, P 3 INT S COOP DAT S, P87; LIOTTA G, 1996, 9628 BROWN U DEP COM; MILLER H, 2001, RES MONOGRAPHS GEOGR; Murray AT, 1998, INT J GEOGR INF SCI, V12, P431; Ng R., 1994, P 20 INT C VER LARG, P144; OPENSHAW S, 1999, P 4 GEOC 99; Openshaw S., 1999, GEOGRAPHICAL INFORMA, V1, P267; Openshaw S, 1994, SPATIAL ANAL GIS, P83; Openshaw S, 1987, INT J GEOGR INF SYST, V1, P335, DOI 10.1080/02693798708927821; POSSE C, 1999, 363 U WASH DEP STAT; Rousseeuw P., 1987, ROBUST REGRESSION OU; Schikuta E, 1997, LECT NOTES COMPUT SC, V1280, P513; Shekhar S, 2001, LECT NOTES COMPUT SC, V2121, P236; SON EJ, 1998, P 6 INT S ADV GEOGR, P157, DOI 10.1145/288692.288720; Tsoukatos I, 2001, LECT NOTES COMPUT SC, V2121, P425; Tung AKH, 2001, PROC INT CONF DATA, P359, DOI 10.1109/ICDE.2001.914848; Tung AKH, 2000, LECT NOTES ARTIF INT, V1805, P165; Veloso M, 1998, AI MAG, V19, P61; WANG W, 1997, P 23 INT C VER LARG, P186; Wang W, 1999, PROC INT CONF DATA, P116; Witten IH, 2000, DATA MINING PRACTICA; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083; Zhang T, 1996, SIGMOD REC, V25, P103	50	5	7	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0924-2716			ISPRS J PHOTOGRAMM	ISPRS-J. Photogramm. Remote Sens.	AUG	2004	59	1-2					21	34		10.1016/j.isprsjprs.2003.12.003		14	Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology	Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology	843WF	WOS:000223116800003		
J	Gamberger, D; Lavrac, N; Zelezny, F; Tolar, J				Gamberger, D; Lavrac, N; Zelezny, F; Tolar, J			Induction of comprehensible models for gene expression datasets by subgroup discovery methodology	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						gene expression measurements; disease markers; subgroup discovery; machine learning; comprehensible classification	ACUTE MYELOID-LEUKEMIA; ACUTE LYMPHOBLASTIC-LEUKEMIA; PROSTAGLANDIN-D SYNTHASE; COMPLEMENT PROTEIN-D; LEPTIN RECEPTOR; SERUM-LEVELS; U937 CELLS; CANCER; INTERLEUKIN-18; INFANT	Finding disease markers (classifiers) from gene expression data by machine learning algorithms is characterized by a high risk of overfitting the data due the abundance of attributes (simultaneously measured gene expression values) and shortage of available examples (observations). To avoid this pitfall and achieve predictor robustness, state-of-the-art approaches construct complex classifiers that combine relatively weak contributions of up to thousands of genes (attributes) to classify a disease. The complexity of such classifiers limits their transparency and consequently the biological insights they can provide. The goal of this study is to apply to this domain the methodology of constructing simple yet robust logic-based classifiers amenable to direct expert interpretation. On two well-known, publicly available gene expression classification problems, the paper shows the feasibility of this approach, employing a recently developed subgroup discovery methodology. Some of the discovered classifiers allow for novel biological interpretations. (C) 2004 Elsevier Inc. All rights reserved.	Rudjer Boskovic Inst, Informat Syst Lab, Zagreb 10000, Croatia; Jozef Stefan Inst, Dept Knowledge Technol, Zagreb 1000, Croatia; Nova Gorica Polytech Vipavska 13, Nova Gorica 5000, Slovenia; Czech Tech Univ, FEL, Dept Cybernet, Prague 16627, Czech Republic; Univ Wisconsin, Sch Med, Dept Biostat, Madison, WI 53706 USA; Univ Minnesota, Sch Med, Inst Human Genet, Minneapolis, MN 55455 USA	Gamberger, D (reprint author), Rudjer Boskovic Inst, Informat Syst Lab, Bijenicka 54, Zagreb 10000, Croatia.	dragan.gamberger@irb.hr; nada.lavrac@ijs.si; zelezny@fel.cvut.cz; tolar003@umn.edu	Zelezny, Filip/B-1671-2008; Gamberger, Dragan/J-3752-2012				Abbott RT, 2003, MODERN PATHOL, V16, P607, DOI 10.1097/01.MP.0000067423.83712.74; Agrawal R., 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Amo Y, 2001, BRIT J DERMATOL, V145, P674, DOI 10.1046/j.1365-2133.2001.04420.x; Balasubramaniyan V, 2003, PHARMACOL RES, V47, P211, DOI 10.1016/S1043-6618(02)00317-1; BARNUM SR, 1985, J IMMUNOL, V134, P1799; BARNUM SR, 1985, EUR J IMMUNOL, V15, P1148, DOI 10.1002/eji.1830151115; BARNUM SR, 1992, BIOCHEM J, V287, P595; Borkhardt A, 2001, GENE CHROMOSOME CANC, V32, P82, DOI 10.1002/gcc.1169; Chow ML, 2001, PHYSIOL GENOMICS, V5, P99; Cianflone K, 2003, BBA-BIOMEMBRANES, V1609, P127, DOI 10.1016/S0005-2736(02)00686-7; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; CohenSalmon M, 1997, MAMM GENOME, V8, P349, DOI 10.1007/s003359900438; Deo RC, 2004, EMBO J, V23, P9, DOI 10.1038/sj.emboj.7600021; Domingos P, 1999, DATA MIN KNOWL DISC, V3, P409, DOI 10.1023/A:1009868929893; DUDOIT S, 2000, 576 U CAL BERK; Fantuzzi G, 2000, J LEUKOCYTE BIOL, V68, P437; Fu JF, 2003, GENE CHROMOSOME CANC, V38, P253, DOI 10.1002/gcc.10272; Furnkranz J, 1999, ARTIF INTELL REV, V13, P3, DOI 10.1023/A:1006524209794; Gamberger D., 2002, J ARTIF INTELL RES, V17, P501; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hastie T., 2001, ELEMENTS STAT LEARNI; Hino M, 2000, LEUKEMIA LYMPHOMA, V36, P457, DOI 10.3109/10428190009148392; Hsing T, 2003, MACH LEARN, V52, P11, DOI 10.1023/A:1023985022691; Iversen PO, 2002, BLOOD, V100, P4123, DOI 10.1182/blood-2001-11-0134; Jovanoski V., 2001, P 10 PORT C ART INT, P44; Kawashima M, 2001, MODERN PATHOL, V14, P197, DOI 10.1038/modpathol.3880285; Kearns PR, 2003, BRIT J HAEMATOL, V120, P80, DOI 10.1046/j.1365-2141.2003.04039.x; Kelner MJ, 1996, GENOMICS, V36, P100, DOI 10.1006/geno.1996.0429; Kim HJ, 2003, GENE CHROMOSOME CANC, V38, P8, DOI 10.1002/gcc.10235; Kitano E, 2002, INT IMMUNOPHARMACOL, V2, P843, DOI 10.1016/S1567-5769(02)00028-0; KLSGEN W, 1996, EXPLORA MULIPATTERN; Konopleva M, 1999, BLOOD, V93, P1668; Krajinovic M, 2002, PHARMACOGENETICS, V12, P655, DOI 10.1097/00008571-200211000-00010; LAVRAC N, 1997, IEEE INTELL SYST APP, V13, P50; Li J, 2002, SER INF MANAGE SCI, V1, P325; Liu H., 1998, FEATURE SELECTION KN; Merendino RA, 2001, INT J BIOL MARKER, V16, P126; Michalski R. S., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; Mitchell T., 1997, MACHINE LEARNING; Molla M, 2004, AI MAG, V25, P23; Mukobata S, 2002, BIOCHEM BIOPH RES CO, V297, P722, DOI 10.1016/S0006-291X(02)02284-2; Ohtsuki T, 1997, ANTICANCER RES, V17, P3253; OKAMURA H, 1995, NATURE, V378, P88, DOI 10.1038/378088a0; Ono R, 2002, CANCER RES, V62, P333; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; SCHAFFER C, 1993, MACH LEARN, V10, P153, DOI 10.1007/BF00993504; Slater DJ, 2002, ONCOGENE, V21, P4706, DOI 10.1038/sj.onc.1205572; Stankovic T, 2002, LEUKEMIA LYMPHOMA, V43, P1563, DOI 10.1080/1042819021000002884; Steele TA, 2002, LEUKEMIA RES, V26, P411, DOI 10.1016/S0145-2126(01)00138-2; Su B, 2001, CLIN CHEM LAB MED, V39, P1198, DOI 10.1515/CCLM.2001.190; Takada H, 1999, BRIT J HAEMATOL, V106, P182, DOI 10.1046/j.1365-2141.1999.01504.x; Taniguchi M, 1997, J IMMUNOL METHODS, V206, P107, DOI 10.1016/S0022-1759(97)00094-X; Voso MT, 2002, BLOOD, V100, P2703, DOI 10.1182/blood.V100.8.2703; Wrobel S, 1997, LECT NOTES ARTIF INT, V1263, P78; Xu Q, 2003, BLOOD, V102, P972, DOI 10.1182/blood-2002-11-3429; YAN YM, 1993, NEURON, V11, P423, DOI 10.1016/0896-6273(93)90147-J; Zhang B, 2002, LEUKEMIA RES, V26, P887, DOI 10.1016/S0145-2126(02)00025-5; Zhang B, 2003, LEUKEMIA RES, V27, P813, DOI 10.1016/S0145-2126(03)00005-5; Zhong B, 2002, IMMUNOBIOLOGY, V205, P74, DOI 10.1078/0171-2985-00112	59	21	21	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464			J BIOMED INFORM	J. Biomed. Inform.	AUG	2004	37	4					269	284		10.1016/j.jbi.2004.07.007		16	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	863VZ	WOS:000224592800006	15465480	
J	Rosset, S; Ji, Z; Hastie, T				Rosset, S; Ji, Z; Hastie, T			Boosting as a regularized path to a maximum margin classifier	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						boosting; regularized optimization; support vector machines; margin maximization		In this paper we study boosting methods from a new perspective. We build on recent work by Efron et al. to show that boosting approximately (and in some cases exactly) minimizes its loss criterion with an l(1) constraint on the coefficient vector. This helps understand the success of boosting with early stopping as regularized fitting of the loss criterion. For the two most commonly used criteria (exponential and binomial log-likelihood), we further show that as the constraint is relaxed-or equivalently as the boosting iterations proceed - the solution converges (in the separable case) to an '' l(1)-optimal '' separating hyper- plane. We prove that this l(1)-optimal separating hyper- plane has the property of maximizing the minimal l(1)-margin of the training data, as defined in the boosting literature. An interesting fundamental similarity between boosting and kernel support vector machines emerges, as both can be described as methods for regularized optimization in high-dimensional predictor space, using a computational trick to make the calculation practical, and converging to margin-maximizing solutions. While this statement describes SVMs exactly, it applies to boosting only approximately.	IBM Corp, TJ Watson Res Ctr, Data Analyt Res Grp, Yorktown Hts, NY 10598 USA; Univ Michigan, Dept Stat, Ann Arbor, MI 48109 USA; Stanford Univ, Dept Stat, Stanford, CA 94305 USA	Rosset, S (reprint author), IBM Corp, TJ Watson Res Ctr, Data Analyt Res Grp, Yorktown Hts, NY 10598 USA.	SROSSET@US.IBM.COM; JIZHU@UMICH.EDU; HASTIE@STAT.STANFORD.EDU					Blake C., 1998, REPOSITORY MACHINE L; Breiman L, 1999, NEURAL COMPUT, V11, P1493, DOI 10.1162/089976699300016106; Collins M., 2000, COMPUTATIONAL LEARNI, P158; DONOHO DL, 1995, J ROY STAT SOC B MET, V57, P301; Efron B., 2004, ANN STAT, P32; Freund Y., 1995, EUR C COMP LEARN THE, P23; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman J. H., 2001, ANN STAT, V29; Hastie T., 2001, ELEMENTS STAT LEARNI; Mangasarian OL, 1999, OPER RES LETT, V24, P15, DOI 10.1016/S0167-6377(98)00049-2; MASON L, 1999, NEURAL INFORM PROCES, V12; RATSCH G, 2002, UNPUB JMLR       DEC; RATSCH G, 2001, NEUROCOLT2 TECHNICAL; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; ROSSET S, 2003, NIPS02; Schapire RE, 1998, ANN STAT, V26, P1651; ZHANG T, 2003, IEEE T INFORM THEORY, V49; ZHANG T, 2003, BOOSTING EARLY STOPP	18	62	65	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	AUG	2004	5						941	973				33	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026GS	WOS:000236328000004		
J	Christmann, A; Steinwart, I				Christmann, A; Steinwart, I			On robustness properties of convex risk minimization methods for pattern recognition	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						AdaBoost loss function; influence function; kernel logistic regression; robustness; sensitivity curve; statistical learning; support vector machine; total variation	SUPPORT VECTOR MACHINES; LOGISTIC-REGRESSION; SQUARES; DEPTH	The paper brings together methods from two disciplines: machine learning theory and robust statistics. We argue that robustness is an important aspect and we show that many existing machine learning methods based on the convex risk minimization principle have besides other good properties also the advantage of being robust. Robustness properties of machine learning methods based on convex risk minimization are investigated for the problem of pattern recognition. Assumptions are given for the existence of the influence function of the classifiers and for bounds on the influence function. Kernel logistic regression, support vector machines, least squares and the AdaBoost loss function are treated as special cases. Some results on the robustness of such methods are also obtained for the sensitivity curve and the maxbias, which are two other robustness criteria. A sensitivity analysis of the support vector machine is given.	Univ Dortmund, Dept Stat, D-44221 Dortmund, Germany; Los Alamos Natl Lab, Modeling Algorithms & Informat Grp, Los Alamos, NM 87545 USA	Christmann, A (reprint author), Univ Dortmund, Dept Stat, D-44221 Dortmund, Germany.	CHRISTMANN@STATISTIK.UNI-DORTMUND.DE; INGO@LANL.GOV					Akerkar R., 1999, NONLINEAR FUNCTIONAL; Bartlett P. L., 2003, J MACHINE LEARNING R, V3, P463; Bartlett P. L., 2003, CONVEXITY CLASSIFICA; BARTLETT PL, 2002, LOCAL RADEMACHER COM; Bauer H., 1990, MASS INTEGRATIONSTHE; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; Brown A., 1977, INTRO OPERATOR THEOR; CHEN DR, 2003, SUPPORT VECTOR MACHI; CHENEY W., 2001, ANAL APPL MATH; CHRISTMANN A, 1994, BIOMETRIKA, V81, P413, DOI 10.1093/biomet/81.2.413; CHRISTMANN A, 1998, THESIS U DORTMUND; Christmann A, 2001, COMPUT STAT DATA AN, V37, P65, DOI 10.1016/S0167-9473(00)00063-3; Christmann A, 2002, COMPUTATION STAT, V17, P273, DOI 10.1007/s001800200106; CHRISTMANN A, 2004, 1604 U DORTM; Diestel J., 1977, VECTOR MEASURES; Donohos DL, 1983, FESTSCHRIFT EL LEHMA, P157; Dudley R. M., 2002, REAL ANAL PROBABILIT; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Hampel F., 1986, ROBUST STAT APPROACH; HAMPEL FR, 1974, J AM STAT ASSOC, V69, P383, DOI 10.2307/2285666; Hand David J, 2001, PRINCIPLES DATA MINI; Hastie T., 2001, ELEMENTS STAT LEARNI; HIPP J, WORKSH RES ISS DAT M; HOFFGEN KU, 1995, J COMPUT SYST SCI, V50, P114, DOI 10.1006/jcss.1995.1011; Huber P., 1981, ROBUST STAT; HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732; Joachims T, 1999, ADV KERNEL METHODS S, P41; Lindenstrauss J, 1977, CLASSICAL BANACH SPA; Pedersen G.K., 1989, ANAL NOW; Rieder H, 1994, ROBUST ASYMPTOTIC ST; Rousseeuw PJ, 1999, J AM STAT ASSOC, V94, P388, DOI 10.2307/2670155; Scholkopf B., 2002, LEARNING KERNELS SUP; SCOVEL JC, 2003, LAUR039117; STEINWART I, 2004, IN PRESS P NEUR INF; Steinwart I., 2001, J MACHINE LEARNING R, V2, P67, DOI 10.1162/153244302760185252; Steinwart I, 2002, J COMPLEXITY, V18, P768, DOI 10.1006/jcom.2002.0642; STEINWART I, 2002, IN PRESS IEEE T INFO; Steinwart Ingo, 2003, J MACHINE LEARNING R, V4, P1071, DOI 10.1162/jmlr.2003.4.6.1071; Suykens JAK, 2002, NEUROCOMPUTING, V48, P85, DOI 10.1016/S0925-2312(01)00644-0; Tsybakov AB, 2004, ANN STAT, V32, P135; Tukey J.W., 1977, EXPLORATORY DATA ANA; Vapnik V., 1998, STAT LEARNING THEORY; Vayatis N, 2003, J MACHINE LEARNING R, V4, P861; Wahba G, 1999, ADVANCES IN KERNEL METHODS, P69; Yosida K., 1974, FUNCTIONAL ANAL; Zeidler E., 1986, NONLINEAR FUNCTIONAL; Zhang T, 2004, ANN STAT, V32, P56	48	27	28	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	AUG	2004	5						1007	1034				28	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026GS	WOS:000236328000006		
J	Lee, JM; Yoo, CK; Lee, IB				Lee, JM; Yoo, CK; Lee, IB			Statistical process monitoring with independent component analysis	JOURNAL OF PROCESS CONTROL			English	Article						process monitoring; fault detection; independent component analysis; kernel density estimation; wastewater treatment process	DISTURBANCE DETECTION; CONTRIBUTION PLOTS; FAULT-DETECTION; ALGORITHMS; DIAGNOSIS; PCA	In this paper we propose a new statistical method for process monitoring that uses independent component analysis (ICA). ICA is a recently developed method in which the goal is to decompose observed data into linear combinations of statistically independent components [1,2]. Such a representation has been shown to capture the essential structure of the data in many applications, including signal separation and feature extraction. The basic idea of our approach is to use ICA to extract the essential independent components that drive a process and to combine them with process monitoring techniques. I-2, I-e(2) and SPE charts are proposed as on-line monitoring charts and contribution plots of these statistical quantities are also considered for fault identification. The proposed monitoring method was applied to fault detection and identification in both a simple multivariate process and the simulation benchmark of the biological wastewater treatment process, which is characterized by a variety of fault sources with non-Gaussian characteristics. The simulation results clearly show the power and advantages of ICA monitoring in comparison to PCA monitoring. (C) 2003 Elsevier Ltd. All rights reserved.	Pohang Univ Sci & Technol, Dept Chem Engn, Pohang 790784, South Korea; State Univ Ghent, BIOMATH, B-9000 Ghent, Belgium	Lee, IB (reprint author), Pohang Univ Sci & Technol, Dept Chem Engn, San 31 Hyoja Dong, Pohang 790784, South Korea.	iblee@postech.edu					Back AD, 1997, INT J NEURAL SYST, V8, P473, DOI 10.1142/S0129065797000458; Bakshi BR, 1998, AICHE J, V44, P1596, DOI 10.1002/aic.690440712; Cardoso JF, 1998, P IEEE, V86, P2009, DOI 10.1109/5.720250; CARDOSO JF, 1993, IEE PROC-F, V140, P362; Chen Q, 2000, CONTROL ENG PRACT, V8, P531, DOI 10.1016/S0967-0661(99)00191-4; Cheung YM, 2001, NEUROCOMPUTING, V41, P145, DOI 10.1016/S0925-2312(00)00358-1; CHEUNG YM, 1999, P INT JOINT C NEUR N, P3883; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; Dong D, 1996, COMPUT CHEM ENG, V20, P65, DOI 10.1016/0098-1354(95)00003-K; Hastie T., 2001, ELEMENTS STAT LEARNI; Hyvarinen A, 1999, IEEE T NEURAL NETWOR, V10, P626, DOI 10.1109/72.761722; Hyvarinen A, 1998, ADV NEUR IN, V10, P273; Hyvarinen A, 2001, INDEPENDENT COMPONEN; Hyvarinen A., 1999, NEURAL COMPUTING SUR, V2, P94; Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; JACKSON JE, 1979, TECHNOMETRICS, V21, P341, DOI 10.2307/1267757; Ku WF, 1995, CHEMOMETR INTELL LAB, V30, P179, DOI 10.1016/0169-7439(95)00076-3; Lee T.W., 1998, INDEPENDENT COMPONEN; Li RF, 2002, COMPUT CHEM ENG, V26, P467; Li WH, 2000, J PROCESS CONTR, V10, P471, DOI 10.1016/S0959-1524(00)00022-6; MACGREGOR JF, 1994, AICHE J, V40, P826, DOI 10.1002/aic.690400509; Martin EB, 1996, J PROCESS CONTR, V6, P349, DOI 10.1016/0959-1524(96)00010-8; NOMIKOS P, 1994, AICHE J, V40, P1361, DOI 10.1002/aic.690400809; PONS MN, 1999, ESCAPE, V9; Rosen C, 1998, WATER SCI TECHNOL, V37, P197, DOI 10.1016/S0273-1223(98)00372-2; ROSEN C, 1998, MONITORING WASTEWATE; Silverman BW, 1986, DENSITY ESTIMATION S; Simoglou A, 2002, COMPUT CHEM ENG, V26, P909, DOI 10.1016/S0098-1354(02)00012-1; Teppola P, 1998, CHEMOMETR INTELL LAB, V44, P307, DOI 10.1016/S0169-7439(98)00188-9; TEPPOLA P, 1999, THEIS LAPPEENRANTA U; Vigario RN, 1997, ELECTROEN CLIN NEURO, V103, P395, DOI 10.1016/S0013-4694(97)00042-8; Wand MP, 1995, KERNEL SMOOTHING; Westerhuis JA, 2000, CHEMOMETR INTELL LAB, V51, P95, DOI 10.1016/S0169-7439(00)00062-9; Wise BM, 1996, J PROCESS CONTR, V6, P329, DOI 10.1016/0959-1524(96)00009-1; Yoo CK, 2002, IND ENG CHEM RES, V41, P4303, DOI 10.1021/ie0105730; YOO CK, 2002, THESIS POSTECH KOREA	36	196	234	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0959-1524			J PROCESS CONTR	J. Process Control	AUG	2004	14	5					467	485		10.1016/j.jprocont.2003.09.004		19	Automation & Control Systems; Engineering, Chemical	Automation & Control Systems; Engineering	808DL	WOS:000220549700001		
J	Hansen, ME; Smedsgaard, J				Hansen, ME; Smedsgaard, J			A new matching algorithm for high resolution mass spectra	JOURNAL OF THE AMERICAN SOCIETY FOR MASS SPECTROMETRY			English	Article							COMPOUND IDENTIFICATION	We present a new matching algorithm designed to compare high-resolution spectra. Whereas existing methods are bound to compare fixed intervals of ion masses, the accurate mass spectrum (AMS) distance method presented here is independent of any alignment. Based on the Jeffreys-Matusitas (JM) distance, a difference between observed peaks across pairs of spectra can be calculated, and used to find a unique correspondence between the peaks. The method takes into account that there may be differences in resolution of the spectra. The algorithm is used for indexing in a database containing 80 accurate mass spectra from an analysis of extracts of 80 isolates representing the nine closely related species in the Penicillium series Viridicata. Using this algorithm we can obtain a retrieval performance of approximate to97-98% that is comparable with the best of the existing methods (e.g., the dot-product distance). Furthermore, the presented method is independent of any variable alignment procedures or binning. (C) 2004 American Society for Mass Spectrometry.	Tech Univ Denmark, Informat & Math Modeling, DK-2800 Lyngby, Denmark; Tech Univ Denmark, BioCentrum DTU, DK-2800 Lyngby, Denmark	Hansen, ME (reprint author), Tech Univ Denmark, Informat & Math Modeling, Richard Petersens Plads,Bldg 321, DK-2800 Lyngby, Denmark.	meh@biocentrum.dtu.dk	Hansen, Michael/C-9028-2011	Hansen, Michael/0000-0001-7879-2106			FRISVAD JC, IN PRESS STUDIES MYC; FUKANAGA K, 1990, INTRO PATTERN RECOGN, P103; GORDON AD, 1999, CLASSIFICATION, P15; GROTCH SL, 1971, ANAL CHEM, V43, P1362, DOI 10.1021/ac60305a015; HANSEN ME, UNPUB J AM SOC MASS; HASTIE T, 2002, ELEMENTS STAT LEARNI, P378; HERTZ HS, 1971, ANAL CHEM, V43, P681, DOI 10.1021/ac60301a009; KNOCK BA, 1970, ANAL CHEM, V42, P1516, DOI 10.1021/ac60295a035; MATUSITA K, 1956, ANN I STAT MATH, V8, P67, DOI 10.1007/BF02863571; MCLAFFER.FW, 1974, ORG MASS SPECTROM, V9, P690, DOI 10.1002/oms.1210090710; PITT JI, 1979, GENUS PENICILLIUM IT, P17; Roussopoulos N., 1995, P ACM SIGMOD INT C M, P71, DOI DOI 10.1145/223784.223794; SAMSON RA, 2000, INTRO FOOD AIRBORNE, P379; Smedsgaard J, 1997, J CHROMATOGR A, V760, P264, DOI 10.1016/S0021-9673(96)00803-5; Smedsgaard J, 1997, BIOCHEM SYST ECOL, V25, P65, DOI 10.1016/S0305-1978(96)00087-7; STEIN SE, 1995, J AM SOC MASS SPECTR, V6, P644, DOI 10.1016/1044-0305(95)00291-K; STEIN SE, 1994, J AM SOC MASS SPECTR, V5, P859, DOI 10.1016/1044-0305(94)87009-8; Wan KX, 2002, J AM SOC MASS SPECTR, V13, P85, DOI 10.1016/S1044-0305(01)00327-0	18	20	21	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	1044-0305			J AM SOC MASS SPECTR	J. Am. Soc. Mass Spectrom.	AUG	2004	15	8					1173	1180		10.1016/j.jasms.2004.03.008		8	Chemistry, Analytical; Chemistry, Physical; Spectroscopy	Chemistry; Spectroscopy	843AZ	WOS:000223048500007	15276164	
J	Camacho, F; Avolio, A; Lovell, NH				Camacho, F; Avolio, A; Lovell, NH			Estimation of pressure pulse amplification between aorta and brachial artery using stepwise multiple regression models	PHYSIOLOGICAL MEASUREMENT			English	Article; Proceedings Paper	World Congress on Medical Physics and Biomedical Engineering	AUG, 2003	Sydney, AUSTRALIA			pulse pressure amplification; linear regression model; central aortic blood pressure	DIASTOLIC BLOOD-PRESSURE; CARDIOVASCULAR RISK; WAVE; MEN	The pressure pulse is amplified between the aorta and peripheral sites. This study compares two methods to estimate pressure pulse amplification (PPA) between the aorta and the brachial artery. Method 1: PPA was determined from a multi-parameter linear regression of subject parameters (gender, age, height, weight, heart rate (HR), brachial systolic pressure (BSP), diastolic pressure (BDP), mean pressure (MP)). Method 2: PPA was calculated from central aortic pressure waveforms (CW) estimated from the same subject parameters. The sample population (1421 male, 992 female) was selected from a database where aortic pressure was estimated by mathematical transformation of a peripheral (radial) pulse calibrated to sphygmomanometric BSP and BDP. The two methods were consistent in showing HR and MP as the most important parameters to estimate PPA. Correlation coefficients (R-2) of 0.48 (method 1) and 0.44 (method 2) were obtained using height, weight, HR, BSP, BDP and age. Inclusion of MP increased R-2 to 0.77 (method 1) and 0.71 (method 2). This study shows that databases containing peripheral and central aortic pressure waveforms can be used to construct multiple regression models for PPA estimation. These models could be applied to studies of similar subject groups where peripheral waveforms may not be available.	Univ New S Wales, Grad Sch Biomed Engn, Sydney, NSW 2052, Australia	Camacho, F (reprint author), Univ New S Wales, Grad Sch Biomed Engn, Sydney, NSW 2052, Australia.	f.camacho@unsw.edu.au	Camacho, Fernando/K-9712-2014				Asmar R, 2001, AM J HYPERTENS, V14, P91, DOI 10.1016/S0895-7061(00)01232-2; Chemla D, 2002, CLIN SCI, V103, P7; Chen CH, 1997, CIRCULATION, V95, P1827; Draper N, 1981, APPL REGRESSION ANAL; Gerová Z, 1999, Bratisl Lek Listy, V100, P231; Glynn RJ, 2002, HYPERTENSION, V39, P105, DOI 10.1161/hy1201.097199; Hastie T., 2001, ELEMENTS STAT LEARNI; KARAMANOGLU M, 1993, EUR HEART J, V14, P160; KESTELOOT H, 1980, EPIDEMIOLOGY ARTERIA; Lehmann KG, 1998, AM J CARDIOL, V81, P1004, DOI 10.1016/S0002-9149(98)00080-0; Nichols WW, 1998, MCDONALDS BLOOD FLOW; Pauca AL, 2001, HYPERTENSION, V38, P932, DOI 10.1161/hy1001.096106; Sesso HD, 2000, HYPERTENSION, V36, P801; YAMAKOSHI K, 1982, MED BIOL ENG COMPUT, V20, P314, DOI 10.1007/BF02442798	14	10	10	IOP PUBLISHING LTD	BRISTOL	DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND	0967-3334			PHYSIOL MEAS	Physiol. Meas.	AUG	2004	25	4					879	889		10.1088/0967-3334/25/4/008		11	Biophysics; Engineering, Biomedical; Physiology	Biophysics; Engineering; Physiology	849QW	WOS:000223556600009	15382828	
J	Barnett, A				Barnett, A			CAPPS II: The foundation of aviation security?	RISK ANALYSIS			English	Article						air; air passenger security screening; computers; safety; security; transportation		A new computer system is being developed to classify U.S. air travelers by the degree of terrorist threat they might pose. Reports indicate that the system-called CAPPS II-would use large amounts of information about each passenger, perhaps including such personal details as his or her magazine-subscription behavior. We argue that what is publicly known about CAPPS II raises questions about how substantially the system would improve aviation security. We discuss conditions under which CAPPS II could yield safety benefits, but suggest that it might be more prudent to view the system as one component of future security arrangements rather than the centerpiece of these arrangements.	MIT, Sloan Sch Management, Ctr Operat Res, Cambridge, MA 02139 USA	Barnett, A (reprint author), MIT, Sloan Sch Management, Ctr Operat Res, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	abarnett@mit.edu					CAHKRABARTI S, 2002, 1 MONDAY, V7; Clymer Adam, 2003, NY TIMES, pA1; *COUNC FOR REL, 2002, TERR QUEST ANSW; Hastie T., 2001, ELEMENTS STAT LEARNI; O'Harrow Jr Robert, 2002, WASH POST       0201, pA1; OHARROW R, 2003, WASHINGTON POST 0301, pE1; OWENS MT, 2002, WALL STREET J, pA12; POWER S, 2002, WALL STREET J, pA4; TAYLOR S, 2002, NATL J	9	18	19	BLACKWELL PUBLISHERS	MALDEN	350 MAIN STREET, STE 6, MALDEN, MA 02148 USA	0272-4332			RISK ANAL	Risk Anal.	AUG	2004	24	4					909	916		10.1111/j.0272-4332.2004.00489.x		8	Public, Environmental & Occupational Health; Mathematics, Interdisciplinary Applications; Social Sciences, Mathematical Methods	Public, Environmental & Occupational Health; Mathematics; Mathematical Methods In Social Sciences	856OG	WOS:000224053900013	15357810	
J	Bickel, P; Madigan, D; Stuetzle, W; Markatou, M; Levin, B; Breiman, L; Nair, V				Bickel, P; Madigan, D; Stuetzle, W; Markatou, M; Levin, B; Breiman, L; Nair, V			A report on the future of statistics - Comment	STATISTICAL SCIENCE			English	Article									Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA	Bickel, P (reprint author), Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA.	bickel@stat.berkeley.edu; madigan@stat.rutgers.edu; wxs@stat.washington.edu; mm168@columbia.edu; bruce.levin@biostat.columbia.edu; leo@stat.Berkeley.edu; vnn@umich.edu					BICKEL PJ, 2000, 911 NAT SCI FDN DIV; Committee on Science Engineering and Public Policy, 1995, RESH GRAD ED SCI ENG; FRIEDE A, 1995, ANNU REV PUBL HEALTH, V16, P239; Hastie T., 2001, ELEMENTS STAT LEARNI; Nair V, 2000, J AM STAT ASSOC, V95, P1002, DOI 10.2307/2669486; OLKIN I, 1988, CROSS DISCIPLINARY R; Rao CR, 2001, COMMUN STAT-THEOR M, V30, P2235, DOI 10.1081/STA-100107683; Scholkopf B., 2002, LEARNING KERNELS SUP; Stoumbos ZG, 2000, J AM STAT ASSOC, V95, P992, DOI 10.2307/2669484	9	0	0	INST MATHEMATICAL STATISTICS	BEACHWOOD	PO BOX 22718, BEACHWOOD, OH 44122 USA	0883-4237			STAT SCI	Stat. Sci.	AUG	2004	19	3					407	413				7	Statistics & Probability	Mathematics	909TX	WOS:000227884700002		
J	Willmann, S; Schmitt, W; Keldenich, J; Lippert, J; Dressman, JB				Willmann, S; Schmitt, W; Keldenich, J; Lippert, J; Dressman, JB			A physiological model for the estimation of the fraction dose absorbed in humans	JOURNAL OF MEDICINAL CHEMISTRY			English	Article							ORAL-DRUG ABSORPTION; SUPPORTED LIPID-MEMBRANES; CACO-2 CELL MONOLAYERS; INTESTINAL-ABSORPTION; GASTROINTESTINAL ABSORPTION; SIMULATION-MODELS; P-GLYCOPROTEIN; LINE CACO-2; IN-VITRO; PREDICTION	A physiologically based model for gastrointestinal transit and absorption in humans is presented. The model can be used to study the dependency of the fraction dose absorbed (F-abs) of both neutral and ionizable compounds on the two main physicochemical input parameters (the intestinal permeability coefficient (P-int) and the solubility in the intestinal fluids (S-int)) as well as physiological parameters such as the gastric emptying time and the intestinal transit time. For permeability-limited compounds, the model produces the established sigmoidal dependence between F-abs and P-int. In case of solubility-limited absorption, the model enables calculation of the critical mass-solubility ratio, which defines the onset of nonlinearity in the response of fraction absorbed to dose. In addition, an analytical equation to calculate the intestinal permeability coefficient based on the compound's membrane affinity and molecular weight was used successfully in combination with the physiologically based pharmacokinetic (PB-PK) model to predict the human fraction dose absorbed of compounds with permeability-limited absorption. Cross-validation demonstrated a root-mean-square prediction error of 7% for passively absorbed compounds.	Bayer Technol Serv GmbH, D-51368 Leverkusen, Germany; Bayer AG, D-42096 Wuppertal, Germany; Bayer Technol Serv GmbH, D-51368 Leverkusen, Germany; Univ Frankfurt, Inst Pharmaceut Technol, D-60439 Frankfurt, Germany	Willmann, S (reprint author), Bayer Technol Serv GmbH, Bldg 460 Rm 443, D-42096 Wuppertal, Germany.	Stefan.Willmann.SW@bayertechnology.com	Lippert, Jorg/I-3179-2012				Agoram B, 2001, ADV DRUG DELIV REV, V50, P41; Artursson P, 2001, ADV DRUG DELIVER REV, V46, P27, DOI 10.1016/S0169-409X(00)00128-9; ASHFORD M, 1994, J DRUG TARGET, V2, P241, DOI 10.3109/10611869408996806; Balon K, 1999, PHARMACEUT RES, V16, P882, DOI 10.1023/A:1018882221008; Beaugerie L, 1996, NEUROGASTROENT MOTIL, V8, P235, DOI 10.1111/j.1365-2982.1996.tb00262.x; BIRCHER J, 1999, KLIN PHARM DATENSAMM; BRENER W, 1983, GASTROENTEROLOGY, V85, P76; Camenisch G, 1998, Eur J Pharm Sci, V6, P325; Camenisch G, 1998, Eur J Pharm Sci, V6, P317; Charman WN, 1997, J PHARM SCI-US, V86, P269, DOI 10.1021/js960085v; Collett A, 1999, J PHARMACOL EXP THER, V288, P171; CUMMINGS JH, 1975, GUT, V16, P323, DOI 10.1136/gut.16.4.323; Curatolo W, 1998, PHARM SCI TECHNOL TO, V1, P387, DOI 10.1016/S1461-5347(98)00097-2; DAVIS SS, 1986, GUT, V27, P886, DOI 10.1136/gut.27.8.886; DEYOUNG JL, 1978, J PHARM SCI, V67, P320, DOI 10.1002/jps.2600670311; DRESSMAN JB, 1990, PHARMACEUT RES, V7, P756, DOI 10.1023/A:1015827908309; Egan WJ, 2000, J MED CHEM, V43, P3867, DOI 10.1021/jm000292e; FDA CDER, 1997, GUID IND DISS TEST I; GIBALDI M, 1991, BIOPHARMACEUTICS CLI, P40; Grass GM, 1997, ADV DRUG DELIVER REV, V23, P199, DOI 10.1016/S0169-409X(96)00436-X; Gray VA, 1996, PHARMACOPEIAL FORUM, V22, P1943; Hastie T, 2001, ELEMENTS STAT LEARNI, P193; HIDALGO IJ, 1989, GASTROENTEROLOGY, V96, P736; HILGERS AR, 1990, PHARMACEUT RES, V7, P902, DOI 10.1023/A:1015937605100; *INT COMM RAD PROT, 1992, TASK GROUP REF MAN R; Kansy M, 1998, J MED CHEM, V41, P1007, DOI 10.1021/jm970530e; Kimura T, 2002, BIOL PHARM BULL, V25, P149, DOI 10.1248/bpb.25.149; LANGENBU.F, 1972, J PHARM PHARMACOL, V24, P979; Lave T, 2002, E SCHERING RES FDN W, V37, P81; LEAHY DE, 1989, NOVEL DRUG DELIVERY AND ITS THERAPEUTIC APPLICATION, P33; LEVINE RR, 1970, AM J DIG DIS, V15, P171, DOI 10.1007/BF02235648; Liang E, 2000, PHARMACEUT RES, V17, P1168, DOI 10.1023/A:1026450326712; LIN HC, 1990, AM J PHYSIOL, V259, pG1025; Loidl-Stahlhofen A, 2001, PHARMACEUT RES, V18, P1782; Loidl-Stahlhofen A, 2001, J PHARM SCI, V90, P599, DOI 10.1002/1520-6017(200105)90:5<599::AID-JPS1016>3.0.CO;2-N; MALAGELADA JR, 1984, GASTROENTEROLOGY, V87, P1255; Marathe PH, 2000, BRIT J CLIN PHARMACO, V50, P325; NIMMO W S, 1976, Clinical Pharmacokinetics, V1, P189, DOI 10.2165/00003088-197601030-00002; Norris DA, 2000, J CONTROL RELEASE, V65, P55, DOI 10.1016/S0168-3659(99)00232-1; Pade V, 1998, J PHARM SCI, V87, P1604, DOI 10.1021/js980111k; Palm K, 1997, PHARMACEUT RES, V14, P568, DOI 10.1023/A:1012188625088; Parrott N, 2002, EUR J PHARM SCI, V17, P51, DOI 10.1016/S0928-0987(02)00132-X; PARSONS RL, 1977, CLIN PHARMACOKINET, V2, P45, DOI 10.2165/00003088-197702010-00004; Plusquellec Y, 1999, MED ENG PHYS, V21, P525, DOI 10.1016/S1350-4533(99)00060-0; Poulin P, 2000, J PHARM SCI, V89, P16, DOI 10.1002/(SICI)1520-6017(200001)89:1<16::AID-JPS3>3.0.CO;2-E; RUBINSTEIN A, 1995, CRIT REV THER DRUG, V12, P101; van Asperen J, 1999, BRIT J CANCER, V79, P108; Walter E, 1996, ADV DRUG DELIVER REV, V20, P33, DOI 10.1016/0169-409X(95)00129-U; Wessel MD, 1998, J CHEM INF COMP SCI, V38, P726, DOI 10.1021/ci980029a; Willmann S, 2003, PHARM RES, V20, P1766, DOI 10.1023/B:PHAM.0000003373.72652.c0; WINNE D, 1977, J PHARMACOKINET BIOP, V5, P53, DOI 10.1007/BF01064809; Yu LX, 1999, INT J PHARM, V186, P119, DOI 10.1016/S0378-5173(99)00147-7; Yu LX, 1999, PHARMACEUT RES, V16, P1883, DOI 10.1023/A:1018911728161	53	112	117	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0022-2623			J MED CHEM	J. Med. Chem.	JUL 29	2004	47	16					4022	4031		10.1021/jm030999b		10	Chemistry, Medicinal	Pharmacology & Pharmacy	840KF	WOS:000222856800015	15267240	
J	Mehrotra, R; Sharma, A; Cordery, I				Mehrotra, R; Sharma, A; Cordery, I			Comparison of two approaches for downscaling synoptic atmospheric patterns to multisite precipitation occurrence	JOURNAL OF GEOPHYSICAL RESEARCH-ATMOSPHERES			English	Article						downscaling; multisite rainfall; climate change	CIRCULATION MODEL OUTPUT; HIDDEN MARKOV MODEL; DAILY RAINFALL; CLIMATE-CHANGE; LOCAL CLIMATE; RHINE BASIN; TIME-SERIES; SIMULATION; TEMPERATURE; ALGORITHM	The physical linkages between climate on the large scale and weather on the local scale allow the formulation of downscaling approaches for assessing the impact of climate variability at point locations. This paper presents a comparison between two such approaches applied for downscaling synoptic atmospheric patterns to point rainfall occurrences on a rain gauge network. The approaches evaluated are the parametric nonhomogenous hidden Markov model (NHMM) and the nonparametric k-nearest neighbor downscaling approach. The NHMM defines local-scale weather as a function of a discrete weather state that is Markovian and depends on predictor variables representing synoptic atmospheric patterns. As the model is defined parametrically, the number of parameters that need specification increases as one considers more discrete weather states. Consequently, parameter identification and generalization to ungauged sites becomes difficult. On the other hand, nonparametric resampling is attractive because of its efficiency and simplicity, being structured as a direct probabilistic relationship between the larger-scale climatic variables and the local-scale weather. Such a formulation offers a simpler alternative to the NHMM approach of using intermediate hidden weather state variables but is less capable of representing persistence introduced through Markovian assumptions in the NHMM. In the comparison presented here, we applied weather-state-based nonhomogeneous hidden Markov model and the k-nearest neighbor bootstrap to estimate precipitation occurrences at a network of 30 rain gauge locations around Sydney, Australia. Our results suggest that both the models perform well in representing spatial variations while they show a lack in representing temporal dependence at scales longer than a few days as exhibited through wet spell length characteristics. Local-scale features that are difficult to represent through the large-scale climate predictors are, as expected, not reproduced by either approach.	Univ New S Wales, Sch Civil & Environm Engn, Sydney, NSW 2052, Australia; Natl Inst Hydrol, Roorkee, Uttar Pradesh, India	Mehrotra, R (reprint author), Univ New S Wales, Sch Civil & Environm Engn, Sydney, NSW 2052, Australia.	a.sharma@unsw.edu.au					Agresti A., 1996, INTRO CATEGORICAL DA; Bardossy A, 1997, J ENVIRON MANAGE, V49, P7, DOI 10.1006/jema.1996.0112; BARDOSSY A, 1992, WATER RESOUR RES, V28, P1247, DOI 10.1029/91WR02589; Bates B, 2000, ATMOS OCEAN SCI LIB, V21, P121; Bates BC, 1998, ENVIRON MODELL SOFTW, V13, P325, DOI 10.1016/S1364-8152(98)00037-1; BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196; Beersma JJ, 2003, CLIMATE RES, V25, P121, DOI 10.3354/cr025121; Bellone E, 2000, CLIMATE RES, V15, P1, DOI 10.3354/cr015001; Benestad RE, 2001, INT J CLIMATOL, V21, P1645, DOI 10.1002/joc.703; BISHOP YMM, 1975, DISCRET MULTIVARIATE; Brandsma T, 1998, HYDROL EARTH SYST SC, V2, P195; BUISHAND TA, 1978, J HYDROL, V36, P295, DOI 10.1016/0022-1694(78)90150-6; Buishand TA, 2001, WATER RESOUR RES, V37, P2761, DOI 10.1029/2001WR000291; *BUR MET, 1993, WIND WAV WEATH BOAT; Busuioc A, 1999, J CLIMATE, V12, P258, DOI 10.1175/1520-0442-12.1.258; Chapman T, 1998, ENVIRON MODELL SOFTW, V13, P317, DOI 10.1016/S1364-8152(98)00036-X; Charles SP, 1999, J GEOPHYS RES-ATMOS, V104, P31657, DOI 10.1029/1999JD900119; CHARLES SP, 2000, HYDR 2000 3 INT HYDR, P441; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Haario H, 2001, BERNOULLI, V7, P223, DOI 10.2307/3318737; Harrold TI, 2003, WATER RESOUR RES, V39, DOI 10.1029/2003WR002570; Hastie T., 2001, ELEMENTS STAT LEARNI; Hay LE, 2003, J HYDROL, V282, P56, DOI 10.1016/S0022-1694(03)00252-X; HAY LE, 1991, WATER RESOUR RES, V27, P493, DOI 10.1029/90WR02650; HUGHES JP, 1994, WATER RESOUR RES, V30, P1535, DOI 10.1029/93WR02983; Hughes JP, 1999, J R STAT SOC C-APPL, V48, P15, DOI 10.1111/1467-9876.00136; Juang B. H., 1991, Technometrics, V33, DOI 10.2307/1268779; Kalnay E, 1996, B AM METEOROL SOC, V77, P437, DOI 10.1175/1520-0477(1996)077<0437:TNYRP>2.0.CO;2; Katz RW, 1996, CLIMATE RES, V7, P185, DOI 10.3354/cr007185; Kidson JW, 1998, J CLIMATE, V11, P735, DOI 10.1175/1520-0442(1998)011<0735:ACOSAM>2.0.CO;2; Laio F, 2003, WATER RESOUR RES, V39, DOI 10.1029/2002WR001551; Lall U, 1996, WATER RESOUR RES, V32, P679, DOI 10.1029/95WR02966; Marshall L, 2004, WATER RESOUR RES, V40, DOI 10.1029/2003WR002378; Mearns LO, 1999, J GEOPHYS RES-ATMOS, V104, P6603, DOI 10.1029/1998JD200042; Murphy J, 2000, INT J CLIMATOL, V20, P489, DOI 10.1002/(SICI)1097-0088(200004)20:5<489::AID-JOC484>3.3.CO;2-Y; Murphy J, 1999, J CLIMATE, V12, P2256, DOI 10.1175/1520-0442(1999)012<2256:AEOSAD>2.0.CO;2; Prudhomme C, 2002, HYDROL PROCESS, V16, P1137, DOI 10.1002/hyp.1054; Rajagopalan B, 1999, WATER RESOUR RES, V35, P3089, DOI 10.1029/1999WR900028; RICHARDSON CW, 1981, WATER RESOUR RES, V17, P182, DOI 10.1029/WR017i001p00182; Sailor DJ, 1999, J CLIMATE, V12, P103, DOI 10.1175/1520-0442-12.1.103; Saunders IR, 1999, INT J CLIMATOL, V19, P1165, DOI 10.1002/(SICI)1097-0088(199909)19:11<1165::AID-JOC426>3.3.CO;2-X; Sharma A, 1999, MATH COMPUT SIMULAT, V48, P361, DOI 10.1016/S0378-4754(99)00016-6; Stehlik J, 2002, J HYDROL, V256, P120, DOI 10.1016/S0022-1694(01)00529-7; Timbal B, 2001, CLIM DYNAM, V17, P947, DOI 10.1007/s003820100156; von Storch H, 1999, STAT ANAL CLIMATE RE; Weichert A, 1998, CLIMATE RES, V10, P83, DOI 10.3354/cr010083; Wilby RL, 1997, PROG PHYS GEOG, V21, P530, DOI 10.1177/030913339702100403; Wilby RL, 1998, WATER RESOUR RES, V34, P2995, DOI 10.1029/98WR02577; WILBY RL, 1994, WATER RESOUR RES, V30, P3395, DOI 10.1029/94WR01840; Wilby RL, 2000, GEOPHYS RES LETT, V27, P1199, DOI 10.1029/1999GL006078; Wilks DS, 1999, PROG PHYS GEOG, V23, P329, DOI 10.1177/030913339902300302; Wilks DS, 1999, CLIMATE RES, V11, P125, DOI 10.3354/cr011125; Winkler JA, 1997, J CLIMATE, V10, P2514, DOI 10.1175/1520-0442(1997)010<2514:TSODTT>2.0.CO;2; Xu CY, 1999, PROG PHYS GEOG, V23, P229, DOI 10.1177/030913339902300204; Yarnal B, 2001, INT J CLIMATOL, V21, P1923, DOI 10.1002/joc.675; Yates D, 2003, WATER RESOUR RES, V39, DOI 10.1029/2002WR001769; YOUNG KC, 1994, J APPL METEOROL, V33, P661, DOI 10.1175/1520-0450(1994)033<0661:AMCMFS>2.0.CO;2; Zorita E, 1999, J CLIMATE, V12, P2474, DOI 10.1175/1520-0442(1999)012<2474:TAMAAS>2.0.CO;2	58	28	28	AMER GEOPHYSICAL UNION	WASHINGTON	2000 FLORIDA AVE NW, WASHINGTON, DC 20009 USA	2169-897X	2169-8996		J GEOPHYS RES-ATMOS	J. Geophys. Res.-Atmos.	JUL 28	2004	109	D14							D14107	10.1029/2004JD004823		15	Meteorology & Atmospheric Sciences	Meteorology & Atmospheric Sciences	844VS	WOS:000223189600005		
J	Huang, J; Lin, A; Narasimhan, B; Quertermous, T; Hsiung, CA; Ho, LT; Grove, JS; Olivier, M; Ranade, K; Risch, NJ; Shen, RA				Huang, J; Lin, A; Narasimhan, B; Quertermous, T; Hsiung, CA; Ho, LT; Grove, JS; Olivier, M; Ranade, K; Risch, NJ; Shen, RA			Tree-structured supervised learning and the genetics of hypertension	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article							CLASSIFICATION TREES; DISCRIMINANT-ANALYSIS; ASSOCIATION	This paper is about an algorithm, FlexTree, for general supervised learning. It extends the binary tree-structured approach (Classification and Regression Trees, CART) although it differs greatly in its selection and combination of predictors. It is particularly applicable to assessing interactions: gene by gene and gene by environment as they bear on complex disease. One model for predisposition to complex disease involves many genes. Of them, most are pure noise; each of the values that is not the prevalent genotype for the minority of genes that contribute to the signal carries a "score." Scores add. Individuals with scores above an unknown threshold are predisposed to the disease. For the additive score problem and simulated data, FlexTree has cross-validated risk better than many cutting-edge technologies to which it was compared when small fractions of candidate genes carry the signal. For the model where only a precise list of aberrant genotypes is predisposing, there is not a systematic pattern of absolute superiority; however, overall, FlexTree seems better than the other technologies. We tried the algorithm on data from 563 Chinese women, 206 hypotensive, 357 hypertensive, with information on ethnicity, menopausal status, insulin-resistant status, and 21 loci. FlexTree and Logic Regression appear better than the others in terms of Bayes risk. However, the differences are not significant in the usual statistical sense.	Affymetrix Inc, Santa Clara, CA 95051 USA; Stanford Univ, Dept Stat, Stanford, CA 94305 USA; Stanford Univ, Sch Med, Div Cardiovasc Med, Stanford, CA 94305 USA; Stanford Univ, Sch Med, Dept Genet, Stanford, CA 94305 USA; Stanford Univ, Sch Med, Dept Hlth Res & Policy, Stanford, CA 94305 USA; Natl Hlth Res Inst, Div Biostat & Bioinformat, Taipei 11529, Taiwan; Taipei Vet Gen Hosp, Dept Med Res & Educ, Taipei 112, Taiwan; Univ Hawaii, John A Burns Sch Med, Dept Publ Hlth Sci & Epidemiol, Honolulu, HI 96822 USA; Med Coll Wisconsin, Dept Human Physiol, Milwaukee, WI USA; Med Coll Wisconsin, Ctr Mol Genet, Milwaukee, WI 52336 USA; Bristol Myers Squibb Co, Pharmaceut Res Inst, Princeton, NJ 08543 USA	Huang, J (reprint author), Affymetrix Inc, 3380 Cent Expressway, Santa Clara, CA 95051 USA.	jing-huang@affymetrix.com	Hsiung, Chao Agnes/E-3994-2010				Bechtel S, 2002, EUR J BIOCHEM, V269, P1118, DOI 10.1046/j.1432-1033.2002.02729.x; BONNARDEAUX A, 1994, HYPERTENSION, V24, P63; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chuang LM, 2001, J MOL MED-JMM, V79, P656, DOI 10.1007/s001090100255; Elchebly M, 1999, SCIENCE, V283, P1544, DOI 10.1126/science.283.5407.1544; Friel DD, 2000, CELL CALCIUM, V28, P307, DOI 10.1054/ceca.2000.0172; Hastie T., 2001, ELEMENTS STAT LEARNI; HASTIE T, 1995, ANN STAT, V23, P73, DOI 10.1214/aos/1176324456; Hastie Trevor, 2000, GENOME BIOL, V1; LIFTON RP, 1992, NATURE, V355, P262, DOI 10.1038/355262a0; Lifton RP, 1996, SCIENCE, V272, P676, DOI 10.1126/science.272.5262.676; Lin A, 1999, HEALTH SERV RES, V34, P1033; Loh WY, 1997, STAT SINICA, V7, P815; LOH WY, 1988, J AM STAT ASSOC, V83, P715, DOI 10.2307/2289295; Lynch M, 1998, GENETICS ANAL QUANTI; Morello JP, 2001, ANNU REV PHYSIOL, V63, P607, DOI 10.1146/annurev.physiol.63.1.607; Ostensen CG, 2002, BIOCHEM BIOPH RES CO, V291, P945, DOI 10.1006/bbrc.2002.6536; Ranade K, 2001, HUM MOL GENET, V10, P2157, DOI 10.1093/hmg/10.19.2157; Reaven Gerald M, 2003, Curr Atheroscler Rep, V5, P364, DOI 10.1007/s11883-003-0007-0; Ruczinski I, 2003, J COMPUT GRAPH STAT, V12, P475, DOI 10.1198/1061860032238; Wu XD, 2003, METABOLISM, V52, P705, DOI 10.1016/S0026-0495(03)00065-9; Zhang HP, 2000, GENET EPIDEMIOL, V19, P323, DOI 10.1002/1098-2272(200012)19:4<323::AID-GEPI4>3.0.CO;2-5; Zhang HP, 1998, J AM STAT ASSOC, V93, P180, DOI 10.2307/2669615	25	31	31	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424			P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	JUL 20	2004	101	29					10529	10534		10.1073/pnas.0403794101		6	Multidisciplinary Sciences	Science & Technology - Other Topics	840FN	WOS:000222842700009	15249660	
J	Soltys, SG; Le, QT; Shi, GY; Tibshirani, R; Giaccia, AJ; Koong, AC				Soltys, SG; Le, QT; Shi, GY; Tibshirani, R; Giaccia, AJ; Koong, AC			The use of plasma surface-enhanced laser desorption/ionization time-of-flight mass spectrometry proteomic patterns for detection of head and neck squamous cell cancers	CLINICAL CANCER RESEARCH			English	Article; Proceedings Paper	45th Annual Meeting of the American-Society-for-Therapeutic-Radiology-and-Oncology	OCT 19-23, 2003	SALT LAKE CITY, UT	Amer Soc Therapeut Radiol & Oncol			PROSTATE-CANCER; PROMOTER HYPERMETHYLATION; OVARIAN-CANCER; ORAL-CANCER; SERUM; TUMORS; CARCINOMA; IDENTIFICATION; BIOMARKERS	Purpose: Our study was undertaken to determine the utility of plasma proteomic profiling using surface-enhanced laser desorption/ionization time-of-flight (SELDI-TOF) mass spectrometry for the detection of head and neck squamous cell carcinomas (HNSCCs). Experimental Design: Pretreatment plasma samples from HNSCC patients or controls without known neoplastic disease were analyzed on the Protein Biology System IIc SELDI-TOF mass spectrometer (Ciphergen Biosystems, Fremont, CA). Proteomic spectra of mass:charge ratio (m/z) were generated by the application of plasma to immobilized metal-affinity-capture (IMAC) ProteinChip arrays activated with copper. A total of 37,356 data points were generated for each sample. A training set of spectra from 56 cancer patients and 52 controls were applied to the "Lasso" technique to identify protein profiles that can distinguish cancer from noncancer, and cross-validation was used to determine test errors in this training set. The discovery pattern was then used to classify a separate masked test set of 57 cancer and 52 controls. In total, we analyzed the proteomic spectra of 113 cancer patients and 104 controls. Results: The Lasso approach identified 65 significant data points for the discrimination of normal from cancer profiles. The discriminatory pattern correctly identified 39 of 57 HNSCC patients and 40 of 52 noncancer controls in the masked test set. These results yielded a sensitivity of 68% and specificity of 73%. Subgroup analyses in the test set of four different demographic factors (age, gender, and cigarette and alcohol use) that can potentially confound the interpretation of the results suggest that this model tended to overpredict cancer in control smokers. Conclusions: Plasma proteomic profiling with SELDI-TOF mass spectrometry provides moderate sensitivity and specificity in discriminating HNSCC. Further improvement and validation of this approach is needed to determine its usefulness in screening for this disease.	Stanford Univ, Dept Radiat Oncol, Stanford, CA 94305 USA	Le, QT (reprint author), Stanford Univ, Dept Radiat Oncol, 875 Blake Wilbur Dr,MC 5847, Stanford, CA 94305 USA.	qle@stanford.edu					Adam BL, 2002, CANCER RES, V62, P3609; Banez LL, 2003, J UROLOGY, V170, P442, DOI 10.1097/01.ju.0000069431.95404.56; Downer M C, 1998, Community Dent Health, V15, P72; EFRON B, 2004, IN PRESS ANN STAT; Fliss MS, 2000, SCIENCE, V287, P2017, DOI 10.1126/science.287.5460.2017; Forastiere A, 2001, NEW ENGL J MED, V345, P1890, DOI 10.1056/NEJMra001375; Hanash S, 2003, NATURE, V422, P226, DOI 10.1038/nature01514; HASTIE T, 2001, ELEMENTS STAT LEARNI, P64; HUTCHENS TW, 1993, RAPID COMMUN MASS SP, V7, P576, DOI 10.1002/rcm.1290070703; Kim ES, 2002, ANNU REV MED, V53, P223, DOI 10.1146/annurev.med.53.082901.104015; Li JN, 2002, CLIN CHEM, V48, P1296; Merchant M, 2000, ELECTROPHORESIS, V21, P1164, DOI 10.1002/(SICI)1522-2683(20000401)21:6<1164::AID-ELPS1164>3.3.CO;2-S; Nagpal JK, 2003, ORAL ONCOL, V39, P213, DOI 10.1016/S1368-8375(02)00162-8; PARKIN DM, 1993, INT J CANCER, V54, P594, DOI 10.1002/ijc.2910540413; Petricoin EF, 2002, NAT REV DRUG DISCOV, V1, P683, DOI 10.1038/nrd891; Petricoin EF, 2002, J NATL CANCER I, V94, P1576; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Poon TCW, 2003, CLIN CHEM, V49, P752, DOI 10.1373/49.5.752; Qu YS, 2002, CLIN CHEM, V48, P1835; Rai AJ, 2002, ARCH PATHOL LAB MED, V126, P1518; Rosas SLB, 2001, CANCER RES, V61, P939; Sanchez-Cespedes M, 2000, CANCER RES, V60, P892; Sankaranarayanan R, 2000, CANCER, V88, P664, DOI 10.1002/(SICI)1097-0142(20000201)88:3<664::AID-CNCR25>3.0.CO;2-V; Sidransky D, 2003, J NATL CANCER I, V95, P1711, DOI 10.1093/jnci/djg099; SOBIN LH, 1988, CANCER, V61, P2310, DOI 10.1002/1097-0142(19880601)61:11<2310::AID-CNCR2820611127>3.0.CO;2-X; Spafford MF, 2001, CLIN CANCER RES, V7, P607; Tibshirani R., 2001, ELEMENTS STAT LEARNI; Tibshirani R, 1997, STAT MED, V16, P385, DOI 10.1002/(SICI)1097-0258(19970228)16:4<385::AID-SIM380>3.0.CO;2-3; Vlahou A, 2001, AM J PATHOL, V158, P1491, DOI 10.1016/S0002-9440(10)64100-4; Yanagisawa K, 2003, LANCET, V362, P433, DOI 10.1016/S0140-6736(03)14068-8	30	56	63	AMER ASSOC CANCER RESEARCH	PHILADELPHIA	615 CHESTNUT ST, 17TH FLOOR, PHILADELPHIA, PA 19106-4404 USA	1078-0432			CLIN CANCER RES	Clin. Cancer Res.	JUL 15	2004	10	14					4806	4812		10.1158/1078-0432.CCR-03-0469		7	Oncology	Oncology	840ET	WOS:000222840700027	15269156	
J	Chiang, LH; Kotanchek, ME; Kordon, AK				Chiang, LH; Kotanchek, ME; Kordon, AK			Fault diagnosis based on Fisher discriminant analysis and support vector machines	COMPUTERS & CHEMICAL ENGINEERING			English	Article						fault diagnosis; support vector machines; fisher discriminant analysis; classification	CONTRIBUTION PLOTS	The proficiencies of Fisher discriminant analysis (FDA), support vector machines (SVM), and proximal support vector machines (PSVM) for fault diagnosis (i.e. classification of multiple fault classes) are investigated. The Tennessee Eastman process (TEP) simulator was used to generate overlapping datasets to evaluate the classification performance. When all variables were used, the datasets were masked with irrelevant information, which resulted in poor classification. With key variables selected by genetic algorithms and the contribution charts, SVM and PSVM outperformed FDA and demonstrated the advantage of using nonlinear technique when data are overlapped. The overall misclassification for the testing data using FDA dropped from 38 to 18%; while those using SVM and PSVM dropped from 44-45 to 6%. The effectiveness of the proposed approach is increased in PSVM by saving significant computation time and memory requirement, while obtaining comparable classification results. For auto-correlated data, the incorporation of time lags into SVM and PSVM improved classification results. The added dimensions decreased the degree to which the data overlap and the overall misclassification for the testing set using SVM and PSVM decreased further to 3%. (C) 2003 Elsevier Ltd. All rights reserved.	Dow Chem Co USA, MS&IR, Corp R&D, Freeport, TX 77541 USA	Chiang, LH (reprint author), Dow Chem Co USA, MS&IR, Corp R&D, 2301 Brazosport Blvd,B1217, Freeport, TX 77541 USA.	hchiang@dow.com					Allwein E. L., 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; Baughman D.R., 1995, NEURAL NETWORKS BIOP; Beebe K.R., 1998, CHEMOMETRICS PRACTIC; Bharath R., 1994, NEURAL NETWORK COMPU; Burbidge Robert, 2001, INTRO SUPPORT VECTOR; Cherkassky V., 1998, LEARNING DATA CONCEP; Chiang L.H., 2001, FAULT DETECTION DIAG; Chiang LH, 2004, J PROCESS CONTR, V14, P143, DOI 10.1016/S0959-1524(03)00029-5; Chiang LH, 2000, CHEMOMETR INTELL LAB, V50, P243, DOI 10.1016/S0169-7439(99)00061-1; Conlin AK, 2000, J CHEMOMETR, V14, P725, DOI 10.1002/1099-128X(200009/12)14:5/6<725::AID-CEM611>3.0.CO;2-8; Duda R. O., 1973, PATTERN CLASSIFICATI; ENGL HW, 1998, REGULARISATION INVER; FUNG G, 2001, 0102 DAT MIN I; FUNG G, 2001, MULTICATEGORY PROXIM; Gurden SP, 1998, CHEMOMETR INTELL LAB, V44, P319, DOI 10.1016/S0169-7439(98)00119-1; Hastie T., 2001, ELEMENTS STAT LEARNI; Jordaan E. M., 2002, THESIS TU EINDHOVEN; JORDAAN EM, 2002, P WORLD C COMP INT, V1, P2785; KECMAN V, 2001, LEARING SOFT COMPUTI; Kourti T, 1996, J QUAL TECHNOL, V28, P409; KU K, 1995, CHEMOMETRICS INTELLI, V30, P179; LEE Y, 1999, 9903 DAT MIN I; Lee Y.-J., 2001, P SIAM INT C DAT MIN; LYMAN PR, 1995, COMPUT CHEM ENG, V19, P321, DOI 10.1016/0098-1354(94)00057-U; MACGREGOR JF, 1995, CONTROL ENG PRACT, V3, P403, DOI 10.1016/0967-0661(95)00014-L; McAvoy TJ, 1998, COMPUT CHEM ENG, V22, P1543, DOI 10.1016/S0098-1354(98)00243-9; Mika S., 1999, Fisher discriminant analysis with kernels; Miller P., 1998, Applied Mathematics and Computer Science, V8; Misra M, 2002, COMPUT CHEM ENG, V26, P1281, DOI 10.1016/S0098-1354(02)00093-5; Qin SJ, 2001, J CHEMOMETR, V15, P715, DOI 10.1002/cem.667; Raich A, 1996, AICHE J, V42, P995, DOI 10.1002/aic.690420412; Scholkopf B., 2002, LEARNING KERNELS SUP; *UM, 2002, US GUID SIMCA P SIMC; Vapnik VN, 1995, NATURE STAT LEARNING; DOWNS JJ, 1993, COMPUT CHEM ENG, V17, P245, DOI 10.1016/0098-1354(93)80018-I; Westerhuis JA, 2000, CHEMOMETR INTELL LAB, V51, P95, DOI 10.1016/S0169-7439(00)00062-9	36	152	170	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0098-1354			COMPUT CHEM ENG	Comput. Chem. Eng.	JUL 15	2004	28	8					1389	1401		10.1016/j.compchemeng.2003.10.002		13	Computer Science, Interdisciplinary Applications; Engineering, Chemical	Computer Science; Engineering	825AH	WOS:000221727900017		
J	Kristensen, NR; Madsen, H; Jorgensen, SB				Kristensen, NR; Madsen, H; Jorgensen, SB			A method for systematic improvement of stochastic grey-box models	COMPUTERS & CHEMICAL ENGINEERING			English	Article						model improvement; stochastic differential equations; parameter estimation; statistical tests; nonparametric modelling; bioreactor modelling		A systematic framework for improving the quality of continuous time models of dynamic systems based on experimental data is presented. The framework is based on an interplay between stochastic differential equation modelling, statistical tests and nonparametric modelling and provides features that allow model deficiencies to be pinpointed and their structural origin to be uncovered. More specifically, the proposed framework can be used to obtain estimates of unknown functional relations, in turn allowing unknown or inappropriately modelled phenomena to be uncovered. In this manner the framework permits systematic iterative model improvement. The performance of the proposed framework is illustrated through a case study involving a dynamic model of a fed-batch bioreactor, where it is shown how an inappropriately modelled biomass growth rate can be uncovered and a proper functional relation inferred. A key point illustrated through this case study is that functional relations involving unmeasured variables can also be uncovered. (C) 2003 Elsevier Ltd. All rights reserved.	Tech Univ Denmark, Dept Chem Engn, DK-2800 Lyngby, Denmark; Tech Univ Denmark, Dept Math Modelling, DK-2800 Lyngby, Denmark	Kristensen, NR (reprint author), Tech Univ Denmark, Dept Chem Engn, Bldg 229, DK-2800 Lyngby, Denmark.	nikr@novonordisk.com					Allgower F., 2000, PROGR SYSTEMS CONTRO, V26; Aostrom K. J., 1970, INTRO STOCHASTIC CON; BAK J, 1999, S ANV STAT COP DENM; BOHLIN T, 1995, INT J ADAPT CONTROL, V9, P465, DOI 10.1002/acs.4480090603; BOHLIN T, 2001, IRS3REG0103 ROYAL I; Box GEP, 1976, TIME SERIES ANAL; Brockwell P. J., 1991, TIME SERIES THEORY M; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T, 1990, GEN ADDITIVE MODELS; HOLST J, 1992, 4 IFAC S AD SYST CON, P407; Jazwinski A. H., 1970, STOCHASTIC PROCESSES; KRISTENSEN NR, 2003, IN PRESS AUTOMATICA; Ljung L., 1987, SYSTEM IDENTIFICATIO; MADSEN H, 1991, 7 IIM TECHN U DENM; MELGAARD H, 1993, CTLSM PROGRAM PARAME; Nielsen HA, 2001, COMPUT STAT DATA AN, V37, P13, DOI 10.1016/S0167-9473(00)00061-X; Oksendal B., 1998, STOCHASTIC DIFFERENT; RAISCH J, 2000, P ADCHEM 2000 INT S, P275; Soderstrom T., 1989, SYSTEM IDENTIFICATIO; YOUNG P, 1981, AUTOMATICA, V17, P23, DOI 10.1016/0005-1098(81)90082-0	20	34	34	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0098-1354			COMPUT CHEM ENG	Comput. Chem. Eng.	JUL 15	2004	28	8					1431	1449		10.1016/j.compchemeng.2003.10.003		19	Computer Science, Interdisciplinary Applications; Engineering, Chemical	Computer Science; Engineering	825AH	WOS:000221727900020		
J	Hastie, T; Tibshirani, R				Hastie, T; Tibshirani, R			Efficient quadratic regularization for expression arrays	BIOSTATISTICS			English	Article						eigengenes; euclidean methods; quadratic regularization; SVD	DISCRIMINANT-ANALYSIS; REGRESSION; CLASSIFICATION; MICROARRAYS; PREDICTION	Gene expression arrays typically have 50 to 100 samples and 1000 to 20 000 variables (genes). There have been many attempts to adapt statistical models for regression and classification to these data, and in many cases these attempts have challenged the computational resources. In this article we expose a class of techniques based on quadratic regularization of linear models, including regularized (ridge) regression, logistic and multinomial regression, linear and mixture discriminant analysis, the Cox model and neural networks. For all of these models, we show that dramatic computational savings are possible over naive implementations, using standard transformations in numerical linear algebra.	Stanford Univ, Dept Stat, Stanford, CA 94305 USA; Stanford Univ, Dept Hlth Res & Policy, Stanford, CA 94305 USA	Hastie, T (reprint author), Stanford Univ, Dept Stat, Sequoia Hall, Stanford, CA 94305 USA.	hastie@stanford.edu					Alter O, 2000, P NATL ACAD SCI USA, V97, P10101, DOI 10.1073/pnas.97.18.10101; COX DR, 1972, J R STAT SOC B, V34, P187; EFRON B, 2002, LEAST ANGLE REGRESSI; EILERS P, 2001, P SOC PHOTO-OPT INS, V4266, P23; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Ghosh D, 2003, BIOMETRICS, V59, P992, DOI 10.1111/j.0006-341X.2003.00114.x; Golub G. H., 1983, MATRIX COMPUTATIONS; GUO Y, 2003, REGULARIZED DISCRIMI; Hastie T., 2001, ELEMENTS STAT LEARNI; HASTIE T, 2004, ENTIRE REGULARIZATIO; HASTIE T, 1995, ANN STAT, V23, P73, DOI 10.1214/aos/1176324456; Hastie T, 1996, J ROY STAT SOC B MET, V58, P155; HOERL AE, 1970, TECHNOMETRICS, V12, P55; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; ROSSET S, 2003, NEURAL INFORMATION P; Scholkopf Bernard, 2001, LEARNING KERNELS SUP; Tibshirani R, 2003, STAT SCI, V18, P104, DOI 10.1214/ss/1056397488; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Vapnik VN, 1996, NATURE STAT LEARNING; Wahba G, 2000, ADV NEUR IN, P297; West M, 2003, BAYESIAN STAT, V7, P723; Zhu J, 2004, BIOSTATISTICS, V5, P427, DOI 10.1093/biostatistics/kxg046; ZHU J, 2003, L1 NORM SUPPORT VECT	25	35	36	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1465-4644			BIOSTATISTICS	Biostatistics	JUL	2004	5	3					329	340		10.1093/biostatistics/kxh010		12	Mathematical & Computational Biology; Statistics & Probability	Mathematical & Computational Biology; Mathematics	838OV	WOS:000222723600001	15208198	
J	Zhu, J; Hastie, T				Zhu, J; Hastie, T			Classification of gene microarrays by penalized logistic regression	BIOSTATISTICS			English	Article						cancer diagnosis; feature selection; logistic regression; microarray; support vector machines	EXPRESSION; CANCER; PREDICTION; DIAGNOSIS	Classification of patient samples is an important aspect of cancer diagnosis and treatment. The support vector machine (SVM) has been successfully applied to microarray cancer diagnosis problems. However, one weakness of the SVM is that given a tumor sample, it only predicts a cancer class label but does not provide any estimate of the underlying probability. We propose penalized logistic regression (PLR) as an alternative to the SVM for the microarray cancer diagnosis problem. We show that when using the same set of genes, PLR and the SVM perform similarly in cancer classification, but PLR has the advantage of additionally providing an estimate of the underlying probability. Often a primary goal in microarray cancer diagnosis is to identify the genes responsible for the classification, rather than class prediction. We consider two gene selection methods in this paper, univariate ranking (UR) and recursive feature elimination (RFE). Empirical results indicate that PLR combined with RFE tends to select fewer genes than other methods and also performs well in both cross-validation and test samples. A fast algorithm for solving PLR is also described.	Univ Michigan, Dept Stat, Ann Arbor, MI 48109 USA; Stanford Univ, Dept Stat, Stanford, CA 94305 USA	Zhu, J (reprint author), Univ Michigan, Dept Stat, Ann Arbor, MI 48109 USA.	jizhu@umich.edu					Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hastie T., 2001, ELEMENTS STAT LEARNI; KEERTHI SS, 2002, 19 INT C MACH LEARN; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; KIMELDOR.G, 1971, J MATH ANAL APPL, V33, P82, DOI 10.1016/0022-247X(71)90184-3; Lee Y., 2002, 1051 U WISC DEP STAT; MUKHERJEE S, 1999, 1677 MIT; Platt J. C., 1998, MSRTR9814; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; ROSSET S, 2002, BOOSTING REGULARIZED; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; ZHU J, 2002, ADV NEURAL INFORMATI, V14	14	109	114	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1465-4644			BIOSTATISTICS	Biostatistics	JUL	2004	5	3					427	443		10.1093/biostatistics/kxg046		17	Mathematical & Computational Biology; Statistics & Probability	Mathematical & Computational Biology; Mathematics	838OV	WOS:000222723600007	15208204	
J	Teuffel, O; Dettling, M; Cario, G; Stanulla, M; Schrappe, M; Buhlmann, P; Niggl, FK; Schafer, BW				Teuffel, O; Dettling, M; Cario, G; Stanulla, M; Schrappe, M; Buhlmann, P; Niggl, FK; Schafer, BW			Gene expression profiles and risk stratification in childhood acute lymphoblastic leukemia	HAEMATOLOGICA			English	Article						childhood acute lymphoblastic leukemia; gene expression; microarray; risk stratification	MINIMAL RESIDUAL DISEASE; MOLECULAR CLASSIFICATION; TISSUE SAMPLES; CANCER; TRANSCRIPTION; DISCOVERY; PROTEIN; IMMUNOGLOBULIN; TRANSLOCATIONS; PREDICTION	Background and Objectives. Childhood acute lymphoblastic leukemia (ALL) is a heterogeneous disease. There are several distinct genetic subtypes, characterized by typical changes in gene expression pattern. In addition to cytogenetic markers, the in vivo response to treatment is an emerging prognostic marker for risk stratification. However, it has not yet been reported whether gene expression profiles can predict risk group stratification already at the time of diagnosis. Design and Methods. We analyzed bone marrow samples of 31 ALL patients to identify changes in gene expression that are associated with the current risk assignment, irrespective of the genetic subtype. Gene expression profiles were established using oligonucleotide microarrays. Results. Considering all low- and high-risk patients, no gene was capable of predicting the risk assignment already at time of diagnosis. However, screening for risk group associated genes using more homogeneous subsets of patients revealed 106 discriminatory probe sets. The prognostic significance of these probe sets was subsequently determined for the entire series of patients. Using the selected subgroups as the training set and the remaining samples as an independent test set, logistic regression using 3 predictor variables could accurately predict current risk assignment for 10 out of 12 patients. Interpretation and Conclusions. Gene expression profiles established from a cytogenetically heterogeneous study group are not, as yet, sufficiently accurate to be used prognostically in a clinical setting. Additional risk-associated gene expression analyses need to be performed in more homogeneous sets of patients.	Univ Zurich, Childrens Hosp, Dept Oncol, CH-8032 Zurich, Switzerland; Swiss Fed Inst Technol, Seminar Stat, Zurich, Switzerland; Hannover Med Sch, Dept Pediat Hematol & Oncol, D-3000 Hannover, Germany	Schafer, BW (reprint author), Univ Zurich, Childrens Hosp, Dept Oncol, Steinwiesstr 75, CH-8032 Zurich, Switzerland.	beat.schaefer@kispi.unizh.ch	Schrappe, Martin/A-8109-2010; Cario, Gunnar/D-2535-2010; Stanulla, Martin/D-2528-2010; Buhlmann, Peter/A-2107-2013				Arico M, 2000, NEW ENGL J MED, V342, P998, DOI 10.1056/NEJM200004063421402; Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Cave H, 1998, NEW ENGL J MED, V339, P591, DOI 10.1056/NEJM199808273390904; Curry JD, 2001, BRIT J HAEMATOL, V115, P826, DOI 10.1046/j.1365-2141.2001.03190.x; DEANE M, 1990, EUR J IMMUNOL, V20, P2209, DOI 10.1002/eji.1830201009; Durig J, 2003, BLOOD, V101, P2748, DOI 10.1182/blood-2002-09-2683; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Ferrando AA, 2002, CANCER CELL, V1, P75, DOI 10.1016/S1535-6108(02)00018-1; Fine BM, 2004, BLOOD, V103, P1043, DOI 10.1182/blood-2003-05-1518; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Harrison CJ, 2001, BLOOD REV, V15, P49, DOI 10.1054/blre.2001.0150; Hastie T., 2001, ELEMENTS STAT LEARNI; Hedenfalk I, 2003, P NATL ACAD SCI USA, V100, P2532, DOI 10.1073/pnas.0533805100; Iben S, 2002, CELL, V109, P297, DOI 10.1016/S0092-8674(02)00729-8; Ihaka R, 2005, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Lin YP, 2000, NAT GENET, V26, P122; POGUEGEILE K, 1991, MOL CELL BIOL, V11, P3842; Pongers-Willemse MJ, 1999, LEUKEMIA, V13, P110, DOI 10.1038/sj.leu.2401245; Pui CH, 1998, NEW ENGL J MED, V339, P605; Reese JC, 2003, CURR OPIN GENET DEV, V13, P114, DOI 10.1016/S0959-437X(03)00013-3; Ross ME, 2003, BLOOD, V102, P2951, DOI 10.1182/blood-2003-01-0338; Ruggero D, 2003, NAT REV CANCER, V3, P179, DOI 10.1038/nrc1015; Schrappe M, 2000, LEUKEMIA, V14, P2205, DOI 10.1038/sj.leu.2401973; Uckun FM, 1999, LEUKEMIA LYMPHOMA, V33, P101; Vaarala MH, 1998, INT J CANCER, V78, P27, DOI 10.1002/(SICI)1097-0215(19980925)78:1<27::AID-IJC6>3.0.CO;2-Z; van Dongen JJM, 1998, LANCET, V352, P1731, DOI 10.1016/S0140-6736(98)04058-6; Wang Q, 2001, GENE, V263, P205, DOI 10.1016/S0378-1119(00)00570-9; Welsh JB, 2001, P NATL ACAD SCI USA, V98, P1176, DOI 10.1073/pnas.98.3.1176; Willemse MJ, 2002, BLOOD, V99, P4386, DOI 10.1182/blood.V99.12.4386; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	31	14	14	FERRATA STORTI FOUNDATION	PAVIA	STRADA NUOVA 134, 27100 PAVIA, ITALY	0390-6078			HAEMATOLOGICA	Haematologica	JUL	2004	89	7					801	808				8	Hematology	Hematology	837QK	WOS:000222650200005	15257931	
J	Wang, SJ; Schuurmans, D; Peng, FC; Zhao, YX				Wang, SJ; Schuurmans, D; Peng, FC; Zhao, YX			Learning mixture models with the regularized latent maximum entropy principle	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						expectation maximization (EM); iterative scaling; latent variables; maximum entropy; mixture models; regularization	EM ALGORITHM	This paper presents a new approach to estimating mixture models based on a recent inference principle we have proposed: the latent maximum entropy principle (LME). LME is different from Jaynes' maximum entropy principle, standard maximum likelihood, and maximum a posteriori probability estimation. We demonstrate the LME principle by deriving new algorithms for mixture model estimation, and show how robust new variants of the expectation maximization (EM) algorithm can be developed. We show that a regularized version of LME (RLME), is effective at estimating mixture models. It generally yields better results than plain LME, which in turn is often better than maximum likelihood and maximum a posterior estimation, particularly when inferring latent variable models from small amounts of data.	Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada; Univ Massachusetts, Dept Comp Sci, Amherst, MA 01003 USA; Univ Missouri, Dept Comp Engn & Comp Sci, Columbia, MO 65201 USA	Wang, SJ (reprint author), Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada.						ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; BARRON AR, 1991, ANN STAT, V19, P1347, DOI 10.1214/aos/1176348252; Bernardo J. M., 2000, BAYESIAN THEORY; Bertsekas DP, 1999, NONLINEAR PROGRAMMIN; Borwein J.M., 2000, CONVEX ANAL NONLINEA; Cover T. M., 1991, ELEMENTS INFORMATION; Csiszar I, 1996, FUND THEOR, V79, P35; DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379; DellaPietra S, 1997, IEEE T PATTERN ANAL, V19, P380, DOI 10.1109/34.588021; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Fisher RA, 1936, ANN EUGENIC, V7, P179; Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278; Hastie T., 2001, ELEMENTS STAT LEARNI; JAYNES ET, 1983, PROBABILITY STAT STA; LAFFERTY J, 2001, P 18 INT C MACH LEAR, P282; Lauritzen S., 1995, COMPUTATIONAL STAT D, V19, P191; Lauritzen S.L, 1996, GRAPHICAL MODELS; Lehmann E. L., 1998, THEORY POINT ESTIMAT; Luenberger D. G., 1969, OPTIMIZATION VECTOR; McLachlan GJ, 2000, FINITE MIXTURE MODEL; Minka T. P., 2000, ESTIMATING DIRICHLET; RIEZLER S, 1999, THESIS U STUTTGART G; TIKHONOV A, 1992, ILLPOSED PROBLEMS NA; UEDA N, 1998, NEURAL NETWORKS, V11, P272; WANG S, 2003, LATENT MAXIMUM ENTRO; WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060	26	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1045-9227			IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	JUL	2004	15	4					903	916		10.1109/TNN.2004.828755		14	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	837KS	WOS:000222629300011	15461082	
J	Forrester, JB; Kalivas, JH				Forrester, JB; Kalivas, JH			Ridge regression optimization using a harmonious approach	JOURNAL OF CHEMOMETRICS			English	Article						ridge regression; L-curve; harmonious model; multivariate calibration; bias/variance tradeoff; effective rank; degrees of freedom; parsimony	LEAST-SQUARES REGRESSION; MULTIVARIATE CALIBRATION; CROSS-VALIDATION; L-CURVE; NONORTHOGONAL PROBLEMS; WAVELENGTH SELECTION; PARETO CALIBRATION; MODEL SELECTION; POSED PROBLEMS; BASIS-SETS	A critical component of ridge regression (RR) is determining the optimal ridge parameter value, lambda, where lambda >= 0. Improper selection of lambda not only generates an under- or overfitted model but also leads to incorrect conclusions in inter-model comparison studies such as between RR, PLS, PCR and other modeling methods. Several methods for determining the optimal RR model are evaluated in this paper. For example, the commonly used ridge trace is identified as subjective and impractical. A direct calculation method from the literature yields over- or underfitted RR models with lambda either too small or to large respectively. Methods for determining lambda based on a harmonious approach are discussed. The harmonious approach optimizes lambda by inspecting the bias/variance tradeoff. Of the methods investigated, plotting a variance indicator against a bias measure to yield an L-curve appears not only to simplify selection of lambda but also to reduce the chance of obtaining an under- or overfitted RR model. It is shown with four data sets that the L-curve harmonious approach consistently provides good models. The effective rank of models is also discussed in conjunction with the harmony/parsimony tradeoff. Copyright (C) 2005 John Wiley A Sons, Ltd.	Idaho State Univ, Dept Chem, Pocatello, ID 83209 USA	Kalivas, JH (reprint author), Idaho State Univ, Dept Chem, Pocatello, ID 83209 USA.	kalijohn@isu.edu					Anderson KJ, 2003, APPL SPECTROSC, V57, P309, DOI 10.1366/000370203321558227; [Anonymous], 1998, ANN BOOK ASTM STAND; Baumann K, 2003, TRAC-TREND ANAL CHEM, V22, P395, DOI 10.1016/S0165-9936(03)00607-1; Booksh K.S., 1995, CHEMOMETRICS ENV CHE, P209; CENSOR Y, 1977, APPL MATH OPT, V4, P41, DOI 10.1007/BF01442131; CHEN LY, 1995, SOIL DYN EARTHQ ENG, V14, P361, DOI 10.1016/0267-7261(95)00003-D; Coelho CJ, 2003, CHEMOMETR INTELL LAB, V66, P205, DOI 10.1016/S0169-7439(03)00050-9; Cohon J. L., 1978, MULTIOBJECTIVE PROGR; DACUNHA NO, 1967, J MATH ANAL APPL, V19, P103, DOI 10.1016/0022-247X(67)90025-X; DOX A, 1992, SIAM J OPTIMIZ, V2, P602; DUINEVELD CAA, 1993, ANAL CHIM ACTA, V277, P455, DOI 10.1016/0003-2670(93)80456-U; Faber K, 1997, J CHEMOMETR, V11, P181, DOI 10.1002/(SICI)1099-128X(199705)11:3<181::AID-CEM459>3.0.CO;2-7; Faber K, 1996, CHEMOMETR INTELL LAB, V34, P283, DOI 10.1016/0169-7439(96)00022-6; Faber NM, 2003, TRAC-TREND ANAL CHEM, V22, P330, DOI 10.1016/S0165-9936(03)00503-X; Faber NM, 2002, CHEMOMETR INTELL LAB, V64, P169, DOI 10.1016/S0169-7439(02)00102-8; FEARN T, 1983, APPL STAT, V32, P73, DOI 10.2307/2348045; Pierna JAF, 2003, CHEMOMETR INTELL LAB, V65, P281; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; GELADI P, 1994, CHEMOMETR INTELL LAB, V24, P145, DOI 10.1016/0169-7439(94)00035-2; GOLUB GH, 1979, TECHNOMETRICS, V21, P215, DOI 10.1080/00401706.1979.10489751; Green RL, 2002, CHEMOMETR INTELL LAB, V60, P173, DOI 10.1016/S0169-7439(01)00194-0; GUSANTO A, 2003, J CHEMOMETR, V17, P174; Hansen P.C., 1998, RANK DEFICIENT DISCR; Hansen P.C., 2001, COMPUTATIONAL INVERS, P119; HANSEN PC, 1993, SIAM J SCI COMPUT, V14, P1487, DOI 10.1137/0914086; HANSEN PC, 1992, SIAM REV, V34, P561, DOI 10.1137/1034115; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T, 1990, GEN ADDITIVE MODELS; HOERL AE, 1975, COMMUN STAT, V4, P105, DOI 10.1080/03610917508548342; HOERL AE, 1970, TECHNOMETRICS, V12, P55; HOERL AE, 1970, TECHNOMETRICS, V12, P69, DOI 10.2307/1267352; HOSKULDSSON A, 1992, CHEMOMETR INTELL LAB, V14, P139, DOI 10.1016/0169-7439(92)80099-P; Huang J, 2002, CHEMOMETR INTELL LAB, V62, P25, DOI 10.1016/S0169-7439(01)00211-8; Kalivas JH, 2004, ANAL CHIM ACTA, V505, P9, DOI 10.1016/S0003-2670(02)01603-3; Kalivas JH, 2001, APPL SPECTROSC, V55, P1645, DOI 10.1366/0003702011953955; Kalivas JH, 1999, J CHEMOMETR, V13, P111, DOI 10.1002/(SICI)1099-128X(199903/04)13:2<111::AID-CEM532>3.3.CO;2-E; Kalivas JH, 2001, ANAL CHIM ACTA, V428, P31, DOI 10.1016/S0003-2670(00)01225-3; Kalivas JH, 1994, MATH ANAL SPECTRAL O; Kalivas JH, 1997, CHEMOMETR INTELL LAB, V37, P255, DOI 10.1016/S0169-7439(97)00038-5; Kaufman L, 1996, IEEE T MED IMAGING, V15, P385, DOI 10.1109/42.500147; Lawson CL, 1974, SOLVING LEAST SQUARE; Lorber A., 1988, J CHEMOMETR, V2, P93, DOI 10.1002/cem.1180020203; Mallows C., 1973, TECHNOMETRICS, V42, P87; Myers RH, 1990, CLASSICAL MODERN REG; Naes T., 2002, USER FRIENDLY GUIDE; O'Sullivan F., 1986, STAT SCI, V1, P502, DOI 10.1214/ss/1177013525; Olivieri AC, 2002, J CHEMOMETR, V16, P207, DOI 10.1002/cem.716; Prakash AMC, 1999, CHEMOMETR INTELL LAB, V46, P265, DOI 10.1016/S0169-7439(98)00176-2; Seipel HA, 2004, J CHEMOMETR, V18, P306, DOI 10.1002/cem.874; SHAO J, 1993, J AM STAT ASSOC, V88, P486, DOI 10.2307/2290328; SMILDE AK, 1986, J CHROMATOGR, V369, P1, DOI 10.1016/S0021-9673(00)90093-1; STEINBERG DM, 1984, TECHNOMETRICS, V26, P71, DOI 10.2307/1268097; Tikhonov A N, 1963, SOV MATH DOKL, V4, P1035; Wahba G., 1990, CBMS NSF REGIONAL C, V59; Wise B.M., 2003, PLS TOOLBOX 3 0 USE; Ye JM, 1998, J AM STAT ASSOC, V93, P120, DOI 10.2307/2669609	56	20	22	JOHN WILEY & SONS LTD	CHICHESTER	THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND	0886-9383			J CHEMOMETR	J. Chemometr.	JUL-AUG	2004	18	7-8					372	384		10.1002/cem.883		13	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	907HC	WOS:000227706000006		
J	Jebara, T; Kondor, R; Howard, A				Jebara, T; Kondor, R; Howard, A			Probability product kernels	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						kernels; support vector machines; generative models; Hellinger divergence; Kullback-Leibler divergence; Bhattacharyya affinity; expected likelihood; exponential family; graphical models; latent models; hidden Markov models; dynamical systems; mean field		The advantages of discriminative learning algorithms and kernel machines are combined with generative modeling using a novel kernel between distributions. In the probability product kernel, data points in the input space are mapped to distributions over the sample space and a general inner product is then evaluated as the integral of the product of pairs of distributions. The kernel is straightforward to evaluate for all exponential family models such as multinomials and Gaussians and yields interesting nonlinear kernels. Furthermore, the kernel is computable in closed form for latent distributions such as mixture models, hidden Markov models and linear dynamical systems. For intractable models, such as switching linear dynamical systems, structured mean-field approximations can be brought to bear on the kernel evaluation. For general distributions, even if an analytic expression for the kernel is not feasible, we show a straightforward sampling method to evaluate it. Thus, the kernel permits discriminative learning methods, including support vector machines, to exploit the properties, metrics and invariances of the generative models we infer from each datum. Experiments are shown using multinomial models for text, hidden Markov models for biological data sets and linear dynamical systems for time series data.	Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Jebara, T (reprint author), Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.	JEBARA@CS.COLUMBIA.EDU; RISI@CS.COLUMBIA.EDU; AHOWARD@CS.COLUMBIA.EDU					Bengio Y, 1996, IEEE T NEURAL NETWOR, V7, P1231, DOI 10.1109/72.536317; Bhattacharyya A., 1943, B CALCUTTA MATH SOC; COLLINS M, 2002, NEURAL INFORM PROCES, V14; CORTES C, 2002, NEURAL INFORM PROCES, V15; Cutting D.R., 1992, P ACM SIGIR; DAVIDSON R., 1993, ESTIMATION INFERENCE; Ghahramani Z, 1997, MACH LEARN, V29, P245, DOI 10.1023/A:1007425814087; GOLDZMIDT M, 1998, DATABAE GROUP PUBLIC, V60; Hastie T., 2001, ELEMENTS STAT LEARNI; Haussler D, 1999, UCSCCRL9910; JAAKKOLA T, 1998, NEURAL INFORM PROCES, V11; JAAKKOLA T, 1999, NEURAL INFORM PROCES, V12; Jaakkola T., 2000, ADV MEAN FIELD METHO; JEBARA T, 2003, C LEARN THEORY; JOACHIMS T, 2001, INT C MACH LEARN; JORDAN M, 2004, IN PRESS INTRO GRAPH; KASHIMA H, 2003, MACH LEARN 10 INT C; KONDOR R, 2003, MACH LEARN 10 INT C; LAFFERTY J, 2002, NEURAL INFORM PROCES; LESLIE C, 2002, NEURAL INFORM PROCES; MORENO PJ, 2004, NEURAL INFORM PROCES; Ong C., 2004, ICML; ONG C, 2002, NEURAL INFORM PROCES; PAVLOVIC V, 2000, NEURAL INFORM PROCES, V13, P981; Pearl J., 1997, PROBABILISTIC REASON; Platt J., 1999, ADV KERNEL METHODS S; Scholkopf B, 2002, LEARNING KERNELS; Scholkopf Bernard, 2001, LEARNING KERNELS SUP; Shumway R. H., 1982, Journal of Time Series Analysis, V3, DOI 10.1111/j.1467-9892.1982.tb00349.x; Silverman BW, 1986, DENSITY ESTIMATION S; TOPSOE F, 1999, J INEQUALITIES PURE, V2; Tsuda Koji, 2002, Bioinformatics, V18 Suppl 1, pS268; VAPNIK V, 1998, STT LERNING THEORY; VISHAWANATHAN SVN, 2002, NEURAL INFORM PROCES, V15; WATKINS C, 2000, ADV KERNEL METHODS	35	112	115	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	JUL	2004	5						819	844				26	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026GQ	WOS:000236327800004		
J	Bryan, J				Bryan, J			Problems in gene clustering based on gene expression data	JOURNAL OF MULTIVARIATE ANALYSIS			English	Article						cluster analysis; microarrays; confidence; bootstrap	NUMBER	In this work, we assess the suitability of cluster analysis for the gene grouping problem confronted with microarray data. Gene clustering is the exercise of grouping genes based on attributes, which are generally the expression levels over a number of conditions or subpopulations. The hope is that similarity with respect to expression is often indicative of similarity with respect to much more fundamental and elusive qualities, such as function. By formally defining the true gene-specific attributes as parameters, such as expected expression across the conditions, we obtain a well-defined gene clustering parameter of interest, which greatly facilitates the statistical treatment of gene clustering. We point out that genome-wide collections of expression trajectories often lack natural clustering structure, prior to ad hoc gene filtering. The gene filters in common use induce a certain circularity to most gene cluster analyses: genes are points in the attribute space, a filter is applied to depopulate certain areas of the space, and then clusters are sought (and often found!) in the "cleaned" attribute space. As a result, statistical investigations of cluster number and clustering strength are just as much a study of the stringency and nature of the filter as they are of any biological gene clusters. In the absence of natural clusters, gene clustering may still be a worthwhile exercise in data segmentation. In this context, partitions can be fruitfully encoded in adjacency matrices and the sampling distribution of such matrices can be studied with a variety of bootstrapping techniques. (C) 2003 Elsevier Inc. All rights reserved.	Univ British Columbia, Dept Stat, Vancouver, BC V6M 1L2, Canada; Univ British Columbia, Biotechnol Lab, Vancouver, BC V6M 1L2, Canada	Bryan, J (reprint author), Univ British Columbia, Dept Stat, 336-6356 Agr Rd, Vancouver, BC V6M 1L2, Canada.	jenny@stat.ubc.ca					BAETZ K, IN PRESS P NATL ACAD; Bryan J, 2002, STAT SINICA, V12, P87; BRYAN J, GENE CLASSIFICATION; CORMACK RM, 1971, J R STAT SOC SER A-G, V134, P321, DOI 10.2307/2344237; Dudoit S., 2002, GENOME BIOL, V3; Efron B, 1998, ANN STAT, V26, P1687; Efron B, 1996, P NATL ACAD SCI USA, V93, P13429, DOI 10.1073/pnas.93.23.13429; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Everitt B., 1974, CLUSTER ANAL; Everitt BS, 2001, CLUSTER ANAL; FELSENSTEIN J, 1985, EVOLUTION, V39, P783, DOI 10.2307/2408678; Hastie T., 2001, ELEMENTS STAT LEARNI; Huber Wolfgang, 2002, Bioinformatics, V18 Suppl 1, pS96; Ihaka R, 2005, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Irizarry RA, 2003, ANAL GENE EXPRESSION; JOHNDON RA, 2002, APPL MULTIVARIATE ST; Kaufman L., 1990, FINDING GROUPS DATA; KENDALL M, 1966, P S MULT AN DAYT OH, P165; Kerr MK, 2001, P NATL ACAD SCI USA, V98, P8961, DOI 10.1073/pnas.161273698; MILLIGAN GW, 1983, IEEE T PATTERN ANAL, V5, P40; Pollard KS, 2002, MATH BIOSCI, V176, P99, DOI 10.1016/S0025-5564(01)00116-X; Pritchard CC, 2001, P NATL ACAD SCI USA, V98, P13266, DOI 10.1073/pnas.221465998; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293; van der Laan M J, 2001, Biostatistics, V2, P445, DOI 10.1093/biostatistics/2.4.445; WAKEFIELD JC, 2003, BAYESIAN STAT, V7, P711	26	20	20	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0047-259X			J MULTIVARIATE ANAL	J. Multivar. Anal.	JUL	2004	90	1					44	66		10.1016/j.jmva.2004.02.011		23	Statistics & Probability	Mathematics	828IV	WOS:000221967900003		
J	Ruczinski, I; Kooperberg, C; LeBlanc, ML				Ruczinski, I; Kooperberg, C; LeBlanc, ML			Exploring interactions in high-dimensional genomic data: an overview of Logic Regression, with applications	JOURNAL OF MULTIVARIATE ANALYSIS			English	Article						adaptive model selection; Boolean logic; binary variables; interactions; single nucleotide polymorphisms	NON-HODGKINS-LYMPHOMA; SEQUENCE; MODEL	Logic Regression is an adaptive regression methodology mainly developed to explore high-order interactions in genomic data. Logic Regression is intended for situations where most of the covariates in the data to be analyzed are binary. The goal of Logic Regression is to find predictors that are Boolean (logical) combinations of the original predictors. In this article, we give an overview of the methodology and discuss some applications. We also describe the software for Logic Regression, which is available as an R and S-Plus package. (C) 2004 Elsevier Inc. All rights reserved.	Johns Hopkins Univ, Dept Biostat, Baltimore, MD 21205 USA; Fred Hutchinson Canc Res Ctr, Div Publ Hlth Sci, Seattle, WA 98109 USA	Ruczinski, I (reprint author), Johns Hopkins Univ, Dept Biostat, 615 N Wolfe St, Baltimore, MD 21205 USA.	ingo@jhu.edu					AARTS EHL, 1989, SIMULTED ANNEALING B; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chakravarti A, 1999, NAT GENET, V21, P56, DOI 10.1038/4482; Chipman HA, 1998, J AM STAT ASSOC, V93, P935, DOI 10.2307/2669832; Collins Francis S., 1998, SCIENCE, V282, P683; COX DR, 1972, J R STAT SOC B, V34, P187; Etzioni R, 2003, BIOSTATISTICS, V4, P523, DOI 10.1093/biostatistics/4.4.523; FISHER RI, 1993, NEW ENGL J MED, V328, P1002, DOI 10.1056/NEJM199304083281404; FLEISCHER H, 1983, IBM J RES DEV, V25, P412; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Hastie T., 2001, ELEMENTS STAT LEARNI; Kooperberg C, 2001, GENET EPIDEMIOL, V21, pS626; LEBLANC M, 1993, J AM STAT ASSOC, V88, P457, DOI 10.2307/2290325; LUCEK PR, 1997, GEN EPI, V514, pS1101; Ruczinski I., 2000, THESIS U WASHINGTON; Ruczinski I, 2003, J COMPUT GRAPH STAT, V12, P475, DOI 10.1198/1061860032238; SHIPP MA, 1993, NEW ENGL J MED, V329, P987; WIJSMAN EM, 2001, ANAL COMPLEX GENETIC, V21; Witte JS, 2001, GENET EPIDEMIOL, V21, pS600; Zee R. Y. L., 2002, Pharmacogenomics Journal, V2, P197, DOI 10.1038/sj.tpj.6500101	22	44	49	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0047-259X			J MULTIVARIATE ANAL	J. Multivar. Anal.	JUL	2004	90	1					178	195		10.1016/j.jmva.2004.02.010		18	Statistics & Probability	Mathematics	828IV	WOS:000221967900009		
J	Murata, N; Takenouchi, T; Kanamori, T; Eguchi, S				Murata, N; Takenouchi, T; Kanamori, T; Eguchi, S			Information geometry of U-Boost and Bregman divergence	NEURAL COMPUTATION			English	Article							APPROXIMATION BOUNDS; NETWORKS	We aim at an extension of AdaBoost to U-Boost, in the paradigm to build a stronger classification machine from a set of weak learning machines. A geometric understanding of the Bregman divergence defined by a generic convex function U leads to the U-Boost method in the framework of information geometry extended to the space of the finite measures over a label set. We propose two versions of U-Boost learning algorithms by taking account of whether the domain is restricted to the space of probability functions. In the sequential step, we observe that the two adjacent and the initial classifiers are associated with a right triangle in the scale via the Bregman divergence, called the Pythagorean relation. This leads to a mild convergence property of the U-Boost algorithm as seen in the expectation-maximization algorithm. Statistical discussions for consistency and robustness elucidate the properties of the U-Boost methods based on a stochastic assumption for training data.	Waseda Univ, Sch Sci & Engn, Shinjuku Ku, Tokyo 1698555, Japan; Grad Univ Adv Studies, Dept Stat Sci, Tokyo 1068569, Japan; Tokyo Inst Technol, Dept Math & Comp Sci, Tokyo 1528552, Japan; Grad Univ Adv Studies, Dept Stat Sci, Tokyo 1068569, Japan	Murata, N (reprint author), Waseda Univ, Sch Sci & Engn, Shinjuku Ku, Tokyo 1698555, Japan.	noboru.murata@eb.waseda.ac.jp; ttakashi@ism.ac.jp; kanamori@is.titech.ac.jp; eguchi@ism.ac.jp	Eguchi, Shinto/A-9103-2012; Murata, Noboru/J-3345-2012	Murata, Noboru/0000-0002-4258-6877			AMARI S, 2000, METHODS INFORMATION; Amari S.-I., 1985, DIFFERENTIAL GEOMETR; Amari SI, 1995, NEURAL NETWORKS, V8, P1379, DOI 10.1016/0893-6080(95)00003-8; BARRON AR, 1993, IEEE T INFORM THEORY, V39, P930, DOI 10.1109/18.256500; BISHOP C.M., 1995, NEURAL NETWORKS PATT; Collins M., 2000, P 13 ANN C COMP LEAR, P158; Domingo C., 2000, P 13 ANN C COMP LEAR, P180; Eguchi S, 2002, BIOMETRIKA, V89, P1, DOI 10.1093/biomet/89.1.1; EGUCHI S, 2001, 802 ISM; EGUCHI S, 2001, J KOREAN STAT SOC, V30, P247; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Hampel FR, 1986, ROBUST STAT; Hastie T., 2001, ELEMENTS STAT LEARNI; Kearns M., 1988, TR1488 HARV U AIK CO; Kivinen J., 1999, Proceedings of the Twelfth Annual Conference on Computational Learning Theory, DOI 10.1145/307400.307424; Lebanon G., 2001, CMUCS01144; McLachlan G., 1992, DISCRIMINANT ANAL ST; Minami M., 2002, NEURAL COMPUT, V14, P1859; Murata N, 1996, NEURAL NETWORKS, V9, P947, DOI 10.1016/0893-6080(96)00000-7; MURATA N, 1994, IEEE T NEURAL NETWOR, V5, P865, DOI 10.1109/72.329683; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; SCHATTEN G, 1998, J LAW MED ETHICS, V26, P5; TAKENOUCHI T, 2001, NEURAL COMPUT, V16, P767; Vapnik VN, 1995, NATURE STAT LEARNING	27	69	69	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	0899-7667			NEURAL COMPUT	Neural Comput.	JUL	2004	16	7					1437	1481		10.1162/089976604323057452		45	Computer Science, Artificial Intelligence	Computer Science	822AI	WOS:000221505300006	15165397	
J	Schwender, H; Zucknick, M; Ickstadt, K; Bolt, HM				Schwender, H; Zucknick, M; Ickstadt, K; Bolt, HM		GENICA Network	A pilot study on the application of statistical classification procedures to molecular epidemiological data	TOXICOLOGY LETTERS			English	Article						breast cancer; classification and regression trees (CART); classification; ensemble methods; single nucleotide polymorphism; support vector machines	CANCER; SUSCEPTIBILITY; GENES	The development of new statistical methods for use in molecular epidemiology comprises the building and application of appropriate classification rules. The aim of this study was to assess various classification methods that can potentially handle genetic interactions. A data set comprising genotypes at 25 single nucleotide polymorphic (SNP) loci from 518 breast cancer cases and 586 age-matched population-based controls from the GENICA study was used to built a classification rule with the discrimination methods SVM (support vector machine), CART (classification and regression tree), Bagging, Random Forest, LogitBoost and k nearest neighbours (kNN). A blind pilot analysis of the genotypic data set was a first approach to obtain an impression of the statistical structure of the data. Furthermore, this analysis was performed to explore classification methods that may be applied to molecular-epidemiological evaluation. The results showed that all blindly applied classification methods had a slightly smaller misclassification rate than a random classification. The findings, nevertheless, suggest that SNP data might be useful for the classification of individuals into categories of high or low risk of diseases. (C) 2004 Elsevier Ireland Ltd. All rights reserved.	Univ Dortmund, Dept Stat, Collaborat Res Ctr 475, D-44221 Dortmund, Germany; Univ London Imperial Coll Sci Technol & Med, Dept Biol Sci, London SW7 2AZ, England; Univ Dortmund, Inst Occupat Physiol, IfADo, D-44221 Dortmund, Germany	Schwender, H (reprint author), Univ Dortmund, Dept Stat, Collaborat Res Ctr 475, D-44221 Dortmund, Germany.	holgers@statistik.uni-dortmund.de					BRAUCH H, 2002, BREAST CANC RISK PRE, P148; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; FIX E, 1951, MACHINE RECOGNITION; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Garte S, 2001, CANCER EPIDEM BIOMAR, V10, P1233; Hastie T, 2001, ELEMENTS STAT LEARN; Perera FP, 2000, CARCINOGENESIS, V21, P517, DOI 10.1093/carcin/21.3.517; PERERA FP, 1982, J CHRON DIS, V35, P581, DOI 10.1016/0021-9681(82)90078-9; Pesch B, 2004, TOXICOL LETT, V151, P255, DOI 10.1016/j.toxlet.2004.02.020; Ritchie MD, 2001, AM J HUM GENET, V69, P138, DOI 10.1086/321276; THIER R, 2001, TRENDS PHARMACOL SCI, V11, P449; Thier R, 2002, TOXICOL LETT, V127, P321, DOI 10.1016/S0378-4274(01)00515-X; Vapnik VN, 1995, NATURE STAT LEARNING	16	20	21	ELSEVIER SCI IRELAND LTD	CLARE	CUSTOMER RELATIONS MANAGER, BAY 15, SHANNON INDUSTRIAL ESTATE CO, CLARE, IRELAND	0378-4274			TOXICOL LETT	Toxicol. Lett.	JUN 15	2004	151	1					291	299		10.1016/j.toxlet.2004.02.021		9	Toxicology	Toxicology	831WB	WOS:000222226100033	15177665	
J	de Hoon, MJL; Imoto, S; Nolan, J; Miyano, S				de Hoon, MJL; Imoto, S; Nolan, J; Miyano, S			Open source clustering software	BIOINFORMATICS			English	Article							GENE-EXPRESSION; PATTERNS	We have implemented k-means clustering, hierarchical clustering and self-organizing maps in a single multipurpose open-source library of C routines, callable from other C and C++ programs. Using this library, we have created an improved version of Michael Eisen's well-known Cluster program for Windows, Mac OS X and Linux/Unix. In addition, we generated a Python and a Perl interface to the C Clustering Library, thereby combining the flexibility of a scripting language with the speed of C.	Univ Tokyo, Inst Med Sci, Ctr Human Genome, Minato Ku, Tokyo 1088639, Japan; Univ Calif, Santa Cruz Extens Silicon Valley, Cupertino, CA 95014 USA	de Hoon, MJL (reprint author), Univ Tokyo, Inst Med Sci, Ctr Human Genome, Minato Ku, 4-6-1 Shirokanedai, Tokyo 1088639, Japan.	mdehoon@ims.u-tokyo.ac.jp	de Hoon, Michiel/A-6443-2013; Zhang, Ning/F-1387-2014				ASCHER D, 2001, NUMERICAL PHYTHON; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hastie T., 2001, ELEMENTS STAT LEARNI; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Kohonen T., 2001, SELF ORG MAPS; Press W.H., 1992, NUMERICAL RECIPES C; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Tavazoie S, 1999, NAT GENET, V22, P281	9	822	827	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	JUN 12	2004	20	9					1453	1454		10.1093/bioinformatics/bth078		2	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	830MF	WOS:000222125600013	14871861	
J	Thissen, U; Ustun, B; Melssen, WJ; Buydens, LMC				Thissen, U; Ustun, B; Melssen, WJ; Buydens, LMC			Multivariate calibration with least-squares support vector machines	ANALYTICAL CHEMISTRY			English	Article							INDUCED SPECTRAL VARIATION; RIDGE-REGRESSION; TEMPERATURE; SELECTION; SPECTROMETRY; MODELS	This paper proposes the use of least-squares support vector machines (LS-SVMs) as a relatively new nonlinear multivariate calibration method, capable of dealing with ill-posed problems. LS-SVMs are an extension of "traditional" SVMs that have been introduced recently in the field of chemistry and chemometrics. The advantages of SVM-based methods over many other methods are that these lead to global models that are often unique, and nonlinear regression can be performed easily as an extension to linear regression. An additional advantage of LS-SVM (compared to SVM) is that model calculation and optimization can be performed relatively fast. As a test case to study the use of LS-SVM, the well-known and important chemical problem is considered in which spectra are affected by nonlinear interferences. As one specific example, a commonly used case is studied in which near-infrared spectra are affected by temperature-induced spectral variation. Using this test case, model optimization, pruning, and model interpretation of the LS-SVM have been demonstrated. Furthermore, excellent performance of the LS-SVM, compared to other approaches, has been presented on the specific example. Therefore, it can be concluded that LS-SVMs can be seen as very promising techniques to solve ill-posed problems. Furthermore, these have been shown to lead to robust models in cases of spectral variations due to nonlinear interferences.	Univ Nijmegen, Analyt Chem Lab, NL-6525 ED Nijmegen, Netherlands	Buydens, LMC (reprint author), Univ Nijmegen, Analyt Chem Lab, Toemooiveld 1, NL-6525 ED Nijmegen, Netherlands.	lbuydens@sci.kun.nl	Buydens, Lutgarde/D-4338-2012				Belousov AI, 2002, CHEMOMETR INTELL LAB, V64, P15, DOI 10.1016/S0169-7439(02)00046-1; Belousov AI, 2002, J CHEMOMETR, V16, P482, DOI 10.1002/cem.744; Centner V, 2000, APPL SPECTROSC, V54, P608, DOI 10.1366/0003702001949816; Cristianini N, 2000, INTRO SUPPORT VECTOR; de Kruif BJ, 2003, IEEE T NEURAL NETWOR, V14, P696, DOI 10.1109/TNN.2003.810597; Despagne F, 2000, ANAL CHEM, V72, P1657, DOI 10.1021/ac991076k; Eilers PHC, 2003, CHEMOMETR INTELL LAB, V66, P159, DOI 10.1016/S0169-7439(03)00029-7; Estienne F, 2001, ANAL CHIM ACTA, V450, P123, DOI 10.1016/S0003-2670(01)01372-1; Felipe-Sotelo M, 2003, ANAL CHEM, V75, P5254, DOI 10.1021/ac0343477; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Gunn S.R., 1997, SUPPORT VECTOR MACHI; Gusnanto A, 2003, J CHEMOMETR, V17, P174, DOI 10.1002/cem.787; Hageman JA, 2003, J CHEMOMETR, V17, P427, DOI 10.1002/cem.782; Hastie T., 2001, ELEMENTS STAT LEARNI; HOERL AE, 1970, TECHNOMETRICS, V12, P55; LUKAS L, 2002, ESANN 2002 P EUR S A, P131; MARX BD, 2000, J CHEMOMETR, V16, P129; Pavon JLP, 2003, ANAL CHEM, V75, P6361, DOI 10.1021/ac034543d; PELCKMANS K, 2002, LSSVMLAB MATLAB C TO; Scholkopf B, 1999, IEEE T NEURAL NETWOR, V10, P1000, DOI 10.1109/72.788641; Scholkopf B, 2002, LEARNING KERNELS; SMOLA AJ, 1998, NCTR98030; Song MH, 2002, J CHEM INF COMP SCI, V42, P1347, DOI 10.1021/ci025580t; Suykens J. A. K., 2002, LEAST SQUARES SUPPOR; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Swierenga H, 2000, ANAL CHIM ACTA, V411, P121, DOI 10.1016/S0003-2670(00)00718-2; SWIERENGA H, 2000, THESIS U NIMEGEN NIM; THISSEN U, IN PRESS CHEMOM INTE; Thissen U., 2003, Chemometrics and Intelligent Laboratory Systems, V69, DOI 10.1016/S0169-7439(03)00111-4; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik VN, 1995, NATURE STAT LEARNING; Wentzell PD, 2003, CHEMOMETR INTELL LAB, V65, P257, DOI 10.1016/S0169-7439(02)00138-7; Witjes H, 2000, CHEMOMETR INTELL LAB, V52, P105, DOI 10.1016/S0169-7439(00)00085-X; Wulfert F, 2000, ANAL CHEM, V72, P1639, DOI 10.1021/ac9906835; Wulfert F, 2000, CHEMOMETR INTELL LAB, V51, P189, DOI 10.1016/S0169-7439(00)00069-1; Wulfert F, 1998, ANAL CHEM, V70, P1761, DOI 10.1021/ac9709920; ZHU J, NEURAL INFORMATION P	38	116	118	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0003-2700			ANAL CHEM	Anal. Chem.	JUN 1	2004	76	11					3099	3105		10.1021/ac035522m		7	Chemistry, Analytical	Chemistry	825KH	WOS:000221755200024	15167788	
J	Wolfe, P; Murphy, J; McGinley, J; Zhu, ZJ; Jiang, WQ; Gottschall, EB; Thompson, HJ				Wolfe, P; Murphy, J; McGinley, J; Zhu, ZJ; Jiang, WQ; Gottschall, EB; Thompson, HJ			Using nuclear morphometry to discriminate the tumorigenic potential of cells: A comparison of statistical methods	CANCER EPIDEMIOLOGY BIOMARKERS & PREVENTION			English	Article							URINARY-TRACT LESIONS; IMAGE-ANALYSIS; NEURAL-NETWORKS; IN-SITU; CANCER; CLASSIFICATION; CHEMOPREVENTION; EFFICIENCY; PATHOLOGY; DIAGNOSIS	Despite interest in the use of nuclear morphometry for cancer diagnosis and prognosis as well as to monitor changes in cancer risk, no generally accepted statistical method has emerged for the analysis of these data. To evaluate different statistical approaches, Feulgen-stained nuclei from a human lung epithelial cell line, BEAS-2B, and a human lung adenocarcinoma (non-small cell) cancer cell line, NCI-H522, were subjected to morphometric analysis using a CAS-200 imaging system. The morphometric characteristics of these two cell lines differed significantly. Therefore, we proceeded to address the question of which statistical approach was most effective in classifying individual cells into the cell lines from which they were derived. The statistical techniques evaluated ranged from simple, traditional, parametric approaches to newer machine learning techniques. The multivariate techniques were compared based on a systematic cross-validation approach using 10 fixed partitions of the data to compute the misclassification rate for each method. For comparisons across cell lines at the level of each morphometric feature, we found little to distinguish nonparametric from parametric approaches. Among the linear models applied, logistic regression had the highest percentage of correct classifications; among the nonlinear and nonparametric methods applied, the Classification and Regression Trees model provided the highest percentage of correct classifications. Classification and Regression Trees has appealing characteristics: there are no assumptions about the distribution of the variables to be used, there is no need to specify which interactions to test, and there is no difficulty in handling complex, high-dimensional data sets containing mixed data types.	Colorado State Univ, Canc Prevent Lab, Ft Collins, CO 80523 USA; Natl Jewish Med & Res Ctr, Dept Biometr, Denver, CO USA; Natl Jewish Med & Res Ctr, Dept Occupat Med, Denver, CO USA	Wolfe, P (reprint author), Colorado State Univ, Canc Prevent Lab, 111 Shepardson Bldg,1173 Campus Delivery, Ft Collins, CO 80523 USA.	wolfep@earthlink.net	Thompson, Henry/K-7242-2012	Thompson, Henry/0000-0002-3730-9322			Acker SM, 1998, J AM ACAD DERMATOL, V39, P239, DOI 10.1016/S0190-9622(98)70082-9; BAAK JPA, 1987, ANAL QUANT CYTOL, V9, P89; Bacus J W, 1997, J Cell Biochem Suppl, V28-29, P21; Bacus J W, 1995, J Cell Biochem Suppl, V23, P33; Bacus JW, 1999, CANCER EPIDEM BIOMAR, V8, P1087; BARON AE, 1991, STAT MED, V10, P757, DOI 10.1002/sim.4780100511; Boone CW, 2000, CANCER EPIDEM BIOMAR, V9, P495; Boone C W, 1997, J Cell Biochem Suppl, V28-29, P1; Breiman L., 1998, CLASSIFICATION REGRE; BULL SB, 1987, J AM STAT ASSOC, V82, P1118, DOI 10.2307/2289389; CARR I, 1991, CLIN EXP METASTAS, V9, P127, DOI 10.1007/BF01756384; COLLAN Y, 1987, ANAL QUANT CYTOL, V9, P79; Doudkine A., 1995, Pathologica (Genoa), V87, P286; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; EFRON B, 1975, J AM STAT ASSOC, V70, P892, DOI 10.2307/2285453; Gil J, 2002, MICROSC RES TECHNIQ, V59, P109, DOI 10.1002/jemt.10182; GURLEY AM, 1990, CYTOMETRY, V11, P468, DOI 10.1002/cyto.990110404; Hamilton PW, 1995, ANAL QUANT CYTOL, V17, P397; Hand D. J., 1981, DISCRIMINATION CLASS; Harrell FE, 2001, REGRESSION MODELING; Hastie T., 2001, ELEMENTS STAT LEARNI; HOSMER DW, 2000, APPL LOGISTIC  REGRE; Kavantzas N, 2000, J EXP CLIN CANC RES, V19, P201; Markopoulos C, 1997, ANAL QUANT CYTOL, V19, P453; MARSHALL G, 1994, STAT MED, V13, P1501, DOI 10.1002/sim.4780131502; MCGINLEY JN, 2001, QUANTITATIVE ASSESSM; Millot C, 2000, HISTOL HISTOPATHOL, V15, P1185; Morrison DF, 1990, MULTIVARIATE STAT ME; Nelson LM, 1998, J CLIN EPIDEMIOL, V51, P199, DOI 10.1016/S0895-4356(97)00268-0; Palcic B, 1994, J Cell Biochem Suppl, V19, P40; Pantazopoulos D, 1998, J UROLOGY, V159, P1619, DOI 10.1097/00005392-199805000-00057; Pantazopoulos D, 1998, BRIT J UROL, V81, P574; Pantazopoulos D, 1998, UROLOGY, V51, P946, DOI 10.1016/S0090-4295(98)00024-7; Poulin N, 1999, CYTOMETRY, V38, P214, DOI 10.1002/(SICI)1097-0320(19991015)38:5<214::AID-CYTO3>3.0.CO;2-6; POULIN N, 1995, ANAL QUANT CYTOL, V17, P291; Qu YS, 2002, CLIN CHEM, V48, P1835; Thiele J, 1998, EUR J HAEMATOL, V60, P35; Veltri R W, 2000, J Cell Biochem Suppl, VSuppl 35, P151; Veltri RW, 1996, UROLOGY, V48, P685, DOI 10.1016/S0090-4295(96)00370-6; WESTFALL P. H., 1993, RESAMPLING BASED MUL; Westfall P.H., 1999, MULTIPLE COMPARISONS	41	19	20	AMER ASSOC CANCER RESEARCH	PHILADELPHIA	615 CHESTNUT ST, 17TH FLOOR, PHILADELPHIA, PA 19106-4404 USA	1055-9965			CANCER EPIDEM BIOMAR	Cancer Epidemiol. Biomarkers Prev.	JUN	2004	13	6					976	988				13	Oncology; Public, Environmental & Occupational Health	Oncology; Public, Environmental & Occupational Health	826ZL	WOS:000221867900013	15184254	
J	White, TA; Kell, DB				White, TA; Kell, DB			Comparative genomic assessment of novel broad-spectrum targets for antibacterial drugs	COMPARATIVE AND FUNCTIONAL GENOMICS			English	Article						genomics; antibacterial; antimicrobial; pathogen; virulence; comparative genomics; antibiotics; bioinformatics	SIGNAL-TRANSDUCTION SYSTEMS; INITIATION-FACTOR IF1; ESCHERICHIA-COLI; STAPHYLOCOCCUS-AUREUS; ANTIBIOTIC DISCOVERY; MICROBIAL GENOMICS; BACILLUS-ANTHRACIS; RIBOSOMAL-SUBUNIT; GENE-EXPRESSION; VIRULENCE	Single and multiple resistance to antibacterial drugs currently in use is spreading, since they act against only a very small number of molecular targets; finding novel targets for anti-infectives is therefore of great importance. All protein sequences from three pathogens (Staphylococcus aureus, Mycobacterium tuberculosis and Escherichia coli O157:H7 EDL993) were assessed via comparative genomics methods for their suitability as antibacterial targets according to a number of criteria, including the essentiality of the protein, its level of sequence conservation, and its distribution in pathogens, bacteria and eukaryotes (especially humans). Each protein was scored and ranked based on weighted variants of these criteria in order to prioritize proteins as potential novel broad-spectrum targets for antibacterial drugs. A number of proteins proved to score highly in all three species and were robust to variations in the scoring system used. Sensitivity analysis indicated the quantitative contribution of each metric to the overall score. After further analysis of these targets, tRNA methyltransferase (trmD) and translation initiation factor IF-1 (infA) emerged as potential and novel antimicrobial targets very worthy of further investigation. The scoring strategy used might be of value in other areas of post-genomic drug discovery. Copyright (C) 2004 John Wiley Sons, Ltd.	UMIST, Dept Chem, Manchester M60 1QD, Lancs, England; Univ York, Dept Biol, York YO10 5YW, N Yorkshire, England	Kell, DB (reprint author), UMIST, Dept Chem, Faraday Bldg,Sackville St,POB 88, Manchester M60 1QD, Lancs, England.	dbk@umist.ac.uk	Kell, Douglas/E-8318-2011; White, Tom/B-3016-2011	Kell, Douglas/0000-0001-5838-7963; 			Ahn HJ, 2003, EMBO J, V22, P2593, DOI 10.1093/emboj/cdg269; Alksne LE, 2002, EXPERT OPIN INV DRUG, V11, P1149, DOI 10.1517/13543784.11.8.1149; Allsop A, 2002, J APPL MICROBIOL, V92, P7, DOI 10.1046/j.1365-2672.2002.01483.x; Allsop AE, 1998, CURR OPIN MICROBIOL, V1, P530, DOI 10.1016/S1369-5274(98)80085-4; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Bouhss A, 1997, BIOCHEMISTRY-US, V36, P11556, DOI 10.1021/bi970797f; Brunder W, 2001, INFECT IMMUN, V69, P4447, DOI 10.1128/IAI.69.7.4447-4457.2001; Buysse JM, 2001, CURR MED CHEM, V8, P1713; CHITTUM HS, 1995, CURR MICROBIOL, V30, P273, DOI 10.1007/BF00295501; Chopra I, 2002, J APPL MICROBIOL, V92, p4S, DOI 10.1046/j.1365-2672.92.5s1.13.x; Coello C. A. C., 2002, EVOLUTIONARY ALGORIT; CUMMINGS HS, 1994, J BACTERIOL, V176, P198; Dahlquist KD, 2000, J MOL BIOL, V299, P1, DOI 10.1006/jmbi.2000.3672; Dasgupta P., 1999, MULTIOBJECTIVE HEURI; DAVIES J, 1994, SCIENCE, V264, P375, DOI 10.1126/science.8153624; Deb K., 2001, MULTI OBJECTIVE OPTI; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dougherty TJ, 2002, CURR PHARM DESIGN, V8, P1119, DOI 10.2174/1381612023394782; Dunman PM, 2001, J BACTERIOL, V183, P7341, DOI 10.1128/JB.183.24.7341-7353.2001; EGEBJERG J, 1989, EMBO J, V8, P607; El Zoeiby A, 2003, MOL MICROBIOL, V47, P1, DOI 10.1046/j.1365-2958.2003.03289.x; Fell D. A, 1996, UNDERSTANDING CONTRO; Forsyth RA, 2002, MOL MICROBIOL, V43, P1387, DOI 10.1046/j.1365-2958.2002.02832.x; Giaever G, 1999, NAT GENET, V21, P278, DOI 10.1038/6791; Gillies D. A., 1996, ARTIFICIAL INTELLIGE; Glass JI, 2002, CURR OPIN MICROBIOL, V5, P338, DOI 10.1016/S0959-4388(02)90328-4; GRIBSKOV M, 1992, GENE, V119, P107, DOI 10.1016/0378-1119(92)90073-X; Hancock REW, 1998, CURR OPIN MICROBIOL, V1, P493, DOI 10.1016/S1369-5274(98)80079-9; Haney SA, 2002, CURR PHARM DESIGN, V8, P1099, DOI 10.2174/1381612023394845; Hastie T., 2001, ELEMENTS STAT LEARNI; Heinemann JA, 1999, DRUG DISCOV TODAY, V4, P72, DOI 10.1016/S1359-6446(98)01294-X; Heinrich R, 1996, REGULATION CELLULAR; Hoffmaster AR, 1999, J APPL MICROBIOL, V87, P279, DOI 10.1046/j.1365-2672.1999.00887.x; Hopkins AL, 2002, NAT REV DRUG DISCOV, V1, P727, DOI 10.1038/nrd892; Inoue R, 2001, MOL GENET GENOMICS, V266, P564, DOI 10.1007/s004380100564; Isaacson RE, 2002, CURR PHARM DESIGN, V8, P1091, DOI 10.2174/1381612023394764; Ji YD, 2002, PHARMACOGENOMICS, V3, P315, DOI 10.1517/14622416.3.3.315; KELL DB, 1986, FEMS MICROBIOL LETT, V39, P305, DOI 10.1111/j.1574-6968.1986.tb01863.x; KELL DB, 2000, BIOESSAYS, V26, P99; Knowles DJC, 1998, ADV EXP MED BIOL, V456, P183; Knowles J. D., 2001, P 1 INT C EV MULT CR, P269; Kobayashi K, 2003, P NATL ACAD SCI USA, V100, P4678, DOI 10.1073/pnas.0730515100; Koehler TM, 2002, CURR TOP MICROBIOL, V271, P143; Kornder JD, 2002, MED HYPOTHESES, V58, P34, DOI 10.1054/mehy.2001.1450; Kumar S, 2001, BIOINFORMATICS, V17, P1244, DOI 10.1093/bioinformatics/17.12.1244; Lin AH, 1997, ANTIMICROB AGENTS CH, V41, P2127; Lipinski CA, 2001, ADV DRUG DELIVER REV, V46, P3, DOI 10.1016/S0169-409X(00)00129-0; Marmor S, 2001, BIOCHEMISTRY-US, V40, P12207, DOI 10.1021/bi015567m; McDevitt D, 2001, TRENDS MICROBIOL, V9, P611, DOI 10.1016/S0966-842X(01)02235-1; Mitchell T., 1997, MACHINE LEARNING; Mjolsness E, 2001, SCIENCE, V293, P2051, DOI 10.1126/science.293.5537.2051; NEU H, 1996, MED MICROBIOLOGY; Oneyama C, 2002, ONCOGENE, V21, P2037, DOI 10.1038/sj/onc/1205271; Paulmurugan R, 2004, CANCER RES, V64, P2113, DOI 10.1158/0008-5472.CAN-03-2972; Payne D J, 2001, Curr Opin Investig Drugs, V2, P1028; Payne DJ, 2001, DRUG DISCOV TODAY, V6, P537, DOI 10.1016/S1359-6446(01)01774-3; Projan SJ, 2002, CURR OPIN PHARMACOL, V2, P513, DOI 10.1016/S1471489202001972; Sassetti CM, 2003, MOL MICROBIOL, V48, P77, DOI 10.1046/j.1365-2958.2003.03425.x; Schmid MB, 1998, CURR OPIN CHEM BIOL, V2, P529, DOI 10.1016/S1367-5931(98)80130-0; Schnappinger D, 1996, ARCH MICROBIOL, V165, P359, DOI 10.1007/s002030050339; Sharma VK, 2003, VET MICROBIOL, V93, P247, DOI 10.1016/S0378-1135(03)00039-7; Spaltmann F, 1999, DRUG DISCOV TODAY, V4, P17, DOI 10.1016/S1359-6446(98)01278-1; Stephenson K, 2002, CURR OPIN PHARMACOL, V2, P507, DOI 10.1016/S1471-4892(02)00194-7; Stephenson K, 2004, CURR MED CHEM, V11, P765, DOI 10.2174/0929867043455765; Struelens MJ, 1998, BRIT MED J, V317, P652; Stuber K, 2003, MOL CELL PROBE, V17, P25, DOI 10.1016/S0890-8508(02)00108-1; Sun YH, 2000, NAT MED, V6, P1269; Tanner ME, 1996, J ORG CHEM, V61, P1756, DOI 10.1021/jo951780a; Terstappen GC, 2001, TRENDS PHARMACOL SCI, V22, P23, DOI 10.1016/S0165-6147(00)01584-4; Thompson JD, 1997, NUCLEIC ACIDS RES, V25, P4876, DOI 10.1093/nar/25.24.4876; Triccas JA, 2000, IMMUNOL CELL BIOL, V78, P311, DOI 10.1046/j.1440-1711.2000.00934.x; Wang GH, 2002, J CLIN MICROBIOL, V40, P3613, DOI 10.1128/JCM.40.10.3613-3619.2002; WEBER W, 1990, PLANTA MED, V56, P446, DOI 10.1055/s-2006-961008; Willins DA, 2002, CURR PHARM DESIGN, V8, P1137, DOI 10.2174/1381612023394890; Zambrowicz BP, 2003, NAT REV DRUG DISCOV, V2, P38, DOI 10.1038/nrd987; Zitzler E, 1999, EVOLUTIONARY ALGORIT	78	16	20	JOHN WILEY & SONS LTD	CHICHESTER	THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND	1531-6912			COMP FUNCT GENOM	Compar. Funct. Genom.	JUN	2004	5	4					304	327		10.1002/cfg.411		24	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Genetics & Heredity	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Genetics & Heredity	831YA	WOS:000222231600001	18629165	
J	Loog, M; Duin, RPW				Loog, M; Duin, RPW			Linear dimensionality reduction via a heteroscedastic extension of LDA: The Chernoff criterion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						linear dimension reduction; linear discriminant analysis; Fisher criterion; Chernoff distance; Chernoff criterion	STATISTICAL PATTERN-RECOGNITION; CLASSIFICATION; DISTANCE	We propose an eigenvector-based heteroscedastic linear dimension reduction (LDR) technique for multiclass data. The technique is based on a heteroscedastic two-class technique which utilizes the so-called Chernoff criterion, and successfully extends the well-known linear discriminant analysis (LDA). The latter, which is based on the Fisher criterion, is incapable of dealing with heteroscedastic data in a proper way. For the two-class case, the between-class scatter is generalized so to capture differences in (co)variances. It is shown that the classical notion of between-class scatter can be associated with Euclidean distances between class means. From this viewpoint, the between-class scatter is generalized by employing the Chernoff distance measure, leading to our proposed heteroscedastic measure. Finally, using the results from the two-class case, a multiclass extension of the Chernoff criterion is proposed. This criterion combines separation information present in the class mean as well as the class covariance matrices. Extensive experiments and a comparison with similar dimension reduction techniques are presented.	Univ Med Ctr Utrecht, Image Sci Inst, NL-3508 GA Utrecht, Netherlands; Delft Univ Technol, Fac Elect Engn Math & Comp Sci, Informat & Commun Theory Grp, NL-2600 GA Delft, Netherlands	Loog, M (reprint author), Univ Med Ctr Utrecht, Image Sci Inst, E-01-335,POB 85500, NL-3508 GA Utrecht, Netherlands.	marco@isi.uu.nl; r.p.w.duin@ewi.tudelft.nl					AEBERHARD S, 1994, PATTERN RECOGN, V27, P1065, DOI 10.1016/0031-3203(94)90145-7; Brunzell H, 2000, PATTERN RECOGN, V33, P1741, DOI 10.1016/S0031-3203(99)00142-9; BUTUROVIC LJ, 1994, IEEE T PATTERN ANAL, V16, P420, DOI 10.1109/34.277596; CHEN CH, 1976, INFORM SCIENCES, V10, P159, DOI 10.1016/S0020-0255(76)90746-5; CHUNG JK, 1989, J MATH ANAL APPL, V138, P280, DOI 10.1016/0022-247X(89)90335-1; Cover T. M., 1991, ELEMENTS INFORMATION; Decell H. P.  Jr., 1977, Computers & Mathematics with Applications, V3, DOI 10.1016/0898-1221(77)90116-X; Devijver P. A., 1982, PATTERN RECOGNITION; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fukunaga K, 1990, INTRO STAT PATTERN R; Hastie T., 2001, ELEMENTS STAT LEARNI; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; KUMAR N., 1996, P JOINT M AM STAT AS; Liu XW, 2003, PROC CVPR IEEE, P229; Loog M, 2001, IEEE T PATTERN ANAL, V23, P762, DOI 10.1109/34.935849; Loog M., 1999, WBBM REPORT SERIES, V44; Loog M., 2002, P 4 JOINT IAPR INT W, P508; McLachlan G., 1992, DISCRIMINANT ANAL ST; Murphy P. M., 2004, UCI REPOSITORY MACHI; Okada T., 1984, Electronics and Communications in Japan, V67, DOI 10.1002/ecja.4400670603; RAO CR, 1948, J ROY STAT SOC B, V10, P159; Rice JA, 1995, MATH STAT DATA ANAL; Rohl M., 1998, Proc. Gesellschaft Klassifikat., P252; TUBBS JD, 1982, PATTERN RECOGN, V15, P167, DOI 10.1016/0031-3203(82)90068-1	24	149	154	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2004	26	6					732	739				8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	811EZ	WOS:000220756500007	18579934	
J	Foster, DP; Stine, RA				Foster, DP; Stine, RA			Variable selection in data mining: Building a predictive model for bankruptcy	JOURNAL OF THE AMERICAN STATISTICAL ASSOCIATION			English	Article						AIC; bonferroni; Cp; calibration; hard thresholding; risk inflation criterion (RIC); step-down testing; stepwise regression	REGRESSION; INFLATION; DISCOVERY; CREDIT	We predict the onset of personal bankruptcy using least squares regression. Although well publicized, only 2,244 bankruptcies occur in our dataset of 2.9 million months of credit-card activity. We use stepwise selection to find predictors of these from a mix of payment history. debt load. demographics, and their interactions. This combination of rare responses and over 67,000 possible predictors leads to a challenging modeling question: How does one separate coincidental from useful predictors? We show that three modifications turn stepwise regression into an effective methodology for predicting bankruptcy. Our version of stepwise regression (1) organizes calculations to accommodate interactions, (2) exploits modern decision theoretic criteria to choose predictors, and (3) conservatively estimates p-values to handle sparse data and a binary response. Omitting any one of these leads to poor performance. A final step in our procedure calibrates regression predictions. With these modifications, stepwise regression predicts bankruptcy as well as, if not better than, recently developed data-mining tools. When sorted. the largest 14,000 resulting predictions hold 1,000 of the 1,800 bankruptcies hidden in a validation sample of 2.3 million observations. If the cost of missing a bankruptcy is 200 times that of a false positive. our predictions incur less than 2/3 of the costs of classification errors produced by the tree-based classifier C4.5.	Univ Penn, Wharton Sch, Dept Stat, Philadelphia, PA 19104 USA	Foster, DP (reprint author), Univ Penn, Wharton Sch, Dept Stat, Philadelphia, PA 19104 USA.	stine@wharton.upenn.edu					ABRAMOVICH F, 2000, 200019 STANF U DEP S; Akaike H, 1973, 2 INT S INF THEOR, P261; BARLOW R. E., 1972, STAT INFERENCE ORDER; BASTOS E, 2003, UNPUB DATA MINING BR; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; BENNETT G, 1962, J AM STAT ASSOC, V57, P33, DOI 10.2307/2282438; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; CHENG B, 1994, STAT SCI, V9, P2, DOI 10.1214/ss/1177010638; Cook RD, 2001, TECHNOMETRICS, V43, P443, DOI 10.1198/00401700152672537; Curnow G, 1997, INTERFACES, V27, P29, DOI 10.1287/inte.27.1.29; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Fayyad U, 1996, COMMUN ACM, V39, P24, DOI 10.1145/240455.240463; FOSTER DP, 1996, 1180 NW U CTR MATH S; FOSTER DP, 2002, UNPUB HARD THRESHOLD; FOSTER DP, 1994, ANN STAT, V22, P1947, DOI 10.1214/aos/1176325766; FREEDMAN DA, 1983, AM STAT, V37, P152, DOI 10.2307/2685877; Georgiev G, 2000, ANZ SCHADL-J PEST SC, V73, P1; GOODNIGHT JH, 1979, AM STAT, V33, P149, DOI 10.2307/2683825; Gross DB, 2002, REV FINANC STUD, V15, P319, DOI 10.1093/rfs/15.1.319; Gustafson P, 2000, J AM STAT ASSOC, V95, P795; Hand DJ, 1997, J R STAT SOC A STAT, V160, P523; Hand DJ, 2000, STAT SCI, V15, P111; HAND D.J., 1997, CONSTRUCTION ASSESSM; HAND DJ, 2002, SCORECARD CONSTRUCTI; Hand DJ, 2003, AM STAT, V57, P124, DOI 10.1198/0003130031423; Hastie T., 2001, ELEMENTS STAT LEARNI; JOHNSTONE I, 2002, EMPIRICAL BAYES SELE; Jones MP, 1996, J AM STAT ASSOC, V91, P222, DOI 10.2307/2291399; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; McQuarrie A. D., 1998, REGRESSION TIME SERI; Miller A., 2002, SUBSET SELECTION REG; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; RENCHER AC, 1980, TECHNOMETRICS, V22, P49, DOI 10.2307/1268382; SIMES RJ, 1986, BIOMETRIKA, V73, P751, DOI 10.2307/2336545; STOKER TM, 1986, ECONOMETRICA, V54, P1461, DOI 10.2307/1914309; Thisted R.A., 1988, ELEMENTS STAT COMPUT; THOMAS L, 2002, CREDIT SCORING ITS A; WANG L, 2002, THESIS U PENNSYLVANI	38	34	34	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	0162-1459			J AM STAT ASSOC	J. Am. Stat. Assoc.	JUN	2004	99	466					303	313		10.1198/016214504000000287		11	Statistics & Probability	Mathematics	822WY	WOS:000221572500001		
J	Lange, T; Roth, V; Braun, ML; Buhmann, JM				Lange, T; Roth, V; Braun, ML; Buhmann, JM			Stability-based validation of clustering solutions	NEURAL COMPUTATION			English	Article							GENE-EXPRESSION; MOLECULAR CLASSIFICATION; PATTERNS	Data clustering describes a set of frequently employed techniques in exploratory data analysis to extract "natural" group structure in data. Such groupings need to be validated to separate the signal in the data from spurious structure. in this context, finding an appropriate number of clusters is a particularly important model selection question. We introduce a measure of cluster stability to assess the validity of a cluster model. This stability measure quantifies the reproducibility of clustering solutions on a second sample, and it can be interpreted as a classification risk with regard to class labels produced by a clustering algorithm. The preferred number of clusters is determined by minimizing this classification risk as a function of the number of clusters. Convincing results are achieved on simulated as well as gene expression data sets. Comparisons to other methods demonstrate the competitive performance of our method and its suitability as a general validation tool for clustering solutions in real-world problems.	ETH, Iinst Computat Sci, CH-8092 Zurich, Switzerland; Univ Bonn, Inst Informat 3, D-53117 Bonn, Germany	Lange, T (reprint author), ETH, Iinst Computat Sci, CH-8092 Zurich, Switzerland.	tilman.lange@info.ethz.ch; volker.roth@info.ethz.ch; braunm@cs.uni-bonn.de; jbuhmann@info.ethz.ch					Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Ben-Hur Asa, 2002, Pac Symp Biocomput, P6; Bittner M, 2000, NATURE, V406, P536, DOI 10.1038/35020115; BRECKENRIDGE JN, 1989, MULTIVAR BEHAV RES, V24, P147, DOI 10.1207/s15327906mbr2402_1; Buhmann J.M., 1995, HDB BRAIN THEORY NEU, P278; Duda R. O., 2000, PATTERN CLASSIFICATI; Dudoit S, 2002, GENOME BIOL, V3, DOI 10.1186.; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; FISCHER B, 2001, LNCS ENERGY MINIMIZA; FOWLKES EB, 1983, J AM STAT ASSOC, V78, P553, DOI 10.2307/2288117; Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gordon A. D., 1999, CLASSIFICATION; Hastie T., 2001, ELEMENTS STAT LEARNI; Hofmann T, 1997, IEEE T PATTERN ANAL, V19, P1, DOI 10.1109/34.566806; Iyer VR, 1999, SCIENCE, V283, P83, DOI 10.1126/science.283.5398.83; Jain A., 1999, ACM COMPUT SURV, V31; Jain A, 1988, ALGORITHMS CLUSTERIN; Kuhn HW, 1955, NAV RES LOG, V2, P83, DOI DOI 10.1002/NAV.3800020109; Lander ES, 1999, NAT GENET, V21, P3, DOI 10.1038/4427; Lange T., 2003, ADV NEURAL INFORMATI, V15, P617; Levine E, 2001, NEURAL COMPUT, V13, P2573, DOI 10.1162/089976601753196030; LEVINE E, 1999, THESIS WEIZMANN I SC; ROSE K, 1992, IEEE T INFORM THEORY, V38, P1249, DOI 10.1109/18.144705; ROTH V, IN PRESS IEEE T BIOM; Shamir R., 2001, CURRENT TOPICS COMPU; SHARAN R, 2000, ISMB 00, P307; SMYTH P, 1998, 9809 U CAL INF COMP; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293; Tibshirani R., 2001, CLUSTER VALIDATION P; Yeung KY, 2001, BIOINFORMATICS, V17, P309, DOI 10.1093/bioinformatics/17.4.309	32	144	147	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	0899-7667			NEURAL COMPUT	Neural Comput.	JUN	2004	16	6					1299	1323		10.1162/089976604773717621		25	Computer Science, Artificial Intelligence	Computer Science	816IZ	WOS:000221104900008	15130251	
J	Gorriz, JM; Puntonet, CG; Salmeron, M; de la Rosa, JJG				Gorriz, JM; Puntonet, CG; Salmeron, M; de la Rosa, JJG			A new model for time-series forecasting using radial basis functions and exogenous data	NEURAL COMPUTING & APPLICATIONS			English	Article							INDEPENDENT COMPONENT ANALYSIS; GENETIC ALGORITHMS; SEPARATION	In this paper, we present a new model for time-series forecasting using radial basis functions (RBFs) as a unit of artificial neural networks (ANNs), which allows the inclusion of exogenous information (EI) without additional pre-processing. We begin by summarizing the most well-known El techniques used ad hoc, i.e., principal component analysis (PCA) and independent component analysis (ICA). We analyze the advantages and disadvantages of these techniques in time-series forecasting using Spanish bank and company stocks. Then, we describe a new hybrid model for time-series forecasting which combines ANNs with genetic algorithms (GAs). We also describe the possibilities when implementing the model on parallel processing systems.	Univ Cadiz, Dept Syst Engn & Automat, Cadiz, Spain; Univ Granada, Dept Comp Architecture & Comp Technol, E-18071 Granada, Spain	Gorriz, JM (reprint author), Univ Cadiz, Dept Syst Engn & Automat, Cadiz, Spain.	juanmanuel.gorriz@uca.es; carlos@atc.ugr.es	Puntonet, Carlos/B-1837-2012; Prieto, Ignacio/B-5361-2013; Gorriz, Juan/C-2385-2012				Amari S, 1996, ADV NEUR IN, V8, P757; Back AD, 2001, IEEE T NEURAL NETWOR, V12, P612, DOI 10.1109/72.925564; BACK AD, 1997, P 5 INT C NEUR NETW; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; Box G. E. P., 1994, TIME SERIES ANAL; Cao LJ, 2003, NEUROCOMPUTING, V51, P321, DOI 10.1016/S0925-2312(02)00577-5; CHAO L, 1994, IEEE T SIGNAL PROCES, V42, P927; Chen S., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.687886; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; EIBEN AE, 1991, LECT NOTES COMPUT SC, V496, P4; HAGGSTROM O, 1998, FINTIE MARKOV CHAINS; HASTIE T., 2000, ELEMENTS STAT LEARNI; Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Kuhn HW, 1951, P 2 BERK S MATH STAT, P481; Lozano JA, 1999, THEOR COMPUT SCI, V229, P11, DOI 10.1016/S0304-3975(99)00090-0; Mansour A, 2002, SIGNAL PROCESS, V82, P1155, DOI 10.1016/S0165-1684(02)00250-5; MASTERS T, 1995, EURAL NOVEL HYBRID A; MATWIN S, 1991, IEEE T SYST MAN CYB, V21, P102, DOI 10.1109/21.101141; Michalewicz Z, 1992, GENETIC ALGORITHMS D; Moody J., 1989, NEURAL COMPUT, V1, P284; Muller K., 1997, P INT C ART NEUR NET, P999; Muller KR, 1999, ADVANCES IN KERNEL METHODS, P243; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Platt J., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.213; Pollock D.S.G., 1999, HDB TIME SERIES ANAL; PUNTONET CG, 1994, THESIS U GRANADA DEP; PUNTONET CG, 2001, IEICE T FUND ELECTR, V84, P2539; RODRIGUEZALVARE.M, 2001, LECT NOTES COMPUTERS, V2085, P762; RUDOLPH G, 1994, IEEE T NEURAL NETWOR, V5, P96, DOI 10.1109/72.265964; SAEZ JMG, 2003, THESIS U CADIZ; Salmeron M, 2001, NEUROCOMPUTING, V41, P153, DOI 10.1016/S0925-2312(00)00363-5; SALMERONCAMPOS M, 2001, THESIS U GRANADA; Schmitt LM, 2001, THEOR COMPUT SCI, V259, P1, DOI 10.1016/S0304-3975(00)00406-0; Schmitt LM, 1998, THEOR COMPUT SCI, V200, P101, DOI 10.1016/S0304-3975(98)00004-8; Smola AJ, 1998, NEURAL NETWORKS, V11, P637, DOI 10.1016/S0893-6080(98)00032-X; SUZUKI J, 1995, IEEE T SYST MAN CYB, V25, P655, DOI 10.1109/21.370197; Theis FJ, 2003, NEURAL COMPUT, V15, P419, DOI 10.1162/089976603762552979; TIKHONOV AN, 1997, SOLUTIONS ILL POSED, P415; Vapnik V.N., 1963, Avtomatika i Telemekhanika, V24; Vapnik V., 1998, STAT LEARNING THEORY; VAPNIK VN, 1974, THEORY PATTERN RECOG	42	9	9	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0941-0643			NEURAL COMPUT APPL	Neural Comput. Appl.	JUN	2004	13	2					101	111		10.1007/s00521-004-0412-5		11	Computer Science, Artificial Intelligence	Computer Science	840ZC	WOS:000222898100002		
J	Fischer, GH				Fischer, GH			Remarks on "equivalent linear logistic test models" by Bechger, Verstralen, and Verhelst (2002)	PSYCHOMETRIKA			English	Editorial Material						LLTM; MIRID; identifiability		This paper discusses a new form of specifying and normalizing a Linear Logistic Test Model (LLTM) as suggested by Bechger, Verstralen, and Verhelst (Psychometrika, 2002). It is shown that there are infinitely many ways to specify the same normalization. Moreover, the relationship between some of their results and equivalent previous results in the literature is clarified, and it is shown that the goals of estimating and testing a single element of the weight matrix, for which they propose new methods, can be reached by means of simple, well-known tools already implemented in published LLTM software.	Univ Vienna, A-1010 Vienna, Austria	Fischer, GH (reprint author), Promenadegasse 21, A-1170 Vienna, Austria.						Bechger TM, 2001, PSYCHOMETRIKA, V66, P357, DOI 10.1007/BF02294439; Bechger TM, 2002, PSYCHOMETRIKA, V67, P123, DOI 10.1007/BF02294712; Butter R, 1998, PSYCHOMETRIKA, V63, P47, DOI 10.1007/BF02295436; Fischer G. H., 1998, STRUCTURAL RASCH MOD; Fischer G. H., 1995, RASCH MODELS FDN REC; FISCHER GH, 1983, PSYCHOMETRIKA, V48, P3, DOI 10.1007/BF02314674; Hastie T., 2001, ELEMENTS STAT LEARNI; NAHRER W, 1979, Z EXPT ANGEW PSYCHOL, V27, P553; Rasch G., 1960, PROBABILISTIC MODELS; ROST J, 1966, LEHRBUCH TESTTHEORIE	10	7	7	PSYCHOMETRIC SOC	WILLIAMSBURG	COLLEGE OF WILLIAM AND MARY DEPT PSYCHOLOGY, WILLIAMSBURG, VA 23185 USA	0033-3123			PSYCHOMETRIKA	Psychometrika	JUN	2004	69	2					305	315		10.1007/BF02295946		11	Mathematics, Interdisciplinary Applications; Social Sciences, Mathematical Methods; Psychology, Mathematical	Mathematics; Mathematical Methods In Social Sciences; Psychology	869FO	WOS:000224969000008		
J	Lin, Y				Lin, Y			A note on margin-based loss functions in classification	STATISTICS & PROBABILITY LETTERS			English	Article						Bayes rule of classification; Fisher consistency; margin; method of regularization; method of sieves	CLASSIFIERS; REGRESSION; ALGORITHMS; NETWORKS	In many classification procedures, the classification function is obtained by minimizing a certain empirical risk on the training sample. The classification is then based on the sign of the classification function. In recent years, there have been a host of classification methods proposed that use different margin-based loss functions. The margin-based loss functions are often motivated as upper bounds of the misclassification loss, but this cannot explain the statistical properties of the classification procedures. We show that a large family of margin-based loss functions are Fisher consistent for classification. That is, the population minimizer of the loss function leads to the Bayes optimal rule of classification. Our result covers almost all margin-based loss functions that have been proposed in the literature. We give an inequality that links the Fisher consistency of margin-based loss functions with the consistency of methods based on these loss functions. We use this inequality to obtain the rate of convergence for the method of sieves based on a class of margin-based loss functions. (C) 2004 Elsevier B.V. All rights reserved.	Univ Wisconsin, Dept Stat, Madison, WI 53706 USA	Lin, Y (reprint author), Univ Wisconsin, Dept Stat, 1210 W Dayton St, Madison, WI 53706 USA.	yilin@stat.wisc.edu					BARTLETT PI, 2003, 638 UC BERKL; BOSER BE, 1992, 5 ANN WORSH COMP LEA; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1999, NEURAL COMPUT, V11, P1493, DOI 10.1162/089976699300016106; Breiman L., 2000, 577 U CAL; Buhlmann P, 2003, J AM STAT ASSOC, V98, P324, DOI 10.1198/016214503000125; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COX DD, 1990, ANN STAT, V18, P1676, DOI 10.1214/aos/1176347872; Cristianini N, 2000, INTRO SUPPORT VECTOR; DEVROYE L, 1996, PROBABILITY THEORY P; FREUND Y, 1996, P 13 INT C; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; Grenander U., 1981, ABSTR INF; Hastie T., 2001, ELEMENT STAT LEARNIN; Koltchinskii V, 2002, ANN STAT, V30, P1; Lee WS, 1996, IEEE T INFORM THEORY, V42, P2118; LI KC, 1989, ANN STAT, V17, P1009, DOI 10.1214/aos/1176347254; LIN Y, 2001, 1044 U WISC; Mason L, 2000, MACH LEARN, V38, P243, DOI 10.1023/A:1007697429651; Mason L, 2000, ADV NEUR IN, V12, P512; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Scholkoph B., 2002, LEARNING KERNELS; Shen XT, 2003, J AM STAT ASSOC, V98, P724, DOI 10.1198/016214503000000639; SHEN XT, 1994, ANN STAT, V22, P580, DOI 10.1214/aos/1176325486; Smola AJ, 1998, NEURAL NETWORKS, V11, P637, DOI 10.1016/S0893-6080(98)00032-X; WAHBAG, 1999, ADV KERNEL METHODS S; Zhang T, 2004, ANN STAT, V32, P56	27	38	39	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-7152			STAT PROBABIL LETT	Stat. Probab. Lett.	JUN 1	2004	68	1					73	82		10.1016/j.spl.2004.03.002		10	Statistics & Probability	Mathematics	825RY	WOS:000221777200008		
J	Foffani, G; Moxon, KA				Foffani, G; Moxon, KA			PSTH-based classification of sensory stimuli using ensembles of single neurons	JOURNAL OF NEUROSCIENCE METHODS			English	Article						somatosensory; population coding; multi-electrode whiskers; discrinunant analysis; neural code	INFERIOR TEMPORAL CORTEX; VISUAL-CORTEX; NEURAL CODE; SOMATOSENSORY CORTEX; ACTION-POTENTIALS; COMPUTER-MODEL; SPIKE TRAINS; CA3 REGION; INFORMATION; POPULATION	The problem of understanding how ensembles of neurons code for somatosensory information has been defined as a classification problem: given the response of a population of neurons to a set of stimuli, which stimulus generated the response on a single-trial basis? Multivariate statistical techniques such as linear discriminant analysis (LDA) and artificial neural networks (ANNs), and different types of preprocessing stages. such as principal and independent component analysis, have been used to solve this classification problem, with surprisingly small performance differences. Therefore. the goal of this project was to design a new method to maximize computational efficiency rather than classification performance. We developed a peri-stimulus time histogram (PSTH)-based method, which consists of creating a set of templates based on the average neural responses to stimuli and classifying each single trial by assigning it to the stimulus with the 'closest' template in the Euclidean distance sense. The PSTH-based method is computationally more efficient than methods as simple as linear discriminant analysis. performs significantly better than discriminant analyses (linear, quadratic or Mahalanobis) when small binsizes are used (1 ms) and as well as LDA with any other binsize. is optimal among other minimum-distance classifiers and can be optimally applied on raw neural data without a previous stage of dimension reduction. We conclude that the PSTH-based method is an efficient alternative to more sophisticated methods such as LDA and ANNs to study how ensemble of neurons code for discrete sensory stimuli, especially when datasets with many variables are used and when the time resolution of the neural code is one of the factors of interest. (C) 2004 Elsevier B.V. All rights reserved.	Drexel Univ, Sch Biomed Engn Sci & Hlth Syst, Philadelphia, PA 19104 USA; Politecn Milan, Dept Biomed Engn, I-20133 Milan, Italy	Moxon, KA (reprint author), Drexel Univ, Sch Biomed Engn Sci & Hlth Syst, 3141 Chestnut St, Philadelphia, PA 19104 USA.	karen.moxon@drexel.edu	Moxon, Karen/K-7407-2012	Moxon, Karen/0000-0002-5790-097X			Ahissar E, 2000, NATURE, V406, P302, DOI 10.1038/35018568; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; BIALEK W, 1991, SCIENCE, V252, P1854, DOI 10.1126/science.2063199; Deadwyler SA, 1996, J NEUROSCI, V16, P354; deCharms RC, 1996, NATURE, V381, P610, DOI 10.1038/381610a0; Diesmann M, 1999, NATURE, V402, P529; GEISLER WS, 1991, J NEUROPHYSIOL, V66, P334; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; GEORGOPOULOS AP, 1986, SCIENCE, V233, P416; GERSTEIN GL, 1969, SCIENCE, V164, P828, DOI 10.1126/science.164.3881.828; GERSTEIN GL, 1960, BIOPHYS J, V1, P15; Ghazanfar AA, 2000, J NEUROSCI, V20, P3761; GOCHIN PM, 1994, J NEUROPHYSIOL, V71, P2325; Hastie T., 2001, ELEMENTS STAT LEARNI; HERTZ JA, 1992, INT J NEURAL SYST S, V3, P91, DOI 10.1142/S0129065792000425; HOPFIELD JJ, 1995, NATURE, V376, P33, DOI 10.1038/376033a0; HOPFIELD JJ, 1995, P NATL ACAD SCI USA, V92, P6655, DOI 10.1073/pnas.92.15.6655; Jackson J. E., 1991, USERS GUIDE PRINCIPA, P1; Kepecs A, 2002, J NEUROSCI, V22, P9053; Kjaer T W, 1994, J Comput Neurosci, V1, P109, DOI 10.1007/BF00962721; Kohonen T, 1997, SELF ORG MAPS; Kohonen T., 1987, SELF ORG ASS MEMORY; Kralik JD, 2001, METHODS, V25, P121, DOI 10.1006/meth.2001.1231; Krzanowski W. J., 1988, PRINCIPLES MULTIVARI; Laubach M, 1999, J NEUROSCI METH, V94, P141, DOI 10.1016/S0165-0270(99)00131-4; LEE CK, 1988, NATURE, V332, P357, DOI 10.1038/332357a0; Lewis JE, 1998, J NEUROPHYSIOL, V80, P2584; McAlpine D, 2001, NAT NEUROSCI, V4, P396, DOI 10.1038/86049; MCCLURKIN JW, 1991, SCIENCE, V253, P675, DOI 10.1126/science.1908118; MIDDLEBROOKS JC, 1994, SCIENCE, V264, P842, DOI 10.1126/science.8171339; Moxon KA, 2003, BIOL CYBERN, V88, P247, DOI 10.1007/s00422-002-0373-7; Moxon KA, 1999, BRAIN RES, V825, P75, DOI 10.1016/S0006-8993(99)01187-7; Moxon KA, 2003, BIOL CYBERN, V88, P265, DOI 10.1007/s00422-002-0372-8; Nicolelis MAL, 1997, J NEUROPHYSIOL, V78, P1691; Nicolelis MAL, 1997, NEURON, V18, P529, DOI 10.1016/S0896-6273(00)80295-0; NICOLELIS MAL, 1995, SCIENCE, V268, P1353, DOI 10.1126/science.7761855; Nicolelis MAL, 1998, NAT NEUROSCI, V1, P621, DOI 10.1038/2855; Nirenberg S, 2003, P NATL ACAD SCI USA, V100, P7348, DOI 10.1073/pnas.1131895100; OPTICAN LM, 1987, J NEUROPHYSIOL, V57, P162; Panzeri S, 2001, NEURON, V29, P769, DOI 10.1016/S0896-6273(01)00251-3; Passaglia C, 1997, P NATL ACAD SCI USA, V94, P12649, DOI 10.1073/pnas.94.23.12649; Pasupathy A, 2002, NAT NEUROSCI, V5, P1332, DOI 10.1038/nn972; Petersen RS, 2001, NEURON, V32, P503, DOI 10.1016/S0896-6273(01)00481-0; Petersen RS, 2002, CURR OPIN NEUROBIOL, V12, P441, DOI 10.1016/S0959-4388(02)00338-0; POIRAZI P, 2003, NEURON, V7, P989; RICHMOND BJ, 1990, J NEUROPHYSIOL, V64, P370; Ripley BD, 1996, PATTERN RECOGNITION; Rodriguez P, 2001, BEHAV NEUROSCI, V115, P1224, DOI 10.1037//0735-7044.115.6.1224; Rolls ET, 1998, J NEUROPHYSIOL, V79, P1797; Rolls ET, 1997, EXP BRAIN RES, V114, P149, DOI 10.1007/PL00005615; SCHOENBAUM G, 1995, J NEUROPHYSIOL, V74, P751; Seber G. A. F., 1984, MULTIVARIATE OBSERVA; SIMONS DJ, 1987, NATURE, V326, P694, DOI 10.1038/326694a0; vanSteveninck RRD, 1997, SCIENCE, V275, P1805; Victor JD, 1996, J NEUROPHYSIOL, V76, P1310; Wheeler B, 1999, METHODS NEURAL ENSEM, P61; YOUNG MP, 1992, SCIENCE, V256, P1327, DOI 10.1126/science.1598577	57	46	47	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0270			J NEUROSCI METH	J. Neurosci. Methods	MAY 30	2004	135	1-2					107	120		10.1016/j.neumeth.2003.12.011		14	Biochemical Research Methods; Neurosciences	Biochemistry & Molecular Biology; Neurosciences & Neurology	813DG	WOS:000220887200013	15020095	
J	Elden, L				Elden, L			Partial least-squares vs. Lanczos bidiagonalization - I: analysis of a projection method for multiple regression	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article						partial least-squares; Lanczos bidiagonalization; singular value decomposition; principal components regression; Krylov subspace; chemometrics; shrinkage factors	PLS; EQUATIONS; ALGORITHM; VIEW	Multiple linear regression is considered and the partial least-squares method (PLS) for computing a projection onto a lower-dimensional subspace is analyzed. The equivalence of PLS to Lanczos bidiagonalization is a basic part of the analysis. Singular value analysis, Krylov subspaces, and shrinkage factors are used to explain why, in many cases, PLS gives a faster reduction of the residual than standard principal components regression. It is also shown why in some cases the dimension of the subspace, given by PLS, is not as small as desired. (C) 2003 Elsevier B.V. All rights reserved.	Linkoping Univ, Dept Math, SE-58183 Linkoping, Sweden	Elden, L (reprint author), Linkoping Univ, Dept Math, SE-58183 Linkoping, Sweden.	laeld@math.liu.se					ADOLFSSON T, 1999, STUDIES APPL PROBABI; Axelsson O., 1994, ITERATIVE SOLUTION M; BJORCK A, 1996, NUMERICAL METHODS LE; Bjorck A, 1998, SIAM J MATRIX ANAL A, V19, P720; Burnham AJ, 1996, J CHEMOMETR, V10, P31, DOI 10.1002/(SICI)1099-128X(199601)10:1<31::AID-CEM398>3.0.CO;2-1; Dayal BS, 1997, J CHEMOMETR, V11, P73, DOI 10.1002/(SICI)1099-128X(199701)11:1<73::AID-CEM435>3.0.CO;2-#; Di Ruscio D, 2000, AUTOMATICA, V36, P831; ELDEN L, 2003, UNPUB PARTIAL LEAST, V2; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Golub G.H., 1965, SIAM J NUMER ANAL, V2, P205; Golub G.N., 1996, MATRIX COMPUTATIONS; HANSEN PC, 1997, RANK DEFICIENT DISCR, V3; Hastie T., 2001, ELEMENTS STAT LEARNI; HELLAND IS, 1988, COMMUN STAT SIMULAT, V17, P581, DOI 10.1080/03610918808812681; Helland IS, 2001, CHEMOMETR INTELL LAB, V58, P97, DOI 10.1016/S0169-7439(01)00154-X; Hoskuldsson A., 1996, PREDICTION METHODS S; JOLIFFE LT, 1986, PRINCIPAL COMPONENT; Martens H., 1989, MULTIVARIATE CALIBRA; MASSY WF, 1965, J AM STAT ASSOC, V60, P234, DOI 10.2307/2283149; Miyashita Y., 1990, J CHEMOMETR, V4, P97, DOI 10.1002/cem.1180040111; PAIGE CC, 1982, ACM T MATH SOFTWARE, V8, P43, DOI 10.1145/355984.355989; Phatak A, 2002, J CHEMOMETR, V16, P361, DOI 10.1002/cem.728; STRAND ON, 1974, SIAM J NUMER ANAL, V11, P798, DOI 10.1137/0711066; Trygg J, 2002, J CHEMOMETR, V16, P119, DOI 10.1002/cem.695; Wold H., 1975, PAPERS HONOUR MS BAR; Wold S, 2001, CHEMOMETR INTELL LAB, V58, P109, DOI 10.1016/S0169-7439(01)00155-1; WOLD S, 1984, SIAM J SCI STAT COMP, V5, P735, DOI 10.1137/0905052; Wold S, 1998, CHEMOMETR INTELL LAB, V44, P175, DOI 10.1016/S0169-7439(98)00109-9	28	31	31	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473			COMPUT STAT DATA AN	Comput. Stat. Data Anal.	MAY 28	2004	46	1					11	31		10.1016/S0167-9473(03)00138-5		21	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	813TM	WOS:000220929400002		
J	Podesta, GP; Nunez, L; Villanueva, CA; Skansi, MA				Podesta, GP; Nunez, L; Villanueva, CA; Skansi, MA			Estimating daily solar radiation in the Argentine Pampas	AGRICULTURAL AND FOREST METEOROLOGY			English	Article						solar radiation; transmissivity; diurnal temperature range; Angstrom-Prescott equation; Generalized Additive Models	TEMPERATURE DATA; IRRADIANCE; MODELS; PERFORMANCE; NETWORK; INTERPOLATION; VARIABILITY; SIMULATION; ALGORITHM; LATITUDE	Solar radiation is an important input to crop growth models used for risk management and assessment purposes. Methods are explored to estimate daily solar radiation in the Argentine Pampas, one of the most important agricultural areas in the world. Two scenarios are considered: (i) sunshine duration data are available for a given location, or (ii) only daily temperature (minimum and maximum) and precipitation records exist. If sunshine duration data are available, an association between this quantity and atmospheric transmissivity yields daily radiation estimates with a root mean square error (RMSE) of 1.5 MJ m(-2) per day. Without sunshine duration records, daily temperature and precipitation can be used to estimate atmospheric transmittance and then compute daily radiation values. A model linking predictors that are proxies of cloudiness and atmospheric humidity to atmospheric transmittance was fitted using Generalized Additive Models (GAMs), a modem statistical technique that does not assume any a priori functional forms for the association between predictors and predictand. The errors in radiation estimates using temperature and precipitation are larger (RMSE of 3.2 MJ m(-2) per day) than those derived from sunshine duration, but they are comparable to results for other locations and methods. Most importantly, daily radiation estimates have small bias and the errors show no systematic patterns with season or other variables. (C) 2003 Elsevier B.V. All rights reserved.	Univ Miami, Rosenstiel Sch Marine & Atmospher Sci, Miami, FL 33149 USA; Serv Meteorol Nacl, Buenos Aires, DF, Argentina	Podesta, GP (reprint author), Univ Miami, Rosenstiel Sch Marine & Atmospher Sci, 4600 Rickenbacker Causeway, Miami, FL 33149 USA.	gpodesta@rsmas.miami.edu; lnunez@meteofa.mil.ar; cavi@meteofa.mil.ar; mms@meteofa.mil.ar					ABELEDO H, 1973, METEOROLOGICA, V4, P31; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; ALONSO MR, REV FACULTAD AGRONOM, V22, P51; ANDRETTA A, 1982, J APPL METEOROL, V21, P1377, DOI 10.1175/1520-0450(1982)021<1377:GSREFR>2.0.CO;2; A ngstrom A., 1924, Quarterly Journal of the Royal Meteorological Society, V50; Bechini L, 2000, AGR ECOSYST ENVIRON, V81, P29, DOI 10.1016/S0167-8809(00)00170-5; Bellocchi G, 2002, AGRON J, V94, P1222; BINDI M, 1991, Climate Research, V1, P117, DOI 10.3354/cr001117; Bland WL, 1996, J ATMOS OCEAN TECH, V13, P255, DOI 10.1175/1520-0426(1996)013<0255:UODIEF>2.0.CO;2; BOISVERT JB, 1990, AGR FOREST METEOROL, V52, P275, DOI 10.1016/0168-1923(90)90086-L; Boote KJ, 1996, AGRON J, V88, P704; BRISTOW KL, 1984, AGR FOREST METEOROL, V31, P159, DOI 10.1016/0168-1923(84)90017-0; Castaneda ME, 1994, METEOROLOGICA, V19, P23; Castellvi F, 2001, THEOR APPL CLIMATOL, V69, P231, DOI 10.1007/s007040170028; CRIVELLI ES, 1971, METEOROLOGICA, V2, P86; DEJONG R, 1993, CAN J PLANT SCI, V73, P509; DIAZ RA, 1980, REV INVESTIG AGROPEC, V15, P17; Donatelli M, 1998, P 5 ESA C NITR SLOV, P133; ELIZONDO D, 1994, AGR FOREST METEOROL, V71, P115, DOI 10.1016/0168-1923(94)90103-1; FORSYTHE WC, 1995, ECOL MODEL, V80, P87, DOI 10.1016/0304-3800(94)00034-F; FRULLA LA, 1988, SOL ENERGY, V41, P61, DOI 10.1016/0038-092X(88)90116-8; GALLEGOS HG, 1988, SOL ENERGY, V40, P397, DOI 10.1016/0038-092X(88)90094-1; GALLEGOS HG, 1991, ACT 5 REUN ARG AGR C, P57; Goodin DG, 1999, AGRON J, V91, P845; Grimm AM, 2000, J CLIMATE, V13, P35, DOI 10.1175/1520-0442(2000)013<0035:CVISSA>2.0.CO;2; Guisan A, 2002, ECOL MODEL, V157, P89, DOI 10.1016/S0304-3800(02)00204-1; Hall A.J., 1992, P413; Hansen JW, 1999, AGR FOREST METEOROL, V94, P53, DOI 10.1016/S0168-1923(99)00003-9; Hastie T., 2001, ELEMENTS STAT LEARNI, P533; HASTIE TJ, 1992, STAT MODELS S, P309; Hastie TJ, 1990, GEN ADDITIVE MODELS, P335; Hunt LA, 1998, AGR FOREST METEOROL, V91, P293, DOI 10.1016/S0168-1923(98)00055-0; Iziomon MG, 2001, AGR FOREST METEOROL, V110, P1, DOI 10.1016/S0168-1923(01)00281-7; Liu DL, 2001, AGR FOREST METEOROL, V106, P41, DOI 10.1016/S0168-1923(00)00173-8; LONG CN, 1995, J APPL METEOROL, V34, P1039, DOI 10.1175/1520-0450(1995)034<1039:SMOSIA>2.0.CO;2; Mahmood R, 2002, AGRON J, V94, P723; MARTINEZLOZANO JA, 1984, AGR FOREST METEOROL, V33, P109, DOI 10.1016/0168-1923(84)90064-9; MCCASKILL MR, 1990, AGR FOREST METEOROL, V51, P247, DOI 10.1016/0168-1923(90)90111-I; MEINKE H, 1995, AGR FOREST METEOROL, V72, P295, DOI 10.1016/0168-1923(94)02159-H; Merino GG, 2001, J APPL METEOROL, V40, P1085, DOI 10.1175/1520-0450(2001)040<1085:DOSMTK>2.0.CO;2; Nonhebel Sanderine, 1994, Climate Research, V4, P61, DOI 10.3354/cr004061; Nonhebel Sanderine, 1994, Climate Research, V4, P47, DOI 10.3354/cr004047; Olseth JA, 2001, THEOR APPL CLIMATOL, V69, P239, DOI 10.1007/s007040170029; PINKER RT, 1995, REMOTE SENS ENVIRON, V51, P108, DOI 10.1016/0034-4257(94)00069-Y; Prescott J. A., 1940, T ROY SOC SOUTH AUST, V64, P114; RAVELO AC, 1989, ACT 4 REUN ARG AGR R; Rusticucci M, 2002, INT J CLIMATOL, V22, P467, DOI 10.1002/joc.743; SEILER R, 1980, REV INVESTIG AGROPEC, V15, P355; SUCKLING PW, 1985, SOL ENERGY, V35, P491, DOI 10.1016/0038-092X(85)90117-3; SWIFT LW, 1976, WATER RESOUR RES, V12, P108, DOI 10.1029/WR012i001p00108; Thornton PE, 1999, AGR FOREST METEOROL, V93, P211, DOI 10.1016/S0168-1923(98)00126-9; Vargas W., 1999, METEOROLOGICA, V24, P3; Venables W.N., 2002, MODERN APPL STAT S, P495; Weiss A, 2001, AGRON J, V93, P1321; Wilks DS, 1999, PROG PHYS GEOG, V23, P329, DOI 10.1177/030913339902300302; WILLMOTT C. J, 1981, PHYS GEOG, V2, P184; Xia Y, 2000, THEOR APPL CLIMATOL, V66, P109, DOI 10.1007/s007040070036; Yohai V., 1991, DIRECTIONS ROBUST ST	58	36	39	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0168-1923			AGR FOREST METEOROL	Agric. For. Meteorol.	MAY 20	2004	123	1-2					41	53		10.1016/j.agrformat.2003.11.002		13	Agronomy; Forestry; Meteorology & Atmospheric Sciences	Agriculture; Forestry; Meteorology & Atmospheric Sciences	820CQ	WOS:000221364600003		
J	Klon, AE; Glick, M; Thoma, M; Acklin, P; Davies, JW				Klon, AE; Glick, M; Thoma, M; Acklin, P; Davies, JW			Finding more needles in the haystack: A simple and efficient method for improving high-throughput docking results	JOURNAL OF MEDICINAL CHEMISTRY			English	Article							PROTEIN-TYROSINE-PHOSPHATASE; MOLECULAR DOCKING; SCORING FUNCTIONS; DATABASES; GENERATION; 1B	The technology underpinning high-throughput docking (HTD) has developed over the past few years to where it has become a vital tool in modern drug discovery. Although the performance of various docking algorithms is adequate, the ability to accurately and consistently rank compounds using a scoring function remains problematic. We show that by employing a simple machine learning method (naive Bayes) it is possible to significantly overcome this deficiency. Compounds from the Available Chemical Directory (ACD), along with known active compounds, were docked into two protein targets using three software packages. In cases where HTD alone was able to show some enrichment, the application of naive Bayes was able to improve upon the enrichment. The application of this methodology to enrich HTD results can be carried out without a priori knowledge of the activity of compounds and results in superior enrichment of known actives compared to the use of scoring methods alone.	Novartis Inst Biomed Res, Cambridge, MA 02139 USA	Davies, JW (reprint author), Novartis Inst Biomed Res, 100 Technol Sq, Cambridge, MA 02139 USA.	john.davies@pharma.novartis.com					Abagyan R, 2001, CURR OPIN CHEM BIOL, V5, P375, DOI 10.1016/S1367-5931(00)00217-9; Akamatsu M, 1997, BIOORGAN MED CHEM, V5, P157, DOI 10.1016/S0968-0896(96)00195-2; ANDERSEN HS, 2001, Patent No. 0100451; Berman HM, 2002, ACTA CRYSTALLOGR D, V58, P899, DOI 10.1107/S0907444902003451; Bissantz C, 2000, J MED CHEM, V43, P4759, DOI 10.1021/jm001044l; Charifson PS, 1999, J MED CHEM, V42, P5100, DOI 10.1021/jm990352k; Clark RD, 2002, J MOL GRAPH MODEL, V20, P281, DOI 10.1016/S1093-3263(01)00125-5; Ewing TJA, 2001, J COMPUT AID MOL DES, V15, P411, DOI 10.1023/A:1011115820450; GASTEIGER J, 1980, TETRAHEDRON, V36, P3219, DOI 10.1016/0040-4020(80)80168-2; GLICK M, 2003, J BIOMOL SCREEN, V9, P32; Gohlke H, 2001, CURR OPIN STRUC BIOL, V11, P231, DOI 10.1016/S0959-440X(00)00195-0; Hastie T., 2001, ELEMENTS STAT LEARNI; Iversen LF, 2000, J BIOL CHEM, V275, P10300, DOI 10.1074/jbc.275.14.10300; Johnson TO, 2002, NAT REV DRUG DISCOV, V1, P696, DOI 10.1038/nrd895; LEBLANC Y, 2000, Patent No. 9900864; MORGAN HL, 1965, J CHEM DOC, V5, P107, DOI 10.1021/c160017a018; Rarey M, 1996, J MOL BIOL, V261, P470, DOI 10.1006/jmbi.1996.0477; Schneider G, 2002, DRUG DISCOV TODAY, V7, P64, DOI 10.1016/S1359-6446(02)00004-1; VLATTAS I, 1998, P EUR PEPT S AK KIAD, P766; Wang RX, 2003, J MED CHEM, V46, P2287, DOI 10.1021/jm0203783; Wang RX, 2001, J CHEM INF COMP SCI, V41, P1422, DOI 10.1021/ci010025x; Witten I.H., 1999, DATA MINING PRACTICA; Yang J, 2002, NAT STRUCT BIOL, V9, P940, DOI 10.1038/nsb870	23	69	71	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0022-2623			J MED CHEM	J. Med. Chem.	MAY 20	2004	47	11					2743	2749		10.1021/jm030363k		7	Chemistry, Medicinal	Pharmacology & Pharmacy	821JQ	WOS:000221456700005	15139752	
J	Lu, KH; Patterson, AP; Wang, L; Marquez, RT; Atkinson, EN; Baggerly, KA; Ramoth, LR; Rosen, DG; Liu, JS; Hellstrom, I; Smith, D; Hartmann, L; Fishman, D; Berchuck, A; Schmandt, R; Whitaker, R; Gershenson, DM; Mills, GB; Bast, RC				Lu, KH; Patterson, AP; Wang, L; Marquez, RT; Atkinson, EN; Baggerly, KA; Ramoth, LR; Rosen, DG; Liu, JS; Hellstrom, I; Smith, D; Hartmann, L; Fishman, D; Berchuck, A; Schmandt, R; Whitaker, R; Gershenson, DM; Mills, GB; Bast, RC			Selection of potential markers for epithelial ovarian cancer with gene expression arrays and recursive descent partition analysis	CLINICAL CANCER RESEARCH			English	Article							MOLECULAR CLASSIFICATION; CARCINOMAS; TUMORS	Purpose: Advanced-stage epithelial ovarian cancer has a poor prognosis with long-term survival in less than 30% of patients. When the disease is detected in stage I, more than 90% of patients can be cured by conventional therapy. Screening for early-stage disease with individual serum tumor markers, such as CA125, is limited by the fact that no single marker is up-regulated and shed in adequate amounts by all ovarian cancers. Consequently, use of multiple markers in combination might detect a larger fraction of early-stage ovarian cancers. Experimental Design: To identify potential candidates for novel markers, we have used Affymetrix human genome arrays (U95 series) to analyze differences in gene expression of 41,441 known genes and expressed sequence tags between five pools of normal ovarian surface epithelial cells (OSE) and 42 epithelial ovarian cancers of different stages, grades, and histotypes. Recursive descent partition analysis (RDPA) was performed with 102 probe sets representing 86 genes that were up-regulated at least 3-fold in epithelial ovarian cancers when compared with normal OSE. In addition, a panel of 11 genes known to encode potential tumor markers [mucin 1, transmembrane (MUC1), mucin 16 (CA125), mesothelin, WAP four-disulfide core domain 2 (HE4), kallikrein 6, kallikrein 10, matrix metalloproteinase 2, prostasin, osteopontin, tetranectin, and inhibin] were similarly analyzed. Results: The 3-fold up-regulated genes were examined and four genes [Notch homologue 3 (NOTCH3), E2F transcription factor 3 (E2F3), GTPase activating protein (RAC-GAP1), and hematological and neurological expressed 1 (HN1)] distinguished all tumor samples from normal OSE. The 3-fold up-regulated genes were analyzed using RDPA, and the combination of elevated claudin 3 (CLDN3) and elevated vascular endothelial growth factor (VEGF) distinguished the cancers from normal OSE. The 11 known markers were analyzed using RDPA, and a combination of HE4, CA125, and MUC1 expression could distinguish tumor from normal specimens. Expression at the mRNA level in the candidate markers was examined via semiquantitative reverse transcription-PCR and was found to correlate well with the array data. Immunohistochemistry was performed to identify expression of the genes at the protein level in 158 ovarian cancers of different histotypes. A combination of CLDN3, CA125, and MUC1 stained 157 (99.4%) of 158 cancers, and all of the tumors were detected with a combination of CLDN3, CA125, MUC1, and VEGF. Conclusions: Our data are consistent with the possibility that a limited number of markers in combination might identify >99% of epithelial ovarian cancers despite the heterogeneity of the disease.	Univ Texas, MD Anderson Canc Ctr, Dept Expt Therapeut, Ovarian Canc Res Lab, Houston, TX 77030 USA; Univ Texas, MD Anderson Canc Ctr, Dept Gynecol Oncol, Houston, TX 77030 USA; Univ Texas, MD Anderson Canc Ctr, Dept Biostat, Houston, TX 77030 USA; Univ Texas, MD Anderson Canc Ctr, Dept Mol Therapeut, Houston, TX 77030 USA; Univ Texas, MD Anderson Canc Ctr, Dept Pathol, Houston, TX 77030 USA; Pacific NW Res Inst, Seattle, WA USA; Mayo Clin, Rochester, MN USA; Northwestern Univ, Med Ctr, Chicago, IL 60611 USA; Duke Univ, Med Ctr, Durham, NC USA	Bast, RC (reprint author), Univ Texas, MD Anderson Canc Ctr, Dept Expt Therapeut, Ovarian Canc Res Lab, Box 355,1550 Holcombe Blvd, Houston, TX 77030 USA.	rbast@mdanderson.org	Bast, Robert/E-6585-2011	Bast, Robert/0000-0003-4621-8462			American Cancer Society, 2003, CANC FACTS FIG; BAST RC, 2002, OVARIAN CANC, P61; Chambers JM, 1992, STAT MODELS S PACIFI; FISHMAN DA, 2002, OVARIAN CANC, P3; Giordano TJ, 2001, AM J PATHOL, V159, P1231, DOI 10.1016/S0002-9440(10)62509-6; Greenlee RT, 2000, CA-CANCER J CLIN, V50, P7, DOI 10.3322/canjclin.50.1.7; Hastie T., 2001, ELEMENTS STAT LEARNI; Hellstrom I, 2003, CANCER RES, V63, P3695; Hough CD, 2000, CANCER RES, V60, P6281; KIRCHHOFF C, 1991, BIOL REPROD, V45, P350, DOI 10.1095/biolreprod45.2.350; Laufs U, 2003, J BIOL CHEM, V278, P5956, DOI 10.1074/jbc.M209813200; Li C, 2001, P NATL ACAD SCI USA, V98, P31, DOI 10.1073/pnas.011404098; Mok SC, 2001, J NATL CANCER I, V93, P1458, DOI 10.1093/jnci/93.19.1458; Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; Rangel LBA, 2003, CLIN CANCER RES, V9, P2567; Scholler N, 1999, P NATL ACAD SCI USA, V96, P11531, DOI 10.1073/pnas.96.20.11531; Schummer M, 1999, GENE, V238, P375, DOI 10.1016/S0378-1119(99)00342-X; Schwartz DR, 2002, CANCER RES, V62, P4722; Shridhar V, 2001, CANCER RES, V61, P5895; Su AI, 2001, CANCER RES, V61, P7388; Venables W, 1994, MODERN APPL STAT SPL; Welsh JB, 2001, P NATL ACAD SCI USA, V98, P1176, DOI 10.1073/pnas.98.3.1176	22	229	242	AMER ASSOC CANCER RESEARCH	PHILADELPHIA	615 CHESTNUT ST, 17TH FLOOR, PHILADELPHIA, PA 19106-4404 USA	1078-0432			CLIN CANCER RES	Clin. Cancer Res.	MAY 15	2004	10	10					3291	3300		10.1158/1078-0432.CCR-03-0409		10	Oncology	Oncology	823PY	WOS:000221626600008	15161682	
J	Mannor, S; Meir, R; Zhang, T				Mannor, S; Meir, R; Zhang, T			Greedy algorithms for classification - Consistency, convergence rates, and adaptivity	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article							MODEL SELECTION; APPROXIMATION; REGRESSION; BOUNDS	Many regression and classification algorithms proposed over the years can be described as greedy procedures for the stagewise minimization of an appropriate cost function. Some examples include additive models, matching pursuit, and boosting. In this work we focus on the classification problem, for which many recent algorithms have been proposed and applied successfully. For a specific regularized form of greedy stagewise optimization, we prove consistency of the approach under rather general conditions. Focusing on specific classes of problems we provide conditions under which our greedy procedure achieves the (nearly) minimax. rate of convergence, implying that the procedure cannot be improved in a worst case setting. We also construct a fully adaptive procedure, which, without knowing the smoothness parameter of the decision boundary, converges at the same rate as if the smoothness parameter were known.	MIT, Lab Informat & Decis Syst, Cambridge, MA 02139 USA; Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel; IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA	Mannor, S (reprint author), MIT, Lab Informat & Decis Syst, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	SHIE@MIT.EDU; RMEIR@EE.TECHNION.AC.IL; TZHANG@WATSON.IBM.COM					AGARWAL GG, 1980, ANN STAT, V8, P1307, DOI 10.1214/aos/1176345203; Anthony M., 1999, NEURAL NETWORK LEARN; Antos A., 2002, J MACHINE LEARNING R, V3, P73; Auer P, 1996, ADV NEUR IN, V8, P316; Barron A, 1999, PROBAB THEORY REL, V113, P301, DOI 10.1007/s004400050210; BARRON AR, 1993, IEEE T INFORM THEORY, V39, P930, DOI 10.1109/18.256500; Barron A.R., 1992, P 7 YAL WORKSH AD LE; Bartlett PL, 2002, MACH LEARN, V48, P85, DOI 10.1023/A:1013999503812; Bartlett P. L., 2003, J MACHINE LEARNING R, V3, P463; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; Breiman L, 1998, ANN STAT, V26, P801; Breiman L., 2000, SOME INFINITY THEORY; Buhlmann P, 2003, J AM STAT ASSOC, V98, P324, DOI 10.1198/016214503000125; Devroye L., 1996, PROBABILISTIC THEORY; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T., 1990, MONOGRAPHS STAT APPL, V43; Herbrich R., 2002, LEARNING KERNEL CLAS; JIANG W, 2000, 0003 NW U DEP STAT; JIANG W, 2000, 0005 NW U DEP STAT; Kearns M. J., 1994, INTRO COMPUTATIONAL; KOLTCHINSKII V, 2002, ANN STAT, V30; LESHNO M, 1993, NEURAL NETWORKS, V6, P861, DOI 10.1016/S0893-6080(05)80131-5; LUGOSI G, 2001, BAYES RISK CONSISTEN; LUGOSI G, 2002, LECT NOTES ARTIF INT, V2375, P303; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; MANNOR S, 2001, P 14 ANN C COMP LEAR, P461; MANNOR S, 2002, LECT NOTES COMPUT SC, V2375, P319; Mannor S, 2002, MACH LEARN, V48, P219, DOI 10.1023/A:1013959922467; MANNOR S, 2002, ON LINE APPENDIX; MASON L, 2000, ADV LARGIN MARGIN CL; Meir R, 2002, LECT NOTES ARTIF INT, V2600, P118; MEIR R, 2003, ADV NEURAL INFORMATI, V15, P319; Nedler JA, 1965, COMPUT J, V7, P308; POLLARD D, 1984, CONVERGENCE EMPIRICI; Robert C., 2001, BAYESIAN CHOICE DECI; Schaback R, 2000, J COMPUT APPL MATH, V121, P165, DOI 10.1016/S0377-0427(00)00345-9; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Schapire RE, 1998, ANN STAT, V26, P1651; Van de Geer S., 2000, EMPIRICAL PROCESSES; van der Vaart AW, 1996, WEAK CONVERGENCE EMP; Vapnik V., 1982, ESTIMATION DEPENDENC; Vapnik V., 1998, STAT LEARNING THEORY; Yang YH, 1999, IEEE T INFORM THEORY, V45, P2271; ZHANG T, 2002, IN PRESS ANN STAT; Zhang T, 2003, IEEE T INFORM THEORY, V49, P682, DOI 10.1109/TIT.2002.808136	49	1	1	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	MAY 15	2004	4	4					713	742		10.1162/153244304773936108		30	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	819WC	WOS:000221345700012		
J	Quinones, MJ; Hernandez-Pampaloni, M; Schelbert, H; Bulnes-Enriquez, I; Jimenez, X; Hernandez, G; De la Rosa, R; Chon, Y; Yang, HY; Nicholas, SB; Modilevsky, T; Yu, K; Van Herle, K; Castellani, LW; Elashoff, R; Hsueh, WA				Quinones, MJ; Hernandez-Pampaloni, M; Schelbert, H; Bulnes-Enriquez, I; Jimenez, X; Hernandez, G; De la Rosa, R; Chon, Y; Yang, HY; Nicholas, SB; Modilevsky, T; Yu, K; Van Herle, K; Castellani, LW; Elashoff, R; Hsueh, WA			Coronary vasomotor abnormalities in insulin-resistant individuals	ANNALS OF INTERNAL MEDICINE			English	Article							VASCULAR ENDOTHELIAL-CELLS; NUTRITION EXAMINATION SURVEY; DEPENDENT DIABETES-MELLITUS; MYOCARDIAL BLOOD-FLOW; NECROSIS-FACTOR-ALPHA; 3RD NATIONAL-HEALTH; NITRIC-OXIDE; US ADULTS; GLUCOSE-TOLERANCE; HEART-DISEASE	Background: Insulin resistance is a metabolic spectrum that progresses from hyperinsulinemia to the metabolic syndrome, impaired glucose tolerance, and finally type 2 diabetes mellitus. It is unclear when vascular abnormalities begin in this spectrum of metabolic effects. Objective: To evaluate the association of insulin resistance with the presence and reversibility of coronary vasomotor abnormalities in young adults at low cardiovascular risk. Design: Cross-sectional study followed by prospective, open-label treatment study. Setting: University hospital. Patients: 50 insulin-resistant and 22 insulin-sensitive, age-matched Mexican-American participants without glucose intolerance or traditional risk factors for or evidence of coronary artery disease. Intervention: 3 months of thiazolidinedione therapy for 25 insulin-resistant patients. Measurements: Glucose infusion rate in response to insulin infusion was used to define insulin resistance (glucose infusion rate less than or equal to 4.00 mg/kg of body weight per minute [range, 0.90 to 3.96 mg/kg per minute]) and insulin sensitivity (glucose infusion rate greater than or equal to 7.50 mg/kg per minute [range, 7.52 to 13.92 mg/kg per minute]). Myocardial blood flow was measured by using positron emission tomography at rest, during cold pressor test (largely endothelium-dependent), and after dipyridamole administration (largely vascular smooth muscle-dependent). Results: Myocardial blood flow responses to dipyridamole were similar in the insulin-sensitive and insulin-resistant groups. However, myocardial blood flow response to cold pressor test increased by 47.6% from resting values in insulin-sensitive patients and by 14.4% in insulin-resistant patients. During thiazolidinedione therapy in a subgroup of insulin-resistant patients, insulin sensitivity improved, fasting plasma insulin levels decreased, and myocardial blood flow responses to cold pressor test normalized. Limitations: The study was not randomized, and it included only 1 ethnic group. Conclusions: insulin-resistant patients who do not have hypercholesterolemia or hypertension and do not smoke manifest coronary vasomotor abnormalities. Insulin-sensitizing thiazolidinedione therapy normalized these abnormalities. These results suggest an association between insulin resistance and abnormal coronary vasomotor function, a relationship that requires confirmation in larger studies.	Univ Calif Los Angeles, David Geffen Sch Med, Div Endocrinol Diabet & Hypertens, Cedars Sinai Med Ctr, Los Angeles, CA 90095 USA; Olive View Univ Calif, Los Angeles Med Ctr, Sylmar, CA USA	Hsueh, WA (reprint author), Univ Calif Los Angeles, David Geffen Sch Med, Div Endocrinol Diabet & Hypertens, Cedars Sinai Med Ctr, 900 Vet Ave,Suite 24-130, Los Angeles, CA 90095 USA.	whsueh@mednet.ucla.edu					Amberger A, 1997, CELL STRESS CHAPERON, V2, P94, DOI 10.1379/1466-1268(1997)002<0094:CEOIVE>2.3.CO;2; Arcaro G, 2002, CIRCULATION, V105, P576, DOI 10.1161/hc0502.103333; Balletshofer BM, 2000, CIRCULATION, V101, P1780; Berg AH, 2002, TRENDS ENDOCRIN MET, V13, P84, DOI 10.1016/S1043-2760(01)00524-0; Bhagat K, 1997, CIRCULATION, V96, P3042; Caballero AE, 1999, DIABETES, V48, P1856, DOI 10.2337/diabetes.48.9.1856; Calles-Escandon J, 2001, ENDOCR REV, V22, P36, DOI 10.1210/er.22.1.36; Campisi R, 1998, CIRCULATION, V98, P119; Cooke JP, 2000, ARTERIOSCL THROM VAS, V20, P2032; Cusi K, 2000, J CLIN INVEST, V105, P311, DOI 10.1172/JCI7535; De Fronzo R, 1979, AM J PHYSIOL, V237, P214; Borch-Johnsen K, 2001, ARCH INTERN MED, V161, P397; DiCarli MF, 1997, NEW ENGL J MED, V336, P1208, DOI 10.1056/NEJM199704243361703; Cleeman JI, 2001, JAMA-J AM MED ASSOC, V285, P2486, DOI 10.1001/jama.285.19.2486; Flegal KM, 2002, JAMA-J AM MED ASSOC, V288, P1723, DOI 10.1001/jama.288.14.1723; Fonseca VA, 1998, J DIABETES COMPLICAT, V12, P181, DOI 10.1016/S1056-8727(97)00109-8; Ford ES, 2002, JAMA-J AM MED ASSOC, V287, P356, DOI 10.1001/jama.287.3.356; FRIEDEWA.WT, 1972, CLIN CHEM, V18, P499; Fulton D, 1999, NATURE, V399, P597; Haffner SM, 2000, NEW ENGL J MED, V342, P1040, DOI 10.1056/NEJM200004063421408; Haffner SM, 2002, CIRCULATION, V106, P679, DOI 10.1161/01.CIR.0000025403.20953.23; Harris MI, 1998, DIABETES CARE, V21, P518, DOI 10.2337/diacare.21.4.518; Hastie T., 2001, ELEMENTS STAT LEARNI; Hogikyan RV, 1998, J CLIN ENDOCR METAB, V83, P1946, DOI 10.1210/jc.83.6.1946; Hsueh WA, 1999, AM J CARDIOL, V84, p21J; Jackson SM, 1999, ARTERIOSCL THROM VAS, V19, P2094; Katsuki A, 2000, DIABETES OBES METAB, V2, P189, DOI 10.1046/j.1463-1326.2000.00072.x; KRIVOKAPICH J, 1989, CIRCULATION, V80, P1328; Krook A, 2000, DIABETES, V49, P284, DOI 10.2337/diabetes.49.2.284; KUHLE WG, 1992, CIRCULATION, V86, P1004; Maeda N, 2001, DIABETES, V50, P2094, DOI 10.2337/diabetes.50.9.2094; MARUI N, 1993, J CLIN INVEST, V92, P1866, DOI 10.1172/JCI116778; Momose M, 2002, EUR J NUCL MED MOL I, V29, P1675, DOI 10.1007/s00259-002-0977-0; Montagnani M, 2002, J BIOL CHEM, V277, P1794, DOI 10.1074/jbc.M103728200; NABEL EG, 1988, CIRCULATION, V77, P43; Nitenberg A, 2001, DIABETES, V50, P1180, DOI 10.2337/diabetes.50.5.1180; Ouchi N, 1999, CIRCULATION, V100, P2473; Palatini P, 1999, AM J HYPERTENS, V12, p3S, DOI 10.1016/S0895-7061(98)00207-6; Parulkar AA, 2001, ANN INTERN MED, V134, P61; Peraldi P, 1997, J CLIN INVEST, V100, P1863, DOI 10.1172/JCI119715; *REP EXP COMM DIAG, 2003, DIABETES CARE S1, V26, pS5; Schachinger V, 2000, CIRCULATION, V101, P1899; STAHLINGER MC, 2002, JAMA-J AM MED ASSOC, V287, P1420; Steer P, 2002, LIPIDS, V37, P1135, DOI 10.1007/s11745-002-1010-3; Steinberg HO, 1996, J CLIN INVEST, V97, P2601, DOI 10.1172/JCI118709; TUZCU EM, 1995, CIRCULATION, V91, P1706; Warnick G R, 1986, Methods Enzymol, V129, P101; Williams SB, 1996, J AM COLL CARDIOL, V27, P567, DOI 10.1016/0735-1097(95)00522-6; ZEIHER AM, 1991, CIRCULATION, V84, P1984; ZEIHER AM, 1991, CIRCULATION, V83, P391; Zeng GY, 1996, J CLIN INVEST, V98, P894, DOI 10.1172/JCI118871; Zeng GY, 2000, CIRCULATION, V101, P1539	52	86	90	AMER COLL PHYSICIANS	PHILADELPHIA	INDEPENDENCE MALL WEST 6TH AND RACE ST, PHILADELPHIA, PA 19106-1572 USA	0003-4819			ANN INTERN MED	Ann. Intern. Med.	MAY 4	2004	140	9					700	708				9	Medicine, General & Internal	General & Internal Medicine	816XR	WOS:000221143100003	15126253	
J	Beck, N; King, G; Zeng, L				Beck, N; King, G; Zeng, L			Theory and evidence in international conflict: A response to de Marchi, Gelpi, and Grynaviski	AMERICAN POLITICAL SCIENCE REVIEW			English	Article							MODELS; DEMOCRACY	In this article, we show that de Marchi, Gelpi, and Grynaviski's substantive analyses are fully consistent with our prior theoretical conjecture about international conflict. We note that they also agree with our main methodological point that out-of-sample forecasting performance should be a primary standard used to evaluate international conflict studies. However, we demonstrate that all other methodological conclusions drawn by de Marchi, Gelpi, and Gryanaviski are false. For example, by using the same evaluative criterion for both models, it is easy to see that their claim that properly specified logit models outperform neural network models is incorrect. Finally, we show that flexible neural network models are able to identify important empirical relationships between democracy and conflict that the logit model excludes a priori; this should not be surprising since the logit model is merely a limiting special case of the neural network model.	NYU, Dept Polit, New York, NY 10023 USA; Harvard Univ, Ctr Basic Res Social Sci, Cambridge, MA 02138 USA; George Washington Univ, Dept Polit Sci, Washington, DC 20052 USA	Beck, N (reprint author), NYU, Dept Polit, New York, NY 10023 USA.	Nathaniel.Beck@nyu.edu; King@Harvard.Edu; lzeng@gwu.edu					BEARCE D, 2000, POLITICAL COMPLEXITY, P269; Beck N, 1998, AM J POLIT SCI, V42, P596, DOI 10.2307/2991772; Beck N, 2000, AM POLIT SCI REV, V94, P21, DOI 10.2307/2586378; BISHOP C.M., 1995, NEURAL NETWORKS PATT; BORISYUK R, 2001, FORECASTING 2001 GEN; De Marchi S, 2004, AM POLIT SCI REV, V98, P371; Demuth H., 2002, NEURAL NETWORK TOOLB; GELPI C, 2000, DEMOCRACY INTERDEPEN; Hastie T., 2001, ELEMENTS STAT LEARNI; KING G, 2003, CAN HIST BE OUR GUID; KING G, 2001, POLITICAL ANAL, V0009; King Gary, 1994, DESIGNING SOCIAL INQ; King Gary, 2000, AM J POLIT SCI, V44, P341; LAGAZIO M, 2002, SCOURAGE WAR NEW EXT; Oneal JR, 1997, INT STUD QUART, V41, P267, DOI 10.1111/1468-2478.00042; Peceny M, 2002, AM POLIT SCI REV, V96, P15; Reuveny R, 2003, INT STUD QUART, V47, P325, DOI 10.1111/1468-2478.4703002; RUSSETT BM, 2003, INT STUDIES Q, V47, P371; Signorino CS, 2003, AM J POLIT SCI, V47, P551, DOI 10.2307/3186115; Signorino CS, 1999, AM POLIT SCI REV, V93, P279, DOI 10.2307/2585396; Stock JH, 2003, J ECON LIT, V41, P788, DOI 10.1257/002205103322436197; STONE M, 1974, J R STAT SOC B, V36, P111; Vapnik V., 1998, STAT LEARNING THEORY; VPNIK V, 1995, NATURE STAT LEARNING; Werner S, 2000, POLIT RES QUART, V53, P343, DOI 10.2307/449285; White H., 1992, ARTIFICIAL NEURAL NE; ZENG L, 2000, POLITICAL COMPLEXITY, P239; King G, 2001, WORLD POLIT, V53, P623, DOI 10.1353/wp.2001.0018; Zeng LC, 1999, SOCIOL METHOD RES, V27, P499, DOI 10.1177/0049124199027004002; Zombanakis G. A., 2001, DEFENCE PEACE ECON, V12, P303, DOI 10.1080/10430710108404990	30	20	20	CAMBRIDGE UNIV PRESS	NEW YORK	32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA	0003-0554			AM POLIT SCI REV	Am. Polit. Sci. Rev.	MAY	2004	98	2					379	389				11	Political Science	Government & Law	827MJ	WOS:000221903700012		
J	Garzotto, M; Beer, TM; Mori, M				Garzotto, M; Beer, TM; Mori, M			Predictive modeling for the presence of prostate carcinoma using clinical, laboratory, and ultrasound parameters in patients with prostate-specific antigen levels <= 10 ng/mL - Author reply	CANCER			English	Letter							NETWORK		Portland Vet Adm Med Ctr, Div Urol, Portland, OR 97201 USA; Oregon Hlth Sci Univ, Div Urol, Portland, OR 97201 USA; Oregon Hlth Sci Univ, Div Hematol & Med Oncol, Portland, OR 97201 USA; Oregon Hlth Sci Univ, Inst Canc, Portland, OR 97201 USA	Garzotto, M (reprint author), Portland Vet Adm Med Ctr, Div Urol, Portland, OR 97201 USA.						BERGER A, 2003, J UROLOGY, V169, pA277; Finne P, 2000, UROLOGY, V56, P418, DOI 10.1016/S0090-4295(00)00672-5; Garzotto M, 2003, CANCER, V98, P1417, DOI 10.1002/cncr.11668; Hastie T., 2001, ELEMENTS STAT LEARNI; Sargent DJ, 2001, CANCER, V91, P1636, DOI 10.1002/1097-0142(20010415)91:8+<1636::AID-CNCR1176>3.0.CO;2-D; Stephan C, 2002, INT J CANCER, V99, P466, DOI 10.1002/ijc.10370	6	0	0	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	0008-543X			CANCER	Cancer	MAY 1	2004	100	9					1989	1990		10.1002/cncr.20197		2	Oncology	Oncology	813TI	WOS:000220929000030		
J	Chen, Q; Gong, P				Chen, Q; Gong, P			Automatic variogram parameter extraction for textural classification of the panchromatic IKONOS imagery	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article						IKONOS; range; sill; texture; variogram	SEA-FLOOR CLASSIFICATION; REMOTELY-SENSED DATA; VEGETATION DISCRIMINATION; DIGITAL IMAGES; LAND-COVER; SEMIVARIOGRAM; GEOSTATISTICS; REDUCTION; STC	Range and sill are two important parameters of a variogram. Their extraction usually involves experimental fitting of variograms using models specified by the analyst and requires much use of trial and error. The objective of this paper is to design an algorithm for extracting the range and sill of a variogram automatically without fitting a model. Combined with the semivariance at the lag of one pixel (gamma(1)), the extracted range and sill were applied to the textural classification of a panchromatic IKONOS image over Xichang, Sichuan Province, China. Results show that any of these three parameters can lead to the increase of the classification accuracy. When all three parameters were used with the raw image data, the average kappa statistic for five window sizes increased from 0.24 to 0.76, indicating promise of the range and sill in texture classification.	Univ Calif Berkeley, CAMFER, Berkeley, CA 94720 USA; Nanjing Univ, Int Inst Earth Syst Sci, Nanjing 210093, Peoples R China	Chen, Q (reprint author), Univ Calif Berkeley, CAMFER, Berkeley, CA 94720 USA.	qch@nature.berkeley.edu; gong@nature.berkeley.edu	anzhi, yue/A-8609-2012				Addink EA, 1999, INT J REMOTE SENS, V20, P961, DOI 10.1080/014311699213028; Atkinson PM, 1999, INT J REMOTE SENS, V20, P2663, DOI 10.1080/014311699212001; ATKINSON PM, 1991, INT J REMOTE SENS, V12, P559; Atkinson PM, 2000, COMPUT GEOSCI-UK, V26, P361, DOI 10.1016/S0098-3004(99)00117-X; ATKINSON PM, 1995, IEEE T GEOSCI REMOTE, V33, P1; Bailey T., 1995, INTERACTIVE SPATIAL; Berberoglu S, 2000, COMPUT GEOSCI, V26, P385, DOI 10.1016/S0098-3004(99)00119-3; Carr JR, 1996, COMPUT GEOSCI, V22, P849, DOI 10.1016/S0098-3004(96)00025-8; Carr JR, 1998, IEEE T GEOSCI REMOTE, V36, P1945, DOI 10.1109/36.729366; Chappell A, 2001, INT J REMOTE SENS, V22, P1067, DOI 10.1080/01431160120633; Chica-Olmo M, 2000, COMPUT GEOSCI, V26, P373, DOI 10.1016/S0098-3004(99)00118-1; CRESSIE N, 1984, STAT PROBABIL LETT, V2, P299, DOI 10.1016/0167-7152(84)90069-5; CRESSIE N, 1980, J INT ASS MATH GEOL, V12, P115, DOI 10.1007/BF01035243; Curran PJ, 1998, PROG PHYS GEOG, V22, P61, DOI 10.1177/030913339802200103; CURRAN PJ, 1988, REMOTE SENS ENVIRON, V24, P493, DOI 10.1016/0034-4257(88)90021-1; Friedman J. H., 1984, 5 STANF U DEP STAT L; GONG P, 1992, PHOTOGRAMM ENG REM S, V58, P423; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; Hastie T., 2001, ELEMENTS STAT LEARNI; Herzfeld UC, 1996, COMPUT GEOSCI, V22, P35, DOI 10.1016/0098-3004(96)89522-7; HERZFELD UC, 1993, MATH GEOL, V25, P901, DOI 10.1007/BF00891050; Insightful Corporation, 2001, S PLUS 6 WIND GUID S, V1; Journel AG, 1978, MINING GEOSTATISTICS; JUPP DLB, 1988, IEEE T GEOSCI REMOTE, V26, P463, DOI 10.1109/36.3050; Lark RM, 1996, INT J REMOTE SENS, V17, P2115; Levesque J, 2003, REMOTE SENS ENVIRON, V84, P589, DOI 10.1016/S0034-4257(02)00182-7; MIRANDA FP, 1992, INT J REMOTE SENS, V13, P2349; Miranda FP, 1996, INT J REMOTE SENS, V17, P3523; Myint SW, 2003, INT J REMOTE SENS, V24, P1925, DOI 10.1080/01431160210155992; PHILIPPE M, 2003, PHOTOGRAM ENG REMOTE, V69, P357; RAMSTEIN G, 1989, INT J REMOTE SENS, V10, P1049; Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261; VanderMeer F, 1996, INT J REMOTE SENS, V17, P1233; WEBSTER R, 1989, REMOTE SENS ENVIRON, V29, P67, DOI 10.1016/0034-4257(89)90079-5; WOODCOCK CE, 1988, REMOTE SENS ENVIRON, V25, P323, DOI 10.1016/0034-4257(88)90108-3; Xu B, 2003, PHOTOGRAMM ENG REM S, V69, P529	36	26	30	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0196-2892			IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	MAY	2004	42	5					1106	1115		10.1109/TGRS.2004.825591		10	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing; Imaging Science & Photographic Technology	Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science & Photographic Technology	821MX	WOS:000221466200018		
J	Vanhoucke, V; Sankar, A				Vanhoucke, V; Sankar, A			Mixtures of inverse covariances	IEEE TRANSACTIONS ON SPEECH AND AUDIO PROCESSING			English	Article						automatic speech recognition; covariance modeling; Gaussian mixture models	HIDDEN MARKOV MODEL; MAXIMUM-LIKELIHOOD; SPEECH RECOGNITION	We describe a model which approximates full covariances in a Gaussian mixture while reducing significantly both the number of parameters to estimate and the computations required to evaluate the Gaussian likelihoods. In this model, the inverse covariance of each Gaussian in the mixture is expressed as a linear combination of a small set of prototype matrices that are shared across components. In addition, we demonstrate the benefits of a subspace-factored extension of this model when representing independent or near-independent product densities. We present a maximum likelihood estimation algorithm for these models, as well as a practical method for implementing it. We show through experiments performed on a variety of speech recognition tasks that this model significantly outperforms a diagonal covariance model, while using far fewer Gaussian-specific parameters. Experiments also demonstrate that a better speed/accuracy tradeoff can be achieved on a real-time speech recognition system.	Speech R&D Grp, Nuance Commun, Menlo Pk, CA 94025 USA	Vanhoucke, V (reprint author), Speech R&D Grp, Nuance Commun, Menlo Pk, CA 94025 USA.	vincent@vanhoucke.com; sankar@nuance.com					Axelrod S, 2002, P ICSLP, P2177; AXELROD S, 2003, P IEEE INT C AC SPEE, V1, P912; Berthold M., 1999, INTELLIGENT DATA ANA; Bilmes J. A., 2000, P IEEE INT C AC SPEE; Bilmes J.A., 1998, TR97021 UC BERK, Patent No. TR-97-021; Boyd S., 2003, CONVEX OPTIMIZATION; BOYD S, 1993, LINEAR ALGEBRA APPL, V188, P63, DOI 10.1016/0024-3795(93)90465-Z; CHEN S, 2000, P NIPS 2000; Chong E. K. P., 2001, INTRO OPTIMIZATION; CLARKE RJ, 1981, IEE PROC-F, V128, P359; DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DHARANIPRAGADA S, 2003, P ICASSP, V1, P904; DIGALAKIS V, 1994, P IEEE INT C AC SPEE, V1, P537; DIGALAKIS V, 1998, P INT C SPOK LANG PR; Digalakis V, 2000, COMPUT SPEECH LANG, V14, P33, DOI 10.1006/csla.1999.0134; Digalakis VV, 1996, IEEE T SPEECH AUDI P, V4, P281, DOI 10.1109/89.506931; DOHERTY B, 2000, P IEEE INT C AC SPEE, V2, P969; Eisele T., 1996, Proceedings ICSLP 96. Fourth International Conference on Spoken Language Processing (Cat. No.96TH8206), DOI 10.1109/ICSLP.1996.607092; Gales MJF, 1999, IEEE T SPEECH AUDI P, V7, P272, DOI 10.1109/89.759034; GERSO A, 1992, VECTOR QUANTIZATION; GOPINATH RA, 1998, P INT C SPOK LANG PR; GRAY RM, 2002, P MATH SCI RES I WOR, P189; Hastie T., 2001, ELEMENTS STAT LEARNI; Hermansky H, 1994, IEEE T SPEECH AUDI P, V2, P578, DOI 10.1109/89.326616; HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423; JUANG BH, 1985, AT&T TECH J, V64, P1235; LEDOIT O, 1995, THESIS MIT CAMBRIDGE; LJOLJE A, 1994, COMPUT SPEECH LANG, V8, P223, DOI 10.1006/csla.1994.1011; Mak BKW, 2001, IEEE T SPEECH AUDI P, V9, P378; MYRVOLL TA, 2003, P EUR C SPEECH COMM; OLSEN P, 2002, P IEEE INT C AC SPEE; SANKAR A, 1998, P INT C SPOK LANG PR; VAHOUCKE V, 2003, P IEEE INT C AC SPEE; VISWESWARIAH K, 2003, P IEEE INT C AC SPEE	35	13	13	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1063-6676			IEEE T SPEECH AUDI P	IEEE Trans. Speech Audio Process.	MAY	2004	12	3					250	264		10.1109/TSA.2004.825675		15	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	814VN	WOS:000221002300005		
J	Rueda, IEA; Arciniegas, FA; Embrechts, MJ				Rueda, IEA; Arciniegas, FA; Embrechts, MJ			SVM sensitivity analysis: An application to currency crises aftermaths	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART A-SYSTEMS AND HUMANS			English	Article						banking; currency crises; machine learning; support vector machines; variable selection	SUPPORT VECTOR MACHINES; SELECTION; REGRESSION	A currency crisis is an economic event where a country's fixed exchange rate is under pressure by speculators. In some cases, currency crises are followed by strong recessions (e.g., recent Asian and Argentinean crises), but in other cases they are not. This paper seeks to determine what are the most significant factors in explaining the consequences of currency crises on the economy. This paper collects data on 25 variables for 64 currency crises between 1970 and 1999. This research uses a novel algorithm with support vector machines (SVM) for selecting significant variables. This algorithm works well with datasets characterized by nonlinearity and low variable-observation ratio. Variables of banking size and fragility, international trade, and devaluation were the most significant. Variables of banking supervision, economic development, and IMF intervention were found less significant. The variable selection results of the algorithm were compared with all-best subsets variable selection. The results of our algorithm are more consistent with the economic literature than the results from all-best subsets.	Pacific Econ Grp, Madison, WI 53703 USA; Cen Amer Bank Econ Integrat, Tegucigalpa, Honduras; Rensselaer Polytech Inst, Dept Decis Sci & Engn Syst, Troy, NY 12180 USA	Rueda, IEA (reprint author), Pacific Econ Grp, Madison, WI 53703 USA.	iarcin@hotmail.com; arcinf@alum.rpi.edu; embrem@rpi.edu					Akaike H, 1973, P 2 INT S INF THEOR, P267; AMEMIYA T, 1980, INT ECON REV, V21, P331, DOI 10.2307/2526185; BARTH JR, 1999, FINANCIAL REGULATION; BECK T, 1999, FINANCE SOURCES GROW; BI J, 2001, P ADV NEUR INF PROC, V14; BORDO M, 2000, P CARNEGIE ROCHESTER, V53, P81; Calvo G, 1999, CAPITAL INFLOWS COME; CAMDESSUS M, 1999, P SPEECH C EC CRIS R; CARPIO G, 1998, BANKING CRISES EXPEN; CHAGN R, 1998, 6796 WP NAT BUR EC R; Chapelle O, 2000, ADV NEUR IN, V12, P230; Collobert R, 2001, J MACH LEARN RES, V1, P143, DOI 10.1162/15324430152733142; CORSETTI G, 1998, 6833 WP NAT BUR EC R; DEMIRGUC K, 2000, 00156 INT MON FUND; Diaz-Alejandro Carlos F., 1963, J POLITICAL EC, V71, P577; EDISON H, 2000, 662 FED RES SYST BOA; Edwards S, 1997, J MONETARY ECON, V40, P239, DOI 10.1016/S0304-3932(97)00043-3; EICHENGREEN B, 1994, 4898 WP NBER, P57; EMBRECHTS MJ, 2001, P INNS IEEE INT JOIN, P2478; EMBRECHTS MJ, 2001, STRIPMINER; EMBRECHTS MJ, 2001, P 2001 SMCIA MOUNT W, P13; EMMANOUILIDIS C, 2000, P C EV COMP, V1, P309, DOI 10.1109/CEC.2000.870311; Engelbrecht AP, 1995, LECT NOTES COMPUT SC, V930, P382; Frankel J., 1996, CURRENCY CRASHES EME; FURNIVAL GM, 1974, TECHNOMETRICS, V16, P499, DOI 10.2307/1267601; GEORGE EI, 2000, VARIABLE SELECTION P; Glick R., 2000, STOPPING HOT MONEY S; GYLFASON T, 1987, CREDIT POLICY EC ACT, V60; HALL M, 1996, AUSTR COMP SCI C; Hastie T., 2001, ELEMENTS STAT LEARNI; HERBRICH R, 1999, ADV COMPUT EC, P169; HIGGINS M, 2000, FEDERAL RESERVE BANK, P37; Hoaglin DC, 2000, UNDERSTANDING ROBUST; HOCKING R, 1976, BIOMETRICS, P1; HUSSAIN Q, 1999, WP99135 INT MON FUND; John G., 1994, P 11 INT C MACH LEAR, P121; KAMIN S, 1997, SOME MULTICOUNTRY EV; Kaminsky GL, 1999, AM ECON REV, V89, P473, DOI 10.1257/aer.89.3.473; Kewley RH, 2000, IEEE T NEURAL NETWOR, V11, P668, DOI 10.1109/72.846738; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; KRUGMAN P, 1978, J INT ECON, V8, P445, DOI 10.1016/0022-1996(78)90007-7; LAHIRI A, 2000, SHOULD INTEREST RATE; La Porta R, 1998, J POLIT ECON, V106, P1113; Le Cun Y., 1990, ADV NEURAL INFORMATI, V2, P598; LERAY P, 1998, FEATURE SELECTION NE; LOUAYZA N, 2001, 6 INT M LAT AM CAR E; Maddala G., 1992, INTRO ECONOMETRICS; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; MISHKIN FS, 2000, NBER WOKRING PAPER S, V7926; MOMA M, 2001, SIAM ARL VA; PESENTI P, 2000, EC POLICY REV; Rojas-Suarez Liliana, 2001, WP0110 I INT EC; Ruck D. W., 1990, J NEURAL NETWORK COM, V2, P40; RUEDA IEA, 2001, UNDERSTANDING SPECUL; RUEDA IEA, 2001, ADV SELF ORG MAPS; SMOLA A, 1999, INT C ART NEUR NETW; Smola A. J., 1998, NC2TR1998030 ESPRIT; TARR GL, 1991, THESIS AIR FORCE I T; THOMPSON ML, 1978, INT STAT REV, V46, P1, DOI 10.2307/1402505; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; Vapnik VN, 1995, NATURE STAT LEARNING; Wessel MD, 1998, J CHEM INF COMP SCI, V38, P726, DOI 10.1021/ci980029a; ZURADA JM, 1994, IEEE INT S CIRC SYST, V6, P447; 1998, INT CAPITAL MARKETS	64	4	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4427			IEEE T SYST MAN CY A	IEEE Trans. Syst. Man Cybern. Paart A-Syst. Hum.	MAY	2004	34	3					387	398		10.1109/TSMCA.2004.824850		12	Computer Science, Cybernetics; Computer Science, Theory & Methods	Computer Science	813ZG	WOS:000220944400010		
J	Higuchi, I; Eguchi, S				Higuchi, I; Eguchi, S			Robust principal component analysis with adaptive selection for tuning parameters	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						K-fold cross validation; on-line algorithm; reweighted matrix algorithm; influence function; data contamination	ALGORITHM	The present paper discusses robustness against outliers in a principal component analysis (PCA). We propose a class of procedures for PCA based on the minimum psi principle, which unifies various approaches, including the classical procedure and recently proposed procedures. The reweighted matrix algorithm for off-line data and the gradient algorithm for on-line data are both investigated with respect to robustness. The reweighted matrix algorithm is shown to satisfy a desirable property with local convergence, and the on-line gradient algorithm is shown to satisfy an asymptotical stability of convergence. Some procedures in the class involve tuning parameters, which control sensitivity to outliers. We propose a shape-adaptive selection rule for tuning parameters using K-fold cross validation.	Hiroshima Univ, Dept Appl Math, Higashihiroshima 7398527, Japan; Grad Univ Adv Studies, Minato Ku, Tokyo 1068569, Japan; Inst Stat Math, Minato Ku, Tokyo 1068569, Japan	Higuchi, I (reprint author), Hiroshima Univ, Dept Appl Math, 1-4-1,Kagamiyama, Higashihiroshima 7398527, Japan.	HIGUCHI@AMATH.HIROSHIMA-U.AC.JP; EGUCHI@ISM.AC.JP	HIGUCHI, Isao/D-8996-2011; Eguchi, Shinto/A-9103-2012				AMARI SI, 1977, BIOL CYBERN, V26, P175, DOI 10.1007/BF00365229; Campbell N. A., 1980, Applied Statistics, V29, DOI 10.2307/2346896; Croux C, 2000, BIOMETRIKA, V87, P603, DOI 10.1093/biomet/87.3.603; De La Torre F., 2001, INT C COMP VIS; Hampel F., 1986, ROBUST STAT APPROACH; HAMPEL FR, 1974, J AM STAT ASSOC, V69, P383, DOI 10.2307/2285666; Hastie T., 2001, ELEMENTS STAT LEARNI; Haykin S., 1999, NEURAL NETWORKS; Higuchi I., 1998, Neural Computation, V10, DOI 10.1162/089976698300017241; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Huber P., 1981, ROBUST STAT; Hyvarinen A, 1997, NEURAL COMPUT, V9, P1483, DOI 10.1162/neco.1997.9.7.1483; KAMIYA H, 2001, J MULTIVARIATE ANAL, V76, P239; McLachlan GJ, 1997, EM ALGORITHM EXTENSI; OJA E, 1982, J MATH BIOL, V15, P267, DOI 10.1007/BF00275687; Oja E., 1989, International Journal of Neural Systems, V1, DOI 10.1142/S0129065789000475; CAUSSINUS H, 1990, COMPSTAT 1990 : PROCEEDINGS IN COMPUTATIONAL STATISTICS, P121; TANAKA Y, 1988, COMMUN STAT THEORY, V17, P3157, DOI 10.1080/03610928808829796; WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060; XU L, 1995, IEEE T NEURAL NETWOR, V6, P131	20	19	19	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	MAY	2004	5						453	471				19	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026GN	WOS:000236327500001		
J	Amaratunga, D; Cabrera, J				Amaratunga, D; Cabrera, J			Mining data to find subsets of high activity	JOURNAL OF STATISTICAL PLANNING AND INFERENCE			English	Article; Proceedings Paper	Conference on Contemporary Data Analysis	MAR 05-MAY 09, 2001	Buenos Aires, ARGENTINA	Minerva Res Fdn	Acad Nacl Ciencias Exactas, Fis Natl	ARF; data mining; recursive partitioning; classification tree		Many data mining problems in biometrics research are concerned with trying to identify the characteristics of a subset of cases that responds substantially differently from the rest of the cases. For example, when studying the relationship between a response variable Y and a set of predictor variables, it is often of interest to determine what ranges of values of the predictor variables are associated with a high likelihood of Y = 1 (if Y is a Bernoulli variable) or with high values of Y (if Y is a continuous variable). We describe a criterion (H) and a recursive partitioning method (ARF) that directly addresses this question. A computational algorithm that makes ARF feasible for use even with very large datasets is presented. The basic version of ARF can be generalized to the case of multiple response variables, Y1,...,Y-t and other settings. We illustrate the effectiveness of ARF by mining a structure activity database, a hospital database, and some other real and simulated datasets. We conclude by proposing a basic paradigm for data mining. (C) 2003 Published by Elsevier B.V.	Johnson & Johnson Pharmaceut Res & Dev, Raritan, NJ 08807 USA; Rutgers State Univ, Dept Stat, Piscataway, NJ 08855 USA	Cabrera, J (reprint author), Johnson & Johnson Pharmaceut Res & Dev, Raritan, NJ 08807 USA.	damaratu@prius.jnj.com; cabrera@stat.rutgers.edu					Agresti A., 1990, CATEGORICAL DATA ANA; Blake C.L., 1998, UCI REPOSITORY MACHI; Breiman L., 1984, CLASSIFICATION REGRE; CABRERA J, 2002, STAT CONSULTING; Clark L.A., 1992, STAT MODELS S WADSWO; Fayyad U.M., 1996, ADV KNOWLEDGE DISCOV; FRIEDMAN JH, 1998, DATA MINING STAT WHA; Friedman JH, 1999, STAT COMPUT, V9, P123, DOI 10.1023/A:1008894516817; GORDON L, 1986, PROBAB THEORY REL, V72, P279, DOI 10.1007/BF00699107; Hartigan J.A., 1975, CLUSTERING ALGORITHM; Hastie T., 2001, ELEMENTS STAT LEARNI; HAWKINS DM, 1982, TOPICS MULTIVARIATE; LEE YS, 1999, UNPUB DATA MINING CR; MORGAN JN, 1963, J AM STAT ASSOC, V58, P415, DOI 10.2307/2283276; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Schilling M. F., 1990, COLL MATH J, V21, P196, DOI 10.2307/2686886; Tukey J.W., 1977, EXPLORATORY DATA ANA; TUKEY JW, 1962, ANN MATH STAT, V33, P1, DOI 10.1214/aoms/1177704711	18	9	9	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0378-3758			J STAT PLAN INFER	J. Stat. Plan. Infer.	MAY 1	2004	122	1-2					23	41		10.1016/j.jspi.2003.06.014		19	Statistics & Probability	Mathematics	806ES	WOS:000220417800004		
J	Rosasco, L; De Vito, E; Caponnetto, A; Piana, M; Verri, A				Rosasco, L; De Vito, E; Caponnetto, A; Piana, M; Verri, A			Are loss functions all the same?	NEURAL COMPUTATION			English	Article							LEARNING-THEORY; NETWORKS	In this letter, we investigate the impact of choosing different loss functions from the viewpoint of statistical learning theory. We introduce a convexity assumption, which is met by all loss functions commonly used in the literature, and study how the bound on the estimation error changes with the loss. We also derive a general result on the minimizer of the expected risk for a convex loss function in the case of classification. The main outcome of our analysis is that for classification, the hinge loss appears to be the loss of choice. Other things being equal, the hinge loss leads to a convergence rate practically indistinguishable from the logistic loss rate and much better than the square loss rate. Furthermore, if the hypothesis space is sufficiently rich, the bounds obtained for the hinge loss are not loosened by the thresholding stage.	Univ Genoa, DISI, INFM, I-16146 Genoa, Italy; Univ Modena, Dipartimento Matemat, I-41100 Modena, Italy; Ist Nazl Fis Nucl, Sez Genova, I-16146 Genoa, Italy	Rosasco, L (reprint author), Univ Genoa, DISI, INFM, I-16146 Genoa, Italy.	rosasco@disi.unige.it; devito@unimo.it; caponnetto@disi.unige.it; piana@dima.unige.it; verri@disi.unige.it					Alon N., 1993, Proceedings. 34th Annual Symposium on Foundations of Computer Science (Cat. No.93CH3368-8), DOI 10.1109/SFCS.1993.366858; ARONSZAJN N, 1950, T AM MATH SOC, V68, P337; Cristianini N, 2000, INTRO SUPPORT VECTOR; Cucker F, 2002, B AM MATH SOC, V39, P1; Cucker F, 2002, FOUND COMPUT MATH, V2, P413, DOI 10.1007/s102080010030; Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316; GIROSI F, 1995, NEURAL COMPUT, V7, P219, DOI 10.1162/neco.1995.7.2.219; Hastie T., 2001, ELEMENTS STAT LEARNI; LIN G, 2003, MACH LEARN, V48, P115; LUGOSI G, IN PRESS ANN STAT; PONTIL M, IN PRESS J COMPLEXIT; ROCKAFELLAR RT, 1970, CONEX ANAL; ROSASCO L, 2003, DISITR0307 U GEN DEP; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik VN, 1995, NATURE STAT LEARNING; Wahba G., 1990, SPLINES MODELS OBSER; ZHANG T, IN PRESS ANN STAT; Zhou DX, 2002, J COMPLEXITY, V18, P739, DOI 10.1006/jcom.2002.0635	18	14	17	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	0899-7667			NEURAL COMPUT	Neural Comput.	MAY	2004	16	5					1063	1076		10.1162/089976604773135104		14	Computer Science, Artificial Intelligence	Computer Science	806OK	WOS:000220443000007	15070510	
J	Ma, JS; Theiler, J; Perkins, S				Ma, JS; Theiler, J; Perkins, S			Two realizations of a general feature extraction framework	PATTERN RECOGNITION			English	Article						nonlinear feature extraction; multi-class feature extraction; class separability; regularization; discriminant analysis; kernel functions; classification		A general feature extraction framework is proposed as an extension of conventional linear discriminant analysis. Two nonlinear feature extraction algorithms based on this framework are investigated. The first is a kernel function feature extraction (KFFE) algorithm. A disturbance term is introduced to regularize the algorithm. Moreover, it is revealed that some existing nonlinear feature extraction algorithms are the special cases of this KFFE algorithm. The second feature extraction algorithm, mean-STD1-norm feature extraction algorithm, is also derived from the framework. Experiments based on both synthetic and real data are presented to demonstrate the performance of both feature extraction algorithms. (C) 2003 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Los Alamos Natl Lab, Los Alamos, NM 87544 USA	Ma, JS (reprint author), Los Alamos Natl Lab, POB 1663, Los Alamos, NM 87544 USA.	junshui@osc.edu					ACHLIOPTAS D, 2002, ADV NEURAL INFORMATI, V14; Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; FOWLKES EB, 1988, J CLASSIF, V5, P205, DOI 10.1007/BF01897164; Fukunaga K, 1990, INTRO STAT PATTERN R; Garber F. D., 1988, Proceedings of the 1988 IEEE National Radar Conference (Cat. No.88CH2572-6), DOI 10.1109/NRC.1988.10934; Gordon A. D., 1999, CLASSIFICATION; Hastie T., 2001, ELEMENTS STAT LEARNI; Lee C., 1993, IEEE T GEOSCI REMOTE, V15, P388; Li J, 1996, IEEE T SIGNAL PROCES, V44, P281; MA J, 2001, THESIS OHIO STAT U; MA J, 2002, P INT C MACH LEARN A, P127; MA J, 2003, RADAR SIGNAL PROCESS, V14, P25; Ma JS, 2003, NEUROCOMPUTING, V50, P479, DOI 10.1016/S0925-2312(02)00673-2; Mika S, 2001, ADV NEUR IN, V13, P591; Mika S., 1999, P IEEE NEUR NETW SIG, P41; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Potter LC, 1997, IEEE T IMAGE PROCESS, V6, P79, DOI 10.1109/83.552098; Roth V, 2000, ADV NEUR IN, V12, P568; Ruiz A, 2001, IEEE T NEURAL NETWOR, V12, P16, DOI 10.1109/72.896793; SAITO N, 1994, LOCAL DISCRIMINANT B; Scholkopf B., 1999, ADV KERNEL METHODS; Suszcynsky DM, 2000, J GEOPHYS RES-ATMOS, V105, P2191, DOI 10.1029/1999JD900993; Van Trees H. L., 1968, DETECTION ESTIMATI 1; Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585893; YOUNG TY, 1971, IEEE T COMPUT, VC 20, P967, DOI 10.1109/T-C.1971.223390; ZHAO W, 1998, DISCRIMINANT ANAL PR, P73; ZHAO W, 2000, P INT C PATT REC BAR	28	4	6	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	MAY	2004	37	5					875	887		10.1016/j.patcog.2003.10.010		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	810AM	WOS:000220677200002		
J	Duch, W; Setiono, R; Zurada, JM				Duch, W; Setiono, R; Zurada, JM			Computational intelligence methods for rule-based data understanding	PROCEEDINGS OF THE IEEE			English	Review						data mining; decision support; decision trees; feature selection; fuzzy systems; inductive learning; logical rule extraction; machine learning (ML); neural networks; neurofuzzy systems	ARTIFICIAL NEURAL-NETWORKS; DECISION TREES; FUZZY-SYSTEMS; CLASSIFICATION RULES; EXTRACTING RULES; OPTIMIZATION; FEEDFORWARD; CLASSIFIERS; GENERATION; INVERSION	In many applications, black-box prediction is not satisfactory, and understanding the data is of critical importance. Typically;, approaches useful for understanding of data involve logical rules, evaluate similarity to prototypes, or are based on visualization or graphical methods. This paper is focused on the extraction and use of logical rules for data understanding. All aspects of rule generation, optimization, and application ore described, including the problem of finding good symbolic descriptors for continuous data, tradeoffs between accuracy and simplicity at the rule-extraction stage, and tradeoffs between rejection and error level at the rule optimization stage. Stability of rule-based description, calculation of probabilities front rules, and other related issues are also discussed. Major approaches to extraction of logical rules based oil neural networks, decision trees, machine learning, and statistical methods are introduced. Optimization and application issues for sets of logical rules are described. Applications of such methods to benchmark and real-life problems are reported and illustrated with simple logical rules for many datasets. Challenges and new directions for research are outlined.	Nicholas Copernicus Univ, Dept Informat, PL-87100 Torun, Poland; Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore; Natl Univ Singapore, Sch Comp, Singapore 119260, Singapore; Univ Louisville, Dept Elect & Comp Engn, Louisville, KY 40292 USA	Duch, W (reprint author), Nicholas Copernicus Univ, Dept Informat, PL-87100 Torun, Poland.	duch@ieee.org; rudys@comp.nus.edu.sg; j.zurada@ieee.org	Duch, Wlodzislaw/A-2002-2011; Zurada, Jacek/B-8687-2013	Duch, Wlodzislaw/0000-0001-7882-4729; 			ALEXANDER JA, 1995, ADV NEURAL INFORMATI, V7, P609; Andrews R., 1994, P 5 AUSTR C NEUR NET, P9; ANDREWS R, 1996, RUL EXTR TRAIN ART N; ANDREWS R, 1997, P INT C NEUR INF PRO, V2, P847; Andrews R, 1995, KNOWL-BASED SYST, V8, P373, DOI 10.1016/0950-7051(96)81920-4; Bennett K. P., 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; Bezdek JC, 1981, PATTERN RECOGNITION; BISHOP C.M., 1995, NEURAL NETWORKS PATT; BLIGIC T, 2000, FUNDAMENTALS FUZZY S, V1, P195; Bowers A.F., 2000, P 17 INT C MACH LEAR, P81; Breiman L., 1984, CLASSIFICATION REGRE; BRIEMAN L, 1998, NEURAL NETWORKS MACH; BRODLEY CE, 1995, MACH LEARN, V19, P45, DOI 10.1007/BF00994660; BROWNE C, 1998, ROUGH SETS KNOWLEDGE, V2, P345; Butcher JN, 1996, ANNU REV PSYCHOL, V47, P87, DOI 10.1146/annurev.psych.47.1.87; Cestnik G., 1987, PROGR MACHINE LEARNI, P31; Clark A.J.L., 1988, J MOL ENDOCRINOL, V2, P3; Cohen W.W., 1995, P 12 INT C MACH LEAR, P115; Combs WE, 1998, IEEE T FUZZY SYST, V6, P1, DOI 10.1109/91.660804; Craven M.W., 1994, P 11 INT C MACH LEAR, P37; Craven MW, 1996, ADV NEUR IN, V8, P24; DOUGHERTY D, 1995, MACH LEARN 12 INT C; DUCH W, 2000, FUZZY SYSTEMS MED, P593; Duch W, 2001, IEEE T NEURAL NETWOR, V12, P277, DOI 10.1109/72.914524; Duch W., 1999, P 4 C NEUR NETW THEI, P65; Duch W., 1999, NEURAL COMPUTING SUR, V2, P163; DUCH W, GHOSTMINER SOFTWARE; DUCH W, P EUR S ART NEUR NET, P109; DUCH W, 1997, P 3 C NEUR NETW KUL, P99; DUCH W, 1999, P ENG APPL NEUR NETW, P45; DUCH W, 1996, P 1 ONL WORKSH SOFT, P25; DUCH W, 1998, NEURAL PROCESS LETT, V7, P1; DUCH W, 2000, P 7 INT C NEUR INF P, P1029; DUCH W, 1999, P 6 INT C NEUR INF P, V2, P616; Duch W, 2000, ADV SOFT COMP, P1; DUCH W, 1999, INT JOINT C NEUR NET; DUCH W, 1994, NEURAL NETWORK WORLD, V4, P645; DUCH W, 2001, P INT JOINT C NEUR N, P1858; DUCH W, 1999, INT J ADV COMPUT INT, V3, P348; DUCH W, 1997, P 3 C NEUR NETW, P65; DUCH W, 2003, P INT JOINT C NEUR N, V1, P1735; DUCH W, 1995, COMPUT PHYS COMMUN, V87, P341, DOI 10.1016/0010-4655(95)00023-9; Duda R.O., 2001, PATTERN CLASSIFICATI; Fawcett T., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989510; FAYYAD UM, 1993, 13 INT JOINT C ART I; Frasconi P, 1998, IEEE T NEURAL NETWOR, V9, P768, DOI 10.1109/72.712151; Fu L., 1994, NEURAL NETWORKS COMP; FU LM, 1994, IEEE T SYST MAN CYB, V24, P1114; FU LM, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P590; FU LM, 1993, IEEE T SYST MAN CYB, V23, P173, DOI 10.1109/21.214775; Gallant S. I., 1993, NEURAL NETWORK LEARN; GAWEDA AE, 2003, P INT JOINT C NEUR N, V11, P121; GAWEDA AE, P INT JOINT C NEUR N, V3, P1; GOLDFARB L, 1995, PATTERN RECOGN LETT, V16, P719, DOI 10.1016/0167-8655(95)00024-B; Grabczewski K, 2002, LECT NOTES COMPUT SC, V2415, P504; Grabczewski K, 1999, P 4 C NEUR NETW THEI, P203; GRZYMALABUSSE JW, 1998, P WORKSH INT INF SYS, V7, P371; Guven MK, 2001, IEEE T FUZZY SYST, V9, P194; HALGAMUGE SK, 1994, FUZZY SET SYST, V65, P1, DOI 10.1016/0165-0114(94)90242-9; HAND D, 2001, PRINCIPLES DATA MIN; HANLEY JA, 1982, RADIOLOGY, V143, P29; Hastie T., 2001, ELEMENTS STAT LEARNI; HAYASHI Y, 1991, ADV NEURAL INFORMATI, V3, P578; Hayashi Y, 2000, ARTIF INTELL MED, V20, P205, DOI 10.1016/S0933-3657(00)00064-6; HAYASHI Y, 1990, P 8 INT C CYB SYST N, P54; HAYWARD R, 1996, RULENEG EXTRACTING R; Healy MJ, 1997, IEEE T NEURAL NETWOR, V8, P461, DOI 10.1109/72.572088; Heath D. G., 1993, P 13 INT JOINT C ART, P1002; Hernandez-Espinosa C, 2003, LECT NOTES COMPUT SC, V2714, P670; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; Huang SL, 2002, CELL MOL BIOL LETT, V7, P233; ISHIKAWA M, 1996, P 1996 IEEE ICNN WAS, P1139; JAGIELSKA I, 1996, P 4 INT C SOFT COMP, V2, P565; Jambu M., 1991, EXPLORATORY MULTIVAR; JANG JSR, 1993, IEEE T NEURAL NETWOR, V4, P156, DOI 10.1109/72.182710; JANG JSR, 1997, NEUROFUZZY SOFTCOMPU; Jankowski N., 1997, P 7 INT C ART NEUR N, P385; Jensen CA, 1999, P IEEE, V87, P1536, DOI 10.1109/5.784232; Jordan M.I., 2001, GRAPHICAL MODELS FDN; Kanal L., 1988, SEARCH ARTIFICIAL IN; Kasabov N., 1998, PROF 4 INT C NEUR NE, P403; Kasabov N. K., 1996, FDN NEURAL NETWORKS; KECMAN V, 2001, LEARNING SOFT COMPU; Kohavi R., 1996, P 2 INT C KNOWL DISC, P114; KORDOS M, 2003, P INT C ART NEUR NET, P86; KORDOS M, 2003, P INT C ART NEUR NET, P106; Kosko B, 1992, NEURAL NETWORKS FUZZ; Kuncheva LI, 2000, IEEE T SYST MAN CY B, V30, P501, DOI 10.1109/3477.865167; Langley P., 1987, SCI DISCOVERY COMPUT; Lavrac N., 1994, INDUCTIVE LOGIC PROG; Liu H, 1996, KNOWL-BASED SYST, V9, P67, DOI 10.1016/0950-7051(95)01030-0; Lu HJ, 1996, IEEE T KNOWL DATA EN, V8, P957; MACKAY DJC, 1992, NEURAL COMPUT, V4, P448, DOI 10.1162/neco.1992.4.3.448; MAHONEY JJ, 1993, ADV NEURAL INFORM PR, V5, P107; MANGASARIAN OL, 1989, LARGE SCALE NUMERICA, P22; MARKS RJ, 1992, INT JOINT C NEUR NET; MCMILLAN MC, 1992, ADV NEURAL INFORMATI, V4, P969; MERTZ J, UCI REP MACHINE LEAR; Michalski R., 1997, MACHINE LEARNING DAT; Michalski R. S, 1983, ARTIF INTELL, V20, P11; Michalski R. S., 1969, P 5 INT S INF PROC A, P125; Michalski R. S., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; Michie D., 1994, MACHINE LEARNING NEU; Mitchell T., 1997, MACHINE LEARNING; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; Mitra S, 1997, IEEE T NEURAL NETWOR, V8, P1338, DOI 10.1109/72.641457; MONTI S, 1999, UNC 99 7 INT WORKSH; MURTHY S, 1993, PROCEEDINGS OF THE ELEVENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P322; NAUCK D, BIENN C N AM FUZZ IN; Nauck D., 1997, FDN NEUROFUZZY SYSTE; Oates T., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Pal S. K., 1999, NEUROFUZZY PATTERN R; Pal S.K., 1999, ROUGH FUZZY HYBRIDIZ; Pawlak Z., 1991, ROUGH SETS THEORETIC; Pop E., 1994, RULENEG EXTRACTING R; Quinlan J. R., 1993, PROGRAMS MACHINE LEA; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1995, NEW GENERAT COMPUT, V13, P287; Ripley BD, 1996, PATTERN RECOGNITION; ROTH I, 1995, PERCEPTION REPRESENA; Saito K., 1988, P IEEE INT C NEURAL, V1, P255; Schiffmann W., 1993, P EUR S ART NEUR NET, P97; Sestito S., 1994, AUTOMATED KNOWLEDGE; SETHI IK, 1994, PATTERN RECOGNITION, V4; Setiono R, 2000, ARTIF INTELL MED, V18, P205, DOI 10.1016/S0933-3657(99)00041-X; Setiono R, 2000, APPL INTELL, V12, P15, DOI 10.1023/A:1008307919726; Setiono R, 1997, NEURAL COMPUT, V9, P205, DOI 10.1162/neco.1997.9.1.205; Setiono R, 1999, IEEE T SYST MAN CY B, V29, P440, DOI 10.1109/3477.764880; Setiono R, 1995, P 14 INT JOINT C ART, P480; Setiono R., 2001, IEEE T NEURAL NETWOR, V11, P306; Setiono R, 1996, COMPUTER, V29, P71, DOI 10.1109/2.485895; SHANG N, 1996, P INT C NEUR INF PRO, V1, P133; Sourina O., 1996, International Journal of Information Technology, V2; STER B, P INT C EANN 96, P427; Surmann H, 2001, J SYST ARCHITECT, V47, P649, DOI 10.1016/S1383-7621(01)00021-2; TAN AH, P 1993 CONNECTIONIS, P192; TAN M, 1988, P 5 INT C MACH LEARN, P121; TEGHEM J, 1992, INTELLIGENT DECISION, V11, P267; THRUN S, 1995, ADV NEURAL INFORMATI, V7; Tickle A. B., 1994, DEDEC DECISION DETEC; Tickle AB, 1998, IEEE T NEURAL NETWOR, V9, P1057, DOI 10.1109/72.728352; TOWELL GG, 1993, MACH LEARN, V13, P71, DOI 10.1023/A:1022683529158; TOWELL GG, 1994, ARTIF INTELL, V70, P119, DOI 10.1016/0004-3702(94)90105-8; TRESP V, 1993, ADV NEURAL INFORMATI, V5, P871; Tukey J.W., 1977, EXPLORATORY DATA ANA; Ultsch A., 1993, INFORMATION CLASSIFI, P301; Weiss S. M., 1990, READINGS MACHINE LEA; Weiss S.M., 1990, COMPUTER SYSTEMS LEA; Yager RR, 1996, FUZZY SET SYST, V80, P57, DOI 10.1016/0165-0114(95)00131-X; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; ZARNDT F, 1995, THESIS BRIGHAM YOUNG; Zurada J. M., 1992, INTRO ARTIFICIAL NEU; ZURADA JM, 1996, P 4 INT C SOFT COMP, V2, P618	153	90	91	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9219			P IEEE	Proc. IEEE	MAY	2004	92	5					771	805		10.1109/JPROC.2004.826605		35	Engineering, Electrical & Electronic	Engineering	814TU	WOS:000220997800002		
J	Ding, J; Gribok, AV; Hines, JW; Rasmussen, B				Ding, J; Gribok, AV; Hines, JW; Rasmussen, B			Redundant sensor calibration monitoring using independent component analysis and principal component analysis	REAL-TIME SYSTEMS			English	Article; Proceedings Paper	5th International Conference on Computational Intelligent Systems for Applied Research	SEP 16-18, 2002	Ghent, BELGIUM			independent component analysis; principal component analysis; sensor calibration; process monitoring; parameter estimation	BLIND SEPARATION; IDENTIFICATION; REGRESSION; ALGORITHM; STRATEGY	This paper presents a comparison of methods for industrial on-line sensor calibration monitoring for redundant sensors. Principal component analysis (PCA) and independent component analysis (ICA) techniques are developed and compared using both simulated data and data sets from an operating nuclear power plant. The performance is dependent on the types of noise sources; however, under most conditions ICA outperforms PCA, based on the bias and variance of their respective parameter estimates. A case study is included to demonstrate the usefulness of both techniques for the early detection of sensor drift.	Univ Tennessee, Dept Nucl Engn, Knoxville, TN 37996 USA; Univ Tennessee, Dept Elect & Comp Engn, Knoxville, TN 37996 USA	Ding, J (reprint author), Univ Tennessee, Dept Nucl Engn, Knoxville, TN 37996 USA.	jding@utk.edu; agribok@utk.edu; jhines2@utk.edu; brandonprasmussen@yahoo.com					Amand T, 2001, COMPUT CHEM ENG, V25, P501, DOI 10.1016/S0098-1354(01)00630-5; Cardoso JF, 1992, P EUSIPCO, P739; CICHOCKI A, 2002, SIGNAL PROCESS, V36, P287; COMON P, 1991, SIGNAL PROCESS, V24, P11, DOI 10.1016/0165-1684(91)90080-3; DAVIS E, 1995, WO378502 EPRI; DAVIS E, 1998, TR104965 EPRI; Doymaz F, 2001, J PROCESS CONTR, V11, P343, DOI 10.1016/S0959-1524(00)00004-4; Doymaz F, 2001, CHEMOMETR INTELL LAB, V55, P109, DOI 10.1016/S0169-7439(00)00126-X; Dunia R, 1998, COMPUT CHEM ENG, V22, P927, DOI 10.1016/S0098-1354(97)00277-9; Dunia R, 1996, AICHE J, V42, P2797, DOI 10.1002/aic.690421011; Giannakopoulos X., 1999, INT J NEURAL SYST, V9, P651; GROSS KC, 1991, NUCL TECHNOL, V93, P131; Hastie T., 2002, ELEMENTS STAT LEARNI; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; HyvAarinen A., 2001, INDEPENDENT COMPONEN, P1; Hyvarinen A, 1999, IEEE T NEURAL NETWOR, V10; Joliffe I., 1986, PRINCIPAL COMPONENT; JUTTEN C, 1991, SIGNAL PROCESS, V24, P1, DOI 10.1016/0165-1684(91)90079-X; Kano M, 2000, COMPUT CHEM ENG, V24, P175, DOI 10.1016/S0098-1354(00)00509-3; Kano M, 2001, COMPUT CHEM ENG, V25, P1103, DOI 10.1016/S0098-1354(01)00683-4; MARBACH R, 1990, CHEMOMETR INTELL LAB, V9, P45, DOI 10.1016/0169-7439(90)80052-8; Martens H., 1989, MULTIVARIATE CALIBRA; *MATHW INC, 1999, HIGH EPRF NUM COMP V; *NRC, 104965 TR NRC; Pearson K, 1901, PHILOS MAG, V2, P559; Ray A, 2000, AUTOMATICA, V36, P1525, DOI 10.1016/S0005-1098(00)00067-4; Seiter JC, 2001, TALANTA, V54, P99, DOI 10.1016/S0039-9140(00)00635-4; Vigneau E, 2002, COMPUT STAT DATA AN, V41, P231, DOI 10.1016/S0167-9473(02)00071-3; Wald A, 1947, SEQUENTIAL ANAL; WISE BM, 1997, IFAC SAFEPROCESS 97, P35; WOOTEN B, 1993, TR103436V1 EPRI	31	3	3	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0922-6443			REAL-TIME SYST	Real-Time Syst.	MAY	2004	27	1					27	47		10.1023/B:TIME.0000019125.96107.ac		21	Computer Science, Theory & Methods	Computer Science	801KE	WOS:000220094000003		
J	Goodacre, R; Vaidyanathan, S; Dunn, WB; Harrigan, GG; Kell, DB				Goodacre, R; Vaidyanathan, S; Dunn, WB; Harrigan, GG; Kell, DB			Metabolomics by numbers: acquiring and understanding global metabolite data	TRENDS IN BIOTECHNOLOGY			English	Review							ARTIFICIAL NEURAL-NETWORKS; SYSTEMS BIOLOGY; MASS-SPECTROMETRY; EXPLANATORY ANALYSIS; HUMAN GENOME; METABONOMICS; ORGANIZATION; HYPOTHESIS; SEQUENCE; CHROMATOGRAPHY	In this postgenomic era, there is a specific need to assign function to orphan genes in order to validate potential targets for drug therapy and to discover new biomarkers of disease. Metabolomics is an emerging field that is complementary to the other 'omics and proving to have unique advantages. As in transcriptomics or proteomics, a typical metabolic fingerprint or metabolomic experiment is likely to generate thousands of data points, of which only a handful might be needed to describe the problem adequately. Extracting the most meaningful elements of these data is thus key to generating useful new knowledge with mechanistic or explanatory power.	Univ Manchester, Dept Chem, Manchester M60 1QD, Lancs, England; Pfizer, Global HTS, Chesterfield, MO 63198 USA	Goodacre, R (reprint author), Univ Manchester, Dept Chem, POB 88,Sackville St, Manchester M60 1QD, Lancs, England.	r.goodacre@umist.ac.uk	Kell, Douglas/E-8318-2011; Goodacre, Roy/J-1600-2012; Vaidyanathan, Seetharaman/J-6477-2013	Kell, Douglas/0000-0001-5838-7963; Goodacre, Roy/0000-0003-2230-645X; 			Aharoni Asaph, 2002, OMICS A Journal of Integrative Biology, V6, P217, DOI 10.1089/15362310260256882; Allen J, 2003, NAT BIOTECHNOL, V21, P692, DOI 10.1038/nbt823; Alm E, 2003, CURR OPIN STRUC BIOL, V13, P193, DOI 10.1016/S0959-440X(03)00031-9; Altshuler D, 2000, NAT GENET, V26, P135, DOI 10.1038/79839; ANDERSON S, 1981, NATURE, V290, P457, DOI 10.1038/290457a0; Back T, 1997, HDB EVOLUTIONARY COM; Barabasi AL, 2004, NAT REV GENET, V5, P101, DOI 10.1038/nrg1272; Beecher CWW, 2003, METABOLIC PROFILING: ITS ROLE IN BIOMARKER DISCOVERY AND GENE FUNCTION ANALYSIS, P311; Blattner FR, 1997, SCIENCE, V277, P1453, DOI 10.1126/science.277.5331.1453; Brazma A, 2001, NAT GENET, V29, P365, DOI 10.1038/ng1201-365; Breiman L., 1984, CLASSIFICATION REGRE; Brenner SE, 1999, TRENDS GENET, V15, P132, DOI 10.1016/S0168-9525(99)01706-0; Brent R, 2000, CELL, V100, P169, DOI 10.1016/S0092-8674(00)81693-1; Brindle JT, 2002, NAT MED, V8, P1439, DOI 10.1038/nm802; Broomhead D. S., 1988, Complex Systems, V2; Duran AL, 2003, BIOINFORMATICS, V19, P2283, DOI 10.1093/bioinformatics/btg315; ELLIS DI, 2002, TRENDS FOOD SCI TECH, V12, P413; Famili I, 2003, P NATL ACAD SCI USA, V100, P13134, DOI 10.1073/pnas.2235812100; Fell D. A, 1996, UNDERSTANDING CONTRO; Fiehn O, 2002, PLANT MOL BIOL, V48, P155, DOI 10.1023/A:1013713905833; Fiehn O, 2001, COMPAR FUNCT GENOM, V2, P155, DOI 10.1002/cfg.82; Weckwerth W, 2002, CURR OPIN BIOTECH, V13, P156, DOI 10.1016/S0958-1669(02)00299-9; FLACH PA, 2000, INDUCTION ABDUCTION; FLEISCHMANN RD, 1995, SCIENCE, V269, P496, DOI 10.1126/science.7542800; Forster J, 2003, GENOME RES, V13, P244, DOI 10.1101/gr.234503; Goodacre R, 1996, ANAL CHEM, V68, P271, DOI 10.1021/ac950671t; HARDY F, 2003, METABOLIC PROFILING; HARRIGAN GG, 2003, METABOLIC PROFILING, P335; HARRINGTON PB, 1991, J CHEMOMETR, V5, P467, DOI 10.1002/cem.1180050506; Hastie T., 2001, ELEMENTS STAT LEARNI; Hucka M, 2003, BIOINFORMATICS, V19, P524, DOI 10.1093/bioinformatics/btg015; Ivanova PT, 2001, P NATL ACAD SCI USA, V98, P7152, DOI 10.1073/pnas.131195098; Jeong H, 2000, NATURE, V407, P651; Kacser H., 1986, ORG CELL METABOLISM, P327; Kanehisa M, 2002, NUCLEIC ACIDS RES, V30, P42, DOI 10.1093/nar/30.1.42; Kell DB, 2000, NATO ASI 3 HIGH TECH, V74, P3; Kell DB, 2001, PLANT PHYSIOL, V126, P943, DOI 10.1104/pp.126.3.943; Kell DB, 2000, TRENDS BIOTECHNOL, V18, P93, DOI 10.1016/S0167-7799(99)01407-9; Kell DB, 2004, BIOESSAYS, V26, P99, DOI 10.1002/bies.10385; Kell DB, 2002, TRENDS GENET, V18, P555, DOI 10.1016/S0168-9525(02)02765-8; KELL DB, 1986, FEMS MICROBIOL LETT, V39, P305, DOI 10.1111/j.1574-6968.1986.tb01863.x; Kell DB, 2002, MOL BIOL REP, V29, P237, DOI 10.1023/A:1020342216314; KELL DB, IN PRESS CURR OPIN M; Kholodenko BN, 2002, P NATL ACAD SCI USA, V99, P12841, DOI 10.1073/pnas.192442699; King RD, 2004, NATURE, V427, P247, DOI 10.1038/nature02236; Kitano H, 2002, SCIENCE, V295, P1662, DOI 10.1126/science.1069492; Koza JR, 2003, GENETIC PROGRAMMING; Leggewie G, 2003, PLANTA, V217, P158, DOI 10.1007/s00425-003-0975-x; LI XJ, 2003, METABOLIC PROFILING; Lindon JC, 2003, ANAL CHEM, V75, p384A, DOI 10.1021/ac031386+; MADDOX J, 1994, NATURE, V368, P95; Manly BF, 1994, MULTIVARIATE STAT ME; Mann M, 2001, ANNU REV BIOCHEM, V70, P437, DOI 10.1146/annurev.biochem.70.1.437; Martens H., 1989, MULTIVARIATE CALIBRA; McPherson JD, 2001, NATURE, V409, P934, DOI 10.1038/35057157; Mendes Pedro, 2002, Brief Bioinform, V3, P134; Muggleton S, 1999, ARTIF INTELL, V114, P283, DOI 10.1016/S0004-3702(99)00067-3; Nicholson JK, 2003, NAT REV DRUG DISCOV, V2, P668, DOI 10.1038/nrd1157; Nicholson JK, 1999, XENOBIOTICA, V29, P1181; Oldroyd David R, 1986, ARCH KNOWLEDGE INTRO; Oliver SG, 1998, TRENDS BIOTECHNOL, V16, P373, DOI 10.1016/S0167-7799(98)01214-1; Petrich W, 2001, APPL SPECTROSC REV, V36, P181, DOI 10.1081/ASR-100106156; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Raamsdonk LM, 2001, NAT BIOTECHNOL, V19, P45; Rashed MS, 2001, J CHROMATOGR B, V758, P27, DOI 10.1016/S0378-4347(01)00100-1; Rowe J., 2002, GENETIC ALGORITHMS P; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, VI; Sanders GHW, 2000, TRAC-TREND ANAL CHEM, V19, P364, DOI 10.1016/S0165-9936(00)00011-X; SEASHOLTZ MB, 1993, ANAL CHIM ACTA, V277, P165, DOI 10.1016/0003-2670(93)80430-S; Shellie R, 2001, ANAL CHEM, V73, P1336, DOI 10.1021/ac000987n; SNOEP JL, 1995, MICROBIOL-UK, V141, P2329; Steuer R, 2003, BIOINFORMATICS, V19, P1019, DOI 10.1093/bioinformatics/btg120; Sweetlove LJ, 2003, PLANT PHYSIOL, V132, P420, DOI 10.1104/pp.103.022004; Taylor CF, 2003, NAT BIOTECHNOL, V21, P247, DOI 10.1038/nbt0303-247; ter Kuile BH, 2001, FEBS LETT, V500, P169, DOI 10.1016/S0014-5793(01)02613-8; Tickle AB, 1998, IEEE T NEURAL NETWOR, V9, P1057, DOI 10.1109/72.728352; Tolstikov VV, 2002, ANAL BIOCHEM, V301, P298, DOI 10.1006/abio.2001.5513; Urbanczyk-Wochniak E, 2003, EMBO REP, V4, P989, DOI 10.1038/sj.embor.embor944; Vaidyanathan S, 2003, ANAL CHEM, V75, P6679, DOI 10.1021/ac034669a; van Mispelaar VG, 2003, J CHROMATOGR A, V1019, P15, DOI 10.1016/j.chroma.2003.08.101; Venter JC, 2001, SCIENCE, V291, P1304, DOI 10.1126/science.1058040; von Bertalanffy L, 1969, GEN SYSTEM THEORY; Wagner A, 2001, P ROY SOC B-BIOL SCI, V268, P1803; WECKWERTH W, 2001, P 49 ASMS C MASS SPE; Weckwerth W, 2003, ANNU REV PLANT BIOL, V54, P669, DOI 10.1146/annurev.arplant.54.031902.135014; WESTERHOFF HV, 1987, BIOTECHNOL BIOENG, V30, P101, DOI 10.1002/bit.260300115; White H., 1992, ARTIFICIAL NEURAL NE; Wilson ID, 2003, XENOBIOTICA, V33, P887, DOI 10.1080/00498250310001598221	88	494	521	ELSEVIER SCIENCE LONDON	LONDON	84 THEOBALDS RD, LONDON WC1X 8RR, ENGLAND	0167-7799			TRENDS BIOTECHNOL	Trends Biotechnol.	MAY	2004	22	5					245	252		10.1016/j.tibtech.2004.03.007		8	Biotechnology & Applied Microbiology	Biotechnology & Applied Microbiology	821BS	WOS:000221435100011	15109811	
J	Laubach, M				Laubach, M			Wavelet-based processing of neuronal spike trains prior to discriminant analysis	JOURNAL OF NEUROSCIENCE METHODS			English	Article						spike train; neural coding; discriminant analysis; pattern recognition; feature extraction; preprocessing; dimension reduction; wavelets	INFERIOR TEMPORAL CORTEX; ENSEMBLE ACTIVITY; INFORMATION; REPRESENTATION; PATTERNS; RATS	Investigations of neural coding in many brain systems have focused on the role of spike rate and timing as two means of encoding information within a spike train. Recently, statistical pattern recognition methods, such as linear discriminant analysis (LDA), have emerged as a standard approach for examining neural codes. These methods work well when data sets are over-determined (i.e., there are more observations than predictor variables). But this is not always the case in many experimental data sets. One way to reduce the number of predictor variables is to preprocess data prior to classification. Here, a wavelet-based method is described for preprocessing spike trains. The method is based on the discriminant pursuit (DP) algorithm of Buckheit and Donoho [Proc. SPIE 2569 (1995) 540-51]. DP extracts a reduced set of features that are well localized in the time and frequency domains and that can be subsequently analyzed with statistical classifiers. DP is illustrated using neuronal spike trains recorded in the motor cortex of an awake, behaving rat [Laubach et al. Nature 405 (2000) 567-71]. In addition, simulated spike trains that differed only in the timing of spikes are used to show that DP outperforms another method for preprocessing spike trains, principal component analysis (PCA). (C) 2003 Elsevier B.V. All rights reserved.	Yale Univ, John B Pierce Lab, New Haven, CT 06519 USA; Yale Univ, Dept Neurobiol, New Haven, CT 06519 USA	Laubach, M (reprint author), Yale Univ, John B Pierce Lab, 290 Congress Ave, New Haven, CT 06519 USA.	mark.laubach@yale.edu	Marion-Poll, Frederic/D-8882-2011				Buckheit J. B., 1995, WAVELAB REPRODUCIBLE; BUCKHEIT JB, 1995, P SOC PHOTO-OPT INS, V2569, P540, DOI 10.1117/12.217608; COIFMAN R, 1992, IEEE T INFORM THEORY, V38, P712; Deadwyler SA, 1996, J NEUROSCI, V16, P354; Efron B., 1994, INTRO BOOTSTRAP; ENGEL AK, 1992, TRENDS NEUROSCI, V15, P218, DOI 10.1016/0166-2236(92)90039-B; Fisher RA, 1936, ANN EUGENIC, V7, P179; FRIEDMAN JH, 1987, J AM STAT ASSOC, V82, P249, DOI 10.2307/2289161; Furukawa S, 2002, J NEUROPHYSIOL, V87, P1749, DOI 10.1152/jn.00491.2001; Ghazanfar AA, 2000, J NEUROSCI, V20, P3761; GOCHIN PM, 1994, J NEUROPHYSIOL, V71, P2325; Hastie T., 2001, ELEMENTS STAT LEARNI; HELLER J, 1995, J COMPUT NEUROSCI, V2, P175, DOI 10.1007/BF00961433; Hyvarinen A, 2001, INDEPENDENT COMPONEN; INTRATOR N, 1997, P 1997 CAN WORKSH IN; Kohonen T., 1997, SELF ORGANIZING MAPS; KRIPPENDORFF K, 1986, INFORMATIVE THEORY S; LAUBACH M, 2003, P 29 ANN NE BIOENG C; Laubach M, 2000, NATURE, V405, P567, DOI 10.1038/35014604; Laubach M, 1999, J NEUROSCI METH, V94, P141, DOI 10.1016/S0165-0270(99)00131-4; LAUBACH M, 1997, THESIS WAKE FOREST U; MILLER EK, 1991, SCIENCE, V254, P1377, DOI 10.1126/science.1962197; Nicolelis M., 1999, METHODS NEURAL ENSEM, P121; Nicolelis MAL, 1997, J NEUROPHYSIOL, V78, P1691; Nicolelis MAL, 1997, NEURON, V18, P529, DOI 10.1016/S0896-6273(00)80295-0; Nicolelis MAL, 1998, NAT NEUROSCI, V1, P621, DOI 10.1038/2855; Penev PS, 1996, NETWORK-COMP NEURAL, V7, P477, DOI 10.1088/0954-898X/7/3/002; RICHMOND BJ, 1987, J NEUROPHYSIOL, V57, P147; Ripley BD, 1996, PATTERN RECOGNITION; SAITO N, 1994, P SOC PHOTO-OPT INS, V2303, P2, DOI 10.1117/12.188763; SCHOENBAUM G, 1995, J NEUROPHYSIOL, V74, P751; Shadlen M N, 1995, Curr Opin Neurobiol, V5, P248, DOI 10.1016/0959-4388(95)80033-6; Softky W R, 1995, Curr Opin Neurobiol, V5, P239, DOI 10.1016/0959-4388(95)80032-8; THEUNISSEN F, 1995, J COMPUT NEUROSCI, V2, P149, DOI 10.1007/BF00961885; Vapnik VN, 2000, NATURE STAT LEARNING; Wickerhauser M. V., 1994, ADAPTED WAVELET ANAL; WOLPAW JR, 1991, ELECTROEN CLIN NEURO, V78, P252, DOI 10.1016/0013-4694(91)90040-B	37	17	18	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0270			J NEUROSCI METH	J. Neurosci. Methods	APR 30	2004	134	2					159	168		10.1016/j.jneumeth.2003.11.007		10	Biochemical Research Methods; Neurosciences	Biochemistry & Molecular Biology; Neurosciences & Neurology	803MA	WOS:000220234000006	15003382	
J	Neumann, A; Holstein, J; Chatellier, G; Lepage, E				Neumann, A; Holstein, J; Chatellier, G; Lepage, E			A regression shrinkage method tailored to qualitative regressors and clustered data	STATISTICS IN MEDICINE			English	Article						regression; shrinkage; qualitative data; clustered data; frailty models		We propose a shrinkage method for estimation in linear regression models with qualitative regressors. Due to the nature of the shrinkage constraint, this method tends to give estimates that are exactly zero for some groups of coefficients belonging to the same regressor. The method hence results in concise models, since some of the regressors are entirely eliminated. In conjunction with this estimation method, a model with a fixed cluster effect turns out to be closely related to frailty models. We apply the method for modelling hospital readmissions. Copyright (C) 2004 John Wiley Sons, Ltd.	AP HP, DIME, DIREQ, DPM, F-75184 Paris 04, France	Neumann, A (reprint author), AP HP, DIME, DIREQ, DPM, 3 Ave Victoria, F-75184 Paris 04, France.	anke.neumann@sap.ap-hop-paris.fr					Fang K.T., 1990, SYMMETRIC MULTIVARIA; Halfon P, 2002, J CLIN EPIDEMIOL, V55, P573, DOI 10.1016/S0895-4356(01)00521-2; Hastie T., 2001, ELEMENTS STAT LEARNI; HOERL AE, 1970, TECHNOMETRICS, V12, P55; KELKER D, 1970, SANKHYA SER A, V32, P419; MCGILCHRIST CA, 1994, J ROY STAT SOC B MET, V56, P61; *SAS I INC, 2000, SAS IML US GUID VERS; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267	8	0	0	JOHN WILEY & SONS LTD	CHICHESTER	THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND	0277-6715			STAT MED	Stat. Med.	APR 15	2004	23	7					1147	1157		10.1002/sim.1663		11	Mathematical & Computational Biology; Public, Environmental & Occupational Health; Medical Informatics; Medicine, Research & Experimental; Statistics & Probability	Mathematical & Computational Biology; Public, Environmental & Occupational Health; Medical Informatics; Research & Experimental Medicine; Mathematics	810CP	WOS:000220682700008	15057883	
J	Dugas, M; Merk, S; Breit, S; Dirschedl, P				Dugas, M; Merk, S; Breit, S; Dirschedl, P			mdclust - exploratory microarray analysis by multidimensional clustering	BIOINFORMATICS			English	Article							GENE-EXPRESSION; PATTERNS	Motivation: Unsupervised clustering of microarray data may detect potentially important, but not obvious characteristics of samples, for instance subgroups of diagnoses with distinct gene profiles or systematic errors in experimentation. Results: Multidimensional clustering (mdclust) is a method, which identifies sets of sample clusters and associated genes. It applies iteratively two-means clustering and score-based gene selection. For any phenotype variable best matching sets of clusters can be selected. This provides a method to identify gene-phenotype associations, suited even for settings with a large number of phenotype variables. An optional model based discriminant step may reduce further the number of selected genes.	Dept Med Informat, D-81377 Munich, Germany; Univ Munich, Dept Dermatol, D-80337 Munich, Germany	Dugas, M (reprint author), Dept Med Informat, Marchioninistr 15, D-81377 Munich, Germany.	dug@ibe.med.uni-muenchen.de	Dugas, Martin/F-5454-2011; Dugas, Susanne/G-6201-2011				Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Datta S, 2003, BIOINFORMATICS, V19, P459, DOI 10.1093/bioinformatics/btg025; DUDOIT S, 2003, BIOCONDUCTORS MULTTE; Dugas M, 2001, LEUKEMIA, V15, P1805; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Gentleman R, 2002, R NEWS, V2, P11; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hartigan J. A., 1979, Applied Statistics, V28, DOI 10.2307/2346830; Hastie T., 2002, ELEMENTS STAT LEARNI; Karaman MW, 2003, GENOME RES, V13, P1619, DOI 10.1101/gr.1289803; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; MARKOWETZ F, 2002, P 26 ANN C GERM CLAS, P662; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; von Heydebreck A, 2001, Bioinformatics, V17 Suppl 1, pS107	15	8	9	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	APR 12	2004	20	6					931	936		10.1093/bioinformatics/bth009		6	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	813GH	WOS:000220895100016	14751972	
J	Shih, YS; Tsai, HW				Shih, YS; Tsai, HW			Variable selection bias in regression trees with constant fits	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article						change-point; maximally selected statistic; missing values; P-values	SEQUENCE; SHIFT	The greedy search approach to variable selection in regression trees with constant fits is considered. At each node, the method usually compares the maximally selected statistic associated with each variable and selects the variable with the largest value to form the split. This method is shown to have selection bias, if predictor variables have different numbers of missing values and the bias can be corrected by comparing the corresponding P-values instead. Methods related to some change-point problems are used to compute the P-values and their performances are studied. (C) 2003 Elsevier B.V. All rights reserved.	Natl Chung Cheng Univ, Inst Stat Sci, Chiayi 62117, Taiwan	Shih, YS (reprint author), Natl Chung Cheng Univ, Inst Stat Sci, Minghsiung, Chiayi 62117, Taiwan.	yshih@math.ccu.edu.tw; g8923001@mthmp.math.ccu.edu.tw					Breiman L., 1984, CLASSIFICATION REGRE; DOYLE P, 1973, OPER RES QUART, V24, P465, DOI 10.2307/3008131; Hastie T., 2001, ELEMENTS STAT LEARNI; HAWKINS DM, 1977, J AM STAT ASSOC, V72, P180, DOI 10.2307/2286934; Hawkins DM, 1997, 546 U MINN SCH STAT; HOTHORN T, 2003, COMPUT STAT DATA ANA; JAMES B, 1987, BIOMETRIKA, V74, P71, DOI 10.1093/biomet/74.1.71; Jensen DD, 2000, MACH LEARN, V38, P309, DOI 10.1023/A:1007631014630; KASS GV, 1975, APPL STAT, V24, P178, DOI 10.2307/2346565; Kim H, 2001, J AM STAT ASSOC, V96, P589, DOI 10.1198/016214501753168271; LAUSEN B, 1992, BIOMETRICS, V48, P73, DOI 10.2307/2532740; Loh WY, 2002, STAT SINICA, V12, P361; MORGAN JN, 1963, J AM STAT ASSOC, V58, P415, DOI 10.2307/2283276; SCHLITTGEN R, 1999, BIOMETR J, V8, P943; SCOTT AJ, 1976, APPL STAT, V25, P103, DOI 10.2307/2346677; TORGO L, 1999, THESIS U PROTO; Witten IH, 2000, DATA MINING; YAO YC, 1986, SANKHYA SER A, V48, P339	18	8	8	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473			COMPUT STAT DATA AN	Comput. Stat. Data Anal.	APR 10	2004	45	3					595	607		10.1016/S0167-9473(03)00036-7		13	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	808RI	WOS:000220585800013		
J	Moore, JH; Ritchie, MD				Moore, JH; Ritchie, MD			The challenges of whole-genome approaches to common diseases	JAMA-JOURNAL OF THE AMERICAN MEDICAL ASSOCIATION			English	Article							MULTIFACTOR-DIMENSIONALITY REDUCTION; GENE-GENE INTERACTIONS; NEURAL-NETWORK ARCHITECTURE; ENVIRONMENT; BREAST; CANCER		Vanderbilt Univ, Sch Med, Nashville, TN 37212 USA	Moore, JH (reprint author), Vanderbilt Univ, Sch Med, Nashville, TN 37212 USA.						Bellman R., 1961, ADAPTIVE CONTROL PRO; EASTON DF, 1995, AM J HUM GENET, V56, P265; Gibbs RA, 2003, NATURE, V426, P789, DOI 10.1038/nature02168; Hahn LW, 2003, BIOINFORMATICS, V19, P376, DOI 10.1093/bioinformatics/btf869; HAHN LW, 2004, IN SILICO BIOL, V4, P16; Hastie T., 2001, ELEMENTS STAT LEARNI; Jansen RC, 2003, NAT REV GENET, V4, P145, DOI 10.1038/nrg996; Lucek PR, 1997, GENET EPIDEMIOL, V14, P1101, DOI 10.1002/(SICI)1098-2272(1997)14:6<1101::AID-GEPI90>3.0.CO;2-K; Marinov M, 2001, HUM HERED, V51, P169, DOI 10.1159/000053338; Moore JH, 2003, HUM HERED, V56, P73, DOI 10.1159/000073735; Moore JH, 2002, ANN MED, V34, P88, DOI 10.1080/07853890252953473; Moore JH, 2003, BIOSYSTEMS, V72, P177, DOI 10.1016/S0303-2647(03)00142-4; North BV, 2003, ANN HUM GENET, V67, P348, DOI 10.1046/j.1469-1809.2003.00030.x; Ritchie MD, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-28; Ritchie MD, 2001, AM J HUM GENET, V69, P138, DOI 10.1086/321276; Ritchie MD, 2003, GENET EPIDEMIOL, V24, P150, DOI 10.1002/gepi.10218; Sing CF, 2003, ARTERIOSCL THROM VAS, V23, P1190, DOI 10.1161/01.ATV.0000075081.51227.86; Strohman R, 2002, SCIENCE, V296, P701, DOI 10.1126/science.1070534; Williams SM, 2004, BIOESSAYS, V26, P170, DOI 10.1002/bies.10401; Wu C. H., 2000, NEURAL NETWORKS GENO	20	78	85	AMER MEDICAL ASSOC	CHICAGO	515 N STATE ST, CHICAGO, IL 60610 USA	0098-7484			JAMA-J AM MED ASSOC	JAMA-J. Am. Med. Assoc.	APR 7	2004	291	13					1642	1643		10.1001/jama.291.13.1642		2	Medicine, General & Internal	General & Internal Medicine	809PQ	WOS:000220649000032	15069055	
J	Dodd, LE; Wagner, RF; Armato, SG; McNitt-Gray, MF; Beiden, S; Chan, HP; Gur, D; McLennan, G; Metz, CE; Petrick, N; Sahiner, B; Sayre, J				Dodd, LE; Wagner, RF; Armato, SG; McNitt-Gray, MF; Beiden, S; Chan, HP; Gur, D; McLennan, G; Metz, CE; Petrick, N; Sahiner, B; Sayre, J		Lung Image Database Consortium Res	Assessment methodologies and statistical issues for computer-aided diagnosis of lung nodules in computed tomography: Contemporary research topics relevant to the lung image database consortium	ACADEMIC RADIOLOGY			English	Article						computer-aided diagnosis (CAD); database development; lung cancer; lung nodule; MRMC; ROC	OPERATING CHARACTERISTIC ANALYSIS; OF-VARIANCE MODELS; FINITE-SAMPLE SIZE; OBSERVER-PERFORMANCE; ROC ANALYSIS; CONDITIONAL DEPENDENCE; MULTIPLE-ABNORMALITIES; REGRESSION METHODOLOGY; DISEASE VERIFICATION; SELECTION BIAS	Cancer of the lung and bronchus is the leading fatal malignancy in the United States. Five-year survival is low, but treatment of early stage disease considerably improves chances of survival. Advances in multidetector-row computed tomography technology provide detection of smaller lung nodules and offer a potentially effective screening tool. The large number of images per exam, however, requires considerable radiologist time for interpretation and is an impediment to clinical throughput. Thus, computer-aided diagnosis (CAD) methods are needed to assist radiologists with their decision making. To promote the development of CAD methods, the National Cancer Institute formed the Lung Image Database Consortium (LIDC). The LIDC is charged with developing the consensus and standards necessary to create an image database of multidetector-row computed tomography lung images as a resource for CAD researchers. To develop such a prospective database, its potential uses must be anticipated. The ultimate applications will influence the information that must be included along with the images, the relevant measures of algorithm performance, and the number of required images. In this article we outline assessment methodologies and statistical issues as they relate to several potential uses of the LIDC database. We review methods for performance assessment and discuss issues of defining "truth" as well as the complications that arise when truth information is not available. We also discuss issues about sizing and populating a database. (C) AUR, 2004.	NCI, Biometr Res Branch, Div Canc Treatment & Diag, Bethesda, MD 20892 USA; US FDA, Ctr Devices & Radiol Hlth, Rockville, MD 20857 USA; Univ Chicago, Dept Radiol, Chicago, IL 60637 USA; Univ Calif Los Angeles, Dept Radiol, David Geffen Sch Med, Los Angeles, CA 90024 USA; Univ Michigan, Dept Radiol, Ann Arbor, MI 48109 USA; Univ Pittsburgh, Dept Radiol, Pittsburgh, PA 15260 USA; Univ Iowa, Dept Med, Iowa City, IA 52242 USA; Univ Calif Los Angeles, Dept Biostat, Sch Publ Hlth, Los Angeles, CA 90024 USA; Univ Calif Los Angeles, Dept Radiol, Sch Publ Hlth, Los Angeles, CA 90024 USA; Univ Calif Los Angeles, Dept Radiol, Sch Med, Los Angeles, CA 90024 USA; Univ Calif Los Angeles, Dept Biostat, Sch Med, Los Angeles, CA 90024 USA	Dodd, LE (reprint author), NCI, Biometr Res Branch, Div Canc Treatment & Diag, 6130 Execut Blvd,MSC 7434, Bethesda, MD 20892 USA.	doddl@mail.nih.gov					Albert PS, 2001, BIOMETRICS, V57, P610, DOI 10.1111/j.0006-341X.2001.00610.x; ALBERT PS, UNPUB CAUTIONARY NOT; BEGG CB, 1988, RADIOLOGY, V167, P565; BEGG CB, 1983, BIOMETRICS, V39, P207, DOI 10.2307/2530820; BEGG CB, 1990, MED DECIS MAKING, V10, P29, DOI 10.1177/0272989X9001000106; Beiden SV, 2001, ACAD RADIOL, V8, P605, DOI 10.1016/S1076-6332(03)80685-2; Beiden Sergey V., 2000, Proceedings of the SPIE - The International Society for Optical Engineering, V3981, DOI 10.1117/12.383099; Beiden SV, 2000, ACAD RADIOL, V7, P341, DOI 10.1016/S1076-6332(00)80008-2; Beiden SV, 2003, IEEE T PATTERN ANAL, V25, P1561, DOI 10.1109/TPAMI.2003.1251149; Beiden SV, 2001, ACAD RADIOL, V8, P616, DOI 10.1016/S1076-6332(03)80686-4; Bunch P. C., 1977, P SOC PHOTO-OPT INS, V0127, P124; Cai TX, 2002, J AM STAT ASSOC, V97, P1099, DOI 10.1198/06214502388618915; Chakraborty D, 2002, ACAD RADIOL, V9, P147, DOI 10.1016/S1076-6332(03)80164-2; CHAKRABORTY DP, 2002, RADIOLOGY SP, V225, P259; CHAKRABORTY DP, 1990, RADIOLOGY, V174, P873; Chakraborty DP, 2000, ACAD RADIOL, V7, P553, DOI 10.1016/S1076-6332(00)80329-3; CHAKRABORTY DP, 1989, MED PHYS, V16, P561, DOI 10.1118/1.596358; Chakraborty DP, 2000, HDB MED IMAGING, P771; CHAKRABORTY DP, MED IMAGING 2003 IMA, V5034, P204; Chan HP, 1999, MED PHYS, V26, P2654, DOI 10.1118/1.598805; Clarke LP, 2001, ACAD RADIOL, V8, P447, DOI 10.1016/S1076-6332(03)80555-X; Dendukuri N, 2001, BIOMETRICS, V57, P158, DOI 10.1111/j.0006-341X.2001.00158.x; Dodd LE, 2003, BIOMETRICS, V59, P614, DOI 10.1111/1541-0420.00071; DODD LE, 2003, J AM STAT ASSOC, V98, P397; DORFMAN DD, 1992, INVEST RADIOL, V27, P723, DOI 10.1097/00004424-199209000-00015; Efron Bradley, 1993, INTRO BOOTSTRAP; ESPELAND MA, 1989, BIOMETRICS, V45, P587, DOI 10.2307/2531499; FLEHINGER BJ, 1992, CHEST, V101, P1013, DOI 10.1378/chest.101.4.1013; Fry WA, 1996, CANCER, V77, P1947, DOI 10.1002/(SICI)1097-0142(19960501)77:9<1947::AID-CNCR27>3.0.CO;2-Z; GATSONIS CA, 1995, ACAD RADIOL S, V2, pS1; Gifford H. C., 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4324, DOI 10.1117/12.431182; Giger ML, 1996, INT CONGR SER, V1119, P53; GIGER ML, 1996, P 3 INT WORKSH DIG M, P53; GRAY R, 1984, MED DECIS MAKING, V4, P151, DOI 10.1177/0272989X8400400204; Hastie T., 2001, ELEMENTS STAT LEARNI; HENKELMAN RM, 1990, MED DECIS MAKING, V10, P24, DOI 10.1177/0272989X9001000105; Henschke CI, 1999, LANCET, V354, P99, DOI 10.1016/S0140-6736(99)06093-6; Hui S L, 1998, Stat Methods Med Res, V7, P354, DOI 10.1191/096228098671192352; Jemal A, 2003, CA-CANCER J CLIN, V53, P5; Kaneko M, 1996, RADIOLOGY, V201, P798; KUNDEL HL, 2000, P SOC PHOTO-OPT INS, V4324, P22; Kundel HL, 1998, P SOC PHOTO-OPT INS, V3340, P78, DOI 10.1117/12.306185; MARTINI N, 1995, J THORAC CARDIOV SUR, V109, P120, DOI 10.1016/S0022-5223(95)70427-2; METZ CE, 1989, INVEST RADIOL, V24, P234, DOI 10.1097/00004424-198903000-00012; METZ CE, 1986, INVEST RADIOL, V21, P720; Metz C.E., 2000, HDB MED IMAGING, V1, P751; Metz CE, 1984, INFORMATION PROCESSI, P432; Metz CE, 1986, MULTIPLE REGRESSION, P365; METZ CE, 1978, SEMIN NUCL MED, V8, P283, DOI 10.1016/S0001-2998(78)80014-2; METZ CE, 1976, RADIOLOGY, V121, P337; Metz CE, 1996, INT CONGR SER, V1119, P61; Metz CE, 1998, STAT MED, V17, P1033, DOI 10.1002/(SICI)1097-0258(19980515)17:9<1033::AID-SIM784>3.3.CO;2-Q; Metz CE, 1999, INT CONGR SER, V1182, P543; NAIDICH DP, 1994, RADIOL CLIN N AM, V32, P759; Nishikawa RM, 1998, P SOC PHOTO-OPT INS, V3338, P840, DOI 10.1117/12.310894; Obuchowski NA, 2000, ACAD RADIOL, V7, P516, DOI 10.1016/S1076-6332(00)80324-4; OBUCHOWSKI NA, 1995, ACAD RADIOL, V2, P709, DOI 10.1016/S1076-6332(05)80441-6; Ohmatsu H, 2000, RADIOLOGY, V217, P242; Pepe MS, 2000, BIOMETRICS, V56, P352, DOI 10.1111/j.0006-341X.2000.00352.x; Petrick N, 2002, RADIOLOGY, V224, P217, DOI 10.1148/radiol.2241011062; POLANSKY M, 2000, PHYS PSYCHOPHYSICS, V1, P797; QU Y, 1996, BIOMETRICS, V52, P707; REVESZ G, 1983, INVEST RADIOL, V18, P194, DOI 10.1097/00004424-198303000-00018; Roe CA, 1997, ACAD RADIOL, V4, P298, DOI 10.1016/S1076-6332(97)80032-3; Rubin GD, 2000, EUR J RADIOL, V36, P74, DOI 10.1016/S0720-048X(00)00270-9; Rutter CM, 2000, ACAD RADIOL, V7, P413, DOI 10.1016/S1076-6332(00)80381-5; Sahiner B, 2000, MED PHYS, V27, P1509, DOI 10.1118/1.599017; Schultz DG, 1997, RADIOLOGY, V202, P317; Shapiro DE, 1999, STAT METHODS MED RES, V8, P113, DOI 10.1191/096228099666928387; Sone S, 1998, LANCET, V351, P1242, DOI 10.1016/S0140-6736(97)08229-9; STARR SJ, 1975, RADIOLOGY, V116, P533; Swensson RG, 2000, MED DECIS MAKING, V20, P170, DOI 10.1177/0272989X0002000203; Swensson RG, 1996, MED PHYS, V23, P1709, DOI 10.1118/1.597758; Swets JA, 1982, EVALUATION DIAGNOSTI; Toledano AY, 1996, STAT MED, V15, P1807, DOI 10.1002/(SICI)1097-0258(19960830)15:16<1807::AID-SIM333>3.0.CO;2-U; TorranceRynard VL, 1997, STAT MED, V16, P2157, DOI 10.1002/(SICI)1097-0258(19971015)16:19<2157::AID-SIM653>3.0.CO;2-X; TOSTESON ANA, 1988, MED DECIS MAKING, V8, P204, DOI 10.1177/0272989X8800800309; *U CHIC, ROC SOFTW; VACEK PM, 1985, BIOMETRICS, V41, P959, DOI 10.2307/2530967; Wagner RF, 2001, ACAD RADIOL, V8, P328, DOI 10.1016/S1076-6332(03)80502-0; Wagner R. F., 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4320, DOI 10.1117/12.430881; Wagner RF, 2002, ACAD RADIOL, V9, P1264, DOI 10.1016/S1076-6332(03)80560-3; WALTER SD, 1988, J CLIN EPIDEMIOL, V41, P923, DOI 10.1016/0895-4356(88)90110-2; Zhou X H, 1998, Stat Methods Med Res, V7, P337, DOI 10.1191/096228098676485370; Zou KH, 2000, J APPL STAT, V27, P621	85	51	52	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	1076-6332			ACAD RADIOL	Acad. Radiol.	APR	2004	11	4					462	475		10.1016/S1076-6332(03)00814-6		14	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	807HC	WOS:000220491600011	15109018	
J	Holmes, TH				Holmes, TH			Ten categories of statistical errors: a guide for research in endocrinology and metabolism	AMERICAN JOURNAL OF PHYSIOLOGY-ENDOCRINOLOGY AND METABOLISM			English	Review						statistics; bias; precision; sampling; hypothesis testing	TESTS	A simple framework is introduced that defines ten categories of statistical errors on the basis of type of error, bias or imprecision, and source: sampling, measurement, estimation, hypothesis testing, and reporting. Each of these ten categories is illustrated with examples pertinent to research and publication in the disciplines of endocrinology and metabolism. Some suggested remedies are discussed, where appropriate. A review of recent issues of American Journal of Physiology: Endocrinology and Metabolism and of Endocrinology finds that very small sample sizes may be the most prevalent cause of statistical error in this literature.	Stanford Univ, Sch Med, Dept Hlth Res & Policy, Div Biostat, Stanford, CA 94305 USA	Holmes, TH (reprint author), Stanford Univ, Sch Med, Dept Hlth Res & Policy, Div Biostat, HRP Redwood Bldg,Rm T160C, Stanford, CA 94305 USA.	tholmes@stanford.edu					CARMER SG, 1982, AGRON J, V74, P122; Daniel WW, 1990, APPL NONPARAMETRIC S; Diggle P. J., 1996, ANAL LONGITUDINAL DA; Halpern SD, 2002, JAMA-J AM MED ASSOC, V288, P358, DOI 10.1001/jama.288.3.358; Hastie T., 2001, ELEMENTS STAT LEARNI; HOCHBERG Y, 1988, BIOMETRIKA, V75, P800, DOI 10.1093/biomet/75.4.800; Little RJA, 1987, STAT ANAL MISSING DA; MILLIKEN G.A., 1992, ANAL MESSY DATA, V1; NETER J, 1985, APPL LINEAR STAT MOD, P574; Rencher A.C., 1995, METHODS MULTIVARIATE; RICE WR, 1989, EVOLUTION, V43, P223, DOI 10.2307/2409177; SOKAL R, 1981, BIOMETRY, P59; THOMPSON SK, 1992, SAMPLING, P101; Weir CJ, 2003, STAT MED, V22, P705, DOI 10.1002/sim.1366; WOODWARD M, 1992, STATISTICIAN, V41, P185, DOI 10.2307/2348252	15	15	16	AMER PHYSIOLOGICAL SOC	BETHESDA	9650 ROCKVILLE PIKE, BETHESDA, MD 20814 USA	0193-1849			AM J PHYSIOL-ENDOC M	Am. J. Physiol.-Endocrinol. Metab.	APR	2004	286	4					E495	E501		10.1152/ajpendo.00484.2003		7	Endocrinology & Metabolism; Physiology	Endocrinology & Metabolism; Physiology	801KR	WOS:000220095300001	15010353	
J	Efron, B; Hastie, T; Johnstone, I; Tibshirani, R				Efron, B; Hastie, T; Johnstone, I; Tibshirani, R			Least angle regression	ANNALS OF STATISTICS			English	Article						lasso; boosting; linear regression; coefficient paths; variable selection	SELECTION; LASSO	The purpose of model selection algorithms such as All Subsets, Forward Selection and Backward Elimination is to choose a linear model on the basis of the same set of data to which the model will be applied. Typically we have available a large collection of possible covariates from which we hope to select a parsimonious set for the efficient prediction of a response variable. Least Angle Regression (LARS), a new model selection algorithm, is a useful and less greedy version of traditional forward selection methods. Three main properties are derived: (1) A simple modification of the LARS algorithm implements the Lasso, an attractive version of ordinary least squares that constrains the sum of the absolute regression coefficients; the LARS modification calculates all possible Lasso estimates for a given problem, using an order of magnitude less computer time than previous methods. (2) A different LARS modification efficiently implements Forward Stagewise linear regression, another promising new model selection method; this connection explains the similar numerical results previously observed for the Lasso and Stagewise, and helps us understand the properties of both methods, which are seen as constrained versions of the simpler LARS algorithm. (3) A simple approximation for the degrees of freedom of a LARS estimate is available, from which we derive a C-p estimate of prediction error; this allows a principled choice among the range of possible LARS estimates. LARS and its variants are computationally efficient: the paper describes a publicly available algorithm that requires only the same order of magnitude of computational effort as ordinary least squares applied to the full set of covariates.	Stanford Univ, Dept Stat, Stanford, CA 94305 USA	Efron, B (reprint author), Stanford Univ, Dept Stat, Sequoia Hall, Stanford, CA 94305 USA.	brad@stat.stanford.edu					Breiman L., 1984, CLASSIFICATION REGRE; EFRON B, 1986, J AM STAT ASSOC, V81, P461, DOI 10.2307/2289236; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Golub G., 1983, MATRIX COMPUTATION; Hastie T., 2001, ELEMENTS STAT LEARNI; Lawson CL, 1974, SOLVING LEAST SQUARE; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; Meyer M, 2000, ANN STAT, V28, P1083; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; Rao C R, 1973, LINEAR STAT INFERENC; STEIN CM, 1981, ANN STAT, V9, P1135, DOI 10.1214/aos/1176345632; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Weisberg S., 1980, APPL LINEAR REGRESSI; Ye JM, 1998, J AM STAT ASSOC, V93, P120, DOI 10.2307/2669609	18	1804	1872	INST MATHEMATICAL STATISTICS	BEACHWOOD	PO BOX 22718, BEACHWOOD, OH 44122 USA	0090-5364			ANN STAT	Ann. Stat.	APR	2004	32	2					407	451				45	Statistics & Probability	Mathematics	820TA	WOS:000221411000001		
J	Graham, PL; Cook, DA				Graham, PL; Cook, DA			Prediction of risk of death using 30-day outcome - A practical end point for quality auditing in intensive care	CHEST			English	Article						logistic regression; quality monitoring; risk adjustment; risk assessment	LOGISTIC-REGRESSION MODELS; ARTIFICIAL NEURAL-NETWORKS; ACTIVATED PROTEIN-C; APACHE-III MODELS; HOSPITAL MORTALITY; UNIT PATIENTS; SEVERE SEPSIS; SYSTEM; MULTICENTER; SEVERITY	Study objective: To validate the APACHE (acute physiology and chronic health evaluation) HI unadjusted and similar hospital mortality estimate models on 30-day mortality, and to propose a simple approach to modeling local 30-day in-hospital mortality of critically ill hospitalized adults for quality management and risk-adjusted monitoring. Design: Noninterventional, observational study. Patients: A total of 5,278 consecutive eligible hospital admissions between January 1, 1995, and December 31, 1999. Measurements: Prospective collection of demographic, diagnostic, physiologic, laboratory, and hospital admission and discharge data. Results: The APACHE III mortality predictions exhibited excellent discrimination (receiver operating characteristic [ROC] curve area) for 30-day outcome (ROC area, 0.89) and hospital outcome (ROC area, 0.89). Calibration curves and Hosmer-Lemeshow statistics demonstrated good calibration of all models on 30-day outcome, except for the unadjusted APACHE III model. New, simplified risk adjustment models showed good discrimination and calibration on development and test data. ROC areas were 0.88 (developmental data) and 0.87 (test data), and the new model calibration was equivalent to the APACHE HI model. Conclusion: For quality audit, 30-day in-hospital mortality can be used as an alternative outcome to survival to hospital discharge. New logistic regression models provide evidence that local models, possessing good calibration and discrimination, may be built from a few explanatory variables.	Univ Newcastle, Sch Math & Phys Sci, Newcastle, NSW 2308, Australia; Princess Alexandra Hosp, Intens Care Unit, Woolloongabba, Qld, Australia	Graham, PL (reprint author), Univ Newcastle, Sch Math & Phys Sci, Bldg V, Newcastle, NSW 2308, Australia.	pgraham@maths.newcastle.edu.au	Cook, David/D-7318-2013				LEMESHOW S, 1982, AM J EPIDEMIOL, V115, P92; *AP MED SYST, 1990, AP 3 MAN SYST SOFT 1; Ash AS, 1994, RISK ADJUSTMENT MEAS, P313; Bernard GR, 2001, NEW ENGL J MED, V344, P699, DOI 10.1056/NEJM200103083441001; Breiman L., 1984, CLASSIFICATION REGRE; CASTELLA X, 1995, CRIT CARE MED, V23, P1327, DOI 10.1097/00003246-199508000-00005; Clermont G, 2001, CRIT CARE MED, V29, P291, DOI 10.1097/00003246-200102000-00012; Cook DA, 2003, CRIT CARE MED, V31, P1676, DOI 10.1097/01.CCM.0000065273.63224.A8; Cook DA, 2002, ANAESTH INTENS CARE, V30, P308; Cook DA, 2000, CHEST, V118, P1732, DOI 10.1378/chest.118.6.1732; Glance LG, 2002, CHEST, V121, P326, DOI 10.1378/chest.121.2.326; HANLEY JA, 1982, RADIOLOGY, V143, P29; Hastie T., 2001, ELEMENTS STAT LEARNI; HOLLANDER M, 1999, NONPARAMETRIC STAT M, P20; Hosmer D. W., 1989, APPL LOGISTIC REGRES, P135; IEZZONI LI, 1994, RISK ADJUSTMENT MEAS, P29; JENCKS SF, 1988, JAMA-J AM MED ASSOC, V260, P2240, DOI 10.1001/jama.260.15.2240; Johnston JA, 2002, MED CARE, V40, P929, DOI 10.1097/01.MLR.0000027367.95427.AA; Justice AC, 1999, ANN INTERN MED, V130, P515; KNAUS WA, 1985, CRIT CARE MED, V13, P818, DOI 10.1097/00003246-198510000-00009; KNAUS WA, 1993, ANN INTERN MED, V118, P753; KNAUS WA, 1991, CHEST, V100, P1619, DOI 10.1378/chest.100.6.1619; LEGALL JR, 1993, JAMA-J AM MED ASSOC, V270, P2957, DOI 10.1001/jama.270.24.2957; LEMESHOW S, 1995, INTENS CARE MED, V21, P770, DOI 10.1007/BF01704747; SEIGEL JP, 2002, NEW ENGL J MED, V347, P1030; Sirio CA, 2002, CHEST, V121, P539, DOI 10.1378/chest.121.2.539; WAGNER D, 1989, CRIT CARE MED, V17, pS199, DOI 10.1097/00003246-198912000-00008; Warren HS, 2002, NEW ENGL J MED, V347, P1027, DOI 10.1056/NEJMsb020574; Wong LSS, 1999, ANAESTHESIA, V54, P1048, DOI 10.1046/j.1365-2044.1999.01104.x	29	12	13	AMER COLL CHEST PHYSICIANS	NORTHBROOK	3300 DUNDEE ROAD, NORTHBROOK, IL 60062-2348 USA	0012-3692			CHEST	Chest	APR	2004	125	4					1458	1466		10.1378/chest.125.4.1458		9	Critical Care Medicine; Respiratory System	General & Internal Medicine; Respiratory System	825YB	WOS:000221793700043	15078759	
J	Skowron, A; Synak, P				Skowron, A; Synak, P			Complex patterns	FUNDAMENTA INFORMATICAE			English	Article; Proceedings Paper	Meeting on Concurrency Specification and Programming (CS&P)	SEP 25-27, 2003	Czarna, POLAND	Humboldt Univ, Warsaw Univ, Univ Informat Technol & Management		complex object; concept approximation; pattern; rough sets; spatio-temporal reasoning; classifier; network of classifiers	INFORMATION MAPS; ROUGH MEREOLOGY; SETS; GRANULES; SYSTEMS	We outline some results of our current research on developing a methodology for solving problems of spatio-temporal reasoning. We consider classifiers for complex concepts in spatio-temporal reasoning that are constructed hierarchically. We emphasise the fact that the construction of such hierarchical classifiers should be supported by domain knowledge. Approximate reasoning networks (AR networks) are proposed for approximation of reasoning schemes expressed in natural language. Such reasoning schemes are extracted from knowledge bases representing domain knowledge. This approach makes it possible to induce classifiers for complex concepts by constructing them along schemes of reasoning extracted from domain knowledge.	Warsaw Univ, Inst Math, PL-02097 Warsaw, Poland; Polish Japanese Inst Informat Technol, PL-02008 Warsaw, Poland	Skowron, A (reprint author), Warsaw Univ, Inst Math, Banacha 2, PL-02097 Warsaw, Poland.	skowron@mimuw.edu.pl; synak@pjwstk.edu.pl					Barsalou LW, 1999, BEHAV BRAIN SCI, V22, P577; BARWISE J, 1997, TRACTS THEORETICAL C, V44; Bennett B, 2002, APPL INTELL, V17, P239, DOI 10.1023/A:1020083231504; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Escrig M.T., 1998, QUALITATIVE SPATIAL; Fahle M, 2002, PERCEPTUAL LEARNING; Friedman J., 2001, ELEMENTS STAT LEARNI; Harnad S.R., 1987, CATEGORICAL PERCEPTI; Kloesgen Willi, 2002, HDB KNOWLEDGE DISCOV; MCCARTHY J, 1993, 13 INT JOINT C ART I; McCarthy J., 1969, MACH INTELL, P463; Mitchell T., 1997, MACHINE LEARNING; Pal S.K., 1999, ROUGH FUZZY HYBRIDIZ; Pal S.K., 2004, ROUGH NEURAL COMPUTI; Pawlak Z, 1991, SYSTEM THEORY KNOWLE, V9; Peters JF, 2003, LECT NOTES ARTIF INT, V2715, P370; Poggio T., 2003, NOTICES AMS, V50, P537; Polkowski L, 2000, STUD FUZZ SOFT COMP, V56, P89; Polkowski L, 1996, INT J APPROX REASON, V15, P333, DOI 10.1016/S0888-613X(96)00072-2; Polkowski L., 1996, 3 WORLD C EXP SYST S, P774; Polkowski L, 2001, COMPUT INTELL, V17, P472, DOI 10.1111/0824-7935.00159; Polkowski L., 1999, COMPUTING WORDS INFO, P201; Roddick J. F., 2001, SIGKDD TEMP DAT MIN, P167; Roddick JF, 2001, LECT NOTES ARTIF INT, V2007, P147; Sandewall E., 1994, FEATURES FLUENTS REP, V1; Skowron A, 2003, FUND INFORM, V54, P263; SKOWRON A, 2004, ROUGH NEURAL COMPUTI, P43; Skowron A, 2004, FUND INFORM, V59, P241; Skowron A, 2001, INT J INTELL SYST, V16, P57, DOI 10.1002/1098-111X(200101)16:1<57::AID-INT6>3.0.CO;2-Y; Skowron A., 2001, B INT ROUGH SET SOC, V5, P9; Skowron A, 2001, FUND INFORM, V47, P337; Skowron A., 1996, Fundamenta Informaticae, V27; Skowron A, 2002, LECT NOTES ARTIF INT, V2475, P453; Stone P., 2000, LAYERED LEARNING MUL; Swiniarski RW, 2003, PATTERN RECOGN LETT, V24, P833, DOI 10.1016/S0167-8655(02)00196-4; Vapnik V., 1998, STAT LEARNING THEORY; Zadeh LA, 2001, AI MAG, V22, P73; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	38	29	29	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0169-2968			FUND INFORM	Fundam. Inform.	APR	2004	60	1-4			SI		351	366				16	Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	839ET	WOS:000222766900023		
J	Smith, TE; Song, SY				Smith, TE; Song, SY			A spatial mixture model of innovation diffusion	GEOGRAPHICAL ANALYSIS			English	Article; Proceedings Paper	North American Meeting of the Regional-Science-Association-International	NOV, 2002	San Juan, PR	Reg Sci Assoc Int				The diffusion of new product or technical innovation over space is here modeled as an event-based process in which the likelihood of the next adopter being in region r is influenced by two factors: (i) the potential interactions of individuals in r with current adopters in neighboring regions, and (ii) all other attributes of individuals in r that may influence their adoption propensity. The first factor is characterized by a logit model reflecting the likelihood of adoption due to spatial contacts with previous adopters, and the second by a logit model reflecting the likelihood of adoption due to other intrinsic effects. The resulting spatial diffusion process is then assumed, to be driven by a probabilistic mixture of the two. A number of formal properties of this model are analyzed, including its asymptotic behavior. But the main analytical focus is on statistical estimation of parameters. Here it is shown that standard maximum-likelihood estimates require large sample sizes to achieve reasonable results. Two estimation approaches are developed which yield more sensible results for small sample sizes. These results are applied to a small data set involving the adoption Of a new Internet grocery-shopping service by consumers in the Philadelphia metropolitan area.	Univ Penn, Dept Elect & Syst Engn, Philadelphia, PA 19104 USA; Univ Penn, Wharton Sch, Philadelphia, PA 19104 USA	Smith, TE (reprint author), Univ Penn, Dept Elect & Syst Engn, Philadelphia, PA 19104 USA.	tesmith@seas.upenn.edu; sangyoun@wharton.upenn.edu					BASS FM, 1969, MANAGE SCI, V15, P215, DOI 10.1287/mnsc.15.5.215; BRUMELLE SL, 1980, J MATH SOCIOL, V7, P73; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Hagerstrand T., 1967, INNOVATION DIFFUSION; HAINING R, 1983, T I BRIT GEOGR, V8, P158, DOI 10.2307/622109; Hastie T., 2001, ELEMENTS STAT LEARNI; Hirsch M.W., 1974, DIFFERENTIAL EQUATIO; Kulkarni V., 1995, MODELING ANAL STOCHA; KUSHNR HJ, 1997, STOCHASTIC APPROXIMA; KUSHNR HJ, 1978, STOCHASTIC APPROXIMA; Lehmann E. L., 1983, THEORY POINT ESTIMAT; MAHAJAN V, 1990, J MARKETING, V54, P1, DOI 10.2307/1252170; MCLACHLAN G, 2000, FINTIE MIXTURE MODEL; Morrill R. L, 1988, SPATIAL DIFFUSION; ROBERT CH, 1998, MARKOV CHAIN MONTE C; Rogers E., 1995, DIFFUSION INNOVATION; SMITH TE, 2003, SPATIAL MIXTURE MODE; SPECKMAN PL, 2001, EXISTENCE MLE PROPRI; Stephens M, 2000, J ROY STAT SOC B, V62, P795, DOI 10.1111/1467-9868.00265; STRANG D, 1993, AM J SOCIOL, V99, P614, DOI 10.1086/230318; Wedel M, 2000, MARKET SEGMENTATION	21	2	2	OHIO STATE UNIV PRESS	COLUMBUS	1050 CARMACK RD, COLUMBUS, OH 43210 USA	0016-7363			GEOGR ANAL	Geogr. Anal.	APR	2004	36	2					119	145		10.1111/j.1538-4632.2004.tb01129.x		27	Geography	Geography	817IF	WOS:000221170500004		
J	Enachescu, D				Enachescu, D			Multilayer perceptron model for prostate cancer prediction	INTERNATIONAL JOURNAL OF COMPUTER MATHEMATICS			English	Article						neural network; regression model; prostate specific antigen		We present a regression model based on multilayer perceptron (MLP) network for the level of prostate specific antigen. Finally, the results of the MLP-network are compared with other regression models; the conclusion is that the MLP-model is approximately 10 times more accurate that the other models.	Univ Bucharest, Fac Math & Informat, Dept Informat, Bucharest 5, Romania	Enachescu, D (reprint author), Univ Bucharest, Fac Math & Informat, Dept Informat, Str Acad 14, Bucharest 5, Romania.	denaches@fmi.unibuc.ro					Demuth H, 2000, NEURAL NETWORK TOOLB; Foresee F.D., 1997, P 1997 INT JOINT C N, DOI DOI 10.1109/ICNN.1997.614194; Hastie T., 2002, ELEMENTS STAT LEARNI; Nguyen D, 1990, INT JOINT C NEURAL N, V3, P21; Stamey T., 1989, J UROLOGY, V16, P1076	5	0	0	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0020-7160			INT J COMPUT MATH	Int. J. Comput. Math.	APR	2004	81	4					407	415		10.1080/00207160410001661302		9	Mathematics, Applied	Mathematics	810PQ	WOS:000220716600003		
J	Friedman, C; Sandow, S				Friedman, C; Sandow, S			Learning Probabilistic models: An expected utility maximization approach	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						learning probabilistic models; expected utility; relative entropy; pareto optimality; robustness		We consider the problem of learning a probabilistic model from the viewpoint of an expected utility maximizing decision maker/investor who would use the model to make decisions (bets), which result in well defined payoffs. In our new approach, we seek good out-of-sample model performance by considering a one-parameter family of Pareto optimal models, which we define in terms of consistency with the training data and consistency with a prior (benchmark) model. We measure the former by means of the large-sample distribution of a vector of sample-averaged features, and the latter by means of a generalized relative entropy. We express each Pareto optimal model as the solution of a strictly convex optimization problem and its strictly concave (and tractable) dual. Each dual problem is a regularized maximization of expected utility over a well-defined family of functions. Each Pareto optimal model is robust: maximizing worst-case outperformance relative to the benchmark model. Finally, we select the Pareto optimal model with maximum (out-of-sample) expected utility. We show that our method reduces to the minimum relative entropy method if and only if the utility function is a member of a three-parameter logarithmic family.	Stand & Poors Risk Solut Grp, New York, NY 10041 USA	Friedman, C (reprint author), Stand & Poors Risk Solut Grp, 55 Water St, New York, NY 10041 USA.						AVELLANEDA M, 1997, APPL MATH FINANCE; Avellaneda M, 1998, INT J THEORETICAL AP, V1, P447, DOI 10.1142/S0219024998000242; Berger J. O., 1985, STATISTICAL DECISION; BERKOVITZ J, 2002, CONVEXITY OPTIMIZATI; Boyd S., 2001, CONVEX OPTIMIZATION; Burnham K.P., 2002, MODEL SELECTION MULT; Chen Stanley F, 1999, CMUCS99108; Cover T. M., 1991, ELEMENTS INFORMATION; DANIELL GJ, 1991, MAXIMUM ENTROPY ACTI; Duffie D., 1996, DYNAMIC ASSET PRICIN; FRENK G, 2002, EEQUIVALENT RESULTS; Friedman C., 2003, INT J THEORETICAL AP, V6, P355, DOI 10.1142/S0219024903001918; FRIEDMAN C, 2003, DEFAULT PROBABILITY; FRIEDMAN C, 2003, RISK; Frittelli M, 2000, MATH FINANC, V10, P39, DOI 10.1111/1467-9965.00079; GOLAN A, 1996, MAXIMUM ENTROPY EC; GRUNWALD P, 2002, P ITW; Gulko L., 2002, INT J THEORETICAL AP, V5, P355, DOI 10.1142/S021902490200147X; GULL SF, 1978, NATURE, V272, P686, DOI 10.1038/272686a0; Hastie T., 2001, ELEMENTS STAT LEARNI; HUANG J, 2003, COMMUNICATION; JAYNES E, 1984, P 4 MAX ENTR WORKSH, P26; JAYNES ET, 1982, P IEEE, V70, P939, DOI 10.1109/PROC.1982.12425; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; KULLBACK S, 1997, IFNORMATION THEORY S; Lebanon G., 2001, CMUCS01144; Luenberger D., 1998, INVESTMENT SCI; Luenberger D. G., 1969, OPTIMIZATION VECTOR; Rockafellar R.T., 1970, CONVEX ANAL; SAMPERI D, 1997, THESIS NEW YORK U NE; SANDOW S, 2003, EC WIDE BOND DEFAULT; SKILLING J, 1991, MAXIMUM ENTROPY ACTI; TOPSOE F, 1979, KYBERNETIKA, V15, P8; Vapnik V., 1999, NATURE STAT LEARNING; von Neumann J., 1944, THEORY GAMES EC BEHA; Wu N., 1997, MAXIMUM ENTROPY METH	36	0	0	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	APR 1	2004	4	3					257	291				35	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	815LN	WOS:000221043900001		
J	Kerber, A; Laue, R; Meringer, M; Rucker, C				Kerber, A; Laue, R; Meringer, M; Rucker, C			Molgen-QSPR, a software package for the study of quantitative structure property relationships	MATCH-COMMUNICATIONS IN MATHEMATICAL AND IN COMPUTER CHEMISTRY			English	Article							ELECTROTOPOLOGICAL-STATE; MOLECULAR GRAPHS; ATOMIC-LEVEL; INDEX; DESCRIPTORS; HYDROCARBONS; WALKS	A new software package MOLGEN-QSPR for the exploration of quantitative structure property relationships is introduced. Practical results obtained using this software are presented.	Univ Bayreuth, Dept Math, D-95440 Bayreuth, Germany	Rucker, C (reprint author), Univ Bayreuth, Dept Math, POB 101251, D-95440 Bayreuth, Germany.	ChristRckr@aol.com	Rucker, Christoph/C-5519-2009; Meringer, Markus/F-8297-2010	Meringer, Markus/0000-0001-8526-2429			ALLINGER NL, 1977, J AM CHEM SOC, V99, P8127, DOI 10.1021/ja00467a001; BALABAN AT, 1983, PURE APPL CHEM, V55, P199; Bonchev D, 2001, J CHEM INF COMP SCI, V41, P582, DOI 10.1021/ci000104t; Bonchev D, 2001, SAR QSAR ENVIRON RES, V12, P213, DOI 10.1080/10629360108035379; Breiman L., 1984, CLASSIFICATION REGRE; DELSETH C, 1978, HELV CHIM ACTA, V61, P1327, DOI 10.1002/hlca.19780610415; DELSETH C, 1976, HELV CHIM ACTA, V59, P1410; DELSETH C, 1976, HELV CHIM ACTA, V59, P466, DOI 10.1002/hlca.19760590213; Dong Q, 2002, J CHEM INF COMP SCI, V42, P473, DOI 10.1021/ci010118e; Fliszar S., 1983, CHARGE DISTRIBUTION; GREENSHIELDS JB, 1958, J PHYS CHEM-US, V62, P271, DOI 10.1021/j150561a005; GUGISCH R, 2000, MATCH COMMUN MATH CO, V41, P189; Gutman I, 2001, J CHEM INF COMP SCI, V41, P739, DOI 10.1021/ci000149u; HALL LH, 1991, QUANT STRUCT-ACT REL, V10, P43, DOI 10.1002/qsar.19910100108; HALL LH, 1991, J CHEM INF COMP SCI, V31, P76, DOI 10.1021/ci00001a012; Hastie T., 2002, ELEMENTS STAT LEARNI; HOSOYA H, 1971, B CHEM SOC JPN, V44, P2332, DOI 10.1246/bcsj.44.2332; Ihaka R, 2005, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Katritzky A.R., 1994, CODESSA REFERENCE MA; Kier L. B., 1999, MOL STRUCTURE DESCRI; KIER LB, 1990, PHARMACEUT RES, V7, P801, DOI 10.1023/A:1015952613760; Lucic B, 2002, CROAT CHEM ACTA, V75, P847; Ren BY, 2003, J CHEM INF COMP SCI, V43, P161, DOI 10.1021/ci020382n; Ripley BD, 1996, PATTERN RECOGNITION; RUCKER C, 2003, MOL DESCRIPTORS COMP; RUCKER G, 1993, J CHEM INF COMP SCI, V33, P683; RUCKER G, 1999, J CHEM INF COMP SCI, V39, P78; Vapnik VN, 1995, NATURE STAT LEARNING; WIENER H, 1947, J AM CHEM SOC, V69, P17, DOI 10.1021/ja01193a005; Wildman SA, 1999, J CHEM INF COMP SCI, V39, P868, DOI 10.1021/ci990307l; Zupan J., 1993, NEURAL NETWORKS CHEM	31	3	3	UNIV BAYREUTH, DEPT MATHEMATICS	BAYREUTH	C/O PROF DR A KERBER, D-95440 BAYREUTH, GERMANY	0340-6253			MATCH-COMMUN MATH CO	Match-Commun. Math. Cmput. Chem.	APR	2004		51					187	204				18	Chemistry, Multidisciplinary; Computer Science, Interdisciplinary Applications; Mathematics, Interdisciplinary Applications	Chemistry; Computer Science; Mathematics	833JD	WOS:000222332700014		
J	Takenouchi, T; Eguchi, S				Takenouchi, T; Eguchi, S			Robustifying AdaBoost by adding the naive error rate	NEURAL COMPUTATION			English	Article							REGRESSION	AdaBoost can be derived by sequential minimization of the exponential loss function. It implements the learning process by exponentially reweighting examples according to classification results. However, weights are often too sharply tuned, so that AdaBoost suffers from the nonrobustness and overlearning. We propose a new boosting method that is a slight modification of AdaBoost. The loss function is defined by a mixture of the exponential loss and naive error loss functions. As a result, the proposed method incorporates the effect of forgetfulness into AdaBoost. The statistical significance of our method is discussed, and simulations are presented for confirmation.	Grad Univ Adv Studies, Dept Stat Sci, Tokyo, Japan; Inst Stat Math, Tokyo, Japan	Takenouchi, T (reprint author), Grad Univ Adv Studies, Dept Stat Sci, Tokyo, Japan.	ttakashi@ism.ac.jp; eguchi@ism.ac.jp	Eguchi, Shinto/A-9103-2012				COPAS JB, 1988, J ROY STAT SOC B MET, V50, P225; CSISZAR I, 1984, ANN PROBAB, V12, P768, DOI 10.1214/aop/1176993227; DOMINGO C, 2000, P 13 C COMP LEARN TH; Eguchi S, 2002, BIOMETRIKA, V89, P1, DOI 10.1093/biomet/89.1.1; EGUCHI S, 2001, J KOREAN STAT SOC, V30, P247; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Hampel F., 1986, ROBUST STAT APPROACH; Hastie T., 2001, ELEMENTS STAT LEARNI; Huber P., 1981, ROBUST STAT; LEBANON G, 2001, ADV NEURAL INFORMATI, V14; MASON L, 1999, ADV NEURAL INFORMATI, V11; McLachlan G., 1992, DISCRIMINANT ANAL ST; MURATA N, 2002, 860 ISM; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; SCHAPIRE R, 1999, P 4 EUR C COMP LEARN; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760	17	22	22	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	0899-7667			NEURAL COMPUT	Neural Comput.	APR	2004	16	4					767	787		10.1162/089976604322860695		21	Computer Science, Artificial Intelligence	Computer Science	779DW	WOS:000189281000005	15025829	
J	Esty, DC				Esty, DC			Environmental protection in the information age	NEW YORK UNIVERSITY LAW REVIEW			English	Review							LIABILITY RULES; PROPERTY RULES; NUISANCE LAW; ECONOMIC-ANALYSIS; RISK REGULATION; MARKET VALUE; PROJECT XL; GOVERNANCE; PERFORMANCE; FEDERALISM	Information gaps and uncertainties lie at the heart of many persistent pollution and natural resource management problems. This article develops a taxonomy of these gaps and argues that the emerging technologies of the Information Age will create new gap-filling options and thus expand the range of environmental protection strategies. Remote sensing technologies, modern telecommunications systems, the Internet, and computers all promise to make it much easier to identify harms, track pollution flows and resource consumption, and measure the resulting impacts. These developments will make possible a new structure of institutional responses to environmental problems including a more robust market in environmental property rights, expanded use of economic incentives and market-based regulatory strategies, improved command-and-control regulation, and redefined social norms of environmental stewardship. Likewise, the degree to which policies are designed to promote information generation will determine whether and how quickly new institutional approaches emerge. While some potential downsides to Information Age environmental protection remain, the promise of a more refined, individually tailored, and precise approach to pollution control and natural resource management looks to be significant.	Yale Univ, Sch Forestry & Environm Studies, New Haven, CT 06520 USA; Yale Univ, Sch Law, New Haven, CT 06520 USA	Esty, DC (reprint author), Yale Univ, Sch Forestry & Environm Studies, New Haven, CT 06520 USA.						Adkins Jocelyn C., 1997, VILL ENV L J, V8, P341; Afsah Shakeb, 1997, PUTTING PRESSURE POL; AKERLOF GA, 1970, Q J ECON, V84, P488, DOI 10.2307/1879431; ALDRICH DF, 1999, MASTERING DIGITAL MA, P31; Allenby BR, 2001, INFORMATION SYSTEMS AND THE ENVIRONMENT, P15; ALLENBY BR, INFORMATION SYSTEMS, P1; ANDERSON K, 2001, EUR J INT L, V11, P104; Anderson Kenneth, 2000, EUR J INT LAW, V11, P91, DOI 10.1093/ejil/11.1.91; Anderson T. L., 1998, WHO OWNS ENV, P259; Anderson Terry Lee, 2001, FREE MARKET ENV; Andrew Hoerner J., 1996, OZONE PROTECTION US, V39, P39; ARLEN J, 1997, NEW YORK U LAW REV, V72, P742; Arlen J, 1997, NEW YORK U LAW REV, V72, P687; ARORA S, 1995, J ENV EC M, V28, P273; ARORA S, 1995, J ENVIRON ECON MANAG, V28, P271, DOI 10.1006/jeem.1995.1018; Arrow K.J., 1996, CLIMATE CHANGE 1995, P125; AYRES I, 2003, STANFORD LAW REV, V55, P1296; AYRES I, 1997, YALE LAW J, V106, P706; Ayres I, 1996, YALE LAW J, V106, P703, DOI 10.2307/797308; Ayres I, 2003, STANFORD LAW REV, V55, P1193; AYRES I, 1995, YALE LAW J, V104, P1083; AYRES I, 1992, REPSONSIVE REGULATIO, P45; AYRES I, 1995, YALE LAW J, V104, P1027, DOI 10.2307/797059; AYRES I, 1995, YALE LAW J, V105, P252; AYRES I, 1995, YALE LAW J, V105, P235, DOI 10.2307/797144; BALKIN JM, 2004, IN PRESS NYU L REV, V79; Balkin JM, 1996, DUKE LAW J, V45, P1131, DOI 10.2307/1372884; Barret S., 2000, ENVIRON DEV ECON, V5, P433, DOI 10.1017/S1355770X00000267; Barsa M, 1997, STANFORD LAW REV, V49, P1223, DOI 10.2307/1229251; BASS G, 2004, POST SEPTEMBER 11 AT; BAUMOL WJ, 1988, THEORY ENV POLICY, P18; BEEN V, 1994, YALE LAW J, V103, P1383, DOI 10.2307/797089; BEEN V, 1994, YALE LAW J, V103, P1384; BELL FW, 1972, J POLIT ECON, V80, P148, DOI 10.1086/259867; BENEDICK RE, 1998, OZONE DIPLOMACY NEW, P9; BENKLER Y, 2003, YALE LAW J, V112, P369; BERG JT, 1999, PUB ROADS        MAR, P47; BERMANN GA, 1994, COLUMBIA LAW REV, V94, P339; BERMANN GA, 1994, COLUMBIA LAW REV, V94, P331, DOI 10.2307/1123200; BIEKART JW, 1995, REV EUR COMMUNITY IN, V4, P141, DOI 10.1111/j.1467-9388.1995.tb00213.x; BODANSKY D, 1993, YALE J INT L, V18, P475; Bodansky D., 1993, YALE J INT LAW, V18, P451; BODANSKY D, 1991, ENVT             SEP, P5; BODANSKY D, 1993, YALE J INTL L, V18, P454; BODANSKY D, 1991, ENVIRONMENT      SEP, P4; Bowen W, 2002, ENVIRON MANAGE, V29, P3, DOI 10.1007/s00267-001-0037-8; BRANDENBURGER AM, 1996, COOPERATION, P198; Brandon BH, 2002, ADMIN LAW REV, V54, P1421; BRANSCOMB AW, 1995, YALE LAW J, V104, P1639, DOI 10.2307/797027; BRANSCOMB AW, 1995, YALE LAW J, V104, P1646; Brennan Geoffrey, 1985, REASON RULES CONSTIT; BRENNER JF, 1974, J LEGAL STUD, V3, P403, DOI 10.1086/467519; BREYER S, 1979, HARVARD LAW REV, V92, P556; Breyer Stephen, 1979, HARVARD LAW REV, V92, P547, DOI 10.2307/1340395; BREYER STEPHEN, 1993, BREAKING VICIOUS CIR, P33; BRIFFAULT R, 1990, COLUMBIA LAW REV, V90, P346, DOI 10.2307/1122776; Brooks RRW, 2002, NORTHWEST U LAW REV, V97, P267; BROWN J, 1998, PACE ENV LAW REV, V16, P189; BROWN J, 1998, PACE ENV L REV, V16, P197; Brown Jacqueline Lesley, 1997, J ENVT L LITIG, V12, P151; BROWN JL, 1997, J ENVT L LITIG, V12, P246; BROWN LR, 2001, ECO EC BUILDING EC E, P4; BUCKMAN R, 2001, WALL ST J EUR   0321, P26; Butler Henry N., 1996, YALE L POLY REV, V14, P23; CABALLERO TE, 1998, STAN ENVT LJ, V17, P412; Caballero Thomas E., 1998, STAN ENV LJ, V17, P399; CALABRES.G, 1972, HARVARD LAW REV, V85, P1089, DOI 10.2307/1340059; CALABRESI G, 1991, YALE LAW J, V100, P1211, DOI 10.2307/796691; CAMPBELL SM, 1997, NYLJ            1030, pS4; CAROTHERS L, 1998, ENV F            NOV, P12; Case David W., 2001, ENV L REP, V31, P10773; CASE DW, 2001, ENV L REP, V31, P10776; CHANDAR A, 2002, U CHICAGO LAW REV, V69, P1481; CHANDER A, 2002, U CHICAGO LAW REV, V69, P1493; Chander A, 2002, U CHICAGO LAW REV, V69, P1479, DOI 10.2307/1600656; Charnley Gail, 2002, ENV L REP, V32, P10363; Chertow MR, 2000, ANNU REV ENERG ENV, V25, P313, DOI 10.1146/annurev.energy.25.1.313; CHICHILNISKY G, 2000, ENV MARKETS EQUITY E, P242; COASE RH, 1992, AM ECON REV, V82, P713; Coase Ronald H., 1960, J LAW ECON, V3, P10; COGLIANESE C, 2003, INTERNET PUBLIC PART, P5; COHEN A, 1999, PERSP BUS INNOVATION, P7; Cohen Mark A., 2001, ENV L REP, V31, P10425; Coleman J L, 1988, MARKETS MORALS LAW, P184; DALES JH, 1968, POLLUTION PROPERTY P, P81; Dana DA, 1996, IOWA LAW REV, V81, P969; DAVENPORT TH, 1997, INFORMATION ECOLOGY; Davies J. C., 1998, POLLUTION CONTROL US; Davis S., 1998, BLUR SPEED CHANGE CO; DAWES RN, 2001, EVERYDAY IRRATIONALI, P6; DEALESSI M, 1998, IEA STUD ENV    1111, P40; Demsetz H, 1967, AM ECON REV, V57, P347; *DEP EN, 2004, EN EFF REN EN; DERTOUZOS M, 1997, NEW WORLD INFORMATIO; DESHERBININ A, 2002, ENVT, V44, P22; de Sherbinin A, 2002, ENVIRONMENT, V44, P20; DIVER CS, 1983, YALE LAW J, V93, P65, DOI 10.2307/796245; Dowell G, 2000, MANAGE SCI, V46, P1059, DOI 10.1287/mnsc.46.8.1059.12030; DOWELL G, 2000, M SCI, V46, P1065; DUA A, 1997, SUSTAINING ASIS PACI, P123; ECCLES RG, 2001, VALUE REPORTING REVO, P211; EFRON B, 2002, JACKKNIFE BOOTSTRAP, P2; EHRLICH I, 1974, J LEGAL STUD, V3, P257, DOI 10.1086/467515; Ehrlich Isaac, 1974, J LEGAL STUD, V3, P261; ELDRIQUEZ J, 2003, SMALLEST EVER GUIDE, P22; ELLICKSON RC, 1989, CHI KENT L REV, V65, P35; ELLICKSON RC, 1977, YALE LAW J, V86, P429; Ellickson RC, 1998, J LEGAL STUD, V27, P537, DOI 10.1086/468033; ELLICKSON RC, 1998, J LEGAL STUD, V27, P540; ELLICKSON RC, 1973, U CHICAGO LAW REV, V40, P719; ELLICKSON RC, 1977, YALE LAW J, V86, P475; ELLICKSON ROBERT, 1991, ORDER LAW NEIGHBORS; ELLICKSON RC, 1977, YALE LAW J, V86, P385, DOI 10.2307/795798; Ellickson Robert C., 1973, U CHICAGO LAW REV, V40, P728; ELLICKSON RC, 1989, YALE LAW J, V99, P611, DOI 10.2307/796756; Ellickson Robert C., 1973, U CHICAGO LAW REV, V40, P681, DOI DOI 10.2307/1599220; ELLIOTT ED, 1998, APPL RES PUB POL WIN, P48; Engraving Copyright Act, 1734, AM ECON REV, V8; Enriquez J., 2001, FUTURE CATCHES YOU G; *ENV LAW I, 1993, WETL MIT BANK; *EPA, 2002, STAT PRIM; *EPA, 2001, MAJ MAN CHALL PROGR, P13; *EPA, 2004, FIN REP OZ TRANSP AS; EPSTEIN MJ, 1996, MEASURING CORPORATE, P128; EPSTEIN RA, 1995, SIMPLE RULES COMPLEX, P30; Eskridge Jr William N., 1988, VA LAW REV, V74, P285; ESKRIDGE WN, 1988, VA LAW REV, V74, P275, DOI 10.2307/1073145; Esty D., 2001, REGULATORY COMPETITI; Esty D. C., 2000, GLOCAL COMPETITIVENE, P60; Esty D. C., 2001, ENVIRON LAW REP, V31.5, P10603; Esty Daniel, 1998, J INT ECON LAW, V1, P123, DOI 10.1093/jiel/1.1.123; Esty Daniel C., 1998, J IND ECOL, V2, P35, DOI 10.1162/jiec.1998.2.1.35; ESTY DC, 1999, NEW YORK U LAW REV, V74, P1519; ESTY DC, 2001, ENV L REV, V31, P10606; Esty DC, 1996, MICH LAW REV, V95, P570, DOI 10.2307/1290162; ESTY DC, 1998, J IND ECOLOGY, V2, P37; Esty DC, 1999, NEW YORK U LAW REV, V74, P1495; ESTY DC, 2001, ENV PERFORMANCE MEAS, P6; FARBER DA, 1999, HARV ENG L REV, V23, P315; FARBER DA, 2003, UC DAVIS L REV, V37, P148; Farber DA, 1999, HARVARD ENVIRON LAW, V23, P297; FARBER DA, 1992, J L EC ORG, V8, P78; Farber Daniel A., 2003, UC DAVIS L REV, V37, P145; FARBER DA, 1992, J LAW ECON ORGAN, V8, P59; Rachlinski JJ, 2002, CORNELL LAW REV, V87, P549; *FED HIGHW ADM OFF, 2004, TRAFF VOL TRENDS; Fiorino DJ, 1999, HARVARD ENVIRON LAW, V23, P441; FIORINO DJ, 1999, HARVARD ENVIRON LAW, V23, P454; FITZGERALD N, 1998, TOMORROWS WASH CHALL; FLORINI A, 2003, COMING DEMOCRACY NEW, P188; Francis WL, 1997, LEGIS STUD QUART, V22, P137; FRANK AG, 1997, COLUM J ENVT, V22, P145; Freeman J, 1997, UCLA LAW REV, V45, P1; FRENCH H, 2000, VANISHING BORDERS PR, P10; FRIEDMAN F, 1991, ENVT F           MAY, P20; FRIEDMAN F, 1991, ENVT F           MAY, P23; GALSTON WA, 2002, LIBERAL PLURALISM, P5; GARDNER RC, 1996, ENV L REP, V26, P10075; Gauna Eileen P., 2002, ENV JUSTICE LAW POLI; GELBSPAN R, 1998, HEAT IS CLIMATE CRIS, P33; *GEN ACC OFF, 2000, GAO0197T; Gladwell M., 2000, TIPPING POINT LITTLE; GLICKSMAN RL, 1996, KAN JL PUB POLY, V5, P9; GLICKSMAN RL, 1996, KAN J L PUB POLY, V5, P19; Goebel M., 1999, SIGKDD EXPLORATIONS, V1, P20; GOLDSTEIN A, 2002, TIME            0429, P30; GOLLUB M, 1998, ENVIRON LAW, V4, P311; Gondal MA, 1997, APPL OPTICS, V36, P3195, DOI 10.1364/AO.36.003195; GONDAL MA, 1997, APPL OPTICS, V36, P3200; GORE A, 1992, EARTH BALANCE ECOLOG, P342; GRAEDEL TE, 2001, ENCY GLOBAL ENV CHAN, V3, P73; Graedel TE, 1996, ANNU REV ENERG ENV, V21, P69, DOI 10.1146/annurev.energy.21.1.69; Graham J. D., 1995, RISK VERSUS RISK TRA; Grtibler A., 2002, TECHNOLOGICAL CHANGE; Guile Bruce, 1997, P76; GUNNINGHAN N, 1998, SMART REGULATION DES, P15; GUSTAVE J, 2004, RED SKY MORNING AM C; HAGEL J, 1999, NET WORTH SHAPING MA, pR12; HAHN RW, 1991, ECOL LAW QUART, V18, P1; HAHN RW, 2000, REVIVING REGULATORY, P6; Halverson MA, 2003, OECOLOGIA, V134, P360, DOI 10.1007/s00442-002-1136-9; HAMILTON JT, 1995, J ENVIRON ECON MANAG, V28, P98, DOI 10.1006/jeem.1995.1007; HANSELL S, 2003, NY TIMES        1028, pA1; HANSEN F, 2000, ENV F            MAY, P45; HARDIN G, 1968, SCIENCE, V162, P1243; Hardin Garrett, 1968, SCIENCE, V162, P1244, DOI [DOI 10.1126/SCIENCE.162.3859.1243), 10.1126/science.162.3859.1243]; Hart SL, 1997, HARVARD BUS REV, V75, P66; HARTMAN T, 2000, DENVER ROCKY MO 0831, pA4; Hastie T., 2001, ELEMENTS STAT LEARNI; HAUFLER VIRGINIA, 2001, PUBLIC ROLE PRIVATE, p[31, 53, 81]; HAUSKER K, 1999, ENV L REP, V29, P10148; HAUSKER K, 1999, ENV L REP, V29, P10152; HAYES D, 1995, ENV L REV, V25, P958; Haykin S., 1999, NEURAL NETWORKS COMP, P1; HINSTA EJ, 1994, GEOPHYSICAL RES LETT, V21, P2559; Hirsch D. D., 2001, VA ENV LJ, V20, P57; Hirsch DD, 1998, U ILLINOIS LAW REV, P129; HIRSCH DD, 2001, COLUM J ENV L, V26, P219; HIRSCH DD, 2001, COLUM J ENV L, V26, P256; Hoffman AJ, 1996, SOC NATUR RESOUR, V9, P47, DOI 10.1080/08941929609380951; Hoffman AJ, 1999, ACAD MANAGE J, V42, P351, DOI 10.2307/257008; HOFFMAN AJ, 1999, ACAD MANAGE J, V42, P363; HOMERDIXON T, 2000, INGENUITY GAP, P1; Hopkins M., 2003, PLANETARY BARGAIN CO; HORNSTEIN DT, 1992, COLUMBIA LAW REV, V92, P562, DOI 10.2307/1122954; HORNSTEIN DT, 1992, COLUMBIA LAW REV, V92, P584; HORWITZ MJ, 1977, TRANBSFORMTION AM LA, P97; HOVENKAMP H, 1983, MINN LAW REV, V67, P670; HOVENKAMP H, 1983, MINN LAW REV, V67, P645; HUMPHRIES C, 2001, FOCUS NEWS HARV MED; HYAES D, 1995, ENVT L, V25, P953; *IND AN DIV, 2000, TRENDS TEL SERV, P14; *INT PAN CLIM CHAN, 2001, CLIM CHANG 2000 IMP, P14; IRWIN F, 2002, ENVTL L REP, V32, P10784; Joy B., 2000, WIRED            APR, P238; KABRAMAN D, 2003, MODELING FACTS CULTU; KAHAN DM, 2003, U PENN LAW REV, V51, P1291; Kahan DM, 1999, HARVARD LAW REV, V113, P413, DOI 10.2307/1342330; KAHAN DM, 1999, HARVARD LAW REV, V113, P459; KAHAN DM, 1999, HARVARD LAW REV, V113, P448; KAPLOW L, 1995, J LAW ECON ORGAN, V11, P150; Kaplow L, 1996, HARVARD LAW REV, V109, P713, DOI 10.2307/1342135; Kaplow Louis, 1995, J L EC ORG, V11, P161; Karkkainen BC, 2001, GEORGETOWN LAW J, V89, P257; KATZ ML, 1994, J ECON PERSPECT, V8, P93; KEETON RE, 1965, BASIC PROTECTION TRA, P180; Kelly K., 1994, OUT CONTROL NEW BIOL; KENNEDY D, 2001, PT KELIAN CASE STUDY; KENNEDY R, 2003, NY TIMES MAG    0420, P42; KEOHANE NO, 2000, EC ENV SELECTED READ, P559; KERR IR, 2001, DALHOUSIE LJ, V22, P208; KERR IR, 2001, DALHOUSIE LJ, V22, P190; Khanna M, 1998, J ENVIRON ECON MANAG, V36, P243, DOI 10.1006/jeem.1998.1048; KLEE RJ, 2004, IN PRESS STAN ENV LJ, V23; Kleindorfer PR, 1998, RISK ANAL, V18, P155, DOI 10.1111/j.1539-6924.1998.tb00927.x; KNAUER J, INFORMATION SYSTESM, P185; KOMESAR NK, 1994, IMPERFECT ALTERNATIV, P102; Konar S, 1997, J ENVIRON ECON MANAG, V32, P109, DOI 10.1006/jeem.1996.0955; Konar S, 2001, REV ECON STAT, V83, P281, DOI 10.1162/00346530151143815; Krier Jame E., 1977, POLLUTION POLICY CAS; KRIER JE, 1974, UCLA LAW REV, V22, P323; KRIER JE, 1971, ENV LAW POLICY READI, P293; KRIER JE, 1995, MD L REV, V54, P1226; KRIER JE, 1995, NEW YORK U LAW REV, V70, P453; KRIER JE, 1995, NEW YORK U LAW REV, V70, P440; KRIER JE, 1995, MD L REV, V54, P1228; KRIER JE, 1973, NAT RESOUR J, V13, P89; KUNICH JC, 2001, SOUTH CALIF LAW REV, V74, P859; Kunich JC, 2001, SOUTHERN CALIF LAW R, V74, P807; KURAN T, 1999, STANFORD LAW REV, V51, P705; Kuran T, 1999, STANFORD LAW REV, V51, P683, DOI 10.2307/1229439; Landy MK, 1990, ENV PROTECTION AGENC; Latin Howard, 1988, YALE J REG, V5, P89; LAZARUS RJ, 1993, NORTHWEST U LAW REV, V87, P787; LEDGERS G, 1995, CASE STUDIES CORPORA; LEE E, 2002, NOTRE DAME L REV, V77, P1317; LEE E, 2002, NOTRE DAME L REV, V77, P1275; Lessig L, 2001, UCLA LAW REV, V48, P1057; Lessig L., 1999, CODE OTHER LAWS CYBE; Lessig L., 2001, FUTURE IDEAS FATE CO; LESSIG L, 2001, UCLA LAW REV, V48, P1072; LEWIN JL, 1986, IOWA LAW REV, V71, P775; LEWIN JL, 1986, IOWA LAW REV, V71, P809; Libecap Gary D., 1989, CONTRACTING PROPERTY, P17; Lowenstein L, 1996, COLUMBIA LAW REV, V96, P1335, DOI 10.2307/1123407; LYNCH M, 2001, GUIDANCE DISTRIBUTIN; LYNDON ML, 1989, MICH LAW REV, V87, P1795, DOI 10.2307/1289204; LYNDON ML, 1989, MICH LAW REV, V87, P1797; MAKAR SD, 1995, FLA B J, V69, P44; Mank BC, 1998, ECOL LAW QUART, V25, P1; MANK BC, 1998, ECOLOGY L Q, V25, P24; Martin P, 1997, PET SCI TECHNOL, V15, P409, DOI 10.1080/10916469708949667; MASHAW JL, 1997, CHAOS GOVERNANCE USI; MATTHEWS HS, 2001, UNPUB ENV IMP POL IM, P27; Maxwell J., 2002, EC I ENV POLICY; MAZUREK J, 2000, GREENER M INT, V32, P57; Mazurek Jan, 1999, MAKING MICROCHIPS PO; McCubbins Mathew D., 1987, J L EC ORG, V3, P243, DOI DOI 10.1016/J.MRREV.2004.07.002; MCGARITY TO, 1980, HARVARD LAW REV, V93, P837, DOI 10.2307/1340420; MCGARITY TO, 2002, WASHBURN LJ, V41, P549; MCGARITY TO, 2002, WASHBURN L J, V41, P559; McKibben Bill, 2003, ENOUGH STAYING HUMAN; MEDEARIS J, 1989, LA TIMES        1024, pA9; Medema S., 1998, COASEAN EC LAW EC NE; MENDELSOHN R, 1986, J ENVIRON ECON MANAG, V13, P301, DOI 10.1016/0095-0696(86)90001-X; Menell Peter S., 1995, MD L REV, V54, P1435; MENELL PS, 1995, MD L REV, V54, P1437; MEYER C, 1989, ENVIRON LAW, V19, P321; MEYER CB, 1989, ENV L, V19, P323; MICHELMA.FI, 1971, YALE LAW J, V80, P647, DOI 10.2307/795267; Mill John Stuart, 1859, LIBERTY; Mintz A., 2002, WEB DECEPTION MISINF; POLINSKY AM, 1980, STANFORD LAW REV, V32, P1075, DOI 10.2307/1228549; MITCHELL RB, 1998, INT STUD Q, V42, P110; Mitchell RB, 1998, INT STUD QUART, V42, P109, DOI 10.1111/0020-8833.00071; MITCHELL WJ, 1999, URBAN LIFE JIM BUT N, P13; MITCHELL WJ, 1971, YALE LAW J, V80, P666; MITCHELL WJ, 1971, YALE LAW J, V80, P649; Morgenstern Richard D., 1997, EC ANAL EPA ASS REG; NAGLE JC, 1994, MINN LAW REV, V78, P1493; *NAT GROUND WAT AS, 2000, RAD WHAT YOU NEED KN; *NAT MIN ASS, 2004, NMA SUST DEV PRINC; NATHENSON IS, 1998, HARV JL TECH, V12, P43; National Soil Survey Office, 1995, SETT PRIOR GETT RES, P1; Negroponte N., 1995, BEING DIGITAL; NORTH DC, 1987, ECON INQ, V25, P419; Noveck Beth Simone, 2003, B U J SCI TECH L, V9, P1; NOVECK BS, 2003, B U J SCI TECH L, V9, P14; *OFF AIR QUAL PLAN, 2000, NAT AIR QUAL EM TREN; *OFF AIR QUAL PLAN, 2000, NAT AIR POLL EM TREN; *OFF AIR QUAL PLAN, 1998, NAT AIR QUAL EM TREN; *OFF POLL PREV TOX, 1999, EPA745R9904; *OFF SOL WAST EM R, 2002, EPA530R02001; OGUS AI, 1994, REGULATION LEGAL FOR, P204; OLIVER C, 1996, INVESTORS BUS D 1205, pA1; OLSON M, 1969, AM ECON REV, V59, P482; OLSON M, 1969, AM ECON REV, V59, P479; Olson Mancur, 1971, LOGIC COLLECTIVE ACT; Organization for Economic Cooperation and Development, 1998, SUST DEV ENV IND; Orts EW, 1995, NORTHWEST U LAW REV, V89, P1227; ORTS EW, 2001, ENV CONTRACTS COMP A, P5; ORTS EW, 1995, NORTHWEST U LAW REV, V89, P1252; Ostrom Elinor, 1990, GOVERNING COMMONS EV, P88; Park J., 2002, ECOLOGY NEW EC SUSTA; Paustenbach DJ, 2000, J TOXICOL ENV HEAL B, V3, P179, DOI 10.1080/10937400050045264; PEDERSEN WF, 2001, HARVARD ENVIRON LAW, V25, P160; Pedersen WF, 2001, HARVARD ENVIRON LAW, V25, P151; PERCIVAL RV, 2003, ENV REGULATION LAW S, P85; PERKS R, 2003, REWRITING RULES YEAR; PETKOVA E, 2002, WORLD RES I CLOSING, P33; PEZZOLI K, 2000, CAL W L REV, V36, P363; PEZZOLI K, 2000, CAL W L REV, V36, P335; PFAFF AS, 2000, J LAW ECON ORGAN, V16, P191; PFAFF ASP, 2004, IN RPESS J POLY ANAL, V23; Pfaff ASP, 2000, J LAW ECON ORGAN, V16, P189, DOI 10.1093/jleo/16.1.189; PILDES RH, 1995, U CHICAGO LAW REV, V62, P1, DOI 10.2307/1600132; PITTS G, INFORMATION SYSTEMS, P159; POLINSKY AM, 1979, J LEGAL STUD, V8, P1, DOI 10.1086/467601; POLINSKY AM, 1980, STANFORD LAW REV, V32, P1100; POPPER KR, 1985, POPPER SELECTIONS, P33; PORTER ME, 1995, HARVARD BUS REV, V73, P120; PORTER ME, 1991, SCI AM, V264, P168; PORTER ME, 1995, J ECON PERSPECT, V9, P97; PORTER ME, 1995, J EC PERSP, V9, P106; PORTER ME, 1990, COMPETITIVE ADVANTAG, P586; PORTNEY PR, 1990, PUBLIC POLICIES ENV, V7, P11; Posner E. A., 2000, LAW SOCIAL NORMS; POSNER RA, 1984, INT REV LAW ECON, V4, P131, DOI 10.1016/0144-8188(84)90002-4; POSNER RA, 1992, EC ANAL LAW, P367; POSNER RA, 1984, INT REV L EC, V4, P133; Posner Richard A., 1972, J LEGAL STUD, V1, P29, DOI DOI 10.1086/467478; *PRES COUNC SUST D, 1996, SUST AM NEW CONS PRO, P11; RABIN E, 1977, VA LAW REV, V63, P1335; RABIN E, 1977, VA LAW REV, V63, P1299, DOI 10.2307/1072461; RACHLINSKI JJ, 2000, U ILL L REV, P303; Rachlinski JJ, 2000, U ILLINOIS LAW REV, P299; RAINES JCB, 1992, OKLA L REV, V45, P698; RAINES JCB, 1992, OKLA LAW REV, V45, P689; *RECYCL WORLD, 2004, RECYCL EXCHA; *REG REINV XL PIL, 2000, FED REG         0627, V65, P39614; Reinhardt F. L., 2000, DOWN EARTH APPL BUSI; REISS S, 1996, WIRED            DEC, P184; REVESZ RL, 1992, NEW YORK U LAW REV, V67, P1210; Revesz RL, 2001, HARVARD LAW REV, V115, P553, DOI 10.2307/1342673; Rheingold H., 2002, SMART MOBS NEXT SOCI; Rhodes Edwardo Lao, 2003, ENV JUSTICE AM NEW P; RICHARD N. L. ANDREWS, 1999, MANAGING ENV MANAGIN; Richardson SD, 1999, J EXPO ANAL ENV EPID, V9, P200, DOI 10.1038/sj.jea.7500020; Ridley M., 1999, GENOME AUTOBIOGRAPHY; ROE D, 1989, ECON DEV Q, V3, P179, DOI 10.1177/089124248900300301; ROE D, 1989, ECON DEV Q, V3, P180; Roe David, 2002, ENV L REP, V32, P10; Roe David, 2002, ENV L REP, V32, P10232; ROMM J, 1999, INTERNET EC GLOBAL W, P22; ROOME N, 2000, GRENNER M INT, V32, P24; ROSE CM, 1991, DUKE LAW J, P1; Rose Carol, 1997, YALE LAW J, V106, P2193; Rose CM, 1996, NOTRE DAME LAW REV, V71, P329; Rose CM, 1997, YALE LAW J, V106, P2175, DOI 10.2307/797165; ROSE CM, 1991, DUKE LAW J, P12; ROSEN C, 1993, L HIST REV, V11, P354; Rosen Christine, 1993, LAW HIST REV, V11, P303, DOI 10.2307/743617; RUBIN PH, 1983, BUSINESS FIRMS COMMO, P27; Ruhl J. B., 1999, STAN ENV LJ, V18, P31; RUHL JB, 1999, STAN ENV L J, V18, P41; RUSSO MV, 1997, ACAD M J, V40, P549; Russo MV, 1997, ACAD MANAGE J, V40, P534, DOI 10.2307/257052; Sagoff Mark, 1982, ENV L, V12, P283; Sagoff Mark, 1982, ENV L, V12, P286; SALBU SR, 1998, HARV JL TECH, V11, P429; SALOP S, 1976, AM ECON REV, V66, P240; SALZMAN J, 2002, WYO L REV, V2, P286; SALZMAN J, 2000, STANFORD LAW REV, V53, P648; Salzman J, 2000, STANFORD LAW REV, V53, P607, DOI 10.2307/1229470; SALZMAN J, 2002, WYO L REV, V2, P253; Salzman J, 1999, UCLA LAW REV, V47, P411; SALZMAN J, 1999, UCLA LAW REV, V47, P415; Salzman James, 1997, J IND ECOLOGY, P11, DOI 10.1162/jiec.1997.1.2.11; SAUL M, 2003, NAT RESOURCES EN FAL, P76; SCHMALENSEE R, 1989, HDB IND ORG, V1, P135; Schnoor J. L., 1996, ENV MODELING FATE TR; Schoen D, 1998, ENVIRON SCI TECHNOL, V32, p498A, DOI 10.1021/es9838211; SCHUCK PH, 2000, LIMITS LAW ESSAYS DE, P438; Schwartz PM, 1999, VANDERBILT LAW REV, V52, P1609; SCHWARTZ PM, 1999, VANDERBILT LAW REV, V52, P1648; *SCI ADV BD ENV PR, 1990, RED RISK SETT PRIOR, P6; Shabecoff Philip, 1993, FIERCE GREEN FIRE AM; SHANKAR R, 2003, YALEGLOBAL ONLI 0328; SHAVELL S, 1984, J LEGAL STUD, V13, P357, DOI 10.1086/467745; Shavell Steven, 1984, J LEGAL STUD, V13, P359; SHRADERFRECHETT.KS, 2002, ENV JUSTICE CREATING; Simmons PJ, 1998, FOREIGN POLICY, P82, DOI 10.2307/1149037; SIMON HA, 1976, ADM BEHAV, P79; Slovic P., 2000, PERCEPTION RISK; Solomon A., 2002, BUSINESS STRATEGY EN, V11, P154, DOI DOI 10.1002/BSE.328; SOLOMON A, 2002, BUS STRAT ENV, V11, P156; SOMMER JH, 2000, BERKELEY TECH LJ, V15, P1148; Sommer Joseph H., 2000, BERKELEY TECH LJ, V15, P1145; SPICER SJ, 1997, VILL ENVT L J, V8, P4; SPICER SJ, 1997, VILL ENVT L J, V8, P1; Stenzel PL, 2000, AM BUS LAW J, V37, P237; STENZEL PL, 2000, AM BUS LJ, V37, P267; Stephenson K, 1998, CONTEMP ECON POLICY, V16, P412; STEPHENSON K, 1998, CONT EC POLY, V16, P415; Stern M. A., 1999, GLOBAL PUBLIC GOODS, P308; STEWART RB, 1993, YALE LAW J, V102, P2039, DOI 10.2307/796859; STEWART RB, 1993, YALE LAW J, V102, P2090; STEWART RB, 1977, YALE LAW J, V86, P1196, DOI 10.2307/795705; Stewart Richard B., 2001, CAP U L REV, V29, P21; Stewart Richard B., 1987, COLUM J ENV L, V13, P171; STEWART RB, 1990, U CHICAGO LAW REV, V57, P335, DOI 10.2307/1599949; STIGLER GJ, 1961, J POLIT ECON, V69, P213, DOI 10.1086/258464; Stiglitz JE, 2000, Q J ECON, V115, P1441, DOI 10.1162/003355300555015; Sugden R., 1986, EC RIGHTS COOPERATIO; Sunstein C. R., 2000, BEHAV LAW EC, P13; Sunstein C R, 1993, FLA ST U L REV, V20, P653; Sunstein C. R., 2002, RISK REASON SAFETY L; SUNSTEIN CR, 2000, J LEGAL STUD, V29, P1064; SUNSTEIN CR, 2000, GREEN BAG, V3, P397; Sunstein CR, 2000, J LEGAL STUD, V29, P1059, DOI 10.1086/468105; SUNSTEIN CR, 2001, REPUBLIC COM, P3; SUNSTEIN CR, 1999, U PENN LAW REV, V147, P626; SUNSTEIN CR, 2000, GREEN BAG, V3, P400; SUNSTEIN CR, 1996, U PENN LAW REV, V144, P2029; SUNSTEIN CR, 1993, FLA ST UL REV, V20, P655; Sunstein CR, 1999, U PENN LAW REV, V147, P613, DOI 10.2307/3312719; Sunstein CR, 2002, YALE LAW J, V112, P61, DOI 10.2307/1562234; SUNSTEIN R, 1997, FREE MARKETS SOCIAL, P327; SUSSKIND LE, 1998, UCLA J ENVT L POLY, V17, P95; Susskind L.E., 1998, UCLA J ENV L POLY, V17, P67; SWIFT B, 1998, ENV L REP, V28, P10202; Talley E, 2001, U PENN LAW REV, V149, P1955, DOI 10.2307/3312903; TAPSCOTT D, 2003, NAKED CORPORATION, P3; Tay Simon SC, 1999, GEO INT ENV L REV, V11, P241; TAY SSC, 1999, GEO INT ENV L REV, V11, P251; TAYLOR D, 1999, ENV INFRASTRUCTURE W; Theodoridis S, 1999, PATTERN RECOGNITION; THOMPSON D, 1999, DEMOCRACY COM GOVERN, P35; TIEBOUT CM, 1956, J POLIT ECON, V64, P416, DOI 10.1086/257839; Tietenberg T, 1998, ENVIRON RESOUR ECON, V11, P587, DOI 10.1023/A:1008291411492; TSAGAROUSIANOU R, 1998, CYBERDEMOCRACY TECHN, P41; Tufte E.R., 1983, VISUAL DISPLAY QUANT; UHLIR PF, 1990, EARTH OBSERVATION SY, P16; *URB I, 2003, IDEOLOGY POLITICS GU; *US EPA, 1999, SMOG WHO DOES IT HUR, P3; Vanclay J, 2003, CAN J FOREST RES, V33, P536, DOI 10.1139/X02-117; VANDUNNE JM, 1993, ENV CONTRACTS COVENA, P1; VISCUSI K, 1992, INFORMATIONAL APPROA; Viscusi W. Kip, 1998, RATIONAL RISK POLICY; Viscusi W. Kip, 1992, FATAL TRADEOFFS PUBL; VODACEK A, 2000, INFORMATIK INFOR AUG, P21; Voinov A, 1999, J ENVIRON MANAGE, V56, P231, DOI 10.1006/jema.1999.0281; VONWEIZSACKER EU, 1997, FACTOR 4 DOUBLING WE, pR21; Wackernagel M., 1996, OUR ECOLOGICAL FOOTP; WAGNER WE, 1997, CORNELL LAW REV, V82, P833; Wagner WE, 1997, CORNELL LAW REV, V82, P773; WAGNER WE, 1995, COLUMBIA LAW REV, V95, P1619; WAGNER WE, 1995, COLUMBIA LAW REV, V95, P1613, DOI 10.2307/1123193; WALLEY N, 1994, HARVARD BUS REV, V72, P46; WALLIS JJ, 1986, LONG TERM FACTORS AM, V95; Wargo John P., 1996, OUR CHILDRENS TOXIC; WATTS RJ, 1998, HAZARDOUS WASTES SOU, P405; Webster CR, 2001, APPL OPTICS, V40, P321, DOI 10.1364/AO.40.000321; Wiener JB, 1999, YALE LAW J, V108, P677, DOI 10.2307/797394; WIENER JB, 1999, YALE LAW J, V108, P763; WIENER JB, 1999, YALE LAW J, V108, P709; Williams CA, 1999, HARVARD LAW REV, V112, P1197, DOI 10.2307/1342384; WILLIAMS CA, 1999, HARVARD LAW REV, V112, P1211; WILLIAMS E, 2003, SUSTAINABLE CONSUMPT; WILLIAMSON OE, 1979, J LAW ECON, V22, P233, DOI 10.1086/466942; WILLIAMSON OE, 1979, J LAW ECON, V22, P237; Williamson O.E., 1975, MARKETS HIERARCHIES, P253; WILLIAMSON OE, 1975, MARKETS HIERARCHIES, P141; WILSDON J, 2001, DIGITAL FUTURES LIVI; Wirth Timothy E., 2002, COLO J INT ENV L POL, V13; WOJ C, 1985, J LEGAL STUD, V14, P411, DOI 10.1086/467778; *WORLD EC FOR, 2001, 2001 ENV SUST IND IN, P17; *WORLD RES I, 1992, COMPL NEW IND VIEW E; WRIGHT R, 2001, MR ORDER MEETS M MAY, P50; YANDLE B, 2001, TECHNOLOGY PROPERTY, P1; Yandle B., 1997, COMMON SENSE COMMON; YOUNG OR, 1994, INT GOV PROTECTING E, P101; ZYWICKI TJ, 1999, TUL L REV, V73, P868; Zywicki Todd J., 1999, TUL L REV, V73, P845; 2000, SEA FISHING ENFORCEM; 2002, NY REV BOOKS    0425, P61; 2003, NY TIMES        0418, pC11; 1999, ECONOMIST       1211, P20; 2003, ENVT F           SEP, P46; 2003, ECONOMIST       1018, P66	510	52	54	NEW YORK UNIV SCHOOL LAW	NEW YORK	110 WEST THIRD ST, NEW YORK, NY 10012 USA	0028-7881			NEW YORK U LAW REV	N. Y. Univ. Law Rev.	APR	2004	79	1					115	211				97	Law	Government & Law	815YU	WOS:000221078400003		
J	Restle, J; Hissmann, M; Hamprecht, FA				Restle, J; Hissmann, M; Hamprecht, FA			Nonparametric smoothing of interferometric height maps using confidence values	OPTICAL ENGINEERING			English	Article						confidence; normalized convolution; weighted regression; white light interferometry	IMAGE-RESTORATION; ROUGH SURFACES; FILTERS; VISION	We use an extension of normalized convolution to smooth height maps from interferometry using confidence values. The latter are often used for dichotomous good/bad decisions only, with all bad data being discarded. To minimize loss of information, we weight each pixel individually by the inverse of its expected variance. The relation between supplied confidence values and empirical variances is found by regression. The width of the smoothing kernel-as small as possible to prevent loss of spatial resolution, as large as necessary to average out noise-is adjusted locally so as to yield a smoothed image with a prespecified uncertainty that is homogeneous throughout. In our experimental investigations using metrological data from a white light interferometric sensor, the variable-width mask leads to images with somewhat lower absolute deviation from an average image than the fixed-width masks we use for comparison. (C) 2004 Society of Photo-Optical Instrumentation Engineers.	Robert Bosch GmbH, D-70442 Stuttgart, Germany; Univ Heidelberg, Interdisciplinary Ctr Sci Comp, D-69120 Heidelberg, Germany	Restle, J (reprint author), Robert Bosch GmbH, Postfach 300240, D-70442 Stuttgart, Germany.	fred.hamprecht@iwr.uni-heidelberg.de					Barash D, 2002, IEEE T PATTERN ANAL, V24, P844, DOI 10.1109/TPAMI.2002.1008390; CABER PJ, 1993, APPL OPTICS, V32, P3438, DOI 10.1364/AO.32.003438; CHEN CT, 1996, IEEE T IMAGE PROCESS, V1, P419; Chen T, 2001, IEEE SIGNAL PROC LET, V8, P1, DOI 10.1109/97.889633; DENG G, 1993, P IEEE NUCL SCI S ME, V3, P1615; DRESEL T, 1992, APPL OPTICS, V31, P919, DOI 10.1364/AO.31.000919; Galatsanos NP, 1992, IEEE T IMAGE PROCESS, V1, P322, DOI 10.1109/83.148606; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; Granlund G. H., 1995, SIGNAL PROCESSING CO; Hampel F., 1986, ROBUST STAT APPROACH; Hastie T., 2001, ELEMENTS STAT LEARNI; HAUSLER G, 2001, COMMUNICATION U ERLA; Jahne B., 2001, DIGITAL IMAGE PROCES; LI SZ, 1995, IEEE T PATTERN ANAL, V17, P576, DOI 10.1109/34.387504; MARROQUIN JL, 1984, 1402 MIT LIDS; Nadaraya E. A., 1964, THEOR PROBAB APPL, V10, P186; Park SC, 2000, OPT ENG, V39, P3124, DOI 10.1117/1.1320976; Ramponi G, 1996, IEEE SIGNAL PROC LET, V3, P63, DOI 10.1109/97.481156; Recknagel RJ, 2000, J OPT A-PURE APPL OP, V2, P538, DOI 10.1088/1464-4258/2/6/307; RESTLE J, 2003, OPTIMIERUNG WEISSLIC; RESTREPO A, 1988, IEEE T ACOUST SPEECH, V36, P1326, DOI 10.1109/29.1660; Riedel K. S., 1994, Computers in Physics, V8; SAINTMARC P, 1991, IEEE T PATTERN ANAL, V13, P514, DOI 10.1109/34.87339; SEITZ KG, 1986, Z FEINWERKTECHN MESS, V94, P423; Tomasi C, 1998, P IEEE INT C COMP VI, P839; Watson G.S., 1964, SANKHYA            A, V26, P101	26	1	1	SPIE-INT SOCIETY OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA	0091-3286			OPT ENG	Opt. Eng.	APR	2004	43	4					866	871		10.1117/1.1666622		6	Optics	Optics	814IN	WOS:000220968500014		
J	Tornoe, CW; Agerso, H; Nielsen, HA; Madsen, H; Jonsson, EN				Tornoe, CW; Agerso, H; Nielsen, HA; Madsen, H; Jonsson, EN			Population pharmacokinetic modeling of a subcutaneous depot for GnRH antagonist degarelix	PHARMACEUTICAL RESEARCH			English	Article						degarelix; NONMEM; population pharmacokinetic modeling; prostate cancer; subcutaneous depot	GONADOTROPIN-RELEASING-HORMONE; ABSORPTION; INSULIN; KINETICS	Purpose. The objective of this study is to develop a population pharmacokinetic (PK) model that describes the subcutaneous (SC) depot formation of gonadotropin-releasing hormone ( GnRH) antagonist degarelix, which is being developed for treatment of prostate cancer, exhibiting dose-volume and dose-concentration dependent absorption. Methods. The PK analysis is made in NONMEM through joint analysis of data from two phase I clinical studies; an intravenous infusion study and a single SC dose escalation study. The SC absorption is modeled using an approximation to Ficks' second law of diffusion out of a spherical depot. The dose-volume effect on the SC release is estimated using a B-spline basis whereas the bioavailability is modeled as a function of the dose-concentration. Results. The SC depot model is approximated by using two concentric spherical compartments for the SC absorption combined with a two-compartment disposition model. The results indicate that the volume effect is most apparent at low injection volumes whereas the effect is diminishing at higher injection volumes. The dose-concentration effect on the bioavailability is estimated to decrease at increasing dose-concentrations. Conclusions. The presented SC depot model describes the PK profile of GnRH antagonist degarelix. This modeling approach might also be applicable for other depot-formulated drugs exhibiting complex PK profiles.	Ferring Pharmaceut AS, Clin Pharmacol & Expt Med, Copenhagen, Denmark; Tech Univ Denmark, DK-2800 Lyngby, Denmark; Uppsala Univ, Dept Pharmaceut Biosci, Div Pharmacokinet & Drug Therapy, Uppsala, Sweden	Tornoe, CW (reprint author), Ferring Pharmaceut AS, Clin Pharmacol & Expt Med, Copenhagen, Denmark.	christoffer.tornoe@ferring.com					Agerso H, 2003, EUR J PHARM SCI, V20, P335, DOI 10.1016/j.ejps.2003.08.001; Arfken G. B., 1995, MATH METHODS PHYS; Beal SL, 1994, NONMEM USERS GUIDES; Broqua P, 2002, J PHARMACOL EXP THER, V301, P95, DOI 10.1124/jpet.301.1.95; Cook T, 2000, Oncologist, V5, P162, DOI 10.1634/theoncologist.5-2-162; de Boor C, 2001, PRACTICAL GUIDE SPLI; de Pinieux G, 2001, AM J PATHOL, V159, P753, DOI 10.1016/S0002-9440(10)61746-4; Fattinger KE, 1995, BIOMETRICS, V51, P1236, DOI 10.2307/2533256; Fick A., 1855, ANN PHYS CHEM, V94, P59, DOI DOI 10.1002/ANDP.18551700105; Hastie T., 2001, ELEMENTS STAT LEARNI; Jiang GC, 2001, J MED CHEM, V44, P453, DOI 10.1021/jm0003900; Jonsson EN, 1999, COMPUT METH PROG BIO, V58, P51; Karlsson MO, 1998, J PHARMACOKINET BIOP, V26, P207, DOI 10.1023/A:1020561807903; Klingmüller D, 1992, Recent Results Cancer Res, V124, P1; MOSEKILDE E, 1989, J PHARMACOKINET BIOP, V17, P67, DOI 10.1007/BF01059088; Nucci G, 2000, COMPUT METH PROG BIO, V62, P249, DOI 10.1016/S0169-2607(00)00071-7; Parker KL, 2001, GOODMAN GILMANS PHAR, P1541; Racine-Poon A, 1998, Stat Methods Med Res, V7, P63, DOI 10.1191/096228098670696372; Reissmann T, 2000, HUM REPROD UPDATE, V6, P322, DOI 10.1093/humupd/6.4.322; Tilbrook AJ, 2001, BIOL REPROD, V64, P735, DOI 10.1095/biolreprod64.3.735; VEROTTA D, 1993, ANN BIOMED ENG, V21, P605, DOI 10.1007/BF02368641; WACH P, 1995, MED BIOL ENG COMPUT, V33, P18, DOI 10.1007/BF02522939; Wang B, 2001, J PHARMACOKINET PHAR, V28, P321, DOI 10.1023/A:1011534529622; Weinbauer G F, 1992, Recent Results Cancer Res, V124, P113; WINSBERG S, 1980, BIOMETRIKA, V67, P669; Zhou HH, 2003, J CLIN PHARMACOL, V43, P211, DOI 10.1177/0091270002250613	26	16	16	KLUWER ACADEMIC/PLENUM PUBL	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0724-8741			PHARM RES	Pharm. Res.	APR	2004	21	4					574	584		10.1023/B:PHAM.0000022403.60314.51		11	Chemistry, Multidisciplinary; Pharmacology & Pharmacy	Chemistry; Pharmacology & Pharmacy	808YE	WOS:000220603600003	15139513	
J	Ghosh, AK; Chaudhuri, P				Ghosh, AK; Chaudhuri, P			Optimal smoothing in kernel discriminant analysis	STATISTICA SINICA			English	Article						average misclassification probability; bandwidth selection; Bayes' risk; cross-validation techniques; location-shift models; scale space; spherical symmetry	SQUARES CROSS-VALIDATION; DENSITY-ESTIMATION; BANDWIDTH SELECTION; CLASSIFICATION TREES; ERROR RATES; ESTIMATORS; REGRESSION; CURVES	One well-known use of kernel density estimates is in nonparametric discriminant analysis, and its popularity is evident in its implementation in some commonly used statistical softwares (e.g., SAS). In this paper, we make a critical investigation into the influence of the value of the bandwidth on the behavior of the average misclassification probability of a classifier that is based on kernel density estimates. In the course of this investigation, we have observed some counter-intuitive results. For instance, the use of bandwidths that minimize mean integrated square errors of kernel estimates of population densities may lead to rather poor average misclassification rates. Further, the best choice of smoothing parameters in classification problems not only depends on the underlying true densities and sample sizes but also on prior probabilities. In particular, if the prior probabilities are all equal, the behavior of the average misclassification probability turns out to be quite interesting when both the sample sizes and the bandwidths are large. Our theoretical analysis provides some new insights into the problem of smoothing in nonparametric discriminant analysis. We also observe that popular cross-validation techniques (e.g., leave-one-out or V-fold) may not be very effective for selecting the bandwidth in practice. As a by-product of our investigation, we present a method for choosing appropriate values of the bandwidths when kernel density estimates are fitted to the training sample in a classification problem. The performance of the proposed method has been demonstrated using some simulation experiments as well as analysis of benchmark data sets, and its asymptotic properties have been studied under some regularity conditions.	Indian Stat Inst, Theoret Stat & Math Unit, Kolkata 700108, W Bengal, India	Ghosh, AK (reprint author), Indian Stat Inst, Theoret Stat & Math Unit, 203,BT Rd, Kolkata 700108, W Bengal, India.	res9812@isical.ac.in; probal@isical.ac.in					AEBERHARD S, 1994, PATTERN RECOGN, V27, P1065, DOI 10.1016/0031-3203(94)90145-7; Anderson T. W., 1984, INTRO MULTIVARIATE S; BENSMAIL H, 2002, IN PRESS MODEL BASED; Bhattacharya R.N., 1976, NORMAL APPROXIMATION; Bose S, 1996, COMPUT STAT DATA AN, V22, P505, DOI 10.1016/0167-9473(96)00009-6; Breiman L., 1984, CLASSIFICATION REGRE; Chaudhuri P, 1999, J AM STAT ASSOC, V94, P807, DOI 10.2307/2669996; Chaudhuri P, 2000, ANN STAT, V28, P408; Cooley CA, 1998, BIOMETRIKA, V85, P823, DOI 10.1093/biomet/85.4.823; Coomans D., 1986, POTENTIAL PATTERN RE; Dasarathy B.V., 1991, NEAREST NEIGHBOR NN; Duda R. O., 2000, PATTERN CLASSIFICATI; Efron B., 1982, JACKKNIFE BOOTSTRAP; EFRON B, 1993, ITNRO BOOTSTRAP; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fukunaga K, 1990, INTRO STAT PATTERN R; HALL P, 1987, PROBAB THEORY REL, V74, P567, DOI 10.1007/BF00363516; HALL P, 1983, ANN STAT, V11, P1156; HALL P, 1988, BIOMETRIKA, V75, P541, DOI 10.1093/biomet/75.3.541; HALL P, 1991, BIOMETRIKA, V78, P263; Hand D, 1982, KERNEL DISCRIMINANT; Hastie T., 2001, ELEMENTS STAT LEARNI; HASTIE T, 1994, J AM STAT ASSOC, V89, P1255, DOI 10.2307/2290989; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; HILLS M, 1966, J ROY STAT SOC B, V28, P1; James M., 1985, CLASSIFICATION ALGOR; Jones MC, 1996, COMPUTATION STAT, V11, P337; Jones MC, 1996, J AM STAT ASSOC, V91, P401, DOI 10.2307/2291420; Kim H, 2001, J AM STAT ASSOC, V96, P589, DOI 10.1198/016214501753168271; Kooperberg C, 1997, J AM STAT ASSOC, V92, P117, DOI 10.2307/2291455; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; Loh WY, 1997, STAT SINICA, V7, P815; LOH WY, 1988, J AM STAT ASSOC, V83, P715, DOI 10.2307/2289295; Mardia KV, 1979, MULTIVARIATE ANAL; McLachlan G., 1992, DISCRIMINANT ANAL ST; MOSTELLER F, 1963, J AM STAT ASSOC, V58, P275, DOI 10.2307/2283270; MULLER HG, 1984, ANN STAT, V12, P766, DOI 10.1214/aos/1176346523; Rao C R, 1973, LINEAR STAT INFERENC; Ripley BD, 1996, PATTERN RECOGNITION; Scott D. W., 1992, MULTIVARIATE DENSITY; SHEATHER SJ, 1991, J ROY STAT SOC B MET, V53, P683; SILVERMAN BW, 1986, DENSTIY ESTIMATION S; STONE CJ, 1984, ANN STAT, V12, P1285, DOI 10.1214/aos/1176346792; Wand MP, 1995, KERNEL SMOOTHING	44	14	14	STATISTICA SINICA	TAIPEI	C/O DR H C HO, INST STATISTICAL SCIENCE, ACADEMIA SINICA, TAIPEI 115, TAIWAN	1017-0405	1996-8507		STAT SINICA	Stat. Sin.	APR	2004	14	2					457	483				27	Statistics & Probability	Mathematics	817JG	WOS:000221173200008		
J	Hsieh, WW				Hsieh, WW			Nonlinear multivariate and time series analysis by neural network methods	REVIEWS OF GEOPHYSICS			English	Review						neural networks; principal component analysis; canonical correlation analysis; singular spectrum analysis; El Nino	CANONICAL CORRELATION-ANALYSIS; PRINCIPAL COMPONENT ANALYSIS; QUASI-BIENNIAL OSCILLATION; TROPICAL STRATOSPHERIC WIND; SINGULAR SPECTRUM ANALYSIS; SEA-SURFACE TEMPERATURE; EL-NINO; VARIABILITY; PACIFIC; CIRCULATION	Methods in multivariate statistical analysis are essential for working with large amounts of geophysical data, data from observational arrays, from satellites, or from numerical model output. In classical multivariate statistical analysis, there is a hierarchy of methods, starting with linear regression at the base, followed by principal component analysis (PCA) and finally canonical correlation analysis (CCA). A multivariate time series method, the singular spectrum analysis (SSA), has been a fruitful extension of the PCA technique. The common drawback of these classical methods is that only linear structures can be correctly extracted from the data. Since the late 1980s, neural network methods have become popular for performing nonlinear regression and classification. More recently, neural network methods have been extended to perform nonlinear PCA (NLPCA), nonlinear CCA (NLCCA), and nonlinear SSA (NLSSA). This paper presents a unified view of the NLPCA, NLCCA, and NLSSA techniques and their applications to various data sets of the atmosphere and the ocean ( especially for the El Nino-Southern Oscillation and the stratospheric quasi-biennial oscillation). These data sets reveal that the linear methods are often too simplistic to describe real-world systems, with a tendency to scatter a single oscillatory phenomenon into numerous unphysical modes or higher harmonics, which can be largely alleviated in the new nonlinear paradigm.	Univ British Columbia, Dept Earth & Ocean Sci, Vancouver, BC V6T 1Z4, Canada	Hsieh, WW (reprint author), Univ British Columbia, Dept Earth & Ocean Sci, 6339 Stores Rd, Vancouver, BC V6T 1Z4, Canada.	whsieh@eos.ubc.ca	Hsieh, William/G-8380-2011	Hsieh, William/0000-0003-2654-392X			Aires F, 2000, J GEOPHYS RES-ATMOS, V105, P17437, DOI 10.1029/2000JD900152; Baldwin MP, 2001, REV GEOPHYS, V39, P179, DOI 10.1029/1999RG000073; BARNETT TP, 1987, MON WEATHER REV, V115, P1825, DOI 10.1175/1520-0493(1987)115<1825:OALOMA>2.0.CO;2; BARNSTON AG, 1992, J CLIMATE, V5, P1316, DOI 10.1175/1520-0442(1992)005<1316:POEEUC>2.0.CO;2; BISHOP C.M., 1995, NEURAL NETWORKS PATT; BRETHERTON CS, 1992, J CLIMATE, V5, P541, DOI 10.1175/1520-0442(1992)005<0541:AIOMFF>2.0.CO;2; Burnham K. P., 1998, MODEL SELECTION INFE; Cavazos T, 1999, J CLIMATE, V12, P1506, DOI 10.1175/1520-0442(1999)012<1506:LSCACT>2.0.CO;2; Cherkassky V., 1998, LEARNING DATA; Chevallier F, 2000, Q J ROY METEOR SOC, V126, P761, DOI 10.1256/smsqj.56317; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; Del Frate F, 1999, IEEE T GEOSCI REMOTE, V37, P2335, DOI 10.1109/36.789630; Diaz H.F., 2000, EL NINO SO OSCILLATI; ELSNER JB, 1996, SINGULAR SPECTRUM AN; Essenreiter R, 2001, GEOPHYS PROSPECT, V49, P341, DOI 10.1046/j.1365-2478.2001.00261.x; Gardner MW, 1998, ATMOS ENVIRON, V32, P2627, DOI 10.1016/S1352-2310(97)00447-0; Gemmill WH, 1999, WEATHER FORECAST, V14, P789, DOI 10.1175/1520-0434(1999)014<0789:TUOSID>2.0.CO;2; Ghil M, 2002, REV GEOPHYS, V40, DOI 10.1029/2000RG000092; Golyandina N., 2001, ANAL TIME SERIES STR; Hamilton K, 2002, J GEOPHYS RES-ATMOS, V107, DOI 10.1029/2001JD001250; Hamilton K, 1998, ATMOS OCEAN, V36, P319; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; Hastie T., 2001, ELEMENTS STAT LEARNI; Haykin S., 1999, NEURAL NETWORKS COMP; Hoerling MP, 1997, J CLIMATE, V10, P1769, DOI 10.1175/1520-0442(1997)010<1769:ENOLNA>2.0.CO;2; Hollingsworth JL, 1997, ADV SPACE RES, V19, P1237, DOI 10.1016/S0273-1177(97)00275-5; HOLTON JR, 1980, J ATMOS SCI, V37, P2200, DOI 10.1175/1520-0469(1980)037<2200:TIOTEQ>2.0.CO;2; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Hsieh WW, 2000, NEURAL NETWORKS, V13, P1095, DOI 10.1016/S0893-6080(00)00067-8; Hsieh WW, 2003, Q J ROY METEOR SOC, V129, P2367, DOI 10.1256/qj.01.158; Hsieh WW, 1998, B AM METEOROL SOC, V79, P1855, DOI 10.1175/1520-0477(1998)079<1855:ANNMTP>2.0.CO;2; Hsieh WW, 2001, J CLIMATE, V14, P2528, DOI 10.1175/1520-0442(2001)014<2528:NCCAOT>2.0.CO;2; Hsieh WW, 2001, TELLUS A, V53, P599, DOI 10.1034/j.1600-0870.2001.00251.x; Hsieh WW, 2002, J GEOPHYS RES-OCEANS, V107, DOI 10.1029/2001JC000957; Hyvarinen A, 2001, INDEPENDENT COMPONEN; Jolliffe I., 2002, PRINCIPAL COMPONENT; KAISER HF, 1958, PSYCHOMETRIKA, V23, P187, DOI 10.1007/BF02289233; Kirby MJ, 1996, NEURAL COMPUT, V8, P390, DOI 10.1162/neco.1996.8.2.390; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Kohonen T., 2001, SELF ORG MAPS; KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209; KRASNOPOLSKY VM, 2000, P 2 C ART INT AMS LO, P27; Lai P L, 2000, Int J Neural Syst, V10, P365, DOI 10.1016/S0129-0657(00)00034-X; Lai PL, 1999, NEURAL NETWORKS, V12, P1391, DOI 10.1016/S0893-6080(99)00075-1; LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2; Malthouse EC, 1998, IEEE T NEURAL NETWOR, V9, P165, DOI 10.1109/72.655038; Mardia K. V., 1979, MUTLIVARIATE ANAL; Marzban C, 2000, NEURAL COMPUT APPL, V9, P133, DOI 10.1007/s005210070024; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; Melzer T, 2003, PATTERN RECOGN, V36, P1961, DOI 10.1016/S0031-3203(03)00058-X; Monahan AH, 2000, J CLIMATE, V13, P821, DOI 10.1175/1520-0442(2000)013<0821:NPCABN>2.0.CO;2; Monahan AH, 2001, J CLIMATE, V14, P219, DOI 10.1175/1520-0442(2001)013<0219:NPCATI>2.0.CO;2; Monahan AH, 2001, GEOPHYS RES LETT, V28, P1019, DOI 10.1029/2000GL012069; Monahan AH, 2000, GEOPHYS RES LETT, V27, P1139, DOI 10.1029/1999GL011111; NEWBIGGING SC, 2003, ATMOS OCEAN, V41, P291, DOI 10.3137/ao.410403; PHILANDER SG, 1990, EL NINO LA NINA SO O; Preisendorfer R.W., 1988, PRINCIPAL COMPONENT; Rangarajan GK, 2000, EARTH PLANETS SPACE, V52, P121; Richaume P, 2000, J GEOPHYS RES-OCEANS, V105, P8737, DOI 10.1029/1999JC900225; RICHMAN MB, 1986, J CLIMATOL, V6, P293; Ripley BD, 1996, PATTERN RECOGNITION; Rojas R., 1996, NEURAL NETWORKS SYST; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Sandham W, 2003, GEOPHYS APPL ARTIFIC; Shabbar A, 1996, MON WEATHER REV, V124, P2370, DOI 10.1175/1520-0493(1996)124<2370:SOSCFI>2.0.CO;2; Taner MT, 2001, J PETROL GEOL, V24, P405, DOI 10.1111/j.1747-5457.2001.tb00683.x; Tang BY, 2000, J CLIMATE, V13, P287, DOI 10.1175/1520-0442(2000)013<0287:SCBNNA>2.0.CO;2; Tang Y, 2002, CLIM DYNAM, V19, P343, DOI 10.1007/s00382-002-0231-2; Tang YM, 2003, J GEOPHYS RES-OCEANS, V108, DOI 10.1029/2001JC001236; Vapnik V., 1998, STAT LEARNING THEORY; Villmann T, 2003, NEURAL NETWORKS, V16, P389, DOI 10.1016/S0893-6080(03)00021-2; von Storch H, 1999, STAT ANAL CLIMATE RE; Watari S, 1996, SOL PHYS, V168, P413, DOI 10.1007/BF00148065; WOODRUFF SD, 1987, B AM METEOROL SOC, V68, P1239, DOI 10.1175/1520-0477(1987)068<1239:ACOADS>2.0.CO;2; Wu A, 2002, J GEOPHYS RES-ATMOS, V107, DOI 10.1029/2001JD001090; Wu A, 2002, CLIM DYNAM, V19, P713, DOI 10.1007/s00382-002-0262-8; Wu A, 2003, CLIM DYNAM, V21, P719, DOI 10.1007/s00382-003-0361-1; Wu AM, 2003, J CLIMATE, V16, P2325, DOI 10.1175/2776.1; Yacoub M, 2001, LECT NOTES COMPUT SC, V2130, P492; Yuval, 2001, J CLIMATE, V14, P2150, DOI 10.1175/1520-0442(2001)014<2150:EAEEON>2.0.CO;2; Yuval, 2000, MON WEATHER REV, V128, P1456, DOI 10.1175/1520-0493(2000)128<1456:NNTFPO>2.0.CO;2; Yuval, 2002, Q J ROY METEOR SOC, V128, P1609, DOI 10.1256/00359000260247381; Yuval, 2003, WEATHER FORECAST, V18, P303, DOI 10.1175/1520-0434(2003)018<0303:AANMSF>2.0.CO;2	84	56	58	AMER GEOPHYSICAL UNION	WASHINGTON	2000 FLORIDA AVE NW, WASHINGTON, DC 20009 USA	8755-1209			REV GEOPHYS	Rev. Geophys.	MAR 18	2004	42	1							RG1003	10.1029/2002RG000112		25	Geochemistry & Geophysics	Geochemistry & Geophysics	806NS	WOS:000220441200001		
J	Wagner, M; Naik, DN; Pothen, A; Kasukurti, S; Devineni, RR; Adam, BL; Semmes, OJ; Wright, GL				Wagner, M; Naik, DN; Pothen, A; Kasukurti, S; Devineni, RR; Adam, BL; Semmes, OJ; Wright, GL			Computational protein biomarker prediction: a case study for prostate cancer	BMC BIOINFORMATICS			English	Article							DISEASE CLASSIFICATION; MASS-SPECTROMETRY; OVARIAN-CANCER; SERUM; IDENTIFICATION; PATTERNS	Background: Recent technological advances in mass spectrometry pose challenges in computational mathematics and statistics to process the mass spectral data into predictive models with clinical and biological significance. We discuss several classification-based approaches to finding protein biomarker candidates using protein profiles obtained via mass spectrometry, and we assess their statistical significance. Our overall goal is to implicate peaks that have a high likelihood of being biologically linked to a given disease state, and thus to narrow the search for biomarker candidates. Results: Thorough cross-validation studies and randomization tests are performed on a prostate cancer dataset with over 300 patients, obtained at the Eastern Virginia Medical School using SELDI-TOF mass spectrometry. We obtain average classification accuracies of 87% on a four-group classification problem using a two-stage linear SVM-based procedure and just 13 peaks, with other methods performing comparably. Conclusions: Modern feature selection and classification methods are powerful techniques for both the identification of biomarker candidates and the related problem of building predictive models from protein mass spectrometric profiles. Cross-validation and randomization are essential tools that must be performed carefully in order not to bias the results unfairly. However, only a biological validation and identification of the underlying proteins will ultimately confirm the actual value and power of any computational predictions.	Cincinnati Childrens Hosp Res Fdn, Cincinnati, OH 45229 USA; Univ Cincinnati, Dept Biomed Engn, Cincinnati, OH 45229 USA; Old Dominion Univ, Dept Math & Stat, Norfolk, VA 23529 USA; Old Dominion Univ, Dept Comp Sci, Norfolk, VA 23529 USA; Eastern Virginia Med Sch, Dept Microbiol & Cell Biol, Norfolk, VA 23507 USA	Wagner, M (reprint author), Cincinnati Childrens Hosp Res Fdn, Cincinnati, OH 45229 USA.	mwagner@cchmc.org; dnaik@odu.edu; pothen@cs.odu.edu; skasukur@cs.odu.edu; devin_r@cs.odu.edu; adambl@evms.edu; semmesoj@evms.edu; wrightgl@evms.edu	Wagner, Michael/A-4649-2011				Adam BL, 2002, CANCER RES, V62, P3609; Cristianini N, 2000, INTRO SUPPORT VECTOR; Hastie T., 2001, ELEMENTS STAT LEARNI; Howard BA, 2003, PROTEOMICS, V3, P1720, DOI 10.1002/pmic.200300514; KHATTREE R., 2000, MULTIVARIATE DATA RE; Lee Y, 2001, COMPUTING SCI STAT, V33, P498; Li JN, 2002, CLIN CHEM, V48, P1296; Lilien RH, 2003, J COMPUT BIOL, V10, P925, DOI 10.1089/106652703322756159; MANGASAR.OL, 1965, OPER RES, V13, P444, DOI 10.1287/opre.13.3.444; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Qu YS, 2002, CLIN CHEM, V48, P1835; RIFKIN R, SVMFU; Sorace JM, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-24; Wagner M, 2003, PROTEOMICS, V3, P1692, DOI 10.1002/pmic.200300519	14	53	61	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	MAR 11	2004	5								26	10.1186/1471-2105-5-26		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	820RR	WOS:000221407500001	15113409	
J	Sorensen, JVT; Madsen, H; Madsen, H				Sorensen, JVT; Madsen, H; Madsen, H			Efficient Kalman filter techniques for the assimilation of tide gauge data in three-dimensional modeling of the North Sea and Baltic Sea system	JOURNAL OF GEOPHYSICAL RESEARCH-OCEANS			English	Article						tide gauge; data assimilation; North Sea; Baltic Sea	OCEANOGRAPHY	Data assimilation in operational forecasting systems is a discipline undergoing rapid development. Despite the ever increasing computational resources, it requires efficient as well as robust assimilation schemes to support online prediction products. The parameter considered for assimilation here is water levels from tide gauge stations. The assimilation approach is Kalman filter based and examines the combination of the Ensemble Kalman Filter with spatial and dynamic regularization techniques. Further, both a Steady Kalman gain approximation and a dynamically evolving Kalman gain are considered. The estimation skill of the various assimilation schemes is assessed in a 4-week hindcast experiment using a setup of an operational model in the North Sea and Baltic Sea system. The computationally efficient dynamic regularization works very well and is to be encouraged for water level nowcasts. Distance regularization gives much improved results in data sparse areas, while maintaining performance in areas with a denser distribution of tide gauges.	DHI Water & Environm, DK-2970 Horsholm, Denmark; Tech Univ Denmark, Kongens Lyngby, Denmark	Sorensen, JVT (reprint author), DHI Water & Environm, Agern Alle 11, DK-2970 Horsholm, Denmark.	jts@dhi.dk; jts@dhi.dk; hm@imm.dtu.dk					BAHUREL P, 2002, INT S ROUT GODAE CEN; Bertino L, 2002, INVERSE PROBL, V18, P1, DOI 10.1088/0266-5611/18/1/301; Burgers G, 1998, MON WEATHER REV, V126, P1719, DOI 10.1175/1520-0493(1998)126<1719:ASITEK>2.0.CO;2; Canizares R, 2001, ESTUAR COAST SHELF S, V53, P595, DOI 10.1006/ecss.1999.0629; CHUI CK, 1991, KALMAN FILTER REAL T; DEE DP, 1995, MON WEATHER REV, V123, P1128, DOI 10.1175/1520-0493(1995)123<1128:OLEOEC>2.0.CO;2; DEE DP, 1991, Q J ROY METEOR SOC, V117, P365; DHI, 2001, MIKE 3 EST COAST HYD; *DHI, 2002, MIKE 21 COAST HYDR O; ERICHSEN AC, 2002, P 7 INT C EST COAST, P165; EVENSEN G, 1994, J GEOPHYS RES-OCEANS, V99, P10143, DOI 10.1029/94JC00572; Evensen G., 2003, OCEAN DYNAM, V53, P343, DOI [10.1007/s10236-003-0036-9, DOI 10.1007/S10236-003-0036-9]; Fukumori I, 1999, J GEOPHYS RES-OCEANS, V104, P25647, DOI 10.1029/1999JC900193; FUKUMORI I, 1995, J GEOPHYS RES-OCEANS, V100, P6777, DOI 10.1029/94JC03084; Gerritsen H, 1995, COASTAL ESTUARINE ST, V47, P425, DOI 10.1029/CE047p0425; Hamill TM, 2001, MON WEATHER REV, V129, P2776, DOI 10.1175/1520-0493(2001)129<2776:DDFOBE>2.0.CO;2; Hastie T., 2001, ELEMENTS STAT LEARNI; HEEMINK AW, 1990, INT J NUMER METH FL, V11, P1097, DOI 10.1002/fld.1650110804; Houtekamer PL, 1998, MON WEATHER REV, V126, P796, DOI 10.1175/1520-0493(1998)126<0796:DAUAEK>2.0.CO;2; Ide K, 1997, J METEOROL SOC JPN, V75, P181; Jazwinski A. H., 1970, STOCHASTIC PROCESSES; Madsen H, 1999, INT J NUMER METH FL, V31, P961, DOI 10.1002/(SICI)1097-0363(19991130)31:6<961::AID-FLD907>3.3.CO;2-S; Pham DT, 1998, CR ACAD SCI II A, V326, P255, DOI 10.1016/S1251-8050(97)86815-2; Pham DT, 1998, J MARINE SYST, V16, P323; Pinardi N, 2002, OCEAN FORECASTING CO; PINARDI N, 2002, OCEAN FORECASTING CO, P339; ROGERS E, 2001, NWS TECH PROCEDURES, V488; SORENSEN JVT, 2004, IN PRESS STOCHASTIC; SORENSEN JVT, 2004, IN PRESS OCEAN MODEL; SORENSEN JVT, 2002, P 5 INT C HYDR, V2, P1204; Verlaan M, 1997, STOCH HYDROL HYDRAUL, V11, P349, DOI 10.1007/BF02427924; Vested HJ, 1995, COASTAL ESTUARINE ST, V47, P373	32	12	12	AMER GEOPHYSICAL UNION	WASHINGTON	2000 FLORIDA AVE NW, WASHINGTON, DC 20009 USA	2169-9275	2169-9291		J GEOPHYS RES-OCEANS	J. Geophys. Res.-Oceans	MAR 10	2004	109	C3							C03017	10.1029/2003JC002144		14	Oceanography	Oceanography	806KT	WOS:000220433500001		
J	Lucas, PJF; van der Gaag, LC; Abu-Hanna, A				Lucas, PJF; van der Gaag, LC; Abu-Hanna, A			Bayesian networks in biomedicine and health-care	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Editorial Material							NORMATIVE EXPERT SYSTEMS; PROBABILISTIC NETWORKS; BELIEF-NETWORK; MANAGEMENT; CANCER; ISSUES		Catholic Univ Nijmegen, Inst Comp & Informat Sci, NL-6525 ED Nijmegen, Netherlands; Univ Utrecht, Inst Comp & Informat Sci, Utrecht, Netherlands; Univ Amsterdam, Acad Med Ctr, Dept Med Informat, NL-1105 AZ Amsterdam, Netherlands	Lucas, PJF (reprint author), Catholic Univ Nijmegen, Inst Comp & Informat Sci, Toernooiveld 1, NL-6525 ED Nijmegen, Netherlands.	peterl@cs.kun.nl; l.c.vandergaag@cs.uu.nl; a.abu-hanna@amc.uva.nl	Lucas, Peter/D-1708-2012				Andreassen S., 1987, P 10 INT JOINT C ART, P366; Andreassen S, 1999, ARTIF INTELL MED, V15, P121, DOI 10.1016/S0933-3657(98)00048-7; Andreassen S., 1992, Artificial Intelligence in Medicine, V4, DOI 10.1016/0933-3657(92)90029-O; Cheng J., 1997, P 6 ACM INT C INF KN, P325, DOI 10.1145/266714.266920; Cheng J., 1999, P 15 C UNC ART INT U, P101; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; Coupe VMH, 2000, KNOWL ENG REV, V15, P215, DOI 10.1017/S0269888900003027; Cowell R.G., 1999, PROBABILISTIC NETWOR; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Galan SF, 2001, LECT NOTES ARTIF INT, V2101, P207; Glymour CN, 1999, COMPUTATION CAUSATIO; Hastie T., 2001, ELEMENTS STAT LEARNI; HECKERMAN DE, 1992, METHOD INFORM MED, V31, P90; HECKERMAN DE, 1992, METHOD INFORM MED, V31, P106; HELSPER EM, 2002, P 15 EUR C ART INT, P680; KORVER M, 1993, MED INFORM, V18, P219; Lam W., 1994, COMPUT INTELL, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x; Larranaga P, 1996, IEEE T PATTERN ANAL, V18, P912, DOI 10.1109/34.537345; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; LAURITZEN SL, 1992, J AM STAT ASSOC, V87, P1098, DOI 10.2307/2290647; LUCAS P, 2002, P 1 EUR WORKSH PROB, P117; Lucas P.J.F., 1996, AISB Q, V94, P23; Lucas PJF, 1998, METHOD INFORM MED, V37, P206; Lucas PJF, 2000, ARTIF INTELL MED, V19, P251, DOI 10.1016/S0933-3657(00)00048-8; Pearl J., 1988, PROBABILISTIC REASON; Ramoni M, 2002, MACH LEARN, V47, P91, DOI 10.1023/A:1013635829250; Renooij S., 2002, P 18 C UNC ART INT, P422; Renooij S, 2001, KNOWL ENG REV, V16, P255, DOI 10.1017/S0269888901000145; SHACHTER RD, 1986, OPER RES, V34, P871, DOI 10.1287/opre.34.6.871; van der Gaag L., 1999, P 15 C UNC ART INT, P647; van der Gaag L. C., 2001, P 17 C UNC ART INT, P530; van der Gaag LC, 2002, ARTIF INTELL MED, V25, P123, DOI 10.1016/S0933-3657(02)00012-X; van der Gaag LC, 2002, LECT NOTES ARTIF INT, V2473, P21; VANDIJK S, 2003, P GEN EV COMP C, P886; WONG ML, 2002, P GEN EV COMP C, P214	38	60	61	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657			ARTIF INTELL MED	Artif. Intell. Med.	MAR	2004	30	3					201	214		10.1016/j.artmed.2003.11.001		14	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	810CC	WOS:000220681400001	15081072	
J	Gardner, TS; Shimer, S; Collins, JJ				Gardner, TS; Shimer, S; Collins, JJ			Inferring microbial genetic networks	ASM NEWS			English	Article							ESCHERICHIA-COLI		Boston Univ, Dept Biomed Engn, Boston, MA 02215 USA; Cellicon Biotechnol Inc, Boston, MA USA	Gardner, TS (reprint author), Boston Univ, Dept Biomed Engn, Boston, MA 02215 USA.						Cheung KJ, 2003, GENOME RES, V13, P206, DOI 10.1101/gr.401003; Courcelle J, 2001, GENETICS, V158, P41; Gardner TS, 2003, SCIENCE, V301, P102, DOI 10.1126/science.1081900; Hastie T., 2001, ELEMENTS STAT LEARNI; Lee TI, 2002, SCIENCE, V298, P799, DOI 10.1126/science.1075090; Lewis K, 2001, ANTIMICROB AGENTS CH, V45, P999, DOI 10.1128/AAC.45.4.999-1007.2001; Liang S, 1998, PAC S BIOCOMPUT, V3, P18; LOVLEY DR, 1991, NATURE, V350, P413, DOI 10.1038/350413a0; Weng GZ, 1999, SCIENCE, V284, P92, DOI 10.1126/science.284.5411.92	9	4	4	AMER SOC MICROBIOLOGY	WASHINGTON	1752 N ST NW, WASHINGTON, DC 20036-2904 USA	0044-7897			ASM NEWS	ASM News	MAR	2004	70	3					121	126				6	Microbiology	Microbiology	802KH	WOS:000220161900013		
J	Yasui, Y; Pepe, M; Hsu, L; Adam, BL; Feng, ZD				Yasui, Y; Pepe, M; Hsu, L; Adam, BL; Feng, ZD			Partially supervised learning using an EM-boosting algorithm	BIOMETRICS			English	Article						high-dimensional data; misclassification; proteomics	CONTAIN MISCLASSIFICATION ERRORS; PROSTATE-CANCER; LOGISTIC-REGRESSION; RESPONSES; BIAS	Training data in a supervised learning problem consist of the class label and its potential predictors for a set of observations. Constructing effective classifiers from training data is the goal of supervised learning. In biomedical sciences and other scientific applications, class labels may be subject to errors. We consider a setting where there are two classes but observations with labels corresponding to one of the classes may in fact be mislabeled. The application concerns the use of protein mass-spectrometry data to discriminate between serum samples from cancer and noncancer patients. The patients in the training set are classified on the basis of tissue biopsy. Although biopsy is 100% specific in the sense that a tissue that shows itself to have malignant cells is certainly cancer, it is less than 100% sensitive. Reference gold standards that are subject to this special type of misclassification due to imperfect diagnosis certainty arise in many fields. We consider the development of a supervised learning algorithm under these conditions and refer to it as partially supervised learning. Boosting is a supervised learning algorithm geared toward high-dimensional predictor data, such as those generated in protein mass-spectrometry. We propose a modification of the boosting algorithm for partially supervised learning. The proposal is to view the true class membership of the samples that are labeled with the error-prone class label as missing data, and apply an algorithm related to the EM algorithm for minimization of a loss function. To assess the usefulness of the proposed method, we artificially mislabeled a subset of samples and applied the original and EM-modified boosting (EM-Boost) algorithms for comparison. Notable improvements in misclassification rates are observed with EM-Boost.	Fred Hutchinson Canc Res Ctr, Div Publ Hlth Sci, Seattle, WA 98109 USA; Univ Washington, Dept Biostat, Seattle, WA 98195 USA; Med Coll Georgia, Ctr Biotechnol & Genom Med, Augusta, GA 30912 USA	Yasui, Y (reprint author), Fred Hutchinson Canc Res Ctr, Div Publ Hlth Sci, Seattle, WA 98109 USA.	yyasui@fhcrc.org					Adam BL, 2002, CANCER RES, V62, P3609; BRENNER H, 1993, AM J EPIDEMIOL, V138, P1007; CHEN TT, 1992, STAT MED, V7, P1095; CHU CK, 1995, BIOMETRIKA, V82, P315; COPELAND KT, 1977, AM J EPIDEMIOL, V105, P488; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Djavan B, 2001, PROSTATE, V47, P111; EKHOLM A, 1991, BIOMETRICS, V47, P1171, DOI 10.2307/2532670; ESPELAND MA, 1987, BIOMETRICS, V43, P1001, DOI 10.2307/2531553; Fisher RA, 1936, ANN EUGENIC, V7, P179; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; GREEN DM, 1966, SIGNAL DETECTION THE; Hastie T., 2001, ELEMENTS STAT LEARNI; Magder LS, 1997, AM J EPIDEMIOL, V146, P195; QUADE D, 1980, AM J EPIDEMIOL, V111, P503; MCLACHLIN JJ, 1992, DISCRIMINANT ANAL ST; Neuhaus JM, 1999, BIOMETRIKA, V86, P843, DOI 10.1093/biomet/86.4.843; Pepe MS, 2001, J NATL CANCER I, V93, P1054, DOI 10.1093/jnci/93.14.1054; Prescott GJ, 2002, BIOMETRICS, V58, P454, DOI 10.1111/j.0006-341X.2002.00454.x; Qu YS, 2002, CLIN CHEM, V48, P1835; Srivastava S, 2000, LAB INVEST, V80, P1147, DOI 10.1038/labinvest.3780122; Wang CY, 2000, J ROY STAT SOC B, V62, P509, DOI 10.1111/1467-9868.00247; WHITE E, 1986, AM J EPIDEMIOL, V124, P816; Yasui Y, 2003, BIOSTATISTICS, V4, P449, DOI 10.1093/biostatistics/4.3.449; Yasui Y, 2003, J BIOMED BIOTECHNOL, P242	26	9	10	BLACKWELL PUBLISHING LTD	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DG, OXON, ENGLAND	0006-341X			BIOMETRICS	Biometrics	MAR	2004	60	1					199	206		10.1111/j.0006-341X.2004.00156.x		8	Biology; Mathematical & Computational Biology; Statistics & Probability	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology; Mathematics	805RW	WOS:000220384400024	15032790	
J	Tuv, E; Runger, GC				Tuv, E; Runger, GC			Scoring levels of categorical variables with heterogeneous data	IEEE INTELLIGENT SYSTEMS			English	Article									Intel Corp, Anal & Control Technol, Chandler, AZ 85226 USA; Arizona State Univ, Tempe, AZ 85287 USA	Tuv, E (reprint author), Intel Corp, Anal & Control Technol, CH5-255,5000 W Chandler Blvd, Chandler, AZ 85226 USA.	eugene.tuv@intel.com; runger@asu.edu					Benzecri J.-P., 1992, CORRESPONDENCE ANAL; Breiman L., 1984, CLASSIFICATION REGRE; Friedman J, 1999, STOCHASTIC GRADIENT; Friedman JH, 1999, GREEDY FUNCTION APPR; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Greenacre MJ, 1984, THEORY APPL CORRESPO; Hastie T., 2001, ELEMENTS STAT LEARNI; Kaufman L., 1990, FINDING GROUPS DATA; Michailidis G, 1998, STAT SCI, V13, P307; Nishisato S., 1993, ELEMENTS DUAL SCALIN; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; YOUNG FW, 1978, PSYCHOMETRIKA, V43, P279, DOI 10.1007/BF02293871	12	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1094-7167			IEEE INTELL SYST	IEEE Intell. Syst.	MAR-APR	2004	19	2					14	19		10.1109/MIS.2004.1274906		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	806SH	WOS:000220453100005		
J	Feng, CXJ; Wang, XFD				Feng, CXJ; Wang, XFD			Data mining techniques applied to predictive modeling of the knurling process	IIE TRANSACTIONS			English	Article							NEURAL-NETWORKS; REGRESSION; PARAMETERS	Knurls are designed into a product to provide the correct frictional force for easy assembly and maintenance and sometimes for decorative purposes. The literature to date has merely studied how to realize a good and consistent knurl, but no predictive models of the knurling process have been presented. This paper applies two competing data mining techniques, regression analysis and artificial neural networks, to develop a predictive model of the knurling process. Fractional factorial design of experiments is used to plan the experiments. Four criteria, namely the PRESS statistic, the adjusted R-2, the C-p statistic, and the residual mean square s(2), are employed to select the best regression model. Hypothesis testing is conducted to test the effectiveness of each model, and to compare the two data mining schemes. This study demonstrates that for a reasonably large set of data from structurally designed experiments, the two methods produce comparable results in both model construction ( or training) and model validation. Due to the explicit nature of a regression model, it is preferred to a neural network model to investigate the process.	Bradley Univ, Coll Engn & Technol, Dept Ind & Mfg Engn & Technol, Peoria, IL 61625 USA	Feng, CXJ (reprint author), Bradley Univ, Coll Engn & Technol, Dept Ind & Mfg Engn & Technol, Peoria, IL 61625 USA.	cfeng@bradley.edu					Box G., 1987, EMPIRICAL MODEL BUIL; Coit DW, 1998, INT J PROD RES, V36, P2953, DOI 10.1080/002075498192229; Daniel C., 1980, FITTING EQUATIONS DA; Draper NR, 1998, APPL REGRESSION ANAL; FENG CX, 2002, SME J MANUF SYST, V21, P395; FENG CX, 2002, SME J MANUFACTURING, V21, P419; FENG CX, 2003, T NAMRI SME DEARB MI; Feng CX, 2003, IIE TRANS, V35, P11, DOI 10.1080/07408170390116634; Feng CX, 2002, J INTELL MANUF, V13, P189, DOI 10.1023/A:1015734805987; FENG CX, 1999, ASME DE, V103, P15; GROTH R, 1998, DATA MINING HANDS AP; Hastie T., 2001, ELEMENTS STAT LEARNI; Hertz J., 1991, INTRO THEORY NEURAL; HOGG RV, 1992, APPL STAT ENG PHYS S, pCH9; Kusiak A, 2000, IEEE T ELECTRON PA M, V23, P345, DOI 10.1109/6104.895081; Kusiak A, 2001, IEEE T ROBOTIC AUTOM, V17, P191, DOI 10.1109/70.928564; Lawrence J., 1994, INTRO NEURAL NETWORK; Lawrence M, 1998, BRAINMAKER USERS GUI, P95959; LEHMANN EL, 1998, TESTING STAT HYPOTHE; Miller A., 2002, SUBSET SELECTION REG; Montgomery D. C, 2001, INTRO LINEAR REGRESS; Montgomery D. C., 2001, DESIGN ANAL EXPT; Montgomery D.C., 2003, APPL STAT PROBABILIT, V3; Moon HS, 1997, J MANUF SYST, V16, P13, DOI 10.1016/S0278-6125(97)88402-6; Petri KL, 1998, J MANUF SYST, V17, P52, DOI 10.1016/S0278-6125(98)80009-5; Smith A. E., 1997, Engineering Economist, V42, DOI 10.1080/00137919708903174; Twomey JM, 1998, IEEE T SYST MAN CY C, V28, P417, DOI 10.1109/5326.704579; Witten IH, 2000, DATA MINING PRACTICA; Yarlagadda PKDV, 2000, INT J PROD RES, V38, P119, DOI 10.1080/002075400189617; ZHANG HC, 1995, INT J PROD RES, V33, P705, DOI 10.1080/00207549508930175; 2000, MEET MINITAB; 1995, MACHINERYS HDB; 1978, TECHNICAL DATA KNURL; TECHNICAL PUBLICATIO; 1985, FANUC OT MODEL OPERA	35	8	8	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0740-817X			IIE TRANS	IIE Trans.	MAR	2004	36	3					253	263		10.1080/07408170490274214		11	Engineering, Industrial; Operations Research & Management Science	Engineering; Operations Research & Management Science	812FE	WOS:000220824600004		
J	Wold, S; Josefson, M; Gottfries, J; Linusson, A				Wold, S; Josefson, M; Gottfries, J; Linusson, A			The utility of multivariate design in PLS modeling	JOURNAL OF CHEMOMETRICS			English	Article; Proceedings Paper	8th Scandinavian Symposium on Chemometrics	JUN, 2003	Mariehamn, FINLAND			PLS; QSAR; NIR; D-op.; experimental design	STATISTICAL MOLECULAR DESIGN; INHIBITORS	We discuss the use of multivariate design to ensure representativity and balance of the training set data for PLS multivariate modeling. Three application areas are used to illustrate the discussion, namely multivariate calibration in process analytical chemistry, quantitative structure activity relationships QSAR) in medicinal and pharmaceutical chemistry, and data mining. In both QSAR and data mining, the multivariate design is also useful for the balanced sampling of data from a large, complex, and unbalanced data repository. Copyright (C) 2004 John Wiley Sons, Ltd.	Umea Univ, S-90187 Umea, Sweden; Umetr AB, S-90187 Umea, Sweden; AstraZeneca R&D, S-43183 Molndal, Sweden	Wold, S (reprint author), Umea Univ, S-90187 Umea, Sweden.						ANDERSSON M, 2000, ANAL CHIM ACTA, V419, P45; Andersson PM, 1999, MOLECULAR DIVERSITY IN DRUG DESIGN, P197; Box G.E.P., 1978, STAT EXPT; Carlson R., 1992, DESIGN OPTIMIZATION; CHEUNG HS, 1980, J BIOL CHEM, V255, P401; COOK RD, 1980, TECHNOMETRICS, V22, P315; DUMOUCHEL W, 1994, TECHNOMETRICS, V36, P37, DOI 10.2307/1269197; ERIKSSON L, IN PRESS J CHEMOMETR; Gottfries J, 1996, J PHARMACEUT BIOMED, V14, P1495, DOI 10.1016/0731-7085(96)01800-6; Hand D.J., 2000, PRINCIPLES DATA MINI; Hastie T., 2001, ELEMENTS STAT LEARNI; HELLBERG S, 1987, J MED CHEM, V30, P1126, DOI 10.1021/jm00390a003; Linusson A, 2000, J MED CHEM, V43, P1320, DOI 10.1021/jm991118x; Linusson A, 2001, J MED CHEM, V44, P3424, DOI 10.1021/jm010833f; LUNDSTEDT T, 1997, COMPUTER ASSISTED LE, P190; LUNDSTEDT T, 1987, ACTA CHEM SCAND B, V41, P157, DOI 10.3891/acta.chem.scand.41b-0157; Maitra R, 2001, TECHNOMETRICS, V43, P336, DOI 10.1198/004017001316975925; Naes T, 1999, J CHEMOMETR, V13, P435; OLSSON IM, IN PRESS J CHEMOMETR; Oprea TI, 2001, J COMB CHEM, V3, P157, DOI 10.1021/cc0000388; Sandberg M, 1998, J MED CHEM, V41, P2481, DOI 10.1021/jm9700575; WOLD S, 1986, ANAL CHIM ACTA, V191, P17, DOI 10.1016/S0003-2670(00)86294-7	22	23	23	JOHN WILEY & SONS LTD	CHICHESTER	THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND	0886-9383			J CHEMOMETR	J. Chemometr.	MAR-APR	2004	18	3-4					156	165		10.1002/cem.861		10	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	848KV	WOS:000223467300006		
J	Lang, S; Brezger, A				Lang, S; Brezger, A			Bayesian P-splines	JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS			English	Article						geoadditive models; locally adaptive smoothing parameters; MCMC; surface fitting; varying coefficient models	REGRESSION SPLINES; DYNAMIC-MODELS; LINEAR-MODELS; MIXED MODELS; PENALTIES; PRIORS	P-splines are an attractive approach for modeling nonlinear smooth effects of covariates within the additive and varying coefficient models framework. In this article, we first develop a Bayesian version for P-splines and generalize in a second step the approach in various ways. First, the assumption of constant smoothing parameters can be replaced by allowing the smoothing parameters to be locally adaptive. This is particularly useful in situations with changing curvature of the underlying smooth function or with highly oscillating functions. In a second extension, one-dimensional P-splines are generalized to two-dimensional surface fitting for modeling interactions between metrical covariates. In a last step, the approach is extended to situations with spatially correlated responses allowing the estimation of geoadditive models. Inference is fully Bayesian and uses recent MCMC techniques for drawing random samples from the posterior. In a couple of simulation studies the performance of Bayesian P-splines is studied and compared to other approaches in the literature. We illustrate the approach by two complex application on rents for flats in Munich and on human brain mapping.	Univ Munich, Dept Stat, D-80539 Munich, Germany	Lang, S (reprint author), Univ Munich, Dept Stat, Ludwigstr 33, D-80539 Munich, Germany.	lang@stat.uni-muenchen.de; andib@stat.uni-muenchen.de	Lang, Stefan/E-7500-2010	Lang, Stefan/0000-0003-0739-3858			ALBERT JH, 1993, J AM STAT ASSOC, V88, P669, DOI 10.2307/2290350; Besag J, 1995, BIOMETRIKA, V82, P733, DOI 10.1093/biomet/82.4.733; BESAG J, 1991, ANN I STAT MATH, V43, P1, DOI 10.1007/BF00116466; Besag J, 1999, J ROY STAT SOC B, V61, P691, DOI 10.1111/1467-9868.00201; Biller C, 2000, J COMPUT GRAPH STAT, V9, P122, DOI 10.2307/1390616; BREIMAN L, 1985, J AM STAT ASSOC, V80, P580, DOI 10.2307/2288473; CARTER CK, 1994, BIOMETRIKA, V81, P541; CHEN ZH, 1993, J ROY STAT SOC B MET, V55, P473; Clayton D, 1996, MARKOV CHAIN MONTE C, P275; Cleveland W.S., 1991, STAT COMPUT, V1, P47, DOI 10.1007/bf01890836; de Boor C., 1978, PRACTICAL GUIDE SPLI; Denison DGT, 1998, J ROY STAT SOC B, V60, P333, DOI 10.1111/1467-9868.00128; DiMatteo I, 2001, BIOMETRIKA, V88, P1055, DOI 10.1093/biomet/88.4.1055; Eilers PHC, 1996, STAT SCI, V11, P89, DOI 10.1214/ss/1038425655; Fahrmeir L, 2001, ANN I STAT MATH, V53, P11, DOI 10.1023/A:1017904118167; Fahrmeir L, 2001, MULTIVARIATE STAT MO; Fahrmeir L, 2001, J ROY STAT SOC C-APP, V50, P201, DOI 10.1111/1467-9876.00229; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; GEORGE A, 1981, COMPUTER SOLUTION LA; GOSSL C, 2001, BAYESIAN MODELS FUCT; Gossl C, 2000, MAGNET RESON MED, V43, P72; Hansen MH, 2002, STAT SCI, V17, P2, DOI 10.1214/ss/1023798997; Hastie T., 2001, ELEMENTS STAT LEARNI; HASTIE T, 2000, STAT SCI, V15, P193; HASTIE T, 1993, J ROY STAT SOC B MET, V55, P757; Hobert JP, 1996, J AM STAT ASSOC, V91, P1461, DOI 10.2307/2291572; Kammann EE, 2003, J ROY STAT SOC C-APP, V52, P1, DOI 10.1111/1467-9876.00385; Knorr-Held L, 1999, SCAND J STAT, V26, P129, DOI 10.1111/1467-9469.00141; Lange N, 1996, STAT MED, V15, P389, DOI 10.1002/(SICI)1097-0258(19960229)15:4<389::AID-SIM285>3.0.CO;2-J; Luo Z, 1997, J AM STAT ASSOC, V92, P107, DOI 10.2307/2291454; MALLICK B, 2000, GEN LINEAR MODELS BA; Marx BD, 1998, COMPUT STAT DATA AN, V28, P193, DOI 10.1016/S0167-9473(98)00033-4; Rue H, 2001, J ROY STAT SOC B, V63, P325, DOI 10.1111/1467-9868.00288; Ruppert D, 2000, AUST NZ J STAT, V42, P205, DOI 10.1111/1467-842X.00119; Smith M, 1997, J AM STAT ASSOC, V92, P1522, DOI 10.2307/2965423; Smith M, 1996, J ECONOMETRICS, V75, P317, DOI 10.1016/0304-4076(95)01763-1; SPIEGELHALTER D, 2002, IN PRESS J ROYAL S B; Stone CJ, 1997, ANN STAT, V25, P1371; Wand MP, 2000, COMPUTATION STAT, V15, P443, DOI 10.1007/s001800000047; Wood SN, 2000, J ROY STAT SOC B, V62, P413, DOI 10.1111/1467-9868.00240	40	192	192	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	1061-8600			J COMPUT GRAPH STAT	J. Comput. Graph. Stat.	MAR	2004	13	1					183	212		10.1198/1061860043010		30	Statistics & Probability	Mathematics	802RZ	WOS:000220181900011		
J	Chiang, LH; Pell, RJ				Chiang, LH; Pell, RJ			Genetic algorithms combined with discriminant analysis for key variable identification	JOURNAL OF PROCESS CONTROL			English	Article						genetic algorithms; contribution chart; principal component analysis (PCA); Fisher discriminant analysis (FDA); fault identification; variable selection	PRINCIPAL COMPONENT ANALYSIS; FEATURE-SELECTION; REGRESSION; PLS	Many trouble-shooting problems in process industries are related to key variable identification for classifications. The contribution charts, based on principal component analysis (PCA), can be applied for this purpose. Genetic algorithms (GAs) have been proposed recently for many applications including variable selection for multivariate calibration, molecular modeling, regression analysis, model identification, curve fitting, and classification. In this paper, GAs are incorporated with Fisher discriminant analysis (FDA) for key variable identification. GAs are used as an optimization tool to determine variables that maximize the FDA classification success rate for two given data sets. GA/FDA is a proposed solution for the variable selection problem in discriminant analysis. The Tennessee. Eastman process (TEP) simulator was used to generate the data sets to evaluate the correctness of the key variable selection using GA/FDA, and the T-2 and Q statistic contribution charts. GA/FDA correctly identifies the key variables for the TEP case studies that were tested. For one case study where the correlation changes in two data sets, the contribution charts incorrectly suggest that the operating conditions are similar. On the other hand, GA/FDA not only determines that the operating conditions are different, but also identifies the key variables for the change. For another case study where many key variables are responsible for the changes in the two data sets, the contribution charts only identifies a fraction of the key variables, while GA/ FDA correctly identifies all of the key variables. GA/FDA is a promising technique for key variable identification, as is evidenced in successful applications at The Dow Chemical Company. (C) 2003 Elsevier Ltd. All rights reserved.	Dow Chem Co USA, Analyt Sci Lab, Midland, MI 48667 USA	Chiang, LH (reprint author), Dow Chem Co USA, Analyt Sci Lab, 1897 Bldg, Midland, MI 48667 USA.						Aarts E., 1989, SIMULATED ANNEALING; Beebe K.R., 1998, CHEMOMETRICS PRACTIC; BLOMMERS MJJ, 1992, BIOPOLYMERS, V32, P45, DOI 10.1002/bip.360320107; Chen FZ, 2000, IND ENG CHEM RES, V39, P2378, DOI 10.1021/ie9904899; Chiang L.H., 2001, FAULT DETECTION DIAG; Chiang LH, 2003, J PROCESS CONTR, V13, P437, DOI 10.1016/S0959-1524(02)00068-9; Chiang LH, 2000, CHEMOMETR INTELL LAB, V50, P243, DOI 10.1016/S0169-7439(99)00061-1; DEWEIJER AP, 1994, ANAL CHEM, V66, P23, DOI 10.1021/ac00073a006; Duda R. O., 1973, PATTERN CLASSIFICATI; Glover F., 1998, TABU SEARCH; Hastie T., 2001, ELEMENTS STAT LEARNI; Jackson J.E., 1959, TECHNOMETRICS, P359, DOI 10.2307/1266717; JACKSON JE, 1979, TECHNOMETRICS, V21, P341, DOI 10.2307/1267757; Kemsley EK, 2001, CHEMOMETR INTELL LAB, V55, P39, DOI 10.1016/S0169-7439(00)00114-3; Kourti T, 1996, J QUAL TECHNOL, V28, P409; Ku WF, 1995, CHEMOMETR INTELL LAB, V30, P179, DOI 10.1016/0169-7439(95)00076-3; Leardi R, 2001, J CHEMOMETR, V15, P559, DOI 10.1002/cem.651; LEARDI R, 1992, J CHEMOMETR, V6, P267, DOI 10.1002/cem.1180060506; Leardi R, 1998, CHEMOMETR INTELL LAB, V41, P195, DOI 10.1016/S0169-7439(98)00051-3; Leardi R, 2000, J CHEMOMETR, V14, P643, DOI 10.1002/1099-128X(200009/12)14:5/6<643::AID-CEM621>3.3.CO;2-5; LYMAN PR, 1995, COMPUT CHEM ENG, V19, P321, DOI 10.1016/0098-1354(94)00057-U; MACGREGOR JF, 1995, CONTROL ENG PRACT, V3, P403, DOI 10.1016/0967-0661(95)00014-L; MCCABE GP, 1975, TECHNOMETRICS, V17, P103, DOI 10.2307/1268007; MCGARRAH DB, 1993, J COMPUT CHEM, V14, P1385, DOI 10.1002/jcc.540141115; Miller P., 1998, Applied Mathematics and Computer Science, V8; Qin SJ, 2001, J CHEMOMETR, V15, P715, DOI 10.1002/cem.667; Valle S, 1999, IND ENG CHEM RES, V38, P4389, DOI 10.1021/ie990110i; DOWNS JJ, 1993, COMPUT CHEM ENG, V17, P245, DOI 10.1016/0098-1354(93)80018-I; Westerhuis JA, 2000, CHEMOMETR INTELL LAB, V51, P95, DOI 10.1016/S0169-7439(00)00062-9; Wise BM, 1995, CHEMOMETR INTELL LAB, V30, P81, DOI 10.1016/0169-7439(95)00041-0	30	39	46	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0959-1524			J PROCESS CONTR	J. Process Control	MAR	2004	14	2					143	155		10.1016/S0959-1524(03)00029-5		13	Automation & Control Systems; Engineering, Chemical	Automation & Control Systems; Engineering	759FA	WOS:000187726600004		
J	Giraud-Carrier, C; Vilalta, R; Brazdil, P				Giraud-Carrier, C; Vilalta, R; Brazdil, P			Introduction to the special issue on meta-learning	MACHINE LEARNING			English	Editorial Material						meta-learning; meta-knowledge; inductive bias; dynamic bias selection	SELECTION		ELCA Informat SA, CH-1001 Lausanne, Switzerland; Univ Houston, Dept Comp Sci, Houston, TX 77204 USA; Univ Porto, Fac Econ, LIACC, P-4150180 Oporto, Portugal	Giraud-Carrier, C (reprint author), ELCA Informat SA, Ave Harpe 22-24,Case Postale 519, CH-1001 Lausanne, Switzerland.						Aha D. W., 1992, P 9 INT C MACH LEARN, P1; BALTES J, 1992, P ML92 WORKSH BIAS I; Baxter J, 1998, LEARNING TO LEARN, P71; Bensusan H., 2000, P ECML 2000 WORKSH M, P29; Bensusan H., 1998, P ECML, P119; Brazdil PB, 2003, MACH LEARN, V50, P251, DOI 10.1023/A:1021713901879; BRAZDIL PB, 1998, P 10 EUR C MACH LEAR, P11; BRODLEY CE, 1995, MACH LEARN, V20, P63, DOI 10.1007/BF00993475; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chandra C, 1998, INT J SOFTW ENG KNOW, V8, P3, DOI 10.1142/S0218194098000030; DZEROSKI S, 2004, MACH LEARN, V54, P195; Gama J., 1995, Progress in Artificial Intelligence. 7th Portuguese Conference on Artificial Intelligence, EPIA '95. Proceedings; GEMAN S, 1991, NEURAL COMPUT, V4, P1; GORDON DF, 1990, THESIS U MARYLAND; GORDON DF, 1995, MACH LEARN, V20, P5, DOI 10.1023/A:1022630017346; Hastie T., 2001, ELEMENTS STAT LEARNI; KALOUSIS A, 2004, MACH LEARN, V54, P195; KELLER J, 2000, P ECML 2000 WORKSH M, P73; Merz C. J, 1995, LEARNING DATA ARTIFI; Michie D., 1994, MACHINE LEARNING NEU; Ortega J., 2001, Knowledge and Information Systems, V3, DOI 10.1007/PL00011679; PENG W, 2002, LECT NOTES ARTIF INT, V2534, P141; Pfahringer B., 2000, P 17 INT C MACH LEAR, P743; PRATT L, 1997, MACHINE LEARNING, V28; Rendell L., 1987, Proceedings of the Fourth International Workshop on Machine Learning; RENDELL L., 1987, P 10 INT JOINT C ART, P308; SCHMIDHUBER J, 2004, MACH LEARN, V54, P195; Soares C, 2004, MACH LEARN, V54, P195, DOI 10.1023/B:MACH.0000015879.28004.9b; Stone P., 2000, P 11 EUR C MACH LEAR, P369; Thrun S, 1998, LEARNING TO LEARN, P181; Thrun S., 1995, P INT JOINT C ART IN, P1217; Todorovski L, 2003, MACH LEARN, V50, P223, DOI 10.1023/A:1021709817809; UTGOFF P, 2003, NEURAL NETWORKS, V14, P2497; Utgoff P., 1986, MACHINE LEARNING ART, VII, P107; Vilalta R, 2002, ARTIF INTELL REV, V18, P77, DOI 10.1023/A:1019956318069; Widmer G, 1997, MACH LEARN, V27, P259, DOI 10.1023/A:1007365809034; Widmer G, 1996, MACH LEARN, V23, P69, DOI 10.1007/BF00116900; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	38	41	43	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	MAR	2004	54	3					187	193		10.1023/B:MACH.0000015878.60765.42		7	Computer Science, Artificial Intelligence	Computer Science	773LK	WOS:000188925100001		
J	Siepel, A; Haussler, D				Siepel, A; Haussler, D			Phylogenetic estimation of context-dependent substitution rates by maximum likelihood	MOLECULAR BIOLOGY AND EVOLUTION			English	Article						neighbor-dependent substitution; CpG effect; codon model; expectation maximization; substitution rate matrix	NEIGHBORING BASE COMPOSITION; HIDDEN MARKOV MODEL; CODON-BASED MODEL; DNA-SEQUENCES; NUCLEOTIDE SUBSTITUTION; CHLOROPLAST GENOME; PROTEIN EVOLUTION; APPROXIMATE METHODS; SECONDARY STRUCTURE; ACID-SEQUENCES	Nucleotide substitution in both coding and noncoding regions is context-dependent, in the sense that substitution rates depend on the identity of neighboring bases. Context-dependent substitution has been modeled in the case of two sequences and an unrooted phylogenetic tree, but it has only been accommodated in limited ways with more general phylogenies. In this article, extensions are presented to standard phylogenetic models that allow for better handling of context-dependent substitution, yet still permit exact inference at reasonable computational cost. The new models improve goodness of fit substantially for both coding and noncoding data. Considering context dependence leads to much larger improvements than does using a richer substitution model or allowing for rate variation across sites, under the assumption of site independence. The observed improvements appear to derive from three separate properties of the models: their explicit characterization of context-dependent substitution within N-tuples of adjacent sites, their ability to accommodate overlapping N-tuples, and their rich parameterization of the substitution process. Parameter estimation is accomplished using an expectation maximization algorithm, with a quasi-Newton algorithm for the maximization step; this approach is shown to be preferable to ordinary Newton methods for parameter-rich models. Overlapping tuples are efficiently handled by assuming Markov dependence of the observed bases at each site on those at the N - 1 preceding sites, and the required. conditional probabilities are computed with an extension of Felsenstein's algorithm. Estimated substitution rates based on a data set of about 160,000 noncoding sites in mammalian genomes indicate a pronounced CpG effect, but they also suggest a complex overall pattern of context-dependent substitution, comprising a variety of subtle effects. Estimates based on about 3 million sites in coding regions demonstrate that amino acid substitution rates can be learned at the nucleotide level, and suggest that context effects across codon boundaries are significant.	Univ Calif Santa Cruz, Ctr Biomol Sci & Engn, Santa Cruz, CA 95064 USA; Univ Calif Santa Cruz, Howard Hughes Med Inst, Santa Cruz, CA 95064 USA	Siepel, A (reprint author), Univ Calif Santa Cruz, Ctr Biomol Sci & Engn, Santa Cruz, CA 95064 USA.	acs@soc.ucsc.edu					Adachi J., 1996, MOLPHY VERSION 2 3 P; Anderson E, 1999, LAPACK USERS GUIDE; Arndt P.F., 2002, P 6 ANN INT C COMP B, P32, DOI 10.1145/565196.565201; Bernardi G, 2000, GENE, V259, P31, DOI 10.1016/S0378-1119(00)00441-8; BLAKE RD, 1992, J MOL EVOL, V34, P189, DOI 10.1007/BF00162968; BLANCHETTE M, 2004, IN PRESS GENOME RES; Bray N, 2003, NUCLEIC ACIDS RES, V31, P3525, DOI 10.1093/nar/gkg623; BULMER M, 1986, MOL BIOL EVOL, V3, P322; Cooper GM, 2003, GENOME RES, V13, P813, DOI 10.1101/gr.1064503; Dayhoff M. O., 1978, ATLAS PROTEIN SEQ S3, V5, P345; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Durbin R, 1998, BIOL SEQUENCE ANAL P; EHRLICH M, 1990, MUTAT RES, V238, P277, DOI 10.1016/0165-1110(90)90019-8; Felsenstein J, 1996, MOL BIOL EVOL, V13, P93; Felsenstein J., 1993, PHYLIP PHYLOGENY INF; FELSENSTEIN J, 1981, J MOL EVOL, V17, P368, DOI 10.1007/BF01734359; Friedman N, 2002, J COMPUT BIOL, V9, P331, DOI 10.1089/10665270252935494; Fryxell KJ, 2000, MOL BIOL EVOL, V17, P1371; Goldman N, 1996, J MOL BIOL, V263, P196, DOI 10.1006/jmbi.1996.0569; GOLDMAN N, 1994, MOL BIOL EVOL, V11, P725; GRANTHAM R, 1974, SCIENCE, V185, P862, DOI 10.1126/science.185.4154.862; Green P, 2003, NAT GENET, V33, P514, DOI 10.1038/ng1103; Hardison RC, 2003, GENOME RES, V13, P13, DOI 10.1101/gr.844103; HASEGAWA M, 1985, J MOL EVOL, V22, P160, DOI 10.1007/BF02101694; Hastie T., 2001, ELEMENTS STAT LEARNI; HESS ST, 1994, J MOL BIOL, V236, P1022, DOI 10.1016/0022-2836(94)90009-4; Huelsenbeck JP, 1997, SCIENCE, V276, P227, DOI 10.1126/science.276.5310.227; Jensen JL, 2000, ADV APPL PROBAB, V32, P499; JONES DT, 1992, COMPUT APPL BIOSCI, V8, P275; Jordan M., 1999, LEARNING GRAPHICAL M; Karlin S., 1975, 1 COURSE STOCHASTIC; Kent WJ, 2002, GENOME RES, V12, P996, DOI 10.1101/gr.229102; Koshi JM, 1996, J MOL EVOL, V42, P313, DOI 10.1007/BF02198858; Lio P, 1998, GENOME RES, V8, P1233; MIYATA T, 1979, J MOL EVOL, V12, P219, DOI 10.1007/BF01732340; MORDAN MI, 2004, IN PRESS STAT SCI; MORTON BR, 1995, J MOL EVOL, V41, P597; Morton BR, 1997, J MOL EVOL, V45, P227, DOI 10.1007/PL00006224; Morton BR, 1997, MOL BIOL EVOL, V14, P189; Murphy KP, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P467; MUSE SV, 1994, MOL BIOL EVOL, V11, P715; MUSE SV, 1995, GENETICS, V139, P1429; Neyman J., 1971, STAT DECISION THEORY, P1; Notredame C, 2000, J MOL BIOL, V302, P205, DOI 10.1006/jmbi.2000.4042; OLSEN GJ, 1994, COMPUT APPL BIOSCI, V10, P41; Pedersen AMK, 2001, MOL BIOL EVOL, V18, P763; Pedersen AMK, 1998, MOL BIOL EVOL, V15, P1069; Pedersen JS, 2003, BIOINFORMATICS, V19, P219, DOI 10.1093/bioinformatics/19.2.219; Press W.H., 1992, NUMERICAL RECIPES C; Pruitt KD, 2001, NUCLEIC ACIDS RES, V29, P137, DOI 10.1093/nar/29.1.137; RZHETSKY A, 1995, GENETICS, V141, P771; Schadt E, 2002, MOL BIOL EVOL, V19, P1534; SCHONIGER M, 1994, MOL PHYLOGENET EVOL, V3, P240, DOI 10.1006/mpev.1994.1026; Schoniger M, 1995, SYST BIOL, V44, P533, DOI 10.2307/2413659; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SIEPEL A, 2004, IN PRESS J COMP BIOL; SWOFFORD D, 2002, PAUP PHYLOGENETIC AN; Tavare S, 1986, LECTURES MATH LIFE S, V17, P57; Thomas JW, 2003, NATURE, V424, P788, DOI 10.1038/nature01858; TILLIER ERM, 1995, MOL BIOL EVOL, V12, P7; WAINWRIGHT M, 2001, IEEE T INFORMATION T, V49, P1120; Waterston RH, 2002, NATURE, V420, P520, DOI 10.1038/nature01262; Whelan S, 2001, TRENDS GENET, V17, P262, DOI 10.1016/S0168-9525(01)02272-7; Yang YW, 2002, J MOL EVOL, V55, P111, DOI 10.1007/s00239-001-2310-0; Yang ZH, 1996, MOL BIOL EVOL, V13, P650; YANG ZH, 1994, J MOL EVOL, V39, P306, DOI 10.1007/BF00160154; YANG ZH, 1994, MOL BIOL EVOL, V11, P316; YANG ZB, 1994, J MOL EVOL, V39, P105; YANG ZH, 1993, MOL BIOL EVOL, V10, P1396; YANG ZH, 1995, GENETICS, V139, P993; Yang ZH, 2000, GENETICS, V155, P431; YANG ZH, 1995, MOL BIOL EVOL, V12, P451; Yang ZH, 1997, COMPUT APPL BIOSCI, V13, P555; YANG ZH, 1995, GENETICS, V141, P1641; Yang ZH, 1998, MOL BIOL EVOL, V15, P1600; YEDIDIA J, 2000, ADV NEURAL INFORMATI, V13, P689; Zhao Z, 2002, GENOME RES, V12, P1679, DOI 10.1101/gr.287302	77	168	173	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0737-4038			MOL BIOL EVOL	Mol. Biol. Evol.	MAR	2004	21	3					468	488		10.1093/molbev/msh039		21	Biochemistry & Molecular Biology; Evolutionary Biology; Genetics & Heredity	Biochemistry & Molecular Biology; Evolutionary Biology; Genetics & Heredity	804BG	WOS:000220273600006	14660683	
J	Rosenberg, NA				Rosenberg, NA			DISTRUCT: a program for the graphical display of population structure	MOLECULAR ECOLOGY NOTES			English	Article						admixture; ancestry; assignment test; clustering; subdivided population	MULTILOCUS GENOTYPE DATA; INFERENCE	In analysis of multilocus genotypes from structured populations, individual coefficients of membership in subpopulations are often estimated using programs such as STRUCTURE. DISTRUCT provides a general method for visualizing these estimated membership coefficients. Subpopulations are represented as colours, and individuals are depicted as bars partitioned into coloured segments that correspond to membership coefficients in the subgroups. DISTRUCT, available at www.cmb.usc.edu/-noahr/distruct.html, can also be used to display subpopulation assignment probabilities when individuals are assumed to have ancestry in only one group.	Univ So Calif, Program Mol & Computat Biol, Los Angeles, CA 90089 USA	Rosenberg, NA (reprint author), Univ So Calif, Program Mol & Computat Biol, 1042 W 36th Pl,DRB 289, Los Angeles, CA 90089 USA.	noahr@usc.edu					*ABOD SYST INC, 1986, POSTSC LANG REF; Anderson EC, 2002, GENETICS, V160, P1217; Banks MA, 2000, J HERED, V91, P87, DOI 10.1093/jhered/91.1.87; Beaumont M, 2001, MOL ECOL, V10, P319, DOI 10.1046/j.1365-294x.2001.01196.x; Falush D, 2003, GENETICS, V164, P1567; Hastie T., 2001, ELEMENTS STAT LEARNI; MILLAR RB, 1987, CAN J FISH AQUAT SCI, V44, P583, DOI 10.1139/f87-071; Pritchard JK, 2000, AM J HUM GENET, V67, P170, DOI 10.1086/302959; Pritchard JK, 2000, GENETICS, V155, P945; Rannala B, 1997, P NATL ACAD SCI USA, V94, P9197, DOI 10.1073/pnas.94.17.9197; Rosenberg NA, 2002, SCIENCE, V298, P2381, DOI 10.1126/science.1078311; Rosenberg NA, 2001, GENETICS, V159, P699	12	1049	1069	BLACKWELL PUBLISHING LTD	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DG, OXON, ENGLAND	1471-8278			MOL ECOL NOTES	Mol. Ecol. Notes	MAR	2004	4	1					137	138		10.1046/j.1471-8286.2003.00566.x		2	Biochemistry & Molecular Biology; Ecology; Evolutionary Biology	Biochemistry & Molecular Biology; Environmental Sciences & Ecology; Evolutionary Biology	777DJ	WOS:000189159500042		
J	Alexe, G; Alexe, S; Liotta, LA; Petricoin, E; Reiss, M; Hammer, PL				Alexe, G; Alexe, S; Liotta, LA; Petricoin, E; Reiss, M; Hammer, PL			Ovarian cancer detection by logical analysis of proteomic data	PROTEOMICS			English	Article						logical analysis of data; ovarian cancer	PROSTATE-CANCER; BREAST-CANCER; SERUM; PATTERNS; IDENTIFICATION; PREDICTION; CARCINOMA; MARKERS; RISK	A new type of efficient and accurate proteomic ovarian cancer diagnosis systems is proposed. The system is developed using the combinatorics and optimization-based methodology of logical analysis of data (LAD) to the Ovarian Dataset 8-7-02 (http://clinicalproteomics.steem.com), which updates the one used by Petricoin et al, in The Lancet 2002, 359, 572-577. This mass spectroscopy-generated dataset contains expression profiles of 15154 peptides defined by their mass/charge ratios (m/z) in serum of 162 ovarian cancer and 91 control cases. Several fully reproducible models using only 7-9 of the 15 154 peptides were constructed, and shown in multiple cross-validation tests (k-folding and leave-one-out) to provide sensitivities and specificities of up to 100%. A special diagnostic system for stage I ovarian cancer patients is shown to have similarly high accuracy. Other results: (i) expressions of peptides with relatively low m/z values in the dataset are shown to be better at distinguishing ovarian cancer cases from controls than those with higher m/z values; (ii) two large groups of patients with a high degree of similarities among their formal (mathematical) profiles are detected; (iii) several peptides with a blocking or promoting effect on ovarian cancer are identified.	Rutgers State Univ, Rutgers Ctr Operat Res, RUTCOR, Piscataway, NJ 08854 USA; NCI, Pathol Lab, NIH, Bethesda, MD 20892 USA; US FDA, Ctr Biol Evaluat & Res, NIH, Clin Proteom Program,Dept Therapeut, Bethesda, MD 20014 USA; Univ Med & Dent New Jersey, Robert Wood Johnson Med Sch, Inst Canc, Dept Med, New Brunswick, NJ USA	Hammer, PL (reprint author), Rutgers State Univ, Rutgers Ctr Operat Res, RUTCOR, 640 Bartholomew Rd, Piscataway, NJ 08854 USA.	hammer@rutcor.rutgers.edu	Reiss, Michael/A-8314-2009				ABRAMSON S, 2002, RUTCOR RES REPORT; Adam BL, 2002, CANCER RES, V62, P3609; ALEXE G, 2003, IN PRESS DISER APPL; ALEXE G, 2002, RUTCOR RUTGERS CTR O; Alexe S, 2003, ANN OPER RES, V119, P15, DOI 10.1023/A:1022970120229; ALEXE S, 2003, RUTCOR RES REPORT; Ardekani Ali M, 2002, Expert Rev Mol Diagn, V2, P312, DOI 10.1586/14737159.2.4.312; Bandera CA, 2003, CURR OPIN OBSTET GYN, V15, P51, DOI 10.1097/01.gco.0000051556.77832.52; Bishop C. M., 1996, NEURAL NETWORKS PATT; Boros E, 2000, IEEE T KNOWL DATA EN, V12, P292, DOI 10.1109/69.842268; Boros E, 1997, MATH PROGRAM, V79, P163, DOI 10.1007/BF02614316; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brown RE, 2002, ANN CLIN LAB SCI, V32, P12; Cohen LS, 2001, GYNECOL ONCOL, V82, P40, DOI 10.1006/gyno.2001.6253; Crama Y., 1988, Annals of Operations Research, V16, DOI 10.1007/BF02283750; Cristianini N, 2000, INTRO SUPPORT VECTOR; Duda R.O., 2001, PATTERN CLASSIFICATI; ECKSTEIN J, 2003, IN PRESS ANN OPERATI; Goldberg D.E., 1989, GENETIC ALGORITHMS S; Hammer AB, 1999, ANN OPER RES, V87, P165, DOI 10.1023/A:1018920600320; HAMMER PL, 2002, INFORMS ANN M SAN JO; HAMMER PL, 2003, RR7 RUTCOR RUTG U; Hastie T., 2001, ELEMENTS STAT LEARNI; Jobson J., 1991, APPL MULTIVARIATE DA; Lauer MS, 2002, CIRCULATION, V106, P685, DOI 10.1161/01.CIR.0000024410.15081.FD; Lüftner Diana, 2002, Expert Rev Mol Diagn, V2, P23, DOI 10.1586/14737159.2.1.23; OLSHEN RA, 1984, CLASSIFICATION REGRE; Ozolos RF, 2000, PRINCIPLES PRACTICE, P981; Petricoin EF, 2002, J NATL CANCER I, V94, P1576; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Pucci-Minafra I, 2002, PROTEOMICS, V2, P919, DOI 10.1002/1615-9861(200207)2:7<919::AID-PROT919>3.0.CO;2-P; Qu YS, 2002, CLIN CHEM, V48, P1835; Rai AJ, 2002, ARCH PATHOL LAB MED, V126, P1518; Sauter ER, 2002, BRIT J CANCER, V86, P1440, DOI 10.1038/sj/bjc/6600285; Srinivas PR, 2001, LANCET ONCOL, V2, P698, DOI 10.1016/S1470-2045(01)00560-5; TIMM N, 2002, APPL MULTIVARIATE AN; Wright George L Jr, 2002, Expert Rev Mol Diagn, V2, P549, DOI 10.1586/14737159.2.6.549; Wulfkuhle JD, 2002, CANCER RES, V62, P6740	38	49	52	WILEY-V C H VERLAG GMBH	WEINHEIM	PO BOX 10 11 61, D-69451 WEINHEIM, GERMANY	1615-9853			PROTEOMICS	Proteomics	MAR	2004	4	3					766	783		10.1002/pmic.200300574		18	Biochemical Research Methods; Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	802QX	WOS:000220179100020	14997498	
J	Fitzpatrick, R; Norquist, JM; Jenkinson, C; Reeves, BC; Morris, RW; Murray, DW; Gregg, PJ				Fitzpatrick, R; Norquist, JM; Jenkinson, C; Reeves, BC; Morris, RW; Murray, DW; Gregg, PJ			A comparison of Rasch with Likert scoring to discriminate between patients' evaluations of total hip replacement surgery	QUALITY OF LIFE RESEARCH			English	Article						hip replacement surgery; outcomes; Rasch measurement	QUALITY-OF-LIFE; HEALTH OUTCOMES; FOLLOW-UP; ARTHROPLASTY; SATISFACTION; PERCEPTIONS; OXFORD	The purpose of this study was to examine whether there are advantages in terms of outcome assessment of using Rasch methods of scoring the 12-item Oxford Hip Score ( OHS) questionnaire over conventionally Likert scores. As part of a prospective cohort study of total hip replacements in five former regions of England the OHS was sent to patients pre-operatively, at 3 months and 1 year post-operatively. Postoperative data was collected on over 5000 cases. Based on the level of satisfaction with surgery, patients were divided into satisfied and dissatisfied. Analyses were performed to test the relative precision ( RP) of Rasch scoring vs. conventionally Likert scores in discriminating the groups experiencing different level of satisfaction. Considerable gains in precision were achieved with Rasch scoring methods when groups were compared 3 and 12 months post-operatively. The results from the current study suggest that in some situations there may be substantial gains in measuring health related outcomes using Rasch-based scoring methods.	Univ Oxford, Inst Hlth Sci, Dept Publ Hlth, Oxford OX3 7LF, England; Univ Oxford, Inst Hlth Sci, Hlth Serv Res Unit, Oxford OX3 7LF, England; London Sch Hyg & Trop Med, London WC1, England; Picker Inst Europe, Oxford, England; UCL Royal Free & Univ Coll Med Sch, London, England; Nuffield Orthopaed Ctr, Dept Orthopaed Surg, Oxford OX3 7LD, England; S Tees Hosp NHS Trust Middlesborugh Gen Hosp, Middlesbrough, Cleveland, England	Fitzpatrick, R (reprint author), Univ Oxford, Inst Hlth Sci, Dept Publ Hlth, Oxford OX3 7LF, England.	raymond.fitzpatrick@nuffield.oxford.ac.uk	Murray, David/D-7117-2011				BAYLEY KB, 1995, MED CARE, V33, pAS226; Birbeck GL, 2000, NEUROLOGY, V54, P1822; Bond T. G., 2001, APPL RASCH MODEL FUN; Dawson J, 1996, J BONE JOINT SURG BR, V78B, P185; Dawson J, 1996, QUAL HEALTH CARE, V5, P81, DOI 10.1136/qshc.5.2.81; Dawson J, 2000, J ARTHROPLASTY, V15, P710, DOI 10.1054/arth.2000.7109; Dawson J, 1996, J Health Serv Res Policy, V1, P224; Efron Bradley, 1993, INTRO BOOTSTRAP; Espehaug B, 1998, CLIN ORTHOP RELAT R, P135; Fayers P. M., 2000, QUALITY LIFE ASSESSM; FISCHER GH, 1996, RASCH MODELS FDN REC, P353; FISCHER GH, 1996, RASCH MODELS FDN REC, P157; Fitzpatrick R, 2000, QUAL HEALTH CARE, V9, P146, DOI 10.1136/qhc.9.3.146; Fitzpatrick R, 1998, Health Technol Assess, V2, P1; Fitzpatrick R, 1997, PSYCHOL HEALTH, V12, P793, DOI 10.1080/08870449708406740; Granger CV, 1998, ARCH PHYS MED REHAB, V79, P52, DOI 10.1016/S0003-9993(98)90208-8; Hajat Shakoor, 2002, J Health Serv Res Policy, V7, P19, DOI 10.1258/1355819021927638; Hastie T., 2001, ELEMENTS STAT LEARNI; Hays RD, 2000, MED CARE, V38, P28; Linacre J. M., 2000, USERS GUIDE WINSTEPS; LUDLOW LH, 1995, EDUC PSYCHOL MEAS, V55, P967, DOI 10.1177/0013164495055006005; MACKNIGHT C, 2000, J CLIN EPIDEMIOL, V53, P1224; Mahomed NN, 2002, J RHEUMATOL, V29, P1273; McHorney CA, 1997, J CLIN EPIDEMIOL, V50, P451, DOI 10.1016/S0895-4356(96)00424-6; McMurray R, 1999, QUAL HEALTH CARE, V8, P228; Morris RW, 2001, ANN ROY COLL SURG, V83, P190; Norquist JM, 2004, MED CARE, V42, P25, DOI 10.1097/01.mlr.0000103530.13056.88; Pacault-Legendre V, 1999, INT ORTHOP, V23, P23, DOI 10.1007/s002640050297; Raczek AE, 1998, J CLIN EPIDEMIOL, V51, P1203, DOI 10.1016/S0895-4356(98)00112-7; Ritter MA, 1997, CLIN ORTHOP RELAT R, P81; Shepperd S, 1998, BRIT MED J, V316, P1786; Smith E V Jr, 2000, J Appl Meas, V1, P303; Smith R M, 1998, J Outcome Meas, V2, P66; VANALPHEN A, 1994, J ADV NURS, V20, P196; WAMPOLD BE, 1999, RASCH MEAS TRANS, V13, P695; Wolfe E W, 1999, J Outcome Meas, V3, P134; Wolfe F, 2001, J RHEUMATOL, V28, P982; WRIGHT B, 1983, RATING SCALE ANAL; Wright B, 1996, RASCH MEASUREMENT T, V9, P472; Wright B. D., 1994, RASCH MEASUREMENT T, V8, P370; Wright B. D., 1979, BEST TEST DESIGN; WRIGHT BD, 1989, ARCH PHYS MED REHAB, V70, P857	42	16	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0962-9343			QUAL LIFE RES	Qual. Life Res.	MAR	2004	13	2					331	338		10.1023/B:QURE.0000018489.25151.e1		8	Health Care Sciences & Services; Health Policy & Services; Public, Environmental & Occupational Health	Health Care Sciences & Services; Public, Environmental & Occupational Health	800BS	WOS:000220004500005	15085905	
J	Meireles, SI; Cristo, EB; Carvalho, AF; Hirata, R; Pelosof, A; Gomes, LI; Martins, WK; Begnami, MD; Zitron, C; Montagnini, AL; Soares, FA; Neves, EJ; Reis, LFL				Meireles, SI; Cristo, EB; Carvalho, AF; Hirata, R; Pelosof, A; Gomes, LI; Martins, WK; Begnami, MD; Zitron, C; Montagnini, AL; Soares, FA; Neves, EJ; Reis, LFL			Molecular classifiers for gastric cancer and nonmalignant diseases of the gastric mucosa	CANCER RESEARCH			English	Article							DIFFERENTIALLY EXPRESSED GENES; INTESTINAL METAPLASIA; BARRETTS-ESOPHAGUS; CDNA MICROARRAY; CYTOKERATIN IMMUNOREACTIVITY; HELICOBACTER-PYLORI; CARCINOMA; CLASSIFICATION; TUMOR; DIFFUSE	High incidence of gastric cancer-related death is mainly due to diagnosis at an advanced stage in addition to the lack of adequate neoadjuvant therapy. Hence, new tools aimed at early diagnosis would have a positive impact in the outcome of the disease. Using cDNA arrays having 376 genes either identified previously as altered in gastric tumors or known to be altered in human cancer, we determined expression signature of 99 tissue fragments representing normal gastric mucosa, gastritis, intestinal metaplasia, and adenocarcinomas. We first validated the array by identifying molecular markers that are associated with intestinal metaplasia, considered as a transition stage of gastric adenocarcinomas of the intestinal type as well as markers that are associated with diffuse type of gastric adenocarcinomas. Next, we applied Fisher's linear discriminant analysis in an exhaustive search of trios of genes that could be used to build classifiers for class distinction. Many classifiers could distinguish between normal and tumor samples, whereas, for the distinction of gastritis from tumor and for metaplasia from tumor, fewer classifiers were identified. Statistical validations showed that trios that discriminate between normal and tumor samples are powerful classifiers to distinguish between tumor and nontumor samples. More relevant, it was possible to identify samples of intestinal metaplasia that have expression signature resembling that of an adenocarcinoma and can now be used for follow-up of patients to determine their potential as a prognostic test for malignant transformation.	Ludwig Inst Canc Res, Sao Paulo, Brazil; Hosp Canc AC Camargo, Sao Paulo, Brazil; Univ Sao Paulo, BioInfo & Inst Matemat & Estatist, Sao Paulo, Brazil; SENAC Coll Comp Sci & Technol, Sao Paulo, Brazil	Reis, LFL (reprint author), Rua Prof Antonio Prudente 109, BR-01509010 Sao Paulo, SP, Brazil.	lreis@ludwig.org.br	Hirata Jr., Roberto/E-4436-2011; Cancer, Cepid/I-4384-2013; Reis, Luiz/C-4556-2013	Hirata Jr., Roberto/0000-0003-3861-7260; 			Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Beer DG, 2002, NAT MED, V8, P816, DOI 10.1038/nm733; Bossenmeyer-Pourie C, 2002, J CELL BIOL, V157, P761, DOI 10.1083/jcb200108056; Boussioutas A, 2003, CANCER RES, V63, P2569; Correa P, 1994, Cancer Surv, V19-20, P55; Couvelard A, 2001, GUT, V49, P761, DOI 10.1136/gut.49.6.761; Dubois RN, 2000, ALIMENT PHARM THERAP, V14, P64, DOI 10.1046/j.1365-2036.2000.014s1064.x; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Edwards D, 2003, BIOINFORMATICS, V19, P825, DOI 10.1093/bioinformatics/btg083; El-Rifai W, 2001, INT J CANCER, V92, P832, DOI 10.1002/ijc.1264; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Grabsch H, 2001, HISTOPATHOLOGY, V39, P141, DOI 10.1046/j.1365-2559.2001.01177.x; Guilford P, 1998, NATURE, V392, P402, DOI 10.1038/32918; Hasegawa S, 2002, CANCER RES, V62, P7012; Hastie T., 2001, ELEMENTS STAT LEARNI; Hippo Y, 2002, CANCER RES, V62, P233; Inoue H, 2002, CLIN CANCER RES, V8, P3475; Jovanovic I, 2002, HISTOL HISTOPATHOL, V17, P445; Kang GH, 2001, CANCER RES, V61, P2847; LAUREN P, 1965, ACTA PATHOL MIC SC, V64, P31; Lee HS, 2003, J PATHOL, V200, P39, DOI 10.1002/path.1288; Lee S, 2002, CANCER LETT, V184, P197, DOI 10.1016/S0304-3835(02)00197-0; Leung WK, 2001, CANCER, V91, P2294; Liu LX, 2002, WORLD J GASTROENTERO, V8, P580; Meireles SI, 2003, CANCER LETT, V190, P199, DOI 10.1016/S0304-3835(02)00587-6; Mohammed IA, 2002, MODERN PATHOL, V15, P611, DOI 10.1038/modpathol.3880574; Mori M, 2002, SURGERY, V131, pS39, DOI 10.1067/msy.2002.119292; Mouzas IA, 2002, GUT, V51, P894, DOI 10.1136/gut.51.6.894-a; Odze R, 2002, LANCET, V359, P1711, DOI 10.1016/S0140-6736(02)08661-0; Oliveira FJ, 1998, GASTRIC CANCER, V1, P51, DOI 10.1007/s101200050054; Ormsby AH, 1999, HUM PATHOL, V30, P288, DOI 10.1016/S0046-8177(99)90007-2; Peek RM, 2002, NAT REV CANCER, V2, P28, DOI 10.1038/nrc703; Quackenbush J, 2001, NAT REV GENET, V2, P418, DOI 10.1038/35076576; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Saeed AI, 2003, BIOTECHNIQUES, V34, P374; SHIAO YH, 1994, AM J PATHOL, V144, P511; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Stadtlander CTKH, 1999, CARCINOGENESIS, V20, P2195, DOI 10.1093/carcin/20.12.2195; Sung JJY, 2000, AM J PATHOL, V157, P729, DOI 10.1016/S0002-9440(10)64586-5; van de Vijver MJ, 2002, NEW ENGL J MED, V347, P1999, DOI 10.1056/NEJMoa021967; Woo DK, 2001, INT J CANCER, V95, P108, DOI 10.1002/1097-0215(20010320)95:2<108::AID-IJC1019>3.0.CO;2-#; Yang YH, 2002, NUCLEIC ACIDS RES, V30, DOI 10.1093/nar/30.4.e15; Yeatman TJ, 2003, AM SURGEON, V69, P41	44	37	42	AMER ASSOC CANCER RESEARCH	PHILADELPHIA	615 CHESTNUT ST, 17TH FLOOR, PHILADELPHIA, PA 19106-4404 USA	0008-5472			CANCER RES	Cancer Res.	FEB 15	2004	64	4					1255	1265		10.1158/0008-5472.CAN-03-1850		11	Oncology	Oncology	778MK	WOS:000189245200011	14973074	
J	Braga-Neto, UM; Dougherty, ER				Braga-Neto, UM; Dougherty, ER			Is cross-validation valid for small-sample microarray classification?	BIOINFORMATICS			English	Article							BREAST-CANCER	Motivation: Microarray classification typically possesses two striking attributes: (1) classifier design and error estimation are based on remarkably small samples and (2) cross-validation error estimation is employed in the majority of the papers. Thus, it is necessary to have a quantifiable understanding of the behavior of cross-validation in the context of very small samples. Results: An extensive simulation study has been performed comparing cross-validation, resubstitution and bootstrap estimation for three popular classification rules-linear discriminant analysis, 3-nearest-neighbor and decision trees (CART)-using both synthetic and real breast-cancer patient data. Comparison is via the distribution of differences between the estimated and true errors. Various statistics for the deviation distribution have been computed: mean (for estimator bias), variance (for estimator precision), root-mean square error (for composition of bias and variance) and quartile ranges, including outlier behavior. In general, while cross-validation error estimation is much less biased than resubstitution, it displays excessive variance, which makes individual estimates unreliable for small samples. Bootstrap methods provide improved performance relative to variance, but at a high computational cost and often with increased bias (albeit, much less than with resubstitution).	Texas A&M Univ, Dept Elect Engn, College Stn, TX 77840 USA; Univ Texas, MD Anderson Canc Ctr, Sect Clin Canc Genet, Houston, TX 77030 USA; Univ Texas, MD Anderson Canc Ctr, Dept Pathol, Houston, TX 77030 USA	Dougherty, ER (reprint author), Texas A&M Univ, Dept Elect Engn, 214 Zachry Engn Ctr, College Stn, TX 77840 USA.	edward@ee.tamu.edu					Azuaje F, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-5; Chernick M.R., 1999, BOOTSTRAP METHODS PR; Devroye L., 1996, PROBABILISTIC THEORY; Dougherty ER, 2001, COMPAR FUNCT GENOM, V2, P28, DOI 10.1002/cfg.62; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Hastie T., 2001, ELEMENTS STAT LEARNI; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; van de Vijver MJ, 2002, NEW ENGL J MED, V347, P1999, DOI 10.1056/NEJMoa021967; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vapnik V., 1998, STAT LEARNING THEORY; Witten IH, 2000, DATA MINING	12	214	223	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	FEB 12	2004	20	3					374	380		10.1093/bioinformatics/btg419		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	774PD	WOS:000188990900010	14960464	
J	Machens, CK; Wehr, MS; Zador, AM				Machens, CK; Wehr, MS; Zador, AM			Linearity of cortical receptive fields measured with natural sounds	JOURNAL OF NEUROSCIENCE			English	Article						natural stimuli; auditory cortex; whole cell; patch clamp; reverse correlation; neural code	PRIMARY AUDITORY-CORTEX; PYRAMIDAL NEURONS; DYNAMIC SPECTRA; UNIT RESPONSES; VISUAL-CORTEX; PREDICTION; SYSTEM; CELLS; CAT; THALAMUS	How do cortical neurons represent the acoustic environment? This question is often addressed by probing with simple stimuli such as clicks or tone pips. Such stimuli have the advantage of yielding easily interpreted answers, but have the disadvantage that they may fail to uncover complex or higher-order neuronal response properties. Here, we adopt an alternative approach, probing neuronal responses with complex acoustic stimuli, including animal vocalizations. We used in vivo whole-cell methods in the rat auditory cortex to record subthreshold membrane potential fluctuations elicited by these stimuli. Most neurons responded robustly and reliably to the complex stimuli in our ensemble. Using regularization techniques, we estimated the linear component, the spectrotemporal receptive field (STRF), of the transformation from the sound (as represented by its time-varying spectrogram) to the membrane potential of the neuron. We find that the STRF has a rich dynamical structure, including excitatory regions positioned in general accord with the prediction of the classical tuning curve. However, whereas the STRF successfully predicts the responses to some of the natural stimuli, it surprisingly fails completely to predict the responses to others; on average, only 11% of the response power could be predicted by the STRF. Therefore, most of the response of the neuron cannot be predicted by the linear component, although the response is deterministically related to the stimulus. Analysis of the systematic errors of the STRF model shows that this failure cannot be attributed to simple nonlinearities such as adaptation to mean intensity, rectification, or saturation. Rather, the highly nonlinear response properties of auditory cortical neurons must be attributable to nonlinear interactions between sound frequencies and time-varying properties of the neural encoder.	Cold Spring Harbor Lab, Cold Spring Harbor, NY 11724 USA	Zador, AM (reprint author), Cold Spring Harbor Lab, 1 Bungtown Rd, Cold Spring Harbor, NY 11724 USA.	zador@cshl.edu					Abbott LF, 1997, SCIENCE, V275, P220; Attias H, 1997, ADV NEUR IN, V9, P27; Barbour DL, 2003, SCIENCE, V299, P1073, DOI 10.1126/science.1080425; Blake DT, 2002, J NEUROPHYSIOL, V88, P3409, DOI 10.1152/jn.00233.2002; Brockwell P. J., 1991, TIME SERIES THEORY M; Cohen L., 1995, TIME FREQUENCY ANAL; CREUTZFELDT O, 1980, EXP BRAIN RES, V39, P87; deCharms RC, 1998, SCIENCE, V280, P1439, DOI 10.1126/science.280.5368.1439; Depireux DA, 2001, J NEUROPHYSIOL, V85, P1220; DEWEESE MR, 2000, SOC NEUR ABSTR, V26, P63714; DeWeese MR, 2003, J NEUROSCI, V23, P7940; EGGERMONT JJ, 1983, HEARING RES, V10, P191, DOI 10.1016/0378-5955(83)90053-9; EGGERMONT JJ, 1993, HEARING RES, V66, P177, DOI 10.1016/0378-5955(93)90139-R; Hastie T., 2001, ELEMENTS STAT LEARNI; He JF, 2001, J NEUROSCI, V21, P8672; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; Klein DJ, 2000, J COMPUT NEUROSCI, V9, P85, DOI 10.1023/A:1008990412183; Kowalski N, 1996, J NEUROPHYSIOL, V76, P3503; Kowalski N, 1996, J NEUROPHYSIOL, V76, P3524; Linden JF, 2003, J NEUROPHYSIOL, V90, P2660, DOI 10.1152/jn.00751.2002; MACHENS CK, 2003, ADV NEURAL INFORMATI, P149; Markram H, 1996, NATURE, V382, P807, DOI 10.1038/382807a0; Miller LM, 2002, J NEUROPHYSIOL, V87, P516; Nelken I, 1999, NATURE, V397, P154, DOI 10.1038/16456; Ojima H, 2002, CEREB CORTEX, V12, P1079, DOI 10.1093/cercor/12.10.1079; Paninski L, 2003, NETWORK-COMP NEURAL, V14, P437, DOI 10.1088/0954-898X/14/3/304; Press W.H., 1992, NUMERICAL RECIPES C; Rotman Y, 2001, HEARING RES, V152, P110, DOI 10.1016/S0378-5955(00)00243-4; RUTKOWSKI RG, 2002, AUDIOL NEURO-OTOL, V7, P314; Sahani M, 2003, ADV NEURAL INFORM PR, P125; Sahani M, 2003, ADV NEURAL INFORM PR, P317; Schnupp JWH, 2001, NATURE, V414, P200, DOI 10.1038/35102568; SHARPEE T, 2003, ADV NEURAL INFORMATI, P277; Smyth D, 2003, J NEUROSCI, V23, P4746; SOVIJARVI ARA, 1975, ACTA PHYSIOL SCAND, V93, P318, DOI 10.1111/j.1748-1716.1975.tb05821.x; Stevens CF, 1998, NAT NEUROSCI, V1, P210, DOI 10.1038/659; TAI L, 2002, SOC NEUR ABSTR, V28; Tai L., 2001, Society for Neuroscience Abstracts, V27, P1634; Theunissen FE, 2000, J NEUROSCI, V20, P2315; Theunissen FE, 2001, NETWORK-COMP NEURAL, V12, P289; Wehr M, 2003, NATURE, V426, P442, DOI 10.1038/nature02116; WOLLBERG Z, 1972, SCIENCE, V175, P212, DOI 10.1126/science.175.4018.212; YESHURUN Y, 1989, B MATH BIOL, V51, P337, DOI 10.1007/BF02460112	43	126	128	SOC NEUROSCIENCE	WASHINGTON	11 DUPONT CIRCLE, NW, STE 500, WASHINGTON, DC 20036 USA	0270-6474			J NEUROSCI	J. Neurosci.	FEB 4	2004	24	5					1089	1100		10.1523/JNEUROSCI.4445-03.2004		12	Neurosciences	Neurosciences & Neurology	770UZ	WOS:000188750300010	14762127	
J	Friedman, J; Hastie, T; Rosset, S; Tibshirani, R; Zhu, J				Friedman, J; Hastie, T; Rosset, S; Tibshirani, R; Zhu, J			The golden chain - Discussion	ANNALS OF STATISTICS			English	Editorial Material							WAVELET SHRINKAGE		Stanford Univ, Dept Stat, Stanford, CA 94305 USA	Hastie, T (reprint author), Stanford Univ, Dept Stat, Stanford, CA 94305 USA.	hastie@stanford.edu					Donoho D., 2002, OPTIMALLY SPARSE REP; DONOHO DL, 1995, J ROY STAT SOC B MET, V57, P301; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; DONOHO DL, 1992, J ROY STAT SOC B MET, V54, P41; EFRON B, 2004, IN PRESS ANN STAT; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 1999, GREEDY FUNCTION APPR; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Hastie T., 2001, ELEMENTS STAT LEARNI; ROSSET S, 2002, BOOSTING REGULARIZED; Vapnik VN, 1995, NATURE STAT LEARNING	12	23	24	INST MATHEMATICAL STATISTICS	BEACHWOOD	PO BOX 22718, BEACHWOOD, OH 44122 USA	0090-5364			ANN STAT	Ann. Stat.	FEB	2004	32	1					102	107				6	Statistics & Probability	Mathematics	809BQ	WOS:000220612600009		
J	Freund, Y; Schapire, RE				Freund, Y; Schapire, RE			The golden chain - Discussion	ANNALS OF STATISTICS			English	Editorial Material							LOGISTIC-REGRESSION; ALGORITHM; MAJORITY; MARGIN		Columbia Univ, Ctr Computat Learning Syst, New York, NY 10027 USA; Princeton Univ, Dept Comp Sci, Princeton, NJ 08544 USA	Freund, Y (reprint author), Columbia Univ, Ctr Computat Learning Syst, MC 4750,500 W 120th St, New York, NY 10027 USA.	schapire@cs.princeton.edu					Collins M, 2002, MACH LEARN, V48, P253, DOI 10.1023/A:1013912006537; Freund Y., 1996, Proceedings of the Ninth Annual Conference on Computational Learning Theory, DOI 10.1145/238061.238163; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y, 1999, GAME ECON BEHAV, V29, P79, DOI 10.1006/game.1999.0738; Freund Y, 2001, MACH LEARN, V43, P293, DOI 10.1023/A:1010852229904; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Hastie T., 2001, ELEMENTS STAT LEARNI; Kivinen J., 1999, Proceedings of the Twelfth Annual Conference on Computational Learning Theory, DOI 10.1145/307400.307424; Koltchinskii V, 2002, ANN STAT, V30, P1; LEBANON G, 2002, ADV NEURAL INFORMATI, V14; Mason L, 2000, ADV NEUR IN, P221; MASON L, 2000, ADV NEURAL INFORMATI, V12; Ratsch G., 2000, P 13 ANN C COMP LEAR; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Schapire RE, 1998, ANN STAT, V26, P1651; Shafer Glenn, 2001, PROBABILITY FINANCE; Valiant L. G., 1984, P 16 ANN ACM S THEOR, P436, DOI DOI 10.1145/800057.808710; Vapnik VN, 1995, NATURE STAT LEARNING	20	3	3	INST MATHEMATICAL STATISTICS	BEACHWOOD	PO BOX 22718, BEACHWOOD, OH 44122 USA	0090-5364			ANN STAT	Ann. Stat.	FEB	2004	32	1					113	117				5	Statistics & Probability	Mathematics	809BQ	WOS:000220612600011		
J	Kelly, BC; McKay, TA				Kelly, BC; McKay, TA			Morphological classification of galaxies by shapelet decomposition in the Sloan Digital Sky Survey	ASTRONOMICAL JOURNAL			English	Article						galaxies : fundamental parameters; galaxies : statistics; methods : data analysis; methods : statistical; techniques : image processing	SPECTROSCOPIC TARGET SELECTION; AUTOMATED CLASSIFICATION; DISTANT GALAXIES; HUBBLE-SPACE; DATA RELEASE; SYSTEM; SAMPLE; PARAMETERS; MODEL; FIELD	We describe application of the "shapelet'' linear decomposition of galaxy images to morphological classification using images of similar to 3000 galaxies from the Sloan Digital Sky Survey. After decomposing the galaxies, we perform a principal component analysis to reduce the number of dimensions of the shapelet space to nine. We find that each of these nine principal components contains unique morphological information and give a description of each principal component's contribution to a galaxy's morphology. We find that galaxies of differing Hubble type separate cleanly in the shapelet space. We apply a Gaussian mixture model to the nine-dimensional space spanned by the principal components and use the results as a basis for classification. Using the mixture model, we separate galaxies into seven classes and give a description of each class' physical and morphological properties. We find that several of the mixture model classes correlate well with the traditional Hubble types both in their morphology and their physical parameters ( e. g., color, velocity dispersions, etc.). In addition, we find an additional class of late-type morphology but with high velocity dispersions and very blue color; most of these galaxies exhibit poststarburst activity. This method provides an objective and quantitative alternative to traditional and subjective visual classification.	Univ Arizona, Steward Observ, Tucson, AZ 85721 USA; Univ Michigan, Dept Phys, Ann Arbor, MI 48109 USA	Kelly, BC (reprint author), Univ Arizona, Steward Observ, 933 N Cherry Ave, Tucson, AZ 85721 USA.	bkelly@as.arizona.edu; tamckay@umich.edu	McKay, Timothy/C-1501-2009	McKay, Timothy/0000-0001-9036-6150			Abazajian K, 2003, ASTRON J, V126, P2081, DOI 10.1086/378165; Abraham R. G., 1996, MNRAS, V279, P47; Abraham RG, 2000, ASTRON J, V120, P2835, DOI 10.1086/316877; Abraham RG, 1996, ASTROPHYS J SUPPL S, V107, P1, DOI 10.1086/192352; ABRAHAM RG, 1994, ASTROPHYS J, V432, P75, DOI 10.1086/174550; ARP H, 1966, ASTROPHYS J, VS 14, P1, DOI 10.1086/190147; BALL NM, 2003, IN PRESS MNRAS; Blanton MR, 2003, ASTROPHYS J, V594, P186, DOI 10.1086/375528; Blanton MR, 2003, ASTRON J, V125, P2276, DOI 10.1086/344761; Chang TC, 2002, ASTROPHYS J, V570, P447, DOI 10.1086/339496; CONNOLLY AJ, 2000, ASTROPH0008187; CONSELICE CJ, 2003, IN PRESS APJS; de Vaucouleurs G., 1959, HDB PHYSIK, V53, P275; DOI M, 1993, MON NOT R ASTRON SOC, V264, P832; Eisenstein DJ, 2001, ASTRON J, V122, P2267, DOI 10.1086/323717; ELMEGREEN DM, 1982, MON NOT R ASTRON SOC, V201, P1021; ELMEGREEN DM, 1998, GALAXIES GALACTIC ST; FARGE M, 1992, ANNU REV FLUID MECH, V24, P395, DOI 10.1146/annurev.fluid.24.1.395; Fischer P, 2000, ASTRON J, V120, P1198, DOI 10.1086/301540; Frei Z, 1999, ASTROPHYS SPACE SCI, V269, P577, DOI 10.1023/A:1017095718809; Fukugita M, 1996, ASTRON J, V111, P1748, DOI 10.1086/117915; Goderya SN, 2002, ASTROPHYS SPACE SCI, V279, P377, DOI 10.1023/A:1015193432240; Gunn JE, 1998, ASTRON J, V116, P3040, DOI 10.1086/300645; Hastie T., 2001, ELEMENTS STAT LEARNI; Hogg DW, 2001, ASTRON J, V122, P2129, DOI 10.1086/323103; Hubble E. P., 1936, REALM NEBULAE; Koopmann RA, 1998, ASTROPHYS J, V497, pL75, DOI 10.1086/311283; Kormendy J., 1982, MORPHOLOGY DYNAMICS, P113; MASSEY RJ, 2003, IN PRESS MNRAS; MATTHEWS TA, 1964, ASTROPHYS J, V140, P35, DOI 10.1086/147890; Misiriotis A, 2001, ASTRON ASTROPHYS, V372, P775, DOI 10.1051/0004-6361:20010568; Moore AW, 1999, ADV NEUR IN, V11, P543; MORGAN WW, 1958, PUBL ASTRON SOC PAC, V70, P364, DOI 10.1086/127243; MORGAN WW, 1965, ASTROPHYS J, V142, P1364, DOI 10.1086/148422; NAIM A, 1995, MON NOT R ASTRON SOC, V274, P1107; Nakamura O, 2003, ASTRON J, V125, P1682, DOI 10.1086/368135; ODEWAHN SC, 1995, PUBL ASTRON SOC PAC, V107, P770, DOI 10.1086/133622; Odewahn SC, 2002, ASTROPHYS J, V568, P539, DOI 10.1086/339036; Pier JR, 2003, ASTRON J, V125, P1559, DOI 10.1086/346138; Refregier A, 2003, MON NOT R ASTRON SOC, V338, P48, DOI 10.1046/j.1365-8711.2003.05902.x; Refregier A, 2003, MON NOT R ASTRON SOC, V338, P35, DOI 10.1046/j.1365-8711.2003.05901.x; Richards GT, 2002, ASTRON J, V123, P2945, DOI 10.1086/340187; ROBERTS MS, 1994, ANNU REV ASTRON ASTR, V32, P115; SANDAGE A, 1979, ASTRON J, V84, P472, DOI 10.1086/112440; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Smith JA, 2002, ASTRON J, V123, P2121, DOI 10.1086/339311; Starck JL, 2003, ASTRON ASTROPHYS, V398, P785, DOI 10.1051/0004-6361:20021571; Stoughton C, 2002, ASTRON J, V123, P485, DOI 10.1086/324741; Strauss MA, 2002, ASTRON J, V124, P1810, DOI 10.1086/342343; THANKI S, 2000, BAAS, V32, P717; Trinidad M. A., 1998, Revista Mexicana de Astronomia y Astrofisica, Serie de Conferencias, V7; VANDENBERGH S, 1960, ASTROPHYS J, V131, P215, DOI 10.1086/146821; van den Bergh S, 2001, ASTRON J, V122, P611, DOI 10.1086/321173; VANDENBERGH S, 1998, GALAXY MORPHOLOGY CL; VANDENBERGH S, 1976, ASTROPHYS J, V206, P883, DOI 10.1086/154452; YIP CW, 2003, UNPUB AJ; York DG, 2000, ASTRON J, V120, P1579, DOI 10.1086/301513	57	30	30	UNIV CHICAGO PRESS	CHICAGO	1427 E 60TH ST, CHICAGO, IL 60637-2954 USA	0004-6256			ASTRON J	Astron. J.	FEB	2004	127	2					625	645		10.1086/380934		21	Astronomy & Astrophysics	Astronomy & Astrophysics	801FG	WOS:000220081200006		
J	Yen, PPW; Huettmann, F; Cooke, F				Yen, PPW; Huettmann, F; Cooke, F			A large-scale model for the at-sea distribution and abundance of Marbled Murrelets (Brachyramphus marmoratus) during the breeding season in coastal British Columbia, Canada	ECOLOGICAL MODELLING			English	Review						Marbled Murrelets; Brachyramphus marmoratus; breeding distribution; marine distribution; modelling algorithms; Classification and Regression Trees (CART); Artificial Neural Networks (ANNs); Multiple Adaptive Regression Splines (MARS); Generalized Linear Model (GLM)	ARTIFICIAL NEURAL-NETWORKS; PACIFIC SAND LANCE; AMMODYTES-HEXAPTERUS; RHINOCEROS AUKLET; RIVER DISCHARGE; SEABIRD COLONY; ISLAND; REGRESSION; ALASKA; VARIABILITY	The role that the marine environment plays in the distribution and abundance of Marbled Murrelets (Brachyramphus marmoratus), a seabird which nests in old-growth forests, is not well understood. Therefore, we investigated how Marbled Murrelet marine distribution and abundance is related to the abiotic and biotic components of the marine environment. Data on the marine distribution of Marbled Murrelets in British Columbia (BC), densities (birds/km(2); 1972-1993), counts (number of birds per survey; 1922-1989), and pertinent environmental variables as identified from the literature were compiled and then organized in a Geographic Information System (GIS). On a 10 km scale, count surveys were not correlated with density surveys (r(2) = 0.01, P = 0.46). This suggests the interpretation of count survey data (relative abundance) should be done with care; and it is not further used in this study. We built a parsimonious model to explain marine densities with marine predictors. First, significant predictors were identified with multivariate Generalized Linear Models (GLMs) by evaluating the shortest distances from survey locations to predictor variables. Murrelet density is higher close to sandy substrate, estuaries and cooler sea temperatures, and lower close to glaciers and herring spawn areas. Model predictors selected by using P-values and AIC include sea surface temperature, herring spawn index, estuary locations, distribution of sand and fine gravel substrates (as a proxy for sand lance distribution), and proximity to glaciers. Secondly, spatially explicit large-scale distribution model algorithms use this set of significant predictors to predict Marbled Murrelet abundance (density), distribution and populations in coastal BC. The modelling algorithms used include GLM, Classification and Regression Trees (CART) [Classification and Regression Trees, Wadsworth & Brooks, Pacific Grove, CA, 368 pp.; Software CART and MARS, San Diego, CA] and Tree (SPLUS) [Modem Applied Statistics with S-Plus, Statistics and Computing, 2nd ed., Springer, New York, 462 pp.], Multivariate Adaptive Regression Splines (MARS) [Software CART and MARS, San Diego, CA], and Artificial Neural Networks (ANNs) (SPLUS) [Modem Applied Statistics with S-Plus, Statistics and Computing, 2nd ed., Springer, New York 462 pp.]. Model performances were evaluated by backfitting, and by standardizing models. Tree-SPLUS was identified as the best performing model, and therefore used to predict the maximum carrying capacity of 170,500 birds for the marine habitat of coastal BC. An additional, a posteriori predictor, the shortest distance to old-growth forest, explained much of the remaining residual variance. This model result led us to a hypothesis of how Marbled Murrelet distribution and abundance relates to proximity to old-growth forests, and it makes an initial basic link between the marine and terrestrial aspects of Marbled Murrelet habitat. Our approach presents the first predictive abundance and distribution models applied to Marbled Murrelets on a large scale (British Columbia coast). Our approach is robust, and the statistical algorithms compared here are fully described and are known to perform well. Our findings are crucial for decision making and consider conservation management on a scale pertinent for the habitat protection of this species. (C) 2003 Published by Elsevier B.V.	Univ Alaska, Inst Arch Biol, Dept Biol & Wildlife, Fairbanks, AK 99775 USA; Simon Fraser Univ, Ctr Wildlife Ecol, Dept Biol Sci, Burnaby, BC V5A 1S6, Canada	Yen, PPW (reprint author), Point Reyes Bird Observ, Marine Sci Program, 4990 Shoreline Highway, Stinson Beach, CA 94970 USA.	pyen@prbo.org; fffh@uaf.edu; f.cooke@uea.ac.uk					BAIRD PH, 1990, ORNIS SCAND, V21, P224, DOI 10.2307/3676782; Bell JF, 1996, J APPL STAT, V23, P349, DOI 10.1080/02664769624297; BERTRAM DF, 1993, CAN J FISH AQUAT SCI, V50, P1908, DOI 10.1139/f93-213; BLACKBURN JE, 1997, 9701 U ALASKA FAIRBA; Bourne W.R.P., 1981, P119; Breiman L., 1984, CLASSIFICATION REGRE; Brennan L.A., 1986, P177; Buckland S.T., 1993, DISTANCE SAMPLING ES; BURGER AE, 1999, P BIOL MANAGEMENT SP, P723; BURGER A.E., 1995, ECOLOGY CONSERVATION, P295; Burkett E.B, 1995, ECOLOGY CONSERVATION, P223; Burnham K. P., 1999, MODEL SELECTION INFE; Burnham K.P., 2002, MODEL SELECTION MULT; CAIRNS D K, 1987, Biological Oceanography, V5, P261; Campbell R. W., 1990, BIRDS BRIT COLUMBIA, V1; CARTER H.R., 1990, STUD AVIAN BIOL, V14, P93; CARTER HR, 1982, MARINE BIRDS THEIR F, P212; CARTER H.R., 1984, THESIS U MANITOBA WI; CLOERN JE, 1991, J MAR RES, V49, P203, DOI 10.1357/002224091784968611; Croxall J.P., 1988, P261; DEDON MF, 1986, WILDLIFE 2000 MODELL; *DEP FISH ENV, 1978, W COAST OFFSH ENV CA; DICK MH, 1982, SYESIS, V15, P43; DUNBAR MJ, 1973, SCIENCE, V182, P398, DOI 10.1126/science.182.4110.398; DUSTAN P, 1989, LIMNOL OCEANOGR, V34, P410; ENSOR P H, 1979, Notornis, V26, P349; *ESRI, 1996, US ARC VIEW GIS REDL; Fielding AH, 1997, ENVIRON CONSERV, V24, P38, DOI 10.1017/S0376892997000088; FOREMAN MGG, 1995, J GEOPHYS RES-OCEANS, V100, P721, DOI 10.1029/94JC02721; FOREMAN MGG, 1993, J GEOPHYS RES-OCEANS, V98, P2509, DOI 10.1029/92JC02470; Foreman MGG, 1997, J PHYS OCEANOGR, V27, P1300, DOI 10.1175/1520-0485(1997)027<1300:TDMSOT>2.0.CO;2; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Gaston A.J., 1982, Naturaliste Canadien (Quebec), V109, P895; GIRSA II, 1976, J ICHTHYOL, V15, P862; HAMER TE, 1991, RELATIONSHIPS FOREST; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T, 1986, STAT SCI, V1, P297, DOI DOI 10.1214/SS/1177013604; HAY DE, 1999, DISTRIBUTION TIMING; HEDLEY SL, 2000, THESIS U ST ANDREWS; HIRSCH KV, 1981, CONDOR, V83, P264, DOI 10.2307/1367321; HOBSON KA, 1990, CONDOR, V92, P897, DOI 10.2307/1368725; HUETTMANN F, J WILDL MANAG; HUETTMANN F, 2002, MARBLED MURRELETS LA; Huettmann F, 2001, ECOL MODEL, V141, P261, DOI 10.1016/S0304-3800(01)00278-2; HULL CL, 1999, COSEWIC STATUS REPOR; HUNT GL, 1981, E BERING SEA SHELF O, V2, P649; HUNT Jr. G.L., 1995, ECOLOGY CONSERVATION, P219; *INFORAIN, 1998, ECOTRUST; INOUE A, 1967, NAIKAI REGIONAL FISH, V25, P1; JOHNSON D H, 1989, Prairie Naturalist, V21, P193; KAISER GW, 1992, ORNIS SCAND, V23, P1, DOI 10.2307/3676419; KITAKATA M, 1957, B HOKKAIDO REGIONAL, V16, P39; Lek S, 1999, ECOL MODEL, V120, P65, DOI 10.1016/S0304-3800(99)00092-7; LOUGHEED C, 1999, THESIS S FRASER U BU; Manel S, 2001, J APPL ECOL, V38, P921, DOI 10.1046/j.1365-2664.2001.00647.x; MARKOWITZ MA, 1995, CHEM PHYS LIPIDS, V76, P63, DOI 10.1016/0009-3084(94)02430-D; MATTHEWS JB, 1975, J FISH RES BOARD CAN, V32, P1693; McGowan JA, 1998, SCIENCE, V281, P210, DOI 10.1126/science.281.5374.210; MCGURK MD, 1992, 920019 US DEP INT MI; MEYER CB, 1999, THESIS U WYOMING; *MIN ENV LAND PARK, 1999, BC WAT ATL WAT GROUP; MONTEVECCHI WA, 1988, CAN J FISH AQUAT SCI, V45, P568, DOI 10.1139/f88-068; MORGAN KH, 1991, 72 CAN WILDL SERV OT; *NAT OC ATM ADM, 2000, COASTW W COAST REG N; Nelson S. Kim, 1997, Birds of North America, V276, P1; Newton I, 1997, ECOGRAPHY, V20, P137, DOI 10.1111/j.1600-0587.1997.tb00356.x; OConnell M, 1995, BIOL ENVIRON, V95B, P87; O'Connor EJ, 2000, CONSERV BIOL, V14, P904; OCONNOR R, 1997, 62 T N AM WILDL NAT, P501; Ozesmi SL, 1999, ECOL MODEL, V116, P15, DOI 10.1016/S0304-3800(98)00149-5; Pearce J, 2000, ECOL MODEL, V133, P225, DOI 10.1016/S0304-3800(00)00322-7; PEARSON WH, 1984, MAR ENVIRON RES, V11, P17, DOI 10.1016/0141-1136(84)90008-4; PINTO JM, 1984, MAR BIOL, V83, P93; Preisler HK, 1997, FOREST SCI, V43, P71; RALPH CJ, 1995, ECOLOGY CONSERVATION, P3; Raphael M.G., 1986, P129; REVELANTE N, 1976, MAR BIOL, V34, P259, DOI 10.1007/BF00388803; Ripley B, 1996, PATTERN RECOGN, P403; ROBARDS MD, 1999, NWRP521 PORTLAND; Rodway Michael S., 1992, Proceedings of the Western Foundation of Vertebrate Zoology, V5, P17; *SALF SYST, 2001, SOFTW CART MARS SAN; Samson F. B., 2002, PREDICTING SPECIES O; Scardi M, 1996, MAR ECOL PROG SER, V139, P289, DOI 10.3354/meps139289; SEAL PV, 1975, ACTA ORTHOP SCAND, V46, P141; SEALY SG, 1975, CAN J ZOOL, V53, P418, DOI 10.1139/z75-055; SEALY SG, 1974, AUK, V91, P10; SHAW J, 1989, GEOLOGY, V17, P853, DOI 10.1130/0091-7613(1989)017<0853:DSMFAO>2.3.CO;2; Speckman SG, 2000, WATERBIRDS, V23, P364, DOI 10.2307/1522174; *STATSCI, 2000, SPLUS GUID STAT MATH; STEINBERG D, 1999, MARS USER GUIDE SALF; Steinberg D., 1997, CART CLASSIFICATION; STEVENTON JD, 2003, LONGTERM RISKS MARBL; SUTHERLAND WJ, 1982, ESTUAR COAST SHELF S, V14, P223, DOI 10.1016/S0302-3524(82)80047-9; SWARTZMAN G, 1994, ICES J MAR SCI, V51, P481, DOI 10.1006/jmsc.1994.1049; Thomas L, 1997, CONSERV BIOL, V11, P276, DOI 10.1046/j.1523-1739.1997.96102.x; Thomas L, 1996, ECOLOGY, V77, P49, DOI 10.2307/2265653; *US FISH WILDL SER, 1981, 103 ESM; VANHORNE B, 1983, J WILDLIFE MANAGE, V47, P893; Venables W, 1994, MODERN APPL STAT SPL; VENABLES WN, 2002, MODERN APPL STAT SPL; VERMEER K, 1992, ECOLOGY STATUS CONSE, V72, P41; VERMEER K, 1979, IBIS, V121, P348, DOI 10.1111/j.1474-919X.1979.tb06857.x; VERNER J, 1986, WILDLIFE 2000 MODELI, P480; WILSON MF, 1999, PNWRP521, P17; WILSON UW, 1986, CONDOR, V88, P143, DOI 10.2307/1368909; Yin KD, 1997, CAN J FISH AQUAT SCI, V54, P1015, DOI 10.1139/cjfas-54-5-1015	106	29	32	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3800			ECOL MODEL	Ecol. Model.	FEB 1	2004	171	4					395	413		10.1016/j.ecolmodel.2003.07.006		19	Ecology	Environmental Sciences & Ecology	774QJ	WOS:000188994300005		
J	Keysers, D; Macherey, W; Ney, G; Dahmen, J				Keysers, D; Macherey, W; Ney, G; Dahmen, J			Adaptation in statistical pattern recognition using tangent vectors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						statistical pattern recognition; adaptation; tangent vectors; linear models	MODELS	We integrate the tangent method into a statistical framework for classification analytically and practically. The resulting consistent framework for adaptation allows us to efficiently estimate the tangent vectors representing the variability. The framework improves classification results on two real-world pattern recognition tasks from the domains handwritten character recognition and automatic speech recognition.	Rhein Westfal TH Aachen, Aachen Tech Univ, Dept Comp Sci, Lehrstuhl Informat 6, D-52056 Aachen, Germany	Keysers, D (reprint author), Rhein Westfal TH Aachen, Aachen Tech Univ, Dept Comp Sci, Lehrstuhl Informat 6, D-52056 Aachen, Germany.	keysers@informatik.rwth-aachen.de; w.macherey@informatik.rwth-aachen.de; ney@informatik.rwth-aachen.de; dahmen@informatik.rwth-aachen.de					Bishop CM, 1999, ADV NEUR IN, V11, P382; BISHOP C.M., 1995, NEURAL NETWORKS PATT; Dahmen J, 2001, J MATH IMAGING VIS, V14, P285, DOI 10.1023/A:1011242314266; Duda R.O., 2001, PATTERN CLASSIFICATI; EISELE T, 1996, P INT C SPOK LANG PR, V1, P252, DOI 10.1109/ICSLP.1996.607092; Fukunaga K, 1990, INTRO STAT PATTERN R; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T, 1998, STAT SCI, V13, P54; Hinton GE, 1997, IEEE T NEURAL NETWOR, V8, P65, DOI 10.1109/72.554192; Kambhatla N, 1997, NEURAL COMPUT, V9, P1493, DOI 10.1162/neco.1997.9.7.1493; KEYSERS D, 2000, P 22 S GERM ASS PATT, P107; KEYSERS D, 2001, LNCS, V2167, P263; MINKA TP, 2000, ADV NEURAL INFORMATI, V13, P598; Roweis S, 1999, NEURAL COMPUT, V11, P305, DOI 10.1162/089976699300016674; Scholkopf B, 1998, ADV NEUR IN, V10, P640; Simard P., 1993, ADV NEURAL INFORMATI, V5, P50; Simard PY, 1998, LECT NOTES COMPUT SC, V1524, P239; TIPPING ME, 2000, ADV NEURAL INFORMATI, V12, P332; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; WELLING L, 1995, P 1995 EUR C SPEECH, V2, P1483	21	27	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2004	26	2					269	274		10.1109/TPAMI.2004.1262198		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	762DA	WOS:000187954300013	15376902	
J	Glick, M; Klon, AE; Acklin, P; Davies, JW				Glick, M; Klon, AE; Acklin, P; Davies, JW			Enrichment of extremely noisy high-throughput screening data using a naive Bayes classifier	JOURNAL OF BIOMOLECULAR SCREENING			English	Article						high-throughput screening; compound mixtures; molecular similarity; extended-connectivity fingerprints; naive Bayes		The noise level of a high-throughput screening (HTS) experiment depends on various factors such as the quality and robustness of the assay itself and the quality of the robotic platform. Screening of compound mixtures is noisier than screening single compounds per well. A classification model based on naive Bayes (NB) may be used to enrich such data. The authors studied the ability of the NB classifier to prioritize noisy primary HTS data of compound mixtures (5 compounds/well) in 4 campaigns in which the percentage of noise presumed to be inactive compounds ranged between 81% and 91%. The top 10% of the compounds suggested by the classifier captured between 26% and 45% of the active compounds. These results are reasonable and useful, considering the poor quality of the training set and the short computing time that is needed to build and deploy the classifier.	Novartis Inst Biomed Res, Cambridge, MA 02139 USA	Glick, M (reprint author), Novartis Inst Biomed Res, 100 Technol Sq, Cambridge, MA 02139 USA.	meir.glick@pharma.novartis.com					Glick M, 2003, MOL PHYS, V101, P1325, DOI 10.1080/0026897031000099862; Hann M, 1999, J CHEM INF COMP SCI, V39, P897, DOI 10.1021/ci990423o; Hastie T., 2001, ELEMENTS STAT LEARNI; *INS CORP, 2001, INS MIN 2 US GUID; Labute P, 1999, Pac Symp Biocomput, P444; Lipinski CA, 2001, ADV DRUG DELIVER REV, V46, P3, DOI 10.1016/S0169-409X(00)00129-0; MORGAN HL, 1965, J CHEM DOC, V5, P107, DOI 10.1021/c160017a018; Opitz D., 1999, J ARTIFICIAL INTELLI, V11, P169; ROGERS D, UNPUB HIGH THROUGHPU; Witten I.H., 1999, DATA MINING PRACTICA; Zhang JH, 2000, J COMB CHEM, V2, P258, DOI 10.1021/cc9900706	11	54	54	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	1087-0571			J BIOMOL SCREEN	J. Biomol. Screen	FEB	2004	9	1					32	36		10.1177/1087057103260590		5	Biochemical Research Methods; Biotechnology & Applied Microbiology; Chemistry, Analytical	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Chemistry	775GY	WOS:000189033400004	15006146	
J	Wagenmakers, EJ; Ratcliff, R; Gomez, P; Iverson, GJ				Wagenmakers, EJ; Ratcliff, R; Gomez, P; Iverson, GJ			Assessing model mimicry using the parametric bootstrap	JOURNAL OF MATHEMATICAL PSYCHOLOGY			English	Review							BAYESIAN SPECIFICATION ANALYSIS; SHORT-TERM-MEMORY; REACTION-TIME; DIFFUSION-MODEL; CONFIDENCE-INTERVALS; SPEED-ACCURACY; RETRIEVAL DYNAMICS; REGRESSION-MODELS; SELECTION; INFORMATION	We present a general sampling procedure to quantify model mimicry, defined as the ability of a model to account for data generated by a competing model. This sampling procedure, called the parametric bootstrap cross-fitting method (PBCM; cf. Williams (J. R. Statist. Soc. B 32 (1970) 350; Biometrics 26 (1970) 23)), generates distributions of differences in goodness-of-fit expected under each of the competing models. In the data informed version of the PBCM, the generating models have specific parameter values obtained by fitting the experimental data under consideration. The data informed difference distributions can be compared to the observed difference in goodness-of-fit to allow a quantification of model adequacy. In the data uninformed version of the PBCM, the generating models have a relatively broad range of parameter values based on prior knowledge. Application of both the data informed and the data uninformed PBCM is illustrated with several examples. (C) 2003 Elsevier Inc. All rights reserved.	Northwestern Univ, Evanston, IL 60208 USA; De Paul Univ, Chicago, IL 60614 USA; Univ Calif Irvine, Irvine, CA 92717 USA	Wagenmakers, EJ (reprint author), Univ Amsterdam, Dept Dev Psychol, Roetersstr 15,Room 1001, NL-1018 WB Amsterdam, Netherlands.	ej@northwestern.edu	Gomez, Pablo/A-8157-2012	Gomez, Pablo/0000-0003-4180-1560			Aitchison J., 1975, STAT PREDICTION ANAL; AITKIN M, 1991, J ROY STAT SOC B MET, V53, P111; Akaike H., 1973, P 2 INT S INF THEOR; Anderson J. R., 1998, ATOMIC COMPONENTS TH; ANDERSON NH, 1981, FDN INFORMATION INTE; Andrews DWK, 2000, ECONOMETRICA, V68, P23, DOI 10.1111/1468-0262.00092; Atkinson R. C., 1965, INTRO MATH LEARNING; BERGER JO, 1985, STAT DECISION THOERY; BERKHOF J, IN PRESS STAT SINICA; Bollback JP, 2002, MOL BIOL EVOL, V19, P1171; BOLLEN KA, 1992, SOCIOL METHOD RES, V21, P205, DOI 10.1177/0049124192021002004; BOX GEP, 1980, J ROY STAT SOC A STA, V143, P383, DOI 10.2307/2982063; Burnham K.P., 2002, MODEL SELECTION MULT; BUSH RR, 1955, STOCHASTIC MODELS LE; COLLYER CE, 1985, PERCEPT PSYCHOPHYS, V38, P476, DOI 10.3758/BF03207179; CORBETT AT, 1977, J VERB LEARN VERB BE, V16, P233, DOI 10.1016/S0022-5371(77)80049-2; COX DR, 1962, J ROY STAT SOC B, V24, P406; CROWTHER CS, 1995, PSYCHOL REV, V102, P396, DOI 10.1037//0033-295X.102.2.396; CUTTING JE, 1992, J EXP PSYCHOL GEN, V121, P364; Cutting JE, 2000, J MATH PSYCHOL, V44, P3, DOI 10.1006/jmps.1999.1274; Davidson AC, 1997, BOOTSTRAP METHODS TH; Davidson K, 2000, HEALTH PSYCHOL, V19, P55, DOI 10.1037//0278-6133.19.1.55; DICICCIO TJ, 1988, J ROY STAT SOC B MET, V50, P338; Djuric PM, 1998, IEEE T SIGNAL PROCES, V46, P2726, DOI 10.1109/78.720374; DOSHER BA, 1981, COGNITIVE PSYCHOL, V13, P551, DOI 10.1016/0010-0285(81)90020-7; Dunn JC, 2000, PSYCHOL RES-PSYCH FO, V63, P174, DOI 10.1007/PL00008176; EDWARDS W, 1963, PSYCHOL REV, V70, P193, DOI 10.1037/h0044139; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Efron B., 1986, STAT SCI, V1, P54, DOI DOI 10.1214/SS/1177013815; Efron Bradley, 1993, INTRO BOOTSTRAP; Estes WK, 2002, PSYCHON B REV, V9, P3, DOI 10.3758/BF03196254; ESTES WK, 1956, PSYCHOL BULL, V53, P134, DOI 10.1037/h0045156; Feng ZD, 1996, J ROY STAT SOC B MET, V58, P609; Gelman A, 2000, J ROY STAT SOC C-APP, V49, P247, DOI 10.1111/1467-9876.00190; Geweke J., 1999, ECONOMET REV, V18, P1, DOI 10.1080/07474939908800428; Geweke J, 2001, AM J AGR ECON, V83, P1181, DOI 10.1111/0002-9092.00264; Geweke J., 1999, BAYESIAN STAT, V6, P275; GOLDEN RM, 1995, J MATH PSYCHOL, V39, P3, DOI 10.1006/jmps.1995.1002; Golden RM, 2003, PSYCHOMETRIKA, V68, P229, DOI 10.1007/BF02294799; GREEN DM, 1966, SIGNAL DETECTION THE; Grunwald P, 2000, J MATH PSYCHOL, V44, P133, DOI 10.1006/jmps.1999.1280; HALL P, 1988, ANN STAT, V16, P927, DOI 10.1214/aos/1176350933; HALL P, 1991, BIOMETRICS, V47, P757, DOI 10.2307/2532163; Hall P. G., 1992, BOOTSTRAP EDGEWORTH; Hastie T., 2001, ELEMENTS STAT LEARNI; HINKLEY DV, 1988, J ROY STAT SOC B MET, V50, P321; Horowitz J., 2001, HDB ECONOMETRICS, V5, P3159, DOI 10.1016/S1573-4412(01)05005-X; Kass RE, 1996, J AM STAT ASSOC, V91, P1343, DOI 10.2307/2291752; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572; LAUD PW, 1995, J ROY STAT SOC B MET, V57, P247; MASSARO DW, 1988, J MEM LANG, V27, P213, DOI 10.1016/0749-596X(88)90074-5; MASSARO DW, 1990, PSYCHOL REV, V97, P225, DOI 10.1037//0033-295X.97.2.225; Massaro D.W., 1998, PERCEIVING TALKING F; Massaro DW, 2001, PSYCHON B REV, V8, P1, DOI 10.3758/BF03196136; MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0; MCELREE B, 1993, J EXP PSYCHOL GEN, V122, P291; McElree B, 1999, J EXP PSYCHOL HUMAN, V25, P1517, DOI 10.1037/0096-1523.25.6.1517; MCELREE B, 1989, J EXP PSYCHOL GEN, V118, P346, DOI 10.1037//0096-3445.118.4.346; MCLACHLAN GJ, 1987, APPL STAT-J ROY ST C, V36, P318, DOI 10.2307/2347790; MENG XL, 1994, ANN STAT, V22, P1142, DOI 10.1214/aos/1176325622; METROPOLIS N, 1949, J AM STAT ASSOC, V44, P335, DOI 10.2307/2280232; Movellan JR, 2001, PSYCHOL REV, V108, P113, DOI 10.1037//0033-295X.108.1.113; MYUNG IJ, 2002, 1 ANN SUMM INT C SQU; Myung IJ, 1997, PSYCHON B REV, V4, P79, DOI 10.3758/BF03210778; Myung IJ, 2000, J MATH PSYCHOL, V44, P1, DOI 10.1006/jmps.1999.1273; Navarro D. J., 2003, P 25 ANN C COGN SCI; NAVARRO DJ, 2003, UNPUB ASSESSING DIST; ODEN GC, 1978, PSYCHOL REV, V85, P172, DOI 10.1037/0033-295X.85.3.172; PARZEN E, 1998, SELECTED PAPERS HIRO; Pitt MA, 2002, PSYCHOL REV, V109, P472, DOI 10.1037//0033-295X.109.3.472; Pitt MA, 2003, PSYCHON B REV, V10, P29, DOI 10.3758/BF03196467; Press W. H., 1986, NUMERICAL RECIPES; Raftery AE, 1995, SOCIOL METHODOL, V25, P111, DOI 10.2307/271063; RATCLIFF R, 1988, PSYCHOL REV, V95, P238, DOI 10.1037/0033-295X.95.2.238; RATCLIFF R, 1978, PSYCHOL REV, V85, P59, DOI 10.1037//0033-295X.85.2.59; RATCLIFF R, 1979, PSYCHOL BULL, V86, P446, DOI 10.1037/0033-2909.86.3.446; RATCLIFF R, IN PRESS PSYCHOL REV; RATCLIFF R, 1993, PSYCHOL BULL, V114, P510, DOI 10.1037/0033-2909.114.3.510; Ratcliff R, 2003, PERCEPT PSYCHOPHYS, V65, P523, DOI 10.3758/BF03194580; Ratcliff R, 2001, PSYCHOL AGING, V16, P323, DOI 10.1037//0882-7974.16.2.323; RATCLIFF R, 1984, 17 ANN MATH PSYCH M; Ratcliff R, 2002, PSYCHON B REV, V9, P438, DOI 10.3758/BF03196302; Ratcliff R, 2000, J EXP PSYCHOL HUMAN, V26, P127, DOI 10.1037/0096-1523.26.1.127; RATCLIFF R, 1988, J MATH PSYCHOL, V32, P192, DOI 10.1016/0022-2496(88)90045-4; Ratcliff R, 1998, PSYCHOL SCI, V9, P347, DOI 10.1111/1467-9280.00067; REED AV, 1976, MEM COGNITION, V4, P16, DOI 10.3758/BF03213250; Rissanen J, 2001, IEEE T INFORM THEORY, V47, P1712, DOI 10.1109/18.930912; Rissanen JJ, 1996, IEEE T INFORM THEORY, V42, P40, DOI 10.1109/18.481776; RUBIN DB, 1981, ANN STAT, V9, P130, DOI 10.1214/aos/1176345338; RUBIN DB, 1984, ANN STAT, V12, P1151, DOI 10.1214/aos/1176346785; RUBIN DB, 1994, LATENT VARIABLE ANAL; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SIVLERMAN BW, 1986, DENSITY ESTIMATION S; Stuart A., 1991, KENDALLS ADV THEORY, V2; Thapar A, 2003, PSYCHOL AGING, V18, P415, DOI 10.1037/0882-7974.18.3.415; Thurman WN, 2001, AM J AGR ECON, V83, P1187, DOI 10.1111/0002-9092.00265; TOWNSEND JT, 1972, BRIT J MATH STAT PSY, V25, P168; Usher M, 2001, PSYCHOL REV, V108, P550, DOI 10.1037//0033-295X.108.3.550; Van Zandt T., 2002, STEVENS HDB EXPT PSY, V4, P461; VANZANDT T, 1995, PSYCHON B REV, V2, P20, DOI 10.3758/BF03214411; von Neumann J., 1951, NBS APPL MATH SER, V12, P36; VUONG QH, 1989, ECONOMETRICA, V57, P307, DOI 10.2307/1912557; WAGENMAKERS EJ, IN PRESS BIOMETRICS; WAGENMAKERS EM, IN PRESS PSYCHONOMIC; Wasserman L, 2000, J MATH PSYCHOL, V44, P92, DOI 10.1006/jmps.1999.1278; Wichmann FA, 2001, PERCEPT PSYCHOPHYS, V63, P1314, DOI 10.3758/BF03194545; WICKELGREN WA, 1976, PSYCHOL REV, V83, P466, DOI 10.1037//0033-295X.83.6.466; WICKELGREN WA, 1977, ACTA PSYCHOL, V41, P67, DOI 10.1016/0001-6918(77)90012-9; WICKELGREN WA, 1980, J VERB LEARN VERB BE, V19, P387, DOI 10.1016/S0022-5371(80)90276-5; Wilks SS, 1938, ANN MATH STAT, V9, P60, DOI 10.1214/aoms/1177732360; WILLIAMS DA, 1970, J R STAT SOC B, V32, P350; WILLIAMS DA, 1970, BIOMETRICS, V26, P23, DOI 10.2307/2529041	112	55	55	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0022-2496			J MATH PSYCHOL	J. Math. Psychol.	FEB	2004	48	1					28	50		10.1016/j.jmp.2003.11.004		23	Mathematics, Interdisciplinary Applications; Social Sciences, Mathematical Methods; Psychology, Mathematical	Mathematics; Mathematical Methods In Social Sciences; Psychology	800DT	WOS:000220009800004		
J	Iakoucheva, LM; Radivojac, P; Brown, CJ; O'Connor, TR; Sikes, JG; Obradovic, Z; Dunker, AK				Iakoucheva, LM; Radivojac, P; Brown, CJ; O'Connor, TR; Sikes, JG; Obradovic, Z; Dunker, AK			The importance of intrinsic disorder for protein phosphorylation	NUCLEIC ACIDS RESEARCH			English	Article							SECONDARY STRUCTURE PREDICTION; CRYSTAL-STRUCTURE; UNSTRUCTURED PROTEINS; SEQUENCE COMPLEXITY; PEPTIDE SUBSTRATE; GLOBULAR-PROTEINS; TYROSINE KINASE; WIDE PREDICTION; BINDING; ALIGNMENTS	Reversible protein phosphorylation provides a major regulatory mechanism in eukaryotic cells. Due to the high variability of amino acid residues flanking a relatively limited number of experimentally identified phosphorylation sites, reliable prediction of such sites still remains an important issue. Here we report the development of a new web-based tool for the prediction of protein phosphorylation sites, DISPHOS (DiSorder-enhanced PHOSphorylation predictor, hftp://www.ist.temple.edu/DISPHOS). We observed that amino acid compositions, sequence complexity, hydrophobicity, charge and other sequence attributes of regions adjacent to phosphorylation sites are very similar to those of intrinsically disordered protein regions. Thus, DISPHOS uses position-specific amino acid frequencies and disorder information to improve the discrimination between phosphorylation and nonphosphorylation sites. Based on the estimates of phosphorylation rates in various protein categories, the outputs of DISPHOS are adjusted in order to reduce the total number of misclassified residues. When tested on an equal number of phosphorylated and non-phosphorylated residues, the accuracy of DISPHOS reaches 76% for serine, 81% for threonine and 83% for tyrosine. The significant enrichment in disorder-promoting residues surrounding phosphorylation sites together with the results obtained by applying DISPHOS to various protein functional classes and proteomes, provide strong support for the hypothesis that protein phosphorylation predominantly occurs within intrinsically disordered protein regions.	Washington State Univ, Sch Mol Biosci, Pullman, WA 99164 USA; Temple Univ, Ctr Informat Sci & Technol, Philadelphia, PA 19122 USA	Dunker, AK (reprint author), Indiana Univ, Sch Med, Ctr Computat Biol & Bioinformat, Indianapolis, IN 46202 USA.	kedunker@iupui.edu					ALEX LA, 1994, TRENDS GENET, V10, P133, DOI 10.1016/0168-9525(94)90215-1; Belsley David A., 1980, REGRESSION DIAGNOSTI; Bienkiewicz EA, 2002, BIOCHEMISTRY-US, V41, P752, DOI 10.1021/bi015763t; BISHOP C.M., 1995, NEURAL NETWORKS PATT; Blom N, 1999, J MOL BIOL, V294, P1351, DOI 10.1006/jmbi.1999.3310; Bossel H, 2002, CONSERV ECOL, V5; Dunker AK, 2002, BIOCHEMISTRY-US, V41, P6573, DOI 10.1021/bi012159+; Dyson HJ, 2002, CURR OPIN STRUC BIOL, V12, P54, DOI 10.1016/S0959-440X(02)00289-0; Efron Bradley, 1993, INTRO BOOTSTRAP; EISENBERG D, 1984, ANNU REV BIOCHEM, V53, P595; EISENBERG D, 1984, P NATL ACAD SCI-BIOL, V81, P140, DOI 10.1073/pnas.81.1.140; Falquet L, 2002, NUCLEIC ACIDS RES, V30, P235, DOI 10.1093/nar/30.1.235; Fontana A., 1993, PROTEIN STABILITY ST, P101; Fontana A, 1997, J MOL BIOL, V266, P223, DOI 10.1006/jmbi.1996.0787; Gould C, 2002, PHARMACOL THERAPEUT, V93, P169, DOI 10.1016/S0163-7258(02)00186-9; Hastie T., 2001, ELEMENTS STAT LEARNI; Hauer JA, 1999, BIOCHEMISTRY-US, V38, P6774, DOI 10.1021/bi983074k; Hay TJ, 2000, FEBS LETT, V478, P183, DOI 10.1016/S0014-5793(00)01850-0; Haykin S., 1999, NEURAL NETWORKS COMP; HUBBARD SJ, 1994, PROTEIN SCI, V3, P757; Hubbard SR, 1997, EMBO J, V16, P5572, DOI 10.1093/emboj/16.18.5572; HUNTER T, 1984, ADV CYCLIC NUCL PROT, V17, P443; Iakoucheva LM, 2002, J MOL BIOL, V323, P573, DOI 10.1016/S0022-2836(02)00969-5; JANIN J, 1979, NATURE, V277, P491, DOI 10.1038/277491a0; Johnson LN, 2001, CHEM REV, V101, P2209, DOI 10.1021/cr000225s; Kriwacki RW, 1996, P NATL ACAD SCI USA, V93, P11504, DOI 10.1073/pnas.93.21.11504; Kubat M, 1998, MACH LEARN, V30, P195, DOI 10.1023/A:1007452223027; Kubat M., 1997, P 14 INT C MACH LEAR, P179; Leonard CJ, 1998, GENOME RES, V8, P1038; Lowe ED, 1997, EMBO J, V16, P6646, DOI 10.1093/emboj/16.22.6646; Manning G, 2002, SCIENCE, V298, P1912, DOI 10.1126/science.1075762; Marks F., 1996, PROTEIN PHOSPHORYLAT; MCDONALD IK, 1994, J MOL BIOL, V238, P777, DOI 10.1006/jmbi.1994.1334; Narayana N, 1997, BIOCHEMISTRY-US, V36, P4438, DOI 10.1021/bi961947+; Nigg E A, 1991, Semin Cell Biol, V2, P261; Obenauer JC, 2003, NUCLEIC ACIDS RES, V31, P3635, DOI 10.1093/nar/gkg584; Ojala PM, 2000, NAT CELL BIOL, V2, P819, DOI 10.1038/35041064; Qian N, 1988, J MOL BIOL, V202, P865, DOI 10.1016/0022-2836(88)90564-5; Radivojac P., 2003, PAC S BIOC, V8, P216; Radivojac P, 2004, PROTEIN SCI, V13, P71, DOI 10.1110/ps.03128904; Rechsteiner M, 1996, TRENDS BIOCHEM SCI, V21, P267, DOI 10.1016/S0968-0004(96)10031-1; Romero P, 1999, FEBS LETT, V462, P363, DOI 10.1016/S0014-5793(99)01557-4; Romero P, 2001, PROTEINS, V42, P38, DOI 10.1002/1097-0134(20010101)42:1<38::AID-PROT50>3.0.CO;2-3; ROST B, 1994, COMPUT APPL BIOSCI, V10, P53; Rost B, 1999, PROTEIN ENG, V12, P85, DOI 10.1093/protein/12.2.85; Saerens M, 2002, NEURAL COMPUT, V14, P21, DOI 10.1162/089976602753284446; Salamov AA, 1997, J MOL BIOL, V268, P31, DOI 10.1006/jmbi.1997.0958; SALAMOV AA, 1995, J MOL BIOL, V247, P11, DOI 10.1006/jmbi.1994.0116; Schulz GE, 1979, MOL MECH BIOL RECOGN, P79; Songyang Zhou, 1994, Current Biology, V4, P973, DOI 10.1016/S0960-9822(00)00221-9; SWEET RM, 1983, J MOL BIOL, V171, P479, DOI 10.1016/0022-2836(83)90041-4; ter Haar E, 2001, NAT STRUCT BIOL, V8, P593, DOI 10.1038/89624; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P769; Vetter SW, 2001, EUR J BIOCHEM, V268, P4292, DOI 10.1046/j.1432-1327.2001.02347.x; VIHINEN M, 1994, PROTEINS, V19, P141, DOI 10.1002/prot.340190207; VUCETIC S, 2001, LECT NOTES COMPUTER, V2167, P527; Vucetic S, 2003, PROTEINS, V52, P573, DOI 10.1002/prot.10437; WOOTTON JC, 1993, COMPUT CHEM, V17, P149, DOI 10.1016/0097-8485(93)85006-X; Wright PE, 1999, J MOL BIOL, V293, P321, DOI 10.1006/jmbi.1999.3110; Xie Q., 1998, GENOME INFORMATICS, V9, P193; Yaffe MB, 2001, NAT BIOTECHNOL, V19, P348, DOI 10.1038/86737; Zhou HL, 2001, NAT BIOTECHNOL, V19, P375, DOI 10.1038/86777; ZHOU SY, 1995, TRENDS BIOCHEM SCI, V20, P470; Zor T, 2002, J BIOL CHEM, V277, P42241, DOI 10.1074/jbc.M207361200	64	438	447	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0305-1048			NUCLEIC ACIDS RES	Nucleic Acids Res.	FEB	2004	32	3					1037	1049		10.1093/nar/gkh253		13	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	807GQ	WOS:000220490400017	14960716	
J	Wagenmakers, EJ; Farrell, S				Wagenmakers, EJ; Farrell, S			AIC model selection using Akaike weights	PSYCHONOMIC BULLETIN & REVIEW			English	Editorial Material							INFORMATION CRITERION; CATEGORIZATION; IDENTIFICATION; INFERENCE; ATTENTION		Northwestern Univ, Evanston, IL USA	Wagenmakers, EJ (reprint author), Univ Amsterdam, Dept Psychol, Roetersstr 15, NL-1018 WB Amsterdam, Netherlands.	ewagenmakers@fmg.uva.nl; simon.farrell@bristol.ac.uk	Farrell, Simon/H-3266-2011	Farrell, Simon/0000-0001-7452-8789			Aitchison J., 1975, STAT PREDICTION ANAL; AKAIKE H, 1987, PSYCHOMETRIKA, V52, P317, DOI 10.1007/BF02294359; AKAIKE H, 1978, STATISTICIAN, V27, P217, DOI 10.2307/2988185; Akaike H, 1973, P 2 INT S INF THEOR, P267; Akaike H, 1983, INT STAT I, V44, P277; AKAIKE H, 1979, BIOMETRIKA, V66, P237; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Boltzmann L., 1877, WIEN BER, V76, P373; BOZDOGAN H, 1987, PSYCHOMETRIKA, V52, P345, DOI 10.1007/BF02294361; Buckland ST, 1997, BIOMETRICS, V53, P603, DOI 10.2307/2533961; Burnham K.P., 2002, MODEL SELECTION MULT; Burnham KP, 2001, WILDLIFE RES, V28, P111, DOI 10.1071/WR99107; EFRON B, 1986, J AM STAT ASSOC, V81, P416; Eid M, 1999, PSYCHOL METHODS, V4, P100, DOI 10.1037/1082-989X.4.1.100; Eliason S. R., 1993, MAXIMUM LIKELIHOOD E; Golan A, 2002, J ECONOMETRICS, V107, P1, DOI 10.1016/S0304-4076(01)00110-5; Hastie T., 2001, ELEMENTS STAT LEARNI; HURVICH CM, 1995, BIOMETRICS, V51, P1077, DOI 10.2307/2533006; Joreskog K., 1996, LISREL 8 USERS REFER; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Maddox WT, 2001, MEM COGNITION, V29, P598, DOI 10.3758/BF03200461; MADDOX WT, 1993, PERCEPT PSYCHOPHYS, V53, P49, DOI 10.3758/BF03211715; McQuarrie A. D., 1998, REGRESSION TIME SERI; Myung IJ, 1997, PSYCHON B REV, V4, P79, DOI 10.3758/BF03210778; Nosofsky RM, 1998, J EXP PSYCHOL HUMAN, V24, P322, DOI 10.1037/0096-1523.24.1.322; PARZEN E, 1998, SELECTED PAPERS HIRO; Ploeger A, 2002, PSYCHON B REV, V9, P26, DOI 10.3758/BF03196255; Raijmakers MEJ, 2001, MEM COGNITION, V29, P659, DOI 10.3758/BF03200469; Royall Richard, 1997, STAT EVIDENCE LIKELI; SAKAMOTO Y, 1986, AKAIKE INFORMATION C; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Smith PL, 1998, J EXP PSYCHOL HUMAN, V24, P105, DOI 10.1037/0096-1523.24.1.105; Spiegelhalter D., 2002, J ROYAL STAT SOC B, V64, P1; SUGIURA N, 1978, COMMUN STAT A-THEOR, V7, P13, DOI 10.1080/03610927808827599; TAKANE Y, 1987, PSYCHOMETRIKA, V52; Thomas RD, 2001, PERCEPT PSYCHOPHYS, V63, P625, DOI 10.3758/BF03194426; Wasserman L, 2000, J MATH PSYCHOL, V44, P92, DOI 10.1006/jmps.1999.1278	38	234	238	PSYCHONOMIC SOC INC	AUSTIN	1710 FORTVIEW RD, AUSTIN, TX 78704 USA	1069-9384			PSYCHON B REV	Psychon. Bull. Rev.	FEB	2004	11	1					192	196		10.3758/BF03206482		5	Psychology, Mathematical; Psychology, Experimental	Psychology	809ZI	WOS:000220674200028	15117008	
J	Alimonti, C; Falcone, G				Alimonti, C; Falcone, G			Integration of multiphase flowmetering, neural networks, and fuzzy logic in field performance monitoring	SPE PRODUCTION & FACILITIES			English	Article; Proceedings Paper	2002 SPE Annual Technical Conference and Exhibition	SEP 29-OCT 02, 2002	SAN ANTONIO, TEXAS	Soc Petr Engineers				The usual approach to the interpretation of producing wells is based on mechanistic models for the simulation of steady-state and transient flow regimes. However, there are significant reservations about convergence problems, computational limits, the need for extensive tuning on field data, the instability of boundary conditions. the limited applicability of existing multiphase flow models, and the uncertainties associated with choke-valve models. The current industry standards are critically reviewed within this framework. The real-time monitoring of producing wells is recognized as the best way of optimizing field performance. Monitoring a producing well implies the ability to track any changes in fluid composition, flow rates, or pressure and temperature profiles in real time. Multiphase flowmetering (MFM) plays a key role in this scenario. Such information, combined with the critical analysis of historical data from the well itself or from analog wells, allows diagnosis of the system and prediction of future trends. However, field data per se do not necessarily generate knowledge. This is particularly true for large databases, which are difficult to manipulate to provide suitable inputs for wellbore simulators. This paper suggests how MFM, knowledge discovery in databases (KDD), and fuzzy logic (FL) can offer an alternative approach to analyzing producing wells. KDD is the automated extraction of patterns representing knowledge implicitly stored in large information repositories. Distributed, ad hoc field measurements (including MFM and downhole measurements) can be processed by means of data cleaning, data integration, data mining, artificial intelligence (AI), and pattern evaluation. FL can then manage the resulting information in terms of flow assurance and production optimization. The same techniques can also be extended to the reservoir and production network for an integrated approach to production-system analysis.	Univ Roma La Sapienza, Rome, Italy; Enterprise Oil UK Plc, Aberdeen, Scotland	Alimonti, C (reprint author), Univ Roma La Sapienza, Rome, Italy.	claudio.alimonti@uniroma1.it; gioia.falcone@total.com					ALI JK, 1994 SPE EUR PETR CO; ALIMONTI C, 2001 4 INT C MULT FL; ALIMONTI C, 2001 10 INT C MULT B; ANNUNZIATO M, 2000 7 INT C MULT FL; BOE HS, 2000 SPE EUR PETR C; FALCONE G, 2001 SPE ANN TECHN C; Fang JH, 1997, J PETROL GEOL, V20, P185, DOI 10.1111/j.1747-5457.1997.tb00772.x; GUAITA P, 1999 SPE ANN TECHN C; Han J., 2001, DATA MINING CONCEPTS; Hastie T., 2001, ELEMENTS STAT LEARNI; HUNT AP, 2001 10 INT C MULT B; JANSEN B, 1999 SPE ANN TECHN C; LOPEZ D, 1998 SPE INT PETR C; MURRAY A, 1999 SPE OFFSH EUR C; ROGERS SJ, 1995, PREDICTING PREMEABIL; Ross TJ, 1995, FUZZY LOGIC ENG APPL; SCHIOZER DJ, 1994 SPE W REG M LON; SCHIOZER DJ, 1993, SPE; Toral H., 1998, N SEA FLOW MEAS WORK; VAZQUEZ M, 2001 SPE ANN TECHN C; XU ZG, 2001 10 INT C MULT B; Zaheh L.A., 1965, INFORM CONTR, V8, P338	22	6	6	SOC PETROLEUM ENG	RICHARDSON	222 PALISADES CREEK DR,, RICHARDSON, TX 75080 USA	1064-668X			SPE PROD FACIL	SPE Prod. Fac.	FEB	2004	19	1					25	32				8	Engineering, Petroleum	Engineering	778GP	WOS:000189231400004		
J	Titterington, DM				Titterington, DM			Bayesian methods for neural networks and related models	STATISTICAL SCIENCE			English	Article						Bayesian methods; Bayesian model choice; feed-forward neural network; graphical model; Laplace approximation; machine learning; Markov chain Monte Carlo; variational approximation	RELEVANCE VECTOR MACHINE; SELF-ORGANIZING MAPS; HYBRID MONTE-CARLO; EVIDENCE FRAMEWORK; HIERARCHICAL MIXTURES; PARAMETER-ESTIMATION; GAUSSIAN-PROCESSES; EM ALGORITHM; SELECTION; CLASSIFIERS	Models such as feed-forward neural networks and certain other structures investigated in the computer science literature are not amenable to closed-form Bayesian analysis. The paper reviews the various approaches taken to overcome this difficulty, involving the use of Gaussian approximations, Markov chain Monte Carlo simulation routines and a class of non-Gaussian but "deterministic" approximations called variational approximations.	Univ Glasgow, Dept Stat, Glasgow G12 8QQ, Lanark, Scotland	Titterington, DM (reprint author), Univ Glasgow, Dept Stat, Glasgow G12 8QQ, Lanark, Scotland.	mike@stats.gla.ac.uk					Andrieu C, 2000, ADV NEUR IN, V12, P379; Andrieu C, 2001, NEURAL COMPUT, V13, P2359, DOI 10.1162/089976601750541831; Archer GEB, 2002, J STAT PLAN INFER, V108, P365, DOI 10.1016/S0378-3758(02)00318-X; Attias H, 1999, NEURAL COMPUT, V11, P803, DOI 10.1162/089976699300016458; Attias H, 2000, ADV NEUR IN, V12, P209; Attias H, 1999, P 15 C UNC ART INT, P21; Barber D., 1998, Neural Networks and Machine Learning. Proceedings; Berger JO, 1985, STAT DECISION THEORY; Bishop CM, 2003, ADV NEURAL INFORM PR, V15, P793; Bishop C.M., 2000, P 16 C UNC ART INT, P46; Bishop CM, 1998, NEUROCOMPUTING, V21, P203, DOI 10.1016/S0925-2312(98)00043-5; Bishop CM, 1998, ADV NEUR IN, V10, P416; BISHOP C.M., 1995, NEURAL NETWORKS PATT; BISHOP CM, 1999, P 9 INT C ART NEUR N, V1, P509; Buntine W. L., 1991, Complex Systems, V5; Chan KL, 2003, NEURAL COMPUT, V15, P1991, DOI 10.1162/08997660360675116; Chen S, 2001, IEEE T NEURAL NETWOR, V12, P1529, DOI 10.1109/72.963792; CHENG B, 1994, STAT SCI, V9, P2, DOI 10.1214/ss/1177010638; CHOUDREY R, 2001, PARG0103 U OXF DEP E; CHU W, 2001, CD0115 NATL U SING; Corden LD, 2001, CELL ADHES COMMUN S, V8, P27; Csiszar I., 1984, STATISTICS DECISIO S, V1, P205; de Freitas N., 2001, P 17 C UNC ART INT, P120; de Freitas JFG, 2000, NEURAL COMPUT, V12, P955; DUANE S, 1987, PHYS LETT B, V195, P216, DOI 10.1016/0370-2693(87)91197-X; Edwards PJ, 1999, IEEE T NEURAL NETWOR, V10, P1456, DOI 10.1109/72.809090; GEIGER D, 1999, LEARNING GRAPHICAL M, P461; Gencay R, 2001, IEEE T NEURAL NETWOR, V12, P726, DOI 10.1109/72.935086; Ghahramani Z, 2000, ADV NEUR IN, V12, P449; Ghahramani Z, 1997, MACH LEARN, V29, P245, DOI 10.1023/A:1007425814087; Ghahramani Z, 2001, ADV NEUR IN, V13, P507; Gibbs MN, 2000, IEEE T NEURAL NETWOR, V11, P1458, DOI 10.1109/72.883477; Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711; Hall P, 2002, J ROY STAT SOC B, V64, P549, DOI 10.1111/1467-9868.00350; Hastie T., 2001, ELEMENTS STAT LEARNI; Heckerman D, 1999, LEARNING GRAPHICAL M, P301; Hinton G. E., 1993, Proceeding of the Sixth Annual ACM Conference on Computational Learning Theory, DOI 10.1145/168304.168306; Holmes CC, 1998, NEURAL COMPUT, V10, P1217, DOI 10.1162/089976698300017421; HUMPHREYS K, 2000, P COMP STAT 2000, P331; HUMPHREYS K, 2001, ADV MEAN FIELD METHO, P179; Humphreys K, 2000, NEURAL PROCESS LETT, V12, P183, DOI 10.1023/A:1009617914949; Husmeier D, 1999, NEURAL NETWORKS, V12, P677, DOI 10.1016/S0893-6080(99)00020-9; Husmeier D, 2000, NEURAL COMPUT, V12, P2685, DOI 10.1162/089976600300014890; Jaakkola T. S., 2001, ADV MEAN FIELD METHO, p[129, 860]; Jaakkola TS, 2000, STAT COMPUT, V10, P25, DOI 10.1023/A:1008932416310; Jacobs RA, 1997, NEURAL NETWORKS, V10, P231, DOI 10.1016/S0893-6080(96)00050-0; Jordan M., 1999, LEARNING GRAPHICAL M; Jordan M. I., 1999, LEARNING GRAPHICAL M, P105; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; KAY JW, 1999, STAT NEURAL NETWORKS; Konishi S, 2004, BIOMETRIKA, V91, P27, DOI 10.1093/biomet/91.1.27; Kwok JTY, 1999, IEEE T NEURAL NETWOR, V10, P1018, DOI 10.1109/72.788642; Kwok JTY, 2000, IEEE T NEURAL NETWOR, V11, P1162, DOI 10.1109/72.870047; Lampinen J, 2001, NEURAL NETWORKS, V14, P257, DOI 10.1016/S0893-6080(00)00098-8; Lee HKH, 2001, J CLASSIF, V18, P227; Lee HKH, 2003, MACH LEARN, V50, P197, DOI 10.1023/A:1020258113913; Leisink MAR, 2001, NEURAL COMPUT, V13, P2149, DOI 10.1162/089976601750399344; LUTTRELL SP, 1994, NEURAL COMPUT, V6, P767, DOI 10.1162/neco.1994.6.5.767; MACKAY DJC, 1995, NETWORK-COMP NEURAL, V6, P469, DOI 10.1088/0954-898X/6/3/011; MacKay D. J. C., 1997, ENSEMBLE LEARNING HI; MACKAY DJC, 1992, NEURAL COMPUT, V4, P448, DOI 10.1162/neco.1992.4.3.448; MacKay DJC, 1999, NEURAL COMPUT, V11, P1035, DOI 10.1162/089976699300016331; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.415; MACKAY DJC, 1992, NEURAL COMPUT, V4, P720, DOI 10.1162/neco.1992.4.5.720; Medeiros MC, 2001, IEEE T NEURAL NETWOR, V12, P755, DOI 10.1109/72.935089; Meng XL, 1997, J ROY STAT SOC B MET, V59, P511, DOI 10.1111/1467-9868.00082; Miskin J, 2000, PERSP NEURAL COMP, P123; MOODY JE, 1992, ADV NEUR IN, V4, P847; Muller P, 1998, NEURAL COMPUT, V10, P749, DOI 10.1162/089976698300017737; Neal R, 1999, LEARNING GRAPHICAL M, P355; Neal R. M., 1996, BAYESIAN LEARNING NE; Opper M., 2001, ADV MEAN FIELD METHO; Paige RL, 2001, BIOMETRIKA, V88, P623, DOI 10.1093/biomet/88.3.623; PENG F, 1996, J AM STAT ASSOC, V91, P9535; Penny WD, 1999, NEURAL NETWORKS, V12, P877, DOI 10.1016/S0893-6080(99)00040-4; RIPLEY BD, 1994, J ROY STAT SOC B MET, V56, P409; Ripley BD, 1996, PATTERN RECOGNITION; RIPLEY BD, 1995, PROBABILISTIC REASON, P97; Sato M, 2001, NEURAL COMPUT, V13, P1649, DOI 10.1162/089976601750265045; Seeger M, 2000, ADV NEUR IN, V12, P603; Sommer FT, 1998, IEEE T NEURAL NETWOR, V9, P705, DOI 10.1109/72.701183; Spiegelhalter DJ, 2002, J ROY STAT SOC B, V64, P583, DOI 10.1111/1467-9868.00353; Tanaka K, 2003, J PHYS A-MATH GEN, V36, P11023, DOI 10.1088/0305-4470/36/43/025; Thodberg HH, 1996, IEEE T NEURAL NETWOR, V7, P56, DOI 10.1109/72.478392; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Tipping ME, 2000, ADV NEUR IN, V12, P652; TITTERINGTON DM, 1985, STAT ANAL FINITE MIX; Ueda N, 2002, NEURAL NETWORKS, V15, P1223, DOI 10.1016/S0893-6080(02)00040-0; Utsugi A, 1998, NEURAL COMPUT, V10, P2115, DOI 10.1162/089976698300016990; Utsugi A, 1997, NEURAL COMPUT, V9, P623, DOI 10.1162/neco.1997.9.3.623; Van Gestel T, 2002, NEURAL COMPUT, V14, P1115; Vila JP, 2000, IEEE T NEURAL NETWOR, V11, P265, DOI 10.1109/72.838999; Vivarelli F, 2001, NEURAL NETWORKS, V14, P427, DOI 10.1016/S0893-6080(01)00024-7; Waterhouse S, 1996, ADV NEUR IN, V8, P351; Williams CKI, 1998, NEURAL COMPUT, V10, P1203, DOI 10.1162/089976698300017412; Wright WA, 1999, IEEE T NEURAL NETWOR, V10, P1261, DOI 10.1109/72.809073; YEDIDIA J, 2001, 200116 MERL TR; Zhang BL, 2001, IEEE T NEURAL NETWOR, V12, P765, DOI 10.1109/72.935090; Zhang J, 1993, IEEE T IMAGE PROCESS, V2, P27, DOI 10.1109/83.210863; ZHANG J, 1992, IEEE T SIGNAL PROCES, V40, P2570, DOI 10.1109/78.157297	100	22	22	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	0883-4237			STAT SCI	Stat. Sci.	FEB	2004	19	1					128	139		10.1214/088342304000000099		12	Statistics & Probability	Mathematics	842OE	WOS:000223012900014		
J	He, P; Xu, CJ; Liang, YZ; Fang, KT				He, P; Xu, CJ; Liang, YZ; Fang, KT			Improving the classification accuracy in chemistry via boosting technique	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS			English	Article						boosting; classification; chemometrics; decision tree; neural network	MASS-SPECTRAL CLASSIFIERS; NEURAL NETWORKS; DISCRIMINANT-ANALYSIS	One of the main tasks of chemometrics is to classify chemical objects to one of several distinct predefined categories. There are many classification methods in data mining, one of which is the boosting technique that can improve predicate performance of a given classifier and it is one of the most powerful methods in classification methodology. In this paper, we apply boosting neural network (NN) and boosting tree in classification for chemical data. Experimental results show that boosting can significantly improve the prediction performance of any single classification method. Two techniques to interpret the model are also introduced in order to help us better understand the experimental results. (C) 2003 Elsevier B.V. All rights reserved.	Hong Kong Baptist Univ, Dept Math, Hong Kong, Hong Kong, Peoples R China; Cent S Univ, Coll Chem & Chem Engn, Changsha 410083, Peoples R China; Sichuan Univ, Coll Math, Chengdu 610064, Peoples R China	Fang, KT (reprint author), Hong Kong Baptist Univ, Dept Math, Hong Kong, Hong Kong, Peoples R China.	ktfang@hkbu.edu.hk	Fang, Kai Tai/B-7196-2009; HKBU, Mathematics/B-5086-2009				Anderson T. W., 1984, INTRO MULTIVARIATE S; BLANK TB, 1994, J CHEMOMETR, V8, P391, DOI 10.1002/cem.1180080605; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L., 1984, WADSWORTH STAT PROBA; Coomans D., 1978, ANAL CHIM ACTA, V103, P409, DOI 10.1016/S0003-2670(01)83105-6; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Freund Y, 2001, P 8 INT WORKSH ART I; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Friedman JH, 1999, GREEDY FUNCTION APPR; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Friel DD, 2000, CELL CALCIUM, V28, P307, DOI 10.1054/ceca.2000.0172; Hastie T., 2001, ELEMENTS STAT LEARNI; Indahl UG, 1999, CHEMOMETR INTELL LAB, V49, P19, DOI 10.1016/S0169-7439(99)00023-4; KREINOVICH VY, 1991, NEURAL NETWORKS, V4, P381, DOI 10.1016/0893-6080(91)90074-F; LINDON JC, 2000, ENCY SPECTROSCOPY, P232; Mallet Y, 1996, CHEMOMETR INTELL LAB, V35, P157, DOI 10.1016/S0169-7439(96)00050-0; McLachlan G., 1992, DISCRIMINANT ANAL ST; RIPLEY BD, 1994, J ROY STAT SOC B MET, V56, P409; Varmuza K, 1996, J CHEM INF COMP SCI, V36, P323, DOI 10.1021/ci9501406; Verhaar HJM, 1996, J CHEMOMETR, V10, P149, DOI 10.1002/(SICI)1099-128X(199603)10:2<149::AID-CEM414>3.0.CO;2-F; Werther W, 2002, J CHEMOMETR, V16, P99, DOI 10.1002/cem.694; Xu J, 2002, J MED CHEM, V45, P5311, DOI 10.1021/jm010520k; Yoshida H, 2001, ANAL CHIM ACTA, V446, P485	25	19	20	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-7439			CHEMOMETR INTELL LAB	Chemometrics Intell. Lab. Syst.	JAN 28	2004	70	1					39	46		10.1016/j.chemolab.2003.10.001		8	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	777CK	WOS:000189156600005		
J	Bock, RK; Chilingarian, A; Gaug, M; Hakl, F; Hengstebeck, T; Jirina, M; Klaschka, J; Kotrc, E; Savicky, P; Towers, S; Vaiclulis, A; Wittek, W				Bock, RK; Chilingarian, A; Gaug, M; Hakl, F; Hengstebeck, T; Jirina, M; Klaschka, J; Kotrc, E; Savicky, P; Towers, S; Vaiclulis, A; Wittek, W			Methods for multidimensional event classification: a case study using images from a Cherenkov gamma-ray telescope	NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT			English	Article						classification; discrimination; multivariate; neural networks; kernel methods; nearest-neighbour; regression trees		We present results from a case study comparing different multivariate classification methods. The input is a set of Monte Carlo data, generated and approximately triggered and pre-processed for an imaging gamma-ray Cherenkov telescope. Such data belong to two classes, originating either from incident gamma rays or caused by hadronic showers. There is only a weak discrimination between signal (gamma) and background (hadrons), making the data an excellent proving ground for classification techniques. The data and methods are described, and a comparison of the results is made. Several methods give results comparable in quality within small fluctuations, suggesting that they perform at or close to the Bayesian limit of achievable separation. Other methods give clearly inferior or inconclusive results. Some problems that this study can not address are also discussed. (C) 2003 Elsevier B.V. All rights reserved.	Max Planck Inst Phys & Astrophys, D-80805 Munich, Germany; Inst Phys, Cosmic Ray Div, Yerevan, Armenia; Inst Fis Altes Energies, Barcelona, Spain; Acad Sci Czech Republ, Inst Comp Sci, Prague, Czech Republic; Univ GH Siegen, Fachbereich Phys, Siegen, Germany; SUNY Stony Brook, Stony Brook, NY 11794 USA; Univ Rochester, Rochester, NY 14627 USA	Bock, RK (reprint author), Max Planck Inst Phys & Astrophys, D-80805 Munich, Germany.	rkb@mail.cern.ch	Hakl, Frantisek/A-5717-2014; Klaschka, Jan/A-6076-2014; Jirina, Marcel/B-2846-2014; chilingarian, ashot/E-1606-2014; Savicky, Petr/E-7685-2014; GAug, Markus/L-2340-2014	chilingarian, ashot/0000-0002-2018-9715; GAug, Markus/0000-0001-8442-7877			Ametller L, 1996, PHYS REV D, V54, P1233, DOI 10.1103/PhysRevD.54.1233; BOCK RK, 1999, 9904 MAGIC; Breiman L, 1983, CLASSIFICATION REGRE; Breiman L., 1999, COMBINING ARTIFICIAL; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, MANUAL SETTING USING, V3, P1; BREIMAN L, FORTRAN PROGRAM RAND; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chilingaryan A, 2002, MATH BIOSCI, V176, P59, DOI 10.1016/S0025-5564(01)00105-5; Christianini N, 2000, INTRO SUPPORT VECTOR; DUNLEA S, 2001, P 2M INT COSM RAY C, P2939; EGAN JP, 1975, SIGNAL DETECTION THE; ERNENWEIN JP, NEUNET PACKAGE ROOT; Farlow S.J., 1984, SELF ORG METHODS MOD; Fegan DJ, 1997, J PHYS G NUCL PARTIC, V23, P1013, DOI 10.1088/0954-3899/23/9/004; GAUG M, 2001, 2 WORKSH METH ASP UN, P123; Hastie T., 2001, ELEMENTS STAT LEARNI; Heck D., 1998, 6019 FZKA; JIRINA M, 1994, P 10 IFAC S SYST ID, V2, P309; JIRINA M, 1995, NEURAL NETWORK WORLD, V5, P329; JOLLIFE IT, 1986, MANY TXB EXPLAIN PCA; KESTEL M, 2001, P 27 INT COSM RAY C; KNUTESON B, 2001, ABSTR PHYSICS; KRANICH D, 2001, THESIS TU MUNCHEN; MORIARTY P, 1999, AIP C P, V515, P338; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1996, P AAAI 96 PORTL OR; TOWERS S, TERRAFERMA SUITE MUL; VAICIULIS A, 2002, P C ADV STAT TECHN P; 2002, P C ADV STAT TECHN P	30	52	52	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0168-9002			NUCL INSTRUM METH A	Nucl. Instrum. Methods Phys. Res. Sect. A-Accel. Spectrom. Dect. Assoc. Equip.	JAN 11	2004	516	2-3					511	528		10.1016/j.nima.2003.08.157		18	Instruments & Instrumentation; Nuclear Science & Technology; Physics, Particles & Fields; Spectroscopy	Instruments & Instrumentation; Nuclear Science & Technology; Physics; Spectroscopy	763KC	WOS:000188083200026		
J	Huo, XM; Chen, JH				Huo, XM; Chen, JH			Building a cascade detector and its applications in automatic target detection	APPLIED OPTICS			English	Article							TREES	A hierarchical classifier (cascade) is proposed for target detection. In building an optimal cascade we considered three heuristics: (1) use of a frontier-following approximation, (2) controlling error rates, and (3) weighting. Simulations of synthetic data with various underlying distributions were carried out. We found that a weighting heuristic is optimal in terms of both computational complexity and error rates. We initiate a systematic comparison of several potential heuristics that can be utilized in building a hierarchical model. A range of discussions regarding the implications and the promises of cascade architecture as well as of techniques that can be integrated into this framework is provided. The optimum heuristic-weighting algorithms-was applied to an IR data set. It was found that these algorithms outperform some state-of-the-art approaches that utilize the same type of simple classifier. (C) 2004 Optical Society of America.	Georgia Inst Technol, Sch Ind & Syst Engn, Atlanta, GA 30332 USA	Huo, XM (reprint author), Georgia Inst Technol, Sch Ind & Syst Engn, 765 Ferst Dr, Atlanta, GA 30332 USA.	xiaoming@isye.gatech.edu; chenjh@isye.gatech.edu					Bennett KP, 2000, MACH LEARN, V41, P295, DOI 10.1023/A:1007600130808; Breiman L., 1984, CLASSIFICATION REGRE; BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851; Cristianini N., 2000, SUPPORT VECTOR MACHI; Elad M, 2002, PATTERN RECOGN LETT, V23, P1459, DOI 10.1016/S0167-8655(02)00106-X; FRIEDMAN J, 2002, GETTING STARTED MART; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Hastie T., 2001, ELEMENTS STAT LEARNI; HEISELE B, 2001, P IEEE COMP SOC C CO, V2, P18; HELOR Y, 2002, CS20021; HELOR Y, 2003, INT C IM PROC BARC S; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834; Schapire RE, 1998, ANN STAT, V26, P1651; SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085; Vapnik VN, 1995, NATURE STAT LEARNING; VIOLA P, 2001, ICCV WORKSH STAT COM; ZHU M, IN PRESS J COMPUT GR	19	2	2	OPTICAL SOC AMER	WASHINGTON	2010 MASSACHUSETTS AVE NW, WASHINGTON, DC 20036 USA	1559-128X	2155-3165		APPL OPTICS	Appl. Optics	JAN 10	2004	43	2					293	303		10.1364/AO.43.000293		11	Optics	Optics	762TN	WOS:000187998400011	14735949	
B	DiCarlo, JM; Montgomery, GE; Trovinger, SW			IS&T	DiCarlo, JM; Montgomery, GE; Trovinger, SW			Emissive chart for imager calibration	12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS			English	Proceedings Paper	12th Color Imaging Conference	NOV 09-12, 2004	Scottsdale, AZ	Soc Imaging Sci & Technol, Soc Informat Display, Adobe Syst Inc, Agfa Gevaert NMV, Eastman Kodak Co, Fuji Photo Film Co Ltd, Hewlett Packard Co, Konica Minolta Holdings, Inc, Lexmark Int Inc, Sharp Labs Amer, Sony Corp, Xerox Corp				Each and every color imaging device should be custom calibrated both to enhance image processing algorithms and to produce pleasing and faithful images of the captured scenes or medias. Custom calibrations, however, are usually not performed because calibration instruments are either too slow to be used on the manufacturing line or the instruments lack the necessary accuracy. We have developed a calibration instrument that enables both fast and accurate imager calibrations. The instrument is based on emissive narrow-band light sources-light emitting diodes-arranged in a grid pattern or chart configuration. We refer to the instrument as the emissive calibration chart or the EC chart. We compare the emissive calibration chart to other calibration instruments, which include reflective charts, like the Macbeth ColorChecker or DC charts, and monochromators. The results demonstrate that custom calibrations of each and every imager could be accurately determined on the manufacturing line using the emissive calibration chart.	Hewlett Packard Labs, Palo Alto, CA USA	DiCarlo, JM (reprint author), Hewlett Packard Labs, Palo Alto, CA USA.						Adams J, 1998, IEEE MICRO, V18, P20, DOI 10.1109/40.743681; Berns R. S., 2000, BILLMEYER SALTZMANS; DiCarlo J. M., 2001, P 9 COL IM C, P27; DICARLO JM, 2004, SPIE EL IM C SAN J B, V5017; Finlayson G. D., 1997, P IS T SID 5 COL IM, P6; Hastie T., 2001, ELEMENTS STAT LEARNI; HUNT R. W. G., 1995, REPROD COLOUR; Johnson R. A., 2002, APPL MULTIVARIATE ST; Kailath T., 2000, LINEAR ESTIMATION; Mardia KV, 1979, MULTIVARIATE ANAL; MCCAMY CS, 1976, J APPL PHOTOGRAPHIC, V48, P777; Sharma G, 1999, SEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P69; Strang G., 1998, INTRO LINEAR ALGEBRA; WANDELL BA, 1987, IEEE T PATTERN ANAL, V9, P2; Wyszecki G, 1982, COLOR SCI CONCEPTS M	15	4	4	SOC IMAGING SCIENCE & TECHNOLOGY	SPRINGFIELD	7003 KILWORTH LANE, SPRINGFIELD, VA 22151 USA			0-89208-254-2				2004							295	301				7	Computer Science, Software Engineering; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BBN71	WOS:000226297300051		
B	Gorriz, JM; Puntonet, CG; Salmeron, M; Martin-Clemente, R			IEEE COMPUTER SOCIETY	Gorriz, JM; Puntonet, CG; Salmeron, M; Martin-Clemente, R			Parallelization of time series forecasting model	12TH EUROMICRO CONFERENCE ON PARALLEL, DISTRIBUTED AND NETWORK-BASED PROCESSING, PROCEEDINGS			English	Proceedings Paper	12th Euromicro Conference on Parallel, Distributed and Network-Based Processing	FEB 11-13, 2004	Coruna, SPAIN				GENETIC ALGORITHMS	In this paper we show a Parallel Neural Network (Cross-over Prediction Model) for time series statistical learning implemented in PVM ("Parallel Virtual Machine") and MPI ("Message Passing Interface"), in order to reduce computational time. Parallelization is achieved in two ways: updating autoregressive parameters via a genetic algorithm and evaluating the overall prediction function via a parallel neural Network. PVM permits an heterogeneous collection of Unix computers networked together to be viewed by our program as a simple parallel computer We show different architectures of parallel processors systems and discuss its computing model.	Univ Cadiz, EPS Algeciras, Algeciras 11202, Spain	Gorriz, JM (reprint author), Univ Cadiz, EPS Algeciras, Avda Ramon Puyol S-N, Algeciras 11202, Spain.		Puntonet, Carlos/B-1837-2012; Martin-Clemente, Ruben/E-8977-2012; Gorriz, Juan/C-2385-2012				CHAO L, 1994, IEEE T SIGNAL PROCES, V42, P927; Chen S., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.687886; EIBEN AE, 1991, LECT NOTES COMPUT SC, V496, P4; GORRIZ JM, 2003, NEW MODEL TIME SERIE; GORRIZSAEZ JM, 2003, IN PRESS ALGORITMOS; HAGGSTROM O, 1998, FINITE MARKOV CHAINS; HASTIE T., 2000, ELEMENTS STAT LEARNI; HOARE CAR, 1962, COMPUT J, V5, P10, DOI 10.1093/comjnl/5.1.10; Lozano JA, 1999, THEOR COMPUT SCI, V229, P11, DOI 10.1016/S0304-3975(99)00090-0; MATWIN S, 1991, IEEE T SYST MAN CYB, V21, P102, DOI 10.1109/21.101141; MICHALEWICZ Z, 1992, GENETIC ALGORITHMS P; Moody J., 1989, NEURAL COMPUT, V1, P284; Pollock D.S.G., 1999, HDB TIME SERIES ANAL; RUDOLPH G, 1994, IEEE T NEURAL NETWOR, V5, P96, DOI 10.1109/72.265964; SALMERONCAMPOS M, 2001, PREDICCION SERIES TE; Schmitt LM, 2001, THEOR COMPUT SCI, V259, P1, DOI 10.1016/S0304-3975(00)00406-0; Schmitt LM, 1998, THEOR COMPUT SCI, V200, P101, DOI 10.1016/S0304-3975(98)00004-8; SUZUKI J, 1995, IEEE T SYST MAN CYB, V25, P655, DOI 10.1109/21.370197; TIKHONOV T, 1977, SOLUTIONS ILL POSED; Wilkinson B., 1999, PARALLEL PROGRAMMING; WIRTH N, 1999, ALGORITHMS PLUS DATA	21	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2083-9				2004							103	110		10.1109/EMPDP.2004.1271434		8	Computer Science, Theory & Methods	Computer Science	BY62P	WOS:000189424200015		
S	Solo, V			ieee	Solo, V			An EM algorithm for singular state space models: II	2004 43RD IEEE CONFERENCE ON DECISION AND CONTROL (CDC), VOLS 1-5	IEEE CONFERENCE ON DECISION AND CONTROL - PROCEEDINGS		English	Proceedings Paper	43rd IEEE Conference on Decision and Control	DEC 14-17, 2004	San Diego, CA	IEEE, Honeywell, MathWorks, Natl Instruments, United Technol Res Ctr, XEROX				We develop a state space EM algorithm for the case when the state innovations covariance matrix is singular and where there is correlation between state and observation noise. Previous state space EM algorithms precluded this practically important case.	Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA	Solo, V (reprint author), Univ Michigan, Dept Elect Engn & Comp Sci, 1301 Beal Ave, Ann Arbor, MI 48109 USA.						EAGLE R, 1983, JL ECONOMETRICS, V23, P385; GIBSON S, 2000, P 39 IEEE CDC SYDN A; Hastie T., 2001, ELEMENTS STAT LEARNI; LANGE K, 1995, J ROY STAT SOC B MET, V57, P425; Shumway R. H., 1982, Journal of Time Series Analysis, V3, DOI 10.1111/j.1467-9892.1982.tb00349.x; SOLO V, 2003, P IEEE CDC HON HAW; WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060	7	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0191-2216		0-7803-8682-5	IEEE DECIS CONTR P			2004							3611	3612		10.1109/CDC.2004.1429288		2	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	BBO61	WOS:000226745603043		
S	Lindgren, D; Ljung, L			ieee	Lindgren, D; Ljung, L			Nonlinear dynamics isolated by Delaunay triangulation criteria	2004 43RD IEEE CONFERENCE ON DECISION AND CONTROL (CDC), VOLS 1-5	IEEE CONFERENCE ON DECISION AND CONTROL - PROCEEDINGS		English	Proceedings Paper	43rd IEEE Conference on Decision and Control	DEC 14-17, 2004	San Diego, CA	IEEE, Honeywell, MathWorks, Natl Instruments, United Technol Res Ctr, XEROX			PROJECTION PURSUIT	Inspired by an idea by Q. Zhang, we show that Delaunay triangulation of data points sampled from a system with an additive nonlinearity gives a criterion by which a linear projection can be found that isolates the nonlinear dependence, leaving out the linear one. This isolation means the nonlinear modeling can be confined to a regressor space of lower dimensionality, which in turn means over-parameterization can be avoided. Monte Carlo simulations indicate that a particular criterion built on triangle asymmetries has a minimum that coincides with the sampled system nonlinear part. The criterion is however complex to compute and non-convex, which makes it difficult to optimize globally.	Linkoping Univ, Div Automat Control, S-58183 Linkoping, Sweden	Lindgren, D (reprint author), Linkoping Univ, Div Automat Control, S-58183 Linkoping, Sweden.		Ljung, Lennart/B-3822-2014	Ljung, Lennart/0000-0003-4881-8955			ARMS L, 1999, IEEE P VIRT REAL, P88; Delaunay B, 1932, Z KRISTALLOGR, V84, P109; FRIEDMAN JH, 1974, IEEE T COMPUT, VC 23, P881, DOI 10.1109/T-C.1974.224051; FRIEDMAN JH, 1981, J AM STAT ASSOC, V76, P817, DOI 10.2307/2287576; Hastie T., 2001, ELEMENTS STAT LEARNI; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; JONES MC, 1987, J ROY STAT SOC A STA, V150, P1, DOI 10.2307/2981662; Knuth D., 1992, LECT NOTES COMPUTER; LINDGREN D, 2002, LITHISYR995 LINK U; LINDGREN D, 2002, 83 SE581 LINK U; SWAYNE D, 1998, J COMPUTATIONAL GRAP; Tukey PA, 1981, INTERPRETING MULTIVA, P189; YOUNG FW, 1991, IBM J RES DEV, V35, P97; ZHANG Q, 2003, METHOD NONLINEAR REL	14	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0191-2216		0-7803-8682-5	IEEE DECIS CONTR P			2004							3862	3867		10.1109/CDC.2004.1429340		6	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	BBO61	WOS:000226745603085		
B	Chen, DC; Hua, DD; Liu, ZQ; Cheng, ZF			IEEE	Chen, DC; Hua, DD; Liu, ZQ; Cheng, ZF			An integrated system for class prediction using gene expression profiling	2004 8th International Conference on Control, Automation, Robotics and Vision, Vols 1-3			English	Proceedings Paper	8th International Conference on Control, Automation, Robotics and Vision (ICARCV 2004)	DEC 06-09, 2004	Kunming, PEOPLES R CHINA	Nanyang Technol Univ, Sch Elect & Elect Engn, Republic Singapore, Nanjing Univ Sci & Technol, Peoples Republic China, IEEE Robotics & Automation Soc, IEEE Syst, Man & Cybernet Soc, IEEE Control Syst Soc, IEE, Natl Nat Sci Fdn China, Singapore Tech Engn Ltd, Lee Fdn			CANCER; CLASSIFICATION; DIAGNOSIS; TUMOR	Motivation: Gene expression profiles have been successfully applied to class prediction. Due to a large number of genes (features) and a small number of samples in gene expression data, feature selection is essential when performing the prediction task. Many methods have been proposed to select features in microarray data analysis, but there is no unique method which performs uniformly well for all the learning algorithms. It is then practical to find a feature selection method and a learning algorithm that give superior performance. Results: In this paper, we present an integrated scheme to perform the task of class prediction based on gene expression profiles. The scheme incorporates a simple novel feature selection procedure into naive Bayes models. Each selected gene has a high score of discriminatory power determined by the Brown-Forsythe test statistic. Any pair of selected genes have a low correlation. This facilitates the use of the conditional independence among genes assumed by the naive Bayes models. To demonstrate the effectiveness, the proposed scheme was applied to three commonly used expression data sets COLON, OVARIAN, and LEUKEMIA. The results show that the numbers of misclassified samples are 0, 0, and 4, respectively.	Uniformed Serv Univ Hlth Sci, Bethesda, MD 20814 USA	Chen, DC (reprint author), Uniformed Serv Univ Hlth Sci, 4301 Jones Bride Rd, Bethesda, MD 20814 USA.						Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; BROWN MB, 1974, TECHNOMETRICS, V16, P129, DOI 10.2307/1267501; Chen DC, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P492; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hastie T., 2001, ELEMENTS STAT LEARNI; Liu Huiqing, 2002, Genome Inform, V13, P51; Neter J., 1996, APPL LINEAR STAT MOD; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Ripley BD, 1996, PATTERN RECOGNITION; STUART A, 1999, KENDALLS ADV THEOR A, V2; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Welsh JB, 2001, P NATL ACAD SCI USA, V98, P1176, DOI 10.1073/pnas.98.3.1176; XING EP, 2003, UNDERSTANDING USING; Xiong MM, 2001, GENOME RES, V11, P1878	15	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-8653-1				2004							1023	1028				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Robotics	Automation & Control Systems; Computer Science; Robotics	BCP26	WOS:000230484501045		
B	Wang, P; Kim, Y; Pollack, J; Tibshirani, R			IEEE Comp Soc	Wang, P; Kim, Y; Pollack, J; Tibshirani, R			Boosted PRIM with application to searching for oncogenic pathway of lung cancer	2004 IEEE COMPUTATIONAL SYSTEMS BIOINFORMATICS CONFERENCE, PROCEEDINGS			English	Proceedings Paper	IEEE Computational Systems Bioinformatics Conference (CSB 2004)	AUG 16-19, 2004	Stanford, CA	IEEE Comp Soc, Hewlett-Packard Co, Coop Platinum, BioMed Cent, Off Sci, US DOE			TREE MODELS	Boosted PRIM (Patient Rule Induction Method) is a new algorithm developed for two-class classification problems. PRIM is a variation of those Tree-Based methods ( [4] Ch9.3), seeking box-shaped regions in the feature space to separate different classes. Boosted PRIM is to implement PRIM-styled weak learners in Adaboost, one of the most popular boosting algorithms. In addition, we improve the performance of the algorithm by introducing a regularization to the boosting process, which supports the perspective of viewing boosting as a steepest-descent numerical optimization by Jerry Friedman [3]. The motivation for Boosted PRIM is to solve the problem of "searching for oncogenic pathways" based on array-CGH (Comparative Genomic Hybridization) data, though the algorithm itself is suitable for general classification problems. We illustrate the performance of the method through some simulation studies as well as an application on a lung cancer array-CGH data set.	Stanford Univ, Dept Stat, Stanford, CA 94305 USA	Wang, P (reprint author), Stanford Univ, Dept Stat, Stanford, CA 94305 USA.						Desper R, 2000, J COMPUT BIOL, V7, P789, DOI 10.1089/10665270050514936; FRIEDMAN JH, IMS 1999 REITZ LECT; Hastie T., 2001, ELEMENTS STAT LEARNI; Jiang F, 2000, CANCER RES, V60, P6503; LENGAUER C, 1998, NATURE, V396; NEWTON MA, 2001, STAT METHOD DISCOVER; PINKEL D, 1998, NATURE GENETICS, V20	7	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2194-0				2004							604	609				6	Biotechnology & Applied Microbiology; Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Genetics & Heredity	Biotechnology & Applied Microbiology; Computer Science; Genetics & Heredity	BAX76	WOS:000224127800102		
B	Risteski, D; Kulakov, A; Davcev, D			ieee	Risteski, D; Kulakov, A; Davcev, D			Single exponential smoothing method and neural network in one method for time series prediction	2004 IEEE CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEMS, VOLS 1 AND 2	IEEE Conference on Cybernetics and Intelligent Systems		English	Proceedings Paper	IEEE Conference on Cybernetics and Intelligent Systems	DEC 01-03, 2004	Singapore, SINGAPORE	IEEE				The purpose of this paper is to present a new method that combines statistical techniques and neural networks in one method for the better time series prediction. In this paper we presented single exponential smoothing method (statistical technique) merged with feed forward back propagation neural network in one method named as Smart Single Exponential Smoothing Method (SSESM). The basic idea of the new method is to learn from the mistakes. More specifically, our neural network learns from the mistakes made by the statistical techniques. The mistakes are made by the smoothing parameter, which is constant. In our method, the smoothing parameter is a variable. It is changed according to the prediction of the neural network. Experimental results show that the prediction with a variable smoothing parameter is better than with a constant smoothing parameter.	Fac Elect Engn, Comp Sci Dept, Skopje, Macedonia	Risteski, D (reprint author), Fac Elect Engn, Comp Sci Dept, Skopje, Macedonia.	rdimce@yahoo.com; kulak@etf.ukum.edu.mk; etfdav@etf.ukim.edu.mk					[Anonymous], TIME SERIES DATA LIB; Atiya AF, 2001, IEEE T NEURAL NETWOR, V12, P929, DOI 10.1109/72.935101; FRANK RJ, 1999, P 5 INT C ENG APPL N; Hastie T., 2001, ELEMENTS STAT LEARNI; LOTRIC U, 2001, P ART NEUR NETS GEN, P43; MICHAL RZ, 2003, J PHYS A, V36, P4543; *NIST SEMATECH, HDB STAT METH; PLUMMER EA, TIME SERIES FORECAST; SMALL M, 2002, PHYS REV E, V66; TAKAHO H, 2002, P INT S NONL THEOR A, P163; Trueblood Robert P., 2001, DATA MINING STAT ANA; WEIGEND A, 1994, INT J FORECASTING, V10, P161; Yao JT, 2001, 8TH INTERNATIONAL CONFERENCE ON NEURAL INFORMATION PROCESSING, VOLS 1-3, PROCEEDING, P757	13	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-8643-4	CONF CYBERN INTELL S			2004							741	745				5	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Theory & Methods	Computer Science	BBR10	WOS:000227335800132		
S	Jung, BY; Sukhatme, GS			IEEE	Jung, BY; Sukhatme, GS			A generalized region-based approach for multi-target tracking in outdoor environments	2004 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1- 5, PROCEEDINGS	IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION		English	Proceedings Paper	IEEE International Conference on Robotics and Automation	APR 26-MAY 01, 2004	New Orleans, LA	IEEE Robot & Automat Soc, IEEE			TARGETS	We propose a generalized region-based approach to multi-target tracking, which is applicable to structured and unstructured environments. In this approach each robot constructs virtual regions based on the latest tracking information from other robots. Without pre-partitioned region information, each robot independently estimates the most urgent region that needs to be visited. The idea is for robots to coarsely estimate where the targets are present, and to navigate there. A multi-robot system to track moving objects outdoors has been designed using this approach in order to validate the idea. The performance of the individual motion trackers and the cooperative tracking behaviors is evaluated through experiments with different robot bases (a helicopter, a Segway RMP, and a Pioneer) and in simulation. Experimental results indicate that robots are able to distribute themselves appropriately in response to target movement.	Univ So Calif, Ctr Robot & Embedded Syst, Robot Embedded Syst Lab, Los Angeles, CA 90089 USA	Jung, BY (reprint author), Univ So Calif, Ctr Robot & Embedded Syst, Robot Embedded Syst Lab, Los Angeles, CA 90089 USA.						Censi A., 1999, Proceedings 10th International Conference on Image Analysis and Processing, DOI 10.1109/ICIAP.1999.797671; FOX D, 2001, ADV NEURAL INFORMATI, V14; Gerkey BP, 2001, LECT NOTES CONTR INF, V271, P353; Hastie T., 2001, ELEMENTS STAT LEARNI; JUNG B, 2004, UNPUB 8 C INT AUT SY; Jung B, 2002, AUTON ROBOT, V13, P191, DOI 10.1023/A:1020598107671; Murrieta-Cid R., 2002, Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No.02CH37292), DOI 10.1109/ROBOT.2002.1014421; Parker LE, 1999, INTELL AUTOM SOFT CO, V5, P5; Spletzer JR, 2003, INT J ROBOT RES, V22, P7, DOI 10.1177/0278364903022001002; Ulrich I., 1998, Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No.98CH36146), DOI 10.1109/ROBOT.1998.677362; WELCH G, 95041 U N CAR CHAP H; WERGER BB, 2000, P DISTR AUT ROB SYST	12	4	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1050-4729		0-7803-8232-3	IEEE INT CONF ROBOT			2004							2189	2195				7	Automation & Control Systems; Computer Science, Artificial Intelligence; Robotics	Automation & Control Systems; Computer Science; Robotics	BAE24	WOS:000221794800354		
S	Ng, WWY; Yeung, DS; Cloete, I			IEEE	Ng, WWY; Yeung, DS; Cloete, I			Quantitative study on effect of center selection to RBFNN classification performance	2004 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN & CYBERNETICS, VOLS 1-7	IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, CONFERENCE PROCEEDINGS		English	Proceedings Paper	IEEE International Conference on Systems, Man and Cybernetics	OCT 10-13, 2004	The Hague, NETHERLANDS	IEEE		radial basis function neural network (RBFNN); stochastic sensitivity measure; model evaluation; number of centers (RBF neurons); neural network performance assessment	MULTILAYER PERCEPTRON; SENSITIVITY ANALYSIS; MODEL SELECTION; REGRESSION; INPUT	xIn pattern classification problems using a RBFNN classifier, the selection of the number of clusters and their corresponding centers influences the network's ability to generalize unseen data. In this paper, we evaluate different RBFNN architectures by a quantitative measure - RBFNN sensitivity measure, which is defined as the absolute expectation plus standard deviation of network output perturbations with respect to input perturbations. Numerical comparisons of a number of different RBFNN architectures are given using two of UCI datasets. The experiments show that the sensitivity measure would be correlated to the testing error for the unseen samples and simpler classification problem may have smaller sensitivity measure.	Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China	Ng, WWY (reprint author), Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China.						Bai YF, 2002, IEEE IJCNN, P840; Ben-Hur A., 2001, J MACHINE LEARNING R, V2, P125; Brizzotti MM, 1999, IEE CONF PUBL, P87, DOI 10.1049/cp:19990287; Cherkassky V, 2003, NEURAL COMPUT, V15, P1691, DOI 10.1162/089976603321891864; JIN YC, 1992, IEEE T NEURAL NETWOR, V3, P101, DOI 10.1109/72.105422; DAQI G, 2002, IEEE P IJCNN, P846; Duda R. O., 2000, PATTERN CLASSIFICATI; Engelbrecht AP, 2001, IEEE T NEURAL NETWOR, V12, P1386, DOI 10.1109/72.963775; Hastie T, 2003, NEURAL COMPUT, V15, P1477, DOI 10.1162/089976603321891765; Hastie T., 2001, ELEMENT STAT LEARNIN; Haykin S., 1998, NEURAL NETWORKS; KARAYIANNIS NB, 2003, IEEE T NEURAL NETWOR, P835; PICHE SW, 1995, IEEE T NEURAL NETWOR, V6, P432, DOI 10.1109/72.363478; Townsend NW, 1999, IEEE T NEURAL NETWOR, V10, P217, DOI 10.1109/72.750542; Widrow B., 1960, IRE Wescon Convention Record, V4; WING WY, 2002, P INT C MACH LEARN C, P2214; WING WY, 2003, IEE ELECT LETT, V39, P787; WING WY, 2003, IEEE P INT C SMC, P2593; WING WY, 2004, IN PRESS P INT C MAC; WING WY, 2002, IEEE P INT C SMC TUN, P503; WING WYN, 2003, P INT C MACH LEARN C, P1293; Xiong QY, 2000, IEEE RO-MAN 2000: 9TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P107; Yeung DS, 2002, IEEE T NEURAL NETWOR, V13, P34, DOI 10.1109/72.977266; Zeng XQ, 2003, NEURAL COMPUT, V15, P183, DOI 10.1162/089976603321043757; Zeng XQ, 2001, IEEE T NEURAL NETWOR, V12, P1358, DOI 10.1109/72.963772	25	3	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X		0-7803-8566-7	IEEE SYS MAN CYBERN			2004							3692	3697		10.1109/ICSMC.2004.1400917		6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Robotics	Automation & Control Systems; Computer Science; Robotics	BBP32	WOS:000226863300622		
S	Cherkassky, V; Ma, YQ			ieee	Cherkassky, V; Ma, YQ			Comparison of loss functions for linear regression	2004 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-4, PROCEEDINGS	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Networks (IJCNN)	JUL 25-29, 2004	Budapest, HUNGARY	IEEE, IEEE Neural Networks Soc, Hungarian Acad Sci, Comp & Automat Res Inst, Katholieke Univ Leuven, Republic Hungary, Natl Commun & Informat Council			PARAMETERS; SELECTION	This paper addresses selection of the loss function for regression problems with finite data. It is well-known (under standard regression formulation) that for a known noise density there exist an optimal loss function under an asymptotic setting (large number of samples), i.e. squared loss is optimal for Gaussian noise density. However, in real-life applications the noise density is unknown and the number of training samples is finite. For such practical situations, we suggest using Vapnik's epsilon-insensitive loss function. We use practical method for setting the value of epsilon as a function of known number of samples and (known or estimated) noise variance [1,2]. We consider commonly used noise densities (such as Gaussian, Uniform and Laplacian noise). Empirical comparisons for several representative linear regression problems indicate that Vapnik's E-insensitive loss yields more robust performance and improved prediction accuracy, in comparison with squared loss and least-modulus loss, especially for noisy high-dimensional data sets.	Univ Minnesota, Dept Elect & Comp Engn, Minneapolis, MN 55455 USA	Cherkassky, V (reprint author), Univ Minnesota, Dept Elect & Comp Engn, Minneapolis, MN 55455 USA.						Cherkassky V, 2002, LECT NOTES COMPUT SC, V2415, P687; Cherkassky V., 2002, Natural Computing, V1, DOI 10.1023/A:1015007927558; Cherkassky V., 1998, LEARNING DATA CONCEP; Cherkassky V, 2004, NEURAL NETWORKS, V17, P113, DOI 10.1016/S0893-6080(03)00169-2; Drucker H., 1997, NEURAL INFORMATION P, P155; Hastie T., 2001, ELEMENTS STAT LEARNI; HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732; Scholkopf Bernard, 1999, ADV KERNEL METHODS S; Smola A., 1998, NCTR98030 U LOND ROY; Vapnik VN, 1995, NATURE STAT LEARNING	10	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		0-7803-8359-1	IEEE IJCNN			2004							395	400		10.1109/IJCNN.2004.1379938		6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	BBC97	WOS:000224941900067		
S	Pelckmans, K; Suykens, JAK; De Moor, B; Leuven, KU			ieee	Pelckmans, K; Suykens, JAK; De Moor, B; Leuven, KU		ESAT SCD SISTA	Regularization constants in LS-SVMs: a fast estimate via convex optimization	2004 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-4, PROCEEDINGS	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Networks (IJCNN)	JUL 25-29, 2004	Budapest, HUNGARY	IEEE, IEEE Neural Networks Soc, Hungarian Acad Sci, Comp & Automat Res Inst, Katholieke Univ Leuven, Republic Hungary, Natl Commun & Informat Council				In this paper, the tuning of the regularization constant in applications of Least Squares Support Vector Machines (LS-SVMs) for regression and classification is considered. The formulation of the LS-SVM training and regularization constant tuning problem (w.r.t. the validation performance) is considered as a single constrained optimization problem. In the formulation with Tikhonov regularization the problem of estimation the weights, validation errors and the regularization constants is a non-convex problem. The main result of this paper is a conversion of the nonlinear constraints into a set of linear constraints which turns the problem into a convex one. This is done based upon a simple Nadaraya-Watson kernel estimator via approximating the LS-SVM smoother matrix by the Nadaraya-Watson smoother. The paper further illustrates how to use this initial estimate towards grid search or local search methods. Numerical examples show considerable speed-ups by the proposed method.	Katholieke Univ Leuven, ESAT, SCD, SISTA, B-3001 Heverlee, Belgium	Pelckmans, K (reprint author), Katholieke Univ Leuven, ESAT, SCD, SISTA, Kasteelpk Arenberg 10, B-3001 Heverlee, Belgium.		Pelckmans, Kristiaan/A-3118-2013; Suykens, Johan/C-9781-2014				BISHOP C.M., 1995, NEURAL NETWORKS PATT; Boyd S., 2004, CONVEX OPTIMIZATION; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Cressie N. A., 1993, STAT SPATIAL DATA; Cristianini N, 2000, INTRO SUPPORT VECTOR; Golub G.H., 1989, MATRIX COMPUTATIONS; Hastie T., 2001, ELEMENTS STAT LEARNI; MACKAY DJC, 1992, NEURAL COMPUT, V4, P698; PELCKMANS K, 2003, 03184 ESAT SISTA KU; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Saunders C., 1998, P 15 INT C MACH LEAR, P515; Schoelkopf B., 2002, LEARNING KERNELS; Suykens J. A. K., 2002, LEAST SQUARES SUPPOR; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; SUYKENS JAK, 2003, NATO SCI SERIES, V3; Tikhonov AN, 1977, SOLUTION ILL POSED P; Vapnik V., 1998, STAT LEARNING THEORY; Wahba G, 1990, SPLINE MODELS OBSERV	18	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		0-7803-8359-1	IEEE IJCNN			2004							699	704		10.1109/IJCNN.2004.1380002		6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	BBC97	WOS:000224941900122		
S	Zegers, P; Sundareshan, MK			ieee	Zegers, P; Sundareshan, MK			Systematic testing of generalization level during training in regression-type learning scenarios	2004 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-4, PROCEEDINGS	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Networks (IJCNN)	JUL 25-29, 2004	Budapest, HUNGARY	IEEE, IEEE Neural Networks Soc, Hungarian Acad Sci, Comp & Automat Res Inst, Katholieke Univ Leuven, Republic Hungary, Natl Commun & Informat Council				In training a Learning Machine (LM) with unlimited data samples available in the training set, it is important to be able to determine when the LM has attained an adequate level of generalization in order to stop the training process. While this is a problem that has not yet achieved a satisfactory solution, aiding the determination of the generalization level is the observation that as the LM becomes consistent and reaches an acceptable generalization threshold, finding samples from the training set that will make the system fail and trigger a new cycle of the training algorithm to be implemented becomes more infrequent. In a statistical sense, the number of samples that can be tested as having no new information (i.e. information not already learnt from training cycles already completed) between two successive triggers of training events asymptotically displays a faster than exponential growth behavior, which in turn provides a telltale sign of a LM reaching consistency and thus attaining a desired generalization level. This work employs some ideas taken from statistical learning theory to conjecture the existence of such exponential behavior and designs a new approach to implementing the training steps that can exploit this behavior in order to systematically test the generalization level during the training process. Examples of nonlinear regression problems are included to illustrate the ideas and to validate the methods. The obtained results are general and are independent of the configuration of the LM, its architecture, and the specific training algorithm used; hence, they are applicable to a broad class of supervised learning problems.	Univ Los Andes, Fac Ingn, Santiago, Region Metropol, Chile	Zegers, P (reprint author), Univ Los Andes, Fac Ingn, Santiago, Region Metropol, Chile.						Cataltepe Z, 1999, NEURAL COMPUT, V11, P995, DOI 10.1162/089976699300016557; Cherkassky V., 1998, LEARNING DATA CONCEP; Hastie T., 2001, ELEMENTS STAT LEARNI; Haykin S, 1998, NEURAL NETWORKS COMP; Nocedal J., 1999, NUMERICAL OPTIMIZATI; RALAIVOLA L, 2001, P ICANN VIENN AUSTR; Riedmiller M., 1993, P IEEE INT C NEUR NE; Sundareshan MK, 1998, IEEE T NEURAL NETWOR, V9, P354; TALAGRAND M, 1994, ANN PROBAB, V22, P20; TSETLIN ML, 1961, AUTOMAT REM CONTR, V22, P1210; VAPNIK V, 1994, NEURAL COMPUT, V6, P851, DOI 10.1162/neco.1994.6.5.851; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Vapnik VN, 1995, NATURE STAT LEARNING; Vayatis N, 1999, LECT NOTES ARTIF INT, V1572, P230	15	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		0-7803-8359-1	IEEE IJCNN			2004							2807	2812				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	BBC97	WOS:000224941900484		
S	Millan, JD			ieee	Millan, JD			On the need for on-line learning in brain-computer interfaces	2004 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-4, PROCEEDINGS	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Networks (IJCNN)	JUL 25-29, 2004	Budapest, HUNGARY	IEEE, IEEE Neural Networks Soc, Hungarian Acad Sci, Comp & Automat Res Inst, Katholieke Univ Leuven, Republic Hungary, Natl Commun & Informat Council			COMMUNICATION	In this paper we motivate the need for on-line learning in brain-computer interfaces (BCI) and illustrate its benefits with the simplest method, namely fixed learning rates. However, the use of this method is supported by the risk of hampering the user to acquire suitable control of the BCI if the embedded classifier changes too rapidly. We report the results with 3 beginner subjects in a series of consecutive recordings, where the classifiers are iteratively trained with the data of a given session and tested on the next session. Interestingly, performance improved over sessions significantly for 2 of the subjects. These results show that on-line learning improves systematically the performance of the subjects. Moreover, performance with online learning is statistically similar to that obtained training the classifier off-line with the same amount of data.	IDIAP Res Inst, CH-1920 Martigny, Switzerland	Millan, JD (reprint author), IDIAP Res Inst, CH-1920 Martigny, Switzerland.		Millan, Jose del R./F-1696-2011	Millan, Jose del R./0000-0001-5819-1522			Babiloni F, 2000, IEEE T REHABIL ENG, V8, P186, DOI 10.1109/86.847810; Birbaumer N, 1999, NATURE, V398, P297, DOI 10.1038/18581; Hastie T., 2001, ELEMENTS STAT LEARNI; Kohonen T, 1997, SELF ORG MAPS; Millan J. R., 2004, IEEE T BIOMEDICAL EN, V51; MILLAN JD, 2002, HDB BRAIN THEORY NEU, P178; Millan JD, 2003, COMMUN ACM, V46, P74, DOI 10.1145/636772.636773; Millan JD, 2003, IEEE T NEUR SYS REH, V11, P159, DOI 10.1109/TNSRE.2003.814435; Millan JD, 1996, IEEE T SYST MAN CY B, V26, P408, DOI 10.1109/3477.499792; NICOLELIS MAL, 2001, NATURE, V409, P203; PERRIN F, 1990, ELECTROEN CLIN NEURO, V76, P565; PERRIN F, 1989, ELECTROEN CLIN NEURO, V72, P184, DOI 10.1016/0013-4694(89)90180-6; Pfurtscheller G, 2001, P IEEE, V89, P1123, DOI 10.1109/5.939829; SAAD D, 1998, ON LINE LEARNING NEU; Schaal S, 2002, APPL INTELL, V17, P49, DOI 10.1023/A:1015727715131; Serruya MD, 2002, NATURE, V416, P141, DOI 10.1038/416141a; Sutton R. S., 1998, REINFORCEMENT LEARNI; Taylor DM, 2002, SCIENCE, V296, P1829, DOI 10.1126/science.1070291; Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3; WOLPAW JR, 1994, ELECTROEN CLIN NEURO, V90, P444, DOI 10.1016/0013-4694(94)90135-X	20	14	14	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		0-7803-8359-1	IEEE IJCNN			2004							2877	2882				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	BBC97	WOS:000224941900496		
S	Zimmermann, J; Kiesling, C		Seibert, JA		Zimmermann, J; Kiesling, C			Neural networks for the H1 experiment	2004 IEEE NUCLEAR SCIENCE SYMPOSIUM CONFERENCE RECORD, VOLS 1-7	IEEE NUCLEAR SCIENCE SYMPOSIUM - CONFERENCE RECORD		English	Proceedings Paper	Nuclear Science Symposium/Medical Imaging Conference	OCT 16-22, 2004	Rome, ITALY	IEEE Commun Soc, Nucl & Plasma Sci Soc		neural networks; H1; statistical learning; trigger; classification; purification; background suppression	HERA	With its rising luminosity the HERA-2 period does not only produce more physics events for the H1 Detector but also - and in a more dramatic way - higher backgrounds. The Neural network trigger becomes more important than before because background rejection is now needed even for triggers that had no rate problem before. We will discuss several examples of newly developed neural network triggers ranging from deeply virtual compton scattering to charged current interactions. But also in offline analysis neural networks are a very powerful tool to separate event classes by complex pattern recognition. We will discuss the example of the search for instantons in the high Q(2) regime and show that the neural networks give higher separation powers for the event sample purification than other techniques.	Forschungszentrum Julich, D-52425 Julich, Germany	Zimmermann, J (reprint author), Forschungszentrum Julich, Postfach 1913, D-52425 Julich, Germany.						Abt I, 1997, NUCL INSTRUM METH A, V386, P310, DOI 10.1016/S0168-9002(96)00893-5; Hastie T., 2001, ELEMENTS STAT LEARNI; KOBLITZ B, 2002, THESIS U HAMBURG; Kohne JK, 1997, NUCL INSTRUM METH A, V389, P128, DOI 10.1016/S0168-9002(97)00062-4; Nilsson N. J., 1996, INTRO MACHINE LEARNI; PREVOTET JC, 2002, THESIS U P M CURIE	6	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1082-3654		0-7803-8700-7	IEEE NUCL SCI CONF R			2004							1869	1872				4	Nuclear Science & Technology; Physics, Nuclear; Radiology, Nuclear Medicine & Medical Imaging	Nuclear Science & Technology; Physics; Radiology, Nuclear Medicine & Medical Imaging	BCZ05	WOS:000232002102119		
B	Halstead, JB; Brown, DE		Jones, MH; Patek, SD; Tawney, BE		Halstead, JB; Brown, DE			Improving upon logistic regression to predict united states army delayed entry program (DEP) losses	2004 IEEE SYSTEMS & INFORMATION ENGINEERING DESIGN SYMPOSIUM			English	Proceedings Paper	IEEE Systems and Information Engineering Design Symposium	APR   16, 2004	Charlottesville, VA	IEEE				We improve upon McFadden's use of logistic regression for choice analysis. We investigate the use of neural networks, support vector machines, and random forest as functional approximations to improve upon the results obtained from logistic regression. The choice involves an Army enlisted applicant choosing between honoring their enlistment contract with the Army by shipping to basic combat training or choosing to not honor the contract and becoming a DEP Loss. An Army enlisted applicant is a person who signs an active duty enlistment contract with the United States Army. The enlistment contract contains various terms, such as: the length of the service, the Army job (Military Occupational Skill (MOS)), special schooling received by the applicant, and incentives. A shipper is an Army enlisted applicant who initially honors their Army contract. A DEP Loss is an Army enlisted applicant who doesn't honor their Army contract. We discover, for these data, both support vector machines and random forest outperform logistic regression. We also discover support vector machines outperforming all other functional approximations for these data. Performance is based on various metrics: Error rate, Type H error, and ROC Curves.	Univ Virginia, Charlottesville, VA 22904 USA	Halstead, JB (reprint author), Univ Virginia, 151 Engineers Way,POB 400747, Charlottesville, VA 22904 USA.						BENALKIVA ME, 1985, DISCRETE CHOICE ANAL; Beyer W. H., 1981, CRC STANDARD MATH TA; BREIMAN L, 2003, RANDOMFOREST PACKAGE; FOX J, 2002, R SPLUS COMPANION AP; Hastie T., 2001, ELEMENTS STAT LEARNI; Johnson R. A., 2002, APPL MULTIVARIATE ST; LIAW A, RANDOM FOREST ITS AP; McFadden D., 1973, FRONTIERS ECONOMETRI, P105; MILTON J. S., 2003, INTRO PROBABILITY ST; Neter J., 1996, APPL LINEAR REGRESSI; *US ARM ACC COMM, 2004, USAAC STRAT PLAN VER; Walpole R E., 1989, PROBABILITY STAT ENG; XUE YF, 2003, DECISION BASED SPATI, P153	13	0	0	UNIV VIRGINIA, DEPT SYSTEMS & INFORMATION ENGINEERING	CHARLOTTESVILLE	151 ENINEERS WAY, PO BOX 400747, CHARLOTTESVILLE, VA 22904-4747 USA			0-9744559-2-X				2004							191	201				11	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Transportation Science & Technology	Computer Science; Transportation	BAK77	WOS:000222652000025		
B	Nugent, A; Kenyon, G; Porter, R		Zebulum, RS; Gwaltney, D; Hornby, G; Keymeulen, D; Lohn, F; Stoica, A		Nugent, A; Kenyon, G; Porter, R			Unsupervised adaptation to improve fault tolerance of neural network classifiers	2004 NASA/DOD CONFERENCE ON EVOLVABLE HARDWARE, PROCEEDINGS			English	Proceedings Paper	6th NASA/DoD Conference on Evolvable Hardware	JUN 24-26, 2004	Seattle, WA	NASA, US Dept Def, IEEE Circuits & Syst Soc	Jet Propuls Lab			We investigate how to exploit the dynamics of unsupervised online learning rules for fault tolerance in neural network classifiers. We first design an adaptation mechanism that keeps neural network weights at a useful fixed point for classification problems. We then demonstrate the robustness of the system when the network inputs are subjected to faults.	Biophys Grp, Space Data Syst Grp, Los Alamos, NM 87545 USA	Nugent, A (reprint author), Biophys Grp, Space Data Syst Grp, Los Alamos, NM 87545 USA.						Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; DOTAN Y, 1998, IEEE T NEURAL NETWOR, V9; HADDOW PC, 2001, 3 NASA DOD WORKSH EV; Hastie T., 2001, ELEMENTS STAT LEARNI; Hyvarinen A, 2001, INDEPENDENT COMPONEN; INTRATOR N, 1992, NEURAL NETWORKS, V5, P3, DOI 10.1016/S0893-6080(05)80003-6; OJA E, 1982, J MATH BIOL, V15, P267, DOI 10.1007/BF00275687; SIGILLITO V, UCI MACHINE LEARNING	8	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2145-2				2004							146	149				4	Computer Science, Hardware & Architecture	Computer Science	BAN41	WOS:000222965600022		
J	Gur, D; Wagner, RF; Chan, HP				Gur, D; Wagner, RF; Chan, HP			On the repeated use of databases for testing incremental improvement of computer-aided detection schemes	ACADEMIC RADIOLOGY			English	Editorial Material							FINITE-SAMPLE SIZE; CLASSIFIERS; PERFORMANCE; DIAGNOSIS		Univ Pittsburgh, Dept Radiol, Pittsburgh, PA 15213 USA; US FDA, Off Sci & Technol, Ctr Devices & Radiol Hlth, Rockville, MD USA; Univ Michigan, Dept Radiol, Ann Arbor, MI 48109 USA	Gur, D (reprint author), Univ Pittsburgh, Dept Radiol, Suite 4200,300 Halket St, Pittsburgh, PA 15213 USA.						Beiden SV, 2003, IEEE T PATTERN ANAL, V25, P1561, DOI 10.1109/TPAMI.2003.1251149; Chan HP, 1999, MED PHYS, V26, P2654, DOI 10.1118/1.598805; Clarke LP, 2001, ACAD RADIOL, V8, P447, DOI 10.1016/S1076-6332(03)80555-X; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Fukunaga K., 1990, STAT PATTERN RECOGNI; Hastie T., 2001, ELEMENTS STAT LEARNI; Sahiner B, 2000, MED PHYS, V27, P1509, DOI 10.1118/1.599017	7	9	11	ASSOC UNIV RADIOLOGISTS	OAK BROOK	820 JORIE BLVD, OAK BROOK, IL 60523-2251 USA	1076-6332			ACAD RADIOL	Acad. Radiol.	JAN	2004	11	1					103	105		10.1016/S1076-6332(03)00511-7		3	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	759CR	WOS:000187721200015	14746409	
S	Lucas, PJF		Gamez, JA; Moral, S; Salmeron, A		Lucas, PJF			Restricted Bayesian network structure learning	ADVANCES IN BAYESIAN NETWORKS	STUDIES IN FUZZINESS AND SOFT COMPUTING		English	Proceedings Paper	1st European Workshop on Probabilistic Graphical Models (PGM 02)	NOV, 2002	Cuenca, SPAIN				INTERNIST-1/QMR KNOWLEDGE BASE; NORMATIVE EXPERT SYSTEMS; COPENHAGEN POCKET CHART; ACUTE ABDOMINAL-PAIN; DIFFERENTIAL-DIAGNOSIS; DECISION-SUPPORT; JAUNDICE; COMPUTER; MODEL; REFORMULATION	Learning the structure of a Bayesian network from data is a difficult problem, as its associated search space is superexponentially large. As a consequence, researchers have studied learning Bayesian networks with a fixed structure, notably naive Bayesian networks and tree-augmented Bayesian networks, which involves no search at all. There is substantial evidence in the literature that the performance of such restricted networks can be surprisingly good. In this paper, we propose a restricted, polynomial time structure learning algorithm that is not as restrictive as both other approaches, and allows researchers to determine the right balance between classification performance and quality of the underlying probability distribution. The results obtained with this algorithm allow drawing some conclusions with regard to Bayesian- network structure learning in general.	Univ Nijmegen, Inst Comp & Informat Sci, NL-6525 ED Nijmegen, Netherlands	Lucas, PJF (reprint author), Univ Nijmegen, Inst Comp & Informat Sci, Toernooiveld 1, NL-6525 ED Nijmegen, Netherlands.		Lucas, Peter/D-1708-2012				Andreassen S., 1987, P 10 INT JOINT C ART, P366; Berthold M., 1999, INTELLIGENT DATA ANA; BURBANK F, 1996, AM J MED, V46, P401; Cheng J., 1999, P 15 C UNC ART INT U, P101; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; Cowell R.G., 1999, PROBABILISTIC NETWOR; DEDOMBAL FT, 1991, BRIT MED J, V302, P1495; DEDOMBAL FT, 1984, FRONTIERS GASTROINTE, V7, P119; DEDOMBAL FT, 1972, BRIT MED J, V2, P9; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GORRY GA, 1968, COMPUT BIOMED RES, V1, P490, DOI 10.1016/0010-4809(68)90016-5; Hastie T., 2001, ELEMENTS STAT LEARNI; HECKERMAN DE, 1992, PROBABILISTIC SIMILA; HECKERMAN DE, 1992, METHOD INFORM MED, V31, P90; HECKERMAN DE, 1992, METHOD INFORM MED, V31, P106; KNILLJON.RP, 1973, BRIT MED J, V1, P530; KORVER M, 1993, MED INFORM, V18, P219; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; LINDBERG G, 1987, LIVER, V7, P43; Lucas P, 1991, PRINCIPLES EXPERT SY; Lucas PJF, 1998, METHOD INFORM MED, V37, P206; Lucas PJF, 2000, ARTIF INTELL MED, V19, P251, DOI 10.1016/S0933-3657(00)00048-8; MALCHOWMOLLER A, 1987, LIVER, V7, P333; MALCHOWMOLLER A, 1986, J HEPATOL, V3, P154, DOI 10.1016/S0168-8278(86)80021-6; MARTIN WB, 1960, AM J MED SCI, V240, P571; MATZEN P, 1984, LIVER, V4, P360; MIDDLETON B, 1991, METHOD INFORM MED, V30, P256; Monti S., 1999, P 15 C UNC ART INT S, P447; ONISKO A, 2001, P 8 C ART INT MED EU, P283; RAMONI M, 1999, INTELLIGENT DATA ANA, P130; SEGAAR RW, 1988, NETH J MED, V33, P5; SHWE MA, 1991, METHOD INFORM MED, V30, P241; SPIEGELHALTER DJ, 1984, J ROY STAT SOC A STA, V147, P35, DOI 10.2307/2981737; SPIEGELHALTER DJ, 1990, UNCERTAINTY ARTIFICI, V5, P285; TODD BS, 1993, TECHNICAL MONOGRAPH, V109; WARNER HR, 1961, JAMA-J AM MED ASSOC, V177, P177	37	9	10	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1434-9922		3-540-20876-3	STUD FUZZ SOFT COMP			2004	146						217	234				18	Computer Science, Artificial Intelligence; Statistics & Probability	Computer Science; Mathematics	BAB70	WOS:000221494100012		
S	Arshadi, N; Jurisica, I		Funk, P; Calero, PAG		Arshadi, N; Jurisica, I			Maintaining case-based reasoning systems: A machine learning approach	ADVANCES IN CASE-BASED REASONING, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	7th European Conference on Case-Based Reasoning	AUG 30-SEP 02, 2004	Madrid, SPAIN	Spanish Minist Sci & Technol, Musicstrands, Kaidara Software, PricewaterhouseCoopers, Ctr Adv Res, Malardalen Univ, Dept Comp Sci & Engn, Univ Complutense Madrid, Dept Sistem Informat Programmac			GENE-EXPRESSION; NEAREST-NEIGHBOR; KNOWLEDGE; MICROARRAYS; PREDICTION	Over the years, many successful applications of case-based reasoning (CBR) systems have been developed in different areas. The performance of CBR systems depends on several factors, including case representation, similarity measure, and adaptation. Achieving good performance requires careful design, implementation, and continuous optimization of these factors. In this paper, we propose a maintenance technique that integrates an ensemble of CBR classifiers with spectral clustering and logistic regression to improve the classification accuracy of CBR classifiers on (ultra) high-dimensional biological data sets. Our proposed method is applicable to any CBR system; however, in this paper, we demonstrate the improvement achieved by applying the method to a computational framework of a CBR system called TA3.. We have evaluated the system on two publicly available microarray data sets that cover leukemia and lung cancer samples. Our maintenance method improves the classification accuracy of TA3 by approximately 20% from 65% to 79% for the leukemia and from 60% to 70% for the lung cancer data set.	Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada; Princess Margaret Hosp, Ontario Canc Inst, Univ Hlth Network, Div Canc Informat, Toronto, ON M5G 2M9, Canada	Jurisica, I (reprint author), Univ Toronto, Dept Comp Sci, 10 Kings Coll Rd, Toronto, ON M5S 3G4, Canada.	ij@uhnres.utoronto.ca					Aha D.W., 1994, P AAAI 94 WORKSH CAS, P106; ARSHADI N, 2004, CSRG490 U TOR DEP CO; Baeza-Yates R., 1999, MODERN INFORMATION R; Dunn J. C., 1974, Journal of Cybernetics, V4; FRANCIS AG, 1993, P 1993 AAAI WORKSH C; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; HAN J., 2000, DATA MINING CONCEPTS; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T., 2001, ELEMENTS STAT LEARNI; Jaeger J., 2003, PAC S BIOC, V8, P53; John G. H., 1994, MACH LEARN, P121; JONES L, 2003, CRITICAL ASSESSMENT, P38; Jurisica I, 2001, IBM SYST J, V40, P394; JURISICA I, 2004, BIOINFORMATICS, V25, P85; Jurisica I, 1998, ARTIF INTELL MED, V12, P1, DOI 10.1016/S0933-3657(97)00037-7; Jurisica I, 2000, APPL INTELL, V12, P251, DOI 10.1023/A:1008375309626; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohonen T., 1995, SELF ORG MAPS; LEAKE D, 1999, P 3 INT C CAS BAS RE, P203; Leake D. B., 2000, Advances in Case-Based Reasoning. 5th European Workshop, EWCBR 2000. Proceedings (Lecture Notes in Artificial Intelligence Vol.1898); LEAKE DB, 1998, P 4 EUR WORKSH CAS B, P196; LEAKE SB, 1996, P 13 NAT C ART INT 8, P648; Lenz M., 1998, CASE BASED REASONING; Molla M, 2004, AI MAG, V25, P23; MYLOPOULOS J, 1990, ACM T INFORM SYST, V8, P325, DOI 10.1145/102675.102676; NG AY, 2002, ADV NEURAL INFORMATI, V14; Quackenbush J, 2001, NAT REV GENET, V2, P418, DOI 10.1038/35076576; Richter M. M., 1998, Case-based reasoning technology. From foundations to applications; Shiu SCK, 2001, COMPUT INTELL, V17, P295, DOI 10.1111/0824-7935.00146; SMYTH B, 1999, P 3 INT C CAS BAS RE, P329; SMYTH B, 1998, 11 INT C IND ENG APP, V2, P507; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; Wilson DC, 2001, COMPUT INTELL-US, V17, P196, DOI 10.1111/0824-7935.00140; XING EP, 2003, PRACTICAL APPROACH M, P110, DOI 10.1007/0-306-47815-3_6; Xing EP, 2001, P 18 INT C MACH LEAR, P601; Yang Q, 2000, LECT NOTES ARTIF INT, V1822, P102; ZHANG Z, 1999, P 15 INT JOINT C ART, P228	39	5	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-22882-9	LECT NOTES COMPUT SC			2004	3155						17	31				15	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BAV76	WOS:000223825700003		
S	Tong, HG; Li, MJ; Zhang, HJ; He, JR; Zhang, CS		Aizawa, K; Nakamura, Y; Satoh, S		Tong, HG; Li, MJ; Zhang, HJ; He, JR; Zhang, CS			Classification of digital photos taken by photographers or home users	ADVANCES IN MULTIMEDIA INFORMATION PROCESSING - PCM 2004, PT 1, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	5th Pacific Rim Conference on Multimedia	NOV 30-DEC 03, 2004	Tokyo, JAPAN	IEEE Circuits & Syst Soc, IEEE Region 10, IEEE Japan Council, ACM SIGMM, IEICE, ITE				In this paper, we address a specific image classification task, i.e. to group images according to whether they were taken by photographers or home users. Firstly, a set of low-level features explicitly related to such high-level semantic concept are investigated together with a set of general-purpose low-level features. Next, two different schemes are proposed to find out those most discriminative features and feed them to suitable classifiers: one resorts to boosting to perform feature selection and classifier training simultaneously; the other makes use of the information of the label by Principle Component Analysis for feature reextraction and feature de-correlation; followed by Maximum Marginal Diversity for feature selection and Bayesian classifier or Support Vector Machine for classification. In addition, we show an application in No-Reference holistic quality assessment as a natural extension of such image classification. Experimental results demonstrate the effectiveness of our methods.	Tsing Hua Univ, Automat Dept, Beijing 100084, Peoples R China; Microsoft Res Asia, Beijing 100080, Peoples R China	Tong, HG (reprint author), Tsing Hua Univ, Automat Dept, Beijing 100084, Peoples R China.	walkstar98@mails.tsinghua.edu.cn; mjli@microsoft.com; hjzhang@microsoft.com; hejingrui98@mails.tsinghua.edu.cn; zcs@tsinghua.edu.cn					ATHITSOS V, 1997, IEEE WORKSH CBAIVL; Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Hasler D, 2003, P SOC PHOTO-OPT INS, V5007, P87, DOI 10.1117/12.477378; Hastie T., 2001, ELEMENTS STAT LEARNI; HE JR, 2004, P ICPR; Huang J, 1997, PROC CVPR IEEE, P762; Ma Y.F., 2002, ACM MULT C, P533; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; MAO JC, 1992, PATTERN RECOGN, V25, P173, DOI 10.1016/0031-3203(92)90099-5; Oliveira CJS, 2002, SIBGRAPI 2002: XV BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P327; Pass G., 1997, ACM INT C MULT, P65; Serrano N., 2002, Proceedings 16th International Conference on Pattern Recognition, DOI 10.1109/ICPR.2002.1047420; SHEIKH HR, 2002, BLIND QUALITY ASSESS; Stricker M., 1995, SPIE, V2420, P381; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999; TONG HH, 2004, P ICIP; TONG HH, 2004, P ICME; Vasconcelos N, 2003, PROC CVPR IEEE, P762; Wang JZ, 1998, INT J DIGITAL LIB, V4, P311, DOI 10.1007/s007990050026	21	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-23974-X	LECT NOTES COMPUT SC			2004	3331						198	205				8	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BBL54	WOS:000226023600025		
S	Conversano, C		Bock, HH; Chiodi, M; Mineo, A		Conversano, C			Smoothing score algorithm for generalized additive models	ADVANCES IN MULTIVARIATE DATA ANALYSIS	STUDIES IN CLASSIFICATION, DATA ANALYSIS, AND KNOWLEDGE ORGANIZATION		English	Proceedings Paper	Meeting of the Classification-and-Data-Analysis-Group of the Italian-Statistical-Society	JUL 05-06, 2001	Palermo, ITALY	Italian Stat Soc, Classificat & Data Anal Grp	Univ Palermo			In the framework of Generalized Additive Models (CAM) an automatic data-driven procedure is introduced for assigning an appropriate smoother to each covariate and for defining an ordering entrance for the covariates in the model. The resulting Smoothing Score algorithm aims to improve model indentifiability. It uses the bagging procedure in order to select the smoothers to be assigned to each covariate and a new scoring measure able to rank the candidate smoothers with respect to their bagged predictive accuracy. The adequacy of this scoring measure is evaluated on artificial data. A comparison between the smoothing score algorithm and the standard CAM is made using real data concerning a classification task.	Univ Cassino, Fac Econ, Dipartimento Econ & Territorio, I-03043 Cassino, Italy	Conversano, C (reprint author), Univ Cassino, Fac Econ, Dipartimento Econ & Territorio, Via Mazzaroppi, I-03043 Cassino, Italy.						Blake C.L., 1998, UCI REPOSITORY MACHI; BREIMAN L, 1996, MACH LEARN, V26, P46; Conversano C, 2002, PATTERN ANAL APPL, V5, P351, DOI 10.1007/s100440200031; Conversano C, 2002, COMPUT STAT DATA AN, V38, P487, DOI 10.1016/S0167-9473(01)00074-3; CONVERSANO C, 2001, NEW TRENDS STAT MODE, P103; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T J, 1992, STAT MODELS S; Hastie T. J., 1990, GENERALIZED ADDITIVE; Schimek M. G., 2000, SMOOTHING REGRESSION	9	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1431-8814		3-540-20889-5	ST CLASS DAT ANAL			2004							95	107				13	Mathematics, Applied; Statistics & Probability	Mathematics	BBB79	WOS:000224587900008		
S	Zhu, J; Rosset, S; Hastie, T; Tibshirani, R		Thrun, S; Saul, K; Scholkopf, B		Zhu, J; Rosset, S; Hastie, T; Tibshirani, R			1-norm support vector machines	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 16	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS		English	Proceedings Paper	17th Annual Conference on Neural Information Processing Systems (NIPS)	DEC   08, 2003	CANADA				CLASSIFICATION; SELECTION; CANCER	The standard 2-norm SVM is known for its good performance in two-class classipoundcation. In this paper, we consider the 1-norm SVM. We argue that the 1-norm SVNI may have some advantage over the standard 2-norm SVM, especially when there are redundant noise features. We also propose an efpoundcient algorithm that computes the whole solution path of the 1-norm SVNI, hence facilitates adaptive selection of the tuning parameter for the 1-norm SVM.	Stanford Univ, Dept Stat, Stanford, CA 94305 USA	Zhu, J (reprint author), Stanford Univ, Dept Stat, Stanford, CA 94305 USA.						Bradley Paul S., 1998, ICML 98; EVGENIOU T, 1999, ADV LARGE MARGIN CLA; FRIEDMAN J, 2004, IN PRESS ANN STAT; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; HASTIE T, 2001, ELEMENTS STAT LEANRI; MUKHERJEE S, 1999, 1677 MIT; ROSSET S, 2003, TECHNICAL REPORT DEP; SONG M, J CHEM INFORMATI SEP; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Vapnik VN, 1995, NATURE STAT LEARNING; Wahba G, 1999, ADVANCES IN KERNEL METHODS, P69; Zhu J, 2003, THESIS STANFORD U; ZHU J, 2003, IN PRESS CLASSIFICAT	14	60	66	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	1049-5258		0-262-20152-6	ADV NEUR IN			2004	16						49	56				8	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	BBF99	WOS:000225309500007		
S	Mizutani, E; Demmel, JW		Thrun, S; Saul, K; Scholkopf, B		Mizutani, E; Demmel, JW			Iterative scaled trust-region learning in Krylov subspaces via Pearlmutter's implicit sparse Hessian-vector multiply	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 16	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS		English	Proceedings Paper	17th Annual Conference on Neural Information Processing Systems (NIPS)	DEC   08, 2003	CANADA					The online incremental gradient (or backpropagation) algorithm is widely considered to be the fastest method for solving large-scale neural-network (NN) learning problems. In contrast, we show that, an appropriately implemented iterative batch-mode (or block-mode) learning method can be much faster. For example, it is three times faster in the UCI letter classification problem (26 outputs, 16,000 data items, 6,066 parameters with a two-hidden-layer multilayer perceptron) and 353 times faster in a nonlinear regression problem arising in color recipe prediction (10 outputs, 1,000 data items, 2,210 parameters with a neuro-fuzzy modular network). The three principal innovative ingredients in our algorithm are the following: First, we use scaled trust-region regularization with inner-outer iteration to solve the associated "overdetermined" nonlinear least squares problem, where the inner iteration performs a truncated (or inexact) Newton method. Second, we employ Pearlmutter's implicit sparse Hessian matrix-vector multiply algorithm to construct the Krylov subspaces used to solve for the truncated Newton update. Third, we exploit sparsity (for preconditioning) in the matrices resulting from the NNs having many outputs.	Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 300, Taiwan	Mizutani, E (reprint author), Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 300, Taiwan.						Amari S, 1998, NEURAL COMPUT, V10, P251, DOI 10.1162/089976698300017746; Conn A.R., 2000, TRUST REGION METHODS; Demmel J. W., 1997, APPL NUMERICAL LINEA; DENNIS JE, 1981, ACM T MATH SOFTWARE, V7, P3; Hastie T., 2002, ELEMENTS STAT LEARNI; Jacobs M, 2001, CHEM ENG NEWS, V79, P3, DOI 10.1021/cen-v079n030.p003; MIZUTANI E, 2001, P INNS IEEE INT JOIN, V1, P347; MIZUTANI E, 2002, P IEEE INT JOINT C N, V3, P2399; Mizutani E, 2003, NEURAL NETWORKS, V16, P745, DOI 10.1016/S0893-6080(03)00085-6; MORE JJ, 1983, SIAM J SCI STAT COMP, V4, P553; PEARLMUTTER BA, 1994, NEURAL COMPUT, V6, P147, DOI 10.1162/neco.1994.6.1.147; Schwenk H, 2000, NEURAL COMPUT, V12, P1869, DOI 10.1162/089976600300015178; STEIHAUG T, 1983, SIAM J NUMER ANAL, V20, P626, DOI 10.1137/0720042	13	7	7	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	1049-5258		0-262-20152-6	ADV NEUR IN			2004	16						209	216				8	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	BBF99	WOS:000225309500027		
S	Zheng, AX; Jordan, MI; Liblit, B; Aiken, A		Thrun, S; Saul, K; Scholkopf, B		Zheng, AX; Jordan, MI; Liblit, B; Aiken, A			Statistical debugging of sampled programs	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 16	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS		English	Proceedings Paper	17th Annual Conference on Neural Information Processing Systems (NIPS)	DEC   08, 2003	CANADA					We present a novel strategy for automatically debugging programs given sampled data from thousands of actual user runs. Our goal is to pinpoint those features that are most correlated with crashes. This is accomplished by maximizing an appropriately defined utility function. It has analogies with intuitive debugging heuristics, and, as we demonstrate, is able to deal with various types of bugs that occur in real programs.	Univ Calif Berkeley, EE Div, Berkeley, CA 94720 USA	Zheng, AX (reprint author), Univ Calif Berkeley, EE Div, Berkeley, CA 94720 USA.						Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hastie T., 2001, ELEMENTS STAT LEARNI; JAPKOWICZ N, 2002, INTELLIGENT DATA ANA, V6; Lehmann E., 1986, TESTING STAT HYPOTHE; LIBLIT B, 2003, ACM SIGPLAN PLDI 200; Urruty J.- B. Hiriart-, 1993, CONVEX ANAL MINIMIZA, VII	7	0	0	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	1049-5258		0-262-20152-6	ADV NEUR IN			2004	16						603	610				8	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	BBF99	WOS:000225309500076		
S	Rosset, S; Zhu, J; Hastie, T		Thrun, S; Saul, K; Scholkopf, B		Rosset, S; Zhu, J; Hastie, T			Margin maximizing loss functions	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 16	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS		English	Proceedings Paper	17th Annual Conference on Neural Information Processing Systems (NIPS)	DEC 08, 2003	CANADA					Margin maximizing properties play an important role in the analysis of classification models, such as boosting and support vector machines. Margin maximization is theoretically interesting because it facilitates generalization error analysis, and practically interesting because it presents a clear geometric interpretation of the models being built. We formulate and prove a sufficient condition for the solutions of regularized loss functions to converge to margin maximizing separators, as the regularization vanishes. This condition covers the hinge loss of SVM, the exponential loss of AdaBoost and logistic regression loss, We also generalize it to multi-class classification problems, and present margin maximizing multiclass versions of logistic regression and support vector machines.	IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA	Rosset, S (reprint author), IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.	srosset@us.ibm.com; jizhu@umich.edu; hastie@stat.stanford.edu					Bartlett P. L., 2003, CONVEXITY CLASSIFICA; Breiman L, 1999, NEURAL COMPUT, V11, P1493, DOI 10.1162/089976699300016106; Freund Y., 1995, P 2 EUR C COMP LEARN; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; GROVE AJ, 1998, P 15 NAT C AI; Hastie T., 2001, ELEMENTS STAT LEARNI; Mangasarian OL, 1999, OPER RES LETT, V24, P15, DOI 10.1016/S0167-6377(98)00049-2; ROSSET R, 2003, BOOSTING REGULARIZED; SCAHPIRE RE, 1998, ANN STAT, V26, P1651; Vapnik VN, 1995, NATURE STAT LEARNING; Weston J, 1998, CSDTR9804 U LOND	11	0	0	MIT PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	1049-5258		0-262-20152-6	ADV NEUR IN			2004	16						1237	1244				8	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	BBF99	WOS:000225309500154		
S	Sousa, PAC; Pimentao, JP; Santos, BRD; Garcao, AS		Menasalvas, E; Chavez, E		Sousa, PAC; Pimentao, JP; Santos, BRD; Garcao, AS			Analysis of a web content categorization system based on multi-agents	ADVANCES IN WEB INTELLIGENCE, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	2nd International Atlantic Web Intelligence Conference (AWIC 2004)	MAY 16-19, 2004	Cancun, MEXICO	Ctr Investigac Cientif Educ Super Ensenada, Inst Nac Astrofis Opt Elect, Univ Michoacan San Nicolas Hidalgo, Univ Politean Madrid, Soc Mexicana Cienc Computac				This paper presents a Multi-Agent based web content categorization system. The system was prototyped using an Agents' Framework for Internet data collection. The agents employ supervised learning techniques, specifically text learning to capture users preferences. The Framework and its application to E-commerce are described and the results achieve during the IST DEEPSIA project are shown. A detailed description of the most relevant system agents as well as their information flow is presented. The advantages derived from agent's technology application are conferred.	Univ Nova Lisboa, Fac Ciencias & Tecnol, Caparica, Portugal; Univ Nova Lisboa, Caparica, Portugal	Sousa, PAC (reprint author), Univ Nova Lisboa, Fac Ciencias & Tecnol, Caparica, Portugal.	pas@fct.unl.pt; pim@fct.unl.pt; brd@uninova.pt; asg@uninova.pt	Sousa, Pedro/A-8849-2011; Garcao, Adolfo/A-5344-2012; Pimentao, Joao/A-7691-2012	Garcao, Adolfo/0000-0002-5134-2794; 			AULT T, 2001, ROCCHIO METRICS INFO; BELLIFEMINE F, 1999, JADE COMPLIANT AGENT; *ECCMA, 2002, ECCMA 2002; *FIPA ACL MESS STR, 2000, FIPA00061; GHANI R, ICML01 18 INT C MACH; Hastie T., 2001, ELEMENTS STAT LEARNI; HORSTMANN C, 2003, COMPUTING CONCEPTS J; JUNKER M, 1999, 5 INT C DOC AN REC B; Mitchell T. M., 1996, MACHINE LEARNING; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; SARLE W, 2003, WHAT CROSS VALIDATIO; SOUSA PA, 2002, FRAMEWORK INTERNAT D; TAN T, 1993, DEVELOPMENT INTELLIG; VONRIJSBERGEN C, 1979, INFORMATION RETRIEVA; YANG Y, 1999, SIGIR99; YANG YJ, 1997, ICML97 14 2NT C MACH	16	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-22009-7	LECT NOTES ARTIF INT			2004	3034						184	195				12	Computer Science, Artificial Intelligence	Computer Science	BAE37	WOS:000221807000019		
J	Orlandi, F; Lanari, D; Pieroni, L; Romano, B; Fornaciari, M				Orlandi, F; Lanari, D; Pieroni, L; Romano, B; Fornaciari, M			Instrumental test to estimate a model of forecast yield: a non-parametric application to the pollen index in South Italy	ANNALS OF APPLIED BIOLOGY			English	Article						pollen index; principal component analysis; non parametric estimation; optimal specification; forecast yield	OLEA-EUROPAEA; REGRESSION; OLIVE	A statistical test is described to verify the characteristics of the biological information contained in the dynamics of the flowering process. The test focuses on interactions between the pollen index and climatic variables to investigate if the biological indicator can synthesise the information of the pre-flowering phases. The multiple-regression model is built upon two pre-flowering climate macro-indicators extracted by Principal Component Analysis (PCA) and the optimised pollen index is obtained by non-parametric estimation. The empirical analysis is applied to 15 stations located in southern Italy in regions that have a long-standing tradition of olive production. Using the variance explained, we find that an optimised pollen index is fairly well predicted by the pre-flowering climatic data. We conclude that the optimised pollen index makes more parsimonious the modelling for predicting olive production.	Univ Perugia, Dept Plant Biol & Agroenvironm Biotechnol, I-06121 Perugia, Italy; Univ Perugia, Dept Econ, I-06123 Perugia, Italy	Orlandi, F (reprint author), Univ Perugia, Dept Plant Biol & Agroenvironm Biotechnol, Borgo 20 Giugno 74, I-06121 Perugia, Italy.	fabor@unipg.it	Orlandi, Fabio/F-6017-2012; Fornaciari da Passano, Marco/F-6768-2014				BROUSSES E, 1991, ANAL CONNAISSANCES C; BUJA A, 1989, ANN STAT, V17, P453, DOI 10.1214/aos/1176347115; DEBOISSEZON H, 1995, P WORKSH CENTR E EUR; Fornaciari M, 2002, ECON BOT, V56, P66, DOI 10.1663/0013-0001(2002)056[0066:ANATCT]2.0.CO;2; Fornaciari M., 1997, Agricoltura Mediterranea, V127, P134; FORNACIARI M, 2000, POMA31 PROGETTO REAL; Fornaciari M, 1998, GRANA, V37, P110; Galan C, 2004, FIELD CROP RES, V86, P43, DOI 10.1016/S0378-4290(03)00170-9; HACKETT WP, 1967, PHYSIOL PLANTARUM, V20, P430, DOI 10.1111/j.1399-3054.1967.tb07183.x; Hastie T., 2002, ELEMENTS STAT LEARNI; HIRST JM, 1952, ANN APPL BIOL, V39, P257, DOI 10.1111/j.1744-7348.1952.tb00904.x; LEBART L, 1997, STAT EXPLORATIVE MUL; LeBlanc M, 1996, J AM STAT ASSOC, V91, P1641, DOI 10.2307/2291591; Miller AJ, 1990, SUBSET SELECTION REG; PALM R, 1995, P WORKSH CENTR E EUR; PALM R, 1991, B RECHERCHE AGRONOMI, V26, P71; PIERONI L, 1998, P 6 INT C AER AUG 31; SHARMAN M, 1992, P 43 C INT ASTR FED; Silverman BW, 1986, DENSITY ESTIMATION S	19	3	3	ASSOC APPLIED BIOLOGISTS	WARWICK	C/O HORTICULTURE RESEARCH INT WELLSBOURNE, WARWICK CV35 9EF, ENGLAND	0003-4746			ANN APPL BIOL	Ann. Appl. Biol.		2004	145	1					81	90		10.1111/j.1744-7348.2004.tb00362.x		10	Agriculture, Multidisciplinary	Agriculture	848LX	WOS:000223470300010		
J	Kersten, D; Mamassian, P; Yuille, A				Kersten, D; Mamassian, P; Yuille, A			Object perception as Bayesian inference	ANNUAL REVIEW OF PSYCHOLOGY			English	Review						shape; material; depth; vision; neural; psychophysics; fMRI; computer vision	GENERIC VIEWPOINT ASSUMPTION; PRIMARY VISUAL-CORTEX; NATURAL IMAGES; LIGHTNESS PERCEPTION; MOTION INTEGRATION; SURFACE CURVATURE; POPULATION CODES; IDEAL OBSERVERS; CUE COMBINATION; CAST SHADOWS	We perceive the shapes and material properties of objects quickly and reliably despite the complexity and objective ambiguities of natural images. Typical images are highly complex because they consist of many objects embedded in background clutter. Moreover, the image features of an object are extremely variable and ambiguous owing to the effects of projection, occlusion, background clutter, and illumination. The very success of everyday vision implies neural mechanisms, yet to be understood, that discount irrelevant information and organize ambiguous or noisy local image features into objects and surfaces. Recent work in Bayesian theories of visual perception has shown how complexity may be managed and ambiguity resolved through the task-dependent, probabilistic integration of prior object knowledge with image features.	Univ Minnesota, Dept Psychol, Minneapolis, MN 55455 USA; Univ Glasgow, Dept Psychol, Glasgow G12 8QB, Lanark, Scotland; Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA; Univ Calif Los Angeles, Dept Psychol, Los Angeles, CA 90095 USA	Kersten, D (reprint author), Univ Minnesota, Dept Psychol, Minneapolis, MN 55455 USA.	kersten@umn.edu	Mamassian, Pascal/F-4781-2012				Albert MK, 2000, PERCEPTION, V29, P601, DOI 10.1068/p3050; Albright TD, 2002, ANNU REV NEUROSCI, V25, P339, DOI 10.1146/annurev.neuro.25.112701.142900; Atick JJ, 1996, NEURAL COMPUT, V8, P1321, DOI 10.1162/neco.1996.8.6.1321; BARLOW HB, 1962, J PHYSIOL-LONDON, V160, P155; Berger JO, 1985, STAT DECISION THEORY; Bertamini M, 2001, PERCEPTION, V30, P1295, DOI 10.1068/p3197; Biederman I, 2000, SPATIAL VISION, V13, P241, DOI 10.1163/156856800741063; BLAKE A, 1990, NATURE, V343, P165, DOI 10.1038/343165a0; Bloj MG, 1999, NATURE, V402, P877; Brady MJ, 2003, J VISION, V3, P413, DOI 10.1167/3.6.2; Brainard DH, 1997, J OPT SOC AM A, V14, P1393, DOI 10.1364/JOSAA.14.001393; BUCKLEY D, 1994, PERCEPTION, V23, P869, DOI 10.1068/p230869; Bullier J, 2001, BRAIN RES REV, V36, P96, DOI 10.1016/S0165-0173(01)00085-6; Bulthoff HH, 1991, COMMENTS THEORETICAL, V2, P283; BULTHOFF HH, 1988, J OPT SOC AM A, V5, P1749, DOI 10.1364/JOSAA.5.001749; Burgi PY, 2000, NEURAL COMPUT, V12, P1839, DOI 10.1162/089976600300015169; Clark J. J., 1990, DATA FUSION SENSORY; Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778; DAYAN P, 1995, NEURAL COMPUT, V7, P889, DOI 10.1162/neco.1995.7.5.889; DEBEVEC P, 1998, SIGGRAPH; DROR RO, 2001, P CVPR HAW; Eckstein MP, 2000, PERCEPT PSYCHOPHYS, V62, P425, DOI 10.3758/BF03212096; Elder James H, 2002, J Vis, V2, P324, DOI 10.1167/2.4.5; Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a; Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316; Feldman J, 2001, PERCEPT PSYCHOPHYS, V63, P1171, DOI 10.3758/BF03194532; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; Fine I, 2003, J OPT SOC AM A, V20, P1283, DOI 10.1364/JOSAA.20.001283; Fleming RW, 2003, J VISION, V3, P347, DOI 10.1167/3.5.3; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; FREEMAN WT, 1994, NATURE, V368, P542, DOI 10.1038/368542a0; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; Geisler WS, 2001, VISION RES, V41, P711, DOI 10.1016/S0042-6989(00)00277-7; GEISLER WS, 1995, VISION RES, V35, P2723, DOI 10.1016/0042-6989(95)00029-Y; Geisler WS, 2002, NAT NEUROSCI, V5, P508, DOI 10.1038/nn0602-508; Gepshtein S, 2003, CURR BIOL, V13, P483, DOI 10.1016/S0960-9822(03)00133-7; POGGIO T, 1990, SCIENCE, V247, P978, DOI 10.1126/science.247.4945.978; Gold JI, 2001, TRENDS COGN SCI, V5, P10, DOI 10.1016/S1364-6613(00)01567-9; GREEN DM, 1996, ELEMENTS PATTERN THE; GREEN DM, 1974, SIGNAL DETECTION THE; Grill-Spector K, 2001, VISION RES, V41, P1409, DOI 10.1016/S0042-6989(01)00073-6; Grill-Spector K., 2003, CURR OPIN NEUROBIOL, V13, P1; Hastie T., 2001, ELEMENTS STAT LEARNI; HELMHOLTZ H, 1867, DB PHYSL OPTIK; HILL H, 1993, PERCEPTION, V22, P887, DOI 10.1068/p220887; Hillis JM, 2002, SCIENCE, V298, P1627, DOI 10.1126/science.1075396; Hinton GE, 1997, PHILOS T ROY SOC B, V352, P1177; Howe CQ, 2002, P NATL ACAD SCI USA, V99, P13184, DOI 10.1073/pnas.162474299; Humphrey GK, 1997, CURR BIOL, V7, P144, DOI 10.1016/S0960-9822(06)00058-3; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Jacobs RA, 2002, TRENDS COGN SCI, V6, P345, DOI 10.1016/S1364-6613(02)01948-4; Jensen HW, 2001, COMP GRAPH SIGGRAPH; KANIZSA G, 1976, VISION ARTIFACT; Kersten D., 1999, NEW COGNITIVE NEUROS, P353; KERSTEN D, 2002, PERCEPTION PHYSICAL; Kersten D, 1997, PERCEPTION, V26, P171, DOI 10.1068/p260171; Kersten D., 2003, CURRENT OPINION NEUR, V13, P1; Knill D, 1996, PERCEPTION BAYESIAN; Knill DC, 1998, VISION RES, V38, P1683, DOI 10.1016/S0042-6989(97)00325-8; KNILL DC, 1991, NATURE, V351, P228, DOI 10.1038/351228a0; KNILL DC, 1990, J OPT SOC AM A, V7, P1113, DOI 10.1364/JOSAA.7.001113; Koechlin E, 1999, BIOL CYBERN, V80, P25, DOI 10.1007/s004220050502; Koenderink JJ, 2001, PERCEPTION, V30, P431, DOI 10.1068/p3030; KONISHI SM, 2003, PATTERN ANAL MACH IN, V1, P37; Lamme VAF, 2000, TRENDS NEUROSCI, V23, P571, DOI 10.1016/S0166-2236(00)01657-X; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; Landy MS, 2001, J OPT SOC AM A, V18, P2307, DOI 10.1364/JOSAA.18.002307; LANDY MS, 1995, VISION RES, V35, P389, DOI 10.1016/0042-6989(94)00176-M; Langer MS, 2001, PERCEPTION, V30, P403, DOI 10.1068/p3178; Lee TS, 2002, NAT NEUROSCI, V5, P589, DOI 10.1038/nn860; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; Legge GE, 2002, VISION RES, V42, P2219, DOI 10.1016/S0042-6989(02)00131-1; Lennie P, 2003, CURR BIOL, V13, P493, DOI 10.1016/S0960-9822(03)00135-0; Leopold DA, 2001, NAT NEUROSCI, V4, P89, DOI 10.1038/82947; Lerner Y, 2001, CEREB CORTEX, V11, P287, DOI 10.1093/cercor/11.4.287; Liu ZL, 1998, VISION RES, V38, P2507, DOI 10.1016/S0042-6989(98)00063-7; Liu ZL, 2003, J OPT SOC AM A, V20, P1331, DOI 10.1364/JOSAA.20.001331; LIU ZL, 1995, VISION RES, V35, P549, DOI 10.1016/0042-6989(94)00150-K; Liu ZL, 1999, VISION RES, V39, P603, DOI 10.1016/S0042-6989(98)00167-9; LORENCEAU J, 1992, VISION RES, V32, P263, DOI 10.1016/0042-6989(92)90137-8; MacKay DM, 1956, AUTOMATA STUDIES, P235; Maloney L., 2002, PERCEPTION PHYS WORL, P145; Mamassian P, 1998, VISION RES, V38, P2817, DOI 10.1016/S0042-6989(97)00438-0; Mamassian P, 2001, COGNITION, V81, pB1, DOI 10.1016/S0010-0277(01)00116-0; Mamassian P, 2001, VISION RES, V41, P2653, DOI 10.1016/S0042-6989(01)00147-X; Mamassian P, 1998, TRENDS COGN SCI, V2, P288, DOI 10.1016/S1364-6613(98)01204-2; Marschner SR, 2000, APPL OPTICS, V39, P2592, DOI 10.1364/AO.39.002592; McDermott J, 2001, PERCEPTION, V30, P905, DOI 10.1068/p3219; MUMFORD D, 1992, BIOL CYBERN, V66, P241, DOI 10.1007/BF00198477; Murray SO, 2002, P NATL ACAD SCI USA, V99, P15164, DOI 10.1073/pnas.192579399; NAKAYAMA K, 1992, SCIENCE, V257, P1357, DOI 10.1126/science.1529336; Oliva A, 2000, COGNITIVE PSYCHOL, V41, P176, DOI 10.1006/cogp.1999.0728; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Olshausen BA, 2000, AM SCI, V88, P238, DOI 10.1511/2000.23.770; Oram MW, 1998, TRENDS NEUROSCI, V21, P259, DOI 10.1016/S0166-2236(97)01216-2; PARISH DH, 1991, VISION RES, V31, P1399, DOI 10.1016/0042-6989(91)90060-I; Parraga CA, 2000, CURR BIOL, V10, P35, DOI 10.1016/S0960-9822(99)00262-6; Pearl J., 1988, PROBABILISTIC REASON; PELLI DG, 2003, NATURE, V243, P752; Pizlo Z, 2001, VISION RES, V41, P3145, DOI 10.1016/S0042-6989(01)00173-0; PIZLO Z, 1994, VISION RES, V34, P1637, DOI 10.1016/0042-6989(94)90123-6; Platt ML, 1999, NATURE, V400, P233, DOI 10.1038/22268; POGGIO T, 1990, NATURE, V343, P263, DOI 10.1038/343263a0; PORTILLA J, 2000, INT J COMPUT VISION, V40, P9; Pouget A, 2000, NAT REV NEUROSCI, V1, P125, DOI 10.1038/35039062; RAMACHANDRAN VS, 1985, PERCEPTION, V14, P97; Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580; Rao R.P.N., 2002, PROBABILISTIC MODELS; Read JCA, 2002, BIOL CYBERN, V86, P117, DOI 10.1007/s004220100280; Riesenhuber M, 2002, CURR OPIN NEUROBIOL, V12, P162, DOI 10.1016/S0959-4388(02)00304-5; ROCK I, 1983, LOGIC PERCPETION; Sanger TD, 1996, J NEUROPHYSIOL, V76, P2790; Saunders JA, 2001, VISION RES, V41, P3163, DOI 10.1016/S0042-6989(01)00187-0; Scholkopf B., 2002, LEARNING KERNELS SUP; Schrater PR, 2000, NAT NEUROSCI, V3, P64, DOI 10.1038/71134; Schrater PR, 2000, INT J COMPUT VISION, V40, P73; Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193; SINHA P, 1993, P INT C COMP VIS BER; Sun J, 1998, NAT NEUROSCI, V1, P183, DOI 10.1038/630; TARR MJ, 1995, J EXP PSYCHOL HUMAN, V21, P1494, DOI 10.1037/0096-1523.21.6.1494; Tenebaum JB, 2001, BEHAV BRAIN SCI, V24, P629; Tenenbaum JB, 2000, ADV NEUR IN, V12, P59; TENENBAUM JB, 2000, P ANN C COGN SCI SOC; TJAN BS, 1995, VISION RES, V35, P3053, DOI 10.1016/0042-6989(95)00070-G; Troje NF, 1999, PERCEPTION, V28, P483, DOI 10.1068/p2901; TU Z, 2003, P INT C COMP VIS CAN; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; Ullman S., 1996, HIGH LEVEL VISION OB; VanRullen R, 2001, PERCEPTION, V30, P655, DOI 10.1068/p3029; Vapnik V., 1998, STAT LEARNING THEORY; Vetter T, 1997, J OPT SOC AM A, V14, P2152, DOI 10.1364/JOSAA.14.002152; Viola P., 2001, P IEEE WORKSH STAT C; WEBER M, 2000, P EUR C COMP VIS 6 D; Weiss Y, 2002, NAT NEUROSCI, V5, P598, DOI 10.1038/nn858; YONAS A, 2003, ENCY COGNITIVE SCI, P96; Yu AJ, 2002, NEURAL NETWORKS, V15, P719, DOI 10.1016/S0893-6080(02)00058-8; Yuille A, 2003, J OPT SOC AM A, V20, P24, DOI 10.1364/JOSAA.20.000024; YUILLE AL, 2001, P INT C COMP VIS VAN; YUILLE AL, 1988, NATURE, V333, P71, DOI 10.1038/333071a0; Zhu SC, 1999, IEEE T PATTERN ANAL, V21, P1170; Zhu SC, 1997, NEURAL COMPUT, V9, P1627, DOI 10.1162/neco.1997.9.8.1627; Zhu SC, 1997, IEEE T PATTERN ANAL, V19, P1236; Zipser K, 1996, J NEUROSCI, V16, P7376	144	317	320	ANNUAL REVIEWS	PALO ALTO	4139 EL CAMINO WAY, PO BOX 10139, PALO ALTO, CA 94303-0139 USA	0066-4308			ANNU REV PSYCHOL	Annu. Rev. Psychol.		2004	55						271	304		10.1146/annurev.psych.55.090902.142005		38	Psychology; Psychology, Multidisciplinary	Psychology	780BK	WOS:000189351100010	14744217	
B	Rodionov, AS; L'vov, AA			IEEE	Rodionov, AS; L'vov, AA			Comparison of linear, nonlinear and feature selection methods for EEG signal classification	APEDE 2004: INTERNATIONAL CONFERENCE ON ACTUAL PROBLEMS OF ELECTRON DEVICES ENGINEERING, CONFERENCE PROCEEDINGS			English	Proceedings Paper	International Conference on Actual Problems of Electron Devices Engineering (APEDE 2004)	SEP 15-16, 2004	Saratov, RUSSIA	IEEE, EDS					Saratov State Tech Univ, Saratov, Russia	Rodionov, AS (reprint author), Saratov State Tech Univ, Saratov, Russia.						ANDERSON C, 2003, P 1 IEEE WORKSH COMP, P37; BLANKERTZ B, 2002, ADV NEURAL INFORMATI, V14, P234; CAWLEY GC, 2000, MATLAB SUPPORT VECTO, P333; HASTIE T, 2001, ELEMENTS STAT LEARNI, P75	4	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-8442-3				2004							436	439				4	Engineering, Electrical & Electronic; Physics, Condensed Matter	Engineering; Physics	BBQ65	WOS:000227171200081		
S	Kapetanovic, IM; Umar, A; Khan, J		Umar, A; Kapetanovic, I; Khan, J		Kapetanovic, IM; Umar, A; Khan, J			Proceedings: The applications of bioinformatics in cancer detection workshop	APPLICATIONS OF BIOINFORMATICS IN CANCER DETECTION	ANNALS OF THE NEW YORK ACADEMY OF SCIENCES		English	Article; Proceedings Paper	Applications of Bioinformatics in Cancer Detection Workshop	AUG 06-07, 2002	Bethesda, MD	NCI, Div Canc Prevent		bioinformatics; data mining; cancer; early detection; risk assessment; genomics; proteomics; drug discovery	ARTIFICIAL NEURAL NETWORKS; PROSTATE-CANCER; MICROARRAY DATA; COMPUTATION; PREDICTION; PATTERNS	The Division of Cancer Prevention of the National Cancer Institute sponsored and organized the Applications of Bioinformatics in Cancer Detection Workshop on August 6-7, 2002. The goal of the workshop was to evaluate the state of the science of bioinformatics and determine how it may be used to assist early cancer detection, risk identification, risk assessment, and risk reduction. This paper summarizes the proceedings of this conference and points out future directions for research.	NCI, Div Canc Prevent, Chemoprevent Agent Dev Res Grp, Bethesda, MD 20892 USA; NCI, Div Canc Prevent, Gastrointestinal & Other Canc Res Grp, Bethesda, MD 20892 USA; NCI, Oncogenom Sect, Pediat Oncol Branch, Bethesda, MD 20892 USA	Kapetanovic, IM (reprint author), NCI, Div Canc Prevent, Chemoprevent Agent Dev Res Grp, Bethesda, MD 20892 USA.	kapetani@mail.nih.gov					Bafna V, 2001, Bioinformatics, V17 Suppl 1, pS13; Boland MV, 2001, BIOINFORMATICS, V17, P1213, DOI 10.1093/bioinformatics/17.12.1213; Brazma A, 2001, NAT GENET, V29, P365, DOI 10.1038/ng1201-365; Dayhoff JE, 2001, CANCER, V91, P1615, DOI 10.1002/1097-0142(20010415)91:8+<1615::AID-CNCR1175>3.0.CO;2-L; Dudoit S., 2003, ANAL GENE EXPRESSION; Hastie T., 2001, ELEMENTS STAT LEARNI; Kecman V., 2001, LEARNING SOFT COMPUT; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Li C, 2001, P NATL ACAD SCI USA, V98, P31, DOI 10.1073/pnas.011404098; Moloshok TD, 2002, BIOINFORMATICS, V18, P566, DOI 10.1093/bioinformatics/18.4.566; Pena-Reyes CA, 2000, ARTIF INTELL MED, V19, P1, DOI 10.1016/S0933-3657(99)00047-0; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Rhodes DR, 2002, CANCER RES, V62, P4427; Rubin MA, 2002, JAMA-J AM MED ASSOC, V287, P1662, DOI 10.1001/jama.287.13.1662; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Weeraratna AT, 2002, CANCER CELL, V1, P279, DOI 10.1016/S1535-6108(02)00045-4	16	1	2	NEW YORK ACAD SCIENCES	NEW YORK	2 EAST 63RD ST, NEW YORK, NY 10021 USA	0077-8923		1-57331-510-9	ANN NY ACAD SCI	Ann.NY Acad.Sci.		2004	1020						1	9		10.1196/annals.1310.002		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Oncology; Computer Science, Interdisciplinary Applications; Multidisciplinary Sciences	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Oncology; Computer Science; Science & Technology - Other Topics	BAH03	WOS:000222177400001	15208178	
S	Kapetanovic, IM; Rosenfeld, S; Izmirlian, G		Umar, A; Kapetanovic, I; Khan, J		Kapetanovic, IM; Rosenfeld, S; Izmirlian, G			Overview of commonly used bioinformatics methods and their applications	APPLICATIONS OF BIOINFORMATICS IN CANCER DETECTION	Annals of the New York Academy of Sciences		English	Article; Proceedings Paper	Applications of Bioinformatics in Cancer Detection Workshop	AUG 06-07, 2002	Bethesda, MD	NCI, Div Canc Prevent		bioinformatics; data mining; cancer; early detection; risk assessment; hierarchical clustering; neural networks; support vector machines; fuzzy logic; genomics; proteomics; drug discovery	ARTIFICIAL NEURAL NETWORKS; BREAST-CANCER DIAGNOSIS; GENE-EXPRESSION DATA; FUZZY-LOGIC; PROSTATE-CANCER; MEDICAL APPLICATIONS; PATTERNS; CLASSIFICATION; PROFILES; SERUM	Bioinformatics, in its broad sense, involves application of computer processes to solve biological problems. A wide range of computational tools are needed to effectively and efficiently process large amounts of data being generated as a result of recent technological innovations in biology and medicine. A number of computational tools have been developed or adapted to deal with the experimental riches of complex and multivariate data and transition from data collection to information or knowledge. These include a wide variety of clustering and classification algorithms, including self-organized maps (SOM), artificial neural networks (ANN), support vector machines (SVM), fuzzy logic, and even hyphenated techniques as neuro-jazzy networks. These bioinformatics tools are being evaluated and applied in various medical areas including early detection, risk assessment, classification, and prognosis of cancer. The goal of these efforts is to develop and identify bioinformatics methods with optimal sensitivity, specificity, and predictive capabilities.	NCI, Div Canc Prevent, Chemoprevent Agent Dev Res Grp, Bethesda, MD 20892 USA; NCI, Biometry Res Grp, Div Canc Prevent, Bethesda, MD 20892 USA	Kapetanovic, IM (reprint author), NCI, Div Canc Prevent, Chemoprevent Agent Dev Res Grp, Bethesda, MD 20892 USA.	kapetani@mail.nih.gov					Abbod MF, 2001, FUZZY SET SYST, V120, P331, DOI 10.1016/S0165-0114(99)00148-7; Adam BL, 2002, CANCER RES, V62, P3609; Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Ball G, 2002, BIOINFORMATICS, V18, P395, DOI 10.1093/bioinformatics/18.3.395; Boland MV, 2001, BIOINFORMATICS, V17, P1213, DOI 10.1093/bioinformatics/17.12.1213; Breiman L., 2002, MANUAL SETTING UP US; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Dayhoff JE, 2001, CANCER, V91, P1615, DOI 10.1002/1097-0142(20010415)91:8+<1615::AID-CNCR1175>3.0.CO;2-L; DEAN PM, 2002, BIOTECHNIQUES S, V32, pS28; DeLeo JM, 2001, IEEE IJCNN, P3009, DOI 10.1109/IJCNN.2001.938857; Errejon A, 2001, MOL UROL, V5, P153, DOI 10.1089/10915360152745821; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Gruvberger S, 2001, CANCER RES, V61, P5979; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie Trevor, 2000, GENOME BIOL, V1; Jagota A., 2001, MICROARRAY DATA ANAL; Keller T, 1998, J CANCER RES CLIN, V124, P565, DOI 10.1007/s004320050216; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Kovalerchuk B, 1997, ARTIF INTELL MED, V11, P75, DOI 10.1016/S0933-3657(97)00021-3; Kuncheva LI, 1999, ARTIF INTELL MED, V16, P121, DOI 10.1016/S0933-3657(98)00068-2; Lenz GR, 2000, DRUG DISCOV TODAY, V5, P145, DOI 10.1016/S1359-6446(00)01468-9; LIAW A, 2003, RANDOM FOREST PACKAG; Mahfouf M, 2001, ARTIF INTELL MED, V21, P27, DOI 10.1016/S0933-3657(00)00072-5; McLeod HL, 2001, ANNU REV PHARMACOL, V41, P101, DOI 10.1146/annurev.pharmtox.41.1.101; Pegg SCH, 2001, J COMPUT AID MOL DES, V15, P911, DOI 10.1023/A:1014389729000; Pena-Reyes CA, 1999, ARTIF INTELL MED, V17, P131, DOI 10.1016/S0933-3657(99)00019-6; Pena-Reyes CA, 2000, ARTIF INTELL MED, V19, P1, DOI 10.1016/S0933-3657(99)00047-0; Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Pratt JM, 2002, MOL CELL PROTEOMICS, V1, P579, DOI 10.1074/mcp.M200046-MCP200; Qu YS, 2002, CLIN CHEM, V48, P1835; Quackenbush J, 2001, NAT REV GENET, V2, P418, DOI 10.1038/35076576; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Ringner M, 2002, PHARMACOGENOMICS, V3, P403, DOI 10.1517/14622416.3.3.403; Selaru FM, 2002, GASTROENTEROLOGY, V122, P606, DOI 10.1053/gast.2002.31904; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Steimann F, 1997, ARTIF INTELL MED, V11, P1; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Terfloth L, 2001, DRUG DISCOV TODAY, V6, pS102; TIBSHIRANI R, 1999, CLUSTERING METHODS A; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Vapnik V., 1998, STAT LEARNING THEORY; Verma B, 2001, IEEE T INF TECHNOL B, V5, P46, DOI 10.1109/4233.908389; Vitez TS, 1996, J CARDIOTHOR VASC AN, V10, P800, DOI 10.1016/S1053-0770(96)80210-2; Woolf PJ, 2000, PHYSIOL GENOMICS, V3, P9; XIAO Z, 2003, UNPUB; Xu Y, 2002, CANCER RES, V62, P3493; Yeang C H, 2001, Bioinformatics, V17 Suppl 1, pS316; Zheng X. F. Steven, 2002, Current Issues in Molecular Biology, V4, P33	52	32	35	NEW YORK ACAD SCIENCES	NEW YORK	2 EAST 63RD ST, NEW YORK, NY 10021 USA	0077-8923		1-57331-511-7	ANN NY ACAD SCI	Ann.NY Acad.Sci.		2004	1020						10	21		10.1196/annals.1310.003		12	Biochemical Research Methods; Biotechnology & Applied Microbiology; Oncology; Computer Science, Interdisciplinary Applications; Multidisciplinary Sciences	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Oncology; Computer Science; Science & Technology - Other Topics	BAH03	WOS:000222177400002	15208179	
S	Izmirlian, G		Umar, A; Kapetanovic, I; Khan, J		Izmirlian, G			Application of the random forest classification algorithm to a SELDI-TOF proteomics study in the setting of a cancer prevention trial	APPLICATIONS OF BIOINFORMATICS IN CANCER DETECTION	ANNALS OF THE NEW YORK ACADEMY OF SCIENCES		English	Article; Proceedings Paper	Applications of Bioinformatics in Cancer Detection Workshop	AUG 06-07, 2002	Bethesda, MD	NCI, Div Canc Prevent		random forest (RF) algorithm; SELDI-TOF; cancer; classifier; classification tree (CT); detection; prevention; MDM; statistic	OVARIAN-CANCER; PATTERNS; SERUM	A thorough discussion of the random forest (RF) algorithm as it relates to a SELDI-TOF proteomics study is presented, with special emphasis on its application for cancer prevention: specifically, what makes it an efficient, yet reliable classifier, and what makes it optimal among the many available approaches. The main body of the paper treats the particulars of how to successfully apply the RF algorithm in a proteomics profiling study to construct a classifier and discover peak intensities most likely responsible for the separation between the classes.	NCI, DHHS, Div Canc Prevent, Biometry Res Grp, Rockville, MD 20852 USA	Izmirlian, G (reprint author), NCI, DHHS, Div Canc Prevent, Biometry Res Grp, Execut Plaza N,Suite 3131,6130 Execut Blvd,MSC 73, Rockville, MD 20852 USA.	izmirlian@nih.gov					BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BREIMAN L, 2003, RANDOM FOREST PACKAG; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Diamandis EP, 2002, LANCET, V360, P170, DOI 10.1016/S0140-6736(02)09390-X; Durrett R., 1991, PROBABILITY THEORY E; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Efron B., 1995, CROSS VALIDATION BOO; Elwood M, 2002, LANCET, V360, P170, DOI 10.1016/S0140-6736(02)09389-3; Hastie T., 2001, ELEMENTS STAT LEARNI; LIAW A, 2003, RANDOM FOREST PACKAG; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Pollack A., 2004, NY TIMES, P1; Rockhill B, 2002, LANCET, V360, P169, DOI 10.1016/S0140-6736(02)09387-X; SVETNIK V, 2003, COMMUNICATION; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210; Yanagisawa K, 2003, LANCET, V362, P433, DOI 10.1016/S0140-6736(03)14068-8; Yip TT, 2002, TECHNOL CANCER RES T, V1, P273; YOUDEN WJ, 1950, CANCER, V3, P32, DOI 10.1002/1097-0142(1950)3:1<32::AID-CNCR2820030106>3.0.CO;2-3	21	45	47	NEW YORK ACAD SCIENCES	NEW YORK	2 EAST 63RD ST, NEW YORK, NY 10021 USA	0077-8923		1-57331-510-9	ANN NY ACAD SCI	Ann.NY Acad.Sci.		2004	1020						154	174		10.1196/annals.1310.015		21	Biochemical Research Methods; Biotechnology & Applied Microbiology; Oncology; Computer Science, Interdisciplinary Applications; Multidisciplinary Sciences	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Oncology; Computer Science; Science & Technology - Other Topics	BAH03	WOS:000222177400014	15208191	
S	Karlhohn, J		Sadjadi, FA		Karlhohn, J			Design and evaluation of a hierarchy of boosted classifiers for detection of ground targets in aerial surveillance imagery	AUTOMATIC TARGET RECOGNITION XIV	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	14th Conference on Automatic Target Recognition	APR 13-15, 2004	Orlando, FL	SPIE		detection; ground targets; aerial surveillance		One way to increase the robustness and efficiency of unmanned surveillance platforms is to introduce an autonomous data acquisition capability. In order to mimic a sensor operator's search pattern, combining wide area search with detailed study of detected regions of interest, the system must be able to produce target indications in real time. Rapid detection algorithms are also useful for cueing image analysts that process large amounts of aerial reconnaissance imagery. Recently, the use of a sequence of increasingly complex classifiers has by several authors been suggested as a means to achieve high processing rates at low false alarm and miss rates. The basic principle is that much of the background can be rejected by a simple classifier before more complex classifiers are applied to analyse more difficult remaining image regions. Even higher performance can be achieved if each detector stage is implemented as a set of expert classifiers, each specialised to a subset of the target training set. In order to cope with the increasingly difficult classification problem faced at successive stages, the partitioning of the target training set must be made increasingly fine-grained, resulting in a coarse-to-fine hierarchy of detectors. Most of the literature on this type of detectors is concerned with face detection. The present paper describes a system designed for detection of military ground vehicles in thermal imagery from airborne platforms. The classifier components used are trained using a variant of the LogitBoost algorithm. The results obtained are encouraging, and suggest that it is possible to achieve very low false alarm and miss rates for this very demanding application.	Swedish Def Res Agcy, Dept IR Syst, SE-58111 Linkoping, Sweden	Karlhohn, J (reprint author), Swedish Def Res Agcy, Dept IR Syst, POB 1165, SE-58111 Linkoping, Sweden.						Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Boser B., 1992, 5 ANN ACM WORKSH COL, P144; Cooper ML, 2000, IEEE T INFORM THEORY, V46, P1896; Fleuret F, 2001, INT J COMPUT VISION, V41, P85, DOI 10.1023/A:1011113216584; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Hastie T., 2001, ELEMENTS STAT LEARNI; Jacobs PAM, 1996, THERMAL INFRARED CHA; Johnson KR, 1998, P 9 ANN GROUND TARG; Jones M., 2003, TR200396 MITS EL RES; Kay S., 1993, FUNDAMENTALS STAT SI, V1; LI SZ, 2002, P 7 EUR C COMP VIS C; Lienhart R., 2002, P IEEE INT C IM PROC, P900, DOI DOI 10.1109/ICIP.2002.1038171; OMOHUNDRO S, 1987, UIUCDCSR871331; Poor H.V., 1994, INTRO SIGNAL DETECTI; Romdhani S., 2001, Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001, DOI 10.1109/ICCV.2001.937694; Schafft HA, 1997, MICROELECTRON RELIAB, V37, P3, DOI 10.1016/0026-2714(96)00235-1; Scholkopf B., 2002, LEARNING KERNELS SUP; Scholkopf B, 1999, IEEE T NEURAL NETWOR, V10, P1000, DOI 10.1109/72.788641; Vapnik V., 1998, STAT LEARNING THEORY; VIOLA P, 2001, 200101 CRL COMP COMP	21	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		0-8194-5349-8	P SOC PHOTO-OPT INS			2004	5426						358	369		10.1117/12.542281		12	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BBB08	WOS:000224466600035		
S	Rowicka, M; Kudlicki, A		Fischer, R; Preuss, R; VonToussaint, U		Rowicka, M; Kudlicki, A			Bayesian modeling of protein interaction networks	BAYESIAN INFERENCE AND MAXIMUM ENTROPY METHODS IN SCIENCE AND ENGINEERING	AIP CONFERENCE PROCEEDINGS		English	Proceedings Paper	24th International Workshop on Bayesian Inference and Maximum Entropy Methods in Science and Engineering	JUL 25-30, 2004	Garching, GERMANY	Boise State Univ, Edwin T Jaynes Int Ctr Bayesian Methods & Maximum Entropy, Ctr Interdisciplinary Plasma Sci	Max Planck Inst Plasmaphys			Han et al.[5] have analyzed a sample of protein interaction data, considering the correlations of expression patterns in proteins with at least five known interactions ("hubs"). We present a Bayesian re-analysis of their data, and find that the model selected for its highest posterior probability yields a substantially different classification of hubs than the published one.	Univ Texas, SW Med Ctr, Dept Biochem, Dallas, TX 75390 USA	Rowicka, M (reprint author), Univ Texas, SW Med Ctr, Dept Biochem, 5323 Harry Hines Blvd, Dallas, TX 75390 USA.		Kudlicki, Andrzej/C-7612-2012; Rowicka, Maga/E-2496-2012				ADAMIC LA, 2001, PHYS REV E, P64; Aiello W., 2000, Proceedings of the Thirty Second Annual ACM Symposium on Theory of Computing, DOI 10.1145/335305.335326; Baldi P., 2002, DNA MICROARRAYS GENE; Branden C., 1999, INTRO PROTEIN STRUCT; Han JDJ, 2004, NATURE, V430, P88, DOI 10.1038/nature02555; Hastie T., 2001, ELEMENTS STAT LEARNI; Kitano H, 2002, SCIENCE, V295, P1662, DOI 10.1126/science.1069492; Sivia D S, 1996, DATA ANAL BAYESIAN T; SIVIA DS, LUMINESCENCE DATING	9	0	0	AMER INST PHYSICS	MELVILLE	2 HUNTINGTON QUADRANGLE, STE 1NO1, MELVILLE, NY 11747-4501 USA	0094-243X		0-7354-0217-5	AIP CONF PROC			2004	735						283	288				6	Statistics & Probability	Mathematics	BBJ28	WOS:000225765400033		
J	Kell, DB; Oliver, SG				Kell, DB; Oliver, SG			Here is the evidence, now what is the hypothesis? The complementary roles of inductive and hypothesis-driven science in the post-genomic era	BIOESSAYS			English	Article							SYSTEMS BIOLOGY; FUNCTIONAL GENOMICS; MOLECULAR-BIOLOGY; DNA-SEQUENCE; DISCOVERY; OPTIMIZATION; CHROMOSOME; LANDSCAPE; KNOWLEDGE; PROGRAMS	It is considered in some quarters that hypothesis-driven methods are the only valuable, reliable or significant means of scientific advance. Data-driven or 'inductive' advances in scientific knowledge are then seen as marginal, irrelevant, insecure or wrong-headed, while the development of technology-which is not of itself 'hypothesis-led' (beyond the recognition that such tools might be of value)-must be seen as equally irrelevant to the hypothetico-deductive scientific agenda. We argue here that data- and technology-driven programmes are not alternatives to hypothesis-led studies in scientific knowledge discovery but are complementary and iterative partners with them. Many fields are data-rich but hypothesis-poor. Here, computational methods of data analysis, which may be automated, provide the means of generating novel hypotheses, especially in the post-genomic era. (C) 2003 Wiley Periodicals, Inc.	Univ Manchester, Dept Chem, Manchester M60 1QD, Lancs, England; Univ Manchester, Sch Biol Sci, Manchester M13 9PL, Lancs, England	Kell, DB (reprint author), Faraday Bldg,Sackville St,POB 88, Manchester M60 1QD, Lancs, England.	dbk@umist.ac.uk	Kell, Douglas/E-8318-2011	Kell, Douglas/0000-0001-5838-7963			Adamo Jean-Marc, 2001, DATA MINING ASS RULE; Allen JF, 2001, EMBO REP, V2, P542, DOI 10.1093/embo-reports/kve139; Allen JF, 2001, BIOESSAYS, V23, P104, DOI 10.1002/1521-1878(200101)23:1<104::AID-BIES1013>3.0.CO;2-2; Allen JF, 2001, BIOESSAYS, V23, P861, DOI 10.1002/bies.1125; Back T, 1997, HDB EVOLUTIONARY COM; Bentley PJ, 1999, EVOLUTIONARY DESIGN; Brent R, 2000, CELL, V100, P169, DOI 10.1016/S0092-8674(00)81693-1; Brent R, 1999, CURR BIOL, V9, pR338, DOI 10.1016/S0960-9822(99)80208-5; BRYANT J, 2001, HEALTH TECHNOL ASSES, V5, P1; BUCHANAN BG, 1978, ARTIF INTELL, V11, P5, DOI 10.1016/0004-3702(78)90010-3; BUCHANAN BG, 1988, CHEMOMETR INTELL LAB, V5, P33, DOI 10.1016/0169-7439(88)80123-0; Cohn DA, 1996, J ARTIF INTELL RES, V4, P129; Corne D, 2003, LECT NOTES COMPUT SC, V2611, P187; Corne D., 1999, NEW IDEAS OPTIMIZATI; Csete ME, 2002, SCIENCE, V295, P1664, DOI 10.1126/science.1069981; Daniel C, 2003, SCIENCE, V299, P536, DOI 10.1126/science.1078517; Davey HM, 1996, MICROBIOL REV, V60, P641; Dreyfus H. L., 1992, WHAT COMPUTERS STILL; Duda R.O., 2001, PATTERN CLASSIFICATI; Evans WE, 2001, ANNU REV GENOM HUM G, V2, P9, DOI 10.1146/annurev.genom.2.1.9; Fayyad U.M., 1996, ADV KNOWLEDGE DISCOV; Feigenbaum EA, 1993, ARTIF INTELL, V59, P223; FENN JB, 2002, NOBEL LECT ELECTROSP; FLACH PA, 2000, INDUCTION ABDUCTION; Forst Christian V, 2002, Pharmacogenomics, V3, P739, DOI 10.1517/14622416.3.6.739; Freitas AA, 2002, DATA MINING KNOWLEDG; Gilbert G. N., 1984, OPENING PANDORAS BOX; Gillies D. A., 1996, ARTIFICIAL INTELLIGE; Gillies DA, 2001, BIOESSAYS, V23, P859, DOI 10.1002/bies.1123; Goffeau A, 1996, SCIENCE, V274, P546, DOI 10.1126/science.274.5287.546; Goldberg D., 2002, DESIGN INNOVATION LE; Hand David J, 2001, PRINCIPLES DATA MINI; HASENJAGER M, 1998, NEURAL P LETT, V7, P110; Hastie T., 2001, ELEMENTS STAT LEARNI; HEINRICH R, 1974, EUR J BIOCHEM, V42, P89, DOI 10.1111/j.1432-1033.1974.tb03318.x; Hughes TR, 2000, CELL, V102, P109, DOI 10.1016/S0092-8674(00)00015-5; Iberall A. S., 1972, GEN SCI VIABLE SYSTE; Ideker T, 2001, ANNU REV GENOM HUM G, V2, P343, DOI 10.1146/annurev.genom.2.1.343; JUDSON RS, 1992, PHYS REV LETT, V68, P1500, DOI 10.1103/PhysRevLett.68.1500; Kacser H, 1973, Symp Soc Exp Biol, V27, P65; KARAS M, 1989, INT J MASS SPECTROM, V92, P231, DOI 10.1016/0168-1176(89)83030-7; Kauffman S., 2000, INVESTIGATIONS; Kauffman S, 2000, J ECON BEHAV ORGAN, V43, P141, DOI 10.1016/S0167-2681(00)00114-1; Kell DB, 2000, NATO ASI 3 HIGH TECH, V74, P3; Kell DB, 2000, TRENDS BIOTECHNOL, V18, P93, DOI 10.1016/S0167-7799(99)01407-9; KELL DB, 1991, TIMES HIGHER ED 0809, P15; Kelley LA, 2001, BIOESSAYS, V23, P860, DOI 10.1002/bies.1124; KING RD, 2003, IN PRESS NATURE; Kitano H, 2002, NATURE, V420, P206, DOI 10.1038/nature01254; Kitano H, 2002, SCIENCE, V295, P1662, DOI 10.1126/science.1069492; Koza J., 1999, GENETIC PROGRAMMING, VIII; Koza JR, 2003, SCI AM, V288, P52; Koza JR, 2003, GENETIC PROGRAMMING; Koza J. R., 2000, Genetic Programming and Evolvable Machines, V1, DOI 10.1023/A:1010076532029; Langley P., 1987, SCI DISCOVERY COMPUT; Langley P, 2000, INT J HUM-COMPUT ST, V53, P393, DOI 10.1006/ijhc.2000.0396; Lazebnik Y, 2002, CANCER CELL, V2, P179, DOI 10.1016/S1535-6108(02)00133-2; Lin FR, 1997, ANN OPER RES, V75, P105, DOI 10.1023/A:1018999110972; LINDSAY RK, 1993, ARTIF INTELL, V61, P209, DOI 10.1016/0004-3702(93)90068-M; Maddox Brenda, 2002, R FRANKLIN DARK LADY; MADDOX J, 1994, NATURE, V368, P95; MADDOX J, 1992, NATURE, V355, P201; Mayr E, 1982, GROWTH BIOL THOUGHT; Mayr E., 2001, WHAT EVOLUTION IS; Medawar P, 1982, PLUTOS REPUBLIC; Mendes P, 1998, BIOINFORMATICS, V14, P869, DOI 10.1093/bioinformatics/14.10.869; Michalewicz Z., 1994, GENETIC ALGORITHMS P; Michalewicz Z, 2000, SOLVE IT MODERN HEUR; Michalski R. S., 1998, MACHINE LEARNING DAT; MULLIS KB, 1987, METHOD ENZYMOL, V155, P335; Munakata T, 1999, COMMUN ACM, V42, P26, DOI 10.1145/319382.319387; NEWLON CS, 1991, GENETICS, V129, P343; Oldroyd David R, 1986, ARCH KNOWLEDGE INTRO; Oliver SG, 1996, NATURE, V379, P597, DOI 10.1038/379597a0; OLIVER SG, 1992, NATURE, V357, P38, DOI 10.1038/357038a0; Pearl J., 2000, CAUSALITY MODELS REA; Perutz M, 1998, I WISH ID MADE YOU A; PLATETSKYSHAPIR.G, 1991, KNOWLEDGE DISCOVERY; Popper K, 1992, CONJECTURES REFUTATI; Reeves C.R., 1995, MODERN HEURISTIC TEC; Reiser P.G.K., 2001, ELECT T ARTIF INTELL, V5-B2, P223; ROBERTSD RM, 1989, SERENDIPITY ACCIDENT; Rothman K., 1998, MODERN EPIDEMIOLOGY; Rothman KJ, 2002, EPIDEMIOLOGY INTRO; SANGER F, 1977, P NATL ACAD SCI USA, V74, P5463, DOI 10.1073/pnas.74.12.5463; Smalheiser NR, 2002, EMBO REP, V3, P702, DOI 10.1093/embo-reports/kvf164; STERNBERG MJE, 1994, PHILOS T ROY SOC B, V344, P365, DOI 10.1098/rstb.1994.0075; SULSTON J, 2002, COMMON THREAD STORY, P44; Thompson A., 1998, HARDWARE EVOLUTION A; VAIDYANATHAN S, 2003, IN RPESS ANAL CHEM; Valdes-Perez RE, 1999, COMMUN ACM, V42, P37, DOI 10.1145/319382.319389; VISCHER E, 1949, J BIOL CHEM, V177, P429; von Bertalanffy L, 1969, GEN SYSTEM THEORY; WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0; Wiley HS, 2003, TRENDS CELL BIOL, V13, P43; Wilkins A S, 2001, Bioessays, V23, P1, DOI 10.1002/1521-1878(200101)23:1<1::AID-BIES1000>3.0.CO;2-O; Williams R. J., 1956, BIOCH INDIVIDUALITY; ZAMENHOF S, 1952, BIOCHIM BIOPHYS ACTA, V9, P402, DOI 10.1016/0006-3002(52)90184-4; Zytkow J. M., 1990, AAAI-90 Proceedings. Eighth National Conference on Artificial Intelligence	99	189	193	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0265-9247			BIOESSAYS	Bioessays	JAN	2004	26	1					99	105		10.1002/bies.10385		7	Biochemistry & Molecular Biology; Biology	Biochemistry & Molecular Biology; Life Sciences & Biomedicine - Other Topics	760YF	WOS:000187862300013	14696046	
S	Reinke, D; Dowling, R; Hranac, R; Alexiadis, V			TBR	Reinke, D; Dowling, R; Hranac, R; Alexiadis, V			Development of a high-level algorithm verification and validation procedure for traffic microsimulation models	CALIBRATION AND VALIDATION OF SIMULATION MODELS 2004	TRANSPORTATION RESEARCH RECORD		English	Article; Proceedings Paper	83rd Annual Meeting of the Transportation-Research-Board	JAN 11-15, 2004	Washington, DC	Transportat Res Board, US Dept Transportat, US Bur Transportat Stat, US Fed Aviat Adm, US Fed Highway Adm, US Fed Motor Carrier Safety Adm, US Fed Railroad Adm, US FedTransit Adm, US Natl Highway Traff Safety Adm, US Res& Special Programs Adm, NASA, USA Corps Engineers, US Coast Guard, US DOE, US EPA				The successful acceptance of traffic microsimulation software depends crucially on the verification and validation (V&V) procedures for testing the core behavioral algorithms. These must be sufficient to convince researchers, software developers, and practitioners that the algorithms are accurate and robust. V&V procedures must also be well documented to ensure public acceptance. A suggested V&V procedure is presented. The central theme is that verification and validation are integral parts of the entire algorithm development process. A three-stage algorithm development and V&V procedure for traffic microsimulation algorithms is recommended. Algorithm development includes identifying key variables and setting model parameters. Next, the software implementation of the algorithm is tested during the algorithm-level testing stage with a combination of hypothetical and simple real-world data. Finally, system-level testing of the algorithm software is done within a complete microsimulation modeling system. In the last stage, the system with the new algorithm is tested against complex real-world data sets.	Dowling Associates Inc, Oakland, CA 94612 USA; Cambridge Systemat Inc, Oakland, CA 94607 USA	Reinke, D (reprint author), Dowling Associates Inc, 180 Grand Ave,Suite 250, Oakland, CA 94612 USA.						[Anonymous], 1998, 10121998 IEEE; Beizer B., 1990, SOFTWARE TESTING TEC; Burnstein I., 2003, PRACTICAL SOFTWARE T; Gamma E, 1995, DESIGN PATTERNS ELEM; GELPERIN D, 1988, COMMUN ACM, V31, P687, DOI 10.1145/62959.62965; Graham I., 2001, OBJECT ORIENTED METH; HALL A, 1990, IEEE SOFTWARE, V7, P11, DOI 10.1109/52.57887; Hastie T., 2001, ELEMENTS STAT LEARNI; JIMINEZ T, 2000, SIMULATION MODELLING; KNUTH DE, 1997, ART COMPUTER PROGRAM, V1, P4; O'Regan G., 2002, PRACTICAL APPROACH S; Potter B., 1996, INTRO FORMAL SPECIFI	12	0	0	TRANSPORTATION RESEARCH BOARD NATL RESEARCH COUNCIL	WASHINGTON	500 FIFTH ST, NW, WASHINGTON, DC 20001 USA	0361-1981		0-309-09470-4	TRANSPORT RES REC			2004		1876					151	158				8	Engineering, Civil; Operations Research & Management Science; Transportation Science & Technology	Engineering; Operations Research & Management Science; Transportation	BBR01	WOS:000227334900016		
S	Chan, HP; Sahiner, B; Hadjiiski, L		Lemke, HU; Inamura, K; Doi, K; Vannier, MW; Farman, AG; Reiber, JHC		Chan, HP; Sahiner, B; Hadjiiski, L			Sample size and validation issues on the development of CAD systems	CARS 2004: COMPUTER ASSISTED RADIOLOGY AND SURGERY, PROCEEDINGS	INTERNATIONAL CONGRESS SERIES		English	Proceedings Paper	18th International Congress and Exhibition on Computer Assisted Radiology and Surgery (CARS 2004)	JUN 23-26, 2004	Chicago, IL			computer-aided diagnosis; sample size; classifier design; resampling techniques	COMPUTER-AIDED DIAGNOSIS; CLASSIFIER PERFORMANCE; DESIGN	Classifier design and performance validation are important steps in the development of computer-aided diagnosis (CAD) systems. Within a CAD system, one or more classifiers may be used at various stages to differentiate malignant and benign lesions, or to differentiate true lesions from false positives. A classifier is trained with case samples drawn from the patient population. The performance of the trained classifier on unknown samples depends on the quality (whether the training samples are statistically representative of the patient population) and the quantity (sample size) of the training samples. To evaluate the performance of the classifier (or the CAD system), an independent set of test samples that have not been seen by the classifier (unknown samples) should be used. Because the available samples with ground truth are often limited in medical imaging research, the finite sample size is a limiting factor in the development of CAD systems. In this talk, we will review some of the issues associated with classifier design and validation under the constraint of finite sample size. (C) 2004 Published by Elsevier B.V.	Univ Michigan, Dept Radiol, Ann Arbor, MI 48109 USA	Chan, HP (reprint author), Univ Michigan, Dept Radiol, 1500 E Med Ctr Dr,UHB1F510B, Ann Arbor, MI 48109 USA.						Chan HP, 1999, MED PHYS, V26, P2654, DOI 10.1118/1.598805; CHERNICK MR, 1985, PATTERN RECOGN LETT, V3, P167, DOI 10.1016/0167-8655(85)90049-2; Efron B., 1982, JACKKNIFE BOOTSTRAP; Fukunaga K, 1990, INTRO STAT PATTERN R; FUKUNAGA K, 1989, IEEE T PATTERN ANAL, V11, P873, DOI 10.1109/34.31448; Hastie T., 2001, ELEMENTS STAT LEARNI; Sahiner B, 2000, MED PHYS, V27, P1509, DOI 10.1118/1.599017	7	4	4	ELSEVIER SCIENCE BV	AMSTERDAM	SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0531-5131		0-444-51731-6	INT CONGR SER			2004	1268						872	877		10.1016/j.ics.2004.03.226		6	Computer Science, Interdisciplinary Applications; Radiology, Nuclear Medicine & Medical Imaging; Surgery	Computer Science; Radiology, Nuclear Medicine & Medical Imaging; Surgery	BAV01	WOS:000223659100155		
B	Tran, LV; Lenz, R			IS&T	Tran, LV; Lenz, R			Efficient descriptors of hue distributions from kernel density estimators and Fourier transforms	CGIV 2004: SECOND EUROPEAN CONFERENCE ON COLOR IN GRAPHICS, IMAGING, AND VISION - CONFERENCE PROCEEDINGS			English	Proceedings Paper	2nd European Conference on Color in Graphics, Imaging, and Vision/6th International Symposium on Multispectral Color Science	APR 05-08, 2004	Aachen, GERMANY	Soc Imaging Sci & Technol, Comit Espanol Color, Danish Color Grp, European Federat Sci Image, French Color Imaging Grp, German Color Grp, German Soc Color Sci & Applicat, Hungarian Natl Colour Comm, Swedish Colour Ctr Fdn, Colour Grp Great Britain, Flemish Innovat Ctr Graph Commun, Colour Grp S Africa Opt Soc, Royal Photograph Soc Great Britain				Many color-based image retrieval systems define the similarity (with regard to color) between two images as the similarity between the probability distributions of the color vectors in the images. These probability distributions are almost always estimated by histograms. Histograms have however the disadvantage that they are discontinuous and their form depends on the selection of the histogram bins. Results from probability theory and statistics show that kernel-based estimators are superior to the histogram in many respects. Previous studies in image retrieval have however shown that a naive application of kernel-based estimators provide no improvement in retrieval performance. In this paper we first motivate why a combination of kernel-based estimators and Fourier transform theory provides good estimators of the similarity of hue-distributions. We then show that Fourier coefficients provide efficient descriptors of the probability distributions and that these Fourier coefficients can be directly used to compute the similarity between the hue distributions of images. Next we describe two methods to select the most relevant Fourier coefficients for image retrieval. We will argue that in image retrieval we should not select those Fourier coefficients that are most important for the description of the probability distributions themselves but that we should select those coefficients that are most important in the estimation of the difference between similar distributions. In the experimental part of the paper we describe the performance of these kernel-based methods when they are applied to image retrieval tasks involving the MPEG7 image database. We will show that the retrieval performance of the kernel based method is better than the performance of histogram methods and we will show that the retrieval performance is also relatively insensitive to the choice of the Kernel and the width of the Kernel.	Linkoping Univ, Dept Sci & Technol, SE-60174 Norrkoping, Sweden	Tran, LV (reprint author), Linkoping Univ, Dept Sci & Technol, SE-60174 Norrkoping, Sweden.						GEVERS T, 2001, P INT C COMP VIS; Hastie T., 2001, ELEMENTS STAT LEARNI; *ISO IEC, 1999, MPEG99M5060 ISOIEC; Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413; SCHETTINI R, 2000, P INT C COL GRAPH IM, P244; Scott D. W., 1992, MULTIVARIATE DENSITY; Silverman BW, 1986, DENSITY ESTIMATION S; Trail L.V., 2003, THESIS LINKOPING U; TRAN LV, 2003, P SPIE INT IM 4 C EL; TRAN LV, 2001, IEEE P INT C IM PROC; Wand MP, 1995, KERNEL SMOOTHING	11	0	0	SOC IMAGING SCIENCE & TECHNOLOGY	SPRINGFIELD	7003 KILWORTH LANE, SPRINGFIELD, VA 22151 USA			0-89208-250-X				2004							151	155				5	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Optics; Imaging Science & Photographic Technology	Computer Science; Optics; Imaging Science & Photographic Technology	BBQ24	WOS:000227038900031		
S	Jeske, DR; Liu, RY		Banks, D; House, L; McMorris, FR; Arabie, P; Gaul, W		Jeske, DR; Liu, RY			Mining massive text data and developing tracking statistics	CLASSIFICATION, CLUSTERING, AND DATA MINING APPLICATIONS	STUDIES IN CLASSIFICATION, DATA ANALYSIS, AND KNOWLEDGE ORGANIZATION		English	Proceedings Paper	Meeting of the International-Federation-of-Classifications-Societies (IFCS)	JUL 15-18, 2004	Chicago, IL	Int Federat Classificat Soc	Illinois Inst Technol		DATA DEPTH; SYSTEMS	This paper outlines a systematic data mining procedure for exploring large free-style text datasets to discover useful features and develop tracking statistics, generally referred to as performance measures or risk indicators. The procedure includes text mining, risk analysis, classification for error measurements and nonparametric multivariate analysis. Two aviation safety report repositories PTRS from the FAA and AAS from the NTSB will be used to illustrate applications of our research to aviation risk management and general decision-support systems. Some specific text analysis methodologies and tracking statistics will be discussed. Approaches to incorporating misclassified data or error measurements into tracking statistics will be discussed as well.	Univ Calif Riverside, Riverside, CA 92521 USA	Jeske, DR (reprint author), Univ Calif Riverside, Riverside, CA 92521 USA.						BROSS I, 1954, BIOMETRICS, V10, P478, DOI 10.2307/3001619; Cheng AY, 2000, IIE TRANS, V32, P861, DOI 10.1080/07408170008967445; Clopper CJ, 1934, BIOMETRIKA, V26, P404, DOI 10.2307/2331986; Fleiss J., 2003, STAT METHODS RATES P; Hastie T., 2001, ELEMENTS STAT LEARNI; *IAE AG, 1992, SAF REP SAF SER, V75; JESKE D, 2003, MEASURING RISK PERFO; Lewis D.D., 1998, EUR C MACH LEARN, P4; LIU R, 2002, STAT DATA ANAL BASED, P379; Liu RY, 2003, DEVELOPMENTS IN ROBUST STATISTICS, P246; Liu RY, 1999, ANN STAT, V27, P783; *NAT TECHN INF SER, MILSSTD1629 NAT TECH; SPIEGELHALTER DJ, 1984, J ROY STAT SOC A STA, V147, P35, DOI 10.2307/2981737	13	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1431-8814		3-540-22014-3	ST CLASS DAT ANAL			2004							495	510				16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science; Mathematics, Applied	Computer Science; Operations Research & Management Science; Mathematics	BAS44	WOS:000223368200047		
S	Shatkin, JA; Qian, S		Linkov, I; Ramadan, AB		Shatkin, JA; Qian, S			Classification schemes for priority setting and decision making - A selected review of expert judgment, rule-based, and prototype methods	COMPARATIVE RISK ASSESSMENT AND ENVIRONMENTAL DECISION MAKING	NATO Science Series IV Earth and Environmental Sciences		English	Proceedings Paper	NATO Advanced Research Workshop on Comparative Risk Assessment and Environmental Decision Making	OCT 13-16, 2002	Rome, ITALY	NATO, Soc Risk Anal, Soc Toxicol			ARTIFICIAL NEURAL-NETWORK; ELECTROTOPOLOGICAL STATE INDEXES; DISCRIMINANT-ANALYSIS; ALGAL BLOOMS; DIAGNOSIS; RIVER	Agencies and organizations charged with priority setting require analytical approaches that are accurate, efficient, and reliable. Increasingly, decision analysis is applied using formal techniques that are measurable and repeatable. This paper surveys available methods ranging from expert judgment approaches to complex statistical models, and considers the benefits and issues raised for decision making that applies various approaches.	Cadmus Grp Inc, Watertown, MA 02472 USA							BAXT WG, 1991, ANN INTERN MED, V115, P843; BRAUSE R, 1999, 799 U FRANKF FB INF; Breiman L., 1984, CLASSIFICATION REGRE; *CADM GROUP INC, 1992, CADM RISK IND APPR; *COMM EUR COMM, 1997, EUSES 1 0 US MAN; *COMM GEOSC ENV RE, 1998, SETT PRIOR DRINK WAT, P113; *CONS DES CTR, 1996, DELPH PROC; Davis G., 1994, COMP EVALUATION CHEM; FIELDING A, 2000, BIOL DATA PROCESSING, V2; FIELDING A, 2000, JOINING CLUSTERS CLU; Flug M, 2000, J WATER RES PL-ASCE, V126, P270, DOI 10.1061/(ASCE)0733-9496(2000)126:5(270); Freeman K, 2000, ENVIRON HEALTH PERSP, V108, pA464; GOOSSENS LHJ, 2001, NATO SCI SERIES, V4, P411; Grassi M, 2001, EUR J EPIDEMIOL, V17, P19, DOI 10.1023/A:1010987521885; Green PJ, 1994, NONPARAMETRIC REGRES; Hastie T., 2001, ELEMENTS STAT LEARNI; HASTIE T, 1994, J AM STAT ASSOC, V89, P1255, DOI 10.2307/2290989; HASTIE T, 1996, ENCY BIOSTATISTICS; HASTIE T, 1995, ANN STAT, V23, P73, DOI 10.1214/aos/1176324456; Hastie T, 1996, J ROY STAT SOC B MET, V58, P155; Hastie T. J., 1990, GENERALIZED ADDITIVE; HASTIE TR, 2000, STAT NEURAL NETWORKS, pCH1; Heckerman David, 1995, MSRTR9506; HELLER M, 1996, P UCOWR 1996 SAN ANT, V9, P2; HINTON GE, 1992, NEURAL NETWORKS LEAR, P145; Huuskonen J, 2001, ENVIRON TOXICOL CHEM, V20, P491; Huuskonen JJ, 2000, J CHEM INF COMP SCI, V40, P947, DOI 10.1021/ci9904261; *INT SOL INC, 2001, NEUR NETW NNETSH FAQ; Janssen R, 2001, J MULTICRITERIA DECI, V10, P101, DOI 10.1002/mcda.293; KERR M, 2001, DELPHI PROCESS; KILSSON NJ, 1996, INTRO MACHINE LEARNI; KON MA, 1997, P BIAL C STAT PHYS, P122; Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195; LIN H, 2001, GIS SUPPORTED MODELI; Lootsma F. A., 2000, J MULTICRITERIA DECI, V9, P7, DOI 10.1002/1099-1360(200001/05)9:1/3<7::AID-MCDA263>3.0.CO;2-4; MACHIE D, 1994, MACHINE LEARNING NEU; Neelakantan TR, 2001, WATER SCI TECHNOL, V43, P125; Nerini D, 2000, ACTA BIOTHEOR, V48, P181, DOI 10.1023/A:1010248608012; NIGHSWONGER G, 2000, MED DEVICE DIAGNOSTI; *NRC, 2001, CLASS DRINK WAT CONT; *NRC, 1999, ID FUT DRINK WAT CON; *NRC, 1999, SETT PRIOR DRINK WAT; *OECD, OECD SER TEST ASS, V33; *ORG EC COOP DEV, 2001, JOINT M CHEM COMM WO; PONTIL M, 1998, 1649 MIT AI; PONTIL M, 1997, 1612 MIT AI; QIAN S, 2000, ENVIRON SCI TECHNOL, V35, P941; Qian SS, 1999, ENVIRON SCI TECHNOL, V33, P3332, DOI 10.1021/es9812148; Ripley BD, 1996, PATTERN RECOGNITION; SARLE W, 2001, FAQS NEURAL NETWORKS; Sarle Warren S., 1994, P 19 ANN SAS US GROU; SHATKIN JA, 1998, COMP RISK ASSESSMENT; Smith L., 2001, INTRO NEURAL NETWORK; *SRA, 2001, SOC RISK AN ANN M DE; *STATS, 2002, STAT NEUR NETW; Stiber NA, 1999, ENVIRON SCI TECHNOL, V33, P3012, DOI 10.1021/es981216s; STOW CA, 2002, IN PRESS ECOSYSTEMS; *SUPP VECT MACH, 2001, NEURSCIENCES; TAIN YI, 2001, T PATTERN ANAL MACHI, V23, P97; Turoff M., 1996, COMPUTER BASED DELPH; *US EPA, 1994, WAST MIN PRIOR TOOL; *US EPA, 1998, AG GUID COND EXT PEE; *US EPA, 1997, 52194 US EPA FR; *US EPA, 2001, US CLUST SCOR SYST; *US EPA, 2001, SOURC RANK DAT SRD; *US EPA, 2001, SCREEN LEV TOOLS; *US EPA, 1994, CHEM HAZ EV MAN STRA; Wei B, 2001, WATER RES, V35, P2022, DOI 10.1016/S0043-1354(00)00464-4; WEISMAN O, 1995, PERCEPTRON; Wenstop F, 2001, J MULTICRITERIA DECI, V10, P53, DOI 10.1002/mcda.289; WILSON RA, 2001, DECISION TREES MIT E; Woo YT, 2002, ENVIRON HEALTH PERSP, V110, P75; Yu RF, 2000, WATER SCI TECHNOL, V42, P403; *Z SOL, 1999, LIGHT INTR NEUR NETW; ZAKNIXH A, 1998, ARTIFICIAL NEURAL NE; ZHU J, 2001, NIPS2001 C VANC NOV	76	2	2	SPRINGER	DORDRECHT	PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1568-1238		1-4020-1895-9	NATO SCI S SS IV EAR	NATO Sci. Series IV Earth Environ. Sciences		2004	38						213	243				31	Environmental Sciences; Environmental Studies	Environmental Sciences & Ecology	BAH65	WOS:000222255300013		
B	Grossmann, W; Schimek, MG; Sint, PP		Antoch, J		Grossmann, W; Schimek, MG; Sint, PP			The history of compstat and key-steps of statistical computing during the last 30 years	COMPSTAT 2004: PROCEEDINGS IN COMPUTATIONAL STATISTICS			English	Proceedings Paper	16th Symposium on Computational Statistics (COMPSTAT 2004)	2004	Prague, CZECH REPUBLIC			COMPSTAT symposium; computational statistics; history of statistics; statistical computing; statistical languages; statistical software	REGRESSION; MODELS; ALGORITHM		Univ Vienna, Inst Stat & Decis Support Syst, A-1010 Vienna, Austria	Grossmann, W (reprint author), Univ Vienna, Inst Stat & Decis Support Syst, Univ Str 5, A-1010 Vienna, Austria.						*ACM, 1999, SOFTW SYST AW; ADAM A, 1973, HIMMLISCHEN UHRWERK; Andrews D., 1972, ROBUST ESTIMATION LO; ANSCOMBE FJ, 1981, COMPUTING STAT SCI A; BARRITT MM, 1980, COMPSTAT 1980 P COMP; BETHLEHEM JG, 2000, COMPSTAT 2000 P COMP; Breiman L., 1984, CLASSIFICATION REGRE; BRUCKMANN G, 1974, COMPSTAT 1974 P COMP; BUJA A, 1989, ANN STAT, V17, P453, DOI 10.1214/aos/1176347115; CAUSSINUS H, 1982, COMPSTAT 1982 P COMP; Chambers J. M., 1992, STAT MODELS S; CHAMBERS J M., 1998, PROGRAMMING DATA GUI; CHRISTELLER S, 1974, COMPSTAT P COMP STAT, P479; CODD EF, 1970, COMMUN ACM, V13, P377, DOI 10.1145/362384.362685; Coppi R, 2002, COMPUT STAT DATA AN, V38, P501, DOI 10.1016/S0167-9473(01)00075-5; CORSTEN LCA, 1978, COMPSTAT 1978 P COMP; COX DR, 1972, J R STAT SOC B, V34, P187; DAHL OJ, 1966, COMMUN ACM, V9, P671, DOI 10.1145/365813.365819; DEANTONI F, 1986, COMPSTAT 1986 P COMP; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Devroye L., 1986, NONUNIFORM RANDOM VA; DIRSCHEDL P, 1994, COMPUTATIONAL STAT; DIXON WJ, 1971, BMD BIOMEDICAL COMPU; DODGE Y, 1992, COMPUTATIONAL STAT, V2; DODGE Y, 1992, COMPUTATION STAT, V1, P3; DODGE Y, 1992, COMPUTATIONAL STAT, V1; DUTTER W, 1994, COMPSTAT 1994 P COMP; EDWARDS D, 1988, COMPSTAT 1988 P COMP; Efron B, 2003, ANN STAT, V31, P366, DOI 10.1214/aos/1051027871; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; EFRON B, 2002, FESTSCHRIFT 50 JAHRE, P7; FISHERKELLER MA, 1974, STANFORD LINEAR ACCE, V1408; FLECK C, 2000, OSTERREICHISCHE Z GE, V1, P129; FRANCIS I, 1981, STAT SOFTWARE COMP R; Frawley W., 1992, AI MAGAZINE      FAL, P213; FRIEDMAN JH, 1974, IEEE T COMPUT, VC 23, P881, DOI 10.1109/T-C.1974.224051; Friedman JH, 2002, ANN STAT, V30, P1629; Gelman A, 1996, BAYESIAN DATA ANAL; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; Gentle JE, 2002, ELEMENTS COMPUTATION; Gershenfeld N., 1999, NATURE MATH MODELING; Goldstine H., 1972, COMPUTER PASCAL VON; GORDESCH J, 1976, COMPSTAT 1976 P COMP; Hand D. J., 1996, COMPSTAT. Proceedings in Computational Statistics. 12th Symposium; HARDLE W, 1995, XPLORE INTERACTIVE S; HARDLE W, 2002, COMPSTAT 2002 P COMP; HARDLE W, 1996, P COMPSTAT 94 SAT M; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T. J., 1990, GENERALIZED ADDITIVE; HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.2307/2334940; HAVRANEK T, 1984, COMPSTAT 1984 P COMP; HEIDE L, 2003, ISTOS WORKSH U POMP; Hornik K., 2002, FESTSCHRIFT 50 JAHRE, P61; HUBER HE, 1994, CURR MED CHEM, V1, P13; Huber PJ, 1999, J COMPUT GRAPH STAT, V8, P635; HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732; Ihaka R, 2005, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Lang DT, 2000, J COMPUT GRAPH STAT, V9, P423, DOI 10.2307/1390938; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; Lauro C, 1996, COMPUT STAT DATA AN, V23, P191, DOI 10.1016/0167-9473(96)88920-1; Mehta CR, 2000, J AM STAT ASSOC, V95, P99, DOI 10.2307/2669530; MEHTA CR, 1997, EXACT INFERENCE CATE; MEHTA CR, 1992, COMPUTATION STAT, V2, P63; METROPOLIS N, 1949, J AM STAT ASSOC, V44, P335, DOI 10.2307/2280232; Meyer D, 2002, COMPSTAT 2002: PROCEEDINGS IN COMPUTATIONAL STATISTICS, P545; MOMIROVIC K, 1990, COMPSTAT 1990 P COMP; Monahan J. F., 2001, NUMERICAL METHODS ST; NELDER JA, 1974, COMPSTAT P COMP STAT, P499; NELDER JA, 1972, J R STAT SOC SER A-G, V135, P370, DOI 10.2307/2344614; Nelder J. A., 1978, COMPSTAT 1978 Proceedings in Computational Statistics; NEUWIRTH E, 2002, DSC 2001 P 2 INT WOR; OWEN DB, 1976, P S AM MATH HER; PAYNE R, 1998, COMPSTAT 1998 P COMP; PRAT A, 1996, COMPSTAT 1996 P COMP; Ripley B., 1987, STOCHASTIC SIMULATIO; ROBBINS H, 1956, 3RD P BERK S MATH ST, V1, P157; SCHAFFLER O, 1895, Patent No. 463182; Shoshani A., 1997, Proceedings of the Sixteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, PODS 1997, DOI 10.1145/263661.263682; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; SUNDGREN B, 1975, THEORY DATA BASES; Thisted R.A., 1988, ELEMENTS STAT COMPUT; Tierney L., 1990, LISP STAT OBJECT ORI; TIERNEY L, 1989, 528 U MINN SCH STAT; Tukey J. W., 1970, EXPLORATORY DATA ANA, V1; TUKEY JW, 1962, ANN MATH STAT, V33, P1, DOI 10.1214/aoms/1177704711; TUKEY JW, 1965, MAT COMPUT, V19, P237; TUKEY JW, 1970, EXPLORATORY DATA ANA, V2; Wegman EJ, 2003, J COMPUT GRAPH STAT, V12, P893, DOI 10.1198/1061860032625; WILKINSON L, 2000, J COMPUTAT GRAPH STA, V9, P558; ZEMANEK H, 1975, OSTERREICHISCHER GEW, V92, P71	90	0	0	PHYSICA-VERLAG GMBH & CO	HEIDELBERG	TIERGARTENSTR 17, D-69121 HEIDELBERG, GERMANY			3-7908-1554-3				2004							1	35				35	Statistics & Probability	Mathematics	BAY19	WOS:000224173300001		
B	Rodriguez, PN; Rodriguez, A			Wessex Inst of Technology	Rodriguez, PN; Rodriguez, A			Predicting stock market indices movements	COMPUTATIONAL FINANCE AND ITS APPLICATIONS			English	Proceedings Paper	1st International Conference on Computational Finance and its Applications	2004	Bologna, ITALY	Wessex Inst Technol		stock indices movements; data mining; ROC analysis	EFFICIENT CAPITAL-MARKETS; NEURAL-NETWORKS; ROC CURVE; CLASSIFICATION; SPLINES; AREA	This paper examines the extent to which the daily movements of three large emerging markets stock indices are predictable. Lagged technical indicators are used as explanatory variables. In the analysis, we employed seven classification techniques and assessed the discriminatory power of the classifiers through the area under the receiver operating characteristic (ROC) curve. The results show that the daily movements of the three indices are better predictable than random. After taking into account the bias induced by non-synchronous price quotations, a trading system with break-even costs is simulated. The non-random classifiers yield returns above those of both random walk and contrarian investment strategies. No inefficiency is found due to the fact that relatively low break-even transaction costs are enough to eliminate the sources of trading profits.	Univ Complutense Madrid, Dept Stat & Operat Res 2, E-28040 Madrid, Spain							Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CAMPBELL JY, 1994, ECONOMETRICS FINANCI; Chande T. S., 1994, NEW TECHNICAL TRADER; Chen CP, 2001, RARE METAL MAT ENG, V30, P31; FAMA EF, 1991, J FINANC, V46, P1575, DOI 10.2307/2328565; FAMA EF, 1970, J FINANC, V25, P383, DOI 10.2307/2325486; Fernandez-Rodriguez F, 2000, ECON LETT, V69, P89, DOI 10.1016/S0165-1765(00)00270-6; Friedman J. H., 2001, ANN STAT, V29; Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; HAND D.J., 1997, CONSTRUCTION ASSESSM; HANLEY JA, 1982, RADIOLOGY, V143, P29; Hastie T., 2002, ELEMENTS STAT LEARNI; JOKIVUOLLE E, 1995, J FINANC QUANT ANAL, V30, P455, DOI 10.2307/2331351; Kim KJ, 2003, NEUROCOMPUTING, V55, P307, DOI 10.1016/S0925-2312(03)00372-2; Leung MT, 2000, INT J FORECASTING, V16, P173, DOI 10.1016/S0169-2070(99)00048-5; Metz CE, 1998, STAT MED, V17, P1033, DOI 10.1002/(SICI)1097-0258(19980515)17:9<1033::AID-SIM784>3.3.CO;2-Q; Provost F, 2003, MACH LEARN, V52, P199, DOI 10.1023/A:1024099825458; RIPLEY BD, 1994, J ROY STAT SOC B MET, V56, P409; Stone CJ, 1997, ANN STAT, V25, P1371; Tsaih R, 1998, DECIS SUPPORT SYST, V23, P161, DOI 10.1016/S0167-9236(98)00028-1; Zemke S, 1999, PHYSICA A, V269, P177, DOI 10.1016/S0378-4371(99)00091-6; Zhou XH, 2002, STAT METHODS DIAGNOS	26	0	0	WIT PRESS	SOUTHAMPTON	ASHURST LODGE, SOUTHAMPTON SO40 7AA, ASHURST, ENGLAND			1-85312-709-4				2004							13	23				11	Business, Finance; Computer Science, Artificial Intelligence	Business & Economics; Computer Science	BAR59	WOS:000223267800002		
S	Gupta, MR		Bouman, CA; Miller, EL		Gupta, MR			Inverting color transforms	COMPUTATIONAL IMAGING II	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Conference on Computational Imaging II	JAN 19-20, 2004	San Jose, CA	SPIE, Soc Imaging Sci & Technol		color management; regular grids; inverse problem; LIME; maximum entropy; PLI; linear interpolation		We consider experimental methods for creating regular grids for applications such as color management where the grids must be estimated from non-grid samples. To estimate the regular grid, we propose applying a generalization of linear interpolation, called linear interpolation with maximum entropy (LIME). Evaluating different estimation methods for this problem is difficult and does not correspond to the standard statistical learning paradigm of using iid training and test sets in order to compare algorithms. In this paper we consider the experimental issues and propose considering the end goal of the regular grid in evaluating an estimated grid's value. Preliminary experimental results compare LIME, traditional linear interpolation, linear regression and ridge regression.	Univ Washington, Dept Elect Engn, Seattle, WA 98301 USA	Gupta, MR (reprint author), Univ Washington, Dept Elect Engn, Seattle, WA 98301 USA.						Cover T. M., 1991, ELEMENTS INFORMATION; Gupta M. R., 2003, THESIS STANFORD U ST; GUPTA MR, 2003, P IEEE WORKSH STAT S; Hastie T., 2001, ELEMENTS STAT LEARNI; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; KACKER D, 1998, P IEEE INT C IM PROC, V1, P186, DOI 10.1109/ICIP.1998.723454; Kang H. R., 1997, COLOR TECHNOLOGY ELE; Rovatti R, 1998, IEEE T COMPUT, V47, P894, DOI 10.1109/12.707591; Scharf L. L., 1991, STAT SIGNAL PROCESSI	9	1	1	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		0-8194-5202-5	P SOC PHOTO-OPT INS			2004	5299						83	92		10.1117/12.538834		10	Imaging Science & Photographic Technology	Imaging Science & Photographic Technology	BAH93	WOS:000222330700009		
S	Wozniak, M		Lagana, A; Gavrilova, ML; Kumar, V; Mun, Y; Tan, CJK; Gervasi, O		Wozniak, M			Information fusion for probabilistic reasoning and its application to the medical decision support systems	COMPUTATIONAL SCIENCE AND ITS APPLICATIONS - ICCSA 2004, PT 3	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	International Conference on Computational Science and Its Applications (ICSSA 2004)	MAY 14-17, 2004	Assisi, ITALY	Univ Perugia, Univ Calgary, Univ Minnesota, Queens Univ Belfast, Heuchera Technologies, Minist Sci & Educ Italy, GRID IT Project, COST				Paper deals with the knowledge acquisition process problems. Different experts formulate the rules for decision support system. We assume they have different knowledge about the problem and therefore obtained rules have different qualities. Additional some of them can be generated by machine learning algorithms - of course the quality of information stored in the databases are different. We will formulate the proposition of the confidence measure of knowledge. We will show some of its applications to the decision process. We will propose how use proposed measure for typical probabilistic decision process. The presented concepts will: be applied to the real medical decision problem based on boosting idea.	Wroclaw Tech Univ, Chair Syst & Comp Networks, PL-50370 Wroclaw, Poland	Wozniak, M (reprint author), Wroclaw Tech Univ, Chair Syst & Comp Networks, Wybrzeze Wyspianskiego 27, PL-50370 Wroclaw, Poland.	Michal.Wozniak@pwr.wroc.pl	Wozniak, Michal/A-4806-2008				BERGADANO F, 1988, P 3 EUR WORK SESS LE; DEAN P, 1997, APPL INTELLIGENCE; Devijver P. A., 1982, PATTERN RECOGNITION; Duda R.O., 2001, PATTERN CLASSIFICATI; Giakoumakis E., 1987, PATTERN RECOGNITION; Hastie T., 2001, ELEMENTS STAT LEARNI; KASPRZAK A, 2003, SPRINGER VERLAG LECT, V2660; Mitchell T., 1997, MACHINE LEARNING; PUCHALA E, 2003, SPRINGER VERLAG LECT, V2659; PUCHALA E, 2003, P 37 C MOD SIM SYST; Schapire R., 2001, P MSRI WORKSH NONL E; WOZNIAK M, 2003, SPRINGER VERLAG LECT, V2657	12	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-22057-7	LECT NOTES COMPUT SC			2004	3045						593	601				9	Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BAE50	WOS:000221852900062		
J	Ghosh, AK; Bose, S				Ghosh, AK; Bose, S			Backfitting neural networks	COMPUTATIONAL STATISTICS			English	Article						backfitting; backpropagation; backward deletion; cross validation; multi-layer perceptron; simulation	PROJECTION PURSUIT; REGRESSION; CLASSIFICATION; SPLINES	Regression and classification problems can be viewed as special cases of the problem of function estimation. It is rather well known that a two-layer perceptron with sigmoidal transformation functions can approximate any continuous function on the compact subsets of RP if there are sufficient number of hidden nodes. In this paper, we present an algorithm for fitting perceptron models, which is quite different from the usual backpropagation or Levenberg-Marquardt algorithm. This new algorithm based on backfitting ensures a better convergence than backpropagation. We have also used resampling techniques to select an ideal number of hidden nodes automatically using the training data itself. This resampling technique helps to avoid the problem of overfitting that one faces for the usual perceptron learning algorithms without any model selection scheme. Case studies and simulation results are presented to illustrate the performance of this proposed algorithm.	Indian Stat Inst, Stat Math Unit, Kolkata 700108, W Bengal, India	Ghosh, AK (reprint author), Indian Stat Inst, Stat Math Unit, 203 BT Rd, Kolkata 700108, W Bengal, India.	res9812@isical.ac.in; smarajit@isical.ac.in					Anderson T. W., 1984, INTRO MULTIVARIATE S; BARRON AR, 1988, S INT STAT COMP SCI, P192; Bose S, 1996, COMPUT STAT DATA AN, V22, P505, DOI 10.1016/0167-9473(96)00009-6; BOSE S, 2003, IN PRESS COMPUT STAT; BREIMAN L, 1984, NONLINEAR DISCRIMINA; Breiman L., 1984, CLASSIFICATION REGRE; BREIMAN L, 1993, COMPUT STAT DATA AN, V15, P13, DOI 10.1016/0167-9473(93)90217-H; Chauvin Y., 1989, ADV NEURAL INFORMATI, VI, P519; CHAUVIN Y, 1990, ADV NEURAL INFORMATI, V2, P642; CHENG B, 1994, STAT SCI, V9, P2, DOI 10.1214/ss/1177010638; Cooley CA, 1998, BIOMETRIKA, V85, P823, DOI 10.1093/biomet/85.4.823; Cristianini N, 2000, INTRO SUPPORT VECTOR; Donoho DL, 1996, ANN STAT, V24, P508; Duda R. O., 2000, PATTERN CLASSIFICATI; Fan J., 1996, LOCAL POLYNOMIAL MOD; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; FRIEDMAN JH, 1981, J AM STAT ASSOC, V76, P817, DOI 10.2307/2287576; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Fukunaga K, 1990, INTRO STAT PATTERN R; HARRISON D, 1978, J ENVIRON ECON MANAG, V5, P81, DOI 10.1016/0095-0696(78)90006-2; Hastie T., 2001, ELEMENTS STAT LEARNI; HASTIE T, 1994, J AM STAT ASSOC, V89, P1255, DOI 10.2307/2290989; Hinton G. E., 1986, P 8 ANN C COGN SCI S, P1; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; HWANG JN, 1994, IEEE T NEURAL NETWOR, V5, P342; Karnin E D, 1990, IEEE Trans Neural Netw, V1, P239, DOI 10.1109/72.80236; Kooperberg C, 1997, J AM STAT ASSOC, V92, P117, DOI 10.2307/2291455; Laarhoven P, 1987, SIMULATED ANNEALING; Lippmann R. P., 1987, IEEE ASSP Magazine, V4, DOI 10.1109/MASSP.1987.1165576; McLachlan G., 1992, DISCRIMINANT ANAL ST; Mozer M. C., 1989, ADV NEURAL INFORMATI, VI, P107; NOWLAN SJ, 1992, NEURAL COMPUT, V4, P473, DOI 10.1162/neco.1992.4.4.473; PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875; REED R, 1993, IEEE T NEURAL NETWOR, V4, P740, DOI 10.1109/72.248452; RIPLEY BD, 1994, J ROY STAT SOC B MET, V56, P409; Ripley BD, 1996, PATTERN RECOGNITION; ROOSEN CB, 1994, J COMPUTA GRAPHICAL, V3, P235, DOI 10.2307/1390909; Scott D. W., 1992, MULTIVARIATE DENSITY; Seber G.A.F., 1989, NONLINEAR REGRESSION; Silverman BW, 1986, DENSITY ESTIMATION S; Zhao Y, 1996, IEEE T NEURAL NETWOR, V7, P362	42	3	3	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	0943-4062	1613-9658		COMPUTATION STAT	Comput. Stat.		2004	19	2					193	210		10.1007/BF02892056		18	Statistics & Probability	Mathematics	828KZ	WOS:000221973500003		
S	Tsin, Y; Kanade, T		Pajdla, T; Matas, J		Tsin, Y; Kanade, T			A correlation-based approach to robust point set registration	COMPUTER VISION - ECCV 2004, PT 3	Lecture Notes in Computer Science		English	Article; Proceedings Paper	8th European Conference on Computer Vision	MAY 11-14, 2004	Prague, CZECH REPUBLIC	Business Informat Grp as, Camea spol sro, Casablanca INT sro, ECVision, Microsoft Res, Miracle Network sro, Neovision sro, Toyota			ALGORITHM; DISTANCE; IMAGES	Correlation is a very effective way to align intensity images. We extend the correlation technique to point set registration using a method we call kernel correlation. Kernel correlation is an affinity measure, and it is also a function of the point set entropy. We define the point set registration problem as finding the maximum kernel correlation configuration of the the two point sets to be registered. The new registration method has intuitive interpretations, simple to implement algorithm and easy to prove convergence property. Our method shows favorable performance when compared with the iterative closest point (ICP) and EM-ICP methods.	Siemens Corp Res, Princeton, NJ 08540 USA; Carnegie Mellon Univ, Pittsburgh, PA 15213 USA	Tsin, Y (reprint author), Siemens Corp Res, 755 Coll Rd E, Princeton, NJ 08540 USA.						BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; CHEN H, 2002, EUR C COMP VIS, P236; FITSGIBBON A, 2001, BMVC 01; GEMAN S, 1984, IEEE TPAMI, V6, P1721; GRANGER S, 2002, ECCV 02 JUNE; Hastie T., 2001, ELEMENTS STAT LEARNI; Huber P., 1981, ROBUST STAT; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; LAVALLEE S, 1995, IEEE T PATTERN ANAL, V17, P378, DOI 10.1109/34.385980; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Press W.H., 1992, NUMERICAL RECIPES C; PRINCIPE J, 1999, 1 INT WORKSH IND COM, P407; Rangarajan A, 1997, LECT NOTES COMPUT SC, V1230, P29; Renyi A, 1961, 4TH P BERK S MATH ST, V1, P547; Rousseeuw P., 1987, ROBUST REGRESSION OU; SCOTT GL, 1991, P ROY SOC B-BIOL SCI, V244, P21, DOI 10.1098/rspb.1991.0045; TSIN Y, 2003, CMURI0336; Zhang Z., 1994, IJCV, V13, P6	19	32	33	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-21982-X	LECT NOTES COMPUT SC			2004	3023						558	569				12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BAC68	WOS:000221569700044		
S	Gebert, J; Latsch, M; Pickl, SW; Radde, N; Weber, GW; Wunschiers, R		Dubois, DM		Gebert, J; Latsch, M; Pickl, SW; Radde, N; Weber, GW; Wunschiers, R			Genetic networks and anticipation of gene expression patterns	COMPUTING ANTICIPATORY SYSTEMS	AIP CONFERENCE PROCEEDINGS		English	Proceedings Paper	6th Interantional Conference on Computing Anticipatory Systems (CASYS 03)	AUG 11-16, 2003	Liege, BELGIUM	Fonds Natl Rech Sci, Minist Commun Francaise Belgique, Hotel Ville Liege, Echevinat Culture Musees Tourisme Ville Liege, Hautes Etudes Commericales, Euro View Serv SA, World Org Syst & Cybernet, Syst Sci European Union, Washington Evolut Syst Soc		computational biology; gene expression data; dynamical system; discrete approximation; mathematical modelling		An interesting problem for computational biology is the analysis of time-series expression data. Here, the application of modem methods from dynamical systems, optimization theory, numerical algorithms and the utilization of implicit discrete information lead to a deeper understanding. In [I], we suggested to represent the behavior of time-series gene expression patterns by a system of ordinary differential equations, which we analytically and algorithmically investigated under the parametrical aspect of stability or instability. Our algorithm strongly exploited combinatorial information. In this paper, we deepen, extend and exemplify this study from the viewpoint of underlying mathematical modelling. This modelling consists in evaluating DNA-microarray measurements as the basis of anticipatory prediction, in the choice of a smooth model given by differential equations, in an approach of the right-hand side with parametric matrices, and in a discrete approximation which is a least squares optimization problem. We give a mathematical and biological discussion, and pay attention to the special case of a linear system, where the matrices do not depend on the state of expressions. Here, we present first numerical examples.	Univ Cologne, Ctr Appl Comp Sci, Math Inst, D-50931 Cologne, Germany	Gebert, J (reprint author), Univ Cologne, Ctr Appl Comp Sci, Math Inst, D-50931 Cologne, Germany.		Wunschiers, Robbe/A-3963-2011				Akutsu T, 1999, Pac Symp Biocomput, P17; Amann H., 1983, GEWOHNLICHE DIFFEREN; BANK B, 1982, NONLIENAR PARAMETRIC; Chen T, 1999, Pac Symp Biocomput, P29; CORDUNEANU C, 2001, COMP ANT SYST CASYS, P160; DETRAD CH, 2001, P IEEE EMBS, P115; DRIVER RD, 1965, ARCH RAT MECH AN, V18, P241; Duda R.O., 2001, PATTERN CLASSIFICATI; Gaffke N., 1996, HANDB STAT, V13, P1149, DOI 10.1016/S0169-7161(96)13032-7; GEBERT J, 2002, SIM METH 5 INT WORKS, P79; Gygi SP, 1999, MOL CELL BIOL, V19, P1720; HALANAY A, 1968, QUALITATIVE THEORY I, P4; Hastie T., 2001, ELEMENTS STAT LEARNI; HOON MD, 2002, LECT NOTES COMPUTER, V2534, P267; Isaacson E., 1966, ANAL NUMERICAL METHO; Jongen H. T., 1990, Annals of Operations Research, V27, DOI 10.1007/BF02055198; KACZOREK T, 2001, COMP ANT SYST CASY 5, P107; KRAFFT O, 1997, LINEARE STAT MODELLE; KREBS W, 1997, MATH MODELLIERUNG EI; Monod J, 1972, CHANCE NECESSITY; MORIYAMA T, 1999, GEN INF SER WORKSH G, V10, P186; MOULIN T, 2001, COMPUTING ANTICIPATO, V4, P253; QUARTERONI A, 1991, TEXTS MATH APPL MATH, V37; RIEDEL KO, 2002, THESIS U COLOGNE GER; Sakamoto E, 2001, IEEE C EVOL COMPUTAT, P720, DOI 10.1109/CEC.2001.934462; SCHENA M, 1999, DNA MICROARRAYS; Schliep A., 2003, BIOINFORMATICS, V19, pi255; Schrodinger E., 1944, WHAT IS LIFE; SLONIM D, 2002, NAT GENET, P32; Spellucci P., 1993, NUMERISCHE VERFAHREN; SPELLUCCI P, 2001, J COMPUTATIONAL TECH, V6, P64; Weber G.-W., 1991, J GLOBAL OPTIM, V1, P47, DOI 10.1007/BF00120665; ZOUYOUSEFAIN MS, 1990, THESIS U TEXAS ARLIN	33	17	17	AMER INST PHYSICS	MELVILLE	2 HUNTINGTON QUADRANGLE, STE 1NO1, MELVILLE, NY 11747-4501 USA	0094-243X		0-7354-0198-5	AIP CONF PROC			2004	718						474	485				12	Computer Science, Interdisciplinary Applications; Mathematics, Applied	Computer Science; Mathematics	BAU89	WOS:000223656700041		
S	Kamenetsky, M; Widrow, B		Matthews, MB		Kamenetsky, M; Widrow, B			A variable leaky LMS adaptive algorithm	CONFERENCE RECORD OF THE THIRTY-EIGHTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2	CONFERENCE RECORD OF THE ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS AND COMPUTERS		English	Proceedings Paper	38th Asilomar Conference on Signals, Systems and Computers	NOV 07-10, 2004	Pacific Grove, CA				GAUSSIAN DATA; FILTERS	The LMS algorithm has found wide application in many areas of adaptive signal processing and control. We introduce a variable leaky LMS algorithm, designed to overcome the slow convergence of standard LMS in cases of high input eigenvalue spread. The algorithm uses a greedy punish/reward heuristic together with a quantized leak adjustment function to vary the leak. Simulation results confirm that the new algorithm can significantly outperform standard LMS when the input eigenvalue spread is high.	Stanford Univ, Dept Elect Engn, ISL, Stanford, CA 94305 USA	Kamenetsky, M (reprint author), Stanford Univ, Dept Elect Engn, ISL, Stanford, CA 94305 USA.						CIOFFI JM, 1987, IEEE T CIRCUITS SYST, V34, P821, DOI 10.1109/TCS.1987.1086209; FEUER A, 1985, IEEE T ACOUST SPEECH, V33, P222, DOI 10.1109/TASSP.1985.1164493; Hastie T., 2001, ELEMENTS STAT LEARNI; Kailath T., 2000, LINEAR ESTIMATION; Mayyas K, 1997, IEEE T SIGNAL PROCES, V45, P927, DOI 10.1109/78.564181; REY GJ, 1991, IEEE T CIRCUITS SYST, V38, P476, DOI 10.1109/31.76484; SAYED AH, 2001, P ICASSP, V6, P3873; SEGALEN A, 1982, ELECTRON LETT, V18, P226, DOI 10.1049/el:19820154; SETHARES WA, 1986, IEEE T ACOUST SPEECH, V34, P868, DOI 10.1109/TASSP.1986.1164874; Widrow B., 1960, IRE Wescon Convention Record, V4; Widrow B., 1985, ADAPTIVE SIGNAL PROC, V4	11	2	5	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1058-6393		0-7803-8622-1	CONF REC ASILOMAR C			2004							125	128				4	Engineering, Electrical & Electronic; Remote Sensing; Imaging Science & Photographic Technology; Telecommunications	Engineering; Remote Sensing; Imaging Science & Photographic Technology; Telecommunications	BBS96	WOS:000227655300025		
S	Dzeroski, S; Todorovski, L; Ljubic, P		Boulicaut, JF; Raedt, LD; Mannila, H		Dzeroski, S; Todorovski, L; Ljubic, P			Inductive queries on polynomial equations	CONSTRAINT-BASED MINING AND INDUCTIVE DATABASES	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	European Workshop on Inductive Databases and Constraint Based Mining	MAR 11-13, 2004	Hinterzarten, GERMANY	IST Programme, EU GET Arm			KNOWLEDGE DISCOVERY	Inductive databases (IDBs) contain both data and patterns. Inductive Queries (IQs) are used to access, generate and manipulate the patterns in the IDB. IQs are conjunctions of primitive constraints that have to be satisfied by target patterns: they can be different for different types of patterns. Constraint-based data mining algorithms are used to answer IQs. So far, mostly the problem of mining frequent patterns has been considered in the framework of IDBs: the types of patterns considered include frequent itemsets, episodes, Datalog queries, sequences, and molecular fragments. Here we consider the problem of constraint-based mining for predictive models, where the data mining task is regression and the models are polynomial equations. More specifically, we first define the pattern domain of polynomial equations. We then present a complete and a heuristic solver for this domain. We evaluate the use of the heuristic solver on standard regression problems and illustrate its use on a toy problem of reconstructing a biochemical reaction network. Finally, we consider the use of a combination of different pattern domains (molecular fragments and polynomial equations) for practical applications in modeling quantitative structure-activity relationships (QSARs).	Jozef Stefan Inst, Ljubljana, Slovenia	Dzeroski, S (reprint author), Jozef Stefan Inst, Janova 39, Ljubljana, Slovenia.						BASSINGTHWAIGHT.JB, 2002, WEB PAGE PHYSIOME PR; Bayardo R., 2002, SIGKDD EXPLORATIONS, V4; Blake C.L., 1998, UCI REPOSITORY MACHI; DERAEDT L, 2002, COMPUTATIONAL LOGIC; DERAEDT L, 2003, ARTIFICIAL INTELLIGE; DZEROSKI S, 1999, P 9 INT C IND LOG PR, P80; DZEROSKI S, 2003, P 6 INT C DISC SCI, P297; Hastie T., 2001, ELEMENTS STAT LEARNI; Helma C., 2005, PREDICTIVE TOXICOLOG; Howard P, 1991, HDB ENV DEGRADATION; Imielinski T, 1996, COMMUN ACM, V39, P58, DOI 10.1145/240455.240472; Koza J R, 2001, Pac Symp Biocomput, P434; Kramer S., 2001, P 18 INT C MACH LEAR, P258; Langley P., 1987, SCI DISCOVERY; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; RICHARD A, 2004, DISTRIBUTED STRUCTUR; Dzeroski S., 1995, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V4, DOI 10.1007/BF00962824; Todorovski L., 1997, P 14 INT C MACH LEAR, P376; TODOROVSKI L, 2001, P 4 INT C DISC SCI, P390; TODOROVSKI L, 2004, P 15 INT C MACH LEAR, P441; TODOROVSKI L, 2003, P 6 INT C MACH LEAN, P151; TORGO L, 2001, REGRESSION DATA SETS; Voit E. O., 2000, COMPUTATIONAL ANAL B; Wang Y, 1997, P 9 EUR C MACH LEARN, P128; Witten I.H., 1999, DATA MINING PRACTICA	25	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-31331-1	LECT NOTES ARTIF INT			2004	3848						127	154				28	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BDW55	WOS:000235842700007		
S	Giannella, C; Bhargava, R; Kargupta, H		Klusch, M; Ossowski, S; Kashyap, V; Unland, R		Giannella, C; Bhargava, R; Kargupta, H			Multi-agent systems and distributed data mining	COOPERATIVE INFORMATION AGENTS VIII, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	8th International Workshop on Cooperative Information Agents	SEP 27-29, 2004	Erfurt, GERMANY	Assoc Comp Machinery, TranSIT GmbH, URJC Decis Engn Lab, Whitestein Technologies, Spanish Assoc Artificial Intelligence, AgentLink III, EU FP6 Coordinating Act		multi-agent systems; distributed data mining; clustering	PARALLEL	Multi-agent systems offer an architecture for distributed problem solving. Distributed data mining algorithms specialize on one class of such distributed problem solving tasks-analysis and modeling of distributed data. This paper offers a perspective on distributed data mining algorithms in the context of multiagents systems. It particularly focuses on distributed clustering algorithms and their potential applications in multi-agent-based problem solving scenarios. It discusses potential applications in the sensor network domain, reviews some of the existing techniques, and identifies future possibilities in combining multi-agent systems with the distributed data mining technology.	Univ Maryland Baltimore Cty, Dept Comp Sci & Elect Engn, Baltimore, MD 21250 USA	Giannella, C (reprint author), Univ Maryland Baltimore Cty, Dept Comp Sci & Elect Engn, Baltimore, MD 21250 USA.	cgiannel@cs.umbc.edu; ruchital@cs.umbc.edu; hillol@cs.umbc.edu					BABAOGLU O, 2001, 9 U BOL DEP COMP SCI; Babcock B., 2002, P 21 ACM SIGACT SIGM, P1; DHILLON I, 1990, P KDD 99 WORKSH HIGH, P245; EISENHARDT M, 2003, GI LECT NOTES INFORM; FARINELLI A, 2003, IEEE RSJ INT C INT R, V4, P3148; Forman G., 2000, SIGKDD EXPLORATIONS, V2, P34; Fred A. L. N., 2002, Proceedings 16th International Conference on Pattern Recognition, DOI 10.1109/ICPR.2002.1047450; Han J., 2001, DATA MINING CONCEPTS; Hastie T., 2001, ELEMENTS STAT LEARNI; HINENBURG A, 1998, P 1998 INT C KNOWL D, P58; JANUZAJ E, 2004, LECT NOTES COMPUTER, P88; Johnson E, 1999, LECT NOTES COMPUTER, V1759, P221; JOUVE P, 2003, P WORKSH PAR DISTR C; KAHN J, 1999, ACM IEEE ITN C MOB C; Kargupta H., 2001, Knowledge and Information Systems, V3, DOI 10.1007/PL00011677; Kargupta H., 2004, DATA MINING NEXT GEN; Kargupta H., 2000, ADV DISTRIBUTED PARA; KARGUPTA H, 2004, P 2004 SIAM INT C DA; KLUSCH M, 2003, J JOINT INT C AI IJC; LAZAREVIC A, 2000, P 8 EUR S ART NEUR N, P129; MERUGU S, 2003, P IEEE C DAT MIN ICD; OGSTON E, 2002, 1 INT JOINT C AUT AG, P150; Park BH, 2003, HUM FAC ER, P341; Provost F, 2000, ADVANCES IN DISTRIBUTED AND PARALLEL KNOWLEDGE DISCOVERY, P3; Samatova NF, 2002, DISTRIB PARALLEL DAT, V11, P157; SHARPLES S, 1999, INT SENSOR REV J; Smyth P., 2001, PRINCIPALS DATA MINI; SOH LK, 2001, INT JOINT C ART INT; Strehl A., 2002, J MACHINE LEARNING R, V3, P583, DOI DOI 10.1162/153244303321897735; TOPCHY A, 2003, P IEEE C DAT MIN; Witten I.H., 1999, DATA MINING PRACTICA; YU B, 2002, P 1 INT JOINT C AUT, P1208; Zaki MJ, 2000, LECT NOTES ARTIF INT, V1759, P1, DOI 10.1007/3-540-46502-2_1; Zaki MJ, 1999, IEEE CONCURR, V7, P14, DOI 10.1109/4434.806975	34	12	12	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-23170-6	LECT NOTES ARTIF INT			2004	3191						1	15				15	Computer Science, Artificial Intelligence	Computer Science	BBA05	WOS:000224361400001		
S	Karkkainen, T; Ayramo, S		Zanasi, A; Ebecken, NFF; Brebbia, CA		Karkkainen, T; Ayramo, S			Robust clustering methods for incomplete and erroneous data	DATA MINING V: DATA MINING, TEXT MINING AND THEIR BUSINESS APPLICATIONS	MANAGEMENT INFORMATION SYSTEMS		English	Proceedings Paper	5th International Conference on Data Mining	SEP 15-17, 2004	Malaga, SPAIN	Wessex Inst Technol			K-MEANS ALGORITHM	In this paper, reliable methods for clustering erroneous and incomplete data per se (e.g. without imputation) are considered. For this purpose, the usual K-means algorithm is generalized by using robust location estimates and special projection technique. Numerical comparison of the resulting methods with simulated data are presented and analyzed.	Univ Jyvaskyla, SF-40351 Jyvaskyla, Finland	Karkkainen, T (reprint author), Univ Jyvaskyla, SF-40351 Jyvaskyla, Finland.						Bandyopadhyay S, 2002, INFORM SCIENCES, V146, P221, DOI 10.1016/S0020-0255(02)00208-6; Barnett V., 1984, OUTLIERS STAT DATA; Bazaraa M. S., 1993, NONLINEAR PROGRAMMIN; Berkhin P, 2002, SURVEY CLUSTERING DA; Bradley P. S., 1998, P 15 INT C MACH LEAR, P91; Duda R.O., 2001, PATTERN CLASSIFICATI; Estivill-Castro V, 2004, DATA MIN KNOWL DISC, V8, P127, DOI 10.1023/B:DAMI.0000015869.08323.b3; ESTIVILLCASTRO V, 2000, HYBRID OPTIMIZATION; Everitt BS, 2001, CLUSTER ANAL; Fayyad U.M., 1996, ADV KNOWLEDGE DISCOV; Han J., 2001, DATA MINING CONCEPTS; Hastie T., 2001, ELEMENTS STAT LEARNI; Huber P., 1981, ROBUST STAT; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Karkkainen T, 2004, NEURAL COMPUT, V16, P837, DOI 10.1162/089976604322860721; Kaufman L., 1990, FINDING GROUPS DATA; Kim W, 2003, DATA MIN KNOWL DISC, V7, P81, DOI 10.1023/A:1021564703268; Lagarias JC, 1998, SIAM J OPTIMIZ, V9, P112, DOI 10.1137/S1052623496303470; Likas A, 2003, PATTERN RECOGN, V36, P451; Little RJA, 1987, STAT ANAL MISSING DA; LU Y, 2004, IN PRESS P 19 ACM S; Makela M., 1992, NONSMOOTH OPTIMIZATI; Pena JM, 1999, PATTERN RECOGN LETT, V20, P1027, DOI 10.1016/S0167-8655(99)00069-0; Rousseeuw P., 1987, ROBUST REGRESSION OU; SMALL CG, 1990, INT STAT REV, V58, P263, DOI 10.2307/1403809; Vardi Y, 2000, P NATL ACAD SCI USA, V97, P1423, DOI 10.1073/pnas.97.4.1423; WAN SJ, 1988, ACM T MATH SOFTWARE, V14, P153, DOI 10.1145/45054.45056; ZHANG B, 2000, 137 HEWL PACK	28	0	0	WIT PRESS	SOUTHAMPTON	ASHURST LODGE, SOUTHAMPTON SO40 7AA, ASHURST, ENGLAND	1470-6326		1-85312-729-9	MANAG INFORMAT SYST			2004	10						101	112				12	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Computer Science	BBO45	WOS:000226691500010		
S	Fernandez-Steeger, TM; Zander, F; Callsen, S; Steinberg, S; Brauns, N		Zanasi, A; Ebecken, NFF; Brebbia, CA		Fernandez-Steeger, TM; Zander, F; Callsen, S; Steinberg, S; Brauns, N			Data mining in publishing: a nice feature or a necessity?	DATA MINING V: DATA MINING, TEXT MINING AND THEIR BUSINESS APPLICATIONS	MANAGEMENT INFORMATION SYSTEMS		English	Proceedings Paper	5th International Conference on Data Mining	SEP 15-17, 2004	Malaga, SPAIN	Wessex Inst Technol				The two distribution channels in the publishing business - retail and subscription - compete against but at the same time complement each other. The following three examples show the importance and potentials of data mining in this stress field. The first example shows a model using Markov chains that will explain the coherence of these units. The other examples show how to estimate the medium lifetime of subscriptions and subsequently the maximum IPO. The last example finally explains how to create test groups for market research by employing supervised clustering and points out the advantages of using this method.	VKG Verlagvertriebs KG Bauer Verlagsgrp, Hamburg, Germany	Fernandez-Steeger, TM (reprint author), VKG Verlagvertriebs KG Bauer Verlagsgrp, Hamburg, Germany.		Fernandez-Steeger, Tomas/G-9467-2011	Fernandez-Steeger, Tomas/0000-0003-1105-6133			CARTER EF, RANDOM WALKS MARKOV; HARTUNGE J, 1999, STAT LEHR HDB ANGEWA, P218; Hastie T, 2001, ELEMENTS STAT LEARNI, P453; POHL S, 2003, DAT MIN STAT HOCHSCH, P157; REICHMANN T, 1997, CONTROLLING KENNZAHL, P237; Tornqvist L, 1936, BANK FINLAND MONTHLY, V10, P1	6	0	0	WIT PRESS	SOUTHAMPTON	ASHURST LODGE, SOUTHAMPTON SO40 7AA, ASHURST, ENGLAND	1470-6326		1-85312-729-9	MANAG INFORMAT SYST			2004	10						253	262				10	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Computer Science	BBO45	WOS:000226691500024		
S	Huang, YZ; O'Brien, DB; Gray, RM		Storer, JA; Cohn, M		Huang, YZ; O'Brien, DB; Gray, RM			Classification of features and images using Gauss mixtures with VQ clustering	DCC 2004: DATA COMPRESSION CONFERENCE, PROCEEDINGS	IEEE DATA COMPRESSION CONFERENCE		English	Proceedings Paper	Data Compression Conference (DCC 2004)	MAR 23-25, 2004	Snowbird, UT	Brandeis Univ, IEEE Comp Soc				Gauss mixture (CM) models are frequently used for their ability to well approximate many densities and for their tractability to analysis. We propose new classification methods built on GM clustering algorithms more often studied and used for vector quantization (VQ). One of our methods is an extension of the 'codebook matching' idea to the specific case of classifying whole images. We apply these methods to a realistic supervised classification problem and empirically evaluate their performances compared with other classification methods.	Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA	Huang, YZ (reprint author), Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA.						Aiyer A, 2001, THESIS STANFORD U; BURTON DK, 1985, IEEE T ACOUST SPEECH, V33, P837, DOI 10.1109/TASSP.1985.1164650; Cover T. M., 1991, ELEMENTS INFORMATION; FRIEDMAN J, 2001, ANN STAT, V39; GRAY RM, 2001, P 2001 IEEE ICIP THE; GRAY RM, 2003, IEEE T INFORM TH MAY, P1204; Hastie T., 2001, ELEMENTS STAT LEARNI; Hoffbeck JP, 1996, IEEE T PATTERN ANAL, V18, P763, DOI 10.1109/34.506799; OBRIEN DB, P ICIP 2003 BARC SPA; OBRIEN DB, ICPIIT 8 C 2003 HOUS; PYUN K, 2002, MULTIMEDIA EXPO 2002, P501; SHIH J, 2001, P 2001 IEEE ICASSP S, P2629; YOON S, DCC 2003; YOUNG C, 2003, THESIS STANFORD U	14	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1068-0314		0-7695-2082-0	IEEE DATA COMPR CONF			2004							13	21				9	Computer Science, Information Systems	Computer Science	BY95C	WOS:000189502800002		
S	Yu, SH; Mehra, RK		Harmon, RS; Broach, JT; Holloway, JH		Yu, SH; Mehra, RK			Regional processing of GPR data in an imperfect world	DETECTION AND REMEDIATION TECHNOLOGIES FOR MINES AND MINELIKE TARGETS IX, PTS 1 AND 2	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Conference on Detection and Remediation Technologies for Mines and Minelike Targets IX	APR 12-16, 2004	Orlando, FL	SPIE		landmine; ATR; PCA; GPR; Gaussian mixtures; support vector machines; regional processing; novelty detection		Designing robust landmine detection algorithms for ground penetrating radar (GPR) remains a challenging task due to variations of environmental conditions and diverse clutter objects in the soil, among others. The problem is aggravated for handheld systems by introducing operator motion and by the position uncertainty. Even though aggregating consecutive GPR samples to form multi-sample features seems to be an intuitively sensible approach to improve Pd/Pf, determining multi-sample features that are robust to the operator motion and position uncertainty is a formidable task. In this paper, we propose an ATR method to identify mines based on handheld GPR data collected for regional processing, where systematic operator motion is required and perhaps some position information is collected along with the data. The regional processing is intended to be conducted after other initial detection methods have identified an area for further interrogation. In this study, we will use GPR data that were collected by a robotic arm. In order for the developed ATR method to be applicable to data collected by human operators, which have greater position uncertainty, we focus on features that can still be used either directly or with minor modification when accurate sensor positions are not available. We tested two classes of classifiers, Support Vector Machines (SVM) and Gaussian Mixtures (GM). For both classifiers, less complex forms of the classifiers outperform those with more complicated structures. The reason is that the training set is relatively small compared to the diversity of the mines and the clutter objects in the training set.	Sci Syst Co Inc, Burlington, MA 01803 USA	Yu, SH (reprint author), Sci Syst Co Inc, 500 W Cummings Pk,Suite 3000, Burlington, MA 01803 USA.						Bar-Shalom Y., 1993, ESTIMATION TRACKING; BHATTACHARJYA AK, 1992, SIGNAL PROCESS, V28, P335, DOI 10.1016/0165-1684(92)90047-Z; Hastie T., 2001, ELEMENTS STAT LEARNI; YU S, 2000, P SPIE, V4038; YU S, 2002, P SPIE, V4742; YU S, 1999, P SPIE, V3710	6	1	1	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		0-8194-5338-2	P SOC PHOTO-OPT INS			2004	5415		1-2				923	932		10.1117/12.543148		10	Instruments & Instrumentation; Physics, Applied; Imaging Science & Photographic Technology	Instruments & Instrumentation; Physics; Imaging Science & Photographic Technology	BBB07	WOS:000224464100093		
S	Agarwal, S; Menon, D; Swonger, CWR		Harmon, RS; Broach, JT; Holloway, JH		Agarwal, S; Menon, D; Swonger, CWR			Knowledge-based architecture for airborne mine and minefield detection	DETECTION AND REMEDIATION TECHNOLOGIES FOR MINES AND MINELIKE TARGETS IX, PTS 1 AND 2	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Conference on Detection and Remediation Technologies for Mines and Minelike Targets IX	APR 12-16, 2004	Orlando, FL	SPIE		airborne mine detection; minefield detection; knowledge-based architecture	CFAR DETECTION	One of the primary lessons learned from airborne mid-wave infrared (MWIR) based mine and minefield detection research and development over the last few years has been the fact that no single algorithm or static detection architecture is able to meet mine and minefield detection performance specifications. This is true not only because of the highly varied environmental and operational conditions under which an airborne sensor is expected to perform but also due to the highly data dependent nature of sensors and algorithms employed for detection. Attempts to make the algorithms themselves more robust to varying operating conditions have only been partially successful. In this paper, we present a knowledge-based architecture to tackle this challenging problem. The detailed algorithm architecture is discussed for such a mine/minefield detection system, with a description of each functional block and data interface. This dynamic and knowledge-driven architecture will provide more robust mine and minefield detection for a highly multi-modal operating environment. The acquisition of the knowledge for this system is predominantly data driven, incorporating not only the analysis of historical airborne mine and minefield imagery data collection, but also other "all source data" that may be available such as terrain information and time of day. This "all source data" is extremely important and embodies causal information that drives the detection performance. This information is not being used by current detection architectures. Data analysis for knowledge acquisition will facilitate better understanding of the factors that affect the detection performance and will provide insight into areas for improvement for both sensors and algorithms. Important aspects of this knowledge-based architecture, its motivations and the potential gains from its implementation are discussed, and some preliminary results are presented.	Engn Res Lab 304, Rolla, MO 65401 USA	Agarwal, S (reprint author), Engn Res Lab 304, Rolla, MO 65401 USA.						AGARWAL S, 2003, NVESD AITR M FEB 14; Brodley C. E., 1993, P 10 INT C MACH LEAR, P17; EARP SL, 1995, P SOC PHOTO-OPT INS, V2496, P543, DOI 10.1117/12.211350; GRAF HP, 1997, IEEE C COMP CYB SIM, V3, P2034; Hastie T., 2001, ELEMENTS STAT LEARNI; HOLMES QA, 1995, P SOC PHOTO-OPT INS, V2496, P421, DOI 10.1117/12.211339; Liao WJ, 2001, P SOC PHOTO-OPT INS, V4394, P310, DOI 10.1117/12.445482; Malloy N., 2003, LINEAR PATTERN DETEC; MENON D, 2003, USER MANUAL      APR; MENON D, 2004, P SPIE DET TECHN MIN; MERZ CJ, LEARNING DATA ARTIFI; NIETEN J, 1993, P SOC PHOTO-OPT INS, V1963, P31, DOI 10.1117/12.141752; NOVE CA, 1999, P SPIE NOND EV AG MA, V3585, P154, DOI 10.1117/12.339843; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; REED IS, 1990, IEEE T ACOUST SPEECH, V38, P1760, DOI 10.1109/29.60107; SRIRAM P, 2002, P SPIE DET TECHN MIN, V4742; SWONGER CWR, 2002, AIRBORNE MINE MINEFI; SWONGER CWR, 2003, AIRB ALG WORKSH 29 J; SWONGER CWR, MINE VS NONMINE FEAT; Yitzhaky Y, 2003, IEEE T PATTERN ANAL, V25, P1027, DOI 10.1109/TPAMI.2003.1217608	20	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		0-8194-5338-2	P SOC PHOTO-OPT INS			2004	5415		1-2				1174	1184		10.1117/12.544719		11	Instruments & Instrumentation; Physics, Applied; Imaging Science & Photographic Technology	Instruments & Instrumentation; Physics; Imaging Science & Photographic Technology	BBB07	WOS:000224464100117		
S	Chu, F; Wang, YZ; Zaniolo, C		Suzuki, E; Arikawa, S		Chu, F; Wang, YZ; Zaniolo, C			Mining noisy data streams via a discriminative model	DISCOVERY SCIENCE, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	7th International Conference on Discovery Science	OCT 02-05, 2004	Padova, ITALY		Univ Padova	data mining; discriminative modelling; robust statistics; logistic regression		The two main challenges typically associated with mining data streams are concept drift and data contamination. To address these challenges, we seek learning techniques and models that are robust to noise and can adapt to changes in timely fashion. In this paper, we approach the stream-mining problem using a statistical estimation framework, and propose a discriminative model for fast mining of noisy data streams. We build an ensemble of classifiers to achieve adaptation by weighting classifiers in a way that maximizes the likelihood of the data. We further employ robust statistical techniques to alleviate the problem of noise sensitivity. Experimental results on both synthetic and real-life data sets demonstrate the effectiveness of this new discriminative model.	Univ Calif Los Angeles, Los Angeles, CA 90095 USA	Chu, F (reprint author), Univ Calif Los Angeles, Los Angeles, CA 90095 USA.						AGGARWAL C, 2001, INT C MAN DAT SIGM; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BILMES J.A., 1998, ICSITR97021; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BRODLEY C, 1996, ARTIF INTELL, P779; BRUENIG M, 2002, INT C MAN DAT SIGM; DOMENICONI C, 2001, INT C DAT MIN ICDM; HASTIE T., 2000, ELEMENTS STAT LEARNI; HULTEN G, 2001, INT C KNOWL DISC DAT; Kolter J., 2001, INT C DAT MIN ICDM; KUBICA J, 2003, INT C DAT MIN ICDM; Oza Nikunj C., 2001, ARTIF INTELL, P105; RAMASWAMY S, 2000, INT C MAN DAT SIGM; Schlimmer J. C., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; STOLFO S, 1997, AAAI97 WORKSH FRAUD; Street W., 2001, INT C KNOWL DISC DAT; Wang H., 2003, INT C KNOWL DISC DAT; Widmer G, 1996, MACH LEARN, V23, P69, DOI 10.1007/BF00116900	18	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-23357-1	LECT NOTES COMPUT SC			2004	3245						47	59				13	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BBB88	WOS:000224608200004		
S	Ohara, K; Onishi, Y; Babaguchi, N; Motoda, H		Suzuki, E; Arikawa, S		Ohara, K; Onishi, Y; Babaguchi, N; Motoda, H			Constructive inductive learning based on meta-attributes	DISCOVERY SCIENCE, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	7th International Conference on Discovery Science	OCT 02-05, 2004	Padova, ITALY		Univ Padova			Constructive Inductive Learning, CIL, aims at learning more accurate or comprehensive concept descriptions by generating new features from the basic features initially given. Most of the existing CIL systems restrict the kinds of functions that can be applied to construct new features, because the search space of feature candidates can be very large. However, so far, no constraint has been applied to combining the basic features. This leads to generating many new but meaningless features. To avoid generating such meaningless features, in this paper, we introduce meta-attributes into CIL, which represent domain knowledge about basic features and allow to eliminate meaningless features. We also propose a Constructive Inductive learning system using Meta-Attributes, CIMA, and experimentally show it can significantly reduce the number of feature candidates.	Osaka Univ, ISIR, Osaka 5670047, Japan; Osaka Univ, Grad Sch Engn, Suita, Osaka 5650871, Japan	Ohara, K (reprint author), Osaka Univ, ISIR, 8-1 Mihogaoka, Osaka 5670047, Japan.	ohara@ar.sanken.osaka-u.ac.jp; babaguchi@comm.eng.osaka-u.ac.jp; motoda@ar.sanken.osaka-u.ac.jp					BENSUASAN H, 1996, P ICML 96 WORKSH EV; Blake C.L., 1998, UCI REPOSITORY MACHI; Hastie T., 2001, ELEMENTS STAT LEARNI; Hu YJ, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P806; Kramer S, 2001, RELATIONAL DATA MINING, P262; KRAWIEC K, 2000, RA0062000 POZN U TEC; Markovitch S, 2002, MACH LEARN, V49, P59, DOI 10.1023/A:1014046307775; Michalski R.S., 1978, 927 U ILL DEP COMP S; MICHALSKI RS, 1983, ARTIF INTELL, V20, P111, DOI 10.1016/0004-3702(83)90016-4; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; Quinlan J., 1992, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1995, NEW GENERAT COMPUT, V13, P287	12	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-23357-1	LECT NOTES COMPUT SC			2004	3245						142	154				13	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BBB88	WOS:000224608200011		
J	Feng, ZD; Yasui, Y				Feng, ZD; Yasui, Y			Statistical considerations in combining biomarkers for disease classification	DISEASE MARKERS			English	Article							PROSTATE-CANCER; OVARIAN-CANCER; SERUM; DISCOVERY; ALGORITHM		Fred Hutchinson Canc Res Ctr, Div Publ Hlth Sci, Seattle, WA 98109 USA	Feng, ZD (reprint author), Fred Hutchinson Canc Res Ctr, Div Publ Hlth Sci, 1124 Columbia St, Seattle, WA 98109 USA.						Adam BL, 2002, CANCER RES, V62, P3609; Baker SG, 2000, BIOMETRICS, V56, P1082, DOI 10.1111/j.0006-341X.2000.01082.x; Bellman R., 1961, ADAPTIVE CONTROL PRO; Efron Bradley, 1993, INTRO BOOTSTRAP; EGAN JP, 1975, SIGNAL DETECTION THE; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; GREEN DM, 1966, SIGNAL DETECTION THE; Hastie T., 2001, ELEMENTS STAT LEARNI; McIntosh MW, 2002, BIOMETRICS, V58, P657, DOI 10.1111/j.0006-341X.2002.00657.x; Pepe MS, 2003, STAT EVALUATION MED; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Qu YS, 2002, CLIN CHEM, V48, P1835; Rai AJ, 2002, ARCH PATHOL LAB MED, V126, P1518; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; STONE M, 1974, J R STAT SOC B, V36, P111; Yasui Y, 2003, BIOSTATISTICS, V4, P449, DOI 10.1093/biostatistics/4.3.449; YASUI Y, 2002, UW BIOSTATISTICS WOR; Yasui Y, 2003, J BIOMED BIOTECHNOL, P242	19	4	6	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0278-0240			DIS MARKERS	Dis. Markers		2004	20	2					45	51				7	Biotechnology & Applied Microbiology; Genetics & Heredity; Medicine, Research & Experimental; Pathology	Biotechnology & Applied Microbiology; Genetics & Heredity; Research & Experimental Medicine; Pathology	852EW	WOS:000223739000002	15322313	
S	Vilalta, R; Achari, M; Eick, CE		LopezdeMantaras, R; Saitta, L		Vilalta, R; Achari, M; Eick, CE			Piece-wise model fitting using local data patterns	ECAI 2004: 16TH EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE, PROCEEDINGS	FRONTIERS IN ARTIFICIAL INTELLIGENCE AND APPLICATIONS		English	Proceedings Paper	16th European Conference on Artificial Intelligence	AUG 22-27, 2004	Valencia, SPAIN	European Coordinating Comm Artificial Intelligence, Asoc Espanola Inteligencia Artificial, Assoc Catalana Intelligencia Artificial, Univ Politecn Valencia, Grp Tecnol Informat			ALGORITHMS	In this paper we propose a novel classification algorithm that fits models of different complexity on separate regions of the input space. Our goal is to achieve a balance between global and local learning strategies by decomposing the classification task into simpler subproblems; each task narrows the learning problem to a local region of high example density over the input space. Specifically, our proposed approach is to apply a clustering algorithm to every set of training examples that belong to the same class; each cluster becomes an intermediate concept that is learned by selecting a model with an (estimated) optimal degree of complexity. Experimental results on real-world domains show consistent good performance in predictive accuracy with our piece-wise model fitting strategy.	Univ Houston, Dept Comp Sci, Houston, TX 77204 USA	Vilalta, R (reprint author), Univ Houston, Dept Comp Sci, 4800 Calhoun Rd, Houston, TX 77204 USA.						Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; BLUMER A, 1989, J ACM, V36, P929, DOI 10.1145/76359.76371; BOTTOU L, 1992, NEURAL COMPUT, V4, P888, DOI 10.1162/neco.1992.4.6.888; GEMAN S, 1992, NEURAL COMPUT, P1; Hastie T., 2001, ELEMENTS STAT LEARNI; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; Kearns M. J., 1994, INTRO COMPUTATIONAL; Lewis P. M., 1959, INFORM CONTR, V2, P214, DOI 10. 1016/S0019-9958(59)90207-4; McLachlan GJ, 1997, EM ALGORITHM EXTENSI; Mitchell T., 1997, MACHINE LEARNING; VAPNIK V, 1993, NEURAL COMPUT, V5, P893, DOI 10.1162/neco.1993.5.6.893; VAPNIK V, 1999, NATURE STATE LEARNIN; VILALTA R, 2003, EUR C MACH LEARN, P444; VILALTA R, 2003, IEEE 3 INT C DAT MIN, P673; Witten IH, 2000, DATA MINING PRACTICA	16	0	0	I O S PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0922-6389		1-58603-452-9	FR ART INT			2004	110						559	563				5	Computer Science, Artificial Intelligence	Computer Science	BBH24	WOS:000225505100109		
S	Johansson, J; Treloar, R; Jern, M		Banissi, E; Borner, K; Chen, C; Dastbaz, M; Clapworthy, G; Faiola, A; Izquierdo, E; Maple, C; Roberts, J; Moore, C; Ursyn, A; Zhang, JJ		Johansson, J; Treloar, R; Jern, M			Integration of unsupervised clustering, enteraction and parallel coordinates for the exploration of large multivariate data	EIGHTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS	IEEE CONFERENCE ON INFORMATION VISUALIZATION - PROCEEDINGS		English	Proceedings Paper	8th International Conference on Information Visualisation	JUL 14-16, 2004	London, ENGLAND			parallel coordinates; unsupervised clustering; linked views; interactive visualization		Parallel coordinates are widely used in many applications for visualization of multivariate data. Because of the nature of parallel coordinates, the visualization technique is often used for data overview. However when the number of tuples to be visualized becomes very large, this technique makes it difficult to distinguish the overall structure. In this paper we present a novel technique which uses a classification approach, the self-organizing map (an unsupervised learning algorithm), to solve this problem by creating an initial clustering of the data. By initially only visualizing the resulting representational clusters, the inherited global structure can be shown. Using linked views and allowing the user to perform drill-down and filtering on these representations reveals the single data items without loss of context.	Linkoping Univ, S-58183 Linkoping, Sweden	Johansson, J (reprint author), Linkoping Univ, S-58183 Linkoping, Sweden.						BRODBECK D, 2003, IEEE INT C COORD MUL; BUJA A, 1991, IEEE VISUALIZATION, P156; Fua Y.-H., 1999, IEEE VISUALIZATION, P43; Graham M., 2001, IEEE 5 INT C INF VIS, P425; Hastie T., 2001, ELEMENTS STAT LEARNI; Inselberg A., 1990, IEEE VISUALIZATION, P361; Kaski S., 1997, THESIS HELSINKI U TE; Kohonen T, 1997, SELF ORG MAPS; LEUNG Y, 1994, ACM T HUM INT, P126; MACKINLAY JD, 1995, C HUM FACT COMP SYST, P173; MUKHERJEA S, 1995, ACM SIGCHI C HUM FAC, P331; North C, 2000, ADV VISUAL INTERFACE, P128; SIIRTOLA H, 2002, IEEE 6 INT C INF VIS, P373; VESANTO J, 2000, IEEE NEUR NETW, P586; Wang Baldonado M.Q., 2000, ADV VISUAL INTERFACE, P110; Wong PC, 1996, IEEE VISUAL, P141	16	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1093-9547		0-7695-2177-0	IEEE INFOR VIS			2004							52	57				6	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering	Computer Science	BAQ15	WOS:000223198000008		
S	Crossan, A; Williamson, J; Murray-Smith, R		Banissi, E; Borner, K; Chen, C; Dastbaz, M; Clapworthy, G; Faiola, A; Izquierdo, E; Maple, C; Roberts, J; Moore, C; Ursyn, A; Zhang, JJ		Crossan, A; Williamson, J; Murray-Smith, R			Haptic granular synthesis: Targeting, visualisation and texturing	EIGHTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS	IEEE CONFERENCE ON INFORMATION VISUALIZATION - PROCEEDINGS		English	Proceedings Paper	8th International Conference on Information Visualisation	JUL 14-16, 2004	London, ENGLAND					This paper introduces the idea of haptic rendering using granular synthesis - an established technique for synthesising audio. It describes the technique along with potential application areas, and initial results from an implementation on a PHANToM force feedback device. Three main applications are considered. Firstly, rendering of probabilistic vector fields for presenting ambiguity and context information to the user. Secondly, the possibility of producing textured virtual objects using granular synthesis is discussed. Thirdly, we use the approach to display scatterplot data on haptic devices.	Natl Univ Ireland, Hamilton Inst, Maynooth, Kildare, Ireland	Crossan, A (reprint author), Natl Univ Ireland, Hamilton Inst, Maynooth, Kildare, Ireland.						BARRETT RC, 1995, P ACM C HUM FACT COM, P316; Bensmaia SJ, 2000, J ACOUST SOC AM, V108, P1236, DOI 10.1121/1.1288937; FITZA JP, 1996, P SPIE INT S INT SYS; Hastie T., 2001, ELEMENTS STAT LEARNI; JAGACINSKI RJ, 2003, CONTROL THOERY HUMAN; JONSSON G, 1998, EUR C DIS SWED, P105; Massie Thomas H., 1994, P ASME WINT ANN M S; MCGEE MR, 2002, COMPUTING SCI; Roads C, 2001, MICROSOUND; TITTERINGTON DM, 1985, STAT ANAL FINITE MIX; VANSCOY F, 2000, LECT NOTES COMPUT SC, V2058, P31; WALL SA, P ACM CHI 2003; WILLIAMSON J, 2004, INT WORKSH INT SON G; WILLIAMSON J, 2003, TR2003147 DCS GLASGW; Xenakis I., 1971, FORMALIZED MUSIC THO; Yu W, 2003, J UNIVERSAL ACCESS I, V2, P105	16	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1093-9547		0-7695-2177-0	IEEE INFOR VIS			2004							527	532				6	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering	Computer Science	BAQ15	WOS:000223198000079		
S	Reis, MS; Saraiva, PM		BarbosaPovoa, AP; Matos, H		Reis, MS; Saraiva, PM			Accounting for measurement uncertainties in industrial data analysis	EUROPEAN SYMPOSIUM ON COMPUTER-AIDED PROCESS ENGINEERING - 14	COMPUTER-AIDED CHEMICAL ENGINEERING		English	Proceedings Paper	14th European Symposium on Computer Aided Process Engineering (ESCAPE-14)	MAY 16-19, 2004	Lisbon, PORTUGAL					This paper addresses the issue of integrating measurement uncertainty information in data analysis, namely in parametric and non-parametric regression. Several existent and new approaches will be presented here and critically accessed regarding their prediction and parameter estimation ability, under different scenarios. The results show that methods which explicitly incorporate measurement uncertainty information are quite sound and promising but do not always outperform other simpler approaches.	Univ Coimbra, Dept Chem Engn, GEPSI PSE Grp, P-3030290 Coimbra, Portugal	Reis, MS (reprint author), Univ Coimbra, Dept Chem Engn, GEPSI PSE Grp, Polo II Pinhal Marrocos, P-3030290 Coimbra, Portugal.						Draper NR, 1998, APPL REGRESSION ANAL; Hastie T., 2001, ELEMENTS STAT LEARNI; *ISO, 1993, GUIDE EXPRESSION UNC; MARTINEZ A, 2002, J CHEMOMETR, P16; WENTZELL PD, 1997, ANAL CHEM, V69	5	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1570-7946		0-444-51694-8	COMP AID CH			2004	18						751	756				6	Computer Science, Interdisciplinary Applications; Engineering, Chemical; Engineering, Manufacturing	Computer Science; Engineering	BBL83	WOS:000226030600112		
S	Kostuch, P; Socha, K		Gottlieb, J; Raidl, GR		Kostuch, P; Socha, K			Hardness prediction for the University Course Timetabling Problem	EVOLUTIONARY COMPUTATION IN COMBINATORIAL OPTIMIZATION, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	4th European Conference on Evolutionary Computation in Combinatorial Optimization	APR 05-07, 2004	Coimbra, PORTUGAL	EvoNet, Univ Coimbra				This paper presents an attempt to find a statistical model that predicts the hardness of the University Course Timetabling Problem by analyzing instance properties. The model may later be used for better understanding what makes a particular instance hard. It may also be used for tuning the algorithm actually solving that problem instance. The paper introduces the definition of hardness, explains the statistical approach used for modeling instance hardness, as well as presents results obtained and possible ways of exploiting them.	Univ Oxford, Dept Stat, Oxford OX1 3TG, England; Free Univ Brussels, IRIDIA, B-1050 Brussels, Belgium	Kostuch, P (reprint author), Univ Oxford, Dept Stat, 1 S Pk Rd, Oxford OX1 3TG, England.	kostuch@stats.ox.ac.uk; ksocha@ulb.ac.be					Davidian M., 1995, NONLINEAR MODELS REP; Dorigo M., 1999, NEW IDEAS OPTIMIZATI; Hastie T., 2001, ELEMENTS STAT LEARNI; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; KOSTUCH P, 2003, THESIS OXFORD U ENGL; MANIEZZO V, 2001, ESSAYS SURVEYS METAH; McCullagh P., 1989, GEN LINEAR MODELS; Neter J., 1990, APPL LINEAR STAT MOD; Roli A., 2001, P MIC 2001 MET INT C, V1, P187; ROSSIDORIA O, 2003, P PATAT 2002, V2740; SOCHA K, 2003, TRIRIDIA200330 U LIB; Stutzle T, 2000, FUTURE GENER COMP SY, V16, P889, DOI 10.1016/S0167-739X(00)00043-1; Venables WN, 1999, MODERN APPL STAT S P	13	6	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-21367-8	LECT NOTES COMPUT SC			2004	3004						135	144				10	Computer Science, Theory & Methods	Computer Science	BY95A	WOS:000189502600014		
J	Zhou, BZ; Hatherly, P				Zhou, Binzhong; Hatherly, Peter			Coal seismic depth conversion for mine data integration: A case study from the Sandy Creek 3D seismic survey	EXPLORATION GEOPHYSICS			English	Article						coal seismic data; depth conversion; data integration		When seismic data are presented as two-way reflection times, these times are not easily directly scalable to depths, because of spatial variations of seismic velocity. Apparent structures in the time domain can be misleading. Correct conversion of seismic time sections to depth sections removes this ambiguity. In general, seismic depth conversion is a complex process requiring careful use of NMO and migration velocities, the study of well data, and the generation of synthetic seismograms. The process is usually iterative, especially when the structures are complex. In this paper, we present a depth-conversion algorithm designed for coal seismic data. Our method exploits the relatively simple structure of coal seams and the availability of many exploration boreholes to constrain the process. Once converted to depth, the seismic data can be exported into mine-planning software and used to provide seam elevations for tasks such as in-seam drilling and other mine activities. Our method has been implemented into an MS Windows-based program, and allows new boreholes to be incorporated without the need to go back to a seismic processing centre. A 3D seismic data set from Xstrata's Sandy Creek coal mine is used to demonstrate our method. The results show that the depth-conversion algorithm can accommodate differences in seismic processing. The depth-converted seismic data agrees with the geological model based on the borehole results and underground mine surveys. Given confidence in the depth conversion, it is possible to look more closely into the seismic data in order to make interpretations that are more detailed.	[Zhou, Binzhong] CSIRO Explorat & Min, CRC Min, Kenmore, Qld 4069, Australia; [Hatherly, Peter] Univ Sydney, Sch Geosci, CRC Min, Sydney, NSW 2006, Australia	Zhou, BZ (reprint author), CSIRO Explorat & Min, CRC Min, POB 883, Kenmore, Qld 4069, Australia.	Binzhong.Zhou@csiro.au; phatherly@geosci.usyd.edu.au			Australian Coal Association Research Program (ACARP) [C11038]; CRC Mining and CSIRO Exploration and Mining	This work was based on project C11038 (Zhou et al., 2004) which was funded by the Australian Coal Association Research Program (ACARP). Additional funding was provided by CRC Mining and CSIRO Exploration and Mining. The data used in this paper were provided by Gary Fallon and Diane Sommer, both formerly of Xstrata. Their interest in this work is acknowledged. Andrew Willson of Anglocoal Australia provided a useful review of the report to ACARP. Renate Sliwa of CEM is thanked for her help in picking the horizons for the 3D seismic volume.	AlChalabi M, 1997, GEOPHYS PROSPECT, V45, P715, DOI 10.1046/j.1365-2478.1997.520293.x; Al-Chalabi M., 1979, DEV GEOPHYSICAL EXPL, V1, P1; Armstrong T, 2001, GEOPHYS PROSPECT, V49, P79, DOI 10.1046/j.1365-2478.2001.00238.x; BLACKBURN G, 1980, GEOPHYSICS, V45, P1465, DOI 10.1190/1.1441043; GERRITSMA PHA, 1977, GEOPHYSICS, V42, P760, DOI 10.1190/1.1440744; Hastie T., 2001, ELEMENTS STAT LEARNI; Hubral P., 1977, Geophysical Prospecting, V25, DOI 10.1111/j.1365-2478.1977.tb01200.x; KEYDAR S, 1989, GEOPHYSICS, V54, P1001, DOI 10.1190/1.1442724; Robein E., 2003, TIME IMAGING DEPTH I; Thore P, 2002, GEOPHYSICS, V67, P840, DOI 10.1190/1.1484528; WHITCOMBE DN, 1994, GEOPHYSICS, V59, P439, DOI 10.1190/1.1443606; Yilmaz O., 2001, SEISMIC DATA ANAL PR; Yilmaz O., 2001, Geophysics, V66, DOI 10.1190/1.1487112; Zhou B., 2003, PREVIEW, V105, P25; Zhou B., 2004, INTEGRATION SE UNPUB	15	1	1	CSIRO PUBLISHING	COLLINGWOOD	150 OXFORD ST, PO BOX 1139, COLLINGWOOD, VICTORIA 3066, AUSTRALIA	0812-3985			EXPLOR GEOPHYS	Explor. Geophys.		2004	35	4					324	330		10.1071/EG04324		7	Geochemistry & Geophysics	Geochemistry & Geophysics	V24GJ	WOS:000208398600017		
B	Kukar, M		Rastogi, R; Morik, K; Bramer, M; Wu, X		Kukar, M			Transduction and typicalness for quality assessment of individual classifications in machine learning and data mining	FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS			English	Proceedings Paper	4th IEEE International Conference on Data Mining	NOV 01-04, 2004	Brighton, ENGLAND	IEEE Comp Soc, TCCI, IEEE Comp Soc, TCPAMI, IBM Res, StatSoft Ltd, Web Intelligence Consortium		machine learning; confidence estimation; typicalness; transduction; quality assessment		In the past machine learning algorithms have been successfully used in many problems, and are emerging as valuable data analysis tools. However, their serious practical use is affected by the fact, that more often than not, they cannot produce reliable and unbiased assessments of their predictions' quality. In last years, several approaches for estimating reliability or confidence of individual classifiers have emerged, many of them building upon the algorithmic theory of randomness, such as (historically ordered) transduction-based confidence estimation, typicalness-based confidence estimation, and transductive reliability estimation. Unfortunately, they all have weaknesses: either they are tightly bound with particular learning algorithms, or the interpretation of reliability estimations is not always consistent with statistical confidence levels. In the paper we propose a joint approach that compensates the mentioned weaknesses by integrating typicalness-based confidence estimation and transductive reliability estimation into joint confidence machine. The resulting confidence machine produces confidence values in the statistical sense (e.g., a confidence level of 95% means that in 95% the predicted class is also a true class), as well as provides us with a general principle that is independent of to the particular underlying classifier We perform a series of tests with several different machine learning algorithms in several problem domains. We compare our results with that of a proprietary TCM-NN method as well as with kernel density estimation. We show that the proposed method significantly outperforms density estimation methods, and how it may be used to improve their performance.	Univ Ljubljana, Fac Comp & Informat Sci, SI-1001 Ljubljana, Slovenia	Kukar, M (reprint author), Univ Ljubljana, Fac Comp & Informat Sci, Trzaska 25, SI-1001 Ljubljana, Slovenia.						BAY SD, 2000, P 17 INT C MACH LEAR, P49; Gibbs AL, 2002, INT STAT REV, V70, P419, DOI 10.2307/1403865; HALCK OM, 2002, P 13 EUR C MACH LEAR, P124; Hastie T., 2001, ELEMENTS STAT LEARNI; HO SS, 2003, P INT J C NEUR NETW; Kononenko I, 1997, APPL INTELL, V7, P39, DOI 10.1023/A:1008280620621; KONONENKO I., 1991, P 6 EUR WORK SESS LE, P206; Kukar M., 2002, P MACH LEARN ECML 20, P219; KUKAR M, 2003, ARTIF INTELL MED, P81; Langley P., 1995, P 11 C UNC ART INT M; MELLUISH T, 2001, P ECML 2001, V2164, P350; Nouretdinov I., 2001, P 18 INT C MACH LEAR, P385; Pfahringer B., 2000, P 17 INT C MACH LEAR; Proedru K., 2002, P 13 EUR C MACH LEAR, p[381, 2002]; RUMELHART DE, 1986, PARALLED DISTRIBUTED; SAUNDERS C, 1909, P INT JOINT C ART IN; SAUNDERS C, 2000, ALGORITHMIC LEARNING, V1968, P325, DOI 10.1007/3-540-40992-0_25; Seewald A. K., 2001, P 4 INT S ADV INT DA, P115; SMYTH P, 1995, P 12 INT C MACH LEAR, P506; SPECHT DF, 1994, P IEEE INT C NEUR NE; VENABLES WN, 2002, MODERN APPL STAT SPL; Wand MP, 1995, KERNEL SMOOTHING	22	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2142-8				2004							146	153		10.1109/ICDM.2004.10089		8	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BBI95	WOS:000225713000019		
B	Staiano, A; De Vinco, L; Ciaramella, A; Raiconi, G; Tagliaferri, R; Amato, R; Longo, G; Donalek, C; Miele, G; Di Bernardo, D		Rastogi, R; Morik, K; Bramer, M; Wu, X		Staiano, A; De Vinco, L; Ciaramella, A; Raiconi, G; Tagliaferri, R; Amato, R; Longo, G; Donalek, C; Miele, G; Di Bernardo, D			Probabilistic principal surfaces for yeast gene microarray data mining	FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS			English	Proceedings Paper	4th IEEE International Conference on Data Mining	NOV 01-04, 2004	Brighton, ENGLAND	IEEE Comp Soc, TCCI, IEEE Comp Soc, TCPAMI, IBM Res, StatSoft Ltd, Web Intelligence Consortium			SELF-ORGANIZING MAPS; EXPRESSION; PATTERNS	The recent technological advances are producing huge data sets in almost all fields of scientific research, from astronomy to genetics. Although each research field often requires ad-hoc, fine tuned, procedures to properly exploit all the available information inherently present in the data, there is an urgent need for a new generation of general computational theories and tools capable to boost most human activities of data analysis. Here we propose Probabilistic Principal Surfaces (PPS) as an effective high-D data visualization and clustering, tool for data mining applications, emphasizing its flexibility and generality of use in data-rich field. In order to better illustrate the potentialities of the method, we also provide a real world case-study by discussing the use of PPS for the analysis of yeast gene expression levels from microarray chips.	Univ Salerno, Dipartimento Matemat & Informat, I-84084 Fisciano, Sa, Italy	Staiano, A (reprint author), Univ Salerno, Dipartimento Matemat & Informat, Via Ponte Don Melillo, I-84084 Fisciano, Sa, Italy.		di Bernardo, Diego/I-9440-2012	di Bernardo, Diego/0000-0002-1911-7407			Bezdek J.C., 1999, FUZZY MODELS ALGORIT; BISHOP C, 1998, NEURAL COMPUTATION; CHANG K, 2001, IEEE T PATTERN ANAL, V23; CHANG K, 2000, THESIS U TEXAS AUSTI; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Hastie T., 2001, ELEMENTS STAT LEARNI; Kohonen T., 1995, SELF ORGANIZING MAPS; Nabney I. T., 2002, NETLAB ALGORITHMS PA; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; STAIANO A, 2003, THESIS U SALERNO ITA; Tagliaferri R, 1999, ASTRON ASTROPHYS SUP, V137, P391, DOI 10.1051/aas:1999254; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Toronen P, 1999, FEBS LETT, V451, P142, DOI 10.1016/S0014-5793(99)00524-4	13	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2142-8				2004							202	208		10.1109/ICDM.2004.10088		7	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BBI95	WOS:000225713000026		
B	Wu, G; Chang, EY		Rastogi, R; Morik, K; Bramer, M; Wu, X		Wu, G; Chang, EY			Aligning boundary in kernel space for learning imbalanced dataset	FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS			English	Proceedings Paper	4th IEEE International Conference on Data Mining	NOV 01-04, 2004	Brighton, ENGLAND	IEEE Comp Soc, TCCI, IEEE Comp Soc, TCPAMI, IBM Res, StatSoft Ltd, Web Intelligence Consortium			MACHINES	An imbalanced training dataset poses serious problem for many real-world supervised learning tasks. In this paper, we propose a kernel-boundary-alignment algorithm, which considers training-data imbalance as prior information to augment SVMs to improve class-prediction accuracy. Using a simple example, we first show that SVMs can suffer from high incidences of false negatives when the training instances of the target class are heavily outnumbered by the training instances of a non-target class. The remedy we propose is to adjust the class boundary by modifying the kernel matrix, according to the imbalanced data distribution. Through theoretical analysis backed by empirical study, we show that our kernel-boundary-alignment algorithm works effectively on several datasets.	Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA	Wu, G (reprint author), Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.						Amari S, 1999, NEURAL NETWORKS, V12, P783, DOI 10.1016/S0893-6080(99)00032-5; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Burges CJC, 1999, ADVANCES IN KERNEL METHODS, P89; CHAN P, 1998, WORKSH NOTES KDD 98, P1; Chang E, 2003, IEEE T CIRC SYST VID, V13, P26, DOI 10.1109/TCSVT.2002.808079; CHAWLA N, 2000, INT C KNOWL BAS COMP; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Fawcett T, 1997, DATA MIN KNOWL DISC, V1, P291, DOI 10.1023/A:1009700419189; Fukunaga K, 1990, INTRO STAT PATTERN R; Hastie T., 2001, ELEMENTS STAT LEARNI; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Kandola J, 2003, P 9 INT WORKSH ART I; KARAKOULAS G, 1999, ADV NEURAL INFORMATI; Kubat M., 1997, P 14 INT C MACH LEAR, P179; KUHN HW, 1961, NON LINEAR PROGRAMMI; Lin Y, 2002, MACH LEARN, V46, P191, DOI 10.1023/A:1012406528296; Nugroho AS, 2002, IEICE T INF SYST, VE85D, P1165; SCHOLKOPF B, 2002, LEARNING KERNLES SUP; Shawe-Taylor J., 2002, J MACHINE LEARNING R, VI; Veropoulos K., 1999, P INT JOINT C ART IN, P55; Weiss G.M., 2001, MLTR44 RUTG U DEP CO; WU G, 2003, ACM INT C MULT NOV; Wu G., 2003, P 20 INT C MACH LEAR, P816; WU G, 2004, KERNEL BOUNDARY ALIG	25	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2142-8				2004							265	272				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BBI95	WOS:000225713000034		
B	Chu, F; Wang, YZ; Zaniolo, C		Rastogi, R; Morik, K; Bramer, M; Wu, X		Chu, F; Wang, YZ; Zaniolo, C			An adaptive learning approach for noisy data streams	FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS			English	Proceedings Paper	4th IEEE International Conference on Data Mining	NOV 01-04, 2004	Brighton, ENGLAND	IEEE Comp Soc, TCCI, IEEE Comp Soc, TCPAMI, IBM Res, StatSoft Ltd, Web Intelligence Consortium				Two critical challenges typically associated with mining data streams are concept drift and data contamination. To address these challenges, we seek learning techniques and models that are robust to noise and can adapt to changes in timely fashion. We approach the stream-mining problem using a statistical estimation framework, and propose a fast and robust discriminative model for learning noisy data streams. We build an ensemble of classifiers to achieve timely adaptation by weighting classifiers in a way that maximizes the likelihood of the data. We further employ robust statistical techniques to alleviate the problem of noise sensitivity. Experimental results on both synthetic and real-life data sets demonstrate the effectiveness of this new model learning approach.	Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA	Chu, F (reprint author), Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA.						Bilmes J., 1998, TR97021 ICSI; CHU F, 2004, 040029 UCLA COMP SCI; HASTIE T., 2000, ELEMENTS STAT LEARNI; Street W., 2001, INT C KNOWL DISC DAT; Wang H., 2003, INT C KNOWL DISC DAT	5	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2142-8				2004							351	354				4	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BBI95	WOS:000225713000049		
J	Zamboni, N; Sauer, U				Zamboni, N; Sauer, U			Model-independent fluxome profiling from H-2 and C-13 experiments for metabolic variant discrimination	GENOME BIOLOGY			English	Article							CENTRAL CARBON METABOLISM; BACILLUS-SUBTILIS; FUNCTIONAL GENOMICS; ESCHERICHIA-COLI; COMPONENT ANALYSIS; MASS-SPECTROMETRY; GLYCOLYTIC GENES; AMINO-ACIDS; MUTANTS; PATHWAY	We introduce a conceptually novel method for intracellular fluxome profiling from unsupervised statistical analysis of stable isotope labeling. Without a priori knowledge on the metabolic system, we identified characteristic flux fingerprints in 10 Bacillus subtilis mutants from 132 H-2 and C-13 tracer experiments. Beyond variant discrimination, independent component analysis automatically mapped several fingerprints to their metabolic determinants. The approach is flexible and paves the way to large-scale fluxome profiling of any biological system and condition.	ETH, Inst Biotechnol, CH-8093 Zurich, Switzerland	Sauer, U (reprint author), ETH, Inst Biotechnol, CH-8093 Zurich, Switzerland.	sauer@biotech.biol.ethz.ch					Allen J, 2003, NAT BIOTECHNOL, V21, P692, DOI 10.1038/nbt823; Bailey JE, 1999, NAT BIOTECHNOL, V17, P616, DOI 10.1038/10794; Brown GD, 2001, TRENDS NEUROSCI, V24, P54, DOI 10.1016/S0166-2236(00)01683-0; Dauner M, 2001, J BACTERIOL, V183, P7308, DOI 10.1128/JB.183.24.7308-7317.2001; Doan T, 2003, MOL MICROBIOL, V47, P1709, DOI 10.1046/j.1365-2958.2003.03404.x; Duetz WA, 2000, APPL ENVIRON MICROB, V66, P2641, DOI 10.1128/AEM.66.6.2641-2646.2000; Fiehn O, 2000, NAT BIOTECHNOL, V18, P1157, DOI 10.1038/81137; Fillinger S, 2000, J BIOL CHEM, V275, P14031, DOI 10.1074/jbc.275.19.14031; Fischer E, 2004, ANAL BIOCHEM, V325, P308, DOI 10.1016/j.ab.2003.10.036; Fischer E, 2003, J BIOL CHEM, V278, P46446, DOI 10.1074/jbc.M307968200; Fischer E, 2003, EUR J BIOCHEM, V270, P880, DOI 10.1046/j.1432-1033.2003.03448.x; Gross J, 2001, P NATL ACAD SCI USA, V98, P694, DOI 10.1073/pnas.98.2.694; Gunnarsson N, 2004, MOL MICROBIOL, V52, P895, DOI 10.1111/j.1365-2958.2004.04028.x; Hastie T., 2001, ELEMENTS STAT LEARNI; Hellerstein MK, 2003, ANNU REV NUTR, V23, P379, DOI 10.1146/annurev.nutr.23.011702.073045; Himberg J, 2004, NEUROIMAGE, V22, P1214, DOI 10.1016/j.neuroimage.2004.03.027; *HUT CIS, FASTICA PACK MATLAB; Hyvarinen A, 2001, INDEPENDENT COMPONEN; Jolliffe I., 2002, PRINCIPAL COMPONENT; Klapa MI, 2003, EUR J BIOCHEM, V270, P3525, DOI 10.1046/j.1432-1033.2003.03732.x; Kobayashi K, 2003, P NATL ACAD SCI USA, V100, P4678, DOI 10.1073/pnas.0730515100; Kunst F, 1997, NATURE, V390, P249, DOI 10.1038/36786; Lee SI, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-11-r76; Liebermeister W, 2002, BIOINFORMATICS, V18, P51, DOI 10.1093/bioinformatics/18.1.51; Ludwig H, 2001, MOL MICROBIOL, V41, P409, DOI 10.1046/j.1365-2958.2001.02523.x; Papin JA, 2003, TRENDS BIOCHEM SCI, V28, P250, DOI 10.1016/S0968-0004(03)00064-1; Petersen S, 2000, J BIOL CHEM, V275, P35932, DOI 10.1074/jbc.M908728199; Raghevendran V, 2004, YEAST, V21, P769, DOI 10.1002/yea.1136; Roessner-Tunali U, 2004, PLANT J, V39, P668, DOI 10.1111/j.1365-313X.2004.02157.x; Sauer U, 1999, J BACTERIOL, V181, P6679; Sauer U, 2004, J BIOL CHEM, V279, P6613, DOI 10.1074/jbc.M311657200; Sauer U, 2004, CURR OPIN BIOTECH, V15, P58, DOI 10.1016/j.copbio.2003.11.001; Sauer U, 1997, NAT BIOTECHNOL, V15, P448, DOI 10.1038/nbt0597-448; Schwender J, 2003, J BIOL CHEM, V278, P29442, DOI 10.1074/jbc.M303432200; SZYPERSKI T, 1995, EUR J BIOCHEM, V232, P433, DOI 10.1111/j.1432-1033.1995.433zz.x; WEICHERT W, 2001, METAB ENG, V3, P195; Zamboni N, 2004, J BACTERIOL, V186, P4528, DOI 10.1128/JB.186.14.4528-4534.2004	37	16	19	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1465-6914			GENOME BIOL	Genome Biol.		2004	5	12							R99	10.1186/gb-2004-5-12-r99		12	Biotechnology & Applied Microbiology; Genetics & Heredity	Biotechnology & Applied Microbiology; Genetics & Heredity	875YY	WOS:000225460600011	15575973	
B	Collins-Thompson, K; Callan, J			acl	Collins-Thompson, K; Callan, J			A language modeling approach to predicting reading difficulty	HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE			English	Proceedings Paper	Human Language Technology Conference of the North American Chapter of the Association-for-Computational-Linguistics	MAY 02-07, 2004	Boston, MA					We demonstrate a new research approach to the problem of predicting the reading difficulty of a text passage, by recasting readability in terms of statistical language modeling. We derive a measure based on an extension of multinomial naive Bayes classification that combines multiple language models to estimate the most likely grade level for a given passage. The resulting classifier is not specific to any particular subject and can be trained with relatively little labeled data. We perform predictions for individual Web pages in English and compare our performance to widely-used semantic variables from traditional readability measures. We show that with minimal changes, the classifier may be retrained for use with French Web documents. For both English and French, the classifier maintains consistently good correlation with labeled grade level (0.63 to 0.79) across all test sets. Some traditional semantic variables such as type-token ratio gave the best performance on commercial calibrated test passages, while our language modeling approach gave better accuracy for Web documents and very short passages (less than 10 words).	Carnegie Mellon Univ, Sch Comp Sci, Language Technol Inst, Pittsburgh, PA 15213 USA	Collins-Thompson, K (reprint author), Carnegie Mellon Univ, Sch Comp Sci, Language Technol Inst, 4502 Newell Simon Hall, Pittsburgh, PA 15213 USA.						Burnard L., 1995, USERS REFERENCE GUID; Carroll J. B., 1971, WORD FREQUENCY BOOK; Chall J. S., 1983, STAGES READING DEV; CHALL JS, 1958, BUREAU ED RES MONOGR, V34; Chall JS, 1995, READABILITY REVISITE; Crammer K., 2001, P C NEUR INF PROC SY, P641; Dale E, 1981, LIVING WORD VOCABULA; Duda R.O., 2001, PATTERN CLASSIFICATI; FRY E, 1990, J READING, V33, P594; Gale WA, 1995, J QUANT LINGUIST, V2, P217, DOI 10.1080/09296179508590051; GARTIN S, 1994, J AGR ED, V35; Hastie T., 2001, ELEMENTS STAT LEARNI; KINCAID J, 875 CHIEF NAV TRAIN; Klare G. R., 1963, MEASUREMENT READABIL; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; MACCULLAGH P, 1980, J ROYAL STAT SOC B, V42, P109; Mitchell J. V., 1985, 9 MENTAL MEASUREMENT; MLADENIC D, 1998, WORKING NOTES LEARNI; *READ A Z COM, 2003, READ A Z LEV CORR CH; Si L., 2001, P 10 INT C INF KNOWL, P574; Stenner AJ, 1988, LEXILE FRAMEWORK	21	1	1	ASSOCIATION COMPUTATIONAL LINGUISTICS	SOMERSET	PO BOX 6090, SOMERSET, NJ 08875 USA			1-932432-23-X				2004							193	200				8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	BAP35	WOS:000223117100025		
B	Stahlbock, R		Arabnia, HR; Mun, Y		Stahlbock, R			An evolutionary neural classification approach to evaluate retail stores and support decisions on their location, in-store design and assortment	IC-AI '04 & MLMTA'04 , VOL 1 AND 2, PROCEEDINGS			English	Proceedings Paper	International Conference on Artificial Intelligence/International Conference on Machine Learning, Models, Technologies and Applications	JUN 21-24, 2004	Las Vegas, NV	Comp Sci Res, Educ, & Applicat Press, Int Technol Inst, Korean Soc Internet Informat, World Acad Sci Informat Technol			LEARNING VECTOR QUANTIZATION	Artificial neural networks (ANN) like learning vector quantization (LVQ) an suitable for solving classification tasks. Several enhancements of standard algorithms for improving convergence or accuracy exist. They show promising results, at least when applied to simple problems. In this paper, a new approach of evolutionary optimized LVQ is proposed. Its classification accuracy in a complex economic task is examined. The analyzed real-world problem is the classification and evaluation of retail stores in terms of sales volume. Given data reflect macroscopic external infrastructure and microscopic internal aspects of existing stores. Results of numerous computational experiments with a parallelized implementation in a PC network are compared with results of some standard neural networks which am dominated. Finally, the results are interpreted as support for investment decisions. New stores can be established, or existing stores without prospective profits can be shut down. Alternatively, their in-store design or assortment of goods can be modified.	Univ Hamburg, Inst Informat Syst, D-20146 Hamburg, Germany	Stahlbock, R (reprint author), Univ Hamburg, Inst Informat Syst, D-20146 Hamburg, Germany.						Braun H., 1997, NEURONALE NETZE OPTI; DERIGS U, 1997, OR SPEKTRUM, P285; DeSieno D, 1988, P IEEE INT C NEURAL, V1, P117; Fausett L., 1994, FUNDAMENTALS NEURAL; Goldberg D.E., 1989, GENETIC ALGORITHMS S; Hammer B, 2002, LECT NOTES COMPUT SC, V2415, P370; Hastie T., 2001, ELEMENTS STAT LEARNI; HOLLAND JH, 1994, ADAPTATION NATURAL A; KITAJIMA N, 1995, P INT C NEUR NETW IE, V5, P2775, DOI 10.1109/ICNN.1995.488170; Kohonen T., 1997, SELF ORGANIZING MAPS; LAAKSONEN JT, 1992, ARTIFICIAL NEURAL NE, V2, P1181; Merelo JJ, 1995, ARTIFICIAL NEURAL NETS AND GENETIC ALGORITHMS, P92; NeuralWare Inc, 1993, NEUR COMP TECHN HDB; NISSEN V, 1994, EVOLUTIONARE ALGORIT; Odorico R, 1997, NEURAL NETWORKS, V10, P1083, DOI 10.1016/S0893-6080(97)00012-9; PAL NR, 1993, IEEE T NEURAL NETWOR, V3, P546; Patterson D, 1996, ARTIFICIAL NEURAL NE; PREGENZER M, 1994, P IEEE INT C NEURAL, V5, P2890, DOI 10.1109/ICNN.1994.374690; SATO A, 1999, P INT C ART NEUR NET, V2, P928; SCHURMANN J, 1996, UNIFIED VIEW STAT NE; Seo S, 2003, NEURAL COMPUT, V15, P1589, DOI 10.1162/089976603321891819; STAHLBOCK R, 2002, EVOLUTIONARE ENTWICK; Vakil-Baghmisheh MT, 2003, PATTERN RECOGN, V36, P1901, DOI 10.1016/S0031-3203(02)00291-1; Verleysen M., 1993, New Trends in Neural Computation. International Workshop on Artificial Neural Networks. IWANN '93 Proceedings; YOU SJ, 1995, P ICNN 95 P IEEE INT, V5, P2763; Young T. Y., 1974, CLASSIFICATION ESTIM; ZELL ANDREAS, 1994, SIMULATION NEURONALE	27	0	0	C S R E A PRESS	ATHENS	115 AVALON DR, ATHENS, GA 30606 USA			1-932415-33-5				2004							228	234				7	Computer Science, Artificial Intelligence	Computer Science	BBL81	WOS:000226030400034		
B	Liu, H; Kustra, R; Zhang, J		Arabnia, HR; Mun, Y		Liu, H; Kustra, R; Zhang, J			A novel dimensionality reduction technique based on independent component analysis for modeling microarray gene expression data	IC-AI '04 & MLMTA'04 , VOL 1 AND 2, PROCEEDINGS			English	Proceedings Paper	International Conference on Artificial Intelligence/International Conference on Machine Learning, Models, Technologies and Applications	JUN 21-24, 2004	Las Vegas, NV	Comp Sci Res, Educ, & Applicat Press, Int Technol Inst, Korean Soc Internet Informat, World Acad Sci Informat Technol		gene expression data; dimensionality reduction; independent component analysis; latent regulatory factors	PATTERNS	DNA microarray experiments generating thousands of gene expression measurements, are being used to gather information from tissue and cell samples regarding gene expression differences that will be useful in diagnosing disease. But one challenge of microarray studies is the fact that the number n of samples collected is relatively small compared to the number p of genes per sample which are usually in thousands. In statistical terms this very large number of predictors compared to a small number of samples or observations makes the classification problem difficult. This is known as the "curse of dimensionality problem". An efficient way to solve this problem is by using dimensionality reduction techniques. Principle Component Analysis(PCA) is a leading method for dimensionality reduction of gene expression data which is optimal in the sense of least square error In this paper we propose a new dimensionality reduction technique for specific bioinformatics applications based on Independent component Analysis(ICA). Being able to exploit higher order statistics to identify a linear model result, this ICA based dimensionality reduction technique outperforms PCA from both statistical and biological significance aspects. We present experiments on NCI 60 dataset to show this result.	Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada	Liu, H (reprint author), Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada.						Alter O, 2000, P NATL ACAD SCI USA, V97, P10101, DOI 10.1073/pnas.97.18.10101; Althauser R, 1971, CAUSAL MODELS SOCIAL, P453; Cherkassky V., 1998, LEARNING DATA; CHIPPETTA P, 2002, P JOBIM 02 ST ML, P131; Hastie T., 2001, ELEMENTS STAT LEARNI; Hyvarinen A., 1999, NEURAL COMPUTING SUR, V2, P94; Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; Lee SI, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-11-r76; Liebermeister W, 2002, BIOINFORMATICS, V18, P51, DOI 10.1093/bioinformatics/18.1.51; Lockhart DJ, 1996, NAT BIOTECHNOL, V14, P1675, DOI 10.1038/nbt1296-1675; Mallat S. G., 1999, WAVELET TOUR SIGNAL; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; SCHENA M, 1995, SCIENCE, V270, P467, DOI 10.1126/science.270.5235.467; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520	14	0	0	C S R E A PRESS	ATHENS	115 AVALON DR, ATHENS, GA 30606 USA			1-932415-33-5				2004							1133	1139				7	Computer Science, Artificial Intelligence	Computer Science	BBL81	WOS:000226030400173		
B	Huang, JT; Ma, LH; Qian, JX		Zhong, Y		Huang, JT; Ma, LH; Qian, JX			A new improved support vector machine: QGA-SVM	ICCC2004: Proceedings of the 16th International Conference on Computer Communication Vol 1and 2			English	Proceedings Paper	16th International Conference on Computer Communication (ICCC 2004)	SEP 15-17, 2004	Beijing, PEOPLES R CHINA	Minist Informat Ind, Int Council Comp Commun, China Ctr Informat Ind Dev, China Elect Chamber Commerce, China Comp Soc, China Inst Commun, Chinese Assoc Artificial Intelligence, Beijing Univ Posts &Telecommun, China Fed Informat Promot, Nat Sci Fdn China, Chinese Assoc Sci & Technol, States Adm Foreign Experts Affairs		support vector machine; genetic algorithm; QGA-SVM		As a realizing algorithm of the statistical learning theory, Support Vector Machine (SVM) has been paid more and more attention recently. Many researchers have developed some variations of the standard SVM, which is put forward by Vapnik first. SVM has excellent generalization performance compared to the classical learning algorithms, such as NN, ML, etc. In this paper, we developed a new improved SVM algorithm, QGA-SVM. The Quasi Genetic Algorithm (QGA) strategy is integrated in the SVM learning procedure to further optimize and accelerate the training procedure. The tests on some datasets proved its advantages, especially for the multi-class pattern classification with unbalanced classes.	Zhejiang Univ, Inst Syst Engn, Hangzhou 310027, Peoples R China	Huang, JT (reprint author), Zhejiang Univ, Inst Syst Engn, Hangzhou 310027, Peoples R China.						Chang C, 2001, LIBSVM LIB SUPPORT V; Christopher J.C.B., 1998, DATA MIN KNOWL DISC, V2, P121; CHU LL, 2002, MATH FDN COMPUTATION; Hastie T., 2001, ELEMENTS STAT LEARNI; Johan A.K.S., 2002, LEAST SQUARES SUPPOR; Keerthi SS, 2003, NEURAL COMPUT, V15, P1667, DOI 10.1162/089976603321891855; Lin H.-T., 2003, STUDY SIGMOID KERNEL; Ming Z., 1999, PRINCIPLE APPL GENET; Mitchell T., 1997, MACHINE LEARNING; Murphy P., 1994, UCI REPOSITORY MACHI; OSUNA E, 1997, P IEEE WORKSH NEUR N, P276; Platt J, 1998, ADV KERNEL METHODS S; Richard O. Duda, 2001, PATTERN CLASSIFICATI; Vapnik VN, 2000, NATURE STAT LEARNING; XU P, 2003, P INT JOINT C NEUR N	15	0	0	PUBLISHING HOUSE ELECTRONICS INDUSTRY	BEIJING	PO BOX 173 WANSHOU ROAD, BEIJING 100036, PEOPLES R CHINA			7-121-00308-2				2004							1749	1753				5	Computer Science, Information Systems; Telecommunications	Computer Science; Telecommunications	BCC66	WOS:000228632800316		
S	Rooney, N; Patterson, D; Nugent, C		Khoshgoftaar, TM		Rooney, N; Patterson, D; Nugent, C			Reduced ensemble size stacking	ICTAI 2004: 16TH IEEE INTERNATIONALCONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE, PROCEEDINGS	PROCEEDINGS - INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	16th IEEE International Conference on Tools with Artificial Intelligence	NOV 15-17, 2004	Boca Raton, FL	IEEE Comp Soc, Informat Technol Res Inst, Wright State Univ, Florida Atlantic Univ			COMBINING CLASSIFIERS	In this paper we investigate an algorithmic extension to the technique of Stacked Regression that prunes the size of a homogeneous ensemble set based on a consideration of the accuracy and diversity of the set members. We show that the pruned ensemble set is as accurate on average over the data-sets tested as the non-pruned version, which provides benefits in terms of its application efficiency and reduced complexity of the ensemble.	Univ Ulster, Nikel, Coleraine BT52 1SA, Londonderry, North Ireland	Rooney, N (reprint author), Univ Ulster, Nikel, Coleraine BT52 1SA, Londonderry, North Ireland.						Breiman L, 1996, MACH LEARN, V24, P49; Christensen SW, 2003, LECT NOTES COMPUT SC, V2709, P286; CLARKE C, 2003, JMLR, V4, P683; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Dzeroski S, 2004, MACH LEARN, V54, P255, DOI 10.1023/B.MAC.0000015881.36452.6e; Hastie T., 2001, ELEMENTS STAT LEARNI; Ho T. K., 1998, LECT NOTES COMPUTER, P640; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Krogh A, 1995, ADV NEURAL INFORMATI, V7, P231; Kuncheva LI, 2002, IEEE T SYST MAN CY B, V32, P146, DOI 10.1109/3477.990871; LEBLANC M, 1992, COMBINING ESTIMATES; Puuronen S., 1999, LECT NOTES ARTIF INT, V1609, P592; Quinlan R., 1992, P 5 AUSTR JOINT C AR, P343; SEEWALD A, P 19 INT C MACH LEAR; Sharkey A. J. C., 1996, Connection Science, V8, DOI 10.1080/095400996116785; Ting KM, 1999, J ARTIF INTELL RES, V10, P271; Tsymbal A., 2003, Information Fusion, V4, DOI 10.1016/S1566-2535(03)00004-6; Witten I.H., 1999, DATA MINING PRACTICA; Wolpert D. H., 1996, COMBINING STACKING B; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Zenobi G., 2001, LECT NOTES COMPUTER, P576; ZHOU Z, 2002, ARTIF INTELL, V137, P90263, DOI UNSP 2390263	22	2	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1082-3409		0-7695-2236-X	PROC INT C TOOLS ART			2004							266	271				6	Computer Science, Artificial Intelligence	Computer Science	BBI06	WOS:000225597000034		
B	Berge, A; Solberg, AS			ieee	Berge, A; Solberg, AS			Robust classification of hyperspectral data	IGARSS 2004: IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM PROCEEDINGS, VOLS 1-7: SCIENCE FOR SOCIETY: EXPLORING AND MANAGING A CHANGING PLANET	IEEE International Symposium on Geoscience and Remote Sensing (IGARSS)		English	Proceedings Paper	IEEE International Geoscience and Remote Sensing Symposium	SEP 20-24, 2004	Anchorage, AK	IEEE, IEEE Geosci & Remote Sensing Soc, Univ Alaska Fairbanks, Geophys Inst, Univ Missouri Columbia, NASA, NOAA, USN, Off Naval Res, Ball Aerosp &Technol Corp, Natl Polar Orbiting Operat Environm Satellite Syst, Japan Aerosp Explorat Agcy, Raytheon, US Geol Survey, ITT Ind, IEEE Ocean Engn Soc, Int Union Radio Sci			DISCRIMINANT-ANALYSIS	High dimensionality and highly correlated features are two important characteristics of hyperspectral data that leads to poor performance of conventional classification methods. Furthermore, hyperspectral sensors usually provide relatively low optical resolution, which implies that pixels are bound to cover a mixture of objects with different reflective properties. Since it is common to define sharp labels on pixels, classes might not be adequately described with a single mode Gaussian as it is clone in many conventional and contemporary classification methods for hyperspectral data. We study a framework that facilitates a penalized classification, making the classifier robust for overfitting. This framework also allows the classes to be modeled as a mixture of subclasses, giving the model more flexibility.	Univ Oslo, Dept Informat, N-0316 Oslo, Norway	Berge, A (reprint author), Univ Oslo, Dept Informat, N-0316 Oslo, Norway.						BERGE A, 2004, P IEEE GEOSC REM SEN; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Hastie T., 2001, ELEMENTS STAT LEARNI; HASTIE T, 1994, J AM STAT ASSOC, V89, P1255, DOI 10.2307/2290989; HASTIE T, 1995, ANN STAT, V23, P73, DOI 10.1214/aos/1176324456; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267	6	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-8742-2	INT GEOSCI REMOTE SE			2004							937	940				4	Geosciences, Multidisciplinary; Instruments & Instrumentation; Remote Sensing; Imaging Science & Photographic Technology	Geology; Instruments & Instrumentation; Remote Sensing; Imaging Science & Photographic Technology	BBP98	WOS:000227006900248		
B	Nishii, R; Eguchi, S			ieee	Nishii, R; Eguchi, S			Supervised image classification based on AdaBoost with contextual weak classifiers	IGARSS 2004: IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM PROCEEDINGS, VOLS 1-7: SCIENCE FOR SOCIETY: EXPLORING AND MANAGING A CHANGING PLANET	IEEE International Symposium on Geoscience and Remote Sensing (IGARSS)		English	Proceedings Paper	IEEE International Geoscience and Remote Sensing Symposium	SEP 20-24, 2004	Anchorage, AK	IEEE, IEEE Geosci & Remote Sensing Soc, Univ Alaska Fairbanks, Geophys Inst, Univ Missouri Columbia, NASA, NOAA, USN, Off Naval Res, Ball Aerosp &Technol Corp, Natl Polar Orbiting Operat Environm Satellite Syst, Japan Aerosp Explorat Agcy, Raytheon, US Geol Survey, ITT Ind, IEEE Ocean Engn Soc, Int Union Radio Sci				AdaBoost, one of machine learning techniques, is employed for supervised classification of land-cover categories of geostatistical data. We introduce contextual classifiers based on neighbouring pixels. First, posterior probabilities are calculated at all pixels. Then, averages of the posteriors in various neighborhoods are calculated, and the averages are used as contextual classifiers. Weights for the classifiers can be determined by minimizing the empirical risk with muilticlass. Finally, a linear combination of classifier is obtained. The proposed method is applied to artificial multispectral images and shows an excellent performance similar to the MRF-based classifier with much less computation time.	Kyushu Univ, Grad Sch Math, Fukuoka 8128581, Japan	Nishii, R (reprint author), Kyushu Univ, Grad Sch Math, Fukuoka 8128581, Japan.						Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Hastie T., 2001, ELEMENTS STAT LEARNI; Kwok JTY, 2000, IEEE T NEURAL NETWOR, V11, P1162, DOI 10.1109/72.870047; Nishii R, 2003, IEEE T GEOSCI REMOTE, V41, P2316, DOI 10.1109/TGRS.2003.816648; ROTH V, 2001, DTSCH ARBEITSGEMEINS, P246; Takenouchi T, 2004, NEURAL COMPUT, V16, P767, DOI 10.1162/089976604322860695; Vapnik VN, 2000, NATURE STAT LEARNING	8	1	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-8742-2	INT GEOSCI REMOTE SE			2004							1467	1470				4	Geosciences, Multidisciplinary; Instruments & Instrumentation; Remote Sensing; Imaging Science & Photographic Technology	Geology; Instruments & Instrumentation; Remote Sensing; Imaging Science & Photographic Technology	BBP98	WOS:000227006900384		
B	Delisle, S; Dugre, M; St-Pierre, J		Arabnia, HR		Delisle, S; Dugre, M; St-Pierre, J			Multidimensional SME performance evaluation: Upgrading to data warehousing & data mining techniques	IKE '04: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE ENGNINEERING			English	Proceedings Paper	International Conference on Information and Knowledge Engineering (IKE 04)	JUN 21-24, 2004	Las Vegas, NV			benchmarking; data warehousing; data mining; diagnosis; expert systems; performance; SME	EXPERT-SYSTEMS; KNOWLEDGE ACQUISITION; FIELD	We present a fully implemented expert diagnostic system which evaluates the performance of SMEs on a benchmarking basis. The system has been in use for several years and has gone through a constant and quite challenging evolution in order to meet both the needs of research and the production of benchmarking reports. We discuss why we decided to upgrade our system with data warehousing and data mining techniques. At the time of writing, we are about to activate the new data warehouse and start our experimentations with data mining techniques-newest results will be available when the conference will be held. We think data warehousing and data mining will allow us to significantly extend our knowledge on SMEs, and further improve our performance evaluation model.	Univ Quebec, Inst Rech, PME, Dept Math & Informat, Trois Rivieres, PQ G9A 5H7, Canada	Delisle, S (reprint author), Univ Quebec, Inst Rech, PME, Dept Math & Informat, Trois Rivieres, PQ G9A 5H7, Canada.						BAMBERGER SK, 1997, LECT NOTES COMPUTER, V1303, P325; Bui T, 1999, DECIS SUPPORT SYST, V25, P225, DOI 10.1016/S0167-9236(99)00008-1; CASSELL C, 2001, INT J, V8, P212; DENKENA B, 2003, P BUS EXC PERF MEAS; Golfarelli M., 1998, P ACM 1 INT WORKSH D, P3, DOI 10.1145/294260.294261; Hastie T., 2001, ELEMENTS STAT LEARNI; *IMT STRAT INC, 1999, DAT WAR ULT GUID BUI, P15; Kimball R., 1996, DATA WAREHOUSE TOOLK; Matsatsinis NF, 1997, EXPERT SYST APPL, V12, P247, DOI 10.1016/S0957-4174(96)00098-X; Mitchell T., 1997, MACHINE LEARNING; Nedovic L, 2002, EXPERT SYST APPL, V23, P49, DOI 10.1016/S0957-4174(02)00027-1; ONEIL B, 1997, ORACLE DATA WAREHOUS; ROUGE A, 1995, EXPERT SYST APPL, V8, P333, DOI 10.1016/0957-4174(94)E0024-O; Schreiber G., 2002, KNOWLEDGE ENG MANAGE; Shim JP, 2002, DECIS SUPPORT SYST, V33, P111, DOI 10.1016/S0167-9236(01)00139-7; Sierra-Alonso A, 2000, LECT NOTES ARTIF INT, V1793, P458; Stamelos L, 2002, LECT NOTES ARTIF INT, V2308, P42; STPIERRE J, 2004, IN PRESS INT J, V11; Turban E., 2001, DECISION SUPPORT SYS; Wagner WP, 2002, KNOWL-BASED SYST, V15, P439, DOI 10.1016/S0950-7051(02)00026-6; YASIN MM, 2002, INT J, V9, P217	21	0	0	C S R E A PRESS	ATHENS	115 AVALON DR, ATHENS, GA 30606 USA			1-932415-27-0				2004							371	377				7	Computer Science, Information Systems	Computer Science	BBN32	WOS:000226272900058		
J	Ko, M; Osei-Bryson, KM				Ko, M; Osei-Bryson, KM			The productivity impact of information technology in the healthcare industry: an empirical study using a regression spline-based approach	INFORMATION AND SOFTWARE TECHNOLOGY			English	Article						information technology investments; productivity; regression splines; data mining; multivariate adaptive regression splines	FIRM PERFORMANCE; PROFITABILITY; EFFICIENCY; SYSTEMS	This paper explores the productivity impact of information technology (IT) in the healthcare industry using a regression spline (RS)-based approach. Application of the RS-based approach offered additional valuable insights that contribute to our understanding of the complex relationship between investments in IT and organizational productivity. For example, the results of this study suggest that investments in the IT Stock has a positive impact on productivity only under certain conditions, and that this impact of IT is not uniform but is conditioned both by the amount invested in the IT Stock and the investments in Non-IT Capital. (C) 2003 Elsevier B.V. All rights reserved.	Univ Texas, Coll Business, Dept Informat Syst, San Antonio, TX 78249 USA; Virginia Commonwealth Univ, Sch Business, Dept Informat Syst, Richmond, VA 23284 USA; Virginia Commonwealth Univ, Sch Business, Informat Syst Res Inst, Richmond, VA 23284 USA	Ko, M (reprint author), Univ Texas, Coll Business, Dept Informat Syst, San Antonio, TX 78249 USA.	mko@utsa.edu; kweku.muata@isy.vcu.edu					Barua A, 2000, FRAMING DOMAINS IT M; Breiman L., 1984, CLASSIFICATION REGRE; Brynjolfsson E, 1996, MANAGE SCI, V42, P541, DOI 10.1287/mnsc.42.4.541; Brynjolfsson E., 1993, Communications of the ACM, V36, DOI 10.1145/163298.163309; Dewan S, 1997, MANAGE SCI, V43, P1660, DOI 10.1287/mnsc.43.12.1660; Eubank R.L., 1988, SPLINE SMOOTHING NON; EVANS D, 2000, FINANCE DEV RES PROG, P1; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; GARRETSON R, 1999, INFOWORLD, V21, P32; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie TJ, 1990, GEN ADDITIVE MODEL; Henderson J. M., 1980, MICROECONOMIC THEORY; Hitt LM, 1996, MIS QUART, V20, P121, DOI 10.2307/249475; HOOGEVEEN D, 2002, P 35 HAW INT C SYST; Lee B, 2000, J MANAGE INFORM SYST, V16, P99; Li MF, 1999, INFORM MANAGE, V35, P43, DOI 10.1016/S0378-7206(98)00075-5; Loveman G. W., 1994, INFORMATION TECHNOLO, P84; MARKUS L, 1993, STRATEGIC INFORMATIO, P375; MCKEEN JD, 1993, STRATEGIC INFORMATIO, P405; Menon NM, 2000, INFORM SYST RES, V11, P83, DOI 10.1287/isre.11.1.83.11784; PRASAD B, 1997, 9709 WHART SCH FIN I; SHAO B, 2000, THESIS STATE U NEW Y; Shao BBM, 2000, J COMPUT INFORM SYST, V41, P25; Shao BBM, 2001, INFORM SOFTWARE TECH, V43, P447, DOI 10.1016/S0950-5849(01)00150-1; Sircar S, 2000, J MANAGE INFORM SYST, V16, P69; Soh C., 1995, P 16 INT C INF SYST, P29; Steinberg D., 1999, MARS USER GUIDE; SUMNER AT, 1995, HEALTH CARE MANAGE R, V20, P92; Targett D., 1999, IT PRODUCTIVITY PARA; Teo TSH, 2000, INT J INFORM MANAGE, V20, P269, DOI 10.1016/S0268-4012(00)00016-5; WARD S, 2002, US TODAY        0520; Weill P., 1992, INFORMATION SYSTEMS, V3, P307, DOI DOI 10.1287/ISRE.3.4.307	32	2	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-5849			INFORM SOFTWARE TECH	Inf. Softw. Technol.	JAN 1	2004	46	1					65	73		10.1016/S0950-5849(03)00110-1		9	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	762HG	WOS:000187965600005		
J	Ko, M; Osei-Bryson, KM				Ko, M; Osei-Bryson, KM			Using regression splines to assess the impact of information technology investments on productivity in the health care industry	INFORMATION SYSTEMS JOURNAL			English	Article						information technology investments; productivity; regression; regression splines; data mining; MARS	SYSTEMS; FIRM; FIT; PROFITABILITY; PERFORMANCE; MANAGEMENT; MODELS	This paper explores the impact of information technology (IT) investments on productivity using a new technique, multivariate adaptive regression splines (MARS). We believe that it provides additional insights on the nature of the impact of IT investments on productivity. The results from our study are compared with findings from a previous study that has also used the same data set. While the results of a previous study indicate that IT investments have a positive but uniform impact on productivity, our study suggests that the impact of IT on productivity is not uniform but is contingent on other complementary factors. Our findings describe that the complementary relationship exists between IT and non-IT related investments. Thus, improved organizational productivity cannot be expected from investment in IT alone but only together with non-IT investments. Our findings also point out that further investment may not necessarily bring on higher organizational productivity.	Univ Texas, Coll Business, Dept Informat Syst, San Antonio, TX 78249 USA; Virginia Commonwealth Univ, Dept Informat Syst, Richmond, VA 23284 USA; Virginia Commonwealth Univ, Informat Syst Res Inst, Richmond, VA 23284 USA	Ko, M (reprint author), Univ Texas, Coll Business, Dept Informat Syst, San Antonio, TX 78249 USA.	ko@utsa.edu; Kweku.Muata@isy.vcu.edu					ABRAHAM A, 2001, INT WORK C ART NAT N, P679; Abraham A., 2002, WORLD C COMP INT, P1616; Anderson JG, 1997, COMMUN ACM, V40, P83, DOI 10.1145/257874.257895; Barua A, 2000, FRAMING DOMAINS IT M; BARUA A, 1995, INFORM SYST RES, V6, P3, DOI 10.1287/isre.6.1.3; Barua A, 1996, INFORM SYST RES, V7, P409, DOI 10.1287/isre.7.4.409; Bergeron F, 2001, OMEGA-INT J MANAGE S, V29, P125, DOI 10.1016/S0305-0483(00)00034-7; BOSE B, 2003, EXPERT SYSTEMS APPL, V24, P59; Breiman L., 1984, CLASSIFICATION REGRE; BRIAND LC, 2000, ISERN0007 VERSION 1; BRIAND LC, 2000, ISERN0006 VERSION 2; Brynjolfsson E, 1996, MANAGE SCI, V42, P541, DOI 10.1287/mnsc.42.4.541; CAREY WP, 1992, SENSOR ACTUAT B-CHEM, V9, P113, DOI 10.1016/0925-4005(92)80203-A; Danzon P., 2001, EC PAYOFF INTERNET R, P189; DASH J, 1997, SOFTWARE MAGAZINE, V17, P76; Devaraj S, 2000, J MANAGE INFORM SYST, V16, P41; DEVEAUX RD, 1993, COMPUT CHEM ENG, V17, P819, DOI 10.1016/0098-1354(93)80066-V; Dewan S, 1997, MANAGE SCI, V43, P1660, DOI 10.1287/mnsc.43.12.1660; Ekman T, 1999, INT CONF ACOUST SPEE, P2667; Eubank R.L., 1988, SPLINE SMOOTHING NON; EVANS D, 2000, FINANCE DEV RES PROG, P1; Francalanci C, 1998, MIS QUART, V22, P227, DOI 10.2307/249396; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Griffin WL, 1997, J GEOCHEM EXPLOR, V59, P233, DOI 10.1016/S0375-6742(97)00015-0; Grimson J, 2000, COMMUN ACM, V43, P49; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie TJ, 1990, GEN ADDITIVE MODEL; Henderson J. M., 1980, MICROECONOMIC THEORY; Hitt LM, 1996, MIS QUART, V20, P121, DOI 10.2307/249475; HOOGEVEEN D, 2002, P 35 HAW INT C SYST; Jin R., 2000, AIAA20004801; Kuhnert PM, 2000, COMPUT STAT DATA AN, V34, P371, DOI 10.1016/S0167-9473(99)00099-7; Lee B, 2000, J MANAGE INFORM SYST, V16, P99; Li MF, 1999, INFORM MANAGE, V35, P43, DOI 10.1016/S0378-7206(98)00075-5; Lichtenberg F, 1995, EC INNOVATION NEW TE, V3, P201, DOI DOI 10.1080/10438599500000003; Loveman G. W., 1994, INFORMATION TECHNOLO, P84; MacLean M B, 1991, Health Rep, V3, P229; MALLICK BK, 1997, BAYESIAN SURVIVAL AN; MARKUS L, 1993, STRATEGIC INFORMATIO, P375; Menon NM, 2000, INFORM SYST RES, V11, P83, DOI 10.1287/isre.11.1.83.11784; Menon NM, 2000, DECIS SUPPORT SYST, V30, P153, DOI 10.1016/S0167-9236(00)00095-6; MILGROM P, 1995, J ACCOUNT ECON, V19, P179, DOI 10.1016/0165-4101(94)00382-F; Mukhopadhyay T, 1997, MANAGE SCI, V43, P1645, DOI 10.1287/mnsc.43.12.1645; NguyenCong V, 1996, EUR J MED CHEM, V31, P797, DOI 10.1016/0223-5234(96)83973-0; Prasad A.M., 2000, 4 INT C INT GIS ENV; PRASAD B, 1997, 9709 U PENNS WHART S; Raghupathi W., 1997, COMMUN ACM, V40, P81, DOI 10.1145/257874.257894; *SALF SYST, 2000, MARS WIND VERS 2 0; SELTO FH, 1995, ACCOUNT ORG SOC, V20, P665, DOI 10.1016/0361-3682(95)00022-2; SHAO B, 2000, THESIS STATE U NEW Y; Shao BBM, 2001, INFORM SOFTWARE TECH, V43, P447, DOI 10.1016/S0950-5849(01)00150-1; Smith H L, 2000, Hosp Top, V78, P13; Soh C., 1995, P 16 INT C INF SYST, P29; Steinberg D., 1999, MARS USER GUIDE; SUMNER AT, 1995, HEALTH CARE MANAGE R, V20, P92; Teo TSH, 2000, INT J INFORM MANAGE, V20, P269, DOI 10.1016/S0268-4012(00)00016-5; WARD S, 2002, US TODAY        0520; Weill P., 1992, INFORMATION SYSTEMS, V3, P307, DOI DOI 10.1287/ISRE.3.4.307; Wholey DR, 2000, HEALTH CARE MANAGE R, V25, P24; York T., 2001, GENETIC EPIDEMIOLOGY, V21, P649	60	12	12	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	1350-1917			INFORM SYST J	Inf. Syst. J.	JAN	2004	14	1					43	63		10.1111/j.1365-2575.2004.00160.x		21	Information Science & Library Science	Information Science & Library Science	761FY	WOS:000187891900004		
S	Famili, AF; Ouyang, J; Kryworuchko, M; Alvarez-Maya, I; Smith, B; Diaz-Mitoma, F		Orchard, B; Yang, C; Ali, M		Famili, AF; Ouyang, J; Kryworuchko, M; Alvarez-Maya, I; Smith, B; Diaz-Mitoma, F			Knowledge discovery in hepatitis C virus transgenic mice	INNOVATIONS IN APPLIED ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	17th International Conference on Industrial and Engineering Applications of Artificial Intelligence and Expert Systems	MAY 17-20, 2004	Ottawa, CANADA				GENE-EXPRESSION; INFECTION; CLASSIFICATION; MICROARRAY	For the purpose of gene identification, we propose an approach to gene expression data mining that uses. a combination of unsupervised and supervised learning techniques to search for useful patterns in the data. The approach involves validation and elimination of irrelevant data, extensive data pre-processing, data visualization, exploratory clustering, pattern recognition and model summarization. We have evaluated our method using data from microarray experiments in a Hepatitis C Virus transgenic mouse model. We demonstrate that from a total of 15311 genes (attributes) we can generate simple models and identify a small number of genes that can be used for future classifications. The approach has potential for future disease classification, diagnostic and virology applications.	Natl Res Council Canada, Inst Informat Technol, Ottawa, ON K1A 0R6, Canada; Childrens Hosp Eastern Ontario, Ottawa, ON K1H 8L1, Canada; Natl Res Council Canada, Inst Biol Sci, Ottawa, ON K1A 0R6, Canada	Famili, AF (reprint author), Natl Res Council Canada, Inst Informat Technol, Bldg M-50 NRC, Ottawa, ON K1A 0R6, Canada.	fazel.famili@nrc.gc.ca; junjun.ouyang@nrc.gc.ca; MKryworuchko@cheo.on.ca; IAlvarez-Maya@cheo.on.ca; brandon.smith@nrc.gc.ca; diaz@cheo.on.ca					Bigger CB, 2001, J VIROL, V75, P7059, DOI 10.1128/JVI.75.15.7059-7066.2001; Breiman L., 1984, CLASSIFICATION REGRE; CUI X, 2002, P CAMDA 02; Drazan KE, 2000, LIVER TRANSPLANT, V6, P396, DOI 10.1053/jlts.2000.6449; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; FAMILI F, 2003, APPL INFORMATICS, P32; FRIEDMAN J, 2002, GETTING STARTED MART; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hastie T., 2001, ELEMENTS STAT LEARNI; Lanford R E, 2001, ILAR J, V42, P117; Lanford RE, 2002, VIROLOGY, V293, P1, DOI 10.1006/viro.2001.1316; Li K, 2002, HEPATOLOGY, V35, P1237, DOI 10.1053/jhep.2002.32968; Okabe H, 2001, CANCER RES, V61, P2129; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Su AI, 2002, P NATL ACAD SCI USA, V99, P15669, DOI 10.1073/pnas.202608199; WALKER PR, 2004, AI MED; Witten I.H., 1999, DATA MINING PRACTICA; Yang YH, 2001, NORMALIZATION CDNA M	18	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-22007-0	LECT NOTES COMPUT SC			2004	3029						29	39				11	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Robotics	Computer Science; Robotics	BAD82	WOS:000221714200004		
S	King, RD; Ouali, M		Yang, ZR; Everson, R; Yin, H		King, RD; Ouali, M			Poly-transformation	INTELLIGENT DAA ENGINEERING AND AUTOMATED LEARNING IDEAL 2004, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	5th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL 2004)	AUG 25-27, 2004	Execter, ENGLAND	Execter Univ, Comp Sci Dept, IEEE Neural Networks Soc, Springer Verlag			PROTEIN SECONDARY STRUCTURE; STRUCTURE PREDICTION; ALGORITHMS	Poly-transformation is the extension of the idea of ensemble learning to the transformation step of Knowledge Discovery in Databases (KDD). In poly-transformation multiple transformations of the data are made before learning (data mining) is applied. The theoretical basis for poly-transformation is the same as that for other combining methods - using different predictors to remove uncorrelated errors. It is not possible to demonstrate the utility of poly-transformation using standard datasets, because no pre-transformed data exists for such datasets. We therefore demonstrate its utility by applying it to a single well-known hard problem for which we have expertise - the problem of predicting protein secondary structure from primary structure. We applied four different transformations of the data, each of which was justifiable by biological background knowledge. We then applied four different learning methods (linear discrimination, back-propagation, C5.0, and learning vector quantization) both to the four transformations, and to combining predictions from the different transformations to form the poly-transformation predictions. Each of the learning methods produced significantly higher accuracy with poly-transformation than with only a single transformation. Poly-transformation is the basis of the secondary structure prediction method Prof, which is one of the most accurate existing methods for this problem.	Univ Coll Wales, Dept Comp Sci, Aberystwyth SY23 3DB, Dyfed, Wales	King, RD (reprint author), Univ Coll Wales, Dept Comp Sci, Aberystwyth SY23 3DB, Dyfed, Wales.	rdk@aber.ac.uk					Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Cherkauer K., 1996, AAAI WORKSH INT MULT, P15; Dietterich TG, 1997, AI MAG, V18, P97; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; Fayyad U.M., 1996, ADV KNOWLEDGE DISCOV; Garnier J, 1996, METHOD ENZYMOL, V266, P541; Hastie T., 2001, ELEMENTS STAT LEARNI; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; KING RD, 1995, NEW GENERAT COMPUT, V13, P411; King RD, 1996, PROTEIN SCI, V5, P2298; KOHONEN T, 1992, P INT JOINT C NEUR N, P725; MUGGLETON S, 1992, PROTEIN ENG, V5, P647, DOI 10.1093/protein/5.7.647; Quali M., 2000, PROTEIN SCI, V9, P1162; ROST B, 1993, J MOL BIOL, V232, P584, DOI 10.1006/jmbi.1993.1413; SALAMOV AA, 1995, J MOL BIOL, V247, P11, DOI 10.1006/jmbi.1994.0116; ZHENG Z, 1998, P AUSTR JOINT C ART, P321	17	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-22881-0	LECT NOTES COMPUT SC			2004	3177						99	107				9	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BAV07	WOS:000223701300015		
S	Perez, JM; Muguerza, J; Arbelaitz, O; Gurrutxaga, I		Klopotek, MA; Wierzchon, ST; Trojanowski, K		Perez, JM; Muguerza, J; Arbelaitz, O; Gurrutxaga, I			A new algorithm to build consolidated trees: study of the error rate and steadiness	INTELLIGENT INFORMATION PROCESSING AND WEB MINING	ADVANCES IN SOFT COMPUTING		English	Proceedings Paper	International Intelligent Information Processing and Web Mining Conference	MAY 17-20, 2004	Zakopane, POLAND	Polish Acad Sci, Inst Comp Sci				This paper presents a new methodology for building decision trees, Consolidated Trees Construction algorithm, that improves the behavior of C4.5. It reduces the error and the complexity of the induced trees, being the differences in the complexity statistically significant. The advantage of this methodology in respect to other techniques such as bagging, boosting, etc. is that the final classifier is based on a single tree and not in a set of trees, so that, the explaining capacity of the classification is not lost. The experimentation has been done with some databases of the UCI Repository and a real application of customer fidelization from a company of electrical appliances.	Univ Basque Country, Fac Comp Sci, Donostia San Sebastian 20080, Spain	Perez, JM (reprint author), Univ Basque Country, Fac Comp Sci, POB 649, Donostia San Sebastian 20080, Spain.		Muguerza, Javier/G-6075-2012; Perez, Jesus/G-8065-2012; Gurrutxaga, Ibai/N-1674-2014	Perez, Jesus/0000-0003-1728-3249; Gurrutxaga, Ibai/0000-0003-1830-1058			Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Blake C.L., 1998, UCI REPOSITORY MACHI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Chawla NV, 2002, LECT NOTES COMPUT SC, V2364, P52; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Hastie T., 2001, ELEMENTS STAT LEARNI; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Skurichina M, 2002, LECT NOTES COMPUT SC, V2364, P62	12	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1615-3871		3-540-21331-7	ADV SOFT COMP			2004							79	88				10	Computer Science, Artificial Intelligence	Computer Science	BAI29	WOS:000222366800009		
J	Soeria-Atmadja, D; Zorzet, A; Gustafsson, MG; Hammerling, U				Soeria-Atmadja, D; Zorzet, A; Gustafsson, MG; Hammerling, U			Statistical evaluation of local alignment features predicting allergenicity using supervised classification algorithms	INTERNATIONAL ARCHIVES OF ALLERGY AND IMMUNOLOGY			English	Article						allergy; amino acid sequence; computational toxicology; risk assessment	ACID SUBSTITUTION MATRICES; GENETICALLY-MODIFIED FOODS; POTENTIAL ALLERGENICITY; SEQUENCE ALIGNMENTS; AMINO-ACIDS; PROTEIN; DESCRIPTORS; HOMOLOGY; DATABASE; PEPTIDES	Background: Recently, two promising alignment-based features predicting food allergenicity using the k nearest neighbor (kNN) classifier were reported. These features are the alignment score and alignment length of the best local alignment obtained in a database of known allergen sequences. Methods: In the work reported here a much more comprehensive statistical evaluation of the potential of these features was performed, this time for the prediction of allergenicity in general. The evaluation consisted of the following four key components. (1) A new high quality database consisting of 318 carefully selected, non-redundant allergens and 1,007 sequences carefully selected to be non-allergens. (2) Three different supervised algorithms: the kNN classifier, the Bayesian linear Gaussian classifier, and the Bayesian quadratic Gaussian classifier. (3) A large set of local alignment procedures defined using the FASTA3 alignment program by means of a wide range of different parameter settings. (4) Novel performance curves, alternative to conventional receiver-operating characteristic curves, to display not only average behaviors but also statistical variations due to small data sets. Results: The linear Gaussian classifier proved most useful among the tested supervised machine learning algorithms, closely followed by the quadratic Gaussian equivalent and kNN. The overall best classification results were obtained with a novel feature vector consisting of the combined alignment scores derived from local alignment procedures using different substitution matrices. Conclusions: The models reported here should be useful as a part of an integrated assessment scheme for potential protein allergenicity and for future comparisons with alternative bioinformatic approaches. Copyright (C) 2004 S. Karger AG, Basel.	Uppsala Univ, Signal & Syst Grp, SE-75120 Uppsala, Sweden; Natl Food Adm Toxicol Lab, Div Toxicol, Uppsala, Sweden	Gustafsson, MG (reprint author), Uppsala Univ, Signal & Syst Grp, POB 528, SE-75120 Uppsala, Sweden.	mg@signal.uu.se					Aalberse RC, 2000, J ALLERGY CLIN IMMUN, V106, P228, DOI 10.1067/mai.2000.108434; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Ayuso R, 2002, INT ARCH ALLERGY IMM, V127, P27, DOI 10.1159/000048166; Bailey T, 1994, ISMB, V2, P28; Bailey TL, 2002, J COMPUT BIOL, V9, P575, DOI 10.1089/106652702760138637; Bailey TL, 1998, J COMPUT BIOL, V5, P211, DOI 10.1089/cmb.1998.5.211; Bernstein JA, 2003, ENVIRON HEALTH PERSP, V111, P1114; Boeckmann B, 2003, NUCLEIC ACIDS RES, V31, P365, DOI 10.1093/nar/gkg095; Dayhoff M. O., 1978, ATLAS PROTEIN SEQ S3, V5, P345; FAO/WHO, 2001, EV ALL GEN MOD FOODS; GANDER ES, 1991, PLANT MOL BIOL, V16, P437, DOI 10.1007/BF00023994; Gendel SM, 1998, ADV FOOD NUTR RES, V42, P45, DOI 10.1016/S1043-4526(08)60092-3; Gendel SM, 2002, ANN NY ACAD SCI, V964, P87; GOLDSTEIN RA, 1992, P NATL ACAD SCI USA, V89, P4918, DOI 10.1073/pnas.89.11.4918; Hastie T., 2001, ELEMENTS STAT LEARNI; HENIKOFF S, 1992, P NATL ACAD SCI USA, V89, P10915, DOI 10.1073/pnas.89.22.10915; Hileman RE, 2002, INT ARCH ALLERGY IMM, V128, P280, DOI 10.1159/000063861; Ivanciuc O, 2002, BIOINFORMATICS, V18, P1358, DOI 10.1093/bioinformatics/18.10.1358; Karwath A, 2002, BMC BIOINFORMATICS, V3, DOI 10.1186/1471-2105-3-11; Kleter Gijs A, 2002, BMC Struct Biol, V2, P8, DOI 10.1186/1472-6807-2-8; KROGH A, 1994, J MOL BIOL, V235, P1501, DOI 10.1006/jmbi.1994.1104; Lack G, 2002, CLIN EXP ALLERGY, V32, P1131, DOI 10.1046/j.1365-2222.2002.01464.x; Lambert B, 1996, APPL ENVIRON MICROB, V62, P80; Li WZ, 2001, BIOINFORMATICS, V17, P282, DOI 10.1093/bioinformatics/17.3.282; Lin K, 2001, J COMPUT BIOL, V8, P471, DOI 10.1089/106652701753216495; Metcalfe DD, 1996, CRIT REV FOOD SCI, V36, pS165; Ng PC, 2000, BIOINFORMATICS, V16, P760, DOI 10.1093/bioinformatics/16.9.760; Nielsen H, 1999, PROTEIN ENG, V12, P3, DOI 10.1093/protein/12.1.3; Park J, 1997, J MOL BIOL, V273, P349, DOI 10.1006/jmbi.1997.1288; Park J, 1998, J MOL BIOL, V284, P1201, DOI 10.1006/jmbi.1998.2221; PEARSON WR, 1988, P NATL ACAD SCI USA, V85, P2444, DOI 10.1073/pnas.85.8.2444; Pearson W R, 2000, Methods Mol Biol, V132, P185; ROBINSON C, 2001, GENETIC MODIFICATION; Rost B, 1999, PROTEIN ENG, V12, P85, DOI 10.1093/protein/12.2.85; Sampson HA, 1999, J ALLERGY CLIN IMMUN, V103, P717, DOI 10.1016/S0091-6749(99)70411-2; Sandberg M, 1998, J MED CHEM, V41, P2481, DOI 10.1021/jm9700575; Schwartz R. M., 1978, ATLAS PROTEIN SEQ S3, V5, P353; *SCI COMM PLANTS, 1998, OCC SEV FOOD ALL EU; Stadler MB, 2003, FASEB J, V17, P1141, DOI 10.1096/fj.02-1052fje; Teshima R, 2002, J FOOD HYG SOC JPN, V43, P273; Thompson JD, 1997, NUCLEIC ACIDS RES, V25, P4876, DOI 10.1093/nar/25.24.4876; Venkatarajan MS, 2001, J MOL MODEL, V7, P445, DOI 10.1007/s00894-001-0058-5; VINING DJ, 1992, RADIOGRAPHICS, V12, P1147; Webb AR, 2002, STAT PATTERN RECOGNI; YOUNG E, 1994, LANCET, V343, P1127, DOI 10.1016/S0140-6736(94)90234-8; Zhu J, 1998, BIOINFORMATICS, V14, P25, DOI 10.1093/bioinformatics/14.1.25; Zorzet Anna, 2002, In Silico Biology, V2, P525	47	35	36	KARGER	BASEL	ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND	1018-2438			INT ARCH ALLERGY IMM	Int. Arch. Allergy Immunol.		2004	133	2					101	112		10.1159/000076382		12	Allergy; Immunology	Allergy; Immunology	800LG	WOS:000220029200001	14739578	
