PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	PU	PI	PA	SN	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	PG	WC	SC	GA	UT
J	Piwowarski, B; Gallinari, P				Piwowarski, B; Gallinari, P			A Bayesian framework for XML information retrieval: Searching and learning with the INEX collection	INFORMATION RETRIEVAL			English	Article						Bayesian Networks; structured information retrieval; XML; machine learning for structured retrieval	MODEL; PERFORMANCE	Most recent document standards like XML rely on structured representations. On the other hand, current information retrieval systems have been developed for flat document representations and cannot be easily extended to cope with more complex document types. The design of such systems is still an open problem. We present a new model for structured document retrieval which allows computing scores of document parts. This model is based on Bayesian networks whose conditional probabilities are learnt from a labelled collection of structured documents-which is composed of documents, queries and their associated assessments. Training these models is a complex machine learning task and is not standard. This is the focus of the paper: we propose here to train the structured Bayesian Network model using a cross-entropy training criterion. Results are presented on the INEX corpus of XML documents.	Univ Chile, Ctr Web Res, Santiago 2120, Chile; LIP 6, F-75015 Paris, France	Piwowarski, B (reprint author), Univ Chile, Ctr Web Res, Santiago 2120, Chile.	bpiwowar@dcc.uchile.cl; gallinar@poleia.lip6.fr					CRESTANI F, 2003, 7 EUR C ECSQARU 2003, P74; Crestani F, 2003, LECT NOTES COMPUT SC, V2857, P168; Culioli J. C., 1994, INTRO OPTIMISATION; CULLAN JP, 1992, P 3 INT C DAT EXP SY, P78; de Campos LM, 2003, INT J APPROX REASON, V34, P265, DOI 10.1016/j.ijar.2003.07.011; De Campos LM, 2003, INT J UNCERTAIN FUZZ, V11, P101, DOI 10.1142/S0218488503002296; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; FUHR N, 2003, P 2 INEX WORKSH; FUHR N, 1998, P 6 INT C EXT DAT TE; GOVERT N, 2003, EVALUATING EFFECTIVE; GOVERT N, 2002, P 1 ANN WORKSH IN EV; INDRAWAN M, 1994, ACIS 5 AUSTR C INF S, P259; Jensen F., 1996, INTRO BAYESIAN NETWO; KAZAI G, 2003, P 2 INEX WORKSH; KAZIA G, 2004, P 2 INEX WORKSH; Krause PJ, 1998, KNOWL ENG REV, V13, P321; Lalmas M, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P110, DOI 10.1145/258525.258546; Myaeng S. H., 1998, P 21 ANN INT ACM SIG, P138, DOI 10.1145/290941.290980; Pearl J., 1988, PROBABILISTIC REASON; PIWOWARSKI B, 2003, P 2 INEX WORKSH DAGS; PIWOWARSKI B, 2004, P 13 C INF KNOWL MAN; Ribeiro-Neto B. A., 1996, P 19 ANN INT ACM SIG, P253, DOI 10.1145/243199.243272; Robertson S, 2002, INFORM RETRIEVAL, V5, P239, DOI 10.1023/A:1015702129514; WALKER S, 1999, NIST SPECIAL PUBLICA; Wilkinson R, 1994, P 17 ANN INT ACM SIG, P311	25	2	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1386-4564		INFORM RETRIEVAL	Inf. Retr.	DEC	2005	8	4					655	681		10.1007/s10791-005-0751-6		27	Computer Science, Information Systems	Computer Science	924LD	WOS:000228979400007	
J	Street, WN				Street, WN			Oblique multicategory decision trees using nonlinear programming	INFORMS JOURNAL ON COMPUTING			English	Article						artificial intelligence; programming; nonlinear; applications; machine learning; decision trees	MISCLASSIFICATION MINIMIZATION; SEPARATION	Induction of decision trees is a popular and effective method for solving classification problems in data-mining applications. This paper presents a new algorithm for multi-category decision tree induction based on nonlinear programming. This algorithm, termed OC-SEP (Oblique Category SEParation), combines the advantages of several other methods and shows improved generalization performance on a collection of real-world data sets.	Univ Iowa, Dept Management Sci, Iowa City, IA 52242 USA	Street, WN (reprint author), Univ Iowa, Dept Management Sci, S232 Pappajohn Business Bldg, Iowa City, IA 52242 USA.	nick-street@uiowa.edu					Bennet K.-P., 1992, P 4 MIDW ART INT COG, P97; Bennet K. P., 1997, INFORMS Journal on Computing, V9, DOI 10.1287/ijoc.9.3.311; Bennett K.P., 2000, GEOMETRY WORK, P132; Bennett K.P, 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; Biggs M. C., 1975, GLOBAL OPTIMIZATION, P341; Blake C. L., 1998, UCI REPOSITORY MACHI; Bradley P. S., 1998, INFORMS Journal on Computing, V10, DOI 10.1287/ijoc.10.2.209; Bradley PS, 1999, INFORMS J COMPUT, V11, P217, DOI 10.1287/ijoc.11.3.217; Breiman L, 1984, CLASSIFICATION REGRE; BRODLEY CE, 1995, P 12 INT C MACH LEAR, P73; Chen CH, 1995, MATH PROGRAM, V71, P51, DOI 10.1007/BF01592244; Chen CH, 1996, ADV COMPUT MATH, V5, P127, DOI 10.1007/BF02124738; Coleman T., 1999, OPTIMIZATION TOOLBOX; FAYYAD UM, 1992, P 11 NAT C ART INT S, P322; FAYYAD UM, 1991, THESIS U MICHIGAN; Fayyad U.M., 1996, ADV KNOWLEDGE DISCOV; GLOVER F, 1990, DECISION SCI, V21, P771, DOI 10.1111/j.1540-5915.1990.tb01249.x; Hertz J., 1991, INTRO THEORY NEURAL; MANGASARIAN OL, 1994, J GLOBAL OPTIM, V5, P309, DOI 10.1007/BF01096681; MANGASAR.OL, 1965, OPER RES, V13, P444, DOI 10.1287/opre.13.3.444; Mangasarian O. L., 1993, ORSA Journal on Computing, V5; MANGASAR.OL, 1968, IEEE T INFORM THEORY, V14, P801, DOI 10.1109/TIT.1968.1054229; MOONEY R, 1989, P 11 INT JOINT C ART, P775; Murthy S.K., 1994, J ARTIFICIAL INTELLI, V2, P1; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; STONE M, 1974, J R STAT SOC B, V36, P111; Vapnik V. N, 1995, NATURE STAT LEARNING	28	2	2	INFORMS	LINTHICUM HTS	901 ELKRIDGE LANDING RD, STE 400, AIPORT SQUARE, LINTHICUM HTS, MD 21090-2908 USA	1091-9856		INFORMS J COMPUT	INFORMS J. Comput.	WIN	2005	17	1					25	31		10.1287/ijoc/1030.0047		7	Computer Science, Interdisciplinary Applications; Operations Research & Management Science	Computer Science; Operations Research & Management Science	911PK	WOS:000228016400004	
J	Li, DC; Wu, CS; Chang, FMM				Li, DC; Wu, CS; Chang, FMM			Using data-fuzzification technology in small data set learning to improve FMS scheduling accuracy	INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY			English	Article						ANFIS; flexible manufacturing system; machine learning; scheduling; small data set	MANUFACTURING SYSTEMS; DECISION TREE; KNOWLEDGE; IDENTIFICATION; SIMULATION; NETWORK; ANFIS; TOOL	Production decisions in real dynamic flexible manufacturing systems (FMS), especially in the early stages are often made with limited information. Information is limited because scheduling knowledge is hard to establish in such an environment. Though the machine learning technique in the field of Artificial Intelligence is thus used for this task by many researchers, this research is aimed at increasing the accuracy of machine learning for FMS scheduling using small data sets. Approaches used include data-fuzzifying, domain range expansion, and the application of adaptive-network-based fuzzy inference systems (ANFIS). The results indicate that learning accuracy under this strategy is significantly better than that of a traditional crisp data neural networks.	Natl Cheng Kung Univ, Dept Ind & Informat Management, Tainan 701, Taiwan; Tungfang Inst Technol, Dept Ind Engn & Management, Kaohsiung, Taiwan	Li, DC (reprint author), Natl Cheng Kung Univ, Dept Ind & Informat Management, 1 Ta Hsueh Rd, Tainan 701, Taiwan.	lidc@mail.ncku.edu.tw					Chen LH, 1996, IEEE COMMUN MAG, V34, P6; JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541; Li DC, 2003, INT J PROD RES, V41, P4011, DOI 10.1080/0020754031000149211; Li DC, 1997, INT J SYST SCI, V28, P977, DOI 10.1080/00207729708929461; Li DC, 1996, EUR J OPER RES, V88, P404, DOI 10.1016/0377-2217(94)00196-0; Lo SP, 2002, INT J ADV MANUF TECH, V19, P564, DOI 10.1007/s001700200061; NAKASUKA S, 1992, INT J PROD RES, V30, P411, DOI 10.1080/00207549208942903; PIERREVAL H, 1990, J OPER RES SOC, V41, P461, DOI 10.2307/2583031; Priore P, 2001, AI EDAM, V15, P251, DOI 10.1017/S0890060401153059; Quinlan JR, 1996, ACM COMPUT SURV, V28, P71, DOI 10.1145/234313.234346; Sabuncuoglu I, 2002, INT J PROD RES, V40, P2483, DOI 10.1080/00207540210135596; SHAW MJ, 1992, IIE TRANS, V24, P2, DOI 10.1080/07408179208964219; LI DC, 1994, INT J PROD RES, V32, P2187; SRINIVASAN M, 1997, INT J PROD RES, V35, P1759; SUGENO M, 1988, FUZZY SET SYST, V28, P15, DOI 10.1016/0165-0114(88)90113-3; Sun YL, 1996, INT J PROD RES, V34, P2353, DOI 10.1080/00207549608905029; TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116; Takagi T., 1983, P IFAC S FUZZ INF KN, P55	18	15	15	SPRINGER LONDON LTD	GODALMING	SWEETAPPLE HOUSE CATTESHALL ROAD, GODALMING GU7 3DJ, SURREY, ENGLAND	0268-3768		INT J ADV MANUF TECH	Int. J. Adv. Manuf. Technol.	DEC	2005	27	3-4					321	328		10.1007/s00170-003-2184-y		8	Automation & Control Systems; Engineering, Manufacturing	Automation & Control Systems; Engineering	986QL	WOS:000233464700015	
J	Vrakas, D; Vlahavas, I				Vrakas, D; Vlahavas, I			A visualization environment for planning	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS			English	Article						automated planning; graphical interfaces; machine learning; knowledge engineering	HEURISTIC-SEARCH; SYSTEM	This article presents ViTAPlan-2, a visual tool for adaptive planning that is build on top of HAPRC, a rule-configurable planning system, which automatically adapts to each problem, in order to achieve best performance. Apart from HAPRC, ViTAPlan can be interfaced with any other planning system that supports the PDDL language. More than just being a user friendly environment for executing the underlying planner, the tool serves as a unified planning environment for encoding a new problem problem, solving it, visualizing the solution and monitoring its execution on a simulation of the problem's word. The tool consists of various sub-systems, each one accompanied by a graphical interface, that collaborate with each other and assist the user, whether he is a knowledge engineer, a domain expert, an academic or even an end user in industry, to carry out complex planning tasks.	Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece	Vrakas, D (reprint author), Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.	dvrakas@csd.auth.gr; vlahavas@csd.auth.gr					BLUM A, 1995, P 14 INT C ART INT B, P636; Bonet B, 2001, ARTIF INTELL, V129, P5, DOI 10.1016/S0004-3702(01)00108-4; BOTEA A, 2005, IN PRESS J ARTIFICIA; Bourbakis N, 1997, J INTELL ROBOT SYST, V19, P321, DOI 10.1023/A:1007985805475; CHEN Y, 2005, J ARTIFICIAL INTELLG; CHIEN S, 2000, P SPAC 2000 TOUL FRA; Fox M, 2003, J ARTIF INTELL RES, V20, P61; GEREVINI A, 2004, INT PLANNING COMPETI; Gerevini A, 2003, J ARTIF INTELL RES, V20, P239; GHALLAB M, 1988, PDDL PLANNING DOMAIN; Hoffmann J, 2003, J ARTIF INTELL RES, V20, P291; Hoffmann J, 2001, J ARTIF INTELL RES, V14, P253; Kautz H, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1194; KAUTZ H, 1998, P AIPS 98 WORKSH PLA, P58; Kosara R, 2001, ARTIF INTELL MED, V22, P111, DOI 10.1016/S0933-3657(00)00103-2; KUNDU K, 2002, P 3 INT NASA WORKSH; Long D, 1999, J ARTIF INTELL RES, V10, P87; McCluskey T. L., 2003, Proceedings, Thirteenth International Conference on Automated Planning and Scheduling; NGUYEN X, 2002, P 2000 INT C KNOWLED; Sanchez J, 2003, PROC INT C TOOLS ART, P274, DOI 10.1109/TAI.2003.1250201; TSOUMAKAS G, 2004, P 16 EUR C ART INT E, P693; VIDAL V, 2004, P 14 INT C AUT PLANN, P3; VRAKAS D, 2002, P 10 INT C ART INT M, P61; VRAKAS D, PACOPLAN PROJECT PAR; VRAKAS D, 2003, P DOCT CONS 13 INT C, P137; VRAKAS D, 2003, P 9 PANH C INF THESS, P167; Vrakas D., 2003, Proceedings, Thirteenth International Conference on Automated Planning and Scheduling; VRAKAS D, 2002, P 6 EUR C PLANN TOL, P1; Wilkins DE, 2003, J ARTIF INTELL RES, V18, P217	29	0	1	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-2130		INT J ARTIF INTELL T	Int. J. Artif. Intell. Tools	DEC	2005	14	6					975	998		10.1142/S0218213005002491		24	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	996BC	WOS:000234148400006	
J	Amato, R; Ciaramella, A; Del Mondo, C; De Vinco, L; Donalek, C; Longo, G; Miele, G; Raiconi, G; Staiano, A; Tagliaferri, R				Amato, R; Ciaramella, A; Del Mondo, C; De Vinco, L; Donalek, C; Longo, G; Miele, G; Raiconi, G; Staiano, A; Tagliaferri, R			Novel techniques for microarray data analysis: Probabilistic Principal Surfaces and Competitive Evolution on Data	JOURNAL OF COMPUTATIONAL AND THEORETICAL NANOSCIENCE			English	Article						microarray data; data mining; latent variable models; evolutionary algorithms; visualization; clustering	SELF-ORGANIZING MAPS; GENE-EXPRESSION; PATTERNS; MODEL	Microarrays are among the most powerful tools in biological research, but in order to attain its full potentialities, it is imperative to develop techniques capable to effectively exploit the huge quantity of data which they produce. In this paper two machine learning methodologies for microarray data analysis are proposed: (1) Probabilistic Principal Surfaces (PPS), which is a nonlinear latent variable model which offers very appealing visualization and classification abilities and can be effectively employed for clustering purposes. More specifically, the PPS method builds a probability density function of a given data set of patterns, lying in a D-dimensional space (with D >> 3), expressed in terms of a fixed number of latent variables, lying in a Q-dimensional space (Q is usually 2 or 3), which can be used (after a proper manipulation) to visualize, classify and cluster the data; (2) Competitive Evolution on Data (CED) is instead an evolutionary system in which the possible solutions (cluster centroids) compete to conquer the largest possible number of resources (data) and thus partition the input data set in clusters. We discuss the application of both methods to the analysis of microarray data obtained for the yeast genome.	Univ Salerno, Dept Math & Informat, Fisciano, Sa, Italy; Univ Naples Federico II, Dept Phys Sci, Naples, Italy; Univ Naples Federico II, Dept Math & Applicat, Naples, Italy; Ist Nazl Fis Nucl, Italian Inst Nucl Phys, Unit Naples, I-80125 Naples, Italy; INAF, Italian Inst Astrophys, Naples, Italy	Staiano, A (reprint author), Univ Salerno, Dept Math & Informat, Fisciano, Sa, Italy.		Miele, Gennaro/F-3628-2010; Staiano, Antonino/B-6781-2013	Staiano, Antonino/0000-0002-4708-5860			AMATO R, 2005, UNPUB BIOINFORMATIC; Bishop C., 1999, LEARNING GRAPHICAL M; BISHOP CM, 1998, GTM GENERATIVE TOPOG; Bishop C.M., 1995, NEURAL NETWORKS PATT; Bishop CM, 1998, IEEE T PATTERN ANAL, V20, P281, DOI 10.1109/34.667885; Chang K, 2001, IEEE T PATTERN ANAL, V23, P22; CHANG K, 2000, THESIS DEP ELECT COM; DELMONDO C, 2004, IN PRESS; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Forrest S, 1993, EVOL COMPUT, V1, P191, DOI 10.1162/evco.1993.1.3.191; Lesk A. M., 2002, INTRO BIOINFORMATICS; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; STAIANO A, 2004, MML04 MATH METH LEAR; STAIANO A, 2003, THESIS U SALERNO ITA; STAIANO A, 2004, ICDM 04 4 IEEE INT C, P202; Tagliaferri R, 1999, ASTRON ASTROPHYS SUP, V137, P391, DOI 10.1051/aas:1999254; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; TINO P, IN PRESS IEEE T PATT; Toronen P, 1999, FEBS LETT, V451, P142, DOI 10.1016/S0014-5793(99)00524-4	19	0	0	AMER SCIENTIFIC PUBLISHERS	STEVENSON RANCH	25650 NORTH LEWIS WAY, STEVENSON RANCH, CA 91381-1439 USA	1546-1955		J COMPUT THEOR NANOS	J. Comput. Theor. Nanosci.	DEC	2005	2	4					514	523		10.1166/jctn.2005.006		10	Chemistry, Multidisciplinary; Nanoscience & Nanotechnology; Materials Science, Multidisciplinary; Physics, Applied; Physics, Condensed Matter	Chemistry; Science & Technology - Other Topics; Materials Science; Physics	992XG	WOS:000233916700006	
J	Venayagamoorthy, GK; Singhal, G				Venayagamoorthy, GK; Singhal, G			Quantum-Inspired Evolutionary Algorithms and Binary Particle Swarm Optimization for training MLP and SRN neural networks	JOURNAL OF COMPUTATIONAL AND THEORETICAL NANOSCIENCE			English	Article						Quantum-Inspired Evolutionary Algorithms; Particle Swarm Optimization; Multilayer Perceptron; Simultaneous Recurrent Neural Network; binary training algorithms		This paper presents a comparison of two machine learning methods inspired by nano-scale and macro-scale natural processes and related to distributed intelligence, namely Quantum-Inspired Evolutionary Algorithm (QEA) and Binary Particle Swarm Optimization (BPSO). QEA is based on the concepts and principles of Quantum Computing, such as a quantum bit (Q-bit) and superposition of states. QEA uses a Q-bit for the probabilistic representation and a Q-bit individual as a string of Q-bits. A modified QEA with less memory requirements is also presented. The effectiveness of these algorithms in binary search space are compared for training neural networks. Results are presented for Multilayer Perceptrons (MLPs) and Simultaneous Recurrent Neural Networks (SRNs). For neural networks trained on complex nonlinear functions, the QEA based algorithms achieve convergence faster than BPSO.	Univ Missouri, Real Time Power & Intelligent Syst Lab, Dept Elect & Comp Engn, Rolla, MO 65409 USA	Venayagamoorthy, GK (reprint author), Univ Missouri, Real Time Power & Intelligent Syst Lab, Dept Elect & Comp Engn, Rolla, MO 65409 USA.						COLLIN P, 1998, EXPLORATIONS QUANTUM; Dasgupta D., 1997, EVOLUTIONARY ALGORIT; FOGEL D. B., 2000, EVOLUTIONARY COMPUTA; Hagan M.T., 1996, NEURAL NETWORK DESIG; Han KH, 2002, IEEE T EVOLUT COMPUT, V6, P580, DOI 10.1109/TEVC.2002.804320; Hey T, 1999, COMPUT CONTROL ENG J, V10, P105, DOI 10.1049/cce:19990303; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Jinli M., 2000, P 3 WORLD C INT CONT, V2, P839; Kennedy J., 1997, P IEEE INT C SYST MA, V5, P4104; Kennedy J., 2001, SWARM INTELLIGENCE; Kennedy J., 1995, P IEEE INT C NEUR NE, V4, P1942, DOI DOI 10.1109/ICNN.1995.488968; SANTOS J, 1994, P IEEE WORLD C COMP, V2, P759; SERPELL R, 1977, I COMP HUMAN DEV Q N, V1, P11; Shi Y., 1998, P IEEE INT C EV COMP, P69, DOI DOI 10.1109/ICEC.1998.699146; VENAYAGAMOORTHY GK, 2004, C NEUR COMP EV INT A, P28; WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337; WERBOS PJ, 1996, P WORLD C NEUR NETW, P88; Whitley D., 1995, GENETIC ALGORITHMS E, P191; Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585893	19	6	7	AMER SCIENTIFIC PUBLISHERS	STEVENSON RANCH	25650 NORTH LEWIS WAY, STEVENSON RANCH, CA 91381-1439 USA	1546-1955		J COMPUT THEOR NANOS	J. Comput. Theor. Nanosci.	DEC	2005	2	4					561	568		10.1166/jctn.2005.011		8	Chemistry, Multidisciplinary; Nanoscience & Nanotechnology; Materials Science, Multidisciplinary; Physics, Applied; Physics, Condensed Matter	Chemistry; Science & Technology - Other Topics; Materials Science; Physics	992XG	WOS:000233916700011	
J	Hara, A; Ichimura, T; Yoshida, K				Hara, A; Ichimura, T; Yoshida, K			Discovering multiple diagnostic rules from coronary heart disease database using automatically defined groups	JOURNAL OF INTELLIGENT MANUFACTURING			English	Article						evolutionary computation; genetic programming; multi-agent system; rule extraction		Much of the research on extracting rules from a large amount of data has focused on the extraction of a general rule that covers as many data as possible. In the field of health care, where people's lives are at stake, it is necessary to diagnose appropriately without overlooking the small number of patients who show different symptoms. Thus, the exceptional rules for rare cases are also important. From such a viewpoint, multiple rules, each of which covers a part of the data, are needed for covering all data. In this paper, we describe the extraction of such multiple rules, each of which is expressed by a tree structural program. We consider a multi-agent approach to be effective for this purpose. Each agent has a rule that covers a part of the data set, and multiple rules which cover all data are extracted by multi-agent cooperation. In order to realize this approach, we propose a new method for rule extraction using Automatically Defined Groups (ADG). The ADG, which is based on Genetic Programming, is an evolutionary optimization method of multi-agent systems. By using this method, we can acquire both the number of necessary rules and the tree structural programs which represent these respective rules. We applied this method to a database used in the machine learning field and showed its effectiveness. Moreover, we applied this method to medical data and developed a diagnostic system for coronary heart diseases.	Hiroshima Univ, Fac Informat Sci, Asaminami Ku, Hiroshima 7313194, Japan; St Marianna Univ, Sch Med, Dept Prevent Med, Miyamae Ku, Kawasaki, Kanagawa 2168511, Japan	Hara, A (reprint author), Hiroshima Univ, Fac Informat Sci, Asaminami Ku, 3-4-1 Ozuka Higashi, Hiroshima 7313194, Japan.	ahara@its.hiroshima-cu.ac.jp; ichimura@its.hiroshima-cu.ac.jp; k2yosida@marianna-u.ac.jp					Goldberg DE, 1989, GENETIC ALGORITHMS S; Hara A., 2002, International Journal of Computational Intelligence and Applications, V2, DOI 10.1142/S1469026802000749; HARA A, 2003, P 7 C KNOWL BAS INT, V2, P1405; HARA A, 2004, KNOWLEDGE BASED INTE, P51; HARA A, 1999, P 1999 GECCO, P1039; HAYNES T, 1995, GENETIC ALGORITHMS, P271; HOLLAND JH, 1995, ADAPTATION NATURAL A; IBA H, 1996, PARALLEL PROBLEM SOL, V4, P32; Iba H., 1997, Genetic Programming 1997 Proceedings of the Second Annual Conference; ICHIMURA T, 2003, P 7 C KNOWL BAS INT, V2, P373; ICHIMURA T, 1995, INT J BIOMED COMPUT, V40, P139, DOI 10.1016/0020-7101(95)01138-5; ICHIMURA T, 2001, J BIOMEDICAL FUZZY S, V7, P19; Koza J. R., 1992, GENETIC PROGRAMMING; Luke S., 1996, Genetic Programming. Proceedings of the First Annual Conference 1996; SOULE T, 1999, P GEN EV COMP C GECC, P916; SOULE T, 2000, P GEN EV COMP C GECC, P778; SUKA M, 2004, P 8 C KNOWL BAS INT; Thrun S, 1991, CMUCS91197	18	5	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0956-5515		J INTELL MANUF	J. Intell. Manuf.	DEC	2005	16	6					645	661		10.1007/s10845-005-4368-9		17	Computer Science, Artificial Intelligence; Engineering, Manufacturing	Computer Science; Engineering	980UK	WOS:000233043500008	
J	D'Avila Garcez, AS; Gabbay, DM; Lamb, LC				D'Avila Garcez, AS; Gabbay, DM; Lamb, LC			Value-based argumentation frameworks as neural-symbolic learning systems	JOURNAL OF LOGIC AND COMPUTATION			English	Article						neural-symbolic systems; value-based argumentation frameworks; hybrid systems	NETWORKS	While neural networks have been successfully used in a number of machine learning applications, logical languages have been the standard for the representation of argumentative reasoning. In this paper, we establish a relationship between neural networks and argumentation networks, combining reasoning and learning in the same argumentation framework. We do so by presenting a new neural argumentation algorithm, responsible for translating argumentation networks into standard neural networks. We then show a correspondence between the two networks. The algorithm works not only for acyclic argumentation networks, but also for circular networks, and it enables the accrual of arguments through learning as well as the parallel computation of arguments.	City Univ London, Dept Comp, London EC1V 0HB, England; Kings Coll London, Dept Comp Sci, London WC2R 2LS, England; Univ Fed Rio Grande do Sul, Inst Informat, BR-91501970 Porto Alegre, RS, Brazil	D'Avila Garcez, AS (reprint author), City Univ London, Dept Comp, London EC1V 0HB, England.	aag@soi.city.ac.uk; dg@dcs.kcl.ac.uk; LuisLamb@acm.org					Antoniou G., 1997, NONMONOTONIC REASONI; APT KR, 1993, INFORM COMPUT, V106, P109, DOI 10.1006/inco.1993.1051; BARRINGER H, 2005, MECH MATH REASONING, P59; Bench-Capon TJM, 2003, J LOGIC COMPUT, V13, P429, DOI 10.1093/logcom/13.3.429; Besnard P., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); Bondarenko A, 1997, ARTIF INTELL, V93, P63, DOI 10.1016/S0004-3702(97)00015-5; BOSE NK, 1996, NEURAL NETWORKS FUND; Brewka G, 2001, J LOGIC COMPUT, V11, P257, DOI 10.1093/logcom/11.2.257; Chesnevar CI, 2000, ACM COMPUT SURV, V32, P337, DOI 10.1145/371578.371581; d'Avila Garcez A. S., 2002, NEURAL SYMBOLIC LEAR; DUNG PM, 1995, ARTIF INTELL, V77, P321, DOI 10.1016/0004-3702(94)00041-X; GABBAY DM, 2003, PHI NEWS, V4, P5; GARCEZ AD, 2004, P 19 NAT C ART INT; Garcez ASD, 2001, ARTIF INTELL, V125, P155; GARCEZ ASD, 2004, INT J ARTIFICIAL INT, V13, P115; Garcez ASD, 2004, ADV NEUR IN, V16, P921; Garcia AJ, 2004, THEOR PRACT LOG PROG, V4, P95, DOI 10.1017/S1471068403001674; Gelfond M., 1988, P 5 INT C LOG PROGR, P1070; HAENNI R, 2000, HDB DEFEASIBLE REASO; Haykin S., 1999, NEURAL NETWORKS COMP; Kowalski R. A., 1996, Artificial Intelligence and Law, V4, DOI 10.1007/BF00118494; Lloyd J.W., 1987, FDN LOGIC PROGRAMMIN; Mitchell T, 1997, MACHINE LEARNING; NUTE D, 1994, HDB LOGIC ARTIFICIAL, V3, P355; olldobler S. H, 1994, P ECAI94 WORKSH COMB, P68; POLLOCK JL, 1987, COGNITIVE SCI, V11, P481, DOI 10.1207/s15516709cog1104_4; Pollock John, 1991, MIND MACH, V1, P367, DOI 10.1007/BF00352916; PRAKKEN H, 2000, HDB PHLOSOPHICAL LOG; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1, P318; TOWELL GG, 1994, ARTIF INTELL, V70, P119, DOI 10.1016/0004-3702(94)90105-8; Valiant LG, 2003, J ACM, V50, P96, DOI 10.1145/602382.602410; VERHEIJ B, 1996, THESIS MASTRICHT U H; Verheij Bart, 1995, P 2 DUTCH GERM WORKS, P217; Vreeswijk GAW, 1997, ARTIF INTELL, V90, P225, DOI 10.1016/S0004-3702(96)00041-0; WILLIAMSON J, 2004, LAWS MODELS SCI	35	9	9	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0955-792X		J LOGIC COMPUT	J. Logic Comput.	DEC	2005	15	6					1041	1058		10.1093/logcom/exi057		18	Computer Science, Theory & Methods; Logic	Computer Science; Science & Technology - Other Topics	991WD	WOS:000233844300007	
J	Ramirez, R; Hazan, A; Gomez, E; Maestre, E; Serra, X				Ramirez, R; Hazan, A; Gomez, E; Maestre, E; Serra, X			Discovering expressive transformation rules from saxophone jazz performances	JOURNAL OF NEW MUSIC RESEARCH			English	Article							MUSIC	If-then rules are one of the most expressive and intuitive knowledge representations and their application to represent musical knowledge raises particularly interesting questions. In this paper, we describe an approach to learning expressive performance rules from monophonic recordings of jazz standards by a skilled saxophonist. We have first developed a melodic transcription system which extracts a set of acoustic features from the recordings producing a melodic representation of the expressive performance played by the musician. We apply machine learning techniques, namely inductive logic programming, to this representation in order to induce first order logic rules of expressive music performance.	Pompeu Fabra Univ, Mus Technol Grp, Barcelona 08003, Spain	Ramirez, R (reprint author), Pompeu Fabra Univ, Mus Technol Grp, Ocata 1, Barcelona 08003, Spain.	rafael@iua.upf.es	Gomez, Emilia/F-4485-2010	Gomez, Emilia/0000-0003-4983-3989			BRESIN R, 2002, P 2001 INT COMP MUS, P294; Canazza S., 1997, P 1997 INT COMP MUS, P113; Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866; COLMERAUER A, 1990, COMMUN ACM, V33, P69, DOI 10.1145/79204.79210; Dannenberg RB, 1998, J NEW MUSIC RES, V27, P211, DOI 10.1080/09298219808570747; de Mantaras RL, 2002, AI MAG, V23, P43; DOVEY MJ, 1995, P 8 EUR C MACH LEARN, P279; FRIBERG A, 1998, J NEW MUSIC RES, V27, P217; Friberg A, 2000, J NEW MUSIC RES, V29, P199, DOI 10.1076/jnmr.29.3.199.3093; GABRIELSSON A, 1999, PSYCHOL MUSIC; GOMEZ E, 2003, P 114 AUD ENG SOC CO; GOMEZ E, 2003, P STOCKH MUS AC C; IGARASHI S, 2002, P 2 INT C MUS ART IN; Johnson M. L., 1992, READINGS COMPUTER GE, P41; KLAPURI A, 1999, P IEEE INT C AC SPEE; MAHER RC, 1994, J ACOUST SOC AM, V95, P2254, DOI 10.1121/1.408685; McNab R.J., 1996, P 19 AUSTR COMP SCI, P301; Mitchell T, 1997, MACHINE LEARNING; Morales EF, 1997, MACH LEARN, V26, P227, DOI 10.1023/A:1007373508948; NARMOUR E, 1990, ANAL COGNITION BASIS; Narmour E., 1991, ANAL COGNITION MELOD; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; RAMIREZ R, 2005, P INT COMP MUS C 200; RAMIREZ R, 2004, P 10 INT C KNOWL DIS; RAMIREZ R, 2005, P 18 FLOR ART INT RE; REPP BH, 1992, J ACOUST SOC AM, V92, P25; Shapiro E.Y., 1983, ALGORITHMIC PROGRAM; Srinivasan A., 2001, ALEPH MANUAL; Tobudic A., 2003, P INT C IND LOG PROG, P365; TODD N, 1992, J ACOUST SOC AM, V91, P35; VANBAELEN E, 1996, INT C IND LOG PROGR, P55; Widmer G, 2002, J NEW MUSIC RES, V31, P37, DOI 10.1076/jnmr.31.1.37.8103; WIDMER G, 2001, P 12 EUR C MACH LEAR; WIDMER G, 2002, P 5 INT C DISC SCI D	35	4	4	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXFORDSHIRE, ENGLAND	0929-8215		J NEW MUSIC RES	J. New Music Res.	DEC	2005	34	4					319	330		10.1080/09298210600578097		12	Computer Science, Interdisciplinary Applications; Music	Computer Science; Music	048ST	WOS:000237967500002	
J	Van Someren, M; Urbancic, T				Van Someren, Maarten; Urbancic, Tanja			Applications of machine learning: matching problems to tasks and methods	KNOWLEDGE ENGINEERING REVIEW			English	Review							MEDICAL DIAGNOSIS; HEART-DISEASE; REAL-WORLD; DISCOVERY; SYSTEMS; RECOVERY; SLOVENIA	The terminology of Machine Learning and Data Mining methods does not always allow a simple match between practical problems and methods. While some problems look similar from the user's point of view, but require different methods to be solved, some others look very different, yet they can be solved by applying the same methods and tools. Choosing appropriate Machine Learning methods for problem solving in practice is therefore largely a matter of experience and it is not realistic to expect a simple look-up table with matches between problems and methods. However, some guidelines can be given and a collection that summarizes other people's experience can also be helpful. A small number of definitions characterize the tasks that are performed by a large proportion of methods. Most of the variation in methods is concerned with differences in data types and algorithmic aspects of methods. In this paper, we summarize the main task types and illustrate how a wide variety of practical problems are formulated in terms of these tasks. The match between problems and tasks is illustrated with a collection of example applications with the aim of helping to express new practical problems as Machine Learning tasks. Some tasks can be decomposed into subtasks, allowing a wider variety of matches between practical problems and (combinations of) methods. We review the main principles for choosing between alternatives and illustrate this with a large collection of applications. We believe that this provides some guidelines.	Univ Amsterdam, NL-1098 VA Amsterdam, Netherlands; Nova Gorica Polytech, SI-5001 Nova Gorica, Slovenia; Jozef Stefan Inst, SI-1000 Ljubljana, Slovenia	Van Someren, M (reprint author), Univ Amsterdam, Kruislaan 419, NL-1098 VA Amsterdam, Netherlands.	maarten@science.uva.nl; tanja.urbancic@p-ng.si					Adriaans Pieter, 1996, DATA MINING; Alberdi E, 1997, ARTIF INTELL, V91, P257, DOI 10.1016/S0004-3702(97)00010-6; AMACHO R, 1998, P 10 EUR C MACH LEAR; Andrews PJD, 2002, J NEUROSURG, V97, P326, DOI 10.3171/jns.2002.97.2.0326; ANDROTSOPOULOS I, 2000, P C MACH LEARN NEW I; Arcos JL, 2001, APPL INTELL, V14, P115, DOI 10.1023/A:1008311209823; Blockeel H, 2004, APPL ARTIF INTELL, V18, P157, DOI 10.1080/08839510490279131; Bratko I, 2002, LECT NOTES ARTIF INT, V2358, P812; BRATKO I, 1998, MACHINE LEARNING DAT, P131; BRATKO I, 1992, P INT C 5 GEN COMP S; BULITKO VV, 1999, P WORKSH MACH LEARN; CHAPMAN F, 2000, CRISP DM 1 0 STEP BY; Dalaka A, 2000, ECOL MODEL, V129, P245, DOI 10.1016/S0304-3800(00)00237-4; Debeljak M, 2001, ECOL MODEL, V138, P321, DOI 10.1016/S0304-3800(00)00411-7; DOLSAK B, 1998, MACHINE LEARNING DAT, P147; DZEROSKI S, 2002, HDB DATA MINING KNOW, P817; Dzeroski S, 1998, APPL ARTIF INTELL, V12, P363, DOI 10.1080/088395198117686; DZEROSKI S, 2003, P 6 INT C SAPP JAP O, P87; DZEROSKI S, 1998, P EUR C MACH LEARN, P61; Fawcett T, 1997, DATA MIN KNOWL DISC, V1, P291, DOI 10.1023/A:1009700419189; Fayyad U.M., 1996, ADV KNOWLEDGE DISCOV; Filipic B, 2000, COMPUT IND, V43, P31, DOI 10.1016/S0166-3615(00)00056-7; FLACH P, 2003, DATA MINING DECISION, P143; Gamberger D, 2003, ARTIF INTELL MED, V28, P27, DOI 10.1016/S0933-3657(03)00034-4; Gamberger D, 2004, J BIOMED INFORM, V37, P269, DOI 10.1016/j.jbi.2004.07.007; Gams M, 1997, ENG APPL ARTIF INTEL, V10, P41, DOI 10.1016/S0952-1976(96)00074-7; Han J., 2001, DATA MINING CONCEPTS; Hand D., 2001, PRINCIPLES DATA MINI; Jerina K, 2003, ECOL MODEL, V170, P453, DOI 10.1016/S0304-3800(03)00245-X; KING RD, 1995, NEW GENERAT COMPUT, V13, P411; KLEMA J, 1999, SYSTEMS INTEGRATION, P119; KNOBBE A, 1998, P BEN 1998, P31; KOENIG I, 1998, UITSTROOM GOED BEKEK; Kononenko I, 2001, ARTIF INTELL MED, V23, P89, DOI 10.1016/S0933-3657(01)00077-X; KONONENKO I, 1993, APPL ARTIF INTELL, V7, P317, DOI 10.1080/08839519308949993; KRAAKMAN A, 1998, P BEN 1998 WEG ATO D, P148; Krisper M., 1989, Proceedings of the IASTED International Symposium. Expert Systems Theory and Applications; Kukar M, 1996, ARTIF INTELL MED, V8, P431, DOI 10.1016/S0933-3657(96)00351-X; Kukar M, 1999, ARTIF INTELL MED, V16, P25, DOI 10.1016/S0933-3657(98)00063-3; Langley P., 1995, Communications of the ACM, V38, DOI 10.1145/219717.219768; LANGLEY P, 2001, MACHINE LEARNING ITS; LOPEZ MJJ, 2002, DEALING DATA FLOOD; MANAGO M, 1997, MACHINE LEARNING DAT; MEIJ J, 2002, DEALING DATA FLOOD; Michalski R. S., 1983, MACHINE LEARNING ART, P83; Michalski R. S., 1998, MACHINE LEARNING DAT; MICHIE D, 1995, P EUR C MACH LEARN S, P17; Middleton SE, 2004, ACM T INFORM SYST, V22, P54, DOI 10.1145/963770.963773; MISCHIATI M, 2000, P ECML 2000 BERL; MLADENIC D, 1993, DATA MINING DECISION, P15; MOCZULSKI W, 1999, MACHINE LEARNING DAT, P131; Morik K, 2000, ARTIF INTELL MED, V19, P225, DOI 10.1016/S0933-3657(00)00047-6; Morik K., 2003, INTELLIGENT TECHNOLO, P47; OLAVE M, 1988, OMEGA-INT J MANAGE S, V16, P353, DOI 10.1016/0305-0483(88)90072-2; Paass G, 1998, LECT NOTES ARTIF INT, V1394, P234; Paliouras G, 2001, MACHINE LEARNING ITS; PEEAR Z, 2002, THESIS U MARIBOR; Saitta L, 1998, MACH LEARN, V30, P133, DOI 10.1023/A:1007448122119; Sammut C., 1992, P 9 INT C MACH LEARN; Sanchez M, 1996, ARTIF INTELL ENG, V10, P275, DOI 10.1016/0954-1810(96)00004-0; SCHREIBER A Th, 2000, KNOWLEDGE ENG MANAGE; SMYTH B, 2000, J KNOWLEDGE BASED SY, V13, P53; Spiliopoulou M, 2001, DATA MIN KNOWL DISC, V5, P85, DOI 10.1023/A:1009800113571; Srinivasan A, 1999, DATA MIN KNOWL DISC, V3, P37, DOI 10.1023/A:1009815821645; Todorovski L, 1998, ECOL MODEL, V113, P71, DOI 10.1016/S0304-3800(98)00135-5; URBANCIC T, 1994, P 11 EUR C ART INT, P498; URBANCIC T, 1998, DP7806 IJS U LJUBLJ; Van Der Putten P., 1999, COMPLEXITY MANAGEMEN; VANDERPUTTEN P, 1999, INFORMATIE INFORMATI, V17, P15; VANDERPUTTEN P, 2000, 200009 I ADV COMP SC; Van der Putten P, 2004, MACH LEARN, V57, P177, DOI 10.1023/B:MACH.0000035476.95130.99; VANHOOF K, 1997, P ECML, P290; VASCONCELOS MH, 1999, WORKSH MACH LEARN AP; Verdenius F, 1997, AI COMMUN, V10, P3; Widmer G, 2003, J NEW MUSIC RES, V32, P259, DOI 10.1076/jnmr.32.3.259.16860; Widmer G, 2003, AI MAG, V24, P111; Zupan B, 2000, ARTIF INTELL MED, V20, P59, DOI 10.1016/S0933-3657(00)00053-1; *IDC, 2000, ICT NED; *KNOWL PROC SOFT, 2004, 67 KNOWL PROC SOFTW; *KNOWL PROC SOFTW, 2004, 215 KNOWL PROC SOFTW; *KNOWL PROC SOFTW, 2002, 128 KNOWL PROC SOFTW	81	2	2	CAMBRIDGE UNIV PRESS	NEW YORK	32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA	0269-8889		KNOWL ENG REV	Knowl. Eng. Rev.	DEC	2005	20	4					363	402		10.1017/S0269888906000762		40	Computer Science, Artificial Intelligence	Computer Science	052AC	WOS:000238201800002	
J	Klimovsky, A				Klimovsky, A			Learning and generalization errors for the 2D binary perceptron	MATHEMATICAL AND COMPUTER MODELLING			English	Article						binary perceptron; neural networks; machine learning; statistical mechanics		The statistical mechanics model of the binary perceptron learning is considered. It is proved that under the regularity conditions learning and generalization errors for the binary perceptron with two inputs tend to 0 at the average; the first term of the asymptotics is provided; its behavior with respect to the inverse temperature beta does not coincide with that for the model with a smooth activation function. (c) 2005 Elsevier Ltd. All rights reserved.	B Verkin Inst Low Temp Phys & Engn, Div Math, Kharkov, Ukraine; Tech Univ Berlin, Inst Math, D-10623 Berlin, Germany	Klimovsky, A (reprint author), B Verkin Inst Low Temp Phys & Engn, Div Math, Kharkov, Ukraine.	klimovsk@math.tu-berlin.de					CHERNOFF H, 1952, ANN MATH STAT, V23, P493, DOI 10.1214/aoms/1177729330; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; Ledoux M., 1991, PROBABILITY BANACH S; MENDELSON S, 1998, THESIS TECHNION; Pinkus A., 1999, Acta Numerica, V8, DOI 10.1017/S0962492900002919; Shcherbina M, 2002, MATH COMPUT MODEL, V35, P259, DOI 10.1016/S0895-7177(01)00163-7; Shcherbina M, 2003, COMMUN MATH PHYS, V234, P383, DOI 10.1007/s00220-002-0783-3; SOLLA SA, 1992, PHYS REV A, V46, P2124, DOI 10.1103/PhysRevA.46.2124; Talagrand M, 2002, MATH PHYS ANAL GEOM, V5, P77, DOI 10.1023/A:1015840632110; Talagrand M., 2003, SPIN GLASSES CHALLEN; Vapnik V., 1982, ESTIMATION DEPENDENC	11	0	0	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0895-7177		MATH COMPUT MODEL	Math. Comput. Model.	DEC	2005	42	11-12					1339	1358		10.1016/j.mcm.2004.09.010		20	Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	995AC	WOS:000234071300015	
J	Zhang, XHF; Leslie, CS; Chasin, LA				Zhang, XHF; Leslie, CS; Chasin, LA			Computational searches for splicing signals	METHODS			English	Article						pre-mRNA; splicing; exons; introns; pseudo exons; genomics; SVM; machine learning; splicing enhancers; splicing silencers; computation; statistics; ESE; ESS; ISE; ISS; SVM; statistics	PRE-MESSENGER-RNA; SUPPORT VECTOR MACHINE; EXON-INTRON DATABASE; GENE DISTRIBUTION; EXPRESSED GENES; HUMAN GENOME; SELECTION PRESSURE; SEQUENCE MOTIFS; DNA-SEQUENCE; IDENTIFICATION	The removal of introns from pre-mRNA requires as an initial event the accurate molecular recognition of the proper exon-intron borders. It is now evident that RNA sequence elements in addition to the consensus splice site sequences themselves are required for this recognition. Genomic analyses have contributed to the definition of these elements as exonic and intronic splicing enhancers and silencers, comprising what has been called the "splicing code." Many computational methods have been brought to bear in such studies. We describe here some of the methods we have used to discover functional splicing signals. What these methods have in common is a comparison of sequences in and around exons to sequences found elsewhere in the genome. We have especially made use of comparisons to "pseudo exons," intronic sequences resembling exons by virtue of being bounded by sequences indistinguishable from splice sites. Two computational strategies are emphasized: (1) the use of a machine learning technique in which a computational algorithm, a support vector machine, is first trained on known examples and then used to predict sequences associated with splicing; and (2) straight statistical analysis of differences between regions associated with exons and other regions in the genome. In most cases, the predictions made using these methods have been validated by subsequent empirical tests. An attempt has been made to make this description understandable by researchers unfamiliar with computational practice and to include practical references to specific databases and programs. (c) 2005 Elsevier Inc. All rights reserved.	Columbia Univ, Dept Biol Sci, New York, NY 10027 USA; Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Chasin, LA (reprint author), Columbia Univ, Dept Biol Sci, New York, NY 10027 USA.	lac2@columbia.edu	Zhang, Xiang/B-1522-2008				BERGET SM, 1995, J BIOL CHEM, V270, P2411; Bernardi G, 2000, GENE, V259, P31, DOI 10.1016/S0378-1119(00)00441-8; BRUNAK S, 1991, J MOL BIOL, V220, P49, DOI 10.1016/0022-2836(91)90380-O; Burge C, 1997, J MOL BIOL, V268, P78, DOI 10.1006/jmbi.1997.0951; Castillo-Davis CI, 2002, NAT GENET, V31, P415, DOI [10.1038/ng940, 10.1038/ng1011]; Cavaloc Y, 1999, RNA, V5, P468, DOI 10.1017/S1355838299981967; Clark F, 2002, HUM MOL GENET, V11, P451, DOI 10.1093/hmg/11.4.451; Coulter LR, 1997, MOL CELL BIOL, V17, P2143; Davuluri RV, 2001, NAT GENET, V29, P412, DOI 10.1038/ng780; D'Onofrio G, 2002, GENE, V300, P155, DOI 10.1016/S0378-1119(02)01048-X; Dror G, 2005, BIOINFORMATICS, V21, P897, DOI 10.1093/bioinformatics/bti132; DURET L, 1995, J MOL EVOL, V40, P308, DOI 10.1007/BF00163235; Eden E, 2004, NUCLEIC ACIDS RES, V32, P1131, DOI 10.1093/nar/gkh273; Elemento O, 2005, GENOME BIOL, V6, DOI 10.1186/gb-2005-6-2-r18; Eyre-Walker A, 2001, NAT REV GENET, V2, P549, DOI 10.1038/35080577; Fairbrother WG, 2002, SCIENCE, V297, P1007, DOI 10.1126/science.1073774; Fedorov A, 2001, NUCLEIC ACIDS RES, V29, P1464, DOI 10.1093/nar/29.7.1464; FICKETT JW, 1992, NUCLEIC ACIDS RES, V20, P6441, DOI 10.1093/nar/20.24.6441; Florea L, 1998, GENOME RES, V8, P967; Fu XD, 2004, CELL, V119, P736, DOI 10.1016/j.cell.2004.11.039; Gardiner K, 1996, TRENDS GENET, V12, P519, DOI 10.1016/S0168-9525(97)81400-X; GARDINERGARDEN M, 1994, J MOL ENDOCRINOL, V12, P365; Gopalan V, 2004, NUCLEIC ACIDS RES, V32, pD59, DOI 10.1093/nar/gkh051; Hsu F, 2005, NUCLEIC ACIDS RES, V33, pD454, DOI 10.1093/nar/gki100; Huang XQ, 1997, GENOMICS, V46, P37, DOI 10.1006/geno.1997.4984; Hubbard T, 2005, NUCLEIC ACIDS RES, V33, pD447, DOI 10.1093/nar/gki138; Joachims T., 1999, ADV KERNEL METHODS S; Karlin S, 1996, J MOL BIOL, V262, P459, DOI 10.1006/jmbi.1996.0528; Kent WJ, 2002, GENOME RES, V12, P656, DOI [10.1101/gr.229202, 10.1101/gr.229202. Article published online before March 2002]; Lander ES, 2001, NATURE, V409, P860, DOI 10.1038/35057062; Lim LP, 2001, P NATL ACAD SCI USA, V98, P11193, DOI 10.1073/pnas.201407298; Liu HX, 2000, MOL CELL BIOL, V20, P1063, DOI 10.1128/MCB.20.3.1063-1071.2000; Liu HX, 1998, GENE DEV, V12, P1998, DOI 10.1101/gad.12.13.1998; Modrek B, 2003, NAT GENET, V34, P177, DOI 10.1038/ng1159; Pertea M, 2001, NUCLEIC ACIDS RES, V29, P1185, DOI 10.1093/nar/29.5.1185; Pollard DA, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-6; Pruitt KD, 2005, NUCLEIC ACIDS RES, V33, pD501, DOI 10.1093/nar/gki025; Resch A, 2004, NUCLEIC ACIDS RES, V32, P1261, DOI 10.1093/nar/gkh284; Rice P, 2000, TRENDS GENET, V16, P276, DOI 10.1016/S0168-9525(00)02024-2; Sakharkar M, 2002, NUCLEIC ACIDS RES, V30, P191, DOI 10.1093/nar/30.1.191; Saxonov S, 2000, NUCLEIC ACIDS RES, V28, P185, DOI 10.1093/nar/28.1.185; Schaal TD, 1999, MOL CELL BIOL, V19, P1705; Schneider TD, 1997, J THEOR BIOL, V189, P427, DOI 10.1006/jtbi.1997.0540; SENAPATHY P, 1990, METHOD ENZYMOL, V183, P252, DOI 10.1016/0076-6879(90)83018-5; SHAPIRO MB, 1987, NUCLEIC ACIDS RES, V15, P7155, DOI 10.1093/nar/15.17.7155; SHARP PM, 1987, NUCLEIC ACIDS RES, V15, P1281, DOI 10.1093/nar/15.3.1281; Sironi M, 2004, NUCLEIC ACIDS RES, V32, P1783, DOI 10.1093/nar/gkh341; Sorek R, 2003, GENOME RES, V13, P1631, DOI 10.1101/gr.1208803; Stajich JE, 2002, GENOME RES, V12, P1611, DOI 10.1101/gr.361602; Storey JD, 2003, P NATL ACAD SCI USA, V100, P9440, DOI 10.1073/pnas.1530509100; Sun HZ, 2000, MOL CELL BIOL, V20, P6414, DOI 10.1128/MCB.20.17.6414-6425.2000; Tacke R, 1999, CURR OPIN CELL BIOL, V11, P358, DOI 10.1016/S0955-0674(99)80050-7; Usuka J, 2000, BIOINFORMATICS, V16, P203, DOI 10.1093/bioinformatics/16.3.203; Vapnik VN, 1998, STAT LEARNING THEORY; Versteeg R, 2003, GENOME RES, V13, P1998, DOI 10.1101/gr.1649303; Volfovsky N, 2003, GENOME RES, V13, P1216, DOI 10.1101/gr.677503; Wheelan SJ, 2001, GENOME RES, V11, P1952; Wheeler DL, 2005, NUCLEIC ACIDS RES, V33, pD39, DOI 10.1093/nar/gki062; Xie XH, 2005, NATURE, V434, P338, DOI 10.1038/nature03441; Xing Y, 2004, TRENDS GENET, V20, P472, DOI 10.1016/j.tig.2004.07.009; Yeo G, 2004, J COMPUT BIOL, V11, P377, DOI 10.1089/1066527041410418; Yeo GW, 2005, P NATL ACAD SCI USA, V102, P2850, DOI 10.1073/pnas.0409742102; Zhang XHF, 2004, GENE DEV, V18, P1241, DOI 10.1101/gad.1195304; Zhang XHF, 2005, GENOME RES, V15, P768, DOI 10.1101/gr.3217705; Zhang XHF, 2003, GENOME RES, V13, P2637, DOI 10.1101/gr.1679003; Zhang Z, 2000, J COMPUT BIOL, V7, P203, DOI 10.1089/10665270050081478; Zoubak S, 1996, GENE, V174, P95, DOI 10.1016/0378-1119(96)00393-9	67	21	21	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1046-2023		METHODS	Methods	DEC	2005	37	4					292	305		10.1016/j.myeth.2005.07.011		14	Biochemical Research Methods; Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	994ML	WOS:000234035800002	
J	Bohme, R; Westfeld, A				Bohme, R; Westfeld, A			Feature-based encoder classification of compressed audio streams	MULTIMEDIA SYSTEMS			English	Article						MP3 encoder classification; steganography; steganalysis; attacks; digital forensics; naive bayes classifier	STEGANALYSIS; INFORMATION	Today's digital audio coding algorithms use sophisticated models to maximise the encoding rate with minimal audible distortion. As a result of this complexity, different implementations of one encoding standard tend to produce varying output streams for the same uncompressed input data. This article presents a method to distinguish between encoding programs used to compress ISO/MPEG 1 Audio Layer-3 (MP3) files on the basis of statistical features that can be extracted from the compressed streams. The method employs a Bayesian machine learning classifier to determine the most likely encoder from a vector of 10 features. Experimental evidence suggests that the method is reliable enough to decrease the rate of false positives in a stego-detection case. Thus, it can be considered as a generic tool to increase the overall reliability of steganalysis in MP3 files. Moreover, a post-hoc interpretation of the trained classifier's parameters reveals interesting details about the degree of relation between subsets of the 20 encoding programs examined in the study. Further topics, such as implications on the robustness and possible extensions to different file formats are addressed in the discussion.	Tech Univ Dresden, Inst Syst Architecture, D-01062 Dresden, Germany	Bohme, R (reprint author), Tech Univ Dresden, Inst Syst Architecture, D-01062 Dresden, Germany.	rainer.boehme@inf.tu-dresden.de; westfeld@inf.tu-dresden.de					BOHME R, 2004, ACM MUTLIMEDIA SECUR, P25; BRANDENBURG K, 1994, J AUDIO ENG SOC, V42, P780; Duda R.O, 1973, PATTERN CLASSIFICATI; Fridrich J, 2004, LECT NOTES COMPUT SC, V3200, P67; HIPP M, 2001, MPG123 FAST MP3 PLAY; HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898; Ihaka R, 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Langley P., 1992, P 10 NAT C ART INT, P223; LINDLEY DV, 1995, SOC IND APPL MATH; Lyu S, 2003, LECT NOTES COMPUT SC, V2578, P340; MODDEMEIJER R, 1989, SIGNAL PROCESS, V16, P233, DOI 10.1016/0165-1684(89)90132-1; Ozer H, 2003, P SOC PHOTO-OPT INS, V5020, P55, DOI 10.1117/12.477313; PETITCOLAS FAP, 2002, MP3STEGO; Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065; Westfeld A, 2003, LECT NOTES COMPUT SC, V2578, P324; *IEC, 1990, 958 IEC; *ISO IEC, 1994, 138183 ISOIEC	17	2	2	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0942-4962		MULTIMEDIA SYST	Multimedia Syst.	DEC	2005	11	2					108	120		10.1007/s00530-005-0195-2		13	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	002HV	WOS:000234603200004	
J	Nanni, L				Nanni, L			Hyperplanes for predicting protein-protein interactions	NEUROCOMPUTING			English	Article; Proceedings Paper	13th IEEE Workshop on Neural Networks for Signal Processing (NNSP 2003)	SEP 17-19, 2003	Toulouse, FRANCE	IEEE Signal Proc Soc		protein-protein interactions; machine learning		Prediction of protein-protein interaction is a difficult and important problem in biology. Given (numerical) features, one of the existing machine learning techniques can be then applied to learn and classify proteins represented by these features. Our computational results demonstrate that a system based on K-local hyperplane outperforms the methods proposed in the literature based oil global representation of a protein pair. The approach is demonstrated by building a learning system based on experimentally validated protein-protein interactions in the human gastric bacterium Helicobacter pylori dataset and in Human dataset. (c) 2005 Elsevier B.V. All rights reserved.	Univ Bologna, DEIS, CNR, IEIIT, I-40136 Bologna, Italy	Nanni, L (reprint author), Univ Bologna, DEIS, CNR, IEIIT, Viale Risorgimento 2, I-40136 Bologna, Italy.	lnanni@deis.unibo.it					Bock JR, 2003, BIOINFORMATICS, V19, P125, DOI 10.1093/bioinformatics/19.1.125; Bock JR, 2001, BIOINFORMATICS, V17, P455, DOI 10.1093/bioinformatics/17.5.455; Duda R. O., 2001, PATTERN CLASSIFICATI; Kuncheva LI, 2005, INFORM FUSION, V6, P3, DOI 10.1016/j.inffus.2004.04.009; Martin S, 2005, BIOINFORMATICS, V21, P218, DOI 10.1093/bioinformatics/bth483; NANNI L, 2004, IN PRESS NEUROCOMPUT; OKUN O, 2004, P 2 EUR WORKSH DAT M, V1, P51; Valencia A, 2002, CURR OPIN STRUC BIOL, V12, P368, DOI 10.1016/S0959-440X(02)00333-0; WU C, 1992, PROTEIN SCI, V1, P667	9	19	22	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	DEC	2005	69	1-3					257	263		10.1016/j.neucom.2005.05.007		7	Computer Science, Artificial Intelligence	Computer Science	987GW	WOS:000233507400018	
J	Mourao-Miranda, J; Bokde, ALW; Born, C; Hampel, H; Stetter, M				Mourao-Miranda, J; Bokde, ALW; Born, C; Hampel, H; Stetter, M			Classifying brain states and determining the discriminating activation patterns: Support Vector Machine on functional MRI data	NEUROIMAGE			English	Article						machine learning methods; Support Vector Machine; classifiers; functional magnetic resonance imaging data analysis	HUMAN EXTRASTRIATE CORTEX; FMRI DATA; PERFORMANCE METRICS; BLIND SEPARATION; VISUAL-CORTEX; NEGATIVE BOLD; DEFAULT MODE; ATTENTION; IMAGES; REPRODUCIBILITY	In the present study, we applied the Support Vector Machine (SVM) algorithm to perform multivariate classification of brain states from whole functional magnetic resonance imaging (fMRI) volumes without prior selection of spatial features. In addition, we did a comparative analysis between the SVM and the Fisher Linear Discriminant (FLD) classifier. We applied the methods to two multisubject attention experiments: a face matching and a location matching task. We demonstrate that SVM outperforms FLD in classification performance as well as in robustness of the spatial maps obtained (i.e. discriminating volumes). In addition, the SVM discrimination maps had greater overlap with the general linear model (GLM) analysis compared to the FLD. The analysis presents two phases: during the training, the classifier algorithm finds the set of regions by which the two brain states can be best distinguished from each other. In the next phase, the test phase, given an fMRI volume from a new subject, the classifier predicts the subject's instantaneous brain state. (c) 2005 Elsevier Inc. All rights reserved.	Siemens Corp Technol Informat & Commun, Munich, Germany; Univ Munich, Dept Psychiat, Dementia & Neuroimaging Res Sect, Alzheimer Mem Ctr, Munich, Germany; Univ Munich, Dept Psychiat, Geriatr Psychiat Branch, Munich, Germany; Univ Munich, Inst Clin Radiol, Munich, Germany	Stetter, M (reprint author), Siemens AG, CT IC 4,Otto Hahn Ring 6, D-81739 Munich, Germany.	stetter@siemens.com					Almeida R, 2002, NEUROIMAGE, V17, P1065, DOI 10.1006/nimg.2002.1234; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; BLANZ V, 1999, 26 INT C COMP GRAPH; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Bullmore E, 1996, MAGNET RESON MED, V35, P261, DOI 10.1002/mrm.1910350219; Carlson TA, 2003, J COGNITIVE NEUROSCI, V15, P704, DOI 10.1162/089892903322307429; CORBETTA M, 1991, CIBA F SYMP, V163, P165; CORBETTA M, 1991, J NEUROSCI, V11, P2383; Cox DD, 2003, NEUROIMAGE, V19, P261, DOI 10.1016/S1053-8119(03)00049-1; FORD J, 2003, 6 ANN INT C MED IM C; FRISTON KJ, 1995, NEUROIMAGE, V2, P166, DOI 10.1006/nimg.1995.1019; Friston K.J., 1995, HUMAN BRAIN MAPPING, V2, P189, DOI DOI 10.1002/HBM.460020402; Friston K.J., 1997, HUMAN BRAIN FUNCTION; Greicius MD, 2003, P NATL ACAD SCI USA, V100, P253, DOI 10.1073/pnas.0135058100; HAXBY JV, 1991, P NATL ACAD SCI USA, V88, P1621, DOI 10.1073/pnas.88.5.1621; HAXBY JV, 1994, J NEUROSCI, V14, P6336; Holmes AP, 1996, J CEREBR BLOOD F MET, V16, P7; HOLMES AP, 1997, STAT MODELS EXPT DES; Huettel SA, 2001, J COGNITIVE NEUROSCI, V13, P1006, DOI 10.1162/089892901753165908; JACKSON JE, 1991, USER GUIDE PRINCIPLA; Kherif F, 2002, NEUROIMAGE, V16, P1068, DOI 10.1006/nimg.2002.1094; Kjems U, 2002, NEUROIMAGE, V15, P772, DOI 10.1006/nimg.2001.1033; LaConte S, 2003, NEUROIMAGE, V18, P10, DOI 10.1006/nimg.2002.1300; McIntosh AR, 1996, NEUROIMAGE, V3, P143, DOI 10.1006/nimg.1996.0016; McKeown MJ, 1998, HUM BRAIN MAPP, V6, P160, DOI 10.1002/(SICI)1097-0193(1998)6:3<160::AID-HBM5>3.0.CO;2-1; Mitchell TM, 2004, MACH LEARN, V57, P145, DOI 10.1023/B:MACH.0000035475.85309.1b; MORCH N, 1997, P 1K INT C INF PROC; Nichols TE, 2002, HUM BRAIN MAPP, V15, P1, DOI 10.1002/hbm.1058; Raichle ME, 2001, P NATL ACAD SCI USA, V98, P676, DOI 10.1073/pnas.98.2.676; Scholkopf B., 2002, LEARNING KERNELS; Shmuel A, 2002, NEURON, V36, P1195, DOI 10.1016/S0896-6273(02)01061-9; Smith AT, 2004, HUM BRAIN MAPP, V21, P213, DOI 10.1002/hbm.20017; Strother S, 2004, NEUROIMAGE, V23, pS196, DOI 10.1016/j.neuroimage.2004.07.022; Tegeler C, 1999, HUM BRAIN MAPP, V7, P267, DOI 10.1002/(SICI)1097-0193(1999)7:4<267::AID-HBM5>3.0.CO;2-3; Vapnik V. N, 1995, NATURE STAT LEARNING; WANG X, 2003, 17 ANN C NEUR INF PR; WEAVER JB, 1995, J CEREBR BLOOD F MET, V15, P892	37	189	191	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1053-8119		NEUROIMAGE	Neuroimage	DEC	2005	28	4					980	995		10.1016/j.neuroimage.2005.06.070		16	Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical Imaging	Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging	994FC	WOS:000234015300023	
J	Twa, MD; Parthasarathy, S; Roberts, C; Mahmoud, AM; Raasch, TW; Bullimore, MA				Twa, MD; Parthasarathy, S; Roberts, C; Mahmoud, AM; Raasch, TW; Bullimore, MA			Automated decision tree classification of corneal shape	OPTOMETRY AND VISION SCIENCE			English	Article; Proceedings Paper	Annual Meeting of the Association-for-Research-in-Vision-and-Ophthalmology	MAY 01-05, 2005	Ft Lauderdale, FL	Assoc Res Vis & Ophthalmol		corneal topography; Zernike polynomials; keratoconus; classification; decision tree	VIDEOKERATOSCOPIC HEIGHT DATA; KERATOCONUS DETECTION; ZERNIKE POLYNOMIALS; VIDEOKERATOGRAPHY; TOPOGRAPHY; EYES; DIAGNOSIS; INDEX	Purpose. The volume and complexity of data produced during videokeratography examinations present a challenge of interpretation. As a consequence, results are often analyzed qualitatively by subjective pattern recognition or reduced to comparisons of summary indices. We describe the application of decision tree induction, an automated machine learning classification method, to discriminate between normal and keratoconic corneal shapes in an objective and quantitative way. We then compared this method with other known classification methods. Methods. The corneal surface was modeled with a seventh-order Zernike polynomial for 132 normal eyes of 92 subjects and 112 eyes of 71 subjects diagnosed with keratoconus. A decision tree classifier was induced using the C4.5 algorithm, and its classification performance was compared with the modified Rabinowitz-McDonnell index, Schwiegerling's Z3 index (Z3), Keratoconus Prediction Index (KPI), KISA%, and Cone Location and Magnitude Index using recommended classification thresholds for each method. We also evaluated the area under the receiver operator characteristic (ROC) curve for each classification method. Results. Our decision tree classifier performed equal to or better than the other classifiers tested: accuracy was 92% and the area under the ROC curve was 0.97. Our decision tree classifier reduced the information needed to distinguish between normal and keratoconus eyes using four of 36 Zernike polynomial coefficients. The four surface features selected as classification attributes by the decision tree method were inferior elevation, greater sagittal depth, oblique toricity, and trefoil. Conclusion. Automated decision tree classification of corneal shape through Zernike polynomials is an accurate quantitative method of classification that is interpretable and can be generated from any instrument platform capable of raw elevation data output. This method of pattern classification is extendable to other classification problems.	Ohio State Univ, Coll Optometry, Columbus, OH 43210 USA; Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA; Ohio State Univ, Dept Ophthalmol, Columbus, OH 43210 USA; Ohio State Univ, Dept Biomed Engn, Columbus, OH 43210 USA	Twa, MD (reprint author), Ohio State Univ, Coll Optometry, 338 W 10th Ave, Columbus, OH 43210 USA.	twa.1@osu.edu	Twa, Michael/B-8755-2012; Roberts, Cynthia/E-3961-2011; Raasch, Thomas/A-3588-2013				CARROLL JP, 1994, OPTOMETRY VISION SCI, V71, P259, DOI 10.1097/00006324-199404000-00006; Carvalho LA, 2005, OPTOMETRY VISION SCI, V82, P151, DOI 10.1097/01.OPX.0000153193.41554.A1; Chastang PJ, 2000, J CATARACT REFR SURG, V26, P675, DOI 10.1016/S0886-3350(00)00303-5; Dingeldein S A, 1989, Refract Corneal Surg, V5, P372; Hastie T, 2001, ELEMENTS STAT LEARNI; Hosmer DW, 2000, APPL LOGISTIC REGRES; Hsu J, 1996, MULTIPLE COMP THEORY; Kalin Neil S., 1996, CLAO Journal, V22, P164; KATZ J, 1994, INVEST OPHTH VIS SCI, V35, P2461; KATZ J, 1988, OPHTHALMIC SURG LAS, V19, P585; Klyce S D, 1989, Refract Corneal Surg, V5, P368; Klyce SD, 2000, J CATARACT REFR SURG, V26, P472, DOI 10.1016/S0886-3350(00)00384-9; Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence; Kuo WJ, 2001, BREAST CANCER RES TR, V66, P51, DOI 10.1023/A:1010676701382; MAEDA N, 1995, INVEST OPHTH VIS SCI, V36, P1327; MAEDA N, 1994, INVEST OPHTH VIS SCI, V35, P2749; MAEDA N, 1995, ARCH OPHTHALMOL-CHIC, V113, P870; Mahmoud AM, 2001, INVEST OPHTH VIS SCI, V42, pS898; Mitchell T, 1997, MACHINE LEARNING; Nagy N, 1999, INT J MOL MED, V4, P299; Quinlan J. R., 1993, PROGRAMS MACHINE LEA; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Rabinowitz YS, 1999, J CATARACT REFR SURG, V25, P1327, DOI 10.1016/S0886-3350(99)00195-9; Rabinowitz Y S, 1989, Refract Corneal Surg, V5, P400; RABINOWITZ YS, 1995, J REFRACT SURG, V11, P371; SCHWIEGERLING J, 1995, J OPT SOC AM A, V12, P2105, DOI 10.1364/JOSAA.12.002105; Schwiegerling J, 1996, OPTOMETRY VISION SCI, V73, P721, DOI 10.1097/00006324-199612000-00001; Smolek MK, 1997, INVEST OPHTH VIS SCI, V38, P2290; Thibos LN, 2002, J REFRACT SURG, V18, pS652; Twa MD, 2003, SIAM PROC S, P3; Viikki K, 1999, MED INFORM INTERNET, V24, P277, DOI 10.1080/146392399298302; WILSON SE, 1991, ARCH OPHTHALMOL-CHIC, V109, P349; WITTEN JH, 2000, PRACTICAL MACHINE LE; Zadnik K, 1999, INVEST OPHTH VIS SCI, V40, P1936; Zadnik K, 1998, INVEST OPHTH VIS SCI, V39, P2537; Zadnik K, 2002, CORNEA, V21, P671, DOI 10.1097/00003226-200210000-00008	36	23	23	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	530 WALNUT ST, PHILADELPHIA, PA 19106-3261 USA	1040-5488		OPTOMETRY VISION SCI	Optom. Vis. Sci.	DEC	2005	82	12					1038	1046		10.1097/01.opx.0000192350.01045.6f		9	Ophthalmology	Ophthalmology	996KP	WOS:000234173100006	
J	Sen, SK; Samanta, T				Sen, S. K.; Samanta, T.			Relative merits of random number generators: indirect approach	NONLINEAR ANALYSIS-THEORY METHODS & APPLICATIONS			English	Article						Computational complexity; Monte Carlo method; Probabilistic algorithm; Pseudo-random number generators; Root-mean-square error		Uniformly distributed pseudo-random number generators (pseudo-RNGs) are at the base of numerous problems (such as those in operations research and machine learning) whose deterministic solution is often exponential/combinatorial and hence intractable. While designing perfect RNGs is impossible, it is possible to select one among the existing RNGs, which would be the core of a probabilistic algorithm to solve such a problem in polynomial-time and produce the best quality result. Presented here is a study of only three RNGs and their merits just to highlight an indirect way of comparing any two or more RNGs before selecting one to be used in the probabilistic algorithm. The indirect approach depends on the performance of an RNG in the specified randomized algorithm used for test problems. How good the quality of results is and how less the computational complexity is, are the core of this approach. A direct approach for comparing two or more RNGs, on the other hand, is independent of algorithms. We use in this approach one or more testing procedures for random numbers to decide which one we should choose. We believe that such a study would help one in choosing an appropriate RNG for his problem. (C) 2004 Elsevier Ltd. All rights reserved.	[Sen, S. K.; Samanta, T.] Florida Inst Technol, Dept Math Sci, Melbourne, FL 32901 USA	Samanta, T (reprint author), Florida Inst Technol, Dept Math Sci, Melbourne, FL 32901 USA.	sksen@fit.edu; tsamanta@fit.edu					ALLARD JL, 1963, J ACM, V10, P131, DOI 10.1145/321160.321163; Banks J, 1996, DISCRETE EVENT SYSTE; Deng LY, 2000, AM STAT, V54, P145, DOI 10.2307/2686034; EICHENAUERHERRMANN J, 1995, INT STAT REV, V63, P247, DOI 10.2307/1403620; IBM Corp, 1959, Random Number Generation and Testing, Reference Manual C20-8011; Intel Corporation, 1999, The Intel&REG; Random Number Generator; Knuth D.E., 1981, SEMINUMERICAL ALGORI, V2; Krishnamurthy E.V., 2001, Numerical Algorithms: Computations in Science and Engineering; LAGARIAS JC, 1993, STAT SCI, V8, P31, DOI 10.1214/ss/1177011081; L'Ecuyer P., 1989, P 1989 WINT SIM C, P467, DOI 10.1145/76738.76799; L'ecuyer P, 1998, HANDBOOK OF SIMULATION, P93, DOI 10.1002/9780470172445.ch4; L'Ecuyer P, 2003, MATH COMPUT SIMULAT, V62, P395, DOI 10.1016/S0378-4754(02)00234-3; L'Ecuyer P, 2004, STAT COMPUT, V14, P5, DOI 10.1023/B:STCO.0000009417.88960.81; Leeb H., 1995, THESIS U SALZBURG; Leydold J., 2002, UNURAN-A Library for Universal Non-Uniform Random Number Generators; MACLAREN MD, 1965, J ACM, V12, P83, DOI 10.1145/321250.321257; Marsaglia G., 1985, Computer Science and Statistics. Proceedings of the Sixteenth Symposium on the Interface; PARK SK, 1988, COMMUN ACM, V31, P1192, DOI 10.1145/63039.63042; Press WH, 1992, NUMERICAL RECIPES C; Purdy J., 1993, Research Reporter, V23; Smid M., 2001, NIST SPECIAL PUBLICA, V800-22; VonNeumann J., 1951, John von Neumann Collected Works, P768; Wu PC, 1997, ACM T MATH SOFTWARE, V23, P255, DOI 10.1145/264029.264056	23	0	0	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0362-546X		NONLINEAR ANAL-THEOR	Nonlinear Anal.-Theory Methods Appl.	NOV 30	2005	63	5-7					E2525	E2532		10.1016/j.na.2004.09.007		8	Mathematics, Applied; Mathematics	Mathematics	V20NX	WOS:000208147800249	
J	Im, J; Jensen, JR				Im, J; Jensen, JR			A change detection model based on neighborhood correlation image analysis and decision tree classification	REMOTE SENSING OF ENVIRONMENT			English	Article						change detection; neighborhood correlation images; decision trees; high spatial resolution multispectral image	REMOTELY-SENSED DATA; CHANGE-VECTOR ANALYSIS; URBAN-ENVIRONMENT; ALGORITHMS; WETLAND; COVER	This study introduces a change detection model based on Neighborhood Correlation Image (NCI) logic. It is based on the fact that the same geographic area (e.g., a 3 x 3 pixel window) on two dates of imagery will tend to be highly correlated if little change has occurred, and uncorrelated when change occurs. Computing the piecewise correlation between two data sets provides valuable information regarding the location and numeric change value derived using contextual information within the specified neighborhood. Various neighborhood configurations (i.e., multi-level NCIs) were explored in the study using high spatial resolution multispectral imagery: smaller neighborhood sizes provided some detailed change information (such as a new patios added to an existing building) at the cost of introducing some noise (such as changes in shadows). Larger neighborhood sizes were useful for removing this noise but introduced some inaccurate change information (such as removing some linear feature changes). When combined with image classification using a machine learning decision tree (C5.0), classifications based on multi-level NCIs yielded superior results (e.g., using a 3-pixel circular radius neighborhood had a Kappa of 0.94), compared to the classification that did not incorporate NCIs (Kappa=0.86). (C) 2005 Elsevier Inc. All rights reserved.	Univ S Carolina, Columbia, SC 29208 USA	Im, J (reprint author), Univ S Carolina, Columbia, SC 29208 USA.	imj@sc.edu					Chan JCW, 2001, PHOTOGRAMM ENG REM S, V67, P213; Chen J, 2003, PHOTOGRAMM ENG REM S, V69, P369; CONGALTON R. G., 1999, ASSESSING ACCURACY R; CONGALTON RG, 1991, REMOTE SENS ENVIRON, V37, P35, DOI 10.1016/0034-4257(91)90048-B; Dai XL, 1999, PHOTOGRAMM ENG REM S, V65, P1187; GWET K, 2002, SERIES STAT METHODS; Hayes DJ, 2001, PHOTOGRAMM ENG REM S, V67, P1067; Hodgson ME, 2003, PHOTOGRAMM ENG REM S, V69, P973; IM J, 2004, KOREAN J REMOTE SENS, V20, P23; IM J, 2005, IEEE INT GEOSC REM S; JENSEN JR, 1995, PHOTOGRAMM ENG REM S, V61, P199; JENSEN JR, 1993, PHOTOGRAMM ENG REM S, V59, P1039; Jensen J.R., 2005, INTRO DIGITAL IMAGE; Johnson RD, 1998, INT J REMOTE SENS, V19, P411, DOI 10.1080/014311698216062; LUNETTA R., 2000, REMOTE SENSING CHANG; Lyon JG, 1998, PHOTOGRAMM ENG REM S, V64, P143; McIver DK, 2002, REMOTE SENS ENVIRON, V81, P253, DOI 10.1016/S0034-4257(02)00003-2; NIEMEYER I, 2003, PIXEL BASED OBJECT O; NIEMEYER I, 2001, P SPIES INT S REM SE, V4545, P100; Quinlan J., 2003, DATA MINING TOOLS SE; Ridd MK, 1998, REMOTE SENS ENVIRON, V63, P95, DOI 10.1016/S0034-4257(97)00112-0; SCHOTT JR, 1988, REMOTE SENS ENVIRON, V26, P1, DOI 10.1016/0034-4257(88)90116-2; Seto KC, 2003, PHOTOGRAMM ENG REM S, V69, P981; Walter V, 2004, ISPRS J PHOTOGRAMM, V58, P225, DOI 10.1016/j.isprsjprs.2003.09.007; Yue TX, 2003, ECOL MODEL, V164, P21, DOI 10.1016/S0304-3800(02)00391-5	25	49	54	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0034-4257		REMOTE SENS ENVIRON	Remote Sens. Environ.	NOV 30	2005	99	3					326	340		10.1016/j.rse.2005.09.008		15	Environmental Sciences; Remote Sensing; Imaging Science & Photographic Technology	Environmental Sciences & Ecology; Remote Sensing; Imaging Science & Photographic Technology	986VT	WOS:000233478500010	
J	Goulon-Sigwalt-Abram, A; Duprat, A; Dreyfus, G				Goulon-Sigwalt-Abram, A; Duprat, A; Dreyfus, G			From Hopfield nets to recursive networks to graph machines: Numerical machine learning for structured data	THEORETICAL COMPUTER SCIENCE			English	Article						graph; graph machine; structured data; recursive network; folding network; recurrent network; neural network; SVM; QSAR; QSPR; RAAM; LRAAM; classification; regression	RECURRENT NEURAL-NETWORKS; SUPPORT VECTOR MACHINES; PATTERN-RECOGNITION; APPROXIMATION CAPABILITY; INFORMATION-STORAGE; CASCADE CORRELATION; NATURAL-LANGUAGE; STRING KERNELS; CLASSIFICATION; REPRESENTATIONS	The present paper is a short survey of the development of numerical learning from structured data, an old problem that was first addressed by the end of the years 1980, and has recently undergone exciting developments, both from a theoretical point of view and for applications. Traditionally, numerical machine learning deals with unstructured data, in the form of vectors: neural networks, graphical models, support vector machines, handle vectors of features that are assumed to be relevant for solving the problem at hand (classification or regression). It is often the case, however, that data is structured, i.e. is in the form of graphs; three examples will be described here: prediction of the properties of molecules, image analysis, and natural language processing. The traditional approach consists in handcrafting a vector representation of the structured data (features describing the molecules, "bag of words" for language processing), and subsequently training a machine to perform the task from that representation. By contrast, we describe here a family of approaches (RAAMs, LRAAMs, recursive or folding networks, graph machines) that are specifically designed to learn from structured data. We show that, despite the apparent diversity, two basic principles underlie the recent approaches: first, use structured machines to learn structured data; second, learn representations instead of handcrafting them; although neither principle is really new, they proved very successful for handling structured data, to the point of generating a novel branch of numerical machine learning. (c) 2005 Elsevier B.V. All rights reserved.	ESPCI Paristech, CNRS, UMR 7084, Elect Lab, F-75005 Paris, France; ESPCI Paristech, CNRS, UMR 7084, Chim Organ Lab, F-75005 Paris, France	Dreyfus, G (reprint author), ESPCI Paristech, CNRS, UMR 7084, Elect Lab, 10,Rue Vauquelin, F-75005 Paris, France.	Gerard.Dreyfus@espci.fr					BALDI P, 2003, J MACH LEARN RES, V4, P576; Bianucci AM, 2000, APPL INTELL, V12, P117, DOI 10.1023/A:1008368105614; BIENENSTOCK E, 1987, EUROPHYS LETT, V4, P121, DOI 10.1209/0295-5075/4/1/020; BIENENSTOCK E, 1989, NEURAL NETWORKS FROM MODELS TO APPLICATIONS, P472; Bishop C.M., 1995, NEURAL NETWORKS PATT; BLANK DS, 1992, SYMBOLIC CONNECTIONI; CHEN HH, 1986, AIP C P, V151, P86; Collins M, 2002, ADV NEUR IN, V14, P625; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264136; CUETOS F, 1988, COGNITION, V30, P72; Diligenti M, 2001, PATTERN RECOGN, V34, P2049, DOI 10.1016/S0031-3203(00)00127-8; DREYFUS G, 2005, FEATURE EXTRACTION F; Personnaz L., 1985, Journal de Physique Lettres, V46, DOI 10.1051/jphyslet:01985004608035900; Dreyfus G, 1998, NEURAL COMPUT, V10, P133, DOI 10.1162/089976698300017926; DREYFUS G, 1988, NEURAL NETWORKS MODE, P483; Dreyfus G, 2005, NEURAL NETWORKS METH; Duprat AF, 1998, J CHEM INF COMP SCI, V38, P586, DOI 10.1021/ci980042v; Goller C, 1996, IEEE IJCNN, P347, DOI 10.1109/ICNN.1996.548916; Goller C., 1999, IJCNN'99. International Joint Conference on Neural Networks. Proceedings (Cat. No.99CH36339), DOI 10.1109/IJCNN.1999.831114; Gori M, 2003, IEEE IJCNN, P1351; GOULONSIGWALTAB.A, 2005, APPL STAT MODELING D; GUYON I, 1987, LECT NOTES PHYS, V275; GUYON I, 1988, PHYS REV A, V38, P6365, DOI 10.1103/PhysRevA.38.6365; Hammer B., 2000, SPRINGER LECT NOTES, V254; Hammer B, 2000, NEUROCOMPUTING, V31, P107, DOI 10.1016/S0925-2312(99)00174-5; Hammer B, 2002, COGNITIVE SYSTEMS RE, V3, P145; HAUSSLER D, 1999, UCSCCLR9910; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; HOPFIELD JJ, 1985, BIOL CYBERN, V52, P141; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; HORNIK K, 1993, NEURAL NETWORKS, V6, P1069; Jaakkola TS, 1999, ADV NEUR IN, V11, P487; JOCHUM C, 1977, J CHEM INF COMP SCI, V17, P113, DOI 10.1021/ci60010a014; KASHIMA H, 2003, 20 INT C MACH LEARN, P321; KREE R, 1988, J PHYS A, V21, P813; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; Leslie CS, 2004, BIOINFORMATICS, V20, P467, DOI 10.1093/bioinformatics/btg431; Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687; MAHE P, 2004, 21 INT C MACH LEARN, P552; MARCOS S, 1992, INT J CIRC THEOR APP, V20, P1159; Menchetti S, 2005, PATTERN RECOGN LETT, V26, P1896, DOI 10.1016/j.patrec.2005.03.011; Hammer B, 2005, NEURAL COMPUT, V17, P1109, DOI 10.1162/0899766053491878; Micheli A, 2005, NEUROCOMPUTING, V64, P73, DOI 10.1016/j.neucom.2004.11.013; NERRAND O, 1994, IEEE T NEURAL NETWOR, V5, P178, DOI 10.1109/72.279183; Oussar Y, 2001, NEURAL NETWORKS, V14, P1161, DOI 10.1016/S0893-6080(01)00096-X; PERSONNAZ L, 1986, PHYS REV A, V34, P4217, DOI 10.1103/PhysRevA.34.4217; PERSONNAZ L, 1987, EUROPHYS LETT, V4, P863, DOI 10.1209/0295-5075/4/8/001; POLLACK JB, 1990, ARTIF INTELL, V46, P77, DOI 10.1016/0004-3702(90)90005-K; Press W. H., 2002, NUMERICAL RECIPES AR; Quenet B, 2002, BIOSYSTEMS, V67, P203, DOI 10.1016/S0303-2647(02)00078-3; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Saunders C., 2003, ADV NEURAL INFORM PR, V15, P633; SIEGELMANN HT, 1995, J COMPUT SYST SCI, V50, P132, DOI 10.1006/jcss.1995.1013; SONTAG ED, 1993, PROG SYST C, V14, P339; Sperduti A., 1994, Connection Science, V6, DOI 10.1080/09540099408915733; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; VONDERMALSBURG C, 1987, EUROPHYS LETT, V3, P1243; WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701; Yao XJ, 2004, J CHEM INF COMP SCI, V44, P1257, DOI 10.1021/ci049965i; Yao Y, 2003, PATTERN RECOGN, V36, P397	60	8	8	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3975		THEOR COMPUT SCI	Theor. Comput. Sci.	NOV 17	2005	344	2-3					298	334		10.1016/j.tcs.2005.08.026		37	Computer Science, Theory & Methods	Computer Science	984NW	WOS:000233312600009	
J	Boernsen, KO; Gatzek, S; Imbert, G				Boernsen, KO; Gatzek, S; Imbert, G			Controlled protein precipitation in combination with chip-based nanospray infusion mass spectrometry. An approach for metabolomics profiling of plasma	ANALYTICAL CHEMISTRY			English	Article							PHARMACEUTICAL COMPOUNDS; ELECTROSPRAY-IONIZATION; LIQUID-CHROMATOGRAPHY; ESI-MS; NANOELECTROSPRAY; IDENTIFICATION; SAMPLES	liquid chromatography-mass spectrometry (LC-MS) is a common method for profiling biological samples in metabolomics. However, LC-MS data of metabolomic studies are often affected by high noise levels, retention time shifts, and high variability in signal intensities. With a new chip-based nanoelectrospray source it becomes possible to directly infuse complex biological samples such as plasma without any chromatographic separation beforehand. In combination with highly diluted samples and long data acquisition times, the parallel analysis of hundreds of compounds is now possible. In a proof-of-concept study, 10 human plasma samples from females and males were analyzed with the intention to separate the two groups by their different metabolomes. The reproducibility was so high that statistical analysis of the data could be performed without prior normalization. Two groups of female and male samples were separated by a supervised machine learning algorithm, principal component analysis, and hierarchical clustering. Peaks contributing to the group separation were characterized by accurate mass measurement and MS-MS fragmentation and by spiking experiments. The feasibility of direct sample infusion using the new chip-based nanoelectrospray device opens a new dimension for the rapid parallel analysis of complex biological mixtures.	Novartis Pharm AG, Basel, Switzerland	Boernsen, KO (reprint author), Novartis Pharm AG, Basel, Switzerland.	k.olaf.boernsen@novartis.com					ANTIGNACA JP, 2005, ANAL CHIM ACTA, P129; Beecher CWW, 2003, METABOLIC PROFILING: ITS ROLE IN BIOMARKER DISCOVERY AND GENE FUNCTION ANALYSIS, P311; Benkestock K, 2003, J BIOMOL SCREEN, V8, P247, DOI 10.1177/1087057103255301; Corkery LJ, 2005, J AM SOC MASS SPECTR, V16, P363, DOI 10.1016/j.jasms.2004.11.018; Dethy JM, 2003, ANAL CHEM, V75, P805, DOI 10.1021/ac0260692; Gangl ET, 2001, ANAL CHEM, V73, P5635, DOI 10.1021/ac010501i; Groenewold GS, 2000, J AM SOC MASS SPECTR, V11, P69, DOI 10.1016/S1044-0305(99)00118-X; HAO Z, 2003, CORRELOGIC SYSTEMS A; Juraschek R, 1999, J AM SOC MASS SPECTR, V10, P300, DOI 10.1016/S1044-0305(98)00157-3; KAPRON JT, 2003, J RAPID COMMUN MASS, V17, P2019; Leuthold LA, 2004, RAPID COMMUN MASS SP, V18, P1995, DOI 10.1002/rcm.1587; Mallet CR, 2004, RAPID COMMUN MASS SP, V18, P49, DOI 10.1002/rcm.1276; Pham-Tuan H, 2003, J CHROMATOGR B, V789, P283, DOI 10.1016/S1570-0232(03)00077-1; Rule G, 1999, J AM SOC MASS SPECTR, V10, P1322, DOI 10.1016/S1044-0305(99)00107-5; Schmidt A, 2003, J AM SOC MASS SPECTR, V14, P492, DOI 10.1016/S1044-0305(03)00128-4; Scholz M, 2004, BIOINFORMATICS, V20, P2447, DOI 10.1093/bioinformatics/bth270; Schultz GA, 2000, ANAL CHEM, V72, P4058, DOI 10.1021/ac000325y; Souverain S, 2004, J PHARMACEUT BIOMED, V35, P913, DOI 10.1016/j.jpba.2004.03.005; Van Pelt CK, 2003, RAPID COMMUN MASS SP, V17, P1573, DOI 10.1002/rcm.1087; Wickremsinhe ER, 2005, RAPID COMMUN MASS SP, V19, P47, DOI 10.1002/rcm.1747; Williams JG, 2004, J AM SOC MASS SPECTR, V15, P1333, DOI 10.1016/j.jasms.2004.06.007; Wilson ID, 2005, J CHROMATOGR B, V817, P67, DOI 10.1016/j.jchromb.2004.07.045; Xia YQ, 2005, J AM SOC MASS SPECTR, V16, P417, DOI 10.1016/j.jasms.2004.11.020; YU L, 2005, DRUG METAB DISPOS, V10, P1124; Zamfir A, 2004, J AM SOC MASS SPECTR, V15, P1649, DOI 10.1016/j.jasms.2004.08.002; Zhang S, 2003, ELECTROPHORESIS, V24, P3620, DOI 10.1002/elps.200305585; Zhang S, 2003, ANAL CHEM, V75, P3010, DOI 10.1021/ac034089d	27	48	50	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0003-2700		ANAL CHEM	Anal. Chem.	NOV 15	2005	77	22					7255	7264		10.1021/ac0508604		10	Chemistry, Analytical	Chemistry	985UM	WOS:000233404200019	
J	Zwir, I; Huang, H; Groisman, EA				Zwir, I; Huang, H; Groisman, EA			Analysis of differentially-regulated genes within a regulatory network by GPS genome navigation	BIOINFORMATICS			English	Article							ESCHERICHIA-COLI K-12; BINDING-SITES; TRANSCRIPTIONAL REGULATION; MOLECULAR CHARACTERIZATION; OLIGONUCLEOTIDE ARRAYS; SALMONELLA-ENTERICA; PHOP-PHOQ; EXPRESSION; IDENTIFICATION; DISCOVERY	Motivation: A critical challenge of the post-genomic era is to understand how genes are differentially regulated even when they belong to a given network. Because the fundamental mechanism controlling gene expression operates at the level of transcription initiation, computational techniques have been developed that identify cis regulatory features and map such features into expression patterns to classify genes into distinct networks. However, these methods are not focused on distinguishing between differentially regulated genes within a given network. Here we describe an unsupervised machine learning method, termed GPS for gene promoter scan, that discriminates among co-regulated promoters by simultaneously considering both cis-acting regulatory features and gene expression. GPS is particularly useful for knowledge discovery in environments with reduced datasets and high levels of uncertainty. Results: Application of this method to the enteric bacteria Escherichia coli and Salmonella enterica uncovered novel members, as well as regulatory interactions in the regulon controlled by the PhoP protein that were not discovered using previous approaches. The predictions made by GPS were experimentally validated to establish that the PhoP protein uses multiple mechanisms to control gene transcription, and is a central element in a highly connected network.	Washington Univ, Sch Med, Howard Hughes Med Inst, Dept Mol Microbiol, St Louis, MO 63110 USA	Groisman, EA (reprint author), Washington Univ, Sch Med, Howard Hughes Med Inst, Dept Mol Microbiol, Campus Box 8230,660 S Euclid Ave, St Louis, MO 63110 USA.	groisman@borcim.wustl.edu					Agrawal R, 1996, IEEE T KNOWL DATA EN, V8, P962, DOI 10.1109/69.553164; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Azevedo RBR, 2005, NATURE, V433, P152, DOI 10.1038/nature03102; Bar-Joseph Z, 2003, NAT BIOTECHNOL, V21, P1337, DOI 10.1038/nbt890; Beer MA, 2004, CELL, V117, P185, DOI 10.1016/S0092-8674(04)00304-6; BENITEZBELLON E, 2002, GENOME BIOL, V3, pH13, DOI 10.1186/gb-2002-3-3-research0013; BEZDEK JC, 1992, FUZZY MODELS PATTERN; Ashburner M, 2000, NAT GENET, V25, P25; CHEESEMAN P, 1994, SELECTING MODELS DAT; Chickering D. M., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303321897717; COLLADOVIDES J, 1991, MICROBIOL REV, V55, P371; Conlon EM, 2003, P NATL ACAD SCI USA, V100, P3339, DOI 10.1073/pnas.0630591100; CONSORTIUM E, 2002, 1 EUR WORKSH PROB GR, P222; Cook DJ, 2001, IEEE ENG MED BIOL, V20, P67, DOI 10.1109/51.940050; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; Cordon O, 2002, IEEE T FUZZY SYST, V10, P2, DOI 10.1109/91.983275; Cotik V, 2005, FUZZY SET SYST, V152, P83, DOI 10.1016/j.fss.2004.10.016; Crooks GE, 2004, GENOME RES, V14, P1188, DOI 10.1101/gr.849004; Deb K., 2001, MULTIOBJECTIVE OPTIM; Eguchi Y, 2004, J BACTERIOL, V186, P3006, DOI 10.1128/JB.186.10.3006-3014.2004; Everitt BS, 1996, HDB STAT ANAL USING; Falkenauer E., 1998, GENETIC ALGORITHMS G; Gasch AP, 2002, GENOME BIOL, V3; Groisman EA, 2001, J BACTERIOL, V183, P1835, DOI 10.1128/JB.183.6.1835-1842.2001; Gutierrez-Rios RM, 2003, GENOME RES, V13, P2435, DOI 10.1101/gr.1387003; Kato A, 2004, GENE DEV, V18, P2302, DOI 10.1101/gad.1230804; Kato A, 2003, P NATL ACAD SCI USA, V100, P4706, DOI 10.1073/pnas.0836837100; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Larranaga P, 1996, IEEE T PATTERN ANAL, V18, P912, DOI 10.1109/34.537345; Lejona S, 2003, J BACTERIOL, V185, P6287, DOI 10.1128/JB.185.21.6287-6294.2003; Li C, 2001, P NATL ACAD SCI USA, V98, P31, DOI 10.1073/pnas.011404098; Li H, 2002, P NATL ACAD SCI USA, V99, P11772, DOI 10.1073/pnas.112341999; Martinez-Antonio A, 2003, CURR OPIN MICROBIOL, V6, P482, DOI 10.1016/j.mib.2003.09.002; Masuda N, 2003, MOL MICROBIOL, V48, P699, DOI 10.1046/j.1365-2958.2003.03477.x; McCue LA, 2001, NUCLEIC ACIDS RES, V29, P774, DOI 10.1093/nar/29.3.774; Minagawa S, 2003, J BACTERIOL, V185, P3696, DOI 10.1128/JB.185.13.3696-3702.2003; Mitchell T, 1997, MACHINE LEARNING; Oshima T, 2002, MOL MICROBIOL, V46, P281, DOI 10.1046/j.1365-2958.2002.03170.x; Qin ZHS, 2003, NAT BIOTECHNOL, V21, P435, DOI 10.1038/nbt802; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Requena F, 2000, STAT PROBABIL LETT, V50, P39, DOI 10.1016/S0167-7152(00)00079-1; Rissanen J., 1989, STOCHASTIC COMPLEXIT; Ronen M, 2002, P NATL ACAD SCI USA, V99, P10555, DOI 10.1073/pnas.152046799; Rosner B, 1986, FUNDAMENTALS BIOSTAT; Ruspini E.H., 1998, HDB FUZZY COMPUTATIO, pF61; RUSPINI EHA, 2001, PATTERN RECOGN, P612; Salgado H, 2004, NUCLEIC ACIDS RES, V32, pD303, DOI 10.1093/nar/gkh140; SAPORTA G, 1996, PROBABILITS ANAL DON; Shi YX, 2004, J BIOL CHEM, V279, P38618, DOI 10.1074/jbc.M406149200; Shin D, 2005, J BIOL CHEM, V280, P4089; Stormo GD, 2000, BIOINFORMATICS, V16, P16, DOI 10.1093/bioinformatics/16.1.16; Tavazoie S, 1999, NAT GENET, V22, P281; Tucker DL, 2002, J BACTERIOL, V184, P6551, DOI 10.1128/JB.184.23.6551-6558.2002; Yeung KY, 2001, BIOINFORMATICS, V17, P763, DOI 10.1093/bioinformatics/17.9.763; ZALIZ RR, 2004, APPL MULTIOBJECTIVE, P427; Zitzler E, 1999, IEEE T EVOLUT COMPUT, V3, P257, DOI 10.1109/4235.797969; Zwir I, 2002, ANN NY ACAD SCI, V980, P65; Zwir I, 2005, P NATL ACAD SCI USA, V102, P2862, DOI 10.1073/pnas.0408238102	58	23	23	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	NOV 15	2005	21	22					4073	4083		10.1093/bioinformatics/bti672		11	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	983FZ	WOS:000233218100002	
J	Honda, K; Hayashida, Y; Umaki, T; Okusaka, T; Kosuge, T; Kikuchi, S; Endo, M; Tsuchida, A; Aoki, T; Itoi, T; Moriyasu, F; Hirohashi, S; Yamada, T				Honda, K; Hayashida, Y; Umaki, T; Okusaka, T; Kosuge, T; Kikuchi, S; Endo, M; Tsuchida, A; Aoki, T; Itoi, T; Moriyasu, F; Hirohashi, S; Yamada, T			Possible detection of pancreatic cancer by plasma protein profiling	CANCER RESEARCH			English	Article							MASS-SPECTROMETRY; OVARIAN-CANCER; PROTEOMIC PATTERNS; SERUM BIOMARKERS; PROSTATE-CANCER; CARCINOMA; ADENOCARCINOMA; IDENTIFICATION; INDIVIDUALS; TECHNOLOGY	The survival rate of pancreatic cancer patients is the lowest among those with common solid tumors, and early detection is one of the most feasible means of improving outcomes. We compared plasma proteomes between pancreatic cancer patients and sex- and age-matched healthy controls using surface- enhanced laser desorption/ionization coupled with hybrid quadrupole time-of-flight mass spectrometry. Proteomic spectra were generated from a total of 245 plasma samples obtained from two institutes. A discriminating proteomic pattern was extracted from a training cohort (71 pancreatic cancer patients and 71 healthy controls) using a support vector machine learning algorithm and was applied to two validation cohorts. We recognized a set of four mass peaks at 8,766, 17,272, 28,080, and 14,779 m/z, whose mean intensities differed significantly (Mann-Whitney U test, P < 0.01), as most accurately discriminating cancer patients from healthy controls in the training cohort [sensitivity of 97.2% (69 of 71), specificity of 94.4% (67 of 71), and area under the curve value of 0.978]. This set discriminated cancer patients in the first validation cohort with a sensitivity of 90.9% (30 of 33) and a specificity of 91.1% (41 of 45), and its discriminating capacity was further validated in an independent cohort at a second institution. When combined with CA19-9, 100% (29 of 29 patients) of pancreatic cancers, including early-stage (stages I and 11) tumors, were detected. Although a multi-institutional large-scale study will be necessary to confirm clinical significance, the biomarker set identified in this study may be applicable to using plasma samples to diagnose pancreatic cancer.	Natl Canc Ctr, Res Inst, Chemotherapy Div, Chuoh Ku, Tokyo 1040045, Japan; Natl Canc Ctr, Res Inst, Canc Prote Project, Tokyo 1040045, Japan; Tokyo Med Univ, Dept Surg 3, Tokyo, Japan; Tokyo Med Univ, Dept Internal Med 4, Tokyo, Japan; Natl Canc Ctr, Hepatobiliary & Pancreat Oncol Div, Tokyo, Japan; Natl Canc Ctr, Hepatobiliary & Pancreat Surg Div, Tokyo, Japan	Yamada, T (reprint author), Natl Canc Ctr, Res Inst, Chemotherapy Div, Chuoh Ku, 5-1-1 Tsukiji, Tokyo 1040045, Japan.	tyamada@ncc.go.jp					Abrams RA, 1999, INT J RADIAT ONCOL, V44, P1039, DOI 10.1016/S0360-3016(99)00107-8; Adam BL, 2002, CANCER RES, V62, P3609; Anderson NL, 2002, MOL CELL PROTEOMICS, V1, P845, DOI 10.1074/mcp.R200007-MCP200; Baggerly KA, 2004, BIOINFORMATICS, V20, P777, DOI 10.1093/bioinformatics/btg484; Banez LL, 2003, J UROLOGY, V170, P442, DOI 10.1097/01.ju.0000069431.95404.56; Berrington de Gonzalez A, 2004, LANCET, V363, P345; Byvatov Evgeny, 2003, Appl Bioinformatics, V2, P67; Chapman K, 2002, BIOCHEM SOC T, V30, P82; Conrads TP, 2004, ENDOCR-RELAT CANCER, V11, P163, DOI 10.1677/erc.0.0110163; Coombes KR, 2005, NAT BIOTECHNOL, V23, P291, DOI 10.1038/nbt0305-291; Gansauge S, 1996, J MOL MED-JMM, V74, P313, DOI 10.1007/BF00207508; Gershon D, 2003, NATURE, V424, P581, DOI 10.1038/424581a; Goggins M, 2000, J SURG ONCOL, V74, P243, DOI 10.1002/1096-9098(200008)74:4<243::AID-JSO1>3.0.CO;2-C; Hara T, 2005, J UROLOGY, V174, P1213, DOI 10.1097/01.ju.0000173915.83164.87; HAYASHIDA Y, IN PRESS CLIN CANC R; HERLYN M, 1982, J CLIN IMMUNOL, V2, P135, DOI 10.1007/BF00916897; Howard BA, 2003, PROTEOMICS, V3, P1720, DOI 10.1002/pmic.200300514; Issaq HJ, 2002, BIOCHEM BIOPH RES CO, V292, P587, DOI 10.1006/bbrc.2002.6678; Japan Pancreas Society, 2002, GEN RUL STUD PANCR C; Kadota K, 2003, PHYSIOL GENOMICS, V12, P251, DOI 10.1152/physiolgenomics.00153.2002; Khan N, 2004, CANCER, V101, P379, DOI 10.1002/cncr.20377; Koomen JM, 2005, CLIN CANCER RES, V11, P1110; Koopmann J, 2004, CLIN CANCER RES, V10, P860, DOI 10.1158/1078-0432.CCR-1167-3; Landis SH, 1999, CA-CANCER J CLIN, V49, P8, DOI 10.3322/canjclin.49.1.8; Liotta LA, 2003, NATURE, V425, P905, DOI 10.1038/425905a; Lowenfels AB, 2004, JPN J CLIN ONCOL, V34, P238, DOI 10.1093/jjco/hyh045; METZ CE, 1978, SEMIN NUCL MED, V8, P283, DOI 10.1016/S0001-2998(78)80014-2; Narimatsu H, 1998, CANCER RES, V58, P512; Petricoin EF, 2004, CURR OPIN BIOTECH, V15, P24, DOI 10.1016/j.copbio.2004.01.005; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Ransohoff DF, 2005, J NATL CANCER I, V97, P315, DOI 10.1093/jnci/dji054; Ritts R E, 1998, Surg Oncol Clin N Am, V7, P93; Safi F, 1997, J Gastrointest Surg, V1, P106, DOI 10.1016/S1091-255X(97)80097-2; Shimamura T, 2003, J CLIN ONCOL, V21, P659, DOI 10.1200/JCO.2003.06.179; Tolson J, 2004, LAB INVEST, V84, P845, DOI 10.1038/labinvest.3700097; von Eggeling F, 2001, ELECTROPHORESIS, V22, P2898, DOI 10.1002/1522-2683(200108)22:14<2898::AID-ELPS2898>3.0.CO;2-A; WEINSTEIN PS, 1984, SCAND J IMMUNOL, V19, P193; Yamamoto M, 1998, PANCREAS, V16, P238, DOI 10.1097/00006676-199804000-00006; Zhang Z, 2004, CANCER RES, V64, P5882, DOI 10.1158/0008-5472.CAN-04-0746	39	75	80	AMER ASSOC CANCER RESEARCH	PHILADELPHIA	615 CHESTNUT ST, 17TH FLOOR, PHILADELPHIA, PA 19106-4404 USA	0008-5472		CANCER RES	Cancer Res.	NOV 15	2005	65	22					10613	10622		10.1158/0008-5472.CAN-05-1851		10	Oncology	Oncology	985ZV	WOS:000233418900063	
J	Hayashida, Y; Honda, K; Osaka, Y; Hara, T; Umaki, T; Tsuchida, A; Aoki, T; Hirohashi, S; Yamada, T				Hayashida, Y; Honda, K; Osaka, Y; Hara, T; Umaki, T; Tsuchida, A; Aoki, T; Hirohashi, S; Yamada, T			Possible prediction of chemoradiosensitivity of esophageal cancer by serum protein profiling	CLINICAL CANCER RESEARCH			English	Article							SQUAMOUS-CELL CARCINOMA; OVARIAN-CANCER; PREOPERATIVE CHEMORADIOTHERAPY; PROTEOMIC PATTERNS; MASS-SPECTROMETRY; CHEMOTHERAPY; ADENOCARCINOMA; IDENTIFICATION; BIOMARKERS; PROGNOSIS	Purpose: Establishment of a reliable method of predicting the efficacy of chemotherapy and radiotherapy is necessary to provide the most suitable treatment for each cancer patient. We investigated whether proteomic profiles of serum samples obtained from untreated patients were capable of being used to predict the efficacy of combined preoperative chemoradiotherapy against esophageal cancer. Experimental Design: Proteomic spectra were obtained from a training set of 27 serum samples (15 pathologically diagnosed responders to preoperative chemoradiotherapy and 12 non-responders) by surface-enhanced laser desorption and ionization coupled with hybrid quadrupole time-of-flight mass spectrometry. A proteomic pattern prediction model was constructed from the training set by machine learning algorithms, and it was then tested with an independent validation set consisting of serum samples from 15 esophageal cancer patients in a blinded manner. Results: We selected a set of four mass peaks, at 7,420, 9,112,17,123, and 12,867 m/z, from a total of 859 protein peaks, as perfectly distinguishing responders from nonresponders in the training set with a support vector machine algorithm. This set of peaks (i.e., the classifier) correctly diagnosed chemoradiosensitivity in 93.3% (14 of 15) of the cases in the validation set. Conclusions: Recent mass spectrometric approaches have revealed that serum contains a large volume of information that reflects the microenvironment of diseased organs. Although a multi-institutional large-scale study will be necessary to confirm each component of the classifier, there is a subtle but definite difference in serum proteomic profile between responders and nonresponders to chemoradiotherapy.	Natl Canc Ctr, Inst Res, Chemotherapy Div & Canc Proteom Project, Chuo Ku, Tokyo 1040045, Japan; Tokyo Med Univ, Dept Surg 3, Tokyo, Japan	Yamada, T (reprint author), Natl Canc Ctr, Inst Res, Chemotherapy Div & Canc Proteom Project, Chuo Ku, 5-1-1 Tsukiji, Tokyo 1040045, Japan.	tyamada@ncc.go.jp					Adam BL, 2002, CANCER RES, V62, P3609; Ancona E, 2001, CANCER, V91, P2165, DOI 10.1002/1097-0142(20010601)91:11<2165::AID-CNCR1245>3.0.CO;2-H; Baggerly KA, 2004, BIOINFORMATICS, V20, P777, DOI 10.1093/bioinformatics/btg484; Boguski MS, 2003, NATURE, V422, P233, DOI 10.1038/nature01515; Byvatov Evgeny, 2003, Appl Bioinformatics, V2, P67; Fiorica F, 2004, GUT, V53, P925, DOI 10.1136/gut.2003.025080; Gershon D, 2003, NATURE, V424, P581, DOI 10.1038/424581a; Gras R, 1999, ELECTROPHORESIS, V20, P3535, DOI 10.1002/(SICI)1522-2683(19991201)20:18<3535::AID-ELPS3535>3.3.CO;2-A; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Heath EI, 2000, J CLIN ONCOL, V18, P868; HONDA K, IN PRESS CANC RES; Issaq HJ, 2002, BIOCHEM BIOPH RES CO, V292, P587, DOI 10.1006/bbrc.2002.6678; Japanese Society for Esophageal Diseases, 2001, GUID CLIN PATH STUD; Koopmann J, 2004, CLIN CANCER RES, V10, P860, DOI 10.1158/1078-0432.CCR-1167-3; Kozak KR, 2003, P NATL ACAD SCI USA, V100, P12343, DOI 10.1073/pnas.2033602100; Liotta LA, 2003, NATURE, V425, P905, DOI 10.1038/425905a; NYGAARD K, 1992, WORLD J SURG, V16, P1104; Osaka Y, 2004, ONCOL REP, V12, P1121; OSAKA Y, 2004, NIHON GEKAKEI RENGOG, V29, P6; Petricoin EF, 2004, CURR OPIN BIOTECH, V15, P24, DOI 10.1016/j.copbio.2004.01.005; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Shimada H, 2002, BRIT J CANCER, V86, P552, DOI 10.1038/sj/bjc/6600129; Tolson J, 2004, LAB INVEST, V84, P845, DOI 10.1038/labinvest.3700097; VOGEL SB, 1995, ANN SURG, V221, P685, DOI 10.1097/00000658-199506000-00008; Walsh TN, 1996, NEW ENGL J MED, V335, P462, DOI 10.1056/NEJM199608153350702; Yanagisawa K, 2003, LANCET, V362, P433, DOI 10.1016/S0140-6736(03)14068-8; Zhang Z, 2004, CANCER RES, V64, P5882, DOI 10.1158/0008-5472.CAN-04-0746	27	20	23	AMER ASSOC CANCER RESEARCH	PHILADELPHIA	615 CHESTNUT ST, 17TH FLOOR, PHILADELPHIA, PA 19106-4404 USA	1078-0432		CLIN CANCER RES	Clin. Cancer Res.	NOV 15	2005	11	22					8042	8047		10.1158/1078-0432.CCR-05-0656		6	Oncology	Oncology	987HI	WOS:000233508600011	
J	Torabi, K; Sayad, S; Balke, ST				Torabi, K; Sayad, S; Balke, ST			On-line adaptive Bayesian classification for in-line particle image monitoring in polymer film manufacturing	COMPUTERS & CHEMICAL ENGINEERING			English	Article						on-line; adaptive; Bayesian; classification; particle; monitoring		Contaminant particles suspended in polymer melts flowing through an extruder can result in film defects which ruin film performance and appearance. In-line monitoring of the polymer melt using a specialized camera system provides images which can be used to anticipate and potentially diagnose the cause of such defects. However, image interpretation is sensitive to changes in image quality. Development of a practical method for adapting to such changes during an extrusion operation and automatically distinguish images containing contaminant particles from those that do not, was the objective of this work. This was accomplished off-line by using a database of about 6000 in-line acquired images and a very recently developed adaptive machine learning method employing a Bayesian model. Performance, robustness, structure complexity and computational time considerations are examined. (c) 2005 Elsevier Ltd. All rights reserved.	Univ Toronto, Dept Chem Engn & Appl Chem, Toronto, ON M5S 3E5, Canada	Balke, ST (reprint author), Univ Toronto, Dept Chem Engn & Appl Chem, 200 Coll St, Toronto, ON M5S 3E5, Canada.	balke@chem-eng.utoronto.ca					BLUM A, 1997, LECT NOTES COMPUT SC, V1442, P306; CHEN R, 2000, P 5 EUR C PRINC PRAC; HONGLU Y, 2003, IND ENG CHEM RES, V42, P3036; ING LD, 2001, SOC PLAST ENG ANTEC; Langley P., 1996, ELEMENTS MACHINE LEA; LITTLESTONE N, 1994, INFORM COMPUT, V108, P212, DOI 10.1006/inco.1994.1009; Opper M, 1996, PHYS REV LETT, V77, P4671, DOI 10.1103/PhysRevLett.77.4671; SAYAD S, 2003, Patent No. 60412810; SAYAD S, 2003, P 4 INT DAT MIN C RI; SOLLA SA, 1998, THEORETICAL ASPECTS, P61; TORABI K, 2002, P 3 INT DAT MIN C BO, P857; TORABI K, 2005, THESIS U TORONTO TOR; TUCKER A, 1989, P 12 ACM S OP SYST P, P159, DOI 10.1145/74850.74866; Witten I. H., 2000, DATA MINING; YOUNG IT, 1986, CYTOMETRY, V7, P467, DOI 10.1002/cyto.990070513	15	4	4	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0098-1354		COMPUT CHEM ENG	Comput. Chem. Eng.	NOV 15	2005	30	1					18	27		10.1016/j.compchemeng.2005.06.008		10	Computer Science, Interdisciplinary Applications; Engineering, Chemical	Computer Science; Engineering	994DI	WOS:000234010200002	
J	Davatzikos, C; Ruparel, K; Fan, Y; Shen, DG; Acharyya, M; Loughead, JW; Gur, RC; Langleben, DD				Davatzikos, C; Ruparel, K; Fan, Y; Shen, DG; Acharyya, M; Loughead, JW; Gur, RC; Langleben, DD			Classifying spatial patterns of brain activity with machine learning methods: Application to lie detection	NEUROIMAGE			English	Article							FUNCTIONAL MAGNETIC-RESONANCE; DECEPTION; FMRI; CLASSIFICATION; RESPONSES; CORTEX	Patterns of brain activity during deception have recently been characterized with fMRI on the multi-subject average group level. The clinical value of fMRI in lie detection will be determined by the ability to detect deception in individual subjects, rather than group averages. High-dimensional non-linear pattern classification methods applied to functional magnetic resonance (fMRI) images were used to discriminate between the spatial patterns of brain activity associated with lie and truth. In 22 participants performing a forced-choice deception task, 99% of the true and false responses were discriminated correctly. Predictive accuracy, assessed by cross-validation in participants not included in training, was 88%. The results demonstrate the potential of non-linear machine learning techniques in lie detection and other possible clinical applications of fMRI in individual subjects, and indicate that accurate clinical tests could be based on measurements of brain function with fMRI. (c) 2005 Elsevier Inc. All rights reserved.	Univ Penn, Dept Radiol, Philadelphia, PA 19104 USA; Univ Penn, Dept Psychiat, Philadelphia, PA 19104 USA; Univ Penn, Treatment Res Ctr, Philadelphia, PA 19104 USA	Davatzikos, C (reprint author), Univ Penn, Dept Radiol, 3600 Market St,Suite 380, Philadelphia, PA 19104 USA.	christos@rad.upenn.edu					Ashburner J, 1999, HUM BRAIN MAPP, V7, P254, DOI 10.1002/(SICI)1097-0193(1999)7:4<254::AID-HBM4>3.0.CO;2-G; BANDETTINI PA, 1992, MAGNET RESON MED, V25, P390, DOI 10.1002/mrm.1910250220; Bechara A, 2000, CEREB CORTEX, V10, P295, DOI 10.1093/cercor/10.3.295; CHAMBERS JM, 1991, STAT MODELS; Clark L.A., 1993, STAT MODELS S, P377; Cox DD, 2003, NEUROIMAGE, V19, P261, DOI 10.1016/S1053-8119(03)00049-1; Critchley HD, 2000, J NEUROSCI, V20, P3033; Davatzikos C, 2004, NEUROIMAGE, V23, P17, DOI 10.1016/j.neuroimage.2004.05.010; Friston K.J., 1995, HUMAN BRAIN MAPPING, V2, P189, DOI DOI 10.1002/HBM.460020402; Friston KJ, 1998, MAGNET RESON MED, V39, P41, DOI 10.1002/mrm.1910390109; Ganis G, 2003, CEREB CORTEX, V13, P830, DOI 10.1093/cercor/13.8.830; Hastie T., 2001, SPRINGER SERIES STAT; Kozel FA, 2004, BEHAV NEUROSCI, V118, P852, DOI 10.1037/0735-7044.118.4.852; Kozel FA, 2004, J NEUROPSYCH CLIN N, V16, P295, DOI 10.1176/appi.neuropsych.16.3.295; LaConte S, 2005, NEUROIMAGE, V26, P317, DOI 10.1016/j.neuroimage.2005.01.048; LANGLEBEN DD, IN PRESS HUM BRAIN M; Langleben DD, 2002, NEUROIMAGE, V15, P727, DOI 10.1006/nimg.2001.1003; Lao ZQ, 2004, NEUROIMAGE, V21, P46, DOI 10.1016/j.neuroimage.2003.09.027; Lee TMC, 2002, HUM BRAIN MAPP, V15, P157, DOI 10.1002/hbm.10020; Lykken D T, 1991, Integr Physiol Behav Sci, V26, P214, DOI 10.1007/BF02912513; McIntosh AR, 1996, NEUROIMAGE, V3, P143, DOI 10.1006/nimg.1996.0016; OTA U. S. Congress, 1983, SCI VAL POL TEST RES; ROSE KA, 1988, ECOL MODEL, V42, P1, DOI 10.1016/0304-3800(88)90089-0; Rosenfeld J. P., 2001, HDB POLYGRAPHY; SCHOLKOPF B, 2001, LEARNING KERNELS SUP, P644; SPENCE SA, 2004, NEUROIMAGING, V359, P1755; Spence SA, 2001, NEUROREPORT, V12, P2849, DOI 10.1097/00001756-200109170-00019; STERN PC, 2004, REPORT NAT RES COUNC, P340; STROTHER SC, 1995, J CEREB FLOW METAB, V15, P355; Vapnik V.N., 1999, NATURE STAT LEARNING	30	154	157	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1053-8119		NEUROIMAGE	Neuroimage	NOV 15	2005	28	3					663	668		10.1016/j.neuroimage.2005.08.009		6	Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical Imaging	Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging	983UG	WOS:000233257000013	
J	Springer, C; Adalsteinsson, H; Young, MM; Kegelmeyer, PW; Roe, DC				Springer, C; Adalsteinsson, H; Young, MM; Kegelmeyer, PW; Roe, DC			PostDOCK: A structural, empirical approach to scoring protein ligand complexes	JOURNAL OF MEDICINAL CHEMISTRY			English	Article							ITERATIVE PARTIAL EQUALIZATION; ORBITAL ELECTRONEGATIVITY; MOLECULAR DOCKING; BINDING; SOLVATION; DATABASES; ENERGY; MODEL; CLASSIFICATION; COOPERATIVITY	In this work we introduce a postprocessing filter (PostDOCK) that distinguishes true binding ligand-protein complexes from docking artifacts (that are created by DOCK 4.0.1). PostDOCK is a pattern recognition system that relies on (1) a database of complexes, (2) biochemical descriptors of those complexes, and (3) machine learning tools. We use the protein databank (PDB) as the structural database of complexes and create diverse training and validation sets from it based on the "families of structurally similar proteins" (FSSP) hierarchy. For the biochemical descriptors, we consider terms from the DOCK score, empirical scoring, and buried solvent accessible surface area. For the machine-learners, we use a random forest classifier and logistic regression. Our results were obtained on a test set of 44 structurally diverse protein targets. Our highest performing descriptor combinations obtained similar to 19-fold enrichment (39 of 44 binding complexes were correctly identified, while only allowing 2 of 44 decoy complexes), and our best overall accuracy was 92%.	Sandia Natl Labs, Livermore, CA 94551 USA	Springer, C (reprint author), Sandia Natl Labs, POB 969,MS 9951, Livermore, CA 94551 USA.	clayton.springer@novartis.com					Ben-Naim A, 1998, J CHEM PHYS, V109, P7443, DOI 10.1063/1.477366; Bissantz C, 2000, J MED CHEM, V43, P4759, DOI 10.1021/jm001044l; BOHM HJ, 1994, J COMPUT AID MOL DES, V8, P243, DOI 10.1007/BF00126743; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brunzell H, 2000, PATTERN RECOGN, V33, P1741, DOI 10.1016/S0031-3203(99)00142-9; Charifson PS, 1999, J MED CHEM, V42, P5100, DOI 10.1021/jm990352k; COVER TM, 1977, IEEE T SYST MAN CYB, V7, P657, DOI 10.1109/TSMC.1977.4309803; Duda R. O., 2001, PATTERN CLASSFICIATI; EISENBERG D, 1986, NATURE, V319, P199, DOI 10.1038/319199a0; Eldridge MD, 1997, J COMPUT AID MOL DES, V11, P425, DOI 10.1023/A:1007996124545; Ewing TJA, 2001, J COMPUT AID MOL DES, V15, P411, DOI 10.1023/A:1011115820450; GASTEIGER J, 1981, ORG MAGN RESONANCE, V15, P353, DOI 10.1002/mrc.1270150408; GASTEIGER J, 1980, TETRAHEDRON, V36, P3219, DOI 10.1016/0040-4020(80)80168-2; Gohlke H, 2000, J MOL BIOL, V295, P337, DOI 10.1006/jmbi.1999.3371; Holm L, 1997, NUCLEIC ACIDS RES, V25, P231, DOI 10.1093/nar/25.1.231; HOLM L, 1994, NUCLEIC ACIDS RES, V22, P3600; Jones G, 1997, J MOL BIOL, V267, P727, DOI 10.1006/jmbi.1996.0897; LEO A, PROGRAMS CLOP CMR; Lum K, 1999, J PHYS CHEM B, V103, P4570, DOI 10.1021/jp984327m; Majeux N, 2001, PROTEINS, V42, P256, DOI 10.1002/1097-0134(20010201)42:2<256::AID-PROT130>3.0.CO;2-4; MARSILI M, 1980, CROAT CHEM ACTA, V53; Martin YC, 2002, J MED CHEM, V45, P4350, DOI 10.1021/jm020155c; McCullagh P., 1989, GEN LINEAR MODELS; MENG EC, 1992, J COMPUT CHEM, V13, P505, DOI 10.1002/jcc.540130412; Muegge I, 1999, J MED CHEM, V42, P791, DOI 10.1021/jm980536j; OROZCO M, 1993, BIOCHEMISTRY-US, V32, P12864, DOI 10.1021/bi00210a040; Pang YP, 2001, J COMPUT CHEM, V22, P1750, DOI 10.1002/jcc.1129; Robinson GW, 1999, J CHEM PHYS, V111, P698, DOI 10.1063/1.479349; Rusinko A, 1999, J CHEM INF COMP SCI, V39, P1017, DOI 10.1021/ci9903049; Sham YY, 2000, PROTEINS, V39, P393, DOI 10.1002/(SICI)1097-0134(20000601)39:4<393::AID-PROT120>3.0.CO;2-H; Shoichet BK, 1999, PROTEINS, V34, P4, DOI 10.1002/(SICI)1097-0134(19990101)34:1<4::AID-PROT2>3.0.CO;2-6; TRUNK GV, 1979, IEEE T PATTERN ANAL, V1, P306; VARSHNEY A, 1993, FAST ANAL COMPUTATIO; VENABLES WN, 1994, MODERN APPL STAT S P; WALLQVIST A, 1995, J PHYS CHEM-US, V99, P5705, DOI 10.1021/j100015a063; WEINER SJ, 1984, J AM CHEM SOC, V106, P765, DOI 10.1021/ja00315a051; WILLETT P, SIMILARITY CLUSTERIN; Zhang LY, 2001, J COMPUT CHEM, V22, P591, DOI 10.1002/jcc.1031; Zou XQ, 1999, J AM CHEM SOC, V121, P8033, DOI 10.1021/ja984102p	39	28	28	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0022-2623		J MED CHEM	J. Med. Chem.	NOV 3	2005	48	22					6821	6831		10.1021/jm0493360		11	Chemistry, Medicinal	Pharmacology & Pharmacy	980KL	WOS:000233017300010	
J	Franke, L; Byvatov, E; Werz, O; Steinhilber, D; Schneider, P; Schneider, G				Franke, L; Byvatov, E; Werz, O; Steinhilber, D; Schneider, P; Schneider, G			Extraction and visualization of potential pharmacophore points using support vector machines: Application to ligand-based virtual screening for COX-2 inhibitors	JOURNAL OF MEDICINAL CHEMISTRY			English	Article							NONSTEROIDAL ANTIINFLAMMATORY DRUGS; FOCUSED LIBRARY DESIGN; CYCLOOXYGENASE-2 INHIBITORS; SELECTIVE-INHIBITION; 5-LIPOXYGENASE 5-LOX; RECEPTOR LIGANDS; FORCE-FIELD; IN-SILICO; IDENTIFICATION; DISCOVERY	Support vector machines (SVM) were trained to predict cyclooxygenase 2 (COX-2) and thrombin inhibitors. The classifiers were obtained using sets of known COX-2 and thrombin inhibitors as "positive examples" and a large collection of screening compounds as "negative examples". Molecules were encoded by topological pharmacophore-point triangles. In retrospective virtual screening, 50-90% of the known active compounds were listed within the first 0.1% of the ranked database. To check the validity of the constructed classifiers, we developed a method for feature extraction and visualization using SVM. As a result, potential pharmacophore points were weighted according to their importance for COX-2 and thrombin inhibition. Known thrombin and COX-2 pharmacophore points were correctly recognized by the machine learning system. In a prospective virtual screening study, several potential COX-2 inhibitors were predicted and tested in a cellular activity assay. A benzimidazole derivative exhibited significant inhibitory activity with an IC50 of 0.2 mu M, which is better than Celecoxib in our assay. It was demonstrated that the SVM machine-learning method can be used in virtual screening and be analyzed in a human-interpretable way that results in a set of rules for designing novel molecules.	Univ Frankfurt, Inst Organ Chem & Chem Biol, D-60439 Frankfurt, Germany; Univ Frankfurt, Inst Pharmazeut Chem, D-60439 Frankfurt, Germany; Schneider Consulting GbR, D-61440 Oberursel, Germany	Schneider, G (reprint author), Univ Frankfurt, Inst Organ Chem & Chem Biol, Marie Curie Str 9, D-60439 Frankfurt, Germany.	gisbert.schneider@modlab.de	Steinhilber, Dieter/J-3221-2012				Albert D, 2002, BIOCHEM PHARMACOL, V64, P1767, DOI 10.1016/S0006-2952(02)01387-4; BANNER D, 2003, PROTEIN LIGAND INTER, P163; Baxter CA, 1998, PROTEINS, V33, P367, DOI 10.1002/(SICI)1097-0134(19981115)33:3<367::AID-PROT6>3.0.CO;2-W; BERLINER LJ, 1992, THROMBIN STRUCTURE F; BRUNE K, 1985, FEBS LETT, V186, P46, DOI 10.1016/0014-5793(85)81336-3; BRUNGS M, 1995, P NATL ACAD SCI USA, V92, P107, DOI 10.1073/pnas.92.1.107; Burbidge R, 2001, COMPUT CHEM, V26, P5, DOI 10.1016/S0097-8485(01)00094-8; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; BUSH BL, 1993, J CHEM INF COMP SCI, V33, P756, DOI 10.1021/ci00015a015; Byvatov E, 2005, CHEMBIOCHEM, V6, P997, DOI 10.1002/cbic.200400400; Byvatov E, 2004, J CHEM INF COMP SCI, V44, P993, DOI 10.1021/ci0342876; Byvatov E, 2003, J CHEM INF COMP SCI, V43, P1882, DOI 10.1021/ci0341161; Byvatov Evgeny, 2003, Appl Bioinformatics, V2, P67; Charlier C, 2003, EUR J MED CHEM, V38, P645, DOI 10.1016/S0223-5234(03)00115-6; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cristianini N., 2000, INTRO SUPPORT VECTOR; CRUCIANI G, 1994, J MED CHEM, V37, P2589, DOI 10.1021/jm00042a012; Dror O, 2004, CURR MED CHEM, V11, P71, DOI 10.2174/0929867043456287; Duda R., 2000, PATTERN CLASSIFICATI; FLOWER RJ, 1972, NATURE, V240, P410, DOI 10.1038/240410a0; Guner Osman F., 2002, Current Topics in Medicinal Chemistry, V2, P1321, DOI 10.2174/1568026023392940; Halgren TA, 1996, J COMPUT CHEM, V17, P490, DOI 10.1002/(SICI)1096-987X(199604)17:5/6<490::AID-JCC1>3.0.CO;2-P; HILPERT K, 1994, J MED CHEM, V37, P3889, DOI 10.1021/jm00049a008; Horvath D, 2003, J CHEM INF COMP SCI, V43, P680, DOI 10.1021/ci025634z; Irwin JJ, 2005, J CHEM INF MODEL, V45, P177, DOI 10.1021/ci049714+; Joachims T., 1999, ADV KERNEL METHODS S, P41; Jones G, 1995, J COMPUT AID MOL DES, V9, P532, DOI 10.1007/BF00124324; Kalgutkar AS, 2001, CURR DRUG TARGETS, V2, P79, DOI 10.2174/1389450013348830; Kato M, 2001, J PHARM PHARMACOL, V53, P1679, DOI 10.1211/0022357011778070; KIKUMOTO R, 1984, BIOCHEMISTRY-US, V23, P85, DOI 10.1021/bi00296a014; KIMBALL SD, 1995, BLOOD COAGUL FIBRIN, V6, P511, DOI 10.1097/00001721-199509000-00002; Kozak KR, 2001, J BIOL CHEM, V276, P30072, DOI 10.1074/jbc.M104467200; Kurogi Y, 2001, CURR MED CHEM, V8, P1035; Kurumbail RG, 1996, NATURE, V384, P644, DOI 10.1038/384644a0; LAB UPSA, 1998, Patent No. 9815528; LAUFER S, 2001, Patent No. 00105792; Liu Y, 2004, J CHEM INF COMP SCI, V44, P1823, DOI 10.1021/ci049875d; MARTIN YC, 1993, J COMPUT AID MOL DES, V7, P83, DOI 10.1007/BF00141577; McGregor MJ, 1999, J CHEM INF COMP SCI, V39, P569, DOI 10.1021/ci980159j; Muller KR, 2005, J CHEM INF MODEL, V45, P249, DOI 10.1021/ci049737o; Palomer A, 2002, J MED CHEM, V45, P1402, DOI 10.1021/jm010458r; Patel Y, 2002, J COMPUT AID MOL DES, V16, P653, DOI 10.1023/A:1021954728347; Penning TD, 1997, J MED CHEM, V40, P1347, DOI 10.1021/jm960803q; PICKETT S, 2003, PROTEIN LIGAND INTER, P73; Renner S, 2004, J MED CHEM, V47, P4653, DOI 10.1021/jm031139y; Schneider P, 2003, QSAR COMB SCI, V22, P713, DOI 10.1002/qsar.200330825; SCHNEIDER P, 2004, CHEMOGENOMICS DRUG D, P341; Sheridan RP, 1996, J CHEM INF COMP SCI, V36, P128, DOI 10.1021/ci950275b; Sippl W, 2000, J COMPUT AID MOL DES, V14, P559, DOI 10.1023/A:1008115913787; Smith WL, 1996, J BIOL CHEM, V271, P33157; STURZEBECHER J, 1983, THROMB RES, V29, P635, DOI 10.1016/0049-3848(83)90218-9; TONG S, 2000, P 7 INT C MACH LEARN; Trummlitz G, 2002, CURR OPIN DRUG DI DE, V5, P550; Ulbrich H, 2002, EUR J MED CHEM, V37, P953, DOI 10.1016/S0223-5234(02)01418-6; Vapnik V. N, 1995, NATURE STAT LEARNING; Warmuth MK, 2003, J CHEM INF COMP SCI, V43, P667, DOI 10.1021/ci025620t; Wolber G, 2005, J CHEM INF MODEL, V45, P160, DOI 10.1021/ci049885e; YAMAMOTO S, 1987, ENZYME IMMUNOASSAY P; Zernov VV, 2003, J CHEM INF COMP SCI, V43, P2048, DOI 10.1021/ci0340916	59	37	39	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0022-2623		J MED CHEM	J. Med. Chem.	NOV 3	2005	48	22					6997	7004		10.1021/jm050619h		8	Chemistry, Medicinal	Pharmacology & Pharmacy	980KL	WOS:000233017300027	
J	Liu, HX; Yao, XJ; Zhang, RS; Liu, MC; Hu, ZD; Fan, BT				Liu, HX; Yao, XJ; Zhang, RS; Liu, MC; Hu, ZD; Fan, BT			Accurate quantitative structure-property relationship model to predict the solubility of C-60 in various solvents based on a novel approach using a least-squares support vector machine	JOURNAL OF PHYSICAL CHEMISTRY B			English	Article							DRUG-LIKENESS; QSPR; NETWORKS; PERFORMANCE; INHIBITION; FULLERENE; SERIES; QSAR	A least-squares support vector machine (LSSVM) was used for the first time as a novel machine-learning technique for the prediction of the solubility of C-60 in a large number of diverse solvents using calculated molecular descriptors from the molecular structure alone and on the basis of the software CODESSA as inputs. The heuristic method of CODESSA was used to select the correlated descriptors and build the linear model. Both the linear and the nonlinear models can give very satisfactory prediction results: the square of the correlation coefficient R-2 was 0.892 and 0.903, and the root-mean-square error was 0.126 and 0.116, respectively, for the whole data set. The prediction result of the LSSVM model is better than that obtained by the heuristic method and the reference, which proved LSSVM was a useful tool in the prediction of the solubility of C-60. In addition, this paper provided a new and effective method for predicting the solubility of C-60 from its structures and gave some insight into the structural features related to the solubility of C-60 in different solvents.	Lanzhou Univ, Dept Chem, Lanzhou 730000, Peoples R China; Lanzhou Univ, Dept Comp Sci, Lanzhou 730000, Peoples R China; Univ Paris 07, ITODYS, F-75005 Paris, France	Yao, XJ (reprint author), Lanzhou Univ, Dept Chem, Lanzhou 730000, Peoples R China.	xiaojunyao@yahoo.com					Belousov AI, 2002, CHEMOMETR INTELL LAB, V64, P15, DOI 10.1016/S0169-7439(02)00046-1; Burbidge R, 2001, COMPUT CHEM, V26, P5, DOI 10.1016/S0097-8485(01)00094-8; Burges C, 1998, DATA MIN KNOWL DISC, V2, P1, DOI DOI 10.1023/A:1009715923555; Chen N., 2004, SUPPORT VECTOR MACHI; Christianini N., 2000, INTRO SUPPORT VECTOR; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Danauskas SM, 2001, J CHEM INF COMP SCI, V41, P419, DOI 10.1021/ci000140s; Gunn SR, 1997, LECT NOTES COMPUT SC, V1280, P313; Katritzky A. R., 1994, COMPREHENSIVE DESCRI; Katritzky AR, 2001, J CHEM INF COMP SCI, V41, P1162, DOI 10.1021/ci010011r; Katritzky AR, 2001, J CHEM INF COMP SCI, V41, P1521, DOI 10.1021/ci010043e; Katritzky AR, 2003, J CHEM INF COMP SCI, V43, P1794, DOI 10.1021/ci034120c; KATRITZKY AR, 1995, CHEM SOC REV, V24, P279, DOI 10.1039/cs9952400279; Kiss IZ, 2000, J PHYS CHEM A, V104, P8081, DOI 10.1021/jp000739v; Liu HX, 2004, J COMPUT AID MOL DES, V18, P389, DOI 10.1007/s10822-004-2722-1; Ma WP, 2005, J PHYS CHEM A, V109, P3485, DOI 10.1021/jp0501446; Makitra RG, 2003, RUSS J GEN CHEM+, V73, P1227, DOI 10.1023/B:RUGC.0000007645.77987.b4; MANALLACK DT, 1999, EUR J MED CHEM, V34, P95; Marcus Y, 1997, J PHYS CHEM B, V101, P8617, DOI 10.1021/jp970671s; Marcus Y, 2001, J PHYS CHEM B, V105, P2499, DOI 10.1021/jp0023720; Morris CW, 2001, ECOL MODEL, V146, P57; Muller KR, 2005, J CHEM INF MODEL, V45, P249, DOI 10.1021/ci049737o; MURRAY JS, 1995, J PHYS CHEM-US, V99, P12081, DOI 10.1021/j100032a005; Oblak M, 2000, J CHEM INF COMP SCI, V40, P994, DOI 10.1021/ci000001a; Pelckmans K., 2002, 0244 ESATSISTA; RUOFF RS, 1993, J PHYS CHEM-US, V97, P3379, DOI 10.1021/j100115a049; Scholkopf B., 1999, ADV KERNEL METHODS S; Sivaraman N, 2001, J CHEM INF COMP SCI, V41, P1067, DOI 10.1021/ci010003a; STEWART JPP, 1989, MOPAC VERS 6 0 QUANT; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Thissen U, 2004, ANAL CHEM, V76, P3099, DOI 10.1021/ac035522m; Tugcu N, 2003, ANAL CHEM, V75, P5806, DOI 10.1021/ac0341564; Vapnik VN, 1998, STAT LEARNING THEORY; Yao XJ, 2002, ANAL CHIM ACTA, V462, P101, DOI 10.1016/S0003-2670(02)00273-8; Yao XJ, 2004, J CHEM INF COMP SCI, V44, P1257, DOI 10.1021/ci049965i; Yasri A, 2001, J CHEM INF COMP SCI, V41, P1218, DOI 10.1021/ci010291a; Zernov VV, 2003, J CHEM INF COMP SCI, V43, P2048, DOI 10.1021/ci0340916; *HYP INC, 1994, HYP VERS 4 0	38	40	40	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1520-6106		J PHYS CHEM B	J. Phys. Chem. B	NOV 3	2005	109	43					20565	20571		10.1021/jp052223n		7	Chemistry, Physical	Chemistry	979QL	WOS:000232959800073	
J	Nouali, O; Blache, P				Nouali, O; Blache, P			Email automatic filtering - An adaptive and multi-level approach	ANNALES DES TELECOMMUNICATIONS-ANNALS OF TELECOMMUNICATIONS			French	Article; Proceedings Paper	Conference on Technologies and Tools for 3D-Imaging	MAY 25-26, 2004	Lille, FRANCE			electronic mail; filtering; adaptive method; machine learning; linguistic model; spam message		This article proposes an electronic mail system with several levels of filtering: a simple filtering based on contents analysis of the message header fields; a Boolean filtering based on the existence or not of key words in the body of the courriel; a Vectorial filtering based on weight of key words; a linguistic filtering based on the linguistic properties characterizing structure and contents of courriel. We propose an adaptive solution by using an automatic learning method which allows the filtering system to learn from data, to modify its knowledge and to adapt to user's interests. Moreover, we use a lexical network to improve message representation and to take into account the semantic aspect.	CERIST, Lab Logiciels Base, Algiers 16030, Algeria; Univ Aix Marseille 1, LPL, F-13621 Aix En Provence, France	Nouali, O (reprint author), CERIST, Lab Logiciels Base, Rue 3 Freres Aissiou, Algiers 16030, Algeria.	onouali@mail.cerist.dz; pb@lpl.univ-aix.fr					AITMOKHTAR S, 1997, P 5 C APPL NAT LANG, P72, DOI 10.3115/974557.974569; AMINI MR, 2001, THESIS U PARIS 6; Androutsopoulos I., 2000, P WORKSH MACH LEARN, P9; BENHAZEZ S, 2001, TALN 2001, P73; Biber D., 1988, VARIATION ACROSS SPE; Brill E., 1992, P 3 C APPL NAT LANG, P152, DOI 10.3115/974499.974526; Bronckart J.-P., 1985, FONCTIONNEMENT DISCO; CAROPRESO M, 2001, LEARNER INDEPENDENT, P78; CARRERAS X, 2001, P RANLP 01 4 INT C R; CHANDRASEKAR R, 1997, P RIAO 97, P531; Collins M., 1996, P 34 ANN M ACL SANT; COPECK T, 2000, TALN2000; DAVALO E, 1993, RES NEURONES; DESCLES JP, 1997, CONTEXT 97, P189; DREYFUS G, 2002, RES NEURONES METHODO; GARCIA D, 1998, RIFRA 98 RENCONTRE I, P44; HABERT B, 2000, JADT 2000 5 JOURN IN; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Joachims T., 1997, P 14 INT C MACH LEAR, P143; JUNKER M, 1997, P RANLP 97 2 INT C R, P202; APTE C, 1994, ACM T INFORM SYST, V12, P233, DOI 10.1145/183422.183423; LEWIS DD, 1994, P 3 ANN S DOC AN INF; LEWIS DD, 1992, P SIGIR 92 15 ACM IN, P35; MARCU D, 1997, WORKSH INT SCAL TEXT; MCCALLUM A, 1998, LEARNING TEXT CATEGO; Miller G., 1990, INT J LEXICOGRAPHY; MINEL JL, 2001, REV TECHNIQUE SCI IN; NAMER F, 2000, TRAITEMENT AUTOMATIQ, V41, P523; NOUALI O, 2004, THESIS U SCI TECHNOL; ORASAN C, 2002, P LREC 2002 LAS PALM; POIBEAU T, 1999, TAL, V40, P87; Sahami M, 1998, LEARNING TEXT CATEGO, P55; SEBASTIANI F, 1999, P ASAI 99 1 ARG S AR; Yang Y., 1997, INT C MACH LEARN ICM	34	1	1	PRESSES POLYTECHNIQUES ET UNIVERSITAIRES ROMANDES	LAUSANNE	EPFL-ECUBLENS, CENTRE MIDI, CH-1015 LAUSANNE, SWITZERLAND	0003-4347		ANN TELECOMMUN	Ann. Telecommun.-Ann Telecommun.	NOV-DEC	2005	60	11-12					1466	1487				22	Telecommunications	Telecommunications	016HP	WOS:000235611600010	
J	Nguyen, MH; Abbass, HA; McKay, RI				Nguyen, MH; Abbass, HA; McKay, RI			Stopping criteria for ensemble of evolutionary artificial neural networks	APPLIED SOFT COMPUTING			English	Article						ensemble; artificial neural network; machine learning; early stopping; negative correlation learning; island model; MOP; evolutionary computation; (mu plus lambda) evolutionary strategies	NEGATIVE CORRELATION	The formation of ensemble of artificial neural networks has attracted attentions of researchers in the machine learning and statistical inference domains. It has been shown that combining different neural networks could improve the generalization ability of the learning machine. One challenge is when to stop the training or evolution of the neural networks to avoid overfitting. In this paper, we show that different early stopping criteria based on (i) the minimum validation fitness of the ensemble, and (ii) the minimum of the average population validation fitness could generalize better than the survival population in the last generation. The proposition was tested on four different ensemble methods: (i) a simple ensemble method, where each individual of the population (created and maintained by the evolutionary process) is used as a committee member, (ii) ensemble with island model as a diversity promotion mechanism, (iii) a recent successful ensemble method namely ensemble with negative correlation learning and (iv) an ensemble formed by applying multi-objective optimization. The experimental results suggested that using minimum validation fitness of the ensemble as an early stopping criterion is beneficial. (C) 2005 Elsevier B.V. All rights reserved.	Univ New S Wales, Australian Def Force Acad, Sch Informat Technol & Elect Engn, ALAR Lab, Canberra, ACT 2600, Australia	Nguyen, MH (reprint author), Univ New S Wales, Australian Def Force Acad, Sch Informat Technol & Elect Engn, ALAR Lab, Canberra, ACT 2600, Australia.	z2280951@student.adfa.edu.au; h.abbass@adfa.edu.au; r.mckay@adfa.edu.au	Abbass, Hussein/C-9563-2009				Abbass HA, 2003, LECT NOTES ARTIF INT, V2903, P554; Adamidis P., 1994, REV PARALLEL GENETIC; Back T., 1996, EVOLUTIONARY ALGORIT; Blake C. L., 1998, UCI REPOSITORY MACHI; CHANDRA A, 2004, P 5 INT C INT DAT EN, P619; Chellapilla K, 1999, P IEEE, V87, P1471, DOI 10.1109/5.784222; CHO SB, 2001, P 2001 C EV COMP, V1, P390; CHO SB, 2001, P IJCNN 01 INT JOINT, V2, P808; Coello CAC, 2001, LECT NOTES COMPUT SC, V1993, P21; Haykin S., 1999, NEURAL NETWORKS COMP; ISLAM MM, 2001, IEEE INT C SYST MAN, V3, P1526; Islam M, 2003, IEEE T NEURAL NETWOR, V14, P820, DOI 10.1109/TNN.2003.813832; Jimenez D.A., 1998, P 1998 INT JOINT C N, P753; KUNCHEVA LI, 2003, LECT NOTES COMPUTER, P1126; LIN G, 1996, P INT C PAR ALG, V1, P605; Liu Y, 1999, NEURAL NETWORKS, V12, P1399, DOI 10.1016/S0893-6080(99)00073-8; Liu Y, 2000, IEEE T EVOLUT COMPUT, V4, P380; Liu Y, 1997, PROCEEDINGS OF 1997 IEEE INTERNATIONAL CONFERENCE ON EVOLUTIONARY COMPUTATION (ICEC '97), P605; McKay R. I., 2001, Australian Journal of Intelligent Information Processing Systems, V7; OPTIZ DW, 1996, CONNECT SCI, V8, P337; Rechenberg I., 1994, WERKSTATT BIONIK EVO, V1; Rechenberg I., 1973, EVOLUTIONSSTRATEGIE; Rosen B. E., 1996, Connection Science, V8, DOI 10.1080/095400996116820; SCHWEFEHM HP, 1981, NUMERICAL OPTIMIZATI; SHARKEY AJC, 1998, COMBINING ARTIFICIAL; Van Veldhuizen DA, 2000, EVOL COMPUT, V8, P125; WU JX, 2001, P 8 INT C NEUR INF P, V3, P1477; Yao X, 1997, IEEE T NEURAL NETWOR, V8, P694, DOI 10.1109/72.572107; YAO X, 1996, IEEE INT C EV COMP I, P659; Yao X, 1999, P IEEE, V87, P1423; Yao X, 1998, IEEE T SYST MAN CY B, V28, P417, DOI 10.1109/3477.678637; Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X; Zitzler E., 1999, THESIS SWISS FEDERAL	33	10	11	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1568-4946		APPL SOFT COMPUT	Appl. Soft. Comput.	NOV	2005	6	1					100	107		10.1016/j.asoc.2004.12.005		8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	974EG	WOS:000232573500009	
J	Delany, SJ; Cunningham, P; Coyle, L				Delany, SJ; Cunningham, P; Coyle, L			An assessment of case-based reasoning for spam filtering	ARTIFICIAL INTELLIGENCE REVIEW			English	Article; Proceedings Paper	15th Artificial Intelligence and Cognitive Science Conference (AICS 2004)	SEP, 2004	Castlebar, IRELAND			case base reasoning; spam filtering	LEARNING ALGORITHMS	Because of the changing nature of spam, a spam filtering system that uses machine learning will need to be dynamic. This suggests that a case-based (memory-based) approach may work well. Case-Based Reasoning (CBR) is a lazy approach to machine learning where induction is delayed to run time. This means that the case base can be updated continuously and new training data is immediately available to the induction process. In this paper we present a detailed description of such a system called ECUE and evaluate design decisions concerning the case representation. We compare its performance with an alternative system that uses Naive Bayes. We find that there is little to choose between the two alternatives in cross-validation tests on data sets. However, ECUE does appear to have some advantages in tracking concept drift over time.	Dublin Inst Technol, Dublin 8, Ireland; Univ Dublin Trinity Coll, Dublin 2, Ireland; Natl Univ Ireland Univ Coll Dublin, Dublin 4, Ireland	Delany, SJ (reprint author), Dublin Inst Technol, Kevin St, Dublin 8, Ireland.	sarahjane.delany@comp.dit.ie					Andrieu B, 2000, BIOFUTUR, V2000, P13; ANDROUTSOPOULOS I, 2000, 200402 NCSR; Androutsopoulos I., 2000, P WORKSH MACH LEARN, P9; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Cuadrado J., 2003, SEMANTIC SEARCH UNST; Cunningham P., 2003, ICCBR 2003 WORKSH LO; Delany SJ, 2004, LECT NOTES COMPUT SC, V3155, P128; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; GEE KR, 2003, SAC 03 P 2003 ACM S, P460; Kohavi R., 1997, P 9 EUR C MACH LEARN; Lenz M., 1998, Case-based reasoning technology. From foundations to applications; Lewis DD, 1994, P 3 ANN S DOC AN INF, P81; McKenna E, 2000, FR ART INT, V54, P60; Niblett T, 1987, PROGR MACHINE LEARNI, P67; PANTEL P, 1988, P WORKSH TEXT CAT AA, P95; Quinlan J.R., 1997, C4 5 PROGRAMS MACHIN; Sahami M., 1998, P AAAI WORKSH LEARN, P55; Sakkis G, 2003, INFORM RETRIEVAL, V6, P49, DOI 10.1023/A:1022948414856; WILSON D, 1997, ICML 97, P403; Yang Y, 1997, ICML 97, P412; 2000, Patent No. 6161130	23	18	20	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0269-2821		ARTIF INTELL REV	Artif. Intell. Rev.	NOV	2005	24	3-4					359	378		10.1007/s10462-005-9006-6		20	Computer Science, Artificial Intelligence	Computer Science	994GI	WOS:000234018800008	
J	Mahony, S; Hendrix, D; Smith, TJ; Golden, A				Mahony, S; Hendrix, D; Smith, TJ; Golden, A			Self-organizing maps of position weight matrices for motif discovery in biological sequences	ARTIFICIAL INTELLIGENCE REVIEW			English	Article; Proceedings Paper	15th Artificial Intelligence and Cognitive Science Conference (AICS 2004)	SEP, 2004	Castlebar, IRELAND			biological motif discovery; self-organizing map	IDENTIFICATION; PATTERNS; SITES; DICTIONARY; ALGORITHM; GENOMES; GENES	The identification of overrepresented motifs in a collection of biological sequences continues to be a relevant and challenging problem in computational biology. Currently popular methods of motif discovery are based on statistical learning theory. In this paper, a machine-learning approach to the motif discovery problem is explored. The approach is based on a Self-Organizing Map (SOM) where the output layer neuron weight vectors are replaced by position weight matrices. This approach can be used to characterise features present in a set of sequences, and thus can be used as an aid in overrepresented motif discovery. The SOM approach to motif discovery is demonstrated using biological sequence datasets, both real and simulated.	NUI Galway, Natl Ctr Biomed Engn Sci, Galway, Ireland; Univ Calif Berkeley, Ctr Integrat Genom, Berkeley, CA 94720 USA; NUI Galway, Dept Informat Technol, Galway, Ireland	Mahony, S (reprint author), NUI Galway, Natl Ctr Biomed Engn Sci, Galway, Ireland.	shaun.mahony@nuigalway.ie					Abe T, 2003, GENOME RES, V13, P693, DOI 10.1101/gr.634603; Bailey T L, 1994, Proc Int Conf Intell Syst Mol Biol, V2, P28; Bussemaker HJ, 2000, P NATL ACAD SCI USA, V97, P10096, DOI 10.1073/pnas.180265397; Gupta M, 2003, J AM STAT ASSOC, V98, P55, DOI 10.1198/016214503388619094; Hughes JD, 2000, J MOL BIOL, V296, P1205, DOI 10.1006/jmbi.2000.3519; Kanaya S, 2001, GENE, V276, P89, DOI 10.1016/S0378-1119(01)00673-4; Kohonen T., 1995, SELF ORG MAPS; Kohonen T, 2002, NEURAL NETWORKS, V15, P945, DOI 10.1016/S0893-6080(02)00069-2; LAWRENCE CE, 1993, SCIENCE, V262, P208, DOI 10.1126/science.8211139; LAWRENCE CE, 1990, PROTEINS, V7, P41, DOI 10.1002/prot.340070105; Liu X, 2001, Pac Symp Biocomput, P127; Mahony S, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-23; Matys V, 2003, NUCLEIC ACIDS RES, V31, P374, DOI 10.1093/nar/gkg108; Pevzner P A, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P269; Rigoutsos I, 1998, BIOINFORMATICS, V14, P55, DOI 10.1093/bioinformatics/14.1.55; Sinha S, 2002, NUCLEIC ACIDS RES, V30, P5549, DOI 10.1093/nar/gkf669; Wan HH, 2003, J COMPUT BIOL, V10, P171, DOI 10.1089/106652703321825955; Wang HC, 2001, MOL BIOL EVOL, V18, P792; Yang ZR, 2003, J CHEM INF COMP SCI, V43, P1748, DOI 10.1021/ci034138n	19	8	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0269-2821		ARTIF INTELL REV	Artif. Intell. Rev.	NOV	2005	24	3-4					397	413		10.1007/s10462-005-9011-9		17	Computer Science, Artificial Intelligence	Computer Science	994GI	WOS:000234018800010	
J	Panait, L; Luke, S				Panait, L; Luke, S			Cooperative multi-agent learning: The state of the art	AUTONOMOUS AGENTS AND MULTI-AGENT SYSTEMS			English	Review						multi-agent systems; machine learning; multi-agent learning; cooperation; survey	SYSTEMS; EVOLUTION; AGENTS; MODELS; COMMUNICATION; COEVOLUTION; STRATEGIES; COMMUNITY; BEHAVIOR	Cooperative multi-agent systems (MAS) are ones in which several agents attempt, through their interaction, to jointly solve tasks or to maximize utility. Due to the interactions among the agents, multi-agent problem complexity can rise rapidly with the number of agents or their behavioral sophistication. The challenge this presents to the task of programming solutions to MAS problems has spawned increasing interest in machine learning techniques to automate the search and optimization process. We provide a broad survey of the cooperative multi-agent learning literature. Previous surveys of this area have largely focused on issues common to specific subareas (for example, reinforcement learning, RL or robotics). In this survey we attempt to draw from multi-agent learning work in a spectrum of areas, including RL, evolutionary computation, game theory, complex systems, agent modeling, and robotics. We find that this broad view leads to a division of the work into two categories, each with its own special issues: applying a single learner to discover joint solutions to multi-agent problems (team learning), or using multiple simultaneous learners, often one per agent (concurrent learning). Additionally, we discuss direct and indirect communication in connection with learning, plus open issues in task decomposition, scalability, and adaptive dynamics. We conclude with a presentation of multi-agent learning problem domains, and a list of multi-agent learning resources.	George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA	Panait, L (reprint author), George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA.	lpanait@cs.gmu.edu; sean@cs.gmu.edu					ACKLEY DH, 1994, ARTIFICIAL LIFE, V4; ANDRE D, 1999, ROBOCUP 98 ROBOT SOC, V2; ANDRE D, 1996, GENETIC PROGRAMMING; ANGELINE PJ, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P264; ARTHUR WB, 1994, AM ECON REV, V84, P406; Back T., 1996, EVOLUTIONARY ALGORIT; BALCH T, 1997, GITCC9712; Balch T., 1998, THESIS GEORGIA I TEC; Balch T., 1999, IJCAI 99 WORKSH AG L; BANERJEE B, 2000, AGENTS 00 W3R5SH DEC, P9; Barto A.G., 1990, LEARNING COMPUTATION; BASSETT JK, 2002, THESIS G MAS U; BASSETT JK, 2000, P 12 INT S METH INT, P157; Beckers R., 1994, ARTIFICIAL LIFE; Benda M, 1986, BCSG201028 BOEING AD; BERENJI H, 2000, IIS0010; BERENJI HR, 2000, P 9 IEEE INT C FUZZ; BERNSTEIN D, 2000, P UAI 2000 16 C UNC; BLUMENTHAL HJ, 2004, P ART MULT LEARN PAP; Bonabeau E., 1999, SWARM INTELLIGENCE N; Bongard JC, 2000, LECT NOTES COMPUT SC, V1802, P16; Boutilier C, 1996, P 6 C THEOR ASP RAT, P195; BOWLING M, 2003, THESIS CARNEGIE MELL; Bowling M., 2001, P 17 INT JOINT C ART, P1021; BOWLING M, 2000, CMUCS00165 COMP SCI; BOWLING M, 2000, P 17 INT C MACH LEAR, P89; BOWLING M, 2002, CMUCS02104 COMP SCI; Bowling M, 2002, ARTIF INTELL, V136, P215, DOI 10.1016/S0004-3702(02)00121-2; Boyan J. A., 1994, ADV NIPS, V6, P671; BRAFMAN R, 2002, ADV NEURAL INFORMATI; Brauer W., 1998, Proceedings International Conference on Multi Agent Systems (Cat. No.98EX160), DOI 10.1109/ICMAS.1998.699030; BRAZDIL P, 1991, LECT NOTES ARTIF INT, V482, P412; BUFFET O, 2002, P 1 INT JOINT C AUT; BUFLET O, 2001, P 5 INT C AUT AG MON, P31; BUI H, 1998, AGENTS MULTAGENT SYS, V1441, P164, DOI 10.1007/BFb0055027; Bui HH, 1999, INT J COOP INF SYST, V8, P275; BULL L, 1997, P 7 ANN C GEN ALG; Bull L., 1997, P 7 INT C GEN ALG, P370; BULL L, 1998, P 7 ANN C EV PROGR, P43; BULL L, 1994, P 3 ANN C EV PROGR, P308; BUTILIER C, 1996, UNCERTAINTY ARTIFICI, P106; Cangelosi A, 2001, IEEE T EVOLUT COMPUT, V5, P93, DOI 10.1109/4235.918429; Cao YU, 1997, AUTON ROBOT, V4, P7, DOI 10.1023/A:1008855018923; CARMEL D, 1997, THESIS ISRAEL I TECH; CARMEL D, 1994, 9402 TECHN ISR I TEC; Cederman Lars-Erik, 1997, EMERGENT ACTORS WORL; CHALKIADAKIS G, 2003, P 2 INT JOINT C AUT; CHALUPSKY H, 2002, AI MAGAZINE      SUM; CHANG YH, 2003, P NEUR INF PROC SYST; CHANG YH, 2004, P ART MULT LEARN P 2; Claus C., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Cliff D., 1995, P 3 EUR C ART LIF, P200; Collins R. J., 1991, Parallel Problem Solving from Nature. 1st Workshop, PPSN 1 Proceedings; Collins R. J., 1992, ARTIF LIFE, VII, P579; CRAWFORD E, 2004, P ART MULT LEARN 200; CRESPI V, 2002, TR2002414 DARTM COLL; CRITES RH, 1996, THESIS U MASSACHUSET; CUTKOSKY MR, 1997, READINGS AGENTS, P46; DAHL T, 2002, P 2002 IEEE RSJ INT; DAS R, 1994, PARALLEL PROBLEM SOL, V3, P344; DAVIS J, 2002, P 2002 C EV COMP EV; De Jong K. A., 1975, THESIS U MICHIGAN AN; DEBOER B, 1997, P 4 EUR C ART LIF; Decker K, 1999, KNOWL ENG REV, V14, P279, DOI 10.1017/S026988899900301X; DECKER KS, 1989, DISTRIBUTED ARTIFICI, V2, P487; DEJONG KA, 2005, EVOLUTIONARY COMPUTA; DENEUBOURG JL, 1991, FROM ANIMALS TO ANIMATS, P356; Denzinger J., 1996, P ICMAS 96 KYOT, P48; DOWELL M, 1995, THESIS U S CAROLINA; DRESNER K, 2004, AAMAS 2004; DUDEK G, 1993, P IEEE RSJ C INT ROB; DURFEE E, 1992, NAT C ART INT, P858; DURFEE EH, 1987, IEEE T COMPUT, V36, P1275; Durfee E. H., 1989, IEEE Transactions on Knowledge and Data Engineering, V1, DOI 10.1109/69.43404; DUTECH A, 2001, P IJCAI 01 C SEATTL, P833; Fernandez F., 2001, International Journal of Robotics & Automation, V16; FICICI SG, 2000, P 6 INT C PAR PROBL; FICICI SG, 1998, P 6 INT C ART LIF, P238; FISCHER K, 1993, P 5 EUR WORKSH MOD A; Fogel D.B., 2001, BLONDIE24 PLAYING ED; Fogel LJ, 1999, INTELLIGENCE SIMULAT; Fudenberg D., 1998, THEORY LEARNING GAME; Garland A, 2004, AUTON AGENT MULTI-AG, V8, P267, DOI 10.1023/B:AGNT.0000018808.95119.9e; GHAVAMZADEH M, 2004, AAMAS 2004; GLANCE NS, 1994, SCI AM, V270, P76; GMYTRASIEWICZ P, 1992, THESIS U MICHIGAN; Goldberg DE, 1989, GENETIC ALGORITHMS S; Goldman C. V., 1996, Adaption and Learning in Multi-Agent Systems. IJCAI '95 Workshop. Proceedings; GOOD BM, 2000, THESIS U SUSSEX; GORDIN M, 1997, AAAI 97 WORKSH MULT, P31; Grand S., 1997, Proceedings of the First International Conference on Autonomous Agents, DOI 10.1145/267658.267663; Grand S., 1997, AUTON AGENT MULTI-AG, V1, P39, DOI 10.1023/A:1010042522104; GRECU DL, 1997, THESIS WORCESTER POL; GREENWALD A, 2002, P G HOPP CEL WOM COM; GREENWALD A, 2003, P 20 INT C MACH LEAR; Grefenstette JJ, 1991, P 4 INT C GEN ALG SA, P303; GREFENSTETTE JJ, 1990, MACH LEARN, V5, P355, DOI 10.1007/BF00116876; GUESTRIN C, 2002, P 2002 AAAI S SER CO; Gustafson SM, 2001, LECT NOTES COMPUT SC, V2038, P291; Gustafson S.M., 2000, THESIS KANSAS STATE; Hara A., 1999, P 1999 GEN EV COMP C, P1038; HARVEY I, 1996, ROBOT AUTON SYST; HAYNES T, 1995, GENETIC ALGORITHMS, P271; HAYNES T, 1995, LECT NOTES ARTIFICIA; Haynes T., 1996, Adaptation, Coevolution and Learning in Multiagent Systems. Papers from the 1996 AAAI Symposium (TR SS-96-01); HAYNES T, 1996, UTULSAMCS9609; HAYNES T, 1996, AAAI 96 WORKSH AG MO, P46; Haynes T., 1997, Genetic Programming 1997 Proceedings of the Second Annual Conference; HAYNES T, 1995, UTULSAMCS9504; Haynes T., 1995, AAAI 95 FALL S GP, P23; HAYNES TD, 1997, INT J COMPUT INTELL; Hillis D, 1991, ARTIFICIAL LIFE 2, V10, P313; Holland J., 1975, ADAPTATION NATURAL A; HOLLAND JH, 1985, P INT C GEN ALG; HOLLDOBLER B, 1990, ANTS; HSU WH, 2002, GENETIC EVOLUTIONARY, P764; HU J, 1996, P 2 INT C MULT SYST; Hu J., 1998, P 2 INT C AUT AG, P239, DOI 10.1145/280765.280839; Hu J., 1998, P 15 INT C MACH LEAR, P242; Hu J.L., 2003, J MACHINE LEARNING R, V4, P1039, DOI 10.1162/jmlr.2003.4.6.1039; HUANG J, 1995, LECT NOTES ARTIF INT, V890, P219; HUHNS M, 1998, MACHINE LEARN J, V33; HUHNS MN, 1998, READINGS AGENTS, P1; IBA H, 1998, INFORM SCI, V108; IBA H, 1999, ADV GENETIC PROGRAMM, V3, P447; Iba H, 1996, LNCS, V1141, P32; IMAM I, 1996, INTELLIGENT ADAPTIVE; ITO A, 1997, ARTIF LIFE, V5, P185; JANSEN T, 2003, P GEN EV COMP C GECC; JENNINGS NR, 1993, ENG APPL ARTIF INTEL, V6, P317, DOI 10.1016/0952-1976(93)90016-Q; JUILLE H, 1998, P 3 ANN GEN PROGR C; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237; KAPETANAKIS S, 2002, P 2 S AD AG MULT SYS; KAPETANAKIS S, 2002, P 19 NAT C ART INT A; KENDALL G, 2001, P 14 AUSTR JOINT C A; Kendall G, 2001, IEEE C EVOL COMPUTAT, P995, DOI 10.1109/CEC.2001.934299; KIM KC, 2000, ARTIF LIFE, V6, P237; Kitano H., 1997, Proceedings of the First International Conference on Autonomous Agents, DOI 10.1145/267658.267738; Koza J. R., 1992, GENETIC PROGRAMMING; Lauer M., 2000, P 17 INT C MACH LEAR, P535; LEERINK LR, 1995, P 6 AUSTR C NEUR NET; LESSER V, 1987, UMCS19871111; Lesser VR, 1999, IEEE T KNOWL DATA EN, V11, P133, DOI 10.1109/69.755622; Lichbach M. I., 1996, COOPERATORS DILEMMA; Littman M. L., 2001, P 18 INT C MACH LEAR, P322; Littman M. L., 1994, P 11 INT C MACH LEAR, P157; LUBBERTS A, 2001, COEVOLUTION TURNING; LUCK M, 1998, KNOWL ENG REV, P214; Luck M, 1998, KNOWL ENG REV, V13, P297, DOI 10.1017/S0269888998003014; Luke S., 1996, Genetic Programming. Proceedings of the First Annual Conference 1996; LUKE S, 2004, GMUCSTR20041 DEP COM; Luke S., 1998, Genetic Programming 1998. Proceedings of the Third Annual Conference; LUKE S, 1997, P 1 INT WORKSH ROBOC; LUKE S, 1998, MACHINE LEARN, V32, P237; MAHADEVAN S, 1991, NAT C ART INT, P768; Makar R., 2001, P 5 INT C AUT AG, P246, DOI 10.1145/375735.376302; MATARIC M, 1998, JOINT SPECIAL ISSUE, V31, P141; MATARIC M, 1994, THESIS MIT CAMBRIDGE; MATARIC M, 1994, 3 INT C SIM AD BEH; MATARIC M, AITR1495; MATARIC MJ, 1994, INT C MACH LEARN, P181; Mataric M. J., 1995, Proceedings. 1995 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human Robot Interaction and Cooperative Robots (Cat. No.95CB35836), DOI 10.1109/IROS.1995.525940; Mataric MJ, 1997, AUTON ROBOT, V4, P73, DOI 10.1023/A:1008819414322; Michalewicz Z, 1996, GENETIC ALGORITHMS D; Michaud F, 1998, AUTON ROBOT, V5, P335, DOI 10.1023/A:1008814507256; MICONI T, 2003, P 18 INT JOINT C ART; Miconi T., 2001, P GEN EV COMP C GECC, P876; Mitchell M., 1996, P 1 INT C EV COMP IT; Werfel J, 2000, IEEE T EVOLUT COMPUT, V4, P388, DOI 10.1109/4235.887238; MONEKOSSO N, 2002, P 8 IB C ART INT IBE, P224; MONEKOSSO N, 2001, P 2 WORKSH CENTR E E, P197; MONEKOSSO N, 2001, AI2001 ADV ARTIFICIA, P345; MONEKOSSO N, 2002, LECT NOTES ARTIFICIA, V2296; MOODY J, 2004, P ART MAN LEARN 2004; MUKHEREE R, 2001, AG 2001 WORKSH LEARN; MUKHOPADJYAY U, 1986, J AM SOC INFORM SCI, V37; MULLER JP, 1994, INT J INTELL COOP I, V3, P25, DOI 10.1142/S021821579400003X; MUNDHE M, 2000, P INT C MULT SYST; Mundhe M., 2000, P GEN EV COMP C GECC, P809; NAGAYUKI Y, 2000, P INT C MULT SYST IC; NAGENDRAPRASAD M, 1997, THESIS U MASSACHUSET; NAIR R, 2003, P 18 INT JOINT C ART; Nowak MA, 1998, NATURE, V393, P573, DOI 10.1038/31225; NOWE A, 2001, LEARNING AGENTS HOMO; NUNES L, 2004, AAMAS 2004; OKHO T, 1997, LECT NOTES ARTIFICIA, V1221; OSTERGAARD E, 2001, P 5 INT C SIM SYNTH; Pagie L, 2001, COEVOLUTION TURNING, P20; PANAIT L, 2004, PARALLEL PROBLEM SOL; PANAIT L, 2003, P 18 INT JOINT C ART; PANAIT L, 2004, GEN EV COMP C GECCO; PANAIT L, 2004, AAMAS 20004; Panait L., 2004, P 9 INT C SIM SYNTH; PAPADIMITRIOU CH, 1987, MATH OPER RES, V12, P441, DOI 10.1287/moor.12.3.441; PARKER L, 2002, AUTON ROBOTS, V12; PARKER L, 2000, P 5 INT S DISTR AUT; Parker L., 2001, ROBOT TEAMS DIVERSIT; PARKER L. E., 2000, DISTRIBUTED AUTONOMO, V4, P3; PARUNAK HV, 1996, FDN DISTRIBUTED AI; PECENY M, 1996, FKI21896 TU MUNCH I; PEETERS M, 2004, P ART MULT LEARN; Peshkin L., 2000, 16 C UNC ART INT SAN, P307; POLI R, 2002, FDN GENETIC ALGORITH, V7; POLLACK JB, 1997, ARTIF LIFE, V5, P92; Pollack JB, 1998, MACH LEARN, V32, P225, DOI 10.1023/A:1007417214905; POPOVICI E, 2004, ART MULT S 2004 AAAI; POTTER M, 2001, P 17 INT C ART INT I; Potter M. A., 1997, THESIS G MASON U FAI; Potter MA, 1994, LECT NOTES COMPUT SC, V866, P249; Potter MA, 2000, EVOL COMPUT, V8, P1, DOI 10.1162/106365600568086; Potter M.A., 1995, P 6 INT C GEN ALG, P366; PUPPALA N, 1998, P 1998 IEEE WORLD C, P570; QUINN M, 2002, 515 U SUSS SCH COGN; Quinn M, 2001, IEEE C EVOL COMPUTAT, P128, DOI 10.1109/CEC.2001.934381; QUINN M, 2001, ADV ARTIFICIAL LIFE; Reynolds C. W., 1994, ARTIF LIFE, P59; Reynolds C. W., 1987, COMPUT GRAPH, V21, P25, DOI DOI 10.1145/37402.37406; REYNOLDS CW, 1993, ANIMALS ANIMATS, V2, P384; Riley P, 2000, DISTRIBUTED AUTONOMO, P371; ROBINSON A, 2002, GEN EV COMP C GECCO; Rosin CD, 1997, EVOL COMPUT, V5, P1, DOI 10.1162/evco.1997.5.1.1; SALUSTOWICZ R, 1997, LEARNING TEAM STRATE; Salustowicz RP, 1998, MACH LEARN, V33, P263, DOI 10.1023/A:1007570708568; Samuel A.L., 1959, IBM Journal of Research and Development, V3; SANDHOLM T, 1995, ADAPTATION LEARNING, P191; SANTANA H, 2004, AAMAS 2004; SAUNDERS G, 1996, ANIMALS ANIMATS, V4; SAUTER J, 2001, EVOLUTIONARY COMPUTA, P321; Sauter J. A., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems; SCHMIDHUBER J, 1996, LEARNING DISTRIBUTED; SCHMIDHUBER J, 1996, ECAI WORKSH LDAIS IC, P82; Schneider J., 1999, P 16 INT C MACH LEAR, P371; Schultz A., 1996, ROBOTICS MANUFACTURI, V6, P763; SCHWUTTKE UM, 1993, P 13 INT JOINT C ART; SEKARAN M, 1995, P 17 ANN C COGN SCI, P736; SEN S, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P426; Sen S, 1997, TRENDS COGN SCI, V1, P334, DOI 10.1016/S1364-6613(97)01100-5; Sen S, 1998, J EXP THEOR ARTIF IN, V10, P333, DOI 10.1080/095281398146798; SEN S, 1996, P IJCAI WORKSH AD LE, V1042, P218; SEN S, 1995, LECT NOTES ARTIF INT, P206; Sen S, 1998, INT J HUM-COMPUT ST, V48, P1, DOI 10.1006/ijhc.1997.0157; SHOHAM Y, 2004, P ART MULT LEARN 200; Smith R. E., 1993, 94002 TCGA U AL DEP; SPECTOR L, 2002, WORKSH P 8 INT C SIM, P163; SPECTOR L, 2003, P GEN EV COMP C GECC; STEEB R, 1988, READINGS DISTRIBUTED, P90; STEELS L, 1996, P ART LIF, V5; Steels L., 1996, P SIM AD BEH C; Steels Luc, 1995, Artificial Life, V2, P319; STEELS L, 2000, KOGNITIONSWISSENSCHA, V8, P143, DOI 10.1007/s001970050001; STEELS L, 1997, APPROACHES EVOLUTION; Steels L., 1996, MACHINE INTELLIGENCE; STEELS L, 1999, P ECAL99 EUR C ART L, P679; Stone P., 1998, THESIS CARNEGIE MELL; STONE P, 1997, P NAT C ART INT AAAI; STONE P, 2002, LECT NOTES COMPUTER, V2377, P214; Stone P, 2000, AUTON ROBOT, V8, P345, DOI 10.1023/A:1008942012299; Sturtevant N. R., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); Subramanian D., 1997, P 15 INT JOINT C ART, P832; Suematsu N., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems; Suryadi D., 1999, P 7 INT C US MOD; Sutton R. S., 1988, Machine Learning, V3, DOI 10.1007/BF00115009; Sutton R.S., 1998, REINFORCEMENT LEARNI; SVENNEBRING J, 2003, P INT C ROB AUT ICRA; TAMBE M, 1995, P 1 INT C MULT SYST; TAN M, 1993, READINGS AGENTS, P487; TANGAMCHT P, 2002, P IEEE C ROB AUT; Tesauro G, 2002, AUTON AGENT MULTI-AG, V5, P289, DOI 10.1023/A:1015504423309; TESAURO G, 1995, COMMUN ACM, V38, P58, DOI 10.1145/203330.203343; THOEN PJ, 2004, P 15 EUR C MACH LEAR; Thrun S., 1995, ADV NEURAL INFORMATI, V7, P1069; TUMER K, 2002, P 1 INT JOINT C AUT, P378; TUYLS K, 2003, AAMAS 2003; UTHER W, 2003, CMUCS03107 SCH COMP; VARGA LZ, 1994, EXPERT SYST APPL, V7, P563, DOI 10.1016/0957-4174(94)90080-9; VIDAL J, 1998, P 3 ANN C MULT SYST; VIDAL J, 1997, AAAI 97 WORKSH MULT; VIDAL J, 2003, AUTONOMOUS AGENTS MU; Wagner K, 2000, ARTIF LIFE, V6, P149, DOI 10.1162/106454600568384; Wang X., 2002, ADV NEURAL INFORM PR; WATSON R, 2001, P GEN EV COMP C GECC; WEIGAND RP, 2002, P 2002 C EV COMP CEC, P1600; Weihmayer R., 1994, AI APPROACHES TELECO; WEINBERG M, 2004, AAMAS 2004; WEISS G, 1996, LECT NOTES ARTIFICAL, V1042; Weiss G., 1999, MULTIAGENT SYSTEMS M; WEISS G, 1994, FKI18994 TU MUNCH I; Weiss G., 1999, COLLABORATIVE LEARNI, P64; WEISS G, 1998, J EXP THEO ARTIF INT, V10; WEISS G, 1995, DISTRIBUTED MACHINE; Weiss G., 1997, LECT NOTES ARTIFICIA, V1221; Wellman MP, 1998, MACH LEARN, V33, P179, DOI 10.1023/A:1007514623589; WERGER BB, 1999, IRIS99378 U SO CAL; WERNER GM, 1993, ANIMALS ANIMATS, V2; White T., 1998, Genetic Programming 1998. Proceedings of the Third Annual Conference; WHITESON S, 2003, AAMAS 2003; Wiegand R., 2001, P GEN EV COMP C GECC, P1235; WIEGAND RP, 2004, PARALLEL PROBLEM SOL; Wiegand R.P., 2003, THESIS G MASON U; WIEGAND RP, 2002, FDN GENETIC ALGORITH, V7, P231; Wiering M, 1999, AUTON ROBOT, V7, P77, DOI 10.1023/A:1008921914343; Williams AB, 2004, AUTON AGENT MULTI-AG, V8, P165, DOI 10.1023/B:AGNT.0000011160.45980.4b; Wilson E.O., 1975, SOCIOBIOLOGY NEW SYN; Wolpert D. H., 1999, Proceedings of the Third International Conference on Autonomous Agents, DOI 10.1145/301136.301167; WOLPERT DH, 2001, ADV COMPLEX SYST, V4, P265, DOI 10.1142/S0219525901000188; Wolpert DH, 1999, ADV NEUR IN, V11, P952; Wooldridge M., 1998, AUTON AGENT MULTI-AG, V1, P7, DOI 10.1023/A:1010090405266; WOOLDRIDGE M, 1996, P 1 INT C PRACT APPL; WU A, 1999, IEEE COMP INT ROB AU; YANCO H, 1993, ANIMALS ANIMATS, V2, P478; ZAERA N, 1996, HPL9604; ZHANG BT, 1998, ADV GENETIC PROGRAMM, V3, P425; Zhao J., 1996, ANIMALS ANIMATS, P516	313	153	157	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1387-2532		AUTON AGENT MULTI-AG	Auton. Agents Multi-Agent Syst.	NOV	2005	11	3					387	434		10.1007/s10458-005-2631-2		48	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	971IK	WOS:000232377200005	
J	Ressom, HW; Varghese, RS; Abdel-Hamid, M; Eissa, SAL; Saha, D; Goldman, L; Petricoin, EF; Conrads, TP; Veenstra, TD; Loffredo, CA; Goldman, R				Ressom, HW; Varghese, RS; Abdel-Hamid, M; Eissa, SAL; Saha, D; Goldman, L; Petricoin, EF; Conrads, TP; Veenstra, TD; Loffredo, CA; Goldman, R			Analysis of mass spectral serum profiles for biomarker selection	BIOINFORMATICS			English	Article							OVARIAN-CANCER; PROTEOMIC PATTERNS; SPECTROMETRY; IDENTIFICATION; RESOLUTION; DISCOVERY; CARCINOMA; DIAGNOSIS; SAMPLES; MARKER	Motivation: Mass spectrometric profiles of peptides and proteins obtained by current technologies are characterized by complex spectra, high dimensionality and substantial noise. These characteristics generate challenges in the discovery of proteins and protein-profiles that distinguish disease states, e.g. cancer patients from healthy individuals. We present low-level methods for the processing of mass spectral data and a machine learning method that combines support vector machines, with particle swarm optimization for biomarker selection. Results: The proposed method identified mass points that achieved high prediction accuracy in distinguishing liver cancer patients from healthy individuals in SELDI-QqTOF profiles of serum.	Georgetown Univ, Lombardi Comprehens Canc Ctr, Washington, DC 20057 USA; NHTMRI, Viral Hepatitis Res Lab, Cairo, Egypt; Natl Canc Inst, Cairo, Egypt; NCI, US FDA, Clin Proteom Program, Ctr Biol Evaluat, Bethesda, MD 20892 USA; NCI, SAIC Frederick, Frederick, MD 21701 USA; NCI, Biomed Proteom Program, Frederick, MD 21701 USA	Ressom, HW (reprint author), Georgetown Univ, Lombardi Comprehens Canc Ctr, Washington, DC 20057 USA.	hwr@georgetown.edu	Varghese, Rency/A-8770-2012				Baggerly KA, 2004, BIOINFORMATICS, V20, P777, DOI 10.1093/bioinformatics/btg484; Baggerly KA, 2003, PROTEOMICS, V3, P1667, DOI 10.1002/pmic.200300522; Conrads TP, 2004, ENDOCR-RELAT CANCER, V11, P163, DOI 10.1677/erc.0.0110163; COOMBES KR, 2004, UTMDABTR00104 U TEX; Diamandis EP, 2004, MOL CELL PROTEOMICS, V3, P367, DOI 10.1074/mcp.R400007-MCP200; Eilers PHC, 1996, STAT SCI, V11, P89, DOI 10.1214/ss/1038425655; EZZAT S, 2005, IN PRESS INT J HYG E; Fung E. T., 2002, BIOTECHNIQUES S, V32, P34; Koomen JM, 2005, CLIN CANCER RES, V11, P1110; Koopmann J, 2004, CLIN CANCER RES, V10, P860, DOI 10.1158/1078-0432.CCR-1167-3; Li JN, 2002, CLIN CHEM, V48, P1296; Malyarenko DI, 2005, CLIN CHEM, V51, P65, DOI 10.1373/clinchem.2004.037283; Paradis V, 2005, HEPATOLOGY, V41, P40, DOI 10.1002/hep.20505; Petricoin EF, 2002, J NATL CANCER I, V94, P1576; PETRICOIN EF, 2004, BMC BIOINFORMATICS, V4; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Pusztai L, 2004, CANCER, V100, P1814, DOI 10.1002/cncr.20203; Ransohoff DF, 2005, NAT REV CANCER, V5, P142, DOI 10.1038/nrc1550; RESSOM H, 2005, P GEN EV COMP C GECC, V1, P431; Sauve A., 2004, P GEN SIGN PROC STAT; SEMMES OJ, 2004, CLIN CHEM, V51, P102, DOI 10.1373/clinchem.2004.038950; Sorace JM, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-24; Villanueva J, 2004, ANAL CHEM, V76, P1560, DOI 10.1021/ac0352171; Yasui Y, 2003, BIOSTATISTICS, V4, P449, DOI 10.1093/biostatistics/4.3.449; Zhang Z, 2004, CANCER RES, V64, P5882, DOI 10.1158/0008-5472.CAN-04-0746; Zhu W, 2003, P NATL ACAD SCI USA, V100, P14666, DOI 10.1073/pnas.2532248100	26	49	53	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	NOV 1	2005	21	21					4039	4045		10.1093/bioinformatics/bti670		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	978VM	WOS:000232901100016	
J	Yu, C; Ballard, DH; Aslin, RN				Yu, C; Ballard, DH; Aslin, RN			The role of embodied intention in early lexical acquisition	COGNITIVE SCIENCE			English	Review						language acquisition; computational model; machine learning; embodied cognition; cognitive development	WORD SEGMENTATION; COMPUTATIONAL PERSPECTIVE; SPEECH SEGMENTATION; SOUND PATTERNS; FLUENT SPEECH; INFANTS; CUES; RECOGNITION; MODEL; LANGUAGE	We examine the influence of inferring interlocutors' referential intentions from their body movements at the early stage of lexical acquisition. By testing human participants and comparing their performances in different learning conditions, we find that those embodied intentions facilitate both word discovery and word-meaning association. In light of empirical findings, the main part of this article presents a computational model that can identify the sound patterns of individual words from continuous speech, using nonlinguistic contextual information, and employ body movements as deictic references to discover word-meaning associations. To our knowledge, this work is the first model of word learning that not only learns lexical items from raw multisensory signals to closely resemble infant language development from natural environments, but also explores the computational role of social cognitive skills in lexical acquisition.	Indiana Univ, Dept Psychol, Bloomington, IN 47405 USA; Indiana Univ, Cognit Sci Program, Bloomington, IN 47405 USA; Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA; Univ Rochester, Dept Brain & Cognit Sci, Rochester, NY 14627 USA	Yu, C (reprint author), Indiana Univ, Dept Psychol, Bloomington, IN 47405 USA.	chenyu@indiana.edu					ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913; AGGARWAL CC, 2000, P ACM SIGM DALL TX; ARBIB MA, IN PRESS BEHAV BRAIN; Aslin RN, 1996, SIGNAL TO SYNTAX: BOOTSTRAPPING FROM SPEECH TO GRAMMAR IN EARLY ACQUISITION, P117; Bahrick LE, 2004, CURR DIR PSYCHOL SCI, V13, P99, DOI 10.1111/j.0963-7214.2004.00283.x; BAILEY D, 1998, 20 ANN M COGN SCI SO; Bailey D., 1997, THESIS U CALIFORNIA; Baldwin DA, 1996, CHILD DEV, V67, P3135, DOI 10.1111/j.1467-8624.1996.tb01906.x; BALDWIN DA, 1993, DEV PSYCHOL, V29, P832, DOI 10.1037/0012-1649.29.5.832; BALLARD DH, 2003, P IEEE INT C AC SPEE, V5, P784; BALLARD DH, 1997, BEHAV BRAIN SCI, V20, P1311; Baron-Cohen S., 1995, MINDBLINDNESS ESSAY; Bloom P., 2000, CHILDREN LEARN MEANI; Booth AE, 2002, DEV PSYCHOL, V38, P948, DOI 10.1037//0012-1649.38.6.948; Brent MR, 1999, TRENDS COGN SCI, V3, P294, DOI 10.1016/S1364-6613(99)01350-9; Brent MR, 1999, MACH LEARN, V34, P71, DOI 10.1023/A:1007541817488; Brent MR, 1997, J PSYCHOLINGUIST RES, V26, P363, DOI 10.1023/A:1025032825951; Brent MR, 1996, COGNITION, V61, P93, DOI 10.1016/S0010-0277(96)00719-6; Brown P. F., 1993, Computational Linguistics, V19; Butterworth G. E., 1991, NATURAL THEORIES MIN, P223; Carey S., 1978, PAPERS REPORTS CHILD, V15, P17; CASELLI MC, 2000, LANGUAGE DEV ESSENTI, P76; Christiansen MH, 1998, LANG COGNITIVE PROC, V13, P221; CHURCH KW, 1987, COGNITION, V25, P53, DOI 10.1016/0010-0277(87)90004-7; CLARK A, 1997, BEING PUTTING BRAIN; COHEN PR, 2001, LECT NOTES ARTIF INT, V2225, P32; CUTLER A, 1992, J MEM LANG, V31, P218, DOI 10.1016/0749-596X(92)90012-M; Ervin-Tripp Susan, 1973, COGNITIVE DEV ACQUIS, P261; GENTNER D, 1982, LANGUAGE DEV, V2, P310; Gillette J, 1999, COGNITION, V73, P135, DOI 10.1016/S0010-0277(99)00036-0; Gleitman L., 1990, LANG ACQUIS, V1, P1, DOI DOI 10.1207/S153278171A0101_2; GLEITMAN L, 2005, LANGUAGE LEARNING DE, V1; Gleitman L. R., 1995, INVITATION COGNITIVE, V1; Gogate LJ, 2001, DEVELOPMENTAL SCI, V4, P1, DOI 10.1111/1467-7687.00143; Gopnik A., 1995, NAMES THINGS YOUNG C, P63; Griffin ZM, 2000, PSYCHOL SCI, V11, P274, DOI 10.1111/1467-9280.00255; Hartigan J. A., 1975, CLUSTERING ALGORITHM; Johnson EK, 2001, J MEM LANG, V44, P548, DOI 10.1006/jmla.2000.2755; Jusczyk P. W., 1997, DISCOVERY SPOKEN LAN; Jusczyk PW, 1999, COGNITIVE PSYCHOL, V39, P159, DOI 10.1006/cogp.1999.0716; JUSCZYK PW, 1995, COGNITIVE PSYCHOL, V29, P1, DOI 10.1006/cogp.1995.1010; Jusczyk PW, 1999, PERCEPT PSYCHOPHYS, V61, P1465, DOI 10.3758/BF03213111; KRUSKAL JB, 1999, TIME WARPS STRING ED, P1; Kuhl PK, 2003, P NATL ACAD SCI USA, V100, P9096, DOI 10.1073/pnas.1532872100; Ladefoged P., 1993, COURSE PHONETICS; LAKOFF G, 1999, PHILOSOPHY FLESH EMB; Lakoff G., 1980, METAPHORS WE LIVE; LANDAU B, 2004, WEAVING LEXCON, P110; LANDAU B, 1998, TRENDS COGNITIVE SCI; Li P, 2004, NEURAL NETWORKS, V17, P1345, DOI 10.1016/j.neunet.2004.07.004; Macnamara J., 1982, NAMES THINGS STUDY C; MacWhinney B, 1989, LINGUISTIC CATEGORIZ, P195; MANDEL DR, 1995, PSYCHOL SCI, V6, P314, DOI 10.1111/j.1467-9280.1995.tb00517.x; MARKMAN E, 1995, ACQUISITION LEXICON, P199; Markson L, 1997, NATURE, V385, P813, DOI 10.1038/385813a0; Mattys SL, 2001, COGNITION, V78, P91, DOI 10.1016/S0010-0277(00)00109-8; Mel BW, 1997, NEURAL COMPUT, V9, P777, DOI 10.1162/neco.1997.9.4.777; Meyer AS, 1998, COGNITION, V66, pB25, DOI 10.1016/S0010-0277(98)00009-2; Pinker S., 1989, LEARNABILITY COGNITI; Plunkett K, 1997, TRENDS COGN SCI, V1, P146, DOI 10.1016/S1364-6613(97)01039-5; Plunkett K., 1992, Connection Science, V4, DOI 10.1080/09540099208946620; Quine W. V., 1960, WORLD OBJECT; QUINN PC, 1993, PERCEPTION, V22, P463, DOI 10.1068/p220463; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; REGIER T, 2001, P 23 ANN M COGN SCI, P815; Regier T, 2003, TRENDS COGN SCI, V7, P263, DOI 10.1016/S1364-6613(03)00108-6; Regier T., 1996, HUMAN SEMANTIC POTEN; RICHARDS DD, 1986, COGNITIVE DEV, V1, P183; ROBERTS K, 1991, COGNITIVE DEV, V6, P355, DOI 10.1016/0885-2014(91)90044-E; Robinson T, 1994, IEEE T NEURAL NETWOR, V5, P298; Roy DK, 2002, COGNITIVE SCI, V26, P113, DOI 10.1016/S0364-0213(01)00061-1; Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926; Saffran JR, 1997, PSYCHOL SCI, V8, P101, DOI 10.1111/j.1467-9280.1997.tb00690.x; Saffran JR, 1996, J MEM LANG, V35, P606, DOI 10.1006/jmla.1996.0032; Salvucci D.D., 2000, P EYE TRACK RES APPL, P71, DOI DOI 10.1145/355017.355028; Salvucci DD, 1998, PROCEEDINGS OF THE TWENTIETH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P923; Schiele B, 2000, INT J COMPUT VISION, V36, P31, DOI 10.1023/A:1008120406972; Schyns PG, 1997, J EXP PSYCHOL LEARN, V23, P681, DOI 10.1037//0278-7393.23.3.681; Schyns PG, 1998, BEHAV BRAIN SCI, V21, P1; SISKIND JM, 1999, 99033 NEC RES I; Siskind JM, 1996, COGNITION, V61, P39, DOI 10.1016/S0010-0277(96)00728-7; Slater A, 1999, DEVELOPMENTAL SCI, V2, P333, DOI 10.1111/1467-7687.00079; Slobin D, 1985, CROSSLINGUISTIC STUD, P1157; Sloutsky VM, 1999, DEV PSYCHOL, V35, P1478, DOI 10.1037/0012-1649.35.6.1478; Smith L. B., 2000, BECOMING WORD LEARNE, P51; Smith LB, 1996, COGNITION, V60, P143, DOI 10.1016/0010-0277(96)00709-3; SNEDEKER J, 2004, WEAVING LEXICON, pR20; STEELS L, 1997, EVOLUTION HUMAN LANG, P384; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Tardif T, 1996, DEV PSYCHOL, V32, P492, DOI 10.1037//0012-1649.32.3.492; Tenenbaum JB, 2000, PROCEEDINGS OF THE TWENTY-SECOND ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P517; Thiessen ED, 2003, DEV PSYCHOL, V39, P706, DOI 10.1037/0012-1649.39.4.706; Tomasello M., 2001, LANG ACQUIS, P132, DOI 10.1017/CBO9780511620669.007; TOMASELLO M, 2000, LANGUAGE ACQUISITION, P111; TOMASELLO M, 1986, CHILD DEV, V57, P1454, DOI 10.1111/j.1467-8624.1986.tb00470.x; Wang S, 2003, IEEE T PATTERN ANAL, V25, P675, DOI 10.1109/TPAMI.2003.1201819; WAXMAN S, 1993, CHILD DEV, V29, P257; WAXMAN SR, 2004, WEAVING LEXCON, P110; Wellman H.M., 2004, CHILD DEV, V75, P502; Williams S., 1989, I WENT WALKING; Woodward AL, 2002, COGNITIVE DEV, V17, P1061, DOI 10.1016/S0885-2014(02)00074-6; Yu C., 2004, ACM T APPL PERCEPT, V1, P57, DOI 10.1145/1008722.1008727; YU C, 2003, P 5 INT C COGN MOD B, P219; Yu C, 2003, PROCEEDINGS OF THE TWENTY-FIFTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, PTS 1 AND 2, P1293	104	41	41	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0364-0213		COGNITIVE SCI	Cogn. Sci.	NOV-DEC	2005	29	6					961	1005		10.1207/s15516709cog0000_40		45	Psychology, Experimental	Psychology	997LA	WOS:000234245600004	
J	Epstein, SL; Freuder, EC; Wallace, RJ				Epstein, SL; Freuder, EC; Wallace, RJ			Learning to support constraint programmers	COMPUTATIONAL INTELLIGENCE			English	Article						constraint satisfaction; machine learning; mixture of experts; cognitively-oriented architecture	HEURISTICS; SEARCH	This paper describes the Adaptive Constraint Engine (ACE), an ambitious ongoing research project to support constraint programmers, both human and machine. The program begins with substantial knowledge about constraint satisfaction. The program harnesses a cognitively-oriented architecture (FORR) to manage search heuristics and to learn new ones. ACE can transfer what it learns on simple problems to solve more difficult ones, and can readily export its knowledge to ordinary constraint solvers. It currently serves both as a learner and as a test bed for the constraint community.	CUNY Hunter Coll, Dept Comp Sci, New York, NY 10021 USA; CUNY, Grad Ctr, New York, NY USA; Natl Univ Ireland Univ Coll Cork, Cork Constraint Computat Ctr, Cork, Ireland	Epstein, SL (reprint author), CUNY Hunter Coll, Dept Comp Sci, New York, NY 10021 USA.						Beck J., 2003, 13 INT C AUT PLANN S; Bessiere C., 1996, LNCS, V1118, P61; BISWAS G, 1995, COGNITIVELY DIAGNOST, P167; BORRETT J, 1996, 12 EUR C AI BUD HUNG; CARBONELL JG, 1991, ARCHITECTURES INTELL; Chatterjee S., 1987, American Journal of Mathematical and Management Sciences, V7; CHEESEMAN PB, 1991, 12 INT JOINT C ART I; CROWLEY K, 1993, COGNITIVE SCI, V17, P531, DOI 10.1207/s15516709cog1704_3; Dechter R., 2003, CONSTRAINT PROCESSIN; EPSTEIN SL, 2001, MACHINES LEARN PLAY, P153; EPSTEIN SL, 2001, PRINCIPLES PRACTICE, V2239, P46, DOI 10.1007/3-540-45578-7_4; EPSTEIN SL, 1995, 14 INT JOINT C ART I; EPSTEIN SL, 2002, PRINCIPLES PRACTICE, V2470, P525; Epstein SL, 1998, ARTIF INTELL, V100, P275, DOI 10.1016/S0004-3702(97)00083-0; EPSTEIN SL, 2004, AAAI SPRING S KNOWL; EPSTEIN SL, 2004, COGNITIVE SCI; Epstein S. L., 1998, Constraints, V3, DOI 10.1023/A:1009734028965; FREUDER E, 1992, CONSTRAINT BASED REA; FREUDER EC, 1982, J ACM, V29, P24, DOI 10.1145/322290.322292; FROST, 1995, IJCAI 95 MONTR; GASCHNIG J, 1979, 6 INT JOINT C ART IN; GEELEN PA, 1992, 10 EUR C ART INT VIE; GENT IE, 1996, 13 NAT C ART INT POR; Gigerenzer G., 1999, SIMPLE HEURISTICS MA; Gigerenzer G, 1996, PSYCHOL REV, V103, P650, DOI 10.1037//0033-295X.103.4.650; Ginsberg M. L., 1993, J ARTIFICIAL INTELLI, V1, P25; Gomes CP, 2000, J AUTOM REASONING, V24, P67, DOI 10.1023/A:1006314320276; JACOBS RA, 1995, NEURAL COMPUT, V7, P867, DOI 10.1162/neco.1995.7.5.867; JOHNSON DS, 1989, OPER RES, V37, P865, DOI 10.1287/opre.37.6.865; KEIM GA, 1999, 16 NAT C ART INT; KIZILTAN Z, 2001, KI 01; KONDRAK G, 1995, 14 INT JOINT C ART I; LANGLEY P, 1985, COGNITIVE SCI, V9, P217, DOI 10.1207/s15516709cog0902_2; MACKWORTH AK, 1977, ARTIF INTELL, V8, P99, DOI 10.1016/0004-3702(77)90007-8; Minton S., 1996, Constraints, V1, DOI 10.1007/BF00143877; MITCHELL T, 1991, THEO FRAMEWORK SELF; NUDEL B, 1983, ARTIF INTELL, V21, P135, DOI 10.1016/S0004-3702(83)80008-3; Prosser P., 1993, COMPUT INTELL, V9, P268, DOI 10.1111/j.1467-8640.1993.tb00310.x; RATTERMAN MJ, 1995, 17 ANN C COGN SCI SO; ROSENBLOOM PS, 1991, ARCHITECTURES INTELL; RUAN Y, 2004, AAAI 2004; Sabin D, 1997, LECT NOTES COMPUT SC, V1330, P167; SCHRAAGEN JM, 1993, COGNITIVE SCI, V17, P285, DOI 10.1207/s15516709cog1702_4; SCLIMMER JG, 1986, 5 NAT C ART INT PHIL; SOLNON C, 2002, EVOWORKSHOPS 2002 AP; Sutton R.S., 1998, REINFORCEMENT LEARNI; Tsang E., 1993, FDN CONSTRAINT SATIS; WALSH T, 1999, IJCAI 99	48	4	4	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0824-7935		COMPUT INTELL-US	Comput. Intell.	NOV	2005	21	4					336	371		10.1111/j.1467-8640.2005.00277.x		36	Computer Science, Artificial Intelligence	Computer Science	969LN	WOS:000232235800002	
J	Carchrae, T; Beck, JC				Carchrae, T; Beck, JC			Applying machine learning to low-knowledge control of optimization algorithms	COMPUTATIONAL INTELLIGENCE			English	Article						algorithm selection; algorithm control; machine learning; classifiers; scheduling		This paper addresses the question of allocating computational resources among a set of algorithms to achieve the best performance on scheduling problems. Our primary motivation in addressing this problem is to reduce the expertise needed to apply optimization technology. Therefore, we investigate algorithm control techniques that make decisions based only on observations of the improvement in solution quality achieved by each algorithm. We call our approach "low knowledge" since it does not rely on complex prediction models, either of the problem domain or of algorithm behavior. We show that a low-knowledge approach results in a system that achieves significantly better performance than all of the pure algorithms without requiring additional human expertise. Furthermore the low-knowledge approach achieves performance equivalent to a perfect high-knowledge classification approach.	Natl Univ Ireland Univ Coll Cork, Dept Comp Sci, Cork Constraint Computat Ctr, Cork, Ireland; Univ Toronto, Dept Mech & Ind Engn, Toronto Intelligent Decis Engn Lab, Toronto, ON, Canada	Carchrae, T (reprint author), Natl Univ Ireland Univ Coll Cork, Dept Comp Sci, Cork Constraint Computat Ctr, Cork, Ireland.						BECK J, 2004, P 1 INT C INT AI OR, P50; BECK JC, 2000, P 2 INT WORKSH INT A; Beck JC, 2000, ARTIF INTELL, V117, P31, DOI 10.1016/S0004-3702(99)00099-5; Boyan J., 2000, J MACHINE LEARNING R, V1, P77; CHCKERING DM, 2002, MSRTR2002103 MICR; Cohen P. R., 1995, EMPIRICAL METHODS AR; Horvitz E., 2001, P 17 C UNC ART INT U, P235; Kautz H., 2002, P 18 NAT C ART INT A, P674; Laborie P, 2003, ARTIF INTELL, V143, P151, DOI 10.1016/S0004-3702(02)00362-4; LAGOUDAKIS MG, 2000, P 17 INT C MACH LEAR; Le Pape C., 2002, Principles and Practice of Constraint Programming - CP 2002. 8th International Conference, CP 2002. Proceedings (Lecture Notes in Computer Science Vol.2470); Leyton-Brown K., 2002, Principles and Practice of Constraint Programming - CP 2002. 8th International Conference, CP 2002. Proceedings (Lecture Notes in Computer Science Vol.2470); LUBY M, 1993, INFORM PROCESS LETT, V47, P173, DOI 10.1016/0020-0190(93)90029-9; Minton S., 1996, Constraints, V1, DOI 10.1007/BF00143877; Nowicki E, 1996, MANAGE SCI, V42, P797, DOI 10.1287/mnsc.42.6.797; Nuijten W. P. M., 1994, THESIS EINDHOVEN U T; Rice J. R., 1976, ADV COMPUT, V15, P65, DOI 10.1016/S0065-2458(08)60520-3; Ruan Y., 2002, P 8 INT C PRINC PRAC, P573; SCHEDULER, 2001, ILOG SCHEDULER 5 2 U; Watson JP, 2002, INFORMS J COMPUT, V14, P98, DOI 10.1287/ijoc.14.2.98.120; WATSON JP, 2003, THESIS COLORADO STAT; WU H, 2003, 9 INT C PRINC PRACT, P1001	22	18	18	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	0824-7935		COMPUT INTELL	Comput. Intell.	NOV	2005	21	4					372	387		10.1111/j.1467-8640.2005.00278.x		16	Computer Science, Artificial Intelligence	Computer Science	969LN	WOS:000232235800003	
J	Pearson, DJ; Laird, JE				Pearson, DJ; Laird, JE			Combining learning from instruction with recovery from incorrect knowledge	COMPUTATIONAL INTELLIGENCE			English	Article						procedural knowledge; incremental learning; error detection; error recovery; planning; symbolic; operators; theory revision; machine learning		Autonomous agents that learn about their environment can be divided into two broad classes. One class of existing learners, reinforcement learners, typically employ weak learning methods to directly modify an agent's execution knowledge. These systems are robust in dynamic and complex environments but generally do not support planning or the pursuit of multiple goals. In contrast, symbolic theory revision systems learn declarative planning knowledge that allows them to pursue multiple goals in large state spaces, but these approaches are generally only applicable to fully sensed, deterministic environments with no exogenous events. This research investigates the hypothesis that by limiting an agent to procedural access to symbolic planning knowledge, the agent can combine the powerful, knowledge-intensive learning performance of the theory revision systems with the robust performance in complex environments of the reinforcement learners. The system, IMPROV, uses an expressive knowledge representation so that it can learn complex actions that produce conditional or sequential effects over time. By developing learning methods that only require limited procedural access to the agent's knowledge, IMPROV's learning remains tractable as the agent's knowledge is scaled to large problems. IMPROV learns to correct operator precondition and effect knowledge in complex environments that include such properties as noise, multiple agents and time-critical tasks, and demonstrates a general learning method that can be easily strengthened through the addition of many different kinds of knowledge.	ThreePenny Software, Seattle, WA USA; Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA	Pearson, DJ (reprint author), 4649 Eastern Ave N, Seattle, WA 98103 USA.	doug-web1@sunnyhome.org					BAFFES P, 1993, P 13 INT JOINT C ART, P1135; BOOKER LB, 1989, ARTIF INTELL, V40, P234; FIKES RE, 1971, ARTIF INTELL, V2, P189, DOI 10.1016/0004-3702(71)90010-5; GIL Y, 1993, P 10 INT C MACH LEAR, P128; GIL Y, 1994, P 11 INT C MACH LEAR, P87; Gil Yolanda, 1992, THESIS CARNEGIE MELL; Holland J. H, 1986, MACHINE LEARNING ART, VII; LAIRD JE, 1987, ARTIF INTELL, V33, P1, DOI 10.1016/0004-3702(87)90050-6; MILLER CS, 1993, THESIS U MICHIGAN AN; MILLER CS, 1991, 13 ANN C COGN SCI SO, P827; OURSTON D, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P815; Pazzani M., 1991, P 8 INT WORKSH MACH, P432; PAZZANI MJ, 1988, P 5 INT WORKSH MACH, P291; Pearson D. J., 1996, THESIS U MICHIGAN; PEARSON DJ, 1995, MACH LEARN C WORKSH; PEARSON DJ, 1999, MACHINE INTELLIGENCE, V15; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; Samuel A.L., 1959, IBM Journal of Research and Development, V3; Shen W., 1989, P IJCAI 89 DETR MI, P675; Sutton R. S., 1988, Machine Learning, V3, DOI 10.1007/BF00115009; TESAURO G, 1992, P INT C MACH LEARN I, P451; Wang X., 1995, P 12 INT C MACH LEAR, P549; Wang X., 1996, THESIS CARNEGIE MELL; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698	25	3	3	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	0824-7935		COMPUT INTELL	Comput. Intell.	NOV	2005	21	4					414	439		10.1111/j.1467-8640.2005.00280.x		26	Computer Science, Artificial Intelligence	Computer Science	969LN	WOS:000232235800005	
J	Upal, MA				Upal, MA			Learning to improve plan quality	COMPUTATIONAL INTELLIGENCE			English	Article						machine learning; AI planning; search-control rules; rewrite rules	CONTROL KNOWLEDGE; SEARCH	Adaptive automated planning systems that can, over time, improve the quality of plans they produce are a promising prospect. The first part of the article discusses the issues involved in designing quality improving learning for planning systems and reviews recent work on learning to improve plan quality. The second part describes our work on the Performance Improving Planning (PIP) System. The heart of PIP is an analytic technique that compares two planning episodes for solving a planning problem that led to two different quality solutions-a higher-quality solution and a lower quality solution-and identifies the critical differences that were responsible for the resulting differences in the quality of the completed plans. We compare the effectiveness of two different ways of storing and applying the knowledge learned from this analysis-as search-control rules and as rewrite rules. The results show that the search-control rules are more effective in improving plan quality. Further analysis of PIP-search-control-the version of PIP that stores the learned knowledge as search-control rules-shows that it is an effective technique for improving plan quality in a variety of situations.	Univ Toledo, Dept Elect Engn & Comp Sci, Toledo, OH 43606 USA	Upal, MA (reprint author), Univ Toledo, Dept Elect Engn & Comp Sci, Toledo, OH 43606 USA.	afzal@eecs.utoledo.edu					Adam F., 2004, ENTERPRISE RESOURCE; Aler R, 2002, ARTIF INTELL, V141, P29, DOI 10.1016/S0004-3702(02)00246-1; AMBITE J, 2000, P AIPS 2000; AMBITE J, AAAI 97, P97; Borrajo D, 1997, ARTIF INTELL REV, V11, P371, DOI 10.1023/A:1006549800144; ESTLIN T, 1997, P IJCAI; FIKES RE, 1972, ARTIF INTELL, V3, P251, DOI 10.1016/0004-3702(72)90051-3; Fishburn PC, 1970, UTILITY THEORY DECIS; Fox M, 2003, J ARTIF INTELL RES, V20, P61; Gerevini A, 1996, J ARTIF INTELL RES, V5, P95; Ihrig LH, 1997, J ARTIF INTELL RES, V7, P161; IWAMOTO M, 1994, P AIPS, P281; KORF RE, 1985, ARTIF INTELL, V27, P97, DOI 10.1016/0004-3702(85)90084-0; MILLER TL, 1996, ADV PLANNING TECHNOL; MINTON S, 1989, ARTIF INTELL, V40, P63, DOI 10.1016/0004-3702(89)90047-7; PEDNAULT EPD, 1989, S REPR REAS, P324; PEREZ A, 1996, P INT C MACH LEARN; UPAL MA, 2003, P 3 INT C INT SYST D, P149; Upal M. A., 1999, Proceedings of the Twelfth International Florida AI Research Society Conference; UPAL MA, 1998, P AIPS 98 WORKSH KNO, P94; UPAL MA, 2001, P 14 INT FLAIRS C, P412; UPAL MA, 1999, THESIS U ALBERTA; VANCZA J, 2001, PRINC PRACT CONSTR P, P745; VELOSO M, 1994, LEARNING ANALOGICAL; WILLIAMSON M, 1996, TR960603 U WASH; Zimmerman T, 2003, AI MAG, V24, P73; ZIMMERMAN T, 2002, ICAPS WORKSH PLANNN; ZIMMERMAN T, 1996, P AAAI 96	28	0	0	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0824-7935		COMPUT INTELL-US	Comput. Intell.	NOV	2005	21	4					440	461		10.1111/j.1467-8640.2005.00281.x		22	Computer Science, Artificial Intelligence	Computer Science	969LN	WOS:000232235800006	
J	Jones, RM; Langley, P				Jones, RM; Langley, P			A constrained architecture for learning and problem solving	COMPUTATIONAL INTELLIGENCE			English	Article						human and machine learning; problem solving; cognitive architecture; memory limitations; qualitative cognitive model	ACQUISITION	This paper describes EUREKA, a problem-solving architecture that operates under strong constraints on its memory and processes. Most significantly, EUREKA does not assume free access to its entire long-term memory. That is, failures in problem solving may arise not only from missing knowledge, but from the (possibly temporary) inability to retrieve appropriate existing knowledge from memory. Additionally, the architecture does not include systematic backtracking to recover from fruitless search paths. These constraints significantly impact EUREKA's design. Humans are also subject to such constraints, but are able to overcome them to solve problems effectively. In EUREKA's design, we have attempted to minimize the number of additional architectural commitments, while staying faithful to the memory constraints. Even under such minimal commitments, EUREKA provides a qualitative account of the primary types of learning reported in the literature on human problem solving. Further commitments to the architecture would refine the details in the model, but the approach we have taken de-emphasizes highly detailed modeling to get at general root causes of the observed regularities. Making minimal additional commitments to EUREKA's design strengthens the case that many regularities in human learning and problem solving are entailments of the need to handle imperfect memory.	Soar Technol Inc, Waterville, ME 04901 USA; Stanford Univ, Ctr Study Language & Informat, Computat Learning Lab, Stanford, CA 94305 USA	Jones, RM (reprint author), Soar Technol Inc, Waterville, ME 04901 USA.						ALTMANN EM, 2002, COGNITIVE SCI, V25, P39; Anderson J. R., 1976, LANGUAGE MEMORY THOU; Anderson J. R., 1998, ATOMIC COMPONENTS TH; Anderson John R., 1983, ARCHITECTURE COGNITI; CARBONELL JG, 1986, MCAHINE LEARNING ART, V2; Charniak E., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; Duncker K., 1945, PSYCHOL MONOGRAPHS, V58; Ernst G. W., 1969, GPS CASE STUDY GEN P; ESTLIN TA, 1997, P 15 INT JOINT C ART, P1227; FIKES RE, 1972, ARTIF INTELL, V3, P251, DOI 10.1016/0004-3702(72)90051-3; GENTNER D, 1991, PROGRAM OF THE THIRTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P504; GRANGER RH, 1986, EXPERIENCE MEMORY RE; HAMMOND KJ, 1988, THESIS YALE U; HENDLER J, THESIS BROWN U; Hofstadter D., 1995, FLUID CONCEPTS CREAT; Holland J. H., 1986, INDUCTION PROCESSES; HOLYOAK KJ, 1987, MEM COGNITION, V15, P332, DOI 10.3758/BF03197035; Iba G. A., 1989, Machine Learning, V3, DOI 10.1007/BF00116836; JONES RM, 1991, PROGRAM OF THE THIRTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P358; JONES RM, 1993, FDN KNOWLEDGE ACQUIS; KAMBHAMPATI S, 1992, ARTIF INTELL, V55, P193, DOI 10.1016/0004-3702(92)90056-4; KOLODNER JL, 1985, P IJCAI 85 LOS ANGEL, P284; LAIRD JE, 1987, ARTIF INTELL, V33, P1, DOI 10.1016/0004-3702(87)90050-6; LANGLAY P, 1992, P 1 INT C AI PLANN S; LANGLEY P, 1991, PROGRAM OF THE THIRTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P364; LANGLEY P, 1985, COGNITIVE SCI, V9, P217, DOI 10.1207/s15516709cog0902_2; Luchins A., 1942, PSYCHOL MONOGR, V54, P248; MINTON S, 1990, ARTIF INTELL, V42, P363, DOI 10.1016/0004-3702(90)90059-9; MITCHELL T, 1983, MACHINE LEARNING ART; NEELY JH, 1990, BASIC PROCESSES READ; NEVES D, 1981, COGNITIVE SKILLS THE; Newell A., 1972, HUMAN PROBLEM SOLVIN; Newell A., 1990, UNIFIED THEORIES COG; NEWELL A, 1981, COGNITIVE SKILLS THE; NORVIG P, 1985, P 9 INT JOINT C ART, P624; Ohlsson S, 1996, PSYCHOL REV, V103, P241, DOI 10.1037//0033-295X.103.2.241; Ohlsson S., 1991, Journal of Experimental and Theoretical Artificial Intelligence, V3, DOI 10.1080/09528139108915280; Ohlsson S, 1997, PROCEEDINGS OF THE NINETEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P584; QUILLIAN MR, 1968, SEMANTIC INFORMATION; SHAVLIK J, 1988, THESIS U ILLINOIS; SHEPARD RN, 1967, J VERB LEARN VERB BE, V6, P156, DOI 10.1016/S0022-5371(67)80067-7; THAGARD P, 1990, ARTIF INTELL, V46, P259, DOI 10.1016/0004-3702(90)90018-U; Thorndike E.L, 1998, PSYCHOL REV MONOGR S, V2, P8; THORNDIKE EL, 1907, ELEMENTS PSYCHOL; UPAL MA, 2000, P 13 CAN C ART INT, P240; JONES RM, 1994, MACH LEARN, V16, P11, DOI 10.1023/A:1022626701243; VanLehn K., 1992, J LEARN SCI, V2, P1, DOI 10.1207/s15327809jls0201_1; VANLEHN K, 1989, FDN COGNITIVE SCI; VANLEHN K, 1993, MACHINE LEARNING MET; VELOSO MM, 1993, MACH LEARN, V10, P249, DOI 10.1023/A:1022686910523; Zimmerman T, 2003, AI MAG, V24, P73; ZITOWOLF R, 1993, PROCEEDINGS OF THE ELEVENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P73	52	8	8	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	0824-7935		COMPUT INTELL	Comput. Intell.	NOV	2005	21	4					480	502		10.1111/j.1467-8640.2005.00283.x		23	Computer Science, Artificial Intelligence	Computer Science	969LN	WOS:000232235800008	
J	Judson, DH; Bagchi, S; Quint, T				Judson, DH; Bagchi, S; Quint, T			On the inference of semi-coherent structures from data	COMPUTERS & OPERATIONS RESEARCH			English	Article						coherent structure; system reliability; simple game; monotonic Boolean function; Sperner set; clutter; record linkage; voting; machine learning	RELIABILITY	In this paper, we consider an unknown semi-coherent structure function. Our main focus is the inductive inference problem, that is, how to learn the structure function from data which partially defines the function. We develop a set of algorithms and simulate their success in learning an arbitrary 10-component function, and conclude that the algorithms are feasible. (c) 2004 Elsevier Ltd. All rights reserved.	US Census Bur, Adm Records Evaluat & Linkage Planning Res & Eval, Suitland, MD 20746 USA; Univ Nevada, Dept Math, Reno, NV 89557 USA	Judson, DH (reprint author), US Census Bur, Adm Records Evaluat & Linkage Planning Res & Eval, 4700 Silver Hill Rd, Suitland, MD 20746 USA.	dean.h.judson@census.gov					Barlow R.E., 1981, STAT THEORY RELIABIL; Barlow RE, 1998, ENG RELIABILITY; Birkhoff G., 1967, AM MATH SOC C PUBLIC, V25; BIRNBAUM ZW, 1961, TECHNOMETRICS, V3, P55, DOI 10.2307/1266477; BOROS E, 1996, 796 RUTCOR RRR; BOROS E, 1996, 2296 RUTCOR RRR; CLAROTTI CA, 1993, RELIABILITY DECISION; Colbourn C.J., 1987, COMBINATORICS NETWOR; Comtet L., 1974, ADV COMBINATORICS AR; Crama Y., 1988, Annals of Operations Research, V16, DOI 10.1007/BF02283750; EKIN O, 1998, 598 RUTCOR RRR; HANSEL G, 1966, CR ACAD SCI A MATH, V262, P1088; JUDSON DH, 2001, 2001 M FED COMM STAT; JUDSON DH, 1994, ADV GROUP PROCESSES, V11, P175; Kovalerchuk B, 2000, COMPUT BIOMED RES, V33, P296, DOI 10.1006/cbmr.2000.1546; Kovalerchuk B, 1996, INFORM SCIENCES, V94, P87, DOI 10.1016/0020-0255(96)00082-5; LU J, 1998, UNPUB KNOWLEDGE ACQU; PANTELIS P, 1987, COHERENT STRUCTURES; POLESSKII VP, 1997, PROBLEMY PEREDACHI I, V33, P50; Ramamurthy K., 1990, COHERENT STRUCTURES; RUSSELL A, 1995, GRAPHICAL BELIEF MOD; Shier D.R., 1991, NETWORK RELIABILITY; SKORNJAKOV LA, 1977, ELEMENTS LATTICE THE; Taylor A., 1995, MATH POLITICS STRATE; TORVIK VI, 2001, ENCY OPTIMIZATION, V2, P472; TORVIK VI, 2002, INFORMS J COMPUT, V14, P142; TRIANTAPHYLLOU E, MASSIVE COMPUTING SE; TRIANTAPHYLLOU E, 1997, INTERFACES COMPUTER	28	0	0	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0305-0548		COMPUT OPER RES	Comput. Oper. Res.	NOV	2005	32	11					2853	2874		10.1016/j.cor.2004.04.019		22	Computer Science, Interdisciplinary Applications; Engineering, Industrial; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	934UY	WOS:000229735500008	
J	Yu, HJ; Yang, J; Han, JW; Li, XL				Yu, HJ; Yang, J; Han, JW; Li, XL			Making SVMs scalable to large data sets using hierarchical cluster indexing	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article							SUPPORT VECTOR MACHINES	Support vector machines (SVMs) have been promising methods for classification and regression analysis due to their solid mathematical foundations, which include two desirable properties: margin maximization and nonlinear classification using kernels. However, despite these prominent properties, SVMs are usually not chosen for large-scale data mining problems because their training complexity is highly dependent on the data set size. Unlike traditional pattern recognition and machine learning, real-world data mining applications often involve huge numbers of data records. Thus it is too expensive to perform multiple scans on the entire data set, and it is also infeasible to put the data set in memory. This paper presents a method, Clustering-Based SVM (CB-SVM), that maximizes the SVM performance for very large data sets given a limited amount of resource, e.g., memory. CB-SVM applies a hierarchical micro-clustering algorithm that scans the entire data set only once to provide an SVM with high quality samples. These samples carry statistical summaries of the data and maximize the benefit of learning. Our analyses show that the training complexity of CB-SVM is quadratically dependent on the number of support vectors, which is usually much less than that of the entire data set. Our experiments on synthetic and real-world data sets show that CB-SVM is highly scalable for very large data sets and very accurate in terms of classification.	Univ Iowa, Dept Comp Sci, Iowa City, IA 52242 USA; Case Western Reserve Univ, Dept Comp Sci, Cleveland, OH 44106 USA; Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA	Yu, HJ (reprint author), Univ Iowa, Dept Comp Sci, Iowa City, IA 52242 USA.	hwanjoyu@cs.uiowa.edu; jiong@eecs.cwru.edu; hanj@cs.uiuc.edu; xli10@uiuc.edu					AGARWAL DK, 2002, P 8 ACM SIGKDD INT C, P173; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Cauwenberghs G., 2000, P ADV NEUR INF PROC, P409; Chang CC, 2001, NEURAL COMPUT, V13, P2119, DOI 10.1162/089976601750399335; Chang K. C., 2002, P ACM SIGKDD INT C K, P239; Collobert R, 2001, J MACH LEARN RES, V1, P143, DOI 10.1162/15324430152733142; Devroye L., 1996, PROBABILISTIC THEORY; DOMINGOS P, 2000, P ACM SIGKDD INT C K; Fung G., 2001, P KDD 2001 KNOWL DIS, P77, DOI 10.1145/502512.502527; GANTI V, 1999, P INT C DAT ENG ICDE; GREINER R, 1996, P 13 INT C MACH LEAR, P207; Guha S., 1998, P ACM SIGMOD INT C M, P73, DOI 10.1145/276304.276312; Joachims T., 1998, ADV KERNEL METHODS S; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637; KIVINEN J, 2001, P ADV NEUR INF PROC, P785; LEE YJ, 2001, SIAM INT C DAT MIN; MANGASARIAN OL, 2000, ACTIVE SUPPORT VECTO; Platt J., 1998, ADV KERNEL METHODS S; SCHEFFER T, 2002, J MACHINE LEARNING R; Schohn G., 2000, P 17 INT C MACH LEAR, P839; Scholkopf B., 2000, P ADV NEUR INF PROC, P582; SHIH L, 2002, P WORKSH TEXT LEARN; Smola A. J., 1998, NC2TR1998030 NEUROCO; Syed N, 1999, P WORKSH SUPP VECT M; Tong S., 2000, P 17 INT C MACH LEAR, P999; Vapnik VN, 1998, STAT LEARNING THEORY; Wang WL, 1997, ELEC SOC S, V97, P186; WATANABE O, 2001, INT C DAT MIN ICDM 0, P43; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324	30	11	15	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	NOV	2005	11	3					295	321		10.1007/s10618-005-0005-7		27	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	990GZ	WOS:000233732500005	
J	Nakayama, H; Yun, YB; Asada, T; Yoon, M				Nakayama, H; Yun, YB; Asada, T; Yoon, M			MOP/GP models for machine learning	EUROPEAN JOURNAL OF OPERATIONAL RESEARCH			English	Article						data mining; machine learning; linear classifier with maximal margin; support vector machine; goal programming	DISCRIMINANT-ANALYSIS; PROGRAMMING-MODELS	Techniques for machine learning have been extensively studied in recent years as effective tools in data mining. Although there have been several approaches to machine learning, we focus on the mathematical programming (in particular, multi-objective and goal programming; MOP/GP) approaches in this paper. Among them, Support Vector Machine (SVM) is gaining much popularity recently. In pattern classification problems with two class sets, its idea is to find a maximal margin separating hyperplane which gives the greatest separation between the classes in a high dimensional feature space. This task is performed by solving a quadratic programming problem in a traditional formulation, and can be reduced to solving a linear programming in another formulation. However, the idea of maximal margin separation is not quite new: in the 1960s the multi-surface method (MSM) was suggested by Mangasarian. In the 1980s, linear classifiers using goal programming were developed extensively. This paper presents an overview on how effectively MOP/GP techniques can be applied to machine learning such as SVM, and discusses their problems. (c) 2004 Elsevier B.V. All rights reserved.	Konan Univ, Dept Appl Math, Kobe, Hyogo 6588501, Japan; Kagawa Univ, Kagawa 7610396, Japan; Osaka Univ, Osaka 5650871, Japan; Yonsei Univ, Seoul 120749, South Korea	Nakayama, H (reprint author), Konan Univ, Dept Appl Math, 8-9-1 Okamoto, Kobe, Hyogo 6588501, Japan.	nakayama@konan-u.ac.jp; yun@eng.kagawa-u.ac.jp; asada@sa.eie.eng.osaka-u.ac.jp; myoon@base.yonsei.ac.kr					Asada T, 2003, ADV SOFT COMP, P93; Bennett K.P, 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; CAVALIER TM, 1989, COMPUT OPER RES, V16, P353, DOI 10.1016/0305-0548(89)90007-5; Cristianini N., 2000, INTRO SUPPORT VECTOR; ERENGUC SS, 1990, MANAGE DECIS ECON, V11, P215, DOI 10.1002/mde.4090110403; FREED N, 1981, EUR J OPER RES, V7, P44, DOI 10.1016/0377-2217(81)90048-5; GLOVER F, 1990, DECISION SCI, V21, P771, DOI 10.1111/j.1540-5915.1990.tb01249.x; Haykin S., 1994, NEURAL NETWORKS COMP; Mangasarian OL, 2000, ADV NEUR IN, P135; MANGASAR.OL, 1968, IEEE T INFORM THEORY, V14, P801, DOI 10.1109/TIT.1968.1054229; Marcotte P., 1992, ZOR, Methods and Models of Operations Research, V36, DOI 10.1007/BF01416243; NAKAYAMA H, 2000, P INT JOINT C NEUR N; NAKAYAMA H, 2001, P ICOTA2001, V3, P1171; Nakayama H, 1998, J GLOBAL OPTIM, V12, P111, DOI 10.1023/A:1008244409770; NAKAYAMA H, 2002, P ICONIP CD ROM; Platt J., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.213; SAWARAGI Y, 1994, THEORY MULTIOBJECTIV; Vapnik V. N, 1995, NATURE STAT LEARNING; Yamauchi K, 1999, IEEE T NEURAL NETWOR, V10, P1351, DOI 10.1109/72.809080; Yoon M, 2003, ADV SOFT COMP, P281; Yoon M, 2003, IEEE IJCNN, P2049	21	7	8	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0377-2217		EUR J OPER RES	Eur. J. Oper. Res.	NOV 1	2005	166	3					756	768		10.1016/j.ejor.2004.03.043		13	Management; Operations Research & Management Science	Business & Economics; Operations Research & Management Science	931PT	WOS:000229498000011	
J	Wang, HJ; Parrish, A; Smith, RK; Vrbsky, S				Wang, HJ; Parrish, A; Smith, RK; Vrbsky, S			Improved variable and value ranking techniques for mining categorical traffic accident data	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						variable and feature selection; variable ranking; value ranking; performance	ATTRIBUTE SELECTION; CLASSIFICATION; CANCER; MODEL	The ever increasing size of datasets used for data mining and machine learning applications has placed a renewed emphasis on algorithm performance and processing strategies. This paper addresses algorithms for ranking variables in a dataset, as well as for ranking values of a specific variable. We propose two new techniques, called Max Gain (MG) and Sum Max Gain Ratio (SMGR), which are well-correlated with existing techniques, yet are much more intuitive. MG and SMGR were developed for the public safety domain using categorical traffic accident data. Unlike the typical abstract statistical techniques for ranking variables and values, the proposed techniques can be motivated as useful intuitive metrics for non-statistician practitioners in a particular domain. Additionally, the proposed techniques are generally more efficient than the more traditional statistical approaches. (c) 2005 Elsevier Ltd. All rights reserved.	Univ Alabama, Dept Comp Sci, Tuscaloosa, AL 35487 USA	Wang, HJ (reprint author), Univ Alabama, Dept Comp Sci, Box 870390, Tuscaloosa, AL 35487 USA.	hwang@cs.ua.edu					Agrawal R., 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; ANDREWS HC, 1971, IEEE T COMPUT, VC 20, P1045, DOI 10.1109/T-C.1971.223400; BAIM PW, 1988, IEEE T PATTERN ANAL, V10, P888, DOI 10.1109/34.9110; Berry M.J.A., 1997, DATA MINING TECHNIQU; Bishop C.M., 1995, NEURAL NETWORKS PATT; CARUANA R, 1994, P 11 INT C MACH LEAR, V11, P28; Forman G., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753670; Foster DP, 2004, J AM STAT ASSOC, V99, P303, DOI 10.1198/016214504000000287; FUKUNAGA K, 1970, IEEE T COMPUT, VC 19, P311, DOI 10.1109/T-C.1970.222918; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; GRIMALDI M, 2003, 14 EUR C MACH LEARN; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hall M. A., 1999, Proceedings of the Twelfth International Florida AI Research Society Conference; Hall MA, 2003, IEEE T KNOWL DATA EN, V15, P1437, DOI 10.1109/TKDE.2003.1245283; HAWLEY W, 1996, FDN STAT; Howell D.C., 2001, STAT METHODS PSYCHOL; KAUTARDZIC M, 2001, DATA MINING CONCEPTS; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; KOHAVI R, 1994, P 11 INT C MACH LEAR, P121; Lehmann EL, 1959, TESTING STAT HYPOTHE; Mitchell T, 1997, MACHINE LEARNING; MLADEMNICD GROBELNIK M, 1999, P 16 INT C MACH LEAR, P258; Pappa G., 2002, P 4 INT C REC ADV SO; Parrish A, 2005, DECIS SUPPORT SYST, V38, P621, DOI 10.1016/j.dss.2003.09.005; Parrish AS, 2003, COMPUTER, V36, P22, DOI 10.1109/MC.2003.1204320; Pavlidis P, 2002, J COMPUT BIOL, V9, P401, DOI 10.1089/10665270252935539; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; RICHARDS WD, 2002, ZEN EMPIRICAL RES; Slonim DK, 2000, P 4 ANN INT C COMP M, P263, DOI 10.1145/332306.332564; Srikant R., 1995, P 21 VLDB C ZUR SWIT; Stockburger D. W., 1996, INTRO STAT CONCEPTS; Stoppiglia H., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753733; Viallefont V, 2001, STAT MED, V20, P3215, DOI 10.1002/sim.976.abs; WANG H, 2005, P 20 ACM S APPL COMP, P36; WANG H, 2003, P 41 ACM S REG C, P268; Weston J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753751; Yang Yiming, 1997, P 14 INT C MACH LEAR, P412; ZEMBOWICZ R, 1996, ADV KNOWLEDGE DISCOV, P328	40	1	1	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	NOV	2005	29	4					795	806		10.1016/j.eswa.2005.06.007		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	976UA	WOS:000232757700008	
J	Enke, D; Thawornwong, S				Enke, D; Thawornwong, S			The use of data mining and neural networks for forecasting stock market returns	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						stock return forecasting; data mining; information gain; neural networks; trading strategies	ECONOMIC-SIGNIFICANCE; TRADING STRATEGIES; PREDICTING RETURNS; INDEX; REGRESSION; BUSINESS; MODELS; LEVEL	It has been widely accepted by many studies that non-linearity exists in the financial markets and that neural networks can be effectively used to uncover this relationship. Unfortunately, many of these studies fail to consider alternative forecasting techniques, the relevance of input variables, or the performance of the models when using different trading strategies. This paper introduces an information gain technique used in machine learning for data mining to evaluate the predictive relationships of numerous financial and economic variables. Neural network models for level estimation and classification are then examined for their ability to provide an effective forecast of future values. A cross-validation technique is also employed to improve the generalization ability of several models. The results show that the trading strategies guided by the classification models generate higher risk-adjusted profits than the buy-and-hold strategy, as well as those guided by the level-estimation based forecasts of the neural network and linear regression models. (c) 2005 Elsevier Ltd. All rights reserved.	Univ Missouri, Lab Investment & Financial Engn, Smart Engn Syst Lab, Intelligent Syst Ctr, Rolla, MO 65409 USA	Enke, D (reprint author), Univ Missouri, Lab Investment & Financial Engn, Smart Engn Syst Lab, Intelligent Syst Ctr, Rolla, MO 65409 USA.	enke@umr.edu					Abhyankar A, 1997, J BUS ECON STAT, V15, P1, DOI 10.2307/1392068; Aggarwal R, 1997, J FUTURES MARKETS, V17, P781, DOI 10.1002/(SICI)1096-9934(199710)17:7<781::AID-FUT3>3.0.CO;2-J; BALVERS RJ, 1990, J FINANC, V45, P1109, DOI 10.2307/2328717; BREEN W, 1989, J FINANC, V44, P1177, DOI 10.2307/2328638; Burrell PR, 1997, NEURAL COMPUT APPL, V6, P193, DOI 10.1007/BF01501506; CAMPBELL JY, 1987, J FINANC ECON, V18, P373, DOI 10.1016/0304-405X(87)90045-6; Chenoweth T, 1996, NEUROCOMPUTING, V10, P275, DOI 10.1016/0925-2312(95)00109-3; Demuth H., 1997, NEURAL NETWORK TOOLB; Desai VS, 1998, DECISION SCI, V29, P405, DOI 10.1111/j.1540-5915.1998.tb01582.x; ELTON EJ, 1991, MODERN PORTFOLIO THE; FAMA EF, 1970, J FINANC, V25, P383, DOI 10.2307/2325486; FAMA EF, 1977, J FINANC ECON, V5, P115, DOI 10.1016/0304-405X(77)90014-9; FAMA EF, 1988, J FINANC ECON, V22, P3, DOI 10.1016/0304-405X(88)90020-7; FAMA EF, 1989, J FINANC ECON, V25, P23, DOI 10.1016/0304-405X(89)90095-0; FERSON WE, 1989, J FINANC, V44, P1191, DOI 10.2307/2328639; Gencay R, 1998, ECON LETT, V59, P249, DOI 10.1016/S0165-1765(98)00051-2; HAN J, 2000, DATA MIXING CONCEPTS; Hill T, 1996, MANAGE SCI, V42, P1082, DOI 10.1287/mnsc.42.7.1082; JENSEN MC, 1978, J FINANC ECON, V6, P95, DOI 10.1016/0304-405X(78)90025-9; KEIM DB, 1986, J FINANC ECON, V17, P357, DOI 10.1016/0304-405X(86)90070-X; LEITCH G, 1991, AM ECON REV, V81, P580; Leung MT, 2000, INT J FORECASTING, V16, P173, DOI 10.1016/S0169-2070(99)00048-5; Lo A., 1988, REV FINANC STUD, V1, P41, DOI DOI 10.1093/RFS/1.1.41; MABERLY ED, 1986, J FUTURES MARKETS, V6, P385; MALLIARIS M, 1993, APPL INTELL, V3, P193, DOI 10.1007/BF00871937; MILLS TC, 1991, J EC SURVEYS, V5, P215, DOI 10.1111/j.1467-6419.1991.tb00133.x; Motiwalla L, 2000, COMPUT OPER RES, V27, P1111, DOI 10.1016/S0305-0548(99)00148-3; Nelson M, 1999, J FORECASTING, V18, P359, DOI 10.1002/(SICI)1099-131X(199909)18:5<359::AID-FOR746>3.0.CO;2-P; Pantazopoulos KN, 1998, IEEE T SYST MAN CY B, V28, P520, DOI 10.1109/3477.704291; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PESARAN MH, 1992, J BUS ECON STAT, V10, P461, DOI 10.2307/1391822; PESARAN MH, 1995, J FINANC, V50, P1201, DOI 10.2307/2329349; PETERSON GE, 1995, IEEE T NEURAL NETWOR, V6, P949, DOI 10.1109/72.392257; Poddig T, 1996, NEUROCOMPUTING, V10, P251, DOI 10.1016/0925-2312(96)00049-5; Priestly M B, 1988, NONLINEAR NONSTATION; Qi M, 1999, J FORECASTING, V18, P151, DOI 10.1002/(SICI)1099-131X(199905)18:3<151::AID-FOR716>3.3.CO;2-M; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1, P318; SCHWERT GW, 1990, J FINANC, V45, P1237, DOI 10.2307/2328722; SPECHT DF, 1991, IEEE T NEURAL NETWOR, V2, P568, DOI 10.1109/72.97934; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Swales G. S.  Jr., 1992, Financial Analysts Journal, V48, DOI 10.2469/faj.v48.n5.78; Vellido A, 1999, EXPERT SYST APPL, V17, P51, DOI 10.1016/S0957-4174(99)00016-0; Wasserman P. D., 1993, ADV METHODS NEURAL C; Wood D, 1996, COMPUT OPER RES, V23, P611, DOI 10.1016/0305-0548(95)00065-8; Wu YR, 1997, J INT MONEY FINANC, V16, P609	46	61	61	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	NOV	2005	29	4					927	940		10.1016/j.eswa.2005.06.024		14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	976UA	WOS:000232757700018	
J	Piramuthu, S				Piramuthu, S			Machine learning for dynamic multi-product supply chain formation	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						supply chain configuration; machine learning; intelligent agents	DESIGN	Recent trend in eCommerce applications toward effectively reducing supply chain costs-including spatial, temporal, and monetary resources-has spurred interest among researchers as well as practitioners to efficiently utilize supply chains. One of the least studied of these views is adaptive or dynamic configuration of supply chains. This problem is relatively new since faster communications over the Internet or by any other means and the willingness to utilize it for effective management of supply chains did not exist a few decades ago. The proposed framework addresses the problem of supply chain configuration. We incorporate machine-learning techniques to develop a dynamically configurable supply chain framework, and evaluate its effectiveness with respect to comparable static supply chains. Specifically, we consider the case where several parts go into the production of a product. A single supplier or a combination of suppliers could supply these parts. The proposed framework automatically forms the supply chain dynamically as per the dictates of incoming orders and the constraints from suppliers upstream. (c) 2005 Elsevier Ltd. All rights reserved.	Univ Florida, Gainesville, FL 32611 USA	Piramuthu, S (reprint author), Univ Florida, 351 Stuzin Hall, Gainesville, FL 32611 USA.	selwyn@ufl.edu					AKKERMANS H, 2001, P 34 HAW INT SYST SC; COLLINS J, 2001, TESTBED MULIT AGENT; EMERSON D, AGENT BASED FRAMEWOR; Fan M, 2003, INFORM SYST RES, V14, P1, DOI 10.1287/isre.14.1.1.14763; Fox MS, 2000, INT J FLEX MANUF SYS, V12, P165, DOI 10.1023/A:1008195614074; GRASER TJ, 1997, P DETC 97 1997 ASME; Kimbrough SO, 2002, DECIS SUPPORT SYST, V33, P323, DOI 10.1016/S0167-9236(02)00019-2; KNIRSCH P, 1999, P 4 INT S LOG ISM 99, P213; Lin F, 2000, IEEE T SYST MAN CY A, V30, P380; Park SC, 2001, DECIS SUPPORT SYST, V31, P205, DOI 10.1016/S0167-9236(00)00132-9; PIRAMUTHU S, 2004, EUROPEAN J OPERATION; QUINLAN R, 2002, C5 0 RULEQUEST RES; Strader T., 1998, J ARTIFICIAL SOC SOC, V1; TAN GW, 2000, INFORMATION SYSTEMS, V2, P41, DOI 10.1023/A:1010093803431; VANDERPOL JM, 2000, 11 INT WORK SEM PROD, V3, P621; WALSH W, 2001, THESIS U MICHIGAN; WALSH WE, 2000, COMBINATORIAL AUCTIO; WALSH WE, 1999, IJCAI 99 WORKSH AG M; *SAP, 2002, AD SUPPL CHIAN WHIT	19	10	10	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	NOV	2005	29	4					985	990		10.1016/eswa.2005.07.004		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	976UA	WOS:000232757700024	
J	Piramuthu, S				Piramuthu, S			Knowledge-based web-enabled agents and intelligent tutoring systems	IEEE TRANSACTIONS ON EDUCATION			English	Article						agent-based; intelligent tutoring systems; knowledge-based system; machine learning; virtual learning environments	EDUCATION	Intelligent tutoring systems have been in existence for decades, and their characteristics can be beneficially applied in environments utilizing information and communication technology (ICT). The "intelligence" in these systems is seen through the way these systems adapt themselves to the characteristics of the students, such as speed of learning, specific areas in which the student excels as well as falls behind, and rate of learning as more knowledge is learned. In such intelligent learning environments, the agent or set of agents can be modeled to perform pedagogical tasks. This paper considers the necessary characteristics that constitute a good intelligent tutoring system. This paper introduces a framework incorporating an incremental machine-learning approach to capture 1) the dynamics of knowledge creation in the domain of interest and 2) the learned-knowledge content of the student over time. Some of the components of the proposed system are illustrated using examples from an introductory course on database design.	Univ Florida, Gainesville, FL 32611 USA	Piramuthu, S (reprint author), Univ Florida, Gainesville, FL 32611 USA.	selwyn@ufl.edu					BAYLOR AL, 2003, ED MEDIA HON HI; BAYLOR AL, 2002, J EDUC COMPUT RES, V26, P249; BRUSILOVSKY P, 1997, 8 WORLD C AIED SOC A; Conati C, 2004, P 9 INT C INT US INT, P6, DOI 10.1145/964442.964446; Dorca F. A., 2003, Proceedings 3rd IEEE International Conference on Advanced Technologies, DOI 10.1109/ICALT.2003.1215127; DOWLING C, 2000, P C ED US INF COMM T, P43; Frize M, 2000, CLIN INVEST MED, V23, P266; GARRO A, 2003, EXP, V3, P126; HOSPERS M, 2003, APPL INTELLIGENT AGE, P143; Jafari A., 2002, EDUCAUSE Q, V3, P28; JAQUES PA, 2002, P COMP SUPP COLL LEA, P546, DOI 10.3115/1658616.1658713; JOHNSON WL, 2003, P INTELLIGENT USER I, P251; Kolb D. A., 1984, EXPT LEARNING; Markels A., 2003, US NEWS         0317, P48; MARSH C, 1999, EDGE, V3, P3; MCCARTHY J, 1958, P TEDD C MECH THOUGH, P75; MORALES R, 2002, P IEEE ICALT KAZ STA, P502; NAKANISHI H, 2002, P SICE ANN C SICE 20, P2029; Pena C.-I., 2002, P IEEE INT C ADV LEA, P21; QUINLAN R, 2002, SEE5 0; SANTOS C, 2002, LECT NOT6ES COMPUTER, P91; Silveira RA, 2002, LECT NOTES COMPUT SC, V2363, P105; SILVEIRA RA, 2003, IADIS INT C E SOC LI; SWAN E, 1999, AUTONOMOUS AGENTS 99; Symonds W. C., 2001, BUS WEEK        0319, P67; TECUCI G, 1998, P AAAI 98 WORKSH SOF, P37; UENO M, 2002, P ICALT2002, P436; Virvou M., 2002, P 2002 IEEE INT C AD, P144; WEIZENBA.J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168; WHATLEY J, 2004, J INF TECHNOL, V3, P53; Wooldridge Michael, 1995, INTELLIGENT AGENTS	31	13	13	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9359		IEEE T EDUC	IEEE Trans. Educ.	NOV	2005	48	4					750	756		10.1109/TE.2005.854574		7	Education, Scientific Disciplines; Engineering, Electrical & Electronic	Education & Educational Research; Engineering	983XA	WOS:000233264500022	
J	Nishii, R; Eguchi, S				Nishii, R; Eguchi, S			Supervised image classification by contextual AdaBoost based on posteriors in neighborhoods	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article; Proceedings Paper	IEEE International Geoscience and Remote Sensing Symposium	SEP 20-24, 2004	Anchorage, AK	IEEE, IEEE Geosci & Remote Sensing Soc, Univ Alaska Fairbanks, Geophys Inst, Univ Missouri Columbia, NASA, NOAA, USN, Off Naval Res, Ball Aerosp &Technol Corp, Natl Polar Orbiting Operat Environm Satellite Syst, Japan Aerosp Explorat Agcy, Raytheon, US Geol Survey, ITT Ind, IEEE Ocean Engn Soc, Int Union Radio Sci		Bayes rule; image segmentation; machine learning; Markov random field (MRF); posterior probability	SUPPORT VECTOR MACHINES; FUSION	AdaBoost, a machine learning technique, is employed for supervised classification of land-cover categories of geostatistical data. We introduce contextual classifiers based on neighboring pixels. First, posterior probabilities are calculated at all pixels. Then, averages of the log posteriors are calculated in different neighborhoods and are then used as contextual classification functions. Weights for the classification functions can be determined by minimizing the empirical risk with multiclass. Finally, a convex combination of classification functions is obtained. The classification is performed by a noniterative maximization procedure. The proposed method is applied to artificial multispectral images and benchmark datasets. The performance of the proposed method is excellent and is similar to the Markov-random-field-based classifier, which requires an iterative maximization procedure.	Kyushu Univ, Fac Math, Fukuoka 8128581, Japan; Inst Stat Math, Tokyo 1068569, Japan	Nishii, R (reprint author), Kyushu Univ, Fac Math, Fukuoka 8128581, Japan.	nishii@math.kyushu-u.ac.jp; eguchi@ism.ac.jp	Eguchi, Shinto/A-9103-2012				Benediktsson JA, 1999, IEEE T GEOSCI REMOTE, V37, P1367, DOI 10.1109/36.763301; BESAG J, 1986, J ROY STAT SOC B MET, V48, P259; Eguchi S, 2002, BIOMETRIKA, V89, P1, DOI 10.1093/biomet/89.1.1; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; Hastie T, 1998, ANN STAT, V26, P451; Hastie T, 2001, ELEMENTS STAT LEARNI; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Kwok JTY, 2000, IEEE T NEURAL NETWOR, V11, P1162, DOI 10.1109/72.870047; MCLACHALN GJ, 2004, DISCRIMINANT ANAL ST; Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865; Nishii R, 2003, IEEE T GEOSCI REMOTE, V41, P2316, DOI 10.1109/TGRS.2003.816648; ROTH V, 2001, DTSCH ARBEITSGEMEINS, P246; Switzer P, 1980, MATH GEOL, V12, P367; Takenouchi T, 2004, NEURAL COMPUT, V16, P767, DOI 10.1162/089976604322860695; WAHBA G, 1999, ADV KERNEL METHODS S, P68	17	20	22	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0196-2892		IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	NOV	2005	43	11					2547	2554		10.1109/TGRS.2005.848693		8	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing	Geochemistry & Geophysics; Engineering; Remote Sensing	979KU	WOS:000232941700014	
J	Zhou, ZH; Li, M				Zhou, ZH; Li, M			Tri-training: Exploiting unlabeled data using three classifiers	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; machine learning; learning from unlabeled data; semi-supervised learning; co-training; tri-training; Web page classification	EM	In many practical data mining applications, such as Web page classification, unlabeled training examples are readily available, but labeled ones are fairly expensive to obtain. Therefore, semi-supervised learning algorithms such as co-training have attracted much attention. In this paper, a new co-training style semi-supervised learning algorithm, named tri-training, is proposed. This algorithm generates three classifiers from the original labeled example set. These classifiers are then refined using unlabeled examples in the tri-training process. In detail, in each round of tri-training, an unlabeled example is labeled for a classifier if the other two classifiers agree on the labeling, under certain conditions. Since tri-training neither requires the instance space to be described with sufficient and redundant views nor does it put any constraints on the supervised learning algorithm, its applicability is broader than that of previous co-training style algorithms. Experiments on UCl data sets and application to the Web page classification task indicate that tri-training can effectively exploit unlabeled data to enhance the learning performance.	Nanjing Univ, Lab Novel Software Technol, Nanjing 210093, Peoples R China	Zhou, ZH (reprint author), Nanjing Univ, Lab Novel Software Technol, Nanjing 210093, Peoples R China.	zhouzh@lamda.nju.edu.cn; lim@lamda.nju.edu.cn					Angluin D., 1988, Machine Learning, V2, DOI 10.1007/BF00116829; Bennett Kristin P., 2002, P 8 ACM SIGKDD INT C, P289; Blake C. L., 1998, UCI REPOSITORY MACHI; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; Blum A., 2001, P 18 INT C MACH LEAR, P19; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211; Collins M., 1999, P JOINT SIGDAT C EMP, P100; d'Alche-Buc F, 2002, ADV NEUR IN, V14, P553; Dasgupta S, 2002, ADV NEUR IN, V14, P375; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DIETTERICH T, 2000, LECT NOTES COMPUTER, V1867, P1; Efron B., 1993, INTRO BOOTSTRAP; Goldman S., 2000, P 17 INT C MACH LEAR, P327; HWA R, 2003, ICML 03 WORKSH CONT; Joachims T., 1999, P 16 INT C MACH LEAR, P200; Miller DJ, 1997, ADV NEUR IN, V9, P571; Muhlenbach F, 2004, J INTELL INF SYST, V22, P89, DOI 10.1023/A:1025832930864; Nigam K., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, DOI 10.1145/354756.354805; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Pierce D, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P1; QUINLAN JR, 1998, MINIBOOSTING DECISIO; Riloff E., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); Sarkar BK, 2001, B MATER SCI, V24, P95, DOI 10.1007/BF02710081; Seung H. S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130417; SHAHSHAHANI BM, 1994, IEEE T GEOSCI REMOTE, V32, P1087, DOI 10.1109/36.312897; Steedman M., 2003, P 11 C EUR CHAPT ASS, P331; Witten I. H., 2000, DATA MINING PRACTICA; Yarowsky D., 1995, P 33 ANN M ASS COMP, P189, DOI 10.3115/981658.981684	29	117	167	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	NOV	2005	17	11					1529	1541				13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	964OV	WOS:000231891300007	
J	Zhu, XQ; Wu, XD				Zhu, XQ; Wu, XD			Cost-constrained data acquisition for intelligent data preparation	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; intelligent data preparation; data acquisition; cost-sensitive; machine learning; instance ranking	LEARNING ALGORITHMS	Real-world data is noisy and can often suffer from corruptions or incomplete values that may impact the models created from the data. To build accurate predictive models, data acquisition is usually adopted to prepare the data and complete missing values. However, due to the significant cost of doing so and the inherent correlations in the data set, acquiring correct information for all instances is prohibitive and unnecessary. An interesting and important problem that arises here is to select what kinds of instances to complete so the model built from the processed data can receive the "maximum" performance improvement. This problem is complicated by the reality that the costs associated with the attributes are different, and fixing the missing values of some attributes is inherently more expensive than others. Therefore, the problem becomes that given a fixed budget, what kinds of instances should be selected for preparation, so that the learner built from the processed data set can maximize its performance? In this paper, we propose a solution for this problem, and the essential idea is to combine attribute costs and the relevance of each attribute to the target concept, so that the data acquisition can pay more attention to those attributes that are cheap in price but informative for classification. To this end, we will first introduce a unique Economical Factor (EF) that seamlessly integrates the cost and the importance ( in terms of classification) of each attribute. Then, we will propose a cost-constrained data acquisition model, where active learning, missing value prediction, and impact-sensitive instance ranking are combined for effective data acquisition. Experimental results and comparative studies from real-world data sets demonstrate the effectiveness of our method.	Univ Vermont, Dept Comp Sci, Burlington, VT 05401 USA	Zhu, XQ (reprint author), Univ Vermont, Dept Comp Sci, 33 Colchester Ave,Votey 377, Burlington, VT 05401 USA.	zqzhu@cs.uvm.edu; xwu@cs.uvm.edu					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Berry M. J. A., 1999, MASTERING DATA MININ; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1984, CLASSIFICATION REGRE; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211; Freitas AA, 2001, ARTIF INTELL REV, V16, P177, DOI 10.1023/A:1011996210207; Friedman N., 1997, P 14 INT C MACH LEAR, P125; GREINER R, 1997, ARTIFICIAL INTELLIGE, V97; Han J., 2001, DATA MINING CONCEPTS; Hoel P. G., 1962, INTRO MATH STAT; Jain AK, 1998, ALGORITHMS CLUSTERIN; Kononenko I., 1984, EXPT AUTOMATIC LEARN; Lewis D. D., 1994, P 17 ANN INT ACM SIG, P3; Lewis D, 1994, P 11 INT C MACH LEAR, P148; Little R. J., 1987, STAT ANAL MISSING DA; LIZOTTE DJ, 2003, P UNC ART INT; MACKAY DJC, 1992, NEURAL COMPUT, V4, P590, DOI 10.1162/neco.1992.4.4.590; NUNEZ M, 1991, MACH LEARN, V6, P231, DOI 10.1007/BF00114778; Padmanabhan B., 2002, P INT C DAT, P562; Provost F., 1999, P 5 ACM SIGKDD INT C, P23, DOI 10.1145/312129.312188; Pyle Dorian, 1999, DATA PREPARATION DAT; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J. R., 1989, P 6 INT WORKSH MACH, P164; Redman TC., 1996, DATA QUALITY INFORM; SCHUURMANS D, 1996, LEARNING CLASSIFY IN; SEUNG HS, 1992, P ACM WORKSH COMP LE; Shannon C.E., 1971, MATH THEORY COMMUNIC; Shapiro A.D., 1987, STRUCTURED INDUCTION; TAN M, 1993, MACHINE LEARNING, V13; Tseng SM, 2003, APPL ARTIF INTELL, V17, P535, DOI 10.1080/08839510390219318; Turney P. D., 1995, Journal of Artificial Intelligence Research, V2; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Winston P. H., 1975, PSYCHOL COMPUTER VIS; ZHU X, 2004, P 19 NATL C ART INT; ZHU X, 2004, P IEEE INT C TOOLS A	38	3	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	NOV	2005	17	11					1542	1556		10.1109/TKDE.2005.176		15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	964OV	WOS:000231891300008	
J	Kokkinos, I; Maragos, P				Kokkinos, I; Maragos, P			Nonlinear speech analysis using models for chaotic systems	IEEE TRANSACTIONS ON SPEECH AND AUDIO PROCESSING			English	Article						chaos; nonlinear systems; speech analysis	EM ALGORITHM; LYAPUNOV EXPONENTS; TIME-SERIES; NETWORK; RECONSTRUCTION; SIGNALS	In this paper, we use concepts and methods from chaotic systems to model and analyze nonlinear dynamics in speech signals. The modeling is done not on the scalar speech signal, but on its reconstructed multidimensional attractor by embedding the scalar signal into a phase space. We have analyzed and compared a variety of nonlinear models for approximating the dynamics of complex systems using a small record of their observed output. These models include approximations based on global or local polynomials as well as approximations inspired from machine learning such as radial basis function networks, fuzzy-logic systems and support vector machines. Our focus has been on facilitating the application of the methods of chaotic signal analysis even when only a short time series is available, like phonemes in speech utterances. This introduced an increased degree of difficulty that was dealt with by resorting to sophisticated function approximation models that are appropriate for short data sets. Using these models enabled us to compute for short time series of speech sounds useful features like Lyapunov exponents that are used to assist in the characterization of chaotic systems. Several experimental insights are reported on the possible applications of such nonlinear models and features.	Natl Tech Univ Athens, Sch Elect & Comp Engn, Athens, Greece	Kokkinos, I (reprint author), Natl Tech Univ Athens, Sch Elect & Comp Engn, Athens, Greece.	jkokkin@cs.ntua.gr; maragos@cs.ntua.gr					Abarbanel H.D.I., 1996, ANAL OBSERVED CHAOTI; Banbrook M, 1999, IEEE T SPEECH AUDI P, V7, P1, DOI 10.1109/89.736326; Banbrook M, 1997, IEEE T SIGNAL PROCES, V45, P1378, DOI 10.1109/78.575715; Barnard RW, 1999, J COMPUT APPL MATH, V105, P1, DOI 10.1016/S0377-0427(99)00010-2; BERNHARD HP, 1991, P 12 INT C PHON SCI; BIRGMEIER M, 1995, P IEEE INT C NEUR NE, P259; Casdagli M., 1992, NONLINEAR MODELING F; Cowper MR, 2002, SIGNAL PROCESS, V82, P775, DOI 10.1016/S0165-1684(02)00155-X; Darbyshire AG, 1996, PHYSICA D, V89, P287, DOI 10.1016/0167-2789(95)00246-4; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; ECKMANN JP, 1986, PHYS REV A, V34, P4971, DOI 10.1103/PhysRevA.34.4971; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Golub G. H., 1989, MATRIX COMPUTATIONS; GOUESBET G, 1994, PHYS REV E, V49, P4955, DOI 10.1103/PhysRevE.49.4955; Ishii S, 2001, NEURAL NETWORKS, V14, P1239, DOI 10.1016/S0893-6080(01)00094-6; JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; Kaiser J., 1983, VOCAL FOLD PHYSL BIO, P358; Kantz H., 1997, NONLINEAR TIME SERIE; KUBIN G, 1996, P INT C AC SPEECH SI, P267; Kumar A, 1996, J ACOUST SOC AM, V100, P615, DOI 10.1121/1.415886; Mann I, 2001, SIGNAL PROCESS, V81, P1743, DOI 10.1016/S0165-1684(01)00087-1; MANNLE M, 2000, P SAF IFAC BUD HUNG, P587; MARAGOS P, 2002, P INT C DSP SANT GRE; MARTINEZ F, 2002, P IEEE 14 INT C DIG, P317; MCGOWAN RS, 1988, J ACOUST SOC AM, V83, P696, DOI 10.1121/1.396165; MCLAUGHLIN S, 2002, P INT C DSP; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; Munkherjee S., 1997, P IEEE WORKSH NEUR N, P511; NARAYANAN SS, 1995, J ACOUST SOC AM, V97, P2511, DOI 10.1121/1.411971; Petry A, 2003, COMPUT SPEECH LANG, V17, P403, DOI 10.1016/S0885-2308(03)00029-9; PITSIKALIS V, 2003, P EUR GEN SWITZ SEP; QUATIERI TF, 1990, P ICASSP 1990 ALB NM, V3, P1551; RANK E, 2001, P 6 INT WORKSH ART N; RICHARD G, 1995, P EUR; Riedmiller M., 1993, P IEEE INT C NEUR NE, P586; Sato M, 2000, NEURAL COMPUT, V12, P407, DOI 10.1162/089976600300015853; STOKBRO L, 1990, NONLINEAR MODELING F; TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116; TEAGER HM, 1989, SPEECH PRODUCTION SP, V55; Thomas T. J., 1986, Computer Speech and Language, V1, DOI 10.1016/S0885-2308(86)80019-5; Tokuda I, 1996, INT J BIFURCAT CHAOS, V6, P149, DOI 10.1142/S0218127496001892; Vapnik V., 1996, ADV NEURAL INFORM PR, V8, P281	43	22	25	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1063-6676		IEEE T SPEECH AUDI P	IEEE Trans. Speech Audio Process.	NOV	2005	13	6					1098	1109		10.1109/TSA.2005.852982		12	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	976LI	WOS:000232734500002	
J	Rokach, L; Maimon, O				Rokach, L; Maimon, O			Top-down induction of decision trees classifiers - A survey	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART C-APPLICATIONS AND REVIEWS			English	Article						classification; decision trees; pruning methods; splitting criteria	CLASSIFICATION TREES; DESIGN; ALGORITHM; SELECTION; CONSTRUCTION; ACCURACY; DATASETS; RULES	Decision trees are considered to be one of the most popular approaches for representing classifiers. Researchers from various disciplines such as statistics, machine learning, pattern recognition, and data mining considered the issue of growing a decision tree from available data. This paper presents an updated survey of current methods for constructing decision tree classifiers in a top-down manner. The paper suggests a unified algorithmic framework for presenting these algorithms and describes the various splitting criteria and pruning methodologies.	Tel Aviv Univ, Dept Ind Engn, IL-69978 Ramat Aviv, Israel	Rokach, L (reprint author), Tel Aviv Univ, Dept Ind Engn, IL-69978 Ramat Aviv, Israel.	liorr@eng.tau.ac.il	Rokach, Lior/F-8247-2010				ALMUALLIM H, 1994, ARTIF INTELL, V69, P279, DOI 10.1016/0004-3702(94)90084-1; Almuallim H, 1996, ARTIF INTELL, V83, P347, DOI 10.1016/0004-3702(95)00060-7; Alsabti K., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; ATTNEAVE F, 1959, APPL INFORMATION THE; BAKER E, 1976, P 3 INT JOINT C PATT, P45; BENBASSAT M, 1978, IEEE T COMPUT, V27, P170; BENNETT P, 1994, OPTIMIZATION METH SO, V3, P29; BOHANEC M, 1994, MACH LEARN, V15, P223, DOI 10.1007/BF00993345; Breiman L, 1984, CLASSIFICATION REGRE; BRODLEY CE, 1995, MACH LEARN, V19, P45, DOI 10.1007/BF00994660; BUNTINE W, 1992, MACH LEARN, V8, P75, DOI 10.1007/BF00994006; CATLETT J, 1991, THESIS U SYDNEY SYDN; Chan P. K., 1997, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V8, DOI 10.1023/A:1008640732416; CRAWFORD SL, 1989, INT J MAN MACH STUD, V31, P197, DOI 10.1016/0020-7373(89)90027-8; DEMANTARAS RL, 1991, MACH LEARN, V6, P81, DOI 10.1023/A:1022694001379; Duda R.O, 1973, PATTERN CLASSIFICATI; Esposito F, 1997, IEEE T PATTERN ANAL, V19, P476, DOI 10.1109/34.589207; Fayyad U., 1992, P 10 NAT C ART INT S, P104; FIFIELD DJ, 1992, THESIS U CANBERRA AU; Freitas A. A, 1998, MINING VERY LARGE DA; FRIEDMAN JH, 1977, IEEE T COMPUT, V26, P404; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Gehrke J, 2000, DATA MIN KNOWL DISC, V4, P127, DOI 10.1023/A:1009839829793; Gehrke J., 1999, P ACM SIGMOD INT C M, P169, DOI 10.1145/304182.304197; GELFAND SB, 1991, IEEE T PATTERN ANAL, V13, P163, DOI 10.1109/34.67645; GILLO MW, 1972, BEHAV SCI, V17, P251; Grumbach S, 1996, J COMPUT SYST SCI, V52, P570, DOI 10.1006/jcss.1996.0042; Hancock T, 1996, INFORM COMPUT, V126, P114, DOI 10.1006/inco.1996.0040; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; Hyafil L., 1976, Information Processing Letters, V5, DOI 10.1016/0020-0190(76)90095-8; JOHN GH, 1996, LEARNING DATA ARTIFI, P375; Kass G. V., 1980, APPL STATIST, V29, P119, DOI DOI 10.2307/2986296; Kearns M., 1998, P 15 INT C MACH LEAR, P269; Kohavi R., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Kohavi R., 2002, HDB DATA MINING KNOW, P267; Langley P., 1994, P 1994 AAAI WORKSH C, P113; Last M, 2002, INT J PATTERN RECOGN, V16, P145, DOI 10.1142/S0218001402001599; LI XB, 1986, PATTERN RECOGN, V19, P229, DOI 10.1016/0031-3203(86)90013-0; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; LIN WC, 1983, PATTERN RECOGN, V16, P1, DOI 10.1016/0031-3203(83)90002-X; LOH SL, 1999, STAT COMPUT, V9, P309; LOH WY, 1988, J AM STAT ASSOC, V83, P715, DOI 10.2307/2289295; Loh WY, 1997, STAT SINICA, V7, P815; LUBINSKY D, 1993, P AL STAT, P435; Martin JK, 1997, MACH LEARN, V28, P257, DOI 10.1023/A:1007367629006; Mehta M., 1996, P 5 INT C EXT DAT TE, P18; Mehta RL, 1995, P 1 INT C KNOWL DISC, P216; Mingers J., 1989, Machine Learning, V4, DOI 10.1023/A:1022604100933; MORGAN MW, 1973, THAID SEQUENTIAL SEA; Muller W., 1994, Annals of Operations Research, V52, DOI 10.1007/BF02032305; Murthy S.K., 1994, J ARTIFICIAL INTELLI, V2, P1; Murthy SK, 1998, DATA MIN KNOWL DISC, V2, P345, DOI 10.1023/A:1009744630224; Naumov G. E., 1991, Soviet Physics - Doklady, V36; NIBLETT T, 1986, EXPERT SYSTEMS; PAGALLO G, 1990, MACH LEARN, V5, P71, DOI 10.1023/A:1022611825350; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J. R., 1989, P 6 INT WORKSH MACH, P164; QUINLAN JR, 1989, INFORM COMPUT, V80, P227; Quinlan J.R., 1988, MACH INTELL, V11, P305; Rastogi R, 2000, DATA MIN KNOWL DISC, V4, P315, DOI 10.1023/A:1009887311454; Rissanen J., 1989, STOCHASTIC COMPLEXIT; ROUNDS EM, 1980, PATTERN RECOGN, V12, P313, DOI 10.1016/0031-3203(80)90029-1; SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458; SCLIMMER JC, 1993, P INT C MACH LEARN S, P284; SETHI IK, 1994, PATTERN RECOGN, V27, P939, DOI 10.1016/0031-3203(94)90159-7; Shafer J, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P544; Shih YS, 2001, STAT PROBABIL LETT, V54, P341, DOI 10.1016/S0167-7152(00)00188-7; Sklansky J., 1981, PATTERN CLASSIFIERS; SONQUIST A, 1971, SEARCING STRUCTURE; TAYLOR PC, 1993, STAT COMPUT, V3, P147, DOI 10.1007/BF00141771; Utgoff P. E., 1989, Machine Learning, V4, DOI 10.1023/A:1022699900025; Utgoff P. E., 1989, Connection Science, V1, DOI 10.1080/09540098908915648; UTGOFF PE, 963 U MASS DEP COMP; UTGOFF PE, 1997, MACH LEARN, V29; WALLACE CS, 1993, MACH LEARN, V11, P7, DOI 10.1023/A:1022646101185; Zantema H., 2000, International Journal of Foundations of Computer Science, V11, DOI 10.1142/S0129054100000193	78	75	78	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1094-6977		IEEE T SYST MAN CY C	IEEE Trans. Syst. Man Cybern. Part C-Appl. Rev.	NOV	2005	35	4					476	487		10.1109/TSMCC.2004.843247		12	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications	Computer Science	978BH	WOS:000232846700003	
J	Pedrycz, W; Sosnowski, ZA				Pedrycz, W; Sosnowski, ZA			C-fuzzy decision trees	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART C-APPLICATIONS AND REVIEWS			English	Article						decision trees; depth-and-breadth tree expansion; experimental studies; fuzzy clustering; node variability; tree growing		This paper introduces a concept and design of decision trees based on information granules-multivariable entities characterized by high homogeneity (low variability). As such granules are developed via fuzzy clustering and play a pivotal role in the growth of the decision trees, they will be referred to as C-fuzzy decision trees. In contrast with "standard" decision trees in which one variable (feature) is considered at a time, this form of decision trees involves all variables that are considered at each node of the tree. Obviously, this gives rise to a completely new geometry of the partition of the feature space that is quite different from the guillotine cuts implemented by standard decision trees. The growth of the C.-decision tree is,realized by expanding a node of tree characterized by the highest variability of the information granule residing there. This paper shows how the tree is grown depending on some additional node expansion criteria such as cardinality (number of data) at a given node and a level of structural dependencies (structurability) of data existing there. A series of experiments is reported using both synthetic and machine learning data sets. The results are compared with those produced by the "standard" version of the decision tree (namely, C4.5).	Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2V4, Canada; Polish Acad Sci, Syst Res Inst, PL-01447 Warsaw, Poland; Bialystok Tech Univ, Dept Comp Sci, PL-15351 Bialystok, Poland	Pedrycz, W (reprint author), Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2V4, Canada.	pedrycz@ee.ualberta.ca; ezenon@ii.pb.bialystok.pl					Alexander W. P., 1996, J COMPUTATIONAL GRAP, V5, P156, DOI 10.2307/1390778; Bezdek J. C., 1981, PATTERN RECOGNITION; Breiman L, 1984, CLASSIFICATION REGRE; CANTUPAZ E, P GEN EV COMP C 2000, P1053; Dobra A., 2002, P 8 ACM SIGKDD INT C; ITTNER A, P INT FUZZ SYST ASS, P394; ITTNER A, 1996, P 13 INT C MACH LEAR; Jain A. K., 1999, ACM COMPUT SURV, V31; Merz C., 1996, UCI REPOSITORY MACHI; Murthy S.K., 1994, J ARTIFICIAL INTELLI, V2, P1; Pedrycz W, 2000, IEEE T SYST MAN CY A, V30, P151, DOI 10.1109/3468.833095; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLANN JR, 1993, C4 5 PROGRAMS MACHIN; SIEBERT JP, 1987, TIRM87017; Weber R., 1992, P 2 INT C FUZZ LOG N, P265; Yildiz OT, 2001, IEEE T NEURAL NETWOR, V12, P1539	16	21	21	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1094-6977		IEEE T SYST MAN CY C	IEEE Trans. Syst. Man Cybern. Part C-Appl. Rev.	NOV	2005	35	4					498	511		10.1109/TSMCC.2004.843205		14	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications	Computer Science	978BH	WOS:000232846700005	
J	Burgansky-Eliash, Z; Wollstein, G; Chu, TJ; Ramsey, JD; Glymour, C; Noecker, RJ; Ishikawa, H; Schuman, JS				Burgansky-Eliash, Z; Wollstein, G; Chu, TJ; Ramsey, JD; Glymour, C; Noecker, RJ; Ishikawa, H; Schuman, JS			Optical coherence tomography machine learning classifiers for glaucoma detection: A preliminary study	INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE			English	Article							NERVE-FIBER LAYER; SCANNING LASER POLARIMETRY; HEIDELBERG RETINA TOMOGRAPH; VISUAL-FIELD; THICKNESS MEASUREMENTS; REPRODUCIBILITY; EYES; DAMAGE; DISC; OPHTHALMOSCOPE	PURPOSE. Machine-learning classifiers are trained computerized systems with the ability to detect the relationship between multiple input parameters and a diagnosis. The present study investigated whether the use of machine-learning classifiers improves optical coherence tomography (OCT) glaucoma detection. METHODS. Forty-seven patients with glaucoma ( 47 eyes) and 42 healthy subjects ( 42 eyes) were included in this cross-sectional study. Of the glaucoma patients, 27 had early disease ( visual field mean deviation [MD] >= - 6 dB) and 20 had advanced glaucoma (MD < - 6 dB). Machine-learning classifiers were trained to discriminate between glaucomatous and healthy eyes using parameters derived from OCT output. The classifiers were trained with all 38 parameters as well as with only 8 parameters that correlated best with the visual field MD. Five classifiers were tested: linear discriminant analysis, support vector machine, recursive partitioning and regression tree, generalized linear model, and generalized additive model. For the last two classifiers, a backward feature selection was used to find the minimal number of parameters that resulted in the best and most simple prediction. The cross-validated receiver operating characteristic (ROC) curve and accuracies were calculated. RESULTS. The largest area under the ROC curve (AROC) for glaucoma detection was achieved with the support vector machine using eight parameters (0.981). The sensitivity at 80% and 95% specificity was 97.9% and 92.5%, respectively. This classifier also performed best when judged by cross-validated accuracy (0.966). The best classification between early glaucoma and advanced glaucoma was obtained with the generalized additive model using only three parameters ( AROC = 0.854). CONCLUSIONS. Automated machine classifiers of OCT data might be useful for enhancing the utility of this technology for detecting glaucomatous abnormality.	Univ Pittsburgh, Sch Med, Dept Ophthalmol,UPMC Eye Ctr, Eye & Ear Inst,Ophthalmol & Visual Sci Res Ctr, Pittsburgh, PA 15213 USA; Inst Human & Machine Cognit, Pensacola, FL USA; Carnegie Mellon Univ, Dept Philosophy, Pittsburgh, PA 15213 USA	Wollstein, G (reprint author), Univ Pittsburgh, Sch Med, Dept Ophthalmol,UPMC Eye Ctr, Eye & Ear Inst,Ophthalmol & Visual Sci Res Ctr, 203 Lothrop St,Eye & Ear Inst Suite 827, Pittsburgh, PA 15213 USA.	wollsteing@upmc.edu	Schuman, Joel/K-7304-2012				Blumenthal EZ, 2000, OPHTHALMOLOGY, V107, P2278, DOI 10.1016/S0161-6420(00)00341-9; Bowd C, 2002, INVEST OPHTH VIS SCI, V43, P3444; Bowd C, 2001, INVEST OPHTH VIS SCI, V42, P1993; Breiman L, 1984, CLASSIFICATION REGRE, P18; Budenz DL, 2005, OPHTHALMOLOGY, V112, P3, DOI 10.1016/j.ophtha.2004.06.039; Chauhan BC, 2001, ARCH OPHTHALMOL-CHIC, V119, P1492; Colen TP, 2004, J GLAUCOMA, V13, P28, DOI 10.1097/00061198-200402000-00006; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; Essock EA, 2003, ARCH OPHTHALMOL-CHIC, V121, P1238, DOI 10.1001/archopht.121.9.1238; Fisher RA, 1936, ANN EUGENIC, V7, P179; GOLUB GH, 1979, TECHNOMETRICS, V21, P215, DOI 10.1080/00401706.1979.10489751; Guedes V, 2003, OPHTHALMOLOGY, V110, P177, DOI 10.1016/S0161-6420(02)01564-6; Harwerth RS, 1999, INVEST OPHTH VIS SCI, V40, P2242; Hastie T., 1986, STAT SCI, V1, P297, DOI DOI 10.1214/SS/1177013604; Hastie T., 2001, ELEMENTS STAT LEARNI, P84; Hoh ST, 2000, AM J OPHTHALMOL, V129, P129, DOI 10.1016/S0002-9394(99)00294-9; Hougaard JL, 2004, ACTA OPHTHALMOL SCAN, V82, P410, DOI 10.1111/j.1600-0420.2004.00302.x; HUANG D, 1991, SCIENCE, V254, P1178, DOI 10.1126/science.1957169; Kanamori A, 2003, AM J OPHTHALMOL, V135, P513, DOI 10.1016/S0002-9394(02)02003-2; Lauande-Pimentel R, 2001, BRIT J OPHTHALMOL, V85, P586, DOI 10.1136/bjo.85.5.586; Mardin CY, 2003, J GLAUCOMA, V12, P340, DOI 10.1097/00061198-200308000-00008; Medeiros FA, 2004, ARCH OPHTHALMOL-CHIC, V122, P827, DOI 10.1001/archopht.122.6.827; Medeiros FA, 2003, BRIT J OPHTHALMOL, V87, P413, DOI 10.1136/bjo.87.4.413; Mikelberg F S, 1995, J Glaucoma, V4, P242; NELDER JA, 1972, J R STAT SOC SER A-G, V135, P370, DOI 10.2307/2344614; Nouri-Mahdavi K, 2004, AM J OPHTHALMOL, V137, P228, DOI 10.1016/j.ajo.2003.09.004; Paunescu LA, 2004, INVEST OPHTH VIS SCI, V45, P1716, DOI 10.1167/iovs.03-0514; QUIGLEY HA, 1982, ARCH OPHTHALMOL-CHIC, V100, P135; QUIGLEY HA, 1992, OPHTHALMOLOGY, V99, P19; SCHLKOPF R, 2001, LEARNING KERNELS SUP, P189; Schuman JS, 1996, OPHTHALMOLOGY, V103, P1889; SOMMER A, 1977, ARCH OPHTHALMOL-CHIC, V95, P2149; SOMMER A, 1991, ARCH OPHTHALMOL-CHIC, V109, P77; STONE M, 1974, J R STAT SOC B, V36, P111; Vapnik V, 1998, STAT LEARNING THEORY, P401; Villain MA, 2003, OPHTHALMIC SUR LA IM, V34, P33; WANG F, 1994, ARCH OPHTHALMOL-CHIC, V112, P796; Wollstein G, 2005, ARCH OPHTHALMOL-CHIC, V123, P464, DOI 10.1001/archopht.123.4.464; Wollstein G, 1998, OPHTHALMOLOGY, V105, P1557, DOI 10.1016/S0161-6420(98)98047-2; Wollstein G, 2004, AM J OPHTHALMOL, V138, P218, DOI 10.1016/j.ajo.2004.03.019; Zangwill LM, 2004, INVEST OPHTH VIS SCI, V45, P3144, DOI 10.1167/iovs.04-0202; Zangwill LM, 2001, ARCH OPHTHALMOL-CHIC, V119, P985	42	48	48	ASSOC RESEARCH VISION OPHTHALMOLOGY INC	ROCKVILLE	12300 TWINBROOK PARKWAY, ROCKVILLE, MD 20852-1606 USA	0146-0404		INVEST OPHTH VIS SCI	Invest. Ophthalmol. Vis. Sci.	NOV	2005	46	11					4147	4152		10.1167/iovs.05-0366		6	Ophthalmology	Ophthalmology	977MH	WOS:000232807400029	
J	Huma, Z; Rehman, MJU; Iftikhar, N				Huma, Z; Rehman, MJU; Iftikhar, N			An ontology-based framework for semi-automatic schema integration	JOURNAL OF COMPUTER SCIENCE AND TECHNOLOGY			English	Article						heterogeneous databases; database integration; database semantics; rule-based processing; machine learning		Currently, schema integration frameworks use approaches like rule-based, machine learning, etc. This paper presents an ontology-based wrapper-mediator framework that uses both the rule-based and machine learning strategies at the same time. The proposed framework uses global and local ontologies for resolving syntactic and semantic heterogeneity, and XML for interoperability. The concepts in the candidate schemas are merged on the basis of the similarity coefficient, which is calculated using the defined rules and the prior mappings stored in the case-base.	Muhammad Ali Jinnah Univ, Islamabad, Pakistan	Huma, Z (reprint author), Muhammad Ali Jinnah Univ, Islamabad, Pakistan.	zille@jinnah.edu.pk; jaffar@jinnah.edu.pk; nadeem@jinnah.edu.pk					Batini C., 1986, ACM COMPUT SURV, V18, P324; Chawathe S, 1994, P 10 M INF PROC SOC, P7; Do H.H., 2002, P 28 INT C VER LARG, P610; Doan A, 2003, VLDB J, V12, P303, DOI 10.1007/S00778-003-0104-2; Doan A., 2001, P 2001 ACM SIGMOD IN, P509, DOI 10.1145/375663.375731; DOAN A, 2000, P 3 INT WORKSH WEB D, P81; Genesereth MR, 1997, P ACM SIGMOD INT C M, P539, DOI 10.1145/253260.253400; GRUBR TR, 1993, PUD WORKSH FORM ONT; HAKIMPOUR F, 2001, C FORM ONT INF SYST, P297; Palopoli L., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288671; Lawrence R., 2001, P ACM S APPL COMP SA, P225, DOI 10.1145/372202.372327; Li WS, 2000, DATA KNOWL ENG, V33, P49, DOI 10.1016/S0169-023X(99)00044-0; Madhavan J., 2001, Proceedings of the 27th International Conference on Very Large Data Bases; Milo T., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; NENEVENTANO D, 2003, IEEE INT COMP IEEE C, V7, P42; Parent C., 1998, COMMUN ACM, V41, P166, DOI 10.1145/276404.276408; Rahm E, 2001, VLDB J, V10, P334, DOI 10.1007/s007780100057; RAM S, 1995, IEEE EXPERT, V10, P56, DOI 10.1109/64.393144; WACHE H, 2001, P IJCAI 01 WORKSH ON, P108; WACHE H, 1999, INT S DAT APPL NONTR, P109	20	2	4	SCIENCE PRESS	BEIJING	16 DONGHUANGCHENGGEN NORTH ST, BEIJING 100717, PEOPLES R CHINA	1000-9000		J COMPUT SCI TECHNOL	J. Comput. Sci. Technol.	NOV	2005	20	6					788	796		10.1007/s11390-005-0788-4		9	Computer Science, Hardware & Architecture; Computer Science, Software Engineering	Computer Science	984YM	WOS:000233343300006	
J	Staelin, C; Bergman, R; Fischer, M; Vans, M; Greig, D; Braverman, G; Harush, S; Shelef, E				Staelin, C; Bergman, R; Fischer, M; Vans, M; Greig, D; Braverman, G; Harush, S; Shelef, E			Dot gain table and developer voltage prediction for the HP indigo press	JOURNAL OF IMAGING SCIENCE AND TECHNOLOGY			English	Article								Color consistency is crucial for both photo and commercial printing applications. Dot gain tables are updated regularly, however between updates colors can shift due to process drift in the press, which is a common problem of both digital and offset presses. The goal of this investigation is to dynamically control the dot gain table and developer voltage to ensure more consistent color control while minimizing waste and calibration measurements. In this article we approach the elements of this calibration process as a series of machine-learning problems and investigate the efficacy of replacing physical calibration measurements with model-based predictions. The current state of the machine, expressed as sensor measurements, is used to model both the developer voltage, and the subsequent dot gain look up table. We also consider models that make a prediction based on a restricted set of calibration measurements, not necessarily including the full machine state vector. Our initial investigation using a preliminary dataset shows that machine learning methods are suitable for predicting the dot gain table.	Technion Israel Inst Technol, HP Labs Israel, Haifa, Israel; HP Labs Bristol, Bristol, Avon, England; Kiryat Weizmann, HP Indigo Div, Rehovot, Israel	Staelin, C (reprint author), Technion Israel Inst Technol, HP Labs Israel, Haifa, Israel.	Carl.staelin@hp.com					Bender R, 2000, BIOMETRICAL J, V42, P677, DOI 10.1002/1521-4036(200010)42:6<677::AID-BIMJ677>3.3.CO;2-F; BISHOP CM, 1995, NEURAL NEWORKS PATTE; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Ripley B. D, 1996, PATTERN RECOGNITION; STAELIN C, 2002, HPL2002355; Staelin C, 2002, HPL2002354; Tibshirani R., 2001, ELEMENTS STAT LEARNI	7	3	3	I S & T - SOC IMAGING SCIENCE TECHNOLOGY	SPRINGFIELD	7003 KILWORTH LANE, SPRINGFIELD, VA 22151 USA	1062-3701		J IMAGING SCI TECHN	J. Imaging Sci. Technol.	NOV-DEC	2005	49	6					620	628				9	Imaging Science & Photographic Technology	Imaging Science & Photographic Technology	013YN	WOS:000235446000009	
J	Schittkowski, K				Schittkowski, K.			Optimal parameter selection in support vector machines	JOURNAL OF INDUSTRIAL AND MANAGEMENT OPTIMIZATION			English	Article						machine learning; support vector machine; SVM; binary classification; Gaussian kernel; kernel parameter; sequential quadratic programming; SQP; nonlinear programming		The purpose of the paper is to apply a nonlinear programming algorithm for computing kernel and related parameters of a support vector machine (SVM) by a two-level approach. Available training data are split into two groups, one set for formulating a quadratic SVM with L-2-soft margin and another one for minimizing the generalization error, where the optimal SVM variables are inserted. Subsequently, the total generalization error is evaluated for a separate set of test data. Derivatives of functions by which the optimization problem is defined, are evaluated in an analytical way, where an existing Cholesky decomposition needed for solving the quadratic SVM, is exploited. The approach is implemented and tested on a couple of standard data sets with up to 4,800 patterns. The results show a significant reduction of the generalization error, an increase of the margin, and a reduction of the number of support vectors in all cases where the data sets are sufficiently large. By a second set of test runs, kernel parameters are assigned to individual features. Redundant attributes are identified and suitable relative weighting factors are computed.	Univ Bayreuth, Dept Comp Sci, D-95440 Bayreuth, Germany	Schittkowski, K (reprint author), Univ Bayreuth, Dept Comp Sci, POB 101251, D-95440 Bayreuth, Germany.	Klaus.Schittkowski@uni-bayreuth.de					ANGUITA D, 2005, SUPPORT VECTOR MACHI; AYAT NE, 2002, P INT WORKSH FRONT H; Bradley PS, 1999, INFORMS J COMPUT, V11, P217, DOI 10.1287/ijoc.11.3.217; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Cherkassky V, 2004, NEURAL NETWORKS, V17, P113, DOI 10.1016/S0893-6080(03)00169-2; CHRISTIANINI N, 2002, INTRO SUPPORT VECTOR; DAI YH, 2005, UNPUB SEQUENTIAL QUA; DEBNATH R, 2004, NEURAL INFORM PROCES, V5, P41; Fung GM, 2004, COMPUT OPTIM APPL, V28, P185, DOI 10.1023/B:COAP.0000026884.66338.df; GOLDFARB D, 1983, MATH PROGRAM, V27, P1, DOI 10.1007/BF02591962; Mangasaian OL, 2001, J MACH LEARN RES, V1, P161, DOI 10.1162/15324430152748218; Mangasarian OL, 2002, OPTIM METHOD SOFTW, V17, P913, DOI 10.1080/1055678021000028375; MANGASARIAN OL, 2003, SYSTEM MODELING OPTI, V20, P91; POWELL MJD, 1983, 1983NA19 U DAMTP U C; SCHITTKOWSKI K, 2004, NLPQLP20 FORTRAN IMP; Schittkowski K., 1985, ANN OPER RES, V5, P485; SCHITTKOWSKI K, 2003, QL FORTRAN CODE CONV; Shawe-Taylor J., 2004, KERNEL METHODS PATTE	18	22	24	AMER INST MATHEMATICAL SCIENCES	SPRINGFIELD	PO BOX 2604, SPRINGFIELD, MO 65801-2604 USA	1547-5816		J IND MANAG OPTIM	J. Ind. Manag. Optim.	NOV	2005	1	4					465	476				12	Engineering, Multidisciplinary; Operations Research & Management Science; Mathematics, Interdisciplinary Applications	Engineering; Operations Research & Management Science; Mathematics	088ZH	WOS:000240849100004	
J	Ando, RK; Zhang, T				Ando, RK; Zhang, T			A framework for learning predictive structures from multiple tasks and unlabeled data	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article								One of the most important issues in machine learning is whether one can improve the performance of a supervised learning algorithm by including unlabeled data. Methods that use both labeled and unlabeled data are generally referred to as semi-supervised learning. Although a number of such methods are proposed, at the current stage, we still don't have a complete understanding of their effectiveness. This paper investigates a closely related problem, which leads to a novel approach to semi-supervised learning. Specifically we consider learning predictive structures on hypothesis spaces (that is, what kind of classifiers have good predictive power) from multiple learning tasks. We present a general framework in which the structural learning problem can be formulated and analyzed theoretically, and relate it to learning with unlabeled data. Under this framework, algorithms for structural learning will be proposed, and computational issues will be investigated. Experiments will be given to demonstrate the effectiveness of the proposed algorithms in the semi-supervised learning setting.	IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA; Yahoo Res, New York, NY USA	Ando, RK (reprint author), IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.	rie1@us.ibm.com; tzhang@yahoo-inc.com					ANDO RK, 2005, ACL 05; Baxter J, 2000, J ARTIF INTELL RES, V12, P149; Belkin M, 2004, MACH LEARN, V56, P209, DOI 10.1023/B:MACH.0000033120.25363.1e; BENDAVID S, 2003, COLT 03; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; Breiman L, 1997, J ROY STAT SOC B MET, V59, P3, DOI 10.1111/1467-9868.00054; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chieu HL, 2003, P CONLL 2003, P160; EVEGNIOU T, 2004, P C KNOWL DISC DAT M; Florian R., 2003, P CONLL 2003, P168; Hastie T, 2001, ELEMENTS STAT LEARNI; Joachims T., 1999, P 16 INT C MACH LEAR, P200; Klein D, 2003, P CONLL 2003, P188; Ledoux M., 1991, PROBABILITY BANACH S; MCDIARMID C, 1989, LOND MATH S, V141, P148; MICCHELLI CA, 2005, NIPS 2004; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Pierce D., 2001, P 2001 C EMP METH NA; SZUMMER M, 2002, NIPS 2001; Vapnik VN, 1998, STAT LEARNING THEORY; Wellner J. A., 1996, WEAK CONVERGENCE EMP; Yarowsky D., 1995, P 33 ANN M ASS COMP, P189, DOI 10.3115/981658.981684; ZHANG T, 2000, INT JOINT C MACH LEA, P1191; ZHANG T, 2004, ICML 04, P919; ZHANG T, 2003, P CONLL 2003, P204; Zhou D., 2004, NIPS, P321; ZHU X, 2003, ICML 2003	27	134	139	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	NOV	2005	6						1817	1853				37	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026HT	WOS:000236330700003	
J	Heskes, T; Opper, M; Wiegerinck, W; Winther, O; Zoeter, O				Heskes, T; Opper, M; Wiegerinck, W; Winther, O; Zoeter, O			Approximate inference techniques with expectation constraints	JOURNAL OF STATISTICAL MECHANICS-THEORY AND EXPERIMENT			English	Article						analysis of algorithms; message-passing algorithms	BELIEF PROPAGATION; GRAPHICAL MODELS; ALGORITHM	This paper discusses inference problems in probabilistic graphical models that often occur in a machine learning setting. In particular it presents a unified view of several recently proposed approximation schemes. Expectation consistent approximations and expectation propagation are both shown to be related to Bethe free energies with weak consistency constraints, i.e. free energies where local approximations are only required to agree on certain statistics instead of full marginals.	Radboud Univ Nijmegen, SNN, Nijmegen, Netherlands; Univ Southampton, Sch Elect & Comp Sci, ISIS, Southampton SO9 5NH, Hants, England; Tech Univ Denmark, DK-2800 Lyngby, Denmark	Heskes, T (reprint author), Radboud Univ Nijmegen, SNN, Nijmegen, Netherlands.	T.Heskes@science.ru.nl; mo@ecs.soton.ac.uk; W.Wiegerinck@science.ru.nl; owi@imm.dtu.dk; O.Zoeter@science.ru.nl	Heskes, Tom/A-1443-2010; Wiegerinck, Wim/J-2510-2012				Heskes T., 2003, P 19 ANN C UNC ART I, P313; HESKES T, 2002, UAI 2002 P 18 ANN C; HESKES T, 2003, ADV NEURAL INFORMATI, V15, P359; Ikeda S, 2004, NEURAL COMPUT, V16, P1779, DOI 10.1162/0899766041336477; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; KAPPEN HJ, 1999, ADV NEURAL INFORMATI, V11, P280; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; LAURITZEN SL, 1992, J AM STAT ASSOC, V87, P1098, DOI 10.2307/2290647; Mezard M., 1987, LECT NOTES PHYS, V9; Minka T., 2001, THESIS MIT MEDIA LAB; Minka T., 2001, EP ENERGY FUNCTION M; MINKA T, 2004, ADV NEURAL INFORMATI, V16; Murphy KP, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P467; OPPER M, 2005, ADV NEURAL INFORMATI, V17, P1001; Opper M, 2001, PHYS REV E, V64, part. no., DOI 10.1103/PhysRevE.64.056131; Opper M, 2001, PHYS REV LETT, V86, P3695, DOI 10.1103/PhysRevLett.86.3695; PARISI G, 1995, J PHYS A-MATH GEN, V28, P5267, DOI 10.1088/0305-4470/28/18/016; Pearl J., 1988, PROBABILISTIC REASON; Saul LK, 1996, J ARTIF INTELL RES, V4, P61; Teh YW, 2002, ADV NEUR IN, V14, P953; THOULESS DJ, 1977, PHILOS MAG, V35, P593, DOI 10.1080/14786437708235992; Wainwright M. J., 2003, GRAPHICAL MODELS EXP; Weiss Y, 2001, NEURAL COMPUT, V13, P2173, DOI 10.1162/089976601750541769; Welling M., 2001, P C UNC ART INT, P554; WELLING M, 2005, P 21 ANN C UNC AI; WIEGERINCK W, 2000, P 16 ANN C UNC AI UA; Yedidia JS, 2001, ADV NEUR IN, V13, P689; Yuille AL, 2002, NEURAL COMPUT, V14, P1691, DOI 10.1162/08997660260028674; ZOETER O, 2005, CHANGEPOINT PROBLEMS	29	7	7	IOP PUBLISHING LTD	BRISTOL	TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND	1742-5468		J STAT MECH-THEORY E	J. Stat. Mech.-Theory Exp.	NOV	2005									P11015	10.1088/1742-5468/2005/11/P11015		24	Mechanics; Physics, Mathematical	Mechanics; Physics	994BM	WOS:000234004800004	
J	Malzahn, D; Opper, M				Malzahn, D; Opper, M			A statistical physics approach for the analysis of machine learning algorithms on real data	JOURNAL OF STATISTICAL MECHANICS-THEORY AND EXPERIMENT			English	Article						cavity and replica method; disordered systems (theory); analysis of algorithms	GAUSSIAN-PROCESSES; MODELS	We combine the replica approach of statistical physics with a variational technique to make it applicable for the analysis of machine learning algorithms on real data. The method is applied to Gaussian process models and their relative, the support vector machine. We discuss the quality of our theoretical results in comparison to experiments. As a key result, we apply our theory on real world benchmark data and show its potential for practical applications by deriving approximate expressions for data averaged performance measures which hold for general data distributions and allow us to optimize the performance of the learning algorithm.	Univ Karlsruhe, Inst Math Stochast, D-76218 Karlsruhe, Germany; Univ Gottingen, Dept Genet Epidemiol, D-37073 Gottingen, Germany; Univ Southampton, Sch Elect & Comp Sci, Southampton SO17 1BJ, Hants, England	Malzahn, D (reprint author), Univ Karlsruhe, Inst Math Stochast, D-76218 Karlsruhe, Germany.	dmalzah@gwdg.de; mo@ecs.soton.ac.uk					ANLAUF JK, 1990, PROPERTIES ADAPTIVE; Bartlett P., 2000, ADV LARGE MARGIN CLA; Bialek W, 1996, PHYS REV LETT, V77, P4693, DOI 10.1103/PhysRevLett.77.4693; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Cristianini N., 2000, SUPPORT VECTOR MACHI; Dietrich R, 1999, PHYS REV LETT, V82, P2975, DOI 10.1103/PhysRevLett.82.2975; Engel A., 2001, STAT MECH LEARNING; FEYNMAN RP, 1965, QUANTUM MECH PATH IN; GARDNER E, 1988, J PHYS A-MATH GEN, V21, P257, DOI 10.1088/0305-4470/21/1/030; Malzahn D, 2002, PHYS REV LETT, V89, DOI 10.1103/PhysRevLett.89.108302; MALZAHN D, 2002, ADV NEURAL INFORM PR, V14; Mezard M., 1987, LECT NOTES PHYS, V9; Mezard M, 2002, SCIENCE, V297, P812, DOI 10.1126/science.1073287; NEAL R, 1996, SPRINGER LECT NOTES, V118; Nishimori H., 2001, STAT PHYS SPIN GLASS; Opper M, 2001, PHYS REV LETT, V86, P3695, DOI 10.1103/PhysRevLett.86.3695; Opper M., 2001, ADV MEAN FIELD METHO; Opper M, 2001, PHYS REV LETT, V86, P4410, DOI 10.1103/PhysRevLett.86.4410; Opper M, 2000, NEURAL COMPUT, V12, P2655, DOI 10.1162/089976600300014881; Papoulis A, 1991, PROBABILITY RANDOM V; Parisi G, 1988, STAT FIELD THEORY; Ripley B. D, 1996, PATTERN RECOGNITION; Vapnik V. N, 1995, NATURE STAT LEARNING; Wahba G., 1990, SERIES APPL MATH, V59; Williams CKI, 1996, ADV NEUR IN, V8, P514; *U CA DEP INF COMP, 1998, UCI REP MACH LEARN D; *U TOR DEP COMP SC, 1995, DAT EV LEARN VAL EXP	27	0	0	IOP PUBLISHING LTD	BRISTOL	TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND	1742-5468		J STAT MECH-THEORY E	J. Stat. Mech.-Theory Exp.	NOV	2005									P11001	10.1088/1742-5468/2005/11/P11001		33	Mechanics; Physics, Mathematical	Mechanics; Physics	994BM	WOS:000234004800018	
J	Parmanto, B; Zeng, XM				Parmanto, B; Zeng, XM			Metric for Web accessibility evaluation	JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY			English	Article								A novel metric for quantitatively measuring the content accessibility of the Web for persons with disabilities is proposed. The metric is based on the Web Content Accessibility Guidelines (WCAG) checkpoints, an internationally accepted standard, that can be automatically tested using computer programs. Problems with current accessibility evaluation and the need for a good Web accessibility metric are discussed. The proposed metric is intended to overcome the deficiencies of the current measurements used in Web accessibility studies. The proposed metric meets the requirements as a measurement for scientific research. Examples of large-scale Web accessibility evaluations using the metric are given. The examples cover a comparison of Web accessibility of top medical journal Web sites and a longitudinal study of a Web site over time. The validity of the metric was tested using a large number of Web sites with different levels of compliance (rating categories) to the standard WCAG. The metric, which uses a predetermined simple weighting scheme, compares well to the more complex C5.0 machine learning algorithm in separating Web sites into different rating categories.	Univ Pittsburgh, Sch Hlth & Rehabil Sci, Dept Hlth Informat Management, Pittsburgh, PA 15260 USA	Parmanto, B (reprint author), Univ Pittsburgh, Sch Hlth & Rehabil Sci, Dept Hlth Informat Management, Pittsburgh, PA 15260 USA.	parmanto@pitt.edu; xizst9@pitt.edu					Bergman Michael K., 2001, J ELECT PUBLISHING, V7; BOHMAN P, 2003, VISUAL VS COGNITIVE; DEAUKANTAS P, 2002, THINK TANK REPORT FE; Dellavalle RP, 2003, SCIENCE, V302, P787, DOI 10.1126/science.1088234; Dhyani D, 2002, ACM COMPUT SURV, V34, P469, DOI 10.1145/592642.592645; EGAN JP, 1975, SIGNAL DETECTION THE; EMERY GR, 2002, SURVEY AGENCY WEB SI; Friedman C., 1997, EVALUATION METHODS M; HANLEY JA, 1982, RADIOLOGY, V143, P29; HANLEY JA, 1983, RADIOLOGY, V148, P839; Ivory M, 2002, IEEE INTERNET COMPUT, V6, P56, DOI 10.1109/4236.991444; Ivory MY, 2001, ACM COMPUT SURV, V33, P470, DOI 10.1145/503112.503114; JACKSONSANBORN E, 2002, LIB HI TECH, P308; MCMULLIN B, 2004, 1 MONDAY, V9; MURRAY B, 2000, SIZING INTERNET; Paciello Michael, 2000, WEB ACCESSIBILITY PE; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Stower G., 2002, STATE FEDERAL WEBSIT; SULLIVAN T, 2000, P CUU 2000 ACM C UN; Tufte E, 1997, VISUAL EXPLANATIONS; WEISS R, 2003, WASHINGTON POST 1124; WEST DM, 2001, WMRC GLOBAL E GOVT S; YAUKEY J, 2003, ARCH SITE PRESERVES; Zeng XM, 2004, J MED INTERNET RES, V6, DOI 10.2196/jmir.6.2.e19; *AUSTR HUM RIGHTS, 1997, DIS STAND GUID; *RINCE ASS BRAIL, 2003, SIT WEB FRANC QUOT I; *SPSS INC, 2003, CLEM 7 0; *U CHIC, 2004, ROCKIT COMP PROGR; *WAI, 2002, EV WEB SIT ACC; *WAI, 1999, WEB CONT ACC GUID 1; *WATCHF CORP, 2004, BOBB WATCHF CORP	31	15	16	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	1532-2882		J AM SOC INF SCI TEC	J. Am. Soc. Inf. Sci. Technol.	NOV	2005	56	13					1394	1404		10.1002/asi.20233		11	Computer Science, Information Systems; Information Science & Library Science	Computer Science; Information Science & Library Science	974US	WOS:000232617500003	
J	Amini, MR; Gallinari, P				Amini, MR; Gallinari, P			Semi-supervised learning with an imperfect supervisor	KNOWLEDGE AND INFORMATION SYSTEMS			English	Article						semi-supervised learnin; imperfect supervision; Classification Expectation Maximisation; Classification Maximum Likelihood	DISCRIMINANT-ANALYSIS; STOCHASTIC SUPERVISOR; INITIAL SAMPLES; EM ALGORITHM	Real-life applications may involve huge data sets with misclassified or partially classified training data. Semi-supervised learning and learning in the presence of label noise have recently emerged as new paradigms in the machine learning community to cope with this kind of problems. This paper describes a new discriminant algorithm for semi-supervised learning. This algorithm optimizes the classification maximum likelihood (CML) of a set of labeled-unlabeled data, using a discriminant extension of the Classification Expectation Maximization algorithm. We further propose to extend this algorithm by modeling imperfections in the estimated class labels for unlabeled data. The parameters of this label-error model are learned together with the semi-supervised classifier parameters. We demonstrate the effectiveness of the approach using extensive experiments on different datasets.	Univ Paris 06, Dept Comp Sci, F-75015 Paris, France	Amini, MR (reprint author), Univ Paris 06, Dept Comp Sci, 8 Rue Capitaine Scott, F-75015 Paris, France.	Massih-Reza.Amini@lip6.fr					AITCHISON J, 1976, BIOMETRIKA, V63, P1; Ambroise C, 2000, P 7 INT FED CLASS SO, P161; Amini M.-R., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval; Amini MR, 2003, P 18 INT JOINT C ART, P555; Anderson J.A., 1982, HDB STATISTICS, P169, DOI 10.1016/S0169-7161(82)02010-0; ANDERSON JA, 1979, BIOMETRIKA, V66, P17, DOI 10.1093/biomet/66.1.17; ATCHISON J., 1986, STAT ANAL COMPOSITIO; BANKO M, 1999, P PAC ASS COMP LING; Basu S, 2002, P 19 INT C MACH LEAR, P19; Belkin M, 2004, MACH LEARN, V56, P209, DOI 10.1023/B:MACH.0000033120.25363.1e; Bennett KP, 1999, ADV NEUR IN, V11, P368; Blake C. L., 1998, UCI REPOSITORY MACHI; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; Castelli V, 1996, IEEE T INFORM THEORY, V42, P2102, DOI 10.1109/18.556600; CELEUX G, 1992, COMPUT STAT DATA AN, V14, P315, DOI 10.1016/0167-9473(92)90042-E; Chapelle O., 2005, SEMISUPERVISED CLASS; CHHIKARA RS, 1984, J AM STAT ASSOC, V79, P899, DOI 10.2307/2288722; CHITTENI CB, 1982, PATTERN RECOGN, V12, P169; Collins M, 1999, P JOINT SIGDAT C EMP, P189; Cozman F. G., 2003, P 20 INT C MACH LEAR, P99; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DESA VR, 1994, ADV NEURAL INFORMATI, V6, P112; Jaakkola T, 2000, ADV NEUR IN, V12, P470; Joachims T., 1999, P 16 INT C MACH LEAR, P200; KRISHNAN T, 1987, PATTERN RECOGN, V20, P379, DOI 10.1016/0031-3203(87)90062-8; KRISHNAN T, 1988, PATTERN RECOGN, V21, P183, DOI 10.1016/0031-3203(88)90026-X; Kupiec J., 1995, P 18 ANN INT ACM SIG, P68, DOI 10.1145/215206.215333; LACHENBR.PA, 1974, TECHNOMETRICS, V16, P419, DOI 10.2307/1267672; Lawrence N. D., 2001, P 18 INT C MACH LEAR, P306; MCLACHLAN GJ, 1982, COMMUN STAT B-SIMUL, V11, P753, DOI 10.1080/03610918208812293; McLachlan G.J., 1992, DISCRIMINANT ANAL ST; MCLACHLA.GJ, 1972, TECHNOMETRICS, V14, P415, DOI 10.2307/1267432; Miller DJ, 1997, ADV NEUR IN, V9, P571; MLADENIC D, 1998, WORKING NOTES LEARNI; Murray GJ, 1978, APPL STAT, V27, P325, DOI 10.2307/2347169; Muslea I., 2002, P 19 INT C MACH LEAR, P435; NIGAM K, 2000, MACH LEARN, V39, P127; ONEILL TJ, 1978, J AM STAT ASSOC, V73, P821, DOI 10.2307/2286287; Ratsaby J., 1995, Proceedings of the Eighth Annual Conference on Computational Learning Theory, DOI 10.1145/225298.225348; Roth V, 2000, ADV NEUR IN, V12, P568; Seeger M., 2000, LEARNING LABELED UNL; SYMONS MJ, 1981, BIOMETRICS, V37, P35, DOI 10.2307/2530520; Szummer M, 2001, ADV NEUR IN, V13, P626; TIBSHIRANI R, 1996, NEURAL COMPUT, V8, P182; TITTERINGTON DM, 1989, PATTERN RECOGN, V22, P91, DOI 10.1016/0031-3203(89)90041-1; VITTAUT JN, 2002, P 13 EUR C MACH LEAR, P468; Zhu X., 2003, P 20 INT C MACH LEAR, P912, DOI DOI 10.1109/18.850663; *SUMMAC, 1998, TIPSTER TEXT SUMM EV	48	10	11	SPRINGER LONDON LTD	LONDON	236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND	0219-1377		KNOWL INF SYST	Knowl. Inf. Syst.	NOV	2005	8	4					385	413		10.1007/s10115-005-0219-4		29	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	989QH	WOS:000233688300001	
J	Dastani, M; Jacobs, N; Jonker, CM; Treur, J				Dastani, M; Jacobs, N; Jonker, CM; Treur, J			Modelling user preferences and mediating agents in electronic commerce	KNOWLEDGE-BASED SYSTEMS			English	Article						inductive logic programming; world wide web; agent-mediated electronic commerce	COMPOSITIONAL VERIFICATION; MULTIAGENT SYSTEMS	An important ingredient in agent-mediated electronic commerce is the presence of intelligent mediating agents that assist electronic commerce participants (e.g. individual users, other agents, organisations). These mediating agents are in principle autonomous agents that interact with their environments (e.g. other agents and web-servers) oil behalf of participants who have delegated tasks to them. For mediating agents a (preference) model of participants is indispensable. In this paper, a generic mediating agent architecture is introduced. Furthermore, we discuss our view of user preference modelling and its need in agent-mediated electronic commerce. We survey the state of the art in the field of preference modelling and suggest that the preferences of electronic commerce participants can be modelled by learning from their behaviour. In particular, we employ an existing machine learning method called inductive logic programming (ILP). We argue that this method can be used by mediating agents to detect regularities in the behaviour of the involved participants and induce hypotheses about their preferences automatically. Finally, we discuss some advantages and disadvantages of using inductive logic programming as a method for learning user preferences and compare this method with other approaches. (c) 2005 Elsevier B.V. All rights reserved.	Univ Utrecht, Intelligent Syst Grp, NL-3508 TB Utrecht, Netherlands; Free Univ Amsterdam, Dept Artificial Intelligence, NL-1081 HV Amsterdam, Netherlands; Katholieke Univ Leuven, Dept Comp Sci, B-3001 Heverlee, Belgium	Dastani, M (reprint author), Univ Utrecht, Intelligent Syst Grp, POB 80-089, NL-3508 TB Utrecht, Netherlands.	mehdi@cs.uu.nl; nico.Jacobs@cs.kuleuven.ac.be; jonker@cs.vu.nl; treur@cs.vu.nl					Basu C., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; BENN W, 1999, P 3 INT WORKSH COOP, V1652; Billsus D, 1998, P 15 INT C MACH LEAR, P46; Blockeel H., 1997, LECT NOTES ARTIF INT, V1297, P77; Blockeel H, 1999, DATA MIN KNOWL DISC, V3, P59, DOI 10.1023/A:1009867806624; Brazier F. M. T., 1997, LECT NOTES ARTIF INT, V1193, P141; Brazier FMT, 2004, APPL INTELL, V20, P95, DOI 10.1023/B:APIN.0000013334.33853.0c; Brazier FMT, 1997, INT J COOP INF SYST, V6, P67, DOI 10.1142/S0218843097000069; Chavez A., 1997, PAAM 97. Proceedings of the Second International Conference on the Practical Application of Intelligent Agents Multi-Agent Technology; Chavez A., 1996, PAAM 96. Proceedings of the First International Conference on the Practical Application of Intelligent Agents and Multi-Agent Technology; DERAEDT L, 1994, ARTIF INTELL, V70, P375, DOI 10.1016/0004-3702(94)90112-0; DeRaedt L, 1997, ARTIF INTELL, V95, P187, DOI 10.1016/S0004-3702(97)00041-6; ERIKSON J, 1997, THESIS UPPSALA U SWE; EUGENE C, 1998, PRINCIPLES PRACTICE; Guttman R. H., 1998, P WORKSH AG MED EL T; GUTTMAN RH, 1998, AGENT MEDIATED ELECT; Hill W., 1995, P ACM CHI 95 C HUM F, P194, DOI 10.1145/223904.223929; HOFMANN T, 1999, P 16 INT JOINT C ART; Jonker CM, 2002, INT J COOP INF SYST, V11, P51, DOI 10.1142/S0218843002000480; JONKER CM, 2002, INTELLIGENT AGENTS T, P149; Keeney R.L., 1976, DECISIONS MULTIPLE O; KUOKKA D, 1995, P 1 INT C MULT SYST, P239; Lang K., 1995, P 12 INT C MACH LEAR, P331; Langley P, 1997, P 21 GERM ANN C ART, P53; LANGLEY P, 1999, P 7 INT C US MOD; LIEBERMAN H, 1995, P 1J INT JOINT C ART; Martin D., 1997, PAAM 97. Proceedings of the Second International Conference on the Practical Application of Intelligent Agents Multi-Agent Technology; MUGGLETON S, 1994, P 4 INT WORKSH IND L, P139; OLIVEIRA E, 1999, P 1 INT WORKSH CENTR; Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943; Quinlan J. R., 1992, PROGRAMS MACHINE LEA; ROBERTS S, 1998, P 8 INT C IND LOG PR, V1446; Sandholm T, 1995, P 1 INT C MULT SYST, P328; SHARADANAND U, 1995, P CHI 95 C; Tsvetovatyy M. B., 1996, PAAM 96. Proceedings of the First International Conference on the Practical Application of Intelligent Agents and Multi-Agent Technology; Vincke P, 1992, MULTICRITERIA DECISI; WOOLDRIDGE M, 1995, LECT NOTES AI, V890	37	5	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051		KNOWL-BASED SYST	Knowledge-Based Syst.	NOV	2005	18	7					335	352		10.1016/j.knosys.2005.05.001		18	Computer Science, Artificial Intelligence	Computer Science	018DL	WOS:000235743900004	
J	Shimada, Y; Ando, S; Matsunaga, T; Misawa, A; Aizawa, T; Shirahata, T; Itoi, E				Shimada, Y; Ando, S; Matsunaga, T; Misawa, A; Aizawa, T; Shirahata, T; Itoi, E			Clinical application of acceleration sensor to detect the swing phase of stroke gait in functional electrical stimulation	TOHOKU JOURNAL OF EXPERIMENTAL MEDICINE			English	Article						functional electrical stimulation; hemiplegia; foot drop; sensor; Neural Network	COMPLETE PARAPLEGIA	Functional electrical stimulation (FES) can improve the gait of stroke patients by stimulating the peroneal nerve in the swing phase of the affected leg, causing dorsiflexion of the foot that allows the toes to clear the ground. A sensor can trigger the electrical stimulation automatically during the stroke gait. We previously used a heel sensor system, which detects the contact pressure of the heel, in FES to correct foot drop gait. However, the heel sensor has disadvantages in cosmetics and durability. Therefore, we have replaced the heel sensor with an acceleration sensor that can detect the swing phase based on the acceleration speed of the affected leg, using a machine learning technique (Neural Network). We have used a signal for heel contact in a gait using the heel sensor before training with the Neural Network. The accuracy of the Neural Network detector was compared with a swing phase detector based on the heel sensor. The Neural Network detector was able to detect similarly the swing phase in the heel sensor. The largest difference in timing of the swing phase was less than 60 milliseconds in normal subjects and 80 milliseconds in stroke patients. We were able to correct foot drop gait using FES with an acceleration sensor and Neural Network detector. The present results indicate that an acceleration sensor positioned on the thigh, which is cosmetically preferable to systems in which the sensor is farther from the entry point of the electrodes, is useful for correction of stroke gait using FES.	Akita Univ Hosp, Rehabil Div, Akita 0108543, Japan; Akita Univ, Sch Med, Dept Orthoped Surg, Akita 010, Japan	Shimada, Y (reprint author), Akita Univ Hosp, Rehabil Div, 1-1-1 Hondo, Akita 0108543, Japan.	yshimada@med.akita-u.ac.jp					ANDO S, 1999, P 4 ANN C IFESS SOC, P69; Dai R, 1996, IEEE Trans Rehabil Eng, V4, P63; GHOUSSAYNI SN, 2004, P 9 ANN C IFESS SOC, P398; Hansen M, 2004, IEEE T NEUR SYS REH, V12, P81, DOI 10.1109/TNSRE.2003.819890; JEGLIC A, 1971, FINAL REPORT PROJECT, P17; KONISHI N, 1996, J JPN MED SOC PARAPL, V9, P290; Kostov A, 1999, ARTIF ORGANS, V23, P443, DOI 10.1046/j.1525-1594.1999.06375.x; LIBERSON W T, 1961, Arch Phys Med Rehabil, V42, P101; Mansfield A, 2003, MED ENG PHYS, V25, P879, DOI 10.1016/S1350-4533(03)00116-4; Shimada Y, 1996, ARCH PHYS MED REHAB, V77, P1014, DOI 10.1016/S0003-9993(96)90061-1; Shimada Y, 1996, SPINAL CORD, V34, P615; Shimada Y, 2001, TOHOKU J EXP MED, V193, P221, DOI 10.1620/tjem.193.221; Shimada Y, 2003, TOHOKU J EXP MED, V201, P91, DOI 10.1620/tjem.201.91; VODOVNIK L, 1965, IEEE T BIO-MED ENG, VBM12, P169, DOI 10.1109/TBME.1965.4502374	14	9	9	TOHOKU UNIV MEDICAL PRESS	SENDAI	SCHOOL OF MEDICINE, SENDAI, 980-77, JAPAN	0040-8727		TOHOKU J EXP MED	Tohoku J. Exp. Med.	NOV	2005	207	3					197	202		10.1620/tjem.207.197		6	Medicine, General & Internal; Medicine, Research & Experimental	General & Internal Medicine; Research & Experimental Medicine	970DY	WOS:000232286600003	
J	Solorio, T; Fuentes, O; Terlevich, R; Terlevich, E				Solorio, T; Fuentes, O; Terlevich, R; Terlevich, E			An active instance-based machine learning method for stellar population studies	MONTHLY NOTICES OF THE ROYAL ASTRONOMICAL SOCIETY			English	Article						methods : data analysis; methods : numerical; methods : statistical; galaxies : fundamental parameters; galaxies : stellar content	DIGITAL SKY SURVEY; STAR-FORMATION HISTORY; GALAXIES; SPECTRA; LIBRARY	We have developed a method for the determination of fast and accurate stellar population parameters in order to apply it to high-resolution galaxy spectra. The method is based on an optimization technique that combines active learning with an instance-based machine learning algorithm. We tested the method with the retrieval of the star formation history and dust content in 'synthetic' galaxies with a wide range of signal-to-noise ratios (S/N). The 'synthetic' galaxies were constructed using two different grids of high-resolution theoretical population synthesis models. The results of our controlled experiment show that our method can estimate with good speed and accuracy the parameters of the stellar populations that make up the galaxy even for very low S/N input. For a spectrum with S/N = 5 the typical average deviation between the input and fitted spectrum is less than 10(-5). Additional improvements are achieved using prior knowledge.	INAOE, Puebla 72840, Mexico; Univ Cambridge, Inst Astron, Cambridge CB3 0HA, England	Solorio, T (reprint author), INAOE, Luis Enrique Erro 1 Tonantzintla, Puebla 72840, Mexico.	thamy@inaoep.mx; fuentes@inaoep.mx; rjt@inaoep.mx; eterlevi@inaoep.mx					Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; BAILERJONES CAL, 1996, THESIS U CAMBRIDGE; BERTELLI G, 1994, ASTRON ASTROPHYS SUP, V106, P275; Bertone E, 2004, ASTRON J, V128, P829, DOI 10.1086/422486; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; BRESSAN A, 1994, ASTROPHYS J SUPPL S, V94, P63, DOI 10.1086/192073; Cid Fernandes, 2005, MNRAS, V358, P363; Colless M, 2001, MON NOT R ASTRON SOC, V328, P1039, DOI 10.1046/j.1365-8711.2001.04902.x; Dietterich T., 2000, 1 INT WORKSH MULT CL, P1; FUENTES O, 2004, P MEX INT C ART INT, P242; Gonzalez Delgado R. M., 2005, Monthly Notices of the Royal Astronomical Society, V357, DOI 10.1111/j.1365-2966.2005.08692.x; GULATI RK, 1997, PASP, V109, P737; Heavens A, 2004, NATURE, V428, P625, DOI 10.1038/nature02474; Heavens AF, 2000, MON NOT R ASTRON SOC, V317, P965, DOI 10.1046/j.1365-8711.2000.03692.x; Kauffmann G, 2003, MON NOT R ASTRON SOC, V346, P1055, DOI 10.1111/j.1365-2966.2003.07154.x; Kurucz R. L., 1993, ATLAS 9; Martins LP, 2005, MON NOT R ASTRON SOC, V358, P49, DOI 10.1111/j.1365-2966.2005.08703.x; Mayya YD, 2004, ASTROPHYS J, V600, P188, DOI 10.1086/379707; Powell MJD, 1987, ALGORITHMS APPROXIMA, P143; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Rodriguez-Merino LH, 2005, ASTROPHYS J, V626, P411, DOI 10.1086/429858; Stoughton C, 2002, ASTRON J, V123, P485, DOI 10.1086/324741; Tremonti CA, 2004, ASTROPHYS J, V613, P898, DOI 10.1086/423264; York DG, 2000, ASTRON J, V120, P1579, DOI 10.1086/301513	24	3	3	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	0035-8711		MON NOT R ASTRON SOC	Mon. Not. Roy. Astron. Soc.	OCT 21	2005	363	2					543	554		10.1111/j.1365-2966.2005.09456.x		12	Astronomy & Astrophysics	Astronomy & Astrophysics	972GB	WOS:000232441200015	
J	Tan, AC; Naiman, DQ; Xu, L; Winslow, RL; Geman, D				Tan, AC; Naiman, DQ; Xu, L; Winslow, RL; Geman, D			Simple decision rules for classifying human cancers from gene expression profiles	BIOINFORMATICS			English	Article							PROSTATE-CANCER; MOLECULAR CLASSIFICATION; MICROARRAY DATA; LEUKEMIA; PREDICTION; TUMOR; SIGNATURES; ADENOCARCINOMA; CARCINOMAS; DIAGNOSIS	Motivation: Various studies have shown that cancer tissue samples can be successfully detected and classified by their gene expression patterns using machine learning approaches. One of the challenges in applying these techniques for classifying gene expression data is to extract accurate, readily interpretable rules providing biological insight as to how classification is performed. Current methods generate classifiers that are accurate but difficult to interpret. This is the trade-off between credibility and comprehensibility of the classifiers. Here, we introduce a new classifier in order to address these problems. It is referred to as k-TSP (k-Top Scoring Pairs) and is based on the concept of 'relative expression reversals'. This method generates simple and accurate decision rules that only involve a small number of gene-to-gene expression comparisons, thereby facilitating follow-up studies. Results: In this study, we have compared our approach to other machine learning techniques for class prediction in 19 binary and multi-class gene expression datasets involving human cancers. The k-TSP classifier performs as efficiently as Prediction Analysis of Microarray and support vector machine, and outperforms other learning methods (decision trees, k-nearest neighbour and naive Bayes). Our approach is easy to interpret as the classifier involves only a small number of informative genes. For these reasons, we consider the k-TSP method to be a useful tool for cancer classification from microarray gene expression data.	Whitaker Biomed Engn Inst, Ctr Cardiovasc Bioinformat & Modeling, Baltimore, MD 21218 USA; Johns Hopkins Univ, Dept Appl Math & Stat, Baltimore, MD 21218 USA	Tan, AC (reprint author), Whitaker Biomed Engn Inst, Ctr Cardiovasc Bioinformat & Modeling, 3400 N Charles St, Baltimore, MD 21218 USA.	actan@jhu.edu	Naiman, Daniel/A-3304-2010; Geman, Donald/A-3325-2010; Tan, Aik Choon/A-3135-2011	Naiman, Daniel/0000-0001-6504-9081; 			Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Amit Y, 1997, IEEE T PATTERN ANAL, V19, P1300, DOI 10.1109/34.632990; Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765; Beer DG, 2002, NAT MED, V8, P816, DOI 10.1038/nm733; BERNSTEIN ID, 1992, BLOOD, V79, P1811; Bhattacharjee A, 2001, P NATL ACAD SCI USA, V98, P13790, DOI 10.1073/pnas.191502998; Bo T., 2002, GENOME BIOL, V3, P11; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Chang MS, 2000, BIOCHEM BIOPH RES CO, V279, P732, DOI 10.1006/bbrc.2000.3992; Dettling M, 2003, BIOINFORMATICS, V19, P1061, DOI 10.1093/bioinformatics/btf867; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dudoit S., 2003, STAT ANAL GENE EXPRE, P93, DOI 10.1201/9780203011232.ch3; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Furnkranz J, 2002, J MACH LEARN RES, V2, P721, DOI 10.1162/153244302320884605; GEMAN D, 2004, STAT APPL GENETI MOL, V3; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gordon GJ, 2002, CANCER RES, V62, P4963; GRIFFIN JD, 1983, BLOOD, V62, P557; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Haste H, 1997, PSYCHOLOGIST, V10, P507; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Li T, 2004, BIOINFORMATICS, V20, P2429, DOI 10.1093/bioinformatics/bth267; Long PM, 2003, MACH LEARN, V52, P31, DOI 10.1023/A:1023937123600; Mutis T, 1999, BLOOD, V93, P2336; Pavlidis P, 2003, BIOINFORMATICS, V19, P295, DOI 10.1093/bioinformatics/19.2.295; Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Stuart RO, 2004, P NATL ACAD SCI USA, V101, P615, DOI 10.1073/pnas.2536479100; Su AI, 2001, CANCER RES, V61, P7388; Tan Aik Choon, 2003, Appl Bioinformatics, V2, pS75; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Tsutsumi S, 2003, CANCER RES, V63, P4882; Welsh JB, 2001, CANCER RES, V61, P5974; Witten I. H., 2000, DATA MINING PRACTICA; Yang XJ, 2004, NUCLEIC ACIDS RES, V32, P959, DOI 10.1093/nar/gkh252; YEOH AEJ, 2002, CANCER CELL, V1, P133	43	105	109	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	OCT 15	2005	21	20					3896	3904		10.1093/bioinformatics/bti631		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	974MQ	WOS:000232596300013	
J	Naderi, JR; Raman, B				Naderi, JR; Raman, B			Capturing impressions of pedestrian landscapes used for healing purposes with decision tree learning	LANDSCAPE AND URBAN PLANNING			English	Article; Proceedings Paper	Symposium on Research on the Built and Virtual Environments	2003	College Station, TX		Texas A&M Univ	pedestrian landscapes; user evaluation; artificial intelligence; multi-disciplinary design analysis; walking for health	PHYSICAL-ACTIVITY; FACILITIES; SERVICE; LEVEL	In 2002, Medicare health insurance recognized the relationship between pedestrian environments and public health by providing co-pay for health care delivered in residential land use. In this multi-disciplinary experiment, artificial intelligence (AI) and landscape architecture (LA) bridge their respective domains to measure and model the pedestrian reaction to walking environments in small town residential community in Central Texas. In the process, we gained a deeper understanding of the health motivation of walkers and their empirical relationship to various street environments that they used for health purposes. The analytical model we ultimately developed is a flexible tool that facilitates exploration of people's perceptions of the landscape, how the pedestrian landscapes are functioning in the opinion of its users, and how changes to the design of the walking domain may predictably affect physical activity levels with the associated health benefits. A pilot study involving fifty-four participants and six walking environments were used in the development of an analytical model that is significantly site-specific and grass roots oriented. Participant perceptions were measured querying each participant's rating of fifty discrete environmental variables taken. This data was then analyzed using the decision tree algorithm. Our primary objective was to capture the decision-making pattern walkers engage in when deciding to walk in a particular environment specifically for health purposes and to make this available to the designers of pedestrian environments in transportation corridors. The approach gave the designers new insight into the critical variables and the not so critical variables that affected people's decision to walk for health purposes. The results from the analysis defined measurable environmental variables that form the design for pedestrian activity in the six walking environments in the study area. A customized version of decision tree machine learning algorithm rules for designing good pedestrian landscapes for health purposes were extracted from the grass roots surveys. The data indicated that variables influencing the decision to walk for health purposes in the study area included weather, sound, water, light and edge of space. The analytical model derived from the discipline of artificial intelligence facilitated examining a subset of variables and manipulating of individual or group of these variables to better under-stand how the built environment affected decisions to walk for different purposes. This collaboration was our first phase in developing intelligent tools for designers that provided site-specific user-specific data to the planner or designer of pedestrian space. (c) 2004 Published by Elsevier B.V.	Texas A&M Univ, Coll Architecture, Dept Landscape Architecture & Urban Planning, College Stn, TX 77843 USA	Naderi, JR (reprint author), Texas A&M Univ, Coll Architecture, Dept Landscape Architecture & Urban Planning, 3137 TAMU, College Stn, TX 77843 USA.	jrnaderi@archone.tamu.edu					ANSHEL M, 1996, BEHAV MED, V21, P86; APPLEYARD D, 1965, NATURE ART MOTION; Berlyne D. E., 1971, AESTHETICS PSYCHOBIO; Cervero R., 1996, TRANSPORT POLICY, V3, P127, DOI 10.1016/0967-070X(96)00016-9; EMERY J, 2003, AM J HLTH PROMOT, P38; Fruin J.J., 1971, PEDESTRIAN PLANNING; Giles-Corti B, 2002, SOC SCI MED, V54, P1793, DOI 10.1016/S0277-9536(01)00150-2; Hall E. T., 1966, HIDDEN DIMENSION; Hancock Trevor, 1993, Journal of Public Health Policy, V14, P5, DOI 10.2307/3342823; Handy SL, 2002, AM J PREV MED, V23, P64, DOI 10.1016/S0749-3797(02)00475-0; Helbing D, 2001, ENVIRON PLANN B, V28, P361, DOI 10.1068/b2697; Hillier Bill, 1990, SOCIAL LOGIC SPACE; Isaacs R., 2000, J URBAN DESIGN, V5, P145, DOI 10.1080/713683961; Jacobs A. B., 1993, GREAT STREETS; Kaplan R., 1998, PEOPLE MIND; KHISTY CJ, 1994, 1438 TRB NAT RES COU, P45; KILLINGSWORTH R, 2003, AM J PUBLIC HLTH AM; Kramer AF, 1999, NATURE, V400, P418, DOI 10.1038/22682; LANDIS B, 2001, 010511 TRB; Lynch K., 1960, IMAGE CITY; McHarg I., 1969, DESIGN NATURE; Meinig D. W., 1979, INTERPRETATION ORDIN; Mitchell T, 1997, MACHINE LEARNING; MORI M, 1987, TRANSPORT RES A-POL, V21, P223, DOI 10.1016/0191-2607(87)90016-1; Moudon AV, 2003, AM J HEALTH PROMOT, V18, P21; NADERI JR, 2003, LANDSCAPING CLEAR ZO; NDBUSI F, 2002, ECOLOGICAL PLANNING; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; RAMAN B, IN PRESS COMPUTER BA; Sallis JF, 1997, RES Q EXERCISE SPORT, V68, P345; Sallis JF, 1996, HLTH BEHAV HLTH ED T, P403; Sallis JF, 1998, AM J PREV MED, V15, P379, DOI 10.1016/S0749-3797(98)00076-2; SENEVIRATNE PN, 1985, TRANSPORT Q, V39, P109; SHOEMAKER CA, 2002, P 6 INT PEOPL PLANT; Southworth M, 1997, J AM PLANN ASSOC, V63, P28, DOI 10.1080/01944369708975722; STEINITZ C, 2000, ECOLOGY DESIGN, P231; Ulrich R.S., 1999, HEALING GARDENS THER, P27; Untermann R., 1984, ACCOMODATING PEDESTR; Whyte WH, 1980, SOCIAL LIFE SMALL UR; *AASHTO, 1994, POL GEOM DES HIGHW S; *MAR DEP TRANSP, 2001, WHEN MAIN STREET STA; *SURG GEN OFF, 2001, SURG GEN CALL ACT NA; *US DEP TRANSP, 2001, DES SID TRAILS ACC 2	43	9	9	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-2046		LANDSCAPE URBAN PLAN	Landsc. Urban Plan.	OCT 15	2005	73	2-3					155	166		10.1016/j.landurbplan.2004.11.012		12	Ecology; Environmental Studies; Geography; Geography, Physical; Urban Studies	Environmental Sciences & Ecology; Geography; Physical Geography; Urban Studies	969PD	WOS:000232245600007	
J	Kachrimanis, K; Petrides, M; Malamataris, S				Kachrimanis, K; Petrides, M; Malamataris, S			Flow rate of some pharmaceutical diluents through die-orifices relevant to mini-tableting	INTERNATIONAL JOURNAL OF PHARMACEUTICS			English	Article						powder flow rate; mini-tableting; neural networks; lazy learning	NEURAL-NETWORKS; POWDER FLOW	The effects of cylindrical orifice length and diameter on the flow rate of three commonly used pharmaceutical direct compression diluents (lactose, dibasic calcium phosphate dihydrate and pregelatinised starch) were investigated, besides the powder particle characteristics (particle size, aspect ratio, roundness and convexity) and the packing properties (true, bulk and tapped density). Flow rate was determined for three different sieve fractions through a series of miniature tableting dies of different orifice diameter (0.4,0.3 and 0.2 cm) and thickness (1.5, 1.0 and 0.5 cm). It was found that flow rate decreased with the increase of the orifice length for the small diameter (0.2 cm) but for the large diameter (0.4 cm) was increased with the orifice length (die thickness). Flow rate changes with the orifice length are attributed to the flow regime (transitional arch formation) and possible alterations in the position of the free flowing zone caused by pressure gradients arising from the flow of self-entrained air, both above the entrance in the die orifice and across it. Modelling by the conventional Jones-Pilpel non-linear equation and by two machine learning algorithms (lazy learning, LL, and feed-forward back-propagation, FBP) was applied and predictive performance of the fitted models was compared. It was found that both FBP and LL algorithms have significantly higher predictive performance than the Jones-Pilpel non-linear equation, because they account both dimensions of the cylindrical die opening (diameter and length). The automatic relevance determination for FBP revealed that orifice length is the third most influential variable after the orifice diameter and particle size, followed by the bulk density, the difference between bulk and tapped densities and the particle convexity. (c) 2005 Elsevier B.V. All rights reserved.	Univ Thessaloniki, Sch Pharm, Dept Pharmaceut Technol, Thessaloniki 54124, Greece	Kachrimanis, K (reprint author), Univ Thessaloniki, Sch Pharm, Dept Pharmaceut Technol, Thessaloniki 54124, Greece.	kgk@pharm.auth.gr					Bertho Y, 2002, J FLUID MECH, V459, P317, DOI 10.1017/S0022112002008042; BEVERLOO WA, 1961, CHEM ENG SCI, V15, P260, DOI 10.1016/0009-2509(61)85030-6; Birattari M, 1999, ADV NEUR IN, V11, P375; BROWN RL, 1965, RHEOL ACTA, V4, P153, DOI 10.1007/BF01969251; CREWDSON BJ, 1977, POWDER TECHNOL, V16, P197, DOI 10.1016/0032-5910(77)87007-1; FLEMMING J, 1995, DRUG DEV IND PHARM, V21, P2239, DOI 10.3109/03639049509065904; JONES TM, 1966, J PHARM PHARMACOL, V18, P81; Kachrimanis K, 2003, INT J PHARM, V250, P13, DOI 10.1016/S0378-5173(02)00528-8; MURTONIEMI E, 1994, INT J PHARM, V108, P155, DOI 10.1016/0378-5173(94)90327-1; NABNEY I, 2001, ADV PATTER RECOGNITI; Neal R. M., 1996, BAYESIAN LEARNING NE; Rasmussen C.E., 1996, DELVE MANUAL; Sinka IC, 2004, INT J PHARM, V280, P27, DOI 10.1016/j.ijpharm.2004.04.021; Srivastava A, 2003, POWDER TECHNOL, V129, P72, DOI 10.1016/S0032-5910(02)00132-8; Wu CY, 2003, POWDER TECHNOL, V134, P24, DOI 10.1016/S0032-5910(03)00130-X	15	8	10	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0378-5173		INT J PHARM	Int. J. Pharm.	OCT 13	2005	303	1-2					72	80		10.1016/j.ijpharm.2005.07.003		9	Pharmacology & Pharmacy	Pharmacology & Pharmacy	974EP	WOS:000232574400008	
J	Catchpole, GS; Beckmann, M; Enot, DP; Mondhe, M; Zywicki, B; Taylor, J; Hardy, N; Smith, A; King, RD; Kell, DB; Fiehn, O; Draper, J				Catchpole, GS; Beckmann, M; Enot, DP; Mondhe, M; Zywicki, B; Taylor, J; Hardy, N; Smith, A; King, RD; Kell, DB; Fiehn, O; Draper, J			Hierarchical metabolomics demonstrates substantial compositional similarity between genetically modified and conventional potato crops	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article						genetically modified substantial equivalence; machine learning	FUNCTIONAL GENOMICS; MASS-SPECTROMETRY; CLASSIFICATION; IDENTIFICATION; METABOLITES; PHENOTYPES; NETWORKS; TUBER	There is current debate whether genetically modified (GM) plants might contain unexpected, potentially undesirable changes in overall metabolite composition. However, appropriate analytical technology and acceptable metrics of compositional similarity require development. We describe a comprehensive comparison of total metabolites in field-grown GM and conventional potato tubers using a hierarchical approach initiating with rapid metabolome "fingerprinting" to guide more detailed profiling of metabolites where significant differences are suspected. Central to this strategy are data analysis procedures able to generate validated, reproducible metrics of comparison from complex metabolome data. We show that, apart from targeted changes, these GM potatoes in this study appear substantially equivalent to traditional cultivars.	Univ Wales, Inst Biol Sci, Aberystwyth SY23 3DA, Dyfed, Wales; Univ Wales, Dept Comp Sci, Aberystwyth SY23 3DA, Dyfed, Wales; Max Planck Inst Mol Plant Physiol, D-14424 Golm, Germany	Draper, J (reprint author), Univ Wales, Inst Biol Sci, Aberystwyth SY23 3DA, Dyfed, Wales.	jhd@aber.ac.uk	Kell, Douglas/E-8318-2011				Aharoni Asaph, 2002, OMICS A Journal of Integrative Biology, V6, P217, DOI 10.1089/15362310260256882; Allen J, 2003, NAT BIOTECHNOL, V21, P692, DOI 10.1038/nbt823; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; EDELMAN J, 1968, NEW PHYTOL, V67, P517, DOI 10.1111/j.1469-8137.1968.tb05480.x; Fiehn O, 2000, NAT BIOTECHNOL, V18, P1157, DOI 10.1038/81137; Fiehn O, 2002, PLANT MOL BIOL, V48, P155, DOI 10.1023/A:1013713905833; GENTLEMAN R, 2004, R LANGUAGE ENV STAT; GIBSON GR, 1995, GASTROENTEROLOGY, V108, P968; Goodacre R, 1998, MICROBIOL-UK, V144, P1157; Hellwege EM, 2000, P NATL ACAD SCI USA, V97, P8699, DOI 10.1073/pnas.150043797; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; Kell DB, 2001, PLANT PHYSIOL, V126, P943, DOI 10.1104/pp.126.3.943; Kok EJ, 2003, TRENDS BIOTECHNOL, V21, P439, DOI 10.1016/Sj.tibtech.2003.08.003; Little R. J., 1987, STAT ANAL MISSING DA; Manley B.F.J., 1994, MULTIVARIATE STAT ME; McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996; POLSTIKOV VV, 2003, ANAL BIOCHEM, V301, P298; QUINLAN JR, 1993, C4 5 PROGRAMS MACHIE; Roessner U, 2000, PLANT J, V23, P131, DOI 10.1046/j.1365-313x.2000.00774.x; Roessner U, 2001, PLANT PHYSIOL, V127, P749, DOI 10.1104/pp.127.3.749; Sato S, 2004, PLANT J, V40, P151, DOI 10.1111/j.1365-313X.2004.02187.x; Scholz M, 2004, BIOINFORMATICS, V20, P2447, DOI 10.1093/bioinformatics/bth270; Sumner LW, 2003, PHYTOCHEMISTRY, V62, P817, DOI 10.1016/S0031-9422(02)00708-2; Taylor J, 2002, BIOINFORMATICS, V18, pS241; VANGELDER WMJ, 1991, POISONOUS PLANT CONT; Ward JL, 2003, PHYTOCHEMISTRY, V62, P949, DOI 10.1016/S0031-9422(02)00705-7; Weckwerth W, 2004, P NATL ACAD SCI USA, V101, P7809, DOI 10.1073/pnas.0303415101; WU B, 2004, BIOINFORMATICS, V19, P1636; ZAR JH, 1984, BIOSTAT ANAL, P201; ZYWICKI B, 2004, ANAL BIOCHEM, V336, P178; *ORG EC COOP DEV, 2001, REP OECD WORKSH NUTR	31	182	199	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424		P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	OCT 4	2005	102	40					14458	14462		10.1073/pnas.0503955102		5	Multidisciplinary Sciences	Science & Technology - Other Topics	971OD	WOS:000232392900060	
J	Cao, Y; Tien, WC; Faloutsos, P; Pighin, F				Cao, Y; Tien, WC; Faloutsos, P; Pighin, F			Expressive speech-driven facial animation	ACM TRANSACTIONS ON GRAPHICS			English	Article						algorithms; facial animation; lip synching; expression synthesis; independent component analysis		Speech-driven facial motion synthesis is a well explored research topic. However, little has been done to model expressive visual behavior during speech. We address this issue using a machine learning approach that relies on a database of speech-related high-fidelity facial motions. From this training set, we derive a generative model of expressive facial motion that incorporates emotion control, while maintaining accurate lip-synching. The emotional content of the input speech can be manually specified by the user or automatically extracted from the audio signal using a Support Vector Machine classifier.	Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA; Univ So Calif, ICT, Los Angeles, CA 90089 USA; Univ So Calif, Inst Creat Technol, Marina Del Rey, CA 90292 USA	Cao, Y (reprint author), Univ Calif Los Angeles, Dept Comp Sci, 4732 Boelter Hall, Los Angeles, CA 90095 USA.	abingcao@cs.ucla.edu; tien@ict.usc.edu; pfal@cs.ucla.edu; pighin@ict.usc.edu					ALBRECHT I, 2002, P WSCG 2002, P9; Brand M, 1999, P SIGGRAPH 99, P21, DOI 10.1145/311535.311537; Bregler C, 1997, SIGGRAPH 97 C P, P353; BROOK N, 1994, INT S SPEECH IM PROC; Buhmann M., 2003, RADIAL BASIS FUNCTIO; Burges C.J.C., 1998, DATA MIN KNOWL DISC, V2, P955; CASSELL J, 1994, P ACM SIGGRAPH 1994; Chang CC, 2001, NEURAL COMPUT, V13, P2119, DOI 10.1162/089976601750399335; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; CHUANG E, 2002, P PAC GRAPH; COHEN N, 1993, MODELS TECHNIQUES CO, P139; Ekman P., 1978, MANUAL FACIAL ACTION; Ezzat T., 2002, P ACM SIGGRAPH 2002, P388, DOI 10.1145/566570.566594; FALOUTSOS P, 2003, P ACM SIGGRAPH EUR S, P225; Flannery B.P., NUMERICAL RECIPES C; Hyvarinen A., 2001, INDEPENDENT COMPONEN; Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; Joshi P., 2003, P 2003 ACM SIGGRAPH, P187; Kalberer GA, 2002, VISION MODELING, AND VISUALIZATION 2002, PROCEEDINGS, P463; Kovar L., 2002, P 29 ANN C COMP GRAP, P473, DOI 10.1145/566570.566605; KSHIRSAGAR S, 2003, P EUR 2003; Lee J., 2002, P ACM SIGGRAPH 2002, P491, DOI 10.1145/566570.566607; LEE SP, 2003, P ACM SIGGRAPH 2003, P637; Lee Y., 1995, SIGGRAPH 95 C P, P55; Lewis J., 1991, Journal of Visualization and Computer Animation, V2, DOI 10.1002/vis.4340020404; Li Y., 2002, P ACM SIGGRAPH, P465, DOI 10.1145/566570.566604; Lien J. J., 1998, Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No.98EX107), DOI 10.1109/AFGR.1998.670980; MASUKO T, 1998, P INT C AC SPEECH SI; NOH J, 2000, ACM S VIRT REAL SOFT, P166; PARKE FI, 1975, COMPUTERS GRAPHICS J, V1, P1; Pelachaud C., 1991, THESIS U PENNSYLVANI; Pighin F., 1998, SIGGRAPH 98 C P, P75; Pyun H., 2003, P 2003 ACM SIGGRAPH, P167; SAISAN P, 2004, EUR C COMP VIS, P456; Sankoff D., 1983, TIME WARPS STRING ED; Sartaj Sahni, DATA STRUCTURES ALGO; Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349; VASILESCU MAO, 2003, C COMP VIS PATT REC; WATERS K, 1987, COMPUT GRAPH, V21, P17; WU TF, 2003, P NEUR INF PROC SYST; *CARN MELL U SPEEC, FEST SOFTW; *HELS U TECHN LAB, FASTICA; *HOUS MOV INC, DIV SOFTW; *INT COMP SCI I, RAST SOFTW	44	20	22	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	0730-0301		ACM T GRAPHIC	ACM Trans. Graph.	OCT	2005	24	4					1283	1302		10.1145/1095878.1095881		20	Computer Science, Software Engineering	Computer Science	983PN	WOS:000233244700003	
J	Ren, L; Shakhnarovich, G; Hodgins, JK; Pfister, H; Viola, P				Ren, L; Shakhnarovich, G; Hodgins, JK; Pfister, H; Viola, P			Learning silhouette features for control of human motion	ACM TRANSACTIONS ON GRAPHICS			English	Article						algorithm; performance animation; motion control; motion capture; animation interface; machine-learning; computer vision	HUMAN MOVEMENT; RECOGNITION; TRACKING; CASCADE	We present a vision-based performance interface for controlling animated human characters. The system interactively combines information about the user's motion contained in silhouettes from three viewpoints with domain knowledge contained in a motion capture database to produce an animation of high quality. Such an interactive system might be useful for authoring, for teleconferencing, or as a control interface for a character in a game. In our implementation, the user performs in front of three video cameras; the resulting silhouettes are used to estimate his orientation and body configuration based on a set of discriminative local features. Those features are selected by a machine-learning algorithm during a preprocessing step. Sequences of motions that approximate the user's actions are extracted from the motion database and scaled in time to match the speed of the user's motion. We use swing dancing, a complex human motion, to demonstrate the effectiveness of our approach. We compare our results to those obtained with a set of global features, Hu moments, and ground truth measurements from a motion capture system.	Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA; MIT, CSAIL, Cambridge, MA 02139 USA; Mitsubishi Elect Res Lab, Cambridge, MA 02139 USA; Microsoft Corp, Redmond, WA 98052 USA	Ren, L (reprint author), Carnegie Mellon Univ, Dept Comp Sci, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	liuren@cs.cmu.edu; Gregory@csail.mit.edu; jkh@cs.cmu.edu; pfister@merl.com; viola@microsoft.com					Arikan O, 2003, ACM T GRAPHIC, V22, P402, DOI 10.1145/882262.882284; Arikan O, 2002, ACM T GRAPHIC, V21, P483; BRAND M, 2000, P SIGGRAPH 2000, P183, DOI 10.1145/344779.344865; Brand M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, DOI 10.1109/ICCV.1999.790422; Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581; Carranza J, 2003, ACM T GRAPHIC, V22, P569, DOI 10.1145/882262.882309; Chai JX, 2005, ACM T GRAPHIC, V24, P686, DOI 10.1145/1073204.1073248; CHEUNG KM, 2000, P IEEE C COMP VIS PA, P714; COLLINS M, 2000, P 13 ANN C COMP LEAR, P158; Crow F.C., 1984, P 11 ANN C COMP GRAP, P207, DOI 10.1145/800031.808600; Davis JW, 1997, PROC CVPR IEEE, P928, DOI 10.1109/CVPR.1997.609439; Delamarre Q., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, DOI 10.1109/ICCV.1999.790292; Deutscher J., 2000, P IEEE C COMP VIS PA, P126, DOI 10.1109/CVPR.2000.854758; Duda R., 2000, PATTERN CLASSIFICATI; Efros A. A., 2003, Proceedings Ninth IEEE International Conference on Computer Vision; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Granieri J. P., 1995, ACM Transactions on Modeling and Computer Simulation, V5, DOI 10.1145/217853.217856; HU M, 1962, IRE T INFORM THEOR, V8, P179; Jones M., 2003, TR200325 MERL; Kim TH, 2003, ACM T GRAPHIC, V22, P392, DOI 10.1145/882262.882283; Kovar L, 2002, ACM T GRAPHIC, V21, P473; LEE J, 1999, ANN C SERIES, P39; Lee JH, 2002, ACM T GRAPHIC, V21, P491; LEVENTON ME, 1998, TR199806; Matusik W., 2001, P 12 EUR WORKSH REND, P115; Mikic I, 2001, PROC CVPR IEEE, P455; MORI G, 2002, P EUR C COMP VIS, V3, P666; Noser H., 1997, Proceedings. Computer Graphics International (Cat. No.97TB100104), DOI 10.1109/CGI.1997.601300; Ramanan D, 2004, ADV NEUR IN, V16, P1547; Rosales R., 2000, Proceedings Workshop on Human Motion, DOI 10.1109/HUMO.2000.897366; ROSALES R, 2001, 2001008 BOST U COMP; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Shakhnarovich G., 2003, Proceedings Ninth IEEE International Conference on Computer Vision; Shin HJ, 2001, ACM T GRAPHIC, V20, P67, DOI 10.1145/502122.502123; Shipp C.A., 2002, P 9 INT C INF PROC M, P203; Sidenbladh H., 2002, P EUR C COMP VIS, P784; Sminchisescu C, 2003, INT J ROBOT RES, V22, P371, DOI 10.1177/0278364903022006003; Stenger B., 2003, Proceedings Ninth IEEE International Conference on Computer Vision; Viola P., 2003, Proceedings Ninth IEEE International Conference on Computer Vision; Viola P, 2001, PROC CVPR IEEE, P511; Wu JX, 2004, ADV NEUR IN, V16, P1523; Yamamoto M, 1998, PROC CVPR IEEE, P2, DOI 10.1109/CVPR.1998.698580; YIN K, 2003, P 2003 ACM SIGGRAPH, P329; *CA I TECHN, 2002, CAM CAL TOOLB MATL; *POINT GREY CORP, 2001, DRAG CAM	46	32	37	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	0730-0301		ACM T GRAPHIC	ACM Trans. Graph.	OCT	2005	24	4					1303	1331		10.1145/1095878.1095882		29	Computer Science, Software Engineering	Computer Science	983PN	WOS:000233244700004	
J	Pant, G; Srinivasan, P				Pant, G; Srinivasan, P			Learning to crawl: Comparing classification schemes	ACM TRANSACTIONS ON INFORMATION SYSTEMS			English	Article						topical crawlers; focused crawlers; classifiers; machine learning	SUPPORT VECTOR MACHINES; NEURAL NETWORKS; WEB; TUTORIAL	Topical crawling is a young and creative area of research that holds the promise of benefiting from several sophisticated data mining techniques. The use of classification algorithms to guide topical crawlers has been sporadically suggested in the literature. No systematic study, however, has been done on their relative merits. Using the lessons learned from our previous crawler evaluation studies, we experiment with multiple versions of different classification schemes. The crawling process is modeled as a parallel best-first search over a graph defined by the Web. The classifiers provide heuristics to the crawler thus biasing it towards certain portions of the Web graph. Our results show that Naive Bayes is a weak choice for guiding a topical crawler when compared with Support Vector Machine or Neural Network. Further, the weak performance of Naive Bayes can be partly explained by extreme skewness of posterior probabilities generated by it. We also observe that despite similar performances, different topical crawlers cover subspaces on the Web with low overlap.	Univ Utah, Sch Accounting & Informat Syst, Salt Lake City, UT 84112 USA; Univ Iowa, Sch Lib & Informat Sci, Iowa City, IA 52242 USA; Univ Iowa, Dept Management Sci, Iowa City, IA 52242 USA	Pant, G (reprint author), Univ Utah, Sch Accounting & Informat Syst, Salt Lake City, UT 84112 USA.	gautam.pant@business.utah.edu; padmini-srinivasan@uiowa.edu					Aggarwal C. C., 2001, P 10 INT WORLD WID W; BENSHAUL I, 1999, COMPUTER NETWORKS IS, V31, P11; Ben-Shaul I, 1999, COMPUT NETW, V31, P1653, DOI 10.1016/S1389-1286(99)00045-6; Burges C. J. C., 1998, DATA MIN KNOWL DISC, V2; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CHAKRABARTI S, 1999, P 8 INT WORLD WID WE; Chakrabarti S., 2002, P 11 INT WORLD WID W; CHAU M, 2001, P 1 ACM IEEE CS JOIT; CHEN H, 2002, DECIS SUPPORT SYST, P1; Chen HC, 1998, J AM SOC INFORM SCI, V49, P604, DOI 10.1002/(SICI)1097-4571(19980515)49:7<604::AID-ASI3>3.0.CO;2-T; Chow C.K., 1957, Institute of Radio Engineers Transactions on Electronic Computers, VEC-6; CRASWELL N, 2003, P TREC 2003; Cristianini N, 2002, AI MAG, V23, P31; DAVISON BD, 2000, P 23 ANN INT ACM SIG; DAY M, 2003, COLLECTING PRESERVIN; DEBRA PME, 1994, P 1 INT WORLD WIDE W; Dietterich TG, 1997, AI MAG, V18, P97; Diligenti M., 2000, P 26 INT C VER LARG, P527; Duda R., 2000, PATTERN CLASSIFICATI; DUMAIS ST, 1998, IEEE INTELL SYST APP, V13, P4; ELKAN C, 1997, INT C KNOWL DISC DAT; Hersovici M., 1998, P 7 INT WORLD WID WE; Hogg R.V., 2004, INTRO MATH STAT; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891; Joachims T., 2002, THESIS KLUWER; John G. H., 1995, P 11 C UNC ART INT, P338; Johnson J., 2003, P 20 INT C MACH LEAR; Katzer J., 1982, Information Technology: Research and Development, V1; Lawrence S, 1998, SCIENCE, V280, P98, DOI 10.1126/science.280.5360.98; LeCun Y., 1986, DISORDERED SYSTEMS B, P233; RUMELHART DE, 1994, COMMUN ACM, V37, P87, DOI 10.1145/175247.175256; Lewis D. D., 1998, P 10 EUR C MACH LEAR, P4; LIPPMANN RP, 1988, ARTIFICIAL NEURAL NE, V36; MCCALLUM A, 1998, P AAAI 98 WORKSH LER; McCallum AK, 2000, INFORM RETRIEVAL, V3, P127, DOI 10.1023/A:1009953814988; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; MCLACHLAN G, 1992, DISCRIMINATN ANAL ST; Menczer F, 2000, MACH LEARN, V39, P203, DOI 10.1023/A:1007653114902; Menczer F, 2004, ACM T INTERNET TECHN, V4, P378, DOI 10.1145/1031114.1031117; Menczer F., 2001, P 24 ANN INT ACM SIG; Mitchell T, 1997, MACHINE LEARNING; MMAREK YS, 1997, COMPUTER NETWORKS IS, V29, P1269; MMAREK YS, 1997, COMPUTER NETWORKS IS, V29, P8; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; PANT G, 2003, P 7 EUR C RES ADV TE; PANT G, 2002, P 11 WORLD WID WEB W; Pant G., 2004, WEB DYNAMICS; Pant G., 2004, P 4 ACM IEEE CS JOIN, P142, DOI 10.1145/996350.996384; Pant G, 2002, AUTON AGENT MULTI-AG, V5, P221, DOI 10.1023/A:1014853428272; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; Qin J., 2004, P 4 ACM IEEE CS JOIN; Rennieyz J., 1999, P 16 INT C MACH LEAR, P335; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1, P318; Salton G., 1983, INTRO MODERN INFORM; Salton G., 1971, SMART RETRIEVAL SYST; Schapire R. E., 1999, P 16 INT JOINT C ART, P1401; Scholkopf B., 1999, ADV KERNEL METHODS S; SCHOLKOPF B, 2003, LECT NOTES ARTIF INT, P41; SRINIVASAN P, 2003, SIGIR 2003 WORKSH DE; Srinivasan P, 2005, INFORM RETRIEVAL, V8, P417, DOI 10.1007/s10791-005-6993-5; Theodoridis S., 2003, PATTERN RECOGNITION; Vapnik V. N, 1995, NATURE STAT LEARNING; WIDROW B, 1990, P IEEE, V78, P1415, DOI 10.1109/5.58323; WRIGHT S, 1999, NUMERICAL OPTIMIZATI; Yang Yiming, 1997, P 14 INT C MACH LEAR, P412	67	30	34	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	1046-8188		ACM T INFORM SYST	ACM Trans. Inf. Syst.	OCT	2005	23	4					430	462		10.1145/1095872.1095875		33	Computer Science, Information Systems	Computer Science	987TP	WOS:000233540500003	
J	Freischlad, M; Schnellenbach-Held, M				Freischlad, M; Schnellenbach-Held, M			A machine learning approach for the support of preliminary structural design	ADVANCED ENGINEERING INFORMATICS			English	Article; Proceedings Paper	11th International Workshop of the European-Group-for-Intelligent-Computing-in-Engineering	MAY 31-JUN 01, 2004	Weimar, GERMANY	European Grp Intelligent Comp Engn		knowledge acquisition; linguistic fuzzy modeling; genetic fuzzy systems		This paper deals with the representation and acquisition of structural design knowledge using fuzzy systems. A new approach for linguistic fuzzy modeling as well as a multi-objective evolutionary algorithm for the data-driven design of fuzzy systems is presented. The developed genetic fuzzy system has been applied to test problems and real-world tasks. Making use of the proposed approaches the interpretability of fuzzy systems can be increased without loss of accuracy. The developed system facilitates the knowledge acquisition and improves the maintainability of the knowledge base. (c) 2005 Elsevier Ltd. All rights reserved.	Univ Duisburg Essen, Inst Concrete Struct, Dept Civil Engn, D-45144 Essen, Germany	Freischlad, M (reprint author), Univ Duisburg Essen, Inst Concrete Struct, Dept Civil Engn, D-45144 Essen, Germany.	mark.freischlad@uni-essen.de; m.schnelienbach-held@uni-essen.de					ALBERT A, 2002, FORTSCHRITT BERICHT, V4; Bethke A. D., 1981, DISS ABSTR INT B; BODENHOFER U, 1997, INT SUMM SCH ADV CON; Casillas J., 2003, STUDIES FUZZINESS SO, V129; Foo N, 1972, CR2093 NASA; Geyer-Schulz A., 1995, FUZZY RULE BASED EXP; Goldberg DE, 1989, GENETIC ALGORITHMS S; Grefenstette J. J., 1985, P 1 INT C GEN ALG TH; Koza J. R., 1992, GENETIC PROGRAMMING; MAMDANI EH, 1975, INT J MAN MACH STUD, V7, P1, DOI 10.1016/S0020-7373(75)80002-2; Marin-Blazquez JG, 2002, IEEE T FUZZY SYST, V10, P484, DOI 10.1109/TFUZZ.2002.800687; POMARES H, 2003, STUDIES FUZZINESS SO, V129; SCHNELLENBACHHE.M, 2002, FUZZY RULE BASED MOD; SCHNELLENBACHHE.M, 2002, ADV INTELLIGENT COMP; Setnes M, 1998, IEEE T SYST MAN CY C, V28, P165, DOI 10.1109/5326.661100; TAKAGI T, 1985, IEEE T SYST MAN CYBE, V15; *EUR, 1992, 2 EUR 1	17	3	3	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1474-0346		ADV ENG INFORM	Adv. Eng. Inform.	OCT	2005	19	4					281	287		10.1016/j.aei.2005.07.001		7	Computer Science, Artificial Intelligence; Engineering, Multidisciplinary	Computer Science; Engineering	983TM	WOS:000233255000004	
J	Nugent, C; Cunningham, P				Nugent, C; Cunningham, P			A case-based explanation system for black-box systems	ARTIFICIAL INTELLIGENCE REVIEW			English	Article						black-box systems; case-based reasoning; explanation	ARTIFICIAL NEURAL-NETWORKS	Most users of machine-learning products are reluctant to use them without any sense of the underlying logic that has led to the system's predictions. Unfortunately many of these systems lack any transparency in the way they operate and are deemed to be black boxes. In this paper we present a Case-Based Reasoning (CBR) solution to providing supporting explanations of black-box systems. This CBR solution has two key facets; it uses local information to assess the importance of each feature and using this, it selects the cases from the data used to build the black-box system for use in explanation. The retrieval mechanism takes advantage of the derived feature importance information to help select cases that are a better reflection of the black-box solution and thus more convincing explanations.	Univ Dublin Trinity Coll, Dept Comp Sci, Machine Learning Grp, Dublin 2, Ireland	Nugent, C (reprint author), Univ Dublin Trinity Coll, Dept Comp Sci, Machine Learning Grp, Dublin 2, Ireland.	conor.nugent@cs.tcd.ie; padraig.cunningham@cs.tcd.ie					Andrews R, 1995, KNOWL-BASED SYST, V8, P373, DOI 10.1016/0950-7051(96)81920-4; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; CASSENS J, 2004, P ECCBR 2004 WORKSH, P97; Cunningham P, 2003, LECT NOTES ARTIF INT, V2689, P122; Domingos P., 1998, INTELL DATA ANAL, V2, P187, DOI 10.1016/S1088-467X(98)00023-7; Doyle D, 2004, LECT NOTES COMPUT SC, V3155, P157; Gentner D, 2003, J EDUC PSYCHOL, V95, P393, DOI 10.1037/0022-0663.95.2.393; Leake D. B., 1996, CASE BASED REASONING, P3; Majchrzak A., 1991, AI & Society, V5, DOI 10.1007/BF02077438; McSherry D, 2004, LECT NOTES COMPUT SC, V3155, P317; MCSHERRY D, 2003, P 8 UK WORKSH CAS BA, P47; SORMO F, 2004, P ECCBR 2004 WORKSH, P165; Tickle AB, 1998, IEEE T NEURAL NETWOR, V9, P1057, DOI 10.1109/72.728352; Walsh Paul, 2004, Eur J Emerg Med, V11, P259, DOI 10.1097/00063110-200410000-00004; Zhou ZH, 2003, IEEE T INF TECHNOL B, V7, P37, DOI 10.1109/TITB.2003.808498	15	7	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0269-2821		ARTIF INTELL REV	Artif. Intell. Rev.	OCT	2005	24	2					163	178		10.1007/s10462-005-4609-5		16	Computer Science, Artificial Intelligence	Computer Science	983OU	WOS:000233242800004	
J	Kasson, PM; Huppa, JB; Davis, MM; Brunger, AT				Kasson, PM; Huppa, JB; Davis, MM; Brunger, AT			A hybrid machine-learning approach for segmentation of protein localization data	BIOINFORMATICS			English	Article							SUPPORT VECTOR MACHINES; T-CELL-RECEPTOR; IMMUNOLOGICAL SYNAPSE FORMATION; INTRANUCLEAR INCLUSIONS; ACTIVE CONTOURS; RECOGNITION; ACTIVATION; DYNAMICS; COMPLEX; VISUALIZATION	Motivation: Subcellular protein localization data are critical to the quantitative understanding of cellular function and regulation. Such data are acquired via observation and quantitative analysis of fluorescently labeled proteins in living cells. Differentiation of labeled protein from cellular artifacts remains an obstacle to accurate quantification. We have developed a novel hybrid machine-learning-based method to differentiate signal from artifact in membrane protein localization data by deriving positional information via surface fitting and combining this with fluorescence-intensity-based data to generate input for a support vector machine. Results: We have employed this classifier to analyze signaling protein localization in T-cell activation. Our classifier displayed increased performance over previously available techniques, exhibiting both flexibility and adaptability: training on heterogeneous data yielded a general classifier with good overall performance; training on more specific data cyielded an extremely high-performance specific classifier. We also demonstrate accurate automated learning utilizing additional experimental data.	Stanford Univ, Stanford Synchrotron Radiat Lab, Dept Mol & Cellular Physiol, Stanford, CA 94305 USA; Stanford Univ, Stanford Synchrotron Radiat Lab, Dept Neurol & Neurol Sci, Stanford, CA 94305 USA; Stanford Univ, Med Sci Training Program, Stanford, CA 94305 USA; Stanford Univ, Biophys Program, Stanford, CA 94305 USA; Howard Hughes Med Inst, Stanford, CA 94305 USA; Stanford Univ, Sch Med, Dept Microbiol & Immunol, Stanford, CA 94305 USA	Brunger, AT (reprint author), Stanford Univ, Stanford Synchrotron Radiat Lab, Dept Mol & Cellular Physiol, Stanford, CA 94305 USA.	brunger@stanford.edu					Bock JR, 2001, BIOINFORMATICS, V17, P455, DOI 10.1093/bioinformatics/17.5.455; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; Davies SW, 1997, CELL, V90, P537, DOI 10.1016/S0092-8674(00)80513-9; Davis MM, 2003, ANNU REV BIOCHEM, V72, P717, DOI 10.1146/annurev.biochem.72.121801.161625; Ding CHQ, 2001, BIOINFORMATICS, V17, P349, DOI 10.1093/bioinformatics/17.4.349; Ehrlich LIR, 2002, IMMUNITY, V17, P809, DOI 10.1016/S1074-7613(02)00481-8; FINK PJ, 1986, NATURE, V321, P219, DOI 10.1038/321219a0; Gautam M, 1996, CELL, V85, P525, DOI 10.1016/S0092-8674(00)81253-2; GENOVESIO A, 2003, 2003 INT C IM PROC; Gerlich D, 2003, METHODS, V29, P3, DOI 10.1016/S1046-2023(20)00287-6; Gerlich D, 2001, NAT CELL BIOL, V3, P852, DOI 10.1038/ncb0901-852; Glebov OO, 2004, NAT CELL BIOL, V6, P238, DOI 10.1038/ncb1103; Grakoui A, 1999, SCIENCE, V285, P221, DOI 10.1126/science.285.5425.221; Huan YH, 1999, J CLIN INVEST, V104, P1459, DOI 10.1172/JCI5111; Huppa JB, 2003, NAT IMMUNOL, V4, P749, DOI 10.1038/ni951; Huppa JB, 2003, NAT REV IMMUNOL, V3, P973, DOI 10.1038/nri1245; Joachims T., 1999, ADV KERNEL METHODS S; Karchin R, 2002, BIOINFORMATICS, V18, P147, DOI 10.1093/bioinformatics/18.1.147; Kasson PM, 2005, BIOPHYS J, V88, P579, DOI 10.1529/biophysj.104.048827; Krummel MF, 2000, SCIENCE, V289, P1349, DOI 10.1126/science.289.5483.1349; Lee KH, 2003, SCIENCE, V302, P1218, DOI 10.1126/science.1086507; Lee KH, 2002, SCIENCE, V295, P1539, DOI 10.1126/science.1067710; Monks CRF, 1998, NATURE, V395, P82; Moss WC, 2002, P NATL ACAD SCI USA, V99, P15024, DOI 10.1073/pnas.192573999; Ohno K, 2002, AM J HUM GENET, V70, P875, DOI 10.1086/339465; Pagliarini RA, 2003, SCIENCE, V302, P1227, DOI 10.1126/science.1088474; Pontil M, 1998, IEEE T PATTERN ANAL, V20, P637, DOI 10.1109/34.683777; Roitbak T, 2004, MOL BIOL CELL, V15, P1334, DOI 10.1091/mbc.E03-05-0296; Saudou F, 1998, CELL, V95, P55, DOI 10.1016/S0092-8674(00)81782-1; Singh SP, 1998, CANCER RES, V58, P1730; Stauffer TP, 1998, CURR BIOL, V8, P343, DOI 10.1016/S0960-9822(98)70135-6; Varnai P, 1998, J CELL BIOL, V143, P501, DOI 10.1083/jcb.143.2.501; Wulfing C, 1998, P NATL ACAD SCI USA, V95, P6302, DOI 10.1073/pnas.95.11.6302; Xia WY, 2004, CLIN CANCER RES, V10, P3815, DOI 10.1158/1078-0432.CCR-03-0527; Yang JW, 2001, NAT BIOTECHNOL, V19, P219, DOI 10.1038/85655; Zimmer C, 2002, IEEE T MED IMAGING, V21, P1212, DOI [10.1109/TMI.2002.806292, 10.1109/TMI.2002.0806292]	40	6	6	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	OCT 1	2005	21	19					3778	3786		10.1093/bioinformatics/bti615		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	974MO	WOS:000232596100012	
J	Sajn, L; Kukar, M; Kononenko, I; Milcinski, M				Sajn, L; Kukar, M; Kononenko, I; Milcinski, M			Computerized segmentation of whole-body bone scintigrams and its use in automated diagnostics	COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE			English	Article						whole-body bone scintigraphy; reference point detection; automatic segmentation; image processing; machine learning	DISEASE	Bone scintigraphy or whole-body bone scan is one of the most common diagnostic procedures in nuclear medicine used in the last 25 years. Pathological conditions, technically poor image resolution and artefacts necessitate that algorithms use sufficient background knowledge of anatomy and spatial relations of bones in order to work satisfactorily. A robust knowledge based methodology for detecting reference points of the main skeletal regions that is simultaneously applied on anterior and posterior whole-body bone scintigrams is presented. Expert knowledge is represented as a set of parameterized rules which are used to support standard image-processing algorithms. Our study includes 467 consecutive, non-selected scintigrams, which is, to our knowledge the largest number of images ever used in such studies. Automatic analysis of whole-body bone scans using our segmentation algorithm gives more accurate and reliable results than previous studies. Obtained reference points are used for automatic segmentation of the skeleton, which is applied to automatic (machine learning) or manual (expert physicians) diagnostics. Preliminary experiments show that an expert system based on machine learning closely mimics the results of expert physicians. (c) 2005 Elsevier Ireland Ltd. All rights reserved.	Univ Ljubljana, Fac Comp & Informat Sci, SI-1001 Ljubljana, Slovenia; Univ Ljubljana, Ctr Med, Dept Nucl Med, SI-1525 Ljubljana, Slovenia	Sajn, L (reprint author), Univ Ljubljana, Fac Comp & Informat Sci, Trzaska 25, SI-1001 Ljubljana, Slovenia.	luka.sajn@fri.uni-lj.si; igor.kononenko@fri.uni-lj.si; metka.milcinski@kclj.si	Sajn, Luka/A-6584-2008				BENNEKE A, 1997, THESIS U HILDESHEIM; BERNAUER J, 1995, THESIS U HILDESHEIM; BERNING KC, 1996, THESIS U HILDESHEIM; BEVK M, 2004, ECML PKDD 2004 P WOR, P43; Blum H., 1967, MODELS PERCEPTION SP; Cristianini N., 2000, INTRO SUPPORT VECTOR; EBERLY D, 2003, INFORM ELLIPSES, V12; Hendler A, 1998, POSTGRAD MED, V104, P54; Hough P. V. C., 1959, P INT C HIGH EN ACC; Jammal G, 2004, SIGNAL PROCESS, V84, P1049, DOI 10.1016/j.sigpro.2004.03.008; KINDRATENKO V, 1997, THESIS U INSTELLING; Kukar M, 1999, ARTIF INTELL MED, V16, P25, DOI 10.1016/S0933-3657(98)00063-3; MAISEY MN, 1973, J CLIN ENDOCR METAB, V36, P317; McCallum A, 1999, P AAAI 99 WORKSH TEX; MULLER V, 2001, RADIOL ONCOL, V35, P21; Noguchi M, 2003, BRIT J CANCER, V88, P195, DOI 10.1038/sj.bjc.6600715; SAJN L, 2004, AUTOMATIC SEGMENTATI; SHEN X, 2004, P 2004 INT S EL IM E; WEINER MG, 2001, RADIOL ONCOL, V35, P185; Yin TK, 2004, IEEE T MED IMAGING, V23, P639, DOI 10.1109/TMI.2004.826355	20	11	11	ELSEVIER IRELAND LTD	CLARE	ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND	0169-2607		COMPUT METH PROG BIO	Comput. Meth. Programs Biomed.	OCT	2005	80	1					47	55		10.1016/j.cmpb.2005.06.001		9	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	976ST	WOS:000232754300005	
J	Tseng, VS; Kao, CP				Tseng, VS; Kao, CP			Efficiently mining gene expression data via a novel parameterless clustering method	IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS			English	Article						machine learning; data mining; clustering; mining methods and algorithms	PATTERNS	Clustering analysis has been an important research topic in the machine learning field due to the wide applications. In recent years, it has even become a valuable and useful tool for in-silico analysis of microarray or gene expression data. Although a number of clustering methods have been proposed, they are confronted with difficulties in meeting the requirements of automation, high quality, and high efficiency at the same time. In this paper, we propose a novel, parameterless and efficient clustering algorithm, namely, Correlation Search Technique (CST), which fits for analysis of gene expression data. The unique feature of CST is it incorporates the validation techniques into the clustering process so that high quality clustering results can be produced on the fly. Through experimental evaluation, CST is shown to outperform other clustering methods greatly in terms of clustering quality, efficiency, and automation on both of synthetic and real data sets.	Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 701, Taiwan	Tseng, VS (reprint author), Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, 1 Ta Hsueh Rd, Tainan 701, Taiwan.	tsengsm@mail.ncku.edu.tw; zeno@dmlab.csie.ncku.edu.tw					Aldenderfer M. S., 1984, CLUSTER ANAL; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Ben-Dor A, 1999, J COMPUT BIOL, V6, P281, DOI 10.1089/106652799318274; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Guha S, 1999, PROC INT CONF DATA, P512, DOI 10.1109/ICDE.1999.754967; Guha S., 1998, P ACM SIGMOD INT C M, P73, DOI 10.1145/276304.276312; Hathaway RJ, 2003, PATTERN RECOGN LETT, V24, P1563, DOI 10.1016/S0167-8655(02)00395-1; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Kerr MK, 2001, P NATL ACAD SCI USA, V98, P8961, DOI 10.1073/pnas.161273698; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; ROHLF F. JAMES, 1963, ANN ENTOMOL SOC AMER, V56, P798; RUMELHART DE, 1985, COGNITIVE SCI, V9, P75, DOI 10.1207/s15516709cog0901_5; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; TSENG SM, 2003, INFORMATICA, V27, P21; TSENG SM, 2002, P INT C MATH ENG TEC; Yeung KY, 2001, BIOINFORMATICS, V17, P309, DOI 10.1093/bioinformatics/17.4.309; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324	21	44	46	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1545-5963		IEEE ACM T COMPUT BI	IEEE-ACM Trans. Comput. Biol. Bioinform.	OCT-DEC	2005	2	4					355	365		10.1109/TCBB.2005.56		11	Biochemical Research Methods; Computer Science, Interdisciplinary Applications; Mathematics, Interdisciplinary Applications; Statistics & Probability	Biochemistry & Molecular Biology; Computer Science; Mathematics	017PB	WOS:000235704400007	
J	Saligrama, V				Saligrama, V			A convex analytic approach to system identification	IEEE TRANSACTIONS ON AUTOMATIC CONTROL			English	Article						complex systems; convex analysis; input design; linear algorithms; robust identification	SET MEMBERSHIP UNCERTAINTY; TIME-VARYING SYSTEMS; PERSISTENT IDENTIFICATION; ROBUST IDENTIFICATION; UNMODELED DYNAMICS; ERROR-BOUNDS; DISTURBANCES; COMPLEXITY; MODELS	This paper introduces a new concept for system identification in order to account for random and nonrandom(deterministic/set-membership) uncertainties. While, random/stochastic models are natural for modeling measurement errors, nonrandom uncertainties are well-suited for modeling parametric and nonparametric components. The new concept introduced is distinct from earlier concepts in many respects. First, inspired by the concept of uniform convergence of empirical means developed in machine learning theory, we seek a stronger notion of convergence in that the objective is to obtain probabilistic uniform convergence of model estimates to the minimum possible radius of uncertainty. Second, the formulation lends itself to convex analysis leading to description of optimal algorithms, which turn out to be well-known instrument-variable methods for many of the problems. Third, we characterize conditions on inputs in terms of second-order sample path properties required to achieve the minimum radius of uncertainty. Finally, we present fundamental bounds and optimal algorithms for system identification for a wide variety of standard as well as nonstandard problems that include special structures such as unmodeled dynamics, positive real conditions, bounded sets and linear fractional maps.	Boston Univ, Dept Elect & Comp Engn, Boston, MA 02215 USA	Saligrama, V (reprint author), Boston Univ, Dept Elect & Comp Engn, Boston, MA 02215 USA.	srv@bu.edu					Billingsley P., 1995, PROBABILITY MEASURE; BORKAR V, 2004, J INDIAN STAT I, V66, P292; Caines P., 1988, LINEAR STOCHASTIC SY; CAMPI MC, 1994, IEEE T SIGNAL PROCES, V42, P2906, DOI 10.1109/78.330351; Campi MC, 2002, IEEE T AUTOMAT CONTR, V47, P1329, DOI 10.1109/TAC.2002.800750; DAHLEH MA, 1993, SYST CONTROL LETT, V20, P157, DOI 10.1016/0167-6911(93)90057-D; GARULLI A, 2000, P IFAC S SYST ID SAN; Giarre L, 1997, AUTOMATICA, V33, P1133, DOI 10.1016/S0005-1098(97)00007-1; GU GX, 1992, IEEE T AUTOMAT CONTR, V37, P953, DOI 10.1109/9.148347; LEHMANNEL, 1997, TESTING STAT HYPOTHE; Ljung L., 1987, IDENTIFICATION THEOR; LJUNG L, 1985, IEEE T AUTOMAT CONTR, V30, P514; Luenberger D., 1969, OPTIMIZATION VECTOR; MAKILA PM, 1991, INT J CONTROL, V54, P1189, DOI 10.1080/00207179108934204; MILANESE M, 1982, IEEE T AUTOMAT CONTR, V27, P408, DOI 10.1109/TAC.1982.1102926; MILANESE M, 1991, AUTOMATICA, V27, P997, DOI 10.1016/0005-1098(91)90134-N; MORSE AS, 1992, IEEE T AUTOMAT CONTR, V37, P1343, DOI 10.1109/9.159571; Papadimitriou C.H., 1997, COMBINATORIAL OPTIMI; POOLLA K, 1994, IEEE T AUTOMAT CONTR, V39, P944, DOI 10.1109/9.284870; RUDIN W., 1976, PRINCIPLES MATH ANAL; TSE DNC, 1993, IEEE T AUTOMAT CONTR, V38, P1176, DOI 10.1109/9.233151; VANDENHOF P, 1993, SPECIAL TOPICS IDENT, P39; Vapnik V. N, 1995, NATURE STAT LEARNING; VENKATESH S, 2004, Patent No. 6748086; VENKATESH S, 2002, INT S INF THEOR LAUS; Venkatesh S, 2004, SYST CONTROL LETT, V53, P117, DOI 10.1016/j.sysconle.2003.10.007; Venkatesh SR, 1997, IEEE T AUTOMAT CONTR, V42, P1620, DOI 10.1109/9.650013; Venkatesh SR, 2001, IEEE T AUTOMAT CONTR, V46, P235, DOI 10.1109/9.905690; VENKATESH SR, 1997, P 36 IEEE C DEC CONT; Vicino A, 1996, IEEE T AUTOMAT CONTR, V41, P774, DOI 10.1109/9.506230; Vidyasagar M., 1997, THEORY LEARNING GENE; WAHLBERG B, 1991, IEEE T AUTOMAT CONTR, V36, P551, DOI 10.1109/9.76361; WAHLBERG B, 1992, IEEE T AUTOMAT CONTR, V37, P900, DOI 10.1109/9.148343; Wang LY, 2000, IEEE T AUTOMAT CONTR, V45, P1246; Wang LY, 1997, IEEE T AUTOMAT CONTR, V42, P66; Wasilkowski G. W., 1983, INFORM UNCERTAINTY C	36	7	7	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9286		IEEE T AUTOMAT CONTR	IEEE Trans. Autom. Control	OCT	2005	50	10					1550	1566		10.1109/TAC.2005.856654		17	Automation & Control Systems; Engineering, Electrical & Electronic	Automation & Control Systems; Engineering	975CU	WOS:000232639400008	
J	Wang, Y; van der Schaar, M; Chang, SF; Loui, AC				Wang, Y; van der Schaar, M; Chang, SF; Loui, AC			Classification-based multidimensional adaptation prediction for scalable video coding using subjective quality evaluation	IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY			English	Article						classification-based video adaptation; motion compensated three-dimensional subband coding (MC-3DSBC); multidimensional adaptation (MDA); subjective perceptual quality		Scalable video coding offers a flexible representation for video adaptation in multiple dimensions comprising spatial detail and temporal resolution, thus providing great benefits for universal media access (UMA) applications. However, currently most of the approaches address the multidimensional adaptation (MDA) problem in an ad hoc manner. One challenging issue affecting the systematic MDA solution is the difficulty in constructing analytical models in theoretical optimization that capture the relations between video utility And MDA operations. In this paper, we propose a general classification-based prediction framework for selecting the preferred MDA operations based on subjective quality evaluation. For this purpose, we first apply domain-specific knowledge or general unsupervised clustering to construct distinct categories within which the videos share similar preferred MDA operations. Thereafter, a machine learning based method is applied where the low level content features extracted from the compressed video streams are employed to train a framework for the problem of joint signal-to-noise ratio (SNR)-temporal adaptation selection based on the motion compensated three-dimensional subband coding (MC-3DSBC) system. We conduct extensive subjective tests involving 31 subjects, 128 video clips, and formal subjective quality metrics. Statistical analysis of the experimental results confirms the excellent accuracy in using domain knowledge And content features to predict the MDA operation.	Columbia Univ, Dept Elect Engn, New York, NY 10027 USA; Univ Calif Davis, Dept Elect & Comp Engn, Davis, CA 95616 USA; Eastman Kodak Co, Imaging Sci & Technol Lab, Rochester, NY 14650 USA	Wang, Y (reprint author), Columbia Univ, Dept Elect Engn, New York, NY 10027 USA.	mvanderschaar@ece.ucdavis.edu; sfchang@ee.columbia.edu; alexander.loui@kodak.com					AKYOL E, 2004, PICT COD S SAN FRANC; Barbara D., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; BOCHECK P, 1999, ACM INT WOKSH NETW O; Chang SF, 2005, P IEEE, V93, P148, DOI 10.1109/JPROC.2004.839600; Chen JJ, 1997, IEEE T CIRC SYST VID, V7, P299; Chen PS, 2004, IEEE T CIRC SYST VID, V14, P1183, DOI 10.1109/TCSVT.2004.833165; Choi SJ, 1999, IEEE T IMAGE PROCESS, V8, P155, DOI 10.1109/83.743851; ELEFTHERIADIS A, 1995, THESIS COLUMBIA U NE; Hung BF, 2003, IEEE J SEL AREA COMM, V21, P1595; LAMBRECHT CJ, 1996, THESIS ECOLE POLYTEC; MUKHERJEE D, 2004, IEEE T MULTIMEDIA, V7, P454; Radha HM, 2001, IEEE T MULTIMEDIA, V3, P53, DOI 10.1109/6046.909594; RAJENDRAN RK, 2002, P ISCAS MAY, P445; Reed EC, 2002, IEEE T IMAGE PROCESS, V11, P873, DOI 10.1109/TIP.2002.801122; ROHALY A, 2000, 980E COM ITUT; Shanableh T, 2000, IEEE T MULTIMEDIA, V2, P101, DOI 10.1109/6046.845014; VETRO A, 2002, P IEEE INT C IM PROC, V3, P534; Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P18, DOI 10.1109/MSP.2003.1184336; WANG Y, P SPIE VID COMM IM P, P529; WANG Y, 2003, P 2003 IEEE WIC INT, P189; Werner O, 1999, IEEE T IMAGE PROCESS, V8, P179, DOI 10.1109/83.743853; YIN P, 2000, P IEEE INT C IM PROC, P972	23	18	18	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1051-8215		IEEE T CIRC SYST VID	IEEE Trans. Circuits Syst. Video Technol.	OCT	2005	15	10					1270	1279		10.1109/TCSVT.2005.854224		10	Engineering, Electrical & Electronic	Engineering	971BB	WOS:000232355000008	
J	Butz, MV; Goldberg, DE; Lanzi, PL				Butz, MV; Goldberg, DE; Lanzi, PL			Gradient descent methods in learning classifier systems: Improving XCS performance in multistep problems	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION			English	Article						function approximation; gradient descent; learning classifier systems (LCSs); multistop problems; Q-learning; reinforcement learning; XCS		The accuracy-based XCS classifier system has been shown to solve typical data mining problems in a machine-learning competitive way. However, successful applications in multistep problems, modeled by a Markov decision process, were restricted to very small problems. Until now, the temporal difference learning technique in XCS was based on deterministic updates. However, since a prediction is actually generated by a set of rules in XCS and Learning Classifier Systems in general, gradient-based update methods are applicable. The extension of XCS to gradient-based update methods results in a classifier system that is more robust and more parameter independent, solving large and difficult maze problems reliably. Additionally, the extension to gradient methods highlights the relation of XCS to other function approximation methods in reinforcement learning.	Univ Illinois, Dept Gen Engn, Illinois Genet Algorithms Lab, Urbana, IL 61801 USA; Politecn Milan, Dipartimento Elettron & Informat, Artificial Intelligence & Robot Lab, I-20133 Milan, Italy	Butz, MV (reprint author), Univ Illinois, Dept Gen Engn, Illinois Genet Algorithms Lab, Urbana, IL 61801 USA.	butz@illigal.ge.uiuc.edu; deg@illigal.ge.uiuc.edu; lanzi@illigal.ge.uiuc.edu	Butz, Martin/C-2366-2009				Baird L. C, 1999, THESIS CARNEGIE MELL; Baird L. C., 1995, P 12 INT C MACH LEAR, P30; Barry A. M., 2002, Soft Computing, V6, DOI 10.1007/s005000100115; Bernado-Mansilla E., 2001, P 4 INT WORKSH LEARN, P337; Bull L, 2002, EVOL COMPUT, V10, P185, DOI 10.1162/106365602320169848; Butz MV, 2003, LECT NOTES COMPUT SC, V2724, P1857; Butz M. V., 2002, Soft Computing, V6, DOI 10.1007/s005000100111; BUTZ MV, 2003, 2003023 U ILL ILL GE; Butz MV, 2004, IEEE T EVOLUT COMPUT, V8, P28, DOI 10.1109/TEVC.2003.818194; Butz MV, 2003, LECT NOTES ARTIF INT, V2684, P282; Dixon PW, 2002, LECT NOTES ARTIF INT, V2321, P133; GLANTZ SA, 2001, PRIER APPL REGRESSIO; Goldberg D. E, 1983, THESIS U MICHIGAN; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237; Kovacs T., 2003, STRENGTH ACCURACY CR; LANZI PL, 2001, P GEN EV COMP C GECC, P958; LANZI PL, 1999, P GEN EV COMP C GECC, P353; Lanzi PL, 1999, EVOL COMPUT, V7, P125, DOI 10.1162/evco.1999.7.2.125; Lanzi P. L., 2002, Soft Computing, V6, DOI 10.1007/s005000100113; Lanzi PL, 1999, P GEN EV COMP C GECC, P337; LANZL PI, 2002, XCS LIB; Sutton R. S., 1990, P 7 INT C MACH LEARN, P216; Sutton R.S., 1998, REINFORCEMENT LEARNI; Watkins C. J. C. H., 1989, THESIS KINGS COLL CA; WILSON JM, 1994, CLIN IMMUNOTHER, V1, P1; Wilson S., 2001, LECT NOTES ARTIF INT, V1996, P158; Wilson S. W., 2001, P GEN EV COMP C GECC, P974; Wilson S.W., 1998, P 3 ANN GEN PROGR C, P665; Wilson S. W., 2002, Natural Computing, V1, DOI 10.1023/A:1016535925043; Wilson SW, 2000, LECT NOTES ARTIF INT, V1813, P209, DOI 10.1007/3-540-45027-0_11; Wilson SW, 1995, EVOL COMPUT, V3, P149, DOI 10.1162/evco.1995.3.2.149	31	19	19	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1089-778X		IEEE T EVOLUT COMPUT	IEEE Trans. Evol. Comput.	OCT	2005	9	5					452	473		10.1109/TEVC.2005.850265		22	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	971VM	WOS:000232412900002	
J	Wei, LY; Yang, YY; Nishikawa, RM; Wernick, MN; Edwards, A				Wei, LY; Yang, YY; Nishikawa, RM; Wernick, MN; Edwards, A			Relevance vector machine for automatic detection of clustered microcalcifications	IEEE TRANSACTIONS ON MEDICAL IMAGING			English	Article						breast cancer detection; computer-aided diagnosis; mammography; microcalcifications; relevance vector machine	DIGITAL MAMMOGRAMS; SEGMENTATION; ENHANCEMENT; ALGORITHMS; CONTRAST; IMAGES	Clustered microcalcifications (MC) in mammograms can be an important early sign of breast cancer in women. Their accurate detection is important in computer-aided detection (CADe). In this paper, we propose the use of a recently developed machine-learning technique - relevance vector machine (RVM) for detection of MCs in digital mammograms. RVM is based on Bayesian estimation theory, of which a distinctive feature is that it can yield a sparse decision function that is defined by only a very small number of so-called relevance vectors. By exploiting this sparse property of the RVM, we develop computerized detection algorithms that are not only accurate but also computationally efficient for MC detection in mammograms. We formulate MC detection as a supervised-learning problem, and apply RVM as a classifier to determine at each location in the mammogram if an MC object is present or not. To increase the computation speed further, we develop a two-stage classification network, in which a computationally much simpler linear RVM classifier is applied first to quickly eliminate the overwhelming majority, non-MC pixels in a mammogram from any further consideration. The proposed method is evaluated using a database of 141 clinical mammograms (all containing MCs), and compared with a well-tested support vector machine (SVM) classifier. The detection performance is evaluated using free-response receiver operating characteristic (FROC) curves. It is demonstrated in our experiments that the RVM classifier could greatly reduce the computational complexity of the SVM while maintaining its best detection accuracy. In particular, the two-stage RVM approach could reduce the detection time from 250 s for SVM to 7.26 s for a mammogram (nearly 35-fold reduction). Thus, the proposed RVM classifier is more advantageous for real-time processing of MC clusters in mammograms.	IIT, Dept Elect & Comp Engn, Chicago, IL 60616 USA; IIT, Dept Biomed Engn, Chicago, IL 60616 USA; Univ Chicago, Dept Radiol, Chicago, IL 60637 USA	Yang, YY (reprint author), IIT, Dept Elect & Comp Engn, 3301 S Dearborn St, Chicago, IL 60616 USA.						Bazzani A, 2001, PHYS MED BIOL, V46, P1651, DOI 10.1088/0031-9155/46/6/305; BUNCH PC, 1978, J APPL ENG, V4; Cheng HD, 1998, IEEE T MED IMAGING, V17, P442; DENGLER J, 1993, IEEE T MED IMAGING, V12, P634, DOI 10.1109/42.251111; El-Naqa I, 2002, IEEE T MED IMAGING, V21, P1552, DOI 10.1109/TMI.2002.806569; Kallergi M, 1999, MED PHYS, V26, P267, DOI 10.1118/1.598514; Li H, 1997, IEEE T MED IMAGING, V16, P785, DOI 10.1109/42.650875; McLoughlin KJ, 2004, IEEE T MED IMAGING, V23, P313, DOI 10.1109/TMI.2004.824240; MORROW WM, 1992, IEEE T MED IMAGING, V11, P392, DOI 10.1109/42.158944; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; NISHIKAWA RM, 2002, IMAGE PROCESSING TEC; NISHIKAWA RM, 1995, MED BIOL ENG COMPUT, V33, P174, DOI 10.1007/BF02523037; Ripley B. D, 1996, PATTERN RECOGNITION; Strickland RN, 1996, IEEE T MED IMAGING, V15, P218, DOI 10.1109/42.491423; TIPPING ME, SPARSE BAYESIAN LEAR; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Vapnik VN, 1998, STAT LEARNING THEORY; Veldkamp WJH, 2000, IEEE T MED IMAGING, V19, P731, DOI 10.1109/42.875197; Yu SY, 2000, IEEE T MED IMAGING, V19, P115; Zwiggelaar R, 2004, IEEE T MED IMAGING, V23, P1077, DOI 10.1109/TMI.2004.828675; *AM CANC SOC, 1998, CANC FACTS FIG 1998	21	45	53	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0278-0062		IEEE T MED IMAGING	IEEE Trans. Med. Imaging	OCT	2005	24	10					1278	1285		10.1109/TMI.2005.855435		8	Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging	Computer Science; Engineering; Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging	969LX	WOS:000232236800005	
J	Gyimothy, T; Ferenc, R; Siket, I				Gyimothy, T; Ferenc, R; Siket, I			Empirical validation of object-oriented metrics on open source software for fault prediction	IEEE TRANSACTIONS ON SOFTWARE ENGINEERING			English	Article; Proceedings Paper	20th IEEE International Conference on Software Maintenance (ICSM 2004)	SEP 11-14, 2004	Chicago, IL	IEEE Comp Soc		fact extraction; metrics validation; reverse engineering; open source software; fault-proneness detection; Mozilla; Bugzilla; C plus; compiler wrapping; Columbus	DESIGN; C++	Open source software systems are becoming increasingly important these days. Many companies are investing in open source projects and lots of them are also using such software in their own work. But, because open source software is often developed with a different management style than the industrial ones, the quality and reliability of the code needs to be studied. Hence, the characteristics of the source code of these projects need to be measured to obtain more information about it. This paper describes how we calculated the object-oriented metrics given by Chidamber and Kemerer to illustrate how fault-proneness detection of the source code of the open source Web and e-mail suite called Mozilla can be carried out. We checked the values obtained against the number of bugs found in its bug database - called Bugzilla - using regression and machine learning methods to validate the usefulness of these metrics for fault-proneness prediction. We also compared the metrics of several versions of Mozilla to see how the predicted fault-proneness of the software system changed during its development cycle.	Univ Szeged, Dept Software Engn, H-6720 Szeged, Hungary	Gyimothy, T (reprint author), Univ Szeged, Dept Software Engn, Arpad Ter 2, H-6720 Szeged, Hungary.	gyimi@inf.u-szeged.hu; ferenc@inf.u-szeged.hu; siket@inf.u-szeged.hu					Basili V. R., 1996, IEEE T SOFTWARE ENG, V22, P751; Bishop C.M., 1995, NEURAL NETWORKS PATT; BRIAND LC, 2002, ADV COMPUTERS, V56; Briand LC, 2002, IEEE T SOFTWARE ENG, V28, P706, DOI 10.1109/TSE.2002.1019484; Briand LC, 2000, J SYST SOFTWARE, V51, P245, DOI 10.1016/S0164-1212(99)00102-8; Chen YF, 1998, IEEE T SOFTWARE ENG, V24, P682; CHIDAMBER SR, 1994, IEEE T SOFTWARE ENG, V20, P476, DOI 10.1109/32.295895; Ferenc R., 2002, Proceedings of the Sixth European Conference on Software Maintenance and Reengineering, DOI 10.1109/CSMR.2002.995790; Ferenc R, 2004, PROC IEEE INT CONF S, P60, DOI 10.1109/ICSM.2004.1357790; Ferenc R, 2002, PROC IEEE INT CONF S, P172, DOI 10.1109/ICSM.2002.1167764; Finnigan PJ, 1997, IBM SYST J, V36, P564; Fioravanti F., 2001, Proceedings Fifth European Conference on Software Maintenance and Reengineering, DOI 10.1109/CSMR.2001.914976; Godfrey M.W., 2000, P 2 INT S CONSTR SOF, P15; Hosmer DW, 1989, APPL LOGISTIC REGRES; Neter J., 1990, APPL LINEAR STAT MOD; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; REIS CR, 2002, P WORKSH OP SOURC SO, P155; Subramanyam R, 2003, IEEE T SOFTWARE ENG, V29, P297, DOI 10.1109/TSE.2003.1191795; Yu P., 2002, P 6 EUR C SOFTW MAIN, P99; 2005, MOZILLA HOMEPAGE	20	149	156	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0098-5589		IEEE T SOFTWARE ENG	IEEE Trans. Softw. Eng.	OCT	2005	31	10					897	910		10.1109/TSE.2005.112		14	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	980JR	WOS:000233015300008	
J	Cantu-Paz, E; Kamath, C				Cantu-Paz, E; Kamath, C			An empirical comparison of combinations of evolutionary algorithms and neural networks for classification problems	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						classification; evolutionary algorithms; feature election; machine learning; network design; training algorithms	FEATURE SUBSET-SELECTION; LEARNING ALGORITHMS; GENETIC ALGORITHMS; OPTIMIZATION	There are numerous combinations of neural networks (NNs) and evolutionary algorithms (EAs) used in classification problems. EAs have been used to train the networks, design their architecture, and select feature subsets. However, most of these combinations have been tested on only a few data sets and many comparisons are done inappropriately measuring the performance in training data or without using proper statistical tests to support the conclusions. This paper presents an empirical evaluation of light combinations of EAs and NNs on 15 public-domain and artificial data sets. Our objective is to identify the methods that consistently produce accurate classifiers that generalize well. In most cases, the combinations of EAs and NNs perform equally well on the data sets we tried and were not more accurate than hand-designed neural networks trained with simple backpropagation.	Lawrence Livermore Natl Lab, Ctr Appl Sci Comp, Livermore, CA 94605 USA	Cantu-Paz, E (reprint author), Lawrence Livermore Natl Lab, Ctr Appl Sci Comp, Livermore, CA 94605 USA.	cantupaz@acm.org; kamath2@llnl.gov					Alpaydin E, 1999, NEURAL COMPUT, V11, P1885, DOI 10.1162/089976699300016007; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Back T., 1996, EVOLUTIONARY ALGORIT; BALASHOV YA, 1996, PETROLOGY+, V4, P3; Belew R.K., 1991, P 2 ART LIF C, P511; Blake C. L., 1998, UCI REPOSITORY MACHI; BOERS JW, 1992, BIOL METAPHORS DESIG; Bransen J, 1995, PROCEEDINGS OF THE EIGHTH INTERNATIONAL KANT CONGRESS, VOL II, PT 1, SECT 1-9, P145; BRILL FZ, 1990, IPCTR90004 U VIRG I; BROTHERTON TW, 1995, EVOLUTIONARY PROGRAM, V4, P83; CANTUPAZ E, 2002, P GEN EV COMP C SAN, P303; Cantu-Paz E, 2003, NEURAL NETWORKS, V16, P507, DOI 10.1016/S0893-6080(03)00020-0; Cantu-Paz E, 2003, LECT NOTES COMPUT SC, V2723, P790; Cantu-Paz E., 2000, P GEN EV COMP C GECC, P1053; CASTILLO PA, 2002, P 7 WORLD C SOFT COM; CAUDELL TP, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P370; Deb K, 2002, EVOL COMPUT, V10, P371, DOI 10.1162/106365602760972767; DIETTERICH TG, 1998, NEURAL COMPUT, V10, P7; FOGEL DB, 1990, BIOL CYBERN, V63, P487, DOI 10.1007/BF00199581; Goldberg DE, 1989, GENETIC ALGORITHMS S; Goldberg D. E., 1999, Proceedings of International Workshop on Soft Computing in Industry '99 (IWSCI'99); GRONROSS MA, 1998, THESIS U TURKU TURKU; Gruau F, 1992, P INT WORKSH COMB GE, P55, DOI 10.1109/COGANN.1992.273948; Gruau F, 1993, EVOL COMPUT, V1, P213, DOI 10.1162/evco.1993.1.3.213; HANCOCK PJB, 1992, PARALLEL PROBLEM SOL, V2, P441; HANCOCK PJB, 1992, P 1992 INT C ART NEU, V2, P991; Harik G, 1999, EVOL COMPUT, V7, P231, DOI 10.1162/evco.1999.7.3.231; hierens D., 1995, THESIS KATHOLIEKE U; Houck CR, 1997, EVOL COMPUT, V5, P31, DOI 10.1162/evco.1997.5.1.31; Inza I, 2000, ARTIF INTELL, V123, P157, DOI 10.1016/S0004-3702(00)00052-7; JULSTROM BA, 1999, P C EV COMP GEN EV C, P134; KADABA N, 1990, P 7 INT C MACH LEARN, P140; Kelly J. D. J., 1991, P 4 INT C GEN ALG TH, P377; KITANO H, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P789; Kitano H., 1990, Complex Systems, V4; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Ku KWC, 1997, PROCEEDINGS OF 1997 IEEE INTERNATIONAL CONFERENCE ON EVOLUTIONARY COMPUTATION (ICEC '97), P617, DOI 10.1109/ICEC.1997.592386; LEBARON B, 1997, EVOLUTIONARY BOOTSTR; Marshall S.J., 1991, P IEE 2 INT C ART NE, P39; Matsumoto M., 1998, ACM T MODEL COMPUT S, V8, P3; MILLER GF, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P379; Montana D., 1989, P 11 INT JOINT C ART, P762; Muhlenbein H., 1992, PARALLEL PROBLEM SOL, P15; NOLF P, 1905, ARCH INT PHYSL, V3, P1; Opitz D., 1999, J ARTIFICIAL INTELLI, P169; OZDEMIR M, 2001, P IEEE MOUNT WORKSH, P53; Prechelt L, 1996, NEURAL NETWORKS, V9, P457, DOI 10.1016/0893-6080(95)00123-9; PUNCH WF, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P557; Radcliffe N. J., 1990, THESIS U EDINBURGH E; REED R, 1993, IEEE T NEURAL NETWOR, V4, P740, DOI 10.1109/72.248452; Reunanen J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753715; ROBERTS SG, 1995, P INT C GEN ALG NEUR, P96; Schaffer JD, 1992, P INT WORKSH COMB GE, P1, DOI 10.1109/COGANN.1992.273950; SIDDIQI A, 1998, P 1998 IEEE INT C EV, P392; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; SKINNER AJ, 1995, MODEL SIMUL MATER SC, V3, P371, DOI 10.1088/0965-0393/3/3/006; Thierens D., 1991, P C NEUR NETS GEN AL, P658; Vafaie H., 1993, Proceedings. Fifth International Conference on Tools with Artificial Intelligence TAI '93 (Cat. No.93CH3325-8), DOI 10.1109/TAI.1993.633981; WHITLEY D, 1990, PARALLEL COMPUT, V14, P347, DOI 10.1016/0167-8191(90)90086-O; WHITLEY D, 1989, CS89113 COL STAT U D; WHITLEY D, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P391; Whitley D. L., 1994, PARALLEL PROBLEM SOL, VIII, P6; Yang JH, 1998, IEEE INTELL SYST APP, V13, P44, DOI 10.1109/5254.671091; YAO X, 2000, P 1 IEEE S COMB EV A; Yao X, 1999, P IEEE, V87, P1423	65	43	43	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	OCT	2005	35	5					915	927		10.1109/TSMCB.2005.847740		13	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	971KZ	WOS:000232384200006	
J	Tran, QL; Toh, KA; Srinivasan, D; Wong, KL; Low, SQC				Tran, QL; Toh, KA; Srinivasan, D; Wong, KL; Low, SQC			An empirical comparison of nine pattern classifiers	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						hyperbolic functions; machine learning; parameter estimation; pattern classification; polynomials	NETWORKS	There are many learning algorithms available in the field of pattern classification and people are still discovering new algorithms that they hope will work better. Any new learning algorithm, beside its theoretical foundation, needs to be justified in many aspects including accuracy and efficiency when applied to real life problems. In this paper, we report the empirical comparison of a recent algorithm RM, its new extensions and free classical, classifiers in different aspects including classification accuracy, computational time and storage requirement. The comparison is performed in a standardized way and we believe that this would give a good sight into the algorithm RM and its extension. The experiments also show at nominal attributes do have an impact on the performance of those compared learning algorithms.	Inst Infocomm Res, Singapore 119613, Singapore; Natl Univ Singapore, Singapore 119260, Singapore	Tran, QL (reprint author), Inst Infocomm Res, Singapore 119613, Singapore.	katoh@ieee.org; dipti@nus.edu.sg					Bishop C.M., 1995, NEURAL NETWORKS PATT; Blake C. L., 1998, UCI REPOSITORY MACHI; CHEN S, 1991, IEEE T NEURAL NETWOR, V2, P302, DOI 10.1109/72.80341; Duda R. O., 2001, PATTERN CLASSIFICATI; Haykin S., 1999, NEURAL NETWORKS COMP; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; HU YH, NEAREST NEIGHBOR CLA; KRESSEL U, 1999, ADV KERNEL METHODS S, pCH15; Ma J., OSU SVM CLASSIFIER M; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Schurmann J., 1996, PATTERN CLASSIFICATI; Smola Alex, 2002, LEARNING KERNELS; Soares C, 2004, MACH LEARN, V54, P195, DOI 10.1023/B:MACH.0000015879.28004.9b; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Toh K.-A., 2003, Proceedings 12th International Conference on Image Analysis and Processing; Toh KA, 2004, IEEE T PATTERN ANAL, V26, P740, DOI 10.1109/TPAMI.2004.3; Toh KA, 2004, IEEE T SYST MAN CY B, V34, P1196, DOI 10.1109/TSMCB.2003.821868; TORN A, 1989, LECT NOTES COMPUT SC, V350, P1; Vapnik VN, 1998, STAT LEARNING THEORY	19	8	8	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	OCT	2005	35	5					1079	1091		10.1109/TSMCB.2005.847745		13	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	971KZ	WOS:000232384200019	
J	Toyomura, A; Omori, T				Toyomura, A; Omori, T			A computational model for taxonomy-based word learning inspired by infant developmental word acquisition	IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS			English	Article						word acquisition; shape bias; taxonomic bias; human interface; neural network; PATON	CONSTRAINTS; SHAPE	To develop human interfaces such as home information equipment, highly capable word learning ability is required. In particular, in order to realize user-customized and situation-dependent interaction using language, a function is needed that can build new categories online in response to presented objects for an advanced human interface. However, at present, there are few basic studies focusing on the purpose of language acquisition with category formation. In this study, taking hints from an analogy between machine learning and infant developmental word acquisition, we propose a taxonomy-based word-learning model using a neural network. Through computer simulations, we show that our model can build categories and find the name of an object based on categorization.	Hokkaido Univ, Grad Sch Engn, Sapporo, Hokkaido 0608628, Japan; Hokkaido Univ, Grad Sch Informat Sci & Technol, Sapporo, Hokkaido 0600814, Japan	Toyomura, A (reprint author), Hokkaido Univ, Grad Sch Engn, Sapporo, Hokkaido 0608628, Japan.	toyo@complex.eng.hokudai.ac.jp					BARSALOU LW, 1983, MEM COGNITION, V11, P211, DOI 10.3758/BF03196968; ELMAN JL, 1993, COGNITION, V48, P171; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1016/0364-0213(90)90002-E; IMAI M, 1994, COGNITIVE DEV, V9, P45, DOI 10.1016/0885-2014(94)90019-1; LANDAU B, 1988, COGNITIVE DEV, V3, P299, DOI 10.1016/0885-2014(88)90014-7; MARKMAN EM, 1990, COGNITIVE SCI, V14, P57, DOI 10.1207/s15516709cog1401_4; MARKMAN EM, 1984, COGNITIVE PSYCHOL, V16, P1, DOI 10.1016/0010-0285(84)90002-1; OMORI T, 1996, BRAIN PROCESSES THEO, P134; OMORI T, 1999, 2 C COGN SCI, V99, P189; Omori T, 1999, NEURAL NETWORKS, V12, P1157, DOI 10.1016/S0893-6080(99)00054-4; OMORI T, 1994, P INT C NEURAL NETWO, V94, P2227; Price CJ, 2002, TRENDS COGN SCI, V6, P416, DOI 10.1016/S1364-6613(02)01976-9; SHIMOTOMAI T, 2002, P 9 INT C NEUR INF P, P1236, DOI 10.1109/ICONIP.2002.1202818; TOMASELLO M, 2001, LANGUAGE DEV	14	2	2	IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG	TOKYO	KIKAI-SHINKO-KAIKAN BLDG MINATO-KU SHIBAKOEN 3 CHOME, TOKYO, 105, JAPAN	0916-8532		IEICE T INF SYST	IEICE Trans. Inf. Syst.	OCT	2005	E88D	10					2389	2398		10.1093/ietisy/e88-d.10.2389		10	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	977YR	WOS:000232839900017	
J	Zhao, Y; Karypis, G				Zhao, Y; Karypis, G			Prediction of contact maps using support vector machines	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS			English	Article						contact map prediction; correlated mutation analysis; support vector machines	PROTEIN STABILITY; NONLOCAL INTERACTIONS; CORRELATED MUTATIONS; GENOMIC SEQUENCES; FOLD RECOGNITION; NEURAL NETWORKS; DATABASE; CLASSIFICATION; RESIDUES; BARNASE	Contact map prediction is of great interest for its application in fold recognition and protein 3D structure determination. In this paper we present a contact-map prediction algorithm that employs Support Vector Machines as the machine learning tool and incorporates various features such as sequence profile and their conservations, correlated mutation analysis based on various amino acid physicochemical properties, and secondary structure. In addition, we evaluated the effectiveness of the different features on contact map prediction for different fold classes. On average, our predictor achieved a prediction accuracy of 0.224 with an improvement over a random predictor of a factor 11.7, which is better than reported studies. Our study showed that predicted secondary structure features play an important roles for the proteins containing beta-structures. Models based on secondary structure features and correlated mutation analysis features produce different sets of predictions. Our study also suggests that models learned separately for different protein fold families may achieve better performance than a unified model.	Univ Minnesota, Dept Comp Sci, Minneapolis, MN 55455 USA	Zhao, Y (reprint author), Univ Minnesota, Dept Comp Sci, Minneapolis, MN 55455 USA.	yxhao@cs.umn.edu; karypis@cs.umn.edu					ABKEVICH VI, 1995, J MOL BIOL, V252, P460, DOI 10.1006/jmbi.1995.0511; Benson DA, 2000, NUCLEIC ACIDS RES, V28, P15, DOI 10.1093/nar/28.1.15; Berman HM, 2000, NAT STRUCT BIOL, V7, P957, DOI 10.1038/80734; Dumais S, 1998, IEEE INTELLIGENT SYS, V13; Fariselli P, 2001, PROTEINS, P157; Fariselli P, 2001, PROTEIN ENG, V14, P835, DOI 10.1093/protein/14.11.835; SERRANO L, 1992, J MOL BIOL, V224, P783, DOI 10.1016/0022-2836(92)90562-X; FERSHT AR, 1992, J MOL BIOL, V224, P771, DOI 10.1016/0022-2836(92)90561-W; Gilis D, 1997, J MOL BIOL, V272, P276, DOI 10.1006/jmbi.1997.1237; Hua SJ, 2001, J MOL BIOL, V308, P397, DOI 10.1006/jmbi.2001.4580; Joachims T., 1999, ADV KERNEL METHODS S; Jones DT, 1999, J MOL BIOL, V287, P797, DOI 10.1006/jmbi.1999.2583; Kawashima S, 1999, NUCLEIC ACIDS RES, V27, P368, DOI 10.1093/nar/27.1.368; KELLIS JT, 1988, NATURE, V333, P784, DOI 10.1038/333784a0; MCLACHLA.AD, 1971, J MOL BIOL, V61, P409, DOI 10.1016/0022-2836(71)90390-1; Munoz V, 1996, FOLD DES, V1, pR71, DOI 10.1016/S1359-0278(96)00036-3; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; Niggemann M, 2000, J MOL BIOL, V296, P181, DOI 10.1006/jmbi.1999.3385; Olmea O, 1999, J MOL BIOL, V293, P1221, DOI 10.1006/jmbi.1999.3208; Orengo CA, 1997, STRUCTURE, V5, P1093, DOI 10.1016/S0969-2126(97)00260-8; Pearl FMG, 2000, NUCLEIC ACIDS RES, V28, P277, DOI 10.1093/nar/28.1.277; Pollastri G, 2002, Bioinformatics, V18 Suppl 1, pS62; Pollock DD, 1999, J MOL BIOL, V287, P187, DOI 10.1006/jmbi.1998.2601; Pollock DD, 1997, PROTEIN ENG, V10, P647, DOI 10.1093/protein/10.6.647; PREVOST M, 1991, P NATL ACAD SCI USA, V88, P10880, DOI 10.1073/pnas.88.23.10880; PRITCHARD P, 2001, PROTEIN ENG, V14, P549; REVA B, 2000, P PAC S BIOC, P165; Thomas DJ, 1996, PROTEIN ENG, V9, P941, DOI 10.1093/protein/9.11.941; THOMPSON JD, 1994, NUCLEIC ACIDS RES, V22, P4673, DOI 10.1093/nar/22.22.4673; Vapnik VN, 1998, STAT LEARNING THEORY; Vendruscolo M, 1997, FOLD DES, V2, P295, DOI 10.1016/S1359-0278(97)00041-2; Zaki M. J., 2000, Proceedings IEEE International Symposium on Bio-Informatics and Biomedical Engineering, DOI 10.1109/BIBE.2000.889604	32	2	2	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-2130		INT J ARTIF INTELL T	Int. J. Artif. Intell. Tools	OCT	2005	14	5					849	865		10.1142/S0218213005002429		17	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	986SI	WOS:000233469600010	
J	Goldbaum, MH; Sample, PA; Zhang, ZH; Chan, KL; Hao, JC; Lee, TW; Boden, C; Bowd, C; Bourne, R; Zangwill, L; Sejnowski, T; Spinak, D; Weinreb, RN				Goldbaum, MH; Sample, PA; Zhang, ZH; Chan, KL; Hao, JC; Lee, TW; Boden, C; Bowd, C; Bourne, R; Zangwill, L; Sejnowski, T; Spinak, D; Weinreb, RN			Using unsupervised learning with independent component analysis to identify patterns of glaucomatous visual field defects	INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE			English	Article							NEURAL NETWORKS; AUTOMATED PERIMETRY; CLASSIFICATION; CLASSIFIERS; MIXTURE	PURPOSE. Clustering by unsupervised learning with machine learning classifiers was shown to segment clusters of patterns in standard automated perimetry (SAP) for glaucoma in previous publications. In this study, unsupervised learning by independent component analysis decomposed SAP field patterns into axes, and the information represented by these axes was evaluated. METHODS. SAP fields were used that were obtained with the Humphrey Visual Field Analyzer (Carl Zeiss Meditec, Dublin, CA) from 189 normal eyes and 156 eyes with glaucomatous optic neuropathy (GON) determined by masked review with stereoscopic optic disc photographs. The variational Bayesian independent component analysis mixture model (vB-ICA-mm) partitioned the SAP fields into the most informative number of clusters. Simultaneously, the model learned an optimal number of maximally independent axes for each cluster. RESULTS. The most informative number of clusters in the SAP set was two. vB-ICA-mm placed 68.6% of the eyes with GON in a cluster labeled G and 98.4% of the eyes with normal optic discs in a cluster labeled N. Cluster G optimally contained six axes. Post hoc analysis of patterns generated at -1 SD and -2 SD from the cluster G mean on the six axes revealed defects similar to those identified by experts as indicative of glaucoma. SAP fields associated with an axis showed increasing severity, as they were located farther in the positive direction from the cluster G mean. CONCLUSIONS. vB-ICA-mm represented the SAP fields with patterns that were meaningful for glaucoma experts. This process also captured severity in the patterns uncovered. These findings should validate vB-ICA-mm as a data-mining technique for new and unfamiliar complex tests.	Univ Calif San Diego, Dept Ophthalmol, Hamilton Glaucoma Ctr, La Jolla, CA 92093 USA; Univ Calif San Diego, Ophthalm Informat Lab, La Jolla, CA 92093 USA; Univ Calif San Diego, Inst Neural Computat, La Jolla, CA 92093 USA; Vet Adm San Diego Hlth Serv, San Diego, CA USA; Salk Inst Biol Studies, Computat Neurobiol Lab, La Jolla, CA USA	Goldbaum, MH (reprint author), Univ Calif San Diego, Dept Ophthalmol, Hamilton Glaucoma Ctr, 9500 Gilman Dr, La Jolla, CA 92093 USA.	mgoldbaum@ucsd.edu	Hao, Jiucang/G-7017-2012				BICKLERBLUTH M, 1989, OPHTHALMOLOGY, V96, P616; Bjerrum J, 1889, NORD OPHTHALMOL TSKR, V2, P141; Bowd C, 2002, INVEST OPHTH VIS SCI, V43, P3444; Brigatti L, 1996, AM J OPHTHALMOL, V121, P511; Chan K., 2002, J MACHINE LEARNING R, V3, P99; Goldbaum MH, 2002, INVEST OPHTH VIS SCI, V43, P162; GOLDBAUM MH, 1994, INVEST OPHTH VIS SCI, V35, P3362; Henson DB, 1996, BRIT J OPHTHALMOL, V80, P526, DOI 10.1136/bjo.80.6.526; Hyvarinen A., 2001, INDEPENDENT COMPONEN; Lee TW, 2000, IEEE T PATTERN ANAL, V22, P1078; MACKAY DJC, 1995, NETWORK-COMP NEURAL, V6, P469, DOI 10.1088/0954-898X/6/3/011; Sample PA, 2004, INVEST OPHTH VIS SCI, V45, P2596, DOI 10.1167/iovs.03-0343; Sample PA, 2002, INVEST OPHTH VIS SCI, V43, P2660; Sample PA, 2005, INVEST OPHTH VIS SCI, V46, P3684, DOI 10.1167/iovs.04-1168; SAMPLE PA, 2003, INVEST OPHTH VIS SCI, V44, P1813; VONGRAEFE A, 1856, GRAEFES ARCH OPHTHAL, V2, P258	16	11	11	ASSOC RESEARCH VISION OPHTHALMOLOGY INC	ROCKVILLE	12300 TWINBROOK PARKWAY, ROCKVILLE, MD 20852-1606 USA	0146-0404		INVEST OPHTH VIS SCI	Invest. Ophthalmol. Vis. Sci.	OCT	2005	46	10					3676	3683		10.1167/iovs.04-1167		8	Ophthalmology	Ophthalmology	967TA	WOS:000232112900030	
J	Sample, PA; Boden, C; Zhang, ZH; Pascual, J; Lee, TW; Zangwill, LM; Weinreb, RN; Crowston, JG; Hoffmann, EM; Medeiros, FA; Sejnowski, T; Goldbaum, M				Sample, PA; Boden, C; Zhang, ZH; Pascual, J; Lee, TW; Zangwill, LM; Weinreb, RN; Crowston, JG; Hoffmann, EM; Medeiros, FA; Sejnowski, T; Goldbaum, M			Unsupervised machine learning with independent component analysis to identify areas of progression in glaucomatous visual fields	INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE			English	Article							OCULAR HYPERTENSION TREATMENT; OPEN-ANGLE GLAUCOMA; INTRAOCULAR-PRESSURE; MEDICATION DELAYS; PREVENTS; TRIAL; ONSET; TERM	PURPOSE. To determine whether a variational Bayesian independent component analysis mixture model (vB-ICA-mm), a form of unsupervised machine learning, can be used to identify and quantify areas of progression in standard automated perimetry fields. METHODS. In an earlier study, it was shown that a model using vB-ICA-mm can separate normal fields from fields with six different patterns of visual field loss related to glaucomatous optic neuropathy (GON) along maximally independent axes. In the present study, an independent group of 191 patient eyes (66 with ocular hypertension (OHT), 12 with suspected glaucoma by field, 61 with suspected glaucoma by disc, and 52 with glaucoma) with five or more standard visual fields under observation for a mean of 6.24 +/- 2.65 years and 8.11 +/- 2.42 visual fields were evaluated with the vB-ICA-mm. In addition, eyes with progressive GON (PGON) were identified (n = 39). Each participant had a series of fields tested, with each field entered independently and placed along the axes of the previously developed model. This allowed change in one pattern of visual field defect (along one axis) to be assessed relative to results other areas of that same field (no change along other axes). Progression was based on a slope falling outside the 5th and the 95th percentile limits of all slopes, with at least two axes not showing such a deviation in a given individual's series of fields. Fields were also scored using Advanced Glaucoma Intervention Study (AGIS) and the Early Manifest Glaucoma Treatment Trial (EMGT) criteria. RESULTS. Thirty-two of 191 eyes progressed on vB-ICA-mm by this definition. Of the 32, 22 had field loss at baseline, 7 had only GON, 3 were OHTs and 12 were from the 39 eyes (31%) with PGON. The vB-ICA-mm identified a higher percentage of progressing eyes in each diagnostic category than did AGIS or and the EMGT. CONCLUSIONS. The vB-ICA-mm can quantitatively identify progression in eyes with glaucoma by evaluating change in one or more patterns of the visual field loss while other areas or patterns remain stable. This may enable each eye to contribute to the determination of whether change is caused by true progression or by variability.	Univ Calif San Diego, Dept Ophthalmol, Inst Neural Computat, La Jolla, CA 92093 USA; Univ Calif San Diego, Visual Funct Lab, La Jolla, CA 92093 USA; Univ Calif San Diego, Ophthalm Informat Lab, La Jolla, CA 92093 USA; Univ Calif San Diego, Hamilton Glaucoma Ctr, La Jolla, CA 92093 USA; Salk Inst Biol Studies, La Jolla, CA USA	Sample, PA (reprint author), Univ Calif San Diego, Dept Ophthalmol, Inst Neural Computat, 9500 Gilman Dr, La Jolla, CA 92093 USA.	psample@glaucoma.ucsd.edu					Kass MA, 2000, AM J OPHTHALMOL, V130, P490, DOI 10.1016/S0002-9394(00)00658-9; Birch MK, 1995, OPHTHALMOLOGY, V102, P1234; BIRCH MK, 1995, OPHTHALMOLOGY, V102, P1227; Boden C, 2004, AM J OPHTHALMOL, V138, P1029, DOI 10.1016/j.ajo.2004.07.003; Brigatti L, 1997, ARCH OPHTHALMOL-CHIC, V115, P725; FLAMMER J, 1984, ARCH OPHTHALMOL-CHIC, V102, P704; Goldbaum MH, 2005, INVEST OPHTH VIS SCI, V46, P3676, DOI 10.1167/iovs.04-1167; HEIJL A, 1991, PERIMETRY UPDATE 1990/1991, P303; Heijl A, 2002, ARCH OPHTHALMOL-CHIC, V120, P1268; Henson DB, 1996, BRIT J OPHTHALMOL, V80, P526, DOI 10.1136/bjo.80.6.526; Henson DB, 1997, ARTIF INTELL MED, V10, P99, DOI 10.1016/S0933-3657(97)00388-6; Higginbotham EJ, 2004, ARCH OPHTHALMOL-CHIC, V122, P813, DOI 10.1001/archopht.122.6.813; Kass MA, 2002, ARCH OPHTHALMOL-CHIC, V120, P701; Katz J, 1999, ARCH OPHTHALMOL-CHIC, V117, P1137; Lee AC, 2002, OPHTHALMOLOGY, V109, P1059, DOI 10.1016/S0161-6420(02)01043-6; Leske MC, 2003, ARCH OPHTHALMOL-CHIC, V121, P48; MIKELBERG FS, 1984, AM J OPHTHALMOL, V98, P443, DOI 10.1016/0002-9394(84)90128-4; Musch DC, 1999, OPHTHALMOLOGY, V106, P653, DOI 10.1016/S0161-6420(99)90147-1; Nouri-Mahdavi K, 2004, OPHTHALMOLOGY, V111, P1627, DOI 10.1016/j.ophtha.2004.02.017; Robin AL, 2004, ARCH OPHTHALMOL-CHIC, V122, P376, DOI 10.1001/archopht.122.3.376; Spry PGD, 2002, SURV OPHTHALMOL, V47, P158, DOI 10.1016/S0039-6257(01)00299-5; Vesti E, 2003, INVEST OPHTH VIS SCI, V44, P3873, DOI 10.1167/iovs.02-1171; WILD JM, 1991, ACTA OPHTHALMOL, V69, P210	23	15	15	ASSOC RESEARCH VISION OPHTHALMOLOGY INC	ROCKVILLE	12300 TWINBROOK PARKWAY, ROCKVILLE, MD 20852-1606 USA	0146-0404		INVEST OPHTH VIS SCI	Invest. Ophthalmol. Vis. Sci.	OCT	2005	46	10					3684	3692		10.1167/iovs.04-1168		9	Ophthalmology	Ophthalmology	967TA	WOS:000232112900031	
J	Ohno-Machado, L				Ohno-Machado, L			Clinical machine learning	JOURNAL OF BIOMEDICAL INFORMATICS			English	Editorial Material									Harvard Univ, MIT, Brigham & Womens Hosp, Div Hlth Sci & Technol,Dept Radiol,Decis Syst Grp, Boston, MA 02115 USA	Ohno-Machado, L (reprint author), Harvard Univ, MIT, Brigham & Womens Hosp, Div Hlth Sci & Technol,Dept Radiol,Decis Syst Grp, Boston, MA 02115 USA.	machado@dsg.bwh.harvard.edu					Blanco R, 2005, J BIOMED INFORM, V38, P376, DOI 10.1016/j.jbi.2005.05.004; Cooper GF, 2005, J BIOMED INFORM, V38, P347, DOI 10.1016/j.jbi.2005.02.005; DRIESEITL S, 2005, J BIOMED INFORM, V38, P389; Lasko TA, 2005, J BIOMED INFORM, V38, P404, DOI 10.1016/j.jbi.2005.02.008; Matheny ME, 2005, J BIOMED INFORM, V38, P367, DOI 10.1016/j.jbi.2005.02.007; Zou KH, 2005, J BIOMED INFORM, V38, P395, DOI 10.1016/j.jbi.2005.02.004	6	0	0	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464		J BIOMED INFORM	J. Biomed. Inform.	OCT	2005	38	5					345	346		10.1016/j.jbi.2005.05.009		2	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	976MV	WOS:000232738600001	
J	Cooper, GF; Abraham, V; Aliferis, CF; Aronis, JM; Buchanan, BG; Caruana, R; Fine, MJ; Janosky, JE; Livingston, G; Mitchell, T; Monti, S; Spirtes, P				Cooper, GF; Abraham, V; Aliferis, CF; Aronis, JM; Buchanan, BG; Caruana, R; Fine, MJ; Janosky, JE; Livingston, G; Mitchell, T; Monti, S; Spirtes, P			Predicting dire outcomes of patients with community acquired pneumonia	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						machine learning; community acquired pneumonia; outcome prediction; quality and cost of healthcare delivery	LIKELIHOOD; SELECTION; COST	Comm unity-acquired pneumonia (CAP) is an important clinical condition with regard to patient mortality, patient morbidity, and healthcare resource utilization. The assessment of the likely clinical course of a CAP patient can significantly influence decision making about whether to treat the patient as an inpatient or as an outpatient. That decision can in turn influence resource utilization, as well as patient well being. Predicting dire outcomes, such as mortality or severe clinical complications, is a particularly important component in assessing the clinical course of patients. We used a training set of 1601 CAP patient cases to construct 11 statistical and machine-learning models that predict dire outcomes. We evaluated the resulting models on 686 additional CAP-patient cases. The primary goal was not to compare these learning algorithms as a study end point; rather, it was to develop the best model possible to predict dire outcomes. A special version of an artificial neural network (NN) model predicted dire outcomes the best. Using the 686 test cases, we estimated the expected healthcare quality and cost impact of applying the NN model in practice. The particular, quantitative results of this analysis are based on a number of assumptions that we make explicit; they will require further study and validation. Nonetheless, the general implication of the analysis seems robust, namely, that even small improvements in predictive performance for prevalent and costly diseases, such as CAP, are likely to result in significant improvements in the quality and efficiency of healthcare delivery. Therefore, seeking models with the highest possible level of predictive performance is important. Consequently, seeking ever better machine-learning and statistical modeling methods is of great practical significance. (c) 2005 Elsevier Inc. All rights reserved.	Univ Pittsburgh, Ctr Biomed Informat, Pittsburgh, PA 15213 USA; Stanford Univ, Meyler Lib 260, Stanford, CA 94305 USA; Vanderbilt Univ, Dept Biomed Informat, Eskind Lib 412, Nashville, TN 37232 USA; Univ Pittsburgh, Dept Comp Sci, Pittsburgh, PA 15260 USA; Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA; Univ Pittsburgh, VA Pittsburgh Healthcare Syst, Ctr Hlth Equ Res & Promot, Pittsburgh, PA 15240 USA; Univ Pittsburgh, Dept Family Med & Clin Epidemiol, Pittsburgh, PA 15261 USA; Univ Massachusetts, Dept Comp Sci, Lowell, MA 01854 USA; Carnegie Mellon Univ, Ctr Automated Learning & Discovery, Pittsburgh, PA 15213 USA; MIT, Broad Inst, Cambridge, MA 02141 USA; Harvard Univ, Cambridge, MA 02141 USA; Carnegie Mellon Univ, Dept Philosophy, Pittsburgh, PA 15213 USA	Cooper, GF (reprint author), Univ Pittsburgh, Ctr Biomed Informat, Suite 8084 Forber Tower,200 Lothrop St, Pittsburgh, PA 15213 USA.	gfc@cbmi.pitt.edu					ABUMOSTAFA YS, 1989, J COMPLEXITY, P192; ADAMS P, 1995, CURRENT ESTIMATES NA, V10, P1; Afifi A.A., 1990, COMPUTER AIDED MULTI; Caruana R, 1996, ADV NEUR IN, V8, P959; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Cheeseman P., 1996, ADV KNOWLEDGE DISCOV; Chickering DM, 1997, MACH LEARN, V29, P181; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DIXON WJ, 1992, BMDO STAT SOFTWARE M, P1136; Fine MJ, 1997, NEW ENGL J MED, V336, P243, DOI 10.1056/NEJM199701233360402; GRAVES EJ, 1996, SUMMARY NATL HOSP DI; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; HANLEY JA, 1982, RADIOLOGY, V143, P29; HANLEY JA, 1983, RADIOLOGY, V148, P839; KAPOOR WN, 1996, ASSESSMENT VARIATION; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; KONTKANEN P, 1997, NCTR97003; KONTKANEN P, 1997, P CAUS MOD STAT LEAR, P103; LANGLEY P, 1994, P 10 C UNC ART INT, P399; Langley P., 1992, P 10 NAT C ART INT, P223; Lave JR, 1999, SEM RESP CRIT CARE M, V20, P189, DOI 10.1055/s-2007-1021315; LIVINGSTON GR, 2001, THESIS U PITTSBURGH; Marrie TJ, 2000, JAMA-J AM MED ASSOC, V283, P749, DOI 10.1001/jama.283.6.749; MCLACHLAN GJ, 1997, EM ALGORITHM EXTENIO; MONTI S, 1999, P 15 C UNC ART INT S, P447; Niederman MS, 1998, CLIN THER, V20, P820, DOI 10.1016/S0149-2918(98)80144-6; PROVOST FJ, 1992, THESIS U PITTSBURGH; PROVOST FJ, 1995, MACH LEARN, V20, P35, DOI 10.1007/BF00993474; Russell S., 2002, ARTIFICIAL INTELLIGE; SOX HC, 1988, MED DECISION MAKIN; SUDDARTH SC, 1991, INT J MAN MACH STUD, V35, P291, DOI 10.1016/S0020-7373(05)80130-0; Weinstein M. C., 1980, CLIN DECISION ANAL; 1995, MMWR, V44, P5335; 1995, PHYS, V10, P1528	34	5	5	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464		J BIOMED INFORM	J. Biomed. Inform.	OCT	2005	38	5					347	366		10.1016/j.jbi.2005.02.005		20	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	976MV	WOS:000232738600002	
J	Blanco, R; Inza, M; Merino, M; Quiroga, J; Larranaga, P				Blanco, R; Inza, M; Merino, M; Quiroga, J; Larranaga, P			Feature selection in Bayesian classifiers for the prognosis of survival of cirrhotic patients treated with TIPS	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						Bayesian classification models; filter approach; wrapper approach; transjugular intrahepatic portosystemic shunt; survival prediction	MACHINE-LEARNING-METHODS; FEATURE SUBSET-SELECTION; ESOPHAGEAL-VARICES; DIAGNOSIS; MORTALITY	The transjugular intrahepatic portosystemic shunt (TIPS) is a treatment for cirrhotic patients with portal hypertension. A subgroup of patients dies in the first 6 months and another subgroup lives a long period of time. Nowadays, no risk factors have been identified in order to determine how long a patient will survive. An empirical study for predicting the survival rate within the first 6 months after TIPS placement is conducted using a clinical database with 107 cases and 77 variables. Applications of Bayesian classification models, based on Bayesian networks, to medical problems have become popular in the last years. Feature subset selection is useful due to the heterogeneity of the medical databases where not all the variables are required to perform the classification. In this paper, filter and wrapper approaches based on the feature subset selection are adapted to induce Bayesian classifiers (naive Bayes, selective naive Bayes, semi naive Bayes, tree augmented naive Bayes, and k-dependence Bayesian classifier) and are applied to distinguish between the two subgroups of cirrhotic patients. The estimated accuracies obtained tally with the results of previous studies. Moreover, the medical significance of the subset of variables selected by the classifiers along with the comprehensibility of Bayesian models is greatly appreciated by physicians. (c) 2005 Elsevier Inc. All rights reserved.	Univ Basque Country, Dept Comp Sci & Artificial Intelligence, E-20080 San Sebastian, Spain; Basque Hlth Serv Osakidetza, E-20013 San Sebastian, Spain; Univ Navarra Clin, Fac Med, E-31080 Pamplona, Spain	Blanco, R (reprint author), Univ Basque Country, Dept Comp Sci & Artificial Intelligence, POB 649, E-20080 San Sebastian, Spain.	rosa@si.ehu.es	Larranaga, Pedro/F-9293-2013				BAILEY NTJ, 1964, MATH COMPUTER SCI BI, P103; BAYES T, 1764, ESSAY SOLVING PROBLE; BORNMAN PC, 1994, LANCET, V343, P1079, DOI 10.1016/S0140-6736(94)90186-4; Brier G.W., 1950, MONTHLY WEATHER REVI, V78, P1, DOI DOI 10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2; Castillo E., 1997, EXPERT SYSTEMS PROBA; CATTLET J, 1999, P EUR WORK SESS LEAR, P164; Chalasani N, 2000, GASTROENTEROLOGY, V118, P138, DOI 10.1016/S0016-5085(00)70422-7; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; Cios KJ, 2002, ARTIF INTELL MED, V26, P1, DOI 10.1016/S0933-3657(02)00049-0; CONN HO, 1981, HEPATOLOGY, V1, P1; Cooper GF, 1997, ARTIF INTELL MED, V9, P107, DOI 10.1016/S0933-3657(96)00367-3; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Draper D, 2000, J GLOBAL OPTIM, V18, P399, DOI 10.1023/A:1026504402220; Dreiseitl S, 2001, J BIOMED INFORM, V34, P28, DOI 10.1006/jbin.2001.10004; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GAMEZ J, 2002, P 1 EUR WORKSH PROB, P222; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; HANLEY JA, 1982, RADIOLOGY, V143, P29; Inza I, 2001, ARTIF INTELL MED, V23, P187, DOI 10.1016/S0933-3657(01)00085-9; JELONEK J, 1997, ARTIF INTELL MED, V20, P1202; JENSEN F, 2001, BAYESIAN NETWORKS DE; KEOGH E, 1999, 7 INT WORKSH ART INT, P225; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; KONONENKO I, 1984, P INT SCH SYNTH EXP; KONONENKO I, 1991, P 6 EUR WORK SESS LE, pS206; Kononenko I., 1990, CURRENT TRENDS KNOWL; LANGLEY P, 1994, P 10 C UNC ART INT, P399; LAPLACE PS, 1995, PHILOS ESSAYS PROBAB; Malinchoc M, 2000, HEPATOLOGY, V31, P864, DOI 10.1053/he.2000.5852; MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491; Minsky M., 1961, T I RADIO ENG, V49, P8; Neapolitan R. E., 2003, LEARNING BAYESIAN NE; NORDYKE RA, 1971, COMPUT BIOMED RES, V4, P374, DOI 10.1016/0010-4809(71)90022-X; Ohmann C, 1996, ARTIF INTELL MED, V8, P23, DOI 10.1016/0933-3657(95)00018-6; PAZZANI M, 1997, LECT NOTES STAT; Pearl J., 1988, PROBABILISTIC REASON; PUGH RNH, 1973, BRIT J SURG, V60, P646, DOI 10.1002/bjs.1800600817; RUSSEK E, 1983, COMPUT BIOMED RES, V16, P537, DOI 10.1016/0010-4809(83)90040-X; Sahami M., 1996, P 2 INT C KNOWL DISC, P335; SAUNDERS JB, 1981, BRIT MED J, V282, P263; STONE M, 1974, J R STAT SOC B, V36, P111; VANDERGAAG LC, 2001, P 13 BELG NETH C ART, P109; VINTERBO S, 1999, THESIS NORWEGIAN U S	43	23	24	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464		J BIOMED INFORM	J. Biomed. Inform.	OCT	2005	38	5					376	388		10.1016/j.jbi.2005.05.004		13	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	976MV	WOS:000232738600004	
J	Chechile, RA				Chechile, RA			Introduction to machine learning.	JOURNAL OF MATHEMATICAL PSYCHOLOGY			English	Book Review																Alpaydin E, 2004, INTRO MACHINE LEARNI	1	0	0	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0022-2496		J MATH PSYCHOL	J. Math. Psychol.	OCT	2005	49	5					423	423				1	Mathematics, Interdisciplinary Applications; Social Sciences, Mathematical Methods; Psychology, Mathematical	Mathematics; Mathematical Methods In Social Sciences; Psychology	975OK	WOS:000232671600006	
J	You, LW; Garwicz, D; Rognvaldsson, T				You, LW; Garwicz, D; Rognvaldsson, T			Comprehensive bioinformatic analysis of the specificity of human immunodeficiency virus type 1 protease	JOURNAL OF VIROLOGY			English	Article							SUPPORT VECTOR MACHINES; GAG PROCESSING SITES; CELL LEUKEMIA-VIRUS; P1 AMINO-ACID; HIV-1 PROTEASE; CLEAVAGE SITES; SUBSTRATE-SPECIFICITY; DRUG-RESISTANCE; NEURAL-NETWORKS; VIRAL FITNESS	Rapidly developing viral resistance to licensed human immunodeficiency virus type 1 (HIV-1) protease inhibitors is an increasing problem in the treatment of HIV-infected individuals and AIDS patients. A rational design of more effective protease inhibitors and discovery of potential biological substrates for the HIV-1 protease require accurate models for protease cleavage specificity. In this study, several popular bioinformatic machine learning methods, including support vector machines and artificial neural networks, were used to analyze the specificity of the HIV-1 protease. A new, extensive data set (746 peptides that have been experimentally tested for cleavage by the HIV-1 protease) was compiled, and the data were used to construct different classifiers that predicted whether the protease would cleave a given peptide substrate or not. The best predictor was a nonlinear predictor using two physicochemical parameters (hydrophobicity, or alternatively polarity, and size) for the amino acids, indicating that these properties are the key features recognized by the HIV-1 protease. The present in silico study provides new and important insights into the workings of the HIV-1 protease at the molecular level, supporting the recent hypothesis that the protease primarily recognizes a conformation rather than a specific amino acid sequence. Furthermore, we demonstrate that the presence of 1 to 2 lysine residues near the cleavage site of octameric peptide substrates seems to prevent cleavage efficiently, suggesting that this positively charged amino acid plays an important role in hindering the activity of the HIV-1 protease.	Halmstad Univ, Sch Informat Sci Comp & Elect Engn, SE-30118 Halmstad, Sweden; Lund Univ, Dept Lab Med, Div Hematol & Transfus Med, Lund, Sweden; Karolinska Inst, Inst Environm Med, Div Mol Toxicol, S-10401 Stockholm, Sweden	Rognvaldsson, T (reprint author), Halmstad Univ, Sch Informat Sci Comp & Elect Engn, Box 823, SE-30118 Halmstad, Sweden.	denni@ide.hh.se					Baldi P., 2001, BIOINFORMATICS MACHI; Beck HP, 2002, ADV HUM PER, V2, P37, DOI 10.1016/S1479-3601(02)02005-2; Beck ZQ, 2000, VIROLOGY, V274, P391, DOI 10.1006/viro.2000.0420; Beck ZQ, 2001, J VIROL, V75, P9458, DOI 10.1128/JVI.75.19.9458-9469.2001; BETTS MJ, 2003, BIOINFORMATICS GENET, V1, P289; BLACK SD, 1991, ANAL BIOCHEM, V193, P72, DOI 10.1016/0003-2697(91)90045-U; Boden D, 1998, ANTIMICROB AGENTS CH, V42, P2775; BOGOSSI P, 2005, J VIROL, V79, P4213; Bouzide A, 2005, BIOORG MED CHEM LETT, V15, P1509, DOI 10.1016/j.bmcl.2004.12.068; Brik A, 2003, ORG BIOMOL CHEM, V1, P5, DOI 10.1039/b208248a; Cai YD, 2002, J COMPUT CHEM, V23, P267, DOI 10.1002/jcc.10017; Cai YD, 1998, ADV ENG SOFTW, V29, P119, DOI 10.1016/S0965-9978(98)00046-5; Callebaut C, 1996, VIROLOGY, V218, P181, DOI 10.1006/viro.1996.0178; Chen LM, 2004, J VIROL, V78, P3722, DOI 10.1128/JVI.78.7.3722-3732.2004; Chou KC, 1996, ANAL BIOCHEM, V233, P1, DOI 10.1006/abio.1996.0001; Clemente JC, 2004, BIOCHEMISTRY-US, V43, P12141, DOI 10.1021/bi049459m; Cote HCF, 2001, J VIROL, V75, P589, DOI 10.1128/JVI.75.2.589-594.2001; Cristianini N., 2000, INTRO SUPPORT VECTOR; Dauber DS, 2002, J VIROL, V76, P1359, DOI 10.1128/JVI.76.3.1359-1368.2002; De Clercq E, 2004, J CLIN VIROL, V30, P115, DOI 10.1016/j.jvc.2004.02.009; De Clercq E, 2004, INT J BIOCHEM CELL B, V36, P1800, DOI 10.1016/j.biocel.2004.02.015; de Oliveira T, 2003, J VIROL, V77, P9422, DOI 10.1128/JVI.77.17.9422-9430.2003; Devroe E, 2005, VIROLOGY, V331, P181, DOI 10.1016/j.virol.2004.10.023; Feher A, 2002, EUR J BIOCHEM, V269, P4114, DOI 10.1046/j.1432-1033.2002.03105.x; Hazebrouck S, 2001, BIOCHEM J, V358, P505, DOI 10.1042/0264-6021:3580505; Hertz J., 1991, LECT NOTES, VI; Kadas J, 2004, J BIOL CHEM, V279, P27148, DOI 10.1074/jbc.M401868200; KAPLAN AH, 1993, J VIROL, V67, P4050; Kurt N, 2003, BIOPHYS J, V85, P853, DOI 10.1016/S0006-3495(03)74525-1; Maguire MF, 2002, J VIROL, V76, P7398, DOI 10.1128/JVI.76.15.7398-7406.2002; Narayanan Ajit, 2002, Bioinformatics, V18 Suppl 1, pS5; Pettit SC, 2002, J VIROL, V76, P10226, DOI 10.1128/JVI.76.20.10226-10233.2002; PETTIT SC, 1991, J BIOL CHEM, V266, P14539; POORMAN RA, 1991, J BIOL CHEM, V266, P14554; Prabu-Jeyabalan M, 2002, STRUCTURE, V10, P369, DOI 10.1016/S0969-2126(02)00720-7; Qian N, 1988, J MOL BIOL, V202, P865, DOI 10.1016/0022-2836(88)90564-5; Randolph JT, 2004, CURR TOP MED CHEM, V4, P1079, DOI 10.2174/1568026043388330; Ridky TW, 1998, BIOCHEMISTRY-US, V37, P13835, DOI 10.1021/bi980612k; Ridky TW, 1996, J BIOL CHEM, V271, P4709; Ripley B. D, 1996, PATTERN RECOGNITION; Rognvaldsson T, 2004, BIOINFORMATICS, V20, P1702, DOI 10.1093/bioinformatics/bth144; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; Thompson TB, 1995, J THEOR BIOL, V177, P369, DOI 10.1006/jtbi.1995.0254; Thomson R, 2003, BIOINFORMATICS, V19, P1741, DOI 10.1093/bioinformatics/btg237; TOZSER J, 1991, FEBS LETT, V279, P356, DOI 10.1016/0014-5793(91)80186-7; TOZSER J, 1991, FEBS LETT, V281, P77, DOI 10.1016/0014-5793(91)80362-7; Tozser J, 2000, EUR J BIOCHEM, V267, P6287, DOI 10.1046/j.1432-1327.2000.01714.x; Tozser J, 1997, J BIOL CHEM, V272, P16807, DOI 10.1074/jbc.272.27.16807; Ventoso I, 2001, P NATL ACAD SCI USA, V98, P12966, DOI 10.1073/pnas.231343498; Yang ZR, 2004, BIOINFORMATICS, V20, P3398, DOI 10.1093/bioinformatics/bth414; Yang ZR, 2003, BIOSYSTEMS, V72, P159, DOI 10.1016/S0303-2647(03)00141-2; Yang ZR, 2004, BIOINFORMATICS, V20, P735, DOI 10.1093/bioinformatics/btg477; YOU L, 2004, 12 INT C INT SYST MO; Zhang YM, 1997, J VIROL, V71, P6662; *UNAIDS, 2004, GLOB EST HIV AIDS EN, P10; *UNAIDS WHO, 2004, GLOB SUMM AIDS EP DE, P1	56	26	27	AMER SOC MICROBIOLOGY	WASHINGTON	1752 N ST NW, WASHINGTON, DC 20036-2904 USA	0022-538X		J VIROL	J. Virol.	OCT	2005	79	19					12477	12486		10.1128/JVI.79.19.12477-12486.2005		10	Virology	Virology	966AR	WOS:000231992500036	
J	Baldi, P; Rosen-Zvi, M				Baldi, P; Rosen-Zvi, M			On the relationship between deterministic and probabilistic directed Graphical models: From Bayesian networks to recursive neural networks	NEURAL NETWORKS			English	Article						Bayesian networks; belief propagation; recursive neural networks; recurrent neural networks; constraint networks graphical models		Machine learning methods that can handle variable-size structured data such as sequences and graphs include Bayesian networks (BNs) and Recursive Neural Networks (RNNs). In both classes of models, the data is modeled using a set of observed and hidden variables associated with the nodes of a directed acyclic graph. In BNs, the conditional relationships between parent and child variables are probabilistic, whereas in RNNs they are deterministic and parameterized by neural networks. Here, we study the formal relationship between both classes of models and show that when the source nodes variables are observed, RNNs can be viewed as limits, both in distribution and probability, of BNs with local conditional distributions that have vanishing covariance matrices and converge to delta functions. Conditions for uniform convergence are also given together with an analysis of the behavior and exactness of Belief Propagation (BP) in 'deterministic' BNs. Implications for the design of mixed architectures and the corresponding inference algorithms are briefly discussed. (c) 2005 Elsevier Ltd. All rights reserved.	Univ Calif Irvine, Sch Informat & Comp Sci, Irvine, CA 92697 USA; Univ Calif Irvine, Inst Genom & Bioinformat, Irvine, CA 92697 USA; Hebrew Univ Jerusalem, Sch Comp Sci & Engn, IL-91904 Jerusalem, Israel	Baldi, P (reprint author), Univ Calif Irvine, Sch Informat & Comp Sci, Irvine, CA 92697 USA.	pfbaldi@ics.uci.edu					Baldi P, 2003, J MACHINE LEARNING R, V4, P575; Baldi P, 1996, NEURAL COMPUT, V8, P1541, DOI 10.1162/neco.1996.8.7.1541; BALDI P, 2005, RELATIONSHIP DETERMI; BARBER D, 2000, ADV NEURAL INFORMATI, V12; Billingsley P., 1995, PROBABILITY MEASURE; BOZHENA R, 2001, EPSILON CUTSET EFFEC; Dechter R., 2003, CONSTRAINT PROCESSIN; Frasconi P, 1998, IEEE T NEURAL NETWOR, V9, P768, DOI 10.1109/72.712151; Goller C, 1996, IEEE IJCNN, P347, DOI 10.1109/ICNN.1996.548916; Heckerman D, 1998, TUTORIAL LEARNING BA; PEARL J, 1986, ARTIF INTELL, V29, P241, DOI 10.1016/0004-3702(86)90072-X; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Micheli A, 2001, J CHEM INF COMP SCI, V41, P202, DOI 10.1021/ci0000399; Pearl J., 1988, PROBABILISTIC REASON; ROSENZVI M, 2003, APPROXIMATE INFERENC; Sperduti A, 1997, IEEE T NEURAL NETWOR, V8, P714, DOI 10.1109/72.572108	16	2	3	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080		NEURAL NETWORKS	Neural Netw.	OCT	2005	18	8					1080	1086		10.1016/j.neunet.2005.07.007		7	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	982QU	WOS:000233177500007	
J	Ralaivola, L; Swamidass, SJ; Saigo, H; Baldi, P				Ralaivola, L; Swamidass, SJ; Saigo, H; Baldi, P			Graph kernels for chemical informatics	NEURAL NETWORKS			English	Article						kernel methods; graph kernels; convolution kernels; spectral kernels; computational chemistry; chemical informatics; toxicity; activity; drug design; recursive neural networks	NEURAL NETWORKS; SECONDARY-STRUCTURE; SIMILARITY; PREDICTION; BENZODIAZEPINES; CLASSIFICATION; MUTAGENICITY; DATABASES; SPACE	Increased availability of large repositories of chemical compounds is creating new challenges and opportunities for the application of machine learning methods to problems in computational chemistry and chemical informatics. Because chemical compounds are often represented by the graph of their covalent bonds, machine learning methods in this domain Must be capable of processing graphical structures with variable size. Here, we first briefly review the literature on graph kernels and then introduce three new kernels (Tanimoto, MmMax, Hybrid) based on the idea of molecular fingerprints and counting labeled paths of depth up to d using depth-first search from each possible vertex. The kernels are applied to three classification problems to predict mutagenicity, toxicity, and anti-cancer activity on three publicly available data sets. The kernels achieve performances at least comparable, and most often superior, to those previously reported in the literature reaching accuracies of 91.5% on the Mutag dataset, 65-67% on the PTC (Predictive Toxicology Challenge) dataset, and 72% on the NCI (National Cancer Institute) dataset. Properties and tradeoffs of these kernels, as well as other proposed kernels that leverage 1D or 3D representations of molecules, are briefly discussed. (c) 2005 Elsevier Ltd. All rights reserved.	Univ Calif Irvine, Sch Informat & Comp Sci, Irvine, CA 92697 USA; Univ Calif Irvine, Inst Genom & Bioinformat, Irvine, CA 92697 USA	Baldi, P (reprint author), Univ Calif Irvine, Sch Informat & Comp Sci, Irvine, CA 92697 USA.	pfbaldi@ics.uci.edu					Aizerman M.A., 1964, AUTOMAT REM CONTR, P821; Bach F. R., 2002, J MACHINE LEARNING R, V3, P1; BALDI P, NEURAL NETWORKS KERN; Baldi P., 2001, BIOINFORMATICS MACHI; Baldi P, 2003, J MACHINE LEARNING R, V4, P575; Baldi P, 1996, NEURAL COMPUT, V8, P1541, DOI 10.1162/neco.1996.8.7.1541; BOSER B, 1992, P 5 WORKSH COMP LEAR, V5; CHEN J, 2005, UNPUB CHEMDB PUBLIC; CHERQAOUI D, 1994, J CHEM SOC FARADAY T, V90, P97, DOI 10.1039/ft9949000097; Chou P Y, 1978, Adv Enzymol Relat Areas Mol Biol, V47, P45; COLLINS M, 2002, CONVOLUTION KERNELS, V14; Cortes C, 1995, MACH LEARN, V20, P1; Cristianini N., 2000, INTRO SUPPORT VECTOR; De Raedt L., 2001, P 18 INT C MACH LEAR, P258; DEBNATH AK, 1991, J MED CHEM, V34, P786, DOI 10.1021/jm00106a046; Dobson CM, 2004, NATURE, V432, P824, DOI 10.1038/nature03192; Dumais S., 1998, P 7 INT C INF KNOWL; Fligner MA, 2002, TECHNOMETRICS, V44, P110, DOI 10.1198/004017002317375064; FLOWER DR, 1998, J CHEM INF COMP SCI, V38, P378; Frasconi P, 1998, IEEE T NEURAL NETWOR, V9, P768, DOI 10.1109/72.712151; Freund Y, 1999, MACH LEARN, V37, P277, DOI 10.1023/A:1007662407062; Frey B. J., 1998, GRAPHICAL MODELS MAC; FRIESS T, 1998, P 15 C MACH LEARN LO; GARTNER T, 2003, NIPS WORKSH UNR DAT; Gartner T., 2003, P 16 ANN C COMP LEAR; Gasteiger J, 1996, J CHEM INF COMP SCI, V36, P1030, DOI 10.1021/ci960343+; Goller C, 1996, IEEE IJCNN, P347, DOI 10.1109/ICNN.1996.548916; GOWER JC, 1986, J CLASSIF, V3, P5, DOI 10.1007/BF01896809; GOWER JC, 1971, BIOMETRICS, V27, P857, DOI 10.2307/2528823; HADJIPAVLOULITINA D, 1994, CHEM REV, V94, P1483, DOI 10.1021/cr00030a002; HANLEY JA, 1982, RADIOLOGY, V143, P29; HAUSSLER D, 1999, UCSCRL9910; Heckerman D, 1998, LEARNING GRAPHICAL M; Helma C, 2001, BIOINFORMATICS, V17, P107, DOI 10.1093/bioinformatics/17.1.107; Herbrich R., 2002, LEARNING KERNEL CLAS; Horvath T., 2004, P 10 ACM SIGKDD INT, P158, DOI 10.1145/1014052.1014072; JAAKKOLA T, 1998, ADV NEURAL INFORMATI, V11; James C. A., 2004, DAYLIGHT THEORY MANU; Jonsdottir SO, 2005, BIOINFORMATICS, V21, P2145, DOI 10.1093/bioinformatics/bti314; Kashima H., 2003, P 20 INT C MACH LEAR; KIMELDOR.G, 1971, J MATH ANAL APPL, V33, P82, DOI 10.1016/0022-247X(71)90184-3; KING RD, 1995, NEW GENERAT COMPUT, V13, P411; King RD, 1996, P NATL ACAD SCI USA, V93, P438, DOI 10.1073/pnas.93.1.438; KONDOR RI, 2002, DIFFUSION KERNELS GR; Koza J. R., 1994, Proceedings of the First IEEE Conference on Evolutionary Computation. IEEE World Congress on Computational Intelligence (Cat. No.94TH0650-2), DOI 10.1109/ICEC.1994.350008; Lauritzen S. L., 1996, GRAPHICAL MODELS; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Leslie Christina, 2002, Pac Symp Biocomput, P564; LESLIE C, 2003, MISMATCH STRING KERN, V15; LODHI H, 2000, TEXT CLASSIFICATION, V15; Mahe P., 2004, P 21 INT C MACH LEAR; Micheli A, 2001, J CHEM INF COMP SCI, V41, P202, DOI 10.1021/ci0000399; MICHELI A, 2003, SOFT COMPUTING APPRO, P265; MIKA S, 1999, KERNEL PCA DENOISING; Muggleton S., 1992, APIC SERIES, V38; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Pearl J., 1988, PROBABILISTIC REASON; Pollastri G, 2002, PROTEINS, V47, P228, DOI 10.1002/prot.10082; Raymond JW, 2002, J COMPUT AID MOL DES, V16, P59, DOI 10.1023/A:1016387816342; ROUVRAY DH, 1992, J CHEM INF COMP SCI, V32, P580, DOI 10.1021/ci00010a002; SADOWSKI J, 1994, J CHEM INF COMP SCI, V34, P1000, DOI 10.1021/ci00020a039; SAKAKIBARA Y, 1994, NUCLEIC ACIDS RES, V22, P5112, DOI 10.1093/nar/22.23.5112; SALTON G, 1991, SCIENCE, V253, P974, DOI 10.1126/science.253.5023.974; Scholkopf B., 2002, LEARNING KERNELS SUP; SCHOLKOPF B, 2000, NCTR00081; Sperduti A, 1997, IEEE T NEURAL NETWOR, V8, P714, DOI 10.1109/72.572108; Srinivasan A, 1996, ARTIF INTELL, V85, P277, DOI 10.1016/0004-3702(95)00122-0; SWAMIDASS SJ, 2005, BIOINFORMATICS S1, P359; Tsuda Koji, 2002, BIOINFORMATICS, V18, P268; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037//0033-295X.84.4.327; UKKONEN E, 1995, ALGORITHMICA, V14, P249, DOI 10.1007/BF01206331; Vapnik VN, 1998, STAT LEARNING THEORY; Vert J.-P., 2003, ADV NEURAL INFORMATI, V15, P1425; Vert JP, 2002, BIOINFORMATICS, V18, P276; VISHWANATHAN SVN, 2003, FAST KERNELS STRINGS, V15; Weiner P., 1973, P 14 IEEE S SWITCH A, P1; Yang Yiming, 1997, P 14 INT C MACH LEAR, P412; Yanover C., 2002, ADV NEURAL INFORM PR, V15, P1457	78	77	81	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080		NEURAL NETWORKS	Neural Netw.	OCT	2005	18	8					1093	1110		10.1016/j.neunet.2005.07.009		18	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	982QU	WOS:000233177500009	
J	Chen, SC; Chen, L; Zhou, ZH				Chen, SC; Chen, L; Zhou, ZH			A unified SWSI-KAMs framework and performance evaluation on face recognition	NEUROCOMPUTING			English	Article						small-word structure (SWS); associative memory (AM); neural networks; kernel method; performance evaluation; face recognition	BIDIRECTIONAL ASSOCIATIVE MEMORY; NETWORKS; ALGORITHMS; IMAGE	The Kernel method is an effective and popular trick in machine learning. In this paper, by introducing it into conventional auto-associative memory models (AMs), we construct a unified framework of kernel auto-associative memory models (KAMs), which makes the existing exponential and polynomial AMs become its special cases. Further, in order to reduce KAM's connect complexity, inspired by "small-world network" recently described by Watts and Strogatz, we propose another unified framework of small-world structure (SWS) inspired kernel auto-associative memory models (SWSI-KAMs), which, in principle, makes KAMs simpler in structure. Simulation results on the FERET face database show that, the SWSI-KAMs adopting kernels such as Exponential and Hyperbolic tangent kernels have advantages of configuration simplicity while their recognition performance is almost as good as or even better than corresponding KAMs with full connectivity. In the end, the SWSI-KAM adopting Exponential kernel with different connectivities was emphatically investigated for robustness based on those face images which were added random noises and/or partially occluded in a mosaic way, and the experiments demonstrate that the SWSI-KAM with Exponential kernel is more robust in all cases of network connectivity of 20%, 40% and 60% than both PCA and recently proposed (PC)(2)A algorithms for face recognition. (c) 2005 Published by Elsevier B.V.	Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, Nanjing 210016, Peoples R China; Nanjing Univ, Natl Lab Novel Software Technol, Nanjing 210093, Peoples R China	Chen, SC (reprint author), Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, 29 Yudao St, Nanjing 210016, Peoples R China.	s.chen@nuaa.edu.cn; chenleijx@sohu.com					Achacoso T. B., 1992, AYS NEUROANATOMY C E; Bohland JW, 2001, NEUROCOMPUTING, V38, P489, DOI 10.1016/S0925-2312(01)00378-2; CANNING A, 1988, J PHYS A, V21, P3273; Chen SC, 1997, ELECTRON LETT, V33, P223, DOI 10.1049/el:19970155; Chen SC, 2004, IEEE T SYST MAN CY B, V34, P1907, DOI 10.1109/TSMCB.2004.831165; CHEN SC, 2004, BOOK CHAPTER ADV NEU; CHEN ZY, 1994, P IEEE INT C NEUR NE, P1068; CHIUEH TD, 1993, IEEE T NEURAL NETWOR, V4, P364, DOI 10.1109/72.207604; CHIUEH TD, 1991, IEEE T NEURAL NETWOR, V2, P275, DOI 10.1109/72.80338; Cristianini N., 2000, INTRO SUPPORT VECTOR; Erdos P., 1960, PUBL MATH I HUNG, V5, P17; Hattori M., 1996, Transactions of the Institute of Electrical Engineers of Japan, Part C, V116-C; Haykin S., 1999, NEURAL NETWORKS COMP; HEBB DO, 1943, ORG BEHAV; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; JENG YJ, 1991, IEEE T NEURAL NETWOR, V2, P275; Kim BJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.045101; KOMLOS J, 1993, J COMPUT SYST SCI, V47, P350, DOI 10.1016/0022-0000(93)90036-V; KOSKO B, 1988, IEEE T SYST MAN CYB, V18, P49, DOI 10.1109/21.87054; LeCun Y. A., 1995, P INT C ART NEUR NET, P53; Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P117, DOI 10.1109/TNN.2002.806629; MCELIECE RJ, 1987, IEEE T INFORM THEORY, V33, P461, DOI 10.1109/TIT.1987.1057328; McGraw PN, 2003, PHYS REV E, V68, DOI 10.1103/PhysRevE.68.047102; Mika S., 1999, P IEEE NEUR NETW SIG, P41; Milgram S., 1967, PSYCHOL TODAY, V1, P60, DOI DOI 10.1145/335305.335325; OH H, 1994, IEEE T NEURAL NETWOR, V5, P576; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; TAI HM, 1989, ELECTRON LETT, V25, P1424, DOI 10.1049/el:19890950; Torres JJ, 2004, NEUROCOMPUTING, V58, P229, DOI 10.1016/j.neucom.2004.01.048; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), DOI 10.1109/CVPR.1991.139758; VENKATESH SS, 1992, IEEE T INFORM THEORY, V38, P1114, DOI 10.1109/18.135650; Lee DL, 1998, NEURAL NETWORKS, V11, P1623; Wang ZO, 1996, IEEE T COMPUT, V45, P1171; Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918; Wu JX, 2002, PATTERN RECOGN LETT, V23, P1711, DOI 10.1016/S0167-8655(02)00134-4; Zhang DQ, 2003, NEURAL PROCESS LETT, V18, P155, DOI 10.1023/B:NEPL.0000011135.19145.1b; Zhang Ling, 1994, Chinese Journal of Computers, V17; Zhang Ling, 1994, Chinese Journal of Computers, V17	39	3	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	OCT	2005	68						54	69		10.1016/j.neucom.2005.02.001		16	Computer Science, Artificial Intelligence	Computer Science	969VH	WOS:000232262900004	
J	Nanni, L				Nanni, L			Fusion of classifiers for predicting protein-protein interactions	NEUROCOMPUTING			English	Article						protein-protein interactions; machine learning; fusion of classifiers	CLASSIFICATION	Prediction of protein-protein interaction is a difficult and an important problem in biology. In this paper, we describe a very general method for predicting protein-protein interactions. The interaction mining approach is demonstrated by building a learning system based on experimentally validated protein-protein interactions in the human gastric bacterium Helicobacter pylori. We show that combining linear discriminant classifier and cloud points we obtain an error rate lower than previously published in the literature. (c) 2005 Elsevier B.V. All rights reserved.	Univ Bologna, DEIS, IEIIT, CNR, I-40136 Bologna, Italy	Nanni, L (reprint author), Univ Bologna, DEIS, IEIIT, CNR, Viale Risorgimento 2, I-40136 Bologna, Italy.	lnanni@deis.unibo.it					Bock JR, 2003, BIOINFORMATICS, V19, P125, DOI 10.1093/bioinformatics/19.1.125; Bock JR, 2001, BIOINFORMATICS, V17, P455, DOI 10.1093/bioinformatics/17.5.455; Duda R. O., 2001, PATTERN CLASSIFICATI; Kuncheva LI, 2005, INFORM FUSION, V6, P3, DOI 10.1016/j.inffus.2004.04.009; Lai C, 2004, INT J PATTERN RECOGN, V18, P867, DOI 10.1142/S0218001404003459; Manevitz LM, 2002, J MACH LEARN RES, V2, P139, DOI 10.1162/15324430260185574; Martin S, 2005, BIOINFORMATICS, V21, P218, DOI 10.1093/bioinformatics/bth483; ONG MGH, 2003, MULTIMEDIA BIOMETRIC, P100; Rain JC, 2001, NATURE, V409, P211, DOI 10.1038/35051615; Sprinzak E, 2003, J MOL BIOL, V327, P919, DOI 10.1016/S0022-2836(03)00239-0; Valencia A, 2002, CURR OPIN STRUC BIOL, V12, P368, DOI 10.1016/S0959-440X(02)00333-0; WU C, 1992, PROTEIN SCI, V1, P667	12	15	18	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	OCT	2005	68						289	296		10.1016/j.neucom.2005.03.004		8	Computer Science, Artificial Intelligence	Computer Science	969VH	WOS:000232262900021	
J	Nanni, L				Nanni, L			Fusion of classifiers for protein fold recognition	NEUROCOMPUTING			English	Article						fusion of classifiers; protein fold recognition; machine learning algorithms		Predicting the three-dimensional structure of a protein from its amino acid sequence is ail important problem in bioinformatics and a challenging task for machine learning algorithms. Given (numerical) features, one of the existing machine learning techniques can be then applied to learn and classify proteins represented by these features. We show that combining Fisher's linear classifier and K-Local Hyperplane Distance Nearest Neighbor we obtain an error rate lower than previously published in the literature. (c) 2005 Elsevier B.V. All rights reserved.	Univ Bologna, CNR, IEIIT, DEIS, I-40136 Bologna, Italy	Nanni, L (reprint author), Univ Bologna, CNR, IEIIT, DEIS, Viale Risorgimento 2, I-40136 Bologna, Italy.	lnanni@deis.unibo.it					BOLOGNA G, 2002, P 9 INT C NEUR INF P, V5, P2492; Chung IF, 2003, LECT NOTES COMPUT SC, V2714, P1159; Ding CHQ, 2001, BIOINFORMATICS, V17, P349, DOI 10.1093/bioinformatics/17.4.349; Duda R., 2000, PATTERN CLASSIFICATI; Kuncheva LI, 2002, PATTERN RECOGN LETT, V23, P593, DOI 10.1016/S0167-8655(01)00155-6; Kuncheva LI, 2005, INFORM FUSION, V6, P3, DOI 10.1016/j.inffus.2004.04.009; OKUN O, 2004, P 2 EUR WORKSH DAT M, V1, P51; ONG MGH, 2003, MULTIMEDIA BIOMETRIC, V1, P100; Pal NR, 2003, LECT NOTES COMPUT SC, V2714, P1176	9	6	6	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	OCT	2005	68						315	321		10.1016/j.neucom.2005.03.001		7	Computer Science, Artificial Intelligence	Computer Science	969VH	WOS:000232262900024	
J	Du, HF; Gong, MG; Liu, RC; Jiao, LC				Du, HF; Gong, MG; Liu, RC; Jiao, LC			Adaptive chaos clonal evolutionary programming algorithm	SCIENCE IN CHINA SERIES F-INFORMATION SCIENCES			English	Article						chaos; clonal selection; evolutionary algorithms		Based on the chaos movement and the clonal selection theory, a novel artificial immune system algorithm, Adaptive Chaos Clonal Evolutionary Programming Algorithm (ACCEP), is proposed in this paper. The new algorithm uses the Logistic Sequence to control the mutation scale and uses the Chaos Mutation Operator to control the clonal selection. Compared with SGA and Clonal Selection Algorithm, ACCEP can enhance the precision and stability, avoid prematurity to some extent, and have the high convergence speed. The results of the experiment indicate that ACCEP has the capability to solve complex machine learning tasks, like Multimodal Function Optimization.	Xidian Univ, Inst Intelligent Informat Proc, Xian 710071, Peoples R China; Xidian Univ, Key Lab Radar Signal Proc, Xian 710071, Peoples R China; Xian Jiaotong Univ, Sch Mech Engn, Xian 710049, Peoples R China	Du, HF (reprint author), Xidian Univ, Inst Intelligent Informat Proc, Xian 710071, Peoples R China.	haifengdu72@163.com					Chen Guo-Liang, 1996, GENETIC ALGORITHM AP; Choi C., 1998, ARTIFICIAL LIFE ROBO, V2, P41, DOI 10.1007/BF02471151; Dasgupta D., 1999, Proceedings of the Second International Conference on Intelligent Processing and Manufacturing of Materials. IPMM'99 (Cat. No.99EX296), DOI 10.1109/IPMM.1999.792486; De Castro L.N., 2000, P GECCO 00 WORKSH AR, P36; Du H., 2002, P 1 INT C MACH LEARN, P506; Jiao Li-cheng, 2003, Acta Electronica Sinica, V31; Kim J, 2001, IEEE C EVOL COMPUTAT, P1244; Li Bing, 1997, Control Theory & Applications, V14; LI K, 2001, SCI CHINA SER F, V44, P430; Liu YG, 2003, SCI CHINA SER F, V46, P126, DOI 10.1360/03yf9011; LU JH, 2002, ANAL APPL CHAOS TIME; LUO CZ, 2000, CONTROL DECISION, V15, P557; QI AS, 1999, NONLINEAR MODEL IMMU	13	6	10	SCIENCE PRESS	BEIJING	16 DONGHUANGCHENGGEN NORTH ST, BEIJING 100717, PEOPLES R CHINA	1009-2757		SCI CHINA SER F	Sci. China Ser. F-Inf. Sci.	OCT	2005	48	5					579	595		10.1360/04yf0458		17	Computer Science, Information Systems	Computer Science	984YR	WOS:000233343800003	
J	Zhang, F; Mallick, B; Weng, ZJ				Zhang, F; Mallick, B; Weng, ZJ			A Bayesian method for identifying independent sources of non-random spatial patterns	STATISTICS AND COMPUTING			English	Article						blind source separation; variational Bayesian; conjugate prior; principal component analysis	MULTIVARIATE MANUFACTURING PROCESSES; COMPONENT ANALYSIS; BLIND SEPARATION; PRINCIPAL COMPONENTS; MAXIMUM-LIKELIHOOD; EM ALGORITHM; MODELS	A Bayesian blind source separation (BSS) algorithm is proposed in this paper to recover independent sources from observed multivariate spatial patterns. As a widely used mechanism, Gaussian mixture model is adopted to represent the sources for statistical description and machine learning. In the context of linear latent variable BSS model, some conjugate priors are incorporated into the hyperparameters estimation of mixing matrix. The proposed algorithm then approximates the full posteriors over model structure and source parameters in an analytical manner based on variational Bayesian treatment. Experimental studies demonstrate that this Bayesian source separation algorithm is appropriate for systematic spatial pattern analysis by modeling arbitrary sources and identify their effects on high dimensional measurement data. The identified patterns will serve as diagnosis aids for gaining insight into the nature of physical process for the potential use of statistical quality control.	Fairchild Corp, Portland, ME 04106 USA; Texas A&M Univ, Dept Stat, College Stn, TX 77843 USA; NW Polytech Univ, Dept Comp Sci & Engn, Fremont, CA 94539 USA	Zhang, F (reprint author), Fairchild Corp, 82 Running Hill Rd, Portland, ME 04106 USA.	zhangfeng@neo.tamu.edu					Apley DW, 2003, TECHNOMETRICS, V45, P220, DOI 10.1198/004017003000000041; Apley DW, 2001, TECHNOMETRICS, V43, P84, DOI 10.1198/00401700152404354; ATTIAS H, 2000, ADV NEURAL INFORMATI, V12, P49; Bartholomew D. J., 1999, LATENT VARIABLE MODE; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; BISHOP C. M., 2001, ARTIF INTELL, P27; Cardoso JF, 1999, NEURAL COMPUT, V11, P157, DOI 10.1162/089976699300016863; Ceglarek D, 1996, J ENG IND-T ASME, V118, P55, DOI 10.1115/1.2803648; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Gelman A. B., 2000, BAYESIAN DATA ANAL; Haykin S., 2000, UNSUPERVISED ADAPTIV, VI; Hyvarinen A., 1999, NEURAL COMPUTING SUR, V2, P94; Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; JACKSON JE, 1981, J QUAL TECHNOL, V13, P46; JACKSON JE, 1980, J QUAL TECHNOL, V12, P201; Johnson Richard A., 2002, APPL MULTIVARIATE ST; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; JUTTEN C, 1991, SIGNAL PROCESS, V24, P1, DOI 10.1016/0165-1684(91)90079-X; Knuth KH, 1998, P SOC PHOTO-OPT INS, V3459, P147, DOI 10.1117/12.323794; LEE TW, 2000, IEEE T PATTERN ANAL, V22, P78; MacKay D. J. C., 1996, MAXIMUM LIKELIHOOD C; McLachlan G., 2000, FINITE MIXTURE MODEL; Moulines E, 1997, P INT C AC SPEECH SI, P3617; Pearlmutter BA, 1997, ADV NEUR IN, V9, P613; ROWE DB, 2002, J INTERDISCIPLINARY, V5, P49; Roweis S, 1999, NEURAL COMPUT, V11, P305, DOI 10.1162/089976699300016674; Tipping ME, 1999, J ROY STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; Tong L, 1990, IEEE INT S CIRC SYST, P1784; Wax M, 1997, IEEE SIGNAL PROC LET, V4, P52, DOI 10.1109/97.554471	31	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0960-3174		STAT COMPUT	Stat. Comput.	OCT	2005	15	4					329	339		10.1007/s11222-005-4075-6		11	Computer Science, Theory & Methods; Statistics & Probability	Computer Science; Mathematics	973OA	WOS:000232531300007	
J	Oh, DCH; Tan, CL				Oh, DCH; Tan, CL			Making better recommendations with online profiling agents	AI MAGAZINE			English	Article; Proceedings Paper	19th National Conference on Artificial Intelligence/16th Conference on Innovative Applications of Artificial Intelligence	JUL 25-29, 2004	San Jose, CA	Amer Assoc Artificial Intelligence				In recent years, we have witnessed the success of autonomous agents applying machine-learning techniques across a wide range of applications. However, agents applying the same machine-learning techniques in online applications have not been so successful. Even agent-based hybrid recommender systems that combine information filtering techniques with collaborative filtering techniques have been applied with considerable success only to simple consumer goods such as movies, books, clothing, and food. Yet complex, adaptive autonomous agent systems that can handle complex goods such as real estate, vacation plans, insurance, mutual funds, and mortgages have emerged. To a large extent, the reinforcement learning methods developed to aid agents in learning have been more successfully deployed in offline applications. The inherent limitations in these methods have rendered them somewhat ineffective in online applications. In this article, we postulate that a small amount of prior knowledge and human-provided input can dramatically speed up online learning. We demonstrate that our agent HumanE-with its prior knowledge or "experiences" about the real estate domain-can effectively assist users in identifying requirements, especially unstated ones, quickly and unobtrusively.	Natl Univ Singapore, Dept Comp Sci, Sch Comp, Singapore 117548, Singapore							BROOKS RA, 1986, IEEE T ROBOTIC AUTOM, V2, P14, DOI 10.1109/JRA.1986.1087032; Burke RD, 1997, IEEE EXPERT, V12, P32, DOI 10.1109/64.608186; FRANKLIN S, 1996, LECT NOTES ARTIFICIA, V1193; GAO X, 1998, 11998 U MELB DEP COM; KRAEMER K, 1991, INFORMATION SYSTEMS, P299; NEWSTED PR, 1997, 1996 INT C INF SYST; Pinsonneault A., 1993, Journal of Management Information Systems, V10; Schneiderman B, 1983, IEEE COMPUT, V16, P57; Shearin S., 2001, P INT C INT US INT I, P145, DOI 10.1145/359784.360325; SMART WD, 2002, P IEE INT C ROB AUT, V4, P3403; Turban E., 1998, DECISION SUPPORT SYS	11	0	0	AMER ASSOC ARTIFICIAL INTELL	MENLO PK	445 BURGESS DRIVE, MENLO PK, CA 94025-3496 USA	0738-4602		AI MAG	AI Mag.	FAL	2005	26	3					29	39				11	Computer Science, Artificial Intelligence	Computer Science	970QH	WOS:000232324200003	
J	Fernandez, S; Aler, R; Borrajo, D				Fernandez, S; Aler, R; Borrajo, D			Machine learning in hybrid hierarchical and partial-order planners for manufacturing domains	APPLIED ARTIFICIAL INTELLIGENCE			English	Article							CONTROL KNOWLEDGE; ARCHITECTURE; TECHNOLOGY	The application of AI planning techniques to manufacturing systems is being widely deployed for all the tasks involved in the process, from product design to production planning and control. One of these problems is the automatic generation control sequences for the entire manufacturing system in such a way that final plans can be directly used as the sequential control programs which drive the operation of manufacturing systems. HYBIS is a hierarchical and nonlinear planner whose goal is to obtain partially ordered plans at such a level of detail that they can be used as sequential control programs for manufacturing systems. Currently, those sequential control programs all, being generated by hand rising modeling tools. This document describes a work aimed to improve the efficiency of solving problems with HYBIS by using machine learning techniques. It implements a deductive learning method that is able to automatically acquire control knowledge (heuristics) by generating bounded explanations of the, problem-solving episodes. The learning approach builds on HAMLET; a system that learns control knowledge in the form of control rules.	Univ Carlos III Madrid, Dept Informat, Madrid 2891, Spain	Fernandez, S (reprint author), Univ Carlos III Madrid, Dept Informat, Madrid 2891, Spain.	susana.fernandez@uc3m.es					Aler R, 2002, ARTIF INTELL, V141, P29, DOI 10.1016/S0004-3702(02)00246-1; ALGEO MEA, 1996, P JAP US S FLEX AUT, V1, P699; AYLETT R, 1997, P 4 EUR C PLANN, P41; Bacchus F, 2000, ARTIF INTELL, V116, P123, DOI 10.1016/S0004-3702(99)00071-5; BECKERS JM, 2002, EXPT ASTRONOMY, V12, P1; BEZIRGAN A, 1992, P EXP SYST 92 12 ANN, P225; Borrajo D, 1997, ARTIF INTELL REV, V11, P371, DOI 10.1023/A:1006549800144; Braatz A., 2003, Automatisierungstechnische Praxis, V45; Braccesi L., 2004, Proceedings. Ninth IEEE International Conference on Engineering of Complex Computer Systems, DOI 10.1109/ICECCS.2004.1310920; BRESLOW L, 1997, AIC97018 NAV CTR APP; Burke E. K., 2001, P 2001 GEN EV COMP C, P1252; BURKE EK, 2002, 4 AS PAC C SIM EV LE; CARBONELL JG, 1992, CMUCS92150 CARN MELL; CASTILLO L, 2000, ECAI WORKSH PLANN CO; CASTILLO L, 2000, ARTIF INTELL, V4, P15; Castles FG, 2001, STUD EMP SOC POLICY, V11, P141; Cowling P., 2000, LECT NOTES COMPUTER, P176; Cunningham P, 1997, INT J PROD RES, V35, P2947, DOI 10.1080/002075497194237; DEJONG G, 1986, MACH LEARN, V1, P2; Erol K., 1994, ARTIF INTELL, P249; ESTLIN TA, 1997, P 15 INT JOINT C ART, P1227; FABIAN M, 1997, P ECC 97 BRUSS BELG; FDEZOLIVARES J, 2001, THESIS U GRANADA; GARLAND A, 2001, 1 INT C KNOWL CAPT; Gerevini A., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; GIL Y, 1991, CMUCS91179 SCH COMP; Giunchiglia F, 1999, ARTIF INTELL REV, V13, P201, DOI 10.1023/A:1006507609248; GUANGHONG H, 2003, CONTROL ENG CHINA, V10, P339; HAN L, 2002, P 4 AS PAC C SIM EV; Haskose A, 2004, INT J PROD ECON, V90, P169, DOI 10.1016/S0925-5273(03)00052-5; HEINONEN J, 2003, P C EV COMP CANB, V2, P966; HUANG YC, 2000, P 17 INT C MACH LEAR; Ilghami O., 2002, P 6 INT C AI PLANN S, P131; Kambhampati S, 2000, J ARTIF INTELL RES, V12, P1; KAPARTHI S, 1993, EUR J OPER RES, V69, P342, DOI 10.1016/0377-2217(93)90020-N; Kiritsis D., 1998, First International Workshop on Intelligent Manufacturing Systems (IMS-Europe 1998). Proceedings; KLEIN I, 1998, ARTIF INTELL, V13, P69; LAIRD JE, 1987, ARTIF INTELL, V33, P1, DOI 10.1016/0004-3702(87)90050-6; LIU B, 1999, P ACM SIGKDD INT C K; Liu B., 1998, KNOWLEDGE DISCOVERY, P80; LUGER G, 1998, AAAI SPECIAL INTERES; MAROPOULOS PG, 1995, COMPUT INTEGR MANUF, V8, P13, DOI 10.1016/0951-5240(95)92809-9; McCluskey T. L., 2003, Proceedings, Thirteenth International Conference on Automated Planning and Scheduling; McCluskey T. L., 2002, P 6 INT C ART INT PL; MINTON S, 1988, CMUCS88133; MUNOZ H, 1995, P 1 INT C CAS BAS RE, P241; MUNOZAVILA H, 1999, P 9 C INN APPL ART I, P879; NAREYCK A, 2001, CHOOSING SEARCH HEUR; Nau D., 1999, P 16 INT JOINT C ART, P968; NAU DS, 1995, P INT JOINT C ART IN, P1670; PARK SC, 1993, IEEE T SYST MAN CYB, V23, P1597, DOI 10.1109/21.257757; Peschke J., 2003, Proceedings. IEEE International Conference on Industrial Informatics (IEEE Cat. No.03EX768); Pollack ME, 1997, J ARTIF INTELL RES, V6, P223; SACERDOT.ED, 1974, ARTIF INTELL, V5, P115, DOI 10.1016/0004-3702(74)90026-5; SIMPSON R, 2001, P 6 EUR C PLANN ECP; Szelke E, 1997, COMPUT IND, V33, P31, DOI 10.1016/S0166-3615(97)00009-2; VALYOV M, 2004, EUROPEAN J OPERATION, V157, P620; VANLENT M, 1999, P 16 INT C MACH LEAR, P229; VELOSO M, 1994, PLANNING LEARNING AN; VELOSO M, 1995, J EXP THEOR ARTIF IN, V7, P81, DOI 10.1080/09528139508953801; Viswanathan S, 1998, COMPUT CHEM ENG, V22, P1673, DOI 10.1016/S0098-1354(98)00228-2; Vrakas D., 2003, Proceedings, Thirteenth International Conference on Automated Planning and Scheduling; WELD DS, 1994, AI MAG, V15, P27; Zimmerman T, 2003, AI MAG, V24, P73; *ANSI ISA, 1995, BATCH CONTR 1	65	2	2	TAYLOR & FRANCIS INC	PHILADELPHIA	325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA	0883-9514		APPL ARTIF INTELL	Appl. Artif. Intell.	SEP	2005	19	8					783	809		10.1080/08839510490961491		27	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	965OP	WOS:000231960300003	
J	Carvalho, DR; Freitas, AA				Carvalho, DR; Freitas, AA			Evaluating six candidate solutions for the small-disjunct problem and choosing the best solution via meta-learning	ARTIFICIAL INTELLIGENCE REVIEW			English	Article						classification; data mining; decision trees; genetic algorithms; instance-based learning		A set of classification rules can be considered as a disjunction of rules, where each rule is a disjunct. A small disjunct is a rule covering a small number of examples. Small disjuncts are a serious problem for effective classification, because the small number of examples satisfying these rules makes their prediction unreliable and error-prone. This paper offers two main contributions to the research on small disjuncts. First, it investigates six candidate solutions (algorithms) for the problem of small disjuncts. Second, it reports the results of a meta-learning experiment, which produced meta-rules predicting which algorithm will tend to perform best for a given data set. The algorithms investigated in this paper belong to different machine learning paradigms and their hybrid combinations, as follows: two versions of a decision-tree (DT) induction algorithm; two versions of a hybrid DT/genetic algorithm (GA) method; one GA; one hybrid DT/instance-based learning (IBL) algorithm. Experiments with 22 data sets evaluated both the predictive accuracy and the simplicity of the discovered rule sets, with the following conclusions. If one wants to maximize predictive accuracy only, then the hybrid DT/IBL seems to be the best choice. On the other hand, if one wants to maximize both predictive accuracy and rule set simplicity - which is important in the context of data mining - then a hybrid DT/GA seems to be the best choice.	Univ Tuiuti Parana, Dept Comp Sci, BR-80215090 Curitiba, Parana, Brazil; Univ Kent, Comp Lab, Canterbury CT2 7NF, Kent, England	Carvalho, DR (reprint author), Univ Tuiuti Parana, Dept Comp Sci, Av Comendador Franco 1860, BR-80215090 Curitiba, Parana, Brazil.	deborah@utp.br; a.a.freitas@kent.ac.uk					Brodley CE, 1999, J ARTIF INTELL RES, V11, P131; Carvalho DR, 2004, INFORM SCIENCES, V163, P13, DOI 10.1016/j.ins.2003.03.013; CARVALHO DR, 2002, P GEN EV COMP C GECC, P1035; CARVALHO DR, 2002, P 4 INT C REC ADV SO, P260; Carvalho D. R., 2002, Applied Soft Computing, V2, DOI 10.1016/S1568-4946(02)00031-5; Carvalho D. R., 2000, Principles of Data Mining and Knowledge Discovery. 4th European Conference, PKDD 2000. Proceedings (Lecture Notes in Artificial Intelligence Vol.1910); Cover T. M., 1991, ELEMENTS INFORMATION; Danyluk A. P., 1993, P 10 INT C MACH LEAR, P81; Deb K., 2001, MULTIOBJECTIVE OPTIM; Dhar V, 2000, DATA MIN KNOWL DISC, V4, P251, DOI 10.1023/A:1009848126475; Fayyad U.M., 1996, ADV KNOWLEDGE DISCOV, P1; FREITAS A, 2002, HDB DATA MINING KNOW, P698; Freitas A., 2002, DATA MINING KNOWLEDG; Freitas A.A., 2000, P GEN EV COMP C GECC, P1061; Freitas AA, 2001, ARTIF INTELL REV, V16, P177, DOI 10.1023/A:1011996210207; Han J., 2001, DATA MINING CONCEPTS; Hand D. J., 1997, CONSTRUCTION ASSESSM; HENERY RJ, 1994, MACHINE LEARNING NEU, P6; HOLTE RC, 1989, P IJCAI, V89, P813; Krieger Abba, 2001, P 18 INT C MACH LEAR, P274; Langley P., 1996, ELEMENTS MACHINE LEA; Mitchell T, 1997, MACHINE LEARNING; Papagelis A, 2001, P 18 INT C MACH LEAR, P393; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1991, MACH LEARN, V6, P93, DOI 10.1007/BF00153762; Rendell L., 1990, Computational Intelligence, V6, DOI 10.1111/j.1467-8640.1990.tb00298.x; RENDELL L, 1993, P 13 INT JOINT C ART, P952; Ting K., 1994, P 10 CAN C ART INT, P91; WEISS G M, 1995, P 12 INT C MACH LEAR, P558; WEISS GM, 1998, P 15 INT C MACH LEAR, P574; Weiss G. M., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); Witten I. H., 2000, DATA MINING	32	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0269-2821		ARTIF INTELL REV	Artif. Intell. Rev.	SEP	2005	24	1					61	98		10.1007/s10462-005-1586-7		38	Computer Science, Artificial Intelligence	Computer Science	914VA	WOS:000228254900003	
J	Pham, TH; Clemente, JC; Satou, K; Ho, TB				Pham, TH; Clemente, JC; Satou, K; Ho, TB			Computational discovery of transcriptional regulatory rules	BIOINFORMATICS			English	Article; Proceedings Paper	Joint Meeting of the 4th European Conference on Computational Biology/6th Meeting of the Spanish-Bioinformatics-Network	SEP 28-OCT 01, 2005	Madrid, SPAIN	Spanish Bioinformat Network			SACCHAROMYCES-CEREVISIAE; BINDING-SITES; NETWORKS; GENOME; MODULES; GENES	Motivation: Even in a simple organism like yeast Saccharomyces cerevisiae, transcription is an extremely complex process. The expression of sets of genes can be turned on or off by the binding of specific transcription factors to the promoter regions of genes. Experimental and computational approaches have been proposed to establish mappings of DNA-binding locations of transcription factors. However, although location data obtained from experimental methods are noisy owing to imperfections in the measuring methods, computational approaches suffer from over-prediction problems owing to the short length of the sequence motifs bound by the transcription factors. Also, these interactions are usually environment-dependent: many regulators only bind to the promoter region of genes under specific environmental conditions. Even more, the presence of regulators at a promoter region indicates binding but not necessarily function: the regulator may act positively, negatively or not act at all. Therefore, identifying true and functional interactions between transcription factors and genes in specific environment conditions and describing the relationship between them are still open problems. Results: We developed a method that combines expression data with genomic location information to discover (1) relevant transcription factors from the set of potential transcription factors of a target gene; and (2) the relationship between the expression behavior of a target gene and that of its relevant transcription factors. Our method is based on rule induction, a machine learning technique that can efficiently deal with noisy domains. When applied to genomic location data with a confidence criterion relaxed to P-value = 0.005, and three different expression datasets of yeast S.cerevisiae, we obtained a set of regulatory rules describing the relationship between the expression behavior of a specific target gene and that of its relevant transcription factors. The resulting rules provide strong evidence of true positive gene-regulator interactions, as well as of protein-protein interactions that could serve to identify transcription complexes. Availability: Supplementary files are available from http://www.jaist.ac.jp/similar to h-pham/regulatory-rules.	Japan Adv Inst Sci & Technol, Nomi, Ishikawa 9231292, Japan; Japan Sci & Technol Agcy, BIRD, Chiyoda Ku, Tokyo 1028666, Japan	Pham, TH (reprint author), Japan Adv Inst Sci & Technol, 1-1-Asahidai, Nomi, Ishikawa 9231292, Japan.	h-pham@jaist.ac.jp					Bader GD, 2003, NUCLEIC ACIDS RES, V31, P248, DOI 10.1093/nar/gkg056; Bar-Joseph Z, 2003, NAT BIOTECHNOL, V21, P1337, DOI 10.1038/nbt890; BRUIN RA, 2004, CELL, V117, P887; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; CLARK P, 1991, 5TH P EUR WORK SESS, P151; Furnkranz J, 1999, ARTIF INTELL REV, V13, P3, DOI 10.1023/A:1006524209794; Gasch AP, 2001, MOL BIOL CELL, V12, P2987; Gasch AP, 2000, MOL BIOL CELL, V11, P4241; Harbison CT, 2004, NATURE, V431, P99, DOI 10.1038/nature02800; HARRIS MA, 2004, NUCLEIC ACIDS RES, V32, P258; Ihmels J, 2002, NAT GENET, V31, P370, DOI 10.1038/ng941; Iyer VR, 2001, NATURE, V409, P533, DOI 10.1038/35054095; Kellis M, 2003, NATURE, V423, P241, DOI 10.1038/nature01644; KOCH C, 1993, SCIENCE, V261, P1551, DOI 10.1126/science.8372350; Lavrac N, 2004, J MACH LEARN RES, V5, P153; Lee TI, 2002, SCIENCE, V298, P799, DOI 10.1126/science.1075090; Lieb JD, 2001, NAT GENET, V28, P327, DOI 10.1038/ng569; LIU B, 1998, 4 INT C KNOWL DISC D; Liu XS, 2002, NAT BIOTECHNOL, V20, P835, DOI 10.1038/nbt717; Matys V, 2003, NUCLEIC ACIDS RES, V31, P374, DOI 10.1093/nar/gkg108; Pham Tho Hoan, 2004, Genome Inform, V15, P287; PHAM TH, 2005, WORKSH KNOWL DIS DAT, P29; Pilpel Y, 2001, NAT GENET, V29, P153, DOI 10.1038/ng724; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1987, 10TH P INT JOINT C A, P304; Ren B, 2000, SCIENCE, V290, P2306, DOI 10.1126/science.290.5500.2306; ROTH FP, 1998, NAT BIOTECHNOL, V16, P907; Segal E, 2003, NAT GENET, V34, P166, DOI 10.1038/ng1165; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; TIMOTHY L, 1995, P 3 INT C INT SYST M, P21	30	10	10	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	SEP	2005	21			2			101	107		10.1093/bioinoformatics/bti1117		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	971YN	WOS:000232421000019	
J	De Raedt, K; De Raedt, H; Michielsen, K				De Raedt, K; De Raedt, H; Michielsen, K			Deterministic event-based simulation of quantum phenomena	COMPUTER PHYSICS COMMUNICATIONS			English	Article						computer simulation; machine learning; quantum interference; quantum theory		We propose and analyse simple deterministic algorithms that can be used to construct machines that have primitive learning capabilities. We demonstrate that locally connected networks of these machines can be used to perform blind classification on an event-by-event basis, without storing the information of the individual events. We also demonstrate that properly designed networks of these machines exhibit behavior that is usually only attributed to quantum systems. We present networks that simulate quantum interference on an event-by-event basis. In particular we show that by using simple geometry and the learning capabilities of the machines it is possible to simulate single-photon interference in a Mach-Zehnder interferometer. The interference pattern generated by the network of deterministic learning machines is in perfect agreement with the quantum theoretical result for the single-photon Mach-Zehnder interferometer. To illustrate that networks of these machines are indeed capable of simulating quantum interference we simulate, event-by-event, a setup involving two chained Mach-Zehnder interferometers, and demonstrate that also in this case the simulation results agree with quantum theory. (C) 2005 Elsevier B.V. All rights reserved.	Univ Groningen, Ctr Mat Sci, Dept Appl Phys, NL-9747 AG Groningen, Netherlands; Univ Groningen, Dept Comp Sci, NL-9747 AC Groningen, Netherlands	De Raedt, H (reprint author), Univ Groningen, Ctr Mat Sci, Dept Appl Phys, Nijenborgh 4, NL-9747 AG Groningen, Netherlands.	deraedt@cs.rug.nl; deraedt@phys.rug.nl; kristel@phys.rug.nl					Ballentine L E, 2003, QUANTUM MECH MODERN; Baym G, 1974, LECT QUANTUM MECH; Born M., 1964, PRINCIPLES OPTICS; Chuang I. L., 2000, QUANTUM COMPUTATION; De Raedt H., 1996, ANN REV COMPUT PHYS, V4, P107; DERAEDT H, IN PRESS J PHYS SOC; Feynman R P, 1996, FEYNMAN LECT PHYS, VIII; FEYNMAN RP, 1982, INT J THEOR PHYS, V21, P467, DOI 10.1007/BF02650179; Golub G. H., 1996, MATRIX COMPUTATIONS; GRANGIER P, 1986, EUROPHYS LETT, V1, P173, DOI 10.1209/0295-5075/1/4/004; HAYKIN S, 1986, ADAPTIVE FILTER THEO; HAYKIN S, 1999, NEUTRAL NETWORKS; Home D., 1997, CONCEPTUAL FDN QUANT; Landau D. P., 2000, GUIDE MONTE CARLO SI; Mardia K. V., 1982, MULTIVARIATE ANAL; MICHIELSEN K, IN PRESS J COMP THEO; Penrose R, 1990, EMPERORS NEW MIND; Rarity JG, 1997, PHILOS T R SOC A, V355, P2267; Schrodinger E, 1926, ANN PHYS-BERLIN, V79, P361; SCHRODINGER E, 1926, ANN PHYS, V79, P491; t Hooft G., HEPTH0105105; Tonomura A., 1998, QUANTUM WORLD UNVEIL; VANKAMPEN NG, 1988, PHYSICA A, V153, P97, DOI 10.1016/0378-4371(88)90105-7; Zalka C, 1998, P ROY SOC LOND A MAT, V454, P313, DOI 10.1098/rspa.1998.0162; 't Hooft G., QUANTPH0212095	25	28	28	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0010-4655		COMPUT PHYS COMMUN	Comput. Phys. Commun.	SEP 1	2005	171	1					19	39		10.1016/j.cpc.2005.04.012		21	Computer Science, Interdisciplinary Applications; Physics, Mathematical	Computer Science; Physics	959AF	WOS:000231488600002	
J	Adami, G; Avesani, P; Sona, D				Adami, G; Avesani, P; Sona, D			Clustering documents into a web directory for bootstrapping a supervised classification	DATA & KNOWLEDGE ENGINEERING			English	Article; Proceedings Paper	5th ACM International Workdshop on Web Information and Data Management (WIDM 2003)	NOV 07-08, 2003	New Orleans, LA	ACM		Web directories; TaxSOM; constrained clustering; K-means; unsupervised learining; relational machine learning; taxonomy bootstrapping; text categorization; knowledge management; digital libraries		The management of hierarchically organized data is starting to play a key role in the knowledge management community due to the proliferation of topic hierarchies for text documents. The creation and maintenance of such organized repositories of information requires a great deal of human intervention. The machine learning community has partially addressed this problem by developing hierarchical supervised classifiers that help people categorize new resources within given hierarchies. The worst problem of hierarchical supervised classifiers, however, is their high demand in terms of labeled examples. The number of examples required is related to the number of topics in the taxonomy. Bootstrapping a huge hierarchy with a proper set of labeled examples is therefore a critical issue. This paper proposes some solutions for the bootstrapping problem, that implicitly or explicitly use taxonomy definition: a baseline approach that classifies documents according to the class terms, and two clustering approaches, whose training is constrained by the a priori knowledge encoded in the taxonomy structure, which consists of both terminological and relational aspects. In particular, we propose the Tax-SOM model, that clusters a set of documents in a predefined hierarchy of classes, directly exploiting the knowledge of both their topological organization and their lexical description. Experimental evaluation was performed on a set of taxonomies taken from the Google (TM) and LookSmart (TM) web directories, obtaining good results. (c) 2004 Elsevier B.V. All rights reserved.	IRST, ITC, Automat Reasoning Syst Div, I-38050 Trento, Italy	Sona, D (reprint author), IRST, ITC, Automat Reasoning Syst Div, Via Sommar 18, I-38050 Trento, Italy.	gioadami@itc.it; avesani@itc.it; sona@itc.it					Adami G., 2003, P 5 ACM INT WORKSH W, P66; ADAMI G., 2003, P CIKM 03 12 ACM INT, P295; Aggarwal C., 1999, P 5 ACM SIGKDD INT C, P352, DOI 10.1145/312129.312279; AVESANI P, 2004, T040402 ITCIRST; BAEZAYATES R, 1999, MODERN INFORMATION R; BONIFACIO M, 2002, INFORMATIK INFORMATI, V3; Ceci M, 2003, LECT NOTES COMPUT SC, V2633, P57; CHAKRABARTI S, 1997, VLDB 97, P446; CHEN Y, 2001, SCI CHINA SER B, V5, P433; COHN DA, 1995, ADV NEURAL INFORM PR, V7, P705; Doan A, 2003, MACH LEARN, V50, P279, DOI 10.1023/A:1021765902788; DUMAIS S, 2000, P 23 ACM INT C RES; Fellbaum C., 1998, WORDNET ELECT LEXICA; Goldman S., 2000, P 17 INT C MACH LEAR, P327; Jeon B, 1999, IEEE T GEOSCI REMOTE, V37, P1073; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; KOHONEN T, 2001, SELF ORG MAPSSERIES, V30; Koller D., 1997, ICML 1997 P 14 INT C, P170; Liu B, 2002, P 19 INT C MACH LEAR, P387; MCCALLUM A, 1999, ACL 99 WORKSH UNS LE; Nigam K., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Roy N., 2001, P 18 INT C MACH LEAR, P441; Ruiz ME, 2002, INFORM RETRIEVAL, V5, P87, DOI 10.1023/A:1012782908347; Sun A., 2001, ICDM 2001, P521; Urena-Lopez LA, 2001, COMPUT HUMANITIES, V35, P215, DOI 10.1023/A:1002632712378; WANG K, 1999, P 25 VLDB C; Yang Y., 1994, P 17 ANN INT ACM SIG, P13	27	12	12	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-023X		DATA KNOWL ENG	Data Knowl. Eng.	SEP	2005	54	3					301	325		10.1016/j.datak.2004.11.003		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	934JF	WOS:000229704400003	
J	Lemm, S; Blankertz, B; Curio, G; Muller, KR				Lemm, S; Blankertz, B; Curio, G; Muller, KR			Spatio-spectral filters for improving the classification of single trial EEG	IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING			English	Article						BCI; classification; CSP; feature extraction	BRAIN-COMPUTER INTERFACES; BOOSTING BIT RATES; DESYNCHRONIZATION; COMMUNICATION; MOVEMENT	Data recorded in electroencephalogram (EEG)-based brain-computer interface experiments is generally very noisy, non-stationary, and contaminated with artifacts that can deteriorate discrimination/classification methods. In this paper, we extend the common spatial pattern (CSP) algorithm with the aim to alleviate these adverse effects. In particular, we suggest an extension of CSP to the state space, which utilizes the method of time delay embedding. As we will show, this allows for individually tuned frequency filters at each electrode position and, thus, yields an improved and more robust machine learning procedure. The advantages of the proposed method over the original CSP method are verified in terms of an improved information transfer rate (bits per trial) on a set of EEG-recordings from experiments of imagined limb movements.	FIRST Fraunhofer Inst, Dept Inteligent Data Anal, D-12489 Berlin, Germany; Univ Med, Charite, Dept Neurol, Neurophys Grp, D-12200 Berlin, Germany; Univ Potsdam, Dept Comp Sci, D-14482 Potsdam, Germany	Lemm, S (reprint author), FIRST Fraunhofer Inst, Dept Inteligent Data Anal, D-12489 Berlin, Germany.	steven.lemin@first.fhg.de	Muller, Klaus/C-3196-2013				Birbaumer N, 1999, NATURE, V398, P297, DOI 10.1038/18581; Blanco A, 2002, TAPPI J, V1, P14; Blankertz B, 2003, IEEE T NEUR SYS REH, V11, P127, DOI 10.1109/TNSRE.2003.814456; DORNHEGE G, 2004, ADV NEURAL INFORMATI, V16; Dornhege G, 2004, IEEE T BIO-MED ENG, V51, P993, DOI 10.1109/TBME.2004.827088; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Fukanaga K., 1972, INTRO STAT PATTERN R; Jasper H, 1949, ARCH PSYCHIAT NERVEN, V183, P163, DOI 10.1007/BF01062488; Koles ZJ, 1998, ELECTROEN CLIN NEURO, V107, P343, DOI 10.1016/S0013-4694(98)00084-4; LAUBACH M, 2000, NATURE, V405, P523; Leuthardt Eric C, 2004, J Neural Eng, V1, P63, DOI 10.1088/1741-2560/1/2/001; Levine SP, 2000, IEEE T REHABIL ENG, V8, P180, DOI 10.1109/86.847809; McFarland DJ, 2003, BIOL PSYCHOL, V63, P237, DOI 10.1016/S0301-0511(03)00073-5; Mika S, 2000, ADV NEUR IN, V12, P526; Millan JD, 2004, IEEE T BIO-MED ENG, V51, P1026, DOI 10.1109/TBME.2004.827086; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Muller KR, 2003, IEEE T NEUR SYS REH, V11, P165, DOI 10.1109/TNSRE.2003.814484; NIKOULINE V, 2000, NEUROSCI LETT, V294; PARRA L, 2002, NEUROIMAGE, V7, P223; Penny WD, 2000, IEEE T REHABIL ENG, V8, P214, DOI 10.1109/86.847820; Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8; PFURTSCHELLER G, 1979, ELECTROEN CLIN NEURO, V46, P138, DOI 10.1016/0013-4694(79)90063-4; Pfurtscheller G, 2000, IEEE T REHABIL ENG, V8, P216, DOI 10.1109/86.847821; Ramoser H, 2000, IEEE T REHABIL ENG, V8, P441, DOI 10.1109/86.895946; Schnitzler A, 1997, NEUROIMAGE, V6, P201, DOI 10.1006/nimg.1997.0286; Takens F., 1981, DYNAMICAL SYSTEMS TU, P366, DOI DOI 10.1007/BFB0091924; Taylor DM, 2002, SCIENCE, V296, P1829, DOI 10.1126/science.1070291; Trejo LJ, 2003, IEEE T NEUR SYS REH, V11, P199, DOI 10.1109/TNSRE.2003.814426; Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3	29	124	128	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9294		IEEE T BIO-MED ENG	IEEE Trans. Biomed. Eng.	SEP	2005	52	9					1541	1548		10.1109/TBME.2005.851521		8	Engineering, Biomedical	Engineering	955ZO	WOS:000231268900006	
J	Liu, XY; Wang, HQ				Liu, XY; Wang, HQ			A discretization algorithm based on a heterogeneity criterion	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article; Proceedings Paper	1st International Workshop on Data Cleaning and Preprocessing	DEC09, 2002	Maebashi City, JAPAN	Univ Technol Sydney, Hong Kong Univ Sci & Technol		data mining; data preparation; discretization; entropy; heterogeneity	MIXED-MODE DATA; CONTINUOUS ATTRIBUTES	Discretization, as a preprocessing step for data mining, is a process of converting the continuous attributes of a data set into discrete ones so that they can be treated as the nominal features by machine learning algorithms. Those various discretization methods, that use entropy-based criteria, form a large class of algorithm. However, as a measure of class homogeneity, entropy cannot always accurately reflect the degree of class homogeneity of an interval. Therefore, in this paper, we propose a new measure of class heterogeneity of intervals from the viewpoint of class probability itself, Based on the definition of heterogeneity, we present a new criterion to evaluate a discretization scheme and analyze its property theoretically. Also, a heuristic method is proposed to find the approximate optimal discretization scheme. Finally, our method is compared, in terms of predictive error rate and tree size, with Ent-MDLC, a representative entropy-based discretization method well-known for its good performance. Our method is shown to produce better results than those of Ent-MDLC, although the improvement is not significant. It can be a good alternative to entropy-based discretization methods.	City Univ Hong Kong, Dept Informat Syst, Kowloon, Hong Kong, Peoples R China	Liu, XY (reprint author), City Univ Hong Kong, Dept Informat Syst, Kowloon, Hong Kong, Peoples R China.	50007212@student.cityu.edu.hk; iswang@cityu.edu.hk	Liu, Xiaoyan/K-8376-2012				Blake C. L., 1998, UCI REPOSITORY MACHI; Boulle M, 2004, MACH LEARN, V55, P53, DOI 10.1023/B:MACH.0000019804.29836.05; CATLETT J, 1991, LECT NOTES ARTIF INT, V482, P164; Cerquides J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; CHING JY, 1995, IEEE T PATTERN ANAL, V17, P641, DOI 10.1109/34.391407; Chmielewski MR, 1996, INT J APPROX REASON, V15, P319, DOI 10.1016/S0888-613X(96)00074-6; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; Ho K. M., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Kerber R., 1992, P 10 NAT C ART INT, P123; Kohavi R., 1996, P 2 INT C KNOWL DISC, P114; KOHAVI R, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P613; KURGAN L, 2001, P 2001 INT C ART INT, P980; Kurgan LA, 2004, IEEE T KNOWL DATA EN, V16, P145, DOI 10.1109/TKDE.2004.1269594; Liu H, 1997, IEEE T KNOWL DATA EN, V9, P642; Liu H, 2002, DATA MIN KNOWL DISC, V6, P393, DOI 10.1023/A:1016304305535; PFAHRINGER B, 1995, P 12 INT C MACH LEAR; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Richeldi M, 1995, LECT NOTES ARTIF INT, V912, P335; ROIGER RJ, 2002, DATA MINING TUTORIAL; SHANNON C, 1949, MATH THEORY INFORMAT; Tay FEH, 2002, IEEE T KNOWL DATA EN, V14, P666, DOI 10.1109/TKDE.2002.1000349; WONG AKC, 1987, IEEE T PATTERN ANAL, V9, P796; Zhang P, 2003, IEEE NETWORK, V17, P5; Zhang SC, 2004, IEEE INTELL SYST, V19, P12; [Anonymous], 1993, P 13 INT JOINT C ART, P1022	25	21	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	SEP	2005	17	9					1166	1173		10.1109/TKDE.2005.135		8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	953SW	WOS:000231101800002	
J	Combarro, EF; Montanes, E; Diaz, I; Ranilla, J; Mones, R				Combarro, EF; Montanes, E; Diaz, I; Ranilla, J; Mones, R			Introducing a family of linear measures for feature selection in text categorization	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article; Proceedings Paper	1st International Workshop on Data Cleaning and Preprocessing	DEC09, 2002	Maebashi City, JAPAN	Univ Technol Sydney, Hong Kong Univ Sci & Technol		text categorization; feature selection; filtering measures; machine learning		Text Categorization, which consists of automatically assigning documents to a set of categories, usually involves the management of a huge number of features. Most of them are irrelevant and others introduce noise which could mislead the classifiers. Thus, feature reduction is often performed in order to increase the efficiency and effectiveness of the classification. In this paper, we propose to select relevant features by means of a family of linear filtering measures which are simpler than the usual measures applied for this purpose. We carry out experiments over two different corpora and find that the proposed measures perform better than the existing ones.	Univ Oviedo, Ctr Artificial Intelligence, Gijon 33204, Spain	Combarro, EF (reprint author), Univ Oviedo, Ctr Artificial Intelligence, Edificio Marina Civil,Campus Viesques S-N, Gijon 33204, Spain.	elias@aic.uniovi.es; elena@aic.uniovi.es; sirene@aic.uniovi.es; ranilla@aic.uniovi.es; mones@aic.uniovi.es	Ranilla, Jose/E-8012-2013	Ranilla, Jose/0000-0003-2941-3741			APTE C, 1994, INFORM SYST, V12, P233; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Diaz I, 2004, J AM SOC INF SCI TEC, V55, P579, DOI 10.1002/asi.10409; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288651; Furnkranz J., 1994, P 11 INT C MACH LEAR, P70; Galavotti L, 2000, LECT NOTES COMPUT SC, V1923, P59; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; JOHNSONGENTILE K, 1994, J EDUC COMPUT RES, V11, P121; MLADEMNICD GROBELNIK M, 1999, P 16 INT C MACH LEAR, P258; Montanes E, 2003, LECT NOTES COMPUT SC, V2810, P589, DOI 10.1007/978-3-540-45231-7_54; MONTANES E, IN PRESS IEEE INTELL; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; SALTON G, 1983, INTRO MODERN INFORMA; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Vapnik V. N, 1995, NATURE STAT LEARNING; Yang Yiming, 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; Yang Yiming, 1997, P 14 INT C MACH LEAR, P412; *NAT LIB MED, 1993, MED SUBJ HEAD MESH	18	18	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	SEP	2005	17	9					1223	1232		10.1109/TKDE.2005.149		10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	953SW	WOS:000231101800007	
J	Chen, ZS; Ji, CY				Chen, ZS; Ji, CY			Spatial-temporal modeling of malware propagation in networks	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						graphical models; malware; modeling; security; stochastic processes		Network security is an important task of network management. One threat to network security is malware (malicious software) propagation. One type of malware is called topological scanning that spreads based on topology information. The focus of this work is on modeling the spread of topological malwares, which is important for understanding their potential damages, and for developing countermeasures to protect the network infrastructure. Our model is motivated by probabilistic graphs, which have been widely investigated in machine learning. We first use a graphical representation to abstract the propagation of malwares that employ different scanning methods. We then use a spatial-temporal random process to describe the statistical dependence of malware propagation in arbitrary topologies. As the spatial dependence is particularly difficult to characterize, the problem becomes how to use simple (i.e., biased) models to approximate the spatially dependent process. In particular, we propose the independent model and the Markov model as simple approximations. We conduct both theoretical analysis and extensive simulations on large networks using both real measurements and synthesized topologies to test the performance of the proposed models. Our results show that the independent model can capture temporal dependence and detailed topology information and, thus, outperforms the previous models, whereas the Markov model incorporates a certain spatial dependence and, thus, achieves a greater accuracy in characterizing both transient and equilibrium behaviors of malware propagation.	Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA	Chen, ZS (reprint author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.	zchen@ece.gatech.edu; jic@ece.gatech.edu					Andersson H., 2000, LECT NOTES STAT, V151; Barabasi AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509; Boguna M, 2003, LECT NOTES PHYS, V625, P127; Chen Z., 2003, P IEEE INFOCOM, P1890; Cover T. M., 1991, ELEMENTS INFORMATION; Ebel H, 2002, PHYS REV E, V66, DOI 10.1103/PhysRevE.66.035103; Erdos P., 1960, PUBL MATH I HUNG, V5, P17; ESARY JD, 1967, ANN MATH STAT, V38, P1466, DOI 10.1214/aoms/1177698701; Faloutsos M., 1999, P ACM SIGCOMM, P251, DOI 10.1145/316188.316229; GANESH A, 2005, P INFOCOM05 MIAMI MA; GARETTO M, 2003, P IEEE INFOCOM, V3, P1869; Kephart J. O., 1991, Proceedings. 1991 IEEE Computer Society Symposium on Research in Security and Privacy (Cat. No.91CH2986-8), DOI 10.1109/RISP.1991.130801; Lauritzen S. L., 1996, GRAPHICAL MODELS; Liggett TM, 1985, INTERACTING PARTICLE, P9; MEDINA A, 2001, BUCSTR2001003 APR; MOORE D, 2003, P 22 ANN JOINT C IEE, P1901; NARASIMHA R, 2005, IN PRESS IEEE T SIGN; Opper M., 2001, ADV MEAN FIELD METHO; Orman H., 2003, IEEE Security & Privacy, V1, DOI 10.1109/MSECP.2003.1236233; SAROIU S, 2002, P MULTIMEDIA COMPUTI; SCHECHTER SE, INOCULATING SSH AGAI; Staniford S., 2002, P 11 USENIX SEC S; Vazquez A, 2002, PHYS REV E, V65, DOI 10.1103/PhysRevE.65.066130; WAINWRIGHT MJ, 2003, 649 U CAL BERK CA TE; WANG C, 2000, P 16 ACM ANN COMP AP, P343; WANG Y, 2003, P S REL DISTR SYST F; Yedidia J. S., 2001, ADV MEAN FIELD METHO, P21; Zou C. C., 2002, P 9 ACM C COMP COMM, P138, DOI DOI 10.1145/586110.586130; Zou C. C., 2004, Proceedings. 13th International Conference on Computer Communications and Networks (IEEE Cat. No.04EX969), DOI 10.1109/ICCCN.2004.1401687	29	7	7	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	SEP	2005	16	5					1291	1303		10.1109/TNN.2005.853425		13	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	966AM	WOS:000231992000023	
J	Balakrishnan, N; Hariharakrishnan, K; Schonfeld, D				Balakrishnan, N; Hariharakrishnan, K; Schonfeld, D			A new image representation algorithm inspired by image submodality models, redundancy reduction, and learning in biological vision	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; feature representation; statistical models; clustering algorithms; machine learning; color	BRIGHTNESS PERCEPTION; NATURAL IMAGES; LIGHTNESS	We develop a new biologically motivated algorithm for representing natural images using successive projections into complementary subspaces. An image is first projected into an edge subspace spanned using an ICA basis adapted to natural images which captures the sharp features of an image like edges and curves. The residual image obtained after extraction of the sharp image features is approximated using a mixture of probabilistic principal component analyzers (MPPCA) model. The model is consistent with cellular, functional, information theoretic, and learning paradigms in visual pathway modeling. We demonstrate the efficiency of our model for representing different attributes of natural images like color and luminance. We compare the performance of our model in terms of quality of representation against commonly used basis, like the discrete cosine transform (DCT), independent component analysis ( ICA), and principal components analysis (PCA), based on their entropies. Chrominance and luminance components of images are represented using codes having lower entropy than DCT, ICA, or PCA for similar visual quality. The model attains considerable simplification for learning from images by using a sparse independent code for representing edges and explicitly evaluating probabilities in the residual subspace.	Univ Illinois, Dept Bioengn, Chicago, IL 60607 USA; Motorola India Elect Ltd, Bangalore 560093, Karnataka, India; Univ Illinois, Dept Elect & Comp Engn, Chicago, IL 60607 USA	Balakrishnan, N (reprint author), Univ Illinois, Dept Bioengn, 851 S Morgan St,Room 218,M-C 063, Chicago, IL 60607 USA.	nikhilbalakrishnan@gmail.com; coonoor@gmail.com; ds@ece.uic.edu					Abbott L., 1999, NEURAL CODES DISTRIB; BALLARD DH, 1999, INTRO NATURAL COMPUT, P46; Barlow H, 2001, NETWORK-COMP NEURAL, V12, P241, DOI 10.1088/0954-898X/12/3/301; Barlow H. B., 1961, SENS COMMUN, P217; Barlow H. B., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.3.295; Cover TM, 1991, ELEMENTS INFORMATION, P12; DAUGMAN J, 2003, HDB BRAIN THEORY NEU, P457; Geisler WS, 2001, VISION RES, V41, P711, DOI 10.1016/S0042-6989(00)00277-7; GONZALEZ RC, 1993, DIGITAL IMAGE PROCEW; GROSSBERG S, 1988, PERCEPT PSYCHOPHYS, V43, P723; HURLBERT A, 1986, J OPT SOC AM A, V3, P1684, DOI 10.1364/JOSAA.3.001684; Hyvarinen A, 2000, NEURAL COMPUT, V12, P1705, DOI 10.1162/089976600300015312; Hyvarinen A., 2001, INDEPENDENT COMPONEN; Hyvarinen A, 2001, NEURAL COMPUT, V13, P1527, DOI 10.1162/089976601750264992; HYVARINEN A, FASTICA MATLAB PACKA; KENTRIDGE R, 2003, HDB BRAIN THEORY NEU, P230; Kruger N, 1998, NEURAL PROCESS LETT, V8, P117, DOI 10.1023/A:1009688428205; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; McArthur JA, 1999, VISION RES, V39, P1199, DOI 10.1016/S0042-6989(98)00216-8; NABNEY IT, 2003, NETLAB NEURAL NETWOR; NEUMANN H, 2003, HDB BRAIN THEORY NEU, P271; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; PARADISO MA, 1991, VISION RES, V31, P1221, DOI 10.1016/0042-6989(91)90047-9; SNELL RS, 1997, CLIN NEUROANATOMY ME, P702; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728	25	4	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2005	27	9					1367	1378		10.1109/TPAMI.2005.170		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	944XB	WOS:000230463300002	
J	Tappen, MF; Freeman, WT; Adelson, EH				Tappen, MF; Freeman, WT; Adelson, EH			Recovering intrinsic images from a single image	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; machine learning; reflectance; shading; boosting; belief propagation	VISION	Interpreting real-world images requires the ability distinguish the different characteristics of the scene that lead to its final appearance. Two of the most important of these characteristics are the shading and reflectance of each point in the scene. We present an algorithm that uses multiple cues to recover shading and reflectance intrinsic images from a single image. Using both color information and a classifier trained to recognize gray-scale patterns, given the lighting direction, each image derivative is classified as being caused by shading or a change in the surface's reflectance. The classifiers gather local evidence about the surface's form and color, which is then propagated using the Generalized Belief Propagation algorithm. The propagation step disambiguates areas of the image where the correct classification is not clear from local evidence. We use real- world images to demonstrate results and show how each component of the system affects the results.	MIT, Comp Sci & Artificial Intelligence Lab, Stata Ctr, Cambridge, MA 02139 USA; MIT, Dept Brain Cognit Sci, Cambridge, MA 02139 USA	Tappen, MF (reprint author), MIT, Comp Sci & Artificial Intelligence Lab, Stata Ctr, Blsg 32,32 Vassar St, Cambridge, MA 02139 USA.	mtappen@csail.mit.edu; billf@mit.edu; adelson@csail.mit.edu					Barrow H. G., 1978, COMPUTER VISION SYST, P3; BELL M, 2001, P INT C COMP VIS; BESAG J, 1975, STATISTICIAN, V24, P179, DOI 10.2307/2987782; Brockington M., 1992, P 2 EUR C COMP VIS, P124; Finlayson G., 2002, P 7 EUR C COMP VIS 4, P823; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; FREEMAN WT, 1998, ADV NEURAL INFORMATI; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; GIBSON JJ, 1966, SENSES CONSIDERED PE, pCH10; Heeger D. J., 1995, P SIGGRAPH 95, P229, DOI DOI 10.1145/218380.218446; HORN BKP, 1986, ROBOT VISION, pCH9; Lafferty J., 2001, P INT C MACH LEARN I; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; LEUNG T, 1999, P IEEE INT C COMP VI; Matsushita Y., 2003, P CVPR, V1, P3; OPPENHEI.AV, 1968, IEEE T ACOUST SPEECH, VAU16, P437, DOI 10.1109/TAU.1968.1161990; PENTLAND AP, 1990, INT J COMPUT VISION, V4, P153, DOI 10.1007/BF00127815; RUBIN JM, 1982, BIOL CYBERN, V45, P215, DOI 10.1007/BF00336194; Simoncelli E., 1995, P IEEE INT C IM PROC, V3, p[444, 2], DOI 10.1109/ICIP.1995.537667; Sinha P., 1993, P 4 INT C COMP VIS, P156; TIEU K, 2000, P IEEE C COMP VIS PA, V1, P228, DOI 10.1109/CVPR.2000.855824; Weiss Y., 2001, P INT C COMP VIS; Yedidia JS, 2001, ADV NEUR IN, V13, P689	24	62	63	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2005	27	9					1459	1472		10.1109/TPAMI.2005.185		14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	944XB	WOS:000230463300008	
J	Hullermeier, E				Hullermeier, E			Experience-based decision making: A satisficing decision tree approach	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART A-SYSTEMS AND HUMANS			English	Article						bounded rationality; case-based reasoning; compilation; decision making; decision trees; machine learning	INDUCTION	This paper introduces a framework of experienced-based decision making as an extension of case-based decision making, a recently proposed alternative to expected utility theory. In experienced-based decision making, an agent faced with a new decision problem acts on the basis of experience gathered from previous problems in the past, either through predicting the utility of potential actions or through establishing a direct relationship between decision problems and appropriate actions. In the paper, a realization of the latter approach in the form of "satisficing" decision trees is proposed.	Univ Marburg, Dept Math & Comp Sci, D-35032 Marburg, Germany	Hullermeier, E (reprint author), Univ Marburg, Dept Math & Comp Sci, D-35032 Marburg, Germany.						Aha D.W., 1997, LAZY LEARNING; Allais M, 1953, ECONOMETRICA, V21, P503, DOI 10.2307/1907921; Bonet B., 1996, P 12 C UNC ART INT U, P98; BOUTILIER C, 1994, MOR KAUF R, P75; BRAFMAN R, 1997, P 14 NAT C ART INT A, P76; Brafman RI, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1291; Breiman L, 1984, CLASSIFICATION REGRE; Brodley C. E., 1993, P 10 INT C MACH LEAR, P17; Cercone N, 1999, IEEE T KNOWL DATA EN, V11, P166, DOI 10.1109/69.755625; CHATURVEDI AR, 1993, DECIS SUPPORT SYST, V10, P213, DOI 10.1016/0167-9236(93)90039-6; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; de Mantaras RL, 1998, DATA KNOWL ENG, V25, P99; Dougherty J., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning; Dubois D., 1999, Fundamenta Informaticae, V37; Dubois D., 1995, P 14 INT JOINT C ART, P1924; Dubois D, 1998, P 14 C UNC ART INT U, P121; ELLSBERG D, 1961, Q J ECON, V75, P643, DOI 10.2307/1884324; FARGIER H, 1996, KP 13 NAT C ART INT, P175; Friedman JH, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P717; Gilboa I, 1996, GAME ECON BEHAV, V15, P1, DOI 10.1006/game.1996.0056; Gilboa I, 1997, ECON THEORY, V9, P47, DOI 10.1007/BF01213442; Gilboa I, 2000, IEEE T SYST MAN CY A, V30, P85, DOI 10.1109/3468.833090; GILBOA I, 1998, P 13 EUR C ART INT, P706; Gilboa I, 2003, ECONOMETRICA, V71, P1, DOI 10.1111/1468-0262.00388; GILBOA I, 1995, Q J ECON, V110, P605, DOI 10.2307/2946694; HAUSSLER D, 1992, INFORM COMPUT, V100, P78, DOI 10.1016/0890-5401(92)90010-D; Hullermeier E., 2004, 10 INT C INF PROC MA; HULLERMEIER E, 2001, EXPERIENCE BASED DEC; Keane M. T., 1995, P 14 INT JOINT C ART, P377; Kolodner J.L., 1993, CASE BASED REASONING; March J.G., 1958, ORGANIZATIONS; Mingers J., 1989, Machine Learning, V3, DOI 10.1007/BF00116837; Mingers J., 1989, Machine Learning, V4, DOI 10.1023/A:1022604100933; PEARL J, 1993, P UAI 93, P12; Quinlan J. R., 1979, EXPERT SYSTEMS MICRO; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan R., 1993, P 10 INT C MACH LEAR, P236; Russell Stuart J., 1991, DO RIGHT THING STUDI; SABBADIN R, 1998, P 13 EUR C ART INT E, P600; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1023/A:1022661727670; Savage L., 1954, FDN STAT; Shepard D., 1968, P 1968 23 ACM NAT C, P517, DOI DOI 10.1145/800186.810616; Simon HA, 1957, MODELS MAN; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; TAN SW, 1994, MOR KAUF R, P530; TAN SW, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P928; Tversky A., 1986, J BUS, V59, P251; Utgoff P. E., 1989, Machine Learning, V4, DOI 10.1023/A:1022699900025; Vapnik V. N., 2000, NATURE STAT LEARNING; Vapnik VN, 1998, STAT LEARNING THEORY; Von Neumann J., 1953, THEORY GAMES EC BEHA; Wand MP, 1995, KERNEL SMOOTHING; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256	53	4	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1083-4427		IEEE T SYST MAN CY A	IEEE Trans. Syst. Man Cybern. Paart A-Syst. Hum.	SEP	2005	35	5					641	653		10.1109/TSMCA.2005.851145		13	Computer Science, Cybernetics; Computer Science, Theory & Methods	Computer Science	956AC	WOS:000231270300005	
J	Zhao, H; Sinha, AP				Zhao, H; Sinha, AP			An efficient algorithm for generating generalized decision forests	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART A-SYSTEMS AND HUMANS			English	Article						cascade generalization; classification; data mining; decision forest; decision tree; machine learning	CASCADE GENERALIZATION; TREES	A shortcoming of univariate decision tree learners is that they do not learn intermediate concepts and select only one of the input features in the branching decision at each intermediate tree node. It has been empirically demonstrated that cascading other classification methods, which learn intermediate concepts, with decision tree learners can alleviate such representational bias of decision trees and potentially improve classification performance. However, a more complex model that fits training data better may not necessarily perform better on unseen data, commonly referred to as the overfitting problem. To find the most appropriate degree of such cascade generalization, a decision forest (i.e., a set of decision trees with other classification models cascaded to different degrees) needs to be generated, from which the best decision tree can then be identified. In this paper, the authors propose an efficient algorithm for generating such decision forests. The algorithm uses an extended decision tree data structure and constructs any node that is common to multiple decision trees only once. The authors have empirically evaluated the algorithm using 32 data sets for classification problems from the University of California, Irvine (UCI) machine learning repository and report on results demonstrating the efficiency of the algorithm in this paper.	Univ Wisconsin, Sch Business Adm, Milwaukee, WI 53201 USA	Sinha, AP (reprint author), Univ Wisconsin, Sch Business Adm, Milwaukee, WI 53201 USA.	hzhao@uwm.edu; sinha@uwm.edu					Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Bioch JC, 1997, LECT NOTES ARTIF INT, V1263, P232; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; BRODLEY CE, 1995, MACH LEARN, V19, P45, DOI 10.1007/BF00994660; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dietterich Thomas G., 2000, P 1 INT WORKSH MULT, P1; Domingos Pedro, 2000, P 17 INT C MACH LEAR, P231; Gama J., 1999, P 16 INT C MACH LEAR, P134; Gama J, 2000, MACH LEARN, V41, P315, DOI 10.1023/A:1007652114878; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Heath D., 1993, P 13 INT JOINT C ART, P1002; Hosmer DW, 2000, APPL LOGISTIC REGRES; JOHN GH, 1996, LECT NOTES STAT, V5, P375; Kohavi R., 1996, P 13 INT C MACH LEAR, P275; Murphy M A, 1994, J Clin Neurosci, V1, P257, DOI 10.1016/0967-5868(94)90066-3; Murthy S.K., 1994, J ARTIFICIAL INTELLI, V2, P1; Murthy SK, 1998, DATA MIN KNOWL DISC, V2, P345, DOI 10.1023/A:1009744630224; Quinlan J. R., 1979, EXPERT SYSTEMS MICRO; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Weiss S. M., 1991, COMPUTER SYSTEMS LEA; Witten I. H., 2000, DATA MINING PRACTICA; Yildiz O.T., 2000, P 17 INT C MACH LEAR, P1175; Zhao HM, 2004, IEEE T KNOWL DATA EN, V16, P727, DOI 10.1109/TKDE.2004.3	26	8	10	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4427		IEEE T SYST MAN CY A	IEEE Trans. Syst. Man Cybern. Paart A-Syst. Hum.	SEP	2005	35	5					754	762		10.1109/TSMCA.2005.843392		9	Computer Science, Cybernetics; Computer Science, Theory & Methods	Computer Science	956AC	WOS:000231270300015	
J	Trotman, A				Trotman, A			Learning to rank	INFORMATION RETRIEVAL			English	Article						searching; document ranking; genetic programming; machine learning	TEXT RETRIEVAL	New general purpose ranking functions are discovered using genetic programming. The TREC WSJ collection was chosen as a training set. A baseline comparison function was chosen as the best of inner product, probability, cosine, and Okapi BM25. An elitist genetic algorithm with a population size 100 was run 13 times for 100 generations and the best performing algorithms chosen from these. The best learned functions, when evaluated against the best baseline function (BM25), demonstrate some significant performance differences, with improvements in mean average precision as high as 32% observed on one TREC collection not used in training. In no test is BM25 shown to significantly outperform the best learned function.	Univ Otago, Dept Comp Sci, Dunedin, New Zealand	Trotman, A (reprint author), Univ Otago, Dept Comp Sci, Dunedin, New Zealand.	andrew@cs.otago.ac.nz	Trotman, Andrew/A-4918-2008				ANH VN, 2002, AUSTR COMPUTER SCI C, V24, P41; Buckley C, 1991, TREC EVAL; Buckley C., 2000, P 23 ANN INT ACM SIG, P33, DOI 10.1145/345508.345543; Clarke CLA, 2000, INFORM PROCESS MANAG, V36, P291, DOI 10.1016/S0306-4573(99)00017-5; de Jong K. A., 1975, THESIS U MICHIGAN; FAN W, 2004, P 37 ANN HAW INT C S; FAN W, 1999, P 1999 AM C INF SYST; Fan WG, 2004, INFORM PROCESS MANAG, V40, P587, DOI 10.1016/j.ipm.2003.08.001; GREFENSTETTE JJ, 1986, IEEE T SYST MAN CYB, V16, P122, DOI 10.1109/TSMC.1986.289288; HARMAN D, 1992, INFORMATION RETRIEVA, P363; Harman D., 1993, P 16 ANN INT ACM SIG, P36, DOI 10.1145/160688.160692; HART WE, 1996, ADAPTIVE INDIVIDUALS, P483; HAWKING D, 1999, P 8 INT WORLD WID WE, P1321; Heitkotter J., 1994, P 22 ANN ACM COMP SC, P66, DOI 10.1145/197530.197558; HOLLAND JH, 1975, ADAPTATION NATURAL A; Igel C., 1999, P GEN EV COMP C GECC, P1061; JONES S, 1999, P 8 TEXT RETRIEVAL C; Kaszkiel M., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.291031; Kekalainen J, 2002, J AM SOC INF SCI TEC, V53, P1120, DOI 10.1002/asi.10137; Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140; Koza J. R., 1992, GENETIC PROGRAMMING; OREN N, 2002, P SAICSIT, P224; OREN N, 2002, THESIS U WITWATERSRA; Page L., 1998, PAGERANK CITATION RA; Possas B., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval; Raghavan V. V., 1983, Proceedings of the Sixth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval; Robertson S. E., 1995, P 4 TEXT RETR C TREC; Robertson SE, 1994, P 3 TEXT RETR C TREC, P109; ROBERTSON SE, 1976, J AM SOC INFORM SCI, V27, P129, DOI 10.1002/asi.4630270302; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; SAVOY J, 1995, P 4 TEXT RETRIEVAL C, P537; SHAW WM, 1991, LIBR INFORM SCI RES, V13, P347; SMART W, 2004, P 2 WORKSH AUSTR INF; TONGCHIM S, 2000, P 5 INT S ART LIF RO, P251; Williams HE, 1999, COMPUT J, V42, P193, DOI 10.1093/comjnl/42.3.193; Witten Ian H., 1994, MANAGING GIGABYTES C; Zobel J., 1998, SIGIR Forum, V32; ZOBEL J, 1995, SOFTWARE PRACT EXPER, V25, P891, DOI 10.1002/spe.4380250804; Zobel J, 1998, ACM T DATABASE SYST, V23, P453, DOI 10.1145/296854.277632	40	19	19	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1386-4564		INFORM RETRIEVAL	Inf. Retr.	SEP	2005	8	3					359	381		10.1007/s10791-005-6991-7		23	Computer Science, Information Systems	Computer Science	907NW	WOS:000227725800001	
J	Metzler, D; Croft, WB				Metzler, D; Croft, WB			Analysis of statistical question classification for fact-based questions	INFORMATION RETRIEVAL			English	Article						question classification; question answering; machine learning; Support Vector Machines; syntactic features; semantic features; WordNet		Question classification systems play an important role in question answering systems and can be used in a wide range of other domains. The goal of question classification is to accurately assign labels to questions based on expected answer type. Most approaches in the past have relied on matching questions against hand-crafted rules. However, rules require laborious effort to create and often suffer from being too specific. Statistical question classification methods overcome these issues by employing machine learning techniques. We empirically show that a statistical approach is robust and achieves good performance on three diverse data sets with little or no hand tuning. Furthermore, we examine the role different syntactic and semantic features have on performance. We find that semantic features tend to increase performance more than purely syntactic features. Finally, we analyze common causes of misclassification error and provide insight into ways they may be overcome.	Univ Massachusetts, Amherst, MA 01003 USA	Metzler, D (reprint author), Univ Massachusetts, Amherst, MA 01003 USA.						Bikel D. M., 1999, MACH LEARN, V34, P211; BROWN PF, 1991, M ASS COMP LING, P264; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CHINCHOR NA, 1998, P MUC 7; COLLINS M, 2002, ADV NEURAL INFORMATI, V14; Davidov D., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/1008992.1009036; DellaPietra S, 1997, IEEE T PATTERN ANAL, V19, P380, DOI 10.1109/34.588021; Fellbaum C., 2000, WORDNET ELECT LEXICA; HOVY E, 2002, HUM LANG TECHN C HLT; Hovy E., 2001, P DARPA HUM LANG TEC; Hull D., 1999, P 8 TEXT RETR C TREC; ITTYCHERIAH A, 2000, P 9 TEXT RETR C TREC; Joachims T., 1998, ADV KERNEL METHODS; Lee SY, 2003, J IND ENG CHEM, V9, P9; LI X, 2002, P 19 INT C COMP LING; McCallum A., 1998, AAAI 98 WORKSH LEARN; Morik K, 1999, P 16 INT C MACH LEAR, P268; Murdock V., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval; Nigam K., 1999, P IJCAI 99 WORKSH MA, P61; Niles I, 2001, P 2 INT C FORM ONT I, P2; NYBERG E, 2003, P 12 TEXT RETR C TRE; PASCA M, 2001, RES DEV INFORMATION, P366; POMERANTZ J, IN PRESS INFORMATION; PRAGER J, 1999, P 8 TEXT RETR C TREC; PRAGER J, 2001, P HUM LANG TECHN C, P26; RADEV D, 2002, 2002 WWW C; Ratnaparkhi A., 1996, P C EMP METH NAT LAN, P133; Rosenfeld R, 1996, COMPUT SPEECH LANG, V10, P187, DOI 10.1006/csla.1996.0011; Vapnick V. N., 1998, STAT LEARNING THEORY; Voorhees E. M., 2000, P 9 TEXT RETR C TREC; VOORHEES EM, 2001, P 10 TEXT RETR C TRE; Yang Yiming, 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; Zhang D., 2003, P 26 ANN INT ACM SIG, P26; [Anonymous], 1999, P 8 TEXT RETR C TREC	34	27	27	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1386-4564		INFORM RETRIEVAL	Inf. Retr.	SEP	2005	8	3					481	504		10.1007/s10791-005-6995-3		24	Computer Science, Information Systems	Computer Science	907NW	WOS:000227725800005	
J	Mustiere, S				Mustiere, S			Cartographic generalization of roads in a local and adaptive approach: A knowledge acquistion problem	INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE			English	Article						cartographic generalization; knowledge acquistion; line generalization; machine learning		This paper presents a local and adaptive approach to road generalization, where different algorithms may be successively applied to each part of a road. The specific problem addressed is how to acquire and formalize cartographic knowledge in order to guide the application of the algorithms during the process. Our approach requires toolboxes of algorithms to transform and analyse the data, as well as an engine to chain them together. First, we present the toolboxes used in our experiments for road generalization. Then, we present two different engines, as well as the knowledge-acquisition processes used to determine them. The first engine, named GALBE, is an empirically determined process, where the application of algorithms is mainly based on a single criterion: the coalescence. The second engine, which is more complex, uses multiple measures to describe the road. The choice of which algorithm to use given a particular set of measures is determined from examples using supervised learning techniques. Results obtained with both engines are presented.	IGN, Cogit Lab, F-94165 St Mande, France	Mustiere, S (reprint author), IGN, Cogit Lab, 2 Ave Pasteur, F-94165 St Mande, France.	sebastien.mustiere@ign.fr	Wright, Dawn/A-4518-2011	Wright, Dawn/0000-0002-2997-7611			Bader M., 2001, THESIS U ZURICH; BARRAULT M, 2001, P 20 INT CART C BEIJ, V3, P2110; BROPHY M, 1973, P AM C SURV MAPP, P300; BUTTENFIELD B, 1984, THESIS U WASHINGTON; Cohen W. W., 1995, P 12 INT C MACH LEAR, P115; DAVID JM, 1993, 2 GENERATION EXPERT; DEBENEDETTI VMG, 1995, CANCER EPIDEM BIOMAR, V4, P79; DOUGENIK J, 1980, P AUTO CARTO 4, V4, P304; Douglas D., 1973, CANADIAN CARTOGRAPHE, V10, P112, DOI DOI 10.3138/FM57-6770-U75U-7727; FRITSCH E, 1997, THESIS U MARNE LA VA; HARRIE L, 2000, INT ARCH PHOTOGRA B4, V33, P348; Kilpelainen T., 2000, CARTOGR GEOGR INF SC, V27, P41, DOI 10.1559/152304000783547993; LANG T, 1969, GEOGR MAG, V42, P50; Lecordix F, 1997, GEOINFORMATICA, V1, P161, DOI 10.1023/A:1009736628698; LOWE DG, 1988, P 2 INT C COMP VIS, P558; MCMASTER R, 1983, THESIS U KANSAS; McMaster R B, 1989, CARTOGRAPHICA, V26, P101, DOI 10.3138/C213-3627-90X7-LR15; Mitchell T, 1997, MACHINE LEARNING; MUSTIERE S, 2000, P 9 INT S SPAT DAT H, P50; MUSTIERE S, 1998, P U GIS PLANET C LIS; MUSTIERE S, 2001, THESIS U PARIS 6 JUS; PLAZANET C, 1996, THESIS U MARNE LA VA; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Ruas A., 1996, P 7 SPAT DAT HANDL S, P319; RUAS A, 1999, THESIS U MARNE LA VA; SAAFELD A, 1999, CARTOGRAPHY GEOGRAPH, V26, P7; Sester M., 2000, INT ARCH PHOTOGRA B4, VXXXIII, P931; THOMAS J, 1996, THESIS U P M CURIE P; WEIBEL R, 1996, P 7 INT S SPAT DAT H, V2, P1; WEIBEL R, 1995, P 2 INT C SPAT INF T, P139; WEIBEL R, 1991, MAP GEN MAKING RULES, P86; ZHANG L, 1997, P 18 INT CART C STOC, V2, P831	32	14	15	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1365-8816		INT J GEOGR INF SCI	Int. J. Geogr. Inf. Sci.	SEP-OCT	2005	19	8-9					937	955		10.1080/136588105099161245		19	Computer Science, Information Systems; Geography; Geography, Physical; Information Science & Library Science	Computer Science; Geography; Physical Geography; Information Science & Library Science	975KM	WOS:000232661400005	
J	Liu, J; Li, M				Liu, J; Li, M			Finding cancer biomarkers from mass spectrometry data by decision lists	JOURNAL OF COMPUTATIONAL BIOLOGY			English	Article						decision lists; biomarkers; mass spectrometry; cancer diagnosis; machine learning	ARTIFICIAL NEURAL-NETWORKS; DISEASE CLASSIFICATION; PROTEOMIC PATTERNS; SERUM; IDENTIFICATION	Finding accurate biomarkers is key to early diagnosis and successful treatment of many otherwise incurable diseases. In this work, we study the problem of finding biomarkers through mass spectrometry (SELDI-TOF) spectra from cancerous and normal tissues. In contrast to the common practice of using vague methods such as genetic algorithms, or uninterpretable methods such as Support Vector Machines, we look for a method that is simple, intuitive, interpretable, usable, and more accurate. We introduce decision lists to this domain. Our experiments on clinical cancer datasets demonstrate that decision lists can achieve more accurate results than other methods. More interestingly, the resulting decision lists are more interpretable for possible causal relationship between cancer and differentially expressed proteins, and directly usable in clinical biomarker design. In particular, our approach is capable of finding multiple biomarkers with high sensitivity and specificity. Such a feature will provide clues for medical experts to thoroughly investigate the roles of protein in cancer development and progression.	Univ Waterloo, Sch Comp Sci, Waterloo, ON N2L 3G1, Canada; McGill Univ, Dept Biomed Engn, Montreal, PQ H3A 2B4, Canada; City Univ Hong Kong, Hong Kong, Hong Kong, Peoples R China; Tsing Hua Univ, Beijing 100084, Peoples R China	Liu, J (reprint author), Univ Waterloo, Sch Comp Sci, Waterloo, ON N2L 3G1, Canada.	mli@uwaterloo.ca					Adam BL, 2002, CANCER RES, V62, P3609; Ball G, 2002, BIOINFORMATICS, V18, P395, DOI 10.1093/bioinformatics/18.3.395; Chen YD, 2004, CLIN CANCER RES, V10, P8380, DOI 10.1158/1078-0432.CCR-1162-03; Conrods TP, 2003, EXPERT REV MOL DIAGN, V3, P411, DOI 10.1586/14737159.3.4.411; Cristianini N., 2000, INTRO SUPPORT VECTOR; Goodacre R, 1999, FEMS MICROBIOL LETT, V176, P17, DOI 10.1016/S0378-1097(99)00212-8; Hanash S, 2003, NATURE, V422, P226, DOI 10.1038/nature01514; Hancock T, 1996, INFORM COMPUT, V126, P114, DOI 10.1006/inco.1996.0040; Li JN, 2002, CLIN CHEM, V48, P1296; Lilien RH, 2003, J COMPUT BIOL, V10, P925, DOI 10.1089/106652703322756159; LIU Q, 2003, P BIOL ASP SIGN PROC; Miketova P, 2003, J ANAL APPL PYROL, V67, P109, DOI 10.1016/S0165-2370(02)00019-0; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Rivest R. L., 1987, Machine Learning, V2, DOI 10.1007/BF00058680; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Wagner M, 2003, PROTEOMICS, V3, P1692, DOI 10.1002/pmic.200300519; WAGNER MD, 2004, BMC BIOINFORMATICS, V5; Xiong MM, 2001, GENOME RES, V11, P1878; 2003, CLIN PROTEOMICS PROG	19	5	5	MARY ANN LIEBERT INC	NEW ROCHELLE	140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA	1066-5277		J COMPUT BIOL	J. Comput. Biol.	SEP	2005	12	7					971	979		10.1089/cmb.2005.12.971		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	971LS	WOS:000232386200005	
J	Chen, YT; Jeng, B				Chen, YT; Jeng, B			MFILM: a multi-dimensional fuzzy inductive learning method	JOURNAL OF EXPERIMENTAL & THEORETICAL ARTIFICIAL INTELLIGENCE			English	Article						inductive learning; machine learning; expert systems; multi-dimensional decision tree	EXPERT SYSTEM	Inductive learning that creates a decision tree from a set of existing examples is shown to be useful for automated knowledge acquisition. Most of the existing methods however, handle only single-dimensional decision problems. Only some methods can deal with multi-dimensional decision problems. However, they are based on crisp concepts that are weak in handling marginal cases. In this paper, we present a multidimensional fuzzy inductive learning method that integrates the fuzzy set theory into the conventional multi-dimensional decision tree induction methods. The method converts a multi-dimensional decision tree into a fuzzy multi-dimensional decision tree in which hurdle values for splitting branches and classes associated with leaves are fuzzy. Results from empirical tests indicate that the new fuzzy approach outperforms the other conventional methods.	Acad Sinica, Inst Informat Sci, Taipei, Taiwan; Natl Sun Yat Sen Univ, Dept Informat Management, Kaohsiung 80424, Taiwan	Chen, YT (reprint author), Acad Sinica, Inst Informat Sci, Taipei, Taiwan.	ytchen@mail.iis.sinica.edu.tw					Babic S. H., 1999, Proceedings 12th IEEE Symposium on Computer-Based Medical Systems (Cat. No.99CB36365), DOI 10.1109/CBMS.1999.781262; Blake CL, UCI REPOSITORY MACHI; BRAUN H, 1987, DECISION SCI, V18, P415, DOI 10.1111/j.1540-5915.1987.tb01533.x; CARTER C, 1987, IEEE EXPERT, V2, P71, DOI 10.1109/MEX.1987.4307093; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; CARUANA R, 1997, CMUCS97203; CHUNG HMM, 1992, DECISION SCI, V23, P687, DOI 10.1111/j.1540-5915.1992.tb00412.x; Fisher RA, 1936, ANN EUGENIC, V7, P179; FOROURAGHI B, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P607; HUNT E, 1996, EXPT INDUCTION; JENG B, 1993, P 1 AS FUZZ SYST S S; JENG BC, 1995, EXPERT SYST APPL, V8, P135, DOI 10.1016/0957-4174(94)E0004-E; Jeng BC, 1997, DECIS SUPPORT SYST, V21, P61, DOI 10.1016/S0167-9236(97)00019-5; Kendall M. G., 1980, MULTIVARIATE ANAL; Kibler D., 1989, Computational Intelligence, V5, DOI 10.1111/j.1467-8640.1989.tb00315.x; Klir G.J., 1988, FUZZY SETS UNCERTAIN; LIANG T, 1990, EXPERT SYSTEMS APPL, V1, P391, DOI 10.1016/0957-4174(90)90048-Y; Liang T., 1992, CONTEMP ACCOUNT RES, V9, P306; LIU SOR, 2000, DECIS SUPPORT SYST, V30, P105; MESSIER WF, 1988, MANAGE SCI, V34, P1403, DOI 10.1287/mnsc.34.12.1403; Michalski R. S., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; PATERSON A, 1982, ACLS USER MANUAL; Quinlan J. R., 1979, EXPERT SYSTEMS MICRO; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; REICH Y, 1990, P 1 INT WORKSH FORM, P330; SHAW MJ, 1988, FINANC MANAGE, V17, P45, DOI 10.2307/3666071; Suzuki Einoshin, 2001, LECT NOTES ARTIF INT, P436; WNEK J, 1990, COMP LEARNING PARADI; YAGER RR, 1980, FUZZY SET SYST, V4, P235, DOI 10.1016/0165-0114(80)90013-5; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	31	8	8	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0952-813X		J EXP THEOR ARTIF IN	J. Exp. Theor. Artif. Intell.	SEP	2005	17	3					267	281		10.1080/09528130500281828		15	Computer Science, Artificial Intelligence	Computer Science	979JL	WOS:000232938100005	
J	Boulle, M				Boulle, M			A Bayes optimal approach for partitioning the values of categorical attributes	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						data preparation; grouping; Bayesianism; model selection; classification; naive Bayes	DISCRETIZATION	In supervised machine learning, the partitioning of the values (also called grouping) of a categorical attribute aims at constructing a new synthetic attribute which keeps the information of the initial attribute and reduces the number of its values. In this paper, we propose a new grouping method MODL1 founded on a Bayesian approach. The method relies on a model space of grouping models and on a prior distribution defined on this model space. This results in an evaluation criterion of grouping, which is minimal for the most probable grouping given the data, i.e. the Bayes optimal grouping. We propose new super-linear optimization heuristics that yields near-optimal groupings. Extensive comparative experiments demonstrate that the MODL grouping method builds high quality groupings in terms of predictive quality, robustness and small number of groups.	France Telecom, R&D, F-22300 Lannion, France	Boulle, M (reprint author), France Telecom, R&D, 2 Ave Pierre Marzin, F-22300 Lannion, France.	MARC.BOULLE@FRANCETELECOM.COM					ASSERAF M, 2000, INT C HUM SYST LEARN; BERCKMAN NC, 1995, VALUE GROUPING BINAR; Bernardo J., 1994, BAYESIAN THEORY; Blake C. L., 1998, UCI REPOSITORY MACHI; BOULLE M, 2004, RNTI E 2, V2, P173; Boulle M, 2004, MANAG INFORMAT SYST, V10, P199; Boulle M, 2004, MACH LEARN, V55, P53, DOI 10.1023/B:MACH.0000019804.29836.05; Breiman L, 1984, CLASSIFICATION REGRE; CESTNIK B, 1987, PROGR MACHINE LEARNI; CHOU PA, 1991, IEEE T PATTERN ANAL, V13, P340, DOI 10.1109/34.88569; Dietterich T. G., 1998, NEURAL COMPUTATION, V10; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; Fulton T., 1995, P 12 INT C MACH LEAR, P244; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; Hsu CN, 2003, MACH LEARN, V53, P235, DOI 10.1023/A:1026367023636; Kass G. V., 1980, APPL STATIST, V29, P119, DOI DOI 10.2307/2986296; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.2307/2291091; KERBER R, 1991, P 10 INT C ART INT, P123; Kullback S., 1968, INFORM THEORY STAT; Langley P., 1992, P 10 NAT C ART INT, P223; LECHEVALLIER Y, 1990, 1247 INRIA; Pyle Dorian, 1999, DATA PREPARATION DAT; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; RITSCHARD G, 2003, REVUE NOUVELLES TECH, V1, P99; RITSCHARD G, 2001, MATH SCI HUM, V155, P81; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SPSS, 2001, ANSW TREE 3 0 US GUI; YANG Y, 2003, P 16 AUSTR JOINT C A; ZIGHED DA, 2000, GRAPHES INDUCTION, P327	30	14	14	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	SEP	2005	6						1431	1452				22	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026HN	WOS:000236330100007	
J	Tsochantaridis, I; Joachims, T; Hofmann, T; Altun, Y				Tsochantaridis, I; Joachims, T; Hofmann, T; Altun, Y			Large margin methods for structured and interdependent output variables	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article							ALGORITHM	Learning general functional dependencies between arbitrary input and output spaces is one of the key challenges in computational intelligence. While recent progress in machine learning has mainly focused on designing flexible and powerful input representations, this paper addresses the complementary issue of designing classification algorithms that can deal with more complex outputs, such as trees, sequences, or sets. More generally, we consider problems involving multiple dependent output variables, structured output spaces, and classification problems with class attributes. In order to accomplish this, we propose to appropriately generalize the well-known notion of a separation margin and derive a corresponding maximum-margin formulation. While this leads to a quadratic program with a potentially prohibitive, i.e. exponential, number of constraints, we present a cutting plane algorithm that solves the optimization problem in polynomial time for a large class of problems. The proposed method has important applications in areas such as computational biology, natural language processing, information retrieval/extraction, and optical character recognition. Experiments from various domains involving different types of output spaces emphasize the breadth and generality of our approach.	Google Inc, Mountain View, CA 94043 USA; Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA; Tech Univ Darmstadt, Fraunhofer IPSI, D-64287 Darmstadt, Germany; Toyota Technol Inst, Chicago, IL 60637 USA	Tsochantaridis, I (reprint author), Google Inc, Mountain View, CA 94043 USA.	IOANNIS@GOOGLE.COM; TJ@CS.CORNELL.EDU; HOFMANN@INT.TU-DARMSTADT.DE; ALTUN@TTI-C.ORG					ALTUN Y, 2003, P  12 INT C MACH LEA; CAI L, 2004, P ACM 13 C INF KNOWL; Cohen WW, 1999, J ARTIF INTELL RES, V10, P243; COLLINS M, 2000, P 17 INT C MACH LEAR; Collins M, 2002, ADV NEUR IN, V14, P625; COLLINS M, 2002, P 14 ANN M ASS COMP; Collins M, 2002, P C EMP METH NAT LAN; Crammer K, 2001, J MACHINE LEARNING R, V2, P265; CRAMMER K, 2002, ADV NEURAL INFORM PR, V14; Durbin R, 1998, BIOL SEQUENCE ANAL; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; GROTSCHEL M, 1981, COMBINATORICA, V1, P169, DOI 10.1007/BF02579273; HARPELED S, 2002, ADV NEURAL INFORM PR, V14; Herbrich R., 2000, ADV LARGE MARGIN CLA, P115; HOFMANN T, 2002, P 6 KERN WORKSH; JOACHIMS T., 2002, P ACM C KNOWL DISC D; Joachims T., 2005, P 22 INT C MACH LEAR; JOACHIMS T, 2003, LEARNING ALIGN SEQUE; Johnson M, 1998, COMPUT LINGUIST, V24, P613; KARMARKAR N, 1984, COMBINATORICA, V4, P373, DOI 10.1007/BF02579150; KELLEY JE, 1960, J SOC IND APPL MATH, V8, P703; Lafferty J., 2001, P 18 INT C MACH LEAR, P282; Manning C. D., 1999, FDN STAT NATURAL LAN; Ristad E.S., 1997, P 14 INT C MACH LEAR, P287; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Schwartz R., 1990, P IEEE INT C AC SPEE, P81; SMOLA A, 2003, EXPONENTIAL FAMILIES; TASKAR B, 2004, P C EMP METH NAT LAN; Taskar Ben, 2004, ADV NEURAL INFORM PR; Tsochantaridis I., 2004, P 21 INT C MACH LEAR; Vapnik VN, 1998, STAT LEARNING THEORY; WESTON J, 2003, ADV NEURAL INFORM PR, V15; Weston J, 1998, CSDTR9804; YOUNGER DH, 1967, INFORM CONTROL, V10, P189, DOI 10.1016/S0019-9958(67)80007-X	34	269	279	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	SEP	2005	6						1453	1484				32	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026HN	WOS:000236330100008	
J	Brown, G; Wyatt, JL; Tino, P				Brown, G; Wyatt, JL; Tino, P			Managing diversity in regression ensembles	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						ensemble; diversity; regression estimators; neural networks; hessian matrix; negative correlation learning		Ensembles are a widely used and effective technique in machine learning - their success is commonly attributed to the degree of disagreement, or 'diversity', within the ensemble. For ensembles where the individual estimators output crisp class labels, this 'diversity' is not well understood and remains an open research issue. For ensembles of regression estimators, the diversity can be exactly formulated in terms of the covariance between individual estimator outputs, and the optimum level is expressed in terms of a bias-variance-covariance trade-off. Despite this, most approaches to learning ensembles use heuristics to encourage the right degree of diversity. In this work we show how to explicitly control diversity through the error function. The first contribution of this paper is to show that by taking the combination mechanism for the ensemble into account we can derive an error function for each individual that balances ensemble diversity with individual accuracy. We show the relationship between this error function and an existing algorithm called negative correlation learning, which uses a heuristic penalty term added to the mean squared error function. It is demonstrated that these methods control the bias-variance-covariance trade-off systematically, and can be utilised with any estimator capable of minimising a quadratic error function, for example MLPs, or RBF networks. As a second contribution, we derive a strict upper bound on the coefficient of the penalty term, which holds for any estimator that can be cast in a generalised linear regression framework, with mild assumptions on the basis functions. Finally we present the results of an empirical study, showing significant improvements over simple ensemble learning, and finding that this technique is competitive with a variety of methods, including boosting, bagging, mixtures of experts, and Gaussian processes, on a number of tasks.	Univ Birmingham, Sch Comp Sci, Birmingham B15 2TT, W Midlands, England	Brown, G (reprint author), Univ Birmingham, Sch Comp Sci, Birmingham B15 2TT, W Midlands, England.	G.BROWN@CS.BHAM.AC.UK; J.L.WYATT@CS.BHAM.AC.UK; P.TINO@CS.BHAM.AC.UK					Brown G., 2005, J INFORM FUSION, V6, P5; BROWN G, 2005, LNCS, V3541; BROWN G., 2004, THESIS U BIRMINGHAM; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Fumera G, 2003, LECT NOTES COMPUT SC, V2709, P74; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; HANSEN JV, 2000, THESIS AARHUS UI DAT; Krogh A, 1995, NIPS, V7, P231; Kuncheva L., 2003, MACH LEARN, P181; LIU Y, 2000, IEEE T EVOLUTIONARY, V4; LIU Y, 1998, THESIS U COLLEGE U N; Liu Y., 1997, AUSTR J INTELLIGENT, V4, P176; Markowitz H, 1952, J FINANCE, V7; McKay R, 2001, P 2001 C ART NEUR NE, P22; PERRONE MP, 1993, THESIS BROWN U I BRA; Rosen B. E., 1996, Connection Science, V8, DOI 10.1080/095400996116820; Sollich P, 1996, ADV NEUR IN, V8, P190; Tino P, 2004, J CHEM INF COMP SCI, V44, P1647, DOI 10.1021/ci034255i; TUMER K, 1995, TR950298 U TEX COMP; UEDA N, 1996, P INT C NEUR NETW, P90; YAO X, 2001, P INT JOINT C NEUR N, P693	21	63	65	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	SEP	2005	6						1621	1650				30	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026HN	WOS:000236330100013	
J	Goodacre, R				Goodacre, R			Biomarker discovery using metabolomics and explanatory machine learning.	JOURNAL OF MEDICAL GENETICS			English	Meeting Abstract	British Human Genetics Conference	SEP 12-14, 2005	York, ENGLAND	British Soc Human Genet	Univ York				Univ Manchester, Sch Chem, Manchester M13 9PL, Lancs, England		Roy.Goodacre@manchester.ac.uk	Goodacre, Roy/J-1600-2012	Goodacre, Roy/0000-0003-2230-645X				0	1	1	B M J PUBLISHING GROUP	LONDON	BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND	0022-2593		J MED GENET	J. Med. Genet.	SEP	2005	42			1			S16	S16				1	Genetics & Heredity	Genetics & Heredity	966GV	WOS:000232009000003	
J	Liu, Y; Schumann, M				Liu, Y; Schumann, M			Data mining feature selection for credit scoring models	JOURNAL OF THE OPERATIONAL RESEARCH SOCIETY			English	Article						insurance; risk; credit scoring; classification algorithms; feature selection		The features used may have an important effect on the performance of credit scoring models. The process of choosing the best set of features for credit scoring models is usually unsystematic and dominated by somewhat arbitrary trial. This paper presents an empirical study of four machine learning feature selection methods. These methods provide an automatic data mining technique for reducing the feature space. The study illustrates how four feature selection methods -'ReliefF','Correlation-based', 'Consistency-based' and 'Wrapper' algorithms help to improve three aspects of the performance of scoring models: model simplicity, model speed and model accuracy. The experiments are conducted on real data sets using four classification algorithms -'model tree (M5)', 'neural network (multi-layer perceptron with back-propagation)', 'logistic regression', and 'k-nearest-neighbours'.	Univ Gottingen, D-3400 Gottingen, Germany	Liu, Y (reprint author), Jilin Univ, Sch Business, 10 Qianwei Rd, Changchun, Peoples R China.	yliuddff@hotmail.com					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Cios K, 1998, DATA MINING METHODS; Dash M, 2000, LECT NOTES ARTIF INT, V1805, P98; Hall M., 2000, P 17 INT C MACH LEAR, P359; Hall M., 1997, P 4 INT C NEUR INF P, P855; HALL MA, 2000, 0010 U WAIK DEP COMP; Hand DJ, 1997, J R STAT SOC A STAT, V160, P523, DOI 10.1111/j.1467-985X.1997.00078.x; Kira K, 1992, P 9 INT C MACH LEARN, P249; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kononenko I., 1994, P EUR C MACH LEARN, P171; Liu H, 1998, FEATURE SELECTION KN; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; Witten I. H., 2000, DATA MINING PRACTICA	13	11	11	PALGRAVE MACMILLAN LTD	BASINGSTOKE	BRUNEL RD BLDG, HOUNDMILLS, BASINGSTOKE RG21 6XS, HANTS, ENGLAND	0160-5682		J OPER RES SOC	J. Oper. Res. Soc.	SEP	2005	56	9					1099	1108		10.1057/palgrave.jors.2601976		10	Management; Operations Research & Management Science	Business & Economics; Operations Research & Management Science	952IL	WOS:000230997100011	
J	Richter, MM; Aamodt, A				Richter, MM; Aamodt, A			Case-based reasoning foundations	KNOWLEDGE ENGINEERING REVIEW			English	Review							FRAMEWORK; KNOWLEDGE; SYSTEM	A basic observation is that case-based reasoning has roots in different disciplines: cognitive science, knowledge representation and processing, machine learning and mathematics. As a consequence, there are foundational aspects from each of these areas. We briefly discuss them and comment oil the relations between these types of foundations.	TU Kaiserslautern, FB Informat, D-67653 Kaiserslautern, Germany; Norwegian Univ Sci & Technol, Dept Comp & Informat Sci, N-7491 Trondheim, Norway	Richter, MM (reprint author), TU Kaiserslautern, FB Informat, POB 3049, D-67653 Kaiserslautern, Germany.	richter@informatik.uni-kl.de; agnar.aamodt@idi.ntnu.no					AAMODT A, 1994, AI COMMUN, V7, P39; AAMODT A, 1994, PROC INT C TOOLS ART, P836, DOI 10.1109/TAI.1994.346389; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BARTLETT F. C., 1932, REMEMBERING STUDY EX; Carbonell J., 1986, MACHINE LEARNING ART, VII, P371; Diaz-Agudo B, 2001, LECT NOTES ARTIF INT, V2080, P158; Falkenheiner B., 1990, ARTIF INTELL, V41, P1; FORBUS K, 2001, ANALOGY PERSPECTIVES, P24; GENTNER D, 1983, COGNITIVE SCI, V7, P155, DOI 10.1207/s15516709cog0702_3; GLOBIG C, 1997, NEW GENERAT COMPUT, V15, P57; HAMMER B, 2002, ADAPTIVITY LEARNING, P141; KEANE MT, 1994, LECT NOTES ARTIF INT, V837, P21; KIBLER MK, 1987, P 4 INT WORKSH MACH, P24; Kolodner J. L., 1996, CASE BASED REASONING, P31; KOLODNER JL, 1983, COGNITIVE SCI, V7, P281, DOI 10.1207/s15516709cog0704_2; KOLODNER JL, 1986, EXPERIENCE MEMORY RE; Kolodner J.L., 1993, CASE BASED REASONING; Koton P, 1988, P AAAI 88, P256; LEAKE D, 1988, P AAAI 88, P251; Plaza E, 1995, LECT NOTES ARTIF INT, V1010, P265; PORTER BW, 1990, ARTIF INTELL, V45, P229, DOI 10.1016/0004-3702(90)90041-W; RICHTER MM, 2005, IN PRESS KNOWLEDGE C; RICHTER MM, 1995, ICCBR95 SES PORT; ROTHBERGHOFER T, 2002, THESIS U KAISERSLAUT; Schank R. C., 1982, DYNAMIC MEMORY; Smith E. E., 1981, CATEGORIES CONCEPTS; Tulving E., 1972, ORG MEMORY; Wess S., 1994, Topics in Case-Based Reasoning. First European Workshop, EWCBR-93. Selected Papers	28	6	6	CAMBRIDGE UNIV PRESS	NEW YORK	40 WEST 20TH ST, NEW YORK, NY 10011-4211 USA	0269-8889		KNOWL ENG REV	Knowl. Eng. Rev.	SEP	2005	20	3					203	207		10.1017/S0269888906000695		5	Computer Science, Artificial Intelligence	Computer Science	049PF	WOS:000238027800002	
J	Fung, P; Roth, D				Fung, P; Roth, D			Guest editors introduction: Machine learning in speech and language technologies	MACHINE LEARNING			English	Editorial Material									Hong Kong Univ Sci & Technol, Dept Elect & Elect Engn, Hong Kong, Peoples R China; Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA	Fung, P (reprint author), Hong Kong Univ Sci & Technol, Dept Elect & Elect Engn, Hong Kong, Peoples R China.	pascale@ee.ust.hk; danr@cs.uiuc.edu					CARRERAS X, 2004, CONLL C NAT LANG LEA; Church K. W., 1993, COMPUTATIONAL LINGUI, V19.1, P1; CHURCH KW, 1988, ANLP C APPL NAT LANG; COLLINS M, 2002, P ANN M ACL; COLLINS M, 2002, EMNLP C EMPR METH NA; COLLINS M, 2001, P INT WORKSH PARS TE; CUMBY C, 2003, P INT C MACH LEARN; KINGSBURY P, 2002, P LREC; KUDO T, 2003, P ANN M ACL; Lafferty J., 2001, P 18 INT C MACH LEAR, P282; MCCALLUM A, 2000, P INT C MACH LEARN S; PUNYAKANOK V, 2001, ADV NEURAL INFORMATI, V13; PUNYAKANOK V, 2005, P INT JOINT C ART IN; Roth D., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Roth D, 1999, P INT JOINT C ART IN, P898	15	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	SEP	2005	60	1-3					5	9		10.1007/s10994-005-1399-6		5	Computer Science, Artificial Intelligence	Computer Science	958BW	WOS:000231420700001	
J	Pradhan, S; Hacioglu, K; Krugler, V; Ward, W; Martin, J; Jurafsky, D				Pradhan, S; Hacioglu, K; Krugler, V; Ward, W; Martin, J; Jurafsky, D			Support vector learning for semantic argument classification	MACHINE LEARNING			English	Article						shallow semantic parsing; support vector machines		The natural language processing community has recently experienced a growth of interest in domain independent shallow semantic parsing-the process of assigning a WHO did WHAT to WHOM, WHEN, WHERE, WHY, How etc. structure to plain text. This process entails identifying groups of words in a sentence that represent these semantic arguments and assigning specific labels to them. It could play a key role in NLP tasks like Information Extraction, Question Answering and Summarization. We propose a machine learning algorithm for semantic role parsing, extending the work of Gildea and Jurafsky (2002), Surdeanu et al. (2003) and others. Our algorithm is based on Support Vector Machines which we show give large improvement in performance over earlier classifiers. We show performance improvements through a number of new features designed to improve generalization to unseen data, such as automatic clustering of verbs. We also report on various analytic studies examining which features are most important, comparing our classifier to other machine learning algorithms in the literature, and testing its generalization to new test set from different genre. On the task of assigning semantic labels to the PropBank (Kingsbury, Palmer, & Marcus, 2002) corpus, our final system has a precision of 84% and a recall of 75%, which are the best results currently reported for this task. Finally, we explore a completely different architecture which does not requires a deep syntactic parse. We reformulate the task as a combined chunking and classification problem, thus allowing our algorithm to be applied to new languages or genres of text for which statistical syntactic parsers may not be available.	Univ Colorado, Ctr Spoken Language Res, Boulder, CO 80303 USA	Pradhan, S (reprint author), Univ Colorado, Ctr Spoken Language Res, Boulder, CO 80303 USA.	spradhan@cslr.colorado.edu; hacioglu@cslr.colorado.edu; krugler@cslr.colorado.edu; whw@cslr.colorado.edu; martin@cslr.colorado.edu; jurafsky@cslr.colorado.edu					Allwein E.L., 2000, P 17 INT C MACH LEAR, P9; Baker C., 1998, P 36 ANN M ASS COMP, P86; Bikel DM, 1999, MACH LEARN, V34, P211, DOI 10.1023/A:1007558221122; Blaheta D., 2000, P 1 ANN M N AM CHAPT, P234; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CHARNIAK E, 2001, P 39 ANN C ASS COMP; CHEN J, 2003, P C EMP METH NAT LAN; Collins M., 1999, THESIS U PENNSYLVANI; DANIEL K, 1992, P 14 INT C COMP LING; FLEISCHMAN M, 2003, P HUM LANG TECHN C E; Gildea D, 2002, COMPUT LINGUIST, V28, P245, DOI 10.1162/089120102760275983; GILDEA D, 2003, P C EMP METH NAT LAN; GILDEA D, 2000, P 38 ANN C ASS COMP, P512, DOI 10.3115/1075218.1075283; GILDEA D, 2002, P 40 ANN C ASS COMP; HACIOGLU K, 2003, P HUM LANG TECHN C E; Hacioglu K., 2003, TRCSLR20031; Hearst M., 1999, P 37 ANN M ASS COMP, P3, DOI DOI 10.3115/1034678.1034679; HOFMANN T, 1998, UNPUB STAT MODELS CO; Joachims T., 1998, P EUR C MACH LEARN E; Kingsbury P., 2002, P HUM LANG TECHN C S; KRESSEL U, 1999, ADV KERNEL METHODS; KUDO T, 2001, P 2 M N AM CHAPT ASS; Kudoh T, 2000, P CONLL 2000 LLL 200, P142; LIN D, 1998, P INT C COMP LING CO; Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687; MAGERMAN D, 1994, THESIS STANFORD U CA; MARCUS MP, 1994, PENN TREEBANK ANNOTA; Platt J C, 2000, ADV LARGE MARGIN CLA; PRADHAN S, 2003, P INT C DAT MIN ICDM; Pradhan S., 2004, P HUM LANG TECHN C N; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; QUINLAN R, 2003, DATA MINING TOOLS; Ramshaw Lance A., 1995, P 3 WORKSH VER LARG, P82; Surdeanu M., 2003, P 41 ANN M ASS COMP; THOMPSON CA, 2003, P EUR C MACH LEARN E; Tjong Kim Sang E. F., 1999, P 9 C EUR CHAPT ASS, P173, DOI 10.3115/977035.977059; Vapnik VN, 1998, STAT LEARNING THEORY; Wallis S, 2001, DATA MIN KNOWL DISC, V5, P305, DOI 10.1023/A:1011453128373; *LDC, 2002, LDC2002T31	39	36	44	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	SEP	2005	60	1-3					11	39		10.1007/s10994-005-0912-2		29	Computer Science, Artificial Intelligence	Computer Science	958BW	WOS:000231420700002	
J	Cortes, C; Mohri, M				Cortes, C; Mohri, M			Moment kernels for regular distributions	MACHINE LEARNING			English	Article						statistical learning; kernel methods; rational kernels; string kernels; weighted automata; weighted finite-state transducers; spoken-dialog classification		Many machine learning problems in natural language processing, transaction-log analysis, or computational biology, require the analysis of variable-length sequences, or, more generally, distributions of variable-length sequences. Kernel methods introduced for fixed-size vectors have proven very successful in a variety of machine learning tasks. We recently introduced a new and general kernel framework, rational kernels, to extend these methods to the analysis of variable-length sequences or more generally distributions given by weighted automata. These kernels are efficient to compute and have been successfully used in applications such as spoken-dialog classification with Support Vector Machines. However, the rational kernels previously introduced in these applications do not fully encompass distributions over alternate sequences. They are based only on the counts of co-occurring subsequences averaged over the alternate paths without taking into accounts information about the higher-order moments of the distributions of these counts. In this paper, we introduce a new family of rational kernels, moment kernels, that precisely exploits this additional information. These kernels are distribution kernels based on moments of counts of strings. We describe efficient algorithms to compute moment kernels and apply them to several difficult spoken-dialog classification tasks. Our experiments show that using the second moment of the counts of n-gram sequences consistently improves the classification accuracy in these tasks.	Google Labs, New York, NY 10018 USA; AT&T Labs Res, Florham Pk, NJ 07932 USA	Cortes, C (reprint author), Google Labs, 1440 Broadway, New York, NY 10018 USA.	corinna@google.com; mohri@research.att.com					ALLAUZEN C, 2004, P 9 INT C IMPL APPL; Boser B, 1992, P 5 ANN WORKSH COMP, P144, DOI DOI 10.1145/130385.130401; CORTES C, 2003, ADV NEURAL INFORMATI, V15; Cortes C, 2003, LECT NOTES ARTIF INT, V2777, P41, DOI 10.1007/978-3-540-45167-9_5; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; CORTES C, 2003, P 9 EUR C SPEECH COM; GAERTNER T, 2003, LECT NOTES COMPUTER, V2777; Haussler D., 1999, UCSCCRL9910; LESLIE C, 2003, NIPS 2002; LODHI H, 2001, NIPS 2000, P563; Mohri M, 2000, THEOR COMPUT SCI, V231, P17, DOI 10.1016/S0304-3975(99)00014-6; MOHRI M, 1996, ECAI 96 WORKSH BUD H; Pereira FCN, 1997, LANG SPEECH & COMMUN, P431; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Scholkopf B., 2002, LEARNING KEMELS; SCHULTZENBERGER MP, 1961, INFORMATION CONTROL, V4; Takimoto E., 2003, J MACHINE LEARNING R, V4, P773; van Lint J.H., 1992, COURSE COMBINATORICS; Vapnik VN, 1998, STAT LEARNING THEORY; WATKINS C, 1999, CSDTR9811 U LOND ROY	20	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	SEP	2005	60	1-3					117	134		10.1007/s10994-005-0919-8		18	Computer Science, Artificial Intelligence	Computer Science	958BW	WOS:000231420700006	
J	Kazama, J; Tsujii, J				Kazama, J; Tsujii, J			Maximum entropy models with inequality constraints: A case study on text categorization	MACHINE LEARNING			English	Article						maximum entropy model; inequality constraint; regularization; feature selection; text categorization		Data sparseness or overfitting is a serious problem in natural language processing employing machine learning methods. This is still true even for the maximum entropy (ME) method, whose flexible modeling capability has alleviated data sparseness more successfully than the other probabilistic models in many NLP tasks. Although we usually estimate the model so that it completely satisfies the equality constraints on feature expectations with the ME method, complete satisfaction leads to undesirable overfitting, especially for sparse features, since the constraints derived from a limited amount of training data are always uncertain. To control overfitting in ME estimation, we propose the use of box-type inequality constraints, where equality can be violated up to certain predefined levels that reflect this uncertainty. The derived models, inequality ME models, in effect have regularized estimation with L-1 norm penalties of bounded parameters. Most importantly, this regularized estimation enables the model parameters to become sparse. This can be thought of as automatic feature selection, which is expected to improve generalization performance further. We evaluate the inequality ME models on text categorization datasets, and demonstrate their advantages over standard ME estimation, similarly motivated Gaussian MAP estimation of ME models, and support vector machines (SVMs), which are one of the state-of-the-art methods for text categorization.	Japan Adv Inst Sci & Technol JAIST, Sch Informat Sci, Noumi, Ishikawa 9231292, Japan; Univ Tokyo, Dept Comp Sci, Fac Informat Sci & Technol, Bunkyo Ku, Tokyo 1130033, Japan; JST Japan Sci & Technol Agcy, CREST, Kawaguchi, Saitama 3320012, Japan	Kazama, J (reprint author), Japan Adv Inst Sci & Technol JAIST, Sch Informat Sci, 1-1 Asahidai, Noumi, Ishikawa 9231292, Japan.	kazama@jaist.ac.jp; tsujii@is.s.u-tokyo.ac.jp					BENSON S, 2002, ANLMCSTM242; Berglund B, 1996, ENVIRON INT, V22, P1, DOI 10.1016/0160-4120(95)00098-4; Bertsekas DP, 1999, NONLINEAR PROGRAMMIN; Borthwick A., 1999, THESIS NEW YORK U; Chen CC, 2000, APPL IMMUNOHISTO M M, V8, P1, DOI 10.1097/00022744-200003000-00001; Chen Stanley F., 1999, CMUCS99108; Cristianini N., 2000, INTRO SUPPORT VECTOR; Curran J. R., 2003, P 11 ANN M EUR CHAPT, P91; DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379; DellaPietra S, 1997, IEEE T PATTERN ANAL, V19, P380, DOI 10.1109/34.588021; Fang S.C., 1997, ENTROPY OPTIMIZATION; GOODMAN J, 2003, EXPONENTIAL PRIORS M; GOODMAN J, 2004, P HLT NAACL 2004, P305; Hersh W.R., 1994, P 17 ANN INT ACM SIG, P192; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Joachims T., 1998, ADV KERNEL METHODS S, P169; JOHNSON M, 2000, P 1 C N AM CHAPT ASS, P154; JOHNSON M, 1999, ESTIMATORS STOCHASTI; KAZAMA J, 2004, THESIS U TOKYO; Kazama J, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P137; KHUDANPUR S, 1995, P J HOPK U LANG MOD, P1; LAU R, 1994, THESIS MIT; LEWIS D. D., 1992, P SPEECH NAT LANG WO, P212, DOI 10.3115/1075527.1075574; Malouf R, 2002, P 6 C NAT LANG LEARN, P49; Matwin S., 1999, P 16 INT C MACH LEAR, P379; MCCALLUM A, 2003, P C UNC ART INT UAI; MINKA T, 2001, 758 CMU; Miyao Y., 2002, P HUM LANG TECHN C H; MLADENIC D, 1998, P 17 EL COMP SCI C E; More J., 2001, ANLMCSP9090901; NEWMAN WI, 1977, IEEE T INFORM THEORY, V23, P89, DOI 10.1109/TIT.1977.1055659; Nigam K, 1999, IJCAI 99 WORKSH MACH, P61; Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79; Ratnaparkhi A., 1996, P C EMP METH NAT LAN, P133; SALTON G, 1988, INFORMATION PROCESSI, V24, P5; Sha F., 2003, P C N AM CHAPT ASS C, P134; SHIRAI K, 1998, P 4 ANN M NAT LANG P, P356; TAN CM, 2002, J INFORM PROCESS MAN, V30, P529; Vapnik V. N, 1995, NATURE STAT LEARNING; Yang Yiming, 1997, P 14 INT C MACH LEAR, P412; Zhou YQ, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P153	41	10	15	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	SEP	2005	60	1-3					159	194		10.1007/s10994-005-0911-3		36	Computer Science, Artificial Intelligence	Computer Science	958BW	WOS:000231420700008	
J	Cui, DP; Curry, D				Cui, DP; Curry, D			Prediction in marketing using the support vector machine	MARKETING SCIENCE			English	Article						automated modeling; choice models; kernel transformations; multinomial logit model; predictive models; support vector machine	CONSUMER DECISION-MAKING; CONJOINT-ANALYSIS; PRIOR KNOWLEDGE; CHOICE; MODELS; CLASSIFICATION; PROBABILITIES; NETWORKS; INTERNET; BEHAVIOR	Many marketing problems require accurately predicting the outcome of a process or the future state of a system. In this paper, we investigate the ability of the support vector machine to predict outcomes in emerging environments in marketing, such as automated modeling, mass-produced models, intelligent software agents, and data mining. The support vector machine (SVM) is a semiparametric technique with origins in the machine-learning literature of computer science. Its approach to prediction differs markedly from that of standard parametric models. We explore these differences and benchmark the SVM's prediction hit-rates against those from the multinomial logit model. Because there are few applications of the SVM in marketing, we develop a framework to position it against current modeling techniques and to assess its weaknesses as well as its strengths.	Ipsos Insight N Amer, Chicago, IL 60606 USA; Univ Cincinnati, Coll Business Adm, Cincinnati, OH 45221 USA	Cui, DP (reprint author), Ipsos Insight N Amer, 111 N Canal,Suite 405, Chicago, IL 60606 USA.	dapeng.cui@ipsos-na.com; david.curry@uc.edu					ABRAHAM M, 1987, MARKET SCI, V6, P1; ABRAMOVICI F, 1993, APPL NUMER MATH, V12, P3, DOI 10.1016/0168-9274(93)90109-5; ALLENBY G, 2002, CANADIAN J MARKETING, V20, P44; ALLENBY GM, 1995, J MARKETING RES, V32, P152, DOI 10.2307/3152044; Andrews RL, 2002, J MARKETING RES, V39, P87, DOI 10.1509/jmkr.39.1.87.18936; Ariely D, 2004, J CONSUM PSYCHOL, V14, P81, DOI 10.1207/s15327663jcp1401&2_10; Avery C, 1999, AM ECON REV, V89, P564, DOI 10.1257/aer.89.3.564; BELLMAN E, 1961, ADAPTIVE CONTROL PRO; Ben Akiva M., 1985, DISCRETE CHOICE ANAL; Ben-Avika M., 1997, MARKET LETT, V8, P273, DOI 10.1023/A:1007956429024; Berry M.J.A., 1997, DATA MINING TECHNIQU; BLATTBERG R, 1994, MARKETING INFORMATIO, P173; Boser B., 1992, 5 ANN ACM WORKSH COL, P144; BRADLOW ET, 2003, CURRENT ISSUES WISH, P1; BRAZERMAN MH, 1994, JUDGMENT MANAGERIAL; BRONSON R., 1991, MATRIX METHODS INTRO; BUCKLIN RE, 1998, MARKET LETT, V9, P235, DOI 10.1023/A:1008047504898; Bucklin RE, 2002, MARKET LETT, V13, P245, DOI 10.1023/A:1020231107662; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Cooper LG, 2000, MANAGE SCI, V46, P249, DOI 10.1287/mnsc.46.2.249.11932; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Courant R, 1953, METHODS MATH PHYS, V1; Cristianini N., 2000, INTRO SUPPORT VECTOR; CUI DP, 2003, APPL SUPPORT VECTOR; DAWES RM, 1974, PSYCHOL BULL, V81, P95, DOI 10.1037/h0037613; Diehl K, 2003, J CONSUM RES, V30, P56, DOI 10.1086/374698; Domencich T, 1975, URBAN TRAVEL DEMAND; EDGINGTON ES, 1995, RANDOMIZATION TEST; Efron B., 1993, INTRO BOOTSTRAP; EINHORN HJ, 1970, PSYCHOL BULL, V73, P221, DOI 10.1037/h0028695; Evgeniou T, 2005, MARKET SCI, V24, P415, DOI 10.1287/mksc.1040.0100; Fisher R. A., 1950, CONTRIBUTIONS MATH S; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Gershoff AD, 1998, MARKET LETT, V9, P79, DOI 10.1023/A:1007924221687; Gilbride TJ, 2004, MARKET SCI, V23, P391, DOI 10.1287/mksc.1030.0032; GOOD PI, 2005, RESAMPLING METHODS P, V20; Guadagni P. M., 1983, MARKET SCI, V2, P203, DOI 10.1287/mksc.2.3.203; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; HAHN GH, 1966, 66C165 GEN EL RES DE; Haubl G, 2000, MARKET SCI, V19, P4, DOI 10.1287/mksc.19.1.4.15178; Hempel C. G., 1965, ASPECTS SCI EXPLANAT, P331; Hinton G. E., 1986, PARALLEL DISTRIBUTED, V2, P77; HOFSTEDE FT, 2002, J MARKETING RES, V39, P253, DOI 10.1509/jmkr.39.2.253.19087; HUNG SD, 1983, MARKETING THEORY PHI; Iacobucci D., 2000, J INTERACTIVE MARKET, V14, P2, DOI 10.1002/1520-6653(200022)14:3<2::AID-DIR1>3.0.CO;2-J; Kahneman D., 2002, NOBEL PRIZES 2002, P449; Kamakura WA, 2003, INT J RES MARK, V20, P45, DOI 10.1016/S0167-8116(02)00121-0; Kardes FR, 1999, CONSUMER BEHAV MANAG; KreBel U.H.G., 1999, ADV KERNEL METHODS S, P255; LANGLEY K, 2000, LINEAR NONLINEAR HID; Lilien GL, 2002, J BUS RES, V55, P111, DOI 10.1016/S0148-2963(00)00146-6; LITTLE JDC, 2001, 5 INV CHOIC S; Luce D., 1959, INDIVIDUAL CHOICE BE; Mattera D, 1999, ADVANCES IN KERNEL METHODS, P211; MCKAY DJC, 1995, GEN ERROR NUMBER HID; Minsky M., 1969, PERCEPTIONS INTRO CO; Moe WW, 2004, MANAGE SCI, V50, P326, DOI 10.1287/mnsc.1040.0153; Muller KR, 1999, ADVANCES IN KERNEL METHODS, P243; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; Platt JC, 2000, ADV NEUR IN, P61; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Platt JC, 2000, ADV NEUR IN, V12, P547; POLITZ AW, 1953, J MARKETING      JUL; Ratner B., 2003, STAT MODELING ANAL D; Rossi PE, 2003, MARKET SCI, V22, P304, DOI 10.1287/mksc.22.3.304.17739; Russo J. E., 1989, DECISION TRAPS; Sandor Z, 2004, TRANSPORT RES B-METH, V38, P313, DOI 10.1016/S0191-2615(03)00014-6; Schmahmann B, 2000, WOMAN ART J, V20, P29; Scholkopf B, 1999, ADVANCES IN KERNEL METHODS, P327; Scholkopf B, 1999, ADV NEUR IN, V11, P330; Scholkopf B, 1998, ADV NEUR IN, V10, P640; SHAWETAYLOR J, 1999, EUROCOLT 99, P263; SHAWETAYLOR J, 1999, COLT 99, P278; SHAWETAYLOR J, 1999, ADV LARGE MARGIN CLA, P349; Sismeiro C, 2004, J MARKETING RES, V41, P306, DOI 10.1509/jmkr.41.3.306.35985; Smith MD, 2001, J IND ECON, V49, P541; Stitson MO, 1999, ADVANCES IN KERNEL METHODS, P285; Thurstone LL, 1927, PSYCHOL REV, V34, P273, DOI 10.1037/h0070288; Toubia O, 2004, J MARKETING RES, V41, P116, DOI 10.1509/jmkr.41.1.116.25082; TVERSKY A, 1972, PSYCHOL REV, V79, P281, DOI 10.1037/h0032955; Vapnik V, 1979, ESTIMATION DEPENDENC; Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646; Vapnik V, 2000, ADV NEUR IN, P261; Vapnik V. N, 1995, NATURE STAT LEARNING; Vapnik V. N., 1964, AUTOMATION REMOTE CO, V25; Vapnik VN, 1998, STAT LEARNING THEORY; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; Viaene S, 2002, J RISK INSUR, V69, P373, DOI 10.1111/1539-6975.00023; West P. M., 1999, MARKET LETT, V10, P285, DOI 10.1023/A:1008127022539; West PM, 1997, MARKET SCI, V16, P370, DOI 10.1287/mksc.16.4.370; Weston J, 1999, ADVANCES IN KERNEL METHODS, P293; WESTON J, 1998, P 6 EUR S ART NEUR N, P276; Wierenga B, 1999, MARKET SCI, V18, P196, DOI 10.1287/mksc.18.3.196; Wierenga B., 2000, MARKETING MANAGEMENT; Young G, 1940, PSYCHOMETRIKA, V5, P47, DOI 10.1007/BF02288560	95	36	36	INST OPERATIONS RESEARCH  MANAGEMENT SCIENCES	LINTHICUM HTS	901 ELKRIDGE LANDING RD, STE 400, LINTHICUM HTS, MD 21090-2909 USA	0732-2399		MARKET SCI	Mark. Sci.	FAL	2005	24	4					595	615		10.1287/mksc.1050.0123		21	Business	Business & Economics	998MI	WOS:000234322500007	
J	Ciupke, K				Ciupke, K			A comparative study on methods of reduction and selection of information in technical diagnostics	MECHANICAL SYSTEMS AND SIGNAL PROCESSING			English	Article						machinery diagnostics; knowledge acquisition; machine learning; selection of attributes; conversion of attribute values		The problem of knowledge acquisition is one of the most important problems connected with applications of expert systems in the domain of machinery diagnostics. The knowledge acquisition from databases by means of machine learning methods is one of the methods that could be applied to solve the problem. In most cases, collected values of attributes (diagnostic symptoms) are real numbers. The usage of machine learning methods usually requires a conversion of quantitative values to qualitative ones-this requires an estimation of cutting points. Limitation of a number of attributes used in knowledge acquisition process is also crucial. In the paper, a methodological process of estimation of cutting points as well as attributes selection for a machine state assessment is presented. The concept of an indirect assessment of the considered methods is also presented. Then an example of verification is shown. (c) 2004 Elsevier Ltd. All rights reserved.	Silesian Tech Univ, Dept Fundamentals Machinery Design, PL-44100 Gliwice, Poland	Ciupke, K (reprint author), Silesian Tech Univ, Dept Fundamentals Machinery Design, Konarskiego 18A, PL-44100 Gliwice, Poland.	kciupke@polsl.pl					Chmielewski M.R., 1994, 3 INT WORKSH ROUGH S, P294; CHOLEWA W, 1983, SERIES MECHANICS, V79; CIUPKE K, 2000, S METH ART INT MECH; CIUPKE K, 2001, DEP FUNDAMENTALS MAC, V118; CIUPKE K, 2000, 2 INT C TECHN DIAGN; CIUPKE R, 2000, P WORKSH INT IN SYST, P21; Dougherty J, 1995, 12 INT C MACH LEARN, P194; Goldberg DE, 1989, GENETIC ALGORITHMS S; Hand DJ, 1981, DISCRIMINATION CLASS; Hoa Nguyen S., 1996, P C INF PROC MAN UNC, P1451; JOHNSONGENTILE K, 1994, J EDUC COMPUT RES, V11, P121; Kerber R., 1992, P 10 NAT C ART INT, P123; KLOSGEN W, 1997, PKDD TUTORIAL NOTES; Kohavi R., 1998, FEATURE EXTRACTION C; KUBAT M, 1996, MACHINE LEARNING DAT; MICHALSKI RS, 1997, INTELLIGENT INFORMAT; MICHALSKI RS, 1996, MACHINE LEARNING DAT; MOCZULSKI W, 1997, SERIES MECH SILESIAN, V130; MROZEK A, 1989, INT J MAN MACH STUD, V30, P4527; Nguyen H. S., 1995, P 2 JOINT ANN C INF, P34; NGUYEN S, 1998, ROUGH SETS KNOWLEDGE, P451; Pawlak Z., 1991, ROUGH SETS THEORETIC; Skowron A., 1992, HDB APPL ADV ROUGH S, P331; SOBCZAK W, 1995, METHODS SELECTION RE; SOKOLOWSKI A, 2000, 2 INT C TECHN DIAGN; Swiniarski R. W., 2001, International Journal of Applied Mathematics and Computer Science, V11; WEISS S, 1989, 11 INT JOINT C ART I, P177; Wroblewski J., 1995, P 2 ANN JOINT C INF, P186; YANG J, 1998, FEATURE EXTRACTIION; Z.Michalewicz, 1992, GENETIC ALGORITHMS D; *BENTL NV, 1996, ROT KIT INSTR MAN NO; *SOL INSTR, COMM VIBR SYMPT TURB	32	0	0	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0888-3270		MECH SYST SIGNAL PR	Mech. Syst. Signal Proc.	SEP	2005	19	5					919	938		10.1016/j.ymssp.2004.08.003		20	Engineering, Mechanical	Engineering	929SX	WOS:000229367400001	
J	Yao, XJ; Liu, HX; Zhang, RS; Liu, MC; Hu, ZD; Panaye, A; Doucet, JP; Fan, BT				Yao, Xiaojun; Liu, Huanxiang; Zhang, Ruisheng; Liu, Mancang; Hu, Zhide; Panaye, A.; Doucet, J. P.; Fan, Botao			QSAR and classification study of 1,4-dihydropyridine calcium channel antagonists based on least squares support vector machines	MOLECULAR PHARMACEUTICS			English	Article						QSAR; calcium channel antagonists; least squares support vector machines		The least squares support vector machine (LSSVM), as a novel machine learning algorithm, was used to develop quantitative and classification models as a potential screening mechanism for a novel series of 1,4-dihydropyridine calcium channel antagonists for the first time. Each compound was represented by calculated structural descriptors that encode constitutional, topological, geometrical, electrostatic, quantum-chemical features. The heuristic method was then used to search the descriptor space and select the descriptors responsible for activity. Quantitative modeling results in a nonlinear, seven-descriptor model based on LSSVM with mean-square errors 0.2593, a predicted correlation coefficient (R-2) 0.8696, and a cross-validated correlation coefficient (R-cv(2)) 0.8167. The best classification results are found using LSSVM: the percentage (%) of correct prediction based on leave one out cross-validation was 91.1%. This paper provides a new and effective method for drug design and screening.	[Yao, Xiaojun; Liu, Huanxiang; Zhang, Ruisheng; Liu, Mancang; Hu, Zhide] Lanzhou Univ, Dept Chem, Lanzhou 730000, Peoples R China; [Panaye, A.; Doucet, J. P.; Fan, Botao] Univ Paris 07, CNRS, ITODYS, UMR 7086, F-75005 Paris, France	Yao, XJ (reprint author), Lanzhou Univ, Dept Chem, Lanzhou 730000, Peoples R China.	xiaojunyao@yahoo.com					Basak SC, 2000, J CHEM INF COMP SCI, V40, P891, DOI 10.1021/ci990114y; Belousov AI, 2002, CHEMOMETR INTELL LAB, V64, P15, DOI 10.1016/S0169-7439(02)00046-1; Burbidge R, 2001, COMPUT CHEM, V26, P5, DOI 10.1016/S0097-8485(01)00094-8; Burges C, 1998, DATA MIN KNOWL DISC, V2, P1, DOI DOI 10.1023/A:1009715923555; Chua KS, 2003, PATTERN RECOGN LETT, V24, P75, DOI 10.1016/S0167-8655(02)00190-3; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COSTA MCA, 1997, THEOCHEM-J MOL STRUC, V394, P291; Cristianini N., 2000, INTRO SUPPORT VECTOR; Hemmateenejad B, 2002, CHEMOMETR INTELL LAB, V64, P91, DOI 10.1016/S0169-7439(02)00068-0; Hemmateenejad B, 2003, J CHEM INF COMP SCI, V43, P1328, DOI 10.1021/ci025661p; Katritzky A. R., 1994, COMPREHENSIVE DESCRI; Katritzky AR, 2001, J CHEM INF COMP SCI, V41, P1162, DOI 10.1021/ci010011r; Katritzky AR, 2001, J CHEM INF COMP SCI, V41, P1521, DOI 10.1021/ci010043e; Katritzky AR, 2003, J CHEM INF COMP SCI, V43, P1794, DOI 10.1021/ci034120c; KATRITZKY AR, 1995, CHEM SOC REV, V24, P279, DOI 10.1039/cs9952400279; Liu HX, 2004, J COMPUT AID MOL DES, V18, P389, DOI 10.1007/s10822-004-2722-1; Liu HX, 2004, J CHEM INF COMP SCI, V44, P1979, DOI 10.1021/ci049891a; Liu HX, 2003, J CHEM INF COMP SCI, V43, P1288, DOI 10.1021/ci03040355; Liu HX, 2003, J CHEM INF COMP SCI, V43, P900, DOI 10.1021/ci0256438; Liu HX, 2004, J CHEM INF COMP SCI, V44, P161, DOI 10.1021/ci034173u; Morris CW, 2001, ECOL MODEL, V146, P57; Oblak M, 2000, J CHEM INF COMP SCI, V40, P994, DOI 10.1021/ci000001a; Pelckmans K., 2002, 0244 ESATSISTA; Schleifer KJ, 2002, QUANT STRUCT-ACT REL, V21, P239, DOI 10.1002/1521-3838(200208)21:3<239::AID-QSAR239>3.0.CO;2-W; Scholkopf B., 1999, ADV KERNEL METHODS S; Stewart J.P.P., 1989, 455 QCPE IND U; Suykens JAK, 1999, INT J CIRC THEOR APP, V27, P605, DOI 10.1002/(SICI)1097-007X(199911/12)27:6<605::AID-CTA86>3.0.CO;2-Z; Suykens JAK, 2001, NEURAL NETWORKS, V14, P23, DOI 10.1016/S0893-6080(00)00077-0; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Takahata Y, 2003, J CHEM INF COMP SCI, V43, P540, DOI 10.1021/ci010117m; Thissen U, 2004, ANAL CHEM, V76, P3099, DOI 10.1021/ac035522m; Vapnik V., 1982, ESTIMATION DEPENDENC; Vapnik VN, 1998, STAT LEARNING THEORY; Viaene S, 2001, INT J INTELL SYST, V16, P1023, DOI 10.1002/int.1047; Viswanadhan VN, 2001, J CHEM INF COMP SCI, V41, P505, DOI 10.1021/ci000072+; Xue CX, 2004, J CHEM INF COMP SCI, V44, P669, DOI 10.1021/ci034248u; Yao XJ, 2005, ANAL CHIM ACTA, V535, P259, DOI 10.1016/j.aca.2004.11.066; Zamponi GW, 2003, J MED CHEM, V46, P87, DOI 10.1021/jm020354w; *HYP, 1994, HYPERCHEM 4 0	39	40	43	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1543-8384		MOL PHARMACEUT	Mol. Pharm.	SEP-OCT	2005	2	5					348	356		10.1021/mp050027v		9	Pharmacology & Pharmacy	Pharmacology & Pharmacy	V52JE	WOS:000203539000002	
J	Zivadinov, R; Chandrasekhar, R; Sampath, T; Prakash, R; Srinivasaraghavan, B; Abdelrahman, N; Dwyer, MG				Zivadinov, R; Chandrasekhar, R; Sampath, T; Prakash, R; Srinivasaraghavan, B; Abdelrahman, N; Dwyer, MG			Automated evaluation of confluent and non-confluent T2 lesion volume using supervised and unsupervised machine-learning approaches	MULTIPLE SCLEROSIS			English	Meeting Abstract	21st Congress of the European-Committee-for-Treatment-and-Research-in-Multiple-Sclerosis/10th Annual Meeting of Rehabilitation in MS	SEP 28-OCT 01, 2005	Thessaloniki, GREECE	European Comm Treatment & Res Multiple Sclerosis					Buffalo Neuroimaging Anal Ctr, Buffalo, NY USA			Bastianello, Stefano/A-9001-2012					0	1	1	HODDER ARNOLD, HODDER HEADLINE PLC	LONDON	338 EUSTON ROAD, LONDON NW1 3BH, ENGLAND	1352-4585		MULT SCLER	Mult. Scler.	SEP	2005	11			1			S146	S146				1	Clinical Neurology	Neurosciences & Neurology	969QO	WOS:000232249900531	
J	de la Higuera, C				de la Higuera, C			A bibliographical study of grammatical inference	PATTERN RECOGNITION			English	Review						grammatical inference; grammar induction	CONTEXT-FREE GRAMMARS; PATTERN LANGUAGES; PROBABILISTIC-AUTOMATA; REGULAR LANGUAGES; FINITE AUTOMATA; POLYNOMIAL-TIME; TREE-LANGUAGES; SUBSEQUENTIAL TRANSDUCERS; COMPUTATIONAL-COMPLEXITY; INDUCTIVE INFERENCE	The field of grammatical inference (also known as grammar induction) is transversal to a number of research areas including machine learning, formal language theory, syntactic and structural pattern recognition, computational linguistics, computational biology and speech recognition. There is no uniform literature on the subject and one can find many papers with original definitions or points of view. This makes research in this subject very hard, mainly for a beginner or someone who does not wish to become a specialist but just to find the most suitable ideas for his own research activity. The goal of this paper is to introduce a certain number of papers related with grammatical inference. Some of these papers are essential and should constitute a common background to research in the area, whereas others are specialized on particular problems or techniques, but can be of great help on specific tasks. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Univ St Etienne, Fac Sci & Tech, EURISE, F-42023 St Etienne, France	de la Higuera, C (reprint author), Univ St Etienne, Fac Sci & Tech, EURISE, 23 Rue Paul Michelon, F-42023 St Etienne, France.	cdlh@univ-st-edenne.fr					ABE N, 1992, MACH LEARN, V9, P205, DOI 10.1007/BF00992677; Abe N, 1997, MACH LEARN, V29, P275, DOI 10.1023/A:1007477814995; ABE N, 2001, LECT NOTES COMPUTER, V2225; ADRIAANS P, 2002, LECT NOTES ARTIFICIA, V2484; ADRIAANS P, 1992, THESIS U ANSTERDAM; Adriaans P, 2002, LECT NOTES ARTIF INT, V2484, P293; Aho A. V., 1972, THEORY PARSING TRANS, VI; AHONEN H, 1994, LECT NOTES ARTIF INT, V862, P153; Amengual J. C., 2000, Machine Translation, V15, DOI 10.1023/A:1011116115948; Amengual JC, 2001, MACH LEARN, V44, P143, DOI 10.1023/A:1010832230794; Angluin D., 1988, YALEUDCSRR614; ANGLUIN D, 1983, ACM COMPUT SURV, V15, P237, DOI 10.1145/356914.356918; ANGLUIN D, 1982, J ACM, V29, P741, DOI 10.1145/322326.322334; ANGLUIN D, 1980, INFORM CONTROL, V45, P117, DOI 10.1016/S0019-9958(80)90285-5; ANGLUIN D, 1979, 11 ANN ACM S THEOR C, P130; Angluin D., 1988, Machine Learning, V2, DOI 10.1007/BF00116828; ANGLUIN D, 1978, INFORM CONTROL, V39, P337, DOI 10.1016/S0019-9958(78)90683-6; Angluin D., 1991, P 23 ANN ACM S THEOR, P444, DOI 10.1145/103418.103420; ANGLUIN D, 1981, INFORM CONTROL, V51, P76, DOI 10.1016/S0019-9958(81)90090-5; ANGLUIN D, 1990, MACH LEARN, V5, P121, DOI 10.1023/A:1022692615781; ANGLUIN D, 2001, LECT NOTES ARTIF INT, V2225, P12; ARIMURA H, 2001, LECT NOTES ARTIF INT, V2225, P315; Baker J, 1979, 97 M AC SOC AM, P547; Balcazar J. L., 1994, Proceedings of the Seventh Annual ACM Conference on Computational Learning Theory, COLT 94, DOI 10.1145/180139.181110; BALCAZAR JL, 1994, NEW GENERAT COMPUT, V12, P337; Vanlehn K., 1987, Machine Learning, V2, DOI 10.1007/BF00058754; Baum L. E., 1972, INEQUALITIES, V3, P1; BERNARD M, 2001, REV INTELL ARTIF, V14, P375; BHATTACHARYYA P, 1993, 1 C GRAMM INF ESS UK; BIERMANN A, 1971, 4 HAW INT C SYST SCI, P121; Birkendorf A, 2000, SIAM J DISCRETE MATH, V13, P465, DOI 10.1137/S0895480198340943; BOOTH TL, 1973, IEEE T COMPUT, VC 22, P442, DOI 10.1109/T-C.1973.223746; Borges J, 2000, LECT NOTES COMPUT SC, V1836, P92; BOSTROM H, 1998, LECT NOTES ARTIF INT, V1398, P226; BOSTROM H, 1996, 13 INT C MACH LEARN; Brazma A., 1998, LECT NOTES ARTIF INT, V1433, P257; Bshouty NH, 1996, J COMPUT SYST SCI, V52, P421, DOI 10.1006/jcss.1996.0032; BUNKE H, 1990, SERIES COMPUTER SCI, V7; Cano A, 2002, LECT NOTES ARTIF INT, V2484, P28; Carmel D, 1998, J EXP THEOR ARTIF IN, V10, P309, DOI 10.1080/095281398146789; Carmel D., 1999, Autonomous Agents and Multi-Agent Systems, V2, DOI 10.1023/A:1010007108196; Carrasco R. C., 1994, LECT NOTES ARTIF INT, V862, P139; CARRASCO RC, 1997, THEORET INFORM APPL, V31, P437; CARRASCO RC, 1996, LECT NOTES ARTIF INT, V1147, P274; CARRASCO RC, 1994, LECT NOTES ARTIFICIA, V862; Carrasco RC, 2001, MACH LEARN, V44, P185, DOI 10.1023/A:1010836331703; Carrasco RC, 1999, RAIRO-INF THEOR APPL, V33, P1, DOI 10.1051/ita:1999102; Casacuberta F, 2000, LECT NOTES ARTIF INT, V1891, P15; CASACUBERTA F, 1990, IEEE T PATTERN ANAL, V12, P691, DOI 10.1109/34.56212; CHIDLOVSKII B, 2000, P WORKSH MACH LEARN; Chidlovskii B, 2000, LECT NOTES ARTIF INT, V1810, P96; CHIDLOVSKII B, 2001, P 8 INT WORKSH KNOWL, V45; CRUZ P, 1998, LECT NOTES ARTIF INT, V1433, P211; De La Higuera C., 2002, LECT NOTES ARTIF INT, V2375, P185; de la Higuera C., 1996, LECT NOTES ARTIF INT, V1147, P313; DEAN TL, 1992, P AAAI 92 SAN JOS CA, P208; DelaHiguera C, 1997, MACH LEARN, V27, P125, DOI 10.1023/A:1007353007695; De la Higuera C, 2000, LECT NOTES COMPUT SC, V1876, P28; DELAHIGUERA C, 1998, LECT NOTES ARTIF INT, V1433, P79; de la Higuera C, 2002, LECT NOTES ARTIF INT, V2484, P134; Denis F, 2002, LECT NOTES ARTIF INT, V2484, P63; Denis F., 2001, LECT NOTES COMPUTER, V2225, P348; DEOLIVEIRA A, 2000, LECT NOTES ARTIFICIA, V1891; DEOLIVEIRA AL, 2001, MACH LEARNING J, V44, P93; Dupont P, 1994, LECT NOTES ARTIF INT, V862, P25; Dupont P., 1994, LECT NOTES ARTIF INT, V862, P236; Dupont P, 2000, LECT NOTES ARTIF INT, V1891, P51; Erlebach T, 1997, LECT NOTES ARTIF INT, V1316, P260; Fernau H, 2001, LECT NOTES ARTIF INT, V2123, P73; FERNAU H, 2002, LECT NOTES ARTIF INT, V2375, P153; Fernau H, 2000, LECT NOTES ARTIF INT, V1968, P116; Florencio CC, 2002, LECT NOTES ARTIF INT, V2484, P49; Foret A, 2002, LECT NOTES ARTIF INT, V2484, P106; Forney G.D., 1973, IEEE P, V61, P268; Fu K. S., 1974, SYNTACTIC METHODS PA; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P409, DOI 10.1109/TSMC.1975.5408432; Fu K. S., 1975, IEEE T SYST MAN CYB, V5, P59; GARCIA P, 1993, DSICII4793 U POL VAL; GARCIA P, 1990, IEEE T PATTERN ANAL, V12, P920, DOI 10.1109/34.57687; Garcia P., 1994, INT J PATTERN RECOGN, V4, P667; GAVALDA R, 1993, I MATH ITS APPL C SE, V53, P193; Giles CL, 2001, MACH LEARN, V44, P161, DOI 10.1023/A:1010884214864; GIORDANO JY, 1994, LECT NOTES ARTIF INT, V862, P212; Giordano J.Y., 1996, LECT NOTES ARTIF INT, V1147, P292; GOAN T, 1996, P AAAI SPRING S MACH; GOLD EM, 1978, INFORM CONTROL, V37, P302, DOI 10.1016/S0019-9958(78)90562-4; GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5; GOLDMAN SA, 1995, J COMPUT SYST SCI, V50, P20, DOI 10.1006/jcss.1995.1003; Goldman SA, 1999, LECT NOTES ARTIF INT, V1720, P347; Goldman SA, 1996, J COMPUT SYST SCI, V52, P255, DOI 10.1006/jcss.1996.0020; Habrard A, 2002, LECT NOTES ARTIF INT, V2484, P120; Harrison M. A., 1978, INTRO FORMAL LANGUAG; Honavar V, 2001, MACH LEARN, V44, P5, DOI 10.1023/A:1010812817165; HONAVAR V, 1998, LECT NOTES ARTIFICIA, V1433; Hopcroft J., 1979, INTRO AUTOMATA THEOR; Ishigami Y, 1997, DISCRETE APPL MATH, V74, P123, DOI 10.1016/S0166-218X(96)00025-X; ISHIZAKA I, 1989, P COLT 89; JAGOTA A, 2001, LECT NOTES COMPUTER, V2149, P69; JANTKE KP, 1995, THEOR COMPUT SCI, V137, P25, DOI 10.1016/0304-3975(95)91134-C; Jelinek F., 1998, STAT METHODS SPEECH; KAMMEYER T, 1996, FDN GENETIC ALGORITH; KANAZAWA M, 1998, CSLI PUBLICATIONS; KEARNS M, 1989, 21ST P ANN ACM S THE, P433; Kearns M., 1994, Proceedings of the Twenty-Sixth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/195058.195155; Kearns MJ, 1994, INTRO COMPUTATIONAL; Kermorvant C, 2002, LECT NOTES ARTIF INT, V2484, P161; KIVINEN J, 2002, LECT NOTES ARTIFICIA, V2375; KNUUTILA T, 1996, LECT NOTES ARTIF INT, V1147, P22; KNUUTILA T, 1994, THEOR COMPUT SCI, V129, P337, DOI 10.1016/0304-3975(94)90033-7; Koshiba T, 1997, THEOR COMPUT SCI, V185, P63, DOI 10.1016/S0304-3975(97)00016-9; Koshiba Takeshi, 1995, LECT NOTES ARTIF INT, V904, P367; KWERK SS, 1999, COLT COMPUTATIONAL L; Lang K, 1998, LECT NOTES ARTIF INT, V1433, P1; Lang K. J., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130390; LANG K, 1997, ABBADINGO 1 DFA LEAR; Lang KJ, 1999, FASTER ALGORITHMS FI; Langley P, 2000, LECT NOTES ARTIF INT, V1810, P220; Lari K., 1990, Computer Speech and Language, V4, DOI 10.1016/0885-2308(90)90022-X; LEE S, 1997, TR1296 CTR RES COMP; Li M., 1993, INTRO KOLMOGOROV COM; LI M, 1991, SIAM J COMPUT, V20, P911, DOI 10.1137/0220056; Littlestone N., 1988, Machine Learning, V2, DOI 10.1007/BF00116827; LUCAS S, 1994, LECT NOTES ARTIF INT, V862, P168; LUZEAUX D, 1996, P 8 INT C ART INT EX; Lyngsø R B, 1999, Proc Int Conf Intell Syst Mol Biol, P178; Lyngso RB, 2001, LECT NOTES COMPUT SC, V2223, P416; Makinen E., 1996, Fundamenta Informaticae, V25; MALER O, 1991, PROCEEDINGS OF THE FOURTH ANNUAL WORKSHOP ON COMPUTATIONAL LEARNING THEORY, P128; MCALLESTER D, 2002, LEARNING THEORY LANG; Miclet L., 1990, SYNTACTIC STRUCTURAL, P237; Miclet L., 1986, STRUCTURAL METHODS P; MICLET L, 1996, LECT NOTES ARTIFICIA, V1147; Mitchell A, 1999, LECT NOTES ARTIF INT, V1720, P93; Mitchell T, 1997, MACHINE LEARNING; Mohri M, 2000, THEOR COMPUT SCI, V231, P17, DOI 10.1016/S0304-3975(99)00014-6; Mohri M, 1997, COMPUT LINGUIST, V23, P269; MORGAN N, IEEE SIGNAL PROCESS, V12; Muggleton S., 1999, MIT ENCY COGNITIVE S; NATARAJAN BK, 1991, MACHINE LEARNING THE; NevillManning CG, 1997, J ARTIF INTELL RES, V7, P67; NEY H, 1992, P NATO ADV STUDY I, P313; ONCINA J, 1993, IEEE T PATTERN ANAL, V15, P448, DOI 10.1109/34.211465; ONCINA J, 1996, LECT NOTES ARTIF INT, V1147, P301; ONCINA J, 1998, LECT NOTES COMPUTER, V1433, P50; PAREKH RJ, 1997, WORKSH AUT IND GRAMM; Paz A., 1971, INTRO PROBABILISTIC; PITT L, 1988, 3 C STRUCTR COMPL TH, P60; PITT L, 1993, J ACM, V40, P95, DOI 10.1145/138027.138042; PITT L, 1989, LECT NOTES ARTIF INT, V397, P18; Ra DY, 1999, INFORM PROCESS LETT, V72, P37, DOI 10.1016/S0020-0190(99)00119-2; RABIN MO, 1963, INFORM CONTROL, V6, P230, DOI 10.1016/S0019-9958(63)90290-0; Rico-Juan JR, 2002, LECT NOTES ARTIF INT, V2484, P199; RIEGER A, 1995, P MLNET FAM WORKSH 3, P65; RIVEST RL, 1993, INFORM COMPUT, V103, P299, DOI 10.1006/inco.1993.1021; Ron D., 1994, Proceedings of the Seventh Annual ACM Conference on Computational Learning Theory, COLT 94, DOI 10.1145/180139.181006; Ron D., 1995, Proceedings of the Eighth Annual Conference on Computational Learning Theory, DOI 10.1145/225298.225302; Rossmanith P, 2001, MACH LEARN, V44, P67, DOI 10.1023/A:1010875913047; Sakakibara Y, 2000, LECT NOTES ARTIF INT, V1891, P229; Sakakibara Y, 1997, THEOR COMPUT SCI, V185, P15, DOI 10.1016/S0304-3975(97)00014-5; SAKAKIBARA Y, 1992, INFORM COMPUT, V97, P23, DOI 10.1016/0890-5401(92)90003-X; SAKAKIBARA Y, 1987, 81 INT I ADV STUD SO; SAKAKIBARA Y, 1994, NUCLEIC ACIDS RES, V22, P5112, DOI 10.1093/nar/22.23.5112; SAKAKIBARA Y, 1990, THEOR COMPUT SCI, V76, P223, DOI 10.1016/0304-3975(90)90017-C; SAKAKIBARA Y, 1999, P 16 INT C MACH LEAR, P354; Salvador I, 2002, INT J PATTERN RECOGN, V16, P309, DOI 10.1142/S0218001402001691; Sanchez JA, 1997, IEEE T PATTERN ANAL, V19, P1052, DOI 10.1109/34.615455; SEBBAN M, 2003, P ICML; SEMPERE JM, 1994, LECT NOTES ARTIF INT, V862, P38; SEMPERE JM, 1998, LECT NOTES ARTIF INT, V1433, P162; SOLOMONOFF RJ, 1964, INFORM CONTROL, V7, P224, DOI 10.1016/S0019-9958(64)90131-7; STOLCKE A, 1994, LECT NOTES ARTIF INT, V862, P106; STOLCKE A, 1995, COMPUT LINGUIST, V21, P165; TAKADA Y, 1994, LECT NOTES ARTIF INT, V862, P16; Takao H, 2004, J COMPUT ASSIST TOMO, V28, P193, DOI 10.1097/00004728-200403000-00007; TELLIER I, 1998, LECT NOTES ARTIF INT, V1433, P25; Thollard F., 2000, P 17 INT C MACH LEAR, P975; THOLLARD F, 2001, 8 INT C MACH LEARN W, P561; Thomason M.G., 1978, SYNTACTIC PATTERN RE; Trakhtenbrot B.A., 1973, FINITE AUTOMATA BEHA; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; VANZAANEN M, 2003, GRAMMATICAL INFERENC; Vilar JM, 2000, LECT NOTES ARTIF INT, V1891, P298; VILAR JM, 1996, LECT NOTES ARTIF INT, V1147, P72; Wang JTL, 1999, J COMPUT BIOL, V6, P209, DOI 10.1089/cmb.1999.6.209; WANG Y, 2001, P IEEE WORKSH AUT SP; WANG Y, 2002, P INT C AC SPEECH SI; WARMUTH MK, 1989, LECT NOTES ARTIF INT, V397, P78; WATANABE O, 1999, LECT NOTES COMPUTER, V1720; WHARTON RM, 1974, INFORM CONTROL, V26, P236, DOI 10.1016/S0019-9958(74)91369-2; WITTEN IH, 1991, IEEE T INFORM THEORY, V37, P1085, DOI 10.1109/18.87000; Wright K., 1989, Proceedings of the Second Annual Workshop on Computational Learning Theory; YOKOMORI T, 1994, P INT WORKSH ROUGH S; Yokomori T., 1994, MACH INTELL, V13, P169; YOKOMORI T, 1996, MATH SYST THEORY, P259; YOKOMORI T, 1989, LECT NOTES ARTIF INT, V397, P104; Young-Lai M, 2000, MACH LEARN, V40, P111, DOI 10.1023/A:1007653929870; Zeugmann T., 1993, LECTURE NOTES ARTIFI, V<IT>659</IT>, P254; ZEUGMANN T, 1999, ALT SERIES HOME PAGE	198	47	47	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	SEP	2005	38	9					1332	1348		10.1016/j.patcog.2005.01.003		17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	939BT	WOS:000230047900002	
J	Nakamura, K; Matsumoto, M				Nakamura, K; Matsumoto, M			Incremental learning of context free grammars based on bottom-up parsing and search	PATTERN RECOGNITION			English	Article; Proceedings Paper	6th International Colloquium on Grammatical Inference	SEP 23-25, 2002	AMSTERDAM, NETHERLANDS			incremental learning; CYK algorithm; context free language; unambiguous grammar; Chomsky normal form; synapse		This paper describes approaches for machine learning of context free grammars (CFGs) from positive and negative sample strings, which are implemented in Synapse system. The grammatical inference consists of a rule generation by "inductive CYK algorithm," mechanisms for incremental learning, and search. Inductive CYK algorithm generates minimum production rules required for parsing positive samples, when the bottom-up parsing by CYK algorithm does not succeed. The incremental learning is used not only for synthesizing grammars by giving the system positive strings in the order of their length but also for learning grammars from other similar grammars. Synapse can synthesize fundamental ambiguous and unambiguous CFGs including nontrivial grammars such as the set of strings not of the form omega omega with omega is an element of {a, b}(+). (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Tokyo Denki Univ, Dept Syst & Comp Engn, Hatoyama, Saitama 3500394, Japan; Hitachi Ltd, Distribut Syst Div, Shinagawa Ku, Tokyo 1408570, Japan	Nakamura, K (reprint author), Tokyo Denki Univ, Dept Syst & Comp Engn, Hatoyama, Saitama 3500394, Japan.	nakamura@k.dendai.ac.jp					ANGLUIN D, 1995, J COMPUT SYST SCI, V50, P336, DOI 10.1006/jcss.1995.1026; GIBSON E, 1994, LINGUIST INQ, V25, P407; Hopcroft J., 1979, INTRO AUTOMATA THEOR; Langley P, 2000, LECT NOTES ARTIF INT, V1810, P220; Nakamura K, 2000, LECT NOTES ARTIF INT, V1891, P186; Nakamura K, 2002, LECT NOTES ARTIF INT, V2484, P174; PAREKH R, 1996, LECT NOTES COMPUTER, V1147, P222; PITT L, 1993, J ACM, V40, P95, DOI 10.1145/138027.138042; Sakakibara Y, 2000, LECT NOTES ARTIF INT, V1891, P229; SAKAKIBARA Y, 1999, P 16 INT C MACH LEAR, P354; VERVOORT M, 2002, EMILE 4 4 6 USER GUI	11	12	12	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	SEP	2005	38	9					1384	1392		10.1016/j.patcog.2005.01.004		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	939BT	WOS:000230047900005	
J	Rocco, CM; Muselli, M				Rocco, CM; Muselli, M			Approximate multi-state reliability expressions using a new machine learning technique	RELIABILITY ENGINEERING & SYSTEM SAFETY			English	Article						network reliability evaluation; reliability expression; rule generation; hamming clustering; multi-state system	STOCHASTIC-FLOW NETWORK; MINIMAL CUTS; PRODUCTS	The machine-learning-based methodology, previously proposed by the authors for approximating binary reliability expressions, is now extended to develop a new algorithm, based on the procedure of Hamming Clustering, which is capable to deal with multi-state systems and any success criterion. The proposed technique is presented in details and verified on literature cases: experiment results show that the new algorithm yields excellent predictions. (c) 2004 Elsevier Ltd. All rights reserved.	Cent Univ Venezuela, Fac Ingn, Caracas, Venezuela; CNR, Ist Elettron & Ingn Informaz & Telecomun, Genoa, Italy	Rocco, CM (reprint author), Cent Univ Venezuela, Fac Ingn, Caracas, Venezuela.	crocco@reacciun.ve; marco.muselli@ieiit.cnr.it	Rocco Sanseverino, Claudio M/G-5427-2010				AGGARWAL KK, 1982, IEEE T RELIAB, V31; Colbourn C.J., 1987, COMBINATORICS NETWOR; HEIDTMANN KD, 1989, IEEE T RELIAB, V38, P305, DOI 10.1109/24.44172; Jin T, 2003, RELIAB ENG SYST SAFE, V82, P41, DOI 10.1016/S0951-8320(03)00117-0; Lin YK, 2001, COMPUT OPER RES, V28, P1277, DOI 10.1016/S0305-0548(00)00039-3; Lin YK, 2002, RELIAB ENG SYST SAFE, V75, P41, DOI 10.1016/S0951-8320(01)00110-7; LISNIANSKI A, 2003, MULTI STATE SYSTEM R; Muselli M, 2000, IEEE T CIRCUITS-I, V47, P513, DOI 10.1109/81.841853; Muselli M, 2002, IEEE T KNOWL DATA EN, V14, P1258, DOI 10.1109/TKDE.2002.1047766; Papadimitriou C., 1982, COMBINATORIAL OPTIMI; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; RAMIREZMARQUEZ JE, 2003, P IND ENG RES C PORT; RAMIREZMARQUEZ JE, 2003, 03121 RUTG U IE; RAMIREZMARQUEZ JE, 2002, 03135 RUTG U IE; RAMIREZMARQUEZ JE, 2005, RELIAB ENG SYST, V87, P149; Rauzy A, 2003, RELIAB ENG SYST SAFE, V79, P33, DOI 10.1016/S0951-8320(02)00165-5; Reingold E.M., 1977, COMBINATORIAL ALGORI; Rocco CM, 2004, RELIAB ENG SYST SAFE, V83, P301, DOI 10.1016/j.ress.2003.10.001; ROCCO S, 2004, P PROB SAF ASS MAN P, P3142; TORGO LF, 1999, THESIS FACULDADE CIE; Veropulos K, 1999, P INT JOINT C ART IN, P55; YEH WC, 2004, IN PRESS RELIAB ENG; ZIO E, 2004, RELIAB ENG SYST SAFE, V86, P179	23	15	17	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0951-8320		RELIAB ENG SYST SAFE	Reliab. Eng. Syst. Saf.	SEP	2005	89	3					261	270		10.1016/j.ress.2004.08.023		10	Engineering, Industrial; Operations Research & Management Science	Engineering; Operations Research & Management Science	945AF	WOS:000230472000003	
J	Lum, EB; Ma, KL				Lum, EB; Ma, KL			Expressive line selection by example	VISUAL COMPUTER			English	Article; Proceedings Paper	13th Pacific Conference on Computer Graphics and Applications	OCT 12-14, 2005	Macao, PEOPLES R CHINA			non-photorealistic rendering; silhouettes; example-based rendering; machine learning	MODELS	An important problem in computer generated line drawing is determining which set of lines produces a representation that is in agreement with a user's communication goals. We describe a method that enables a user to intuitively specify which types of lines should appear in rendered images. Our method employs conventional silhouette-edge and other feature-line extraction algorithms to derive a set of candidate lines, and integrates machine learning into a user-directed line removal process using a sketching metaphor. The method features a simple and intuitive user interface that provides interactive control over the resulting line selection criteria and can be easily adapted to work in conjunction with existing line detection and rendering algorithms. Much of the method's power comes from its ability to learn the relationships between numerous geometric attributes that define a line style. Once learned, a user's style and intent can be passed from object to object as well as from view to view.	Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA	Lum, EB (reprint author), Univ Calif Davis, Dept Comp Sci, 1 Shields Av, Davis, CA 95616 USA.	lume@cs.ucdavis.edu					Bishop C., 1996, NEURAL NETWORKS PATT; BUCHANAN JW, 2000, P 1 INT S NONPH AN R; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CHEN H, 2004, NPAR 04, P95; Chen H., 2001, ICCV01, V438, P433; Curtis C., 1998, SIGGRAPH 98 C ABSTR, P317, DOI [10.1145/281388.281913, DOI 10.1145/281388.281913]; DECARLO D, 2003, ACM T GRAPHIC, V22, P845; GOOCH B, 1999, 1999 ACM S INT 3D GR, P31; GRABLI S, 2004, RENDERING TECHNIQUES; Hertz J., 1991, INTRO THEORY NEURAL; HERTZMANN A, 2000, P SIGGRAPH 2000, P517, DOI 10.1145/344779.345074; HERTZMANN A, 1999, SIGGRAPH 99 COURSE N; Hertzmann A., 2001, P ACM SIGGRAPH, p[327, 2, 5], DOI 10.1145/383259.383295; ISENBERG T, 2002, COMPUT GRAPH FORUM, V21; Isenberg T, 2003, IEEE COMPUT GRAPH, V23, P28, DOI 10.1109/MCG.2003.1210862; JODOIN P. - M., 2002, NPAR 2002 2 INT S NO, P29; Kalnins RD, 2002, ACM T GRAPHIC, V21, P755; Markosian L., 1997, SIGGRAPH 97 C P, P415; NORTHRUP JD, 2000, P NPAR 2000, P31, DOI DOI 10.1145/340916.340920; Pasztor E, 1999, TR9911 MERL; SAITO T, 2000, P SIGGRAPH 1990 C, P197; SOUSA M, 2003, COMPUTER GRAPHICS, V22; Werbos P., 1974, THESIS HARVARD U	23	3	3	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0178-2789		VISUAL COMPUT	Visual Comput.	SEP	2005	21	8-10			SI		811	820		10.1007/s00371-005-0342-y		10	Computer Science, Software Engineering	Computer Science	964CX	WOS:000231857400034	
J	Dinakarpandian, D; Raheja, V; Mehta, S; Schuetz, EG; Rogan, PK				Dinakarpandian, D; Raheja, V; Mehta, S; Schuetz, EG; Rogan, PK			Tandem machine learning for the identification of genes regulated by transcription factors	BMC BIOINFORMATICS			English	Article							PREGNANE-X-RECEPTOR; INFORMATION-THEORY; BINDING-SITES; TARGET GENES; GENOME; PREDICTION; REFINEMENT; SEQUENCES; CLUSTERS; DATABASE	Background: The identification of promoter regions that are regulated by a given transcription factor has traditionally relied upon the identification and distributions of binding sites recognized by the factor. In this study, we have developed a tandem machine learning approach for the identification of regulatory target genes based on these parameters and on the corresponding binding site information contents that measure the affinities of the factor for these cognate elements. Results: This method has been validated using models of DNA binding sites recognized by the xenobiotic-sensitive nuclear receptor, PXR/RXR alpha, for target genes within the human genome. An information theory-based weight matrix was first derived and refined from known PXR/RXR alpha binding sites. The promoter region of candidate genes was scanned with the weight matrix. A novel information density-based clustering algorithm was then used to identify clusters of information rich sites. Finally, transformed data representing metrics of location, strength and clustering of binding sites were used for classification of promoter regions using an ensemble approach involving neural networks, decision trees and Naive Bayesian classification. The method was evaluated on a set of 24 known target genes and 288 genes known not to be regulated by PXR/RXR alpha. We report an average accuracy ( proportion of correctly classified promoter regions) of 71%, sensitivity of 73%, and specificity of 70%, based on multiple cross-validation and the leave-one-out strategy. The performance on a test set of 13 genes showed that 10 were correctly classified. Conclusion: We have developed a machine learning approach for the successful detection of gene targets for transcription factors with high accuracy. The method has been validated for the transcription factor PXR/RXR alpha and has the potential to be extended to other transcription factors.	Univ Missouri, Sch Comp & Engn, Kansas City, MO 64110 USA; St Jude Childrens Res Hosp, Memphis, TN 38105 USA; Childrens Mercy Hosp, Lab Human Mol Genet, Kansas City, MO 64108 USA	Dinakarpandian, D (reprint author), Univ Missouri, Sch Comp & Engn, Kansas City, MO 64110 USA.	dinakard@umkc.edu; vsrxtd@umkc.edu; saumil07@stanford.edu; Erin.Schuetz@stjude.org; progan@cmh.edu					Alkema WBL, 2004, NUCLEIC ACIDS RES, V32, pW195, DOI 10.1093/nar/gkh387; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Berman BP, 2002, P NATL ACAD SCI USA, V99, P757, DOI 10.1073/pnas.231608898; Ester M., 1996, P 2 INT C KNOWL DISC, P226; Frith MC, 2003, NUCLEIC ACIDS RES, V31, P3666, DOI 10.1093/nar/gkg540; Gadiraju S, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-38; Goodwin B, 2002, ANNU REV PHARMACOL, V42, P1, DOI 10.1146/annurev.pharmtox.42.111901.111051; Handschin C, 2003, PHARMACOL REV, V55, P649, DOI 10.1124/pr.55.4.2; Lamba V, 2004, TOXICOL APPL PHARM, V199, P251, DOI 10.1016/j.taap.2003.12.027; Marchler-Bauer A, 2005, NUCLEIC ACIDS RES, V33, pD192, DOI 10.1093/nar/gki069; Markstein M, 2002, P NATL ACAD SCI USA, V99, P763, DOI 10.1073/pnas.012591199; Matys V, 2003, NUCLEIC ACIDS RES, V31, P374, DOI 10.1093/nar/gkg108; Nalla VK, 2005, HUM MUTAT, V25, P334, DOI 10.1002/humu.20151; Podvinec M, 2002, MOL ENDOCRINOL, V16, P1269, DOI 10.1210/me.16.6.1269; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Quinlan J., 1993, C4 5 PROGRAMS MACHIN, P302; Rebeiz M, 2002, P NATL ACAD SCI USA, V99, P9888, DOI 10.1073/pnas.152320899; Rogan PK, 2003, PHARMACOGENETICS, V13, P207, DOI 10.1097/01.fpc.0000054078.64000.de; Schneider TD, 1996, METHOD ENZYMOL, V274, P445; Schneider TD, 1997, J THEOR BIOL, V189, P427, DOI 10.1006/jtbi.1997.0540; Stormo GD, 2000, BIOINFORMATICS, V16, P16, DOI 10.1093/bioinformatics/16.1.16; Vyhlidal CA, 2004, J BIOL CHEM, V279, P46779, DOI 10.1074/jbc.M408395200; Wagner A, 1999, BIOINFORMATICS, V15, P776, DOI 10.1093/bioinformatics/15.10.776; WITTEN IH, 1999, DATA MINING PRACTICA, P416; ZELL AKT, 1991, P APPL NEURAL NETWOR, V1294	25	2	2	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	AUG 22	2005	6								204	10.1186/1471-2105-6-204		10	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	964CH	WOS:000231855800001	
J	Li, B; Gallin, WJ				Li, B; Gallin, WJ			Computational identification of residues that modulate voltage sensitivity of voltage-gated potassium channels	BMC STRUCTURAL BIOLOGY			English	Article							SHAKER K+ CHANNEL; GENE-EXPRESSION DATA; ION CHANNELS; ELECTROSTATIC INTERACTIONS; STRUCTURAL ELEMENTS; CRYSTAL-STRUCTURE; RAT-BRAIN; CLONING; CANCER; S4	Background: Studies of the structure-function relationship in proteins for which no 3D structure is available are often based on inspection of multiple sequence alignments. Many functionally important residues of proteins can be identified because they are conserved during evolution. However, residues that vary can also be critically important if their variation is responsible for diversity of protein function and improved phenotypes. If too few sequences are studied, the support for hypotheses on the role of a given residue will be weak, but analysis of large multiple alignments is too complex for simple inspection. When a large body of sequence and functional data are available for a protein family, mature data mining tools, such as machine learning, can be applied to extract information more easily, sensitively and reliably. We have undertaken such an analysis of voltage-gated potassium channels, a transmembrane protein family whose members play indispensable roles in electrically excitable cells. Results: We applied different learning algorithms, combined in various implementations, to obtain a model that predicts the half activation voltage of a voltage-gated potassium channel based on its amino acid sequence. The best result was obtained with a k-nearest neighbor classifier combined with a wrapper algorithm for feature selection, producing a mean absolute error of prediction of 7.0 mV. The predictor was validated by permutation test and evaluation of independent experimental data. Feature selection identified a number of residues that are predicted to be involved in the voltage sensitive conformation changes; these residues are good target candidates for mutagenesis analysis. Conclusion: Machine learning analysis can identify new testable hypotheses about the structure/ function relationship in the voltage-gated potassium channel family. This approach should be applicable to any protein family if the number of training examples and the sequence diversity of the training set that are necessary for robust prediction are empirically validated. The predictor and datasets can be found at the VKCDB web site [ 1].	Univ Alberta, Dept Biol Sci, Edmonton, AB T6G 2E9, Canada; Univ Alberta, Dept Cell Biol, Edmonton, AB T6G 2E9, Canada; Harvard Univ, Massachusetts Gen Hosp, Sch Med, Partners AIDS Res Ctr, Charlestown, MA 02129 USA	Gallin, WJ (reprint author), Univ Alberta, Dept Biol Sci, Edmonton, AB T6G 2E9, Canada.	bli4@partners.org; wgallin@ualberta.ca					Abdul M, 2002, ONCOL REP, V9, P961; ADAMS EN, 1972, SYST ZOOL, V21, P390; ALMUALLIM H, 1991, LEARNING MANY IRRELE, P547; Bixby KA, 1999, NAT STRUCT BIOL, V6, P38; Bose I, 2001, INFORM MANAGE-AMSTER, V39, P211, DOI 10.1016/S0378-7206(01)00091-X; CARDIE C, 1993, USING DECISION TREES, P25; Comu S, 1996, ANN NEUROL, V40, P684, DOI 10.1002/ana.410400422; Cooper EC, 2001, EPILEPSIA, V42, P49, DOI 10.1046/j.1528-1157.2001.0420s5049.x; de Lichtenberg U, 2005, BIOINFORMATICS, V21, P1164, DOI 10.1093/bioinformatics/bti093; Doyle DA, 1998, SCIENCE, V280, P69, DOI 10.1126/science.280.5360.69; Edgar RC, 2004, BMC BIOINFORMATICS, V5, P1, DOI 10.1186/1471-2105-5-113; Fleishman SJ, 2004, J MOL BIOL, V340, P307, DOI 10.1016/j.jmb.2004.04.064; Ford John W, 2002, Prog Drug Res, V58, P133; Fry M, 2004, J NEUROBIOL, V60, P227, DOI 10.1002/neu.20024; Hayes WS, 1998, GENOME RES, V8, P1154; HEGINBOTHAM L, 1992, SCIENCE, V258, P1152, DOI 10.1126/science.1279807; HENIKOFF S, 1992, P NATL ACAD SCI USA, V89, P10915, DOI 10.1073/pnas.89.22.10915; Higgins DG, 1996, METHOD ENZYMOL, V266, P383; Hille B, 2001, ION CHANNELS EXCITAB, P814; Holmqvist MH, 2002, P NATL ACAD SCI USA, V99, P1035, DOI 10.1073/pnas.022509299; Jan LY, 1997, J PHYSIOL-LONDON, V505, P267, DOI 10.1111/j.1469-7793.1997.267bb.x; Jentsch TJ, 2000, NAT REV NEUROSCI, V1, P21, DOI 10.1038/35036198; Jiang YX, 2002, NATURE, V417, P515, DOI 10.1038/417515a; Jiang YX, 2003, NATURE, V423, P42, DOI 10.1038/nature01581; Jiang YX, 2002, NATURE, V417, P523, DOI 10.1038/417523a; Kira K., 1992, FEATURE SELECTION PR, P129; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Koni PA, 2003, J BIOL CHEM, V278, P39443, DOI 10.1074/jbc.M304879200; Kuo AL, 2003, SCIENCE, V300, P1922, DOI 10.1126/science.1085028; Laine M, 2004, FEBS LETT, V564, P257, DOI 10.1016/S0014-5793(04)00273-X; Larsson HP, 1996, NEURON, V16, P387, DOI 10.1016/S0896-6273(00)80056-2; LERCHE H, 2003, NATURE, V423, P33; Li B, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-3; Li-Smerin YY, 2000, J GEN PHYSIOL, V115, P33; Listgarten J, 2004, CLIN CANCER RES, V10, P2725, DOI 10.1158/1078-0432.CCR-1115-03; MacKinnon R, 1991, Curr Opin Neurobiol, V1, P14, DOI 10.1016/0959-4388(91)90005-R; Maddison DR, 2003, MACCLADE 4 ANAL PHYL; Mendez MA, 2002, FEBS LETT, V522, P24, DOI 10.1016/S0014-5793(02)02873-9; MILLER C, 1991, SCIENCE, V252, P1092, DOI 10.1126/science.252.5009.1092; Mitchell T, 1997, MACHINE LEARNING; Nguyen DV, 2002, BIOINFORMATICS, V18, P39, DOI 10.1093/bioinformatics/18.1.39; OVERTURF KE, 1994, AM J PHYSIOL-CELL PH, V267, pC1231; PAPAZIAN DM, 1995, NEURON, V14, P1293, DOI 10.1016/0896-6273(95)90276-7; Patton DE, 1997, NEURON, V19, P711, DOI 10.1016/S0896-6273(00)80383-9; POTTER DM, 2004, STAT MED; Rae JL, 2000, EXP EYE RES, V70, P339, DOI 10.1006/exer.1999.0796; RETTIG J, 1992, EMBO J, V11, P2473; Ringner M, 2003, BIOTECHNIQUES, P30; Ronquist F, 2003, BIOINFORMATICS, V19, P1572, DOI 10.1093/bioinformatics/btg180; Routledge RD, 1997, COMPUT STAT DATA AN, V24, P379, DOI 10.1016/S0167-9473(96)00073-4; SALVADORRECATAL.V, 2004, UNPUB STRUCTURE FUNC; Sands Z, 2005, CURR BIOL, V15, pR44, DOI 10.1016/j.cub.2004.12.050; Scholle A, 2000, RECEPTOR CHANNEL, V7, P65; SCHROTER KH, 1991, FEBS LETT, V278, P211, DOI 10.1016/0014-5793(91)80119-N; Schwartz R. M., 1978, ATLAS PROTEIN SEQ S3, V5, P345; Seoh SA, 1996, NEURON, V16, P1159, DOI 10.1016/S0896-6273(00)80142-7; Sokolova O, 2001, STRUCTURE, V9, P215, DOI 10.1016/S0969-2126(01)00578-0; STUHMER W, 1989, NATURE, V339, P597, DOI 10.1038/339597a0; SWOFFORD DL, 2000, PAUP PHYLOGENETIC AN; Tag PM, 1996, J APPL METEOROL, V35, P714, DOI 10.1175/1520-0450(1996)035<0714:MLOMFF>2.0.CO;2; TiwariWoodruff SK, 1997, BIOPHYS J, V72, P1489; Tiwari-Woodruff SK, 2000, J GEN PHYSIOL, V115, P123, DOI 10.1085/jgp.115.2.123; Treptow W, 2004, BIOPHYS J, V87, P2365, DOI 10.1529/biophysj.104.039628; Weiss JL, 1999, J NEUROBIOL, V38, P287, DOI 10.1002/(SICI)1097-4695(19990205)38:2<287::AID-NEU10>3.0.CO;2-U; WISHART DS, 1994, COMPUT APPL BIOSCI, V10, P687; WITTEN IH, 2000, M KAUFMANN SERIES DA; Yellen G, 2002, NATURE, V419, P35, DOI 10.1038/nature00978; Yellen G, 1998, Q REV BIOPHYS, V31, P239, DOI 10.1017/S0033583598003448	68	7	7	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2237		BMC STRUCT BIOL	BMC Struct. Biol.	AUG 19	2005	5								16	10.1186/1472-6807-5-16		17	Biophysics	Biophysics	997YN	WOS:000234285000001	
J	Piramuthu, S				Piramuthu, S			Knowledge-based framework for automated dynamic supply chain configuration - Production, manufacturing and logistics	EUROPEAN JOURNAL OF OPERATIONAL RESEARCH			English	Article						adaptive decision support system; e-commerce; supply chain configuration	INFORMATION; INVENTORIES	Supply chain management has gained renewed interest among researchers in recent years. This is primarily due to the availability of timely information across the various stages of the supply chain, and therefore the need to effectively utilize the information for improved performance. Although information plays a major role in effective functioning of supply chains, there is a paucity of studies that deal specifically with the dynamics of supply chains and how data collected in these systems can be used to improve their performance. In this paper I develop a framework, with machine learning, for automated supply chain configuration. Supply chain configuration used to be mostly a one-shot problem. Once a supply chain is configured, researchers and practitioners were more interested in means to improve performance given that initial configuration. However, recent developments in e-commerce applications and faster communication over the Internet in general necessitates dynamic (re)configuration of supply chains over time to take advantage of better configurations. Using examples, I show performance improvements of the proposed adaptive supply chain configuration framework over static configurations. (c) 2004 Elsevier B.V. All rights reserved.	Univ Florida, Gainesville, FL 32611 USA	Piramuthu, S (reprint author), Univ Florida, 351 Stuzin Hall,POB 117169, Gainesville, FL 32611 USA.	selwyn@ufl.edu					AKKERMANS H, 2001, P 34 HAW INT C SYST; ALLES M, 2000, MANAGEMENT SCI, V46; Baganha M. P., 1998, OPER RES, V46, P72; BELL DR, 1998, MANAGE SCI, V44, pS145; Bourland KE, 1996, EUR J OPER RES, V92, P239, DOI 10.1016/0377-2217(95)00136-0; Cachon GP, 2000, MANAGE SCI, V46, P1032, DOI 10.1287/mnsc.46.8.1032.12029; CLARK AJ, 1960, MANAGE SCI, V6, P475, DOI 10.1287/mnsc.6.4.475; COLLINS J, 2001, WORKSH AG BAS APPR B; Copacino W., 1997, SUPPLY CHAIN MANAGEM; GRASER TJ, 1997, P DETC 97 1997 ASME; Graves S. C., 1993, LOGISTICS PRODUCTION, V4; Handfield R.B., 1998, INTRO SUPPLY CHAIN M; Hariharan R, 1995, MANAGE SCI, V41, P1599, DOI 10.1287/mnsc.41.10.1599; KARMARKAR US, 1987, MANAGE SCI, V33, P409, DOI 10.1287/mnsc.33.3.409; KNIRSCH P, 1999, LOGISTICS INFORMATIO, P213; Lee HL, 1997, MANAGE SCI, V43, P546, DOI 10.1287/mnsc.43.4.546; LEE HL, 2000, INT J MANUFACTURING, V1; LEE HL, 1992, SLOAN MANAGEMENT SPR, P65; Lee WW, 1997, J NUCL MED, V38, P3; MUKHOPADHYAY T, 1997, MANAGEMENT SCI   DEC; Park SC, 2001, DECIS SUPPORT SYST, V31, P205, DOI 10.1016/S0167-9236(00)00132-9; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 2002, C5 0 RULEQUEST RES; RADJOU N, 2002, SUPPL CHAIN WORLD N; SIMCHILEVI D, 1998, DESIGNING MANAGING S; Tayur S., 1999, QUANTITATIVE MODELS; VANDERPOL JM, 2000, 11 INT WORK SEM PROD, V3, P621; Waller M.A., 1999, J BUSINESS LOGISTICS, V20, P183; WALSH W, 2001, THESIS U MICHIGAN; WALSH WE, 1999, IJCAI 99 WORKSH AG M; WALSH WE, 2000, ACM C EL COMM MINN; Whang S., 1993, Journal of Organizational Computing, V3; WOOLLEY S, 1997, FORBES          0324, P54; *SAP, 2000, 2002 SAP	34	43	44	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0377-2217		EUR J OPER RES	Eur. J. Oper. Res.	AUG 16	2005	165	1					219	230		10.1016/j.ejor.2003.12.023		12	Management; Operations Research & Management Science	Business & Economics; Operations Research & Management Science	905CJ	WOS:000227545000014	
J	Nagy, B				Nagy, B			On the language equivalence of NE star-patterns	INFORMATION PROCESSING LETTERS			English	Article						formal languages; pattern languages; star-pattern; non-erasing pattern; extended regex		A pattern is a finite string of constant and variable symbols. The language generated by a pattern is the set of all strings of constant symbols which can be obtained from the pattern by substituting (non-empty) strings for variables. The pattern languages are one of language family which is orthogonal to the Chomsky-type languages hierarchy. They have many applications, such as the extended regular expressions, for instance, in languages Perl, awk, etc. They are well applicable in machine learning as well. There are erasing and non-erasing patterns are used. For non-erasing pattern languages the equivalence of languages is decidable but the inclusion problem for them is undecidable. In extended regular expressions one can use union, concatenation and Kleene star to make more complex patterns. It is also known, that the equivalence problem of extended regular expressions is undecidable. However, the problem, whether the equivalence is decidable for patterns using only concatenation and star still open. In this paper there are some interesting results about inclusion properties and equivalences of some kinds of erasing and non-erasing pattern languages. We show that the equivalence problem of non-erasing patterns in some cases can be reduced to the decidability problem of some very special inclusion properties. These results may be useful to decide whether the language equivalence of non-erasing star-patterns is decidable or not. (c) 2005 Elsevier B.V. All rights reserved.	Univ Rovira & Virgili, Res Grp Math Linguist, Tarragona 43005, Spain; Debrecen Univ Med, Fac Informat, H-4010 Debrecen, Hungary	Nagy, B (reprint author), Univ Rovira & Virgili, Res Grp Math Linguist, Pl Imperial Tarraco 1, Tarragona 43005, Spain.	nbenedek@inf.unideb.hu	Nagy, Benedek/A-5415-2008	Nagy, Benedek/0000-0002-9494-6440			ANGLUIN D, 1980, J COMPUT SYST SCI, V21, P46, DOI 10.1016/0022-0000(80)90041-0; Campeanu C., 2003, International Journal of Foundations of Computer Science, V14, DOI 10.1142/S012905410300214X; Friedl J. E. F., 1997, MASTERING REGULAR EX; JANTKE KP, 1984, LECT NOTES COMPUT SC, V166, P314; JIANG T, 1995, J COMPUT SYST SCI, V50, P53, DOI 10.1006/jcss.1995.1006; NAGY B, 2004, CDMTCS252, P51; SALOMAA K, 2004, FORMAL LANGUAGES APP, P367	7	1	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0020-0190		INFORM PROCESS LETT	Inf. Process. Lett.	AUG 16	2005	95	3					396	400		10.1016/j.ipl.2005.05.003		5	Computer Science, Information Systems	Computer Science	943KL	WOS:000230352300004	
J	Solan, Z; Horn, D; Ruppin, E; Edelman, S				Solan, Z; Horn, D; Ruppin, E; Edelman, S			Unsupervised learning of natural languages	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article						computational linguistics; grammar induction; language acquisition; machine learning; protein classification	GRAMMAR; INFANTS; SPEECH	We address the problem, fundamental to linguistics, bioinformatics, and certain other disciplines, of using corpora of raw symbolic sequential data to infer underlying rules that govern their production. Given a corpus of strings (such as text, transcribed speech, chromosome or protein sequence data, sheet music, etc.), our unsupervised algorithm recursively distills from it hierarchically structured patterns. The ADIOS (automatic distillation of structure) algorithm relies on a statistical method for pattern extraction and on structured generalization, two processes that have been implicated in language acquisition. It has been evaluated on artificial context-free grammars with thousands of rules, on natural languages as diverse as English and Chinese, and on protein data correlating sequence with function. This unsupervised algorithm is capable of learning complex syntax, generating grammatical novel sentences, and proving useful in other fields that call for structure discovery from raw data, such as bioinformatics.	Cornell Univ, Dept Psychol, Ithaca, NY 14853 USA; Tel Aviv Univ, Sch Phys & Astron, IL-69978 Tel Aviv, Israel; Tel Aviv Univ, Sch Comp Sci, IL-69978 Tel Aviv, Israel	Edelman, S (reprint author), Cornell Univ, Dept Psychol, Ithaca, NY 14853 USA.	se37@cornell.edu					Adriaans P, 2002, LECT NOTES ARTIF INT, V2484, P293; Adriaans Pieter W., 2004, GRAMMARS, V7, P57; Cai CZ, 2003, NUCLEIC ACIDS RES, V31, P3692, DOI 10.1093/nar/gkg600; Cameron-Faulkner T, 2003, COGNITIVE SCI, V27, P843, DOI 10.1016/j.cogsci.2003.06.001; CHELBA C, 2001, P IEEE INT C AC SPEE, V1, pA544; CHOMSKY N, 1986, KNOWLEDGE LANGUAGE N; CLARK A, 2001, THESIS U SUSSEX SUSS; de Marcken C. G., 1996, THESIS MIT CAMBRIDGE; Fillmore Charles J., 1985, BERKELEY LINGUISTIC, V11, P73; FINCH S, 1991, ARTIF INTELL SIMUL B, V78, P16; GEMAN S, 2003, IMA VOLUMES MATH ITS, V138, P1; Goldberg AE, 2003, TRENDS COGN SCI, V7, P219, DOI 10.1016/S1364-6613(03)00080-9; Gomez RL, 2002, PSYCHOL SCI, V13, P431, DOI 10.1111/1467-9280.00476; Goodman J. T., 2001, MSRTR200172; Gross M, 1997, LANG SPEECH & COMMUN, P329; Guyon I., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, DOI 10.1109/ICDAR.1995.599034; HARRIS ZS, 1954, WORD, V10, P140; Hemphill C.T, 1990, P DARPA SPEECH NAT L, P96, DOI 10.3115/116580.116613; HENRICHSEN PJ, 2002, P CONLL 2002 TAIP TA, P22; HOPCROFT JE, 1979, INTRO AUTOMATA THELR; KERMORVANT C, 2004, J ELECTRONIQUE INTEL, V6; Klein D., 2004, P 42 ANN M ASS COMP, P478, DOI 10.3115/1218955.1219016; Klein D, 2002, ADV NEUR IN, V14, P35; Lari K., 1990, Computer Speech and Language, V4, DOI 10.1016/0885-2308(90)90022-X; MACWHINNEY B, 1985, J CHILD LANG, V12, P271; MAGERMAN DM, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P984; Marcus GF, 1999, SCIENCE, V283, P77, DOI 10.1126/science.283.5398.77; MARKMAN EM, 1988, CATEGORIZATION NAMIN; MCCANDLESS MK, 1993, P 3 EUR C SPEECH COM, P981; Nowak MA, 2001, SCIENCE, V291, P114, DOI 10.1126/science.291.5501.114; Pena M, 2002, SCIENCE, V298, P604, DOI 10.1126/science.1072901; Pereira F, 2000, PHILOS T ROY SOC A, V358, P1239, DOI 10.1098/rsta.2000.0583; PHILLIPS C, 2003, ENCY COGNITIVE SCI, V4, P319; Plunkett Kim, 1996, RETHINKING INNATENES; Resnik P, 1999, COMPUT HUMANITIES, V33, P129, DOI 10.1023/A:1001798929185; Roark B, 2001, COMPUT LINGUIST, V27, P249, DOI 10.1162/089120101750300526; Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926; Seidenberg MS, 1997, SCIENCE, V275, P1599, DOI 10.1126/science.275.5306.1599; Seidenberg MS, 2002, SCIENCE, V298, P553, DOI 10.1126/science.1078094; Stolcke A., 1994, Grammatical Inference and Applications. Second International Colloquium, ICGI-94 Proceedings; van Zaanen M., 2000, P 18 INT C COMP LING, P961; Wolff J., 1988, CATEGORIES PROCESSES, P179	42	61	62	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424		P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	AUG 16	2005	102	33					11629	11634		10.1073/pnas.0409746102		6	Multidisciplinary Sciences	Science & Technology - Other Topics	956RH	WOS:000231317000013	
J	West-Hielsen, M; Hogdall, EV; Marchiori, E; Hogdall, CK; Schou, C; Heegaard, NHH				West-Hielsen, M; Hogdall, EV; Marchiori, E; Hogdall, CK; Schou, C; Heegaard, NHH			Sample handling for mass spectrometric proteomic investigations of human sera	ANALYTICAL CHEMISTRY			English	Article							OVARIAN-CANCER; SELDI-TOF; BIOMARKER DISCOVERY; PATTERNS; DIAGNOSIS; CLASSIFICATION; STABILITY; PROSTATE; FLUIDS	Proteomic investigations of sera are potentially of value for diagnosis, prognosis, choice of therapy, and disease activity assessment by virtue of discovering new biomarkers and biomarker patterns. Much debate focuses on the biological relevance and the need for identification of such biomarkers while less effort has been invested in devising standard procedures for sample preparation and storage in relation to model building based on complex sets of mass spectrometric (MS) data. Thus, development of standardized methods for collection and storage of patient samples together with standards for transportation and handling of samples are needed. This requires knowledge about how sample processing affects MS-based proteome analyses and thereby how nonbiological biased classification errors are avoided. In this study, we characterize the effects of sample handling, including clotting conditions, storage temperature, storage time, and freeze/thaw cycles, on MS-based proteomics of human serum by using principal components analysis, support vector machine learning, and clustering methods based on genetic algorithms as class modeling and prediction methods. Using spiking to artificially create differentiable sample groups, this integrated approach yields data that - even when working with sample groups that differ more than may be expected in biological studies -clearly demonstrate the need for comparable sampling conditions for samples used for modeling and for the samples that are going into the test set group. Also, the study emphasizes the difference between class prediction and class comparison studies as well as the advantages and disadvantages of different modeling methods.	Statens Serum Inst, Dept Autoimmunol, DK-2300 Copenhagen, Denmark; Danish Canc Soc, Inst Canc Epidemiol, Dept Virus Hormones & Canc, DK-2100 Copenhagen, Denmark; Free Univ Amsterdam, Dept Comp Sci, NL-1081 HV Amsterdam, Netherlands; Rigshosp, Julia Marie Ctr, Gynecol Clin, DK-2100 Copenhagen, Denmark	Heegaard, NHH (reprint author), Statens Serum Inst, Dept Autoimmunol, DK-2300 Copenhagen, Denmark.	nhe@ssi.dk					Adam BL, 2001, PROTEOMICS, V1, P1264, DOI 10.1002/1615-9861(200110)1:10<1264::AID-PROT1264>3.0.CO;2-R; Alexe G, 2004, PROTEOMICS, V4, P766, DOI 10.1002/pmic.200300574; Baggerly KA, 2004, BIOINFORMATICS, V20, P777, DOI 10.1093/bioinformatics/btg484; Carrette O, 2003, PROTEOMICS, V3, P1486, DOI 10.1002/pmic.200300470; Coombes KR, 2003, CLIN CHEM, V49, P1615, DOI 10.1373/49.10.1615; Cordingley HC, 2003, BIOTECHNIQUES, V34, P364; Cristiannini N., 2000, SUPPORT VECTOR MACHI; Diamandis EP, 2004, J NATL CANCER I, V96, P353, DOI 10.1093/jnci/djh056; Diamandis EP, 2003, CLIN CHEM, V49, P1272, DOI 10.1373/49.8.1272; Diamandis EP, 2004, MOL CELL PROTEOMICS, V3, P367, DOI 10.1074/mcp.R400007-MCP200; Evgeniou T, 2004, MACH LEARN, V55, P71, DOI 10.1023/B:MACH.0000019805.88351.60; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hogdall EVS, 1999, CLIN CHEM, V45, P692; Hogdall EVS, 2000, SCAND J CLIN LAB INV, V60, P247, DOI 10.1080/00365510050184886; Hulmes JD, 2004, CLIN PROTEOMICS, V1, P17, DOI 10.1385/CP:1:1:017; Li LP, 2004, BIOINFORMATICS, V20, P1638, DOI 10.1093/bioinformatics/bth098; Paweletz CP, 2001, DIS MARKERS, V17, P301; Petricoin E, 2003, CLIN CHEM, V49, P1276, DOI 10.1373/49.8.1276; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Pusch W, 2003, PHARMACOGENOMICS, V4, P463, DOI 10.1517/phgs.4.4.463.22753; Riisbro R, 2001, INT J BIOL MARKER, V16, P233; Rosenblatt KP, 2004, ANNU REV MED, V55, P97, DOI 10.1146/annurev.med.55.091902.105237; Schaub S, 2004, KIDNEY INT, V65, P323, DOI 10.1111/j.1523-1755.2004.00352.x; Simon R, 2003, J NATL CANCER I, V95, P14; Sorace JM, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-24; Vapnik VN, 1998, STAT LEARNING THEORY; Villanueva J, 2004, NATURE, V430, P611, DOI 10.1038/430611b; Villanueva J, 2004, ANAL CHEM, V76, P1560, DOI 10.1021/ac0352171; Wellmann A, 2002, INT J MOL MED, V9, P341; White CN, 2004, CLIN BIOCHEM, V37, P636, DOI 10.1016/j.clinbiochem.2004.05.004; Zhukov TA, 2003, LUNG CANCER, V40, P267, DOI 10.1016/S0169-5002(03)00082-5	31	79	79	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0003-2700		ANAL CHEM	Anal. Chem.	AUG 15	2005	77	16					5114	5123		10.1021/ac050253g		10	Chemistry, Analytical	Chemistry	955OT	WOS:000231236300006	
J	Bhasin, M; Zhang, H; Reinherz, EL; Reche, PA				Bhasin, M; Zhang, H; Reinherz, EL; Reche, PA			Prediction of methylated CpGs in DNA sequences using a support vector machine	FEBS LETTERS			English	Article						DNA; CpG; methylation; support vector machine; prediction	MAMMALIAN DEVELOPMENT; ISLAND METHYLATION; BINDING; CANCER; PROMOTER; HYPOMETHYLATION; TRANSCRIPTION; TUMORS	DNA methylation plays a key role in the regulation of gene expression. The most common type of DNA modification consists of the methylation of cytosine in the CpG dinucleotide. At the present time, there is no method available for the prediction of DNA methylation sites. Therefore, in this study we have developed a support vector machine (SVM)-based method for the prediction of cytosine methylation in CpG dinucleotides. Initially a SVM module was developed from human data for the prediction of human-specific methylation sites. This module achieved a MCC and AUC of 0.501 and 0.814, respectively, when evaluated using a 5-fold cross-validation. The performance of this SVM-based module was better than the classifiers built using alternative machine learning and statistical algorithms including artificial neural networks, Bayesian statistics, and decision trees. Additional SVM modules were also developed based on mammalian- and vertebrate-specific methylation patterns. The SVM module based on human methylation patterns was used for genome-wide analysis of methylation sites. This analysis demonstrated that the percentage of methylated CpGs is higher in UTRs as compared to exonic and intronic regions of human genes. This method is available on line for public use under the name of Methylator at http://bio.dfci.harvard.edu/Methylator/. (c) 2005 Federation of European Biochemical Societies. Published by Elsevier B.V. All rights reserved.	Harvard Univ, Sch Med, Dana Farber Canc Inst, Immunobiol Lab, Boston, MA 02115 USA; Harvard Univ, Sch Med, Dana Farber Canc Inst, Dept Med Oncol, Boston, MA 02115 USA; Harvard Univ, Sch Med, Dept Med, Boston, MA 02115 USA	Reche, PA (reprint author), Harvard Univ, Sch Med, Dana Farber Canc Inst, Immunobiol Lab, 77 Ave Louis Pasteur, Boston, MA 02115 USA.	reche@research.dfci.harvard.edu					Adorjan P, 2002, NUCLEIC ACIDS RES, V30, DOI 10.1093/nar/30.5.e21; Ahuja N, 2000, HISTOL HISTOPATHOL, V15, P835; Amoreira C, 2003, NUCLEIC ACIDS RES, V31, P75, DOI 10.1093/nar/gkg093; Bhasin M, 2004, BIOINFORMATICS, V20, P421, DOI 10.1093/bioinformatics/btg424; BIRD A, 1992, CELL, V70, P5, DOI 10.1016/0092-8674(92)90526-I; BIRD A, 1985, CELL, V40, P91, DOI 10.1016/0092-8674(85)90312-5; BIRD AP, 1986, NATURE, V321, P209, DOI 10.1038/321209a0; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; CAIAFA P, 2004, J CELL BIOCHEM, V94, P257; Costello JF, 2000, NAT GENET, V24, P132, DOI 10.1038/72785; Dasarathy BV, 1991, NEAREST NEIGHBOR NOR; DOERFLER W, 1983, ANNU REV BIOCHEM, V52, P93, DOI 10.1146/annurev.bi.52.070183.000521; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Eden A, 2003, SCIENCE, V300, P455, DOI 10.1126/science.1083557; Ehrenhofer-Murray AE, 2004, EUR J BIOCHEM, V271, P2335, DOI 10.1111/j.1432-1033.2004.04162.x; Feltus FA, 2003, P NATL ACAD SCI USA, V100, P12253, DOI 10.1073/pnas.2037852100; Frank E, 2004, BIOINFORMATICS, V20, P2479, DOI 10.1093/bioinformatics/bth261; Gaudet F, 2003, SCIENCE, V300, P489, DOI 10.1126/science.1083558; Hamet P, 2003, METABOLISM, V52, P5, DOI 10.1053/S0026-0495(03)00294-4; Hermann A, 2004, CELL MOL LIFE SCI, V61, P2571, DOI 10.1007/s00018-004-4201-1; Hosmer DW, 1989, APPL LOGISTIC REGRES; Iannello RC, 2000, J BIOL CHEM, V275, P19603, DOI 10.1074/jbc.M001867200; IGUCHIARIGA SMM, 1989, GENE DEV, V3, P612, DOI 10.1101/gad.3.5.612; INAMDAR NM, 1991, PLANT MOL BIOL, V17, P111, DOI 10.1007/BF00036811; Issa JP, 2004, NAT REV CANCER, V4, P988, DOI 10.1038/nrc1507; Joachims T., 1999, ADV KERNEL METHODS S; Jones PA, 2002, ONCOGENE, V21, P5358, DOI 10.1038/sj.onc.1205597; Li E, 2002, NAT REV GENET, V3, P662, DOI 10.1038/nrg887; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; RAMASHOYE BH, 2000, P NATL ACAD SCI USA, V97, P5237; Reik W, 2001, SCIENCE, V293, P1089, DOI 10.1126/science.1063443; RIGGS AD, 1983, ADV CANCER RES, V40, P1, DOI 10.1016/S0065-230X(08)60678-8; RITCHOT N, 1990, GENE, V86, P103, DOI 10.1016/0378-1119(90)90120-G; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; SCARANO MI, 2004, J CELL PHYSL, P21; Shi T, 2005, HELICOBACTER, V10, P71, DOI 10.1111/j.1523-5378.2005.00293.x; SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615; Takai D, 2002, P NATL ACAD SCI USA, V99, P3740, DOI 10.1073/pnas.052410099; Ward JJ, 2003, BIOINFORMATICS, V19, P1650, DOI 10.1093/bioinformatics/btg223; ZELL A, 1997, STUTTGART NEURAL NET; Zhang ZY, 2002, MECH AGEING DEV, V123, P1257	41	31	35	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0014-5793		FEBS LETT	FEBS Lett.	AUG 15	2005	579	20					4302	4308		10.1016/j.febslet.2005.07.002		7	Biochemistry & Molecular Biology; Biophysics; Cell Biology	Biochemistry & Molecular Biology; Biophysics; Cell Biology	957DX	WOS:000231350900017	
J	Bauckhage, C; Hanheide, M; Wrede, S; Kaster, T; Pfeiffer, M; Sagerer, G				Bauckhage, C; Hanheide, M; Wrede, S; Kaster, T; Pfeiffer, M; Sagerer, G			Vision systems with the human in the loop	EURASIP JOURNAL ON APPLIED SIGNAL PROCESSING			English	Article						cognitive vision; adaption; learning; contextual reasoning; architecture; evaluation		The emerging cognitive vision paradigm deals with vision systems that apply machine learning and automatic reasoning in order to learn from what they perceive. Cognitive vision systems can rate the relevance and consistency of newly acquired knowledge, they can adapt to their environment and thus will exhibit high robustness. This contribution presents vision systems that aim at flexibility and robustness. One is tailored for content-based image retrieval, the others are cognitive vision systems that constitute prototypes of visual active memories which evaluate, gather, and integrate contextual knowledge for visual analysis. All three systems are designed to interact with human users. After we will have discussed adaptive content-based image retrieval and object and action recognition in an office environment, the issue of assessing cognitive systems will be raised. Experiences from psychologically evaluated human-machine interactions will be reported and the promising potential of psychologically-based usability experiments will be stressed.	Univ Bielefeld, Fac Technol, D-33501 Bielefeld, Germany	Bauckhage, C (reprint author), Univ Bielefeld, Fac Technol, POB 100131, D-33501 Bielefeld, Germany.	cbauckha@techfak.uni-bielefeld.de; rnhanheid@techfak.uni-bielefeld.de; swrede@techfak.uni-bielefeld.de; tkaester@techfak.uni-bielefeld.de; pfeiffer@techfak.uni-bielefeld.de; sagerer@techfak.uni-bielefeld.de					BAUCKHAGE C, 2004, P IEEE INT C COMP VI, V2; BAUCKHAGE C, 2003, P 29 ANN C IEEE IND, V2, P1882; Bekel H, 2004, LECT NOTES COMPUT SC, V3175, P447; Ben-Hur A, 2001, J MACHINE LEARNING R, V2, P125; BERINGER N, 2002, P WORKSH MULT RESS M; BERKELEY DB, 2004, SLEEPYCAT SOFTWARE; Black M., 1998, P 5 EUR C COMP VIS, V1, P909; BRANDT S, 2000, P 15 INT C PATT REC, V2, P1062, DOI 10.1109/ICPR.2000.906258; CHRISTENSEN H, 2003, ERCIM NEWS, P17; Cockburn A., 2001, AGILE SOFTWARE DEV; Crowley J., 1995, VISION PROCESS; Cruse H, 2003, COGNITIVE SCI, V27, P135, DOI 10.1016/S0364-0213(02)00110-6; Fink GA, 1999, LECT NOTES ARTIF INT, V1692, P229; FRITSCH J, 2003, THESIS BIELEFELD U B; Grassl C, 2003, LECT NOTES COMPUT SC, V2781, P273; HANHEIDE M, 2004, P 17 IEEE INT C PATT, V2, P459, DOI 52219025,12,1; HEIDEMANN G, 2003, P INT C COGN VIS SYS, P22; HEIDEMANN G, 2004, P 6 INT C MULT INT, P53, DOI 10.1145/1027933.1027944; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; JENSEN F, 2001, BAYESIAN NETWORKS DE; Kampa M, 2002, BMC CLIN PATHOL, V2, P3, DOI 10.1186/1472-6890-2-3; Kast RE, 2003, NEOPLASIA, V5, P3; Kittler J, 2003, LECT NOTES COMPUT SC, V2709, P106; LAURITZEN SL, 1995, COMPUT STAT DATA AN, V19, P191, DOI 10.1016/0167-9473(93)E0056-A; LINDEGAARD G, 1994, USABILITY TESTING SY; MONTESINOS P, 1998, P 14 INT C PATT REC, V1, P838, DOI 10.1109/ICPR.1998.711280; Murphy K, 2003, P ADV NEUR INF PROC; Pearl J., 1988, PROBABILISTIC REASON; PREECE JJ, 2002, HUMAN COMPUTER INTER; Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644; Rui Y., 2000, P IEEE INT C COMP VI, V1, P236, DOI 10.1109/CVPR.2000.855825; Stricker M, 1997, MACH VISION APPL, V10, P66, DOI 10.1007/s001380050060; Tung CP, 1996, IEEE T ROBOTIC AUTOM, V12, P187; VIOLA P, 2001, P IEEE INT C COMP VI, V1; WACHSMUTH S, 2002, P AAAI, P300; WREDE S, 2004, P ICPR, V1, P761, DOI 52217047,12,1; Wrede S., 2004, P 7 INT C INF FUS ST, P198; Wrede S, 2004, INT C PATT RECOG, P757, DOI 10.1109/ICPR.2004.1334304	38	2	2	HINDAWI PUBLISHING CORPORATION	NEW YORK	410 PARK AVENUE, 15TH FLOOR, #287 PMB, NEW YORK, NY 10022 USA	1110-8657		EURASIP J APPL SIG P	EURASIP J Appl. Signal Process.	AUG 11	2005	2005	14					2375	2390		10.1155/ASP.2005.2375		16	Engineering, Electrical & Electronic	Engineering	996WD	WOS:000234205200020	
J	Ahmed, FE				Ahmed, Farid E.			Artificial neural networks for diagnosis and survival prediction in colon cancer	MOLECULAR CANCER			English	Review							GENE-EXPRESSION; COLORECTAL-CANCER; DATA SETS; CLASSIFICATION; REGRESSION; MODELS; FEEDFORWARD; IMPROVEMENT; TESTS	ANNs are nonlinear regression computational devices that have been used for over 45 years in classification and survival prediction in several biomedical systems, including colon cancer. Described in this article is the theory behind the three-layer free forward artificial neural networks with backpropagation error, which is widely used in biomedical fields, and a methodological approach to its application for cancer research, as exemplified by colon cancer. Review of the literature shows that applications of these networks have improved the accuracy of colon cancer classification and survival prediction when compared to other statistical or clinicopathological methods. Accuracy, however, must be exercised when designing, using and publishing biomedical results employing machine-learning devices such as ANNs in worldwide literature in order to enhance confidence in the quality and reliability of reported data.	E Carolina Univ, Brody Sch Med, Leo W Jenkins Canc Ctr, Dept Radiat Oncol, Greenville, NC 27858 USA	Ahmed, FE (reprint author), E Carolina Univ, Brody Sch Med, Leo W Jenkins Canc Ctr, Dept Radiat Oncol, Greenville, NC 27858 USA.	ahmedf@mail.ecu.edu					Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; ASTION ML, 1992, CLIN CHEM, V38, P34; Ball G, 2002, BIOINFORMATICS, V18, P395, DOI 10.1093/bioinformatics/18.3.395; BASET WG, 1995, LANCET, V346, P1135; Basheer IA, 2000, J MICROBIOL METH, V43, P3, DOI 10.1016/S0167-7012(00)00201-3; Bottaci L, 1997, LANCET, V350, P469, DOI 10.1016/S0140-6736(96)11196-X; Burke H. B., 2001, CANCER S, V91, P857; Dayhoff JE, 2001, CANCER, V91, P1615, DOI 10.1002/1097-0142(20010415)91:8+<1615::AID-CNCR1175>3.0.CO;2-L; DELAURENTIIS M, 1994, CANCER LETT, V77, P127, DOI 10.1016/0304-3835(94)90095-7; Dreiseitl S, 2002, J BIOMED INFORM, V35, P352, DOI 10.1016/S1532-0464(03)00034-0; Efron B., 1993, INTRO BOOTSTRAP; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Ennett CM, 2004, MED ENG PHYS, V26, P321, DOI 10.1016/j.medengphy.2003.09.005; Fu LM, 2004, FEBS LETT, V561, P186, DOI 10.1016/S0014-5793(04)00175-9; Gallant S.I., 1994, NEURAL NETWORK LEARN; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Grumett Simon, 2003, Clin Colorectal Cancer, V2, P239, DOI 10.3816/CCC.2003.n.005; HANLEY JA, 1982, RADIOLOGY, V143, P29; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; HORNIK K, 1989, NEURAL NET, V6, P1969; KATES RE, 1909, P 3 INT C KNOWL BAS; Kattan M, 2002, J CLIN ONCOL, V20, P885; Kattan MW, 2003, J UROLOGY, V170, pS6, DOI 10.1097/01.ju0000094764.56269.2d; LeBlanc M, 2003, BIOINFORMATICS, V19, P686, DOI 10.1093/bioinformatics/btg079; LIU B, 2004, BMC BIOINFORMATICS, V51, P131; LIVINGSTONE DJ, 1993, J MED CHEM, V36, P1295, DOI 10.1021/jm00061a023; Ma L, 2004, NEURAL NETWORKS, V17, P589, DOI 10.1016/j.neunet.2004.02.002; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; Mehrotra K., 1997, ELEMENTS ARTIFICIAL; NEWLAND RC, 1994, CANCER, V73, P2076, DOI 10.1002/1097-0142(19940415)73:8<2076::AID-CNCR2820730811>3.0.CO;2-6; Penny W, 1996, MED DECIS MAKING, V16, P386, DOI 10.1177/0272989X9601600409; PICARD RR, 1990, AM STAT, V44, P140, DOI 10.2307/2684155; Remaley AT, 1999, CLIN CHEM, V45, P934; RINGNER M, 2003, BIOTECHNIQUES, V39, P530; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; Sargent DJ, 2001, CANCER, V91, P1636, DOI 10.1002/1097-0142(20010415)91:8+<1636::AID-CNCR1176>3.0.CO;2-D; Schwarzer G, 2000, STAT MED, V19, P541, DOI 10.1002/(SICI)1097-0258(20000229)19:4<541::AID-SIM355>3.3.CO;2-M; Selaru FM, 2002, GASTROENTEROLOGY, V122, P606, DOI 10.1053/gast.2002.31904; Shepherd AJ, 1997, 2 ORDER METHODS NEUR; Snow PB, 2001, CANCER, V91, P1673, DOI 10.1002/1097-0142(20010415)91:8+<1673::AID-CNCR1182>3.0.CO;2-T; SOMOZA E, 1992, MED DECIS MAKING, V12, P179, DOI 10.1177/0272989X9201200303; Stager F, 1997, NEURAL NETWORKS, V10, P1435, DOI 10.1016/S0893-6080(97)00053-1; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Tetko IV, 1997, NEURAL NETWORKS, V10, P1361, DOI 10.1016/S0893-6080(97)00005-1; Walker CR, 2004, PEDIATR RES, V56, P6, DOI 10.1203/01.PDR.0000129654.02381.B9; Werbos P. I., 1974, THESIS HARVARD U CAM; WIDROW B, 1960, ADAPTIVE SWITCHING C, V4, P96	48	21	22	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1476-4598		MOL CANCER	Mol. Cancer	AUG 6	2005	4								29	10.1186/1476-5498-4-29		12	Biochemistry & Molecular Biology; Oncology	Biochemistry & Molecular Biology; Oncology	076NT	WOS:000239965700001	
J	Kruegel, C; Vigna, G; Robertson, W				Kruegel, C; Vigna, G; Robertson, W			A multi-model approach to the detection of web-based attacks	COMPUTER NETWORKS			English	Article						intrusion detection; world-wide web; machine learning; anomaly models		Web-based vulnerabilities represent a substantial portion of the security exposures of computer networks. In order to detect known web-based attacks, misuse detection systems are equipped with a large number of signatures. Unfortunately, it is difficult to keep up with the daily disclosure of web-related vulnerabilities, and, in addition, vulnerabilities may be introduced by installation-specific web-based applications. Therefore, misuse detection systems should be complemented with anomaly detection systems. This paper presents an intrusion detection system that uses a number of different anomaly detection techniques to detect attacks against web servers and web-based applications. The system analyzes client queries that reference server-side programs and creates models for a wide-range of different features of these queries. Examples of such features are access patterns of server-side programs or values of individual parameters in their invocation. In particular, the use of application-specific characterization of the invocation parameters allows the system to perform focused analysis and produce a reduced number of false positives. The system derives automatically the parameter profiles associated with web applications (e.g., length and structure of parameters) and relationships between queries (e.g., access times and sequences) from the analyzed data. Therefore, it can be deployed in very different application environments without having to perform time-consuming tuning and configuration. (c) 2005 Elsevier B.V. All rights reserved.	Univ Calif Santa Barbara, Reliable Software Grp, Santa Barbara, CA 93106 USA	Kruegel, C (reprint author), Univ Calif Santa Barbara, Reliable Software Grp, Santa Barbara, CA 93106 USA.	chris@cs.ucsb.edu; vigna@cs.ucsb.edu; wkr@cs.ucsb.edu					ALMGREN M, 2000, P ISOC S NETW DISTR; ALMGREN M, 2001, P 4 INT S REC ADV IN, P22; Berk V., 2003, P ACM WORKSH RAP MAL, P24, DOI 10.1145/948187.948193; Billingsley P., 1995, PROBABILITY MEASURE; CERT/CC, 2001, COD RED WORM EXPL BU; COAR K, 1999, WWW COMMON GATEWAY I; DENNING DE, 1987, IEEE T SOFTWARE ENG, V13, P222, DOI 10.1109/TSE.1987.232894; FENG H, 2004, P IEEE S SEC PRIV OA; Fielding R., 1999, 2616 RFC; Forrest S, 1996, P IEEE S SECUR PRIV, P120, DOI 10.1109/SECPRI.1996.502675; Ghosh A. K., 1998, Proceedings 14th Annual Computer Security Applications Conference (Cat. No.98EX217), DOI 10.1109/CSAC.1998.738646; Hayter A. J., 2001, PROBABILITY STAT ENG; ILGUN K, 1995, IEEE T SOFTWARE ENG, V21, P181, DOI 10.1109/32.372146; JAVITZ HS, 1991, P IEEE S SEC PRIV OA; KLEIN D, 1999, P USENIX WORKSH INTR; Ko C, 1997, P IEEE S SECUR PRIV, P175, DOI 10.1109/SECPRI.1997.601332; KRUEGEL C, 2003, P ANN COMP SEC APPL; KRUEGEL C, 2002, P S APPL COMP SAC MA; Kruegel C., 2003, P 10 ACM C COMP COMM, P251; Kruegel C., 2003, P 8 EUR S RES COMP S, P326; Lane T., 1998, P 5 ACM C COMP COMM, P150, DOI 10.1145/288090.288122; Lee W., 2000, ACM Transactions on Information and Systems Security, V3, DOI 10.1145/382912.382914; LIBERTY J, 2002, PROGRAMMING ASP NET; LINDQVIST U, 1999, IEEE S SEC PRIV, P146; Mahoney M. V., 2002, P 8 ACM SIGKDD INT C, P376; Paxson V., 1998, P 7 USENIX SEC S SAN; Portnoy L, 2001, P ACM CSS WORKSH DAT; ROESCH M, 1999, P USENIX LISA 99 C S; SEKAR R, 2001, P IEEE S SEC PRIV OA; Snedecor G. W., 1998, STAT METHODS; STOLCKE A, 1994, INT C GRAMM INF; STOLCKE A, 1993, P ADV NEUR INF PROC; TAN KMC, 2002, P 5 INT S REC ADV IN, P54; TARJAN R, 1972, SIAM J COMPUT, V1, P10; Vigna G., 2003, Proceedings. 19th Annual Computer Security Applications Conference; Wagner D., 2001, P IEEE S SEC PRIV OA; Wagner David, 2002, P 9 ACM C COMP COMM, p255 ; Warrender C, 1999, P IEEE S SECUR PRIV, P133, DOI 10.1109/SECPRI.1999.766910; 2004, APACHE 2 0 DOCUMENTA	39	42	47	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1389-1286		COMPUT NETW	Comput. Netw.	AUG 5	2005	48	5					717	738		10.1016/j.comnet.2005.01.009		22	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	960QW	WOS:000231609300003	
J	Nguyen, XL; Jordan, MI; Sinopoli, B				Nguyen, Xuanlong; Jordan, Michael I.; Sinopoli, Bruno			A Kernel-Based Learning Approach to Ad Hoc Sensor Network Localization	ACM TRANSACTIONS ON SENSOR NETWORKS			English	Article						Algorithms; Ad hoc wireless sensor networks; localization; kernel methods; statistical machine learning; position estimation		We show that the coarse-grained and fine-grained localization problems for ad hoc sensor networks can be posed and solved as a pattern recognition problem using kernel methods from statistical learning theory. This stems from an observation that the kernel function, which is a similarity measure critical to the effectiveness of a kernel-based learning algorithm, can be naturally defined in terms of the matrix of signal strengths received by the sensors. Thus we work in the natural coordinate system provided by the physical devices. This not only allows us to sidestep the difficult ranging procedure required by many existing localization algorithms in the literature, but also enables us to derive a simple and effective localization algorithm. The algorithm is particularly suitable for networks with densely distributed sensors, most of whose locations are unknown. The computations are initially performed at the base sensors, and the computation cost depends only on the number of base sensors. The localization step for each sensor of unknown location is then performed locally in linear time. We present an analysis of the localization error bounds, and provide an evaluation of our algorithm on both simulated and real sensor networks.	[Nguyen, Xuanlong; Jordan, Michael I.; Sinopoli, Bruno] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA	Nguyen, XL (reprint author), Univ Calif Berkeley, Dept Elect Engn & Comp Sci, 387 Soda Hall, Berkeley, CA 94720 USA.	xuanlong@cs.berkeley.edu			National Science Foundation [0412995]	This work was supported by Grant 0412995 from the National Science Foundation.	Bahl P., 2000, INFOCOM, P775; Bulusu N., 2000, 00729 U SO CAL COMP; DCOSTA A, 2003, 2 INT WORKSH INF PRO, P193; GIROD L, 2001, IEEE RSI INT C INT R; HIGHTOWER J, 2000, LOCATION MODELING UB, P21; Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27; Li D, 2002, IEEE SIGNAL PROC MAG, V19, P17; Poor H. V., 1994, INTRO SIGNAL DETECTI; Priyantha N., 2000, ACM INT C MOB COMP N; Savarese C, 2002, USENIX ASSOCIATION PROCEEDINGS OF THE GENERAL TRACK, P317; Savvides A., 2001, P 7 ANN INT C MOB CO, P166, DOI DOI 10.1145/381677.381693; Scholkopf B., 2002, LEARNING KERNELS; SEIDEL SY, 1992, IEEE T ANTENN PROPAG, V40, P207, DOI 10.1109/8.127405; SHENG X, 2003, 2 INT WORKSH INF PRO, P285; Vapnik VN, 1998, STAT LEARNING THEORY; WANT R, 1992, ACM T INFORM SYST, V10, P91, DOI 10.1145/128756.128759; Ward A, 1997, IEEE PERS COMMUN, V4, P42, DOI 10.1109/98.626982; Whitehouse C., 2002, THESIS U CALIFORNIA	18	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1550-4859		ACM TRANS SENS NETW	ACM Trans. Sens. Netw.	AUG	2005	1	1										19	Computer Science, Information Systems; Telecommunications	Computer Science; Telecommunications	V74DY	WOS:000205012600006	
J	Lee, AC				Lee, AC			Learning via finitely many queries	ANNALS OF MATHEMATICS AND ARTIFICIAL INTELLIGENCE			English	Article						inductive inference; machine learning; learning by example; learning via a teacher	INDUCTIVE INFERENCE; IDENTIFICATION; MACHINES	This work introduces a new query inference model that can access data and communicate with the teacher by asking finitely many Boolean queries in a language L. In this model the parameters of interest are the number of queries used and the expressive power of L. We study how the learning power varies with these parameters. Results suggest that this model may help studying query inference in a resource bounded environment.	Univ SW Louisiana, Dept Comp Sci, Lafayette, LA 70504 USA	Lee, AC (reprint author), Univ SW Louisiana, Dept Comp Sci, Lafayette, LA 70504 USA.	cx19999@louisiana.edu					ANGLUIN D, 1983, COMPUT SURV, V15, P237; ANGLUIN D, 2001, LECT NOTES ARTIF INT, V2225, P12; ANGLUIN D, 1987, INFORM COMPUT, V75, P87, DOI 10.1016/0890-5401(87)90052-6; CASE J, 1983, THEOR COMPUT SCI, V25, P193, DOI 10.1016/0304-3975(83)90061-0; Case J, 1999, INFORM COMPUT, V152, P74, DOI 10.1006/inco.1998.2784; Case J, 2003, LECT NOTES ARTIF INT, V2777, P699, DOI 10.1007/978-3-540-45167-9_51; ELGOT CC, 1966, J SYMBOLIC LOGIC, V31, P169, DOI 10.2307/2269808; Enderton Herbert B., 1972, MATH INTRO LOGIC; Freivalds R, 1995, J ACM, V42, P1146, DOI 10.1145/227683.227685; FULK M, 1994, J COMPUT SYST SCI, V49, P589, DOI 10.1016/S0022-0000(05)80072-8; GASARCH W, 1997, LECT NOTES PURE APPL, V187; Gasarch W, 2002, ANN PURE APPL LOGIC, V117, P169, DOI 10.1016/S0168-0072(01)00115-4; Gasarch W. I., 1997, Proceedings of the Tenth Annual Conference on Computational Learning Theory, DOI 10.1145/267460.267512; GASARCH WI, 1995, ANN MATH ARTIFICIAL, V15, P155; GASARCH WI, 1992, J ACM, V39, P649, DOI 10.1145/146637.146670; GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5; Jain Sanjay, 1999, SYSTEMS LEARN INTRO; Matiyasevich Y. V., 1993, FDN COMPUTING SERIES; Rogers H., 1967, THEORY RECURSIVE FUN; Rogers H., 1958, J SYMBOLIC LOGIC, V23, P331, DOI 10.2307/2964292; SMITH CH, 1982, J ACM, V29, P1144, DOI 10.1145/322344.322356; SMITH CH, 1994, P 5 INT WORKSH ALG L, P211; SOARE RI, 1987, OMEGA SERIES; van Leeuwen J, 1990, HDB THEORETICAL COMP, VB, P135	24	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1012-2443		ANN MATH ARTIF INTEL	Ann. Math. Artif. Intell.	AUG	2005	44	4					401	418		10.1007/s10472-005-7035-0		18	Computer Science, Artificial Intelligence; Mathematics, Applied	Computer Science; Mathematics	965FY	WOS:000231937100005	
J	Zhang, T; Yu, B				Zhang, T; Yu, B			Boosting with early stopping: Convergence and consistency	ANNALS OF STATISTICS			English	Article						boosting; greedy optimization; matching pursuit; early stopping; consistency	CLASSIFICATION METHODS; GREEDY APPROXIMATION; LOGISTIC-REGRESSION; VOTING METHODS; CLASSIFIERS; EXPLANATION; ALGORITHMS; ADABOOST; NETWORKS; MARGIN	Boosting is one of the most significant advances in machine learning for classification and regression. In its original and computationally flexible version, boosting seeks to minimize empirically a loss function in a greedy fashion. The resulting estimator takes an additive function form and is built iteratively by applying a base estimator (or learner) to updated samples depending on the previous iterations. An unusual regularization technique, early stopping, is employed based on CV or a test set. This paper studies numerical convergence, consistency and statistical rates of convergence of boosting with early stopping, when it is carried out over the linear span of a family of basis functions. For general loss functions, we prove the convergence of boosting's greedy optimization to the infinimum of the loss function over the linear span. Using the numerical convergence result, we find early-stopping strategies under which boosting is shown to be consistent based on i.i.d. samples, and we obtain bounds on the rates of convergence for boosting estimators. Simulation studies are also presented to illustrate the relevance of our theoretical results for providing insights to practical aspects of boosting. As a side product, these results also reveal the importance of restricting the greedy search step-sizes, as known in practice through the work of Friedman and others. Moreover, our results lead to rigorous proof that for a linearly separable problem, AdaBoost with epsilon -> 0 step-size becomes an L-1-margin maximizer when left to run to convergence.	IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA; Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA	Zhang, T (reprint author), IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.	tzhang@watson.ibm.com; binyu@stat.berkeley.edu					BARRON AR, 1993, IEEE T INFORM THEORY, V39, P930, DOI 10.1109/18.256500; Bartlett P. L, 2003, J MACHINE LEARNING R, V3, P463; BARTLETT PL, 2005, IN PRESS J AM STAT A; Bartlett PL, 2005, ANN STAT, V33, P1497, DOI 10.1214/009053605000000282; Blanchard G, 2004, J MACH LEARN RES, V4, P861, DOI 10.1162/1532443041424319; Bousquet O., 2002, LECT NOTES COMPUT SC, V2375, P59; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 2004, ANN STAT, V32, P1; Breiman L, 1999, NEURAL COMPUT, V11, P1493, DOI 10.1162/089976699300016106; BUHLMANN P, 2002, CONSISTENCY L2 BOOST; Buhlmann P, 2003, J AM STAT ASSOC, V98, P324, DOI 10.1198/016214503000125; Collins M, 2002, MACH LEARN, V48, P253, DOI 10.1023/A:1013912006537; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Grove A. J., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Hastie T, 2001, ELEMENTS STAT LEARNI; Hastie T. J., 1990, GEN ADDITIVE MODELS; Jiang WX, 2004, ANN STAT, V32, P13; JONES LK, 1992, ANN STAT, V20, P608, DOI 10.1214/aos/1176348546; Koltchinskii V, 2005, ANN STAT, V33, P1455, DOI 10.1214/009053605000000228; Koltchinskii V, 2002, ANN STAT, V30, P1; Koltchinskii V, 2001, LECT NOTES ARTIF INT, V2111, P241; LEDOUX M, 1991, PROBABILITY BANAC SP; Lee WS, 1996, IEEE T INFORM THEORY, V42, P2118; LESHNO M, 1993, NEURAL NETWORKS, V6, P861, DOI 10.1016/S0893-6080(05)80131-5; LI F, 2003, P 20 C MACH LEARN, V2, P472; Lugosi G, 2004, ANN STAT, V32, P30; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Mannor Shie, 2003, J MACHINE LEARNING R, V4, P713; Mason L, 2000, ADV NEUR IN, P221; MEIER J, 2003, J MACH LEARN RES, V4, P839; Schapire RE, 1998, ANN STAT, V26, P1651; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Vapnik VN, 1998, STAT LEARNING THEORY; Wellner J. A., 1996, WEAK CONVERGENCE EMP; Zhang T, 2001, INFORM RETRIEVAL, V4, P5, DOI 10.1023/A:1011441423217; Zhang T, 2004, ANN STAT, V32, P56; Zhang T, 2003, IEEE T INFORM THEORY, V49, P682, DOI 10.1109/TIT.2002.808136	39	52	54	INST MATHEMATICAL STATISTICS	BEACHWOOD	PO BOX 22718, BEACHWOOD, OH 44122 USA	0090-5364		ANN STAT	Ann. Stat.	AUG	2005	33	4					1538	1579		10.1214/009053605000000255		42	Statistics & Probability	Mathematics	957YE	WOS:000231408600003	
J	Patil, NS; Shelokar, PS; Jayaraman, VK; Kulkarni, BD				Patil, NS; Shelokar, PS; Jayaraman, VK; Kulkarni, BD			Regression models using pattern search assisted least square support vector machines	CHEMICAL ENGINEERING RESEARCH & DESIGN			English	Article						equality constraints; LS-SVM; pattern search; optimization; model selection	NEURAL-NETWORK; FEATURE-EXTRACTION; BOILING POINTS; KERNEL PCA; APPROXIMATION; PREDICTION; SYSTEMS; CHAOS	Least Square Support Vector Machines (LS-SVM), a new machine-learning tool has been employed for developing data driven models of non-linear processes. The method is firmly rooted in the statistical learning theory and transforms the input data to a higher dimensional feature space where the use of appropriate kernel functions avoid computational difficulty. Further, a pattern search algorithm, which explores multiple directions and utilizes coordinate search with fixed step size, is employed for selecting optimal LS-SVM model that produces a minimum possible prediction error. To show the efficacy and efficiency of the fully automated pattern search assisted LS-SVM methodology, we have tested it on several benchmark examples. The study suggests that proposed paradigm can be a useful and viable tool in building data driven models of non-linear processes.	Natl Chem Lab, Chem Engn & Proc Dev Div, Pune 411008, Maharashtra, India	Kulkarni, BD (reprint author), Natl Chem Lab, Chem Engn & Proc Dev Div, Pune 411008, Maharashtra, India.	bdk@ems.ncl.res.in	KULKARNI, B/C-1371-2009; Shelokar, Prakash/E-4215-2010				Banerjee A, 1997, AICHE J, V43, P1204, DOI 10.1002/aic.690430511; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L., 1994, 421 U CAL DEP STAT; Davis L, 1987, GENETIC ALGORITHMS S; DENNIS JE, 1994, P 5 AIAA USAF NASA I, P922; Drucker H, 1997, ADV NEUR IN, V9, P155; Espinosa G, 2000, J CHEM INF COMP SCI, V40, P859, DOI 10.1021/ci000442u; Fletcher R., 1987, PRACTICAL METHODS OP; Gao L, 2001, COMPUT CHEM ENG, V25, P1403, DOI 10.1016/S0098-1354(01)00708-6; Goll ES, 1999, J CHEM INF COMP SCI, V39, P974, DOI 10.1021/ci9900711; Golub G. H., 1989, MATRIX COMPUTATIONS; Gunn S. R., 1997, SUPPORT VECTOR MACHI; HARRISON D, 1978, J ENVIRON ECON MANAG, V5, P81, DOI 10.1016/0095-0696(78)90006-2; HESTENES MR, 1952, J RES NAT BUR STAND, V49, P409, DOI 10.6028/jres.049.044; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Jade AM, 2003, CHEM ENG SCI, V58, P4441, DOI 10.1016/S0009-2509(03)00340-3; KILLORY H, 1987, PHYS LETT A, V122, P341, DOI 10.1016/0375-9601(87)90839-5; LEWIS R, 1996, SIAM J OPTIMIZ, V9, P1082; Lucic B, 1999, J CHEM INF COMP SCI, V39, P610, DOI 10.1021/ci980161a; Lucic B, 2000, J CHEM INF COMP SCI, V40, P403, DOI 10.1021/ci990061k; MACKEY MC, 1977, SCIENCE, V197, P287, DOI 10.1126/science.267326; Murray-Smith Roderick, 1997, MULTIPLE MODEL APPRO; Mwembeshi MM, 2001, CHEM ENG RES DES, V79, P323, DOI 10.1205/026387601750281833; Pedrycz W, 2003, NEUROCOMPUTING, V55, P383, DOI 10.1016/S0925-2312(02)00630-6; POGGIO T, 1990, P IEEE, V78, P9; Rosipal R, 2001, NEURAL COMPUT APPL, V10, P231, DOI 10.1007/s521-001-8051-z; Saunders C., 1998, P 15 INT C MACH LEAR, P515; Smola A., 1998, NCTR98030 U LOND ROY; SMOLA A, 1999, THESIS GMD; SUYKENS J, 1998, NONLINEAR MODELING; Suykens J.A.K., 2000, EUR S ART NEUR NETW, P37; Suykens JAK, 2002, NEUROCOMPUTING, V48, P85, DOI 10.1016/S0925-2312(01)00644-0; SUYKENS JAK, 1999, EUR C CIRC THEOR DES, P839; Suykens J.A.K., 2002, LEAST SQUARES SUPPOR; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Vapnik V, 1997, ADV NEUR IN, V9, P281; Vapnik V. N, 1995, NATURE STAT LEARNING; Venkatasubramanian V, 2003, COMPUT CHEM ENG, V27, P313, DOI 10.1016/S0098-1354(02)00161-8; WESTON J, 2005, SPIDER V1 6 OBJECT O; Yang SH, 1999, CHEM ENG RES DES, V77, P779, DOI 10.1205/026387699526773; Zamprogna E, 2001, CHEM ENG RES DES, V79, P689, DOI 10.1205/026387601316971361	42	6	6	INST CHEMICAL ENGINEERS	RUGBY	165-189 RAILWAY TERRACE, DAVIS BLDG, RUGBY CV21 3HQ, ENGLAND	0263-8762		CHEM ENG RES DES	Chem. Eng. Res. Des.	AUG	2005	83	A8					1030	1037		10.1205/cherd.03144		8	Engineering, Chemical	Engineering	962PI	WOS:000231744300010	
J	Arodz, T; Kurdziel, M; Sevre, EOD; Yuen, DA				Arodz, T; Kurdziel, M; Sevre, EOD; Yuen, DA			Pattern recognition techniques for automatic detection of suspicious-looking anomalies in mammograms	COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE			English	Article						mammogram analysis; computer-aided diagnosis; machine learning	COMPUTER-AIDED DETECTION; CLUSTERED MICROCALCIFICATIONS; DIGITAL MAMMOGRAMS; ENHANCEMENT; SEARCH; BREAST	We have employed two pattern recognition methods used commonly for face recognition in order to analyse digital mammograms. The methods are based on novel classification schemes, the AdaBoost and the support vector machines (SVM). A number of tests have been carried out to evaluate the accuracy of these two algorithms under different circumstances. Results for the AdaBoost classifier method are promising, especially for classifying mass-type Lesions. In the best case the algorithm achieved accuracy of 76% for all lesion types and 90% for masses only. The SVM based algorithm did not perform as well. In order to achieve a higher accuracy for this method, we should choose image features that are better suited for analysing digital mammograms than the currently used ones. (c) 2005 Elsevier Ireland Ltd. All rights reserved.	AGH Univ Sci & Technol, Inst Comp Sci, PL-30059 Krakow, Poland; Univ Minnesota, Minnesota Supercomp Inst, Minneapolis, MN 55455 USA	Arodz, T (reprint author), AGH Univ Sci & Technol, Inst Comp Sci, Al Mickiewicza 30, PL-30059 Krakow, Poland.	arodz@agh.edu.pl; kurdziel@agh.edu.pl; esevre@msi.umn.edu; davey@krissy.geo.umn.edu					Cheng HD, 2003, PATTERN RECOGN, V36, P2967, DOI 10.1016/S0031-3203(03)00192-4; Cheng HD, 2004, PATTERN RECOGN, V37, P363, DOI 10.1016/S0031-3203(03)00230-9; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Freer TW, 2001, RADIOLOGY, V220, P781, DOI 10.1148/radiol.2203001282; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; Gabor D., 1946, J INT ELECT ENG, V93, P427; GRANLUND GH, 1978, COMPUT VISION GRAPH, V8, P155, DOI 10.1016/0146-664X(78)90047-3; LAINE AF, 1994, IEEE T MED IMAGING, V13, P725, DOI 10.1109/42.363095; LEGAL M, 1984, B CANCER, V71, P57; Li H, 1997, IEEE T MED IMAGING, V16, P785, DOI 10.1109/42.650875; Netsch T, 1999, IEEE T MED IMAGING, V18, P774, DOI 10.1109/42.802755; Smeraldi F, 2000, IMAGE VISION COMPUT, V18, P323, DOI 10.1016/S0262-8856(99)00080-3; Vapnik V, 1997, ADV NEUR IN, V9, P281; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; ZHAO D, 1992, P IEEE INT C AC SPEE, P129, DOI 10.1109/ICASSP.1992.226259; *ACS, 2003, CANC FACTS FIG; [Anonymous], 2003, BREAST IMAGING REPOR	17	8	8	ELSEVIER IRELAND LTD	CLARE	ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND	0169-2607		COMPUT METH PROG BIO	Comput. Meth. Programs Biomed.	AUG	2005	79	2					135	149		10.1016/j.cmpb.2005.03.009		15	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	954EQ	WOS:000231137300004	
J	Kovalev, V; Bhowmick, SS; Madria, S				Kovalev, V; Bhowmick, SS; Madria, S			HW-STALKER: A machine learning-based system for transforming QURE-Pagelets to XML	DATA & KNOWLEDGE ENGINEERING			English	Article						hidden web; dynamic content; identifiers; facilitators; STALKER; XML; QURE-Pagelets	WORLD-WIDE-WEB; WRAPPER INDUCTION; INFORMATION	In this paper, we address the problem of extracting and transforming dynamically generated hyperlinked hidden web query results to XML. Our approach is based on the STALKER approach. As STALKER was designed to extract data from a single web page, it cannot handle a set of hyperlinked pages. We propose an algorithm called HW-Transform for transforming hidden web query results (also called QURE-Pagelets) to XML format using machine learning by extending STALKER to handle hyperlinked hidden web pages. One of the key features of our approach is that we identify and transform key attributes of query results into XML attributes. These key attributes facilitate applications such as change detection and data integration by efficiently identifying related or identical results. Based on the proposed algorithm, we have implemented a prototype system called HW-STALKER using Java. Our experiments demonstrate that HW-Transform shows acceptable performance for transforming QURE-Pagelets to XML. (c) 2005 Elsevier B.V. All rights reserved.	Nanyang Technol Univ, Sch Comp Engn, Div Informat Syst, Singapore 639798, Singapore; Univ Missouri, Dept Comp Sci, Rolla, MO 65409 USA	Bhowmick, SS (reprint author), Nanyang Technol Univ, Sch Comp Engn, Div Informat Syst, Singapore 639798, Singapore.	assourav@ntu.edu.sg; madrias@umr.edu	S Bhowmick, .Sourav/A-3728-2011				BARYOSSEF Z, 2002, P WORLD WID WEB C; BAUMGARTNER R, 2001, P 27 VLDB C ROM; CAVERLEE JB, 2004, P INT C DAT ENG ICDE; CHAKRABARTI S, 1999, 8 WORLD WID WEB C MA; Crescenzi V., 2001, Proceedings of the 27th International Conference on Very Large Data Bases; DAVULKU H, 1999, ACM C MAN DAT SIGMOD; DILIGENTI M, 2000, 26 INT C VER LARG DA; Freitag D, 2000, MACH LEARN, V39, P169, DOI 10.1023/A:1007601113994; Hammer J., 1997, SIGMOD Record, V26; KNOBLOCK CA, 2000, IEEE DATA ENG B, V23, P33; Konopnicki D, 1998, ACM T DATABASE SYST, V23, P369, DOI 10.1145/296854.277639; KOVALEV V, 2004, P 15 INT C DAT EXP S; KOVALEV V, 2003, THESIS NANYANG TU SI; Kushmerick N, 2000, ARTIF INTELL, V118, P15, DOI 10.1016/S0004-3702(99)00100-9; Lawrence S, 1999, NATURE, V400, P107, DOI 10.1038/21987; Lawrence S, 1998, SCIENCE, V280, P98, DOI 10.1126/science.280.5360.98; McCallum A., 1999, P AAAI 99 SPRING S I; MECCA G, 1998, P ACM SIGMOD INT C M, P544, DOI 10.1145/276304.276375; Muslea I, 2001, AUTON AGENT MULTI-AG, V4, P93, DOI 10.1023/A:1010022931168; Shestakov D, 2005, DATA KNOWL ENG, V52, P273, DOI 10.1016/j.datak.2004.06.009	20	3	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-023X		DATA KNOWL ENG	Data Knowl. Eng.	AUG	2005	54	2					241	276		10.1016/j.datak.2005.01.001		36	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	934JE	WOS:000229704300006	
J	Fan, WG; Gordon, MD; Pathak, P				Fan, WG; Gordon, MD; Pathak, P			Effective profiling of consumer information retrieval needs: a unified framework and empirical comparison	DECISION SUPPORT SYSTEMS			English	Article						personalization; profiling; information push; information routing; selective dissemination of information; information retrieval	QUERY EXPANSION; WEB; CONTEXT	Due to the overwhelming volume of information that is increasingly available, many people rely on current awareness systems to keep abreast of the latest developments in the fields that they are interested in, as evidenced in the popularity of subscriptions to news-monitoring and digital library services. The success of these services, however, often requires effective acquisition of users' personal standing interests as represented in personal profiles. Our objective in this paper is twofold. First, we have introduced a new method for profile generation and compared it against other well-known methods. We have found promising results. Second, although there are various methods proposed in information retrieval and machine learning literature to address the issue of profiling, a unified framework and systematic cross-system comparison to help users, especially service providers, to determine the most effective way of profiling consumers is still lacking in the literature. In this paper, we try to fill the gap by looking at these methods from a more integrated point of view based on statistical contingency theory. Variations of these methods are then systematically tested on three well-known routing systems and results are analyzed and reported. (c) 2004 Elsevier B.V. All rights reserved.	Virginia Tech, Accounting & Informat Syst, Blacksburg, VA 24061 USA; Univ Michigan, Ann Arbor, MI 48109 USA; Univ Florida, Gainesville, FL 32611 USA	Fan, WG (reprint author), Virginia Tech, Accounting & Informat Syst, 3007 Pamplin Hall, Blacksburg, VA 24061 USA.	wfan@vt.edu	Fan, Weiguo/E-6343-2012	Fan, Weiguo/0000-0003-1272-5538			Chen L., 1998, Proceedings of the Second International Conference on Autonomous Agents, DOI 10.1145/280765.280789; Dietterich TG, 1997, AI MAG, V18, P97; Dumais S, 1998, IEEE INTELL SYST APP, V13, P21; FAN W, 2003, IN PRESS INFORM PROC; FAN W, 2000, P 21 INT C INF SYST, P20; Fan WG, 2004, IEEE T KNOWL DATA EN, V16, P523, DOI 10.1109/TKDE.2004.1269663; FRANKLIN M, 1998, P ACM SIGMOD INT C M, P516, DOI 10.1145/276304.276360; FURNAS GW, 1987, COMMUN ACM, V30, P947; HULL D, 1999, NIST SPECIAL PUBLICA, V500, P33; Jansen BJ, 2000, INFORM PROCESS MANAG, V36, P207, DOI 10.1016/S0306-4573(99)00056-4; Menczer F, 2000, MACH LEARN, V39, P203, DOI 10.1023/A:1007653114902; Mitchell T, 1997, MACHINE LEARNING; MITCHELL T, 1994, COMMUN ACM, V37, P81; Ng HT, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P67, DOI 10.1145/258525.258537; NG HT, 1999, NIST SPECIAL PUBLICA, V500, P267; PACKER KH, 1979, J AM SOC INFORM SCI, V30, P125, DOI 10.1002/asi.4630300303; Pathak P., 2000, P 33 HAW INT C SYST; Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943; PEDHAZUR EJ, 1991, MEASUREMENT DESIGN A; ROBERTSON SE, 1986, J DOC, V42, P182, DOI 10.1108/eb026792; Robertson S.E., 1996, NIST SPECIAL PUBLICA, p[73, 500]; ROBERTSON SE, 1976, J AM SOC INFORM SCI, V27, P129, DOI 10.1002/asi.4630270302; ROBERTSON SE, 1990, J DOC, V46, P359, DOI 10.1108/eb026866; ROCCHIO J. J., 1971, SMART RETRIEVAL SYST; Salton G., 1971, SMART RETRIEVAL SYST; Schutze H., 1995, P 18 ANN INT ACM SIG, P229, DOI 10.1145/215206.215365; Singhal A, 1996, INFORM PROCESS MANAG, V32, P619, DOI 10.1016/0306-4573(96)00008-8; van Rijsbergen C. J., 1979, INFORM RETRIEVAL; Xu J., 1996, P 19 ANN INT ACM SIG, P4, DOI 10.1145/243199.243202; Yang Yiming, 1997, P 14 INT C MACH LEAR, P412	30	18	18	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9236		DECIS SUPPORT SYST	Decis. Support Syst.	AUG	2005	40	2					213	233		10.1016/j.dss.2004.02.003		21	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science	Computer Science; Operations Research & Management Science	973LM	WOS:000232524100005	
J	Prank, K; Schulze, E; Eckert, O; Nattkemper, TW; Bettendorf, M; Maser-Gluth, C; Sejnowski, TJ; Grote, A; Penner, E; von zur Muhlen, A; Brabant, G				Prank, K; Schulze, E; Eckert, O; Nattkemper, TW; Bettendorf, M; Maser-Gluth, C; Sejnowski, TJ; Grote, A; Penner, E; von zur Muhlen, A; Brabant, G			Machine learning approaches for phenotype-genotype mapping: predicting heterozygous mutations in the CYP21B gene from steroid profiles	EUROPEAN JOURNAL OF ENDOCRINOLOGY			English	Article							CONGENITAL ADRENAL-HYPERPLASIA; ARTIFICIAL NEURAL NETWORKS; PCR-BASED DIAGNOSIS; 21-HYDROXYLASE DEFICIENCY; STEROID-21-HYDROXYLASE; CLASSIFICATION; INTRON-2; WOMEN	Objective: Non-linear relations between multiple biochemical parameters are the basis for the diagnosis of many diseases. Traditional linear analytical methods are not reliable predictors. Novel nonlinear techniques are increasingly used to improve the diagnostic accuracy of automated data interpretation. This has been exemplified in particular for the classification and diagnostic prediction of cancers based on expression profiling data. Our objective was to predict the genotype from complex biochemical data by comparing the performance of experienced clinicians to traditional linear analysis, and to novel non-linear analytical methods. Design and methods: As a model, we used a well-defined set of interconnected data consisting of unstimulated serum levels of steroid intermediates assessed in 54 subjects heterozygous for a mutation of the 21-hydroxylase gene (CYP21B) and in 43 healthy controls. Results: The genetic alteration was predicted from the pattern of steroid levels with an accuracy of 39% by clinicians and of 64% by linear analysis. In contrast, non-linear analysis, such as self-organizing artificial neural networks, support vector machines, and nearest neighbour classifiers, allowed for higher accuracy up to 83%. Conclusions: The successful application of these non-linear adaptive methods to capture specific biochemical problems may have generalized implications for biochemical testing in many areas. Nonlinear analytical techniques such as neural networks, support vector machines, and nearest neighbour classifiers may serve as an important adjunct to the decision process of a human investigator not ' trained ' in a specific complex clinical or laboratory setting and may aid them to classify the problem more directly.	Univ Bielefeld, Int NRW Grad Sch Bioinformat, D-33615 Bielefeld, Germany; Univ Bielefeld, Genome Res Ctr Biotechnol, D-33615 Bielefeld, Germany; Hannover Med Sch, D-30625 Hannover, Germany; Mol Genet Lab Raue, D-69121 Heidelberg, Germany; Hannover Med Sch, Dept Visceral & Transplantat Surg, D-30623 Hannover, Germany; Hannover Med Sch, Dept Clin Endocrinol, D-30623 Hannover, Germany; Univ Bielefeld, Fac Technol, Appl Neuroinformat Grp, D-33615 Bielefeld, Germany; Univ Heidelberg, Dept Pediat, D-69120 Heidelberg, Germany; Univ Heidelberg, Dept Pharmacol, D-69120 Heidelberg, Germany; Salk Inst, Howard Hughes Med Inst, San Diego, CA 92186 USA; Salk Inst, Computat Neurobiol Lab, San Diego, CA 92186 USA	Prank, K (reprint author), Univ Bielefeld, Int NRW Grad Sch Bioinformat, D-33615 Bielefeld, Germany.	klaus.prank@cebitec.uni-bielefeld.de					Azziz R, 1997, FERTIL STERIL, V68, P183; Baxt WG, 1996, LANCET, V347, P12, DOI 10.1016/S0140-6736(96)91555-X; BAXT WG, 1995, LANCET, V346, P1135, DOI 10.1016/S0140-6736(95)91804-3; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blanche H, 1997, HUM GENET, V101, P56, DOI 10.1007/s004390050586; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROSS SS, 1995, LANCET, V346, P1075, DOI 10.1016/S0140-6736(95)91746-2; Day DJ, 1996, HUM MOL GENET, V5, P2039, DOI 10.1093/hmg/5.12.2039; Dhanasekaran SM, 2001, NATURE, V412, P822, DOI 10.1038/35090585; FIET J, 1994, ANN CLIN BIOCHEM, V31, P56; GRUNWALD K, 1990, GYNECOL ENDOCRINOL, V4, P287, DOI 10.3109/09513599009024983; KEERTHI SS, 1999, CD9914 TR NAT U SING; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; KOHONEN T, 1982, BIOL CYBERN, V44, P135, DOI 10.1007/BF00317973; KOZOWER M, 1974, J CLIN ENDOCR METAB, V38, P407; Martinerie J, 1998, NAT MED, V4, P1173, DOI 10.1038/2667; MARTINETZ T, 1994, NEURAL NETWORKS, V7, P507, DOI 10.1016/0893-6080(94)90109-0; MARTINETZ TM, 1993, IEEE T NEURAL NETWOR, V4, P558, DOI 10.1109/72.238311; Mika S, 1999, NEURAL NETWORKS SIGN, P41; MOREIRA AC, 1992, J CLIN ENDOCR METAB, V74, P198, DOI 10.1210/jc.74.1.198; NEW MI, 1994, J STEROID BIOCHEM, V48, P15, DOI 10.1016/0960-0760(94)90246-1; Platt J., 1998, ADV KERNEL METHODS S; Scholkopf B, 1999, ADVANCES IN KERNEL METHODS, P327; SCHULZE E, 1995, ENDOCR RES, V21, P359; Schulze E, 1998, ENDOCR RES, V24, P637; SPEISER PW, 2003, ENGLAND J MED, V21, P776; Tarassenko L., 1998, GUIDE NEURAL COMPUTI; Vapnik V. N, 1995, NATURE STAT LEARNING; WILSON RC, 1995, J CLIN ENDOCR METAB, V80, P2322, DOI 10.1210/jc.80.8.2322	30	1	1	BIO SCIENTIFICA LTD	BRISTOL	EURO HOUSE, 22 APEX COURT WOODLANDS, BRADLEY STOKE, BRISTOL BS32 4JT, ENGLAND	0804-4643		EUR J ENDOCRINOL	Eur. J. Endocrinol.	AUG	2005	153	2					301	305		10.1530/eje.1.01957		5	Endocrinology & Metabolism	Endocrinology & Metabolism	961YS	WOS:000231698400016	
J	Frias-Martinez, E; Magoulas, G; Chen, S; Macredie, R				Frias-Martinez, E; Magoulas, G; Chen, S; Macredie, R			Modeling human behavior in user-adaptive systems: Recent advances using soft computing techniques	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						user modeling; adaptive hypermedia; soft computing; machine learning; data mining	GENETIC ALGORITHM; PERSONALIZATION; CUSTOMERS; RECOMMENDATION; MACHINE; IMPROVE; RULES	Adaptive Hypermedia systems are becoming more important in our everyday activities and users are expecting more intelligent services from them. The key element of a generic adaptive hypermedia system is the user model. Traditional machine learning techniques used to create user models are usually too rigid to capture the inherent uncertainty of human behavior. In this context, soft computing techniques can be used to handle and process human uncertainty and to simulate human decision-making. This paper examines how soft computing techniques, including fuzzy logic, neural networks, genetic algorithms, fuzzy clustering and neuro-fuzzy systems, have been used, alone or in combination with other machine learning techniques, for user modeling from 1999 to 2004. For each technique, its main applications, limitations and future directions for user modeling are presented. The paper also presents guidelines that show which soft computing techniques should be used according to the task implemented by the application. (C) 2005 Elsevier Ltd. All rights reserved.	Brunel Univ, Dept Informat Syst & Comp, Uxbridge UB8 3PH, Middx, England; Univ London Birkbeck Coll, Sch Comp Sci & Informat Syst, London WC1E 7HX, England	Frias-Martinez, E (reprint author), Brunel Univ, Dept Informat Syst & Comp, Uxbridge UB8 3PH, Middx, England.	frias-martinez@brunel.ac.uk; gmagoulas@dcs.bbk.ac.uk; sherry.chen@brunel.ac.uk; robert.macredie@brunel.ac.uk	Macredie, Robert/F-4928-2013	Macredie, Robert/0000-0001-5066-425X			ARDISSONO L, 1999, P 7 INT C US MOD UM, P35; Beck JE, 2003, LECT NOTES ARTIF INT, V2702, P303; Becker S, 1998, ASSIST TECHN RES SER, V4, P6; BEZDEK JC, 1981, PATTERN RECOGNTION F; BIDEL S, 2003, P 2 WORKSH MACH LEAR, P56; BONISSONE PP, 1995, P IEEE, V83, P450, DOI 10.1109/5.364490; BUCZAK AL, 2002, P 2 WORKSH PERS FUT, P9; CALLAN J, 2001, P 2 DELOS WORKSH PER; Changchien SW, 2001, EXPERT SYST APPL, V20, P325, DOI 10.1016/S0957-4174(01)00017-3; Drigas A, 2004, EXPERT SYST APPL, V26, P217, DOI 10.1016/S0957-4174(03)00136-2; ERINAKI M, 2003, ACM T INTERNET TECHN, V3, P1; FAN W, 2000, P 21 INT C INF SYST, P20; Fausett L., 1994, FUNDAMENTALS NEURAL; GEORGE G, 1999, P 8 C COMP GEN FORC, P575; Goldberg DE, 1989, GENETIC ALGORITHMS S; Goren-Bar D, 2001, LECT NOTES ARTIF INT, V2109, P188; Haykin S., 1999, NEURAL NETWORKS; Hsieh NC, 2004, EXPERT SYST APPL, V27, P623, DOI 10.1016/j.eswa.2004.06.007; Jang J.-S. R., 1997, NEUROFUZZY SOFT COMP; JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541; JANG JSR, 1995, P IEEE, V83, P378, DOI 10.1109/5.364486; Joshi A., 2000, P ACM SIGMOD WORKSH, P63; Kim Y, 2004, DECIS SUPPORT SYST, V37, P215, DOI 10.1016/S0167-9236(03)00008-3; Klir J., 1995, FUZZY SETS FUZZY LOG; Kobsa A, 2001, USER MODEL USER-ADAP, V11, P49, DOI 10.1023/A:1011187500863; Krishnapuram R, 2001, IEEE T FUZZY SYST, V9, P595, DOI 10.1109/91.940971; Kuo RJ, 2004, EXPERT SYST APPL, V26, P141, DOI 10.1016/S0957-4174(03)00115-5; LAMPINEN T, 2002, P 1 INT C FUZZ SYST, P300; LEE RST, 2001, LECT NOTES ARTIF INT, V2198, P403; Lee WP, 2003, EXPERT SYST APPL, V24, P365, DOI 10.1016/S0957-4174(02)00186-0; Li YF, 2004, KNOWL-BASED SYST, V17, P207, DOI 10.1016/j.knosys.2004.05.002; Magoulas G. D., 2001, Informatica, V25; Min H., 2001, Proceedings of the ISCA 3rd International Conference Information Reuse and Integration; Mobasher B, 2000, COMMUN ACM, V43, P142, DOI 10.1145/345124.345169; Nasraoui O., 2000, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V9, DOI 10.1142/S021821300000032X; Nasraoui O., 2003, P WEBKDD 2003 KDD WO, P37; Nasraoui O., 1999, P 8 INT FUZZ SYST AS; Pal SK, 2002, IEEE T NEURAL NETWOR, V13, P1163, DOI 10.1109/TNN.2002.1031947; Perkowitz M, 2000, COMMUN ACM, V43, P152, DOI 10.1145/345124.345171; Pierrakos D, 2003, USER MODEL USER-ADAP, V13, P311, DOI 10.1023/A:1026238916441; Riecken D, 2000, COMMUN ACM, V43, P27; Roh TH, 2003, EXPERT SYST APPL, V25, P413, DOI 10.1016/S0957-4174(03)00067-8; Romero C, 2003, LECT NOTES ARTIF INT, V2702, P25; Sas C., 2003, P 2 WORKSH MACH LEAR, P40; Schmitt C, 2003, LECT NOTES ARTIF INT, V2702, P297; Schwefel H. P., 1995, EVOLUTION OPTIMUM SE; SHAVLIK J, 2001, USER MODEL USER-ADAP, V13, P35; SHEPERD A, 2002, P 3K ANN HAW INT C S, V4; Shin HW, 2004, EXPERT SYST APPL, V27, P27, DOI 10.1016/j.eswa.2003.12.002; Shin KS, 2002, EXPERT SYST APPL, V23, P321, DOI 10.1016/S0957-4174(02)00051-9; SINHA NK, 2000, OUTLINE COMPUTATIONA, P3; Stathacopoulou R, 2003, LECT NOTES ARTIF INT, V2702, P337; Sternberg M., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.687883; TICLEK AB, 1998, IEEE T NEURAL NETWOR, V9, P1057; VRETTOS S, 2001, LECT NOTES ARTIF INT, V2198, P448; Webb GI, 2001, USER MODEL USER-ADAP, V11, P19, DOI 10.1023/A:1011117102175; Witten I. H., 1999, DATA MINING PRACTICA; YAN J, 1994, USING FUZZY LOGIC; Zukerman I., 1999, P 7 INT C US MOD UM, P275	59	13	13	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	AUG	2005	29	2					320	329		10.1016/j.eswa.2005.04.005		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	951RE	WOS:000230947400009	
J	Suraj, Z; Peters, JF; Grochowalski, P				Suraj, Z; Peters, JF; Grochowalski, P			A controller design for the Khepera robot: A rough set approach	FUNDAMENTA INFORMATICAE			English	Article; Proceedings Paper	Meeting on Concurrency Specification and Programming	SEP 24-26, 2004	Caputh, GERMANY			artificial intelligence; rough sets; fuzzy systems; machine learning; Khepera robot; control design; expert system	SYSTEM	The Khepera robot belongs to the family of miniature mobile robots of the K-Team firm. It is used in a number of places for scientific and educational purposes. Considering its advantages (such as small size, precision of movement, ease of control), it is applied to testing different approaches in the domain of artificial intelligence. This paper describes the methodology of a control system design for the Khepera robot based on a rough set approach. The proposed approach entails a Study of robot behaviour insofar as its movements are influenced by measurements from its sensors and the choice of actions that make it possible for the robot to achieve its system goals. The constructed controller concerns the realization of some tasks such as avoiding the obstacles, reaching a target, following an obstacle, finding the way out of a labyrinth. The proposed controller has been tested on both a robot simulator and on a real robot. Our experimental results show that the proposed rough set methodology can be applied to the design of a controller for the Khepera robot.	Rzeszow Univ, Inst Math, Rzeszow, Poland; Univ Manitoba, Dept Elect & Comp Engn, Winnipeg, MB R3T 2N2, Canada; Univ Informat Technol & Management, Chair Comp Sci Fdn, Rzeszow, Poland	Grochowalski, P (reprint author), Rzeszow Univ, Inst Math, Rzeszow, Poland.	zsuraj@wsiz.rzeszow.pl; jfpeters@ee.umanitoba.ca; piotrg@univ.rzeszow.pl					ALPIGINI JJ, 2002, P 3 INT C ROUGH SETS; CZOGALA E, 1995, FUZZY SET SYST, V72, P61, DOI 10.1016/0165-0114(94)00264-8; FURUHASHI T, 1998, P SYST MAN CYB SMC 9, P2101; FURUHASHI T, 1999, INT J ADV COMPUTATIO, V3, P99; GROCHOWALSKI P, 2002, THESIS RZESZOW U TEC; Li H., 1995, FUZZY LOGIC INTELLIG; LIN TY, 1997, ROUGH SETS DATA MINI, P123; MROZEK A, 1994, P 3 INT WORKSH ROUGH, P498; MUNAKATA T, 1997, ROUGH SETS DATA MINI, P77; Pal S. K., 2004, ROUGH NEURAL COMPUTI; PAWLAK Z, 1985, B POLISH ACAD SCI TE, V33, P551; PAWLAK Z, 1987, B EATCS, V33, P85; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Pawlak Z., 1994, ADV DEMPSTER SHAFER, P251; PAWLAK Z, 1997, ROUGH SETS DAT AMINI, P139; Pawlak Z., 1996, P 4 EUR C INT TECHN, P209; Pawlak Z., 1985, LECT NOTES COMPUTER, V208, P186; PAWLAK Z, 1986, B POLISH ACAD SCI TE, V34, P553; Pawlak Z., 1991, ROUGH SETS THEORETIC; PAWLAK Z, 2004, T ROUGH SETS, V1, P1; Pedrycz W., 1997, P IEEE AER C SNOWM A, P385; PEDRYCZ W, 1997, P IEEE INT C COMP CY, P1139; Pedrycz W, 1993, FUZZY CONTROL FUZZY; Peters J. F., 2000, Fundamenta Informaticae, V43; Petersen J. L., 1998, Proceedings of FMSP'98. Second Workshop on Formal Methods in Software Practice, DOI 10.1145/298595.298597; PETERS JF, 1998, P CAN C EL COMP ENG, P233; PETERS JF, 1998, LECT NOTES ARTIF INT, V1424, P491; Peters JF, 2003, STUD FUZZ SOFT COMP, V116, P141; Peters JF, 2003, LECT NOTES ARTIF INT, V2639, P213; POLKOWSKI L, 1995, SOFT COMPUTING, P240; RUTKOWSKA D, 1997, NEURON NETWORKS GENE, P97; Tanaka K., 1997, INTRO FUZZY LOGIC PR; WANG G, 2003, LECT NOTES ARTIFICIA, V2639; ZIARKO W, 2001, LECT NOTES ARTIFICIA; 1999, KHEPERA USER MANUAL	35	0	0	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0169-2968		FUND INFORM	Fundam. Inform.	AUG	2005	67	1-3					219	231				13	Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	020YH	WOS:000235948800017	
J	Chi, HM; Ersoy, MK				Chi, HM; Ersoy, MK			A statistical self-organizing learning system for remote sensing classification	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article						artificial neural networks; hyperspectral image; classification; machine learning; overlitting; support vector machine (SMV); t-test	TIME-SERIES PREDICTION; FUNCTIONAL-LINK NET; NEURAL-NETWORKS	A new learning system called a statistical self-organizing learning system (SSOLS), combining functional-link neural networks, statistical hypothesis testing, and self-organization of a number of enhancement nodes, is introduced for remote sensing applications. Its structure consists of two stages, a mapping stage and a learning stage. The input training vectors are initially mapped to the enhancement vectors in the mapping stage by multiplying with a random matrix, followed by pointwise nonlinear transformations. Starting with only one enhancement node, the enhancement layer incrementally adds an extra node in each iteration. The optimum dimension of the enhancement layer is determined by using an efficient leave-one-out cross-validation method. In this way, the number of enhancement nodes is also learned automatically. A t-test algorithm can also be applied to the mapping stage to mitigate the effect of overfitting and to further reduce the number of enhancement nodes required, resulting in a more compact network. In the learning stage, both the input vectors and the enhancement vectors are fed into a least squares learning module to obtain the estimated output vectors. This is made possible by choosing the output layer linear. In addition, several SSOLSs can be trained independently in parallel to form a consensual SSOLS, whose final output is a linear combination of the outputs of each SSOLS module. The SSOLS is simple, fast to compute, and suitable for remote sensing applications,	Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA	Chi, HM (reprint author), Purdue Univ, Sch Elect & Comp Engn, 1285 Elect Engn Bldg, W Lafayette, IN 47907 USA.	hoiming@purdue.edu; ersoy@purdue.edu					Benediktsson JA, 1997, IEEE T NEURAL NETWOR, V8, P54, DOI 10.1109/72.554191; BURMAN P, 1989, BIOMETRIKA, V76, P503, DOI 10.1093/biomet/76.3.503; Casella G., 1990, STAT INFERENCE; Chen CLP, 1999, IEEE T SYST MAN CY B, V29, P62, DOI 10.1109/3477.740166; Chen CLP, 1998, NEUROCOMPUTING, V18, P11, DOI 10.1016/S0925-2312(97)00062-3; CHI HM, 2002, P 2002 INT ENG SYST, V11; Cowen C. C., 1996, LINEAR ALGEBRA ENG S; Fukunaga K., 1990, INTRO STAT PATTERN R; Haykin S., 1999, NEURAL NETWORKS; Joachims T., 1998, ADV KERNEL METHODS S; Kay SM, 1993, FUNDAMENTALS STAT SI; Landgrebe D. A., 2003, SIGNAL THEORY METHOD; LEE CH, 1993, IEEE T PATTERN ANAL, V15, P388, DOI 10.1109/34.206958; Montgomery D. C., 1997, DESIGN ANAL EXPT; MOORE AW, 2001, CROSS VALIDATION DET; PAO YH, 1994, NEUROCOMPUTING, V6, P163, DOI 10.1016/0925-2312(94)90053-1; PAO YH, 1992, COMPUTER, V25, P76, DOI 10.1109/2.144401; Rencher A.C., 2002, METHODS MULTIVARIATE; SCHWAIGHOFER A, MATLAB INTERFACE SVM; STONE M, 1974, J R STAT SOC B, V36, P111; Stone M., 1978, Mathematische Operationsforschung und Statistik, Series Statistics, V9; Valafar F, 1996, CIRC SYST SIGNAL PR, V15, P23, DOI 10.1007/BF01187692; Vapnik V. N, 1995, NATURE STAT LEARNING	23	4	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0196-2892		IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	AUG	2005	43	8					1890	1900		10.1109/TGRS.2005.851188		11	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing	Geochemistry & Geophysics; Engineering; Remote Sensing	949BX	WOS:000230761000019	
J	Ueda, N; Aoki-Kinoshita, KF; Yamaguchi, A; Akutsu, T; Mamitsuka, H				Ueda, N; Aoki-Kinoshita, KF; Yamaguchi, A; Akutsu, T; Mamitsuka, H			A probabilistic model for mining labeled ordered trees: Capturing patterns in carbohydrate sugar chains	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						biology and genetics; machine learning; data mining; mining methods and algorithms	MARKOV-MODELS; CLASSIFICATION	Glycans, or carbohydrate sugar chains, which play a number of important roles in the development and functioning of multicellular organisms, can be regarded as labeled ordered trees. A recent increase in the documentation of glycan structures, especially in the form of database curation, has made mining glycans important for the understanding of living cells. We propose a probabilistic model for mining labeled ordered trees, and we further present an efficient learning algorithm for this model, based on an EM algorithm. The time and space complexities of this algorithm are rather favorable, falling within the practical limits set by a variety of existing probabilistic models, including stochastic context-free grammars. Experimental results have shown that, in a supervised problem setting, the proposed method outperformed five other competing methods by a statistically significant factor in all cases. We further applied the proposed method to aligning multiple glycan trees, and we detected biologically significant common subtrees in these alignments where the trees are automatically classified into subtypes already known in glycobiology. Extended abstracts of parts of the work presented in this paper have appeared in [35], [4], and [3].	Kyoto Univ, Inst Chem Res, Bioinformat Ctr, Uji 6110011, Japan	Ueda, N (reprint author), Kyoto Univ, Inst Chem Res, Bioinformat Ctr, Gokasho, Uji 6110011, Japan.	ueda@kuicr.kyoto-u.ac.jp; kiyoko@kuicr.kyoto-u.ac.jp; atsuko@kuicr.kyoto-u.ac.jp; takutsu@kuicr.kyoto-u.ac.jp; mami@kuicr.kyoto-u.ac.jp					Abe H, 2001, ARTIF CELL BLOOD SUB, V29, P275, DOI 10.1081/BIO-100104230; ABITEBOULD S, 2000, DATA WEB RELATIONS S; Aoki KF, 2004, NUCLEIC ACIDS RES, V32, pW267, DOI 10.1093/nar/gkh473; AOKI KF, 2004, P 12 INT C INT SYST; AOKI KF, 2004, ACM SIGMOD RECORD, V33; Asai T, 2002, SIAM PROC S, P158; Baker J, 1979, 97 M AC SOC AM, P547; BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147; Bertozzi CR, 2001, SCIENCE, V291, P2357, DOI 10.1126/science.1059820; BROOKS S, 2002, BIOS SCI; Cadez I, 2003, DATA MIN KNOWL DISC, V7, P399, DOI 10.1023/A:1024992613384; Chang GJS, 1997, P INT COMP SOFTW APP, P536, DOI 10.1109/CMPSAC.1997.625064; CONG G, 2002, P 2 SIAM INT C DAT M; Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Diligenti M, 2003, IEEE T PATTERN ANAL, V25, P519, DOI 10.1109/TPAMI.2003.1190578; Durbin R., 1998, BIOL SEQUENCE ANAL P; Fine S, 1998, MACH LEARN, V32, P41, DOI 10.1023/A:1007469218079; Gartner T., 2003, P 16 ANN C LEARN THE, P129; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; Horvath T., 2004, P 10 ACM SIGKDD INT, P158, DOI 10.1145/1014052.1014072; Jaakkola TS, 1999, ADV NEUR IN, V11, P487; Kashima H., 2003, P 20 INT C MACH LEAR, P321; KASHIMA H, 2002, P 19 INT C MACH LEAR, P411; Lari K., 1990, Computer Speech and Language, V4, DOI 10.1016/0885-2308(90)90022-X; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; Mahe P., 2004, P 21 INT C MACH LEAR, P552; McLachlan G., 2000, FINITE MIXTURE MODEL; McLachlan G. J., 1996, EM ALGORITHM EXTENSI; Kanehisa M, 2004, NUCLEIC ACIDS RES, V32, pD277, DOI 10.1093/nar/gkh063; Pearl J., 1988, PROBABILISTIC REASON; Rabiner L, 1993, FUNDAMENTALS SPEECH; Termier A., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183987; Tsuda Koji, 2002, BIOINFORMATICS, V18, P268; UEDA N, 2001, P 4 INT C DISC SCI, P401; Ueda N, 2004, SIAM PROC S, P357; Varki A., 1999, ESSENTIALS GLYCOBIOL; Zaki M. J., 2003, P 9 ACM SIGKDD INT C, P316	38	11	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	AUG	2005	17	8					1051	1064		10.1109/TKDE.2005.117		14	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	935UP	WOS:000229809200004	
J	Arshadi, N; Jurisica, I				Arshadi, N; Jurisica, I			Data mining for case-based reasoning in high-dimensional biological domains	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						machine learning; data mining; clustering; feature selection; case-based reasoning classifiers; microarray data analysis; mass spectrometry data analysis; biomarker discovery	OVARIAN-CANCER; GENE-EXPRESSION; SERUM; CLASSIFICATION; PATTERNS; REPRODUCIBILITY; PREDICTION; KNOWLEDGE; SELECTION; SUPPORT	Case-based reasoning (CBR) is a suitable paradigm for class discovery in molecular biology, where the rules that define the domain knowledge are difficult to obtain and the number and the complexity of the rules affecting the problem are too large for formal knowledge representation. To extend the capabilities of CBR, we propose the mixture of experts for case-based reasoning (MOE4CBR), a method that combines an ensemble of CBR classifiers with spectral clustering and logistic regression. Our approach not only achieves higher prediction accuracy, but also leads to the selection of a subset of features that have meaningful relationships with their class labels. We evaluate MOE4CBR by applying the method to a CBR system called TA3-a computational framework for CBR systems. For two ovarian mass spectrometry data sets, the prediction accuracy improves from 80 percent to 93 percent and from 90 percent to 98.4 percent, respectively. We also apply the method to leukemia and lung microarray data sets with prediction accuracy improving from 65 percent to 74 percent and from 60 percent to 70 percent, respectively. Finally, we compare our list of discovered biomarkers with the lists of selected biomarkers from other studies for the mass spectrometry data sets.	Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada; Princess Margaret Hosp, Ontario Canc Inst, Univ Hlth Network, Div Canc Informat, Toronto, ON M5G 2M9, Canada	Arshadi, N (reprint author), Univ Toronto, Dept Comp Sci, 10 Kings Coll Rd, Toronto, ON M5S 3G4, Canada.	niloofar@cs.toronto.edu; juris@ai.utoronto.ca					AHA D, 1998, CAS BAS REAS INT PAP; Aha D. W., 1994, P AAAI 94 WORKSH CAS, P106; ANDRITSOS P., 2004, P INT C EXT DAT TECH, P123; ARSHADI N, 2004, CSRG490 U TOR DEP CO; Arshadi N, 2004, LECT NOTES COMPUT SC, V3155, P17; BAEZAYATES R, 1999, MODERN INFORMATION R; Baggerly KA, 2004, BIOINFORMATICS, V20, P777, DOI 10.1093/bioinformatics/btg484; Baggerly KA, 2005, J NATL CANCER I, V97, P307, DOI 10.1093/jnci/dji008; Devore J. L., 1995, PROBABILITY STAT ENG; Dunn J. C., 1974, Journal of Cybernetics, V4; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Han J. W, 2000, DATA MINING CONCEPTS; Hastie T, 2001, ELEMENTS STAT LEARNI; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; Jaeger J, 2003, Pac Symp Biocomput, P53; JONES L, 2003, CRITICAL ASSESSMENT, P38; Jurisica I, 1998, ARTIF INTELL MED, V12, P1, DOI 10.1016/S0933-3657(97)00037-7; Jurisica I, 2004, AI MAG, V25, P85; Jurisica I, 2001, IBM SYST J, V40, P394; Jurisica I., 1997, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V6, DOI 10.1142/S0218213097000268; JURISICA I, 2000, INT J APPL INTELLIGE, V12, P251; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohonen T., 1995, SELF ORG MAPS; Leake D.B., 1996, CASE BASED REASONING; LeCun Y, 1990, ADV NEURAL INFORMATI, V2, P598; Lenz Mario, 1998, CASE BASED REASONING; Marling C, 2002, AI MAG, V23, P69; Mitchell T, 1997, MACHINE LEARNING; Mukherjee S, 2003, PRACTICAL APPROACH M, P166, DOI 10.1007/0-306-47815-3_9; MYLOPOULOS J, 1990, ACM T INFORM SYST, V8, P325, DOI 10.1145/102675.102676; NG AY, 2002, ADV NEURAL INFORMATI, V14; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Sorace JM, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-24; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210; Xing E., 2001, P 18 INT C MACH LEAR, P601; Yang Q, 2000, LECT NOTES ARTIF INT, V1822, P102; Zhu W, 2003, P NATL ACAD SCI USA, V100, P14666, DOI 10.1073/pnas.2532248100	41	37	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	AUG	2005	17	8					1127	1137		10.1109/TKDE.2005.124		11	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	935UP	WOS:000229809200010	
J	Snoek, CGM; Worring, M				Snoek, CGM; Worring, M			Multimedia event-based video indexing using time intervals	IEEE TRANSACTIONS ON MULTIMEDIA			English	Article						context; multimodal integration; semantic event classification; statistical pattern recognition; synchronization; time interval relations; video indexing	CLASSIFICATION; RETRIEVAL	We propose the time interval multimedia event (TIME) framework as a robust approach for classification of semantic events in multimodal video documents. The representation used in TIME extends the Allen temporal interval relations and allows for proper inclusion of context and synchronization of the heterogeneous information sources involved in multimodal video analysis. To demonstrate the viability of our approach, it was evaluated on the domains of soccer and news broadcasts. For automatic classification of semantic events, we compare three different machine learning techniques, i.c. C4.5 decision tree, maximum entropy, and support vector machine. The results show that semantic video indexing results significantly benefit from using the TIME framework.	Univ Amsterdam, Inst Informat, Intelligent Syst Lab, NL-1098 SJ Amsterdam, Netherlands	Snoek, CGM (reprint author), Univ Amsterdam, Inst Informat, Intelligent Syst Lab, Kruislaan 403, NL-1098 SJ Amsterdam, Netherlands.	cgmsnoek@science.uva.nl					Aiello M., 2002, International Journal on Document Analysis and Recognition, V5, DOI 10.1007/s10032-002-0080-x; ALLEN JF, 1983, COMMUN ACM, V26, P11; ASSFALG J, 2002, P IEEE INT C MULT EX; BAAN J, 2001, P 10 TEXT RETR C GAI; Babaguchi N, 2002, IEEE T MULTIMEDIA, V4, P68, DOI 10.1109/6046.985555; Berger AL, 1996, COMPUT LINGUIST, V22, P39; Bertini M, 2002, PATTERN RECOGN, V35, P581, DOI 10.1016/S0031-3203(01)00061-9; DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379; Eickeler S., 1999, P IEEE INT C AC SPEE, P2997; Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758; Fischer S., 1995, P ACM MULT 95 SAN FR, P295, DOI 10.1145/217279.215283; HAN M, 2002, P ACM MULT JUAN LES; HUANG J, 1999, P IEEE WORKSH MULT S; Ide I, 1999, LECT NOTES COMPUT SC, V1554, P87; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; LAU R, 1993, P ARPA HUM LANG TECH, P81; Leonardi R, 2002, IEEE MULTIMEDIA, V9, P44, DOI 10.1109/93.998057; LIN WH, 2002, P ACM MULT JUAN LES; Naphade MR, 2001, IEEE T MULTIMEDIA, V3, P141; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; SNOEK CGM, 2003, P IEEE INT C MULT EX, V3, P481; Snoek CGM, 2005, MULTIMED TOOLS APPL, V25, P5, DOI 10.1023/B:MTAP.0000046380.27575.a5; Vapnik V. N., 2000, NATURE STAT LEARNING; YOW D, 1995, P AS C COMP VIS SING; Zhou WS, 2002, INFORM SYST, V27, P559, DOI 10.1016/S0306-4379(02)00018-2	28	38	42	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1520-9210		IEEE T MULTIMEDIA	IEEE Trans. Multimedia	AUG	2005	7	4					638	647		10.1109/TMM.2005.850966		10	Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications	Computer Science; Telecommunications	946XQ	WOS:000230607000006	
J	Sueyoshi, T; Tadiparthi, GR				Sueyoshi, T; Tadiparthi, GR			A wholesale power trading simulator with learning capabilities	IEEE TRANSACTIONS ON POWER SYSTEMS			English	Article						electricity competition; machine learning; market model; strategic pricing; wholesale power trading	BIDDING STRATEGIES; ELECTRICITY MARKET; NEURAL-NETWORK; PRICE; ENVIRONMENT; CONTRACTS	The U.S. wholesale power market comprises a large commodity market. The growth in power trading is due to the ongoing deregulation policy of the electric power industry. Most deregulation scenarios indicate a further separation of power production from transmission and retailing. The power production is opened to more competition. Unfortunately, the power trading mechanism is not clearly investigated in the level that we can predict a price change in the U.S. wholesale power market. Such a price change in the U.S. wholesale power market is explored from a simulation system with learning capabilities. Using the new intelligence system, we investigate the bidding strategies of traders in the wholesale power market and examine how the price change occurs under different economic and engineering environments.	New Mexico Inst Min & Technol, Dept Management, Socorro, NM 87801 USA; New Mexico Inst Min & Technol, Dept Comp Sci, Socorro, NM 87801 USA	Sueyoshi, T (reprint author), New Mexico Inst Min & Technol, Dept Management, Socorro, NM 87801 USA.	toshi@nmt.edu; gtadiparthi@ieee.org					AMUNDSEN ES, 1994, ENERG ECON, V16, P271, DOI 10.1016/0140-9883(94)90024-8; ANDERSSON B, 1995, ENERGY J, V16, P97; Arroyo JM, 2002, IEEE T POWER SYST, V17, P1225, DOI 10.1109/TPWRS.2002.804952; AXELROD R, 1997, COMPELXITY COOPERATI; Bagnall A. J., 2000, P GEN EV COMP C LAS, P605; Brennan D, 1998, ENERG ECON, V20, P121, DOI 10.1016/S0140-9883(97)00010-8; Cheng JWM, 1998, IEEE T POWER SYST, V13, P1020, DOI 10.1109/59.709092; Contreras J, 2002, IEEE T POWER SYST, V17, P148, DOI 10.1109/59.982206; GEDRA TW, 1994, IEEE T POWER SYST, V9, P1766, DOI 10.1109/59.331429; GREEN R, 1992, J POLIT ECON, V44, P205; Guan XH, 2001, IEEE T POWER SYST, V16, P402; Jacobs JM, 1997, IEEE T POWER SYST, V12, P968, DOI 10.1109/59.589794; Joskow Paul, 1983, MARKETS POWER; Krishna V., 2002, AUCTION THEORY; Lamont JW, 1997, IEEE T POWER SYST, V12, P1729, DOI 10.1109/59.627883; Song HL, 2000, IEEE T POWER SYST, V15, P618, DOI 10.1109/59.867150; Liu Y, 2003, IEEE T POWER SYST, V18, P106, DOI 10.1109/TPWRS.2002.807063; MORKIIYO T, 2004, ASIA PACIFIC MANAG R, V9, P751; Nogales FJ, 2002, IEEE T POWER SYST, V17, P342, DOI 10.1109/TPWRS.2002.1007902; Richter CW, 1998, IEEE T POWER SYST, V13, P256, DOI 10.1109/59.651644; Richter CW, 1999, IEEE T POWER SYST, V14, P1207, DOI 10.1109/59.801874; Rosenwald GW, 1996, IEEE T POWER SYST, V11, P1757, DOI 10.1109/59.544639; Schweppe F. C., 1988, SPOT PRICING ELECT; Senjyu T, 2002, IEEE T POWER SYST, V17, P113, DOI 10.1109/59.982201; Shahidehpour M., 2002, MARKET OPERATIONS EL; Song HL, 2002, IEEE T POWER SYST, V17, P73; Stoft S., 2002, POWER SYSTEM EC; Sutton R.S., 1998, REINFORCEMENT LEARNI; Taylor JW, 2002, IEEE T POWER SYST, V17, P626, DOI 10.1109/TPWRS.2002.800906; Villar J, 2003, IEEE T POWER SYST, V18, P91, DOI 10.1109/TPWRS.2002.807061; Wilson R, 2002, ECONOMETRICA, V70, P1299, DOI 10.1111/1468-0262.00334; Yeung CSK, 1999, IEEE T POWER SYST, V14, P929, DOI 10.1109/59.780905; Zhang L, 2003, IEEE T POWER SYST, V18, P99, DOI 10.1109/TPWRS.2002.807062	33	21	22	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0885-8950		IEEE T POWER SYST	IEEE Trans. Power Syst.	AUG	2005	20	3					1330	1340		10.1109/TPWRS.2005.851948		11	Engineering, Electrical & Electronic	Engineering	952KH	WOS:000231001900016	
J	Zhou, ZH; Yu, Y				Zhou, ZH; Yu, Y			Ensembling local learners through multimodal perturbation	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						data mining; ensemble learning; local learner; machine learning; multimodal perturbation; nearest-neighbor classifier; stable base learner	DECISION TREES; ACCURACY; CLASSIFIERS	Ensemble learning algorithms train multiple component learners and then combine their predictions. In order to generate a strong ensemble, the component learners should be with high accuracy as well as high diversity. A popularly used scheme in generating accurate but diverse component learners is to perturb the training data with resampling methods, such as the bootstrap sampling used in bagging. However, such a scheme is not very effective on local learners such as nearest-neighbor classifiers because a slight change in training data can hardly result in local learners with big differences. In this paper, a new ensemble algorithm named Filtered Attribute Subspace based Bagging with Injected Randomness (FASBIR) is proposed for building ensembles of local learners, which utilizes multimodal perturbation to help generate accurate but diverse component learners. In detail, FASBIR employs the perturbation on the training data with bootstrap sampling, the perturbation on the input attributes with attribute filtering and attribute subspace selection, and the perturbation on the learning parameters with randomly configured distance metrics. A large empirical study shows that FASBIR is effective in building ensembles of nearest-neighbor classifiers, whose performance is better than that of many other ensemble algorithms.	Nanjing Univ, Natl Lab Novel Software Technol, Nanjing 210093, Peoples R China	Zhou, ZH (reprint author), Nanjing Univ, Natl Lab Novel Software Technol, Nanjing 210093, Peoples R China.	zhouzh@nju.edu.cn; yuy@lamda.nju.edu.cn					Aha DW, 1997, ARTIF INTELL REV, V11, P7, DOI 10.1023/A:1006538427943; Ali KM, 1996, MACH LEARN, V24, P173, DOI 10.1007/BF00058611; Alkoot FM, 2002, PATTERN ANAL APPL, V5, P326; Bay S.D., 1998, P 15 INT C MACH LEAR, P37; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 2000, MACH LEARN, V40, P229, DOI 10.1023/A:1007682208299; Breiman L., 1996, 460 U CAL STAT DEP; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Cherkauer K., 1996, P 13 AAAI WORKSH INT, P15; Dasarathy BV, 1991, NEAREST NEIGHBOR NOR; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Dietterich T.G., 2002, HDB BRAIN THEORY NEU; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Efron B., 1993, INTRO BOOTSTRAP; Freund Y., 1995, P 2 EUR C COMP LEARN, P23; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; HALL LO, 2003, P 3 IEEE INT C DAT M, P533; Ho T.K., 1998, LECT NOTES COMPUTER, V1451, P640; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Kolen J.F., 1991, ADV NEURAL INFORMATI, V3, P860; Krogh A., 1995, ADV NEURAL INFORMATI, V8, P231; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; KWOK SW, 1988, P 4 ANN C UNCERTAINT, P327; Lam L., 2000, LECT NOTES COMPUTER, V1857, P78; Latinne P, 2000, LECT NOTES COMPUT SC, V1857, P200; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Tumer K, 2003, PATTERN ANAL APPL, V6, P65, DOI 10.1007/s10044-002-0181-7; Vlachos M, 2002, P 8 ACM SIGKDD INT C, P645; Zhou ZH, 2005, J COMPUT SCI TECHNOL, V20, P48, DOI 10.1007/s11390-005-0005-5	30	32	39	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	AUG	2005	35	4					725	735		10.1109/TSMCB.2005.845396		11	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	946JT	WOS:000230569000007	
J	Bhatt, RB; Gopal, M				Bhatt, RB; Gopal, M			Improved feature selection algorithm with fuzzy-rough sets on compact computational domain	INTERNATIONAL JOURNAL OF GENERAL SYSTEMS			English	Article						compact computational domain; feature selection; fuzzy-rough sets; machine learning		The aim of this paper is to provide an efficient input feature selection algorithm for modeling of systems based on modified definition of fuzzy-rough sets. Some of the critical issues concerning the complexity and convergence of the feature selection algorithm are discussed in detail. Based on some natural properties of fuzzy t-norm and t-conorm operators, the concept of fuzzy-rough sets on compact computational domain is put forward, which is then utilized to construct improved Fuzzy-Rough Feature Selection algorithm. Various mathematical properties of this new definition of fuzzy-rough sets are discussed from pattern classification viewpoint. Speedup factor as high as 622 has been achieved with proposed algorithm compared to recently proposed FRSAR, with improved model performance on selected set of features.	Indian Inst Technol, Control Grp, Dept Elect Engn, New Delhi 110016, India	Bhatt, RB (reprint author), Indian Inst Technol, Control Grp, Dept Elect Engn, New Delhi 110016, India.	bhattrajen@ee.iitd.ernet.in; mgopal@ee.iitd.ernet.in					Bauer KW, 2000, NEUROCOMPUTING, V31, P29, DOI 10.1016/S0925-2312(99)00147-2; Bezdek J. C., 1981, PATTERN RECOGNITION; BHATT RB, 2004, P INT C SYST CYB INF, P371; Black C.L, 1998, UCI REPOSITORY MACHI; Dubois D., 1992, INTELLIGENT DECISION, P203; Emami MR, 1998, IEEE T FUZZY SYST, V6, P346, DOI 10.1109/91.705501; Jensen R, 2002, PROCEEDINGS OF THE 2002 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOL 1 & 2, P29; LIN YH, 1995, IEEE T FUZZY SYST, V3, P190; Mitra S, 2002, IEEE T NEURAL NETWOR, V13, P3, DOI 10.1109/72.977258; PAWLAK Z, 1993, I COMPUT SCI RES REP, P23; Pawlak Z., 1998, P IEEE WORLD C COMP, V1, P106; Pawlak Z, 2002, INFORM SCIENCES, V147, P1, DOI 10.1016/S0020-0255(02)00197-4; Pawlak Z., 1991, ROUGH SETS THEORETIC; Radzikowska A., 2002, FUZZY SETS SYSTEMS, V126, P137, DOI 10.1016/S0165-0114(01)00032-X; SARA B, 1988, COMPUTER ALGORITHMS; SARKAR M, 1998, P IEEE INT C SYST MA; Setiono R, 1997, IEEE T NEURAL NETWOR, V8, P654; SUGENO M, 1993, IEEE T FUZZY SYST, V6, P7; Verikas A, 2002, PATTERN RECOGN LETT, V23, P1323, DOI 10.1016/S0167-8655(02)00081-8; WANG LX, 1992, IEEE T SYST MAN CYB, V22, P1414, DOI 10.1109/21.199466; WINDHAM MP, 1982, IEEE T PATTERN ANAL, V4, P357	21	1	1	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0308-1079		INT J GEN SYST	Int. J. Gen. Syst.	AUG	2005	34	4					485	505		10.1080/03081070500192579		21	Computer Science, Theory & Methods; Ergonomics	Computer Science; Engineering	982NU	WOS:000233169700006	
J	Bousquet, C; Henegar, C; Lillo-Le Louet, A; Degoulet, P; Jaulent, MC				Bousquet, C; Henegar, C; Lillo-Le Louet, A; Degoulet, P; Jaulent, MC			Implementation of automated signal generation in pharmacovigilance using a knowledge-based approach	INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS			English	Article						adverse drug reaction reporting systems; terminology; automatic data processing; knowledge representation (computer); description logic; ontological modeling	ADVERSE DRUG-REACTIONS; MEDICAL DICTIONARY; MEDDRA; DISPROPORTIONALITY; TERMINOLOGY; DATABASE; SYSTEMS	Automated signal generation is a growing field in pharmacovigilance that relies on data mining of huge spontaneous reporting systems for detecting unknown adverse drug reactions (ADR). Previous implementations of quantitative techniques did not take into account issues related to the medical dictionary for regulatory activities (MedDRA) terminology used for coding ADRs. MedDRA is a first generation terminology tacking formal definitions; grouping of similar medical conditions is not accurate due to taxonomic limitations. Our objective was to build a data-mining tool. that improves signal detection algorithms by performing terminological reasoning on MedDRA codes described with the DAML + OIL description logic. We propose the PharmaMiner tool. that implements quantitative techniques based on underlying statistical and bayesian models. It is a JAVA application displaying results in tabular format and performing terminological reasoning with the Racer inference engine. The mean frequency of drug-adverse effect associations in the French database was 2.66. Subsumption reasoning based on MedDRA taxonomical hierarchy produced a mean number of occurrence of 2.92 versus 3.63 (p < 0.001) obtained with a combined technique using subsumption and approximate matching reasoning based on the ontological structure. Semantic integration of terminological systems with data mining methods is a promising technique for improving machine learning in medical databases. (C) 2005 Elsevier Ireland Ltd. All rights reserved.	Fac Med Broussais Hotel Dieu, INSERM, U729, F-75006 Paris, France; Hop Europeen Georges Pompidou, Ctr Reg Pharmacovigilance, Paris, France	Jaulent, MC (reprint author), Fac Med Broussais Hotel Dieu, INSERM, U729, 15 Rue Ecole Med, F-75006 Paris, France.	cedric.bousquet@spim.jussieu.fr; marie-christine.jaulent@spim.jussieu.fr					BATE A, 2003, THESIS UMEA U; Bate A, 1998, EUR J CLIN PHARMACOL, V54, P315, DOI 10.1007/s002280050466; BECHHOFER S, 2001, LNAI; Bousquet C, 2005, DRUG SAFETY, V28, P19, DOI 10.2165/00002018-200528010-00002; Brown EG, 1999, DRUG SAFETY, V20, P109, DOI 10.2165/00002018-199920020-00002; Brown EG, 2002, DRUG SAFETY, V25, P445, DOI 10.2165/00002018-200225060-00009; Cimino JJ, 1998, METHOD INFORM MED, V37, P394; DuMouchel W., 2001, P 7 ACM SIGKDD INT C, P67, DOI 10.1145/502512.502526; DuMouchel W, 1999, AM STAT, V53, P177, DOI 10.2307/2686093; Egberts ACG, 2002, DRUG SAFETY, V25, P453, DOI 10.2165/00002018-200225060-00010; Evans SJW, 2001, PHARMACOEPIDEM DR S, V10, P483, DOI 10.1002/pds.677; FRAM DM, 2003, SIGKDD 03 WASH DC; HAARSLEV V, 2001, P INT WORKSH DESCR L, V1, P132; Henegar C, 2004, ST HEAL T, V107, P626; Horrocks I., 2000, P 17 INT C AUT DED, P482; HORROCKS I, 1999, P 12 AUSTR JOINT C A; Lindquist M, 2000, DRUG SAFETY, V23, P533, DOI 10.2165/00002018-200023060-00004; Lussier YA, 1998, METHOD INFORM MED, V37, P161; Meyboom RHB, 2002, DRUG SAFETY, V25, P459, DOI 10.2165/00002018-200225060-00011; Rossi Mori A, 1998, Methods Inf Med, V37, P551; Szarfman A, 2002, DRUG SAFETY, V25, P381, DOI 10.2165/00002018-200225060-00001; van Puijenbroek EP, 2002, PHARMACOEPIDEM DR S, V11, P3, DOI 10.1002/pds.668; Yokotsuka M, 2000, INT J MED INFORM, V57, P139, DOI 10.1016/S1386-5056(00)00062-9	23	16	18	ELSEVIER IRELAND LTD	CLARE	ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND	1386-5056		INT J MED INFORM	Int. J. Med. Inform.	AUG	2005	74	7-8					563	571		10.1016/j.ijmedinf.2005.04.006		9	Computer Science, Information Systems; Health Care Sciences & Services; Medical Informatics	Computer Science; Health Care Sciences & Services; Medical Informatics	954VY	WOS:000231184500008	
J	Leroy, G; Rindflesch, TC				Leroy, G; Rindflesch, TC			Effects of information and machine learning algorithms on word sense disambiguation with small datasets	INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS			English	Article						word sense disambiguation; machine learning; naive Bayes; decision tree; neural network; UMLS	TERMS	Current approaches to word sense disambiguation use (and often combine) various machine learning techniques. Most refer to characteristics of the ambiguity and its surrounding words and are based on thousands of examples. Unfortunately, developing large training sets is burdensome, and in response to this challenge, we investigate the use of symbolic knowledge for small datasets. A naive Bayes classifier was trained for 15 words with 100 examples for each. Unified Medical Language System (UMLS) semantic types assigned to concepts found in the sentence and relationships between these semantic types form the knowledge base. The most frequent sense of a word served as the baseline. The effect of increasingly accurate symbolic knowledge was evaluated in nine experimental conditions. Performance was measured by accuracy based on 10-fold cross-validation. The best condition used only the semantic types of the words in the sentence. Accuracy was then on average 10% higher than the baseline; however, it varied from 8% deterioration to 29% improvement. To investigate this large variance, we performed several follow-up evaluations, testing additional algorithms (decision tree and neural network), and gold standards (per expert), but the results did not significantly differ. However, we noted a trend that the best disambiguation was found for words that were the least troublesome to the human evaluators. We conclude that neither algorithm nor individual human behavior cause these large differences, but that the structure of the UMLS Metathesaurus (used to represent senses of ambiguous words) contributes to inaccuracies in the gold standard, leading to varied performance of word sense disambiguation techniques. (C) 2005 Elsevier Ireland Ltd. All rights reserved.	Claremont Grad Univ, Sch Informat Sci, Claremont, CA 91711 USA; Natl Lib Med, Bethesda, MD USA	Leroy, G (reprint author), Claremont Grad Univ, Sch Informat Sci, 130 E 9th St, Claremont, CA 91711 USA.	gondy.leroy@cgu.edu					ARONSON AR, 2001, AMIA S; FLORIAN R, 2002, NATURAL LANGUAGE ENG, V1, P1; Florian R., 2002, Natural Language Engineering, DOI 10.1017/S1351324902002978; Ginter F, 2004, J MACH LEARN RES, V5, P605; HAN H, 2004, 4 ACM IEEE CS JOINT; HATZIVASSILOGLO.V, 2001, BIOINFORMATICS, V1, P1; Hoste V., 2002, Natural Language Engineering, DOI 10.1017/S1351324902003005; Humphreys BL, 1998, J AM MED INFORM ASSN, V5, P1; Ide N, 1998, COMPUT LINGUIST, V24, P1; INKPEN DZ, 2003, 4 C INT TEXT PROC CO; LEROY G, 2004, MEDINFO SAN FRANC; Liu HF, 2002, J AM MED INFORM ASSN, V9, P621, DOI 10.1097/jamia.M1101; Liu HF, 2001, J BIOMED INFORM, V34, P249, DOI 10.1006/jbin.2001.1023; Magnini B., 2002, Natural Language Engineering, DOI 10.1017/S1351324902003029; McCray AT, 1993, ADV INFORMATION MANA, P45; MIHALCEA R, 1998, COL ACL 98 WIRJFSH U; MILLER GA, 1998, INTRO WORDNET ON LIN; MOONEY RJ, 1996, C EMP METH NAT LANG; PEDERSEN T, 1997, 2 C EMP METH NAT LAN; PEDERSEN T, 2001, 2 ANN M N AM CHAPT A; Ruch P, 2003, ARTIF INTELL MED, V29, P169, DOI 10.1016/S0933-3657(03)00052-6; RUCH P, 1999, AMIA S; Santamaria C, 2003, COMPUT LINGUIST, V29, P485, DOI 10.1162/089120103322711613; Schutze H, 1998, COMPUT LINGUIST, V24, P97; WEEBER M, 2001, AMIA S; Witten I. H., 2000, DATA MINING PRACTICA	26	17	17	ELSEVIER IRELAND LTD	CLARE	ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND	1386-5056		INT J MED INFORM	Int. J. Med. Inform.	AUG	2005	74	7-8					573	585		10.1016/j.ijmedinf.2005.03.013		13	Computer Science, Information Systems; Health Care Sciences & Services; Medical Informatics	Computer Science; Health Care Sciences & Services; Medical Informatics	954VY	WOS:000231184500009	
J	Bellotti, T; Luo, ZY; Gammerman, A; Van Delft, FW; Saha, V				Bellotti, T; Luo, ZY; Gammerman, A; Van Delft, FW; Saha, V			Qualified predictions for microarray and proteomics pattern diagnostics with confidence machines	INTERNATIONAL JOURNAL OF NEURAL SYSTEMS			English	Article; Proceedings Paper	5th International Conference on Intelligent Data Engineeing and Automated Learning	AUG, 2004	Exeter, ENGLAND			machine learning; microarray; proteomics; classification; confidence machine	GENE-EXPRESSION; OVARIAN-CANCER; CLASSIFICATION; DISCOVERY; LEUKEMIA	We focus on the problem of prediction with confidence and describe a recently developed learning algorithm called transductive confidence machine for making qualified region predictions. Its main advantage, in comparison with other classifiers, is that it is well-calibrated, with number of prediction errors strictly controlled by a given predefined confidence level. We apply the transductive confidence machine to the problems of acute leukaemia and ovarian cancer prediction using microarray and proteomics pattern diagnostics, respectively. We demonstrate that the algorithm performs well, yielding well-calibrated and informative predictions whilst maintaining a high level of accuracy.	Univ London Royal Holloway & Bedford New Coll, Comp Learning Res Ctr, Egham TW20 0EX, Surrey, England; Canc Res UK, Childrens Canc Grp, John Vane Sci Ctr, London EC1M 6BQ, England	Bellotti, T (reprint author), Univ London Royal Holloway & Bedford New Coll, Comp Learning Res Ctr, Egham TW20 0EX, Surrey, England.	tony@cs.rhul.ac.uk; zhiyuan@cs.rhul.ac.uk; alex@cs.rhul.ac.uk; Frederik.Vandelft@cancer.org.uk; Vaskar.Saha@cancer.org.uk					AMBROISE C, 2002, P NATL ACAD SCI USA, V99, P3562; Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765; BAGGERLY KA, 2004, BIOINFORMATICS, V20, P77; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Braga-Neto UM, 2004, BIOINFORMATICS, V20, P374, DOI 10.1093/bioinformatics/btg419; Gammerman A, 2002, THEOR COMPUT SCI, V287, P209, DOI 10.1016/S0304-3975(02)00100-7; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; KORB KB, 1999, P 16 INT JOINT C ART, P73; LILLEYMAN JS, 2000, CHILDHOOD LEUKAEMIA; Luo ZY, 2004, LECT NOTES COMPUT SC, V3177, P46; Nouretdinov I, 2001, LECT NOTES ARTIF INT, V2111, P337; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; PROEDROU K, 2002, P 13 EUR C MACH LEAR; Read C. B., 1986, ENCY STATISTICAL SCI, V7, P210; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; VANDELFT FW, 2003, BRIT J CANCER, V88, P54; VANDELFT FW, 2003, BLOOD, V102, P365; Vapnik VN, 1998, STAT LEARNING THEORY; Vovk V., 2002, Proceedings 43rd Annual IEEE Symposium on Foundations of Computer Science, DOI 10.1109/SFCS.2002.1181895; Vovk V., 2005, ALGORITHMIC LEARNING; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6; Zhu W, 2003, P NATL ACAD SCI USA, V100, P14666, DOI 10.1073/pnas.2532248100	24	16	18	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0129-0657		INT J NEURAL SYST	Int. J. Neural Syst.	AUG	2005	15	4					247	258		10.1142/S012906570500027X		12	Computer Science, Artificial Intelligence	Computer Science	986OS	WOS:000233460200003	
J	Al-Shahib, A; Breitling, R; Gilbert, D				Al-Shahib, A; Breitling, R; Gilbert, D			FrankSum: New feature selection method for protein function prediction	INTERNATIONAL JOURNAL OF NEURAL SYSTEMS			English	Article; Proceedings Paper	5th International Conference on Intelligent Data Engineeing and Automated Learning	AUG, 2004	Exeter, ENGLAND			feature selection; protein function; sequence features; machine learning	INTRINSICALLY UNSTRUCTURED PROTEINS; DISORDER PREDICTION	In the study of in silico functional genomics, improving the performance of protein function prediction is the ultimate goal for identifying proteins associated with defined cellular functions. The classical prediction approach is to employ pairwise sequence alignments. However this method often faces difficulties when no statistically significant homologous sequences are identified. An alternative way is to predict protein function from sequence-derived features using machine learning. In this case the choice of possible features which can be derived from the sequence is of vital importance to ensure adequate discrimination to predict function. In this paper we have successfully selected biologically significant features for protein function prediction. This was performed using a new feature selection method (FrankSum) that avoids data distribution assumptions, uses a data independent measurement (p-value) within the feature, identifies redundancy between features and uses an appropiate ranking criterion for feature selection. We have shown that classifiers generated from features selected by FrankSum outperforms classifiers generated from full feature sets, randomly selected features and features selected from the Wrapper method. We have also shown the features are concordant across all species and top ranking features are biologically informative. We conclude that feature selection is vital for successful protein function prediction and FrankSum is one of the feature selection methods that can be applied successfully to such a domain.	Univ Glasgow, Dept Comp Sci, Bioinformat Res Ctr, Glasgow G12 8QQ, Lanark, Scotland; Univ Glasgow, Inst Biomed Life Sci, Glasgow G12 8QQ, Lanark, Scotland	Al-Shahib, A (reprint author), Univ Glasgow, Dept Comp Sci, Bioinformat Res Ctr, Glasgow G12 8QQ, Lanark, Scotland.	alshahib@dcs.gla.ac.uk; R.Breitling@bio.gla.ac.uk; drg@dcs.gla.ac.uk	Gilbert, David/G-1432-2011				ALSHAHIB A, IN PRESS APPL BIOINF; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; APPICE A, 2004, P INT C MACH LEARN, P33; BAMBER D, 1975, J MATH PSYCHOL, V12, P387, DOI 10.1016/0022-2496(75)90001-2; BISHOP C, 1993, NEURAL NETWORKS PATT; BOESCH C, 1978, EUR J BIOCHEM, V91, P209, DOI 10.1111/j.1432-1033.1978.tb20953.x; Duda R. O., 2001, PATTERN CLASSIFICATI; Dyson HJ, 2005, NAT REV MOL CELL BIO, V6, P197, DOI 10.1038/nrm1589; GABRILOVICH E, 2004, ICML 04 2U INT C MAC; Gribskov M, 1996, COMPUT CHEM, V20, P25, DOI 10.1016/S0097-8485(96)80004-0; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Iakoucheva LM, 2002, J MOL BIOL, V323, P573, DOI 10.1016/S0022-2836(02)00969-5; Kendall M., 1990, RANK CORRELATION MET; KOTSIANTIS SB, 2004, IJSIT LECT NOT INT C, V1, P153; Krogh A, 2001, J MOL BIOL, V305, P567, DOI 10.1006/jmbi.2000.4315; Lakoucheva L, 2004, NUCLEIC ACIDS RES, V32, P1037; Lehman E., 1975, NONPARAMETRICS STAT; Linding R, 2003, STRUCTURE, V11, P1453, DOI 10.1016/j.str.2003.10.002; Macqueen J. B., 1967, P 5 BERK S MATH STAT, P281; Ouali M, 2000, PROTEIN SCI, V9, P1162; RILEY M, 1993, MICROBIOL REV, V57, P862; Romero P, 2000, ARTIF INTELL REV, V14, P447, DOI 10.1023/A:1006678623815; SAEYS Y, 2003, BIOINFORMATICS, V19, DOI UNSP 179II-188II; Tompa P, 2002, TRENDS BIOCHEM SCI, V27, P527, DOI 10.1016/S0968-0004(02)02169-2; van Erp M., 2000, P 7 INT WORKSH FRONT, P443; Whitley E, 2002, CRIT CARE, V6, P509, DOI 10.1186/cc1820; WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968; Wright PE, 1999, J MOL BIOL, V293, P321, DOI 10.1006/jmbi.1999.3110; *STDGEN, AL NAT LAB BIOSC DIV	29	13	13	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0129-0657		INT J NEURAL SYST	Int. J. Neural Syst.	AUG	2005	15	4					259	275		10.1142/S0129065705000281		17	Computer Science, Artificial Intelligence	Computer Science	986OS	WOS:000233460200004	
J	Huang, HD; Horng, JT; Wu, LC; Fang, SF				Huang, HD; Horng, JT; Wu, LC; Fang, SF			Discovering common structural motifs of ribosomal RNA secondary structures in prokaryotes	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS			English	Article						SSU 16 rRNA; motifs; data mining	PHYLOGENETIC ANALYSIS; 16 S; NUCLEOTIDES; SEQUENCE; DATABASE; TREES; LOOPS	Certain structural motifs, like tetra-loops, in ribosomal RNA are known to functionally implicate in virtually every aspect of protein synthesis. Ribosomal RNA molecules were also widely used as a tool in molecular evolutionary studies because of their ubiquity, size and low evolutionary rate. In this study, we adapt a data mining approach to discover common structural motifs, and then we use a machine learning approach to identify discriminating CSMs from groups of organisms. Finally, we construct phylogeneitc trees to investigate the evolution of ribosomal RNA by serving the CSMs discovered as targets, which are used to estimate the evolutionary relatedness between organisms. The aim of this study is to discover common structural motifs (CSMs), i.e., those single-strain regions shared in ribosomal RNA secondary structures by several organisms, which are related to specific domains or functions. We discover a set of common structural motifs from several data sets of Archaea and Bacteria. Significant CSMs are then induced by a decision tree. Furthermore, phylogenetic trees are constructed based on CSMs and primary sequences of SSU 16 S ribosomal RNA.	Natl Chiao Tung Univ, Dept Biol Sci & Technol, Inst Bioinformat, Hsinchu 300, Taiwan; Natl Cent Univ, Dept Life Sci, Dept Comp Sci & Informat Engn, Chungli 320, Taiwan	Huang, HD (reprint author), Natl Chiao Tung Univ, Dept Biol Sci & Technol, Inst Bioinformat, Hsinchu 300, Taiwan.	bryan@mail.nctu.edu.tw; horng@db.csie.ncu.edu; richard@db.csie.ncu.edu.tw; sffang@db.csie.ncu.edu.tw	Hsu, Sheng-Da/F-4576-2010				AGRAWAL R, 1997, 9839 RJ; Agrawal R., 1995, P 11 INT C DAT ENG T; EGEBJERG J, 1990, RIBOSOME, P168; FEIGENBAUM EA, 1988, RISE EXPERT COMPANY; FELSENSTEIN J, 1995, PHYLOGENETIC INFEREN; FRESCO JR, 1960, NATURE, V188, P98, DOI 10.1038/188098a0; GUTELL R, J MOL BIOL, V300, P791; GUTELL RR, 1994, NUCLEIC ACIDS RES, V22, P3502, DOI 10.1093/nar/22.17.3502; Han Jiawei, DATA MINING CONCEPTS; NOLLER HF, 1990, RIBOSOME, P73; Jain A.K., 1988, ALGORITHMS CLUSTERIN; KANGSEOK L, 1997, J MOL BIOL, V269, P732; Leontis NB, 1998, J MOL BIOL, V283, P571, DOI 10.1006/jmbi.1998.2106; Mankin AS, 1997, J MOL BIOL, V274, P8, DOI 10.1006/jmbi.1997.1387; Merryman C, 1999, J MOL BIOL, V285, P97, DOI 10.1006/jmbi.1998.2242; Morosyuk SV, 2000, J MOL BIOL, V300, P113, DOI 10.1006/jmbi.2000.3852; OLSEN GJ, 1987, COLD SPRING HARB SYM, V52, P825; Phillips A, 2000, MOL PHYLOGENET EVOL, V16, P317, DOI 10.1006/mpev.2000.0785; RAUE HA, 1990, RIBOSOME, P217; Van de Peer Y, 1999, NUCLEIC ACIDS RES, V27, P179, DOI 10.1093/nar/27.1.179; SAITOU N, 1987, MOL BIOL EVOL, V4, P406; Swofford David L., 1996, P407; VandePeer Y, 1996, NUCLEIC ACIDS RES, V24, P3381, DOI 10.1093/nar/24.17.3381; Van de Peer Y, 2000, NUCLEIC ACIDS RES, V28, P175, DOI 10.1093/nar/28.1.175; Williams DJ, 2000, J MOL BIOL, V297, P1045, DOI 10.1006/jmbi.2000.3623; WOESE CR, 1990, P NATL ACAD SCI USA, V87, P8467, DOI 10.1073/pnas.87.21.8467; WOESE CR, 1993, RNA WORLD; WUINLAN JR, 1993, C4 5 PROGRAMS MACHIN; Yang ZH, 1996, J MOL EVOL, V42, P294, DOI 10.1007/BF02198856	29	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-2130		INT J ARTIF INTELL T	Int. J. Artif. Intell. Tools	AUG	2005	14	4					621	639		10.1142/S0218213005002296		19	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	986SE	WOS:000233469200005	
J	Kuramochi, M; Karypis, G				Kuramochi, M; Karypis, G			Gene classification using expression profiles: A feasibility study	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS			English	Article						gene classification; expression profiles; SVM; k-NN	PROTEIN SEQUENCES; YEAST GENOME; DATABASE; MIPS	As various genome sequencing projects have already been completed or are near completion, genome researchers are shifting their focus to functional genomics. Functional genomics represents the next phase, that expands the biological investigation to studying the functionality of genes of a single organism as well as studying and correlating the functionality of genes across many different organisms. Recently developed methods for monitoring genome-wide mRNA expression changes hold the promise of allowing us to inexpensively gain insights into the function of unknown genes. In this paper we focus on evaluating the feasibility of using supervised machine learning methods for determining the function of genes based solely on their expression profiles. We experimentally evaluate the performance of traditional classification algorithms such as support vector machines and k-nearest neighbors on the yeast genome, and present new approaches for classification that improve the overall recall with moderate reductions in precision. Our experiments show that the accuracies achieved for different classes varies dramatically. In analyzing these results we show that the achieved accuracy is highly dependent on whether or not the genes of that class were significantly active during the various experimental conditions, suggesting that gene expression profiles can become a viable alternative to sequence similarity searches provided that the genes are observed under a wide range of experimental conditions.	Univ Minnesota, Dept Comp Sci & Engn, Army HPC Res Ctr, Digital Technol Ctr, Minneapolis, MN 55455 USA	Kuramochi, M (reprint author), Univ Minnesota, Dept Comp Sci & Engn, Army HPC Res Ctr, Digital Technol Ctr, 4-192 EE CS Bldg,200 Union St SE, Minneapolis, MN 55455 USA.	kuram@cs.umn.edu; karypis@cs.umn.edu					Ashburner M, 2000, NAT GENET, V25, P25; Breiman L, 1984, CLASSIFICATION REGRE; BROWN MPS, 1999, UCSCCRL9909 DEP COMP; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Cameron-Jones R.M, 1994, SIGART B, V5, P33; Cohen W. W., 1995, P 12 INT C MACH LEAR, P115; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Eisen M, CLUSTER ANAL DISPLAY; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; FODOR SPA, 1993, NATURE, V364, P555, DOI 10.1038/364555a0; Goldberg DE, 1989, GENETIC ALGORITHMS S; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hieter P, 1997, SCIENCE, V278, P601, DOI 10.1126/science.278.5338.601; HVIDSTEN TR, 2001, P PAC S BIOC; Iyer VR, 1999, SCIENCE, V283, P83, DOI 10.1126/science.283.5398.83; Joachims T., 1999, ADV KERNEL METHODS S; MCCALLUM AK, 1996, TOOLKIT STAT LANGUAG; Mewes HW, 1997, NUCLEIC ACIDS RES, V25, P28, DOI 10.1093/nar/25.1.28; Mewes HW, 1998, NUCLEIC ACIDS RES, V26, P33, DOI 10.1093/nar/26.1.33; Mewes HW, 1997, NATURE, V387, P7; Mewes HW, 1999, NUCLEIC ACIDS RES, V27, P44, DOI 10.1093/nar/27.1.44; Mitchell T., 1996, MACHINE LEARNING; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Sarwar B., 2000, P 2 ACM C EL COMM, P158, DOI DOI 10.1145/352871.352887; SARWAR BM, 2000, WEBKDD 2000 WORKSH N; SARWAR BM, 2001, P WWW10; Schena M., 1995, SCIENCE, V270; Taylor C., 1994, MACHINE LEARNING NEU; Vapnik V. N, 1995, NATURE STAT LEARNING; Vapnik VN, 1998, STAT LEARNING THEORY; VELCULESCU VE, 1995, SCIENCE, V270; Weiss S. M., 1991, COMPUTER SYSTEMS LEA; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256	35	10	16	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-2130		INT J ARTIF INTELL T	Int. J. Artif. Intell. Tools	AUG	2005	14	4					641	660		10.1142/S0218213005002302		20	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	986SE	WOS:000233469200006	
J	Cleveland, WS				Cleveland, WS			Learning from data: Unifying statistics and computer science	INTERNATIONAL STATISTICAL REVIEW			English	Article; Proceedings Paper	Conference on the Vital Role of Statistical Science in Assuring National Prosperity	AUG 29-31, 2004	Daejon, SOUTH KOREA	Korean Stat Soc, Korea Natl Stat Off		data mining; machine learning; data visualization; exploratory data analysis; computing with data; statistical model buildinG		Research in the data-oriented areas of computer science is contributing a new wave of theory and tools for learning from data. Some of the research areas complement those in statistics and others overlap. While the research topics of the two fields are not the same, the goals of the research are identical-to enhance theory, methods, models, and systems for the study of data. Unification-close collaboration in research, in teaching, and in applications-would greatly enhance new developments in learning from data.	Purdue Univ, Dept Stat, W Lafayette, IN 47907 USA; Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA	Cleveland, WS (reprint author), Purdue Univ, Dept Stat, W Lafayette, IN 47907 USA.	wsc@purdue.edu						0	1	1	INT STATISTICAL INST	VOORBURG	428 PRINSES BEATRIXLAAN, 2270 AZ VOORBURG, NETHERLANDS	0306-7734		INT STAT REV	Int. Stat. Rev.	AUG	2005	73	2					217	221				5	Statistics & Probability	Mathematics	954WD	WOS:000231185000019	
J	Kell, DB				Kell, DB			Metabolomics, machine learning and modelling in systems biology: Towards an understanding of the language of cells	JOURNAL OF BIOTECHNOLOGY			English	Meeting Abstract	12th European Congress on Biotechnology (ECB 12)	AUG 21-24, 2005	Copenhagen, DENMARK				OPTIMIZATION; HYPOTHESIS		Univ Manchester, Sch Chem, Manchester M60 1QD, Lancs, England		dbk@manchester.ac.uk	Kell, Douglas/E-8318-2011				BRENNER S, 1980, NATURE          0605; BROWN M, 2005, METABOLOMICS, V1, P35; Goodacre R, 2004, TRENDS BIOTECHNOL, V22, P245, DOI 10.1016/j.tibtech.2004.03.007; Ihekwaba A. E. C., 2004, Systems Biology, V1, P93, DOI 10.1049/sb:20045009; Kell DB, 2004, CURR OPIN MICROBIOL, V7, P296, DOI 10.1016/j.mib.2004.04.012; Kell DB, 2004, BIOESSAYS, V26, P99, DOI 10.1002/bies.10385; KELL DB, IN PRESS NAT REV MIC; King RD, 2004, NATURE, V427, P247, DOI 10.1038/nature02236; Mendes P, 1998, BIOINFORMATICS, V14, P869, DOI 10.1093/bioinformatics/14.10.869; Nelson DE, 2004, SCIENCE, V306, P704, DOI 10.1126/science.1099962; O'Hagan S, 2005, ANAL CHEM, V77, P290, DOI 10.1021/ac049146x	11	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0168-1656		J BIOTECHNOL	J. Biotechnol.	AUG	2005	118			1			S5	S5				1	Biotechnology & Applied Microbiology	Biotechnology & Applied Microbiology	954ZV	WOS:000231195200015	
J	Fernandez, F; Borrajo, D; Parker, LE				Fernandez, F; Borrajo, D; Parker, LE			A reinforcement learning algorithm in cooperative multi-robot domains	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS			English	Article						reinforcement learning; function approximation; state space discretizations; collaborative multi-robot domains	CLASSIFIERS	Reinforcement learning has been widely applied to solve a diverse set of learning tasks, from board games to robot behaviours. In some of them, results have been very successful, but some tasks present several characteristics that make the application of reinforcement learning harder to define. One of these areas is multi-robot learning, which has two important problems. The first is credit assignment, or how to define the reinforcement signal to each robot belonging to a cooperative team depending on the results achieved by the whole team. The second one is working with large domains, where the amount of data can be large and different in each moment of a learning step. This paper studies both issues in a multi-robot environment, showing that introducing domain knowledge and machine learning algorithms can be combined to achieve successful cooperative behaviours.	Univ Carlos III Madrid, Madrid 28911, Spain; Univ Tennessee, Knoxville, TN 37996 USA	Fernandez, F (reprint author), Univ Carlos III Madrid, Avda Univ 30, Madrid 28911, Spain.	ffernand@inf.uc3m.es; dborrajo@ia.uc3m.es; parker@cs.utk.edu					Aha D.W., 1997, LAZY LEARNING; Balch Tucker, 2002, ROBOT TEAMS DIVERSIT; Bellman R. E., 1957, DYNAMIC PROGRAMMING; Bertsekas D. P., 1996, NEURODYNAMIC PROGRAM; Duda R.O, 1973, PATTERN CLASSIFICATI; FERNANDEZ F, 2002, P EUR C ART INT ECAI; Fernandez F, 2004, J HEURISTICS, V10, P431, DOI 10.1023/B:HEUR.0000034715.70386.5b; Fernandez F., 2001, International Journal of Robotics & Automation, V16; Fernandez F, 2000, LECT NOTES ARTIF INT, V1856, P292; Fernandez F, 2002, COMPUT INFORM, V21, P205; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237; MAHADEVAN S, 1992, ARTIF INTELL, V55, P311, DOI 10.1016/0004-3702(92)90058-6; Moore AW, 1995, MACH LEARN, V21, P199, DOI 10.1007/BF00993591; Ng A. Y., 2000, P 17 INT C MACH LEAR; Parker L. E., 2000, DISTRIBUTED AUTONOMO, V4, P391; Parker LE, 2002, AUTON ROBOT, V12, P231, DOI 10.1023/A:1015256330750; Puterman ML, 1994, MARKOV DECISION PROC; Santamaria J., 1998, ADAPT BEHAV, V6, P163; Smart W. D., 2002, THESIS BROWN U PROVI; STONE P, 2000, AUTONOM ROBOTS, V8; TESAURO G, 1992, MACH LEARN, V8, P257, DOI 10.1007/BF00992697; Tsitsiklis JN, 1996, MACH LEARN, V22, P59, DOI 10.1007/BF00114724; Watkins C. J. C. H., 1989, THESIS KINGS COLL CA	23	5	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0921-0296		J INTELL ROBOT SYST	J. Intell. Robot. Syst.	AUG	2005	43	2-4					161	174		10.1007/s10846-005-5137-x		14	Computer Science, Artificial Intelligence; Robotics	Computer Science; Robotics	996VZ	WOS:000234204700003	
J	Shriberg, LD; Barbara, L; Tomblin, J; McSweeny, JL; Karlsson, HB; Scheer, AR				Shriberg, LD; Barbara, L; Tomblin, J; McSweeny, JL; Karlsson, HB; Scheer, AR			Toward diagnostic and phenotype markers for genetically transmitted speech delay	JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH			English	Article						articulation; assessment; genetics; phenotype; phonology	DEVELOPMENTAL PHONOLOGICAL DISORDERS; S-VERTICAL-BAR; LANGUAGE IMPAIRMENT; NONWORD REPETITION; CHILDHOOD APRAXIA; FAMILIAL AGGREGATION; SOUND NORMALIZATION; CLINICAL MARKER; OTITIS-MEDIA; RISK-FACTORS	Converging evidence supports the hypothesis that the most common subtype of childhood speech sound disorder (SSD) of currently unknown origin is genetically. transmitted. We report the first findings toward a set of diagnostic markers to, differentiate this proposed etiological subtype (provisionally termed speech, delay-genetic) from other proposed subtypes of SSD of unknown origin. Conversational speech samples from 72 preschool children with speech delay of. unknown origin from 3 research centers were selected from an audio archive. Participants differed on the number of biological, nuclear family members (0 or 2+) classified as positive for current and/or prior speech-language disorder. Although participants in the 2 groups were found to have similar speech competence, as indexed by their Percentage of Consonants Correct scores, their speech error patterns differed significantly in 3 ways. Compared with children who may have reduced genetic load for speech delay (no affected nuclear family members), children with possibly higher genetic load (2+ affected members) had (a) a significantly higher proportion of relative omission errors on the Late-8 consonants; (b) a significantly lower proportion of relative distortion errors on these consonants, particularly on the sibilant fricatives /s/, /z/, and /integral/; and (c) a significantly lower proportion of backed /s/ distortions, as assessed by both perceptual and acoustic methods. Machine learning routines identified a 3-part classification rule that included differential weightings of these variables. The classification rule had diagnostic accuracy value of 0.83 (95% confidence limits = 0.74 - 0.92), with positive and negative likelihood ratios of 9.6 (95% confidence limits = 3.1 - 29.9) and 0.40 (95% confidence limits = 0.24 - 0.68), respectively. The diagnostic accuracy findings are viewed as promising. The error pattern for this proposed subtype of SSD is viewed as consistent with the cognitive-linguistic processing deficits that have been reported for genetically transmitted verbal disorders.	Univ Wisconsin, Waisman Ctr, Phonol Project, Madison, WI 53705 USA; Case Western Reserve Univ, Cleveland, OH 44106 USA; Univ Iowa, Iowa City, IA USA	Shriberg, LD (reprint author), Univ Wisconsin, Waisman Ctr, Phonol Project, 1500 Highland Ave, Madison, WI 53705 USA.	shriberg@waisman.wisc.edu					Aguilar-Mediavilla EM, 2002, CLIN LINGUIST PHONET, V16, P573, DOI 10.1080/02699200210148394; Bishop DVM, 2004, AM J MED GENET B, V129B, P94, DOI 10.1002/ajmg.b.30065; Bortolini U, 2002, INT J LANG COMM DIS, V37, P77, DOI 10.1080/13682820110116758; Campbell TF, 2003, CHILD DEV, V74, P346, DOI 10.1111/1467-8624.7402002; Choudhury N, 2003, J SPEECH LANG HEAR R, V46, P261, DOI 10.1044/1092-4388(2003/021); Cohen J., 1988, STAT POWER ANAL BEHA; Conti-Ramsden G, 2001, J CHILD PSYCHOL PSYC, V42, P741, DOI 10.1111/1469-7610.00770; DAVIS BL, 1998, CLIN LINGUIST PHONET, V12, P26; Dollaghan C, 1998, J SPEECH LANG HEAR R, V41, P1136; Dunn L. M, 1981, PEABODY PICTURE VOCA; Eaves LJ, 2003, BEHAV GENET, V33, P1, DOI 10.1023/A:1021060430942; Felsenfeld S, 1997, J SPEECH LANG HEAR R, V40, P778; Fisher SE, 2005, APPL PSYCHOLINGUIST, V26, P111, DOI 10.1017/S0142716405050095; Fisher SE, 2003, ANNU REV NEUROSCI, V26, P57, DOI 10.1146/annurev.neuro.26.041002.131144; Flipsen P, 1999, J SPEECH LANG HEAR R, V42, P663; Hauner KKY, 2005, J SPEECH LANG HEAR R, V48, P635, DOI 10.1044/1092/4388(2005/044); Hosom JP, 2004, J MED SPEECH-LANG PA, V12, P167; KARLSSON HB, 2003, 12 U WIS MAD WAISM C; Karlsson HB, 2002, CLIN LINGUIST PHONET, V16, P403, DOI 10.1080/02699200210128954; KISELEV MV, 1994, ANN M ESCTAIC EUR SO; Law J, 2000, INT J LANG COMM DIS, V35, P165, DOI 10.1080/136828200247133; LEONARD LB, 1998, CHILDREN SPECIFIC LA; LEWIS BA, 1994, ANN CONV AM SPEECH L; MACDERMOT KD, 2004, ANN M AM SOC HUM GEN; Marcus GF, 2003, TRENDS COGN SCI, V7, P257, DOI 10.1016/S1364-6613(03)00104-9; McSweeny J. L., 2001, CLIN LINGUIST PHONET, V15, P631; Merikangas KR, 2003, SCIENCE, V302, P599, DOI 10.1126/science.1091468; MILENKOVIC P, 1996, CSPEECH VERSION 4 CO; Miller J., 1981, ASSESSING LANGUAGE P; Newbury DF, 2002, AM J HUM GENET, V70, P384; NEWBURY DF, 2002, CURRENT OPINIONS PED, V14, P679; Newcomer P., 1988, TEST LANGUAGE DEV PR; PENNINGTON BF, 2003, P 2002 CHILDH APR SP, P101; Plante E, 1996, J SPEECH HEAR RES, V39, P661; Rice ML, 1996, J SPEECH HEAR RES, V39, P1239; ROBERTS J, 2002, OTITIS MEDIA LANGUAG; Sackett DL HR, 1991, CLIN EPIDEMIOLOGY BA; SCHICK J, 2002, EUR HUM GEN C BERL G; Semel E., 1987, CLIN EVALUATION LANG; Shriberg L D, 1994, Clin Commun Disord, V4, P38; SHRIBERG LD, 1993, J SPEECH HEAR RES, V36, P105; Shriberg L. D., 2003, P 2002 CHILDH APR SP; Shriberg L. D., 2003, CLIN PHONETICS; Shriberg LD, 1997, J SPEECH LANG HEAR R, V40, P708; SHRIBERG LD, 1998, SPEECH LANGUAGE CONN, P73; Shriberg LD, 2003, CLIN LINGUIST PHONET, V17, P575, DOI 10.1080/0269920031000138141; SHRIBERG LD, 2002, 11 U WISC MAD WAISM; Shriberg LD, 1999, J SPEECH LANG HEAR R, V42, P1461; SHRIBERG LD, 1982, SPEECH LANGUAGE ADV, V8, P2; SHRIBERG LD, 1994, J SPEECH HEAR RES, V37, P1100; SHRIBERG LD, 1991, CLIN LINGUIST PHONET, V5, P225, DOI 10.3109/02699209108986113; SHRIBERG LD, 1994, J SPEECH HEAR RES, V37, P1127; Shriberg LD, 2003, CLIN LINGUIST PHONET, V17, P549, DOI 10.1080/0269920031000138123; Shriberg LD, 2003, CLIN LINGUIST PHONET, V17, P507, DOI 10.1080/0269920031000138169; Shriberg LD, 2003, CLIN LINGUIST PHONET, V17, P529, DOI 10.1080/0269920031000138132; SHRIBERG LD, 2004, INT ASS LOG PHON BRI; SHRIBERG LD, 1990, J SPEECH HEAR RES, V33, P627; SHRIBERG LD, 2003, ANN CONV AM SPEECH L; SHRIBERG LD, 1975, ANN CONV AM SPEECH H; Shriberg LD, 2001, PEPPER PROGRAMS EXAM; Shriberg LD, 1997, J SPEECH LANG HEAR R, V40, P723; SHRIBERG LD, 1994, J SPEECH HEAR RES, V37, P1151; Smith SD, 2005, J CHILD PSYCHOL PSYC, V46, P1057, DOI 10.1111/j.1469-7610.2005.01534.x; SMITH SD, 2003, 53 ANN M AM SOC HUM; Spitz RV, 1997, J SPEECH LANG HEAR R, V40, P990; Stein CM, 2004, AM J HUM GENET, V74, P283, DOI 10.1086/381562; Stromswold K, 2001, LANGUAGE, V77, P647, DOI 10.1353/lan.2001.0247; Stromswold K, 1998, HUM BIOL, V70, P297; Tager-Flusberg H, 1999, J SPEECH LANG HEAR R, V42, P1275; Tallal P, 2001, J SPEECH LANG HEAR R, V44, P1172, DOI 10.1044/1092-4388(2001/091); Tomblin JB, 1996, J SPEECH HEAR RES, V39, P1284; TOMBLIN JB, 1992, J SPEECH HEAR RES, V35, P832; Viding E, 2003, J SPEECH LANG HEAR R, V46, P1271, DOI 10.1044/1092-4388(2003/099); Weismer SE, 2000, J SPEECH LANG HEAR R, V43, P865; Whitehill TL, 2003, J SPEECH LANG HEAR R, V46, P451, DOI 10.1044/1092-4388(2003/037); WHITESIDE SP, 2001, PHONETICIAN, V84, P9; Wijsman EM, 2004, BEHAV GENET, V34, P51, DOI 10.1023/B:BEGE.0000009476.33020.b9; ZEESMAN S, 2004, ANN M AM SOC HUM GEN; *J HOPK U MCKUS NA, 2000, ONL MEND INH MAN	79	30	35	AMER SPEECH-LANGUAGE-HEARING ASSOC	ROCKVILLE	10801 ROCKVILLE PIKE, ROCKVILLE, MD 20852-3279 USA	1092-4388		J SPEECH LANG HEAR R	J. Speech Lang. Hear. Res.	AUG	2005	48	4					834	852		10.1044/1092-4388(2005/058)		19	Audiology & Speech-Language Pathology; Linguistics; Rehabilitation	Audiology & Speech-Language Pathology; Linguistics; Rehabilitation	993SI	WOS:000233974900010	
J	Hamza, M; Larocque, D				Hamza, M; Larocque, D			An empirical comparison of ensemble methods based on classification trees	JOURNAL OF STATISTICAL COMPUTATION AND SIMULATION			English	Article						bagging; boosting; arcing; random forest (RF); classification tree; CART; noise; linear combination of variables; splitting rule; Gini; entropy; twoing	ALGORITHMS	In this paper, we perform an empirical comparison of the classification error of several ensemble methods based on classification trees. This comparison is performed by using 14 data sets that are publicly available and that were used by Lim, Loh and Shih [Lim, T., Loh, W. and Shih, Y.-S., 2000, A comparison of prediction accuracy, complexity, and training time of thirty-three old and new classification algorithms. Machine Learning, 40, 203-228.]. The methods considered are a single tree, Bagging, Boosting (Arcing) and random forests (RF). They are compared from different perspectives. More precisely, we look at the effects of noise and of allowing linear combinations in the construction of the trees, the differences between some splitting criteria and, specifically for RF, the effect of the number of variables from which to choose the best split at each given node. Moreover, we compare our results with those obtained by Lim et al. [Lim, T., Loh, W. and Shih, Y-S., 2000, A comparison of prediction accuracy, complexity, and training time of thirty-three old and new classification algorithms. Machine Learning, 40, 203-228.]. In this study, the best overall results are obtained with RF. In particular, RF are the most robust against noise. The effect of allowing linear combinations and the differences between splitting criteria are small on average, but can be substantial for some data sets.	HEC Montreal, Dept Management Sci, Montreal, PQ H3T 2A7, Canada	Larocque, D (reprint author), HEC Montreal, Dept Management Sci, 3000 Chemin Cote Sainte Catherine, Montreal, PQ H3T 2A7, Canada.	denis.larocque@hec.ca					Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P41, DOI 10.1007/BF00117831; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Freund Y, 2001, MACH LEARN, V43, P293, DOI 10.1023/A:1010852229904; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; Maclin R., 1999, J ARTIFICIAL INTELLI, V11, P169; Meir R, 2002, LECT NOTES ARTIF INT, V2600, P118; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; SERVEDIO RA, 2001, P 14 ANN C COMP LEAR, P472	15	19	19	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0094-9655		J STAT COMPUT SIM	J. Stat. Comput. Simul.	AUG	2005	75	8					629	643		10.1080/00949650410001729472		15	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	962AD	WOS:000231702500003	
J	Delany, SJ; Cunningham, P; Tsymbal, A; Coyle, L				Delany, SJ; Cunningham, P; Tsymbal, A; Coyle, L			A case-based technique for tracking concept drift in spam filtering	KNOWLEDGE-BASED SYSTEMS			English	Article; Proceedings Paper	AI-2004 Conference/24th SGAI International Conference on Innovative Techniques and Applications of Artificial Intell igence	DEC 12-15, 2004	Cambridge, ENGLAND	Brithish Comp Soc Specialist Grp Artificial Intelligence		concept drift; case-based reasoning; spam filtering	CONTEXT	Spam filtering is a particularly challenging machine learning task as the data distribution and concept being learned changes over time. It exhibits a particularly awkward form of concept drift as the change is driven by spammers wishing to circumvent spam filters. In this paper we show that lazy learning techniques are appropriate for such dynamically changing contexts. We present a case-based system for spam filtering that can learn dynamically. We evaluate its performance as the case-base is updated with new cases. We also explore the benefit of periodically redoing the feature selection process to bring new features into play. Our evaluation shows that these two levels of model update are effective in tracking concept drift. (c) 2005 Published by Elsevier B.V.	Dublin Inst Technol, Dublin 8, Ireland; Univ Dublin Trinity Coll, Coll Green, Dublin 2, Ireland	Delany, SJ (reprint author), Dublin Inst Technol, Kevin St, Dublin 8, Ireland.	Sarahjane.Delany@dit.ie					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ANDROUTSOPOULOS I, 2004, 20042 NCSR; Androutsopoulos I., 2000, P WORKSH MACH LEARN, P9; ANDROUTSOPOULOS I, 2000, 4 PKDD WORKSH MACH L; Carreras X., 2001, P 4 INT C REC ADV NA; CUNNINGHAM P, 2003, ICCBR 03 WORKSH LONG; DELANY SJ, 2004, P 7 EUR C CAS BAS RE, P128; DELANY SJ, 2004, P 15 ART INT COGN SC; Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; Gee K.R., 2003, P 2003 ACM S APPL CO, P460; Harries MB, 1998, MACH LEARN, V32, P101, DOI 10.1023/A:1007420529897; Hulten Geoff, 2001, P 7 ACM SIGKDD INT C, P97, DOI DOI 10.1145/502512.502529; Klinkenberg R., 2004, INTELLIGENT DATA ANA, V8; KOLCZ A, 2001, P TEXTDM 2001 IEEE I; KOLTER JZ, 2003, P 3 IEEE INT C DAT M, P123; Kubat M., 1994, OFAITR9427 AUSTR RES; LANQUILLON C, 1999, P 8 INT C INF KNOWL, P537; LENZ M, 1998, LNCS, V104; PANTEL P, 1998, LEARNING TEXT CATEGO, P95; Quinlan J. R., 1993, C4 5 PROGRAM MACHINE; Sahami M., 1998, AAAI WORKSH MAD WISC, P55; Sakkis G, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P44; SAKKIS G, 2004, INFORMATIN RETRIEVAL, V6, P49; Salganicoff M, 1997, ARTIF INTELL REV, V11, P133, DOI 10.1023/A:1006515405170; Schlimmer J. C., 1986, Machine Learning, V1, DOI 10.1007/BF00116895; SPIRA J, 2003, SPAM EMAIL ITS IMPAC; Stanley K. O., 2003, UTAITR03302 DEP COMP; Street W.N., 2001, P 7 ACM SIGKDD INT C, P377, DOI DOI 10.1145/502512.502568; Wang H., 2003, P 9 ACM SIGKDD INT C, P226, DOI DOI 10.1145/956750.956778; Widmer G., 1993, LNCS, V667, P227; Widmer G, 1996, MACH LEARN, V23, P69, DOI 10.1023/A:1018046501280; Yang Yiming, 1997, P 14 INT C MACH LEAR, P412	32	36	40	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051		KNOWL-BASED SYST	Knowledge-Based Syst.	AUG	2005	18	4-5					187	195		10.1016/j.knosys.2004.10.002		9	Computer Science, Artificial Intelligence	Computer Science	952DY	WOS:000230983600008	
J	Hohenner, M; Wachsmuth, S; Sagerer, G				Hohenner, M; Wachsmuth, S; Sagerer, G			Modelling expertise for structure elucidation in organic chemistry using Bayesian networks	KNOWLEDGE-BASED SYSTEMS			English	Article; Proceedings Paper	AI-2004 Conference/24th SGAI International Conference on Innovative Techniques and Applications of Artificial Intell igence	DEC 12-15, 2004	Cambridge, ENGLAND	Brithish Comp Soc Specialist Grp Artificial Intelligence		Bayesian networks; structure elucidation; NMR spectra	AUTOMATED STRUCTURE ELUCIDATION	The development of automated methods for chemical synthesis as well as for chemical analysis has inundated chemistry with huge amounts of experimental data. To refine them into information, the field of chemoinformatics applies techniques from artificial intelligence, pattern recognition and machine learning. A key task concerning organic chemistry is structure elucidation. NMR spectra have become accessible at low expenses of time and sample size, they also are predictable with good precision, and they are directly related to structural properties of the molecule. So the classical approach of ranking structure candidates by comparison of NMR spectra works well, but since the structural space is huge, more sophisticated approaches are in demand. Bayesian networks are promising in this concern, as they allow for contemplation in a dual way: provided an appropriate model, conclusions can be drawn from a given spectrum regarding the corresponding structure or vice versa, since the same interrelations hold in both directions. The development of such a model is documented, and first results are shown supporting the applicability of Bayesian networks to structure elucidation. (c) 2005 Elsevier B.V. All rights reserved.	Univ Bielefeld, Fac Technol, Appl Comp Sci Grp, D-4800 Bielefeld, Germany	Hohenner, M (reprint author), Univ Bielefeld, Fac Technol, Appl Comp Sci Grp, POB 100 131, D-4800 Bielefeld, Germany.	mhohenne@techfak.uni-bielefeld.de					Atkins P., 2001, ATKINS PHYS CHEM; BENECKE C, 1995, ANAL CHIM ACTA, V314, P141, DOI 10.1016/0003-2670(95)00291-7; BEYER H, 1996, HDB ORGANIC CHEM, P42; BILMES J, 2003, GRAPHICAL MODELS AUT; Borgelt C., 2002, GRAPHICAL MODELS MET; Bremser W., 1987, ANAL CHIM ACTA, V103, P355, DOI 10.1016/S0003-2670(01)83100-7; Elyashberg M. E., 1999, Laboratory Automation and Information Management, V34, DOI 10.1016/S1381-141X(99)00002-7; EWING DF, 1979, ORG MAGN RESONANCE, V12, P499, DOI 10.1002/mrc.1270120902; Funatsu K, 1996, J CHEM INF COMP SCI, V36, P190, DOI 10.1021/ci950152r; Jensen F., 1996, INTRO BAYESIAN NETWO; KLINGLER TM, 1994, PROTEIN SCI, V3, P1847; Meiler J, 2001, J CHEM INF COMP SCI, V41, P1535, DOI 10.1021/ci0102970; MEILER J, 2002, MATCH-COMMUN MATH CO, V45, P86; Pearl J., 1988, PROBABILISTIC REASON; Smyth P, 1997, PATTERN RECOGN LETT, V18, P1261, DOI 10.1016/S0167-8655(97)01050-7; Will M, 1996, J CHEM INF COMP SCI, V36, P221, DOI 10.1021/ci950092p	16	2	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051		KNOWL-BASED SYST	Knowledge-Based Syst.	AUG	2005	18	4-5					207	215		10.1016/j.knosys.2005.03.001		9	Computer Science, Artificial Intelligence	Computer Science	952DY	WOS:000230983600010	
J	Hennessy, K; Madden, MG; Conroy, J; Ryder, AG				Hennessy, K; Madden, MG; Conroy, J; Ryder, AG			An improved genetic programming technique for the classification of Raman spectra	KNOWLEDGE-BASED SYSTEMS			English	Article; Proceedings Paper	AI-2004 Conference/24th SGAI International Conference on Innovative Techniques and Applications of Artificial Intell igence	DEC 12-15, 2004	Cambridge, ENGLAND	Brithish Comp Soc Specialist Grp Artificial Intelligence		machine learning; genetic programming; neural networks; spectroscopy; Raman	TRANSFORM INFRARED-SPECTROSCOPY; LEAST-SQUARES METHODS; QUANTITATIVE-ANALYSIS; NEURAL-NETWORKS; IDENTIFICATION; REGRESSION	The aim of this study is to evaluate the effectiveness of genetic programming relative to that of more commonly-used methods for the identification of components within mixtures of materials using Raman spectroscopy. A key contribution of the genetic programming technique proposed in this research is that it explicitly aims to optimise the certainty levels associated with discovered rules, so as to minimize the chance of misclassification of future samples. (c) 2005 Elsevier B.V. All rights reserved.	Natl Univ Ireland Univ Coll Galway, Dept Informat Technol, Galway, Ireland; Natl Univ Ireland Univ Coll Galway, Dept Chem, Galway, Ireland	Hennessy, K (reprint author), Natl Univ Ireland Univ Coll Galway, Dept Informat Technol, Galway, Ireland.	hennessy@vega.it.nuigalway.ie; michael.madden@nuigalway.ie; jennifer.conroy@nuigalway.ie; alan.ryder@nuigalway.ie	Madden, Michael/C-7113-2011; Ryder, Alan /C-1297-2009				BANJATHAPANUM N, 1998, MEASUREMENT, V24, P1; Berthold M. R, 2003, INTELLIGENT DATA ANA; BRIERLEY P, 2004, VISUAL NEURAL DATA M; BULKIN BJ, 1991, CHEM ANAL, V114, P1; Ellis DI, 2002, APPL ENVIRON MICROB, V68, P2822, DOI 10.1128/AEM.68.6.2822-2828.2002; Estienne F, 2001, ANAL CHIM ACTA, V450, P123, DOI 10.1016/S0003-2670(01)01372-1; Ferraro J. R., 2003, INTRO RAMAN SPECTROS; Goodacre R, 2003, VIB SPECTROSC, V32, P33, DOI 10.1016/S0924-2031(03)00045-6; Goodacre R, 1996, FEMS MICROBIOL LETT, V140, P233, DOI 10.1111/j.1574-6968.1996.tb08342.x; KOZA JR, 1999, GENETIC PROGRAMMING, V2; Madden MG, 2003, P SOC PHOTO-OPT INS, V4876, P1130, DOI 10.1117/12.464039; Ryder AG, 2000, J RAMAN SPECTROSC, V31, P221, DOI 10.1002/(SICI)1097-4555(200003)31:3<221::AID-JRS518>3.0.CO;2-5; SCHULZE HG, 1995, J NEUROSCI METH, V56, P155, DOI 10.1016/0165-0270(94)00118-Z; SHAVER JM, 2001, HDB RAMAN SPECTROSCO, V28; STATSOFT INC., EL STAT TXB; Taylor J, 1998, FEMS MICROBIOL LETT, V160, P237, DOI 10.1111/j.1574-6968.1998.tb12917.x; Witten I. H., 2000, DATA MINING PRACTICA; Yang HS, 2003, ANAL CHIM ACTA, V489, P125, DOI 10.1016/S0003-2670(03)00726-8	18	3	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051		KNOWL-BASED SYST	Knowledge-Based Syst.	AUG	2005	18	4-5					217	224		10.1016/j.knosys.2004.10.001		8	Computer Science, Artificial Intelligence	Computer Science	952DY	WOS:000230983600011	
J	[Anonymous]				[Anonymous]			New machine learning approaches for classification of mass spectrometry database search results	MOLECULAR & CELLULAR PROTEOMICS			English	Meeting Abstract																	0	0	0	AMER SOC BIOCHEMISTRY MOLECULAR BIOLOGY INC	BETHESDA	9650 ROCKVILLE PIKE, BETHESDA, MD 20814-3996 USA	1535-9476		MOL CELL PROTEOMICS	Mol. Cell. Proteomics	AUG	2005	4	8		2			S450	S450				1	Biochemical Research Methods	Biochemistry & Molecular Biology	958KW	WOS:000231446100049	
J	Wang, SJ; Lai, JL				Wang, SJ; Lai, JL			Geometrical learning, descriptive geometry, and biomimetic pattern recognition	NEUROCOMPUTING			English	Article						information geometry; high-dimensional descriptive geometry; biomimetic pattern recognition; geometry learning; RBF network; support vector machine		Studies on learning problems from geometry perspective have attracted an ever increasing attention in machine learning, leaded by achievements on information geometry. This paper proposes a different geometrical learning from the perspective of high-dimensional descriptive geometry. Geometrical properties of high-dimensional structures underlying a set of samples are learned via successive projections from the higher dimension to the lower dimension until two-dimensional Euclidean plane, under guidance of the established properties and theorems in high-dimensional descriptive geometry. Specifically, we introduce a hyper sausage like geometry shape for learning samples and provides a geometrical learning algorithm for specifying the hyper sausage shapes, which is then applied to biomimetic pattern recognition. Experimental results are presented to show that the proposed approach outperforms three types of support vector machines with either a three degree polynomial kernel or a radial basis function kernel, especially in the cases of high-dimensional samples of a finite size. (c) 2005 Elsevier B.V. All rights reserved.	Chinese Acad Sci, Inst Semicond, Artificial Neural Networks Lab, Beijing 100083, Peoples R China	Lai, JL (reprint author), Chinese Acad Sci, Inst Semicond, Artificial Neural Networks Lab, Beijing 100083, Peoples R China.	Ldstt@red.semi.ac.cn					Amari S., 2000, METHODS INFORM GEOME; Boser B., 1992, 5 ANN ACM WORKSH COL, P144; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Csiszar I., 1984, STATISTICS DECISIO S, V1, P205; Duda R.O, 1973, PATTERN CLASSIFICATI; FEJES T, 1972, EBENE KUGEL RAUM; HOPP TH, 2006, 5831 NISTIR NAT I ST; Hsiang W.Y., 1993, INT J MATH, V4, P739, DOI 10.1142/S0129167X93000364; Knerr S., 1990, NEUROCOMPUTING ALGOR; Rao C.R., 1945, Bulletin of the Calcutta Mathematical Society, V37; Sylvester J.J., 1860, PHILOS MAG SER, VXX, P203; Vapnik VN, 1998, STAT LEARNING THEORY; Wang DZ, 2001, RARE METAL MAT ENG, V30, P1; Wang Shou-jue, 2002, Acta Electronica Sinica, V30; Wang SJ, 2004, CHINESE J ELECTRON, V13, P373; Xu L, 1998, NEUROCOMPUTING, V19, P223, DOI 10.1016/S0925-2312(97)00091-X; Xu L, 2004, IEEE T NEURAL NETWOR, V15, P885, DOI 10.1109/TNN.2004.828767	17	34	41	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	AUG	2005	67						9	28		10.1016/j.neucom.2004.11.034		20	Computer Science, Artificial Intelligence	Computer Science	958HW	WOS:000231436300002	
J	Knuth, KH				Knuth, KH			Lattice duality: The origin of probability and entropy	NEUROCOMPUTING			English	Article						probability; entropy; lattice; information theory; Bayesian inference; inquiry	INFORMATION; SEPARATION	Bayesian probability theory is an inference calculus, which originates from a generalization of inclusion on the Boolean lattice of logical assertions to a degree of inclusion represented by a real number. Dual to this lattice is the distributive lattice of questions constructed from the ordered set of down-sets of assertions, which forms the foundation of the calculus of inquiry-a generalization of information theory. In this paper we introduce this novel perspective on these spaces in which machine learning is performed and discuss the relationship between these results and several proposed generalizations of information theory in the literature. Published by Elsevier B.V.	NASA, Ames Res Ctr, Moffett Field, CA 94035 USA	Knuth, KH (reprint author), NASA, Ames Res Ctr, Mail Stop 269-3, Moffett Field, CA 94035 USA.	kevin.h.knuth@nasa.gov					Aczel J., 1974, ADV APPL PROBAB, V6, P131, DOI 10.2307/1426210; Aczel J., 1966, LECT FUNCTIONAL EQUA; BARNABEI M, 1995, MOBIUS FUNCTIONS, P83; Bell A., 2003, P 5 INT WORKSH IND C; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; Belnap N., 1976, LOGIC QUESTIONS ANSW; Bernoulli Jacob, 1713, ARS CONJECTANDI; Birkhoff G, 1967, LATTICE THEORY; Boole G., 1854, INVESTIGATION LAWS T; BOOLE G, 1848, DUBLIN MATH J, V3, P183; Caticha A, 1998, PHYS REV A, V57, P1572, DOI 10.1103/PhysRevA.57.1572; Cohen F. S., 1929, MONIST, V39, p350 364; Cox R. T., 1979, MAXIMUM ENTROPY FORM, P119; COX RT, 1946, AM J PHYS, V14, P1, DOI 10.1119/1.1990764; Cox R.T., 1961, ALGEBRA PROBABLE INF; Davey B.A., 2002, INTRO LATTICES ORDER; Fedorov V. V., 1972, THEORY OPTIMAL EXPT; FRY RL, 1998, IMPLEMENTATION TECHN, V3; FRY RL, 1999, ELECT COURSE NOTES, V525, P475; FRY RL, 1995, IEEE T NEURAL NETWOR, V6, P918, DOI 10.1109/72.392254; Fry RL, 2002, AIP CONF PROC, V617, P497; Garrett AJM, 1998, FUND THEOR PHYS, V98, P71; HAN TS, 1975, INFORM CONTROL, V29, P337, DOI 10.1016/S0019-9958(75)80004-0; Hartley RVL, 1928, BELL SYST TECH J, V7, P535; Jaynes E. T., 2003, PROBABILITY THEORY L; JAYNES ET, 1968, IEEE T SYST SCI CYB, VSSC4, P227, DOI 10.1109/TSSC.1968.300117; JAYNES ET, 1985, MAXIMUM ENROPY BAYES; Jaynes E.T., 1979, MAXIMUM ENTROPY FORM, P15; Kaiser A, 2002, PHYSICA D, V166, P43, DOI 10.1016/S0167-2789(02)00432-3; Keynes John Maynard, 1921, TREATISE PROBABILITY; Klain D, 1997, INTRO GEOMETRIC PROB; KNUTH KH, 2002, AIP C P, V659, P227; Knuth KH, 2001, AIP CONF PROC, V568, P340; Knuth KH, 2004, AIP CONF PROC, V707, P204; Knuth KH, 2003, PHILOS T R SOC A, V361, P2859, DOI 10.1098/rsta.2003.1268; KNUTH KH, 1999, P 1 INT WORKSH IND C, P283; Laplace P. S., 1812, THEORIE ANAL PROBABI; LINDLEY DV, 1956, ANN MATH STAT, V27, P986, DOI 10.1214/aoms/1177728069; Loredo TJ, 2004, AIP CONF PROC, V707, P330; LUTTRELL SP, 1985, INVERSE PROBL, V1, P199, DOI 10.1088/0266-5611/1/3/006; MACKAY DJC, 1992, NEURAL COMPUT, V4, P589; McGill W.J., 1954, IEEE T INFORM THEORY, V4, P93; PIERCE JG, 1979, MAXIMUM ENTROPY FORM, P339; Rota G., 1964, Z WAHRSCH VERW GEBIE, V2, P340, DOI DOI 10.1007/BF00531932; Rota G.-C., 1971, STUDIES PURE MATH, P221; Rota GC, 1998, MATH INTELL, V20, P11; Shannon CE, 1949, MATH THEORY COMMUNIC; SMITH CR, 1990, FUND THEOR, V39, P17; TRIBUS M, 1969, DECISIONS DESIGNS; Watanabe S, 1969, KNOWING GUESSING	50	18	18	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	AUG	2005	67						245	274		10.1016/j.neucom.2004.11.039		30	Computer Science, Artificial Intelligence	Computer Science	958HW	WOS:000231436300010	
J	Kim, HJ; Kim, JU; Ra, YG				Kim, HJ; Kim, JU; Ra, YG			Boosting Naive Bayes text classification using uncertainty-based selective sampling	NEUROCOMPUTING			English	Article						machine learning; boosting; Naive Bayes learning; active learning; uncertainty; selective sampling		This paper presents adaptive boosting with uncertainty-based selective sampling (AdaBUS), a variant of the AdaBoost algorithm for boosting the Naive Bayes (NB) text classification. Although the boosting technique has been shown to effectively improve the accuracy of machine-learning-based classifiers, boosting does not work well with NB text classification owing to the low variance in the accuracy of its base classifier. In this study, we propose boosting the NB text classifier by combining the AdaBoost boosting algorithm with uncertainty-based selective sampling. Experiments using the popular Reuters-21578 document collection showed that the proposed algorithm effectively improves classification accuracy. (c) 2005 Elsevier B.V. All rights reserved.	Univ Seoul, Dept Elect & Comp Engn, Seoul, South Korea	Kim, HJ (reprint author), Univ Seoul, Dept Elect & Comp Engn, Seoul, South Korea.	khj@uos.ac.kr					AGGRAWAL R, 2000, P 7 INT C EXT DAT TE, P365; Cover TM, 1991, ELEMENTS INFORMATION, P12; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y., 1990, Proceedings of the Third Annual Workshop on Computational Learning Theory; Lewis D, 1994, P 11 INT C MACH LEAR, P148; Mitchell T, 1997, MACHINE LEARNING; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Ting KM, 2003, COMPUT INTELL-US, V19, P186, DOI 10.1111/1467-8640.00219	9	4	4	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	AUG	2005	67						403	410		10.1016/j.neucom.2004.09.003		8	Computer Science, Artificial Intelligence	Computer Science	958HW	WOS:000231436300027	
J	Rueda, L				Rueda, L			A one-dimensional analysis for the probability of error of linear classifiers for normally distributed classes	PATTERN RECOGNITION			English	Article						linear discriminant analysis; Fisher's classifier; error rate evaluation; Gaussian distributions; curse of dimensionality		Computing the probability of error is an important problem in evaluating classifiers. When dealing with normally distributed classes, this problem becomes intricate due to the fact that there is no closed-form expression for integrating the probability density function. In this paper, we derive lower and upper bounds for the probability of error for a linear classifier, where the random vectors representing the underlying classes obey the multivariate normal distribution. The expression of the error is derived in the one-dimensional space, independently of the dimensionality of the original problem. Based on the two bounds, we propose an approximating expression for the error of a generic linear classifier. In particular, we derive the corresponding bounds and the expression for approximating the error of Fisher's classifier. Our empirical results on synthetic data, including up to two-hundred-dimensional featured samples, show that the computations for the error are extremely fast and quite accurate; it differs from the actual error in at most epsilon = 0.0184340683. The scheme has also been successfully tested on real-life data sets drawn from the UCI machine learning repository. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Univ Windsor, Sch Comp Sci, Windsor, ON N9B 3P4, Canada	Rueda, L (reprint author), Univ Windsor, Sch Comp Sci, 401 Sunset Ave, Windsor, ON N9B 3P4, Canada.	lrueda@uwindsor.ca					CODY WJ, 1993, ACM T MATH SOFTWARE, V19, P22, DOI 10.1145/151271.151273; DAVIES P, 1999, NUMERICALLY STABLE G; Duda R., 2000, PATTERN CLASSIFICATI; Fukunaga K., 1990, INTRO STAT PATTERN R; Genz A, 1992, J COMPUTATIONAL GRAP, V1, P141, DOI DOI 10.2307/1390838; Herbrich R, 2001, LEARNING KERNEL CLAS; Herbrich R, 2002, IEEE T INFORM THEORY, V48, P3140, DOI 10.1109/TIT.2002.805090; JOE H, 1995, J AM STAT ASSOC, V90, P957, DOI 10.2307/2291331; KENDALL M, 1998, KENDALLS ADV THEORY, V1; Lee C, 2000, IEEE T GEOSCI REMOTE, V38, P1471; Miwa T, 2003, J ROY STAT SOC B, V65, P223, DOI 10.1111/1467-9868.00382; Raudys S, 1998, PATTERN RECOGN LETT, V19, P385, DOI 10.1016/S0167-8655(98)00016-6; Rueda L, 2004, PATTERN RECOGN, V37, P811, DOI 10.1016/j.patcog.2003.07.013; Somerville PN, 1998, J COMPUT GRAPH STAT, V7, P529, DOI 10.2307/1390681; VASWANI N, 2002, P 16 INT C PATT REC, V2, P60; Webb A.R., 2002, STAT PATTERN RECOGNI; Xu Y, 2004, PATTERN RECOGN, V37, P381, DOI 10.1016/S0031-3203(03)00232-2	17	2	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	AUG	2005	38	8					1197	1207		10.1016/j.patcog.2004.12.002		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	933YW	WOS:000229669900005	
J	Li, HF; Lee, SY; Shan, MK				Li, HF; Lee, SY; Shan, MK			Online mining maximal frequent structures in continuous landmark melody streams	PATTERN RECOGNITION LETTERS			English	Article						machine learning; data mining; landmark melody stream; maximal melody structure; Online algorithm		In this paper, we address the problem of online mining maximal frequent structures (Type I & II melody structures) in unbounded, continuous landmark melody streams. An efficient algorithm, called MMSLMS (Maximal Melody Structures of Landmark Melody Streams), is developed for online incremental mining of maximal frequent melody substructures in one scan of the continuous melody streams. In MMSLMS, a space-efficient scheme, called CMB (Chord-set Memory Border), is proposed to constrain the upper-bound of space requirement of maximal frequent melody structures in such a streaming environment. Theoretical analysis and experimental study show that our algorithm is efficient and scalable for mining the set of all maximal melody structures in a landmark melody stream. (c) 2005 Elsevier B.V. All rights reserved.	Natl Chiao Tung Univ, Dept Comp Sci & Informat Engn, Hsinchu 300, Taiwan; Natl Chengchi Univ, Dept Comp Sci, Taipei 116, Taiwan	Li, HF (reprint author), Natl Chiao Tung Univ, Dept Comp Sci & Informat Engn, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.	hfli@csie.nctu.edu.tw; sylee@csie.nctu.edu.tw; mkshan@cs.nccu.edu.tw					Agrawal R., 1994, P 20 INT C VER LARG, P487; Babcock B., 2002, P 21 ACM SIGACT SIGM, P1; Bakhmutova IV, 1997, COMPUT MUSIC J, V21, P58, DOI 10.2307/3681219; FISHER MJ, 1982, J ALGORITHM, V3, P362; Hsu JL, 2001, IEEE T MULTIMEDIA, V3, P311; Jones G.T., 1974, MUSIC THEORY; Karp RM, 2003, ACM T DATABASE SYST, V28, P51, DOI 10.1145/762471.762473; Shan MK, 2003, IEICE T INF SYST, VE86D, P655; Yoshitaka A, 1999, IEEE T KNOWL DATA EN, V11, P81, DOI 10.1109/69.755617; ZHU Y, 2001, P 2 IEEE PAC RIM C M, P530	10	9	9	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	AUG	2005	26	11					1658	1674		10.1016/j.patrec.2005.01.016		17	Computer Science, Artificial Intelligence	Computer Science	939DJ	WOS:000230052300006	
J	Roberts, K; Weikum, G; Mucklich, F				Roberts, K; Weikum, G; Mucklich, F			Examinations on the automatic classification of lamellar graphite using the support vector machine	PRAKTISCHE METALLOGRAPHIE-PRACTICAL METALLOGRAPHY			German	Article								The different structure of graphite in cast iron is significant for the mechanical properties of this material. This is why six general forms of a graphite structure, amongst them five configuration classes for lamellar graphite, were defined in the standard EN ISO 945:1994. The subjective classification of the latter can give rise to contradictory results and should be substituted for by an objective classification method using image analyses. The use of the support vector machine is introduced by which a binary classification is performed by calculating a maximum-margin separating hyperplane in the m-dimensional space The location of the hyperplane is defined by support vectors which are determined by a measurement of image analytical parameters on training images. Six stereological parameters and 14 Haralick parameters were calculated for each image during this examination. The training was based on 350 training images classified by experts. The performance measure of interest was the classification quality of the support vector machine. Furthermore, it was possible to determine the relevance of the 20 parameters for the classification of the individual graphite structures The support vector machine appears as an interesting classification method from the field of "Machine Learning", which can also be employed more generally for metallographic images in the future.	Univ Karlsruhe, Inst Informat Technol, D-76128 Karlsruhe, Germany; Max Planck Inst Informat, D-66123 Saarbrucken, Germany; Univ Saarland, Fachbereich Werkstoffwissenscaften, D-66041 Saarbrucken, Germany	Roberts, K (reprint author), Univ Karlsruhe, Inst Informat Technol, Kaiserstr 12, D-76128 Karlsruhe, Germany.	roberts@ira.uka.de; weikum@mpi-sb.mpg.de; muecke@matsci.uni-sb.de					CONNERS RW, 1980, IEEE T PATTERN RECOG, V2, P202; Handels H, 2000, MED BILDVERARBEITUNG; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; JAOCHIMS T, 2001, THESIS U DORTMUND; MCUKLICH F, 2000, STAT ANAL MICROSTRUC; OHSER J, 2003, IMAGE ANAL CHARACTER; ROBERTS K, 2003, THESIS U SAARLANDES	7	3	3	CARL HANSER VERLAG	MUNICH	KOLBERGERSTRASSE 22, POSTFACH 86 04 20, D-81679 MUNICH, GERMANY	0032-678X		PRAKT METALLOGR-PR M	Prakt. Metallogr.-Pract. Metallogr.	AUG	2005	42	8					396	410				15	Metallurgy & Metallurgical Engineering	Metallurgy & Metallurgical Engineering	967EM	WOS:000232074300003	
J	Pham, DT; Afify, AA				Pham, DT; Afify, AA			Online discretization of continuous-valued attributes in rule induction	PROCEEDINGS OF THE INSTITUTION OF MECHANICAL ENGINEERS PART C-JOURNAL OF MECHANICAL ENGINEERING SCIENCE			English	Article						machine learning; classification learning; inductive learning; rule induction; discretization; continuous attributes	MIXED-MODE DATA; DECISION TREES; GENERATION; SELECTION	Machine learning algorithms designed for engineering applications must be able to handle numerical attributes, particularly attributes with real (or continuous) values. Many algorithms deal with continuous-valued attributes by discretizing them before starting the learning process. This paper describes a new approach for discretization of continuous-valued attributes during the learning process. Incorporating discretization within the learning process has the advantage of taking into account the bias inherent in the learning system as well as the interactions between the different attributes. Experiments have demonstrated that the proposed method, when used in conjunction with the SRI rule induction algorithm developed by the authors, improves the accuracy of the induced model.	Cardiff Univ, Sch Engn, Mfg Engn Ctr, Intelligent Syst Lab, Cardiff CF24 0YF, S Glam, Wales	Pham, DT (reprint author), Cardiff Univ, Sch Engn, Mfg Engn Ctr, Intelligent Syst Lab, POB 925,Newport Rd, Cardiff CF24 0YF, S Glam, Wales.		Pham, Duc/H-1516-2011				An A., 1999, P 3 PAC AS C KNOWL D, P509; AUER P, 1995, P 12 INT C MACH LEAR, P21; Berka P, 1998, INT J PATTERN RECOGN, V12, P1017, DOI 10.1142/S0218001498000567; BIRKENDORF A, 1997, LECT NOTES ARTIF INT, V1208, P198; Blake C. L., 1998, UCI REPOSITORY MACHI; Braha D., 2001, DATA MINING DESIGN M; CAI Z, 2001, THESIS U WALES CARDI; Catlett J., 1991, THESIS U TECHNOLOGY; Catlett J., 1991, P EUR WORK SESS LEAR, P164; Cerquides J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; CHING JY, 1995, IEEE T PATTERN ANAL, V17, P641, DOI 10.1109/34.391407; CHMIELEWSKI MR, 1994, P 3 INT WORKSH ROUGH, P294; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; Elomaa T, 1999, MACH LEARN, V36, P201, DOI 10.1023/A:1007674919412; Elomaa T, 1999, LECT NOTES ARTIF INT, V1704, P89; FAYYAD UM, 1992, MACH LEARN, V8, P87, DOI 10.1007/BF00994007; Frank E., 1998, P 15 INT C MACH LEAR, P152; Fulton T., 1995, P 12 INT C MACH LEAR, P244; Good I.J., 1965, ESTIMATION PROBABILI; Han J., 2001, DATA MINING CONCEPTS; HO KM, 1997, IEEE T KNOW DATA ENG, V9, P718; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; Jun BH, 1997, IEEE T PATTERN ANAL, V19, P1371, DOI 10.1109/34.643896; Kerber R., 1992, P 10 NAT C ART INT, P123; Klosgen W., 2002, HDB DATA MINING KNOW; Kohavi R., 1996, P 2 INT C KNOWL DISC, P114; Kontkanen P, 1997, P EUR S INT TECHN BA, P265; KURGAN L, 2001, P 2001 INT C ART INT, P980; Liu H, 1997, IEEE T KNOWL DATA EN, V9, P642; Liu H, 2002, DATA MIN KNOWL DISC, V6, P393, DOI 10.1023/A:1016304305535; Maass W., 1994, Proceedings of the Seventh Annual ACM Conference on Computational Learning Theory, COLT 94, DOI 10.1145/180139.181016; Mitchell T, 1997, MACHINE LEARNING; MONOSTORI L, 2003, ENG APPL ARTIF INTEL, V16, P227; Peng YH, 2004, J INTELL MANUF, V15, P373, DOI 10.1023/B:JIMS.0000026574.95637.36; Pfahringer B., 1995, P 12 INT C MACH LEAR, P456; PHAM DT, 2002, P 9 INT WORKSH SYST, P12; PHAM DT, 2004, UNPUB P I MECH ENG C; Pham DT, 2005, P I MECH ENG B-J ENG, V219, P395, DOI 10.1243/095440505X32274; Quinlan J., 1983, MACHINE LEARNING ART, V1, P463; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1989, INFORM COMPUT, V80, P227; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; Richeldi M., 1995, P 8 EUR C MACH LEARN, P335; ROUSSU J, 2001, THESIS U HELSINKI FI; Taylor C., 1994, MACHINE LEARNING NEU; TING KM, 1994, 491 U SYDN BASS DEP; TRAUTZSCH S, 1998, ADV PATTERN RECOGNIT, V1451, P475; TRAUTZSCH S, 2003, COMP DIFFERENT MULTI; VENTURA D, 1995, THESIS BRINGHAM YOUN; Wang K, 1998, LECT NOTES ARTIF INT, V1531, P250; WONG AKC, 1987, IEEE T PATTERN ANAL, V9, P796; Wu XD, 1996, COMPUT J, V39, P688, DOI 10.1093/comjnl/39.8.688; Zighed D. A., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; [Anonymous], 1993, P 13 INT JOINT C ART, P1022	55	2	2	PROFESSIONAL ENGINEERING PUBLISHING LTD	WESTMINISTER	1 BIRDCAGE WALK, WESTMINISTER SW1H 9JJ, ENGLAND	0954-4062		P I MECH ENG C-J MEC	Proc. Inst. Mech. Eng. Part C-J. Eng. Mech. Eng. Sci.	AUG	2005	219	8					829	842		10.1243/095440605X31571		14	Engineering, Mechanical	Engineering	982GD	WOS:000233145100011	
J	Schetinin, V; Schult, J				Schetinin, V; Schult, J			A neural-network technique to learn concepts from electroencephalograms	THEORY IN BIOSCIENCES			English	Article						artificial neural network; machine learning; decision tree; electroencephalogram	RISK; APNEA; AGE	A new technique is presented developed to learn multi-class concepts from clinical electroencephalograms (EEGs). A desired concept is represented as a neuronal computational model consisting of the input, hidden, and output neurons. In this model the hidden neurons learn independently to classify the EEG segments presented by spectral and statistical features. This technique has been applied to the EEG data recorded from 65 sleeping healthy newborns in order to learn a brain maturation concept of newborns aged between 35 and 51 weeks. The 39,399 and 19,670 segments from these data have been used for learning and testing the concept, respectively. As a result, the concept has correctly classified 80.1% of the testing segments or 87.7% of the 65 records. (C) 2005 Elsevier GmbH. All rights reserved.	Univ Exeter, Dept Comp Sci, Exeter EX4 4QF, Devon, England; Univ Jena, D-6900 Jena, Germany	Schult, J (reprint author), Moltpestr 27, D-23564 Lubeck, Germany.	v.schetinin@ex.ac.uk; joachim_schult@web.de					ANDERSON JR, 1995, ANIM WELFARE, V4, P171; Breidbach O, 1998, THEOR BIOSCI, V117, P377; BRODLEY CE, 1992, 9282 COINS U MASS; GALANT S, 1993, NEURAL NETWORK LEARN; Galicki M, 1997, NEURAL NETWORKS, V10, P1153, DOI 10.1016/S0893-6080(97)00033-6; Holthausen K, 1999, THEOR BIOSCI, V118, P189; Holthausen K, 1999, NEUROSCI LETT, V268, P123, DOI 10.1016/S0304-3940(99)00397-3; Murthy S.K., 1994, J ARTIFICIAL INTELLI, V2, P1; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Riddington E. P., 1994, Proceedings of the International Conference on Neural Networks and Expert Systems in Medicine and Healthcare; Salzberg S, 1998, J COMPUT BIOL, V5, P667, DOI 10.1089/cmb.1998.5.667; UTGOFF P, 1991, 9110 COINS U MASS; Wackermann J, 1998, ELECTROEN CLIN NEURO, V107, P415, DOI 10.1016/S0013-4694(98)00090-X	13	4	4	URBAN & FISCHER VERLAG	JENA	BRANCH OFFICE JENA, P O BOX 100537, D-07705 JENA, GERMANY	1431-7613		THEOR BIOSCI	Theory Biosci.	AUG	2005	124	1					41	53		10.1016/j.thbio.2005.05.004		13	Biology; Mathematical & Computational Biology	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology	961NY	WOS:000231670300003	
J	Cheverst, K; Byun, HE; Fitton, D; Sas, C; Kray, C; Villar, N				Cheverst, K; Byun, HE; Fitton, D; Sas, C; Kray, C; Villar, N			Exploring issues of user model transparency and proactive behaviour in an office environment control system	USER MODELING AND USER-ADAPTED INTERACTION			English	Article						context history; intelligent environment; inference; machine learning; proactive behaviour; prototype deployment; scrutability	COMPUTER	It is important that systems that exhibit proactive behaviour do so in a way that does not surprise or frustrate the user. Consequently, it is desirable for such systems to be both personalised and designed in such a way as to enable the user to scrutinise her user model (part of which should hold the rules describing the behaviour of the system). This article describes on-going work to investigate the design of a prototype system that can learn a given user's behaviour in an office environment in order to use the inferred rules to populate a user model and support appropriate proactive behaviour (e.g. turning on the user's fan under appropriate conditions). We explore the tension between user control and proactive services and consider issues related to the design of appropriate transparency with a view to supporting user comprehensibility of system behaviour. To this end, our system enables the user to scrutinise and possibly over-ride the 'IF-THEN' rules held in her user model. The system infers these rules from the context history (effectively a data set generated using a variety of sensors) associated with the user by using a fuzzy-decision-tree-based algorithm that can provide a confidence level for each rule in the user model. The evolution of the system has been guided by feedback from a number of real-life users in a university department. A questionnaire study has yielded supplementary results concerning the extent to which the approach taken meets users' expectations and requirements.	Univ Lancaster, Dept Comp, Lancaster LA1 4YR, England	Cheverst, K (reprint author), Univ Lancaster, Dept Comp, Lancaster LA1 4YR, England.	kc@comp.lancs.ac.uk					Abowd G. D., 2000, ACM Transactions on Computer-Human Interaction, V7, DOI 10.1145/344949.344988; Arroyo E., 2002, Proceedings Fourth IEEE International Conference on Multimodal Interfaces, DOI 10.1109/ICMI.2002.1167043; BARKHUUS L, 2003, P UB, P159; Brumitt B.L., 2000, P 2 INT S HANDH UB C, P12; Byun H. E., 2003, P UM 2003 WORKSH US, P17; Byun HE, 2004, APPL ARTIF INTELL, V18, P533, DOI 10.1080/08839510490462894; Cheverst K, 2001, PERS UBIQUIT COMPUT, V5, P8, DOI 10.1007/s007790170020; CHEVERST K, 2003, P AUSTR COMP HUM C O, P74; COEN MH, 1998, P INT ENV 1998 AAAI, P37; COHEN S, 1980, PSYCHOL BULL, V88, P82, DOI 10.1037//0033-2909.88.1.82; Dey AK, 2000, P WORKSH SOFTW ENG W; GUETOVA M, 2002, P 25 GERM C ART INT, P67; Holmquist L. E., 2001, P 3 INT C UB COMP UB, P116; Horvitz E., 1999, P ACM SIGCHI C HUM F, P159, DOI 10.1145/302979.303030; Intille S., 2003, P IEEE ASME INT C AD; Intille S.S., 2002, IEEE PERVASIVE C APR, P80; JAMESON A, 2004, P 1 INT WORKSH INV T, P29; Janikow C. Z., 1996, Proceedings of the Fifth IEEE International Conference on Fuzzy Systems. FUZZ-IEEE '96 (Cat. No.96CH35998), DOI 10.1109/FUZZY.1996.552397; KARLGREN J, 1994, P 4 INT C US MOD UM; KAY J, 2003, P UM03 WORKSH US MOD, P1; MANTYJARVI J, 2002, 4 INT S HUM COMP INT, P95; McFarlane DC, 2002, HUM-COMPUT INTERACT, V17, P1, DOI 10.1207/S15327051HCI1701_1; Mitchell T., 1994, Communications of the ACM, V37, DOI 10.1145/176789.176798; Mozer MC, 1998, LECT NOTES ARTIF INT, V1387, P370; POHL W, 1996, P ICML96 WORKSH MACH, P29; RODIN J, 1977, J PERS SOC PSYCHOL, V35, P897, DOI 10.1037/0022-3514.35.12.897; Rubinstein JS, 2001, J EXP PSYCHOL HUMAN, V27, P763, DOI 10.1037//0096-1523.27.4.763; SALOVAARA A, 2004, P 3 NORD C HUM COMP, P57, DOI 10.1145/1028014.1028022; SHIU SCK, 2000, ADV CASE BASED REASO, P285; Speier C., 1997, P 18 INT C INF SYST, P21; WEISER M, 1991, SCI AM, V265, P94; ZEIDLER J, 1996, P 6 INT C INF PROC M, P395; *X10 LTD, 2004, WHAT IS X10	33	15	15	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-1868		USER MODEL USER-ADAP	User Model. User-Adapt. Interact.	AUG	2005	15	3-4					235	273		10.1007/s11257-005-1269-8		39	Computer Science, Cybernetics	Computer Science	983PZ	WOS:000233245900003	
J	Geurts, P; Fillet, M; de Seny, D; Meuwis, MA; Malaise, M; Merville, MP; Wehenkel, L				Geurts, P; Fillet, M; de Seny, D; Meuwis, MA; Malaise, M; Merville, MP; Wehenkel, L			Proteomic mass spectra classification using decision tree based ensemble methods	BIOINFORMATICS			English	Article							OVARIAN-CANCER	Motivation: Modern mass spectrometry allows the determination of proteomic fingerprints of body fluids like serum, saliva or urine. These measurements can be used in many medical applications in order to diagnose the current state or predict the evolution of a disease. Recent developments in machine learning allow one to exploit such datasets, characterized by small numbers of very high-dimensional samples. Results: We propose a systematic approach based on decision tree ensemble methods, which is used to automatically determine proteomic biomarkers and predictive models. The approach is validated on two datasets of surface-enhanced laser desorption/ionization time of flight measurements, for the diagnosis of rheumatoid arthritis and inflammatory bowel diseases. The results suggest that the methodology can handle a broad class of similar problems.	Univ Liege, Dept Elect Engn & Comp Sci, B-4000 Liege, Belgium; Univ Liege, Lab Clin Chem & Rheumatol, CBIG, B-4000 Liege, Belgium	Geurts, P (reprint author), Univ Liege, Dept Elect Engn & Comp Sci, B-4000 Liege, Belgium.	p.geurts@ulg.ac.be					Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Freund Y., 1995, P 2 EUR C COMP LEARN, P23; FUNG ET, 2002, COMPUTATIONAL PROT S, V32, pS34; Hastie T, 2001, ELEMENTS STAT LEARNI; Izmirlian G, 2004, ANN NY ACAD SCI, V1020, P154, DOI 10.1196/annals.1310.015; Jong K, 2004, LECT NOTES COMPUT SC, V3005, P41; Li J., 2003, BIOINFORMATICS S2, V19, pii93; Liu Huiqing, 2002, Genome Inform, V13, P51; Pusch W, 2003, PHARMACOGENOMICS, V4, P463, DOI 10.1517/phgs.4.4.463.22753; Qu YS, 2002, CLIN CHEM, V48, P1835; QUINLAN J, 1986, C4 5 PROGRAMS MACHIN; Rai AJ, 2002, ARCH PATHOL LAB MED, V126, P1518; Wehenkel L., 1998, AUTOMATIC LEARNING T; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210	19	63	68	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	JUL 15	2005	21	14					3138	3145		10.1093/bioinformatics/bti494		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	941GX	WOS:000230204400011	
J	Matsunaga, T; Muramatsu, MA				Matsunaga, T; Muramatsu, MA			Knowledge-based computational search for genes associated with the metabolic syndrome	BIOINFORMATICS			English	Article							LOW-DENSITY-LIPOPROTEIN; SMOOTH-MUSCLE-CELL; INSULIN RESISTANCE; CANDIDATE GENES; DATABASE; ATHEROSCLEROSIS; CHOLESTEROL; DISEASE; EXPRESSION; OBESITY	Motivation: A methodology to search for genes associated with multifactorial diseases by integrating the large amount of accumulated knowledge is seriously needed. A comprehensive understanding derived from a holistic view of gene relationship structures can be gained from our proposed analysis called the cross-subspace analysis (CSA). In this analysis, gene objects are generated by machine learning using their term occurrence patterns in MEDLINE abstracts and the degree of relationship between gene objects is quantified by matching these patterns. Results: Structuralization of relationships of a set of genes was performed using CSA, which were retrieved using the terms, 'obesity', 'diabetes', 'hypertriglyceridemia' and 'hypertension' that refer to diseases comprising metabolic syndrome, on a 2D plane inferring important biomedical concepts from the gene distribution. Then, we prioritized the significance of 6131 well-annotated human genes in terms of the distance on the plane from the centroid of 'metabolic syndrome'- related genes distribution. The validity was confirmed by comparing the knowledge extracted by the ordering with existing medical knowledge.	NTT DATA Corp, Res & Dev Headquaeters, Tokyo 1040033, Japan; Tokyo Med & Dent Univ, Med Res Inst, Tokyo 1138510, Japan; HuBit Genomix Inc, Res Inst, Tokyo 1020092, Japan	Matsunaga, T (reprint author), NTT DATA Corp, Res & Dev Headquaeters, Tokyo 1040033, Japan.	matsunagat@nttdata.co.jp					Abusamieh Mohammed, 2004, Cardiol Rev, V12, P267, DOI 10.1097/01.crd.0000124843.85660.ed; Bairoch A, 1997, J MOL MED-JMM, V75, P312; Barabasi AL, 2004, NAT REV GENET, V5, P101, DOI 10.1038/nrg1272; Baxevanis AD, 2003, NUCLEIC ACIDS RES, V31, P1, DOI 10.1093/nar/gkg120; Bhakdi S, 1999, ARTERIOSCL THROM VAS, V19, P2348; BROWN MS, 1983, ANNU REV BIOCHEM, V52, P223, DOI 10.1146/annurev.bi.52.070183.001255; Collins FS, 2001, JAMA-J AM MED ASSOC, V285, P540, DOI 10.1001/jama.285.5.540; DEFRONZO RA, 1991, DIABETES CARE, V14, P173, DOI 10.2337/diacare.14.3.173; Cleeman JI, 2001, JAMA-J AM MED ASSOC, V285, P2486, DOI 10.1001/jama.285.19.2486; FUJIOKA S, 1987, METABOLISM, V36, P54, DOI 10.1016/0026-0495(87)90063-1; GREGORY J, 2001, HUM MOL GENET, V10, P663; Halushka MK, 1999, PHYSIOL GENOMICS, V1, P75; Hamosh A, 2000, HUM MUTAT, V15, P57, DOI 10.1002/(SICI)1098-1004(200001)15:1<57::AID-HUMU12>3.0.CO;2-G; Hansson GK, 2001, ARTERIOSCL THROM VAS, V21, P1876, DOI 10.1161/hq1201.100220; Homayouni R, 2005, BIOINFORMATICS, V21, P104, DOI 10.1093/bioinformatics/bth464; Jenssen TK, 2001, NAT GENET, V28, P21, DOI 10.1038/ng0501-21; KANNEL WB, 1971, ANN INTERN MED, V74, P1; KAPLAN NM, 1989, ARCH INTERN MED, V149, P1514, DOI 10.1001/archinte.149.7.1514; Kitahara O, 2001, CANCER RES, V61, P3544; Kobayashi K, 2003, J LIPID RES, V44, P716, DOI 10.1194/jlr.M200329-JLR200; KODAMA T, 1990, NATURE, V343, P531, DOI 10.1038/343531a0; Kruglyak L, 1999, NAT GENET, V22, P139, DOI 10.1038/9642; Kruskal J, 1978, MULTIDIMENSIONAL SCA; KULLBACK S, 1959, INFORMATION THEORY S; Libby P, 2002, NATURE, V420, P868, DOI 10.1038/nature01323; Matsunaga T., 2004, Systems and Computers in Japan, V35, DOI 10.1002/scj.10670; Matsunaga T., 2000, Systems and Computers in Japan, V31, DOI 10.1002/(SICI)1520-684X(200001)31:1<48::AID-SCJ6>3.0.CO;2-F; MATSUNAGA T, 2005, IN PRESS SYST COMPUT; Oja E., 1983, SUBSPACE METHODS PAT; Perez-Iratxeta C, 2002, NAT GENET, V31, P316, DOI 10.1038/ng895; REAVEN GM, 1988, DIABETES, V37, P1595, DOI 10.2337/diabetes.37.12.1595; Rebhan M, 1998, BIOINFORMATICS, V14, P656, DOI 10.1093/bioinformatics/14.8.656; ROSS R, 1973, SCIENCE, V180, P1332, DOI 10.1126/science.180.4093.1332; SALTON G, 1973, J DOC, V29, P351, DOI 10.1108/eb026562; STEINBERG D, 1989, NEW ENGL J MED, V320, P915; Stephens M, 2001, Pac Symp Biocomput, P483; Torzewski M, 1997, ARTERIOSCL THROM VAS, V17, P2448; Wheeler DL, 2003, NUCLEIC ACIDS RES, V31, P28, DOI 10.1093/nar/gkg033; Wjst M, 1998, BIOINFORMATICS, V14, P827, DOI 10.1093/bioinformatics/14.9.827; Yagi T, 2003, BLOOD, V102, P1849, DOI 10.1182/blood-2003-02-0578; Yamada Y, 2002, NEW ENGL J MED, V347, P1916, DOI 10.1056/NEJMoa021445; YAMAGUCHI O, 1998, P 3 IEEE INT C AUT F, V10, P318; Zee RYL, 2004, HUM MOL GENET, V13, P389, DOI 10.1093/hmg/ddh039; Zhang WY, 1997, J BIOL CHEM, V272, P31700, DOI 10.1074/jbc.272.50.31700; Zhou M, 2004, HUM MUTAT, V23, P1, DOI 10.1002/humu.10289	45	4	5	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	JUL 15	2005	21	14					3146	3154		10.1093/bioinformatic/bti484		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	941GX	WOS:000230204400012	
J	Settles, B				Settles, B			ABNER: an open source tool for automatically tagging genes, proteins and other entity names in text	BIOINFORMATICS			English	Article								ABNER ( A Biomedical Named Entity Recognizer) is an open source software tool for molecular biology text mining. At its core is a machine learning system using conditional random fields with a variety of orthographic and contextual features. The latest version is 1.5, which has an intuitive graphical interface and includes two modules for tagging entities ( e. g. protein and cell line) trained on standard corpora, for which performance is roughly state of the art. It also includes a Java application programming interface allowing users to incorporate ABNER into their own systems and train models on new corpora.	Univ Wisconsin, Dept Comp Sci, Madison, WI USA; Univ Wisconsin, Dept Biostat & Med Informat, Madison, WI USA	Settles, B (reprint author), Univ Wisconsin, Dept Comp Sci, Madison, WI USA.						HIRSCHMAN L, 2004, P CRIT ASS INF EXTR; KLIM J, 2003, BIOINFORMATICS S1, V19, pI180; Lafferty J., 2001, P 18 INT C MACH LEAR, P282; NOCEDAL J, 1999, NUMERICAL OPTIMIZATI, P224; Settles B., 2004, P INT JOINT WORKSH N, P104, DOI 10.3115/1567594.1567618; YEH A, 2004, P CRIT ASS INF EXTR	6	105	111	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	JUL 15	2005	21	14					3191	3192		10.1093/bioinformatics/bti475		2	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	941GX	WOS:000230204400026	
J	Rovira, A; Valdes, M; Casanova, J				Rovira, A; Valdes, M; Casanova, J			A new methodology to solve non-linear equation systems using genetic algorithms. Application to combined cycle gas turbine simulation	INTERNATIONAL JOURNAL FOR NUMERICAL METHODS IN ENGINEERING			English	Article						genetic algorithms; genetic-based machine learning; non-linear equation systems; combined cycle gas turbine; heat recovery steam generator		This paper shows a methodology to sort out the equations of a non-linear system in order to solve it by the fixed-point method. The arrangement of the equations is established by a genetic algorithm that deals with a population of possible resolution processes of the system. The method is specially useful in the following situations: first, when the system is very non-linear and has many variables (where the Newton-Raphson method does not work properly); second, when the number of equations and variables may be altered because the equation system may change in each simulation and, therefore, more than one only solution process is needed if the fixed-point process is employed. As an example, the methodology has been applied to solve the equation system that models the behaviour of a heat recovery steam generator of a combined cycle power plant at full load and part load conditions. Copyright (c) 2005 John Wiley & Sons, Ltd.	Univ Politecn Madrid, ETS Ingn Ind, Dept Ingn Energet & Fluidomecan, E-28006 Madrid, Spain	Rovira, A (reprint author), Univ Politecn Madrid, ETS Ingn Ind, Dept Ingn Energet & Fluidomecan, Jose Gutierrez Abascal 2, E-28006 Madrid, Spain.	rovira@etsii.upm.es; mvaldes@etsii.upm.es; jcasanova@etsii.upm.es	Rovira, Antonio/D-1954-2009				Bentley P, 1999, EVOLUTIONARY DESIGN BY COMPUTERS, P1; BOOKER LB, 1989, ARTIF INTELL, V40, P235, DOI 10.1016/0004-3702(89)90050-7; BURDEN L, 1985, ANALISIS NUMERICO; Goldberg DE, 1989, GENETIC ALGORITHMS S; HOLLAND JH, 1975, ADAPTATION NATURAL A; Karr CL, 1998, ENG APPL ARTIF INTEL, V11, P369, DOI 10.1016/S0952-1976(97)00067-5; NGUYEN TT, 1993, ELECTRON LETT, V29, P1403, DOI 10.1049/el:19930940; Rheinboldt W.C., 1974, METHODS SOLVING SYST; ROVIRA A, 2004, THESIS U POLITECNICA; Valdes M, 2003, APPL THERM ENG, V23, P2169, DOI 10.1016/S1359-4311(03)00203-5; VALDES M, 2004, INT J ENERG RES, V28, P1255; WU Z, 2003, C EVOLUTIONARY COMPU, V2, P1026	12	3	4	JOHN WILEY & SONS LTD	CHICHESTER	THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND	0029-5981		INT J NUMER METH ENG	Int. J. Numer. Methods Eng.	JUL 14	2005	63	10					1424	1435		10.1002/nme.1267		12	Engineering, Multidisciplinary; Mathematics, Interdisciplinary Applications	Engineering; Mathematics	943AU	WOS:000230324800003	
J	Corani, G				Corani, G			Air quality prediction in Milan: feed-forward neural networks, pruned neural networks and lazy learning	ECOLOGICAL MODELLING			English	Article						feed forward neural networks; pruned neural networks; lazy learning; time series prediction; atmospheric pollution	OZONE CONCENTRATIONS; PM10 CONCENTRATIONS; TIME-SERIES; MODELS; POLLUTION; SANTIAGO; MAXIMUM; CHILE; ALGORITHMS; VARIABLES	Ozone and PM10 constitute the major concern for air quality of Milan. This paper addresses the problem of the prediction of such two pollutants, using to this end several statistical approaches. In particular, feed-forward neural networks (FFNNs), currently recognized as state-of-the-art approach for statistical prediction of air quality, are compared with two alternative approaches derived from machine learning: pruned neural networks (PNNs) and lazy learning (LL). PNNs constitute a parameter-parsimonious approach, based on the removal of redundant parameters from fully connected neural networks; LL, on the other hand, is a local linear prediction algorithm, which performs a local learning procedure each time a prediction is required. All the three approaches are tested in the prediction of ozone and PM10; predictors are trained to return at 9 a.m. the concentration estimated for the current day. No strong differences are found between the forecast accuracies of the different models; nevertheless, LL provides the best performances on indicators related to average goodness of the prediction (correlation, mean absolute error, etc.), while PNNs are superior to the other approaches in detecting of the exceedances of alarm and attention thresholds. In some cases, data-deseasonalization is found to improve the prediction accuracy of the models. Finally, some striking features of lazy learning deserve consideration: the LL predictor can be quickly designed, and, thanks to the simplicity of the local linear regressors, it both gets rid of overfitting problems and can be readily interpreted; moreover, it can be also easily kept up-to-date. (c) 2005 Elsevier B.V. All rights reserved.	Politecn Milan, Dipartimento Elettr, I-20133 Milan, Italy	Corani, G (reprint author), Politecn Milan, Dipartimento Elettr, Via Ponzio 34-5, I-20133 Milan, Italy.	corani@elet.polimi.it					Ballester EB, 2002, ECOL MODEL, V156, P27; BIRATTARI M, 1998, P INT WORKSH ADV BLA, P62; Birattari M, 1999, ADV NEUR IN, V11, P375; BIRATTARI M, 2001, FUZZY SETS SYST, V121, P59; Bishop C.M., 1995, NEURAL NETWORKS PATT; Bontempi G., 1999, THESIS U LIBRE BRUXE; Bontempi G, 1999, INT J CONTROL, V72, P643, DOI 10.1080/002071799220830; CASTELLI S, 2003, P 13 IFAC S SYST ID, P1951; CECCHETTI M, 2004, P IEMSS 2004 INT C C; CHANGEUX JP, 1973, P NATL ACAD SCI USA, V70, P2974, DOI 10.1073/pnas.70.10.2974; CORANI G, 2004, P 9 INT C HARM ATM D; Dorling SR, 2003, ATMOS ENVIRON, V37, P3435, DOI 10.1016/S1352-2310(03)00323-6; Edelman G., 1987, NEURAL DARWINISM; Garcia-Gimeno RM, 2002, INT J FOOD MICROBIOL, V72, P19, DOI 10.1016/S0168-1605(01)00608-0; Gardner MW, 1998, ATMOS ENVIRON, V32, P2627, DOI 10.1016/S1352-2310(97)00447-0; Gevrey M, 2003, ECOL MODEL, V160, P249, DOI 10.1016/S0304-3800(02)00257-0; Hassibi B., 1993, P ADV NEUR INF PROC, P164; Henrique HM, 2000, CHEM ENG SCI, V55, P5457, DOI 10.1016/S0009-2509(00)00170-6; Hertz J., 1991, INTRO THEORY NEURAL; Kolehmainen M, 2001, ATMOS ENVIRON, V35, P815, DOI 10.1016/S1352-2310(00)00385-X; Kukkonen J, 2003, ATMOS ENVIRON, V37, P4539, DOI 10.1016/S1352-2310(03)00583-1; LeCun Y, 1990, ADV NEURAL INFORMATI, V2, P598; Marr LC, 2002, ATMOS ENVIRON, V36, P2327, DOI 10.1016/S1352-2310(02)00188-7; NELSON M, 1999, J FORECASTING, V5, P359; Norgaard M, 2000, NEURAL NETWORKS MODE; NORGAARD M, 2000, 00E891 TECHN U DENM; Nunnari G, 1998, ECOL MODEL, V111, P187, DOI 10.1016/S0304-3800(98)00118-5; Ostro B, 1999, J AIR WASTE MANAGE, V49, P100; Ostro BD, 1999, ENVIRON HEALTH PERSP, V107, P69, DOI 10.2307/3434291; Perez P, 2000, ATMOS ENVIRON, V34, P1189, DOI 10.1016/S1352-2310(99)00316-7; Perez P, 2002, ATMOS ENVIRON, V36, P4555, DOI 10.1016/S1352-2310(02)00419-3; Poppi RJ, 1998, ANAL CHIM ACTA, V375, P187, DOI 10.1016/S0003-2670(98)00462-0; Prybutok VR, 2000, EUR J OPER RES, V122, P31, DOI 10.1016/S0377-2217(99)00069-7; REED R, 1993, IEEE T NEURAL NETWOR, V4, P740, DOI 10.1109/72.248452; Schlink U, 2003, ATMOS ENVIRON, V37, P3237, DOI 10.1016/S1352-2310(03)00330-3; Viotti P, 2002, ECOL MODEL, V148, P27, DOI 10.1016/S0304-3800(01)00434-3; Vukovich FM, 2000, J AIR WASTE MANAGE, V50, P2067; ZICKUS M, 2002, WATER AIR SOIL POLL, V2, P717, DOI 10.1023/A:1021321820639; ZIOMAS IC, 1995, ATMOS ENVIRON, V29, P3703, DOI 10.1016/1352-2310(95)00131-H; *AG MIL MOB AMB, 2003, REL STAT AMB COM MIL	40	59	60	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3800		ECOL MODEL	Ecol. Model.	JUL 10	2005	185	2-4					513	529		10.1016/j.ecolmodel.2005.01.008		17	Ecology	Environmental Sciences & Ecology	929RJ	WOS:000229363200022	
J	Hoiem, D; Efros, AA; Hebert, M				Hoiem, D; Efros, AA; Hebert, M			Automatic photo pop-up	ACM TRANSACTIONS ON GRAPHICS			English	Article; Proceedings Paper	ACM SIGGRAPH 2005 Conference	JUL 31-AUG 04, 2005	Los Angeles, CA	ACM SIGGRAPH		image-based rendering; single-view reconstruction; machine learning; image segmentation	LOGISTIC-REGRESSION; VIEW	This paper presents a fully automatic method for creating a 3D model from a single photograph. The model is made up of several texture-mapped planar billboards and has the complexity of a typical children's pop-up book illustration. Our main insight is that instead of attempting to recover precise geometry, we statistically model geometric classes defined by their orientations in the scene. Our algorithm labels regions of the input image into coarse categories: "ground", "sky", and "vertical". These labels are then used to "cut and fold" the image into a pop-up model using a set of simple assumptions. Because of the inherent ambiguity of the problem and the statistical nature of the approach, the algorithm is not expected to work on every image. However, it performs surprisingly well for a wide range of scenes taken from a typical person's photo album.	Carnegie Mellon Univ, Pittsburgh, PA 15213 USA	Hoiem, D (reprint author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.	dhoiem@cs.cmu.edu; efros@cs.cmu.edu; hebert@cs.cmu.edu					CHEN ES, 1995, ACM SIGGRAPH COMPUTE, P29; Cipolla R., 1999, IEEE INT C MULT COMP, V1, P25; Collins M, 2002, MACH LEARN, V48, P253, DOI 10.1023/A:1013912006537; Criminisi A, 2000, INT J COMPUT VISION, V40, P123, DOI 10.1023/A:1026598000963; Debevec P. E., 1996, ANN C SERIES, P11; Duda R., 2000, PATTERN CLASSIFICATI; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; Everingham M.R., 1999, INT J VIRTUAL REALIT, V3, P3; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Gortler S. J., 1996, ANN C SERIES, P43; Hartley R., 2004, MULTIPLE VIEW GEOMET; Horry Y., 1997, ANN C SERIES ACM SIG, P225; KANG H, 2001, P EUROGRAPHICS, P132; KONISHI S, 2000, COMPUTER VISION PATT, P1125; Kosecka J., 2002, ECCV 02, P476; Levoy M., 1996, ACM SIGGRAPH 96, P31; Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719; Liebowitz D., 1999, P EUROGRAPHICS, V18, P39; Martin D., 2001, ICCV, V2, P416, DOI DOI 10.1109/ICCV.2001.937655; Nister D., 2001, THESIS ROYAL I TECHN; OH BM, 2001, ACM SIGGRAPH P, P433; Pollefeys M, 2004, INT J COMPUT VISION, V59, P207, DOI 10.1023/B:VISI.0000025798.50602.3a; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Ren X, 2003, ICCV, P10; SINGHAL A, 2003, COMPUTER VISION PATT, P235; Tao H., 2001, ICCV, P532; ZHANG L, 2001, CVPR, P990; Ziegler R., 2003, EG S GEOM PROC, P248	29	64	65	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	0730-0301		ACM T GRAPHIC	ACM Trans. Graph.	JUL	2005	24	3					577	584		10.1145/1073204.1073232		8	Computer Science, Software Engineering	Computer Science	955KB	WOS:000231223700025	
J	Hsu, E; Pulli, K; Popovic, J				Hsu, E; Pulli, K; Popovic, J			Style translation for human motion	ACM TRANSACTIONS ON GRAPHICS			English	Article; Proceedings Paper	ACM SIGGRAPH 2005 Conference	JUL 31-AUG 04, 2005	Los Angeles, CA	ACM SIGGRAPH		human simulation; data mining; machine learning	COMPUTER PUPPETRY; ANIMATION; GENERATION; MODELS	Style translation is the process of transforming an input motion into a new style while preserving its original content. This problem is motivated by the needs of interactive applications, which require rapid processing of captured performances. Our solution learns to translate by analyzing differences between performances of the same content in input and output styles. It relies on a novel correspondence algorithm to align motions, and a linear time-invariant model to represent stylistic differences. Once the model is estimated with system identification, our system is capable of translating streaming input with simple linear operations at each frame.	MIT, Cambridge, MA 02139 USA; Nokia Res Ctr, Helsinki, Finland	Hsu, E (reprint author), MIT, Cambridge, MA 02139 USA.						Amaya K, 1996, PROC GRAPH INTERF, P222; Arikan O, 2003, ACM T GRAPHIC, V22, P402, DOI 10.1145/882262.882284; Arikan O, 2002, ACM T GRAPHIC, V21, P483; BRAND M, 2000, ANN C SERIES, P183; Brockwell P. J., 2002, INTRO TIME SERIES FO; BRUDERLIN A, 1995, ANN C SERIES, P97; DELATORRE F, 2001, IEEE C COMP VIS PATT, P643; Dontcheva M, 2003, ACM T GRAPHIC, V22, P409, DOI 10.1145/882262.882285; Duda R., 2000, PATTERN CLASSIFICATI; FALOUTSOS P., 2001, ANN C SERIES, P251; Freeman WT, 2003, ACM T GRAPHIC, V22, P33, DOI 10.1145/588272.588277; Giese MA, 2000, INT J COMPUT VISION, V38, P59, DOI 10.1023/A:1008118801668; Gleicher M., 1998, ANN C SERIES, P33; Grassia F. S., 1998, J GRAPHICS TOOLS, V3, P29; Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755; HERTZMANN A, 2001, ACM SIGGRAPH, P327; HSU E, 2004, 2004 ACM SIGGRAPH EU, P69; Ilg W, 2002, LECT NOTES COMPUT SC, V2525, P528; JEBARA T, 1999, INT C COMP VIS SYST, V1542, P273; Kovar L, 2003, P ACM SIGGRAPH EUR S, p[214, 6]; Kovar L, 2002, ACM T GRAPHIC, V21, P473; Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760; KOVAR L, 2002, ACM SIGGRAPH S COMP, P97; LEE J, 1999, ANN C SERIES, P39; Lee JH, 2002, ACM T GRAPHIC, V21, P491; Li Y, 2002, ACM T GRAPHIC, V21, P465; Ljung L, 1999, SYSTEM IDENTIFICATIO; Luenberger D. G., 1979, INTRO DYNAMIC SYSTEM; Park SI, 2004, COMPUT ANIMAT VIRT W, V15, P125, DOI 10.1002/cav.15; Park SI, 2002, ACM SIGGRAPH EUR S C, P105; PERLIN K, 1995, IEEE T VIS COMPUT GR, V1, P5, DOI 10.1109/2945.468392; POPOVIC Z, 1999, ANN C SERIES, P11; Pullen K, 2002, ACM T GRAPHIC, V21, P501; Rabiner L, 1993, FUNDAMENTALS SPEECH; Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559; Shin HJ, 2001, ACM T GRAPHIC, V20, P67, DOI 10.1145/502122.502123; SOATTO S, 2001, IEEE INT C COMP VIS, P439; Stengel R. F., 1994, OPTIMAL CONTROL ESTI; Sturman DJ, 1998, IEEE COMPUT GRAPH, V18, P38, DOI 10.1109/38.637269; Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349; UNUMA M, 1995, ANN C SERIES, P91; Van Overschee P., 1996, SUBSPACE IDENTIFICAT; VASILESCU MAO, 2002, INT C PATT REC ICPR, V3, P456; Witkin A, 1995, ANN C SERIES, P105	44	52	62	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	0730-0301		ACM T GRAPHIC	ACM Trans. Graph.	JUL	2005	24	3					1082	1089		10.1145/1073204.1073315		8	Computer Science, Software Engineering	Computer Science	955KB	WOS:000231223700091	
J	Ren, L; Patrick, A; Efros, AA; Hodgins, JK; Rehg, JM				Ren, L; Patrick, A; Efros, AA; Hodgins, JK; Rehg, JM			A data-driven approach to quantifying natural human motion	ACM TRANSACTIONS ON GRAPHICS			English	Article; Proceedings Paper	ACM SIGGRAPH 2005 Conference	JUL 31-AUG 04, 2005	Los Angeles, CA	ACM SIGGRAPH		human animation; natural motion; machine learning; motion evaluation	BALLISTIC MOTION; INTERPOLATION; ANIMATION	In this paper, we investigate whether it is possible to develop a measure that quantifies the naturalness of human motion (as defined by a large database). Such a measure might prove useful in verifying that a motion editing operation had not destroyed the naturalness of a motion capture clip or that a synthetic motion transition was within the space of those seen in natural human motion. We explore the performance of mixture of Gaussians (MoG), hidden Markov models (HMM), and switching linear dynamic systems (SLDS) on this problem. We use each of these statistical models alone and as part of an ensemble of smaller statistical models. We also implement a Naive Bayes (NB) model for a baseline comparison. We test these techniques on motion capture data held out from a database, keyframed motions, edited motions, motions with noise added, and synthetic motion transitions. We present the results as receiver operating characteristic (ROC) curves and compare the results to the judgments made by subjects in a user study.	Carnegie Mellon Univ, Pittsburgh, PA 15213 USA; Georgia Inst Technol, Atlanta, GA 30332 USA	Ren, L (reprint author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.	liuren@cs.cmu.edu; apatrick@cc.gatech.edu; efros@cs.cmu.edu; jkh@cs.cmu.edu; rehg@cc.gatech.edu					Arikan O, 2002, ACM T GRAPHIC, V21, P483; ASSA J, 2005, ACM T GRAPHICS, V24; BRAND M, 2000, P SIGGRAPH 2000, P183, DOI 10.1145/344779.344865; COLE Ronald A., 1996, SURVEY STATE ART HUM; FARID H, 2003, IEEE WORKSH STAT AN; Gleicher M, 2001, GRAPH MODELS, V63, P107, DOI 10.1006/gmod.2001.0549; HAMID R, 2005, IN PRESS IEEE C COMP; Hara K, 2002, NEURAL NETWORKS FOR SIGNAL PROCESSING XII, PROCEEDINGS, P697, DOI 10.1109/NNSP.2002.1030081; Harrison J, 2004, ACM T GRAPHIC, V23, P569, DOI 10.1145/1015706.1015761; Ikemoto L., 2004, P 2004 ACM SIGGRAPH, P99, DOI 10.1145/1028523.1028537; Kovar L, 2002, ACM T GRAPHIC, V21, P473; Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760; Lee JH, 2002, ACM T GRAPHIC, V21, P491; Lerner U.N., 2002, THESIS STANFORD U; Li Y, 2002, ACM T GRAPHIC, V21, P465; O'Sullivan C, 2003, ACM T GRAPHIC, V22, P527, DOI 10.1145/882262.882303; Pavlovic V., 2000, P ADV NEUR INF PROC, P981; PERLIN K, 1995, IEEE T VIS COMPUT GR, V1, P5, DOI 10.1109/2945.468392; POLLICK F, 2003, P 3 INT WORKSH EP RO, V101, P107; Rabiner L, 1993, FUNDAMENTALS SPEECH; Reitsma PSA, 2003, ACM T GRAPHIC, V22, P537, DOI 10.1145/882262.882304; Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559; Soatto S., 2001, INT C COMP VIS VANC, P439; Sulejmanpasic A, 2005, ACM T GRAPHIC, V24, P165, DOI 10.1145/1037957.1037966; Troje NF, 2002, J VISION, V2, P371, DOI 10.1167/2.5.2; Van Trees H. L., 1968, DETECTION ESTIMATION, V1; Wang J., 2003, P 2003 ACM SIGGRAPH, P232; Wang J., 2004, P ACM SIGGRAPH EUR S, P335, DOI 10.1145/1028523.1028568; Wiley DJ, 1997, IEEE COMPUT GRAPH, V17, P39, DOI 10.1109/38.626968; ZHONG H, 2004, IEEE C COMP VIS PATT, V2, P819	30	31	34	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	0730-0301		ACM T GRAPHIC	ACM Trans. Graph.	JUL	2005	24	3					1090	1097		10.1145/1073204.1073316		8	Computer Science, Software Engineering	Computer Science	955KB	WOS:000231223700092	
J	Dachwald, B				Dachwald, B			Optimization of very-low-thrust trajectories using evolutionary neurocontrol	ACTA ASTRONAUTICA			English	Article; Proceedings Paper	55th International-Astronautical-Federation Congress	2004	Vancouver, CANADA	Int Astronaut Federat				Searching optimal interplanetary trajectories for low-thrust spacecraft is usually a difficult and time-consuming task that involves much experience and expert knowledge in astrodynamics and optimal control theory. This is because the convergence behavior of traditional local optimizers, which are based on numerical optimal control methods, depends on an adequate initial guess, which is often hard to find, especially for very-low-thrust trajectories that necessitate many revolutions around the sun. The obtained solutions are typically close to the initial guess that is rarely close to the (unknown) global optimum. Within this paper, trajectory optimization problems are attacked from the perspective of artificial intelligence and machine learning. Inspired by natural archetypes, a smart global method for low-thrust trajectory optimization is proposed that fuses artificial neural networks and evolutionary algorithms into so-called evolutionary neurocontrollers. This novel method runs without an initial guess and does not require the attendance of an expert in astrodynamics and optimal control theory. This paper details how evolutionary neurocontrol works and how it could be implemented. The performance of the method is assessed for three different interplanetary missions with a thrust to mass ratio < 0.15 mN/kg (solar sail and nuclear electric). (c) 2005 Elsevier Ltd. All rights reserved.	German Aerosp Ctr, Inst Space Simulat, D-51170 Cologne, Germany	Dachwald, B (reprint author), German Aerosp Ctr, Inst Space Simulat, D-51170 Cologne, Germany.	bemd.dachwald@dlr.de					COVERSTONECARROLL, 2000, COMPUT METHOD APPL M, V186, P387; DACHWALD B, 2004, LOW THRUST TRAJECTOR; DRACOPOULOS DC, 1997, EVOLUTIONARY LEARNIN; FORTESCUE P, 1995, SAPCECRAFT SYSTEMS E; JESSBERGER EK, ENEAS EXPLORATION NE; KEERTHI S, 1995, TUTORIAL SURVEY REIN; ROJAS R, 1994, MATH ASPEKTE ANGEWAN, P58; Santo AG, 2001, PLANET SPACE SCI, V49, P1481, DOI 10.1016/S0032-0633(01)00087-3; SEBOLDT W, 51 INT ASTR C; Stengel R. F., 1994, OPTIMAL CONTROL ESTI; Sutton R.S., 1998, REINFORCEMENT LEARNI; TSINAS L, 1994, P 1 IEEE C EV COMP I, V2, P770; VASILE M, AAS AIAA SPAC FLIGHT; WHITLEY D, 1993, MACH LEARN, V13, P259, DOI 10.1023/A:1022674030396; Yao X., 1995, ENCY COMP S, V33, P137; *QINETIQ, T6 ION PROP SYST	16	10	10	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0094-5765		ACTA ASTRONAUT	Acta Astronaut.	JUL-OCT	2005	57	2-8					175	185		10.1016/j.actaastro.2005.03.004		11	Engineering, Aerospace	Engineering	938QM	WOS:000230017900016	
J	Lv, G; Cheng, HZ; Zhai, HB; Dong, LX				Lv, G; Cheng, HZ; Zhai, HB; Dong, LX			Fault diagnosis of power transformer based on multi-layer SVM classifier	ELECTRIC POWER SYSTEMS RESEARCH			English	Article						fault diagnosis; multi-layer SVM classifier; power transformer; reliability	DISSOLVED-GAS ANALYSIS; INCIPIENT FAULTS; NEURAL NETWORKS; EXPERT-SYSTEM	Support vector machine (SVM) is a novel machine learning method based on statistical learning theory (SLT). SVM is powerful for the problem with small sampling, nonlinear and high dimension. A multi-layer SVM classifier is applied to fault diagnosis of power transformer for the first time in this paper. Content of five diagnostic gases dissolved in oil obtained by dissolved gas analysis (DGA) is preprocessed through a special data processing, and six features are extracted for SVMs. Then the multi-layer SVM classifier is trained with the training samples which are extracted by the above data processing. Finally, the four fault types of transformer are identified by the trained classifier. The test results show that the classifier has an excellent performance on training speed and reliability. (c) 2005 Elsevier B.V. All rights reserved.	Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai 200030, Peoples R China	Lv, G (reprint author), Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai 200030, Peoples R China.	ganyun_lv@yahoo.com; chenghz@online.sh.cn					Su Q, 2000, IEEE T POWER SYST, V15, P593, DOI 10.1109/59.867146; Chan WC, 2001, ENG APPL ARTIF INTEL, V14, P105, DOI 10.1016/S0952-1976(00)00069-5; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; DUKARM JJ, 1993, CAN C EL COMP ENG, V1, P329; HONG TY, 1999, IEEE T POWER DELIVER, V14, P1342; Huang YC, 1997, IEEE T POWER DELIVER, V12, P761; Jack LB, 2002, MECH SYST SIGNAL PR, V16, P373, DOI 10.1006/mssp.2001.1454; LIN CE, 1993, IEEE T POWER DELIVER, V8, P231, DOI 10.1109/61.180341; Lu J. W., 2001, P IEEE INT WORKSH NE, P373; Mofizul Islam S., 2000, IEEE Transactions on Dielectrics and Electrical Insulation, V7, DOI 10.1109/94.841806; Purkait P., 2000, POW ENG SOC WINT M, V<IT>3</IT>, P2181; ROGERS RR, 1978, IEEE T ELECTR INSUL, V13, P349, DOI 10.1109/TEI.1978.298141; Saha TK, 2003, IEEE T DIELECT EL IN, V10, P903, DOI 10.1109/TDEI.2003.1237337; Tay FR, 2004, OPER DENT, V29, P309; Thang KF, 2003, IEEE T POWER DELIVER, V18, P1241, DOI 10.1109/TPWRD.2003.817733; Vapnik V. N, 1995, NATURE STAT LEARNING; Wang MH, 2003, IEEE T POWER DELIVER, V18, P164, DOI 10.1109/TPWRD.2002.803838; Wang MH, 2003, IEE P-GENER TRANSM D, V150, P679, DOI 10.1049/ip-gtd:20030901; Wang ZY, 1998, IEEE T POWER DELIVER, V13, P1224; Yan WW, 2002, PROCEEDINGS OF THE 4TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-4, P2697; YANN CH, 2003, IEEE T POWER DELIVER, V18, P1257; YANN CH, 2003, IEEE T POWER DELIVER, V18, P843; Zhang Y, 1996, IEEE T POWER DELIVER, V11, P1836, DOI 10.1109/61.544265	23	22	24	ELSEVIER SCIENCE SA	LAUSANNE	PO BOX 564, 1001 LAUSANNE, SWITZERLAND	0378-7796		ELECTR POW SYST RES	Electr. Power Syst. Res.	JUL	2005	75	1					9	15		10.1016/j.epsr.2004.07.013		7	Engineering, Electrical & Electronic	Engineering	933WE	WOS:000229662800002	
J	Ong, CS; Huang, JJ; Tzeng, GH				Ong, CS; Huang, JJ; Tzeng, GH			Building credit scoring models using genetic programming	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						credit scorings; artificial neural network (ANN); decision trees; genetic programming (GP); rough sets	ROUGH SET-THEORY; BUSINESS FAILURE PREDICTION; NEURAL-NETWORK; REGRESSION; METHODOLOGY	Credit scoring models have been widely studied in the areas of statistics, machine learning, and artificial intelligence (AI). Many novel approaches such as artificial neural networks (ANNs), rough sets, or decision trees have been proposed to increase the accuracy of credit scoring models. Since an improvement in accuracy of a fraction of a percent might translate into significant savings, a more sophisticated model should be proposed to significantly improving the accuracy of the credit scoring mode. In this paper, genetic programming (GP) is used to build credit scoring models. Two numerical examples will be employed here to compare the error rate to other credit scoring models including the ANN, decision trees, rough sets, and logistic regression. On the basis of the results, we can conclude that GP can provide better performance than other models. (c) 2005 Elsevier Ltd. All rights reserved.	Natl Chiao Tung Univ, Inst Management Technol, Hsinchu 1001, Taiwan; Natl Taiwan Univ, Dept Informat Management, Taipei, Taiwan; Kainan Univ, Coll Management, Tao Yuan, Taiwan	Tzeng, GH (reprint author), Natl Chiao Tung Univ, Inst Management Technol, Ta Hsuch Rd, Hsinchu 1001, Taiwan.	ghtzeng@cc.nctu.edu.tw	Tzeng, Gwo-Hshiung/B-2775-2009				Agresti A., 1990, CATEGORICAL DATA ANA; Ahn BS, 2000, EXPERT SYST APPL, V18, P65, DOI 10.1016/S0957-4174(99)00053-6; Aldrich J, 1984, LINEAR PROBABILITY L; Beynon MJ, 2001, OMEGA-INT J MANAGE S, V29, P561, DOI 10.1016/S0305-0483(01)00045-7; Castillo F, 2003, LECT NOTES COMPUT SC, V2724, P1975; Chakrabarty K, 2000, FUZZY SET SYST, V110, P247, DOI 10.1016/S0165-0114(97)00414-4; Chung H. M., 1999, J MANAGEMENT INFORMA, V16, P11; Craven M.W., 1997, FUTURE GENER COMP SY, V13, P221; Davidson JW, 2003, INFORM SCIENCES, V150, P95, DOI 10.1016/S0020-0255(02)00371-7; DeMaris A., 1992, LOGIT MODELING; DESAI VS, 1997, IMA J MATH APPL BUSI, V8, P324; Desai VS, 1996, EUR J OPER RES, V95, P24, DOI 10.1016/0377-2217(95)00246-4; Dimitras AI, 1999, EUR J OPER RES, V114, P263, DOI 10.1016/S0377-2217(98)00255-0; Dubois D., 1991, ROUGH SETS THEORETIC, pix; Feraud R, 2002, NEURAL NETWORKS, V15, P237, DOI 10.1016/S0893-6080(01)00127-7; Grzymala-Busse J. W., 1988, Journal of Intelligent and Robotic Systems: Theory and Applications, V1, DOI 10.1007/BF00437317; Jensen H. L., 1992, MANAGE FINANC, V18, P15; Knoke D, 1980, LOG LINEAR MODELS; Koza J. R., 1992, GENETIC PROGRAMMING; Lee TS, 2002, EXPERT SYST APPL, V23, P245, DOI 10.1016/S0957-4174(02)00044-1; Liao Tim Futing, 1994, INTERPRETING PROBABI; MAHLHOTRA R, 2003, OMEGA-INT J MANAGE S, V31, P83; MCCULLAGH P, 1980, J ROY STAT SOC B MET, V42, P109; Mordeson JN, 2001, FUZZY SET SYST, V121, P315, DOI 10.1016/S0165-0114(00)00023-3; Nath R, 1997, COMPUT OPER RES, V24, P767, DOI 10.1016/S0305-0548(96)00088-3; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Pawlak Z., 1995, Communications of the ACM, V38, DOI 10.1145/219717.219791; Piramuthu S, 1999, EUR J OPER RES, V112, P310, DOI 10.1016/S0377-2217(97)00398-6; PRESS SJ, 1978, J AM STAT ASSOC, V73, P699, DOI 10.2307/2286261; Radzikowska A., 2002, FUZZY SETS SYSTEMS, V126, P137, DOI 10.1016/S0165-0114(01)00032-X; Shan N., 1996, P 4 INT WORKSH ROUGH, P74; STEFANO CD, 2002, PATTERN RECOGN, V23, P1439; Walczak B, 1999, CHEMOMETR INTELL LAB, V47, P1, DOI 10.1016/S0169-7439(98)00200-7; West D, 2000, COMPUT OPER RES, V27, P1131, DOI 10.1016/S0305-0548(99)00149-5; Wu XD, 1996, COMPUT J, V39, P688, DOI 10.1093/comjnl/39.8.688; Zhang YF, 2004, INFORM SCIENCES, V163, P85, DOI 10.1016/j.ins.2003.03.028	36	80	81	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	JUL	2005	29	1					41	47		10.1016/j.eswa.2005.01.003		7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	922MZ	WOS:000228843300004	
J	Wang, FH				Wang, FH			On acquiring classification knowledge from noisy data based on rough set	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						classification; rough set; noisy information system; lower approximation; information granule; randomization analysis	MODEL	Induction of classification rules based on rough set theory has been an active research area in the field of machine learning. However, pure rough set theory is not well suited for analyzing noisy information systems. This paper adopts a generalization of rough set model based on fuzzy lower approximation with respect to information granules. Based on the fuzzy lower approximation, a concept of tolerant approximation is introduced to deal with the problem of discovering effective rules from noisy data. An efficient rule induction algorithm based on the tolerant lower approximation is proposed, and two heuristics are investigated to study their inductive effectiveness. Empirical experiments are conducted on five real-life data sets, acknowledged in the machine learning community, using the algorithms. The Tree classification algorithm from the IBM Intelligent Miner is also investigated as a comparison basis. Effectiveness measurements include the prediction accuracy, cost ratio and the rule validation rate based on randomization analysis. The empirical evidences show that the proposed algorithm is effective in dealing with rule induction in noisy environments. (c) 2005 Elsevier Ltd. All rights reserved.	Ming Chuan Univ, Dept Comp Sci & Informat Engn, Taoyuan 333, Taiwan	Wang, FH (reprint author), Ming Chuan Univ, Dept Comp Sci & Informat Engn, 5 Teh Ming Rd,Gwei Shan Dist, Taoyuan 333, Taiwan.	fhwang@mcu.edu.tw					Bell DA, 1998, J AM SOC INFORM SCI, V49, P403, DOI 10.1002/(SICI)1097-4571(19980415)49:5<403::AID-ASI3>3.3.CO;2-#; Blake C. L., 1998, UCI REPOSITORY MACHI; DEVORE J, 1999, APPL STAT ENG SCI, P315; Duntsch I, 1997, INT J HUM-COMPUT ST, V46, P589, DOI 10.1006/ijhc.1996.0105; Komorouski J., 1999, ROUGH FUZZY HYBRIDIZ, P3; Kryszkiewicz M, 1998, INFORM SCIENCES, V112, P39, DOI 10.1016/S0020-0255(98)10019-1; LIANG J, 2000, 3 WORLD C INT CONTR, P2526; Lingras PJ, 1998, J AM SOC INFORM SCI, V49, P415, DOI 10.1002/(SICI)1097-4571(19980415)49:5<415::AID-ASI4>3.3.CO;2-Q; MICHALSKI RS, 1986, UIUDCDR861260 DEP CO; Nguyen SH, 2001, COMPUT INTELL, V17, P514, DOI 10.1111/0824-7935.00161; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Pawlak Z, 1999, INT J HUM-COMPUT ST, V51, P369, DOI 10.1006/ijhc.1983.0315; PIASTA Z, 1996, 2496 ICS WARS U TECH; Quinlan JR, 1999, INT J HUM-COMPUT ST, V51, P497, DOI 10.1006/ijhc.1987.0321; SEVER H, 1998, P 2 INT C NONL PROBL, V2, P673; Slowinski R., 1992, INTELLIGENT DECISION; Stefanowski J., 1998, ROUGH SETS DATA MINI, P500; TSUMOTO S, 2000, IEEE EMB MAGAZINE, P56; Wang F. H, 2001, LECT NOTES ARTIF INT, P161; WONG SKM, 1986, INT J FUZZY SETS SYS, V21, P357; ZIARKO W, 2002, FRONTIERS AI APPL, V87, P442; Ziarko W, 1999, LECT NOTES ARTIF INT, V1711, P463; ZIARKO W, 1993, J COMPUT SYST SCI, V46, P39, DOI 10.1016/0022-0000(93)90048-2; 1991, ROUGH SETS THEORETIC	24	18	21	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	JUL	2005	29	1					49	64		10.1016/j.eswa.2005.01.005		16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	922MZ	WOS:000228843300005	
J	Kell, DB				Kell, DB			Metabolomics, modelling and machine learning in systems biology; understanding complex systems using genetic programming to produce simple interpretable rules. The Theodor Bucher Lecture and Medal	FEBS JOURNAL			English	Meeting Abstract	IUBMB 50th Anniversary Symposium	JUL 02-07, 2005	Budapest, HUNGARY	Int Union Biochem Molecular Biol			HYPOTHESIS		Univ Manchester, Manchester, Lancs, England		dbk@manchester.ac.uk	Kell, Douglas/E-8318-2011				BRENNER S, 1980, NATURE          0605; Goodacre R, 2004, TRENDS BIOTECHNOL, V22, P245, DOI 10.1016/j.tibtech.2004.03.007; Ihekwaba A. E. C., 2004, Systems Biology, V1, P93, DOI 10.1049/sb:20045009; Kell DB, 2004, CURR OPIN MICROBIOL, V7, P296, DOI 10.1016/j.mib.2004.04.012; Kell DB, 2004, BIOESSAYS, V26, P99, DOI 10.1002/bies.10385; King RD, 2004, NATURE, V427, P247, DOI 10.1038/nature02236; Nelson DE, 2004, SCIENCE, V306, P704, DOI 10.1126/science.1099962; O'Hagan S, 2005, ANAL CHEM, V77, P290, DOI 10.1021/ac049146x	8	0	0	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	1742-464X		FEBS J	FEBS J.	JUL	2005	272			1			2	2				1	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	005MG	WOS:000234826100004	
J	Jemwa, GT; Aldrich, C				Jemwa, GT; Aldrich, C			Monitoring of an industrial liquid-liquid extraction system with kernel-based methods	HYDROMETALLURGY			English	Article						liquid-liquid extraction; kernel-based methods; process monitoring; fault detection; fault identification; support vector machines	NEURAL NETS	The behaviour of liquid-liquid extraction systems can be complex and as a result linear methods of process condition monitoring such as principal component analysis or partial least squares may not be able to detect and identify process faults when they occur. In contrast, kemel-based methods represent a general framework that can be used where linear methods do not perform satisfactorily. This is demonstrated in a case study on an industrial liquid-liquid extraction system, where a linear discriminant analysis problem is recast as a support vector machine learning problem. The support vector machine is subsequently used to extract features from the plant data that can be used for considerably more accurate fault detection than is possible with its linear equivalent or with other nonlinear methods. Fault identification can be accomplished from an analysis of the residuals of models using the features to reconstruct the original plant data. (c) 2005 Elsevier B.V. All rights reserved.	Univ Stellenbosch, Dept Proc Engn, ZA-7602 Stellenbosch, South Africa	Aldrich, C (reprint author), Univ Stellenbosch, Dept Proc Engn, Private Bag 11,Matieland, ZA-7602 Stellenbosch, South Africa.	ca1@sun.ac.za					Aldrich C, 2001, APPLICATION OF NEURAL NETWORKS AND OTHER LEARNING TECHNOLOGIES IN PROCESS ENGINEERING, P3, DOI 10.1142/9781848161467_0001; ALDRICH C, 1995, CHEM ENG, P11; Bakir GH, 2004, ADV NEUR IN, V16, P449; Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; BOGER Z, 1993, P ISEC 93 SOLV EXTR, P1198; Chouai A, 2000, CHEM ENG PROCESS, V39, P171, DOI 10.1016/S0255-2701(99)00086-0; Cristianini N., 2000, INTRO SUPPORT VECTOR; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fukunaga K., 1990, INTRO STAT PATTERN R; GARDNER S, 2001, THESIS U STELLENBOSC; Giles AE, 1996, HYDROMETALLURGY, V43, P241, DOI 10.1016/0304-386X(95)00098-2; Hastie T, 2001, ELEMENTS STAT LEARNI; KOURTI T, 1995, CHEMOMETR INTELL LAB, V28, P3, DOI 10.1016/0169-7439(94)00079-X; MARTIN EB, 1996, SYSTEMS ENG AUTOMATI, V143, P132; Mika S., 1999, P IEEE NEUR NETW SIG, P41; Montgomery D. C., 1992, INTRO LINEAR REGRESS; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Rousseeuw PJ, 1999, AM STAT, V53, P382, DOI 10.2307/2686061; Ruts I, 1996, COMPUT STAT DATA AN, V23, P153, DOI 10.1016/S0167-9473(96)00027-8; Scholkopf B, 1999, IEEE T NEURAL NETWOR, V10, P1000, DOI 10.1109/72.788641; Scholkopf B., 2002, LEARNING KERNELS SUP; Vapnik VN, 1998, STAT LEARNING THEORY; Woinaroschy A, 1998, HUNG J IND CHEM, V26, P121	23	1	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-386X		HYDROMETALLURGY	Hydrometallurgy	JUL	2005	78	1-2					41	51		10.1016/j.hydromet.2005.03.003		11	Metallurgy & Metallurgical Engineering	Metallurgy & Metallurgical Engineering	948UD	WOS:000230740300005	
J	Ling, CX; Noble, WS; Yang, Q				Ling, CX; Noble, WS; Yang, Q			Guest editor's introduction to the special issue: Machine learning for bioinformatics - Part 2	IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS			English	Editorial Material									Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada; Univ Washington, Dept Genome Sci, Seattle, WA 98195 USA; Hong Kong UST, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China	Ling, CX (reprint author), Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada.	cling@csd.uwo.ca; noble@gs.washington.edu; qyang@cs.ust.hk						0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1545-5963		IEEE ACM T COMPUT BI	IEEE-ACM Trans. Comput. Biol. Bioinform.	JUL-SEP	2005	2	3					177	178		10.1109/TCBB.2005.41		2	Biochemical Research Methods; Computer Science, Interdisciplinary Applications; Mathematics, Interdisciplinary Applications; Statistics & Probability	Biochemistry & Molecular Biology; Computer Science; Mathematics	017OZ	WOS:000235704200001	
J	Kaski, S; Nikkila, J; Sinkkonen, J; Lahti, L; Knuuttila, JEA; Roos, C				Kaski, S; Nikkila, J; Sinkkonen, J; Lahti, L; Knuuttila, JEA; Roos, C			Associative clustering for exploring dependencies between functional genomics data sets	IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS			English	Article						biology and genetics; clustering; contingency table analysis; machine learning; multivariate statistics	GENE-EXPRESSION DATA; SACCHAROMYCES-CEREVISIAE; CELL-CYCLE; NETWORKS; TRANSCRIPTOMES; DISTRIBUTIONS; EVOLUTION; PROFILES; PATHWAYS; PATTERNS	High-throughput genomic measurements, interpreted as cooccurring data samples from multiple sources, open up a fresh problem for machine learning: What is in common in the different data sets, that is, what kind of statistical dependencies are there between the paired samples from the different sets? We introduce a clustering algorithm for exploring the dependencies. Samples within each data set are grouped such that the dependencies between groups of different sets capture as much of pairwise dependencies between the samples as possible. We formalize this problem in a novel probabilistic way, as optimization of a Bayes factor. The method is applied to reveal commonalities and exceptions in gene expression between organisms and to suggest regulatory interactions in the form of dependencies between gene expression profiles and regulator binding patterns.	Univ Helsinki, Dept Comp Sci, FI-00014 Helsinki, Finland; Helsinki Univ Technol, Neural Networks Res Ctr, FI-02015 Espoo, Finland; Univ Helsinki, Ctr Neurosci, FI-00014 Helsinki, Finland; Medicel Oy, FI-00350 Helsinki, Finland	Kaski, S (reprint author), Univ Helsinki, Dept Comp Sci, POB 68, FI-00014 Helsinki, Finland.	samuel.kaski@cs.helsinki.fi; janne.nikkila@hut.fi; janne.sinkkonen@hut.fi; leo.lahtij@hut.fi; Juha.Knuuttila@helsinki.fi; christophe.roos@helsinki.fi	Knuuttila, Juha/A-3193-2009; Lahti, Leo/G-3170-2010				Bazaraa M. S., 1993, NONLINEAR PROGRAMMIN; BECKER S, 1992, NATURE, V355, P161, DOI 10.1038/355161a0; Becker S, 1996, NETWORK-COMP NEURAL, V7, P7, DOI 10.1088/0954-898X/7/1/003; Beer MA, 2004, CELL, V117, P185, DOI 10.1016/S0092-8674(04)00304-6; Ben-Dor A, 2000, J COMPUT BIOL, V7, P559, DOI 10.1089/106652700750050943; Bergmann S, 2004, PLOS BIOL, V2, P85, DOI 10.1371/journal.pbio.0020009; Bishop C.M., 1995, NEURAL NETWORKS PATT; Bono H, 2002, CURR OPIN STRUC BIOL, V12, P355, DOI 10.1016/S0959-440X(02)00335-4; Ashburner M, 2000, NAT GENET, V25, P25; Carroll SB, 2003, NATURE, V422, P849, DOI 10.1038/nature01495; Cho RJ, 1998, MOL CELL, V2, P65, DOI 10.1016/S1097-2765(00)80114-8; Clark AG, 2003, SCIENCE, V302, P1960, DOI 10.1126/science.1088821; Efron B., 1993, INTRO BOOTSTRAP; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Enard W, 2002, SCIENCE, V296, P340, DOI 10.1126/science.1068996; EWING RM, 2000, PAC S BIOCOMPUT, V5, P427; Friedman N., 2001, P 17 C UNC ART INT U, P152; Ganti V., 1999, Proceedings of the Eighteenth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, DOI 10.1145/303976.303989; Ge H, 2001, NAT GENET, V29, P482, DOI 10.1038/ng776; GOOD IJ, 1976, ANN STAT, V4, P1159, DOI 10.1214/aos/1176343649; Hastie T, 2001, ELEMENTS STAT LEARNI; Horak CE, 2002, GENE DEV, V16, P3017, DOI 10.1101/gad.1039602; HOSACK DA, 2003, GENOME BIOL, V4, P70; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Hughes TR, 2000, CELL, V102, P109, DOI 10.1016/S0092-8674(00)00015-5; Jimenez JL, 2003, GENOME BIOL, V4; KASKI S, IN PRESS NEUROCOMPUT; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.2307/2291091; Kerr MK, 2001, P NATL ACAD SCI USA, V98, P8961, DOI 10.1073/pnas.161273698; Khaitovich P, 2004, PLOS BIOL, V2, P682, DOI 10.1371/journal.pbio.0020132; Lee TI, 2002, SCIENCE, V298, P799, DOI 10.1126/science.1075090; McLachlan G. J., 2004, ANAL MICROARRAY GENE; Neves SR, 2002, SCIENCE, V296, P1636, DOI 10.1126/science.1071550; Nikkila J, 2002, NEURAL NETWORKS, V15, P953, DOI 10.1016/S0893-6080(02)00070-9; PELTONEN J, 2004, P 21 INT C MACH LEAR, P647; Segal E, 2003, NAT GENET, V34, P166, DOI 10.1038/ng1165; SINKKONEN J, 2004, P 15 EUR C MACH LEAR, P396; SINKKONEN J, 2005, PUBLICATIONS COMPUTE; Sinkkonen J, 2002, NEURAL COMPUT, V14, P217, DOI 10.1162/089976602753284509; Slonim N., 2002, THESIS HEBREW U; Slonim N., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Su AI, 2002, P NATL ACAD SCI USA, V99, P4465, DOI 10.1073/pnas.012025199; Tishby N., 1999, P 37 ANN ALL C COMM, P368; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; Wheeler DL, 2003, NUCLEIC ACIDS RES, V31, P28, DOI 10.1093/nar/gkg033	46	6	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1545-5963		IEEE ACM T COMPUT BI	IEEE-ACM Trans. Comput. Biol. Bioinform.	JUL-SEP	2005	2	3					203	216		10.1109/TCBB.2005.32		14	Biochemical Research Methods; Computer Science, Interdisciplinary Applications; Mathematics, Interdisciplinary Applications; Statistics & Probability	Biochemistry & Molecular Biology; Computer Science; Mathematics	017OZ	WOS:000235704200004	
J	Hawkins, J; Boden, M				Hawkins, J; Boden, M			The applicability of recurrent neural networks for biological sequence analysis	IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS			English	Article						machine learning; neural network architecture; recurrent neural network; bias; biological sequence analysis; motif; subcellular localization; pattern recognition; classifier design	PROTEIN SECONDARY STRUCTURE; ARCHITECTURAL BIAS; PREDICTION	Selection of machine learning techniques requires a certain sensitivity to the requirements of the problem. In particular, the problem can be made more tractable by deliberately using algorithms that are biased toward solutions of the requisite kind. In this paper, we argue that recurrent neural networks have a natural bias toward a problem domain of which biological sequence analysis tasks are a subset. We use experiments with synthetic data to illustrate this bias. We then demonstrate that this bias can be exploitable using a data set of protein sequences containing several classes of subcellular localization targeting peptides. The results show that, compared with feed forward, recurrent neural networks will generally perform better on sequence analysis tasks. Furthermore, as the patterns within the sequence become more ambiguous, the choice of specific recurrent architecture becomes more critical.	Univ Queensland, Sch Informat Technol & Elect Engn, St Lucia, Qld 4072, Australia	Hawkins, J (reprint author), Univ Queensland, Sch Informat Technol & Elect Engn, St Lucia, Qld 4072, Australia.	jhawkins@itee.uq.edu.au; mikael@itee.uq.edu.au	Boden, Mikael/A-6030-2010				Altschul S. F., 1990, J MOL BIOL, V215, P403; BAILEY TL, 1999, PATTERN DISCOVERY BI, P30; Baldi P., 2001, BIOINFORMATICS MACHI; Baldi P, 1999, BIOINFORMATICS, V15, P937, DOI 10.1093/bioinformatics/15.11.937; Christiansen MH, 1999, COGNITIVE SCI, V23, P157, DOI 10.1207/s15516709cog2302_2; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1016/0364-0213(90)90002-E; Emanuelsson Olof, 2002, Brief Bioinform, V3, P361, DOI 10.1093/bib/3.4.361; Emanuelsson O, 2000, J MOL BIOL, V300, P1005, DOI 10.1006/jmbi.2000.3903; Hammer B, 2003, NEURAL COMPUT, V15, P1897, DOI 10.1162/08997660360675080; Janulczyk R, 2001, INFECT IMMUN, V69, P4019, DOI 10.1128/IAI.69.6.4019-4026.2001; Kall L, 2004, J MOL BIOL, V338, P1027, DOI 10.1016/j.jmb.2004.03.016; KOLEN JF, 1994, PROCEEDINGS OF THE 1993 CONNECTIONIST MODELS SUMMER SCHOOL, P203; Ma B, 2002, BIOINFORMATICS, V18, P440, DOI 10.1093/bioinformatics/18.3.440; MITCHELL T, 1980, READINGS MACHINE LEA; POLLACK JB, 1991, MACH LEARN, V7, P227, DOI 10.1007/BF00114845; Pollastri G, 2002, PROTEINS, V47, P228, DOI 10.1002/prot.10082; SCHNEIDER TD, 1990, NUCLEIC ACIDS RES, V18, P6097, DOI 10.1093/nar/18.20.6097; Tino P, 2003, NEURAL COMPUT, V15, P1931, DOI 10.1162/08997660360675099; Tino P, 2004, IEEE T NEURAL NETWOR, V15, P6, DOI 10.1109/TNN.2003.820839; VULLO A, 2003, P 2003 ACM S APPL CO, P67; Williams EJB, 2000, GENE, V253, P313, DOI 10.1016/S0378-1119(00)00233-X	21	10	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1545-5963		IEEE ACM T COMPUT BI	IEEE-ACM Trans. Comput. Biol. Bioinform.	JUL-SEP	2005	2	3					243	253		10.1109/TCBB.2005.44		11	Biochemical Research Methods; Computer Science, Interdisciplinary Applications; Mathematics, Interdisciplinary Applications; Statistics & Probability	Biochemistry & Molecular Biology; Computer Science; Mathematics	017OZ	WOS:000235704200007	
J	Demir, C; Gultekin, SH; Yener, B				Demir, C; Gultekin, SH; Yener, B			Learning the topological properties of brain tumors	IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS			English	Article						image representation; machine learning; model development; graph theory; medical information systems	BREAST-CANCER DIAGNOSIS; IDENTIFICATION; CLASSIFICATION; NETWORKS; CYTOLOGY	This work presents a graph-based representation (a.k.a., cell-graph) of histopathological images for automated cancer diagnosis by probabilistically assigning a link between a pair of cells (or cell clusters). Since the node set of a cell-graph can include a cluster of cells as well as individual ones, it enables working with low-cost, low-magnification photomicrographs. The contributions of this work are twofold. First, it is shown that without establishing a pairwise spatial relation between the cells (i.e., the edges of a cell-graph), neither the spatial distribution of the cells nor the texture analysis of the images yields accurate results for tissue level diagnosis of brain cancer called malignant glioma. Second, this work defines a set of global metrics by processing the entire cell-graph to capture tissue level information coded into the histopathological images. In this work, the results are obtained on the photomicrographs of 646 archival brain biopsy samples of 60 different patients. It is shown that the global metrics of cell-graphs distinguish cancerous tissues from noncancerous ones with high accuracy (at least 99 percent accuracy for healthy tissues with lower cellular density level, and at least 92 percent accuracy for benign tissues with similar high cellular density level such as nonneoplastic reactive/inflammatory conditions).	Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA; Mt Sinai Sch Med, Dept Pathol, New York, NY 10021 USA	Demir, C (reprint author), Rensselaer Polytech Inst, Dept Comp Sci, 110 8th St, Troy, NY 12180 USA.	demir@cs.rpi.edu; gultekin@ohsu.edu; yener@cs.rpi.edu					Antal P., 2000, Proceedings 13th IEEE Symposium on Computer-Based Medical Systems. CBMS 2000, DOI 10.1109/CBMS.2000.856886; Bishop C.M., 1995, NEURAL NETWORKS PATT; Chickering D. M., 1996, LEARNING DATA ARTIFI, P121; CVETKOVIC DM, 1978, SPECTRA GRAPH; DOROGOVTSEV SN, 2002, ADV PHYS ORGANIC CHE, V51, P1979; Einstein AJ, 1998, J PATHOL, V185, P366; Esgiar AN, 1998, ANAL QUANT CYTOL, V20, P297; Esgiar AN, 2002, IEEE T INF TECHNOL B, V6, P54, DOI 10.1109/4233.992163; Esgiar A N, 1998, IEEE Trans Inf Technol Biomed, V2, P197; Faloutsos M., 1999, P ACM SIGCOMM, P251, DOI 10.1145/316188.316229; GANSTER H, 2001, IEEE T MED IMAGING, V3, P233; Glotsos D., 2003, Proceedings of the International Conference of Computational Methods in Sciences and Engineering 2003 (ICCMSE 2003); Gunduz Cigdem, 2004, Bioinformatics, V20 Suppl 1, pi145, DOI 10.1093/bioinformatics/bth933; Hamilton PW, 1997, J PATHOL, V182, P68; HAMILTON PW, 1987, HISTOPATHOLOGY, V11, P901, DOI 10.1111/j.1365-2559.1987.tb01897.x; Hartigan J. A., 1979, Applied Statistics, V28, DOI 10.2307/2346830; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891; Jain R, 2004, AUSTRALIASIAN PHYS E; MANGASARIAN OL, 1995, OPER RES, V43, P570, DOI 10.1287/opre.43.4.570; Pena-Reyes CA, 1999, ARTIF INTELL MED, V17, P131, DOI 10.1016/S0933-3657(99)00019-6; Schnorrenberg F, 1996, Technol Health Care, V4, P147; Tasoulis D.K., 2003, P KNOWL BAS INT INF, P199; Todman AG, 2001, P CAN C EL COMP ENG, V2, P1379; WOLBERG WH, 1995, HUM PATHOL, V26, P792, DOI 10.1016/0046-8177(95)90229-5; Wyszecki G, 2000, COLOR SCI CONCEPTS M; Zhou ZH, 2002, ARTIF INTELL MED, V24, P25, DOI 10.1016/S0933-3657(01)00094-X	27	14	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1545-5963		IEEE ACM T COMPUT BI	IEEE-ACM Trans. Comput. Biol. Bioinform.	JUL-SEP	2005	2	3					262	270		10.1109/TCBB.2005.42		9	Biochemical Research Methods; Computer Science, Interdisciplinary Applications; Mathematics, Interdisciplinary Applications; Statistics & Probability	Biochemistry & Molecular Biology; Computer Science; Mathematics	017OZ	WOS:000235704200009	
J	Song, C; Guan, XH; Zhao, QC; Ho, YC				Song, C; Guan, XH; Zhao, QC; Ho, YC			Machine learning approach for determining feasible plans of a remanufacturing system	IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING			English	Article						manufacturing planning; remanufacturing systems; rough set theory; simulation-based optimization	ROUGH SET-THEORY; ORDINAL OPTIMIZATION; IMPACT	Resource planning for a complex remanufacturing system is in general extremely difficult in terms of, e.g., problem size and uncertainties. In many cases, simulation is the only way to select a good plan among a great number of candidates. When there exist complicated constraints, direct selection could be very inefficient since many candidates may not be feasible but cannot be excluded beforehand. To meet the challenge, a machine learning method is introduced in this paper to perform feasibility analysis. The rough set theory is first applied to establish the relationship between a plan and its feasibility and an iterative reinforcement process is applied to enhance confidence. The numerical testing results show that this method is promising and scalable for the large-scale problems. The research lays a basis for developing an efficient simulation-based optimization method with complicated constraints.	Xian Jiaotong Univ, SKLMS, Lab & Syst Engn Inst, Xian 710049, Peoples R China; Tsinghua Univ, Ctr Intelligent & Networked Syst, Beijing 100084, Peoples R China; Harvard Univ, Div Engn & Appl Sci, Cambridge, MA 02138 USA	Song, C (reprint author), Xian Jiaotong Univ, SKLMS, Lab & Syst Engn Inst, Xian 710049, Peoples R China.	csong@sei.xjtu.edu.cn; xhguan@tsinghua.edu.cn; zhaoqc@tsinghua.edu.cn; ho@hrl.harvard.edu					AARONSON S, COMPLEXITY ZOO; Berardi VL, 1999, INT J PROD ECON, V58, P253, DOI 10.1016/S0925-5273(98)00211-4; Bertrand J.W.M., 1990, PRODUCTION CONTROL S; Black PE, DICT ALGORITHMS DATA; Cai ZM, 2003, EXPERT SYST, V20, P251, DOI 10.1111/1468-0394.00249; Cassandras C., 1993, DISCRETE EVENT SYSTE; Cohen G, 1998, COMPUT INTEGR MANUF, V11, P243, DOI 10.1016/S0951-5240(98)00013-5; Cohen W. W., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning; Ferrer G, 2000, ECOL ECON, V32, P413, DOI 10.1016/S0921-8009(99)00110-X; FOURCAUD R, 1993, P REMANUFACTURING SE, P4; Fu MC, 2002, INFORMS J COMPUT, V14, P192, DOI 10.1287/ijoc.14.3.192.113; Guide VDR, 1997, INT J PROD ECON, V48, P187, DOI 10.1016/S0925-5273(96)00091-6; Guide VDR, 1997, INT J PROD RES, V35, P67, DOI 10.1080/002075497195984; Guide VDR, 2000, J OPER MANAG, V18, P467, DOI 10.1016/S0272-6963(00)00034-6; Gungor A, 2002, INT J PROD RES, V40, P2569, DOI 10.1080/00207540210135622; Gupta A, 2000, COMPUT CHEM ENG, V24, P2613, DOI 10.1016/S0098-1354(00)00617-7; HAN J, 2002, DATA MINING CONCEPTS, pCH3; Haynsworth H. C., 1987, Production and Inventory Management, V28; HO Y. C., 1992, J DISCRETE EVENT DYN, V2, P61; HO YC, 1994, IEEE DECIS CONTR P, P1975; HO YC, 2003, IEEE T AUTOMAT CONTR, V48, P483; Ho YC, 1999, INFORM SCIENCES, V113, P169, DOI 10.1016/S0020-0255(98)10056-7; KAELBLING LP, REINFORCEMENT LEARNI; Kiesmuller GP, 2003, INT J PROD ECON, V81-2, P333, DOI 10.1016/S0925-5273(02)00329-8; KLEIJN MJ, 1998, 9838A EC I; KOMOROWSKI J, 1999, ROUGH FUZZY HYBRIDIZ, P33; KUNG HT, 1976, ANAL COMPUTATIONAL C; Kusiak A, 2001, IEEE T ELECTRON PA M, V24, P44, DOI 10.1109/6104.924792; Lambert AJD, 2002, COMPUT IND ENG, V43, P553, DOI 10.1016/S0360-8352(02)00125-0; Li D, 2002, INFORM SCIENCES, V148, P201, DOI 10.1016/S0020-0255(02)00296-7; Maturana F, 1997, COMPUT IND, V32, P281, DOI 10.1016/S0166-3615(96)00081-4; McConocha D.M., 1991, J BUSINESS IND MARKE, V6, P23, DOI 10.1108/08858629110035275; Monostori L, 2003, ENG APPL ARTIF INTEL, V16, P277, DOI 10.1016/S0952-1976(03)00078-2; MUNAKATA T, 1996, P 4 EUR C INT TECHN, V1, P209; OHM A, 1998, STUDIES FUZZINESS SO, P572; OKUBO B, 2006, INT J PROD ECON, V44, P159; OLHAGER J, 1995, OPER RES, V2, P29; Pandey PC, 1996, INT J COMPUT APPL T, V9, P119; PANISSET BD, 1988, PRODUCTION INVENTORY, V29, P12; Pawlak Z, 1997, EUR J OPER RES, V99, P48, DOI 10.1016/S0377-2217(96)00382-7; PAWLAK Z, 1991, ROUGH SETS THEORETIC, pCH1; Perry J. H., 1991, Production and Inventory Management Journal, V32; RUNYAN RP, 1996, FUNDAMENTALS BEHAV S, pCH10; Spall J., 2003, INTRO STOCHASTIC SEA; SPROW E, 1992, MANUF ENG, V108, P38; SURI R, 1995, INTERFACES, V25, P128, DOI 10.1287/inte.25.5.128; Tang Y, 2001, IEEE T ROBOTIC AUTOM, V17, P773; Vinterbo S, 2000, INT J APPROX REASON, V25, P123, DOI 10.1016/S0888-613X(00)00051-7; Vollman T.E., 1998, MANUFACTURING PLANNI; Walczak B, 1999, CHEMOMETR INTELL LAB, V47, P1, DOI 10.1016/S0169-7439(98)00200-7; WASSWEILER W, 1993, MANUFACTURING SYSTEM, V11, P52; Zapfel G, 1996, INT J PROD ECON, V46, P153, DOI 10.1016/0925-5273(95)00192-1; Zellner A, 1995, J COMPUT APPL MATH, V64, P3, DOI 10.1016/0377-0427(95)00002-X; Zhang W., 2001, ROUGH SET THEORY MET	54	4	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1545-5955		IEEE T AUTOM SCI ENG	IEEE Trans. Autom. Sci. Eng.	JUL	2005	2	3					262	275		10.1109/TASE.2005.849090		14	Automation & Control Systems	Automation & Control Systems	941MH	WOS:000230218400006	
J	Russo, M				Russo, M			Crossover enhancements in GEFREX	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						crossover; fuzzy logic; genetic algorithms (GAs); machine learning; neural networks		This letter describes some improvements to the crossover operator in the genetic-neuro-fuzzy algorithm called genetic fuzzy rule extractor (GEFREX). Although, the new crossovers studied are very simple the performance of GEFREX, in terms of learning time, is decidedly improved.	Univ Catania, Dept Phys & Astron, I-95125 Catania, Italy; Natl Inst Nucl Phys, I-95125 Catania, Italy	Russo, M (reprint author), Univ Catania, Dept Phys & Astron, I-95125 Catania, Italy.	marco.russo@ct.infn.it					Golub G. H., 1996, MATRIX COMPUTATIONS; Russo M, 2000, IEEE T EVOLUT COMPUT, V4, P259, DOI 10.1109/4235.873236; Russo M, 2001, IEEE T NEURAL NETWOR, V12, P475, DOI 10.1109/72.925552	3	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	JUL	2005	16	4					1000	1002		10.1109/TNN.2005.849841		3	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	945MC	WOS:000230505600023	
J	Vidal, E; Thollard, F; de la Higuera, C; Casacuberta, F; Carrasco, RC				Vidal, E; Thollard, F; de la Higuera, C; Casacuberta, F; Carrasco, RC			Probabilistic finite-state machines - Part I	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						automata; classes defined by grammars or automata; machine learning; language acquisition; language models; language parsing and understanding; machine translation; speech recognition and synthesis; structural pattern recognition; syntactic pattern recognition	HIDDEN MARKOV-MODELS; GRAMMATICAL INFERENCE; SPEECH RECOGNITION; REGULAR GRAMMARS; POLYNOMIAL-TIME; AUTOMATA	Probabilistic finite- state machines are used today in a variety of areas in pattern recognition, or in fields to which pattern recognition is linked: computational linguistics, machine learning, time series analysis, circuit testing, computational biology, speech recognition, and machine translation are some of them. In Part I of this paper, we survey these generative objects and study their definitions and properties. In Part II, we will study the relation of probabilistic finite- state automata with other well- known devices that generate strings as hidden Markov models and n- grams and provide theorems, algorithms, and properties that represent a current state of the art of these objects.	Univ Politecn Valencia, Dept Sistemas Informat & Computac, E-46071 Valencia, Spain; Univ Politecn Valencia, Inst Informat Technol, E-46071 Valencia, Spain; EURISE, Fac Sci & Tech, FR-42023 St Etienne, France; Univ Alicante, Dept Lenguajes & Sistemas Informat, E-03071 Alicante, Spain	Vidal, E (reprint author), Univ Politecn Valencia, Dept Sistemas Informat & Computac, Camino Vera S-N, E-46071 Valencia, Spain.	evidal@iti.upv.es; Franck.Thollard@univ-st-etienne.fr; Colin.Delahiguera@univ-st-etienne.fr; fcn@iti.upv.es; carrasco@dlsi.ua.es					Abe H, 2001, ARTIF CELL BLOOD SUB, V29, P275, DOI 10.1081/BIO-100104230; ABE N, 1998, P 3 WORKSH COMP LEAR, P52; ALSHAWI H, 2000, COMPUTATIONAL LINGUI, V26; Alshawi H., 2000, Machine Translation, V15, DOI 10.1023/A:1011187330969; Amengual J. C., 2000, Machine Translation, V15, DOI 10.1023/A:1011116115948; Angluin D., 1988, YALEUDCSRR614; Bangalore S., 2000, P WORKSH EMB MACH TR, P52; BANGALORE S, 2001, P NORTH AM ASS C MAY; Bengio Y, 2001, IEEE T NEURAL NETWOR, V12, P113, DOI 10.1109/72.896800; Blondel VD, 2003, THEOR COMPUT SYST, V36, P231, DOI 10.1007/s00224-003-1061-2; Brehelin L, 2001, IEEE T PATTERN ANAL, V23, P997, DOI 10.1109/34.955112; Brown P. F., 1992, Computational Linguistics, V18; Carrasco R., 1994, P 2 INT C GRAMM INF, P139; Carrasco RC, 1997, RAIRO-INF THEOR APPL, V31, P437; Carrasco RC, 1999, RAIRO-INF THEOR APPL, V33, P1, DOI 10.1051/ita:1999102; CASACUBERTA F, 2000, P 5 INT C GRAMM INF, P15; CASACUBERTA F, 2003, COMPUTER SPEECH LANG; CASACUBERTA F, 1990, IEEE T PATTERN ANAL, V12, P691, DOI 10.1109/34.56212; COOK C, 1974, NATO ASI COMPUTER OR, P157; Cover T. M., 1991, ELEMENTS INFORMATION; DelaHiguera C, 1997, MACH LEARN, V27, P125, DOI 10.1023/A:1007353007695; DELAHIGUERA C, 2003, 0301 EURISE U SAINTE; DUPONT P, 2004, PATTERN RECOGNITION; Forney G.D., 1973, IEEE P, V61, P268; FRED A, 2000, P 5 INT C GRAMM INF, P103; Fu K., 1982, SYNTACTIC PATTERN RE; Fu K. S., 1974, SYNTACTIC METHODS PA; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P409, DOI 10.1109/TSMC.1975.5408432; Fu K. S., 1975, IEEE T SYST MAN CYB, V5, P59; GALLEGUER RG, 1996, DISCRETE STOCHASTIC; Goodman J., 2001, BIT PROGR LANGUAGE M; Harrison M. A., 1978, INTRO FORMAL LANGUAG; Jelinek F., 1998, STAT METHODS SPEECH; Kearns M., 1989, Proceedings of the Twenty First Annual ACM Symposium on Theory of Computing, DOI 10.1145/73007.73049; Kearns M., 1994, Proceedings of the Twenty-Sixth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/195058.195155; Kearns MJ, 1994, INTRO COMPUTATIONAL; Kneser R., 1993, P EUR C SPEECH COMM, P973; Knill K, 1997, TEXT SPEECH LANG TEC, V2, P27; LUCAS S, 1994, P 2 INT C GRAMM INF, P168; LYNGSO RB, 2001, P 12 ANN INT S ALG C; LYNGSO RB, 1999, P INTELLIGENT SYSTEM; MERHAV N, 1991, IEEE T SIGNAL PROCES, V39, P2111, DOI 10.1109/78.134449; Merhav N., 1991, Computer Speech and Language, V5, DOI 10.1016/0885-2308(91)90002-8; MICHLET L, 1987, STRUCTURAL METHODS P; Mohri M, 2000, THEOR COMPUT SCI, V231, P17, DOI 10.1016/S0304-3975(99)00014-6; Mohri M, 1997, COMPUT LINGUIST, V23, P269; NEY H, 1992, P NATO ADV STUDY I, P313; Ney H, 1997, TEXT SPEECH LANG TEC, V2, P174; PARADAENS JJ, 1974, COMPUTING, V13, P93; Paz A., 1971, INTRO PROBABILISTIC; RABIN MO, 1963, INFORM CONTROL, V6, P230, DOI 10.1016/S0019-9958(63)90290-0; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RON D, 1995, MACH LEARN, V18, P149, DOI 10.1007/BF00993409; Ron D., 1994, Proceedings of the Seventh Annual ACM Conference on Computational Learning Theory, COLT 94, DOI 10.1145/180139.181006; Ron D., 1995, Proceedings of the Eighth Annual Conference on Computational Learning Theory, DOI 10.1145/225298.225302; SAKAKIBARA Y, 1994, NUCLEIC ACIDS RES, V22, P5112, DOI 10.1093/nar/22.23.5112; Saul L., 1997, P 2 C EMP METH NAT L, P81; THOMASON MG, 1976, CS7617 U TENNESSEE C; TZENG WG, 1992, SIAM J COMPUT, V21, P216, DOI 10.1137/0221017; Vidal E., 1998, P INT C GRAMM INF, P211; Vidal E, 2005, IEEE T PATTERN ANAL, V27, P1026, DOI 10.1109/TPAMI.2005.148; WETHERELL C, 1980, COMPUTING SURVEYS, V12; Young-Lai M, 2000, MACH LEARN, V40, P111, DOI 10.1023/A:1007653929870	63	50	53	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2005	27	7					1013	1025		10.1109/TPAMI.2005.147		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	925AQ	WOS:000229024300002	
J	Vidal, E; Thollard, F; de la Higuera, C; Casacuberta, F; Carrasco, RC				Vidal, E; Thollard, F; de la Higuera, C; Casacuberta, F; Carrasco, RC			Probabilistic finite-state machines - Part II	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Review						automata; classes defined by grammars or automata; machine learning; language acquisition; language models; language parsing and understanding; machine translation; speech recognition and synthesis; structural pattern recognition; syntactic pattern recognition	CONTEXT-FREE GRAMMARS; EVEN LINEAR LANGUAGES; GRAMMATICAL INFERENCE; SPEECH RECOGNITION; GROWTH TRANSFORMATIONS; STATISTICAL-ESTIMATION; PATTERN-RECOGNITION; REGULAR GRAMMARS; POLYNOMIAL-TIME; TRANSDUCERS	Probabilistic finite- state machines are used today in a variety of areas in pattern recognition or in fields to which pattern recognition is linked. In Part I of this paper, we surveyed these objects and studied their properties. In this Part II, we study the relations between probabilistic finite- state automata and other well- known devices that generate strings like hidden Markov models and n- grams and provide theorems, algorithms, and properties that represent a current state of the art of these objects.	Univ Politecn Valencia, Dept Sistemas Informat & Computac, E-46071 Valencia, Spain; Univ Politecn Valencia, Inst Informat Technol, E-46071 Valencia, Spain; EURISE, Fac Sci & Tech, FR-42023 St Etienne, France; Univ Alicante, Dept Lenguajes & Sistemas Informat, E-03071 Alicante, Spain	Vidal, E (reprint author), Univ Politecn Valencia, Dept Sistemas Informat & Computac, Camino Vera S-N, E-46071 Valencia, Spain.	evidal@iti.upv.es; Franck.Thollard@univ-st-etienne.fr; Colin.Delahiguera@univ-st-etienne.fr; fcn@iti.upv.es; carrasco@dlsi.ua.es					Abe H, 2001, ARTIF CELL BLOOD SUB, V29, P275, DOI 10.1081/BIO-100104230; ABE N, 1992, MACH LEARN, V9, P205, DOI 10.1007/BF00992677; ABE N, 1998, P 3 WORKSH COMP LEAR, P52; ALSHAWI H, 2000, COMPUTATIONAL LINGUI, V26; ALSHAWI H, 2000, MACHINE TRANSLATION; Amengual JC, 2001, MACH LEARN, V44, P143, DOI 10.1023/A:1010832230794; Angluin D., 1988, YALEUDCSRR614; BALASUBRAMANIAN V, 1993, AITR1370 MASS I TECH; BANGALORE S, 2001, P N AM CHAPTER ASS C; Bangalore S., 2000, P WORKSH EMB MACH TR, P52; Baum L. E., 1972, INEQUALITIES, V3, P1; Bazzi I, 1999, IEEE T PATTERN ANAL, V21, P495, DOI 10.1109/34.771314; Bengio Y, 2001, IEEE T NEURAL NETWOR, V12, P113, DOI 10.1109/72.896800; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; BUNKE H, 2001, HIDDEN MARKOV MODELS, V45; Carrasco R., 1994, P 2 INT C GRAMM INF, P139; Carrasco RC, 2001, MACH LEARN, V44, P185, DOI 10.1023/A:1010836331703; Carrasco RC, 1999, RAIRO-INF THEOR APPL, V33, P1, DOI 10.1051/ita:1999102; CASACUBERTA F, 2000, P 5 INT C GRAMM INF, P1; CASACUBERTA F, 2001, P WORKSH AUT SPEECH; CASACUBERTA F, 2004, IN PRES PATTERN RECO; Casacuberta F, 1996, INT J PATTERN RECOGN, V10, P183, DOI 10.1142/S0218001496000153; CASACUBERTA F, 2003, COMPUTER SPEECH LANG; CASACUBERTA F, 1995, P 6 SPAN S PATT REC, P201; Casacuberta F., 2002, P WORKSH SPEECH TO S, P39; CASACUBERTA F, 1996, P 3 INT C GRAMM INF, P282; Casacuberta F, 2004, COMPUT LINGUIST, V30, P205, DOI 10.1162/089120104323093294; CASACUBERTA F, 1990, IEEE T PATTERN ANAL, V12, P691, DOI 10.1109/34.56212; CASACUBERTA F, 1995, PATTERN RECOGN LETT, V16, P565, DOI 10.1016/0167-8655(95)80002-B; CASACUBERTA F, 2004, P 5 INT C GRAMM INF, P15; CHAUDHURI R, 1986, J ACM, V33, P702, DOI 10.1145/6490.214099; Chen S., 1996, P 34 ANN M ASS COMP, P310, DOI 10.3115/981863.981904; Clark A, 2004, J MACH LEARN RES, V5, P473; DELAHIGUERA C, 2000, P 5 INT C GRAMM INF, P15; DENIS F, 1993, P 13 S THEOR ASP COM, P231; DENIS F, 1997, ALGORITHMIC LEARNING; DUPONT P, 2004, PATTERN RECOGNITION; DUPONT P, 1998, P 4 INT C GRAMM INF, P232; DUPONT P, 2000, P 5 INT C GRAMM INF, P51; Eilenberg S., 1974, AUTOMATA LANGUAGES M, VA; EISNER J, 2002, P 40 ANN M ASS COMP; FRED A, 2000, P 5 INT C GRAMM INF, P103; GARCIA P, 1990, IEEE T PATTERN ANAL, V12, P920, DOI 10.1109/34.57687; GARCIA P, 1987, IEEE T PATTERN ANAL, V9, P841; GOLD EM, 1978, INFORM CONTROL, V37, P302, DOI 10.1016/S0019-9958(78)90562-4; GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5; Goodman J., 2001, BIT PROGR LANGUAGE M; HORNING JJ, 1972, INFORMATION PROCESSI, V71, P519; Jelinek F., 1998, STAT METHODS SPEECH; Kammeyer T. E., 1996, FDN GENETIC ALGORITH; Kapur S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130419; KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125; Kearns M., 1989, Proceedings of the Twenty First Annual ACM Symposium on Theory of Computing, DOI 10.1145/73007.73049; Kearns M., 1994, Proceedings of the Twenty-Sixth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/195058.195155; KERMORVANT C, 2002, P 6 INT C GRAMM INF, P149; KERMORVANT C, 2002, P INT C GRAMM INF, V2484; Kneser R., 1993, P EUR C SPEECH COMM, P973; Kneser R., 1995, IEEE INT C AC SPEECH, V1, P181, DOI DOI 10.1109/ICASSP.1995.479394; Knight K, 1998, LECT NOTES ARTIF INT, V1529, P421; Koshiba T., 2000, Acta Cybernetica, V14; Koshiba T, 1997, THEOR COMPUT SCI, V185, P63, DOI 10.1016/S0304-3975(97)00016-9; Lari K., 1990, Computer Speech and Language, V4, DOI 10.1016/0885-2308(90)90022-X; Llobet R, 2003, LECT NOTES COMPUT SC, V2652, P411; LLORENS D, 2000, THESIS U POLITECNICA; Llorens D, 2002, INT J PATTERN RECOGN, V16, P275, DOI 10.1142/S0218001402001666; MAKINEN E, 1999, A19993 U TAMP; MARYANSKI FJ, 1979, INT J COMPUT INF SCI, V8, P89, DOI 10.1007/BF00989665; McAllester D, 2000, P 13 ANN C COMP LEAR, P1; McLachlan G, 1997, EM ALGORITHM EXTENSI; McNaughton R., 1974, Mathematical Systems Theory, V8, DOI 10.1007/BF01761708; Mohri M, 2000, THEOR COMPUT SCI, V231, P17, DOI 10.1016/S0304-3975(99)00014-6; Mohri M, 1997, COMPUT LINGUIST, V23, P269; MOHRI M, 2000, ROBUSTNESS LANGUAGE, P252; Mohri M, 2002, COMPUT SPEECH LANG, V16, P69, DOI 10.1006/csla.2001.0184; MOLINA A, 2002, J MACHINE LEARNING R, V2, P559; NEDERHOFF MJ, 2000, COMPUTATIONAL LINGUI, V26; Ney H, 1997, TEXT SPEECH LANG TEC, V2, P174; ONCINA J, 1993, IEEE T PATTERN ANAL, V15, P448, DOI 10.1109/34.211465; Orlitsky A., 2003, Proceedings 44th IEEE Symposium on Foundations of Computer Science - FOCS 2003; PAREKH R, 1997, P WORKSH AUT IND GRA; PICO D, 2000, P JOINT INT ASS PATT, P417; Pico D, 2001, MACH LEARN, V44, P121, DOI 10.1023/A:1010880113956; Picone J., 1990, IEEE ASSP Magazine, V7, DOI 10.1109/53.54527; PITT L, 1993, J ACM, V40, P95, DOI 10.1145/138027.138042; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Ron D., 1995, Proceedings of the Eighth Annual Conference on Computational Learning Theory, DOI 10.1145/225298.225302; SAKAKIBARA Y, 1994, NUCLEIC ACIDS RES, V22, P5112, DOI 10.1093/nar/22.23.5112; SAKAKIBARA Y, 1990, THEOR COMPUT SCI, V76, P223, DOI 10.1016/0304-3975(90)90017-C; SANCHEZ J, 1996, P 6 INT WORKSH ADV S, P50; Sanchez JA, 1997, IEEE T PATTERN ANAL, V19, P1052, DOI 10.1109/34.615455; STOLCKE A, 1994, P 2 INT C GRAMM INF, P106; TAKADA Y, 1988, INFORM PROCESS LETT, V28, P193, DOI 10.1016/0020-0190(88)90208-6; Thollard F., 2000, P 17 INT C MACH LEAR, P975; THOLLARD F, 2002, P 6 INT C GRAMM INF, P269; THOLLARD F, 2001, P 18 INT C MACH LEAR, P561; TOSELLI A, 2004, INT J PATTERN RECOGN; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; VIDAL E, 1989, STRUCTURAL PATTERN A, P17; Vidal E, 2005, IEEE T PATTERN ANAL, V27, P1013, DOI 10.1109/TPAMI.2005.147; VIDAL E, 1996, P 3 INT C GRAMM INF, P179; VILAR JM, 2000, P 5 INT C GRAMM INF, P298; WETHERELL C, 1980, COMPUTING SURVEYS, V12; WITTEN IH, 1991, IEEE T INFORM THEORY, V37, P1085, DOI 10.1109/18.87000; WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060; Young-Lai M, 2000, MACH LEARN, V40, P111, DOI 10.1023/A:1007653929870; Zalcstein Y., 1972, Journal of Computer and System Sciences, V6, DOI 10.1016/S0022-0000(72)80020-5	106	13	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2005	27	7					1026	1039		10.1109/TPAMI.2005.148		14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	925AQ	WOS:000229024300003	
J	Lucas, SM; Reynolds, TJ				Lucas, SM; Reynolds, TJ			Learning Deterministic Finite Automata with a smart state labeling evolutionary algorithm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						grammatical inference; finite state automata; random hill climber; evolutionary algorithm		Learning a Deterministic Finite Automaton ( DFA) from a training set of labeled strings is a hard task that has been much studied within the machine learning community. It is equivalent to learning a regular language by example and has applications in language modeling. In this paper, we describe a novel evolutionary method for learning DFA that evolves only the transition matrix and uses a simple deterministic procedure to optimally assign state labels. We compare its performance with the Evidence Driven State Merging ( EDSM) algorithm, one of the most powerful known DFA learning algorithms. We present results on random DFA induction problems of varying target size and training set density. We also study the effects of noisy training data on the evolutionary approach and on EDSM. On noise free data, we find that our evolutionary method outperforms EDSM on small sparse data sets. In the case of noisy training data, we find that our evolutionary method consistently outperforms EDSM, as well as other significant methods submitted to two recent competitions.	Univ Essex, Dept Comp Sci, Colchester CO4 3SQ, Essex, England	Lucas, SM (reprint author), Univ Essex, Dept Comp Sci, Wivenhoe Pk, Colchester CO4 3SQ, Essex, England.	sml@essex.ac.uk; reynt@essex.ac.uk					ANGELINE PJ, 1994, IEEE T NEURAL NETWOR, V5, P54, DOI 10.1109/72.265960; Beyer HG, 1994, EVOL COMPUT, V2, P381, DOI 10.1162/evco.1994.2.4.381; Cicchello O, 2002, LECT NOTES ARTIF INT, V2484, P37; Cicchello O., 2003, J MACHINE LEARNING R, V4, P603; DUPONT P, 1994, P GRAMM INF APPL 2 I, P236; Dupont Pierre, 1994, P 2 INT C GRAMM INF, P25; GILES CL, 1990, ADV NEURAL INFORMATI, P380; GOMEX J, 2004, P GEN EV COMP C; Juille H., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Kearns M., 1989, Proceedings of the Twenty First Annual ACM Symposium on Theory of Computing, DOI 10.1145/73007.73049; LANG K, 1998, TR98139; Lang K. J., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130390; LANG KJ, 2005, GOWACHIN SERVER; LANGAAS K, 1998, P 6 EUR C MATH OIL R, P1; LANKHORST M, 1995, CSR9502; LUCAS S, 2004, P GEN EV COMP C; LUCAS SM, 2003, P C EV COMP, P351; Lucas S., 1994, Proceedings of the First IEEE Conference on Evolutionary Computation. IEEE World Congress on Computational Intelligence (Cat. No.94TH0650-2), DOI 10.1109/ICEC.1994.350028; LUCAS SM, 2003, P 6 EUR C GEN PROGR, P130; LUKE S, 1999, P GEN EV COMP C, P1098; Mitchell M, 1994, ADV NEURAL INFORMATI, P51; Mitchell M, 1996, INTRO GENETIC ALGORI; Oliveira AL, 1998, STRING PROCESSING AND INFORMATION RETRIEVAL - PROCEEDINGS, P81; ONCINA J, 1992, S MACH PERC, V1, P49; PITT L, 1993, J ACM, V40, P95, DOI 10.1145/138027.138042; SCHACHTMAN TR, 1992, BEHAV PROCESS, V26, P1, DOI 10.1016/0376-6357(92)90027-B; SEBBAN M, 2003, P INT C MACH LEARN I; SEBBAN M, 2004, P GEN EV COMP C; Tomita M., 1982, P 4 ANN COGN SCI C, P105; TRAKHTENBROT BA, 1973, FINITE AUTOMATA; WATROUS RL, 1992, ADV NEUR IN, V4, P309; WYARD P, 1991, P 4 INT C GEN ALG, P514	32	8	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2005	27	7					1063	1074		10.1109/TPAMI.2005.143		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	925AQ	WOS:000229024300006	
J	Navigli, R; Velardi, P				Navigli, R; Velardi, P			Structural semantic interconnections: A knowledge-based approach to word sense disambiguation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						natural language processing; ontology learning; structural pattern matching; word sense disambiguation		Word Sense Disambiguation ( WSD) is traditionally considered an AI- hard problem. A break- through in this field would have a significant impact on many relevant Web- based applications, such as Web information retrieval, improved access to Web services, information extraction, etc. Early approaches to WSD, based on knowledge representation techniques, have been replaced in the past few years by more robust machine learning and statistical techniques. The results of recent comparative evaluations of WSD systems, however, show that these methods have inherent limitations. On the other hand, the increasing availability of large- scale, rich lexical knowledge resources seems to provide new challenges to knowledge- based approaches. In this paper, we present a method, called structural semantic interconnections ( SSI), which creates structural specifications of the possible senses for each word in a context and selects the best hypothesis according to a grammar G, describing relations between sense specifications. Sense specifications are created from several available lexical resources that we integrated in part manually, in part with the help of automatic procedures. The SSI algorithm has been applied to different semantic disambiguation problems, like automatic ontology population, disambiguation of sentences in generic texts, disambiguation of words in glossary definitions. Evaluation experiments have been performed on specific knowledge domains ( e. g., tourism, computer networks, enterprise interoperability), as well as on standard disambiguation test sets.	Univ Roma La Sapienza, Dipartimento Informat, I-00198 Rome, Italy	Navigli, R (reprint author), Univ Roma La Sapienza, Dipartimento Informat, Via Saleria 113, I-00198 Rome, Italy.	navigli@di.uniroma.it; velardi@di.uniroma.it					BERNERSLEE T, 2001, SCI AM           MAY; Bunke H., 1990, SYNTACTIC STRUCTURAL; Fellbaum C., 1998, WORDNET ELECT LEXICA; Fu K., 1982, SYNTACTIC PATTERN RE; Gale W., 1992, P 4 DARPA SPEECH NAT, P233, DOI 10.3115/1075527.1075579; GALE WA, 1992, COMPUT HUMANITIES, V26, P415, DOI 10.1007/BF00136984; Gonzalo J., 1998, P COLING ACL 98 WORK; Guarino N, 2002, COMMUN ACM, V45, P61; Ide N, 1998, COMPUT LINGUIST, V24, P1; KROVETZ R, 1989, SIGIR FORUM, V23, P127, DOI 10.1145/75334.75349; Lea D., 2002, OXFORD COLLOCATIONS; Litkowski K. C., 2004, P ACL 2004 SENSEVAL, P13; LONGMAN K, 2003, LONGMAN LANGUAGE ACT; MAGNINI B, 2000, P 2 INT C LANG RES E; MCCARTHY D, 2004, P 42 ANN M ASS COMP; MIHALCEA R, 2001, P WORKSH WORDN OTH L; Mihalcea R. F., 2001, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V10, DOI 10.1142/S0218213001000398; Miller G, 1994, P ARPA HUM LANG TECH, P240, DOI 10.3115/1075812.1075866; NAVIGLI R, 2005, P 18 FLAIRS INT C MA; Navigli R., 2003, P WORKSH AD TEXT EXT; NAVIGLI R, 2005, P AAI SPR S; Navigli Roberto, 2004, COMPUTATIONAL LINGUI, P30; NG HT, 1996, P 34 ANN M ASS COMP; RESNIK P, 1995, P INT JOINT C ART IN; Schank R. C., 1977, SCRIPTS PLANS GOALS; WILKS Y, 1978, ARTIF INTELL, V6, P53; Witten I. H., 2000, DATA MINING PRACTICA; Yarowsky D., 1992, P 14 INT C COMP LING, P454; 2004, 2 GLOB WORDN C   JAN; 2004, P EKAW04 WORKSH COR	30	40	45	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2005	27	7					1075	1086		10.1109/TPAMI.2005.149		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	925AQ	WOS:000229024300007	
J	Riccardi, G; Hakkani-Tur, D				Riccardi, G; Hakkani-Tur, D			Active learning: Theory and applications to automatic speech recognition	IEEE TRANSACTIONS ON SPEECH AND AUDIO PROCESSING			English	Article						acoustic modeling; active learning; language modeling; large vocabulary continuous speech recognition; machine learning	NATURAL SPOKEN DIALOG; ADAPTATION	We are interested in the problem of adaptive learning in the context of automatic speech recognition (ASR). In this paper, we propose an active learning algorithm for ASR. Automatic speech recognition systems are trained using human supervision to provide transcriptions of speech utterances. The goal, of Active Learning is to minimize the human supervision for training acoustic and language models and to maximize the performance given the transcribed and untranscribed data. Active learning aims at reducing the number of training examples to be labeled by automatically processing the unlabeled examples, and then selecting the most informative ones with respect to a given cost function for a human to label. In this paper we describe how to estimate the confidence score for each utterance through an on-line algorithm using the lattice output of a speech recognizer. The utterance scores are filtered through the informativeness function and an optimal subset of training samples is selected. The active learning algorithm has been applied to both batch and on-line learning scheme and we have experimented with different selective sampling algorithms. Our experiments show that by using active learning the amount of labeled data needed for a given word accuracy can be reduced by more than 60 % with respect to random sampling.	AT&T Labs Res, Florham Pk, NJ 07932 USA	Riccardi, G (reprint author), AT&T Labs Res, 180 Pk Ave, Florham Pk, NJ 07932 USA.	dsp3@research.att.com	riccardi, gabriele/A-9269-2012				COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211; CRITCHLOW DE, 1980, METRIC METHODS ANAL; De Mori R., 1998, SPOKEN DIALOGUES COM; DIGALAKIS VV, 1995, IEEE T SPEECH AUDI P, V3, P357, DOI 10.1109/89.466659; Engelson S. P., 1995, P 12 INT C MACH LEAR, P150; FALAVIGNA D, 2002, P INT C SPOK LANG PR; Federico M., 1996, Proceedings ICSLP 96. Fourth International Conference on Spoken Language Processing (Cat. No.96TH8206), DOI 10.1109/ICSLP.1996.607087; FREUND Y, 1994, MACH LEARN, V15, P201; Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278; Gorin AL, 2002, COMPUTER, V35, P51, DOI 10.1109/MC.2002.993771; GRETTER R, 2001, P IEEE INT C AC SPEE; HAKKANITUR D, 2002, P ICASSP, P3904; HAKKANITUR D, 2003, P ICASSP HONG KONG; HWA R, 2001, P 5 COMP NAT LANG LE, P84; Jelinek F., 1997, STAT METHODS SPEECH; KAMM TM, 2002, P HUM LANG TECHN C S; KEMP T, 1999, IEEE INTELL SYST, P51; Lebanon G., 2002, P 19 INT C MACH LEAR; Leggetter C., 1995, COMPUT SPEECH LANG, V9; Lewis D, 1994, P 11 INT C MACH LEAR, P148; LIERE R, 2000, THESIS OREGON STATE; Mangu L, 2000, COMPUT SPEECH LANG, V14, P373, DOI 10.1006/csla.2000.0152; MUSLEA I, 2000, THESIS U SO CALIFORN; RABINR L, 1993, FUNDAMENTALS SPEECH; Riccardi G, 1996, COMPUT SPEECH LANG, V10, P265, DOI 10.1006/csla.1996.0014; RICCARDI G, 2003, P EUROSPEECH; Riccardi G, 2000, IEEE T SPEECH AUDI P, V8, P3, DOI 10.1109/89.817449; ROSE RC, 1995, P INT C AC SPEECH SI, P281; STOLCKE A, 2001, P 2001 NIST LARG VOC; Tang M., 2002, P 40 ANN M ASS COMP, P120; Thompson C.A., 1999, P 16 INT C MACH LEAR, P406; TUR G, 2003, P ICASSP HONG KONG M; ZAVALIAGKOS G, 1998, P DARPA BROADC NEWS, P301; Zhang R., 2001, P 7 EUR C SPEECH COM, P2105	34	26	29	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1063-6676		IEEE T SPEECH AUDI P	IEEE Trans. Speech Audio Process.	JUL	2005	13	4					504	511		10.1109/TSA.2005.848882		8	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	937IE	WOS:000229917000005	
J	Oh, JH; Choi, KS				Oh, JH; Choi, KS			Machine learning based english-to-Korean transliteration using grapheme and phoneme information	IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS			English	Article						machine transliteration; machine learning; information retrieval; machine translation; natural language processing	ALGORITHM	Machine transliteration is an automatic method to generate characters or words in one alphabetical system for the corresponding characters in another alphabetical system. Machine transliteration can play an important role in natural language application such as information retrieval and machine translation, especially for handling proper nouns and technical terms. The previous works focus on either a grapheme-based or phoneme-based method. However, transliteration is an orthographical and phonetic converting process. Therefore, both grapheme and phoneme information should be considered in machine transliteration. In this paper, we propose a grapheme and phoneme-based transliteration model and compare it with previous grapheme-based and phoneme-based models using several machine learning techniques. Our method shows about 13 similar to 78% performance improvement.	Korea Adv Inst Sci & Technol, Dept Comp Sci, Taejon 305701, South Korea	Oh, JH (reprint author), Korea Adv Inst Sci & Technol, Dept Comp Sci, 373-1 Guseong Dong, Taejon 305701, South Korea.	rovellia@world.kaist.ac.kr; kschoi@world.kaist.ac.kr	Choi, Key-Sun/C-1978-2011				Aha DW, 1997, ARTIF INTELL REV, V11, P7, DOI 10.1023/A:1006538427943; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Berglund B, 1996, ENVIRON INT, V22, P1, DOI 10.1016/0160-4120(95)00098-4; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1023/A:1022664626993; DAELEMANS W, 2003, TIMBL TILBURG MEMORY; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; Fujii A, 2001, COMPUT HUMANITIES, V35, P389, DOI 10.1023/A:1011856202986; GOTO I, 2003, P MT SUMM 9, P125; HALL PAV, 1980, ACM COMPUT SURV, V12, P381, DOI 10.1145/356827.356830; KANG BJ, 2001, THESIS KAIST; KANG BJ, 2000, P 2 INT C LANG RES E, P1135; KANG IH, 2000, P 18 INT C COMP LING, P418; KIM JJ, 1999, P KOR COGN SCI ASS, P247; KNIGHT K, 1997, P 35 ANN M ASS COMP, P128; LEE JH, 1999, THESIS KAIST; LEE JS, 1998, INT J COMPUTER PROCE, P17; Levenshtein V., 1966, SOV PHYS DOKL, V10, P707; LI H, 2004, P ACL 2004, P160; Mitchell T, 1997, MACHINE LEARNING; MIYAO Y, 2002, P HUM LANG TECHN C; NAM YS, 1997, FOREIGN DICT; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; SOONG KF, 1991, IEEE INT C AC SPEECH, P546; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Vapnik V. N, 1995, NATURE STAT LEARNING; Zhang L., 2004, MAXIMUM ENTROPY MODE; *CMU, 1997, CARN MELL U CMU PRON; *KOR MIN CULT TOUR, 1995, ENGL KOR STAND CONV	29	2	2	IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG	TOKYO	KIKAI-SHINKO-KAIKAN BLDG MINATO-KU SHIBAKOEN 3 CHOME, TOKYO, 105, JAPAN	0916-8532		IEICE T INF SYST	IEICE Trans. Inf. Syst.	JUL	2005	E88D	7					1737	1748		10.1093/ietisy/e88-d.7.1737		12	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	948GA	WOS:000230702800055	
J	Senawongse, P; Dalby, AR; Yang, ZR				Senawongse, P; Dalby, AR; Yang, ZR			Predicting the phosphorylation sites using hidden Markov models and machine learning methods	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							PROTEASE CLEAVAGE SITES; STATISTICAL-ANALYSIS; SIGNAL PEPTIDES; NEURAL-NETWORK; PROTEINS; KINASES	Accurately predicting phosphorylation sites in proteins is an important issue in postgenomics, for which how to efficiently extract the most predictive features from amino acid sequences for modeling is still challenging. Although both the distributed encoding method and the bio-basis function method work well, they still have some limits in use. The distributed encoding method is unable to code the biological content in sequences efficiently, whereas the bio-basis function method is a nonparametric method, which is often computationally expensive. As hidden Markov models (HMMs) can be used to generate one model for one cluster of aligned protein sequences, the aim in this study is to use HMMs to extract features from amino acid sequences, where sequence clusters are determined using available biological knowledge. In this novel method, HMMs are first constructed using functional sequences only. Both functional and nonfunctional training sequences are then inputted into the trained HMMs to generate functional and nonfunctional feature vectors. From this, a machine learning algorithm is used to construct a classifier based on these feature vectors. It is found in this work that (1) this method provides much better prediction accuracy than the use of HMMs only for prediction, and (2) the support vector machines (SVMs) algorithm outperforms decision trees and neural network algorithms when they are constructed on the features extracted using the trained HMMs.	Univ Exeter, Dept Biol Sci, Exeter EX4 4QJ, Devon, England; Univ Exeter, Dept Comp Sci, Exeter EX4 4QJ, Devon, England	Yang, ZR (reprint author), Univ Exeter, Dept Biol Sci, Exeter EX4 4QJ, Devon, England.	z.r.yang@ex.ac.uk					ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Bendtsen JD, 2004, J MOL BIOL, V340, P783, DOI 10.1016/j.jmb.2004.05.028; Berry EA, 2004, COMPUT BIOL CHEM, V28, P75, DOI 10.1016/j.compbiolchem.2003.11.005; Cai YD, 2002, J COMPUT CHEM, V23, P267, DOI 10.1002/jcc.10017; Cai YD, 1998, J PROTEIN CHEM, V17, P607, DOI 10.1007/BF02780962; Dayhoff MO, 1978, ATLAS PROTEIN SEQ S3, P345; Duda R., 2002, PATTERN CLASSIFICATI; Eddy SR, 1998, BIOINFORMATICS, V14, P755, DOI 10.1093/bioinformatics/14.9.755; Grundy WN, 1997, COMPUT APPL BIOSCI, V13, P397; HENIKOFF S, 1992, P NATL ACAD SCI USA, V89, P10915, DOI 10.1073/pnas.89.22.10915; JOACHIMS T, 1993, ADV KERNEL METHODS S; KING RJB, 2000, CANC BIOL; Kobayashi K, 2003, J NEUROL SCI, V208, P17, DOI 10.1016/S0022-510X(02)00410-0; Kreegipuu A, 1998, FEBS LETT, V430, P45, DOI 10.1016/S0014-5793(98)00503-1; KROGH A, 1994, J MOL BIOL, V235, P1501, DOI 10.1006/jmbi.1994.1104; Lewin B, 2000, GENES; Li Lewyn, 2003, Proceedings of the National Academy of Sciences of the United States of America, V100, P4463, DOI 10.1073/pnas.0737647100; Manning G, 2002, SCIENCE, V298, P1912, DOI 10.1126/science.1075762; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; MATTHEWS HR, 1995, PHARMACOL THERAPEUT, V67, P323, DOI 10.1016/0163-7258(95)00020-8; METZ CE, 1978, SEMIN NUCL MED, V8, P283, DOI 10.1016/S0001-2998(78)80014-2; Narayanan Ajit, 2002, Bioinformatics, V18 Suppl 1, pS5; Nielsen H, 1997, PROTEIN ENG, V10, P1, DOI 10.1093/protein/10.1.1; Olsson B, 2001, INFORM SCIENCES, V139, P113, DOI 10.1016/S0020-0255(01)00161-X; Pinna LA, 1996, BBA-MOL CELL RES, V1314, P191, DOI 10.1016/S0167-4889(96)00083-3; POORMAN RA, 1991, J BIOL CHEM, V266, P14554; Qian N, 1988, J MOL BIOL, V202, P865, DOI 10.1016/0022-2836(88)90564-5; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Rang H.P., 1999, PHARMACOLOGY; Rumelhart D., 1986, PARALLEL DISTRIBUTED; Salway JG, 1999, METABOLISM GLANCE; Thomson R, 2003, BIOINFORMATICS, V19, P1741, DOI 10.1093/bioinformatics/btg237; Vapnik V. N, 1995, NATURE STAT LEARNING; Vert J P, 2002, Pac Symp Biocomput, P649; Yang ZR, 2004, BIOINFORMATICS, V20, P903, DOI 10.1093/bioinformatics/bth001; YANG ZR, 2004, J BIOINF COMPUT BIOL, V2, P1; Yang ZR, 2005, IEEE T SYST MAN CY B, V35, P100, DOI 10.1109/TSMCB.2004.840723; YANG ZR, IN PRESS BIOINFORMAT; Yang ZR, 2005, IEEE T NEURAL NETWOR, V16, P263, DOI 10.1109/TNN.2004.836196	40	18	20	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596		J CHEM INF MODEL	J. Chem Inf. Model.	JUL-AUG	2005	45	4					1147	1152		10.1021/ci0500047+		6	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	950NO	WOS:000230864300036	
J	Liu, HX; Yao, XJ; Zhang, RS; Liu, MC; Hu, ZD; Fan, BT				Liu, HX; Yao, XJ; Zhang, RS; Liu, MC; Hu, ZD; Fan, BT			Prediction of the tissue/blood partition coefficients of organic compounds based on the molecular structure using least-squares support vector machines	JOURNAL OF COMPUTER-AIDED MOLECULAR DESIGN			English	Article						heuristic method; least-squares support vector machines (LS-SVM); QSAR; tissue/blood partition coefficients	NETWORKS; QSPR; QSAR; MODEL	The accurate nonlinear model for predicting the tissue/blood partition coefficients (PC) of organic compounds in different tissues was firstly developed based on least-squares support vector machines (LS-SVM), as a novel machine learning technique, by using the compounds' molecular descriptors calculated from the structure alone and the composition features of tissues. The heuristic method (HM) was used to select the appropriate molecular descriptors and build the linear model. The prediction result of the LS-SVM model is much better than that obtained by HM method and the prediction values of tissue/blood partition coefficients based on the LS-SVM model are in good agreement with the experimental values, which proved that nonlinear model can simulate the relationship between the structural descriptors, the tissue composition and the tissue/blood partition coefficients more accurately as well as LS-SVM was a powerful and promising tool in the prediction of the tissue/blood partition behaviour of compounds. Furthermore, this paper provided a new and effective method for predicting the tissue/blood partition behaviour of the compounds in the different tissues from their structures and gave some insight into structural features related to the partition process of the organic compounds in different tissues.	Lanzhou Univ, Dept Chem, Lanzhou 730000, Peoples R China; Lanzhou Univ, Dept Comp Sci, Lanzhou 730000, Peoples R China; Univ Paris 07, F-75005 Paris, France	Hu, ZD (reprint author), Lanzhou Univ, Dept Chem, Lanzhou 730000, Peoples R China.	huzd@lzu.edu.cn					Balaz S, 1999, QUANT STRUCT-ACT REL, V18, P361, DOI 10.1002/(SICI)1521-3838(199910)18:4<361::AID-QSAR361>3.0.CO;2-A; Belousov AI, 2002, CHEMOMETR INTELL LAB, V64, P15, DOI 10.1016/S0169-7439(02)00046-1; Boobis A, 2002, EUR J PHARM SCI, V17, P183, DOI 10.1016/S0928-0987(02)00185-9; Burbidge R, 2001, COMPUT CHEM, V26, P5, DOI 10.1016/S0097-8485(01)00094-8; Burges C, 1998, DATA MIN KNOWL DISC, V2, P1, DOI DOI 10.1023/A:1009715923555; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cristianini N., 2000, INTRO SUPPORT VECTOR; Cronin M T, 2000, Curr Opin Drug Discov Devel, V3, P292; Ekins S, 2000, J PHARMACOL EXP THER, V295, P463; Katritzky A. R., 1994, COMPREHENSIVE DESCRI; Katritzky AR, 2001, J CHEM INF COMP SCI, V41, P1162, DOI 10.1021/ci010011r; Katritzky AR, 2001, J CHEM INF COMP SCI, V41, P1521, DOI 10.1021/ci010043e; KATRITZKY AR, 1995, CHEM SOC REV, V24, P279, DOI 10.1039/cs9952400279; Liu HX, 2004, J COMPUT AID MOL DES, V18, P389, DOI 10.1007/s10822-004-2722-1; LIU HX, 2004, J CHEM INF COMP SCI, V444, P1979; Liu HX, 2003, J CHEM INF COMP SCI, V43, P1288, DOI 10.1021/ci03040355; Liu HX, 2004, J CHEM INF COMP SCI, V44, P161, DOI 10.1021/ci034173u; Morris CW, 2001, ECOL MODEL, V146, P57; Oblak M, 2000, J CHEM INF COMP SCI, V40, P994, DOI 10.1021/ci000001a; PELCKMANS K, 2002, 0244 ESATSISTA KU LE; Scholkopf B., 1999, ADV KERNEL METHODS S; STANTON DT, 1992, J CHEM INF COMP SCI, V32, P306, DOI 10.1021/ci00008a009; Stewart J.P.P., 1989, 455 QCPE IND U; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Vapnik V., 1982, ESTIMATION DEPENDENC; Vapnik VN, 1998, STAT LEARNING THEORY; Xue CX, 2004, J CHEM INF COMP SCI, V44, P669, DOI 10.1021/ci034248u; Yao XJ, 2004, J CHEM INF COMP SCI, V44, P1257, DOI 10.1021/ci049965i; Yoshida F, 2000, J MED CHEM, V43, P2575, DOI 10.1021/jm0000564; Zhang HB, 2005, J CHEM INF MODEL, V45, P121, DOI 10.1021/ci049718e; Zhang HB, 2004, J PHARM SCI-US, V93, P1595, DOI 10.1002/jps.20084	31	17	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-654X		J COMPUT AID MOL DES	J. Comput.-Aided Mol. Des.	JUL	2005	19	7					499	508		10.1007/s10822-005-9003-5		10	Biochemistry & Molecular Biology; Biophysics; Computer Science, Interdisciplinary Applications	Biochemistry & Molecular Biology; Biophysics; Computer Science	006DG	WOS:000234874800003	
J	Huang, CD; Liang, SF; Lin, CT; Wu, RC				Huang, CD; Liang, SF; Lin, CT; Wu, RC			Machine learning with automatic feature selection for multi-class protein fold classification	JOURNAL OF INFORMATION SCIENCE AND ENGINEERING			English	Article						machine learning; hierarchical architecture; feature selection; gate; neural network; protein fold; bioinformatics	NEURAL NETWORKS; RECOGNITION; PREDICTION	In machine learning, both the properly used networks and the selected features are important factors which should be considered carefully. These two factors will influence the result, whether for better or worse. In bioinformatics, the amount of features may be very large to make machine learning possible. In this study we introduce the idea of feature selection in the problem of bioinformatics. We use neural networks to complete our task where each input node is associated with a gate. At the beginning of the training, all gates are almost closed, and, at this time, no features are allowed to enter the network. During the training phase, gates are either opened or closed, depending oil the requirements. After the selection training phase has completed, gates corresponding to the helpful features are completely opened while gates Corresponding to the useless features are closed more tightly. Some gates may be partially open, depending oil the importance of the corresponding features. So, the network can not only select features in an online manner during learning, but it also does some feature extraction. We combine feature selection with our novel hierarchical machine learning architecture and apply it to multi-class protein fold classification. At the first level the network classifies the data into four major folds: all alpha, all beta, alpha + beta and alpha/beta. In the next level, we have another set of networks which further classifies the data into twenty-seven folds. This approach helps achieve the following. The gating network is found to reduce the number of features drastically. It is interesting to observe that, for the first level using just 50 features selected by the gating network, we can get a test accuracy comparable to that using 125 features in neural classifiers. The process also helps us get a better insight into the folding process. For example, tracking the evolution of different gates, we call find which characteristics (features) of the data are more important for the folding process. Eventually, it reduces the computation time. The use of the hierarchical architecture helps LIS get a better performance also.	Hsiuping Inst Technol, Dept Elect Engn, Taichung 412, Taiwan; Natl Chiao Tung Univ, Dept Elect & Control Engn, Hsinchu 300, Taiwan	Huang, CD (reprint author), Hsiuping Inst Technol, Dept Elect Engn, Taichung 412, Taiwan.	ctlin@mail.nctu.edu.tw					CHUNG I, 2003, ICANN, P1159; De RK, 1997, PATTERN RECOGN, V30, P1579, DOI 10.1016/S0031-3203(96)00190-2; Ding CHQ, 2001, BIOINFORMATICS, V17, P349, DOI 10.1093/bioinformatics/17.4.349; DUBCHAK I, 1995, P NATL ACAD SCI USA, V92, P8700, DOI 10.1073/pnas.92.19.8700; Dubchak I, 1999, PROTEINS, V35, P401, DOI 10.1002/(SICI)1097-0134(19990601)35:4<401::AID-PROT3>3.0.CO;2-K; DUBCHAK I, 1993, PROTEINS, V16, P79, DOI 10.1002/prot.340160109; Fasman G.D., 1989, PREDICTION PROTEIN S, P549; FUKUNAGA K, 1970, IEEE T COMPUT, VC 19, P311, DOI 10.1109/T-C.1970.222918; Nakashima H, 1986, J BIOCHEM-TOKYO, V99, P152; Pal N. R., 1997, NEURAL PARALLEL SCI, V5, P359; PRIDDY KL, 1993, NEUROCOMPUTING, V5, P91, DOI 10.1016/0925-2312(93)90030-7; Verikas A, 2002, PATTERN RECOGN LETT, V23, P1323, DOI 10.1016/S0167-8655(02)00081-8	12	1	1	INST INFORMATION SCIENCE	TAIPEI	ACADEMIA SINICA, TAIPEI 115, TAIWAN	1016-2364		J INF SCI ENG	J. Inf. Sci. Eng.	JUL	2005	21	4					711	720				10	Computer Science, Information Systems	Computer Science	945KE	WOS:000230500600003	
J	Ong, CS; Smola, AJ; Williamson, RC				Ong, CS; Smola, AJ; Williamson, RC			Learning the kernel with hyperkernels	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						learning the kernel; capacity control; kernel methods; support vector machines; representer theorem; semidefinite programming	SUPPORT VECTOR MACHINES; GAUSSIAN-PROCESSES; SVM	This paper addresses the problem of choosing a kernel suitable for estimation with a support vector machine, hence further automating machine learning. This goal is achieved by defining a reproducing kernel Hilbert space on the space of kernels itself. Such a formulation leads to a statistical estimation problem similar to the problem of minimizing a regularized risk functional. We state the equivalent representer theorem for the choice of kernels and present a semidefinite programming formulation of the resulting optimization problem. Several recipes for constructing hyperkernels are provided, as well as the details of common machine learning problems. Experimental results for classification, regression and novelty detection on UCI data show the feasibility of our approach.	Max Planck Inst Biol Cybernet, D-72076 Tubingen, Germany; Friedrich Miescher Lab, D-72076 Tubingen, Germany; Natl ICT Australia, Canberra, ACT 2601, Australia	Ong, CS (reprint author), Max Planck Inst Biol Cybernet, Spemannstr 35, D-72076 Tubingen, Germany.	CHENGSOON.ONG@TUEBINGEN.MPG.DE; ALEX.SMOLA@NICTA.COM.AU; BOB.WILLIAMSON@NICTA.COM.AU					ALBERT A, 1969, SIAM J APPL MATH, V17, P434, DOI 10.1137/0117041; ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI 10.2307/1990404; Bach F. R., 2002, J MACHINE LEARNING R, V3, P1; Bennett K.P, 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; Bishop C.M., 1995, NEURAL NETWORKS PATT; BOUSQUET O, 2002, ADV NEURAL INFORM PR, V15, P399; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COX DD, 1990, ANN STAT, V18, P1676, DOI 10.1214/aos/1176347872; CRAMMER K, 2002, ADV NEURAL INFORM PR, V15, P537; Cristianini N, 2002, ADV NEUR IN, V14, P367; Cristianini N., 2003, OPTIMIZING KERNEL AL; Duan K, 2003, NEUROCOMPUTING, V51, P41, DOI 10.1016/S0925-2312(02)00601-X; Fine S., 2001, J MACHINE LEARNING R, V2, P243; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Haussler D., 1999, UCSCCRL9910; HERBRICH R, 2002, JMLR, V3, P175; KIMELDOR.G, 1971, J MATH ANAL APPL, V33, P82, DOI 10.1016/0022-247X(71)90184-3; Lanckriet G., 2002, P 19 INT C MACH LEAR, P323; Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27; LAURITZEN LS, 1996, GRAPHICAL MODELS; LOFBERG J, 2002, YALMIP YET ANOTHER L; Luntz A., 1969, TECHNICHESKAYA KIBER, V3; MACKAY DJC, 1994, ASHRAE T, V4, P448; Mangasaian OL, 2001, J MACH LEARN RES, V1, P161, DOI 10.1162/15324430152748218; Meyer D, 2003, NEUROCOMPUTING, V55, P169, DOI 10.1016/S0925-2312(03)00431-4; Neal R. M., 1996, BAYESIAN LEARNING NE; ONG CS, 2003, P 20 INT C MACH LEAR, P568; ONG CS, 2002, NEURAL INFORM PROCES, V15, P495; Opper M, 2000, ADV NEUR IN, P311; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; Scholkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565; Scholkopf B., 2002, LEARNING KERNELS; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; SEEGER M, 1999, THESIS U EDINBURGH; Smola AJ, 1998, NEURAL NETWORKS, V11, P637, DOI 10.1016/S0893-6080(98)00032-X; Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766; Tsuda K., 2003, J MACHINE LEARNING R, V4, P67; Vandenberghe L, 1996, SIAM REV, V38, P49, DOI 10.1137/1038003; Vapnik V. N, 1995, NATURE STAT LEARNING; WAHBA G, 1990, CBMS NSF REGIONAL AM, V59; Williams CKI, 1996, ADV NEUR IN, V8, P514; Williams CKI, 1998, IEEE T PATTERN ANAL, V20, P1342, DOI 10.1109/34.735807; ZHANG T, 2001, P 18 INT C MACH LEAR, P624	45	91	99	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	JUL	2005	6						1043	1071				29	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026HL	WOS:000236329900002	
J	Markatou, M; Tian, H; Biswas, S; Hripcsak, G				Markatou, M; Tian, H; Biswas, S; Hripcsak, G			Analysis of variance of cross-validation estimators of the generalization error	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						cross-validation; generalization error; moment approximation; prediction; variance estimation	DISCRIMINANT-ANALYSIS; BIAS; APPROXIMATION; STABILITY; RATES	This paper brings together methods from two different disciplines: statistics and machine learning. We address the problem of estimating the variance of cross-validation (CV) estimators of the generalization error. In particular, we approach the problem of variance estimation of the CV estimators of generalization error as a problem in approximating the moments of a statistic. The approximation illustrates the role of training and test sets in the performance of the algorithm. It provides a unifying approach to evaluation of various methods used in obtaining training and test sets and it takes into account the variability due to different training and test sets. For the simple problem of predicting the sample mean and in the case of smooth loss functions, we show that the variance of the CV estimator of the generalization error is a function of the moments of the random variables Y = Card(S-j boolean AND S-j') and Y* = Card(S-j(c)boolean AND S-j'(c)), where S-j, S-j' are two training sets, and S-j(c), S-j'(c) are the corresponding test sets. We prove that the distribution of Y and Y* is hypergeometric and we compare our estimator with the one proposed by Nadeau and Bengio (2003). We extend these results in the regression case and the case of absolute error loss, and indicate how the methods can be extended to the classification case. We illustrate the results through simulation.	Columbia Univ, Dept Biostat, New York, NY 10032 USA; Columbia Univ, Coll Biomed Informat, New York, NY 10032 USA	Markatou, M (reprint author), Columbia Univ, Dept Biostat, New York, NY 10032 USA.	MM168@COLUMBIA.EDU; HT2031@COLUMBIA.EDU; SPB2003@COLUMBIA.EDU; GH13@COLUMBIA.EDU					Bengio Y, 2004, J MACH LEARN RES, V5, P1089; Bickel P., 2001, MATH STAT; Breiman L, 1996, ANN STAT, V24, P2350; Cramer H., 1999, MATH METHODS STAT; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Efron B., 1993, INTRO BOOTSTRAP; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Efron B, 2004, J AM STAT ASSOC, V99, P619, DOI 10.1198/016214504000000692; Hastie T, 2001, ELEMENTS STAT LEARNI; Hitomi K., 2001, J JAPAN STAT SOC, V31, P39; Ioffe AD, 1997, T AM MATH SOC, V349, P789, DOI 10.1090/S0002-9947-97-01726-1; James GM, 2003, MACH LEARN, V51, P115, DOI 10.1023/A:1022899518027; Kearns M, 1996, ADV NEUR IN, V8, P183; Kearns M, 1999, NEURAL COMPUT, V11, P1427, DOI 10.1162/089976699300016304; Khan RA, 2004, STATISTICS, V38, P117, DOI 10.1080/02331880310001655635; Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence; Lehmann EL, 1983, THEORY POINT ESTIMAT; MCLACHLAN GJ, 1976, BIOMETRIKA, V63, P239, DOI 10.1093/biomet/63.2.239; MCLACHLA.GJ, 1974, BIOMETRIKA, V61, P131, DOI 10.2307/2334294; MCLACHLAN GJ, 1974, AUSTR J STAT, V15, P210; MCLACHLA.GJ, 1972, AUST J STAT, V14, P68; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; PICARD RR, 1984, J AM STAT ASSOC, V79, P575, DOI 10.2307/2288403; PIPER J, 1992, PATTERN RECOGN LETT, V13, P685, DOI 10.1016/0167-8655(92)90097-J; Ronchetti E, 2001, STAT COMPUT, V11, P67, DOI 10.1023/A:1026562000322; Sen P. K., 1993, LARGE SAMPLE METHODS	26	10	10	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	JUL	2005	6						1127	1168				42	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026HL	WOS:000236329900005	
J	Gillette, MA; Mani, DR; Carr, SA				Gillette, MA; Mani, DR; Carr, SA			Place of pattern in proteomic biomarker discovery	JOURNAL OF PROTEOME RESEARCH			English	Article						biomarker discovery; proteomics; diagnostic; mass spectrometry; serum/plasma; pattern; machine learning; pattern recognition; feature selection; classification	ELECTRON-CAPTURE DISSOCIATION; FLIGHT-MASS-SPECTROMETRY; ACUTE RESPIRATORY SYNDROME; HUMAN PLASMA PROTEOME; CELL LUNG-CANCER; SELDI-TOF-MS; LIQUID-CHROMATOGRAPHY; OVARIAN-CANCER; PROSTATE-CANCER; HEPATOCELLULAR-CARCINOMA	The role of pattern in biomarker discovery and clinical diagnosis is examined in its historical context. The use of MS-derived pattern is treated as a logical extension of prior applications of non-MS-derived pattern. Criticisms pertaining to specific technology platforms and analytic methodologies are considered separately from the larger issues of pattern utility and deployment in biomarker discovery. We present a hybrid strategy that marries the desirable attributes of high-information content MS pattern with the capability to obtain identity, and explore the key steps in establishing a data analysis pipeline for pattern-based biomarker discovery.	MIT, Broad Inst, Cambridge, MA 02141 USA; Harvard Univ, Cambridge, MA 02141 USA; Massachusetts Gen Hosp, Cambridge, MA 02141 USA	Gillette, MA (reprint author), MIT, Broad Inst, 320 Charles St, Cambridge, MA 02141 USA.	gillette@broad.mit.edu; scarr@broad.mit.edu					Adam BL, 2002, CANCER RES, V62, P3609; Adkins JN, 2002, MOL CELL PROTEOMICS, V1, P947, DOI 10.1074/mcp.M200066-MCP200; Anderson NL, 2002, MOL CELL PROTEOMICS, V1, P845, DOI 10.1074/mcp.R200007-MCP200; Andreev VP, 2003, ANAL CHEM, V75, P6314, DOI 10.1021/ac0301806; Baggerly KA, 2004, BIOINFORMATICS, V20, P777, DOI 10.1093/bioinformatics/btg484; BANFIELD JD, 1993, BIOMETRICS, V49, P803, DOI 10.2307/2532201; Brieman L., 1984, CLASSIFICATION REGRE; Burtis C.A., 1999, TIETZ TXB CLIN CHEM; Bylund D, 2002, J CHROMATOGR A, V961, P237, DOI 10.1016/S0021-9673(02)00588-5; Cadieux PA, 2004, J CLIN LAB ANAL, V18, P170, DOI 10.1002/jcla.20018; Carroll J.A., 1996, RAPID COMMUN MASS SP, V13, P1683; Charles L, 2003, RAPID COMMUN MASS SP, V17, P1383, DOI 10.1002/rcm.1060; Chen YD, 2004, CLIN CANCER RES, V10, P8380, DOI 10.1158/1078-0432.CCR-1162-03; Christianini N., 2000, INTRO SUPPORT VECTOR; Colombo M, 2004, RAPID COMMUN MASS SP, V18, P511, DOI 10.1002/rcm.1368; Conrads TP, 2004, ENDOCR-RELAT CANCER, V11, P163, DOI 10.1677/erc.0.0110163; Diamandis EP, 2005, CLIN CANCER RES, V11, P963; Diamandis EP, 2004, MOL CELL PROTEOMICS, V3, P367, DOI 10.1074/mcp.R400007-MCP200; Ebert MPA, 2004, J PROTEOME RES, V3, P1261, DOI 10.1021/pr049865s; Eckers C, 2000, ANAL CHEM, V72, P3683, DOI 10.1021/ac000448i; FUNG ET, 2005, INT J CANC; Gelman A., 2003, BAYESIAN DATA ANAL; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gonzalez RC, 2002, DIGITAL IMAGE PROCES; Hastie T, 2001, ELEMENTS STAT LEARNI; Haykin S., 1998, NEURAL NETWORKS COMP; Horn DM, 2000, J AM SOC MASS SPECTR, V11, P320, DOI 10.1016/S1044-0305(99)00157-9; HUNTER C, 2004, ISCIENCE PROTEOMICS, P1; JOBSON JD, 1996, APPL MULTIVARIATE DA; Junker K, 2005, INT J MOL MED, V15, P285; Kang XX, 2005, CLIN CHEM, V51, P56, DOI 10.1373/clinchem.2004.032458; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.2307/2291091; Kelleher N L, 1999, Anal Chem, V71, P4250, DOI 10.1021/ac990684x; Koopmann J, 2004, CLIN CANCER RES, V10, P860, DOI 10.1158/1078-0432.CCR-1167-3; Koza J. R., 1992, GENETIC PROGRAMMING; Kruger N.A., 1999, INT J MASS SPECTROM, V187, P787; Laronga C, 2003, DIS MARKERS, V19, P229; LE L, 2005, CLIN CHEM; Li JN, 2004, J UROLOGY, V171, P1782, DOI 10.1097/01.ju.0000119823.86393.49; Li JN, 2002, CLIN CHEM, V48, P1296; Liggett WS, 2004, DIS MARKERS, V20, P295; LISTGARTEN J, 2005, MOL CELL PROTEOMICS; Liu Jian, 2005, J Zhejiang Univ Sci B, V6, P4, DOI 10.1631/jzus.2005.B0004; MacCoss MJ, 2003, ANAL CHEM, V75, P6912, DOI 10.1021/ac034790h; Malik G, 2005, CLIN CANCER RES, V11, P1073; MANI DR, 2005, NEXT GENERATION DATA; Mitchell T, 1997, MACHINE LEARNING; Paradis V, 2005, HEPATOLOGY, V41, P40, DOI 10.1002/hep.20505; Pearl DC, 2002, LANCET, V360, P169, DOI 10.1016/S0140-6736(02)09388-1; Pelander A, 2003, ANAL CHEM, V75, P5710, DOI 10.1021/ac030162o; Petricoin EF, 2002, NAT REV DRUG DISCOV, V1, P683, DOI 10.1038/nrd891; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Poon TCW, 2003, CLIN CHEM, V49, P752, DOI 10.1373/49.5.752; QIAN WJ, 2005, MOL CELL PROTEOMICS; Qu YS, 2002, CLIN CHEM, V48, P1835; Radulovic D, 2004, MOL CELL PROTEOMICS, V3, P984, DOI 10.1074/mcp.M400061-MCP200; Rai AJ, 2002, ARCH PATHOL LAB MED, V126, P1518; RANDOLPH TW, 2004, UW BIOSTATISTICS WOR; Ransohoff DF, 2005, NAT REV CANCER, V5, P142, DOI 10.1038/nrc1550; Ransohoff DF, 2004, NAT REV CANCER, V4, P309, DOI 10.1038/nrc1322; Rosty C, 2002, CANCER RES, V62, P1868; Schwegler EE, 2005, HEPATOLOGY, V41, P634, DOI 10.1002/hep.20577; SENKO MW, 1995, J AM SOC MASS SPECTR, V6, P52, DOI 10.1016/1044-0305(94)00091-D; SENKO MW, 1995, J AM SOC MASS SPECTR, V6, P229, DOI 10.1016/1044-0305(95)00017-8; Shen YF, 2004, ANAL CHEM, V76, P1134, DOI 10.1021/ac034869m; Shen YF, 2003, ANAL CHEM, V75, P3596, DOI 10.1021/ac0300690; Shi SDH, 2001, ANAL CHEM, V73, P19, DOI 10.1021/ac000703z; Sleno L, 2005, J AM SOC MASS SPECTR, V16, P183, DOI 10.1016/j.jasms.2004.10.001; Smith S., 1997, SCI ENG GUIDE DIGITA; Sorace JM, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-24; Spengler B, 2004, J AM SOC MASS SPECTR, V15, P703, DOI 10.1016/j.jasms.2004.01.007; Syka JEP, 2004, P NATL ACAD SCI USA, V101, P9528, DOI 10.1073/pnas.0402700101; Tao WA, 2003, CURR OPIN BIOTECH, V14, P110, DOI 10.1016/S0958-1669(02)00018-6; Tibshirani R, 2004, BIOINFORMATICS, V20, P3034, DOI 10.1093/bioinformatics/bth357; Tirumalai RS, 2003, MOL CELL PROTEOMICS, V2, P1096, DOI 10.1074/mcp.M300031-MCP200; VerBerkmoes NC, 2002, J PROTEOME RES, V1, P239, DOI 10.1021/pr025508a; Villanueva J, 2004, ANAL CHEM, V76, P1560, DOI 10.1021/ac0352171; Vlahou Antonia, 2003, Clin Breast Cancer, V4, P203, DOI 10.3816/CBC.2003.n.026; Wang WX, 2003, ANAL CHEM, V75, P4818, DOI 10.1021/ac026468x; Wiener MC, 2004, ANAL CHEM, V76, P6085, DOI 10.1021/ac0493875; Won Y, 2003, PROTEOMICS, V3, P2310, DOI 10.1002/pmic.200300590; Woong-Shick Ahn, 2005, Cancer Science, V96, P197, DOI 10.1111/j.1349-7006.2005.00029.x; Xiao XY, 2003, BIOMED ENVIRON SCI, V16, P140; Yanagisawa K, 2003, LANCET, V362, P433, DOI 10.1016/S0140-6736(03)14068-8; Yasui Y, 2003, BIOSTATISTICS, V4, P449, DOI 10.1093/biostatistics/4.3.449; Yip TTC, 2005, CLIN CHEM, V51, P47, DOI 10.1373/clinchem.2004.031229; Yu JK, 2004, WORLD J GASTROENTERO, V10, P3127; Zhang YF, 2004, CLIN BIOCHEM, V37, P772, DOI 10.1016/j.clinbiochem.2004.04.002; Zhang Z, 2004, CANCER RES, V64, P5882, DOI 10.1158/0008-5472.CAN-04-0746; Zhu XD, 2004, WORLD J GASTROENTERO, V10, P2327; Zhukov TA, 2003, LUNG CANCER, V40, P267, DOI 10.1016/S0169-5002(03)00082-5; Zubarev RA, 1998, J AM CHEM SOC, V120, P3265, DOI 10.1021/ja973478k	92	58	62	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1535-3893		J PROTEOME RES	J. Proteome Res.	JUL-AUG	2005	4	4					1143	1154		10.1021/pr0500962		12	Biochemical Research Methods	Biochemistry & Molecular Biology	954VV	WOS:000231184200013	
J	Fragoudis, D; Meretakis, D; Likothanassis, S				Fragoudis, D; Meretakis, D; Likothanassis, S			Best terms: an efficient feature-selection algorithm for text categorization	KNOWLEDGE AND INFORMATION SYSTEMS			English	Article						feature selection; machine learning; text categorization		In this paper, we propose a new feature-selection algorithm for text classification, called best terms (BT). The complexity of BT is linear in respect to the number of the training-set documents and is independent from both the vocabulary size and the number of categories. We evaluate BT on two benchmark document collections, Reuters-21578 and 20-Newsgroups, using two classification algorithms, naive Bayes (NB) and support vector machines (SVM). Our experimental results, comparing BT with an extensive and representative list of feature-selection algorithms, show that (1) BT is faster than the existing feature-selection algorithms; (2) BT leads to a considerable increase in the classification accuracy of NB and SVM as measured by the F1 measure; (3) BT leads to a considerable improvement in the speed of NB and SVM; in most cases, the training time of SVM has dropped by an order of magnitude; (4) in most cases, the combination of BT with the simple, but very fast, NB algorithm leads to classification accuracy comparable with SVM while sometimes it is even more accurate.	Univ Patras, Comp Engn & Informat Dept, GR-26500 Patras, Greece; Griffith Univ, Novartis Pharma, Basel, Switzerland; Inst Comp Technol, Patras, Greece	Fragoudis, D (reprint author), Univ Patras, Comp Engn & Informat Dept, GR-26500 Patras, Greece.	dfragoud@ceid.upatras.gr					Baker L. D., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.290970; Bekkerman R., 2001, P SIGIR 01 24 ACM IN, P146, DOI 10.1145/383952.383976; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288651; Fuhr N., 1991, P RIAO 91, P606; Galavotti L, 2000, LECT NOTES COMPUT SC, V1923, P59; Joachims T., 1999, ADV KERNEL METHODS S; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; John G.H., 1994, P 11 INT C MACH LEAR, P121; Lang K., 1995, P 12 INT C MACH LEAR, P331; LEWIS D. D., 1992, P SPEECH NAT LANG WO, P212, DOI 10.3115/1075527.1075574; McCallum A, 1998, P AAAI 98 WORKSH LEA, P41; Ng HT, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P67, DOI 10.1145/258525.258537; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J.R., 1983, MACHINE LEARNING ART; Rogati M., 2002, P 11 INT C INF KNOWL; Ruiz M. E., 1999, Proceedings of SIGIR '99. 22nd International Conference on Research and Development in Information Retrieval, DOI 10.1145/312624.312700; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; VANRIJSBERGEN CJ, 1979, INFORMATION RETRIEVA; Vapnik VN, 1998, STAT LEARNING THEORY; Wiener E., 1995, P 4 ANN S DOC AN INF, P317; Yang Y., 1997, 14 INT C MACH LEARN; Yang Y., 1999, J INFORMATION RETRIE, V1, P67; Yang Yiming, 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; Zhang T, 2001, INFORM RETRIEVAL, V4, P5, DOI 10.1023/A:1011441423217	26	8	8	SPRINGER LONDON LTD	LONDON	236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND	0219-1377		KNOWL INF SYST	Knowl. Inf. Syst.	JUL	2005	8	1					16	33		10.1007/s10115-004-0177-2		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	938TE	WOS:000230025100002	
J	Kenny, LC; Dunn, WB; Ellis, DI; Myers, J; Baker, PN; Kell, DB				Kenny, Louise C.; Dunn, Warwick B.; Ellis, David I.; Myers, Jenny; Baker, Philip N.; Kell, Douglas B.		GOPEC Consortium	Novel biomarkers for pre-eclampsia detected using metabolomics and machine learning	METABOLOMICS			English	Article						pre-eclampsia; mass spectrometry; GC-MS; metabolomics; machine; learning; genetic programming; prognosis; diagnosis; classification		Pre-eclampsia is a multi-system disorder of pregnancy with major maternal and perinatal implications. Emerging therapeutic strategies are most likely to be maximally effective if commenced weeks or even months prior to the clinical presentation of the disease. Although widespread plasma alterations precede the clinical onset of pre-eclampsia, no single plasma constituent has emerged as a sensitive or specific predictor of risk. Consequently, currently available methods of identifying the condition prior to clinical presentation are of limited clinical use. We have exploited genetic programming, a powerful data mining method, to identify patterns of metabolites that distinguish plasma from patients with pre-eclampsia from that taken from healthy, matched controls. High-resolution gas chromatography time-of-flight mass spectrometry (GC-tof-MS) was performed on 87 plasma samples from women with pre-eclampsia and 87 matched controls. Normalised peak intensity data were fed into the Genetic Programming (GP) system which was set up to produce a model that gave an output of 1 for patients and 0 for controls. The model was trained on 50% of the data generated and tested on a separate hold-out set of 50%. The model generated by GP from the GC-tof-MS data identified a metabolomic pattern that could be used to produce two simple rules that together discriminate pre-eclampsia from normal pregnant controls using just 3 of the metabolite peak variables, with a sensitivity of 100% and a specificity of 98%. Thus, pre-eclampsia can be diagnosed at the level of small-molecule metabolism in blood plasma. These findings justify a prospective assessment of metabolomic technology as a screening tool for pre-eclampsia, while identification of the metabolites involved may lead to an improved understanding of the aetiological basis of pre-eclampsia and thus the development of targeted therapies.	[Kenny, Louise C.; Myers, Jenny; Baker, Philip N.] Univ Manchester, St Marys Hosp, Maternal & Fetal Hlth Res Ctr, Manchester M13 0JH, Lancs, England; [Dunn, Warwick B.; Ellis, David I.; Kell, Douglas B.] Univ Manchester, Sch Chem, Manchester M60 1QD, Lancs, England	Kenny, LC (reprint author), Univ Manchester, St Marys Hosp, Maternal & Fetal Hlth Res Ctr, Whitworth Pk, Manchester M13 0JH, Lancs, England.	louise.kenny@manchester.ac.uk; dbk@manchester.ac.uk	Kell, Douglas/E-8318-2011; Kenny, Louise/G-1112-2011	Kenny, Louise/0000-0002-9011-759X	BBSRC; EPSRC; Royal Society of Chemistry	LK, JM, & PB thank Tommy's, the Baby Charity, for financial support. DBK thanks the BBSRC, EPSRC and the Royal Society of Chemistry for financial support. The authors wish to thank Jenny Robinson and Dympna Tansinda for their assistance with the collection of control plasma samples. We thank an anonymous referee for a useful comment.	Allen J, 2004, APPL ENVIRON MICROB, V70, P6157, DOI 10.1128/AEM.70.10.6157-6165.2004; Bino RJ, 2004, TRENDS PLANT SCI, V9, P418, DOI 10.1016/j.tplants.2004.07.004; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Brindle JT, 2002, NAT MED, V8, P1439, DOI 10.1038/nm802; BROWN M, 2005, METABOLOMICS, V1, P35; Dunn WB, 2005, ANALYST, V130, P606, DOI 10.1039/b418288j; Dunn WB, 2005, TRAC-TREND ANAL CHEM, V24, P285, DOI 10.1016/j.trac.2004.11.021; ELLIS DI, 2003, METABOLIC PROFILING; Ellis DI, 2002, APPL ENVIRON MICROB, V68, P2822, DOI 10.1128/AEM.68.6.2822-2828.2002; Fiehn O, 2000, NAT BIOTECHNOL, V18, P1157, DOI 10.1038/81137; Frank R, 2003, NAT REV DRUG DISCOV, V2, P566, DOI 10.1038/nrd1130; Gardosi J, 1998, J PERINAT MED, V26, P137; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Goodacre R, 2004, TRENDS BIOTECHNOL, V22, P245, DOI 10.1016/j.tibtech.2004.03.007; Harrigan GG, 2003, METABOLIC PROFILING; Hayman R, 1999, J SOC GYNECOL INVEST, V6, P3, DOI 10.1016/S1071-5576(98)00044-6; Hibbard B, 1994, Health Trends, V26, P26; JELLUM E, 1981, J CHROMATOGR, V217, P231, DOI 10.1016/S0021-9673(00)88077-2; Kell DB, 2004, CURR OPIN MICROBIOL, V7, P296, DOI 10.1016/j.mib.2004.04.012; KELL DB, 2005, BIOCH SOC T IN PRESS, V33; KELL DB, 2005, NAT REV IN PRESS JUL; Kell DB, 2000, NATO ASI 3 HIGH TECH, V74, P3; Kell DB, 2001, PLANT PHYSIOL, V126, P943, DOI 10.1104/pp.126.3.943; Kell DB, 2004, BIOESSAYS, V26, P99, DOI 10.1002/bies.10385; Kell DB, 2002, TRENDS GENET, V18, P555, DOI 10.1016/S0168-9525(02)02765-8; Kenny LC, 2002, CLIN SCI, V103, P67; Koza J. R., 1992, GENETIC PROGRAMMING; Lesko LJ, 2001, ANNU REV PHARMACOL, V41, P347, DOI 10.1146/annurev.pharmtox.41.1.347; LEWIS G, 2001, WHY WOMEN DIE REPORT; O'Hagan S, 2005, ANAL CHEM, V77, P290, DOI 10.1021/ac049146x; Oliver SG, 1998, TRENDS BIOTECHNOL, V16, P373, DOI 10.1016/S0167-7799(98)01214-1; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; PIJNENBORG R, 1991, BRIT J OBSTET GYNAEC, V98, P648, DOI 10.1111/j.1471-0528.1991.tb13450.x; Raamsdonk LM, 2001, NAT BIOTECHNOL, V19, P45; Rashed MS, 2001, J CHROMATOGR B, V758, P27, DOI 10.1016/S0378-4347(01)00100-1; ROBERTS JM, 1989, AM J OBSTET GYNECOL, V161, P1200; RODGERS GM, 1988, AM J OBSTET GYNECOL, V159, P908; Shi Y, 2003, NATURE, V425, P516, DOI 10.1038/nature01991; van der Greef J, 2004, CURR OPIN CHEM BIOL, V8, P559, DOI 10.1016/j.cbpa.2004.08.013; Urbanczyk-Wochniak E, 2003, EMBO REP, V4, P989, DOI 10.1038/sj.embor.embor944; Whitfield PD, 2004, BRIT J NUTR, V92, P549, DOI 10.1079/BJN20041243; *CESDI, 1998, 5 CESDI MAT CHILD HL	42	46	49	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1573-3882		METABOLOMICS	Metabolomics	JUL	2005	1	3					227	234		10.1007/s11306-005-0003-1		8	Endocrinology & Metabolism	Endocrinology & Metabolism	V63QO	WOS:000204301800002	
J	Chen, BN; Harrison, RF; Hert, J; Mpanhanga, C; Willett, P; Wilton, DJ				Chen, BN; Harrison, RF; Hert, J; Mpanhanga, C; Willett, P; Wilton, DJ			Ligand-based virtual screening using binary kernel discrimination	MOLECULAR SIMULATION			English	Article						binary kernel discrimination; circular substructure; fingerprints; similarity searching; virtual screening	BIOACTIVE REFERENCE STRUCTURES; SUBSTRUCTURAL ANALYSIS; DESCRIPTORS	This paper discusses the use of a machine- learning technique called binary kernel discrimination ( BKD) for virtual screening in drug- and pesticide- discovery programmes. BKD is compared with several other ligand- based tools for virtual screening in databases of 2D structures represented by fragment bit- strings, and is shown to provide an effective, and reasonably efficient, way of prioritising compounds for biological screening.	Univ Sheffield, Krebs Inst Biomolec Res, Dept Chem, Sheffield S10 2TN, S Yorkshire, England; Univ Sheffield, Dept Automat Control & Syst Engn, Sheffield S10 2TN, S Yorkshire, England; Univ Sheffield, Dept Informat Studies, Sheffield S10 2TN, S Yorkshire, England	Willett, P (reprint author), Univ Sheffield, Krebs Inst Biomolec Res, Dept Chem, Sheffield S10 2TN, S Yorkshire, England.	p.willett@sheffield.ac.uk	Hert, Jerome/A-8158-2008; Harrison, Robert/B-9034-2008				AITCHISON J, 1976, BIOMETRIKA, V63, P413, DOI 10.1093/biomet/63.3.413; Bender A, 2004, J CHEM INF COMP SCI, V44, P170, DOI 10.1021/ci034207y; Bender A, 2004, J CHEM INF COMP SCI, V44, P1708, DOI 10.1021/ci0498719; Bohm H.-J, 2000, VIRTUAL SCREENING BI; CRAMER RD, 1974, J MED CHEM, V17, P533, DOI 10.1021/jm00251a014; Ginn CMR, 2000, PERSPECT DRUG DISCOV, V20, P1, DOI 10.1023/A:1008752200506; Harper G, 2001, J CHEM INF COMP SCI, V41, P1295, DOI 10.1021/ci000397q; Hert J, 2004, J CHEM INF COMP SCI, V44, P1177, DOI 10.1021/ci034231b; Hert J, 2004, ORG BIOMOL CHEM, V2, P3256, DOI 10.1039/b409865j; Holliday JD, 2003, J CHEM INF COMP SCI, V43, P819, DOI 10.1021/ci034001x; Klebe G, 2000, VIRTUAL SCREENING AL; MORGAN HL, 1965, J CHEM DOC, V5, P107, DOI 10.1021/c160017a018; ORMEROD A, 1989, QUANT STRUCT-ACT REL, V8, P115, DOI 10.1002/qsar.19890080207; Shemetulskis NE, 1996, J CHEM INF COMP SCI, V36, P862, DOI 10.1021/ci950169+; Sheridan RP, 2002, DRUG DISCOV TODAY, V7, P903, DOI 10.1016/S1359-6446(02)02411-X; Williamson BL, 1998, NAT MED, V4, P983, DOI 10.1038/1951; Wilton D, 2003, J CHEM INF COMP SCI, V43, P469, DOI 10.1021/ci025586i	17	2	2	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0892-7022		MOL SIMULAT	Mol. Simul.	JUL	2005	31	8					597	604		10.1080/08927020500134177		8	Chemistry, Physical; Physics, Atomic, Molecular & Chemical	Chemistry; Physics	956PH	WOS:000231311800008	
J	Bao, L; Zhou, M; Cui, Y				Bao, L; Zhou, M; Cui, Y			nsSNPAnalyzer: identifying disease-associated nonsynonymous single nucleotide polymorphisms	NUCLEIC ACIDS RESEARCH			English	Article							DATABASE; CLASSIFICATION; PREDICTION; SEQUENCES	Nonsynonymous single nucleotide polymorphisms (nsSNPs) are prevalent in genomes and are closely associated with inherited diseases. To facilitate identifying disease-associated nsSNPs from a large number of neutral nsSNPs, it is important to develop computational tools to predict the nsSNP's phenotypic effect (disease-associated versus neutral). nsSNPAnalyzer, a web-based software developed for this purpose, extracts structural and evolutionary information from a query nsSNP and uses a machine learning method called Random Forest to predict the nsSNP's phenotypic effect. nsSNPAnalyzer server is available at http://snpanalyzer.utmem.edu/.	Univ Tennessee, Ctr Hlth Sci, Ctr Genom & Bioinformat, Dept Mol Sci, Memphis, TN 38163 USA	Cui, Y (reprint author), Univ Tennessee, Ctr Hlth Sci, Ctr Genom & Bioinformat, Dept Mol Sci, 858 Madison Ave, Memphis, TN 38163 USA.	ycui2@utmem.edu					BAO L, 2005, BIOINFORMATICS, DOI DOI 10.1093/BIOINFORMSTICS/BTI365; BOWIE JU, 1991, SCIENCE, V253, P164, DOI 10.1126/science.1853201; BREIMAN L, 2001, RANDOM FOREST; Chandonia JM, 2004, NUCLEIC ACIDS RES, V32, pD189, DOI 10.1093/nar/gkh034; Fredman D, 2002, NUCLEIC ACIDS RES, V30, P387, DOI 10.1093/nar/30.1.387; Frishman D, 1995, PROTEINS, V23, P566, DOI 10.1002/prot.340230412; Gunther EC, 2003, P NATL ACAD SCI USA, V100, P9608, DOI 10.1073/pnas.1632587100; Irizarry K, 2000, NAT GENET, V26, P233; Ng PC, 2001, GENOME RES, V11, P863, DOI 10.1101/gr.176601; Ng PC, 2003, NUCLEIC ACIDS RES, V31, P3812, DOI 10.1093/nar/gkg509; Ramensky V, 2002, NUCLEIC ACIDS RES, V30, P3894, DOI 10.1093/nar/gkf493; Saunders CT, 2002, J MOL BIOL, V322, P891, DOI 10.1016/S0022-2836(02)00813-6; Sherry ST, 2001, NUCLEIC ACIDS RES, V29, P308, DOI 10.1093/nar/29.1.308; Stenson PD, 2003, HUM MUTAT, V21, P577, DOI 10.1002/humu.10212; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210; Yip YL, 2004, HUM MUTAT, V23, P464, DOI 10.1002/humu.20021	17	44	45	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0305-1048		NUCLEIC ACIDS RES	Nucleic Acids Res.	JUL 1	2005	33			2			W480	W482		10.1093/nar/gki372		3	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	942GR	WOS:000230271400097	
J	Kumar, M; Bhasin, M; Natt, NK; Raghava, GPS				Kumar, M; Bhasin, M; Natt, NK; Raghava, GPS			BhairPred: prediction of beta-hairpins in a protein from multiple alignment information using ANN and SVM techniques	NUCLEIC ACIDS RESEARCH			English	Article							NEURAL-NETWORK METHOD; SECONDARY STRUCTURE; PSI-BLAST; TURNS; ACCURACY	This paper describes a method for predicting a supersecondary structural motif, beta-hairpins, in a protein sequence. The method was trained and tested on a set of 5102 hairpins and 5131 non-hairpins, obtained from a non-redundant dataset of 2880 proteins using the DSSP and PROMOTIF programs. Two machine-learning techniques, an artificial neural network (ANN) and a support vector machine (SVM), were used to predict beta-hairpins. An accuracy of 65.5% was achieved using ANN when an amino acid sequence was used as the input. The accuracy improved from 65.5 to 69.1% when evolutionary information (PSI- BLAST profile), observed secondary structure and surface accessibility were used as the inputs. The accuracy of the method further improved from 69.1 to 79.2% when the SVM was used for classification instead of the ANN. The performances of the methods developed were assessed in a test case, where predicted secondary structure and surface accessibility were used instead of the observed structure. The highest accuracy achieved by the SVM based method in the test case was 77.9%. A maximum accuracy of 71.1% with Matthew's correlation coefficient of 0.41 in the test case was obtained on a dataset previously used by X. Cruz, E. G. Hutchinson, A. Shephard and J.M. Thornton (2002) Proc. NatlAcad. Sci. USA, 99, 11157-11162. The performance of the method was also evaluated on proteins used in the '6th community-wide experiment on the critical assessment of techniques for protein structure prediction (CASP6)'. Based on the algorithm described, a web server, BhairPred ( http:// www. imtech. res. in/ raghava/ bhairpred/), has been developed, which can be used to predict b- hairpins in a protein using the SVM approach.	Inst Microbial Technol, Bioinformat Ctr, Chandigarh, India	Raghava, GPS (reprint author), Inst Microbial Technol, Bioinformat Ctr, Sector 39-A, Chandigarh, India.	raghava@imtech.res.in	Bhasin, Manoj /B-3018-2009; Raghava, Gajendra/B-1717-2009				Ahmad S, 2002, BIOINFORMATICS, V18, P819, DOI 10.1093/bioinformatics/18.6.819; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; BRANDEN C, 1999, INTRO PROTEIN STRUCT, P67; CRUZ X, 2002, P NATL ACAD SCI USA, V99, P11157; HUTCHINSONEG, 1996, PROTEIN SCI, V5, P212; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; Jones D T, 1999, Proteins, VSuppl 3, P104; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; Kaur H, 2004, PROTEINS, V55, P83, DOI 10.1002/prot.10569; Kaur H, 2003, PROTEIN SCI, V12, P923, DOI 10.1110/ps.0241703; Kaur H, 2003, PROTEIN SCI, V12, P627, DOI 10.1110/ps.0228903; Kaur Harpreet, 2003, J Bioinform Comput Biol, V1, P495, DOI 10.1142/S0219720003000253; Kaur H, 2002, BIOINFORMATICS, V18, P498, DOI 10.1093/bioinformatics/18.3.498; Kaur H, 2004, BIOINFORMATICS, V20, P2751, DOI 10.1093/bioinformatics/bth322; Kaur H, 2002, BIOINFORMATICS, V18, P1508, DOI 10.1093/bioinformatics/18.11.1508; Kuhn M, 2004, PROTEINS, V54, P282, DOI 10.1002/prot.10589; Petersen TN, 2000, PROTEINS, V41, P17, DOI 10.1002/1097-0134(20001001)41:1<17::AID-PROT40>3.0.CO;2-F; Raghava G.P.S., 2000, CASP, V4, P75; ROST B, 1993, J MOL BIOL, V232, P584, DOI 10.1006/jmbi.1993.1413; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sun ZR, 1997, PROTEIN ENG, V10, P763, DOI 10.1093/protein/10.7.763	22	24	27	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0305-1048		NUCLEIC ACIDS RES	Nucleic Acids Res.	JUL 1	2005	33			2			W154	W159		10.1093/nar/gki588		6	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	942GR	WOS:000230271400028	
J	Chang, KC; Chen, HD				Chang, KC; Chen, HD			Efficient inference for hybrid dynamic Bayesian networks	OPTICAL ENGINEERING			English	Article						dynamic Bayesian networks; hybrid Bayesian networks; decision tree; estimation for dynamic systems		Bayesian networks for static as well as for dynamic cases have been the subject of a great deal of theoretical analysis and practical inference-algorithm development in the research community of artificial intelligence, machine learning, and pattern recognition. After summarizing the well-known theory of discrete and continuous Bayesian networks, we introduce an efficient reasoning scheme into hybrid Bayesian networks. In addition to illustrating the similarities between the dynamic Bayesian networks and the Kalman filter, we present a computationally efficient approach for the inference problem of hybrid dynamic Bayesian networks (HDBNs). The proposed method is based on the separation of the dynamic and static nodes, and subsequent hypercubic partitions via the decision tree algorithm. Experiments show that with high statistical confidence the novel algorithm used in the HDBN performs favorably in the trade-offs of computational complexity and accuracy performance, compared to other exact and approximate methods for applications with uncertainty in a dynamic system. (c) 2005 Society of Photo-Optical Instrumentation Engineers.	George Mason Univ, Dept Syst Engn & Operat Res, Fairfax, VA 22030 USA	Chang, KC (reprint author), George Mason Univ, Dept Syst Engn & Operat Res, MS 4A6,4400 Univ Dr, Fairfax, VA 22030 USA.	kchang@gmu.edu					Anderson B. D. O., 1979, OPTIMAL FILTERING; BOYEN X, 1998, P 14 C UNC ART INT; Chang KC, 2003, P SOC PHOTO-OPT INS, V5096, P346, DOI 10.1117/12.486863; HECKERMAN D, 1995, COMMUN ACM, V38, P24, DOI 10.1145/203330.203334; Jensen F., 1996, INTRO BAYESIAN NETWO; KJAERULFF U, 1992, P 8 C UNC ART INT; KOZLOV AV, 1997, P 13 C UNC ART INT, P314; LERNER UN, 2001, P 17 C UNC ART INT; Martinez-Munoz G, 2004, IEEE T SYST MAN CY C, V34, P393, DOI 10.1109/TSMCC.2004.833295; POLAND WB, 1993, P 9 C UNC ART INT; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; TAKIKAWA M, 2002, P 18 C UNC ART INT	12	0	0	SPIE-INT SOCIETY OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA	0091-3286		OPT ENG	Opt. Eng.	JUL	2005	44	7							077201	10.1117/1.1948127		7	Optics	Optics	974KU	WOS:000232591100039	
J	Lee, KK; Yoon, WC				Lee, KK; Yoon, WC			Adaptive classification with ellipsoidal regions for multidimensional pattern classification problems	PATTERN RECOGNITION LETTERS			English	Article						classification; ellipsoidal regions; adaptation procedure; input variable selection	FUZZY CLASSIFIER; FEATURE-SELECTION; RULES; PERFORMANCE	This paper presents an adaptive classification method that utilizes ellipsoidal regions for multidimensional pattern classification problems with continuous input variables. The classification method fits a finite number of the ellipsoidal regions to data pattern by using adaptive operations iteratively. The method adaptively expands, rotates, shrinks, and/ or moves the ellipsoidal regions while each ellipsoidal region is separately handled with a fitness value assigned. The adaptation procedure is combined with a variable selection process in the outer loop, where significant input variables for the ellipsoids are determined by using a stepwise selection method. The performance of the method is evaluated on well-known classification problems from the UCI machine learning repository. The evaluation result shows that the proposed method can exert equivalent or superior performance, with smaller number of rules, to other classification methods such as fuzzy rules, decision trees, or neural networks. &COPY; 2004 Elsevier B.V. All rights reserved.	Korea Adv Inst Sci & Technol, Dept Ind Engn, Taejon 305701, South Korea	Lee, KK (reprint author), Korea Adv Inst Sci & Technol, Dept Ind Engn, 373-1 Gusong Dong, Taejon 305701, South Korea.	kiklee@naver.com	Yoon, Wan Chul/C-1982-2011				Abe S, 1997, IEEE T FUZZY SYST, V5, P358, DOI 10.1109/91.618273; ABE S, 1995, IEEE T FUZZY SYST, V3, P18, DOI 10.1109/91.366565; Abe S, 1999, IEEE T SYST MAN CY C, V29, P140, DOI 10.1109/5326.740676; Baram Y, 2000, PATTERN RECOGN, V33, P177, DOI 10.1016/S0031-3203(99)00050-3; BLAKE CL, 1998, UCI RESP MACHINE LEA; Garcia S, 1999, LECT NOTES COMPUT SC, V1598, P203; Haykin S., 1994, NEURAL NETWORKS COMP; Hoffmann F, 2004, FUZZY SET SYST, V141, P47, DOI 10.1016/S0165-0114(03)00113-1; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; Ishibuchi H, 1999, IEEE T SYST MAN CY B, V29, P601, DOI 10.1109/3477.790443; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Liu HA, 1998, APPL INTELL, V9, P217, DOI 10.1023/A:1008363719778; Olaru C, 2003, FUZZY SET SYST, V138, P221, DOI 10.1016/S0165-0114(03)00089-7; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Corcoran A. L., 1994, Proceedings of the First IEEE Conference on Evolutionary Computation. IEEE World Congress on Computational Intelligence (Cat. No.94TH0650-2), DOI 10.1109/ICEC.1994.350030; SIMPSON PK, 1992, IEEE T NEURAL NETWOR, V3, P776, DOI 10.1109/72.159066; UEBELE V, 1995, IEEE T SYST MAN CYB, V25, P353, DOI 10.1109/21.364829; WEISS SM, 1991, COMPUTER SYSTEMS THA	20	3	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	JUL 1	2005	26	9					1232	1243		10.1016/j.patrec.2004.11.004		12	Computer Science, Artificial Intelligence	Computer Science	932OB	WOS:000229561900003	
J	Saetrom, O; Snove, O; Saetrom, P				Saetrom, O; Snove, O; Saetrom, P			Weighted sequence motifs as an improved seeding step in microRNA target prediction algorithms	RNA-A PUBLICATION OF THE RNA SOCIETY			English	Article						miRNA target prediction; genetic programming; boosting; machine learning	CAENORHABDITIS-ELEGANS; MESSENGER-RNA; C-ELEGANS; COMPUTATIONAL IDENTIFICATION; MAMMALIAN-CELLS; REGULATORY RNA; GENES; EXPRESSION; DROSOPHILA; ANTISENSE	We present a new microRNA target prediction algorithm called TargetBoost, and show that the algorithm is stable and identifies more true targets than do existing algorithms. TargetBoost uses machine learning on a set of validated microRNA targets in lower organisms to create weighted sequence motifs that capture the binding characteristics between microRNAs and their targets. Existing algorithms require candidates to have (1) near-perfect complementarity between microRNAs' 5' end and their targets; (2) relatively high thermodynamic duplex stability; (3) multiple target sites in the target's 3' UTR; and (4) evolutionary conservation of the target between species. Most algorithms use one of the two first requirements in a seeding step, and use the three others as filters to improve the method's specificity. The initial seeding step determines an algorithm's sensitivity and also influences its specificity. As all algorithms may add filters to increase the specificity, we propose that methods should be compared before such filtering. We show that TargetBoost's weighted sequence motif approach is favorable to using both the duplex stability and the sequence complementarity steps.	Interagon AS, Med Tek Ctr, NO-7489 Trondheim, Norway; Norwegian Univ Sci & Technol, Dept Comp & Informat Sci, N-7034 Trondheim, Norway	Saetrom, P (reprint author), Interagon AS, Med Tek Ctr, NO-7489 Trondheim, Norway.	paal.saetrom@interagon.com					Bartel DP, 2004, CELL, V116, P281, DOI 10.1016/S0092-8674(04)00045-5; Boutla A, 2003, NUCLEIC ACIDS RES, V31, P4973, DOI 10.1093/nar/gkg707; Breiman L, 1984, CLASSIFICATION REGRE; Brennecke J, 2003, CELL, V113, P25, DOI 10.1016/S0092-8674(03)00231-9; Doench JG, 2003, GENE DEV, V17, P438, DOI 10.1101/gad.1064703; Doench JG, 2004, GENE DEV, V18, P504, DOI 10.1101/gad.1184404; Enright AJ, 2004, GENOME BIOL, V5; Gribskov M, 1996, COMPUT CHEM, V20, P25, DOI 10.1016/S0097-8485(96)80004-0; Griffiths-Jones S, 2004, NUCLEIC ACIDS RES, V32, pD109, DOI 10.1093/nar/gkh023; Halaas A, 2004, IEEE T VLSI SYST, V12, P727, DOI [10.1109/TVLSI.2004.830918, 10.1109/tvlsi.2004.830918]; John B, 2004, PLOS BIOL, V2, P1862, DOI 10.1371/journal.pbio.0020363; Kiriakidou M, 2004, GENE DEV, V18, P1165, DOI 10.1101/gad.1184704; Kloosterman WP, 2004, NUCLEIC ACIDS RES, V32, P6284, DOI 10.1093/nar/gkh968; KNUTH DE, 1964, COMMUN ACM, V7, P735, DOI 10.1145/355588.365140; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Koza J. R., 1992, GENETIC PROGRAMMING; Lagos-Quintana M, 2001, SCIENCE, V294, P853, DOI 10.1126/science.1064921; Lai EC, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-9-115; Lai EC, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-7-r42; Lau NC, 2001, SCIENCE, V294, P858, DOI 10.1126/science.1065062; Lee RC, 2001, SCIENCE, V294, P862, DOI 10.1126/science.1065329; LEE RC, 1993, CELL, V75, P843, DOI 10.1016/0092-8674(93)90529-Y; Lewis BP, 2003, CELL, V115, P787, DOI 10.1016/S0092-8674(03)01018-3; Lim LP, 2003, GENE DEV, V17, P991, DOI 10.1101/gad.1074403; Lim LP, 2003, SCIENCE, V299, P1540, DOI 10.1126/science.1080372; Meir R, 2002, LECT NOTES ARTIF INT, V2600, P118; Metz CE, 1998, MED DECIS MAKING, V18, P110, DOI 10.1177/0272989X9801800118; Moss EG, 1997, CELL, V88, P637, DOI 10.1016/S0092-8674(00)81906-6; Olsen PH, 1999, DEV BIOL, V216, P671, DOI 10.1006/dbio.1999.9523; Pasquinelli AE, 2000, NATURE, V408, P86, DOI 10.1038/35040556; Rajewsky N, 2004, DEV BIOL, V267, P529, DOI 10.1016/j.ydbio.2003.12.003; Rehmsmeier M, 2004, RNA, V10, P1507, DOI 10.1021/rna.5248604; Reinscheid RK, 2000, PEPTIDES, V21, P901, DOI 10.1016/S0196-9781(00)00226-6; Saetrom P, 2004, BIOCHEM BIOPH RES CO, V321, P247, DOI 10.1016/j.bbrc.2004.06.116; Saetrom P, 2004, BIOINFORMATICS, V20, P3055, DOI 10.1093/bioinformatics/bth364; Saxena S, 2003, J BIOL CHEM, V278, P44312, DOI 10.1074/jbc.M307089200; Scacheri PC, 2004, P NATL ACAD SCI USA, V101, P1892, DOI 10.1073/pnas.0308698100; Smalheiser NR, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-139; Stark A, 2003, PLOS BIOL, V1, P397, DOI 10.1371/journal.pbio.0000060; WIGHTMAN B, 1993, CELL, V75, P855, DOI 10.1016/0092-8674(93)90530-4; Yekta S, 2004, SCIENCE, V304, P594, DOI 10.1126/science.1097434; Zeng Y, 2002, MOL CELL, V9, P1327, DOI 10.1016/S1097-2765(02)00541-5; Zuker M, 2003, NUCLEIC ACIDS RES, V31, P3406, DOI 10.1093/nar/gkg595	43	63	72	COLD SPRING HARBOR LAB PRESS, PUBLICATIONS DEPT	COLD SPRING HARBOR	1 BUNGTOWN RD, COLD SPRING HARBOR, NY 11724 USA	1355-8382		RNA	RNA-Publ. RNA Soc.	JUL	2005	11	7					995	1003		10.1261/rna.7290705		9	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	941LQ	WOS:000230216700001	
J	Luke, S; Cioffi-Revilla, C; Panait, L; Sullivan, K; Balan, G				Luke, S; Cioffi-Revilla, C; Panait, L; Sullivan, K; Balan, G			MASON: A multiagent simulation environment	SIMULATION-TRANSACTIONS OF THE SOCIETY FOR MODELING AND SIMULATION INTERNATIONAL			English	Article						agent-based modeling; simulation; multi-agent systems; computational social science		MASON is a fast, easily extensible, discrete-event multi-agent simulation toolkit in Java, designed to serve as the basis for a wide range of multi-agent simulation tasks ranging from swarm robotics to machine learning to social complexity environments. MASON carefully delineates between model and visualization, allowing models to be dynamically detached from or attached to visualizers, and to change platforms mid-run. This paper describes the MASON system, its motivation, and its basic architectural design. It then compares MASON to related multi-agent libraries in the public domain, and discusses six applications of the system built over the past year which suggest its breadth of utility.	George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA; George Mason Univ, Ctr Social Complex, Fairfax, VA 22030 USA	Luke, S (reprint author), George Mason Univ, Dept Comp Sci, 4400 Univ Dr, Fairfax, VA 22030 USA.						AXTELL R, 2001, SOCIAL SCI COMPUTATI; BALCH T, 1997, TEAMBOTS SIMULATION; BASSETT JK, 2000, P 12 INT S METH INT, P157; Cioffi-Revilla C., 2004, P AG 2004 C SOC DYN; COLLIER N, 2001, REPAST AGENT BASED M; Epstein Joshua M., 1996, GROWING ARTIFICIAL S; Fernandez F., 2001, International Journal of Robotics & Automation, V16; GERKEY B, 2003, PLAYER STAGE ROBOTIC; GILBERT D, 2004, JFREECHART; Gilbert N., 2005, SIMULATION SOCIAL SC; JOHNSON PE, 2000, SWARM USER GUIDE; KLEIN J, 2002, P ART LIF 8 INT C SI, V8; LOWAGIE B, 2004, ITEXT JAVA PDF GENER; Luke S., 2005, P 4 INT JOINT C AUT, P911, DOI 10.1145/1082473.1082611; Luke S., 2004, ECJ 11 JAVA EVOLUTIO; PANAIT L, 2004, P 3 INT JOINT C AUT; Panait L., 2004, P 9 INT C SIM SYNTH; Parker L., 2003, MULTIROBOT SYSTEMS, V2, P205; Parker LE, 2002, AUTON ROBOT, V12, P231, DOI 10.1023/A:1015256330750; PARKER M, 1998, ASCAPE; PAUS S, 2003, FLOODLAND SIMPLE SIM; Resnick M., 1994, TURTLES TERMITES TRA; Smith R. L., 2004, OPEN DYNAMICS ENGINE; Wilensky U., 1999, NETLOGO	24	105	106	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	0037-5497		SIMUL-T SOC MOD SIM	Simul.-Trans. Soc. Model. Simul. Int.	JUL	2005	81	7					517	527		10.1177/0037549705058073		11	Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering	Computer Science	968CF	WOS:000232138800005	
J	Rohde, DJ; Drinkwater, MJ; Gallagher, MR; Downs, T; Doyle, MT				Rohde, DJ; Drinkwater, MJ; Gallagher, MR; Downs, T; Doyle, MT			Applying machine learning to catalogue matching in astrophysics	MONTHLY NOTICES OF THE ROYAL ASTRONOMICAL SOCIETY			English	Article						astronomical data bases : miscellaneous; catalogues	SUPERCOSMOS SKY SURVEY; NEURAL-NETWORKS; HIPASS CATALOG; CLASSIFICATION; ASTRONOMY	We present the results of applying automated machine learning techniques to the problem of matching different object catalogues in astrophysics. In this study, we take two partially matched catalogues where one of the two catalogues has a large positional uncertainty. The two catalogues we used here were taken from the H I Parkes All Sky Survey (HIPASS) and SuperCOSMOS optical survey. Previous work had matched 44 per cent (1887 objects) of HIPASS to the SuperCOSMOS catalogue. A supervised learning algorithm was then applied to construct a model of the matched portion of our catalogue. Validation of the model shows that we achieved a good classification performance (99.12 per cent correct). Applying this model to the unmatched portion of the catalogue found 1209 new matches. This increases the catalogue size from 1887 matched objects to 3096. The combination of these procedures yields a catalogue that is 72 per cent matched.	Univ Queensland, Dept Phys, St Lucia, Qld 4072, Australia; Univ Queensland, Sch ITEE, St Lucia, Qld 4072, Australia	Rohde, DJ (reprint author), Univ Queensland, Dept Phys, St Lucia, Qld 4072, Australia.	djr@physics.uq.edu.au	Drinkwater, Michael/A-2201-2008	Drinkwater, Michael/0000-0003-4867-0022			Andreon S, 2000, MON NOT R ASTRON SOC, V319, P700, DOI 10.1046/j.1365-8711.2000.03700.x; Bazell D, 2001, ASTROPHYS J, V548, P219, DOI 10.1086/318696; Bertin E, 1996, ASTRON ASTROPHYS SUP, V117, P393, DOI 10.1051/aas:1996164; Bishop C. M., 1995, NEURAL NETWORKS PATT, P116; Budavari T, 2004, ASTR SOC P, V314, P177; CRISTIANINI N, 2000, SUPPORT VECTOR MACHI, P103; Drinkwater MJ, 1997, MON NOT R ASTRON SOC, V284, P85; FELLEGI IP, 1969, J AM STAT ASSOC, V64, P1183, DOI 10.2307/2286061; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hambly NC, 2001, MON NOT R ASTRON SOC, V326, P1279, DOI 10.1111/j.1365-2966.2001.04660.x; Hambly NC, 2001, MON NOT R ASTRON SOC, V326, P1295, DOI 10.1111/j.1365-2966.2001.04661.x; Joachims T., 1998, ADV KERNEL METHODS S; Meyer MJ, 2004, MON NOT R ASTRON SOC, V350, P1195, DOI 10.1111/j.1365-2966.2004.07710.x; Richard GF, 2000, EMBO REP, V1, P122, DOI 10.1093/embo-reports/kvd031; Rohde D, 2004, LECT NOTES COMPUT SC, V3177, P702; SCHLKOPF B, 2002, LEARNING KERNELS SUP, P45; SUTHERLAND W, 1992, MON NOT R ASTRON SOC, V259, P413; Tagliaferri R, 2003, NEURAL NETWORKS, V16, P297, DOI 10.1016/S0893-6080(03)00028-5; VAPNIK V, 1995, NATURE STAT LEARNING, P437; Voisin B, 2001, P SOC PHOTO-OPT INS, V4477, P35, DOI 10.1117/12.447184; Wakamatsu K, 2003, ASTR SOC P, V289, P97; Zwaan MA, 2004, MON NOT R ASTRON SOC, V350, P1210, DOI 10.1111/j.1365-2966.2004.07782.x	22	7	7	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	0035-8711		MON NOT R ASTRON SOC	Mon. Not. Roy. Astron. Soc.	JUN 11	2005	360	1					69	75		10.1111/j.1365-2966.2005.08930.x		7	Astronomy & Astrophysics	Astronomy & Astrophysics	937ET	WOS:000229908100006	
J	Qin, ZC; Lawry, J				Qin, ZC; Lawry, J			Decision tree learning with fuzzy labels	INFORMATION SCIENCES			English	Article						label semantics; LID3; linguistic decision tree; mass assignment; random set; linguistic constraint; transparency	LOGIC	Label semantics is a random set based framework for "Computing with Words" that captures the idea of computation on linguistic terms rather than numerical quantities. Within this new framework, a decision tree learning model is proposed where nodes are linguistic descriptions of variables and leaves are sets of appropriate labels. In such decision trees, the probability estimates for branches across the whole tree is used for classification, instead of the majority class of the single branch into which the examples fall. By empirical experiments on real-world datasets it is verified that our algorithm has better or equivalent classification accuracy compared to three well known machine learning algorithms. By applying a new forward branch merging algorithm, the complexity of the tree can be greatly reduced without significant loss of accuracy. Finally, a linguistic interpretation of trees and classification with linguistic constraints are introduced. (c) 2004 Elsevier Inc. All rights reserved.	Univ Bristol, Dept Engn Math, Artificial Intelligence Grp, Bristol BS8 1TR, Avon, England	Qin, ZC (reprint author), Univ Bristol, Dept Engn Math, Artificial Intelligence Grp, Bristol BS8 1TR, Avon, England.	Z.Qin@bristol.ac.uk; J.Lawry@bristol.ac.uk					Baldwin J., 1995, FRIL FUZZY EVIDENTIA; BALDWIN JF, 1997, P FUZZ LOG APPL FUT, P278; Blake C, UCI MACHINE LEARNING; FAYYAD UM, 1993, P 13 INT JOINT C ART, V2; Goodman I.R., 1982, FUZZY SET POSSIBILIT, P327; JANIKOW CZ, 1998, IEEE T SYSTEMS MAN B, V28; Jeffrey R., 1965, LOGIC DECISION; LAWRY J, 2001, P 10 IEEE INT C FUZZ; Lawry J, 1998, INT J APPROX REASON, V19, P315, DOI 10.1016/S0888-613X(98)10013-0; Lawry J, 2004, ARTIF INTELL, V155, P1, DOI 10.1016/j.artint.2003.10.001; LAWRY J, 2001, LECT NOTES ARTIF INT, P374; Mitchell T, 1997, MACHINE LEARNING; Olaru C, 2003, FUZZY SET SYST, V138, P221, DOI 10.1016/S0165-0114(03)00089-7; PENG Y, 2001, ECML PKDD WORKSH IDD; Provost F, 2003, MACH LEARN, V52, P199, DOI 10.1023/A:1024099825458; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; RANDON NJ, 2002, LINGUISTIC MODELLING; Witten I. H., 1999, DATA MINING PRACTICA; Zadeh LA, 1996, IEEE T FUZZY SYST, V4, P103, DOI 10.1109/91.493904	20	34	34	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255		INFORM SCIENCES	Inf. Sci.	JUN 9	2005	172	1-2					91	129		10.1016/j.ins.2004.12.005		39	Computer Science, Information Systems	Computer Science	930YE	WOS:000229452200004	
J	Dubey, A; Realff, MJ; Lee, JH; Bommarius, AS				Dubey, A; Realff, MJ; Lee, JH; Bommarius, AS			Support vector machines for learning to identify the critical positions of a protein	JOURNAL OF THEORETICAL BIOLOGY			English	Article						support vector machines; identifying critical positions; machine learning; amino-acid sequence; beta-lactamase; directed evolution	TEM-1 BETA-LACTAMASE; SECONDARY STRUCTURE PREDICTION; DIRECTED EVOLUTION; SUBSTRATE-SPECIFICITY; RANDOM MUTAGENESIS; GENE LIBRARIES; RECOMBINATION; ENZYME; CLASSIFICATION; DETERMINANTS	A method for identifying the positions in the amino acid sequence, which are critical for the catalytic activity of a protein using support vector machines (SVMs) is introduced and analysed. SVMs are supported by an efficient learning algorithm and can utilize some prior knowledge about the structure of the problem. The amino acid sequences of the variants of a protein, created by inducing mutations. along with their fitness are required as input data by the method to predict its critical positions. To investigate the performance of this algorithm, variants of the beta-lactamase enzyme were created in silico using simulations of both mutagenesis and recombination protocols. Results from literature on beta-lactamase were used to test the accuracy of this method. It was also compared with the results from a simple search algorithm. The algorithm was also shown to be able to predict critical positions that can tolerate two different amino acids and retain function. (c) 2005 Elsevier Ltd. All rights reserved.	Georgia Inst Technol, Sch Chem & Biomol Engn, Atlanta, GA 30332 USA	Realff, MJ (reprint author), Georgia Inst Technol, Sch Chem & Biomol Engn, Atlanta, GA 30332 USA.	matthew.realff@chbe.gatech.edu	Lee, Jay Hyung/C-1808-2011	Lee, Jay Hyung/0000-0001-6134-6118			Axe DD, 2000, J MOL BIOL, V301, P585, DOI 10.1006/jmbi.2000.3997; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Cantu C, 1997, J BIOL CHEM, V272, P29144, DOI 10.1074/jbc.272.46.29144; CHEN KQ, 1993, P NATL ACAD SCI USA, V90, P5618, DOI 10.1073/pnas.90.12.5618; Christianini N., 2000, INTRO SUPPORT VECTOR; Daugherty PS, 2000, P NATL ACAD SCI USA, V97, P2029, DOI 10.1073/pnas.030527597; Deniz O, 2003, PATTERN RECOGN LETT, V24, P2153, DOI 10.1016/S0167-8655(03)00081-3; Elcock AH, 2001, J MOL BIOL, V312, P885, DOI 10.1006/jmbi.2001.5009; Gutteridge A, 2003, J MOL BIOL, V330, P719, DOI 10.1016/S0022-2836(03)00515-1; Huang WZ, 1996, J MOL BIOL, V258, P688, DOI 10.1006/jmbi.1996.0279; JOACHIMS, 1998, P EUR C MACH LEARN; Joern JM, 2002, J MOL BIOL, V316, P643, DOI 10.1006/jmbi.2001.5349; Kim H, 2003, PROTEIN ENG, V16, P553, DOI 10.1093/protein/gzg072; Largeron-Leteno C, 2003, PATTERN RECOGN LETT, V24, P3153, DOI 10.1016/j.patrec.2003.08.002; Lin Hening, 2002, Angew Chem Int Ed Engl, V41, P4402, DOI 10.1002/1521-3773(20021202)41:23<4402::AID-ANIE4402>3.0.CO;2-H; Maheshri N, 2003, P NATL ACAD SCI USA, V100, P3071, DOI 10.1073/pnas.0537968100; Mao KZ, 2004, IEEE T SYST MAN CY B, V34, P60, DOI 10.1109/TSMCB.2002.805808; Meldrum D, 2000, GENOME RES, V10, P1288, DOI 10.1101/gr.157400; Meldrum D, 2000, GENOME RES, V10, P1081, DOI 10.1101/gr.101400; METZ CE, 1986, INVEST RADIOL, V21, P720; Meyer MM, 2003, PROTEIN SCI, V12, P1686, DOI 10.1110/ps.0306603; Miyazaki K, 2000, J MOL BIOL, V297, P1015, DOI 10.1006/jmbi.2000.3612; Moore GL, 2000, COMPUT CHEM ENG, V24, P693, DOI 10.1016/S0098-1354(00)00319-7; Moore GL, 2000, J THEOR BIOL, V205, P483, DOI 10.1006/jtbi.2000.2082; Moore JC, 1996, NAT BIOTECHNOL, V14, P458, DOI 10.1038/nbt0496-458; Neylon C, 2004, NUCLEIC ACIDS RES, V32, P1448, DOI 10.1093/nar/gkh315; Nocedal J., 1999, NUMERICAL OPTIMIZATI; Ostermeier M, 2003, TRENDS BIOTECHNOL, V21, P244, DOI 10.1016/S0167-7799(03)00089-1; PALZKILL T, 1992, J BACTERIOL, V174, P5237; Petrounia IP, 2000, CURR OPIN BIOTECH, V11, P325, DOI 10.1016/S0958-1669(00)00107-5; Platt J., 1998, MSRTR9814; RAQUET X, 1995, PROTEINS, V23, P63, DOI 10.1002/prot.340230108; Saraf MC, 2004, P NATL ACAD SCI USA, V101, P4142, DOI 10.1073/pnas.0400065101; SIEZEN RJ, 1991, PROTEIN ENG, V4, P719, DOI 10.1093/protein/4.7.719; STEMMER WPC, 1994, P NATL ACAD SCI USA, V91, P10747, DOI 10.1073/pnas.91.22.10747; Swets J. A., 1982, EVALUATION DIAGNOSTI; TERWILLIGER TC, 1994, J MOL BIOL, V236, P556, DOI 10.1006/jmbi.1994.1165; To KN, 2004, J COMPUT APPL MATH, V163, P233, DOI 10.1016/j.cam.2003.08.068; Vapnik V. N, 1995, NATURE STAT LEARNING; Voet D., 1995, BIOCHEMISTRY; Voigt CA, 2001, P NATL ACAD SCI USA, V98, P3778, DOI 10.1073/pnas.051614498; Ward JJ, 2003, BIOINFORMATICS, V19, P1650, DOI 10.1093/bioinformatics/btg223; Zaccolo M, 1999, J MOL BIOL, V285, P775, DOI 10.1006/jmbi.1998.2262	43	8	10	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0022-5193		J THEOR BIOL	J. Theor. Biol.	JUN 7	2005	234	3					351	361		10.1016/j.jtbi.2004.11.037		11	Biology; Mathematical & Computational Biology	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology	914IP	WOS:000228221400005	
J	Zmazek, B; Zivcic, M; Todorovski, L; Dzeroski, S; Vaupotic, J; Kobal, I				Zmazek, B; Zivcic, M; Todorovski, L; Dzeroski, S; Vaupotic, J; Kobal, I			Radon in soil gas: How to identify anomalies caused by earthquakes	APPLIED GEOCHEMISTRY			English	Article							ATMOSPHERIC-PRESSURE FLUCTUATIONS; SLOVENIA; PREDICTION; RADIOACTIVITY; WATERS; GEOCHEMISTRY; YUGOSLAVIA; EMANATION; EXPOSURE; EVENTS	Anomalies have been observed in Rn content in soil gas from 3 boreholes at the Orlica fault in the Krsko basin, Slovenia. To distinguish the anomalies caused by environmental parameters (air and soil temperature, barometric pressure, rainfall) from those resulting solely from seismic activity, the following approaches have been used: (i) deviation of Rn concentration from the seasonal average, (ii) correlation between time gradients of Rn concentration and barometric pressure, and (iii) regression trees within a machine learning program. Approach (i) is much less successful in predicting anomalies caused by seismic events than approaches (ii) and (iii) if +/- 2 sigma criterion is used and is equally successful if I a is used. Approaches (ii) and (iii) did not fail to observe an anomaly preceding an earthquake, but show false seismic anomalies, the number of which is much lower with (iii) than with (ii). Model trees are shown to outperform other approaches. A model has been built which, in the seismically non-active periods when Rn is presumably influenced only by environmental parameters, predicts the concentration with a correlation of 0.8. This correlation is reduced significantly in the seismically active periods. (c) 2005 Elsevier Ltd. All rights reserved.	Jozef Stefan Inst, Ljubljana 1000, Slovenia; Environm Agcy Republ Slovenia, Off Seismol, Ljubljana 1000, Slovenia	Zmazek, B (reprint author), Jozef Stefan Inst, Ljubljana 1000, Slovenia.	boris.zmazek@ijs.si					BELYAEV AA, 2001, GEOCHEM INT, V12, P1245; Biagi PF, 2001, J SEISMOL, V5, P487, DOI 10.1023/A:1012015317086; Breiman L, 1984, CLASSIFICATION REGRE; Cuomo V, 2000, NAT HAZARDS, V21, P247, DOI 10.1023/A:1008157730467; DIBELLO G, 1998, IL NUOVO CIMENTO, V6, P609; DOBROVOLSKY IP, 1979, PURE APPL GEOPHYS, V117, P1025, DOI 10.1007/BF00876083; DZEROSKI S, 2002, HDB DATA MINING KNOW; Fujiyoshi R, 2002, CHEMOSPHERE, V47, P369, DOI 10.1016/S0045-6535(01)00310-1; Hubbard LM, 1996, ENVIRON INT, V22, pS477; Ioannides KG, 1996, J RADIOAN NUCL CH AR, V208, P541, DOI 10.1007/BF02040071; KING CY, 1986, J GEOPHYS RES-SOLID, V91, P2269, DOI 10.1029/JB091iB12p12269; KING CY, 1978, NATURE, V271, P516, DOI 10.1038/271516a0; KLUSMAN RW, 1981, B SEISMOL SOC AM, V71, P211; KLUSMAN RW, 1987, J GEOCHEM EXPLOR, V27, P259, DOI 10.1016/0375-6742(87)90023-9; KOBAL I, 1990, ENVIRON INT, V16, P141, DOI 10.1016/0160-4120(90)90154-X; KOBAL I, 1979, HEALTH PHYS, V37, P239; KOBAL I, 1978, J RADIOANAL CHEM, V44, P307, DOI 10.1007/BF02519623; KOBAL I, 1987, RADIAT PROT DOSIM, V20, P257; KOBAL I, 1987, HEALTH PHYS, V53, P307; MJACHKIN VI, 1975, PURE APPL GEOPHYS, V113, P169, DOI 10.1007/BF01592908; Negarestani A., 2001, J ENVIRON RADIOACTIV, V62, P225, DOI 1016/S0265-931X(01)00165-5; Ohno M, 1996, J PHYS EARTH, V44, P391; Planinic J, 2001, APPL RADIAT ISOTOPES, V55, P267, DOI 10.1016/S0969-8043(00)00387-0; PLANINIC J, 2003, P 5 S CROAT RAD PROT, P349; Planinic J., 2000, Fizika B, V9; Popit A, 2004, J ENVIRON RADIOACTIV, V76, P337, DOI 10.1016/j.jenvrad.2003.12.010; POPIT A, 2002, MAT GEOENVIRON, V49, P487; Pulinets SA, 1997, ADV SPACE RES, V20, P2173, DOI 10.1016/S0273-1177(97)00666-2; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; Riley WJ, 1996, J WIND ENG IND AEROD, V61, P153, DOI 10.1016/0167-6105(96)00045-1; Robinson AL, 1997, ATMOS ENVIRON, V31, P1477, DOI 10.1016/S1352-2310(96)00304-4; Robinson AL, 1997, ATMOS ENVIRON, V31, P1487, DOI 10.1016/S1352-2310(97)83264-5; SCHOLZ CH, 1973, SCIENCE, V181, P803, DOI 10.1126/science.181.4102.803; Singh M, 1999, RADIAT MEAS, V30, P465, DOI 10.1016/S1350-4487(99)00049-9; Steinitz G, 2003, GEOLOGY, V31, P505, DOI 10.1130/0091-7613(2003)031<0505:SSRBRF>2.0.CO;2; Toutain JP, 1999, TECTONOPHYSICS, V304, P1, DOI 10.1016/S0040-1951(98)00295-9; UI H, 1988, TECTONOPHYSICS, V152, P147, DOI 10.1016/0040-1951(88)90034-0; UI H, 1986, CRUST CHEM LAB REP, V4, P85; Ulomov V. I, 1971, IZV AKAD NAUK UZB SS, P188; Vaupotic J, 2001, RADIAT PROT DOSIM, V97, P265; Vaupotic J, 2002, HEALTH PHYS, V83, P901, DOI 10.1097/00004032-200212000-00018; Virk HS, 2001, J GEODYN, V31, P201; WANG Y, 1997, P POST PAP EUR C MAC; Witten I. H., 1999, DATA MINING PRACTICA; Yasuoka Y, 1997, HEALTH PHYS, V72, P759, DOI 10.1097/00004032-199705000-00012; Zmazek B, 2002, APPL RADIAT ISOTOPES, V57, P919, DOI 10.1016/S0969-8043(02)00200-2; ZMAZEK B, 2000, 2 DRESD S RAD PROT S; ZMAZEK B, 2000, NEW ASPECTS RAD MEAS; Zmazek B., 2000, Fizika B, V9; Zmazek B, 2003, APPL RADIAT ISOTOPES, V58, P697, DOI 10.1016/S0969-8043(03)00094-0; ZMAZEK B, 2002, 1 WORKSH NAT RAD HYD; Zmazek B, 2002, APPL RADIAT ISOTOPES, V56, P649, DOI 10.1016/S0969-8043(01)00255-X	52	19	20	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0883-2927		APPL GEOCHEM	Appl. Geochem.	JUN	2005	20	6					1106	1119		10.1016/j.apgeochem.2005.01.014		14	Geochemistry & Geophysics	Geochemistry & Geophysics	935OM	WOS:000229791600005	
J	Stamatatos, E; Widmer, G				Stamatatos, E; Widmer, G			Automatic identification of music performers with learning ensembles	ARTIFICIAL INTELLIGENCE			English	Article						machine learning; classification; ensemble learning; music	CLASSIFICATION ALGORITHMS; DISCOVERIES; RULES; AI	This article addresses the problem of identifying the most likely music performer, given a set of performances of the same piece by a number of skilled candidate pianists. We propose a set of very simple features for representing stylistic characteristics of a music performer, introducing 'normbased' features that relate to a kind of 'average' performance. A database of piano performances of 22 pianists playing two pieces by Frederic Chopin is used in the presented experiments. Due to the limitations of the training set size and the characteristics of the input features we propose an ensemble of simple classifiers derived by both subsampling the training set and subsampling the input features. Experiments show that the proposed features are able to quantify the differences between music performers. The proposed ensemble can efficiently cope with multi-class music performer recognition under inter-piece conditions, a difficult musical task, displaying a level of accuracy unlikely to be matched by human listeners (under similar conditions). &COPY; 2005 Elsevier B.V. All rights reserved.	Johannes Kepler Univ, Dept Computat Percept, A-4040 Linz, Austria; Univ Aegean, Dept Informat & Commun Syst Engn, Samos, Greece; Austrian Res Inst Artificial Intelligence, Vienna, Austria	Widmer, G (reprint author), Johannes Kepler Univ, Dept Computat Percept, A-4040 Linz, Austria.	stamatatos@aegean.gr; gerhard.widmer@jku.at	Stamatatos, Efstathios/F-2927-2012				ARCOS JL, 2003, P 5 INT C CAS BAS RE, P20; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Blum A, 1997, MACH LEARN, V26, P5, DOI 10.1023/A:1007335615132; CAMBOUROPOULOS E, 2000, P AAAI 2000 WORKSH A, P19; de Mantaras RL, 2002, AI MAG, V23, P43; Dietterich T., 2000, 1 INT WORKSH MULT CL, P1; EISENBEIS R, 1972, DISCRIMINANT ANAL CL; Friberg A, 1995, P KTH S GRAMM MUS PE, P37; FRIBERG A, 1991, COMPUT MUSIC J, V15, P56, DOI 10.2307/3680917; Goebl W, 2001, J ACOUST SOC AM, V110, P563, DOI 10.1121/1.1376133; GOEBL W, 2004, P 2004 INT S MUS AC, P332; GOEBL W, 2003, P 5 ESCOM C HANN GER, P376; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; Opitz DW, 1996, ADV NEUR IN, V8, P535; Palmer C, 1996, MUSIC PERCEPT, V14, P23; Parmanto B, 1996, ADV NEUR IN, V8, P882; REPP BH, 1992, J ACOUST SOC AM, V92, P2546, DOI 10.1121/1.404425; STAMATATOS E, 2004, P MOSART WORKSH CURR, P65; STAMATATOS E, 2002, P INT COMP MUS C ICM, P376; TIMMERS R, 2003, TR200325 AUSTR RES I; Todorovski L, 2003, MACH LEARN, V50, P223, DOI 10.1023/A:1021709817809; Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560; Widmer G, 2001, AI COMMUN, V14, P149; Widmer G, 2002, J NEW MUSIC RES, V31, P37, DOI 10.1076/jnmr.31.1.37.8103; Widmer G, 2003, ARTIF INTELL, V146, P129, DOI 10.1016/S0004-3702(03)00016-X; Widmer G, 2003, AI MAG, V24, P111	26	18	18	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0004-3702		ARTIF INTELL	Artif. Intell.	JUN	2005	165	1					37	56		10.1016/j.artint.2005.01.007		20	Computer Science, Artificial Intelligence	Computer Science	927DT	WOS:000229173300002	
J	Nattkemper, TW; Arnrich, B; Lichte, O; Timm, W; Degenhard, A; Pointon, L; Hayes, C; Leach, MO				Nattkemper, TW; Arnrich, B; Lichte, O; Timm, W; Degenhard, A; Pointon, L; Hayes, C; Leach, MO			Evaluation of radiological features for breast tumour classification in clinical screening with machine learning methods	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						breast cancer; magnetic resonance imaging; clinical screening; computer aided diagnosis; machine learning; artificial neural networks; support vector machine (SVM); decision trees	CONTRAST-ENHANCED MRI; CANCER; RESONANCE; DIAGNOSIS; ACCURACY	Objective: In this work, methods utilizing supervised and unsupervised machine learning are applied to analyze radiologically derived morphological and calculated kinetic tumour features. The features are extracted from dynamic contrast enhanced magnetic resonance imaging (DCE-MRI) time-course data. Material: The DCE-MRI data of the female breast are obtained within the UK Multicenter Breast Screening Study. The group of patients imaged in this study is selected on the basis of an increased genetic risk for developing breast cancer. Methods: The k-means clustering and self-organizing maps (SOM) are applied to analyze the signal structure in terms of visualization. We employ k-nearest neighbor classifiers (k-nn), support vector machines (SVM) and decision trees (DT) to classify features using a computer aided diagnosis (CAD) approach. Results: Regarding the unsupervised techniques, clustering according to features indicating benign and malignant characteristics is observed to a limited extend. The supervised approaches classified the data with 74% accuracy (DT) and providing an area under the receiver-operator-characteristics (ROC) curve (AUC) of 0.88 (SVM). Conclusion: It was found that contour and wash-out type (WOT) features determined by the radiologists lead to the best SVM classification results. Although a fast signal uptake in early time-point measurements is an important feature for malignant/benign classification of tumours, our results indicate that the wash-out characteristics might be considered as important. &COPY; 2004 Elsevier B.V. All rights reserved.	Univ Bielefeld, Appl Neuroinformat Grp, D-33501 Bielefeld, Germany; Royal Marsden Hosp, Inst Canc Res, Sect Magnet Resonance, Clin MR Res Grp,Canc Res UK, Sutton, Surrey, England	Nattkemper, TW (reprint author), Univ Bielefeld, Appl Neuroinformat Grp, POB 100130, D-33501 Bielefeld, Germany.	tnattkem@techfak.uni-bielefeld.de	leach, martin/C-2248-2008; Arnrich, Bert/C-6905-2013				ABBASS HA, 2001, ARTIF INTELL MED, V25, P1; Bishop C., 1997, NEURAL NETWORKS PATT; Brown J, 2000, MAGN RESON IMAGING, V18, P765, DOI 10.1016/S0730-725X(00)00167-3; Degenhard A, 2002, PHYSIOL MEAS, V23, P727, DOI 10.1088/0967-3334/23/4/311; EASTON DF, 1993, AM J HUM GENET, V52, P678; ELOMAA T, 1997, SCAND C AI, P950; FAYYAD UM, 1993, P 13 INT JOINT C ART, V1, P1022; Greiner M, 2000, PREV VET MED, V45, P23, DOI 10.1016/S0167-5877(00)00115-X; HARMS SE, 1993, RADIOLOGY, V187, P493; Heiberg EV, 1996, MAGN RESON IMAGING, V14, P337, DOI 10.1016/0730-725X(95)02112-7; HeywangKobrunner SH, 1997, EUR J RADIOL, V24, P94, DOI 10.1016/S0720-048X(96)01142-4; HEYWANGKOBRUNNE.SH, 1996, CONTRAST ENHANCED MR; KEERTHI SS, 1999, CD9914 TR U SING; KOHONEN T, 2000, SERIES INFORMATION S, V30; Kohonen T, 1989, SELF ORG ASS MEMORY; Kononenko I, 2001, ARTIF INTELL MED, V23, P89, DOI 10.1016/S0933-3657(01)00077-X; Kuhl CK, 1997, RADIOLOGY, V203, P137; Liu PF, 1998, BRIT J RADIOL, V71, P501; Lucht REA, 2001, MAGN RESON IMAGING, V19, P51, DOI 10.1016/S0730-725X(01)00222-3; Markey MK, 2003, ARTIF INTELL MED, V27, P113, DOI 10.1016/S0933-3657(03)00003-4; MIKA S, 1999, NEURAL NETWORKS SIGN, V9, P410; Nunes LW, 1997, AM J ROENTGENOL, V169, P409; Platt J., 1998, ADV KERNEL METHODS S; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Schnall MD, 2001, BREAST CANCER RES, V3, P17, DOI 10.1186/bcr265; Scholkopf B, 1999, ADVANCES IN KERNEL METHODS, P327; Vapnik V. N, 1995, NATURE STAT LEARNING; West D, 2000, ARTIF INTELL MED, V20, P183, DOI 10.1016/S0933-3657(00)00063-4; WOLBERG W, 1990, P NATL ACAD SCI USA, P9193; ZWEIG MH, 1993, CLIN CHEM, V39, P561	30	21	21	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657		ARTIF INTELL MED	Artif. Intell. Med.	JUN	2005	34	2					129	139		10.1016/j.artmed.2004.09.001		11	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	932NA	WOS:000229559200003	
J	Tucker, A; Vinciotti, V; Liu, X; Garway-Heath, D				Tucker, A; Vinciotti, V; Liu, X; Garway-Heath, D			A spatio-temporal Bayesian network classifier for understanding visual field deterioration	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						classification; multivariate time series; Bayesian networks; visual field; glaucoma	GLAUCOMA	Objective: Progressive toss of the field of vision is characteristic of a number of eye diseases such as glaucoma which is a leading cause of irreversible blindness in the world. Recently, there has been an explosion in the amount of data being stored on patients who suffer from visual deterioration including field test data, retinal image data and patient demographic data. However, there has been relatively little work in modelling the spatial and temporal relationships common to such data. In this paper we introduce a novel method for classifying visual field (VF) data that explicitly models these spatial and temporal relationships. Methodology: We carry out an analysis of our proposed spatio-temporal. Bayesian classifier and compare it to a number of classifiers from the machine learning and statistical communities. These are all tested on two datasets of VF and clinical data. We investigate the receiver operating characteristics curves, the resulting network structures and also make use of existing anatomical knowledge of the eye in order to validate the discovered models. Results: Results are very encouraging showing that our classifiers are comparable to existing statistical models whilst also facilitating the understanding of underlying spatial and temporal relationships within VF data. The results reveal the potential of using such models for knowledge discovery within ophthalmic databases, such as networks reflecting the 'nasal step', an early indicator of the onset of glaucoma. Conclusion: The results outlined in this paper pave the way for a substantial program of study involving many other spatial and temporal datasets, including retinal image and clinical data. &COPY; 2004 Elsevier B.V. All rights reserved.	Brunel Univ, Dept Informat Syst & Comp, Uxbridge UB8 3PH, Middx, England; Moorfields Eye Hosp, Glaucoma Unit, London, England	Tucker, A (reprint author), Brunel Univ, Dept Informat Syst & Comp, Uxbridge UB8 3PH, Middx, England.	allan.tucker@brunel.ac.uk	Vinciotti, Veronica/A-7703-2008; Liu, Xiaohui/B-5046-2013	Liu, Xiaohui/0000-0003-1589-1267			ANDERSSEN KE, 1998, THESIS AALBORG U DEN; Chan KL, 2002, IEEE T BIO-MED ENG, V49, P963, DOI 10.1109/TBME.2002.802012; COOPER GF, 1990, ARTIF INTELL, V42, P393, DOI 10.1016/0004-3702(90)90060-D; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; Dagum P, 1992, P 8 C UNC ART INT UA, P41; DOMINGOS P, 1997, MACHINE LEARN, V9, P309; Fitzke FW, 1996, BRIT J OPHTHALMOL, V80, P40, DOI 10.1136/bjo.80.1.40; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GAASTERLAND DE, 1994, OPHTHALMOLOGY, V101, P1445; Garway-Heath DF, 2000, OPHTHALMOLOGY, V107, P1809, DOI 10.1016/S0161-6420(00)00284-0; Goldbaum MH, 2002, INVEST OPHTH VIS SCI, V43, P162; GREFENSTETTE JJ, 1986, IEEE T SYST MAN CYB, V16, P122, DOI 10.1109/TSMC.1986.289288; Hand D. J., 1997, CONSTRUCTION ASSESSM; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; HAND DJ, 2003, AM STAT, V124, P131; Heijl A, 1990, PERIMETRY UPDATE 199, P303; HEIJL A, 1987, ARCH OPHTHALMOL-CHIC, V105, P1544; HENRION M, 1986, P 2 ANN C UNC AI, P149; Hilton S, 1996, STAT MED, V15, P1349, DOI 10.1002/(SICI)1097-0258(19960715)15:13<1349::AID-SIM270>3.0.CO;2-B; Hothorn T, 2003, ARTIF INTELL MED, V27, P65, DOI 10.1016/S0933-3657(02)00085-4; IBANEZ MV, 2003, 55 U JAUM 1 DEP MATH; Kamal D, 2003, GRAEF ARCH CLIN EXP, V241, P196, DOI 10.1007/s00417-002-0614-4; KATZ J, 1986, ARCH OPHTHALMOL-CHIC, V104, P65; Kirkpatrick S., 1983, SCIENCE, V220, P671; Kohavi R, 1996, P 2 INT C KNOWL DISC, P202; LANGLEY P, 1994, P 10 C UNC ART INT, P399; Langley P., 1992, P 10 NAT C ART INT, P223; LIU X, 2001, P GEN EV COMP C, P7; Pearl J., 1988, PROBABILISTIC REASON; RAMONI M, 1999, INTELLIGENT DATA ANA; Swift S, 2002, ARTIF INTELL MED, V24, P5, DOI 10.1016/S0933-3657(01)00095-1; TUCKER A, 2003, P GEN EV COMP C, P12; Tucker A, 2001, INT J INTELL SYST, V16, P621, DOI 10.1002/int.1027; Vinciotti V, 2003, J IRAN STAT SOC, V2, P189; Weber J, 1992, Ger J Ophthalmol, V1, P79; WELLMAN MP, 1993, IEEE T PATTERN ANAL, V15, P287, DOI 10.1109/34.204911	36	24	25	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657		ARTIF INTELL MED	Artif. Intell. Med.	JUN	2005	34	2					163	177		10.1016/j.artmed.2004.07.004		15	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	932NA	WOS:000229559200006	
J	Lin, SP				Lin, SP			On paradox of fuzzy modeling: Supervised learning for rectifying fuzzy membership function	ARTIFICIAL INTELLIGENCE REVIEW			English	Article						artificial intelligence; fuzzy mathematics; machine learning; membership function		The paradox of fuzzy modeling is recognized due to the co-existence of its effectiveness of solving uncertain problems in the real world and the skepticism of its reasonability in membership function. In this paper, a revised membership function by means of supervised machine learning is introduced, in which the membership function curve is revised from the learning data of existing samples. It points that the information from supervised machine learning by samples is in the same argument to the statistic data from observation in the probability model. The formulations of supervised fuzzy machine learning by samples for revising the membership function are presented, and satisfactory results by the revised membership function compared with the experimental data are shown. It steps forward in promoting the pragmatic application of fuzzy methods in real world problems.	Shanghai Jiao Tong Univ, Sch Civil Engn & Mech, Shanghai 200030, Peoples R China	Lin, SP (reprint author), Shanghai Jiao Tong Univ, Sch Civil Engn & Mech, 1954 Hua Shan Rd, Shanghai 200030, Peoples R China.	splin@sjtu.edu.cn					Nilsson N., 1998, ARTIFICIAL INTELLIGE; SHAOPEI L, 1998, P 2 INT C ART INT IT, P56; SHAOPEI L, 1995, P INT S UNC MOD AN I; SHAOPEI L, 1990, 4 CORN U; SHAOPEI L, 1992, P 8 ASCE COMP CIV EN; TABY J, 1985, P BEH OFFSH STRUCT H, P395; TABY J, 1981, NORWEGIAN MARITIME R, V2; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	8	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0269-2821		ARTIF INTELL REV	Artif. Intell. Rev.	JUN	2005	23	4					395	405		10.1007/s10462-004-7189-x		11	Computer Science, Artificial Intelligence	Computer Science	914KH	WOS:000228226000003	
J	Kell, DB				Kell, DB			Metabolomics, machine learning and modelling: towards an understanding of the language of cells	BIOCHEMICAL SOCIETY TRANSACTIONS			English	Article; Proceedings Paper	Meeting on Systems Biology: Will it Work	JAN 12-14, 2005	Sheffield, ENGLAND		Univ Sheffield	computational technology; genetic programming; machine learning; metabolomics; signal processing elements; systems biology	ARTIFICIAL NEURAL NETWORKS; SACCHAROMYCES-CEREVISIAE; BIOLOGICAL-SYSTEMS; MASS-SPECTROMETRY; BIOCHEMICAL PATHWAYS; PARAMETER-ESTIMATION; EXPLANATORY ANALYSIS; FLOW-CYTOMETRY; FREE-ENERGY; TRANSCRIPTION	In answering the question 'Systems Biology - will it work? (which it self-evidently has already), it is appropriate to highlight advances in philosophy, in new technique development and in novel findings. in terms of philosophy, we see that systems biology involves an iterative interplay between linked activities - for instance, between theory and experiment, between induction and deduction and between measurements of parameters and variables - with more emphasis than has perhaps been common now being focused on the first in each of these pairs. in technique development, we highlight closed loop machine learning and its use in the optimization of scientific instrumentation, and the ability to effect high-quality and quasi-continuous optical images of cells. This leads to many important and novel findings. in the first case, these may involve new biomarkers for disease, whereas in the second case, we have determined that many biological signals may be frequency-rather than amplitude-encoded. This leads to a very different view of how signalling 'works' (equations such as that of Michaelis and Menten which use only amplitudes, i.e. concentrations, are inadequate descriptors), lays emphasis on the signal processing network elements that lie 'downstream' of what are traditionally considered the signals, and allows one simply to understand how cross-talk may be avoided between pathways which nevertheless use common signalling elements. The language of cells is much richer than we had supposed, and we are now well placed to decode it.	Univ Manchester, Sch Chem, Manchester M60 1QD, Lancs, England	Kell, DB (reprint author), Univ Manchester, Sch Chem, Faraday Bldg,Sackville St,POB 88, Manchester M60 1QD, Lancs, England.	dbk@manchester.ac.uk	Kell, Douglas/E-8318-2011				Aldana M, 2003, P NATL ACAD SCI USA, V100, P8710, DOI 10.1073/pnas.1536783100; Allen J, 2004, APPL ENVIRON MICROB, V70, P6157, DOI 10.1128/AEM.70.10.6157-6165.2004; Allen J, 2003, NAT BIOTECHNOL, V21, P692, DOI 10.1038/nbt823; Brown R A, 2001, Cardiovasc Toxicol, V1, P35, DOI 10.1385/CT:1:1:35; Buchler NE, 2003, P NATL ACAD SCI USA, V100, P5136, DOI 10.1073/pnas.0930314100; Chen W.K., 1986, PASSIVE ACTIVE FILTE; Cornell M, 2003, YEAST, V20, P1291, DOI 10.1002/yea.1047; Csete ME, 2002, SCIENCE, V295, P1664, DOI 10.1126/science.1069981; Davey HM, 1996, MICROBIOL REV, V60, P641; Forster J, 2003, GENOME RES, V13, P244, DOI 10.1101/gr.234503; Garwood K, 2004, BMC GENOMICS, V5, DOI 10.1186/1471-2164-5-68; Goodacre R, 2004, TRENDS BIOTECHNOL, V22, P245, DOI 10.1016/j.tibtech.2004.03.007; Hoffmann A, 2002, SCIENCE, V298, P1241, DOI 10.1126/science.1071914; Ihekwaba A. E. C., 2004, Systems Biology, V1, P93, DOI 10.1049/sb:20045009; Jenkins H, 2004, NAT BIOTECHNOL, V22, P1601, DOI 10.1038/nbt1041; Kell DB, 2004, CURR OPIN MICROBIOL, V7, P296, DOI 10.1016/j.mib.2004.04.012; KELL DB, 1991, ANTON LEEUW INT J G, V60, P145, DOI 10.1007/BF00430362; Kell DB, 2000, NATO ASI 3 HIGH TECH, V74, P3; Kell DB, 2001, PLANT PHYSIOL, V126, P943, DOI 10.1104/pp.126.3.943; Kell DB, 2004, BIOESSAYS, V26, P99, DOI 10.1002/bies.10385; Kell DB, 2002, TRENDS GENET, V18, P555, DOI 10.1016/S0168-9525(02)02765-8; KELL DB, 1986, FEMS MICROBIOL REV, V39, P305, DOI 10.1111/j.1574-6968.1986.tb01863.x; Kell DB, 2002, MOL BIOL REP, V29, P237, DOI 10.1023/A:1020342216314; Kell DB, 2000, TRENDS BIOTECHNOL, V18, P93, DOI 10.1016/S0167-7799(99)01407-9; KELL DB, 2004, NONLINEAR DIELECTRIC, P335; King RD, 2004, NATURE, V427, P247, DOI 10.1038/nature02236; Kitano H, 2004, NAT REV GENET, V5, P826, DOI 10.1038/nrg1471; Koza J. R., 2001, PACIFIC S BIOCOMPUTI, P434; Koza JR, 2003, GENETIC PROGRAMMING; KOZA JR, 2001, P GECCO 2001, P57; Kramer BP, 2004, BIOTECHNOL BIOENG, V87, P478, DOI 10.1002/bit.20142; Langley P., 1987, SCI DISCOVERY COMPUT; Mangan S, 2003, P NATL ACAD SCI USA, V100, P11980, DOI 10.1073/pnas.2133841100; Mendes P, 2001, BIOINFORMATICS, V17, P288, DOI 10.1093/bioinformatics/17.3.288; Mendes P, 1998, BIOINFORMATICS, V14, P869, DOI 10.1093/bioinformatics/14.10.869; Mendes P, 1996, BIOSYSTEMS, V38, P15, DOI 10.1016/0303-2647(95)01565-5; Mikulecky DC, 2001, COMPUT CHEM, V25, P369, DOI 10.1016/S0097-8485(01)00072-9; Milo R, 2004, SCIENCE, V303, P1538, DOI 10.1126/science.1089167; Milo R, 2002, SCIENCE, V298, P824, DOI 10.1126/science.298.5594.824; Moles CG, 2003, GENOME RES, V13, P2467, DOI 10.1101/gr.1262503; Nelson DE, 2004, SCIENCE, V306, P704, DOI 10.1126/science.1099962; Nelson G, 2002, J CELL SCI, V115, P1137; O'Hagan S, 2005, ANAL CHEM, V77, P290, DOI 10.1021/ac049146x; PETHIG R, 1987, PHYS MED BIOL, V32, P933, DOI 10.1088/0031-9155/32/8/001; Pritchard L, 2002, EUR J BIOCHEM, V269, P3894, DOI 10.1046/j.1432-1033.2002.03055.x; Rosenfeld N, 2003, J MOL BIOL, V329, P645, DOI 10.1016/S0022-2836(03)00506-0; Schmitt BM, 2004, CHEMBIOCHEM, V5, P1384, DOI 10.1002/cbic.200400126; Shen-Orr SS, 2002, NAT GENET, V31, P64, DOI 10.1038/ng881; Teusink B, 2000, EUR J BIOCHEM, V267, P5313, DOI 10.1046/j.1432-1327.2000.01527.x; Tyson JJ, 2001, NAT REV MOL CELL BIO, V2, P908, DOI 10.1038/35103078; Tyson JJ, 2003, CURR OPIN CELL BIOL, V15, P221, DOI 10.1016/S0955-0674(03)00017-6; Vaidyanathan S, 2003, ANAL CHEM, V75, P6679, DOI 10.1021/ac034669a; Vaidyanathan S, 2004, ANAL CHEM, V76, P5024, DOI 10.1021/ac049684; von Dassow G, 2000, NATURE, V406, P188, DOI 10.1038/35018085; Westerhoff H. V., 1987, THERMODYNAMICS CONTR; WESTERHOFF HV, 1988, FERROELECTRICS, V86, P79, DOI 10.1080/00150198808227005; Westerhoff HV, 2001, METAB ENG, V3, P207, DOI 10.1006/mben.2001.0192; Westerhoff HV, 2004, NAT BIOTECHNOL, V22, P1249, DOI 10.1038/nbt1020; WESTERHOFF HV, 1986, P NATL ACAD SCI USA, V83, P4734, DOI 10.1073/pnas.83.13.4734; White TA, 2004, COMP FUNCT GENOM, V5, P304, DOI 10.1002/cfg.411; Wilson ID, 2003, J CHROMATOGR A, V1000, P325, DOI 10.1016/S0021-9673(03)00504-1; Wolf DM, 2003, CURR OPIN MICROBIOL, V6, P125, DOI 10.1016/S1369-5274(03)00033-X; Woodward AM, 2004, ANALYST, V129, P542, DOI 10.1039/b403134b; WOODWARD AM, 1990, BIOELECTROCH BIOENER, V24, P83, DOI 10.1016/0302-4598(90)85013-8; Woodward AM, 1996, BIOELECTROCH BIOENER, V40, P99, DOI 10.1016/0302-4598(96)05065-9; Yeger-Lotem E, 2004, P NATL ACAD SCI USA, V101, P5934, DOI 10.1073/pnas.0306752101	66	21	25	PORTLAND PRESS LTD	LONDON	THIRD FLOOR, EAGLE HOUSE, 16 PROCTER STREET, LONDON WC1V 6 NX, ENGLAND	0300-5127		BIOCHEM SOC T	Biochem. Soc. Trans.	JUN	2005	33		3				520	524				5	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	938SX	WOS:000230024400021	
J	Murphy, RF				Murphy, RF			Location proteomics: a systems approach to subcellular location	BIOCHEMICAL SOCIETY TRANSACTIONS			English	Article; Proceedings Paper	Meeting on Systems Biology: Will it Work	JAN 12-14, 2005	Sheffield, ENGLAND		Univ Sheffield	fluorescence microscopy; location proteomics; machine learning; protein tagging; subcellular location; 3T3 cell	FLUORESCENCE MICROSCOPE IMAGES; PATTERNS; RECOGNITION	Systems Biology requires comprehensive systematic data on all aspects and levels of biological organization and function. in addition to information on the sequence, structure, activities and binding interactions of all biological macromolecules, the creation of accurate predictive models of cell behaviour will require detailed information on the distribution of those molecules within cells and the ways in which those distributions change over the cell cycle and in response to mutations or external stimuli. Current information on subcellular location in protein databases is limited to unstructured text descriptions or sets of terms assigned by human curators. These entries do not permit basic operations that are common to other biological databases, such as measurement of the degree of similarity between the distributions of two proteins, and they are not able to fully capture the complexity of protein patterns that can be observed. The field of location proteomics seeks to provide automated, objective high-resolution descriptions of protein location patterns within cells. Methods have been developed to group proteins into statistically indistinguishable location patterns using automated analysis of fluorescence microscope images. The resulting clusters, or location families, are analogous to clusters found for other domains, such as protein sequence families. Preliminary work suggests the feasibility of expressing each unique pattern as a generative model that can be incorporated into comprehensive models of cell behaviour.	Carnegie Mellon Univ, Dept Biol Sci, Pittsburgh, PA 15213 USA; Carnegie Mellon Univ, Dept Biomed Engn, Pittsburgh, PA 15213 USA; Carnegie Mellon Univ, Ctr Automated Learning & Discovery Bioimage Infor, Pittsburgh, PA 15213 USA	Murphy, RF (reprint author), Carnegie Mellon Univ, Dept Biol Sci, Pittsburgh, PA 15213 USA.	murphy@icmu.edu					Boland MV, 2001, BIOINFORMATICS, V17, P1213, DOI 10.1093/bioinformatics/17.12.1213; Boland MV, 1998, CYTOMETRY, V33, P366, DOI 10.1002/(SICI)1097-0320(19981101)33:3<366::AID-CYTO12>3.0.CO;2-R; CHEN X, 2003, P SOC PHOTO-OPT INS, V4962, P298, DOI 10.1117/12.477899; CHEN X, 2005, IN PRESS J BIOMED BI; CHEN X, 2004, 26 ANN INT C IEEE EN, P1632; FENG ZP, 2002, IN SILICO BIOL, V2, P291; Greenbaum D, 2001, GENOME RES, V11, P1463, DOI 10.1101/gr.207401; Harris MA, 2004, NUCLEIC ACIDS RES, V32, pD258, DOI 10.1093/nar/gkh036; Huang K, 2003, P SOC PHOTO-OPT INS, V4962, P307, DOI 10.1117/12.477903; Huang K, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-78; Jarvik JW, 2002, BIOTECHNIQUES, V33, P852; Roques EJS, 2002, TRAFFIC, V3, P61, DOI 10.1034/j.1600-0854.2002.30108.x; Velliste M, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING, PROCEEDINGS, P867, DOI 10.1109/ISBI.2002.1029397	13	20	20	PORTLAND PRESS LTD	LONDON	THIRD FLOOR, EAGLE HOUSE, 16 PROCTER STREET, LONDON WC1V 6 NX, ENGLAND	0300-5127		BIOCHEM SOC T	Biochem. Soc. Trans.	JUN	2005	33		3				535	538				4	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	938SX	WOS:000230024400024	
J	Song, Y; Kim, E; Lee, GG; Yi, BK				Song, Y; Kim, E; Lee, GG; Yi, BK			POSBIOTM-NER: a trainable biomedical named-entity recognition system	BIOINFORMATICS			English	Article								POSBIOTM-NER is a trainable biomedical named-entity recognition system. POSBIOTM-NER can be automatically trained and adapted to new datasets without performance degradation, using CRF (conditional random field) machine learning techniques and automatic linguistic feature analysis. Currently, we have trained our system on three different datasets. GENIA-NER was trained based on GENIA Corpus, GENE-NER based on BioCreative data and GPCR-NER based on our own POSBIOTM/NE corpus, respectively, which would be used in GPCR-related pathway extraction.	POSTECH, Dept CSE, Pohang 790784, South Korea	Song, Y (reprint author), POSTECH, Dept CSE, Pohang 790784, South Korea.	songyu@postech.ac.kr					Blaschke C., 2004, P BIOCREATIVE WORKSH; Collier N, 2000, P 18 INT C COMP LING, P201; DINGARE S, 2004, P BIOCREATIVE WORKSH; Kim JD, 2003, BIOINFORMATICS, V19, pi180, DOI 10.1093/bioinformatics/btg1023; KIM JD, 2004, P INT WORKSH NAT LAN; Lafferty J., 2001, P 18 INT C MACH LEAR, P282; Zhou GD, 2004, BIOINFORMATICS, V20, P1178, DOI 10.1093/bioinformatics/bth060	7	8	10	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	JUN 1	2005	21	11					2794	2796		10.1093/bioinformatics/bti414		3	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	930UB	WOS:000229441500034	
J	Ratsch, G; Sonnenburg, S; Scholkopf, B				Ratsch, G; Sonnenburg, S; Scholkopf, B			RASE: recognition of alternatively spliced exons in C.elegans	BIOINFORMATICS			English	Article; Proceedings Paper	13th International Conference on Intelligent Systems for Molecular Biology	JUN 25-29, 2005	Detroit, MI	Int Soc Computat Biol			PREDICTION; SEQUENCES; DATABASE; KERNELS	Motivation: Eukaryotic pre-mRNAs are spliced to form mature mRNA. Pre-mRNA alternative splicing greatly increases the complexity of gene expression. Estimates show that more than half of the human genes and at least one-third of the genes of less complex organisms, such as nematodes or flies, are alternatively spliced. In this work, we consider one major form of alternative splicing, namely the exclusion of exons from the transcript. It has been shown that alternatively spliced exons have certain properties that distinguish them from constitutively spliced exons. Although most recent computational studies on alternative splicing apply only to exons which are conserved among two species, our method only uses information that is available to the splicing machinery, i.e. the DNA sequence itself. We employ advanced machine learning techniques in order to answer the following two questions: (1) Is a certain exon alternatively spliced? (2) How can we identify yet unidentified exons within known introns? Results: We designed a support vector machine (SVM) kernel well suited for the task of classifying sequences with motifs having positional preferences. In order to solve the task (1), we combine the kernel with additional local sequence information, such as lengths of the exon and the flanking introns. The resulting SVM-based classifier achieves a true positive rate of 48.5% at a false positive rate of 1%. By scanning over single EST confirmed exons we identified 215 potential alternatively spliced exons. For 10 randomly selected such exons we successfully performed biological verification experiments and confirmed three novel alternatively spliced exons. To answer question ( 2), we additionally used SVM-based predictions to recognize acceptor and donor splice sites. Combined with the above mentioned features we were able to identify 85.2% of skipped exons within known introns at a false positive rate.	Max Planck Soc, Friedrich Miescher Lab, Tubingen, Germany; Fraunhofer Inst FIRST, Berlin, Germany; Max Planck Inst Biol Cybernet, Tubingen, Germany	Ratsch, G (reprint author), Max Planck Soc, Friedrich Miescher Lab, Spemannstr 35, Tubingen, Germany.	Gunnar.Raetsch@tuebingen.mpg.de	Ratsch, Gunnar/B-8182-2009; Sonnenburg, Soeren/F-2230-2010; Scholkopf, Bernhard/A-7570-2013				Bach Francis R., 2004, P 21 INT C MACH LEAR; BENNETT KP, 2000, P 17 INT C MACH LEAR, P65; BOGUSKI MS, 1993, NAT GENET, V4, P332, DOI 10.1038/ng0893-332; Burge C, 1997, J MOL BIOL, V268, P78, DOI 10.1006/jmbi.1997.0951; DROR G, 2004, BIOINFORMATICS, V21, P897, DOI 10.1093/bioinformatics/bti132; Gupta S, 2004, BMC GENOMICS, V5, DOI 10.1186/1471-2164-5-72; Harris TW, 2004, NUCLEIC ACIDS RES, V32, pD411, DOI 10.1093/nar/gkh066; HAUSSLER D, 1999, CRL9910 UC SANT CRUZ; HILLER M, 2004, IN SILICO BIOL, V4, P195; Jaakkola T, 1999, P 7 INT WORKSH ART I; Kent WJ, 2002, GENOME RES, V12, P656, DOI [10.1101/gr.229202, 10.1101/gr.229202. Article published online before March 2002]; LESLIE C, 2002, P 7 PAC S BIOC PSB 0; Maniatis T, 2002, NATURE, V418, P236, DOI 10.1038/418236a; Meinicke P, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-169; METZ CE, 1978, SEMIN NUCL MED, V8, P283, DOI 10.1016/S0001-2998(78)80014-2; RATSCH G, 2003, KERNEL METHODS COMPU, P277; Rozen S, 2000, BIOINFORMATICS METHO, P365, DOI DOI 10.1385/1-59259-192-2:365; Sakai H, 2004, Pac Symp Biocomput, P54; Scholkopf B, 2004, KERNEL METHODS COMPU; SONNENBURG S, 2006, P 9 INT C RES COMP M, P389; Sorek R, 2004, GENOME RES, V14, P1617, DOI 10.1101/gr.2572604; Sorek R, 2003, GENOME RES, V13, P1631, DOI 10.1101/gr.1208803; Vapnik V. N, 1995, NATURE STAT LEARNING; Watkins C, 2000, ADV NEUR IN, P39; Wheeler DL, 2003, NUCLEIC ACIDS RES, V31, P28, DOI 10.1093/nar/gkg033; *CPLEX OPT INC, 1994, US CPLEX CALL LIB	26	21	21	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	JUN	2005	21			1			I369	I377		10.1093/bioinformatics/bti1053		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	942HH	WOS:000230273000042	
J	Yu, JS; Chen, XW				Yu, JS; Chen, XW			Bayesian neural network approaches to ovarian cancer identification from high-resolution mass spectrometry data	BIOINFORMATICS			English	Article; Proceedings Paper	13th International Conference on Intelligent Systems for Molecular Biology	JUN 25-29, 2005	Detroit, MI	Int Soc Computat Biol			GAUSSIAN-PROCESSES; MONTE-CARLO; CLASSIFICATION; SERUM; DIAGNOSTICS; REGRESSION	Motivation: The classification of high-dimensional data is always a challenge to statistical machine learning. We propose a novel method named shallow feature selection that assigns each feature a probability of being selected based on the structure of training data itself. Independent of particular classifiers, the high dimension of biodata can be fleetly reduced to an applicable case for consequential processing. Moreover, to improve both efficiency and performance of classification, these prior probabilities are further used to specify the distributions of top-level hyperparameters in hierarchical models of Bayesian neural network (BNN), as well as the parameters in Gaussian process models. Results: Three BNN approaches were derived and then applied to identify ovarian cancer from NCI's high-resolution mass spectrometry data, which yielded an excellent performance in 1000 independent k-fold cross validations (k = 2,..., 10). For instance, indices of average sensitivity and specificity of 98.56 and 98.42%, respectively, were achieved in the 2-fold cross validations. Furthermore, only one control and one cancer were misclassified in the leave-one-out cross validation. Some other popular classifiers were also tested for comparison.	Univ Kansas, Informat & Telecommun Technol Ctr, Lawrence, KS 66045 USA; Univ Kansas, Dept Elect Engn & Comp Sci, Lawrence, KS 66045 USA; Peking Univ, Sch Elect Engn & Comp Sci, Beijing 100871, Peoples R China	Chen, XW (reprint author), Univ Kansas, Informat & Telecommun Technol Ctr, Lawrence, KS 66045 USA.	xwchen@ku.edu					Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Bickel P. J., 2001, MATH STAT BASIC IDEA, V1; Bishop C.M., 1995, NEURAL NETWORKS PATT; Buntine W. L., 1991, Complex Systems, V5; Conrads TP, 2004, ENDOCR-RELAT CANCER, V11, P163, DOI 10.1677/erc.0.0110163; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cristianini N., 2000, INTRO SUPPORT VECTOR; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; DUANE S, 1987, PHYS LETT B, V195, P216, DOI 10.1016/0370-2693(87)91197-X; Efron B., 1993, INTRO BOOTSTRAP; Gelman A., 2004, BAYESIAN DATA ANAL; Gibbs M. N., 1997, THESIS U CAMBRIDGE U; INSUA DR, 1998, PRACTICAL NONPARAMET, P181; Kass RE, 1998, AM STAT, V52, P93, DOI 10.2307/2685466; Lampinen J., 2001, NEURAL NETWORKS, V14, P7; Lehmann EL, 1975, NONPARAMETRICS STAT; Lilien RH, 2003, J COMPUT BIOL, V10, P925, DOI 10.1089/106652703322756159; Liotta LA, 2003, NATURE, V425, P905, DOI 10.1038/425905a; Liu J. S., 2001, MONTE CARLO STRATEGI; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.415; Mackay D. J. C., 1998, NEURAL NETWORKS MACH; MACKAY DJC, 1995, NETWORK-COMP NEURAL, V6, P469, DOI 10.1088/0954-898X/6/3/011; MACKAY DJC, 1992, NEURAL COMPUT, V4, P448, DOI 10.1162/neco.1992.4.3.448; MARDIA KV, 1984, BIOMETRIKA, V71, P135, DOI 10.1093/biomet/71.1.135; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Muller P., 1998, NEURAL COMPUT, V10, P571; NEAL R. M., 1999, BAYESIAN STAT, P475; Neal R.M., 1996, LECT NOTES STAT, V118; NEAL RM, 1992, CRGTR921; OHAGAN A, 1978, J ROY STAT SOC B MET, V40, P1; Petricoin EF, 2004, CURR OPIN BIOTECH, V15, P24, DOI 10.1016/j.copbio.2004.01.005; Petricoin EF, 2003, CLIN CHEM, V49, P533, DOI 10.1373/49.4.533; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Rasmussen CE, 1996, THESIS U TORONTO CAN; Ripley B. D, 1996, PATTERN RECOGNITION; SCHOLKOFT B, 2002, LEARNING KERNELS; Spiegelhalter D. J., 1995, BUGS BAYESIAN INFERE; Vapnik V. N, 1995, NATURE STAT LEARNING; Vlahou A, 2003, J BIOMED BIOTECHNOL, P308; Williams CKI, 1996, ADV NEUR IN, V8, P514; WILLIAMS CKI, 2002, HDB BRAIN THEORY NEU; Williams CKI, 1998, IEEE T PATTERN ANAL, V20, P1342, DOI 10.1109/34.735807; WILLIAMS CKI, 1997, NEURAL INFORMATION P, V9, P295; Williams CKI, 1998, NATO ADV SCI I D-BEH, V89, P599; WU B, 2003, BIOINFORMATICS, V19, P636; Wulfkuhle JD, 2003, NAT REV CANCER, V3, P267, DOI 10.1038/nrc.1043; Yaglom A.M., 1987, CORRELATION THEORY S; YU JS, 2005, BIOINFORMATICS	48	19	19	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	JUN	2005	21			1			I487	I494		10.1093/bioinformatics/bti1030		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	942HH	WOS:000230273000055	
J	Tavakkoli-Moghaddam, R; Daneshmand-Mehr, M				Tavakkoli-Moghaddam, R; Daneshmand-Mehr, M			A computer simulation model for job shop scheduling problems minimizing makespan	COMPUTERS & INDUSTRIAL ENGINEERING			English	Article; Proceedings Paper	30th International Conference on Computers and Industrial Engineering	JUN 29-JUL 02, 2002	Tinos Isl, GREECE			job shop scheduling; sequencing; makespan; computer simulation model; visual SLAM	GENETIC ALGORITHM; FLOWSHOP; NETWORK	One of the basic and significant problems, that a shop or a factory manager is encountered, is a suitable scheduling and sequencing of jobs on machines. One type of scheduling problem is job shop scheduling. There are different machines in a shop of which a job may require some or all these machines in some specific sequence. For solving this problem, the objective may be to minimize the makespan. After optimizing the makespan, the jobs sequencing must be carried out for each machine. The above problem can be solved by a number of different methods such as branch and bound, cutting plane, heuristic methods, etc. In recent years, researches have used genetic algorithms, simulated annealing, and machine learning methods for solving such problems. In this paper, a simulation model is presented to work out job shop scheduling problems with the objective of minimizing makespan. The model has been coded by Visual SLAM which is a special simulation language. The structure of this language is based on the network modeling. After modeling the scheduling problem, the model is verified and validated. Then the computational results are presented and compared with other results reported in the literature. Finally, the model output is analyzed. (c) 2004 Elsevier Ltd. All rights reserved.	Univ Tehran, Fac Engn, Dept Ind Engn, Tehran, Iran; Mazandaran Univ Sci & Technol, Dept Ind Engn, Babol Sar, Iran	Tavakkoli-Moghaddam, R (reprint author), Univ Tehran, Fac Engn, Dept Ind Engn, POB 11365-4563, Tehran, Iran.	tavakoli@ut.ac.ir; maryamdm@yahoo.com					Akpan EOP, 1996, INT J OPER PROD MAN, V16, P76, DOI 10.1108/01443579610110503; Azadeh M.A., 2000, J FACULTY ENG, V34, P127; Baker KR, 1974, INTRO SEQUENCING SCH; BIANCO L, 1999, NAV RES LOG, V46, P895; BIDOKHTI B, 2001, SANAAYE Q MAGAZINE I, V25, P38; Blazewicz J, 1996, EUR J OPER RES, V93, P1, DOI 10.1016/0377-2217(95)00362-2; Blazewicz J, 2000, EUR J OPER RES, V127, P317, DOI 10.1016/S0377-2217(99)00486-5; Chen LH, 1996, COMPUT IND ENG, V30, P1, DOI 10.1016/0360-8352(95)00164-6; DANESHMANDMEHR M, 2002, THESIS MAZANDARAN U; DRAKE GR, 1996, WINT SIM C P, P1083; EMRE AV, 2001, COMPUT IND ENG, V41, P77; Fisher H., 1963, IND SCHEDULING; Grangeon N, 1999, COMPUT IND ENG, V37, P207, DOI 10.1016/S0360-8352(99)00056-X; Guinet A, 2000, EUR J OPER RES, V125, P469, DOI 10.1016/S0377-2217(99)00389-6; IDA K, 2002, P 30 INT C COMP IND, P389; Lee CY, 1997, INT J PROD RES, V35, P1171, DOI 10.1080/002075497195605; LORENCO HR, 1995, EUROPEAN J OPER RES, V83, P347; NEJATI M, 1998, THESIS U TEHRAN; Pinedo M., 2001, SCHEDULING THEORY AL; PRITSKER A, 1996, SIMULATION VISUAL SL; RAHMATI A, 1998, THESIS U TEHRAN; Sabuncuoglu I, 2000, EUR J OPER RES, V126, P567, DOI 10.1016/S0377-2217(99)00311-2; Satake T, 1999, INT J PROD ECON, V60-1, P515, DOI 10.1016/S0925-5273(98)00171-6; Steinhofel K, 1999, EUR J OPER RES, V118, P524, DOI 10.1016/S0377-2217(98)00326-9; Subramaniam V, 2000, PROD PLAN CONTROL, V11, P73, DOI 10.1080/095372800232504; Sule D. R., 1997, IND SCHEDULING; Yu HB, 2001, COMPUT IND ENG, V39, P337, DOI 10.1016/S0360-8352(01)00010-9	27	8	8	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0360-8352		COMPUT IND ENG	Comput. Ind. Eng.	JUN	2005	48	4					811	823		10.1016/j.cie.2004.12.010		13	Computer Science, Interdisciplinary Applications; Engineering, Industrial	Computer Science; Engineering	920OD	WOS:000228699100011	
J	Zaremba, MB; Palenichka, RM				Zaremba, MB; Palenichka, RM			Relevance-based content modeling and object retrieval from multi-source image data	CONCURRENT ENGINEERING-RESEARCH AND APPLICATIONS			English	Article						design automation; object retrieval; content modeling; machine learning; classification; image relevance analysis; discriminating property map	ATTENTION; CLASSIFICATION; FEATURES	The problem of object retrieval for design automation based on semi-semantic representation of objects of interest in images is addressed in this article. The concept of an ordered set of salient feature vectors (SFVs) is introduced to concisely describe multi-source image data in different application areas. A system architecture is presented which combines statistical learning modules with multi-scale morphological modeling and analysis of image contents. In the presented approach, the object retrieval is based on establishing correspondence between two ordered sets of SFVs: a query reference image (or concise description of the object) and a database image. On a higher level, new rules of association are established between the design objects, based on the extracted SFVs and their spatial relations in images. Experiments with different types of images confirmed the utility of the proposed content modeling and proved the adequacy of the extraction accuracy of the SFVs.	Univ Quebec, Dept Comp Sci & Engn, Quebec City, PQ, Canada	Zaremba, MB (reprint author), Univ Quebec, Dept Comp Sci & Engn, Quebec City, PQ, Canada.	zaremba@uqo.ca					ALFAREZ R, 1999, IEEE T PATTERN ANAL, V21, P505; Belongie S., 1998, P INT C COMP VIS, P675; BERRETTI S, 1998, IEEE T PATTERN ANAL, V23, P1069; Di Gesu V, 2001, SIGNAL PROCESS, V81, P265, DOI 10.1016/S0165-1684(00)00206-1; Djeraba C, 2003, IEEE T KNOWL DATA EN, V15, P118, DOI 10.1109/TKDE.2003.1161586; Duta N, 2001, IEEE T PATTERN ANAL, V23, P433, DOI 10.1109/34.922703; ELHAKIM SF, 1999, SPIE P, V3641, P127; ELHAKIM SF, 2001, SPIE P, V4309, P21; Fisher R. A., 1950, CONTRIBUTIONS MATH S; Gevers T, 2000, IEEE T IMAGE PROCESS, V9, P102, DOI 10.1109/83.817602; HARSANYI JC, 1994, IEEE T GEOSCI REMOTE, V32, P779, DOI 10.1109/36.298007; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jee HJ, 2003, CONCURRENT ENG-RES A, V11, P151, DOI 10.1177/106329303035389; LINDEBERG T, 1993, INT J COMPUT VISION, V11, P283, DOI 10.1007/BF01469346; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465; Palenichka RM, 1996, PATTERN RECOGN, V29, P1495, DOI 10.1016/0031-3203(96)00001-5; PALENICHKA RM, 2004, LNCS, V2396, P310; Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261; REISFELD D, 1995, INT J COMPUT VISION, V14, P119, DOI 10.1007/BF01418978; Rui Y., 1999, J VISUAL COMMUNICATI, V10; Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2383, P186; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; Sebe N, 2003, PATTERN RECOGN LETT, V24, P89, DOI 10.1016/S0167-8655(02)00192-7; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; SUK M, 1992, 3 DIMENSIOINAL OBJEC; Tagare HD, 2001, IEEE T PATTERN ANAL, V23, P490, DOI 10.1109/34.922707; TOENSHOFF HK, 1999, PRODUCTION ENG, V6, P125; WEINHART K, 2000, PRODUCTION ENG, V7, P61; WERMAN M, 1995, IEEE T PATTERN ANAL, V17, P810, DOI 10.1109/34.400572; Zheng ZQ, 1999, PATTERN RECOGN LETT, V20, P149, DOI 10.1016/S0167-8655(98)00134-2	30	1	1	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	1063-293X		CONCURRENT ENG-RES A	Concurrent Eng.-Res. Appl.	JUN	2005	13	2					155	166		10.1177/1063293X05053794		12	Computer Science, Interdisciplinary Applications; Engineering, Manufacturing; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	926WP	WOS:000229154700007	
J	Facca, FM; Lanzi, PL				Facca, FM; Lanzi, PL			Mining interesting knowledge from weblogs: a survey	DATA & KNOWLEDGE ENGINEERING			English	Article						machine learning; Web Mining	WORLD-WIDE-WEB; RECOMMENDER SYSTEMS; PERSONALIZATION; DISCOVERY; FRAMEWORK; EFFICIENT; SESSIONS	Web Usage Mining is that area of Web Mining which deals with the extraction of interesting knowledge from logging information produced by Web servers. In this paper we present a survey of the recent developments in this area that is receiving increasing attention from the Data Mining community. (c) 2004 Elsevier B.V. All rights reserved.	Politecn Milan, Dipartimento Elettron & Informaz, Artificial Intelligence & Robot Lab, I-20133 Milan, Italy	Lanzi, PL (reprint author), Politecn Milan, Dipartimento Elettron & Informaz, Artificial Intelligence & Robot Lab, I-20133 Milan, Italy.	facca@elet.polimi.it; lanzi@elet.polimi.it					ADOMAVICIUS G, 2001, WORKSH INT TECHN WEB; Agrawal R, 2000, P ACM SIGMOD C MAN D, P439, DOI DOI 10.1145/342009.335438; ANDERSEN J, 2000, INT WORKSH DAT WAR O; ANDERSON CR, 2002, P 8 ACM SIGKDD INT C; Anderson CR, 2002, THESIS U WASHINGTON; ANSARI S, 2001, P 2001 IEEE INT C DA; ANSARI S, 2000, WEBKDD 2000 WEB MIN; BANERJEE A, 2001, P WEB MIN WORKSH 1 S; BERENDT B, 2002, P 4 WEBKDD 2002 WORK; Berendt B, 2002, DATA MIN KNOWL DISC, V6, P37, DOI 10.1023/A:1013280719795; Bonchi F, 2001, DATA KNOWL ENG, V39, P165, DOI 10.1016/S0169-023X(01)00038-6; BORGES J, 2000, THESIS U COLLEGE LON; BOUNSAYTHIP C, 2001, TTEI200118 VTT; Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X; CATLEDGE LD, 1995, COMPUT NETWORKS ISDN, V27, P1065, DOI 10.1016/0169-7552(95)00043-7; CHANG CY, 2002, P 11 INT C INF KNOWL, P632; CHANG WL, 2000, WEBKDD 2000 WEB MIN; Chen M., 2002, P 25 ANN INT ACM SIG, P65; Chi E.H., 2001, P ACM CHI 2001 C HUM, P490, DOI 10.1145/365024.365325; Cooley R, 2003, ACM T INTERNET TECHN, V3, P93, DOI 10.1145/767193.767194; Cooley R., 1999, Knowledge and Information Systems, V1; COOLEY R, 2000, WEB USAGE DISCOVERY; Craven M, 2000, ARTIF INTELL, V118, P69, DOI 10.1016/S0004-3702(00)00004-7; Dai H., 2002, P 2 SEM WEB MIN WORK; DIEBOLD B, 2001, AUSTR S INF VIS, P159; Eirinaki M, 2003, P 9 ACM SIGKDD INT C, P99; Eirinaki M., 2003, ACM T INTERNET TECHN, V3, P1, DOI DOI 10.1145/643477.643478; Etzioni O, 1996, COMMUN ACM, V39, P65, DOI 10.1145/240455.240473; EVFIMIEVSKI A. V., 2002, P 8 ACM SIGKDD INT C; FENSTERMACHER KD, 2002, 4 IEEE INT WORKSH AD, P205; Fu Y, 2001, P 10 INT C INF KNOWL, P583; Han J., 2001, DATA MINING CONCEPTS; HAN J, 2000, P 6 ACM SIGKDD INT C; HAY B, 2001, INTELLIGENT TECHNIQU, P1; HEER J, 2002, P WORKSH WEB AN 2 SI; HOLLAND JH, 1992, ADAPTATION NATURAL A; Huang JZ, 2002, LECT NOTES ARTIF INT, V2356, P48; Huang X., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; JESPERSEN SE, 2002, P 4 INT C DAT WAR KN, P73; Joshi KP, 2003, DISTRIB PARALLEL DAT, V13, P161, DOI 10.1023/A:1021515408295; KAMDAR T, 2001, THESIS U MARYLAND BA; Kim HR, 2003, P 8 INT C INT US INT, P101; Kosala R., 2000, ACM SIGKDD EXPLORATI, V2, P1, DOI DOI 10.1145/360402.360406; Kristol D.M., 2001, ACM T INTERNET TECHN, V1, P151, DOI 10.1145/502152.502153; LAN B, 2000, P 9 ACM INT C INF KN, P504, DOI 10.1145/354756.354859; LI T, 2001, THESIS S FRASER U; Lin WY, 2002, DATA MIN KNOWL DISC, V6, P83, DOI 10.1023/A:1013284820704; Lindell Y, 2000, LECT NOTES COMPUT SC, V1880, P36; MENASALVAS E, 2002, P FUZZ IEEE FUZZ SET; MEO R, 2004, IN PRESS WEBKDD2004; Mobasher B, 2002, DATA MIN KNOWL DISC, V6, P61, DOI 10.1023/A:1013232803866; Mobasher B, 2000, COMMUN ACM, V43, P142, DOI 10.1145/345124.345169; MOBASHER B, 2001, WEB INFORMATION DATA, P9; MORTAZAVIASL B, 2001, THESIS S FRASER U; Nanopoulos A, 2002, LECT NOTES ARTIF INT, V2356, P68; Nanopoulos A, 2003, IEEE T KNOWL DATA EN, V15, P1155, DOI 10.1109/TKDE.2003.1232270; NANOPOULOS A, 2002, 4 ACM CIKM INT WORKS; NASRAOUI O, 2002, P WORLD C COMP INT W, P711; NIU ESN, 2002, P 4 INT WORKSH WEB S, P53; OYANAGI S, 2001, WEBKDD 2001 MIN WEB; Paik H.-Y., 2002, WWW J, V5, P325, DOI 10.1023/A:1021072310244; Pal SK, 2002, IEEE T NEURAL NETWOR, V13, P1163, DOI 10.1109/TNN.2002.1031947; Pei J., 2000, P PAC AS C KNOWL DIS, P396; PEI J, IN PRESS IEEE T KNOW; Punin JR, 2002, LECT NOTES ARTIF INT, V2356, P88; Schafer J. B., 2001, Data Mining and Knowledge Discovery, V5, DOI 10.1023/A:1009804230409; SHAHABI C, 2002, E COMMERCE INTELLIGE, V105; Shahabi C, 2002, LECT NOTES ARTIF INT, V2356, P113; SPILOPOULOU M, 2001, DATA MINING MEASURIN, P85; Srikant R, 2001, WORLD WIDE WEB, P430; SRIVASTAVA J, 2000, SIGKDD EXPLORATIONS, V1, P12; STUMME G, 2002, NAT SCI FDN WORKSH N; Tan PN, 2002, DATA MIN KNOWL DISC, V6, P9, DOI 10.1023/A:1013228602957; TAN PN, 2000, WEBKDD 2000 WEB MIN; Toolan F, 2002, WISE 2002: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON WEB INFORMATION SYSTEMS ENGINEERING (WORKSHOPS), P232; VANDERMEER D, 2000, P ACM E COMM 2000 C, P185, DOI 10.1145/352871.352892; WONG SSC, 2001, WORKSH SOFT COMP CAS; Wu Y, 2002, WORLD WIDE WEB, V5, P67, DOI 10.1023/A:1015750423727; Xie Y., 2001, P 1 INT C KNOWL CAPT, P202; Yang Q, 2003, IEEE T KNOWL DATA EN, V15, P1050; YPMA A, 2002, P 14 BELG DUTCH C AI; ZAIANE OR, 2001, P C ADV TECHN ED, P450; Zhu JH, 2002, LECT NOTES COMPUT SC, V2311, P60; [Anonymous], 1995, OFFICIAL J EUROPEAN, VL 281, P0031; *EUR COMM INF SOC, 1998, CONS DISC KNOWL IND; *IBM, 2003, SURFA AN; *PIL SOFTW, 2002, WEB SIT AN GOING TRA; CONFIGURATION FILE W; W3C EXTENDED LOG FIL	89	73	81	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-023X		DATA KNOWL ENG	Data Knowl. Eng.	JUN	2005	53	3					225	241		10.1016/j.datak.2004.08.001		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	907ZZ	WOS:000227758100001	
J	Mora-Lopez, L; Mora, J; Morales-Bueno, R; Sidrach-de-Cardona, M				Mora-Lopez, L; Mora, J; Morales-Bueno, R; Sidrach-de-Cardona, M			Modeling time series of climatic parameters with probabilistic finite automata	ENVIRONMENTAL MODELLING & SOFTWARE			English	Article						machine learning; modeling climatic data; time series	RADIATION; SEQUENCES; VALUES; SYSTEM	A model to characterize and predict continuous time series from machine-learning techniques is proposed. This model includes the following three steps: dynamic discretization of continuous values, construction of probabilistic finite automata and prediction of new series with randomness. The first problem in most models from machine learning is that they are developed for discrete values; however, most phenomena in nature are continuous. To convert these continuous values into discrete values a dynamic discretization method has been used. With the obtained discrete series, we have built probabilistic finite automata which include all the representative information which the series contain. The learning algorithm to build these automata is polynomial in the sample size. An algorithm to predict new series has been proposed. This algorithm incorporates the randomness in nature. After finishing the three steps of the model, the similarity between the predicted series and the real ones has been checked. For this, a new adaptable test based on the classical Kolmogorov-Smirnov two-sample test has been done. The cumulative distribution function of observed and generated series has been compared using the concept of indistinguishable values. Finally, the proposed model has been applied in several practical cases of time series of climatic parameters. (c) 2004 Elsevier Ltd. All rights reserved.	Univ Malaga, Dept Lenguajes & C Computac, ETSI Informat, E-29071 Malaga, Spain; Univ Alicante, Dept Fundamentos Anal Econ, E-03080 Alicante, Spain; Univ Malaga, Dept Fis Aplicada 2, ETSI Informat, E-29071 Malaga, Spain	Mora-Lopez, L (reprint author), Univ Malaga, Dept Lenguajes & C Computac, ETSI Informat, Campus Teatinos, E-29071 Malaga, Spain.	llanos@lcc.uma.es; juan@merlin.fae.ua.es; morales@lcc.uma.es; msidrach@ctima.uma.es					AGUIAR R, 1992, SOL ENERGY, V49, P167, DOI 10.1016/0038-092X(92)90068-L; AGUIAR RJ, 1988, SOL ENERGY, V40, P269, DOI 10.1016/0038-092X(88)90049-7; Anh V, 1997, ENVIRON MODELL SOFTW, V12, P67, DOI 10.1016/S1364-8152(96)00043-6; BENDT P, 1981, SOL ENERGY, V27, P1, DOI 10.1016/0038-092X(81)90013-X; Box G.E.P., 1976, TIME SERIES ANAL; BRINKWORTH BJ, 1977, SOL ENERGY, V19, P343, DOI 10.1016/0038-092X(77)90004-4; FORBUS KD, 1984, ARTIF INTELL, V24, P85, DOI 10.1016/0004-3702(84)90038-9; Kemmoku Y, 1999, SOL ENERGY, V66, P193, DOI 10.1016/S0038-092X(99)00017-1; Kleer JO., 1984, ARTIF INTELL, V24, P7; KROG A, 1993, UCSCCRL9316 U CAL; KUIPERS B, 1984, ARTIF INTELL, V24, P169, DOI 10.1016/0004-3702(84)90039-0; McMillan AC, 2000, ENVIRON MODELL SOFTW, V15, P245, DOI 10.1016/S1364-8152(00)00010-4; Mohandes M, 1998, RENEW ENERG, V14, P179, DOI 10.1016/S0960-1481(98)00065-2; MORALOPEZ L, 2000, LECT NOTES ARTIF INT, V1810, P280; MORALOPEZ L, 2003, SOL ENERGY, V73, P235; MoraLopez LL, 1997, SOL ENERGY, V60, P257, DOI 10.1016/S0038-092X(97)00018-2; NADAS A, 1984, IEEE T ACOUST SPEECH, V32, P859, DOI 10.1109/TASSP.1984.1164378; RABINER LR, 1994, P 7 ANN WORKSH COMP; RISSANEN J, 1983, IEEE T INFORM THEORY, V29, P656, DOI 10.1109/TIT.1983.1056741; ROHATGI VK, 1976, INTRO PROBABILITY T; RON D, 1994, P 7 ANN WORKSH COMP; Ron D, 1998, J COMPUT SYST SCI, V56, P133, DOI 10.1006/jcss.1997.1555	22	2	3	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1364-8152		ENVIRON MODELL SOFTW	Environ. Modell. Softw.	JUN	2005	20	6					753	760		10.1016/j.envsoft.2004.04.007		8	Computer Science, Interdisciplinary Applications; Engineering, Environmental; Environmental Sciences	Computer Science; Engineering; Environmental Sciences & Ecology	905RI	WOS:000227586900008	
J	Glickman, M; Balthrop, J; Forrest, S				Glickman, M; Balthrop, J; Forrest, S			A machine learning evaluation of an artificial immune system	EVOLUTIONARY COMPUTATION			English	Article						anomaly detection; artificial immune systems; machine learning; immune system; network intrusion detection; computer security		ARTIS is an artificial immune system framework which contains several adaptive mechanisms. LISYS is a version of ARTIS specialized for the problem of network intrusion detection. The adaptive mechanisms of LISYS are characterized in terms of their machine-learning counterparts, and a series of experiments is described, each of which isolates a different mechanism of LISYS and studies its contribution to the system's overall performance. The experiments were conducted on a new data set, which is more recent and realistic than earlier data sets. The network intrusion detection problem is challenging because it requires one-class learning in an on-line setting with concept drift. The experiments confirm earlier experimental results with LISYS, and they study in detail how LISYS achieves success on the new data set.	Univ New Mexico, Dept Comp Sci, Albuquerque, NM 87131 USA; Santa Fe Inst, Santa Fe, NM 87501 USA	Glickman, M (reprint author), Univ New Mexico, Dept Comp Sci, Albuquerque, NM 87131 USA.	glickman@cs.unm.edu; judd@cs.unm.edu; forrest@cs.unm.edu					Anchor K. P., 2002, P 1 INT C ART IMM SY, P12; Anderson D., 1995, SRICSL9507; ANGLUIN D, 1980, INFORM CONTROL, V45, P117, DOI 10.1016/S0019-9958(80)90285-5; Axelsson S., 2000, ACM Transactions on Information and Systems Security, V3, DOI 10.1145/357830.357849; BALASUBRAMANIYA.J, 1998, TR9805 PURD U; BALTHROP J, 2002, CEC 2002; Balthrop J., 2002, GECCO 2002; Bradley D. W., 2001, Proceedings Third NASA/DoD Workshop on Evolvable Hardware. EH-2001, DOI 10.1109/EH.2001.937962; CARUANA RA, 1988, MACHLERN5; CASWELL B, 2003, SNORT OPEN SOURCE NE; CHAO D, 2001, COMMUNICATION; Dasgupta D., 2002, IEEE T EVOLUTIONARY, V6, P1081; DEBAR H, 1999, COMPUTER NETWORKS, V31, P361; DOWELL C, 1990, P 13 NAT COMP SEC C; EGAN JP, 1975, SIGNAL DETECTION THE; Esponda F, 2004, IEEE T SYST MAN CY B, V34, P357, DOI 10.1109/TSMCB.2003.817026; Forrest S., 1994, P 1994 IEEE S RES SE; Gaffney JE, 2001, P IEEE S SECUR PRIV, P50, DOI 10.1109/SECPRI.2001.924287; GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5; Heberlein LT, 1990, P IEEE S SEC PRIV; HELMAN P, 1993, IEEE T SOFTWARE ENG, V19, P886, DOI 10.1109/32.241771; HELMBOLD DP, 1994, MACH LEARN, V14, P27, DOI 10.1007/BF00993161; Hofmeyr S., 1999, THESIS U NEW MEXICO; Hofmeyr SA, 2000, EVOL COMPUT, V8, P443, DOI 10.1162/106365600568257; Holland J. H., 1986, INDUCTION PROCESSES; Kim J., 1999, 7 EUR C INT TECHN SO; Kim J., 2002, P 1 INT C ART IMM SY, P59; KIM J, 1999, GECCO 99 P, P149; KIM J, 2002, P 1 INT C ART IMM SY, P182; Kim J., 2001, P GEN EV COMP C GECC, P1330; Klinkenberg R., 2000, P 17 INT C MACH LEAR, P487; LANE TD, 2000, THESIS PURDUE U W LA; McHugh J, 2000, LECT NOTES COMPUT SC, V1907, P145; Mitchell T, 1997, MACHINE LEARNING; MITCHELL TM, 1980, CBMTR117 TURG U; Mitchell T., 1994, Communications of the ACM, V37, DOI 10.1145/176789.176798; MUGGLETON S, 1996, LECT NOTES ARTIF INT, V1314, P358; MUKHERJEE B, 1994, IEEE NETWORK, V8, P26, DOI 10.1109/65.283931; PERCUS JK, 1993, P NATL ACAD SCI USA, V90, P1691, DOI 10.1073/pnas.90.5.1691; Pinker S, 1984, LANGUAGE LEARNABILIT; PORRAS PA, 1997, P NAT INF SYST SEC C; PRATT L, 1997, LEARNING LEARN, pCH2; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1, P318; Smaha S.E., 1988, P IEEE 4 AER COMP SE; WILLIAMS PD, 2001, LECT NOTES COMPUTER, V2212, P117; *ISS, 2000, REALS PROD DAT INT S; *NIST, 2003, 7007 NIST IR	47	19	23	MIT PRESS	CAMBRIDGE	55 HAYWARD STREET, CAMBRIDGE, MA 02142 USA	1063-6560		EVOL COMPUT	Evol. Comput.	SUM	2005	13	2					179	212		10.1162/1063656054088503		34	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	937LO	WOS:000229925800003	
J	Ferre, S; King, RD				Ferre, S; King, RD			A dichotomic search algorithm for mining and learning in domain-specific logics	FUNDAMENTA INFORMATICAE			English	Article; Proceedings Paper	1st International Workshop on Mining Graphs, Trees and Sequences	SEP   10, 2003	Cavtat, CROATIA			data structures; domain-specific logics; search algorithm; dichotomy; formal concept analysis; concept learning; pattern mining; bioinformatics	DISCOVERY	Many application domains make use of specific data structures such as sequences and graphs to represent knowledge. These data structures are ill-fitted to the standard representations used in machine learning and data-mining algorithms: propositional representations are not expressive enough, and first order ones are not efficient enough. In order to efficiently represent and reason on these data structures, and the complex patterns that are related to them, we use domain-specific logics. We show these logics can be built by the composition of logical components that model elementary data structures. The standard strategies of top-down and bottom-up search are ill-suited to some of these logics, and lack flexibility. We therefore introduce a dichotomic search strategy, that is analogous to a dichotomic search in an ordered array. We prove this provides more flexibility in the search, while retaining completeness and non-redundancy. We present a novel algorithm for learning using domain specific logics and dichotomic search, and analyse its complexity. We also describe two applications which illustrates the search for motifs in sequences; where these motifs have arbitrary length and length-constrained gaps. In the first application sequences represent the trains of the East-West challenge; in the second application they represent the secondary structure of Yeast proteins for the discrimination of their biological functions.	Univ Rennes 1, IRISA, F-35042 Rennes, France; Univ Wales, Dept Comp Sci, Aberystwyth SY23 3DB, Dyfed, Wales	Ferre, S (reprint author), Univ Rennes 1, IRISA, Campus Beaulieu, F-35042 Rennes, France.	ferre@irisa.fr; rdk@aber.ac.uk					ABE K, 2002, LNCS, V2431; ALBERTLORINCZ H, 2003, SIAM INT C DAT MIN; ALT M, 1995, LNCS, V983; APOSTOLICO A, 1997, HDB FORMAL LANGUAGES, V2, P361; BADEA L, 2001, LNCS, V2157; BADEA L, 1999, LNCS, V1634; BAKER BS, 1998, LNCS, V1461; BRACHMAN RJ, 1979, ASS NETWORKS REPRESE; BRAZMA A, 1995, 113 U BERG DEP INF; Brejova B., 2000, CS200022 U WAT; Clare A., 2003, BIOINFORMATICS, V19, P42; COHEN WW, 1994, PRINC KNOWL REPR REA; DEHASPE L, 1998, INT C KNOWL DISC DAT; DEHASPE L, 1997, LNCS, V1297; Domingos P, 1999, DATA MIN KNOWL DISC, V3, P409, DOI 10.1023/A:1009868929893; FENSEL D, 1993, LNCS, V667; FERRE S, 2000, LNCS, V1867; FERRE S, 2002, LNCS, V2372; Ferre S, 2004, INFORM PROCESS MANAG, V40, P383, DOI 10.1016/S0306-4573(03)00018-9; Finn V. K., 1983, SEMIOTIKA INFORMATIK, V20, P35; FRUHWIRTH H, 1995, PRINCIPLES PRACTICE, pCH19; FURNKRANZ J, 1996, OEFAITR9625 AUSTR RE; Ganter B., 1999, FORMAL CONCEPT ANAL; GANTER B, 2000, LNCS, V1867; GEAMSAKUL W, 2003, LNCS, V2637; GOFFEAU A, 1997, NATURE S, V387, P1; Inokuchi A, 2003, MACH LEARN, V50, P321, DOI 10.1023/A:1021726221443; Jensen DD, 2000, MACH LEARN, V38, P309, DOI 10.1023/A:1007631014630; JONASSEN I, 1996, 118 U BERG DEP INF; KONONENKO I, 1992, INT WORKSH MACH LEAR; Lanckriet GRG, 2004, PAC S BIOC; LEE SD, 2002, P WORKSH MULT REL DA; Lesh N, 2000, IEEE INTELL SYST APP, V15, P48, DOI 10.1109/5254.850827; Michie D., 1994, INT COMPUTING COMMUN; Mitchell T, 1997, MACHINE LEARNING; Muggleton S., 1994, Journal of Logic Programming, V19-20, DOI 10.1016/0743-1066(94)90035-3; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; Muggleton S. H., 1992, INDUCTIVE LOGIC PROG, P281; Ouali M, 2000, PROTEIN SCI, V9, P1162; Page D., 2003, J MACHINE LEARNING R, V4, P415; Plotkin G. D., 1971, THESIS EDINBURGH U; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Rigoutsos I, 1998, BIOINFORMATICS, V14, P55, DOI 10.1093/bioinformatics/14.1.55; RUCKERT U, 2003, INT WORKSH KNOWL DIS; SRINIVASAN A, ALEPH LEARNING ENGIN; Srinivasan A, 1999, DATA MIN KNOWL DISC, V3, P37, DOI 10.1023/A:1009815821645; SRINIVASAN A, 1995, INT WORKSH IND LOG P; WIDMER G, 1993, INFORMATICA, V17, P371; Wille R., 1982, ORDERED SETS, P445; Wolpert D.H., 1995, SFITR9502010; ZUCKER JD, 1996, INT C MACH LEARN; 2001, CRITICAL ASSESSMENT, V45	52	1	1	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0169-2968		FUND INFORM	Fundam. Inform.	JUN	2005	66	1-2					1	32				32	Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	020YC	WOS:000235948300002	
J	Geamsakul, W; Yoshida, T; Ohara, K; Motoda, H; Yokoi, H; Takabayashi, K				Geamsakul, W; Yoshida, T; Ohara, K; Motoda, H; Yokoi, H; Takabayashi, K			Constructing a decision tree for graph-structured data and its applications	FUNDAMENTA INFORMATICAE			English	Article; Proceedings Paper	1st International Workshop on Mining Graphs, Trees and Sequences	SEP   10, 2003	Cavtat, CROATIA			graph mining; graph-based induction; decision tree; beam search; evidence-based medicine	PATTERNS	A machine learning technique called Graph-Based Induction (GBI) efficiently extracts typical patterns from graph-structured data by stepwise pair expansion (pairwise chunking). It is very efficient because of its greedy search. Meanwhile, a decision tree is an effective means of data classification from which rules that are easy to understand can be obtained. However, a decision tree could not be constructed for the data which is not explicitly expressed with attribute-value pairs. This paper proposes a method called Decision Tree Graph-Based Induction (DT-GBI), which constructs a classifier (decision tree) for graph-structured data while simultaneously constructing attributes for classification using GBI. Substructures (patterns) are extracted at each node of a decision tree by stepwise pair expansion in GBI to be used as attributes for testing. Since attributes (features) are constructed while a classifier is being constructed, DT-GBI can be conceived as a method for feature construction. The predictive accuracy of a decision tree is affected by which attributes (patterns) are used and how they are constructed. A beam search is employed to extract good enough discriminative patterns within the greedy search framework. Pessimistic pruning is incorporated to avoid overfitting to the training data. Experiments using a DNA dataset were conducted to see the effect of the beam width and the number of chunking at each node of a decision tree. The results indicate that DT-GBI that uses very little prior domain knowledge can construct a decision tree that is comparable to other classifiers constructed using the domain knowledge. DT-GBI was also applied to analyze a real-world hepatitis dataset as a part of evidence-based medicine. Four classification tasks of the hepatitis data were conducted using only the time-series data of blood inspection and urinalysis. The preliminary results of experiments, both constructed decision trees and their predictive accuracies as well as extracted patterns, are reported in this paper. Some of the patterns match domain experts' experience and the overall results are encouraging.	Osaka Univ, Inst Sci & Ind Res, Ibaraki, Osaka 5670047, Japan; Chiba Univ Hosp, Div Med Informat, Chiba, Japan	Geamsakul, W (reprint author), Osaka Univ, Inst Sci & Ind Res, 8-1 Mihogaoka, Ibaraki, Osaka 5670047, Japan.	warodom@ar.sanken.osaka-u.ac.jp; yoshida@ar.sanken.osaka-u.ac.jp; ohara@ar.sanken.osaka-u.ac.jp; motoda@ar.sanken.osaka-u.ac.jp; yokoi@telemed.ho.chiba-u.ac.jp; takaba@ho.chiba-u.ac.jp					Blake C. L., 1998, UCI REPOSITORY MACHI; BLOCKEEL H, 2003, ACM SIGKDD EXPLORATI, V5, P17, DOI 10.1145/959242.959246; Blockeel H, 1998, ARTIF INTELL, V101, P285, DOI 10.1016/S0004-3702(98)00034-4; BREIMAN L, 1989, MACH LEARN, V3, P261; Breiman L, 1984, CLASSIFICATION REGRE; Cook DJ, 2000, IEEE INTELL SYST APP, V15, P32, DOI 10.1109/5254.850825; DZEROSKI S, 2001, RELATIONAL DATA MINI, P63; Fortin S, 1996, GRAPH ISOMORPHISM PR; HIRANO S, 2002, P 2002 IEEE INT C DA; HO TB, 2003, P 9 ACM SIGKDD INT C; Inokuchi A, 2003, MACH LEARN, V50, P321, DOI 10.1023/A:1021726221443; INOKUCHI A, 2000, P 4 EUR C PRINC DAT; Kramer S, 2001, RELATIONAL DATA MINING, P140; MATSUDA T, 2002, SPRINGER VERLAG LNAI, V2417; MATSUDA T, 2002, P 5 INT C DISC SCI; MATSUDA T, 2000, SPRINGER VERLAG LNAI, V1805; MICHALSKI RS, 1990, MACHINE LEARNING ART, V3, P63; Muggleton S, 1999, ARTIF INTELL, V114, P283, DOI 10.1016/S0004-3702(99)00067-3; Muggleton S., 1994, Journal of Logic Programming, V19-20, DOI 10.1016/0743-1066(94)90035-3; Nedellec C., 1996, ADV INDUCTIVE LOGIC, P82; OHSAKI M, 2003, RULE DISCOVERY SUPPO; Page D., 2003, J MACHINE LEARNING R, V4, P415; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Read R. C., 1977, J GRAPH THEOR, V1, P339, DOI 10.1002/jgt.3190010410; TOWELL GG, 1993, MACH LEARN, V13, P71, DOI 10.1007/BF00993103; WARODOM G, 2003, SPRINGER VERLAG LNAI, V2637; WARODOM G, 2003, SPRINGER VERLAG LNAI, V2843; YAMADA Y, 2003, P 12 INT C MACH LEAR; YOSHIDA K, 1995, ARTIF INTELL, V75, P63, DOI 10.1016/0004-3702(94)00066-A	30	8	8	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0169-2968		FUND INFORM	Fundam. Inform.	JUN	2005	66	1-2					131	160				30	Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	020YC	WOS:000235948300007	
J	Garcia-Pedrajas, N; Hervas-Martinez, U; Ortiz-Boyer, D				Garcia-Pedrajas, N; Hervas-Martinez, U; Ortiz-Boyer, D			Cooperative coevolution of artificial neural network ensembles for pattern classification	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION			English	Article						classification; cooperative coevolution; multiobjective optimization; neural network ensembles	MULTIOBJECTIVE EVOLUTIONARY ALGORITHMS; DECISION TREES; COMBINING CLASSIFIERS; NEGATIVE CORRELATION; PREDICTORS; REGULARIZATION; INFORMATION; REGRESSION; DIVERSITY; ACCURACY	This paper presents a cooperative coevolutive approach for designing neural network ensembles. Cooperative coevolution is a recent paradigm in evolutionary computation that allows the effective modeling of cooperative environments. Although theoretically, a single neural network with a sufficient number of neurons in the hidden layer would suffice to solve any problem, in practice many real-world problems are too hard to construct the appropriate network that solve them. In such problems, neural network ensembles are a successful alternative. Nevertheless, the design of neural network ensembles is a complex task. In this paper, we propose a general framework for designing neural network ensembles by means of cooperative coevolution. The proposed model has two main objectives: first, the improvement of the combination of the trained individual networks; second, the cooperative evolution of such networks, encouraging collaboration among them, instead of a separate training of each network. In order to favor the cooperation of the networks, each network is evaluated throughout the evolutionary process using a multiobjective method. For each network, different objectives are defined, considering not only its performance in the given problem, but also its cooperation with the rest of the networks. In addition, a population of ensembles is evolved, improving the combination of networks and obtaining subsets of networks to form ensembles that perform better than the combination of all the evolved networks. The proposed model is applied to ten real-world classification problems of a very different nature from the UCI machine learning repository and proben1 benchmark set. In all of them the performance of the model is better than the performance of standard ensembles in terms of generalization error. Moreover, the size of the obtained ensembles is also smaller.	Univ Cordoba, Dept Comp & Numer Anal, E-14071 Cordoba, Spain	Garcia-Pedrajas, N (reprint author), Univ Cordoba, Dept Comp & Numer Anal, E-14071 Cordoba, Spain.	npedrajas@uco.es; chervas@uco.es; dortiz@uco.es					AFIFI A, 1979, STAT ANA COMPUTER OR; ANGELINE PJ, 1994, IEEE T NEURAL NETWOR, V5, P54, DOI 10.1109/72.265960; Avnimelech R, 1999, NEURAL COMPUT, V11, P483, DOI 10.1162/089976699300016737; Bakker B, 2003, NEURAL NETWORKS, V16, P261, DOI 10.1016/S0893-6080(02)00187-9; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Benediktsson JA, 1997, IEEE T NEURAL NETWOR, V8, P54, DOI 10.1109/72.554191; Bosman PAN, 2003, IEEE T EVOLUT COMPUT, V7, P174, DOI 10.1109/TEVC.2003.810761; Breiman L, 2000, MACH LEARN, V40, P229, DOI 10.1023/A:1007682208299; Breiman L, 1996, MACH LEARN, V24, P49, DOI 10.1007/BF00117832; Breiman L., 1996, 460 U CAL DEP STAT; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Caelli T, 1999, P IEEE, V87, P1497, DOI 10.1109/5.784227; Cantu-Paz E, 2003, IEEE T EVOLUT COMPUT, V7, P54, DOI 10.1109/TEVC.2002.806857; CLEMEN RT, 1985, OPER RES, V33, P427, DOI 10.1287/opre.33.2.427; Coello C. A. C., 1999, Knowledge and Information Systems, V1; Collins R., 1991, P 4 INT C GEN ALG, P249; Cover T. M., 1991, ELEMENTS INFORMATION; de Jong K. A., 1975, THESIS U MICHIGAN; Deb K, 1999, P EV ALG ENG COMP SC; DEB K, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P42; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dietterich Thomas G., 2000, P 1 INT WORKSH MULT, P1; Dzeroski S, 2004, MACH LEARN, V54, P255, DOI 10.1023/B.MAC.0000015881.36452.6e; Fern A, 2003, MACH LEARN, V53, P71, DOI 10.1023/A:1025619426553; FINNOFF W, 1993, NEURAL NETWORKS, V6, P771, DOI 10.1016/S0893-6080(05)80122-4; Fogel D. B., 1992, THESIS U CALIFORNIA; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Garcia-Pedrajas N, 2002, NEURAL NETWORKS, V15, P1255; Garcia-Pedrajas N, 2003, IEEE T NEURAL NETWOR, V14, P575, DOI 10.1109/TNN.2003.810618; GIACINTO G, 2000, P MULTIPLE CLASSIFIE, V1850, P177; Goldberg D., 1991, FDN GENETIC ALGORITH, P94; Goldberg D. E., 1987, P 2 INT C GEN ALG, P148; Goldberg DE, 1989, GENETIC ALGORITHMS S; Goutte C, 1997, NEURAL NETWORKS, V10, P1053, DOI 10.1016/S0893-6080(97)00027-0; Hansen JV, 1999, INFORM SCIENCES, V119, P91, DOI 10.1016/S0020-0255(99)00052-3; Hashem S, 1997, NEURAL NETWORKS, V10, P599, DOI 10.1016/S0893-6080(96)00098-6; Haykin S., 1999, NEURAL NETWORKS COMP; Horn J, 1994, EVOL COMPUT, V2, P37, DOI 10.1162/evco.1994.2.1.37; ISHIKAWA MA, 1990, TR907 EL LAB; Islam M, 2003, IEEE T NEURAL NETWOR, V14, P820, DOI 10.1109/TNN.2003.813832; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Jolliffe IT, 1986, PRINCIPAL COMPONENTS; KHARE VR, THESIS U BIRMINGHAM, P200; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kivinen J, 1997, INFORM COMPUT, V132, P1, DOI 10.1006/inco.1996.2612; KNOWLES KD, 2000, EVOL COMPUT, V8, P149; Kohavi R., 1996, P 13 INT C MACH LEAR, P275; KONG EB, 1995, P 12 INT C MACH LEAR, P275; KOZAJR, 1994, GENETIC PROGRAMMING, V2; Krogh A., 1995, ADV NEURAL INFORMATI, V8, P231; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; LEBLANC M, 1993, COMBINING ESTIMATES; LeCun Y., 1998, Neural networks: tricks of the trade; LIU Y, 2001, P 2001 IEEE C EV COM, P384; LIU Y, 1998, P 3 INT S ART LIF RO, P736; Liu Y, 1999, NEURAL NETWORKS, V12, P1399, DOI 10.1016/S0893-6080(99)00073-8; Liu Y, 2000, IEEE T EVOLUT COMPUT, V4, P380; Liu Y, 1999, IEEE T SYST MAN CY B, V29, P716, DOI 10.1109/3477.809027; MEIR R, 1995, ADV NEURAL INFORMATI, V7; Merz CJ, 1999, MACH LEARN, V36, P33, DOI 10.1023/A:1007559205422; Merz CJ, 1999, MACH LEARN, V36, P9, DOI 10.1023/A:1007507221352; Michalewicz Z, 1994, GENETIC ALGORITHMS D; Moriarry D.E., 1998, EVOLUTIONARY COMPUTA, V5, P373; Moriarty D., 1997, THESIS U TEXAS AUSTI; NOWLAN SJ, 1992, NEURAL COMPUT, V4, P473, DOI 10.1162/neco.1992.4.4.473; Opitz D., 1999, J ARTIFICIAL INTELLI, P169; Opitz D. W., 1996, Connection Science, V8, DOI 10.1080/095400996116802; Perrone M.P., 1993, NEURAL NETWORKS SPEE, P126; PLAUT C, 1986, CMUCS86126; POTTER MA, 1997, THESIS GOERGE MASON; Potter MA, 2000, EVOL COMPUT, V8, P1, DOI 10.1162/106365600568086; PRECHELT L, 1994, 2194 U KARLSR FAK IN; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; REED R, 1993, IEEE T NEURAL NETWOR, V4, P740, DOI 10.1109/72.248452; Rosen B. E., 1996, Connection Science, V8, DOI 10.1080/095400996116820; SCHAEFER P, 1990, EARTH ISL J, V5, P2; Sharkey A. J. C., 1996, Connection Science, V8, DOI 10.1080/095400996116785; Srinivas N., 1994, Evolutionary Computation, V2, P221, DOI 10.1162/evco.1994.2.3.221; Syswerda G, 1991, FDN GENETIC ALGORITH, P94; SYSWERDA G, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P2; Todorovski L, 2003, MACH LEARN, V50, P223, DOI 10.1023/A:1021709817809; Tumer K., 1996, PATTERN RECOGN, V29, P341, DOI DOI 10.1016/0031-3203(95)00085-2; TURNER K, 1996, 787121084 TX; Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849; Werbos P. J., 1994, ROOTS BACKPROPAGATIO; Whitley D., 1990, Journal of Experimental and Theoretical Artificial Intelligence, V2, DOI 10.1080/09528139008953723; WHITLEY D, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P116; Whitley D, 1988, P ROCK MOUNT C ART I, P118; WILLIAMS PM, 1995, NEURAL COMPUT, V7, P117, DOI 10.1162/neco.1995.7.1.117; Yao X, 1997, IEEE T NEURAL NETWOR, V8, P694, DOI 10.1109/72.572107; Darwen P. J., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.687878; Yao X, 1998, IEEE T SYST MAN CY B, V28, P417, DOI 10.1109/3477.678637; Yule GU, 1900, PHILOS T R SOC LOND, V194, P257, DOI 10.1098/rsta.1900.0019; ZENOBI G, 2001, LECT NOTES ARTIFICIA, V2167; Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X; Zitzler E, 2003, IEEE T EVOLUT COMPUT, V7, P117, DOI 10.1109/TEVC.2003.810758; Zitzler E, 1999, IEEE T EVOLUT COMPUT, V3, P257, DOI 10.1109/4235.797969	100	87	92	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1089-778X		IEEE T EVOLUT COMPUT	IEEE Trans. Evol. Comput.	JUN	2005	9	3					271	302		10.1109/TEVC.2005.844158		32	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	933SX	WOS:000229654300004	
J	Ajemba, PO; Ramirez, L; Durdle, NG; Hill, DL; Raso, VJ				Ajemba, PO; Ramirez, L; Durdle, NG; Hill, DL; Raso, VJ			A support vectors classifier approach to predicting the risk of progression of adolescent idiopathic scoliosis	IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE			English	Article						decision support systems; Lenke indicators; machine learning (NIL); scoliosis progression; support vector classifiers (SVCs)	CURVE	A support vector classifier (SVC) approach was employed in predicting the risk of progression of adolescent idiopathic scoliosis (AIS), a condition that causes visible trunk asymmetries. As the aetiology of AIS is unknown, its risk of progression can only be predicted from measured indicators. Previous studies suggest that individual indicators of AIS do not reliably predict its risk of progression. Complex indicators with better predictive values have been developed but are unsuitable for clinical use as obtaining their values is often onerous, involving much skill and repeated measurements taken over time. Based on the hypothesis that combining common indicators of AIS using an SVC approach would produce better prediction results more quickly, we conducted a study using three datasets comprising a total of 44 moderate AIS patients (30 observed, 14 treated with brace). Of the 44 patients, 13 progressed less than 5' and 31 progressed more than 5'. One dataset comprised all the patients. A second dataset comprised all the observed patients and a third comprised all the brace-treated patients. Twenty-one radiographic and clinical indicators were obtained for each patient. The result of testing on the three datasets showed that the system achieved 100% accuracy in training and 65%-80% accuracy in testing. It outperformed a "statistically equivalent" logistic regression model and a stepwise linear regression model on the said datasets. It took less than 20 min per patient to measure the indicators, input their values into the system, and produce the needed results, making the system viable for use in a clinical environment.	Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2V4, Canada; Glenrose Rehabil Hosp, Dept Rehabil Technol, Edmonton, AB T5G 0B7, Canada	Ajemba, PO (reprint author), Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2V4, Canada.	ajemba@ece.ualbert.ca; durdle@ece.ualbert.ca					AJEMBA PO, 2003, P 4 BIOM ENG C BANFF; Cobb J. R., 1948, AM ACADEMY ORTHOPAED, V5, P261; DUVALBEAUPERE G, 1985, SPINE, V10, P421, DOI 10.1097/00007632-198506000-00003; Jain A.K., 2000, IEEE T PATTERN ANAL, P22; KAROL LA, 1993, J BONE JOINT SURG AM, V75A, P1804; KOHASHI Y, 1993, SPINE, V21, P212; LENKE LG, 2001, SPINE, V27, P604; Lenke LG, 2001, J BONE JOINT SURG AM, V83A, P1169; LONSTEIN JE, 1984, J BONE JOINT SURG AM, V66A, P1061; LONSTEIN JE, 1994, LANCET, V344, P1407; LOU E, 2002, RES INTO SPINAL DEFO; NACHEMSON AL, 1982, ANN M SCOL RES SOC D; PETERSON LE, 1995, J BONE JOINT SURG AM, V77A, P823; Platt J.C., 1999, ADV KERNEL METHODS S; Ramirez L, 2002, SOFT COMPUTING AND INDUSTRY, P281; Raso VJ, 1998, J PEDIATR ORTHOPED, V18, P222, DOI 10.1097/00004694-199803000-00017; RISSER J C, 1958, Clin Orthop, V11, P111; Smith AE, 2003, ARTIF INTELL MED, V27, P1, DOI 10.1016/S0933-3657(02)00088-X; Vapnik VN, 1998, STAT LEARNING THEORY	19	4	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1089-7771		IEEE T INF TECHNOL B	IEEE T. Inf. Technol. Biomed.	JUN	2005	9	2					276	282		10.1109/TITB.2005.847169		7	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Medical Informatics	Computer Science; Mathematical & Computational Biology; Medical Informatics	933QY	WOS:000229649200014	
J	Luo, JB; Boutell, M; Gray, RT; Brown, C				Luo, JB; Boutell, M; Gray, RT; Brown, C			Image transform bootstrapping and its applications to semantic scene classification	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article; Proceedings Paper	IEEE International Conference on Multimedia	JUL, 2003	BALTIMORE, MD	IEEE		bootstrapping; exemplar-based learning; image transform; meta-classifier; semantic scene classification		The performance of an exemplar-based scene classification system depends largely on the size and quality of its set of training exemplars, which can be limited in practice. In addition, in nontrivial data sets, variations in scene content as well as distracting regions may exist in many testing images to prohibit good matches with the exemplars. Various boosting schemes have been proposed in machine learning, focusing on the feature space. We introduce the novel concept of image-transform bootstrapping using transforms in the image space to address such issues. In particular, three major schemes are described for exploiting this concept to augment training, testing, and both. We have successfully applied it to three applications of increasing difficulty: sunset detection, outdoor scene classification, and automatic image orientation detection. It is shown that appropriate transforms and meta-classification methods can be selected to boost performance according to the domain of the problem and the features/classifier used.	Eastman Kodak Co, Res & Dev Labs, Rochester, NY 14650 USA; Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA	Luo, JB (reprint author), Eastman Kodak Co, Res & Dev Labs, Rochester, NY 14650 USA.	jiebo.luo@kodak.com; boutell@cs.rochester.edu; robert.gray@kodak.com; brown@cs.rochester.edu					Bay S.D., 1998, P 15 INT C MACH LEAR, P37; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Bryll R, 2003, PATTERN RECOGN, V36, P1291, DOI 10.1016/S0031-3203(02)00121-8; Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800; COHEN I, 2003, IEEE C COMP VIS PATT; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Duda R. O., 2001, PATTERN CLASSIFICATI; DUIN RPW, 2002, INT C PATT REC; Hunt RWG, 1995, REPROD COLOR; LIPSON P, 1997, IEEE C COMP VIS PATT; ROWLEY H, 1998, IEEE C COMP VIS PATT; Scholkopf B., 1999, ADV KERNEL METHODS S; Skurichina M, 1998, PATTERN RECOGN, V31, P909, DOI 10.1016/S0031-3203(97)00110-6; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Smith JR, 1999, COMPUT VIS IMAGE UND, V75, P165, DOI 10.1006/cviu.1999.0771; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; VAILAYA A, 1999, IEEE INT C MULT COMP; VAILAYA A, 1999, IEEE INT C IM PROC; WAN GY, 2001, IEEE WORKSH CONT BAS; ZHANG T, 2000, INT C MACH LEARN	20	5	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	JUN	2005	35	3					563	570		10.1109/TSMCB.2005.846677		8	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	928ZD	WOS:000229309700017	
J	Pedrycz, W; Sosnowski, ZA				Pedrycz, W; Sosnowski, ZA			Genetically optimized fuzzy decision trees	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						computational intelligence; fuzzy decision trees; genetic algorithm (GA); propagation mechanisms; triangular norms and co-norms; two-stage design	ALGORITHM METHOD; CLASSIFIER; NETWORKS; MODELS	In this study, we are concerned with genetically optimized fuzzy decision trees (G-DTs). Decision trees are fundamental architectures of machine learning, pattern recognition, and system modeling. Starting with the generic decision tree with discrete or interval-valued attributes, we develop its fuzzy set-based generalization. In this generalized structure we admit the values of the attributes that are represented by some membership functions. Such fuzzy decision trees are constructed in the setting of genetic optimization. The underlying genetic algorithm optimizes the parameters of the fuzzy sets associated with the individual nodes where they play a role of fuzzy "switches" by distributing a flow of processing completed within the tree. We discuss various forms of the fitness function that help capture the essence of the problem at hand (that could be either of classification nature when dealing with discrete outputs or regression-like when handling a continuous output variable). We quantify a nature of the generalization of the tree by studying an optimally adjusted spreads of the membership functions located at the nodes of the decision tree. A series of experiments exploiting synthetic and machine learning data is used to illustrate the performance of the G-DTs.	Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2G7, Canada; Polish Acad Sci, Syst Res Inst, PL-01447 Warsaw, Poland; Bialystok Tech Univ, Dept Comp Sci, PL-15351 Bialystok, Poland	Pedrycz, W (reprint author), Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2G7, Canada.	pedrycz@ee.ualberta.ca; zenon@ii.pb.bialystok.pl					Apolloni B, 1998, NEURAL NETWORKS, V11, P885, DOI 10.1016/S0893-6080(98)00030-6; Carvalho DR, 2004, INFORM SCIENCES, V163, P13, DOI 10.1016/j.ins.2003.03.013; Chiasserini CF, 2002, IEEE T WIREL COMMUN, V1, P87, DOI 10.1109/7693.975448; D'heygere T, 2003, ECOL MODEL, V160, P291, DOI 10.1016/S0304-3800(02)00260-0; Dombi J, 2005, EUR J OPER RES, V160, P663, DOI 10.1016/j.ejor.2003.10.006; Haskell RE, 2004, PATTERN RECOGN, V37, P1653, DOI 10.1016/j.patcog.2004.01.010; Janikow CZ, 1996, INFORM SCIENCES, V89, P275, DOI 10.1016/0020-0255(95)00239-1; Kampichler C, 2004, ECOL INDIC, V4, P99, DOI 10.1016/j.ecolind.2004.01.001; LEE KC, 1989, FUZZY SET SYST, V33, P1, DOI 10.1016/0165-0114(89)90212-1; Merz C., 1996, UCI REPOSITORY MACHI; Mugambi EM, 2004, KNOWL-BASED SYST, V17, P81, DOI 10.1016/j.knosys.2004.03.003; Olaru C, 2003, FUZZY SET SYST, V138, P221, DOI 10.1016/S0165-0114(03)00089-7; PEDRYCZ W, UNPUB IEEE T SYST MA; Pedrycz W, 2000, IEEE T SYST MAN CY A, V30, P151, DOI 10.1109/3468.833095; Pedrycz W, 2001, FUZZY SET SYST, V123, P271, DOI 10.1016/S0165-0114(00)00118-4; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLANN JR, 1993, C4 5 PROGRAMS MACHIN; Roa-Sepulveda CA, 2003, ELECTR POW SYST RES, V66, P115, DOI 10.1016/S0378-7796(03)00020-8; Sorensen K, 2003, EUR J OPER RES, V151, P253, DOI 10.1016/S0377-2217(02)00824-X; Youssif RS, 2004, NEUROCOMPUTING, V61, P39, DOI 10.1016/j.neucom.2004.03.003	20	15	15	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	JUN	2005	35	3					633	641		10.1109/TSMCB.2005.843975		9	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	928ZD	WOS:000229309700024	
J	Wilson, J; Berry, I				Wilson, J; Berry, I			The use of gradient direction in pre-processing images from crystallization experiments	JOURNAL OF APPLIED CRYSTALLOGRAPHY			English	Article							AUTOMATIC CLASSIFICATION; TRIALS	Robots are now used routinely to perform crystallization experiments and many laboratories now have imaging systems to record the results. These images must be evaluated rapidly and the results fed back into optimization procedures. Software to analyse the images is being developed; described here are methods to restrict the area of the image to be analysed in order to speed up processing. Properties of the gradient of greyscale images are used to identify first the well and then the crystallization drop for various crystallization trays and different imaging systems. Methods are discussed to identify artefacts in the images that are not related to the experimental outcome, but can cause problems for the machine-learning algorithms used in classification and waste time during analysis. Gradient angles are exploited to eliminate faults in the crystallization trays, bubbles and splatter droplets prior to analysis.	Univ York, Dept Chem, York Struct Biol Lab, York YO10 5YW, N Yorkshire, England; Div Struct Biol, Oxford OX3 7BN, England; Oxford Prot Prod Facil, Oxford OX3 7BN, England	Wilson, J (reprint author), Univ York, Dept Chem, York Struct Biol Lab, York YO10 5YW, N Yorkshire, England.	julie@ysbl.york.ac.uk					Bern M, 2004, J APPL CRYSTALLOGR, V37, P279, DOI 10.1107/S0021889804001761; BERRY I, 2004, IN PRESS INT J NEURA; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679; Cumbaa CA, 2003, ACTA CRYSTALLOGR D, V59, P1619, DOI 10.1107/S0907444903015130; Gonzalez RC, 2002, DIGITAL IMAGE PROCES; Hough P., 1962, U.S. Patent, Patent No. [3,069,654, 3069654]; Spraggon G, 2002, ACTA CRYSTALLOGR D, V58, P1915, DOI 10.1107/S0907444902016840; Wilson J, 2002, ACTA CRYSTALLOGR D, V58, P1907, DOI 10.1107/S0907444902016633; WILSON V, 2004, CRYSTALLOGR REV, V10, P73	9	4	4	BLACKWELL MUNKSGAARD	FREDERIKSBERG C	1 ROSENORNS ALLE, DK-1970 FREDERIKSBERG C, DENMARK	0021-8898		J APPL CRYSTALLOGR	J. Appl. Crystallogr.	JUN	2005	38		3				493	500		10.1107/S0021889805007442		8	Crystallography	Crystallography	926SE	WOS:000229142100012	
J	Sun, HW				Sun, HW			Mercer theorem for RKHS on noncompact sets	JOURNAL OF COMPLEXITY			English	Article						mercer kernel; reproducing kernel Hilbert spaces; nondegenerate Borel measure; positive semidefiniteness	SUPPORT VECTOR MACHINES; LEARNING-THEORY	Reproducing kernel Hilbert spaces are an important family of function spaces and play useful roles in various branches of analysis and applications including the kernel machine learning. When the domain of definition is compact, they can be characterized as the image of the square root of an integral operator, by means of the Mercer theorem. The purpose of this paper is to extend the Mercer theorem to noncompact domains, and to establish a functional analysis characterization of the reproducing kernel Hilbert spaces on general domains. (c) 2004 Published by Elsevier Inc.	Jinan Univ, Sch Sci, Jinan 250022, Peoples R China	Sun, HW (reprint author), Jinan Univ, Sch Sci, Jinan 250022, Peoples R China.	Shw_yb@sina.com					ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI 10.2307/1990404; CUCKER F, LEARNING THEORY; Cucker F, 2002, FOUND COMPUT MATH, V2, P413, DOI 10.1007/s102080010030; Cucker F., 2001, B AM MATH SOC, V39, P1, DOI 10.1090/S0273-0979-01-00923-5; Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316; Girosi F, 1998, NEURAL COMPUT, V10, P1455, DOI 10.1162/089976698300017269; Hochstadt H., 1973, INTEGRAL EQUATIONS; Mercer J, 1909, PHILOS T R SOC LOND, V209, P415, DOI 10.1098/rsta.1909.0016; Smale S, 2003, ANAL APPL, V1, P17, DOI 10.1142/S0219530503000089; Vapnik VN, 1998, STAT LEARNING THEORY; Wahba G., 1990, SERIES APPL MATH, V59; Zhou DX, 2002, J COMPLEXITY, V18, P739, DOI 10.1006/jcom.2002.0635; Zhou DX, 2003, IEEE T INFORM THEORY, V49, P1743, DOI 10.1109/TIT.2003.813564	13	25	26	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0885-064X		J COMPLEXITY	J. Complex.	JUN	2005	21	3					337	349		10.1016/j.jco.2004.09.002		13	Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	930US	WOS:000229443200006	
J	Ding, BY; Gentleman, R				Ding, BY; Gentleman, R			Classification using generalized partial least squares	JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS			English	Article						cross-validation; Firth's procedure; gene expression; iteratively reweighted partial least squares; (quasi) separation; two-stage PLS	GENE-EXPRESSION DATA; LOGISTIC-REGRESSION MODELS; CANCER CLASSIFICATION; EXISTENCE; SELECTION; PATTERNS; TUMOR; BIAS	Advances in computational biology have made simultaneous monitoring of thousands of features possible. The high throughput technologies not only bring about a much richer information context in which to study various aspects of gene function, but they also present the challenge of analyzing data with a large number of covariates and few samples. As an integral part of machine learning, classification of samples into two or more categories is almost always of interest to scientists. We address the question of classification in this setting by extending partial least squares (PLS), a popular dimension reduction tool in chemometrics, in the context of generalized linear regression, based on a previous approach, iteratively reweighted partial least squares, that is, IRWPLS. We compare our results with two-stage PLS and with other classifiers. We show that by phrasing the problem in a generalized linear model setting and by applying Firth's procedure to avoid (quasi)separation, we often get lower classification error rates.	Amgen Inc, Med Affairs Biostat, Newbury Pk, CA 91320 USA; Fred Hutchinson Canc Res Ctr, Program Computat Biol, Div Publ Hlth Sci, Seattle, WA 98104 USA	Ding, BY (reprint author), Amgen Inc, Med Affairs Biostat, 1 Amgen Ctr Dr,Mail Stop 24-2-A, Newbury Pk, CA 91320 USA.	bding@amgen.com; rgentlem@fhcrc.org					ALBERT A, 1984, BIOMETRIKA, V71, P1; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BREIMAN L., 2002, MANUAL SETTING USING; Chen Y, 1997, J Biomed Opt, V2, P364, DOI 10.1117/1.429838; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Eilers P. H. C., 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4266, DOI 10.1117/12.427987; Fahrmeir L., 2001, MULTIVARIATE STAT MO; FIRTH D, 1993, BIOMETRIKA, V80, P27, DOI 10.1093/biomet/80.1.27; Firth D., 1992, COMPUTATION STAT, V1, P553; FIRTH D, 1993, BIOMETRIKA, V82, P667; Firth D., 1992, ADV GLIM STAT MODELL, P91; Fisher RA, 1936, ANN EUGENIC, V7, P179; FORT G, 2003, TR0331 IAP; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; GELADI P, 1986, ANAL CHIM ACTA, V185, P1, DOI 10.1016/0003-2670(86)80028-9; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Heinze G, 2002, STAT MED, V21, P2409, DOI 10.1002/sim.1047; HELLAND IS, 1988, COMMUN STAT SIMULAT, V17, P581, DOI 10.1080/03610918808812681; Hoskuldsson A, 1988, J CHEMOMETR, V2, P211, DOI 10.1002/cem.1180020306; KRUSKAL J, 1978, INT ENCY STAT; Martens H., 1989, MULTIVARIATE CALIBRA; Marx BD, 1996, TECHNOMETRICS, V38, P374, DOI 10.2307/1271308; MASSY WF, 1965, J AM STAT ASSOC, V60, P234, DOI 10.2307/2283149; McCullagh P., 1989, GEN LINEAR MODELS; Newton MA, 2001, J COMPUT BIOL, V8, P37, DOI 10.1089/106652701300099074; Nguyen DV, 2002, BIOINFORMATICS, V18, P1216, DOI 10.1093/bioinformatics/18.9.1216; Nguyen DV, 2002, BIOINFORMATICS, V18, P39, DOI 10.1093/bioinformatics/18.1.39; Ripley B. D, 1996, PATTERN RECOGNITION; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; SANTNER TJ, 1986, BIOMETRIKA, V73, P755, DOI 10.1093/biomet/73.3.755; Scherf U, 2000, NAT GENET, V24, P236, DOI 10.1038/73439; Smith J. W., 1988, Proceedings. The Twelfth Annual Symposium on Computer Applications in Medical Care (IEEE Cat. No.88CH2616-1); Venables W. N., 2002, MODERN APPL STAT S; Wang CY, 1999, PHOTOCHEM PHOTOBIOL, V69, P471, DOI 10.1111/j.1751-1097.1999.tb03314.x; Wold H, 1975, PERSPECTIVES PROBABI	38	23	23	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	1061-8600		J COMPUT GRAPH STAT	J. Comput. Graph. Stat.	JUN	2005	14	2					280	298		10.1198/106186005X47697		19	Statistics & Probability	Mathematics	008LJ	WOS:000235041900003	
J	Michielsen, K; De Raedt, K; De Raedt, H				Michielsen, K; De Raedt, K; De Raedt, H			Simulation of quantum computation: A deterministic event-based approach	JOURNAL OF COMPUTATIONAL AND THEORETICAL NANOSCIENCE			English	Article						quantum computation; computer simulation; machine learning; quantum theory	FACTORING ALGORITHM; COMPUTER; GATES	We demonstrate that locally connected networks of machines that have primitive learning capabilities can be used to perform a deterministic, event-based simulation of quantum computation. We present simulation results for basic quantum operations such as the Hadamard and the controlled-NOT gate, and for seven-qubit quantum networks that implement Shor's numbering factoring algorithm.	Univ Groningen, Ctr Mat Sci, Dept Appl Phys, NL-9747 AG Groningen, Netherlands; Univ Groningen, Dept Comp Sci, NL-9747 AC Groningen, Netherlands	De Raedt, H (reprint author), Univ Groningen, Ctr Mat Sci, Dept Appl Phys, Nijenborgh 4, NL-9747 AG Groningen, Netherlands.						BARENCO A, 1995, PHYS REV A, V52, P3457, DOI 10.1103/PhysRevA.52.3457; Baym G, 1974, LECT QUANTUM MECH; Born M., 1964, PRINCIPLES OPTICS; Chiorescu I, 2004, NATURE, V431, P159, DOI 10.1038/nature02831; Chuang I. L., 2000, QUANTUM COMPUTATION; DERAEDT H, 2005, HDB COMPUTATIONAL TH; De Raedt H, 2000, COMPUT PHYS COMMUN, V132, P1, DOI 10.1016/S0010-4655(00)00132-6; DERAEDT H, 2005, J PHYS SOC JPN S, V20, P16; DERANDT K, IN PRESS ARXIVQUANTP; DIVINCENZO DP, 1995, PHYS REV A, V51, P1015, DOI 10.1103/PhysRevA.51.1015; Ekert A, 1996, REV MOD PHYS, V68, P733, DOI 10.1103/RevModPhys.68.733; ELZERMAN JM, 2004, NATURE, V435, P331; Feynman R P, 1996, FEYNMAN LECT PHYS, VIII; GRANGIER P, 1986, EUROPHYS LETT, V1, P173, DOI 10.1209/0295-5075/1/4/004; Haykin S., 1999, NEURAL NETWORKS; Home D., 1997, CONCEPTUAL FDN QUANT; Michielsen K., 2003, Turkish Journal of Physics, V27; Penrose R, 1990, EMPERORS NEW MIND; Rarity JG, 1997, PHILOS T R SOC A, V355, P2267; Rugar D, 2004, NATURE, V430, P329, DOI 10.1038/nature02658; Schiff L. I., 1968, QUANTUM MECH; Shor PW, 1999, SIAM REV, V41, P303, DOI 10.1137/S0036144598347011; TONOMURA A, 1998, QUAUNTUM MECH MODERN; VANDERSYPEN LMK, 2004, THESIS DEP EL ENG ST; Vandersypen LMK, 2001, NATURE, V414, P883, DOI 10.1038/414883a; VANKAMPEN NG, 1988, PHYSICA A, V153, P97, DOI 10.1016/0378-4371(88)90105-7; XIAO X, 2004, NATURE, V435, P335; Zalka C, 1998, P ROY SOC LOND A MAT, V454, P313, DOI 10.1098/rspa.1998.0162; Zurek WH, 2003, REV MOD PHYS, V75, P715, DOI 10.1103/RevModPhys.75.715	29	32	33	AMER SCIENTIFIC PUBLISHERS	STEVENSON RANCH	25650 NORTH LEWIS WAY, STEVENSON RANCH, CA 91381-1439 USA	1546-1955		J COMPUT THEOR NANOS	J. Comput. Theor. Nanosci.	JUN	2005	2	2					227	239		10.1166/jctn.2005.106		13	Chemistry, Multidisciplinary; Nanoscience & Nanotechnology; Materials Science, Multidisciplinary; Physics, Applied; Physics, Condensed Matter	Chemistry; Science & Technology - Other Topics; Materials Science; Physics	987RC	WOS:000233534000006	
J	Berrar, D; Sturgeon, B; Bradbury, I; Downes, CS; Dubitzky, W				Berrar, D; Sturgeon, B; Bradbury, I; Downes, CS; Dubitzky, W			Survival trees for analyzing clinical outcome in lung adenocarcinomas based on gene expression profiles: Identification of neogenin and diacylglycerol kinase alpha expression as critical factors	JOURNAL OF COMPUTATIONAL BIOLOGY			English	Article						survival tree; microarrays; lung adenocarcinomas; machine learning	BREAST-CANCER; DCC; CLASSIFICATION; CARCINOMAS; SUBCLASSES; PREDICTION; PROTEIN; CELLS	We present survival trees as an exploratory tool for revealing new insights into gene expression profiles in combination with clinical patient data. Survival trees partition the patient data studied into groups with similar survival outcomes and identify characteristic genetic profiles within these groups. We demonstrate the application of survival trees in a study involving the expression profiles of 3,588 genes in 211 lung adenocarcinoma patients. The survival tree identified a group of early-stage cancer patients with relatively low survival rates and another group of advanced-stage patients with remarkably good survival outcome. For both groups, the tree identified characteristic expression profiles of genes that might play a role in cancerogenesis and disease progression, notably the genes for the netrin receptor neogenin and the Ras/Rho kinase modulator diacylglycerol kinase alpha.	Univ Ulster, Sch Biomed Sci, Bioinformat Res Grp, Fac Life & Hlth Sci, Coleraine BT52 1SA, Londonderry, North Ireland	Berrar, D (reprint author), Univ Ulster, Sch Biomed Sci, Bioinformat Res Grp, Fac Life & Hlth Sci, Cromore Rd, Coleraine BT52 1SA, Londonderry, North Ireland.	dp.berrar@ulster.ac.uk					Altman RB, 2001, CURR OPIN STRUC BIOL, V11, P340, DOI 10.1016/S0959-440X(00)00212-8; Bair E, 2003, SIGKDD EXPLORATIONS, V5, P48; Beer DG, 2002, NAT MED, V8, P816, DOI 10.1038/nm733; BERRAR D, 2005, P INT C CRIT ASS MIC, P147; Bhattacharjee A, 2001, P NATL ACAD SCI USA, V98, P13790, DOI 10.1073/pnas.191502998; BOLSTAD BM, 2002, BIOINFORMATICS, V19, P185; Borczuk AC, 2003, AM J PATHOL, V163, P1949, DOI 10.1016/S0002-9440(10)63553-5; Breiman L, 1984, CLASSIFICATION REGRE; Chang JC, 2003, LANCET, V362, P362, DOI 10.1016/S0140-6736(03)14023-8; DAVIS RB, 1989, STAT MED, V8, P947, DOI 10.1002/sim.4780080806; Glinsky GV, 2004, CLIN CANCER RES, V10, P2272, DOI 10.1158/1078-0432.CCR-03-0522; Hu YC, 2001, CLIN CANCER RES, V7, P2213; INTRATOR O, 1995, 275 U WASH DEP STAT; Jiang Y, 2003, DEV BIOL, V258, P364, DOI 10.1016/S0012-1606(03)00136-2; LEBLANC M, 1992, BIOMETRICS, V48, P411, DOI 10.2307/2532300; Meyerhardt JA, 1997, ONCOGENE, V14, P1129, DOI 10.1038/sj.onc.1200935; MOLINARO AM, 2004, THESIS U CALIFORNIA; SEGAL MR, 1988, BIOMETRICS, V44, P35, DOI 10.2307/2531894; Shibata D, 1996, NEW ENGL J MED, V335, P1727, DOI 10.1056/NEJM199612053352303; SIMON R, 2003, SIGKDD EXPLORATIONS, V5, P31; Sorlie T, 2001, P NATL ACAD SCI USA, V98, P10869, DOI 10.1073/pnas.191367098; Srinivasan K, 2003, DEV CELL, V4, P371, DOI 10.1016/S1534-5807(03)00054-6; Topham MK, 2001, J CELL BIOL, V152, P1135, DOI 10.1083/jcb.152.6.1135; van de Vijver MJ, 2002, NEW ENGL J MED, V347, P1999, DOI 10.1056/NEJMoa021967; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Van't Veer LJ, 2002, NAT MED, V8, P13, DOI 10.1038/nm0102-13; Vielmetter J, 1997, GENOMICS, V41, P414, DOI 10.1006/geno.1997.4688; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	28	13	13	MARY ANN LIEBERT INC	NEW ROCHELLE	140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA	1066-5277		J COMPUT BIOL	J. Comput. Biol.	JUN	2005	12	5					534	544		10.1089/cmb.2005.12.534		11	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	938VQ	WOS:000230031900003	
J	Bshouty, NH; Jackson, JC; Tamon, C				Bshouty, NH; Jackson, JC; Tamon, C			Exploring learnability between exact and PAC	JOURNAL OF COMPUTER AND SYSTEM SCIENCES			English	Article; Proceedings Paper	15th Annual Conference on Computational Learning Theory	JUL 08-10, 2002	Sydney, AUSTRALIA			machine learning; computational learning theory; probably approximately correct learning; exact learning; parallel learning	CIRCUITS	We study a model of probably exactly correct (PExact) learning that can be viewed either as the Exact model (learning from equivalence queries only) relaxed so that counterexamples to equivalence queries are distributionally drawn rather than adversarially chosen or as the probably approximately correct (PAC) model strengthened to require a perfect hypothesis. We also introduce a model of probably almost exactly correct (PAExact) learning that requires a hypothesis with negligible error and thus lies between the PExact and PAC models. Unlike the Exact and PExact models, PAExact learning is applicable to classes of functions defined over infinite instance spaces. We obtain a number of separation results between these models. Of particular note are some positive results for efficient parallel learning in the PAExact model, which stand in stark contrast to earlier negative results for efficient parallel Exact learning. (c) 2004 Elsevier Inc. All rights reserved.	Clarkson Univ, Dept Math & Comp Sci, Sci Ctr 373, Potsdam, NY 13699 USA; Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel; Duquesne Univ, Dept Math & Comp Sci, Pittsburgh, PA 15219 USA	Tamon, C (reprint author), Clarkson Univ, Dept Math & Comp Sci, Sci Ctr 373, Box 5815, Potsdam, NY 13699 USA.	bshouty@cs.technion.ac.il; jackson@mathcs.duq.edu; tino@clarkson.edu					Angluin D., 1988, Machine Learning, V2, DOI 10.1007/BF00116828; ANGLUIN D, 1990, MACH LEARN, V5, P121, DOI 10.1023/A:1022692615781; Anthony M., 1992, COMPUTATIONAL LEARNI; BLUM AL, 1994, SIAM J COMPUT, V23, P990, DOI 10.1137/S009753979223455X; BLUMER A, 1987, INFORM PROCESS LETT, V24, P377, DOI 10.1016/0020-0190(87)90114-1; Bshouty NH, 1997, MACH LEARN, V26, P25, DOI 10.1023/A:1007320031970; Bshouty N. H., 2002, Proceedings 43rd Annual IEEE Symposium on Foundations of Computer Science, DOI 10.1109/SFCS.2002.1181893; Denis F, 2001, MACH LEARN, V44, P37, DOI 10.1023/A:1010826628977; Kearns MJ, 1994, INTRO COMPUTATIONAL; Krause M, 1997, THEOR COMPUT SCI, V174, P137, DOI 10.1016/S0304-3975(96)00019-9; LINIAL N, 1993, J ACM, V40, P607, DOI 10.1145/174130.174138; Littlestone N., 1988, Machine Learning, V2, DOI 10.1007/BF00116827; PAREKH R, 1999, P 16 INT C MACH LEAR, P298; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972	14	1	1	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0022-0000		J COMPUT SYST SCI	J. Comput. Syst. Sci.	JUN	2005	70	4			SI		471	484		10.1016/j.jcss.2004.10.002		14	Computer Science, Hardware & Architecture; Computer Science, Theory & Methods	Computer Science	928AM	WOS:000229243500003	
J	Vyugin, MV; V'yugin, VV				Vyugin, MV; V'yugin, VV			Predictive complexity and information	JOURNAL OF COMPUTER AND SYSTEM SCIENCES			English	Article; Proceedings Paper	15th Annual Conference on Computational Learning Theory	JUL 08-10, 2002	Sydney, AUSTRALIA			machine learning; algorithmic prediction; predictive complexity; predictive information; loss functions; Kolmogorov complexity; expanding property	EXPERT ADVICE	The notions of predictive complexity and of corresponding amount of information are considered. Predictive complexity is a generalization of Kolmogorov complexity which bounds the ability of any algorithm to predict elements of a sequence of outcomes. We consider predictive complexity for a wide class of bounded loss functions which are generalizations of square-loss function. Relations between unconditional KG(x) and conditional KG(x vertical bar y) predictive complexities are studied. We define an algorithm which has some "expanding property". It transforms with positive probability sequences of given predictive complexity into sequences of essentially bigger predictive complexity. A concept of amount of predictive information IG(y : x) is studied. We show that this information is noncommutative in a very strong sense and present asymptotic relations between values IG(y : x), IG(x : y), KG(x) and KG(y). (c) 2004 Elsevier Inc. All rights reserved.	Russian Acad Sci, Inst Informat Transmiss Problems, Moscow 101447, Russia; Univ London Royal Holloway & Bedford New Coll, Dept Comp Sci, Egham TW20 0EX, Surrey, England	V'yugin, VV (reprint author), Russian Acad Sci, Inst Informat Transmiss Problems, Bolshoi Karetnyi Per 19,GSP-4, Moscow 101447, Russia.	misha@cs.rhul.ac.uk; vyugin@iitp.ru					CesaBianchi N, 1997, J ACM, V44, P427, DOI 10.1145/258128.258179; CORMEN HT, 1990, INTRO ALGORITHMS; HAUSSLER D, 1994, UCSCCRL9436; Li M., 1997, INTRO KOLMOGOROV COM; Rogers H., 1967, THEORY RECURSIVE FUN; VITANYI P, 1995, LECT NOTES COMPUTER, V904, P69; Vovk V., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279947; Vovk V, 1998, J COMPUT SYST SCI, V56, P153, DOI 10.1006/jcss.1997.1556; Vovk V, 1999, COMPUT J, V42, P318, DOI 10.1093/comjnl/42.4.318; Vovk V. G., 1990, Proceedings of the Third Annual Workshop on Computational Learning Theory; VYUGIN MV, 2002, LECT NOTES ARTIF INT, V2375, P90; Vyugin MV, 2002, INFORM COMPUT, V178, P241, DOI 10.1006/inco.2002.3164; V'yugin VV, 2002, THEOR COMPUT SCI, V276, P407, DOI 10.1016/S0304-3975(01)00122-0; Yamanishi K., 1995, Proceedings of the Eighth Annual Conference on Computational Learning Theory, DOI 10.1145/225298.225308; Zvonkin A. K., 1970, RUSS MATH SURV, V25, P83, DOI 10.1070/RM1970v025n06ABEH001269	15	0	0	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0022-0000		J COMPUT SYST SCI	J. Comput. Syst. Sci.	JUN	2005	70	4			SI		539	554		10.1016/j.jcss.2004.10.005		16	Computer Science, Hardware & Architecture; Computer Science, Theory & Methods	Computer Science	928AM	WOS:000229243500006	
J	Du, CJ; Sun, DW				Du, CJ; Sun, DW			Comparison of three methods for classification of pizza topping using different colour space transformations	JOURNAL OF FOOD ENGINEERING			English	Article						classification; colour; computer vision; decision tree; machine learning; neural network; pizza topping; support vector machine; SVM	COMPUTER VISION; QUALITY INSPECTION; NEURAL-NETWORKS; MACHINE VISION; ALGORITHM; SEGMENTATION; PRODUCTS; IMAGES; SYSTEM	Five transformations of RGB (red, green, and blue) colour space were evaluated for their performance in classifying pizza toppings, i.e., NRGB (normalised RGB), HSV (hue, saturation, and value), I1I2I3, L*a*b*, and YCbCr. Using these five colour space transformations, the performance of three SVM (support vector machine) classifiers (linear, polynomial, and RBF) on pizza topping classification was compared with two classical classification approaches, i.e., C4.5 classifier and an RBF_NN (radial basis function neural network) classifier. The C4.5 classifier obtained the best classification accuracy of 93.3% with L*a*b* or I1I2I3 colour space transformation, and the RBF_NN classifier achieved the best classification accuracy of 86.7% with YCbCr, HSV or L*a*b* colour space transformation. For the SVM classifiers, the polynomial SVM classifier had the best classification accuracy of 96.7% with HSV colour space transformation, while the radial basis function (RBF) SVM classifier obtained the best classification accuracy of 90.0% with YCbCr, L*a*b* or HSV colour space transformation. Among the SVM classifiers, the polynomial SVM classifier combined with HSV colour space transformation proved to be a good approach for the classification of pizza toppings using computer vision. (C) 2004 Elsevier Ltd. All rights reserved.	Natl Univ Ireland Univ Coll Dublin, Dept Biosyst Engn, FRCFT Grp, Dublin 2, Ireland	Sun, DW (reprint author), Natl Univ Ireland Univ Coll Dublin, Dept Biosyst Engn, FRCFT Grp, Earlsfort Terrace, Dublin 2, Ireland.	dawen.sun@ucd.ie	Sun, Da-Wen/B-1899-2012				Abdullah MZ, 2000, J FOOD QUALITY, V23, P39, DOI 10.1111/j.1745-4557.2000.tb00194.x; Ahmad IS, 1999, PLANT DIS, V83, P320, DOI 10.1094/PDIS.1999.83.4.320; Albert A., 1972, REGRESSION MOORE PEN; Bishop C.M., 1995, NEURAL NETWORKS PATT; Brosnan T, 2004, J FOOD ENG, V61, P3, DOI 10.1016/S0260-8774(03)00183-3; CASADY WW, 1992, T ASAE, V35, P2027; Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616; Kavdir I, 2002, T ASAE, V45, P1995; MCQUEEN RJ, 1995, COMPUT ELECTRON AGR, V12, P275, DOI 10.1016/0168-1699(95)98601-9; MILLER BK, 1989, T ASAE, V32, P1484; Mitchell RS, 1996, COMPUT ELECTRON AGR, V15, P195, DOI 10.1016/0168-1699(96)00016-6; Nakano K, 1997, COMPUT ELECTRON AGR, V18, P105, DOI 10.1016/S0168-1699(97)00023-9; OHTA Y, 1980, COMPUT VISION GRAPH, V13, P222, DOI 10.1016/0146-664X(80)90047-7; PARDO M, 2002, P 8 INT S CHEM AN CH; Park B, 2000, J FOOD PROCESS ENG, V23, P329, DOI 10.1111/j.1745-4530.2000.tb00519.x; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; ROMANIUK M, 1993, ASAE INT WINT M CHIC; Rousu J, 2003, J FOOD ENG, V57, P45, DOI 10.1016/S0260-8774(02)00221-2; RYAN R, 2002, THESIS MASSACHUSETTS; Shahin MA, 2002, T ASAE, V45, P1613; SHEARER SA, 1990, T ASAE, V33, P2045; Sun DW, 2003, J FOOD ENG, V57, P81, DOI 10.1016/S0260-8774(02)00275-3; Sun DW, 2004, J FOOD ENG, V61, P17, DOI 10.1016/S0260-8774(03)00184-5; Sun DW, 2000, J FOOD ENG, V44, P245, DOI 10.1016/S0260-8774(00)00024-8; Sun DW, 2003, J FOOD ENG, V57, P91, DOI 10.1016/S0260-8774(02)00276-5; Sun DW, 2004, J FOOD ENG, V61, P1, DOI 10.1016/S0260-8774(03)00182-1; Vapnik V. N, 1995, NATURE STAT LEARNING; Vizhanyo T, 2000, COMPUT ELECTRON AGR, V26, P187, DOI 10.1016/S0168-1699(00)00071-5; Wang HH, 2003, J FOOD ENG, V56, P339, DOI 10.1016/S0260-8774(02)00159-0; [Anonymous], 2001, MATL US GUID; *CIE, 1931, P 8 SESS CAMBR ENGL	31	33	34	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0260-8774		J FOOD ENG	J. Food Eng.	JUN	2005	68	3					277	287		10.1016/j.jfoodeng.2004.05.044		11	Engineering, Chemical; Food Science & Technology	Engineering; Food Science & Technology	903EO	WOS:000227408500001	
J	Minowa, Y				Minowa, Y			Classification rules discovery from selected trees for thinning with the C4.5 machine learning system	JOURNAL OF FOREST RESEARCH			English	Article						decision trees; gain ratio criterion; production rules; machine learning; neural network	ARTIFICIAL NEURAL NETWORKS; FRACTAL GEOMETRY; FOREST; LOGIC	To use heuristic information efficiently, it is necessary to develop a knowledge-based system and to digitize acquired knowledge. The purpose of this article is to discover classification rules from selected trees for thinning with a machine learning system, C4.5, and to compare these to results from a neural network model. An algorithm used for information entropy, the gain ratio criterion, was used in order to induce decision trees and production rules. The number of samples used was 503 and two kinds of thinning types were used: binary case and four cases. The rate of accurate classification when trees were classified into four thinning types was about 63%-78%. In the case of a binary decision, whose output was "thinned" or "unthinned," about 88%-97% of its answers were correct. The C4.5 machine learning system can be constructed from 10 to 20 rules, in comparison with the large data sample in this study. Where only estimation accuracy for unseen cases was compared, estimation accuracy of the neural network was superior to that of C4.5 for each thinning type. However, C4.5 has an advantage in that the rules are shown as linguistic information such as if-then type rules, which people can easily comprehend and use.	Kyoto Prefectural Univ, Grad Sch Agr, Sakyo Ku, Kyoto 6068522, Japan	Minowa, Y (reprint author), Kyoto Prefectural Univ, Grad Sch Agr, Sakyo Ku, 1-5 Shimogamo-Hangi Cho, Kyoto 6068522, Japan.	sharmy@uf.kpu.ac.jp					AISAKA K, 2000, IEICE I ELEC INFO CO, V23, P273, DOI UNSP J83-D-I; BARE BB, 1992, CAN J FOREST RES, V22, P423, DOI 10.1139/x92-055; Boreux JJ, 1998, CAN J FOREST RES, V28, P1249, DOI 10.1139/cjfr-28-8-1249; BREN LJ, 1995, FOREST ECOL MANAG, V75, P1, DOI 10.1016/0378-1127(95)03553-M; CHEN SG, 1994, FOREST ECOL MANAG, V69, P97, DOI 10.1016/0378-1127(94)90222-4; COOK DF, 1991, FOREST SCI, V37, P1463; Drake JB, 2000, FOREST ECOL MANAG, V128, P121, DOI 10.1016/S0378-1127(99)00279-0; Duda R. O., 2001, PATTERN CLASSIFICATI; Estevez PA, 2003, FOREST PROD J, V53, P87; Fisher DS, 2000, FOREST ECOL MANAG, V128, P39, DOI 10.1016/S0378-1127(99)00270-4; GUAN BT, 1991, FOREST SCI, V37, P1429; HAYASHI Y, 1989, P 5 FUZZ SYST S KOB, P169; ISHII M, 1997, I ELEC INFO COMM ENG, V1, P237, DOI UNSP J80-D-2; Kivinen VP, 2002, FOREST SCI, V48, P673; Liu CM, 2003, FOREST SCI, V49, P619; LOWELL K, 1994, CAN J FOREST RES, V24, P1970, DOI 10.1139/x94-252; Magnussen S, 1996, FOREST SCI, V42, P76; Marsden SJ, 2002, FOREST ECOL MANAG, V165, P117, DOI 10.1016/S0378-1127(01)00653-3; Minowa Y, 2001, J FOR RES, V6, P95, DOI [10.1007/BF02762494, DOI 10.1007/BF02762494]; Minowa Y., 1999, Journal of the Japanese Forestry Society, V81, P130; Minowa Y., 1997, Journal of the Japanese Forestry Society, V79, P143; Mizoue N, 2003, FOREST ECOL MANAG, V172, P79, DOI 10.1016/S0378-1127(02)00281-5; Mizoue N., 1994, Journal of the Japanese Forestry Society, V76, P242; MORI Y, 2003, I ELEC INFO COMM ENG, V8, P1166, DOI UNSP J86-D-2; Nordmark U, 2002, SCAND J FOREST RES, V17, P72, DOI 10.1080/028275802317221109; OOTAKI A, 1998, APPL TREE BASED METH; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Reynolds KM, 2003, FOREST POLICY ECON, V5, P433, DOI 10.1016/S1389-9341(03)00041-8; Sandak J, 2003, FOREST PROD J, V53, P36; TASAKA T, 2001, B UTSUNOMIYA U FOR, V37, P177; WARNER WS, 1990, FOREST ECOL MANAG, V31, P101, DOI 10.1016/0378-1127(90)90115-R; Yamasaki H., 1996, Journal of the Japanese Forestry Society, V78, P143; YAMASHIRO M, 1997, I ELEC INFO COMM ENG, V8, P2248, DOI UNSP J80-D-2; ZEIDE B, 1991, FOREST ECOL MANAG, V46, P179, DOI 10.1016/0378-1127(91)90230-S; Zhang QB, 2000, FOREST SCI, V46, P229	35	1	1	SPRINGER TOKYO	TOKYO	3-3-13, HONGO, BUNKYO-KU, TOKYO, 113-0033, JAPAN	1341-6979		J FOR RES-JPN	J. For. Res.	JUN	2005	10	3					221	231		10.1007/s10310-004-0134-7		11	Forestry	Forestry	940IA	WOS:000230135700008	
J	Krstacic, A; Gamberger, D; Krstacic, G; Car, Z				Krstacic, A; Gamberger, D; Krstacic, G; Car, Z			Risk factors analysis by inductive machine learning in stroke patients	JOURNAL OF NEUROLOGY			English	Meeting Abstract	15th Meeting of the European-Neurological-Society	JUN 18-22, 2005	Vienna, AUSTRIA	European Neurol Soc					Univ Zagreb, Univ Clin Traumatol, Zagreb, Croatia; Rudjer Boskovic Inst, Zagreb, Croatia; Univ Zagreb, Inst Cardiovasc Res, Zagreb, Croatia; Univ Zagreb, Univ Hosp Ctr Zagreb, Zagreb, Croatia			Gamberger, Dragan/J-3752-2012					0	0	0	DR DIETRICH STEINKOPFF VERLAG	HEIDELBERG	TIERGARTENSTRASSE 17, 69121 HEIDELBERG, GERMANY	0340-5354		J NEUROL	J. Neurol.	JUN	2005	252			2			96	97				2	Clinical Neurology	Neurosciences & Neurology	937QV	WOS:000229941500359	
J	El Naqa, I; Clark, V; Bradley, J; Deasy, J				El Naqa, I; Clark, V; Bradley, J; Deasy, J			Machine learning methods for radiobiological outcomes modeling	MEDICAL PHYSICS			English	Meeting Abstract	47th Annual Meeting of the American-Association-of-Physicists-in-Medicine	JUL 24-28, 2005	Seattle, WA	Amer Assoc Physicists Med					Washington Univ, St Louis, MO USA								0	0	0	AMER ASSOC PHYSICISTS MEDICINE AMER INST PHYSICS	MELVILLE	STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA	0094-2405		MED PHYS	Med. Phys.	JUN	2005	32	6					2037	2037		10.1118/1.1998104		1	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	937EY	WOS:000229908601087	
J	Lu, R; Radke, R; Hong, L; Chui, C; Xiong, J; Yorke, E; Jackson, A				Lu, R; Radke, R; Hong, L; Chui, C; Xiong, J; Yorke, E; Jackson, A			Machine learning for the geometry/intensity relationship in IMRT	MEDICAL PHYSICS			English	Meeting Abstract	47th Annual Meeting of the American-Association-of-Physicists-in-Medicine	JUL 24-28, 2005	Seattle, WA	Amer Assoc Physicists Med					Rensselaer Polytech Inst, Troy, NY USA; Mem Sloan Kettering Canc Ctr, New York, NY 10021 USA								0	0	0	AMER ASSOC PHYSICISTS MEDICINE AMER INST PHYSICS	MELVILLE	STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA	0094-2405		MED PHYS	Med. Phys.	JUN	2005	32	6					2140	2140		10.1118/1.1998578		1	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	937EY	WOS:000229908601483	
J	Jeong, KH; Xu, JW; Erdogmus, D; Principe, JC				Jeong, KH; Xu, JW; Erdogmus, D; Principe, JC			A new classifier based on information theoretic learning with unlabeled data	NEURAL NETWORKS			English	Article; Proceedings Paper	International Joint Conference on Neural Networks	JUL 31-AUG 04, 2005	Montreal, CANADA	IEEE Computat Intelligence Soc, Int Neural Networks Soc		adaptive system; unlabeled data; classification; information theoretic learning; (ITL)		Supervised learning is conventionally performed with pairwise input-output labeled data. After the training procedure, the adaptive system's weights are fixed while the testing procedure with unlabeled data is performed. Recently, in an attempt to improve classification performance unlabeled data has been exploited in the machine learning community. In this paper, we present an information theoretic learning (ITL) approach based on density divergence minimization to obtain an extended training algorithm using unlabeled data during the testing. The method uses a boosting-like algorithm with an ITL based cost function. Preliminary simulations suggest that the method has the potential to improve the performance of classifiers in the application phase. (c) 2005 Elsevier Ltd. All rights reserved.	Univ Florida, Dept Elect & Comp Engn, Computat NeuroEngn Lab, Gainesville, FL 32611 USA; OHSU, Oregon Grad Inst, Portland, OR 97006 USA	Jeong, KH (reprint author), Univ Florida, Dept Elect & Comp Engn, Computat NeuroEngn Lab, Gainesville, FL 32611 USA.	khjeong@cnel.ufl.edu; jianwu@cnel.ufl.edu; derdogmus@ieee.org; principe@cnel.ufl.edu	Erdogmus, Deniz/A-8170-2009; Xu, Jianwu/C-6090-2012				BELKIN M, 2004, TR200406 DEP COMP U; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; Cristianini N., 2000, INTRO SUPPORT VECTOR; Erdogmus D, 2003, IEEE SIGNAL PROC LET, V10, P242, DOI 10.1109/LSP.2003.814400; ERDOGMUS D, 2005, P INT C ACC SPEECH S; Gammerman A., 1998, P 14 C UNC ART INT M, P148; Haykin S., 1999, NEURAL NETWORKS COMP; JEONG KH, 2005, P INT JOINT C NEUR N; Naftaly U, 1997, NETWORK-COMP NEURAL, V8, P283, DOI 10.1088/0954-898X/8/3/004; NIGRAM K, 2000, MACH LEARN, V39, P103; NOVAK B, 2004, P C DAT MIN WAR, P834; Parzen E, 1962, ANN MATH STAT; PRINCIPE JC, 2000, UNSUPERVISED ADAPTIV, V1, P265; SANCHEZ J, 2005, P C 2 INT IEEE WORKS; SAUNDERS C., 1999, P 16 INT JOINT C ART; Widrow B., 1985, ADAPTIVE SIGNAL PROC	16	4	4	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080		NEURAL NETWORKS	Neural Netw.	JUN-JUL	2005	18	5-6					719	726		10.1016/j.neunet.2005.06.018		8	Computer Science, Artificial Intelligence	Computer Science	967MY	WOS:000232096500031	
J	Zorkadis, V; Karras, DA; Panayotou, M				Zorkadis, V; Karras, DA; Panayotou, M			Efficient information theoretic strategies for classifier combination, feature extraction and performance evaluation in improving false positives and false negatives for spam e-mail filtering	NEURAL NETWORKS			English	Article; Proceedings Paper	International Joint Conference on Neural Networks	JUL 31-AUG 04, 2005	Montreal, CANADA	IEEE Computat Intelligence Soc, Int Neural Networks Soc		privacy-enhancing technology; anti-spam filter; classifier combination; information theoretic feature extraction; classification equivocation; committee machines; Bayesian e-mail filter; boosting trees		Spam emails are considered as a serious privacy-related violation, besides being a costly, unsolicited communication. Various spam filtering techniques have been so far proposed, mainly based on Naive Bayesian algorithms. Other Machine Learning algorithms like Boosting trees, or Support Vector Machines (SVM) have already been used with success. However, the number of False Positives (FP) and False Negatives (FN) resulting through applying various spam e-mail filters still remains too high and the problem of spam e-mail categorization cannot be solved completely from a practical viewpoint. In this paper, we propose a novel approach for spam e-mail filtering based on efficient information theoretic techniques for integrating classifiers, for extracting improved features and for properly evaluating categorization accuracy in terms of FP and FN. The goal of the presented methodology is to empirically but explicitly minimize these FP and FN numbers by combining high-performance FP filters with high-performance FN filters emerging from a previous work of the authors [Zorkadis, V., Panayotou, M., & Karras, D. A. (2005). Improved spam e-mail filtering based on committee machines and information theoretic feature extraction. Proceedings of the International Joint Conference on Neural Networks, July 31-August 4, 2005, Montreal, Canada].(1) To this end, Random Committee-based filters along with ADTree-based ones are efficiently combined through information theory, respectively. The experiments conducted are of the most extensive ones so far in the literature, exploiting widely accepted benchmarking e-mail data sets and comparing the proposed methodology with the Naive Bayes spam filter as well as with the Boosting tree methodology, the classification via regression and other machine learning models. It is illustrated by means of novel information theoretic measures of FP & FN filtering performance that the proposed approach is very favorably compared to the other rival methods. Finally, it is found that the proposed information theoretic Boolean features present a remarkably high sparn categorization performance. (c) 2005 Elsevier Ltd. All rights reserved.	Data Protect Author & Hellen Open Univ, Athens, Greece; Chalkis Inst Technol, Dept Automat, Athens 16342, Greece; Hellen Open Univ, Chalkis Inst Technol, Athens 16342, Greece	Karras, DA (reprint author), Data Protect Author & Hellen Open Univ, Athens, Greece.	zorkadis@dpa.gr; dakarras@teihal.gr; dakarras@ieee.org					Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; CARRERAS X, 2001, P RANLP 01 4 INT C R; Cover T. M., 1991, ELEMENTS INFORMATION; DRUCKER H, 1999, IEEE T NEURAL NETWOR, P10; Elkan C., 1997, CS97557 U CAL DEP CO; Frank E, 1998, MACH LEARN, V32, P63, DOI 10.1023/A:1007421302149; Freund Y., 1999, P 16 INT C MACH LEAR, P124; KAPLAN S, 2003, WIRED MAGAZINE, P43; PORTER MF, 2003, ALGORITHM SUFFIX STR; Tresp V., 2001, HDB NEURAL NETWORK S; TRETYAKOV K, 2004, MACHINE LEARNING TEC, V3, P60; VAUGHANNICHOLS SJ, 2003, IEEE SPECTRUM MAGAZI, P40; ZORKADIS V, 2005, P INT JOINT C NEUR N	13	14	19	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080		NEURAL NETWORKS	Neural Netw.	JUN-JUL	2005	18	5-6					799	807		10.1016/j.neunet.2005.06.045		9	Computer Science, Artificial Intelligence	Computer Science	967MY	WOS:000232096500040	
J	Yong, X; Feng, D; Rongchun, Z; Petrou, M				Yong, X; Feng, D; Rongchun, Z; Petrou, M			Learning-based algorithm selection for image segmentation	PATTERN RECOGNITION LETTERS			English	Article						image segmentation; segmentation evaluation; machine learning; support vector machine	SYSTEM; CLASSIFICATION	Segmentation of nontrivial images is one of the most important tasks in image processing. It is easy for human being, but extremely difficult for computers. With the purpose of finding optimal segmentation algorithm for every image through learning from human experience, this paper investigates the manual segmentation process and thus presents a performance prediction based algorithm selection model to bridge the knowledge gap between images and segmentation algorithms. Derived from that model, a framework of learning-based algorithm selection system is proposed to automatically segment all images in a large database. A simulation system is designed to select the optimal segmentation algorithm from four candidates for synthetic images. The system is tested on 9000 images by comparing with the manual algorithm selection. The best algorithms are selected for 85% of the cases. If we also regard the second best algorithm as acceptable, more than 97% of images can be properly segmented. The satisfied result demonstrated that this study has provided a promising approach to achieve automated image segmentation. &COPY; 2004 Elsevier B.V. All rights reserved.	Hong Kong Polytech Univ, Dept Elect & Informat Engn, Ctr Multimedia Signal Proc, Hong Kong, Hong Kong, Peoples R China; Northwestern Polytech Univ, Sch Comp, Xian 710072, Peoples R China; Univ Sydney, Sch Informat Technol, Sydney, NSW 2006, Australia; Univ Surrey, Sch Elect Comp & Math, Guildford GU2 5XH, Surrey, England	Yong, X (reprint author), Northwestern Polytech Univ, Sch Comp, Dept Comp Informat & Engn, POB 756, Xian 710072, Peoples R China.	yxia@it.usyd.edu.au	Xia, Yong/C-6567-2008				FRACIS HY, 1998, IEEE T IMAGE PROCESS, V7, P468; FU KS, 1981, PATTERN RECOGN, V13, P3, DOI 10.1016/0031-3203(81)90028-5; Gevers T, 2002, IEEE T PATTERN ANAL, V24, P848, DOI 10.1109/TPAMI.2002.1008391; Guo GD, 2003, IEEE T NEURAL NETWOR, V14, P209, DOI 10.1109/TNN.2002.806626; HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7; Jackson JE, 1991, WILEY SERIES PROBABI; KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2; KITCHEN L, 1981, IEEE T SYST MAN CYB, V11, P597, DOI 10.1109/TSMC.1981.4308758; KITTLER J, 1985, IEEE T SYST MAN CYB, V15, P652; Kohonen T., 1995, SELF ORG MAPS; LI X, 1988, P IEEE INT C SYST MA, V1, P652; MACLEOD JES, 1987, IEEE T SYST MAN CYB, V17, P689, DOI 10.1109/TSMC.1987.289362; MATSUYAMA T, 1989, COMPUT VISION GRAPH, V48, P22, DOI 10.1016/0734-189X(89)90103-5; Mitchell T, 1997, MACHINE LEARNING; More J., 1977, LECT NOTES MATH, V630; MUSSA AW, 1992, P INT C IM PROC ITS, P167; NAZIF AM, 1984, IEEE T PATTERN ANAL, V6, P555; Olabarriaga SD, 2001, MED IMAGE ANAL, V5, P127, DOI 10.1016/S1361-8415(00)00041-4; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62; Pal NR, 1993, PATTERN RECOGN, V26, P1227; Peng J, 1998, IEEE T PATTERN ANAL, V20, P139; Perner P, 1999, ENG APPL ARTIF INTEL, V12, P749, DOI 10.1016/S0952-1976(99)00038-X; REYNOLDS RG, 1995, P IEEE INT C EV COMP, V2, P819, DOI 10.1109/ICEC.1995.487492; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; SAHOO PK, 1988, COMPUT VIS GRAPH IMA, V41, P232; Udupa JK, 1997, IEEE T MED IMAGING, V16, P598, DOI 10.1109/42.640750; Vapnic V., 1995, NATURE STAT LEARNING; WESZKA JS, 1974, IEEE T COMPUT, VC 23, P1322, DOI 10.1109/T-C.1974.223858; XIA Y, 2002, CHINESE J STEREOLOGY, V7, P235; Yang YB, 2000, PATTERN RECOGN, V33, P787, DOI 10.1016/S0031-3203(99)00094-1; Zhang MR, 2002, IEEE T SYST MAN CY B, V32, P571, DOI 10.1109/TSMCB.2002.1033177; Zhang XP, 2001, IEEE T IMAGE PROCESS, V10, P1020, DOI 10.1109/83.931096; Zhang YJ, 2000, OPT ENG, V39, P1450, DOI 10.1117/1.602517; ZHANG YJ, 1992, P EUROSCO 92, V1, P551; Zhang Yan-ning, 2002, Acta Electronica Sinica, V30	35	4	4	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	JUN	2005	26	8					1059	1068		10.1016/j.patrec.2004.09.049		10	Computer Science, Artificial Intelligence	Computer Science	926NW	WOS:000229130900004	
J	Huang, SW; Hwang, JK				Huang, SW; Hwang, JK			Computation of conformational entropy from protein sequences using the machine-learning method - Application to the study of the relationship between structural conservation and local structural stability	PROTEINS-STRUCTURE FUNCTION AND BIOINFORMATICS			English	Article						structural conservation; sequence structural entropy; structural profile; support vector machines; hydrogen exchange	SUPPORT VECTOR MACHINES; SECONDARY STRUCTURE PREDICTION; STATE HYDROGEN-EXCHANGE; FOLDING PATHWAY; CHYMOTRYPSIN INHIBITOR-2; SUBCELLULAR-LOCALIZATION; STRUCTURE ASSIGNMENT; MATHEMATICAL-THEORY; CYTOCHROME-C; FUNNELS	A complete protein sequence can usually determine a unique conformation; however, the situation is different for shorter subsequences-some of them are able to adopt unique conformations, independent of context; while others assume diverse conformations in different contexts. The conformations of subsequences are determined by the interplay between local and nonlocal interactions. A quantitative measure of such structural conservation or variability will be useful in the understanding of the sequence-structure relationship. In this report, we developed an approach using the support vector machine method to compute the conformational. variability directly from sequences, which is referred to as the sequence structural entropy. As a practical application, we studied the relationship between sequence structural entropy and the hydrogen exchange for a set of well-studied proteins. We found that the slowest exchange cores usually comprise amino acids of the lowest sequence structural entropy. Our results indicate that structural conservation is closely related to the local structural stability. This relationship may have interesting implications in the protein folding processes, and may be useful in the study of the sequence-structure relationship. (c) 2005 Wiley-Liss, Inc.	Natl Chiao Tung Univ, Dept Biol Sci & Technol, Hsinchu 30050, Taiwan; Natl Chiao Tung Univ, Inst Bioinformat, Hsinchu 30050, Taiwan	Hwang, JK (reprint author), Natl Chiao Tung Univ, Dept Biol Sci & Technol, Hsinchu 30050, Taiwan.	jkhwang@cc.nctu.edu.tw					Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Andersen Claus A F, 2003, Methods Biochem Anal, V44, P341; Anderson D. E., 1993, NMR PROTEINS, P258; BAI YW, 1995, SCIENCE, V269, P192, DOI 10.1126/science.7618079; Bai YW, 1996, PROTEINS, V24, P145, DOI 10.1002/(SICI)1097-0134(199602)24:2<145::AID-PROT1>3.0.CO;2-I; Bairoch A, 2000, NUCLEIC ACIDS RES, V28, P45, DOI 10.1093/nar/28.1.45; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Betz SF, 1996, BIOCHEMISTRY-US, V35, P7422, DOI 10.1021/bi9528558; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; BRYNGELSON JD, 1995, PROTEINS, V21, P167, DOI 10.1002/prot.340210302; Chan CH, 2004, PROTEINS, V57, P684, DOI 10.1002/prot.20263; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Chen YC, 2004, PROTEINS, V55, P1036, DOI 10.1002/prot.20079; Clarke J, 1998, CURR OPIN STRUC BIOL, V8, P112, DOI 10.1016/S0959-440X(98)80018-3; Ding CHQ, 2001, BIOINFORMATICS, V17, P349, DOI 10.1093/bioinformatics/17.4.349; Dobson PD, 2003, J MOL BIOL, V330, P771, DOI 10.1016/S0022-2836(03)00628-4; Duan K, 2003, NEUROCOMPUTING, V51, P41, DOI 10.1016/S0925-2312(02)00601-X; Frishman D, 1995, PROTEINS, V23, P566, DOI 10.1002/prot.340230412; Heinig M, 2004, NUCLEIC ACIDS RES, V32, pW500, DOI 10.1093/nar/gkh429; Hespenheide BM, 2002, J MOL GRAPH MODEL, V21, P195, DOI 10.1016/S1093-3263(02)00146-8; Hilser VJ, 1996, J MOL BIOL, V262, P756, DOI 10.1006/jmbi.1996.0550; Hoang L, 2002, P NATL ACAD SCI USA, V99, P12173, DOI 10.1073/pnas.152439199; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Hua SJ, 2001, J MOL BIOL, V308, P397, DOI 10.1006/jmbi.2001.4580; Itzhaki LS, 1997, J MOL BIOL, V270, P89, DOI 10.1006/jmbi.1997.1049; JENG MF, 1990, BIOCHEMISTRY-US, V29, P10433, DOI 10.1021/bi00498a001; KABSCH W, 1984, P NATL ACAD SCI-BIOL, V81, P1075, DOI 10.1073/pnas.81.4.1075; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; Kim H, 2003, PROTEIN ENG, V16, P553, DOI 10.1093/protein/gzg072; Kim H, 2004, PROTEINS, V54, P557, DOI 10.1002/prot.10602; KRAULIS PJ, 1991, J APPL CRYSTALLOGR, V24, P946, DOI 10.1107/S0021889891004399; LEOPOLD PE, 1992, P NATL ACAD SCI USA, V89, P8721, DOI 10.1073/pnas.89.18.8721; Li RH, 1999, PROTEIN SCI, V8, P1571; MATOUSCHEK A, 1992, J MOL BIOL, V224, P837, DOI 10.1016/0022-2836(92)90565-2; Mezei M, 1998, PROTEIN ENG, V11, P411, DOI 10.1093/protein/11.6.411; Minor DL, 1996, NATURE, V380, P730, DOI 10.1038/380730a0; Mullins LS, 1997, PROTEIN SCI, V6, P1387; Neira JL, 1997, J MOL BIOL, V270, P99, DOI 10.1006/jmbi.1997.1088; Onuchic JN, 2004, CURR OPIN STRUC BIOL, V14, P70, DOI 10.1016/j.sbi.2004.01.009; OTZEN DE, 1994, P NATL ACAD SCI USA, V91, P10422, DOI 10.1073/pnas.91.22.10422; PERRETT S, 1995, BIOCHEMISTRY-US, V34, P9288, DOI 10.1021/bi00029a003; RADFORD SE, 1992, PROTEINS, V14, P237, DOI 10.1002/prot.340140210; RICHARDS FM, 1988, PROTEINS, V3, P71, DOI 10.1002/prot.340030202; ROSE GD, PROSS DIHEDRAL ANGLE; ROST B, 1993, J MOL BIOL, V232, P584, DOI 10.1006/jmbi.1993.1413; SHANNON CE, 1948, AT&T TECH J, V27, P379; SHANNON CE, 1948, AT&T TECH J, V27, P623; Shoemaker BA, 1997, P NATL ACAD SCI USA, V94, P777, DOI 10.1073/pnas.94.3.777; Sivaraman T, 1998, J BIOL CHEM, V273, P10181, DOI 10.1074/jbc.273.17.10181; SKLENAR H, 1989, PROTEINS, V6, P46, DOI 10.1002/prot.340060105; Sudarsanam S, 1998, PROTEINS, V30, P228, DOI 10.1002/(SICI)1097-0134(19980215)30:3<228::AID-PROT2>3.0.CO;2-G; Vapnik V. N., 1995, NATURE STATE LEARNIN; Ward JJ, 2003, BIOINFORMATICS, V19, P1650, DOI 10.1093/bioinformatics/btg223; Woodward C, 1998, TRENDS BIOCHEM SCI, V23, P379, DOI 10.1016/S0968-0004(98)01282-1; WOODWARD CK, 1980, BIOPHYS J, V32, P561; Yamasaki K, 1995, BIOCHEMISTRY-US, V34, P16552, DOI 10.1021/bi00051a003; Yu CS, 2004, PROTEIN SCI, V13, P1402, DOI 10.1110/ps.03479604; Yu CS, 2003, PROTEINS, V50, P531, DOI 10.1002/prot.10313	58	6	6	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0887-3585		PROTEINS	Proteins	JUN 1	2005	59	4					802	809		10.1002/prot.20462		8	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	927UR	WOS:000229226500014	
J	Kao, B; Katriel, R				Kao, B; Katriel, R			Subsampled model aggregation	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS			English	Article						machine learning; ensemble learning; subsampling		There has been a recent push for a new framework of learning, due in part to the availability of storage, networking and the abundance of very large datasets. This framework argues for parallelized learning algorithms that can operate on a distributed platform and have the ability to terminate early in the likely event that data size is too inundating. Methods described herein propose a subsampled model aggregation technique based on the bagging algorithm. It is capable of significant run-time reduction with no loss in modeling performance. These claims were validated with a variety of base-learning algorithms on large web and newswire datasets.	Acquire Media Corp, Roseland, NJ 07068 USA	Kao, B (reprint author), Acquire Media Corp, 3 Becker Farm,Suite 204, Roseland, NJ 07068 USA.						AGRAWAL D, 2001, S PRINC DAT SYST; BERRY MW, 1995, UTCS95271 U TENN DEP; Berry MW, 1995, SIAM REV, V37, P573, DOI 10.1137/1037127; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Duda R., 2000, PATTERN CLASSIFICATI; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; HAISTEN M, 2002, DATA WAREHOUSING WHA; KACHITES A, 1996, TOOLKIT STAT LANGUAG; KAO B, 1999, DISTRIBUTED LEARNING; KATRIEL RG, 2001, SCALABLE REAL TIME S; KEARNS M, 1990, COMPUTATIONAL COMPLE; Lazarevic A., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; MOSTELLER F, 1964, INFERENCE DISPUTED A; Papadimitriou C. H., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, DOI 10.1145/275487.275505; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; Rennieyz J., 1999, P 16 INT C MACH LEAR, P335; Schapire R. E., 1997, P 14 INT C MACH LEAR, P322; YANG Y, 1993, P 16 ANN INT ACM SIG, P281, DOI 10.1145/160688.160738	19	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-2130		INT J ARTIF INTELL T	Int. J. Artif. Intell. Tools	JUN	2005	14	3					385	397		10.1142/S0218213005002168		13	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	986SC	WOS:000233469000002	
J	Krallinger, M; Padron, M; Valencia, A				Krallinger, M; Padron, M; Valencia, A			A sentence sliding window approach to extract protein annotations from biomedical articles	BMC BIOINFORMATICS			English	Article							GENE ONTOLOGY; TEXT	Background: Within the emerging field of text mining and statistical natural language processing (NLP) applied to biomedical articles, a broad variety of techniques have been developed during the past years. Nevertheless, there is still a great ned of comparative assessment of the performance of the proposed methods and the development of common evaluation criteria. This issue was addressed by the Critical Assessment of Text Mining Methods in Molecular Biology (BioCreative) contest. The aim of this contest was to assess the performance of text mining systems applied to biomedical texts including tools which recognize named entities such as genes and proteins, and tools which automatically extract protein annotations. Results: The "sentence sliding window" approach proposed here was found to efficiently extract text fragments from full text articles containing annotations on proteins, providing the highest number of correctly predicted annotations. Moreover, the number of correct extractions of individual entities (i.e. proteins and GO terms) involved in the relationships used for the annotations was significantly higher than the correct extractions of the complete annotations (protein-function relations). Conclusion: We explored the use of averaging sentence sliding windows for information extraction, especially in a context where conventional training data is unavailable. The combination of our approach with more refined statistical estimators and machine learning techniques might be a way to improve annotation extraction for future biomedical text mining applications.	CSIC, CNB, Natl Biotechnol Ctr, Prot Design Grp, E-28049 Madrid, Spain	Krallinger, M (reprint author), CSIC, CNB, Natl Biotechnol Ctr, Prot Design Grp, E-28049 Madrid, Spain.	martink@cnb.uam.es; mpadron@cnb.uam.es; valencia@cnb.uam.es					Andrade MA, 1998, BIOINFORMATICS, V14, P600, DOI 10.1093/bioinformatics/14.7.600; Blaschke C, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S1-S16; Blaschke C, 1999, Proc Int Conf Intell Syst Mol Biol, P60; Boeckmann B, 2003, NUCLEIC ACIDS RES, V31, P365, DOI 10.1093/nar/gkg095; Camon E., 2004, NUCLEIC ACIDS RES, V32, P262; Camon EB, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S1-S17; Chang J T, 2001, Pac Symp Biocomput, P374; Chaussabel D, 2002, GENOME BIOL, V3; Chiang JH, 2003, BIOINFORMATICS, V19, P1417, DOI 10.1093/bioinformatics/btg160; Datar M, 2002, SIAM PROC S, P635; Devos D, 2001, TRENDS GENET, V17, P429, DOI 10.1016/S0168-9525(01)02348-4; Devos D, 2000, PROTEINS, V41, P98, DOI 10.1002/1097-0134(20001001)41:1<98::AID-PROT120>3.0.CO;2-S; Hirschman L, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S1-S11; Jenssen TK, 2001, NAT GENET, V28, P21, DOI 10.1038/ng0501-21; MacCallum RM, 2000, BIOINFORMATICS, V16, P125, DOI 10.1093/bioinformatics/16.2.125; Manning C. D., 1999, FDN STAT NATURAL LAN; Marquet Gwenaelle, 2003, Stud Health Technol Inform, V95, P80; McCray Alexa T, 2002, Proc AMIA Symp, P504; Mewes HW, 2004, NUCLEIC ACIDS RES, V32, pD41, DOI 10.1093/nar/gkh092; Oliveros J C, 2000, Genome Inform Ser Workshop Genome Inform, V11, P106; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; Raychaudhuri S, 2002, GENOME RES, V12, P203, DOI 10.1101/gr.199701; Raychaudhuri S, 2003, BIOINFORMATICS, V19, P396, DOI 10.1093/bioinformatics/btg002; SIPOS L, 1993, EUR J BIOCHEM, V213, P1333, DOI 10.1111/j.1432-1033.1993.tb17885.x; Wheeler DL, 2003, NUCLEIC ACIDS RES, V31, P28, DOI 10.1093/nar/gkg033; Xie HQ, 2002, GENOME RES, V12, P785, DOI 10.1101/gr.86902; Yeh A, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S1-S2; Yeh AS, 2003, BIOINFORMATICS, V19, P331	28	10	10	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	MAY 24	2005	6			1					S19	10.1186/1471-2105-6-S1-S19		12	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	022NB	WOS:000236061400019	
J	Rice, SB; Nenadic, G; Stapley, BJ				Rice, SB; Nenadic, G; Stapley, BJ			Mining protein function from text using term-based support vector machines	BMC BIOINFORMATICS			English	Article							BIOMEDICAL LITERATURE; CONNECTIONS; MAGNESIUM	Background: Text mining has spurred huge interest in the domain of biology. The goal of the BioCreAtIvE exercise was to evaluate the performance of current text mining systems. We participated in Task 2, which addressed assigning Gene Ontology terms to human proteins and selecting relevant evidence from full-text documents. We approached it as a modified form of the document classification task. We used a supervised machine-learning approach (based on support vector machines) to assign protein function and select passages that support the assignments. As classification features, we used a protein's co-occurring terms that were automatically extracted from documents. Results: The results evaluated by curators were modest, and quite variable for different problems: in many cases we have relatively good assignment of GO terms to proteins, but the selected supporting text was typically non-relevant (precision spanning from 3% to 50%). The method appears to work best when a substantial set of relevant documents is obtained, while it works poorly on single documents and/or short passages. The initial results suggest that our approach can also mine annotations from text even when an explicit statement relating a protein to a GO term is absent. Conclusion: A machine learning approach to mining protein function predictions from text can yield good performance only if sufficient training data is available, and significant amount of supporting data is used for prediction. The most promising results are for combined document retrieval and GO term assignment, which calls for the integration of methods developed in BioCreAtIvE Task 1 and Task 2.	Univ Manchester, Fac Life Sci, Manchester M13 9PL, Lancs, England; Univ Manchester, Sch Informat, Manchester M13 9PL, Lancs, England; Natl Ctr Text Min, Manchester, Lancs, England	Stapley, BJ (reprint author), Univ Manchester, Fac Life Sci, Manchester M13 9PL, Lancs, England.	S.Rice@postgrad.manchester.ac.uk; G.Nenadic@manchester.ac.uk; B.Stapley@manchester.ac.uk					ANANIADOU S, 2000, GENOME INFORM SERIES; Andrade MA, 1998, BIOINFORMATICS, V14, P600, DOI 10.1093/bioinformatics/14.7.600; BAEZAYATES R, 1999, MODERN INFORMATION R; Blaschke C, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S1-S16; Chiba N, 2002, CANCER RES, V62, P4222; Craven M, 1999, Proc Int Conf Intell Syst Mol Biol, P77; DONALDSON I, BMC BIOINFORMATICS, V4, P11; Hirschman L, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S1-S11; Joachims T., 1999, ADV KERNEL METHODS S; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Krauthammer M, 2004, J BIOMED INFORM, V37, P512, DOI 10.1016/j.jbi.2004.08.004; Leopold E, 2002, MACH LEARN, V46, P423, DOI 10.1023/A:1012491419635; Marcotte EM, 2001, BIOINFORMATICS, V17, P359, DOI 10.1093/bioinformatics/17.4.359; McCray Alexa T, 2002, Proc AMIA Symp, P504; Frantzi K., 2000, International Journal on Digital Libraries, V3, DOI 10.1007/s007999900023; MORGAN A, 2003, P ACL 2003 WORKSH NA, P1; Nenadic G, 2003, BIOINFORMATICS, V19, P938, DOI 10.1093/bioinformatics/btg105; NENADIC G, 2003, P ACL 2003 WORKSH NA, P121; NENADIC G, 2002, P 3 INT C LANG RES E, P2155; NENADIC G, 2004, P COLING 2004, P604, DOI 10.3115/1220355.1220442; Nenadic G., 2004, Terminology, V10, DOI 10.1075/term.10.1.04nen; Raychaudhuri S, 2002, GENOME RES, V12, P203, DOI 10.1101/gr.199701; REGEV Y, ACM SIGKDD EXPLORATI, V4, P290; SMALHEISER NR, 1994, NEUROSCI RES COMMUN, V15, P1; Stapley B J, 2002, Pac Symp Biocomput, P374; SWANSON DR, 1988, PERSPECT BIOL MED, V31, P526; SWANSON DR, 1990, PERSPECT BIOL MED, V33, P157; VERSPOOR CM, 2003, P WORKSH TEXT AN SEA; VOUTILAINEN A, 1993, CREATING USING ENGLI, P189; Yeh A, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S1-S2	30	19	19	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	MAY 24	2005	6			1					S22	10.1186/1471-2105-6-S1-S22		11	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	022NB	WOS:000236061400022	
J	Coifman, RR; Lafon, S; Lee, AB; Maggioni, M; Nadler, B; Warner, F; Zucker, SW				Coifman, RR; Lafon, S; Lee, AB; Maggioni, M; Nadler, B; Warner, F; Zucker, SW			Geometric diffusions as a tool for harmonic analysis and structure definition of data: Diffusion maps	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article							DIMENSIONALITY REDUCTION; EIGENMAPS	We provide a framework for structural multiscale geometric organization of graphs and subsets of R-n. We use diffusion semigroups to generate multiscale geometries in order to organize and represent complex structures. We show that appropriately selected eigenfunctions or scaling functions of Markov matrices, which describe local transitions, lead to macroscopic descriptions at different scales. The process of iterating or diffusing the Markov matrix is seen as a generalization of some aspects of the Newtonian paradigm, in which local infinitesimal transitions of a system lead to global macroscopic descriptions by integration. We provide a unified view of ideas from data analysis, machine learning, and numerical analysis.	Yale Univ, Dept Math, Program Appl Math, New Haven, CT 06510 USA; Yale Univ, Dept Comp Sci, New Haven, CT 06510 USA	Coifman, RR (reprint author), Yale Univ, Dept Math, Program Appl Math, 10 Hillhouse Ave, New Haven, CT 06510 USA.	coifman-ronald@yale.edu	Nadler, Boaz/C-7217-2008				Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Chung F. R. K., 1997, SPECTRAL GRAPH THEOR; Coifman RR, 2005, P NATL ACAD SCI USA, V102, P7432, DOI 10.1073/pnas.0500896102; COIFMAN RR, 2004, IN PRESS DIFFUSION M; COIFMAN RR, 1994, CR ACAD SCI I-MATH, V319, P191; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100; GAR CW, 2002, COMPUT CHEM ENG, V26, P941; HAM J, 2003, KERNEL VIEW DIMENSIO, P1; HASTIE T, 2001, ELEMENTS STAT LEARNI, P144; HUGGINS PS, 2002, P 7 EUR C COMP VIS C, P384; Kevrekidis I. G., 2003, COMMUN MATH SCI, V1, P715; NADLER B, 2004, IN PRESS APPL COMPUT; PEDERSEN KS, 2002, P 7 EUR C COMP VIS, P328; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; Szummer M., 2001, ADV NEURAL INFORM PR, V14, P945; Weiss Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, DOI 10.1109/ICCV.1999.790354; Zhongyi Zhang, 2002, COMMUNICATIONS PURE, P1	18	203	207	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424		P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	MAY 24	2005	102	21					7426	7431		10.1073/pnas.0500334102		6	Multidisciplinary Sciences	Science & Technology - Other Topics	930LN	WOS:000229417500007	
J	Fox, R				Fox, R			Directed molecular evolution by machine learning and the influence of nonlinear interactions	JOURNAL OF THEORETICAL BIOLOGY			English	Article						directed evolution; genetic algorithm; DNA shuffling; NK landscape; machine learning	ARTIFICIAL NEURAL-NETWORKS; VARIABLE SELECTION; PEPTIDE DESIGN; SEARCH ALGORITHM; CLEAVAGE SITES; GA STRATEGY; DRUG DESIGN; 3D QSAR; PROTEIN; REGRESSION	Alternative search strategies for the directed evolution of proteins are presented and compared with each other. In particular, two different machine learning strategies based on partial least-squares regression are developed: the first contains only linear terms that represent a given residue's independent contribution to fitness, the second contains additional nonlinear terms to account for potential epistatic coupling between residues. The nonlinear modeling strategy is further divided into two types, one that contains all possible nonlinear terms and another that makes use of a genetic algorithm to select a subset of important interaction terms. The performance of each modeling type as a function of training set size is analysed. Simulated molecular evolution on a synthetic protein landscape shows the use of machine learning techniques to guide library design can be a powerful addition to library generation methods such as DNA shuffling. (c) 2004 Elsevier Ltd. All rights reserved.	Codexis Inc, Redwood City, CA 94063 USA	Fox, R (reprint author), Codexis Inc, 200 Penobscot Dr, Redwood City, CA 94063 USA.	richard.fox@codexis.com					Aita T, 2002, BIOPOLYMERS, V64, P95, DOI 10.1002/bip.10126; Baffi G, 1999, COMPUT CHEM ENG, V23, P395, DOI 10.1016/S0098-1354(98)00283-X; Bennett K.P., 2003, ADV LEARNING THEORY, P227; Berglund A, 1997, J CHEMOMETR, V11, P141, DOI 10.1002/(SICI)1099-128X(199703)11:2<141::AID-CEM461>3.0.CO;2-2; BOGARAD LD, 1999, P NATL ACAD SCI US; Bucht G, 1999, BBA-PROTEIN STRUCT M, V1431, P471, DOI 10.1016/S0167-4838(99)00079-5; Byvatov E, 2004, J CHEM INF COMP SCI, V44, P993, DOI 10.1021/ci0342876; Byvatov E, 2003, J CHEM INF COMP SCI, V43, P1882, DOI 10.1021/ci0341161; CHEN R, 2001, TRENDS BIOTECHNOL, P19; Cho SJ, 1998, J CHEM INF COMP SCI, V38, P259, DOI 10.1021/ci9700945; Daren Z, 2001, Comput Chem, V25, P197, DOI 10.1016/S0097-8485(00)00081-4; DARIUS F, 1994, BIOPHYS J, V67, P2120; De Genst E, 2002, J BIOL CHEM, V277, P29897, DOI 10.1074/jbc.M202359200; de Jong S, 2001, J CHEMOMETR, V15, P85; EARL DJ, 2004, P NATL ACAD SCI USA, P101; Edwards AWF, 2000, GENETICS, V154, P1419; Fisher R. A., 1930, GENETICAL THEORY NAT; Fox R, 2003, PROTEIN ENG, V16, P589, DOI 10.1093/protein/gzg077; Goldberg D. E., 1985, P 1 INT C GEN ALG TH, P154; Gustafsson C, 2001, J MOL RECOGNIT, V14, P308, DOI 10.1002/jmr.543; Hasegawa K, 1997, J CHEM INF COMP SCI, V37, P306, DOI 10.1021/ci960047x; Hasegawa K, 1999, J CHEM INF COMP SCI, V39, P112, DOI 10.1021/ci980088o; Hastie T., 2003, ELEMENTS STAT LEARNI; KAUFFMAN SA, 1993, ORIGINS ORDER; Kubinyi H, 1997, DRUG DISCOV TODAY, V2, P538, DOI 10.1016/S1359-6446(97)01084-2; Kubinyi H, 1996, J CHEMOMETR, V10, P119, DOI 10.1002/(SICI)1099-128X(199603)10:2<119::AID-CEM409>3.3.CO;2-W; Kubinyi H, 1997, DRUG DISCOV TODAY, V2, P457, DOI 10.1016/S1359-6446(97)01079-9; Kurtzman AL, 2001, CURR OPIN BIOTECH, V12, P361, DOI 10.1016/S0958-1669(00)00228-7; Leardi R, 1998, CHEMOMETR INTELL LAB, V41, P195, DOI 10.1016/S0169-7439(98)00051-3; Lee MJ, 2000, INSECT BIOCHEM MOLEC, V30, P899, DOI 10.1016/S0965-1748(00)00078-3; Lu SM, 2001, P NATL ACAD SCI USA, V98, P1410, DOI 10.1073/pnas.031581398; Mee RP, 1997, J PEPT RES, V49, P89; NESS JE, 2002, NAT BIOTECH; Ness JE, 1999, NAT BIOTECHNOL, V17, P893, DOI 10.1038/12884; OZDEMIR M, 2002, ENG SCI, P285; PIERCE AN, 2002, PROTEIN ENG, V15, P779; Raman V, 1998, INFORM PROCESS LETT, V65, P1, DOI 10.1016/S0020-0190(97)00223-8; Rosipal R, 2001, J MACHINE LEARNING R, V2, P97; SCHNEIDER G, 1995, BIOPHYS J, V68, P434; SCHNEIDER G, 1994, COMPUT APPL BIOSCI, V10, P635; SCHNEIDER G, 1995, BIOL CYBERN, V73, P245, DOI 10.1007/BF00201426; Schneider G, 1998, P NATL ACAD SCI USA, V95, P12179, DOI 10.1073/pnas.95.21.12179; STEMMER WPC, 1994, NATURE, V370, P389, DOI 10.1038/370389a0; VANREGENMORTEL MH, 2000, J MOL RECOG, V13; WELLS JA, 1990, BIOCHEMISTRY-US, V29, P8509, DOI 10.1021/bi00489a001; Wold H., 1985, ENCY STATISTICAL SCI, V6, P581; Wrede P, 1998, BIOCHEMISTRY-US, V37, P3588, DOI 10.1021/bi9726032; WRIGHT SEWALL, 1932, PROC SIXTH INTERNAT CONGR GENETICS ITHACA NEW YORK, V1, P356; YU X, 2004, CURR OPIN STRUC BIOL, V14, P202	49	11	13	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0022-5193		J THEOR BIOL	J. Theor. Biol.	MAY 21	2005	234	2					187	199		10.1016/j.jtbi.2004.11.031		13	Biology; Mathematical & Computational Biology	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology	909GV	WOS:000227849300005	
J	Bao, L; Cui, Y				Bao, L; Cui, Y			Prediction of the phenotypic effects of non-synonymous single nucleotide polymorphisms using structural and evolutionary information	BIOINFORMATICS			English	Article							SECONDARY STRUCTURE; PROTEIN-STRUCTURE; PSI-BLAST; CLASSIFICATION; SEQUENCES; SERVER; SNPS; TOOL	Motivation: There has been great expectation that the knowledge of an individual's genotype will provide a basis for assessing susceptibility to diseases and designing individualized therapy. Non-synonymous single nucleotide polymorphisms (nsSNPs) that lead to an amino acid change in the protein product are of particular interest because they account for nearly half of the known genetic variations related to human inherited diseases. To facilitate the identification of disease-associated nsSNPs from a large number of neutral nsSNPs, it is important to develop computational tools to predict the phenotypic effects of nsSNPs. Results: We prepared a training set based on the variant phenotypic annotation of the Swiss-Prot database and focused our analysis on nsSNPs having homologous 3D structures. Structural environment parameters derived from the 3D homologous structure as well as evolutionary information derived from the multiple sequence alignment were used as predictors. Two machine learning methods, support vector machine and random forest, were trained and evaluated. We compared the performance of our method with that of the SIFT algorithm, which is one of the best predictive methods to date. An unbiased evaluation study shows that for nsSNPs with sufficient evolutionary information (with not < 10 homologous sequences), the performance of our method is comparable with the SIFT algorithm, while for nsSNPs with insufficient evolutionary information (< 10 homologous sequences), our method outperforms the SIFT algorithm significantly. These findings indicate that incorporating structural information is critical to achieving good prediction accuracy when sufficient evolutionary information is not available.	Univ Tennessee, Ctr Hlth Sci, Dept Mol Sci, Ctr Genom & Bioinformat, Memphis, TN 38163 USA	Cui, Y (reprint author), Univ Tennessee, Ctr Hlth Sci, Dept Mol Sci, Ctr Genom & Bioinformat, 858 Madison Ave, Memphis, TN 38163 USA.	ycui2@utmem.edu					Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Apweiler R, 2004, NUCLEIC ACIDS RES, V32, pD115, DOI 10.1093/nar/gkh131; Berman Helen M, 2004, Am J Pharmacogenomics, V4, P247, DOI 10.2165/00129785-200404040-00004; Bhasin M, 2004, NUCLEIC ACIDS RES, V32, pW414, DOI 10.1093/nar/gkh350; BOWIE JU, 1991, SCIENCE, V253, P164, DOI 10.1126/science.1853201; BREIMAN L, 2001, RANDOM FOREST; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Chandonia JM, 2004, NUCLEIC ACIDS RES, V32, pD189, DOI 10.1093/nar/gkh034; Chasman D, 2001, J MOL BIOL, V307, P683, DOI 10.1006/jmbi.2001.4510; Chen YC, 2004, PROTEINS, V55, P1036, DOI 10.1002/prot.20079; Collins FS, 1998, GENOME RES, V8, P1229; Fredman D, 2002, NUCLEIC ACIDS RES, V30, P387, DOI 10.1093/nar/30.1.387; Frishman D, 1995, PROTEINS, V23, P566, DOI 10.1002/prot.340230412; Gunther EC, 2003, P NATL ACAD SCI USA, V100, P9608, DOI 10.1073/pnas.1632587100; Hardin C, 2002, CURR OPIN STRUC BIOL, V12, P176, DOI 10.1016/S0959-440X(02)00306-8; Henikoff JG, 1996, COMPUT APPL BIOSCI, V12, P135; Irizarry K, 2000, NAT GENET, V26, P233; Joachims T., 1999, ADV KERNEL METHODS S; Krishnan VG, 2003, BIOINFORMATICS, V19, P2199, DOI 10.1093/bioinformatics/btg297; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; Ng PC, 2001, GENOME RES, V11, P863, DOI 10.1101/gr.176601; Ng PC, 2003, NUCLEIC ACIDS RES, V31, P3812, DOI 10.1093/nar/gkg509; Ramensky V, 2002, NUCLEIC ACIDS RES, V30, P3894, DOI 10.1093/nar/gkf493; REIMAN L, 1984, CLASSIFICATION REGRE; Saunders CT, 2002, J MOL BIOL, V322, P891, DOI 10.1016/S0022-2836(02)00813-6; Schwede T, 2003, NUCLEIC ACIDS RES, V31, P3381, DOI 10.1093/nar/gkg520; Stenson PD, 2003, HUM MUTAT, V21, P577, DOI 10.1002/humu.10212; Sunyaev S, 2001, HUM MOL GENET, V10, P591, DOI 10.1093/hmg/10.6.591; Sunyaev S, 2000, TRENDS GENET, V16, P198, DOI 10.1016/S0168-9525(00)01988-0; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Vapnik VN, 1998, STAT LEARNING THEORY; Wang Z, 2001, HUM MUTAT, V17, P263, DOI 10.1002/humu.22; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210; Zhou XH, 2002, STAT METHODS DIAGNOS	35	74	76	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	MAY 15	2005	21	10					2185	2190		10.1093/bioinformatics/bti365		6	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	928QA	WOS:000229285600006	
J	Sehgal, MSB; Gondal, I; Dooley, LS				Sehgal, MSB; Gondal, I; Dooley, LS			Collateral missing value imputation: a new robust missing value estimation algorithm for microarray data	BIOINFORMATICS			English	Article							CANCER; CLASSIFICATION; PREDICTION	Motivation: Microarray data are used in a range of application areas in biology, although often it contains considerable numbers of missing values. These missing values can significantly affect subsequent statistical analysis and machine learning algorithms so there is a strong motivation to estimate these values as accurately as possible before using these algorithms. While many imputation algorithms have been proposed, more robust techniques need to be developed so that further analysis of biological data can be accurately undertaken. In this paper, an innovative missing value imputation algorithm called collateral missing value estimation (CMVE) is presented which uses multiple covariance-based imputation matrices for the final prediction of missing values. The matrices are computed and optimized using least square regression and linear programming methods. Results: The new CMVE algorithm has been compared with existing estimation techniques including Bayesian principal component analysis imputation (BPCA), least square impute (LSImpute) and K-nearest neighbour (KNN). All these methods were rigorously tested to estimate missing values in three separate non-time series (ovarian cancer based) and one time series (yeast sporulation) dataset. Each method was quantitatively analyzed using the normalized root mean square (NRMS) error measure, covering a wide range of randomly introduced missing value probabilities from 0.01 to 0.2. Experiments were also undertaken on the yeast dataset, which comprised 1.7% actual missing values, to test the hypothesis that CMVE performed better not only for randomly occurring but also for a real distribution of missing values. The results confirmed that CMVE consistently demonstrated superior and robust estimation capability of missing values compared with other methods for both series types of data, for the same order of computational complexity. A concise theoretical framework has also been formulated to validate the improved performance of the CMVE algorithm.	Monash Univ, Gippsland Sch Comp & Informat Technol, Clayton, Vic 3842, Australia	Sehgal, MSB (reprint author), Monash Univ, Gippsland Sch Comp & Informat Technol, Clayton, Vic 3842, Australia.	Shoaib.Sehgal@infotech.monash.edu.au					Acuna E, 2004, ST CLASS DAT ANAL, P639; AMIR AJ, 2002, J NATL CANCER I, V94, P981; BROWN WN, 1997, P NATL ACAD SCI USA, V97, P262; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; GUSTAVO B, 2003, APPL ARTIF INTELL, V17, P519; Harvey M., 2004, FITTING MODELS BIOL; HELLEM BT, 2004, NUCLEIC ACIDS RES, V32, pE34; Lawson C., 1974, SOLVING LEAST SQUARE; MCLEAN A, 2000, J STAT ED, V8; Munagala K, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-21; Oba S, 2003, BIOINFORMATICS, V19, P2088, DOI 10.1093/bioinformatics/btg287; Ouyang M, 2004, BIOINFORMATICS, V20, P917, DOI 10.1093/bioinformatics/bth007; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; SEHGAL MSB, 2004, ICBA 04 US; SEHGAL MSB, 2004, HIS 04 JAP; SEHGAL MSB, 2004, IEEE CIBCB 04 US; SEHGAL MSB, 2004, COMPL 04 AUSTR; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520	21	43	53	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	MAY 15	2005	21	10					2417	2423		10.1093/bioinformatics/bti345		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	928QA	WOS:000229285600035	
J	Tetko, IV; Brauner, B; Dunger-Kaltenbach, I; Frishman, G; Montrone, C; Fobo, G; Ruepp, A; Antonov, AV; Surmeli, D; Mewes, HW				Tetko, IV; Brauner, B; Dunger-Kaltenbach, I; Frishman, G; Montrone, C; Fobo, G; Ruepp, A; Antonov, AV; Surmeli, D; Mewes, HW			MIPS bacterial genomes functional annotation benchmark dataset	BIOINFORMATICS			English	Article							WHOLE GENOMES; CLASSIFICATION; PROTEINS	Motivation: Any development of new methods for automatic functional annotation of proteins according to their sequences requires high-quality data (as benchmark) as well as tedious preparatory work to generate sequence parameters required as input data for the machine learning methods. Different program settings and incompatible protocols make a comparison of the analyzed methods difficult. Results: The MIPS Bacterial Functional Annotation Benchmark dataset (MIPS-BFAB) is a new, high-quality resource comprising four bacterial genomes manually annotated according to the MIPS functional catalogue (FunCat). These resources include precalculated sequence parameters, such as sequence similarity scores, InterPro domain composition and other parameters that could be used to develop and benchmark methods for functional annotation of bacterial protein sequences. These data are provided in XML format and can be used by scientists who are not necessarily experts in genome annotation.	GSF, Natl Res Ctr Environm & Hlth, Inst Bioinformat MIPS, D-85764 Neuherberg, Germany	Tetko, IV (reprint author), GSF, Natl Res Ctr Environm & Hlth, Inst Bioinformat MIPS, Ingolstaedter Landstr 1, D-85764 Neuherberg, Germany.	i.tetko@gsf.de	Tetko, Igor/B-1540-2010	Tetko, Igor/0000-0002-6855-0012			Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Cai YD, 2004, BIOINFORMATICS, V20, P1292, DOI 10.1093/bioinformatics/bth085; Clare A., 2003, BIOINFORMATICS, V19, P42; Mateos A, 2002, GENOME RES, V12, P1703, DOI 10.1101/gr.192502; Mewes HW, 2004, NUCLEIC ACIDS RES, V32, pD41, DOI 10.1093/nar/gkh092; Mi HY, 2003, GENOME RES, V13, P2118, DOI 10.1101/gr.771603; Mulder NJ, 2005, NUCLEIC ACIDS RES, V33, pD201, DOI 10.1093/nar/gki106; NAKAI K, 1991, PROTEINS, V11, P95, DOI 10.1002/prot.340110203; Pearson WR, 1996, METHOD ENZYMOL, V266, P227; Ruepp A, 2004, NUCLEIC ACIDS RES, V32, P5539, DOI 10.1093/nar/gkh894	10	9	9	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	MAY 15	2005	21	10					2520	2521		10.1093/bioinformatics/bti380		2	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	928QA	WOS:000229285600050	
J	Dai, HY; van't Veer, L; Lamb, J; He, YD; Mao, M; Fine, BM; Bernards, R; de Vijver, MV; Deutsch, P; Sachs, A; Stoughton, R; Friend, S				Dai, HY; van't Veer, L; Lamb, J; He, YD; Mao, M; Fine, BM; Bernards, R; de Vijver, MV; Deutsch, P; Sachs, A; Stoughton, R; Friend, S			A cell proliferation signature is a marker of extremely poor outcome in a subpopulation of breast cancer patients	CANCER RESEARCH			English	Article							GENE-EXPRESSION PROFILES; ESTROGEN-RECEPTOR STATUS; PROGNOSTIC VALUE; DUCTAL CARCINOMA; PROSTATE-CANCER; FOLLOW-UP; PREDICTS; PATTERNS; SURVIVAL; CLASSIFICATION	Breast cancer comprises a group of distinct subtypes that despite having similar histologic appearances, have very different metastatic potentials. Being able to identify the biological driving force, even for a subset of patients, is crucially important given the large population of women diagnosed with breast cancer. Here, we show that within a subset of patients characterized by relatively high estrogen receptor expression for their age, the occurrence of metastases is strongly predicted by a homogeneous gene expression pattern almost entirely consisting of cell cycle genes (5-year odds ratio of metastasis, 24.0; 95% confidence interval, 6.0-95.5). Overexpression of this set of genes is clearly associated with an extremely poor outcome, with the 10-year metastasis-free probability being only 24% for the poor group, compared with 85% for the good group. In contrast, this gene expression pattern is much less correlated with the outcome in other patient subpopulations. The methods described here also illustrate the value of combining clinical variables, biological insight, and machine-learning to dissect biological complexity. Our work presented here may contribute a crucial step towards rational design of personalized treatment.	Merck & Co Inc, Merck Res Labs, W Point, PA 19486 USA; Rosetta Inpharmat LLC, Seattle, WA USA; Netherlands Canc Inst, Div Diagnost Oncol Radiotherapy & Mol Carcinogene, Amsterdam, Netherlands; Netherlands Canc Inst, Ctr Biomed Genet, Amsterdam, Netherlands; GHC Technol Inc, La Jolla, CA USA	Friend, S (reprint author), Merck & Co Inc, Merck Res Labs, POB 4,WP14-2500,770 Sumneytown Pike, W Point, PA 19486 USA.	stephen_friend@merck.com					Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Beer DG, 2002, NAT MED, V8, P816, DOI 10.1038/nm733; Bijker N, 2001, J CLIN ONCOL, V19, P2263; Collett K, 1996, J CLIN PATHOL, V49, P920, DOI 10.1136/jcp.49.11.920; DeRisi J, 1996, NAT GENET, V14, P457; Foulkes WD, 2004, CLIN CANCER RES, V10, P2029, DOI 10.1158/1078-0432.CCR-03-1061; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; Glinsky GV, 2004, J CLIN INVEST, V113, P913, DOI 10.1172/JCI200420032; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gruvberger S, 2001, CANCER RES, V61, P5979; Ishibashi Y, 2003, CANCER RES, V63, P5159; Kaufmann M, 1996, Recent Results Cancer Res, V140, P77; Khan J, 1998, CANCER RES, V58, P5009; Latil A, 2003, CLIN CANCER RES, V9, P5477; Liu SQ, 2001, CLIN CANCER RES, V7, P1716; Maggard MA, 2003, J SURG RES, V113, P109, DOI 10.1016/S0022-4804(03)00179-3; Medri L, 2004, MODERN PATHOL, V17, P1024, DOI 10.1038/modpathol.3800126; Michels JJ, 2004, CANCER, V100, P455, DOI 10.1002/cncr.11916; Mirza AN, 2002, ANN SURG, V235, P10, DOI 10.1097/00000658-200201000-00003; Pang ST, 2002, ENDOCRINOLOGY, V143, P4897, DOI 10.1210/en.2002-220327; Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; Pichon MF, 1996, BRIT J CANCER, V73, P1545, DOI 10.1038/bjc.1996.291; Pittman J, 2004, P NATL ACAD SCI USA, V101, P8431, DOI 10.1073/pnas.0401736101; Reed W, 2000, CANCER, V88, P804, DOI 10.1002/(SICI)1097-0142(20000215)88:4<804::AID-CNCR11>3.0.CO;2-Y; Simpson JF, 2000, J CLIN ONCOL, V18, P2059; Sorlie T, 2001, P NATL ACAD SCI USA, V98, P10869, DOI 10.1073/pnas.191367098; Sorlie T, 2003, P NATL ACAD SCI USA, V100, P8418, DOI 10.1073/pnas.0932692100; Sotiriou C, 2003, P NATL ACAD SCI USA, V100, P10393, DOI 10.1073/pnas.1732912100; Surowiak P, 2001, FOLIA HISTOCHEM CYTO, V39, P143; van de Vijver MJ, 2002, NEW ENGL J MED, V347, P1999, DOI 10.1056/NEJMoa021967; van Diest PJ, 2004, J CLIN PATHOL, V57, P675, DOI 10.1136/jcp.2003.010777; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; West M, 2001, P NATL ACAD SCI USA, V98, P11462, DOI 10.1073/pnas.201162998; Whitfield ML, 2002, MOL BIOL CELL, V13, P1977, DOI 10.1091/mbc.02-02-0030; Zajchowski DA, 2001, CANCER RES, V61, P5168	35	149	153	AMER ASSOC CANCER RESEARCH	PHILADELPHIA	615 CHESTNUT ST, 17TH FLOOR, PHILADELPHIA, PA 19106-4404 USA	0008-5472		CANCER RES	Cancer Res.	MAY 15	2005	65	10					4059	4066		10.1158/0008-5472.CAN-04-3953		8	Oncology	Oncology	925OI	WOS:000229062000012	
J	Adamczak, R; Porollo, A; Meller, J				Adamczak, R; Porollo, A; Meller, J			Combining prediction of secondary structure and solvent accessibility in proteins	PROTEINS-STRUCTURE FUNCTION AND BIOINFORMATICS			English	Article						secondary structure; neural networks; classification; protein structure prediction; relative solvent accessibility; SABLE	NEURAL NETWORKS; DATABASE; REGRESSION; ACCURACY; FAMILIES; FEATURES; MODELS	Owing to the use of evolutionary information and advanced machine learning protocols, secondary structures of amino acid residues in proteins can be predicted from the primary sequence with more than 75% per-residue accuracy for the 3-state (i.e., helix, beta-strand, and coil) classification problem. In this work we investigate whether further progress may be achieved by incorporating the relative solvent accessibility (RSA) of an amino acid residue as a fingerprint of the overall topology of the protein. Toward that goal, we developed a novel method for secondary structure prediction that uses predicted RSA in addition to attributes derived from evolutionary profiles. Our general approach follows the 2-stage protocol of Rost and Sander, with a number of Elman-type recurrent neural networks (NNs) combined into a consensus predictor. The RSA is predicted using our recently developed regression-based method that provides real-valued RSA, with the overall correlation coefficients between the actual and predicted RSA of about 0.66 in rigorous tests on independent control sets. Using the predicted RSA, we were able to improve the performance of our secondary structure prediction by up to 1.4% and achieved the overall per-residue accuracy between 77.0% and 78.4% for the 3-state classification problem on different control sets comprising, together, 603 proteins without homology to proteins included in the training. The effects of including solvent accessibility depend on the quality of RSA prediction. In the limit of perfect prediction (i.e., when using the actual RSA values derived from known protein structures), the accuracy of secondary structure prediction increases by up to 4%. We also observed that projecting real-valued RSA into 2 discrete classes with the commonly used threshold of 25% RSA decreases the classification accuracy for secondary structure prediction. While the level of improvement of secondary structure prediction may be different for prediction protocols that implicitly account for RSA in other ways, we conclude that an increase in the 3-state classification accuracy may be achieved when combining RSA with a state-of-theart protocol utilizing evolutionary profiles. The new method is available through a Web server at http://sable.cchme.org. (c) 2005 Wiley-Liss, Inc.	Childrens Hosp Res Fdn, Cincinnati, OH 45229 USA; Nicholas Copernicus Univ, Dept Informat, Torun, Poland	Meller, J (reprint author), Childrens Hosp Res Fdn, 3333 Burnet Ave, Cincinnati, OH 45229 USA.	jmeller@chmcc.org	Meller, Jaroslaw/A-1971-2011; de Sousa, Miguel/A-3877-2009	Meller, Jaroslaw/0000-0002-1162-8253; 			Adamczak R, 2004, PROTEINS, V56, P753, DOI 10.1002/prot.20176; Ahmad S, 2002, BIOINFORMATICS, V18, P819, DOI 10.1093/bioinformatics/18.6.819; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Baldi P, 1999, BIOINFORMATICS, V15, P937, DOI 10.1093/bioinformatics/15.11.937; Bateman A, 2002, NUCLEIC ACIDS RES, V30, P276, DOI 10.1093/nar/30.1.276; Benson DA, 2003, NUCLEIC ACIDS RES, V31, P23, DOI 10.1093/nar/gkg057; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Bystroff C, 2000, J MOL BIOL, V301, P173, DOI 10.1006/jmbi.2000.3837; CUFF JA, 1999, PROTEIN-STRUCT FUNCT, V40, P502; Cuff JA, 1998, BIOINFORMATICS, V14, P892, DOI 10.1093/bioinformatics/14.10.892; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1016/0364-0213(90)90002-E; Eyrich VA, 2001, BIOINFORMATICS, V17, P1242, DOI 10.1093/bioinformatics/17.12.1242; FAHLMANN SE, 1988, 1988 CONNECTIONISTS; Fischer D, 2001, PROTEINS, P171; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; Karplus K, 1998, BIOINFORMATICS, V14, P846, DOI 10.1093/bioinformatics/14.10.846; Macdonald JR, 2001, PROTEIN SCI, V10, P1172, DOI 10.1110/ps.420101; MATTHEWS BM, 1975, BIOCHIM BIOPHYS ACTA, V405, P445; Meller J, 2001, PROTEINS, V45, P241, DOI 10.1002/prot.1145; MELLER J, LOOPP LEARNING OBSER; Petersen TN, 2000, PROTEINS, V41, P17, DOI 10.1002/1097-0134(20001001)41:1<17::AID-PROT40>3.0.CO;2-F; Pollastri G, 2002, PROTEINS, V47, P142, DOI 10.1002/prot.10069; Pollastri G, 2002, PROTEINS, V47, P228, DOI 10.1002/prot.10082; Przybylski D, 2002, PROTEINS, V46, P197, DOI 10.1002/prot.10029; Riedmiller M., 1993, P IEEE INT C NEUR NE, V586591; Anderson CAF, 2002, STRUCTURE, V10, P175, DOI 10.1016/S0969-2126(02)00700-1; Rost B, 2001, J STRUCT BIOL, V134, P204, DOI 10.1006/jsbi.2000.4336; ROST B, 1993, J MOL BIOL, V232, P584, DOI 10.1006/jmbi.1993.1413; ROST B, 1994, PROTEINS, V20, P216, DOI 10.1002/prot.340200303; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; Saxonov S, 2000, NUCLEIC ACIDS RES, V28, P185, DOI 10.1093/nar/28.1.185; Schonbrun J, 2002, CURR OPIN STRUC BIOL, V12, P348, DOI 10.1016/S0959-440X(02)00336-6; Venclovas C, 2001, PROTEINS, P163; Wagner M, 2005, J COMPUT BIOL, V12, P355, DOI 10.1089/cmb.2005.12.355; ZELL A, 1995, SNNS USERS MANUAL VE; Zemla A, 1999, PROTEINS, V34, P220, DOI 10.1002/(SICI)1097-0134(19990201)34:2<220::AID-PROT7>3.0.CO;2-K; Zhu ZY, 1996, J MOL BIOL, V260, P261, DOI 10.1006/jmbi.1996.0397	38	114	120	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0887-3585		PROTEINS	Proteins	MAY 15	2005	59	3					467	475		10.1002/prot.20441		9	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	921QJ	WOS:000228779200006	
J	Nair, V; Laprise, PO; Clark, JJ				Nair, V; Laprise, PO; Clark, JJ			An FPGA-based people detection system	EURASIP JOURNAL ON APPLIED SIGNAL PROCESSING			English	Article						computer vision; FPGA; people detection; smart camera		This paper presents an FPGA-based system for detecting people from video. The system is designed to use JPEG-compressed frames from a network camera. Unlike previous approaches that use techniques such as background subtraction and motion detection, we use a machine- learning-based approach to train an accurate detector. We address the hardware design challenges involved in implementing such a detector, along with JPEG decompression, on an FPGA. We also present an algorithm that efficiently combines JPEG decompression with the detection process. This algorithm carries out the inverse DCT step of JPEG decompression only partially. Therefore, it is computationally more efficient and simpler to implement, and it takes up less space on the chip than the full inverse DCT algorithm. The system is demonstrated on an automated video surveillance application and the performance of both hardware and software implementations is analyzed. The results show that the system can detect people accurately at a rate of about 2.5 frames per second on a Virtex-11 2V1000 using a MicroBlaze processor running at 75 MHz, communicating with dedicated hardware over FSL links.	McGill Univ, Ctr Intelligent Machines, Montreal, PQ H3A 2A7, Canada	Nair, V (reprint author), McGill Univ, Ctr Intelligent Machines, Montreal, PQ H3A 2A7, Canada.	vnair@cim.mcgill.ca; plapri@cim.mcgill.ca; clark@cim.mcgill.ca					ABDELALI AB, 2002, IEEE INT C SYST MAN, V2, P69, DOI 10.1109/ICSMC.2002.1173387; Boschetti M. R., 2002, Proceedings 15th Symposium on Integrated Circuits and Systems Design, DOI 10.1109/SBCCI.2002.1137655; CERROPRADA E, 1999, 7 INT C IM PROC ITS, V1, P450; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Fry TW, 2002, ANN IEEE SYM FIELD P, P251, DOI 10.1109/FPGA.2002.1106679; Miano J, 1999, COMPRESSED IMAGE FIL; Nguyen K., 2002, Proceedings Third International Workshop on Digital and Computational Video. DCV 2002 (Cat. No.02EX724); SRIVASTAVA N, 2003, P INT PAR DISTR PROC, P180; Viola P., 2001, 2 INT WORKSH STAT CO; Wallace G. K., 1992, IEEE T CONSUM ELECTR, V38, P18	10	11	11	HINDAWI PUBLISHING CORPORATION	NEW YORK	410 PARK AVENUE, 15TH FLOOR, #287 PMB, NEW YORK, NY 10022 USA	1110-8657		EURASIP J APPL SIG P	EURASIP J Appl. Signal Process.	MAY 11	2005	2005	7					1047	1061		10.1155/ASP.2005.1047		15	Engineering, Electrical & Electronic	Engineering	948WA	WOS:000230745200006	
J	Jimenez, DA				Jimenez, DA			Improved latency and accuracy for neural branch prediction	ACM TRANSACTIONS ON COMPUTER SYSTEMS			English	Article						performance; Branch prediction; machine learning		Microarchitectural prediction based on neural learning has received increasing attention in recent years. However, neural prediction remains impractical because its superior accuracy over conventional predictors is not enough to offset the cost imposed by its high latency. We present a new neural branch predictor that solves the problem from both directions: it is both more accurate and much faster than previous neural predictors. Our predictor improves accuracy by combining path and pattern history to overcome limitations inherent to previous predictors. It also has much lower latency than previous neural predictors. The result is a predictor with accuracy far superior to conventional predictors but with latency comparable to predictors from industrial designs. Our simulations show that a path-based neural predictor improves the instructions-per-cycle (IPC) rate of an aggressively clocked microarchitecture by 16% over the original perceptron predictor. One reason for the improved accuracy is the ability of our new predictor to learn linearly inseparable branches; we show that these branches account for 50% of all branches and almost all branch mispredictions.	Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA	Jimenez, DA (reprint author), Rutgers State Univ, Dept Comp Sci, 110 Frelinghuysen Rd, Piscataway, NJ 08854 USA.	djimenez@cs.rutgers.edu					BALL T, 1993, P SIGPLAN 93 C PROGR, P300, DOI 10.1145/155090.155119; BLOCK HD, 1962, REV MOD PHYS, V34, P123, DOI 10.1103/RevModPhys.34.123; Burger D., 1997, 1342 U WISC COMP SCI; CALDER B, 1995, P SIGPLAN C PROGR LA, P79, DOI 10.1145/207110.207118; Cormen Thomas H., 1990, INTRO ALGORITHMS; Evers M., 1998, Proceedings. 25th Annual International Symposium on Computer Architecture (Cat. No.98CB36235), DOI 10.1109/ISCA.1998.694762; FAUSETT L, 1994, RUNDAMENTALS NEURAL; Jimenez D. A., 2001, Proceedings HPCA Seventh International Symposium on High-Performance Computer Architecture, DOI 10.1109/HPCA.2001.903263; JIMENEZ DA, 2002, P 9 INT S HIGH PERF, P43; Jimenez DA, 2002, ACM T COMPUT SYST, V20, P369, DOI 10.1145/571637.571639; JIMENEZ DA, 2003, P 36 ANN IEEE ACM IN, P243; Jimenez D. A., 2000, Proceedings 33rd Annual IEEE/ACM International Symposium on Microarchitecture. MICRO-33 2000, DOI 10.1109/MICRO.2000.898059; Kessler RE, 1999, IEEE MICRO, V19, P24, DOI 10.1109/40.755465; Loh G. H., 2002, Proceedings 2002 International Conference on Parallel Architectures and Compilation Techniques. PACT 2002, DOI 10.1109/PACT.2002.1106015; MCFARLING S., 1993, TN36M DIG W RES LAB; Nair R., 1995, Proceedings of the 28th Annual International Symposium on Microarchitecture (Cat. No.95TB100012), DOI 10.1109/MICRO.1995.476809; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; SEZNEC A, 2003, P 30 INT S COMP ARCH; SEZNEC A, 2002, P 29 INT S COMP ARCH; SHIVAKUMAR R, 2001, 20012 COMP COMP CORP; Skadron K., 2000, Proceedings 2000 International Conference on Parallel Architectures and Compilation Techniques (Cat. No.PR00622), DOI 10.1109/PACT.2000.888344; Smith J. E., 1981, P 8 ANN INT S COMP A, P135; Sprangle E., 2002, Proceedings 29th Annual International Symposium on Computer Architecture, DOI 10.1109/ISCA.2002.1003559; STARK J, 1998, P 8 INT C ARCH SUPP, P170, DOI 10.1145/291069.291042; THOMAS R, 2003, P 30 INT S COMP ARCH; VINTAN LN, 1999, P INT JOINT C NEUR N, V2, P868	26	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	0734-2071		ACM T COMPUT SYST	ACM Trans. Comput. Syst.	MAY	2005	23	2					197	218		10.1145/1062247.1062250		22	Computer Science, Theory & Methods	Computer Science	932VU	WOS:000229583400003	
J	King, RD; Garrett, SM; Coghill, GM				King, RD; Garrett, SM; Coghill, GM			On the use of qualitative reasoning to simulate and identify metabolic pathways	BIOINFORMATICS			English	Article							TRYPANOSOMA-BRUCEI; NETWORKS; ENCYCLOPEDIA; KINETICS; GENES; CELL	Motivation: Perhaps the greatest challenge of modern biology is to develop accurate in silico models of cells. To do this we require computational formalisms for both simulation (how according to the model the state of the cell evolves over time) and identification (learning a model cell from observation of states). We propose the use of qualitative reasoning (QR) as a unified formalism for both tasks. The two most commonly used alternative methods of modelling biochemical pathways are ordinary differential equations (ODEs), and logical/graph-based (LG) models. Results: The QR formalism we use is an abstraction of ODEs. It enables the behaviour of many ODEs, with different functional forms and parameters, to be captured in a single QR model. QR has the advantage over LG models of explicitly including dynamics. To simulate biochemical pathways we have developed 'enzyme' and 'metabolite' QR building blocks that fit together to form models. These models are finite, directly executable, easy to interpret and robust. To identify QR models we have developed heuristic chemoinformatics graph analysis and machine learning procedures. The graph analysis procedure is a series of constraints and heuristics that limit the number of ways metabolites can combine to form pathways. The machine learning procedure is generate-and-test inductive logic programming. We illustrate the use of QR for modelling and simulation using the example of glycolysis.	Univ Wales, Dept Comp Sci, Aberystwyth SY23 3DB, Dyfed, Wales; Univ Aberdeen, Dept Comp Sci, Aberdeen ABD24 3UE, Scotland	King, RD (reprint author), Univ Wales, Dept Comp Sci, Aberystwyth SY23 3DB, Dyfed, Wales.	rdk@aber.ac.uk					Akutsu T, 2000, BIOINFORMATICS, V16, P727, DOI 10.1093/bioinformatics/16.8.727; ALON U, 1999, NATURE, V397, P169; Arkin A, 1997, SCIENCE, V277, P1275, DOI 10.1126/science.277.5330.1275; Bakker BM, 1997, J BIOL CHEM, V272, P3207; BRATKO I, 1991, P 8 INT WORKSH MACH, P385; CLELAND WW, 1963, BIOCHIM BIOPHYS ACTA, V67, P173, DOI 10.1016/0926-6569(63)90226-8; COGHILL GM, 2004, P 16 EUR C ART INT, P445; COGHILL GM, 2002, P 16 INT WORKSH QUAL; Eisenthal R, 1998, J BIOL CHEM, V273, P5500, DOI 10.1074/jbc.273.10.5500; Famili I, 2003, P NATL ACAD SCI USA, V100, P13134, DOI 10.1073/pnas.2235812100; Ferrell JE, 1998, SCIENCE, V280, P895, DOI 10.1126/science.280.5365.895; Fiehn O, 2001, COMPAR FUNCT GENOM, V2, P155, DOI 10.1002/cfg.82; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Goryanin I, 1999, BIOINFORMATICS, V15, P749, DOI 10.1093/bioinformatics/15.9.749; Hau DT, 1997, MACH LEARN, V26, P177, DOI 10.1023/A:1007317323969; Hayes P. J., 1979, Expert Systems in the Micro-Electronic Age. Proceedings of the 1979 AISB Summer School; Heidtke KR, 1998, BIOINFORMATICS, V14, P81, DOI 10.1093/bioinformatics/14.1.81; Heidtke K. R., 1998, Proceedings Sixth International Conference on Intelligent Systems for Molecular Biology; Karp PD, 1996, NUCLEIC ACIDS RES, V24, P32, DOI 10.1093/nar/24.1.32; Kauffman S. A., 1993, ORIGINS ORDER SELF O; King RD, 2004, NATURE, V427, P247, DOI 10.1038/nature02236; Koza J R, 2001, Pac Symp Biocomput, P434; Kuipers B., 1994, QUALITATIVE REASONIN; Ljung L, 1999, SYSTEM IDENTIFICATIO; MALOBERTI J, 2001, P ILP 01 C, P164; MATSUNO H, 2000, P PAC S BIOC MAUN LA, P41; MENDES P, 1997, TRENDS BIOCHEM SCI, V22, P36; Mitchell T, 1997, MACHINE LEARNING; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; Ogata H, 1999, NUCLEIC ACIDS RES, V27, P29, DOI 10.1093/nar/27.1.29; Regev A, 2001, Pac Symp Biocomput, P459; REISER PK, 2001, ELECT T ARTIFICIAL I, V5, P233; Santillan M, 2001, P NATL ACAD SCI USA, V98, P1364, DOI 10.1073/pnas.98.4.1364; Say ACC, 1996, ARTIF INTELL, V83, P75, DOI 10.1016/0004-3702(95)00016-X; Somogyi R., 1996, COMPLEXITY, V1, P45; STRYER L, 1996, BIOCHEMISTRY; Tomita M, 1999, BIOINFORMATICS, V15, P72, DOI 10.1093/bioinformatics/15.1.72; VALDESPEREZ RE, 1994, J CHEM INF COMP SCI, V34, P976, DOI 10.1021/ci00020a036; von Dassow G, 2000, NATURE, V406, P188, DOI 10.1038/35018085; Weld D., 1990, READINGS QUALITATIVE	40	26	28	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	MAY 1	2005	21	9					2017	2026		10.1093/bioinformatics/bti255		10	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	921RS	WOS:000228783000034	
J	Iliadis, LS				Iliadis, LS			A decision support system applying an integrated fuzzy model for long-term forest fire risk estimation	ENVIRONMENTAL MODELLING & SOFTWARE			English	Article						fuzzy sets; semi-triangular membership function; semi-trapezoidal membership function; long-term forest fire risk	GREECE	Fire is the main cause of forest destruction in Mediterranean basin countries. Long-term prediction is intended for long-term planning which may serve to characterize and cluster regions as subject to high or low fire risk. This will enable the development of a rational and sensible forest fire prevention and protection policy. The problem with the existing approaches of long-term forest fire risk clustering is that they use crisp sets applying specific cluster boundaries. On the other hand, fuzzy algebra can provide reliable and flexible means of modeling that can be applied by a suitable decision support system. Given a specific area of interest, the evaluation of the long-term forest fire risk can be performed by the use of a triangular and a trapezoidal membership function. The decision support system that has been developed applies an inference mechanism that is based on various aspects of fuzzy sets and fuzzy machine learning techniques. The system has been applied in Greece, but it can be used on a global basis. Results show that the system successfully estimates the forest fire risky areas. (C) 2004 Elsevier Ltd. All rights reserved.	Democritus Univ Thrace, Lab Forest Informat, Dept Forestry & Management Environm & Nat Resourc, Orestiada 68200, Greece	Iliadis, LS (reprint author), Democritus Univ Thrace, Lab Forest Informat, Dept Forestry & Management Environm & Nat Resourc, Pantazidou 193, Orestiada 68200, Greece.	liliadis@fmenr.duth.gr					Adeli H., 1995, MACHINE LEARNING; ALEXANDER ME, 1982, CANADIAN FOREST FIRE; AYANZ JSM, 2003, EUROPEAN FOREST FIRE; BRILLINGER DR, 1986, RISK ASSESSMENT FORE; BURGAN RE, 1989, P 10 C FIR FOR MET O, P275; BURGAN RE, 1988, US J FOR, V86, P25; CHANG TC, 1991, FUZZY SET SYST, V44, P169, DOI 10.1016/0165-0114(91)90001-7; CHENEY P, 1991, C BUSHF MOD FIR DANG, P119; DEEMING JE, 1977, INT39 USDA FOR SERV; DEEMING JE, 1972, RM84 USDA FOR SERV R; DIMITRAKOPOULOS A, 1984, ANAL FOREST FIRE CAU; DOUKIDIS G, 1988, DEV EXPERT SYSTEMS; Iliadis LS, 2002, FOREST POLICY ECON, V4, P43, DOI 10.1016/S1389-9341(01)00079-X; Iliadis LS, 2002, J ENVIRON MANAGE, V65, P327, DOI 10.1006/jema.2002.0592; KAILIDHS D, 1990, FOREST FIRES; KAILIDHS D, 1969, FOREST FIRES GREECE; Kandel A, 1992, FUZZY EXPERT SYSTEMS; KATSANOS A, 1970, STUDY FOREST FIRES F; KEEMAN, 2001, LEARNING SOFT COMPUT; Kuncheva LI, 2000, ENVIRON MODELL SOFTW, V15, P161, DOI 10.1016/S1364-8152(99)00031-6; Leondes C.T., 1998, FUZZY LOGIC EXPERT S; LI BW, 1990, FUZZY SET SYST, V36, P37, DOI 10.1016/0165-0114(90)90076-I; LIN C, 2002, DEV SYSTEMS EVALUATI; LOPEZ AS, 2001, 2 MODELS EUROPEAN ST; MARKALAS S, 1996, FOREST FIRES GREECE; MCARTHUR AG, 1967, 107 COMM AUST FOR TI; NOBLE IR, 1980, AUST J ECOL, V5, P201, DOI 10.1111/j.1442-9993.1980.tb01243.x; Pal S.K., 1986, FUZZY MATH APPROACH; PAPASTAVROU A, 1988, LEGISLATIVE FRAMEWOR; Partridge D., 1995, KNOWLEDGE BASED INFO; PEARCE HG, 1993, P 12 INT C FIR FOR M, P534; Picton P., 2000, NEURAL NETWORKS; SPEED TP, 1980, 2 ROUTE RISK ASSESSM; SPEED TP, 1983, NEYM KIEF C WADS PAC; STOCKS BJ, 1989, FOREST CHRON, V65, P450; VELEZ R, 1997, P EUR SCH CLIM NAT H; VORISSIS D, 1999, DELFI P ATH, P159; ZADEH LA, 1968, INFORM CONTROL, V12, P94, DOI 10.1016/S0019-9958(68)90211-8; *LEON BEZ LTD, 1993, LEON US GUID; 2002, ECONOMIST, V364, P24	40	47	48	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1364-8152		ENVIRON MODELL SOFTW	Environ. Modell. Softw.	MAY	2005	20	5					613	621		10.1016/j.envsoft.2004.03.006		9	Computer Science, Interdisciplinary Applications; Engineering, Environmental; Environmental Sciences	Computer Science; Engineering; Environmental Sciences & Ecology	896XB	WOS:000226966600012	
J	Min, JH; Lee, YC				Min, JH; Lee, YC			Bankruptcy prediction using support vector machine with optimal choice of kernel function parameters	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						bankruptcy prediction; support vector machine; grid-search; kernel function; back-propagation neural networks	NEURAL-NETWORKS; DISCRIMINANT-ANALYSIS; FINANCIAL DISTRESS; SCORING MODELS; CLASSIFICATION; FAILURE; FRAMEWORK; RATIOS; SYSTEM	Bankruptcy prediction has drawn a lot of research interests in previous literature, and recent studies have shown that machine learning techniques achieved better performance than traditional statistical ones. This paper applies support vector machines (SVMs) to the bankruptcy prediction problem in an attempt to suggest a new model with better explanatory power and stability. To serve this purpose, we use a grid-search technique using 5-fold cross-validation to find out the optimal parameter values of kernel function of SVM. In addition, to evaluate the prediction accuracy of SVM, we compare its performance with those of multiple discriminant analysis (MDA), logistic regression analysis (Logit), and three-layer fully connected back-propagation neural networks (BPNs). The experiment results show that SVM outperforms the other methods. (c) 2005 Published by Elsevier Ltd.	Dongguk Univ, Coll Commerce & Econ, Gyeongbuk 780714, South Korea; Sogang Univ, Coll Business Adm, Seoul 121742, South Korea	Min, JH (reprint author), Dongguk Univ, Coll Commerce & Econ, Gyeongbuk 780714, South Korea.	jaemin@ccs.sogang.ac.kr; chanlee@dongguk.ac.kr					ALTMAN EI, 1994, J BANK FINANC, V18, P505, DOI 10.1016/0378-4266(94)90007-8; ALTMAN EI, 1968, J FINANC, V23, P4; Barniv R., 1997, International Journal of Intelligent Systems in Accounting, Finance and Management, V6, DOI 10.1002/(SICI)1099-1174(199709)6:3<177::AID-ISAF134>3.0.CO;2-D; Basel Committee on Banking Supervision, 1999, CRED RISK MOD CURR P; BEAVER WH, 1966, J ACCOUNTING RES, V4, P71, DOI 10.2307/2490171; BELL TB, 1990, P 1990 DEL TOUCH U K, P29; Bryant S. M., 1997, International Journal of Intelligent Systems in Accounting, Finance and Management, V6, DOI 10.1002/(SICI)1099-1174(199709)6:3<195::AID-ISAF132>3.0.CO;2-F; BUTTA P, 1994, AI EXPERT, V9, P34; Chang C. C., 2004, LIBSVM LIB SUPPORT V; Chen MC, 2003, EXPERT SYST APPL, V24, P433, DOI 10.1016/S0957-4174(02)00191-4; CIELEN AK, 1999, BANKRUPTCY PREDICTIO; Coakley J. R., 2000, International Journal of Intelligent Systems in Accounting, Finance and Management, V9, DOI 10.1002/1099-1174(200006)9:2<119::AID-ISAF182>3.0.CO;2-Y; COATS PK, 1993, FINANC MANAGE, V22, P142, DOI 10.2307/3665934; Cristianini N., 2000, INTRO SUPPORT VECTOR; CURRAM SP, 1994, J OPER RES SOC, V45, P440, DOI 10.1057/jors.1994.62; Davis R.H., 1992, IMA J MATH APPL BUSI, V4, P43, DOI 10.1093/imaman/4.1.43; DESAI VS, 1997, IMA J MATH APPL BUSI, V8, P324; Desai VS, 1996, EUR J OPER RES, V95, P24, DOI 10.1016/0377-2217(95)00246-4; DIAKOULAKI D, 1992, OMEGA-INT J MANAGE S, V20, P467, DOI 10.1016/0305-0483(92)90021-X; Dimitras AI, 1996, EUR J OPER RES, V90, P487, DOI 10.1016/0377-2217(95)00070-4; Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; Eisenbeis R., 1978, J BANK FINANC, V2, P205, DOI 10.1016/0378-4266(78)90012-2; ELMER PJ, 1988, FINANC MANAGE, V17, P66, DOI 10.2307/3666073; Emela A. B., 2003, SOCIOECONOMIC PLANNI, V37, P103, DOI 10.1016/S0038-0121(02)00044-7; FALBO P, 1991, OMEGA-INT J MANAGE S, V19, P275, DOI 10.1016/0305-0483(91)90045-U; FAN A, 2000, P INT JOINT C NEUR N; Fanning K. M., 1994, International Journal of Intelligent Systems in Accounting, Finance and Management, V3; FLETCHER D, 1993, INFORM MANAGE, V24, P159, DOI 10.1016/0378-7206(93)90064-Z; Gunn S.R., 1998, SUPPORT VECTOR MACHI; Hair Jr J. F., 1998, MULTIVARIATE DATA AN; Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428; Hsu C.-W., 2004, PRACTICAL GUIDE SUPP; Huang Z, 2004, DECIS SUPPORT SYST, V37, P543, DOI 10.1016/S0167-9236(03)00086-1; Jensen H. L., 1992, MANAGE FINANC, V18, P15; Jo H, 1996, EXPERT SYST APPL, V11, P415, DOI 10.1016/S0957-4174(96)00056-5; FRYDMAN H, 1985, J FINANC, V40, P269, DOI 10.2307/2328060; Kim KJ, 2003, NEUROCOMPUTING, V55, P307, DOI 10.1016/S0925-2312(03)00372-2; Lawrence S., 1997, P 14 NAT C ART INT A, P540; Lee G., 1999, J MANAGE INFORM SYST, V16, P63; LEE H, 1997, EXPERT SYSTEMS APPL, V13, P97; Lee KC, 1996, DECIS SUPPORT SYST, V18, P63, DOI 10.1016/0167-9236(96)00018-8; Lee TS, 2002, EXPERT SYST APPL, V23, P245, DOI 10.1016/S0957-4174(02)00044-1; Lopez JA, 2000, J BANK FINANC, V24, P151, DOI 10.1016/S0378-4266(99)00055-2; Malhotra R, 2002, EUR J OPER RES, V136, P190, DOI 10.1016/S0377-2217(01)00052-2; MARKHAM IS, 1995, DECISION SCI, V26, P229, DOI 10.1111/j.1540-5915.1995.tb01427.x; Martin D., 1977, J BANK FINANC, V1, P249, DOI 10.1016/0378-4266(77)90022-X; MOODY JE, 1992, ADV NEUR IN, V4, P847; ODOM M, 1990, P INT JOINT C NEUR N, P163; OHLSON JA, 1980, J ACCOUNTING RES, V18, P109, DOI 10.2307/2490395; Park CS, 2002, EXPERT SYST APPL, V23, P255, DOI 10.1016/S0957-4174(02)00045-3; PATUWO E, 1993, DECISION SCI, V24, P825, DOI 10.1111/j.1540-5915.1993.tb00491.x; PEEL MJ, 1986, OMEGA-INT J MANAGE S, V14, P5, DOI 10.1016/0305-0483(86)90003-4; Reichert A. K., 1983, J BUS ECON STAT, V1, P101, DOI 10.2307/1391851; ROY B, 1991, THEOR DECIS, V31, P49, DOI 10.1007/BF00134132; Sarle W., 1995, P 27 S INT COMP SCI, P352; Smith M., 1993, NEURAL NETWORKS STAT; SRINIVASAN V, 1990, EUR J OPER RES, V45, P293, DOI 10.1016/0377-2217(90)90194-G; SRINIVASAN V, 1988, FINANC MANAGE, V5, P32; TAM KY, 1992, MANAGE SCI, V38, P926, DOI 10.1287/mnsc.38.7.926; Tay FEH, 2001, OMEGA-INT J MANAGE S, V29, P309, DOI 10.1016/S0305-0483(01)00026-3; Van Gestel T, 2001, IEEE T NEURAL NETWOR, V12, P809, DOI 10.1109/72.935093; Vapnik VN, 1998, STAT LEARNING THEORY; Viaene S, 2002, J RISK INSUR, V69, P373, DOI 10.1111/1539-6975.00023; WEIGEND AS, 1994, PROCEEDINGS OF THE 1993 CONNECTIONIST MODELS SUMMER SCHOOL, P335; West D, 2000, COMPUT OPER RES, V27, P1131, DOI 10.1016/S0305-0548(99)00149-5; WILSON RL, 1994, DECIS SUPPORT SYST, V11, P545, DOI 10.1016/0167-9236(94)90024-8; Zhang GQ, 1999, EUR J OPER RES, V116, P16, DOI 10.1016/S0377-2217(98)00051-4; Zhang GQP, 2000, IEEE T SYST MAN CY C, V30, P451, DOI 10.1109/5326.897072	68	133	140	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	MAY	2005	28	4					603	614		10.1016/j.eswa.2004.12.008		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	913BD	WOS:000228124200001	
J	Xu, R; Wunsch, D				Xu, R; Wunsch, D			Survey of clustering algorithms	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Review						adaptive resonance theory (ART); clustering; clustering algorithm; cluster validation; neural networks; proximity; self-organizing feature map (SOFM)	HIDDEN MARKOV-MODELS; K-MEANS ALGORITHM; GENE-EXPRESSION DATA; NONLINEAR DIMENSIONALITY REDUCTION; TRAVELING-SALESMAN PROBLEM; SELF-ORGANIZING MAP; LARGE DATA SETS; PATTERN-RECOGNITION; NEURAL-NETWORKS; COMPONENT ANALYSIS	Data analysis plays an indispensable role for understanding various phenomena. Cluster analysis, primitive exploration with little or no prior knowledge, consists of research developed across a wide variety of communities. The diversity, on one hand, equips us with many tools. On the other hand, the profusion of options causes confusion. We survey clustering algorithms for data sets appearing in statistics, computer science, and machine learning, and illustrate their applications in some benchmark data sets, the traveling salesman problem, and bioinformatics, a new field attracting intensive efforts. Several tightly related topics, proximity measure, and cluster validation, are also discussed.	Univ Missouri, Dept Elect & Comp Engn, Rolla, MO 65409 USA	Xu, R (reprint author), Univ Missouri, Dept Elect & Comp Engn, Rolla, MO 65409 USA.	rxu@umr.edu; dwunsch@ece.umr.edu					Abascal F, 2002, BIOINFORMATICS, V18, P908, DOI 10.1093/bioinformatics/18.7.908; Aggarwal CC, 2002, IEEE T KNOWL DATA EN, V14, P210, DOI 10.1109/69.991713; Agrawal R., 1998, P ACM SIGMOD INT C M, P94, DOI 10.1145/276304.276314; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Alpert C. J., 1994, P ACM IEEE DES AUT C, P652, DOI 10.1145/196244.196603; ALPERT CJ, 1995, VLSI J, V19, P1; ALSULTAN KS, 1995, PATTERN RECOGN, V28, P1443, DOI 10.1016/0031-3203(95)00022-R; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; ANAGNOSTOPOULOS G, P IEEE INNS ENNS INT, V6, P59; ANAGNOSTOPOULOS GC, 2001, P IEEE INNS ENNS INT, V2, P1221; Anderberg M. R, 1973, CLUSTER ANAL APPL; BABU GP, 1994, PATTERN RECOGN, V27, P321, DOI 10.1016/0031-3203(94)90063-9; BABU GP, 1993, PATTERN RECOGN LETT, V14, P763; BACKER E, 1981, IEEE T PATTERN ANAL, V3, P66; Baldi P, 2001, BIOINFORMATICS, V17, P509, DOI 10.1093/bioinformatics/17.6.509; BALDI P, 1989, NEURAL NETWORKS, V2, P53, DOI 10.1016/0893-6080(89)90014-2; Baldi P., 2001, BIOINFORMATICS MACHI; BALL GH, 1967, BEHAV SCI, V12, P153, DOI 10.1002/bs.3830120210; Bandyopadhyay S, 2001, IEEE T SYST MAN CY C, V31, P120, DOI 10.1109/5326.923275; Baraldi A., 1999, TR99010; Baraldi A, 2002, IEEE T NEURAL NETWOR, V13, P645, DOI 10.1109/TNN.2002.1000130; Baraldi A, 1999, IEEE T SYST MAN CY B, V29, P778, DOI 10.1109/3477.809032; Barbara D., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347145; BELKIN M, 2002, ADV NEURAL INFORMATI, V14; Bellman R., 1961, ADAPTIVE CONTROL PRO; Ben-Dor A, 1999, J COMPUT BIOL, V6, P281, DOI 10.1089/106652799318274; Bengio Y., 1999, NEURAL COMPUTING SUR, V2, P129; Ben-Hur A, 2001, J MACHINE LEARNING R, V2, P125; BENHUR A, 2000, P INT C PATT REC, V2, P2724; Berkhin P., 2001, SURVEY CLUSTERING DA; Beyer K., 1999, P 7 INT C DAT THEOR, P217; Bezdek J. C., 1981, PATTERN RECOGNITION; Bezdek JC, 1998, IEEE T SYST MAN CY B, V28, P301, DOI 10.1109/3477.678624; BEZDEK JC, 1992, IEEE T NEURAL NETWOR, V3, P787, DOI 10.1109/72.159067; Bishop C.M., 1995, NEURAL NETWORKS PATT; BOBROWSKI L, 1991, IEEE T SYST MAN CYB, V21, P545, DOI 10.1109/21.97475; Bock HH, 1996, COMPUT STAT DATA AN, V23, P5, DOI 10.1016/0167-9473(96)88919-5; Bolten E, 2001, BIOINFORMATICS, V17, P935, DOI 10.1093/bioinformatics/17.10.935; Boujemaa N, 2000, PEACHFUZZ 2000 : 19TH INTERNATIONAL CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS, P133, DOI 10.1109/NAFIPS.2000.877405; BRADLEY P, 2000, P 15 INT C PATT REC, V2, P76, DOI 10.1109/ICPR.2000.906021; Bradley P. S., 1998, P 15 INT C MACH LEAR, P91; Bradley P. S., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; BROWN DE, 1992, PATTERN RECOGN, V25, P401, DOI 10.1016/0031-3203(92)90088-Z; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Burke J, 1999, GENOME RES, V9, P1135, DOI 10.1101/gr.9.11.1135; CARPENTER G, 1991, NEURAL NETWORKS, V4, P169; Carpenter G. A., 1988, IEEE COMPUT, V21, P77; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; CARPENTER GA, 1987, APPL OPTICS, V26, P4919, DOI 10.1364/AO.26.004919; CARPENTER GA, 1991, NEURAL NETWORKS, V4, P759, DOI 10.1016/0893-6080(91)90056-B; CARPENTER GA, 1990, NEURAL NETWORKS, V3, P129, DOI 10.1016/0893-6080(90)90085-Y; CARPENTER KE, 1992, HARVARD LIBR BULL, V3, P5; CELEUX G, 1992, COMPUT STAT DATA AN, V14, P315, DOI 10.1016/0167-9473(92)90042-E; Cheeseman P, 1996, ADV KNOWLEDGE DISCOV, P153; CHEN C, 1993, HDB PATER RECOGNITIO, P61; CHEN C, 1993, HDB PATTERN RECOGNIT, P3; Cherkassky V., 1998, LEARNING DATA CONCEP; Cherng J., 2001, P IEEE INT C DAT MIN, P83; Chiang JH, 2003, IEEE T FUZZY SYST, V11, P518, DOI 10.1109/TFUZZ.2003.814839; CHINRUNGRUENG C, 1995, IEEE T NEURAL NETWOR, V6, P157, DOI 10.1109/72.363440; CHU S, 2000, DATA MINING, V2, P515; Corchado J., 2000, Computing and Information Systems, V7; Cowgill MC, 1999, COMPUT MATH APPL, V37, P99, DOI 10.1016/S0898-1221(99)00090-5; Cummings CA, 2000, EMERG INFECT DIS, V6, P513; Dahlhaus E, 2000, J ALGORITHM, V36, P205, DOI 10.1006/jagm.2000.1090; DAVE RN, 1992, IEEE T NEURAL NETWOR, V3, P643, DOI 10.1109/72.159055; Dave RN, 1997, IEEE T FUZZY SYST, V5, P270, DOI 10.1109/91.580801; DELGADO M, 1997, P 6 IEEE INT C FUZZ, V1, P125, DOI 10.1109/FUZZY.1997.616356; Dembele D, 2003, BIOINFORMATICS, V19, P973, DOI 10.1093/bioinformatics/btg119; Duda R. O., 2001, PATTERN CLASSIFICATI; Dunn J. C., 1973, Journal of Cybernetics, V3; Duran B., 1974, CLUSTER ANAL SURVEY; Durbin R., 1998, BIOL SEQUENCE ANAL P; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Eisen MB, 1999, METHOD ENZYMOL, V303, P179; El-Sonbaty Y, 1998, IEEE T FUZZY SYST, V6, P195, DOI 10.1109/91.669013; Eltoft T, 1998, IEEE T NEURAL NETWOR, V9, P1021, DOI 10.1109/72.712183; Enright AJ, 2000, BIOINFORMATICS, V16, P451, DOI 10.1093/bioinformatics/16.5.451; Eschrich S, 2003, IEEE T FUZZY SYST, V11, P262, DOI 10.1109/TFUZZ.2003.809902; Ester M., 1996, P 2 INT C KNOWL DISC, P226; Estivill-Castro V., 2000, PRICAI 2000. Topics in Artificial Intelligence. 6th Pacific Rim International Conference on Artificial Intelligence. Proceedings (Lecture Notes in Artificial Intelligence Vol.1886); ESTIVILLCASTRO V, 1999, P 9 INT S SPAT DAT H; Everitt B., 2001, CLUSTER ANAL; Fasulo D., 1999, 010302 U WASH DEP CO; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1023/A:1022852608280; Fisher RA, 1936, ANN EUGENIC, V7, P179; FOGEL DB, 1994, IEEE T NEURAL NETWOR, V5, P1; FORGY EW, 1965, BIOMETRICS, V21, P768; Fraley C, 2002, J AM STAT ASSOC, V97, P611, DOI 10.1198/016214502760047131; Fraley C, 1999, J CLASSIF, V16, P297, DOI 10.1007/s003579900058; FRIEDMAN JH, 1987, J AM STAT ASSOC, V82, P249, DOI 10.2307/2289161; Frigui H, 1999, IEEE T PATTERN ANAL, V21, P450, DOI 10.1109/34.765656; Fritzke B., 1997, SOME COMPETITIVE LEA; Gabrys B, 2000, IEEE T NEURAL NETWOR, V11, P769, DOI 10.1109/72.846747; Ganti V, 1999, PROC INT CONF DATA, P502, DOI 10.1109/ICDE.1999.754966; GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473; Geva AB, 1999, IEEE T FUZZY SYST, V7, P723, DOI 10.1109/91.811242; Ghosh D, 2002, BIOINFORMATICS, V18, P275, DOI 10.1093/bioinformatics/18.2.275; GHOZEIL A, 1996, P 1 ANN C GEN PROGR, P512; Girolami M, 2002, IEEE T NEURAL NETWOR, V13, P780, DOI 10.1109/TNN.2002.1000150; Glover F., 1989, ORSA Journal on Computing, V1; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gordon A, 1999, CLASSIFICATION; Gordon A., 1998, DATA SCI CLASSIFICAT, P22; GOWER JC, 1971, BIOMETRICS, V27, P857, DOI 10.2307/2528823; GROSSBERG S, 1976, BIOL CYBERN, V23, P187; Grunwald P. D., 1998, P 14 INT C UNC ART I, P183; Guan XJ, 1998, BIOINFORMATICS, V14, P783, DOI 10.1093/bioinformatics/14.9.783; Guha S., 1998, P ACM SIGMOD INT C M, P73, DOI 10.1145/276304.276312; Guha S, 2000, INFORM SYST, V25, P345, DOI 10.1016/S0306-4379(00)00022-3; Gupata S., 1999, P 1 INT C DAT WAR KN, P203; Guralnik V., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989516; Gusfield Dan, 1997, ALGORITHMS STRINGS T; Halkidi M, 2002, SIGMOD RECORD, V31; Hall LO, 1999, IEEE T EVOLUT COMPUT, V3, P103, DOI 10.1109/4235.771164; Hammah RE, 2000, IEEE T PATTERN ANAL, V22, P1467, DOI 10.1109/34.895981; Hansen P, 2001, PATTERN RECOGN, V34, P405, DOI 10.1016/S0031-3203(99)00216-2; Hansen P, 1997, MATH PROGRAM, V79, P191, DOI 10.1007/BF02614317; Harary F, 1969, GRAPH THEORY; HARTIAN J, 1975, CLUSTERING ALGORITHM; Hartuv E, 2000, INFORM PROCESS LETT, V76, P175, DOI 10.1016/S0020-0190(00)00142-3; Hathaway RJ, 2000, IEEE T FUZZY SYST, V8, P576, DOI 10.1109/91.873580; Hathaway RJ, 2001, IEEE T SYST MAN CY B, V31, P735, DOI 10.1109/3477.956035; HAY B, 2001, P INT TECHN WEB PERS, V1, P1; Haykin S., 1999, NEURAL NETWORKS COMP; HE Q, 1999, UIUCLIS19996 IRG; HEALY MJ, 1993, IEEE T NEURAL NETWOR, V4, P9, DOI 10.1109/72.182691; Hinneburg A., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Hinneburg A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P506; Hoeppner F, 1997, IEEE T FUZZY SYST, V5, P599, DOI 10.1109/91.649912; Hoey J., 2002, Proceedings of Fifth IEEE International Conference on Automatic Face Gesture Recognition, DOI 10.1109/AFGR.2002.1004179; Hofmann T, 1997, IEEE T PATTERN ANAL, V19, P1, DOI 10.1109/34.566806; Holland J. H., 1975, ADAPTION NATURAL ART; Hoppner Frank, 1999, FUZZY CLUSTER ANAL M; HUANG JX, 1995, NEURAL NETWORKS, V8, P203, DOI 10.1016/0893-6080(94)00073-U; Huang ZX, 1998, DATA MIN KNOWL DISC, V2, P283, DOI 10.1023/A:1009769707641; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; Hughey R, 1996, COMPUT APPL BIOSCI, V12, P95; Hung M.-C., 2001, P IEEE INT C DAT MIN, P225; Hunt L, 1999, AUST NZ J STAT, V41, P153; HWANG JN, 1989, IEEE T ACOUST SPEECH, V37, P1967, DOI 10.1109/29.45543; Hyvarinen A., 1999, NEURAL COMPUTING SUR, V2, P94; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Jiang DX, 2004, IEEE T KNOWL DATA EN, V16, P1370; JUTTEN C, 1991, SIGNAL PROCESS, V24, P1, DOI 10.1016/0165-1684(91)90079-X; Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616; Karayiannis NB, 1996, IEEE T NEURAL NETWOR, V7, P1062, DOI 10.1109/72.536304; Karayiannis NB, 1997, IEEE T NEURAL NETWOR, V8, P505, DOI 10.1109/72.572091; Karhunen J, 1997, IEEE T NEURAL NETWOR, V8, P486, DOI 10.1109/72.572090; KARYPIS G, 1999, IEEE COMPUT, V32, P68, DOI DOI 10.1109/2.781637; KATHARI R, 1999, PATTERN RECOGNIT LET, V20, P405; Kaufman L., 1990, FINDING GROUPS DATA; Kent WJ, 2000, GENOME RES, V10, P1115, DOI 10.1101/gr.10.8.1115; Kersten P., 1997, P 6 IEEE INT C FUZZ, V2, P957, DOI 10.1109/FUZZY.1997.622838; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Kirkpatrick S., 1983, SCIENCE, V220, P671; Kleinberg J., 2002, P 2002 C ADV NEUR IN, V15, P463; KOHAVI R, 1995, P 14 INT JOINT C ART, P338; Kohonen T, 2000, IEEE T NEURAL NETWOR, V11, P574, DOI 10.1109/72.846729; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Kohonen T, 2001, SELF ORG MAPS; Kolatch E, 2001, CLUSTERING ALGORITHM; Kolen JF, 2002, IEEE T FUZZY SYST, V10, P263, DOI 10.1109/91.995126; Krishna K, 1999, IEEE T SYST MAN CY B, V29, P433, DOI 10.1109/3477.764879; Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, DOI 10.1109/91.227387; KRISHNAPURAM R, 1992, IEEE T NEURAL NETWOR, V3, P663, DOI 10.1109/72.159056; KRISHNAPURAM R, 1995, IEEE T FUZZY SYST, V3, P29, DOI 10.1109/91.366564; KROGH A, 1994, J MOL BIOL, V235, P1501, DOI 10.1006/jmbi.1994.1104; LANCE GN, 1967, COMPUT J, V9, P373; Lander ES, 2001, NATURE, V409, P860, DOI 10.1038/35057062; LAW MH, 2000, P INT C PATT REC ICP, V2, P195, DOI 10.1109/ICPR.2000.906046; Leung Y, 2000, IEEE T PATTERN ANAL, V22, P1396; Levine E, 2001, NEURAL COMPUT, V13, P2573, DOI 10.1162/089976601753196030; Li C, 2002, IEEE T KNOWL DATA EN, V14, P673, DOI 10.1109/TKDE.2002.1019208; Li C, 2002, IEEE T KNOWL DATA EN, V14, P792; LI C, 1999, LECT NOTES COMPUTER, V1642; Li WZ, 2001, BIOINFORMATICS, V17, P282, DOI 10.1093/bioinformatics/17.3.282; Likas A, 2003, PATTERN RECOGN, V36, P451; LIN S, 1973, OPER RES, V21, P498, DOI 10.1287/opre.21.2.498; Lipshutz RJ, 1999, NAT GENET, V21, P20, DOI 10.1038/4447; Liu G. L., 1968, INTRO COMBINATORIAL; Lozano JA, 1999, PATTERN RECOGN LETT, V20, P911, DOI 10.1016/S0167-8655(99)00057-4; MacQueen J. B., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; Madeira SC, 2004, IEEE ACM T COMPUT BI, V1, P24, DOI 10.1109/TCBB.2004.2; MAN Y, 1994, IEEE T PATTERN ANAL, V16, P855, DOI 10.1109/34.308484; Mao JC, 1996, IEEE T NEURAL NETWOR, V7, P16; Maulik U, 2000, PATTERN RECOGN, V33, P1455, DOI 10.1016/S0031-3203(99)00137-5; McLachlan G., 1999, J STAT SOFTWARE, V4; Peel D, 2000, STAT COMPUT, V10, P339, DOI 10.1023/A:1008981510081; McLachlan G, 1997, EM ALGORITHM EXTENSI; McLachlan G., 2000, FINITE MIXTURE MODEL; Miller C, 1999, BIOINFORMATICS, V15, P111, DOI 10.1093/bioinformatics/15.2.111; Miller RT, 1999, GENOME RES, V9, P1143, DOI 10.1101/gr.9.11.1143; Miller W, 2001, BIOINFORMATICS, V17, P391, DOI 10.1093/bioinformatics/17.5.391; MILLIGAN GW, 1985, PSYCHOMETRIKA, V50, P159, DOI 10.1007/BF02294245; Mollineda RA, 2000, FR ART INT, V56, P19; Moore B., 1989, P 1988 CONN MOD SUMM, P174; Moore SK, 2001, IEEE SPECTRUM, V38, P54, DOI 10.1109/6.908856; Moreau Y, 2002, P IEEE, V90, P1722, DOI 10.1109/JPROC.2002.804681; MORZY T, 1999, P ADV DAT INF SYST, P179; Mulder SA, 2003, NEURAL NETWORKS, V16, P827, DOI 10.1016/S0893-6080(03)00130-8; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; MURTAGH F, 1983, COMPUT J, V26, P354; Murtagh F, 2000, COMPUT J, V43, P107, DOI 10.1093/comjnl/43.2.107; Ng RT, 2002, IEEE T KNOWL DATA EN, V14, P1003, DOI 10.1109/TKDE.2002.1033770; Oates T., 2001, LECT NOTES COMPUTER, V1828, P35; OJA E, 1992, NEURAL NETWORKS, V5, P927, DOI 10.1016/S0893-6080(05)80089-9; Oliver J J, 1996, P 13 INT C MACH LEAR, P364; OLSON CF, 1995, PARALLEL COMPUT, V21, P1313, DOI 10.1016/0167-8191(95)00017-I; Ordonez C, 2004, IEEE T KNOWL DATA EN, V16, P909, DOI 10.1109/TKDE.2004.25; Owsley LMD, 1997, IEEE T SIGNAL PROCES, V45, P2787, DOI 10.1109/78.650105; PAL NR, 1995, IEEE T FUZZY SYST, V3, P370, DOI 10.1109/91.413225; PAL NR, 1993, IEEE T NEURAL NETWOR, V4, P549, DOI 10.1109/72.238310; Patane G, 2001, NEURAL NETWORKS, V14, P1219, DOI 10.1016/S0893-6080(01)00104-6; Patane G, 2002, IEEE T NEURAL NETWOR, V13, P1285, DOI 10.1109/TNN.2002.804226; PEARSON WR, 1988, P NATL ACAD SCI USA, V85, P2444, DOI 10.1073/pnas.85.8.2444; Pelleg D., 2000, P 17 INT C MACH LEAR, P727; Pena JM, 1999, PATTERN RECOGN LETT, V20, P1027, DOI 10.1016/S0167-8655(99)00069-0; Pizzuti C, 2003, IEEE T KNOWL DATA EN, V15, P629, DOI 10.1109/TKDE.2003.1198395; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RALFHERWIG A, 1999, GENOME RES, P1093; Rauber A., 2000, J INFORMATION ORG SC, V24, P195; Ridella S, 1998, NEURAL COMPUT APPL, V7, P37, DOI 10.1007/BF01413708; Rissanen JJ, 1996, IEEE T INFORM THEORY, V42, P40, DOI 10.1109/18.481776; Rose K, 1998, P IEEE, V86, P2210, DOI 10.1109/5.726788; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Sankoff David, 1999, TIME WARPS STRING ED; Sasson Ori, 2002, Bioinformatics, V18 Suppl 1, pS14; Scherf U, 2000, NAT GENET, V24, P236, DOI 10.1038/73439; Scheunders P, 1997, PATTERN RECOGN LETT, V18, P1379, DOI 10.1016/S0167-8655(97)00116-5; Scholkopf B., 2002, LEARNING KERNELS SUP; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SCOTT G, 2001, P C EV COMP PISC NJ, V2, P737; SEBASTIANI P, 2000, LECT NOTES ARTIF INT, V1828, P11; SELIM SZ, 1991, PATTERN RECOGN, V24, P1003, DOI 10.1016/0031-3203(91)90097-O; Shamir R, 2002, CURRENT TOPICS COMPU, P269; Sharan R., 2000, Proceedings. Eighth International Conference on Intelligent Systems for Molecular Biology; Sheikholeslami G., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Simpson P. K., 1993, IEEE Transactions on Fuzzy Systems, V1, DOI 10.1109/TFUZZ.1993.390282; SMITH TF, 1980, J GEOL, V88, P451; Cadez I. V., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347119; Smyth P., 1999, P 7 INT WORKSH AI ST, P299; Smyth P., 1996, P 2 INT C KNOWL DISC, P126; Smyth P, 2000, STAT COMPUT, V10, P63, DOI 10.1023/A:1008940618127; Smyth P, 1997, ADV NEUR IN, V9, P648; SNEATH PHA, 1957, J GEN MICROBIOL, V17, P201; SOMERVUO P, 2000, LECT NOTES ARTIF INT, V1967, P76; Spath H., 1980, CLUSTER ANAL ALGORIT; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Stoffel K., 1999, P EUR 99 PAR PROC, P1451; Su MS, 2001, IEEE T PATTERN ANAL, V23, P674; Su MC, 2000, IEEE T NEURAL NETWOR, V11, P721, DOI 10.1109/72.846743; SUN R, 2000, LNAI, V1828; Sung CS, 2000, PATTERN RECOGN, V33, P849, DOI 10.1016/S0031-3203(99)00090-4; T SOrensen, 1948, BIOL SKRIFTER, V5, P1; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Tavazoie S, 1999, NAT GENET, V22, P281; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tibshirani R, 1999, J ROY STAT SOC B, V61, P529, DOI 10.1111/1467-9868.00191; TIBSHIRANI R, CLUSTERING METHODS A; Tseng LY, 2001, PATTERN RECOGN, V34, P415, DOI 10.1016/S0031-3203(00)00005-4; Vapnik VN, 1998, STAT LEARNING THEORY; Venter JC, 2001, SCIENCE, V291, P1304, DOI 10.1126/science.1058040; Vesanto J, 2000, IEEE T NEURAL NETWOR, V11, P586, DOI 10.1109/72.846731; Wagstaff K., 2001, P 18 INT C MACH LEAR, P577; Wallace C. S., 1994, Proceedings of the 7th Australian Joint Conference on Artificial Intelligence. Artificial Intelligence. AI'94. Sowing the Seeds for the Future; Wang H., 2002, P 2002 ACM SIGMOD IN, P394; Wei C., 2000, P 33 HAW INT C SYST, P1; Williamson JR, 1996, NEURAL NETWORKS, V9, P881, DOI 10.1016/0893-6080(95)00115-8; WINDHAM MP, 1992, J AM STAT ASSOC, V87, P1188, DOI 10.2307/2290659; Wu SH, 2004, IEEE T INF TECHNOL B, V8, P5, DOI 10.1109/TITB.2004.824724; NEEDLEMA.SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4; WUNSCH DC, 1993, IEEE T NEURAL NETWOR, V4, P673, DOI 10.1109/72.238321; Wunsch II D.C., 1991, THESIS U WASHINGTON; Xiong Y., 2002, P IEEE INT C DAT MIN, P717; XU R, 2002, P 2002 INT JOINT C N, V1, P300; Xu Y, 2002, BIOINFORMATICS, V18, P536, DOI 10.1093/bioinformatics/18.4.536; YAGER RR, 1994, IEEE T SYST MAN CYB, V24, P1279, DOI 10.1109/21.299710; Yager RR, 2000, IEEE T SYST MAN CY B, V30, P835, DOI 10.1109/3477.891145; Yeung KY, 2001, BIOINFORMATICS, V17, P309, DOI 10.1093/bioinformatics/17.4.309; Young F., 1987, MULTIDIMENSIONAL SCA; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; Zhang JS, 2004, IEEE T FUZZY SYST, V12, P209, DOI 10.1109/TFUZZ.2004.825079; Zhang T., 1996, P 1996 ACM SIGMOD IN, P103, DOI DOI 10.1145/235968.233324; Zhang YJ, 2002, IEEE T NEURAL NETWOR, V13, P369, DOI 10.1109/72.991422; Zhuang XH, 1996, IEEE T IMAGE PROCESS, V5, P1293; *U MINN, 2000, 00034 U MINN	294	736	824	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	MAY	2005	16	3					645	678		10.1109/TNN.2005.845141		34	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	923KX	WOS:000228909900013	
J	Myrtveit, I; Stensrud, E; Shepperd, M				Myrtveit, I; Stensrud, E; Shepperd, M			Reliability and validity in comparative studies of software prediction models	IEEE TRANSACTIONS ON SOFTWARE ENGINEERING			English	Article						software metrics; cost estimation; cross-validation; empirical methods; arbitrary function approximators; machine learning; estimation by analogy; regression analysis; simulation; reliability; validity; accuracy indicators	COST ESTIMATION; REGRESSION; SIMULATION; ACCURACY; SYSTEMS	Empirical studies on software prediction models do not converge with respect to the question "which prediction model is best?" The reason for this lack of convergence is poorly understood. In this simulation study, we have examined a frequently used research procedure comprising three main ingredients: a single data sample, an accuracy indicator, and cross validation. Typically, these empirical studies compare a machine learning model with a regression model. In our study, we use simulation and compare a machine learning and a regression model. The results suggest that it is the research procedure itself that is unreliable. This lack of reliability may strongly contribute to the lack of convergence. Our findings thus cast some doubt on the conclusions of any study of competing software prediction models that used this research procedure as a basis of model comparison. Thus, we need to develop more reliable research procedures before we can have confidence in the conclusions of comparative studies of software prediction models.	Norwegian Sch Management BI, N-1301 Sandvika, Norway; Myrtveit & Stensrud ANS, N-0752 Oslo, Norway; Bournemouth Univ, Sch Design Engn & Comp, Bournemouth BH12 5BB, Dorset, England	Myrtveit, I (reprint author), Norwegian Sch Management BI, Elias Smiths Vei 15,Box 580, N-1301 Sandvika, Norway.	ingunn.myrtveit@bi.no; erik.stensrud@ieee.org; mshepper@bmth.ac.uk	Shepperd, Martin/F-9683-2013	Shepperd, Martin/0000-0003-1874-6145			Briand L. C., 2000, Proceedings of the 2000 International Conference on Software Engineering. ICSE 2000 the New Millennium, DOI 10.1109/ICSE.2000.870428; Briand L., 2001, ENCY SOFTWARE ENG; BRIAND LC, 1998, P 9 EUR SOFTW CONTR, P4; BRIAND LC, 1992, IEEE T SOFTWARE ENG, V18, P931, DOI 10.1109/32.177363; BRIAND LC, 1993, IEEE T SOFTWARE ENG, V19, P1028, DOI 10.1109/32.256851; Briand L. C., 1999, Proceedings of the 1999 International Conference on Software Engineering (IEEE Cat. No.99CB37002), DOI 10.1109/ICSE.1999.841021; CARMINES EG, 1979, SAGE U PAPERS; Conte S, 1986, SOFTWARE ENG METRICS; Dolado JJ, 2001, INFORM SOFTWARE TECH, V43, P61, DOI 10.1016/S0950-5849(00)00137-3; EFRON B, 1983, AM STAT, V37, P36, DOI 10.2307/2685844; Foss T, 2003, IEEE T SOFTWARE ENG, V29, P985, DOI 10.1109/TSE.2003.1245300; FOSS T, 2001, P 12 EUR SOFTW CONTR, P9; Gray A. R., 1999, Empirical Software Engineering, V4, DOI 10.1023/A:1009849100780; Jeffery R, 2001, P 7 INT SOFTW METR S, P16; JEFFERY R, 1999, P ESCOM 99 HERSTM EN, P37; JORGENSEN M, 1995, IEEE T SOFTWARE ENG, V21, P674, DOI 10.1109/32.403791; Kitchenham B, 1998, IEEE T SOFTWARE ENG, V24, P278, DOI 10.1109/32.677185; Kitchenham B. A., 2001, IEE Proceedings-Software, V148, DOI 10.1049/ip-sen:20010506; Kitchenham B., 1993, Proceedings First International Software Metrics Symposium (Cat. No.93TH0518-1), DOI 10.1109/METRIC.1993.263805; Kitchenham BA, 2002, INFORM SOFTWARE TECH, V44, P13, DOI 10.1016/S0950-5849(01)00204-X; Kotz S., 1982, ENCY STAT SCI; KUHA J, 2004, MODEL ASSESSMENT MOD; Mair C, 2000, J SYST SOFTWARE, V53, P23, DOI 10.1016/S0164-1212(00)00005-4; MAIR C, 2004, P C EMP ASS SOFTW EN; MIYAZAKI Y, 1994, J SYST SOFTWARE, V27, P3, DOI 10.1016/0164-1212(94)90110-4; MUKHOPADHYAY T, 1992, MIS Q            JUN, P155; Myrtveit I, 1999, IEEE T SOFTWARE ENG, V25, P510, DOI 10.1109/32.799947; Nesi P, 1998, J SYST SOFTWARE, V42, P89, DOI 10.1016/S0164-1212(97)10021-8; Nunnally J. C., 1994, PSYCHOMETRIC THEORY; Pickard L., 1999, Proceedings Sixth International Software Metrics Symposium (Cat. No.PR00403), DOI 10.1109/METRIC.1999.809734; Samson B, 1997, INFORM SOFTWARE TECH, V39, P55, DOI 10.1016/0950-5849(96)01124-X; Shepperd M, 2001, IEEE T SOFTWARE ENG, V27, P1014, DOI 10.1109/32.965341; Shepperd M, 2001, IEEE T SOFTWARE ENG, V27, P987, DOI 10.1109/32.965339; Shepperd M, 1997, IEEE T SOFTWARE ENG, V23, P736, DOI 10.1109/32.637387; SRINIVASAN K, 1995, IEEE T SOFTWARE ENG, V21, P126, DOI 10.1109/32.345828; Stensrud E., 1998, Proceedings Fifth International Software Metrics Symposium. Metrics (Cat. No.98TB100262), DOI 10.1109/METRIC.1998.731247; Stensrud E, 2003, EMPIR SOFTW ENG, V8, P139, DOI 10.1023/A:1023010612345; Stensrud E, 2003, IEEE T SOFTWARE ENG, V29, P398, DOI 10.1109/TSE.2003.1199070; Strike K, 2001, IEEE T SOFTWARE ENG, V27, P890, DOI 10.1109/32.962560; Taylor C., 1994, MACHINE LEARNING NEU; Vicinanza S.S., 1991, INFORMATION SYSTEMS, V2, P243, DOI 10.1287/isre.2.4.243; Walkerden F., 1999, Empirical Software Engineering, V4, DOI 10.1023/A:1009872202035	42	51	51	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0098-5589		IEEE T SOFTWARE ENG	IEEE Trans. Softw. Eng.	MAY	2005	31	5					380	391		10.1109/TSE.2005.58		12	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	929VC	WOS:000229373700002	
J	Xu, CS; Maddage, NC; Shao, X				Xu, CS; Maddage, NC; Shao, X			Automatic music classification and summarization	IEEE TRANSACTIONS ON SPEECH AND AUDIO PROCESSING			English	Article						clustering; music characterization; music classification; music summarization; support vector machines	COMPRESSED DOMAIN	Automatic music classification and summarization are very useful to music indexing, content-based music retrieval and on-line music distribution, but it is a challenge to extract the most common and salient themes from unstructured raw music data. In this paper, we propose effective algorithms to automatically classify and summarize music content. Support vector machines are applied to classify music into pure music and vocal music by learning from training data. For pure music and vocal music, a number of features are extracted to characterize the music content, respectively. Based on calculated features, a clustering algorithm is applied to structure the music content. Finally, a music summary is created based on the clustering results and domain knowledge related to pure and vocal music. Support vector machine learning shows a better performance in music classification than traditional Euclidean distance methods and hidden Markov model methods. Listening tests are conducted to evaluate the quality of summarization. The experiments on different genres of pure and vocal music illustrate the results of summarization are significant and effective.	Inst Infocomm Res, Singapore 119613, Singapore	Xu, CS (reprint author), Inst Infocomm Res, Singapore 119613, Singapore.	xucs@i2r.a-star.edu.sg; maddage@i2r.a-star.edu.sg; shaoxi@i2r.a-star.edu.sg					Chew CM, 2001, LECT NOTES COMPUT SC, V2195, P490; Chin J. P., 1988, P SIGCHI C HUM FACT, P213, DOI 10.1145/57167.57203; COOPER M, 2002, P INT C MUS INF RETR; Deller J. R., 1999, DISCRETE TIME PROCES; Duda R., 2000, PATTERN CLASSIFICATI; ELLIS GM, 1994, ELECT FILTER ANAL SY; ELMALEH K, 2000, P ICASSP00 IST TURK; GAO S, P 4 IEEE PCM 2003 SI; GONG Y, 2001, P IEEE INT C MULT EX, P788; HORI C, 1998, P INT C SPOK LANG PR; JAOCHIMS T, 1998, P EUR C MACH LEARN C; KIMBER D, 1996, P INT C SYDN AUSTR; KOUMPIS K, 1998, P INT C SPOK LANG PR; KRAFT R, 2001, Patent No. 6225546; LOGAN B, 2000, P IEEE INT C AUD SPE; LU L, 2001, P ACM MUTL 2001 OTT, V6; Mani I, 1999, ADV AUTOMATIC TEXT S; MARTIN KD, 1998, 136 M ASA OCT; Narmour E., 1990, ANAL COGNITION BASIC; PAPAGEORGIOU C, 1998, P INT C COMP VIS BOM; PEETERS G, 2002, P INT C MUS INF RETR; Rabiner L, 1993, FUNDAMENTALS SPEECH; REN F, 1998, AUTOMATIC EXTRACT NL, V98, P71; Scheirer E, 1997, P ICASSP 97, V2, P1331, DOI 10.1109/ICASSP.1997.596192; SOUNDERS J, 1996, P ICASSP96 ATL GA, V2, P993; Sun XD, 2001, LECT NOTES COMPUT SC, V2195, P450; XU C, P 3 IEEE PCM 2002 TA, P928; YAHIAOUI I, 2001, P ICME JAP, P792; ZHANG T, 1999, P SPIE 1999 SAN JOS, V4, P78	29	30	31	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1063-6676		IEEE T SPEECH AUDI P	IEEE Trans. Speech Audio Process.	MAY	2005	13	3					441	450		10.1109/TSA.2004.840939		10	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	916RQ	WOS:000228403900013	
J	Tan, KC; Yu, Q; Lee, TH				Tan, KC; Yu, Q; Lee, TH			A distributed evolutionary classifier for knowledge discovery in data mining	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART C-APPLICATIONS AND REVIEWS			English	Article						classification; coevolution; data mining; evolutionary algorithms (EA)	NEURAL-NETWORKS; COEVOLUTION; INDUCTION; DESIGN	This paper presents a distributed coevolutionary classifier (DCC) for extracting comprehensible rules in data mining. It allows different species to be evolved cooperatively and simultaneously, while the computational workload is shared among multiple computers over the Internet. Through the intercommunications among different species of rules and rule sets in a distributed manner, the concurrent processing and computational speed of the coevolutionary classifiers are enhanced. The advantage and performance of the proposed DCC are validated upon various datasets obtained from the UCI machine learning repository. It is shown that the predicting accuracy of DCC is robust and the computation time is reduced as the number of remote engines increases. Comparison results illustrate that the DCC produces good classification rules for the datasets, which are competitive as compared to existing classifiers in literature.	Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore	Tan, KC (reprint author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore.	eletankc@nus.edu.sg					ANDRE D, 1995, WORKSHOP GENETIC PRO, V95, P111; Banzhaf W., 1998, GENETIC PROGRAMMING; Brameier M, 2001, IEEE T EVOLUT COMPUT, V5, P17, DOI 10.1109/4235.910462; Cantu-Paz E., 1998, CALCULATEURS PARALLE, V10, P141; Cattral R., 1999, P C EV COMP CEC99, V1, P125; Chambers J, 1983, GRAPHICAL METHODS DA; CHEN YW, 1996, P 13 INT C PATT REC, V3, P694; CHONG FS, 1997, THESIS U BIRMINGHAM; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; CRISTEA V, 2000, P IEEE C EV COMP, V1, P431, DOI 10.1109/CEC.2000.870328; DEFALCO I, 2002, APPL SOFT COMPUT, V23, P1; DEJONG KA, 1993, MACH LEARN, V13, P161, DOI 10.1023/A:1022617912649; Domingos P, 1996, MACH LEARN, V24, P141, DOI 10.1023/A:1018006431188; FIDELIS MV, 2000, P 2000 C EV COMP, V1, P805, DOI 10.1109/CEC.2000.870381; Frank E., 1998, P 15 INT C MACH LEAR, P144; Freitas A. A., 2002, ADV EVOLUTIONARY COM; Giordana A, 1995, EVOL COMPUT, V3, P375, DOI 10.1162/evco.1995.3.4.375; Hruschka E. R., 2000, International Journal of Computers, Systems and Signals, V1; Ishibuchi H, 2001, INFORM SCIENCES, V136, P109, DOI 10.1016/S0020-0255(01)00144-X; JANIKOW CZ, 1993, MACH LEARN, V13, P189, DOI 10.1023/A:1022669929488; JOHN GH, 1999, P 11 C UNC ART INT S, P338; Kishore JK, 2000, IEEE T EVOLUT COMPUT, V4, P242, DOI 10.1109/4235.873235; Wong ML, 2000, GENET PROGR SER, V3, P1; Liu Y, 2001, IEEE C EVOL COMPUTAT, P1101, DOI 10.1109/CEC.2001.934314; Mendes R. R. F., 2001, LECT NOTES ARTIF INT, V2168, P314; Michalewicz Z, 1994, GENETIC ALGORITHMS D; Michalski R. S., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; MICHALSKI RS, 1983, ARTIF INTELL, V20, P111, DOI 10.1016/0004-3702(83)90016-4; Mitchell T, 1997, MACHINE LEARNING; Montgomery D.C., 2001, ENG STAT; MORIARTY DE, 1997, SYMBIOTIC EVOLUTION; Muni DP, 2004, IEEE T EVOLUT COMPUT, V8, P183, DOI 10.1109/TEVC.2004.825567; NANG J, 1994, J SOC CINSTRUM CONTR, V33, P186; Noda E., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), DOI 10.1109/CEC.1999.782601; PAECHTER B, 2000, P IEEE C EV COMP, V2, P951, DOI 10.1109/CEC.2000.870746; Paredis Jan, 1996, Artificial Life, V2, P355, DOI 10.1162/artl.1995.2.4.355; Pena-Reyes CA, 2001, IEEE T FUZZY SYST, V9, P727, DOI 10.1109/91.963759; POLO AR, 2000, P 20 INT C CHIL COMP, P14; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; RADCLIFFE NJ, 1994, EPCCTR9409 U ED PAR; Rivest R. L., 1987, Machine Learning, V2, DOI 10.1007/BF00058680; Rosin CD, 1997, EVOL COMPUT, V5, P1, DOI 10.1162/evco.1997.5.1.1; Rouwhorst S.E., 2000, P IEEE C EV COMP, V1, P633, DOI 10.1109/CEC.2000.870357; Setiono R, 1997, NEUROCOMPUTING, V17, P1, DOI 10.1016/S0925-2312(97)00038-6; Sleem A., 2000, Proceedings ISCC 2000. Fifth IEEE Symposium on Computers and Communications, DOI 10.1109/ISCC.2000.860632; Tan KC, 2003, ARTIF INTELL MED, V27, P129, DOI 10.1016/S0933-3657(03)00002-2; Tan K. C., 2002, Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No.02TH8600), DOI 10.1109/CEC.2002.1004431; Tan KC, 2002, ARTIF INTELL MED, V25, P169, DOI 10.1016/S0933-3657(02)00014-3; Tan KC, 2003, IEEE T SYST MAN CY C, V33, P325, DOI 10.1109/TSMCC.2003.817359; Tanev I., 2001, Proceedings 15th International Conference on Information Networking, DOI 10.1109/ICOIN.2001.905345; Taylor C., 1994, MACHINE LEARNING NEU; TOMASSINI M, 2000, IEEE INT C CLUST COM, P209; Wang CH, 2000, FUZZY SET SYST, V112, P141, DOI 10.1016/S0165-0114(97)00385-0; Witten I. H., 1999, DATA MINING PRACTICA; Wong M. L, 2001, DECIS SUPPORT SYST, V31, P405, DOI 10.1016/S0167-9236(01)00092-6; Yao X, 1997, IEEE T NEURAL NETWOR, V8, P694, DOI 10.1109/72.572107; YOSHIDA N, 1999, IEEE INT C SYST MAN, V5, P571, DOI 10.1109/ICSMC.1999.815615	57	6	7	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1094-6977		IEEE T SYST MAN CY C	IEEE Trans. Syst. Man Cybern. Part C-Appl. Rev.	MAY	2005	35	2					131	142		10.1109/TSMCC.2004.841911		12	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications	Computer Science	918RZ	WOS:000228566600002	
J	Tzeng, FY; Lum, EB; Ma, KL				Tzeng, FY; Lum, EB; Ma, KL			An intelligent system approach to higher-dimensional classification of volume data	IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS			English	Article						user interface design; classification; transfer functions; graphics hardware; visualization; volume rendering; machine learning	SUPPORT VECTOR MACHINES; NEURAL-NETWORK	In volume data visualization, the classification step is used to determine voxel visibility and is usually carried out through the interactive editing of a transfer function that defines a mapping between voxel value and color/opacity. This approach is limited by the difficulties in working effectively in the transfer function space beyond two dimensions. We present a new approach to the volume classification problem which couples machine learning and a painting metaphor to allow more sophisticated classification in an intuitive manner. The user works in the volume data space by directly painting on sample slices of the volume and the painted voxels are used in an iterative training process. The trained system can then classify the entire volume. Both classification and rendering can be hardware accelerated, providing immediate visual feedback as painting progresses. Such an intelligent system approach enables the user to perform classification in a much higher dimensional space without explicitly specifying the mapping for every dimension used. Furthermore, the trained system for one data set may be reused to classify other data sets with similar characteristics.	Univ Calif Davis, Dept Comp Sci, IDAV, Davis, CA 95616 USA	Tzeng, FY (reprint author), Univ Calif Davis, Dept Comp Sci, IDAV, Davis, CA 95616 USA.	tzeng@cs.ucdavis.edu; lume@cs.ucdavis.edu; ma@cs.ucdavis.edu					Bajaj C. L., 1997, Proceedings. Visualization '97 (Cat. No.97CB36155), DOI 10.1109/VISUAL.1997.663875; Blanz V., 1996, P INT C ART NEUR NET, P251; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Cherkauer KJ, 1996, ADV NEUR IN, V8, P45; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Fujishiro I., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), DOI 10.1109/VISUAL.1999.809932; Gelenbe E., 1996, Proceedings International Workshop on Neural Networks for Identification, Control, Robotics, and Signal/Image Processing (Cat. No.96TB100029), DOI 10.1109/NICRSP.1996.542760; HALL LO, 1992, IEEE T NEURAL NETWOR, V3, P672, DOI 10.1109/72.159057; He T., 1996, P IEEE VIS 96, P227, DOI DOI 10.1109/VISUAL.1996.568113; Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428; Huang R., 2003, P 11 PAC C COMP GRAP, P355; Jankun-Kelly T., 2001, P 2001 INT WORKSH VO, P51; KINDLMANN G, 1998, P IEEE S VOL VIS, P79, DOI DOI 10.1145/288126.288167; Kniss J., 2001, Proceedings Visualization 2001 (Cat. No.01CH37269), DOI 10.1109/VISUAL.2001.964519; KONIG A, 2001, P SPRING C COMP GRAP, V17, P279; LEVOY M, 1988, IEEE COMPUT GRAPH, V8, P29, DOI 10.1109/38.511; Marks J., 1997, P SIGGRAPH 97, P389, DOI 10.1145/258734.258887; McCallum A., 2000, P 17 INT C MACH LEAR, P591; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; Perlovsky L., 2000, NEURAL NETWORKS INTE; Pfister H, 2001, IEEE COMPUT GRAPH, V21, P16, DOI 10.1109/38.920623; Rumelhart D., 1986, PARALLEL DISTRIBUTED; Takanashi I., 2002, Proceedings 10th Pacific Conference on Computer Graphics and Applications, DOI 10.1109/PCCGA.2002.1167880; Thorsten J., 1998, P 10 EUR C MACH LEAR, P137; Tzeng F.-Y., 2003, P IEEE VIS 2003 C, P505; Van Gelder A., 1996, Proceedings 1996 Symposium on Volume Visualization (IEEE Cat. No.96TB100087), DOI 10.1109/SVV.1996.558039; Werbos P., 1974, THESIS HARVARD U	28	51	61	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1077-2626		IEEE T VIS COMPUT GR	IEEE Trans. Vis. Comput. Graph.	MAY-JUN	2005	11	3					273	284				12	Computer Science, Software Engineering	Computer Science	903XY	WOS:000227460100004	
J	Huang, Z; Lees, B				Huang, Z; Lees, B			Representing and reducing error in natural-resource classification using model combination	INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE			English	Article						representing error; reducing error; natural-resource classification; model combination	GEOGRAPHIC INFORMATION-SYSTEM; NEURAL-NETWORK; DECISION-TREE; INTEGRATION; VEGETATION; GIS; DISTRIBUTIONS; EXTRACTION; IMAGES	Artificial Intelligence ( AI) models such as Artificial Neural Networks (ANNs), Decision Trees and Dempster-Shafer's Theory of Evidence have long claimed to be more error-tolerant than conventional statistical models, but the way error is propagated through these models is unclear. Two sources of error have been identified in this study: sampling error and attribute error. The results show that these errors propagate differently through the three AI models. The Decision Tree was the most affected by error, the Artificial Neural Network was less affected by error, and the Theory of Evidence model was not affected by the errors at all. The study indicates that AI models have very different modes of handling errors. In this case, the machine-learning models, including ANNs and Decision Trees, are more sensitive to input errors. Dempster-Shafer's Theory of Evidence has demonstrated better potential in dealing with input errors when multisource data sets are involved. The study suggests a strategy of combining AI models to improve classification accuracy. Several combination approaches have been applied, based on a 'majority voting system', a simple average, Dempster Shafer's Theory of Evidence, and fuzzy-set theory. These approaches all increased classification accuracy to some extent. Two of them also demonstrated good performance in handling input errors. Second-stage combination approaches which use statistical evaluation of the initial combinations are able to further improve classification results. One of these second-stage combination approaches increased the overall classification accuracy on forest types to 54% from the original 46.5% of the Decision Tree model, and its visual appearance is also much closer to the ground data. By combining models, it becomes possible to calculate quantitative confidence measurements for the classification results, which can then serve as a better error representation. Final classification products include not only the predicted hard classes for individual cells, but also estimates of the probability and the confidence measurements of the prediction.	Australian Natl Univ, Sch Resources Environm & Soc, Canberra, ACT 0200, Australia	Lees, B (reprint author), Australian Natl Univ, Sch Resources Environm & Soc, Canberra, ACT 0200, Australia.	Brian.lees@anu.edu.au					ABRAHART RJ, 1998, P 3 INT C GEOCOMPUTA; BISCHOF H, 1992, IEEE T GEOSCI REMOTE, V30, P482, DOI 10.1109/36.142926; DRUMMOND J, 1996, SPAT ACC ASS NAT RES, P189; DRUMMOND J, 1987, ITC J, V1, P73; ENBUTSU I, 1993, WATER SCI TECHNOL, V28, P333; FITZGERALD RW, 1994, ANU KIOLOA 1994 REMO; FORIER F, 1996, SPATIAL ACCURACY ASS, P225; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; GOODCHILD MF, 1992, INT J GEOGR INF SYST, V6, P87, DOI 10.1080/02693799208901898; GOODCHILD MF, 1989, ACCURACY OF SPATIAL DATABASES, P107; GOSTIN VA, 1969, THESIS AUSTR NATL U; GUPTILL SC, 1989, ACCURACY OF SPATIAL DATABASES, P91; HEPNER GF, 1990, PHOTOGRAMM ENG REM S, V56, P469; Heuvelink G. B. M., 1989, International Journal of Geographical Information Systems, V3, DOI 10.1080/02693798908941518; HUANG Z, 2004, THESIS AUSTR NATL U; Huang Z, 2004, PHOTOGRAMM ENG REM S, V70, P415; LAFFAN SW, 1998, P 3 INT C GEOCOMPUTA; LANTER DP, 1992, PHOTOGRAMM ENG REM S, V58, P825; LEE J, 1992, PHOTOGRAMM ENG REM S, V58, P1461; Lees BG, 1996, COMPUT GEOSCI, V22, P955, DOI 10.1016/S0098-3004(96)00033-7; LEES BG, 1991, ENVIRON MANAGE, V15, P823, DOI 10.1007/BF02394820; LODWICK WA, 1989, ACCURACY SPATIAL DAT, pCH6; LUNETTA RS, 1991, PHOTOGRAMM ENG REM S, V57, P677; Mingers J., 1989, Machine Learning, V3, DOI 10.1007/BF00116837; MOON WM, 1990, IEEE T GEOSCI REMOTE, V28, P711; MOORE DM, 1991, ENVIRON MANAGE, V15, P59, DOI 10.1007/BF02393838; NEWCOMER JA, 1984, AM CARTOGRAPHER, V11, P58; Openshaw S., 1991, Handling geographic information: Methodology and potential applications, P78; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Shafer Glenn, 1976, MATH THEORY EVIDENCE; Spear M., 1996, SPAT ACC ASS NAT RES, P199; Taylor JR, 1982, INTRO ERROR ANAL; Unwin DJ, 1995, PROG HUM GEOG, V19, P549, DOI 10.1177/030913259501900408; Van Niel KP, 2004, J VEG SCI, V15, P747, DOI 10.1658/1100-9233(2004)015[0747:EOEITD]2.0.CO;2; VEREGIN H, 1989, ACCURACY OF SPATIAL DATABASES, P3; VEREGIN H, 1995, INT J GEOGR INF SYST, V9, P595, DOI 10.1080/02693799508902059; WALSH SJ, 1987, PHOTOGRAMM ENG REM S, V53, P1423; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	38	14	15	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1365-8816		INT J GEOGR INF SCI	Int. J. Geogr. Inf. Sci.	MAY	2005	19	5					603	621		10.1080/13658810500032446		19	Computer Science, Information Systems; Geography; Geography, Physical; Information Science & Library Science	Computer Science; Geography; Physical Geography; Information Science & Library Science	935PG	WOS:000229793600005	
J	Wang, YH; Li, Y; Yang, SL; Yang, L				Wang, YH; Li, Y; Yang, SL; Yang, L			Classification of substrates and inhibitors of P-glycoprotein using unsupervised machine learning approach	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							TRANSPORT	P-glycoprotein (P-gp), a drug efflux pump, affects the bioavailability of therapeutic drugs and plays a potentially important role in clinical drug-drug interactions. Classification of candidate drugs as substrates or inhibitors of the carrier protein is of crucial importance in drug development. Accurate classification is difficult to achieve due to two major factors: i. The extreme diversity of substrates and the presence of multiple binding sites complicate the understanding of the mechanisms behind and hinder the development of a true, conclusive quantitative structure-activity relationship (QSAR) for P-gp substrates. ii. Both inhibitors and substrates interact with the same binding site of P-gp, as a result, it is not surprising that both share many common structural features. In this work, an unsupervised machine learning approach based on the Kohonen self-organizing maps (SOM) was explored, which incorporated a predefined set of physicochemical descriptors encoding the key molecular properties capable of discerning a substrate from an inhibitor. The SOM model can discriminate between substrates and inhibitors with an average accuracy of 82.3%. The current results show that the SOM-based method provides a potential in silico model for virtual screening.	Chinese Acad Sci, Dalian Inst Chem Phys, Grad Sch, Lab Pharmaceut Resource Discovery, Dalian 116023, Peoples R China; Dalian Univ Technol, Sch Chem Engn, Dalian 116012, Peoples R China	Yang, L (reprint author), Chinese Acad Sci, Dalian Inst Chem Phys, Grad Sch, Lab Pharmaceut Resource Discovery, 457 Zhongshan Rd, Dalian 116023, Peoples R China.	yling@dicp.ac.cn	Yang, Ling/F-5472-2012				Ayesh S, 1996, BBA-MOL BASIS DIS, V1316, P8, DOI 10.1016/0925-4439(96)00008-7; Bain LJ, 1997, ENVIRON HEALTH PERSP, V105, P812, DOI 10.1289/ehp.97105812; Ekins S, 2002, MOL PHARMACOL, V61, P964, DOI 10.1124/mol.61.5.964; HAGAN M, 1994, IEEE T NEURAL NETWOR, P989; Huang K, 2003, P SOC PHOTO-OPT INS, V4962, P307, DOI 10.1117/12.477903; IIVARINEN J, 1994, P C ART INT RES FINL, P122; Jennrich R.I., 1977, STAT METHODS DIGITAL, P77; Kohonen T., 1987, SELF ORG ASS MEMORY; Korolev D, 2003, J MED CHEM, V46, P3631, DOI 10.1021/jm030102a; Li Y, 2005, J MOL STRUCT, V733, P111, DOI 10.1016/j.molstruc.2004.08.012; Penzotti JE, 2002, J MED CHEM, V45, P1737, DOI 10.1021/jm0255062; Safa Ahmad R., 2004, Current Medicinal Chemistry - Anti-Cancer Agents, V4, P1, DOI 10.2174/1568011043482142; Schmitt L, 2002, CURR OPIN STRUC BIOL, V12, P754, DOI 10.1016/S0959-440X(02)00399-8; Shapiro AB, 1997, EUR J BIOCHEM, V250, P130, DOI 10.1111/j.1432-1033.1997.00130.x; SOOKIE L, 2003, ANAL CHIM ACTA, V486, P171; Ultsch A., 1990, P INT NEUR NETW C IN, P305; Varma MVS, 2003, PHARMACOL RES, V48, P347, DOI 10.1016/S1043-6618(03)00158-0; Wiese M, 2001, CURR MED CHEM, V8, P685; XUE Y, 2004, J CHEM INF COMP 0508; Yu DK, 1999, J CLIN PHARMACOL, V39, P1203, DOI 10.1177/00912709922012006	20	65	69	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596		J CHEM INF MODEL	J. Chem Inf. Model.	MAY-JUN	2005	45	3					750	757		10.1021/ci050041k		8	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	929YZ	WOS:000229384000022	
J	Fiori, S				Fiori, S			Quasi-geodesic neural learning algorithms over the orthogonal group: A tutorial	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						differential geometry; diffusion-type gradient; Lie groups; non-negative independent component analysis; Riemannian gradient	INDEPENDENT COMPONENT ANALYSIS; BLIND-DECONVOLUTION; MONTE-CARLO; EQUATIONS; MANIFOLD	The aim of this contribution is to present a tutorial on learning algorithms for a single neural layer whose connection matrix belongs to the orthogonal group. The algorithms exploit geodesics appropriately connected as piece-wise approximate integrals of the exact differential learning equation. The considered learning equations essentially arise from the Riemannian-gradient-based optimization theory with deterministic and diffusion-type gradient. The paper aims specifically at reviewing the relevant mathematics (and at presenting it in as much transparent way as possible in order to make it accessible to readers that do not possess a background in differential geometry), at bringing together modern optimization methods on manifolds and at comparing the different algorithms on a common machine learning problem. As a numerical case-study, we consider an application to non-negative independent component analysis, although it should be recognized that Riemannian gradient methods give rise to general-purpose algorithms, by no means limited to ICA-related applications.	Univ Perugia, Fac Ingn, Polo Didattico & Sci Ternano, I-05100 Terni, Italy	Fiori, S (reprint author), Univ Perugia, Fac Ingn, Polo Didattico & Sci Ternano, Localita Pentima Bassa 21, I-05100 Terni, Italy.	FIORI@UNIPG.IT					AKUZAWA T, 2001, P INT C IND COMP AN, P114; Amari S, 1998, NEURAL COMPUT, V10, P251, DOI 10.1162/089976698300017746; AMARI SI, 1989, LECT NOTES STAT, V28; Celledoni E, 2004, J COMPUT APPL MATH, V172, P247, DOI 10.1016/j.cam.2004.02.007; Cichocki A., 2002, ADAPTIVE BLIND SIGNA; Fiori S, 2001, NEURAL COMPUT, V13, P1625, DOI 10.1162/089976601750265036; Fiori S, 2004, IEEE T NEURAL NETWOR, V15, P455, DOI 10.1109/TNN.2004.824258; Fiori S, 2005, NEURAL COMPUT, V17, P779, DOI 10.1162/0899766053429381; Fiori S, 2002, IEEE T NEURAL NETWOR, V13, P521, DOI 10.1109/TNN.2002.1000121; FIORI S, IN PRESS IEEE T NEUR; HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.2307/2334940; Higham DJ, 2001, SIAM REV, V43, P525, DOI 10.1137/S0036144500378302; Hyvarinen A., 2001, INDEPENDENT COMPONEN; Kass RE, 1998, AM STAT, V52, P93, DOI 10.2307/2685466; Keshava N, 2002, IEEE SIGNAL PROC MAG, V19, P44, DOI 10.1109/79.974727; Liu XW, 2004, IEEE T PATTERN ANAL, V26, P662; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; NISHIMORI Y, 1999, P INT JOINT C NEUR N, P1625; OLVER PJ, 2003, GRADUATE TEXTS MATH, V107; Park H, 2000, NEURAL NETWORKS, V13, P755, DOI 10.1016/S0893-6080(00)00051-4; Plumbley M, 2002, IEEE SIGNAL PROC LET, V9, P177, DOI 10.1109/LSP.2002.800502; PLUMBLEY MD, 2004, P INT C IND COMP AN, P1245; Plumbley MD, 2003, IEEE T NEURAL NETWOR, V14, P534, DOI 10.1109/TNN.2003.810616; Srivastava A, 2002, J STAT PLAN INFER, V103, P15, DOI 10.1016/S0378-3758(01)00195-1; WARNES GR, 2001, 39 U WASH DEPT STAT; Wilson DR, 2003, NEURAL NETWORKS, V16, P1429, DOI 10.1016/S0893-6080(03)00138-2; Yang HH, 1997, NEURAL COMPUT, V9, P1457, DOI 10.1162/neco.1997.9.7.1457; Zhang LQ, 2002, J VLSI SIG PROC SYST, V31, P31, DOI 10.1023/A:1014441120905	28	24	25	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	MAY	2005	6						743	781				39	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026HJ	WOS:000236329700002	
J	Murray, JF; Hughes, GF; Kreutz-Delgado, K				Murray, JF; Hughes, GF; Kreutz-Delgado, K			Machine learning methods for predicting failures in hard drives: A multiple-instance application	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						hard drive failure prediction; rank-sum test; support vector machines (SVM); exact nonparametric statistics; multiple instance naive-Bayes	VECTOR MACHINE; CLASSIFIER; TIME	We compare machine learning methods applied to a difficult real-world problem: predicting computer hard-drive failure using attributes monitored internally by individual drives. The problem is one of detecting rare events in a time series of noisy and nonparametrically-distributed data. We develop a new algorithm based on the multiple-instance learning framework and the naive Bayesian classifier (mi-NB) which is specifically designed for the low false-alarm case, and is shown to have promising performance. Other methods compared are support vector machines (SVMs), unsupervised clustering, and non-parametric statistical tests (rank-sum and reverse arrangements). The failure-prediction performance of the SVM, rank-sum and mi-NB algorithm is considerably better than the threshold method currently implemented in drives, while maintaining low false alarm rates. Our results suggest that nonparametric statistical tests should be considered for learning problems involving detecting rare events in time series data. An appendix details the calculation of rank-sum significance probabilities in the case of discrete, tied observations, and we give new recommendations about when the exact calculation should be used instead of the commonly-used normal approximation. These normal approximations may be particularly inaccurate for rare event problems like hard drive failures.	Univ Calif San Diego, Jacobs Sch Engn, La Jolla, CA 92093 USA; Univ Calif San Diego, Ctr Magnet Recording Res, La Jolla, CA 92093 USA	Murray, JF (reprint author), Univ Calif San Diego, Jacobs Sch Engn, La Jolla, CA 92093 USA.	JFMURRAY@JFMURRAY.ORG; GFHUGHES@UCSD.EDU; KREUTZ@ECE.UCSD.EDU					ANDREWS S, 2003, ADV NEURAL INFORM PR, V15, P1; Bendat JS, 2000, RANDOM DATA; Bickel P.J., 1977, MATH STAT; Bridge PD, 1999, J CLIN EPIDEMIOL, V52, P229, DOI 10.1016/S0895-4356(98)00168-1; Brunner E, 2002, J STAT PLAN INFER, V108, P37, DOI 10.1016/S0378-3758(02)00269-0; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Catlett J., 1991, P EUR WORK SESS LEAR, P164; CHEESEMAN P, 1995, ADV KNOWLEDGE DISCOV, P158; Cherkassky V., 1998, LEARNING DATA CONCEP; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; DIETZ EJ, 1981, J AM STAT ASSOC, V76, P169, DOI 10.2307/2287063; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; EMERSON JD, 1985, BIOMETRICS, V41, P303, DOI 10.2307/2530667; FRANK E, 1999, P 16 INT C MACH LEAR, P115; HAMERLY G, 2001, 18 INT C MACH LEARN, P1; HETTMANSPERGER TP, 1984, STAT INFERENCE BASED; Hughes GF, 2002, IEEE T RELIAB, V51, P350, DOI [10.1109/TR.2002.802886, 10.1109/tTR.2002.802886]; Kendall M.G., 1969, ADV THEORY STAT, V1; KLOTZ JH, 1966, J AM STAT ASSOC, V61, P772, DOI 10.2307/2282786; LEHMAN SY, 1961, J AM STAT ASSOC, V56, P293, DOI 10.2307/2282254; Lehmann E., 1998, NONPARAMETRICS STAT; Liang FM, 2003, NEURAL COMPUT, V15, P1959, DOI 10.1162/08997660360675107; MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491; Mann HB, 1945, ECONOMETRICA, V13, P245, DOI 10.2307/1907187; MEHTA CR, 1988, J AM STAT ASSOC, V83, P999, DOI 10.2307/2290126; MEHTA CR, 1988, BIOMETRIKA, V75, P295, DOI 10.1093/biomet/75.2.295; Murray J. F., 2003, P INT C ART NEUR NET; Ng A.Y., 2002, ADV NEURAL INFORM PR, V14; Orlitsky A, 2003, SCIENCE, V302, P427, DOI 10.1126/science.1088284; PAGANO M, 1983, J AM STAT ASSOC, V78, P435, DOI 10.2307/2288653; Preusser B. E., 1991, Proceedings of the American Power Conference; ROTHMAN KJ, 2000, MODERN EPIDEMIOLOGY; Ruping S., 2000, MYSVM MANUAL; THEODOSSIOU PT, 1993, J AM STAT ASSOC, V88, P441, DOI 10.2307/2290323; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Vapnik V. N, 1995, NATURE STAT LEARNING; Vincent P, 2002, MACH LEARN, V48, P165, DOI 10.1023/A:1013955821559; Wang J., 2000, P 17 INT C MACH LEAR, P1119; WEISS GM, 1998, P 4 INT C KNOWL DISC; WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968; Xu X, 2003, THESIS U WAIKATO HAM	42	19	20	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	MAY	2005	6						783	816				34	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026HJ	WOS:000236329700003	
J	Colton, S				Colton, S			Automated conjecture making in number theory using HR, Otter and Maple	JOURNAL OF SYMBOLIC COMPUTATION			English	Article; Proceedings Paper	Symposium on Integration of Symbolic Computation Systems and Mechnanized Reasoning	JUL 01-05, 2002	Marseille, FRANCE			automated mathematical discovery; automated reasoning; computer algebra systems; machine learning; integration of reasoning systems	DISCOVERY	One of the main applications of computational techniques to pure mathematics has been the use of computer algebra systems to perform calculations which mathematicians cannot perform by hand. Because the data is produced within the computer algebra system, this becomes an environment for the exploration of new functions and the data produced is often analysed in order to make conjectures empirically. We add some automation to this discovery process by using the HR theory formation system to make conjectures about Maple functions supplied by the user. HR forms theories by inventing concepts, making conjectures empirically which relate the concepts and appealing to third party theorem provers and model generators to prove/disprove the conjectures. It has been used with success in number theory, graph theory and various algebraic domains such as group theory and ring theory. Experience has shown that HR produces too many conjectures which can be easily proven from the definitions of the functions involved. Hence, we use the Otter theorem prover to discard any theorems which can be easily proven, leaving behind the more interesting ones which are empirically plausible but not easily provable. We describe the core functionality of HR which enables it to form a theory, and the additional functionality implemented in order for HR to work with Maple functions. We present two experiments where we have applied HR's theory formation in number theory. We discuss the modes of operation for the user and provide some of the results produced in this way. We hope to show that using HR, Otter and Maple in this fashion has much potential for the advancement of computer algebra systems. (c) 2005 Elsevier Ltd. All rights reserved.	Univ London Imperial Coll Sci Technol & Med, Dept Comp, London SW7 2AZ, England	Colton, S (reprint author), Univ London Imperial Coll Sci Technol & Med, Dept Comp, 180 Queens Gate, London SW7 2AZ, England.	sgc@doc.ic.ac.uk					BUCHBERGER B, 1998, P CALCULEMUS, V99; CHOU S, 1985, 49 U AUST COMP SCI; COLTON S, 1999, J INTEGER SEQUENCES, V2; COLTON S, 2000, P 17 NAT C ART INT; COLTON S, 2002, P 1 BRIT CUB WORKSH; COLTON S, 2000, MACHINE LEARNING; Colton S, 2003, LECT NOTES ARTIF INT, V2741, P289; Colton S, 2000, INT J HUM-COMPUT ST, V53, P351, DOI 10.1006/ijhc.2000.0394; COLTON S, 2002, AUTOMATED THEORY FOR; COLTON S, 2001, P CP 01; Dehaspe L, 1999, DATA MIN KNOWL DISC, V3, P7, DOI 10.1023/A:1009863704807; DeRaedt L, 1997, MACH LEARN, V26, P99, DOI 10.1023/A:1007361123060; FAJTLOWICZ S, 1988, DISCRETE MATH, V72, P113, DOI 10.1016/0012-365X(88)90199-9; FRANKE A, 1999, P CADE, V16, P217; Hardy G. H., 1938, THEORY NUMBERS; KENNEDY R, 1990, INT J MATH MATH SCI, V13, P383, DOI 10.1155/S0161171290000576; Lenat D., 1982, KNOWLEDGE BASED SYST; McCasland RL, 1998, ROCKY MT J MATH, V28, P1357, DOI 10.1216/rmjm/1181071721; McCune W., 1994, ANLMCSTM194; MCCUNE W, 1990, ANL909; McCune W, 1997, J AUTOM REASONING, V19, P263, DOI 10.1023/A:1005843212881; MCCUNE WW, 1993, J AUTOM REASONING, V10, P1, DOI 10.1007/BF00881862; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; REDFERN D, 1999, MAPLE HDB; SLOANE N, 2000, ONLINE ENCY INTEGER; ZIMMER J, 2001, INTEGRATING HR TPTP2; *GAP GROUP, 2000, GAP REF MAN	27	0	0	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0747-7171		J SYMB COMPUT	J. Symb. Comput.	MAY	2005	39	5					593	615		10.1016/j.jsc.2004.12.003		23	Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	922PK	WOS:000228849800006	
J	Krasnopolsky, VM; Fox-Rabinovitz, MS; Chalikov, DV				Krasnopolsky, VM; Fox-Rabinovitz, MS; Chalikov, DV			New approach to calculation of atmospheric model physics: Accurate and fast neural network emulation of longwave radiation in a climate model	MONTHLY WEATHER REVIEW			English	Article							PARAMETERIZATION; APPROXIMATIONS; WATER	A new approach based on a synergetic combination of statistical/machine learning and deterministic modeling within atmospheric models is presented. The approach uses neural networks as a statistical or machine learning technique for an accurate and fast emulation or statistical approximation of model physics parameterizations. It is applied to development of an accurate and fast approximation of an atmospheric longwave radiation parameterization for the NCAR Community Atmospheric Model, which is the most time consuming component of model physics. The developed neural network emulation is two orders of magnitude, 50-80 times, faster than the original parameterization. A comparison of the parallel 10-yr climate simulations performed with the original parameterization and its neural network emulations confirmed that these simulations produce almost identical results. The obtained results show the conceptual and practical possibility of an efficient synergetic combination of deterministic and statistical learning components within an atmospheric climate or forecast model. A developmental framework and practical validation criteria for neural network emulations of model physics components are outlined.	NOAA, NCEP, SAIC, Camp Springs, MD USA; Univ Maryland, Earth Syst Sci Interdisciplinary Ctr, College Pk, MD 20742 USA	Krasnopolsky, VM (reprint author), 5200 Auth Rd, Camp Springs, MD 20746 USA.	Viadimir.Krasnopolsky@noaa.gov					Attali JG, 1997, NEURAL NETWORKS, V10, P1069, DOI 10.1016/S0893-6080(97)00010-5; CHEN T, 1995, NEURAL NETWORKS, V6, P904; Chevallier F, 2000, Q J ROY METEOR SOC, V126, P761, DOI 10.1256/smsqj.56317; Chevallier F, 1998, J APPL METEOROL, V37, P1385, DOI 10.1175/1520-0450(1998)037<1385:ANNAFA>2.0.CO;2; Chevallier F, 2001, J APPL METEOROL, V40, P1445, DOI 10.1175/1520-0450(2001)040<1445:EOTJOI>2.0.CO;2; Collins WD, 2002, J GEOPHYS RES-ATMOS, V107, DOI 10.1029/2001JD001365; Collins WD, 2001, J ATMOS SCI, V58, P3224, DOI 10.1175/1520-0469(2001)058<3224:POGCOF>2.0.CO;2; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; Duffy PB, 2003, CLIM DYNAM, V21, P371, DOI 10.1007/s00382-003-0339-z; Fox-Rabinovitz MS, 2001, MON WEATHER REV, V129, P453, DOI 10.1175/1520-0493(2001)129<0453:AVRSGG>2.0.CO;2; FOXRABINOVITZ MS, 1998, J GEOPHYS RES, V107, P4768; FUNAHASHI K, 1989, NEURAL NETWORKS, V2, P183, DOI 10.1016/0893-6080(89)90003-8; HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T; KRASNOPOLSKY V, 2004, P 15 S GLOB CHANG CL; KRASNOPOLSKY V, 1995, J GEOPHYS RES, V100, P33; KRASNOPOLSKY V, 1997, RES ACTIVITIES ATMOS; Krasnopolsky VM, 2003, NEURAL NETWORKS, V16, P321, DOI 10.1016/S0893-6080(03)00027-3; Krasnopolsky VM, 2002, OCEAN MODEL, V4, P363, DOI 10.1016/S1463-5003(02)00010-0; KRASNOPOLSKY VM, 2000, P 2 C ART INT AMS LO, P27; RIPLEY BD, 1997, PATTERN RECOGNITION; Schoendorf J, 2003, GEOPHYS RES LETT, V30, DOI 10.1029/2002GL016649; Tolman HL, 2005, OCEAN MODEL, V8, P253, DOI 10.1016/j.ocemod.2003.12.008	22	25	25	AMER METEOROLOGICAL SOC	BOSTON	45 BEACON ST, BOSTON, MA 02108-3693 USA	0027-0644		MON WEATHER REV	Mon. Weather Rev.	MAY	2005	133	5					1370	1383		10.1175/MWR2923.1		14	Meteorology & Atmospheric Sciences	Meteorology & Atmospheric Sciences	930CH	WOS:000229392900020	
J	Devillers, L; Vidrascu, L; Lamel, L				Devillers, L; Vidrascu, L; Lamel, L			Challenges in real-life emotion annotation and machine learning based detection	NEURAL NETWORKS			English	Article						emotion detection; emotion annotation; blended emotion; naturalistic spoken data; prosodic, disfluency and lexical features; machine learning; SVM; decision trees	BASIC EMOTIONS; SPEECH	Since the early studies of human behavior, emotion has attracted the interest of researchers in many disciplines of Neurosciences and Psychology. More recently, it is a growing field of research in computer science and machine learning. We are exploring how the expression of emotion is perceived by listeners and how to represent and automatically detect a subject's emotional state in speech. In contrast with most previous studies, conducted on artificial data with archetypal emotions, this paper addresses some of the challenges faced when studying real-life non-basic emotions. We present a new annotation scheme allowing the annotation of emotion mixtures. Our studies of real-life spoken dialogs from two call center services reveal the presence of many blended emotions, dependent on the dialog context. Several classification methods (SVM, decision trees) are compared to identify relevant emotional states from prosodic, disfluency and lexical cues extracted from the real-life spoken human-human interactions. (c) 2005 Elsevier Ltd. All rights reserved.	CNRS, LIMSI, Dept Human Machine Commun, F-91403 Orsay, France	Devillers, L (reprint author), CNRS, LIMSI, Dept Human Machine Commun, BP 133, F-91403 Orsay, France.	devil@limsi.fr; vidrascu@limsi.fr; lamel@limsi.fr					ABRILIAN S, 2005, P HUMAN COMPUTER INT; ANG J, 2002, P INT C SPOK LANG PR, V3, P2037; Barras C., 2000, SPEECH COMMUN, V33, P5; Batliner A., 2004, P 4 INT C LANG RES E, P171; Batliner A, 2003, SPEECH COMMUN, V40, P117, DOI 10.1016/S0167-6393(02)00079-1; Batliner A., 2000, P ISCA WORKSH SPEECH, P195; BOERMSA P, 1993, P I PHON SCI AMST NE, P97; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; BURGER S, 2002, INT C SPOK LANG PROC, P301; Campbell N., 2003, 15 INT C PHON SCI, P2417; Campbell N., 2004, P SPEECH PROSODY, P217; Carletta J, 1996, COMPUT LINGUIST, V22, P249; Cowie R, 2003, SPEECH COMMUN, V40, P5, DOI 10.1016/S0167-6393(02)00071-7; Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197; COWIE R, 2000, P ISCA WORKSH SPEECH, P224; CRAGGS R, 2002, P AAAI SPR S EXPL AT; Cronbach L.J., 1972, DEPENDABILITY BEHAV; Damasio Antonio R., 1994, DESCARTES ERROR EMOT; DAVIDSON J, 2003, HDB AFFECTIVE SCI; DELLAERT F, 1996, P 4 INT C SPOK LANG, V3, P1970, DOI 10.1109/ICSLP.1996.608022; DEVILLERS I, 2000, P IEEE INT C MULTIME; DEVILLERS L, 2003, P 15 INT C PHON SCI, P1505; DEVILLERS L, 2004, 4 INT C LANG RES EVA, V4, P1423; DEVILLERS L, 2004, P SPEECH PROSODY, P205; DEVILLERS L, 2002, INT STANDARDS LANGUA; DOUGLASCOWIE E, 2005, P INTERSPEECH; Douglas-Cowie E, 2003, SPEECH COMMUN, V40, P33, DOI 10.1016/S0167-6393(02)00070-5; EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068; Fernandez R, 2003, SPEECH COMMUN, V40, P145, DOI 10.1016/S0167-6393(02)00080-8; FORBESRILEY K, 2004, P HUM LANG TECHN C N; Freund Y., 1996, P 13 INT C MACH LEAR, P148; HARDY H, 2002, INT STANDARDS LANGUA; LeDoux JE, 1989, J COGNITIVE NEUROSCI, V1, P238, DOI 10.1162/jocn.1989.1.3.238; Lee C. M., 2002, P INT C SPOK LANG PR, P873; LEE CM, 2001, P IEEE AUTOMATIC SPE; NARAYANAN S, 2002, INT STANDARDS LANUAG; ORTONY A, 1990, PSYCHOL REV, V97, P315, DOI 10.1037//0033-295X.97.3.315; OSGOOD CE, 1975, CROSS CULTURAL U AFF; Petrushin V.A., 1999, ARTIFICIAL NEU NET E, P7; Picard W.R., 1997, AFFECTIVE COMPUTING; PLUTCHIK R, 1984, APPROACHES EMOTION, P293; Polzin T. S., 1998, COOPERATIVE MULTIMOD; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; SCHERER K., 1984, APPROACHES EMOTION, P293; Scherer K. R., 1999, HDB COGNITION EMOTIO, P637; SHAFRAN I, 2003, P IEEE AUT SPEECH RE, P31; STEIDL S, 2005, P IEEE INT C AC SPEE; TAYLOR J, 1997, NEURAL NETWORKS MIND, P243; Vapnik V. N, 1995, NATURE STAT LEARNING; VIDRASCU L, 2005, P IEEE INT C MULT; Witten I. H., 1999, P ICONIP ANZIIS ANNE, P192; WREDED E, 2003, P EUROSPEECH, V3, P1677	52	66	66	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080		NEURAL NETWORKS	Neural Netw.	MAY	2005	18	4					407	422		10.1016/j.neunet.2005.03.007		16	Computer Science, Artificial Intelligence	Computer Science	948JB	WOS:000230710900006	
J	Pham, DT; Afify, AA				Pham, D. T.; Afify, A. A.			Machine-learning techniques and their applications in manufacturing	PROCEEDINGS OF THE INSTITUTION OF MECHANICAL ENGINEERS PART B-JOURNAL OF ENGINEERING MANUFACTURE			English	Review						machine learning; inductive learning; intelligent manufacturing; classification; scaling up; multiple models	DECISION-TREE INDUCTION; TIME PRODUCTION SYSTEM; NEURAL-NETWORKS; RULE INDUCTION; KNOWLEDGE ACQUISITION; GENETIC ALGORITHM; YIELD MANAGEMENT; INTEGRATION; SIMULATION; SELECTION	Machine learning is concerned with enabling computer programs automatically to improve their performance at some tasks through experience. Manufacturing is an area where the application of machine learning can be very fruitful. However, little has been published about the use of machine-learning techniques in the manufacturing domain. This paper evaluates several machine-learning techniques and examines applications in which they have been successfully deployed. Special attention is given to inductive learning, which is among the most mature of the machine-learning approaches currently available. Current trends and recent developments in machine-learning research are also discussed. The paper concludes with a summary of some of the key research issues in machine learning.	Cardiff Univ, Mfg Engn Ctr, Cardiff CF24 3AA, Wales	Pham, DT (reprint author), Cardiff Univ, Mfg Engn Ctr, Cardiff CF24 3AA, Wales.	phamdt@cf.ac.uk	Pham, Duc/H-1516-2011				AHA DW, 1997, ARTIF INTELL, P7; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Aksoy MS, 2004, J INTELL MANUF, V15, P569, DOI 10.1023/B:JIMS.0000034120.86709.8c; Akyol DE, 2004, COMPUT IND ENG, V46, P679, DOI 10.1016/j.cie.2004.05.005; Apte C., 1993, Proceedings. The Ninth Conference on Artificial Intelligence for Applications (Cat. No.93CH3254-0), DOI 10.1109/CAIA.1993.366608; AYTUG H, 1994, IEEE T ENG MANAGE, V41, P165, DOI 10.1109/17.293383; AYTUG H, 1994, COMPUT OPER RES, V21, P909, DOI 10.1016/0305-0548(94)90020-5; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; BENARIEH D, 1998, P 1998 IEEE INT C SY, P2738; BERGADANO F, 1992, MACH LEARN, V8, P5, DOI 10.1023/A:1022682318197; Braha D., 2001, DATA MINING DESIGN M; Breiman L, 1996, MACH LEARN, V24, P49, DOI 10.1007/BF00117832; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; BUNTINE WL, 1991, THESIS U TECHNOLOGY; Catlett J., 1991, THESIS U TECHNOLOGY; Catlett J., 1991, P EUR WORK SESS LEAR, P164; Cestnik B., 1990, P EUR C ART INT, P147; Chan P., 1993, AAAI WORKSH KNOWL DI; Chan P. K., 1997, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V8, DOI 10.1023/A:1008640732416; CHATTERJEE A, 1996, P 19 IEEE CPMT INT E, P372; CHAUVIN Y, 1995, BACKPROBAGATION THEO; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Clark P., 1991, P 5 EUR WORK SESS LE, P151; CLARK P, 1987, PROGR MACHINE LEARNI, P11; Cohen W. W., 1995, P 12 INT C MACH LEAR, P115; Cohen W. W., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); Craven MW, 1997, FUTURE GENER COMP SY, V13, P211, DOI 10.1016/S0167-739X(97)00022-8; DAS SK, 1994, PROD PLAN CONTROL, V5, P342, DOI 10.1080/09537289408919505; Dash M., 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; DEJONG KA, 1993, MACH LEARN, V13, P161, DOI 10.1023/A:1022617912649; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Dietterich TG, 1997, AI MAG, V18, P97; DOMINGOS P, 1995, P 14 INT JOINT C ART, P1226; DOMINGOS P, 1997, THESIS U CALIFORNIA; Domingos P., 1998, INTELL DATA ANAL, V2, P187, DOI 10.1016/S1088-467X(98)00023-7; Domingos P., 1996, P 13 INT C MACH LEAR, P105; ELATTAR M, 1994, APPL ARTIF INTELL, V8, P497; ERCIL A, 1993, WELD J, V72, P59; EVANS B, 2002, HDB DATA MINING KNOW; EVANS B, 1994, IEEE EXPERT, V9, P60, DOI 10.1109/64.295130; FAMILI A, 1994, AI EDAM, V8, P63; Fayyad U.M., 1996, ADV KNOWLEDGE DISCOV, P1; FILIPIC B, 1994, P 2 INT C ART INT AP, P513; FORSYTH R, 1989, MACHINE LEARNING PRI; Freitas A., 2002, DATA MINING KNOWLEDG; FREITAS AA, 1999, ADV SOFT COMPUTING E, P340; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y., 1996, P 13 INT C MACH LEAR, P148; FRIEDMAN J, 1996, BIAS VARIANCE 0 1 LO; Furnkranz J, 1998, J ARTIF INTELL RES, V8, P129; Furnkranz J., 1994, P 11 INT C MACH LEAR, P70; Gardner M., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347171; Gehrke J., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; GIORDANA A, 1996, P 3 INT WORKSH MULT, P125; Giordana A, 1995, EVOL COMPUT, V3, P375, DOI 10.1162/evco.1995.3.4.375; Giordana A., 1994, P 11 INT C MACH LEAR, P96; Goldberg DE, 1989, GENETIC ALGORITHMS S; Graefe G., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; GREENE DP, 1993, MACH LEARN, V13, P229, DOI 10.1023/A:1022622013558; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Haykin S., 1994, NEURAL NETWORKS COMP; Heckerman D., 1996, ADV KNOWLEDGE DISCOV, P273; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; HUI PCL, 1997, INT J CLOTH SCI TECH, V9, P34, DOI 10.1108/09556229710157867; IP CY, 2003, P 8 ACM S SOL MOD AP, P322; IRANI KB, 1993, IEEE EXPERT, V8, P41, DOI 10.1109/64.193054; Jain AS, 1998, INT J PROD RES, V36, P1249, DOI 10.1080/002075498193309; JANIKOW CZ, 1993, MACH LEARN, V13, P189, DOI 10.1023/A:1022669929488; Jiang Y, 2002, IEEE IJCNN, P1416; KALBFLEISH J, 1979, PROBABILITY STAT INF, V2; Kang BS, 1998, EXPERT SYST APPL, V15, P123, DOI 10.1016/S0957-4174(98)00017-7; KE M, 1989, P 2 INT C IND ENG AP, V2, P824, DOI 10.1145/67312.67353; KHERA D, 1994, IEEE T ENG MANAGE, V41, P143, DOI 10.1109/17.293381; Kim CO, 1998, INT J PROD RES, V36, P2497, DOI 10.1080/002075498192652; Koonce DA, 1997, COMPUT IND ENG, V33, P27, DOI 10.1016/S0360-8352(97)00033-8; LANGLEY P, 1995, COMMUN ACM, V38, P55; Lavrac N, 2004, MACH LEARN, V57, P13, DOI 10.1023/B:MACH.0000035516.74817.51; Lee CY, 1997, INT J PROD RES, V35, P1171, DOI 10.1080/002075497195605; Letourneau S, 1999, IEEE INTELL SYST APP, V14, P59, DOI 10.1109/5254.809569; Lin ZC, 1996, ARTIF INTELL ENG, V10, P21, DOI 10.1016/0954-1810(95)00013-5; Liu HA, 1998, EXPERT SYST APPL, V15, P333, DOI 10.1016/S0957-4174(98)90049-5; Liu JJ, 2000, IEEE C EVOL COMPUTAT, P458; LU SCY, 1993, ANN CIRP, V38, P143; LU SCY, 1987, ARTIF INTELL, V1, P109; Madigan D., 1996, P AAAI WORKSH INT MU, P77; Markham IS, 1998, COMPUT IND ENG, V34, P717, DOI 10.1016/S0360-8352(98)00099-0; Marks HM, 2000, ADV RES TH SCH MANAG, V4, P239; Mathieu RG, 2002, PROD PLAN CONTROL, V13, P715, DOI 10.1080/0953728031000057343; Mehta M., 1996, P 5 INT C EXT DAT TE, P18; Michalewicz Z, 1996, GENETIC ALGORITHMS D; Michalski R. S., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; Michalski RS, 1969, P 5 INT S INF PROC A, VA3, P125; MICHALSKI RS, 2001, 012 MLI G MAS U; MICHALSKI RS, 1983, 835 ISG U ILL URB CH; Mitchell F, 1997, IRONMAK STEELMAK, V24, P306; Mitchell T, 1997, MACHINE LEARNING; Mitchell T.M., 1999, COMMUN ACM, V42, P31; Monostori L, 1996, CIRP ANN-MANUF TECHN, V45, P675; MONOSTORI L, 2003, ENG APPL ARTIF INTEL, V16, P227; Moore A, 1998, J ARTIF INTELL RES, V8, P67; MORELLO BC, 2001, P 8 IEEE INT C EM TE, V1, P651; Morimoto Y., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; MURATA T, 2001, P JOINT 9 INT FUZZ S, V4, P2417, DOI 10.1109/NAFIPS.2001.944451; NAKASUKA S, 1992, INT J PROD RES, V30, P411, DOI 10.1080/00207549208942903; Neri F, 1996, IEEE T PATTERN ANAL, V18, P1135, DOI 10.1109/34.544085; Noda E., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), DOI 10.1109/CEC.1999.782601; Optiz D.W., 1999, P 16 INT C ART INT, P379; Osisek V, 2004, J INTELL MANUF, V15, P55, DOI 10.1023/B:JIMS.0000010075.60589.58; PARK MW, 1996, ANN CIRP, V45, P475; Park SC, 1997, IEEE T ROBOTIC AUTOM, V13, P486; Peng YH, 2004, J INTELL MANUF, V15, P373, DOI 10.1023/B:JIMS.0000026574.95637.36; Perez R.A., 1992, P 25 HAW INT C SYST, V3, P14; Pham D. T., 2000, INTELLIGENT OPTIMISA; Pham DT, 1997, P I MECH ENG B-J ENG, V211, P239, DOI 10.1243/0954405971516239; Pham DT, 2003, P I MECH ENG C-J MEC, V217, P1273, DOI 10.1243/095440603322769929; PHAM DT, 1995, J SYST ENG, V5, P115; PHAM DT, 1993, ARTIF INTELL, V8, P227; Pham D.T., 2000, EUR S INT TECHN ESIT, P119; PHAM DT, 1996, INTELLIGENT QUALITY; Pham D.T., 1999, NEURAL NETWORKS IDEN; Pham DT, 1997, PATTERN RECOGN, V30, P1137, DOI 10.1016/S0031-3203(96)00148-3; PHAM DT, 1995, EXPERT SYST APPL, V8, P59, DOI 10.1016/S0957-4174(99)80008-6; Pham DT, 2004, P I MECH ENG C-J MEC, V218, P1255, DOI 10.1243/0954406042369017; PHAMN DT, 2004, P 4 CIRP INT SEM INT; PIERREVAL H, 1990, J OPER RES SOC, V41, P461, DOI 10.2307/2583031; PIORE P, 2003, INTEGR MFG SYST, V14, P160; PIRAMUTHU S, 1994, IEEE T ENG MANAGE, V41, P172, DOI 10.1109/17.293384; PIRAMUTHU S, 1993, DECIS SUPPORT SYST, V9, P127, DOI 10.1016/0167-9236(93)90027-Z; Priore P., 2001, International Journal of Foundations of Computer Science, V12, DOI 10.1142/S0129054101000849; PROVOST F, 1999, DATA MIN KNOWL DISC, V2, P1; Quinlan J., 1983, MACHINE LEARNING ART, V1, P463; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; QUIROGA LA, 1995, COMPUT IND ENG, V29, P561, DOI 10.1016/0360-8352(95)00134-M; RAKES TR, 1994, ADV ARTIF INTELL EC, V1, P125; Rastogi R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; REICH Y, 1995, INT J HUM-COMPUT ST, V42, P3, DOI 10.1006/ijhc.1995.1002; Reich Y, 1996, AI EDAM, V10, P171; Rivest R. L., 1987, Machine Learning, V2, DOI 10.1007/BF00058680; SAXENA S, 1993, P KNOWL DISC DAT WOR, P81; Schapire R., 1997, P 14 INT C MACH LEAR, P313; Schapire R. E., 1997, P 14 INT C MACH LEAR, P322; SCHULZ G, 1997, P 2 WORLD C INT MAN, P66; Shafer J, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P544; SHAW MJ, 1992, IIE TRANS, V24, P2, DOI 10.1080/07408179208964219; LI DC, 1994, INT J PROD RES, V32, P2187; Shigaki I, 2001, PROD PLAN CONTROL, V12, P379, DOI 10.1080/09537280010014695; Shigaki I, 1999, PROD PLAN CONTROL, V10, P727, DOI 10.1080/095372899232551; Shin CK, 2000, INT J PROD RES, V38, P4261, DOI 10.1080/00207540050205073; Sluga A, 1998, COMPUT IND, V37, P185, DOI 10.1016/S0166-3615(98)00098-0; STIRLING D, 1988, ARTIF INTELL, P301; SUWA H, 1997, IFAC IFIP C MAN CONT, P353; SUWA H, 1996, P 6 IFIP TCS WG5 7 I, P631; SUWA H, 1998, P IEEE INT S IND EL, V2, P720; Suwa H., 1996, Proceedings of the Japan-USA Symposium on Flexible Automation - 1996; TING KM, 1996, P 15 INT JOINT C ART, P250; TOWELL GG, 1993, MACH LEARN, V13, P71, DOI 10.1007/BF00993103; TURNEY P, 1995, P IJCAI 9K WORKSH DA, P50; Venturini G., 1993, P EUR C MACH LEARN V, P280; Whitehall B. L., 1990, Artificial Intelligence in Engineering, V5, DOI 10.1016/0954-1810(90)90020-5; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Wray BA, 1997, J INTELL MANUF, V8, P83, DOI 10.1023/A:1018548519287; Wu XD, 1998, LECT NOTES ARTIF INT, V1531, P24; ZAKI M, 1998, THESIS U ROCHESTER R; Zhang SC, 2001, APPL ARTIF INTELL, V15, P129, DOI 10.1080/088395101750065732; ZHANG X, 1992, J MOL BIOL, V225, P1049, DOI 10.1016/0022-2836(92)90104-R; Zhou C, 2001, IEEE T ELECTRON PACK, V24, P222; Zhou Z.H., 2000, International Journal of Computers, Systems and Signals, V1, P154; *ISL, 1998, CLEM DAT MIN PACK; *RULEQUEST, DAT MIN TOOLS C5 0	172	8	8	PROFESSIONAL ENGINEERING PUBLISHING LTD	WESTMINISTER	1 BIRDCAGE WALK, WESTMINISTER SW1H 9JJ, ENGLAND	0954-4054		P I MECH ENG B-J ENG	Proc. Inst. Mech. Eng. Part B-J. Eng. Manuf.	MAY	2005	219	5					395	412		10.1243/095440505X32274		18	Engineering, Manufacturing; Engineering, Mechanical	Engineering	952SL	WOS:000231025700002	
J	Du, HF; Gong, MG; Jiao, LC; Liu, RC				Du, HF; Gong, MG; Jiao, LC; Liu, RC			A novel algorithm of artificial immune system for high-dimensional function numerical optimization	PROGRESS IN NATURAL SCIENCE			English	Article						clonal selection; immune memory; artificial immune system; evolutionary algorithms; Markov chain		Based on the clonal selection theory and immune memory theory, a novel artificial immune system algorithm, immune memory clonal programming algorithm (IMCPA), is put forward. Using the theorem of Markov chain, it is proved that IMCPA is convergent. Compared with some other evolutionary programming algorithms (like Breeder genetic algorithm), IMCPA is shown to be an evolutionary strategy capable of solving complex machine learning tasks, like high-dimensional function optimization, which maintains the diversity of the population and avoids prematurity to some extent, and has a higher convergence speed.	Xidian Univ, Inst Intelligent Informat Proc, Xian 710071, Peoples R China; Xidian Univ, Key Lab Radar Signal Proc, Xian 710071, Peoples R China; Xian Jiaotong Univ, Sch Mech Engn, Xian 710049, Peoples R China	Du, HF (reprint author), Xidian Univ, Inst Intelligent Informat Proc, Xian 710071, Peoples R China.	haifengdu72@163.com					Balazinska M., 2000, Proceedings Seventh Working Conference on Reverse Engineering, DOI 10.1109/WCRE.2000.891457; COOPER KD, 1992, PROCEEDINGS OF THE 1992 INTERNATIONAL CONFERENCE ON COMPUTER LANGUAGES, P96, DOI 10.1109/ICCL.1992.185472; Dasgupta D., 1999, Proceedings of the Second International Conference on Intelligent Processing and Manufacturing of Materials. IPMM'99 (Cat. No.99EX296), DOI 10.1109/IPMM.1999.792486; De Castro L.N., 2000, P GECCO 00 WORKSH AR, P36; Ding Y., 2000, PATTERN RECOGN, V13, P52; ESMAILI N, 1995, IEEE INT C SYST MAN, P2904; Hybinette M, 1997, PROCEEDINGS OF THE 1997 WINTER SIMULATION CONFERENCE, P444, DOI 10.1145/268437.268523; Kim J, 2001, IEEE C EVOL COMPUTAT, P1244; Leung YW, 2001, IEEE T EVOLUT COMPUT, V5, P41; LU DY, 1998, MODERN IMMUNOLOGY; Muhlenbein H, 1993, EVOL COMPUT, V1, P25, DOI 10.1162/evco.1993.1.1.25; PAN ZJ, 1998, EVOLUTION COMPUTATIO	12	22	29	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1002-0071		PROG NAT SCI	Prog. Nat. Sci.	MAY	2005	15	5					463	471				9	Materials Science, Multidisciplinary; Multidisciplinary Sciences	Materials Science; Science & Technology - Other Topics	950RB	WOS:000230873800014	
J	Sachs, K; Perez, O; Pe'er, D; Lauffenburger, DA; Nolan, GP				Sachs, K; Perez, O; Pe'er, D; Lauffenburger, DA; Nolan, GP			Causal protein-signaling networks derived from multiparameter single-cell data	SCIENCE			English	Article							FLOW-CYTOMETRY; CANCER-CELLS; KINASE-C; ACTIVATION; RAF-1; PHOSPHORYLATION; EXPRESSION	Machine learning was applied for the automated derivation of causal influences in cellular signaling networks. This derivation relied on the simultaneous measurement of multiple phosphorylated protein and phospholipid components in thousands of individual primary human immune system cells. Perturbing these cells with molecular interventions drove the ordering of connections between pathway components, wherein Bayesian network computational methods automatically elucidated most of the traditionally reported signaling relationships and predicted novel interpathway network causalities, which we verified experimentally. Reconstruction of network models from physiologically relevant primary single cells might be applied to understanding native-state tissue signaling biology, complex drug actions, and dysfunctional signaling in diseased cells.	MIT, Biol Engn Div, Cambridge, MA 02139 USA; Stanford Univ, Sch Med, Baxter Lab Genet Pharmacol, Dept Microbiol & Immunol, Stanford, CA 94305 USA; Harvard Univ, Sch Med, Dept Genet, Boston, MA 02115 USA	Lauffenburger, DA (reprint author), MIT, Biol Engn Div, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	lauffen@mit.edu; gnotan@stanford.edu					CARROLL MP, 1994, J BIOL CHEM, V269, P1249; FRIEDMAN KMN, 1998, P 14 ANN C UNC ART I; Friedman N, 2004, SCIENCE, V303, P799, DOI 10.1126/science.1094068; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Fukuda R, 2003, CANCER RES, V63, P2330; Hartemink A J, 2001, Pac Symp Biocomput, P422; Heckerman D, 1998, NATO ADV SCI I D-BEH, V89, P301; Herzenberg LA, 2002, CLIN CHEM, V48, P1819; Ideker T, 2001, ANNU REV GENOM HUM G, V2, P343, DOI 10.1146/annurev.genom.2.1.343; IRENE JDG, 2002, BIOINFORMATICS, V18, pS241; Irish JM, 2004, CELL, V118, P217, DOI 10.1016/j.cell.2004.06.028; Kelley BP, 2004, NUCLEIC ACIDS RES, V32, pW83, DOI 10.1093/nar/gkh411; MARAIS R, 1995, EMBO J, V14, P3136; Marais R, 1998, SCIENCE, V280, P109, DOI 10.1126/science.280.5360.109; Pe'er D., 2001, BIOINFORMATICS S1, V17, P215; Pearl J, 2000, CAUSALITY MODELS REA; Pearl J., 1988, PROBABILISTIC REASON; PEER D, 2005, SCI STKE 2005; Perez OD, 2003, NAT IMMUNOL, V4, P1083, DOI 10.1038/ni984; Perez OD, 2002, NAT BIOTECHNOL, V20, P155; Perfetto SP, 2004, NAT REV IMMUNOL, V4, P648, DOI 10.1038/nri1416; Roederer M, 2004, CLIN IMMUNOL, V110, P199, DOI 10.1016/j.clim.2003.11.015; Sachs Karen, 2002, Sci STKE, V2002, ppe38, DOI 10.1126/stke.2002.148.pe38; Steffen M, 2002, BMC BIOINFORMATICS, V3, DOI 10.1186/1471-2105-3-34; Woolf PJ, 2005, BIOINFORMATICS, V21, P741, DOI 10.1093/bioinformatics/bti056; Zhang WM, 1998, AM J PHYSIOL-CELL PH, V274, pC82	26	442	460	AMER ASSOC ADVANCEMENT SCIENCE	WASHINGTON	1200 NEW YORK AVE, NW, WASHINGTON, DC 20005 USA	0036-8075		SCIENCE	Science	APR 22	2005	308	5721					523	529		10.1126/science.1105809		7	Multidisciplinary Sciences	Science & Technology - Other Topics	922BK	WOS:000228810500045	
J	Friedel, CC; Jahn, KHV; Sommer, S; Rudd, S; Mewes, HW; Tetko, IV				Friedel, CC; Jahn, KHV; Sommer, S; Rudd, S; Mewes, HW; Tetko, IV			Support vector machines for separation of mixed plant-pathogen EST collections based on codon usage	BIOINFORMATICS			English	Article							FUNGAL SEQUENCES; DROSOPHILA; PATTERNS	Motivation: Discovery of host and pathogen genes expressed at the plant-pathogen interface often requires the construction of mixed libraries that contain sequences from both genomes. Sequence identification requires high-throughput and reliable classification of genome origin. When using single-pass cDNA sequences difficulties arise from the short sequence length, the lack of sufficient taxonomically relevant sequence data in public databases and ambiguous sequence homology between plant and pathogen genes. Results: A novel method is described, which is independent of the availability of homologous genes and relies on subtle differences in codon usage between plant and fungal genes. We used support vector machines (SVMs) to identify the probable origin of sequences. SVMs were compared to several other machine learning techniques and to a probabilistic algorithm (PF-IND) for expressed sequence tag (EST) classification also based on codon bias differences. Our software (Eclat) has achieved a classification accuracy of 93.1% on a test set of 3217 EST sequences from Hordeum vulgare and Blumeria graminis, which is a significant improvement compared to PF-IND (prediction accuracy of 81.2% on the same test set). EST sequences with at least 50 nt of coding sequence can be classified using Eclat with high confidence. Eclat allows training of classifiers for any host-pathogen combination for which there are sufficient classified training sequences.	GSF Forschungszentrum Umwelt & Gesundheit GmbH, Inst Bioinformat, D-85764 Neuherberg, Germany; Univ Muenchen, Inst Informat, D-80538 Munich, Germany; Tech Univ Muenchen, Fak Informat, D-85748 Garching, Germany; Turku Ctr Biotechnol, Bioinformat Grp, Turku, Finland; Tech Univ Muenchen, Wissensch Zentrum Weihenstephan, Dept Genome Oriented Bioinformat, D-85350 Freising Weihenstephan, Germany	Tetko, IV (reprint author), GSF Forschungszentrum Umwelt & Gesundheit GmbH, Inst Bioinformat, Ingolstaedter Landstr 1, D-85764 Neuherberg, Germany.	friedel@informatik.uni-muenchen.de	Tetko, Igor/B-1540-2010; Rudd, Stephen/A-6434-2013	Tetko, Igor/0000-0002-6855-0012; Rudd, Stephen/0000-0002-0344-7487			Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Duret L, 1999, P NATL ACAD SCI USA, V96, P4482, DOI 10.1073/pnas.96.8.4482; FENNOY SL, 1993, NUCLEIC ACIDS RES, V21, P5294, DOI 10.1093/nar/21.23.5294; Heumann K., 1996, Proceedings of the Third South American Workshop on String Processing. WSP 1996; Hsiang T, 2003, J MICROBIOL METH, V54, P339, DOI 10.1016/S0167-7012(03)00067-8; Huang XQ, 1999, GENOME RES, V9, P868, DOI 10.1101/gr.9.9.868; Joachims T., 1999, ADV KERNEL METHODS S; Kawabe A, 2003, GENES GENET SYST, V78, P343, DOI 10.1266/ggs.78.343; Keerthi SS, 2003, NEURAL COMPUT, V15, P1667, DOI 10.1162/089976603321891855; Koski LB, 2001, J MOL EVOL, V52, P540; Lin H.-T., 2003, STUDY SIGMOID KERNEL; Maor R, 2003, CURR GENET, V43, P296, DOI 10.1007/s00294-003-0394-3; Platt J. C., 1998, ADV KERNEL METHODS S, P185; Rudd S, 2003, NUCLEIC ACIDS RES, V31, P128, DOI 10.1093/nar/gkg075; SHARP PM, 1988, NUCLEIC ACIDS RES, V16, P8207, DOI 10.1093/nar/16.17.8207; SLATER G, 2000, THESIS U CAMBRIDGE U; Tetko IV, 2002, J CHEM INF COMP SCI, V42, P717, DOI 10.1021/ci010379o; Vapnik V. N, 1995, NATURE STAT LEARNING; Witten I. H., 2000, DATA MINING PRACTICA	21	13	14	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	APR 15	2005	21	8					1383	1388		10.1093/bioinformatics/bti200		6	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	916QX	WOS:000228401800015	
J	Yang, SS; Lu, WC; Chen, NY; Hu, QN				Yang, SS; Lu, WC; Chen, NY; Hu, QN			Support vector regression based QSPR for the prediction of some physicochemical properties of alkyl benzenes	JOURNAL OF MOLECULAR STRUCTURE-THEOCHEM			English	Article						support vector regression; topological index; quantitative structure-property relationship; alkyl benzene	DESCRIPTORS; MACHINES	Physicochemical properties of alkyl benzenes are essential to separate pure component from alkyl benzene mixture. Support vector regression (SVR), a novel powerful machine learning technology based on statistical learning theory (SLT), integrated with topological indices was applied to the prediction of five physicochemical properties of alkyl benzenes including the normal boiling point (bp), enthalpy of vaporization at the boiling point (H(vb)), critical temperature (T(c)), critical pressure (P(c)), and critical volume (V(c)). In a benchmark test, SVR models for bp, Hvb, Tc, Pc, and V. were compared with several modeling techniques currently used in this field. The prediction accuracy of the model was discussed on the basis of the leave-one-out cross-validation. The results show that the prediction accuracy of SVR model was higher than those of back propagation artificial neural network (BP ANN) and partial least squares (PLS) methods. (c) 2004 Elsevier B.V. All rights reserved.	Shanghai Univ, Coll Sci, Dept Chem, Shanghai 200436, Peoples R China; Cent S Univ, Coll Chem & Chem Engn, Res Ctr Modernizat Chinese Herb Med, Changsha 410083, Peoples R China	Lu, WC (reprint author), Shanghai Univ, Coll Sci, Dept Chem, Shanghai 200436, Peoples R China.	wclu@mail.shu.edu.cn					Brown RD, 1997, J CHEM INF COMP SCI, V37, P1, DOI 10.1021/ci960373c; Burbidge R, 2001, COMPUT CHEM, V26, P5, DOI 10.1016/S0097-8485(01)00094-8; BVASAK SC, 1999, TOPOLOGICAL INDICES; Cai YD, 2003, PEPTIDES, V24, P629, DOI 10.1016/S0196-9781(03)00100-1; Chen JW, 2003, COMPUT BIOL CHEM, V27, P165, DOI 10.1016/S0097-8485(02)00017-7; CHEN NY, 2002, APPL APPL CHEM, V19, P673; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Firpo M, 2000, J MOL STRUC-THEOCHEM, V501, P419, DOI 10.1016/S0166-1280(99)00453-4; [胡黔楠 Hu Qiannan], 2003, [计算机与应用化学, Computers and Applied Chemistry], V20, P386; 李国正, 2002, [计算机与应用化学, Computers and Applied Chemistry], V19, P703; LU HZ, 1982, HDB FUNADAMENTAL DAT; 陆文聪, 2002, [计算机与应用化学, Computers and Applied Chemistry], V19, P697; MA PS, 1993, HDB FUNDAMENTAL DATA; Mracec M, 1996, J MOL STRUC-THEOCHEM, V367, P139, DOI 10.1016/S0166-1280(96)04511-3; Ribeiro FAD, 2003, J MOL STRUC-THEOCHEM, V663, P109, DOI 10.1016/j.theochem.2003.08.107; Stephenson R. M., 1987, HDB THERMODYNAMICS O; Trotter MWB, 2001, MEAS CONTROL-UK, V34, P235; Vapnik VN, 1998, STAT LEARNING THEORY; Yao XJ, 2002, COMPUT CHEM, V26, P159, DOI 10.1016/S0097-8485(01)00093-6; Zhao H, 2004, ACTA CHIM SINICA, V62, P649	20	20	28	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0166-1280		J MOL STRUC-THEOCHEM	Theochem-J. Mol. Struct.	APR 14	2005	719	1-3					119	127		10.1016/j.theochem.2004.10.060		9	Chemistry, Physical	Chemistry	918FL	WOS:000228527600017	
J	Trutschl, M; Dinkova, TD; Rhoads, RE				Trutschl, M; Dinkova, TD; Rhoads, RE			Application of machine learning and visualization of heterogeneous datasets to uncover relationships between translation and developmental stage expression of C-elegans mRNAs	PHYSIOLOGICAL GENOMICS			English	Article						eIF4E; self-organizing map; color scale; mRNA-specific translational control; Caenorhabditis elegans	CAENORHABDITIS-ELEGANS; GENE-EXPRESSION; ISOFORMS; PATTERNS; PROTEIN; EIF4E	The relationships between genes in neighboring clusters in a self-organizing map (SOM) and properties attributed to them are sometimes difficult to discern, especially when heterogeneous datasets are used. We report a novel approach to identify correlations between heterogeneous datasets. One dataset, derived from microarray analysis of polysomal distribution, contained changes in the translational efficiency of Caenorhabditis elegans mRNAs resulting from loss of specific eIF4E isoform. The other dataset contained expression patterns of mRNAs across all developmental stages. Two algorithms were applied to these datasets: a classical scatter plot and an SOM. The outputs were linked using a two-dimensional color scale. This revealed that an mRNA's eIF4E-dependent translational efficiency is strongly dependent on its expression during development. This correlation was not detectable with a traditional one-dimensional color scale.	Louisiana State Univ, Hlth Sci Ctr, Dept Biochem & Mol Biol, Shreveport, LA 71130 USA; Louisiana State Univ, Hlth Sci Ctr, Dept Comp Sci, Shreveport, LA 71130 USA; Louisiana State Univ, Hlth Sci Ctr, Ctr Bioinformat & Computat Biol, Shreveport, LA 71130 USA	Rhoads, RE (reprint author), Louisiana State Univ, Hlth Sci Ctr, Dept Biochem & Mol Biol, Shreveport, LA 71130 USA.	rrhoad@lsuhsc.edu					CHALFIE M, 1994, SCIENCE, V263, P802, DOI 10.1126/science.8303295; Dinkova TD, 2005, MOL CELL BIOL, V25, P100, DOI 10.1128/MCB.25.1.100-113.2005; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; GASCH AP, 2002, GENOME BIOL, V3; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Jankowska-Anyszka M, 1998, J BIOL CHEM, V273, P10538, DOI 10.1074/jbc.273.17.10538; Jiang M, 2001, P NATL ACAD SCI USA, V98, P218, DOI 10.1073/pnas.011520898; Keiper BD, 2000, J BIOL CHEM, V275, P10590, DOI 10.1074/jbc.275.14.10590; Kohonen T., 1995, SELF ORG MAPS; Levkowitz H., 1997, COLOR THEORY MODELIN; LODISH HF, 1974, NATURE, V251, P385, DOI 10.1038/251385a0; Roy PJ, 2002, NATURE, V418, P975, DOI 10.1038/nature01012; Sonenberg NH, 2000, TRANSLATIONAL CONTRO; Stachelska A, 2002, ACTA BIOCHIM POL, V49, P671; SULSTON JE, 1977, DEV BIOL, V56, P110, DOI 10.1016/0012-1606(77)90158-0; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Wang J, 2003, DEVELOPMENT, V130, P1621, DOI 10.1242/dev.00363; Zhang Y, 2002, NATURE, V418, P331, DOI 10.1038/nature00891; Zong Q, 1999, P NATL ACAD SCI USA, V96, P10632, DOI 10.1073/pnas.96.19.10632	19	3	3	AMER PHYSIOLOGICAL SOC	BETHESDA	9650 ROCKVILLE PIKE, BETHESDA, MD 20814 USA	1094-8341		PHYSIOL GENOMICS	Physiol. Genomics	APR 14	2005	21	2					264	273		10.1152/physiolgenomics.00307.2004		10	Cell Biology; Genetics & Heredity; Physiology	Cell Biology; Genetics & Heredity; Physiology	916LX	WOS:000228387600014	
J	Shi, L; Campagne, F				Shi, L; Campagne, F			Building a protein name dictionary from full text: a machine learning term extraction approach	BMC BIOINFORMATICS			English	Article							INFORMATION; GENE; DATABASES; RECEPTORS	Background: The majority of information in the biological literature resides in full text articles, instead of abstracts. Yet, abstracts remain the focus of many publicly available literature data mining tools. Most literature mining tools rely on pre-existing lexicons of biological names, often extracted from curated gene or protein databases. This is a limitation, because such databases have low coverage of the many name variants which are used to refer to biological entities in the literature. Results: We present an approach to recognize named entities in full text. The approach collects high frequency terms in an article, and uses support vector machines (SVM) to identify biological entity names. It is also computationally efficient and robust to noise commonly found in full text material. We use the method to create a protein name dictionary from a set of 80,528 full text articles. Only 8.3% of the names in this dictionary match SwissProt description lines. We assess the quality of the dictionary by studying its protein name recognition performance in full text. Conclusion: This dictionary term lookup method compares favourably to other published methods, supporting the significance of our direct extraction approach. The method is strong in recognizing name variants not found in SwissProt.	Weill Cornell Med Coll, Inst Computat Biomed, New York, NY 10021 USA; Weill Cornell Med Coll, Dept Physiol & Biophys, New York, NY 10021 USA	Campagne, F (reprint author), Weill Cornell Med Coll, Inst Computat Biomed, 1300 York Ave, New York, NY 10021 USA.	les2007@med.cornell.edu; fac2003@med.cornell.edu	Campagne, Fabien/F-5158-2010				Albert S, 2003, MOL ENDOCRINOL, V17, P1555, DOI 10.1210/me.2002-0424; BOLDI P, 2004, MG4J MANAGING GIGABY; Burr Settles, 2004, BIOMEDICAL NAMED ENT; Chang JT, 2004, BIOINFORMATICS, V20, P216, DOI 10.1093/bioinformatics/btg393; Corney DPA, 2004, BIOINFORMATICS, V20, P3206, DOI 10.1093/bioinformatics/bth386; CUNNINGHAM A, 1997, CS9702 U SHEFF, P1; Franzen K, 2002, INT J MED INFORM, V67, P49, DOI 10.1016/S1386-5056(02)00052-7; Hatzivassiloglou V, 2001, Bioinformatics, V17 Suppl 1, pS97; Hersh W, 2004, ST HEAL T, V107, P773; Hirschman L, 2002, J BIOMED INFORM, V35, P247, DOI 10.1016/S1532-0464(03)00014-5; Horn F, 2004, BIOINFORMATICS, V20, P557, DOI 10.1093/bioinformatics/btg449; Jenssen TK, 2001, NAT GENET, V28, P21, DOI 10.1038/ng0501-21; Joachims T., 1999, ADV KERNEL METHODS S; JOACHIMS T, 2001, KLUWER INT SERIES EN, P205; JOACHIMS T, 2004, SVMLIGHT; Krauthammer M, 2000, GENE, V259, P245, DOI 10.1016/S0378-1119(00)00431-5; Lafferty J., 2001, CONDITIONAL RANDOM F; MIKA S, 2004, BIOINFORMATICS, V20, P1241; Muller HM, 2004, PLOS BIOL, V2, P1984, DOI 10.1371/journal.pbio.0020309; PALJMANS JJ, 1999, EXPLORATIONS DOCUMEN; PLATT JC, 1999, ADV LARGE MARGIN CLA, P422; Rzhetsky A, 2004, J BIOMED INFORM, V37, P43, DOI 10.1016/j.jbi.2003.10.001; Schuemie MJ, 2004, BIOINFORMATICS, V20, P2597, DOI 10.1093/bioinformatics/bth291; Srdanovic M, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-5; Tanabe Lorraine, 2004, J Bioinform Comput Biol, V1, P611, DOI 10.1142/S0219720004000399; Wheeler DL, 2004, NUCLEIC ACIDS RES, V32, pD35, DOI 10.1093/nar/gkh073; Wilkinson DM, 2004, P NATL ACAD SCI USA, V101, P5241, DOI 10.1073/pnas.0307740100; Wren JD, 2005, NUCLEIC ACIDS RES, V33, pD289, DOI 10.1093/nar/gki137; Yeh AS, 2003, BIOINFORMATICS, V19, P331; Zhou GD, 2004, BIOINFORMATICS, V20, P1178, DOI 10.1093/bioinformatics/bth060	30	7	8	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	APR 7	2005	6								88	10.1186/1471-2105-6-88		13	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	923SR	WOS:000228930100002	
J	Dinerstein, J; Egbert, PK				Dinerstein, J; Egbert, PK			Fast multi-level adaptation for interactive autonomous characters	ACM TRANSACTIONS ON GRAPHICS			English	Article						algorithms; human factors; performance; computer animation; character animation; behavioral modeling; AI-based animation; machine learning	BEHAVIORAL ANIMATION; MOBILE ROBOT	Adaptation (online learning) by autonomous virtual characters, due to interaction with a human user in a virtual environment, is a difficult and important problem in computer animation. In this article we present a novel multi-level technique for fast character adaptation. We specifically target environments where there is a cooperative or competitive relationship between the character and the human that interacts with that character. In our technique, a distinct learning method is applied to each layer of the character's behavioral or cognitive model. This allows us to efficiently leverage the character's observations and experiences in each layer. This also provides a convenient temporal distinction between what observations and experiences provide pertinent lessons for each layer. Thus the character can quickly and robustly learn how to better interact with any given unique human user, relying only on observations and natural performance feedback from the environment (no explicit feedback from the human). Our technique is designed to be general, and can be easily integrated into most existing behavioral animation systems. It is also fast and memory efficient.	Brigham Young Univ, Dept Comp Sci, Provo, UT 84602 USA	Dinerstein, J (reprint author), Brigham Young Univ, Dept Comp Sci, 3366 TCMB, Provo, UT 84602 USA.	jondinerstein@yahoo.com; egbert@cs.byu.edu					Arikan O, 2003, ACM T GRAPHIC, V22, P402, DOI 10.1145/882262.882284; BLUMBERG B, 2002, P 29 ANN C COMP GRAP, P417, DOI 10.1145/566570.566597; BLUMBERG BM, 1995, P SIGGRAPH 95, P47, DOI 10.1145/218380.218405; BROOKS RA, 1986, IEEE T ROBOTIC AUTOM, V2, P14, DOI 10.1109/JRA.1986.1087032; DINERSTEIN J, 2004, J COMPUT ANIM VIRTUA, V15, P95; DINERSTEIN J, 2004, P COMP AN SOC AG CAS, P231; Egges A, 2004, COMPUT ANIMAT VIRT W, V15, P1, DOI 10.1002/cav.3; EVANS R, 2002, AI GAME PROGRAMMING, P567; FALOUTSOS P, 2001, P ACM SIGGRAPH, P39; Funge J., 1999, P SIGGRAPH 99, P29, DOI 10.1145/311535.311538; Gadanho S.C., 2003, J MACHINE LEARNING R, V4, P385, DOI 10.1162/jmlr.2003.4.3.385; Gillies MFP, 2002, J VISUAL COMP ANIMAT, V13, P287, DOI 10.1002/vis.296; Gmytrasiewicz PJ, 2000, AUTON AGENT MULTI-AG, V3, P319, DOI 10.1023/A:1010028119149; Grzeszczuk R., 1998, P SIGGRAPH 98, P9, DOI 10.1145/280814.280816; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; He L.-W., 1996, P 23 ANN C COMP GRAP, P217, DOI 10.1145/237170.237259; ISLA D, 2001, P INT JOINT C ART IN, P1051; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237; Kaminka GA, 2002, COMMUN ACM, V45, P43; Kasper M, 2001, ROBOT AUTON SYST, V34, P153, DOI 10.1016/S0921-8890(00)00119-6; Kerkez B., 2003, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V12, DOI 10.1142/S0218213003001307; Laird J. E., 2001, Proceedings of the Fifth International Conference on Autonomous Agents, DOI 10.1145/375735.376343; van Lent M., 2001, Proceedings of the First International Conference on Knowledge Capture; MATTHEWS G, 1997, PERSONALITY EMOTION; MELTZOFF AN, 1992, INFANT BEHAV DEV, V15, P479, DOI 10.1016/0163-6383(92)80015-M; Millar RJ, 1999, COMPUT GRAPH-UK, V23, P127, DOI 10.1016/S0097-8493(98)00121-6; Minsky M. L., 1985, SOC MIND; Mitchell T, 1997, MACHINE LEARNING; MONZANI J, 2001, COMPUT GRAPH FORUM, V20, P3; Newell A., 1990, UNIFIED THEORIES COG; Perlin K., 1996, P SIGGRAPH 96, P205, DOI 10.1145/237170.237258; PRICE R, 2002, THESIS U BRIT COLUMB; Rao A. S., 1995, P 1 INT C MULT SYST; Reif JH, 1999, ROBOT AUTON SYST, V27, P171, DOI 10.1016/S0921-8890(99)00004-4; Reynolds C., 1987, P 14 ANN C COMP GRAP, P25, DOI 10.1145/37401.37406; Schyns PG, 1998, BEHAV BRAIN SCI, V21, P1; SEN S, 1997, AAAI 97 WORKSH MULT, P59; Sims K., 1994, P 21 ANN C COMP GRAP, P15, DOI 10.1145/192161.192167; Stone P., 2000, LAYERED LEARNING MUL; Stone P, 2000, AUTON ROBOT, V8, P345, DOI 10.1023/A:1008942012299; Sutton R.S., 1998, REINFORCEMENT LEARNI; TESAURO G, 1995, COMMUN ACM, V38, P58, DOI 10.1145/203330.203343; TOMLINSON B, 2002, 1 GSFC JPL WORKSH RA; Tu X., 1994, P SIGGRAPH 94, P43, DOI 10.1145/192161.192170; YOON B, 2003, P DARPA COGN SYST C; ZHU T, 2003, P 9 INT C US MOD	46	10	11	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	0730-0301		ACM T GRAPHIC	ACM Trans. Graph.	APR	2005	24	2					262	288		10.1145/1061347.1061352		27	Computer Science, Software Engineering	Computer Science	928QX	WOS:000229287900005	
J	Granitto, PM; Verdes, PF; Ceccatto, HA				Granitto, PM; Verdes, PF; Ceccatto, HA			Neural network ensembles: evaluation of aggregation algorithms	ARTIFICIAL INTELLIGENCE			English	Article						machine learning; ensemble methods; neural networks; regression		Ensembles of artificial neural networks show improved generalization capabilities that outperform those of single networks. However, for aggregation to be effective, the individual networks must be as accurate and diverse as possible. An important problem is, then, how to tune the aggregate members in order to have an optimal compromise between these two conflicting conditions. We present here an extensive evaluation of several algorithms for ensemble construction, including new proposals and comparing them with standard methods in the literature. We also discuss a potential problem with sequential aggregation algorithms: the non-frequent but damaging selection through their heuristics of particularly bad ensemble members. We introduce modified algorithms that cope with this problem by allowing individual weighting of aggregate members. Our algorithms and their weighted modifications are favorably tested against other methods in the literature, producing a sensible improvement in performance on most of the standard statistical databases used as benchmarks. (c) 2004 Elsevier B.V. All rights reserved.	Univ Nacl Rosario, CONICET, Inst Fis Rosario, RA-2000 Rosario, Santa Fe, Argentina	Ceccatto, HA (reprint author), Univ Nacl Rosario, CONICET, Inst Fis Rosario, Blvd 27 Febrero 210 Bis, RA-2000 Rosario, Santa Fe, Argentina.	ceccatto@ifir.edu.ar	Granitto, Pablo/A-3645-2013				Avnimelech R, 1999, NEURAL COMPUT, V11, P499, DOI 10.1162/089976699300016746; BREIMAN L, 1996, OUT OF BAG ESTIMATIO; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Carney J G, 2000, Int J Neural Syst, V10, P267, DOI 10.1016/S0129-0657(00)00027-2; Drucker H., 1997, P 14 INT C MACH LEAR, P107; DRUCKER H, 1999, COMBINING ARTIFICIAL, P51; Duffy N., 2000, P 13 ANN C COMP LEAR, P208; Efron B., 1993, INTRO BOOTSTRAP; Freund Y., 1995, P 2 EUR C COMP LEARN, P23; Friedman J, 1999, GREEDY FUNCTION APPR; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Grant JM, 2001, WOMEN HEALTH ISS, V11, P305, DOI 10.1016/S1049-3867(01)00095-0; IKEDA K, 1979, OPT COMMUN, V30, P257, DOI 10.1016/0030-4018(79)90090-7; Karakoulas G, 2000, ADV NEUR IN, P247; Muller A, 1999, CLIN DIAGN LAB IMMUN, V6, P243; Naftaly U, 1997, NETWORK-COMP NEURAL, V8, P283, DOI 10.1088/0954-898X/8/3/004; NAVONE H, 2001, REV IBEROAMERICANA I, V3, P70; Ratsch G, 2002, MACH LEARN, V48, P189, DOI 10.1023/A:1013907905629; Ridgeway G., 1999, P ART INT STAT, P152; Rosen B. E., 1996, Connection Science, V8, DOI 10.1080/095400996116820; Sharkey Amanda J. C., 1999, COMBINING ARTIFICIAL; Zemel RS, 2001, ADV NEUR IN, V13, P696; Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X	24	32	43	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0004-3702		ARTIF INTELL	Artif. Intell.	APR	2005	163	2					139	162		10.1016/j.artint.2004.09.006		24	Computer Science, Artificial Intelligence	Computer Science	909JW	WOS:000227857200001	
J	Krstacic, A; Krstacic, G; Gamberger, D; Car, Z				Krstacic, A; Krstacic, G; Gamberger, D; Car, Z			Stroke patient models based on supervised inductive machine learning	ATHEROSCLEROSIS SUPPLEMENTS			English	Meeting Abstract	75th Congress of the European-Atherosclerosis-Society	APR 23-26, 2005	Prague, CZECH REPUBLIC	European Atherosclerosis Soc					Univ Clin Traumatol, Zagreb, Croatia; Inst Cardiovasc Dis, Zagreb, Croatia; Rudjer Boskovic Inst, Zagreb, Croatia; Univ Clin Ctr, Zagreb, Croatia			Gamberger, Dragan/J-3752-2012					0	0	0	ELSEVIER IRELAND LTD	CLARE	ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND	1567-5688		ATHEROSCLEROSIS SUPP	Atheroscler. Suppl.	APR	2005	6	1					158	159		10.1016/S1567-5688(05)80619-1		2	Peripheral Vascular Disease	Cardiovascular System & Cardiology	921BK	WOS:000228739000620	
J	Fushiki, T; Komaki, F; Aihara, K				Fushiki, T; Komaki, F; Aihara, K			Nonparametric bootstrap prediction	BERNOULLI			English	Article						asymptotic theory; bagging; bootstrap predictive distribution; information geometry; Kullback-Leibler divergence	FIT	Ensemble learning has recently been intensively studied in the field of machine learning. 'Bagging' is a method of ensemble learning and uses bootstrap data to construct various predictors. The required prediction is then obtained by averaging the predictors. Harris proposed using this technique with the parametric bootstrap predictive distribution to construct predictive distributions, and showed that the parametric bootstrap predictive distribution gives asymptotically better prediction than a plug-in distribution with the maximum likelihood estimator. In this paper, we investigate nonparametric bootstrap predictive distributions. The nonparametric bootstrap predictive distribution is precisely that obtained by applying bagging to the statistical prediction problem. We show that the nonparametric bootstrap predictive distribution gives predictions asymptotically as good as the parametric bootstrap predictive distribution.	Inst Stat Math, Minato Ku, Tokyo 1068569, Japan; Univ Tokyo, Grad Sch Informat Sci & Technol, Dept Math Informat, Bunkyo Ku, Tokyo 1138656, Japan; Univ Tokyo, Grad Sch Frontier Sci, Dept Complex Sci & Engn, Bunkyo Ku, Tokyo 1138656, Japan; JST, ERATO Aihara Complex Modelling Project, Tokyo 1510065, Japan	Fushiki, T (reprint author), Inst Stat Math, Minato Ku, 4-6--7 Minami Azabu, Tokyo 1068569, Japan.	fushiki@ism.ac.jp; komaki@mist.i.u-toyko.ac.jp; aihara@sat.t.u-toyko.ac.jp					AITCHISON J, 1975, BIOMETRIKA, V62, P547, DOI 10.1093/biomet/62.3.547; AMARI S, 2000, METHODS INFORMATION; Amari S., 1985, DIFFERENTIAL GEOMETR; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Fushiki T, 2004, SCAND J STAT, V31, P403, DOI 10.1111/j.1467-9469.2004.02_127.x; HARRIS IR, 1989, BIOMETRIKA, V76, P675, DOI 10.1093/biomet/76.4.675; Hartigan JA, 1998, ANN STAT, V26, P2083; Komaki F, 1996, BIOMETRIKA, V83, P299, DOI 10.1093/biomet/83.2.299; McCullagh P., 1987, TENSOR METHODS STAT; Vidoni P, 1995, BIOMETRIKA, V82, P855, DOI 10.1093/biomet/82.4.855	11	6	6	INT STATISTICAL INST	VOORBURG	428 PRINSES BEATRIXLAAN, 2270 AZ VOORBURG, NETHERLANDS	1350-7265		BERNOULLI	Bernoulli	APR	2005	11	2					293	307		10.3150/bj/1116340296		15	Statistics & Probability	Mathematics	920AN	WOS:000228659500006	
J	Dror, G; Sorek, R; Shamir, R				Dror, G; Sorek, R; Shamir, R			Accurate identification of alternatively spliced exons using support vector machine	BIOINFORMATICS			English	Article							INTRONIC SEQUENCES; HUMAN GENES; CLASSIFICATION; RNA; PREDICTION; GENOME; KERNELS; CANCER; SITES; MOUSE	Motivation: Alternative splicing is a major component of the regulatory action on mammalian transcriptomes. It is estimated that over half of all human genes have more than one splice variant. Previous studies have shown that alternatively spliced exons possess several features that distinguish them from constitutively spliced ones. Recently, we have demonstrated that such features can be used to distinguish alternative from constitutive exons. In the current study, we used advanced machine learning methods to generate robust classifier of alternative exons. Results: We extracted several hundred local sequence features of constitutive as well as alternative exons. Using feature selection methods we find seven attributes that are dominant for the task of classification. Several less informative features help to slightly increase the performance of the classifier. The classifier achieves a true positive rate of 50% for a false positive rate of 0.5%. This result enables one to reliably identify alternatively spliced exons in exon databases that are believed to be dominated by constitutive exons.	Acad Coll Tel Aviv Yaffo, IL-4044 Tel Aviv, Israel; Tel Aviv Univ, Sackler Fac Med, Dept Human Genet, IL-69978 Tel Aviv, Israel; Compugen, IL-69512 Tel Aviv, Israel; Tel Aviv Univ, Sch Comp Sci, IL-69073 Tel Aviv, Israel	Dror, G (reprint author), Acad Coll Tel Aviv Yaffo, IL-4044 Tel Aviv, Israel.	gideon@mta.ac.il	Shamir, Ron/E-6514-2011				AGARWAL S, 2004, UIUCDCSR20042433 DEP; Brett D, 2000, FEBS LETT, V474, P83, DOI 10.1016/S0014-5793(00)01581-7; BROWNELL WE, 1999, VOLTA REV, V99, P9; Cartegni L, 2002, NAT REV GENET, V3, P285, DOI 10.1038/nrg775; Clark F, 2002, HUM MOL GENET, V11, P451, DOI 10.1093/hmg/11.4.451; Duan K, 2003, NEUROCOMPUTING, V51, P41, DOI 10.1016/S0925-2312(02)00601-X; Florea L, 1998, GENOME RES, V8, P967; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Graveley BR, 2001, TRENDS GENET, V17, P100, DOI 10.1016/S0168-9525(00)02176-4; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Jaakkola T, 2000, J COMPUT BIOL, V7, P95, DOI 10.1089/10665270050081405; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; Johnson JM, 2003, SCIENCE, V302, P2141, DOI 10.1126/science.1090100; Kan ZY, 2002, GENOME RES, V12, P1837, DOI 10.1101/gr.764102; Kan ZY, 2001, GENOME RES, V11, P889, DOI 10.1101/gr.155001; Lander ES, 2001, NATURE, V409, P860, DOI 10.1038/35057062; Leslie CS, 2004, BIOINFORMATICS, V20, P467, DOI 10.1093/bioinformatics/btg431; Ling C. X., 2003, P 18 INT C ART INT I, P329; Maniatis T, 2002, NATURE, V418, P236, DOI 10.1038/418236a; Mironov AA, 1999, GENOME RES, V9, P1288, DOI 10.1101/gr.9.12.1288; Modrek B, 2001, NUCLEIC ACIDS RES, V29, P2850, DOI 10.1093/nar/29.13.2850; Modrek B, 2003, NAT GENET, V34, P177, DOI 10.1038/ng1159; Modrek B, 2002, NAT GENET, V30, P13, DOI 10.1038/ng0102-13; Scholkopf B., 1999, ADV KERNEL METHODS; Smola A. J., 2000, ADV LARGE MARGIN CLA; Sorek R, 2004, GENOME RES, V14, P1617, DOI 10.1101/gr.2572604; Sorek R, 2004, MOL CELL, V14, P221, DOI 10.1016/S1097-2765(04)00181-9; Sorek R, 2004, TRENDS GENET, V20, P68, DOI 10.1016/j.tig.2003.12.004; Sorek R, 2003, GENOME RES, V13, P1631, DOI 10.1101/gr.1208803; Sun YF, 2003, COMPUT BIOL MED, V33, P17, DOI 10.1016/S0010-4825(02)00057-4; Vapnik VN, 1998, STAT LEARNING THEORY; Yamamura M, 2003, GENOME INFORM, V14, P426; Zhang XHF, 2003, GENOME RES, V13, P2637, DOI 10.1101/gr.1679003; ZHUANG Y, 1986, CELL, V46, P827, DOI 10.1016/0092-8674(86)90064-4; Zien A, 2000, BIOINFORMATICS, V16, P799, DOI 10.1093/bioinformatics/16.9.799	36	53	59	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	APR 1	2005	21	7					897	901		10.1093/bioinformatics/bti132		5	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	911CB	WOS:000227977800009	
J	Zeng, FZ; Qiu, ZD; Leng, YG; Yue, JH				Zeng, FZ; Qiu, ZD; Leng, YG; Yue, JH			A redundancy-free, accurate analytical center machine for classification	CHINESE JOURNAL OF ELECTRONICS			English	Article						redundancy constraints removal; analytical center; polyhedron; incremental algorithm		Analytical center machine (ACM) has remarkable generalization performance based on analytical center of version space and outperforms SVM. From the analysis of geometry of machine learning and principle of ACM, it is showed that some training patterns are redundant to the definition of version space. Redundant patterns push ACM classifier away from analytical center of the prime version space so that the generalization performance degrades, at the same time redundant patterns slow down the classifier and reduce the efficiency of storage. Thus, an incremental algorithm is proposed to remove redundant patterns and embed into the frame of ACM that yields a Redundancy free accurate-Analytical center machine (RFA-ACM) for classification. Experiments with Heart, Thyroid, Banana datasets demonstrate the validity of RFA-ACM.	Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China; Shangdong Inst Business & Technol, Sch Informat & Elect, Yantai 264005, Peoples R China	Zeng, FZ (reprint author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.						CARON RJ, ANAL CTR REPELLING I; HERBRICH R, 2000, P ESANN 2000, P49; Scholkopf B., 1999, ADV KERNEL METHODS S; Smola A. J., 2000, ADV LARGE MARGIN CLA; Sonnevend G., 1985, LECT NOTES CONTROL I, P866; Trafalis TB, 2002, MACH LEARN, V46, P203, DOI 10.1023/A:1012458531022; Vapnik V. N, 1995, NATURE STAT LEARNING	7	0	0	TECHNOLOGY EXCHANGE LIMITED HONG KONG	SHATIN	26-28 AU PUI WAN ST, STE 1102, FO TAN INDUSTRIAL CENTRE, FO TAN, SHATIN, 00000, PEOPLES R CHINA	1022-4653		CHINESE J ELECTRON	Chin. J. Electron.	APR	2005	14	2					225	228				4	Engineering, Electrical & Electronic	Engineering	920RV	WOS:000228708700008	
J	Le, L; Chi, K; Tyldesley, S; Flibotte, S; Diamond, DL; Kuzyk, MA; Sadar, MD				Le, L; Chi, K; Tyldesley, S; Flibotte, S; Diamond, DL; Kuzyk, MA; Sadar, MD			Identification of serum amyloid a as a biomarker to distinguish prostate cancer patients with bone lesions	CLINICAL CHEMISTRY			English	Article							ACUTE-PHASE PROTEIN; ANDROGEN RECEPTOR; ALKALINE-PHOSPHATASE; A SAA; DISEASE-ACTIVITY; ANTIGEN; INTERLEUKIN-6; EXPRESSION; CELLS; ACTIVATION	Background: Prostate cancer has a propensity to metastasize to the bone. Currently, there are no curative treatments for this stage of the disease. Sensitive biomarkers that can be monitored in the blood to indicate the presence or development of bone metastases and/or response to therapies are lacking. Surf ace-enhanced laser desorption/ionization time-of-flight mass spectrometry (SELDI-TOF MS) is an affinity-based approach that allows sensitive and high-throughput protein profiling and screening of biological samples. Methods: We used SELDI-TOF MS for protein profiling of sera from prostate cancer patients (n = 38) with and without bone metastases in our effort to identify individual or multiple serum markers that may be of added benefit to those in current use. Serum was applied to ProteinChip (R) surfaces (H4 and IMAC) to quickly screen samples and detect peaks predominating in the samples obtained from patients with bone metastases. Unique proteins in the bone metastasis cohort observed by SELDI-TOF MS were identified by two-dimensional gel electrophoresis, in-gel trypsin digestion, and tandem MS. The identities of the proteins were confirmed by ELISA and immunodepletion assays. Results: The cluster of unique proteins in the sera of patients with bone metastases was identified as isoforms of serum amyloid A. Machine-learning algorithms were also used to identify patients with bone metastases with a sensitivity and specificity of 89.5%. Conclusions: SELDI-TOF MS protein profiling in combination with other proteomic approaches may provide diagnostic tools with potential clinical applications and serve as tools to aid in the discovery of biomarkers associated with various diseases. (c) 2005 American Association for Clinical Chemistry.	British Columbia Canc Agcy, Genom Sci Ctr, Vancouver, BC V5Z 4E6, Canada; Ciphergen Biosyst Inc, Fremont, CA USA	Sadar, MD (reprint author), British Columbia Canc Agcy, Genom Sci Ctr, 600 West 10th Ave, Vancouver, BC V5Z 4E6, Canada.	msadar@bccrc.ca	Sadar, Marianne/E-9136-2012				ADLER HL, 1999, J UROLOGY, V161, P181; Berruti A, 1997, ANTICANCER RES, V17, P4697; Berruti A, 2001, ANN ONCOL, V12, pS153; BIRAN H, 1986, J CLIN PATHOL, V39, P794, DOI 10.1136/jcp.39.7.794; Blaszczyk N, 2004, CLIN CANCER RES, V10, P1860, DOI 10.1158/1078-0432.CCR-0974-3; BOVA GS, 2001, PROSTATE CANC BIOL G, P39; TWILLIE DA, 1995, UROLOGY, V45, P542, DOI 10.1016/S0090-4295(99)80034-X; Cazares LH, 1999, PROSTATE CANCER P D, V5/6, P264, DOI 10.1038/sj.pcan.4500384; Coleman RE, 1998, EUR J CANCER, V34, P252, DOI 10.1016/S0959-8049(97)10134-4; Collins Andrew R., 1998, Molecular Aspects of Medicine, V19, P359, DOI 10.1016/S0098-2997(99)00003-5; CULIG Z, 1994, CANCER RES, V54, P5474; Diamond DL, 2001, J IMMUNOL METHODS, V256, P65, DOI 10.1016/S0022-1759(01)00442-2; Drachenberg DE, 1999, PROSTATE, V41, P127, DOI 10.1002/(SICI)1097-0045(19991001)41:2<127::AID-PROS7>3.0.CO;2-H; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; GALASKO CSB, 1981, BONE METASTASIS, V6, P49; GLEASON DONALD F., 1966, CANCER CHEMO THERAP REP, V50, P125; GREENLEE LK, 2000, CA CANC J CLIN, V50, P7; HAQ M, 1992, CANCER RES, V52, P4613; Hobisch A, 1998, CANCER RES, V58, P4640; Hoosein N, 1995, Urol Oncol, V1, P246, DOI 10.1016/1078-1439(96)00012-9; Huber P R, 1987, Scand J Urol Nephrol Suppl, V104, P33; KANETI J, 1984, UROL RES, V12, P239; Kantoff PW, 1999, J CLIN ONCOL, V17, P2506; Li JN, 2002, CLIN CHEM, V48, P1296; MACKINTOSH J, 1990, BRIT J UROL, V66, P88, DOI 10.1111/j.1464-410X.1990.tb14871.x; NEUHOFF V, 1988, ELECTROPHORESIS, V9, P255, DOI 10.1002/elps.1150090603; OESTERLING JE, 1991, J UROLOGY, V145, P907; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; PLESNICAR S, 1985, CLIN EXP METASTAS, V3, P103, DOI 10.1007/BF01758959; Poon TCW, 2003, CLIN CHEM, V49, P752, DOI 10.1373/49.5.752; Qu YS, 2002, CLIN CHEM, V48, P1835; RAYNES JG, 1991, CLIN EXP IMMUNOL, V83, P488; RIEGMAN PHJ, 1991, MOL ENDOCRINOL, V5, P1921; ROSENTHAL CJ, 1979, ANN INTERN MED, V91, P383; Sabbatini P, 1999, J CLIN ONCOL, V17, P948; Sadar MD, 1999, ENDOCR-RELAT CANCER, V6, P487, DOI 10.1677/erc.0.0060487; SADI MV, 1991, CANCER, V67, P3057, DOI 10.1002/1097-0142(19910615)67:12<3057::AID-CNCR2820671221>3.0.CO;2-S; SCHAGGER H, 1987, ANAL BIOCHEM, V166, P368, DOI 10.1016/0003-2697(87)90587-2; SOLOWAY MS, 1988, CANCER, V61, P195, DOI 10.1002/1097-0142(19880101)61:1<195::AID-CNCR2820610133>3.0.CO;2-Y; Srinivas PR, 2001, CLIN CHEM, V47, P1901; STAMEY TA, 1987, NEW ENGL J MED, V317, P909, DOI 10.1056/NEJM198710083171501; Stenman UH, 2000, UROLOGY, V56, P893, DOI 10.1016/S0090-4295(00)00812-8; Tannock IF, 1996, J CLIN ONCOL, V14, P1756; Ueda T, 2002, J BIOL CHEM, V277, P38087, DOI 10.1074/jbc.M203313200; Ueda T, 2002, J BIOL CHEM, V277, P7076, DOI 10.1074/jbc.M108255200; Urieli-Shoval S, 2000, CURR OPIN HEMATOL, V7, P64, DOI 10.1097/00062752-200001000-00012; Urieli-Shoval S, 1998, J HISTOCHEM CYTOCHEM, V46, P1377; URWIN GH, 1985, BRIT J UROL, V57, P711, DOI 10.1111/j.1464-410X.1985.tb07038.x; van Delft JHM, 1998, CRIT REV TOXICOL, V28, P477; VANDERKWAST TH, 1991, INT J CANCER, V48, P189, DOI 10.1002/ijc.2910480206; Wehbi NK, 2002, J UROLOGY, V167, P2215, DOI 10.1016/S0022-5347(05)65131-2; WEINSTEIN PS, 1984, SCAND J IMMUNOL, V19, P193; Witten I. H., 2000, DATA MINING PRACTICA; Wolff JM, 1998, UROL INT, V61, P12, DOI 10.1159/000030276; Xiao Z, 2000, PROTEIN EXPRES PURIF, V19, P12, DOI 10.1006/prep.2000.1222; Zhau Haiyen E., 2000, Cancer, V88, P2995, DOI 10.1002/1097-0142(20000615)88:12+<2995::AID-CNCR15>3.0.CO;2-Y; Zhukov TA, 2003, LUNG CANCER, V40, P267, DOI 10.1016/S0169-5002(03)00082-5	57	74	84	AMER ASSOC CLINICAL CHEMISTRY	WASHINGTON	2101 L STREET NW, SUITE 202, WASHINGTON, DC 20037-1526 USA	0009-9147		CLIN CHEM	Clin. Chem.	APR	2005	51	4					695	707		10.1373/clinchem.2004.041087		13	Medical Laboratory Technology	Medical Laboratory Technology	910MW	WOS:000227936600004	
J	Ganyun, LV; Cheng, HZ; Zhai, HB; Dong, LX				Ganyun, LV; Cheng, HZ; Zhai, HB; Dong, LX			Fault diagnosis of power transformer based on multi-layer SVM classifier	ELECTRIC POWER SYSTEMS RESEARCH			English	Article						fault diagnosis; multi-layer SVM classifier; power transformer; reliability	DISSOLVED-GAS ANALYSIS; INCIPIENT FAULTS; NEURAL NETWORKS; EXPERT-SYSTEM	Support vector machine (SVM) is a novel machine learning method based on statistical learning theory (SLT). SVM is powerful for the problem with small sampling, nonlinear and high dimension. A multi-layer SVM classifier is applied to fault diagnosis of power transformer for the first time in this paper. Content of five diagnostic gases dissolved in oil obtained by dissolved gas analysis (DGA) is preprocessed through a special data processing, and six features are extracted for SVMs. Then, the multi-layer SVM classifier is trained with the training samples, which are extracted by the above data processing. Finally, the four fault types of transformer are identified by the trained classifier. The test results show that the classifier has an excellent performance on training speed and reliability. (C) 2004 Published by Elsevier B.V.	Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai 200030, Peoples R China	Ganyun, LV (reprint author), Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai 200030, Peoples R China.	stmc17@sina.com; chenghz@online.sh.cn					Su Q, 2000, IEEE T POWER SYST, V15, P593, DOI 10.1109/59.867146; Chan WC, 2001, ENG APPL ARTIF INTEL, V14, P105, DOI 10.1016/S0952-1976(00)00069-5; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; DUKARM JJ, 1993, CAN C EL COMP ENG, V1, P329; Francis E.H.T., 2001, OMEGA, V29, P309; HONG TY, 1999, IEEE T POWER DELIVER, V14, P1342; Huang YC, 1997, IEEE T POWER DELIVER, V12, P761; Jack LB, 2002, MECH SYST SIGNAL PR, V16, P373, DOI 10.1006/mssp.2001.1454; LIN CE, 1993, IEEE T POWER DELIVER, V8, P231, DOI 10.1109/61.180341; Lu J. W., 2001, P IEEE INT WORKSH NE, P373; Mofizul Islam S., 2000, IEEE Transactions on Dielectrics and Electrical Insulation, V7, DOI 10.1109/94.841806; Purkait P., 2000, POW ENG SOC WINT M, V<IT>3</IT>, P2181; ROGERS RR, 1978, IEEE T ELECTR INSUL, V13, P349, DOI 10.1109/TEI.1978.298141; Saha TK, 2003, IEEE T DIELECT EL IN, V10, P903, DOI 10.1109/TDEI.2003.1237337; Thang KF, 2003, IEEE T POWER DELIVER, V18, P1241, DOI 10.1109/TPWRD.2003.817733; Vapnik V. N, 1995, NATURE STAT LEARNING; Wang MH, 2003, IEEE T POWER DELIVER, V18, P164, DOI 10.1109/TPWRD.2002.803838; Wang MH, 2003, IEE P-GENER TRANSM D, V150, P679, DOI 10.1049/ip-gtd:20030901; Wang ZY, 1998, IEEE T POWER DELIVER, V13, P1224; YAN WW, 2002, P 4 WORLD C INT CONT, P2670; YANN CH, 2003, IEEE T POWER DELIVER, V18, P1257; YANN CH, 2003, IEEE T POWER DELIVER, V18, P843; Zhang Y, 1996, IEEE T POWER DELIVER, V11, P1836, DOI 10.1109/61.544265	23	17	21	ELSEVIER SCIENCE SA	LAUSANNE	PO BOX 564, 1001 LAUSANNE, SWITZERLAND	0378-7796		ELECTR POW SYST RES	Electr. Power Syst. Res.	APR	2005	74	1					1	7		10.1016/j.epsr.2004.07.008		7	Engineering, Electrical & Electronic	Engineering	904SQ	WOS:000227518400001	
J	Abdel-Aal, RE				Abdel-Aal, RE			Improving electric load forecasts using network committees	ELECTRIC POWER SYSTEMS RESEARCH			English	Article						machine learning; neural networks; abductive networks; GMDH; network committee; network ensemble; modeling; forecasting; load forecasting; daily peak load; power system planning	ARTIFICIAL NEURAL-NETWORK; PREDICTORS; ENSEMBLES	Accurate daily peak load forecasts are important for secure and profitable operation of modem power utilities, with deregulation and competition demanding ever-increasing accuracies. Machine learning techniques including neural and abductive networks have been used for this purpose. Network committees have been proposed for improving regression and classification accuracy in many disciplines, but are yet to be widely applied to load forecasting. This paper presents a formal approach to apply the technique using historical load and temperature data spanning multiple years, with individual committee members trained on different years. Correlation among data for successive years is investigated and methods to enhance independence between member models for improving committee performance are described. Both neural and abductive networks implementations are presented and compared. An abductive network three-member committee was developed on data for three successive years and evaluated on the fourth year. Compared to a monolithic model trained on the same full three-year data, the committee reduces the mean absolute percentage error from 2.52% to 2.19%. The corresponding reduction in the mean of the absolute error from 70 MW to 61 MW is statistically significant at the 95% confidence level. (C) 2004 Elsevier B.V. All rights reserved.	King Fahd Univ Petr & Minerals, Dept Phys, Dhahran 31261, Saudi Arabia	Abdel-Aal, RE (reprint author), King Fahd Univ Petr & Minerals, Dept Phys, POB 1759, Dhahran 31261, Saudi Arabia.	radwan@kfupm.edu.sa					Abdel-Aal RE, 2004, IEEE T POWER SYST, V19, P164, DOI 10.1109/TPWRS.2003.820695; ABDULLAH MHL, 2000, P TENCON 2000 KUAL L, P157; ABOULMAGD MA, 2001, P LARG ENG SYST C PO, P105; AbTech Corporation, 1990, AIM US MAN; ANTONIOU CA, 2000, P 4 INT C KNOWL BAS, P205; Asar A.-U., 1994, IEEE Transactions on Control Systems Technology, V2, DOI 10.1109/87.294341; Barron A., 1984, SELF ORG METHODS MOD, P87; Borra S, 2002, COMPUT STAT DATA AN, V38, P407, DOI 10.1016/S0167-9473(01)00068-8; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; da Silva APA, 2001, IEEE POW TECH C PORT; Drezga I, 1999, IEEE T POWER SYST, V14, P844, DOI 10.1109/59.780894; Drucker H, 1996, ADV NEUR IN, V8, P479; EDELMAN D, 1999, 3 INT C KNOWL BAS IN, P166; Farlow SJ, 1984, SELF ORG METHODS MOD, P1; Goh WY, 2003, IEEE T NEURAL NETWOR, V14, P459, DOI 10.1109/TNN.2003.809420; GROSS G, 1987, P IEEE, V75, P1558, DOI 10.1109/PROC.1987.13927; GUO JJ, 2002, IEEE POW ENG SOC WIN, P77; HSU YY, 1991, IEE PROC-C, V138, P414; JIMENEZ D, 1998, IEEE WORLD C COMPUTA, V1, P753; KHOTANZAD A, 1995, IEEE T POWER SYST, V10, P1716, DOI 10.1109/59.466468; KIM SJ, 1999, IEEE INT JOINT C NEU, P4043; Krogh A., 1995, ADV NEURAL INFORMATI, V8, P231; MATSUMOTO T, 1993, P ANNPS 93, P245; Mendenhall W., 1994, INTRO PROBABILITY ST; Montgomery GJ, 1990, P SPIE C APPL ART NE, P56; MORIOKA Y, 1993, P 2 INT FOR APPL NEU, P60; ONODA T, 1993, P 2 INT FOR APPL NEU, P284; PARK DC, 1991, IEEE T POWER SYST, V6, P442, DOI 10.1109/59.76685; PARMPERO PS, 1998, P 1998 IEEE INT JOIN, P1723; Podolak IT, 2000, INT C PATT RECOG, P957; Prampero PS, 1999, IEE CONF PUBL, P67, DOI 10.1049/cp:19990283; Radevski V, 2000, IEEE IJCNN, P561; Shimshoni Y, 1998, IEEE T SIGNAL PROCES, V46, P1194, DOI 10.1109/78.668782; Su M, 2001, IEEE IJCNN, P2159; Swann A, 1998, ELECTRON LETT, V34, P1408, DOI 10.1049/el:19981000; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; YAO X, 2001, P INT JOINT C NEUR N, P693; Yao X., 2001, IJCNN'01. International Joint Conference on Neural Networks. Proceedings (Cat. No.01CH37222), DOI 10.1109/IJCNN.2001.939108; Zhou ZH, 2002, ARTIF INTELL MED, V24, P25, DOI 10.1016/S0933-3657(01)00094-X	39	8	9	ELSEVIER SCIENCE SA	LAUSANNE	PO BOX 564, 1001 LAUSANNE, SWITZERLAND	0378-7796		ELECTR POW SYST RES	Electr. Power Syst. Res.	APR	2005	74	1					83	94		10.1016/j.epsr.2004.09.007		12	Engineering, Electrical & Electronic	Engineering	904SQ	WOS:000227518400009	
J	Shieh, JS; Linkens, DA; Asbury, AJ				Shieh, JS; Linkens, DA; Asbury, AJ			A hierarchical system of on-line advisory for monitoring and controlling the depth of anaesthesia using self-organizing fuzzy	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE			English	Article						hierarchical architecture; depth of anaesthesia; machine-learning; self-organizing learning system; self-organizing fuzzy logic	BISPECTRAL INDEX; CLINICAL SIGNS; PROPOFOL; ISOFLURANE; ALFENTANIL; SURGERY; LOGIC	A hierarchical system has been developed to on-line advise on the concentration of inhaled volatile anaesthetics for controlling depth of anaesthesia. It merges on-line measurements (such as systolic arterial pressure and heart rate) and clinical information (such as sweating, lacrimation and movement) using a hierarchical architecture and self-organizing fuzzy logic for reasoning. It has been developed to predict depth of anaesthesia from either a "hand-crafted" anaesthetists' or machine-learning rule-base using self-organizing learning system and control the drug levels using self-organizing fuzzy logic algorithm. In this paper, machine-learning rule-base has been validated via tests with 10 patients off-line and 17 patients on-line. The drug controller rule-base has also been validated via pre-tuning on 10 off-line patients and testing on 17 on-line patients. After extensive validation of this system, this online approach has shown promise and very successful for reducing the recovery time in comparison with either 10 patients off-line or other research. (c) 2004 Elsevier Ltd. All rights reserved.	Yuan Ze Univ, Dept Engn Mech, Taoyuan 320, Taiwan; Univ Sheffield, Dept Automat Control & Syst Engn, Sheffield S1 3JD, S Yorkshire, England; Univ Glasgow, Western Infirm, Dept Anaesthesia, Glasgow G11 6NT, Lanark, Scotland	Shieh, JS (reprint author), Yuan Ze Univ, Dept Engn Mech, 135 Yuan Tung Rd, Taoyuan 320, Taiwan.	jsshieh@saturn.yzu.edu.tw					Bruhn J, 2003, ANESTHESIOLOGY, V98, P621, DOI 10.1097/00000542-200303000-00008; DIEM K, 1965, DOCUMENTA GEIGY, P634; EVANS JM, 1987, BRIT J ANAESTH, V59, P1346, DOI 10.1093/bja/59.11.1346; Glass PS, 1997, ANESTHESIOLOGY, V86, P836, DOI 10.1097/00000542-199704000-00014; Jensen EW, 1999, BRIT J ANAESTH, V82, P25; JENSTRUP M, 1990, BRIT J ANAESTH, V64, P717, DOI 10.1093/bja/64.6.717; Linkens DA, 1996, FUZZY SET SYST, V79, P43, DOI 10.1016/0165-0114(95)00290-1; LINKENS DA, 1986, BIOMED MEAS INFOR CO, V1, P223; PROCYK TJ, 1979, AUTOMATICA, V15, P15, DOI 10.1016/0005-1098(79)90084-0; Mason DG, 1997, MED BIOL ENG COMPUT, V35, P498, DOI 10.1007/BF02525530; RAJU GVS, 1991, INT J CONTROL, V54, P1201, DOI 10.1080/00207179108934205; ROBB HM, 1993, BRIT J ANAESTH, V71, P366, DOI 10.1093/bja/71.3.366; SCHEEPSTRA GL, 1989, BRIT J ANAESTH, V62, P54, DOI 10.1093/bja/62.1.54; Sebel PS, 1997, ANESTH ANALG, V84, P891, DOI 10.1097/00000539-199704000-00035; SHEIH JS, 2000, J CLIN MONITOR COMP, V16, P583; Shieh JS, 1999, IEE P-CONTR THEOR AP, V146, P265, DOI 10.1049/ip-cta:19990125; SHIEH JS, 1998, BIOMED ENG APPL BASI, V10, P195; Shieh JS, 1999, IEEE T SYST MAN CY C, V29, P98; Struys MMRF, 2001, ANESTHESIOLOGY, V95, P6, DOI 10.1097/00000542-200107000-00007; THORNTON C, 1988, BRIT J ANAESTH, V60, P372, DOI 10.1093/bja/60.4.372	20	16	16	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0952-1976		ENG APPL ARTIF INTEL	Eng. Appl. Artif. Intell.	APR	2005	18	3					307	316		10.1016/j.engappai.2004.09.009		10	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	914YP	WOS:000228264400005	
J	Stephen, B; Petropoulakis, L				Stephen, B; Petropoulakis, L			An ambient software monitoring system for unsupervised user modelling	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						finite state machines; pattern discovery; behaviour modelling; gesture recognition; human computer interaction; user interface	SEARCH	This paper describes a means of unsupervised learning of recurring patterns in user activity through patterns in system level events generated by a graphical user interface. Earlier work has shown that using this distillation of the more complex behavioural interaction between the user and the application provides a symbolic representation of knowledge and goals that could be used to imply preference. Although prior research has explored the possibilities of removing this information acquisition bottleneck in such an expert system using ambient monitoring approaches, some have experienced difficulty in dealing with the varying length training sequences and segmentation of the continuous event stream. Unlike previous work the approach documented here handles interactions of varying sizes and is able to recall recurrent patterns in real time irrespective of the number of interactions learned. In addition to describing the proposed approach we also describe the shortcomings of various previously applied machine learning techniques on the same type of data. We also demonstrate a practical implementation of our approach applied to web browser usage. (c) 2005 Elsevier Ltd. All rights reserved.	Univ Strathclyde, Dept Elect & Elect Engn, Glasgow G1 1QE, Lanark, Scotland	Stephen, B (reprint author), Univ Strathclyde, Dept Elect & Elect Engn, Graham Hills Bldg,50 George St, Glasgow G1 1QE, Lanark, Scotland.	bstephen@eee.strath.ac.uk; l.petropoulakis@eee.strath.ac.uk					AHO AV, 1975, COMMUN ACM, V18, P333, DOI 10.1145/360825.360855; BOUKREEV K, 2001, MOUSE GESTURES RECOG; Breese J. S., 1998, P 14 C UNC ART INT; BRUBACHER D, 1999, P 3 USENIX WIND NT S, P135; Crochemore M, 1996, ACM COMPUT SURV, V28, P39, DOI 10.1145/234313.234331; CYPHER A, 1991, P CHI 91, P33, DOI 10.1145/108844.108850; DIX A, 1992, PEOPLE COMPUTERS, V7, P429; FINLAY J, 1996, P ICML 96, P17; HECKERMANN D, 1998, LUMIERE PROJECT BAYE; KOSKO B, 2000, PRESENCE; Lee WP, 2003, EXPERT SYST APPL, V24, P365, DOI 10.1016/S0957-4174(02)00186-0; Levenshtein A., 1966, SOV PHYS DOKL, V10, P707; Memon A. M, 2003, P 10 WORK C REV ENG; MILLER G, 1956, PSYCHOL REV, V23; RICHTER J, 1999, PROGRAMMING APPL MIC, P945; SCHWAB I, 2002, ADAPTIVITY UNOBTRUSI; TURK M, 2000, P 15 ICPR BARC SPAIN, V3, P691; TURK M, 2000, P 4 INT C GEST REC; YANNAKAKIS M, 1996, P IEEE 84 AUG, P1090	19	2	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	APR	2005	28	3					557	567		10.1016/j.eswa.2004.12.017		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	905CV	WOS:000227546200016	
J	Ling, CX; Noble, WS; Yang, Q				Ling, CX; Noble, WS; Yang, Q			Guest editors' introduction to the special issue: Machine learning for bioinformatics - Part 1	IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS			English	Editorial Material									Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada; Univ Washington, Dept Genome Sci, Seattle, WA 98195 USA; Hong Kong UST, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China	Ling, CX (reprint author), Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada.	cling@csd.uwo.ca; noble@gs.washington.edu; qyang@cs.ust.hk						0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1545-5963		IEEE ACM T COMPUT BI	IEEE-ACM Trans. Comput. Biol. Bioinform.	APR-JUN	2005	2	2					81	82		10.1109/TCBB.2005.25		2	Biochemical Research Methods; Computer Science, Interdisciplinary Applications; Mathematics, Interdisciplinary Applications; Statistics & Probability	Biochemistry & Molecular Biology; Computer Science; Mathematics	017OY	WOS:000235704100001	
J	Furlanello, C; Serafini, M; Merler, S; Jurman, G				Furlanello, C; Serafini, M; Merler, S; Jurman, G			Semisupervised learning for molecular profiling	IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS			English	Article						machine learning; data mining; classifier design and evaluation; feature evaluation and selection; pattern analysis; clustering; similarity measures; biology and genetics; boinformatics databases	GENE-EXPRESSION DATA; MICROARRAY DATA; CLASSIFICATION; SURVIVAL; PREDICTION; SELECTION; CANCER; BIAS	Class prediction and feature selection are two learning tasks that are strictly paired in the search of molecular profiles from microarray data. Researchers have become aware how easy it is to incur a selection bias effect, and complex validation setups are required to avoid overly optimistic estimates of the predictive accuracy of the models and incorrect gene selections. This paper describes a semisupervised pattern discovery approach that uses the by-products of complete validation studies on experimental setups for gene profiling. In particular, we introduce the study of the patterns of single sample responses (sample-tracking profiles) to the gene selection process induced by typical supervised learning tasks in microarray studies. We originate sample-tracking profiles as the aggregated off-training evaluation of SVM models of increasing gene panel sizes. Genes are ranked by E-RFE, an entropy-based variant of the recursive feature elimination for support vector machines (RFE-SVM). A Dynamic Time Warping (DTW) algorithm is then applied to define a metric between sample-tracking profiles. An unsupervised clustering based on the DTW metric allows automating the discovery of outliers and of subtypes of different molecular profiles. Applications are described on synthetic data and in two gene expression studies.	ITC Irst, I-38050 Povo, Trento, Italy	Furlanello, C (reprint author), ITC Irst, Via Sommar 18, I-38050 Povo, Trento, Italy.	furlan@itc.it; mserafini@itc.it; merler@itc.it; jurman@itc.it					Aach J, 2001, BIOINFORMATICS, V17, P495, DOI 10.1093/bioinformatics/17.6.495; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Bair E, 2004, PLOS BIOL, V2, P511, DOI 10.1371/journal.pbio.00200108; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; CHAPELLE O, 2002, THESIS; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P181; Furlanello C, 2003, NEURAL NETWORKS, V16, P641, DOI 10.1016/S0893-6080(03)00103-5; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hartemink A., 2004, KERNEL METHODS COMPU, P299; Kari L, 2003, J EXP MED, V197, P1477, DOI 10.1084/jem.20021726; Keogh E. J., 2000, KDD, P285; Merler S, 2004, INT J PATTERN RECOGN, V18, P891, DOI 10.1142/S0218001404003460; Moler EJ, 2000, PHYSIOL GENOMICS, V4, P109; Mukherjee S, 2003, PRACTICAL APPROACH M, P166, DOI 10.1007/0-306-47815-3_9; Noble W. S., 2004, KERNEL METHODS COMPU, P71; Nutt CL, 2003, CANCER RES, V63, P1602; R Development Core Team, 2004, R LANG ENV STAT COMP; Rakotomamonjy A., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753706; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; Sakoe H., 1978, IEEE T ACOUSTICS SPE, VASSP-26; SIMON R, 2004, SERIES STAT BIOL HLT; Simon R, 2003, J NATL CANCER I, V95, P14; Vapnik V. N., 2000, NATURE STAT LEARNING; *CARDIOGENOMICS, 2004, GEN CARD DEV AD REM; 2003, BMC BIOINFORMATICS, P54	26	15	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1545-5963		IEEE ACM T COMPUT BI	IEEE-ACM Trans. Comput. Biol. Bioinform.	APR-JUN	2005	2	2					110	118		10.1109/TCBB.2005.28		9	Biochemical Research Methods; Computer Science, Interdisciplinary Applications; Mathematics, Interdisciplinary Applications; Statistics & Probability	Biochemistry & Molecular Biology; Computer Science; Mathematics	017OY	WOS:000235704100004	
J	Mamitsuka, H				Mamitsuka, H			Essential latent knowledge for protein-protein interactions: Analysis by an unsupervised learning approach	IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS			English	Article						biology and genetics; machine learning; data mining; mining methods and algorithms	SACCHAROMYCES-CEREVISIAE; YEAST PROTEOME; COMPLEXES; NETWORKS	Protein-protein interactions play a number of central roles in many cellular functions, including DNA replication, transcription and translation, signal transduction, and metabolic pathways. A recent increase in the number of protein-protein interactions has made predicting unknown protein-protein interactions important for the understanding of living cells. However, the protein-protein interactions experimentally obtained so far are often incomplete and contradictory and, consequently, existing computational prediction methods have integrated evidence (latent knowledge of proteins) from different and more reliable sources. Analyzing the relationships between proteins and the latent knowledge is important to understanding the cellular processes. For this analysis, we propose a new probabilistic model for protein-protein interactions by considering the latent knowledge of proteins. We further present an efficient learning algorithm for this model, based on an EM algorithm. Experimental results have shown that in a supervised test setting, the proposed method outperformed five other competing methods by a statistically significant factor in all cases. Using the probability parameters of a trained model, we have further shown the latent knowledge that is essential to predicting protein-protein interactions. Overall, our experimental results confirm that our proposed model is especially effective for analyzing protein-protein interactions from a viewpoint of the latent knowledge of proteins.	Kyoto Univ, Inst Chem Res, Uji 6110011, Japan	Mamitsuka, H (reprint author), Kyoto Univ, Inst Chem Res, Uji 6110011, Japan.	mami@kuicr.kyoto-u.ac.jp					Bader GD, 2002, NAT BIOTECHNOL, V20, P991, DOI 10.1038/nbt1002-991; Bader JS, 2004, NAT BIOTECHNOL, V22, P78, DOI 10.1038/nbt924; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Bishop CM, 1998, IEEE T PATTERN ANAL, V20, P281, DOI 10.1109/34.667885; Bock JR, 2001, BIOINFORMATICS, V17, P455, DOI 10.1093/bioinformatics/17.5.455; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Deng MH, 2002, GENOME RES, V12, P1540, DOI 10.1101/gr.153002; Gavin AC, 2002, NATURE, V415, P141, DOI 10.1038/415141a; Gomez SM, 2003, BIOINFORMATICS, V19, P1875, DOI 10.1093/bioinformatics/btg352; Grigoriev A, 2003, NUCLEIC ACIDS RES, V31, P4157, DOI 10.1093/nar/gkg466; Ho Y, 2002, NATURE, V415, P180, DOI 10.1038/415180a; HOFMANN T, 1998, P C AUT LEARN DISC C; Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950; Ito T, 2000, P NATL ACAD SCI USA, V97, P1143, DOI 10.1073/pnas.97.3.1143; Ito T, 2001, P NATL ACAD SCI USA, V98, P4569, DOI 10.1073/pnas.061034498; Jansen R, 2003, SCIENCE, V302, P449, DOI 10.1126/science.1087361; MAMITSUKA H, 2003, P INT C MACH LEARN, P504; Mewes HW, 2004, NUCLEIC ACIDS RES, V32, pD41, DOI 10.1093/nar/gkh092; Mrowka R, 2001, GENOME RES, V11, P1971, DOI 10.1101/gr.206701; Mulder NJ, 2003, NUCLEIC ACIDS RES, V31, P315, DOI 10.1093/nar/gkg046; Pereira F., 1993, P 31 ANN M ASS COMP, P183, DOI 10.3115/981574.981598; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Sprinzak E, 2001, J MOL BIOL, V311, P681, DOI 10.1006/jmbi.2001.4920; Sprinzak E, 2003, J MOL BIOL, V327, P919, DOI 10.1016/S0022-2836(03)00239-0; Uetz P, 2000, NATURE, V403, P623; UETZ P, 2004, ENCY REFERENCE GENOM; Vapnik V. N, 1995, NATURE STAT LEARNING; von Mering C, 2002, NATURE, V417, P399	28	7	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1545-5963		IEEE ACM T COMPUT BI	IEEE-ACM Trans. Comput. Biol. Bioinform.	APR-JUN	2005	2	2					119	130		10.1109/TCBB.2005.23		12	Biochemical Research Methods; Computer Science, Interdisciplinary Applications; Mathematics, Interdisciplinary Applications; Statistics & Probability	Biochemistry & Molecular Biology; Computer Science; Mathematics	017OY	WOS:000235704100005	
J	Shen, L; Tan, EC				Shen, L; Tan, EC			Dimension reduction-based penalized logistic regression for cancer classification using microarray data	IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS			English	Article						dimension reduction; penalized logistic regression; singular value decomposition; partial least squares; cancer classification; classifier design and evaluation; feature evaluation and selection; microarray data	DISCRIMINANT-ANALYSIS; DNA MICROARRAYS; EXPRESSION DATA; GENE; DISCOVERY	The use of penalized logistic regression for cancer classification using microarray expression data is presented. Two dimension reduction methods are respectively combined with the penalized logistic regression so that both the classification accuracy and computational speed are enhanced. Two other machine-learning methods, support vector machines and least-squares regression, have been chosen for comparison. It is shown that our methods have achieved at least equal or better results. They also have the advantage that the output probability can be explicitly given and the regression coefficients are easier to interpret. Several other aspects, such as the selection of penalty parameters and components, pertinent to the application of our methods for cancer classification are also discussed.	Nanyang Technol Univ, BioInformat Res Ctr, Singapore 637553, Singapore; Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore	Shen, L (reprint author), Nanyang Technol Univ, BioInformat Res Ctr, Res TechnolPlaza,3rd Story,XFrontiers Block,50 Na, Singapore 637553, Singapore.	shenli@pmail.ntu.edu.sg; asectan@ntu.edu.sg					Brown PO, 1999, NAT GENET, V21, P33, DOI 10.1038/4462; Debouck C, 1999, NAT GENET, V21, P48, DOI 10.1038/4475; Dettling M, 2004, J MULTIVARIATE ANAL, V90, P106, DOI 10.1016/j.jmva.2004.02.012; Duggan DJ, 1999, NAT GENET, V21, P10, DOI 10.1038/4434; EFRON B, 1975, J AM STAT ASSOC, V70, P892, DOI 10.2307/2285453; Eilers P. H. C., 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4266, DOI 10.1117/12.427987; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Golub G. H., 1996, MATRIX COMPUTATIONS; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; GUNN S, 2001, SVM MATLAB TOOLBOX; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hastie T, 2001, ELEMENTS STAT LEARNI; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.2307/1267351; LECESSIE S, 1992, APPL STAT-J ROY ST C, V41, P191; LI J, 2002, KENT RIDGE BIOMEDICA; Nguyen DV, 2002, BIOINFORMATICS, V18, P39, DOI 10.1093/bioinformatics/18.1.39; Peterson MA, 2003, J HEALTH POLIT POLIC, V28, P1, DOI 10.1215/03616878-28-1-1; PRESS SJ, 1978, J AM STAT ASSOC, V73, P699, DOI 10.2307/2286261; Rosipal R, 2001, J MACHINE LEARNING R, V2, P97; SCHIMEK MG, 2003, P ART SEM C; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SCHWAIGHHOFER A, 2001, SVM MATLAB TOOLBOX; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Tan A.C., 2003, APPL BIOINFORMATIC S, V2, P75; WEGELIN J, 2000, SURVEY PARTIAL LEAST; Zhu J, 2004, BIOSTATISTICS, V5, P427, DOI 10.1093/biostatistics/kxg046	26	22	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1545-5963		IEEE ACM T COMPUT BI	IEEE-ACM Trans. Comput. Biol. Bioinform.	APR-JUN	2005	2	2					166	175				10	Biochemical Research Methods; Computer Science, Interdisciplinary Applications; Mathematics, Interdisciplinary Applications; Statistics & Probability	Biochemistry & Molecular Biology; Computer Science; Mathematics	017OY	WOS:000235704100009	
J	Abdel-Galil, TK; Sharkawy, RM; Salama, MMA; Bartnikas, R				Abdel-Galil, TK; Sharkawy, RM; Salama, MMA; Bartnikas, R			Partial discharge pulse pattern recognition using an inductive inference algorithm	IEEE TRANSACTIONS ON DIELECTRICS AND ELECTRICAL INSULATION			English	Article; Proceedings Paper	Volta Colloquium on Partial Discharge Measurements	OCT, 2001	Como, ITALY	Politechn Milano, AEI, Milan Sect, Centro Alessandro Volta		cables; feature extraction; partial discharges; pattern classification	MULTILAYER PERCEPTRON TECHNIQUE; NEURAL-NETWORK; MUTUAL INFORMATION; CLASSIFICATION; DIAGNOSIS; SHAPES; SYSTEM	This paper presents a novel approach in the area of time dependent partial discharge (PD) pulse pattern recognition, to applications based on the inductive learning (decision tree) approach. Different attributes based on pulse shape analysis are used as representative feature vectors that can accurately capture the unique and salient characteristics of the PD pulse shape. In the training phase, a decision tree is developed to relate the pulse shape with the cavity size by using inductive machine learning. The C4.5 machine learning algorithm is deployed to realize the tree using the training data, since it has the capability of inferring the rules and to produce the tree in terms of continuous features. During testing, the cavity size is recognized by means of the rules extracted from the decision tree. The dependency between the features and the classes are examined using the mutual information approach. The proposed algorithm possesses the inherent advantage of explaining the result via the self-created rule base as demonstrated by the results obtained. Those self-created rules can be employed as the basis for applying a fuzzy expert system for the classification of void sizes in an easily interpreted fashion.	Dept Elect & Comp Engn, Waterloo, ON N2L 3G1, Canada	Abdel-Galil, TK (reprint author), Dept Elect & Comp Engn, 200 Univ Ave W, Waterloo, ON N2L 3G1, Canada.						Bartnikas R., 1979, ENG DIELECTRICS, V1; BARTNIKAS R, 1975, IEEE T POWER AP SYST, VPA94, P716, DOI 10.1109/T-PAS.1975.31899; Bartnikas R, 2002, IEEE T DIELECT EL IN, V9, P763, DOI 10.1109/TDEI.2002.1038663; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Candela R, 2000, IEEE T DIELECT EL IN, V7, P87, DOI 10.1109/94.839345; Duda R. O., 2001, PATTERN CLASSIFICATI; El-Saadany E. F., 1998, International Journal of Power and Energy Systems, V18; Ghosh S, 1999, IEEE T DIELECT EL IN, V6, P131, DOI 10.1109/94.752021; Grall-Maes E, 2002, IEEE T SIGNAL PROCES, V50, P779, DOI 10.1109/78.992120; Hipel KW, 1994, TIME SERIES MODELLIN; KRANZ HG, 1992, IEEE T ELECTR INSUL, V27, P93, DOI 10.1109/14.123444; KRANZ HG, 1993, IEEE T ELECTR INSUL, V28, P1016, DOI 10.1109/14.249375; KRIVDA A, 1995, IEEE T DIELECT EL IN, V2, P796, DOI 10.1109/94.469976; GULSKI E, 1993, IEEE T ELECTR INSUL, V28, P984, DOI 10.1109/14.249372; MAZROUA AA, 1993, IEEE T ELECTR INSUL, V28, P1082, DOI 10.1109/14.249382; MAZROUA AA, 1995, IEEE T POWER DELIVER, V10, P92, DOI 10.1109/61.368411; MAZROUA AA, 1994, IEEE T DIELECT EL IN, V1, P1119, DOI 10.1109/94.368651; Quinlan J., 1992, C4 5 PROGRAMS MACHIN; Salama MMA, 2002, IEEE T NEURAL NETWOR, V13, P446, DOI 10.1109/72.991430; Salama MMA, 2000, IEEE T DIELECT EL IN, V7, P118, DOI 10.1109/94.839349; SCHNETTLER A, 1993, ARCH ELEKTROTECH, V76, P149, DOI 10.1007/BF01597593; *ASTM, 2001, ANN BOOK ASTM STAND, V10, P1	22	6	10	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1070-9878		IEEE T DIELECT EL IN	IEEE Trns. Dielectr. Electr. Insul.	APR	2005	12	2					320	327		10.1109/TDEI.2005.1430400		8	Engineering, Electrical & Electronic; Physics, Applied	Engineering; Physics	920EW	WOS:000228673200012	
J	Song, XM; Fan, GL; Rao, M				Song, XM; Fan, GL; Rao, M			Automatic CRP mapping using nonparametric machine learning approaches	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article						conservation reserve program; decision tree; multisource data classification; support vector machine (SVM)	SUPPORT VECTOR MACHINES; REMOTELY-SENSED DATA; DECISION TREE CLASSIFICATION; LAND-COVER; MULTISOURCE CLASSIFICATION; SENSING DATA; CLASSIFIERS	This paper studies an uneven two-class unsupervised classification problem of satellite imagery, i.e., the mapping of U.S. Department of Agriculture's (USDA) Conservation Reserve Program (CRP) tracts. CRP is a nationwide program that encourages farmers to plant long-term, resource conserving covers to improve soil, water, and wildlife resources. With recent payments of nearly US $1.6 billion for new enrollments (2002 signup), it is imperative to obtain accurate digital CRP maps for management and evaluation purposes. CRP mapping is a complex classification problem where both CRP and non-CRP areas are composed of various cover types. Two nonparametric machine learning approaches, i.e., decision tree classifier (DTC) and support vector machine (SVMs) are implemented in this work. Specifically, considering the importance of CRP classification sensitivity, a new DTC pruning method is proposed to increase recall. We also study two SVM relaxation approaches to increase recall. Moreover, a localized and parallel framework is suggested in order to efficiently deal with the large-scale CRP mapping need. Simulation results validate the applicability of the suggested framework and proposed techniques.	Oklahoma State Univ, Sch Elect & Comp Engn, Stillwater, OK 74078 USA; Oklahoma State Univ, Dept Geog, Stillwater, OK 74078 USA	Song, XM (reprint author), Oklahoma State Univ, Sch Elect & Comp Engn, Stillwater, OK 74078 USA.	xiaos@okstate.edu; glfan@okstate.edu; mahesh@okstate.edu	Fan, Guoliang/G-2893-2011				ALVAREZ SA, 2002, BCCS0201 BOST COLL C; BELWARD AS, 1987, INT J REMOTE SENS, V8, P229; BENEDIKTSSON JA, 1993, INT J REMOTE SENS, V14, P2883; BOTTOU L, 1994, INT C PATT RECOG, P77, DOI 10.1109/ICPR.1994.576879; Briem GJ, 2002, IEEE T GEOSCI REMOTE, V40, P2291, DOI 10.1109/TGRS.2002.802476; BROSER BE, 1992, 5 ANN ACM WORKSH COM; Brown M, 2000, IEEE T GEOSCI REMOTE, V38, P2346, DOI 10.1109/36.868891; Bruzzone L, 1997, PHOTOGRAMM ENG REM S, V63, P523; BURGES CJC, 1998, KNOWL DISCOV DATA MI, V2; CANCEDDA N, 2003, P 11 TEXT RETR C; CHAVEZ PJ, 1996, PHOTOGRAMM ENG REMOT, P1025; Cherkassky V., 1998, LEARNING DATA CONCEP; Chuvieco E, 2002, INT J REMOTE SENS, V23, P2145, DOI 10.1080/01431160110069818; Cortes C., 1995, MACH LEARN, P1; De Fries RS, 1998, INT J REMOTE SENS, V19, P3141, DOI 10.1080/014311698214235; Dundar MM, 2002, IEEE T GEOSCI REMOTE, V40, P2692, DOI 10.1109/TGRS.2002.807010; Egbert S. L., 1998, GEOCARTO INT, V13, P17, DOI 10.1080/10106049809354660; Esposito F, 1997, IEEE T PATTERN ANAL, V19, P476, DOI 10.1109/34.589207; Foody GM, 2004, IEEE T GEOSCI REMOTE, V42, P1335, DOI 10.1109/TGRS.2004.827257; Friedl MA, 1997, REMOTE SENS ENVIRON, V61, P399, DOI 10.1016/S0034-4257(97)00049-7; Fukunaga K., 1990, INTRO STAT PATTERN R; GUALTIERI JA, 1999, JPL PUB; GUALTIERI JA, 1998, 27 SPIE AIPR WORKSH; GUALTIERI JA, 2000, P GEOSCI REM SENS S, V2, P813; Hansen M, 1996, INT J REMOTE SENS, V17, P1075; Hermes L., 1999, P IEEE INT GEOSC REM, P348; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Huang C, 2002, INT J REMOTE SENS, V23, P725, DOI 10.1080/01431160110040323; Huang XQ, 1997, PHOTOGRAMM ENG REM S, V63, P1185; HULL DA, 2000, 8 TEXT RETR C; HUTCHINSON CF, 1982, PHOTOGRAMM ENG REM S, V48, P123; Joachims T., 1999, ADV KERNEL METHODS S; JOACHIMS T, 2000, INT C MACH LEARN; Keuchel J, 2003, REMOTE SENS ENVIRON, V86, P530, DOI 10.1016/S0034-4257(03)00130-5; KUO B, 2004, IEEE T GEOSCI REMOTE, V43, P1096; LEE T, 1987, IEEE T GEOSCI REMOTE, V25, P283, DOI 10.1109/TGRS.1987.289800; LENNON M, 2002, P IEEE INT GEOSC REM, V3, P1670; LEWIS DD, 2002, P 10 RETR C, P286; Lillesand T.M., 2000, REMOTE SENSING IMAGE; LUNTS AL, 1967, ENG CYBERN, P98; MELGANI F, 2002, P IGARSS JUN, V1, P506; MORIK K, 1999, 16 INT C MACH LEARN; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Scholkopf B., 1999, ADV KERNEL METHODS S; SHANAHAN JG, 2003, CIKM 2003; Simard M, 2000, IEEE T GEOSCI REMOTE, V38, P2310, DOI 10.1109/36.868888; SOLBERG AHS, 1994, IEEE T GEOSCI REMOTE, V32, P768, DOI 10.1109/36.298006; SONG X, 2003, P IEEE WORKSH ADV TE; Tax D., 2001, THESIS TU DELFT; Vapnik VN, 1998, STAT LEARNING THEORY; ZHAI C, 1999, 7 TEXT RETR C, P149	53	15	16	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0196-2892		IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	APR	2005	43	4					888	897		10.1109/TGRS.2005.844031		10	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing	Geochemistry & Geophysics; Engineering; Remote Sensing	909TB	WOS:000227882500022	
J	Bernstein, A; Provost, F; Hill, S				Bernstein, A; Provost, F; Hill, S			Toward intelligent assistance for a data mining process: An ontology-based approach for cost-sensitive classification	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						cost-sensitive learning; data mining; data mining process; intelligent assistants; knowledge discovery; knowledge; discovery process; machine learning; metalearning	BIAS SELECTION; SUPPORT; ALGORITHMS; KNOWLEDGE	A data mining (DM) process involves multiple stages. A simple, but typical, process might include preprocessing data, applying a data mining algorithm, and postprocessing the mining results. There are many possible choices for each stage, and only some combinations are valid. Because of the large space and nontrivial interactions, both novices and data mining specialists need assistance in composing and selecting DM processes. Extending notions developed for statistical expert systems we present a prototype Intelligent Discovery Assistant (IDA), which provides users with 1) systematic enumerations of valid DM processes, in order that important, potentially fruitful options are not overlooked, and 2) effective rankings of these valid processes by different criteria, to facilitate the choice of DM processes to execute. We use the prototype to show that an IDA can indeed provide useful enumerations and effective rankings in the context of simple classification processes. We discuss how an IDA could be an important tool for knowledge sharing among a team of data miners. Finally, we illustrate the claims with a demonstration of cost-sensitive classification using a more complicated process and data from the 1998 KDDCUP competition.	Univ Zurich, Dept Informat, CH-8057 Zurich, Switzerland; NYU, Stern Sch Business, New York, NY 10012 USA	Bernstein, A (reprint author), Univ Zurich, Dept Informat, Winterthurerstr 190, CH-8057 Zurich, Switzerland.	bernstein@ifi.unizh.ch; fprovost@stern.nyu.edu; shill@stern.nyu.edu					Ackerman MS, 1999, J ORG COMP ELECT COM, V9, P105, DOI 10.1207/s15327744joce0902&3_2; AGRAWAL N, 1998, URBAN SCI WINS KDD 9; ANKOLEKAR A, 2001, P SEM WEB WORK S; Blake C, 2000, UCI REPOSITORY MACHI; Gama J., 1995, Progress in Artificial Intelligence. 7th Portuguese Conference on Artificial Intelligence, EPIA '95. Proceedings; BRAZDIL P, 2000, P 11 EUR C MACH LEAR, P63; Brazdil P., 1994, P EUR C MACH LEARN E, P83; BRAZDIL PB, 1998, P 10 EUR C MACH LEAR, P11; BRODLEY CE, 1995, MACH LEARN, V20, P63, DOI 10.1007/BF00993475; BUCHANAN B, 1975, ENCY COMPUTER SCI TE, P24; BUNTINE WL, 1999, P 5 INT C KNOWL DISC, P372, DOI 10.1145/312129.312286; CHANDRASEKARAN B, 1992, COMMUN ACM, V35, P124, DOI 10.1145/130994.131002; CHAPMAN P, 2000, CRISP DM 1 0 STEP BY; CHRISTENSEN E, 2001, WORLD WIDE WEB CONSO; CRAW S, 1992, RES DEV EXPERT SYSTE, V9, P5; DAVIS R, 1984, ADDISON WESLEY SERIE, P171; Engels R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; ENGELS R, 1996, P 2 INT C KNOWL DISC, P170; Fayyad U, 1996, COMMUN ACM, V39, P27, DOI 10.1145/240455.240464; Furnkranz Johannes, 2001, P ECML WKSHOP INT AS, P57; GALE WA, 2006, ARTIFICIAL INTELLIGE; GHALLAB M, 1998, TR98003DCSTR1165 CT; GORDON DF, 1995, MACH LEARN, V20, P5, DOI 10.1023/A:1022630017346; HAND D, 1994, CHANCE, V7, P28; HILARIO M, 2001, UNIGEAI0101 U GEN; Hoeting JA, 1999, STAT SCI, V14, P382; Kerber R., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Kohavi R., 1996, P 2 INT C KNOWL DISC, P114; Kohavi R., 2000, SIGKDD EXPLORATIONS, V2, P86; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; LENAT D, 1982, MCGRAW HILL ADV CO D, P3; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; LIVINGSTON G, 2003, J KNOWLEDGE INFORMAT, V5, P133; LUBINSKY D, 1988, J ECONOMETRICS, V38, P247, DOI 10.1016/0304-4076(88)90035-8; MORIK K, 2000, P 11 EUR C MACH LEAR, P4; Morik K., 2003, INTELLIGENT TECHNOLO, P47; Nishisato S., 1994, ELEMENTS DUAL SCALIN; Oates T., 1997, P 14 INT C MACH LEAR, P254; OLDFORD R, 1985, ARTIF INTELL, P335; OLDFORD R, 1997, P 29 S INT; PENTLAND BT, 1992, ADMIN SCI QUART, V37, P527, DOI 10.2307/2393471; Perlich C, 2004, J MACH LEARN RES, V4, P211, DOI 10.1162/153244304322972694; PETRAK J, 2000, TR200007 AUSTR RES I; Pfahringer B., 2000, P 17 INT C MACH LEAR, P743; Provost F, 1999, DATA MIN KNOWL DISC, V3, P131, DOI 10.1023/A:1009876119989; Provost F., 1999, P 5 ACM SIGKDD INT C, P23, DOI 10.1145/312129.312188; PROVOST FJ, 1995, MACH LEARN, V20, P35, DOI 10.1007/BF00993474; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; SCHOLZ M, 2002, TR1205; Senator T. E., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347102; SOARES C, 2001, 7 JORN CLASS AN DAD, P72; St Amant R, 1998, J COMPUT GRAPH STAT, V7, P545; Suyama A., 1998, P 1998 AAAI WORKSH M, P29; Taylor C., 1994, MACHINE LEARNING NEU; Tcheng D., 1989, P 11 INT JOINT C ART, P806; TURNEY P, 2001, COST SENSITIVE LEARN; Ulrich K., 2004, PRODUCT DESIGN DEV; VERDENIUS F, 1997, P 7 BELG DUTCH C MAC, P119; WIRTH R, 1997, P 1 EUR S PRINC DAT, P55; Witten I. H., 1999, DATA MINING PRACTICA; Zadrozny B., 2001, P 7 ACM SIGKDD INT C, P204, DOI 10.1145/502512.502540	61	41	43	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	APR	2005	17	4					503	518		10.1109/TKDE.2005.67		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	897IB	WOS:000226996100005	
J	Haasdonk, B				Haasdonk, B			Feature space interpretation of SVMs with indefinite kernels	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						support vector machine; indefinite kernel; pseudo-Euclidean space; separation of convex hulls; pattern recognition	CLASSIFICATION	Kernel methods are becoming increasingly popular for various kinds of machine learning tasks, the most famous being the support vector machine (SVM) for classification. The SVM is well understood when using conditionally positive definite (cpd) kernel functions. However, in practice, non-cpd kernels arise and demand application in SVMs. The procedure of "plugging" these indefinite kernels in SVMs often yields good empirical classification results. However, they are hard to interpret due to missing geometrical and theoretical understanding. In this paper, we provide a step toward the comprehension of SVM classifiers in these situations. We give a geometric interpretation of SVMs with indefinite kernel functions. We show that such SVMs are optimal hyperplane classifiers not by margin maximization, but by minimization of distances between convex hulls in pseudo-Euclidean spaces. By this, we obtain a sound framework and motivation for indefinite SVMs. This interpretation is the basis for further theoretical analysis, e. g., investigating uniqueness, and for the derivation of practical guidelines like characterizing the suitability of indefinite SVMs.	Univ Freiburg, Dept Comp Sci, D-79110 Freiburg, Germany	Haasdonk, B (reprint author), Univ Freiburg, Dept Comp Sci, D-79110 Freiburg, Germany.	haasdonk@informatik.uni-freiburg.de					Bahlmann C., 2002, Proceedings Eighth International Workshop on Frontiers in Handwriting Recognition, DOI 10.1109/IWFHR.2002.1030883; Bennett KP, 2000, P 17 INT C MACH LEAR, P57; CHANG C. C., LIBSVM LIB SUPPORT V; Chang CC, 2001, NEURAL COMPUT, V13, P2119, DOI 10.1162/089976601750399335; CHAPELLE O, 2000, P ADV NEUR INF PROC, P230; CORTES C, 2003, P ADV NEUR INF PROC, V15; CRISP DJ, 2000, P ADV NEUR INF PROC, V12, P223; Cristianini N., 2000, INTRO SUPPORT VECTOR; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; Goldfarb L., 1985, PROGR PATTERN RECOGN, V2, P241; Graepel T, 1999, ADV NEUR IN, V11, P438; GRAEPEL T, 1999, P 9 INT C ART NEUR N, P304; Haasdonk B, 2004, LECT NOTES COMPUT SC, V3175, P220; Haasdonk B., 2002, Proceedings 16th International Conference on Pattern Recognition, DOI 10.1109/ICPR.2002.1048439; HAUSSLER D, 1999, UCSCRL9910; Hein M., 2003, P 16 ANN C COMP LEAR, P72; Lin H.-T., 2003, STUDY SIGMOID KERNEL; Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687; MARY X, 2003, THESIS INSA ROUEN; MORENO PJ, 2004, P ADV NEUR INF PROC, V16, P1385; Pardalos P. M., 1987, CONSTRAINED GLOBAL O; Pekalksa E., 2001, J MACHINE LEARNING R, V2, P175; RONNEBERGER O, 2004, LIBSVMTL SUPPORT VEC; Scholkopf B., 2000, NEURAL COMPUT, V12, P1083; Scholkopf B., 2002, LEARNING KERNELS; SCHOLKOPF B, 2000, 200051 MSR; SELLATHURAI M, 1999, P IEEE INT C AC SPEE, P1021; Shimodaira H, 2002, ADV NEUR IN, V14, P921; Vapnik V. N, 1995, NATURE STAT LEARNING	29	65	67	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2005	27	4					482	492		10.1109/TPAMI.2005.78		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	895FG	WOS:000226845700001	
J	Dong, JX; Krzyzak, A; Suen, CY				Dong, JX; Krzyzak, A; Suen, CY			Fast SVM training algorithm with decomposition on very large data sets	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						support vector machines (SVMs); algorithm design and analysis; algorithm efficiency; machine learning; handwritten character recognition	SUPPORT VECTOR MACHINES; SMO ALGORITHM; MIXTURE	Training a support vector machine on a data set of huge size with thousands of classes is a challenging problem. This paper proposes an efficient algorithm to solve this problem. The key idea is to introduce a parallel optimization step to quickly remove most of the nonsupport vectors, where block diagonal matrices are used to approximate the original kernel matrix so that the original problem can be split into hundreds of subproblems which can be solved more efficiently. In addition, some effective strategies such as kernel caching and efficient computation of kernel matrix are integrated to speed up the training process. Our analysis of the proposed algorithm shows that its time complexity grows linearly with the number of classes and size of the data set. In the experiments, many appealing properties of the proposed algorithm have been investigated and the results show that the proposed algorithm has a much better scaling capability than Libsvm, SVMlight, and SVMTorch. Moreover, the good generalization performances on several large databases have also been achieved.	Concordia Univ, Dept Comp Sci & Software Engn, Ctr Pattern Recognit & Machine Intelligence, Montreal, PQ H3G 1M8, Canada	Dong, JX (reprint author), Concordia Univ, Dept Comp Sci & Software Engn, Ctr Pattern Recognit & Machine Intelligence, 1455 Maisonneuve Blvd W,Suite GM-606, Montreal, PQ H3G 1M8, Canada.	jdong@cenparmi.concordia.ca; krzyzak@cs.concordia.ca; suen@cenparmi.concordia.ca					Ben-Hur A, 2002, J COMPLEXITY, V18, P51, DOI 10.1006/jcom.2001.0581; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blackard JA, 1999, COMPUT ELECTRON AGR, V24, P131, DOI 10.1016/S0168-1699(99)00046-0; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Breiman L, 1996, MACH LEARN, V24, P49, DOI 10.1007/BF00117832; Breiman L., 1996, 460 U CAL STAT DEP; Chang CC, 2003, LIBSVM LIB SUPPORT V; Collobert R, 2001, J MACH LEARN RES, V1, P143, DOI 10.1162/15324430152733142; Collobert R, 2002, NEURAL COMPUT, V14, P1105, DOI 10.1162/089976602753633402; Collobert R, 2003, INT J PATTERN RECOGN, V17, P349, DOI 10.1142/S0218001403002411; Cristianini N., 2000, INTRO SUPPORT VECTOR; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Dong JX, 2003, INT J PATTERN RECOGN, V17, P367, DOI 10.1142/S0218001403002423; DONG JX, 2003, P INT WORKSH ART NEU; DONGARRA JJ, 1990, ACM T MATH SOFTWARE, V16, P1, DOI 10.1145/77626.79170; Duda R. O., 2001, PATTERN CLASSIFICATI; Flake GW, 2002, MACH LEARN, V46, P271, DOI 10.1023/A:1012474916001; Fukunaga K., 1990, INTRO STAT PATTERN R; FUKUNAGA K, 1969, IEEE T COMPUT, VC 18, P220, DOI 10.1109/T-C.1969.222635; Gnedenko B. V., 1969, MATH METHODS RELIABI; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Joachims T., 1998, ADV KERNEL METHODS S, P169; Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493; Keerthi SS, 2002, MACH LEARN, V46, P351, DOI 10.1023/A:1012431217818; Kuhn H. W., 1951, P 2 BERK S MATH STAT, P481; LeCun Y. A., 1995, P INT C ART NEUR NET, P53; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; Patterson D. A., 1996, COMPUTER ARCHITECTUR; Platt J. C., 1998, ADV KERNEL METHODS S, P185; RIDA A, 1999, P 7 INT WORKSH AI ST; Scholkopf B., 2002, LEARNING KERNELS; Scholkopf B., 1995, P 1 INT C KNOWL DISC, P252; SCHWAIGHOFER A, 2001, P INT C ART NEUR NET, P411; Staddon J. E. R., 1983, ADAPTIVE BEHAV LEARN; Tresp V, 2000, NEURAL COMPUT, V12, P2719, DOI 10.1162/089976600300014908; Vapnik VN, 1998, STAT LEARNING THEORY; Verbeek JJ, 2003, NEURAL COMPUT, V15, P469, DOI 10.1162/089976603762553004; WHALEY RC, 1998, P HIGH PERF NETW COM; Whaley RC, 2000, AUTOMATED EMPIRICAL; *INT CORP, 2002, 248966 INT CORP; *INT CORP, 2002, 245470 INT CORP	42	75	87	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2005	27	4					603	618				16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	895FG	WOS:000226845700010	
J	Guan, SU; Zhu, FM				Guan, SU; Zhu, FM			An incremental approach to genetic-algorithms-based classification	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						classifier agents; genetic algorithms (GAs); incremental learning	PERFORMANCE; SYSTEMS; NETWORKS	Incremental learning has been widely addressed in the machine learning literature to cope with learning tasks where the learning environment is ever changing or training samples become available over time. However, most research work explores incremental learning with statistical algorithms or neural networks, rather than evolutionary algorithms. The work in this paper employs genetic algorithms (GAs) as basic learning algorithms for incremental learning within one or more classifier agents in a multiagent environment. Four new approaches with different initialization schemes are proposed. They keep the old solutions and use an "integration" operation to integrate them with new elements to accommodate new attributes, while biased mutation and crossover operations are adopted to further evolve a reinforced solution. The simulation results on benchmark classification data sets show that the proposed, approaches can deal with the arrival of new input attributes and integrate them with the original input space. It is also shown that the proposed approaches can be successfully used for incremental learning and improve classification rates as compared to the retraining GA. Possible applications for continuous incremental training and feature selection are also discussed.	Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119260, Singapore	Guan, SU (reprint author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119260, Singapore.	eleguans@nus.edu.sg; elezfm@nus.edu.sg					Bernado E, 2002, LECT NOTES ARTIF INT, V2321, P115; Blake C. L., 1998, UCI REPOSITORY MACHI; BRADSHAW JM, 1997, SOFTWARE AGENT; CARAGEA D, 2000, P WORKSH DISTR PAR K; CHEAH CY, 2004, THESIS NATL U SINGAP; DALCHEBUC F, 2001, P AM I PHYS C, V627, P320; De Jong K., 1988, Machine Learning, V3, DOI 10.1023/A:1022606120092; DE JONG K. A., 1991, P INT JOINT C ART IN, P651; Enee G., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), DOI 10.1109/CEC.1999.785484; ENGELBRECHT AP, 2001, P INT JOINT C NEUR N, V3, P2019; Fogel D.B., 1991, P 25 AS C SIGN SYST, P540; Fu LM, 1996, IEEE T NEURAL NETWOR, V7, P757; Giraud-Carrier C, 2000, AI COMMUN, V13, P215; Goldberg DE, 1989, GENETIC ALGORITHMS S; Guan SU, 2001, NEURAL PROCESS LETT, V14, P241, DOI 10.1023/A:1012799113953; Harik GR, 2000, COMPUT METHOD APPL M, V186, P295, DOI 10.1016/S0045-7825(99)00388-6; Holland J. H., 1986, MACHINE LEARNING ART; Holland J.H., 1975, ADAPTATION NATURE AR; Ishibuchi H, 1999, IEEE T IND ELECTRON, V46, P1057, DOI 10.1109/41.807986; Ishibuchi H, 1999, IEEE T SYST MAN CY B, V29, P601, DOI 10.1109/3477.790443; KANG H, 2000, P C EV COMP, P464; Koza J. R., 1992, GENETIC PROGRAMMING; Lanzi PL, 2000, LEARNING CLASSIFIER; MERELO J, 2001, ADV EVOLUTIONARY SYN; Michalewicz Z, 1996, GENETIC ALGORITHMS D; Osorio FS, 1999, NEUROCOMPUTING, V28, P191, DOI 10.1016/S0925-2312(98)00124-6; Pelikan M, 2000, EVOL COMPUT, V8, P311, DOI 10.1162/106365600750078808; Polikar R, 2001, IEEE T SYST MAN CY C, V31, P497, DOI 10.1109/5326.983933; PRECHELT L, 1994, 2194 U KARLSR DEP IN; Schwefel HP, 1995, LECT NOTES ARTIF INT, V929, P893; Corcoran A. L., 1994, Proceedings of the First IEEE Conference on Evolutionary Computation. IEEE World Congress on Computational Intelligence (Cat. No.94TH0650-2), DOI 10.1109/ICEC.1994.350030; Setnes M, 2000, IEEE T FUZZY SYST, V8, P509, DOI 10.1109/91.873575; Smith SF, 1980, THESIS U PITTSBURGH; Su L., 2001, Journal of Intelligent Systems, V11; Weiss S. M., 1991, COMPUTER SYSTEMS LEA; Yamauchi K, 1999, IEEE T NEURAL NETWOR, V10, P1351, DOI 10.1109/72.809080; Zhu FM, 2004, INT J INTELL SYST, V19, P1239, DOI 10.1002/int.20046	37	23	24	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	APR	2005	35	2					227	239		10.1109/TSMCB.2004.842247		13	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	907WD	WOS:000227747900005	
J	Ishibuchi, H; Yamamoto, T; Nakashima, T				Ishibuchi, H; Yamamoto, T; Nakashima, T			Hybridization of fuzzy GBML approaches for pattern classification problems	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						fuzzy rules; genetic algorithms; machine learning; pattern classification	SYSTEMS; PERFORMANCE; ATTRIBUTES	We propose a hybrid algorithm of two fuzzy genetics-based machine learning approaches (i.e., Michigan and Pittsburgh) for designing fuzzy rule-based classification systems. First, we examine the search ability of each approach to efficiently find fuzzy rule-based systems with high classification accuracy. It is clearly demonstrated that each approach has its own advantages and disadvantages. Next, we combine these two approaches into a single hybrid algorithm. Our hybrid algorithm is based on the Pittsburgh approach where a set of fuzzy rules is handled as an individual. Genetic operations for generating new fuzzy rules in the Michigan approach are utilized as a kind of heuristic mutation for partially modifying each rule set. Then, we compare bur hybrid algorithm with the Michigan and Pittsburgh approaches. Experimental results show that our hybrid algorithm has higher search ability. The necessity of a heuristic specification method of antecedent fuzzy sets is also demonstrated by computational experiments on high-dimensional problems. Finally,, we examine the generalization ability of fuzzy rule-based classification systems designed by our hybrid algorithm.	Osaka Prefecture Univ, Dept Ind Engn, Osaka 5998531, Japan	Ishibuchi, H (reprint author), Osaka Prefecture Univ, Dept Ind Engn, Osaka 5998531, Japan.	hisaoi@ie.osakafu-u.ac.jp	Ishibuchi, Hisao/B-3599-2009	Ishibuchi, Hisao/0000-0001-9186-6472			Abonyi J, 2003, INT J APPROX REASON, V32, P1, DOI 10.1016/S0888-613X(02)00076-2; BOOKER LB, 1989, ARTIF INTELL, V40, P235, DOI 10.1016/0004-3702(89)90050-7; Cordon O., 2001, GENETIC FUZZY SYSTEM; Elomaa T, 1999, MACH LEARN, V36, P201, DOI 10.1023/A:1007674919412; FELDMAN DS, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P312; Goldberg DE, 1989, GENETIC ALGORITHMS S; Guan SU, 2004, IEEE T SYST MAN CY B, V34, P381, DOI 10.1109/TSMCB.2003.817030; HOLLAND JH, 1975, ADAPTATION NATURAL A; Ishibuchi H, 1999, IEEE T IND ELECTRON, V46, P1057, DOI 10.1109/41.807986; Ishibuchi H, 2001, IEEE T FUZZY SYST, V9, P506, DOI 10.1109/91.940964; Ishibuchi H, 1999, IEEE T SYST MAN CY B, V29, P601, DOI 10.1109/3477.790443; Ishibuchi H, 2002, PROCEEDINGS OF THE 2002 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOL 1 & 2, P908; Ishihara Kazuyuki, 2001, International Journal of Clinical Oncology, V6, P109, DOI 10.1007/PL00012091; Karr C. L., 1991, P 4 INT C GEN ALG, P450; Nomura H., 1992, P INT FUZZ SYST INT, P236; PARODI A, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P223; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Smith SF, 1980, THESIS U PITTSBURGH; Thrift P., 1991, P 4 INT C GEN ALG, P509; Valenzuela-Rendon M., 1991, P 4 INT C GEN ALG, P346; van den Berg J, 2002, PROCEEDINGS OF THE 2002 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOL 1 & 2, P991	21	72	72	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	APR	2005	35	2					359	365		10.1109/TSMCB.2004.842257		7	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	907WD	WOS:000227747900016	
J	Zhao, HM; Ram, S				Zhao, HM; Ram, S			Entity identification for heterogeneous database integration - a multiple classifier system approach and empirical evaluation	INFORMATION SYSTEMS			English	Article						heterogeneous database integration; entity identification; multiple classifier system	LINKAGE	Entity identification, i.e., detecting semantically corresponding records from heterogeneous data sources, is a critical step in integrating the data sources. The objective of this research is to develop and evaluate a novel multiple classifier system approach that improves entity identification accuracy. We apply various classification techniques drawn from statistical pattern recognition, machine learning, and artificial neural networks to determine whether two records from different data sources represent the same real-world entity. We further employ a variety of ways to combine multiple classifiers for improved classification accuracy. In this paper, we report on some promising empirical results that demonstrate performance improvement by combining multiple classifiers. (C) 2003 Elsevier Ltd. All rights reserved.	Univ Wisconsin, Sch Business Adm, Milwaukee, WI 53201 USA; Univ Arizona, Dept Management Informat Syst, Tucson, AZ 85721 USA	Zhao, HM (reprint author), Univ Wisconsin, Sch Business Adm, POB 742, Milwaukee, WI 53201 USA.	hzhao@uwm.edu; ram@bpa.arizona.edu					Budzinsky C.D., 1991, AUTOMATED SPELLING C; Chen ALP, 1996, DISTRIB PARALLEL DAT, V4, P143; Dey D, 1998, P ANN HICSS, P305, DOI 10.1109/HICSS.1998.649225; Dietterich Thomas G., 2000, P 1 INT WORKSH MULT, P1; FAIR ME, 1997, P REC LINK TECHN, P427; FELLEGI IP, 1969, J AM STAT ASSOC, V64, P1183, DOI 10.2307/2286061; Gama J, 2000, MACH LEARN, V41, P315, DOI 10.1023/A:1007652114878; Ganesh M., 1996, P 2 INT C KNOWL DISC, P291; Haimowitz I. J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Hernandez MA, 1998, DATA MIN KNOWL DISC, V2, P9, DOI 10.1023/A:1009761603038; KITTLER J, 2002, P MCS 2002 BERL; KITTLER J, 2001, P MCS 2001 BERL; KITTLER J, 2000, P MCS 2000 BERL; Lujan-Mora S., 2001, Proceedings 2001 International Database Engineering and Applications Symposium, DOI 10.1109/IDEAS.2001.938087; NEWCOMBE HB, 1959, SCIENCE, V130, P954, DOI 10.1126/science.130.3381.954; Newcombe HB, 1988, HDB RECORD LINKAGE M; Pinheiro J. C., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; RAM S, 2001, P 11 ANN WORKSH INF, P193; Segev A, 1996, INT J COOP INF SYST, V5, P73, DOI 10.1142/S021884309600004X; Stephen G.A., 1994, STRING SEARCHING ALG; Tejada S, 2001, INFORM SYST, V26, P607, DOI 10.1016/S0306-4379(01)00042-4; Verykios VS, 2000, INFORM SCIENCES, V126, P83, DOI 10.1016/S0020-0255(00)00013-X; Weiss S. M., 1991, COMPUTER SYSTEMS LEA; WINKLER WE, 1999, EXCHANGE TECHNOLOGY, P313; WINKLER WE, 1997, P REC LINK TECHN, P374; Witten I. H., 2000, DATA MINING PRACTICA; ZHAO H, 2001, P AMCIS BOST MA US A, P357	28	18	19	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0306-4379		INFORM SYST	Inf. Syst.	APR	2005	30	2					119	132		10.1016/j.is.2003.11.001		14	Computer Science, Information Systems	Computer Science	879TA	WOS:000225740600002	
J	Bowd, C; Medeiros, FA; Zhang, ZH; Zangwill, LM; Hao, JC; Lee, TW; Sejnowski, TJ; Weinreb, RN; Goldbaum, MH				Bowd, C; Medeiros, FA; Zhang, ZH; Zangwill, LM; Hao, JC; Lee, TW; Sejnowski, TJ; Weinreb, RN; Goldbaum, MH			Relevance vector machine and support vector machine classifier analysis of scanning laser polarimetry retinal nerve fiber layer measurements	INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE			English	Article							VARIABLE CORNEAL COMPENSATION; ANTERIOR SEGMENT BIREFRINGENCE; STANDARD AUTOMATED PERIMETRY; VISUAL-FIELD ABNORMALITIES; LEARNING CLASSIFIERS; GLAUCOMATOUS EYES; POLARIZATION COMPENSATION; STRUCTURAL DAMAGE; NEURAL NETWORKS; OPTIC DISC	PURPOSE. To classify healthy and glaucomatous eyes using relevance vector machine (RVM) and support vector machine (SVM) learning classifiers trained on retinal nerve fiber layer (RNFL) thickness measurements obtained by scanning laser polarimetry (SLP). METHODS. Seventy-two eyes of 72 healthy control subjects ( average age = 64.3 +/- 8.8 years, visual field mean deviation = - 0.71 +/- 1.2 dB) and 92 eyes of 92 patients with glaucoma ( average age = 66.9 +/- 8.9 years, visual field mean deviation = - 5.32 +/- 4.0 dB) were imaged with SLP with variable corneal compensation (GDx VCC; Laser Diagnostic Technologies, San Diego, CA). RVM and SVM learning classifiers were trained and tested on SLP-determined RNFL thickness measurements from 14 standard parameters and 64 sectors ( approximately 5.6 degrees each) obtained in the circumpapillary area under the instrument-defined measurement ellipse ( total 78 parameters). Tenfold cross-validation was used to train and test RVM and SVM classifiers on unique subsets of the full 164-eye data set and areas under the receiver operating characteristic (AUROC) curve for the classification of eyes in the test set were generated. AUROC curve results from RVM and SVM were compared to those for 14 SLP software-generated global and regional RNFL thickness parameters. Also reported was the AUROC curve for the GDx VCC software-generated nerve fiber indicator (NFI). RESULTS. The AUROC curves for RVM and SVM were 0.90 and 0.91, respectively, and increased to 0.93 and 0.94 when the training sets were optimized with sequential forward and backward selection ( resulting in reduced dimensional data sets). AUROC curves for optimized RVM and SVM were significantly larger than those for all individual SLP parameters. The AUROC curve for the NFI was 0.87. CONCLUSIONS. Results from RVM and SVM trained on SLP RNFL thickness measurements are similar and provide accurate classification of glaucomatous and healthy eyes. RVM may be preferable to SVM, because it provides a Bayesian-derived probability of glaucoma as an output. These results suggest that these machine learning classifiers show good potential for glaucoma diagnosis.	Univ Calif San Diego, Hamilton Glaucoma Ctr, La Jolla, CA 92037 USA; Univ Calif San Diego, Inst Neural Computat, La Jolla, CA 92037 USA; Salk Inst Biol Studies, Computat Neurobiol Labs, La Jolla, CA USA; VA San Diego Healthcare Syst, San Diego, CA USA	Bowd, C (reprint author), Univ Calif San Diego, Hamilton Glaucoma Ctr, La Jolla, CA 92037 USA.	cbowd@eyecenter.ucsd.edu	Hao, Jiucang/G-7017-2012				Bagga H, 2003, AM J OPHTHALMOL, V135, P521, DOI 10.1016/S0002-9394(02)02077-9; Bagga Harmohina, 2004, International Ophthalmology Clinics, V44, P29, DOI 10.1097/00004397-200404420-00005; Bagga H, 2004, AM J OPHTHALMOL, V137, P797, DOI 10.1016/j.ajo.2003.11.060; Bishop CM, 2000, UNCERTAINTY ARTIFICI, P45; BISHOP CM, 2003, NATO SCI SERIES 3, V190, P267; Bowd C, 2002, INVEST OPHTH VIS SCI, V43, P3444; Bowd C, 2003, ARCH OPHTHALMOL-CHIC, V121, P961, DOI 10.1001/archopht.121.7.961; Bowd C, 2004, INVEST OPHTH VIS SCI, V45, P2255, DOI 10.1167/iovs.03-1087; Bowd C, 2001, INVEST OPHTH VIS SCI, V42, P1993; Brigatti L, 1996, AM J OPHTHALMOL, V121, P511; Campanini R, 2004, PHYS MED BIOL, V49, P961, DOI 10.1088/0031-9155/49/6/007; Colen TP, 2001, OPHTHALMOLOGY, V108, P151, DOI 10.1016/S0161-6420(00)00516-9; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; Garway-Health DF, 2002, INVEST OPHTH VIS SCI, V43, P1465; Goldbaum MH, 2002, INVEST OPHTH VIS SCI, V43, P162; Greenfield DS, 2000, AM J OPHTHALMOL, V129, P715, DOI 10.1016/S0002-9394(00)00353-6; Hodapp E, 1993, CLIN DECISIONS GLAUC; Hothorn T, 2003, ARTIF INTELL MED, V27, P65, DOI 10.1016/S0933-3657(02)00085-4; Mardin CY, 2003, J GLAUCOMA, V12, P340, DOI 10.1097/00061198-200308000-00008; Medeiros FA, 2004, ARCH OPHTHALMOL-CHIC, V122, P698, DOI 10.1001/archopht.122.5.698; Medeiros FA, 2004, ARCH OPHTHALMOL-CHIC, V122, P827, DOI 10.1001/archopht.122.6.827; Medeiros FA, 2003, BRIT J OPHTHALMOL, V87, P413, DOI 10.1136/bjo.87.4.413; Piliouras N, 2004, COMPUT MED IMAG GRAP, V28, P247, DOI 10.1016/j.compmedimag.2004.04.003; Reus NJ, 2004, INVEST OPHTH VIS SCI, V45, P840, DOI 10.1167/iovs.03-0646; Sample PA, 2002, INVEST OPHTH VIS SCI, V43, P2660; Shoeb A, 2004, EPILEPSY BEHAV, V5, P483, DOI 10.1016/j.yebeh.2004.05.005; Strauss DJ, 2004, IEEE T BIO-MED ENG, V51, P1147, DOI 10.1109/TBME.2004.827948; Tannenbaum DP, 2004, OPHTHALMOLOGY, V111, P259, DOI 10.1016/j.ophtha.2003.05.015; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Uchida H, 1996, INVEST OPHTH VIS SCI, V37, P2393; Vapnik V. N., 2000, NATURE STAT LEARNING; Vapnik VN, 1998, STAT LEARNING THEORY; WEINREB RN, 1990, ARCH OPHTHALMOL-CHIC, V108, P557; Weinreb RN, 1999, ARCH OPHTHALMOL-CHIC, V117, P1403; Weinreb RN, 2002, ARCH OPHTHALMOL-CHIC, V120, P901; Weinreb RN, 2003, ARCH OPHTHALMOL-CHIC, V121, P218; Zangwill LM, 2004, INVEST OPHTH VIS SCI, V45, P3144, DOI 10.1167/iovs.04-0202; ZANGWILL LM, 2004, GLAUCOMA, P63; Zhou QY, 2002, INVEST OPHTH VIS SCI, V43, P2221	39	32	34	ASSOC RESEARCH VISION OPHTHALMOLOGY INC	ROCKVILLE	12300 TWINBROOK PARKWAY, ROCKVILLE, MD 20852-1606 USA	0146-0404		INVEST OPHTH VIS SCI	Invest. Ophthalmol. Vis. Sci.	APR	2005	46	4					1322	1329		10.1167/iovs.04-1122		8	Ophthalmology	Ophthalmology	910DB	WOS:000227908900032	
J	Baumgartner, C; Bohm, C; Baumgartner, D				Baumgartner, C; Bohm, C; Baumgartner, D			Modelling of classification rules on metabolic patterns including machine learning and expert knowledge	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						machine learning; classification rules; metabolic patterns; expert knowledge; metabolic disorders	TANDEM MASS-SPECTROMETRY; BLOOD SPOTS; PHENYLALANINE; DEFICIENCY; DIAGNOSIS; NEWBORN; PHENYLKETONURIA; TYROSINE	Machine learning has a great potential to mine potential markers from high-dimensional metabolic data without any a priori knowledge. Exemplarily, we investigated metabolic patterns of three severe metabolic disorders, PAHD, MCADD, and 3-MCCD, on which we constructed classification models for disease screening and diagnosis using a decision tree paradigm and logistic regression analysis (LRA). For the LRA model-building process we assessed the relevance of established diagnostic flags, which have been developed from the biochemical knowledge of newborn metabolism, and compared the models' error rates with those of the decision tree classifier. Both approaches yielded comparable classification accuracy in terms of sensitivity (> 95.2%), while the LRA models built on flags showed significantly enhanced specificity. The number of false positive cases did not exceed 0.001%. (c) 2004 Elsevier Inc. All rights reserved.	Univ Hlth Sci Med Informat & Technol, Inst Informat Syst, Res Grp Biomed Data Min, A-6020 Innsbruck, Austria; Univ Munich, Inst Comp Sci, D-80538 Munich, Germany; Univ Innsbruck, Dept Pediat, A-6020 Innsbruck, Austria	Baumgartner, C (reprint author), Univ Hlth Sci Med Informat & Technol, Inst Informat Syst, Res Grp Biomed Data Min, Innrain 98, A-6020 Innsbruck, Austria.	christian.baumgartner@umit.at					ADLER C, 1992, J INHERIT METAB DIS, V15, P405, DOI 10.1007/BF02435989; BANNWART C, 1992, J INHERIT METAB DIS, V15, P863, DOI 10.1007/BF01800223; Baumgartner C, 2004, Proceedings of the Second IASTED International Conference on Biomedical Engineering, P357; BAUMGARTNER C, 2004, IN PRESS BIOINFORMAT; BLAU N, 2001, METABOLIC MOL BASES, pCH78; Chace DH, 1999, ACTA PAEDIATR, V88, P45, DOI 10.1080/080352599750029367; Chace DH, 1998, CLIN CHEM, V44, P2405; CHACE DH, 1993, CLIN CHEM, V39, P66; Hosmer DW, 2000, APPL LOGISTIC REGRES; Langley P., 1994, P AAAI FALL S REL, P140; Lee KR, 2003, PROTEOMICS, V3, P1680, DOI 10.1002/pmic.200300515; LIEBL B, 2003, EUR J PEDIATR S1, V162, P57; Liebl B, 2002, PREV MED, V34, P132, DOI 10.1006/pmed.2001.0954; Mendes Pedro, 2002, Brief Bioinform, V3, P134; Millington D.S., 1992, ADV CHEM DIAGNOSIS T, V1, P59; Mitchell T, 1997, MACHINE LEARNING; Neville P, 2003, PROTEOMICS, V3, P1710, DOI 10.1002/pmic.200300516; Purohit PV, 2003, PROTEOMICS, V3, P1699, DOI 10.1002/pmic.200300518; Quinlan R, 1992, MACH LEARN, V1, P81; Quinlan Ross, 1993, C4 5 PROGRAM MACHINE; RASHED MS, 1995, PEDIATR RES, V38, P324, DOI 10.1203/00006450-199509000-00009; VANHOVE JLK, 1993, AM J HUM GENET, V52, P958; Witten I. H., 2000, DATA MINING PRACTICA; *AM COLL MED GEN A, 2000, GENET MED, V2, P267; *CAL DEP HLTH SERV, MSMS RES PROJ; *CHILDR HLTH SYST, GEN TESTS MED GEN IN; *NAT CTR BIOT INF, ONL MEND INH MAN OMI; *WISC STAT LAB HYG, HLTH PROF GUID NEWB	28	20	20	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464		J BIOMED INFORM	J. Biomed. Inform.	APR	2005	38	2					89	98		10.1016/j.jbi.2004.08.009		10	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	915OO	WOS:000228313800001	
J	Pakhomov, SV; Buntrock, J; Chute, CG				Pakhomov, SV; Buntrock, J; Chute, CG			Prospective recruitment of patients with congestive heart failure using an ad-hoc binary classifier	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						automatic classification; naive Bayes; perceptron; machine learning; congestive heart failure; natural language processing; medical informatics		This paper addresses a very specific problem of identifying patients diagnosed with a specific condition for potential recruitment in a clinical trial or an epidemiological study. We present a simple machine learning method for identifying patients diagnosed with congestive heart failure and other related conditions by automatically classifying clinical notes dictated at Mayo Clinic. This method relies on an automatic classifier trained on comparable amounts of positive and negative samples of clinical notes previously categorized by human experts. The documents are represented as feature vectors, where features are a mix of demographic information as well as single words and concept mappings to MeSH and HICDA classification systems. We compare two simple and efficient classification algorithms (Naive Bayes and Perceptron) and a baseline term spotting method with respect to their accuracy and recall on positive samples. Depending on the test set, we find that Naive Bayes yields better recall on positive samples (95 vs. 86%) but worse accuracy than Perceptron (57 vs. 65%). Both algorithms perform better than the baseline with recall on positive samples of 71% and accuracy of 54%. (c) 2004 Elsevier Inc. All rights reserved.	Mayo Clin & Mayo Fdn, Coll Med, Div Biomed Informat, Rochester, MN 55905 USA	Pakhomov, SV (reprint author), Mayo Clin & Mayo Fdn, Coll Med, Div Biomed Informat, 200 1st St SW, Rochester, MN 55905 USA.	pakhomov@mayo.edu; buntrock@mayo.edu; chute@mayo.edu					AFRIN B, 2003, P AM MED INF ASS FAL, P16; Anderson J. A., 1995, INTRO NEURAL NETWORK; ARONOW D, 1995, P MED S, V199, P8; Aronow DB, 1999, J AM MED INFORM ASSN, V6, P393; Aronsky D, 2000, Proc AMIA Symp, P12; CARLSON AJ, SNOW USERS GUIDE COG; Chapman W W, 2001, Proc AMIA Symp, P105; Commission on Professional and Hospital Activities, 1973, HOSP AD ICDA, V1; Damerau F. J., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval; Horn L.R., 1989, NATURAL HIST NEGATIO; Jain N L, 1997, Proc AMIA Annu Fall Symp, P829; Johnson DE, 2002, IBM SYST J, V41, P428; Lewis D. D., 1998, P 10 EUR C MACH LEAR, P4; Manning C. D., 1999, FDN STAT NATURAL LAN; Nigam K., 1999, P IJCAI 99 WORKSH MA, P61; WILCOX A, 2000, THESIS COLUMBIA U NY; Yang Y., 1992, P 14 INT C COMP LING, P447; YANG YM, 1994, P 17 ANN INT ACM SIG, P11; *NLM, 2000, FACT SHEET MED SUBJ	19	20	20	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464		J BIOMED INFORM	J. Biomed. Inform.	APR	2005	38	2					145	153		10.1016/j.jbi.2004.11.016		9	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	915OO	WOS:000228313800005	
J	Arimoto, R; Prasad, MA; Gifford, EM				Arimoto, R; Prasad, MA; Gifford, EM			Development of CYP3A4 inhibition models: Comparisons of machine-learning techniques and molecular descriptors	JOURNAL OF BIOMOLECULAR SCREENING			English	Article						CYP3A4; BFC; in silico screening; machine learning; structural fingerprint; similarity index; kappa	CYTOCHROME-P450 ACTIVE-SITES; DRUG-DRUG INTERACTIONS; HUMAN LIVER-MICROSOMES; IN-VITRO; 3A4 INHIBITORS; KETOCONAZOLE; METABOLISM; PHARMACOPHORE; DISCOVERY; CYP2D6	Computational models of cytochrome P450 3A4 inhibition were developed based on high-throughput screening data for 4470 proprietary compounds. Multiple models differentiating inhibitors (IC50 < 3 mu M) and noninhibitors were generated using various machine-learning algorithms (recursive partitioning [RP], Bayesian classifier, logistic regression, k-nearest-neighbor, and support vector machine [SVM]) with structural fingerprints and topological indices. Nineteen models were evaluated by internal 10-fold cross-validation and also by an independent test set. Three most predictive models, Barnard Chemical Information (BCI)-fingerprint/SVM, MDL-keyset/SVM, and topological indices/RP, correctly classified 249,248, and 236 compounds of 291 noninhibitors and 135,137, and 147 compounds of 179 inhibitors in the validation set. Their overall accuracies were 82%, 82%, and 81%, respectively. Investigating applicability of the BCI/SVM model found a strong correlation between the predictive performance and the structural similarity to the training set. Using Tanimoto similarity index as a confidence measurement for the predictions, the limitation of the extrapolation was 0.7 in the case of the BCI/SVM model. Taking consensus of the 3 best models yielded a further improvement in predictive capability, kappa = 0.65 and accuracy = 83%. The consensus model could also be tuned to minimize either false positives or false negatives depending on the emphasis of the screening. (Journal of Biomolecular Screening 2005:197-205).	Pfizer Global Res & Dev, Ann Arbor, MI USA	Arimoto, R (reprint author), Vertex Pharmaceut Inc, 130 Waverly St, Cambridge, MA 02139 USA.	rieko_arimoto@vrtx.com					AHMAD SR, 1995, LANCET, V345, P508, DOI 10.1016/S0140-6736(95)90595-2; Arbib MA, 2003, HDB BRAIN THEORY NEU, P405; Baune B, 1999, DRUG METAB DISPOS, V27, P565; Blanchard N, 2004, CURR DRUG METAB, V5, P147, DOI 10.2174/1389200043489072; Boxenbaum H, 1999, J PHARM PHARM SCI, V2, P47; Breiman L, 2001, MACH LEARN, V45, P261, DOI 10.1023/A:1017934522171; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L., 1984, CLASSIFCATION REGRES; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Cohen LH, 2003, DRUG METAB DISPOS, V31, P1005, DOI 10.1124/dmd.31.8.1005; Crespi CL, 1998, MED CHEM RES, V8, P457; Crespi CL, 1997, ANAL BIOCHEM, V248, P188, DOI 10.1006/abio.1997.2145; de Groot MJ, 2002, ADV DRUG DELIVER REV, V54, P367, DOI 10.1016/S0169-409X(02)00009-1; DOWNS GM, 1989, J CHEM INF COMP SCI, V29, P207, DOI 10.1021/ci00063a009; Duda R. O., 2001, PATTERN CLASSIFICATI; Durant JL, 2002, J CHEM INF COMP SCI, V42, P1273, DOI 10.1021/ci010132r; Ekins S, 2003, DRUG METAB DISPOS, V31, P1077, DOI 10.1124/dmd.31.9.1077; Ekins S, 2001, DRUG METAB DISPOS, V29, P936; Ekins S, 1999, J PHARMACOL EXP THER, V290, P429; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Galetin A, 2002, DRUG METAB DISPOS, V30, P1512, DOI 10.1124/dmd.30.12.1512; Gao F, 2002, J BIOMOL SCREEN, V7, P373, DOI 10.1089/108705702320351231; Gasteiger J., 1990, TETRAHEDRON COMPUT M, V3, P537, DOI 10.1016/0898-5529(90)90156-3; HONIG PK, 1993, JAMA-J AM MED ASSOC, V269, P1513, DOI 10.1001/jama.269.12.1513; Hutzler JM, 2002, DRUG METAB DISPOS, V30, P355, DOI 10.1124/dmd.30.4.355; JOACHIMS T., 2002, LEARNING CLASSIFY TE; Kenworthy KE, 1999, BRIT J CLIN PHARMACO, V48, P716; Kier L.B., 1986, MOL CONNECTIVITY STR; Kier L.B., 1999, MOL STRUCTURE DESCRI; KIER LB, 1986, QUANT STRUCT-ACT REL, V5, P1, DOI 10.1002/qsar.19860050102; KOMAREK PR, 2003, 9 INT WORKSH ART INT; Korzekwa KR, 1998, BIOCHEMISTRY-US, V37, P4137, DOI 10.1021/bi9715627; Krayenbuhl JC, 1999, EUR J CLIN PHARMACOL, V55, P559, DOI 10.1007/s002280050673; Lichter JB, 1997, CURR OPIN BIOTECH, V8, P692, DOI 10.1016/S0958-1669(97)80121-8; Lin JH, 1998, CLIN PHARMACOKINET, V35, P361, DOI 10.2165/00003088-199835050-00003; Lin JH, 2002, DRUG DRUG INTERACTIO, P415; LIU T, 2004, ADV NEURAL INFORMATI, P16; Molnar L, 2002, BIOORG MED CHEM LETT, V12, P419, DOI 10.1016/S0960-894X(01)00771-5; PROVOST F, 1998, 15 INT C MACH LEARN; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Riley RJ, 2001, PHARMACEUT RES, V18, P652, DOI 10.1023/A:1011085411050; Smith DA, 1997, DRUG DISCOV TODAY, V2, P479, DOI 10.1016/S1359-6446(97)01085-4; STOKES ME, 1995, CATEGORICAL DATA ANA, P98; Stresser DM, 2000, DRUG METAB DISPOS, V28, P1440; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Vapnik V. N, 1995, NATURE STAT LEARNING; Wang JS, 1999, PHARMACOL TOXICOL, V85, P157; Wang RW, 2000, DRUG METAB DISPOS, V28, P360; WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005; Willett P, 1998, J CHEM INF COMP SCI, V38, P983, DOI 10.1021/ci9800211; Williams PA, 2004, SCIENCE, V305, P683, DOI 10.1126/science.1099736; Wrighton SA, 2000, DRUG METAB REV, V32, P339, DOI 10.1081/DMR-100102338; Yano JK, 2004, J BIOL CHEM, V279, P38091, DOI 10.1074/jbc.C400293200	54	44	44	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	1087-0571		J BIOMOL SCREEN	J. Biomol. Screen	APR	2005	10	3					197	205		10.1177/1087057104274091		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Chemistry, Analytical	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Chemistry	916KX	WOS:000228384900001	
J	Wagner, M; Adamczak, R; Porollo, A; Meller, J				Wagner, M; Adamczak, R; Porollo, A; Meller, J			Linear regression models for solvent accessibility prediction in proteins	JOURNAL OF COMPUTATIONAL BIOLOGY			English	Article						relative solvent accessibility; support vector regression; least squares regression; neural networks; classification; protein structure prediction	SECONDARY STRUCTURE; NEURAL-NETWORKS; INFORMATION; FAMILIES; DATABASE	The relative solvent accessibility ( RSA) of an amino acid residue in a protein structure is a real number that represents the solvent exposed surface area of this residue in relative terms. The problem of predicting the RSA from the primary amino acid sequence can therefore be cast as a regression problem. Nevertheless, RSA prediction has so far typically been cast as a classification problem. Consequently, various machine learning techniques have been used within the classification framework to predict whether a given amino acid exceeds some ( arbitrary) RSA threshold and would thus be predicted to be "exposed," as opposed to " buried." We have recently developed novel methods for RSA prediction using nonlinear regression techniques which provide accurate estimates of the real-valued RSA and outperform classification-based approaches with respect to commonly used two-class projections. However, while their performance seems to provide a significant improvement over previously published approaches, these Neural Network (NN) based methods are computationally expensive to train and involve several thousand parameters. In this work, we develop alternative regression models for RSA prediction which are computationally much less expensive, involve orders-of-magnitude fewer parameters, and are still competitive in terms of prediction quality. In particular, we investigate several regression models for RSA prediction using linear L-1-support vector regression (SVR) approaches as well as standard linear least squares (LS) regression. Using rigorously derived validation sets of protein structures and extensive cross-validation analysis, we compare the performance of the SVR with that of LS regression and NN-based methods. In particular, we show that the flexibility of the SVR ( as encoded by metaparameters such as the error insensitivity and the error penalization terms) can be very beneficial to optimize the prediction accuracy for buried residues. We conclude that the simple and computationally much more efficient linear SVR performs comparably to nonlinear models and thus can be used in order to facilitate further attempts to design more accurate RSA prediction methods, with applications to fold recognition and de novo protein structure prediction methods.	Childrens Hosp Res Fdn, Div Biomed Informat, Cincinnati, OH 45229 USA; Nicholas Copernicus Univ, Dept Informat, PL-87100 Torun, Poland	Meller, J (reprint author), Childrens Hosp Res Fdn, Div Biomed Informat, 3333 Burnet Ave, Cincinnati, OH 45229 USA.	jmeller@chmcc.org	Meller, Jaroslaw/A-1971-2011; Wagner, Michael/A-4649-2011	Meller, Jaroslaw/0000-0002-1162-8253; 			Adamczak R, 2004, PROTEINS, V56, P753, DOI 10.1002/prot.20176; Ahmad S, 2002, BIOINFORMATICS, V18, P819, DOI 10.1093/bioinformatics/18.6.819; Ahmad S, 2003, PROTEINS, V50, P629, DOI 10.1002/prot.10328; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Bateman A, 2002, NUCLEIC ACIDS RES, V30, P276, DOI 10.1093/nar/30.1.276; Benson DA, 2003, NUCLEIC ACIDS RES, V31, P23, DOI 10.1093/nar/gkg057; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; CHOTHIA C, 1976, J MOL BIOL, V105, P1, DOI 10.1016/0022-2836(76)90191-1; CUFF JA, 1999, PROTEIN-STRUCT FUNCT, V40, P502; Czyzyk J, 1999, OPTIM METHOD SOFTW, V11-2, P397, DOI 10.1080/10556789908805757; Eyrich VA, 2001, BIOINFORMATICS, V17, P1242, DOI 10.1093/bioinformatics/17.12.1242; Fischer D, 2001, PROTEINS, P171; Hastie T, 2001, ELEMENTS STAT LEARNI; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; Kim H, 2004, PROTEINS, V54, P557, DOI 10.1002/prot.10602; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; Meller J, 2001, PROTEINS, V45, P241, DOI 10.1002/prot.1145; MELLER J, 2000, LOOPP LEARNING OBSER; Naderi-Manesh H, 2001, PROTEINS, V42, P452, DOI 10.1002/1097-0134(20010301)42:4<452::AID-PROT40>3.0.CO;2-Q; Pollastri G, 2002, PROTEINS, V47, P142, DOI 10.1002/prot.10069; Przybylski D, 2002, PROTEINS, V46, P197, DOI 10.1002/prot.10029; Richardson CJ, 1999, PROTEIN ENG, V12, P1051, DOI 10.1093/protein/12.12.1051; ROST B, 1994, PROTEINS, V19, P55, DOI 10.1002/prot.340190108; Rost B, 2001, J STRUCT BIOL, V134, P204, DOI 10.1006/jsbi.2000.4336; ROST B, 1994, PROTEINS, V20, P216, DOI 10.1002/prot.340200303; Schonbrun J, 2002, CURR OPIN STRUC BIOL, V12, P348, DOI 10.1016/S0959-440X(02)00336-6; Simons KT, 1997, J MOL BIOL, V268, P209, DOI 10.1006/jmbi.1997.0959; Thompson MJ, 1996, PROTEINS, V25, P38, DOI 10.1002/(SICI)1097-0134(199605)25:1<38::AID-PROT4>3.3.CO;2-H; Venclovas C, 2001, PROTEINS, P163; Wagner M, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-26; Wagner M, 2004, MATH PROGRAM, V101, P301, DOI 10.1007/s10107-004-0526-7; *MATHW, MATLAB VERS 7 0	33	48	49	MARY ANN LIEBERT INC	NEW ROCHELLE	140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA	1066-5277		J COMPUT BIOL	J. Comput. Biol.	APR	2005	12	3					355	369		10.1089/cmb.2005.12.355		15	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	922JS	WOS:000228834200005	
J	Winn, J; Bishop, CM				Winn, J; Bishop, CM			Variational message passing	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						Bayesian networks; variational inference; message passing	PROPAGATION; MODELS	Bayesian inference is now widely established as one of the principal foundations for machine learning. In practice, exact inference is rarely possible, and so a variety of approximation techniques have been developed, one of the most widely used being a deterministic framework called variational inference. In this paper we introduce Variational Message Passing (VMP), a general purpose algorithm for applying variational inference to Bayesian Networks. Like belief propagation, VMP proceeds by sending messages between nodes in the network and updating posterior beliefs using local operations at each node. Each such update increases a lower bound on the log evidence ( unless already at a local maximum). In contrast to belief propagation, VMP can be applied to a very general class of conjugate-exponential models because it uses a factorised variational approximation. Furthermore, by introducing additional variational parameters, VMP can be applied to models containing non-conjugate distributions. The VMP framework also allows the lower bound to be evaluated, and this can be used both for model comparison and for detection of convergence. Variational message passing has been implemented in the form of a general purpose inference engine called VIBES ('Variational Inference for BayEsian networkS') which allows models to be specified graphically and then solved variationally without recourse to coding.	Microsoft Res Cambridge, Cambridge CB3 0FB, England	Winn, J (reprint author), Microsoft Res Cambridge, Roger Needham Bldg 7 JJ Thomson Ave, Cambridge CB3 0FB, England.	JWINN@MICROSOFT.COM; CMBISHOP@MICROSOFT.COM					Attias H, 2000, ADV NEUR IN, V12, P209; Bishop C. M., 2003, P 19 C UNC ART INT, P57; BISHOP CM, 2002, ADV NEURAL INFORM PR, V15; BISHOP CM, 2000, P EUR C COMP VIS, V1, P3; BISHOP CM, 1999, P 9 INT C ART NEUR N, V1, P509; BISHOP CM, 2003, P ART INT STAT KEY W; Cowell R., 1999, STAT ENG INFORM SCI; Ghahramani Z., 2001, ADV NEURAL INFORM PR, V13; GILKS WR, 1992, APPL STAT-J ROY ST C, V41, P337, DOI 10.2307/2347565; JAAKKOLA T, 1996, P 6 INT WORKSH ART I; Jordan MI, 1998, NATO ADV SCI I D-BEH, V89, P105; PEARL J, 1986, ARTIF INTELL, V29, P241, DOI 10.1016/0004-3702(86)90072-X; LAURITZEN SL, 1992, J AM STAT ASSOC, V87, P1098, DOI 10.2307/2290647; LUNN DJ, 2000, STAT COMPUT, V10, P321; MINKA T, 2001, P 17 C UNC ART INT, P362; Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355; THOMAS A, 1992, BAYESIAN STAT; Wiegerinck W, 2000, UNCERTAINTY ARTIFICI; Winn J. M., 2003, THESIS U CAMBRIDGE	19	70	71	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	APR	2005	6						661	694				34	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026HI	WOS:000236329600011	
J	Majumder, SK; Ghosh, N; Gupta, PK				Majumder, SK; Ghosh, N; Gupta, PK			Relevance vector machine for optical diagnosis of cancer	LASERS IN SURGERY AND MEDICINE			English	Article						diagnostic algorithm; oral cancer; posterior probability; relevance vector machine (RVM); squamous cell carcinoma (SCC); support vector machine (SVM)	LASER-INDUCED FLUORESCENCE; MULTIVARIATE STATISTICAL ALGORITHM; AUTOFLUORESCENCE SPECTROSCOPY; PATTERN-RECOGNITION; EXCITATION WAVELENGTHS; CERVICAL FLUORESCENCE; IN-VITRO; CLASSIFICATION; NETWORKS; SPECTRA	Background and Objectives: A probability-based, robust diagnostic algorithm is an essential requirement for successful clinical use of optical spectroscopy for cancer diagnosis. This study reports the use of the theory of relevance vector machine (RVM), a recent Bayesian machine learning framework of statistical pattern recognition, for development of a fully probabilistic algorithm for auto fluorescence diagnosis of early stage cancer of human oral cavity. It also presents a comparative evaluation of the diagnostic efficacy of the RVM algorithm with that based on support vector machine (SVM) that has recently received considerable attention for this purpose. Study Design/Materials and Methods: The diagnostic algorithms were developed. using in vivo autofluorescence spectral data acquired from human oral cavity with a N-2 laser-based portable fluorimeter. The spectral data of both patients as well as normal volunteers, enrolled at Out Patient department of the Govt. Cancer Hospital, Indore for screening of oral cavity, A ere used for this purpose. The patients selected had no prior confirmed malignancy and were diagnosed of squamous cell carcinoma (SCC), Grade-I on the basis of histopathology of biopsy taken from abnormal site subsequent to acquisition of spectra.. Autofluorescence spectra were recorded from a total of 171 tissue sites from 16 patients and 154 healthy squamous tissue sites from 13 normal volunteers. Of 171 tissues sites from patients; 83 were SCC and the rest were contralateral uninvolved squamous tissue. Each site was treated separately and classified via the diagnostic algorithm developed. Instead of the spectral data from uninvolved sites of patients, the data from normal volunteers were used as the normal database for the development of diagnostic algorithms. Results: The diagnostic algorithms based on RVM were found to provide classification performance comparable to the state-of-the-art SVMs, while at the same time explicitly predicting the probability of class membership. The sensitivity and specificity towards cancer were up to 88% and 95% for the training set data based on leaveone-out cross validation a-id up to 91% and 96% for the validation set data. When implemented on the spectral data of the uninvolved oral cavity sites from the patients, it yielded a specificity of up to 91%. Conclusions: The Bayesian framework of RVM formulation makes it possible to Predict the posterior probability of class membership in discriminating early SCC from the normal squamous tissue sites of the oral cavity in contrast to dichotomous classification provided by the non Bayesian SVM. Such classification is very helpful in handling asymmetric misclassification costs like assigning different weights for having a false negative result for identifying cancer compared to false positive. The results further demonstrate that for comparable diagnostic performances, the RVM-based algorithms use significantly fewer kernel functions and do not need to estimate any hoe parameters associated with the learning or the optimization technique to be used. This implies a considerable saving in memory and computation in a practical implementation. (c) 2005 Wiley-Liss, Inc.	Ctr Adv Technol, Biomed Applicat Sect, Indore 452013, India	Majumder, SK (reprint author), Ctr Adv Technol, Biomed Applicat Sect, R&D Block-D, Indore 452013, India.	shkm@cat.ernet.in					Agrawal N., 2003, IEEE J SEL TOP QUANT, V9, P154; Yang Y., 1996, Lasers in the Life Sciences, V7; Atkinson E N, 1995, J Cell Biochem Suppl, V23, P125; Berger J.O., 1985, STAT DECISION THEORY; Brewer M, 2001, LASER SURG MED, V29, P128, DOI 10.1002/lsm.1098; Brookner CK, 1999, LASER SURG MED, V24, P29, DOI 10.1002/(SICI)1096-9101(1999)24:1<29::AID-LSM6>3.0.CO;2-H; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Cothren RM, 1996, GASTROINTEST ENDOSC, V44, P168, DOI 10.1016/S0016-5107(96)70135-9; Dhingra JK, 1996, ARCH OTOLARYNGOL, V122, P1181; Duda R.O, 1973, PATTERN CLASSIFICATI; Gupta PK, 1997, LASER SURG MED, V21, P417, DOI 10.1002/(SICI)1096-9101(1997)21:5<417::AID-LSM2>3.0.CO;2-T; HAND DJ, 1986, PATTERN RECOGN LETT, V4, P335, DOI 10.1016/0167-8655(86)90054-1; Heintzelman DL, 2000, PHOTOCHEM PHOTOBIOL, V72, P103, DOI 10.1562/0031-8655(2000)072<0103:OEWFIV>2.0.CO;2; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; KAPADIA CR, 1990, GASTROENTEROLOGY, V99, P150; Koenig F, 1996, J UROLOGY, V156, P1597, DOI 10.1016/S0022-5347(01)65456-9; Lin WC, 2000, J BIOMED OPT, V5, P214, DOI 10.1117/1.429989; Lin WM, 2004, J BIOMED OPT, V9, P180, DOI 10.1117/1.1628244; MACKAY DJC, 1992, NEURAL COMPUT, V4, P720, DOI 10.1162/neco.1992.4.5.720; Mahadevan-Jansen A, 1996, J Biomed Opt, V1, P31, DOI 10.1117/12.227815; Majumder SK, 2000, CURR SCI INDIA, V79, P1089; Majumder SK, 2003, LASER SURG MED, V33, P48, DOI 10.1002/lsm.10191; Majumder S. K., 1999, Lasers in the Life Sciences, V8; Majumder SK, 1996, CURR SCI INDIA, V70, P833; MARCHESINI R, 1992, J PHOTOCH PHOTOBIO B, V14, P219, DOI 10.1016/1011-1344(92)85100-9; METZ CE, 1978, SEMIN NUCL MED, V8, P283, DOI 10.1016/S0001-2998(78)80014-2; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Nath A, 2004, J BIOMED OPT, V9, P523, DOI 10.1117/1.1695562; Palmer GM, 2003, IEEE T BIO-MED ENG, V50, P1233, DOI [10.1109/TBME.2003.818488, 10.1109/TMBE.2003.818488]; Ramanujam N, 1996, PHOTOCHEM PHOTOBIOL, V64, P720, DOI 10.1111/j.1751-1097.1996.tb03130.x; Ramanujam N., 2000, NEOPLASIA, V2; Rovithakis GA, 2001, IEEE T BIO-MED ENG, V48, P1088, DOI 10.1109/10.951511; SCHOMACKER KT, 1992, LASER SURG MED, V12, P63, DOI 10.1002/lsm.1900120111; SERVICKMURACA E, 1996, ANNU REV PHYS CHEM, V47, P556; Sollich P, 2000, ADV NEUR IN, V12, P349; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Tumer K, 1998, IEEE T BIO-MED ENG, V45, P953, DOI 10.1109/10.704864; van Staveren HJ, 2000, ORAL ONCOL, V36, P286, DOI 10.1016/S1368-8375(00)00004-X; Vapnik VN, 1998, STAT LEARNING THEORY; Wagnieres GA, 1998, PHOTOCHEM PHOTOBIOL, V68, P603, DOI 10.1111/j.1751-1097.1998.tb02521.x; Wang CY, 1999, PHOTOCHEM PHOTOBIOL, V69, P471, DOI 10.1111/j.1751-1097.1999.tb03314.x; WESTON J, 1998, CSDTR9804 U LONSD DE; Yang Y., 1995, Lasers in the Life Sciences, V6; Zuluaga AF, 1999, APPL SPECTROSC, V53, P302, DOI 10.1366/0003702991946695	44	25	25	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0196-8092		LASER SURG MED	Lasers Surg. Med.	APR	2005	36	4					323	333		10.1002/lsm.20160		11	Surgery	Surgery	922EK	WOS:000228819000010	
J	Conforti, D; Guido, R				Conforti, D; Guido, R			Kernel-based Support Vector Machine classifiers for early detection of myocardial infarction	OPTIMIZATION METHODS & SOFTWARE			English	Article; Proceedings Paper	Workshop on Mathematical Diagnostics	JUN, 2002	Erice, ITALY		E Majorana Ctr Sci Culture, G Stampacchia Sch Math	medical decision making; diagnosis of myocardial infarction; classification problems; Support Vector Machine; kernel functions	ARTIFICIAL NEURAL NETWORKS; MEDICINE	In this paper, we describe the development of kernel-based Support Vector Machine (SVM) classifiers to aid the early diagnosis of acute myocardial infarction (AMI). In particular, we have to recognize if a chest pain, complained by the patient, may be considered the sign of a myocardial infarction or it is the evidence of some other causes. This is a quite difficult medical decision problem, since chest pain is characterized by low specificity (typical values between 30% and 40%) as a symptom associated with myocardial infarction. Moreover, in order to make an objective and accurate diagnosis, the physician has to evaluate a large set of data coming from the patient. These aspects motivated the use of machine learning methodologies, with the aim to support the physician and increase the quality of the diagnostic decision. To this end, we formulated the medical decision problem as a supervised binary classification problem (AMI class and not AMI class), by developing a training set with 242 cases (130 in the AMI class and 112 in the not AMI class), each case characterized by a set of 105 features. We also considered a feature selection procedure, by selecting 25 of the 105 features. By the framework of generalized SVM model, we tested and validated the behavior of three kernel functions: Polynomial, Gaussian and Laplacian. By running a 10-fold cross validation procedure, the performance of the best tested classifier was 97.5%. By the same 10-fold cross validation procedure, we tested linear and quadratic discriminant analysis classifiers, with testing correctness of 86.8% and 94%, respectively. The numerical results demonstrate the effectiveness and robustness of the proposed approaches for solving the relevant medical decision making problem.	Univ Calabria, Dipartimento Elettron Informat & Sistemist, I-87030 Arcavacata Di Rende, Cosenza, Italy	Conforti, D (reprint author), Univ Calabria, Dipartimento Elettron Informat & Sistemist, Via P Bucci 41C, I-87030 Arcavacata Di Rende, Cosenza, Italy.	mimmo.conforti@unical.it	Guido, Rosita/E-5831-2012				Aizerman M.A., 1964, AUTOMAT REM CONTR, P821; Alpert JS, 2000, J AM COLL CARDIOL, V36, P959; BAXT WG, 1995, LANCET, V346, P1135, DOI 10.1016/S0140-6736(95)91804-3; Bradley P. S., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98); Cassin Matteo, 2002, Ital Heart J, V3, P399; Cherkassky V., 1998, LEARNING DATA CONCEP; Cristianini N., 2000, INTRO SUPPORT VECTOR; Fayyad U.M., 1996, ADV KNOWLEDGE DISCOV; Hertz J., 1991, INTRO THEORY NEURAL; Itchhaporia D, 1996, J AM COLL CARDIOL, V28, P515, DOI 10.1016/0735-1097(96)00174-X; Koller D., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); LEE TH, 1987, AM J CARDIOL, V60, P219, DOI 10.1016/0002-9149(87)90217-7; Lee TH, 2000, NEW ENGL J MED, V342, P1187, DOI 10.1056/NEJM200004203421607; Mangasarian OL, 2000, ADV NEUR IN, P135; MILLER RA, 1994, J AM MED INFORM ASSN, V1, P8; Pope JH, 2000, NEW ENGL J MED, V342, P1163, DOI 10.1056/NEJM200004203421603; Scholkopf B., 2002, LEARNING KERNELS; Schurmann J., 1996, PATTERN CLASSIFICATI; SHORTLIFFE E, 1990, MED INFORMATICS COMP; STONE M, 1974, J R STAT SOC B, V36, P111; VANBEMMEL JH, 1997, HDB MED INFORMATICS; Vapnik VN, 1998, STAT LEARNING THEORY; ZARLING EJ, 1983, JAMA-J AM MED ASSOC, V250, P1177, DOI 10.1001/jama.250.9.1177; Zoni-Berisso M, 2001, Ital Heart J, V2, P612; *CPLEX OPT INC, 2002, ILOG CPLEX 8 1 0 US	25	1	1	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1055-6788		OPTIM METHOD SOFTW	Optim. Method Softw.	APR-JUN	2005	20	2-3					395	407		10.1080/10556780512331318164		13	Computer Science, Software Engineering; Operations Research & Management Science; Mathematics, Applied	Computer Science; Operations Research & Management Science; Mathematics	890TQ	WOS:000226534100015	
J	Almeida, JS; Stanislaus, R; Krug, E; Arthur, JM				Almeida, JS; Stanislaus, R; Krug, E; Arthur, JM			Normalization and analysis of residual variation in two-dimensional gel electrophoresis for quantitative differential proteomics	PROTEOMICS			English	Article						alignment; error models; normalization; staining; two-dimensional gel electrophoresis	HUMAN PITUITARY PROTEOME; MASS-SPECTROMETRY; EXPRESSED PROTEINS; SOFTWARE PACKAGES; BACILLUS-SUBTILIS; GENE-EXPRESSION; NEURAL-NETWORKS; GLOBAL ANALYSIS; CELLS; REGRESSION	Although two-dimensional gel electrophoresis (2-DE) has long been a favorite experimental method to screen proteomes, its reproducibility is seldom analyzed with the assistance of quantitative error models. The lack of models of residual distributions that can be used to assign likelihood to differential expression reflects the difficulty in tackling the combined effect of variability in spot intensity and uncertain recognition of the same spot in different gels. In this report we have analyzed a series of four triplicate two-dimensional gels of chicken embryo heart samples at two distinct development stages to produce such a model of residual distribution. In order to achieve this reference error model, a nonparametric procedure for consistent spot intensity normalization had to be established, and is also reported here. In addition to variability in normalized intensity due to various sources, the residual variation between replicates was observed to be compounded by failure to identify the spot itself (gel alignment). The mixed effect is reflected by variably skewed bimodal density distributions of residuals. The extraction of a global error model that accommodated such distribution was achieved empirically by machine learning, specifically by bootstrapped artificial neural networks. The model described is being used to assign confidence values to observed variations in arbitrary 2-DE gels in order to quantify the degree of over-expression and under-expression of protein spots.	Med Univ S Carolina, Dept Biometry & Epidemiol, Charleston, SC 29425 USA; Med Univ S Carolina, Dept Cell Biol & Anat, Charleston, SC 29425 USA; Med Univ S Carolina, Div Nephrol, Dept Med, Charleston, SC 29425 USA	Almeida, JS (reprint author), Med Univ S Carolina, Dept Biometry & Epidemiol, Charleston, SC 29425 USA.	almeidaj@musc.edu					Almeida Jonas S, 2003, Genome Inform, V14, P114; Almeida JS, 2002, CURR OPIN BIOTECH, V13, P72, DOI 10.1016/S0958-1669(02)00288-4; Antonucci F, 2003, ELECTROPHORESIS, V24, P2376, DOI 10.1002/elps.200305457; Arulampalam G, 2003, NEURAL NETWORKS, V16, P561, DOI 10.1016/S0893-6080(03)00116-3; Bernhardt J, 1999, ELECTROPHORESIS, V20, P2225, DOI 10.1002/(SICI)1522-2683(19990801)20:11<2225::AID-ELPS2225>3.3.CO;2-#; Bernhardt J, 2003, GENOME RES, V13, P224, DOI 10.1101/gr.905003; Castro JL, 2000, NEURAL NETWORKS, V13, P561, DOI 10.1016/S0893-6080(00)00031-9; Cecconi D, 2003, ELECTROPHORESIS, V24, P4291, DOI 10.1002/elps.200305724; Cecconi D, 2003, ELECTROPHORESIS, V24, P1871, DOI 10.1002/elps.200305430; CROARKIN C, 2003, NIST SEMATECH E HDB; Desiderio DM, 2003, CELL MOL BIOL, V49, P689; Dowsey AW, 2003, PROTEOMICS, V3, P1567, DOI 10.1002/pmic.200300459; Dutt MJ, 2000, CURR OPIN BIOTECH, V11, P176, DOI 10.1016/S0958-1669(00)00078-1; Dutt MJ, 2001, ELECTROPHORESIS, V22, P1627, DOI 10.1002/1522-2683(200105)22:9<1627::AID-ELPS1627>3.0.CO;2-R; Frey JR, 2000, ELECTROPHORESIS, V21, P2694, DOI 10.1002/1522-2683(20000701)21:13<2694::AID-ELPS2694>3.3.CO;2-5; GADDIS ML, 1990, ANN EMERG MED, V19, P1462, DOI 10.1016/S0196-0644(05)82622-8; HAMBURGER V, 1951, J MORPHOL, V88, P49, DOI 10.1002/jmor.1050880104; Lefkovits I, 2000, ELECTROPHORESIS, V21, P2688, DOI 10.1002/1522-2683(20000701)21:13<2688::AID-ELPS2688>3.3.CO;2-K; Merril Carl R., 1993, Applied and Theoretical Electrophoresis, V3, P329; Nishihara JC, 2002, ELECTROPHORESIS, V23, P2203, DOI 10.1002/1522-2683(200207)23:14<2203::AID-ELPS2203>3.0.CO;2-H; Patton WF, 2002, J CHROMATOGR B, V771, P3, DOI 10.1016/S1570-0232(02)00043-0; PETERSON GL, 1977, ANAL BIOCHEM, V83, P346, DOI 10.1016/0003-2697(77)90043-4; Raman B, 2002, ELECTROPHORESIS, V23, P2194, DOI 10.1002/1522-2683(200207)23:14<2194::AID-ELPS2194>3.0.CO;2-#; Rosengren AT, 2003, PROTEOMICS, V3, P1936, DOI 10.1002/pmic.200300544; ROWLAND T, 2003, E WEISSTEINS WORLD M; Sivakumar Ashwin, 2002, In Silico Biology, V2, P507; Smales CM, 2003, BIOCHEM BIOPH RES CO, V306, P1050, DOI 10.1016/S0006-291X(03)01115-X; Stanislaus R, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-9; Terry DE, 2003, PROTEOMICS, V3, P1962, DOI 10.1002/pmic.200300463; Wang Zheng, 2003, Zhonghua Bing Li Xue Za Zhi, V32, P333; Wolf G, 2003, WATER SCI TECHNOL, V47, P161; Yan JX, 2002, PROTEOMICS, V2, P1682, DOI 10.1002/1615-9861(200212)2:12<1682::AID-PROT1682>3.0.CO;2-Y; Zaknich A, 2003, NEURAL NETWORKS, V16, P833, DOI 10.1016/S0893-6080(03)00096-0; Zhan XQ, 2003, CLIN CHEM, V49, P1740, DOI 10.1373/49.10.1740; Zhang B, 2003, WORLD J GASTROENTERO, V9, P2726	35	32	37	WILEY-V C H VERLAG GMBH	WEINHEIM	PO BOX 10 11 61, D-69451 WEINHEIM, GERMANY	1615-9853		PROTEOMICS	Proteomics	APR	2005	5	5					1242	1249		10.1002/pmic.200401003		8	Biochemical Research Methods; Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	914IM	WOS:000228221000007	
J	Narahari, Y; Raju, CVL; Ravikumar, K; Shah, S				Narahari, Y; Raju, CVL; Ravikumar, K; Shah, S			Dynamic pricing models for electronic business	SADHANA-ACADEMY PROCEEDINGS IN ENGINEERING SCIENCES			English	Article						dynamic pricing; shopbots; pricebots; inventory-based models; data-driven models; reinforcement learning	REVENUE MANAGEMENT; AUCTIONS; EQUILIBRIUM; INFORMATION; INTERNET; COMMERCE	Dynamic pricing is the dynamic adjustment of prices to consumers depending upon the value these customers attribute to a product or service. Today's digital economy is ready for dynamic pricing; however recent research has shown that the prices will have to be adjusted in fairly sophisticated ways, based on sound mathematical models, to derive the benefits of dynamic pricing. This article attempts to survey different models that have been used in dynamic pricing. We first motivate dynamic pricing and present underlying concepts, with several examples, and explain conditions under which dynamic pricing is likely to succeed. We then bring out the role of models in computing dynamic prices. The models surveyed include inventory-based models, data-driven models, auctions, and machine learning. We present a detailed example of an e-business market to show the use of reinforcement learning in dynamic pricing.	Indian Inst Sci, Bangalore 560012, Karnataka, India; Gen Motors India Sci Lab, Bangalore 560066, Karnataka, India; Birla Inst Technol & Sci, Dept Comp Sci, Pilani 333031, Rajasthan, India	Narahari, Y (reprint author), Indian Inst Sci, Bangalore 560012, Karnataka, India.	hari@csa.iisc.ernet.in; V.L.Chinthalapati@lse.ac.uk; ravikumar.karumanchi@gm.com					ABOUNADI J, 1996, LEARNING ALGORITHMS; AGRAWAL V, 2000, DYNAMIC PRICING TRAT; Baker W.L., 2001, MCKINSEY Q, V10, P1; BERNSTEIN F, 2005, IN PRESS MANAGE SCI; Bernstein F, 2003, OPER RES, V51, P409, DOI 10.1287/opre.51.3.409.14957; Bertsekas D., 1996, NEURO DYNAMIC PROGRA; Bichler M, 2002, IBM SYST J, V41, P287; BILLER S, 2005, IN PRESS ELECT COMME; BOLIYA N, 2005, SADHANA, V30; Boyd EA, 2003, MANAGE SCI, V49, P1363, DOI 10.1287/mnsc.49.10.1363.17316; BROOKS C, 1999, P 1 ACM C EL COMM EC, P31, DOI 10.1145/336992.337000; Cao XR, 2002, IEEE ACM T NETWORK, V10, P208; CARVALHO A, 2003, DYNAMIC PRICING REIN; CHANDE A, 2005, SADHANA, V30; COY P, 2000, BUSINESS WEEK   0410; CRAMTON P, 2004, COMBINATORIAL AUCTIO; Dasgupta P, 2000, LECT NOTES COMPUT SC, V1901, P299; DIMICCO JM, 2002, LEARNING CURVE SIMUL; DIMICCO JM, 2001, P 3 ACM C EL COMM EC, P51; DUBE P, 2002, P INFOCOM 2002; ELMAGHRABY W, 2005, INT SERIES OPERATION; ELMAGHRABY W, 2003, PRACTICE SUPPLY CHAI; Elmaghraby W, 2003, MANAGE SCI, V49, P1287, DOI 10.1287/mnsc.49.10.1287.17315; Federgruen A, 1999, OPER RES, V47, P454, DOI 10.1287/opre.47.3.454; GALLEGO G, 1994, MANAGE SCI, V40, P9999; GREENWALD A, 1999, P 1 ACM C EL COMM EC; GUPTA M, 2002, P IEEE C SYST MAN CY, P373; HE L, 2005, P INFOCOM2005; Hohner G, 2003, INTERFACES, V33, P23, DOI 10.1287/inte.33.1.23.12717; Hopp WJ, 2000, FACTORY PHYS; HU JL, 2002, ONLINE REINFORMCENET; Kagel J.H., 1995, HDB EXPT EC, P501; KALAGNANAM JK, 2005, HDB QUANTITATIVE SUP; Kannan PK, 2001, INT J ELECTRON COMM, V5, P63; KEPHART JO, 2000, P 17 INT C MACH LEAR, P463; KLEMPERER P., 2003, AUCTIONS THEORY PRAC; Klemperer P., 1999, J EC SURVEYS, V33, P227, DOI 10. 1111/1467-6419. 00083; Konda VR, 1999, SIAM J CONTROL OPTIM, V38, P94, DOI 10.1137/S036301299731669X; Krishna V., 2002, AUCTION THEORY; La R. J., 1999, Proceedings of the 38th IEEE Conference on Decision and Control (Cat. No.99CH36304), DOI 10.1109/CDC.1999.827987; LAWRENCE R, 2002, MACHINE LEARNING APP; Ledyard JO, 2002, INTERFACES, V32, P4, DOI 10.1287/inte.32.5.4.30; LELOUP B, 2001, J ELECTRON COMMER RE, V1, P265; MCAFEE RP, 1987, J ECON LIT, V25, P699; McGill JI, 1999, TRANSPORT SCI, V33, P233, DOI 10.1287/trsc.33.2.233; MCWILLIAMS G, 2001, WALL STREET J   0608; Milgrom P., 2004, PUTTING AUCTION THEO; MILGROM P, 1989, J ECON PERSPECT, V3, P3; Morris J., 2000, P 2 ACM C EL COMM EC, P128, DOI DOI 10.1145/352871.352885; NARAHARI Y, 2005, SADHANA, V30; Pigou A.C., 1920, EC WELFARE; RAGHAVAN NRS, 2005, SADHANA, V30; RAJU CVL, 2004, LEARNING DYNAMIC PRI; RAJU CVL, 2004, LEARNING NON LINEAR; RAJU CVL, 2005, IN PRESS IEEE T SY C; RAJU CVL, 2003, P IEEE C EL COMM CEC; RAJU CVL, 2005, ANN OPER RES, V22; RAVIKUMAR K, 2002, MULTI AGENT LEARNING; RAVIKUMAR K, 2005, DEMAND SENSING EBUSI, V30; Reinartz W.J., 2001, EUROPEAN BUSINESS FO, V6, P35; Ross SM, 1983, INTRO STOCHASTIC DYN; ROTHSCHI.M, 1974, J ECON THEORY, V9, P185, DOI 10.1016/0022-0531(74)90066-0; RUSMEVICHIENTON.P, 2005, IN PRESS OPER RES; RUSMEVICHIENTON.P, 2004, OPPORTUNITIES CHALLE; SALOP S, 1982, AM ECON REV, V72, P1121; SHAPIRO C, 1998, INFORMATION RULES; Shen Z.J.M., 2005, HDB SUPPLY CHAIN ANA, P335; SINGH S, 1994, THESIS U MICHIGAN AN; SMITH B, 2001, INTERFACES, V31; Smith Michael D., 2000, UNDERSTANDING DIGITA; SRIDHARAN M, 2000, P 17 INT C MACH LEAR; SRIVASTAVA A, 2001, DYNAMIC PRICING MODE; STIGLER GJ, 1961, J POLIT ECON, V69, P213, DOI 10.1086/258464; STIGLITZ JE, 1979, AM ECON REV, V69, P339; Sutton R.S., 1998, REINFORCEMENT LEARNI; SWANN J, 1999, CR9904ESL; TESAURO G, 1999, P WORKSH ABS3 LEARN; TESAURO GJ, 1999, P WORKSH DEC THEOR G; VARIAN HR, 1989, HDB IND ORG; VARIAN HR, 1996, FIRST MONDAY, P1; VARIAN HR, 1980, AM EC REV        SEP, P651; VISWANATHAN S, 2005, SADHANA, V30; WEISS RM, 2001, VIRGINIA J LAW TECHN, V11, P1; Wolfstetter E., 1996, J EC SURVEYS, V10, P367, DOI 10.1111/j.1467-6419.1996.tb00018.x; Yaiche H, 2000, IEEE ACM T NETWORK, V8, P667, DOI 10.1109/90.879352; *GEN EL CORP, 2000, LETT SHAR OWN	86	17	18	INDIAN ACAD SCIENCES	BANGALORE	C V RAMAN AVENUE, SADASHIVANAGAR, P B #8005, BANGALORE 560 080, INDIA	0256-2499		SADHANA-ACAD P ENG S	Sadhana-Acad. Proc. Eng. Sci.	APR-JUN	2005	30		2-3				231	256		10.1007/BF02706246		26	Engineering, Multidisciplinary	Engineering	947SM	WOS:000230666600008	
J	Michael, WJ; Minsker, BS; Tcheng, D; Valocchi, AJ; Quinn, JJ				Michael, WJ; Minsker, BS; Tcheng, D; Valocchi, AJ; Quinn, JJ			Integrating data sources to improve hydraulic head predictions: A hierarchical machine learning approach	WATER RESOURCES RESEARCH			English	Article							GROUNDWATER MONITORING DESIGN	[1] This study investigates how machine learning methods can be used to improve hydraulic head predictions by integrating different types of data, including data from numerical models, in a hierarchical approach. A suite of four machine learning methods ( decision trees, instance-based weighting, inverse distance weighting, and neural networks) are tested in several hierarchical configurations with different types of data from the 317/319 area at Argonne National Laboratory - East. The best machine learning model had a mean predicted head error 50% smaller than an existing MODFLOW numerical flow model, and a standard deviation of predicted head error 67% lower than the MODFLOW model, computed across all sampled locations used for calibrating the MODFLOW model. These predictions were obtained using decision trees trained with all historical quarterly data; the hourly head measurements were not as useful for prediction, most likely because of their poor spatial coverage. The results show promise for using hierarchical machine learning approaches to improve predictions and to identify the most essential types of data to guide future sampling efforts. Decision trees were also combined with an existing MODFLOW model to test their capabilities for updating numerical models to improve predictions as new data are collected. The combined model had a mean error 50% lower than the MODFLOW model alone. These results demonstrate that hierarchical machine learning approaches can be used to improve predictive performance of existing numerical models in areas with good data coverage. Further research is needed to compare this approach with methods such as Kalman filtering.	Univ Illinois, Dept Civil & Environm Engn, Urbana, IL 61801 USA; Univ Illinois, Natl Ctr Supercomp Applicat, Champaign, IL 61820 USA; Argonne Natl Lab, Div Environm Assessment, Argonne, IL 60439 USA	Michael, WJ (reprint author), Caterpillar Inc, Peoria, IL 61656 USA.						Anderton SP, 2004, HYDROL PROCESS, V18, P435, DOI 10.1002/hyp.1319; Govindaraju RS, 2000, J HYDROL ENG, V5, P124; Bessler FT, 2003, J WATER RES PL-ASCE, V129, P26, DOI 10.1061/(ASCE)0733-9496(2003)129:1(26); Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Coppola E, 2003, J HYDROL ENG, V8, P348, DOI 10.1061/(ASCE)1084-0699(2003)8:6(348); Coulibaly P, 2001, J HYDROL ENG, V6, P367, DOI 10.1061/(ASCE)1084-0699(2001)6:5(367); Coulibaly P, 2001, WATER RESOUR RES, V37, P885, DOI 10.1029/2000WR900368; Eppstein MJ, 1996, WATER RESOUR RES, V32, P3321, DOI 10.1029/96WR02283; Frink N. T., 1994, 940061 AIAA; Gelb A., 1974, APPL OPTIMAL ESTIMAT; GRAHAM W, 2001, STOCHASTIC METHODS S, pCH9; GRAHAM WD, 1993, WATER RESOUR RES, V29, P3791, DOI 10.1029/93WR01813; MATHEUS CJ, 1990, THESIS U ILL URBANA; National Research Council, 2000, NAT ATT GROUNDW REM; National Research Council, 1999, GROUNDW SOIL CLEAN I; National Research Council, 1994, ALT GROUNDW CLEAN; NILSSON NJ, 1995, AI MAG, V16, P9; Principe JC, 1999, NEURAL ADAPTIVE SYST; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinn J. J., 2001, International Journal of Phytoremediation, V3, P41, DOI 10.1080/15226510108500049; Reed P, 2000, WATER RESOUR RES, V36, P3731, DOI 10.1029/2000WR900232; Reed P., 2001, J HYDROINFORM, V3, P71; Reed PM, 2004, J WATER RES PL-ASCE, V130, P140, DOI 10.1061/(ASCE)0733-9496(2004)130:2(140); Tcheng D., 1989, P 11 INT JOINT C ART, P806; WELGE M, 2003, DATA KNOWLEDGE D2K; *NAT RES COUNC, 2003, ENV REM NAV FAC AD S; *TEMPL U, 1995, BUILD CLASS MOD ID3; *US DOE, 2001, DOEEM0653 OFF ENV MA	28	1	1	AMER GEOPHYSICAL UNION	WASHINGTON	2000 FLORIDA AVE NW, WASHINGTON, DC 20009 USA	0043-1397		WATER RESOUR RES	Water Resour. Res.	MAR 26	2005	41	3							W03020	10.1029/2003WR002802		14	Environmental Sciences; Limnology; Water Resources	Environmental Sciences & Ecology; Marine & Freshwater Biology; Water Resources	913MZ	WOS:000228157200001	
J	Levner, I				Levner, I			Feature selection and nearest centroid classification for protein mass spectrometry	BMC BIOINFORMATICS			English	Article							PROTEOMIC PATTERNS; PROSTATE-CANCER; OVARIAN-CANCER; SERUM	Background: The use of mass spectrometry as a proteomics tool is poised to revolutionize early disease diagnosis and biomarker identification. Unfortunately, before standard supervised classification algorithms can be employed, the "curse of dimensionality" needs to be solved. Due to the sheer amount of information contained within the mass spectra, most standard machine learning techniques cannot be directly applied. Instead, feature selection techniques are used to first reduce the dimensionality of the input space and thus enable the subsequent use of classification algorithms. This paper examines feature selection techniques for proteomic mass spectrometry. Results: This study examines the performance of the nearest centroid classifier coupled with the following feature selection algorithms. Student-t test, Kolmogorov-Smirnov test, and the P-test are univariate statistics used for filter-based feature ranking. From the wrapper approaches we tested sequential forward selection and a modified version of sequential backward selection. Embedded approaches included shrunken nearest centroid and a novel version of boosting based feature selection we developed. In addition, we tested several dimensionality reduction approaches, namely principal component analysis and principal component analysis coupled with linear discriminant analysis. To fairly assess each algorithm, evaluation was done using stratified cross validation with an internal leave-one-out cross-validation loop for automated feature selection. Comprehensive experiments, conducted on five popular cancer data sets, revealed that the less advocated sequential forward selection and boosted feature selection algorithms produce the most consistent results across all data sets. In contrast, the state-of-the-art performance reported on isolated data sets for several of the studied algorithms, does not hold across all data sets. Conclusion: This study tested a number of popular feature selection methods using the nearest centroid classifier and found that several reportedly state-of-the-art algorithms in fact perform rather poorly when tested via stratified cross-validation. The revealed inconsistencies provide clear evidence that algorithm evaluation should be performed on several data sets using a consistent (i.e., non-randomized, stratified) cross-validation procedure in order for the conclusions to be statistically sound.	Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2M7, Canada	Levner, I (reprint author), Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2M7, Canada.	ilya@cs.ualberta.ca					Adam BL, 2002, CANCER RES, V62, P3609; BAGGERLY KA, 2004, BIOINFORMATICS, V4; Baggerly KA, 2003, PROTEOMICS, V3, P1667, DOI 10.1002/pmic.200300522; Conrods TP, 2003, EXPERT REV MOL DIAGN, V3, P411, DOI 10.1586/14737159.3.4.411; COTTER RJ, 1994, TIME OF FLIGHT MASS; DIAMANDIS E, 2003, CLIN CHEM POINT COUN, V48, P1272; Duda R.O, 1973, PATTERN CLASSIFICATI; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Hastie T., 2001, SPRINGER SERIES STAT; Inza I, 2004, ARTIF INTELL MED, V31, P91, DOI 10.1016/j.artmed.2004.01.007; Jeffries N.O., 2004, BMC BIOINFORMATICS, V5; JOHANN D, 2003, CLIN PROTEOMICS PROG; Kirby M., 2001, GEOMETRIC DATA ANAL; Lam W, 2002, PATTERN RECOGN, V35, P1491, DOI 10.1016/S0031-3203(01)00131-5; LEVNER I, 2004, TR0410 U ALB; LEVNER I, 2005, IN PRESS FEATURE EXC; LILIEN RH, 2003, COMPUTATIONAL BIOL, V10; Park H., 2003, BIT, V43, P1; Petricoin EF, 2002, J NATL CANCER I, V94, P1576; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Press W. H., 2002, NUMERICAL RECIPES C; Qu YS, 2002, CLIN CHEM, V48, P1835; SCHAPIRE ER, 1999, IJCAI, P1401; Sorace JM, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-24; THOMAS G, 1998, NEURAL COMPUTATIONAL, V10, P1895; TIBSHIRANI R, 2004, BIOINFORMATICS; Tibshirani R, 2003, STAT SCI, V18, P104, DOI 10.1214/ss/1056397488; VIOLA P, 2003, INT J COMPUTER VISIO; WAGNER MD, 2004, BMC BIOINFORMATICS, V5; WU B, 2003, BIOINFORMATICS, V19; Wulfkuhle JD, 2003, NAT REV CANCER, V3, P267, DOI 10.1038/nrc.1043	31	58	62	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	MAR 23	2005	6								68	10.1186/1471-2105-6-68		14	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	913PY	WOS:000228166500001	
J	Firth, L; Hazelton, ML; Campbell, EP				Firth, L; Hazelton, ML; Campbell, EP			Predicting the onset of Australian winter rainfall by nonlinear classification	JOURNAL OF CLIMATE			English	Article							SOUTHERN OSCILLATION; TEMPERATURE	A method for predicting the timing of winter rains is presented, making no assumptions about the functional form of any relationships that may exist. Ideas built on classification and regression trees and machine learning are used to develop robust predictive rules. These methods are applied in a case study to predict the timing of winter rain in five farming towns in the southwest of Western Australia. The variables used to construct the model are mean monthly sea Surface temperatures (SSTs) over a 72-cell grid in the Indian Ocean, Perth monthly mean sea level pressure (MSLP), and monthly values of the Southern Oscillation index (SOI). A predictive model is constructed from data over the period 1949-99. This model correctly classifies the onset of the winter rains approximately 80% of the time with SST variables proving to be the most important in deriving the predictions. Further analysis indicates a change point in the mid-1970s, a well-known phenomenon in the region. The prediction rates are significantly worse after 1975. Furthermore. the important region of the Indian Ocean, in terms of SSTs for prediction, moves from the Tropics down toward the Southern Ocean after this date.	Data Anal Australia, Perth, WA, Australia; Univ Western Australia, Perth, WA 6009, Australia; CSIRO, Perth, WA, Australia	Hazelton, ML (reprint author), Univ Western Australia, Sch Math & Stat, M019,35 Stirling Highway, Crawley, WA 6009, Australia.	martin@maths.uwa.edu.au	Campbell, Eddy/F-1509-2010				Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BREIMAN L, MANUAL SETTING UP US; Breiman L., 1996, OUT BAG ESTIMATION; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, ANN STAT, V24, P2350; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; CAMPBELL E, 2000, UNDERSTANDING CLIMAT, P179; DIETTERICH TG, MACHINE LEARNING BIA; Drosdowsky W, 2001, J CLIMATE, V14, P1677, DOI 10.1175/1520-0442(2001)014<1677:NACNGS>2.0.CO;2; Efron B., 1993, INTRO BOOTSTRAP; GOWER J, 1998, ENCY BIOSTATISTICS, V1, P656; GRAF HF, 2001, 330 MAX PLANCK I MET; Hastie T, 2001, ELEMENTS STAT LEARNI; Huntley D., 2000, CLIN PSYCHOL, V53, P3; Ihaka R, 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; IOCI, 2002, CLIM VAR CHANG S W W; MCBRIDE JL, 1983, MON WEATHER REV, V111, P1998, DOI 10.1175/1520-0493(1983)111<1998:SRBARA>2.0.CO;2; NICHOLLS N, 1984, J CLIMATOL, V4, P425; Nicholls N, 1989, J CLIMATE, V2, P965, DOI 10.1175/1520-0442(1989)002<0965:SSTAAW>2.0.CO;2; NICHOLLS N, 2000, UNDERSTANDING CLIMAT, P1; NICHOLLS N, 1985, J CLIMATOL, V5, P553; NICHOLLS N, 1991, VEGETATIO, V91, P23, DOI 10.1007/BF00036045; Palmer TN, 1999, J CLIMATE, V12, P575, DOI 10.1175/1520-0442(1999)012<0575:ANDPOC>2.0.CO;2; ROBERTSON G, 2001, DIRECTOR GENERALS OV; White WB, 1996, NATURE, V380, P699, DOI 10.1038/380699a0	26	5	5	AMER METEOROLOGICAL SOC	BOSTON	45 BEACON ST, BOSTON, MA 02108-3693 USA	0894-8755		J CLIMATE	J. Clim.	MAR 15	2005	18	6					772	781		10.1175/JCLI-3291.1		10	Meteorology & Atmospheric Sciences	Meteorology & Atmospheric Sciences	911NZ	WOS:000228012600002	
J	Torney, DC				Torney, DC			Bayesian analysis of binary sequences	JOURNAL OF COMPUTATIONAL AND APPLIED MATHEMATICS			English	Article						concave; convex; cut polytope; geometric probability; Laplace approximation; machine learning; moments; nonlinear optimization; polytope; posterior likelihoods; probability monomials; quadratic program; semidefinite	POLYTOPE; VOLUME	This manuscript details Bayesian methodology for "learning by example", with binary n-sequences encoding the objects under consideration. Priors prove influential; conformable priors are described. Laplace approximation of Bayes integrals yields posterior likelihoods for all n-sequences. This involves the optimization of a definite function over a convex domain-efficiently effectuated by the sequential application of the quadratic program.. (C) 2004 Elsevier B.V. All rights reserved.	Los Alamos Natl Lab, Los Alamos, NM 87545 USA	Torney, DC (reprint author), Los Alamos Natl Lab, T-10,MS K710, Los Alamos, NM 87545 USA.	dtorney@earthlink.net					Abramowitz M., 1964, HDB MATH FUNCTIONS; Bahadur R.R., 1961, STUDIES ITEM ANAL PR, P158; BARVINOK AI, 1993, DISCRETE COMPUT GEOM, V10, P123, DOI 10.1007/BF02573970; BERGER JO, 1988, AM SCI, V76, P159; Bruno W., 1999, ANN COMBIN, V3, P13, DOI 10.1007/BF01609871; Copson E. T., 1965, ASYMPTOTIC EXPANSION; Coxeter H. S. M., 1973, REGULAR POLYTOPES; DEZA M, 1993, DISCRETE MATH, V119, P49, DOI 10.1016/0012-365X(93)90116-B; Gantmacher F.R., 1977, THEORY MATRICES; GRUNBAUM B, 1967, CONVEZ POLYTOPES; HARDY GH, 1952, PURE MATH, P285; HAZEWINKEL M, 1989, ENCY MATH, V4, P293; HIEBERT KL, 1980, SIAM J NUMER ANAL, V17, P447, DOI 10.1137/0717038; Lasserre JB, 1998, P AM MATH SOC, V126, P2433, DOI 10.1090/S0002-9939-98-04454-2; LAWRENCE J, 1991, MATH COMPUT, V57, P259, DOI 10.2307/2938672; LAZARSFELD PF, 1961, STUDIES ITEM ANAL PR, P111; POLYAK E, 1997, APPL MATH SCI, V124, P30; POWELL MJD, 1983, DAMTP1983NA17; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; ROCKAFELLAR R, 1970, CONVES ANAL; SCHITTKOWSKI K, 1991, FORTRAN COMPUTER ALG; SPINDLER K, 1994, ABSTR ALGEBRA APPL; Torney DC, 2000, ADV APPL MATH, V25, P34, DOI 10.1006/aama.2000.0692; Ziegler G., 1995, LECT POLYTOPES, V152	24	1	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0377-0427		J COMPUT APPL MATH	J. Comput. Appl. Math.	MAR 15	2005	175	2					231	243		10.1016/j.cam.2004.05.010		13	Mathematics, Applied	Mathematics	881WF	WOS:000225899400003	
J	Adie, EA; Adams, RR; Evans, KL; Porteous, DJ; Pickard, BS				Adie, EA; Adams, RR; Evans, KL; Porteous, DJ; Pickard, BS			Speeding disease gene discovery by sequence based candidate prioritization	BMC BIOINFORMATICS			English	Article							DATABASE; IDENTIFICATION; ASSOCIATION; ANNOTATION; DISORDERS; GENOMES; LENGTH; ERRORS	Background: Regions of interest identified through genetic linkage studies regularly exceed 30 centimorgans in size and can contain hundreds of genes. Traditionally this number is reduced by matching functional annotation to knowledge of the disease or phenotype in question. However, here we show that disease genes share patterns of sequence- based features that can provide a good basis for automatic prioritization of candidates by machine learning. Results: We examined a variety of sequence- based features and found that for many of them there are significant differences between the sets of genes known to be involved in human hereditary disease and those not known to be involved in disease. We have created an automatic classifier called PROSPECTR based on those features using the alternating decision tree algorithm which ranks genes in the order of likelihood of involvement in disease. On average, PROSPECTR enriches lists for disease genes two-fold 77% of the time, five-fold 37% of the time and twenty-fold 11% of the time. Conclusion: PROSPECTR is a simple and effective way to identify genes involved in Mendelian and oligogenic disorders. It performs markedly better than the single existing sequence- based classifier on novel data. PROSPECTR could save investigators looking at large regions of interest time and effort by prioritizing positional candidate genes for mutation detection and case-control association studies.	Univ Edinburgh, Dept Med Sci, Med Genet Sect, Edinburgh, Midlothian, Scotland	Adie, EA (reprint author), Univ Edinburgh, Dept Med Sci, Med Genet Sect, Edinburgh, Midlothian, Scotland.	euan.adie@ed.ac.uk; richard.adams@ed.ac.uk; kathy.evans@ed.ac.uk; porteous@ed.ac.uk; ben.pickard@ed.ac.uk	Adie, Euan/B-2805-2008; Evans, Kathryn /I-5910-2012; Porteous, David/C-7289-2013	Porteous, David/0000-0003-1249-6106			Becker KG, 2004, NAT GENET, V36, P431, DOI 10.1038/ng0504-431; Chiaromonte F, 2003, GENOME RES, V13, P2602, DOI 10.1101/gr.1169203; Devos D, 2001, TRENDS GENET, V17, P429, DOI 10.1016/S0168-9525(01)02348-4; FORBES AD, 1995, J CLIN MONITOR, V11, P189, DOI 10.1007/BF01617722; FRANK E, 2004, BIOINFORMATICS, P261; FREUDENBERG J, 2002, BIOINFORMATICS, V18, P1105; FREUND Y, P 16 INT C MACH LEAR, P124; GARDINERGARDEN M, 1987, J MOL BIOL, V196, P261, DOI 10.1016/0022-2836(87)90689-9; Gilks WR, 2002, BIOINFORMATICS, V18, P1641, DOI 10.1093/bioinformatics/18.12.1641; Glazier AM, 2002, SCIENCE, V298, P2345, DOI 10.1126/science.1076641; Hammond MP, 2004, TRENDS GENET, V20, P268, DOI 10.1016/j.tig.2004.04.002; Hamosh A, 2002, NUCLEIC ACIDS RES, V30, P52, DOI 10.1093/nar/30.1.52; Huang H, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-7-r47; Kapetanovic IM, 2004, ANN NY ACAD SCI, V1020, P10, DOI 10.1196/annals.1310.003; Karlin S, 2002, P NATL ACAD SCI USA, V99, P17008, DOI 10.1073/pnas.262658799; Lopez-Bigas N, 2004, NUCLEIC ACIDS RES, V32, P3108, DOI 10.1093/nar/gkh605; McCarthy MI, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-10-119; Mulder NJ, 2003, NUCLEIC ACIDS RES, V31, P315, DOI 10.1093/nar/gkg046; Pallen M, 1999, MOL MICROBIOL, V34, P195, DOI 10.1046/j.1365-2958.1999.01561.x; Perez-Iratxeta C, 2002, NAT GENET, V31, P316, DOI 10.1038/ng895; Smith NGC, 2003, GENE, V318, P169, DOI 10.1016/S0378-1119(03)00772-8; Stenson PD, 2003, HUM MUTAT, V21, P577, DOI 10.1002/humu.10212; Su AI, 2002, P NATL ACAD SCI USA, V99, P4465, DOI 10.1073/pnas.012025199; Tanguay RL, 1996, MOL CELL BIOL, V16, P146; Turner FS, 2003, GENOME BIOL, V4; van Driel MA, 2003, EUR J HUM GENET, V11, P57, DOI 10.1038/sj.ejhg.5200918; Winter EE, 2004, GENOME RES, V14, P54, DOI 10.1101/gr.1924004	27	102	108	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	MAR 14	2005	6								55	10.1186/1471-2105-6-55		13	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	913PR	WOS:000228165800001	
J	Gastreich, M; Liao, J; Hessler, G; Pfeiffer-Marek, S; Hindle, SA; Warmuth, M; Lemmen, C; Naumann, T; Baringhaus, KH				Gastreich, M; Liao, J; Hessler, G; Pfeiffer-Marek, S; Hindle, SA; Warmuth, M; Lemmen, C; Naumann, T; Baringhaus, KH			Boosting descriptors for similarity searches: Feature trees trained by machine learning.	ABSTRACTS OF PAPERS OF THE AMERICAN CHEMICAL SOCIETY			English	Meeting Abstract	229th National Meeting of the American-Chemical-Society	MAR 13-17, 2005	San Diego, CA	Amer Chem Soc					BioSolveIT GmbH, D-53757 St Augustin, Germany; Univ Calif Santa Cruz, Dept Comp Sci, Santa Cruz, CA 95064 USA		marcus.gastreich@biosolveit.de						0	0	0	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0065-7727		ABSTR PAP AM CHEM S	Abstr. Pap. Am. Chem. Soc.	MAR 13	2005	229		1			083-CINF	U609	U609				1	Chemistry, Multidisciplinary	Chemistry	913TZ	WOS:000228177704082	
J	Pal, M; Mather, PM				Pal, M; Mather, PM			Support vector machines for classification in remote sensing	INTERNATIONAL JOURNAL OF REMOTE SENSING			English	Article								Support vector machines (SVM) represent a promising development in machine learning research that is not widely used within the remote sensing community. This paper reports the results of two experiments in which multi-class SVMs are compared with maximum likelihood (ML) and artificial neural network (ANN) methods in terms of classification accuracy. The two land cover classification experiments use multispectral (Landsat-7 ETM+) and hyperspectral (DAIS) data, respectively, for test areas in eastern England and central Spain. Our results show that the SVM achieves a higher level of classification accuracy than either the ML or the ANN classifier, and that the SVM can be used with small training datasets and high-dimensional data.	Univ Nottingham, Sch Geog, Nottingham NG7 2RD, England	Pal, M (reprint author), Univ Nottingham, Sch Geog, Nottingham NG7 2RD, England.						BENEDIKTSSON JA, 1990, IEEE T GEOSCI REMOTE, V28, P540, DOI 10.1109/TGRS.1990.572944; Boser B, 1992, P 5 ANN WORKSH COMP, P144, DOI DOI 10.1145/130385.130401; Chang C.-C., 2001, LIBSVM LIB SUPP VECT; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; FOODY GM, 1995, INT J REMOTE SENS, V16, P1707; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Huang C, 2002, INT J REMOTE SENS, V23, P725, DOI 10.1080/01431160110040323; HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102; KAVZOGLU T, 2001, THESIS SCH GEOGRAPHY; Knerr S., 1990, Neurocomputing, Algorithms, Architectures and Applications. Proceedings of the NATO Advanced Research Workshop; SAUNDERS C, 1998, CSDTR9803 ROYAL HOLL; Tso B., 2001, CLASSIFICATION METHO; Vapnik V. N, 1995, NATURE STAT LEARNING; Zhu GB, 2002, REMOTE SENS ENVIRON, V80, P233, DOI 10.1016/S0034-4257(01)00305-4	14	115	130	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0143-1161		INT J REMOTE SENS	Int. J. Remote Sens.	MAR 10	2005	26	5					1007	1011		10.1080/01431160512331314083		5	Remote Sensing; Imaging Science & Photographic Technology	Remote Sensing; Imaging Science & Photographic Technology	895LJ	WOS:000226864100013	
J	Li, X; Morie, P; Roth, D				Li, X; Morie, P; Roth, D			Semantic integration in text - From ambiguous names to identifiable entities	AI MAGAZINE			English	Article								Semantic integration focuses on discovering, representing, and manipulating correspondences between entities in disparate data sources. The topic has been widely studied in the context of structured data, with problems being considered including ontology and schema matching, matching relational tuples, and reconciling inconsistent data values. In recent years, however, semantic integration over text has also received increasing attention. This article studies a key challenge in semantic integration over text: identifying whether different mentions of real-world entities, such as "JFK" and "John Kennedy," within and across natural language text documents, actually represent the same concept. We present a machine-learning study of this problem. The first approach is a discriminative approach-a pairwise local classifier is trained in a supervised way to determine whether two given mentions represent the same real-world entity. This is followed, potentially, by a global clustering algorithm that uses the classifier as its similarity metric. Our second approach is a global generative model, at the heart of which is a view on how documents are generated and how names (of different entity types) are "sprinkled" into them. In its most general form, our model assumes (1) a joint distribution over entities (for example, a document that mentions "President Kennedy" is more likely to mention "Oswald" or "White House" than "Roger Clemens"), and (2) an "author" model that assumes that at least one mention of an entity in a document is easily identifiable and then generates other mentions via (3) an "appearance" model that governs how mentions are transformed from the "representative" men Lion. We show that both approaches perform very accurately, in the range of 90-95 percent. F-1 measure for different entity types, much better than previous approaches to some aspects of this problem. Finally, we discuss how our solution for mention matching in text can be potentially applied to matching relational tuples, as well as to linking entities across databases and text.	Univ Illinois, Cogcomp Computat Grp, Dept Comp Sci, Urbana, IL 61801 USA; Univ Illinois, Beckman Inst, Urbana, IL 61801 USA; Univ Illinois, Coll Engn, Urbana, IL 61801 USA	Li, X (reprint author), Univ Illinois, Cogcomp Computat Grp, Dept Comp Sci, Urbana, IL 61801 USA.	xli1@cs.uiuc.edu; morie@cs.uiuc.edu					ANDRITSOS P, 2004, P ACM SIGMOD INT C M; Bagga A., 1998, P 36 ANN M ASS COMP, P79; Bilenko M., 2003, P 9 ACM SIGKDD INT C; CARLSON AJ, 1999, UIUCDCSR992101; COHEN W, 2003, IJCAI 03 WORKSH INF; Cohen W.W., 2002, P 8 ACM SIGKDD INT C; CULOTTA A, 2004, 1 C EM ANT CEAS 2004; DHAMANKAR R, 2004, P ACM SIGMOD INT C M; Doan A, 2003, IEEE INTELL SYST, V18, P54; DOAN AH, 2001, P ACM SIGMOD INT C M; DONG X, 2004, VLDB 2 WORKSH INF IN; GOOI C, 2004, P HUM LANG TECHN C N; Hernandez M., 1995, P 1995 ACM SIGMOD IN, P127, DOI 10.1145/223784.223807; Jain A.K., 1988, ALGORITHMS CLUSTERIN; JONES W, 2004, INF RETR DAT SYN SYN; Kehler A., 2002, COHERENCE REFERENCE; LI X, 2004, P 19 NAT C ART INT M; LI X, 2004, P HUM LANG TECHN C N; MADHAVAN J, 2001, P INT C VER LARG DAT; MANN G, 2003, P C COMP NAT LANG LE; MCCALLUM A, 2003, IJCAI 03 WORKSH INF; Moldovan D., 2002, P 40 ANN M ASS COMP, P33; Ng V, 2002, P 40 ANN M ASS COMP; OUKSEL A, 1999, SIGMOD RECORD, V28; PASULA H, 2002, ADV NEURAL INFORMATI; Rahm E, 2001, VLDB J, V10, P334, DOI 10.1007/s007780100057; ROTH D, 2002, P 11 TEXT RETR C NIS, P592; ROTH D, 2001, P 17 INT JOINT C ART, P1257; Soon WM, 2001, COMPUT LINGUIST, V27, P521, DOI 10.1162/089120101753342653; TEJADA S, 2002, P 8 SIGKDD INT C KNO; Voorhees E. M., 2002, P TREC, P115	31	11	12	AMER ASSOC ARTIFICIAL INTELL	MENLO PK	445 BURGESS DRIVE, MENLO PK, CA 94025-3496 USA	0738-4602		AI MAG	AI Mag.	SPR	2005	26	1					45	58				14	Computer Science, Artificial Intelligence	Computer Science	910JX	WOS:000227928500005	
J	Mani, S; Valtorta, M; McDermott, S				Mani, S; Valtorta, M; McDermott, S			Building Bayesian network models in medicine: The MENTOR experience	APPLIED INTELLIGENCE			English	Article						Bayesian networks; machine learning; artificial intelligence in medicine	EXPERT-SYSTEMS; RETARDATION	An experiment in Bayesian model building from a large medical dataset for Mental Retardation is discussed in this paper. We give a step by step description of the practical aspects of building a Bayesian Network from a dataset. We enumerate and briefly describe the tools required, address the problem of missing values in big datasets resulting from incomplete clinical findings and elaborate on our solution to the problem. We advance some reasons why imputation is a more desirable approach for model building than some other ad hoc methods suggested in literature. In our experiment, the initial Bayesian Network is learned from a dataset using, a machine learning program called CB. The network structure and the conditional probabilities are then modified under the guidance of a domain expert. We present validation results for the unmodified and modified networks and give some suggestions for improvement of the model.	Univ Wisconsin, Dept Elect Engn & Comp Sci, Milwaukee, WI 53201 USA; Univ S Carolina, Dept Comp Sci & Engn, Columbia, SC 29208 USA; Univ S Carolina, Dept Family & Prevent Med, Columbia, SC 29208 USA	Mani, S (reprint author), Univ Wisconsin, Dept Elect Engn & Comp Sci, Milwaukee, WI 53201 USA.	mgv@cse.se.edu					Andersen S., 1989, P 11 INT JOINT C ART, P1080; Andreassen S, 1987, P 10 INT JOINT C ART, P366; BATSHAW ML, 1993, PEDIATR CLIN N AM, V40, P507; CHARNIAK E, 1991, AI MAG, V12, P50; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; Cowell R. G., 1999, PROBABILISTIC NETWOR; Friedman N., 1998, P 14 C UNC ART INT, P129; Jensen F., 1996, INTRO BAYESIAN NETWO; JENSEN F, 2001, BAYESIAN NETWORKS DE; LAURITZEN SL, 1993, 4 INT WORKSH ART INT, P93; LAURITZEN SL, IN PRESS J ROYAL S B; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; Mani S, 1997, RES DEV DISABIL, V18, P303, DOI 10.1016/S0891-4222(97)00012-7; MAUSNER J, 1985, EPIDEMIOLOGY INTRO T, pCH7; McDermott S, 1993, Paediatr Perinat Epidemiol, V7, P195, DOI 10.1111/j.1365-3016.1993.tb00393.x; MONTI S, 1999, P 7 INT WORKSH ART I; Murphy P. M., UCI REPOSITORY MACHI; Neapolitan R. E., 1990, PROBABILISTIC REASON; Neapolitan R.E., 2004, LEARNING BAYESIAN NE; Pearl J, 2000, CAUSALITY MODELS REA; Pearl J., 1988, PROBABILISTIC REASON; PEARL J, 1991, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING, P441; PROVAN G, LECT NOTES STAT, V112, P291; Russell S., 1995, ARTIFICIAL INTELLIGE; Singh M., 1993, P 9 C UNC ART INT, P259; SINGH M, 1995, INT J APPROX REASON, V12, P111, DOI 10.1016/0888-613X(94)00016-V; SPIEGELHALTER DJ, 1993, STAT SCI, V8, P219, DOI 10.1214/ss/1177010888; Spirtes P, 2000, CAUSATION PREDICTION; STEIN ZA, 1992, PUBLIC HLTH PREVENTI; Weiss S. M., 1991, COMPUTER SYSTEMS LEA; XIA B, 2002, THESIS U S CAROLINA; Zytkow J. M., 1991, Knowledge discovery in databases; *AM ASS MENT RET, 1992, MENT RET; *U CA BERK SCH PUB, 1987, DAT ARCH US MAN CHIL, V2; *U CA BERK SCH PUB, 1987, DAT ARCH US MAN CHIL, V1	35	6	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-669X		APPL INTELL	Appl. Intell.	MAR-APR	2005	22	2					93	108		10.1007/s10489-005-5599-3		16	Computer Science, Artificial Intelligence	Computer Science	901JQ	WOS:000227279200002	
J	Zhou, ZH; Jiang, K; Li, M				Zhou, ZH; Jiang, K; Li, M			Multi-instance learning based web mining	APPLIED INTELLIGENCE			English	Article						machine learning; data mining; multi-instance learning; web mining; web index recommendation; text categorization	RECTANGLES; EXAMPLES	In multi-instance learning, the training set comprises labeled bags that are composed of unlabeled instances, and the task is to predict the labels of unseen bags. In this paper, a web mining problem, i.e. web index recommendation, is investigated from a multi-instance view. In detail, each web index page is regarded as a bag while each of its linked pages is regarded as an instance. A user favoring an index page means that he or she is interested in at least one page linked by the index. Based on the browsing history of the user, recommendation could be provided for unseen index pages. An algorithm named Fretcit-kNN, which employs the Minimal Hausdorff distance between frequent term sets and utilizes both the references and citers of an unseen bag in determining its label, is proposed to solve the problem. Experiments show that in average the recommendation accuracy of Fretcit-kNN is 81.0% with 71.7% recall and 70.9% precision, which is significantly better than the best algorithm that does not consider the specific characteristics of multi-instance learning, whose performance is 76.3% accuracy with 63.4% recall and 66.1% precision.	Nanjing Univ, Natl Lab Novel Software Technol, Nanjing 210093, Peoples R China	Zhou, ZH (reprint author), Nanjing Univ, Natl Lab Novel Software Technol, Nanjing 210093, Peoples R China.	zhouzh@nju.edu.cn					Aha DW, 1997, ARTIF INTELL REV, V11, P7, DOI 10.1023/A:1006538427943; Amar R. A., 2001, P 18 INT C MACH LEAR, P3; Auer P, 1998, J COMPUT SYST SCI, V57, P376, DOI 10.1006/jcss.1998.1593; Auer P., 1997, P 14 INT C MACH LEAR, P21; Blum A, 1998, MACH LEARN, V30, P23, DOI 10.1023/A:1007402410823; Chevaleyre YZ, 2001, LECT NOTES ARTIF INT, V2056, P204; Dasarathy BV, 1991, NEAREST NEIGHBOR NOR; De Raedt L., 1998, LECT NOTES ARTIF INT, V1446, P1; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; DIETTERICH TG, 1994, ADV NEURAL INFORMATI, V6, P216; Edgar G. A., 1990, MEASURE TOPOLOGY FRA; Joachims T., 1997, P 14 INT C MACH LEAR, P143; Long PM, 1998, MACH LEARN, V30, P7, DOI 10.1023/A:1007450326753; Maron O., 1998, THESIS MIT; Maron O, 1998, P 15 INT C MACH LEAR, P341; Maron O, 1998, ADV NEUR IN, V10, P570; Ray S, 2001, P 18 INT C MACH LEAR, P425; Ruffo G., 2000, THESIS U TURIN TORIN; Wang J., 2000, P 17 INT C MACH LEAR, P1119; Yang C., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), DOI 10.1109/ICDE.2000.839416; Zhang Q, 2002, ADV NEUR IN, V14, P1073; Zhang Q., 2002, P 19 INT C MACH LEAR, P682; Zhou ZH, 2003, LECT NOTES ARTIF INT, V2837, P492; Zhou Z.-H., 2002, NEURAL NETWORKS MULT; ZUCKER JD, 1998, LECT NOTES ARTIF INT, V1446, P235; ZUCKER JD, 1996, P 13 INT C MACH LEAR, P543	26	33	38	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-669X		APPL INTELL	Appl. Intell.	MAR-APR	2005	22	2					135	147		10.1007/s10489-005-5602-z		13	Computer Science, Artificial Intelligence	Computer Science	901JQ	WOS:000227279200005	
J	Markovitch, S; Reger, R				Markovitch, S; Reger, R			Learning and exploiting relative weaknesses of opponent agents	AUTONOMOUS AGENTS AND MULTI-AGENT SYSTEMS			English	Article						opponent modelling; multi-agent systems; machine learning	MODEL SEARCH; POTENTIAL APPLICATIONS; STRATEGIES; PATHOLOGY	Agents in a competitive interaction can greatly benefit from adapting to a particular adversary, rather than using the same general strategy against all opponents. One method of such adaptation is Opponent Modeling, in which a model of an opponent is acquired and utilized as part of the agent's decision procedure in future interactions with this opponent. However, acquiring an accurate model of a complex opponent strategy may be computationally infeasible. In addition, if the learned model is not accurate, then using it to predict the opponent's actions may potentially harm the agent's strategy rather than improving it. We thus define the concept of opponent weakness, and present a method for learning a model of this simpler concept. We analyze examples of past behavior of an opponent in a particular domain, judging its actions using a trusted judge. We then infer a weakness model based on the opponent's actions relative to the domain state, and incorporate this model into our agent's decision procedure. We also make use of a similar self-weakness model, allowing the agent to prefer states in which the opponent is weak and our agent strong; where we have a relative advantage over the opponent. Experimental results spanning two different test domains demonstrate the agents' improved performance when making use of the weakness models.	Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Markovitch, S (reprint author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	shaulm@cs.technion.ac.il; ronitr@cs.technion.ac.il					ALLIS Y, 1988, THESIS VRIJE U AMSTE; ANGLUIN D, 1978, INFORM CONTROL, V39, P337, DOI 10.1016/S0019-9958(78)90683-6; ATKESON C, 1997, COMP DIRECT MODEL BA; Billings D., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; BRUCE J, 2002, P IROS 2002 WORKSH C; CARMEL D, 1996, CIS9609 TECHN; CARMEL D, P 13 NAT C ART INT P, P120; CARMEL D, 1993, P AAAI FALL S GAM PL; Carmel D, 1998, J EXP THEOR ARTIF IN, V10, P309, DOI 10.1080/095281398146789; Carmel D., 1999, Autonomous Agents and Multi-Agent Systems, V2, DOI 10.1023/A:1010007108196; Carmel D, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P62; Donkers HHLM, 2001, INFORM SCIENCES, V135, P123, DOI 10.1016/S0020-0255(01)00133-5; Freund Y., 1995, Proceedings. 36th Annual Symposium on Foundations of Computer Science (Cat. No.95CB35834), DOI 10.1109/SFCS.1995.492489; GAO X, 1997, P JSSST 14 C SHIK JA, P229; Gao XB, 2001, THEOR COMPUT SCI, V252, P83, DOI 10.1016/S0304-3975(00)00077-3; Gao XB, 1999, LECT NOTES COMPUT SC, V1558, P74; Gmytrasiewicz PJ, 1998, USER MODEL USER-ADAP, V8, P49, DOI 10.1023/A:1008269427670; GMYTRASIEWICZ PJ, 1995, P 1 INT C MULT SYST; Hsu F., 1990, COMPUTERS CHESS COGN, P55; Hu YJ, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P806; IIDA H, 1993, ICCA J, V16, P201; IIDA H, 1994, ICCA J, V17, P10; JANSEN PJ, 1992, THESIS CARNEGIEMELLO; JUNGHANNS A, 1997, P 15 INT JOINT C ART, P692; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237; Littman M. L., 1994, P 11 INT C MACH LEAR, P157; MARKOVITCH S, 2001, MACH LEARN, V49, P59; Markovitch S, 1996, COMPUT INTELL, V12, P88, DOI 10.1111/j.1467-8640.1996.tb00254.x; Matheus C.J., 1989, P 11 INT JOINT C ART, P645; MOORE AW, 1993, MACH LEARN, V13, P103, DOI 10.1023/A:1022635613229; MOR Y, 1996, LECT NOTES ARTIFICIA, V1042; NAU DS, 1980, P ACM NAT C ART INT, P102; NAU DS, 1982, ARTIF INTELL, V19, P257, DOI 10.1016/0004-3702(82)90002-9; PAGALLO G, 1990, MACH LEARN, V5, P71, DOI 10.1023/A:1022611825350; PEARL J, 1983, ARTIF INTELL, V20, P427, DOI 10.1016/0004-3702(83)90004-8; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; REIBMAN AL, 1983, P 3 NAT C ART INT AA, P338; RUSSELL S, 1991, RIGHT THING STUDIES; Sandholm T., 1995, BIOSYSTEMS, V37, P147; Schapire Robert E., 2002, P 19 INT C MACH LEAR; SEN S, 1997, AAAI 97 WORKSH MULT, P59; Sen S, 1999, MULTIAGENT SYSTEMS, P259; SIMON HA, 1982, MODELS BOUNED RATION, V1; Stone P., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); Sutton R. S., 1990, P 7 INT C MACH LEARN, P216; UTHER W, 1997, P AAAI FALL S MOD DI; VIDAL JM, 1995, P 2 INT C MULT SYST; VIDAL JM, 1996, LECT NOTES ARTIF INT, V1037, P171; Watkins C. J., 1989, THESIS U CAMBRIDGE; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698; Weiss G., 1996, LECT NOTES ARTIFICIA, V1042; ZILBERSTEIN S, 1995, P 14 INT JOINT C ART, P1576	52	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1387-2532		AUTON AGENT MULTI-AG	Auton. Agents Multi-Agent Syst.	MAR	2005	10	2					103	130		10.1007/s10458-004-6977-7		28	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	897AT	WOS:000226977100001	
J	Chen, Y; Xu, D				Chen, Y; Xu, D			Understanding protein dispensability through machine-learning analysis of high-throughput data	BIOINFORMATICS			English	Article							SCHIZOSACCHAROMYCES-POMBE; GENE DISPENSABILITY; EVOLUTION; YEAST; NETWORKS; SEQUENCE	Motivation: Protein dispensability is fundamental to the understanding of gene function and evolution. Recent advances in generating high-throughput data such as genomic sequence data, protein-protein interaction data, gene-expression data and growth-rate data of mutants allow us to investigate protein dispensability systematically at the genome scale. Results: In our studies, protein dispensability is represented as a fitness score that is measured by the growth rate of gene-deletion mutants. By the analyses of high-throughput data in yeast Saccharomyces cerevisiae, we found that a protein's dispensability had significant correlations with its evolutionary rate and duplication rate, as well as its connectivity in protein-protein interaction network and gene-expression correlation network. Neural network and support vector machine were applied to predict protein dispensability through high-throughput data. Our studies shed some lights on global characteristics of protein dispensability and evolution.	UT ORNL, Grad Sch Genome Sci & Technol, Oak Ridge, TN 37830 USA; Univ Missouri, Dept Comp Sci, Digital Biol Lab, Columbia, MO USA	Xu, D (reprint author), UT ORNL, Grad Sch Genome Sci & Technol, Oak Ridge, TN 37830 USA.	xudong@missouri.edu					Albert R, 2000, NATURE, V406, P378, DOI 10.1038/35019019; Barabasi AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509; Brown JR, 1996, CELL, V86, P297, DOI 10.1016/S0092-8674(00)80101-4; Brown SDM, 2001, CURR OPIN GENET DEV, V11, P268, DOI 10.1016/S0959-437X(00)00189-1; Decottignies A, 2003, GENOME RES, V13, P399, DOI 10.1101/gr.636103; Gasch AP, 2000, MOL BIOL CELL, V11, P4241; Goffeau A, 1996, SCIENCE, V546, P563; Gu ZL, 2003, NATURE, V421, P63, DOI 10.1038/nature01198; Hastie T, 2001, ELEMENTS STAT LEARNI; Hirsh AE, 2001, NATURE, V411, P1046, DOI 10.1038/35082561; Hurst LD, 1999, CURR BIOL, V9, P747, DOI 10.1016/S0960-9822(99)80334-0; Ito T, 2001, P NATL ACAD SCI USA, V98, P4569, DOI 10.1073/pnas.061034498; Jansen R, 2002, GENOME RES, V12, P37, DOI 10.1101/gr.205602; Jeong H, 2001, NATURE, V411, P41, DOI 10.1038/35075138; Jordan IK, 2003, BMC EVOL BIOL, V3, DOI 10.1186/1471-2148-3-1; JOSHI T, 2004, IN PRESS OMICS; JOSHI T, 2004, P WORLD MULT SYST CY, V9, P17; Krylov DM, 2003, GENOME RES, V13, P2229, DOI 10.1101/gr.1589103; Lawton-Rauh A, 2003, MOL PHYLOGENET EVOL, V29, P396, DOI 10.1016/j.ympev.2003.07.004; Li WH, 1997, MOL EVOLUTION; Mathews B.W., 1975, BIOCHIM BIOPHYS ACTA, V405, P442; OHTA T, 1973, NATURE, V246, P96, DOI 10.1038/246096a0; Ozier O, 2003, NAT BIOTECHNOL, V21, P490, DOI 10.1038/nbt0503-490; Pal C, 2003, NATURE, V421, P496, DOI 10.1038/421496b; Papp B, 2003, NATURE, V424, P194, DOI 10.1038/nature01771; Papp B, 2004, NATURE, V429, P661, DOI 10.1038/nature02636; Pawson T, 2003, SCIENCE, V300, P445, DOI 10.1126/science.1083653; Pearson W R, 2000, Methods Mol Biol, V132, P185; RYDEN LG, 1993, J MOL EVOL, V36, P41, DOI 10.1007/BF02407305; Scholkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565; Steinmetz LM, 2002, NAT GENET, V31, P400, DOI 10.1038/ng929; Tatusov RL, 2000, NUCLEIC ACIDS RES, V28, P33, DOI 10.1093/nar/28.1.33; Thatcher JW, 1998, P NATL ACAD SCI USA, V95, P253, DOI 10.1073/pnas.95.1.253; Tong AHY, 2004, SCIENCE, V303, P808, DOI 10.1126/science.1091317; Tourasse NJ, 2000, MOL BIOL EVOL, V17, P656; Uetz P, 2000, NATURE, V403, P623; Wood V, 2002, NATURE, V415, P871, DOI 10.1038/nature724; ZELL A, 1993, INFORMATIK FACHBERIC, V285, P254	38	25	25	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	MAR 1	2005	21	5					575	581		10.1093/bioinformatics/bti058		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	900VA	WOS:000227241200002	
J	Statnikov, A; Aliferis, CF; Tsamardinos, I; Hardin, D; Levy, S				Statnikov, A; Aliferis, CF; Tsamardinos, I; Hardin, D; Levy, S			A comprehensive evaluation of multicategory classification methods for microarray gene expression cancer diagnosis	BIOINFORMATICS			English	Article							ARTIFICIAL NEURAL-NETWORKS; SUPPORT VECTOR MACHINES; MOLECULAR CLASSIFICATION; PREDICTION; CARCINOMAS; SIGNATURES	Motivation: Cancer diagnosis is one of the most important emerging clinical applications of gene expression microarray technology. We are seeking to develop a computer system for powerful and reliable cancer diagnostic model creation based on microarray data. To keep a realistic perspective on clinical applications we focus on multicategory diagnosis. To equip the system with the optimum combination of classifier, gene selection and cross-validation methods, we performed a systematic and comprehensive evaluation of several major algorithms for multicategory classification, several gene selection methods, multiple ensemble classifier methods and two cross-validation designs using 11 datasets spanning 74 diagnostic categories and 41 cancer types and 12 normal tissue types. Results: Multicategory support vector machines (MC-SVMs) are the most effective classifiers in performing accurate cancer diagnosis from gene expression data. The MC-SVM techniques by Crammer and Singer, Weston and Watkins and one-versus-rest were found to be the best methods in this domain. MC-SVMs outperform other popular machine learning algorithms, such as k-nearest neighbors, backpropagation and probabilistic neural networks, often to a remarkable degree. Gene selection techniques can significantly improve the classification performance of both MC-SVMs and other non-SVM learning algorithms. Ensemble classifiers do not generally improve performance of the best non-ensemble models. These results guided the construction of a software system GEMS (Gene Expression Model Selector) that automates high-quality model construction and enforces sound optimization and performance estimation procedures. This is the first such system to be informed by a rigorous comparative analysis of the available algorithms and datasets.	Vanderbilt Univ, Dept Biomed Informat, Nashville, TN 37240 USA; Vanderbilt Univ, Dept Math, Nashville, TN USA	Statnikov, A (reprint author), Vanderbilt Univ, Dept Biomed Informat, Nashville, TN 37240 USA.	alexander.statnikov@vanderbilt.edu	Hardin, Douglas/C-3386-2013	Hardin, Douglas/0000-0003-0867-2146			Aliferis C. F., 2003, P 2003 AM MED INF AS, P21; ALIFERIS CF, 2003, P 16 INT FLAIRS C, P67; Allwein EL, 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765; BERRAR D, 2003, P PAC S BIOC PSB LIH; Bhattacharjee A, 2001, P NATL ACAD SCI USA, V98, P13790, DOI 10.1073/pnas.191502998; Brown L. E., 2003, P 2003 INT C MATH EN; Chang CC, 2003, LIBSVM LIB SUPPORT V; CORTES C, 1993, ADV NEURAL INFORMATI, P327; CRAMMER K, 2000, P 13 ANN C COMP LEAR; Demuth H., 2001, NEURAL NETWORK TOOLB; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Duda R. O., 2001, PATTERN CLASSIFICATI; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Ferris D, 2003, HARVARD LIBR BULL, V14, P3; Fortina P, 2002, TRENDS MOL MED, V8, P264, DOI 10.1016/S1471-4914(02)02331-6; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; Friedman J, 1996, ANOTHER APPROACH POL; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Good P., 2000, PERMUTATION TESTS PR; GOODMAN PH, 2004, NEVPROP MANUAL INTRO; GUYON I, 2003, ERRATUM GENE SELECTI; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hardin D., 2004, 21 INT C MACH LEARN; Hastie T, 2001, ELEMENTS STAT LEARNI; Herbrich R., 2002, LEARNING KERNEL CLAS; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Joachims T., 1999, ADV KERNEL METHODS S; Jones B, 1997, MATLAB STAT TOOLBOX; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; KRESSEL U, 1999, ADV KERNEL METHODS S, pCH15; Kutin S., 2002, P 18 C UNC ART IND E, P275; Lee Y, 2003, BIOINFORMATICS, V19, P1132, DOI 10.1093/bioinformatics/btg102; Lin CJ, 1999, SIAM J OPTIMIZ, V9, P1100, DOI 10.1137/S1052623498345075; LU J, 2002, METHODS MICROARRAY D, P97; Mitchell T, 1997, MACHINE LEARNING; Mossman D, 1999, MED DECIS MAKING, V19, P78, DOI 10.1177/0272989X9901900110; MUKHERJEE S, 2003, CLASSIFYING MICROARR; Murthy SK, 1998, DATA MIN KNOWL DISC, V2, P345, DOI 10.1023/A:1009744630224; Ntzani EE, 2003, LANCET, V362, P1439, DOI 10.1016/S0140-6736(03)14686-7; Nutt CL, 2003, CANCER RES, V63, P1602; Platt J.C., 1999, ADV KERNEL METHODS S; Platt JC, 2000, ADV NEUR IN, V12, P547; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Reich M, 2004, BIOINFORMATICS, V20, P1797, DOI 10.1093/bioinformatics/bth138; Reunanen J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753715; Romualdi C, 2003, HUM MOL GENET, V12, P823, DOI 10.1093/hmg/ddg093; Schwarzer G, 2000, STAT MED, V19, P541, DOI 10.1002/(SICI)1097-0258(20000229)19:4<541::AID-SIM355>3.3.CO;2-M; Sharkey A. J. C., 1996, Connection Science, V8, DOI 10.1080/095400996116785; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; SINDWANI V, 2001, 1 SIAM INT C DAT MIN; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Staunton JE, 2001, P NATL ACAD SCI USA, V98, P10787, DOI 10.1073/pnas.191368598; Su AI, 2001, CANCER RES, V61, P7388; TSAMARDINOS I, 2003, 9 ACM SIGKDD INT C K; VALENTINI G, 2003, IEEE INNS ENNS INT J; Vapnik VN, 1998, STAT LEARNING THEORY; Weiss S. M., 1991, COMPUTER SYSTEMS LEA; Weston J., 1999, P 7 EUR S ART NEUR N; Wouters L, 2003, BIOMETRICS, V59, P1131, DOI 10.1111/j.0006-341X.2003.00130.x; YEANG C, 2001, P 9 INT C INT SYST M, P316; YEO G, 2001, 2001018 AI	67	270	285	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	MAR 1	2005	21	5					631	643		10.1093/bioinformatics/bti033		13	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	900VA	WOS:000227241200010	
J	Briem, H; Gunther, J				Briem, H; Gunther, J			Classifying "kinase inhibitor-likeness" by using machine-learning methods	CHEMBIOCHEM			English	Article						computer chemistry; drug design; inhibitors; kinases; machine learning	ATOMIC PHYSICOCHEMICAL PARAMETERS; SUPPORT VECTOR MACHINES; PROTEIN-KINASES; DRUG DESIGN; HYDROPHOBIC INTERACTIONS; MEDICINAL CHEMISTRY; CLASSIFICATION; DISCOVERY; TARGETS; NETWORKS	By using an in-house data set of small-molecule structures, encoded by Ghose-Crippen parameters, several machine learning techniques were applied to distinguish between kinase inhibitors and other molecules with no reported activity on any protein kinase. All four approaches pursued-support-vector machines (SVM), artificial neural networks (ANN), k nearest neighbor classification with GA-optimized feature selection (GAANN), and recursive partitioning (RP)-proved capable of providing a reasonable discrimination. Nevertheless, substantial differences in performance among the methods were observed. For all techniques tested, the use of a consensus vote of the 13 different models derived improved the quality of the predictions in terms of accuracy, precision, recall, and F1 value. Support-vector machines, followed by the GA/kNN combination, outperformed the other techniques when comparing the average of individual models. By using the respective majority votes, the prediction of neural networks yielded the highest F1 value, followed by SVMs.	Schering AG, Res Ctr Europe, CDCC Computat Chem, D-13342 Berlin, Germany	Briem, H (reprint author), Schering AG, Res Ctr Europe, CDCC Computat Chem, Muellerstr 178, D-13342 Berlin, Germany.	hans.briem@schering.de					Ajay, 1998, J MED CHEM, V41, P3314, DOI 10.1021/jm970666c; Bleicher KH, 2003, NAT REV DRUG DISCOV, V2, P369, DOI 10.1038/nrd1086; Burbidge R, 2001, COMPUT CHEM, V26, P5, DOI 10.1016/S0097-8485(01)00094-8; Byvatov E, 2003, J CHEM INF COMP SCI, V43, P1882, DOI 10.1021/ci0341161; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Cheek S, 2002, J MOL BIOL, V320, P855, DOI 10.1016/S0022-2836(02)00538-7; Cherry M, 2004, CURR MED CHEM, V11, P663, DOI 10.2174/0929867043455792; Cohen P, 2002, NAT REV DRUG DISCOV, V1, P309, DOI 10.1038/nrd773; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Dean PM, 2001, TRENDS BIOTECHNOL, V19, P288, DOI 10.1016/S0167-7799(01)01696-1; Drevs J, 2003, CURR DRUG TARGETS, V4, P113, DOI 10.2174/1389450033346885; Durant JL, 2002, J CHEM INF COMP SCI, V42, P1273, DOI 10.1021/ci010132r; Engh RA, 2002, PHARMACOL THERAPEUT, V93, P99, DOI 10.1016/S0163-7258(02)00180-8; GHOSE AK, 1988, J COMPUT CHEM, V9, P80, DOI 10.1002/jcc.540090111; GHOSE AK, 1986, J COMPUT CHEM, V7, P565, DOI 10.1002/jcc.540070419; GHOSE AK, 1987, J CHEM INF COMP SCI, V27, P21, DOI 10.1021/ci00053a005; Hardcastle IR, 2002, ANNU REV PHARMACOL, V42, P325, DOI 10.1146/annurev.pharmtox.42.090601.125940; Hawkins DM, 1997, QUANT STRUCT-ACT REL, V16, P296, DOI 10.1002/qsar.19970160404; Huse M, 2002, CELL, V109, P275, DOI 10.1016/S0092-8674(02)00741-9; JUDSON R, 1997, REV COMP CH, V10, P1; Sadowski J, 1998, J MED CHEM, V41, P3325, DOI 10.1021/jm9706776; Lewis D. D., 1994, P 17 ANN INT ACM SIG, P3; Lind P, 2003, J CHEM INF COMP SCI, V43, P1855, DOI 10.1021/ci034107s; Liu HX, 2004, J CHEM INF COMP SCI, V44, P161, DOI 10.1021/ci034173u; Manallack DT, 2002, J CHEM INF COMP SCI, V42, P1256, DOI 10.1021/ci020267c; Manning G, 2002, SCIENCE, V298, P1912, DOI 10.1126/science.1075762; Muller G, 2003, DRUG DISCOV TODAY, V8, P681, DOI 10.1016/S1359-6446(03)02781-8; Nagar B, 2002, CANCER RES, V62, P4236; Naumann T, 2002, J MED CHEM, V45, P2366, DOI 10.1021/jm011002c; Noble MEM, 2004, SCIENCE, V303, P1800, DOI 10.1126/science.1095920; Pargellis C, 2002, NAT STRUCT BIOL, V9, P268, DOI 10.1038/nsb770; RAYMER ML, 2000, THESIS MICHIGAN STAT; Raymer ML, 1997, J MOL BIOL, V265, P445, DOI 10.1006/jmbi.1996.0746; VANRIJSBERGEN CJ, 1979, INFORMATION RETRIEVA; Warmuth MK, 2003, J CHEM INF COMP SCI, V43, P667, DOI 10.1021/ci025620t; WESS G, 2001, ANGEW CHEM, V113, P3443, DOI 10.1002/1521-3757(20010917)113:18<3443::AID-ANGE3443>3.0.CO;2-S; Wess G, 2001, ANGEW CHEM INT EDIT, V40, P3341, DOI 10.1002/1521-3773(20010917)40:18<3341::AID-ANIE3341>3.0.CO;2-D; Yan R., 2003, IEEE INT C AC SPEECH; *TSAR, VERS 3 3 ACCELRYS	39	30	30	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	1439-4227		CHEMBIOCHEM	ChemBioChem	MAR	2005	6	3					558	566		10.1002/cbic.200400109		9	Biochemistry & Molecular Biology; Chemistry, Medicinal	Biochemistry & Molecular Biology; Pharmacology & Pharmacy	906JJ	WOS:000227636700014	
J	Kim, HS; Cha, SD				Kim, HS; Cha, SD			Empirical evaluation of SVM-based masquerade detection using UNIX commands	COMPUTERS & SECURITY			English	Article						intrusion detection; masquerade detection; anomaly detection; machine learning; support vector machine (SVM)	COMPUTER INTRUSION	Masqueraders who impersonate other users pose serious threat to computer security. Unfortunately, firewalls or misuse-based intrusion detection systems are generally ineffective in detecting masquerades. Although anomaly detection techniques have tong been considered as an effective approach to complement misuse detection techniques, they are not widely used in practice due to poor accuracy and relatively high degree of false alarms. In this paper, we performed an empirical study investigating the effectiveness of SVM (support vector machine) in detecting masquerade activities using two different UNIX command sets used in previous studies [R. Maxion, N. Townsend, Proceedings of international conference on dependable systems and networks (DSN-02), p. 219-28, June 2002; R. Maxion, Proceedings of international conference on dependable systems and networks (DSN-03), p. 5-14, June 2003]. Concept of "common commands" was introduced as a feature to more effectively reflect diverse command patterns exhibited by various users. Though still imperfect, we detected masquerades 80.1% and 94.8% of the time, white the previous studies reported the accuracy of 69.3% and 62.8%, respectively, using the same data set containing only the command names. When command names and arguments were included in the experiment, SVM-based approach detected masquerades 87.3% of the time white the previous study, using the same data set, reported 82.1% of accuracy. These combined experiments convincingly demonstrate that SVM is an effective approach to masquerade detection. (c) 2004 Elsevier Ltd. All rights reserved.	Korea Adv Inst Sci & Technol, Div Comp Sci, Taejon, South Korea; Korea Adv Inst Sci & Technol, AITrc, SPIC, IIRTRC,Dept Elect Engn & Comp Sci, Taejon, South Korea	Kim, HS (reprint author), Korea Adv Inst Sci & Technol, Div Comp Sci, 373-1,Guseong Dong, Taejon, South Korea.	kimhs@salmosa.kaist.ac.kr; cha@salmosa.kaist.ac.kr					ANDERSON JP, 1980, COMPUTE SECURITY THR; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CHANG C. C., LIBSVM LIB SUPPORT V; Dumais S., 2000, 23 ACM INT C RES DEV, P256; Fugate M, 2002, LECT NOTES COMPUT SC, V2388, P186; Greenberg S., 1988, 8833345 U CALG DEP C; Hsu C.-W., 2004, PRACTICAL GUIDE SUPP; Lane T., 2000, THESIS PURDUE U; Lee Wenke, 1998, P 7 USENIX SEC S SAN; Maxion R. A., 2002, Proceedings International Conference on Dependable Systems and Networks, DOI 10.1109/DSN.2002.1028903; Maxion R.A., 2003, P INT C DEP SYST NET, P5; Mukkamala S, 2002, IEEE IJCNN, P1702, DOI 10.1109/IJCNN.2002.1007774; PTACEK TH, 2002, INSERTION EVASION DE; Schonlau M, 2001, STAT SCI, V16, P58; THORSTEN J, 2000, P ICML00 17 INT C MA, P431; WEBSTER WH, 2002, REV FBI SECURITY PRO; Yang Yiming, 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; 1999, RAIN FOREST PUPPY LO	18	18	25	ELSEVIER ADVANCED TECHNOLOGY	OXFORD	OXFORD FULFILLMENT CENTRE THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0167-4048		COMPUT SECUR	Comput. Secur.	MAR	2005	24	2					160	168		10.1016/j.cose.2004.08.007		9	Computer Science, Information Systems	Computer Science	912ZD	WOS:000228118100025	
J	Mikut, R; Jakel, J; Groll, L				Mikut, R; Jakel, J; Groll, L			Interpretability issues in data-based learning, of fuzzy systems	FUZZY SETS AND SYSTEMS			English	Article						classification; data mining; decision tree; linguistic fuzzy system; fuzzy rule; inductive learning; interpretability; machine learning	DECISION TREES; MODELS; SIMPLIFICATION; CONSTRUCTION; METHODOLOGY; INFORMATION; COMPLEXITY; INDUCTION; ALGORITHM	This paper presents a method for an automatic and complete design of fuzzy systems from data. The main objective is to build fuzzy systems with a user-controllable trade-off between accuracy and interpretability. Whereas criteria for accuracy mostly follow straightforwardly from the application, definition of interpretability and its criteria are subject to controversial discussion. For this reason, a set of interpretability criteria is given which guide the design process. Consequently, interpretability is maintained by structural choices regarding the type of membership functions, rules, and inference mechanism, on the one hand, and by including interpretability criteria in the rule/rule base evaluation, on the other hand. An application in Instrumented Gait Analysis, to characterize a certain group of patients in comparison to healthy subjects, illustrates the proposed algorithm. (C) 2004 Elsevier B.V. All rights reserved.	Forschungszentrum Karlsruhe, Inst Appl Comp Sci, D-76021 Karlsruhe, Germany	Mikut, R (reprint author), Forschungszentrum Karlsruhe, Inst Appl Comp Sci, POB 3640, D-76021 Karlsruhe, Germany.	ralf.mikut@iai.fzk.de; jens.jaekel@iai.fzk.de; lutz.groell@iai.fzk.de	Mikut, Ralf /A-5949-2013				ADLASSNIG KP, 1980, METHOD INFORM MED, V19, P141; Babuska R., 1998, FUZZY MODELING CONTR; BODENHOFER U, 2002, TRADE OFF ACCURANCY; BONARINI A, 1994, P 1 IEEE C EV COMP, V1, P51; Bonissone P. P., 1986, UNCERTAINTY ARTIFICI, P217; Boyen X, 1999, FUZZY SET SYST, V102, P3, DOI 10.1016/S0165-0114(98)00198-5; Breiman L, 1984, CLASSIFICATION REGRE; BUCKLEY JJ, 1994, FUZZY SET SYST, V66, P1, DOI 10.1016/0165-0114(94)90297-6; CASILLAS J, 2002, TRADE OFF ACCURANCY; Chen MY, 2004, FUZZY SET SYST, V142, P243, DOI 10.1016/S0165-0114(03)00160-X; Cios K, 1998, DATA MINING METHODS; Cordon O, 2003, FUZZY SET SYST, V138, P307, DOI 10.1016/S0165-0114(02)00388-3; Cordon O., 1997, FUZZY MODEL IDENTIFI, P215; Cordon O, 2000, IEEE T FUZZY SYST, V8, P335, DOI 10.1109/91.855921; Delgado M, 1998, FUZZY SET SYST, V97, P287, DOI 10.1016/S0165-0114(96)00351-X; de Oliveira JV, 1999, IEEE T SYST MAN CY A, V29, P128, DOI 10.1109/3468.736369; Drobics M, 2003, INT J APPROX REASON, V32, P131, DOI 10.1016/S0888-613X(02)00080-4; ESHRAGH F, 1979, INT J MAN MACH STUD, V11, P501, DOI 10.1016/S0020-7373(79)80040-1; Espinosa J, 2000, IEEE T FUZZY SYST, V8, P591; Hong TP, 1997, IEEE T KNOWL DATA EN, V9, P336; Hoppner F., 1999, FUZZY CLUSTER ANAL; ICHIBUCHI H, 1993, FUZZY SETS SYSTEMS, V59, P295; Jakel J, 2000, FRONT ARTIF INTEL AP, V57, P1; JAKEL J, 2001, P 9 ZITT FUZZ C 17 1, P230; JAKEL J, 1999, P 7 EUR C INT TECHN, P279; JANG JSR, 1995, P IEEE, V83, P378, DOI 10.1109/5.364486; Jin Y, 1998, P IEEE INT C FUZZ SY, P1188; Jin YC, 2000, IEEE T FUZZY SYST, V8, P212, DOI 10.1109/91.842154; KLAWONN F, 1995, P FUZZ NEUR SYST 95, P223; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; KRONE A, 1997, INT J KNOWLEDGE BASE, V1, P207; Krone A, 2001, FUZZY SET SYST, V123, P343, DOI 10.1016/S0165-0114(00)00112-3; LOOSE T, 2002, GAIT POSTURE S1, V16, P176; LOOSE T, 2002, FZKA, V6767, P43; LOOSE T, 2002, P 2 EUR MED BIOL ENG, P798; Marsala C, 2003, IEEE INT CONF FUZZY, P584; MIKUT R, 2000, FUZZY CONTROL THEORY, P177; MIKUT R, 2002, P 10 ZITT FUZZ C HOC, P300; MIKUT R, 2000, P 8 FUZZ C ZITT, P103; Miller G. A., 1955, INFORMATION THEORY P, P95; MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037//0033-295X.101.2.343; Perry J., 1992, GAIT ANAL NORMAL PAT; Quinlan J. R., 1993, C4 5 PROGRAM MACHINE; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Renooij S, 1999, INT J APPROX REASON, V22, P169, DOI 10.1016/S0888-613X(99)00027-4; RIVES J, 1990, P 1 INT S UNC MOD AN, P457; Setnes M, 1998, IEEE T SYST MAN CY B, V28, P376, DOI 10.1109/3477.678632; Setnes M, 2000, IEEE T FUZZY SYST, V8, P509, DOI 10.1109/91.873575; Sugeno M., 1993, IEEE Transactions on Fuzzy Systems, V1, DOI 10.1109/TFUZZ.1993.390281; Wang CH, 1999, FUZZY SET SYST, V103, P91; Yager RR, 1998, IEEE T SYST MAN CY C, V28, P55, DOI 10.1109/5326.661090; Yen J, 1999, IEEE T SYST MAN CY B, V29, P13, DOI 10.1109/3477.740162; YOSHINARI Y, 1993, FUZZY SET SYST, V54, P157, DOI 10.1016/0165-0114(93)90273-K; YUAN YF, 1995, FUZZY SET SYST, V69, P125, DOI 10.1016/0165-0114(94)00229-Z; ZADEH LA, 2000, COMPUTING WORDS INFO, V2; ZADEH LA, 1999, IEEE T CIRCUITS SYST, V45, P105; ZADEH LA, 1968, J MATH ANAL APPL, V23, P421, DOI 10.1016/0022-247X(68)90078-4; ZADEH LA, 2000, COMPUTING WORDS INFO, V1	58	53	54	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114		FUZZY SET SYST	Fuzzy Sets Syst.	MAR 1	2005	150	2					179	197		10.1016/j.fss.2004.06.006		19	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	889MQ	WOS:000226447500001	
J	Singh, S; Bovis, K				Singh, S; Bovis, K			An evaluation of contrast enhancement techniques for mammographic breast masses	IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE			English	Article						active contour models; contrast enhancement; mammograms; quantitative measures	COMPUTER-AIDED DIAGNOSIS; DIGITAL MAMMOGRAMS; CLUSTERED MICROCALCIFICATIONS; DIGITIZED MAMMOGRAMS; AUTOMATED DETECTION; TEXTURE ANALYSIS; CLASSIFICATION; SEGMENTATION; TRANSFORM; CANCER	The main aim of this paper is to propose a novel set of metrics that measure the quality of the image enhancement of mammographic images in a computer-aided detection framework aimed at automatically finding masses using machine learning techniques. Our methodology includes a novel mechanism for the combination of the metrics proposed into a single quantitative measure. We have evaluated our methodology on 200 images from the publicly available digital database for screening mammograms. We show that the quantitative measures help us select the best suited image enhancement on a per mammogram basis, which improves the quality of subsequent image segmentation much better than using the same enhancement method for all mammograms.	Univ Exeter, Dept Comp Sci, Exeter EX4 4QF, Devon, England; MET Off, Exeter EX1 3PB, Devon, England	Singh, S (reprint author), Univ Exeter, Dept Comp Sci, Exeter EX4 4QF, Devon, England.	s.singh@exeter.ac.uk					Betal D, 1997, BRIT J RADIOL, V70, P903; Bottema MJ, 2000, PATTERN RECOGN LETT, V21, P1209, DOI 10.1016/S0167-8655(00)00083-0; BOVIS KJ, 2000, P 5 INT WORKSH DIG M, P547; CHAN HP, 1995, PHYS MED BIOL, V40, P857, DOI 10.1088/0031-9155/40/5/010; FEURER EJ, 1999, DEVCAN PROBABILITY D; GUPTA R, 1995, PHYS MED BIOL, V40, P835, DOI 10.1088/0031-9155/40/5/009; HAIR J, 1998, MULTIVARIATE DATA AN; Hastie T, 1999, J COMPUT GRAPH STAT, V8, P531, DOI 10.2307/1390873; Jiang YL, 1996, RADIOLOGY, V198, P671; te Brake G M, 1999, IEEE Trans Med Imaging, V18, P628, DOI 10.1109/42.790462; KASS M, 1987, INT J COMPUT VISION, V1, P321; Klette R., 1996, HDB IMAGE PROCESSING; Lado MJ, 1999, MED PHYS, V26, P1294, DOI 10.1118/1.598624; LAU TK, 1991, COMPUT BIOMED RES, V24, P273, DOI 10.1016/0010-4809(91)90049-3; LI L, 1997, ACAD RADIOL, V4, P725; MATSUBARA T, 1997, P INT C INT INF SYST; Mendez AJ, 1998, MED PHYS, V25, P957, DOI 10.1118/1.598274; MOORE R, 2000, P 5 INT WORKSH DIG M; MOSSI JM, 1999, P I EL ENG 99, P465; Nagel RH, 1998, MED PHYS, V25, P1502, DOI 10.1118/1.598326; Pal S.K., 1986, FUZZY MATH APPROACH; PARKER J, 1995, BRIT J RADIOL, V68, P150; Petrequin P, 1996, J ANTHROPOL ARCHAEOL, V15, P1, DOI 10.1006/jaar.1996.0001; Petrick N, 1996, MED PHYS, V23, P1685, DOI 10.1118/1.597756; Petrick N, 1999, MED PHYS, V26, P1642, DOI 10.1118/1.598658; Polakowski WE, 1997, IEEE T MED IMAGING, V16, P811, DOI 10.1109/42.650877; QIAN W, 1998, ACAD RADIOL, V5, P355; Rangayyan R M, 1997, IEEE Trans Inf Technol Biomed, V1, P161, DOI 10.1109/4233.654859; Sahiner B, 1998, MED PHYS, V25, P516, DOI 10.1118/1.598228; Singh M, 2004, IEEE T SYST MAN CY B, V34, P2354, DOI 10.1109/TSMCB.2004.835077; Singh S., 2000, Journal of Intelligent Systems, V10; SINGH S, 2001, ADV ALGORITHMIC APPR, P440; Suckling J., 1994, P 2 INT WORKSH DIG M, P375; Tou J., 1974, PATTERN RECOGNITION; Webb A., 1999, STAT PATTERN RECOGNI; Wei DT, 1997, MED PHYS, V24, P903, DOI 10.1118/1.598011; WU YC, 1995, ACAD RADIOL, V2, P199; YIN FF, 1993, INVEST RADIOL, V28, P473; Zhang W, 1998, MED PHYS, V25, P949, DOI 10.1118/1.598273; Zhang W, 1996, MED PHYS, V23, P595, DOI 10.1118/1.597891; ZHENG B, 1995, ACAD RADIOL, V2, P655, DOI 10.1016/S1076-6332(05)80431-3; 1999, NHS BREAST SCREENING	42	19	21	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1089-7771		IEEE T INF TECHNOL B	IEEE T. Inf. Technol. Biomed.	MAR	2005	9	1					109	119		10.1109/TITB.2004.837581		11	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Medical Informatics	Computer Science; Mathematical & Computational Biology; Medical Informatics	906WU	WOS:000227676200013	
J	Huang, J; Ling, CX				Huang, J; Ling, CX			Using AUC and accuracy in evaluating learning algorithms	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						evaluation of learning algorithms; ROC; AUC of ROC; accuracy	ROC CURVE; AREA	The area under the ROC ( Receiver Operating Characteristics) curve, or simply AUC, has been traditionally used in medical diagnosis since the 1970s. It has recently been proposed as an alternative single-number measure for evaluating the predictive ability of learning algorithms. However, no formal arguments were given as to why AUC should be preferred over accuracy. In this paper, we establish formal criteria for comparing two different measures for learning algorithms and we show theoretically and empirically that AUC is a better measure ( defined precisely) than accuracy. We then reevaluate well-established claims in machine learning based on accuracy using AUC and obtain interesting and surprising new results. For example, it has been well-established and accepted that Naive Bayes and decision trees are very similar in predictive accuracy. We show, however, that Naive Bayes is significantly better than decision trees in AUC. The conclusions drawn in this paper may make a significant impact on machine learning and data mining applications.	Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada	Huang, J (reprint author), Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada.	jhuang@csd.uwo.ca; cling@csd.uwo.ca					Blake C. L., 1998, UCI REPOSITORY MACHI; Boser B, 1992, P 5 ANN WORKSH COMP, P144, DOI DOI 10.1145/130385.130401; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chang CC, 2003, LIBSVM LIB SUPPORT V; Cohen WW, 1999, J ARTIF INTELL RES, V10, P243; Cristianini N., 2000, INTRO SUPPORT VECTOR; Domingos P., 1996, P 13 INT C MACH LEAR, P105; Duda R.O, 1973, PATTERN CLASSIFICATI; EGAN JP, 1975, SIGNAL DETECTION THE; Ferri C., 2002, P 19 INT C MACH LEAR, P139; GREEN DM, 1966, SIGNAL DETECTION THE; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; HANLEY JA, 1982, RADIOLOGY, V143, P29; Hastie T, 2001, ELEMENTS STAT LEARNI; Hsu C., 2001, COMPARISON METHODS M; Kononenko I., 1990, CURRENT TRENDS KNOWL; Langley P., 1992, P 10 NAT C ART INT, P223; Ling C. X., 2003, P 18 INT C ART INT I, P329; Lingjaerde O, 1998, ACTA PSYCHIAT SCAND, V98, P73, DOI 10.1111/j.1600-0447.1998.tb10045.x; LINGNER J, 2002, MOL B INT U, V22, P123; Liu H, 2002, DATA MIN KNOWL DISC, V6, P393, DOI 10.1023/A:1016304305535; METZ CE, 1978, SEMIN NUCL MED, V8, P283, DOI 10.1016/S0001-2998(78)80014-2; MEYER D, 2002, BENCKMARKING SUPPORT; Provost F, 2003, MACH LEARN, V52, P199, DOI 10.1023/A:1024099825458; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; PROVOST F, 2000, 0004IS CDER STERN SC; Provost F. J., 1998, P 15 INT C MACH LEAR, P445; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Scholkopf B., 2002, LEARNING KERNELS; SMYTH P, 1995, P 12 INT C MACH LEAR, P506; Spackman K.A., 1989, P 6 INT WORKSH MACH, P160; Suykens J., 1999, P INT JOINT C NEUR N; SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615; Vapnik VN, 1998, STAT LEARNING THEORY; [Anonymous], 1993, P 13 INT JOINT C ART, P1022	36	135	144	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAR	2005	17	3					299	310				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	888EY	WOS:000226358200001	
J	Wei, LY; Yang, YY; Nishikawa, RM; Jiang, YL				Wei, LY; Yang, YY; Nishikawa, RM; Jiang, YL			A study on several machine-learning methods for classification of malignant and benign clustered microcalcifications	IEEE TRANSACTIONS ON MEDICAL IMAGING			English	Article						clustered microcalcifications; computer-aided diagnosis; kernel methods; mammography; relevance vector machine; support vector machine	COMPUTER-AIDED DIAGNOSIS; SUPPORT VECTOR MACHINES; ARTIFICIAL NEURAL-NETWORKS; FINITE-SAMPLE SIZE; BREAST-CANCER; MAMMOGRAPHY; RECOGNITION; PERFORMANCE; LIKELIHOOD; MASSES	In this paper, we investigate several state-of-the-art machine-learning methods for automated classification of clustered microcalcifications (MCs). The classifier is part of a computer-aided diagnosis (CADx) scheme that is aimed to assisting radiologists in making more accurate diagnoses of breast cancer on mammograms. The methods we considered were: support vector machine (SVM), kernel Fisher discriminant (KFD), relevance vector machine (RVM), and committee machines (ensemble averaging and AdaBoost), of which most have been developed recently in statistical learning theory. We formulated differentiation of malignant from benign MCs as a supervised learning problem, and applied these learning methods to develop the classification algorithm. As input, these methods used image features automatically extracted from clustered MCs. We tested these methods using a database of 697 clinical mammograms from 386 cases, which included a wide spectrum of difficult-to-classify cases. We analyzed the distribution of the cases in this database using the multidimensional scaling technique, which reveals that in the feature space the malignant cases are not trivially separable from the benign ones. We used receiver operating characteristic (ROC) analysis to evaluate and to compare classification performance by the different methods. In addition, we also investigated how to combine information from multiple-view mammograms of the same case so that the best decision can be made by a classifier. In our experiments, the kernel-based methods (i.e., SVM, KFD, and RVM) yielded the best performance (A(z) = 0.85, SVM), significantly outperforming a well-established, clinically-proven CADx approach that is based on neural network (A(z) = 0.80).	IIT, Dept Elect & Comp Engn, Chicago, IL 60616 USA; IIT, Dept Biomed Engn, Chicago, IL 60616 USA; Univ Chicago, Dept Radiol, Chicago, IL 60637 USA; R2 Technol Inc, Sunnyvale, CA USA; Univ Chicago, Dept Radiol, Chicago, IL 60637 USA	Yang, YY (reprint author), IIT, Dept Elect & Comp Engn, 3301 S Dearborn St, Chicago, IL 60616 USA.	yy@ece.iit.edu	Jiang, Yulei/A-9355-2009	Jiang, Yulei/0000-0001-9322-0958			American College of Radiology, 1998, AM COLL RAD BREAST I; Baker JA, 1996, RADIOLOGY, V198, P131; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chan HP, 1999, RADIOLOGY, V212, P817; Chan HP, 1999, MED PHYS, V26, P2654, DOI 10.1118/1.598805; Chan HP, 1998, MED PHYS, V25, P2007, DOI 10.1118/1.598389; Dhawan A., 1995, P 17 ANN INT C IEEE, V1, P535, DOI 10.1109/IEMBS.1995.575237; DORFMAN DD, 1992, INVEST RADIOL, V27, P723, DOI 10.1097/00004424-199209000-00015; DORSI CJ, 1992, RADIOLOGY, V184, P619; El-Naqa I, 2002, IEEE T MED IMAGING, V21, P1552, DOI 10.1109/TMI.2002.806569; FERRARI RJ, 1998, COMPUTER AIDED DIAGN, P281; Fisher RA, 1936, ANN EUGENIC, V7, P179; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Fukunaga K., 1990, INTRO STAT PATTERN R; GIGER ML, 1998, COMPUTER AIDED DIAGN, P167; Groenen P. J. F., 1997, MODERN MULTIDIMENSIO; Hastie T, 2001, ELEMENTS STAT LEARNI; Haykin S., 1999, NEURAL NETWORK COMPR; Huo ZM, 2000, ACAD RADIOL, V7, P1077, DOI 10.1016/S1076-6332(00)80060-4; Jiang YL, 1999, ACAD RADIOL, V6, P22, DOI 10.1016/S1076-6332(99)80058-0; Jiang YL, 1996, RADIOLOGY, V198, P671; Joachims T., 1999, P 16 INT C MACH LEAR, P200; KAPKOWICZ N, 2000, P LEARN IMB DAT SETS, P10; KNUTZEN AM, 1993, MAYO CLIN PROC, V68, P454; KOPANS DB, 1992, AM J ROENTGENOL, V158, P521; Kouskos E, 2003, ACTA RADIOL, V44, P43, DOI 10.1034/j.1600-0455.2003.00008.x; Lo JY, 1997, RADIOLOGY, V203, P159; Metz CE, 1998, STAT MED, V17, P1033, DOI 10.1002/(SICI)1097-0258(19980515)17:9<1033::AID-SIM784>3.3.CO;2-Q; Mika S, 1999, NEURAL NETWORKS SIGN, P41; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; Pontil M, 1998, IEEE T PATTERN ANAL, V20, P637, DOI 10.1109/34.683777; Ripley B. D, 1996, PATTERN RECOGNITION; Sahiner B, 2000, MED PHYS, V27, P1509, DOI 10.1118/1.599017; SCHOLKOPF B, 2002, LEARNIGN KERNELS SUP; Schwenk H., 1997, P INT C ART NEUR NET, P967; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Vapnik VN, 1998, STAT LEARNING THEORY; Veldkamp WJH, 2000, MED PHYS, V27, P2600, DOI 10.1118/1.1318221; VIOLA P, 2001, IEEE C COMP VIS PATT, P511; WAN V, 2000, P IEEE SIGN PROC SOC, V2, P775; WU YZ, 1993, RADIOLOGY, V187, P81; ZAIANE OR, 2002, P MDM KDD, P62	42	79	82	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0278-0062		IEEE T MED IMAGING	IEEE Trans. Med. Imaging	MAR	2005	24	3					371	380		10.1109/TMI.2004.842457		10	Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging	Computer Science; Engineering; Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging	901CH	WOS:000227260100009	
J	Starzyk, JA; Zhu, Z; Liu, TH				Starzyk, JA; Zhu, Z; Liu, TH			Self-organizing learning array	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						information theory-based machine learning; multilayer learning array; self-organizing neurons	NEURAL-NETWORKS; BRAIN	A new machine learning concept-self-organizing learning array (SOLAR)-is presented. It is a sparsely connected, information theory-based learning machine, with a multilayer structure. It has reconfigurable processing units (neurons) and an evolvable system structure, which makes it an adaptive-classification system for a variety of machine learning problems. Its multilayer structure can handle complex problems. Based on the entropy estimation, information theory-based learning is performed locally at each neuron. Neural parameters and connections that correspond to minimum entropy are adaptively set for each neuron. By choosing connections for each neuron, the system sets up its wiring and completes its self-organization. SOLAR classifies input data based on the weighted statistical information from all the neurons. The system classification ability has been simulated and experiments were conducted using test-bench data. Results show a very good performance compared to other classification methods. An important advantage of this structure is its scalability to a large system and ease of hardware implementation on regular arrays of cells.	Ohio Univ, Sch Elect Engn & Comp Sci, Athens, OH 45701 USA	Starzyk, JA (reprint author), Ohio Univ, Sch Elect Engn & Comp Sci, Athens, OH 45701 USA.	starzyk@bobcat.ent.ohiou.edu					ALBUS JS, 1975, T ASME J DYN SYST ME, P270; Arabie P., 1996, CLUSTERING CLASSIFIC; Baesens B, 2003, MANAGE SCI, V49, P312, DOI 10.1287/mnsc.49.3.312.12739; Bermak A, 2003, IEEE T NEURAL NETWOR, V14, P1097, DOI 10.1109/TNN.2003.816362; Cichocki A., 1993, NEURAL NETWORKS OPTI; Dayhoff J, 1990, NEURAL NETWORK ARCHI; Desai VS, 1996, EUR J OPER RES, V95, P24, DOI 10.1016/0377-2217(95)00246-4; DOWLING JE, 1998, CREATING MIND BRAIN; Gupta MM, 2003, STAT DYNAMIC NEURAL; Ham FM, 2001, PRINCIPLES NEUROCOMP; HIGUCHI T, 1994, MASSIVELY PARALLEL A, P339; Hoya T, 2003, IEEE T NEURAL NETWOR, V14, P450, DOI 10.1109/TNN.2003.809417; Hsu CW, 2002, MACH LEARN, V46, P291, DOI 10.1023/A:1012427100071; Ker JS, 1997, IEEE T NEURAL NETWOR, V8, P1545; KOHONEN T, 1995, SELFORGANIZING MAPS; KOONAR G, 2002, P 15 INT C COMP APPL, P197; Korner E, 2002, IEEE ENG MED BIOL, V21, P121, DOI 10.1109/MEMB.2002.1044182; Lee HJ, 2003, IEEE T PARALL DISTR, V14, P1; LENDARIS GG, 1964, P IEEE, V52, P324, DOI 10.1109/PROC.1964.2905; PROCYK TJ, 1979, AUTOMATICA, V15, P15, DOI 10.1016/0005-1098(79)90084-0; Mitchell T, 1997, MACHINE LEARNING; Proakis JG, 1995, DIGITAL COMMUNICATIO; Starzyk J, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL V, P801; Sutton R.S., 1998, REINFORCEMENT LEARNI; Taylor C., 1994, MACHINE LEARNING NEU; Taylor JG, 1999, NEURAL NETWORKS, V12, P943, DOI 10.1016/S0893-6080(99)00044-1; Vapnik VN, 1998, STAT LEARNING THEORY; Vogel DD, 1997, NEURAL NETWORKS, V10, P671, DOI 10.1016/S0893-6080(96)00099-8; Werbos P. I., 1974, THESIS HARVARD U CAM; Wilamowski B M, 2000, Int J Neural Syst, V10, P191, DOI 10.1016/S0129-0657(00)00017-X; *XIL INC, VIRT DAT	31	29	29	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	MAR	2005	16	2					355	363		10.1109/TNN.2004.842362		9	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	903EE	WOS:000227407500006	
J	Boden, M; Hawkins, J				Boden, M; Hawkins, J			Improved access to sequential motifs: A note on the architectural bias of recurrent networks	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Letter						architectural bias; biological sequence; bioinformaties; recurrent neural network	PROTEIN SECONDARY STRUCTURE; NEURAL-NETWORKS; PREDICTION; MEMORY	For many biological sequence problems the available data occupies only sparse regions of the problem space. To use machine learning effectively for the analysis of sparse data we must employ architectures with an appropriate bias. By experimentation we show that the bias of recurrent neural networks-recently analyzed by Tino, et al. and Hammer and Tino-offers superior access to motifs (sequential patterns) compared to the, in bioinformatics, standardly used feedforward neural networks.	Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld 4072, Australia	Boden, M (reprint author), Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld 4072, Australia.		Boden, Mikael/A-6030-2010				Baldi P, 1999, BIOINFORMATICS, V15, P937, DOI 10.1093/bioinformatics/15.11.937; Christiansen MH, 1999, COGNITIVE SCI, V23, P157, DOI 10.1207/s15516709cog2302_2; Hammer B, 2003, NEURAL COMPUT, V15, P1897, DOI 10.1162/08997660360675080; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735; KOLEN JF, 1994, PROCEEDINGS OF THE 1993 CONNECTIONIST MODELS SUMMER SCHOOL, P203; Pollastri G, 2002, PROTEINS, V47, P228, DOI 10.1002/prot.10082; Schmidhuber J, 2002, NEURAL COMPUT, V14, P2039, DOI 10.1162/089976602320263980; Tino P, 2003, NEURAL COMPUT, V15, P1931, DOI 10.1162/08997660360675099; Tino P, 2004, IEEE T NEURAL NETWOR, V15, P6, DOI 10.1109/TNN.2003.820839	9	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	MAR	2005	16	2					491	494		10.1109/TNN.2005.844086		4	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	903EE	WOS:000227407500019	
J	Matsushita, M; Nishizaki, H; Utsuro, T; Nakagawa, S				Matsushita, M; Nishizaki, H; Utsuro, T; Nakagawa, S			Improving keyword recognition of spoken queries by combining multiple, speech recognizer's outputs for speech-driven Web retrieval task	IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS			English	Article						speech recognition; machine learning; multiple LVCSR models; WEB retrieval		This paper presents speech-driven Web retrieval models which accept spoken search topics (queries) in the NTCIR-3 Web retrieval task. The major focus of this paper is on improving speech recognition accuracy of spoken queries and then improving retrieval accuracy in speech-driven Web retrieval. We experimentally evaluated the techniques of combining outputs of multiple LVCSR models in recognition of spoken queries. As model combination techniques, we compared the SVM learning technique with conventional voting schemes such as ROVER. In addition, for investigating the effects on the retrieval performance in vocabulary size of the language model, we prepared two kinds of language models: the one's vocabulary size was 20,000, the other's one was 60,000. Then, we evaluated the differences in the recognition rates of the spoken queries and the retrieval performance. We showed that the techniques of multiple LVCSR model combination could achieve improvement both in speech recognition and retrieval accuracies in speech-driven text retrieval. Comparing with the retrieval accuracies when an LM with a 20,000/60,000 vocabulary size is used in an LVCSR system, we found that the larger the vocabulary size is, the better the retrieval accuracy is.	Denso Techno Corp, Nagaoka, Niigata 4500002, Japan; Univ Yamanashi, Interdisciplinary Grad Sch Med & Engn, Kofu, Yamanashi 4008511, Japan; Kyoto Univ, Grad Sch Informat, Kyoto 6068501, Japan; Toyohashi Univ Technol, Dept Informat & Comp Sci, Toyohashi, Aichi 4408580, Japan	Matsushita, M (reprint author), Denso Techno Corp, Nagaoka, Niigata 4500002, Japan.	hnishi@yamanashi.ac.jp; utsuro@pine.kuee.kyoto-u.ac.jp; nakagawa@slp.ics.tut.ac.jp					BARNETT J, 1997, P EUR 97, P1323; Crestani F., 2000, P 4 INT C FLEX QUER, P267; EGUCHI K, 2002, 3 NTCIR WORKSH M, P1; Evermann G., 2000, P NIST SPEECH TRANSC; Fiscus J., 1997, P IEEE WORKSH AUT SP, P347; FUJII A, 2003, P EUROSPEECH2003, P1153; GAROFOLO JS, 1997, P 6 TEXT RETR C, P83; Goel V., 2000, P 6 ICSLP, P139; KAI A, 1998, P ICSLP 98, P2427; KAWAHARA T, 1998, P 5 ICSLP, P763; KITAOKA N, 2004, IEICE T INF SYST JAP, V87, P799; MATSUSHITA M, 2003, P EUROSPEECH2003, P1205; NAKAGAWA S, 1996, P ICASSP 96, P439; NAKAGAWA S, 1988, SPEECH RECOGNITION B; Nakagawa S., 1990, Journal of the Acoustical Society of Japan, V46; SCHWENK H, 2000, P IEEE INT C SPEECH, P915; UTSURO T, 2004, P HTL NAACL2004, V2, P13; UTSURO T, 2003, P ICASSP2003, V1, P16; Vapnik V. N, 1995, NATURE STAT LEARNING	19	0	0	IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG	TOKYO	KIKAI-SHINKO-KAIKAN BLDG MINATO-KU SHIBAKOEN 3 CHOME, TOKYO, 105, JAPAN	0916-8532		IEICE T INF SYST	IEICE Trans. Inf. Syst.	MAR	2005	E88D	3					472	480		10.1093/ietisy/e88-d.3.472		9	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	908ZG	WOS:000227828100016	
J	Jung, H; Yi, E; Kim, D; Lee, GG				Jung, H; Yi, E; Kim, D; Lee, GG			Information extraction with automatic knowledge expansion	INFORMATION PROCESSING & MANAGEMENT			English	Article						information extraction; question answering; user-oriented learning; lexico-semantic pattern; machine learning		POSIE (POSTECH Information Extraction System) is an information extraction system which uses multiple learning strategies, i.e., SmL, user-oriented learning, and separate-context learning, in a question answering framework. POSIE replaces laborious annotation with automatic instance extraction by the SmL from structured Web documents, and places the user at the end of the user-oriented learning cycle. Information extraction as question answering simplifies the extraction procedures for a set of slots. We introduce the techniques verified on the question answering framework, such as domain knowledge and instance rules, into an information extraction problem. To incrementally improve extraction performance, a sequence of the user-oriented learning and the separate-context learning produces context rules and generalizes them in both the learning and extraction phases. Experiments on the "continuing education" domain initially show that the F1-measure becomes 0.477 and recall 0.748 with no user training. However, as the size of the training documents grows, the F1-measure reaches beyond 0.75 with recall 0.772. We also obtain F-measure of about 0.9 for five out of seven slots on "job offering" domain. (C) 2003 Elsevier Ltd. All rights reserved.	Pohang Univ Sci & Technol, Dept Comp Sci & Engn, Pohang 790784, Kyungbuk, South Korea	Jung, H (reprint author), Pohang Univ Sci & Technol, Dept Comp Sci & Engn, San 31 Hyoja Dong, Pohang 790784, Kyungbuk, South Korea.	jhm@postech.ac.kr; juicy@postech.ac.kr; dskim@postech.ac.kr; gblee@postech.ac.kr					BLUM A, 1998, P C COMP LEARN THEOR; BRIN S, 1998, P INT WORKSH WEB DAT; Califf Mary Elaine, 1998, P AAAI SPRING S APPL; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; Cohen W. W., 1995, P 12 INT C MACH LEAR; Eikvil L, 1999, 945 NORW COMP CTR; Finch S., 1995, P 7 C EUR CHAPT ASS; FLYNN P, 1998, UNDERSTANDING SGML X; FREITAG D, 1998, P 15 C ART INT; FREITAG D, 1998, P 17 C COMP LING 36; GRISHMAN R, 1997, INFORMATION EXTRACTI; HARABAGIU S, 2000, P 9 TEXT RETR C; JONES R, 1999, P IJCAI 99 WORKSH TE; JUNG H, 2003, IEICE T INFORMATIO E, V86; KIM D, 2003, INFORMATION PROCESSI, V39; KIM D, 2002, COMPUTER PROCESSING, V15; KIM H, 2001, COMPUTER PROCCESSING, V14; KNOBLOCK CA, 2000, DATA ENG B, V23; KUSHMERICK N, 2000, ARTIFICAL INTELLIGEN, V118; Michalski R. S., 1983, MACHINE LEARNING ART; MOLDOVAN D, 1999, P 8 TEXT RETR C; MUSLEA I, 1998, P AAAI WORKSH AI INF; NAHM U, 2000, P KDD KNOWL DISC DAT; NAHM UY, 2001, THESIS U TEXAS AUSTI; NIGAM K, 2000, P KDD KNOWL DISC DAT; PIERCE D, 2001, P C EMP METH NAT LAN; PIERCE D, 2001, IJCAI WORKSH AD TEXT; QUINLAN J, 1990, MACHINE LEARNING, V5; RAYCHAUDHURI T, 1997, INTELLIGENT SYSTEMS, V7; Riloff E., 1999, P 16 NAT C ART INT; RILOFF E, 1996, P 13 NAT C ART INT; RIM H, 2001, P S LANG RES AS; SASAKI Y, 1999, P AAAI 99 WORKSH MAC; Seo J., 2001, P 10 TEXT RETR C; SHIM J, 2002, INFORMATION PROCESSI, V38; SODERLAND S, 2001, MACHINE LEARNING, V34; SUDO K, 2001, P C HUM LANG TECHN; YANGARBER R, 2000, P 14 EUR C ART INT W; YANGARBER R, 1998, P TIPSTER TEXT PROGR; ZECHNER KA, 1997, LIT SURVEY INFORMATI	40	5	6	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0306-4573		INFORM PROCESS MANAG	Inf. Process. Manage.	MAR	2005	41	2					217	242		10.1016/S0306-4573(03)00066-9		26	Computer Science, Information Systems; Information Science & Library Science	Computer Science; Information Science & Library Science	874AK	WOS:000225323100004	
J	Laffan, SW; Nielsen, OM; Silcock, H; Hegland, M				Laffan, SW; Nielsen, OM; Silcock, H; Hegland, M			Sparse grids: a new predictive modelling method for the analysis of geographic data	INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE			English	Article						spatial analysis; geographic data; predictive modelling; sparse grids; bauxite	SPATIAL ASSOCIATION; NORTHERN AUSTRALIA; NEURAL-NETWORK; WILD GOOSE; STATISTICS; REGRESSION; VEGETATION	We introduce in this paper a new predictive modelling method to analyse Geographic data known as sparse grids. The sparse grids method has been developed for data-mining applications. It is a machine-learning approach to data analysis and has great applicability to the analysis and understanding of geographic data and processes. Sparse gi grids are a subset of grid-based predictive modelling approaches. The advantages they have over other grid-based methods are that they use fewer parameters and are less susceptible to the curse of dimensionality. These mean that they can be applied to many geographic problems and are readily adapted to the analysis of geographically local samples. We demonstrate the utility of the sparse grids system using a large and spatially extensive data set of regolith samples from Weipa, Australia. We apply both global and local analyses to find relationships between the regolith data and a set of geomorphometric, hydrologic and spectral variables. The results of the global analyses are much better than those generated using an artificial neural network, and the local analysis results are better than those generated using moving window regression for the same analysis window size. The sparse grids system provides a potentially powerful tool for the analysis and understanding of geographic processes and relationships.	Univ New S Wales, Sch Biol Earth & Environm Sci, Ctr Remote Sensing & GIS, Sydney, NSW 2052, Australia; Australian Natl Univ, Inst Math Sci, Canberra, ACT 0200, Australia	Laffan, SW (reprint author), Univ New S Wales, Sch Biol Earth & Environm Sci, Ctr Remote Sensing & GIS, Sydney, NSW 2052, Australia.	shawn.laffan@unsw.edu.au	Laffan, Shawn/A-3761-2008; Hegland, Markus/A-3583-2009	Laffan, Shawn/0000-0002-5996-0570; 			ANSELIN L, 1995, GEOGR ANAL, V27, P93; ASPINALL RJ, 1994, P 6INT S SPAT DAT HA, P1086; Braess D., 2001, FINITE ELEMENTS; Breiman L, 1984, CLASSIFICATION REGRE; BRUNSDON C, 2001, T GIS, V5, P1, DOI 10.1111/1467-9671.00063; Bungartz H.-J., 1992, THESIS TU MUNCHEN; BURROUGH PA, 1993, SOILS FERT, V56, P529; Ciarlet P.G., 2002, CLASSICS APPL MATH, V40; Cook SE, 1996, SOIL SCI SOC AM J, V60, P1893; Crisp MD, 2001, J BIOGEOGR, V28, P183, DOI 10.1046/j.1365-2699.2001.00524.x; DUNSTER JN, 1983, INTERIM REPORT RESER; EGGLETON RA, 1999, NEW APPROACHES OLD, P209; Foster I, 2001, INT J HIGH PERFORM C, V15, P200, DOI 10.1177/109434200101500302; FOSTER LD, 1996, THESIS AUSTR NATL U; Fotheringham A., 2002, GEOGRAPHICALLY WEIGH; Franklin J, 1995, PROG PHYS GEOG, V19, P474, DOI 10.1177/030913339501900403; FREEMAN TG, 1991, COMPUT GEOSCI, V17, P413, DOI 10.1016/0098-3004(91)90048-I; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Gahegan M, 2000, GEOGR ANAL, V32, P113; Gahegan M, 2003, INT J GEOGR INF SCI, V17, P69, DOI 10.1080/13658810210157778; Gahegan M. N., 1999, J GEOGRAPHICAL SYSTE, V1, P3, DOI 10.1007/s101090050002; Garcke J., 2002, Intelligent Data Analysis, V6; Garcke J, 2001, COMPUTING, V67, P225, DOI 10.1007/s006070170007; GETIS A, 1992, GEOGR ANAL, V24, P189; Gilardi N., 2000, J GEOGRAPHIC INFORMA, V4, P11; GOULD P, 1970, ECON GEOGR, V46, P439, DOI 10.2307/143157; GRIEBEL M, 1992, ITERATIVE METHODS IN LINEAR ALGEBRA, P263; Guisan A, 2000, ECOL MODEL, V135, P147, DOI 10.1016/S0304-3800(00)00354-9; Hastie T., 1986, STAT SCI, V1, P297, DOI DOI 10.1214/SS/1177013604; Hastie T, 2001, ELEMENTS STAT LEARNI; Hastie TJ, 1990, MONOGRAPHS STAT APPL, V43; HEGLAND M, 2002, P 5 INT C CURV SURF; KIIVERI HT, 2002, ACCURACY 2002, P471; Laffan SW, 2004, GEODERMA, V120, P241, DOI 10.1016/j.geoderma.0203.09.007; LAFFAN SW, 1998, P 3 INT C GEOC; Laffan SW, 2002, INT J GEOGR INF SCI, V16, P245, DOI 10.1080/13658810110099107; LAFFAN SW, 2001, THESIS AUSTR NATL U; LEES BG, 1990, QUATERNARY RES, V34, P169, DOI 10.1016/0033-5894(90)90029-K; LEES BG, 1992, AUST GEOGR, V23, P1, DOI 10.1080/00049189208703048; LEES BG, 1993, MAR GEOL, V114, P81, DOI 10.1016/0025-3227(93)90040-3; Lees BG, 1996, COMPUT GEOSCI, V22, P955, DOI 10.1016/S0098-3004(96)00033-7; LEES BG, 1991, ENVIRON MANAGE, V15, P823, DOI 10.1007/BF02394820; Luo Z, 1998, J CLIMATE, V11, P18, DOI 10.1175/1520-0442(1998)011<0018:STAOTU>2.0.CO;2; MACKEY B, 2002, GEOGRAPHIC INFORMATI, P223; MOORE ID, 1993, SOIL SCI SOC AM J, V57, P443; ORD JK, 1995, GEOGR ANAL, V27, P286; PAOLA JD, 1995, INT J REMOTE SENS, V16, P3033; PEREIRA JMC, 1991, PHOTOGRAMM ENG REM S, V57, P1475; SMOLIAK SA, 1963, DOKL AKAD NAUK SSSR+, V148, P1042; TOBLER WR, 1970, ECON GEOGR, V46, P234, DOI 10.2307/143141; Wilby RL, 2003, HYDROLOG SCI J, V48, P163, DOI 10.1623/hysj.48.2.163.44699; Zaniewski AE, 2002, ECOL MODEL, V157, P261, DOI 10.1016/S0304-3800(02)00199-0; ZENGER C, 1991, NOTE NUM FL, V31, P241; Zimmermann NE, 1999, J VEG SCI, V10, P469, DOI 10.2307/3237182	54	6	6	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1365-8816		INT J GEOGR INF SCI	Int. J. Geogr. Inf. Sci.	MAR	2005	19	3					267	292		10.1080/13658810512331319118		26	Computer Science, Information Systems; Geography; Geography, Physical; Information Science & Library Science	Computer Science; Geography; Physical Geography; Information Science & Library Science	906UY	WOS:000227670800001	
J	Cho, S; Asfour, S; Onar, A; Kaundinya, N				Cho, S; Asfour, S; Onar, A; Kaundinya, N			Tool breakage detection using support vector machine learning in a milling process	INTERNATIONAL JOURNAL OF MACHINE TOOLS & MANUFACTURE			English	Article						tool breakage detection; multiple sensors; support vector machine	CUTTING FORCE; WEAR	In this paper, an intelligent tool breakage detection system which uses a support vector machine (SVM) learning algorithm is proposed to provide the ability to recognize process abnormalities and initiate corrective action during a manufacutfing process. Specifically in a milling process. The system utilizes multiple sensors to record cutting forces and power consumptions- Attention is focused on training the proposed system for performance improvement and detecting tool breakage. Performance of the developed system is compared to the results from an alternative detection system based on a multiple linear regression model. It is expected that the proposed system will reduce machine downtime, which in turn will lead to reduced production costs and increased customer satisfaction. (C) 2004 Elsevier Ltd. All rights reserved.	Univ Miami, Dept Ind Engn, Coral Gables, FL 33124 USA; Dept Management Sci, Coral Gables, FL 33124 USA	Cho, S (reprint author), Univ Miami, Dept Ind Engn, POB 248294, Coral Gables, FL 33124 USA.	scho@miami.edu					Byrne G, 1995, ANN CIRP, V44, P541; Charbonnaud P, 2001, CONTROL ENG PRACT, V9, P1047, DOI 10.1016/S0967-0661(01)00074-0; CHOI Y, 2002, T NAMRI SME, V30, P191; Dan L., 1990, INT J MACH TOOL MANU, V30, P579, DOI 10.1016/0890-6955(90)90009-8; Elanayar S, 1996, J MANUF SCI E-T ASME, V118, P359, DOI 10.1115/1.2831037; ELBESTAWI MA, 1991, INT J MACH TOOL MANU, V31, P55, DOI 10.1016/0890-6955(91)90051-4; Gunn S. R., 1997, SUPPORT VECTOR MACHI; GUNN SR, 1997, INTELL DATA ANAL, V1208, P313; HUANG SJ, 2001, RRD VIROLOGY I, V3, P1; Jantunen E, 2002, INT J MACH TOOL MANU, V42, P997, DOI 10.1016/S0890-6955(02)00040-8; Kecman V., 2001, LEARNING SOFT COMPUT; KOREN Y, 1991, T ASME, V113, P300; Li XL, 2001, IEEE-ASME T MECH, V6, P491; MATSUMURA T, 2001, T NAMRI SME, V29, P284; RANGWALA S, 1990, J ENG IND-T ASME, V112, P219, DOI 10.1115/1.2899578; Sarhan A, 2001, J MATER PROCESS TECH, V109, P229, DOI 10.1016/S0924-0136(00)00803-7; Vapnik V. N, 1995, NATURE STAT LEARNING; Wilcox SJ, 1997, INT J MACH TOOL MANU, V37, P481, DOI 10.1016/S0890-6955(96)00069-7	18	22	22	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0890-6955		INT J MACH TOOL MANU	Int. J. Mach. Tools Manuf.	MAR	2005	45	3					241	249		10.1016/j.ijmachtools.2004.08.016		9	Engineering, Manufacturing; Engineering, Mechanical	Engineering	890WB	WOS:000226540700001	
J	Russell, I; Markov, Z; Carse, B; Pipe, AG; Holder, LB				Russell, I; Markov, Z; Carse, B; Pipe, AG; Holder, LB			Machine learning and neural network approaches to feature selection and extraction for classification	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Editorial Material									Univ Hartford, Hartford, CT 06117 USA; Cent Connecticut State Univ, New Britain, CT 06050 USA; Univ W England, Bristol BS16 1QY, Avon, England; Univ Texas, Arlington, TX 76019 USA	Russell, I (reprint author), Univ Hartford, Hartford, CT 06117 USA.							0	1	1	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014		INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	MAR	2005	19	2					129	132		10.1142/S0218001405003995		4	Computer Science, Artificial Intelligence	Computer Science	916UG	WOS:000228411100001	
J	Zhang, H				Zhang, H			Exploring conditions for the optimality of Naive bayes	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article; Proceedings Paper	17th International Florida-Artificial-Intelligence-Research-Society Conference (FLAIRS)	MAY, 2004	Miami Beach, FL	Florida Artificial Intelligence Res Soc		Naive Bayes; optimality; classification		Naive Bayes is one of the most efficient and effective inductive learning algorithms for machine learning and data mining. Its competitive performance in classification is surprising, because the conditional independence assumption on which it is based is rarely true in real-world applications. An open question is: what is the true reason for the surprisingly good performance of Naive Bayes in classification? In this paper, we propose a novel explanation for the good classification performance of Naive Bayes. We show that, essentially, dependence distribution plays a crucial role. Here dependence distribution means how the local dependence of an attribute distributes in each class, evenly or unevenly, and how the local dependences of all attributes work together, consistently (supporting a certain classification) or inconsistently (canceling each other out). Specifically, we show that no matter how strong the dependences among attributes are, Naive Bayes can still be optimal if the dependences distribute evenly in classes, or if the dependences cancel each other out. We propose and prove a sufficient and necessary condition for the optimality of Naive Bayes. Further, we investigate the optimality of Naive Bayes under the Gaussian distribution. We present and prove a sufficient condition for the optimality of Naive Bayes, in which the dependences among attributes exist. This provides evidence that dependences may cancel each other out. Our theoretic analysis can be used in designing learning algorithms. In fact, a major class of learning algorithms for Bayesian networks are conditional independence-based (or Cl-based), which are essentially based on dependence. We design a dependence distribution-based algorithm by extending the ChowLiu algorithm, a widely used CI based algorithm. Our experiments show that the new algorithm outperforms the ChowLiu algorithm, which also provides empirical evidence to support our new explanation.	Univ New Brunswick, Fac Comp Sci, Fredericton, NB E3B 5A3, Canada	Zhang, H (reprint author), Univ New Brunswick, Fac Comp Sci, POB 4400, Fredericton, NB E3B 5A3, Canada.	hzhang@unb.ca					Bennett PN, 2000, CMUCS00155; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; COOPER WS, 1995, ACM T INFORM SYST, V13, P100, DOI 10.1145/195705.195735; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Frank E, 2000, MACH LEARN, V41, P5, DOI 10.1023/A:1007670802811; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GARG A, 2001, P 12 EUR C MACH LEAR, P179; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; Kasif Simon, 1994, P 11 INT MACH LEARN, P242; Kononenko I., 1990, CURRENT TRENDS KNOWL; Langley P., 1992, P 10 NAT C ART INT, P223; Merz C., 1997, UCI REPOSITORY MACHI; MONTI F, 1999, P 15 C UNC ART INT, P447; PAZZANI MJ, 1996, LEARNING DATA ARTIFI; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Roth D, 1999, P INT JOINT C ART IN, P898; ZHANG H, 2001, P 18 INT C MACH LEAR, P617; [Anonymous], 1993, P 13 INT JOINT C ART, P1022	19	11	12	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014		INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	MAR	2005	19	2					183	198		10.1142/S0218001405003983		16	Computer Science, Artificial Intelligence	Computer Science	916UG	WOS:000228411100005	
J	Begg, R; Kamruzzaman, J				Begg, R; Kamruzzaman, J			A machine learning approach for automated recognition of movement patterns using basic, kinetic and kinematic gait data	JOURNAL OF BIOMECHANICS			English	Article						gait; support vector machine; gait classification; elderly	SUPPORT VECTOR MACHINES; GROUND REACTION FORCES; NEURAL-NETWORKS; DOMAIN ANALYSIS; CLASSIFICATION; FALLS; TIME	This paper investigated application of a machine learning approach (Support vector machine, SVM) for the automatic recognition of gait changes due to ageing using three types of gait measures: basic temporal/spatial, kinetic and kinematic. The gaits of 12 young and 12 elderly participants were recorded and analysed using a synchronized PEAK motion analysis system and a force platform during normal walking. Altogether, 24 gait features describing the three types of gait characteristics were extracted for developing gait recognition models and later testing of generalization performance. Test results indicated an overall accuracy of 91.7% by the SVM in its capacity to distinguish the two gait patterns. The classification ability of the SVM was found to be unaffected across six kernel functions (linear, polynomial, radial basis, exponential radial basis, multi-layer perceptron and spline). Gait recognition rate improved when features were selected from different gait data type. A feature selection algorithm demonstrated that as little as three gait features, one selected from each data type, could effectively distinguish the age groups with 100% accuracy. These results demonstrate considerable potential in applying SVMs in gait classification for many applications. (C) 2004 Elsevier Ltd. All rights reserved.	Victoria Univ, Ctr Rehabil Exercise & Sport Sci, Biomeh Unit, Melbourne, Vic 8001, Australia; Monash Univ, Gippsland Shc Comp & IT, Clayton, Vic 3842, Australia	Begg, R (reprint author), Victoria Univ, Ctr Rehabil Exercise & Sport Sci, Biomeh Unit, City Flinders Campus,POB 14428, Melbourne, Vic 8001, Australia.	rezaul.begg@vu.edu.au					Barton JG, 1997, GAIT POSTURE, V5, P28, DOI 10.1016/S0966-6362(96)01070-3; Begg RK, 2000, J GERONTOL A-BIOL, V55, P147; Begg RK, 1998, GAIT POSTURE, V7, P99, DOI 10.1016/S0966-6362(97)00039-8; Ben-Yacoub S, 1999, IEEE T NEURAL NETWOR, V10, P1065, DOI 10.1109/72.788647; Chan KL, 2002, IEEE T BIO-MED ENG, V49, P963, DOI 10.1109/TBME.2002.802012; Ding CHQ, 2001, BIOINFORMATICS, V17, P349, DOI 10.1093/bioinformatics/17.4.349; Giakas G, 1997, GAIT POSTURE, V5, P189, DOI 10.1016/S0966-6362(96)01083-1; Gunn S.R., 1998, SUPPORT VECTOR MACHI; HAGEMAN PA, 1986, PHYS THER, V66, P1382; Haykin S., 1999, NEURAL NETWORKS COMP; HOLZREITER SH, 1993, J BIOMECH, V26, P645, DOI 10.1016/0021-9290(93)90028-D; JudgeRoy J. O., 1996, J GERONTOL A-BIOL, V51, P303; KEEMAN V, 2002, LEARNING SOFT COMPUT; Kerrigan DC, 1998, ARCH PHYS MED REHAB, V79, P317, DOI 10.1016/S0003-9993(98)90013-2; Kim HC, 2003, PATTERN RECOGN, V36, P2757, DOI 10.1016/S0031-3203(03)00175-4; LEE L, 2002, P 5 INT C AUT FAC GE; Lord SR, 2003, J AM GERIATR SOC, V51, P1685, DOI 10.1046/j.1532-5415.2003.51551.x; Maki BE, 1997, J AM GERIATR SOC, V45, P313; Muller KR, 2003, IEEE T NEUR SYS REH, V11, P165, DOI 10.1109/TNSRE.2003.814484; NIGG BM, 1994, GAIT POSTURE, V2, P213, DOI DOI 10.1016/0966-6362(94)90106-6; O'Malley M J, 1997, IEEE Trans Rehabil Eng, V5, P300, DOI 10.1109/86.650282; Pang CCC, 2003, IEEE T BIO-MED ENG, V50, P521, DOI 10.1109/TBME.2003.809479; Prince F, 1997, GAIT POSTURE, V5, P128, DOI 10.1016/S0966-6362(97)01118-1; Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646; Vapnik V. N, 1995, NATURE STAT LEARNING; Winter DA, 1991, BIOMECHANICS MOTOR C; Yom-Tov E, 2002, IEEE T NEUR SYS REH, V10, P170, DOI 10.1109/TNSRE.2002.802875; Zavaljevski N, 2002, BIOINFORMATICS, V18, P689, DOI 10.1093/bioinformatics/18.5.689	28	49	52	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0021-9290		J BIOMECH	J. Biomech.	MAR	2005	38	3					401	408		10.1016/j.jbiomech.2004.05.002		8	Biophysics; Engineering, Biomedical	Biophysics; Engineering	895SS	WOS:000226884200002	
J	Muller, KR; Ratsch, G; Sonnenburg, S; Mika, S; Grimm, M; Heinrich, N				Muller, KR; Ratsch, G; Sonnenburg, S; Mika, S; Grimm, M; Heinrich, N			Classifying 'drug-likeness' with kernel-based learning methods	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							SUPPORT VECTOR MACHINE; CLASSIFICATION; COEFFICIENTS	In this article we report about a successful application of modern machine learning technology, namely Support Vector Machines, to the problem of assessing the 'drug-likeness' of a chemical from a given set of descriptors of the Substance. We were able to drastically improve the recent result by Byvatov et al. (2003) on this task and achieved an error rate of about 7% on unseen compounds using Support Vector Machines. We see a very high potential of such machine learning techniques for a variety of computational chemistry problems that occur in the drug discovery and drug design process.	Fraunhofer FIRST, D-12489 Berlin, Germany; Univ Potsdam, D-14482 Potsdam, Germany; Max Planck Soc, Friedrich Miescher Lab, D-72076 Tubingen, Germany; Idalab GmbH, D-10117 Berlin, Germany; Schering AG, Computat Chem, D-13342 Berlin, Germany	Sonnenburg, S (reprint author), Fraunhofer FIRST, Kekulestr 7, D-12489 Berlin, Germany.	soeren.sonnenburg@first.fraunhofer.de	Ratsch, Gunnar/B-8182-2009; Sonnenburg, Soeren/F-2230-2010; Muller, Klaus/C-3196-2013				Bennett K.P, 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; BISHOP CM, 1995, NEURAL COMPUT, V7, P108, DOI 10.1162/neco.1995.7.1.108; Boser B. E., 1992, P 5 ANN ACM WORKSH C; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Byvatov E, 2003, J CHEM INF COMP SCI, V43, P1882, DOI 10.1021/ci0341161; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVILLERS J, 1996, PRINCIPLES QSAR DRUG, V2; Fisher RA, 1936, ANN EUGENIC, V7, P179; GHOSE AK, 1986, J COMPUT CHEM, V7, P565, DOI 10.1002/jcc.540070419; GRAEPEL T, 1999, P ICANN 99, V1, P304; Sadowski J, 1998, J MED CHEM, V41, P3325, DOI 10.1021/jm9706776; Metz C. E., 1978, SEMINARS NUCL MED, V8, P4; MIKA S, 2001, ADV NEURAL INFORMATI, V13; Mika S, 2003, IEEE T PATTERN ANAL, V25, P623, DOI 10.1109/TPAMI.2003.1195996; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; ORR G, 1998, SPRINGER LNCS, V1524; Peterson KL, 2000, REV COMP CH, V16, P53, DOI 10.1002/9780470125939.ch2; Quinlan J., 1992, C4 5 PROGRAMS MACHIN; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B., 2002, LEARNING KERNELS; Vapnik V. N, 1995, NATURE STAT LEARNING; Zien A, 2000, BIOINFORMATICS, V16, P799, DOI 10.1093/bioinformatics/16.9.799; Zupan J., 1999, NEURAL NETWORKS CHEM; 1966, WORLD DRUG INDEX WDI; 1996, AVAILABLE CHEM DIREC	25	46	47	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596		J CHEM INF MODEL	J. Chem Inf. Model.	MAR-APR	2005	45	2					249	253		10.1021/ci049737o		5	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	911PZ	WOS:000228018000005	
J	Fan, WG; Gordon, MD; Pathak, P				Fan, WG; Gordon, MD; Pathak, P			Genetic programming-based discovery of ranking functions for effective Web search	JOURNAL OF MANAGEMENT INFORMATION SYSTEMS			English	Article						business intelligence; genetic programming; information retrieval; machine learning; ranking function; search engine; text mining; Web mining	INFORMATION-RETRIEVAL; RELEVANCE	Web search engines have become an integral part of the daily life of a knowledge worker, who depends on these search engines to retrieve relevant information from the Web or from the company's vast document databases. Current search engines are very fast in terms of their response time to a user query. But their usefulness to the user in terms of retrieval performance leaves a lot to be desired. Typically, the user has to sift through a lot of nonrelevant documents to get only a few relevant ones for the user's information needs. Ranking functions play a very important role in the search engine retrieval performance. In this paper, we describe a methodology using genetic programming to discover new ranking functions for the Web-based information-seeking task. We exploit the content as well as structural information in the Web documents in the discovery process. The discovery process is carried out for both the ad hoc task and the routing task in retrieval. For either of the retrieval tasks, the retrieval performance of these newly discovered ranking functions has been found to be superior to the performance obtained by well-known ranking strategies in the information retrieval literature.	Virginia Polytech Inst & State Univ, Blacksburg, VA 24061 USA; Univ Michigan, Ross Sch Business, Ann Arbor, MI 48109 USA; Univ Florida, Warrington Coll Business, Gainesville, FL 32611 USA	Fan, WG (reprint author), Virginia Polytech Inst & State Univ, Blacksburg, VA 24061 USA.		Fan, Weiguo/E-6343-2012	Fan, Weiguo/0000-0003-1272-5538			Arasu A., 2001, ACM T INTERNET TECHN, V1, P2, DOI 10.1145/383034.383035; BARTELL BT, 1994, P 17 ANN INT ACM SIG, V56, P173; Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X; CHEN H, 1994, J MANAGEMENT INFORMA, V11, P7; Chen HC, 1998, J AM SOC INFORM SCI, V49, P604, DOI 10.1002/(SICI)1097-4571(19980515)49:7<604::AID-ASI3>3.0.CO;2-T; DWORMAN G, 1996, J MANAGEMENT INFORMA, V12, P97; Fan WG, 2004, IEEE T KNOWL DATA EN, V16, P523, DOI 10.1109/TKDE.2004.1269663; Fan WG, 2004, J AM SOC INF SCI TEC, V55, P628, DOI 10.1002/asi.20009; Fan WG, 2004, INFORM PROCESS MANAG, V40, P587, DOI 10.1016/j.ipm.2003.08.001; FUHR N, 1991, ACM T INFORM SYST, V9, P223, DOI 10.1145/125187.125189; FUHR N, 1994, ACM T INFORM SYST, V12, P92, DOI 10.1145/174608.174612; GAO J, 2002, P 10 TEXT RETR C GAI, P384; Gey FC, 1994, P 17 ANN INT ACM SIG, P222; Gordon A, 1999, GLQ-J LESBIAN GAY ST, V5, P1; Gordon M., 1988, COMMUN ACM, V31, P152; Gordon M, 1999, INFORM PROCESS MANAG, V35, P141, DOI 10.1016/S0306-4573(98)00041-7; HARMAN D, 1993, P 3 TEXT RETRIEVAL C, P1; HARMAN DK, 1996, P 4 TEXT RETR C TREC, P1; HARMAN DK, 1992, P 11 ACM SIGIR C, P321; HAWKING D, 2000, P 9 TEXT RETR C GAIT, P86; HAWKING D, 2001, P 10 TEXT RETR C TRE, P61; Jansen BJ, 2000, INFORM PROCESS MANAG, V36, P207, DOI 10.1016/S0306-4573(99)00056-4; JONES WP, 1987, J AM SOC INFORM SCI, V38, P420, DOI 10.1002/(SICI)1097-4571(198711)38:6<420::AID-ASI3>3.0.CO;2-S; Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140; Koza J. R., 1992, GENETIC PROGRAMMING; LANCASTER F, 1993, INFORMATION RETRIEVA; Lee JH, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P267, DOI 10.1145/258525.258587; Martin-Bautista MJ, 1999, J AM SOC INFORM SCI, V50, P760, DOI 10.1002/(SICI)1097-4571(1999)50:9<760::AID-ASI4>3.3.CO;2-F; Pathak P., 2000, P 33 HAW INT C SYST; Raghavan V., 1987, P 2 INT C GEN ALG TH, P241; ROBERTSON SE, 1976, J AM SOC INFORM SCI, V27, P129, DOI 10.1002/asi.4630270302; ROBERTSON SE, 1996, P 4 TEXT RETR C TREC, P73; Salton G., 1971, SMART RETRIEVAL SYST; Salton G., 1989, AUTOMATIC TEXT PROCE; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Singhal A, 1996, INFORM PROCESS MANAG, V32, P619, DOI 10.1016/0306-4573(96)00008-8; Sun A., 2002, P 4 INT WORKSH WEB I, P96; Vogt C. C., 1999, Information Retrieval, V1, DOI 10.1023/A:1009980820262; YANG J, 1993, P 1 TEXT RETR C TREC, P31; Yang Yiming, 1997, P 14 INT C MACH LEAR, P412	40	26	27	M E SHARPE INC	ARMONK	80 BUSINESS PARK DR, ARMONK, NY 10504 USA	0742-1222		J MANAGE INFORM SYST	J. Manage. Inform. Syst.	SPR	2005	21	4					37	56				20	Computer Science, Information Systems; Information Science & Library Science; Management	Computer Science; Information Science & Library Science; Business & Economics	916CG	WOS:000228362400004	
J	Aphinyanaphongs, Y; Tsamardinos, I; Statnikov, A; Hardin, D; Aliferis, CF				Aphinyanaphongs, Y; Tsamardinos, I; Statnikov, A; Hardin, D; Aliferis, CF			Text categorization models for high-quality article retrieval in internal medicine	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article							SUPPORT VECTOR MACHINES; SEARCH STRATEGY; MEDLINE; TRIALS; CURVES	Objective: Finding the best scientific evidence that applies to a patient problem is becoming exceedingly difficult due to the exponential growth of medical publications. The objective of this study was to apply machine learning techniques to automatically identify high-quality, content-specific articles for one time period in internal medicine and compare their performance with previous Boolean-based PubMed clinical query filters of Haynes et al. Design: The selection criteria of the ACP journal Club for articles in internal medicine were the basis for identifying high-quality articles in the areas of etiology, prognosis, diagnosis, and treatment. Naive Bayes, a specialized AdaBoost algorithm, and linear and polynomial support vector machines were applied to identify these articles. Measurements: The machine learning models were compared in each category with each other and with the clinical query filters using area under the receiver operating characteristic curves, 11-point average recall precision, and a sensitivity/specificity match method. Results: In most categories, the data-induced models have better or comparable sensitivity, specificity, and precision than the clinical query filters. The polynomial support vector machine models perform the best among all learning methods in ranking the articles as evaluated by area under the receiver operating curve and 11-point average recall precision. Conclusion: This research shows that, using machine learning methods, it is possible to automatically build models for retrieving high-quality, content-specific articles using inclusion or citation by the ACP journal Club as a gold standard in a given time period in internal medicine that perform better than the 1994 PubMed clinical query filters.	Vanderbilt Univ, Dept Biomed Informat, Eskind Biomed Lib, Nashville, TN 37232 USA; Vanderbilt Univ, Dept Math, Nashville, TN 37232 USA	Aphinyanaphongs, Y (reprint author), Vanderbilt Univ, Dept Biomed Informat, Eskind Biomed Lib, 4th Floor,2209 Garland Ave, Nashville, TN 37232 USA.	ping.pong@vanderbilt.edu	Hardin, Douglas/C-3386-2013	Hardin, Douglas/0000-0003-0867-2146			Aliferis C. F., 2003, P 2003 AM MED INF AS, P21; Aphinyanaphongs Y, 2004, ST HEAL T, V107, P263; APHINYANAPHONGS Y, ON LINE SUPPL TEXT C; APHINYANAPHONGS Y, 2003, P AMIA S, P31; Bachmann LM, 2002, J AM MED INFORM ASSN, V9, P653, DOI 10.1197/jamia.M1124; Bigby M, 1998, ARCH DERMATOL, V134, P1609, DOI 10.1001/archderm.134.12.1609; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CENTOR RM, 1991, MED DECIS MAKING, V11, P102, DOI 10.1177/0272989X9101100205; Cooper HM, 1994, HDB RES SYNTHESIS; Cristianini N., 2000, INTRO SUPPORT VECTOR; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; HAYNES B, 1999, ACP J CLUB, V131, pA15; HAYNES RB, 1994, J AM MED INFORM ASSN, V1, P447; Joachims T, 1997, 14 INT C MACH LEARN, P143; Joachims T., 1999, ADV KERNEL METHODS; Leopold E, 2002, MACH LEARN, V46, P423, DOI 10.1023/A:1012491419635; Mitchell T, 1997, MACHINE LEARNING; Nwosu CR, 1998, OBSTET GYNECOL, V91, P618, DOI 10.1016/S0029-7844(97)00703-5; Pagano M., 2000, PRINCIPLES BIOSTATIS; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; Robinson KA, 2002, INT J EPIDEMIOL, V31, P150, DOI 10.1093/ije/31.1.150; Sackett DL, 1998, EVIDENCE BASED MED P; SCHAPIRE RE, 1999, 10 INT C ALG LEARN T, P13; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Shojania K G, 2001, Eff Clin Pract, V4, P157; Vapnik VN, 1998, STAT LEARNING THEORY; WILCZYNSKI NL, 2003, P AMIA ANN S, P719; WONG SSL, 2003, P AMIA ANN S, P728	28	35	37	B M J PUBLISHING GROUP	LONDON	BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND	1067-5027		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	MAR-APR	2005	12	2					207	216		10.1197/jamia.M1641		10	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Information Science & Library Science; Medical Informatics	Computer Science; Information Science & Library Science; Medical Informatics	909EC	WOS:000227842000011	
J	Hotz, CS; Templeton, SJ; Christopher, MM				Hotz, CS; Templeton, SJ; Christopher, MM			Comparative analysis of expert and machine-learning methods for classification of body cavity effusions in companion animals	JOURNAL OF VETERINARY DIAGNOSTIC INVESTIGATION			English	Article						computer; decision support; effusion; expert system; laboratory information; machine-learning system	SYSTEMS; PATHOLOGY	A rule-based expert system using CLIPS programming language was created to classify body cavity effusions as transudates, modified transudates, exudates, chylous, and hemorrhagic effusions. The diagnostic accuracy of the rule-based system was compared with that produced by 2 machine-learning methods: Rosetta, a rough sets algorithm and RIPPER, a rule-induction method. Results of 508 body cavity fluid analyses (canine, feline, equine) obtained from the University of California-Davis Veterinary Medical Teaching Hospital computerized patient database were used to test CLIPS and to test and train RIPPER and Rosetta. The CLIPS system, using 17 rules, achieved an accuracy of 93.5% compared with pathologist consensus diagnoses. Rosetta accurately classified 91% of effusions by using 5,479 rules. RIPPER achieved the greatest accuracy (95.5%) using only 10 rules. When the original rules of the CLIPS application were replaced with those of RIPPER, the accuracy rates were identical. These results suggest that both rule-based expert systems and machine-learning methods hold promise for the preliminary classification of body fluids in the clinical laboratory.	Univ Calif Davis, Sch Vet Med, Dept Pathol Microbiol & Immunol, Davis, CA 95616 USA; Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA; Univ Calif Davis, Sch Med, Dept Anesthesiol & Pain Med, Davis, CA 95616 USA	Christopher, MM (reprint author), Univ Calif Davis, Sch Vet Med, Dept Pathol Microbiol & Immunol, 1 Shields Ave, Davis, CA 95616 USA.						BAKER R, 2000, COLOR ATLAS CYTOLOGY, P159; Cowell R. L., 1999, DIAGNOSTIC CYTOLOGY, P142; Duncan JR, 1994, VET LAB MED CLIN PAT; EDWARDS G, 1993, PATHOLOGY, V25, P27; GIARRATANO J, 1998, EXPERT SYSTEMS PRINC, P477; Innis MD, 1997, MED INFORM, V22, P251; Ivandic M, 1996, CLIN CHEM, V42, P1214; KONONENKO I, 1997, MACHINE LEARNING DAT, P389; OHRN A, 1998, ROUGH SETS KNOWLEDGE, V1, P376; OLIVIER BN, 1994, SMALL ANIMAL CLIN DI, P219; PARRY BW, 1992, CYTOLOGY HEMATOLOGY, P121; SPACKMAN KA, 1987, ARCH PATHOL LAB MED, V111, P116; WINKEL P, 1989, CLIN CHEM, V35, P1595; WITTEN IH, 2000, DATA MINING PRACTICA, P119	14	1	1	AMER ASSOC VETERINARY LABORATORY DIAGNOSTICIANS INC	TURLOCK	PO BOX 1522, TURLOCK, CA 95381 USA	1040-6387		J VET DIAGN INVEST	J. Vet. Diagn. Invest.	MAR	2005	17	2					158	164				7	Veterinary Sciences	Veterinary Sciences	912CS	WOS:000228055300010	
J	Brown, M; Dunn, WB; Ellis, DI; Goodacre, R; Handl, J; Knowles, JD; O'Hagan, S; Spasic, I; Kell, DB				Brown, Marie; Dunn, Warwick B.; Ellis, David I.; Goodacre, Royston; Handl, Julia; Knowles, Joshua D.; O'Hagan, Steve; Spasic, Irena; Kell, Douglas B.			A metabolome pipeline: from concept to data to knowledge	METABOLOMICS			English	Review						metabolomics; chemometrics; data processing; databases; machine learning; genetic algorithms; genetic programming; evolutionary computing	PYROLYSIS MASS-SPECTROMETRY; FUNCTIONAL GENOMICS; SYSTEMS BIOLOGY; NEURAL-NETWORKS; EXPLANATORY ANALYSIS; EVOLUTIONARY COMPUTATION; QUANTITATIVE-ANALYSIS; PLANT METABOLOMICS; OLIVE OILS; METABONOMICS	Metabolomics, like other omics methods, produces huge datasets of biological variables, often accompanied by the necessary metadata. However, regardless of the form in which these are produced they are merely the ground substance for assisting us in answering biological questions. In this short tutorial review and position paper we seek to set out some of the elements of "best practice" in the optimal acquisition of such data, and in the means by which they may be turned into reliable knowledge. Many of these steps involve the solution of what amount to combinatorial optimization problems, and methods developed for these, especially those based on evolutionary computing, are proving valuable. This is done in terms of a "pipeline" that goes from the design of good experiments, through instrumental optimization, data storage and manipulation, the chemometric data processing methods in common use, and the necessary means of validation and cross-validation for giving conclusions that are credible and likely to be robust when applied in comparable circumstances to samples not used in their generation.	[Brown, Marie; Dunn, Warwick B.; Ellis, David I.; Goodacre, Royston; Handl, Julia; Knowles, Joshua D.; O'Hagan, Steve; Spasic, Irena; Kell, Douglas B.] Univ Manchester, Sch Chem, Manchester M60 1QD, Lancs, England	Kell, DB (reprint author), Univ Manchester, Sch Chem, Faraday Bldg,Sackville St,POB 88, Manchester M60 1QD, Lancs, England.	dbk@umist.ac.uk	Spasic, Irena/D-2259-2010; Kell, Douglas/E-8318-2011; Goodacre, Roy/J-1600-2012	Goodacre, Roy/0000-0003-2230-645X	BBSRC; EPSRC; NERC; The Gottlieb Daimler and Karl Benz Foundation; RSC	We thank the BBSRC, EPSRC, NERC, The Gottlieb Daimler and Karl Benz Foundation and the RSC for financial support, and Nigel Hardy and Helen Fuell for useful discussions.	Achard F, 2001, BIOINFORMATICS, V17, P115, DOI 10.1093/bioinformatics/17.2.115; Aharoni Asaph, 2002, OMICS A Journal of Integrative Biology, V6, P217, DOI 10.1089/15362310260256882; Allen J, 2004, APPL ENVIRON MICROB, V70, P6157, DOI 10.1128/AEM.70.10.6157-6165.2004; Allen J, 2003, NAT BIOTECHNOL, V21, P692, DOI 10.1038/nbt823; Back T., 1997, HDB EVOLUTIONARY COM; Banzhaf W., 1998, GENETIC PROGRAMMING; Barrow JD, 1995, LEFT HAND CREATION O; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Bernardo J.M., 2000, BAYESIAN THEORY; Berry D. A., 1996, STAT BAYESIAN PERSPE; Bishop C.M., 1995, NEURAL NETWORKS PATT; Bland M, 1987, INTRO MED STAT; BOOCH G, 1999, UNIFIED MODELLING LA; Brazma A, 2001, NAT GENET, V29, P365, DOI 10.1038/ng1201-365; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Brindle JT, 2002, NAT MED, V8, P1439, DOI 10.1038/nm802; CHATFIELD C, 1995, J ROY STAT SOC A STA, V158, P419, DOI 10.2307/2983440; CHEN PPS, 1976, ACM T DATABASE SYST, V1, P9, DOI 10.1145/320434.320440; Corne D, 1999, NEW IDEAS OPTIMIZATI; Cornell M, 2003, YEAST, V20, P1291, DOI 10.1002/yea.1047; Cornish-Bowden A, 2001, NATURE, V409, P571, DOI 10.1038/35054646; Dasgupta P, 1999, MULTIOBJECTIVE HEURI; Davies ZS, 2000, APPL ENVIRON MICROB, V66, P1435, DOI 10.1128/AEM.66.4.1435-1443.2000; De Smet F, 2002, BIOINFORMATICS, V18, P735, DOI 10.1093/bioinformatics/18.5.735; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Duda R. O., 2001, PATTERN CLASSIFICATI; Dudoit S, 2002, GENOME BIOL, V3, DOI DOI 10.1186/GB-2002-3-7-RESEARCH0036; Duran AL, 2003, BIOINFORMATICS, V19, P2283, DOI 10.1093/bioinformatics/btg315; Efron B., 1993, INTRO BOOTSTRAP; Ellis DI, 2003, METABOLIC PROFILING: ITS ROLE IN BIOMARKER DISCOVERY AND GENE FUNCTION ANALYSIS, P111; Estivill-Castro V, 2002, SIGKDD EXPLORATIONS, V4, P65; Everitt B. S., 1993, CLUSTER ANAL; Fell D., 1996, UNDERSTANDING CONTRO; Fernie AR, 2003, FUNCT PLANT BIOL, V30, P111, DOI 10.1071/FP02163; Fiehn O, 2003, METABOLIC PROFILING: ITS ROLE IN BIOMARKER DISCOVERY AND GENE FUNCTION ANALYSIS, P199; Fiehn O, 2000, NAT BIOTECHNOL, V18, P1157, DOI 10.1038/81137; Fiehn O, 2003, EUR J BIOCHEM, V270, P579, DOI 10.1046/j.1432-1033.2003.03427.x; Fiehn O, 2002, PLANT MOL BIOL, V48, P155, DOI 10.1023/A:1013713905833; Fiehn O, 2001, COMPAR FUNCT GENOM, V2, P155, DOI 10.1002/cfg.82; Fisher R. A., 1951, DESIGN EXPT; FLEISCHMANN RD, 1995, SCIENCE, V269, P496, DOI 10.1126/science.7542800; Flury B., 1988, MULTIVARIATE STAT PR; Foster JA, 2001, NAT REV GENET, V2, P428, DOI 10.1038/35076523; Gilbert RJ, 1997, ANAL CHEM, V69, P4381, DOI 10.1021/ac970460j; GILBERT RJ, 1999, LATE BREAKING PAPERS, P23; GOODACRE R, 1993, J SCI FOOD AGR, V63, P297, DOI 10.1002/jsfa.2740630306; Goodacre R, 1996, CURR OPIN BIOTECH, V7, P20, DOI 10.1016/S0958-1669(96)80090-5; GOODACRE R, 1992, NATURE, V359, P594, DOI 10.1038/359594a0; Goodacre R, 2002, ANALYST, V127, P1457, DOI 10.1039/b206037j; GOODACRE R, 1993, ANAL CHIM ACTA, V279, P17, DOI 10.1016/0003-2670(93)85062-O; Goodacre R, 2003, METABOLIC PROFILING: ITS ROLE IN BIOMARKER DISCOVERY AND GENE FUNCTION ANALYSIS, P239; Goodacre R, 2004, TRENDS BIOTECHNOL, V22, P245, DOI 10.1016/j.tibtech.2004.03.007; Goodacre R, 2003, VIB SPECTROSC, V32, P33, DOI 10.1016/S0924-2031(03)00045-6; Halkidi M, 2001, J INTELL INF SYST, V17, P107, DOI 10.1023/A:1012801612483; Handl J, 2004, LECT NOTES COMPUT SC, V3242, P1081; Hardy N, 2003, METABOLIC PROFILING: ITS ROLE IN BIOMARKER DISCOVERY AND GENE FUNCTION ANALYSIS, P277; Harrigan GG, 2003, METABOLIC PROFILING; Hastie T, 2001, ELEMENTS STAT LEARNI; Heinrich R, 1996, REGULATION CELLULAR; Hicks C. R., 1999, FUNDAMENTAL CONCEPTS; Hill AB, 1991, B HILLS PRINCIPLES M; Hofmeyr JHS, 1996, J THEOR BIOL, V182, P371, DOI 10.1006/jtbi.1996.0176; HSU J. S. J., 1999, BAYESIAN METHODS ANA; Hucka M, 2003, BIOINFORMATICS, V19, P524, DOI 10.1093/bioinformatics/btg015; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Jenkins H, 2004, NAT BIOTECHNOL, V22, P1601, DOI 10.1038/nbt1041; Johnson H. E., 2000, Genetic Programming and Evolvable Machines, V1, DOI 10.1023/A:1010014314078; Johnson HE, 2003, PHYTOCHEMISTRY, V62, P919, DOI 10.1016/S0031-9422(02)00722-7; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; Jones A, 2004, BIOINFORMATICS, V20, P1583, DOI 10.1093/bioinformatics/bth; Kaderbhai NN, 2003, COMP FUNCT GENOM, V4, P376, DOI 10.1002/cfg.302; Kell DB, 2004, CURR OPIN MICROBIOL, V7, P296, DOI 10.1016/j.mib.2004.04.012; Kell DB, 2001, PLANT PHYSIOL, V126, P943, DOI 10.1104/pp.126.3.943; Kell DB, 2004, BIOESSAYS, V26, P99, DOI 10.1002/bies.10385; KELL DB, 1986, FEMS MICROBIOL REV, V39, P305, DOI 10.1111/j.1574-6968.1986.tb01863.x; Kell DB, 2002, MOL BIOL REP, V29, P237, DOI 10.1023/A:1020342216314; Kell DB, 2000, TRENDS BIOTECHNOL, V18, P93, DOI 10.1016/S0167-7799(99)01407-9; Kohonen T, 1989, SELF ORG ASS MEMORY; Kose F, 2001, BIOINFORMATICS, V17, P1198, DOI 10.1093/bioinformatics/17.12.1198; Koza J., 1994, GENETIC PROGRAMMING; KOZA J. R., 1999, GENETIC PROGRAMMING; Koza J. R., 1992, GENETIC PROGRAMMING; Koza JR, 2003, GENETIC PROGRAMMING; KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209; Langdon W. B., 1998, GENETIC PROGRAMMING; Langdon W. B., 2002, FDN GENETIC PROGRAMM; Lenz EM, 2003, J PHARMACEUT BIOMED, V33, P1103, DOI 10.1016/S0731-7085(03)00410-2; LI XJ, 2003, METABOLIC PROFILING; Lindon JC, 2000, CONCEPT MAGNETIC RES, V12, P289, DOI 10.1002/1099-0534(2000)12:5<289::AID-CMR3>3.0.CO;2-W; Lindon JC, 2003, ANAL CHEM, V75, p384A, DOI 10.1021/ac031386+; Lindon JC, 2003, TOXICOL APPL PHARM, V187, P137, DOI 10.1016/S0041-008X(02)00079-0; Livingstone D., 1995, DATA ANAL CHEM; Martens H., 1989, MULTIVARIATE CALIBRA; Mendes Pedro, 2002, Brief Bioinform, V3, P134; Michalewicz Z., 2000, SOLVE IT MODERN HEUR; Mitchell T, 1997, MACHINE LEARNING; Montgomery DC, 2001, DESIGN ANAL EXPT; MUGGLETON S, 1990, NEW GENERAT COMPUT, V8, P295; Myers R.H., 1995, RESPONSE SURFACE MET; Nicholson JK, 2002, NAT REV DRUG DISCOV, V1, P153, DOI 10.1038/nrd728; Nicholson JK, 2003, NAT REV DRUG DISCOV, V2, P668, DOI 10.1038/nrd1157; OHAGAN S, 2004, ANAL CHEM IN PRESS; Oliver SG, 1998, TRENDS BIOTECHNOL, V16, P373, DOI 10.1016/S0167-7799(98)01214-1; Orchard S, 2003, PROTEOMICS, V3, P1374, DOI 10.1002/pmic.200300496; Page R.D.M., 1998, MOL EVOLUTION PHYLOG; Paton NW, 2000, BIOINFORMATICS, V16, P548, DOI 10.1093/bioinformatics/16.6.548; Pearl J, 2000, CAUSALITY MODELS REA; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Raamsdonk LM, 2001, NAT BIOTECHNOL, V19, P45; RAMONI M, 1998, THEORY PRACTICE BAYE; Rayward-Smith V. J., 1996, MODERN HEURISTIC SEA; Reeves C, 1995, MODERN HEURISTIC TEC; Ripley B. D, 1996, PATTERN RECOGNITION; Roessner U, 2000, PLANT J, V23, P131, DOI 10.1046/j.1365-313x.2000.00774.x; ROTHMAN KJ, 2002, EPIDEMIOLOGY INTRO; Rothman KJ, 1998, MODERN EPIDEMIOLOGY; Rowland JJ, 2003, BIOSYSTEMS, V72, P187, DOI 10.1016/S0303-2647(03)00143-6; Schlesselman JJ, 1982, CASE CONTROL STUDIES; SEASHOLTZ MB, 1993, ANAL CHIM ACTA, V277, P165, DOI 10.1016/0003-2670(93)80430-S; Shannon CE, 1949, MATH THEORY COMMUNIC; Solanky KS, 2003, ANAL BIOCHEM, V323, P197, DOI 10.1016/j.ab.2003.08.028; Steuer R, 2003, BIOINFORMATICS, V19, P1019, DOI 10.1093/bioinformatics/btg120; Sumner LW, 2003, PHYTOCHEMISTRY, V62, P817, DOI 10.1016/S0031-9422(02)00708-2; Taylor C., 1994, MACHINE LEARNING NEU; Taylor CF, 2003, NAT BIOTECHNOL, V21, P247, DOI 10.1038/nbt0303-247; Taylor J, 2002, BIOINFORMATICS, V18, pS241; Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293; Urbanczyk-Wochniak E, 2003, EMBO REP, V4, P989, DOI 10.1038/sj.embor.embor944; Vaidyanathan S, 2003, ANAL CHEM, V75, P6679, DOI 10.1021/ac034669a; Vaidyanathan S, 2004, ANAL CHEM, V76, P5024, DOI 10.1021/ac049684; Weiss S. M., 1991, COMPUTER SYSTEMS LEA; WEUSTERBOTZ D, 1995, PROCESS BIOCHEM, V30, P563, DOI 10.1016/0032-9592(94)00036-H; Wilson ID, 2003, J CHROMATOGR A, V1000, P325, DOI 10.1016/S0021-9673(03)00504-1; Woodward AM, 2004, ANALYST, V129, P542, DOI 10.1039/b403134b	138	52	56	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1573-3882		METABOLOMICS	Metabolomics	MAR	2005	1	1					39	51		10.1007/s11306-005-1106-4		13	Endocrinology & Metabolism	Endocrinology & Metabolism	V63QM	WOS:000204301600006	
J	Ngo, CW; Chan, CK				Ngo, CW; Chan, CK			Video text detection and segmentation for optical character recognition	MULTIMEDIA SYSTEMS			English	Article						video text detection; text segmentation; text recognition	DIGITAL VIDEO; BINARIZATION; LOCALIZATION	In this paper, we present approaches to detecting and segmenting text in videos. The proposed video-text-detection technique is capable of adaptively applying appropriate operators for video frames of different modalities by classifying the background complexities. Effective operators such as the repeated shifting operations are applied for the noise removal of images with high edge density. Meanwhile, a text-enhancement technique is used to highlight the text regions of low-contrast images. A coarse-to-fine projection technique is then employed to extract text lines from video frames. Experimental results indicate that the proposed text-detection approach is superior to the machine-learning-based (such as SVM and neural network), multiresolution-based, and DCT-based approaches in terms of detection and false-alarm rates. Besides text detection, a technique for text segmentation is also proposed based on adaptive thresholding. A commercial OCR package is then used to recognize the segmented foreground text. A satisfactory character-recognition rate is reported in our experiments.	City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China	Ngo, CW (reprint author), City Univ Hong Kong, Dept Comp Sci, Tat Chee Ave, Kowloon, Hong Kong, Peoples R China.						ARADHYE H, 2001, 22064 IBM RC; CAI M, 2002, INT C IM PROC; CHEN X, 2002, P WACV; Flickner M., 1995, IEEE COMPUT, V28, P23; Hua XS, 2004, IEEE T CIRC SYST VID, V14, P498, DOI 10.1109/TCSVT.2004.825538; HUA XS, 2001, INT C DOC AN REC, P545; Jahne B., 2002, DIGITAL IMAGE PROCES; Kim KI, 2001, PATTERN RECOGN, V34, P527, DOI 10.1016/S0031-3203(00)00095-9; LI H, 2000, INT C IM PROC; Li HP, 2000, IEEE T IMAGE PROCESS, V9, P147, DOI 10.1109/83.817607; LIENHART R, 2000, SPIE, V3972, P378; Lienhart R, 2002, IEEE T CIRC SYST VID, V12, P256, DOI 10.1109/76.999203; Lienhart R, 2000, MULTIMEDIA SYST, V8, P69, DOI 10.1007/s005300050006; NGO CW, 2002, IEEE C MULT EXP; Niblack W., 1986, INTRO DIGITAL IMAGE, P115; SATO T, 1997, ICCV WORKSH IM VID R; SAUVOLA J, 1997, INT C DOC AN REC, V1, P147; SHIM JC, 1998, INT C PATT REC; TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P1191, DOI 10.1109/34.476511; Wolf C, 2002, INT C PATT RECOG, P1037; Wong EK, 2003, PATTERN RECOGN, V36, P1397, DOI 10.1016/S0031-3203(02)00230-3; Zhang J., 2002, INT C PATT REC; Zhong Y, 2000, IEEE T PATTERN ANAL, V22, P385	23	13	13	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0942-4962		MULTIMEDIA SYST	Multimedia Syst.	MAR	2005	10	3					261	272		10.1007/s00530-004-0157-0		12	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	902EG	WOS:000227336100007	
J	Widmer, G				Widmer, G			Studying a creative act with computers: Music performance studies with automated discovery methods	MUSICAE SCIENTIAE			English	Article							MACHINE DISCOVERY; DYNAMICS; EXPRESSION; TEMPO	The purpose of this article is to demonstrate how advanced computer methods may be able to provide new insights into a complex creative activity such as music performance. The context is an inter-disciplinary research project in which Artificial Intelligence (AI) methods are used to analyse patterns in performances by human artists. In asking how the computer can take us closer to an understanding of creativity in music performance, we identify two pertinent research strategies within our project: the use of machine learning algorithms that try to discover common performance principles and thus help separate the "rationally explainable" aspects of performance from the more genuinely "creative" ones, and the use of data mining methods that can discover, visualise and describe performance patterns that seem to be characteristic of the style of particular artists and thus may be more directly related to their individual creativity. Some preliminary results are briefly presented that are indicative of the kinds of discoveries these algorithms can make. Some general issues regarding (musical) creativity and its relation to Artificial Intelligence are also briefly discussed.	Johannes Kepler Univ, Dept Computat Percept, A-4040 Linz, Austria; Austrian Res Inst Artificial Intelligence, Vienna, Austria	Widmer, G (reprint author), Johannes Kepler Univ, Dept Computat Percept, Altenberg Str 69, A-4040 Linz, Austria.	gerhard.widmer@jku.at					CHEN SF, 1995, P 33 ANN M ASS COMP, P228, DOI 10.3115/981658.981689; COLTON S, 1999, J INTEGER SEQUENCES, V2; DIXON S, 2003, IN PRESS COMPUTER GR; DIXON S, 2002, P ICMC ICMA, P361; DIXON S, 2002, P 2 INT C MUS ART IN, P58; Dixon S, 2001, J NEW MUSIC RES, V30, P39, DOI 10.1076/jnmr.30.1.39.7119; Friberg A., 1995, THESIS ROYAL I TECHN; Furnkranz J, 1999, ARTIF INTELL REV, V13, P3, DOI 10.1023/A:1006524209794; GABRIELSSON A., 1999, PSYCHOL MUSIC, P501, DOI 10.1016/B978-012213564-4/50015-9; LANGNER J, 2002, P ESCOM C MUS CREAT; Langner J, 2003, COMPUT MUSIC J, V27, P69, DOI 10.1162/014892603322730514; Lavrac N., 1994, INDUCTIVE LOGIC PROG; Mitchell T, 1997, MACHINE LEARNING; MUGGLETON S, 1992, PROTEIN ENG, V5, P647, DOI 10.1093/protein/5.7.647; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; REPP BH, 1992, J ACOUST SOC AM, V92, P2546, DOI 10.1121/1.404425; STAMATATOS E, 2002, P INT COMP MUS C ICM, P376; STAMATATOS E, 2002, P 15 EUR C ART INT E, P335; TODD N, 1989, CONT MUSIC REV, V4, P405, DOI 10.1080/07494468900640451; TODD NPM, 1992, J ACOUST SOC AM, V91, P3540; VALDESPEREZ RE, 1995, ARTIF INTELL, V74, P191, DOI 10.1016/0004-3702(94)00073-A; ValdesPerez RE, 1996, ARTIF INTELL, V82, P331, DOI 10.1016/0004-3702(95)00128-X; WIDMER G, 2000, P 2000 INT COMP MUS, P344; Widmer G., 2001, P 12 EUR C MACH LEAR, P552; Widmer G, 2001, AI COMMUN, V14, P149; WIDMER G, 2002, P 5 INT C DISC SCI D, P13; Widmer G, 2002, J NEW MUSIC RES, V31, P37, DOI 10.1076/jnmr.31.1.37.8103; Widmer G, 2003, J NEW MUSIC RES, V32, P259, DOI 10.1076/jnmr.32.3.259.16860; Windsor WL, 1997, MUSIC PERCEPT, V15, P127; Witten IH, 1999, DATA MINING; ZWICKER E, 2001, PSYCHOACOUSTICS	31	2	2	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	1029-8649		MUSIC SCI	Music Sci.	SPR	2005	9	1					11	30		10.1177/102986490500900101		20	Music; Psychology, Experimental	Music; Psychology	904CZ	WOS:000227475000002	
J	Gunter, S; Bunke, H				Gunter, S; Bunke, H			Off-line cursive handwriting recognition using multiple classifier systems - on the influence of vocabulary, ensemble, and training set size	OPTICS AND LASERS IN ENGINEERING			English	Article						multiple classifier combination; ensemble methods; training set size; vocabulary size; ensemble size; handwritten text recognition; hidden Markov model (HMM)		Unconstrained handwritten text recognition is one of the most difficult problems in the field of pattern recognition. Recently, a number of classifier creation and combination methods, known as ensemble methods, have been proposed in the field of machine learning. They have shown improved recognition performance over single classifiers. In this paper, we examine the influence of the vocabulary size, the number of training samples, and the number of classifiers on the performance of three ensemble methods in the context of cursive handwriting recognition. All experiments were conducted using an off-line handwritten word recognizer based on hidden Markov models (HMMs). (c) 2004 Elsevier Ltd. All rights reserved.	Univ Bern, Dept Comp Sci, CH-3012 Bern, Switzerland	Bunke, H (reprint author), Univ Bern, Dept Comp Sci, Neubruckstr 10, CH-3012 Bern, Switzerland.	sguenter@iam.unibe.ch; bunke@iam.unibe.ch					Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Dietterich Thomas G., 2000, P 1 INT WORKSH MULT, P1; DUIN RPW, 2000, P 1 INT WORKSH MULT, P16; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; GUNTER S, 2003, P 11 C INT GRAPH SOC, P196; HANSEN J, 2000, 4 INT C COMP INT NEU; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; HOULE GF, 1998, DOCUMENT ANAL SYSTEM, V2, P495; Huang T. S., 1995, IEEE T PATTERN ANAL, V17, P90; Impedovo S., 1997, AUTOMATIC BANKCHECK; KIM G, 1999, ADV HANDWRITING RECO, P163; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; KITTLER J, 2000, P 1 INT WORKSH MULT; KUNDU A, 1997, HDB CHARACTER RECOGN, P157; Lam L., 1997, HDB CHARACTER RECOGN, P79; Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, DOI 10.1007/s100320200071; Marti UV, 2001, INT J PATTERN RECOGN, V15, P65, DOI 10.1142/S0218001401000848; NISHIMURA H, 1999, 5 INT C DOC AN REC B, P49; OZA NC, 2003, P 4 INT WORKSH MULT, P15; Partridge D, 1996, NEURAL COMPUT, V8, P869, DOI 10.1162/neco.1996.8.4.869; Rabiner L, 1993, FUNDAMENTALS SPEECH; SIMON JC, 1992, P IEEE, V80, P1150, DOI 10.1109/5.156476; SKURICHINA M, 2000, P 1 INT WORKSH MULT, P190; SKURICHINA M, 2002, 3 INT WORKSH MULT CL, P62; SKURICHINA M, 2001, 2 INT WORKSH MULT CL, P1; Srihari SN, 2000, INT J PATTERN RECOGN, V14, P663, DOI 10.1142/S0218001400000441; SUEN CY, 1992, P IEEE, V80, P1162, DOI 10.1109/5.156477; SUEN CY, 2000, P 1 INT WORKSH MULT, P52; WICKRAMARATNA J, 2001, P 2 INT WORKSH MULT, P11; WINDEATT T, 2002, P 3 INT WORKSH MULT, P42; Zimmermann M., 2002, P 16 INT C PATT REC, V4, P35	32	5	5	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0143-8166		OPT LASER ENG	Opt. Lasers Eng.	MAR-MAY	2005	43	3-5					437	454		10.1016/j.optlaseng.2004.01.004		18	Optics	Optics	905HW	WOS:000227560200017	
J	Gardner, TS; Faith, JJ				Gardner, Timothy S.; Faith, Jeremiah J.			Reverse-engineering transcription control networks	PHYSICS OF LIFE REVIEWS			English	Article						gene networks; reverse-engineering; machine learning; transcription control; gene regulation	GENE-EXPRESSION DATA; ESCHERICHIA-COLI; SACCHAROMYCES-CEREVISIAE; REGULATORY NETWORKS; COMPONENT ANALYSIS; BAYESIAN NETWORKS; TOGGLE SWITCH; IDENTIFICATION; CONSTRUCTION; MICROARRAY	Microarray technologies, which enable the simultaneous measurement of all RNA transcripts in a cell, have spawned the development of algorithms for reverse-engineering transcription control networks. In this article, we classify the algorithms into two general strategies: physical modeling and influence modeling. We discuss the biological and computational principles underlying each strategy, and provide leading examples of each. We also discuss the practical considerations for developing and applying the various methods. (c) 2005 Elsevier B.V. All rights reserved.	Boston Univ, Dept Biomed Engn, Boston, MA 02215 USA	Gardner, TS (reprint author), Boston Univ, Dept Biomed Engn, 44 Cummington St, Boston, MA 02215 USA.	tgardner@bu.edu					AKUTSU T, 1999, PAC S BIOC, V4, P17; Akutsu T, 2000, BIOINFORMATICS, V16, P727, DOI 10.1093/bioinformatics/16.8.727; Arkin A, 1997, SCIENCE, V277, P1275, DOI 10.1126/science.277.5330.1275; Atkinson MR, 2003, CELL, V113, P597, DOI 10.1016/S0092-8674(03)00346-5; Bar-Joseph Z, 2003, NAT BIOTECHNOL, V21, P1337, DOI 10.1038/nbt890; Barkai N, 1997, NATURE, V387, P913; Becskei A, 2001, EMBO J, V20, P2528, DOI 10.1093/emboj/20.10.2528; Beer MA, 2004, CELL, V117, P185, DOI 10.1016/S0092-8674(04)00304-6; Bhalla US, 2002, SCIENCE, V297, P1018, DOI 10.1126/science.1068873; Bhalla US, 1999, SCIENCE, V283, P381, DOI 10.1126/science.283.5400.381; Bussemaker HJ, 2001, NAT GENET, V27, P167, DOI 10.1038/84792; CASHEL M, 1996, ESCHERISCHIA COLI SA, pCH92; Chee M, 1996, SCIENCE, V274, P610, DOI 10.1126/science.274.5287.610; Chen T, 1999, Pac Symp Biocomput, P29; Christensen SK, 2003, J MOL BIOL, V332, P809, DOI 10.1016/S0022-2836(03)00922-7; De Jong H, 2002, J COMPUT BIOL, V9, P67, DOI 10.1089/10665270252833208; de la Fuente A, 2004, BIOINFORMATICS, V20, P3565, DOI 10.1093/bioinformatics/bth445; Dhaeseleer P., 1999, PAC S BIOC, P41; D'haeseleer P, 2000, BIOINFORMATICS, V16, P707, DOI 10.1093/bioinformatics/16.8.707; Di Bernardo D, 2004, Pac Symp Biocomput, P486; DIBERNARDO, 2005, IN PRESS NAT BIOTECH; Elowitz MB, 2000, NATURE, V403, P335, DOI 10.1038/35002125; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Gardner TS, 2000, NATURE, V403, P339; Gardner TS, 2003, SCIENCE, V301, P102, DOI 10.1126/science.1081900; Gutierrez-Rios RM, 2003, GENOME RES, V13, P2435, DOI 10.1101/gr.1387003; Hartemink AJ, 2002, PAC S BIOCOMPUT, V7, P437; Herrgard MJ, 2003, GENOME RES, V13, P2423, DOI 10.1101/gr.1330003; Holter NS, 2001, P NATL ACAD SCI USA, V98, P1693, DOI 10.1073/pnas.98.4.1693; Hughes JD, 2000, J MOL BIOL, V296, P1205, DOI 10.1006/jmbi.2000.3519; Ideker T E, 2000, Pac Symp Biocomput, P305; Ihmels J, 2002, NAT GENET, V31, P370, DOI 10.1038/ng941; Isaacs FJ, 2003, P NATL ACAD SCI USA, V100, P7714, DOI 10.1073/pnas.1332628100; Kalir S, 2004, CELL, V117, P713, DOI 10.1016/j.cell.2004.05.010; Kao KC, 2004, P NATL ACAD SCI USA, V101, P641, DOI 10.1073/pnas.0305287101; KAUFFMAN SA, 1989, OR ORD SELF ORG SEL; Kyoda K M, 2000, Genome Inform Ser Workshop Genome Inform, V11, P196; Leloup JC, 1998, J BIOL RHYTHM, V13, P70, DOI 10.1177/074873098128999934; Liang S, 1998, PAC S BIOCOMPUT, P18; Liao JC, 2003, P NATL ACAD SCI USA, V100, P15522, DOI 10.1073/pnas.2136632100; Lockhart DJ, 1996, NAT BIOTECHNOL, V14, P1675, DOI 10.1038/nbt1296-1675; Lodish H, 2000, MOL CELL BIOL; MARGOLIN AA, 2004, REVERSE ENGN YEAST T; MARGOLIN AA, 2004, ARXIVORGABSQBIO04100; MENDES P, 2003, BIOINFORMATICS S19, V2, pII122; Munoz-Gomez AJ, 2004, FEBS LETT, V567, P316, DOI 10.1016/j.febslet.2004.05.005; Nachman I, 2004, Bioinformatics, V20 Suppl 1, pi248, DOI 10.1093/bioinformatics/bth941; Neapolitan R.E., 2004, LEARNING BAYESIAN NE; Ptashne M, 1992, GENETIC SWITCH PHAGE; Ronen M, 2002, P NATL ACAD SCI USA, V99, P10555, DOI 10.1073/pnas.152046799; SALGADO H, 2004, NUCLEIC ACIDS RES, V32, P303; SCHENA M, 1995, SCIENCE, V270, P467, DOI 10.1126/science.270.5235.467; Schmitt WA, 2004, GENOME RES, V14, P1654, DOI 10.1101/gr.2439804; Segal E., 2003, BIOINFORMATICS S1, V19, P264; Segal E., 2001, BIOINFORMATICS S1, V17, pS243; Segal E, 2003, NAT GENET, V34, P166, DOI 10.1038/ng1165; Szallasi Z, 1999, Pac Symp Biocomput, P5; Tadesse MG, 2004, BIOINFORMATICS, V20, P2553, DOI 10.1093/bioinformatics/bth282; TAMADA Y, 2003, BIOINFORMATICS S19, V2, pII227; Tavazoie S, 1999, NAT GENET, V22, P281; Van Someren E, 2001, P 2 INT C SYST BIOL, P222; van Someren E P, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P355; van Berlo RJP, 2003, SIMUL-T SOC MOD SIM, V79, P689, DOI 10.1177/003754903040942; Vilar JMG, 2002, P NATL ACAD SCI USA, V99, P5988, DOI 10.1073/pnas.092133899; Wang W, 2002, P NATL ACAD SCI USA, V99, P16893, DOI 10.1073/pnas.252638199; Weaver D. C., 1999, PAC S BIOCOMPUT, V4, P112; Yeang CH, 2004, J COMPUT BIOL, V11, P243, DOI 10.1089/1066527041410382; Yeung MKS, 2002, P NATL ACAD SCI USA, V99, P6163, DOI 10.1073/pnas.092576199; Yuh CH, 1998, SCIENCE, V279, P1896, DOI 10.1126/science.279.5358.1896; Zhang YL, 2003, MOL CELL, V12, P913, DOI 10.1016/S1097-2765(03)00402-7	70	87	87	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1571-0645		PHYS LIFE REV	Phys. Life Rev.	MAR	2005	2	1					65	88		10.1016/j.plrev.2005.01.001		24	Biology; Biophysics	Life Sciences & Biomedicine - Other Topics; Biophysics	190EV	WOS:000248041700003	
J	Middendorf, M; Ziv, E; Wiggins, CH				Middendorf, M; Ziv, E; Wiggins, CH			Inferring network mechanisms: The Drosophila melanogaster protein interaction network	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article						machine learning; systems biology; motifs; classification; evolution	COMPLEX NETWORKS; SACCHAROMYCES-CEREVISIAE; DUPLICATION; EVOLUTION; GRAPHS; MOTIFS; GENES; MODEL	Naturally occurring networks exhibit quantitative features revealing underlying growth mechanisms. Numerous network mechanisms have recently been proposed to reproduce specific properties such as degree distributions or clustering coefficients. We present a method for inferring the mechanism most accurately capturing a given network topology, exploiting discriminative tools from machine learning. The Drosophila melanogaster protein network is confidently and robustly (to noise and training data subsampling) classified as a duplication-mutation-complementation network over preferential attachment, small-world, and a duplication-mutation mechanism without complementation. Systematic classification, rather than statistical study of specific properties, provides a discriminative approach to understand the design of complex networks.	Columbia Univ, Dept Appl Phys & Appl Math, New York, NY 10027 USA; Columbia Univ, Dept Phys, New York, NY 10027 USA; Columbia Univ, Coll Phys & Surg, New York, NY 10027 USA; Columbia Univ, Ctr Computat Biol & Bioinformat, New York, NY 10027 USA	Wiggins, CH (reprint author), Columbia Univ, Dept Appl Phys & Appl Math, 500 W 120th St, New York, NY 10027 USA.	chris.wiggins@columbia.edu					Artzy-Randrup Yael, 2004, SCIENCE, V305, P1107, DOI DOI 10.1126/SCIENCE.1099334; Barabasi AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509; BERG J, 2003, ARXIVCONDMAT0207711; Bhan A, 2002, BIOINFORMATICS, V18, P1486, DOI 10.1093/bioinformatics/18.11.1486; Callaway DS, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.041902; Chung F., 1997, REGIONAL C SERIES MA; CONNOR EF, 1979, ECOLOGY, V60, P1132, DOI 10.2307/1936961; Devroye L., 1996, PROBABILISTIC THEORY; ERDOS P., 1959, PUBL MATH-DEBRECEN, V6, P290; FIEDLER M, 1973, CZECH MATH J, V23, P298; Force A, 1999, GENETICS, V151, P1531; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FREUND Y, 1999, J JPN SOC ARTIF INTE, V14, P711; Freund Y., 1999, P 16 INT C MACH LEAR, P124; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Giot L, 2003, SCIENCE, V302, P1727, DOI 10.1126/science.1090289; Goldberg DS, 2003, P NATL ACAD SCI USA, V100, P4372, DOI 10.1073/pnas.0735871100; Gomez Shawn M, 2002, Pac Symp Biocomput, P413; Hastie T, 2001, ELEMENTS STAT LEARNI; Hasty J, 2002, NATURE, V420, P224, DOI 10.1038/nature01257; Holland PW, 1976, SOCIOL METHODOL, V7, P1, DOI 10.2307/270703; HUGHES AL, 1994, P ROY SOC B-BIOL SCI, V256, P119, DOI 10.1098/rspb.1994.0058; Klemm K, 2002, PHYS REV E, V65, DOI 10.1103/PhysRevE.65.036123; Lee TI, 2002, SCIENCE, V298, P799, DOI 10.1126/science.1075090; Mangan S, 2003, P NATL ACAD SCI USA, V100, P11980, DOI 10.1073/pnas.2133841100; Middendorf M, 2004, BIOINFORMATICS, V20, P232, DOI 10.1093/bioinformatics/bth923; Milo R., 2004, SCIENCE, V305, P1107; Milo R, 2004, SCIENCE, V303, P1538, DOI 10.1126/science.1089167; Milo R, 2002, SCIENCE, V298, P824, DOI 10.1126/science.298.5594.824; Morris QD, 2004, ADV NEUR IN, V16, P385; Newman MEJ, 2003, SIAM REV, V45, P167, DOI 10.1137/S003614450342480; PRICE DJD, 1965, SCIENCE, V149, P510; Qian J, 2001, J MOL BIOL, V313, P673, DOI 10.1006/jmbi.2001.5079; Kumar R., 2000, Proceedings 41st Annual Symposium on Foundations of Computer Science, DOI 10.1109/SFCS.2000.892065; Rosenfeld N, 2002, J MOL BIOL, V323, P785, DOI 10.1016/S0022-2836(02)00994-4; Rzhetsky A, 2001, BIOINFORMATICS, V17, P988, DOI 10.1093/bioinformatics/17.10.988; Saito R, 2003, BIOINFORMATICS, V19, P756, DOI 10.1093/bioinformatics/btg070; SCHAPIRE RE, 2002, MSRI WORKSH NONL EST, P149; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Shen-Orr SS, 2002, NAT GENET, V31, P64, DOI 10.1038/ng881; SOLE R. V., 2002, ADV COMPLEX SYST, V5, P43, DOI 10.1142/S021952590200047X; Strogatz SH, 2001, NATURE, V410, P268, DOI 10.1038/35065725; Troyanskaya OG, 2003, P NATL ACAD SCI USA, V100, P8348, DOI 10.1073/pnas.0832373100; Vazquez A, 2003, PHYS REV E, V67, DOI 10.1103/PhysRevE.67.056104; Vazquez Alexei, 2003, ComPlexUs, V1, P38, DOI 10.1159/000067642; Vespignani A, 2003, NAT GENET, V35, P118, DOI 10.1038/ng1003-118; Wang W, 2004, NAT GENET, V36, P523, DOI 10.1038/ng1338; Wasserman S, 1994, SOCIAL NETWORK ANAL; Watts D., 1998, NATURE, V363, P202; Wuchty S, 2003, NAT GENET, V35, P176, DOI 10.1038/ng1242; ZIV E, 2003, ARXIVCONDMAT0306610	51	79	82	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424		P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	MAR 1	2005	102	9					3192	3197		10.1073/pnas.0409515102		6	Multidisciplinary Sciences	Science & Technology - Other Topics	903KC	WOS:000227423700007	
J	Kreucher, C; Kastella, K; Hero, AO				Kreucher, C; Kastella, K; Hero, AO			Sensor management using an active sensing approach	SIGNAL PROCESSING			English	Article						sensor management; machine learning; active sensing; multitarget tracking; particle filtering; joint multitarget probability density	MAXIMUM-LIKELIHOOD-ESTIMATION; TRACKING MULTIPLE TARGETS; MULTITARGET TRACKING; RECOGNITION; ALGORITHMS; GAIN	An approach that is common in the machine learning literature, known as active sensing, is applied to provide a method for managing agile sensors in a dynamic environment. We adopt an active sensing approach to scheduling sensors for multiple target tracking applications that combines particle filtering, predictive density estimation, and relative entropy maximization. Specifically, the goal of the system is to learn the number and states of a group of moving targets occupying a surveillance region. At each time step, the system computes a sensing action to take, based on an entropy measure called the Renyi divergence. After the measurement is made, the system updates its probability density on the number and states of the targets. This procedure repeats at each time where a sensor is available for use. The algorithms developed here extend standard active sensing methodology to dynamically evolving objects and continuous state spaces of high dimension. It is shown using simulated measurements on real recorded target trajectories that this method of sensor management yields more than a ten fold gain in sensor efficiency when compared to periodic scanning. (C) 2004 Elsevier B.V. All rights reserved.	Gen Dynam Adv Informat Syst, Ann Arbor, MI 48113 USA; Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA	Kreucher, C (reprint author), Gen Dynam Adv Informat Syst, POB 134008, Ann Arbor, MI 48113 USA.	ckreuche@umich.edu; keith.kastella@gd-ais.com; hero@eecs.umich.edu					Bertsekas DP, 1999, J HEURISTICS, V5, P89, DOI 10.1023/A:1009634810396; Bethel RE, 1998, IEEE T AERO ELEC SYS, V34, P153, DOI 10.1109/7.640271; BLACKMAN S. S., 1986, MULTIPLE TARGET TRAC; Blahut Richard E, 1987, PRINCIPLES PRACTICE; CASTANON D, 1997, P 1997 C DEC CONTR; CASTANON DA, 1995, IEEE T SYST MAN CYB, V25, P1130, DOI 10.1109/21.391293; Dembo A, 1998, LARGE DEVIATIONS TEC; Denzler J, 2002, IEEE T PATTERN ANAL, V24, P145, DOI 10.1109/34.982896; Doucet A., 2001, SEQUENTIAL MONTE CAR; Fox D, 1998, ROBOT AUTON SYST, V25, P195, DOI 10.1016/S0921-8890(98)00049-9; Goodman I.R., 1997, MATH DATA FUSION; Guonidas L, 2002, ACM INT WORKSH WIR S; Hernandez ML, 2004, IEEE T AERO ELEC SYS, V40, P399, DOI 10.1109/TAES.2004.1309993; HERO AO, 2001, 328 U MICH DEP EECS; Hero AO, 2002, IEEE SIGNAL PROC MAG, V19, P85, DOI 10.1109/MSP.2002.1028355; HINTZ KJ, 1991, IEEE T SYST MAN CYB, V21, P237, DOI 10.1109/21.101154; HINTZ KJ, 1991, IEEE T SYST MAN CYB, V21, P434, DOI 10.1109/21.87090; Isard M., 2001, P INT C COMP VIS, V2, P34, DOI 10.1109/ICCV.2001.937594; KAMEN EW, 1992, IEEE T AUTOMAT CONTR, V37, P371, DOI 10.1109/9.119640; KASTELLA K, 1996, IEEE SMC IMACS MULT, V1, P167; KASTELLA K, 1997, SPIE P ACQ TRACK POI; KASTELLA K, 1993, SPIE P, V1954, P386; KASTELLA K, 1995, IEEE T AUTOMAT CONTR, V40, P1070, DOI 10.1109/9.388686; Kastella K, 1997, IEEE T SYST MAN CY A, V27, P112, DOI 10.1109/3468.553230; KREUCHER C, 2003, SPIE INT S OPT SCI T; KREUCHER C, UNPUB IEEE T AEROSPA; Krishnamurthy V, 2001, IEEE T SIGNAL PROCES, V49, P2893, DOI 10.1109/78.969499; Krishnamurthy V, 2002, IEEE T SIGNAL PROCES, V50, P1382, DOI 10.1109/TSP.2002.1003062; LUMELSKY VJ, 1990, IEEE T ROBOTIC AUTOM, V6, P462, DOI 10.1109/70.59357; MAHLER R, 1996, SELECTED PAPERS SENS, V124, P325; MAHLER R, 1996, P 9 NAT S SENS FUS, V1, P347; MALHOTRA R, 1995, P IEEE 1995 NAT AER, V1, P86, DOI 10.1109/NAECON.1995.521917; MILLER MI, 1995, IEEE T SIGNAL PROCES, V43, P2678, DOI 10.1109/78.482117; Mori S., IEEE T AUTOMATIC CON, VAC-31; MUSICK S, 1994, PROC NAECON IEEE NAT, P606, DOI 10.1109/NAECON.1994.332850; Musick S, 1998, P SOC PHOTO-OPT INS, V3374, P26, DOI 10.1117/12.327111; Orton M, 2002, IEEE T SIGNAL PROCES, V50, P216, DOI 10.1109/78.978377; POPOLI R, 1992, MULTITARGET MULTISEN, V2; Renyi A, 1961, P 4 BERK S MATH STAT, P547; Richardson S, 1997, J ROY STAT SOC B MET, V59, P731, DOI 10.1111/1467-9868.00095; Ristic B, 2004, IEE P-RADAR SON NAV, V151, P129, DOI 10.1049/ip-rsn:20040532; SCHMAEDEKE W, 1994, P SOC PHOTO-OPT INS, V2232, P91, DOI 10.1117/12.177770; SHERTUKDE HM, 1991, IEEE T AERO ELEC SYS, V27, P582, DOI 10.1109/7.85031; Sipe MA, 2002, IEEE T PATTERN ANAL, V24, P1634, DOI 10.1109/TPAMI.2002.1114854; Stone LD, 1999, BAYESIAN MULTIPLE TA; TAO H, 1999, WORKSH VIS ALG, P53; Zhao F, 2002, IEEE SIGNAL PROC MAG, V19, P61	47	53	54	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-1684		SIGNAL PROCESS	Signal Process.	MAR	2005	85	3					607	624		10.1016/j.sigpro.2004.11.004		18	Engineering, Electrical & Electronic	Engineering	900BO	WOS:000227190600013	
J	Nagendra, S; Staubach, JB; Suydam, AJ; Ghunakikar, SJ; Akula, VR				Nagendra, S; Staubach, JB; Suydam, AJ; Ghunakikar, SJ; Akula, VR			Optimal rapid multidisciplinary response networks: RAPIDDISK	STRUCTURAL AND MULTIDISCIPLINARY OPTIMIZATION			English	Article						multidisciplinary optimization (MDO); iSIGHT; neural networks; rapid response strategy; rapiddisk; basic building block approach and disk optimization	DESIGN OPTIMIZATION	The role of uncertainty in information rich design systems is critical to the development of advanced propulsion systems. Future turbine engines would have lower lifetime operating costs similar to current evolving automotive systems. Detailed multi-physics models (thermo-fluid, structural and mechanical systems) and an operational environment are enablers of rapid correction and model-based predictive analyses. Bayesian machine learning paradigms are developed to identify the behavior of turbo-machinery components for preliminary design. The embedded models approach enables systematic evolution from individual components level to the advanced engine. The embedded models approach enables systematic evolution from individual components level to the advanced engine. A rapid response strategy is proposed, for design of turbine disks by using multidisciplinary optimization and neural networks. iSIGHT optimization software is interfaced with ANSYS to find optimum designs for a given set of design boundary conditions (rpm, live rim load, thermals, etc.). The optimum designs obtained from iSIGHT for different set of design conditions are used for machine learning and design knowledge recognition using the neural network technique. The trained network is used to predict responses for design boundary conditions. Responses predicted by the neural network are validated using ANSYS. Discrete design points are chosen from the wide design space of turbine disks. A hierarchical neural network approach provides an ability to quickly train the network and predict responses (weight, stresses, burst margin, etc.) for applied design conditions. This basic building process involves four steps starting from identifying design boundary conditions to the prediction of design shape for the disk. Sensitivity-based scaling rules are developed, to accommodate different materials for the disk. The technique is developed in RAPIDDISK, which provides an optimal preliminary shape and design attributes for a turbine disk.	United Technol Corp, AT&PD Syst Optimizat, Pratt & Whitney Engines Div, E Hartford, CT 06108 USA; InfoTech Enterprise Ltd, Software Units Layout, Hyderabad, Andhra Pradesh, India	Nagendra, S (reprint author), United Technol Corp, AT&PD Syst Optimizat, Pratt & Whitney Engines Div, 400 Main St,M-S 165-16, E Hartford, CT 06108 USA.	nagendra.somanath@pw.utc.com					Balachandran K., 1999, B KOREAN MATH SOC, V36, P1; Bishop C.M., 1995, NEURAL NETWORKS PATT; Box G. E. P., 1987, EMPIRICAL MODEL BUIL; CARPENTER WC, 1993, STRUCT OPTIMIZATION, V5, P166, DOI 10.1007/BF01743353; CHBAT NW, 1996, 96GT316 ASME; Cover T. M., 1991, ELEMENTS INFORMATION; DEMUTH H, 2001, MATLAB NEURAL NETWOR; DORNBERGER R, 2000, EUR C COMP METH APPL; FALLER WE, 1995, AIAA950529; Haffica R.T., 1998, APPL MECH REV, V51, P435; Hertz J., 1991, INTRO THEORY NEURAL; Jang J.-S. R., 1997, NEUROFUZZY SOFT COMP; KOLONAY RM, 1998, 7 AIAA USAF NASA ISS; Kosko B., 1992, NEURAL NETWORKS FUZZ; MACKAY DJC, 1992, NEURAL COMPUT, V4, P448, DOI 10.1162/neco.1992.4.3.448; MADHAMI PG, 1998, AIAA981780; MADSEN JL, 2000, AIAA J, V38; Myers R.H., 1995, RESPONSE SURFACE MET; NAGENDRA S, 1998, P 39 ASM C LONG BEAC; Neal R. M., 1996, BAYESIAN LEARNING NE; NORGAARD M, 1997, TM112197 NASA; OWEN AB, 1992, STAT SINICA, V2, P439; PAPILA N, 1999, 17 APPL AER C NORF V; Pierret S, 1999, J TURBOMACH, V121, P326; RAI MM, 1998, AERODYNAMICS DESIGN; ROSS JC, 1997, TM112193 NASA; Rummelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Sacks J., 1989, STAT SCI, V4, P409, DOI [10.1214/ss/1177012413, DOI 10.1214/SS/1177012413]; SHYY W, 1999, 35 AIAA ASME SAE ASE; SOBIESZCZANSKISOBI, 1997, STRUCT OPTIMIZATION, V14, P1; Sorensen DN, 2000, J FLUID ENG-T ASME, V122, P324; SPARKS DW, 1999, AIAA993167; Tappeta RV, 1999, STRUCT OPTIMIZATION, V18, P134, DOI 10.1007/s001580050114; Traub J. F., 1988, INFORMATION BASED CO; UNAL R, 1998, 7 ANN AIAA USAF NASA; VENTER G, 1998, AIAA J, V36, P12; YIU KFC, 1999, IN PRESS AIAA J PROP	37	3	5	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	1615-147X		STRUCT MULTIDISCIP O	Struct. Multidiscip. Optim.	MAR	2005	29	3					213	231		10.1007/s00158-004-0472-2		19	Computer Science, Interdisciplinary Applications; Engineering, Multidisciplinary; Mechanics	Computer Science; Engineering; Mechanics	907DZ	WOS:000227696800006	
J	Bisant, D				Bisant, D			An application of neural networks to sequence analysis and genre identification	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article; Proceedings Paper	17th International Florida-Artificial-Intelligence-Research-Society Conference (FLAIRS)	MAY , 2004	Miami Beach, FL	Florida Artificial Intelligence Res Soc		neural networks; genre identification; feature selection; sequence analysis; average weight magnitude; weight decay		This study borrowed a technique from molecular sequence analysis and applied it to genre identification, which is the process of determining the type or family of a given document. For example, is the document a letter, a news story, a horoscope, a joke, an advertisement, a pornographic story, etc. Genre identification allows a computer user to further filter email and web sites in a way that is totally different from topic-based methods. This study presents original research in an application of machine learning to the genre identification problem. The specific method selected for the application was neural modeling. The data for the study came from a database constructed by the author and his colleagues. The data consisted of descriptive features and the genre classification, as judged by a human, from over 5,000 different documents. Ten different genres were represented. The descriptive features consisted of 89 different measurements of each document such as average word length, the number of numeric terms, the proportion of present tense verbs, etc. The data was divided into two sets, with 75% set aside for training and 25% reserved separately for testing. The first neural network applied was a very basic single layer network that achieved 79% correct classifications on the testing data. This performance was equivalent to the previous best method on the problem, decision trees. When more complex neural networks were applied to the problem, performance increased significantly. The best performance of 86% correct classifications was achieved by a network with a single hidden layer of 300 units. Increasing the number of hidden layers, or changing the number of hidden units did not improve performance. The best score is also a significant improvement over scores obtained from topic-based filters. The neural networks were further used to determine which input features were most influential in the classifications by the networks. The average magnitude of the weights coming from each feature was computed after training. The analysis indicated that 10% of the features were not of any use to the networks. An additional 10% were very influential and were responsible for most of the performance of the networks. The remaining 80% varied between marginally useful to useful. The analysis of the features indicated that second-order information was being exploited by the networks for better performance. This means that on this problem, neural networks will outperform statistical models or other methods that only utilize first-order information.	Lab Phys Sci, College Pk, MD 20740 USA	Bisant, D (reprint author), Lab Phys Sci, College Pk, MD 20740 USA.						Biber D., 1993, COMPUT HUMANITIES, V26, P331; Hertz J., 1991, INTRO THEORY NEURAL; Kessler B., 1997, P 35 ANN M ASS COMP, P32, DOI http://dx.doi.org/10.3115/976909.979622; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sahami M., 1998, WS9805 AAAI; STAMATATOS E, 2001, COMPUTATIONAL LINGUI, V26, P471; WEBOS P, 1974, THESIS HARVARD U; WEIGEND AS, 1990 CONNECTIONISTS, P105; Yang Y., 1997, MACH LEARN, P412; *DOD 2000, IN PRESS AUT GENR ID; *DOD 2000, 2000, SUPP VECT MACH GENR	11	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014		INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	MAR	2005	19	2					199	215		10.1142/S021800140500396X		17	Computer Science, Artificial Intelligence	Computer Science	916UG	WOS:000228411100006	
J	Fic, G; Nowak, G				Fic, G; Nowak, G			The CSB approach to prediction of chemical reactions	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS			English	Article						CAOS; computer prediction of reactions; machine learning; combinatorial libraries; multicomponent reactions; CSB	ORGANIC-REACTION PREDICTION; REACTION GENERATOR; COMPUTER-PROGRAM; SYNTHESIS DESIGN; SYNTHESIS ROUTE; SYSTEM CSB; SIMULATION; CHEMISTRY; MICROCOMPUTER; IMPLEMENTATION	The methodology and recent advances in developing the chemical sense builder (CSB) system for simulation of organic reactions are presented. This system comprises two functional modules that can be used separately or in combination. Four logic-based and knowledge-based models for reaction generation and discovering constitute the first module. The second one, newly designed, provides knowledge acquisition and learning tools for exploration and derivation of knowledge that can be employed in the reaction simulation process. An overview of the CSB programming tools and a knowledge source are given. The new CSB features are illustrated by an example concerned with the generation and evaluation of example reactions. (C) 2004 Elsevier B.V. All rights reserved.	Rzeszow Univ Technol, Fac Chem, Dept Comp Chem, PL-35041 Rzeszow, Poland; Rzeszow Univ Technol, Fac Chem, Dept Phys Chem, PL-35041 Rzeszow, Poland	Fic, G (reprint author), Rzeszow Univ Technol, Fac Chem, Dept Comp Chem, 6 Powstancow Warszawy Ave, PL-35041 Rzeszow, Poland.	gfic@prz.edu.pl					AGARWAL KK, 1978, COMPUT CHEM, V2, P75, DOI 10.1016/0097-8485(78)87005-3; AZARIO P, 1990, NEW J CHEM, V14, P951; Barberis F, 1996, TETRAHEDRON, V52, P14625, DOI 10.1016/0040-4020(96)00873-3; BARONE R, 1984, NOUV J CHIM, V8, P311; BARONE R, 1991, REV ROUM CHIM, V36, P581; BARONE R, 1986, CHIMIA, V12, P436; BAUER J, 1982, J CHEM RES MINIPRINT, P3101; BAUER J., 1989, TETRAHEDRON COMPUT M, V2, P269, DOI 10.1016/0898-5529(89)90034-1; BAUER J, 1982, J CHEM RES-S, P298; BAUER J, 1982, J CHEM RES M, P3201; BERSOHN M, 1972, B CHEM SOC JPN, V45, P1897, DOI 10.1246/bcsj.45.1897; BLAIR J, 1974, TETRAHEDRON, V30, P1845, DOI 10.1016/S0040-4020(01)97318-1; BLAKE JE, 1990, J CHEM INF COMP SCI, V30, P394, DOI 10.1021/ci00068a008; BORKENT JH, 1988, J CHEM INF COMP SCI, V28, P148, DOI 10.1021/ci00059a005; COREY EJ, 1985, SCIENCE, V228, P408, DOI 10.1126/science.3838594; DONGES R, 1985, J CHEM INFORMATION C, V25, P425; Dugundji J., 1973, TOP CURR CHEM, V39, P19; ELLERMANN L, 1997, LIEBIGS ANN-RECL, V7, P1401; Fic G, 2001, COMPUT CHEM, V25, P177, DOI 10.1016/S0097-8485(00)00079-6; Fic G, 1998, COMPUT CHEM, V22, P141, DOI 10.1016/S0097-8485(97)00048-X; FLEISCHER JM, 1995, J ORG CHEM, V60, P490, DOI 10.1021/jo00108a006; FONTAIN E, 1991, J CHEM INF COMP SCI, V31, P96, DOI 10.1021/ci00001a017; FUNATSU K, 1988, TETRAHEDRON COMP MET, V1, P27, DOI 10.1016/0898-5529(88)90006-1; GASTEIGER J, 2000, J COMPUT AID MOL DES, V20, P245; GASTEIGER J, 1989, CHIM OGGI, P65; GELERNTER H, 1990, J CHEM INF COMP SCI, V30, P492, DOI 10.1021/ci00068a023; GORDEEVA EV, 1992, TETRAHEDRON, V48, P3789, DOI 10.1016/S0040-4020(01)92270-7; HAASE F, 1990, TETRAHEDRON COMPUT M, V3, P461, DOI 10.1016/0898-5529(90)90070-O; HANESSIAN S, CHIRON PROGRAM; HANESSIAN S, 1992, J CHEM INF COMP SCI, V32, P718, DOI 10.1021/ci00010a020; HENDRICKSON JB, 1992, RECL TRAV CHIM PAY B, V111, P323; HENDRICKSON JB, 1985, J AM CHEM SOC, V107, P5228, DOI 10.1021/ja00304a033; HENDRICKSON JB, 1975, J AM CHEM SOC, V97, P5784, DOI 10.1021/ja00853a023; Hendrickson JB, 1998, CHEMTECH, V28, P35; HENDRICKSON JB, 1995, J CHEM INF COMP SCI, V35, P251, DOI 10.1021/ci00024a015; Hicks MG, 1997, J CHEM INF COMP SCI, V37, P146, DOI 10.1021/ci960111a; HIPPE Z, 1985, PRZEM CHEM, V64, P331; Hippe Z., 1981, Analytica Chimica Acta, Computer Techniques and Optimization, V133, DOI 10.1016/S0003-2670(01)95433-9; HIPPE ZS, 1992, RECL TRAV CHIM PAY B, V111, P255; HIPPE ZS, 1994, FDN COMPUTING DECISI, V19, P21; HLADKA E, 1992, TOP CURR CHEM, V166, P121; Hollering R, 2000, J CHEM INF COMP SCI, V40, P482, DOI 10.1021/ci990433p; Ihlenfeldt WD, 1995, ANGEW CHEM INT EDIT, V34, P2613; JORGENSEN WL, 1990, PURE APPL CHEM, V62, P1921, DOI 10.1351/pac199062101921; KOCA J, 1989, J MATH CHEM, V3, P9; LARUENCO C, 1984, TETRAHEDRON, V40, P2721; LONG AK, 1994, J CHEM INF COMP SCI, V34, P922, DOI 10.1021/ci00020a029; MATYSKA L, 1991, J CHEM INF COMP SCI, V31, P380, DOI 10.1021/ci00003a003; MEHTA G, 1998, EUR J ORG CHEM, V7, P1409; MILLER TM, 1994, J CHEM INF COMP SCI, V34, P653, DOI 10.1021/ci00019a027; MOLL R, 1994, J CHEM INF COMP SCI, V34, P117, DOI 10.1021/ci00017a014; MOOCK TE, 1988, TETRAHEDRON COMPUT M, V1, P117, DOI 10.1016/0898-5529(88)90016-4; MOREAU G, 1978, NOUV J CHIM, V2, P187; NAKAYAMA T, 1991, J CHEM INF COMP SCI, V31, P495, DOI 10.1021/ci00004a011; Nowak G, 1997, COMPUT CHEM, V21, P445, DOI 10.1016/S0097-8485(97)00020-X; NOWAK G, UNPUB APPL CSB PREDI; Nowak G, 1998, COMPUT CHEM, V22, P147, DOI 10.1016/S0097-8485(97)00047-8; Ott MA, 1997, J CHEM INF COMP SCI, V37, P98, DOI 10.1021/ci9600972; OTT MA, OVERVIEW LHASA SYSTE; PARLOW A, 1990, J CHEM INF COMP SCI, V30, P400, DOI 10.1021/ci00068a009; ROSE P, 1990, ANAL CHIM ACTA, V235, P163, DOI 10.1016/S0003-2670(00)82071-1; Satoh H, 1996, J CHEM INF COMP SCI, V36, P173, DOI 10.1021/ci950058a; SATOH K, 1997, J CHEM SOFTWARE, V4, P101; SCHUBERT W, 1979, INFORMAL COMMUNICATI, V6, P213; SELLO G, 1994, J CHEM INF COMP SCI, V34, P120, DOI 10.1021/ci00017a015; SIEBER W, 1988, CHEM STRUCTURES INT, P361; SORKAU E, 1986, CHEM ANAL-WARSAW, V31, P377; TAKAHASHI M, 1990, J CHEM INF COMP SCI, V30, P436, DOI 10.1021/ci00068a015; UCHIMARU T, 1999, J NATL I MAT CHEM RE, V7, P177; WEISE A, 1975, Z CHEM, V15, P333; WIPKE WT, 1978, ARTIF INTELL, V11, P173, DOI 10.1016/0004-3702(78)90016-4; YANAKA M, 1990, TETRAHEDRON COMPUT M, V3, P359, DOI 10.1016/0898-5529(90)90062-D; ZASS E, 1998, ENCY COMPUTATIONAL C, V4, P2402; ZEFIROV NS, 1988, J CHEM INF COMP SCI, V28, P188, DOI 10.1021/ci00060a004; ZEFIROV NS, 1994, J CHEM INF COMP SCI, V34, P994, DOI 10.1021/ci00020a038	75	1	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-7439		CHEMOMETR INTELL LAB	Chemometrics Intell. Lab. Syst.	FEB 28	2005	75	2					137	148		10.1016/j.chemolab.2004.05.013		12	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	898CZ	WOS:000227055000003	
J	Guo, QH; Kelly, M; Graham, CH				Guo, QH; Kelly, M; Graham, CH			Support vector machines for predicting distribution of sudden oak death in California	ECOLOGICAL MODELLING			English	Article						geographic information systems; support vector machines; potential disease spread; sudden oak death	GENERALIZED ADDITIVE-MODELS; POTENTIAL DISTRIBUTION; HABITAT MODELS; CHAGAS-DISEASE; NORTH-AMERICA; ABSENCE DATA; CLASSIFICATION; ATTRIBUTES; GENERATION; DYNAMICS	In the central California coastal forests, a newly discovered virulent pathogen (Phytophthora ramorum) has killed hundreds of thousands of native oak trees. Predicting the potential distribution of the disease in California remains an urgent demand of regulators and scientists. Most methods used to map potential ranges of species (e.g. multivariate or logistic regression) require both presence and absence data, the latter of which are not always feasibly collected, and thus the methods often require the generation of 'pseudo' absence data. Other methods (e.g. BIOCLIM and DOMAIN) seek to model the presence-only data directly. In this study, we present alternative methods to conventional approaches to modeling by developing support vector machines (SVMs), which are the new generation of machine learning algorithms used to find optimal separability between classes within datasets, to predict the potential distribution of Sudden Oak Death in California. We compared the performances of two types of SVMs models: two-class SVMs with 'pseudo' absence data and one-class SVMs. Both models performed well. The one-class SVMs have a slightly better true-positive rate (0.9272 +/- 0.0460 S.D.) than the two-class SVMs (0.9105 +/- 0.0712 S.D.). However, the area predicted to be at risk for the disease using the one-class SVMs (18,441 km(2)) is much larger than that of the two-class SVMs (13,828 km(2)). Both models show that the majority of disease risk will occur in coastal areas. Compared with the results of two-class SVMs, the one-class SVMs predict a potential risk in the foothills of the Sierra Nevada mountain ranges; much greater risks are also found in Los Angles and Humboldt Counties. We believe the support vector machines when coupled with geographic information system (GIS) will be a useful method to deal with presence-only data in ecological analysis over a range of scales. (C) 2004 Elsevier B.V. All rights reserved.	Univ Calif Berkeley, Dept Environm Sci Policy & Management, Berkeley, CA 94720 USA; Univ Calif Berkeley, Museum Vertebrate Zool, Berkeley, CA 94720 USA; SUNY Stony Brook, Dept Ecol & Evolut, Stony Brook, NY 11794 USA	Guo, QH (reprint author), Univ Calif Berkeley, Dept Environm Sci Policy & Management, 151 Hilgard Hall 3110, Berkeley, CA 94720 USA.	gqh@nature.berkeley.edu; mkelly@nature.berkeley.edu; cgraham@life.bio.sunysb.edu	Graham, Catherine/A-9560-2011				Beard CB, 2003, EMERG INFECT DIS, V9, P103; Bian L, 1997, PHOTOGRAMM ENG REM S, V63, P161; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; BUSBY JR, 1986, AUST J ECOL, V11, P1, DOI 10.1111/j.1442-9993.1986.tb00912.x; CARPENTER G, 1993, BIODIVERS CONSERV, V2, P667, DOI 10.1007/BF00051966; CHANG C.C., 2001, LIBSVM LIBRARY SUPPO; Cristianini N, 2002, AI MAG, V23, P31; DAVIDSON J, 2001, TRANSMISSION PHYTOPH, pS108; DAVIDSON JM, 2002, 5 S OAK WOODL USDA F; Davis FW, 1998, CALIFORNIA GAP ANAL; De'ath G, 2000, ECOLOGY, V81, P3178, DOI 10.1890/0012-9658(2000)081[3178:CARTAP]2.0.CO;2; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; Engler R, 2004, J APPL ECOL, V41, P263, DOI 10.1111/j.0021-8901.2004.00881.x; Fabricius K, 2001, CORAL REEFS, V19, P303; Felicisimo AM, 2002, PHOTOGRAMM ENG REM S, V68, P455; Fielding AH, 1995, CONSERV BIOL, V9, P1466, DOI 10.1046/j.1523-1739.1995.09061466.x; Fonseca M, 2002, ECOL APPL, V12, P218, DOI 10.2307/3061148; Franklin J, 1995, PROG PHYS GEOG, V19, P474, DOI 10.1177/030913339501900403; Frescino TS, 2001, J VEG SCI, V12, P15, DOI 10.2307/3236670; GARBELOTTO M, 2001, CALIFORNIA AGR   JAN, P9; Guisan A, 2002, ECOL MODEL, V157, P89, DOI 10.1016/S0304-3800(02)00204-1; Hastie T, 2001, ELEMENTS STAT LEARNI; Hirzel AH, 2002, ECOLOGY, V83, P2027, DOI 10.1890/0012-9658(2002)083[2027:ENFAHT]2.0.CO;2; Hirzel AH, 2001, ECOL MODEL, V145, P111, DOI 10.1016/S0304-3800(01)00396-9; Huang C, 2002, INT J REMOTE SENS, V23, P725, DOI 10.1080/01431160110040323; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Kelly M., 2003, COMPUTERS ENV URBAN, V27, P527; Kelly NM, 2001, AQUAT CONSERV, V11, P437, DOI 10.1002/aqc.494; KELLY NM, 2002, USDA FOREST SERV, P799; Lai C, 2002, LECT NOTES COMPUT SC, V2364, P212; LIVINGSTON SA, 1990, J WILDLIFE MANAGE, V54, P644, DOI 10.2307/3809363; Manel S, 1999, J APPL ECOL, V36, P734, DOI 10.1046/j.1365-2664.1999.00440.x; Manevitz LM, 2002, J MACH LEARN RES, V2, P139, DOI 10.1162/15324430260185574; Mjolsness E, 2001, SCIENCE, V293, P2051, DOI 10.1126/science.293.5537.2051; MLADENOFF DJ, 1995, CONSERV BIOL, V9, P279, DOI 10.1046/j.1523-1739.1995.9020279.x; Moisen GG, 2002, ECOL MODEL, V157, P209, DOI 10.1016/S0304-3800(02)00197-7; Paruelo JM, 1996, ECOL APPL, V6, P1212, DOI 10.2307/2269602; Peterson AT, 2002, EMERG INFECT DIS, V8, P662; Peterson AT, 2001, BIOSCIENCE, V51, P363, DOI 10.1641/0006-3568(2001)051[0363:PSIUEN]2.0.CO;2; RIZZO D, 2002, CALIFORNIA PLANT DIS, P205; Rizzo DM, 2003, FRONT ECOL ENVIRON, V1, P197, DOI 10.2307/3868064; Scholkopf B., 1999, MSRTR9987; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Spitz F, 1999, J APPL ECOL, V36, P317, DOI 10.1046/j.1365-2664.1999.00400.x; Stockwell D, 1999, INT J GEOGR INF SCI, V13, P143, DOI 10.1080/136588199241391; SUTHERST RW, 1985, AGR ECOSYST ENVIRON, V13, P281, DOI 10.1016/0167-8809(85)90016-7; SWIECKI TJ, 2001, OBSERVATIONS COMMENT; TAX D, 1999, PATTERN RECOGN, P1191; Tax DMJ, 2002, J MACH LEARN RES, V2, P155, DOI 10.1162/15324430260185583; Tax DMJ, 1999, PATTERN RECOGN LETT, V20, P1191, DOI 10.1016/S0167-8655(99)00087-2; Thrall PH, 1999, EVOL ECOL RES, V1, P681; Vapnik V. N, 1995, NATURE STAT LEARNING; Webb A.R., 2002, STAT PATTERN RECOGNI; Welk E, 2002, DIVERS DISTRIB, V8, P219, DOI 10.1046/j.1472-4642.2002.00144.x; Weltzin JF, 2000, ECOLOGY, V81, P1902, DOI 10.1890/0012-9658(2000)081[1902:IOPRFS]2.0.CO;2; Yonow T, 2004, ECOL MODEL, V173, P9, DOI 10.1016/S0304-3800(03)00306-5; Zaniewski AE, 2002, ECOL MODEL, V157, P261, DOI 10.1016/S0304-3800(02)00199-0	57	73	82	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3800		ECOL MODEL	Ecol. Model.	FEB 25	2005	182	1					75	90		10.1016/j.ecolmodel.2004.07.012		16	Ecology	Environmental Sciences & Ecology	885LN	WOS:000226158200006	
J	Beiko, RG; Charlebois, RL				Beiko, RG; Charlebois, RL			GANN: Genetic algorithm neural networks for the detection of conserved combinations of features in DNA	BMC BIOINFORMATICS			English	Article							AMINO-ACID-SEQUENCES; FACTOR-BINDING SITES; ESCHERICHIA-COLI; PROMOTER SEQUENCES; ADENINE TRACT; TRANSCRIPTION; LATTICE; RECOGNITION; PREDICTION; DODECAMER	Background: The multitude of motif detection algorithms developed to date have largely focused on the detection of patterns in primary sequence. Since sequence-dependent DNA structure and flexibility may also play a role in protein-DNA interactions, the simultaneous exploration of sequence-and structure-based hypotheses about the composition of binding sites and the ordering of features in a regulatory region should be considered as well. The consideration of structural features requires the development of new detection tools that can deal with data types other than primary sequence. Results: GANN ( available at http://bioinformatics.org.au/gann) is a machine learning tool for the detection of conserved features in DNA. The software suite contains programs to extract different regions of genomic DNA from flat files and convert these sequences to indices that reflect sequence and structural composition or the presence of specific protein binding sites. The machine learning component allows the classification of different types of sequences based on subsamples of these indices, and can identify the best combinations of indices and machine learning architecture for sequence discrimination. Another key feature of GANN is the replicated splitting of data into training and test sets, and the implementation of negative controls. In validation experiments, GANN successfully merged important sequence and structural features to yield good predictive models for synthetic and real regulatory regions. Conclusion: GANN is a flexible tool that can search through large sets of sequence and structural feature combinations to identify those that best characterize a set of sequences.	Univ Queensland, Inst Mol Biosci, Brisbane, Qld 4072, Australia; Univ Ottawa, Dept Biol, Ottawa, ON K1N 6N5, Canada; Dalhousie Univ, Dept Biochem & Mol Biol, Halifax, NS B3H 1X5, Canada	Beiko, RG (reprint author), Univ Queensland, Inst Mol Biosci, Brisbane, Qld 4072, Australia.	r.beiko@imb.uq.edu.au; rlcharlebois@neurogadgets.com					Aerts S, 2004, BIOINFORMATICS, V20, P1974, DOI 10.1093/bioinformatics/bth179; AYERS DG, 1989, J MOL BIOL, V207, P749, DOI 10.1016/0022-2836(89)90241-6; Baldi P, 1998, Proc Int Conf Intell Syst Mol Biol, V6, P35; Benos PV, 2002, NUCLEIC ACIDS RES, V30, P4442, DOI 10.1093/nar/gkf578; BERG OG, 1987, J MOL BIOL, V193, P723, DOI 10.1016/0022-2836(87)90354-8; Bulyk ML, 2002, NUCLEIC ACIDS RES, V30, P1255, DOI 10.1093/nar/30.5.1255; Charlebois RL, 2003, FEMS MICROBIOL LETT, V225, P213, DOI 10.1016/S0378-1097(03)00512-3; DICKERSON RE, 1994, P NATL ACAD SCI USA, V91, P3579, DOI 10.1073/pnas.91.9.3579; DIGABRIELE AD, 1993, J MOL BIOL, V231, P1024, DOI 10.1006/jmbi.1993.1349; DIGABRIELE AD, 1989, P NATL ACAD SCI USA, V86, P1816, DOI 10.1073/pnas.86.6.1816; Frith MC, 2003, NUCLEIC ACIDS RES, V31, P3666, DOI 10.1093/nar/gkg540; GORIN AA, 1995, J MOL BIOL, V247, P34, DOI 10.1006/jmbi.1994.0120; Guha M, 2001, CELL SIGNAL, V13, P85, DOI 10.1016/S0898-6568(00)00149-2; Hertz GZ, 1999, BIOINFORMATICS, V15, P563, DOI 10.1093/bioinformatics/15.7.563; Huerta AM, 2003, J MOL BIOL, V333, P261, DOI 10.1016/j.jmb.2003.07.017; Kadam S, 2002, CURR OPIN CELL BIOL, V14, P262, DOI 10.1016/S0955-0674(02)00330-7; Kel-Margoulis O V, 2002, Pac Symp Biocomput, P187; Knudsen S, 1999, BIOINFORMATICS, V15, P356, DOI 10.1093/bioinformatics/15.5.356; Lemmon AR, 2002, P NATL ACAD SCI USA, V99, P10516, DOI 10.1073/pnas.162224399; LISSER S, 1993, NUCLEIC ACIDS RES, V21, P1507, DOI 10.1093/nar/21.7.1507; Lohmann R, 1996, BIOPOLYMERS, V38, P13, DOI 10.1002/(SICI)1097-0282(199601)38:1<13::AID-BIP2>3.0.CO;2-Z; LOHMANN R, 1993, BIOL CYBERN, V69, P319, DOI 10.1007/BF00203128; LOHMANN R, 1994, PROTEIN SCI, V3, P1597; Man TK, 2001, NUCLEIC ACIDS RES, V29, P2471, DOI 10.1093/nar/29.12.2471; Matys V, 2003, NUCLEIC ACIDS RES, V31, P374, DOI 10.1093/nar/gkg108; Mazur Alexey K, 2002, Phys Rev E Stat Nonlin Soft Matter Phys, V66, P011917, DOI 10.1103/PhysRevE.66.011917; Minsky M, 1969, PERCEPTRONS; Notredame C, 1996, NUCLEIC ACIDS RES, V24, P1515, DOI 10.1093/nar/24.8.1515; Olson WK, 1998, P NATL ACAD SCI USA, V95, P11163, DOI 10.1073/pnas.95.19.11163; Ponomarenko JV, 1999, BIOINFORMATICS, V15, P654, DOI 10.1093/bioinformatics/15.7.654; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; SALGADO H, 2004, NUCL ACIDS RES; SATCHWELL SC, 1986, J MOL BIOL, V191, P659, DOI 10.1016/0022-2836(86)90452-3; Steffen Nicholas R, 2002, Genome Inform, V13, P153; STORMO GD, 1989, P NATL ACAD SCI USA, V86, P1183, DOI 10.1073/pnas.86.4.1183; Struhl K, 1999, CELL, V98, P1, DOI 10.1016/S0092-8674(00)80599-1; Travers AA, 2004, PHILOS T ROY SOC A, V362, P1423, DOI 10.1098/rsta.2004.1390; Udalova IA, 2002, P NATL ACAD SCI USA, V99, P8167, DOI 10.1073/pnas.102674699; Wells Christine A, 2003, BMC Immunol, V4, P5, DOI 10.1186/1471-2172-4-5; Wosten MMSM, 1998, FEMS MICROBIOL REV, V22, P127, DOI 10.1016/S0168-6445(98)00011-4	40	11	12	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	FEB 22	2005	6								36	10.1186/1471-2105-6-36		12	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	908MI	WOS:000227790700002	
J	Zwir, I; Shin, D; Kato, A; Nishino, K; Latifi, T; Solomon, F; Hare, JM; Huang, H; Groisman, EA				Zwir, I; Shin, D; Kato, A; Nishino, K; Latifi, T; Solomon, F; Hare, JM; Huang, H; Groisman, EA			Dissecting the PhoP regulatory network of Escherichia coli and Salmonella enterica	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article						promoter; machine learning; gene transcription; acid pH	COMPLETE GENOME SEQUENCE; 2-COMPONENT SYSTEM; GENE-EXPRESSION; MOLECULAR CHARACTERIZATION; RESPONSE REGULATOR; ACID RESISTANCE; BINDING SITES; PROTEIN; SIGNAL; MG2+	Genetic and genomic approaches have been successfully used to assign genes to distinct regulatory networks. However, the present challenge of distinguishing differentially regulated genes within a network is particularly hard because members of a given network tend to have similar regulatory features. We have addressed this challenge by developing a method, termed Gene Promoter Scan, that discriminates coregulated promoters by simultaneously considering both multiple cis promoter features and gene expression. Here, we apply this method to probe the regulatory networks governed by the PhoP/PhoQ two-component system in the enteric bacteria Escherichia coli and Salmonella enterica. Our analysis uncovered members of the PhoP regulon and interactions with other regulatory systems that were not discovered in previous approaches. The predictions made by Gene Promoter Scan were experimentally validated to establish that the PhoP protein uses multiple mechanisms to control gene transcription, regulates acid resistance determinants, and is a central element in a highly connected network.	Washington Univ, Sch Med, Howard Hughes Med Inst, Dept Mol Microbiol, St Louis, MO 63110 USA	Groisman, EA (reprint author), Washington Univ, Sch Med, Howard Hughes Med Inst, Dept Mol Microbiol, Campus Box 8230,660 S Euclid Ave, St Louis, MO 63110 USA.	groisman@borcim.wustl.edu	Kato, Akinori/B-8752-2013				Beer MA, 2004, CELL, V117, P185, DOI 10.1016/S0092-8674(04)00304-6; Blattner FR, 1997, SCIENCE, V277, P1453, DOI 10.1126/science.277.5331.1453; Castelli ME, 2000, J BIOL CHEM, V275, P22948, DOI 10.1074/jbc.M909335199; Chamnongpol S, 2003, J MOL BIOL, V325, P795, DOI 10.1016/S0022-2836(02)01268-8; CHEESEMAN P, 1994, SELECTING MODELS DAT, V4; Conlon EM, 2003, P NATL ACAD SCI USA, V100, P3339, DOI 10.1073/pnas.0630591100; Cook DJ, 2001, IEEE ENG MED BIOL, V20, P67, DOI 10.1109/51.940050; Eguchi Y, 2004, J BACTERIOL, V186, P3006, DOI 10.1128/JB.186.10.3006-3014.2004; Gasch AP, 2002, GENOME BIOL, V3; Groisman EA, 2001, J BACTERIOL, V183, P1835, DOI 10.1128/JB.183.6.1835-1842.2001; GROISMAN EA, 1992, J BACTERIOL, V174, P486; Groisman EA, 1998, BIOESSAYS, V20, P96, DOI 10.1002/(SICI)1521-1878(199801)20:1<96::AID-BIES13>3.3.CO;2-J; Hertz GZ, 1999, BIOINFORMATICS, V15, P563, DOI 10.1093/bioinformatics/15.7.563; Ho DL, 2004, J BIOL CHEM, V279, P39146, DOI 10.1074/jbc.M404565200; Kato A, 2004, GENE DEV, V18, P2302, DOI 10.1101/gad.1230804; Kato A, 1999, J BACTERIOL, V181, P5516; Kato A, 2003, P NATL ACAD SCI USA, V100, P4706, DOI 10.1073/pnas.0836837100; Kox LFF, 2000, EMBO J, V19, P1861, DOI 10.1093/emboj/19.8.1861; Lejona S, 2003, J BACTERIOL, V185, P6287, DOI 10.1128/JB.185.21.6287-6294.2003; Leung TH, 2004, CELL, V118, P453, DOI 10.1016/j.cell.2004.08.007; Li C, 2001, P NATL ACAD SCI USA, V98, P31, DOI 10.1073/pnas.011404098; Ma Z, 2002, J BACTERIOL, V184, P7001, DOI 10.1128/JB.184.24.7001-7012.2002; Martinez-Antonio A, 2003, CURR OPIN MICROBIOL, V6, P482, DOI 10.1016/j.mib.2003.09.002; Masuda N, 2002, J BACTERIOL, V184, P6225, DOI 10.1128/JB.184.22.6225-6234.2002; Masuda N, 2003, MOL MICROBIOL, V48, P699, DOI 10.1046/j.1365-2958.2003.03477.x; McClelland M, 2001, NATURE, V413, P852, DOI 10.1038/35101614; McCue LA, 2001, NUCLEIC ACIDS RES, V29, P774, DOI 10.1093/nar/29.3.774; Minagawa S, 2003, J BACTERIOL, V185, P3696, DOI 10.1128/JB.185.13.3696-3702.2003; Mitchell T, 1997, MACHINE LEARNING; Montagne M, 2001, J BACTERIOL, V183, P1787, DOI 10.1128/JB.183.5.1787-1791.2001; Mouslim C, 2003, J BIOL CHEM, V278, P50588, DOI 10.1074/jbc.M309433200; Nadon R, 2002, TRENDS GENET, V18, P265, DOI 10.1016/S0168-9525(02)02665-3; Oshima T, 2002, MOL MICROBIOL, V46, P281, DOI 10.1046/j.1365-2958.2002.03170.x; Pedrycz W., 1998, HDB FUZZY COMPUTATIO; Salgado H, 2001, NUCLEIC ACIDS RES, V29, P72, DOI 10.1093/nar/29.1.72; Shin D, 2005, J BIOL CHEM, V280, P4089; Stormo GD, 2000, BIOINFORMATICS, V16, P16, DOI 10.1093/bioinformatics/16.1.16; Tucker DL, 2003, J BACTERIOL, V185, P3190, DOI 10.1128/JB.185.10.3190-3201.2003; Tucker DL, 2002, J BACTERIOL, V184, P6551, DOI 10.1128/JB.184.23.6551-6558.2002; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Yamamoto K, 2002, MOL MICROBIOL, V45, P423, DOI 10.1046/j.1365-2958.2002.03017.x	41	106	110	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424		P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	FEB 22	2005	102	8					2862	2867		10.1073/pnas.0408238102		6	Multidisciplinary Sciences	Science & Technology - Other Topics	900RQ	WOS:000227232400036	
J	Kasturi, J; Acharya, R				Kasturi, J; Acharya, R			Clustering of diverse genomic data using information fusion	BIOINFORMATICS			English	Article; Proceedings Paper	19th ACM Symposium on Applied Computing	MAR 14-17, 2004	Nicosia, CYPRUS	ACM			GENE-EXPRESSION DATA; REGULATORY ELEMENTS; SACCHAROMYCES-CEREVISIAE; REGIONS; IDENTIFICATION; SEQUENCES; PATTERNS; MOTIFS; SCALE	Motivation: Genome sequencing projects and high-through-put technologies like DNA and Protein arrays have resulted in a very large amount of information-rich data. Microarray experimental data are a valuable, but limited source for inferring gene regulation mechanisms on a genomic scale. Additional information such as promoter sequences of genes/DNA binding motifs, gene ontologies, and location data, when combined with gene expression analysis can increase the statistical significance of the finding. This paper introduces a machine learning approach to information fusion for combining heterogeneous genomic data. The algorithm uses an unsupervised joint learning mechanism that identifies clusters of genes using the combined data. Results: The correlation between gene expression time-series patterns obtained from different experimental conditions and the presence of several distinct and repeated motifs in their upstream sequences is examined here using publicly available yeast cell-cycle data. The results show that the combined learning approach taken here identifies correlated genes effectively. The algorithm provides an automated clustering method, but allows the user to specify apriori the influence of each data type on the final clustering using probabilities.	Penn State Univ, Dept Comp Sci & Engn, University Pk, PA 16802 USA	Kasturi, J (reprint author), Penn State Univ, Dept Comp Sci & Engn, University Pk, PA 16802 USA.	jkasturi@cse.psu.edu					Babenko VN, 1999, BIOINFORMATICS, V15, P644, DOI 10.1093/bioinformatics/15.7.644; Brazma A, 1998, GENOME RES, V8, P1202; Brazma A, 2000, FEBS LETT, V480, P17, DOI 10.1016/S0014-5793(00)01772-5; Bussemaker HJ, 2001, NAT GENET, V27, P167, DOI 10.1038/84792; Chiang D Y, 2001, Bioinformatics, V17 Suppl 1, pS49; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Fickett JW, 2000, CURR OPIN BIOTECH, V11, P19, DOI 10.1016/S0958-1669(99)00049-X; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Holmes I, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P202; Hughes JD, 2000, J MOL BIOL, V296, P1205, DOI 10.1006/jmbi.2000.3519; Jakt LM, 2001, GENOME RES, V11, P112, DOI 10.1101/gr.148301; Kasturi J, 2003, BIOINFORMATICS, V19, P449, DOI 10.1093/bioinformatics/btg020; Kellis M, 2003, NATURE, V423, P241, DOI 10.1038/nature01644; Kohonen T., 1995, SPRINGER SERIES INFO; Murali T, 2003, PAC S BIOCOMPUT, V8, P77; Park PJ, 2002, BIOINFORMATICS, V18, P1576, DOI 10.1093/bioinformatics/18.12.1576; Roth FP, 1998, NAT BIOTECHNOL, V16, P939, DOI 10.1038/nbt1098-939; Segal E, 2002, P 6 INT C RES COMP M, P263, DOI 10.1145/565196.565231; Sherlock G, 2000, CURR OPIN IMMUNOL, V12, P201, DOI 10.1016/S0952-7915(99)00074-6; Spellman PT, 1998, MOL BIOL CELL, V9, P3273	20	11	13	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	FEB 15	2005	21	4					423	429		10.1093/bioinformatics/bti186		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	899EF	WOS:000227127000001	
J	Androulakis, IP				Androulakis, IP			Selecting maximally informative genes	COMPUTERS & CHEMICAL ENGINEERING			English	Article						maximally informative genes; microarray experiments; genetic information; machine learning; optimization	EXPRESSION PATTERNS; MOLECULAR CLASSIFICATION; OLIGONUCLEOTIDE ARRAYS; MICROARRAY; CANCER; PREDICTION; ALGORITHMS; GENOME; TUMOR	Microarray experiments are emerging as one of the main driving forces in modem biology. By allowing the simultaneous monitoring of the expression of the entire genome for a given organism, array experiments provide tremendous insight into the fundamental biological processes that translate genetic information. One of the major challenges is to identify computationally efficient and biologically meaningful analysis approaches to extract the most informative and unbiased components of the microarray data. This process is complicated by the fact that a number of uncertainties are associated with array experiments. Therefore, the assumption of the existence of a unique computational descriptive model needs to be challenged. In this paper, we introduce a framework that integrates machine learning and optimization techniques for the selection of maximally informative genes in microarray expression experiments. The fundamental premise of the approach is that maximally informative genes are the ones that lead to least complex descriptive and predictive models. We propose a methodology, based on decision trees, which identifies ensembles of groups of maximally informative genes. We raise a number of computational issues that need to be comprehensively addressed and illustrate the approach by analyzing recently published microarray experimental data. (c) 2004 Elsevier Ltd. All rights reserved.	Rutgers State Univ, Dept Biomed Engn, Piscataway, NJ 08854 USA	Androulakis, IP (reprint author), Rutgers State Univ, Dept Biomed Engn, 617 Browser Rd, Piscataway, NJ 08854 USA.	yannis@rci.rutgers.edu					Aarts E., 1997, LOCAL SEARCH COMBINA; Agrafiotis DK, 1997, J CHEM INF COMP SCI, V37, P841, DOI 10.1021/ci9700337; Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Allander SV, 2001, CANCER RES, V61, P8624; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; ANDROULAKIS IP, 2004, INFORMATION GENE SEL; Bassett DE, 1999, NAT GENET, V21, P51, DOI 10.1038/4478; Bittner M, 2000, NATURE, V406, P536, DOI 10.1038/35020115; Bowtell DDL, 1999, NAT GENET, V21, P25, DOI 10.1038/4455; BRADLEY P, 1998, P 13 INT C MACH LEAR, P820; BREIMAN L, 1984, CLASSISIFICATION REG; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Brown PO, 1999, NAT GENET, V21, P33, DOI 10.1038/4462; Burnham K. P., 1998, MODEL SELECTION INFE; Cheung VG, 1999, NAT GENET, V21, P15, DOI 10.1038/4439; Deutsch JM, 2003, BIOINFORMATICS, V19, P45, DOI 10.1093/bioinformatics/19.1.45; Dickson C, 2000, BREAST CANCER RES, V2, P191, DOI 10.1186/bcr53; DIETTERCH TG, 2000, P 1 INT WORKSH MULT; DUDOIT A, 2000, 578 STANF U; FAYYAD UM, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P749; FLOUDAS DC, 2000, DETERMINISTIC GLOBAL; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; HATZIMANIKATIS V, 1999, METAB ENG, V1, pE1; HO TK, 1998, P 14 INT C PATT REC, P545; HO TK, 2000, P 1 INT WORKSH MULT, P21; Ho TK, 2002, PATTERN ANAL APPL, V5, P102, DOI 10.1007/s100440200009; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; Hwang DH, 2002, BIOINFORMATICS, V18, P1184, DOI 10.1093/bioinformatics/18.9.1184; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Kafatos FC, 2002, J MOL BIOL, V319, P861, DOI 10.1016/S0022-2836(02)00427-8; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; KOHAVI R, 1995, WRAPPERS FRATURE SUB; KOVAR H, 1990, ONCOGENE, V5, P1067; Lee MLT, 2000, P NATL ACAD SCI USA, V97, P9834, DOI 10.1073/pnas.97.18.9834; Li W, 2002, METHODS MICROARRAY D, P137; Lipshutz RJ, 1999, NAT GENET, V21, P20, DOI 10.1038/4447; Liu H., 2000, FEATURE SELECTION KN; Luo J, 2001, CANCER RES, V61, P4683; NARENDRA P, 1977, IEEE T COMPUT, V26, P917; PAN W, 2002, GENOME BIOL, V3, P1; Perou CM, 1999, P NATL ACAD SCI USA, V96, P9212, DOI 10.1073/pnas.96.16.9212; Pollack JR, 1999, NAT GENET, V23, P41; QUINLAN R, 1993, C4 5 PROGRAMS MACH L; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; Schadt E E, 2001, J Cell Biochem Suppl, VSuppl 37, P120; SCHENA M, 1995, SCIENCE, V270, P467, DOI 10.1126/science.270.5235.467; TRUNK GV, 1979, IEEE T PATTERN ANAL, V1, P306; Tu Y, 2002, P NATL ACAD SCI USA, V99, P14031, DOI 10.1073/pnas.222164199; Yang H, 2003, P NATL ACAD SCI USA, V100, P1122, DOI 10.1073/pnas.0237337100	50	5	6	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0098-1354		COMPUT CHEM ENG	Comput. Chem. Eng.	FEB 15	2005	29	3					535	546		10.1016/j.compchemeng.2004.08.037		12	Computer Science, Interdisciplinary Applications; Engineering, Chemical	Computer Science; Engineering	917BS	WOS:000228431500013	
J	Jemwa, GT; Aldrich, C				Jemwa, GT; Aldrich, C			Improving process operations using support vector machines and decision trees	AICHE JOURNAL			English	Article							PATTERN-RECOGNITION; DIAGNOSIS	Statistical pattern-recognition methods are now widely applied in the analysis of process systems to achieve predictable and stable operating conditions. For example, multivariate statistical process control (MSPC) techniques use historical operating data to detect abnormal events, and assist engineers to focus their troubleshooting efforts to reduced subsets of variables in an otherwise broad operational space. Through an iterative process, it is hoped that the system variability remains bounded. Usually only a few samples collected under a state of statistical control are of interest, whereas the rest, which may be used to uncover potential improvement opportunities, are ignored. Beyond statistical control, an additional step is required to reduce the dispersion of process quality variables attributed to common causes. To achieve this goal, common and sustained causes not identified by MSPC must be interrogated. In this paper, a methodology based on kernel-based machine learning concepts is proposed to identify decision boundaries. A sparse set of instances or exemplars is identified that define a linear decision boundary in a feature space, which is equivalent to defining a nonlinear decision function in the associated input space. This is extended to defining operating strategies by integrating inductive learning into a decision support framework. Such an extension is founded on the fact that the success or failure of state-of-the-art approaches are invariably linked to the presence or absence of useful knowledge embedded in the system. (C) 2005 American Institute of Chemical Engineers.	Univ Stellenbosch, Dept Proc Engn, ZA-7602 Stellenbosch, South Africa	Aldrich, C (reprint author), Univ Stellenbosch, Dept Proc Engn, ZA-7602 Stellenbosch, South Africa.	ca1@sun.ac.za					BAKSHI BR, 1994, COMPUT CHEM ENG, V18, P303, DOI 10.1016/0098-1354(94)85029-1; BREIMAN L., 1993, CLASSIFICATION REGRE; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Cawley G. C., 2000, MATLAB SUPPORT VECTO; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cristianini N., 2000, INTRO SUPPORT VECTOR; Fletcher R., 1989, PRACTICAL METHODS OP; FUKUNAGAA K, 1990, INTRO STAT PATTERN R; GUNN SR, 1997, P LECT NOTES COMPUTE, V1208, P313; Haykin S., 1999, NEURAL NETWORKS COMP; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; HUNTER JS, 1986, J QUAL TECHNOL, V18, P203; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; KOURTI T, 1995, J PROCESS CONTR, V5, P277, DOI 10.1016/0959-1524(95)00019-M; KRESTA JV, 1991, CAN J CHEM ENG, V69, P35; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Pearson RK, 2001, J PROCESS CONTR, V11, P179, DOI 10.1016/S0959-1524(00)00046-9; Platt JC, 2000, ADV NEUR IN, V12, P547; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1990, IEEE T SYST MAN CYB, V20, P339, DOI 10.1109/21.52545; Raich A, 1996, AICHE J, V42, P995, DOI 10.1002/aic.690420412; SARAIVA PM, 1992, AICHE J, V38, P161, DOI 10.1002/aic.690380202; Scholkopf B., 2002, LEARNING KERNELS; SHEWART WA, 1931, ECON CONTROL QUALITY; Utgoff P. E., 1989, Machine Learning, V4, DOI 10.1023/A:1022699900025; Vapnik V. N, 1995, NATURE STAT LEARNING; Vapnik VN, 1998, STAT LEARNING THEORY; Woodward R.H., 1964, CUMULATIVE SUM TECHN	28	8	8	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	0001-1541		AICHE J	AICHE J.	FEB	2005	51	2					526	543		10.1002/aic.10315		18	Engineering, Chemical	Engineering	893UC	WOS:000226743800015	
J	Takeuchi, K; Collier, N				Takeuchi, K; Collier, N			Bio-medical entity extraction using support vector machines	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						text mining; support vector machines; machine learning; multi-classifier; natural language processing; named entity; MEDLINE		Objective: Support vector machines (SVMs) have achieved state-of-the-art performance in several classification tasks. In this article we apply them to the identification and semantic annotation of scientific and technical terminology in the domain of molecular biology. This illustrates the extensibility of the traditional named entity task to special domains with large-scale terminologies such as those in medicine and related disciplines. Methods and materials: The foundation for the model is a sample of text annotated by a domain expert according to an ontology of concepts, properties and relations. The model then learns to annotate unseen terms in new texts and contexts. The results can be used for a variety of intelligent language processing applications. We illustrate SVMs capabilities using a sample of 100 journal abstracts texts taken from the {human, blood cell, transcription factor} domain of MEDLINE. Results: Approximately 3400 terms are annotated and the model performs at about 74% F-score on cross-vatidation tests. A detailed analysis based on empirical evidence shows the contribution of various feature sets to performance. Conclusion: Our experiments indicate a relationship between feature window size and the amount of training data and that a combination of surface words, orthographic features and head noun features achieve the best performance among the feature sets tested. (c) 2004 Elsevier B.V. All. rights reserved.	Okayama Univ, Okayama 7008530, Japan; Natl Inst Informat, Chiyoda Ku, Tokyo 1018430, Japan	Takeuchi, K (reprint author), Okayama Univ, 3-1-1 Tsushima Naka, Okayama 7008530, Japan.	koichi@cl.it.okayama-u.ac.jp; collier@nii.ac.jp					Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P31, DOI 10.1093/nar/25.1.31; Bikel Daniel M., 1997, P 5 C APPL NAT LANG, P194, DOI 10.3115/974557.974586; Borthwick A., 1998, P 6 WORKSH VER LARG, P152; Brill E., 1992, P 3 C APPL NAT LANG, P152, DOI 10.3115/974499.974526; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; COLLIER N, 2003, P 7 INT C KNOWL BAS, V2773; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Craven M, 1999, Proc Int Conf Intell Syst Mol Biol, P77; Cristianini N., 2000, INTRO SUPPORT VECTOR; DEBESSE B, 1997, TERMINOLOGY, V4, P117, DOI 10.1075/term.4.1.08bes; FREITAG D, 1999, P WORKSH MACH LEARN; GRUBER TR, 1993, KNOWL ACQUIS, V5, P199, DOI 10.1006/knac.1993.1008; HERZIG T, 1997, P AM MED INF ASS ANN; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; JUSTESON J, 1995, NAT LANG ENG, V28, P9; KASHYAP V, 1996, COOPERATIVE INFORMAT; Kressel UHG, 1999, ADVANCES IN KERNEL METHODS, P255; LINDBERG DAB, 1993, METHOD INFORM MED, V32, P281; Lovis C, 1995, Medinfo, V8 Pt 1, P28; Nobata C., 2000, P WORKSH COMP CORP A, P20, DOI 10.3115/1604683.1604690; SCHOLKOPF B, 1998, AUSTR J INTELLIGENT, V1, P3; Sekine S, 1998, P 6 WORKSH VER LARG; TAKEUCHI K, 2002, P 6 C NAT LANG LEARN, P119; Tapanainen Pasi, 1997, P 5 C APPL NAT LANG, P64, DOI 10.3115/974557.974568; TATEISHHI Y, 2000, WORKSHOP SEMANTIC AN; Thomas J., 2000, PACIFIC S BIOCOMPUTI, V5, P538; VANRIJSBERGEN CJ, 1979, INFORMATION RETRIEVA; Vapnik V., 1982, ESTIMATION DEPENDENC; Vapnik V. N, 1995, NATURE STAT LEARNING; *DARPA, 1995, P 6 MESS UND C COL M; *MEDLINE, 1999, PUBMED DAT CAN FOUND; *NLM, 1997, MED SUBJ HEAD BEHT; 1998, IEEE INTELL SYS, P18	34	17	18	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657		ARTIF INTELL MED	Artif. Intell. Med.	FEB	2005	33	2					125	137		10.1016/j.artmed.2004.07.019		13	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	920FC	WOS:000228673800003	
J	Bunescu, R; Ge, RF; Kate, RJ; Marcotte, EM; Mooney, RJ; Ramani, AK; Wong, YW				Bunescu, R; Ge, RF; Kate, RJ; Marcotte, EM; Mooney, RJ; Ramani, AK; Wong, YW			Comparative experiments on learning information extractors for proteins and their interactions	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						information extraction; text mining; machine learning; protein interactions; Medline	GENES; MODELS	Objective: Automatically extracting information from biomedical text holds the promise of easily consolidating large amounts of biological knowledge in computer-accessible form. This strategy is particularly attractive for extracting data relevant to genes of the human genome from the 11 million abstracts in Medline. However, extraction efforts have been frustrated by the lack of conventions for describing human genes and proteins. We have developed and evaluated a variety of learned information extraction systems for identifying human protein names in Medtine abstracts and subsequently extracting information on interactions between the proteins. Methods and Material: We used a variety of machine learning methods to automaticatly develop information extraction systems for extracting information on gene/ protein name, function and interactions from Medline abstracts. We present crossvalidated results on identifying human proteins and their interactions by training and testing on a set of approximately 1000 manuatly-annotated Medline abstracts that discuss human genes/proteins. Results: We demonstrate that machine learning approaches using support vector machines and maximum entropy are able to identify human proteins with higher accuracy than several previous approaches. We also demonstrate that various rule induction methods are able to identify protein interactions with higher precision than manually-developed rules. Conclusion: Our results show that it is promising to use machine learning to automatically build systems for extracting information from biomedical text. The results also give a broad picture of the relative strengths of a wide variety of methods when tested on a reasonably large human-annotated corpus. (c) 2004 Elsevier B.V. All rights reserved.	Univ Texas, Dept Comp Sci, Austin, TX 78712 USA; Univ Texas, Inst Cellular & Mol Biol, Austin, TX 78712 USA; Univ Texas, Ctr Computat Biol & Bioinformat, Austin, TX 78712 USA	Mooney, RJ (reprint author), Univ Texas, Dept Comp Sci, Austin, TX 78712 USA.	razvan@cs.utexas.edu; grf@cs.utexas.edu; rjkate@cs.utexas.edu; marcotte@icmb.utexas.edu; mooney@cs.utexas.edu; arun@icmb.utexas.edu; ywwong@cs.utexas.edu					Berger AL, 1996, COMPUT LINGUIST, V22, P39; Bikel DM, 1999, MACH LEARN, V34, P211, DOI 10.1023/A:1007558221122; Blaschke C, 2001, COMPAR FUNCT GENOM, V2, P196, DOI 10.1002/cfg.91; Blaschke C, 2002, IEEE INTELL SYST, V17, P14, DOI 10.1109/MIS.2002.999215; Brill E, 1995, COMPUT LINGUIST, V21, P543; Califf M. E., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); CALIFF ME, 1999, AAAI1999 WORKSH MACH; Cardie C, 1997, AI MAG, V18, P65; Cestnik B., 1990, P EUR C ART INT, P147; CHARRAS C, 1998, SEQUENCE COMPAR LAB; Collier N, 2000, P 18 INT C COMP LING, P201; Collins M., 1999, P C EMP METH NAT LAN; Collins M., 2002, P ANN M ASS COMP LIN; Cowie J, 1996, COMMUN ACM, V39, P80, DOI 10.1145/234173.234209; Craven M, 1999, Proc Int Conf Intell Syst Mol Biol, P77; DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379; Duda R.O, 1973, PATTERN CLASSIFICATI; ELIASSIRAD T, 2001, P 18 INT C MACH LEAR; Freitag D., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); Freund Y, 1996, P 13 INT C MACH LEAR; Friedman C, 2001, Bioinformatics, V17 Suppl 1, pS74; Fukuda K, 1998, Pac Symp Biocomput, P707; GUSFIELD D, 1997, AGLORITHMS STRINGS; Hahn Udo, 2002, Pac Symp Biocomput, P338; HUMPHREYS K, 2000, P PAC S BIOC PSB, P502; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Kubat M, 1998, MACH LEARN, V30, P195, DOI 10.1023/A:1007452223027; Kudoh T, 2000, P CONLL 2000 LLL 200, P142; KUSHMERICK N, 1997, P 15 INT JOINT C ART, P729; LAFFERTY J, 2001, PROBABLISTIC MODELS; Lander ES, 2001, NATURE, V409, P860, DOI 10.1038/35057062; Leonard JE, 2002, BIOINFORMATICS, V18, P1515, DOI 10.1093/bioinformatics/18.11.1515; Levenshtein V., 1966, SOV PHYS DOKL, V10, P707; MACCALLUM A, P 1N INT C MACH LEAR; Marcotte EM, 2001, BIOINFORMATICS, V17, P359, DOI 10.1093/bioinformatics/17.4.359; Marcus M., 1993, COMPUTATIONAL LINGUI, V19, P313; Park J C, 2001, Pac Symp Biocomput, P396; Pearl J., 1988, PROBABILISTIC REASON; Perez-Iratxeta C, 2002, NAT GENET, V31, P316, DOI 10.1038/ng895; Proux D., 2000, Proceedings. Eighth International Conference on Intelligent Systems for Molecular Biology; PROUX D, 1998, GENOME INFORM SER WO, V9, P72; Pustejovsky J, 2002, Pac Symp Biocomput, P362; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RAMSHAW L, 1995, P 3 WORKSH VER LARG; RAY S, 2001, P 17 INT JOINT C ART, P1273; Raychaudhuri S, 2002, GENOME RES, V12, P203, DOI 10.1101/gr.199701; RINDFLESCH TC, 2000, PAC S BIOC 2000, P515; ROTH D, 2002, P 6 C NAT LANG LEARN; Tanabe L, 2002, BIOINFORMATICS, V18, P1124, DOI 10.1093/bioinformatics/18.8.1124; Thomas J, 2000, Pac Symp Biocomput, P541; Thompson C.A., 1999, P 16 INT C MACH LEAR, P406; Vapnik V. N, 1995, NATURE STAT LEARNING; Vapnik VN, 1998, STAT LEARNING THEORY; Venter JC, 2001, SCIENCE, V291, P1304, DOI 10.1126/science.1058040; Xenarios I, 2001, NUCLEIC ACIDS RES, V29, P239, DOI 10.1093/nar/29.1.239; *NAT I STAND TECH, ACE AUT CONT EXTR	56	67	69	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657		ARTIF INTELL MED	Artif. Intell. Med.	FEB	2005	33	2					139	155		10.1016/j.artmed.2004.07.016		17	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	920FC	WOS:000228673800004	
J	Leban, G; Bratko, I; Petrovic, U; Curk, T; Zupan, B				Leban, G; Bratko, I; Petrovic, U; Curk, T; Zupan, B			VizRank: finding informative data projections in functional genomics by machine learning	BIOINFORMATICS			English	Article							GENE-EXPRESSION	VizRank is a tool that finds interesting two-dimensional projections of class-labeled data. When applied to multi-dimensional functional genomics datasets, VizRank can systematically find relevant biological patterns.	Univ Ljubljana, Fac Comp & Informat Sci, Ljubljana, Slovenia; Jozef Stefan Inst, Ljubljana, Slovenia; Baylor Coll Med, Dept Mol & Human Genet, Houston, TX 77030 USA	Zupan, B (reprint author), Univ Ljubljana, Fac Comp & Informat Sci, Ljubljana, Slovenia.	blaz.zupan@fri.uni-lj.si					Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; DEMSAR J, 2004, ORAGNE EXPT MACHINE; DeRisi JL, 1997, SCIENCE, V278, P680, DOI 10.1126/science.278.5338.680; Hoffman P., 1997, Proceedings. Visualization '97 (Cat. No.97CB36155), DOI 10.1109/VISUAL.1997.663916; McCarthy JF, 2004, ANN NY ACAD SCI, V1020, P239, DOI 10.1196/annals.1310.020	5	12	14	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	FEB 1	2005	21	3					413	414		10.1093/bioinformatics/bti016		2	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	891UE	WOS:000226605700024	
J	Wang, Y; Tetko, IV; Hall, MA; Frank, E; Facius, A; Mayer, KFX; Mewes, HW				Wang, Y; Tetko, IV; Hall, MA; Frank, E; Facius, A; Mayer, KFX; Mewes, HW			Gene selection from microarray data for cancer classification - a machine learning approach	COMPUTATIONAL BIOLOGY AND CHEMISTRY			English	Article						microarray; gene selection; machine learning; cancer classification; feature selection	DIFFERENTIALLY EXPRESSED GENES; TUMOR-SUPPRESSOR; ZYXIN; IDENTIFICATION; PATTERNS; PROFILES; PROTEINS; TARGETS; CELLS	A DNA microarray can track the expression levels of thousands of genes simultaneously. Previous research has demonstrated that this technology can be useful in the classification of cancers. Cancer microarray data normally contains a small number of samples which have a large number of gene expression levels as features. To select relevant genes involved in different types of cancer remains a challenge. In order to extract useful gene information from cancer microarray data and reduce dimensionality, feature selection algorithms were systematically investigated in this study. Using a correlation-based feature selector combined with machine learning algorithms such as decision trees, naive Bayes and support vector machines, we show that classification performance at least as good as published results can be obtained on acute leukemia and diffuse large B-cell lymphoma microarray data sets. We also demonstrate that a combined use of different classification and feature selection approaches makes it possible to select relevant genes with high confidence. This is also the first paper which discusses both computational and biological evidence for the involvement of zyxin in leukaemogenesis. (c) 2004 Elsevier Ltd. All rights reserved.	German Res Ctr Environm & Hlth, Inst Bioinformat, D-85764 Neuherberg, Germany; Univ Waikato, Dept Comp Sci, Hamilton, New Zealand; Tech Univ Munich, Wissenschaftszentrum Weihenstephan, Dept Genome Oriented Bioinformat, D-85354 Freising Weihenstephan, Germany	Wang, Y (reprint author), German Res Ctr Environm & Hlth, Inst Bioinformat, Ingolstadter Landstr 1, D-85764 Neuherberg, Germany.	yu.wang@gsf.de	Tetko, Igor/B-1540-2010; Frank, Eibe/A-1434-2008	Tetko, Igor/0000-0002-6855-0012; 			Agathanggelou A, 2003, CANCER RES, V63, P5344; Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Antoniadis A, 2003, BIOINFORMATICS, V19, P563, DOI 10.1093/bioinformatics/btg062; Antonov AV, 2004, BIOINFORMATICS, V20, P644, DOI 10.1093/bioinformatics/btg462; CRAWFORD AW, 1991, J BIOL CHEM, V266, P5847; Frank E, 2004, BIOINFORMATICS, V20, P2479, DOI 10.1093/bioinformatics/bth261; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hall M. A., 1999, THESIS U WAIKATO; Harada K, 2002, ONCOGENE, V21, P4345, DOI 10.1038/sj.onc.1205446; HERO A, 2003, P INT C SIGN PROC AP; Hirota T, 2000, J CELL BIOL, V149, P1073, DOI 10.1083/jcb.149.5.1073; Hwang DH, 2002, BIOINFORMATICS, V18, P1184, DOI 10.1093/bioinformatics/18.9.1184; Inza I, 2004, ARTIF INTELL MED, V31, P91, DOI 10.1016/j.artmed.2004.01.007; Kira K, 1992, P 9 INT C MACH LEARN, P249; Kononenko I., 1994, EUR C MACH LEARN, P171; Langley P., 1994, P AAAI FALL S REL, P140; Li JY, 2003, BIOINFORMATICS, V19, pII93, DOI 10.1093/bioinformatics/btg1066; Li JY, 2002, BIOINFORMATICS, V18, P725, DOI 10.1093/bioinformatics/18.5.725; Li W, 2002, METHODS MICROARRAY D, P137; Platt J., 1998, ADV KERNEL METHODS S; Press WH, 1988, NUMERICAL RECIPES C; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Salgia R, 1996, J BIOL CHEM, V271, P25198; Su Y, 2003, BIOINFORMATICS, V19, P1578, DOI 10.1093/bioinformatics/btg179; Tavor S, 2003, J BIOL CHEM, V278, P52651, DOI 10.1074/jbc.M307077200; Thomas JG, 2001, GENOME RES, V11, P1227, DOI 10.1101/gr.165101; Tsai CA, 2003, NUCLEIC ACIDS RES, V31, DOI 10.1093/nar/gng052; van der Gaag EJ, 2002, J INVEST DERMATOL, V118, P246, DOI 10.1046/j.0022-202x.2001.01657.x; Vapnik VN, 1998, STAT LEARNING THEORY; Wang Y, 2003, BBA-MOL CELL RES, V1593, P115, DOI 10.1016/S0167-4889(02)00349-X; Witten I. H., 1999, DATA MINING PRACTICA; XING EP, 2001, P 18 INT C MACH LEAR; Xiong MM, 2001, GENOME RES, V11, P1878; Yagi T, 2003, BLOOD, V102, P1849, DOI 10.1182/blood-2003-02-0578; Yi JS, 2002, J BIOL CHEM, V277, P9580, DOI 10.1074/jvc.M106922200; [Anonymous], 1993, P 13 INT JOINT C ART, P1022	38	82	87	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1476-9271		COMPUT BIOL CHEM	Comput. Biol. Chem.	FEB	2005	29	1					37	46		10.1016/j.compbiolchem.2004.11.001		10	Biology; Computer Science, Interdisciplinary Applications	Life Sciences & Biomedicine - Other Topics; Computer Science	905ZV	WOS:000227611200004	
J	Yang, S; Bhowmick, SS; Madria, S				Yang, S; Bhowmick, SS; Madria, S			Bio2X: a rule-based approach for semi-automatic transformation of semi-structured biological data to XML	DATA & KNOWLEDGE ENGINEERING			English	Article; Proceedings Paper	XML Schema and Data Management Workshop/International Conference on Conceptural Modeling	2003	Chicago, IL	XSDM		flat files; rule base; machine learning; XML; transformer	DATA INTEGRATION	Data integration of geographically dispersed, heterogeneous, complex biological databases is a key research area. One of the key features of a successful data integration system is to have a simple self-describing data exchange format. However, many of the biological databases provide data in flat files which are poor data exchange formats. Fortunately, XML can be viewed as a powerful data model and better data exchange format. In this paper, we present the Bio2X system that transforms flat file data into highly hierarchical XML data using rule-based machine learning technique. Bio2X has been fully implemented using Java. Our experiments to transform real world biological data demonstrate the effectiveness of the Bio2X approach. (C) 2004 Elsevier B.V. All rights reserved.	Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore; Univ Missouri, Dept Comp Sci, Rolla, MO 65409 USA	Bhowmick, SS (reprint author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.	assourav@ntu.edu.sg; madrias@umr.edu					Achard F, 2001, BIOINFORMATICS, V17, P115, DOI 10.1093/bioinformatics/17.2.115; ADELBERG B, 1998, P SIGMOD; ATZENI P, 1997, P PRINC DAT SYST POD; CARDIE C, 1998, ACL TUTORIAL SYMBOLI; CHEN IA, 1995, INFORM SYST; Chung SY, 1999, TRENDS BIOTECHNOL, V17, P351, DOI 10.1016/S0167-7799(99)01342-6; DAVULCU H, 2000, P PODS; Etzold T, 1996, METHOD ENZYMOL, V266, P114; Hammer J., 1997, P WORKSH MANG SEM DA; HASS L, 2000, P IEEE S BIOINF BIOM; HSU CN, 1998, INFORM SYST; KUSHMERICK N, 1997, P IJCAI; LI J, 2003, P 9 INT C DAT THEOR, P31; LIU L, 2000, P ICDE; MUSLEA I, 1999, P 3 INT C AUT AG; Shanmugasundaram J, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P302; Wong Limsoon, 2002, Brief Bioinform, V3, P389, DOI 10.1093/bib/3.4.389	17	2	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-023X		DATA KNOWL ENG	Data Knowl. Eng.	FEB	2005	52	2					249	271		10.1016/j.datak.2004.05.008		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	886MA	WOS:000226230300005	
J	Dombi, J; Zsiros, A				Dombi, J; Zsiros, A			Learning multicriteria classification models from examples: Decision rules in continuous space	EUROPEAN JOURNAL OF OPERATIONAL RESEARCH			English	Article; Proceedings Paper	19th EURO Summer Institute on Decision Analysis and Artificial Intelligence	SEP 09-21, 2001	Toulouse, FRANCE			multiple criteria analysis; classification; artificial intelligence; decision trees; fuzzy sets	TREES	The classification problem statement of multicriteria decision analysis is to model the classification of the alternatives/actions according to the decision maker's preferences. These models are based on outranking relations, utility functions or (linear) discriminant functions. Model parameters can be given explicitly or learnt from a preclassified set of alternatives/actions. In this paper we propose a novel approach, the Continuous Decision (CD) method, to learn parameters of a discriminant function, and we also introduce its extension, the Continuous Decision Tree (CDT) method, which describes the classification more accurately. The proposed methods are results of integration of Machine Learning methods in Decision Analysis. From a Machine Learning point of view, the CDT method can be considered as an extension of the C4.5 decision tree building algorithm that handles only numeric criteria but applies more complex tests in the inner nodes of the tree. For the sake of easier interpretation, the decision trees are transformed to rules. (C) 2003 Elsevier B.V. All rights reserved.	Univ Szeged, Dept Comp Algorithms & Artificial Intelligence, H-6701 Szeged, Hungary	Zsiros, A (reprint author), Univ Szeged, Dept Comp Algorithms & Artificial Intelligence, POB 652, H-6701 Szeged, Hungary.	dombi@inf.u-szeged.hu; zsiros@inf.u-szeged.hu					Beuthe M, 2001, EUR J OPER RES, V130, P246, DOI 10.1016/S0377-2217(00)00042-4; Blake C. L., 1998, UCI REPOSITORY MACHI; Bouyssou D., 2000, EVALUATION DECISION; Breiman L, 1984, CLASSIFICATION REGRE; CIOS KJ, 1992, IEEE T NEURAL NETWOR, V3, P280, DOI 10.1109/72.125869; DOMBI J, 1982, FUZZY SET SYST, V8, P149, DOI 10.1016/0165-0114(82)90005-7; DOMBI J, 1993, THESIS A JOZSEF U SZ; Esposito F, 1997, IEEE T PATTERN ANAL, V19, P476, DOI 10.1109/34.589207; French S., 1988, DECISION THEORY INTR; Gal T., 1999, MULTICRITERIA DECISI; Greco S, 2001, EUR J OPER RES, V129, P1, DOI 10.1016/S0377-2217(00)00167-3; Hardy G H, 1934, INEQUALITIES; Hyafil L., 1976, Information Processing Letters, V5, DOI 10.1016/0020-0190(76)90095-8; Kay J, 1997, IEEE T PATTERN ANAL, V19, P492, DOI 10.1109/TPAMI.1997.589208; Kearns MJ, 1994, INTRO COMPUTATIONAL; Keeney R.L., 1976, DECISIONS MULTIPLE O; Luca A.D., 1972, INFORM CONTR, V20, P301; MARICHAL JL, 1999, THESIS U LIEGE; Mitchell T, 1997, MACHINE LEARNING; Mousseau V, 1998, J GLOBAL OPTIM, V12, P157, DOI 10.1023/A:1008210427517; Murthy S.K., 1994, J ARTIFICIAL INTELLI, V2, P1; OLSON D, 1996, DECISION AID SELECTI; Pawlak Z., 1994, INT T OPER RES, V1, P107, DOI 10.1111/1475-3995.d01-12; QUINLAN JR, 1993, C4 5 PROGR MACH LEAR; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; KAN AHGR, 1987, MATH PROGRAM, V39, P27; ROY B, 1993, EUR J OPER RES, V66, P184, DOI 10.1016/0377-2217(93)90312-B; ROY B, 1991, THEOR DECIS, V31, P49, DOI 10.1007/BF00134132; Russel S., 1995, ARTIFICIAL INTELLIGE; Saaty TL, 1980, ANAL HIERARCHY PROCE; Stefanowski J., 1993, Foundations of Computing and Decision Sciences, V18; VETSCHERA R, 2000, CENTRAL EUROPEAN J O, V8, P195; Zopounidis C, 2002, EUR J OPER RES, V138, P229, DOI 10.1016/S0377-2217(01)00243-0	33	8	8	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0377-2217		EUR J OPER RES	Eur. J. Oper. Res.	FEB 1	2005	160	3					663	675		10.1016/j.ejor.2003.10.006		13	Management; Operations Research & Management Science	Business & Economics; Operations Research & Management Science	858LM	WOS:000224193300006	
J	Julenius, K; Molgaard, A; Gupta, R; Brunak, S				Julenius, K; Molgaard, A; Gupta, R; Brunak, S			Prediction, conservation analysis, and structural characterization of mammalian mucin-type O-glycosylation sites	GLYCOBIOLOGY			English	Article						machine learning; mucin-type; neural networks; O-glycosylation; prediction	POLYPEPTIDE N-ACETYLGALACTOSAMINYLTRANSFERASE; HUMAN PROTEIN FUNCTION; GALNAC-TRANSFERASE; UDP-GALNAC; TANDEM REPEAT; LINKED GLYCOSYLATION; SECONDARY STRUCTURE; DISULFIDE LINKAGES; ALPHA-HELIX; IN-VITRO	O-GalNAc-glycosylation is one of the main types of glycosylation in mammalian cells. No consensus recognition sequence for the O-glycosyltransferases is known, making prediction methods necessary to bridge the gap between the large number of known protein sequences and the small number of proteins experimentally investigated with regard to glycosylation status. From O-GLYCBASE a total of 86 mammalian proteins experimentally investigated for in vivo O-GalNAc sites were extracted. Mammalian protein homolog comparisons showed that a glycosylated serine or threonine is less likely to be precisely conserved than a nonglycosylated one. The Protein Data Bank was analyzed for structural information, and 12 glycosylated structures were obtained. All positive sites were found in coil or turn regions. A method for predicting the location for mucin-type glycosylation sites was trained using a neural network approach. The best overall network used as input amino acid composition, averaged surface accessibility predictions together with substitution matrix profile encoding of the sequence. To improve prediction on isolated (single) sites, networks were trained on isolated sites only. The final method combines predictions from the best overall network and the best isolated site network; this prediction method correctly predicted 76% of the glycosylated residues and 93% of the nonglycosylated residues. NetOGlyc 3.1 can predict sites for completely new proteins without losing its performance. The fact that the sites could be predicted from averaged properties together with the fact that glycosylation sites are not precisely conserved indicates that mucin-type glycosylation in most cases is a bulk property and not a very site-specific one. NetOGlyc 3.1 is made available at www.cbs.dtu.dk/services/netoglyc.	Tech Univ Denmark, Biocentrum, Ctr Biol Sequence Anal, DK-2800 Lyngby, Denmark	Julenius, K (reprint author), Tech Univ Denmark, Biocentrum, Ctr Biol Sequence Anal, Bldg 208, DK-2800 Lyngby, Denmark.	karin.julenius@sbc.su.se					Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Apweiler R, 1999, BBA-GEN SUBJECTS, V1473, P4, DOI 10.1016/S0304-4165(99)00165-8; ASKER N, 1995, BIOCHEM J, V308, P873; BENDTSEN JD, IN PRESS J MOL BIOL; Bennett EP, 1999, FEBS LETT, V460, P226, DOI 10.1016/S0014-5793(99)01268-5; Boeckmann B, 2003, NUCLEIC ACIDS RES, V31, P365, DOI 10.1093/nar/gkg095; Cai YD, 1996, ANAL BIOCHEM, V243, P284, DOI 10.1006/abio.1996.0520; Cai YD, 2002, PEPTIDES, V23, P205, DOI 10.1016/S0196-9781(01)00597-6; Cai YD, 1997, J PROTEIN CHEM, V16, P689, DOI 10.1023/A:1026306520790; CARRAWAY K L, 1991, Glycobiology, V1, P131, DOI 10.1093/glycob/1.2.131; CHOTHIA C, 1986, EMBO J, V5, P823; CHOU KC, 1995, PROTEIN SCI, V4, P1365; CHOU KC, 1995, PROTEINS, V21, P118, DOI 10.1002/prot.340210205; Christlet THT, 2001, BIOPHYS J, V80, P952; Coltart DM, 2002, J AM CHEM SOC, V124, P9833, DOI 10.1021/ja020208f; Dalal S, 1997, NAT STRUCT BIOL, V4, P548, DOI 10.1038/nsb0797-548; ELHAMMER AP, 1993, J BIOL CHEM, V268, P10029; Gerbaud V, 2000, J BIOL CHEM, V275, P1057, DOI 10.1074/jbc.275.2.1057; Gerken TA, 1997, J BIOL CHEM, V272, P9709; Gerken TA, 2004, BIOCHEMISTRY-US, V43, P4137, DOI 10.1021/bi036306a; Gerstein M, 1998, PROTEIN SCI, V7, P445; Gorodkin J, 1999, Proc Int Conf Intell Syst Mol Biol, P95; Gupta R, 1999, NUCLEIC ACIDS RES, V27, P370, DOI 10.1093/nar/27.1.370; Hanisch FG, 2001, GLYCOBIOLOGY, V11, P731, DOI 10.1093/glycob/11.9.731; HANSEN JE, 1995, BIOCHEM J, V308, P801; Hansen JE, 1998, GLYCOCONJUGATE J, V15, P115, DOI 10.1023/A:1006960004440; Hart Gerald W., 1992, Current Opinion in Cell Biology, V4, P1017, DOI 10.1016/0955-0674(92)90134-X; HENIKOFF S, 1992, P NATL ACAD SCI USA, V89, P10915, DOI 10.1073/pnas.89.22.10915; Hertz J., 1991, INTRO THEORY NEURAL; Jensen LJ, 2003, BIOINFORMATICS, V19, P635, DOI 10.1093/bioinformatics/btg036; Jensen LJ, 2002, J MOL BIOL, V319, P1257, DOI 10.1016/S0022-2836(02)00379-0; JENTOFT N, 1990, TRENDS BIOCHEM SCI, V15, P291, DOI 10.1016/0968-0004(90)90014-3; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; Kato K, 2001, BIOCHEM BIOPH RES CO, V287, P110, DOI 10.1006/bbrc.2001.5562; Kinarsky L, 2003, GLYCOBIOLOGY, V13, P929, DOI 10.1093/glycob/cwg109; Kirnarsky L, 1998, BIOCHEMISTRY-US, V37, P12811, DOI 10.1021/bi981034a; KNEPPER TP, 1992, BIOCHEMISTRY-US, V31, P11651, DOI 10.1021/bi00161a053; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; McGuffin LJ, 2000, BIOINFORMATICS, V16, P404, DOI 10.1093/bioinformatics/16.4.404; Neumann GM, 1998, BIOCHEMISTRY-US, V37, P6572, DOI 10.1021/bi972894e; Nielsen H, 1997, PROTEIN ENG, V10, P1, DOI 10.1093/protein/10.1.1; NISHIMORI I, 1994, J BIOL CHEM, V269, P16123; OCONNELL B, 1991, BIOCHEM BIOPH RES CO, V180, P1024, DOI 10.1016/S0006-291X(05)81168-4; OCONNELL BC, 1992, J BIOL CHEM, V267, P25010; PETERS BP, 1989, ENDOCRINOLOGY, V124, P1602; Qian N, 1988, J MOL BIOL, V202, P865, DOI 10.1016/0022-2836(88)90564-5; Riesner D, 2003, BRIT MED BULL, V66, P21, DOI 10.1093/bmb/dg66.021; Schuman J, 2000, GLYCOCONJUGATE J, V17, P835, DOI 10.1023/A:1010909011496; Schuman J, 2003, J PEPT RES, V61, P91, DOI 10.1034/j.1399-3011.2003.00031.x; Seitz O, 2000, Chembiochem, V1, P214, DOI 10.1002/1439-7633(20001117)1:4<214::AID-CBIC214>3.0.CO;2-B; SORENSEN T, 1995, J BIOL CHEM, V270, P24166; Spiro RG, 2002, GLYCOBIOLOGY, V12, p43R, DOI 10.1093/glycob/12.4.43R; STROUS GJ, 1992, CRIT REV BIOCHEM MOL, V27, P57, DOI 10.3109/10409239209082559; Tagashira M, 2002, GLYCOCONJUGATE J, V19, P43, DOI 10.1023/A:1022532930708; Takeuchi H, 2002, EUR J BIOCHEM, V269, P6173, DOI 10.1046/j.1432-1033.2002.03334.x; Ten Hagen KG, 2003, GLYCOBIOLOGY, V13, p1R, DOI 10.1093/glycob/cwg007; Ten Hagen KG, 1999, J BIOL CHEM, V274, P27867; Ten Hagen KG, 2001, J BIOL CHEM, V276, P17395; THOMPSON JD, 1994, NUCLEIC ACIDS RES, V22, P4673, DOI 10.1093/nar/22.22.4673; Van den Steen P, 1998, CRIT REV BIOCHEM MOL, V33, P151; VARKI A, 1993, GLYCOBIOLOGY, V3, P97, DOI 10.1093/glycob/3.2.97; Wang H, 2003, BIOCHEM BIOPH RES CO, V300, P738, DOI 10.1016/S0006-291X(02)02908-X; Westbrook J, 2003, NUCLEIC ACIDS RES, V31, P489, DOI 10.1093/nar/gkg068; WILSON IBH, 1991, BIOCHEM J, V275, P529; Yoshida A, 1997, J BIOL CHEM, V272, P16884, DOI 10.1074/jbc.272.27.16884; YOUNG JD, 1979, BIOCHEMISTRY-US, V18, P4444, DOI 10.1021/bi00587a026	66	479	494	OXFORD UNIV PRESS INC	CARY	JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA	0959-6658		GLYCOBIOLOGY	Glycobiology	FEB	2005	15	2					153	164		10.1093/glycob/cwh151		12	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	886AX	WOS:000226199900006	
J	Haykin, S				Haykin, S			Cognitive radio: Brain-empowered wireless communications	IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS			English	Article						awareness; channel-state estimation and predictive modeling; cognition; competition and cooperation; emergent behavior; interference temperature; machine learning; radio-scene analysis; rate feedback; spectrum analysis; spectrum holes; spectrum management; stochastic games; transmit-power control; water filling	NANOTUBE ELECTRONICS; SPECTRUM ESTIMATION	Cognitive radio is viewed as a novel approach for improving the utilization of a precious natural resource: the radio electromagnetic spectrum. The cognitive radio, built on a software-defined radio, is defined as an intelligent wireless communication system that is aware of M environment and uses the methodology of understanding-by-building to learn from the environment and adapt to statistical variations in the input stimuli, with two primary objectives in mind: highly reliable communication whenever and wherever needed; efficient utilization of the radio spectrum. Following the discussion of interference temperature as a new metric for the quantification and management of interference, the paper addresses three fundamental cognitive tasks. 1) Radio-scene analysis. 2) Channel-state estimation and predictive modeling. 3) Transmit-power control and dynamic spectrum management. This paper also discusses the emergent behavior of cognitive radio.	McMaster Univ, Adapt Syst Lab, Hamilton, ON L8S 4K1, Canada	Haykin, S (reprint author), McMaster Univ, Adapt Syst Lab, Hamilton, ON L8S 4K1, Canada.	haykin@mcmaster.ca					AUMANN R, 1995, ECONOMETRICA, V63, P1161, DOI 10.2307/2171725; Avouris P, 2003, P IEEE, V91, P1772, DOI 10.1109/JPROC.2003.818338; BALE B, 2002, RADIO SCI, V37; Basar T., 1999, DYNAMIC NONCOOPERATI; Benveniste A., 1987, ADAPTIVE ALGORITHMS; Berrou C, 2003, IEEE COMMUN MAG, V41, P110, DOI 10.1109/MCOM.2003.1222726; Boyd S, 2004, CONVEX OPTIMIZATION; BROWN AS, 2004, C COGN RAD TECHN COR; Cappe O., 2005, INFERENCE HIDDEN MAR; CHAPIN, 2004, C COGN RAD TECHN TRA; Cohen L., 1995, TIME FREQUENCY ANAL; COMPTON RT, 1988, ADAPTIVE SIGNAL PROC; Cover T. M., 1991, ELEMENTS INFORMATION; FETTE B, 2004, C COGN RAD LAS VEG N; FISCHLER MA, 1987, INTELLIGENCE BRAIN C, P81; Foschini G. J., 1998, Wireless Personal Communications, V6, DOI 10.1023/A:1008889222784; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Fudenberg Drew, 1999, THEORY LEARNING GAME; Fukuda T, 2003, P IEEE, V91, P1803, DOI 10.1109/JPROC.2003.818334; Glimcher PW, 2003, BRADFORD BOOKS, P1; Golub G. H., 1996, MATRIX COMPUTATIONS; GORDON GJ, 2004, IN PRESS NO REGRET A; GREENWALD A, 2004, INT C MACH LEARN BAN; GRIFFITHS LJ, 1982, IEEE T ANTENN PROPAG, V30, P27, DOI 10.1109/TAP.1982.1142739; Gupta P, 2000, IEEE T INFORM THEORY, V46, P388, DOI 10.1109/18.825799; Gustafsson F, 2000, ADAPTIVE FILTERING C; Haykin S, 2004, P IEEE, V92, P439, DOI 10.1109/JPROC.2003.823143; Haykin S., 1999, NEURAL NETWORKS COMP; Haykin S., 2001, COMMUNICATION SYSTEM, P61; Haykin S, 2002, ADAPTIVE FILTER THEO; Haykin S, 2002, P IEEE, V90, P860, DOI 10.1109/JPROC.2002.1015011; Haykin S., 2004, MODERN WIRELESS COMM; HOCHWALD B, UNPUB IEEE T INFORM; Hoshuyama O, 1999, IEEE T SIGNAL PROCES, V47, P2677, DOI 10.1109/78.790650; HUBER K, UNPUB IMPROVED BAYES; IIJIMA S, 1991, NATURE, V354, P56, DOI 10.1038/354056a0; JEN E, 1990, 1989 LECT COMPLEX SY; Kolodzy P., 2001, P DARPA OCT 17; Lanzerotti L. J., 1999, MODERN RADIO SCI 199, P25; Loeve M., 1963, PROBABILITY THEORY; Loeve M., 1946, Revue Scientifique, V84; Mann ME, 1999, ADV GEOPHYS, V41, P1, DOI 10.1016/S0065-2687(08)60026-6; Maynard Smith J., 1982, EVOLUTION THEORY GAM; MCHENRY M, 2003, FCC WORKSH COGN RAD; MCMAHAN HB, 2003, 20 INT C MACH LEARN; MITOLA J, 1995, IEEE COMMUN MAG  MAY; Mitola J., 2000, COGNITIVE RADIO INTE; Mitola J, 1999, IEEE PERS COMMUN, V6, P13, DOI 10.1109/98.788210; NASH J, 1951, ANN MATH, V54, P286, DOI 10.2307/1969529; Nicolis G., 1989, EXPLORING COMPLEXITY; Percival D. B., 1993, SPECTRAL ANAL PHYS A; PFEIFER R, 1999, UNDERSTANDING INTELL, P5; POWELL J, 2004, C COGN RAD TECHN TRA; RALSTON A, 1993, ENCY COMPUTER SCI, P186; Rappaport T.S., 1998, SMART ANTENNAS ADAPT; RAYLEIGH, 2003, PHIL MAG, V41, P238; ROBERT CP, 1999, MONTE CARLO STAT ME; Schuster HG, 2001, COMPLEX ADAPTIVE SYS; SELLATHURAI V, 2004, THESIS MCMASTER U HA; SHEPARD TJ, 1995, THESIS MIT CAMBRIDGE; Sheu B, 2003, P IEEE, V91, P1747, DOI 10.1109/JPROC.2003.818331; SHILLING JD, 2004, C COGN RAD TECHN TRA; SLEPIAN D, 1978, AT&T TECH J, V57, P1371; SMITH JM, 1974, J THEOR BIOL, V47, P209; Staple G, 2004, IEEE SPECTRUM, V41, P48, DOI 10.1109/MSPEC.2004.1270548; Stein D.L., 1989, LECT SCI COMPLEXITY; Stoica P, 1999, CIRC SYST SIGNAL PR, V18, P169, DOI 10.1007/BF01206681; Thomson D. J, 2000, NONLINEAR NONSTATION; THOMSON DJ, 1982, P IEEE, V70, P1055, DOI 10.1109/PROC.1982.12433; Thomson D. J., 1991, ADV SPECTRUM ANAL AR, V1, P58; THOMSON DJ, 1977, AT&T TECH J, V56, P1769; TURNER M, 2004, C COGN RAD TECHN TRA; Von Neumann J., 1947, THEORY GAMES EC BEHA; Weisbunch G, 1991, COMPLEX SYSTEM DYNAM; WELCH PD, 1967, IEEE T ACOUST SPEECH, VAU15, P70, DOI 10.1109/TAU.1967.1161901; Xu J, 2003, P IEEE, V91, P1819, DOI 10.1109/JPROC.2003.818325; Yu W., 2002, THESIS STANFORD U ST; Zander J., 2001, RADIO RESOURCE MANAG; Zheng LZ, 2003, IEEE T INFORM THEORY, V49, P1073, DOI 10.1109/TIT.2003.810646; [Anonymous], 2002, 02135 FED COMM COMM; [Anonymous], 2003, SOFTWARE DEFINED RAD; *FCC, 2003, COGN RAD WORKSH MAY; *IEEE, 80216A2003; *MOT, 2002, UNPUB FCC; *NAT ASS AM RAD, 2004, 03237 NAT ASS AM RAD; SIGNAL PROCESING BOX; 2002, SOFTWARE DEFINED RAD; 2004, P C COGN RAD LAS VEG	88	2757	3027	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0733-8716		IEEE J SEL AREA COMM	IEEE J. Sel. Areas Commun.	FEB	2005	23	2					201	220		10.1109/JSAC.2004.839380		20	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	896OR	WOS:000226943900002	
J	Bernado-Mansilla, E; Ho, TK				Bernado-Mansilla, E; Ho, TK			Domain of competence of XCS classifier system in complexity measurement space	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION			English	Article						classification; genetic algorithms (GAS); geometrical complexity; learning classifier systems (LCSs); machine learning; pattern recognition		The XCS classifier system has recently shown a high degree of competence on a variety of data mining problems, but to what kind of problems XCS is well and poorly suited is seldom understood, especially for real-world classification problems. The major inconvenience has been attributed to the difficulty of determining the intrinsic characteristics of real-world classification problems. This paper investigates the domain of competence of XCS by means of a methodology that characterizes the complexity of a classification problem by a set of geometrical descriptors. In a study of 392 classification problems along with their complexity characterization, we are able to identify difficult and easy domains for XCS. We focus on XCS with hyperrectangle codification, which has been predominantly used for real-attributed domains. The results show high correlations between XCS's performance and measures of length of class boundaries, compactness of classes, and nonlinearities of decision boundaries. We also compare the relative performance of XCS with other traditional classifier schemes. Besides confirming the high degree of competence of XCS in these problems, we are able to relate the behavior of the different classifier schemes to the geometrical complexity of the problem. Moreover, the results highlight certain regions of the complexity measurement space where a classifier scheme excels, establishing a first step toward determining the best classifier scheme for a given classification problem.	Ramon Llull Univ, Dept Comp Engn, Enginyeria & Arquitectura La Salle, Barcelona 08022, Spain; Lucent Technol, Bell Labs, Comp Sci Res Ctr, Murray Hill, NJ 07974 USA	Bernado-Mansilla, E (reprint author), Ramon Llull Univ, Dept Comp Engn, Enginyeria & Arquitectura La Salle, Barcelona 08022, Spain.	esterb@salleURL.edu; tkh@research.bell-labs.com					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BASU M, 1999, P INT JOINT C NEUR N, V2, P1259; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; BRODLEY CE, 1995, MACH LEARN, V20, P63, DOI 10.1007/BF00993475; Butz M., 2001, LECT NOTES ARTIF INT, V1996, P253; Butz M., 2001, P GEN EV COMP C GECC, P935; Butz M.V., 2001, P GEN EV COMP C GECC, P927; DIETTERICH TG, 1998, NEURAL COMPUT, V10, P7; Fourer R., 2003, AMPL MODELING LANGUA; FRIEDMAN JH, 1979, ANN STAT, V7, P697, DOI 10.1214/aos/1176344722; Goldberg D. E., 1987, P 2 INT C GEN ALG, P41; Goldberg DE, 1989, GENETIC ALGORITHMS S; Ho T. K., 2000, P 15 INT C PATT REC, P43; Ho TK, 2002, IEEE T PATTERN ANAL, V24, P289; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Ho TK, 2002, PATTERN ANAL APPL, V5, P102, DOI 10.1007/s100440200009; Hoekstra A., 1996, Proceedings of the 13th International Conference on Pattern Recognition, DOI 10.1109/ICPR.1996.547429; Holland J. H., 1986, MACHINE LEARNING ART, VII, P593; Holland J. H., 1978, PATTERN DIRECTED INF, P313; HOLLAND JH, 1975, ADAPTATION NATURAL A; Horn J, 1994, EVOL COMPUT, V2, P37, DOI 10.1162/evco.1994.2.1.37; Kovacs T., 1999, P GEN EV COMP C GECC, P329; Kovacs T., 2000, LECT NOTES ARTIF INT, V1813/2000, P143, DOI 10.1007/3-540-45027-0_7; KOVACS T, 2001, LECT NOTES ARTIF INT, V1996, P80; Kovacs T., 2000, FDN GENETIC ALGORITH, V6, P165; Lanzi P. L., 1999, P GEN EV COMP C GECC, P345; Lanzi PL, 1999, P GEN EV COMP C GECC, P337; Lebourgeois F., 1996, Proceedings of the 13th International Conference on Pattern Recognition, DOI 10.1109/ICPR.1996.547426; Li M., 1993, INTRO KOLMOGOROV COM; MANSILLA EB, 2002, LECT NOTES ARTIF INT, V2321, P115; MANSILLA EB, 2002, THESIS R LLULL U BAR; MANSILLA EB, 2003, EVOLUTIONARY COMPUTA, V11, P209; Murthy S.K., 1994, J ARTIFICIAL INTELLI, V2, P1; PRIM RC, 1957, AT&T TECH J, V36, P1389; SAXON S, 2000, LECT NOTES ARTIF INT, V1813, P223, DOI 10.1007/3-540-45027-0_12; SMITH FW, 1968, IEEE T COMPUT, VC 17, P367, DOI 10.1109/TC.1968.229395; Stone C, 2003, EVOL COMPUT, V11, P299, DOI 10.1162/106365603322365315; Sutton R.S., 1998, REINFORCEMENT LEARNI; Wilson S., 2001, LECT NOTES ARTIF INT, V1996, P158; WILSON SW, 1998, 3 ANN C GEN PROGR SA; WILSON SW, 1999, FESTSCHRIFT HONOR JH, P111; Wilson SW, 1995, EVOL COMPUT, V3, P149, DOI 10.1162/evco.1995.3.2.149	43	27	27	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1089-778X		IEEE T EVOLUT COMPUT	IEEE Trans. Evol. Comput.	FEB	2005	9	1					82	104		10.1109/TEVC.2004.840153		23	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	905ZT	WOS:000227611000008	
J	Villacci, D; Bontempi, G; Vaccaro, A; Birattari, M				Villacci, D; Bontempi, G; Vaccaro, A; Birattari, M			The role of learning methods in the dynamic assessment of power components loading capability	IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS			English	Article						intelligent systems; learning systems; power system monitoring; power transformers protection	THERMAL OVERLOAD PROTECTION; MODEL	The need for dynamic loading of power components in the deregulated electricity market demands reliable assessment models that should be able to predict the thermal behavior when the load exceeds the nameplate value. When assessing network load capability, the hot-spot temperature of the components is known to be the most critical factor. The knowledge of the evolution of the hot-spot temperature during overload conditions is essential to evaluate the loss of insulation life and to evaluate the consequent risks of both technical and economical nature. This paper discusses an innovative grey-box architecture for integrating physical knowledge modeling (a.k.a. white-box) with machine learning techniques (a.k.a. black-box). In particular, we focus on the problem of forecasting the hot-spot temperature of a mineral-oil-immersed transformer. We perform a set of experiments and we compare the predictions obtained by the grey-, white-, and black-box approaches.	Univ Sannio, Dept Engn, Power Syst Res Grp, I-82100 Benevento, Italy; Free Univ Brussels, Dept Informat, B-1050 Brussels, Belgium; Free Univ Brussels, IRIDIA, B-1050 Brussels, Belgium	Villacci, D (reprint author), Univ Sannio, Dept Engn, Power Syst Res Grp, I-82100 Benevento, Italy.	villacci@unisannio.it; gbonte@ulb.ac.be; mbiro@ulb.ac.be	Birattari, Mauro/D-2597-2009				Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; BERTOLISSI E, 2001, FUZZY SETS SYST, V28, P3; Birattari M, 1999, ADV NEUR IN, V11, P375; BIRATTARI M, 1999, LAZY LEARNING TOOLBO; BONTEMPI G, 1999, MACH LEARN, V1, P32; Bontempi G, 2000, AI COMMUN, V13, P41; Bontempi G, 2001, FUZZY SET SYST, V121, P59, DOI 10.1016/S0165-0114(99)00172-4; Bontempi G., 1999, THESIS U LIBRE BRUXE; BONTEMPI G, 1999, P EUFIT 99; BUONANNO G, 1995, IEE P-GENER TRANSM D, V142, P436, DOI 10.1049/ip-gtd:19951956; Daponte P., 1996, Measurement, V18, DOI 10.1016/0263-2241(96)00043-7; Galdi V, 2000, IEE P-ELECT POW APPL, V147, P415, DOI 10.1049/ip-epa:20000519; Galdi V, 2001, ELECTR POW SYST RES, V60, P107, DOI 10.1016/S0378-7796(01)00173-0; Galdi V, 2001, IEE P-ELECT POW APPL, V148, P163, DOI 10.1049/ip-epa:20010086; HANNAN E, 1998, EARTH ISL J, V13, P2; Hastie T, 2001, ELEMENTS STAT LEARNI; LINDSKOG P, 1995, INT J ADAPT CONTROL, V9, P509, DOI 10.1002/acs.4480090605; Ljung L., 1987, SYSTEM IDENTIFICATIO; LOSI A, 1993, P POW SYST C TEHR IR, P416; LYALL JS, 2000, P POW ENG SOC SUMM M, P457; Mitchell T, 1997, MACHINE LEARNING; Nokes G, 1999, POWER ENG J, V13, P291, DOI 10.1049/pe:19990608; Swift GW, 2001, IEEE T POWER DELIVER, V16, P516, DOI 10.1109/61.956730; VANDERVEKEN W, 2001, P IEEE PES TRANSMISS, P147; WILLIAMS JA, 1999, P IEEE PES TRANSM DI, P128; *IEE STD, 1993, CALC BAR OV COND TEM, P783; *IEEE STD, GUID LOAD MIN OIL IM; *STUD COMM 23 CIGR, 2002, ELECTRA, P63	28	14	14	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0278-0046		IEEE T IND ELECTRON	IEEE Trans. Ind. Electron.	FEB	2005	52	1					280	290		10.1109/TIE.2004.841072		11	Automation & Control Systems; Engineering, Electrical & Electronic; Instruments & Instrumentation	Automation & Control Systems; Engineering; Instruments & Instrumentation	893YB	WOS:000226755900032	
J	Vasconcelos, N; Lippman, A				Vasconcelos, N; Lippman, A			A multiresolution manifold distance for invariant image similarity	IEEE TRANSACTIONS ON MULTIMEDIA			English	Article						Affine transformations; face recognition; image similarity; invariance; manifold distance; multiresolution; robust estimators; semantic movie classification; tangent distance	FACE DETECTION; CLASSIFICATION; RECOGNITION; MODELS; LAYERS	Accounting for spatial image transformations is a requirement for multimedia problems such as video classification and retrieval, face/object recognition or the creation of image mosaics from video sequences. We analyze a transformation invariant metric recently proposed in the machine learning literature to measure the distance between image manifolds - the tangent distance (TD) - and show that it is closely related to alignment techniques from the motion analysis literature. Exposing these relationships results in benefits for the two domains. On one hand, it allows leveraging on the knowledge acquired in the alignment literature to build better classifiers. On the other, it provides a new interpretation of alignment techniques as one component of a decomposition that has interesting properties for the classification of video. In particular, we embed the TD into a multiresolution framework that makes it significantly less prone to local minima. The new metric - multiresolution tangent distance (MRTD) - can be easily combined with robust estimation procedures, and exhibits significantly higher invariance to image transformations than the TD and the Euclidean distance (ED). For classification, this translates into significant improvements in face recognition accuracy. For video characterization, it leads to a decomposition of image dissimilarity into "differences due to camera motion" plus "differences due to scene activity" that is useful for classification. Experimental results on a movie database indicate that the distance could be used as a basis for the extraction of semantic primitives such as action and romance.	Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA; MIT, Media Lab, Cambridge, MA 02139 USA	Vasconcelos, N (reprint author), Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA.	nuno@ece.ucsd.edu					Aigrain P, 1996, MULTIMED TOOLS APPL, V3, P179, DOI 10.1007/BF00393937; AMANDAN P, 1993, MOTION ANAL IMAGE SE, pCH1; Bertsekas D., 1995, NONLINEAR PROGRAMMIN; BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851; Devroye L., 1996, PROBABILISTIC THEORY; Duda R.O, 1973, PATTERN CLASSIFICATI; FREY B, 1999, IEEE COMP SOC C COMP, P416; Huber P. J., 1981, ROBUST STAT; IRANI M, 1996, SIGNAL PROCESS IMAGE, V8; LUCAS BD, 1981, P DARPA IM UND WORKS; MAO JC, 1992, PATTERN RECOGN, V25, P173, DOI 10.1016/0031-3203(92)90099-5; MARTIN W, 1986, RECENT THEORIES NARR, pCH5; MASSEY M, 1996, IBM SYST J, V35; MONTEGOMERY D, 1992, INTRO LINEAR REGRESS; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; RAVELA S, 1998, INT C COMP VIS, P608; Rousseeuw P, 1987, ROBUST REGRESSION OU; ROWLEY H, 1998, IEEE COMP SOC C COMP, P963; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Sawhney HS, 1996, IEEE T PATTERN ANAL, V18, P814, DOI 10.1109/34.531801; Schiele B, 2000, INT J COMPUT VISION, V36, P31, DOI 10.1023/A:1008120406972; Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895; SIMARD P, 1994, P NEUR INF PROC SYST; SIMARD PY, 1994, INT C PATT RECOG, P262, DOI 10.1109/ICPR.1994.576916; SMOLIAR S, 1996, MULTIMEDIA SYSTEMS T; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; SZUMMER M, 1998, WORKSH CONT BAS IM V, P42; TURK M, 1991, J COGN NEUROSCI, V3; Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448; Vasconcelos N, 2000, IEEE T IMAGE PROCESS, V9, P3, DOI 10.1109/83.817595; Vasconcelos N, 1998, PROC CVPR IEEE, P566, DOI 10.1109/CVPR.1998.698662; VASCONCELOS N, 2000, THESIS MIT CAMBRIDGE; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; Weiss Y, 1997, PROC CVPR IEEE, P520, DOI 10.1109/CVPR.1997.609375; ZHANG HJ, 1995, P SOC PHOTO-OPT INS, V2417, P389, DOI 10.1117/12.206066	36	22	22	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1520-9210		IEEE T MULTIMEDIA	IEEE Trans. Multimedia	FEB	2005	7	1					127	142		10.1109/TMM.2004.840596		16	Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications	Computer Science; Telecommunications	893CQ	WOS:000226697300013	
J	Yang, J; Frangi, AF; Yang, JY; Zhang, D; Jin, Z				Yang, J; Frangi, AF; Yang, JY; Zhang, D; Jin, Z			KPCA plus LDA: A complete kernel fisher discriminant framework for feature extraction and recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						kernel-based methods; subspace methods; principal component analysis (PCA); Fisher linear discriminant analysis (LDA or FLD); feature extraction; machine learning; face recognition; handwritten digit recognition	SMALL SAMPLE-SIZE; FACE-RECOGNITION; ALGORITHM; CLASSIFIERS; EIGENFACES; RETRIEVAL; PCA	This paper examines the theory of kernel Fisher discriminant analysis (KFD) in a Hilbert space and develops a two-phase KFD framework, i.e., kernel principal component analysis (KPCA) plus Fisher linear discriminant analysis (LDA). This framework provides novel insights into the nature of KFD. Based on this framework, the authors propose a complete kernel Fisher discriminant analysis (CKFD) algorithm. CKFD can be used to carry out discriminant analysis in "double discriminant subspaces." The fact that, it can make full use of two kinds of discriminant information, regular and irregular, makes CKFD a more powerful discriminator. The proposed algorithm was tested and evaluated using the FERET face database and the CENPARMI handwritten numeral database. The experimental results show that CKFD outperforms other KFD algorithms.	Nanjing Univ Sci & Technol, Dept Comp Sci, Nanjing 210094, Peoples R China; Pompeu Fabra Univ, Dept Technol, Computat Imaging Lab, E-08003 Barcelona, Spain; Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China; Univ Autonoma Barcelona, Ctr Comp Vis, E-08193 Barcelona, Spain	Yang, J (reprint author), Nanjing Univ Sci & Technol, Dept Comp Sci, Nanjing 210094, Peoples R China.	csjyang@comp.polyu.edu.hk; alejandro.frangi@upf.edu; yangjy@mail.njust.edu.cn; csdzhang@comp.polyu.edu.hk; zhongjin@cvc.uab.es					Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Billings SA, 2002, NEURAL NETWORKS, V15, P263, DOI 10.1016/S0893-6080(01)00142-3; Burges CJC, 1997, ADV NEUR IN, V9, P375; Cawley GC, 2003, PATTERN RECOGN, V36, P2585, DOI 10.1016/S0031-3203(03)00136-5; Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9; Devore J, 1997, STAT EXPLORATION ANA; Draper BA, 2003, COMPUT VIS IMAGE UND, V91, P115, DOI 10.1016/S1077-3142(03)00077-8; Yang H, 2003, IMAGE VISION COMPUT, V21, P1037, DOI 10.1016/j.imavis.2003.07.005; Fukunaga K., 1990, INTRO STAT PATTERN R; Golub G. H., 1996, MATRIX COMPUTATIONS; Hamamoto Y., 1996, Proceedings of the 13th International Conference on Pattern Recognition, DOI 10.1109/ICPR.1996.546948; Hutson V, 1980, APPL FUNCTIONAL ANAL; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; Kreyszig E., 1978, INTRO FUNCTIONAL ANA; Lancaster P., 1985, THEORY MATRICES; Lawrence N. D., 2001, P 18 INT C MACH LEAR, P306; Liu CJ, 2000, IEEE T IMAGE PROCESS, V9, P132, DOI 10.1109/83.817604; Liu CJ, 2001, IEEE T IMAGE PROCESS, V10, P598, DOI 10.1109/83.913594; Liu K., 1992, INT J PATTERN RECOGN, V6, P817, DOI 10.1142/S0218001492000412; LOU Z, 1992, PATTERN ANAL APPL, V2, P228; Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P117, DOI 10.1109/TNN.2002.806629; Mika S, 2003, IEEE T PATTERN ANAL, V25, P623, DOI 10.1109/TPAMI.2003.1195996; Mika S, 2001, ADV NEUR IN, V13, P591; Mika S., 1999, P IEEE INT WORKSH NE, P41; MIKA S, 1999, ADV NEURAL INFORMATI, V12; Mika S., 2001, P AISTATS, P98; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Phillips P.J., 2004, FACIAL RECOGNITION T; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Roth V, 2000, ADV NEUR IN, V12, P568; Rudin W., 1973, FUNCTIONAL ANAL; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B., 2002, LEARNING KERNELS; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; Tikhonov A., 1997, SOLUTION ILL POSED P; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Van Gestel T, 2002, NEURAL COMPUT, V14, P1115; Vapnik V. N, 1995, NATURE STAT LEARNING; Weidmann J., 1980, LINEAR OPERATORS HIL; XU J, 2001, P INT JOINT C NEUR N, P1486; Yambor W. S., 2002, EMPIRICAL EVALUATION; Yang J, 2003, PATTERN ANAL APPL, V6, P47, DOI 10.1007/s10044-002-0177-3; YANG J, 2001, P SPIE INTELLIGENT R, V20, P438; Yang J, 2004, NEUROCOMPUTING, V56, P415, DOI 10.1016/S0925-2312(03)00444-2; Yang H, 2003, PATTERN RECOGN, V36, P563; Yang J, 2003, PATTERN RECOGN, V36, P1369, DOI 10.1016/S0031-3203(02)00262-5; Yang Jian, 2003, Acta Automatica Sinica, V29; Yang M.H., 2002, P 5 IEEE INT C AUT F, P215, DOI 10.1109/AFGR.2002.4527207; Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X; ZHAO W, 1998, FACE RECOGNITION THE, P73; Zhao W., 1999, CSTR4009 U MAR	52	304	351	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2005	27	2					230	244				15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	879AR	WOS:000225689300006	
J	Arsenio, AM				Arsenio, AM			Development of neural mechanisms for machine learning	INTERNATIONAL JOURNAL OF NEURAL SYSTEMS			English	Article; Proceedings Paper	International Conference on Neuro-Information Processing	NOV 21-25, 2004	Calcutta, INDIA			development learning; human-robot interactions; humanoid robotics; learning artifacts		The goal of this work is to develop a humanoid robot's perceptual mechanisms through the use of learning aids. We describe methods to enable learning on a humanoid robot using learning aids such as books, drawing materials, boards, educational videos or other children toys. Visual properties of objects are learned and inserted into a recognition scheme, which is then applied to acquire new object representations-we propose learning through developmental stages. Inspired in infant development, we will also boost the robot's perceptual capabilities by having a human caregiver performing educational and play activities with the robot (such as drawing, painting or playing with a toy train on a railway). We describe original algorithms to extract meaningful percepts from such learning experiments. Experimental evaluation of the algorithms corroborates the theoretical framework.	MIT, Comp Sci & Artificial Intelligence Lab, Stata Ctr, Cambridge, MA 02139 USA	Arsenio, AM (reprint author), MIT, Comp Sci & Artificial Intelligence Lab, Stata Ctr, 32 Vassar St,Room G32-376, Cambridge, MA 02139 USA.	arsenio@csail.mit.edu	Arsenio, Artur/A-8463-2010				ARSENIO AM, 2004, INT S ROB; ARSENIO AM, 2004, INT JOINT C NEUR NET; ARSENIO AM, 2004, THESIS MIT; Cutler R., 1998, INT C AUT FAC GEST R; DARRELL T, 1993, IEEE C COMP VIS PATT, P335; FITZPATRICK P, 2003, THESIS MIT CAMBRIDGE; FITZPATRICK P, 2004, INT WORKSH EP ROB; HARRIS J, 1994, ALGEBRAIC GEOMETRY F; HENDRIKSJANSEN H, 1996, CATCHING OURSELVES A; Hernandez-Reif M, 2001, INFANCY, V2, P51, DOI 10.1207/S15327078IN0201_4; Perrett D.I., 1990, VISION ACTION CONTRO, P163; Rao K., 1989, IEEE Control Systems Magazine, V9, DOI 10.1109/37.16767; Scassellati B., 2001, THESIS MIT; SHELOV S, 1998, YOUR BABYS FIRST YEA	14	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0129-0657		INT J NEURAL SYST	Int. J. Neural Syst.	FEB-APR	2005	15	1-2					41	54		10.1142/S0129065705000050		14	Computer Science, Artificial Intelligence	Computer Science	986OP	WOS:000233459900006	
J	Coble, JA; Rathi, R; Cook, DJ; Holder, LB				Coble, JA; Rathi, R; Cook, DJ; Holder, LB			Iterative structure discovery in graph-based data	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS			English	Article; Proceedings Paper	17th International FLAIRS Conference	MAY 17-19, 2004	Miami Beach, FL	FLAIRS		structural data mining; incremental discovery; graph partitioning; machine learning		Much of current data mining research is focused on discovering sets of attributes that discriminate data entities into classes, such as shopping trends for a particular demographic group. In contrast, we are working to develop data mining techniques to discover patterns consisting of complex relationships between entities. Our research is particularly applicable to domains in which the data is event-driven or relationally structured. In this paper we present approaches to address two related challenges; the need to assimilate incremental data updates and the need to mine monolithic datasets. Many realistic problems are continuous in nature and therefore require a data mining approach that can evolve discovered knowledge over time. Similarly, many problems present data sets that are too large to fit into dynamic memory on conventional computer systems. We address incremental data mining by introducing a mechanism for summarizing discoveries from previous data increments so that the globally-best patterns can be computed by mining only the new data increment. To address monolithic datasets we introduce a technique by which these datasets can be partitioned and mined serially with minimal impact on the result quality. We present applications of our work in both the counter-terrorism and bioinformatics domains.	Univ Texas, Dept Comp Sci & Engn, Arlington, TX 76019 USA	Coble, JA (reprint author), Univ Texas, Dept Comp Sci & Engn, Box 19015, Arlington, TX 76019 USA.	coble@cse.uta.edu; rathi@cse.uta.edu; cook@cse.uta.edu; holder@cse.uta.edu					AGRAWAL R, 1995, P INT C DAT ENG TAIP; AGRAWAL R, 1995, P 1 INT C KNOWL DISC; BLUM A, 1996, P WORKSH ON LIN ALG; Cook D. J., 1994, Journal of Artificial Intelligence Research, V1; Cook DJ, 2001, J PARALLEL DISTR COM, V61, P427, DOI 10.1006/jpdc.2000.1696; Farhat C., 1988, ACM IEEE 19 DES AUT, V28, P579; Friedman N., 1997, P 13 C UNC ART INT; Han J., 2000, ACM SIGMOD INT C MAN; HOLDER LB, 2002, PATTERN RECOGNITION; HULTEN G, 2001, KDD 01; KERNINGHAN BW, 1970, BELL SYST TECH J, V49, P421; Mitchell T, 1997, MACHINE LEARNING; Rissanen J., 1989, STOCHASTIC COMPLEXIT; Savasere A., 1995, 21 INT C VER LARG DA; Shenoy Pardeep, 2000, ACM SIGMOD INT C MAN; TOIVONEN H, 1996, P INT C VER LARG DAT; Vapnik V. N, 1995, NATURE STAT LEARNING; WANG H, 2003, 9 ACM INT C KNOWL DI; Widmer G, 1996, MACH LEARN, V23, P69, DOI 10.1023/A:1018046501280	19	2	2	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-2130		INT J ARTIF INTELL T	Int. J. Artif. Intell. Tools	FEB-APR	2005	14	1-2					101	124		10.1142/S0218213005002016		24	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	986SA	WOS:000233468800007	
J	O'Sullivan, D				O'Sullivan, D			Understanding case based recommendation: A similarity knowledge perspective	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS			English	Article; Proceedings Paper	17th International FLAIRS Conference	MAY 17-19, 2004	Miami Beach, FL	FLAIRS		case-based reasoning; collaborative filtering; recommender systems; system analysis; sparsity problem	SYSTEMS	Recommender systems bring together ideas from information retrieval and filtering, user profiling, and machine learning in an attempt to provide users with more proactive and personalized information systems. Forwarded as a response to the information overload problem, recommender systems have enjoyed considerable theoretical and practical successes, with a range of core techniques and a compelling array of evaluation studies to demonstrate success in many real-world domains. That said, there is much yet to understand about the strengths and weaknesses of recommender systems technologies and in this article, we make a fine-grained analysis of a successful case-based recommendation approach. We describe a detailed, fine-grained ablation study of similarity knowledge and similarity metric contributions to improved system performance. In particular, we extend our earlier analyses to examine how measures of interestingness can be used to identify and analyse relative contributions of segments of similarity knowledge. We gauge the strengths and weaknesses of knowledge components and discuss future work as well as implications for research in the area.	Univ Coll Dublin, Smart Med Inst, Dublin 4, Ireland; Univ N Carolina, Dept Software & Informat Syst, Charlotte, NC 28223 USA	O'Sullivan, D (reprint author), Univ Coll Dublin, Smart Med Inst, Dublin 4, Ireland.	dermot.osullivan@ucd.ie					AGRAWAL R, 1996, ADV KNOWLEDGE DISCOV, P307; BURKE R, 2000, P EWCBR 00, P370; Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564; Cotter P., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); FOLTZ PW, 1990, SIGOIS BUL, V11, P40; Goldberg K, 2001, INFORM RETRIEVAL, V4, P133, DOI 10.1023/A:1011419012209; Hayes C, 2001, LECT NOTES ARTIF INT, V2080, P234; HONDA K, 2001, WEB INTELLIGENCE RES, V2198, P394, DOI 10.1007/3-540-45490-X_50; Konstan JA, 1997, COMMUN ACM, V40, P77, DOI 10.1145/245108.245126; Lyman P., 2003, MUCH INFORM; McJones P., 1997, EACHMOVIE COLLABORAT; MCKENNA E, 2000, P EWCBR 00, V1898, P186; OSULLIVAN D, 2004, P 17 INT FLAIRS C MA; OSULLIVAN D, 2002, P 15 INT FLAIRS C FL, P121; OSULLIVAN D, 2004, P 7 EUR C CAS BAS RE; OSULLIVAN D, 2003, P 16 INT FLAIRS C, P139; Resnick P, 1997, COMMUN ACM, V40, P56, DOI 10.1145/245108.245121; ROSENSTEIN M, 2000, CHI 00, P291; ROUSH W, 2004, MIT TECHNOLOGY REV, P34; Sarwar B., 2000, P 2 ACM C EL COMM, P158, DOI DOI 10.1145/352871.352887; Smyth B, 2001, AI MAG, V22, P89; Tan P., 2002, P 8 ACM SIGKDD INT C, P32, DOI DOI 10.1145/775047.775053; [Anonymous], 2001, P 10 INT C WORLD WID, P285, DOI DOI 10.1145/371920.372071	23	1	1	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-2130		INT J ARTIF INTELL T	Int. J. Artif. Intell. Tools	FEB-APR	2005	14	1-2					215	232		10.1142/S0218213005002077		18	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	986SA	WOS:000233468800013	
J	Kenny, LC; Dunn, WB; Ellis, DI; Myers, JE; Robinson, AE; Kell, DB; Baker, PN				Kenny, LC; Dunn, WB; Ellis, DI; Myers, JE; Robinson, AE; Kell, DB; Baker, PN			Novel biomarkers for preeclampsia detected using metabolomics and machine learning.	JOURNAL OF THE SOCIETY FOR GYNECOLOGIC INVESTIGATION			English	Meeting Abstract	52nd Annual Meeting of the Society-for-Gynecologic-Investigation	MAR 23-26, 2005	Los Angeles, CA	Soc Gynecolog Invest					Univ Manchester, Maternal & Fetal Hlth Res Ctr, Manchester, Lancs, England; Univ Manchester, Sch Chem, Manchester, Lancs, England			Kell, Douglas/E-8318-2011				Brindle JT, 2002, NAT MED, V8, P1439, DOI 10.1038/nm802	1	2	2	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	1071-5576		J SOC GYNECOL INVEST	J. Soc. Gynecol. Invest.	FEB	2005	12	2		S		355	199A	199A				1	Obstetrics & Gynecology	Obstetrics & Gynecology	902CN	WOS:000227329100356	
J	Pillai, SK; Good, B; Pond, SK; Wong, JK; Strain, MC; Richman, DD; Smith, DM				Pillai, SK; Good, B; Pond, SK; Wong, JK; Strain, MC; Richman, DD; Smith, DM			Semen-specific genetic characteristics of human immunodeficiency virus type 1 env	JOURNAL OF VIROLOGY			English	Article							ACTIVE ANTIRETROVIRAL THERAPY; PRIMARY INFECTION; HETEROSEXUAL TRANSMISSION; PHENOTYPE PREDICTION; SEXUAL TRANSMISSION; MAXIMUM-LIKELIHOOD; GENITAL SECRETIONS; HIV-1 INFECTION; SEMINAL PLASMA; VIRAL LOAD	Human immunodeficiency virus type 1 (HIV-1) in the male genital tract may comprise virus produced locally in addition to virus transported from the circulation. Virus produced in the male genital tract may be genetically distinct, due to tissue-specific cellular characteristics and immunological pressures. HIV-1 env sequences derived from paired blood and semen samples from the Los Alamos HIV Sequence Database were analyzed to ascertain a male genital tract-specific viral signature. Machine learning algorithms could predict seminal tropism based on env sequences with accuracies exceeding 90%, suggesting that a strong genetic signature does exist for virus replicating in the male genital tract. Additionally, semen-derived viral populations exhibited constrained diversity (P < 0.05), decreased levels of positive selection (P < 0.025), decreased CXCR4 coreceptor utilization, and altered glycosylation patterns. Our analysis suggests that the male genital tract represents a distinct selective environment that contributes to the apparent genetic bottlenecks associated with the sexual transmission of HIV-1.	Univ Calif San Diego, Div Biol Sci, La Jolla, CA 92093 USA; San Diego Healthcare Syst, Vet Adm, San Diego, CA USA	Pillai, SK (reprint author), Univ Calif San Diego, Div Biol Sci, 9500 Gilman Dr,MC 0679, La Jolla, CA 92093 USA.	satish@ucsd.edu	Pond, Sergei/G-9830-2012				Altfeld M, 2001, J EXP MED, V193, P169, DOI 10.1084/jem.193.2.169; Auvert B, 2004, JAIDS-J ACQ IMM DEF, V36, P613, DOI 10.1097/00126334-200405010-00010; Chakraborty H, 2001, AIDS, V15, P621, DOI 10.1097/00002030-200103300-00012; Chun TW, 1997, NATURE, V387, P183, DOI 10.1038/387183a0; COFFIN JM, 1995, SCIENCE, V267, P483, DOI 10.1126/science.7824947; Coombs RW, 2003, AIDS, V17, P455, DOI 10.1097/01.aids.0000042970.95433.f9; Coombs RW, 1998, J INFECT DIS, V177, P320; CORPET F, 1988, NUCLEIC ACIDS RES, V16, P10881, DOI 10.1093/nar/16.22.10881; Davis CW, 2004, J EXP MED, V199, P1037, DOI 10.1084/jem.20040426; Delwart EL, 1998, J VIROL, V72, P617; Derdeyn CA, 2004, SCIENCE, V303, P2019, DOI 10.1126/science.1093137; DREW WL, 1991, J INFECT DIS, V163, P716; Dyer JR, 1997, AIDS, V11, P543; Felsenstein J., 1993, PHYLIP PHYLOGENY INF; Fiscus SA, 1998, AIDS RES HUM RETROV, V14, pS27; Gunthard HF, 2001, J INFECT DIS, V183, P1318, DOI 10.1086/319864; Gupta P, 2000, J INFECT DIS, V182, P79, DOI 10.1086/315644; HUDSON RR, 1992, GENETICS, V132, P583; Jensen Mark A., 2003, AIDS Reviews, V5, P104; Kemal KS, 2003, P NATL ACAD SCI USA, V100, P12972, DOI 10.1073/pnas.2134064100; KIESSLING AK, 1992, J HUMAN VIROL, V2, P193; KOSAKOVSKYPOND S, IN PRESS MOL BIOL EV; KRIEGER JN, 1995, J UROLOGY, V154, P1035, DOI 10.1016/S0022-5347(01)66969-6; Krieger JN, 1998, J UROLOGY, V159, P820, DOI 10.1016/S0022-5347(01)63742-X; Marshall R D, 1974, BIOCHEM SOC S, P17; McInerney JO, 1998, BIOINFORMATICS, V14, P372, DOI 10.1093/bioinformatics/14.4.372; Mjolsness E, 2001, SCIENCE, V293, P2051, DOI 10.1126/science.293.5537.2051; MUSE SV, 1994, MOL BIOL EVOL, V11, P715; Nickle DC, 2003, CURR OPIN MICROBIOL, V6, P410, DOI 10.1016/S1369-5274(03)00096-1; OLSEN GJ, 1994, COMPUT APPL BIOSCI, V10, P41; Page RDM, 1996, COMPUT APPL BIOSCI, V12, P357; Paranjpe S, 2002, AIDS RES HUM RETROV, V18, P1271, DOI 10.1089/088922202320886316; Pillai S, 2003, AIDS RES HUM RETROV, V19, P145, DOI 10.1089/088922203762688658; Piot P, 2001, NATURE, V410, P968, DOI 10.1038/35073639; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinn TC, 2000, NEW ENGL J MED, V342, P921, DOI 10.1056/NEJM200003303421303; RAMBAUT A, 2002, SC AL SEQUENCE ALIGN; Rambaut A, 2000, BIOINFORMATICS, V16, P395, DOI 10.1093/bioinformatics/16.4.395; Resch W, 2001, VIROLOGY, V288, P51, DOI 10.1006/viro.2001.1087; Sadiq ST, 2002, AIDS, V16, P219, DOI 10.1097/00002030-200201250-00011; Singh A, 1999, J VIROL, V73, P6680; SLATKIN M, 1989, GENETICS, V123, P603; SMITH DM, 2004, AIDS, V18, P6; Strain MC, 2003, P NATL ACAD SCI USA, V100, P4819, DOI 10.1073/pnas.0736332100; Taylor S, 2000, AIDS, V14, P1979, DOI 10.1097/00002030-200009080-00014; Vernazza PL, 1997, AIDS, V11, P987, DOI 10.1097/00002030-199708000-00006; Wei XP, 2003, NATURE, V422, P307, DOI 10.1038/nature01470; Witten I. H., 2000, DATA MINING PRACTICA; Wong JK, 1997, J VIROL, V71, P2059; Yu Q, 2004, NAT STRUCT MOL BIOL, V11, P435, DOI 10.1038/nsmb758; Zhang H, 1998, NEW ENGL J MED, V339, P1803, DOI 10.1056/NEJM199812173392502; Zhang LQ, 2002, J VIROL, V76, P9465, DOI 10.1128/JVI.76.18.9465-9473.2002; ZHANG LQ, 1993, J VIROL, V67, P3345; ZHU TF, 1993, SCIENCE, V261, P1179, DOI 10.1126/science.8356453; *UNAIDS WHO, 2004, AIDS EP UPD DEC 2003	55	56	58	AMER SOC MICROBIOLOGY	WASHINGTON	1752 N ST NW, WASHINGTON, DC 20036-2904 USA	0022-538X		J VIROL	J. Virol.	FEB	2005	79	3					1734	1742		10.1128/JVI.79.3.1734-1724.2005		9	Virology	Virology	892FB	WOS:000226634300039	
J	Wu, QX; Bell, D; McGinnity, M				Wu, QX; Bell, D; McGinnity, M			Multiknowledge for decision making	KNOWLEDGE AND INFORMATION SYSTEMS			English	Article						classification; decision making; decision system; knowledge representation; multiknowledge; multiple reducts; rough set; uncertain rule	COMPUTATIONAL METHODS; ROUGH SETS; CLASSIFICATION	The representation of knowledge has an important effect on automated decision-making. In this paper, vector spaces are used to describe a condition space and a decision space, and knowledge is represented by a mapping from the condition space to the decision space. Many such mappings can be obtained from a training set. A set of mappings, which are created from multiple reducts in the training set, is defined as multiknowledge. In order to get a good reduct and find multiple reducts, the WADF (worst-attribute-drop-first) algorithm is developed through analysis of the properties of decision systems using rough set theory. An approach that combines multiknowledge and the naive Bayes classifier is applied to make decisions for unseen instances or for instances with missing attribute values. Benchmark data sets from the UCI Machine Learning Repository are used to test the algorithms. The experimental results are encouraging; the prediction accuracy for unseen instances by using the algorithms is higher than by using other approaches based on a single body of knowledge.	Univ Ulster, Sch Comp & Intelligent Syst, Magee BT48 7JL, Londonderry, North Ireland; Queens Univ Belfast, Sch Comp Sci, Belfast, Antrim, North Ireland	Wu, QX (reprint author), Univ Ulster, Sch Comp & Intelligent Syst, Magee BT48 7JL, Londonderry, North Ireland.	q.wu@ulster.ac.uk					BAO Y, 2003, INT J KNOWL BASED IN, V7, P54; Bao YG, 2002, LECT NOTES COMPUT SC, V2534, P340; Bell DA, 1998, J AM SOC INFORM SCI, V49, P403, DOI 10.1002/(SICI)1097-4571(19980415)49:5<403::AID-ASI3>3.3.CO;2-#; Bell DA, 2000, MACH LEARN, V41, P175, DOI 10.1023/A:1007612503587; Guan JW, 1998, ARTIF INTELL, V105, P77, DOI 10.1016/S0004-3702(98)00090-3; HONG ZQ, 1991, PATTERN RECOGN, V24, P317, DOI 10.1016/0031-3203(91)90074-F; HU X, 1997, ROUGH SET DATA MININ, P109; KOHAVI R, 1994, USEFUL FEATURE SUBSE; LIN TY, 1997, ROUGH SET DATA MININ; Mitchell M., 1997, MACHINE LEARNING; NGUYEN SH, 1997, P 7 INT FUZZ SYST AS, V2, P204; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Pawlak Z., 1991, ROUGH SETS THEORETIC; Polkowski L., 1998, ROUGH SETS KNOWLEDGE, V1; Polkowski L., 1998, ROUGH SETS KNOWLEDGE, V2; POLKOWSKI L, 2000, ROUGH SET METHODS AP; RISH I, 2001, IJCAI01 WORKSH EMP M; Skowron A., 1992, INTELLIGENT DECISION, P331; TANAKA H, 1998, ROUGH SETS KNOWLEDGE, V2, P295; WROBLEWSKI J, 1998, ROUGH SETS KNOWLEDGE, V2, P471; Wroblewski J., 1995, P 2 ANN JOINT C INF, P186; WU QX, 2001, P INT C COMP INT MOD, P543; YAO YY, 1997, ROUGH SETS DATA MINI, P25; Zhong N, 2001, J INTELL INF SYST, V16, P199, DOI 10.1023/A:1011219601502; Zupan B, 1998, IEEE INTELL SYST APP, V13, P38, DOI 10.1109/5254.671090	25	9	10	SPRINGER LONDON LTD	GODALMING	SWEETAPPLE HOUSE CATTESHALL ROAD, GODALMING GU7 3DJ, SURREY, ENGLAND	0219-1377		KNOWL INF SYST	Knowl. Inf. Syst.	FEB	2005	7	2					246	266		10.1007/s10115-004-0150-0		21	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	903FT	WOS:000227411800006	
J	Walker, MA				Walker, MA			Can we talk? Methods for evaluation and training of spoken dialogue systems	LANGUAGE RESOURCES AND EVALUATION			English	Article						dialogue systems; evaluation; machine learning		There is a strong relationship between evaluation and methods for automatically training language processing systems, where generally the same resource and metrics are used both to train system components and to evaluate them. To date, in dialogue systems research, this general methodology is not typically applied to the dialogue manager and spoken language generator. However, any metric for evaluating system performance can be used as a feedback function for automatically training the system. This approach is motivated with examples of the application of reinforcement learning to dialogue manager optimization, and the use of boosting to train the spoken language generator.	Univ Sheffield, Dept Comp Sci, Sheffield S1 4DP, S Yorkshire, England	Walker, MA (reprint author), Univ Sheffield, Dept Comp Sci, Regent Court,221 Porto Bello St, Sheffield S1 4DP, S Yorkshire, England.	walker@dcs.shef.ac.uk					Andre E, 2000, EMBODIED CONVERSATIONAL AGENTS, P220; Barzilay R, 2002, J ARTIF INTELL RES, V17, P35; FREUND Y, 1998, MACHINE LEARNING; HIRSCHMAN L, 2000, SPOKEN LANGUAGE DISC; LAPATA M, 2003, P ACL; LITMAN DJ, 2000, P COLING 2000; RAMBOW O, 2001, P M ASS COMP LING AC; SCHEFFLER K, 2002, HUM LANG TECHN C; Sripada S., 2002, P 2 INT C NAT LANG G, P97; STENT A, 2004, M ASS COMP LING; Sutton R.S., 1998, REINFORCEMENT LEARNI; Walker M., 1997, P 35 ANN M ASS COMP, P271; Walker MA, 2000, J ARTIF INTELL RES, V12, P387; Yeh CL, 1997, COMPUT LINGUIST, V23, P169	14	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1574-020X		LANG RESOUR EVAL	Lang. Resour. Eval.	FEB	2005	39	1					65	75		10.1007/s10579-005-2696-1		11	Computer Science, Interdisciplinary Applications	Computer Science	012RL	WOS:000235356800006	
J	Begnum, K; Burgess, M				Begnum, K; Burgess, M			Principle components and importance ranking of distributed anomalies	MACHINE LEARNING			English	Article						machine learning; anomaly detection		Correlations between locally averaged host observations, at different times and places, hint at information about the associations between the hosts in a network. These smoothed, pseudo-continuous time-series imply relationships with entities in the wider environment. For anomaly detection, mining this information might provide a valuable source of observational experience for determining comparative anomalies or rejecting false anomalies. The difficulties with distributed analysis lie in collating the distributed data and in comparing observables on different hosts, in different frames of reference. In the present work, we examine two methods (Principle Component Analysis and Eigenvector Centrality) that shed light on the usefulness of comparing data destined for different locations in a network.	Oslo Univ Coll, Fac Engn, Oslo, Norway	Begnum, K (reprint author), Oslo Univ Coll, Fac Engn, Oslo, Norway.						Balakrishnan V.K., 1997, GRAPH THEORY; Barbara D., 2003, P 2003 ACM S APPL CO; BONACICH P, 1987, AM J SOCIOL, V92, P1170, DOI 10.1086/228631; BURGESS M, 2002, IFIP IEEE 13 INT WOR, P169; Burgess M, 1998, PROCEEDINGS OF THE TWELFTH SYSTEMS ADMINISTRATION CONFERENCE (LISA XII), P283; BURGESS M, 1995, COMPUT SYST, V8, P309; BURGESS M, 2004, ANAL NETWORK SYSTEM; BURGESS M, 2001, ACM T COMPUT SYST, V20, P125; BURGESS M, SCI COMPUTER PROGRAM; BURGESS M, 2003, P 8 IFIP IEEE IM C N, P293; CANRIGHT G, 2003, SOCIAL NETWORKS INTL; Duda R. O., 2001, PATTERN CLASSIFICATI; Grimmett G, 2001, PROBABILITY RANDOM P; HAN SH, 2002, IFIP IEEE 13 INT WOR, P16; Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140; Page L., 1998, PAGERANK CITATION RA; Ranum MJ, 1997, PROCEEDINGS OF THE ELEVENTH SYSTEMS ADMINISTRATION CONFERENCE (LISA XI), P1; Somayagji A., 2000, Proceedings of the Ninth USENIX Security Symposium; SOMAYAJI A, 1997, NEW SEC PAR WORKSH, P75; STEINDER M, 2003, IN PRESS SCI COMPUTE; STEINDER M, 2002, IFIP IEEE 13 INT WOR, P195; STOLFO SJ, 2001, ACM SIGMOD, V30, P4; ZANERO S, P 2004 ACM S APPL CO	23	8	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	FEB-MAR	2005	58	2-3					217	230		10.1007/s10994-005-5827-4		14	Computer Science, Artificial Intelligence	Computer Science	904CS	WOS:000227474300006	
J	Golland, P; Grimson, WEL; Shenton, ME; Kikinis, R				Golland, P; Grimson, WEL; Shenton, ME; Kikinis, R			Detection and analysis of statistical differences in anatomical shape	MEDICAL IMAGE ANALYSIS			English	Article						shape analysis; discriminative analysis; shape classification	FIXED TOPOLOGY SKELETONS; CORPUS-CALLOSUM; SCHIZOPHRENIA; MORPHOMETRY; DISORDER; MODELS	We present a computational framework for image-based analysis and interpretation of statistical differences in anatomical shape between populations. Applications of such analysis include understanding developmental and anatomical aspects of disorders when comparing patients versus normal controls, studying morphological changes caused by aging, or even differences in normal anatomy, for example, differences between genders. Once a quantitative description of organ shape is extracted from input images, the problem of identifying differences between the two groups can be reduced to one of the classical questions in machine learning of constructing a classifier function for assigning new examples to one of the two groups while making as few misclassifications as possible. The resulting classifier must be interpreted in terms of shape differences between the two groups back in the image domain. We demonstrate a novel approach to such interpretation that allows us to argue about the identified shape differences in anatomically meaningful terms of organ deformation. Given a classifier function in the feature space, we derive a deformation that corresponds to the differences between the two classes while ignoring shape variability within each class. Based on this approach, we present a system for statistical shape analysis using distance transforms for shape representation and the support vector machines learning algorithm for the optimal classifier estimation and demonstrate it on artificially generated data sets, as well as real medical studies. (C) 2004 Elsevier B.V. All rights reserved.	MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA; Harvard Univ, Sch Med, VAMC Brockton, Lab Neurosci,Clin Neurosci Div,Dept Psychiat, Brockton, MA 02401 USA; Harvard Univ, Brigham & Womens Hosp, Sch Med, Surg Planning Lab, Boston, MA 02115 USA	Golland, P (reprint author), MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	polina@csail.mit.edu	Rohlf, F/A-8710-2008				Blum H., 1967, MODELS PERCEPTION SP; Bookstein F L, 1997, Med Image Anal, V1, P225, DOI 10.1016/S1361-8415(97)85012-8; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V11, P123, DOI 10.1016/0146-664X(79)90062-5; BRECHBUHLER C, 1995, COMPUT VIS IMAGE UND, V61, P154, DOI 10.1006/cviu.1995.1013; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CHRISTENSEN GE, 1993, PROCEEDINGS OF THE TWENTY-SEVENTH ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS, P211; COOITES TF, 1999, LNCS, V1613, P322; Cootes T.F., 1992, P BRIT MACH VIS C, P9; Csernansky JG, 1998, P NATL ACAD SCI USA, V95, P11406, DOI 10.1073/pnas.95.19.11406; Davatzikos C, 1996, J COMPUT ASSIST TOMO, V20, P88, DOI 10.1097/00004728-199601000-00017; Dryden I.L, 1998, STAT SHAPE ANAL; Efron B., 1982, JACKKNIFE BOOTSTRAP; FRITSCH DS, 1994, PATTERN RECOGN LETT, V15, P445, DOI 10.1016/0167-8655(94)90135-X; Frumin M, 2002, AM J PSYCHIAT, V159, P866, DOI 10.1176/appi.ajp.159.5.866; Gerig G., 2001, LNCS, V2208, P24; Golland P, 2000, PROC CVPR IEEE, P10, DOI 10.1109/CVPR.2000.855792; Golland P., 2001, LECT NOTES COMPUTER, V2082, P517; Golland P, 1999, LECT NOTES COMPUT SC, V1613, P382; Golland P, 2000, LECT NOTES COMPUT SC, V1935, P72; KELEMEN A, 1998, P IEEE INT WORKSH MO, P87; KIMMEL R, 1995, COMPUT VIS IMAGE UND, V62, P382, DOI 10.1006/cviu.1995.1062; Leventon ME, 2000, PROC CVPR IEEE, P316, DOI 10.1109/CVPR.2000.855835; LEYMARIE F, 1992, IEEE T PATTERN ANAL, V14, P56, DOI 10.1109/34.107013; Machado AMC, 1998, P SOC PHOTO-OPT INS, V3338, P642, DOI 10.1117/12.310942; Martin J., 1994, Proceedings 1994 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.94CH3405-8), DOI 10.1109/CVPR.1994.323892; PIZER S, 1996, IEEE T MED IMAGING, V18, P851; SHENTON ME, 1992, NEW ENGL J MED, V327, P604, DOI 10.1056/NEJM199208273270905; Shenton ME, 2002, PSYCHIAT RES-NEUROIM, V115, P15, DOI 10.1016/S0925-4927(02)00025-2; STAIB LH, 1992, IEEE T PATTERN ANAL, V14, P1061, DOI 10.1109/34.166621; Székely G, 1996, Med Image Anal, V1, P19, DOI 10.1016/S1361-8415(96)80003-X; TIMONER SJ, 2003, THESIS MIT; TIMONER SJ, 2002, LNCS, V2488, P508; Vapnik V. N, 1995, NATURE STAT LEARNING; Vapnik VN, 1998, STAT LEARNING THEORY; YUSHKEVICH P, 2001, LNCS, V2082, P402	35	44	44	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1361-8415		MED IMAGE ANAL	Med. Image Anal.	FEB	2005	9	1					69	86		10.1016/j.media.2004.07.003		18	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging	Computer Science; Engineering; Radiology, Nuclear Medicine & Medical Imaging	883VF	WOS:000226043100005	
J	Yan, KL; Lewicki, MS				Yan, KL; Lewicki, MS			A hierarchical Bayesian model for learning nonlinear statistical regularities in nonstationary natural signals	NEURAL COMPUTATION			English	Article							ICA MIXTURE-MODELS; BLIND SEPARATION; WAVELET-DOMAIN; IMAGES; CLASSIFICATION; EMERGENCE; FILTERS	Capturing statistical regularities in complex, high-dimensional data is an important problem in machine learning and signal processing. Models such as principal component analysis (PCA) and independent component analysis (ICA) make few assumptions about the structure in the data and have good scaling properties, but they are limited to representing linear statistical regularities and assume that the distribution of the data is stationary. For many natural, complex signals, the latent variables often exhibit residual dependencies as well as nonstationary statistics. Here we present a hierarchical Bayesian model that is able to capture higher-order nonlinear structure and represent nonstationary data distributions. The model is a generalization of ICA in which the basis function coefficients are no longer assumed to be independent; instead, the dependencies in their magnitudes are captured by a set of density components. Each density component describes a common pattern of deviation from the marginal density of the pattern ensemble; in different combinations, they can describe nonstationary distributions. Adapting the model to image or audio data yields a nonlinear, distributed code for higher-order statistical regularities that reflect more abstract, invariant properties of the signal.	Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA; Carnegie Mellon Univ, Ctr Neural Basis Cognit, Pittsburgh, PA 15213 USA	Yan, KL (reprint author), Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA.	yan+@cs.cmu.edu; lewicki@cnbc.cmu.edu					Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; Bollerslev T., 1994, HDB ECONOMETRICS; Buccigrossi RW, 1999, IEEE T IMAGE PROCESS, V8, P1688, DOI 10.1109/83.806616; CARDOSO JF, 1997, IEEE SIGNAL PROCESS, V4, P109; Choi SJ, 2002, J VLSI SIG PROC SYST, V32, P93, DOI 10.1023/A:1016319502849; Cichocki A., 2002, ADAPTIVE BLIND SIGNA; EVERSON R, 1999, P 8 INT C ART NEUR N, P503; Foldiak P., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.194; Hoyer PO, 2002, VISION RES, V42, P1593, DOI 10.1016/S0042-6989(02)00017-2; Hurri J, 2003, NEURAL COMPUT, V15, P663, DOI 10.1162/089976603321192121; Hyvarinen A, 2000, NEURAL COMPUT, V12, P1705, DOI 10.1162/089976600300015312; Hyvarinen A., 2001, INDEPENDENT COMPONEN; Hyvarinen A, 2001, NEURAL COMPUT, V13, P1527, DOI 10.1162/089976601750264992; Hyvarinen A, 2003, J OPT SOC AM A, V20, P1237, DOI 10.1364/JOSAA.20.001237; Karklin Y, 2003, NETWORK-COMP NEURAL, V14, P483, DOI 10.1088/0954-898X/14/3/306; KAYSER C, 2001, ARTIFICIAL NEURAL NE, V2130, P1075, DOI 10.1007/3-540-44668-0_149; Kruger N, 1998, NEURAL PROCESS LETT, V8, P117, DOI 10.1023/A:1009688428205; LeCun Y., 1998, NEURAL NETWORKS TRIC; Lee TW, 2002, IEEE T IMAGE PROCESS, V11, P270, DOI 10.1109/83.988960; Lee TW, 2000, IEEE T PATTERN ANAL, V22, P1078; LEE TW, 1997, P IEEE INT WORKSH NE; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; ONEILL JC, 1999, DISCRETE TFDS TIME F; PEARLMUTTER BA, 1996, INT C NEUR INF PROC, P151; Pham DT, 2001, IEEE T SIGNAL PROCES, V49, P1837; Romberg JK, 2001, IEEE T IMAGE PROCESS, V10, P1056, DOI 10.1109/83.931100; Schwartz O, 2001, NAT NEUROSCI, V4, P819, DOI 10.1038/90526; Simoncelli E. P., 1997, P 31 AS C SIGN SYST; van Hateren JH, 1998, P ROY SOC B-BIOL SCI, V265, P359; Wainwright MJ, 2001, APPL COMPUT HARMON A, V11, P89, DOI 10.1006/acha.2000.0350; WELLING M, 2003, ADV NEURAL INFORMATI, V15; Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938	33	0	0	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	0899-7667		NEURAL COMPUT	Neural Comput.	FEB	2005	17	2					397	423				27	Computer Science, Artificial Intelligence	Computer Science	893WS	WOS:000226752100006	
J	Backer, E; van Kranenburg, P				Backer, E; van Kranenburg, P			On musical stylometry - a pattern recognition approach	PATTERN RECOGNITION LETTERS			English	Article						musical style recognition; authorship attribution; style markers; machine learning		In this short communication we describe some experiments in which methods of statistical pattern recognition are applied for musical style recognition and disputed musical authorship attribution. Values of a set of 20 features (also called "style markers") are measured in the scores of a set of compositions, mainly describing the different sonorities in the compositions. For a first study over 300 different compositions of Bach, Handel, Telemann, Mozart and Haydn were used and from this data set it was shown that even with a few features, the styles of the various composers could be separated with leave-one-out-error rates varying from 4% to 9% with the exception of the confusion between Mozart and Haydn which yielded a leave-one-out-error rate of 24%. A second experiment included 30 fugues from J.S. Bach, W.F. Bach and J.L. Krebs, all of different style and character. With this data set of compositions of undisputed authorship, the F minor fugue for organ, BAN 534 (of which Bach's authorship is disputed) then was confronted. It could be concluded that there is experimental evidence that J.L. Krebs should be considered in all probability as the composer of the fugue in question. (C) 2004 Elsevier B.V. All rights reserved.	Delft Univ Technol, Fac Elect Engn Math & Comp Sci, Delft, Netherlands; Univ Utrecht, Fac Arts, Dept Musicol, Utrecht, Netherlands	Backer, E (reprint author), Delft Univ Technol, Fac Elect Engn Math & Comp Sci, Delft, Netherlands.	e.backer@ewi.tudelft.nl; p.vankranenburg@lodebar.nl					DANNENBERG T, 1997, P 1997 INT COMP MUS, P344; de Leon PJP, 2003, LECT NOTES COMPUT SC, V2652, P773; HUMPHREYS D, 1985, SCARLETTI TERCENTENA, P173; Love H., 2002, ATTRIBUTING AUTHORSH; MASON RM, 1985, MODERN METHODS MUSIC; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; VANKRANENBURG P, 2004, THESIS U UTRECHT; VANKRANENBURG P, 2004, P C INT MUS GAZ AUST	8	2	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	FEB	2005	26	3					299	309		10.1016/j.patrec.2004.10.016		11	Computer Science, Artificial Intelligence	Computer Science	895WE	WOS:000226893900009	
J	Guo, T; Shi, YX; Sun, ZR				Guo, T; Shi, YX; Sun, ZR			A novel statistical ligand-binding site predictor: application to ATP-binding sites	PROTEIN ENGINEERING DESIGN & SELECTION			English	Article						ATP-binding site; binding site prediction; Oriented Shell Model; protein-ligand interaction; support vector machine	HYDROGEN-BOND FUNCTIONS; STRUCTURAL GENOMICS; PROBE GROUPS; IDENTIFICATION; MACROMOLECULES; SIMILARITY; MOLECULES; POSITIONS; PROTEINS; LOCATION	Structural genomics initiatives are leading to rapid growth in newly determined protein 3D structures, the functional characterization of which may still be inadequate. As an attempt to provide insights into the possible roles of the emerging proteins whose structures are available and/or to complement biochemical research, a variety of computational methods have been developed for the screening and prediction of ligand-binding sites in raw structural data, including statistical pattern classification techniques. In this paper, we report a novel statistical descriptor (the Oriented Shell Model) for protein ligand-binding sites, which utilizes the distance and angular position distribution of various structural and physicochemical features present in immediate proximity to the center of a binding site. Using the support vector machine (SVM) as the classifier, our model identified 69% of the ATP-binding sites in whole-protein scanning tests and in eukaryotic proteins the accuracy is particularly high. We propose that this feature extraction and machine learning procedure can screen out ligand-binding-capable protein candidates and can yield valuable biochemical information for individual proteins.	Tsing Hua Univ, Inst Bioinformat,Dept Biol Sci & Biotechnol, MOE Key Lab Bioinformat, State Key Lab Biomembrane & Membrane Biotechnol, Beijing 100084, Peoples R China; Tsing Hua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China	Sun, ZR (reprint author), Tsing Hua Univ, Inst Bioinformat,Dept Biol Sci & Biotechnol, MOE Key Lab Bioinformat, State Key Lab Biomembrane & Membrane Biotechnol, Beijing 100084, Peoples R China.	sunzhr@mail.tsinghua.edu.cn					ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Bayliss R, 2003, MOL CELL, V12, P851, DOI 10.1016/S1097-2765(03)00392-7; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Burley SK, 1999, NAT GENET, V23, P151, DOI 10.1038/13783; Campbell SJ, 2003, CURR OPIN STRUC BIOL, V13, P389, DOI 10.1016/S0958-440X(03)00075-7; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Devos D, 2000, PROTEINS, V41, P98, DOI 10.1002/1097-0134(20001001)41:1<98::AID-PROT120>3.0.CO;2-S; Di Gennaro JA, 2001, J STRUCT BIOL, V134, P232, DOI 10.1006/jsbi.2001.4391; Friedberg I, 2002, PROTEIN SCI, V11, P350, DOI 10.1110/ps.18602; GOODFORD PJ, 1985, J MED CHEM, V28, P849, DOI 10.1021/jm00145a002; Gutteridge A, 2004, FEBS LETT, V567, P67, DOI 10.1016/j.febslet.2004.03.067; Gutteridge A, 2003, J MOL BIOL, V330, P719, DOI 10.1016/S0022-2836(03)00515-1; Hopfner KP, 2000, CELL, V101, P789, DOI 10.1016/S0092-8674(00)80890-9; Iancu CV, 2002, J BIOL CHEM, V277, P26779, DOI 10.1074/jbc.M203730200; Jackson RM, 2002, J COMPUT AID MOL DES, V16, P43, DOI 10.1023/A:1016307520660; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; KELLOGG GE, 1991, J COMPUT AID MOL DES, V5, P545, DOI 10.1007/BF00135313; Kinoshita K, 2003, CURR OPIN STRUC BIOL, V13, P396, DOI 10.1016/S0959-440X(03)00074-5; Kunin V, 2001, J MOL BIOL, V307, P939, DOI 10.1006/jmbi.2001.4466; Lake MW, 2000, J BIOL CHEM, V275, P40211, DOI 10.1074/jbc.M007406200; Lichtarge O, 2002, CURR OPIN STRUC BIOL, V12, P21, DOI 10.1016/S0959-440X(02)00284-1; Pang YP, 2001, J COMPUT CHEM, V22, P1750, DOI 10.1002/jcc.1129; PITT WR, 1991, PROTEIN ENG, V4, P531, DOI 10.1093/protein/4.5.531; Prodromou C, 1997, CELL, V90, P65, DOI 10.1016/S0092-8674(00)80314-1; Pupko Tal, 2002, Bioinformatics, V18 Suppl 1, pS71; Rantanen VV, 2001, J MOL BIOL, V313, P197, DOI 10.1006/jmbi.2001.5023; Vapnik V. N, 1995, NATURE STAT LEARNING; Vapnik VN, 1998, STAT LEARNING THEORY; Vitkup D, 2001, NAT STRUCT BIOL, V8, P559, DOI 10.1038/88640; WADE RC, 1993, J MED CHEM, V36, P148, DOI 10.1021/jm00053a019; WADE RC, 1993, J MED CHEM, V36, P140, DOI 10.1021/jm00053a018; Wei Liping, 2003, J Bioinform Comput Biol, V1, P119, DOI 10.1142/S0219720003000150	32	6	6	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1741-0126		PROTEIN ENG DES SEL	Protein Eng. Des. Sel.	FEB	2005	18	2					65	70		10.1093/protein/gzi006		6	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology	919UM	WOS:000228643100002	
J	Fukagawa, D; Akutsu, T				Fukagawa, D; Akutsu, T			Performance analysis of a greedy algorithm for inferring Boolean functions	INFORMATION PROCESSING LETTERS			English	Article						analysis of algorithms; unbalanced function; uniform distribution; machine learning	ATTRIBUTES	We analyzed average case performance of a known greedy algorithm for inference of a Boolean function from positive and negative examples, and gave a proof to an experimental conjecture that the greedy algorithm works optimally with high probability if both input data and the underlying function are generated uniformly at random. (C) 2004 Elsevier B.V. All rights reserved.	Kyoto Univ, Dept Intelligence Sci & Technol, Grad Sch Informat, Kyoto 6068501, Japan; Kyoto Univ, Bioinformat Ctr, Inst Chem Res, Kyoto 6110011, Japan	Fukagawa, D (reprint author), Kyoto Univ, Dept Intelligence Sci & Technol, Grad Sch Informat, Kyoto 6068501, Japan.	daiji@kuicr.kyoto-u.ac.jp; takutsu@kuicr.kyoto-u.ac.jp					Akutsu T, 2003, THEOR COMPUT SCI, V292, P481, DOI 10.1016/S0304-3975(02)00183-4; AKUTSU T, 1996, LECT NOTES COMPUTER, V1090, P290; Akutsu T, 1999, Pac Symp Biocomput, P17; Arpe J, 2003, LECT NOTES ARTIF INT, V2842, P99; BLUM A, 1997, ARTIF INTELL, V1, P245; Boros E, 2003, ANN MATH ARTIF INTEL, V39, P223, DOI 10.1023/A:1024653703689; Fukagawa D, 2003, LECT NOTES ARTIF INT, V2843, P114; Gamberger D, 1995, LECT NOTES ARTIF INT, V912, P151; MANNILA H, 1992, DISCRETE APPL MATH, V40, P237, DOI 10.1016/0166-218X(92)90031-5; Mossel E, 2003, P 35 ACM S THEOR COM, P206; Motwani R., 1995, RANDOMIZED ALGORITHM; TSAI CC, 1994, P DES AUT C JUN, P339, DOI 10.1145/196244.196404; Vazirani V.V, 2001, APPROXIMATION ALGORI	13	5	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0020-0190		INFORM PROCESS LETT	Inf. Process. Lett.	JAN 16	2005	93	1					7	12		10.1016/j.ipl.2004.09.017		6	Computer Science, Information Systems	Computer Science	878PL	WOS:000225658800002	
J	Chen, LF; Liu, HF; Friedman, C				Chen, LF; Liu, HF; Friedman, C			Gene name ambiguity of eukaryotic nomenclatures	BIOINFORMATICS			English	Article							GENOME DATABASE; RESOURCE; BIOLOGY; NETWORK	Motivation: With more and more scientific literature published online, the effective management and reuse of this knowledge has become problematic. Natural language processing (NLP) may be a potential solution by extracting, structuring and organizing biomedical information in online literature in a timely manner. One essential task is to recognize and identify genomic entities in text. 'Recognition' can be accomplished using pattern matching and machine learning. But for 'identification' these techniques are not adequate. In order to identify genomic entities, NLP needs a comprehensive resource that specifies and classifies genomic entities as they occur in text and that associates them with normalized terms and also unique identifiers so that the extracted entities are well defined. Online organism databases are an excellent resource to create such a lexical resource. However, gene name ambiguity is a serious problem because it affects the appropriate identification of gene entities. In this paper, we explore the extent of the problem and suggest ways to address it. Results: We obtained gene information from 21 organisms and quantified naming ambiguities within species, across species, with English words and with medical terms. When the case (of letters) was retained, official symbols displayed negligible intra-species ambiguity (0.02%) and modest ambiguities with general English words (0.57%) and medical terms (1.01%). In contrast, the across-species ambiguity was high (14.20%). The inclusion of gene synonyms increased intra-species ambiguity substantially and full names contributed greatly to gene-medical-term ambiguity. A comprehensive lexical resource that covers gene information for the 21 organisms was then created and used to identify gene names by using a straightforward string matching program to process 45 000 abstracts associated with the mouse model organism while ignoring case and gene names that were also English words. We found that 85.1% of correctly retrieved mouse genes were ambiguous with other gene names. When gene names that were also English words were included, 233% additional 'gene' instances were retrieved, most of which were false positives. We also found that authors prefer to use synonyms (74.7%) to official symbols (17.7%) or full names (7.6%) in their publications.	Columbia Univ, Dept Biomed Informat, New York, NY 10032 USA; Univ Maryland Baltimore Cty, Dept Informat Syst, Baltimore, MD 21250 USA	Chen, LF (reprint author), Columbia Univ, Dept Biomed Informat, New York, NY 10032 USA.	lifeng.chen@dbmi.columbia.edu					Blake JA, 2003, NUCLEIC ACIDS RES, V31, P193, DOI 10.1093/nar/gkg047; Cherry JM, 1998, NUCLEIC ACIDS RES, V26, P73, DOI 10.1093/nar/26.1.73; Christensen L.M, 2002, P WORKSH NAT LANG PR, P29; Dolf G, 1999, J HERED, V90, P3, DOI 10.1093/jhered/90.1.3; Gelbart W, 2003, NUCLEIC ACIDS RES, V31, P172, DOI 10.1093/nar/gkg094; FRIEDMAN C, 1994, J AM MED INFORM ASSN, V1, P161; Friedman C, 2001, Bioinformatics, V17 Suppl 1, pS74; Fukuda K, 1998, Pac Symp Biocomput, P707; Hanisch Daniel, 2003, Pac Symp Biocomput, P403; Harris TW, 2004, NUCLEIC ACIDS RES, V32, pD411, DOI 10.1093/nar/gkh066; Hirschman L, 2002, J BIOMED INFORM, V35, P247, DOI 10.1016/S1532-0464(03)00014-5; Hirschman L, 2002, BIOINFORMATICS, V18, P1553, DOI 10.1093/bioinformatics/18.12.1553; Hu J, 2001, NUCLEIC ACIDS RES, V29, P106, DOI 10.1093/nar/29.1.106; Jenssen TK, 2001, NAT GENET, V28, P21, DOI 10.1038/ng0501-21; Jenssen T K, 2000, Proc AMIA Symp, P384; LINDBERG DAB, 1993, METHOD INFORM MED, V32, P281; LIU H, 2004, P NAACLIHLT 2004 BOS, P25; Liu H, 2001, Proc AMIA Symp, P393; Narayanaswamy Meenakshi, 2003, Pac Symp Biocomput, P427; PROUX D, 1998, GENOME INFORM SER WO, V9, P72; Pruitt KD, 2001, NUCLEIC ACIDS RES, V29, P137, DOI 10.1093/nar/29.1.137; SAGER N, 1995, METHOD INFORM MED, V34, P140; SHEN D, 2003, P ACL 2003 WORKSH NA, P49; Sprague J, 2001, NUCLEIC ACIDS RES, V29, P87, DOI 10.1093/nar/29.1.87; Steen RG, 1999, GENOME RES, V9, P793; Tuason O, 2004, Pac Symp Biocomput, P238; Wain HM, 2002, GENOMICS, V79, P464, DOI 10.1006/geno.2002.6748; Wain HM, 2002, NUCLEIC ACIDS RES, V30, P169, DOI 10.1093/nar/30.1.169; Yamamoto K, 2003, P ACL 2003 WORKSH NA, P65	29	57	62	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	JAN 15	2005	21	2					248	256		10.1093/bioinformatics/bth496		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	887LV	WOS:000226308500013	
J	Dobson, PD; Doig, AJ				Dobson, PD; Doig, AJ			Predicting enzyme class from protein structure without alignments	JOURNAL OF MOLECULAR BIOLOGY			English	Article						protein function prediction; structure; EC number; machine learning; structural genomics	SUPPORT VECTOR MACHINES; 3D COORDINATE TEMPLATES; ACTIVE-SITES; ASTRAL COMPENDIUM; NEURAL-NETWORK; DATABASE; FEATURES; RESIDUES; LOCATION	Methods for predicting protein function from structure are becoming more important as the rate at which structures are solved increases more rapidly than experimental knowledge. As a result, protein structures now frequently lack functional annotations. The majority of methods for predicting protein function are reliant upon identifying a similar protein and transferring its annotations to the query protein. This method fails when a similar protein cannot be identified, or when any similar proteins identified also lack reliable annotations. Here, we describe a method that can assign function from structure without the use of algorithms reliant upon alignments. Using simple attributes that can be calculated from any crystal structure, such as secondary structure content, amino acid propensities, surface properties and ligands, we describe each enzyme in a non-redundant set. The set is split according to Enzyme Classification (EC) number. We combine the predictions of one-class versus one-class support vector machine models to make overall assignments of EC number to an accuracy of 35% with the top-ranked prediction, rising to 60% accuracy with the top two ranks. In doing so we demonstrate the utility of simple structural attributes in protein function prediction and shed light on the link between structure and function. We apply our methods to predict the function of every currently unclassified protein in the Protein Data Bank. (C) 2004 Elsevier Ltd. All rights reserved.	UMIST, Dept Biomol Sci, Manchester M60 1QD, Lancs, England	Doig, AJ (reprint author), UMIST, Dept Biomol Sci, POB 88, Manchester M60 1QD, Lancs, England.	andrew.doig@umist.ac.uk	de Sousa, Miguel/A-3877-2009				Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Attwood Terri K, 2002, Brief Bioinform, V3, P252, DOI 10.1093/bib/3.3.252; Babbitt PC, 2003, CURR OPIN CHEM BIOL, V7, P230, DOI 10.1016/S1367-5931(03)00028-0; Bairoch A, 2000, NUCLEIC ACIDS RES, V28, P304, DOI 10.1093/nar/28.1.304; Bartlett GJ, 2002, J MOL BIOL, V324, P105, DOI 10.1016/S0022-2836(02)01036-7; BATE P, 2004, IN PRESS J MOL BIOL; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; BISHOP CM, 1995, NEURAL NETWORKS PATT, P372; Brenner SE, 2000, NUCLEIC ACIDS RES, V28, P254, DOI 10.1093/nar/28.1.254; Brenner SE, 2001, NAT REV GENET, V2, P801, DOI 10.1038/35093574; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Cai CZ, 2004, PROTEINS, V55, P66, DOI 10.1002/prot.20045; Cai YD, 2002, COMPUT CHEM, V26, P179, DOI 10.1016/S0097-8485(01)00106-1; Chandonia JM, 2002, NUCLEIC ACIDS RES, V30, P260, DOI 10.1093/nar/30.1.260; Cristianini N., 2000, INTRO SUPPORT VECTOR; Dandekar T, 1998, TRENDS BIOCHEM SCI, V23, P324, DOI 10.1016/S0968-0004(98)01274-2; Dobson PD, 2004, CURR MED CHEM, V11, P2135; Dobson PD, 2003, J MOL BIOL, V330, P771, DOI 10.1016/S0022-2836(03)00628-4; Falquet L, 2002, NUCLEIC ACIDS RES, V30, P235, DOI 10.1093/nar/30.1.235; Fernandez-Tornero C, 2001, NAT STRUCT BIOL, V8, P1020, DOI 10.1038/nsb724; Frishman D, 1995, PROTEINS, V23, P566, DOI 10.1002/prot.340230412; FUJIBUCHI W, 1998, PACIFIC S BIOCOMPUT, V3, P681; Gibrat JF, 1996, CURR OPIN STRUC BIOL, V6, P377, DOI 10.1016/S0959-440X(96)80058-3; Gutteridge A, 2003, J MOL BIOL, V330, P719, DOI 10.1016/S0022-2836(03)00515-1; Henikoff S, 1999, BIOINFORMATICS, V15, P471, DOI 10.1093/bioinformatics/15.6.471; Jensen LJ, 2002, J MOL BIOL, V319, P1257, DOI 10.1016/S0022-2836(02)00379-0; John G.H., 1994, P 11 INT C MACH LEAR, P121; Jones S, 2004, CURR OPIN CHEM BIOL, V8, P3, DOI 10.1016/j.cbpa.2003.11.001; Kleywegt GJ, 1997, J MOL BIOL, V273, P371, DOI 10.1006/jmbi.1997.1309; Liu JF, 2001, PROTEIN SCI, V10, P1970, DOI 10.1110/ps.10101; Mulder NJ, 2003, NUCLEIC ACIDS RES, V31, P315, DOI 10.1093/nar/gkg046; Ondrechen MJ, 2001, P NATL ACAD SCI USA, V98, P12473, DOI 10.1073/pnas.211436698; Overbeek R, 1999, P NATL ACAD SCI USA, V96, P2896, DOI 10.1073/pnas.96.6.2896; PEARSON WR, 1988, P NATL ACAD SCI USA, V85, P2444, DOI 10.1073/pnas.85.8.2444; PEARSON WR, 1990, METHOD ENZYMOL, V183, P63, DOI 10.1016/0076-6879(90)83007-V; Pellegrini M, 1999, P NATL ACAD SCI USA, V96, P4285, DOI 10.1073/pnas.96.8.4285; Porter CT, 2004, NUCLEIC ACIDS RES, V32, pD129, DOI 10.1093/nar/gkh028; Rost B, 2002, J MOL BIOL, V318, P595, DOI 10.1016/S0022-2836(02)00016-5; Rost B, 2003, CELL MOL LIFE SCI, V60, P2637, DOI 10.1007/s00018-003-3114-8; Sanner MF, 1996, BIOPOLYMERS, V38, P305, DOI 10.1002/(SICI)1097-0282(199603)38:3<305::AID-BIP4>3.0.CO;2-Y; Shinkai H, 2001, EXPERT OPIN THER PAT, V11, P739, DOI 10.1517/13543776.11.5.739; Shrager J, 2003, BIOINFORMATICS, V19, P1934, DOI 10.1093/bioinformatics/btg277; STAPLEY BJ, 2002, PAC S BIOCOMPUT, V7, P374; Stawiski EW, 2000, P NATL ACAD SCI USA, V97, P3954, DOI 10.1073/pnas.070548997; VAPNIK V, 1999, NATURE STAT LEARING; Wallace AC, 1996, PROTEIN SCI, V5, P1001; Wallace AC, 1997, PROTEIN SCI, V6, P2308; WU TF, 2003, ADV NEURAL INFORMATI	49	78	80	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0022-2836		J MOL BIOL	J. Mol. Biol.	JAN 7	2005	345	1					187	199		10.1016/j.jmb.2004.10.024		13	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	877UX	WOS:000225600500016	
S	Kang, DK; Zhang, J; Silvescu, A; Honavar, V		Zucker, JD; Saitta, L		Kang, DK; Zhang, J; Silvescu, A; Honavar, V			Multinomial event model based abstraction for sequence and text classification	ABSTRACTION, REFORMULATION AND APPROXIMATION, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	6th International Symposium on Abstraction, Reformulation and Approximation	JUL 26-29, 2005	Airth, SCOTLAND					In many machine learning applications that deal with sequences, there is a need for learning algorithms that can effectively utilize the hierarchical grouping of words. We introduce Word Taxonomy guided Naive Bayes Learner for the Multinornial Event Model (WTNBL-MN) that exploits word taxonomy to generate compact classifiers, and Word Taxonomy Learner (WTL) for automated construction of word taxonomy from sequence data. WTNBL-MN is a generalization of the Naive Bayes learner for the Multinomial Event Model for learning classifiers from data using word taxonomy. WTL uses hierarchical agglomerative clustering to cluster words based on the distribution of class labels that co-occur with the words. Our experimental results on protein localization sequences and Reuters text show that the proposed algorithms can generate Naive Bayes classifiers that are more compact and often more accurate than those produced by standard Naive Bayes learner for the Multinomial Model.	Iowa State Univ, Dept Comp Sci, Artificial Intelligence Res Lab, Ames, IA 50011 USA	Kang, DK (reprint author), Iowa State Univ, Dept Comp Sci, Artificial Intelligence Res Lab, Ames, IA 50011 USA.	dkkang@cs.iastate.edu; jzhang@cs.iastate.edu; silvescu@cs.iastate.edu; honavar@cs.iastate.edu					ANDORF C, 2004, 5 INT C KNOWL BAS CO, P256; Apte C., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval; ARNDT C, 2001, INFORMATION MEASURES; Bairoch A, 2000, NUCLEIC ACIDS RES, V28, P45, DOI 10.1093/nar/28.1.45; Baker L. D., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.290970; Berners-Lee T., 2001, SCI AM; Ashburner M, 2000, NAT GENET, V25, P25; DESJARDINS M, 2000, SARA 02, P260; Dumais S.T., 1998, CIKM 98, P148; EYHERAMENDY S, 2003, 9 INT WORKSH ART INT; Fawcett T., 2003, HPL20034; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Ganti V., 1999, P 5 ACM SIGKDD INT C, P73, DOI 10.1145/312129.312201; Gibson D, 2000, VLDB J, V8, P222, DOI 10.1007/s007780050005; Han J., 1996, ADV KNOWLEDGE DISCOV; HAUSSLER D, 1988, ARTIF INTELL, V36, P177, DOI 10.1016/0004-3702(88)90002-1; HENDLER J, 1996, CDSTR3672 U MAR I AD; JAOCHIMS T, 1998, P ECML 98, P137; KANG DK, 2004, P 4 IEEE INT C DAT M, P130; KLIMT B, 2004, LECT NOTES COMPUTER, V320, P217; Kohavi R, 2001, DATA MIN KNOWL DISC, V5, P5, DOI 10.1023/A:1009840925866; Lewis DD, 2004, J MACH LEARN RES, V5, P361; McCallum A., 1998, AAAI 98 WORKSH LEARN; Pazzani M.J., 1997, KNOWLEDGE DISCOVERY, P235; PEREIRA F, 1993, 31ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P183; SLONIM N, 1999, P 13 NEUR INF PROC S; TAYLOR MG, 1997, DMKD; UNDERCOFFER JL, 2004, TARGET CENTRIC ONTOL; YAN C, 2004, P 12 INT C INT SYST, P371; ZHANG J, 2003, 12 INT C MACH LEARN; ZHANG J, 2004, INT C DAT MIN ICDM 2	31	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-27872-9	LECT NOTES ARTIF INT			2005	3607						134	148				15	Computer Science, Artificial Intelligence	Computer Science	BCS42	WOS:000231037400010	
S	Hanczar, B		Zucker, JD; Saitta, L		Hanczar, B			Combining feature selection and feature construction to improve concept learning for high dimensional data	ABSTRACTION, REFORMULATION AND APPROXIMATION, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	6th International Symposium on Abstraction, Reformulation and Approximation	JUL 26-29, 2005	Airth, SCOTLAND				CROSS-VALIDATION; CLASSIFICATION	This paper describes and experimentally analyses a new dimension reduction method for microarray data. Microarrays, which allow simultaneous measurement of the level of expression of thousands of genes in a given situation (tissue, cell or time), produce data which poses particular machine-learning problems. The disproportion between the number of attributes (tens of thousands) and the number of examples (hundreds) requires a reduction in dimension. While gene/class mutual information is often used to filter the genes we propose an approach which takes into account gene-pair/class information. A gene selection heuristic based on this principle is proposed as well as an automatic feature-construction procedure forcing the learning algorithms to make use of these gene pairs. We report significant improvements in accuracy on several public microarray databases.	Univ Paris 13, Lim&Bio, Bobigny, France	Hanczar, B (reprint author), Univ Paris 13, Lim&Bio, Bobigny, France.	hanczar@limbio-paris13.org					Bellman R., 1961, ADAPTIVE CONTROL PRO; BENDOR A, 2000, AGL200013; BO T, 2002, GENOME BIOL; Braga-Neto UM, 2004, BIOINFORMATICS, V20, P374, DOI 10.1093/bioinformatics/btg419; CAKMAKOV D, 2002, FEATURE SELECTION PA; CLEMENT, 2000, ANN ENDOCRINOL; Clement H., 2003, SIGKDD EXPLORATIONS, V5, P23; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; GEMAN D, 2004, P 36 S INT COMP SCI; HWANG KB, 2002, METHODS MICROARRAY D, P167; INZA I, 2002, J INTELL FUZZY SYST, P25; JAKULIN A, 2003, P 7 EUR C PRINC PRAC, P229; LEE JW, IN PRESS COMPUTATION; LI L, 2001, COMB CHEM HIGH T SCR, P727; QI H, 2002, INT C MATH ENG TECHN; WU X, 2003, SIGKDD EXPLORATION, V5, P91; XING EP, 2001, P 18 INT C MACH LEAR	18	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-27872-9	LECT NOTES ARTIF INT			2005	3607						261	273				13	Computer Science, Artificial Intelligence	Computer Science	BCS42	WOS:000231037400019	
S	Wang, Y; de Silva, CW			IEEE	Wang, Y; de Silva, CW			An object transportation system with multiple robots and machine learning	ACC: PROCEEDINGS OF THE 2005 AMERICAN CONTROL CONFERENCE, VOLS 1-7	Proceedings of the American Control Conference		English	Proceedings Paper	American Control Conference 2005 (ACC)	JUN 08-10, 2005	Portland, OR	Amer Automat Control Council, IFAC, AIAA, AIChE, AIST, ASCE, ASME, IEEE, ISA, SCS			MOBILE ROBOTS	This paper investigates the problem of object transportation, particularly pushing or moving an object to a goal location and orientation, using multiple robots. A multi-agent architecture is established to realize effective cooperation between multiple autonomous intelligent robots, in carrying out the task. Machine Learning is incorporated into the architecture. In the developed approach, the world state of the task is established by fusing sensory information. Two machine learning and optimization methods, Reinforcement Learning (RL) and Genetic Algorithms (GA), are combined to learn a cooperation strategy and based on which, determine the optimal actions to reach the task goal. The outputs of RL and GA are evaluated by an arbitrator using a probabilistic method, which will resolve conflicts and improve the overall performance. The feasibility of the scheme is illustrated through computer simulation.	Univ British Columbia, Dept Mech Engn, Vancouver, BC V6T 1Z4, Canada	Wang, Y (reprint author), Univ British Columbia, Dept Mech Engn, Vancouver, BC V6T 1Z4, Canada.	yingwang@interchange.ubc.ca; desilva@mech.ubc.ca					Asada M, 1999, ARTIF INTELL, V110, P275, DOI 10.1016/S0004-3702(99)00026-0; Karray F.O., 2004, SOFT COMPUTING INTEL; Liu Jiming, 2001, MULTIAGENT ROBOTIC S; Mataric M. J., 1995, Proceedings. 1995 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human Robot Interaction and Cooperative Robots (Cat. No.95CB35836), DOI 10.1109/IROS.1995.525940; Mitchell T, 1997, MACHINE LEARNING; Miyata N, 2002, IEEE T ROBOTIC AUTOM, V18, P769, DOI 10.1109/TRA.2002.803464; Rus D., 1995, Proceedings. 1995 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human Robot Interaction and Cooperative Robots (Cat. No.95CB35836), DOI 10.1109/IROS.1995.525802; Stone P, 1998, APPL ARTIF INTELL, V12, P165, DOI 10.1080/088395198117811; Weiss G., 1999, MULTIAGENT SYSTEMS	9	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0743-1619	0-7803-9098-9	P AMER CONTR CONF			2005							1371	1376				6	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	BCY93	WOS:000231947701110	
S	Li, Y; Hu, ZH; Cai, YZ; Xu, XM			IEEE	Li, Y; Hu, ZH; Cai, YZ; Xu, XM			Feature selection via modified RSBRA for SVM classifiers	ACC: Proceedings of the 2005 American Control Conference, Vols 1-7	PROCEEDINGS OF THE AMERICAN CONTROL CONFERENCE		English	Proceedings Paper	American Control Conference 2005 (ACC)	JUN 08-10, 2005	Portland, OR	Amer Automat Control Council, IFAC, AIAA, AIChE, AIST, ASCE, ASME, IEEE, ISA, SCS				Discretization can remove redundant and irrelative attributes during converting continuous attributes into discretized ones and therefore can be used for feature selection. Rough sets and Boolean reasoning based discretization approach (RSBRA), put forward by Nguyen in 1995 181, is very noticeable for its efficiency of reduction. However, the RSBRA is not a suitable feature selection, method for machine learning algorithm such as neural network or SVM because too much useful information loses due to the discretization. In this paper, we present a modified RSBRA for feature selection and evaluate it with SVM classifiers. In the presented algorithm, the level of consistency, coined from the rough sets theory, is introduced to substitute the stop criterion of circulation of the RSBRA, which maintains the fidelity of the training set after discretization. Experiment results show the modified algorithm has better predictive accuracies and less training time than the original RSBRA.	Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200030, Peoples R China	Li, Y (reprint author), Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200030, Peoples R China.						BOSCR B, 1992, P 5 ANN WORKSH COMP, P144; CHMIELEWSKI MR, 1994, P 3 INT WORKSH ROUGH, P294; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; Kerber R., 1992, P 10 NAT C ART INT, P123; LIU H, 1997, IEEE T KNOWLEDGE DAT, V9; NGUYEN HS, 1995, P 2 JOINT ANN C INF, P37; NGUYEN HS, 1996, P INF PROC MAN UNC K, P1451; RICHELDI M, 1995, LECT NOTES ARTIF INT, V914, P335; TAY FEH, 2002, IEEE T KNOWLEDGE DAT, V14; Ventura D., 1995, P 10 INT S COMP INF, P443; WONG AKC, 1987, IEEE T PATTERN ANAL, V9, P796	11	1	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0743-1619	0-7803-9098-9	P AMER CONTR CONF			2005							1455	1459				5	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	BCY93	WOS:000231947701124	
S	Li, CS; Cheng, KH; Chen, JL; Chen, CM			IEEE	Li, CS; Cheng, KH; Chen, JL; Chen, CM			Self-organizing intelligent system and its application for hard disk drive control	ACC: Proceedings of the 2005 American Control Conference, Vols 1-7	PROCEEDINGS OF THE AMERICAN CONTROL CONFERENCE		English	Proceedings Paper	American Control Conference 2005 (ACC)	JUN 08-10, 2005	Portland, OR	Amer Automat Control Council, IFAC, AIAA, AIChE, AIST, ASCE, ASME, IEEE, ISA, SCS			ALGORITHM; NETWORK	An intelligent system with self-organizing ability is discussed in this paper. The intelligent system is based on computational models of fuzzy inference, neural-processing, and machine learning. The concept of pseudo errors is utilized in the study. Clusters are generated from the pseudo-error information, and they are corresponding to fuzzy rules of the self-organizing neuro-fuzzy system (SO-NFS). In this paper, a learning scheme is proposed for hard disk drive (HDD) motion control. The SO-NFS is used as a controller to the HDD servo system for both the track-seeking and the track-following motion control. A reference speed-displacement curve is used to guide the control process. Good performance of the proposed approach is observed.	Chang Gung Univ, Dept Elect Engn, Taoyuan 333, Taiwan	Li, CS (reprint author), Chang Gung Univ, Dept Elect Engn, Taoyuan 333, Taiwan.						Guo G, 2002, IEE P-CONTR THEOR AP, V149, P237, DOI 10.1049/ip-cta:20020233; HORIKAWA S, 1992, IEEE T NEURAL NETWOR, V3, P801, DOI 10.1109/72.159069; Juang CF, 1998, IEEE T FUZZY SYST, V6, P12; Leung FHF, 2003, IEEE T NEURAL NETWOR, V14, P79, DOI 10.1109/TNN.2002.804317; Li CS, 2003, IEEE T FUZZY SYST, V11, P135, DOI 10.1109/TFUZZ.2002.805898; Li CS, 2001, IEEE T IND ELECTRON, V48, P983; LIN CT, 1995, FUZZY SET SYST, V70, P183, DOI 10.1016/0165-0114(94)00216-T; SUSUMU H, 2000, IEEE T MECHATRONICS, V5, P73; TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116; Zhang DQ, 2000, IEE P-CONTR THEOR AP, V147, P440, DOI 10.1049/ip-cta:20000501	10	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0743-1619	0-7803-9098-9	P AMER CONTR CONF			2005							2263	2268				6	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	BCY93	WOS:000231947703004	
S	Flores-Quintanilla, JL; Morales-Menendez, R; Ramirez-Mendoza, RA; Garza-Castanon, LE; Cantu-Ortiz, FJ			IEEE	Flores-Quintanilla, JL; Morales-Menendez, R; Ramirez-Mendoza, RA; Garza-Castanon, LE; Cantu-Ortiz, FJ			Towards a new fault diagnosis system for electric machines based on dynamic probabilistic models	ACC: Proceedings of the 2005 American Control Conference, Vols 1-7	PROCEEDINGS OF THE AMERICAN CONTROL CONFERENCE		English	Proceedings Paper	American Control Conference 2005 (ACC)	JUN 08-10, 2005	Portland, OR	Amer Automat Control Council, IFAC, AIAA, AIChE, AIST, ASCE, ASME, IEEE, ISA, SCS				This paper presents a new approach to diagnose faults in electrical systems based on probabilistic modelling and machine learning techniques. Our framework consist of two phases: an approximated diagnosis on the first phase and a refined diagnosis on the second phase. On the first phase the system behavior is modelled with a Dynamic Bayesian Network that generates a subset of most likely faulty components. In this phase the structure and parameters of the Dynamic Bayesian Network are learned off-line from raw data (discrete and continuous). On the second phase a Particle Filter algorithm is used to monitor suspicious components and extract the faulty components. The feasibility of this approach has been tested in a simulation environment using several interconnected electrical machines.	ITESM, Ctr Innovat & Design & Technol, Mexico City, DF, Mexico	Flores-Quintanilla, JL (reprint author), ITESM, Ctr Innovat & Design & Technol, Monterrey Campus, Mexico City, DF, Mexico.		Morales-Menendez, Ruben/F-7181-2012	Morales-Menendez, Ruben/0000-0003-0498-1566			Awadallah MA, 2003, IEEE T ENERGY CONVER, V18, P245, DOI 10.1109/TEC.2003.811739; BARIGOZZI A, 2004, CONTROL SYSTEMS TECH, V12, P950; DEARDEN R, 2004, P IEEE AER C BIG SKY; De Freitas N, 2004, P IEEE, V92, P455, DOI 10.1109/JPROC.2003.823157; Doucet A., 2000, UNCERTAINTY ARTIFICI, P176; Doucet A., 1998, 310 CUEDFINFENGTR; GARZA LE, 2001, THESIS ITESM MONTERR; Gertler J, 1998, FAULT DETECTION DIAG; Isermann R, 1997, CONTROL ENG PRACT, V5, P639, DOI 10.1016/S0967-0661(97)00046-4; Larson EC, 2002, P AM CONTR C, V5, P4215, DOI 10.1109/ACC.2002.1024593; LUGHOFER E, 2004, INTELLIGENT SYSTEMS, V1, P184; MORALESMENENDEZ R, 2002, ADV NEURAL INFORMATI, V16; Morales-Menendez R, 2004, LECT NOTES COMPUT SC, V2972, P555; MORALESMENENDEZ R, 2004, MODELLING IDENTIFICA; POOLE D, 2000, 1 INT C COMP LOG LON; Poole D, 1997, ARTIF INTELL, V94, P7, DOI 10.1016/S0004-3702(97)00027-1; SHAOYUAN Z, 2004, P 2004 AM CONTR C JU, V6, P5680; SHENG Q, 2003, P 2003 IEEE C 23 25, V2, P1381, DOI 10.1109/CCA.2003.1223214; VALLES F, 2002, AVANCES INTELIGENCIA	19	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0743-1619	0-7803-9098-9	P AMER CONTR CONF			2005							2775	2780		10.1109/ACC.2005.1470389		6	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	BCY93	WOS:000231947703086	
S	Wang, QD; Dai, HP; Sun, YX			IEEE	Wang, QD; Dai, HP; Sun, YX			A novel feature decomposition method to develop multi-hierarchy model	ACC: Proceedings of the 2005 American Control Conference, Vols 1-7	PROCEEDINGS OF THE AMERICAN CONTROL CONFERENCE		English	Proceedings Paper	American Control Conference 2005 (ACC)	JUN 08-10, 2005	Portland, OR	Amer Automat Control Council, IFAC, AIAA, AIChE, AIST, ASCE, ASME, IEEE, ISA, SCS		rough set; feature decomposition; classification; rule induction; concept hierarchy	FEATURE TRANSFORMATION	The comprehensibility of a model is very important since the results should be ultimately be interpreted by a human. This paper presents a new machine learning method, named feature decomposition method based on rough set theory, to discover concept hierarchies and develop a multi-hierarchy model of database. First the features with more relations are selected into a feature group. Then some measures by rough set theory are presented in this paper. According to these measures, the objects defined on the proposed feature group are labeled to discover a new concept. The new concept hierarchies of the database usually have specific meaning, which increase the transparency of data mining process. Finally the rule induction can process on the concept hierarchies of the database to develop a new multi-hierarchy model. The idea presented is illustrated with examples and datasets from UCI Machine Learning Repository. The results show that the multi-hierarchy model established by feature decomposition method can get high classification accuracy and have better comprehensibility.	Zhejiang Univ, Natl Key Lab Ind Control Technol, Hangzhou 310027, Peoples R China	Wang, QD (reprint author), Zhejiang Univ, Natl Key Lab Ind Control Technol, Hangzhou 310027, Peoples R China.						CHAN PK, 1995, P 12 INT C MACH LEAR; CURTIS HA, 1962, ANEW APPROACH DESIGN; Fayyad U.M., 1996, DATA MIN KNOWL DISC, P1; Kusiak A, 2001, IEEE T ELECTRON PA M, V24, P214, DOI 10.1109/6104.956807; Kusiak A, 2000, IEEE T ELECTRON PA M, V23, P345, DOI 10.1109/6104.895081; MAIMON O, 2002, LNCS, V2284, P178; Pawlak Z., 1991, ROUGH SETS THEORETIC; RIDGEWAY G, P 4 INT C KNOWL DISC, P101; Thrun S, 1991, CMUCS91197; YAO YY, 1999, 3 PAC AS C KNOWL DIS, P133; ZAKI MJ, 2000, LARGE SCLAE PARALLEL; Zupan B, 1998, IEEE INTELL SYST APP, V13, P38, DOI 10.1109/5254.671090	12	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0743-1619	0-7803-9098-9	P AMER CONTR CONF			2005							3157	3161				5	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	BCY93	WOS:000231947704030	
S	Shimbo, M; Yamasaki, T; Matsumoto, Y		Tsumoto, S; Yamaguchi, T; Numao, M; Motoda, H		Shimbo, M; Yamasaki, T; Matsumoto, Y			Sentence role identification in medline abstracts: Training classifier with structured abstracts	ACTIVE MINING	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	2nd International Workshop on Active Mining	OCT 28-31, 2003	Maebashi City, JAPAN	Maebashi Inst Technol, Maebashi Convent Bur, Maebashi City Govt, Gunma Prefecture Govt, JSAI SIGKBS		medline; structured abstracts; information retrieval; text classification		The abstract of a scientific paper typically consists of sentences describing the background of study, its objective, experimental method and results, and conclusions. We discuss the task of identifying which of these "structural roles" each sentence in abstracts plays, with a particular focus on its application in building a literature retrieval system. By annotating sentences in an abstract collection with role labels, we can build a literature retrieval system in which users can specify the roles of the sentences in which query terms should be sought. We argue that this facility enables more goal-oriented search, and also makes it easier to narrow down search results when adding extra query terms does not work. To build such a system, two issues need to be addressed: (1) how we should determine the set of structural roles presented to users from which they can choose the target search area, and (2) how we should classify each sentence in abstracts by their structural roles, without relying too much on human supervision. We view the task of role identification as that of text classification based on supervised machine learning. Our approach is characterized by the use of structured abstracts for building training data. In structured abstracts, which is a format of abstracts popular in biomedical domains, sections are explicitly marked with headings indicating their structural roles, and hence they provide us with an inexpensive way to collect training data for sentence classifiers. Statistics on the structured abstracts contained in Medline give an insight on determining the set of sections to be presented to users as well.	Nara Inst Sci & Technol, Grad Sch Informat Sci, Nara 6300192, Japan	Shimbo, M (reprint author), Nara Inst Sci & Technol, Grad Sch Informat Sci, 8916-5 Takayama, Nara 6300192, Japan.	shimbo@is.naist.jp; takah-ya@is.naist.jp; matsu@is.naist.jp					HAYNES RB, 1987, ANN INTERN MED, V106, P598; Charniak Eugene, 2000, P 1 C N AM CHAPT ASS, P132; Collins M., 1999, THESIS U PENNSYLVANI; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Halliday M. A. K., 1976, COHESION ENGLISH; Lafferty J., 2001, P 18 INT C MACH LEAR, P282; LAWRENCE S, 1999, IEEE COMPUT, V32, P67; Lee L., 1999, P 37 ANN M ASS COMP, P25, DOI 10.3115/1034678.1034693; Scholkopf B., 2002, LEARNING KERNELS; SHA F., 2003, P HLT NAACL, P213; Vapnik VN, 1998, STAT LEARNING THEORY	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-26157-5	LECT NOTES COMPUT SC			2005	3430						236	254				19	Computer Science, Artificial Intelligence	Computer Science	BCN63	WOS:000230300800013	
B	Rocha, M; Cortez, P; Neves, J		Ribeiro, B; Albrecht, RF; Dobnikar, A; Pearson, DW; Steele, NC		Rocha, M; Cortez, P; Neves, J			Evolutionary design of neural networks for classification and regression	Adaptive and Natural Computing Algorithms	SPRINGER COMPUTER SCIENCE		English	Proceedings Paper	7th International Conference on Adaptive and Natural Computing Algorithms (ICANNGA)	MAR 21-23, 2005	Coimbra, PORTUGAL		Univ Coimbra	Supervised Machine Learning; Multilayer Perceptrons; Evolutionary algorithms; ensembles.		The Multilayer Perceptrons (MLPs) are the most popular class of Neural Networks. When applying MLPs, the search for the ideal architecture is a crucial task, since it should should be complex enough to learn the input/output mapping, without overfitting the training data. Under this context, the use of Evolutionary Computation makes a promising global search approach for model selection. On the other hand, ensembles (combinations of models) have been boosting the performance of several Machine Learning (ML) algorithms. In this work, a novel evolutionary technique for MLP design is presented, being also used an ensemble based approach. A set of real world classification and regression tasks was used to test this strategy, comparing it with a heuristic model selection, as well as with other ML algorithms. The results favour the evolutionary MLP ensemble method.	Univ Minho, Dept Informat, P-4719 Braga, Portugal	Rocha, M (reprint author), Univ Minho, Dept Informat, P-4719 Braga, Portugal.		Cortez, Paulo/A-2674-2008; Rocha, Miguel/B-9404-2011	Cortez, Paulo/0000-0002-7991-2090; Rocha, Miguel/0000-0001-8439-8172			Blake C. L., 1998, UCI REPOSITORY MACHI; CORTEZ P, 2001, P 3 INT S AD SYST EV, P84; Dietterich TG, 1997, AI MAG, V18, P97; Haykin S., 1999, NEURAL NETWORKS COMP; KOHAVI R, 1995, P INT JOINT C ART IN; Kwok TY, 1997, IEEE T NEURAL NETWOR, V8, P630; Liu Y, 2000, IEEE T EVOLUT COMPUT, V4, P380; QUINLAN JR, 1994, COMPUTATIONAL LEARNI, V1, P445; RIEDMILLER M, 1994, COMPUTER STANDARDS I, V16; ROCHA M, P 4 S ENG INT SYST E; Setiono R., 2003, COMPUT INTELL, P99; THIMM G, 1995, P INT S ART NEUR NET, P20; Witten I. H., 2000, DATA MINING PRACTICA; Yao X, 1999, P IEEE, V87, P1423	14	3	3	SPRINGER-VERLAG WIEN	VIENNA	SACHSENPLATZ 4-6, A-1201 VIENNA, AUSTRIA		3-211-24934-6	SPRING COMP SCI			2005							304	307		10.1007/3-211-27389-1_73		4	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BCH94	WOS:000229368400073	
B	Liu, QZ; Sung, AH; Ribeiro, BM		Ribeiro, B; Albrecht, RF; Dobnikar, A; Pearson, DW; Steele, NC		Liu, QZ; Sung, AH; Ribeiro, BM			Statistical correlations and machine learning for steganalysis	Adaptive and Natural Computing Algorithms	SPRINGER COMPUTER SCIENCE		English	Proceedings Paper	7th International Conference on Adaptive and Natural Computing Algorithms (ICANNGA)	MAR 21-23, 2005	Coimbra, PORTUGAL		Univ Coimbra		NATURAL IMAGES	In this paper, we present a scheme for steganalysis based on statistical correlations and machine learning. In general, digital images are highly correlated in the spatial domain and the wavelet domain; hiding data in images will affect the correlations. Different correlation features are chosen based on ANOVA (analysis of variance) in different steganographic systems. Several machine teaming methods are applied to classify, the extracted feature vectors. Experimental results indicate that our scheme in detecting the presence of hidden messages in several steganographic systems is highly effective.	New Mexico Inst Min & Technol, Dept Comp Sci, Socorro, NM 87801 USA	Liu, QZ (reprint author), New Mexico Inst Min & Technol, Dept Comp Sci, Socorro, NM 87801 USA.						AVCIBAS I, 2003, IEEE T IMAGE PROCESS, V12; CELIK MU, 2004, P SPIE SECURITY STEG, V5306; Duda R. O., 2001, PATTERN CLASSIFICATI; FARID H, 2002, ICIP 2002 ROCH NEW Y; FRIDRICH J, 2001, IEEE, P22; HUANG J, 1999, STAT NATURAL IMAGES, V1; Kawaguchi E, 1998, P SOC PHOTO-OPT INS, V3528, P464; LYU S, 2004, P SPIE SEC STEG WAT, V5306; Provos N., 2001, Proceedings of the 10th USENIX Security Symposium; Rencher A, 1995, METHODS MULTIVARIATE; Schipul S. E., 2012, STAT NEURAL CLASSIFI; Schlesinger M. I., 2002, 10 LECT STAT STRUCTU; Scholkopf B., 2002, LEARNING KERNELS; Srivastava A, 2003, J MATH IMAGING VIS, V18, P17, DOI 10.1023/A:1021889010444; Wainwright MJ, 2000, ADV NEUR IN, V12, P855; Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61; Westfeld A., 2001, LNCS, V2137, P289; Winkler G., 1995, IMAGE ANAL RANDOM FI; YU J, 2003, PACIFIC RIM WORKSHOP	19	2	2	SPRINGER-VERLAG WIEN	VIENNA	SACHSENPLATZ 4-6, A-1201 VIENNA, AUSTRIA		3-211-24934-6	SPRING COMP SCI			2005							437	440		10.1007/3-211-27389-1_105		4	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BCH94	WOS:000229368400105	
B	Mukkamala, S; Sung, AH; Ribeiro, BM		Ribeiro, B; Albrecht, RF; Dobnikar, A; Pearson, DW; Steele, NC		Mukkamala, S; Sung, AH; Ribeiro, BM			Model selection for kernel based intrusion detection systems	ADAPTIVE AND NATURAL COMPUTING ALGORITHMS	SPRINGER COMPUTER SCIENCE		English	Proceedings Paper	7th International Conference on Adaptive and Natural Computing Algorithms (ICANNGA)	MAR 21-23, 2005	Coimbra, PORTUGAL		Univ Coimbra			This paper describes results concerning the robustness and generalization capabilities of a supervised machine learning method in detecting intrusions using network audit trails. We also evaluate the impact of kernel type and parameter values on the accuracy with which a support vector machine (SVM) performs intrusion classification. We show that classification accuracy varies with the kernel type and the parameter values; thus, with appropriately chosen parameter values, intrusions can be detected by SVMs with higher accuracy and lower rates of false alarms. Feature selection is as important for intrusion detection as it is for many other problems. We present support vector decision feature selection method for intrusion detection. It is demonstrated that, with appropriately chosen features, intrusions can be detected in real time or near real time.	New Mexico Inst Min & Technol, Dept Comp Sci, Socorro, NM 87801 USA	Mukkamala, S (reprint author), New Mexico Inst Min & Technol, Dept Comp Sci, Socorro, NM 87801 USA.	srinivas@cs.nmt.edu; sung@cs.nmt.edu; bmr@cs.nmt.edu					CHAPELLE O, 1999, ADV NEURAL INFORMATI, V12; Cherkassy V., 2002, J NATURAL COMPUTING, V1, P109; Cristianini N., 2000, SUPPORT VECTOR MACHI; EGAN JP, 1975, SIGNAL DETECTION THE; Fugate M, 2003, INT J PATTERN RECOGN, V17, P441, DOI 10.1142/S0218001403002459; HELLER K, 2003, 3 IEEE C DAT MIN WOR; HU W, 2003, INT C MACH LEARN, P168; Kendall K., 1998, THESIS MIT; LAZAREVIC A, 2003, 3 SIAM C DAT MIN; MUKKAMALA S, 2003, NEURAL NETWORKS SUPP, V1822, P33; MUKKAMALA S, 2003, INT J DIGITAL EVIDEN; Mukkamala S, 2002, IEEE IJCNN, P1702, DOI 10.1109/IJCNN.2002.1007774; Stolfo J., 1999, COST BASED MODELING; WEBSTER SE, 1998, THESIS MIT	14	1	1	SPRINGER-VERLAG WIEN	VIENNA	SACHSENPLATZ 4-6, A-1201 VIENNA, AUSTRIA		3-211-24934-6	SPRING COMP SCI			2005							458	461		10.1007/3-211-27389-1_110		4	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BCH94	WOS:000229368400110	
J	Stone, P; Sutton, RS; Kuhlmann, G				Stone, P; Sutton, RS; Kuhlmann, G			Reinforcement learning for RoboCup soccer keepaway	ADAPTIVE BEHAVIOR			English	Article						multiagent systems; machine learning; multiagent learning; reinforcement learning; robot soccer	FUNCTION APPROXIMATION; MDPS	RoboCup simulated soccer presents many challenges to reinforcement learning methods, including a large state space, hidden and uncertain state, multiple independent agents learning simultaneously, and long and variable delays in the effects of actions. We describe our application of episodic SMDP Sarsa(lambda) with linear tile-coding function approximation and variable; to learning higher-level decisions in a keepaway subtask of RoboCup soccer. In keepaway, one team, "the keepers," tries to keep control of the ball for as long as possible despite the efforts of "the takers." The keepers learn individually when to hold the ball and when to pass to a teammate. Our agents learned policies that significantly outperform a range of benchmark policies. We demonstrate the generality of our approach by applying it to a number of task variations including different field sizes and different numbers of players on each team.	Univ Texas, Dept Comp Sci, Austin, TX 78712 USA; Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2M7, Canada	Stone, P (reprint author), Univ Texas, Dept Comp Sci, 1 Univ Stn C0500, Austin, TX 78712 USA.	pstone@cs.utexas.edu; sutton@cs.ualberta.ca; kuhlmann@cs.utexas.edu					Albus J. S., 1981, BRAINS BEHAV ROBOTIC; Andou T., 1998, RoboCup-97: Robot Soccer. World Cup I; Andre D, 1999, LECT NOTES ARTIF INT, V1604, P346; Andre D., 2002, P 18 NAT C ART INT, P119; Andre D, 2001, ADV NEUR IN, V13, P1019; Bagnell JA, 2001, IEEE INT CONF ROBOT, P1615; Baird L, 1999, ADV NEUR IN, V11, P968; BALCH T, 2000, TEAMBOTS; BALCH T, 2000, TEAMBOTS DOMAIN SOCC; Boutilier C, 1999, J ARTIF INTELL RES, V11, P1; Bradtke S. J., 1995, ADV NEURAL INFORMATI, V7; Chen M., 2003, USERS MANUAL ROBOCUP; Crites RH, 1996, ADV NEUR IN, V8, P1017; DEAN T, 1992, MACHINE LEARNING MET, P67; Dietterich TG, 2000, J ARTIF INTELL RES, V13, P227; Gordon GJ, 2001, ADV NEUR IN, V13, P1040; Guestrin C, 2002, ADV NEUR IN, V14, P1523; HSU WH, 2002, GENETIC EVOLUTIONARY, P764; Kitano H., 1997, P 15 INT JOINT C ART; Koller D, 1999, P 16 INT JOINT C ART, P1332; LIN CS, 1991, IEEE T NEURAL NETWOR, V2, P530, DOI 10.1109/72.134290; Luke S., 1998, RoboCup-97: Robot Soccer. World Cup I; Marsella S, 2001, AUTON AGENT MULTI-AG, V4, P115, DOI 10.1023/A:1010027016147; MCALLESTER D, 2000, ROBOCUP 2000 ROBOT S, P333; Noda I, 1998, APPL ARTIF INTELL, V12, P233, DOI 10.1080/088395198117848; NODA I, 1996, P 4 PAC RIM INT C AR, P570; PIETRO AD, 2002, GECCO 2002 P GEN EV, P1065; Puterman M., 1994, MARKOV DECISION PROB; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; RIEDMILLER M, 2003, ROBOCUP 2002 ROBOT S; Riedmiller M., 2001, RoboCup 2000: Robot Soccer World Cup IV (Lecture Notes in Artificial Intelligence Vol.2019); Rummery GA, 1994, 166 CUEDFINFENGTR; Stone P, 1999, LECT NOTES ARTIF INT, V1604, P261; Stone P., 2000, LAYERED LEARNING MUL; Stone P., 2002, RoboCup 2001: Robot Soccer. World Cup V (Lecture Notes in Artificial Intelligence Vol.2377); Stone P., 2001, Proceedings of the Fifth International Conference on Autonomous Agents, DOI 10.1145/375735.376320; Stone P., 2001, P 18 INT C MACH LEAR, P537; Stone P., 2001, RoboCup 2000: Robot Soccer World Cup IV (Lecture Notes in Artificial Intelligence Vol.2019); Sutton RS, 2000, ADV NEUR IN, V12, P1057; Sutton RS, 1996, ADV NEUR IN, V8, P1038; Sutton RS, 1999, ARTIF INTELL, V112, P181, DOI 10.1016/S0004-3702(99)00052-1; Sutton R.S., 1998, REINFORCEMENT LEARNI; Tan M., 1993, P 10 INT C MACH LEAR, P330; TAYLOR ME, 2005, 4 INT JOINT C AUT AG, P53; TESAURO G, 1994, NEURAL COMPUT, V6, P215, DOI 10.1162/neco.1994.6.2.215; Tsitsiklis JN, 1997, IEEE T AUTOMAT CONTR, V42, P674, DOI 10.1109/9.580874; UCHIBE E, 2001, P GEN EV COMP C, P1122; UCHIBE E, 1999, THESIS OSAKU U; VELOSO M, 1999, P SPIE SENS FUS DEC, V3839; Watkins C. J. C. H., 1989, THESIS KINGS COLL CA; WHITESON S, 2003, 2 INT JOINT C AUT AG, P193	51	72	73	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	1059-7123		ADAPT BEHAV	Adapt. Behav.		2005	13	3					165	188		10.1177/105971230501300301		24	Computer Science, Artificial Intelligence; Psychology, Experimental; Social Sciences, Interdisciplinary	Computer Science; Psychology; Social Sciences - Other Topics	964JW	WOS:000231878400001	
J	O'Looney, J				O'Looney, J			Social work and the new semantic information revolution	ADMINISTRATION IN SOCIAL WORK			English	Article						information technology; semantic web; organizational transformation		While Internet-based information technology (IT) has certainly affected the field of human services, observation suggests that the impact has been relatively less powerful than in other fields of endeavor. In other fields of endeavor, information technologies have been applied to whole-system transformations, involving process re-engineering, job and task restructuring, expert system support, customer management, and the emergence of matrix, network, and virtual organizational designs. Far fewer Of Such changes have occurred as a result of the introduction of IT into organizations dominated by professional social workers. In this essay we attempt to: (1) explain why the field of social work has been relatively immune to IT-supported transformations by outlining the organizational, administrative, policy, and technical barriers to such transformations in the social services domain; (2) identify the important emerging information technologies (agents, the Semantic Web, and machine learning) that could help to overcome the barriers to organizational transformation; (3) delineate the steps that social services organizations and professionals will need to take in order to capitalize on these emerging technologies.								ATKINSON RD, 2003, POLICY REPORT   0501; BERNERSLEE T, 2001, SCI AM           MAY; BORDEN J, 2003, HEALTHCARE SEMANTIC; Brown J. S, 2000, SOCIAL LIFE INFORM; Davies J., 2003, SEMANTIC WEB ONTOLOG; DOWNS L, 1998, UNLEASHING KILLER AP; DUDECK J, 2003, XML HLTH CARE; Fensel Dieter, 2002, SPINNING SEMANTIC WE; FORRER DA, 2001, P 12 ANN C PROD OP M; Gardner RS, 2004, CLIN MED, V4, P18; Gerschenkron Alexander, 1962, EC BACKWARDNESS HIST; GOLBECK J, 2003, P COOPERATIVE I 0827; Kagan SL, 1993, INTEGRATING SERVICES; LUCK M, 2003, AGENT TECHNOLOG 0929; MEDJAHED B, 2003, NAT C DIG GOV RES MA; Morris C., 1993, HARVARD BUSINESS MAR, P86; OLOONEY J, 2002, WIRED GOVT POSSIBILI; OLOONEY J, 1999, IDENTIFYING OPPORTUN; OLOONEY J, 1993, PHI DELTA KAPPAN, V74, P375; OLOONEY J, 1996, REDESIGNING WORK HUM; RICHARDSON M, 2003, TRUST MANAGEMENT SEM; Schoech D., 1999, HUMAN SERVICES TECHN; Schweiger R, 2003, ARTIF INTELL MED, V28, P105, DOI 10.1016/S0933-3657(03)00038-1; TROUPIN R, 2003, PROMULGATING ST 0923; TUTTLE MS, 2003, SEMANTIC WEB PERFECT; ZHARKO A, 2003, SOCIAL DIMENSION SEM; *CTR MED MED SERV, 2003, TECHN SEC MECH GUARD; *WC3, 2003, SEM WEB         0929; 2003, HLTH LEVEL      1215, V7	29	2	2	HAWORTH PRESS INC	BINGHAMTON	10 ALICE ST, BINGHAMTON, NY 13904-1580 USA	0364-3107		ADMIN SOC WORK	Adm. Soc. Work		2005	29	4					5	34		10.1300/J147v29n04_02		30	Public Administration; Social Work	Public Administration; Social Work	992KP	WOS:000233883100002	
S	Balasubramanyam, V; Hielscher, AH		VoDinh, T; Grundfest, WS; Benaron, DA; Cohn, GE		Balasubramanyam, V; Hielscher, AH			Classification of optical tomographic images of rheumatoid finger joints with support vector machines	Advanced Biomedical and Clinical Diagnostic Systems III	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Conference on Advanced Biomedical and Clinical Diagnostic Systems III	JAN 23-26, 2005	San Jose, CA	SPIE		optical tomography; rheumatoid arthritis; machine learning; support vector machines; feature selection	IN-VIVO; BREAST; BRAIN; OXYGENATION; HEMOGLOBIN; ACTIVATION	Over the last years we have developed a sagittal laser optical tomographic (SLOT) imaging system for the diagnosis and monitoring of inflammatory processes in proximal interphalangeal (PIP) joint of patients with rheumatoid arthritis (RA). While cross sectional images of the distribution of optical properties can now be generated easily, clinical interpretation of these images remains a challenge. In first clinical studies involving 78 finger joints, we compared optical tomographs to ultrasound images and clinical analyses. Receiver-operator curves (ROC) were generated using various image parameters, such as minimum and maximum scattering or absorption coefficients. These studies resulted in specificities and sensitivities in the range of 0.7 to 0.76. Recently, we have trained support vector machines (SVMs) to classify images of healthy and diseased joints. By eliminating redundancy using feature selection, we are achieving sensitivities of 0.72 and specificities up to 1.0. Studies with larger patient groups are necessary to validate these findings; but these initial results support the expectation that SVMs and other machine learning techniques can considerably improve image interpretation analysis in optical tomography.	Columbia Univ, Dept Biomed Engn, New York, NY 10027 USA	Hielscher, AH (reprint author), Columbia Univ, Dept Biomed Engn, 500 W 120th St, New York, NY 10027 USA.						BANKS HT, 2000, INVERSE PROBL, V16, P1; Bluestone AY, 2001, OPT EXPRESS, V9, P272; Bluestone AY, 2004, J BIOMED OPT, V9, P1046, DOI 10.1117/1.1784471; Boas DA, 2004, OPT LETT, V29, P1506, DOI 10.1364/OL.29.001506; Brooksby B, 2004, REV SCI INSTRUM, V75, P5262, DOI 10.1063/1.1819634; BURGES C, DATA MINING KNOWLEDG; Chen NG, 2004, J BIOMED OPT, V9, P504, DOI 10.1117/1.1695410; Durduran T, 2004, OPT LETT, V29, P1766, DOI 10.1364/OL.29.001766; Hebden JC, 2004, PHYS MED BIOL, V49, P1117, DOI 10.1088/0031-9155/49/7/003; Heffer E, 2004, J BIOMED OPT, V9, P1152, DOI 10.1117/1.18055521; Hielscher AH, 2002, DIS MARKERS, V18, P313; Hielscher AH, 2004, PHYS MED BIOL, V49, P1147, DOI 10.1088/0031-9155/49/7/005; Intes X, 2003, MED PHYS, V30, P1039, DOI 10.1118/1.1573791; Jebara T., 2003, MACHINE LEARNING DIS; Lunts A., 1967, ENG CYBERN, V3, P98; Mitchell JSB, 1997, ALGORITHMICA, V19, P1; Scheel AK, 2005, ANN RHEUM DIS, V64, P239, DOI 10.1136/ard.2004.024224; Schwaighofer A, 2003, IEEE T BIO-MED ENG, V50, P375, DOI 10.1109/TBME.2003.808827; Srinivasan S, 2003, P NATL ACAD SCI USA, V100, P12349, DOI 10.1073/pnas.2032822100; Taroni P, 2004, J BIOMED OPT, V9, P464, DOI 10.1117/1.1695561; VAPNIK V, 1995, NATURE STAT LEARING; Xu Y, 2002, J BIOMED OPT, V7, P88, DOI 10.1117/1.1427336	22	2	2	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	0-8194-5666-7	P SOC PHOTO-OPT INS			2005	5692						37	43		10.1117/12.591096		7	Engineering, Biomedical; Optics; Radiology, Nuclear Medicine & Medical Imaging	Engineering; Optics; Radiology, Nuclear Medicine & Medical Imaging	BCF50	WOS:000229038700005	
S	Ramos-Jimenez, G; del Campo-Avila, J; Morales-Bueno, R		Li, X; Wang, S; Dong, ZY		Ramos-Jimenez, G; del Campo-Avila, J; Morales-Bueno, R			E-CIDIM: Ensemble of CIDIM classifiers	ADVANCED DATA MINING AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	1st International Conference on Advanced Data Mining and Applications	JUL 22-24, 2005	Wuhan, PEOPLES R CHINA			n	ALGORITHMS	An active research area in Machine Learning is the construction of multiple classifier systems to increase learning accuracy of simple classifiers. In this paper we present E-CIDIM, a multiple classifier system designed to improve the performance of CIDIM, an algorithm that induces small and accurate decision trees. E-CIDIM keeps a maximum number of trees and it induces new trees that may substitute the old trees in the ensemble. The substitution process finishes when none of the. new trees improves the accuracy of any of the trees in the ensemble after a pre-configured number of attempts. In this way, the accuracy obtained thanks to an unique instance of CIDIM can be improved. In reference to the accuracy of the generated ensembles, E-CIDIM competes well against bagging and boosting at statistically significance confidence levels and it usually outperforms them in the accuracy and the average size of the trees in the ensemble.	Univ Malaga, Dept Lenguajes & Ciencias Computac, ETS Ingn Informat, E-29071 Malaga, Spain	Ramos-Jimenez, G (reprint author), Univ Malaga, Dept Lenguajes & Ciencias Computac, ETS Ingn Informat, E-29071 Malaga, Spain.	ramos@lcc.uma.es; jcampo@lcc.uma.es; morales@lcc.uma.es					Aslam JA, 1998, INFORM COMPUT, V141, P85, DOI 10.1006/inco.1998.2664; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Blake C, 2000, UCI REPOSITORY MACHI; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; FERRI C, 2004, P 21 INT C MACH LEAR; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; Freund Y., 1996, P 13 INT C MACH LEAR, P146; Gama J, 2000, MACH LEARN, V41, P315, DOI 10.1023/A:1007652114878; HERRERA F, 2004, TENDENCIAS MINERIA D; Jerez-Aragones JM, 2003, ARTIF INTELL MED, V27, P45, DOI 10.1016/S0933-3657(02)00086-6; Kearns M, 1999, J COMPUT SYST SCI, V58, P109, DOI 10.1006/jcss.1997.1543; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1993, C4 5 PROGR MACH LEAR; Ramos-Jimenez G., 2000, Proceedings of the International Conference on Artificial Intelligence. IC-AI'2000; Ruiz-Gomez J., 1999, COMPUTERS COMPUTACIO, P158; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Utgoff PE, 1997, MACH LEARN, V29, P5, DOI 10.1023/A:1007413323501; Witten I. H., 2000, DATA MINING PRACTICA; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; *R DEV COR TEAM, 2004, FDN STAT COMP VIENN	22	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-27894-X	LECT NOTES ARTIF INT			2005	3584						108	117				10	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BCR26	WOS:000230895000014	
S	Zhao, Y; Li, B; Li, X; Liu, WH; Ren, SJ		Li, X; Wang, S; Dong, ZY		Zhao, Y; Li, B; Li, X; Liu, WH; Ren, SJ			Customer churn prediction using improved one-class support vector machine	ADVANCED DATA MINING AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	1st International Conference on Advanced Data Mining and Applications	JUL 22-24, 2005	Wuhan, PEOPLES R CHINA					Customer Chum Prediction is an increasingly pressing issue in today's ever-competitive commercial arena. Although there are several researches in chum prediction, but the accuracy rate, which is very important to business, is not high enough. Recently, Support Vector Machines (SVMs), based on statistical learning theory, are gaining applications in the areas of data mining, machine learning, computer vision and pattern recognition because of high accuracy and good generalization capability. But there has no report about using SVM to Customer Churn Prediction. According to chum data set characteristic, the number of negative examples is very small, we introduce an improved one-class SVM. And we have tested our method on the wireless industry customer chum data set. Our method has been shown to perform very well compared with other traditional methods, ANN, Decision Tree, and Naive Bays.	Tsing Hua Univ, Cims Res Ctr, Automat Dept, Beijing 100084, Peoples R China	Zhao, Y (reprint author), Tsing Hua Univ, Cims Res Ctr, Automat Dept, Beijing 100084, Peoples R China.	zhaoyu01@mails.tsinghua.edu.cn					Chiang DA, 2003, EXPERT SYST APPL, V25, P293, DOI 10.1016/S0957-4174(03)00073-3; LI KL, 2003, P 2 INT C MACH LEARN; NATH SV, 2003, P 34 ANN M DEC SCI I, P505; NESLIN SA, DEFECTION DETECTION; SCHOLKOPF B, 2001, ESTIMATING SUPPORT H; SCHOLKOPF B, MSRTR9987; TERADATA D, 2002, TERADATA CTR CUSTOME; TRAFALIS TB, 2000, P IEEE INNS ENNS INT, V6, P348; Vapnik V. N, 1995, NATURE STAT LEARNING	9	16	16	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-27894-X	LECT NOTES ARTIF INT			2005	3584						300	306				7	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BCR26	WOS:000230895000036	
S	Hu, WB; Meng, B		Li, X; Wang, S; Dong, ZY		Hu, WB; Meng, B			Design and implementation of web mining system based on multi-agent	ADVANCED DATA MINING AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	1st International Conference on Advanced Data Mining and Applications	JUL 22-24, 2005	Wuhan, PEOPLES R CHINA				AGENTS	Some challenges for website designers are to provide correct and useful information to individual user with different backgrounds and interests, as well as to increase user satisfaction. Most existing Web search tools work only with individual users and do not help a user benefit from previous search experience of others. In this paper, a collaborative Web Mining System, Collector Engine System is presented, a multi-agent system designed to provide postretrieval analysis and enable across-user collaboration in web search and mining. This system allows the user to annotate search sessions and share them with other users. The prototype system and component of Collector Engine System is discussed and described, and especially designs the web Agent, the knowledge discovery of web Agent is extracted based on a combination of web usage mining and machine learning. The system model is established and realized by J2EE technology. The system's application shows that subjects' search performances are improved, compared to individual search scenarios, in which users have no access to previous searches, when they have access to a limited of earlier search session done by other users.	Wuhan Univ, Coll Comp, Comp Applicat Dept, Hubei 430079, Peoples R China	Hu, WB (reprint author), Wuhan Univ, Coll Comp, Comp Applicat Dept, Hubei 430079, Peoples R China.	hwb77129@126.com; mengbo@126.com					Chau M, 2003, DECIS SUPPORT SYST, V35, P167, DOI 10.1016/S0167-9236(02)00103-3; Lang K., 1995, P 12 INT C MACH LEAR; MAES P, 1994, COMMUN ACM, V37, P31; Menczer F, 2000, MACH LEARN, V39, P203, DOI 10.1023/A:1007653114902; Pitkow J., 1997, P 6 INT WORLD WID WE, P451; SPERTUS E, 1997, P 6 INT WWW C, P485; YAO YY, 2002, P 3 INT C ROUGH SETS, P506	7	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-27894-X	LECT NOTES ARTIF INT			2005	3584						491	498				8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BCR26	WOS:000230895000059	
S	Li, T; Chen, CB		Li, X; Wang, S; Dong, ZY		Li, T; Chen, CB			PromPredictor: A hybrid machine learning system for recognition and location of transcription start sites in human genome	ADVANCED DATA MINING AND APPLICATIONS, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	1st International Conference on Advanced Data Mining and Applications	JUL 22-24, 2005	Wuhan, PEOPLES R CHINA				POLYMERASE-II PROMOTERS; CPG ISLANDS; SEQUENCE CLASSIFICATION; GENE MARKERS; IDENTIFICATION; DNA; LOCALIZATION; PREDICTION; DATABASES; SELECTION	In this paper we present a novel hybrid machine learning system for recognition of gene starts in human genome. The system makes predictions of gene start by extracting compositional features and CpG islands information from promoter regions. It combines a new promoter recognition model, coding theory, feature selection and dimensionality reduction with machine learning algorithm. Evaluation on Human chromosome 4, 21, 22 was 64.47% in sensitivity and 82.20% in specificity. Comparison with the three other systems revealed that our system had superior sensitivity and specificity in predicting gene starts. PromPredictor is written in MATLAB and requires Matlab to run. PromPredictor is freely available at www.whtelecom.com/Prompredictor.htm.	Huazhong Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan 430074, Peoples R China	Li, T (reprint author), Huazhong Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan 430074, Peoples R China.	ljrlt@public.wh.hb.cn; chuanboc@163.com					Bajic VB, 2003, GENOME RES, V13, P1923, DOI 10.1101/gr.869803; Bajic VB, 2004, NAT BIOTECHNOL, V22, P1467, DOI 10.1038/nbt1032; Bajic VB, 2002, BIOINFORMATICS, V18, P198, DOI 10.1093/bioinformatics/18.1.198; Bajic VB, 2003, J MOL GRAPH MODEL, V21, P323, DOI 10.1016/S1093-3263(02)00179-1; BASSAT MB, 1982, HDB STAT, V2, P773; BATTITI R, 1992, NEURAL COMPUT, V4, P141, DOI 10.1162/neco.1992.4.2.141; Bell PJL, 1997, YEAST, V13, P1135, DOI 10.1002/(SICI)1097-0061(19970930)13:12<1135::AID-YEA162>3.0.CO;2-1; BIRD AP, 1987, EMBO J, V6, P999; Bohjanen PR, 1997, NUCLEIC ACIDS RES, V25, P4481, DOI 10.1093/nar/25.22.4481; CAVIN, 1998, NUCLEIC ACIDS RES, V26, P353; Chuzhanova NA, 1998, BIOINFORMATICS, V14, P139, DOI 10.1093/bioinformatics/14.2.139; CLAVERIE JM, 1990, METHOD ENZYMOL, V183, P237, DOI 10.1016/0076-6879(90)83017-4; Collins JE, 2003, GENOME RES, V13, P27, DOI 10.1101/gr.695703; CROSS SH, 1995, CURR OPIN GENET DEV, V5, P309, DOI 10.1016/0959-437X(95)80044-1; Cross SH, 1999, NUCLEIC ACIDS RES, V27, P2099, DOI 10.1093/nar/27.10.2099; DASH M, 1997, INTELLIGENT DATA ANA, V3, P1; Davuluri RV, 2001, NAT GENET, V29, P412, DOI 10.1038/ng780; Down TA, 2002, GENOME RES, V12, P458, DOI 10.1101/gr.216102; Fickett JW, 1997, GENOME RES, V7, P861; GARDINERGARDEN M, 1987, J MOL BIOL, V196, P261, DOI 10.1016/0022-2836(87)90689-9; Grillo G, 1996, COMPUT APPL BIOSCI, V12, P1; HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697; HANNENHALLI S, 2001, BIOINFORMATICS, V17, P90; Ioshikhes IP, 2000, NAT GENET, V26, P61; Lander ES, 1996, SCIENCE, V274, P536, DOI 10.1126/science.274.5287.536; Lander ES, 2001, NATURE, V409, P860, DOI 10.1038/35057062; LARSEN F, 1992, GENOMICS, V13, P1095, DOI 10.1016/0888-7543(92)90024-M; Liu RX, 2002, GENOME RES, V12, P462, DOI 10.1101/gr.198002; Ohler U, 2001, TRENDS GENET, V17, P56, DOI 10.1016/S0168-9525(00)02174-0; Pedersen AG, 1999, COMPUT CHEM, V23, P191, DOI 10.1016/S0097-8485(99)00015-7; Pesole G, 2002, NUCLEIC ACIDS RES, V30, P335, DOI 10.1093/nar/30.1.335; Ponger L, 2002, BIOINFORMATICS, V18, P631, DOI 10.1093/bioinformatics/18.4.631; POWELL MJD, 1977, MATH PROGRAM, V12, P241, DOI 10.1007/BF01593790; Riedmiller M., 1993, P IEEE INT C NEUR NE, V586591; Saxonov S, 2000, NUCLEIC ACIDS RES, V28, P185, DOI 10.1093/nar/28.1.185; Scherf M, 2000, J MOL BIOL, V297, P599, DOI 10.1006/jmbi.2000.3589; Shago M, 1996, MOL CELL BIOL, V16, P4337; SOLOVYEV VV, 1993, COMPUT APPL BIOSCI, V9, P17; Venter JC, 2001, SCIENCE, V291, P1304, DOI 10.1126/science.1058040; Wang WD, 1998, P NATL ACAD SCI USA, V95, P492, DOI 10.1073/pnas.95.2.492	40	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-27894-X	LECT NOTES ARTIF INT			2005	3584						552	563				12	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BCR26	WOS:000230895000066	
S	Peng, YH		Li, X; Wang, S; Dong, ZY		Peng, YH			Robust ensemble learning for cancer diagnosis based on microarray data classification	ADVANCED DATA MINING AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	1st International Conference on Advanced Data Mining and Applications	JUL 22-24, 2005	Wuhan, PEOPLES R CHINA				GENE-EXPRESSION DATA; PREDICTION; SELECTION; ARRAYS; TUMOR	DNA microarray technology has demonstrated to be an effective methodology for the diagnosis of cancers by means of microarray data classification. Although much research has been conducted during the recent years to apply machine learning techniques for microarray data classification, there are two important issues that prevent the use of conventional machine learning techniques, namely the limited availability of training samples and the existence of various uncertainties (e.g. biological variability and experiment variability). This paper presents a new ensemble machine learning approach to address these issues in order to achieve a robust microarray data classification. Ensemble learning combines a set of base classifiers as a committee to make appropriate decisions when classifying new data instances. In order to enhance the performance of the ensemble learning process, the approach presented includes a procedure to select optimal ensemble members that maximize the behavioural diversity. The proposed approach has been verified by three microarray datasets for cancer diagnosis. Experimental results have demonstrated that the classifier constructed by the proposed method outperforms not only the classifiers generated by the conventional machine learning techniques, but also the classifiers generated by two widely-used conventional Bagging and Boosting ensemble learning methods.	Univ Bradford, Dept Comp, Bradford BD7 1DP, W Yorkshire, England	Peng, YH (reprint author), Univ Bradford, Dept Comp, Bradford BD7 1DP, W Yorkshire, England.	y.h.peng@bradford.ac.uk	Peng, Yonghong/A-5778-2013	Peng, Yonghong/0000-0002-8806-2075			Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; BERRAR D, 2003, CAMDA2003; BLANCO R, 2004, IN PRESS INT J PATTE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; CAO J, 1995, PATTERN RECOGN, V28, P153, DOI 10.1016/0031-3203(94)00094-3; CHO SB, 2003, CAMDA 2003 C; Cho S.-B., 2003, P 1 AS PAC BIOINF C; Coombes KR, 2002, J COMPUT BIOL, V9, P655, DOI 10.1089/106652702760277372; Cristianini N., 2000, INTRO SUPPORT VECTOR; Dettling M, 2003, BIOINFORMATICS, V19, P1061, DOI 10.1093/bioinformatics/btf867; Dietterich T., 2000, 1 INT WORKSH MULT CL, P1; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; HO TK, 1998, P 14 INT C PATT REC, P545; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Li LP, 2001, BIOINFORMATICS, V17, P1131, DOI 10.1093/bioinformatics/17.12.1131; MUKHERJEE S, 1999, 182 CBCL; Schapire R. E., 1999, 16 INT JOINT C ART I, P1401; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Tan A.C., 2003, APPL BIOINFORMATIC S, V2, P75; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Wang XJ, 2003, BIOINFORMATICS, V19, P1341, DOI 10.1093/bioinformatics/btg154; XING E, 2000, P 18 INT C MACH LEAR, P601; Yu L., 2004, P 10 ACM SIGKDD INT, P737, DOI 10.1145/1014052.1014149	30	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-27894-X	LECT NOTES ARTIF INT			2005	3584						564	574				11	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BCR26	WOS:000230895000067	
S	Wanga, XD; Ye, MY		Wang, A; Zhang, Y; Ishii, Y		Wanga, XD; Ye, MY			Position error correction of position sensitive detector by least squares support vector machine	Advanced Materials and Devices for Sensing and Imaging II	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Conference on Advanced Materials and Devices for Sensing and Imaging II	NOV 08-10, 2004	Beijing, PEOPLES R CHINA	SPIE, Chinese Opt Soc		position sensitive detector; position error; correction; least squares support vector machines		A new method for position error correction of position-sensitive detector (PSD) using least squares support vector machine (LS-SVM) is presented. The LS-SVM is established based on the structural risk minimization principle rather than minimize the empirical error commonly implemented in the neural networks, LS-SVM achieves higher generalization performance than the MLP and RBF neural networks in solving these machine learning problems. Another key property is that unlike MLP' training that requires non-linear optimization with the danger of getting stuck into local minima, training LS-SVM is equivalent to solving a set of linear equations. Consequently, the solution of LS-SVM is always unique and globally optimal. A difference with the RBF neural networks is that no center parameter vectors of the Gaussians have to be specified and no number of hidden units has to be defined because of Mercer's condition. The position error correction procedure has been illustrated using 2D PSD as example. The results indicate that this approach is effective, and the position detection errors can be reduced from +/- 300/mu m to +/- 10 mu m.	Zhejiang Normal Univ, Coll Informat Sci & Engn, Jinhua, Peoples R China	Wanga, XD (reprint author), Zhejiang Normal Univ, Coll Informat Sci & Engn, Jinhua, Peoples R China.						Henry J, 2003, IEEE SENS J, V3, P519, DOI 10.1109/JSEN.2003.815792; Lin B, 2002, P SOC PHOTO-OPT INS, V4919, P512, DOI 10.1117/12.471903; Schaefer P, 1998, IEEE T INSTRUM MEAS, V47, P914, DOI 10.1109/19.744642; Suykens J. A. K., 2000, Neural Network World, V10; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Tang JY, 2002, P SOC PHOTO-OPT INS, V4919, P18, DOI 10.1117/12.471855; Vapnik V. N., 2000, NATURE STAT LEARNING; Vapnik VN, 1998, STAT LEARNING THEORY; WANG XD, 2002, OPTICAL TECHNIQUE, V28, P174; Wang XD, 2002, P SOC PHOTO-OPT INS, V4919, P452, DOI 10.1117/12.471887	10	1	1	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	0-8194-5588-1	P SOC PHOTO-OPT INS			2005	5633						326	332		10.1117/12.570262		7	Instruments & Instrumentation; Materials Science, Multidisciplinary; Remote Sensing; Optics; Imaging Science & Photographic Technology	Instruments & Instrumentation; Materials Science; Remote Sensing; Optics; Imaging Science & Photographic Technology	BBY98	WOS:000228331600042	
S	Sokolova, M; Szpakowicz, S		Kegl, B; Lapalme, G		Sokolova, M; Szpakowicz, S			Analysis and classification of strategies in electronic negotiations	ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	18th Conference of the Canadian-Society-for-Computational-Studies-of-Intelligence	MAY 09-11, 2005	Victoria, CANADA	Canadian Soc Computat Studies Intelligence				The intensive use of the Web, email and instant messaging for inter- and intra-business communications has resulted in rapid increase of electronic business communication, including negotiations. Simulated electronic negotiations have become an important tool in the study of "real world" electronic negotiations. We explore negotiation strategies by applying Statistical Natural Language Processing and Machine Learning methods to the text data of simulated electronic negotiations. We derive conclusions about strategies in successful and unsuccessful negotiations. We support our. claims by extracting information about strategies and representing data through this information. We classify data and analyze classification results with respect to learning abilities of the classifiers and the data representation.	Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON, Canada	Sokolova, M (reprint author), Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON, Canada.	sokolova@site.uottawa.ca; szpak@site.uottawa.ca					BAZERMAN MH, ANN REV PSYCHOL; Brett J. M., 2001, NEGOTIATING GLOBALLY; CANTRALL W, 1974, VIEWPOINT REFLEXIVES; CELLICH C, 2004, GLOBAL BUSINESS NEGO; Cristianini N., 2000, INTRO SUPPORT VECTOR; Drake LE, 2001, HUM COMMUN RES, V27, P317, DOI 10.1093/hcr/27.3.317; Hargie O., 2004, SKILLED INTERPERSONA; HU J, 2003, NEWS COM; JAOCHIMS T, 1999, ADV KERNEL METHODS S, P169; Jurafsky D., 2000, SPEECH LANGUAGE PROC; Kersten G, 2003, CENTRAL EUROPEAN J O, V11, P297; Kilgarriff A., 2001, INT J CORPUS LINGUIS, V6, P97, DOI 10.1075/ijcl.6.1.05kil; Leech Geoffrey, 1987, MEANING ENGLISH VERB; Manning C. D., 1999, FDN STAT NATURAL LAN; Oakes M., 1998, STAT CORPUS LINGUIST; Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79; Perkins M. R., 1983, MODAL EXPRESSIONS EN; Perloff R. M., 2003, DYNAMICS PERSUASION; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Rudanko Juhani, 1989, COMPLEMENTATION CASE; SCHOOP M, 2003, P LAP 2003, P143; SHAH M, P ICON 2004 HYD IND, P99; SOKOLOVA M, 2004, P CAN AI 2004, P449; SOKOLOVA M, P ICON 2004 HYD IND, P142; Strobel M., 2000, Proceedings of the 8th European Conference on Information Systems; Thompson L, 2002, J SOC ISSUES, V58, P109, DOI 10.1111/1540-4560.00251; Tottie G., 1991, NEGATION ENGLISH SPE; Witten I. H., 2000, DATA MINING	28	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-25864-7	LECT NOTES COMPUT SC			2005	3501						145	157				13	Computer Science, Artificial Intelligence	Computer Science	BCM07	WOS:000229965500016	
S	Bergsma, S		Kegl, B; Lapalme, G		Bergsma, S			Automatic acquisition of gender information for anaphora resolution	ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	18th Conference of the Canadian-Society-for-Computational-Studies-of-Intelligence	MAY 09-11, 2005	Victoria, CANADA	Canadian Soc Computat Studies Intelligence				We present a novel approach to learning gender and number information for anaphora resolution. Noun-pronoun pair counts are collected from gender-indicating lexico-syntactic patterns in parsed corpora, and occurrences of noun-pronoun pairs are mined online from the web. Gender probabilities gathered from these templates provide features for machine learning. Both parsed corpus and web-based features allow for accurate prediction of the gender of a given: noun phrase. Together they constructively combine for 96% accuracy when estimating gender on a list of noun tokens, better than any of our human participants achieved. We show that using this gender information in simple or knowledge-rich pronoun resolution systems significantly improves performance over traditional gender constraints. Our novel gender strategy would benefit any of the current top-performing coreference resolution systems.	Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada	Bergsma, S (reprint author), Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada.	bergsma@cs.ualberta.ca					EVANS R, 2000, P DISC AN REF RES C, P154; GE N, 1998, P 6 WORKSH VER LARG; HAEGEMAN L, 1994, INTRO GOVT BIND THEO; Joachims T., 1999, ADV KERNEL METHODS; Keller F, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P230; Kennedy C., 1996, P 16 INT C COMP LING, P113; Lappin S., 1994, Computational Linguistics, V20; Lin D., 1998, P WORKSH EV PARS SYS; MITKOV R, 2002, P 3 INT C COMP LING, P168; MODJESKA N, 2003, P EACL WORKSH COMP T, P39; Soon WM, 2001, COMPUT LINGUIST, V27, P521, DOI 10.1162/089120101753342653; STUART J, 2003, ARTIF INTELL, P720	12	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-25864-7	LECT NOTES COMPUT SC			2005	3501						342	353				12	Computer Science, Artificial Intelligence	Computer Science	BCM07	WOS:000229965500036	
S	Li, H; Japkowicz, N; Barriere, C		Kegl, B; Lapalme, G		Li, H; Japkowicz, N; Barriere, C			English to Chinese translation of prepositions	ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	18th Conference of the Canadian-Society-for-Computational-Studies-of-Intelligence	MAY 09-11, 2005	Victoria, CANADA	Canadian Soc Computat Studies Intelligence				Machine translation of prepositions is a difficult task; little work has been done, to date, in this area. This article suggests addressing the problem using a semantic framework for the interpretation of the surrounding elements of a preposition in the source language. This framework, called Use Types, will reduce the set of possible prepositions in the target language, therefore helping the translation process. This approach is not language dependent, but we focus, here, on English and Chinese, and we also specifically look at three prepositions: in, on and at. The article describes machine learning experiments designed and conducted in which WordNet is employed to lead to an automatic discovery of the Use Types. Results are analyzed and discussed and a practical use of the system is suggested along with the preliminary results it obtains.	Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON K1N 6N5, Canada	Li, H (reprint author), Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON K1N 6N5, Canada.						FELLBAUM C, 1998, WORDNET ELECT LEXICA, P23; GRIMAUD M, 1988, J AM SOC  GEOLINGUIS, V14, P5476; HERSKOVITS A, 1986, LANGUAGE SPATIAL COG, P39; JAPKOWICZ N, 1990, THESIS U TORONTO; JAPKOWICZ N, 1991, 29 ANN M ASS COMP LI, V29, P153; LI H, 2004, THESIS U OTTAWA; MILLER, 1990, INT J LEXICOGRAPHY, V3; 1978, ADV LEARNERS DICT CU, P58; 1994, OXFORD ADV LEARNERS, P65	9	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-25864-7	LECT NOTES COMPUT SC			2005	3501						412	416				5	Computer Science, Artificial Intelligence	Computer Science	BCM07	WOS:000229965500043	
S	Lorena, AC; de Carvalho, ACPLF		Setubal, JC; VerjovskiAlmeida, S		Lorena, AC; de Carvalho, ACPLF			Protein cellular localization with multiclass Support Vector Machines and Decision Trees	ADVANCES IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	Brazilian Symposium on Bioinformatics (BSB 2005)	JUL 27-29, 2005	Sao Leopoldo, BRAZIL		Univ Vale do Rio dos Sinos	protein cellular localization; Machine Learning; multiclass; Support Vector Machines; Decision Trees	SUBCELLULAR-LOCALIZATION; CLASSIFIERS	Many cellular functions are carried out in compartments of the cell. The cellular localization of a protein is thus related to its function identification. This paper investigates the use of two Machine Learning techniques, Support Vector Machines (SVMs) and Decision Trees (DTs), in the protein cellular localization prediction problem. Since the given task has multiple classes and SVMs are originally designed for the solution of two class problems, several strategies for multiclass SVMs extension were investigated, including one proposed by the authors.	Univ Sao Paulo, ICMC, Sao Paulo, Brazil	Lorena, AC (reprint author), Univ Sao Paulo, ICMC, Sao Paulo, Brazil.	aclorena@icmc.usp.br; andre@icmc.usp.br	Lorena, Ana/A-4494-2008				Ahuja R.K., 1993, NETWORK FLOWS THEORY; Allwein E.L., 2000, P 17 INT C MACH LEAR, P9; CHANG C. C., LIBSVM LIB SUPPORT V; Cheong S., 2004, NEURAL INFORM PROCES, V2, P47; Cristianini N., 2000, INTRO SUPPORT VECTOR; Cui QH, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-66; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Feng Zhi-Ping, 2002, In Silico Biology, V2, P291; Garg A, 2005, J BIOL CHEM, V280, P14427, DOI 10.1074/jbc.M411789200; Horton P, 1997, Proc Int Conf Intell Syst Mol Biol, V5, P147; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Kressel U., 1999, ADV KERNEL METHODS S, P185; Lorena AC, 2005, LECT NOTES ARTIF INT, V3533, P422; Lu Z, 2004, BIOINFORMATICS, V20, P547, DOI 10.1093/bioinformatics/btg447; Mitchell T, 1997, MACHINE LEARNING; Platt JC, 2000, ADV NEUR IN, V12, P547; Quinlan J., 1986, INDUCTION DECISION T, V1, P81, DOI DOI 10.1007/BF00116251; Quinlan J.R., 1988, C4 5 PROGRAMS MACHIN; Salzberg SL, 1997, DATA MIN KNOWL DISC, V1, P317, DOI 10.1023/A:1009752403260; SCHWENKER F, 2000, P 4 INT C KNOWL BAS, P561; Vapnik VN, 1998, STAT LEARNING THEORY; Vural V., 2004, P 21 ICML, P831	22	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28008-1	LECT NOTES COMPUT SC			2005	3594						42	53				12	Biochemical Research Methods; Biochemistry & Molecular Biology; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Biochemistry & Molecular Biology; Computer Science	BCT87	WOS:000231193100006	
S	Monteiro, MI; de Souto, MCP; Goncalves, LMG; Agnez-Lima, LF		Setubal, JC; VerjovskiAlmeida, S		Monteiro, MI; de Souto, MCP; Goncalves, LMG; Agnez-Lima, LF			Machine learning techniques for predicting Bacillus subtilis promoters	ADVANCES IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	Brazilian Symposium on Bioinformatics (BSB 2005)	JUL 27-29, 2005	Sao Leopoldo, BRAZIL		Univ Vale do Rio dos Sinos		ESCHERICHIA-COLI; RNA-POLYMERASE; SEQUENCES; RECOGNITION; NETWORK; GENOME; DNA	One of the most important goals of bioinformatics is the ability to identify genes in uncharacterized DNA sequences. Improved promoter prediction methods can be one step towards developing more reliable ab initio gene prediction methods. In this paper, we present an empirical comparison of machine learning techniques such as Naive Bayes, Decision Trees, Support Vector Machines and Neural Networks to the task of predicting Bacillus subtilis promoters. In order to do so, we first built a data set of promoter and nonpromoter sequences for this organism.	Univ Fed Rio Grande Norte, Dept Comp & Automat, BR-59072970 Natal, RN, Brazil; Univ Fed Rio Grande Norte, Dept Informat & Appl Math, BR-59072970 Natal, RN, Brazil; Univ Fed Rio Grande Norte, Dept Cellular Biol & Genet, BR-59072970 Natal, RN, Brazil	Monteiro, MI (reprint author), Univ Fed Rio Grande Norte, Dept Comp & Automat, BR-59072970 Natal, RN, Brazil.	meika@dca.ufrn.br; marcilio@dimap.ufrn.br; lmarcos@dca.ufrn.br; lfagnez@ufrnet.br	Goncalves, Luiz/C-3786-2009; Agnez-Lima, Lucymara/F-9655-2012	Goncalves, Luiz/0000-0002-7735-5630; 			Alberts B. D., 1989, MOL BIOL CELL; BALDI PF, 1998, MACHINE LEARNING APP; CRAVEN MW, 1994, IEEE EXPERT, V9, P2, DOI 10.1109/64.294127; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Fickett JW, 1997, GENOME RES, V7, P861; HARLEY CB, 1987, NUCLEIC ACIDS RES, V15, P2343, DOI 10.1093/nar/15.5.2343; HELMANN JD, 1995, NUCLEIC ACIDS RES, V23, P2351, DOI 10.1093/nar/23.13.2351; Huerta AM, 2003, J MOL BIOL, V333, P261, DOI 10.1016/j.jmb.2003.07.017; Kanhere A, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-1; Kasabov N., 2004, NEURAL INFORM PROCES, V3, P31; Mitchell T, 1997, MACHINE LEARNING; MULLIGAN ME, 1984, NUCLEIC ACIDS RES, V12, P789, DOI 10.1093/nar/12.1Part2.789; PACES V, 1986, GENE, V44, P115, DOI 10.1016/0378-1119(86)90049-1; Pedersen AG, 1999, COMPUT CHEM, V23, P191, DOI 10.1016/S0097-8485(99)00015-7; Reese MG, 2001, COMPUT CHEM, V26, P51, DOI 10.1016/S0097-8485(01)00099-7; Rombauts S, 2003, PLANT PHYSIOL, V132, P1162, DOI 10.1104/pp.102.017715; STANDEN R, 1984, NUCLEIC ACIDS RES, V12, P505; Tavazoie S, 1999, NAT GENET, V22, P281; TOWELL GG, 1991, THESIS U WISCONSIN; Werner Thomas, 2003, Briefings in Bioinformatics, V4, P22, DOI 10.1093/bib/4.1.22; Witten I. H., 2000, DATA MINING PRACTICA	22	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28008-1	LECT NOTES COMPUT SC			2005	3594						77	84				8	Biochemical Research Methods; Biochemistry & Molecular Biology; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Biochemistry & Molecular Biology; Computer Science	BCT87	WOS:000231193100009	
S	Herrera, J; Huedo, E; Montero, RS; Llorente, IM		Sloot, PMA; Hoekstra, AG; Priol, T; Reinefeld, A; Bubak, M		Herrera, J; Huedo, E; Montero, RS; Llorente, IM			A grid-oriented genetic algorithm	ADVANCES IN GRID COMPUTING - EGC 2005	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	European Grid Conference	FEB 14-16, 2005	Amsterdam, NETHERLANDS	Univ Amsterdam, Dutch Sci Fdn NWO, Sect Exact Sci, SciencePark Amsterdam			FRAMEWORK	Genetic algorithms (GAs) are stochastic search methods that have been successfully applied in many search, optimization, and machine learning problems. Their parallel counterpart (PGA, parallel genetic algorithms) offers many advantages over the traditional GAs, such as speed, ability to search on a larger search space, and less likely to run into a local optimum. With the advent of Grid computing, the computational power that can be deliver to the applications have substantially increased, and so PGAs can potentially benefit from this new Grid technologies. However, because of the dynamic and heterogeneous nature of Grid environments, the implementation and execution of PGAs in a Grid involve challenging issues. This paper discusses the distribution of a PGA across the Grid using the DRMAA standard API and the Grid Way framework. The efficiency and reliability of this schema to solve the One Max problem is analyzed in a globus-based research testbed.	Univ Complutense Madrid, Dept Arquitectura Computadores & Automat, E-28040 Madrid, Spain; CSIC, INTA, Lab Computac Avanzada, Ctr Astrobiol, Torrejon de Ardoz 28850, Spain	Herrera, J (reprint author), Univ Complutense Madrid, Dept Arquitectura Computadores & Automat, E-28040 Madrid, Spain.		Martin Llorente, Ignacio/B-2093-2009; Montero, Ruben/C-5346-2008; Huedo, Eduardo/B-6894-2008	Huedo, Eduardo/0000-0002-2227-2491			ALBA E, 2002, HETEROGENEOUS COMPUT; CANTPAZ E, 1999, SURVEY PARALLEL GENE; Foster I, 1997, INT J SUPERCOMPUT AP, V11, P115, DOI 10.1177/109434209701100205; HAAS A, 2004, DISTRIBUTED RESOURCE; Huedo E, 2004, SOFTWARE PRACT EXPER, V34, P631, DOI 10.1002/spe.584; HUEDOO E, 2004, IN PRESS J SUPERCOMP; Imade H, 2004, NEW GENERAT COMPUT, V22, P177; KANG L, 1999, PARALLEL EVOLUTIONAR; RAJIC H, 2004, DISTRIBUTED RESOURCE; Schaffer J, 1991, P 4 INT C GEN ALG, P61; SCHOPF JM, 2001, GFDI4 GLOB GRID FOR	11	5	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-26918-5	LECT NOTES COMPUT SC			2005	3470						315	322				8	Computer Science, Theory & Methods	Computer Science	BCR15	WOS:000230883700033	
S	Anguita, D; Poggi, A; Rivieccio, F; Scapolla, AM		Sloot, PMA; Hoekstra, AG; Priol, T; Reinefeld, A; Bubak, M		Anguita, D; Poggi, A; Rivieccio, F; Scapolla, AM			Data mining tools: From web to Grid architectures	ADVANCES IN GRID COMPUTING - EGC 2005	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	European Grid Conference	FEB 14-16, 2005	Amsterdam, NETHERLANDS	Univ Amsterdam, Dutch Sci Fdn NWO, Sect Exact Sci, SciencePark Amsterdam				The paradigm of Grid computing is establishing as a novel, reliable and effective method to exploit a pool of hardware resources and make them available to the users. Data-mining benefits from the Grid as it often requires to run time consuming algorithms on large amounts of data which maybe reside on a different resource from the one having the proper data-mining algorithms. Also, in recent times, machine learning methods have been available to the purposes of knowledge discovery, which is a topic of interest for a large community of users. The present work is an account of the evolution of the ways in which a user can be provided with a data-mining service: from a web interface to a Grid service, the exploitation of a complex resource from a technical and a user-friendliness point of view is considered. More specifically, the goal is to show the interest/advantage of running data mining algorithm on the Grid. Such an environment can employ computational and storage resources in an efficient way, making it possible to open data mining services to Grid users and providing services to business contexts.	Univ Genoa, Dept Biophys & Elect Engn, DIBE, I-16145 Genoa, Italy	Anguita, D (reprint author), Univ Genoa, Dept Biophys & Elect Engn, DIBE, Via Opera Pia 11A, I-16145 Genoa, Italy.	anguita@dibe.unige.it; apoggi@dibe.unige.it; rivieccio@dibe.unige.it; ams@dibe.unige.it					Aizerman M.A., 1964, AUTOMAT REM CONTR, P821; ANGUITA D, IN PRESS SUPPORT VEC; ANGUITA D, 2004, 11 PLEN HP OUVA C JU, P2; ANGUITA D, 2000, NEURAL PROCESSING LE, V11; Anguita D, 2003, NEUROCOMPUTING, V55, P109, DOI 10.1016/S0925-2312(03)00430-2; Bartlett PL, 2002, MACH LEARN, V48, P85, DOI 10.1023/A:1013999503812; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Czyzyk J, 1998, IEEE COMPUT SCI ENG, V5, P68, DOI 10.1109/99.714603; DeCoste D., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347165; Efron B., 1993, INTRO BOOTSTRAP; FOSTER I, MODELING STATEFUL RE; Foster I, 2002, PHYSL GRID OPEN GRID; Genton M. G., 2001, J MACHINE LEARNING R, V2, P299; GUYON I, ONLINE SVM APPL LIST; IBM, 2004, WEB SERV RES FRAM; Poggio T., 2003, NOTICES AMS, V50, P537; Vapnik VN, 1998, STAT LEARNING THEORY; Zanghirati G, 2003, PARALLEL COMPUT, V29, P535, DOI 10.1016/S0167-8191(03)00021-8; *GLOB PROJ, 2000, GRIDFTP UN DAT TRANS; *OR CORP, 2004, DISC PATT MAK PRED D	20	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-26918-5	LECT NOTES COMPUT SC			2005	3470						620	629				10	Computer Science, Theory & Methods	Computer Science	BCR15	WOS:000230883700063	
S	Amini, MR; Usunier, N; Gallinari, P		Losada, DE; FernandezLuna, JM		Amini, MR; Usunier, N; Gallinari, P			Automatic text summarization based on word-clusters and ranking algorithms	ADVANCES IN INFORMATION RETRIEVAL	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	27th European Conference on Information Retrieval Research (ECIR 2005)	MAR 21-23, 2005	Santiago Compostela, SPAIN	Microsoft Res, SHARP, ERCIM, CEPIS, BCS	Univ Santiago Compostele, Tech Sch Engn			This paper investigates a new approach for Single Document Summarization based on a Machine Learning ranking algorithm. The use of machine learning techniques for this task allows one to adapt summaries to the user needs and to the corpus characteristics. These desirable properties have motivated an increasing amount of work in this field over the last few years. Most approaches attempt to generate summaries by extracting text-spans (sentences in our case) and adopt the classification framework which consists to train a classifier in order to discriminate between relevant and irrelevant spans of a document. A set of features is first used to produce a vector of scores for each sentence in a given document and a classifier is trained in order to make a global combination of these scores. We believe that the classification criterion for training a classifier is not adapted for SDS and propose an original framework based on ranking for this task. A ranking algorithm also combines the scores of different features but its criterion tends to reduce the relative misordering of sentences within a document. Features we use here are either based on the state-of-the-art or built upon word-clusters. These clusters are groups of words which often co-occur with each other, and can serve to expand a query or to enrich the representation of the sentences of the documents. We analyze the performance of our ranking algorithm on two data sets - the Computation and Language (cmp_1g) collection of TIPSTER SUMMAC and the WIPO collection. We perform comparisons with different baseline - non learning - systems, and a reference trainable summarizer system based on the classification framework. The experiments show that the learning algorithms perform better than the non-learning systems while the ranking algorithm outperforms the classifier. The difference of performance between the two learning algorithms depends on the nature of datasets. We give an explanation of this fact by the different separability hypothesis of the data made by the two learning algorithms.	Comp Sci Lab Paris 6, F-75015 Paris, France	Amini, MR (reprint author), Comp Sci Lab Paris 6, 8 Rue Capitaine Scott, F-75015 Paris, France.	amini@poleia.lip6.fr; usunier@poleia.lip6.fr; gallinarij@poleia.lip6.fr					Amini M.-R., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval; Aslam J.A., 2001, P 24 ANN INT ACM SIG; CAILLET M, 2004, P RIAO; Chuang W.T., 2000, P 23 ANN INT ACM SIG, P152, DOI 10.1145/345508.345566; COLLINS M, 2002, P 40 ANN M ASS COMP; Fellbaum C., 1998, WORDNET ELECT LEXICA; FREUND Y., 2003, J MACHINE LEARNING R, V4, P933, DOI 10.1162/jmlr.2003.4.6.933; Friedman J, 1998, ADDITIVE LOGISTIC RE; Goldstein J., 1999, Proceedings of SIGIR '99. 22nd International Conference on Research and Development in Information Retrieval, DOI 10.1145/312624.312665; JING H, 1998, SUMMARY GENERATION I; KNAUS D, 1994, TREC 4 P; Kupiec J., 1995, P 18 ANN INT ACM SIG, P68, DOI 10.1145/215206.215333; LEBANON G, 2001, CMUCS01144 SCH COMP; LUHN PH, 1958, IBM J, P159; Mani I., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; MARCU D, 1999, P 22 ACM SIGIR; MITRA M, 1997, P ACL EACL 97 WORKSH, P31; PAICE CD, 1993, P 16 ANN INT ACM SIG, P69, DOI 10.1145/160688.160696; SHEN L, 2004, MACHINE LEARNING; SPARCKJONES K, 1993, 29D U CAMBR COMP LAB; SYMONS MJ, 1981, BIOMETRICS, V37, P35, DOI 10.2307/2530520; Taghva K., 1999, International Journal on Document Analysis and Recognition, V1, DOI 10.1007/s100320050018; Teufel S, 1997, P ACL 97 EACL 97 WOR, P58; Xu J., 1996, P 19 ANN INT ACM SIG, V23202; ZECHNER K, 1996, COLING, P986; ZTRZALKOWSKI T, 1998, P 15 NAT C AI, P26	26	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-25295-9	LECT NOTES COMPUT SC			2005	3408						142	156				15	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BCF33	WOS:000229020900011	
S	Hu, YH; Zheng, QH; Bai, HX; Sun, X; Dang, HF		Huang, DS; Zhang, XP; Huang, GB		Hu, YH; Zheng, QH; Bai, HX; Sun, X; Dang, HF			Taxonomy building and machine learning based automatic classification for knowledge-oriented Chinese questions	ADVANCES IN INTELLIGENT COMPUTING, PT 1, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	International Conference on Intelligent Computing	AUG 23-26, 2005	Hefei, PEOPLES R CHINA	Inst Intelligent Machines, Univ Sci Technol, IEEE Computat Intelligence Soc, Hong Kong Computat Intelligence Chapter				In this paper, we propose a taxonomy for knowledge-oriented question, and study the machine learning based classification for knowledge-oriented Chinese questions. By knowledge-oriented questions, we mean questions carrying information or knowledge about something, which cannot be well described by previous taxonomies. We build the taxonomy after the study of previous work and analysis of 6776 Chinese knowledge-oriented questions collected from different realistic sources. Then we investigate the new task of knowledge-oriented Chinese questions classification based on this taxonomy. In our approach, the popular SVM learning method is employed as classification algorithm. We explore different features and their combinations and different kernel functions for the classification, and use different performance metrics for evaluation. The results demonstrate that the proposed approach is desirable and robust. Thorough error analysis is also conduced.	Xian Jiaotong Univ, Dept Comp, Xian 710049, Shaanxi, Peoples R China	Hu, YH (reprint author), Xian Jiaotong Univ, Dept Comp, Xian 710049, Shaanxi, Peoples R China.	yunhuahu@mail.xjtu.edu.cn; qhzheng@mail.xjtu.edu.cn; baihuixian@163.com; sx@mail.xjtu.edu.cn; xjtu_hfdang@163.com					CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; HERMJAKOB U, 2001, P ACL 2001 WORKSH OP, P17; HOVY E, 2002, P HUM LANG TECHN C; HOVY E, 2002, P 9 TEXT RETRIEVAL C, P655; Joachims T., 2000, P 17 INT C MACH LEAR, P431; Kelly D., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; LEHNERT WG, 1986, NATURAL LANGUAGE PRO, P651; Li XM, 2002, POWERCON 2002: INTERNATIONAL CONFERENCE ON POWER SYSTEM TECHNOLOGY, VOLS 1-4, PROCEEDINGS, P556, DOI 10.1109/ICPST.2002.1053604; METZLER D, 2005, J INFORMATION RETRIE, P481; ROTH D, 2002, P 11 REXT RETRIEVAL; SINGHAL A, 2000, P 8 TEXT RETR C TREC, P317; SUZUKI J, 2003, P 41 ANN M ASS COMP, P61; Zhang D., 2003, P 26 ANN INT ACM SIG, P26; ZHENG Q, 2005, MINI MICROSYSTEMS, P554	14	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28226-2	LECT NOTES COMPUT SC			2005	3644						485	494				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDC09	WOS:000232528800051	
S	Xu, X; Xie, T		Huang, DS; Zhang, XP; Huang, GB		Xu, X; Xie, T			A reinforcement learning approach for host-based intrusion detection using sequences of system calls	ADVANCES IN INTELLIGENT COMPUTING, PT 1, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	Conference on Aristophanes Upstairs and Downstairs - Peace, Birds and Frogs in Ancient and Modern Performance	SEP 16-18, 2004	Oxford, ENGLAND	British Acad, Class Assoc, Soc Promot Hellen Studies, Univ Oxford, Craven Comm, Fac Class, Passmore Edwards Fund	Magdalen Coll		MODELS	Intrusion detection has emerged as an important technique for network security. Due to the complex and dynamic properties of intrusion behaviors, machine learning and data mining methods have been widely employed to optimize the performance of intrusion detection systems (IDSs). However, the results of existing work still need to be improved both in accuracy and in computational efficiency. In this paper, a novel reinforcement learning approach is presented for host-based intrusion detection using sequences of system calls. A Markov reward process model is introduced for modeling the behaviors of system call sequences and the intrusion detection problem is converted to predicting the value functions of the Markov reward process. A temporal different learning algorithm using linear basis functions is used for value function prediction so that abnormal temporal behaviors of host processes can be predicted accurately and efficiently. The proposed method has advantages over previous algorithms in that the temporal property of system call data is well captured in a natural and simple way and better intrusion detection performance can be achieved. Experimental results on the MIT system call data illustrate that compared with previous work, the proposed method has better detection accuracy with low training costs.	Natl Univ Def Technol, Sch Comp, Changsha 410073, Peoples R China; Natl Univ Def Technol, Inst Automat, Changsha 410073, Peoples R China	Xu, X (reprint author), Natl Univ Def Technol, Sch Comp, Changsha 410073, Peoples R China.	xuxin_mail@263.net					Denning D., 1987, IEEE T SOFTWARE ENG, V13; Hofmeyr S. A., 1998, Journal of Computer Security, V6; JHA S, 2001, P COMP SEC FDN WORKS; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237; Lane T., 1999, ACM T INFORM SYST, V2, P295, DOI 10.1145/322510.322526; Mukkamala S, 2002, IEEE IJCNN, P1702, DOI 10.1109/IJCNN.2002.1007774; Rao Xian, 2003, Journal of Software, V14; RYAN J, 1998, ADV NEURAL INFORMATI, V10; Lee W, 1999, P IEEE S SECUR PRIV, P120; Sutton R. S., 1988, Machine Learning, V3, DOI 10.1007/BF00115009; Warrender C, 1999, P IEEE S SECUR PRIV, P133, DOI 10.1109/SECPRI.1999.766910; Xu X, 2002, J ARTIF INTELL RES, V16, P259	12	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28226-2	LECT NOTES COMPUT SC			2005	3644						995	1003				9	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDC09	WOS:000232528800103	
S	Yang, J; Xu, YP; Zou, HX		Huang, DS; Zhang, XP; Huang, GB		Yang, J; Xu, YP; Zou, HX			Probabilistic tangent subspace method for M-QAM signal equalization in time-varying multipath channels	ADVANCES IN INTELLIGENT COMPUTING, PT 2, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	International Conference on Intelligent Computing	AUG 23-26, 2005	Hefei, PEOPLES R CHINA	Inst Intelligent Machines, Univ Sci Technol, IEEE Computat Intelligence Soc, Hong Kong Computat Intelligence Chapter			RECURRENT NEURAL-NETWORKS	A new machine learning method called probabilistic tangent subspace is introduced to improve the performance of the equalization for the M-QAM modulation signals in wireless communication systems. Due to the mobility of communicator, wireless communication channels axe time variant. The uncertainties in the time-varying channel's coefficients cause the amplitude distortion as well as the phase distortion of the M-QAM modulation signals. On the other hand, the Probabilistic Tangent Subspace method is designed to encode the pattern variations. Therefore, we are motivated to adopt this method to develop a classifier as an equalizer for time-varying channels. Simulation results show that this equalizer performs better than those based on nearest neighbor method and support vector machine method for Rayleigh fading channels.	Tsing Hua Univ, Dept Automat, Beijing 100084, Peoples R China	Yang, J (reprint author), Tsing Hua Univ, Dept Automat, Beijing 100084, Peoples R China.	yang-jing03@mails.tsinghua.edu.cn; xuyp03@mails.tsinghua.edu.cn; hongxing_zou@tsinghua.edu.cn					BENELLI G, 1991, IEEE P GLOB, P1469; HASTIE T, ADV NEURAL INFORM PR, V7; KECHRIOTIS G, 1994, IEEE T NEURAL NETWOR, V5, P267, DOI 10.1109/72.279190; LEE J, 2004, P 21 INT C MACH LEAR; Liang QL, 2000, IEEE T FUZZY SYST, V8, P551; Parisi R, 1997, IEEE T SIGNAL PROCES, V45, P2731, DOI 10.1109/78.650099; Proakis JG, 1995, DIGITAL COMMUNICATIO; Savazzi P, 1998, IEEE J SEL AREA COMM, V16, P1640, DOI 10.1109/49.737633; Sebald DJ, 2000, IEEE T SIGNAL PROCES, V48, P3217, DOI 10.1109/78.875477; Simard P., 2001, INT J IMAGING SYSTEM, V11, P181; VECIANA GD, 1992, IEEE T COMMUN, V40, P1392	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28227-0	LECT NOTES COMPUT SC			2005	3645						949	957				9	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDC10	WOS:000232529000098	
S	Hullermeier, E; Beringer, J		Famili, AF; Kok, JN; Pena, JM; Siebes, A; Feelders, A		Hullermeier, E; Beringer, J			Learning from ambiguously labeled examples	ADVANCES IN INTELLIGENT DATA ANALYSIS VI, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th International Symposium on Intelligent Data Analysis	SEP 08-10, 2005	Madrid, SPAIN					Inducing a classification function from a set of examples in the form of labeled instances is a standard problem in supervised machine learning. In this paper, we are concerned with ambiguous label classification (ALC), an extension of this setting in which several candidate labels may be assigned to a single example. By extending three concrete classification methods to the ALC setting and evaluating their performance on benchmark data sets, we show that appropriately designed learning algorithms can successfully exploit the information contained in ambiguously labeled examples. Our results indicate that the fundamental idea of the extended methods, namely to disambiguate the label information by means of the inductive bias underlying (heuristic) machine learning methods, works well in practice.	Otto Von Guericke Univ, Fak Informat, Magdeburg, Germany	Hullermeier, E (reprint author), Otto Von Guericke Univ, Fak Informat, Magdeburg, Germany.	eyke.huellermeier@iti.cs.uni-magdeburg.de					Bennett KP, 1999, ADV NEUR IN, V11, P368; Cavarelli J, 1997, STRUCTURE, V5, P813, DOI 10.1016/S0969-2126(97)00235-9; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Clark P., 1991, P 5 EUR WORK SESS LE, P151; Cohen W. W., 1995, P 12 INT C MACH LEAR, P115; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DIETTERICH TG, 1997, ART INTELL J, V89; Domingos P, 1999, DATA MIN KNOWL DISC, V3, P409, DOI 10.1023/A:1009868929893; Furnkranz J, 1999, ARTIF INTELL REV, V13, P3, DOI 10.1023/A:1006524209794; GRANDVALET Y, 2002, IPMU02, P1935; HILLERMEIER E, 2004, IPMU04; JIN R, 2002, NIPS02; McCallum A. K., 1999, AAAI99 WORKSH TEXT L; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; [Anonymous], 1993, P 13 INT JOINT C ART, P1022	15	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28795-7	LECT NOTES COMPUT SC			2005	3646						168	179				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BDA54	WOS:000232273600016	
S	Povalej, P; Kokol, P; Druzovec, TW; Stiglic, B		Famili, AF; Kok, JN; Pena, JM; Siebes, A; Feelders, A		Povalej, P; Kokol, P; Druzovec, TW; Stiglic, B			Machine-learning with Cellular Automata	ADVANCES IN INTELLIGENT DATA ANALYSIS VI, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th International Symposium on Intelligent Data Analysis	SEP 08-10, 2005	Madrid, SPAIN					As the possibility of combining different classifiers into Multiple Classifier System (MCS) becomes an important direction in machine-learning, difficulties arise in choosing the appropriate classifiers to combine and choosing the way for combining their decisions. Therefore in this paper we present a novel approach - Classificational Cellular Automata (CCA). The basic idea of CCA is to combine different classifiers induced on the basis of various machine-learning methods into MCS in a non-predefined way. After several iterations of applying adequate transaction rules only a set of the most appropriate classifiers for solving a specific problem is preserved. We empirically showed that the superior results compared to AdaBoost ID3 are a direct consequence of self-organization abilities of CCA. The presented results also pointed out important advantages of CCA, such as: problem independency, robustness to noise and no need for user input.	Fac Elect Engn & Comp Sci, Maribor 2000, Slovenia	Povalej, P (reprint author), Fac Elect Engn & Comp Sci, Smetanova Ulica 17, Maribor 2000, Slovenia.	Petra.Povalej@uni-mb.si; Kokol@uni-mb.si; Welzer@uni-mb.si; Stiglic@uni-mb.si					Blake CL, UCI REPOSITORY MACHI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Dietterich T., 2000, 1 INT WORKSH MULT CL, P1; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Ganguly N., 2003, SURVEY CELLULAR AUTO; LENIC M, 2003, 3 IEEE INT C DAT MIN, P106; Towell G., 1993, MACH LEARN, P71; von Neumann J, 1966, THEORY SELF REPRODUC; Wolfram S., 2002, NEW KIND SCI	9	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28795-7	LECT NOTES COMPUT SC			2005	3646						305	315				11	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BDA54	WOS:000232273600028	
S	Takahashi, K; Takamura, H; Okumura, M		Ho, TB; Cheung, D; Liu, H		Takahashi, K; Takamura, H; Okumura, M			Automatic occupation coding with combination of machine learning and hand-crafted rules	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	9th Pacific/Asia Conference on Knowledge Discovery and Data Mining	MAY 18-20, 2005	Hanoi, VIETNAM					We apply a machine learning method to the occupation coding, which is a task to categorize the answers to open-ended questions regarding the respondent's occupation. Specifically, we use Support Vector Machines (SVMs) and their combination with hand-crafted rules. Conducting the occupation coding manually is expensive and sometimes leads to inconsistent coding results when the coders are not experts of the occupation coding. For this reason, a rule-based automatic method has been developed and used. However, its categorization performance is not satisfiable. Therefore, we adopt SVMs, which show high performance in various fields, and compare it with the rule-based method. We also investigate effective combination methods of SVMs and the rule-based method. In our methods, the output of the rule-based method is used as features for SVMs. We empirically show that SVMs outperform the rule-based method in the occupation coding and that the combination of the two methods yields even better accuracy.	Keiai Univ, Fac Int Studies, Sakura, Chiba, Japan; Tokyo Inst Technol, Precis & Intelligence Lab, Midori Ku, Yokohama, Kanagawa, Japan	Takahashi, K (reprint author), Keiai Univ, Fac Int Studies, 1-9 Sanno, Sakura, Chiba, Japan.	takak@u-keiai.ac.jp; takamura@pi.titech.ac.jp; oku@pi.titech.ac.jp					Giorgetti D., 2003, P 18 ACM S APPL COMP, P798; HARA J, 1984, SOCIAL SURVEYS SEMIN; Isozaki H, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P184; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Kressel UHG, 1999, ADVANCES IN KERNEL METHODS, P255; KUDO T, 2002, J NATURAL LANGUAGE P, V9, P3; MAINICHI, 2001, CD MAINICHI SHINBUN; PARK SB, 2003, P 41 ANN M ASS COMP, P497; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; TAKAHASHI K, 2002, P 8 ANN M ASS NAT LA, P491; TAKAHASHI K, 2003, JAPANESE VALUES BEHA, P179; TAKAHASHI K, 2004, JAPANESE VALUES BEHA, P163; TAKAHASHI K, 2002, JAPANESE VALUES BEHA, P171; TAKAHASHI K, 2001, KEIAI U INT STUDIES, V8, P31; Takahashi K, 2000, SOCIOL THEOR METHOD, V15, P149; VAPNIK V, 1998, STAT LEARING THEORY; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; *1995SSM SURV RES, 1996, COD 1995SSM SURV; *1995SSM SURV RES, 1995, SSM IND OCC CLASS; *NAT I JAP LANG PU, 1964, WORD LIST SEM PRINC	20	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-26076-5	LECT NOTES ARTIF INT			2005	3518						269	279				11	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BCL84	WOS:000229956700033	
S	Jin, R; Liu, Y		Ho, TB; Cheung, D; Liu, H		Jin, R; Liu, Y			A framework for incorporating class priors into discriminative classification	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	9th Pacific/Asia Conference on Knowledge Discovery and Data Mining	MAY 18-20, 2005	Hanoi, VIETNAM					Discriminative and generative methods provide two distinct approaches to machine learning classification. One advantage of generative approaches is that they naturally model the prior class distributions. In contrast, discriminative approaches directly model the conditional distribution of class given inputs, so the class priors are only implicitly obtained if the input density is known. In this paper, we propose a framework for incorporating class prior proportions into discriminative methods in order to improve their classification accuracy. The basic idea is to enforce that the distribution of class labels predicted on the test data by the discriminative model is consistent with the class priors. Therefore, the discriminative model has to not only fit the training data well but also predict class labels for the test data that are consistent with the class priors. Experiments on five different UCI datasets and one image database show that this framework is effective in improving the classification accuracy when the training data and the test data come from the same class proportions, even if the test data does not have exactly the same feature distribution as the training data.	Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Jin, R (reprint author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.	rongjin@cse.msu.edu; liu3@cse.msu.edu					Berger A. L., 1996, COMPUTATIONAL LINGUI, V22; CHAPELLE O, 1999, IEEE T NEUTRAL NETWO, V9; CORPORATION C, 1999, COREL CLIPART PHOTOS; GOH KS, 2001, P 10 INT C INF KNOWL; Seeger M., 2001, LEARNING LABELED UNL; Shewchuk J., 1994, INTRO CONJUGATE GRAD; TEYTAUD O, 2001, P INT C ART NEUR NET	7	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-26076-5	LECT NOTES ARTIF INT			2005	3518						568	577				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BCL84	WOS:000229956700065	
S	Nguyen, PC; Ohara, K; Motoda, H; Washio, T		Ho, TB; Cheung, D; Liu, H		Nguyen, PC; Ohara, K; Motoda, H; Washio, T			Cl-GBI: A novel approach for extracting typical patterns from graph-structured data	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	9th Pacific/Asia Conference on Knowledge Discovery and Data Mining	MAY 18-20, 2005	Hanoi, VIETNAM					Graph-Based Induction (GBI) is a machine learning technique developed for the purpose of extracting typical patterns from graph-structured data by stepwise pair expansion (pair-wise chunking). GBI is very efficient because of its greedy search strategy, however, it suffers from the problem of overlapping subgraphs. As a result, some of typical patterns cannot be discovered by GBI though a beam search has been incorporated in an improved version of GBI called Beam-wise GBI (B-GBI). In this paper, improvement is made on the search capability by using a new search strategy, where frequent pairs are never chunked but used as pseudo nodes in the subsequent steps, thus allowing extraction of overlapping subgraphs. This new algorithm, called Cl-GBI (Chunking-less GBI), was tested against two datasets, the promoter dataset from UCI repository and the hepatitis dataset provided by Chiba University, and shown successful in extracting more typical patterns than B-GBI.	Osaka Univ, Inst Sci & Ind Res, Ibaraki, Osaka 5670047, Japan	Nguyen, PC (reprint author), Osaka Univ, Inst Sci & Ind Res, 8-1 Mihogaoka, Ibaraki, Osaka 5670047, Japan.	chien@ar.sanken.osaka-u.ac.jp; ohara@ar.sanken.osaka-u.ac.jp; motoda@ar.sanken.osaka-u.ac.jp; washio@ar.sanken.osaka-u.ac.jp					Blake C. L., 1998, UCI REPOSITORY MACHI; Borgelt C., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183885; Breiman L, 1984, CLASSIFICATION REGRE; Cook D. J., 1994, Journal of Artificial Intelligence Research, V1; Fortin S, 1996, TR9620 U ALB DEP COM; GAEMSAKUL W, 2003, P PAKDD 2003, P52; Huan J., 2003, P 3 IEEE INT C DAT M, P549; Inokuchi A, 2003, MACH LEARN, V50, P321, DOI 10.1023/A:1021726221443; INOKUCHI A, 2002, RT0448 IBM TOK RES L; Kuramochi M, 2004, IEEE T KNOWL DATA EN, V16, P1038, DOI 10.1109/TKDE.2004.33; Kuramochi M., 2004, P ICDM 2004, P439; MATSUDA T, 2002, P 5 INT C DISC SCI, P422; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1993, C4 5 PROGR MACH LEAR; Yan X. F., 2002, P 2002 IEEE INT C DA, P721; YOSHIDA K, 1995, ARTIF INTELL, V75, P63, DOI 10.1016/0004-3702(94)00066-A	16	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-26076-5	LECT NOTES ARTIF INT			2005	3518						639	649				11	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BCL84	WOS:000229956700073	
S	Wang, C; Wang, WY		Ho, TB; Cheung, D; Liu, H		Wang, C; Wang, WY			Using term clustering and supervised term affinity construction to boost text classification	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	9th Pacific/Asia Conference on Knowledge Discovery and Data Mining	MAY 18-20, 2005	Hanoi, VIETNAM					The similarity measure is a crucial step in many machine learning problems. The traditional cosine similarity suffers from its inability to represent the semantic relationship of terms. This paper explores the kernel-based similarity measure by using term clustering. An affinity matrix of terms is constructed via the co-occurrence of the terms in both unsupervised and supervised ways. Normalized cut is employed to do the clustering to cut off the noisy edges. Diffusion kernel is adopted to measure the kernel-like similarity of the terms in the same cluster. Experiments demonstrate our methods can give satisfactory results, even when the training set is small.	Tsing Hua Univ, Dept Automat, Beijing 100084, Peoples R China	Wang, C (reprint author), Tsing Hua Univ, Dept Automat, Beijing 100084, Peoples R China.	wangchong99@mails.tsinghua.edu.cn; wwy-dau@tsinghua.edu.cn					FERRER R, 2001, P ROY SOC LOND B BIO, P2261; KANDOLA J, 2002, P NEUR INF PROC SYST; KONDOR RI, 2002, P INT C MACH LEARN I; RIJSBERGEN CJV, 1979, INFORMATION RETRIEVA; SALTON G, 1983, INTRO MODERN INFORMA; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888	6	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-26076-5	LECT NOTES ARTIF INT			2005	3518						813	819				7	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BCL84	WOS:000229956700094	
B	Foster, DP; Stine, RA		Grunwald, PD; Myung, IJ; Pitt, MA		Foster, DP; Stine, RA			The contribution of parameters to stochastic complexity	Advances in Minimum Description Length Theory and Applications	NEURAL INFORMATION PROCESSING SERIES		English	Proceedings Paper	Workshop on Advances in Minimum Description Length - Theory and Applications	DEC, 2001	Whistler, CANADA				MINIMUM DESCRIPTION LENGTH; SELECTION; PRINCIPLE	We consider the contribution of parameters to the stochastic complexity. The stochastic complexity of a class of models is the length of a universal, one-part code representing this class. It combines the length of the maximum likelihood code with the parametric complexity, a normalization that acts as a penalty against overfitting. For models with few parameters relative to sample size, k << n, the parametric complexity is approximately (k)/(2) log n. The accuracy of this approximation, however, deteriorates as k grows relative to n, as occurs in denoising, data mining, and machine learning. For these tasks, the contribution of parameters depends upon the complexity of the model class. Adding a parameter to a model class that already has many produces a different effect than adding one to a model class that has few. In denoising, for example, we show that the parametric complexity leads to an adaptive model selection criterion. We also address the calculation of the parametric complexity when the underlying integration is unbounded over the natural parameter space, as in Gaussian models.	Univ Penn, Wharton Sch, Dept Stat, Philadelphia, PA 19104 USA	Foster, DP (reprint author), Univ Penn, Wharton Sch, Dept Stat, Philadelphia, PA 19104 USA.						ABRAMOVICH F, 2000, 200019 STANF U DEP S; Barron A, 1998, IEEE T INFORM THEORY, V44, P2743, DOI 10.1109/18.720554; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; FOSTER DP, 2002, UNPUB VARIABLE SELEC; FOSTER DP, 1996, 1180 NW U CTR MATH S; Foster DP, 1999, IEEE T INFORM THEORY, V45, P1289, DOI 10.1109/18.761287; George EI, 2000, BIOMETRIKA, V87, P731, DOI 10.1093/biomet/87.4.731; Hansen MH, 2001, J AM STAT ASSOC, V96, P746, DOI 10.1198/016214501753168398; Leadbetter M. R., 1983, EXTREMES RELATED PRO; Rissanen J, 1999, COMPUT J, V42, P260, DOI 10.1093/comjnl/42.4.260; RISSANEN J, 1983, ANN STAT, V11, P416, DOI 10.1214/aos/1176346150; RISSANEN J, 1986, ANN STAT, V14, P1080, DOI 10.1214/aos/1176350051; Rissanen J, 2000, IEEE T INFORM THEORY, V46, P2537, DOI 10.1109/18.887861; Rissanen J., 1989, STOCHASTIC COMPLEXIT; Rissanen JJ, 1996, IEEE T INFORM THEORY, V42, P40, DOI 10.1109/18.481776; Shtarkov Y.M., 1987, PROBL INFORM TRANSM, V23, P3; Stinchcombe AL, 2000, J POLIT PHILOS, V8, P1, DOI 10.1111/1467-9760.00090	17	1	1	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA		0-262-07262-9	NEU INF PRO			2005							195	213				19	Computer Science, Artificial Intelligence; Mathematics, Applied	Computer Science; Mathematics	BCV69	WOS:000231442700008	
B	Yamanishi, K		Grunwald, PD; Myung, IJ; Pitt, MA		Yamanishi, K			Extended stochastic complexity and its applications to learning	ADVANCES IN MINIMUM DESCRIPTION LENGTH THEORY AND APPLICATIONS	Neural Information Processing Series		English	Proceedings Paper	Workshop on Advances in Minimum Description Length - Theory and Applications	DEC, 2001	Whistler, CANADA				INFORMATION; PREDICTION; MODEL	Rissanen has introduced stochastic complexity to define the amount of information in a given data sequence relative to a given hypothesis class of probability densities, where the information is measured in terms of a logarithmic loss associated with universal data compression. We introduce the notion of extended stochastic complexity (ESC) and demonstrate its effectiveness in design and analysis of learning algorithms in online prediction and batch-learning scenarios. ESC can be thought of as an extension of Rissanen's stochastic complexity to the decision-theoretic setting where a general real-valued function is used as a hypothesis and a general loss function is used as a distortion measure. As an application of ESC to online prediction, we show that a sequential realization of ESC produces an online prediction algorithm called Vovk's aggregating strategy, which can be thought of as an extension of the Bayes algorithm. We introduce the notion of the minimax relative cumulative loss as the performance measure of online prediction and show that ESC can be a minimax solution to the minimax relative cumulative loss, which is attained by the aggregating strategy. As an application of ESC to batch-learning, we show that a batch-approximation of ESC induces a batch-learning algorithm called the minimum L-complexity algorithm (MLC), which is an extension of the minimum description length (MDL) principle. We derive upper bounds on the statistical risk for MLC, which are least to date. Through ESC we give a unifying view of the most effective learning algorithms that have recently been explored in machine learning theory.	NEC Corp Ltd, Miyamae Ku, Kawasaki, Kanagawa 2168555, Japan	Yamanishi, K (reprint author), NEC Corp Ltd, Miyamae Ku, 1-1,4 Chome, Kawasaki, Kanagawa 2168555, Japan.	k-yamanisi@cw.jp.nec.com					BARRON AR, 1991, NATO ADV SCI I C-MAT, V335, P561; BARRON AR, 1991, IEEE T INFORM THEORY, V37, P1034, DOI 10.1109/18.86996; Berger J.O., 1985, STAT DECISION THEORY; Cesa-Bianchi N., 1993, Proceeding of the Sixth Annual ACM Conference on Computational Learning Theory; CLARKE BS, 1994, J STAT PLAN INFER, V41, P37, DOI 10.1016/0378-3758(94)90153-8; CLARKE BS, 1990, IEEE T INFORM THEORY, V36, P453, DOI 10.1109/18.54897; DAWID A, 1991, J ROYAL STAT SOC A, V147, P278; DEBRUIJN NG, 1958, ASYMPTOTIC METHODS A; Freund Y., 1996, Proceedings of the Ninth Annual Conference on Computational Learning Theory, DOI 10.1145/238061.238072; Haussler D., 1995, Computational Learning Theory. Second European Conference, EuroCOLT '95. Proceedings; HAUSSLER D, 1992, INFORM COMPUT, V100, P78, DOI 10.1016/0890-5401(92)90010-D; KIVINEN J, 1994, COMPUTATIONAL LEARNI, P109; RISSANEN J, 1987, J ROY STAT SOC B MET, V49, P223; Rissanen J, 2003, IEEE T INFORM THEORY, V49, P476, DOI 10.1109/TIT.2002.807281; RISSANEN J, 1986, ANN STAT, V14, P1080, DOI 10.1214/aos/1176350051; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Rissanen J., 1989, STOCHASTIC COMPLEXIT; RISSANEN J, 1984, IEEE T INFORM THEORY, V30, P629, DOI 10.1109/TIT.1984.1056936; RISSANEN J, 1983, IEEE T INFORM THEORY, V29, P656, DOI 10.1109/TIT.1983.1056741; Rissanen JJ, 1996, IEEE T INFORM THEORY, V42, P40, DOI 10.1109/18.481776; SHANNON CE, 1948, BELL SYST TECH J, V47, P147; Shtarkov Y.M., 1987, PROBL INFORM TRANSM, V23, P3; TAKEUCHI J, 1998, P 1998 IEEE INT S IN; VOVK VG, 1998, P ADV NIPS 98, P364; Vovk V. G., 1990, Proceedings of the Third Annual Workshop on Computational Learning Theory; Yamanishi K, 1997, J COMPUT SYST SCI, V55, P105, DOI 10.1006/jcss.1997.1503; YAMANISHI K, 1992, MACH LEARN, V18, P23; Yamanishi K., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279950; Yamanishi K., 1994, Proceedings of the Seventh Annual ACM Conference on Computational Learning Theory, COLT 94, DOI 10.1145/180139.181096; Yamanishi K, 1998, IEEE T INFORM THEORY, V44, P1424, DOI 10.1109/18.681319; YAMANISHI K, 1995, INFORM COMPUT, V119, P39, DOI 10.1006/inco.1995.1076; YAMANISHI K, 1992, MACH LEARN, V9, P165, DOI 10.1007/BF00992676; YAMANISHI K, 1994, P 1994 C INF SCI SYS, V2, P763	33	0	0	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA		0-262-07262-9	NEURAL INF PROCESS S			2005							215	244				30	Computer Science, Artificial Intelligence; Mathematics, Applied	Computer Science; Mathematics	BCV69	WOS:000231442700009	
S	Luo, DS; Wang, XH; Wu, XH; Chi, HS		Wang, L; Chen, K; Ong, YS		Luo, DS; Wang, XH; Wu, XH; Chi, HS			Learning outliers to refine a corpus for Chinese webpage categorization	ADVANCES IN NATURAL COMPUTATION, PT 1, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st International Conference on Natural Computation (ICNC 2005)	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtang Univ, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artificial Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc China, Hunan Comp Federat				Webpage categorization has turned out to be an important topic in recent years. In a webpage, text is usually the main content, so that auto text categorization (ATC) becomes the key technique to such a task. For Chinese text categorization as well as Chinese webpage categorization, one of the basic and urgent problems is the construction of a good benchmark corpus. In this study, a machine learning approach is presented to refine a corpus for Chinese webpage categorization, where the AdaBoost algorithm is adopted to identify outliers in the corpus. The standard k nearest neighbor (kNN) algorithm under a vector space model (VSM) is adopted to construct a webpage categorization system. Simulation results as well as manual investigation of the identified outliers reveal that the presented method works well.	Peking Univ, Sch Elect Engn & Comp Sci, Natl Lab Machine Percept, Beijing 100871, Peoples R China	Luo, DS (reprint author), Peking Univ, Sch Elect Engn & Comp Sci, Natl Lab Machine Percept, Beijing 100871, Peoples R China.	DsLuo@pku.edu.cn; Wangxh@cis.pku.edu.cn; Wxh@cis.pku.edu.cn; Chi@pku.edu.cn					AAS K, 1999, 941 NNORW COMP CTR; COHEN WW, 1996, P 19 ANN INT ACM SIG, P307, DOI 10.1145/243199.243278; DONG DN, 1999, MODERN CHINESE CLASS; DUMAIS S., 2000, P 23 ANN INT ACM SIG, P256, DOI 10.1145/345508.345593; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Freund Y, 2001, MACH LEARN, V43, P293, DOI 10.1023/A:1010852229904; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; He J, 2003, APPL INTELL, V18, P311, DOI 10.1023/A:1023202221875; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Lewis D., 1994, 3 ANN S DOC AN INF R, P81; Luo DS, 2004, PROCEEDINGS OF THE IASTED INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND APPLICATIONS, VOLS 1AND 2, P281; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; Salton G., 1983, INTRO MODERN INFORM; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Weiss SM, 1999, IEEE INTELL SYST APP, V14, P63, DOI 10.1109/5254.784086; WIENER E, 1993, P 4 ANN S DOC AN INF, P22; WU XH, UNPUB J CHINESE INFO; Yang Y., 1997, 14 INT C MACH LEARN; Yang Y., 1999, J INFORMATION RETRIE, V1, P67; Yang Yiming, 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; Zhang Huaping, 2003, 2 SIGHAN WORKSH AFF, P63	21	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28323-4	LECT NOTES COMPUT SC			2005	3610						167	178				12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDA22	WOS:000232222400019	
S	Wang, JG; Neskovic, P; Cooper, LN		Wang, L; Chen, K; Ong, YS		Wang, JG; Neskovic, P; Cooper, LN			Training data selection for support vector machines	ADVANCES IN NATURAL COMPUTATION, PT 1, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st International Conference on Natural Computation (ICNC 2005)	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtang Univ, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artificial Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc China, Hunan Comp Federat				In recent years, support vector machines (SVMs) have become a popular tool for pattern recognition and machine learning. Training a SVM involves solving a constrained quadratic programming problem, which requires large memory and enormous amounts of training time for large-scale problems. In contrast, the SVM decision function is fully determined by a small subset of the training data, called support vectors, Therefore, it is desirable to remove from the training set the data that is irrelevant to the final decision function. In this paper we propose two new methods that select a subset of data for SVM training. Using real-world datasets, we compare the effectiveness of the proposed data selection strategies in terms of their ability to reduce the training set size while maintaining the generalization performance of the resulting SVM classifiers. Our experimental results show that a significant amount of training data can be removed by our proposed methods without degrading the performance of the resulting SVM classifiers.	Brown Univ, Dept Phys, Inst Brain & Neural Syst, Providence, RI 02912 USA	Wang, JG (reprint author), Brown Univ, Dept Phys, Inst Brain & Neural Syst, Providence, RI 02912 USA.	jigang@brown.edu; pedja@brown.edu; Leon-Cooper@brown.edu					ABE S, 2001, P INT C ART NEUR NET, P308; Almeida M.B., 2000, P 6 BRAZ S NEUR NETW, P162; Bennett KP, 2000, P 17 INT C MACH LEAR, P57; BLAKE CL, 1998, UCI RESP MACHINE LEA; Boser B, 1992, P 5 ANN WORKSH COMP, P144, DOI DOI 10.1145/130385.130401; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; CRISP DJ, 1999, ADV NEURAL INF PROCE, V12; HUANG SY, 2004, REDUCED SUPPORT VECT; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; Koggalage R., 2004, NEURAL INFORM PROCES, V2, P57; Lee Y., 2001, P 1 SIAM INT C DAT M; OSUNA EE, 1996, 1602 AIM MIT; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Shin H, 2003, LECT NOTES ARTIF INT, V2637, P376; Syed N, 1999, P WORKSH SUPP VECT M; Vapnik V., 1982, ESTIMATION DEPENDENC; Vapnik VN, 1998, STAT LEARNING THEORY; ZHANG W, 2002, P INT C NEUR INF PRO, P1423; Zhena S. F., 2003, P IEEE INT C AC SPEE, V2, P821	19	11	13	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28323-4	LECT NOTES COMPUT SC			2005	3610						554	564				11	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDA22	WOS:000232222400071	
S	Liu, GL; Sun, RZ; Gao, WL		Wang, L; Chen, K; Ong, YS		Liu, GL; Sun, RZ; Gao, WL			Uncertainty support vector method for ordinal regression	ADVANCES IN NATURAL COMPUTATION, PT 1, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st International Conference on Natural Computation (ICNC 2005)	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtang Univ, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artificial Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc China, Hunan Comp Federat		uncertainty; ordinal regression; quadratic programming; early-warning		Ordinal regression is complementary to the standard machine learning tasks of classification and metric regression which goal is to predict variables of ordinal scale. However, every input must be exactly assigned to one of these classes without any uncertainty in standard ordinal regression models. Based on structural risk minimization (SRM) principle, a new support vector learning technique for ordinal regression is proposed, which is able to deal with training data with uncertainty. Firstly, the meaning of the uncertainty is defined. Based on this meaning of uncertainty, two algorithms have been derived. This technique extends the application horizon of ordinal regression greatly. Moreover, the problem about early warning of food security in China is solved by our algorithm.	China Agr Univ, Coll Informat & Elect Engn, Beijing 100083, Peoples R China	Liu, GL (reprint author), China Agr Univ, Coll Informat & Elect Engn, Postfach 142, Beijing 100083, Peoples R China.	liugl@cau.edu.cn; Sunrz@cau.edu.cn; gaowlin@cau.edu.cn					AN XN, 1998, METHOD SYSTEM DESIGN, V231; Cristianini N., 2000, INTRO SUPPORT VECTOR; Herbrich R., 2002, LEARNING KERNEL CLAS; HERBRICH R, 2000, LARGE MARGIN RANK BO, P115; LI ZQ, 1998, ANAL EARLY WARNING F, V1; Lin C.F., 2002, IEEE T NEURAL NETWOR, V13	6	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28323-4	LECT NOTES COMPUT SC			2005	3610						650	654				5	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDA22	WOS:000232222400081	
S	Shen, L; Tan, EC		Wang, L; Chen, K; Ong, YS		Shen, L; Tan, EC			Nonlinear kernel MSE methods for cancer classification	ADVANCES IN NATURAL COMPUTATION, PT 1, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st International Conference on Natural Computation (ICNC 2005)	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtang Univ, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artificial Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc China, Hunan Comp Federat			PREDICTION	Combination of kernel PLS (KPLS) and kernel SVD (KSVD) with mini mum-squared-error (MSE) criteria has created new machine learning methods for cancer classification and has been successfully applied to seven publicly available cancer datasets. Besides the high accuracy of the new methods, very fast training speed is also obtained because the matrix inversion in the original MSE procedure is avoided. Although the KPLS-MSE and the KSVD-MSE methods have equivalent accuracies, the KPLS achieves the same results using significantly less but more qualitative components.	Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore	Shen, L (reprint author), Nanyang Technol Univ, Sch Comp Engn, Nanyang Ave, Singapore 639798, Singapore.	PG04480855@ntu.edu.sg; asectan@ntu.edu.sg					DEJONG S, 1993, CHEMOMETR INTELL LAB, V18, P251, DOI 10.1016/0169-7439(93)85002-X; Duda R., 2000, PATTERN CLASSIFICATI; Ghosh Debashis, 2002, Pac Symp Biocomput, P18; Golub G. H., 1996, MATRIX COMPUTATIONS; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; LI J, 2002, KENT RIDGE BIOMEDICL; Nguyen DV, 2002, BIOINFORMATICS, V18, P39, DOI 10.1093/bioinformatics/18.1.39; Rosipal R, 2001, J MACHINE LEARNING R, V2, P97; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Vapnik VN, 1998, STAT LEARNING THEORY; WEGELIN J, 2000, SURVEY PARTIAL LEAST; Wold H., 1975, PERSPECTIVES PROBABI, P520	14	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28323-4	LECT NOTES COMPUT SC			2005	3610						975	984				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDA22	WOS:000232222400129	
S	Cho, YJ; Kim, H		Wang, L; Chen, K; Ong, YS		Cho, YJ; Kim, H			Cleavage site analysis using rule extraction from neural networks	ADVANCES IN NATURAL COMPUTATION, PT 1, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	1st International Conference on Natural Computation (ICNC 2005)	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtang Univ, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artificial Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc China, Hunan Comp Federat			SARS; POLYPROTEINS; VIRUS	In this paper, we demonstrate that the machine learning approach of rule extraction from a trained neural network can be successfully applied to SARS-coronavirus cleavage site analysis. The extracted rules predict cleavage sites better than consensus patterns, Empirical experiments are also shown.	Korea Univ, Dept Comp Sci Educ, Seoul 136701, South Korea	Cho, YJ (reprint author), Korea Univ, Dept Comp Sci Educ, Anam Dong 5 Ga, Seoul 136701, South Korea.	fjx@comedu.korea.ac.kr; hkim@comedu.korea.ac.kr					Andrews R, 1995, KNOWL-BASED SYST, V8, P373, DOI 10.1016/0950-7051(96)81920-4; Benson DA, 2004, NUCLEIC ACIDS RES, V32, pD23, DOI 10.1093/nar/gkh045; Blom N, 1996, PROTEIN SCI, V5, P2203; CHEN LL, 2003, ZCURVE COV NEW SYSTE, P382; FU LM, 1994, IEEE T SYST MAN CYB, V24, P1114; Fu LM, 1995, KNOWL-BASED SYST, V8, P299, DOI 10.1016/0950-7051(96)81914-9; Gao F, 2003, FEBS LETT, V553, P451, DOI 10.1016/S0014-5793(03)01091-3; Hu LD, 2003, ACTA PHARMACOL SIN, V24, P741; KIEMER L, 2004, BMC BIOINFORMATICS; KIM HC, 2000, LECT NOTES ARTIF INT, V1967, P170; Li-Min F, 1994, NEURAL NETWORKS COMP; LIMIN F, 1994, HYEONCHEOL ABSTRACTI; LUO H, 2004, APBC 2004, V29; Marra MA, 2003, SCIENCE, V300, P1399, DOI 10.1126/science.1085953; Narayanan Ajit, 2002, Bioinformatics, V18 Suppl 1, pS5; RUAN Y, 2003, LANCET; Setiono R, 1995, P 14 INT JOINT C ART, P480; Shi JH, 2004, J BIOL CHEM, V279, P24765, DOI 10.1074/jbc.M311744200; SHI Y, 2003, J CLIN MICROBIOL, P5781; Stadler K, 2003, NAT REV MICROBIOL, V1, P209, DOI 10.1038/nrmicro775; TAHA IA, 1999, IEEE T KNOWL DATA EN, V11, P443; TOWELL GG, 1993, MACHINE LEARNING, V13; TSUR S, 2000, P 26 VLDB C CAIR EGY; XU D, 2004, GENETIC VARIATIONS S, V10; YAP YL, 2003, BMC BIOINFORMATICS	25	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28323-4	LECT NOTES COMPUT SC			2005	3610						1002	1008				7	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDA22	WOS:000232222400132	
S	Nguyen, HN; Ohn, SY; Park, J; Park, KS		Wang, L; Chen, K; Ong, YS		Nguyen, HN; Ohn, SY; Park, J; Park, KS			Combined kernel function approach in SVM for diagnosis of cancer	ADVANCES IN NATURAL COMPUTATION, PT 1, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st International Conference on Natural Computation (ICNC 2005)	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtang Univ, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artificial Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc China, Hunan Comp Federat				The problem of determining optimal decision model is a difficult combinatorial task in the fields of pattern classification, machine learning, and especially bioinformatics. Recently, support vector machine (SVM) has shown a higher performance than conventional learning methods in many applications. This paper proposes a new kernel function for support vector machine (SVM) and its learning method that results in fast convergence and good classification performance. The new kernel function is created by combining a set of kernel functions. A new learning method based on evolution algorithm (EA) is proposed to obtain the optimal decision model consisting of an optimal set of features as well as an optimal set of the parameters for combined kernel function. The experiments on clinical datasets such as stomach cancer, colon cancer, and leukemia datasets data sets indicates that the combined kernel function shows higher and more stable classification performance than other kernel functions.	Hankuk Aviat Univ, Dept Comp Engn, Seoul, South Korea; Myongji Univ, Dept Elect Engn, Seoul, South Korea; Dankook Univ, Div Informat & Comp Sci, Seoul, South Korea	Nguyen, HN (reprint author), Hankuk Aviat Univ, Dept Comp Engn, Seoul, South Korea.	nghanam@hau.ac.kr; syohn@hau.ac.kr; jhpark@hau.ac.kr; kspark@dankook.ac.kr					Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Chen XW, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P504; Cristianini N., 2000, INTRO SUPPORT VECTOR; Duda R. O., 2001, PATTERN CLASSIFICATI; Frohlich H, 2003, PROC INT C TOOLS ART, P142, DOI 10.1109/TAI.2003.1250182; Goldberg DE, 1989, GENETIC ALGORITHMS S; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Joachims T., 1999, MAKING LARGE SCALE S; Kecman V., 2001, LEARNING SOFT COMPUT; Michalewicz Z, 1996, GENETIC ALGORITHMS D; Minsky M, 1969, PERCEPTRONS; Mitchell M, 1999, INTRO GENETIC ALGORI; PARK C, 2003, P INT JOINT C, V3, P1702; Ruping S., 2000, MYSVM MANUAL; Schokopf B., 2002, LEARNING KERNELS SUP; VAPNIK VN, 1996, TR9617 CSD U LOND	16	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28323-4	LECT NOTES COMPUT SC			2005	3610						1017	1026				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDA22	WOS:000232222400134	
S	Zhang, JP; Li, ZW; Yang, J; Li, Y		Wang, L; Chen, K; Ong, YS		Zhang, JP; Li, ZW; Yang, J; Li, Y			A gradual training algorithm of incremental support vector machine learning	ADVANCES IN NATURAL COMPUTATION, PT 1, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st International Conference on Natural Computation (ICNC 2005)	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtang Univ, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artificial Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc China, Hunan Comp Federat				Support Vector Machine(SVM) has become a popular tool for learning with large amounts of high dimensional data, but sometimes we prefer to incremental learning algorithms to handle very vast data for training SVM is very costly in time and memory consumption or because the data available are obtained at different intervals. For its outstanding power to summarize the data space in a concise way, incremental SVM framework is designed to deal with large-scale learning problems. This paper proposes a gradual algorithm for training SVM to incremental learning in a dividable way, taking the possible impact of new training data to history data each other into account. Training data are divided and combined in a crossed way to collect support vectors, and being divided into smaller sets makes it easier to decreases the computation complexity and the gradual process can be trained in a parallel way. The experiment results on test dataset show that the classification accuracy using proposed incremental algorithm is superior to that using batch SVM model, the parallel training method is effective to decrease the training time consumption.	Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Peoples R China	Zhang, JP (reprint author), Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Peoples R China.	davis525@163.com					Burges C.J.C., 1998, KNOWLEDGE DISCOVERY, V2, P1; Cauwenberghs G., 2000, ADV NEURAL INFORM PR; Christiani N, 2000, INTRO SUPPORT VECTOR; DOMENICONI C, 2001, P IEEE INT C DAT MIN; Dumais S., 1998, P 7 INT C INF KNOWL; FUNG G, 2002, P 2 SIAM INT C DAT M; Klinkenberg R., 2000, P 17 INT C MACH LEAR; LI K, 2003, J NO JIAOTONG U, V27, P34; LIU YG, 2004, P 5 WORLD C INT CONT; MITRA P, 2000, P ICPR C SPAIN; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; SYED N, 1999, P IJCAI C SWED; TVEIT A, 2003, P 5 INT C DAT WAR KN; Vapnik VN, 1998, STAT LEARNING THEORY; Wang J.C., 2002, J NANJING U, V38, P152	15	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28323-4	LECT NOTES COMPUT SC			2005	3610						1132	1139				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDA22	WOS:000232222400151	
S	Kim, S; Shin, KS; Park, K		Wang, L; Chen, K; Ong, YS		Kim, S; Shin, KS; Park, K			An application of support vector machines for customer churn analysis: Credit card case	ADVANCES IN NATURAL COMPUTATION, PT 2, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st International Conference on Natural Computation (ICNC 2005)	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtang Univ, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artificial Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc China, Hunan Comp Federat			PREDICTION; NETWORKS; SERVICES	This study investigates the effectiveness of support vector machines (SVM) approach in detecting the underlying data pattern for the credit card customer churn analysis. This article introduces a relatively new machine learning technique, SVM, to the customer churning problem in attempt to provide a model with better prediction accuracy. To compare the performance of the proposed model, we used a widely adopted and applied Artificial Intelligence (AI) method, back-propagation neural networks (BPN) as a benchmark. The results demonstrate that SVM outperforms BPN. We also examine the effect of the variability in performance with respect to various values of parameters in SVM.	Ewha Womans Univ, Coll Business Adm, Seoul 120750, South Korea	Kim, S (reprint author), Ewha Womans Univ, Coll Business Adm, 11-1 Daehyun Dong, Seoul 120750, South Korea.	kimsun0122@empal.com; ksshin@ewha.ac.kr; kyungdo@ewha.ac.kr					BenDavid S, 1997, J COMPUT SYST SCI, V55, P171, DOI 10.1006/jcss.1997.1507; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; BURGES CJC, 1997, ADV NEURAL INFORM PR; Burges C.J.C., 1998, DATA MIN KNOWL DISC, V2, P955; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; FRIEDMAN C, 2002, CREDT MODEL TECHNICA; HAYJIN S, 1994, NEURAL NETWORKS COMP; HUANG W, 2004, COMPUTERS OPERATIONS; Huang Z, 2004, DECIS SUPPORT SYST, V37, P543, DOI 10.1016/S0167-9236(03)00086-1; Jaakkola T., 1998, ADV NEURAL INFORM PR; JOACHIMS T., 2002, LEARNING CLASSIFY TE; Kim KJ, 2003, NEUROCOMPUTING, V55, P307, DOI 10.1016/S0925-2312(03)00372-2; Lariviere B, 2004, EXPERT SYST APPL, V27, P277, DOI 10.1016/j.eswa.2004.02.002; LEE KC, 2002, J INTELL INF SYST, V8, P15; Lee TK, 2001, INT J OFFSHORE POLAR, V11, P113; Lin Chih-Jen, 2001, COMP METHODS MULTICL; Mukherjee S., 1997, P IEEE WORKSH NEUR N, P511; OSNA E, 1997, P COMP VIS PATT REC, P130; REICHHELD FF, 1990, HARVARD BUS REV, V68, P105; Shin KS, 2005, EXPERT SYST APPL, V28, P127, DOI 10.1016/j.eswa.2004.08.009; Stoneking D, 1999, IEEE SPECTRUM, V36, P70, DOI 10.1109/6.769272; TARASSENKO L, 1995, P 4 IEE INT C ART NE, P442; Tay FEH, 2001, OMEGA-INT J MANAGE S, V29, P309, DOI 10.1016/S0305-0483(01)00026-3; Tay FEH, 2002, NEUROCOMPUTING, V48, P847, DOI 10.1016/S0925-2312(01)00676-2; Van Gestel T, 2001, IEEE T NEURAL NETWOR, V12, P809, DOI 10.1109/72.935093; VAPNIK V, 1998, STAT LEARNING THOERY; Vapnik V. N, 1998, NATURE STAT LEARNING; Vapnik V. N, 1995, NATURE STAT LEARNING; Wei CP, 2002, EXPERT SYST APPL, V23, P103, DOI 10.1016/S0957-4174(02)00030-1; Witten I. H., 2000, DATA MINING PRACTICA; Zien A, 2000, BIOINFORMATICS, V16, P799, DOI 10.1093/bioinformatics/16.9.799	31	5	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28325-0	LECT NOTES COMPUT SC			2005	3611						636	647				12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDA23	WOS:000232222500091	
S	Do, TD; Hui, SC; Fong, ACM		Wang, L; Chen, K; Ong, YS		Do, TD; Hui, SC; Fong, ACM			Artificial Immune System for Associative Classification	ADVANCES IN NATURAL COMPUTATION, PT 2, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st International Conference on Natural Computation (ICNC 2005)	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtang Univ, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artificial Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc China, Hunan Comp Federat				Artificial Immune Systems (AIS), which are inspired from nature immune system, have recently been investigated for many information processing applications, such as feature extraction, pattern recognition, machine learning and data mining. In this paper, we investigate AIS, and in particular the clonal selection algorithm for Associative Classification (AC). To implement associative classification effectively, we need to tackle the problems on the very large search space of candidate rules during the rule mining process. This paper proposes a new approach known as AIS-AC for mining association rules effectively for classification. In AIS-AC, we treat the rule mining process as an optimization problem of finding an optimal set of association rules according to some predefined constraints. The proposed AIS-AC approach is efficient in dealing with the complexity problem on the large search space of rules. It avoids searching greedily for all possible association rules, and is able to find an effective set of associative rules for classification.	Nanyang Technol Univ, Sch Comp Engn, Singapore 2263, Singapore	Do, TD (reprint author), Nanyang Technol Univ, Sch Comp Engn, Nanyang Ave, Singapore 2263, Singapore.	pa0001852a@ntu.edu.sg; asschui@ntu.edu.sg; ascmfong@ntu.edu.sg					Agrawal R., 1994, P 20 INT C VER LARG, P487; de Castro L.N., 1999, ARTIFICIAL IMMUNE SY; De Castro L.N., 2000, P GECCO 00 WORKSH AR, P36; de Castro LN, 2002, IEEE T EVOLUT COMPUT, V6, P239, DOI 10.1109/TEVC.2002.1011539; de Castro LN, 2003, SOFT COMPUT, V7, P526, DOI [10.1007/S00500-002-0237-Z, 10.1007/S00500-002-0237-z]; Goldberg DE, 1989, GENETIC ALGORITHMS S; HAN J, 2000, P 2000ACM SIGMOD INT; HEGLAND M, 2003, ADV LECT MACHINE LEA; KOHAVI R, 1994, TOOLS ARTIFICIAL INT, P740; Li W., 2001, P ICDM; Liu B., 1998, P 4 INT C KNOWL DISC, P80; POTTER M, 1988, P PAR PROBL SOLV NAT, P530; WATKINS AB, 2002, 2002 IEEE WORLD C CO, P926	13	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28325-0	LECT NOTES COMPUT SC			2005	3611						849	858				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDA23	WOS:000232222500119	
S	Liu, XD; Liu, WQ		Wang, L; Chen, K; Ong, YS		Liu, XD; Liu, WQ			Credit rating analysis with AFS fuzzy logic	ADVANCES IN NATURAL COMPUTATION, PT 3, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st International Conference on Natural Computation (ICNC 2005)	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtang Univ, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artificial Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc China, Hunan Comp Federat			ALGEBRAS	In this paper, we propose a new machine learning approach based on AFS (Axiomatic Fuzzy Sets) fuzzy logic, in attempt to provide a better model with interpretability. First, we will concisely present the AFS theory. Second, we will propose new membership functions for fuzzy sets and their logic operations. Third, we will design a new machine learning algorithm based on the new membership functions and their logic operations. This algorithm has two advantages. One is that it can mimic the human reasoning comprehensively and offers a far more flexible and effective means for the study of large-scale intelligent systems. Another is its simplicity in implementation and mathematical beauty in fuzzy theory. Finally, a credit data example is used to illustrate its effectiveness.	Dalian Univ Technol, Res Ctr Informat & Control, Dalian 116024, Peoples R China; Curtin Univ Technol, Dept Comp, Bentley, WA 6102, Australia	Liu, XD (reprint author), Dalian Univ Technol, Res Ctr Informat & Control, Dalian 116024, Peoples R China.	xdliuros@hotmail.com; wanquan@cs.curtin.edu.au					Chaveesuk R., 1999, Journal of Engineering Valuation and Cost Analysis, V2; Ederington H., 1985, FINANCIAL REV, V20, P237; Gentry J., 1988, FINANCIAL REV, V23, P269, DOI 10.1111/j.1540-6288.1988.tb01267.x; Jackson J.D., 1988, J BEHAV EC, V17, P173, DOI 10.1016/0090-5720(88)90008-3; Kim K. H., 1982, BOOLEAN MATRIX THEOR; Kwon Y. S., 1997, International Journal of Intelligent Systems in Accounting, Finance and Management, V6, DOI 10.1002/(SICI)1099-1174(199703)6:1<23::AID-ISAF113>3.3.CO;2-W; Liu XD, 1998, J MATH ANAL APPL, V217, P479; Liu XD, 1998, FUZZY SET SYST, V95, P179, DOI 10.1016/S0165-0114(96)00298-9; Liu XD, 1998, J MATH ANAL APPL, V217, P459; LIU XD, 2003, IEEE INT C FUZZ SYST, V1, P55; LIU XD, 2002, DONGBEI DAXUE XUEBAO, V23, P321; Maher J. J., 1997, International Journal of Intelligent Systems in Accounting, Finance and Management, V6, DOI 10.1002/(SICI)1099-1174(199703)6:1<59::AID-ISAF116>3.0.CO;2-H; Moody J., 1995, NEURAL NETWORKS CAPI, P277; Zan Huanga, 2004, Decision Support Systems, V37, DOI 10.1016/S0167-9236(03)00086-1	14	10	10	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28320-X	LECT NOTES COMPUT SC			2005	3612						1198	1204				7	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDA32	WOS:000232246700152	
S	Wu, C; Liang, YC; Yang, XW; Hao, ZF		Wang, L; Chen, K; Ong, YS		Wu, C; Liang, YC; Yang, XW; Hao, ZF			Equivalence of classification and regression under support vector machine theory	ADVANCES IN NATURAL COMPUTATION, PT 3, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st International Conference on Natural Computation (ICNC 2005)	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtang Univ, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artificial Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc China, Hunan Comp Federat				A novel classification method based on regression is proposed in this paper and then the equivalences of the classification and regression are demonstrated by using numerical experiments under the framework of support vector machine. The proposed algorithm implements the classification tasks by the way used in regression problems. It is more efficiently for multi-classification problems since it can classify all samples at a time. Numerical experiments show that the two classical machine learning problems (classification and regression) can be solved by the method conventionally used for the opposite problem and the proposed regression-based classification algorithm can classify all samples belonging to different categories concurrently with an agreeable precision.	Jilin Univ, Coll Comp Sci & Technol, Key Lab Symbol Computat & Knowledge, Minist Educ, Changchun 130012, Peoples R China; Beijing Jiaotong Univ, Key Lab Informat Sci & Engn, Railway Minist, Key Lab Adv Informat Sci & Network Technol Beijin, Beijing 100044, Peoples R China; S China Univ Technol, Dept Appl Math, Guangzhou 510640, Peoples R China	Liang, YC (reprint author), Jilin Univ, Coll Comp Sci & Technol, Key Lab Symbol Computat & Knowledge, Minist Educ, Changchun 130012, Peoples R China.	ycliang@jlu.edu.cn	Wu, Chunguo/A-6901-2008				Murphy P.M., 1992, UCI REPOSITORY MACHI; Suykens J.A.K., 2000, P IEEE INT S CIRC SY, P757, DOI DOI 10.1109/ISCAS.2000.856439; Suykens J.A.K., 2002, LEAST SQUARES SUPPOR; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Tao Qing, 2002, Journal of Software, V13; Vapnik VN, 1998, STAT LEARNING THEORY	6	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28320-X	LECT NOTES COMPUT SC			2005	3612						1257	1260				4	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDA32	WOS:000232246700160	
S	Wilks, Y; Webb, N; Setzer, A; Hepple, M; Catizone, R		VanKuppevelt, JCJ; Dybkjaer, L; Bernsen, NO		Wilks, Yorick; Webb, Nick; Setzer, Andrea; Hepple, Mark; Catizone, Roberta			MACHINE LEARNING APPROACHES TO HUMAN DIALOGUE MODELLING	ADVANCES IN NATURAL MULTIMODAL DIALOGUE SYSTEMS	Text Speech and Language Technology		English	Article; Book Chapter						Dialogue management; machine learning; dialogue acts; dialogue modelling; Dialogue Action Frames		We describe two major dialogue system segments: the first is an analysis module that learns to assign dialogue acts from corpora, but on the basis of limited quantities of data, and up to what seems to be some kind of limit on this task, a fact we also discuss. Secondly, we describe a Dialogue Manager which uses a representation of stereotypical dialogue patterns that we call Dialogue Action Frames, which are processed using simple and well understood algorithms, which are adapted from their original role in syntactic analysis role, and which, we believe, generate strong and novel constraints on later access to incomplete dialogue topics.	[Wilks, Yorick; Webb, Nick; Setzer, Andrea; Hepple, Mark; Catizone, Roberta] Univ Sheffield, Dept Comp Sci, Nat Language Proc Grp, Sheffield S10 2TN, S Yorkshire, England	Wilks, Y (reprint author), Univ Sheffield, Dept Comp Sci, Nat Language Proc Grp, Sheffield S10 2TN, S Yorkshire, England.	y.wilks@dcs.shef.ac.uk; n.webb@dcs.shef.ac.uk; a.setzer@dcs.shef.ac.uk; m.hepple@dcs.shef.ac.uk; r.catizone@dcs.shef.ac.uk					ALLEN JF, 1995, J EXP THEOR ARTIF IN, V7, P7, DOI 10.1080/09528139508953799; ALLEN JF, 1980, ARTIF INTELL, V15, P143, DOI 10.1016/0004-3702(80)90042-9; BALLIM A, 1991, ARTIFICIAL BELIEVERS; BRILL E, 1995, COMPUTATIONAL LINGUI, P234; CARBONELL JG, 1983, MACHINE LEARNING ART, P168; COLBY KM, 1971, J ARTIFICIAL INTELLI, V2, P76; FIKES RE, 1971, P 2 INT JOINT C ART, V1, P111; GROSZ B, 1977, READINGS NATURAL LAN, P56; HARDY H, 2002, P ISLE WORKSH DIAL T, P90; Hearst M.A., 1993, UCBS2K9324; HOBBS JR, 1993, P 5 MESS UND C MUC 5, P87, DOI 10.3115/1072017.1072029; Jurafsky D., 1997, 9702 U COL I COGN SC; Jurafsky D., 1998, 30 J HOPK U CTR SPEE; Klesen M., 1997, P 5 EUR C SPEECH COM, P2235; LAGER T, 1999, P 3 INT WORKSH COMP, P190; LAGER T, 1999, P 3 SWED S MULT COMM, P66; LARSSON S, 2000, J NATURAL LANGUAGE E, V6, P267; Lemon O., 2001, P 7 EUR C SPEECH COM, P1559; LEVY D, 1997, P 1 INT WORKSH HUM C, P27; Newell A., 1990, UNIFIED THEORIES COG; REICHMANN R, 1985, GETTING COMPUTERS TA; SAMUEL K, 1998, P 36 ANN M ASS COMP, V2, P1150; Stolcke A, 2000, COMPUT LINGUIST, V26, P339, DOI 10.1162/089120100561737; Walker MA, 2000, J ARTIF INTELL RES, V12, P387; WOODS WA, 1970, COMMUN ACM, V13, P591, DOI 10.1145/355598.362773; Young SJ, 2000, PHILOS T ROY SOC A, V358, P1389, DOI 10.1098/rsta.2000.0593	26	1	1	SPRINGER	DORDRECHT	PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1386-291X	978-1-4020-3933-1	TEXT SPEECH LANG TEC			2005	30						355	370			10.1007/1-4020-3933-6	16	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Language & Linguistics	Computer Science; Linguistics	BLA38	WOS:000269751500017	
S	Liu, Y; Li, Y; Li, GZ; Zhang, BF; Wu, GF		Wang, J; Liao, X; Yi, Z		Liu, Y; Li, Y; Li, GZ; Zhang, BF; Wu, GF			Constructive ensemble of RBF neural networks and its application to earthquake prediction	ADVANCES IN NEURAL NETWORKS - ISNN 2005, PT 1, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	2nd International Symposium on Neural Networks	MAY 30-JUN 01, 2005	Chongqing, PEOPLES R CHINA	Chongqing Univ, SW Normal Univ, Chongqing Univ, Posts& Telecommun, SW Agr Univ, Chongqing Educ Coll, Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, European Neural Network Soc, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, Natl Nat Sci Fdn China, K C Wong Educ Fdn Hong Kong				Neural networks ensemble is a hot topic in machine learning community, which can significantly improve the generalization ability of single neural networks. However, the design of ensemble architecture still relies on either a tedious trial-and-error process or the experts' experience. Tbs paper proposes a novel method called CERNN (Constructive Ensemble of RBF Neural Networks), in which the number of individuals, the number of hidden nodes and training epoch of each individual are determined automatically. The generalization performance of CERNN can be improved by using different training subsets and individuals with different architectures. Experiments on UCI datasets demonstrate that CERNN is effective to release the user from the tedious trialand-error process, so is it when applied to earthquake prediction.	Shanghai Univ, Sch Engn & Comp Sci, Shanghai 200072, Peoples R China	Liu, Y (reprint author), Shanghai Univ, Sch Engn & Comp Sci, Shanghai 200072, Peoples R China.	yliu@staff.shu.edu.cn	Li, Guo-Zheng /D-5744-2011	Li, Guo-Zheng /0000-0001-5568-0347			Blake C. L., 1998, UCI REPOSITORY MACHI; Dietterich Thomas G., 2000, P 1 INT WORKSH MULT, P1; Efron B., 1993, INTRO BOOTSTRAP; GUTTA S, 1996, P IEEE INT C NEUR NE, P1017; Han J. W, 2000, DATA MINING CONCEPTS; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Islam M, 2003, IEEE T NEURAL NETWOR, V14, P820, DOI 10.1109/TNN.2003.813832; LIU Y, 2004, P ISNN 04, P962; Mei SR, 1993, INTRO EARTHQUAKE PRE; MOODEY J, 1989, NEURAL COMPUT, V1, P1281; WANG Z, 2004, P IDEAL 04, P572; Wei Wang, 1999, EARTHQUAKE, V19, P118; ZHANG Z, 1990, CHINA EARTHQUAKE CAS	13	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-25912-0	LECT NOTES COMPUT SC			2005	3496						532	537				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCN38	WOS:000230166900085	
S	Gu, HY; Gao, ZW; Wu, F		Wang, J; Liao, X; Wang, J		Gu, HY; Gao, ZW; Wu, F			Selection of optimal features for iris recognition	ADVANCES IN NEURAL NETWORKS - ISNN 2005, PT 2, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	2nd International Symposium on Neural Networks	MAY 30-JUN 01, 2005	Chongqing, PEOPLES R CHINA	Chongqing Univ, SW Normal Univ, Chongqing Univ, Posts & Telecommun, SW Agr Univ, Chongqing Educ Coll, Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, European Neural Network Soc, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, Natl Nat Sci Fdn China, K C Wong Educ Fdn Hong Kong				Iris recognition is a prospering biometric method, but some technical difficulties still exist. This paper proposes an iris recognition method based on selected optimal features and statistical learning. To better represent the variation details in irises, we extract features from both spatial and frequency domain. Multi-objective genetic algorithm is then employed to optimize the features. Next step is doing classification of the optimal feature sequence. SVM has recently generated a great interest in the community of machine learning due to its excellent generalization performance in a wide variety of learning problems. We modified traditional SVM as non-symmetrical support vector machine to satisfy the different security requirements in iris recognition applications. Experimental data shows that the selected feature sequence represents the variation details of the iris patterns properly.	Zhejiang Univ, Inst Artificial Intelligence, Hangzhou 310027, Peoples R China	Gu, HY (reprint author), Zhejiang Univ, Inst Artificial Intelligence, Hangzhou 310027, Peoples R China.	guhy@cs.zju.edu.cn					DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; Gu Hongying, 2004, Journal of Computer Aided Design & Computer Graphics, V16; Ma L., 2008, P 5 AS C COMP VIS, V1, P279; Oliveira LS, 2002, INT C PATT RECOG, P568; Simoncelli E., 1995, 2 INT C IM P WASH DC, V3, p[444, 2]; SIMONCELLI EP, 1996, IEEE INT C IM PROC, V3, P185; TAN KC, 2004, MULTIOBJECTIVE EVOLU; Vapnik VN, 1998, STAT LEARNING THEORY; *NAT LAB PATT REC, 2003, CASIA IR IM DAT	10	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-25913-9	LECT NOTES COMPUT SC			2005	3497						81	86				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCN40	WOS:000230167200014	
S	Li, LS; Li, LH; Huang, DG; Song, HP		Wang, J; Liao, X; Wang, J		Li, LS; Li, LH; Huang, DG; Song, HP			Chinese syntactic category disambiguation using support vector machines	ADVANCES IN NEURAL NETWORKS - ISNN 2005, PT 2, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	2nd International Symposium on Neural Networks	MAY 30-JUN 01, 2005	Chongqing, PEOPLES R CHINA	Chongqing Univ, SW Normal Univ, Chongqing Univ, Posts& Telecommun, SW Agr Univ, Chongqing Educ Coll, Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, European Neural Network Soc, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, Natl Nat Sci Fdn China, K C Wong Educ Fdn Hong Kong				This paper presents a method of processing Chinese syntactic category ambiguity with support vector machines (SVMs): extracting the word itself, candidate part-of-speech (POS) tags, the pair of candidate POS tags and their probability and context information as the features of the word vector. A training set is established. The machine learning models of disambiguation based on support vector machines are obtained using polynomial kernel functions. The testing results show that this method is efficient. The paper also gives the results obtained with neural networks for comparison.	Dalian Univ Technol, Dept Comp Sci & Engn, Dalian 116023, Liaoning, Peoples R China; Hebei Normal Univ Sci & Technol, Dept Math Phys, Qinhuangdao 066004, Hebei, Peoples R China	Li, LS (reprint author), Dalian Univ Technol, Dept Comp Sci & Engn, Dalian 116023, Liaoning, Peoples R China.	nlp@cjmt.com					Huang De-gen, 2003, Mini-Micro Systems, V24; Joachims T., 1998, LNCS, V1398, P137; Li LS, 2004, LECT NOTES COMPUT SC, V3173, P983; MURATA M, 2001, P 2 WORKSH NAT LANG, P24; Vapnik V. N, 1995, NATURE STAT LEARNING; WEI O, 2000, J SOFTWARE, V4, P473; Weischedel R., 1993, Computational Linguistics, V19; YU X, 1998, COMPUTER RES DEV, V4, P367	8	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-25913-9	LECT NOTES COMPUT SC			2005	3497						246	250				5	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCN40	WOS:000230167200039	
S	Liu, L; Meng, G		Wang, J; Liao, X; Yi, Z		Liu, L; Meng, G			Crack detection in supported beams - Based on neural network and support vector machine	ADVANCES IN NEURAL NETWORKS - ISNN 2005, PT 3, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	2nd International Symposium on Neural Networks	MAY 30-JUN 01, 2005	Chongqing, PEOPLES R CHINA	Chongqing Univ, SW Normal Univ, Chongqing Univ, Posts& Telecommun, SW Agr Univ, Chongqing Educ Coll, Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, European Neural Network Soc, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, Natl Nat Sci Fdn China, K C Wong Educ Fdn Hong Kong			DAMAGE	A study is presented to compare the performance of crack detection using neural network(NN) and support vector machine (SVM) based on natural frequencies. The SVM is a machine learning algorithm based on statistical learning theory, and it is also a class of regression method with the good generalization ability. Firstly, the basic theory of the back-propagation neural network and support vector regression is briefly reviewed. Then the feasibility of the crack detection using these methods are investigated by locating and sizing cracks in supported beams for which a few natural frequencies are available. It is observed that crack's location and depth can be estimated with a relatively small size error. The results show that the SVM is a powerful and effective method for crack identification.	Shanghai Jiao Tong Univ, State Key Lab Vibrat Shock & Noise, Shanghai 200240, Peoples R China	Liu, L (reprint author), Shanghai Jiao Tong Univ, State Key Lab Vibrat Shock & Noise, Shanghai 200240, Peoples R China.	Liu_long@sjtu.edu.cn					Chang C.-C., 2001, LIBSVM LIB SUPPORT V; CHENG CZ, 2001, STRUCTURE DAMAGE MON; Ge M, 2004, MECH SYST SIGNAL PR, V18, P143, DOI 10.1016/S0888-3270(03)00071-2; Hastie T, 2001, ELEMENTS STAT LEARNI; Salawu OS, 1997, ENG STRUCT, V19, P718, DOI 10.1016/S0141-0296(96)00149-6; SAMANTA KR, 2003, ENG APPL ARTIF INTEL, V16, P657; Smola A., 1998, NCTR98030 U LOND ROY; VAPNIK V, 1996, ADV NEURAL INFORMATI; VAPNIK VN, 1981, ESTIMATION DEPENDECE; YUN CB, 1998, NEURAL NETWORK APPRO, P19; Zapico JL, 2003, MECH SYST SIGNAL PR, V17, P119, DOI 10.1006/mssp.2002.1547; *NAT MA, 1998, MATHW NEUR NETW TOOL	12	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-25914-7	LECT NOTES COMPUT SC			2005	3498						597	602				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCN43	WOS:000230167700095	
S	Liu, W; Xue, GR; Yu, Y; Zeng, HJ		Fan, W; Wu, Z; Yang, J		Liu, W; Xue, GR; Yu, Y; Zeng, HJ			Importance-based web page classification using cost-sensitive SVM	ADVANCES IN WEB-AGE INFORMATION MANAGEMENT, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th International Conference on Web -Age Informational Management	OCT 11-13, 2005	Hangzhou, PEOPLES R CHINA	DatabaseSoc China Comp Federat, Natl Sci Fdn China, Zhejiang Univ, Y C Tang Disciplinary Dev & Fund, Oracle China				Web page classification is facing great challenges since there is a huge repository and diversity of information. As known, each web page varies both in content and quality, just as PageRank suggested. Typical machine learning algorithms take advantage of positive and negative examples to train a classifier; however, it has been neglected that each instance has a different weight, which can be user pre-defined. This paper presents an effective algorithm based on Cost-Sensitive Support Vector Machine (CS-SVM) to improve the accuracy of classification. During the training process of CS-SVM, different cost factors are attached on the training errors to generate an optimized hyperplane. Our experiments show that CS-SVM outperforms SVM on the standard ODP data set. The web pages with relative high PageRank values contribute most to the classifier and using them for training can exceed the random sampling technique.	Shanghai Jiao Tong Univ, Shanghai 200240, Peoples R China; Shanghai Jiao Tong Univ, Dept Comp Sci, Shanghai 200030, Peoples R China; Microsoft Res Asia 5F, Beijing Sigma Ctr, Beijing 100080, Peoples R China	Liu, W (reprint author), Shanghai Jiao Tong Univ, 800,Dongchuan Rd, Shanghai 200240, Peoples R China.	liuweiwei@sjtu.edu.cn; grxue@sjtu.edu.cn; yyu@cs.sjtu.edu.cn; hjzeng@microsoft.com					ATTARDI G, 1999, P 1 EUR S TEL HYP AR, P12; Belkin M., 2004, TR200406 U CHIC; BING L, 2003, P 3 IEEE INT C DAT M, P179; Boser Bernhard E., 1992, P 5 ANN ACM WORKSH C, p144~152; Brin S., 1998, P 7 INT WORLD WID WE; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Carroll Raymond J, 1988, Transformation and Weighting in Regression; Chakrabarti S., 1998, P ACM SPEC INT GROUP, V27, P307; Joachims T., 1999, ADV KERNEL METHODS S; Joachims T., 1999, P 16 INT C MACH LEAR, P200; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Kuhn H. W., 1951, P 2 BERK S MATH STAT, P481; Lewis DD, 1994, P 3 ANN S DOC AN INF, P81; McCallum A, 1998, P AAAI 98 WORKSH LEA, P41; PAREDES R, 1999, P 8 S NAC REC FOR AL, V1, P437; Platt J. C., 1998, ADV KERNEL METHODS S, P185; ROUSH W, 2004, MIT TECHNOLOGY REV, P34; Ruiz ME, 2002, INFORM RETRIEVAL, V5, P87, DOI 10.1023/A:1012782908347; SHEN H, 2004, P 5 INT C WEB INF SY; SHIH LK, 2004, P 13 INT C WORLD WID; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Yiming Yang, 1999, Information Retrieval, V1; Yiming Yang, 1999, Proceedings of SIGIR '99. 22nd International Conference on Research and Development in Information Retrieval	23	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-29227-6	LECT NOTES COMPUT SC			2005	3739						127	137				11	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BDG49	WOS:000233385300012	
S	Li, M; Du, XY; Wang, S		Fan, W; Wu, Z; Yang, J		Li, M; Du, XY; Wang, S			A semi-automatic ontology acquisition method for the Semantic Web	ADVANCES IN WEB-AGE INFORMATION MANAGEMENT, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th International Conference on Web -Age Informational Management	OCT 11-13, 2005	Hangzhou, PEOPLES R CHINA	DatabaseSoc China Comp Federat, Natl Sci Fdn China, Zhejiang Univ, Y C Tang Disciplinary Dev & Fund, Oracle China				The success of the Semantic Web strongly depends on the proliferation of ontologies, which requires fast and easy engineering of ontologies. The paper analyzes the semantic similarity between relational model and ontology, and proposes a semi-automatic ontology acquisition method(SOAM) based on data in relational database. SOAM tries to ensure the quality of constructed ontology and the automatic degree of acquiring process by balancing the cooperation between user contributions and machine learning. Because OWL is the latest ontology language standard recommended by W3C, the implementation of SOAM is given to acquire OWL ontology automatically as much as possible. Different from existing methods, the implementation method not only can acquire OWL ontology from relational database directly without demanding a middle model, but also can refine obtained ontology according to existing lexical knowledge repositories semi-automatically.	Renmin Univ China, Sch Informat, Beijing 100872, Peoples R China	Li, M (reprint author), Renmin Univ China, Sch Informat, Beijing 100872, Peoples R China.	liman1@ruc.edu.cn	ruc, comp_xinxi/E-4212-2012				BERNERSLETT T, 2001, SEMANTIC WEB; BISKUP J, 1998, ACHIEVEMENTS RELATIO; CHIANG RHL, 1994, DATA KNOWL ENG, V12, P107, DOI 10.1016/0169-023X(94)90011-6; CODD E, 1970, CACM, V13; Kashyap V., 1999, P 12 WORKSH KNOWL AC; LEVENSHTEIN IV, CYBERNETICS CONTROL, V10, P707; Maedche A., 2002, ONTOLOGY LEARNING SE; MAN L, 2005, P 7 AS PAC WEB C APW; OWL, 2004, WEB ONT LANG; RAMANATHAN S, 1996, MSU960701; Rishe N., 1992, DATABASE DESIGN SEMA; Rubin DL, 2002, P PAC S BIOL; Salzberg B., 1986, SIGMOD Record, V15; STOJANOVIC L, 2002, P 17 ACM S APPL COMP; VERMEER M, 1995, P DASFAA	15	5	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-29227-6	LECT NOTES COMPUT SC			2005	3739						209	220				12	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BDG49	WOS:000233385300019	
S	Grabowski, M; Szalas, A		Szczepaniak, PS; Kacprzyk, J; Niewiadomski, A		Grabowski, M; Szalas, A			A technique for learning similarities on complex structures with applications to extracting ontologies	ADVANCES IN WEB INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	3rd International Atlantic Web Intelligence Conference (AWIC 2005)	JUN 06-09, 2005	Lodz, POLAND	Tech Univ Lodz, Inst Comp Sci, Polish Acad Sci, Syst Res Inst, Polish Cybernet Soc, Lodz Div, Polish Neural Networks Soc				A general similarity-based algorithm for extracting ontologies from data has been provided in (1]. The algorithm works over arbitrary approximation spaces, modeling notions of similarity and mereological part-of relations (see, e.g., [2,3,4,5]). In the current paper we propose a novel technique of machine learning similarity on tuples on the basis of similarities on attribute domains. The technique reflects intuitions behind tolerance spaces of [6] and similarity spaces of [7]. We illustrate the use of the technique in extracting ontologies from data.	Coll Econ & Comp Sci, Olsztyn, Poland	Grabowski, M (reprint author), Coll Econ & Comp Sci, Olsztyn, Poland.	mich@mimuw.edu.pl; sz@ida.liu.se					Cattaneo G., 1998, ROUGH SETS KNOWLEDGE, P59; CENDROWSKA J, 1987, INT J MAN MACH STUD, V27, P349, DOI 10.1016/S0020-7373(87)80003-2; Cimiano P., 2004, P EUR C ART INT ECAI, P435; Doherty P, 2003, FUND INFORM, V57, P147; Doherty P, 2003, LECT NOTES ARTIF INT, V2821, P475; DOHERTY P, 2004, P 7 INT C INF FUS FU, P175; Doherty P., 2004, P 9 INT C PRINC KNOW, P459; Doherty P, 2004, LECT NOTES ARTIF INT, V3066, P143; DUENTSCH I, 1998, ARTIF INTELL, V106, P77; Gomez-Perez A., 2004, ONTOLOGICAL ENG EXAM; Kononenko I., 1994, EUR C MACH LEARN, P171; Lamparter S, 2004, LECT NOTES COMPUT SC, V3290, P618; Lin T. Y., 1995, SOFT COMPUTING SIMUL, P18; MAEDCHE A, 2001, COMP ONTOLOGIES SIMI; Maedche A, 2002, LECT NOTES ARTIF INT, V2473, P251; NGUYEN SH, 1999, THESIS U WARSAW; Skowron A., 1996, Fundamenta Informaticae, V27; Stahl A, 2004, LECT NOTES COMPUT SC, V3075, P150, DOI 10.1007/978-3-540-25967-1_11; WANG XZ, 1995, FUZZY SET SYST, V73, P259, DOI 10.1016/0165-0114(94)00308-T; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256	20	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-26219-9	LECT NOTES COMPUT SC			2005	3528						183	189				7	Computer Science, Artificial Intelligence	Computer Science	BCN66	WOS:000230302600029	
S	Sniezynski, B		Szczepaniak, PS; Kacprzyk, J; Niewiadomski, A		Sniezynski, B			Recommendation system using multistrategy inference and learning	ADVANCES IN WEB INTELLIGENCE, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	3rd International Atlantic Web Intelligence Conference (AWIC 2005)	JUN 06-09, 2005	Lodz, POLAND	Tech Univ Lodz, Inst Comp Sci, Polish Acad Sci, Syst Res Inst, Polish Cybernet Soc, Lodz Div, Polish Neural Networks Soc		recommendation system; adaptive web sites; multistrategy learning; inferential theory of learning; logic of plausible reasoning	LOGIC	This paper presents a new approach to build recommendation systems. Multistrategy Inference and Learning System based on the Logic of Plausible Reasoning (LPR) is proposed. Two groups of knowledge transmutations are defined: inference transmutations that are formalized as LPR proof rules, and complex ones that can use machine learning algorithms to generate intrinsically new knowledge. All operators are used by inference engine in a similar manner. In this paper necessary formalism and system architecture are described. Preliminary experimental results of application of the system conclude the work.	AGH Univ Sci & Technol, Inst Comp Sci, Krakow, Poland	Sniezynski, B (reprint author), AGH Univ Sci & Technol, Inst Comp Sci, Krakow, Poland.	sniezyn@agh.edu.pl	Sniezynski, Bartlomiej/K-2296-2012				COLLINS A, 1989, COGNITIVE SCI, V13, P1; FIASMARTINEZ E, 2004, LECT NOTES COMPUTER, V3137, P104; GABBAY DM, 1991, LDS LABELED DEDUCTIV; Michalski R. S., 1994, MACHINE LEARNING MUL, V4; MICHALSKI RS, 1973, P 1 INT JOINT C PATT; MORGAN CG, 1985, LOGIQUE ANAL, V28, P257; PERKOWITZ M, 1997, P 15 INT JOINT C ART, P16; Sniezynski B, 2003, ADV SOFT COMP, P393; Sniezynski B, 2002, ADV SOFT COMP, P267	9	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-26219-9	LECT NOTES COMPUT SC			2005	3528						421	426				6	Computer Science, Artificial Intelligence	Computer Science	BCN66	WOS:000230302600065	
S	Kapur, A; Kapur, A; Virji-Babul, N; Tzanetakis, G; Driessen, PF		Tao, J; Picard, RW		Kapur, A; Kapur, A; Virji-Babul, N; Tzanetakis, G; Driessen, PF			Gesture-based affective computing on motion capture data	AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	1st International Conference on Affective Computing and Intelligent Interaction	OCT 22-24, 2005	Beijing, PEOPLES R CHINA	Nokia Ltd, Siemens Ltd, Int Speech Commun Assoc, Natl Nat Sci Fdn China, Chinese Assoc Automat, China Soc Image & Graph, China Comp Federat, Natl High Tech Res & Dev Program			FACIAL EXPRESSIONS; RECOGNITION; MOVEMENT; EMOTION	This paper presents research using full body skeletal movements captured using video-based sensor technology developed by Vicon Motion Systems, to train a machine to identify different human emotions. The Vicon system uses a series of 6 cameras to capture lightweight markers placed on various points of the body in 3D space, and digitizes movement into x, y, and z displacement data. Gestural data from five subjects was collected depicting four emotions: sadness, joy, anger, and fear. Experimental results with different machine learning techniques show that automatic classification of this data ranges from 84% to 92% depending on how it is calculated. In order to put these automatic classification results into perspective a user study on the human perception of the same data was conducted with average classification accuracy of 93%.	Univ Victoria, Victoria, BC V8W 2Y2, Canada; Wake Forest Univ, Sch Med, Winston Salem, NC 27109 USA	Kapur, A (reprint author), Univ Victoria, Victoria, BC V8W 2Y2, Canada.	ajay@ece.uvic.ca; akapur@wfubmc.edu; naznin@dsrf.org; gtzan@cs.uvic.ca; peter@ece.uvic.ca					Black MJ, 1997, INT J COMPUT VISION, V25, P23, DOI 10.1023/A:1007977618277; CHEN LS, 1998, P 3 INT C AUT FAC GE; Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197; De Silva L. C., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), DOI 10.1109/AFGR.2000.840655; DEMEIJER M, 1989, J NONVERBAL BEHAV, V13, P247; Essa IA, 1997, IEEE T PATTERN ANAL, V19, P757, DOI 10.1109/34.598232; FERNANDEZ R, 2000, P ISCA WORKSH SPEECH; Ian HW, 2000, DATA MINING PRACTICA; KANG BS, 2000, P ICSLP, P383; KAPOOR S, 2001, P EM INT 2 TANGL KNO; PANTIC M, 2003, P IEEE, V91; Picard R. W., 1997, PERSONAL TECHNOLOGIE, V1, P231, DOI 10.1007/BF01682026; PICARD RW, 2001, IBM SYST J, V39, P705; Pollick FE, 2001, COGNITION, V82, pB51, DOI 10.1016/S0010-0277(01)00147-0; Schiano D. J., 2000, P ACM CHI 2000 C HUM, P193, DOI 10.1145/332040.332430; VERVERIDIS D, 2004, P ICASSP2004, P593; VINES MM, 2003, GEST BAS COMM HUM CO; Wallbott HG, 1998, EUR J SOC PSYCHOL, V28, P879, DOI 10.1002/(SICI)1099-0992(1998110)28:6<879::AID-EJSP901>3.0.CO;2-W; WOOLARD A, 1999, VICON 512 USER MANUA; Yoshitomi Y., 2000, Proceedings 9th IEEE International Workshop on Robot and Human Interactive Communication. IEEE RO-MAN 2000 (Cat. No.00TH8499), DOI 10.1109/ROMAN.2000.892491	20	12	12	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-29621-2	LECT NOTES COMPUT SC			2005	3784						1	7				7	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDM83	WOS:000234342700001	
S	Ma, R; Wang, JX		Tao, J; Picard, RW		Ma, R; Wang, JX			Automatue facial expression recognition using linear and nonlinear holistic spatial analysis	AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	1st International Conference on Affective Computing and Intelligent Interaction	OCT 22-24, 2005	Beijing, PEOPLES R CHINA	Nokia Ltd, Siemens Ltd, Int Speech Commun Assoc, Natl Nat Sci Fdn China, Chinese Assoc Automat, China Soc Image & Graph, China Comp Federat, Natl High Tech Res & Dev Program			COMPONENT ANALYSIS	This paper is engaged in the holistic spatial analysis on facial expression images. We present a systematic comparison of machine learning methods applied to the problem of automatic facial expression recognition, including supervised and unsupervised subspace analysis, SVM classifier and their nonlinear versions. Image-based holistic spatial analysis is more adaptive to recognition task in that it automatically learns the inner structure of training samples and extracts the most pertinent features for classification, Nonlinear analysis methods which could extract higher order dependencies among input patterns are supposed to promote the performance of classification. Surprisingly, the linear classifiers outperformed their nonlinear versions in our experiments. We proposed a new feature selection method named the Weighted Saliency Maps(WSM). Compared to other feature selection schemes such as Adaboost and PCA, WSM has the advantage of being simple, fast and flexible.	Tsinghua Univ, Dept Comp Sci, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China	Ma, R (reprint author), Tsinghua Univ, Dept Comp Sci, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China.	mr02@mails.tsinghua.edu.cn					Bartlett M. S., 2001, FACE IMAGE ANAL UNSU; Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Chang Y, 2004, PROC CVPR IEEE, P520; DAILEY MN, 1999, CS629 UCSD COMP SCI; Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905; Duda R., 2000, PATTERN CLASSIFICATI; Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3; LITTLEWORT G, 2004, IEEE C COMP VIS PATT; Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-29621-2	LECT NOTES COMPUT SC			2005	3784						144	151				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDM83	WOS:000234342700019	
S	Shao, YQ; Wang, ZR; Han, JQ; Liu, T		Tao, J; Picard, RW		Shao, YQ; Wang, ZR; Han, JQ; Liu, T			Modifying spectral envelope to synthetically adjust voice quality and articulation parameters for emotional speech synthesis	AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st International Conference on Affective Computing and Intelligent Interaction	OCT 22-24, 2005	Beijing, PEOPLES R CHINA	Nokia Ltd, Siemens Ltd, Int Speech Commun Assoc, Natl Nat Sci Fdn China, Chinese Assoc Automat, China Soc Image & Graph, China Comp Federat, Natl High-Tech Res & Dev Program				Both of the prosody and spectral features are important for emotional speech synthesis, Besides prosody effects, voice quality and articulation parameters are the factors that should be considered to modify in emotional speech synthetic systems. Generally, rules and filters are designed to process these parameters respectively. This paper proves that by modifying spectral envelope, the voice quality and articulation could be adjusted as a whole. Thus, it will not need to modify each of the parameter separately depending on rules. Accordingly, it will make the synthetic system more flexible by designing an automatic spectral envelope model based on some machine learning methods. The perception test in this paper also shows that when prosody and spectral features are all modified, the best emotional synthetic speech will be obtained.	Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150006, Peoples R China	Shao, YQ (reprint author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150006, Peoples R China.	Yqshao@hit.edu.cn; zrwang@ir.hit.edu.cn; jqhan@hit.edu.cn; tliu@ir.hit.edu.cn					CAHN JE, 1989, THESIS MIT; GOBL C, 2002, P IEEE WORKSH SPEECH; HAWKINS S, 1985, J ACOUST SOC AM, V77, P1560, DOI 10.1121/1.391999; Iida A., 2000, P ISCA WORKSH SPEECH, P167; KLATT DH, 1990, J ACOUST SOC AM, V87, P820, DOI 10.1121/1.398894; MORIYAMA T, 1999, IEEE ICMCS 99; MURRAY IR, 1995, SPEECH COMMUN, V16, P369, DOI 10.1016/0167-6393(95)00005-9; NAGASAKI Y, 2004, P SPEECH PROSODY 200; RANK E, 1998, P 5 INT C SPOK LANG, V3, P671	9	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-29621-2	LECT NOTES COMPUT SC			2005	3784						334	341				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDM83	WOS:000234342700043	
S	Pardoe, D; Stone, P		Faratin, P		Pardoe, D; Stone, P			Bidding for customer orders in TAC SCM	AGENT-MEDIATED ELECTRONIC COMMERCE VI: THEORIES FOR AND ENGINEERING OF DISTRIBUTED MECHANISMS AND SYSTEMS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	6th Workshop on Agent-Mediated Electronic Commerce (AMEC VI)	JUL   19, 2004	New York, NY					Supply chains are a current, challenging problem for agent-based electronic commerce. Motivated by the Trading Agent Competition Supply Chain Management (TAC SCM) scenario, we consider an individual supply chain agent as having three major subtasks: acquiring supplies, selling products, and managing its local manufacturing process. In this paper, we focus on the sales subtask. In particular, we consider the problem of finding the set of bids to customers in simultaneous reverse auctions that maximizes the agent's expected profit. The key technical challenges we address are i) predicting the probability that a customer will accept a particular bid price, and ii) searching for the most profitable set of bids. We first compare several machine learning approaches to estimating the probability of bid acceptance. We then present a heuristic approach to searching for the optimal set of bids. Finally, we perform experiments in which we apply our learning method and bidding method during actual gameplay to measure the impact on agent performance.	Univ Texas, Austin, TX 78712 USA	Pardoe, D (reprint author), Univ Texas, Austin, TX 78712 USA.	dpardoe@cs.utexas.edu; pstone@cs.utexas.edu					ARUNACHALAM R, 2003, TAC SUPPLY CHAIN MAN; BENISCH M, 2004, SIGECOM EXCHANGES, V4, P29; DAHLGREN E, 2004, SIGECOM EXCHANGES, V4, P38; ESTELLE J, 2003, STRATEGIC INTERACTIO; KIEKINTVELD C, 2004, INT C AUT PLANN SCHE; LAWRENCE RD, 2003, P 8 INFORMS COMP SOC; PAPAIOANNOU V, 2000, IEEE INT C SYST MAN; PARDOE D, 2004, SIGECOM EXCHANGES, V4, P19; SADEH NM, 2003, AI MAGAZINE; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Schapire Robert E., 2002, P 19 INT C MACH LEAR; Witten I. H., 1999, DATA MINING PRACTICA	12	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-29737-5	LECT NOTES ARTIF INT			2005	3435						143	157				15	Computer Science, Artificial Intelligence	Computer Science	BEA49	WOS:000236459300011	
S	Sardinha, JARP; Garcia, A; Lucena, CJP; Milidiu, RL		Bresciani, P; Giorgini, P; HendersonSellers, B; Low, G; Winikoff, M		Sardinha, JARP; Garcia, A; Lucena, CJP; Milidiu, RL			A systematic approach for including machine learning in multi-agent systems	AGENT-ORIENTED INFORMATION SYSTEMS II	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	6th International Bi-Conference Workshop on Agent-Oriented Information Systems II	JUL   20, 2004	New York, NY					Large scale multi-agent systems (MASs) in unpredictable environments must use machine learning techniques to perform their goals and improve the performance of the system. This paper presents a systematic approach to introduce machine learning in the design and implementation phases of a software agent. We also present an incremental implementation process for building asynchronous and distributed agents, which suppors the combination of machine learning strategies. This process supports the stepwise building of adaptable MASs for unknown situations, improving their capacity to scale up. We use the Trading Agent Competition (TAC) environment as a case study to illustrate the suitability of our approach.	PUC Rio, Dept Comp Sci, TecComm Grp, LES, Rio De Janeiro, Brazil	Sardinha, JARP (reprint author), PUC Rio, Dept Comp Sci, TecComm Grp, LES, Rua Marques Sao Vicente 225, Rio De Janeiro, Brazil.	sardinha@inf.puc-rio.br; afgarcia@inf.puc-rio.br; lucena@inf.puc-rio.br; milidiu@inf.puc-rio.br					Bowerman B., 1993, FORECASTING TIME SER; Ferber J., 1999, MULTIAGENT SYSTEMS I; GARCIA A, 2004, THESIS PUC RIO RIO D; GIUNCHIGLIA F, 2002, P 1 INT JOINT C AUT; KENDALL E, 1999, IMPLEMENTING APPL FR; MILIDIU RL, 2001, 2001 INT C INT COMP; Mitchell T, 1997, MACHINE LEARNING; Russell S., 1995, ARTIFICIAL INTELLIGE; SARDINHA JAR, 2003, P 2 INT WORKSH SOFTW; SARDINHA JAR, 2001, THESIS PUC RIO; SARDINHA JAR, 2004, 3 INT JOINT C AUT AG; Sardinha J.A.R.P., 2004, 4 LAT AM C PATT LANG; Wooldridge M, 2000, MULTIAGENT SYSTEMS M; Zambonelli F, 2003, ACM T SOFTW ENG METH, V12, P317, DOI 10.1145/958961.958963; *TEL IT LAB, 2003, JADE PROGR GUID; DASH OPTIMIZATION	16	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-25911-2	LECT NOTES ARTIF INT			2005	3508						198	211				14	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BCL82	WOS:000229954600014	
S	Kim, BJ; Kim, IK		Zhang, S; Jarvis, R		Kim, BJ; Kim, IK			Machine learning approach to realtime intrusion detection system	AI 2005: ADVANCES IN ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	18th Australian Joint Conference on Artificial Intelligence	DEC 05-09, 2005	Sydney, AUSTRALIA	AFOSR, Asian Off Aerosp Res & Dev	Univ Technol		COMPONENT ANALYSIS	Computer security has become a critical issue with the rapid development of business and other transaction systems over the internet. Recently applying artificial intelligence, machine learning and data mining techniques to intrusion detection system are increasing. But most of researches are focused on improving the classification performance of classifier. Selecting important features from input data lead to a simplification of the problem, faster and more accurate detection rates. Thus selecting important features is an important issue in intrusion detection. Another issue in intrusion detection is that most of the intrusion detection systems are performed by off-line and it is not proper method for realtime intrusion detection system. In this paper, we develop the realtime intrusion detection system which combining on-line feature extraction method with Least Squares Support Vector Machine classifier. Applying proposed system to KDD CUP 99 data, experimental results show that it have remarkable feature feature extraction and classification performance compared to existing off-line intrusion detection system.	Youngsan Univ, Dept Network & Informat Engn, Yangsan 626847, Kyoungnam, South Korea; Kyungpook Natl Univ, Dept Comp Sci, Taejon, South Korea	Kim, BJ (reprint author), Youngsan Univ, Dept Network & Informat Engn, 150,Junamri, Yangsan 626847, Kyoungnam, South Korea.	bjkim@ysu.ac.kr; ikkim@knu.ac.kr					Diamantaras K. I., 1996, PRINCIPAL COMPONENT; ESKIN E, 2000, P 17 INT C MACH LEAR, P443; GESTEL V, 0065 ESATSISTA KU; GHOSH A, 1999, P 8 USENIX SEC S, P443; Gupta H., EXPT EVALUATION LINE; Hall P., 1998, BRIT MACH VIS C SEPT, V1, P286; Kim BJ, 2003, LECT NOTES ARTIF INT, V2871, P440; KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209; LEE W, 1999, P 1999 C KNOWL DISC; MIKA S, 1998, THESIS TU BERLIN; MURAKAMI H, 1982, IEEE T PATTERN ANAL, V4, P511; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SOFTKY WR, 1991, NEURAL NETWORKS, V4, P337, DOI 10.1016/0893-6080(91)90070-L; Suykens J., 1999, P INT JOINT C NEUR N; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; TIPPING ME, 1998, NEURAL COMPUT, V1, P443; TSUDA K, 1999, P ESANN; Vapnik VN, 1998, STAT LEARNING THEORY; Winkeler J., 1999, CVPR, V2, P511	19	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-30462-2	LECT NOTES ARTIF INT			2005	3809						153	163				11	Computer Science, Artificial Intelligence	Computer Science	BDW41	WOS:000235836100018	
S	Kornienko, L; Albrecht, DW; Dowe, DL		Zhang, S; Jarvis, R		Kornienko, L; Albrecht, DW; Dowe, DL			A preliminary MML linear classifier using principal components for multiple classes	AI 2005: ADVANCES IN ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	18th Australian Joint Conference on Artificial Intelligence	DEC 05-09, 2005	Sydney, AUSTRALIA	AFOSR, Asian Off Aerosp Res & Dev	Univ Technol	machine learning; knowledge discovery and data mining	MESSAGE LENGTH; INFERENCE	In this paper we improve on the supervised classification method developed in Kornienko et al. (2002) by the introduction of Principal Components Analysis to the inference process. We also extend the classifier from dealing with binomial (two-class) problems only to multinomial (multi-class) problems. The application to which the MML criterion has been applied in this paper is the classification of objects via a linear hyperplane, where the objects are able to come from any multi-class distribution. The inclusion of Principal Component Analysis to the original inference scheme reduces the bias present in the classifier's search technique. Such improvements lead to a method which, when compared against three commercial Support Vector Machine (SVM) classifiers on Binary data, was found to be as good as the most successful SVM tested. Furthermore, the new scheme is able to classify objects of a multiclass distribution with just one hyperplane, whereas SVMs require several hyperplanes.	Monash Univ, Sch Comp Sci & Software Engn, Clayton, Vic 3800, Australia	Kornienko, L (reprint author), Monash Univ, Sch Comp Sci & Software Engn, Clayton, Vic 3800, Australia.	Lara.Kornienko@csse.monash.edu.au; David.Albrecht@csse.monash.edu.au					Blake C. L., 1998, UCI REPOSITORY MACHI; Comley Joshua W., 2003, P HAW INT C STAT REL; COMLEY JW, 2003, ADV MINIMUM DESCRIPT; Dowe D. L., 1996, 3 AUSTR C MATH COMP, P233; DOWE DL, 1998, 14 AUSTR STAT C ASC1, P144; DOWE DL, 1993, DECISION TREE MODEL; Fisher RA, 1936, ANN EUGENIC, V7, P179; Joachims T., 1998, ADV KERNEL METHODS S; Kornienko L, 2002, LECT NOTES ARTIF INT, V2557, P119; KORNINEKO L, 2005, PRELIMINARY MML LINE; KORNJENKO L, 2005, THESIS MONASH U CLAY; Kullback S., 1959, INFORM THEORY STAT; MANGASARIAN OL, 2000, LAGRANGIAN SUPPORT V; Needham S. L., 2001, P 8 INT WORKSH ART I, P253; PLATT J, 1999, SEQUENTIAL MINIMAL O, P185; Tan PJ, 2004, LECT NOTES ARTIF INT, V3339, P1082; Vapnik V. N, 1995, NATURE STAT LEARNING; Wallace C. S., 2005, STAT INDUCTIVE INFER; WALLACE CS, 1968, COMPUT J, V11, P185; WALLACE CS, 1987, J ROY STAT SOC B MET, V49, P240; Wallace CS, 1999, COMPUT J, V42, P270, DOI 10.1093/comjnl/42.4.270	21	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-30462-2	LECT NOTES ARTIF INT			2005	3809						922	926				5	Computer Science, Artificial Intelligence	Computer Science	BDW41	WOS:000235836100111	
S	Torres, DE; Rocco, CM		Zhang, S; Jarvis, R		Torres, DE; Rocco, CM			A comparative study for assessing the reliability of complex networks using rules extracted from different machine learning approaches	AI 2005: ADVANCES IN ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	18th Australian Joint Conference on Artificial Intelligence	DEC 05-09, 2005	Sydney, AUSTRALIA	AFOSR, Asian Off Aerosp Res & Dev	Univ Technol			In this paper three machine learning approaches, Neural Networks (NN), Support Vector Machines (SVM) and Neural Fuzzy Networks (FuNN) are used to extract rules and assess the reliability of complex networks. For NN and SVM models the TREPAN approach is proposed as a valid tool for extracting rules whereas the Adaptive Neuro-Fuzzy Inference System (ANFIS) is used for tuning a previous set of rules derived by a fuzzy inference system and neural network approach.	Cent Univ Venezuela, Fac Ingn, Caracas, Venezuela; UNEFA, Caracas, Venezuela	Torres, DE (reprint author), Cent Univ Venezuela, Fac Ingn, Caracas, Venezuela.	douglastd@cantv.net; crocco@reacciun.ve					Billinton R., 1992, RELIABILITY EVALUATI; Cawley G., MATLAB SUPPORT VECTO; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Craven M.W., 1996, THESIS U WISCONSIN M; FORESEE FD, 1997, P IJCNN 97; GRIMALDI RP, REDUNDANCY RELIABILI; Hsu Chih-Wei, PRACTICAL GUIDE SUPP; JACOBSEN HA, 1998, GENERIC ARCHITECTURE; Jain L.C., 1998, FUSION NEURAL NETWOR; Jang J.-S.R., 1997, NEURO FUZZY SOFT COM; KASABOV N, 1996, ICNN 96, P118; Lin C. T., 1996, NEURAL FUZZY SYSTEMS; Lynn N, 1998, SIAM REV, V40, P202, DOI 10.1137/S0036144596306782; Marseguerra M, 2002, BASICS MONTE CARLO M; Papadimitriou C., 1982, COMBINATORIAL OPTIMI; Reingold E.M., 1977, COMBINATORIAL ALGORI; Rocco CM, 2004, RELIAB ENG SYST SAFE, V83, P301, DOI 10.1016/j.ress.2003.10.001; VEROPOULOS K, 1999, P IJCAI 99; YOO YB, 1988, IEEE T RELIAB, V37, P210, DOI 10.1109/24.3743	19	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-30462-2	LECT NOTES ARTIF INT			2005	3809						954	958				5	Computer Science, Artificial Intelligence	Computer Science	BDW41	WOS:000235836100119	
S	Bulitko, V; Wilkins, DC		Zhang, S; Jarvis, R		Bulitko, V; Wilkins, DC			Machine learning for Time Interval Petri Nets	AI 2005: ADVANCES IN ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	18th Australian Joint Conference on Artificial Intelligence	DEC 05-09, 2005	Sydney, AUSTRALIA	AFOSR, Asian Off Aerosp Res & Dev	Univ Technol	domain model learning; Petri Net learning; spatial-temporal data series learning; real-time decision-making; automated damage control		Creating Petri Net domain models faces the same challenges that confront all knowledge-intensive Al performance systems: model specification, knowledge acquisition, and refinement. Thus, a fundamental question to investigate is the degree to which automation can be used. This paper formulates the learning task and presents the first machine learning method for Time Interval Petri Net (TIPN) domain models. In a preliminary evaluation within a damage control domain, the method learned a nearly perfect model of fire spread augmented with temporal and spatial data.	Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada; Stanford Univ, Ctr Study Language & Informat, Stanford, CA 94306 USA	Bulitko, V (reprint author), Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada.	bulitko@ualberta.ca; dwilkins@stanford.edu					Bulitko V, 2003, ARTIF INTELL, V144, P95, DOI 10.1016/S0004-3702(02)00369-7; MIRANDA MC, 1999, P WORKSH APPL PETR N, P59	2	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-30462-2	LECT NOTES ARTIF INT			2005	3809						959	965				7	Computer Science, Artificial Intelligence	Computer Science	BDW41	WOS:000235836100120	
S	Bridle, R; McCreath, E		Zhang, S; Jarvis, R		Bridle, R; McCreath, E			Improving the mobile phone habitat - Learning changes in user's profiles	AI 2005: ADVANCES IN ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	18th Australian Joint Conference on Artificial Intelligence	DEC 05-09, 2005	Sydney, AUSTRALIA	AFOSR, Asian Off Aerosp Res & Dev	Univ Technol			Mobile phones are becoming a popular platform for a range of applications. However, due to size restrictions, the interfaces of these applications can be difficult to use. Customising an interface for a particular user offers the potential to improve an interface's efficiency. In this paper, we propose customising a mobile phone's Profile application. We apply a machine learning approach to discover concepts that describe a user's profile-activations in terms of their scheduled appointments. We found that it is possible to learn useful concepts, which maybe used to improve the users interaction with mobile phone devices.	Australian Natl Univ, Dept Comp Sci, Fac Engn & Informat Technol, Canberra, ACT, Australia	Bridle, R (reprint author), Australian Natl Univ, Dept Comp Sci, Fac Engn & Informat Technol, Canberra, ACT, Australia.						Davison B. D., 1998, Intelligent Environments. Papers from the 1998 AAAI Symposium; Duda R. O., 2001, PATTERN CLASSIFICATI; Korvemaker B., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); Mitchell T., 1994, Communications of the ACM, V37, DOI 10.1145/176789.176798; STAMANT R, 2004, P C HUM FACT COMP SY, P343, DOI 10.1145/985692.985736; *AUSTR BUR STAT, 2003, AUSTR NOW	6	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-30462-2	LECT NOTES ARTIF INT			2005	3809						970	974				5	Computer Science, Artificial Intelligence	Computer Science	BDW41	WOS:000235836100122	
S	Adeva, JJG; Pikatza, JM; Florez, S; Sobrado, FJ		Zhang, S; Jarvis, R		Adeva, JJG; Pikatza, JM; Florez, S; Sobrado, FJ			Intrusion detection using Text Mining in a web-based telemedicine system	AI 2005: ADVANCES IN ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	18th Australian Joint Conference on Artificial Intelligence	DEC 05-09, 2005	Sydney, AUSTRALIA	AFOSR, Asian Off Aerosp Res & Dev	Univ Technol	web intrusion detection; machine learning; Text Mining; telemedicine		Security in telemedicine systems might be considered a particularly sensitive subject due to the type of confidential information generally handled and the responsibilities consequently derived. In this work we focus on detecting attempts of gaining unauthorised access to a telemedicine web application. We introduce a new Text Mining module that by using Text Categorisation of the web application server log entries is capable of learning the characteristics of both normal and malicious user behaviour. As a result, the detection of misuse in the web application is achieved without the need of explicit programming hence improving the system main tainability.	Univ Basque Country, Fac Comp Sci, Dept Languages & Comp Syst, San Sebastian, Spain	Adeva, JJG (reprint author), Univ Basque Country, Fac Comp Sci, Dept Languages & Comp Syst, San Sebastian, Spain.	jjga@ehu.es; jm.pikatza@ehu.es; sh.florez@ehu.es; fj.sobrado@ehu.es					Barbara D, 2001, SIGMOD RECORD, V30, P15; Lee Wenke, 1998, P 7 USENIX SEC S SAN; Lewis D. D., 1998, P 10 EUR C MACH LEAR, P4; MOSCHITTI A, 2003, P 25 EUR C INF RETR; PIKATZA JM, 2002, 7 SOFTW ENG DAT BAS; YANG YM, 1994, ACM T INFORM SYST, V12, P252, DOI 10.1145/183422.183424; 2004, LECT NOTES ARTIFICIA, V3040, P587	7	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-30462-2	LECT NOTES ARTIF INT			2005	3809						1009	1014				6	Computer Science, Artificial Intelligence	Computer Science	BDW41	WOS:000235836100131	
S	Dam, HH; Shafi, K; Abbass, HA		Zhang, S; Jarvis, R		Dam, HH; Shafi, K; Abbass, HA			Can evolutionary computation handle large datasets? A study into network intrusion detection	AI 2005: ADVANCES IN ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	18th Australian Joint Conference on Artificial Intelligence	DEC 05-09, 2005	Sydney, AUSTRALIA	AFOSR, Asian Off Aerosp Res & Dev	Univ Technol			XCS is currently considered as the state of the art Evolutionary Learning Classifier Systems (ELCS). XCS has not been tested on large datasets, particularly in the intrusion detection domain. This work investigates the performance of XCS on the 1999 KDD Cup intrusion detection dataset, a real world dataset approximately five million records, more than 40 fields and multiple classes with non-uniform distribution. We propose several modifications to XCS to improve its detection accuracy. The overall accuracy becomes equivalent to that of traditional machine learning algorithms, with the additional advantages of being evolutionary and with O(n) complexity learner.	Univ New S Wales, Sch ITEE, Artificial Life & Adapt Robot Lab, Canberra, ACT 2600, Australia	Dam, HH (reprint author), Univ New S Wales, Sch ITEE, Artificial Life & Adapt Robot Lab, Canberra, ACT 2600, Australia.	z3140959@itee.adfa.edu.au; k.shafi@student.adfa.edu.au; abbass@itee.adfa.edu.au	Abbass, Hussein/C-9563-2009				BACARDIT J, 2004, 2004030 ILLIGAL U IL; Bernado-Mansilla E., 2001, P 4 INT WORKSH LEARN, P337; DAM HH, 2005, TRALAR2005070001; DIXON PW, 2001, ADV LEARNING CLASSIF, P133; Hettich S., 1999, UCI KDD ARCH; Holland J. H., 1986, MACHINE LEARNING ART, VII, P593; Lanzi P-L., 2000, LEARNING CLASSIFIER, P223; Wilson S. W., 1998, Genetic Programming 1998. Proceedings of the Third Annual Conference; Wilson SW, 1995, EVOL COMPUT, V3, P149, DOI 10.1162/evco.1995.3.2.149	9	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-30462-2	LECT NOTES ARTIF INT			2005	3809						1092	1095				4	Computer Science, Artificial Intelligence	Computer Science	BDW41	WOS:000235836100146	
S	Wozniak, M		Zhang, S; Jarvis, R		Wozniak, M			Some propositions of information fusion for pattern recognition with context task	AI 2005: ADVANCES IN ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	18th Australian Joint Conference on Artificial Intelligence	DEC 05-09, 2005	Sydney, AUSTRALIA	AFOSR, Asian Off Aerosp Res & Dev	Univ Technol			Paper deals with the concept of information fusion and its. application to the contextual pattern recognition task. The concept of the recognition based on the probabilistic model are presented. The machine learning algorithm based on statistical tests for the recognition of controlled Markov chains is shown. Some experimental results of obtained methods are shown.	Wroclaw Tech Univ, Chair Syst & Comp Networks, PL-50370 Wroclaw, Poland	Wozniak, M (reprint author), Wroclaw Tech Univ, Chair Syst & Comp Networks, Wybrzeze Wyspianskiego 27, PL-50370 Wroclaw, Poland.	michal.wozniak@pwr.wroc.pl	Wozniak, Michal/A-4806-2008				Devijver P. A., 1982, PATTERN RECOGNITION; Giakoumakis E., 1987, PATTERN RECOGNITION; HARALICK RM, 1983, IEEE T PATTERN ANAL; Koszalka L, 2005, LECT NOTES COMPUT SC, V3483, P692; Mitchell T, 1997, MACHINE LEARNING; Puchala E, 2004, LECT NOTES COMPUT SC, V3046, P39	6	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-30462-2	LECT NOTES ARTIF INT			2005	3809						1258	1261				4	Computer Science, Artificial Intelligence	Computer Science	BDW41	WOS:000235836100182	
S	Kim, H; Hong, SW; Kim, J		Zhang, S; Jarvis, R		Kim, H; Hong, SW; Kim, J			Detection of auto programs for MMORPGs	AI 2005: ADVANCES IN ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	18th Australian Joint Conference on Artificial Intelligence	DEC 05-09, 2005	Sydney, AUSTRALIA	AFOSR, Asian Off Aerosp Res & Dev	Univ Technol	data mining; entertainment and AI; machine learning; intelligent data analysis		Auto-playing programs are often used on behalf of human players ill a MMORPG(Massively Multi-player Online Role Playing Game). By playing automatically and continuously, it helps to speed up the game character's levelup process. However, the auto-playing programs, either software or hardware, do harm to games servers in various ways including abuse of resources. In this paper, we propose a way of detecting the auto programs by analyzing the window event sequences produced by the game players. In our proposed method, the event sequences are transformed into a set of attributes, and various leaming algorithms are applied to classify the data represented by the set of attribute values into human or auto player. The results from experiments with several MMORPGs show that the Decision Tree learning with proposed method can identify the auto-playing programs with high accuracy.	Dongguk Univ, Dept Comp Engn, Seoul, South Korea	Kim, J (reprint author), Dongguk Univ, Dept Comp Engn, 26 3 Pil Dong, Seoul, South Korea.	hikim@dongguk.edu; swhong@dongguk.edu; jkim@dongguk.edu					DUCHENEAUT N, 2004, P ACM C COMP SUPP CO; ROBERT G, 2002, 3 INT C INT GAM SIM; WHANG SL, 2003, INT C CYBERWORLDS	3	6	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-30462-2	LECT NOTES ARTIF INT			2005	3809						1281	1284				4	Computer Science, Artificial Intelligence	Computer Science	BDW41	WOS:000235836100187	
S	Cornforth, D; Jelinek, H		Zhang, S; Jarvis, R		Cornforth, D; Jelinek, H			Automated classification of dementia subtypes from post-mortem cortex images	AI 2005: ADVANCES IN ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	18th Australian Joint Conference on Artificial Intelligence	DEC 05-09, 2005	Sydney, AUSTRALIA	AFOSR, Asian Off Aerosp Res & Dev	Univ Technol			We apply automated classification techniques to determine whether dementia is associated with changes in the physical structure of small blood vessels in the brain. A successful predictive model would imply such an association. The use of measures derived from fractal analysis, and the use of machine learning classification algorithms, allow exploration of highly complex relationships. Results suggest that although physiological differences are difficult to detect, and vary between different areas of brain tissue, there is evidence for such an association. If such changes can be detected from images of post mortem tissue, this implies that investigation of the medical significance of these changes could provide greater understanding of this class of diseases.	Australian Def Force Acad, Canberra, ACT, Australia; Charles Sturt Univ, Albury, NSW 2640, Australia	Cornforth, D (reprint author), Australian Def Force Acad, Northcott Dr, Canberra, ACT, Australia.	d.cornforth@adfa.edu.au; hjelinek@csu.edu.au					Albus J., 1975, J DYNAMIC SYSTEMS ME, V97, P220; CORNFORTH D, 2001, P 5 BIANN C ART NEUR, P34; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Englund E, 1998, DEMENT GERIATR COGN, V9, P6, DOI 10.1159/000051183; Fernandez E, 2001, METHODS, V24, P309, DOI 10.1006/meth.2001.1201; JELINEK H, 2004, P INT COMP INT MOD C, P646; JELINEK H, 2002, LECT NOTES ARTIF INT, V2557, P721; LANDINI G, 1995, FRACTAL GEOMETRY BIO, P205; Piguet O, 2003, NEUROEPIDEMIOLOGY, V22, P165, DOI 10.1159/000069886; Witten I. H., 1999, DATA MINING PRACTICA	10	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-30462-2	LECT NOTES ARTIF INT			2005	3809						1285	1288				4	Computer Science, Artificial Intelligence	Computer Science	BDW41	WOS:000235836100188	
J	Vrakas, D; Tsoumakas, G; Bassiliades, N; Vlahavas, I				Vrakas, D; Tsoumakas, G; Bassiliades, N; Vlahavas, I			HAP(RC): an automatically configurable planning system	AI COMMUNICATIONS			English	Article							SEARCH	This paper presents an adaptive planning system, called HAP(RC), which automatically fine-tunes its planning parameters according to the morphology of the problem in hand, through a combination of Planning, Machine Learning and Knowledge-Based techniques. The adaptation is guided by a rule-based system that sets planner configuration parameters based on measurable characteristics of the problem instance. The knowledge of the rule system has been acquired through a rule induction algorithm. Specifically, the approach of propositional rule learning was applied to a dataset produced by results from experiments on a large number of problems from various domains, including those used in the three International Planning Competitions. The improvement of the adaptive system over the original planner is assessed through thorough experiments in problems of both known and unknown domains.	Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece	Vrakas, D (reprint author), Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.	dvrakas@csd.auth.gr; greg@csd.auth.gr; nbassili@csd.auth.gr; vlahavas@csd.auth.gr					Ambite J. L., 2000, Proceedings of the Fifth International Conference on Artificial Intelligence Planning and Scheduling; Bonet B., 1999, P ECP 99, P360; BORRAJO D, 1996, AI REV J, V10, P1; Carbonell J.G., 1991, ARCHITECTURES INTELL, P241; Cohen W. W., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); EDELKAMP S, 2001, AI MAG, P67; ETZIONI O, 1993, ARTIF INTELL, V62, P265; FIKES RE, 1972, ARTIF INTELL, V3, P251, DOI 10.1016/0004-3702(72)90051-3; Fox M, 1998, J ARTIF INTELL RES, V9, P367; Gerevini A, 2003, J ARTIF INTELL RES, V20, P239; GOPAL K, 2000, THESIS TEXAS A M U; Hammond K.J., 1989, CASE BASED PLANNING; Hoffmann J, 2001, J ARTIF INTELL RES, V14, P253; HOFFMANN J, 2003, LNAI, V2854; HOWE A, 1993, J ARTIFICIAL INTELLI, V1, P1; HOWE AE, 1999, P 5 EUR C PLANN, P62; KAMBHAMPATI S, 1992, ARTIF INTELL, V55, P193, DOI 10.1016/0004-3702(92)90056-4; KNOBLOCK G, 1990, P 8 NAT C ART INT ME, P923; Liu B., 1998, P 4 INT C KNOWL DISC; MARTIN M, 2000, P 7 INT C KNOWL REPR, P667; MASSEY B, 1999, DIRECTIONS PLANNING; MCCLUSKEY TL, 1993, P ML 93 WORKSH KNOWL; McCluskey TL, 1997, ARTIF INTELL, V95, P1, DOI 10.1016/S0004-3702(97)00034-9; Minton S., 1996, Constraints, V1, DOI 10.1007/BF00143877; Refanidis I, 2001, J ARTIF INTELL RES, V15, P115; Sutton R. S., 1990, P 7 INT C MACH LEARN, P216; TSOUMAKAS G, 2004, P 16 EUR C ART INT E, P693; TSOUMAKAS G, 2004, P 3 HELL C ART INT S, P132; VELOSO M, 1995, J EXP THEOR ARTIF IN, V7, P81, DOI 10.1080/09528139508953801; VRAKAS D, 2002, P 10 INT C ART INT M, P61; VRAKAS D, 2001, P 6 EUR C PLANN TOL, P1; Vrakas D., 2003, Proceedings, Thirteenth International Conference on Automated Planning and Scheduling; WANG X, 1996, P 3 INT WORKSH MULT, P23; Zimmerman T, 2003, AI MAG, V24, P73	34	1	1	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0921-7126		AI COMMUN	AI Commun.		2005	18	1					41	60				20	Computer Science, Artificial Intelligence	Computer Science	935AA	WOS:000229749900004	
J	Wiese, J; Stahl, A; Hansen, J				Wiese, J; Stahl, A; Hansen, J			Applying and optimizing case-based reasoning for wastewater treatment systems	AI COMMUNICATIONS			English	Article; Proceedings Paper	4th Workshop on Binding Environmental Sciences and Artificial Intelligence	AUG 22-23, 2004	Valencia, SPAIN			wastewater treatment; CBR; SBR; control; decision support systems; machine learning		For the last years, artificial intelligence (AI) approaches have become useful tools in environmental engineering. Here, one relevant application area is the optimization of wastewater treatment plants (WWTP). In this paper, we present several examples for real-time Control (RTC) tasks and decision support systems (DSS) for wastewater treatment (WWT), specifically based on case-based reasoning (CBR). Moreover, we present an approach for optimizing the prediction accuracy of these systems. The idea of this approach is to employ knowledge-intensive similarity measures instead of simple distance metrics. In order to facilitate the modeling of these measures resulting in lower deployment costs of the CBR systems, we propose a novel machine learning technique.	Anlagen & Sondermaschinen Automat GmbH ASA GmbH, D-32547 Bad Oeynhausen, Germany; German Res Ctr Artificial Intelligence DFKI GmbH, Image Understanding & Pattern Recognit Grp, D-67608 Kaiserslautern, Germany; Univ Kaiserslautern, Tectraa Ctr Innovat Wastewater Technol, D-67663 Kaiserslautern, Germany	Wiese, J (reprint author), Anlagen & Sondermaschinen Automat GmbH ASA GmbH, Robert Bosch St 7, D-32547 Bad Oeynhausen, Germany.	wiese@asagmbh.de; Armin.Stahl@dfki.de; jhansen@rhrk.uni-kl.de					BERGMANN R, 1999, LNAI, V1612; COMAS J, 2005, P 2 IWA C INSTR CONT, P237; Cortes U, 2001, AI COMMUN, V14, P3; Eikelboom D. H., 2000, PROCESS CONTROL ACTI; FENNER RA, 2002, P 9 INT C URB DRAIN; Kraslawski A., 1995, COMPUT CHEM ENG, V19, P821, DOI 10.1016/0098-1354(95)87136-5; KROVVIDY S, 1993, MACH LEARN, V10, P341, DOI 10.1023/A:1022643228269; Lenz M., 1999, THESIS HUMBOLDT U BE; Nunez H, 2004, ENVIRON MODELL SOFTW, V19, P809, DOI 10.1016/j.envsoft.2003.03.003; Rodriguez-Nunez A, 2001, INFECT CONT HOSP EP, V22, P477, DOI 10.1086/503410; Rodriguez-Roda I, 2002, WATER SCI TECHNOL, V45, P289; Sanchez M, 1996, ARTIF INTELL ENG, V10, P275, DOI 10.1016/0954-1810(96)00004-0; SCHUMACHER J, 2000, P 5 EUR WORKSH CAS B; SMYTH B, 1995, P 14 INT JOINT C ART; Stahl A., 2003, P 5 INT C CAS BAS RE; Stahl A., 2003, THESIS TU KAISERSLAU; STAHL A, 2002, P INT C ART INT IC A; Wettschereck D., 1995, P 1 INT C CAS BAS RE; WIESE J, 2004, P 6 INT C URB DRAIN, P325	19	5	6	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0921-7126		AI COMMUN	AI Commun.		2005	18	4					269	279				11	Computer Science, Artificial Intelligence	Computer Science	986HE	WOS:000233439900004	
J	Perini, A; Susi, A				Perini, A; Susi, A			AI in support of plant disease management	AI COMMUNICATIONS			English	Article; Proceedings Paper	4th Workshop on Binding Environmental Sciences and Artificial Intelligence	AUG 22-23, 2004	Valencia, SPAIN			Environmental Decision Support Systems; Agent-Oriented Software Engineering; Machine Learning	SYSTEMS; PREDICTION	We describe a Decision Support System for plant disease management used by technicians of the Advisory Service of Trentino region, Italy, and by the researchers in disease management techniques. We present the Artificial Intelligence (AI) methods and techniques that have been exploited during the development of the system. In particular, we discuss the role of an Agent Oriented analysis of the application domain, for requirements elicitation and system design, where AI supported the developers of the systems. In addition, Machine Learning techniques have been used to develop decision procedures to support the domain stakeholders in planning and executing actions for managing a plant disease. We illustrate results of the Machine Learning techniques application with reference to a critical apple pest. Notice that in this case AI techniques are part of the system itself. We also describe the system architecture and the main user functions.	ITC IRST, I-38050 Trento, Italy	Perini, A (reprint author), ITC IRST, Via Sommarive 18, I-38050 Trento, Italy.	perini@itc.it; susi@itc.it					Aha D., 1998, CASE BASED REASONING; Allen W, 2001, ENVIRON MANAGE, V27, P215, DOI 10.1007/s002670010144; AVESANI P, 1998, AAAI98 WORKSH CAS BA; AVESANI P, 2004, E ENV PROGR CHALLENG; Bailer-Jones CAL, 1998, NETWORK-COMP NEURAL, V9, P531, DOI 10.1088/0954-898X/9/4/008; BRANTING LK, 2001, P 13 INN APPL ART IN; Branting LK, 1997, AI APPLICATIONS, V11, P29; BRESCIANI P, 2004, J AUTONOMOUS AGENTS, V8, P203; BUTTURINI A, 1992, B IST ENT U BOLOGNA, V47, P123; CARRASCAL MJ, 1992, APPL AIJ, V6; CECCARONI L, 2000, P 2 ECAI WORKSH BIND; CORTES U, 2002, P EUR C ART INT ECAI; CORTES U, 2001, AI COMMUNICATIONS, V14; DENZER R, 2002, INTEGRATED ASSESSMEN, P53; GADOMSKI AM, 2001, IJRAM, V2; GEREVINI A, 1992, AI APPLICATIONS, V6, P51; Giles CL, 2001, MACH LEARN, V44, P161, DOI 10.1023/A:1010884214864; GIUNCHIGLIA F, 2002, LNCS; HARE M, 2002, INTEGRATED ASSESSMEN, V1, P73; Lam D, 2001, ENVIRON MODELL SOFTW, V16, P419, DOI 10.1016/S1364-8152(01)00011-1; Peng Y., 1990, ABDUCTIVE INFERENCE; PERINI A, 2004, ENV MODELLING SOFTWA, V19; Plant R. E., 1991, KNOWLEDGE BASED SYST; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; RICCI F, 2000, APPL INTELLIGENCE J, V4, P41; Rizzoli A, 2002, J MED ENTOMOL, V39, P485, DOI 10.1603/0022-2585-39.3.485; SEVERINI M, 1990, METEOROLOGY AND ENVIRONMENTAL SCIENCES, P674; VEERAMACHANENI S, 2003, P IEEE INT C DAT MIN, P665; VISSER U, 1994, INT C IEA AIE, V7, P367; Witten I. H., 1999, DATA MINING PRACTICA; [Anonymous], 2003, OMG UNIFIED MODELING	31	0	0	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0921-7126		AI COMMUN	AI Commun.		2005	18	4					281	291				11	Computer Science, Artificial Intelligence	Computer Science	986HE	WOS:000233439900005	
J	Gibert, K; Sanchez-Marre, M; Flores, X				Gibert, K; Sanchez-Marre, M; Flores, X			Cluster discovery in environmental databases using GESCONDA: The added value of comparisons	AI COMMUNICATIONS			English	Article; Proceedings Paper	4th Workshop on Binding Environmental Sciences and Artificial Intelligence	AUG 22-23, 2004	Valencia, SPAIN			knowledge acquisition and management; clustering; cluster validation; data mining; machine learning; environmental databases; statistical modelling; wastewater treatment plant	KNOWLEDGE DISCOVERY	Clustering techniques have a great importance in knowledge discovery because they can find out new groups or clusters of objects within databases. Thus, they are unsupervised learning methods, very useful when facing unknown, unlabelled and ill-structured databases, as environmental databases are. In this paper, different clustering algorithms are analyzed and compared. They are used on a real environmental data set in order to study their impact in characterizing states in this kind of domains. The comparison of the methods is undertaken using the system GESCONDA, which is a prototype of a data mining tool. Environmental data used in this paper are from a Catalan wastewater treatment plant and refers to different variables of the plant at different spatial points along 149 days.	Tech Univ Catalonia, Dept Stat & Operat Res, Barcelona, Spain; Tech Univ Catalonia, Knowledge Engn & Machine Learning Grp, Barcelona, Spain; Univ Girona, Lab Engn Quim & Ambiental, Girona, Spain	Gibert, K (reprint author), Tech Univ Catalonia, Dept Stat & Operat Res, Barcelona, Spain.	karina.gibert@upc.edu	Sanchez-Marre, Miquel/A-8569-2011				ADRIANS P, 1998, DATA MINING; Ball G. H., 1965, ISODATA NOVEL METHOD; BRATKO I, 2000, ANAL ENV DATA MACHIN; Comas J, 2001, AI COMMUN, V14, P45; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEMYANOV V, 2000, 2 ICSC S NEUR COMP N, P647; DUBES R, 1980, ADV COMPUTERS, V19; Gibert K, 1998, LECT NOTES ARTIF INT, V1510, P83; GIBERT K, 2004, T 2 BIENN M INT ENV, V1, P51; GIBERT K, 2003, LNCS, P2905; Gibert K., 1997, MATHWARE SORT COMPUT, V4, P251; Gibert K, 1998, COMPUTACION SISTEMAS, V1, P213; GIMENO JM, PRACTICAL APPL DATA; Kanevski M, 2004, ENVIRON MODELL SOFTW, V19, P845, DOI 10.1016/j.envsoft.2003.03.004; MORABITO FC, 2001, NATO ADV RES WORKSH; NAKHAEIZADEH G, 1996, IFCS, V1, P17; ROUX M, 1985, ALGORITHMS CLASSIFIC; SANCHEZMARRE M, 2002, 1 INT C INT EMS SOC, P420; Sneath P. H. A., 1963, PRINCIPLES NUMERICAL; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967; Witten I. H., 1999, DATA MINING PRACTICA	21	3	3	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0921-7126		AI COMMUN	AI Commun.		2005	18	4					319	331				13	Computer Science, Artificial Intelligence	Computer Science	986HE	WOS:000233439900008	
S	Degemmis, M; Lops, P; Semeraro, G		Bandini, S; Manzoni, S		Degemmis, M; Lops, P; Semeraro, G			Intelligent information access by learning WordNet-based user profiles	AI*IA2005: ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	9th Congress of the Italian-Association-for-Artificial-Intelligence	SEP 21-23, 2005	Milan, ITALY	Univ Milano-Bicocca, Dept Comp Sci, Syst & Commun Artificial Intelligence Lab, Italian Assoc Artificial Intelligence, AISoftware S p A, Akhela s r l, Aletheia, Gruppo Fabbro S p A, Illycaffe				The central argument of this paper the induction user profiles by supervised machine learning techniques for Intelligent Information Access. The access must be highly personalized by user profiles, in which representations of the users' interests are maintained. Moreover, users want to retrieve information on the basis of conceptual content, but individual words provide unreliable evidence about the content of documents. A possible solution is the adoption of WordNet as a lexical resource to induce semantic user profiles.	Univ Bari, Dipartimento Informat, I-70125 Bari, Italy	Degemmis, M (reprint author), Univ Bari, Dipartimento Informat, Via E Orabona,4, I-70125 Bari, Italy.	degemmis@di.uniba.it; lops@di.uniba.it; semeraro@di.uniba.it					CECI M, 2003, P ECIR 03 25 EUR C I, P57; Fellbaum C., 1998, WORDNET ELECT LEXICA; MANNING CD, 1984, FDN STAT NATURAL LAN; Salton G., 1983, INTRO MODERN INFORM; YAO YY, 1995, J AM SOC INFORM SCI, V46, P133, DOI 10.1002/(SICI)1097-4571(199503)46:2<133::AID-ASI6>3.0.CO;2-Z	5	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-29041-9	LECT NOTES ARTIF INT			2005	3673						78	81				4	Computer Science, Artificial Intelligence	Computer Science	BDF68	WOS:000233291300008	
S	Ceci, M; Berardi, M; Malerba, D		Bandini, S; Manzoni, S		Ceci, M; Berardi, M; Malerba, D			Relational learning: Statistical approach versus logical approach in document image understanding	AI*IA2005: ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	9th Congress of the Italian-Association-for-Artificial-Intelligence	SEP 21-23, 2005	Milan, ITALY	Univ Milano-Bicocca, Dept Comp Sci, Syst & Commun Artificial Intelligence Lab, Italian Assoc Artificial Intelligence, AISoftware S p A, Akhela s r l, Aletheia, Gruppo Fabbro S p A, Illycaffe			CLASSIFIER	Document image understanding denotes the recognition of semantically relevant components in the layout extracted from a document image. This recognition process is based on some visual models that can be automatically acquired by applying machine learning techniques. In particular, by properly encapsulating knowledge of the inherent spatial nature of the layout of a document image, spatial relations among logical components of interest can play a key role in the learned models. For this reason, we are investigating the application of (multi-)relational learning techniques, which successfully allows relations between components to be effectively and naturally represented. Goal of this paper is to evaluate and systematically compare two different approaches to relational learning, that is, a statistical approach and a logical approach in the task of document image understanding. For a fair comparison, both methods are tested on the same dataset consisting of multi-page articles published in an international journal. An analysis of pros and cons of both approaches is reported.	Univ Bari, Dipartimento Informat, I-70126 Bari, Italy	Ceci, M (reprint author), Univ Bari, Dipartimento Informat, Via Orabona 4, I-70126 Bari, Italy.	ceci@di.uniba.it; berardi@di.uniba.it; malerba@di.uniba.it	Malerba, Donato/H-3850-2012				Aiello M., 2002, International Journal on Document Analysis and Recognition, V5, DOI 10.1007/s10032-002-0080-x; Akindele O. T., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, DOI 10.1109/ICDAR.1995.598977; Altamura O., 2001, International Journal on Document Analysis and Recognition, V4, DOI 10.1007/PL00013569; Ceci M, 2003, LECT NOTES ARTIF INT, V2838, P95; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dzeroski S., 2001, RELATIONAL DATA MINI; LEBOURGEOIS F, 2001, WORKSH DOC LAYOUT IN; Malerba D, 2003, FUND INFORM, V57, P39; MLADEMNICD GROBELNIK M, 1999, P 16 INT C MACH LEAR, P258; Palmero G.I.S., 1999, INT J DOC ANAL RECOG, P181; Pearl J., 1988, PROBABILISTIC REASON; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; ROSENFELD A, 1976, IEEE T SMC, V6; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Taskar B., 2002, P 18 C UNC ART INT U, P485; Walischewski H, 1997, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, VOLS 1 AND 2, P243, DOI 10.1109/ICDAR.1997.619849; Zadrozny B., 2001, P 18 INT C MACH LEAR, P609	18	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-29041-9	LECT NOTES ARTIF INT			2005	3673						418	429				12	Computer Science, Artificial Intelligence	Computer Science	BDF68	WOS:000233291300042	
S	Basile, TMA; Esposito, F; Di Mauro, N; Ferilli, S		Bandini, S; Manzoni, S		Basile, TMA; Esposito, F; Di Mauro, N; Ferilli, S			Handling continuous-valued attributes in incremental first-order rules learning	AI*IA2005: ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	9th Congress of the Italian-Association-for-Artificial-Intelligence	SEP 21-23, 2005	Milan, ITALY	Univ Milano-Bicocca, Dept Comp Sci, Syst & Commun Artificial Intelligence Lab, Italian Assoc Artificial Intelligence, AISoftware S p A, Akhela s r l, Aletheia, Gruppo Fabbro S p A, Illycaffe			NUMERICAL ATTRIBUTES	Machine Learning systems are often distinguished according to the kind of representation they use, which can be either propositional or first-order logic. The framework working with first-order logic as a representation language for both the learned theories and the observations is known as Inductive Logic Programming (ILP). It has been widely shown in the literature that ILP systems have limitations in dealing with large amounts of numerical information, that is however a peculiarity of most real-world application domains. In this work we present a strategy to handle such information in a relational learning incremental setting and its integration with classical symbolic approaches to theory revision. Experiments were carried out on a real-world domain and a comparison with a state-of-art system is reported.	Univ Bari, Dept Comp Sci, I-70121 Bari, Italy	Basile, TMA (reprint author), Univ Bari, Dept Comp Sci, I-70121 Bari, Italy.	basile@di.uniba.it; esposito@di.uniba.it; ndm@di.uniba.it; ferilli@di.uniba.it	Di Mauro, Nicola/B-7719-2008				ALPHONSE E, 2000, P 14 EUR C ART INT E, P256; Baroglio C, 1996, MACH LEARN, V23, P221, DOI 10.1007/BF00117445; Botta M., 1993, P 13 INT JOINT C ART, P937; Botta M, 2000, MACH LEARN, V38, P109, DOI 10.1023/A:1007686007399; CAMERONJONES RM, 1994, EFFICIENT TOP DOWN I; CATLETT J, 1991, LECT NOTES ARTIF INT, V482, P164; Divina F, 2003, LECT NOTES COMPUT SC, V2723, P898; DOUNGHERTY J, 1995, P ICML95, P194; Elomaa T, 1999, MACH LEARN, V36, P201, DOI 10.1023/A:1007674919412; ESPOSITO F, 2000, P 17 INT C MACH LEAR, P263; Esposito F., 2001, Intelligent Data Analysis, V5; Esposito F, 2003, APPL ARTIF INTELL, V17, P859, DOI 10.1080/08839510390225203; Lavrac N., 1994, INDUCTIVE LOGIC PROG; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; SEBAG M, 1996, ADV INDUCTIVE LOGIC, P277; Semeraro G., 1998, LECT NOTES COMPUTER, V1463, P300, DOI 10.1007/3-540-49674-2_16; TRESP V, 1993, ADV NEURAL INFORMATI, V5, P871; ZADEH L, 1992, INTRO FUZZY LOGIC AP; ZUCKER JD, 1998, LECT NOTES ARTIF INT, V1446, P235; [Anonymous], 1993, P 13 INT JOINT C ART, P1022	21	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-29041-9	LECT NOTES ARTIF INT			2005	3673						430	441				12	Computer Science, Artificial Intelligence	Computer Science	BDF68	WOS:000233291300043	
B	Feng, D; Zeng, LF; Wang, F; Qin, LJ; Liu, Q		Shih, TK; Shibata, Y		Feng, D; Zeng, LF; Wang, F; Qin, LJ; Liu, Q			Adaptive policy trigger mechanism for OBSS	AINA 2005: 19th International Conference on Advanced Information Networking and Applications, Vol 2			English	Proceedings Paper	19th International Conference on Advanced Information Networking and Applications	MAR 28-30, 2005	Taipei, TAIWAN	IEEE Comp Soc Tech Comm Distributed Proc, Tamkang Univ, Asian Off Aerosp Res & Dev, USA Asian Res Off				Traditional storage systems, such as NAS, SAN, are largely unaware of the users and applications actually using the storage, because block-based storage devices manage opaque data blocks. But, with OBSS (object-based storage system), the attributes and methods among the storage devices can be adopted in the storage system, the data can be distributed on some of the storage devices and organized better to anticipate users demand. In this paper, the scalability of object storage (including object attributes, object methods and OBSS) is studied. And a self-managing approach, denoted adaptive policy trigger mechanism (APTM), is presented. APTM borrows proven machine learning techniques and takes the perspective scalable object storage. The implementation reveals that APTM is the embodiment of the idea about smart storage device and facilitates to self-manage mass storage system.	Huazhong Univ Sci & Technol, Sch Comp, Minist Educ, Key Lab Data Storage Syst, Wuhan 430074, Peoples R China	Feng, D (reprint author), Huazhong Univ Sci & Technol, Sch Comp, Minist Educ, Key Lab Data Storage Syst, Wuhan 430074, Peoples R China.						ARI I, 2002, P INFORMATICS, V14, P143; BRAAM PJ, 2004, LUSTRE STORAGE ARCH; BROWN A, 1999, P 7 WORKSH HOT TOP O; CHEN Y, 2002, P 9 INT C PAR DISTR, P301; FENG D, 2004, 3 INT C MACH LEARN C, P387; HERBSTER M, 1995, P 12 INT C MACH LEAR, P286; STRUNK JD, 2003, 1 WORKSH ALG ARH SEL; WELLS C, 2004, OCEANSTORE ARCH GOAL; WIKES J, 2001, HIGH PERFORMANCE MAS, P90; XIN Q, 2003, P 20 IEEE 11 NASA GO, P146; ZENG LF, 2004, 3 INT C MACH LEARN C, P3263; *INT CORP, 2004, OBJ BAS STOR NEXT WA; 2004, WHITE PAPER OBJECT S; 2004, IBM STORAGE TANK MAR	14	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-2249-1				2005							591	595				5	Computer Science, Information Systems; Telecommunications	Computer Science; Telecommunications	BCH23	WOS:000229285400126	
B	Zhuang, ZM		Shih, TK; Shibata, Y		Zhuang, ZM			iHITS: Extending HITS for personal interests profiling	AINA 2005: 19th International Conference on Advanced Information Networking and Applications, Vol 2			English	Proceedings Paper	19th International Conference on Advanced Information Networking and Applications	MAR 28-30, 2005	Taipei, TAIWAN	IEEE Comp Soc Tech Comm Distributed Proc, Tamkang Univ, Asian Off Aerosp Res & Dev, USA Asian Res Off				Ever since the boom of World Wide Web, profiling online users' interests has become an important task for content providers. The traditional approach involves manual entry of users' data, which requires intensive labor and time. Recent approaches utilize machine learning and clustering techniques to build the profiles, by analyzing the content of the Web pages visited by the users. Because such solutions rely heavily on the textual information, although they are capable of differentiating different topics of interests, it remains a difficult task to determine the users' different levels of interests in a given topic as well as gauge the shift of interests over time. In this paper, we propose iHITS, which is an extension to the HITS (Hypertext-Induced Topic Search) algorithm. The algorithm automatically determines a ranked list of user's interests through link analysis on Web pages that the user visited. The visit pattern is obtained from the browsing history. We evaluate our approach by comparing automatically-generated interests profiles of the users with users' manual entry to examine its accuracy and effectiveness. Our evaluation shows that the approach is promising and achieves satisfactory results. Our study introduces a novel approach to build a user-interests profiling systems with the capability to automatically capture and rank users' browsing interests preference.	Penn State Univ, Sch Informat & Technol, University Pk, PA 16802 USA	Zhuang, ZM (reprint author), Penn State Univ, Sch Informat & Technol, University Pk, PA 16802 USA.						BILLSUS D, 1999, PERSONAL NEWS AGENT; Kleinberg J., 1998, P 9 ACM SIAM S DISCR; KYOUNG K, 2003, LEARNING IMPLICIT US; LANG K, 1994, P INT C MACH LEARN 1, P331; Middleton SE, 2004, ACM T INFORM SYST, V22, P54, DOI 10.1145/963770.963773; MORITA M, 1994, P 17 SIGIR C; SAKAGAMI H, 1997, P 6 WWW C; SHETH B, 1994, THESIS MIT DEP ELECT; SPILIOPOULOU M, 1999, P PRINCIPLES DATA MI; WANG J, 2002, WIDM 02         1108; YAN TW, 1995, P 1995 USENIX TECHN; YOSHINORI H, 2004, IMPLICIT USER PROFIL	12	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-2249-1				2005							747	751				5	Computer Science, Information Systems; Telecommunications	Computer Science; Telecommunications	BCH23	WOS:000229285400151	
S	Morales, M; Tapia, L; Pearce, R; Rodriguez, S; Amato, NM		Erdmann, M; Hsu, D; Overmars, M; VanDerStappen, F		Morales, M; Tapia, L; Pearce, R; Rodriguez, S; Amato, NM			A machine learning approach for feature-sensitive motion planning	Algorithmic Foundations of Robotics VI	SPRINGER TRACTS IN ADVANCED ROBOTICS		English	Proceedings Paper	6th International Workshop on Algorithmic-Foundations-of-Robotics	JUL 11-13, 2004	Zeist, NETHERLANDS	Utrecht Univ, Dutch Org Sci Res				Although there are many motion planning techniques, there is no method that outperforms all others for all problem instances. Rather, each technique has different strengths and weaknesses which makes it best-suited for certain types of problems. Moreover, since an environment can contain vastly different regions, there may not be a single planner that will perform well in all its regions. Ideally, one would use a suite of planners in concert and would solve the problem by applying the best-suited planner in each region. In this paper, we propose an automated framework for feature-sensitive motion planning. We use a machine learning approach to characterize and partition C-space into regions that are well suited to one of the methods in our library of roadmap-based motion planners. After the best-suited method is applied in each region, the resulting region roadmaps are combined to form a roadmap of the entire planning space. Over a range of problems, we demonstrate that our simple prototype system reliably outperforms any of the planners on their own.	Texas A&M Univ, Dept Comp Sci, Parasol Lab, College Stn, TX 77843 USA	Morales, M (reprint author), Texas A&M Univ, Dept Comp Sci, Parasol Lab, College Stn, TX 77843 USA.		Morales Aguirre, Marco/A-6430-2012				Amato NM, 1998, ROBOTICS: THE ALGORITHMIC PERSPECTIVE, P155; BARRAQUAND J, 1991, INT J ROBOT RES, V10, P628, DOI 10.1177/027836499101000604; BESSIERE P, 1993, P IEEE INT C INT ROB, V2, P1373, DOI 10.1109/IROS.1993.583784; Bohlin R., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), DOI 10.1109/ROBOT.2000.844107; Boor V., 1999, P IEEE INT C ROB AUT, V2, P1018, DOI 10.1109/ROBOT.1999.772447; Brock O., 2001, Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164), DOI 10.1109/ROBOT.2001.932817; Brooks R. A., 1983, P INT JOINT C ART IN, P799; Bystroff C, 1998, J MOL BIOL, V281, P565, DOI 10.1006/jmbi.1998.1943; Canny J.F., 1988, COMPLEXITY ROBOT MOT; Dale L. K., 2001, Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164), DOI 10.1109/ROBOT.2001.932892; GERAERTS R, 2002, P INT WORKSH ALG FDN; Hsu D., 2000, P INT WORKSH ALG FDN, pSAl1; Kamath C, 2002, COMPUT SCI ENG, V4, P52, DOI 10.1109/MCISE.2002.1014980; Kavraki LE, 1996, IEEE T ROBOTIC AUTOM, V12, P566, DOI 10.1109/70.508439; KHATIB O, 1986, INT J ROBOT RES, V5, P90, DOI 10.1177/027836498600500106; LAVALLE S, 2002, P INT WORKSH ALG FDN; LaValle S. M., 1999, Proceedings 1999 IEEE International Conference on Robotics and Automation (Cat. No.99CH36288C), DOI 10.1109/ROBOT.1999.770022; LOZANOPEREZ T, 1979, COMMUN ACM, V22, P560, DOI 10.1145/359156.359164; Mitchell T, 1997, MACHINE LEARNING; MORALES M, 2003, P IEEE INT C ROB AUT, V3, P4427; Nielsen C. L., 2000, TR2000365 RIC U COMP; Overmars M., 1994, P WORKSH ALG FDN ROB, P19; OVERMARS M.H., 1992, RUUCS9232 UTR U; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Reif J. H., 1979, P 20 IEEE S FDN COMP, P421; Schwartz G, 1998, ULTRASOUND OBST GYN, V11, P4, DOI 10.1046/j.1469-0705.1998.11010004.x; Wilmarth S. A., 1999, P IEEE INT C ROB AUT, V2, P1024, DOI 10.1109/ROBOT.1999.772448	27	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1610-7438	3-540-25728-4	SPR TRA ADV ROBOT			2005	17						361	376				16	Robotics	Robotics	BCY49	WOS:000231865200025	
S	Kowalczyk, A; Chapelle, O		Jain, S; Simon, HU; Tomita, E		Kowalczyk, A; Chapelle, O			An analysis of the anti-learning phenomenon for the class symmetric polyhedron	ALGORITHMIC LEARNING THEORY	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	16th Annual International Conference on Algorithmic Learning Theory (LAT 2005)	OCT 08-11, 2005	Singapore, SINGAPORE	Lee Fdn, USAF, Asian Off Aerosp Res & Dev, Natl Univ Singapore, Sch Comp, Ruhr Univ Bochum, Fak Math, Hokkaido Univ, Div Comp Sci, Univ Lubeck, Inst Theoret Comp Sci, MBZ Marketing Buro Zeugmann				This paper deals with an unusual phenomenon where most machine learning algorithms yield good performance on the training set but systematically worse than random performance on the test set. This has been observed so far for some natural data sets and demonstrated for some synthetic data sets when the classification rule is learned from a small set of training samples drawn from some high dimensional space. The initial analysis presented in this paper shows that anti-learning is a property of data sets and is quite distinct from over-fitting of a training data. Moreover, the analysis leads to a specification of some machine learning procedures which can overcome anti-learning and generate machines able to classify training and test data consistently.	Australian Natl Univ, Natl ICT Australia, Canberra, ACT, Australia; Australian Natl Univ, RSISE, Canberra, ACT, Australia; Max Planck Inst Biol Cybernet, Tubingen, Germany	Kowalczyk, A (reprint author), Australian Natl Univ, Natl ICT Australia, GPO Box 4, Canberra, ACT, Australia.	adam.kowalczyk@nicta.com.au; olivier.chapelle@tuebingen.mpg.de					BAMBER D, 1975, J MATH PSYCHOL, V12, P387, DOI 10.1016/0022-2496(75)90001-2; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; CRAVEN M, 2002, SIGKDD EXPLORATIONS, V4; Cristianini N., 2000, INTRO SUPPORT VECTOR; Freund Y, 1999, MACH LEARN, V37, P277, DOI 10.1023/A:1007662407062; HALL P, 2005, IN PRESS J ROYAL STA; KOWALCZYK A, 2005, ANAL ANTI LEARNING P; KOWALCZYK A, 2002, SIGKDD EXPLORATIONS, V4; KOWALCZYK A, 2005, ANTI LEARNING BINARY; Raskutti B., 2004, SIGKDD EXPLORATIONS, V6, P60, DOI DOI 10.1145/1007730.1007739; Scholkopf B., 2001, LEARNING KERNELS SUP; Vapnik VN, 1998, STAT LEARNING THEORY; WARMUTH MK, 2005, IN PRESS COLT 2005; WOLPERT DH, 2001, SUPERVISED LEARNING	14	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-29242-X	LECT NOTES ARTIF INT			2005	3734						78	91				14	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	BDH68	WOS:000233583800007	
S	Harvey, NR; Porter, RB		Shen, SS; Lewis, PE		Harvey, NR; Porter, RB			Spectral morphology for feature extraction from multi- and hyper-spectral imagery	ALGORITHMS AND TECHNOLOGIES FOR MULTISPECTRAL, HYPERSPECTRAL, AND ULTRASPECTRAL IMAGERY XI	Proceedings of SPIE		English	Proceedings Paper	Conference on Algorithms and Technologies for Multispectral, Hyperspectral, and Ultraspectral Imagery XI	MAR 28-APR 01, 2005	Orlando, FL	SPIE, Ball Aerosp & Technol Corp, Univ Central Florida, Coll Opt & Photon, Florida Space Inst, FOI, Swedish Def Res Agcy, Univ Central Florida		mathematical morphology; multispectral; optimization; image processing; feature extraction	GENETIC ALGORITHMS; OPERATIONS; FILTERS; OPTIMIZATION; DESIGN	For accurate and robust analysis of remotely-sensed imagery it is necessary to combine the information from both spectral and spatial domains in a meaningful manner. The two domains are intimately linked: objects in a scene are defined in terms of both their composition and their spatial arrangement, and cannot accurately be described by information from either of these two domains on their own. To date there have been relatively few methods for combining spectral and spatial information concurrently. Most techniques involve separate processing for extracting spatial and spectral information. In this paper we will describe several extensions to traditional morphological operators that can treat spectral and spatial domains concurrently and can be used to extract relationships between these domains in a meaningful way. This includes the investgation and development of suitable vector-ordering metrics and machine-learning-based techniques for optimizing the various parameters of the morphological operators, such as morphological operator, structuring element and vector ordering metric. We demonstrate their application to a range of multi- and hyper-spectral image analysis problems.	Los Alamos Natl Lab, Los Alamos, NM 87544 USA	Harvey, NR (reprint author), Los Alamos Natl Lab, POB 1663, Los Alamos, NM 87544 USA.	harve@lanl.gov; rporter@lanl.gov					Al-Otum HM, 2003, OPT ENG, V42, P2595, DOI 10.1117/1.1594727; Bishop C. M., 1995, NEURAL NETWORKS PATT, p[105, 310, 333]; Chanussot J, 1998, COMP IMAG VIS, V12, P51; Comer ML, 1999, J ELECTRON IMAGING, V8, P279, DOI 10.1117/1.482677; EHRHARDT R, 1994, P SOC PHOTO-OPT INS, V2330, P2; Hamid MS, 2003, IEEE T CIRC SYST VID, V13, P406, DOI 10.1109/TCSVT.2003.811608; HARVEY D, 1996, RETHINKING MARXISM, V8, P1; Harvey NR, 2002, IEEE T GEOSCI REMOTE, V40, P393, DOI 10.1109/36.992801; Kraft P, 1997, J ELECTRON IMAGING, V6, P504, DOI 10.1117/12.277768; Lambert P., 2000, P INT C COL GRAPH IM, P158; Li W, 1996, P SOC PHOTO-OPT INS, V2662, P24, DOI 10.1117/12.235839; MARAGOS P, 1987, IEEE T ACOUST SPEECH, V35, P1153, DOI 10.1109/TASSP.1987.1165259; Ortiz F, 2001, P SOC PHOTO-OPT INS, V4572, P259, DOI 10.1117/12.444190; Perkins S, 2001, P SOC PHOTO-OPT INS, V4381, P286, DOI 10.1117/12.437019; Plaza A, 2002, IEEE T GEOSCI REMOTE, V40, P2025, DOI 10.1109/TGRS.2002.802494; PLAZA A, 2001, SUMMARIES XJPL AIRBO; Plaza A, 2002, P SOC PHOTO-OPT INS, V4541, P278, DOI 10.1117/12.454162; Sartor LJ, 2001, J ELECTRON IMAGING, V10, P548, DOI 10.1117/1.1353199; Wheeler M, 2000, PROCEEDINGS OF THE IEEE 2000 NATIONAL AEROSPACE AND ELECTRONICS CONFERENCE, P618, DOI 10.1109/NAECON.2000.894970	19	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	0-8194-5791-4	PROC SPIE			2005	5806		1&2				100	111		10.1117/12.602747		12	Remote Sensing; Imaging Science & Photographic Technology	Remote Sensing; Imaging Science & Photographic Technology	BCR68	WOS:000230952600010	
S	Ravichandran, B; Gandhe, A; Smith, R; Mehra, R		Zeinio, EG; Garber, FD		Ravichandran, B; Gandhe, A; Smith, R; Mehra, R			SAR ATR using genetics based machine learning	Algorithms for Synthetic Aperture Radar Imagery XII	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Conference on Algorithms for Symthetic Aperture Radar Imagery XII	MAR 28-31, 2005	Orlando, FL			Robust Automatic Target Recognition; Machine Learning; learning classifier systems; evolutionary algorithms; standard/extended operating conditions	PATTERN-RECOGNITION; STATE; ART	Addressing the challenge of robust ATR, this paper describes the development and demonstration of Machine Learning for Robust ATR. The primary innovation of this work is the development of an automated way of developing heuristic inference rules that can draw on multiple models and multiple feature types to make more robust ATR decisions. The key realization is that this "meta learning" problem is one of structural learning: that can be conducted independently of parameter learning associated with each model and feature based technique., and more effectively draw on the strengths of all such techniques, and even information from unforeseen techniques. This is accomplished by using robust, genetics-based machine learning for the ill conditioned combinatorial problem of structural rule learning, while using statistical and mathematical techniques for parameter learning. This paper describes a learning classifier system approach (with evolutionary computation for structural learning) for robust ATR and points to a promising solution to the structural learning problem, across multiple feature types (which we will refer to as the meta-learning problem), for ATR with EOCs. This system was tested on MSTAR Public Release SAR data using nominal and extended operation conditions. These results were also compared against two baseline classifiers, a PCA based distance classifier and a MSE classifier. The systems were evaluated for accuracy (via training set classification) and robustness (via testing set classification). In both cases, the LCS based robust ATR system performed very well with accuracy over 99% and robustness over 80%.	Sci Syst Co Inc, Woburn, MA 01801 USA	Ravichandran, B (reprint author), Sci Syst Co Inc, 500 W Cummings Pk,Suite 3000, Woburn, MA 01801 USA.						Back T., 1997, HDB EVOLUTIONARY COM; BHANU B, 1986, IEEE T AERO ELEC SYS, V22, P364, DOI 10.1109/TAES.1986.310772; DEJONG, 1993, MACHINE LEARNING; DIEMUNSCH J, 1999, ASC990746 AIR FORC R; Duda R. O., 2001, PATTERN CLASSIFICATI; Fukunaga K., 1972, INTRO STAT PATTERN R; Goldberg DE, 1989, GENETIC ALGORITHMS S; Holland J.H., 1992, ADAPTION NATURAL ART; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; KANAL L, 1974, IEEE T INFORMATION T; KEYDEL ER, 1997, ALGORITHMS SYNTHETIC, V2757; LANZI PL, 2000, LEARNING CLASSIFIER, P63; LANZI PL, 1996, ADV LEARNING CLASSIF, P103; Mossing JC, 1998, P SOC PHOTO-OPT INS, V3370, P554, DOI 10.1117/12.321858; NAGY G, 1968, PR INST ELECTR ELECT, V56, P836, DOI 10.1109/PROC.1968.6414; ROSS T, 1997, ALGORITHMS SYNTHETIC, V3070; SMITH RE, 2001, CREATIVE EVOLUTIONAR, P467; Sutton R.S., 1998, REINFORCEMENT LEARNI; Wilson SW, 1994, EVOL COMPUT, V2, P1, DOI 10.1162/evco.1994.2.1.1; Wilson SW, 1995, EVOL COMPUT, V3, P149, DOI 10.1162/evco.1995.3.2.149; ZELNIO E, 1997, SPE, V3070	21	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	0-8194-5793-0	P SOC PHOTO-OPT INS			2005	5808						269	281		10.1117/12.603444		13	Computer Science, Interdisciplinary Applications; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BCU80	WOS:000231335900027	
S	Gilmore, JF		Zeinio, EG; Garber, FD		Gilmore, JF			Machine learning in exploitation	Algorithms for Synthetic Aperture Radar Imagery XII	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Conference on Algorithms for Symthetic Aperture Radar Imagery XII	MAR 28-31, 2005	Orlando, FL			machine learning; exploitation; target recognition; threats	ALGORITHMS	Exploitation has largely focused on single look, single modality platform collections exploited by a variety of classification algorithms over the last several decades. But multi look, multi modality exploitation is the evolving paradigm for threat classification given the evolution and cost of near term unmanned vehicle system sensor platforms. This paper presents an overview of machine learning algorithms that have previously been applied to automatic target recognition, discusses the evolution of target recognition to the 2010 paradigm of multi look, multi modality valid target identification, and explores how advanced machine learning algorithms can be applied to address the exploitation problems of the next decade.	DZN Technol, Saline, MI 48176 USA	Gilmore, JF (reprint author), DZN Technol, 6210 Windmill Court, Saline, MI 48176 USA.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Balch Tucker, 2002, ROBOT TEAMS DIVERSIT; Breiman L, 2001, MACH LEARN, V45, P261, DOI 10.1023/A:1017934522171; Cristianini N., 2000, INTRO SUPPORT VECTOR; FREEMAN JA, 1991, NEURAL NETWORKS; Gen M., 1999, GENETIC ALGORITHMS E; KAZAKOV D, 2002, GRAND CHALLENGES COM; Kearns MJ, 1994, INTRO COMPUTATIONAL; Natschlager T, 2001, NEURAL COMPUT, V13, P2477, DOI 10.1162/089976601753195987; PEAR J, 1988, PROBABILISTIC REASON; QUINLAN JR, 1993, C45 PROGR MACH LEARN; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Sutton R.S., 1998, REINFORCEMENT LEARNI; VILALTA R, 2002, J ARTIFICAL INTELLIG; 2002 AAAI MIX INT LE; 2002, ICML 2002 WORKSH CON	16	2	2	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	0-8194-5793-0	P SOC PHOTO-OPT INS			2005	5808						337	344		10.1117/12.609895		8	Computer Science, Interdisciplinary Applications; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BCU80	WOS:000231335900033	
S	Madeira, SC; Oliveira, AL		Casadio, R; Myers, G		Madeira, SC; Oliveira, AL			A linear time biclustering algorithm for time series gene expression data	ALGORITHMS IN BIOINFORMATICS, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	5th International Workshop on Algorithms in Bioinformatics (WABI 2005)	OCT 03-06, 2005	Mallorca, SPAIN					Several non-supervised machine learning methods have been used in the analysis of gene expression data obtained from microarray experiments. Recently, biclustering, a non-supervised approach that performs simultaneous clustering on the row and column dimensions of the data matrix, has been shown to be remarkably effective in a variety of applications. The goal of biclustering is to find subgroups of genes and subgroups of conditions, where the genes exhibit highly correlated behaviors. In the most common settings, biclustering is an NP-complete problem, and heuristic approaches are used to obtain sub-optimal solutions using reasonable computational resources. In this work, we examine a particular setting of the problem, where we are concerned with finding biclusters in time series expression data. In this context, we are interested in finding biclusters with consecutive columns. For this particular version of the problem, we propose an algorithm that finds and reports all relevant biclusters in time linear on the size of the data matrix. This complexity is obtained by manipulating a discretized version of the matrix and by using string processing techniques based on suffix trees. We report results in both synthetic and real data that show the effectiveness of the approach.	INESC, ID, Lisbon, Portugal; Univ Tecn Lisboa, IST, Lisbon, Portugal; Univ Beira Interior, Covilha, Portugal	Madeira, SC (reprint author), INESC, ID, Lisbon, Portugal.	smadeira@di.ubi.pt; aml@inesc-id.pt	Oliveira, Arlindo/C-1700-2008; Madeira, Sara/C-5494-2008	Oliveira, Arlindo/0000-0001-8638-5594; 			Ben-Dor A, 2002, P 6 INT C COMP BIOL, P49, DOI 10.1145/565196.565203; Cheng Y., 2000, P 8 INT C INT SYST M, P93; Gusfield Dan, 1997, ALGORITHMS STRINGS T; Ji LP, 2005, BIOINFORMATICS, V21, P509, DOI 10.1093/bioinformatics/bti026; Koyuturk M., 2004, Proceedings. 2004 IEEE Computational Systems Bioinformatics Conference; Liu JM, 2004, PROCEEDINGS OF THE 1ST INTERNATIONAL CONFERENCE ON RELIABILITY OF ELECTRICAL PRODUCTS AND ELECTRICAL CONTACTS, P182; LONARDI S, 2004, P 15 ANN S COMB PATT, P102; Luan YH, 2003, BIOINFORMATICS, V19, P474, DOI 10.1093/bioinformatics/btg014; Madeira SC, 2004, IEEE ACM T COMPUT BI, V1, P24, DOI 10.1109/TCBB.2004.2; Martin D, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-12-r101; McLachlan G. J., 2004, ANAL MICROARRAY GENE; MONTEIRO P, YEAST SEARCH TRANSCR; Murali T, 2003, PAC S BIOCOMPUT, V8, P77; Peeters R, 2003, DISCRETE APPL MATH, V131, P651, DOI 10.1016/S0166-218X(03)00333-0; Sheng Q., 2003, BIOINFORMATICS S2, V19, pii196; Tanay Amos, 2002, Bioinformatics, V18 Suppl 1, pS136; Tavazoie S, 1999, NAT GENET, V22, P281; UKKONEN E, 1995, ALGORITHMICA, V14, P249, DOI 10.1007/BF01206331	18	12	12	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-29008-7	LECT NOTES COMPUT SC			2005	3692						39	52				14	Biochemical Research Methods; Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering; Computer Science, Theory & Methods	Biochemistry & Molecular Biology; Computer Science	BDH02	WOS:000233555100004	
