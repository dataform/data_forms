PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	PU	PI	PA	SN	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	PG	WC	SC	GA	UT
J	Kucukyilmaz, T; Cambazoglu, BB; Aykanat, C; Can, F				Kucukyilmaz, Tayfun; Cambazoglu, B. Barla; Aykanat, Cevdet; Can, Fazli			Chat mining: Predicting user and message attributes in computer-mediated communication	INFORMATION PROCESSING & MANAGEMENT			English	Article						authorship analysis; chat mining; computer-mediated communication; machine learning; stylistics; text classification	AUTOMATIC TEXT CATEGORIZATION; WRITING-STYLE; AUTHORSHIP; GENDER; GENRE	The focus of this paper is to investigate the possibility of predicting several user and message attributes in text-based, real-time, online messaging services. For this purpose, a large collection of chat messages is examined. The applicability of various supervised classification techniques for extracting information from the chat messages is evaluated. Two competing models are used for defining the chat mining problem. A term-based approach is used to investigate the user and message attributes in the context of vocabulary use while a style-based approach is used to examine the chat messages according to the variations in the authors' writing styles. Among 100 authors, the identity of an author is correctly predicted with 99.7% accuracy. Moreover, the reverse problem is exploited, and the effect of author attributes on computer-mediated communications is discussed. (C) 2008 Elsevier Ltd. All rights reserved.	[Kucukyilmaz, Tayfun; Aykanat, Cevdet; Can, Fazli] Bilkent Univ, Dept Comp Engn, TR-06800 Bilkent, Turkey; [Cambazoglu, B. Barla] Yahoo, Res Barcelona, Barcelona, Spain	Aykanat, C (reprint author), Bilkent Univ, Dept Comp Engn, TR-06800 Bilkent, Turkey.	ktayfun@cs.bilkent.edu.tr; barla@yahoo-inc.com; aykanat@cs.bilkent.edu.tr; canf@cs.bilkent.edu.tr					Argamon S., 2003, P 9 ACM SIGKDD INT C, P475; Baayen R.H., 1996, LIT LINGUISTIC COMPU, V11, P121; BACKER E, 2004, P C INT MUS CIM04 GR; BINONGO JNG, 1999, LIT LINGUISTIC COMPU, V11, P121; Burrows J. F., 1987, COMPUTATION CRITICIS; CAMBAZOGLU BB, 2005, BUCE0503 COMP ENG DE; Can F, 2004, COMPUT HUMANITIES, V38, P61, DOI 10.1023/B:CHUM.0000009225.28847.77; CORNEY M, 2001, SIGMOD RECORD WEB ED, V30, P55; Corney M. W., 2003, THESIS QUEENSLAND U; Dickey MH, 2007, J ASSOC INF SYST, V8, P47; ELLIOTT W, 1991, NOTES QUERIES, V236, P501; Foster Don, 2000, AUTHOR UNKNOWN TRAIL; Graham N., 2005, Natural Language Engineering, DOI 10.1017/S1351324905003694; HAKUTA K, 1991, STANFORD CTR CHICANO, V33; Han E., 2001, P 5 PAC AS C KNOWL D, P53; Herring SC, 2006, J SOCIOLING, V10, P439, DOI 10.1111/j.1467-9841.2006.00287.x; HERRING SC, 2007, MULTILINGUAL INTERNE; HOLMES DI, 1985, J ROY STAT SOC A STA, V148, P328, DOI 10.2307/2981893; Holmes D. I., 1995, LIT LINGUISTIC COMPU, V10, P111, DOI 10.1093/llc/10.2.111; HOLMES DI, 1994, COMPUT HUMANITIES, V28, P87, DOI 10.1007/BF01830689; HOTA S, 2006, GENDER SHAKESPEARE A; Zheng R, 2006, J AM SOC INF SCI TEC, V57, P378, DOI 10.1002/asi.20316; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; JONSSON E, 1998, ELECT DISCOURSE SPEE; Juola P., 2005, Literary & Linguistic Computing, DOI 10.1093/llc/fqi024; KARLGREN J, 1994, P 15 INT C COMP LING, V2, P1071, DOI 10.3115/991250.991324; Kessler B., 1997, P 35 ANN M ASS COMP, P32, DOI http://dx.doi.org/10.3115/976909.979622; Khmelev D. V., 2001, Literary & Linguistic Computing, V16, DOI 10.1093/llc/16.3.299; KJELL B, 1994, IEEE INT C SYST MAN; Koppel M., 2002, Literary & Linguistic Computing, V17, DOI 10.1093/llc/17.4.401; KRUSL I, 1997, COMPUT SECUR, V16, P233; Kubat M., 1997, P 14 INT C MACH LEAR, P179; KUCUKYILMAZ T, 2006, P 4 BIENN C ADV INF, P274; Lam W, 1999, IEEE T KNOWL DATA EN, V11, P865; Levitan S., 2006, DIGITAL HUMANITIES, P323; Love H., 2002, ATTRIBUTING AUTHORSH; McCallum A., 1998, AAAI 98 WORKSH LEARN; Merriam T. V. N., 1994, Literary & Linguistic Computing, V9, DOI 10.1093/llc/9.1.1; MOSTELLER F, 1964, INFERENCE DISPUTED A; Patton JM, 2004, COMPUT HUMANITIES, V38, P457, DOI 10.1007/s10579-004-1906-6; Pollatschek M., 1981, Association for Literary and Linguistic Computing Bulletin, V8; Radford Marie L, 2007, SCAN, V26, P31; RADFORD ML, 2005, J AM SOC INFORM SCI, V57, P1046; RUDMAN JOSEPH, 1998, COMPUT HUMANITIES, V31, P351; Sabordo M, 2005, P SOC PHOTO-OPT INS, V5649, P513, DOI 10.1117/12.582098; Salton G., 1983, INTRO MODERN INFORM; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Spafford E. H., 1993, Computers & Security, V12, DOI 10.1016/0167-4048(93)90055-A; Stamatatos E, 2000, COMPUT LINGUIST, V26, P471, DOI 10.1162/089120100750105920; Thomson R, 2001, BRIT J SOC PSYCHOL, V40, P193, DOI 10.1348/014466601164812; TSUBOI Y, 2002, THESIS NARA I SCI TE; Turell MT, 2004, INT J SPEECH LANG LA, V11, P1; Tweedie FJ, 1996, COMPUT HUMANITIES, V30, P1, DOI 10.1007/BF00054024; VEL DO, 2002, 2 DIG FOR RES WORKSH; WALTHER JB, 2005, P 38 ANN HAW INT C S; WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968; Yang Yiming, 1997, P 14 INT C MACH LEAR, P412; ZELENKAUSKATIE A, 2006, P CULT ATT TECHN COM, P474; *WIK, 2007, EMOTICON	59	4	4	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0306-4573		INFORM PROCESS MANAG	Inf. Process. Manage.	JUL	2008	44	4					1448	1466		10.1016/j.ipm.2007.12.009		19	Computer Science, Information Systems; Information Science & Library Science	Computer Science; Information Science & Library Science	321AP	WOS:000257276800004	
J	Brovelli, MA; Crespi, M; Fratarcangeli, F; Giannone, F; Realini, E				Brovelli, Maria Antonia; Crespi, Mattia; Fratarcangeli, Francesca; Giannone, Francesca; Realini, Eugenio			Accuracy assessment of high resolution satellite imagery orientation by leave-one-out method	ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING			English	Article						high resolution satellite imagery; orientation; accuracy assessment; leave-one-out cross validation	SENSOR ORIENTATION; RPCS	Interest in high-resolution satellite imagery (HRSI) is spreading in several application fields, at both scientific and commercial levels. Fundamental and critical goals for the geometric use of this kind of imagery are their orientation and orthorectification, processes able to georeference the imagery and correct the geometric deformations they undergo during acquisition. In order to exploit the actual potentialities of orthorectified imagery in Geomatics applications, the definition of a methodology to assess the spatial accuracy achievable from oriented imagery is a crucial topic. In this paper we want to propose a new method for accuracy assessment based on the Leave-One-Out Cross-Validation (LOOCV), a model validation method already applied in different fields such as machine learning, bioinformatics and generally in any other field requiring an evaluation of the performance of a learning algorithm (e.g. in geostatistics), but never applied to HRSI orientation accuracy assessment. The proposed method exhibits interesting features which are able to overcome the most remarkable drawbacks involved by the commonly used method (Hold-Out Validation - HOV), based on the partitioning of the known ground points in two sets: the first is used in the orientation-orthorectification model (GCPs - Ground Control Points) and the second is used to validate the model itself (CPs - Check Points). In fact the HOV is generally not reliable and it is not applicable when a low number of ground points is available. To test the proposed method we implemented a new routine that performs the LOOCV in the software SISAR, developed by the Geodesy and Geomatics Team at the Sapienza University of Rome to perform the rigorous orientation of HRSI; this routine was tested on some EROS-A and QuickBird images. Moreover, these images were also oriented using the world recognized commercial software OrthoEngine v. 10 (included in the Geomatica suite by PCI), manually performing the LOOCV since only the HOV is implemented. The software comparison guaranteed about the overall correctness and good performances of the SISAR model, whereas the results showed the good features of the LOOCV method. (C) 2008 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS). Published by Elsevier B.V. All rights reserved.	[Brovelli, Maria Antonia; Realini, Eugenio] Politecn Milan, DIIAR, I-22100 Como, Italy; [Crespi, Mattia; Fratarcangeli, Francesca; Giannone, Francesca] Univ Roma La Sapienza, Area Geodesia & Geomat, DITS, I-00184 Rome, Italy	Brovelli, MA (reprint author), Politecn Milan, DIIAR, Via Valleggio 11, I-22100 Como, Italy.	maria.brovelli@polimi.it; mattia.crespi@uniromal.it; francesca.giannone@uniromal.it; eugenio.realini@polimi.it					AMATO R, 2004, INT ARCH PHOTOGRAMME, V35, P593; BAIOCCHI V., 2004, P 24 EARSEL S DUBR C, V24, P461; CHEN L. C., 2002, INT ARCH PHOTOGRAMME, V34, P620; CRESPI M, 2006, INT ARCH PHOTOGRAMME, V36; Di KC, 2003, PHOTOGRAMM ENG REM S, V69, P33; ELISSEEFF A, 2002, ADV LEARNING THEORY, P111; Fraser C. S., 2003, ASIAN J GEOINFORMATI, V4, P3; Fraser CS, 2005, PHOTOGRAMM ENG REM S, V71, P909; Fraser CS, 2006, ISPRS J PHOTOGRAMM, V60, P182, DOI 10.1016/j.isprsjprs.2005.11.001; GEISSER S, 1975, J AM STAT ASSOC, V70, P320, DOI 10.2307/2285815; Golub GH, 1993, MATRIX COMPUTATION; JACOBSEN K, 2002, INDIAN CARTOGRAPHER, V22, P106; Kaula W. M., 1966, THEORY SATELLITE GEO; Kohavi R., 1995, STUDY CROSS VALIDATI; Noerdlinger PD, 1999, ISPRS J PHOTOGRAMM, V54, P360, DOI 10.1016/S0924-2716(99)00030-1; Noguchi M, 2004, PHOTOGRAMM REC, V19, P128; Press WH, 1992, NUMERICAL RECIPES C; Simon R, 2003, J NATL CANCER I, V95, P14; STONE M, 1974, J R STAT SOC B, V36, P111; Strang G., 1997, LINEAR ALGEBRA GEODE; Toutin T., 2002, EARTH OBSERVATION MA, V11, P14; Toutin T, 2004, INT J REMOTE SENS, V25, P1893, DOI 10.1080/0143116031000101611; TOUTIN T, 2003, P ISPRS COMM 4 S JOI, P547; WESTIN T, 1990, PHOTOGRAMM ENG REM S, V56, P247; ZHANG L, 2005, 90 ETH IGP	25	14	15	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0924-2716		ISPRS J PHOTOGRAMM	ISPRS-J. Photogramm. Remote Sens.	JUL	2008	63	4					427	440		10.1016/j.isprsjprs.2008.01.006		14	Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology	Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology	337OV	WOS:000258446300004	
J	Elith, J; Leathwick, JR; Hastie, T				Elith, J.; Leathwick, J. R.; Hastie, T.			A working guide to boosted regression trees	JOURNAL OF ANIMAL ECOLOGY			English	Article						data mining; machine learning; model averaging; random forests; species distributions	GENERALIZED ADDITIVE-MODELS; NEW-ZEALAND; PREDICTION; FISH; CLASSIFICATION	1. Ecologists use statistical models for both explanation and prediction, and need techniques that are flexible enough to express typical features of their data, such as nonlinearities and interactions. 2. This study provides a working guide to boosted regression trees (BRT), an ensemble method for fitting statistical models that differs fundamentally from conventional techniques that aim to fit a single parsimonious model. Boosted regression trees combine the strengths of two algorithms: regression trees (models that relate a response to their predictors by recursive binary splits) and boosting (an adaptive method for combining many simple models to give improved predictive performance). The final BRT model can be understood as an additive regression model in which individual terms are simple trees, fitted in a forward, stagewise fashion. 3. Boosted regression trees incorporate important advantages of tree-based methods, handling different types of predictor variables and accommodating missing data. They have no need for prior data transformation or elimination of outliers, can fit complex nonlinear relationships, and automatically handle interaction effects between predictors. Fitting multiple trees in BRT overcomes the biggest drawback of single tree models: their relatively poor predictive performance. Although BRT models are complex, they can be summarized in ways that give powerful ecological insight, and their predictive performance is superior to most traditional modelling methods. 4. The unique features of BRT raise a number of practical issues in model fitting. We demonstrate the practicalities and advantages of using BRT through a distributional analysis of the short-finned eel (Anguilla australis Richardson), a native freshwater fish of New Zealand. We use a data set of over 13 000 sites to illustrate effects of several settings, and then fit and interpret a model using a subset of the data. We provide code and a tutorial to enable the wider use of BRT by ecologists.	[Elith, J.] Univ Melbourne, Sch Bot, Parkville, Vic 3010, Australia; [Leathwick, J. R.] Natl Inst Water & Atmospher Res, Hamilton, New Zealand; [Hastie, T.] Stanford Univ, Dept Stat, Stanford, CA 94305 USA	Elith, J (reprint author), Univ Melbourne, Sch Bot, Parkville, Vic 3010, Australia.	j.elith@unimelb.edu.au					Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; BUCKLAND ST, 1993, J APPL ECOL, V30, P478, DOI 10.2307/2404188; Burnham KP, 2002, MODEL SELECTION INFE; Clarke A, 1999, J ANIM ECOL, V68, P893, DOI 10.1046/j.1365-2656.1999.00337.x; De'ath G, 2007, ECOLOGY, V88, P243, DOI 10.1890/0012-9658(2007)88[243:BTFEMA]2.0.CO;2; De'ath G, 2000, ECOLOGY, V81, P3178, DOI 10.1890/0012-9658(2000)081[3178:CARTAP]2.0.CO;2; Elith J, 2006, ECOGRAPHY, V29, P129, DOI 10.1111/j.2006.0906-7590.04596.x; Fewster RM, 2000, ECOLOGY, V81, P1970, DOI 10.1890/0012-9658(2000)081[1970:AOPTFF]2.0.CO;2; Fidler F, 2004, PSYCHOL SCI, V15, P119, DOI 10.1111/j.0963-7214.2004.01502008.x; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2; Friedman JH, 2003, STAT MED, V22, P1365, DOI 10.1002/sim.1501; Hastie T, 2001, ELEMENTS STAT LEARNI; HASTIE TJ, 1990, GENERALIZED ADDITIVE; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; LEATHWICK JR, 2008, J BIOGEOGRA IN PRESS; Leathwick JR, 2006, MAR ECOL PROG SER, V321, P267, DOI 10.3354/meps321267; McCullagh P., 1989, GENERALIZED LINEAR M; MCDOWALL RM, 1993, NEW ZEAL J MAR FRESH, V27, P453; Miller A. J., 1990, SUBSET SELECTION REG; Moisen GG, 2006, ECOL MODEL, V199, P176, DOI 10.1016/j.ecolmodel.2006.05.021; Prasad AM, 2006, ECOSYSTEMS, V9, P181, DOI 10.1007/s10021-005-0054-1; R Development Core Team, 2006, R LANG ENV STAT COMP; Reineking B, 2006, ECOL MODEL, V193, P675, DOI 10.1016/j.ecolmodel.2005.10.003; RIDGEWAY G, 2006, DOCUMENTATION R PACK; Schapire R., 2003, MSRI WORKSH NONL EST; SEGAL MR, 2004, ESCHOLARSHIP REPOSIT; Whittingham MJ, 2006, J ANIM ECOL, V75, P1182, DOI 10.1111/j.1365-2656.2006.01141.x	31	296	303	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0021-8790		J ANIM ECOL	J. Anim. Ecol.	JUL	2008	77	4					802	813		10.1111/j.1365-2656.2008.01390.x		12	Ecology; Zoology	Environmental Sciences & Ecology; Zoology	310OV	WOS:000256539800020	
J	Bhattacharyya, S; Siegel, ER; Achenbach, SJ; Khosla, S; Suva, LJ				Bhattacharyya, Sudeepa; Siegel, Eric R.; Achenbach, Sara J.; Khosla, Sundeep; Suva, Larry J.			Serum biomarker profile associated with high bone turnover and BMD in postmenopausal women	JOURNAL OF BONE AND MINERAL RESEARCH			English	Article						surface enhanced laser desorption/ionization time of flight mass spectrometry; biomarkers; fracture risk; bone turnover	LASER DESORPTION/IONIZATION-TIME; FLIGHT-MASS-SPECTROMETRY; HOST RESPONSE PROTEINS; SELDI-TOF-MS; PROTEOMIC PATTERNS; OVARIAN-CANCER; BIOCHEMICAL MARKERS; PROSTATE-CANCER; BREAST-CANCER; DIAGNOSIS	Early diagnosis of the onset of osteoporosis is key to the delivery of effective therapy. Biochemical markers of bone turnover provide a means of evaluating skeletal dynamics that complements static measurements of BMD by DXA. Conventional clinical measurements of bone turnover, primarily the estimation of collagen and its breakdown products in the blood or urine, lack both sensitivity and specificity as a reliable diagnostic tool. As a result, improved tests are needed to augment the use of BMD measurements as the principle diagnostic modality. In this study, the serum proteome of 58 postmenopausal women with high or low/normal bone turnover (training set) was analyzed by surface enhanced laser-desorption/ionization time-of-flight mass spectrometry, and a diagnostic fingerprint was identified using a variety of statistical and machine learning tools. The diagnostic fingerprint was validated in a separate distinct test set, consisting of serum samples from an additional 59 postmenopausal women obtained from the same Mayo cohort, with a gap of 2 yr. Specific protein peaks that discriminate between postmenopausal patients with high or low/normal bone turnover were identified and validated. Multiple supervised learning approaches were able to classify the level of bone turnover in the training set with 80% sensitivity and 100% specificity. In addition, the individual protein peaks were also significantly correlated with BMD measurements in these patients. Four of the major discriminatory peaks in the diagnostic profile were identified as fragments of interalpha-trypsin-inhibitor heavy chain H4 precursor (ITIH4), a plasma kallikrein-sensitive glycoprotein that is a component of the host response system. These data suggest that these serum protein fragments are the serum-borne reflection of the increased osteoclast activity, leading to the increased bone turnover that is associated with decreasing BMD and presumably an increased risk of fracture. In conjunction with the identification of the individual proteins, this protein fingerprint may provide a novel approach to evaluate high bone turnover states.	[Bhattacharyya, Sudeepa; Suva, Larry J.] Univ Arkansas Med Sci, Ctr Orthopaed Res, Dept Orthopaed Surg, Barton Res Inst, Little Rock, AR 72205 USA; [Siegel, Eric R.] Univ Arkansas Med Sci, Dept Biostat, Little Rock, AR 72205 USA; [Achenbach, Sara J.] Mayo Clin, Coll Med, Dept Hlth Sci Res, Rochester, MN USA; [Khosla, Sundeep] Mayo Clin, Coll Med, Div Endocrinol, Rochester, MN USA	Suva, LJ (reprint author), Univ Arkansas Med Sci, Ctr Orthopaed Res, Dept Orthopaed Surg, Barton Res Inst, 4301 W Markham St,Slot 644, Little Rock, AR 72205 USA.	suvalarryj@uams.edu					Bendre MS, 2005, CANCER RES, V65, P11001, DOI 10.1158/0008-5472.CAN-05-2630; BHATTACHARYYA S, 2005, DIS MARKERS, V22, P245; Bhattacharyya S, 2004, NEOPLASIA, V6, P674, DOI 10.1593/neo.04262; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Collom SL, 2007, ARCH BIOCHEM BIOPHYS, V459, P59, DOI 10.1016/j.abb.2006.10.028; Delmas PD, 2002, LANCET, V359, P2018, DOI 10.1016/S0140-6736(02)08827-X; Diamandis EP, 2004, J NATL CANCER I, V96, P353, DOI 10.1093/jnci/djh056; Diamandis EP, 2004, MOL CELL PROTEOMICS, V3, P367, DOI 10.1074/mcp.R400007-MCP200; Dogan E, 2002, POSTGRAD MED J, V78, P727, DOI 10.1136/pmj.78.926.727; Fung ET, 2005, INT J CANCER, V115, P783, DOI 10.1002/ijc.20928; Garnero P, 2000, J BONE MINER RES, V15, P1526, DOI 10.1359/jbmr.2000.15.8.1526; Garnero P., 2004, Journal of Musculoskeletal & Neuronal Interactions, V4, P50; Kanis JA, 2002, LANCET, V359, P1929, DOI 10.1016/S0140-6736(02)08761-5; Kanis JA, 2000, OSTEOPOROSIS INT, V11, P192, DOI 10.1007/s001980050281; Khosla S, 1998, J CLIN ENDOCR METAB, V83, P2266, DOI 10.1210/jc.83.7.2266; Kohli Manish, 2006, Cancer Biomarkers, V2, P249; Koomen JM, 2005, CLIN CANCER RES, V11, P1110; Koopmann J, 2004, CLIN CANCER RES, V10, P860, DOI 10.1158/1078-0432.CCR-1167-3; Kozak KR, 2003, P NATL ACAD SCI USA, V100, P12343, DOI 10.1073/pnas.2033602100; Li JN, 2002, CLIN CHEM, V48, P1296; Liotta LA, 2006, J CLIN INVEST, V116, P26, DOI 10.1172/JCI27467; Marguiles AG, 2006, CLIN CANCER RES, V12, p6217S, DOI 10.1158/1078-0432.CCR-06-1070; McGarry KA, 2000, POSTGRAD MED, V108, P79; Melton LJ, 1996, MAYO CLIN PROC, V71, P266; Merchant M, 2000, ELECTROPHORESIS, V21, P1164, DOI 10.1002/(SICI)1522-2683(20000401)21:6<1164::AID-ELPS1164>3.3.CO;2-S; Paweletz CP, 2001, DIS MARKERS, V17, P301; Perrien DS, 2006, J CLIN ENDOCR METAB, V91, P1848, DOI 10.1210/jc.2005-2423; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Qu YS, 2002, CLIN CHEM, V48, P1835; ROMETTE J, 1986, PATHOL BIOL, V34, P1006; Song J, 2006, CLIN CHEM, V52, P1045, DOI 10.1373/clinchem.2005.065722; Suriano R, 2006, J PROTEOME RES, V5, P856, DOI 10.1021/pr050349r; Vermeulen R, 2005, P NATL ACAD SCI USA, V102, P17041, DOI 10.1073/pnas.0508573102; Villanueva J, 2006, J CLIN INVEST, V116, P271, DOI 10.1172/JCI26022; Ward DG, 2006, BRIT J CANCER, V94, P1898, DOI 10.1038/sj.bjc.6603188; Whicher J, 1999, CLIN CHEM LAB MED, V37, P495, DOI 10.1515/CCLM.1999.080; Klibanski A, 2001, JAMA-J AM MED ASSOC, V285, P785; Zhang Z, 2004, CANCER RES, V64, P5882, DOI 10.1158/0008-5472.CAN-04-0746; *US SURG GEN, 2004, SURG GEN REP BON HLT	40	14	14	AMER SOC BONE & MINERAL RES	WASHINGTON	2025 M ST, N W, STE 800, WASHINGTON, DC 20036-3309 USA	0884-0431		J BONE MINER RES	J. Bone Miner. Res.	JUL	2008	23	7					1106	1117		10.1359/JBMR.080235		12	Endocrinology & Metabolism	Endocrinology & Metabolism	319IB	WOS:000257156200018	
J	Barillari, C; Marcou, G; Rognan, D				Barillari, Caterina; Marcou, Gilles; Rognan, Didier			Hot-spots-guided receptor-based pharmacophores (HS-Pharm): A knowledge-based approach to identify ligand-anchoring atoms in protein cavities and prioritize structure-based pharmacophores	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							INFLUENZA-VIRUS NEURAMINIDASE; BINDING-SITE; SELECTIVE INHIBITORS; MOLECULAR DOCKING; CRYSTAL-STRUCTURE; DRUG DISCOVERY; DATA-BANK; DESIGN; IDENTIFICATION; FINGERPRINTS	The design of biologically active compounds from ligand-free protein structures using a structure-based approach is still a major challenge. In this paper, we present a fast knowledge-based approach (HS-Pharm) that allows the prioritization of cavity atoms that should be targeted for ligand binding, by training machine learning algorithms with atom-based fingerprints of known ligand-binding pockets. The knowledge of hot spots for ligand binding is here used for focusing structure-based pharmacophore models. Three targets of pharmacological interest (neuraminidase, 2 adrenergic receptor, and cyclooxygenase-2) were used to test the evaluated methodology, and the derived structure-based pharmacophores were used in retrospective virtual screening studies. The cur-rent study shows that structure-based pharmacophore screening is a powerful technique for the fast identification of potential hits in a chemical library, and that it is a valid alternative to virtual screening by molecular docking.	[Barillari, Caterina; Rognan, Didier] Univ Louis Pasteur Strasbourg 1, CNRS ULP, UMR Bioinformat Drug 7175, F-67400 Illkirch Graffenstaden, France; [Marcou, Gilles] Univ Louis Pasteur Strasbourg 1, CNRS, Lab Infochim, UMR 7551, F-67400 Illkirch Graffenstaden, France	Rognan, D (reprint author), Univ Louis Pasteur Strasbourg 1, CNRS ULP, UMR Bioinformat Drug 7175, 74 route Rhin,BP 24, F-67400 Illkirch Graffenstaden, France.	didier.rognan@pharma.u-strasbg.fr					Ahlstrom MM, 2005, J CHEM INF MODEL, V45, P1313, DOI 10.1021/ci049626p; Baroni M, 2007, J CHEM INF MODEL, V47, P279, DOI 10.1021/ci600253e; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Bissantz C, 2000, J MED CHEM, V43, P4759, DOI 10.1021/jm001044l; BOHM HJ, 1992, J COMPUT AID MOL DES, V6, P61, DOI 10.1007/BF00124387; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bruno IJ, 1997, J COMPUT AID MOL DES, V11, P525, DOI 10.1023/A:1007934413448; Carlson HA, 2000, J MED CHEM, V43, P2100, DOI 10.1021/jm990322h; Charifson PS, 1999, J MED CHEM, V42, P5100, DOI 10.1021/jm990352k; Chen J, 2006, J CHEM INF MODEL, V46, P2684, DOI 10.1021/ci600246s; Cherezov V, 2007, SCIENCE, V318, P1258, DOI 10.1126/science.1150577; Fox T, 2000, J COMPUT AID MOL DES, V14, P411, DOI 10.1023/A:1008167012101; Franke L, 2005, J MED CHEM, V48, P6997, DOI 10.1021/jm050619h; Freund Y., 1996, P 13 INT C MACH LEAR, P148; GOODFORD PJ, 1985, J MED CHEM, V28, P849, DOI 10.1021/jm00145a002; Huang N, 2006, J MED CHEM, V49, P6789, DOI 10.1021/jm0608356; Kellenberger E, 2007, J MED CHEM, V50, P1294, DOI 10.1021/jm061389p; Kellenberger E, 2006, J CHEM INF MODEL, V46, P717, DOI 10.1021/ci050372x; Kellenberger E, 2004, PROTEINS, V57, P225, DOI 10.1002/prot.20149; Kelly MD, 2005, J MED CHEM, V48, P1069, DOI 10.1021/jm049524q; Kelly MD, 2003, J COMPUT AID MOL DES, V17, P401, DOI 10.1023/A:1027346709963; Kirchhoff PD, 2001, J COMPUT CHEM, V22, P993, DOI 10.1002/jcc.1060; Kitchen DB, 2004, NAT REV DRUG DISCOV, V3, P935, DOI 10.1038/nrd1549; Lundstrom K, 2007, J CELL MOL MED, V11, P224, DOI 10.1111/j.1582-4934.2007.00028.x; Marcou G, 2007, J CHEM INF MODEL, V47, P195, DOI 10.1021/ci600342e; MASFERRER JL, 1994, P NATL ACAD SCI USA, V91, P3228, DOI 10.1073/pnas.91.8.3228; Mason JS, 1999, J MED CHEM, V42, P3251, DOI 10.1021/jm9806998; McGovern SL, 2003, J MED CHEM, V46, P2895, DOI 10.1021/jm0300330; Michaux C, 2006, EUR J MED CHEM, V41, P1446, DOI 10.1016/j.ejmech.2006.07.017; Moitessier N, 2008, BRIT J PHARMACOL, V153, pS7, DOI 10.1038/sj.bjp.0707515; Ortuso F, 2006, BIOINFORMATICS, V22, P1449, DOI 10.1093/bioinformatics/btl115; Palomer A, 2002, J MED CHEM, V45, P1402, DOI 10.1021/jm010458r; Phillips George N. Jr., 2007, Journal of Structural and Functional Genomics, V8, P73, DOI 10.1007/s10969-007-9023-6; Quinlan J. R., 1993, PROGRAMS MACHINE LEA; Renner S, 2004, J MED CHEM, V47, P4653, DOI 10.1021/jm031139y; Rogers D, 2005, J BIOMOL SCREEN, V10, P682, DOI 10.1177/1087057105281365; Rollinger JM, 2004, J CHEM INF COMP SCI, V44, P480, DOI 10.1021/ci030031o; Salom D, 2006, P NATL ACAD SCI USA, V103, P16123, DOI 10.1073/pnas.0608022103; Schuller A, 2006, COMB CHEM HIGH T SCR, V9, P359, DOI 10.2174/138620706777452375; Shepphird JK, 2006, J COMPUT AID MOL DES, V20, P763, DOI 10.1007/s10822-006-9070-2; Sherman W, 2006, J MED CHEM, V49, P534, DOI 10.1021/jm050540c; Singh SK, 2005, EUR J MED CHEM, V40, P977, DOI 10.1016/j.ejmech.2005.03.016; Spannhoff A, 2007, J MED CHEM, V50, P2319, DOI 10.1021/jm061250e; Sperandio O, 2007, J CHEM INF MODEL, V47, P1097, DOI 10.1021/ci700031v; Steindl T, 2004, J CHEM INF COMP SCI, V44, P1849, DOI 10.1021/ci049844i; Steindl TM, 2006, J CHEM INF MODEL, V46, P2146, DOI 10.1021/ci6002043; Surgand JS, 2006, PROTEINS, V62, P509, DOI 10.1002/prot.20768; Swaminath G, 2005, J BIOL CHEM, V280, P22165, DOI 10.1074/jbc.M502352200; Taylor MRG, 2007, PHARMACOGENOMICS J, V7, P29, DOI 10.1038/sj.tpj.6500393; Triballeau N, 2005, J MED CHEM, V48, P2534, DOI 10.1021/jm049092j; Varghese JN, 1998, STRUCT FOLD DES, V6, P735, DOI 10.1016/S0969-2126(98)00075-6; Verdonk ML, 1999, J MOL BIOL, V289, P1093, DOI 10.1006/jmbi.1999.2809; von Itzstein M, 2007, NAT REV DRUG DISCOV, V6, P967, DOI 10.1038/nrd2400; Warren GL, 2006, J MED CHEM, V49, P5912, DOI 10.1021/jm050362n; Witten I. H., 2005, DATA MINING PRACTICA; Wolber G, 2008, DRUG DISCOV TODAY, V13, P23, DOI 10.1016/j.drudis.2007.09.007; XIE WL, 1991, P NATL ACAD SCI USA, V88, P2692, DOI 10.1073/pnas.88.7.2692; Zhang Q, 2006, J MED CHEM, V49, P1536, DOI 10.1021/jm050468i; *ACC INC, DISC STUD VERS 2 0; [Anonymous], FLEXX VERS 2 2; *BIOH, MOL SURF PACK VERS 3; *BIOPHARMICS LLC, SURFL VERS 2 11; *CAMBR CRYST DAT C, GOLD VERS 3 2; *CHEM COMP GROUP, MOE VERS 2007 09; *CHEMAXON KFT, JCHEM VERS 3 2 3; *MOL NETW GMBH, COR VERS 3 4; *OPENEYE SCI SOFTW, OECHEM VERS 1 4 2; *OPENEYE SCI SOFTW, FILT VERS 2 0 1; *SCITEGIC INC, PIP PIL VERS 6 1	69	25	26	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596		J CHEM INF MODEL	J. Chem Inf. Model.	JUL	2008	48	7					1396	1410		10.1021/ci800064z		15	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	331HW	WOS:000258004300011	
J	Zhao, H; Kit, CY				Zhao, Hai; Kit, Chunyu			Scaling conditional random fields by one-against-the-other decomposition	JOURNAL OF COMPUTER SCIENCE AND TECHNOLOGY			English	Article						natural language processing; machine learning; conditional random fields; Chinese word segmentation		As a powerful sequence labeling model, conditional random fields (CRFs) have had successful applications in many natural language processing (NLP) tasks. However, the high complexity of CRFs training only allows a very small tag (or label) set, because the training becomes intractable as the tag set enlarges. This paper proposes an improved decomposed training and joint decoding algorithm for CRF learning. Instead of training a single CRF model for all tags, it trains a binary sub-CRF independently for each tag. An optimal tag sequence is then produced by a joint decoding algorithm based on the probabilistic output of all sub-CRFs involved. To test its effectiveness, we apply this approach to tackling Chinese word segmentation (CWS) as a sequence labeling problem. Our evaluation shows that it can reduce the computational cost of this language processing task by 40-50% without any significant performance loss on various large-scale data sets.	[Zhao, Hai; Kit, Chunyu] City Univ Hong Kong, Dept Chinese Translat & Linguist, Kowloon, Hong Kong, Peoples R China	Kit, CY (reprint author), City Univ Hong Kong, Dept Chinese Translat & Linguist, 83 Tat Chee Ave, Kowloon, Hong Kong, Peoples R China.	haizhao@cityu.edu.hk; ctckit@cityu.edu.hk					Abbeel P, 2006, J MACH LEARN RES, V7, P1743; Asahara M., 2005, P 4 SIGHAN WORKSH CH, P134; Chen A., 2005, P 4 SIGHAN WORKSH CH, P138; COHN T, 2005, P 43 ANN M ASS COMP, P10, DOI 10.3115/1219840.1219842; Emerson T., 2005, P 4 SIGHAN WORKSH CH, P123; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Lafferty J., 2001, P 18 INT C MACH LEAR, P282; Low J. K., 2005, P 4 SIGHAN WORKSH CH, P161; McCallum A., 2004, NIPS 2004 WORKSH LEA; Peng F., 2004, P 20 INT C COMP LING, P562, DOI 10.3115/1220355.1220436; PUNYAKANOK V, 2005, P INT JOINT C ART IN, P1124; ROSENFELD B, 2006, P SDM 2006 BETH MAR, P563; Sha F., 2003, P C N AM CHAPT ASS C, P134; Sutton C., 2007, P863, DOI 10.1145/1273496.1273605; Toutanova K., 2003, P HLT NAACL 2003, P252; TSAI RTH, 2006, P 5 SIGHAN WORKSH CH, P108; Tseng H., 2005, P 4 SIGHAN WORKSH CH, P168; VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010; Wallach H., 2002, THESIS U EDINBURGH; Xue Nianwen, 2003, COMPUTATIONAL LINGUI, V8, P29; Zhang R., 2006, P HUM LANG TECHN C N, P193; ZHAO H, 2006, P 5 SIGHAN WORKSH CH, P162; Zhao H, 2006, PACLIC 20: Proceedings of the 20th Pacific Asia Conference on Language, Information and Computation, P87; Zhou GD, 2005, LECT NOTES ARTIF INT, V3651, P530	24	3	3	SCIENCE PRESS	BEIJING	16 DONGHUANGCHENGGEN NORTH ST, BEIJING 100717, PEOPLES R CHINA	1000-9000		J COMPUT SCI TECH-CH	J. Comput. Sci. Technol.	JUL	2008	23	4					612	619		10.1007/s11390-008-9157-4		8	Computer Science, Hardware & Architecture; Computer Science, Software Engineering	Computer Science	328PI	WOS:000257809900010	
J	d'Aspremont, A; Bach, F; El Ghaoui, L				d'Aspremont, Alexandre; Bach, Francis; El Ghaoui, Laurent			Optimal solutions for sparse principal component analysis	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						PCA; subset selection; sparse eigenvalues; sparse recovery; lasso	SELECTION; LASSO; APPROXIMATIONS; ROTATION	Given a sample covariance matrix, we examine the problem of maximizing the variance explained by a linear combination of the input variables while constraining the number of nonzero coefficients in this combination. This is known as sparse principal component analysis and has a wide array of applications in machine learning and engineering. We formulate a new semidefinite relaxation to this problem and derive a greedy algorithm that computes a full set of good solutions for all target numbers of non zero coefficients, with total complexity O(n(3)), where n is the number of variables. We then use the same relaxation to derive sufficient conditions for global optimality of a solution, which can be tested in O ( n3) per pattern. We discuss applications in subset selection and sparse recovery and show on artificial examples and biological data that our algorithm does provide globally optimal solutions in many cases.	[d'Aspremont, Alexandre] Princeton Univ, ORFE, Princeton, NJ 08544 USA; [Bach, Francis] INRIA WILLOW Project Team, CNRS ENS, Ecole Normale Super, Lab Informat,UMR 8548, F-75230 Paris, France; [El Ghaoui, Laurent] Univ Calif Berkeley, Dept EECS, Berkeley, CA 94720 USA	d'Aspremont, A (reprint author), Princeton Univ, ORFE, Princeton, NJ 08544 USA.	ASPREMON@PRINCETON.EDU; FRANCIS.BACH@MINES.ORG; ELGHAOUI@EECS.BERKELEY.EDU					Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon A., 1999, CELL BIOL, V96, P6745; Ben-Tal A, 2002, SIAM J OPTIMIZ, V12, P811, DOI 10.1137/S1052623400374756; Boyd S, 2004, CONVEX OPTIMIZATION; CADIMA J, 1995, J APPL STAT, V22, P203, DOI 10.1080/757584614; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; Couvreur C, 2000, SIAM J MATRIX ANAL A, V21, P797, DOI 10.1137/S0895479898332928; d'Aspremont A., 2007, P 24 INT C MACH LEAR; d'Aspremont A, 2007, SIAM REV, V49, P434, DOI 10.1137/050645506; Donoho DL, 2005, P NATL ACAD SCI USA, V102, P9446, DOI 10.1073/pnas.0502269102; Horn R. A., 1985, MATRIX ANAL; JOLLIFFE IT, 1995, J APPL STAT, V22, P29, DOI 10.1080/757584395; Jolliffe IT, 2003, J COMPUT GRAPH STAT, V12, P531, DOI 10.1198/1061860032148; KAISER HF, 1958, PSYCHOMETRIKA, V23, P187, DOI 10.1007/BF02289233; Kato T, 1966, PERTURBATION THEORY; MEINSHAUSEN N, 2006, LASSO TYPE RECOVERY; MOGHADDAM B., 2006, ADV NEURAL INFORM PR, V18; MOGHADDAM B, 2007, COMP VIS 2007 ICCV 2; MOGHADDAM B, 2006, P ICML; NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406; Neuhaus JO, 1954, BRIT J STATIST PSYCH, V7, P81; Rudin W., 1987, REAL COMPLEX ANAL; Sriperumbudur B. K., 2007, P 24 INT C MACH LEAR, P831, DOI 10.1145/1273496.1273601; Su Y, 2003, BIOINFORMATICS, V19, P1578, DOI 10.1093/bioinformatics/btg179; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Yuan M, 2007, J ROY STAT SOC B, V69, P143, DOI 10.1111/j.1467-9868.2007.00581.x; Zhang ZY, 2002, SIAM J MATRIX ANAL A, V23, P706, DOI 10.1137/S0895479899359631; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430	29	29	29	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	JUL	2008	9						1269	1294				26	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	340LJ	WOS:000258646800001	
J	Bartoli, A				Bartoli, Adrien			Maximizing the predictivity of smooth deformable image warps through cross-validation	JOURNAL OF MATHEMATICAL IMAGING AND VISION			English	Article						image registration; landmarks; warps; cross-validation	REGISTRATION; AUGMENTATION; DEFORMATIONS; SELECTION	Estimating smooth image warps from landmarks is an important problem in computer vision and medical image analysis. The standard paradigm is to find the model parameters by minimizing a compound energy including a data term and a smoother, balanced by a 'smoothing parameter' that is usually fixed by trial and error. We point out that warp estimation is an instance of the general supervised machine learning problem of fitting a flexible model to data, and propose to learn the smoothing parameter while estimating the warp. The leading idea is to depart from the usual paradigm of minimizing the energy to the one of maximizing the predictivity of the warp, i.e. its ability to do well on the entire image, rather than only on the given landmarks. We use cross-validation to measure predictivity, and propose a complete framework to solve for the desired warp. We point out that the well-known non-iterative closed-form for the leave-one-out cross-validation score is actually a good approximation to the true score and show that it extends to the warp estimation problem by replacing the usual vector two-norm by the matrix Frobenius norm. Experimental results on real data show that the procedure selects sensible smoothing parameters, very close to user selected ones.	[Bartoli, Adrien] Univ Copenhagen, DIKU, Copenhagen, Denmark	Bartoli, A (reprint author), Univ Clermont Ferrand, CNRS, LASMEA, Clermont Ferrand, France.	Adrien.Bartoli@gmail.com					ALLEN DM, 1974, TECHNOMETRICS, V16, P125, DOI 10.2307/1267500; Bishop C.M., 1995, NEURAL NETWORKS PATT; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; BRONIELSEN M, 1996, VISUALIZATION BIOMED; BURRAGE K, 1994, SEM ANG MATH JUL; CHRISTENSEN GE, 2001, WORKSH MATH METH BIO; de Bruijne M, 2007, MED IMAGE ANAL, V11, P503, DOI 10.1016/j.media.2007.07.004; DUCHON J, 1976, REV FR AUTOMAT INFOR, V10, P5; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fornefett M, 2001, IMAGE VISION COMPUT, V19, P87, DOI 10.1016/S0262-8856(00)00057-3; GENANT HK, 1993, J BONE MINER RES, V8, P1137; Golub GH, 1997, J COMPUT GRAPH STAT, V6, P1, DOI 10.2307/1390722; Hawkins DM, 2002, COMPUT STAT DATA AN, V40, P253, DOI 10.1016/S0167-9473(02)00034-8; Kanatani K, 1998, INT J COMPUT VISION, V26, P171, DOI 10.1023/A:1007948927139; Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8; MARSLAND S, 2007, IMAGE VISION COMPUTI; MAYBANK S, 1999, BRIT MACH VIS C; Modersitzki J., 2004, NUMERICAL METHODS IM; NIELSEN M, 2004, EUR C COMP VIS; NIELSEN M, 2002, MED IMAGE COMPUTING; Pilet J, 2008, INT J COMPUT VISION, V76, P109, DOI 10.1007/s11263-006-0017-9; Poggio T, 2004, NATURE, V428, P419, DOI 10.1038/nature02341; Rifkin R.M., 2007, MITCSAILTR2007025; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; Szeliski R, 1997, INT J COMPUT VISION, V22, P199, DOI 10.1023/A:1007996332012; TORR PHS, 2002, INT J COMPUT VISION, V50, P27; WAHBA G, 1975, COMMUN STAT, V4, P1; Wahba G., 1990, SPLINES MODELS OBSER	28	11	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-9907		J MATH IMAGING VIS	J. Math. Imaging Vis.	JUL	2008	31	2-3					133	145		10.1007/s10851-007-0062-1		13	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	307TM	WOS:000256341200003	
J	Walkinshaw, N; Bogdanov, K; Holcombe, M; Salahuddin, S				Walkinshaw, Neil; Bogdanov, Kirill; Holcombe, Mike; Salahuddin, Sarah			Improving dynamic software analysis by applying grammar inference principles	JOURNAL OF SOFTWARE MAINTENANCE AND EVOLUTION-RESEARCH AND PRACTICE			English	Article						reverse engineering; dynamic analysis; grammar inference	FINITE-STATE MACHINES; BEHAVIOR; MODELS; IDENTIFICATION; LANGUAGE	Grammar inference is it family of machine learning techniques that aim to infer grammars from a sample of sentences in some (unknown.) language. Dynamic analysis is a family of techniques in the domain of software engineering that attempts to infer rules that govern the behaviour of software systems from it sample of executions. Despite their disparate domains, both fields have broadly similar aims, they try to infer rules that govern the behaviour of some unknown system from a sample of observations. Deriving general rules about program behaviour from dynamic analysis is difficult because it is virtually impossible to identity and supply it complete sample of necessary program executions. The problems that arise with incomplete input samples have been extensively investigated in the grammar inference community. This has resulted in a number of advances that have produced increasingly sophisticated solutions that are more successful at accurately inferring grammars from (potentially) sparse information about the underlying system. This paper investigates the similarities and shows how many of these advances call he applied with similar effect to dynamic analysis problems by a series of small experiments on random state machines. Copyright (C) 2008 John Wiley & Sons, Ltd.	[Walkinshaw, Neil; Bogdanov, Kirill; Holcombe, Mike; Salahuddin, Sarah] Univ Sheffield, Dept Comp Sci, Sheffield S1 4DP, S Yorkshire, England	Walkinshaw, N (reprint author), Univ Sheffield, Dept Comp Sci, 211 Portobello St, Sheffield S1 4DP, S Yorkshire, England.	n.walkinshaw@des.shef.ac.uk					AMMONS G, 2002, MINING SPECIFICATION, P4; ANGLUIN D, 1987, INFORM COMPUT, V75, P87, DOI 10.1016/0890-5401(87)90052-6; ANGLUIN S, 1983, COMPUT SURV, V15, P237; BIERMANN AW, 1972, IEEE T COMPUT, VC 21, P592; Bongard J, 2005, J MACH LEARN RES, V6, P1651; CHOMSKY N, 1956, IRE T INFORM THEOR, V2, P113, DOI 10.1109/TIT.1956.1056813; Cook J. E., 1998, ACM Transactions on Software Engineering and Methodology, V7, DOI 10.1145/287000.287001; Damas C, 2005, IEEE T SOFTWARE ENG, V31, P1056, DOI 10.1109/TSE.2005.138; DELAHIGUERA CD, 1996, ICGI INT C GRAMM INF; DUPONT P, 1996, P INT C GRAMM INF IC; Dupont P, 2008, APPL ARTIF INTELL, V22, P77, DOI 10.1080/08839510701853200; ERNST M, 2003, P INT WORKSH DYN AN; GARCIA P, 2000, P INT C GRAMM INF IC; GOLD EM, 1978, INFORM CONTROL, V37, P302, DOI 10.1016/S0019-9958(78)90562-4; GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5; Hopcroft J., 1979, INTRO AUTOMATA THEOR; HUNGAR N, 2003, INT C COMP AID VER C; KEARNS M, 1994, J ACM, V41, P433; LANG K, 1998, P INT C GRAMM INF IC, V1433, P1; Lang K.J., 1992, COLT, P45; Lee D, 1996, P IEEE, V84, P1090, DOI 10.1109/5.533956; Li KQ, 2006, LECT NOTES COMPUT SC, V4229, P436; Lo D, 2006, SMARTIC BUILDING ACC, P265; LO D, 2006, QUARK EMPIRICAL ASSE, P51; LORENZOLI D, 2006, P INT WORKSH DYN AN; Nerode A., 1958, P AM MATH SOC, V9, P541, DOI 10.2307/2033204; ONCINA J, 1993, IEEE T PATTERN ANAL, V15, P448, DOI 10.1109/34.211465; Oncina J., 1992, PATTERN RECOGN, V1, P49, DOI 10.1142/9789812797902_0004; PAREKH R, 2000, HDB NATURAL LANGUAGE, P727; REISS S, 2001, ENCODING PROGRAM EXE, P221; Rijsbergen C.J.V., 1979, INFORM RETRIEVAL; Trakhtenbrot B.A., 1973, FINITE AUTOMATA BEHA; WALKINSHAW N, 2007, REVERSE ENG STATE MA; Walkinshaw N, 2008, SOFTW TEST VERIF REL, V18, P99, DOI 10.1002/stvr.380	34	1	1	JOHN WILEY & SONS LTD	CHICHESTER	THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND	1532-060X		J SOFTW MAINT EVOL-R	J. Softw. Maint. Evol.-Res. Pract.	JUL-AUG	2008	20	4					269	290		10.1002/smr.373		22	Computer Science, Software Engineering	Computer Science	341RG	WOS:000258731800004	
J	Kendrick, P; Cox, TJ; Li, FF; Zhang, YG; Chambers, JA				Kendrick, Paul; Cox, Trevor J.; Li, Francis F.; Zhang, Yonggang; Chambers, Jonathon A.			Monaural room acoustic parameters from music and speech	JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA			English	Article							BLIND ESTIMATION	This paper compares two methods for extracting room acoustic parameters from reverberated speech and music. An approach which uses statistical machine learning, previously developed for speech, is extended to work with music. For speech, reverberation time estimations are within a perceptual difference limen of the true value. For music, virtually all early decay time estimations are within a difference limen of the true value. The estimation accuracy is not good enough in other cases due to differences between the simulated data set used to develop the empirical model and real rooms. The second method carries out a maximum likelihood estimation on decay phases at the end of notes or speech utterances. This paper extends the method to estimate parameters relating to the balance of early and late energies in the impulse response. For reverberation time and speech, the method provides estimations which are within the perceptual difference limen of the true value. For other parameters such as clarity, the estimations are not sufficiently accurate due to the natural reverberance of the excitation signals. Speech is a better test signal than music because of the greater periods of silence in the signal, although music is needed for low frequency measurement. (c) 2008 Acoustical Society of America.	[Kendrick, Paul; Cox, Trevor J.; Li, Francis F.] Univ Salford, Acoust Res Ctr, Salford M5 4WT, Lancs, England; [Zhang, Yonggang; Chambers, Jonathon A.] Univ Loughborough, Dept Elect & Elect Engn, Adv Signal Proc Grp, Loughborough LE11 3TU, Leics, England	Kendrick, P (reprint author), Univ Salford, Acoust Res Ctr, Salford M5 4WT, Lancs, England.						Aldrich J, 1997, STAT SCI, V12, P162; COX TJ, 1993, ACUSTICA, V79, P27; CREMER L, 1982, PRINCIPLES APPL ROOM, V1; HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697; HOUTGAST T, 1972, P IEEE AFCRL SPEECH, P392; Kendrick P, 2007, ACTA ACUST UNITED AC, V93, P760; KENDRICK P, 2007, P 19 ICA MADR; KUTTUFF H, 2000, ROOM ACOUSTICS; LAHTI T, 2001, P AUD ENG SOC 110 CO, P5356; LI FF, 2003, P IEEE ICASSP 2003, V2, P757; Li FF, 2003, J ACOUST SOC AM, V113, P1999, DOI 10.1121/1.1558373; Mahalanobis P., 1936, P NAT I SCI INDIA, V2, P49; Ratnam R, 2003, J ACOUST SOC AM, V114, P2877, DOI 10.1121/1.1616578; SERAPHIM HP, 1958, ACUSTICA, V8, P280; *EN ISO, 2000, 3382 EN ISO; 1995, DENON ANECHOIC ORCHE; 1992, MUSIC ARCHIMEDES CD	17	0	0	ACOUSTICAL SOC AMER AMER INST PHYSICS	MELVILLE	STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA	0001-4966		J ACOUST SOC AM	J. Acoust. Soc. Am.	JUL	2008	124	1					278	287		10.1121/1.2931960		10	Acoustics; Audiology & Speech-Language Pathology	Acoustics; Audiology & Speech-Language Pathology	327ZW	WOS:000257768000028	
J	Skowronski, MD; Fenton, MB				Skowronski, Mark D.; Fenton, M. Brock			Model-based automated detection of echolocation calls using the link detector	JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA			English	Article							SPEECH RECOGNITION; BAT; IDENTIFICATION; CONSEQUENCES	The link detector combines a model-based spectral peak tracker with an echo filter to detect echolocation calls of bats. By processing calls in the spectrogram domain, the links detector separates calls that overlap in time, including call harmonics and echoes. The links detector was validated by using an artificial recording environment, including synthetic calls, atmospheric absorption, and echoes, which provided control of signal-to-noise ratio and an absolute ground truth. Maximum hit rate (2% false positive rate) for the links detector was 87% compared to 1.5% for a spectral peak detector. The difference in performance was due to the ability of the links detector to filter out echoes. Detection range varied across species from 13 to more than 20 m due to call bandwidth and frequency range. Global features of calls detected by the links detector were compared to those of synthetic calls. The error in all estimates increased as the range increased, and estimates of minimum frequency and frequency of most energy were more accurate compared to maximum frequency. The links detector combines local and global features to automatically detect calls within the machine learning paradigm and detects overlapping calls and call harmonics in a unified framework. (c) 2008 Acoustical Society of America.	[Skowronski, Mark D.; Fenton, M. Brock] Univ Western Ontario, Dept Biol, London, ON N6A 5B7, Canada	Skowronski, MD (reprint author), Univ Western Ontario, Dept Biol, London, ON N6A 5B7, Canada.	mskowro2@uwo.ca; bfenton@uwo.ca					BASS HE, 1990, J ACOUST SOC AM, V88, P2019, DOI 10.1121/1.400176; Bayefsky-Anand S, 2008, J ZOOL, V275, P115, DOI 10.1111/j.1469-7998.2008.00418.x; BETHEL RE, 1990, IEEE T AERO ELEC SYS, V26, P700, DOI 10.1109/7.102705; Dalenback BIL, 1996, J ACOUST SOC AM, V100, P899; Deller John R., 1993, DISCRETE TIME PROCES; Jennings NV, 2004, ACTA CHIROPTEROL, V6, P75; MASTERS WM, 1991, J ACOUST SOC AM, V89, P1402, DOI 10.1121/1.400660; Norberg U.M., 1987, P43; Obrist MK, 2004, MAMMALIA, V68, P307, DOI 10.1515/mamm.2004.030; Oppenheim AV, 1989, DISCRETE TIME SIGNAL; Parsons S, 2000, J EXP BIOL, V203, P2641; PETTERSSON L, 2004, BAT ECHOLOCATION RES, P130; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Skowronski MD, 2008, J ACOUST SOC AM, V123, P2643, DOI 10.1121/1.2896752; Skowronski MD, 2006, J ACOUST SOC AM, V119, P1817, DOI 10.1121/1.2166948; Zhuang Q, 2006, PHYS REV LETT, V97, DOI 10.1103/PhysRevLett.97.218701	16	11	11	ACOUSTICAL SOC AMER AMER INST PHYSICS	MELVILLE	STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA	0001-4966		J ACOUST SOC AM	J. Acoust. Soc. Am.	JUL	2008	124	1					328	336		10.1121/1.2924122		9	Acoustics; Audiology & Speech-Language Pathology	Acoustics; Audiology & Speech-Language Pathology	327ZW	WOS:000257768000032	
J	Dunagan, J; Vempala, S				Dunagan, John; Vempala, Santosh			A simple polynomial-time rescaling algorithm for solving linear programs	MATHEMATICAL PROGRAMMING			English	Article								The perceptron algorithm, developed mainly in the machine learning literature, is a simple greedy method for finding a feasible solution to a linear program (alternatively, for learning a threshold function). In spite of its exponential worst-case complexity, it is often quite useful, in part due to its noise-tolerance and also its overall simplicity. In this paper, we show that a randomized version of the perceptron algorithm along with periodic rescaling runs in polynomial-time. The resulting algorithm for linear programming has an elementary description and analysis.	[Vempala, Santosh] MIT, Dept Math, Atlanta, GA 30332 USA; [Dunagan, John] Microsoft Res, Redmond, WA 98052 USA	Vempala, S (reprint author), Coll Comp, 801 Atlantic Dr, Atlanta, GA 30332 USA.	vempala@math.mit.edu					AGMON S, 1954, CAN J MATH, V6, P382, DOI 10.4153/CJM-1954-037-2; Bertsimas D, 2004, J ACM, V51, P540, DOI 10.1145/1008731.1008733; Blum A, 2002, SIAM PROC S, P905; Blum A, 1998, ALGORITHMICA, V22, P35, DOI 10.1007/PL00013833; BYLANDER T, 1994, P WORKSH COMPT LEARN; Chvatal V., 1983, LINEAR PROGRAMMING; Cohen E., 1997, Proceedings. 38th Annual Symposium on Foundations of Computer Science (Cat. No.97CB36150), DOI 10.1109/SFCS.1997.646140; CUCKER F, 2001, MATH PROGRAM A, V91, P163; DUNAGAN J, 2002, SIAM C OPT; Freund RM, 1999, MATH PROGRAM, V86, P225, DOI 10.1007/s101070050088; FREUND RM, 2000, HIGH PERFORMANCE OPT, P441; FROSTER J, 2001, 16 ANN IEEE C COMP; GOFFIN JL, 1971, THESIS U CALIFORNIA; GOFFIN JL, 1980, MATH OPER RES, V5, P388, DOI 10.1287/moor.5.3.388; GROTCHEL L, 1988, GEOMETRIC ALGORITHMS; KARMARKAR N, 1984, COMBINATORICA, V4, P373, DOI 10.1007/BF02579150; KHACHIIAN LG, 1979, DOKL AKAD NAUK SSSR+, V244, P1093; Minsky M., 1969, PERCEPTRONS INTRO CO; RENEGAR J, 1995, SIAM J OPTIMIZ, V5, P506, DOI 10.1137/0805026; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; SCHRIIVER A, 1998, THEORY LINAR INTEGER; SERVEDIO RA, 2001, 14 ANN C COMP LEARN, P473; Servedio RA, 2002, SIAM J COMPUT, V31, P1358, DOI 10.1137/S0097539798340928; Shor N. Z., 1977, Cybernetics, V13; SHOR NZ, 1970, CYBERNETICS, V1, P7; Vaidya PM, 1996, MATH PROGRAM, V73, P291, DOI 10.1007/BF02592216; Yudin D., 1976, MATEKON, V13, P3	27	4	4	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0025-5610		MATH PROGRAM	Math. Program.	JUL	2008	114	1					101	114		10.1007/s10107-007-0095-7		14	Computer Science, Software Engineering; Operations Research & Management Science; Mathematics, Applied	Computer Science; Operations Research & Management Science; Mathematics	277HO	WOS:000254203500004	
J	Darnell, SJ; LeGault, L; Mitchell, JC				Darnell, Steven J.; LeGault, Laura; Mitchell, Julie C.			KFC Server: interactive forecasting of protein interaction hot spots	NUCLEIC ACIDS RESEARCH			English	Article							BINDING-ENERGY; SMALL-MOLECULE; INTERFACES; RESIDUES; DATABASE; MUTATIONS; COMPLEXES; RECEPTOR; CONSURF	The KFC Server is a web-based implementation of the KFC (Knowledge-based FADE and Contacts) modela machine learning approach for the prediction of binding hot spots, or the subset of residues that account for most of a protein interfaces; binding free energy. The server facilitates the automated analysis of a user submitted proteinprotein or proteinDNA interface and the visualization of its hot spot predictions. For each residue in the interface, the KFC Server characterizes its local structural environment, compares that environment to the environments of experimentally determined hot spots and predicts if the interface residue is a hot spot. After the computational analysis, the user can visualize the results using an interactive job viewer able to quickly highlight predicted hot spots and surrounding structural features within the protein structure. The KFC Server is accessible at http://kfc.mitchell-lab.org.	[Darnell, Steven J.; Mitchell, Julie C.] Univ Wisconsin, Dept Biochem, Madison, WI 53706 USA; [LeGault, Laura] Univ Wisconsin, Dept Comp Sci, Madison, WI 53706 USA; [Mitchell, Julie C.] Univ Wisconsin, Dept Math, Madison, WI 53706 USA	Mitchell, JC (reprint author), Univ Wisconsin, Dept Biochem, Madison, WI 53706 USA.	jcmitchell@wisc.edu					Arkin MR, 2004, NAT REV DRUG DISCOV, V3, P301, DOI 10.1038/nrd1343; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Bogan AA, 1998, J MOL BIOL, V280, P1, DOI 10.1006/jmbi.1998.1843; Chakrabarti P, 2002, PROTEINS, V47, P334, DOI 10.1002/prot.10085; CLACKSON T, 1995, SCIENCE, V267, P383, DOI 10.1126/science.7529940; Darnell SJ, 2007, PROTEINS, V68, P813, DOI 10.1002/prot.21474; del Sol A, 2005, PROTEINS, V58, P672, DOI 10.1002/prot.20348; Dolinsky TJ, 2004, NUCLEIC ACIDS RES, V32, pW665, DOI 10.1093/nar/gkh381; Fischer TB, 2003, BIOINFORMATICS, V19, P1453, DOI 10.1093/bioinformatics/btg163; Gao Y, 2004, J MOL MODEL, V10, P44, DOI 10.1007/s00894-003-0168-3; Glaser F, 2003, BIOINFORMATICS, V19, P163, DOI 10.1093/bioinformatics/19.1.163; Guerois R, 2002, J MOL BIOL, V320, P369, DOI 10.1016/S0022-2836(02)00442-4; Guney E, 2008, NUCLEIC ACIDS RES, V36, pD662, DOI 10.1093/nar/gkm813; Jones S, 1996, P NATL ACAD SCI USA, V93, P13, DOI 10.1073/pnas.93.1.13; Kortemme T, 2002, P NATL ACAD SCI USA, V99, P14116, DOI 10.1073/pnas.202485799; Kortemme T, 2004, SCI STKE, V2004, P12, DOI DOI 10.1126/STKE.2192004P12; Landau M, 2005, NUCLEIC ACIDS RES, V33, pW299, DOI 10.1093/nar/gki370; Li Lei, 2006, Bioinformation, V1, P121; Li X, 2004, J MOL BIOL, V344, P781, DOI 10.1016/j.jmb.2004.09.051; Massova I, 1999, J AM CHEM SOC, V121, P8133, DOI 10.1021/ja990935j; Mitchell JC, 2001, J MOL GRAPH MODEL, V19, P325, DOI 10.1016/S1093-3263(00)00079-6; Moreira IS, 2007, PROTEINS, V68, P803, DOI 10.1002/prot.21396; Sheinerman FB, 2000, CURR OPIN STRUC BIOL, V10, P153, DOI 10.1016/S0959-440X(00)00065-8; Thanos CD, 2006, P NATL ACAD SCI USA, V103, P15422, DOI 10.1073/pnas.0607058103; Thorn KS, 2001, BIOINFORMATICS, V17, P284, DOI 10.1093/bioinformatics/17.3.284; VRIEND G, 1990, J MOL GRAPHICS, V8, P52, DOI 10.1016/0263-7855(90)80070-V; Xu D, 1997, PROTEIN ENG, V10, P999, DOI 10.1093/protein/10.9.999	27	25	28	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0305-1048		NUCLEIC ACIDS RES	Nucleic Acids Res.	JUL	2008	36			S			W265	W269		10.1093/nar/gkn346		5	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	333GZ	WOS:000258142300050	
J	Kim, S; Shin, SY; Lee, IH; Kim, SJ; Sriram, R; Zhang, BT				Kim, Sun; Shin, Soo-Yong; Lee, In-Hee; Kim, Soo-Jin; Sriram, Ram; Zhang, Byoung-Tak			PIE: an online prediction system for protein-protein interactions from text	NUCLEIC ACIDS RESEARCH			English	Article							INFORMATION-RETRIEVAL; PUBMED ABSTRACTS; NETWORK	Protein-protein interaction (PPI) extraction has been an important research topic in bio-text mining area, since the PPI information is critical for understanding biological processes. However, there are very few open systems available on the Web and most of the systems focus on keyword searching based on predefined PPIs. PIE ( Protein Interaction information Extraction system) is a configurable Web service to extract PPIs from literature, including user-provided papers as well as PubMed articles. After providing abstracts or papers, the prediction results are displayed in an easily readable form with essential, yet compact features. The PIE interface supports more features such as PDF file extraction, PubMed search tool and network communication, which are useful for biologists and bio-system developers. The PIE system utilizes natural language processing techniques and machine learning methodologies to predict PPI sentences, which results in high precision performance for Web users. PIE is freely available at http://bi.snu.ac.kr/pie/.	[Kim, Sun; Lee, In-Hee; Zhang, Byoung-Tak] Seoul Natl Univ, Biointelligence Lab, Sch Comp Sci & Engn, Seoul 151744, South Korea; [Shin, Soo-Yong; Sriram, Ram] NIST, Mfg Syst Integrat Div, Gaithersburg, MD 20899 USA; [Zhang, Byoung-Tak] Seoul Natl Univ, Ctr Bioinformat Technol, Grad Program Bioinformat, Seoul 151742, South Korea	Zhang, BT (reprint author), Seoul Natl Univ, Biointelligence Lab, Sch Comp Sci & Engn, Seoul 151744, South Korea.	btzhang@bi.snu.ac.kr					BRILL E, 1992, P 3 C APPL NAT LANG, P151; Cases I, 2007, NUCLEIC ACIDS RES, V35, pW16, DOI 10.1093/nar/gkm280; Chen H, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-147; Cohen AM, 2005, BRIEF BIOINFORM, V6, P57, DOI 10.1093/bib/6.1.57; COLLINS M, 1999, THESIS U PENSSYLVANI; COLLINS M, 2001, P NEUR INF PROC SYST, P625; Fan Wei, 1999, P 16 INT C MACH LEAR, P97; HAKENBERG J, 2006, P INT S SEM MIN BIOM, P89; Hoffmann R, 2004, NAT GENET, V36, P664, DOI 10.1038/ng0704-664; Jang H, 2006, BIOINFORMATICS, V22, pE220, DOI 10.1093/bioinformatics/btl203; Jensen LJ, 2006, NAT REV GENET, V7, P119, DOI 10.1038/nrg1768; Kim J, 2003, BIOINFORMATICS S1, V19, P180, DOI DOI 10.1093/BIOINFORMATICS/BTG1023; Kim Yu-Hwan, 2000, P 23 ANN INT ACM SIG, P168, DOI 10.1145/345508.345572; Krallinger M, 2005, GENOME BIOL, V6, DOI 10.1186/gb-2005-6-7-224; Krallinger M., 2007, P 2 BIOCREATIVE CHAL, P41; PLAKE C, 2005, P ACM S APPL COMP, P195, DOI 10.1145/1066677.1066722; Sanchez-Graillet O, 2007, BIOINFORMATICS, V23, P424; Shin SY, 2007, P 2 BIOCREATIVE WORK, P187; Xiao J., 2005, P S SEM MIN BIOM, P51	19	19	20	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0305-1048		NUCLEIC ACIDS RES	Nucleic Acids Res.	JUL	2008	36			S			W411	W415		10.1093/nar/gkn281		5	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	333GZ	WOS:000258142300076	
J	Lobley, AE; Nugent, T; Orengo, CA; Jones, DT				Lobley, A. E.; Nugent, T.; Orengo, C. A.; Jones, D. T.			FFPred: an integrated feature-based function prediction server for vertebrate proteomes	NUCLEIC ACIDS RESEARCH			English	Article							PROTEIN-FUNCTION; GENE ONTOLOGY; UNIPROT	One of the challenges of the post-genomic era is to provide accurate function annotations for large volumes of data resulting from genome sequencing projects. Most function prediction servers utilize methods that transfer existing database annotations between orthologous sequences. In contrast, there are few methods that are independent of homology and can annotate distant and orphan protein sequences. The FFPred server adopts a machine-learning approach to perform function prediction in protein feature space using feature characteristics predicted from amino acid sequence. The features are scanned against a library of support vector machines representing over 300 Gene Ontology (GO) classes and probabilistic confidence scores returned for each annotation term. The GO term library has been modelled on human protein annotations; however, benchmark performance testing showed robust performance across higher eukaryotes. FFPred offers important advantages over traditional function prediction servers in its ability to annotate distant homologues and orphan protein sequences, and achieves greater coverage and classification accuracy than other feature-based prediction servers. A user may upload an amino acid and receive annotation predictions via email. Feature information is provided as easy to interpret graphics displayed on the sequence of interest, allowing for back-interpretation of the associations between features and function classes.	[Lobley, A. E.; Nugent, T.; Jones, D. T.] UCL, Dept Comp Sci, London WC1E 6BT, England; [Orengo, C. A.; Jones, D. T.] UCL, Div Biosci, Inst Struct & Mol Biol, London WC1E 6BT, England	Jones, DT (reprint author), UCL, Dept Comp Sci, Gower St, London WC1E 6BT, England.	d.jones@cs.ucl.ac.uk					Apweiler R, 2004, NUCLEIC ACIDS RES, V32, pD115, DOI 10.1093/nar/gkh131; ASBURNER M, 2000, NAT GENET, V25, P25; Camon E, 2004, NUCLEIC ACIDS RES, V32, pD262, DOI 10.1093/nar/gkh021; CHURCHILL MEA, 1991, TRENDS BIOCHEM SCI, V16, P92, DOI 10.1016/0968-0004(91)90040-3; DOBSON PD, 2004, PREDICTING ENZYME CL, V345, P187; Fernandez M, 2008, PROTEINS, V70, P167, DOI 10.1002/prot.21524; HT Lin, 2003, NOTE PLATTS PROBABIL; Jensen LJ, 2003, BIOINFORMATICS, V19, P635, DOI 10.1093/bioinformatics/btg036; Lobley A, 2007, PLOS COMPUT BIOL, V3, P1567, DOI 10.1371/journal.pcbi.0030162; MIKA S, 2007, PLOS COMPUT BIOL, V2, pE79; Ofran Y, 2005, DRUG DISCOV TODAY, V10, P1475, DOI 10.1016/S1359-6446(05)03621-4; PIROOZNIA M, 2006, BMC BIOINFORMATICS, V12, pS25; Rost B, 2002, J MOL BIOL, V318, P595, DOI 10.1016/S0022-2836(02)00016-5; SATHIYA KS, 2003, NEURAL COMPUT, V15, P1667; Tian WD, 2003, J MOL BIOL, V333, P863, DOI 10.1016/j.jmb.2003.08.057	15	14	14	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0305-1048		NUCLEIC ACIDS RES	Nucleic Acids Res.	JUL	2008	36			S			W297	W302		10.1093/nar/gkn193		6	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	333GZ	WOS:000258142300056	
J	Zamani, A; Solomatine, D; Azimian, A; Heemink, A				Zamani, Ahmadreza; Solomatine, Dimitri; Azimian, Ahmadreza; Heemink, Arnold			Learning from data for wind-wave forecasting	OCEAN ENGINEERING			English	Article						ANN; data-driven models; instance-based learning; wind-wave	NEURAL-NETWORKS; SEA-SURFACE; PREDICTION; WATER; PARAMETERS; MODELS	Along with existing numerical process models describing the wind-wave interaction, the relatively recent development in the area of machine learning make the so-called data-driven models more and more popular. This paper presents a number of data-driven models for wind-wave process at the Caspian Sea. The problem associated with these models is to forecast significant wave heights for several hours ahead using buoy measurements. Models are based on artificial neural network (ANN) and instance-based learning (IBL) To capture the wind-wave relationship at measurement sites, these models use the existing past time data describing the phenomenon in question. Three feed-forward ANN models have been built for time horizon of 1, 3 and 6 h with different inputs. The relevant inputs are selected by analyzing the average mutual information (AMI). The inputs consist of priori knowledge of wind and significant wave height. The other six models are based on IBL method for the same forecast horizons. Weighted k-nearest neighbors (k-NN) and locally weighted regression (LWR) with Gaussian kernel were used. In IBL-based models, forecast is made directly by combining instances from the training data that are close (in the input space) to the new incoming input vector. These methods are applied to two sets of data at the Caspian Sea. Experiments show that the ANNs yield slightly better agreement with the measured data than IBL. ANNs can also predict extreme wave conditions better than the other existing methods. (c) 2008 Elsevier Ltd. All rights reserved.	[Zamani, Ahmadreza; Azimian, Ahmadreza] Isfahan Univ Technol, Dept Mech Engn, Esfahan 84156, Iran; [Solomatine, Dimitri] Int Inst Infrastruct Hydraul & Environm Engn, NL-2601 DA Delft, Netherlands; [Heemink, Arnold] Delft Univ Technol, Delft Inst Appl Math, NL-2600 AA Delft, Netherlands	Zamani, A (reprint author), Isfahan Univ Technol, Dept Mech Engn, Esfahan 84156, Iran.	arzamani@cc.iut.ac.ir; d.solomatine@unesco-ihe.org; azimian@cc.iut.ac.ir; A.W.Heemink@ewi.tudelft.nl					Abebe AJ, 2004, J COMPUT CIVIL ENG, V18, P373, DOI 10.1061/(ASCE)0887-3801(2004)18:4(373); Agrawal JD, 2002, MAR STRUCT, V15, P57, DOI 10.1016/S0951-8339(01)00014-4; AHA D, 1991, MACH LEARN, V6, P36; BHATTACHARYA B, 2003, P 30 IAHR C THESS GR; Booij N, 1999, J GEOPHYS RES-OCEANS, V104, P7649, DOI 10.1029/98JC02622; Bowden GJ, 2005, J HYDROL, V301, P75, DOI 10.1016/j.jhydrol.2004.06.021; Deo MC, 2001, OCEAN ENG, V28, P889, DOI 10.1016/S0029-8018(00)00027-5; Deo MC, 1999, OCEAN ENG, V26, P191; FEDROV VV, 1993, NONPARAMETRIC STAT, V2, P335; Haykin S., 1999, NEURAL NETWORKS COMP; Jain P., 2006, Ships and Offshore Structures, V1, DOI 10.1533/saos.2004.0005; Kazeminezhad MH, 2005, OCEAN ENG, V32, P1709, DOI 10.1016/j.oceaneng.2005.02.001; Makarynskyy O, 2004, OCEAN ENG, V31, P709, DOI 10.1016/j.oceaneng.2003.05.003; Mandal S, 2006, OCEAN ENG, V33, P1401, DOI 10.1016/j.oceaneng.2005.08.007; MYNETT M, 1999, J HYDROINFORM, V12, P83; of Physical Oceanography Journal, 1988, J PHYS OCEANOGR, V18, P1775, DOI DOI 10.1175/1520-0485(1988)018<1775:TWMTGO.2.0.CO;2; Ozger M, 2007, OCEAN ENG, V34, P460, DOI 10.1016/j.oceaneng.2006.03.003; PUCA S, 2001, P INT C OFFSH POL EN, P17; Scott D. W., 1992, MULTIVARIABLE DENSIT; SOLOMATINE D, 2005, DATA DRIVEN MODELING; Solomatine D. P., 2007, HYDROLOGICAL PROCESS, V22, P275; Solomatine DP, 2008, J HYDROINFORM, V10, P3, DOI 10.2166/hydro.2008.015; SOLOMATINE DP, 2001, P 29 IAHR C BEIJ CHI; Tolman H. L., 1999, 166 NOAANWSNCEPOMB; Tolman HL, 2005, OCEAN MODEL, V8, P253, DOI 10.1016/j.ocemod.2003.12.008; Vaziri M, 1997, J WATERW PORT C-ASCE, V123, P158, DOI 10.1061/(ASCE)0733-950X(1997)123:4(158); WU J, 1982, J GEOPHYS RES-OC ATM, V87, P9704, DOI 10.1029/JC087iC12p09704; ZAMANI A, 2004, P 9 FLUID DYN C TEHR, P48; *US ARM, 2003, COAST ENG MAN MET WA, pCH2	29	18	18	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0029-8018		OCEAN ENG	Ocean Eng.	JUL	2008	35	10					953	962		10.1016/j.oceaneng.2008.03.007		10	Engineering, Marine; Engineering, Civil; Engineering, Ocean; Oceanography	Engineering; Oceanography	322GI	WOS:000257362800001	
J	Li, DF; Hu, WC; Xiong, W; Yang, JB				Li, Ding-Fang; Hu, Wen-Chao; Xiong, Wei; Yang, Jin-Bo			Fuzzy relevance vector machine for learning from unbalanced data and noise	PATTERN RECOGNITION LETTERS			English	Article						relevance vector machine; unbalanced data; noise; fuzzy membership; Bayesian inference		Handing unbalanced data and noise are two important issues in the field of machine learning. This paper proposed a complete framework of fuzzy relevance vector machine by weighting the punishment terms of error in Bayesian inference process of relevance vector machine (RVM). Above problems can be learned within this framework with different kinds of fuzzy membership functions. Experiments on both synthetic data and real world data demonstrate that fuzzy relevance vector machine (FRVM) is effective in dealing with unbalanced data and reducing the effects of noises or outliers. (c) 2008 Published by Elsevier B.V.	[Li, Ding-Fang; Hu, Wen-Chao; Xiong, Wei; Yang, Jin-Bo] Wuhan Univ, Sch Math & Stat, Wuhan 430072, Peoples R China	Li, DF (reprint author), Wuhan Univ, Sch Math & Stat, Wuhan 430072, Peoples R China.	dfli@whu.edu.cn; wchu80@sina.com; wxiongwhu@163.com; yangjb1225@163.com					Bishop CM, 2000, P 16 C UNC ART INT; Cristianini N, 2002, ADV NEUR IN, V14, P367; GUO HM, 2001, LECT NOTES COMPUT SC, V2070, P259; Lin CF, 2002, IEEE T NEURAL NETWOR, V13, P464, DOI 10.1109/72.991432; Lin CF, 2004, PATTERN RECOGN LETT, V25, P1647, DOI 10.1016/j.patrec.2004.06.009; LIN JF, 2005, SUPPORT VECTOR MACHI, P233; Majumder SK, 2005, LASER SURG MED, V36, P323, DOI 10.1002/lsm.20160; Murphey YL, 2004, APPL INTELL, V21, P117, DOI 10.1023/B:APIN.0000033632.42843.17; Tao Q, 2005, IEEE T NEURAL NETWOR, V16, P1561, DOI 10.1109/tnn.2005.857955; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; TIPPING ME, 2001, ADV NEURAL INFORM PR, V12	11	6	7	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	JUL 1	2008	29	9					1175	1181		10.1016/j.patrec.2008.01.009		7	Computer Science, Artificial Intelligence	Computer Science	316PF	WOS:000256961500001	
J	Pedrycz, W; Hirota, K				Pedrycz, Witold; Hirota, Kaoru			A consensus-driven fuzzy clustering	PATTERN RECOGNITION LETTERS			English	Article						fuzzy clustering with consensus; proximity matrix; knowledge-based clustering; local and global quality assessment of information granules	P-FCM; PROXIMITY	In this study, we are concerned with a concept of consensus-driven fuzzy clustering whose objective is to reconcile a structure developed for patterns in some data set with the structural findings already available for other related data sets (where these data sets are reflective of the same phenomenon which has led to the generation of the original patterns). The results of fuzzy clustering are provided in the form of prototypes and fuzzy partition matrices. Given this form of representation of granular results (clusters), we develop a suitable communication scheme using which consensus could be established in an effective manner. Here, we consider proximity matrices induced by the corresponding partition matrices. An overall optimization scheme is presented in detail along with a way of forming a pertinent criterion governing an intensity of collaboration between the data driven- and knowledge oriented hints guiding the process of consensus formation. Several illustrative numeric examples, using both synthetic data and the data coming from publicly available machine learning repositories are also included. (c) 2008 Elsevier B.V. All rights reserved.	[Pedrycz, Witold] Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6R 2G7, Canada; [Pedrycz, Witold] Polish Acad Sci, Syst Res Inst, PL-01447 Warsaw, Poland; [Hirota, Kaoru] Tokyo Inst Technol, Dept Computat Intelligence & Intelligent Informat, Interdisciplinary Grad Sch Sci & Engn, Midori Ku, Tokyo 2268502, Japan	Pedrycz, W (reprint author), Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6R 2G7, Canada.	pedrycz@ee.ualberta.ca					Bezdek J. C., 1978, Fuzzy Sets and Systems, V1, DOI 10.1016/0165-0114(78)90012-X; DIMITRIADOU E, 1999, P INT S ADV INT DAT, P291; Fred A. L. N., 2002, Proceedings 16th International Conference on Pattern Recognition, DOI 10.1109/ICPR.2002.1047450; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Johnson E., 1999, LECT NOTES COMPUTER, V1759, P221; Loia V, 2003, INT J APPROX REASON, V34, P121, DOI 10.1016/j.ijar.2003.07.004; Monti S, 2003, MACH LEARN, V52, P91, DOI 10.1023/A:1023949509487; Pedrycz W, 2004, FUZZY SET SYST, V148, P21, DOI 10.1016/j.fss.2004.03.004; PEDRYCZ W, 2002, SOFT COMPUTING AGENT, P109; Pedrycz W, 2002, PATTERN RECOGN LETT, V23, P1675, DOI 10.1016/S0167-8655(02)00130-7; Pedrycz W, 2005, KNOWLEDGE-BASED CLUSTERING: FROM DATA TO INFORMATION GRANULES, P1, DOI 10.1002/0471708607; Samatova NF, 2002, DISTRIB PARALLEL DAT, V11, P157; Strehl A., 2003, J MACHINE LEARNING R, V3, P583, DOI DOI 10.1162/153244303321897735; Zadeh LA, 2005, INFORM SCIENCES, V172, P1, DOI 10.1016/j.ins.2005.01.017	15	11	11	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	JUL 1	2008	29	9					1333	1343		10.1016/j.patrec.2008.02.015		11	Computer Science, Artificial Intelligence	Computer Science	316PF	WOS:000256961500019	
J	Pham, DT; Afify, AA				Pham, D. T.; Afify, A. A.			A new minimum description length based pruning technique for rule induction algorithms	PROCEEDINGS OF THE INSTITUTION OF MECHANICAL ENGINEERS PART C-JOURNAL OF MECHANICAL ENGINEERING SCIENCE			English	Article						data mining; knowledge discovery; machine learning; inductive learning; rule induction; pruning; noise handling; minimum description length principle	DECISION TREES; PRINCIPLE	When learning is based on noisy data, the induced rule sets have a tendency to overfit the training data, and this degrades the performance of the resulting classifier. Consequently, the ability to tolerate noise is a necessity for robust, practical learning methods. Pruning is a common way of handling noisy data. This paper presents a new pruning technique built on the sound foundation of the minimum description length principle. The proposed pruning technique has the advantage that it does not require the set of examples employed for pruning to be distinct from the set used to build the rule set. The new technique is designed to improve the performance of the RULe Extraction System (RULES) family of inductive learning algorithms, but can be used for pruning rule sets created by other learning algorithms. It was tested in RULES-6, the latest algorithm in the family, and showed significant performance improvements.	[Pham, D. T.; Afify, A. A.] Cardiff Univ, Mfg Engn Ctr, Intelligent Syst Lab, Cardiff CF24 3AA, S Glam, Wales	Pham, DT (reprint author), Cardiff Univ, Mfg Engn Ctr, Intelligent Syst Lab, Queens Bldg,Newport Rd, Cardiff CF24 3AA, S Glam, Wales.	phamdt@cardiff.ac.uk	Pham, Duc/H-1516-2011		'Innovation in Manufacturing, 'Innovative Technologies for Effective Enterprises'; 'Supporting Innovative Product Engineering and Responsive Manufacturing' (SUPERMAN); 'Innovative Production Machines and Systems' (I*PROMS)	This work was carried out within the ERDF (Objective One) projects 'Innovation in Manufacturing, 'Innovative Technologies for Effective Enterprises' and 'Supporting Innovative Product Engineering and Responsive Manufacturing' (SUPERMAN) and within the project 'Innovative Production Machines and Systems' (I*PROMS).	Barron A, 1998, IEEE T INFORM THEORY, V44, P2743, DOI 10.1109/18.720554; Blake C. L., 1998, UCI REPOSITORY MACHI; Braha D., 2001, DATA MINING DESIGN M; BRESLOW A, 1996, KNOWL ENG REV, V12, P1; BRUNK CA, 1991, P 8 INT WORKSH MACH, P389; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Cohen W, 1993, P 13 INT JOINT C ART, P988; Devijver P. A., 1982, PATTERN RECOGNITION; Efron B., 1993, INTRO BOOTSTRAP; Elomaa T, 2001, J ARTIF INTELL RES, V15, P163; Esposito F, 1997, IEEE T PATTERN ANAL, V19, P476, DOI 10.1109/34.589207; FRANK E, 1999, REDUCED ERROR PRUNIN; FRANK E, 2000, THESIS U WAIKATO HAM; FURNKRANZ J, 1994, P 11 EUR C ART INT A, P453; Furnkranz J, 1997, MACH LEARN, V27, P139, DOI 10.1023/A:1007329424533; FURNKRANZ J, 1994, THESIS TU WIEN; Furnkranz J., 1994, P 11 INT C MACH LEAR, P70; GEORGEFF MP, 1984, P 6 EUR C ART INT EC, P473; Grunwald P, 2000, J MATH PSYCHOL, V44, P133, DOI 10.1006/jmps.1999.1280; KRICHEVSKY RE, 1981, IEEE T INFORM THEORY, V27, P199, DOI 10.1109/TIT.1981.1056331; Mehta M., 1995, P 1 INT C KNOWL DISC, P216; Mingers J., 1989, Machine Learning, V4, DOI 10.1023/A:1022604100933; MONOSTORI L, 2002, P 15 TRIENN WORLD C, P119; PAGALLO G, 1990, MACH LEARN, V5, P71, DOI 10.1023/A:1022611825350; PFAHRINGER B, 1995, THESIS TU WIEN; PFAHRINGER B, 1997, P EUR C MACH LEARN P, P199; Pham DT, 2003, P I MECH ENG C-J MEC, V217, P1273, DOI 10.1243/095440603322769929; PHAM DT, 1995, J SYST ENG, V5, P115; PHAM DT, 1993, ARTIF INTELL, V8, P227; PHAM DT, 2005, J ENG MAN, V219, P395; Pham DT, 1997, PATTERN RECOGN, V30, P1137, DOI 10.1016/S0031-3203(96)00148-3; PHAM DT, 1995, EXPERT SYST APPL, V8, P59, DOI 10.1016/S0957-4174(99)80008-6; Pham DT, 2005, P I MECH ENG C-J MEC, V219, P1119, DOI 10.1243/095440605X31931; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; Quinlan J. R., 1994, P 11 INT C MACH LEAR, P233; Quinlan J. R., 1995, P 12 INT C MACH LEAR, P464; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1989, INFORM COMPUT, V80, P227; RISSANEN J, 1986, ANN STAT, V14, P1080, DOI 10.1214/aos/1176350051; ROBNIKSIKONJA M, 1998, P 13 EUR C ART INT, P455; TIRRI H, 2001, P NEUR INF PROC SYST	41	1	1	PROFESSIONAL ENGINEERING PUBLISHING LTD	WESTMINISTER	1 BIRDCAGE WALK, WESTMINISTER SW1H 9JJ, ENGLAND	0954-4062		P I MECH ENG C-J MEC	Proc. Inst. Mech. Eng. Part C-J. Eng. Mech. Eng. Sci.	JUL	2008	222	7					1339	1352		10.1243/09544062JMES842		14	Engineering, Mechanical	Engineering	341VH	WOS:000258742800024	
J	Dong, QW; Wang, XL; Lin, L				Dong, Qiwen; Wang, Xiaolong; Lin, Lei			Prediction of protein local structures and folding fragments based on building-block library	PROTEINS-STRUCTURE FUNCTION AND BIOINFORMATICS			English	Article						the local structure prediction; the folding fragment; the building-block library; the bi-gram model; the building-block lattice	HIDDEN MARKOV MODEL; SEQUENCE-STRUCTURE CORRELATIONS; ALPHABET; SERVER; EVOLUTIONARY; INFORMATION; BACKBONE; ROSETTA; SEARCH; UNITS	In recent years, protein structure prediction using local structure information has made great progress. In this study, a novel and effective method is developed to predict the local structure and the folding fragments proteins. First, the proteins with known structures are split into fragments. Second, these fragments, represented by dihedrals, are clustered to produce the building blocks (BBs). Third, an efficient machine learning method is used to predict the local structures of proteins from sequence profiles. Finally, a bigram model, trained by an iterated algorithm, is introduced to simulate the interactions these BBs. For test proteins, the building-block lattice is constructed, which contains all the folding fragments of the proteins. The local structures and the optimal fragments are then obtained by the dynamic programming algorithm. The experiment is performed on a subset of the PDB database with sequence identity less than 25%. The results show that the performance of the method is better than the method that uses only sequence information. When multiple paths are returned, the average classification accuracy of local structures is 72.27% and the average prediction accuracy of local structures is 67.72%, which is a significant improvement in comparison with previous studies. The method can predict not only the local structures but also the folding fragments of proteins. This work is helpful for the ab initio protein structure prediction and especially, the understanding of the folding process of proteins.	[Dong, Qiwen; Wang, Xiaolong; Lin, Lei] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150006, Peoples R China	Dong, QW (reprint author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150006, Peoples R China.	qwdong@insun.hit.edu.cn					ALTSCHUL SF, 1997, NUCLEIC ACIDS RES, V25, P3402; ANSUEI Y, 2003, BIOINFORMATICS, V19, P1267; Baldwin RL, 1999, TRENDS BIOCHEM SCI, V24, P26, DOI 10.1016/S0968-0004(98)01346-2; Baldwin RL, 1999, TRENDS BIOCHEM SCI, V24, P77, DOI 10.1016/S0968-0004(98)01345-0; Benros C, 2006, PROTEINS, V62, P865, DOI 10.1002/prot.20815; Bystroff C, 1998, J MOL BIOL, V281, P565, DOI 10.1006/jmbi.1998.1943; Bystroff C, 2000, J MOL BIOL, V301, P173, DOI 10.1006/jmbi.2000.3837; Bystroff Christopher, 2002, Bioinformatics, V18 Suppl 1, pS54; Camproux AC, 1999, PROTEIN ENG, V12, P1063, DOI 10.1093/protein/12.12.1063; Camproux AC, 2004, J MOL BIOL, V339, P591, DOI 10.1016/j.jmb.2004.04.005; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Chen Ching-Tai, 2006, Journal of Bioinformatics and Computational Biology, V4, P1287, DOI 10.1142/S0219720006002466; de Brevern AG, 2000, PROTEINS, V41, P271, DOI 10.1002/1097-0134(20001115)41:3<271::AID-PROT10>3.0.CO;2-Z; Dong QW, 2007, COMPUT BIOL MED, V37, P1610, DOI 10.1016/j.compbiomed.2007.03.002; DOR O, 2006, PROTEINS, V66, P838; Etchebest C, 2005, PROTEINS, V59, P810, DOI 10.1002/prot.20458; Gelly JC, 2006, BIOINFORMATICS, V22, P129, DOI 10.1093/bioinformatics/bti773; Gelly JC, 2006, NUCLEIC ACIDS RES, V34, pW75, DOI 10.1093/nar/gkl292; Guyon F, 2004, NUCLEIC ACIDS RES, V32, pW545, DOI 10.1093/nar/gkh467; Haspel N, 2003, PROTEIN SCI, V12, P1177, DOI 10.1110/ps.0232903; Haspel N, 2003, PROTEINS, V51, P203, DOI 10.1002/prot.10294; HENIKOFF S, 1994, J MOL BIOL, V243, P574, DOI 10.1016/0022-2836(94)90032-9; Holm L, 1998, BIOINFORMATICS, V14, P423, DOI 10.1093/bioinformatics/14.5.423; Holmes JB, 2004, PROTEIN SCI, V13, P1636, DOI 10.1110/ps.03494504; Hou Y, 2003, BIOINFORMATICS, V19, P2294, DOI 10.1093/bioinformatics/btg317; Hou YN, 2004, PROTEINS, V57, P518, DOI 10.1002/prot.20221; Hunter CG, 2003, PROTEINS, V50, P572, DOI 10.1002/prot.10310; Karchin R, 2004, PROTEINS, V55, P508, DOI 10.1002/prot.2008; Kato H, 2007, J MOL BIOL, V365, P881, DOI 10.1016/j.jmb.2006.10.048; Kolodny R, 2002, J MOL BIOL, V323, P297, DOI 10.1016/S0022-2836(02)00942-7; Kouranov A, 2006, NUCLEIC ACIDS RES, V34, pD302, DOI 10.1093/nar/gkj120; Lee J, 2005, BIOPHYS CHEM, V115, P209, DOI 10.1016/j.bpc.2004.12.046; Lesk AM, 1997, PROTEINS, P151; LESK AM, 1981, P NATL ACAD SCI-BIOL, V78, P4304, DOI 10.1073/pnas.78.7.4304; Llinas M, 1999, NAT STRUCT BIOL, V6, P1072; MacKerell J. A., 1998, J PHYS CHEM B, V102, P3586; MANNING CD, 1999, FDN STATISTICAL NATU; Martin J, 2006, BMC STRUCT BIOL, V6, DOI 10.1186/1472-6807-6-25; Pei JM, 2004, PROTEINS, V56, P782, DOI 10.1002/prot.20158; Sander O, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-14; Simons KT, 1999, PROTEINS, P171; Tang T, 2005, PACIFIC SYMPOSIUM ON BIOCOMPUTING 2005, P370; Tsai CJ, 2001, IBM J RES DEV, V45, P513; Tyagi M, 2006, PROTEINS, V65, P32, DOI 10.1002/prot.21087; Tyagi M, 2006, NUCLEIC ACIDS RES, V34, pW119, DOI 10.1093/nar/gkl199; Vapnik VN, 1998, STAT LEARNING THEORY; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Wolf YI, 2000, J MOL BIOL, V299, P897, DOI 10.1006/jmbi.2000.3786; Yang JM, 2006, NUCLEIC ACIDS RES, V34, P3646, DOI 10.1093/nar/gkl395; Yarov-Yarovoy V, 2006, PROTEINS, V62, P1010, DOI 10.1002/prot.20817	50	3	5	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0887-3585		PROTEINS	Proteins	JUL	2008	72	1					353	366		10.1002/prot.21931		14	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	311OP	WOS:000256609800031	
J	Wang, T; Si, HZ; Chen, PP; Zhang, KJ; Yao, XJ				Wang, Tao; Si, Hongzong; Chen, Pingping; Zhang, Kejun; Yao, Xiaojun			QSAR models for the dermal penetration of polycyclic aromatic hydrocarbons based on Gene Expression Programming	QSAR & COMBINATORIAL SCIENCE			English	Article						derma; Heuristic method; Gene Expression Programming; polycyclic aromatic hydrocarbons; quantitative structure-activity relationship	PREDICTION; QSPR	Gene Expression Programming (GEP) is a novel machine learning technique. The GEP is used to build nonlinear quantitative structure activity relationship model for the prediction of the Percent of Applied Dose Dermally Absorbed (PADA) over 24 h for polycyclic aromatic hydrocarbons. This model is based on descriptors which are calculated from the molecular structure. Three descriptors are selected from the descriptors pool by Heuristic Method (HM) to build a multivariable linear model. The GEP method produced a nonlinear quantitative model with a correlation coefficient and a mean error of 0.92 and 4.70 for the training set, 0.91 and 7.65 for the test set, respectively. It is shown that the GEP predicted results are in good agreement with experimental ones.	[Wang, Tao] Hosp Qingdao Univ, Qingdao 266071, Shandong, Peoples R China; [Si, Hongzong] Qingdao Univ, Inst Computat Sci & Engn, Lab New Fibrous Mat & Modern Text, Growing Base,State Key Lab, Qingdao 266071, Shandong, Peoples R China; [Chen, Pingping] Southeast Univ, Sch Engn & Comp Sci, Nanjing 211189, Jiangsu, Peoples R China; [Zhang, Kejun] Zhejiang Univ, Dept Comp Sci & Technol, Hangzhou 310027, Zhejiang, Peoples R China; [Yao, Xiaojun] Lanzhou Univ, Dept Chem, Lanzhou 730000, Gansu, Peoples R China	Wang, T (reprint author), Hosp Qingdao Univ, Qingdao 266071, Shandong, Peoples R China.	syr2008@126.com; sihz03@126.com					Barbato F, 1998, FARMACO, V53, P655, DOI 10.1016/S0014-827X(98)00082-2; Baykasoglu A, 2004, CEMENT CONCRETE RES, V34, P2083, DOI 10.1016/j.cemconres.2004.03.028; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Devillers J, 2000, POLYCYCL AROMAT COMP, V18, P231, DOI 10.1080/10406630008028148; DIPPLE A, 1985, POLYCYCLIC HYDROCARB; Ferreira C., 2001, Complex Systems, V13; Ferreira C., 2002, ADV COMPLEX SYST, V5, P389, DOI 10.1142/S0219525902000626; Ferreira C., 2006, GENE EXPRESSION PROG; Gallegos A, 2001, J COMPUT AID MOL DES, V15, P67, DOI 10.1023/A:1011150003086; Gute BD, 1999, SAR QSAR ENVIRON RES, V10, P1, DOI 10.1080/10629369908039162; Katritzky A. R., 1994, COMPREHENSIVE DESCRI; Katritzky AR, 2001, J CHEM INF COMP SCI, V41, P1521, DOI 10.1021/ci010043e; KATRITZKY AR, 1995, CHEM SOC REV, V24, P279, DOI 10.1039/cs9952400279; Liu HX, 2004, J CHEM INF COMP SCI, V44, P161, DOI 10.1021/ci034173u; ROY TA, 1998, SAR QSAR ENVIRON RES, V10, P1; SANNIGRAHI AB, 1992, ADV QUANTUM CHEM, V23, P301, DOI 10.1016/S0065-3276(08)60032-5; Si HZ, 2007, ANAL CHIM ACTA, V591, P255, DOI 10.1016/j.aca.2007.03.070; Si HZ, 2007, QSAR COMB SCI, V26, P41, DOI 10.1002/qsar.200530187; Si HZ, 2006, BIOORGAN MED CHEM, V14, P4834, DOI 10.1016/j.bmc.2006.03.019; STEWART JPP, 1989, MOPAC 6 0 QUNATUM CH; Terzi O, 2005, J APPL SCI, V5, P508; WILSCHUT A, 1995, CHEMOSPHERE, V30, P1275, DOI 10.1016/0045-6535(95)00023-2; Xue CX, 2004, J CHROMATOGR A, V1048, P233, DOI 10.1016/j.chroma.2004.07.043; [Anonymous], 1994, HYPERCHEM 4 0	24	1	1	WILEY-V C H VERLAG GMBH	WEINHEIM	PO BOX 10 11 61, D-69451 WEINHEIM, GERMANY	1611-020X		QSAR COMB SCI	QSAR Comb. Sci.	JUL	2008	27	7					913	921		10.1002/qsar.200710153		9	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Interdisciplinary Applications; Pharmacology & Pharmacy	Pharmacology & Pharmacy; Chemistry; Computer Science	332KT	WOS:000258082600010	
J	Li, LL; Zhang, YX; Zhao, YH				Li LiLi; Zhang YanXia; Zhao YongHeng			k-Nearest Neighbors for automated classification of celestial objects	SCIENCE IN CHINA SERIES G-PHYSICS MECHANICS & ASTRONOMY			English	Article						k-Nearest Neighbors; data analysis; classification; astronomical catalogues	ALGORITHMS	The nearest neighbors (NNs) classifiers, especially the k-Nearest Neighbors (kNNs) algorithm, are among the simplest and yet most efficient classification rules and widely used in practice. It is a nonparametric method of pattern recognition. In this paper, k-Nearest Neighbors, one of the most commonly used machine learning methods, work in automatic classification of multi-wavelength astronomical objects. Through the experiment, we conclude that the running speed of the kNN classier is rather fast and the classification accuracy is up to 97.73%. As a result, it is efficient and applicable to discriminate active objects from stars and normal galaxies with this method. The classifiers trained by the kNN method can be used to solve the automated classification problem faced by astronomy and the virtual observatory (VO).	[Li LiLi; Zhang YanXia; Zhao YongHeng] Chinese Acad Sci, Natl Astron Observ, Beijing 100012, Peoples R China; [Li LiLi] Hebei Normal Univ, Dept Phys, Shijiazhuang 050016, Peoples R China; [Li LiLi] Weishanlu Middle Sch, Tianjin 300222, Peoples R China	Li, LL (reprint author), Chinese Acad Sci, Natl Astron Observ, Beijing 100012, Peoples R China.	my8821@163.com					Adams A., 1994, VISTAS ASTRON, V38, P273, DOI 10.1016/0083-6656(94)90037-X; BailerJones CAL, 1997, PUBL ASTRON SOC PAC, V109, P932, DOI 10.1086/133962; Dasarathy BV, 1991, NEAREST NEIGHBOR NOR; DEVAUCOULEURS G, 1991, 3 REFERENCE CATLOGUE; Devroye L., 1996, PROBABILISTIC THEORY; Duda R., 1973, PATTERN RECOGNITION; FIX E, 1989, INT STAT REV, V57, P238, DOI 10.2307/1403797; GULATI RK, 1994, VISTAS ASTRON, V38, P293, DOI 10.1016/0083-6656(94)90040-X; HUMPHREYS RM, 2001, AM ASTRON SOC, V33, P1322; McGlynn TA, 2004, ASTROPHYS J, V616, P1284, DOI 10.1086/424955; ODEWAHN SC, 1994, VISTAS ASTRON, V38, P281, DOI 10.1016/0083-6656(94)90038-8; Qu M, 2003, SOL PHYS, V217, P157, DOI 10.1023/A:1027388729489; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Ramirez JF, 2001, EXP ASTRON, V12, P163, DOI 10.1023/A:1021899116161; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; SODRE L, 1994, VISTAS ASTRON, V38, P287, DOI 10.1016/0083-6656(94)90039-6; STORRIELOMBARDI MC, 1992, MNRAS, V259, P8; VERONCETTY MP, 2000, 190 ESO; Zhang Y, 2004, ASTRON ASTROPHYS, V422, P1113, DOI 10.1051/0004-6361:20040141; Zhang YX, 2003, PUBL ASTRON SOC PAC, V115, P1006, DOI 10.1086/376847	20	5	5	SCIENCE PRESS	BEIJING	16 DONGHUANGCHENGGEN NORTH ST, BEIJING 100717, PEOPLES R CHINA	1672-1799		SCI CHINA SER G	Sci. China Ser. G-Phys. Mech. Astron.	JUL	2008	51	7					916	922		10.1007/s11433-008-0088-4		7	Physics, Multidisciplinary	Physics	316QW	WOS:000256965800021	
J	Mohaghegh, SD				Mohaghegh, Sh. D.			Essential Components of an Integrated Data Mining Tool for the Oil and Gas Industry with an Example Application in the DJ Basin	SCIENTIA IRANICA			English	Article								Data mining seems to be the new buzz word. During the past several years many industries other than the oil and gas industry have realized the potential benefits of da5ta mining and have established sophisticated operations in order to implement this exciting technology in their respective organizations. Data mining is not new. It has been around for many years. What is new about its current implementation is the incorporation of machine learning techniques. The oil and gas industry has become familiar with machine learning techniques since the early 1990s. Neural networks, genetic optimization and fuzzy logic have been used in numerous applications, from well log interpretations to hydraulic fracturing optimization. Therefore, the new interest in data mining in this industry is not surprising. The industry is at its peak state for benefiting from what data mining has to offer, thanks to an abundance of digital data. A word of caution is in order, which is the main motivation behind writing this paper. As with many other new tools and technologies, the term "Data Mining" can be, and is currently being, misused on several occasions. In this paper, an attempt has been made to answer questions such as; what is Data Mining? How can it be accomplished? What are the essential components of an integrated data mining process and what would be the benefits of such a process? In addition to answering questions such as those mentioned above, this paper will provide a road map (a set of guidelines) for a successful data mining project. Finally, the paper concludes by applying the presented guidelines to a hydraulic fracturing data set in the DJ basin of the United States Rockies for a data mining study.	W Virginia Univ, Dept Petr & Nat Gas Engn, Morgantown, WV 26506 USA	Mohaghegh, SD (reprint author), W Virginia Univ, Dept Petr & Nat Gas Engn, 347 MR Bldg,POB 6070, Morgantown, WV 26506 USA.	sha-hab.Mohaghegh@mail.wvu.edu					BAKER RO, 1996, SPE DOE IMPR OIL REC; Berry M. J. A., 2000, MASTERING DATA MININ; Berthold M. R, 2003, INTELLIGENT DATA ANA; Breiman L, 1984, CLASSIFICATION REGRE; Etemoglu CO, 2003, IEEE T SIGNAL PROCES, V51, P1625, DOI 10.1109/TSP.2003.810279; FRAWLEY W, 1992, KNOWLEDGE DISCOVERY, P213; Hastie T, 2001, ELEMENTS STAT LEARNI; Jensen J. L., 2000, STAT PETROLEUM ENG G; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; Kass G. V., 1980, APPL STATIST, V29, P119, DOI DOI 10.2307/2986296; KUNCHEVA LI, 2000, FUZZY CLASSIFIER DES; LIN Y, 1994, P 3 IEEE INT C FUZZ; Mohaghegh S., 2000, P SPE GAS TECHN S CA; MOHAGHEGH S, 2001, P SPE E REG C EXH OC; MOHAGHEGH S, 2002, P SPE ANN  C EXH SEP; MOHAGHEGH SD, 2004, P SPE ANN C EXH SEPT; MOHAGHEGH SD, 2005, J PETROL SCI ENG, P239; POPA A, 2003, P SPE W REG C EXH MA; PRANG T, 1998, SIMILARITY CLUSTERIN; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Tidwell VC, 2000, SPE RESERV EVAL ENG, V3, P283; Westphal C., 1998, DATA MINING SOLUTION; 2000, J PETROLEUM TECH NOV, P82; 2003, PC AI MAGAZINE, V17, P23; 2000, J PETROLEUM TECH SEP, P64; 2000, J PETROLEUM TECH OCT, P40	26	0	0	SHARIF UNIV TECH	TEHRAN IR	OFF SCIENTIA IRANICA, AZADI AVE, PO BOX  11365-8639, TEHRAN IR, 00000, IRAN	1026-3098		SCI IRAN	Sci. Iran.	JUL-AUG	2008	15	4					469	479				11	Engineering, Multidisciplinary	Engineering	401KY	WOS:000262940800010	
J	Lai, DR; Lu, HT				Lai, Darong; Lu, Hongtao			Identification of community structure in complex networks using affinity propagation clustering method	MODERN PHYSICS LETTERS B			English	Article						complex network; community identification; clustering; affinity propagation; similarity		Identifying communities in complex networks has recently attracted considerable attention in different fields. The goal of community identification is to cluster vertices of a network into groups, which is the same as clustering in machine learning and data mining domains. A recent proposed clustering method called affinity propagation shows high performance in clustering data sets into groups, and it does not require that the number of clusters be pre-specified. In this paper, based on a new method for calculating similarity between pairs of vertices and a transforming method for a given similarity from likelihood to log-domain, we apply that affinity propagation clustering method to identify communities in complex networks. Extensive simulation results demonstrate that affinity propagation clustering algorithm is very effective for identifying community structures in both computer-generated and real-world network data.	[Lai, Darong; Lu, Hongtao] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200030, Peoples R China	Lai, DR (reprint author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200030, Peoples R China.	lionel-ldr@sjtu.edu.cn; lu-ht@cs.sjtu.edu.cn					Albert R, 2002, REV MOD PHYS, V74, P47, DOI 10.1103/RevModPhys.74.47; Brandes U., 2006, ARXIVPHYSICS0608255; Danon L, 2005, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2005/09/P09008; Duch J, 2005, PHYS REV E, V72, DOI [10.1103/PhysRevE.72.027104, 10.1103/PhysRecE.72.027104]; Fortunato S, 2007, P NATL ACAD SCI USA, V104, P36, DOI 10.1073/pnas.0605965104; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799; HAN MK, 2000, DATA MINING CONCEPTS; Leicht EA, 2006, PHYS REV E, V73, DOI [10.1103/PhysRevE.73.026120, 10.1103/PhysRevB.73.026120]; Newman MEJ, 2004, EUR PHYS J B, V38, P321, DOI 10.1140/epjb/e2004-00124-y; Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026113; Newman MEJ, 2003, SIAM REV, V45, P167, DOI 10.1137/S003614450342480; Radicchi F, 2004, P NATL ACAD SCI USA, V101, P2658, DOI 10.1073/pnas.0400054101; Wang XT, 2007, PHYSICA A, V384, P667, DOI 10.1016/j.physa.2007.05.013; ZACHARY WW, 1977, J ANTHROPOL RES, V33, P452; Zhang SH, 2007, PHYSICA A, V374, P483, DOI 10.1016/j.physa.2006.07.023	16	3	4	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0217-9849		MOD PHYS LETT B	Mod. Phys. Lett. B	JUN 30	2008	22	16					1547	1566		10.1142/S0217984908016285		20	Physics, Applied; Physics, Condensed Matter; Physics, Mathematical	Physics	326VE	WOS:000257686300003	
J	Murray, RJ; Lewis, FI; Miller, MD; Brown, AJL				Murray, Robert J.; Lewis, Fraser I.; Miller, Michael D.; Brown, Andrew J. Leigh			Genetic basis of variation in tenofovir drug susceptibility in HIV-1	AIDS			English	Article						antiretroviral therapy; antiviral drug resistance; classification trees; decision trees; HIV-1; machine learning; nucleoside reverse transcriptase inhibitors; reverse transcriptase; tenofovir; thymidine analog mutations	IMMUNODEFICIENCY-VIRUS TYPE-1; ANTIRETROVIRAL-EXPERIENCED PATIENTS; REVERSE-TRANSCRIPTASE MUTATIONS; DISOPROXIL FUMARATE; IN-VITRO; RESISTANCE; PROTEASE; GENOTYPE; STRAINS; PHENOTYPE	Objective: To develop an improved model for the genetic basis of reduced susceptibility to tenofovir in vitro. Methods: A dataset of 532 HIV-1 subtype B reverse transcriptase genotypes for which matched phenotypic Susceptibility data were available was assembled, both as a continuous (transformed) dataset and a categorical dataset generated by imposing a cut-off on the basis of earlier studies of in-vivo response of 1.4-fold. Models were generated using stepwise regression, decision tree and random forest approaches on both the continuous and categorical data. Models were compared by mean squared error (continuous models), or by misclassification rates by nested crossvalidation. Results: From the continuous dataset, stepwise linear regression, regression tree and regression forest methods yielded models with MSE of 0.46, 0.48 and 0.42 respectively. Amino acids 215, 65, 41, 67, 184 and 151 in HIV-1 reverse transcriptase were identified in all three models and amino acid 210 in two. The categorical data yielded logistic regression, classification tree and forest models with misclassification rates of 26, 24 and 23%, respectively. Amino acids 215, 65 and 67 appeared in all; 41, 184, 210 and 151 were also included in the classification forest model. Conclusion: The random forests approach has yielded a substantial improvement in the available models to describe the genetic basis of reduced susceptibility to tenofovir in vitro. The most important sites in these models are amino acid sites 215, 65, 41, 67,184, 151 and 210 in HIV-1 reverse transcriptase. (c) 2008 Wolters Kluwer Health vertical bar Lippincott Williams & Wilkins.	[Murray, Robert J.; Lewis, Fraser I.; Brown, Andrew J. Leigh] Univ Edinburgh, Ashworth Labs, Inst Evolutionary Biol, Sch Biol Sci, Edinburgh EH9 3JT, Midlothian, Scotland; [Miller, Michael D.] Gilead Sci Inc, Foster City, CA 94404 USA; [Lewis, Fraser I.] SAC, Vet Epidemiol Res Unit, Inverness IV2 4JZ, Scotland	Brown, AJL (reprint author), Univ Edinburgh, Ashworth Labs, Inst Evolutionary Biol, Sch Biol Sci, W Mains Rd, Edinburgh EH9 3JT, Midlothian, Scotland.	A.Leigh-Brown@ed.ac.uk	Leigh Brown, Andrew/F-3802-2010; Lewis, Fraser/A-3635-2011	Lewis, Fraser/0000-0003-1145-8271			Arion D, 1998, BIOCHEMISTRY-US, V37, P15908, DOI 10.1021/bi981200e; BEERENWINKEL N, 2007, GENO2PHENO GENOTYPIC; Beerenwinkel N, 2005, BIOINFORMATICS, V21, P3943, DOI 10.1093/bioinformatics/bti654; Beerenwinkel N, 2002, P NATL ACAD SCI USA, V99, P8271, DOI 10.1073/pnas.112177799; BOX GEP, 1964, J ROY STAT SOC B, V26, P211; Boyer PL, 2001, J VIROL, V75, P4832, DOI 10.1128/JVI.75.10.4832-4842.2001; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1984, CLASSIFICATION REGRE; Brown AJL, 2004, J VIROL, V78, P2242, DOI 10.1128/JVI.78.5.2242-2246.2004; DiRienzo AG, 2003, STAT MED, V22, P2785, DOI 10.1002/sim.1516; Frankel FA, 2007, AIDS, V21, P665, DOI 10.1097/QAD.0b013e3280187505; Gonzales MJ, 2003, AIDS, V17, P791, DOI 10.1097/01.aids.0000050860.71999.23; Harrigan PR, 2000, J INFECT DIS, V181, P912, DOI 10.1086/315317; Hertogs K, 2000, ANTIMICROB AGENTS CH, V44, P568, DOI 10.1128/AAC.44.3.568-573.2000; Huang HF, 1998, SCIENCE, V282, P1669, DOI 10.1126/science.282.5394.1669; Iversen AKN, 1996, J VIROL, V70, P1086; Johnson Victoria A, 2006, Top HIV Med, V14, P125; KELLAM P, 1992, P NATL ACAD SCI USA, V89, P1934, DOI 10.1073/pnas.89.5.1934; Larder BA, 1999, NAT STRUCT BIOL, V6, P103, DOI 10.1038/5787; Lasko TA, 2005, J BIOMED INFORM, V38, P404, DOI 10.1016/j.jbi.2005.02.008; Margot NA, 2002, AIDS, V16, P1227, DOI 10.1097/00002030-200206140-00004; Masquelier B, 2004, ANTIVIR THER, V9, P315; MENDOZA CD, 2007, AIDS RES HUM RETROV, V23, P879; Miller MD, 2001, NUCLEOS NUCLEOT NUCL, V20, P1025, DOI 10.1081/NCN-100002483; Miller MD, 1999, J INFECT DIS, V179, P92, DOI 10.1086/314560; Miller MD, 2004, J INFECT DIS, V189, P837, DOI 10.1086/381784; Miller MD, 2004, AIDS REV, V6, P22; Parikh UM, 2006, J VIROL, V80, P4971, DOI 10.1128/JVI.80.10.4971-4977.2006; Petropoulos CJ, 2000, ANTIMICROB AGENTS CH, V44, P920, DOI 10.1128/AAC.44.4.920-928.2000; Pond SLK, 2005, BIOINFORMATICS, V21, P676, DOI 10.1093/bioinformatics/bti079; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Rabinowitz M, 2006, BIOINFORMATICS, V22, P541, DOI 10.1093/bioinformatics/btk011; Rhee SY, 2004, ANTIMICROB AGENTS CH, V48, P3122, DOI 10.1128/AAC.48.8.3122-3126.2004; Rhee SY, 2006, P NATL ACAD SCI USA, V103, P17355, DOI 10.1073/pnas.0607274103; Ross L, 2005, AIDS RES HUM RETROV, V21, P933, DOI 10.1089/aid.2005.21.933; ROYSTON JP, 1982, APPL STAT-J ROY ST C, V31, P115, DOI 10.2307/2347973; Schooley RT, 2002, AIDS, V16, P1257, DOI 10.1097/00002030-200206140-00008; Sevin AD, 2000, J INFECT DIS, V182, P59, DOI 10.1086/315673; Shafer RW, 2000, NUCLEIC ACIDS RES, V28, P346, DOI 10.1093/nar/28.1.346; Shafer RW, 1996, J INFECT DIS, V174, P448; SHAFER RW, 2007, HIV DRUG RESISTANCE; Squires K, 2003, ANN INTERN MED, V139, P313; Srinivas RV, 1998, ANTIMICROB AGENTS CH, V42, P1484; Varma S, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-91; VERCAUTEREN J, 2004, REGA GENOTYPIC RESIS; Wainberg MA, 2001, ANTIVIR THER, V6, P11; Wainberg MA, 1999, ANTIVIR THER, V4, P87; Wang DC, 2003, J INFECT DIS, V188, P653, DOI 10.1086/377453; Wang K, 2004, ANTIVIR THER, V9, P343; Whitcomb JM, 2003, J INFECT DIS, V188, P992, DOI 10.1086/378281; Winters MA, 2001, ANTIMICROB AGENTS CH, V45, P2276, DOI 10.1128/AAC.45.8.2276-2279.2001; Wolf K, 2003, ANTIMICROB AGENTS CH, V47, P3478, DOI 10.1128/AAC.47.11.3478-3484.2003; Zhang J, 2005, JAIDS-J ACQ IMM DEF, V38, P439, DOI 10.1097/01.qai.0000147526.64863.53; *AG NAT RECH SIDA, 2007, ANRS AC11 GEN INT GU	54	3	3	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	530 WALNUT ST, PHILADELPHIA, PA 19106-3621 USA	0269-9370		AIDS	Aids	JUN 19	2008	22	10					1113	1123		10.1097/QAD.0b013e32830184a1		11	Immunology; Infectious Diseases; Virology	Immunology; Infectious Diseases; Virology	321VP	WOS:000257334900002	
J	Rhee, J; Im, J; Carbone, GJ; Jensen, JR				Rhee, Jinyoung; Im, Jungho; Carbone, Gregory J.; Jensen, John R.			Delineation of climate regions using in-situ and remotely-sensed data for the Carolinas	REMOTE SENSING OF ENVIRONMENT			English	Article						climate regions; remote sensing; MODIS; TRMM; decision trees; clustering	CORRELATION IMAGE-ANALYSIS; CLUSTER-ANALYSIS; PRECIPITATION DATA; CLASSIFICATION; TEMPERATURE; STATIONS; AMERICA; ZONES; MODEL	Climatologically homogeneous regions in the Carolinas were delineated using a multi-step approach integrating in-situ and remotely-sensed data. We adopted a consensus clustering technique that obtains climate regions for precipitation and temperature separately. Both average linkage hierarchical and k-means non-hierarchical clustering methods were used to create weather station clusters. Using the resulting precipitation and temperature clusters as training data, we performed a machine-learning decision tree classification of remotely-sensed data (i.e., MODIS and TRMM) to map five precipitation classes and seven temperature classes for the Carolinas. These data were intersected to produce 17 consensus clusters for the Carolinas, and 16 climate regions when summarized by counties. The resultant climate regions showed rational climate regionalization reflecting controls on Carolina climate including topography, latitude, storm tracks, and proximity to the Atlantic Ocean. The use of remotely-sensed data effectively helped the delineation between weather station clusters and even detected consensus clusters that were not identified by intersecting weather station clusters grouped using only in-situ data. We compared the regions with the 15 existing National Climatic Data Center climate divisions using within- and between-cluster standard deviations for both in-situ and remotely-sensed data. Climate regions could improve the existing climate divisions in delineating climatologically homogeneous regions and in separating heterogeneous regions. (C) 2008 Elsevier Inc. All rights reserved.	[Rhee, Jinyoung; Carbone, Gregory J.; Jensen, John R.] Univ S Carolina, Dept Geog, Columbia, SC 29208 USA; [Im, Jungho] SUNY Coll Environm Sci & Forestry, Dept Environm Resources & Forest Engn, Syracuse, NY USA	Rhee, J (reprint author), Univ S Carolina, Dept Geog, Columbia, SC 29208 USA.	jyrhee@gmail.com					BRIGGS RD, 1992, CAN J FOREST RES, V22, P801, DOI 10.1139/x92-109; Bunkers MJ, 1996, J CLIMATE, V9, P130, DOI 10.1175/1520-0442(1996)009<0130:DOCRIT>2.0.CO;2; Carbone GJ, 2008, B AM METEOROL SOC, V89, P20, DOI 10.1175/BAMS-89-1-20; DeGaetano AT, 1996, J CLIMATE, V9, P1765, DOI 10.1175/1520-0442(1996)009<1765:DOMCZI>2.0.CO;2; DeGaetano AT, 2001, INT J CLIMATOL, V21, P791, DOI 10.1002/joc.645; Fovell RG, 1997, J CLIMATE, V10, P1405, DOI 10.1175/1520-0442(1997)010<1405:CCOUST>2.0.CO;2; FOVELL RG, 1993, J CLIMATE, V6, P2103, DOI 10.1175/1520-0442(1993)006<2103:CZOTCU>2.0.CO;2; GONG XF, 1995, J CLIMATE, V8, P897, DOI 10.1175/1520-0442(1995)008<0897:OTAOCA>2.0.CO;2; Guttman NB, 1996, B AM METEOROL SOC, V77, P293, DOI 10.1175/1520-0477(1996)077<0293:AHPOUC>2.0.CO;2; Hodgson ME, 2003, PHOTOGRAMM ENG REM S, V69, P973; IM J, 2006, THESIS U S CAROLINA; Im J, 2008, INT J REMOTE SENS, V29, P399, DOI 10.1080/01431160601075582; Im J, 2005, REMOTE SENS ENVIRON, V99, P326, DOI 10.1016/j.rse.2005.09.008; JAPAN AEROSPACE EXPLORATION AGENCY (JAXA), 2006, TRMM DAT US HDB; Jensen J.R., 2005, INTRO DIGITAL IMAGE; KALKSTEIN LS, 1987, J CLIM APPL METEOROL, V26, P717, DOI 10.1175/1520-0450(1987)026<0717:AEOTCP>2.0.CO;2; Keim BD, 2003, GEOPHYS RES LETT, V30, DOI 10.1029/2002GL016295; Mimmack GM, 2001, J CLIMATE, V14, P2790, DOI 10.1175/1520-0442(2001)014<2790:CODMIC>2.0.CO;2; Muchoney D, 2000, INT J REMOTE SENS, V21, P1115, DOI 10.1080/014311600210100; Quinlan J., 2003, DATA MINING TOOLS SE; RHEE J, 2007, J HYDROMETEOROLOGY; SAS Institute Inc, 2004, SAS STAT 9 1 US GUID; STOOKSBURY DE, 1991, THEOR APPL CLIMATOL, V44, P143, DOI 10.1007/BF00868169; Williams CN, 2007, US HIST CLIMATOLOGY	24	8	9	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0034-4257		REMOTE SENS ENVIRON	Remote Sens. Environ.	JUN 16	2008	112	6					3099	3111		10.1016/j.rse.2008.03.001		13	Environmental Sciences; Remote Sensing; Imaging Science & Photographic Technology	Environmental Sciences & Ecology; Remote Sensing; Imaging Science & Photographic Technology	316YR	WOS:000256986400030	
J	Hong, WC				Hong, Wei-Chiang			Rainfall forecasting by technological machine learning models	APPLIED MATHEMATICS AND COMPUTATION			English	Article						rainfall forecasting; support vector regression (SVR); chaotic particle swarm optimization algorithm (CPSO); recurrent SVR; machine learning	SUPPORT VECTOR MACHINES; PARTICLE SWARM OPTIMIZATION; RECURRENT NEURAL NETWORKS; HYDROLOGIC MODEL; TIME; FEEDFORWARD; PREDICTION; SPACE	Accurate forecasting of rainfall has been one of the most important issues in hydrological research. Due to rainfall forecasting involves a rather complex nonlinear data pattern; there are lots of novel forecasting approaches to improve the forecasting accuracy. Recurrent artificial neural networks (RNNS) have played a crucial role in forecasting rainfall data. Meanwhile, support vector machines (SVMs) have been successfully employed to solve nonlinear regression and time series problems. This investigation elucidates the feasibility of hybrid model of RNNs and SVMs, namely RSVR, to forecast rainfall depth values. Moreover, chaotic particle swarm optimization algorithm (CPSO) is employed to choose the parameters of a SVR model. Subsequently, example of rainfall values during typhoon periods from Northern Taiwan is used to illustrate the proposed RSVRCPSO model. The empirical results reveal that the proposed model yields well forecasting performance, RSVRCPSO model provides a promising alternative for forecasting rainfall values. (C) 2007 Elsevier Inc. All rights reserved.	Oriental Inst Technol 58, Dept Informat Management, Sect 2, Taipei 220, Taiwan	Hong, WC (reprint author), Oriental Inst Technol 58, Dept Informat Management, Sect 2, Sichuan Rd, Taipei 220, Taiwan.	samuelhong@ieee.org	Hong, Wei-Chiang/A-4629-2013				Anctil F, 2004, J HYDROL, V286, P155, DOI 10.1016/j.jhydrol.2003.09.006; Angeline P.J., 1998, EVOLUTIONARY PROGRAM, V7, P601; Box G.E.P., 1976, TIME SERIES ANAL; Cai JJ, 2007, ENERG CONVERS MANAGE, V48, P645, DOI 10.1016/j.enconman.2006.05.020; Cao L., 2002, INTELL DATA ANAL, V6, P67; Cao LJ, 2003, NEUROCOMPUTING, V51, P321, DOI 10.1016/S0925-2312(02)00577-5; Castren E, 2004, CURR OPIN PHARMACOL, V4, P58, DOI 10.1016/j.coph.2003.10.004; Chiang YM, 2004, J HYDROL, V290, P297, DOI 10.1016/j.jhydrol.2003.12.033; CONNOR JT, 1994, IEEE T NEURAL NETWOR, V5, P240, DOI 10.1109/72.279188; Druce DJ, 2001, J HYDROL, V249, P102, DOI 10.1016/S0022-1694(01)00415-2; DUAN Q, 1991, THESIS U ARIZONA TUE; DUAN QY, 1994, J HYDROL, V158, P265, DOI 10.1016/0022-1694(94)90057-4; Eberhart RC, 2001, IEEE C EVOL COMPUTAT, P81; El-Din AG, 2002, WATER RES, V36, P1115, DOI 10.1016/S0043-1354(01)00287-1; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1016/0364-0213(90)90002-E; FRENCH MN, 1992, J HYDROL, V137, P1, DOI 10.1016/0022-1694(92)90046-X; Gencay R, 1997, PHYSICA D, V108, P119, DOI 10.1016/S0167-2789(97)82009-X; Jhee W. C., 1993, INTELLIGENT SYSTEMS, V2, P55; Jordan M.T., 1987, P 8 ANN C COGN SCI S, P531; KECHRIOTIS G, 1994, IEEE T NEURAL NETWOR, V5, P267, DOI 10.1109/72.279190; Kennedy J., 1995, P IEEE INT C NEUR NE, p[IEEE, 1942], DOI DOI 10.1109/ICNN.1995.488968; Kermanshahi B, 1998, NEUROCOMPUTING, V23, P125, DOI 10.1016/S0925-2312(98)00073-3; Lettenmaier DP, 1993, HDB HYDROLOGY; Lin GF, 2004, J HYDROL, V289, P1, DOI 10.1016/j.jhydrol.2003.10.015; Liu B, 2005, CHAOS SOLITON FRACT, V25, P1261, DOI 10.1016/j.chaos.2004.11.095; Luk KC, 2000, J HYDROL, V227, P56, DOI 10.1016/S0022-1694(99)00165-1; Luk KC, 2001, MATH COMPUT MODEL, V33, P683, DOI 10.1016/S0895-7177(00)00272-7; Mandic D.P., 2001, RECURRENT NEURAL NET; Mohandes MA, 2004, RENEW ENERG, V29, P939, DOI 10.1016/j.renene.2003.11.009; PAI PF, 2004, INT J ADV MANUF TECH, V27, P205; Pai PF, 2005, OMEGA-INT J MANAGE S, V33, P497, DOI 10.1016/j.omega.2004.07.024; Pan TY, 2004, J HYDROL, V297, P34, DOI 10.1016/j.jhydrol.2004.04.010; Ramirez MCV, 2005, J HYDROL, V301, P146, DOI 10.1016/j.jhydrol.2004.06.028; Suykens J.A.K., 2002, LEAST SQUARES SUPPOR; Tay FEH, 2001, OMEGA-INT J MANAGE S, V29, P309, DOI 10.1016/S0305-0483(01)00026-3; Tay FEH, 2002, NEUROCOMPUTING, V48, P847, DOI 10.1016/S0925-2312(01)00676-2; TSOI AC, 1994, IEEE T NEURAL NETWOR, V5, P229; Vapnik V. N, 1995, NATURE STAT LEARNING; Vieux BE, 2004, J HYDROL, V298, P155, DOI 10.1016/jhydrol.2004.03.035; Vojislav K., 2001, LEARNING SOFT COMPUT; Wang WJ, 2003, ENG COMPUTATION, V20, P192, DOI 10.1108/02644400310465317; Williams R. J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.270; Yapo PO, 1996, J HYDROL, V181, P23, DOI 10.1016/0022-1694(95)02918-4	43	28	28	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0096-3003		APPL MATH COMPUT	Appl. Math. Comput.	JUN 15	2008	200	1					41	57		10.1016/j.amc.2007.10.046		17	Mathematics, Applied	Mathematics	299AQ	WOS:000255728600005	
J	Kanevski, M; Maignan, M; Pozdnoukhov, A; Timonin, V				Kanevski, M.; Maignan, M.; Pozdnoukhov, A.; Timonin, V.			Interest rates mapping	PHYSICA A-STATISTICAL MECHANICS AND ITS APPLICATIONS			English	Article; Proceedings Paper	6th International Conference on Applications of Physics in Financial Analysis	JUL 04-07, 2007	Lisbon, PORTUGAL			interest rate curves; spatial statistics; machine learning; mapping; forecasting	TERM STRUCTURE	The present study deals with the analysis and mapping of Swiss franc interest rates. Interest rates depend on time and maturity, defining term structure of the interest rate curves (IRC). In the present study IRC are considered in a two-dimensional feature space - time and maturity. Exploratory data analysis includes a variety of tools widely used in econophysics and geostatistics. Geostatistical models and machine learning algorithms (multilayer perceptron and Support Vector Machines) were applied to produce interest rate maps. IR maps can be used for the visualisation and pattern perception purposes, to develop and to explore economical hypotheses, to produce dynamic asset-liability simulations and for financial risk assessments. The feasibility of an application of interest rates mapping approach for the IRC forecasting is considered as well. (C) 2008 Elsevier B.V. All rights reserved.	[Kanevski, M.; Pozdnoukhov, A.; Timonin, V.] Univ Lausanne, IGAR, CH-1015 Lausanne, Switzerland; [Maignan, M.] Banque Cantonale Geneve BCGE, Geneva, Switzerland	Kanevski, M (reprint author), Univ Lausanne, IGAR, Amphipole bldg, CH-1015 Lausanne, Switzerland.	Mikhail.Kanevski@unil.ch					Cajueiro DO, 2007, PHYSICA A, V373, P603, DOI 10.1016/j.physa.2006.04.110; Diebold FX, 2006, J ECONOMETRICS, V130, P337, DOI 10.1016/j.jeconom.2005.03.005; DIMATTEO T, 2002, J THEORET APPL FINAN, V5, P122; Di Matteo T, 2005, PHYSICA A, V355, P21, DOI 10.1016/j.physa.2005.02.063; Haykin S., 1999, NEURAL NETWORKS COMP; Kanevski M, 2004, ANAL MODELLING SPATI; KANEVSKI M, 2003, SWISS STAT SOC C MON; KANTZ KH, 2003, NONLINEAR TIME SERIE; Mantegna R.N., 1999, INTRO ECONOPHYSICS C; MCNEIL PD, 2005, NEURAL NETWORKS FINA; Vapnik V.N., 1999, NATURE STAT LEARNING	11	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0378-4371		PHYSICA A	Physica A	JUN 15	2008	387	15					3897	3903		10.1016/j.physa.2008.02.069		7	Physics, Multidisciplinary	Physics	308RQ	WOS:000256408100013	
J	Ge, GT; Wong, GW				Ge, Guangtao; Wong, G. William			Classification of premalignant pancreatic cancer mass-spectrometry data using decision tree ensembles	BMC BIOINFORMATICS			English	Article							OVARIAN-CANCER; PROTEOMIC ANALYSIS; PROSTATE-CANCER; STACKED GENERALIZATION; PROTEIN EXPRESSION; LOGITBOOST CLASSIFIER; BIOMARKER DISCOVERY; CLINICAL PROTEOMICS; SERUM; IDENTIFICATION	Background: Pancreatic cancer is the fourth leading cause of cancer death in the United States. Consequently, identification of clinically relevant biomarkers for the early detection of this cancer type is urgently needed. In recent years, proteomics profiling techniques combined with various data analysis methods have been successfully used to gain critical insights into processes and mechanisms underlying pathologic conditions, particularly as they relate to cancer. However, the high dimensionality of proteomics data combined with their relatively small sample sizes poses a significant challenge to current data mining methodology where many of the standard methods cannot be applied directly. Here, we propose a novel methodological framework using machine learning method, in which decision tree based classifier ensembles coupled with feature selection methods, is applied to proteomics data generated from premalignant pancreatic cancer. Results: This study explores the utility of three different feature selection schemas (Student t test, Wilcoxon rank sum test and genetic algorithm) to reduce the high dimensionality of a pancreatic cancer proteomic dataset. Using the top features selected from each method, we compared the prediction performances of a single decision tree algorithm C4.5 with six different decision-tree based classifier ensembles (Random forest, Stacked generalization, Bagging, Adaboost, Logitboost and Multiboost). We show that ensemble classifiers always outperform single decision tree classifier in having greater accuracies and smaller prediction errors when applied to a pancreatic cancer proteomics dataset. Conclusion: In our cross validation framework, classifier ensembles generally have better classification accuracies compared to that of a single decision tree when applied to a pancreatic cancer proteomic dataset, thus suggesting its utility in future proteomics data analysis. Additionally, the use of feature selection method allows us to select biomarkers with potentially important roles in cancer development, therefore highlighting the validity of this method.	[Ge, Guangtao] Tufts Univ, Dept Comp Sci, Medford, MA 02155 USA; [Wong, G. William] Johns Hopkins Univ, Sch Med, Dept Physiol, Baltimore, MD 21205 USA; [Wong, G. William] Johns Hopkins Univ, Sch Med, Ctr Metab & Obes Res, Baltimore, MD 21205 USA	Ge, GT (reprint author), Tufts Univ, Dept Comp Sci, Medford, MA 02155 USA.	guge@eecs.tufts.edu; gwwong@jhmi.edu					Adam BL, 2002, CANCER RES, V62, P3609; Alexe G, 2004, PROTEOMICS, V4, P766, DOI 10.1002/pmic.200300574; Alfonso P, 2004, PROTEOMICS, V4, P442, DOI 10.1002/pmic.200300647; Andrade L, 2003, J VLSI SIG PROC SYST, V35, P229, DOI 10.1023/B:VLSI.0000003022.86639.1f; Baggerly KA, 2003, PROTEOMICS, V3, P1667, DOI 10.1002/pmic.200300522; Baggerly KA, 2005, J NATL CANCER I, V97, P307, DOI 10.1093/jnci/dji008; BELLUCO C, 2007, ANN SURG ONCOL; Bhanot G, 2006, PROTEOMICS, V6, P592, DOI 10.1002/pmic.200500192; Brady D, 2000, IEEE T BIO-MED ENG, V47, P1271, DOI 10.1109/10.867962; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Cai YD, 2006, J THEOR BIOL, V238, P172, DOI 10.1016/j.jtbi.2005.05.034; Cecconi D, 2007, PROTEOMICS, V7, P1644, DOI 10.1002/pmic.200600811; Chen R, 2006, PROTEOMICS, V6, P3871, DOI 10.1002/pmic.200500702; Conrads TP, 2004, ENDOCR-RELAT CANCER, V11, P163, DOI 10.1677/erc.0.0110163; COOMBES KR, 2006, FUNDAMENTALS DATA MI, P282; Crnogorac-Jurcevic T, 2005, GASTROENTEROLOGY, V129, P1454, DOI 10.1053/j.gastro.2005.08.012; Diamandis EP, 2004, MOL CELL PROTEOMICS, V3, P367, DOI 10.1074/mcp.R400007-MCP200; FRIEDMAN J, 1998, ADDITIVE LOGISTIC RE, P45; Fung ET, 2002, BIOTECHNIQUES S, V34-8, P40; Fung ET, 2002, BIOTECHNIQUES, P34; Geurts P, 2005, BIOINFORMATICS, V21, P3138, DOI 10.1093/bioinformatics/bti494; Gronborg M, 2004, J PROTEOME RES, V3, P1042, DOI 10.1021/pr0499085; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hingorani SR, 2003, CANCER CELL, V4, P437, DOI 10.1016/S1535-6108(03)00309-X; Izmirlian G, 2004, ANN NY ACAD SCI, V1020, P154, DOI 10.1196/annals.1310.015; Jafari Mehrdad, 2004, Surg Oncol Clin N Am, V13, P751, DOI 10.1016/j.soc.2004.06.009; Lashner BA, 2006, AM J GASTROENTEROL, V101, P965, DOI 10.1111/j.1572-0241.00513.x; Levner I, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-68; Li DH, 2004, LANCET, V363, P1049, DOI 10.1016/S0140-6736(04)15841-8; Li LH, 2004, ARTIF INTELL MED, V32, P71, DOI 10.1016/j.artmed.2004.03.006; Lowenfels AB, 2004, JPN J CLIN ONCOL, V34, P238, DOI 10.1093/jjco/hyh045; MARCUSON R, 1982, CLIN CHEM, V28, P1346; Mikuriya K, 2007, INT J ONCOL, V30, P849; Mitchell T, 1997, MACHINE LEARNING; Neubauer Hans, 2007, V176, P89; Ning Kang, 2006, Genome Inform, V17, P194; Ornstein DK, 2004, J UROLOGY, V172, P1302, DOI 10.1097/01.ju.0000139572.88463.39; Petricoin EF, 2004, UROL ONCOL-SEMIN ORI, V22, P322, DOI 10.1016/j.urolonc.2004.04.011; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Posadas EM, 2004, CURR OPIN ONCOL, V16, P478, DOI 10.1097/00001622-200409000-00012; Qu YS, 2002, CLIN CHEM, V48, P1835; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1996, BAGGING BOOSTING C4, V1; Roesch-Ely M, 2007, ONCOGENE, V26, P54, DOI 10.1038/sj.onc.1209770; Rosty C, 2005, METH MOLEC MED, V103, P189; Scarlett CJ, 2006, GASTROENTEROLOGY, V130, P1670, DOI 10.1053/j.gastro.2006.02.036; SCHAPIRE RE, 1999, BRIEF INTRO BOOSTING, P1401; Schwartz SA, 2004, CLIN CANCER RES, V10, P981, DOI 10.1158/1078-0432.CCR-0927-3; Ting KM, 1997, INT JOINT CONF ARTIF, P866; Todorovski L, 2003, MACH LEARN, V50, P223, DOI 10.1023/A:1021709817809; Vlahou A, 2003, J BIOMED BIOTECHNOL, P308; Wagner M, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-26; Wang HX, 2004, PROTEOMICS, V4, P2476, DOI 10.1002/pmic.200300763; Wang SQ, 2006, J THEOR BIOL, V242, P941, DOI 10.1016/j.jtbi.2006.05.006; Wang WX, 2003, ANAL CHEM, V75, P4818, DOI 10.1021/ac026468x; Wang Z, 2004, CLIN CHEM, V50, P1939, DOI 10.1373/clinchem.2004.036871; Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849; White CN, 2004, CLIN BIOCHEM, V37, P636, DOI 10.1016/j.clinbiochem.2004.05.004; Witten I. H., 1999, DATA MINING PRACTICA; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210; Wulfkuhle JD, 2003, NAT REV CANCER, V3, P267, DOI 10.1038/nrc.1043; Yu JS, 2005, BIOINFORMATICS, V21, pI487, DOI 10.1093/bioinformatics/bti1030; Yu JS, 2005, BIOINFORMATICS, V21, P2200, DOI 10.1093/bioinformatics/bti370; Zhang GY, 2007, J BIOTECHNOL, V127, P417, DOI 10.1016/j.jbiotec.2006.07.020; Zhou L, 2007, PROTEOMICS, V7, P1345, DOI 10.1002/pmic.200600086	67	22	24	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	JUN 11	2008	9								275	10.1186/1471-2105-9-275		12	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	319JW	WOS:000257160900001	
J	Shen, HB; Chou, JJ				Shen, Hongbin; Chou, James J.			MemBrain: Improving the Accuracy of Predicting Transmembrane Helices	PLOS ONE			English	Article								Prediction of transmembrane helices (TMH) in alpha helical membrane proteins provides valuable information about the protein topology when the high resolution structures are not available. Many predictors have been developed based on either amino acid hydrophobicity scale or pure statistical approaches. While these predictors perform reasonably well in identifying the number of TMHs in a protein, they are generally inaccurate in predicting the ends of TMHs, or TMHs of unusual length. To improve the accuracy of TMH detection, we developed a machine-learning based predictor, MemBrain, which integrates a number of modern bioinformatics approaches including sequence representation by multiple sequence alignment matrix, the optimized evidence-theoretic K-nearest neighbor prediction algorithm, fusion of multiple prediction window sizes, and classification by dynamic threshold. MemBrain demonstrates an overall improvement of about 20% in prediction accuracy, particularly, in predicting the ends of TMHs and TMHs that are shorter than 15 residues. It also has the capability to detect N-terminal signal peptides. The MemBrain predictor is a useful sequence-based analysis tool for functional and structural characterization of helical membrane proteins; it is freely available at http://chou.med.harvard.edu/bioinf/MemBrain/.	[Shen, Hongbin; Chou, James J.] Harvard Univ, Sch Med, Dept Biol Chem & Mol Pharmacol, Boston, MA 02115 USA	Shen, HB (reprint author), Harvard Univ, Sch Med, Dept Biol Chem & Mol Pharmacol, Boston, MA 02115 USA.	james_chou@hms.harvard.edu			NIH and the Pew Scholars Program in the Biomedical Sciences	This work was supported by the NIH and the Pew Scholars Program in the Biomedical Sciences awarded to J.J.C.	Abramson J, 2003, SCIENCE, V301, P610, DOI 10.1126/science.1088196; Chamberlain AK, 2004, J MOL BIOL, V339, P471, DOI 10.1016/j.jmb.2004.03.072; Chou KC, 2007, ANAL BIOCHEM, V370, P1, DOI 10.1016/j.ab.2007.07.006; Chou KC, 2006, J PROTEOME RES, V5, P1888, DOI 10.1021/pr060167c; CLAROS MG, 1994, COMPUT APPL BIOSCI, V10, P685; Cserzo M, 2004, BIOINFORMATICS, V20, P136, DOI 10.1093/bioinformatics/btg394; Cuthbertson JM, 2005, PROTEIN ENG DES SEL, V18, P295, DOI 10.1093/protein/gzi032; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Fu DX, 2000, SCIENCE, V290, P481, DOI 10.1126/science.290.5491.481; Hirokawa T, 1998, BIOINFORMATICS, V14, P378, DOI 10.1093/bioinformatics/14.4.378; Jones DT, 2007, BIOINFORMATICS, V23, P538, DOI 10.1093/bioinformatics/btl677; Kall L, 2004, J MOL BIOL, V338, P1027, DOI 10.1016/j.jmb.2004.03.016; Krogh A, 2001, J MOL BIOL, V305, P567, DOI 10.1006/jmbi.2000.4315; KYTE J, 1982, J MOL BIOL, V157, P105, DOI 10.1016/0022-2836(82)90515-0; Lieberman RL, 2005, NATURE, V434, P177, DOI 10.1038/nature03311; MAKIVIRTA A, 1991, COMPUT METH PROG BIO, V34, P139, DOI 10.1016/0169-2607(91)90039-V; Rost B, 1996, PROTEIN SCI, V5, P1704; Schaffer AA, 2001, NUCLEIC ACIDS RES, V29, P2994, DOI 10.1093/nar/29.14.2994; Shafer Glenn, 1976, MATH THEORY EVIDENCE; Shen HB, 2006, BIOINFORMATICS, V22, P1717, DOI 10.1093/bioinformatics/btl170; Shen HB, 2007, BIOCHEM BIOPH RES CO, V363, P297, DOI 10.1016/j.bbrc.2007.08.140; White SH, 2004, PROTEIN SCI, V13, P1948, DOI 10.1110/ps.04712004; Wimley WC, 1996, NAT STRUCT BIOL, V3, P842, DOI 10.1038/nsb1096-842; Yuan Z, 2004, J COMPUT CHEM, V25, P632, DOI 10.1002/jcc.10411; Zhou HY, 2003, PROTEIN SCI, V12, P1547, DOI 10.1110/ps.0305103; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565	26	34	36	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	185 BERRY ST, STE 1300, SAN FRANCISCO, CA 94107 USA	1932-6203		PLOS ONE	PLoS One	JUN 11	2008	3	6							e2399	10.1371/journal.pone.0002399		6	Multidisciplinary Sciences	Science & Technology - Other Topics	405UD	WOS:000263248800037	
J	Yoo, PD; Ho, YS; Zhou, BB; Zomaya, AY				Yoo, Paul D.; Ho, Yung Shwen; Zhou, Bing Bing; Zomaya, Albert Y.			SiteSeek: Post-translational modification analysis using adaptive locality-effective kernel methods and new profiles	BMC BIOINFORMATICS			English	Article							PROTEIN SECONDARY STRUCTURE; SUPPORT VECTOR MACHINES; AMINO-ACID-SEQUENCE; PHOSPHORYLATION SITES; STRUCTURE PREDICTION; MASS-SPECTROMETRY; WIDE PREDICTION; NEURAL-NETWORKS; IDENTIFICATION; KINASES	Background: Post-translational modifications have a substantial influence on the structure and functions of protein. Post- translational phosphorylation is one of the most common modification that occur in intracellular proteins. Accurate prediction of protein phosphorylation sites is of great importance for the understanding of diverse cellular signalling processes in both the human body and in animals. In this study, we propose a new machine learning based protein phosphorylation site predictor, SiteSeek. SiteSeek is trained using a novel compact evolutionary and hydrophobicity profile to detect possible protein phosphorylation sites for a target sequence. The newly proposed method proves to be more accurate and exhibits a much stable predictive performance than currently existing phosphorylation site predictors. Results: The performance of the proposed model was compared to nine existing different machine learning models and four widely known phosphorylation site predictors with the newly proposed PS-Benchmark_I dataset to contrast their accuracy, sensitivity, specificity and correlation coefficient. SiteSeek showed better predictive performance with 86.6% accuracy, 83.8% sensitivity, 92.5% specificity and 0.77 correlation-coefficient on the four main kinase families (CDK, CK2, PKA, and PKC). Conclusion: Our newly proposed methods used in SiteSeek were shown to be useful for the identification of protein phosphorylation sites as it performed much better than widely known predictors on the newly built PS-Benchmark_I dataset.	[Yoo, Paul D.; Zhou, Bing Bing; Zomaya, Albert Y.] Univ Sydney, Sch Informat Technol J12, Adv Networks Res Grp, Sydney, NSW 2006, Australia; [Ho, Yung Shwen] Univ Sydney, Westmead Hosp, Westmead Millennium Inst, Ctr Virus Res,Retroviral Genet Lab, Westmead, NSW 2145, Australia; [Zomaya, Albert Y.] Univ Sydney, Sydney Bioinformat Ctr, Sydney, NSW 2006, Australia; [Zomaya, Albert Y.] Univ Sydney, Ctr Math Biol, Sydney, NSW 2006, Australia	Yoo, PD (reprint author), Univ Sydney, Sch Informat Technol J12, Adv Networks Res Grp, Sydney, NSW 2006, Australia.	dyoo4334@it.usyd.edu.au; shwen_ho@wmi.usyd.edu.au; bbz@it.usyd.edu.au; zomaya@it.usyd.edu.au					AMOS B, 2000, BIOINFORMATICS, V16, P48; BALDI P, 1998, BIOINFORMATICS THE M; Ballif BA, 2004, MOL CELL PROTEOMICS, V3, P1093, DOI 10.1074/mcp.M400085-MCP200; Beausoleil SA, 2004, P NATL ACAD SCI USA, V101, P12130, DOI 10.1073/pnas.0404720101; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Blom N, 2004, PROTEOMICS, V4, P1633, DOI 10.1002/pmic.200300771; BURGES C, 1998, J DATA MINING KNOWLE, V2, P121; Cohen P, 2002, NAT CELL BIOL, V4, pE127, DOI 10.1038/ncb0502-e127; Daly NL, 2000, BIOCHEMISTRY-US, V39, P9039, DOI 10.1021/bi0004807; DAVID R, 2000, THESIS MIT CAMBRIDGE; Diella F, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-79; DIETTERICH TG, 1995, TECH REP DEP COMPUT; Ficarro SB, 2002, NAT BIOTECHNOL, V20, P301, DOI 10.1038/nbt0302-301; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Frishman D, 1996, PROTEIN ENG, V9, P133, DOI 10.1093/protein/9.2.133; Graves LM, 1997, ADV SEC MESS PHOSPH, V31, P49; Hardle W., 2004, NONPARAMETRIC SEMIPA; Hjerrild M, 2004, J PROTEOME RES, V3, P426, DOI 10.1021/pr0341033; HORVATH G, 2003, NATO ASI SERIES COMP, P375; Hu HJ, 2004, IEEE T NANOBIOSCI, V3, P265, DOI 10.1109/TNB.2004.837906; Hunter T, 2000, CELL, V100, P113, DOI 10.1016/S0092-8674(00)81688-8; Hunter T, 1998, PHILOS T ROY SOC B, V353, P583, DOI 10.1098/rstb.1998.0228; Iakoucheva LM, 2004, NUCLEIC ACIDS RES, V32, P1037, DOI 10.1093/nar/gkh253; Jang HH, 2006, FEBS LETT, V580, P351, DOI 10.1016/j.febslet.2005.12.030; Johnson LN, 1998, FEBS LETT, V430, P1, DOI 10.1016/S0014-5793(98)00606-1; Kim H, 2003, PROTEIN ENG, V16, P553, DOI 10.1093/protein/gzg072; Kim JH, 2004, BIOINFORMATICS, V20, P3179, DOI 10.1093/bioinformatics/bth382; King RD, 1996, PROTEIN SCI, V5, P2298; Kolibaba KS, 1997, BBA-REV CANCER, V1333, pF217, DOI 10.1016/S0304-419X(97)00022-X; Korenberg MJ, 2000, ANN BIOMED ENG, V28, P803, DOI 10.1114/1.1289470; KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209; Larose D. T., 2005, DISCOVERING KNOWLEDG; Li CP, 2004, J AGR FOOD CHEM, V52, P5752, DOI 10.1021/jf0498259; Lin K, 2002, J THEOR BIOL, V216, P361, DOI 10.1006/jtbi.2001.2512; Liu JF, 2004, NUCLEIC ACIDS RES, V32, P3522, DOI 10.1093/nar/gkh684; LOHMANN R, 1994, PROTEIN SCI, V3, P1597; Mann M, 2002, TRENDS BIOTECHNOL, V20, P261, DOI 10.1016/S0167-7799(02)01944-3; Obenauer JC, 2003, NUCLEIC ACIDS RES, V31, P3635, DOI 10.1093/nar/gkg584; Pinna LA, 1996, BBA-MOL CELL RES, V1314, P191, DOI 10.1016/S0167-4889(96)00083-3; RADZICKA A, 1988, BIOCHEMISTRY-US, V27, P1664, DOI 10.1021/bi00405a042; ROSE GD, 1985, SCIENCE, V229, P834, DOI 10.1126/science.4023714; ROST B, 1993, J MOL BIOL, V232, P584, DOI 10.1006/jmbi.1993.1413; SALAMOV AA, 1995, J MOL BIOL, V247, P11, DOI 10.1006/jmbi.1994.0116; Schapire R. E., 1999, P 16 INT JOINT C ART, P1401; Scholz M, 2007, LECT NOTES COMPUT SC, V4414, P38; SHAWETAYLOR J, 2005, KERNEL METHODS PATTE; Songyang Z, 1993, Cell, V72, P767; Xue Y, 2005, NUCLEIC ACIDS RES, V33, pW184, DOI 10.1093/nar/gki393; Yaffe MB, 2001, NAT BIOTECHNOL, V19, P348, DOI 10.1038/86737; Yang ZR, 2004, BIOINFORMATICS, V20, P735, DOI 10.1093/bioinformatics/btg477; Zanzoni A, 2007, NUCLEIC ACIDS RES, V35, pD229, DOI 10.1093/nar/gkl922; ZHANG B, 2005, P IEEE C NEUR NETW I, V1, P532; ZVELEBIL MJ, 1987, J MOL BIOL, V195, P957, DOI 10.1016/0022-2836(87)90501-8	53	10	10	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	JUN 10	2008	9								272	10.1186/1471-2105-9-272		17	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	326JE	WOS:000257653700001	
J	Ganascia, JG				Ganascia, Jean-Gabriel			Reconstructing True Wrong Inductions	AI MAGAZINE			English	Article								There have been many erroneousprescientific and commonsense inductions. We want to understand why people believe in wrong theories. My hypothesis is that mistaken inductions are due not only to the lack or facts, but also to the poor description of existing facts and to implicit knowledge that is transmitted socially. This article presents several experiments the aim of which is to validate this hypothesis by using machine-learning and data-mining techniques to simulate the way people build erroneous theories from observations.	[Ganascia, Jean-Gabriel] Orsay Univ Paris XI, Orsay, France; [Ganascia, Jean-Gabriel] CNRS, F-75700 Paris, France; [Ganascia, Jean-Gabriel] Orsay Univ, Orsay, France	Ganascia, JG (reprint author), Univ Paris 06, ACASA Team, LIP6 Lab, F-75252 Paris 05, France.						Agrawal R., 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; BREDIN JD, 1983, AFFAIRE; Carpenter K.J., 1986, HIST SCURVY VITAMIN; CORRUBLE V, 1997, ARTIF INTELL, V2, P205; Dorner D., 1996, LOGIC FAILURE RECOGN; Ganascia JG, 2004, LECT NOTES COMPUT SC, V3127, P156; GANASCIA JG, 1987, P 10 INT JOINT C ART; GANASCIA JG, 2005, LOGIC METHODOLOGY PH; Lippmann W., 1922, PUBLIC OPINION; MAHE J, 1880, DICT ENCY SCI MED 3, V8, P35; Reason J, 1990, HUMAN ERROR; TAGUIEFF PA, 1998, COULEUR SANG DOCTRIN; THAGARD P, 1990, MOR KAUF M, P27; VELCIN J, 2005, P 19 INT JOINT C ART, P883	14	1	1	AMER ASSOC ARTIFICIAL INTELL	MENLO PK	445 BURGESS DRIVE, MENLO PK, CA 94025-3496 USA	0738-4602		AI MAG	AI Mag.	SUM	2008	29	2					57	65				9	Computer Science, Artificial Intelligence	Computer Science	364XF	WOS:000260368200014	
J	Yan, C; Hu, J; Wang, Y				Yan, C.; Hu, J.; Wang, Y.			Discrimination of outer membrane proteins using a K-nearest neighbor method	AMINO ACIDS			English	Article						prediction; transmembrane proteins; machine learning; gram-negative bacteria	AMINO-ACID-COMPOSITION; SUBCELLULAR LOCATION PREDICTION; SUPPORT VECTOR MACHINES; GRAM-NEGATIVE BACTERIA; HIDDEN MARKOV MODEL; ENSEMBLE CLASSIFIER; STRUCTURAL CLASS; WEB SERVER; CONOTOXIN SUPERFAMILY; SECONDARY STRUCTURE	Identification of outer membrane proteins (OMPs) from genome is an important task. This paper presents a k-nearest neighbor (K-NN) method for discriminating outer membrane proteins (OMPs). The method makes predictions based on a weighted Euclidean distance that is computed from residue composition. The method achieves 89.1% accuracy with 0.668 MCC (Matthews correlation coefficient) in discriminating OMPs and non-OMPs. The performance of the method is improved by including homologous information into the calculation of residue composition. The final method achieves an accuracy of 96.1%, with 0.873 MCC, 87.5% sensitivity, and 98.2% specificity. Comparisons with multiple recently published methods show that the method proposed in this study outperforms the others.	[Yan, C.; Hu, J.; Wang, Y.] Utah State Univ, Dept Comp Sci, Logan, UT 84322 USA	Yan, C (reprint author), Old Main Hill 4205, Logan, UT 84322 USA.	charles.yan@usu.edu					Ahmad S, 2004, J MOL BIOL, V341, P65, DOI 10.1016/j.jmb.2004.05.058; ALTSCHUL SF, 1997, NUCLEIC ACIDS RES, V25, P3402; Bagos PG, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-29; Bagos PG, 2004, NUCLEIC ACIDS RES, V32, pW400, DOI 10.1093/nar/gkh417; Bahadur RP, 2004, J MOL BIOL, V336, P943, DOI 10.1016/j.jmb.2003.12.073; Bairoch A, 2004, BRIEF BIOINFORM, V5, P39, DOI 10.1093/bib/5.1.39; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Bao L, 2005, BIOINFORMATICS, V21, P2185, DOI 10.1093/bioinformatics/bti365; Berven FS, 2004, NUCLEIC ACIDS RES, V32, pW394, DOI 10.1093/nar/gkh351; Cao YF, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-20; Chen C, 2006, ANAL BIOCHEM, V357, P116, DOI 10.1016/j.ab.2006.07.022; Chen C, 2006, J THEOR BIOL, V243, P444, DOI 10.1016/j.jtbi.2006.06.025; Chen J, 2007, AMINO ACIDS, V33, P423, DOI 10.1007/s00726-006-0485-9; Chen YL, 2007, J THEOR BIOL, V248, P377, DOI 10.1016/j.jtbi.2007.05.019; Chou KC, 2006, J PROTEOME RES, V5, P3420, DOI 10.1021/pr060404b; Chou KC, 2005, BIOCHEM BIOPH RES CO, V327, P845, DOI 10.1016/j.bbrc.2004.12.069; Chou KC, 2007, ANAL BIOCHEM, V370, P1, DOI 10.1016/j.ab.2007.07.006; Chou KC, 1999, PROTEINS, V34, P137, DOI 10.1002/(SICI)1097-0134(19990101)34:1<137::AID-PROT11>3.0.CO;2-O; Chou KC, 2007, J CELL BIOCHEM, V100, P665, DOI 10.1002/jcb.21096; Chou KC, 2006, J PROTEOME RES, V5, P1888, DOI 10.1021/pr060167c; Chou KC, 2007, BIOCHEM BIOPH RES CO, V357, P633, DOI 10.1016/j.bbrc.2007.03.162; Chou K.C., 2002, GENE CLONING EXPRESS, P57; Chou KC, 2005, J CHEM INF MODEL, V45, P407, DOI 10.1021/ci049686v; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2007, BIOCHEM BIOPH RES CO, V360, P339, DOI 10.1016/j.bbrc.2007.06.027; Chou KC, 2007, J PROTEOME RES, V6, P1728, DOI 10.1021/pr060635i; Chou KC, 2006, BIOCHEM BIOPH RES CO, V347, P150, DOI 10.1016/j.bbrc.2006.06.059; Deng Y, 2004, COMPUT BIOL CHEM, V28, P189, DOI 10.1016/j.compbiolchem.2004.02.004; DIAO Y, 2007, AMINO ACIDS; Ding YS, 2007, PROTEIN PEPTIDE LETT, V14, P811; Dobson RJ, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-217; Douglas SM, 2007, P NATL ACAD SCI USA, V104, P6644, DOI 10.1073/pnas.0700930104; Du PF, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-518; FANG Y, 2007, AMINO ACIDS; Gao QB, 2006, PROTEIN ENG DES SEL, V19, P511, DOI 10.1093/protein/gzl038; Gao QB, 2005, FEBS LETT, V579, P3444, DOI 10.1016/j.febslet.2005.05.021; Gao Y, 2005, AMINO ACIDS, V28, P373, DOI 10.1007/s00726-005-0206-9; Gardy JL, 2005, BIOINFORMATICS, V21, P617, DOI 10.1093/bioinformatics/bti057; Garrow AG, 2005, NUCLEIC ACIDS RES, V33, pW188, DOI 10.1093/nat/gki384; Garrow AG, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-56; Gnanasekaran TV, 2000, BIOINFORMATICS, V16, P839, DOI 10.1093/bioinformatics/16.9.839; Gromiha MM, 2005, BIOINFORMATICS, V21, P961, DOI 10.1093/bioinformatics/bti126; Gromiha MM, 2006, PROTEINS, V63, P1031, DOI 10.1002/prot.20929; Guo J, 2006, PROTEOMICS, V6, P5099, DOI 10.1002/pmic.200600064; Guo YZ, 2006, AMINO ACIDS, V30, P397, DOI 10.1007/s00726-006-0332-z; Huang Y, 2004, BIOINFORMATICS, V20, P21, DOI 10.1093/bioinformatics/btg366; Jahandideh S, 2007, BIOPHYS CHEM, V128, P87, DOI 10.1016/j.bpc.2007.03.006; Kedarisetti KD, 2006, BIOCHEM BIOPH RES CO, V348, P981, DOI 10.1016/j.bbrc.2006.07.141; Koebnik R, 2000, MOL MICROBIOL, V37, P239, DOI 10.1046/j.1365-2958.2000.01983.x; Krogh A, 2001, J MOL BIOL, V305, P567, DOI 10.1006/jmbi.2000.4315; LI FM, 2007, AMINO ACIDS; Lin H, 2007, BIOCHEM BIOPH RES CO, V354, P548, DOI 10.1016/j.bbrc.2007.01.011; Lin H, 2007, J COMPUT CHEM, V28, P1463, DOI 10.1002/jcc.20554; Liu DQ, 2007, AMINO ACIDS, V32, P493, DOI 10.1007/s00726-006-0466-z; Liu H, 2005, PROTEIN J, V24, P385, DOI 10.1007/s10930-005-7592-4; Liu H, 2005, BIOCHEM BIOPH RES CO, V336, P737, DOI 10.1016/j.bbrc.2005.08.160; Liu Q, 2003, COMPUT BIOL CHEM, V27, P355, DOI 10.1016/S1476-9271(02)00085-3; Martelli Pier Luigi, 2002, Bioinformatics, V18 Suppl 1, pS46; Mondal S, 2006, J THEOR BIOL, V243, P252, DOI 10.1016/j.jtbi.2006.06.014; Niu B, 2006, PROTEIN PEPTIDE LETT, V13, P489, DOI 10.2174/092986606776819619; Park KJ, 2005, BIOINFORMATICS, V21, P4223, DOI 10.1093/bioinformatics/bti697; Pu Xian, 2007, J Theor Biol, V247, P259, DOI 10.1016/j.jtbi.2007.01.016; REY S, 2005, NUCLEIC ACIDS RES, V33, P164; ROST B, 1993, P NATL ACAD SCI USA, V90, P7558, DOI 10.1073/pnas.90.16.7558; Schulz GE, 2000, CURR OPIN STRUC BIOL, V10, P443, DOI 10.1016/S0959-440X(00)00120-2; Shen HB, 2007, AMINO ACIDS, V33, P57, DOI 10.1007/s00726-006-0478-8; Shen HB, 2006, BIOINFORMATICS, V22, P1717, DOI 10.1093/bioinformatics/btl170; Shen HB, 2005, BIOCHEM BIOPH RES CO, V334, P288, DOI 10.1016/j.bbrc.2005.06.087; Shen HB, 2007, PROTEIN ENG DES SEL, V20, P39, DOI 10.1093/protein-gzl053; Shen HB, 2007, BIOCHEM BIOPH RES CO, V355, P1006, DOI 10.1016/j.bbrc.2007.02.071; Shen HB, 2007, BIOCHEM BIOPH RES CO, V364, P53, DOI 10.1016/j.bbrc.2007.09.098; Shen HB, 2005, BIOCHEM BIOPH RES CO, V337, P752, DOI 10.1016/j.bbrc.2005.09.117; Shen HB, 2007, AMINO ACIDS, V32, P483, DOI 10.1007/s00726-006-0439-2; Shi JY, 2007, AMINO ACIDS, V33, P69, DOI 10.1007/s00726-006-0475-y; Sun XD, 2006, AMINO ACIDS, V30, P469, DOI 10.1007/s00726-005-0239-0; TAN F, 2007, AMINO ACIDS; Waldispuhl J, 2006, NUCLEIC ACIDS RES, V34, pW189, DOI 10.1093/nar/gkl205; Wang LJ, 2006, NUCLEIC ACIDS RES, V34, pW243, DOI 10.1093/nar/gkl298; Wang M, 2005, AMINO ACIDS, V28, P395, DOI 10.1007/s00726-005-0189-6; WEN Z, 2006, AMINO ACIDS, V32, P277; Wimley WC, 2002, PROTEIN SCI, V11, P301, DOI 10.1110/ps.29402; Wimley WC, 2003, CURR OPIN STRUC BIOL, V13, P404, DOI 10.1016/S0959-440X(03)00099-X; Xiao X, 2007, PROTEIN PEPTIDE LETT, V14, P871, DOI 10.2174/092986607782110293; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Xiao ZJ, 2006, LEUKEMIA RES, V30, P54, DOI 10.1016/j.leukres.2005.05.012; Yan CH, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-262; Ye ZQ, 2007, BIOINFORMATICS, V23, P1444, DOI 10.1093/bioinformatics/btm119; Zhang SW, 2006, AMINO ACIDS, V30, P461, DOI 10.1007/s00726-006-0263-8; ZHANG TL, 2007, AMINO ACIDS; Zhou XB, 2007, J THEOR BIOL, V248, P546, DOI 10.1016/j.jtbi.2007.06.001	90	5	5	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0939-4451		AMINO ACIDS	Amino Acids	JUN	2008	35	1					65	73		10.1007/s00726-007-0628-7		9	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	309QQ	WOS:000256475700008	
J	Hofmann, T; Scholkopf, B; Smola, AJ				Hofmann, Thomas; Schoelkopf, Bernhard; Smola, Alexander J.			Kernel methods in machine learning	ANNALS OF STATISTICS			English	Review						machine learning; reproducing kernels; support vector machines; graphical models	SUPPORT VECTOR MACHINES; INDEPENDENT COMPONENT ANALYSIS; LOG-LINEAR MODELS; PROJECTION PURSUIT; PATTERN-RECOGNITION; CANONICAL-ANALYSIS; METRIC-SPACES; REGRESSION; REGULARIZATION; APPROXIMATION	We review machine learning methods employing positive definite kernels. These methods formulate learning and estimation problems in a reproducing kernel Hilbert space (RKHS) of functions defined on the data domain, expanded in terms of a kernel. Working in linear spaces of function has the benefit of facilitating the construction and analysis of learning algorithms while at the same time allowing large classes of functions. The latter include nonlinear functions as well as functions defined on nonvectorial data. We cover a wide range of methods, ranging from binary classifiers to sophisticated methods for estimation with structured data.	[Hofmann, Thomas] TH Darmstadt, Dept Comp Sci, Darmstadt, Germany; [Schoelkopf, Bernhard] Max Planck Inst Biol Cybernet, Tubingen, Germany; [Smola, Alexander J.] Natl ICT Australia, Stat Machine Learning Program, Canberra, ACT, Australia	Hofmann, T (reprint author), TH Darmstadt, Dept Comp Sci, Darmstadt, Germany.	hofmann@int.tu-darmstadt.de; bs@tuebingen.mpg.de; Alex.Smola@nicta.com.au	Scholkopf, Bernhard/A-7570-2013				Aizerman M.A., 1964, AUTOMAT REM CONTR, P821; Allwein E.L., 2000, P 17 INT C MACH LEAR, P9; Alon N., 1993, Proceedings. 34th Annual Symposium on Foundations of Computer Science (Cat. No.93CH3368-8), DOI 10.1109/SFCS.1993.366858; ALTUN Y, 2004, P INT C MACH LEARN, P25; Altun Y., 2003, P 20 INT C MACH LEAR, P3; ALTUN Y, 2004, UNCERTAINTY ARTIFICI, P2; ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI 10.2307/1990404; Bach F. R., 2002, J MACHINE LEARNING R, V3, P1; Bakir G. H., 2007, PREDICTING STRUCTURE; BAMBER D, 1975, J MATH PSYCHOL, V12, P387, DOI 10.1016/0022-2496(75)90001-2; BARNDORFFNIELSE.OE, 1978, INFORM EXPONENTIAL F; Bartlett P. L, 2003, J MACHINE LEARNING R, V3, P463; Basilico J. B., 2004, P 21 INT C MACH LEAR, P65; Baum L. E., 1972, INEQUALITIES, V3, P1; Ben-David S, 2003, J COMPUT SYST SCI, V66, P496, DOI 10.1016/S0022-0000(03)00038-2; Bennett K.P, 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; BENNETT KP, 2000, P 17 INT C MACH LEAR, P65; BERG C., 1984, HARMONIC ANAL SEMIGR; BERTSIMAS D, 1997, INTRO LINEAR PROGRAM; Bloomfield P, 1983, LEAST ABSOLUTE DEVIA; Bochner S, 1933, MATH ANN, V108, P378, DOI 10.1007/BF01452844; Borgwardt KM, 2006, BIOINFORMATICS, V22, pE49, DOI 10.1093/bioinformatics/btl242; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Bousquet O., 2005, ESAIM-PROBAB STAT, V9, P323; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Cardoso JF, 1998, P IEEE, V86, P2009, DOI 10.1109/5.720250; Chapelle O., 2005, ADV NEURAL INFORM PR, V17, P257; Chen AY, 2005, IEEE T SIGNAL PROCES, V53, P3625, DOI 10.1109/TSP.2005.855098; Chen S, 1999, SIAM J SCI COMPUT, V20, P33; COLLEDGE B, 2000, INT CONSTRUCTION LAW, V17, P175; Collins M, 2002, ADV NEUR IN, V14, P625; Cook D., 1993, J COMPUTATIONAL GRAP, V2, P225, DOI 10.2307/1390644; Cortes C., 2005, ICML, P153; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Crammer K, 2001, J MACHINE LEARNING R, V2, P265; CRAMMER K, 2005, P ANN C COMP LEARN T, P48; Cristianini N., 2000, INTRO SUPPORT VECTOR; Cristianini N, 2002, ADV NEUR IN, V14, P367; CULOTTA A, 2005, UMCS2005028; DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379; DAS S, 1994, LINEAR ALGEBRA APPL, V210, P29, DOI 10.1016/0024-3795(94)90464-2; Dauxois J, 1998, ANN STAT, V26, P1254; Dawid A. P., 1992, Statistics and Computing, V2, DOI 10.1007/BF01890546; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; Dekel O, 2004, ADV NEUR IN, V16, P497; DellaPietra S, 1997, IEEE T PATTERN ANAL, V19, P380, DOI 10.1109/34.588021; EINMAHL JHJ, 1992, ANN STAT, V20, P1062, DOI 10.1214/aos/1176348670; ELISSEEFF A, 2001, ADV NEURAL INFORM PR, V14, P681; FIEDLER M, 1973, CZECH MATH J, V23, P298; FITZGERALD CH, 1995, LINEAR ALGEBRA APPL, V221, P83, DOI 10.1016/0024-3795(93)00232-O; Fletcher R., 1989, PRACTICAL METHODS OP; Fortet R., 1953, ANN SCI ECOLE NORM S, V70, P266; Freund Y., 1996, P 13 INT C MACH LEAR, P148; FRIEDMAN JH, 1974, IEEE T COMPUT, VC 23, P881, DOI 10.1109/T-C.1974.224051; FRIEDMAN JH, 1987, J AM STAT ASSOC, V82, P249, DOI 10.2307/2289161; Gartner T., 2003, SIGKDD EXPLORATIONS, V5, P49; Green P. J., 1985, LECTURE NOTES STATIS, V32, P44; GRETTON A, 2005, P 10 INT WORKSH ART, P112; Gretton A., 2005, P 16 INT C ALG LEARN, P63; Ham J.H., 2004, P 21 INT C MACH LEAR, P369; Hammersley J., 1971, MARKOV FIELDS UNPUB; Haussler David, 1999, UCSCCRL9910 COMP SCI; Hein M, 2005, J COMPUT SYST SCI, V71, P333, DOI 10.1016/j.jcss.2004.10.013; Herbrich R., 2002, LEARNING KERNEL CLAS; Herbrich R, 2000, ADV NEUR IN, P115; HETTICH R, 1993, SIAM REV, V35, P380, DOI 10.1137/1035089; HILBERT D, 1904, NACHR AKAD WISS GO P, V2, P49; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.2307/1267351; Hofmann T., 2006, 156 MAX PLANCK I BIO; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Huber P. J., 1981, ROBUST STAT; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; Hyvarinen A., 2001, INDEPENDENT COMPONEN; JAAKKOLA TS, 1999, P 7 INT WORKSH A1 ST; Jebara T, 2003, LECT NOTES ARTIF INT, V2777, P57, DOI 10.1007/978-3-540-45167-9_6; Jensen F., 1990, COMPUTATIONAL STATIS, V4, P269; Joachims T., 2005, P 22 INT C MACH LEAR, P377, DOI 10.1145/1102351.1102399; JOACHIMS T., 2002, LEARNING CLASSIFY TE; JONES MC, 1987, J ROY STAT SOC A STA, V150, P1, DOI 10.2307/2981662; JORDAN MI, 2003, 638 U CAL; KARUSH W, 1939, THESIS U CHIC DEP MA; Kashima H., 2003, P 20 INT C MACH LEAR, P321; KETTENRI.JR, 1971, BIOMETRIKA, V58, P433, DOI 10.2307/2334380; Kim KI, 2005, IEEE T PATTERN ANAL, V27, P1351; KIMELDOR.G, 1971, J MATH ANAL APPL, V33, P82, DOI 10.1016/0022-247X(71)90184-3; Koltchinskii V, 2001, IEEE T INFORM THEORY, V47, P1902, DOI 10.1109/18.930926; Kondor I., 2002, P 19 INT C MACH LEAR, P315; Kuhn H. W., 1951, P 2 BERK S MATH STAT, P481; LAFFERTY J, 2004, P INT C MACH LEARN, V21, P64; Lafferty J., 2001, P 18 INT C MACH LEAR, V18, P282; Lee TW, 2000, COMPUT MATH APPL, V39, P1, DOI 10.1016/S0898-1221(00)00101-2; Leslie Christina, 2002, Pac Symp Biocomput, P564; Loeve M., 1978, PROBABILITY THEORY; MAGERMAN DM, 1996, SPRINGER VERLAG LECT, V1147, P1; MANGASAR.OL, 1965, OPER RES, V13, P444, DOI 10.1287/opre.13.3.444; MCCALLUM A, 2005, C IMC AO UAI, V388; McCullagh P., 1983, GEN LINEAR MODELS; Mendelson S., 2003, LECT NOTES COMPUT SC, P1; Mercer J, 1909, PHILOS T R SOC LOND, V209, P415, DOI 10.1098/rsta.1909.0016; Mika S, 2003, IEEE T PATTERN ANAL, V25, P623, DOI 10.1109/TPAMI.2003.1195996; Minsky M., 1969, PERCEPTRONS INTRO CO; Morozov V A, 1984, METHODS SOLVING INCO; Murray M.K., 1993, DIFFERENTIAL GEOMETR; Oliver N, 2000, ADV NEUR IN, P51; OSULLIVAN F, 1986, J AM STAT ASSOC, V81, P96, DOI 10.2307/2287973; Parzen E., 1970, P 12 BIENN SEM CAN M, P1; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; POGGIO T, 1975, BIOL CYBERN, V19, P201, DOI 10.1007/BF00334440; Press W. H., 1994, NUMERICAL RECIPES C; RASMUSSEN CE, 2006, GAUSSIAN PROCESSESFO; Ratsch G, 2007, PLOS COMPUT BIOL, V3, P313, DOI 10.1371/journal.pcbi.0030020; Renyi A., 1959, ACTA MATH ACAD SCI H, V10, P441, DOI 10.1007/BF02024507; Rockafellar R.T., 1970, CONVEX ANAL; Schoenberg IJ, 1938, ANN MATH, V39, P811, DOI 10.2307/1968466; Scholkopf B., 1997, SUPPORT VECTOR LEARN; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565; Scholkopf B., 2002, LEARNING KERNELS; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Scholkopf B, 2004, KERNEL METHODS COMPU; SHA F., 2003, P HLT NAACL, P213; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Smola AJ, 2003, LECT NOTES ARTIF INT, V2777, P144, DOI 10.1007/978-3-540-45167-9_12; Smola AJ, 1998, NEURAL NETWORKS, V11, P637, DOI 10.1016/S0893-6080(98)00032-X; Smola AJ, 1998, ALGORITHMICA, V22, P211, DOI 10.1007/PL00013831; SMOLA AJ, 2000, ADV LARGE MATGIN CLA; Steinwart I, 2002, J MACH LEARN RES, V2, P67; Steinwart I, 2002, J COMPLEXITY, V18, P768, DOI 10.1006/jcom.2002.0642; Stewart J., 1976, ROCKY MOUNTAIN MATH, V6, P409; Stitson MO, 1999, ADVANCES IN KERNEL METHODS, P285; TASKAR B, 2004, EMPIRICAL METHODS NA, V1; Taskar B, 2004, ADV NEUR IN, V16, P25; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tikhonov A. N, 1963, SOV MATH DOKL, V4, P1035; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; van Rijsbergen C. J., 1979, INFORM RETRIEVAL; Vapnik V.N., 1963, Avtomatika i Telemekhanika, V24; Vapnik V, 1997, ADV NEUR IN, V9, P281; Vapnik V., 1982, ESTIMATION DEPENDENC; Vapnik V., 1991, PATTERN RECOGN, V1, P283; Vapnik V. N, 1995, NATURE STAT LEARNING; Vapnik VN, 1998, STAT LEARNING THEORY; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; Verleysen M., 1999, P EUR S ART NEUR NET, P251; VISHWANATHAN SVN, 2004, KERNEL METHODS COMPU, P3; Vishwanathan SVN, 2007, INT J COMPUT VISION, V73, P95, DOI 10.1007/s11263-006-9352-0; WAHBA G., 1990, SPLINE MODELSFOR OBS; Wahba G, 1995, ANN STAT, V23, P1865; WAINWRIGHT M, 2003, 649 U CAL DEP STAT; Watkins C, 2000, ADV NEUR IN, P39; Wendland H, 2005, SCATTERED DATA APPRO; WESTON J, 2003, ADV NEURAL INFORM PR, V15, P873; Whittaker J., 1990, GRAPHICAL MODELS APP; Yang HH, 1997, NEURAL COMPUT, V9, P1457, DOI 10.1162/neco.1997.9.7.1457; Zettlemoyer L. S., 2005, UAI, P658; Zien A, 2000, BIOINFORMATICS, V16, P799, DOI 10.1093/bioinformatics/16.9.799	157	71	76	INST MATHEMATICAL STATISTICS	BEACHWOOD	PO BOX 22718, BEACHWOOD, OH 44122 USA	0090-5364		ANN STAT	Ann. Stat.	JUN	2008	36	3					1171	1220		10.1214/009053607000000677		50	Statistics & Probability	Mathematics	310BR	WOS:000256504400007	
J	Chen, XJ; Li, Y; Harrison, R; Zhang, YQ				Chen, Xiujuan; Li, Yong; Harrison, Robert; Zhang, Yan-Qing			Type-2 fuzzy logic-based classifier fusion for support vector machines	APPLIED SOFT COMPUTING			English	Article; Proceedings Paper	BISC International Special Event on Forging the Frontiers (BISCSE'05)	NOV 03-06, 2005	Berkeley, CA		Univ Calif Berkeley	type-2 FLS; fuzzy logic; support vector machines (SVMs); classifier fusion; classification; machine-learning	SYSTEMS; SETS	As a machine-learning tool, support vector machines (SVMs) have been gaining popularity due to their promising performance. However, the generalization abilities of SVMs often rely on whether the selected kernel functions are suitable for real classification data. To lessen the sensitivity of different kernels in SVMs classification and improve SVMs generalization ability, this paper proposes a fuzzy fusion model to combine multiple SVMs classifiers. To better handle uncertainties existing in real classification data and in the membership functions (MFs) in the traditional type-1 fuzzy logic system (FLS), we apply interval type-2 fuzzy sets to construct a type-2 SVMs fusion FLS. This type-2 fusion architecture takes considerations of the classification results from individual SVMs classifiers and generates the combined classification decision as the output. Besides the distances of data examples to SVMs hyperplanes, the type-2 fuzzy SVMs fusion system also considers the accuracy information of individual SVMs. Our experiments show that the type-2 based SVM fusion classifiers outperform individual SVM classifiers in most cases. The experiments also show that the type-2 fuzzy logic-based SVMs fusion model is better than the type-1 based SVM fusion model in general. (C) 2007 Elsevier B.V. All rights reserved.	[Chen, Xiujuan; Li, Yong; Harrison, Robert; Zhang, Yan-Qing] Georgia State Univ, Dept Comp Sci, Atlanta, GA 30302 USA	Chen, XJ (reprint author), Georgia State Univ, Dept Comp Sci, POB 3994, Atlanta, GA 30302 USA.	xchen8@gsu.edu					Aguero JR, 2005, IEEE T POWER SYST, V20, P1551, DOI 10.1109/TPWRS.2005.852090; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Hagras HA, 2004, IEEE T FUZZY SYST, V12, P524, DOI 10.1109/TFUZZ.2004.832538; Joachims T., 1999, MAKING LARGE SCALE S; John RI, 1998, INT J UNCERTAIN FUZZ, V6, P563, DOI 10.1142/S0218488598000434; KARNIK N.N., 1998, P 1998 IEEE FUZZ C A, P915; Karnik NN, 1999, IEEE T FUZZY SYST, V7, P643, DOI 10.1109/91.811231; Kittler J., 1998, IEEE T PATTERN ANAL, V20; Li J., 2003, KENT RIDGE BIOMEDICA; Liang QL, 2000, IEEE T SYST MAN CY C, V30, P329, DOI 10.1109/5326.885114; Liang QL, 2000, IEEE T FUZZY SYST, V8, P535; Liang QL, 2001, IEEE T FUZZY SYST, V9, P183; Mendel J., 2001, UNCERTAIN RULE BASED; Mendel JM, 2002, IEEE T FUZZY SYST, V10, P117, DOI 10.1109/91.995115; Vapnik V. N, 1995, NATURE STAT LEARNING; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; Zeng J, 2006, IEEE T FUZZY SYST, V14, P454, DOI 10.1109/TFUZZ.2006.876366	18	27	30	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1568-4946		APPL SOFT COMPUT	Appl. Soft. Comput.	JUN	2008	8	3					1222	1231		10.1016/j.asoc.2007.02.019		10	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	273TH	WOS:000253954100007	
J	Mal'kov, KV; Tunitskii, DV				Mal'kov, K. V.; Tunitskii, D. V.			On one extremal problem of adaptive machine learning for detection of anomalies	AUTOMATION AND REMOTE CONTROL			English	Article								An adaptive algorithm to solve a wide range of problems of unsupervised learning by constructing a sequence of interrelated extremal principles was proposed. The least squares method with a priori defined weights used as a starting point enabled determination of the "center" of learning sample. Next, a natural passage from the least squares method to more flexible extremal principle enabling adaptive determination of both the "center" and weights of the learning sample events was performed. Finally, a universal extremal principle enabling determination of the scaling coefficient of the membership function in addition to the "center" and weights was constructed.	[Mal'kov, K. V.] PWI Inc, New York, NY USA; [Tunitskii, D. V.] Russian Acad Sci, Trapeznikov Inst Control Sci, Moscow, Russia	Mal'kov, KV (reprint author), PWI Inc, New York, NY USA.						AIZERMAN MA, 1970, METOD POTENTSIALNYKH; Ben-Hur A, 2001, J MACHINE LEARNING R, V2, P125; BOTTOMLEY L, 2003, DATASET DAY HTTP LOG; CHANG C. C., LIBSVM LIB SUPPORT V; Dumitrescu D, 2000, FUZZY SETS THEIR APP; Haussler David, 1999, UCSCCRL9910 COMP SCI; Herbrich R., 2002, LEARNING KERNEL CLAS; MASHECHKIN I, 2005, ICEIS, P188; Petrovskiy M, 2003, LECT NOTES COMPUT SC, V2877, P189; Petrovskiy M, 2003, LECT NOTES ARTIF INT, V2663, P318; PETROVSKIY MI, 2003, PROGRAM COMP SOFTW, V29; Scholkopf B., 2002, LEARNING KERNELS SUP; Tikhonov A. N., 1986, METODY RESHENIYA NEK; *PRIV, 2005, AD SEC AN PRO; *QUEST SOFTW, 2005, INTRUST WIND	15	1	1	MAIK NAUKA/INTERPERIODICA/SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013-1578 USA	0005-1179		AUTOMAT REM CONTR+	Autom. Remote Control	JUN	2008	69	6					942	952		10.1134/S0005117908060052		11	Automation & Control Systems; Instruments & Instrumentation	Automation & Control Systems; Instruments & Instrumentation	325LQ	WOS:000257590800004	
J	Prado-Prado, FJ; Gonzalez-Diaz, H; de la Vega, OM; Ubeira, FM; Chou, KC				Prado-Prado, Francisco J.; Gonzalez-Diaz, Humberto; Martinez de la Vega, Octavio; Ubeira, Florencio M.; Chou, Kuo-Chen			Unified QSAR approach to antimicrobials. Part 3: First multi-tasking QSAR model for Input-Coded prediction, structural back-projection, and complex networks clustering of antiprotozoal compounds	BIOORGANIC & MEDICINAL CHEMISTRY			English	Article						QSAR; multi-tasking learning; machine learning; complex networks; antiparasite drugs; Markov Chain Model; malaria; Plasmodium; Leishmania; Toxoplasma; Trypanosoma; Trichomonas	COMPUTATIONAL CHEMISTRY APPROACH; IN-SILICO DESIGN; TOPS-MODE; PROMISING APPROACH; LINEAR INDEXES; DIHYDROFOLATE-REDUCTASE; ANTIMALARIAL COMPOUNDS; TYROSINASE INHIBITORS; CONNECTIVITY INDEXES; TOPOLOGICAL INDEXES	Several pathogen parasite species show different susceptibilities to different antiparasite drugs. Unfortunately, almost all structure-based methods are one-task or one-target Quantitative Structure-Activity Relationships (ot-QSAR) that predict the biological activity of drugs against only one parasite species. Consequently, multi-tasking learning to predict drugs activity against different species by a single model (mt-QSAR) is vitally important. In the two previous works of the present series we reported two single mt-QSAR models in order to predict the antimicrobial activity against different fungal (Bioorg. Med. Chem. 2006, 14, 5973-5980) or bacterial species (Bioorg. Med. Chem. 2007, 15, 897-902). These mt-QSARs offer a good opportunity (unpractical with ot-QSAR) to construct drug-drug similarity Complex Networks and to map the contribution of sub-structures to function for multiple species. These possibilities were unattended in our previous works. In the present work, we continue this series toward other important direction of chemotherapy (antiparasite drugs) with the development of an mt-QSAR for more than 500 drugs tested in the literature against different parasites. The data were processed by Linear Discriminant Analysis (LDA) classifying drugs as active or non-active against the different tested parasite species. The model correctly classifies 212 out of 244 (87.0%) cases in training series and 207 out of 243 compounds (85.4%) in external validation series. In order to illustrate the performance of the QSAR for the selection of active drugs we carried out an additional virtual screening of antiparasite compounds not used in training or predicting series; the model recognized 97 out of 114 (85.1%) of them. We also give the procedures to construct back-projection maps and to calculate sub-structures contribution to the biological activity. Finally, we used the outputs of the QSAR to construct, by the first time, a multi-species Complex Networks of antiparasite drugs. The network predicted has 380 nodes (compounds), 634 edges (pairs of compounds with similar activity). This network allows us to cluster different compounds and identify on average three known compounds similar to a new query compound according to their pro. le of biological activity. This is the first attempt to calculate probabilities of antiparasitic action of drugs against different parasites. (C) 2008 Elsevier Ltd. All rights reserved.	[Prado-Prado, Francisco J.; Gonzalez-Diaz, Humberto; Ubeira, Florencio M.] Univ Santiago Compostela, Unit Bioinformat & Connect Anal UBICA, Dept Microbiol & Parasitol, Fac Pharm,Inst Ind Pharm, Santiago De Compostela 15782, Spain; [Prado-Prado, Francisco J.; Martinez de la Vega, Octavio] LANGEBIO, CINVESTAV, Dept Bioinformat, Irapuato 62936500, Mexico; [Gonzalez-Diaz, Humberto; Chou, Kuo-Chen] Gordon Life Sci Inst, San Diego, CA 92130 USA	Gonzalez-Diaz, H (reprint author), Univ Santiago Compostela, Unit Bioinformat & Connect Anal UBICA, Dept Microbiol & Parasitol, Fac Pharm,Inst Ind Pharm, Santiago De Compostela 15782, Spain.	gonzalezdiazh@yahoo.es	Prado-Prado, Francisco/B-8335-2012; Gonzalez-Diaz, Humberto/A-6785-2012; Chou, Kuo-Chen/A-8340-2009	Gonzalez-Diaz, Humberto/0000-0002-9392-2797; 			ALVAREZGINARTE YM, 2007, J COMPUT CHEM; Barabasi AL, 2005, SCIENCE, V308, P639, DOI 10.1126/science.1112554; Bermudez CI, 1999, J THEOR BIOL, V197, P193, DOI 10.1006/jtbi.1998.0866; Boccaletti S, 2006, PHYS REP, V424, P175, DOI 10.1016/j.physrep.2005.10.009; Casanola-Martin GM, 2007, EUR J MED CHEM, V42, P1370, DOI 10.1016/j.ejmech.2007.01.026; Casahola-Martin GM, 2007, BIOORGAN MED CHEM, V15, P1483, DOI 10.1016/j.bmc.2006.10.067; Castillo-Garit JA, 2007, J MOL GRAPH MODEL, V26, P32, DOI 10.1016/j.jmgm.2006.09.007; Castillo-Garit JA, 2006, BIOORGAN MED CHEM, V14, P2398, DOI 10.1016/j.bmc.2005.11.024; Chou KC, 2006, CURR MED CHEM, V13, P3263, DOI 10.2174/092986706778773077; Chou KC, 2004, CURR MED CHEM, V11, P2105; Cooke BM, 2004, SEMIN HEMATOL, V41, P173, DOI 10.1053/j.seminhematol.2004.01.004; Cruz-Monteagudo M, 2006, B MATH BIOL, V68, P1527, DOI 10.1007/s11538-005-9013-4; Cruz-Monteagudo M, 2005, EUR J MED CHEM, V40, P1030, DOI 10.1016/j.ejmech.2005.04.012; Cruz-Monteagudo M, 2008, CHEM RES TOXICOL, V21, P619, DOI 10.1021/tx700296t; CURZMONTEAGUDO M, 2007, J COMPUT CHEM, V28, P1909; DAMOS D, 1982, AVIAT SPACE ENVIR MD, V53, P1177; Diaz HG, 2002, J MOL MODEL, V8, P237, DOI 10.1007/s00894-002-0088-7; Du QS, 2005, J COMPUT CHEM, V26, P461, DOI 10.1002/jcc.20174; Erhan D, 2006, J CHEM INF MODEL, V46, P626, DOI 10.1021/ci050367t; Estrada E, 2001, CURR MED CHEM, V8, P1573; Estrada E, 2006, PROTEOMICS, V6, P35, DOI 10.1002/pmic.200500209; Estrada E, 2004, MOL DIVERS, V8, P21, DOI 10.1023/B:MODI.0000006804.97390.40; Estrada E, 2003, J CHEM INF COMP SCI, V43, P75, DOI 10.1021/ci025604w; Gangjee A, 2005, J MED CHEM, V48, P1448, DOI 10.1021/jm040153n; Garcia-Garcia A, 2004, J ANTIMICROB CHEMOTH, V53, P65, DOI 10.1093/jac/dkh014; Gia O, 2005, BIOORGAN MED CHEM, V13, P809, DOI 10.1016/j.bmc.2004.10.044; Gonzalez MP, 2003, J COMPUT AID MOL DES, V17, P665, DOI 10.1023/B:JCAM.0000017373.50020.41; Gonzalez MP, 2004, BIOORGAN MED CHEM, V12, P4467, DOI 10.1016/j.bmc.2004.05.035; Gonzalez-Diaz H, 2007, J COMPUT CHEM, V28, P1990, DOI 10.1002/jcc.20700; Gonzalez-Diaz H, 2007, BIOORGAN MED CHEM, V15, P2544, DOI 10.1016/j.bmc.2007.01.050; Gonzalez-Diaz H, 2007, J COMPUT CHEM, V28, P1049, DOI 10.1002/jcc.20576; Gonzalez-Diaz H., 2007, MARCH INSIDE V3 0 MA; Gonzalez-Diaz H, 2007, J PROTEOME RES, V6, P904, DOI 10.1021/pr060493s; Gonzalez-Diaz H., 2003, COMPUT BIOL CHEM, V27, P217; Gonzalez-Diaz H, 2007, BIOORGAN MED CHEM, V15, P962, DOI 10.1016/j.bmc.2006.10.032; Gonzalez-Diaz H, 2006, BIOORGAN MED CHEM, V14, P5973, DOI 10.1016/j.bmc.2006.05.018; Gonzalez Diaz H., 2004, Bulletin of Mathematical Biology, V66, P1285; Gonzalez-Diaz H, 2007, J COMPUT CHEM, V28, P1042, DOI 10.1002/jcc.20649; Gonzalez-Diaz H, 2006, J INORG BIOCHEM, V100, P1290, DOI 10.1016/j.jinorgbio.2006.02.019; Gonzalez-Diaz H, 2008, J COMPUT CHEM, V29, P656, DOI 10.1002/jcc.20826; Gonzalez-Diaz H., 2007, CURR TOP MED CHEM, V7, P1025; Gonzalez-Diaz H, 2008, PROTEOMICS, V8, P750, DOI 10.1002/pmic.200700638; Gonzales-Diaz H, 2003, J MOL MODEL, V9, P395, DOI 10.1007/s00894-003-0148-7; Gozalbes R, 1999, SAR QSAR ENVIRON RES, V10, P47, DOI 10.1080/10629369908039165; Gupta A, 2006, BIOINFORMATICS, V22, P209, DOI 10.1093/bioinformatics/bti780; Hasegawa K, 2002, COMPUT CHEM, V26, P583, DOI 10.1016/S0097-8485(02)00023-2; Helguera AM, 2005, BIOORGAN MED CHEM, V13, P2477, DOI 10.1016/j.bmc.2005.01.035; Hill T., 2006, STAT METHODS APPL CO; Honey CJ, 2007, P NATL ACAD SCI USA, V104, P10240, DOI 10.1073/pnas.0701519104; Hopfinger AJ, 1997, J AM CHEM SOC, V119, P10509, DOI 10.1021/ja9718937; Ling Y, 2005, J MED CHEM, V48, P3130, DOI 10.1021/jm040132t; Marrero-Ponce Y, 2007, CHEMMEDCHEM, V2, P449, DOI 10.1002/cmdc.200600186; Marrero-Ponce Y, 2005, BIOORGAN MED CHEM, V13, P1293, DOI 10.1016/j.bmc.2004.11.008; Marrero-Ponce Y, 2005, BIOORGAN MED CHEM, V13, P1005, DOI 10.1016/j.bmc.2004.11.040; Marrero-Ponce Y., 2004, INT J MOL SCI, V5, P276; Marrero-Ponce Y, 2005, J CHEM INF MODEL, V45, P1082, DOI 10.1021/ci050085t; Maslovat D, 2004, MOTOR CONTROL, V8, P213; Mattioni BE, 2003, J MOL GRAPH MODEL, V21, P391, DOI 10.1016/S1093-3263(02)00187-0; Meneses-Marcel A, 2005, BIOORG MED CHEM LETT, V15, P3838, DOI 10.1016/j.bmcl.2005.05.124; Pae AN, 1999, BIOORG MED CHEM LETT, V9, P2685, DOI 10.1016/S0960-894X(99)00474-6; Prado-Prado FJ, 2007, BIOORGAN MED CHEM, V15, P897, DOI 10.1016/j.bmc.2006.10.039; Saiz-Urra L, 2007, EUR J MED CHEM, V42, P64, DOI 10.1016/j.ejmech.2006.08.005; Saiz-Urra L, 2007, J MOL GRAPH MODEL, V25, P680, DOI 10.1016/j.jmgm.2006.05.006; Vilar S, 2006, J MED CHEM, V49, P1118, DOI 10.1021/jm050932j; Stiefl N, 2003, J MED CHEM, V46, P1390, DOI 10.1021/jm021077w; Stiefl N, 2005, J CHEM INF MODEL, V45, P739, DOI 10.1021/ci049683i; Todeschini R., 2002, HDB MOL DESCRIPTORS; Van Miert S, 2005, BIOORGAN MED CHEM, V13, P661, DOI 10.1016/j.bmc.2004.10.058; Vilar S, 2005, J CHEM INF MODEL, V45, P502, DOI 10.1021/ci049662o; Yi BM, 2002, J CHEM INF COMP SCI, V42, P1221, DOI 10.1021/ci025509n; Yook SH, 2002, P NATL ACAD SCI USA, V99, P13382, DOI 10.1073/pnas.172501399; Yu XP, 2006, NUCLEIC ACIDS RES, V34, P4925, DOI 10.1093/nar/gkl595; *STATSOFT INC, 2002, STATISTICA DAT AN SO	73	141	142	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0968-0896		BIOORGAN MED CHEM	Bioorg. Med. Chem.	JUN 1	2008	16	11					5871	5880		10.1016/j.bmc.2008.04.068		10	Biochemistry & Molecular Biology; Chemistry, Medicinal; Chemistry, Organic	Biochemistry & Molecular Biology; Pharmacology & Pharmacy; Chemistry	308HD	WOS:000256378200004	
J	Jia, L; Sun, H				Jia, Lei; Sun, Hongmao			Support vector machines classification of hERG liabilities based on atom types	BIOORGANIC & MEDICINAL CHEMISTRY			English	Article						HERG prediction; SVM; atom typing	QT INTERVAL PROLONGATION; POTASSIUM CHANNEL AFFINITY; TORSADE-DE-POINTES; DRUG DEVELOPMENT; CARDIAC-ARRHYTHMIA; K+ CHANNEL; CRYSTAL-STRUCTURE; PREDICTION; KNOWLEDGE; SAFETY	Drug-induced long QT syndrome (LQTS) can cause critical cardiovascular side effects and has accounted for the withdrawal of several drugs from the market. Blockade of the potassium ion channel encoded by the human ether-a-go-go-related gene (hERG) has been identified as a major contributor to drug-induced LQTS. Experimental measurement of hERG activity for each compound in development is costly and time-consuming, thus it is beneficial to develop a predictive hERG model. Here, we present a hERG classfication model formulated using support vector machines (SVM) as machine learning method and using atom types as molecular descriptors. The training set used in this study was composed of 977 corporate compounds with hERG activities measured under the same conditions. The impact of soft margin and kernel function on the performance of the SVM models was examined. The robustness of SVM was evaluated by comparing the predictive power of the models built with 90%, 50%, and 10% of the training set data. The final SVM model was able to correctly classify 94% of an external testing set containing 66 drug molecules. The most important atom types with respect to discriminative power were extracted and analyzed. (C) 2008 Elsevier Ltd. All rights reserved.	[Jia, Lei; Sun, Hongmao] Hoffmann La Roche Inc, Dept Discovery Chem, Nutley, NJ 07110 USA	Sun, H (reprint author), Hoffmann La Roche Inc, Dept Discovery Chem, 340 Kingsland St, Nutley, NJ 07110 USA.	Hongmao.sun@roche.com					Aptula AO, 2004, SAR QSAR ENVIRON RES, V15, P399, DOI 10.1080/10629360412331297353; Aronov Alex M, 2005, Drug Discov Today, V10, P149, DOI 10.1016/S1359-6446(04)03278-7; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Burbidge R, 2001, COMPUT CHEM, V26, P5, DOI 10.1016/S0097-8485(01)00094-8; Chen X., 2007, Cardiovascular & Hematological Agents in Medicinal Chemistry, V5, P11; Cianchetta G, 2005, BIOORG MED CHEM LETT, V15, P3637, DOI 10.1016/j.bmcl.2005.03.062; Coi A, 2006, BIOORGAN MED CHEM, V14, P3153, DOI 10.1016/j.bmc.2005.12.030; Cristianini N., 2000, INTRO SUPPORT VECTOR; Crumb W, 1999, PHARM SCI TECHNOL TO, V2, P270, DOI 10.1016/S1461-5347(99)00172-8; CURRAN ME, 1995, CELL, V80, P795, DOI 10.1016/0092-8674(95)90358-5; De Ponti F, 2002, DRUG SAFETY, V25, P263; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; GANETZKY B, 1983, Journal of Neurogenetics, V1, P17, DOI 10.3109/01677068309107069; Gavaghan CL, 2007, J COMPUT AID MOL DES, V21, P189, DOI 10.1007/s10822-006-9095-6; Gepp MM, 2006, BIOORGAN MED CHEM, V14, P5325, DOI 10.1016/j.bmc.2006.03.043; Guo Liang, 2005, Journal of Pharmacological and Toxicological Methods, V52, P123, DOI 10.1016/j.vascn.2005.04.002; Jiang YX, 2003, NATURE, V423, P33, DOI 10.1038/nature01580; Jiang YX, 2002, NATURE, V417, P515, DOI 10.1038/417515a; Keseru GM, 2003, BIOORG MED CHEM LETT, V13, P2773, DOI 10.1016/S0960-894X(03)00492-X; Kola I, 2004, NAT REV DRUG DISCOV, V3, P711, DOI 10.1038/nrd1470; LANG L, 2004, GASTROENTEROLOGY, V127, P1026, DOI 10.1053/j.gastro.2004.08.066; Leong MK, 2007, CHEM RES TOXICOL, V20, P217, DOI 10.1021/tx060230c; Lipinski CA, 2001, ADV DRUG DELIVER REV, V46, P3, DOI 10.1016/S0169-409X(00)00129-0; Long SB, 2005, SCIENCE, V309, P897, DOI 10.1126/science.1116269; Netzer R, 2001, DRUG DISCOV TODAY, V6, P78, DOI 10.1016/S1359-6446(00)01602-0; Noble W. S., 2004, KERNEL METHODS COMPU; Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565; OBREZANOVA O, 2007, J CHEM INF MODEL; Pavlidis P, 2004, BIOINFORMATICS, V20, P586, DOI 10.1093/bioinformatics/btg461; Recanatini M, 2005, MED RES REV, V25, P133, DOI 10.1002/med.20019; Redfern WS, 2003, CARDIOVASC RES, V58, P32, DOI 10.1016/S0008-6363(02)00846-5; Roche O, 2002, CHEMBIOCHEM, V3, P455, DOI 10.1002/1439-7633(20020503)3:5<455::AID-CBIC455>3.0.CO;2-L; Rognvaldsson T, 2004, BIOINFORMATICS, V20, P1702, DOI 10.1093/bioinformatics/bth144; SANGUINETTI MC, 1995, CELL, V81, P299, DOI 10.1016/0092-8674(95)90340-2; Sanguinetti MC, 2006, NATURE, V440, P463, DOI 10.1038/nature04710; Song MH, 2006, J CHEM INF MODEL, V46, P392, DOI 10.1021/ci050308f; Sun HM, 2005, J MED CHEM, V48, P4031, DOI 10.1021/jm050180t; Sun HM, 2004, J CHEM INF COMP SCI, V44, P748, DOI 10.1021/ci030304f; Sun HM, 2006, CHEMMEDCHEM, V1, P315, DOI 10.1002/cmdc.200500047; Thomas D, 2006, CURR PHARM DESIGN, V12, P2271, DOI 10.2174/138161206777585102; Tobita M, 2005, BIOORG MED CHEM LETT, V15, P2886, DOI 10.1016/j.bmcl.2005.03.080; TRUDEAU MC, 1995, SCIENCE, V269, P92, DOI 10.1126/science.7604285; Vapnik VN, 1998, STAT LEARNING THEORY; Vapnik V.N., 1995, STAT LEARNING THEORY; Vincent GM, 2001, J CARDIOVASC ELECTR, V12, P546, DOI 10.1046/j.1540-8167.2001.00546.x; Whitebread S, 2005, DRUG DISCOV TODAY, V10, P1421, DOI 10.1016/S1359-6446(05)03632-9; Witchel HJ, 2007, EXPERT OPIN THER TAR, V11, P321, DOI 10.1517/14728222.11.3.321; Wood C, 2004, DRUG DISCOV TODAY, V9, P434, DOI 10.1016/S1359-6446(04)03064-8	48	19	19	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0968-0896		BIOORGAN MED CHEM	Bioorg. Med. Chem.	JUN 1	2008	16	11					6252	6260		10.1016/j.bmc.2008.04.028		9	Biochemistry & Molecular Biology; Chemistry, Medicinal; Chemistry, Organic	Biochemistry & Molecular Biology; Pharmacology & Pharmacy; Chemistry	308HD	WOS:000256378200042	
J	Townsend, KA; Wollstein, G; Danks, D; Sung, KR; Ishikawa, H; Kagemann, L; Gabriele, ML; Schuman, JS				Townsend, K. A.; Wollstein, G.; Danks, D.; Sung, K. R.; Ishikawa, H.; Kagemann, L.; Gabriele, M. L.; Schuman, J. S.			Heidelberg Retina Tomograph 3 machine learning classifiers for glaucoma detection	BRITISH JOURNAL OF OPHTHALMOLOGY			English	Article; Proceedings Paper	Annual Meeting of the Association-for-Research-in-Vision-and-Ophthalmology	MAY 06-10, 2007	Ft Lauderdale, FL	Assoc Res Vis & Ophthalmol			HEIDELBERG RETINA TOMOGRAPH; OPTICAL COHERENCE TOMOGRAPHY; NERVE-FIBER LAYER; PROBABILITY SCORE; AUTOMATED-ANALYSIS; DISC IMAGES; DIAGNOSIS	Aims: To assess performance of classifiers trained on Heidelberg Retina Tomograph 3 (HRT3) parameters for discriminating between healthy and glaucomatous eyes. Methods: Classifiers were trained using HRT3 parameters from 60 healthy subjects and 140 glaucomatous subjects. The classifiers were trained on all 95 variables and smaller sets created with backward elimination. Seven types of classifiers, including Support Vector Machines with radial basis (SVM-radial), and Recursive Partitioning and Regression Trees (RPART), were trained on the parameters. The area under the ROC curve (AUC) was calculated for classifiers, individual parameters and HRT3 glaucoma probability scores (GPS). Classifier AUCs and leave-one-out accuracy were compared with the highest individual parameter and GPS AUCs and accuracies. Results: The highest AUC and accuracy for an individual parameter were 0.848 and 0.79, for vertical cup/disc ratio (vC/D). For GPS, global GPS performed best with AUC 0.829 and accuracy 0.78. SVM-radial with all parameters showed significant improvement over global GPS and vC/D with AUC 0.916 and accuracy 0.85. RPART with all parameters provided significant improvement over global GPS with AUC 0.899 and significant improvement over global GPS and vC/D with accuracy 0.875. Conclusions: Machine learning classifiers of HRT3 data provide significant enhancement over current methods for detection of glaucoma.	[Townsend, K. A.; Wollstein, G.; Sung, K. R.; Ishikawa, H.; Kagemann, L.; Gabriele, M. L.; Schuman, J. S.] Univ Pittsburgh, Sch Med, UPMC Eye Ctr,Ophthalmol & Visual Sci Res Ctr, Inst Eye & Ear,Dept Ophthalmol, Pittsburgh, PA 15213 USA; [Danks, D.] Carnegie Mellon Univ, Dept Philosophy, Pittsburgh, PA 15213 USA; [Danks, D.] Inst Human & Machine Cognit, Pensacola, FL USA	Schuman, JS (reprint author), Univ Pittsburgh, Sch Med, UPMC Eye Ctr,Ophthalmol & Visual Sci Res Ctr, Inst Eye & Ear,Dept Ophthalmol, 203 Lothrop St,Suite 816, Pittsburgh, PA 15213 USA.	schumanjs@upmc.edu	Schuman, Joel/K-7304-2012; Kagemann, Larry/B-6255-2013	Kagemann, Larry/0000-0001-8961-0187			Bowd C, 2002, INVEST OPHTH VIS SCI, V43, P3444; Breiman L, 1984, CLASSIFICATION REGRE; Burgansky-Eliash Z, 2007, OPHTHALMOLOGY, V114, P466, DOI 10.1016/j.ophtha.2006.08.022; Burgansky-Eliash Z, 2005, INVEST OPHTH VIS SCI, V46, P4147, DOI 10.1167/iovs.05-0366; Coops A, 2006, INVEST OPHTH VIS SCI, V47, P5348, DOI 10.1167/iovs.06-0579; DeLeon-Ortega JE, 2006, INVEST OPHTH VIS SCI, V47, P3374, DOI 10.1167/iovs.05-1239; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; Ferreras A, 2007, OPHTHALMOLOGY, V114, P1981, DOI 10.1016/j.ophtha.2007.01.015; Fisher RA, 1936, ANN EUGENIC, V7, P179; Garway-Heath DF, 1999, BRIT J OPHTHALMOL, V83, P664, DOI 10.1136/bjo.83.6.664; HASTIE T, 1990, GEN ADDITIVE MODELS, V43, P352; Huang ML, 2005, INVEST OPHTH VIS SCI, V46, P4121, DOI 10.1167/iovs.050069; Iester M, 2001, AM J OPHTHALMOL, V132, P57, DOI 10.1016/S0002-9394(01)00938-2; Mardin CY, 2006, J GLAUCOMA, V15, P299, DOI 10.1097/01.ijg.0000212232.03664.ee; McCullagh P., 1989, GEN LINEAR MODELS; QUIGLEY HA, 1992, OPHTHALMOLOGY, V99, P19; SOMMER A, 1977, ARCH OPHTHALMOL-CHIC, V95, P2149; SOMMER A, 1991, ARCH OPHTHALMOL-CHIC, V109, P77; Swindale NV, 2000, INVEST OPHTH VIS SCI, V41, P1730; Vapnik V, 1998, STAT LEARNING THEORY, P401; Wollstein G, 1998, OPHTHALMOLOGY, V105, P1557, DOI 10.1016/S0161-6420(98)98047-2; Zangwill LM, 2004, INVEST OPHTH VIS SCI, V45, P3144, DOI 10.1167/iovs.04-0202; Zangwill LM, 2007, INVEST OPHTH VIS SCI, V48, P2653, DOI 10.1167/iovs.06-1314; Zangwill LM, 2001, ARCH OPHTHALMOL-CHIC, V119, P985	24	5	5	B M J PUBLISHING GROUP	LONDON	BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND	0007-1161		BRIT J OPHTHALMOL	Br. J. Ophthalmol.	JUN	2008	92	6					814	818		10.1136/bjo.2007.133074		5	Ophthalmology	Ophthalmology	308RJ	WOS:000256407400021	
J	Marquez, L; Carreras, X; Litkowski, KC; Stevenson, S				Marquez, Lluis; Carreras, Xavier; Litkowski, Kenneth C.; Stevenson, Suzanne			Semantic role labeling: An introduction to the special issue	COMPUTATIONAL LINGUISTICS			English	Editorial Material							CLASSIFICATION	Semantic role labeling, the computational identification and labeling of arguments in text, has become a leading task in computational linguistics today. Although the issues for this task have been studied for decades, the availability of large resources and the development of statistical machine learning methods have heightened the amount of effort in this field. This special issue presents selected and representative work in the field. This overview describes linguistic background of the problem, the movement from linguistic theories to computational practice, the major resources that are being used, an overview of steps taken in computational systems, and a description of the key issues and results in semantic role labeling (as revealed in several international evaluations). We assess weaknesses in semantic role labeling and identify important challenges facing the field. Overall, the opportunities and the potential for useful further research in semantic role labeling are considerable.	[Marquez, Lluis] Univ Politecn Cataluna, Dept Llenguatges & Sistemes Informat, ES-08034 Barcelona, Spain; [Carreras, Xavier] MIT, CSAIL, Cambridge, MA 02139 USA; [Litkowski, Kenneth C.] CL Res, Damascus, MD 20872 USA; [Stevenson, Suzanne] Dept Comp Sci, Toronto, ON M5S 3G4, Canada	Marquez, L (reprint author), Univ Politecn Cataluna, Dept Llenguatges & Sistemes Informat, Jiordi Girona Salgado 1-3, ES-08034 Barcelona, Spain.	lluism@lsi.upc.edu; carreras@csail.mit.edu; ken@clres.com; suzanne@cs.toronto.edu					Baker C., 2007, P 4 INT WORKSH SEM E, P99, DOI 10.3115/1621474.1621492; BOAS HC, 2002, P 3 INT C LANG RES E, P1364; BRISCOE T, 1997, P 5 ACL C APPL NAT L, P356, DOI 10.3115/974557.974609; Carreras X., 2004, P 8 C COMP NAT LANG, P89; CARRERAS X, 2004, P 8 C COMP NAT LANG, P106; Carreras X., 2005, P 9 C COMP NAT LANG, P152, DOI 10.3115/1706543.1706571; Cohn T., 2005, P 9 C COMP NAT LANG, P169, DOI 10.3115/1706543.1706573; Copestake A., 2000, P 2 C LANG RES EV LR, P591; DOWTY D, 1991, LANGUAGE, V67, P547, DOI 10.2307/415037; ERK K, 2007, P 45 ANN M ASS COMP, P216; FILLMORE CJ, 1976, ANN NY ACAD SCI, V280, P20, DOI 10.1111/j.1749-6632.1976.tb25467.x; Fillmore Charles J., 1968, UNIVERSALS LINGUIST, P1; FILLMORE CJ, 2004, FRONTIERS LINGUISTIC, V1, P19; Gildea D, 2002, COMPUT LINGUIST, V28, P245, DOI 10.1162/089120102760275983; Grimshaw Jane, 1990, ARGUMENT STRUCTURE; Habash N., 2003, Machine Translation, V18, DOI 10.1023/B:COAT.0000020960.27186.18; Hirst G., 1987, SEMANTIC INTERPRETAT; im Walde S. S., 2006, Computational Linguistics, V32, DOI 10.1162/coli.2006.32.2.159; Jackendoff Ray, 1990, SEMANTIC STRUCTURES; Johansson R., 2007, P 4 INT WORKSH SEM E, P227, DOI 10.3115/1621474.1621522; KIPPER K, 2000, P 17 NAT C ART INT A; Koomen P., 2005, P 9 C COMP NAT LANG, P181, DOI 10.3115/1706543.1706576; Levin B., 2005, ARGUMENT REALIZATION; Levin B., 1998, PROJECTION ARGUMENTS, P97; Levin Beth, 1993, ENGLISH VERB CLASSES; Litkowski K., 2007, P 4 INT WORKSH SEM E, P24, DOI 10.3115/1621474.1621479; LITKOWSKI KC, 2004, P 3 INT WORKSH EV SY, P9; LITKOWSKI KC, 2005, P ACL SIGSEM WORKSH, P171; LOPER E, 2007, P 7 INT WORKSH COMP, P118; MARQUEZ L, 2007, P 4 INT WORKSH SEM E, P42, DOI 10.3115/1621474.1621482; Marquez L., 2005, P 9 C COMP NAT LANG, P193, DOI 10.3115/1706543.1706579; MELLI G, 2005, P HLT EMNLP DOC UND; Merlo P, 2001, COMPUT LINGUIST, V27, P373, DOI 10.1162/089120101317066122; MEYERS A, 2004, P HLT NAACL 2004 WOR, P24; Moldovan D. A., 2004, P COMP LEX SEM WORKS, P60, DOI 10.3115/1596431.1596440; MUSILLO G, 2006, P HUM LANG TECHN C N, P101, DOI 10.3115/1614049.1614075; NARAYANAN S, 2004, P 20 INT C COMP LING, P693, DOI 10.3115/1220355.1220455; OHARA T, 2003, P 7 C NAT LANG LEARN, P79; Palmer M, 2005, COMPUT LINGUIST, V31, P71, DOI 10.1162/0891201053630264; Pradhan S., 2007, P 4 INT WORKSH SEM E, P87, DOI 10.3115/1621474.1621490; Pradhan S., 2005, P 9 C COMP NAT LANG, P217, DOI 10.3115/1706543.1706585; Pradhan S, 2005, MACH LEARN, V60, P11, DOI 10.1007/s10994-005-0912-2; Pustejovsky J., 1995, GENERATIVE LEXICON; Rosario B, 2004, P 42 ANN M ASS COMP, P430, DOI 10.3115/1218955.1219010; Shi L, 2005, LECT NOTES COMPUT SC, V3406, P100; Surdeanu M., 2003, P 41 ANN M ASS COMP, P8; Surdeanu M, 2007, J ARTIF INTELL RES, V29, P105; Swier R., 2005, P JOINT HUM LANG TEC, P883, DOI 10.3115/1220575.1220686; Swier Robert S., 2004, P 2004 C EMP METH NA, P95; THOMPSON CA, 2003, P 14 EUR C MACH LEAR, P397; Toutanova K., 2005, P 43 ANN M ASS COMP, P589, DOI 10.3115/1219840.1219913; Xue N., 2004, P 2004 C EMP METH NA, P88; Yi S., 2007, HUM LANG TECHN 2007, P548; ZAPIRAIN B, 2007, P 4 INT WORKSH SEM E, P354, DOI 10.3115/1621474.1621551	54	13	14	M I T PRESS	CAMBRIDGE	238 MAIN STREET, STE 500, CAMBRIDGE, MA 02142-1046 USA	0891-2017		COMPUT LINGUIST	Comput. Linguist.	JUN	2008	34	2					145	159		10.1162/coli.2008.34.2.145		15	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics; Language & Linguistics	Computer Science; Linguistics	319CB	WOS:000257139400001	
J	Moschitti, A; Pighin, D; Basili, R				Moschitti, Alessandro; Pighin, Daniele; Basili, Roberto			Tree kernels for semantic role labeling	COMPUTATIONAL LINGUISTICS			English	Article								The availability of large scale data sets of manually annotated predicate-argument structures has recently favored the use of machine learning approaches to the design of automated semantic role labeling (SRL) systems. The main research in this area relates to the design choices for feature representation and for effective decompositions of the task in different learning models. Regarding the former choice, structural properties of full syntactic parses are largely employed as they represent ways to encode different principles suggested by the linking theory between syntax and semantics. The latter choice relates to several learning schemes over global views of the parses. For example, re-ranking stages operating over alternative predicate-argument sequences of the same sentence have shown to be very effective. In this article, we propose several kernel functions to model parse tree properties in kernel-based machines, for example, perceptrons or support vector machines. In particular, we define different kinds of tree kernels as general approaches to feature engineering in SRL. Moreover, we extensively experiment with such kernels to investigate their contribution to individual stages of an SRL architecture both in isolation and in combination with other traditional manually coded features. The results for boundary recognition, classification, and re-ranking stages provide systematic evidence about the significant impact of tree kernels on the overall accuracy, especially when the amount of training data is small. As a conclusive result, tree kernels allow for a general and easily portable feature engineering method which is applicable to a large family of natural language processing tasks.	[Moschitti, Alessandro] Univ Trent, Dept Comp Sci & Informat Engn, I-38050 Trento, Italy; [Pighin, Daniele] Univ Trent, Fondazione Bruno Kessler, Ctr Sci & Technol Res, Dept Comp Sci & Informat Engn, I-38050 Trento, Italy; [Basili, Roberto] Univ Roma Tor Vergata, Dept Comp Sci Syst & Prod, I-00133 Rome, Italy	Moschitti, A (reprint author), Univ Trent, Dept Comp Sci & Informat Engn, Via Sommarive 14, I-38050 Trento, Italy.	moschitti@dit.unitn.it; pighin@itc.it; basili@info.uniroma2.it					BAKER CF, 1998, COLING ACL 98, P86; CARRERAS X, 2004, HLT NAACL 2004 WORKS, V2004, P89; Carreras X., 2005, P 9 C COMP NAT LANG, P152, DOI 10.3115/1706543.1706571; Chen J, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P41; Collins M., 2002, ACL02, P263; Culotta A., 2004, ACL 2004, P423; Cumby C., 2003, P 20 INT C MACH LEAR, P107; Fillmore Charles J., 1968, UNIVERSALS LINGUISTI; Gildea D, 2002, COMPUT LINGUIST, V28, P245, DOI 10.1162/089120102760275983; HAGHIGHI A, 2005, P CONLL ANN ARB MI, P173, DOI 10.3115/1706543.1706574; JACKENDOFF, 1990, SEMANTIC STRUCTURES; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; KAZAMA J, 2005, P EMNLP 2005 TOR CAN, P137, DOI 10.3115/1220575.1220593; KUDO T, 2003, P 41 ANN M ASS COMP, V41, P24; Levin Beth, 1993, ENGLISH VERB CLASSES; LIN HT, 2003, NOE PLATT PROBABILIS; LITKOWSKI K, 2004, SENSEVAL 3 3 INT WOR, P9; Marcus M., 1993, COMPUTATIONAL LINGUI, V19, P313; MOSCHITTI A, 2005, P ACL WORKSH FEAT EN, P48, DOI 10.3115/1610230.1610239; Moschitti A., 2006, P 11 C EUR CHAPT ASS, P113; MOSCHITTI A, 2005, P 9 C COMP NAT LANG, P201, DOI 10.3115/1706543.1706581; Moschitti A., 2004, P 42 ANN M ASS COMP, DOI 10.3115/1218955.1218998; Moschitti A., 2006, P WORKSH LEARN STRUC, P49; MOSCHITTI A, 2006, P 1M EUR C MACH LEAR, P17; Palmer M, 2005, COMPUT LINGUIST, V31, P71, DOI 10.1162/0891201053630264; Platt J., 1999, ADV LARGE MARGIN CLA, P61; Pradhan S., 2005, P 9 C COMP NAT LANG, P217, DOI 10.3115/1706543.1706585; PRADHAN S, 2005, P 4O ANN M ASS COMP, V43, P581; Pradhan S, 2005, MACH LEARN, V60, P11, DOI 10.1007/s10994-005-0912-2; Pradhan S, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P233; Punyakanok Vasin, 2005, P 9 C COMP NAT LANG, P181; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; SHEN L, 2003, EMPIRICAL METHODS NA, P89; THOMPSON CA, 2003, 14 EUR C MACH LEARN, P397; TJONG KS, 2005, P 9 C COMP NAT LANG; TOUTANOVA K, 2004, P 2004 C EMP METH NA, P166; Toutanova K., 2005, P 43 ANN M ASS COMP, P589, DOI 10.3115/1219840.1219913; Vapnik VN, 1998, STAT LEARNING THEORY; VISHWANATHAN SVN, 2002, P NEUR INF PROC SYST, P569; Xue N., 2004, P 2004 C EMP METH NA, P88; Zelenko D, 2003, J MACH LEARN RES, V3, P1083, DOI 10.1162/153244303322533205; Zhang M., 2006, P NAACL NEW YORK CIT, P288, DOI 10.3115/1220835.1220872	42	16	17	M I T PRESS	CAMBRIDGE	238 MAIN STREET, STE 500, CAMBRIDGE, MA 02142-1046 USA	0891-2017		COMPUT LINGUIST	Comput. Linguist.	JUN	2008	34	2					193	224		10.1162/coli.2008.34.2.193		32	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics; Language & Linguistics	Computer Science; Linguistics	319CB	WOS:000257139400003	
J	Punyakanok, V; Roth, D; Yih, WT				Punyakanok, Vasin; Roth, Dan; Yih, Wen-tau			The importance of syntactic parsing and inference in semantic role labeling	COMPUTATIONAL LINGUISTICS			English	Article							CLASSIFICATION; WINNOW	We present a general framework for semantic role labeling. The framework combines a machine-learning technique with an integer linear programming-based inference procedure, which incorporates linguistic and structural constraints into a global decision process. Within this framework, we study the role of syntactic parsing information in semantic role labeling. We show that full syntactic parsing information is, by far, most relevant in identifying the argument, especially, in the very first stage-the pruning stage. Surprisingly, the quality of the pruning stage cannot be solely determined based on its recall and precision, Instead, it depends on the characteristics of the output candidates that determine the difficulty of the downstream problems. Motivated by this observation, we propose an effective and simple approach of combining different semantic role labeling systems through joint inference, which significantly improves its performance. Our system has been evaluated in the CoNLL-2005 shared task on semantic role labeling, and achieves the highest F-1 score among 19 participants.	[Roth, Dan] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA	Punyakanok, V (reprint author), 10 Moulton St, Cambridge, MA 02138 USA.	vpunyaka@bbn.com; danr@uiuc.edu; scottyih@microsoft.com					Baker C., 1998, P 36 ANN M ASS COMP, P86; Bikel DM, 2004, COMPUT LINGUIST, V30, P479, DOI 10.1162/0891201042544929; BISHOP CM, 1995, NEURAL NETWORKS PATT, P215; CARLSON AJ, 1999, UIUCDCSR992101 UIUC; Carreras X., 2004, P 8 C COMP NAT LANG, P89; CARRERAS X, 2002, P 13 EUR C MACH LEAR, P35; Carreras X, 2005, MACH LEARN, V60, P41, DOI 10.1007/s10994-005-0917-x; Carreras X., 2005, P 9 C COMP NAT LANG, P152, DOI 10.3115/1706543.1706571; CHARNIAK E, 2001, P 39 ANN M ASS COMP, P116; Chen J, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P41; Collins M., 1999, THESIS U PENNSYLVANI; Dagan I, 1997, P 2 C EMP METH NAT L, P55; Even-Zohar Y, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P10; Freund Y, 1999, MACH LEARN, V37, P277, DOI 10.1023/A:1007662407062; Gildea D., 2002, P 40 ANN M ASS COMP, P239; Gildea D, 2002, COMPUT LINGUIST, V28, P245, DOI 10.1162/089120102760275983; Gildea D, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P57; Golding AR, 1999, MACH LEARN, V34, P107, DOI 10.1023/A:1007545901558; Grove AJ, 2001, MACH LEARN, V42, P123, DOI 10.1023/A:1007655119445; Gueret C, 2002, APPL OPT XPRESS MP; HACIOGLU K, 2004, P 8 C COMP NAT LANG, P110; HACIOGLU K, 2004, P 20 INT C COMP LING, P20; HAGHIGHI A, 2005, P CONLL ANN ARB MI, P173, DOI 10.3115/1706543.1706574; KINGSBURY P, 2002, P WORKSH APPL INT TI; KIPPER K, 2002, P WORKSH APPL INT TI; Koomen P., 2005, P 9 C COMP NAT LANG, P181, DOI 10.3115/1706543.1706576; Levin B., 1996, LEXICAL SEMANT UNPUB; Levin Beth, 1993, ENGLISH VERB CLASSES; LI X, 2001, P ANN C COMP NAT LAN, P107; Marcus M., 1993, COMPUTATIONAL LINGUI, V19, P313; Marquez L., 2005, P 9 C COMP NAT LANG, P193, DOI 10.3115/1706543.1706579; Noreen E., 1989, COMPUTER INTENSIVE M; Palmer M, 2005, COMPUT LINGUIST, V31, P71, DOI 10.1162/0891201053630264; Pradhan S., 2004, P HUM LANG TECHN C N, P233; Pradhan S, 2003, P 3 IEEE INT C DAT M, P629; Pradhan S., 2005, P 9 C COMP NAT LANG, P217, DOI 10.3115/1706543.1706585; Pradhan S, 2005, MACH LEARN, V60, P11, DOI 10.1007/s10994-005-0912-2; Punyakanok V, 2001, ADV NEUR IN, V13, P995; Punyakanok V., 2004, P 20 INT C COMP LING, P1346, DOI 10.3115/1220355.1220552; Roth D., 2005, P INT C MACH LEARN, P737; Roth D., 2004, P ANN C COMP NAT LAN, P1; Roth D., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Surdeanu M., 2003, P 41 ANN M ASS COMP, P8; TJONG KS, 2000, P C NATURAL LANGUAGE, P127; XPRESS MP, 2004, OPTIMIZATION; Xue N., 2004, P 2004 C EMP METH NA, P88; Zhang T, 2002, J MACH LEARN RES, V2, P615, DOI 10.1162/153244302320884560	47	9	10	M I T PRESS	CAMBRIDGE	238 MAIN STREET, STE 500, CAMBRIDGE, MA 02142-1046 USA	0891-2017		COMPUT LINGUIST	Comput. Linguist.	JUN	2008	34	2					257	287		10.1162/coli.2008.34.2.257		31	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics; Language & Linguistics	Computer Science; Linguistics	319CB	WOS:000257139400005	
J	Gosselin, PH; Cord, M; Philipp-Foliguet, S				Gosselin, Philippe Henri; Cord, Matthieu; Philipp-Foliguet, Sylvie			Combining visual dictionary, kernel-based similarity and learning strategy for image category retrieval	COMPUTER VISION AND IMAGE UNDERSTANDING			English	Article						multimedia retrieval; machine learning; kernel functions; quantization	ALGORITHM; MODELS; COLOR	This paper presents a search engine architecture, RETIN, aiming at retrieving complex categories in large image databases. For indexing, a scheme based on a two-step quantization process is presented to compute visual codebooks. The similarity between images is represented in a kernel framework. Such a similarity is combined with online learning strategies motivated by recent machine-learning developments such as active learning. Additionally, an offline supervised learning is embedded in the kernel framework, offering a real opportunity to learn semantic categories. Experiments with real scenario carried out from the Corel Photo database demonstrate the efficiency and the relevance of the RETIN strategy and its outstanding performances in comparison to up-to-date strategies. (C) 2007 Elsevier Inc. All rights reserved.	[Gosselin, Philippe Henri; Philipp-Foliguet, Sylvie] CNRS, ETIS 8051, F-95014 Cergy Pontoise, France; [Cord, Matthieu] CNRS, LIP6, F-75016 Paris, France	Gosselin, PH (reprint author), CNRS, ETIS 8051, 6 Ave Ponceau,BP 44, F-95014 Cergy Pontoise, France.	gosselin@ensea.fr; matthieu.cord@lip6.fr					AKSOY S, 2000, IAPR INT C PATT REC, V4, P812; BERRANI SA, 2003, TECH SCI INFORM, V22, P1201, DOI 10.3166/tsi.22.1201-1230; Brinker K., 2003, INT C MACH LEARN FEB, P59; CHANG EY, 2003, IEEE INT C IM PROC I, P609; Chen YX, 2004, J MACH LEARN RES, V5, P913; Cohn DA, 1996, J ARTIF INTELL RES, V4, P129; CORD M, 2006, IMAGE VISION COMPUT, P14; Cristianini N, 2001, NEURAL INFORM PROCES; DOULAMIS N, 2001, INT C IM PROC ICIP 0; Fayyad U.M., 1996, ADV KNOWLEDGE DISCOV; FOURNIER J, 2001, INT C IM PROC ICIP 0, V1, P686; Fournier J, 2001, PATTERN ANAL APPL, V4, P153, DOI 10.1007/PL00014576; FOURNIER J, 2002, INT C IM PROC ICIP R; GOSSELIN P, 2004, IEEE INT C IM PROC S, V4, P2219; GOSSELIN PH, 2006, IEEE INT C IM PROC; HEISTERKAMP DR, 2002, INT C PATT REC QUEB, V4, P132; Ishikawa Y., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Joachims T., 1999, P 16 INT C MACH LEAR, P200; Kullback S., 1959, INFORM THEORY STAT; Lanckriet G.R.G., 2002, INT C MACH LEARN SYD; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424; Mika S, 1999, NEURAL NETWORKS SIGN, P41; MOJSILOVIC A, 2001, INT C IM PROC ICIP 0, V1, P18; Muller H., 2000, LONG TERM LEARNING U; NAJJAR N, 2003, IEEE ICIP, V2, P559; Patane G, 2001, NEURAL NETWORKS, V14, P1219, DOI 10.1016/S0893-6080(01)00104-6; Peng J, 1999, COMPUT VIS IMAGE UND, V75, P150, DOI 10.1006/cviu.1999.0770; Puzicha J., 1997, IEEE INT C COMP VIS; Roy N., 2001, INT C MACH LEARN; Rubner Y., 1999, THESIS STANFORD U; RUI Y, 2000, C COMP VIS PATT REC, V1, P236; RUI Y, 1997, IEEE WORKSH CONT BAS, P92; Santini S, 2001, IEEE T KNOWL DATA EN, V13, P337, DOI 10.1109/69.929893; SAUX BL, 2003, THESIS INRIA; Schmid C, 2004, INT J COMPUT VISION, V56, P7, DOI 10.1023/B:VISI.0000004829.38247.b0; SCHULTZ M, 2003, NEURAL INFORM PROCES; Sebe N., 2005, MACHINE LEARNING COM; SETHI IK, 1995, P SOC PHOTO-OPT INS, V2410, P329; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Smith J. R., 1996, ACM MULTIMEDIA, P87; Stricker M, 1995, SPIE STORAGE RETRIEV, V2185, P381; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Tong S., 2002, J MACHINE LEARNING R, V2, P45, DOI 10.1162/153244302760185243; Tong S., 2001, ACM MULTIMEDIA, P107; Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646; Vapnik VN, 1998, STAT LEARNING THEORY; VASCONCELOS N, 2001, INT C IM PROC ICIP 0, V3, P6; VASCONCELOS N, 2000, THESIS MIT; VELTKAMP RC, 2000, UUCS200034 UTR U DEP; Xing E.P., 2002, NEURAL INFORM PROCES; Zhu X., 2003, INT C MACH LEARN	52	11	11	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1077-3142		COMPUT VIS IMAGE UND	Comput. Vis. Image Underst.	JUN	2008	110	3					403	417		10.1016/j.cviu.2007.09.018		15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	303NN	WOS:000256047300008	
J	van Eck, NJ; van Wezel, M				van Eck, Nees Jan; van Wezel, Michiel			Application of reinforcement learning to the game of Othello	COMPUTERS & OPERATIONS RESEARCH			English	Article						dynamic programming; Markov decision processes; reinforcement learning; Q-learning; multiagent learning; neural networks; game playing; Othello	TD-GAMMON; PLAY	Operations research and management science are often confronted with sequential decision making problems with large state spaces. Standard methods that are used for solving such complex problems are associated with some difficulties. As we discuss in this article, these methods are plagued by the so-called curse of dimensionality and the curse of modelling. In this article, we discuss reinforcement learning, a machine learning technique for solving sequential decision making problems with large state spaces. We describe how reinforcement learning can be combined with a function approximation method to avoid both the curse of dimensionality and the curse of modelling. To illustrate the usefulness of this approach, we apply it to a problem with a huge state space-learning to play the game of Othello. We describe experiments in which reinforcement learning agents learn to play the game of Othello without the use of any knowledge provided by human experts. It turns out that the reinforcement learning agents learn to play the game of Othello better than players that use basic strategies. (c) 2006 Elsevier Ltd. All rights reserved.	Erasmus Univ, Erasmus Sch Econ, NL-3000 DR Rotterdam, Netherlands	van Eck, NJ (reprint author), Erasmus Univ, Erasmus Sch Econ, POB 1738, NL-3000 DR Rotterdam, Netherlands.	nvaneck@few.eur.nl; mvanwezel@few.eur.nl	van Eck, Nees Jan/B-6042-2008	van Eck, Nees Jan/0000-0001-8448-4521			Allis L. V., 1994, THESIS U LIMBURG MAA; Bellman R. E., 1957, DYNAMIC PROGRAMMING; Bertsekas D. P., 1996, NEURODYNAMIC PROGRAM; Bishop C.M., 1995, NEURAL NETWORKS PATT; Chong SY, 2005, IEEE T EVOLUT COMPUT, V9, P240, DOI 10.1109/TEVC.2005.843750; Crites RH, 1998, MACH LEARN, V33, P235, DOI 10.1023/A:1007518724497; Crites RH, 1996, ADV NEUR IN, V8, P1017; Das TK, 1999, MANAGE SCI, V45, P560, DOI 10.1287/mnsc.45.4.560; DOUCETTE MJ, 1998, WIPEOUT ENG OTHELLO; Fijrnkranz J., 2001, MACHINES LEARN PLAY, P11; Gosavi A., 2003, SIMULATION BASED OPT; Gosavi A, 2002, IIE TRANS, V34, P729, DOI 10.1080/07408170208928908; GOSAVI A, 2004, EUR J OPER RES, V144, P654; Hu J.L., 2003, J MACHINE LEARNING R, V4, P1039, DOI 10.1162/jmlr.2003.4.6.1039; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237; LECOMTE M, 2000, INTRO OTHELLO; LEOUSKI AV, 1996, UMCS1996010 U; Littman M. L., 1994, P 11 INT C MACH LEAR, P157; Littman ML, 2001, J COGNITIVE SYSTEMS, V2, P55; MORISSET J, 1995, CELL SIGNAL, V7, P195, DOI 10.1016/0898-6568(94)00081-L; PEDNAULT E, 2002, P 8 ACM SIGKDD INT C, P259; ROSE B, 2005, OTHELLO MINUTE LEARN; Russell S. J., 2003, ARTIFICIAL INTELLIGE; Sutton R.S., 1998, REINFORCEMENT LEARNI; TESAURO G, 1994, NEURAL COMPUT, V6, P215, DOI 10.1162/neco.1994.6.2.215; TESAURO G, 1995, COMMUN ACM, V38, P58, DOI 10.1145/203330.203343; Tesauro G, 2002, ARTIF INTELL, V134, P181, DOI 10.1016/S0004-3702(01)00110-2; van den Herik HJ, 2002, ARTIF INTELL, V134, P277, DOI 10.1016/S0004-3702(01)00152-7; Watkins C, 1989, THESIS CAMBRIDGE U C; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698; WHITE DJ, 1993, J OPER RES SOC, V44, P1073, DOI 10.1057/jors.1993.181	31	4	4	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0305-0548		COMPUT OPER RES	Comput. Oper. Res.	JUN	2008	35	6					1999	2017		10.1016/j.cor.2006.10.004		19	Computer Science, Interdisciplinary Applications; Engineering, Industrial; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	236HU	WOS:000251294600016	
J	Barahona, P; Krippahl, L				Barahona, Pedro; Krippahl, Ludwig			Constraint programming in structural bioinformatics	CONSTRAINTS			English	Article						constraint programming; structural bioinformatics; protein structure determination; protein docking	ELECTRON-TRANSFER COMPLEXES; CYTOCHROME-C PEROXIDASE; SOFT-DOCKING; PARACOCCUS-DENITRIFICANS; PROTEIN-STRUCTURE; NMR; MODEL; ALGORITHM; BIGGER	Bioinformatics aims at applying computer science methods to the wealth of data collected in a variety of experiments in life sciences (e.g. cell and molecular biology, biochemistry, medicine, etc.) in order to help analysing such data and eliciting new knowledge from it. In addition to string processing bioinformatics is often identified with machine learning used for mining the large banks of bio-data available in electronic format, namely in a number of web servers. Nevertheless, there are opportunities of applying other computational techniques in some bioinformatics applications. In this paper, we report the application of constraint programming to address two structural bioinformatics problems, protein structure prediction and protein interaction (docking). The efficient application of constraint programming requires innovative modelling of these problems, as well as the development of advanced propagation techniques (e.g. global reasoning and propagation), which were adopted in Chemera, a system that is currently used to support biochemists in their research.	[Barahona, Pedro; Krippahl, Ludwig] Univ Nova Lisboa, Dept Informat, P-2825 Monte De Caparica, Portugal	Barahona, P (reprint author), Univ Nova Lisboa, Dept Informat, P-2825 Monte De Caparica, Portugal.	pb@di.fct.unl.pt; ludi@di.fct.unl.pt					BACKOFEN R, 2006, CONSTRAINT BASED APP, V11; CORREIA M, 2005, P 1 INT WORKSH CONST, P59; Correia M, 2004, LECT NOTES ARTIF INT, V3171, P103; Dal Palu A, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-186; Dominguez C, 2003, J AM CHEM SOC, V125, P1731, DOI 10.1021/ja026939x; Fages Francois, 2004, Journal of Biological Physics and Chemistry, V4, P64; Guntert P, 1997, J MOL BIOL, V273, P283, DOI 10.1006/jmbi.1997.1284; HARVEY W, 1995, P IJCAI INT JOINT C; Impagliazzo A, 2005, CHEMBIOCHEM, V6, P1648, DOI 10.1002/cbic.200500082; KATCHALSKIKATZIR E, 1992, P NATL ACAD SCI USA, V89, P2195, DOI 10.1073/pnas.89.6.2195; Krippahl L., 2002, Constraints, V7, DOI 10.1023/A:1020577603762; KRIPPAHL L, 2003, INTEGRATING PROTEIN; Krippahl L, 2006, LECT NOTES COMPUT SC, V4126, P184; KRIPPAHL L, 1999, APPL CONSTRAINT PROG, P289; Krippahl L, 2005, LECT NOTES COMPUT SC, V3709, P373; Krippahl L, 2003, PROTEINS, V52, P19, DOI 10.1002/prot.10387; Krippahl L, 2003, LECT NOTES COMPUT SC, V2833, P452; Moont G, 1999, PROTEINS, V35, P364, DOI 10.1002/(SICI)1097-0134(19990515)35:3<364::AID-PROT11>3.0.CO;2-4; Morelli X, 2000, BIOCHEMISTRY-US, V39, P2530, DOI 10.1021/bi992306s; Morelli XJ, 2001, PROTEIN SCI, V10, P2131, DOI 10.1110/ps.07501; Palma PN, 2000, PROTEINS, V39, P372, DOI 10.1002/(SICI)1097-0134(20000601)39:4<372::AID-PROT100>3.0.CO;2-Q; Palma PN, 2005, FEBS LETT, V579, P4585, DOI 10.1016/j.febslet.2005.07.027; Pettigrew GW, 2003, BIOCHEMISTRY-US, V42, P2046, DOI 10.1021/bi027125w; Pettigrew GW, 1999, J BIOL CHEM, V274, P11383, DOI 10.1074/jbc.274.16.11383; Pettigrew GW, 2003, BIOCHEMISTRY-US, V42, P11968, DOI 10.1021/bi034829c; SANTOS AJ, 2006, MINIG PROTEIN STRUCT; Simons KT, 1997, J MOL BIOL, V268, P209, DOI 10.1006/jmbi.1997.0959; Wang LC, 2006, J COMPUT BIOL, V13, P1267, DOI 10.1089/cmb.2006.13.1267; Wolfson HJ, 1997, IEEE COMPUT SCI ENG, V4, P10, DOI 10.1109/99.641604	29	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1383-7133		CONSTRAINTS	Constraints	JUN	2008	13	1-2					3	20		10.1007/s10601-007-9036-6		18	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	294LR	WOS:000255408000002	
J	Demel, MA; Janecek, AGK; Thai, KM; Ecker, GF; Gansterer, WN				Demel, Michael A.; Janecek, Andreas G. K.; Thai, Khac-Minh; Ecker, Gerhard F.; Gansterer, Wilfried N.			Predictive QSAR models for polyspecific drug targets: The importance of feature selection	CURRENT COMPUTER-AIDED DRUG DESIGN			English	Review						feature selection; dimensionality reduction; machine learning; chemical descriptors; ABC-transporter; nuclear; hormone receptors; cytochrome P450; hERG	HERG POTASSIUM CHANNEL; PREGNANE-X-RECEPTOR; LONG-QT-SYNDROME; P-GLYCOPROTEIN INHIBITORS; CONSTITUTIVE ANDROSTANE RECEPTOR; CAUSE PSEUDOXANTHOMA ELASTICUM; VECTOR MACHINE CLASSIFICATION; CASSETTE ABC TRANSPORTER; RESISTANCE PROTEIN 5; K+ CHANNEL	Since the advent of QSAR ( quantitative structure activity relationship) modeling quantitative representations of molecular structures are encoded in terms of information-preserving descriptor values. Nowadays, a nearly infinite variety of potential descriptors is available and descriptor selection is no longer a task which can be done manually. There is an increasing need for automation in order to reduce the dimensionality of the descriptor space. Classical feature selection ( FS) and dimensionality reduction ( DR) methods like principal component analysis, which relies on the selection of those descriptors that contribute most to the variance of a data set, often fail in providing the best classification result. More sophisticated methods like genetic algorithms, self-organizing- maps and stepwise linear discriminant analysis have proven to be useful techniques in the process of selecting descriptors with a significant discriminative power. The topic FS and DR becomes even more important when predictive models are approached which should describe the QSAR of highly promiscuous target proteins. The ABC-transporter family, the cardiac hERG-potassium channel, and the hepatic cytochrom-P450-family are classical representatives of such poly-specific proteins. In this case the interaction pattern is a rather complex one and thus the selection of the most predictive descriptors needs advanced methods. This review surveys FS and DR methods that have recently been successfully applied to classify ligands of poly-specific target proteins.	[Demel, Michael A.; Thai, Khac-Minh; Ecker, Gerhard F.] Univ Vienna, Dept Med Chem, Emerging Field Pharmacoinformat, A-1090 Vienna, Austria; [Janecek, Andreas G. K.; Gansterer, Wilfried N.] Univ Vienna, Res Lab Computat Applicat & Technol, A-1080 Vienna, Austria	Ecker, GF (reprint author), Univ Vienna, Dept Med Chem, Emerging Field Pharmacoinformat, Althanstr 14, A-1090 Vienna, Austria.	Gerhard.F.Ecker@univie.ac; Wilfried.Gansterer@univie.ac					AHA DW, 1995, P 5 INT WORKSH ART I; Albrecht A, 2003, ARTIF INTELL MED, V28, P75, DOI 10.1016/S0933-3657(03)00036-8; Anzenbacher P, 2001, CELL MOL LIFE SCI, V58, P737, DOI 10.1007/PL00000897; Aptula AO, 2004, SAR QSAR ENVIRON RES, V15, P399, DOI 10.1080/10629360412331297353; Aronov AM, 2004, BIOORGAN MED CHEM, V12, P2307, DOI 10.1016/j.bmc.2004.02.003; Aronov AM, 2006, J MED CHEM, V49, P6917, DOI 10.1021/jm060500o; Bains W, 2004, PROG BIOPHYS MOL BIO, V86, P205, DOI 10.1016/j.pbiomolbio.2003.09.001; BATTISTI RF, 2006, MOL PHARM; Bergen AAB, 2000, NAT GENET, V25, P228, DOI 10.1038/76109; Berkhin P, 2002, SURVEY CLUSTERING DA; Berry MW, 1999, SIAM REV, V41, P335, DOI 10.1137/S0036144598347035; Bertilsson G, 1998, P NATL ACAD SCI USA, V95, P12208, DOI 10.1073/pnas.95.21.12208; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Borst P, 2000, BBA-MOL CELL BIOL L, V1486, P128, DOI 10.1016/S1388-1981(00)00053-6; BREIMAN L, 2002, IMS WALD LECT, V2; Breiman L, 1984, CLASSIFICATION REGRE; BREIMAN L, 2004, J MACH LEARN, V45, P5; Cavalli A, 2002, J MED CHEM, V45, P3844, DOI 10.1021/jm0208875; Cedeno W, 2003, J COMPUT AID MOL DES, V17, P255, DOI 10.1023/A:1025338411016; CHANG PMB, 2006, DMD; Chen ZS, 2001, J BIOL CHEM, V276, P33747, DOI 10.1074/jbc.M104833200; Cherry S, 1997, J CLIMATE, V10, P1759, DOI 10.1175/1520-0442(1997)010<1759:SCOSVD>2.0.CO;2; Cianchetta G, 2005, BIOORG MED CHEM LETT, V15, P3637, DOI 10.1016/j.bmcl.2005.03.062; Coi A, 2006, BIOORGAN MED CHEM, V14, P3153, DOI 10.1016/j.bmc.2005.12.030; Consonni V, 2002, J CHEM INF COMP SCI, V42, P682, DOI 10.1021/ci015504a; COVER TM, 1995, IEEE T INFORM THEORY, V8, P373; Crivori P, 2006, MOL PHARMACEUT, V3, P33, DOI 10.1021/mp050071a; DAS S, 2001, FILTERS WRAPPERS BOO; De Jong K., 1988, Machine Learning, V3, DOI 10.1023/A:1022606120092; Dean M, 2001, GENOME RES, V11, P1156, DOI 10.1101/gr.GR-1649R; Debuse J. C. W., 1997, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V9, DOI 10.1023/A:1008641220268; de Cerqueira Lima Patricia, 2006, J Chem Inf Model, V46, P1245, DOI 10.1021/ci0504317; Demmel J.W., 1997, APPL NUMERICAL LINEA; Didziapetris R, 2003, J DRUG TARGET, V11, P391, DOI 10.1080/10611860310001648248; Dietterich Thomas G., 2002, HDB BRAIN THEORY NEU, P405; DIJCK GV, 2004, P INT C COMP INT; DUBUS E, 2006, CHEMMEDCHEM, V1, P662; Duda R., 2000, PATTERN CLASSIFICATI; Duda R.O, 1973, PATTERN CLASSIFICATI; Dunham MH, 2002, DATA MINING INTRO AD; Dunn RT, 1999, J PHARMACOL EXP THER, V290, P319; Dussault I, 2001, J BIOL CHEM, V276, P33309, DOI 10.1074/jbc.C100375200; Ekins S, 2006, J MED CHEM, V49, P5059, DOI 10.1021/jm060076r; Ekins S, 2002, MOL PHARMACOL, V61, P974, DOI 10.1124/mol.61.5.974; EKINS S, 2007, J MOL PHARMACOL, V72, P592; Ekins S, 2002, DRUG METAB DISPOS, V30, P96, DOI 10.1124/dmd.30.1.96; Ekins S, 2002, PHARM RES-DORDR, V19, P1788, DOI 10.1023/A:1021429105173; Ekins S, 2002, J PHARMACOL EXP THER, V301, P427, DOI 10.1124/jpet.301.2.427; Ekins S, 2005, DRUG METAB DISPOS, V33, P474, DOI 10.1124/dmd.104.002717; Faloutsos C, 1995, P ACM SIGMOD INT C M; Fermini B, 2003, NAT REV DRUG DISCOV, V2, P439, DOI 10.1038/nrd1108; FILIPPONE M, 2006, WRAPPER APPROACH SUP; FIORAVANZO E, 2005, J MOL DES, V4, P625; Fleuret F, 2004, J MACH LEARN RES, V5, P1531; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Fukunaga K., 1990, INTRO STAT PATTERN R; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Gansterer W.N., 2007, SURVEY TEXT MINING 2, P165; Garg D, 2008, J MOL GRAPH MODEL, V26, P966, DOI 10.1016/j.jmgm.2007.08.002; Garrigues A, 2002, MOL PHARMACOL, V62, P1288, DOI 10.1124/mol.62.6.1288; Gavaghan CL, 2007, J COMPUT AID MOL DES, V21, P189, DOI 10.1007/s10822-006-9095-6; Geick A, 2001, J BIOL CHEM, V276, P14581, DOI 10.1074/jbc.M010173200; Gepp MM, 2006, BIOORGAN MED CHEM, V14, P5325, DOI 10.1016/j.bmc.2006.03.043; Gerbal-Chaloin S, 2002, J BIOL CHEM, V277, P209, DOI 10.1074/jbc.M107228200; Gerbal-Chaloin S, 2001, DRUG METAB DISPOS, V29, P242; Gerloff T, 1998, J BIOL CHEM, V273, P10046, DOI 10.1074/jbc.273.16.10046; Giguere V, 1999, ENDOCR REV, V20, P689, DOI 10.1210/er.20.5.689; Goldberg DE, 1989, GENETIC ALGORITHMS S; Gombar VK, 2004, J PHARM SCI-US, V93, P957, DOI 10.1002/jps.20035; Goodwin B, 2001, MOL PHARMACOL, V60, P427; Gorsuch R. L., 1983, FACTOR ANAL; Gregori-Puigjane E, 2006, J CHEM INF MODEL, V46, P1615, DOI 10.1021/ci0600509; Guengerich FP, 2001, CHEM RES TOXICOL, V14, P611, DOI 10.1021/tx0002583; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hall LH, 2000, J CHEM INF COMP SCI, V40, P784, DOI 10.1021/ci990140w; HALL LH, 2002, MOLCONN Z VERSION 4; Han J, 2006, DATA MINING CONCEPTS; Hanson R. J., 1995, SOLVING LEAST SQUARE; Hastie T., 2002, ELEMENTS STAT LEARNI; Hoffmann Peter, 2006, Journal of Pharmacological and Toxicological Methods, V53, P87, DOI 10.1016/j.vasen.2005.07.003; HOSOKAWA M, 1993, BIOCHEM PHARMACOL, V45, P2317, DOI 10.1016/0006-2952(93)90205-B; HUANG J, 2007, J CHEM INF MOD, V47, P1414; Huyn N, 2001, SIGMOD RECORD, V30, P76; IVANCIUC O, 2006, J MOL DES, V5, P488; Jacobs MN, 2004, TOXICOLOGY, V205, P43, DOI 10.1016/j.tox.2004.06.036; Jalaie M, 2005, MINI-REV MED CHEM, V5, P1083, DOI 10.2174/138955705774933338; Jamieson C, 2006, J MED CHEM, V49, P5029, DOI 10.1021/jm0603791; JARMULAK J, 1999, P 1999 WORKSH AUT CO; Jedlitschky G, 2000, J BIOL CHEM, V275, P30069, DOI 10.1074/jbc.M005463200; JENNRICH RI, 1977, MATH METHODS DIGITAL, V3, P76; Jezierska A, 2004, MOL DIVERS, V8, P371, DOI 10.1023/B:MODI.0000047502.66802.3d; Johnson SR, 2007, BIOORGAN MED CHEM, V15, P6182, DOI 10.1016/j.bmc.2007.06.028; Jolliffe I.T., 2002, PRINCIPAL COMPONENT; Kamiya K, 2006, MOL PHARMACOL, V69, P1709, DOI 10.1124/mol.105.020990; Kargupta H., 2000, ADV DISTRIBUTED PARA; Kast HR, 2002, J BIOL CHEM, V277, P2908, DOI 10.1074/jbc.M109326200; Kaufman L, 2005, FINDING GROUPS DATA; KENNEDY J, 1997, P C SYST MAN CYB PIS; Kennedy J., 1995, P IEEE INT C NEUR NE; Keseru GM, 2003, BIOORG MED CHEM LETT, V13, P2773, DOI 10.1016/S0960-894X(03)00492-X; KIRA K, 1992, P 9 INT WORKSH MACH; KIRKPATRICK S, 1983, SCIENCE, V220, P661; Klein C, 2002, J COMPUT AID MOL DES, V16, P785, DOI 10.1023/A:1023828527638; Kliewer SA, 1998, CELL, V92, P73, DOI 10.1016/S0092-8674(00)80900-9; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohonen T., 2000, SELF ORG MAPS; Kool M, 1999, P NATL ACAD SCI USA, V96, P6914, DOI 10.1073/pnas.96.12.6914; Kovatcheva A, 2004, J CHEM INF COMP SCI, V44, P582, DOI 10.1021/ci034203t; Kramer C, 2008, CHEMMEDCHEM, V3, P254, DOI 10.1002/cmdc.200700221; LANGVILLE AN, 2005, J ONLINE MATH ITS AP; Lehmann JM, 1998, J CLIN INVEST, V102, P1016, DOI 10.1172/JCI3703; Leong MK, 2007, CHEM RES TOXICOL, V20, P217, DOI 10.1021/tx060230c; Lewis D. F. V., 2002, Xenobiotica, V32, P305, DOI 10.1080/00498250110112015; Lewis DFV, 2000, TOXICOLOGY, V144, P197, DOI 10.1016/S0300-483X(99)00207-3; Lewis DFV, 2004, DRUG DISCOV TODAY, V9, P530, DOI 10.1016/S1359-6446(04)03115-0; Lewis DFV, 2002, DRUG DISCOV TODAY, V7, P918, DOI 10.1016/S1359-6446(02)02412-1; LEWIS DFV, 2001, REV DRUG METAB DRUG, V18, P221; Lewis DFV, 2002, DRUG METAB REV, V34, P69, DOI 10.1081/DMR-120001391; LI F, 2005, P 20 ANN ACM S APPL; LI ZR, 2007, Z BIOTECHNOL BIOENG, V97, P389; Liu L, 1996, DRUG METAB DISPOS, V24, P854; LIU Y, 2004, P C COMP INF SCI; M Sahami, 1996, P INT C MACH LEARN; MADHU C, 1991, TOXICOL APPL PHARM, V109, P305, DOI 10.1016/0041-008X(91)90177-G; MARZIO WD, 2001, CHEMOSPHERE, V44, P401; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Mitchell JA, 2006, NAT REV DRUG DISCOV, V5, P75, DOI 10.1038/nrd1929; Mitcheson John, 2005, V266, P136; Mitcheson JS, 2000, P NATL ACAD SCI USA, V97, P12329, DOI 10.1073/pnas.210244497; MIYAHARA K, 2000, COLLABORATIVE FILTER; MOLINA LC, 2002, P IEEE INT C DAT MIN; Molnar L, 2002, BIOORG MED CHEM LETT, V12, P419, DOI 10.1016/S0960-894X(01)00771-5; MOORE BC, 1981, IEEE T AUTOMAT CONTR, V26, P17, DOI 10.1109/TAC.1981.1102568; Morschhauser F, 2007, LEUKEMIA LYMPHOMA, V48, P708, DOI 10.1080/10428190701190169; Obrezanova O, 2007, J CHEM INF MODEL, V47, P1847, DOI 10.1021/ci7000633; O'Brien SE, 2005, J MED CHEM, V48, P1287, DOI 10.1021/jm049254b; Pearlstein R, 2003, J MED CHEM, V46, P2017, DOI 10.1021/jm0205651; Pearlstein RA, 2003, BIOORG MED CHEM LETT, V13, P1829, DOI 10.1016/S0960-894X(03)00196-3; Perry M, 2006, MOL PHARMACOL, V69, P509, DOI 10.1124/mol.105.016741; PLATTS JA, 2000, J PHARM RES, P1013; Powell W.B., 2007, APPROXIMATE DYNAMIC; Quinlan R, 1993, C4 5 PROGRAMS MACHIN; Ramoni M, 2001, ARTIF INTELL, V125, P209, DOI 10.1016/S0004-3702(00)00085-0; RANDIC M, 1995, NEW J CHEM, V19, P781; Ratanamahatana C, 2003, APPL ARTIF INTELL, V17, P475, DOI 10.1080/08839510390219327; Recanatini M, 2005, MED RES REV, V25, P133, DOI 10.1002/med.20019; Rendic S, 1997, DRUG METAB REV, V29, P413, DOI 10.3109/03602539709037591; Ringpfeil F, 2000, P NATL ACAD SCI USA, V97, P6001, DOI 10.1073/pnas.100041297; Roche O, 2002, CHEMBIOCHEM, V3, P455, DOI 10.1002/1439-7633(20020503)3:5<455::AID-CBIC455>3.0.CO;2-L; Rojas R., 1996, NEURAL NETWORKS SYST; Roncaglioni A, 2004, J CHEM INF COMP SCI, V44, P300, DOI 10.1021/ci030421a; Runge-Morris M, 1999, MOL PHARMACOL, V56, P1198; SAFAVIAN R, 1998, EEE T SYST MAN CYBER, V22, P660; Sanguinetti MC, 2005, TRENDS PHARMACOL SCI, V26, P119, DOI 10.1016/j.tips.2005.01.003; Sanguinetti MC, 2006, NATURE, V440, P463, DOI 10.1038/nature04710; Sanguinetti Michael C., 2005, V266, P159; SAUX OL, 2000, NAT GENET, V25, P223; Schinkel AH, 1997, P NATL ACAD SCI USA, V94, P4028, DOI 10.1073/pnas.94.8.4028; Schneider G, 2000, NEURAL NETWORKS, V13, P15, DOI 10.1016/S0893-6080(99)00094-5; Scholkopf B., 2001, LEARNING KERNELS SUP; Schuetz JD, 1999, NAT MED, V5, P1048, DOI 10.1038/12487; Seierstad M, 2006, CHEM BIOL DRUG DES, V67, P284, DOI 10.1111/j.1747-0285.2006.00379.x; Song MH, 2006, J CHEM INF MODEL, V46, P392, DOI 10.1021/ci050308f; Stansfeld PJ, 2006, EXPERT OPIN DRUG MET, V2, P81, DOI 10.1517/17425255.2.1.81; Struk B, 2000, J MOL MED-JMM, V78, P282, DOI 10.1007/s001090000114; Sun HM, 2004, J CHEM INF COMP SCI, V44, P748, DOI 10.1021/ci030304f; Sun HM, 2006, CHEMMEDCHEM, V1, P315, DOI 10.1002/cmdc.200500047; SUN Y, 2005, P BIOM CONS C BC ARL; Susnow RG, 2003, J CHEM INF COMP SCI, V43, P1308, DOI 10.1021/ci030283p; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; SVETNIK V, 2004, P 5 INT WORKSH MULT; SYNOLD T, 2001, NATURE MED, V7; TANG EK, 2005, P 2005 IEEE S COMP I; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; TENG S, 2007, J MOL PHARM; Testai L, 2004, CURR MED CHEM, V11, P2691; Tetko IV, 2005, J COMPUT AID MOL DES, V19, P453, DOI 10.1007/s10822-005-8694-y; THAI KM, 2007, J CURR MED CHEM, V14, P3003; Thai KM, 2008, BIOORGAN MED CHEM, V16, P4107, DOI 10.1016/j.bmc.2008.01.017; Tobita M, 2005, BIOORG MED CHEM LETT, V15, P2886, DOI 10.1016/j.bmcl.2005.03.080; Todeschini R., 2000, HDB MOL DESCRIPTORS; Torkkola K., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753742; Trelea IC, 2003, INFORM PROCESS LETT, V85, P317, DOI 10.1016/S0020-0190(02)00447-7; Ung CY, 2007, MOL PHARMACOL, V71, P158, DOI 10.1124/mol.106.027623; VAFAIE H, 1992, P 4 INT C TOOLS ART; Vandenberg JI, 2001, TRENDS PHARMACOL SCI, V22, P240, DOI 10.1016/S0165-6147(00)01662-X; Vapnik V.N., 1999, NATURE STAT LEARNING; Vose M.D., 1999, SIMPLE GENETIC ALGOR; Wang YH, 2005, J COMPUT AID MOL DES, V19, P137, DOI 10.1007/s10822-005-3321-5; Wang YH, 2005, J CHEM INF MODEL, V45, P750, DOI 10.1021/ci050041k; Waring MJ, 2007, BIOORG MED CHEM LETT, V17, P1759, DOI 10.1016/j.bmcl.2006.12.061; Watkins RE, 2001, SCIENCE, V292, P2329, DOI 10.1126/science.1060762; Watkins RE, 2003, BIOCHEMISTRY-US, V42, P1430, DOI 10.1021/bi0268753; WEGNER JK, 2005, JOELIB TUTORIAL JAVA; Wijnholds J, 2000, P NATL ACAD SCI USA, V97, P7476, DOI 10.1073/pnas.120159197; Williams PA, 2004, SCIENCE, V305, P683, DOI 10.1126/science.1099736; Witchel HJ, 2007, EXPERT OPIN THER TAR, V11, P321, DOI 10.1517/14728222.11.3.321; Witten I. H., 2005, DATA MINING PRACTICA; Xie W, 2000, NATURE, V406, P435, DOI 10.1038/35019116; Xie W, 2000, GENE DEV, V14, P3014, DOI 10.1101/gad.846800; Xue Y, 2004, J CHEM INF COMP SCI, V44, P1630, DOI 10.1021/ci049869h; Xue Y, 2004, J CHEM INF COMP SCI, V44, P1497, DOI 10.1021/ci049971e; YANG S, 2004, P C EV COMP; Yang Y., 1997, P INT C MACH LEARN; Yap CW, 2005, J CHEM INF MODEL, V45, P982, DOI 10.1021/ci0500536; Yap CW, 2004, TOXICOL SCI, V79, P170, DOI 10.1093/toxsci/kfh082; Yoshida K, 2006, J CHEM INF MODEL, V46, P1371, DOI 10.1021/ci050450g; Zaki M. J., 2000, LARGE SCALE PARALLEL; Zdrazil B, 2007, QSAR COMB SCI, V26, P669, DOI 10.1002/qsar.200610149; Zolotoy Alexander B., 2003, Current Medicinal Chemistry - Cardiovascular & Hematological Agents, V1, P225, DOI 10.2174/1568016033477432; Zuegge J, 2002, QUANT STRUCT-ACT REL, V21, P249, DOI 10.1002/1521-3838(200208)21:3<249::AID-QSAR249>3.0.CO;2-S; [Anonymous], 2005, INTRO DATA MINING; *CHEMICALCOMPUTING, 2006, MOE MOL OP ENV VERS	215	11	11	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y-2, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	1573-4099		CURR COMPUT-AID DRUG	Curr. Comput.-Aided Drug Des.	JUN	2008	4	2					91	110		10.2174/157340908784533256		20	Chemistry, Medicinal; Computer Science, Interdisciplinary Applications	Pharmacology & Pharmacy; Computer Science	310ZS	WOS:000256570200002	
J	Du, QS; Huang, RB; Chou, KC				Du, Qi-Shi; Huang, Ri-Bo; Chou, Kuo-Chen			Recent advances in QSAR and their applications in predicting the activities of chemical molecules, peptides and proteins for drug design	CURRENT PROTEIN & PEPTIDE SCIENCE			English	Review						FB-QSAR; MF-3D-QSAR; AABPP; drug design; protein; peptide; activity prediction; physicochemical properties; iterative equations	AMINO-ACID-COMPOSITION; SUBCELLULAR LOCATION PREDICTION; SUPPORT VECTOR MACHINES; INFLUENZA NEURAMINIDASE INHIBITORS; STRUCTURAL CLASS PREDICTION; PROTEASE CLEAVAGE SITES; LIPOPHILICITY POTENTIAL HMLP; IMPROVED HYBRID APPROACH; VIRUS TYPE-1 PROTEASE; PARTIAL LEAST-SQUARES	This review is to summarize three new QSAR (quantitative structure-activity relationship) methods recently developed in our group and their applications for drug design. Based on more solid theoretical models and advanced mathematical techniques, the conventional QSAR technique has been recast in the following three aspects. (1) In the fragment-based two dimensional QSAR, or abbreviated as FB-QSAR, the molecular structures in a family of drug candidates are divided into several fragments according to the substitutes being investigated. The bioactivities of drug candidates are correlated with physicochemical properties of the molecular fragments through two sets of coefficients: one is for the physicochemical properties and the other for the molecular fragments. (2) In the multiple field three dimensional QSAR, or MF-3D-QSAR, more molecular potential fields are integrated into the comparative molecular field analysis (CoMFA) through two sets of coefficients: one is for the potential fields and the other for the Cartesian three dimensional grid points. (3) In the AABPP (amino acid-based peptide prediction), the bioactivities of peptides or proteins are correlated with the physicochemical properties of all or partial residues of the sequence through two sets of coefficients: one is for the physicochemical properties of amino acids and the other for the weight factors of the residues. Meanwhile, an iterative double least square (IDLS) technique is developed for solving the two sets of coefficients in a training dataset alternately and iteratively. Using the two sets of coefficients, one can predict the bioactivity of a query peptide, protein, or drug candidate. Compared with the old methods, the new QSAR approaches as summarized in this review possess machine learning ability, can remarkably enhance the prediction power, and provide more structural information. Meanwhile, the future challenge and possible development in this area have been briefly addressed as well.	[Du, Qi-Shi; Huang, Ri-Bo] Guangxi Univ, Key Lab Subtrop Bioresource Conservat & Utilizat, Nanning 530004, Peoples R China; [Huang, Ri-Bo] Guangxi Acad Sci, Nanning 530004, Peoples R China; [Du, Qi-Shi; Chou, Kuo-Chen] Gordon Life Sci Inst, San Diego, CA 92130 USA	Du, QS (reprint author), Guangxi Univ, Key Lab Subtrop Bioresource Conservat & Utilizat, Nanning 530004, Peoples R China.	duqishi@yahoo.com; kcchou@gordonlifescience.org	Chou, Kuo-Chen/A-8340-2009				Adessi C, 2002, CURR MED CHEM, V9, P963, DOI 10.2174/0929867024606731; Baldi P., 1998, BIOINFORMATICS MACHI; Cai YD, 2004, J THEOR BIOL, V228, P551, DOI 10.1016/j.jtbi.2004.02.019; Chen C, 2006, ANAL BIOCHEM, V357, P116, DOI 10.1016/j.ab.2006.07.022; Chen C, 2006, J THEOR BIOL, V243, P444, DOI 10.1016/j.jtbi.2006.06.025; Chen J, 2007, AMINO ACIDS, V33, P423, DOI 10.1007/s00726-006-0485-9; Chen YL, 2007, J THEOR BIOL, V248, P377, DOI 10.1016/j.jtbi.2007.05.019; Chou KC, 2004, PROTEINS, V55, P77, DOI 10.1002/prot.10622; Chou KC, 2004, BIOCHEM BIOPH RES CO, V316, P636, DOI 10.1016/j.bbrc.2004.02.098; Chou KC, 2007, ANAL BIOCHEM, V370, P1, DOI 10.1016/j.ab.2007.07.006; Chou KC, 2008, NAT PROTOC, V3, P153, DOI 10.1038/nprot.2007.494; Chou KC, 2007, J CELL BIOCHEM, V100, P665, DOI 10.1002/jcb.21096; Chou K.C., 2006, FRONTIERS MED CHEM, V3, P455; Chou KC, 2006, J PROTEOME RES, V5, P1888, DOI 10.1021/pr060167c; Chou KC, 2007, BIOCHEM BIOPH RES CO, V357, P633, DOI 10.1016/j.bbrc.2007.03.162; Chou KC, 1996, ANAL BIOCHEM, V233, P1, DOI 10.1006/abio.1996.0001; Chou KC, 2006, CURR MED CHEM, V13, P3263, DOI 10.2174/092986706778773077; Chou KC, 2004, CURR MED CHEM, V11, P2105; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2000, ANAL BIOCHEM, V286, P1, DOI 10.1006/abio.2000.4757; Chou KC, 2007, BIOCHEM BIOPH RES CO, V360, P339, DOI 10.1016/j.bbrc.2007.06.027; Chou KC, 2007, J PROTEOME RES, V6, P1728, DOI 10.1021/pr060635i; Chou KC, 2006, BIOCHEM BIOPH RES CO, V347, P150, DOI 10.1016/j.bbrc.2006.06.059; CHOU KC, 1993, J BIOL CHEM, V268, P16938; COLMAN PM, 1994, PROTEIN SCI, V3, P1687; Cramer R D 3rd, 1989, Prog Clin Biol Res, V291, P161; de Jong MD, 2006, J CLIN VIROL, V35, P2, DOI 10.1016/j.jcv.2005.09.002; Diao Y, 2008, AMINO ACIDS, V34, P111, DOI 10.1007/s00726-007-0550-z; Ding YS, 2007, PROTEIN PEPTIDE LETT, V14, P811; Du PF, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-518; Du QH, 2005, ANAL BIOCHEM, V337, P262, DOI 10.1016/j.ab.2004.10.003; Du QH, 1996, J COMPUT AID MOL DES, V10, P133, DOI 10.1007/BF00402821; Du QS, 1998, J COMPUT AID MOL DES, V12, P451, DOI 10.1023/A:1008040309114; Du QS, 2007, PROTEIN ENG DES SEL, V20, P417, DOI 10.1093/protein/gzm036; Du QS, 2005, J CHEM INF MODEL, V45, P347, DOI 10.1021/ci0497071; Du QS, 2005, J COMPUT CHEM, V26, P461, DOI 10.1002/jcc.20174; Du QS, 2007, J COMPUT CHEM, V28, P2043, DOI 10.1002/jcc.20732; Du QS, 2006, J COMPUT CHEM, V27, P685, DOI 10.1002/jcc.20369; DU QS, 2007, J COMPUT CHEM, V29, P211; Du QS, 1997, J COMPUT AID MOL DES, V11, P503, DOI 10.1023/A:1007949918800; Du QS, 2007, BIOCHEM BIOPH RES CO, V362, P525, DOI 10.1016/j.bbrc.2007.08.025; Dunn CJ, 1999, DRUGS, V58, P761, DOI 10.2165/00003495-199958040-00016; Ertl P, 2000, J MED CHEM, V43, P3714, DOI 10.1021/jm000942e; Fang Y, 2008, AMINO ACIDS, V34, P103, DOI 10.1007/s00726-007-0568-2; Ferguson NM, 2005, NATURE, V437, P209, DOI 10.1038/nature04017; Gao Y, 2005, AMINO ACIDS, V28, P373, DOI 10.1007/s00726-005-0206-9; Garcia KC, 1999, IMMUNOL REV, V172, P73, DOI 10.1111/j.1600-065X.1999.tb01357.x; Guo YZ, 2006, AMINO ACIDS, V30, P397, DOI 10.1007/s00726-006-0332-z; Hagmann M, 1999, SCIENCE, V286, P666, DOI 10.1126/science.286.5440.666; Hall LH, 1997, MED CHEM RES, V7, P407; Hansch C., 1971, DRUG DESIGN, V1; HANSCH C, 1963, J AM CHEM SOC, V85, P2817, DOI 10.1021/ja00901a033; Hansch C. L., 1979, SUBSTITUTE CONSTANTS; HELLAND IS, 1990, SCAND J STAT, V17, P97; Hopfinger AJ, 1997, J AM CHEM SOC, V119, P10509, DOI 10.1021/ja9718937; JARDETZKY TS, 1991, NATURE, V353, P326, DOI 10.1038/353326a0; Kedarisetti KD, 2006, BIOCHEM BIOPH RES CO, V348, P981, DOI 10.1016/j.bbrc.2006.07.141; Kier LB, 2001, SAR QSAR ENVIRON RES, V12, P55, DOI 10.1080/10629360108035371; Kim CU, 1997, J AM CHEM SOC, V119, P681, DOI 10.1021/ja963036t; Kim CU, 1999, ANTIVIR CHEM CHEMOTH, V10, P141; Kim CU, 1998, J MED CHEM, V41, P2451, DOI 10.1021/jm980162u; Klebe G, 1999, J COMPUT AID MOL DES, V13, P1, DOI 10.1023/A:1008047919606; KLEBE G, 1994, J COMPUT AID MOL DES, V8, P583, DOI 10.1007/BF00123667; Le QM, 2005, NATURE, V437, P1108, DOI 10.1038/4371108a; Lew W, 2000, CURR MED CHEM, V7, P663; Li FM, 2008, AMINO ACIDS, V34, P119, DOI 10.1007/s00726-007-0545-9; Liang GZ, 2007, BIOPOLYMERS, V88, P401, DOI 10.1002/bip.20669; Lin H, 2007, BIOCHEM BIOPH RES CO, V354, P548, DOI 10.1016/j.bbrc.2007.01.011; Lin H, 2007, J COMPUT CHEM, V28, P1463, DOI 10.1002/jcc.20554; Liu DQ, 2007, AMINO ACIDS, V32, P493, DOI 10.1007/s00726-006-0466-z; Maring CJ, 2005, J MED CHEM, V48, P3980, DOI 10.1021/jm049276y; MARSHALL GR, 1988, TRENDS PHARMACOL SCI, V9, P285, DOI 10.1016/0165-6147(88)90012-0; Mondal S, 2006, J THEOR BIOL, V243, P252, DOI 10.1016/j.jtbi.2006.06.014; Mundra P, 2007, PATTERN RECOGN LETT, V28, P1610, DOI 10.1016/j.patrec.2007.04.001; Niu B, 2006, PROTEIN PEPTIDE LETT, V13, P489, DOI 10.2174/092986606776819619; Oprea TI, 2000, J COMPUT AID MOL DES, V14, P251, DOI 10.1023/A:1008130001697; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; Parkhurst MR, 1996, J IMMUNOL, V157, P2539; Rognvaldsson T, 2007, EXPERT REV MOL DIAGN, V7, P435, DOI 10.1586/14737159.7.4.435; Rose K, 2002, J CHEM INF COMP SCI, V42, P651, DOI 10.1021/ci010127n; Shen HB, 2007, AMINO ACIDS, V33, P57, DOI 10.1007/s00726-006-0478-8; Shen HB, 2007, BIOPOLYMERS, V85, P233, DOI 10.1002/bip.20640; Shen HB, 2007, BIOCHEM BIOPH RES CO, V363, P297, DOI 10.1016/j.bbrc.2007.08.140; Shen HB, 2007, PROTEIN ENG DES SEL, V20, P39, DOI 10.1093/protein-gzl053; Shen HB, 2007, BIOCHEM BIOPH RES CO, V355, P1006, DOI 10.1016/j.bbrc.2007.02.071; Shen HB, 2007, BIOCHEM BIOPH RES CO, V364, P53, DOI 10.1016/j.bbrc.2007.09.098; Shen HB, 2007, AMINO ACIDS, V32, P483, DOI 10.1007/s00726-006-0439-2; Shi JY, 2007, AMINO ACIDS, V33, P69, DOI 10.1007/s00726-006-0475-y; Smith BJ, 2001, PROTEIN SCI, V10, P689, DOI 10.1110/ps.41801; Sun XD, 2006, AMINO ACIDS, V30, P469, DOI 10.1007/s00726-005-0239-0; Tan F, 2007, AMINO ACIDS, V33, P669, DOI 10.1007/s00726-006-0465-0; Tetko IV, 2005, J COMPUT AID MOL DES, V19, P453, DOI 10.1007/s10822-005-8694-y; Tetko IV, 2005, DRUG DISCOV TODAY, V10, P1497, DOI 10.1016/S1359-6446(05)03584-1; Thompson TB, 1995, J THEOR BIOL, V177, P369, DOI 10.1006/jtbi.1995.0254; Tong W, 1998, J CHEM INF COMP SCI, V38, P669, DOI 10.1021/ci980008g; Venkatesan N, 2002, CURR MED CHEM, V9, P2243; VISWANADHAN VN, 1991, J MED CHEM, V34, P526, DOI 10.1021/jm00106a007; WALLER CL, 1993, J MED CHEM, V36, P2390, DOI 10.1021/jm00068a017; Wang M, 2005, AMINO ACIDS, V28, P395, DOI 10.1007/s00726-005-0189-6; Wang M, 2005, AMINO ACIDS, V29, P301, DOI 10.1007/s00726-005-0258-x; Wang SQ, 2007, BIOCHEM BIOPH RES CO, V354, P634, DOI 10.1016/j.bbrc.2006.12.235; Wei DQ, 2006, BIOCHEM BIOPH RES CO, V344, P1048, DOI 10.1016/j.bbrc.2006.03.210; WEN Z, 2006, AMINO ACIDS, V32, P277; Xiao X, 2007, PROTEIN PEPTIDE LETT, V14, P871, DOI 10.2174/092986607782110293; Xiao X, 2006, AMINO ACIDS, V30, P49, DOI 10.1007/s00726-005-0225-6; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; You LW, 2005, J VIROL, V79, P12477, DOI 10.1128/JVI.79.19.12477-12486.2005; Zhang SW, 2006, AMINO ACIDS, V30, P461, DOI 10.1007/s00726-006-0263-8; Zhang TL, 2007, AMINO ACIDS, V33, P623, DOI 10.1007/s00726-007-0496-1; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou XB, 2007, J THEOR BIOL, V248, P546, DOI 10.1016/j.jtbi.2007.06.001	113	82	82	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y26, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	1389-2037		CURR PROTEIN PEPT SC	Curr. Protein Pept. Sci.	JUN	2008	9	3					248	259		10.2174/138920308784534005		12	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	323QG	WOS:000257461800005	
J	Fan, S; Chen, L; Lee, WJ				Fan, Shu; Chen, Luonan; Lee, Wei-Jen			Machine learning based switching model for electricity load forecasting	ENERGY CONVERSION AND MANAGEMENT			English	Article						electricity load forecasting; machine learning; Bayesian clustering; support vector regression; non-stationarity	NETWORKS	In deregulated power markets, forecasting electricity loads is one of the most essential tasks for system planning, operation and decision making. Based on an integration of two machine learning techniques: Bayesian clustering by dynamics (BCD) and support vector regression (SVR), this paper proposes a novel forecasting model for day ahead electricity load forecasting. The proposed model adopts an integrated architecture to handle the non-stationarity of time series. Firstly, a BCD classifier is applied to cluster the input data set into several subsets by the dynamics of the time series in an unsupervised manner. Then, groups of SVRs are used to fit the training data of each subset in a supervised way. The effectiveness of the proposed model is demonstrated with actual data taken from the New York ISO and the Western Farmers Electric Cooperative in Oklahoma. (C) 2008 Elsevier Ltd. All rights reserved.	[Fan, Shu; Lee, Wei-Jen] Univ Texas Arlington, Energy Syst Res Ctr, Arlington, TX 76019 USA; [Chen, Luonan] Osaka Sangyo Univ, Dept Elect Informat & Commun Engn, Osaka 5740013, Japan	Lee, WJ (reprint author), Univ Texas Arlington, Energy Syst Res Ctr, 416 S Coll St, Arlington, TX 76019 USA.	wlce@uta.edu					Amjady N, 2001, IEEE T POWER SYST, V16, P798, DOI 10.1109/59.962429; Box G.E.P., 1976, TIME SERIES ANAL; Bunn D. W., 1985, COMP MODELS ELECT LO; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Chen BJ, 2004, IEEE T POWER SYST, V19, P1821, DOI 10.1109/TPWRS.2004.835679; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Fan S, 2005, LECT NOTES COMPUT SC, V3498, P640; Fan S, 2006, IEEE T POWER SYST, V21, P392, DOI 10.1109/TPWRS.2005.860944; Fidalgo JN, 2005, IEEE T POWER SYST, V20, P408, DOI 10.1109/TPWRS.2004.840439; Fox J., 1997, APPL REGRESSION ANAL; HAIDA T, 1994, IEEE T POWER SYST, V9, P1788, DOI 10.1109/59.331433; Hippert HS, 2001, IEEE T POWER SYST, V16, P44, DOI 10.1109/59.910780; Huang SJ, 2003, IEEE T POWER SYST, V18, P673, DOI 10.1109/TPWRS.2003.811010; Infield DG, 1998, IEEE T POWER SYST, V13, P1115, DOI 10.1109/59.709108; KHOTANZAD A, 1995, IEEE T POWER SYST, V10, P1716, DOI 10.1109/59.466468; MOLLER KR, 1999, ADV KERNEL METHODS S, P243; Ramoni M, 2002, MACH LEARN, V47, P91, DOI 10.1023/A:1013635829250; Saini LM, 2002, IEEE T POWER SYST, V17, P907, DOI 10.1109/TPWRS.2002.800992; SEBASTIANI P, 2001, P 18 INT C MACH LEAR, P497; Senjyu T, 2005, IEEE T POWER SYST, V20, P102, DOI [10.1109/TPWRS.2004.831256, 10.1109/TPWRS.2004.0831256]; Song KB, 2005, IEEE T POWER SYST, V20, P96, DOI 10.1109/TPWRS.2004.835632; Tayor J. W., 2002, IEEE T POWER SYSTEMS, V17, P626; ZBILUT JP, 1992, PHYS LETT A, V171, P199, DOI 10.1016/0375-9601(92)90426-M	23	7	7	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0196-8904		ENERG CONVERS MANAGE	Energy Conv. Manag.	JUN	2008	49	6					1331	1344		10.1016/j.enconman.2008.01.008		14	Thermodynamics; Energy & Fuels; Mechanics; Physics, Nuclear	Thermodynamics; Energy & Fuels; Mechanics; Physics	306UN	WOS:000256273400005	
J	Belanche-Munoz, L; Blanch, AR				Belanche-Munoz, Lluis; Blanch, Anicet R.			Machine learning methods for microbial source tracking	ENVIRONMENTAL MODELLING & SOFTWARE			English	Article						microbial source tracking; water; machine learning methods; microbial indicators; faecal pollution	ANTIBIOTIC-RESISTANCE PATTERNS; DISCRIMINANT-ANALYSIS; FECAL CONTAMINATION; WATER; CLASSIFICATION; POLLUTION; BACTERIA	This paper reports on a successful application of statistical and inductive learning methods to determine optimal discriminating parameters and develop predictive models for the determination of faecal sources in waters, recently and heavily polluted with wastewaters (microbial source tracking). The data comes from an international study in which various microbial and chemical parameters were determined in heavily polluted waters from diverse geographical areas. A total of 38 variables derived from the microbial and chemical parameters were defined to characterise the available 103 observations. Four methods were evaluated: Euclidean k-nearest-neighbour, linear Bayesian classifier, quadratic Bayesian classifier and a support vector machine. The main aim was the obtention of highly accurate predictive models using the lowest number of variables possible. After a strong feature selection process, the obtained results show that predictive models using only two variables emerge with 100% correct classification. The obtained solutions make use of a linear combination of a discriminating tracer (the enumeration of phages infecting Bacteroides thetaiotaomicron) and a universal non-discriminant faecal indicator. Other models not using the discriminant tracer were developed, though a higher number of variables was needed to achieve a high rate of correct classification. (c) 2007 Elsevier Ltd. All rights reserved.	[Belanche-Munoz, Lluis] Univ Politecn Cataluna, Dept Software, Barcelona, Catalonia, Spain; [Blanch, Anicet R.] Univ Barcelona, Dept Microbiol, Barcelona, Spain	Belanche-Munoz, L (reprint author), Univ Politecn Cataluna, Dept Software, Jordi Girona 1-3, Barcelona, Catalonia, Spain.	belanche@lsi.upc.edu	Blanch, Anicet/B-7573-2012				Bazaraa MS, 2006, NONLINEAR PROGRAMMIN; Blanch AR, 2006, APPL ENVIRON MICROB, V72, P5915, DOI 10.1128/AEM.02453-05; Blanch Anicet R., 2004, Journal of Water and Health, V2, P249; Brion GM, 2002, WATER RES, V36, P3765, DOI 10.1016/S0043-1354(02)00091-X; Burges C.J.C., 1998, DATA MIN KNOWL DISC, V2, P955; Christianini N., 2000, INTRO SUPPORT VECTOR; Dixon M, 2007, ENVIRON MODELL SOFTW, V22, P315, DOI 10.1016/j.envsoft.2005.07.031; Duda R. O., 2001, PATTERN CLASSIFICATI; Everitt B. S., 1993, CLUSTER ANAL; Field KG, 2003, ENVIRON MONIT ASSESS, V81, P313, DOI 10.1023/A:1021349629950; Gibert K, 2006, ENVIRON MODELL SOFTW, V21, P115, DOI 10.1016/j.envsoft.2005.01.004; Harwood VJ, 2000, APPL ENVIRON MICROB, V66, P3698, DOI 10.1128/AEM.66.9.3698-3704.2000; Hertz J., 1991, INTRO THEORY NEURAL; Kanevski M, 2004, ENVIRON MODELL SOFTW, V19, P845, DOI 10.1016/j.envsoft.2003.03.004; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; LIU H, 1998, SPRINGER INT SERIES, V454; Malakoff D, 2002, SCIENCE, V295, P2352, DOI 10.1126/science.295.5564.2352; McCullagh P., 1989, GEN LINEAR MODELS; Mitchell M., 1997, MACHINE LEARNING; Myoda Samuel P., 2003, Journal of Water and Health, V1, P167; Payan A, 2005, APPL ENVIRON MICROB, V71, P5659, DOI 10.1128/AEM.71.9.5659-5662.2005; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Rendell L.A., 1992, P 10 NAT C ART INT, P129; Ritter Kerry J., 2003, Journal of Water and Health, V1, P209; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; Scott TM, 2002, APPL ENVIRON MICROB, V68, P5796, DOI 10.1128/AEM.68.12.5796-5803.2002; Simpson JM, 2002, ENVIRON SCI TECHNOL, V36, P5279, DOI 10.1021/es026000b; Stewart Jill R., 2003, Journal of Water and Health, V1, P225; Vapnik VN, 1998, STAT LEARNING THEORY; Wiggins BA, 1996, APPL ENVIRON MICROB, V62, P3997	30	8	8	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1364-8152		ENVIRON MODELL SOFTW	Environ. Modell. Softw.	JUN	2008	23	6					741	750		10.1016/j.envsoft.2007.09.013		10	Computer Science, Interdisciplinary Applications; Engineering, Environmental; Environmental Sciences	Computer Science; Engineering; Environmental Sciences & Ecology	276LR	WOS:000254144000006	
J	Zeller, G; Clark, RM; Schneeberger, K; Bohlen, A; Weigel, D; Ratsch, G				Zeller, Georg; Clark, Richard M.; Schneeberger, Korbinian; Bohlen, Anja; Weigel, Detlef; Raetsch, Gunnar			Detecting polymorphic regions in Arabidopsis thaliana with resequencing microarrays	GENOME RESEARCH			English	Article							INBRED MOUSE STRAINS; HUMAN GENOME; LINKAGE DISEQUILIBRIUM; DISEASE RESISTANCE; ADAPTIVE EVOLUTION; SEQUENCE; GENE; DNA; MAP; REVEALS	Whole-genome oligonucleotide resequencing arrays have allowed the comprehensive discovery of single nucleotide polymorphisms (SNPs) in eukaryotic genomes of moderate to large size. With this technology, the detection rate for isolated SNPs is typically high. However, it is greatly reduced when other polymorphisms are located near a SNP as multiple mismatches inhibit hybridization to arrayed oligonucleotides. Contiguous tracts of suppressed hybridization therefore typify polymorphic regions (PRs) such as clusters of SNPs or deletions. We developed a machine learning method, designated margin-based prediction of polymorphic regions (mPPR), to predict PRs from resequencing array data. Conceptually similar to hidden Markov models, the method is trained with discriminative learning techniques related to support vector machines, and accurately identifies even very short polymorphic tracts (<10 bp). We applied this method to resequencing array data previously generated for the euchromatic genomes of 20 strains (accessions) of the best-characterized plant, Arabidopsis thaliana. Nonredundantly, 27% of the genome was included within the boundaries of PRs predicted at high specificity (approximate to 97%). The resulting data set provides a fine-scale view of polymorphic sequences in A. thaliana; patterns of polymorphism not apparent in SNP data were readily detected, especially for noncoding regions. Our predictions provide a valuable resource for evolutionary genetic and functional studies in A. thaliana, and our method is applicable to similar data sets in other species. More broadly, our computational approach can be applied to other segmentation tasks related to the analysis of genomic variation.	[Zeller, Georg; Bohlen, Anja; Raetsch, Gunnar] Max Planck Soc, Friedrich Miescher Lab, D-72070 Tubingen, Germany; [Zeller, Georg; Clark, Richard M.; Schneeberger, Korbinian; Weigel, Detlef] Max Planck Inst Dev Biol, Dept Mol Biol, D-72070 Tubingen, Germany	Ratsch, G (reprint author), Max Planck Soc, Friedrich Miescher Lab, D-72070 Tubingen, Germany.	Gunnar.Raetsch@tuebingen.mpg.de	Weigel, Detlef/C-1418-2008; Ratsch, Gunnar/B-8182-2009	Weigel, Detlef/0000-0002-2114-7963; 			Alonso JM, 2006, NAT REV GENET, V7, P524, DOI 10.1038/nrg1893; Altunel Y, 2003, IEEE SOFTWARE, V20, P10; Kaul S, 2000, NATURE, V408, P796; Bakker EG, 2006, PLANT CELL, V18, P1803, DOI 10.1105/tpc.106.042614; Bernal A, 2007, PLOS COMPUT BIOL, V3, P488, DOI 10.1371/journal.pcbi.0030054; Bolstad BM, 2003, BIOINFORMATICS, V19, P185, DOI 10.1093/bioinformatics/19.2.185; Borevitz JO, 2007, P NATL ACAD SCI USA, V104, P12057, DOI 10.1073/pnas.0705323104; Burge C, 1997, J MOL BIOL, V268, P78, DOI 10.1006/jmbi.1997.0951; Chee M, 1996, SCIENCE, V274, P610, DOI 10.1126/science.274.5287.610; Clark RM, 2007, SCIENCE, V317, P338, DOI 10.1126/science.1138632; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cutler DJ, 2001, GENOME RES, V11, P1913; Dawson E, 2001, GENOME RES, V11, P170, DOI 10.1101/gr.156901; Durbin R., 1998, BIOL SEQUENCE ANAL P; Fahlgren N, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000219; Frazer KA, 2004, GENOME RES, V14, P1493, DOI 10.1101/gr.262804; Frazer KA, 2007, NATURE, V448, P1050, DOI 10.1038/nature06067; Giegerich R, 2004, SCI COMPUT PROGRAM, V51, P215, DOI 10.1016/j.scico.2003.12.005; GRANT MR, 1995, SCIENCE, V269, P843, DOI 10.1126/science.7638602; Grant MR, 1998, P NATL ACAD SCI USA, V95, P15843, DOI 10.1073/pnas.95.26.15843; HETTICH R, 1993, SIAM REV, V35, P380, DOI 10.1137/1035089; Hinds DA, 2006, NAT GENET, V38, P82, DOI 10.1038/ng1695; Hinds DA, 2005, SCIENCE, V307, P1072, DOI 10.1126/science.1105436; Altshuler D, 2005, NATURE, V437, P1299, DOI 10.1038/nature04226; Johanson U, 2000, SCIENCE, V290, P344, DOI 10.1126/science.290.5490.344; Jones JDG, 2006, NATURE, V444, P323, DOI 10.1038/nature05286; Jones-Rhoades MW, 2006, ANNU REV PLANT BIOL, V57, P19, DOI 10.1146/annurev.arplant.57.032905.105218; Kim S, 2007, NAT GENET, V39, P1151, DOI 10.1038/ng2115; Lafferty J., 2001, P 18 INT C MACH LEAR; Lee I, 2004, NUCLEIC ACIDS RES, V32, P681, DOI 10.1093/nar/gkh196; Lee JY, 2006, P NATL ACAD SCI USA, V103, P6055, DOI 10.1073/pnas.0510607103; McNally KL, 2006, PLANT PHYSIOL, V141, P26, DOI 10.1104/pp.106.077313; Mills RE, 2006, GENOME RES, V16, P1182, DOI 10.1101/gr.4565806; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Mural RJ, 2002, SCIENCE, V296, P1661, DOI 10.1126/science.1069193; NGUYEN N., 2007, P 24 INT C MACH LEAR, P681, DOI 10.1145/1273496.1273582; Nordborg Magnus, 2005, PLoS Biol, V3, pe196, DOI 10.1371/journal.pbio.0030196; O'Connor TR, 2005, BIOINFORMATICS, V21, P4411, DOI 10.1093/bioinformatics/bti714; Patil N, 2001, SCIENCE, V294, P1719, DOI 10.1126/science.1065573; Rajagopalan R, 2006, GENE DEV, V20, P3407, DOI 10.1101/gad.1476406; RATSCH G, 2007, ADV NEURAL INFORM PR, V19, P1161; Ratsch G, 2007, PLOS COMPUT BIOL, V3, P313, DOI 10.1371/journal.pcbi.0030020; RATSCH G, 2002, MACH LEARN, V48, P193; Schmid KJ, 2003, GENOME RES, V13, P1250, DOI 10.1101/gr.728603; Schmid KJ, 2005, GENETICS, V169, P1601, DOI 10.1534/genetics.104.033795; Scholkopf B., 2002, LEARNING KERNELS; Schulze U, 2007, BIOINFORMATICS, V23, P1892, DOI 10.1093/bioinformatics/btm275; Sha F., 2007, ADV NEURAL INFORM PR, V19, P1249; Shen JD, 2006, GENETICS, V172, P1243, DOI 10.1534/genetics.105.047290; Shendure J, 2004, NAT REV GENET, V5, P335, DOI 10.1038/nrg1325; SONG WY, 1995, SCIENCE, V270, P1804, DOI 10.1126/science.270.5243.1804; Taskar B, 2004, ADV NEUR IN, V16, P25; Thomas JH, 2006, GENOME RES, V16, P1017, DOI 10.1101/gr.5089806; Toomajian C, 2006, PLOS BIOL, V4, P732, DOI 10.1371/journal.pbio.0040137; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Tuskan GA, 2006, SCIENCE, V313, P1596, DOI 10.1126/science.1128691; Vapnik V. N, 1995, NATURE STAT LEARNING; Wicks SR, 2001, NAT GENET, V28, P160, DOI 10.1038/88878; Windsor AJ, 2006, PLANT PHYSIOL, V140, P1169, DOI 10.1104/pp.105.073981; Wright SI, 2005, MOL BIOL EVOL, V22, P506, DOI 10.1093/molbev/msi035	60	35	35	COLD SPRING HARBOR LAB PRESS, PUBLICATIONS DEPT	WOODBURY	500 SUNNYSIDE BLVD, WOODBURY, NY 11797-2924 USA	1088-9051		GENOME RES	Genome Res.	JUN	2008	18	6					918	929		10.1101/gr.070169.107		12	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Genetics & Heredity	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Genetics & Heredity	307YT	WOS:000256356200009	
J	Wu, W; Gao, XR; Hong, B; Gao, SK				Wu, Wei; Gao, Xiaorong; Hong, Bo; Gao, Shangkai			Classifying single-trial EEG during motor imagery by iterative spatio-spectral patterns learning (ISSPL)	IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING			English	Article						brain-computer interface (BCI); common spatial patterns (CSPs); maximal margin hyperplane; single-trial EEG; motor imagery; spatio-spectral filters	BRAIN-COMPUTER INTERFACES; MU-RHYTHM; SYNCHRONIZATION; CLASSIFICATION; COMMUNICATION; FILTERS	In most current motor-imagery-based brain-computer interfaces (BCIs), machine learning is carried out in two consecutive stages: feature extraction and feature classification. Feature extraction has focused on automatic learning of spatial filters, with little or no attention being paid to optimization of parameters for temporal filters that still require time-consuming, ad hoc manual tuning. In this paper, we present a new algorithm termed iterative spatio-spectral patterns learning (ISSPL) that employs statistical learning theory to perform automatic learning of spatio-spectral filters. In ISSPL, spectral filters and the classifier are simultaneously parameterized for optimization to achieve good generalization performance. A detailed derivation and theoretical analysis of ISSPL are given. Experimental results on two datasets show that the proposed algorithm can correctly identify the discriminative frequency bands, demonstrating the algorithm's superiority over contemporary approaches in classification performance.	[Wu, Wei; Gao, Xiaorong; Hong, Bo; Gao, Shangkai] Tsinghua Univ, Dept Biomed Engn, Beijing 100084, Peoples R China	Wu, W (reprint author), Tsinghua Univ, Dept Biomed Engn, Beijing 100084, Peoples R China.	wuwei03@mails.tsinghua.edu.cn; gxr-dea@tsinghua.edu.cn; hongbo@tsinghua.edu.cn; gsk-dea@tsinghua.edu.cn					Bashashati A, 2007, J NEURAL ENG, V4, pR32, DOI 10.1088/1741-2560/4/2/R03; Bishop C. M., 2006, PATTERN RECOGNITION; Blankertz B, 2008, IEEE SIGNAL PROC MAG, V25, P41, DOI [10.1109/MSP.2008.4408441, 10.1109/MSP.200790.900,9]; Blankertz B, 2004, IEEE T BIO-MED ENG, V51, P1044, DOI 10.1109/TBME.2004.826692; Boyd S, 2004, CONVEX OPTIMIZATION; DOMHEGE G, 2006, IEEE T BIOMED ENG, V53, P2274; DOMHEGE G, 2007, BRAIN COMPUTER INTER; FUKUNAGA K, 1970, IEEE T COMPUT, VC 19, P311, DOI 10.1109/T-C.1970.222918; HILL NJ, 2007, BRAIN COMPUTER INTER; Horn RA, 1986, MATRIX ANAL; Lemm S, 2005, IEEE T BIO-MED ENG, V52, P1541, DOI 10.1109/TBME.2005.851521; McFarland DJ, 2006, IEEE T NEUR SYS REH, V14, P135, DOI 10.1109/TNSRE.2006.875637; Muller K.-R., 2004, BIOMED TECH, V49, P11; Naeem M, 2006, J NEURAL ENG, V3, P208, DOI 10.1088/1741-2560/3/3/003; Nunez P. L, 1981, ELECT FIELDS BRAIN N; Oppenheim A. V., 1975, DIGITAL SIGNAL PROCE; Pfurtscheller G, 2006, NEUROIMAGE, V31, P153, DOI 10.1016/j.neuroimage.2005.12.003; PFURTSCHELLER G, 1994, NEUROSCI LETT, V174, P93, DOI 10.1016/0304-3940(94)90127-9; PFURTSCHELLER G, 1993, J MICROCOMPUT APPL, V16, P293, DOI 10.1006/jmca.1993.1030; Platt J., 1998, ADV KERNEL METHODS S; Qin Lei, 2005, J Neural Eng, V2, P65, DOI 10.1088/1741-2560/2/4/001; Ramoser H, 2000, IEEE T REHABIL ENG, V8, P441, DOI 10.1109/86.895946; Scott SH, 2006, NATURE, V442, P141, DOI 10.1038/442141a; Strang G., 1997, WAVELETS FILTER BANK; TOMIOKA R, 2006, 40 U TOKY DEP MATH E; Vapnik VN, 1998, STAT LEARNING THEORY; Varela F, 2001, NAT REV NEUROSCI, V2, P229, DOI 10.1038/35067550; WANG Y, UNPUB IEEE T BIOMED; Wang YH, 1999, CLIN NEUROPHYSIOL, V110, P604, DOI 10.1016/S1388-2457(98)00056-X; Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3	30	29	32	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9294		IEEE T BIO-MED ENG	IEEE Trans. Biomed. Eng.	JUN	2008	55	6					1733	1743		10.1109/TBME.2008.919125		11	Engineering, Biomedical	Engineering	305BX	WOS:000256153900011	
J	Yoo, PD; Sikder, AR; Taheri, J; Zhou, BB; Zomaya, AY				Yoo, Paul D.; Sikder, Abdur R.; Taheri, Javid; Zhou, Bing Bing; Zomaya, Albert Y.			DomNet: Protein domain boundary prediction using enhanced general regression network and new profiles	IEEE TRANSACTIONS ON NANOBIOSCIENCE			English	Article						domain boundary prediction; domain linker index; machine learning; sequence encoding; sequence profile	MULTIPLE SEQUENCE ALIGNMENT; RELATIVE SOLVENT ACCESSIBILITY; SECONDARY STRUCTURE PREDICTION; AMINO-ACID-SEQUENCE; NEURAL-NETWORKS; LINKER LENGTH; DATABASE; REGIONS; CLASSIFICATION; ASSIGNMENT	The accurate and stable prediction of protein domain boundaries is an important avenue for the prediction of protein structure, function, evolution, and design. Recent research on protein domain boundary prediction has been mainly based on widely known machine learning techniques. In this paper, we propose a new machine learning based domain predictor namely, DomNet that can show a more accurate and stable predictive performance than the existing state-of-the-art models. The DomNet is trained using a novel compact domain profile, secondary structure, solvent accessibility information, and interdomain linker index to detect possible domain boundaries for a target sequence. The performance of the proposed model was compared to nine different machine learning models on the Benchmark_2 dataset in terms of accuracy, sensitivity, specificity, and correlation coefficient. The DomNet achieved the best performance with 71 % accuracy for domain boundary identification in multidomains proteins. With the CASP7 benchmark dataset, it again demonstrated superior performance to contemporary domain boundary predictors such as DOMpro, DomPred, DomSSEA, DomCut, and DomainDiscovery.	[Yoo, Paul D.; Taheri, Javid; Zhou, Bing Bing] Univ Sydney, Sch Informat Technol J12, Adv Networks Res Grp, Sydney, NSW 2006, Australia; [Zomaya, Albert Y.] Univ Sydney, Sydney Bioinformat Ctr, Sydney, NSW 2006, Australia; [Zomaya, Albert Y.] Univ Sydney, Ctr Math Biol, Sydney, NSW 2006, Australia	Yoo, PD (reprint author), Univ Sydney, Sch Informat Technol J12, Adv Networks Res Grp, Sydney, NSW 2006, Australia.	dyoo4334@it.usyd.edu.au; arsikder@mtu.edu; javidt@it.usyd.edu.au; bbz@it.usyd.edu.au; zomaya@it.usyd.edu.au					ALTSCHUL SF, 1997, NUCLEIC ACIDS RES, V25, P3402; Andreeva A, 2004, NUCLEIC ACIDS RES, V32, pD226, DOI 10.1093/nar/gkh039; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; BORK P, 1991, FEBS LETT, V286, P47, DOI 10.1016/0014-5793(91)80937-X; CERONI A, 2004, IEEE P NEURAL NETW, V3, P1899; Chen J., 2005, SOFT COMP J, V10, P315; Cheng JL, 2006, DATA MIN KNOWL DISC, V13, P1, DOI 10.1007/s10618-005-0023-5; CHOTHIA C, 1992, NATURE, V357, P543, DOI 10.1038/357543a0; Civera C, 2005, PROTEINS, V58, P354, DOI 10.1002/prot.20320; Contreras-Moreira B, 2002, BIOINFORMATICS, V18, P1141, DOI 10.1093/bioinformatics/18.8.1141; Copley RR, 2002, FEBS LETT, V513, P129, DOI 10.1016/S0014-5793(01)03289-6; Dumontier M, 2005, J MOL BIOL, V350, P1061, DOI 10.1016/j.jmb.2005.05.037; Edgar RC, 2006, CURR OPIN STRUC BIOL, V16, P368, DOI 10.1016/j.sbi.2006.04.004; Edgar RC, 2004, BIOINFORMATICS, V20, P1301, DOI 10.1093/bioinformatics/bth090; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Frishman D, 1996, PROTEIN ENG, V9, P133, DOI 10.1093/protein/9.2.133; Galzitskaya OV, 2003, PROTEIN SCI, V12, P696, DOI 10.1110/ps.0233103; George RA, 2002, J MOL BIOL, V316, P839, DOI 10.1006/jmbi.2001.5387; Gewehr JE, 2006, BIOINFORMATICS, V22, P181, DOI 10.1093/bioinformatics/bti751; Gokhale RS, 2000, CURR OPIN CHEM BIOL, V4, P22, DOI 10.1016/S1367-5931(99)00046-0; Gracy J, 1998, TRENDS BIOCHEM SCI, V23, P495, DOI 10.1016/S0968-0004(98)01294-8; Hardle W., 2004, NONPARAMETRIC SEMIPA; Holland TA, 2006, J MOL BIOL, V361, P562, DOI 10.1016/j.jmb.2006.05.060; Joshi RR, 2007, CURR BIOINFORM, V2, P113, DOI 10.2174/157489307780618213; King RD, 1996, PROTEIN SCI, V5, P2298; KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209; Lehtinen MJ, 2004, J MOL BIOL, V344, P1385, DOI 10.1016/j.jmb.2004.10.017; LEVITT M, 1976, NATURE, V261, P552, DOI 10.1038/261552a0; Liu JF, 2004, NUCLEIC ACIDS RES, V32, P3522, DOI 10.1093/nar/gkh684; Marchler-Bauer A, 2005, NUCLEIC ACIDS RES, V33, pD192, DOI 10.1093/nar/gki069; Marsden RL, 2002, PROTEIN SCI, V11, P2814, DOI 10.1110/ps.0209902; Melo JCB, 2003, IEEE P 2003 INT JOIN; Nagarajan N, 2004, BIOINFORMATICS, V20, P1335, DOI 10.1093/bioinformatics/bth086; Notredame C, 2002, PHARMACOGENOMICS, V3, P131, DOI 10.1517/14622416.3.1.131; Pearson R, 2000, J INDO-EUR STUD, V28, P1; Pollastri G, 2002, PROTEINS, V47, P142, DOI 10.1002/prot.10069; Pollastri G, 2002, PROTEINS, V47, P228, DOI 10.1002/prot.10082; Richardson J S, 1981, Adv Protein Chem, V34, P167, DOI 10.1016/S0065-3233(08)60520-3; Robinson CR, 1998, P NATL ACAD SCI USA, V95, P5929, DOI 10.1073/pnas.95.11.5929; ROST B, 1993, J MOL BIOL, V232, P584, DOI 10.1006/jmbi.1993.1413; SALAMOV AA, 1995, J MOL BIOL, V247, P11, DOI 10.1006/jmbi.1994.0116; Schapire R. E., 1999, P 16 INT JOINT C ART, P1401; Sikder AR, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-S5-S6; Sim J, 2005, PROTEINS, V59, P627, DOI 10.1002/prot.20442; Suyama M, 2003, BIOINFORMATICS, V19, P673, DOI 10.1093/bioinformatics/btg031; Thompson JD, 1999, NUCLEIC ACIDS RES, V27, P2682, DOI 10.1093/nar/27.13.2682; vanLeeuwen HC, 1997, EMBO J, V16, P2043, DOI 10.1093/emboj/16.8.2043; VERETNIK S, 2006, COMPUTATIONAL METHOD; Vieira A, 2005, LECT NOTES COMPUT SC, V3594, P222; WETLAUFE.DB, 1973, P NATL ACAD SCI USA, V70, P697, DOI 10.1073/pnas.70.3.697; Wheelan SJ, 2000, BIOINFORMATICS, V16, P613, DOI 10.1093/bioinformatics/16.7.613; Yoo PD, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-S1-S12; ZVELEBIL MJ, 1987, J MOL BIOL, V195, P957, DOI 10.1016/0022-2836(87)90501-8	53	4	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1536-1241		IEEE T NANOBIOSCI	IEEE Trans. Nanobiosci.	JUN	2008	7	2					172	181		10.1109/TNB.2008.2000747		10	Biochemical Research Methods; Nanoscience & Nanotechnology	Biochemistry & Molecular Biology; Science & Technology - Other Topics	310LR	WOS:000256531600008	
J	Bruyndonckx, P; Lemaitre, C; van der Laan, DJ; Maas, M; Schaart, D; Wang, YG; Li, Z; Krieguer, M; Tavernier, S				Bruyndonckx, Peter; Lemaitre, Cedric; van der Laan, D. J.; Maas, Marnix; Schaart, Dennis; Wang Yonggang; Li, Zhi; Krieguer, M.; Tavernier, Stefaan			Evaluation of machine learning algorithms for localization of photons in undivided scintillator blocks for PET detectors	IEEE TRANSACTIONS ON NUCLEAR SCIENCE			English	Article						monolithic scintillator; positron emission tomography; neural network		Neural Networks trained with error back propagation Levenberg-Marquardt training (LM), Neural Networks trained with an algebraic method and Support Vector Machines (SVM) were evaluated to extract the position information from measured light distributions generated by the interactions of 511 keV photons in monolithic scintillator blocks. All three algorithms can achieve a similar average resolution (similar to 1.6 mm FWHM in a 20 x 10 x 10 mm LSO block) but the LM trained neural networks do so most efficiently. When the incidence angle of the photons increases to 30 degrees, the resolution degrades slightly to 2.0 mm FWHM. A small mismatch (< +/- 5 degrees) between the true incidence angle and the angle for which a neural network was trained can be tolerated without significant resolution loss. Increasing the thickness to 20 mm and using a top-bottom readout of the block yields an average resolution of 2.2 mm FWHM.	[Bruyndonckx, Peter; Lemaitre, Cedric; Li, Zhi; Krieguer, M.; Tavernier, Stefaan] Vrije Univ Brussels, B-1050 Brussels, Belgium; [van der Laan, D. J.; Maas, Marnix; Schaart, Dennis] Delft Univ Technol, NL-2629 JB Delft, Netherlands; [Wang Yonggang] Univ Sci & Technol China, Hefei 230027, Peoples R China	Bruyndonckx, P (reprint author), Vrije Univ Brussels, B-1050 Brussels, Belgium.	pbruynd@vub.ac.be; celemait@vub.ac.be; d.j.vanderlaan@tnw.tudelft.nl; m.c.maas@tudelft.nl; d.r.schaart@tudelft.nl; wangyg@ustc.edu.cn; stefaan.tavernier@vub.ac.be					Bruyndonckx P, 2007, NUCL INSTRUM METH A, V571, P182, DOI 10.1016/j.nima.2006.10.058; Bruyndonckx P, 2004, IEEE T NUCL SCI, V51, P2520, DOI 10.1109/TNS.2004.835782; Bruyndonckx P, 2006, IEEE T NUCL SCI, V53, P2543, DOI 10.1109/TNS.2006.875998; CHANG C. C., LIBSVM LIB SUPPORT V; Ferrari S, 2005, IEEE T NEURAL NETWOR, V16, P24, DOI 10.1109/TNN.2004.836233; FERRARI S, 2000, AIAA GUID NAV CONTR; Haykin S., 1999, NEURAL NETWORKS COMP; Maas MC, 2006, IEEE T NUCL SCI, V53, P1071, DOI 10.1109/TNS.2006.873711; MAAS MC, 2006, P IEEE NUCL SCI S ME; Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88	10	12	12	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9499		IEEE T NUCL SCI	IEEE Trans. Nucl. Sci.	JUN	2008	55	3	1				918	924		10.1109/TNS.2008.922811		7	Engineering, Electrical & Electronic; Nuclear Science & Technology	Engineering; Nuclear Science & Technology	316RO	WOS:000256967600013	
J	Li, J; Wang, JZ				Li, Jia; Wang, James Z.			Real-time computerized annotation of pictures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image annotation; tagging; statistical learning; modeling; clustering	IMAGE RETRIEVAL	Developing effective methods for automated annotation of digital pictures continues to challenge computer scientists. The capability of annotating pictures by computers can lead to breakthroughs in a wide range of applications, including Web image search, online picture-sharing communities, and scientific experiments. In this work, the authors developed new optimization and estimation techniques to address two fundamental problems in machine learning. These new techniques serve as the basis for the Automatic Linguistic Indexing of Pictures-Real Time (ALIPR) system of fully automatic and high-speed annotation for online pictures. In particular, the D2-clustering method, in the same spirit as K-Means for vectors, is developed to group objects represented by bags of weighted vectors. Moreover, a generalized mixture modeling technique (kernel smoothing as a special case) for nonvector data is developed using the novel concept of Hypothetical Local Mapping (HLM). ALIPR has been tested by thousands of pictures from an Internet photo-sharing site, unrelated to the source of those pictures used in the training process. Its performance has also been studied at an online demonstration site, where arbitrary users provide pictures of their choices and indicate the correctness of each annotation word. The experimental results show that a single computer processor can suggest annotation terms in real time and with good accuracy.	[Li, Jia] Penn State Univ, Dept Stat, University Pk, PA 16802 USA; [Wang, James Z.] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA; [Wang, James Z.] Penn State Univ, Coll Informat Sci & Technol, University Pk, PA 16802 USA	Li, J (reprint author), Penn State Univ, Dept Stat, University Pk, PA 16802 USA.	jiali@stat.psu.edu; jwang@ist.psu.edu					Bagdanov A. D., 2007, P INT WORKSH MULT IN, P79, DOI 10.1145/1290082.1290096; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Beymer D, 1996, SCIENCE, V272, P1905, DOI 10.1126/science.272.5270.1905; BICKEL PJ, 1981, ANN STAT, V9, P1196, DOI 10.1214/aos/1176345637; Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61; Chang S.F., 1998, P IEEE INT C IM PROC, V3, P531; Chen YX, 2004, J MACH LEARN RES, V5, P913; DATTA R, 2008, IN PRESS ACM COMPUTI; Daubechies I., 1992, 10 LECT WAVELETS; Evans M., 2000, STAT DISTRIBUTIONS; Gonzalez RC, 2002, DIGITAL IMAGE PROCES; Hastie T, 2001, ELEMENTS STAT LEARNI; He J., 2004, P 6 ACM SIGMM INT WO, P15, DOI 10.1145/1026711.1026715; He X., 2004, P 12 ANN ACM INT C M, P17, DOI 10.1145/1027527.1027532; Levina E., 2001, P IEEE 8 INT C COMP, V2, P251, DOI 10.1109/ICCV.2001.937632; Li J, 2003, IEEE T PATTERN ANAL, V25, P1075; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MALLOWS CL, 1972, ANN MATH STAT, V43, P508, DOI 10.1214/aoms/1177692631; McLachlan G., 2000, FINITE MIXTURE MODEL; Monay F., 2003, P 11 ACM INT C MULT, P275; Quack T., 2004, P 12 ACM INT C MULT, P508, DOI 10.1145/1027527.1027650; Rachev S. T., 1984, THEORY PROBABILITY I, V29, P647; Rubner Y., 1998, P IEEE INT C COMP VI, P59; Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644; Singh PJ, 2003, INT J FATIGUE, V25, P1, DOI 10.1016/S0142-1123(02)00067-1; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Smith J. R., 1996, Proceedings ACM Multimedia 96, DOI 10.1145/244130.244151; Tieu K, 2004, INT J COMPUT VISION, V56, P17, DOI 10.1023/B:VISI.0000004830.93820.78; Tomasi C, 2004, NATURE, V428, P378, DOI 10.1038/428378a; Tong S., 2001, P ACM INT C MULT, P107, DOI DOI 10.1145/560141.500159; Vasconcelos N, 2005, IEEE T MULTIMEDIA, V7, P127, DOI 10.1109/TMM.2004.840596; Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109; WANG JZ, 2002, P ACM MULTIMEDIA, P436; Zhang C, 2002, IEEE T MULTIMEDIA, V4, P260	34	87	91	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2008	30	6					985	1002		10.1109/TPAMI.2007.70847		18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	286UW	WOS:000254872500005	
J	Islam, MM; Yao, X; Nirjon, SMS; Islam, MA; Murase, K				Islam, Md. Monirul; Yao, Xin; Nirjon, S. M. Shahriar; Islam, Muhammad Asiful; Murase, Kazuyuki			Bagging and boosting negatively correlated neural networks	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						bagging; boosting; constructive approach; diversity; generalization; negative correlation learning; neural network (NN); ensemble design	OPTIMAL LINEAR-COMBINATIONS; HIDDEN UNITS; ENSEMBLES; ALGORITHM; MIXTURES; ACCURACY; EXPERTS	In this paper, we propose two cooperative ensemble learning algorithms, i.e., NegBagg and NegBoost, for designing neural network (NN) ensembles. The proposed algorithms incrementally train different individual NNs in an ensemble using the negative correlation learning algorithm. Bagging and boosting algorithms are used in NegBagg and NegBoost, respectively, to create different training sets for different NNs in the ensemble. The idea behind using negative correlation learning in conjunction with the bagging/boosting algorithm is to facilitate interaction and cooperation among NNs during their training. Both NegBagg and NegBoost use a constructive approach to automatically determine the number of hidden neurons for NNs. NegBoost also uses the constructive approach to automatically determine the number of NNs for the ensemble. The two algorithms have been tested on a number of benchmark problems in machine learning and NNs, including Australian credit card assessment, breast cancer, diabetes, glass, heart disease, letter recognition, satellite, soybean, and waveform problems. The experimental results show that NegBagg and NegBoost require a small number of training epochs to produce compact NN ensembles with good generalization.	[Islam, Md. Monirul; Nirjon, S. M. Shahriar] Bangladesh Univ Engn & Technol, Dhaka 1000, Bangladesh; [Islam, Md. Monirul; Murase, Kazuyuki] Univ Fukui, Fukui 9108507, Japan; [Yao, Xin] Univ Birmingham, Birmingham B15 2TT, W Midlands, England; [Yao, Xin] Univ Sci & Technol China, Hefei 230026, Peoples R China; [Islam, Muhammad Asiful] SUNY Stony Brook, Stony Brook, NY 11794 USA	Islam, MM (reprint author), Bangladesh Univ Engn & Technol, Dhaka 1000, Bangladesh.				Japanese Society for the Promotion of Sciences (JSPS); Engineering and Physical Sciences Research Council (U.K.) [GR/T10671/01]; Fund for Foreign Scholars in University Research and Teaching Programs (China) [B07033]	The work of M. M. Islam was supported by the Japanese Society for the Promotion of Sciences (JSPS). The work of X. Yao was supported in part by the Engineering and Physical Sciences Research Council (U.K.) under Grant GR/T10671/01 and by the Fund for Foreign Scholars in University Research and Teaching Programs (China) under Grant B07033. This paper was recommended by Associate Editor N. Chawla.	ALI KM, 1996, THESIS U CALIFORNIA; Ali KM, 1996, MACH LEARN, V24, P173, DOI 10.1007/BF00058611; Ash T., 1989, Connection Science, V1, DOI 10.1080/09540098908915647; Baldi P., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.4.589; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Breiman L, 1996, MACH LEARN, V24, P49, DOI 10.1007/BF00117832; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Breiman L, 1999, NEURAL COMPUT, V11, P1493, DOI 10.1162/089976699300016106; Brown MT, 2005, GEOCHEM GEOPHY GEOSY, V6, DOI 10.1029/2004GC000893; Chauvin Y, 1990, P EUROSZP WORKSH FEB, P46; Cherkauer K., 1996, P 13 AAAI WORKSH INT, P15; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Drucker H., 1997, P 14 INT C MACH LEAR, P107; DRUCKER H, 1994, NEURAL COMPUT, V6, P1289, DOI 10.1162/neco.1994.6.6.1289; FAHLMAN S. E., 1990, ADV NEURAL INFORMATI, V2, P524; Freund Y., 1996, P 13 INT C MACH LEAR, P146; Granitto PM, 2005, ARTIF INTELL, V163, P139, DOI 10.1016/j.artint.2004.09.006; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; HASHEM S, 1995, IEEE T NEURAL NETWOR, V6, P792, DOI 10.1109/72.377990; Hashem S, 1997, NEURAL NETWORKS, V10, P599, DOI 10.1016/S0893-6080(96)00098-6; Haykin S., 1999, NEURAL NETWORKS COMP; HIROSE Y, 1991, NEURAL NETWORKS, V4, P61, DOI 10.1016/0893-6080(91)90032-Z; Islam MM, 2001, NEURAL NETWORKS, V14, P1265, DOI 10.1016/S0893-6080(01)00075-2; Islam M, 2003, IEEE T NEURAL NETWOR, V14, P820, DOI 10.1109/TNN.2003.813832; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; Jacobs RA, 1997, NEURAL COMPUT, V9, P369, DOI 10.1162/neco.1997.9.2.369; Jim KC, 1996, IEEE T NEURAL NETWOR, V7, P1424; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; Kohavi R., 1996, P 13 INT C MACH LEAR, P275; Krogh A, 1997, PHYS REV E, V55, P811, DOI 10.1103/PhysRevE.55.811; Krogh A., 1995, ADV NEURAL INFORMATI, V8, P231; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; Kwok TY, 1997, IEEE T NEURAL NETWOR, V8, P1131; Kwok T.-Y., 1997, IEEE T NEURAL NETWOR, V3, P630; Lehtokangas M, 1999, NEURAL NETWORKS, V12, P707, DOI 10.1016/S0893-6080(99)00018-0; Liu Y, 1999, NEURAL NETWORKS, V12, P1399, DOI 10.1016/S0893-6080(99)00073-8; Liu Y, 2005, LECT NOTES COMPUT SC, V3610, P149; LIU Y, 1998, P 1998 IEEE INT JOIN, P2202; Liu Y, 2000, IEEE T EVOLUT COMPUT, V4, P380; Liu Y, 1999, IEEE T SYST MAN CY B, V29, P716, DOI 10.1109/3477.809027; Liu Y., 1997, AUSTR J INTELLIGENT, V4, P176; Ma LY, 2005, IEEE T NEURAL NETWOR, V16, P821, DOI 10.1109/TNN.2005.851786; Maclin R., 1995, P 14 INT JOINT C ART, P524; Melville P., 2005, Information Fusion, V6, DOI 10.1016/j.inffus.2004.04.001; NICHOLAS TK, 1999, IEEE T NEURAL NETWOR, V10, P1335; NILSSON NJ, 1965, LEARNING MACH FDN TR; ODRI SV, 1993, NEURAL NETWORKS, V6, P583, DOI 10.1016/S0893-6080(05)80061-9; Opitz D., 1999, J ARTIFICIAL INTELLI, P169; Opitz D. W., 1996, Connection Science, V8, DOI 10.1080/095400996116802; Oza N. C., 2001, LECT NOTES COMPUTER, P238; Perrone M.P., 1993, NEURAL NETWORKS SPEE, P126; Prechelt L., 1994, 2194 U KARLSR FAK IN; Prechelt L, 1995, NEUROCOMPUTING, V9, P343, DOI 10.1016/0925-2312(95)00084-1; Prechelt L, 1998, NEURAL NETWORKS, V11, P761, DOI 10.1016/S0893-6080(98)00010-0; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; Raviv Y., 1996, CONNECT SCI, V8, P356; REED R, 1993, IEEE T NEURAL NETWOR, V4, P740, DOI 10.1109/72.248452; Rosen B. E., 1996, Connection Science, V8, DOI 10.1080/095400996116820; SCHAEFER P, 1990, EARTH ISL J, V5, P2; SCHATTEN G, 1998, J LAW MED ETHICS, V26, P5; Schwenk H, 2000, NEURAL COMPUT, V12, P1869, DOI 10.1162/089976600300015178; Selfridge O. G., 1958, P S HELD NAT PHYS LA, P513; Setiono R, 1997, NEURAL COMPUT, V9, P205, DOI 10.1162/neco.1997.9.1.205; Sharp HM, 1997, EUR PSYCHIAT, V12, P1, DOI 10.1016/S0924-9338(97)86371-7; Sharp M, 1996, NATO ASI S 4 SCI TEC, V8, P3; TURNER JS, 1996, J HIGH SPEED NETW, V8, P3; Yao X, 1997, IEEE T NEURAL NETWOR, V8, P694, DOI 10.1109/72.572107; ZHOU ZH, 1999, P 12 AUSTR JOINT C A, V1747, P48	70	18	19	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	JUN	2008	38	3					771	784		10.1109/TSMCB.2008.922055		14	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	342DA	WOS:000258763600016	
J	Bibi, S; Stamelos, I; Angelis, L				Bibi, S.; Stamelos, I.; Angelis, L.			Combining probabilistic models for explanatory productivity estimation	INFORMATION AND SOFTWARE TECHNOLOGY			English	Article						software cost estimation; machine learning; association rules; classification and regression trees	SOFTWARE-DEVELOPMENT EFFORT; DEVELOPMENT EFFORT PREDICTION; ESTIMATION ACCURACY	In this paper Association Rules (AR) and Classification and Regression Trees (CART) are combined in order to deliver an effective conceptual estimation framework. AR descriptive nature is exploited by identifying logical associations between project attributes and the required effort for the development of the project. CART method on the other hand has the benefit of acquiring general knowledge from specific examples of projects and is able to provide estimates for all possible projects. The particular methods have the ability of teaming and modelling associations in data and hence they can be used to describe complex relationships in software cost data sets that are not immediately apparent. Potential benefits of combining these probabilistic methods involve the ability of the final model to reveal the way in which particular attributes can increase or decrease productivity and the fact that such assumptions vary among different ranges of productivity values. Experimental results on two data. sets indicate efficient overall performance of the suggested integrated method. (C) 2007 Elsevier B.V. All rights reserved.	[Bibi, S.; Stamelos, I.; Angelis, L.] Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece	Bibi, S (reprint author), Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.	sbibi@csd.auth.gr; stamelos@csd.auth.gr; lef@csd.auth.gr					ALBRECHT AJ, 1983, IEEE T SOFTWARE ENG, V9, P639, DOI 10.1109/TSE.1983.235271; Angelis L., 2001, P 7 INT SOFTW METR S, P4; BIBI S, 2004, P EUR SOFTW PROC IMP; BIBI S, 2004, 1 SOFTW MEAS EUR FOR; BOEHM B, 1995, ANN SOFTW ENG, V1, P45; Boehm B.W., 1981, SOFTWARE ENG EC; Breiman L, 1984, CLASSIFICATION REGRE; Briand LC, 1998, PROC INT CONF SOFTW, P390, DOI 10.1109/ICSE.1998.671392; CLEMEN RT, 1999, RISK ANAL, V19; Hand D., 2001, PRINCIPLES DATA MINI; HELMERHEIDELBER.O, 1966, SOCIAL TECHNOLOGY; HOGARTH RM, 1978, ORGAN BEHAV HUM PERF, V21, P40, DOI 10.1016/0030-5073(78)90037-5; Jeffery R, 2001, P 7 INT SOFTW METR S, P16; JEFFERY R, 2000, P ESCOM 2000 MUN, P239; Jeffery R, 2000, INFORM SOFTWARE TECH, V42, P1009, DOI 10.1016/S0950-5849(00)00153-1; Jorgensen M, 2004, J SYST SOFTWARE, V70, P37, DOI 10.1016/S0164-1212(02)00156-5; JORGENSEN M, 2002, 14 IEEE C SOFTW ENG; Jorgensen M, 2005, IEEE SOFTWARE, V22, P57, DOI 10.1109/MS.2005.73; Jorgensen M, 2004, J SYST SOFTWARE, V70, P79, DOI 10.1016/S0164-1212(02)00160-7; Jorgensen M, 2003, INFORM SOFTWARE TECH, V45, P123, DOI 10.1016/S0950-5849(02)00188-X; Kitchenham B, 1997, IEEE SOFTWARE, V14, P69, DOI 10.1109/52.589239; Kitchenham B, 2002, J SYST SOFTWARE, V64, P57, DOI 10.1016/S0164-1212(02)00021-3; Kitchenham B, 1998, IEEE T SOFTWARE ENG, V24, P278, DOI 10.1109/32.677185; Lee A, 1998, INFORM MANAGE, V34, P1, DOI 10.1016/S0378-7206(98)00041-X; Lokan CJ, 2000, INFORM SOFTWARE TECH, V42, P649, DOI 10.1016/S0950-5849(00)00108-7; MacDonell SG, 2003, J SYST SOFTWARE, V66, P91, DOI 10.1016/S0164-1212(02)00067-5; MAIR C, 1999, ICSE 99 LOS ANG MAY; Mair C, 2000, J SYST SOFTWARE, V53, P23, DOI 10.1016/S0164-1212(00)00005-4; Maxwell KD, 2002, APPL STAT SOFTWARE M; Passing U., 2003, INT S EMP SOFTW ENG, P120; Pickard L., 2001, IEE Proceedings-Software, V148, DOI 10.1049/ip-sen:20010621; Rissanen J., 1989, STOCHASTIC COMPLEXIT; Sentas P, 2005, INFORM SOFTWARE TECH, V47, P17, DOI 10.1016/j.insof.2004.05.001; Shepperd M, 2001, IEEE T SOFTWARE ENG, V27, P1014, DOI 10.1109/32.965341; SHEPPERD M, 1996, ICSE 18 BERL, P170; SRINIVASAN K, 1995, IEEE T SOFTWARE ENG, V21, P126, DOI 10.1109/32.345828; Stamelos I., 2003, Information and Management, V40, DOI 10.1016/S0378-7206(02)00099-X; Stamelos I, 2003, INFORM SOFTWARE TECH, V45, P51, DOI 10.1016/S0950-5849(02)00163-5; STURGE H, 1926, J AM STAT ASSOC, P65; Torgo L., 1997, INTELLIGENT DATA ANA, V4, P275, DOI 10.1016/S1088-467X(97)00013-9; Witten I. H., 1999, DATA MINING PRACTICA	41	5	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-5849		INFORM SOFTWARE TECH	Inf. Softw. Technol.	JUN	2008	50	7-8					656	669		10.1016/j.infsof.2007.06.004		14	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	305KT	WOS:000256178000004	
J	Bai, X; Padman, R; Ramsey, J; Spirtes, P				Bai, Xue; Padman, Rema; Ramsey, Joseph; Spirtes, Peter			Tabu search-enhanced graphical models for classification in high dimensions	INFORMS JOURNAL ON COMPUTING			English	Article						Markov blanket; Bayesian networks; tabu search; machine learning; text analysis; health care decision support; online marketing	ALGORITHM; INTERNET	Data sets with many discrete variables and relatively few cases arise in health care, e-commerce, information security, text mining, and many other domains. Learning effective and efficient prediction models from such data sets is a challenging task. In this paper, we propose a tabu search-enhanced Markov blanket (TS/MB) algorithm to learn a graphical Markov blanket model for classification of high-dimensional data sets. The TS/MB algorithm makes use of Markov blanket neighborhoods: restricted neighborhoods in a general Bayesian network based on the Markov condition. Computational results from real-world data sets drawn from several domains indicate that the TS/MB algorithm, when used as a feature selection method, is able to find a parsimonious model with substantially fewer predictor variables than is present in the full data set. The algorithm also provides good prediction performance when used as a graphical classifier compared with several machine-learning methods.	[Bai, Xue] Univ Connecticut, Sch Business, Storrs, CT 06269 USA; [Padman, Rema] Carnegie Mellon Univ, H John Heinz III Sch Publ Policy & Management, Pittsburgh, PA 15213 USA; [Ramsey, Joseph; Spirtes, Peter] Carnegie Mellon Univ, Dept Philosophy, Pittsburgh, PA 15213 USA	Bai, X (reprint author), Univ Connecticut, Sch Business, Storrs, CT 06269 USA.	xue.bai@business.uconn.edu; rpadman@andrew.cmu.edu; jdramsey@andrew.cmu.edu; ps7z@andrew.cmu.edu					Adam BL, 2002, CANCER RES, V62, P3609; Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99; Airoldi E, 2006, LECT NOTES ARTIF INT, V3932, P167; ALIFERIS C, 2003, DSL0208 VAND U; Aliferis C. F., 2003, P 2003 AM MED INF AS, P21; BAI X, 2005, P 38 HAW INT C SYST; BAI X, 2005, NEXT WAVE COMPUTING, P338; BAI X, 2004, CMUCALD04103 CARN ME; BAI X, 2003, P 8 INFORMS C INF SY, P23; BAI X, 2005, CMUCALD05101 CARN ME; Berger D, 2000, J HEURISTICS, V6, P253, DOI 10.1023/A:1009679511137; Berry M.J.A., 1997, DATA MINING TECHNIQU; Brynjolfsson E, 2000, MANAGE SCI, V46, P563, DOI 10.1287/mnsc.46.4.563.12061; Campos V, 2005, INFORMS J COMPUT, V17, P111, DOI 10.1287/ijoc.1030.0057; Carletta J, 1996, COMPUT LINGUIST, V22, P249; CHENG J, 2002, SIGKDD EXPLORATIONS, V3, P47; CHICKERING D. M., 2002, J MACHINE LEARNING R, V3, P507; Cohen William W, 2004, MINORTHIRD METHODS I; Cooper GF, 1997, ARTIF INTELL MED, V9, P107, DOI 10.1016/S0933-3657(96)00367-3; Freund Y, 1999, MACH LEARN, V37, P277, DOI 10.1023/A:1007662407062; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Fu ZW, 2003, INFORMS J COMPUT, V15, P3, DOI 10.1287/ijoc.15.1.3.15152; Glover F., 1989, ORSA Journal on Computing, V1; Glover F., 1997, TABU SEARCH; Greiner R., 1999, P 15 C UNC ART INT U, P101; HANLEY JA, 1983, RADIOLOGY, V148, P839; JESUS M, 2001, WEB MINING PROFIT E; Joachims T, 2001, P 24 ANN INT ACM SIG, P128, DOI 10.1145/383952.383974; Koller D., 1996, P 13 INT C MACH LEAR, P284; Lafferty J., 2001, P 18 INT C MACH LEAR, P282; MADDEN MG, 2002, NUIGIT011002 NAT U I; MARGARITIS D, 1999, ADV NEURAL INFORMATI, V12, P505; MONTGOMERY A, 2002, LEARNING CUSTOMERS A; Newman D. J., 1998, UCI REPOSITORY MACHI; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; OPPEN J, 2003, P NIK 2003 NORW INF; Padmanabhan B, 2003, MANAGE SCI, V49, P1327, DOI 10.1287/mnsc.49.10.1327.17310; Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79; Pearl J, 2000, CAUSALITY MODELS REA; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; RAMSEY JD, 2006, CMUPHIL177 CARN MELL; SAARTSECHANSKY M, 2001, P 17 INT JOINT C ART, P911; Smith MD, 2001, J IND ECON, V49, P541; Spirtes P, 2000, CAUSATION PREDICTION; TOTH P, 2003, INFORMS J COMPUT, V15, P334	45	3	3	INFORMS	HANOVER	7240 PARKWAY DR, STE 310, HANOVER, MD 21076-1344 USA	1091-9856		INFORMS J COMPUT	INFORMS J. Comput.	SUM	2008	20	3					423	437		10.1287/ijoc.1070.0255		15	Computer Science, Interdisciplinary Applications; Operations Research & Management Science	Computer Science; Operations Research & Management Science	323UJ	WOS:000257473600009	
J	Pulkkinen, P; Koivisto, H				Pulkkinen, Pletarl; Koivisto, Hannu			Fuzzy classifier identification using decision tree and multiobjective evolutionary algorithms	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING			English	Article						fuzzy classifiers (FCs); multiobjective evolutionary algorithms (MOEAs); decision trees (DTs); initialization	GENETIC ALGORITHM; SYSTEMS; COMPACT; INTERPRETABILITY; PERFORMANCE; EXTRACTION; COMPLEXITY; ACCURATE; MODELS	This paper presents a hybrid method for identification of Pareto-optimal fuzzy classifiers (FCs). In contrast to many existing methods, the initial population for multiobjective evolutionary algorithms (MOEAs) is neither created randomly nor a priori knowledge is required. Instead, it is created by the proposed two-step initialization method. First, a decision tree (DT) created by C4.5 algorithm is transformed into an FC. Therefore, relevant variables are selected and initial partition of input space is performed. Then, the rest of the population is created by randomly replacing some parameters of the initial FC, such that, the initial population is widely spread. That improves the convergence of MOEAs into the correct Pareto front. The initial population is optimized by NSGA-II algorithm and a set of Pareto-optimal FCs representing the trade-off between accuracy and interpretability is obtained. The method does not require any a priori knowledge of the number of fuzzy sets, distribution of fuzzy sets or the number of relevant variables. They are all determined by it. Performance of the obtained FCs is validated by six benchmark data sets from the literature. The obtained results are compared to a recently published paper [H. Ishibuchi, Y. Nojima, Analysis of interpretability-accuracy tradeoff of fuzzy systems by multiobjective fuzzy genetics-based machine learning, International Journal of Approximate Reasoning 44 (1) (2007) 4-31] and the benefits of our method are clearly shown. (C) 2007 Elsevier Inc. All rights reserved.	[Pulkkinen, Pletarl; Koivisto, Hannu] Tampere Univ Technol, Inst Automat & Control, FIN-33101 Tampere, Finland	Pulkkinen, P (reprint author), Tampere Univ Technol, Inst Automat & Control, POB 692, FIN-33101 Tampere, Finland.	pietari.pulkkinen@tut.fi; hannu.koivisto@tut.fi					Abonyi J, 2003, INT J APPROX REASON, V32, P1, DOI 10.1016/S0888-613X(02)00076-2; Deb K., 1995, Complex Systems, V9; Berthold M., 1999, INTELLIGENT DATA ANA; Casillas J, 2005, IEEE T FUZZY SYST, V13, P13, DOI 10.1109/TFUZZ.2004.839670; Chang PC, 2007, APPL SOFT COMPUT, V7, P800, DOI 10.1016/j.asoc.2006.02.002; Chen Yixin, 2003, 12 IEEE INT C FUZZ S, V2, P789; Coello Coello CA, 2006, COMPUT INTELL, P73; Cordon O, 1999, INT J APPROX REASON, V20, P21, DOI 10.1016/S0888-613X(00)88942-2; Cordon O, 2004, FUZZY SET SYST, V141, P5, DOI 10.1016/S0165-0114(03)00111-8; Cordon O, 2003, IEEE T FUZZY SYST, V11, P866, DOI 10.1109/TFUZZ.2003.819820; Deb K., 2003, 2003002 IND I TECHN; Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017; DUDA RO, 2001, STORK PATTERN CLASSI; Elomaa T, 1999, MACH LEARN, V36, P201, DOI 10.1023/A:1007674919412; Gomez-Skarmeta A. F., 1998, 6th European Congress on Intelligent Techniques and Soft Computing. EUFIT '98; GORMAN RP, 1988, NEURAL NETWORKS, V1, P75, DOI 10.1016/0893-6080(88)90023-8; Haubelt C, 2005, LECT NOTES COMPUT SC, V3410, P191; Hoppner Frank, 1999, FUZZY CLUSTER ANAL M; HUANG H, 2006, IEEE C EV COMP VANC, P11078; Ishibuchi H, 2001, INFORM SCIENCES, V136, P109, DOI 10.1016/S0020-0255(01)00144-X; ISHIBUCHI H, 2006, 2006 IEEE INT C FUZZ, P7824; Ishibuchi H, 2001, IEEE T FUZZY SYST, V9, P506, DOI 10.1109/91.940964; Ishibuchi H, 1999, IEEE T SYST MAN CY B, V29, P601, DOI 10.1109/3477.790443; Ishibuchi H, 2007, INT J APPROX REASON, V44, P4, DOI 10.1016/j.ijar.2006.01.004; Ishibuchi H, 2003, LECT NOTES COMPUT SC, V2632, P608; Kim MS, 2006, IEEE T SYST MAN CY B, V36, P1006, DOI 10.1109/TSMCB.2006.872265; King R. T. F., 2006, IEEE C EV COMP, P946; Klose A, 2007, IEEE T SYST MAN CY B, V37, P817, DOI 10.1109/TSMCB.2007.891253; Newman D. J., 1998, UCI REPOSITORY MACHI; NUOVO AGD, 2006, 2006 IEEE INT C FUZZ, P6941; POLES S, 2006, MOPGP 06 7 INT C MUL; Pulkkinen P, 2007, APPL SOFT COMPUT, V7, P520, DOI 10.1016/j.asoc.2006.11.001; QUINLAN JR, 1993, C4 5 PROGRAMS MACHIN, P94403; Roubos H, 2001, IEEE T FUZZY SYST, V9, P516, DOI 10.1109/91.940965; SARKER RA, 2003, 2003 C EV COMP, V3, P2011, DOI 10.1109/CEC.2003.1299920; Setnes M, 2000, IEEE T FUZZY SYST, V8, P509, DOI 10.1109/91.873575; Setzkorn C, 2005, BIOSYSTEMS, V81, P101, DOI 10.1016/j.biosystems.2005.02.003; Wang HL, 2005, FUZZY SET SYST, V149, P149, DOI 10.1016/j.fss.2004.07.013; XING ZY, 2006, 2006 IEEE INT C FUZZ, P6964; Xing ZY, 2007, INT J CONTROL AUTOM, V5, P444; Zitzler E., 2001, P EUROGEN 2001 EV ME, P19	41	42	43	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0888-613X		INT J APPROX REASON	Int. J. Approx. Reasoning	JUN	2008	48	2					526	543		10.1016/j.ijar.2007.10.004		18	Computer Science, Artificial Intelligence	Computer Science	311NK	WOS:000256606700011	
J	Prasad, M				Prasad, M.			Online Feature Selection for Classifying Emphysema in HRCT Images	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS			English	Article						Feature subset selection; HRCT; emphysema		Feature subset selection, applied as a preprocessing step to machine learning, is valuable in dimensionality reduction, eliminating irrelevant data and improving classifier performance. In the classic formulation of the feature selection problem, it is assumed that all the features are available at the beginning. However, in many real world problems, there are scenarios where not all features are present initially and must be integrated as they become available. In such scenarios, online feature selection provides an efficient way to sort through a large space of features. It is in this context that we introduce online feature selection for the classification of emphysema, a smoking related disease that appears as low attenuation regions in High Resolution Computer Tomography (HRCT) images. The technique was successfully evaluated on 61 HRCT scans and compared with different online feature selection approaches, including hill climbing, best first search, grafting, and correlation-based feature selection. The results were also compared against "density mask", a standard approach used for emphysema detection in medical image analysis.	Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA	Prasad, M (reprint author), Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, 110 8th St, Troy, NY 12180 USA.	mithunp@cse.unsw.edu.au					CHIU PT, 2001, LUNG BOUNDARY DETECT; FORREST S, 1993, FDN GENETIC ALGORITH, V2, P109; FRIMAN O, 2002, P 16 INT C PATT REC; GLOCER K, 2005, P ICML, V22, P249; GREEN DM, 1966, SIGNAL DETECTION THE; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hall M, 1999, P 17 INT C MACH LEAR, P359; Hastie T, 2001, ELEMENTS STAT LEARNI; JIANG W, 2005, P IEEE INT C AC SPEE, V2, P509; JS Milton, 1995, INTRO PROBABILITY ST; KAUCZOR HU, 1997, EUROPEAN RADIOLOGY, P1463; KINSELLA M, 1990, CHEST, V97, P315, DOI 10.1378/chest.97.2.315; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Koza J. R., 1992, PROGRAMMING COMPUTER; MIR H, 1995, IEEE ENG MED BIOL, V14; Mitchell T, 1997, MACHINE LEARNING; NURMI P, 2005, PASCAL WORKSH SUBSP, P23; Perkins S, 2003, P 21 INT C MACH LEAR, P592; PRASAD M, 2007, PATTERN ANA IN PRESS; PRASAD M, 2004, P INT C INT SENS SEN; Prasad M, 2009, PATTERN ANAL APPL, V12, P9, DOI 10.1007/s10044-007-0093-7; SINGH PK, 2005, P 8 INT S SIGN PROC, V1, P195, DOI 10.1109/ISSPA.2005.1580229; Uppaluri R, 1999, AM J RESP CRIT CARE, V160, P648; WOODLEY T, 2007, P BRIT MACH VIS C BR, P799	24	3	3	ATLANTIS PRESS	PARIS	29 AVENUE LAUMIERE, PARIS, 75019, FRANCE	1875-6883		INT J COMPUT INT SYS	Int. J. Comput. Intell. Syst.	JUN	2008	1	2					127	133		10.2991/jnmp.2008.1.2.3		7	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	418JE	WOS:000264143700003	
J	Han, SW; Kim, JY				Han, Sang-Wook; Kim, Jae-Yearn			Rough set-based decision tree using a core attribute	INTERNATIONAL JOURNAL OF INFORMATION TECHNOLOGY & DECISION MAKING			English	Article						core; reduct; decision tree; discernibility matrix; rough set		Decision trees are widely used in machine learning and artificial intelligence. In this paper, we extend previous research and present a new decision tree classification algorithm that uses a rough set theory to produce classification rules. Our algorithm is based on core attributes and on comparing the values of attributes between objects. Our experiments compared the performance of the Iterative Dichotomiser 3 (ID3) algorithm, C4.5, and the proposed decision tree algorithm to demonstrate its accuracy and ability to simplify rules.	[Han, Sang-Wook; Kim, Jae-Yearn] Hanyang Univ, Dept Ind Engn, Seoul 133791, South Korea	Han, SW (reprint author), Hanyang Univ, Dept Ind Engn, 17 Haengdang Dong, Seoul 133791, South Korea.	softhan@hanyang.ac.kr					BAI JS, 2003, P 2003 INT C    1026, P533; Bazan J. G., 1994, LECT NOTES ARTIF INT, V869, P346; ELASHOFF JD, 1967, BIOMETRIKA, V54, P668, DOI 10.2307/2335061; HUANG X, 2005, INT J INFOR TECHNOLO, V6, P15; KARNO B, 2001, 23 INT C TECHN ITI 2; Kumar A, 2005, INT J INF TECH DECIS, V4, P263, DOI 10.1142/S0219622005001490; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; PAWLAK Z, 1992, ROUGH SETS THEORETIC, P60; QUINLAN JR, 1990, IEEE T SYST MAN CYB, V20, P339, DOI 10.1109/21.52545; REN N, 2006, INT J INFOR TECHNOLO, V1, P227; SKOWRON A, 1991, DISCRENIBILITY MATRI, P1; TOUSSAIN.GT, 1971, IEEE T INFORM THEORY, V17, P618, DOI 10.1109/TIT.1971.1054686; Tu P.-L., 1992, Proceedings. Fourth International Conference on Tools with Artificial Intelligence, TAI '92 (Cat. No. 92CH3203-7), DOI 10.1109/TAI.1992.246431; WEI J, 2002, P 4 WORLD C INT CONT; YANG J, 2003, 2003 INT C, V1, P364; YANG Y, 2000, P 3 INT C INF FUS, V1	16	4	4	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0219-6220		INT J INF TECH DECIS	Int. J. Inf. Technol. Decis. Mak.	JUN	2008	7	2					275	290		10.1142/S0219622008002946		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Operations Research & Management Science	Computer Science; Operations Research & Management Science	322PN	WOS:000257387900006	
J	Du, AN; Fang, BX				Du, A-Ning; Fang, Binxing			Novel approach for web filtering based on user interest focusing degree	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL			English	Article						machine learning; Web filtering; user interest focusing degree; biased support vector machine	IMAGE RETRIEVAL	Web filtering can help people find the most valuable information. However, current web filtering techniques can not retrieve filtering results which accurately represent the user interest. This paper investigates different web filtering tasks and corresponding user's interest, and proposes the notion of user's interest focusing degree(UIFD) to measure the user's interest. We put forward the definition of UIFD based on the distribution of positives and negatives in the training set and import this parameter into current machine learning approaches. Based on UIFD, Biased Support Vector Machine(BSVM) is proposed as an example to illustrate the effect of UIFD. Experiments show that BSVM has a better filtering performance than SVM and UIFD can help web filers understand the user interest more accurately.	[Du, A-Ning; Fang, Binxing] Harbin Inst Technol, Res Ctr Comp Network & Informat Secur Technol, Harbin 150001, Peoples R China	Du, AN (reprint author), Harbin Inst Technol, Res Ctr Comp Network & Informat Secur Technol, Harbin 150001, Peoples R China.	dan@pact518.hit.edu.cn; bxfang@pact518.hit.edu.cn					BELKIN NJ, 1992, COMMUN ACM, V35, P29, DOI 10.1145/138859.138861; Chai K.M.A., 2002, P 25 ANN INT ACM SIG, P97; CHID FD, 1998, P C AUT LEARN DISC C; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Lee PY, 2002, IEEE INTELL SYST, V17, P48, DOI 10.1109/MIS.2002.1039832; Joachims T., 2001, P 18 INT C MACH LEAR, P250; Longe OB, 2005, Journal of Information Technology Impact, V5, P59; Marzouki K, 2006, INT J INNOV COMPUT I, V2, P411; Miyoshi T, 2006, INT J INNOV COMPUT I, V2, P237; PROJECT N, 2001, REPORT CURRENTLY AVA; Qiao YL, 2006, INT J INNOV COMPUT I, V2, P653; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Zheng WM, 2006, INT J INNOV COMPUT I, V2, P1317	13	4	4	ICIC INT	KUMAMOTO	KYUSHU TOKAI UNIV, 9-1-1, TOROKU, KUMAMOTO, 862-8652, JAPAN	1349-4198		INT J INNOV COMPUT I	Int. J. Innov. Comp. Inf. Control	JUN	2008	4	6					1325	1334				10	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	312ZH	WOS:000256710400007	
J	Gao, H; Huang, DG; Liu, W; Yang, YS				Gao, Hong; Huang, Degen; Liu, Wei; Yang, Yuansheng			Double rule learning in boosting	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL			English	Article						boosting; AdaBoost; machine learning; classification	ADABOOST	Boosting is an effective methodology for classification problems. AdaBoost is the most successful boosting algorithm that solved many practical difficulties of the earlier boosting algorithms. In this paper, we propose an improvement of AdaBoost, called DR-AdaBoost, in which a double-rule learning technique is used for improving the performance of AdaBoost. The DR-AdaBoost algorithm is evaluated with some classification problems of the UCI repository and it is also applied to a natural language processing task, text chunking. All experimental results show DR-AdaBoost outperforms AdaBoost. The improvement is significant, especially for those classification problems in which features are relevant.	[Gao, Hong; Liu, Wei] Dalian Maritime Univ, Dept Math, Dalian 116026, Peoples R China; [Huang, Degen; Yang, Yuansheng] Dalian Univ Technol, Dept Comp Sci & Engn, Dalian 116024, Peoples R China	Gao, H (reprint author), Dalian Maritime Univ, Dept Math, 1 Linghai Rd, Dalian 116026, Peoples R China.						Abney S., 1999, P 1999 JOINT SIGDAT, P38; ALEX SK, 2007, INT J INNOV COMPUT I, V3, P597; CARRERAS X, 2003, P CONLL 2003 EDM CAN, P152; Collins Michael, 2000, P 17 INT C MACH LEAR, P175; Erik F, 2000, P CONLL 2000 LLL 200, P127; Escudero G, 2000, LECT NOTES ARTIF INT, V1810, P129; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FREUND Y., 2003, J MACHINE LEARNING R, V4, P933, DOI 10.1162/jmlr.2003.4.6.933; Horio K, 2007, INT J INNOV COMPUT I, V3, P789; MERLER S, 2001, LNCS, V2096, P32; MERZ CJ, 1998, UCI RESP MACHINE LEA; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; TIEU K, 2000, P IEEE C COMP VIS PA, V1, P228, DOI 10.1109/CVPR.2000.855824; Wilbur WJ, 2005, MACH LEARN, V61, P71, DOI 10.1007/s10994-005-1123-6	16	6	6	ICIC INT	KUMAMOTO	KYUSHU TOKAI UNIV, 9-1-1, TOROKU, KUMAMOTO, 862-8652, JAPAN	1349-4198		INT J INNOV COMPUT I	Int. J. Innov. Comp. Inf. Control	JUN	2008	4	6					1411	1420				10	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	312ZH	WOS:000256710400016	
J	Tangermann, M				Tangermann, Michael			Machine learning methods for fast interfacing between brain and computer	INTERNATIONAL JOURNAL OF PSYCHOLOGY			English	Meeting Abstract									[Tangermann, Michael] Tech Univ Berlin, Inst Machine Learning, Berlin, Germany								0	0	0	PSYCHOLOGY PRESS	HOVE	27 CHURCH RD, HOVE BN3 2FA, EAST SUSSEX, ENGLAND	0020-7594		INT J PSYCHOL	Int. J. Psychol.	JUN-AUG	2008	43	3-4					724	725				2	Psychology, Multidisciplinary	Psychology	349EO	WOS:000259264308531	
J	Markov, Z; Holder, LB; Jonyer, I; Bisant, D				Markov, Zdravko; Holder, Lawrence B.; Jonyer, Istvan; Bisant, David			Special issue on FLAIRS 2007: Machine learning, data mining and neural networks - Preface	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS			English	Editorial Material																	0	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-2130		INT J ARTIF INTELL T	Int. J. Artif. Intell. Tools	JUN	2008	17	3					411	414				4	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	327XQ	WOS:000257762200001	
J	Holland, H; Kubat, M; Zizka, J				Holland, Hans; Kubat, Miroslav; Zizka, Jan			Handling ambiguous values in instance-based classifiers	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS			English	Article; Proceedings Paper	20th International-Florida-AI-Research-Society Conference	MAY, 2007	Key West, FL	Int Florida Artificial Intelligence Res Soc		instance-based classifiers; ambiguous attributes		In an attempt to automate evaluation of network intrusion detection systems, we encountered the problem of ambiguously described learning examples. For instance, an attribute's value, or a class label, in a given example was known to be a or b but definitely not c or d. Previous research in machine learning usually either "disambiguated" the value (by giving preference to a or b), or replaced it with a "don't-know" symbol. Neither approach is satisfactory: while the former distorts the available information by pretending precise knowledge, the latter ignores the fact that at least something is known. Our experiments confirm the intuition that classification performance is indeed impaired if the ambiguities are not handled properly. In there search reported here,we limited ourselves to the realm of the relatively simple nearest-neighbor classifiers and investigated a few alternative solutions. The paper describes the techniques we used and describes their behavior in experimental domains.	[Holland, Hans; Kubat, Miroslav] Univ Miami, Dept Elect & Comp Engn, Coral Gables, FL 33124 USA; [Zizka, Jan] Masaryk Univ, Coll Sci, Brno 62500, Czech Republic	Holland, H (reprint author), Univ Miami, Dept Elect & Comp Engn, Coral Gables, FL 33124 USA.	hholland@miami.edu; mkubat@miami.edu					Bezdek J. C., 1981, PATTERN RECOGNITION; DASARTHY BV, 1991, NEAREST NEIGHBOR CLA; Denoeux T., 2000, P SMC 2000 NASHV US, P2923; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Dunn J. C., 1973, Journal of Cybernetics, V3; Elouedi Z, 2001, INT J APPROX REASON, V28, P91, DOI 10.1016/S0888-613X(01)00045-7; Good I.J., 1965, ESTIMATION PROBABILI; HOLLAND H, 2007, P C FLOR ART INT RES, P7; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P80; Newman D. J., 1998, UCI REPOSITORY MACHI; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Rumelhart D., 1986, PARALLEL DISTRIBUTED; Shafer G., 1990, READINGS UNCERTAIN R; Shafer G, 1997, MATH THEORY EVIDENCE; Vannoorenberghe P., 2004, Information Fusion, V5, DOI 10.1016/j.inffus.2004.01.001; VANNOORENBERGHE P, 2002, P IPMU 2002 ANN FRAN, P1919; Vapnik V. N, 1995, NATURE STAT LEARNING	17	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-2130		INT J ARTIF INTELL T	Int. J. Artif. Intell. Tools	JUN	2008	17	3					449	463		10.1142/S0218213008003996		15	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	327XQ	WOS:000257762200004	
J	Lintean, M; Rus, V				Lintean, Mihai; Rus, Vasile			Large scale experiments with naive Bayes and decision trees for function tagging	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS			English	Article; Proceedings Paper	20th International-Florida-AI-Research-Society Conference	MAY, 2007	Key West, FL	Int Florida Artificial Intelligence Res Soc		natural language processing; function tags; machine learning; naive Bayes; decision trees		This paper describes the use of two machine learning techniques, naive Bayes and decision trees, to address the task of assigning function tags to nodes in a syntactic parse tree. Function tags are extra functional information, such as logical subject or predicate, that can be added to certain nodes in syntactic parse trees. We model the function tags assignment problem as a classification problem. Each function tag is regarded as a class and the task is to find what class/tag a given node in a parse tree belongs to from a set of predefined classes/tags. The paper offers the first systematic comparison of the two techniques, naive Bayes and decision trees, for the task of function tags assignment. The comparison is based on a standardized data set, the Penn Treebank, a collection of sentences annotated with syntactic information including function tags. We found out that decision trees generally outperform naive Bayes for the task of function tagging. Furthermore, this is the first large scale evaluation of decision trees based solutions to the task of functional tagging.	[Lintean, Mihai; Rus, Vasile] Univ Memphis, Dept Comp Sci, Inst Intelligent Syst, Memphis, TN 38152 USA	Lintean, M (reprint author), Univ Memphis, Dept Comp Sci, Inst Intelligent Syst, Memphis, TN 38152 USA.	M.Lintean@memphis.edu; vrus@memphis.edu					Bies A., 1995, BRACKETING GUIDELINE; BLAHETA D, 2003, THESIS BROWN U; Blaheta D., 2000, P 1 ANN M N AM CHAPT, P234; BRANTS T, 1997, P C EMP METH NAT LAN; Breiman L, 1984, CLASSIFICATION REGRE; CHARNIAK E, 2000, P N AM CHAPT ASS COM; CHARNIAK E, 2003, P MACH TRANSL SUMM 9; Collins M., 1999, THESIS U PENNSYLVANI; COLLINS M, 1997, P 35 ANN M ASS COMP; Esposito F, 1997, IEEE T PATTERN ANAL, V19, P476, DOI 10.1109/34.589207; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Gildea D, 2002, COMPUT LINGUIST, V28, P245, DOI 10.1162/089120102760275983; IRINA R, 2001, WORKSH EMPR METH ART; JIJKOUN V, 2004, P ACL 2004; JOHNSON M, 2002, P 40 ANN M ASS COMP; Klein D., 2003, P 41 ANN M ASS COMP; Kononenko I., 1990, CURRENT TRENDS KNOWL; Langley P., 1992, P 10 NAT C ART INT, P223; Lappin S., 1994, Computational Linguistics, V20; Magerman D., 1994, THESIS STANFORD U; Mccallum A., 1998, WORKSH LEARN TEXT CA; MOLDOVAN D, 2000, P ACL 2000 HONG KONG; PAZZANI MJ, 1996, LEARNING DATA ARTIFI; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; Quinlan J., 1986, INDUCTION DECISION T, V1, P81, DOI DOI 10.1007/BF00116251; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Ruppenhofer J., 2006, FRAMENET; RUS V, 2005, P C INT TEXT PROC CO; VOORHEES EM, 2002, P 11 TEXT RETR C; WEISSTEIN EW, K STAT; Witten I. H., 2005, DATA MINING PRACTICA; ZHANG H, 2004, P FLAIRS	32	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-2130		INT J ARTIF INTELL T	Int. J. Artif. Intell. Tools	JUN	2008	17	3					483	499		10.1142/S0218213008004011		17	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	327XQ	WOS:000257762200006	
J	Shirazi, H; Sammut, CA				Shirazi, H.; Sammut, C. A.			Acquiring control knowledge from examples using ripple-down rules and machine learning	IRANIAN JOURNAL OF SCIENCE AND TECHNOLOGY TRANSACTION B-ENGINEERING			English	Article						machine learning; expert systems; knowledge acquisition; RDR		The inability of experts to articulate the knowledge required to solve a problem is, arguably, the greatest challenge to building an expert system. The problem is made worse in situations where the response of the expert must be so rapid that there is not even a chance of a plausible post hoc reconstruction of the decision processes involved. For this reason, construction of the knowledge base by example is the only approach available. Examples can be used in two ways. They may be used as input to an induction program whose task is to find an abstraction of a control strategy from the data. Examples may also be used to induce the expert to discern differences between cases, thereby allowing the knowledge acquisition system to construct rules semi-automatically. The work presented in this paper demonstrates the feasibility of both approaches. In particular, it shows that the RDR methodology can be extended to domains where the expertise involved is necessarily subcognitive. This is demonstrated by the application of a combination of ripple-down rules and machine learning to the task of acquiring piloting skills for an aircraft in a flight simulator.	[Shirazi, H.] Malek Ashtar Univ Technol, Sch Comp Sci & Engn, Fac Informat Technol, Tehran, IR, Iran; [Sammut, C. A.] Univ New S Wales, Sch Comp Sci & Engn, Dept Artificial Intelligence, Sydney, NSW 2052, Australia	Shirazi, H (reprint author), Malek Ashtar Univ Technol, Sch Comp Sci & Engn, Fac Informat Technol, Tehran, IR, Iran.	shirazi@mut.ac.ir					Bratko I, 2002, LECT NOTES ARTIF INT, V2358, P812; BRATKO I, 2004, AI MAG, V24, P107; DAZELEY R, 2003, 16 AUSTR JOINT C ART; GAINES BR, 1992, P 5 AUSTR JOINT C AR; Kadous MW, 2005, MACH LEARN, V58, P179, DOI 10.1007/s10994-005-5826-5; KADOUS W, 2006, 3 INT C AUT ROB AG; MONZINA M, 2007, ARTIF INTELL, V171, P922; MULHOLLAND M, 1994, APPL C4 5 CLASSIFIER; POTTS D, 2005, MACH LEARN, V6, P5; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Sammut C., 1992, P 9 INT C MACH LEARN; SAMMUT C, 1996, KNOWLEDGE ENG REV; SAMMUT C, 2007, INT S SKILL SCI TOK; SHIRAZ GM, 1997, 15 INT C ART INT IJC; Srdoc A, 2007, COMPUT IND, V58, P464, DOI 10.1016/j.compind.2006.09.013; SUCC D, 2000, LECT NOTES COMPUTER, V1810, P382; URBANCIC T, 1994, P 11 EUR C ART INT; YIK TF, 2007, AUSTR C ROB AUT BRIS	18	0	0	SHIRAZ UNIV	SHIRAZ	SHIRAZ, IRAN	1028-6284		IRAN J SCI TECHNOL B	Iran. J. Sci. Technol. Trans. B-Eng.	JUN	2008	32	B3					295	304				10	Engineering, Multidisciplinary	Engineering	322DS	WOS:000257356000008	
J	Abad-Grau, MM; Ierache, J; Cervino, C; Sebastiani, P				Abad-Grau, Maria M.; Ierache, Jorge; Cervino, Claudio; Sebastiani, Paola			Evolution and challenges in the design of computational systems for triage assistance	JOURNAL OF BIOMEDICAL INFORMATICS			English	Review						triage; decision support system; expert system; machine learning; decision tree; Bayesian network	DECISION-SUPPORT; BAYESIAN NETWORKS; EMERGENCY TRIAGE; ABDOMINAL-PAIN; MEDICINE; MODEL; INTEGRATION; TREES	Compared with expert systems for specific disease diagnosis, knowledge-based systems to assist decision making in triage usually try to cover a much wider domain but can use a smaller set of variables due to time restrictions, many of them subjective so that accurate models are difficult to build. In this paper, we first study criteria that most affect the performance of systems for triage assistance. Such criteria include whether principled approaches from machine learning can be used to increase accuracy and robustness and to represent uncertainty, whether data and model integration can be performed or whether temporal evolution can be modeled to implement retriage or represent medication responses. Following the most important criteria, we explore current systems and identify some missing features that, if added, may yield to more accurate triage systems. (c) 2008 Elsevier Inc. All rights reserved.	[Abad-Grau, Maria M.] Univ Granada, Dept Comp Lang & Syst, E-18071 Granada, Spain; [Ierache, Jorge] Univ Moron, FICCTE, Inst Intelligent Syst, Moron, Argentina; [Cervino, Claudio] Univ Moron, FICCTE, Sch Med, Moron, Argentina; [Sebastiani, Paola] Boston Univ, Sch Publ Hlth, Dept Biostat, Boston, MA USA	Abad-Grau, MM (reprint author), Univ Granada, Dept Comp Lang & Syst, C Periodista Daniel Saucedo Aranda, E-18071 Granada, Spain.	mabad@ugr.es; jierache@unimoron.edu.ar; ccervino@unimoron.edu.ar; sebas@bu.edu	Abad-Grau, Maria Mar/B-2172-2012	Abad-Grau, Maria Mar/0000-0001-8470-9719			ABADGRAU MM, 2007, 9 WORKSH INV CIENC C, V1, P43; Abellan J, 2003, INT J INTELL SYST, V18, P1215, DOI 10.1002/int.10143; Barthell EN, 2004, ACAD EMERG MED, V11, P1142, DOI 10.1197/j.aem.2004.08.008; Baxter J, 2000, J ARTIF INTELL RES, V12, P149; Burnside ES, 2004, INT CONGR SER, V1268, P1021, DOI 10.1016/j.ics.2004.03.274; Castillo E., 1997, EXPERT SYSTEMS PROBA; CONSORIUM TE, 2002, P 1 INT WORKSH PROB, P220; Cooper G. F., 1991, P 7 C UNC ART INT LO, P86; Cowell R. G., 1999, PROBABILISTIC NETWOR; Cruz-Ramirez N, 2006, LECT NOTES COMPUT SC, V4225, P706; Dong SL, 2007, ACAD EMERG MED, V14, P16, DOI 10.1197/j.aem.2006.08.021; Elouedi Z, 2001, INT J APPROX REASON, V28, P91, DOI 10.1016/S0888-613X(01)00045-7; Farion KJ, 2008, INT J MED INFORM, V77, P208, DOI 10.1016/j.ijmedinf.2007.01.004; FESMIRE FM, 2003, ANN EMERG MED, V42, P857; Finkelstein SM, 2005, HEART LUNG, V34, P201, DOI 10.1016/j.hrting.2004.09.003; Friedman N., 1997, P 13 C UNC ART INT, P1; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Gellerstedt Martin, 2006, Eur J Emerg Med, V13, P290, DOI 10.1097/00063110-200610000-00009; Gerling IC, 2003, ARCH INTERN MED, V163, P190, DOI 10.1001/archinte.163.2.190; GOMEZJIMENEZ J, 2003, EMERGENCIAS, V1, P339; Graber MA, 2003, EMERG MED J, V20, P426, DOI 10.1136/emj.20.5.426; GRUBER TR, 1993, KNOWL ACQUIS, V5, P199, DOI 10.1006/knac.1993.1008; GUTERMAN JJ, 2003, ENG MED BIOL SOC 200, P592; Holmstrom Inger, 2007, Nurs Health Sci, V9, P23, DOI 10.1111/j.1442-2018.2007.00299.x; HOOT N, 2007, ACAD EMERGENCY MED S, V14, P53; HUANG H, 2004, P 5 WORLD C INT CONT, V1, P4260; Jelinek GA, 1996, EMERGEN MED, V8, P226; JENSEN FV, 1997, BAYESIAN NETWORKS IN; Jinmao Wei, 2002, Proceedings of the 4th World Congress on Intelligent Control and Automation (Cat. No.02EX527), DOI 10.1109/WCICA.2002.1022144; Kanehisa M, 2003, NAT GENET, V33, P305, DOI 10.1038/ng1109; KOHAVI R, 1995, P 15 INT JOINT C ART, P114; Lacave C, 2003, LECT NOTES ARTIF INT, V2774, P1345; Louie B, 2007, J BIOMED INFORM, V40, P5, DOI 10.1016/j.jbi.2006.02.007; MARKLUND B, 2000, SYMPTOMS RAD ATGARD; MICHALOWSKI W, 2004, J INF TECHNOL, V2, P237; Michalowski W, 2005, INFOR, V43, P287; Murray Michael, 2004, CJEM, V6, P421; Neapolitan R. E., 1989, PROBABILISTIC REASON; Padmanabhan N., 2006, P 39 HAW INT C SYST, V1, P3; PAN R, 2006, 18 IEEE INT C TOOLS, V1, P441; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; RISSANEN J, 1978, AUTOMATICA, V14, P222; Sadeghi S, 2006, INT J MED INFORM, V75, P403, DOI 10.1016/j.ijmedinf.2005.07.028; SAJDA P, 2006, ANNU REV BIOMED ENG, V8, P1; SANPEDRO J, 2005, P 38 ANN HAW INT C S, pC157; Schafter C., 1994, P 11 INT C MACH LEAR, P259; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SEBASTIANI P, 2005, STAT MED, V25, P1803; Sebastiani P, 2005, NAT GENET, V37, P435, DOI 10.1038/ng1533; Sebastiani P., 2000, SIGKDD EXPLORATIONS, V1, P91; SEBASTIANI P, 2005, GENOMIC SIGNAL PROCE, P281; SEBASTIANI P, 2007, BLOOD, V6, P1; Shavlik J. W., 1990, READINGS MACHINE LEA; Sheng Yu-Hsiang, 2006, AMIA Annu Symp Proc, P1091; Utgoff P. E., 1989, Machine Learning, V4, DOI 10.1023/A:1022699900025; Vapnik VN, 1998, STAT LEARNING THEORY; WANN TT, 2002, J MED SYST, V26, P127; Wilk S, 2005, EUR J OPER RES, V160, P696, DOI 10.1016/j.ejor.2003.06.034; Wong W.K., 2003, P 20 INT C MACH LEAR, P808; YAMADA Y, 2003, P 20 INT C MACH LEAR, P840; *VICT DEP HUM SERV, 2001, CONS TRIAG VICT EM D; 2004, P 17 INT FLAIRS C, P1	62	3	3	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464		J BIOMED INFORM	J. Biomed. Inform.	JUN	2008	41	3					432	441		10.1016/j.jbi.2008.01.007		10	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	318YR	WOS:000257129200003	
J	Buja, A; Swayne, DF; Littman, ML; Dean, N; Hofmann, H; Chen, L				Buja, Andreas; Swayne, Deborah F.; Littman, Michael L.; Dean, Nathaniel; Hofmann, Heike; Chen, Lisha			Data visualization with multidimensional scaling	JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS			English	Article						dimension reduction; dissimilarity data; external unfolding; gradient descent; graph layout; molecular conformation; multidimensional unfolding; multivariate analysis; proximity data; social networks	NONLINEAR DIMENSIONALITY REDUCTION; UNKNOWN DISTANCE FUNCTION; PROXIMITIES; INFORMATION	We discuss methodology for multidimensional scaling (MDS) and its implementation in two software systems, GGvis and XGvis. MDS is a visualization technique for proximity data, that is, data in the form of N x N dissimilarity matrices. MDS constructs maps ("configurations," "embeddings") in Rk by interpreting the dissimilarities as distances. Two frequent sources of dissimilarities are high-dimensional data and graphs. When the dissimilarities are distances between high-dimensional objects, MDS acts as a (often nonlinear) dimension-reduction technique. When the dissimilarities are shortest-path distances in a graph, MDS acts as a graph layout technique. MDS has found recent attention in machine learning motivated by image databases ("Isomap"). MDS is also of interest in view of the popularity of "kernelizing" approaches inspired by Support Vector Machines (SVMs; "kernel PCA"). This article discusses the following general topics: (1) the stability and multiplicity of MDS solutions; (2) the analysis of structure within and between subsets of objects with missing value schemes in dissimilarity matrices; (3) gradient descent for optimizing general MDS loss functions ("Strain" and "Stress"); (4) a unification of classical (Strain-based) and distance (Stress-based) MDS. Particular topics include the following: (1) blending of automatic optimization with interactive displacement of configuration points to assist in the search for global optima; (2) forming groups of objects with interactive brushing to create patterned missing values in MDS loss functions; (3) optimizing MDS loss functions for large numbers of objects relative to a small set of anchor points ("external unfolding"); and (4) a non-metric version of classical MDS. We show applications to the mapping of computer usage data, to the dimension reduction of marketing segmentation data, to the layout of mathematical graphs and social networks, and finally to the spatial reconstruction of molecules.	[Buja, Andreas] Univ Penn, Wharton Sch, Philadelphia, PA 19104 USA; [Littman, Michael L.] Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA; [Dean, Nathaniel] SW Texas State Univ, Dept Math, San Marcos, TX 78666 USA; [Hofmann, Heike] Iowa State Univ, Dept Stat, Ames, IA 50011 USA; [Chen, Lisha] Yale Univ, Dept Stat, New Haven, CT 06511 USA	Buja, A (reprint author), Univ Penn, Wharton Sch, Philadelphia, PA 19104 USA.	dfs@research.att.com; mlittman@cs.rutgers.edu; nd17@txstate.edu; hofmann@iastate.edu; lisha.chen@yale.edu					ASIMOV D, 1998, GEOMETRY CAPPED NANO; Buja A, 2002, J CLASSIF, V19, P7, DOI 10.1007/s00357-001-0031-0; Buja A., 1996, J COMPUTATIONAL GRAP, V5, P78, DOI 10.2307/1390754; CHEN L, 2008, LOCAL MULTI IN PRESS; Cook D, 2007, USE R, P1, DOI 10.1007/978-0-387-71762-3; Cox R.F., 1994, MULTIDIMENSIONAL SCA; CRIPPEN GM, 1978, ACTA CRYSTALLOGR A, V34, P282, DOI 10.1107/S0567739478000522; DELEEUW J, 2000, IMS LECT NOTES MONOG, P219; Di Battista G., 1999, GRAPH DRAWING ALGORI; GLUNT W, 1993, J COMPUT CHEM, V14, P114, DOI 10.1002/jcc.540140115; GRAEF J, 1979, PSYCHOL BULL, V86, P60, DOI 10.1037/0033-2909.86.1.60; Groenen P. J. F., 1997, MODERN MULTIDIMENSIO; HAVEL TF, 1991, PROG BIOPHYS MOL BIO, V56, P43, DOI 10.1016/0079-6107(91)90007-F; Kruskal J, 1978, MULTIDIMENSIONAL SCA; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P115, DOI 10.1007/BF02289694; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565; KSUSKAL JB, 1980, P 1 GEN C SOC GRAPH, P22; LITTMAN M, 1992, COMPUTING SCI STAT, V24, P208; MCFARLANE M, 1994, J COMPUTATIONAL GRAP, V3, P23, DOI 10.2307/1390793; MEULMAN JJ, 1992, PSYCHOMETRIKA, V57, P539, DOI 10.1007/BF02294419; ROTHKOPF EZ, 1957, J EXP PSYCHOL, V53, P94, DOI 10.1037/h0041867; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Sammon J. W., 1969, IEEE T COMPUTERS C, VC-18; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SHEPARD RN, 1962, PSYCHOMETRIKA, V27, P219, DOI 10.1007/BF02289621; SHEPARD RN, 1962, PSYCHOMETRIKA, V27, P125, DOI 10.1007/BF02289630; SWAYNE DF, 2002, J COMPUTATIONAL STAT, V43, P423; Swayne DF, 1998, J COMPUT GRAPH STAT, V7, P113, DOI 10.2307/1390772; SWAYNE DF, 2003, P 3 ANN WORKSH DISTR; TAKANE Y, 1977, PSYCHOMETRIKA, V42, P7, DOI 10.1007/BF02293745; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; THEUS M, 1998, STAT COMPUTING GRAPH, V9, P12; TORGERSON WS, 1952, PSYCHOMETRIKA, V17, P401; Trosset M., 1998, COMPUTING SCI STAT, V29, P148; Trosset MW, 1998, J CLASSIF, V15, P15, DOI 10.1007/s003579900018	35	19	20	AMER STATISTICAL ASSOC	ALEXANDRIA	732 N WASHINGTON ST, ALEXANDRIA, VA 22314-1943 USA	1061-8600		J COMPUT GRAPH STAT	J. Comput. Graph. Stat.	JUN	2008	17	2					444	472		10.1198/106186008X318440		29	Statistics & Probability	Mathematics	311WG	WOS:000256630500011	
J	Obrezanova, O; Gola, JMR; Champness, EJ; Segall, MD				Obrezanova, Olga; Gola, Joelle M. R.; Champness, Edmund J.; Segall, Matthew D.			Automatic QSAR modeling of ADME properties: blood-brain barrier penetration and aqueous solubility	JOURNAL OF COMPUTER-AIDED MOLECULAR DESIGN			English	Article						automatic model generation process; QSAR modeling; ADME properties; blood-brain barrier penetration; aqueous solubility; Gaussian Processes; drug discovery	QUANTITATIVE STRUCTURE; GAUSSIAN-PROCESSES; ORGANIC-COMPOUNDS; DATA-BASE; PREDICTION	In this article, we present an automatic model generation process for building QSAR models using Gaussian Processes, a powerful machine learning modeling method. We describe the stages of the process that ensure models are built and validated within a rigorous framework: descriptor calculation, splitting data into training, validation and test sets, descriptor filtering, application of modeling techniques and selection of the best model. We apply this automatic process to data sets of blood-brain barrier penetration and aqueous solubility and compare the resulting automatically generated models with 'manually' built models using external test sets. The results demonstrate the effectiveness of the automatic model generation process for two types of data sets commonly encountered in building ADME QSAR models, a small set of in vivo data and a large set of physico-chemical data.	[Obrezanova, Olga; Gola, Joelle M. R.; Champness, Edmund J.; Segall, Matthew D.] BioFocus DPI Ltd, Saffron Walden CB10 1XL, Essex, England	Obrezanova, O (reprint author), BioFocus DPI Ltd, Darwin Bldg,Chesterford Res Pk, Saffron Walden CB10 1XL, Essex, England.	olga.obrezanova@glpg.com	Gola, Joelle/D-5451-2011				Abraham MH, 2006, J PHARM SCI-US, V95, P2091, DOI 10.1002/jps.20595; ABRAHAM MH, 1987, CHROMATOGRAPHIA, V23, P243, DOI 10.1007/BF02311772; BUHMAN MD, 2003, RADIAL BASIS FUNCTIO; Burden FR, 2001, J CHEM INF COMP SCI, V41, P830, DOI 10.1021/ci000459c; Butina D, 2003, J CHEM INF COMP SCI, V43, P837, DOI 10.1021/6020279y; Butina D, 1999, J CHEM INF COMP SCI, V39, P747, DOI 10.1021/ci9803381; Cartmell J, 2005, J COMPUT AID MOL DES, V19, P821, DOI 10.1007/s10822-005-9029-8; Clark DE, 2005, ANNU REP MED CHEM, V40, P403, DOI 10.1016/S0065-7743(05)40026-3; Enot DP, 2001, SAR QSAR ENVIRON RES, V12, P461, DOI 10.1080/10629360108035385; Ertl P, 2000, J MED CHEM, V43, P3714, DOI 10.1021/jm000942e; Huuskonen J, 2000, J CHEM INF COMP SCI, V40, P773, DOI 10.1021/ci9901338; Livingstone D., 1995, DATA ANAL CHEM; MacKay D., 2003, INFORM THEORY INFERE; Obrezanova O, 2007, J CHEM INF MODEL, V47, P1847, DOI 10.1021/ci7000633; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Rose K, 2002, J CHEM INF COMP SCI, V42, P651, DOI 10.1021/ci010127n; Schroeter TS, 2007, J COMPUT AID MOL DES, V21, P485, DOI 10.1007/s10822-007-9125-z; Schwaighofer A, 2007, J CHEM INF MODEL, V47, P407, DOI 10.1021/ci600205g; Tetko IV, 2002, J CHEM INF COMP SCI, V42, P717, DOI 10.1021/ci010379o; Tino P, 2004, J CHEM INF COMP SCI, V44, P1647, DOI 10.1021/ci034255i; Whitley DC, 2000, J CHEM INF COMP SCI, V40, P1160, DOI 10.1021/ci000384c; Winkler DA, 2004, J MOL GRAPH MODEL, V22, P499, DOI 10.1016/j.jmgm.2004.03.010; Wold S, 1998, ENCY COMPUTATIONAL C, V3, P2006; Zhang SX, 2006, J CHEM INF MODEL, V46, P1984, DOI 10.1021/ci060132x; *DAYL CHEM INF SYS, SMARTS TUT	25	23	23	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-654X		J COMPUT AID MOL DES	J. Comput.-Aided Mol. Des.	JUN	2008	22	6-7					431	440		10.1007/s10822-008-9193-8		10	Biochemistry & Molecular Biology; Biophysics; Computer Science, Interdisciplinary Applications	Biochemistry & Molecular Biology; Biophysics; Computer Science	303FV	WOS:000256027300010	
J	Reid, D; Sadjad, BS; Zsoldos, Z; Simon, A				Reid, Darryl; Sadjad, Bashir S.; Zsoldos, Zsolt; Simon, Aniko			LASSO-ligand activity by surface similarity order: a new tool for ligand based virtual screening	JOURNAL OF COMPUTER-AIDED MOLECULAR DESIGN			English	Article						conformation independent QSAR descriptor; scaffold hopping; virtual screening; ligand based screening	ACCURATE DOCKING; RECOGNITION; PREDICTION; GLIDE; SHAPE; QSAR	Virtual Ligand Screening (VLS) has become an integral part of the drug discovery process for many pharmaceutical companies. Ligand similarity searches provide a very powerful method of screening large databases of ligands to identify possible hits. If these hits belong to new chemotypes the method is deemed even more successful. eHiTS LASSO uses a new interacting surface point types (ISPT) molecular descriptor that is generated from the 3D structure of the ligand, but unlike most 3D descriptors it is conformation independent. Combined with a neural network machine learning technique, LASSO screens molecular databases at an ultra fast speed of 1 million structures in under 1 min on a standard PC. The results obtained from eHiTS LASSO trained on relatively small training sets of just 2, 4 or 8 actives are presented using the diverse directory of useful decoys (DUD) dataset. It is shown that over a wide range of receptor families, eHiTS LASSO is consistently able to enrich screened databases and provides scaffold hopping ability.	[Reid, Darryl; Sadjad, Bashir S.; Zsoldos, Zsolt; Simon, Aniko] SimBioSys Inc, Toronto, ON M9W 6V1, Canada	Simon, A (reprint author), SimBioSys Inc, 135 Queens Plate Dr,Suite 520, Toronto, ON M9W 6V1, Canada.	aniko@simbiosys.ca					Bissantz C, 2000, J MED CHEM, V43, P4759, DOI 10.1021/jm001044l; Brandstetter H, 1996, J BIOL CHEM, V271, P29988; Chen B, 2007, J COMPUT AID MOL DES, V21, P53, DOI 10.1007/s10822-006-9096-5; Clark T, 2004, J MOL GRAPH MODEL, V22, P519, DOI 10.1016/j.jmgm.2004.03.012; Dixon SL, 2006, J COMPUT AID MOL DES, V20, P647, DOI 10.1007/s10822-006-9087-6; Friesner RA, 2004, J MED CHEM, V47, P1739, DOI 10.1021/jm0306430; Halgren TA, 2004, J MED CHEM, V47, P1750, DOI 10.1021/jm030644s; Hann MM, 2001, J CHEM INF COMP SCI, V41, P856, DOI 10.1021/ci000403i; Harper G, 2001, J CHEM INF COMP SCI, V41, P1295, DOI 10.1021/ci000397q; Hawkins PCD, 2007, J MED CHEM, V50, P74, DOI 10.1021/jm0603365; Huang N, 2006, J MED CHEM, V49, P6789, DOI 10.1021/jm0608356; Jones G, 1995, J COMPUT AID MOL DES, V9, P532, DOI 10.1007/BF00124324; McGaughey GB, 2007, J CHEM INF MODEL, V47, P1504, DOI 10.1021/ci700052x; Moustakas DT, 2006, J COMPUT AID MOL DES, V20, P601, DOI 10.1007/s10822-006-9060-4; Perola E, 2004, J MED CHEM, V47, P2499, DOI 10.1021/jm030563w; Pham TA, 2006, J MED CHEM, V49, P5856, DOI 10.1021/jm050040j; Saeh JC, 2005, J CHEM INF MODEL, V45, P1122, DOI 10.1021/ci049732r; Triballeau N, 2005, J MED CHEM, V48, P2534, DOI 10.1021/jm049092j; Truchon JF, 2007, J CHEM INF MODEL, V47, P488, DOI 10.1021/ci600426e; Verdonk ML, 2003, PROTEINS, V52, P609, DOI 10.1002/prot.10465; Wagener M, 2000, J CHEM INF COMP SCI, V40, P280, DOI 10.1021/ci990266t; Zell A., 2005, STUTTGART NEURAL NET; Zhang Q, 2006, J MED CHEM, V49, P1536, DOI 10.1021/jm050468i; Zsoldos Z, 2006, CURR PROTEIN PEPT SC, V7, P421, DOI 10.2174/138920306778559412; 2007, J CHEM V 3 2 4	25	9	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-654X		J COMPUT AID MOL DES	J. Comput.-Aided Mol. Des.	JUN	2008	22	6-7					479	487		10.1007/s10822-007-9164-5		9	Biochemistry & Molecular Biology; Biophysics; Computer Science, Interdisciplinary Applications	Biochemistry & Molecular Biology; Biophysics; Computer Science	303FV	WOS:000256027300014	
J	Leskes, B; Torenvliet, L				Leskes, Boaz; Torenvliet, Leen			The value of agreement a new boosting algorithm	JOURNAL OF COMPUTER AND SYSTEM SCIENCES			English	Article						machine learning; boosting; co-training; semi-supervised learning; unlabeled data		In the past few years unlabeled examples and their potential advantage have received a lot of attention. In this paper a new boosting algorithm is presented where unlabeled examples are used to enforce agreement between several different learning algorithms. Not only do the learning algorithms learn from the given training set but they are supposed to do so while agreeing on the unlabeled examples. Similar ideas have been proposed before (for example, the Co-Training algorithm by Mitchell and Blum), but without a proof or under strong assumptions. In our setting, it is only assumed that all learning algorithms are equally adequate for the tasks. A new generalization bound is presented where the use of unlabeled examples results in a better ratio between training-set size and the resulting classifier's quality and thus reduce the number of labeled examples necessary for achieving it. The extent of this improvement depends on the diversity of the learners-a more diverse group of learners will result in a larger improvement whereas using two copies of a single algorithm gives no advantage at all. As a proof of concept, the algorithm, named Agreement Boost, is applied to two test problems. In both cases, using Agreement Boost results in an up to 40% reduction in the number of labeled examples. (c) 2007 Elsevier Inc. All rights reserved.	[Leskes, Boaz; Torenvliet, Leen] Univ Amsterdam, Dept Comp Sci, NL-1018 TV Amsterdam, Netherlands	Torenvliet, L (reprint author), Univ Amsterdam, Dept Comp Sci, Plantage Muidergracht 24, NL-1018 TV Amsterdam, Netherlands.	bleskes@tiscali.nl; leen@science.uva.nl					Bartlett P. L, 2003, J MACHINE LEARNING R, V3, P463; Bennett K.P., 2002, P 8 ACM SIGKDD INT C; Blum A., 1998, P 11 ANN C COMP LEAR; BLUMER A, 1989, J ACM, V36, P929, DOI 10.1145/76359.76371; Collins M., 1999, P JOINT SIGDAT C EMP; Dasgupta S., 2001, ADV NEURAL INFORM PR, V14; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; GOLDMAN S, 2000, INT JOINT C MACH LEA; GROVE AJ, 1998, P 15 NAT C ART INT; HWA R, 2003, P WORKSH CONT LAB UN; KOLTCHINSKII V, 2002, ANN STAT, V30; LEVIN A, 2003, INT C COMP VIS ICCV; Luenberger DG, 1973, INTRO LINEAR NONLINE; MASON L, 1999, BOOSTING ALGORITHMS; Meir R, 2002, LECT NOTES ARTIF INT, V2600, P118; Nigam K, 2000, P 9 INT C INF KNOWL; NIGAM K, 1998, P 15 NAT C ART INT; PARK SB, 2004, INFORM PROCESS MANAG, V40; PIERCE D, 2001, P C EMP METH NAT LAN; RATSCH G, 2001, 98 ROYAL HOLL COLL; SCHAPIRE RE, 1997, MACH LEARN P 14 INT; Zhang T., 2000, P 17 INT C MACH LEAR, P1191	22	5	5	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0022-0000		J COMPUT SYST SCI	J. Comput. Syst. Sci.	JUN	2008	74	4					557	586		10.1016/j.jcss.2007.06.005		30	Computer Science, Hardware & Architecture; Computer Science, Theory & Methods	Computer Science	306XS	WOS:000256282300009	
J	Coz-Rakovac, R; Strunjak-Perovic, I; Popovic, NT; Hacmanjek, M; Smuc, T; Jadan, M; Lipej, Z; Homen, Z				Coz-Rakovac, R.; Strunjak-Perovic, I.; Popovic, N. Topic; Hacmanjek, M.; Smuc, T.; Jadan, M.; Lipej, Z.; Homen, Z.			Cage culture effects on mullets (Mugilidae) liver histology and blood chemistry profile	JOURNAL OF FISH BIOLOGY			English	Article						Adriatic sea; blood chemistry; cage culture; histology; machine learning techniques; mullet	BASS DICENTRARCHUS-LABRAX; TROUT SALMO-GAIRDNERI; RAINBOW-TROUT; ENZYME-ACTIVITIES; PLASMA; SEA; ONCORHYNCHUS; PARAMETERS; CAPTURE; TISSUES	A comparative study of blood chemistry and histology was conducted on two groups of mullets (Mugilidae) living under different conditions with different feed sources. The aquaculture influenced mullet group (AIM), was collected near fish farms and the control group of mullet (CM) was caught in the waters Without any aquaculture activities. Histological and biochemical procedures were employed to Study liver histomorphology, plasma aspartate and alanine aminotransferase (AST, ALT), triglyceride (TRIG), cholesterol (CHOL), glucose (GLU) and total protein (TP) of both AIM and CM. Moderate histological changes (lipid infiltration) were observed in the liver of AIM. Significant changes in plasma variables were observed in AIM. Blood chemistry variables measured proved to be good indicators of artificial feed effects. Classical statistical approaches were applied to the blood chemistry and histopathology data. For the first time machine learning techniques were used to generate comprehensible classification models and to explore blood chemistry variable importance, strength, their mutual interactions or dependencies, and to investigate reliability of particular variables within the groups. (C) 2008 The Authors. Journal compilation (C) 2008 The Fisheries Society of the British Isles.	[Coz-Rakovac, R.; Strunjak-Perovic, I.; Popovic, N. Topic; Hacmanjek, M.; Jadan, M.] Rudjer Boskovic Inst, Ichthyopathol Grp Biol Mat, Div Mat Chem, Zagreb 10002, Croatia; [Smuc, T.] Rudjer Boskovic Inst, Informat Syst Lab, Div Elect, Zagreb 10002, Croatia; [Lipej, Z.] Croatian Vet Inst, Zagreb 10000, Croatia; [Homen, Z.] Minist Agr Fisheries & Rural Dev, Dept Fishery, Zagreb 10000, Croatia	Coz-Rakovac, R (reprint author), Rudjer Boskovic Inst, Ichthyopathol Grp Biol Mat, Div Mat Chem, Bijenicka 54, Zagreb 10002, Croatia.	rrakovac@irb.hr					BELL GR, 1968, J FISH RES BOARD CAN, V25, P1247; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Burtis C. A., 1996, TIETZ FUNDAMENTALS C; CASILLAS E, 1986, J FISH DIS, V8, P437; CASILLAS E, 1983, AQUAT TOXICOL, V3, P61, DOI 10.1016/0166-445X(83)90007-3; CHRISTOFILOGIAN.P, 1993, AQUACULTURE VET FISH, P379; COWEY CB, 1977, BRIT J NUTR, V38, P385, DOI 10.1079/BJN19770103; Coz-Rakovac R, 2005, VET RES COMMUN, V29, P677, DOI 10.1007/s11259-005-3684-z; Duda R., 2000, PATTERN CLASSIFICATI; Dzeroski S, 2003, ECOL MODEL, V170, P219, DOI 10.1016/S0304-3800(03)00229-1; Edsall CC, 1999, J AQUAT ANIM HEALTH, V11, P81, DOI 10.1577/1548-8667(1999)011<0081:ABCPFL>2.0.CO;2; GAUDET M, 1975, J FISH BIOL, V7, P505, DOI 10.1111/j.1095-8649.1975.tb04625.x; Goede R.W., 1990, AM FISHERIES SOC S, V8, P93; Jardas I, 1996, JADRANSKA IHTIOFAUNA; Kavadias S, 2004, J APPL ICHTHYOL, V20, P58, DOI 10.1111/j.1439-0426.2004.00497.x; LEMAIRE P, 1991, AQUACULTURE, V93, P63, DOI 10.1016/0044-8486(91)90205-L; LUNA LG, 1979, MANUAL HISTOLOGIC ME; Luskova V, 1995, FOLIA ZOOL, V44, P75; Luskova Vera, 1997, Acta Scientiarum Naturalium Academiae Scientiarum Bohemicae Brno, V31, P1; Mastrorillo S, 1997, FRESHWATER BIOL, V38, P237, DOI 10.1046/j.1365-2427.1997.00209.x; MCQUEEN RJ, 1995, COMPUT ELECTRON AGR, V12, P275, DOI 10.1016/0168-1699(95)98601-9; MELOTTI P, 1992, J APPL ICHTHYOL, V8, P234, DOI 10.1111/j.1439-0426.1992.tb00688.x; Mitchell T, 1997, MACHINE LEARNING; Popovic NT, 2006, FISH PHYSIOL BIOCHEM, V32, P99, DOI 10.1007/s10695-006-0001-x; Quinlan J., 1992, C4 5 PROGRAMS MACHIN; Rehulka J, 2003, DIS AQUAT ORGAN, V56, P185, DOI 10.3354/dao056185; Rehulka J, 2005, AQUAC RES, V36, P22, DOI 10.1111/j.1365-2109.2004.01177.x; SANDNES K, 1988, J FISH BIOL, V32, P129, DOI 10.1111/j.1095-8649.1988.tb05341.x; TOPIC G., 2004, PARF PARALLEL RANDOM; TOPIC G, 2005, P PAR NUM THEOR APPL, P119; Vellas F., 1995, Hydroecologie Appliquee, V6, P257, DOI 10.1051/hydro:1994013; WELLS RMG, 1986, COMP BIOCHEM PHYS A, V84, P565, DOI 10.1016/0300-9629(86)90366-X; Witten I. H., 1999, DATA MINING PRACTICA; WOOD ME, 1990, AM FISHERIES SOC, V89, P301	34	4	4	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	0022-1112		J FISH BIOL	J. Fish Biol.	JUN	2008	72	10					2557	2569		10.1111/j.1095-8649.2008.01865.x		13	Fisheries; Marine & Freshwater Biology	Fisheries; Marine & Freshwater Biology	325YP	WOS:000257625400009	
J	Garcia-Pedrajas, N; Fyfe, C				Garcia-Pedrajas, Nicolas; Fyfe, Colin			Construction of classifier ensembles by means of artificial immune systems	JOURNAL OF HEURISTICS			English	Article						classifier ensembles; artificial immune system; classification; neural networks	NEURAL-NETWORKS; COMBINING CLASSIFIERS; DECISION TREES; ALGORITHMS	This paper presents the application of Artificial Immune Systems to the design of classifier ensembles. Ensembles of classifiers are a very interesting alternative to single classifiers when facing difficult problems. In general, ensembles are able to achieve better performance in terms of learning and generalisation errors. Several papers have shown that the processes of classifier design and combination must be related in order to obtain better ensembles. Artificial Immune Systems are a recent paradigm based on the immune systems of animals. The features of this new paradigm make it very appropriate for the design of systems where many components must cooperate to solve a given task. The design of classifier ensembles can be considered within such a group of systems, as the cooperation of the individual classifiers is able to improve the performance of the overall system. This paper studies the viability of Artificial Immune Systems when dealing with ensemble design. We construct a population of classifiers that is evolved using an Artificial Immune algorithm. From this population of classifiers several different ensembles can be extracted. These ensembles are favourably compared with ensembles obtained using standard methods in 35 real-world classification problems from the UCI Machine Learning Repository.	[Garcia-Pedrajas, Nicolas] Univ Cordoba, Dept Comp & Numer Anal, E-14071 Cordoba, Spain; [Fyfe, Colin] Univ Paisley, Sch Comp, Paisley PA1 2BE, Renfrew, Scotland	Garcia-Pedrajas, N (reprint author), Univ Cordoba, Dept Comp & Numer Anal, Campus Univ Rabanales, E-14071 Cordoba, Spain.	npedrajas@uco.es; colin.fyfe@paisley.ac.uk					Agresti A., 1990, CATEGORICAL DATA ANA; Anderson TW, 1984, WILEY SERIES PROBABI; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Breiman L, 1996, MACH LEARN, V24, P49, DOI 10.1007/BF00117832; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Carter JH, 2000, J AM MED INFORM ASSN, V7, P28; CASTRO P, 2005, P 4 INT C ART IMM SY, P469; DASGUPTA D, 2000, ARTIFICIAL IMMUNE SY; de Castro L.N., 2000, P 6 BRAZ S NEUR NETW, P84; De Castro L.N., 2002, ARTIFICIAL IMMUNE SY; DECASTRO LN, 1991, 0200 TRDCA STAT U CA; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dietterich Thomas G., 2000, P 1 INT WORKSH MULT, P1; Domingo C., 2000, P 13 ANN C COMP LEAR, P180; DRUCKER H, 1999, COMBINING ARTIFICIAL, P51; Dzeroski S, 2004, MACH LEARN, V54, P255, DOI 10.1023/B.MAC.0000015881.36452.6e; Fern A, 2003, MACH LEARN, V53, P71, DOI 10.1023/A:1025619426553; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Garcia-Pedrajas N, 2007, J MACH LEARN RES, V8, P1; Garcia-Pedrajas N, 2005, IEEE T EVOLUT COMPUT, V9, P271, DOI 10.1109/TEVC.2005.844158; Garrett SM, 2005, EVOL COMPUT, V13, P145, DOI 10.1162/1063656054088512; HALL L, 2003, 3 IEEE INT C DAT MIN; Haykin S., 1999, NEURAL NETWORKS COMP; Hettich S., 1998, UCI REPOSITORY MACHI; HILLIS WD, 1991, ARTIF LIFE, V2, P313; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; JERNE NK, 1974, ANN INST PASTEUR IMM, VC125, P373; Jolliffe IT, 1986, PRINCIPAL COMPONENTS; Juille H., 1999, THESIS BRANDEIS U; Kleinberg EM, 2000, IEEE T PATTERN ANAL, V22, P473, DOI 10.1109/34.857004; Kuncheva L.I., 2001, PATTERN RECOGN, P427, DOI 10.1142/9789812386533_0015; LeCun Y., 1998, Neural networks: tricks of the trade; LIU Y, 2001, P 2001 IEEE C EV COM, P384; Liu Y, 2000, IEEE T EVOLUT COMPUT, V4, P380; Margineantu D, 1997, P 14 INT C MACH LEAR, P211; Melville P., 2005, Information Fusion, V6, DOI 10.1016/j.inffus.2004.04.001; Merz CJ, 1999, MACH LEARN, V36, P33, DOI 10.1023/A:1007559205422; Michalewicz Z, 1994, GENETIC ALGORITHMS D; MORIARTY DE, 1997, A197257 U TEX AUST; MUNRO R, 2003, P 7 C NAT LANG LEARN; Nunes de Castro L., 1999, 0199 TRDCA; Opitz D., 1999, J ARTIFICIAL INTELLI, P169; Paredis Jan, 1996, Artificial Life, V2, P355, DOI 10.1162/artl.1995.2.4.355; Perrone M.P., 1993, NEURAL NETWORKS SPEE, P126; Rosin CD, 1997, EVOL COMPUT, V5, P1, DOI 10.1162/evco.1997.5.1.1; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1, P318; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Sharkey A. J. C., 1996, Connection Science, V8, DOI 10.1080/095400996116785; Skurichina M., 2001, P 2 INT WORKSH MULT, P1; TIMMIS J, 2000, P GEN EV COMP C WORK, P40; Ting KM, 2003, COMPUT INTELL-US, V19, P186, DOI 10.1111/1467-8640.00219; Todorovski L, 2003, MACH LEARN, V50, P223, DOI 10.1023/A:1021709817809; Vapnik V.N., 1999, NATURE STAT LEARNING; Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849; Yao X, 1997, IEEE T NEURAL NETWOR, V8, P694, DOI 10.1109/72.572107; Yao X, 1998, IEEE T SYST MAN CY B, V28, P417, DOI 10.1109/3477.678637; ZENOBI G, 2001, LECT NOTES COMPUTER, V2167, P576; ZHANG X, 2005, P EVOWORKSHOPS, P325; Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X	63	6	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1381-1231		J HEURISTICS	J. Heuristics	JUN	2008	14	3					285	310		10.1007/s10732-007-9036-0		26	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	287GF	WOS:000254904500004	
J	Penas, A; Rodrigo, A; Sama, V; Verdejo, F				Penas, Anselmo; Rodrigo, Alvaro; Sama, Valentin; Verdejo, Felisa			Testing the reasoning for question answering validation	JOURNAL OF LOGIC AND COMPUTATION			English	Article						textual entailment; test collections; question answering; answer validation; evaluation		Question answering (QA) is a task that deserves more collaboration between natural language processing (NLP) and knowledge representation (KR) communities, not only to introduce reasoning when looking for answers or making use of answer type taxonomies and encyclopaedic knowledge, but also, as discussed here, for answer validation (AV), that is to say, to decide whether the responses of a QA system are correct or not. This was one of the motivations for the first Answer Validation Exercise at CLEF 2006 (AVE 2006). The starting point for the AVE 2006 was the reformulation of the answer validation as a recognizing textual entailment (RTE) problem, under the assumption that a hypothesis can be automatically generated instantiating a hypothesis pattern with a QA system answer. The test collections that we developed in seven different languages at AVE 2006 are specially oriented to the development and evaluation of answer validation systems. We show in this article the methodology followed for developing these collections taking advantage of the human assessments already made in the evaluation of QA systems. We also propose an evaluation framework for AV linked to a QA evaluation track. We quantify and discuss the source of errors introduced by the reformulation of the answer validation problem in terms of textual entailment (around 2, in the range of inter-annotator disagreement). We also show the evaluation results of the first answer validation exercise at CLEF 2006 where 11 groups have participated with 38 runs in seven different languages. The most extensively used techniques were Machine Learning and overlapping measures, but systems with broader knowledge resources and richer representation formalisms obtained the best results.	[Penas, Anselmo; Rodrigo, Alvaro; Sama, Valentin; Verdejo, Felisa] Univ Nacl Educ Distancia, Depto Lenguajes & Sistemas Informat, Madrid 28040, Spain	Penas, A (reprint author), Univ Nacl Educ Distancia, Depto Lenguajes & Sistemas Informat, Juan Rosal 16, Madrid 28040, Spain.	anselmo@lsi.uned.es; alvarory@lsi.uned.es; vsama@lsi.uned.es; felisa@lsi.uned.es					Barzilay R., 2003, P HLT NAACL, P16; BURGER J, 2005, P ACL WORKSH EMP MOD, P49, DOI 10.3115/1631862.1631871; Dagan I., 2005, P PASCAL CHALL WORKS, P1; Dagan Ido, 2006, P 2 PASCAL CHALL WOR; DOLAN B, 2004, P COLING 2004 GEN SW; HARABAGIU S, 2006, P 21 INT C COMP LING, P905, DOI 10.3115/1220175.1220289; HARABAGIU S, 2003, P 12 TEXT RETR C TRE, P375; Herrera J, 2005, LECT NOTES COMPUT SC, V3491, P581; Li XM, 2002, POWERCON 2002: INTERNATIONAL CONFERENCE ON POWER SYSTEM TECHNOLOGY, VOLS 1-4, PROCEEDINGS, P556, DOI 10.1109/ICPST.2002.1053604; Lin D., 2001, P ACM SIGKDD C KNOWL, P323, DOI 10.1145/502512.502559; MAGNINI B, 2005, LECT NOTES COMPUTER, V3491, P581; MAGNINI B, 2004, LECT NOTES COMPUTER, V3237, P471; Moldovan D., 2003, P HLT NAACL 2003 HUM, P87; NARDI A, 2006, WORKING NOTES CLEF 2; Penas A, 2004, LECT NOTES COMPUT SC, V2945, P472; SHINYAMA Y, 2002, P HUM LANG TECHN C S; Vallin A, 2006, LECT NOTES COMPUT SC, V4022, P307	17	4	4	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0955-792X		J LOGIC COMPUT	J. Logic Comput.	JUN	2008	18	3					459	474		10.1093/logcom/exm072		16	Computer Science, Theory & Methods; Logic	Computer Science; Science & Technology - Other Topics	305JA	WOS:000256173100008	
J	Jung, H; Allen, J; Galescu, L; Chambers, N; Swift, M; Taysom, W				Jung, Hyuckchul; Allen, James; Galescu, Lucian; Chambers, Nathanael; Swift, Mary; Taysom, William			Utilizing natural language for one-shot task learning	JOURNAL OF LOGIC AND COMPUTATION			English	Article								Learning tasks from a single demonstration presents a significant challenge because the observed sequence is specific to the current situation and is inherently an incomplete representation of the procedure. Observation-based machine-learning techniques are not effective without multiple examples. However, when a demonstration is accompanied by natural language explanation, the language provides a rich source of information about the relationships between the steps in the procedure and the decision-making processes that led to them. In this article, we present a one-shot task learning system built on TRIPS, a dialogue-based collaborative problem solving system, and show how natural language understanding can be used for effective one-shot task learning.	[Jung, Hyuckchul; Allen, James; Galescu, Lucian; Taysom, William] Florida Inst Human & Machine Cognit, Pensacola, FL 32502 USA; [Chambers, Nathanael] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA; [Swift, Mary] Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA	Jung, H (reprint author), Florida Inst Human & Machine Cognit, Pensacola, FL 32502 USA.	hjung@ihmc.us; jallen@ihmc.us; lgalescu@ihmc.us; natec@stanford.edu; swift@cs.rochester.edu; wtaysom@ihmc.us					ALLEN J, 2002, P INT JOINT C AUT AG; ANGROS R, 2002, P INT JOINT C AUT AG; BLYTHE J, 2005, P INT C INT US INT; CHAMBERS N, 2006, P NAT C ART INT; COPESTAKE, 2000, P 2 INT WORKSH LANG; DZIKOVSKA M, IN PRESS J LOGIC COM; FERGUSON G, 1998, P NAT C ART INT; GARLAND KR, 2001, P INT C KNOWL CAPT; GIL Y, 2000, P AAAI FALL S; LAU T, 2004, P INT C INT US INT; LAU T, 1999, P INT C INT US INT; LEE F, 1997, P ANN C COGN SCI SOC; LENT M, 2001, P INT C KNOWL CAPT; MAXWELL J, 1996, P 1 LEX FUNCT GRAMM; NICOLESCU M, 2001, P IEEE RSJ INT C INT; RAYNER M, 2002, P 7 INT C SPOK LANG; Seneff S., 1992, Computational Linguistics, V18; YANG Q, 2005, P INT C AUT PLANN SC	18	0	0	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0955-792X		J LOGIC COMPUT	J. Logic Comput.	JUN	2008	18	3					475	493		10.1093/logcom/exm071		19	Computer Science, Theory & Methods; Logic	Computer Science; Science & Technology - Other Topics	305JA	WOS:000256173100009	
J	Igel, C; Heidrich-Meisner, V; Glasmachers, T				Igel, Christian; Heidrich-Meisner, Verena; Glasmachers, Tobias			Shark	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						machine learning software; neural networks; kernel-methods; evolutionary algorithms; optimization; multi-objective-optimization	COVARIANCE-MATRIX ADAPTATION; SUPPORT VECTOR MACHINES; WORKING SET SELECTION; OPTIMIZATION; KERNELS	SHARK is an object-oriented library for the design of adaptive systems. It comprises methods for single-and multi-objective optimization (e. g., evolutionary and gradient-based algorithms) as well as kernel-based methods, neural networks, and other machine learning techniques.	[Igel, Christian; Heidrich-Meisner, Verena; Glasmachers, Tobias] Ruhr Univ Bochum, Inst Neuroinformat, D-44780 Bochum, Germany	Igel, C (reprint author), Ruhr Univ Bochum, Inst Neuroinformat, D-44780 Bochum, Germany.	christian.igel@neuroinformatik.rub.de; verena.heidrich-meisner@neuroinformatik.rub.de; tobias.glasmachers@neuroinformatik.rub.de	Igel, Christian/B-4091-2009		Honda Research Institute Europe	The authors of this paper comprise the team responsible for a major revision and the maintenance of the SHARK library at the time of writing the article. The SHARK project was started by M. Kreutz, who wrote the basic components such as LinAlg, Array, and Rng as well as the EALib. Then B. Send-hoff joined the project, which was fused with C. Igel's ReClaM library. Afterwards, many people contributed to the package, in particular (in alphabetic order) R. Alberts, T. Bucher, A. W. Diet-rich, who invented the name Shark, T. Glasmachers, who extended the ReClaM library, M. Husken, T. Okabe, who wrote the MOO-EALib, S. Roth, P. Stagge, T. Suttorp, M. Toussaint, and T. VoB. The SHARK project is supported by the Honda Research Institute Europe.	Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Fan RE, 2005, J MACH LEARN RES, V6, P1889; Glasmachers T, 2006, J MACH LEARN RES, V7, P1437; Glasmachers T, 2005, NEURAL COMPUT, V17, P2099, DOI 10.1162/0899766054615635; Hansen N, 2003, EVOL COMPUT, V11, P1, DOI 10.1162/106365603321828970; Igel C, 2003, NEUROCOMPUTING, V50, P105, DOI 10.1016/S0925-2312(01)00700-7; Igel C, 2007, EVOL COMPUT, V15, P1, DOI 10.1162/evco.2007.15.1.1; Igel C, 2007, IEEE ACM T COMPUT BI, V4, P216, DOI 10.1109/tcbb.2007.070208; Romdhani S, 2004, P ROY SOC LOND A MAT, V460, P3283, DOI 10.1098/rspa.2004.1333; Suttorp T, 2007, LECT NOTES COMPUT SC, V4668, P139	10	35	35	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	JUN	2008	9						993	996				4	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	340LE	WOS:000258646300001	
J	Sabato, S; Shalev-Shwartz, S				Sabato, Sivan; Shalev-Shwartz, Shai			Ranking categorical features using generalization properties	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article; Proceedings Paper	20th Annual Conference on Learning Theory	JUN 13-15, 2007	San Diego, CA	Google, Machine Learning, IBM		feature ranking; categorical features; generalization bounds; Gini index; decision trees	BOUNDS	Feature ranking is a fundamental machine learning task with various applications, including feature selection and decision tree learning. We describe and analyze a new feature ranking method that supports categorical features with a large number of possible values. We show that existing ranking criteria rank a feature according to the training error of a predictor based on the feature. This approach can fail when ranking categorical features with many values. We propose the Ginger ranking criterion, that estimates the generalization error of the predictor associated with the Gini index. We show that for almost all training sets, the Ginger criterion produces an accurate estimation of the true generalization error, regardless of the number of values in a categorical feature. We also address the question of finding the optimal predictor that is based on a single categorical feature. It is shown that the predictor associated with the misclassification error criterion has the minimal expected generalization error. We bound the bias of this predictor with respect to the generalization error of the Bayes optimal predictor, and analyze its concentration properties. We demonstrate the efficiency of our approach for feature selection and for learning decision trees in a series of experiments with synthetic and natural data sets.	[Sabato, Sivan] IBM Haifa Res Lab, IL-31905 Haifa, Israel; [Shalev-Shwartz, Shai] Toyota Technol Inst Chicago, Chicago, IL 60637 USA	Sabato, S (reprint author), IBM Haifa Res Lab, Haifa Univ Campus, IL-31905 Haifa, Israel.	sivans@il.ibm.com; shai@tti-c.org	Sabato, Sivan/C-3209-2011				Antos A, 1999, IEEE T PATTERN ANAL, V21, P643, DOI 10.1109/34.777375; Antos A, 2001, RANDOM STRUCT ALGOR, V19, P163, DOI 10.1002/rsa.10019; Breiman L, 1984, CLASSIFICATION REGRE; DEMANTARAS RL, 1991, MACH LEARN, V6, P81, DOI 10.1023/A:1022694001379; Drukh E, 2005, J MACH LEARN RES, V6, P1231; GOOD IJ, 1953, BIOMETRIKA, V40, P237, DOI 10.2307/2333344; Hastie T, 2001, ELEMENTS STAT LEARNI; Kearns M., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/237814.237994; Kutin S., 2002, TR200204 U CHIC; McAllester D, 2000, P 13 ANN C COMP LEAR, P1; MCDIARMID C, 1989, LOND MATH S, V141, P148; Mingers J., 1989, Machine Learning, V3, DOI 10.1007/BF00116837; Mitchell T, 1997, MACHINE LEARNING; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Torkkola K., 2006, FEATURE EXTRACTION F; Wasserman L., 2004, ALL STAT CONCISE COU	16	2	2	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	JUN	2008	9						1083	1114				32	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	340LE	WOS:000258646300005	
J	Subrahmanya, N; Shin, YC				Subrahmanya, Niranjan; Shin, Yung C.			Automated sensor selection and fusion for monitoring and diagnostics of plunge grinding	JOURNAL OF MANUFACTURING SCIENCE AND ENGINEERING-TRANSACTIONS OF THE ASME			English	Article						grinding; process monitoring; machine learning; feature selection; sensor fusion; leave-one-out error; least squares support vector machine	ACOUSTIC-EMISSION; CLASSIFICATION; CHATTER; WHEEL; WEAR; STATE; BURN	This paper deals with the development of an online monitoring system based on feature-level sensor fusion and its application to OD plunge grinding. Different sensors are used to measure acoustic emission, spindle power, and workpiece vibration signals, which are used to monitor three of the most common faults in grinding-workpiece burn, chatter, and wheel wear. Although a number of methods have been reported in recent literature for monitoring these faults, they have not found widespread application in industry as no single method or feature has been shown to be successful for all setups and for all wheel-workpiece combinations. This paper proposes a systematic approach, which allows the development and deployment of process-monitoring systems via automated sensor and feature selection combined with parameter-free model training, both of which are especially crucial for implementation in industry. The proposed algorithm makes use of "sparsity-promoting" penalty terms to encourage sensor and feature selection while the "hyperparameters" of the algorithm are tuned using an approximation of the leave-one-out error. Experimental results obtained for monitoring burn, chatter, and wheel wear from a plunge grinding test bed show the effectiveness of the proposed method.	[Subrahmanya, Niranjan; Shin, Yung C.] Purdue Univ, W Lafayette, IN 47907 USA	Subrahmanya, N (reprint author), Purdue Univ, W Lafayette, IN 47907 USA.		Shin, Yung/E-4626-2011				ALLEN DM, 1974, TECHNOMETRICS, V16, P125, DOI 10.2307/1267500; Bo LF, 2006, NEURAL COMPUT, V18, P961, DOI 10.1162/089976606775774642; CAWLEY GC, 2006, P INT JOINT C NEUR N, P1661, DOI DOI 10.1109/IJCNN.2006.246634; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; DORNFELD D, 1984, J ENG IND-T ASME, V106, P28; Fan KC, 2002, INT J ADV MANUF TECH, V19, P14, DOI 10.1007/PL00003964; Furutani K, 2002, INT J MACH TOOL MANU, V42, P1447, DOI 10.1016/S0890-6955(02)00073-1; Gradisek J, 2003, INT J MACH TOOL MANU, V43, P1397, DOI 10.1016/S0890-6955(03)00184-6; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hall MA, 2003, IEEE T KNOWL DATA EN, V15, P1437, DOI 10.1109/TKDE.2003.1245283; Hwang TW, 2000, ULTRASONICS, V38, P614, DOI 10.1016/S0041-624X(99)00064-5; Inasaki I, 2001, CIRP ANN-MANUF TECHN, V50, P515, DOI 10.1016/S0007-8506(07)62992-8; Inasaki I, 1999, INT J ADV MANUF TECH, V15, P730, DOI 10.1007/s001700050125; Inasaki I, 1998, ULTRASONICS, V36, P273, DOI 10.1016/S0041-624X(97)00052-8; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Krishnapuram B, 2004, IEEE T PATTERN ANAL, V26, P1105, DOI 10.1109/TPAMI.2004.55; Kwak JS, 2004, INT J ADV MANUF TECH, V23, P436, DOI 10.1007/s00170-003-1899-0; Li HQ, 2007, INT J MACH TOOL MANU, V47, P1563, DOI 10.1016/j.ijmachtools.2006.11.009; Liang SY, 2004, J MANUF SCI E-T ASME, V126, P297, DOI 10.1115/1.1707035; Liu Q, 2005, INT J MACH TOOL MANU, V45, P811, DOI 10.1016/j.ijmachtools.2004.11.002; Malkin S., 1989, GRINDING TECHNOLOGY; Neal R. M., 1996, BAYESIAN LEARNING NE; Neumann J, 2005, MACH LEARN, V61, P129, DOI 10.1007/s10994-005-1505-9; Rifkin R, 2004, J MACH LEARN RES, V5, P101; Scholkopf B., 2002, LEARNING KERNELS; Shi Z, 2006, J MANUF SCI E-T ASME, V128, P110, DOI 10.1115/1.2122987; SUBRAHMANYA N, 2007, IEEE T PATTERN UNPUB; SUBRAHMANYA N, 2007, T N AM MANUF RES I S, V35, P489; Sun J, 2004, INT J PROD RES, V42, P901, DOI 10.1080/00207540310001626652; Sun J, 2004, INT J MACH TOOL MANU, V44, P1179, DOI 10.1016/j.ijmachtools.2004.04.003; Suykens J.A.K., 2002, LEAST SQUARES SUPPOR; Tonshoff HK, 2002, CIRP ANN-MANUF TECHN, V51, P551, DOI 10.1016/S0007-8506(07)61700-4; Tonshoff HK, 1999, INT J ADV MANUF TECH, V15, P694, DOI 10.1007/s001700050121; Vapnik VN, 1998, STAT LEARNING THEORY; Wang Z, 2001, INT J MACH TOOL MANU, V41, P283, DOI 10.1016/S0890-6955(00)00057-2; Williams CKI, 1998, IEEE T PATTERN ANAL, V20, P1342, DOI 10.1109/34.735807	36	3	3	ASME-AMER SOC MECHANICAL ENG	NEW YORK	THREE PARK AVE, NEW YORK, NY 10016-5990 USA	1087-1357		J MANUF SCI E-T ASME	J. Manuf. Sci. Eng.-Trans. ASME	JUN	2008	130	3							031014	10.1115/1.2927439		11	Engineering, Manufacturing; Engineering, Mechanical	Engineering	324RK	WOS:000257535500014	
J	Inglis, A; Cruz, L; Roe, DL; Stanley, HE; Rosene, DL; Urbanc, B				Inglis, A.; Cruz, L.; Roe, D. L.; Stanley, H. E.; Rosene, D. L.; Urbanc, B.			Automated identification of neurons and their locations	JOURNAL OF MICROSCOPY			English	Article						active contours; artificial neural network; neuron identification; Nissl-stain; training	CONFOCAL MICROSCOPE IMAGES; SPATIAL-DISTRIBUTION; ACTIVE CONTOURS; TISSUE-SECTIONS; ANALYSIS SYSTEM; CELL-NUCLEI; SEGMENTATION; BRAIN; STEREOLOGY; CORTEX	Individual locations of many neuronal cell bodies (> 10(4)) are needed to enable statistically significant measurements of spatial organization within the brain such as nearest-neighbour and microcolumnarity measurements. In this paper, we introduce an Automated Neuron Recognition Algorithm (ANRA) which obtains the (x, y) location of individual neurons within digitized images of Nissl-stained, 30 mu m thick, frozen sections of the cerebral cortex of the Rhesus monkey. Identification of neurons within such Nissl-stained sections is inherently difficult due to the variability in neuron staining, the overlap of neurons, the presence of partial or damaged neurons at tissue surfaces, and the presence of non-neuron objects, such as glial cells, blood vessels, and random artefacts. To overcome these challenges and identify neurons, ANRA applies a combination of image segmentation and machine learning. The steps involve active contour segmentation to find outlines of potential neuron cell bodies followed by artificial neural network training using the segmentation properties (size, optical density, gyration, etc.) to distinguish between neuron and non-neuron segmentations. ANRA positively identifies 86 +/- 5% neurons with 15 +/- 8% error (mean +/- SD) on a wide range of Nissl-stained images, whereas semi-automatic methods obtain 80 +/- 7%/17 +/- 12%. A further advantage of ANRA is that it affords an unlimited increase in speed from semi-automatic methods, and is computationally efficient, with the ability to recognize similar to 100 neurons per minute using a standard personal computer. ANRA is amenable to analysis of huge photo-montages of Nissl-stained tissue, thereby opening the door to fast, efficient and quantitative analysis of vast stores of archival material that exist in laboratories and research collections around the world.	[Inglis, A.; Cruz, L.; Stanley, H. E.; Urbanc, B.] Boston Univ, Ctr Polymer Studies, Dept Phys, Boston, MA 02215 USA; [Roe, D. L.; Rosene, D. L.] Boston Univ, Sch Med, Dept Anat & Neurobiol, Boston, MA 02118 USA; [Rosene, D. L.] Emory Univ, Yerkes Natl Primate Res Ctr, Atlanta, GA 30322 USA	Inglis, A (reprint author), Boston Univ, Ctr Polymer Studies, Dept Phys, Boston, MA 02215 USA.	ainglis@physics.bu.edu	Urbanc, Brigita/G-5839-2011; Cruz Cruz, Luis/B-2685-2013				AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Asare E, 1996, AM J PATHOL, V148, P31; Benali A, 2003, J NEUROSCI METH, V125, P33, DOI 10.1016/S0165-0270(03)00023-2; Blake A., 1998, ACTIVE CONTOURS; Buldyrev SV, 2000, P NATL ACAD SCI USA, V97, P5039, DOI 10.1073/pnas.060009897; Buxhoeveden D, 1996, ANAT EMBRYOL, V194, P23; CASANOVA MF, 2006, DEV NEUROSCI, V29, P193; Costa LD, 2006, APPL PHYS LETT, V89, DOI 10.1063/1.2358325; Cremers D, 2000, LECT NOTES COMPUT SC, V1888, P164; Cruz L, 2004, P NATL ACAD SCI USA, V101, P15846, DOI 10.1073/pnas.0407002101; Cruz L, 2005, J NEUROSCI METH, V141, P321, DOI 10.1016/j.jneumeth.2004.09.005; Duda R. O., 2001, PATTERN CLASSIFICATI; Duyckaerts C, 2000, J CHEM NEUROANAT, V20, P83, DOI 10.1016/S0891-0618(00)00064-8; Hof PR, 2003, BIOL PSYCHIAT, V53, P1075, DOI 10.1016/S0006-3223(03)00237-3; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; JAVI B, 2002, IMAGE RECOGNITION CL; John G. H., 1995, P 11 C UNC ART INT, P338; Krasnoperov RA, 2004, J MICROSC-OXFORD, V216, P156, DOI 10.1111/j.0022-2720.2004.01407.x; Lin G, 2005, CYTOM PART A, V63A, P20, DOI 10.1002/cyto.a.20099; Lin G, 2007, CYTOM PART A, V71A, P724, DOI 10.1002/cyto.a.20430; Long X, 2005, IEEE T INF TECHNOL B, V9, P407, DOI 10.1109/TITB.2005.847502; Long X, 2006, COMPUT BIOL MED, V36, P339, DOI 10.1016/j.compbiomed.2004.12.002; MAYHEW TM, 1992, J NEUROCYTOL, V21, P313, DOI 10.1007/BF01191700; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; Nattkemper TW, 2001, IEEE T INF TECHNOL B, V5, P138, DOI 10.1109/4233.924804; de Solorzano CO, 1999, J MICROSC-OXFORD, V193, P212; Peng S, 2003, P NATL ACAD SCI USA, V100, P3847, DOI 10.1073/pnas.0230490100; Peters M, 1998, BRAIN COGNITION, V37, P254, DOI 10.1006/brcg.1998.0983; Platt J., 1998, ADV KERNEL METHODS S; Quinlan R, 1993, C4 5 PROGRAMS MACHIN; Ray N, 2002, IEEE T MED IMAGING, V21, P1222, DOI 10.1109/TMI.2002.806291; Schmitz C, 2002, CEREB CORTEX, V12, P954, DOI 10.1093/cercor/12.9.954; Schmitz C, 2005, NEUROSCIENCE, V130, P813, DOI 10.1016/j.neuroscience.2004.08.050; Sjostrom PJ, 1999, CYTOMETRY, V36, P18; SLATER D, 1996, IEEE WORKSH APPL COM; Todtenkopf MS, 2005, SCHIZOPHR RES, V73, P79, DOI 10.1016/j.schres.2004.08.018; TSCHEREPANOW M, 2006, P 18 INT C PATT REC; Urbanc B, 2002, P NATL ACAD SCI USA, V99, P13990, DOI 10.1073/pnas.222433299; Witten I. H., 2005, DATA MINING PRACTICA; Zimmer C, 2002, IEEE T MED IMAGING, V21, P1212, DOI [10.1109/TMI.2002.806292, 10.1109/TMI.2002.0806292]	40	3	3	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0022-2720		J MICROSC-OXFORD	J. Microsc..	JUN	2008	230	3					339	352		10.1111/j.1365-2818.2008.01992.x		14	Microscopy	Microscopy	305ET	WOS:000256161300002	
J	Han, LY; Ma, XH; Lin, HH; Jia, J; Zhu, F; Xue, Y; Li, ZR; Cao, ZW; Ji, ZL; Chen, YZ				Han, L. Y.; Ma, X. H.; Lin, H. H.; Jia, J.; Zhu, F.; Xue, Y.; Li, Z. R.; Cao, Z. W.; Ji, Z. L.; Chen, Y. Z.			A support vector machines approach for virtual screening of active compounds of single and multiple mechanisms from large libraries at an improved hit-rate and enrichment factor	JOURNAL OF MOLECULAR GRAPHICS & MODELLING			English	Article						computer aided dug design; drug discovery high-throughput screening; lead discovery; machine learning method; virtual screening	STATISTICAL LEARNING-METHODS; HIGH-THROUGHPUT DOCKING; BINARY KERNEL DISCRIMINATION; DRUG DISCOVERY; IN-SILICO; MOLECULAR DESCRIPTORS; CHEMICAL SPACE; LEAD DISCOVERY; NEURAL-NETWORK; RECEPTOR ANTAGONISTS	Support vector machines (SVM) and other machine-learning (ML) methods have been explored as ligand-based virtual screening (VS) tools for facilitating lead discovery. While exhibiting good hit selection performance, in screening large compound libraries, these methods tend to produce lower hit-rate than those of the best performing VS tools, partly because their training-sets contain limited spectrum of inactive compounds. We tested whether the performance of SVM can be improved by using training-sets of diverse inactive compounds. In retrospective database screening of active compounds of single mechanism (HIV protease inhibitors, DHFR inhibitors, dopamine antagonists) and multiple mechanisms (CNS active agents) from large libraries of 2.986 million compounds, the yields, hit-rates, and enrichment factors of our SVM models are 52.4-78.0%, 4.7-73.8%, and 214-10,543, respectively, compared to those of 62-95%, 0.65-35%, and 20-1200 by structure-based VS and 55-81%, 0.2-0.7%, and 110-795 by other ligand-based VS tools in screening libraries of >= 1 million compounds. The hit-rates are comparable and the enrichment factors are substantially better than the best results of other VS tools. 24.3-87.6% of the predicted hits are outside the known hit families. SVM appears to be potentially useful for facilitating lead discovery in VS of large compound libraries. (C) 2007 Elsevier Inc. All rights reserved.	[Han, L. Y.; Ma, X. H.; Lin, H. H.; Jia, J.; Zhu, F.; Chen, Y. Z.] Natl Univ Singapore, Dept Pharm, Bioinformat & Drug Design Grp, Singapore 117543, Singapore; [Cao, Z. W.; Chen, Y. Z.] Shanghai Ctr Bioinformat Technol, Shanghai 201203, Peoples R China; [Xue, Y.; Li, Z. R.] Sichuan Univ, Coll Chem, Chengdu 610064, Peoples R China; [Ji, Z. L.] Xiamen Univ, Sch Life Sci, Bioinformat Res Grp, Xiamen 361005, Fujian Province, Peoples R China	Chen, YZ (reprint author), Natl Univ Singapore, Dept Pharm, Bioinformat & Drug Design Grp, Blk S16,Level 8,3 Sci Dr 2, Singapore 117543, Singapore.	phacyz@nus.edu.sg	Han, Lianyi/D-1499-2009; Zhu, Feng/F-1489-2011				Adler CH, 2000, NEUROLOGY, V55, pS9; Alvarez JC, 2004, CURR OPIN CHEM BIOL, V8, P365, DOI 10.1016/j.cbpa.2004.05.001; Bocker A, 2006, J CHEM INF MODEL, V46, P2220, DOI 10.1021/ci050541d; Bostrom J, 2003, J CHEM INF COMP SCI, V43, P1020, DOI 10.1021/ci034004+; Byvatov E, 2003, J CHEM INF COMP SCI, V43, P1882, DOI 10.1021/ci0341161; Cai CZ, 2003, NUCLEIC ACIDS RES, V31, P3692, DOI 10.1093/nar/gkg600; CHEN B, 2007, J COMPUT AID MOL DES; Chen BN, 2006, J CHEM INF MODEL, V46, P478, DOI 10.1021/ci0505426; Cui J, 2007, MOL IMMUNOL, V44, P866, DOI 10.1016/j.molimm.2006.04.001; Cummings MD, 2005, J MED CHEM, V48, P962, DOI 10.1021/jm049798d; Davies JW, 2006, CURR OPIN CHEM BIOL, V10, P343, DOI 10.1016/j.cbpa.2006.06.022; DEMOL P, 1989, EUR J PEDIATR, V148, P489, DOI 10.1007/BF00441540; Doman TN, 2002, J MED CHEM, V45, P2213, DOI 10.1021/jm010548w; Doniger S, 2002, J COMPUT BIOL, V9, P849, DOI 10.1089/10665270260518317; Enyedy IJ, 2001, J MED CHEM, V44, P4313, DOI 10.1021/jm010016f; Evers A, 2005, J MED CHEM, V48, P1088, DOI 10.1021/jm0491804; Fang H, 2001, CHEM RES TOXICOL, V14, P280, DOI 10.1021/tx000208y; Franke L, 2005, J MED CHEM, V48, P6997, DOI 10.1021/jm050619h; Ghosh S, 2006, CURR OPIN CHEM BIOL, V10, P194, DOI 10.1016/j.cbpa.2006.04.002; Glick M, 2006, J CHEM INF MODEL, V46, P193, DOI 10.1021/ci050374h; GROVER JI, 2000, PHARM SCI TECHNOL TO, V3, P50; Hain TC, 2003, CNS DRUGS, V17, P85, DOI 10.2165/00023210-200317020-00002; HAN LY, DRUG DISCOV IN PRESS; Han LY, 2004, NUCLEIC ACIDS RES, V32, P6437, DOI 10.1093/nar/gkh984; Harper G, 2001, J CHEM INF COMP SCI, V41, P1295, DOI 10.1021/ci000397q; He LN, 2003, CHEM RES TOXICOL, V16, P1567, DOI 10.1021/tx030032a; Hert J, 2006, J CHEM INF MODEL, V46, P462, DOI 10.1021/ci050348j; Hu JY, 2003, WATER RES, V37, P1213, DOI 10.1016/S0043-1354(02)00378-0; Jacobs MN, 2004, TOXICOLOGY, V205, P43, DOI 10.1016/j.tox.2004.06.036; Jansen JM, 2004, CURR OPIN CHEM BIOL, V8, P359, DOI 10.1016/j.cbpa.2004.06.002; Jorissen RN, 2005, J CHEM INF MODEL, V45, P549, DOI 10.1021/ci049641u; Koch MA, 2005, P NATL ACAD SCI USA, V102, P17272, DOI 10.1073/pnas.0503647102; Lengauer T, 2004, DRUG DISCOV TODAY, V9, P27, DOI 10.1016/S1359-6446(04)02939-3; Lepp Z, 2006, J CHEM INF MODEL, V46, P158, DOI 10.1021/ci05030ly; Li H, 2005, CHEM RES TOXICOL, V18, P1071, DOI 10.1021/tx049652h; Li H, 2005, J CHEM INF MODEL, V45, P1376, DOI 10.1021/ci050135u; Li H., 2006, DRUG DEVELOP RES, V66, P245; Li H, 2006, J MOL GRAPH MODEL, V25, P313, DOI 10.1016/j.jmgm.2006.01.007; Li H, 2007, J PHARM SCI-US, V96, P2838, DOI 10.1002/jps.20985; Lin HH, 2006, PROTEINS, V62, P218, DOI 10.1002/prot.20605; Linares GEG, 2006, CURR MED CHEM, V13, P335, DOI 10.2174/092986706775476043; Lipinski C, 2004, NATURE, V432, P855, DOI 10.1038/nature03193; Lipinski CA, 2001, ADV DRUG DELIVER REV, V46, P3, DOI 10.1016/S0169-409X(00)00129-0; Lorber DM, 2005, CURR TOP MED CHEM, V5, P739, DOI 10.2174/1568026054637683; MATTHEW WB, 2003, QSAR COMBINATORIAL S, V22, P533; McGuire JJ, 2003, CURR PHARM DESIGN, V9, P2593, DOI 10.2174/1381612033453712; Mozziconacci JC, 2005, J MED CHEM, V48, P1055, DOI 10.1021/jm049332v; Oprea TI, 2004, CURR OPIN CHEM BIOL, V8, P349, DOI 10.1016/j.cbpa.2004.06.008; Oprea TI, 2001, J COMB CHEM, V3, P157, DOI 10.1021/cc0000388; Perez JJ, 2005, CHEM SOC REV, V34, P143, DOI 10.1039/b209064n; Perola E, 2006, PROTEINS, V64, P422, DOI 10.1002/prot.21002; Pirard B, 2005, J CHEM INF MODEL, V45, P477, DOI 10.1021/ci0400011; Potter T, 1998, J MED CHEM, V41, P478, DOI 10.1021/jm9700878; Rang HP, 2001, PHARMACOLOGY; Rella M, 2006, J CHEM INF MODEL, V46, P708, DOI 10.1021/ci0503614; REYMOND TFA, 2007, J CHEM INF MODE 0130; RUCKER G, 1993, J CHEM INF COMP SCI, V33, P683; Schapira M, 2003, P NATL ACAD SCI USA, V100, P7354, DOI 10.1073/pnas.1131854100; Schuster D, 2006, J MED CHEM, V49, P3454, DOI 10.1021/jm0600794; Serretti A, 2004, CURR MED CHEM, V11, P343, DOI 10.2174/0929867043456043; Shoichet BK, 2002, CURR OPIN CHEM BIOL, V6, P439, DOI 10.1016/S1367-5931(02)00339-3; Shoichet BK, 2004, NATURE, V432, P862, DOI 10.1038/nature03197; Snyder RD, 2004, ENVIRON MOL MUTAGEN, V43, P143, DOI 10.1002/em.20013; Spaltenstein A, 2005, CURR TOP MED CHEM, V5, P1589, DOI 10.2174/156802605775009694; Steindl T, 2005, J CHEM INF MODEL, V45, P716, DOI 10.1021/ci049638; Stiefl N, 2006, J CHEM INF MODEL, V46, P587, DOI 10.1021/ci050324c; Sutherland JJ, 2003, J CHEM INF COMP SCI, V43, P1906, DOI 10.1021/ci034143r; Then RL, 2004, J CHEMOTHERAPY, V16, P3; Tong WD, 2004, ENVIRON HEALTH PERSP, V112, P1249, DOI 10.1289/txg.7125; Ung CY, 2007, MOL PHARMACOL, V71, P158, DOI 10.1124/mol.106.027623; van de Waterbeemd H, 2003, NAT REV DRUG DISCOV, V2, P192, DOI 10.1038/nrd1032; Vangrevelinghe E, 2003, J MED CHEM, V46, P2656, DOI 10.1021/jm030827e; Vidal D, 2006, J CHEM INF MODEL, V46, P836, DOI [10.1021/ci050458q, 10.1021/ic050458q]; Whittle M, 2006, J CHEM INF MODEL, V46, P2206, DOI 10.1021/ci0496144; Willett P, 1998, J CHEM INF COMP SCI, V38, P983, DOI 10.1021/ci9800211; Willett P, 2006, DRUG DISCOV TODAY, V11, P1046, DOI 10.1016/j.drudis.2006.10.005; Wilton DJ, 2006, J CHEM INF MODEL, V46, P471, DOI 10.1021/ci050397w; Xue Y, 2004, J CHEM INF COMP SCI, V44, P1630, DOI 10.1021/ci049869h; Xue Y, 2004, J CHEM INF COMP SCI, V44, P1497, DOI 10.1021/ci049971e; Yap CW, 2005, J PHARM SCI-US, V94, P153, DOI 10.1002/jps.20232; Yap CW, 2005, J CHEM INF MODEL, V45, P982, DOI 10.1021/ci0500536; Yap CW, 2004, TOXICOL SCI, V79, P170, DOI 10.1093/toxsci/kfh082; Zernov VV, 2003, J CHEM INF COMP SCI, V43, P2048, DOI 10.1021/ci0340916; *AM SOC HLTH SYST, 2001, BETH AHFS DRUG INF	84	39	39	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	1093-3263		J MOL GRAPH MODEL	J. Mol. Graph.	JUN	2008	26	8					1276	1286		10.1016/j.jmgm.2007.12.002		11	Biochemical Research Methods; Biochemistry & Molecular Biology; Computer Science, Interdisciplinary Applications; Crystallography; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Computer Science; Crystallography; Mathematical & Computational Biology	306TV	WOS:000256271600009	
J	Mangasarian, OL; Wild, EW				Mangasarian, O. L.; Wild, E. W.			Multiple instance classification via successive linear programming	JOURNAL OF OPTIMIZATION THEORY AND APPLICATIONS			English	Article						multiple instance learning; support vector machines; successive linearization algorithm; bilinear constraints	SUPPORT VECTOR MACHINES; RECTANGLES	The multiple instance classification problem (Dietterich et al., Artif. Intell. 89:31-71, 1998; Auer, Proceedings of 14th International Conference on Machine Learning, pp. 21-29, Morgan Kaufmann, San Mateo, 1997; Long et al., Mach. Learn. 30(1):7-22, 1998) is formulated using a linear or nonlinear kernel as the minimization of a linear function in a finite-dimensional (noninteger) real space subject to linear and bilinear constraints. A linearization algorithm is proposed that solves a succession of fast linear programs that converges in a few iterations to a local solution. Computational results on a number of datasets indicate that the proposed algorithm is competitive with the considerably more complex integer programming and other formulations. A distinguishing aspect of our linear classifier not shared by other multiple instance classifiers is the sparse number of features it utilizes. In some tasks, the reduction amounts to less than one percent of the original features.	[Mangasarian, O. L.; Wild, E. W.] Univ Wisconsin, Dept Comp Sci, Madison, WI 53706 USA	Mangasarian, OL (reprint author), Univ Wisconsin, Dept Comp Sci, 1210 W Dayton St, Madison, WI 53706 USA.	olvi@cs.wisc.edu					Andrews S., 2002, ADV NEURAL INFORM PR, V15, P561; Auer P., 1997, P 14 INT C MACH LEAR, P21; Bouckaert RR, 2003, P 20 INT C MACH LEAR, P51; Bradley P. S., 1998, P 15 INT C MACH LEAR, P82; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; DUNN OJ, 1961, J AM STAT ASSOC, V56, P52, DOI 10.2307/2282330; Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372; Gartner T, 2002, P 19 INT C MACH LEAR, P179; ILOG, 2003, ILOG CPLEX 9 0 US MA; Lee Y., 2001, P 1 SIAM INT C DAT M; Long PM, 1998, MACH LEARN, V30, P7, DOI 10.1023/A:1007450326753; Mangasarian OL, 2000, ADV NEUR IN, P135; Mangasarian OL, 1999, OPER RES LETT, V24, P15, DOI 10.1016/S0167-6377(98)00049-2; Maron O., 1998, 15 INT C MACH LEARN; MATLAB, 1994, MATLAB US GUID, P01760; Murphy P. M., 1992, UCI MACHINE LEARNING; RAMON J, 2000, P ICML 2000 WORKSH A; Ray S., 2005, P 22 INT C MACH LEAR, V119, P697; Scholkopf B., 2002, LEARNING KERNELS; Vapnik V. N., 2000, NATURE STAT LEARNING; Zhang Q., 2002, NIPS, P1073; Zhu J, 2004, ADV NEUR IN, V16, P49	24	18	19	SPRINGER/PLENUM PUBLISHERS	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0022-3239		J OPTIMIZ THEORY APP	J. Optim. Theory Appl.	JUN	2008	137	3					555	568		10.1007/s10957-007-9343-5		14	Operations Research & Management Science; Mathematics, Applied	Operations Research & Management Science; Mathematics	303EY	WOS:000256025000007	
J	Newberg, J; Murphy, RF				Newberg, Justin; Murphy, Robert F.			A framework for the automated analysis of subcellular patterns in human protein atlas images	JOURNAL OF PROTEOME RESEARCH			English	Article						location proteomics; immunohistochemistry; spectral unmixing; subcellular location; pattern recognition; machine learning; tissue microarrays	FLUORESCENCE MICROSCOPE IMAGES; LOCATION PROTEOMICS; CLASSIFICATION	The systematic study of subcellular location patterns is required to fully characterize the human proteome, as subcellular location provides critical context necessary for understanding a protein's function. The analysis of tens of thousands of expressed proteins for the many cell types and cellular conditions under which they may be found creates a need for automated subcellular pattern analysis. We therefore describe the application of automated methods, previously developed and validated by our laboratory on fluorescence micrographs of cultured cell lines, to analyze subcellular patterns in tissue images from the Human Protein Atlas. The Atlas currently contains images of over 3000 protein patterns in various human tissues obtained using immunohistochemistry. We chose a 16 protein subset from the Atlas that reflects the major classes of subcellular location. We then separated DNA and protein staining in the images, extracted various features from each image, and trained a support vector machine classifier to recognize the protein patterns. Our results show that our system can distinguish the patterns with 83% accuracy in 45 different tissues, and when only the most confident classifications are considered, this rises to 97%. These results are encouraging given that the tissues contain many different cell types organized in different manners, and that the Atlas images are of moderate resolution. The approach described is an important starting point for automatically assigning subcellular locations on a proteome-wide basis for collections of tissue images such as the Atlas.	[Newberg, Justin; Murphy, Robert F.] Carnegie Mellon Univ, Ctr Bioimage Informat, Pittsburgh, PA 15217 USA; [Murphy, Robert F.] Carnegie Mellon Univ, Dept Biol Sci, Pittsburgh, PA 15217 USA; [Newberg, Justin; Murphy, Robert F.] Carnegie Mellon Univ, Dept Biomed Engn, Pittsburgh, PA 15217 USA; [Murphy, Robert F.] Carnegie Mellon Univ, Dept Machine Learning, Pittsburgh, PA 15217 USA	Murphy, RF (reprint author), Carnegie Mellon Univ, Ctr Bioimage Informat, 5000 Forbes Ave, Pittsburgh, PA 15217 USA.	murphy@cmu.edu					BENGTSSON E, 2004, IMAGE ANAL, V14, P157; Berger CEH, 2006, J FORENSIC SCI, V51, P100, DOI 10.1111/j.1556-4029.00020.x; Boland MV, 2001, BIOINFORMATICS, V17, P1213, DOI 10.1093/bioinformatics/17.12.1213; Chebira A, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-210; CHEN SC, 2006, P 2006 IEEE INT S BI, P558; CHEN X, 2003, P SOC PHOTO-OPT INS, V4962, P298, DOI 10.1117/12.477899; Chen X, 2006, CYTOM PART A, V69A, P631, DOI 10.1002/cyto.a.20280; COULOT L, 2006, P 2006 IEEE INT S BI, P566; Glory E, 2007, DEV CELL, V12, P7, DOI 10.1016/j.devcel.2006.12.007; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; Hochreiter S, 2006, BIOINFORMATICS, V22, P943, DOI 10.1093/bioinformatics/btl033; Huang K, 2003, P SOC PHOTO-OPT INS, V4962, P307, DOI 10.1117/12.477903; Huang K., 2004, P 2004 IEEE INT S BI, P1139; Huang K, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-78; Kononen J, 1998, NAT MED, V4, P844, DOI 10.1038/nm0798-844; Lee DD, 1999, NATURE, V401, P788; MURPHY RF, 2007, P 2007 IEEE INT S BI, P1052; Osuna EG, 2007, ANN BIOMED ENG, V35, P1081, DOI 10.1007/s10439-007-9254-5; Rabinovich A, 2003, ADV NEURAL INFORM PR, P667; Ruifrok AC, 2001, ANAL QUANT CYTOL, V23, P291; Uhlen M, 2005, MOL CELL PROTEOMICS, V4, P384, DOI 10.1074/mcp.R500009-MCP200; Uhlens M, 2005, MOL CELL PROTEOMICS, V4, P1920, DOI 10.1074/mcp.M500279-MCP200; Wu TF, 2004, J MACH LEARN RES, V5, P975	23	20	21	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1535-3893		J PROTEOME RES	J. Proteome Res.	JUN	2008	7	6					2300	2308		10.1021/pr7007626		9	Biochemical Research Methods	Biochemistry & Molecular Biology	311KL	WOS:000256599000013	
J	Menze, BH; Kelm, BM; Weber, MA; Bachert, P; Hamprecht, FA				Menze, Bjoern H.; Kelm, B. Michael; Weber, Marc-Andre; Bachert, Peter; Hamprecht, Fred A.			Mimicking the human expert: Pattern recognition for an automated assessment of data quality in MR spectroscopic images	MAGNETIC RESONANCE IN MEDICINE			English	Article						magnetic resonance spectroscopic imaging; quality classification; artifact recognition; automated diagnostic systems; expert systems	MAGNETIC-RESONANCE-SPECTROSCOPY; CRAMER-RAO BOUNDS; SHORT ECHO TIME; BRAIN-TUMORS; CONFIDENCE IMAGES; SPECTRAL-ANALYSIS; CLASSIFICATION; QUANTIFICATION; QUANTITATION	Besides the diagnostic evaluation of a spectrum, the assessment of its quality and a check for plausibility of its information remains a highly interactive and thus time-consuming process in MR spectroscopic imaging (MRSI) data analysis. In the automation of this quality control, a score is proposed that is obtained by training a machine learning classifier on a representative set of spectra that have previously been classified by experts into evaluable data and nonevaluable data. In the first quantitative evaluation of different quality measures on a test set of 45,312 long echo time spectra in the diagnosis of brain tumor, the proposed pattern recognition (using the random forest classifier) separated high- and low-quality spectra comparable to the human operator (area-under-the-curve of the receiver-operator-characteristic, AUC > 0.993), and performed better than decision rules based on the signal-to-noise-ratio (AUC < 0.934) or the estimated Cramer-Rao-bound on the errors of a spectral fitting (AUC < 0.952). This probabilistic assessment of the data quality provides comprehensible confidence images and allows filtering the input of any subsequent data processing, i.e., quantitation or pattern recognition, in an automated fashion. It thus can increase robustness and reliability of the final diagnostic evaluation and allows for the automation of a tedious part of MRSI data analysis.	[Menze, Bjoern H.; Kelm, B. Michael; Hamprecht, Fred A.] Univ Heidelberg, IWR, D-69120 Heidelberg, Germany; [Menze, Bjoern H.; Bachert, Peter; Hamprecht, Fred A.] Univ Heidelberg, Dept Phys & Astron, D-6900 Heidelberg, Germany; [Weber, Marc-Andre] German Canc Res Ctr, Dept Radiol, D-6900 Heidelberg, Germany; [Bachert, Peter] German Canc Res Ctr, Dept Med Phys Radiol, D-6900 Heidelberg, Germany	Hamprecht, FA (reprint author), Univ Heidelberg, IWR, INF 368, D-69120 Heidelberg, Germany.	fred.hamprecht@iwr.uni-heidelberg.de					Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BRODLEY CE, 1997, INT C MACH LEARN RES; Cavassila S, 2001, NMR BIOMED, V14, P278, DOI 10.1002/nbm.701; Devos A, 2004, J MAGN RESON, V170, P164, DOI 10.1016/j.jmr.2004.06.010; Ebel A, 2001, MAGNET RESON MED, V46, P1072, DOI 10.1002/mrm.1301; Elster C, 2005, MAGNET RESON MED, V53, P1288, DOI 10.1002/mrm.20500; Guha R, 2005, J CHEM INF MODEL, V45, P65, DOI 10.1021/ci0497511; Hagberg G, 1998, NMR BIOMED, V11, P148, DOI 10.1002/(SICI)1099-1492(199806/08)11:4/5<148::AID-NBM511>3.0.CO;2-4; Ihaka R, 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Jansen JFA, 2006, RADIOLOGY, V240, P318, DOI 10.1148/radiol.2402050314; Jiru F, 2006, MAGN RESON MATER PHY, V19, P1, DOI 10.1007/s10334-005-0018-7; Kelm BM, 2007, MAGN RESON MED, V57, P150, DOI 10.1002/mrm.21112; Kreis R, 2004, NMR BIOMED, V17, P361, DOI 10.1002/nbm.891; Laudadio T, 2005, MAGNET RESON MED, V54, P1519, DOI 10.1002/mrm.20710; Liaw A., 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; Lukas L, 2004, ARTIF INTELL MED, V31, P73, DOI 10.1016/j.artmed.2004.01.001; Maudsley AA, 2005, AM J NEURORADIOL, V26, P2167; Maudsley AA, 2006, NMR BIOMED, V19, P492, DOI 10.1002/nbm.1025; MENZE BH, 2006, P BVM WORKSH INF AKT, P31; Menze BH, 2006, NMR BIOMED, V19, P599, DOI 10.1002/nbm.1041; Naressi A, 2001, MAGN RESON MATER PHY, V12, P141, DOI 10.1007/BF02668096; NELSON S, 2006, ISMRM 14 SCI M SEATT; PROVENCHER SW, 1993, MAGNET RESON MED, V30, P672, DOI 10.1002/mrm.1910300604; Ratiney H, 2005, NMR BIOMED, V18, P1, DOI 10.1002/nbm.895; Saitta L, 1998, MACH LEARN, V30, P133, DOI 10.1023/A:1007448122119; Schlemmer HP, 2001, AM J NEURORADIOL, V22, P1316; Seber G. A. F., 1989, NONLINEAR REGRESSION; Sing T, 2005, BIOINFORMATICS, V21, P3940, DOI 10.1093/bioinformatics/bti623; Soher BJ, 1998, MAGNET RESON MED, V40, P822, DOI 10.1002/mrm.1910400607; Tate AR, 2003, MAGNET RESON MED, V49, P29, DOI 10.1002/mrm.10315; Tate AR, 2006, NMR BIOMED, V19, P411, DOI 10.1002/nbm.1016; Vanhamme L, 2001, MAGNET RESON MED, V46, P1254, DOI 10.1002/mrm.1326; Vanhamme L, 1997, J MAGN RESON, V129, P35, DOI 10.1006/jmre.1997.1244; Young K, 2000, MAGNET RESON MED, V44, P537, DOI 10.1002/1522-2594(200010)44:4<537::AID-MRM7>3.0.CO;2-8	34	7	7	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	0740-3194		MAGN RESON MED	Magn. Reson. Med.	JUN	2008	59	6					1457	1466		10.1002/mrm.21519		10	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	306RV	WOS:000256266400030	
J	Lau, HY; Tong, KY; Zhu, HL				Lau, Hong-Yin; Tong, Kai-Yu; Zhu, Hailong			Support vector machine for classification of walking conditions using miniature kinematic sensors	MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING			English	Article						classification; gait analysis; kinematic; machine learning; sensors	FUNCTIONAL ELECTRICAL-STIMULATION; DAILY PHYSICAL-ACTIVITY; GAIT EVENT DETECTION; ACTIVITY MONITOR; NEURAL-NETWORK; GYROSCOPE; ACCELEROMETERS; RECOGNITION; ORIENTATION; SYSTEMS	A portable gait analysis and activity-monitoring system for the evaluation of activities of daily life could facilitate clinical and research studies. This current study developed a small sensor unit comprising an accelerometer and a gyroscope in order to detect shank and foot segment motion and orientation during different walking conditions. The kinematic data obtained in the pre-swing phase were used to classify five walking conditions: stair ascent, stair descent, level ground, upslope and downslope. The kinematic data consisted of anterior-posterior acceleration and angular velocity measured from the shank and foot segments. A machine learning technique known as support vector machine (SVM) was applied to classify the walking conditions. SVM was also compared with other machine learning methods such as artificial neural network (ANN), radial basis function network (RBF) and Bayesian belief network (BBN). The SVM technique was shown to have a higher performance in classification than the other three methods. The results using SVM showed that stair ascent and stair descent could be distinguished from each other and from the other walking conditions with 100% accuracy by using a single sensor unit attached to the shank segment. For classification results in the five walking conditions, performance improved from 78% using the kinematic signals from the shank sensor unit to 84% by adding signals from the foot sensor unit. The SVM technique with the portable kinematic sensor unit could automatically recognize the walking condition for quantitative analysis of the activity pattern.	[Lau, Hong-Yin; Tong, Kai-Yu] Hong Kong Polytech Univ, Dept Hlth Technol & Informat, Hong Kong, Hong Kong, Peoples R China; [Zhu, Hailong] Hong Kong Polytech Univ, Res Inst Innovat Prod & Technol, Hong Kong, Hong Kong, Peoples R China	Tong, KY (reprint author), Hong Kong Polytech Univ, Dept Hlth Technol & Informat, Hong Kong, Hong Kong, Peoples R China.	ajaxlau@yahoo.com.hk; y.tong@polyu.edu.hk; rihlzhu@inet.polyu.edu.hk	Tong, Kai Yu/C-3546-2009; LAU, Ajax/B-9338-2009	LAU, Ajax/0000-0003-1420-4074			Begg R, 2005, J BIOMECH, V38, P401, DOI 10.1016/j.jbiomech.2004.05.002; Begg RK, 2005, IEEE T BIO-MED ENG, V52, P828, DOI 10.1109/TBME.2005.845241; Bishop Christopher M., 2007, PATTERN RECOGNITION; Boser B, 1992, P 5 ANN WORKSH COMP, P144, DOI DOI 10.1145/130385.130401; Chau T, 2001, GAIT POSTURE, V13, P49, DOI 10.1016/S0966-6362(00)00094-1; Chau T, 2001, GAIT POSTURE, V13, P102, DOI 10.1016/S0966-6362(00)00095-3; Coleman KL, 1999, J REHABIL RES DEV, V36, P8; Coley B, 2005, GAIT POSTURE, V22, P287, DOI 10.1016/j.gaitpost.2004.08.008; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Dai R, 1996, IEEE Trans Rehabil Eng, V4, P63; Dejnabadi H, 2006, IEEE T BIO-MED ENG, V53, P1385, DOI [10.1109/TBME.2006.873678, 10.1109/TMBE.2006.873678]; Ethem A., 2004, INTRO MACHINE LEARNI; Haeuber E, 2004, ARCH PHYS MED REHAB, V85, P1997, DOI 10.1016/j.apmr.2003.11.035; Hansen M, 2004, IEEE T NEUR SYS REH, V12, P81, DOI 10.1109/TNSRE.2003.819890; Herren R, 1999, MED SCI SPORT EXER, V31, P1053, DOI 10.1097/00005768-199907000-00020; Kamruzzaman J, 2006, IEEE T BIO-MED ENG, V53, P2479, DOI 10.1109/TBME.2006.883697; Lau HY, 2008, GAIT POSTURE, V27, P248, DOI 10.1016/j.gaitpost.2007.03.018; Luinge HJ, 2005, MED BIOL ENG COMPUT, V43, P273, DOI 10.1007/BF02345966; Mayagoitia RE, 2002, J BIOMECH, V35, P537, DOI 10.1016/S0021-9290(01)00231-7; Michalski R. S., 1983, MACHINE LEARNING ART, V1; MICHALSKI RS, 1990, MACHINE LEARNING ART, V3; Najafi B, 2002, IEEE T BIO-MED ENG, V49, P843, DOI 10.1109/TBME.2002.800763; Pappas IPI, 2001, IEEE T NEUR SYS REH, V9, P113, DOI 10.1109/7333.928571; Perl E, 2004, HUM MOVEMENT SCI, V23, P605, DOI 10.1016/j.humov.2004.10.010; Riener R, 2002, GAIT POSTURE, V15, P32, DOI 10.1016/S0966-6362(01)00162-X; Sabatini AM, 2005, IEEE T BIO-MED ENG, V52, P486, DOI 10.1109/TBME.2004.840727; Shimada Y, 2005, TOHOKU J EXP MED, V207, P197, DOI 10.1620/tjem.207.197; Song KM, 2006, J PEDIATR ORTHOPED, V26, P245; Terrier P, 2001, ERGONOMICS, V44, P48, DOI 10.1080/00140130118289; Tong KY, 1999, MED ENG PHYS, V21, P87, DOI 10.1016/S1350-4533(99)00030-2; Tong KY, 2003, MED BIOL ENG COMPUT, V41, P710, DOI 10.1007/BF02349979; Vapnik V. N, 1995, NATURE STAT LEARNING; Williamson R, 2000, IEEE T REHABIL ENG, V8, P312, DOI 10.1109/86.867873; Zhang K, 2003, OBES RES, V11, P33, DOI 10.1038/oby.2003.7	34	25	25	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	0140-0118		MED BIOL ENG COMPUT	Med. Biol. Eng. Comput.	JUN	2008	46	6					563	573		10.1007/s11517-008-0327-x		11	Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical & Computational Biology; Medical Informatics	Computer Science; Engineering; Mathematical & Computational Biology; Medical Informatics	304AB	WOS:000256081300005	
J	Zhang, J; Spirtes, P				Zhang, Jiji; Spirtes, Peter			Detection of unfaithfulness and robust causal inference	MINDS AND MACHINES			English	Article						Bayesian network; causal inference; epistemology of causation; faithfulness condition; machine learning; uniform consistency	MARKOV CONDITION; INDEPENDENCE; FAITHFULNESS	Much of the recent work on the epistemology of causation has centered on two assumptions, known as the Causal Markov Condition and the Causal Faithfulness Condition. Philosophical discussions of the latter condition have exhibited situations in which it is likely to fail. This paper studies the Causal Faithfulness Condition as a conjunction of weaker conditions. We show that some of the weaker conjuncts can be empirically tested, and hence do not have to be assumed a priori. Our results lead to two methodologically significant observations: (1) some common types of counterexamples to the Faithfulness condition constitute objections only to the empirically testable part of the condition; and (2) some common defenses of the Faithfulness condition do not provide justification or evidence for the testable parts of the condition. It is thus worthwhile to study the possibility of reliable causal inference under weaker Faithfulness conditions. As it turns out, the modification needed to make standard procedures work under a weaker version of the Faithfulness condition also has the practical effect of making them more robust when the standard Faithfulness condition actually holds. This, we argue, is related to the possibility of controlling error probabilities with finite sample size ("uniform consistency") in causal inference.	[Zhang, Jiji] CALTECH, Div Humanities & Social Sci, Pasadena, CA 91125 USA; [Spirtes, Peter] Carnegie Mellon Univ, Dept Philosophy, Pittsburgh, PA 15213 USA	Zhang, J (reprint author), CALTECH, Div Humanities & Social Sci, Pasadena, CA 91125 USA.	jiji@hss.caltech.edu; ps7z@andrew.cmu.edu					ARTZENIUS F, 1992, PSA P, V2, P227; Cartwright N., 1999, DAPPLED WORLD; Cartwright N., 1989, NATURES CAPACITIES T; CARTWRIGHT N, 2001, MONIST, P507; CHICKERING D. M., 2002, J MACHINE LEARNING R, V3, P507; Cooper GF, 1999, COMPUTATION, CAUSATION, AND DISCOVERY, P3; Dawid AP, 2002, INT STAT REV, V70, P161, DOI 10.1111/j.1751-5823.2002.tb00354.x; Glymour C., 1980, THEORY EVIDENCE; GLYMOUR C, 2007, CAUSAL LEARNING PSYC, pCH14; Hausman D, 2004, PHILOS SCI, V71, P846, DOI 10.1086/425235; Hausman DM, 1999, BRIT J PHILOS SCI, V50, P521, DOI 10.1093/bjps/50.4.521; Heckerman D., 1999, COMPUTATION CAUSATIO; HESSLOW G, 1976, PHILOS SCI, V43, P290, DOI 10.1086/288684; Hitchcock C, 2001, PHILOS REV, V110, P361, DOI 10.1215/00318108-110-3-361; Hitchcock C, 2001, J PHILOS, V98, P273, DOI 10.2307/2678432; Hoover K. D., 2001, CAUSALITY MACROECONO; Mayo D., 1996, ERROR GROWTH EXPT KN; Mayo DG, 2004, PHILOS SCI, V71, P1007, DOI 10.1086/425064; McDermott M, 1995, BRIT J PHILOS SCI, V46, P523, DOI 10.1093/bjps/46.4.523; Meek C., 1995, P 11 C UNC ART INT, P411; Meek C., 1995, P 11 C UNC ART INT, P403; Pearl J, 2000, CAUSALITY MODELS REA; Pearl J., 1988, PROBABILISTIC REASON; Ramsey J, 2006, P 22 C UNC ART INT, P401; Richardson T, 2002, ANN STAT, V30, P962; Robins JM, 2003, BIOMETRIKA, V90, P491, DOI 10.1093/biomet/90.3.491; SHIMIZU S, 2006, J MACHINE LEARNING R, P2003; Sober E., 1987, PROBABILITY CAUSATIO, P211; SPANOS A, 2006, IN PRESS J EC METHOD; Spirtes P., 1991, Social Science Computer Review, V9, DOI 10.1177/089443939100900106; Spirtes P., 1993, CAUSATION PREDICTION; Spohn W., 2000, STOCHASTIC DEPENDENC, P157; Steel D, 2006, MIND MACH, V16, P303, DOI 10.1007/s11023-006-9032-4; Verma T., 1990, P 6 C UNC ART INT, P220; Woodward J, 1998, MULTIVAR BEHAV RES, V33, P129, DOI 10.1207/s15327906mbr3301_5; Woodward J., 2003, MAKING THINGS HAPPEN; ZHANG J, 2006, THESIS CARNEGIE MELL; ZHANG J, 2008, IN PRESS SYNTHESE; ZHANG J., 2003, P 19 C UNC ART INT M, P632; ZHANG J, 2006, UNDERDETERMINATION C	40	9	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-6495		MIND MACH	Minds Mach.	JUN	2008	18	2					239	271		10.1007/s11023-008-9096-4		33	Computer Science, Artificial Intelligence	Computer Science	304BW	WOS:000256086000005	
J	Wei, XK; Li, YH; Li, YF; Zhang, DF				Wei, Xun-Kai; Li, Ying-Hong; Li, Yu-Fei; Zhang, Dong-Fang			Enclosing machine learning: concepts and algorithms	NEURAL COMPUTING & APPLICATIONS			English	Article						cognitive process; enclosing machine learning; minimum volume enclosing shapes; minimum volume enclosing ellipsoid; cognitive class description; cognitive class recognizing	MATRIX	A novel machine learning paradigm, i.e., enclosing machine learning based on regular geometric shapes was proposed. First, it adopted regular minimum volume enclosing and bounding geometric shapes (sphere, ellipsoid, box) or their unions and so on to obtain one class description model. Second, Data description, two class classification, learning algorithms based on the one class description model were presented. The most obvious feature was that enclosing machine learning emphasized one class description and learning. To illustrate the concepts and algorithms, a minimum volume enclosing ellipsoid (MVEE) case for enclosing machine learning was then investigated in detail. Implementation algorithms for enclosing machine learning based on MVEE were presented. Subsequently, we validate the performances of MVEE learners using real world datasets. For novelty detection, a benchmark ball bearing dataset is adopted. For pattern classification, a benchmark iris dataset is investigated. The performance results show that our proposed method is comparable even better than Support Vector Machines (SVMs) in the datasets studied.	[Wei, Xun-Kai; Li, Ying-Hong; Li, Yu-Fei; Zhang, Dong-Fang] AF Engn Univ, Sch Engn, Xian 710038, Shaanxi Prov, Peoples R China	Wei, XK (reprint author), AF Engn Univ, Sch Engn, Xian 710038, Shaanxi Prov, Peoples R China.	xunkai.wei@ieee.org; yinghong_li@126.com; horizon_lyf@hotmail.com; zdf0918@yahoo.com.cn					Chang C.-C., 2001, LIBSVM LIB SUPPORT V; DOLIA AN, 2004, P 7 INT C SIGN IM PR; GLINEUR F, 1998, PATTERN SEPARATION E; LI YH, 2004, ENG APPL SUPPORT VEC; LI YH, 2005, J AIR FORCE ENG U, V4, P70; LOFBERG J, 2006, TOOLBOX MODELING OPT; Newman D. J., 1998, REPOSITORY MACHINE L; Shawe-Taylor J, 2002, LECT NOTES ARTIF INT, V2533, P23; Sun P, 2004, OPER RES, V52, P690, DOI 10.1287/opre.1040.0115; Vandenberghe L, 1998, SIAM J MATRIX ANAL A, V19, P499, DOI 10.1137/S0895479896303430; Wei XK, 2006, LECT NOTES COMPUT SC, V3971, P1089	11	1	2	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0941-0643		NEURAL COMPUT APPL	Neural Comput. Appl.	JUN	2008	17	3					237	243		10.1007/s00521-007-0113-y		7	Computer Science, Artificial Intelligence	Computer Science	292HF	WOS:000255256400004	
J	Auer, P; Burgsteiner, H; Maass, W				Auer, Peter; Burgsteiner, Harald; Maass, Wolfgang			A learning rule for very simple universal approximators consisting of a single layer of perceptrons	NEURAL NETWORKS			English	Article						learning algorithm; parallel delta rule; parallel perceptrons; committee machines; reduced communication	NEURAL-NETWORKS; SPIKING	One may argue that the simplest type of neural networks beyond a single perceptron is an array of several perceptrons in parallel. In spite of their simplicity, Such circuits can compute any Boolean function if one views the majority of the binary perceptron outputs as the binary Output Of the parallel perceptron, and they are universal approximators for arbitrary continuous functions With values in 10, 11 if one views the fraction of perceptrons that Output I as the analog output of the parallel perceptron. Note that in contrast to the familiar model of a "multi-layer perceptron" the parallel perceptron that we consider here has just binary values as outputs of gates on the hidden layer. For a long time one has thought that there exists no competitive learning algorithm for these extremely simple neural networks, which also came to be known as committee machines. It is commonly assumed that one has to replace the hard threshold gates on the hidden layer by sigmoidal gates (or RBF-gates) and that one has to tune the weights on at least two successive layers in order to achieve satisfactory learning results for any class of neural networks that yield universal approximators. We show that this assumption is not true, by exhibiting a simple learning algorithm for parallel perceptrons - the parallel delta ride (p-delta rule). In contrast to backprop for multi-layer perceptrons, the p-delta rule only has to tune a single layer of weights, and it does not require the computation and Communication of analog values with high precision. Reduced communication also distinguishes our new learning rule from other learning rules for parallel perceptrons Such as MADALINE. Obviously these features make the p-delta rule attractive as a biologically more realistic alternative to backprop in biological neural circuits, but also for implementations in special purpose hardware. We show that the p-delta rule also implements gradient descent - with regard to a suitable error measure - although it does not require to compute derivatives. Furthermore it is shown through experiments on common real-world benchmark datasets that its performance is competitive with that of other learning approaches from neural networks and machine learning. It has recently been shown [Anthony, M. (2007). On the generalization error of fixed combinations of classifiers. Journal of Computer and System Sciences 73(5). 725-734; Anthony, M. (2004). On learning a function of perceptrons. In Proceedings of the 2004 IEEE international Joint conference on neural networks (pp. 967-972): Vol. 21 that one can also prove quite satisfactory bounds for the generalization error of this new learning rule. (C) 2008 Elsevier Ltd. All rights reserved.	[Burgsteiner, Harald] Graz Univ Appl Sci, Dept Hlth Care Engn, A-8020 Graz, Austria; [Auer, Peter] Univ Min & Met Leoben, Chair Informat Technol, A-8700 Leoben, Austria; [Maass, Wolfgang] Graz Univ Technol, Inst Theoret Comp Sci, A-8010 Graz, Austria	Burgsteiner, H (reprint author), Graz Univ Appl Sci, Dept Hlth Care Engn, Eggenberger Allee 11, A-8020 Graz, Austria.	auer@uniloeoben.ac.at; harry@igi.tugraz.at; maass@igi.tugraz.at					Anthony M, 2007, J COMPUT SYST SCI, V73, P725, DOI 10.1016/j.jcss.2006.10.017; ANTHONY M, 2004, P 2004 IEEE INT JOIN, V2, P967; Auer P, 2002, LECT NOTES COMPUT SC, V2415, P123; Blake C. L., 1998, UCI REPOSITORY MACHI; BLOCK HD, 1962, REV MOD PHYS, V34, P123, DOI 10.1103/RevModPhys.34.123; BOYD S, 1985, IEEE T CIRCUITS SYST, V32, P1150, DOI 10.1109/TCS.1985.1085649; COPELLI M, 1995, J PHYS A-MATH GEN, V28, P1615, DOI 10.1088/0305-4470/28/6/016; Douglas RJ, 2004, ANNU REV NEUROSCI, V27, P419, DOI 10.1146/annurev.neuro.27.070203.144152; Fiete IR, 2006, PHYS REV LETT, V97, DOI 10.1103/PhysRevLett.97.048104; Freund Y, 1999, MACH LEARN, V37, P277, DOI 10.1023/A:1007662407062; Gerstner W, 1998, PULSED NEURAL NETWORKS, P3; GUYON I, 1993, ADV NEURAL INFORM PR, V5, P147; Haykin S., 1999, NEURAL NETWORKS COMP; IZHIKEVICH EM, 2007, CEREBRAL CORTEX 0113; JABRI M, 1992, IEEE T NEURAL NETWOR, V3, P154, DOI 10.1109/72.105429; Maass W, 1997, NEURAL NETWORKS, V10, P1659, DOI 10.1016/S0893-6080(97)00011-7; Maass W, 2000, NEURAL COMPUT, V12, P1743, DOI 10.1162/089976600300015123; Maass W, 2000, NEURAL COMPUT, V12, P2519, DOI 10.1162/089976600300014827; Maass W, 2002, NEURAL COMPUT, V14, P2531, DOI 10.1162/089976602760407955; MAYS CH, 1963, 15571 STANF EL LABS; MOERLAND P, 1996, HDB NEURAL COMPUTATI, P1; NILSSON N. J., 1990, MATH FDN LEARNING MA; ROSENBLATT JF, 1962, PRINCIPLES NEURODYNA; Turrigiano G, 2004, NEURON, V44, P903, DOI 10.1016/j.neuron.2004.12.011; WIDROW B, 1990, P IEEE, V78, P1415, DOI 10.1109/5.58323; Xie XH, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.041909	26	18	18	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080		NEURAL NETWORKS	Neural Netw.	JUN	2008	21	5					786	795		10.1016/j.neunet.2007.12.036		10	Computer Science, Artificial Intelligence	Computer Science	324OY	WOS:000257529100004	
J	Fan, Y; Resnick, SM; Wu, XY; Davatzikos, C				Fan, Yong; Resnick, Susan M.; Wu, Xiaoying; Davatzikos, Christos			Structural and functional biomarkers of prodromal Alzheimer's disease: A high-dimensional pattern classification study	NEUROIMAGE			English	Article						Alzheimer's disease; MCI; high-dimensional pattern classification; MRI; PET; voxel-based analysis; diagnosis of AD	MILD COGNITIVE IMPAIRMENT; VOXEL-BASED MORPHOMETRY; MACHINE LEARNING-METHODS; GRAY-MATTER LOSS; HIPPOCAMPAL VOLUME; TEMPORAL-LOBE; EARLY-ONSET; DIAGNOSTIC PERFORMANCE; SCHIZOPHRENIA-PATIENTS; ELASTIC REGISTRATION	This work builds upon previous studies that reported high sensitivity and specificity in classifying individuals with mild cognitive impairment (MCI), which is often a prodromal phase of Alzheimer's disease (AD), via pattern classification of MRI scans. The current study integrates MRI and PET O-15 water scans from 30 participants in the Baltimore Longitudinal Study of Aging, and tests the hypothesis that joint evaluation of structure and function can yield higher classification accuracy than either alone. Classification rates of up to 100% accuracy were achieved via leave-one-out cross-validation, whereas conservative estimates of generalization performance in new scans, evaluated via bagging cross-validation, yielded an area under the receiver operating characteristic (ROC) curve equal to 0.978 (97.8%), indicating excellent diagnostic accuracy. Spatial maps of regions determined to contribute the most to the classification implicated many temporal, prefrontal, orbitofrontal, and parietal regions. Detecting complex patterns of brain abnormality in early stages of cognitive impairment has pivotal importance for the detection and management of AD. (c) 2008 Elsevier Inc. All rights reserved.	[Fan, Yong; Wu, Xiaoying; Davatzikos, Christos] Univ Penn, Dept Radiol, Sect Biomed Image Anal, Philadelphia, PA 19104 USA; [Resnick, Susan M.] NIA, Lab Personal & Cognit, Bethesda, MD 20892 USA	Davatzikos, C (reprint author), Univ Penn, Dept Radiol, Sect Biomed Image Anal, 3600 Market St,Suite 380, Philadelphia, PA 19104 USA.	christos@rad.upenn.edu					Ardekani S, 2007, MAGN RESON IMAGING, V25, P154, DOI 10.1016/j.mri.2006.09.045; Ashburner J, 2003, LANCET NEUROL, V2, P79, DOI 10.1016/S1474-4422(03)00304-1; Ashburner J, 2000, NEUROIMAGE, V11, P805, DOI 10.1006/nimg.2000.0582; Beresford TP, 2006, ALCOHOL CLIN EXP RES, V30, P1866, DOI 10.1111/j.1530-0277.2006.00223.x; Beresford TP, 2006, J STUD ALCOHOL, V67, P861; Bozzali M, 2006, NEUROLOGY, V67, P453, DOI 10.1212/01.wnl.0000228243.56665.c2; Braak H, 1998, J NEURAL TRANSM-SUPP, P97; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Chetelat G, 2002, NEUROREPORT, V13, P1939; Chung MK, 2001, NEUROIMAGE, V14, P595, DOI 10.1006/nimg.2001.0862; Convit A, 2000, NEUROBIOL AGING, V21, P19, DOI 10.1016/S0197-4580(99)00107-4; Convit A, 1997, NEUROBIOL AGING, V18, P131, DOI 10.1016/S0197-4580(97)00001-8; Davatzikos C, 2004, NEUROIMAGE, V23, P17, DOI 10.1016/j.neuroimage.2004.05.010; Davatzikos C, 2005, NEUROIMAGE, V28, P663, DOI 10.1016/j.neuroimage.2005.08.009; Davatzikos C, 2001, NEUROIMAGE, V14, P1361, DOI 10.1006/nimg.2001.0937; Davatzikos C, 2005, ARCH GEN PSYCHIAT, V62, P1218, DOI 10.1001/archpsyc.62.11.1218; Davatzikos C, 2008, NEUROBIOL AGING, V29, P514, DOI 10.1016/j.neurobiolaging.2006.11.010; Davatzikos C, 1996, J COMPUT ASSIST TOMO, V20, P88, DOI 10.1097/00004728-199601000-00017; Dickerson BC, 2001, NEUROBIOL AGING, V22, P747, DOI 10.1016/S0197-4580(01)00271-8; DRISCOLL I, 2007, LONGITUDINAL BRAIN C; Duchesne S, 2006, NEUROIMAGE, V29, P557, DOI 10.1016/j.neuroimage.2005.07.052; Duda R. O., 2001, PATTERN CLASSIFICATI; Fan Y, 2005, LECT NOTES COMPUT SC, V3749, P1; FAN Y, 2008, FEATURE SELECTION CL; Fan Y, 2008, BIOL PSYCHIAT, V63, P118, DOI 10.1016/j.biopsych.2007.03.015; FAN Y, 2006, DIAGNOSIS BRAIN ABNO, P1044; Fan Y, 2007, NEUROIMAGE, V36, P1189, DOI 10.1016/j.neuroimage.2007.04.009; FAN Y, 2006, IEEE WORKSH MATH MET; Fan Y, 2007, IEEE T MED IMAGING, V26, P93, DOI 10.1109/TMI.2006.886812; Firbank MJ, 2007, NEUROIMAGE, V36, P1, DOI 10.1016/j.neuroimage.2007.02.027; FOSTER NL, 1983, NEUROLOGY, V33, P961; Fox NC, 1996, LANCET, V348, P94, DOI 10.1016/S0140-6736(96)05228-2; Fox NC, 1996, BRAIN, V119, P2001, DOI 10.1093/brain/119.6.2001; Fox NC, 2004, LANCET, V363, P392, DOI 10.1016/S0140-6736(04)15441-X; Frisoni GB, 2007, BRAIN, V130, P720, DOI 10.1093/brain/awl377; Goldszal AF, 1998, J COMPUT ASSIST TOMO, V22, P827, DOI 10.1097/00004728-199809000-00030; GOLLAND P, 2002, 5 INT C MED IM COMP, P508; Good CD, 2002, NEUROIMAGE, V17, P29, DOI 10.1006/nimg.2002.1202; Grundman M, 2004, ARCH NEUROL-CHICAGO, V61, P59, DOI 10.1001/archneur.61.1.59; GUR R, 2006, SCHIZOPHRENIA B, V31, P408; Huang J, 2005, IEEE T KNOWL DATA EN, V17, P299; Hunt A, 2007, PSYCHIAT RES-NEUROIM, V155, P147, DOI 10.1016/j.pscychresns.2006.12.003; Ishii K, 2005, AM J NEURORADIOL, V26, P333; Ishii K, 2005, EUR J NUCL MED MOL I, V32, P959, DOI 10.1007/s00259-004-1740-5; Jack CR, 1999, NEUROLOGY, V52, P1397; Kabani N., 1998, NEUROIMAGE, V7, pS717; Karas G, 2007, NEURORADIOLOGY, V49, P967, DOI 10.1007/s00234-007-0269-2; Karas GB, 2004, NEUROIMAGE, V23, P708, DOI 10.1016/j.neuroimage.2004.07.006; Kawachi T, 2006, EUR J NUCL MED MOL I, V33, P801, DOI 10.1007/s00259-005-0050-x; Kawasaki Y, 2007, NEUROIMAGE, V34, P235, DOI 10.1016/j.neuroimage.2006.08.018; Kaye JA, 1997, NEUROLOGY, V48, P1297; Killiany RJ, 2000, ANN NEUROL, V47, P430, DOI 10.1002/1531-8249(200004)47:4<430::AID-ANA5>3.0.CO;2-I; Kim J.-S., 2003, ABNORMAL WHITE MATTE; KOSS E, 1985, AM J PSYCHIAT, V142, P638; Krasuski JS, 1998, BIOL PSYCHIAT, V43, P60, DOI 10.1016/S0006-3223(97)00013-9; Lao ZQ, 2004, NEUROIMAGE, V21, P46, DOI 10.1016/j.neuroimage.2003.09.027; Liu YX, 2004, LECT NOTES COMPUT SC, V3216, P393; MARTIN A, 1986, J CLIN EXP NEUROPSYC, V8, P594, DOI 10.1080/01688638608405178; Matsuda H, 2002, J NUCL MED, V43, P304; Miller M, 1997, Stat Methods Med Res, V6, P267, DOI 10.1191/096228097673360480; MINOSHIMA S, 1994, LANCET, V344, P895, DOI 10.1016/S0140-6736(94)92871-1; MORRIS JC, 1989, NEUROLOGY, V39, P1159; Mourao-Miranda J, 2005, NEUROIMAGE, V28, P980, DOI 10.1016/j.neuroimage.2005.06.070; Pantano P, 1999, ITAL J NEUROL SCI, V20, pS250, DOI 10.1007/s100729970006; Pennanen C, 2005, J NEUROL NEUROSUR PS, V76, P11, DOI 10.1136/jnnp.2004.035600; Petersen RC, 1999, ARCH NEUROL-CHICAGO, V56, P303, DOI 10.1001/archneur.56.3.303; Pham DL, 1999, IEEE T MED IMAGING, V18, P737, DOI 10.1109/42.802752; Reiman EM, 1996, NEW ENGL J MED, V334, P752, DOI 10.1056/NEJM199603213341202; RESNICK S, 2001, NEUROBIOL AGING, V22, P5; Resnick SM, 2004, NEUROBIOL AGING, V25, P263; RESNICK SM, 2003, J NEUROSCI, V23, P295; Resnick SM, 2000, CEREB CORTEX, V10, P464, DOI 10.1093/cercor/10.5.464; Saykin AJ, 2006, NEUROLOGY, V67, P834, DOI 10.1212/01.wnl.0000234032.77541.a2; Scarmeas N, 2004, NEUROIMAGE, V23, P35, DOI 10.1016/j.neuroimage.2004.04.032; Shen DG, 2002, IEEE T MED IMAGING, V21, P1421, DOI 10.1109/TMI.2002.803111; Shen DG, 2003, NEUROIMAGE, V18, P28, DOI 10.1006/nimg.2002.1301; Stewart WF, 2006, NEUROLOGY, V66, P1476, DOI 10.1212/01.wnl.0000216138.69777.15; Thompson PM, 2001, CEREB CORTEX, V11, P1, DOI 10.1093/cercor/11.1.1; Thompson PM, 2007, ANN NY ACAD SCI, V1097, P183, DOI 10.1196/annals.1379.017; TIMONER SJ, 2002, P 5 INT C MED IM COM, P355; Whitwell JL, 2007, BRAIN, V130, P1777, DOI 10.1093/brain/awml12; Xie S, 2006, NEUROLOGY, V66, P1845, DOI 10.1212/01.wnl.0000219625.77625.aa; Yoon U, 2007, NEUROIMAGE, V34, P1405, DOI 10.1016/j.neuroimage.2006.11.021	83	75	77	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1053-8119		NEUROIMAGE	Neuroimage	JUN	2008	41	2					277	285		10.1016/j.neuroimage.2008.02.043		9	Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical Imaging	Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging	306TQ	WOS:000256271100011	
J	Zhang, J; Liang, L; Anderson, JR; Gatewood, L; Rottenberg, DA; Strother, SC				Zhang, Jing; Liang, Lichen; Anderson, Jon R.; Gatewood, Lael; Rottenberg, David A.; Strother, Stephen C.			A java-based fMRI processing pipeline evaluation system for assessment of univariate general linear model and multivariate canonical variate analysis-based pipelines	NEUROINFORMATICS			English	Article						fMRI; fMRI processing pipeline; machine learning; data mining; prediction accuracy; classification accuracy; reproducibility; cross-validation	FUNCTIONAL NEUROIMAGING EXPERIMENTS; AUTOMATED IMAGE REGISTRATION; TEST-RETEST RELIABILITY; QUANTITATIVE-EVALUATION; PREPROCESSING CHOICES; DISCRIMINANT-ANALYSIS; PERFORMANCE METRICS; STATISTICAL-METHODS; LEARNING-CURVES; BOLD FMRI	As functional magnetic resonance imaging (fMRI) becomes widely used, the demands for evaluation of fMRI processing pipelines and validation of fMRI analysis results is increasing rapidly. The current NPAIRS package, an IDL-based fMRI processing pipeline evaluation framework, lacks system interoperability and the ability to evaluate general linear model (GLM)-based pipelines using prediction metrics. Thus, it can not fully evaluate fMRI analytical software modules such as FSL.FEAT and NPAIRS.GLM. In order to overcome these limitations, a Java-based fMRI processing pipeline evaluation system was developed. It integrated YALE (a machine learning environment) into Fiswidgets (a fMRI software environment) to obtain system interoperability and applied an algorithm to measure GLM prediction accuracy. The results demonstrated that the system can evaluate fMRI processing pipelines with univariate GLM and multivariate canonical variates analysis (CVA)-based models on real fMRI data based on prediction accuracy (classification accuracy) and statistical parametric image (SPI) reproducibility. In addition, a preliminary study was performed where four fMRI processing pipelines with GLM and CVA modules such as FSL.FEAT and NPAIRS.CVA were evaluated with the system. The results indicated that (1) the system can compare different fMRI processing pipelines with heterogeneous models (NPAIRS.GLM, NPAIRS.CVA and FSL.FEAT) and rank their performance by automatic performance scoring, and (2) the rank of pipeline performance is highly dependent on the preprocessing operations. These results suggest that the system will be of value for the comparison, validation, standardization and optimization of functional neuroimaging software packages and fMRI processing pipelines.	[Zhang, Jing] Mt Sinai Med Ctr, New York, NY 10029 USA; [Zhang, Jing; Gatewood, Lael; Strother, Stephen C.] Univ Minnesota, Hlth Informat Grad Program, Minneapolis, MN 55455 USA; [Liang, Lichen] Univ Minnesota, Dept Elect Engn, Minneapolis, MN 55455 USA; [Anderson, Jon R.; Rottenberg, David A.; Strother, Stephen C.] Univ Minnesota, Dept Neurol, Minneapolis, MN 55455 USA; [Strother, Stephen C.] Univ Toronto, Toronto, ON M6A 2E1, Canada	Zhang, J (reprint author), Mt Sinai Med Ctr, New York, NY 10029 USA.	jzhang000@yahoo.com					Beckmann CF, 2004, IEEE T MED IMAGING, V23, P137, DOI 10.1109/TMI.2003.822821; Blanco A, 2002, TAPPI J, V1, P14; Bluemke DA, 2004, JAMA-J AM MED ASSOC, V292, P2735, DOI 10.1001/jama.292.22.2735; BULLMORE E, 1995, NEUROIMAGE, V2, P133, DOI 10.1006/nimg.1995.1016; Chance MR, 2002, PROTEIN SCI, V11, P723, DOI 10.1110/ps.470102; COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211; Cox RW, 1996, COMPUT BIOMED RES, V29, P162, DOI 10.1006/cbmr.1996.0014; EFRON B, 1983, AM STAT, V37, P36, DOI 10.2307/2685844; Fissell K, 2003, NEUROINFORMATICS, V1, P111, DOI 10.1385/NI:1:1:111; FORD J, 2001, NEUROIMAGE, V13, P1302, DOI 10.1016/S1053-8119(01)92616-3; Friston KJ, 2003, NEUROIMAGE, V19, P1240, DOI 10.1016/S1053-8119(03)00144-7; Genovese CR, 1997, MAGNET RESON MED, V38, P497, DOI 10.1002/mrm.1910380319; GEVINS AS, 1987, SCIENCE, V235, P580, DOI 10.1126/science.3810158; Gold S, 1998, HUM BRAIN MAPP, V6, P73, DOI 10.1002/(SICI)1097-0193(1998)6:2<73::AID-HBM1>3.0.CO;2-H; Grant JD, 2004, BIOINFORMATICS, V20, P282, DOI 10.1093/bioinformatics/btg407; Hansen LK, 1999, NEUROIMAGE, V9, P534, DOI 10.1006/nimg.1998.0425; Haynes JD, 2006, NAT REV NEUROSCI, V7, P523, DOI 10.1038/nrn1931; Herskovits EH, 2003, NEUROIMAGE, V19, P1664, DOI 10.1016/S1053-8119(03)00231-3; HOLMES AP, 1994, THESIS U GALSGOW; IYENGAR V, 2000, ACM SIGKDD, P91; Kay KN, 2008, HUM BRAIN MAPP, V29, P142, DOI 10.1002/hbm.20379; KIPPENHAN JS, 1992, J NUCL MED, V33, P1459; Kjems U, 2002, NEUROIMAGE, V15, P772, DOI 10.1006/nimg.2001.1033; Kustra R, 2001, IEEE T MED IMAGING, V20, P376, DOI 10.1109/42.925291; LaConte S, 2005, NEUROIMAGE, V26, P317, DOI 10.1016/j.neuroimage.2005.01.048; LaConte S, 2003, NEUROIMAGE, V18, P10, DOI 10.1006/nimg.2002.1300; Lange N, 1999, NEUROIMAGE, V10, P282, DOI 10.1006/nimg.1999.0472; LAUTRUP B, 1994, P WORKSH SUP BRAIN R; Le TH, 1997, NMR BIOMED, V10, P160, DOI 10.1002/(SICI)1099-1492(199706/08)10:4/5<160::AID-NBM458>3.0.CO;2-A; Lehman CD, 2006, AM J ROENTGENOL, V187, P51, DOI 10.2214/AJR.05.0269; LEWIS JP, 2004, PERFORMANCE JAVA VER; Liberman L, 2003, AM J ROENTGENOL, V180, P333; LIU L, 2004, P DISTR DAT PROC MED, P74; LIU L, 2005, J NEUROIMAGING S, V15, P103; Lukic AS, 2002, ARTIF INTELL MED, V25, P69, DOI 10.1016/S0933-3657(02)00009-X; MADSEN RE, 2003, MULTISUBJECT FMRI GE; Maitra R, 2002, MAGN RESON MED, V48, P62, DOI 10.1002/mrm.10191; Morch N, 1997, LECT NOTES COMPUT SC, V1230, P259; MUNGALL CJ, 2002, GENOME BIOL, V3, P1; Nandy RR, 2003, MAGNET RESON MED, V49, P1152, DOI 10.1002/mrm.10469; NICOLAOU N, 2004, P MEDSIP 04 2 INT C; Prechelt L., 2000, IEEE COMPUT, V33, P23; Rex DE, 2003, NEUROIMAGE, V19, P1033, DOI 10.1016/S1053-8119(03)00185-X; Shaw ME, 2003, NEUROIMAGE, V19, P988, DOI 10.1016/S1053-8119(03)00116-2; SHERLOCK R, 2002, GISRUK 2002 C U SHEF; Skudlarski P, 1999, NEUROIMAGE, V9, P311, DOI 10.1006/nimg.1999.0402; Smith SM, 2005, HUM BRAIN MAPP, V24, P248, DOI 10.1002/hbm.20080; Smith S, 2004, NEUROIMAGE, V23, P208, DOI DOI 10.1016/J.NEUROIMAGE.2004.07.051; STONE M, 1974, J R STAT SOC B, V36, P111; Strother SC, 2006, IEEE ENG MED BIOL, V25, P27, DOI 10.1109/MEMB.2006.1607667; STROTHER S, 2004, NEUROIMAGE, V23, P196; STROTHER SC, 1991, J CEREBRAL BLOOD FLO, V11, P3; Strothert SC, 2002, NEUROIMAGE, V15, P747, DOI 10.1006/nimg.2001.1034; Strother SC, 1997, HUM BRAIN MAPP, V5, P312, DOI 10.1002/(SICI)1097-0193(1997)5:4&lt;312::AID-HBM18&gt;3.0.CO;2-F; Tanabe J, 2002, NEUROIMAGE, V15, P902, DOI 10.1006/nimg.2002.1053; Tegeler C, 1999, HUM BRAIN MAPP, V7, P267, DOI 10.1002/(SICI)1097-0193(1999)7:4<267::AID-HBM5>3.0.CO;2-3; WANG X, 2003, 17 ANN C NEUR INF PR; Winterer G, 1998, NEUROPSYCHOBIOLOGY, V37, P41, DOI 10.1159/000026475; WITTEN IH, 2000, DATA MINING PRACTICA, P10; Woods RP, 1998, J COMPUT ASSIST TOMO, V22, P139, DOI 10.1097/00004728-199801000-00027; Woods RP, 1998, J COMPUT ASSIST TOMO, V22, P153, DOI 10.1097/00004728-199801000-00028; Zijdenbos AP, 2002, IEEE T MED IMAGING, V21, P1280, DOI 10.1109/TMI.2002.806283	62	6	6	HUMANA PRESS INC	TOTOWA	999 RIVERVIEW DRIVE SUITE 208, TOTOWA, NJ 07512 USA	1539-2791		NEUROINFORMATICS	Neuroinformatics	JUN	2008	6	2					123	134		10.1007/s12021-008-9014-1		12	Computer Science, Interdisciplinary Applications; Neurosciences	Computer Science; Neurosciences & Neurology	328BH	WOS:000257771800007	
J	Ricordeau, M; Liquiere, M				Ricordeau, Marc; Liquiere, Michel			Algebraic results and bottom-up algorithm for policies generalization in reinforcement learning using concept lattices	NONLINEAR ANALYSIS-HYBRID SYSTEMS			English	Article						Reinforcement learning; Galois lattices		The generalization of policies in reinforcement learning is a main issue, both from the theoretical model point of view and for their applicability. However, generalizing from a set of examples or searching for regularities is a problem which has already been intensively studied in machine learning. Thus, existing domains such as Inductive Logic Programming have already been linked with reinforcement learning. Our work uses techniques in which generalizations are constrained by a language bias, in order to regroup similar states. Such generalizations are principally based on the properties of concept lattices. To guide the possible groupings of similar states of the environment, we propose a general algebraic framework, considering the generalization of policies through a partition of the set of states and using a language bias as an a priori knowledge. We give a practical application as an example of our theoretical approach by proposing and experimenting a bottom-up algorithm. (c) 2008 Published by Elsevier Ltd	[Ricordeau, Marc; Liquiere, Michel] Lab Informat Robot & Microelect Montpellier, F-34392 Montpellier 5, France	Ricordeau, M (reprint author), Lab Informat Robot & Microelect Montpellier, 161 Rue Ada, F-34392 Montpellier 5, France.	mricorde@wanadoo.fr; liquiere@lirmm.fr					Dietterich T.G., 2000, ARTIF INTELL, P227; Dzeroski S, 2001, MACH LEARN, V43, P7, DOI 10.1023/A:1007694015589; Ganter B., 1999, FORMAL CONCEPT ANAL; Givan R, 2003, ARTIF INTELL, V147, P163, DOI 10.1016/S0004-3702(02)00376-4; James M.R., 2004, ICML 2004, P417; Liquiere M., 1998, ICML, P305; McCallum A., 2003, C UNC ART INT UAI; McCallum A., 1996, THESIS; Mitchell T, 1997, MACHINE LEARNING; Munos R., 1997, FINITE ELEMENT METHO; Munos R., 2003, ICML 2003, P560; Ravindran B., 2003, IJCAI 2003, P1011; Ricordeau M, 2003, PROC INT C TOOLS ART, P316, DOI 10.1109/TAI.2003.1250206; Sutton RS, 1999, ARTIF INTELL, V112, P181, DOI 10.1016/S0004-3702(99)00052-1; Sutton R.S., 1998, REINFORCEMENT LEARNI; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698	16	1	1	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1751-570X		NONLINEAR ANAL-HYBRI	Nonlinear Anal.-Hybrid Syst.	JUN	2008	2	2			SI		684	694		10.1016/j.nahs.2006.12.001		11	Automation & Control Systems; Mathematics, Applied	Automation & Control Systems; Mathematics	V27EN	WOS:000208596600032	
J	Marinaki, M; Marinakis, Y; Doumpos, M; Matsatsinis, N; Zopounidis, C				Marinaki, Magdalene; Marinakis, Yannis; Doumpos, Michael; Matsatsinis, Nikolaos; Zopounidis, Constantin			A comparison of several nearest neighbor classifier metrics using Tabu Search algorithm for the feature selection problem	OPTIMIZATION LETTERS			English	Article						Feature selection problem; Nearest neighbor classification method; Tabu Search	FEATURE SUBSET-SELECTION	The feature selection problem is an interesting and important topic which is relevant for a variety of database applications. This paper utilizes the Tabu Search metaheuristic algorithm to implement a feature subset selection procedure while the nearest neighbor classification method is used for the classification task. Tabu Search is a general metaheuristic procedure that is used in order to guide the search to obtain good solutions in complex solution spaces. Several metrics are used in the nearest neighbor classification method, such as the euclidean distance, the Standardized Euclidean distance, the Mahalanobis distance, the City block metric, the Cosine distance and the Correlation distance, in order to identify the most significant metric for the nearest neighbor classifier. The performance of the proposed algorithms is tested using various benchmark datasets from UCI Machine Learning Repository.	[Doumpos, Michael; Zopounidis, Constantin] Tech Univ Crete, Dept Prod Engn & Management, Financial Engn Lab, Khania 73100, Greece; [Marinaki, Magdalene] Tech Univ Crete, Dept Prod Engn & Management, Ind Syst Control Lab, Khania 73100, Greece; [Marinakis, Yannis; Matsatsinis, Nikolaos] Tech Univ Crete, Dept Prod Engn & Management, Decis Support Syst Lab, Khania 73100, Greece	Zopounidis, C (reprint author), Tech Univ Crete, Dept Prod Engn & Management, Financial Engn Lab, Khania 73100, Greece.	magda@dssl.tuc.gr; marinakis@ergasya.tuc.gr; mdoumpos@dpem.tuc.gr; nikos@ergasya.tuc.gr; kostas@dpem.tuc.gr					AHA DW, 1996, ARTIFICIAL INTELLIGE; Cantu-Paz E, 2004, LECT NOTES COMPUT SC, V3102, P959; Cantu-Paz E., 2004, P 2004 ACM SIGKDD IN, P788, DOI 10.1145/1014052.1016915; Duda R. O., 2001, PATTERN CLASSIFICATI; Duda R.O, 1973, PATTERN CLASSIFICATI; Lopez FG, 2006, EUR J OPER RES, V169, P477, DOI 10.1016/j.ejor.2004.08.010; Gendreau M., 2003, HDB METAHEURISTICS, P37; Giudici P., 2003, APPL DATA MINING STA; Glover F., 1993, TABU SEARCH; Glover F., 1990, ORSA Journal on Computing, V2; Glover F., 1989, ORSA Journal on Computing, V1; Hastie T., 2001, SPRINGER SERIES STAT; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Kira K, 1992, P 9 INT C MACH LEARN, P249; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; NARENDRA P, 1977, IEEE T COMPUT, V26, P917; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Rokach L, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P321, DOI 10.1007/0-387-25465-X_15; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; Siedlecki W., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, DOI 10.1142/S0218001488000145	20	0	0	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	1862-4472		OPTIM LETT	Optim. Lett.	JUN	2008	2	3					299	308		10.1007/s11590-007-0057-2		10	Operations Research & Management Science; Mathematics, Applied	Operations Research & Management Science; Mathematics	377EM	WOS:000261234500002	
J	Mangasarian, OL; Thompson, ME				Mangasarian, O. L.; Thompson, M. E.			Chunking for massive nonlinear kernel classification	OPTIMIZATION METHODS & SOFTWARE			English	Article						classification; nonlinear kernel; massive datasets; linear programming; dual penalty	SUPPORT VECTOR MACHINES; MINIMIZATION	A chunking procedure [Bradley, P.S. and Mangasarian, O.L., 2000, Massive data discrimination via linear Support vector machines. Optimization Methods and Software, 13, 1-10. Available online at: ftp://ftp.es.wise.edu/mathprog/tech-reports/98-05.ps] utilized in [Mangasarian, O.L. and Thompson, M.E., 2006, Massive data classification via unconstrained support vector machines. Journal of Optimization Theory and Applications, 131, 315-325. Available online at: ftp://ftp.cs.wise.edu/pub/dmi/techreports/06-01.pdf for linear classifiers is proposed here for nonlinear kernel classification of massive datasets. A highly accurate algorithm based on nonlinear support vector machines that utilize a linear programming formulation [Mangasarian, O.L., 2000, Generalized support vector machines. In: A. Smola, P. Bartlett, B. Scholkopf and D. Schournians (Eds) Advances in Large Margin Classifiers (Cambridge, MA: MIT Press), pp. 135-146. Available online at: ftp://ftp.cs.wise.edu/math-prog/tech-reports/98-14.ps] is developed here as a Completely unconstrained minimization problem [Mangasarian, O.L., 2005, Exact 1-Norm Support vector machines via unconstrained convex differentiable minimization. Technical Report 05-03, Data Mining Institute, Computer Sciences Department, University of Wisconsin, Madison, Wisconsin. Available online at: ftp://ftp.cs.wisc.edu/pub/dmi/tech-reports/05-03.ps. Journal (of Machine Learning Research, 7, 1517-1530, 2006.]. This approach together with chunking leads to a simple and accurate method for generating nonlinear classifiers for a 250,000-point dataset that typically exceeds machine capacity when standard linear programming methods such as CPLEX [ILOG, 2003, ILOG CPLEX 9.0 User's Manual, Incline Village, Nevada. Available online at: http://www.ilog.com/products/cplex/] are used. Because a 1-norm Support vector machine underlies the proposed method, the approach together with a reduced Support vector machine formulation [Lee, Y.-J. and Mangasarian, O.L., 2001, RSVM: reduce(] Support vector machines. Proceedings of the First SIAM International Conference on Data Mining, Chicago, 5-7 April, CD-ROM. Available online at: ftp://ftp.cs.wisc.edu/pub/dmi/tech-reports/00-07.ps] minimizes the number of kernel functions utilized to generate a simplified nonlinear classifier.	[Mangasarian, O. L.; Thompson, M. E.] Univ Wisconsin, Dept Comp Sci, Madison, WI 53706 USA; [Mangasarian, O. L.] Univ Calif San Diego, Dept Math, La Jolla, CA 92093 USA	Mangasarian, OL (reprint author), Univ Wisconsin, Dept Comp Sci, 1210 W Dayton St, Madison, WI 53706 USA.	olvi@cs.wisc.edu					ARMIJO L, 1966, PAC J MATH, V16, P1; Bradley PS, 2000, OPTIM METHOD SOFTW, V13, P1, DOI 10.1080/10556780008805771; Cherkassky V., 1998, LEARNING DATA CONCEP; Chvatal V., 1983, LINEAR PROGRAMMING; Cristianini N., 2000, INTRO SUPPORT VECTOR; DANTZIG GB, 1960, OPER RES, V8, P101, DOI 10.1287/opre.8.1.101; FACCHINEI F, 1995, OPER RES LETT, V17, P131, DOI 10.1016/0167-6377(94)00059-F; Fung GM, 2004, COMPUT OPTIM APPL, V28, P185, DOI 10.1023/B:COAP.0000026884.66338.df; GILMORE PC, 1961, OPER RES, V9, P849, DOI 10.1287/opre.9.6.849; HIRIARTURRUTY JB, 1984, APPL MATH OPT, V11, P43, DOI 10.1007/BF01442169; Huang S.Y., 2004, THEORETICAL STUDY RE; ILOG, 2003, ILOG CPLEX 9 0 US MA; Lee Y., 2001, P 1 SIAM INT C DAT M; Luenberger D., 1984, LINEAR NONLINEAR PRO; Mangasarian OL, 2002, OPTIM METHOD SOFTW, V17, P913, DOI 10.1080/1055678021000028375; Mangasarian OL, 2000, ADV NEUR IN, P135; Mangasarian OL, 2006, J OPTIMIZ THEORY APP, V131, P315, DOI 10.1007/s10957-006-9157-x; Mangasarian OL, 2006, J MACH LEARN RES, V7, P1517; Murty K., 1983, LINEAR PROGRAMMING; Scholkopf B., 2002, LEARNING KERNELS; THOMPSON ME, 2006, NDCC NORMALLY DISTRI; Tikhonov AN, 1977, SOLUTIONS 3 POSED PR; Vapnik V. N., 2000, NATURE STAT LEARNING; *MATHWORKS INC, MATLAB 1994 2006 US	24	0	0	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1055-6788		OPTIM METHOD SOFTW	Optim. Method Softw.	JUN	2008	23	3					365	374		10.1080/10556780701611976		10	Computer Science, Software Engineering; Operations Research & Management Science; Mathematics, Applied	Computer Science; Operations Research & Management Science; Mathematics	320MP	WOS:000257239500004	
J	Bowd, C; Goldbaum, MH				Bowd, Christopher; Goldbaum, Michael H.			Machine learning classifiers in glaucoma	OPTOMETRY AND VISION SCIENCE			English	Review						glaucoma; diagnosis; retinal nerve fiber layer; optic disc; perimetry; machine learning; neural network; classification	INDEPENDENT COMPONENT ANALYSIS; SCANNING LASER OPHTHALMOSCOPY; STANDARD AUTOMATED PERIMETRY; OPTICAL COHERENCE TOMOGRAPHY; VISUAL-FIELD PROGRESSION; NEURAL-NETWORK; FUNCTIONAL MEASUREMENTS; IDENTIFY PATTERNS; DIAGNOSIS; CLASSIFICATION	Machine learning is concerned with the design and development of algorithms and techniques that allow computers to "learn" patterns in data using iterative processes. Such processes can be supervised (guided by a priori group membership information) or unsupervised (guided by patterns within the data). Machine learning classifiers (MLC) are unconstrained by statistical assumptions and therefore are adaptable to complex data. Recent applications of MLC techniques to the detection and monitoring of glaucoma by analysis of visual field and optical imaging data suggest that these methods can provide improvement over currently available techniques. This article provides some background about the classification task in glaucoma and the structure and evaluation of MLCs, and it reviews MLC techniques as-they have been applied to visual function and optical imaging in glaucoma research.	[Bowd, Christopher; Goldbaum, Michael H.] Univ Calif San Diego, Dept Ophthalmol, Hamilton Glaucoma Ctr 178, La Jolla, CA 92037 USA; [Goldbaum, Michael H.] VA San Diego Hlth Serv, La Jolla, CA USA	Bowd, C (reprint author), Univ Calif San Diego, Dept Ophthalmol, Hamilton Glaucoma Ctr 178, La Jolla, CA 92037 USA.	cbowd@eyecenter.ucsd.edu					Aulhorn E, 1977, DOC OPHTHALMOL P SER, V14, P75; BECKER S, 1991, INT J NEURAL SYST, P17; Bengtsson B, 2005, INVEST OPHTH VIS SCI, V46, P3730, DOI 10.1167/iovs.05-0175; Bizios D, 2007, J GLAUCOMA, V16, P20, DOI 10.1097/IJG.0b013e31802b34e4; Boden C, 2004, AM J OPHTHALMOL, V138, P1029, DOI 10.1016/j.ajo.2004.07.003; Bowd C, 2008, INVEST OPHTH VIS SCI, V49, P945, DOI 10.1167/iovs.07-1083; Bowd C, 2002, INVEST OPHTH VIS SCI, V43, P3444; Bowd C, 2004, INVEST OPHTH VIS SCI, V45, P2255, DOI 10.1167/iovs.03-1087; Bowd C, 2006, ACTA OPHTHALMOL SCAN, V84, P569; Bowd C, 2005, INVEST OPHTH VIS SCI, V46, P1322, DOI 10.1167/iovs.04-1122; Brigatti L, 1996, AM J OPHTHALMOL, V121, P511; Brigatti L, 1997, ARCH OPHTHALMOL-CHIC, V115, P725; Burgansky-Eliash Z, 2005, INVEST OPHTH VIS SCI, V46, P4147, DOI 10.1167/iovs.05-0366; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Caudill M., 1990, NATURALLY INTELLIGEN; Chan K, 2003, J MACH LEARN RES, V3, P99, DOI 10.1162/153244303768966120; Chan KL, 2002, IEEE T BIO-MED ENG, V49, P963, DOI 10.1109/TBME.2002.802012; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; DREHER AW, 1993, INVEST OPHTH VIS SCI, V34, P763; DRUCKER H, 1994, NEURAL COMPUT, V6, P1289, DOI 10.1162/neco.1994.6.6.1289; GAASTERLAND DE, 1994, OPHTHALMOLOGY, V101, P1445; GOLDBAUM MH, 2005, INVEST OPHTHALMOL VI, V46; GOLDBAUM MH, 2004, INVEST OPHTHALMOL VI, V45; Goldbaum MH, 2002, INVEST OPHTH VIS SCI, V43, P162; Goldbaum MH, 2005, INVEST OPHTH VIS SCI, V46, P3676, DOI 10.1167/iovs.04-1167; GOLDBAUM MH, 1994, INVEST OPHTH VIS SCI, V35, P3362; GOLDBAUM M H, 1990, Investigative Ophthalmology and Visual Science, V31, P503; Goldbaum Michael Henry, 2005, Trans Am Ophthalmol Soc, V103, P270; Henson DB, 1996, BRIT J OPHTHALMOL, V80, P526, DOI 10.1136/bjo.80.6.526; Hothorn T, 2003, ARTIF INTELL MED, V27, P65, DOI 10.1016/S0933-3657(02)00085-4; Huang ML, 2005, INVEST OPHTH VIS SCI, V46, P4121, DOI 10.1167/iovs.050069; Huang ML, 2007, INVEST OPHTH VIS SCI, V48, P244, DOI 10.1167/iovs.06-0320; Johnson CA, 2002, AM J OPHTHALMOL, V134, P177, DOI 10.1016/S0002-9394(02)01577-5; KEATING D, 1993, PHYS MED BIOL, V38, P1263, DOI 10.1088/0031-9155/38/9/006; KELMAN SE, 1990, PERIMETRY UPDATE 199, P287; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Kohonen T, 2001, SELF ORG MAPS; Kozak Igor, 2007, Trans Am Ophthalmol Soc, V105, P111; LEE TW, 2005, INVEST OPHTHALMOL VI, V46; Leske MC, 1999, OPHTHALMOLOGY, V106, P2144, DOI 10.1016/S0161-6420(99)90497-9; Lietman T, 1999, J GLAUCOMA, V8, P77; MADSEN EM, 1994, MIL MED, V159, P553; Mardin CY, 2003, J GLAUCOMA, V12, P340, DOI 10.1097/00061198-200308000-00008; Mardin CY, 2006, J GLAUCOMA, V15, P299, DOI 10.1097/01.ijg.0000212232.03664.ee; MUTLUKAN E, 1994, EYE, V8, P321; NAGATA S, 1990, PRIMETRY UPDATE 1990, P291; PARFITT CM, 1995, 17 ANN C ENG MED BIO, V1; Park JM, 2002, IEEE IJCNN, P1178; Pluhacek F, 2004, CENT EUR J PHYS, V2, P12, DOI 10.2478/BF02476270; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sample PA, 2004, INVEST OPHTH VIS SCI, V45, P2596, DOI 10.1167/iovs.03-0343; Sample PA, 2002, INVEST OPHTH VIS SCI, V43, P2660; Sample PA, 2005, INVEST OPHTH VIS SCI, V46, P3684, DOI 10.1167/iovs.04-1168; SCHULZER M, 1992, OPHTHALMOLOGY, V99, P1468; SPENCELEY SE, 1994, OPHTHAL PHYSL OPT, V14, P239, DOI 10.1111/j.1475-1313.1994.tb00004.x; SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615; Swindale NV, 2000, INVEST OPHTH VIS SCI, V41, P1730; TRESP V, 2002, HDB NEURAL NETWORK S, pCH3; Tresp V, 2001, ADV NEUR IN, V13, P654; Tucker A, 2005, ARTIF INTELL MED, V34, P163, DOI 10.1016/j.artmed.2004.07.004; Uchida H, 1996, INVEST OPHTH VIS SCI, V37, P2393; Vapnik V. N., 2000, NATURE STAT LEARNING; Vapnik VN, 1998, STAT LEARNING THEORY; Yu J, 2005, ST HEAL T, V116, P187; Zangwill LM, 2004, INVEST OPHTH VIS SCI, V45, P3144, DOI 10.1167/iovs.04-0202	66	6	6	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	530 WALNUT ST, PHILADELPHIA, PA 19106-3621 USA	1040-5488		OPTOMETRY VISION SCI	Optom. Vis. Sci.	JUN	2008	85	6					396	405		10.1097/OPX.0b013e3181783ab6		10	Ophthalmology	Ophthalmology	311NR	WOS:000256607400007	
J	Hu, YF; Lv, HR; Zhang, XD				Hu, Yafeng; Lv, Hairong; Zhang, Xianda			Comments on "An analytical algorithm for generalized low-rank approximations of matrices"	PATTERN RECOGNITION			English	Editorial Material						low rank approximation; analytical algorithm; iterative algorithm		Low rank approximations of matrices have been widely used in pattern recognition and machine learning. Based on a sequence of matrices, a generalized low rank approximation problem was presented and an iterative scheme was given by Liang and Shi recently proposed an analytical scheme for this approximation problem. In this paper, we identify the weakness in their scheme and prove that their algorithm is incorrect. (C) 2007 Elsevier Ltd. All rights reserved.	[Hu, Yafeng; Lv, Hairong; Zhang, Xianda] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China	Hu, YF (reprint author), Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.	yafh99@mails.tsinghua.edu.cn; zxd-dau@mail.tsinghua.edu.cn					Golub G. H., 1996, MATRIX COMPUTATIONS; INOUE K, 2006, IEEE P COMPUT VISION, P154; Liang ZZ, 2005, PATTERN RECOGN, V38, P2213, DOI 10.1016/j.patcog.2005.04.012; LIU J, 2006, PATTERN RECOGN, V37, P1002; LIU J, 2006, COMMENT ANAL ALGORIT; YE J, 2004, 21 INT C MACH LEARN, P887	6	2	3	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	JUN	2008	41	6					2133	2135		10.1016/j.patcog.2007.10.008		3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	275XZ	WOS:000254106900023	
J	Schlecht, J; Kaplan, ME; Barnard, K; Karafet, T; Hammer, MF; Merchant, NC				Schlecht, Joseph; Kaplan, Matthew E.; Barnard, Kobus; Karafet, Tatiana; Hammer, Michael F.; Merchant, Nirav C.			Machine-learning approaches for classifying haplogroup from Y chromosome STR data	PLOS COMPUTATIONAL BIOLOGY			English	Article							HUMAN-POPULATIONS; HAPLOTYPES; DIVERSITY; PATTERNS	Genetic variation on the non-recombining portion of the Y chromosome contains information about the ancestry of male lineages. Because of their low rate of mutation, single nucleotide polymorphisms (SNPs) are the markers of choice for unambiguously classifying Y chromosomes into related sets of lineages known as haplogroups, which tend to show geographic structure in many parts of the world. However, performing the large number of SNP genotyping tests needed to properly infer haplogroup status is expensive and time consuming. A novel alternative for assigning a sampled Y chromosome to a haplogroup is presented here. We show that by applying modern machine-learning algorithms we can infer with high accuracy the proper Y chromosome haplogroup of a sample by scoring a relatively small number of Y-linked short tandem repeats (STRs). Learning is based on a diverse ground-truth data set comprising pairs of SNP test results (haplogroup) and corresponding STR scores. We apply several independent machine-learning methods in tandem to learn formal classification functions. The result is an integrated high-throughput analysis system that automatically classifies large numbers of samples into haplogroups in a cost-effective and accurate manner.	[Schlecht, Joseph; Barnard, Kobus] Univ Arizona, Dept Comp Sci, Tucson, AZ 85721 USA; [Kaplan, Matthew E.; Karafet, Tatiana; Hammer, Michael F.; Merchant, Nirav C.] Univ Arizona, Arizona Res Labs, Tucson, AZ 85721 USA	Schlecht, J (reprint author), Univ Arizona, Dept Comp Sci, Tucson, AZ 85721 USA.	nirav@email.arizona.edu			Arizona Research Laboratory (ARL)	This study was supported by Arizona Research Laboratory (ARL) development fund.	Behar DM, 2004, HUM GENET, V114, P354, DOI 10.1007/s00439-003-1073-7; Bell PA, 2003, BIOTECHNIQUES, V34, P496; Bishop C. M., 2006, PATTERN RECOGNITION; Bosch E, 1999, AM J HUM GENET, V65, P1623, DOI 10.1086/302676; Butler JM, 2002, FORENSIC SCI INT, V129, P10, DOI 10.1016/S0379-0738(02)00195-0; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Cinnioglu C, 2004, HUM GENET, V114, P127, DOI 10.1007/s00439-003-1031-4; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Hammer MF, 2001, MOL BIOL EVOL, V18, P1189; Hammer MF, 2006, FORENSIC SCI INT, V164, P45, DOI 10.1016/j.forsciint.2005.11.013; Hammer Michael F., 1996, Evolutionary Anthropology, V5, P116, DOI 10.1002/(SICI)1520-6505(1996)5:4<116::AID-EVAN2>3.0.CO;2-E; Hastie T, 2006, ELEMENTS STAT LEARNI; Heyer E, 1997, HUM MOL GENET, V6, P799, DOI 10.1093/hmg/6.5.799; Jobling MA, 2001, TRENDS GENET, V17, P353, DOI 10.1016/S0168-9525(01)02284-3; Jobling MA, 2000, TRENDS GENET, V16, P356, DOI 10.1016/S0168-9525(00)02057-6; Jobling MA, 2003, NAT REV GENET, V4, P598, DOI 10.1038/nrg1124; Jobling MA, 1997, INT J LEGAL MED, V110, P118, DOI 10.1007/s004140050050; Kayser M, 2000, AM J HUM GENET, V66, P1580, DOI 10.1086/302905; OHTA T, 1973, GENET RES, V22, P201; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Rish I, 2001, IJCAI 2001 WORKSH EM; Sengupta S, 2006, AM J HUM GENET, V78, P202, DOI 10.1086/499411; Shannon E., 1948, BELL SYST TECH J, V27, P623; Sharan R, 2005, J COMPUT BIOL, V12, P514, DOI 10.1089/cmb.2005.12.514; Stone AC, 1996, AM J PHYS ANTHROPOL, V99, P231, DOI 10.1002/(SICI)1096-8644(199602)99:2<231::AID-AJPA1>3.0.CO;2-1; Stone AC, 2002, P NATL ACAD SCI USA, V99, P43, DOI 10.1073/pnas.012364999; Underhill PA, 2001, ANN HUM GENET, V65, P43, DOI 10.1046/j.1469-1809.2001.6510043.x; Underhill PA, 2000, NAT GENET, V26, P358, DOI 10.1038/81685; Vapnik VN, 1998, STAT LEARNING THEORY; Witten I. H., 2005, DATA MINING PRACTICA; Ellis N, 2002, GENOME RES, V12, P339; ZHANGE H, P 17 INT FLAIRS C 20	32	15	15	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	185 BERRY ST, STE 1300, SAN FRANCISCO, CA 94107 USA	1553-734X		PLOS COMPUT BIOL	PLoS Comput. Biol.	JUN	2008	4	6							e1000093	10.1371/journal.pcbi.1000093		12	Biochemical Research Methods; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Mathematical & Computational Biology	356OE	WOS:000259786700006	
J	Barenboim, M; Masso, M; Vaisman, II; Jamison, DC				Barenboim, Maxim; Masso, Majid; Vaisman, Iosif I.; Jamison, D. Curtis			Statistical geometry based prediction of nonsynonymous SNP functional effects using random forest and neuro-fuzzy classifiers	PROTEINS-STRUCTURE FUNCTION AND BIOINFORMATICS			English	Article						single nucleotide polymorphism; computational geometry; artificial intelligence; algorithms; protein conformation; statistical models; complex disease; tertiary protein structure; computational biology; amino acid substitution	SINGLE-NUCLEOTIDE POLYMORPHISMS; PROTEIN-STRUCTURE; SECONDARY STRUCTURE; MISSENSE MUTATIONS; CLASSIFICATION; DISEASE; SEQUENCE; NETWORK; IDENTIFICATION; INFORMATION	There is substantial interest in methods designed to predict the effect of nonsynonymous single nucleotide polymorphisms (nsSNPs) on protein function, given their potential relationship to heritable diseases. Current state-of-the-art supervised machine learning algorithms, such as random forest (RF), train models that classify single amino acid mutations in proteins as either neutral or deleterious to function. However, it is frequently the case that the functional effect of a polymorphism on a protein resides between these two extremes. The utilization of classifiers that incorporate fuzzy logic provides a natural extension in order to account for the spectrum of possible functional consequences. We generated a dataset of single amino acid substitutions in human proteins having known three-dimensional structures. Each variant was uniquely represented as a feature vector that included computational geometry and knowledge-based statistical potential predictors obtained though application of Delaunay tessellation of protein structures. Additional attributes consisted of physicochemical properties of the native and replacement amino acids as well as topological location of the mutated residue position in the solved structure. Classification performance of the RF algorithm was evaluated on a training set consisting of the disease-associated and neutral nsSNPs taken from our dataset, and attributes were ranked according to their relative importance. Similarly, we evaluated the performance of adaptive neuro-fuzzy inference system (ANFIS). The utility of statistical geometry predictors was compared with that of traditional structural and evolutionary attributes employed by other researchers, revealing an equally effective yet complementary methodology. Among all attributes in our feature set, the statistical geometry predictors were found to be the most highly ranked. On the basis of the AUC (area under the ROC curve) measure of performance, the ANFIS and RF models were equally effective when only statistical geometry features were utilized. Tenfold cross-validation studies evaluating AUC, balanced error rate (BER), and Matthew's correlation coefficient (MCC) showed that our RF model was at least comparable with the well-established methods of SIFT and PolyPhen. The trained RF and ANFIS models were each subsequently used to predict the disease potential of human nsSNPs in our dataset that are currently unclassified (http:// rna.gmu.edu/FuzzySnps/).	[Barenboim, Maxim; Masso, Majid; Vaisman, Iosif I.; Jamison, D. Curtis] George Mason Univ, Dept Bioinformat & Comp Biol, Manassas, VA 20110 USA	Jamison, DC (reprint author), No Kentucky Univ, Coll Informat, Highland Hts, KY 41099 USA.	barenboimm@mail.nih.gov; jamisond1@nku.edu	Vaisman, Iosif/K-5268-2012	Vaisman, Iosif/0000-0001-6858-1516			Bairoch A, 2000, NUCLEIC ACIDS RES, V28, P45, DOI 10.1093/nar/28.1.45; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Bao L, 2005, BIOINFORMATICS, V21, P2185, DOI 10.1093/bioinformatics/bti365; Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821; Barenboim M, 2005, HUM MUTAT, V26, P471, DOI 10.1002/humu.20238; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; BOWIE JU, 1991, SCIENCE, V253, P164, DOI 10.1126/science.1853201; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Capriotti E., 2004, BIOINFORMATICS, V20, pi63; Care MA, 2007, BIOINFORMATICS, V23, P664, DOI 10.1093/bioinformatics/btl649; Carter CW, 2001, J MOL BIOL, V311, P625, DOI 10.1006/jmbi.2001.4906; Chasman D, 2001, J MOL BIOL, V307, P683, DOI 10.1006/jmbi.2001.4510; Dayhoff MO, 1978, ATLAS PROTEIN SEQ S3, P345; Dobson RJ, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-217; Frishman D, 1995, PROTEINS, V23, P566, DOI 10.1002/prot.340230412; Gunther EC, 2003, P NATL ACAD SCI USA, V100, P9608, DOI 10.1073/pnas.1632587100; HANLEY JA, 1982, RADIOLOGY, V143, P29; JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541; Kaminker JS, 2007, CANCER RES, V67, P465, DOI 10.1158/0008-5472.CAN-06-1736; Krishnan VG, 2003, BIOINFORMATICS, V19, P2199, DOI 10.1093/bioinformatics/btg297; Lohmueller KE, 2003, NAT GENET, V33, P177, DOI 10.1038/ng1071; Masso M, 2006, PROTEINS, V64, P234, DOI 10.1002/prot.20968; Masso M, 2003, BIOCHEM BIOPH RES CO, V305, P322, DOI 10.1016/S0006-291X(03)00760-5; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; MEDVEDEV NN, 1988, J PHYS A-MATH GEN, V21, pL247, DOI 10.1088/0305-4470/21/4/011; Needham CJ, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-405; Negnevitsky M., 2005, ARTIFICIAL INTELLIGE; Ng PC, 2003, NUCLEIC ACIDS RES, V31, P3812, DOI 10.1093/nar/gkg509; Ramensky V, 2002, NUCLEIC ACIDS RES, V30, P3894, DOI 10.1093/nar/gkf493; RISCH N, 1996, SCIENCE, V273, P1517; Saunders CT, 2002, J MOL BIOL, V322, P891, DOI 10.1016/S0022-2836(02)00813-6; Singh RK, 1996, J COMPUT BIOL, V3, P213, DOI 10.1089/cmb.1996.3.213; Stitziel NO, 2003, J MOL BIOL, V327, P1021, DOI 10.1016/S0022-2836(03)00240-7; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116; Tomita Y, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-120; Vaisman I. I., 1998, Proceedings. IEEE International Joint Symposia on Intelligence and Systems (Cat. No.98EX174), DOI 10.1109/IJSIS.1998.685437; Wang Z, 2001, HUM MUTAT, V17, P263, DOI 10.1002/humu.22; Witten I. H., 2005, DATA MINING; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210; Yip YL, 2004, HUM MUTAT, V23, P464, DOI 10.1002/humu.20021; Yue P, 2005, J MOL BIOL, V353, P459, DOI 10.1016/j.jmb.2005.08.020; Yue P, 2006, J MOL BIOL, V356, P1263, DOI 10.1016/j.jmb.2005.12.025	43	11	11	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0887-3585		PROTEINS	Proteins	JUN	2008	71	4					1930	1939		10.1002/prot.21838		10	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	301UH	WOS:000255920600027	
J	Olden, JD; Lawler, JJ; Poff, NL				Olden, Julian D.; Lawler, Joshua J.; Poff, N. Leroy			Machine learning methods without tears: A primer for ecologists	QUARTERLY REVIEW OF BIOLOGY			English	Review						ecological informatics; classification and regression trees; artificial neural networks; evolutionary algorithms; genetic algorithms; GARP; inductive modeling	ARTIFICIAL NEURAL-NETWORKS; SPECIES GEOGRAPHIC DISTRIBUTIONS; DISTRIBUTION MODELS; GENETIC ALGORITHMS; REGRESSION TREES; FISH DIVERSITY; PREDICTION; CLASSIFICATION; CONSERVATION; HABITAT	Machine learning methods, a family of statistical techniques with origins in the field of artificial intelligence, are recognized as holding great promise far the advancement of understanding and prediction about ecological phenomena. These modeling techniques are flexible enough to handle complex problems with multiple interacting elements and typically outcompete traditional approaches (e.g., generalized linear models), making them ideal for modi ling ecological systems. Despite their inherent advantages, a review of the literature reveals only a modest use of these approaches in ecology as compared to other disciplines. One potential explanation for this lack of interest is that machine learning techniques do not fall neatly into the class of statistical, modeling approaches with which most ecologists are familiar In this paper, we provide an introduction three machine learning approaches that can be broadly used by ecologists: classification and regression trees, artificial neural networks, and evolutionary computation. For each approach, we provide a brief background to the methodology, give examples of its application in ecology, describe model development and implementation, discuss strengths and weaknesses, explore the availability of statistical of software, and provide an illustrative	[Olden, Julian D.] Univ Washington, Sch Aquat & Fishery Sci, Seattle, WA 98195 USA; [Lawler, Joshua J.] Univ Washington, Coll Forest Resources, Seattle, WA 98195 USA; [Poff, N. Leroy] Colorado State Univ, Dept Biol, Ft Collins, CO 80523 USA	Olden, JD (reprint author), Univ Washington, Sch Aquat & Fishery Sci, Seattle, WA 98195 USA.	olden@u.washington.edu; jlawler@u.washington-edu; poff@lamar.colostate.edu	Poff, Nathan/C-1239-2009; Olden, Julian/A-8535-2010				Andersen MC, 2000, ECOL APPL, V10, P890, DOI 10.2307/2641053; Anderson RP, 2004, BIOL CONSERV, V116, P167, DOI 10.1016/S0006-3207(03)00187-3; Austin M, 2007, ECOL MODEL, V200, P1, DOI 10.1016/j.ecolmodel.2006.07.005; BELL JF, 1999, MACHINE LEARNING MET, P89; Bishop C.M., 1995, NEURAL NETWORKS PATT; Breiman L, 1984, CLASSIFICATION REGRE; Brosse S, 2001, NEW ZEAL J MAR FRESH, V35, P135; Chen DG, 2000, CAN J FISH AQUAT SCI, V57, P1878, DOI 10.1139/cjfas-57-9-1878; Cho EC, 2006, ECOL INFORM, V1, P229, DOI 10.1016/j.ecoinf.2006.05.001; Clark JS, 2001, SCIENCE, V293, P657, DOI 10.1126/science.293.5530.657; Cornuet JM, 1996, CR ACAD SCI III-VIE, V319, P1167; CUSHING JB, 2005, P LECT NOTES COMPUTE, V3615, P325; Cutler DR, 2007, ECOLOGY, V88, P2783, DOI 10.1890/07-0539.1; DANGELO DJ, 1995, CAN J FISH AQUAT SCI, V52, P1893, DOI 10.1139/f95-782; De'ath G, 2007, ECOLOGY, V88, P243, DOI 10.1890/0012-9658(2007)88[243:BTFEMA]2.0.CO;2; De'ath G, 2000, ECOLOGY, V81, P3178, DOI 10.1890/0012-9658(2000)081[3178:CARTAP]2.0.CO;2; DIMOPOULOS Y, 1995, NEURAL PROCESS LETT, V2, P1, DOI 10.1007/BF02309007; Drake JM, 2006, FISHERIES, V31, P9, DOI 10.1577/1548-8446(2006)31[9:FPDONS]2.0.CO;2; Drake JM, 2006, J APPL ECOL, V43, P424, DOI 10.1111/j.1365-2664.2006.01141.x; Elith J, 2007, DIVERS DISTRIB, V13, P265, DOI 10.1111/j.1472-4642.2007.00340.x; Elith J, 2006, ECOGRAPHY, V29, P129, DOI 10.1111/j.2006.0906-7590.04596.x; Ferrier S, 2006, J APPL ECOL, V43, P393, DOI 10.1111/j.1365-2664.2006.01149.x; Fielding AH, 1997, ENVIRON CONSERV, V24, P38, DOI 10.1017/S0376892997000088; Fielding A.H., 1999, MACHINE LEARNING MET; Garson G. D., 1991, AI EXPERT, V6, P46; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Gevrey M, 2003, ECOL MODEL, V160, P249, DOI 10.1016/S0304-3800(02)00257-0; Goldberg DE, 1989, GENETIC ALGORITHMS S; Green JL, 2005, BIOSCIENCE, V55, P501, DOI 10.1641/0006-3568(2005)055[0501:CIEACM]2.0.CO;2; Guegan JF, 1998, NATURE, V391, P382, DOI 10.1038/34899; Guisan A, 2000, ECOL MODEL, V135, P147, DOI 10.1016/S0304-3800(00)00354-9; Haefner J. W., 2005, MODELING BIOL SYSTEM; Hastie T, 2001, ELEMENTS STAT LEARNI; HOGEWEG P, 1988, APPL MATH COMPUT, V27, P81, DOI 10.1016/0096-3003(88)90100-2; Holland J., 1975, ADAPTATION NATURAL A; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Iverson LR, 1998, ECOL MONOGR, V68, P465, DOI 10.1890/0012-9615(1998)068[0465:PAOTSF]2.0.CO;2; Iverson LR, 2007, LANDSCAPE ECOL, V22, P323, DOI 10.1007/s10980-006-9062-6; KOHONEN I, 2001, SELF ORG MAPS; Koza J. R., 1992, GENETIC PROGRAMMING; Lamon EC, 1999, CAN J FISH AQUAT SCI, V56, P71, DOI 10.1139/cjfas-56-S1-71; Lawler JJ, 2006, GLOBAL CHANGE BIOL, V12, P1568, DOI 10.1111/j.1365-2486.2006.01191.x; Lek S., 2000, ARTIFICIAL NEURONAL; Lek S, 1996, ECOL MODEL, V90, P39, DOI 10.1016/0304-3800(95)00142-5; Levin SA, 1998, ECOSYSTEMS, V1, P431, DOI 10.1007/s100219900037; Maier HR, 2000, ENVIRON MODELL SOFTW, V15, P101, DOI 10.1016/S1364-8152(99)00007-9; Mastrorillo S, 1997, FRESHWATER BIOL, V38, P237, DOI 10.1046/j.1365-2427.1997.00209.x; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; McKay RI, 2001, ECOL MODEL, V146, P231, DOI 10.1016/S0304-3800(01)00309-X; McKenna JE, 2005, T AM FISH SOC, V134, P28, DOI 10.1577/FT04-044.1; Mercado-Silva N, 2006, CONSERV BIOL, V20, P1740, DOI 10.1111/j.1523-1739.2006.00508.x; MINNS CK, 1989, T AM FISH SOC, V118, P533, DOI 10.1577/1548-8659(1989)118<0533:FAFSRI>2.3.CO;2; Mitchell M., 1998, INTRO GENETIC ALGORI; MORGAN JN, 1963, J AM STAT ASSOC, V58, P415, DOI 10.2307/2283276; Muttil N, 2005, ECOL MODEL, V189, P363, DOI 10.1016/j.ecolmodel.2005.03.018; O'Connor Raymond J., 1996, Biodiversity Letters, V3, P97, DOI 10.2307/2999723; Olden JD, 2006, ECOL INFORM, V1, P33, DOI 10.1016/j.ecoinf.2005.08.003; Olden JD, 2002, FRESHWATER BIOL, V47, P1976, DOI 10.1046/j.1365-2427.2002.00945.x; Olden JD, 2004, ECOL MODEL, V178, P389, DOI 10.1016/j.ecolmodel.2004.03.013; Olden JD, 2006, ECOL APPL, V16, P1449, DOI 10.1890/1051-0761(2006)016[1449:RTSICP]2.0.CO;2; Olden JD, 2001, T AM FISH SOC, V130, P878, DOI 10.1577/1548-8659(2001)130<0878:FHRILG>2.0.CO;2; Olden JD, 2002, ECOL MODEL, V154, P135, DOI 10.1016/S0304-3800(02)00064-9; Olden JD, 2003, CONSERV BIOL, V17, P854, DOI 10.1046/j.1523-1739.2003.01280.x; Ozesmi SL, 1999, ECOL MODEL, V116, P15, DOI 10.1016/S0304-3800(98)00149-5; Ozesmi SL, 2006, ECOL MODEL, V195, P83, DOI 10.1016/j.ecolmodel.2005.11.012; Park YS, 2007, ECOL MODEL, V203, P1, DOI 10.1016/j.ecolmodel.2006.05.039; Peters R.H., 1991, CRITIQUE ECOLOGY; Peterson AT, 2003, Q REV BIOL, V78, P419, DOI 10.1086/378926; Peterson AT, 2001, CONDOR, V103, P599, DOI 10.1650/0010-5422(2001)103[0599:PSGDBO]2.0.CO;2; Peterson AT, 2007, ECOL MODEL, V203, P527, DOI 10.1016/j.ecolmodel.2006.12.023; Peterson AT, 2001, BIOSCIENCE, V51, P363, DOI 10.1641/0006-3568(2001)051[0363:PSIUEN]2.0.CO;2; Phillips SJ, 2006, ECOL MODEL, V190, P231, DOI 10.1016/j.ecolmodel.2005.03.026; RECKNAGEL F, 2003, ECOLOGICAL INFORM UN; Recknagel F, 2001, ECOL MODEL, V146, P303, DOI 10.1016/S0304-3800(01)00316-7; Ripley B. D, 1996, PATTERN RECOGNITION; Rollins MG, 2004, ECOL APPL, V14, P75, DOI 10.1890/02-5145; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salski A., 1991, LECT NOTES COMPUTER, V521, P520; Sarkar S, 2006, ANNU REV ENV RESOUR, V31, P123, DOI 10.1146/annurev.energy.31.042606.085844; Scardi M, 1999, ECOL MODEL, V120, P213, DOI 10.1016/S0304-3800(99)00103-9; Smith SJ, 1997, CAN J FISH AQUAT SCI, V54, P1377, DOI 10.1139/cjfas-54-6-1377; Spitz F, 1999, J APPL ECOL, V36, P317, DOI 10.1046/j.1365-2664.1999.00400.x; Stockwell DRB, 2006, ECOL MODEL, V192, P188, DOI 10.1016/j.ecolmodel.2005.05.029; STOCKWELL DRB, 1992, MATH COMPUT SIMULAT, V33, P385, DOI 10.1016/0378-4754(92)90126-2; STOCKWELL RB, 1999, INT J GEOGR INF SYST, V13, P143; Sutton CD, 2005, HANDB STAT, V24, P303, DOI 10.1016/S0169-7161(04)24011-1; Termansen M, 2006, ECOL MODEL, V192, P410, DOI 10.1016/j.ecolmodel.2005.07.009; Thuiller W, 2003, GLOBAL CHANGE BIOL, V9, P1353, DOI 10.1046/j.1365-2486.2003.00666.x; Torres LG, 2003, MAR MAMMAL SCI, V19, P502, DOI 10.1111/j.1748-7692.2003.tb01317.x; Usio N, 2007, BIOL CONSERV, V134, P517, DOI 10.1016/j.biocon.2006.09.002; Vander Zanden MJ, 2004, ECOL APPL, V14, P132; Worner SP, 2006, J APPL ECOL, V43, P858, DOI 10.1111/j.1365-2664.2006.01202.x	93	64	66	UNIV CHICAGO PRESS	CHICAGO	1427 E 60TH ST, CHICAGO, IL 60637-2954 USA	0033-5770		Q REV BIOL	Q. Rev. Biol.	JUN	2008	83	2					171	193		10.1086/587826		23	Biology	Life Sciences & Biomedicine - Other Topics	312UV	WOS:000256697400002	
J	Vossen, P				Vossen, Piek			Linguistic knowledge for more precision, richer answers and flexible systems	REVUE FRANCAISE DE LINGUISTIQUE APPLIQUEE			English	Article								Irion Technologies is a language technology company at Delft (The Netherlands) that incorporates linguistic knowledge to build new generations of information systems: conceptual retrieval, automatic extraction of terms and ontologies and open-domain dialogue systems. These systems are multi-lingual and cross-lingual and combine statistical, machine learning techniques with linguistic techniques. We have carried out evaluations of some of these systems. For information retrieval, we found advantages with respect to standard statistical approaches within special experimental settings that focus on ambiguity. Term extraction is clearly benefiting from rich linguistic knowledge and resources. Dialogue systems depend on the communicative models and systems that also require deep linguistic processing. From our perspective, language technology is definitely helping to make applications better and necessary to develop new applications.	[Vossen, Piek] Vrije Univ Amsterdam, Fac Letteren, NL-1081 HV Amsterdam, Netherlands; [Vossen, Piek] Irion Technol, NL-2601 CV Delft, Netherlands	Vossen, P (reprint author), Vrije Univ Amsterdam, Fac Letteren, De Boelelaan 1105, NL-1081 HV Amsterdam, Netherlands.	p.vossen@let.vu.nl					Atserias J., 2004, P 2 GLOB WORDNET C G, P23; BASILI R, 2007, P REC ADV NAT LANG P; Fellbaum C., 1998, WORDNET ELECT LEXICA; GONZALO J, 1999, P EMP METH NAT LANG; HIEMSTRA D, 1998, NIST SPECIAL PUBLICA, P500; KROVETZ B, 1997, P EACL MADR, P72; KROVETZ B, 2002, P WORKSH CREAT US SE; MAGNINI B, 2002, P 2 INT C LANG RES E; Morin E, 2004, COMPUT HUMANITIES, V38, P363, DOI 10.1007/s10579-004-1926-2; MORIN E, 1999, 37 ANN M ASS COMP LI, P389; Resnik P, 2006, TEXT SPEECH LANG TEC, V33, P299, DOI 10.1007/1-4020-4809-2_11; VOORHEES EM, 1999, INFORM EXTRACTION SC; VOSSEN P, 2006, P 3 GLOB WORDN C, P22; VOSSEN P, 2001, P WORKSH WORDNET OTH; Vossen P., 1998, EUROWORDNET MULTILIN	15	0	0	PUBLICATIONS LINGUISTIQUES	PARIS	15 RUE LAKANAL, PARIS, 75015, FRANCE	1386-1204		REV FR LING APPL	Rev. Fr. Ling. Appl.	JUN	2008	13	1					23	39				17	Linguistics; Language & Linguistics	Linguistics	378EL	WOS:000261303900003	
J	Clavel, C; Vasilescu, I; Devillers, L; Richard, G; Ehrette, T				Clavel, C.; Vasilescu, I.; Devillers, L.; Richard, G.; Ehrette, T.			Fear-type emotion recognition for future audio-based surveillance systems	SPEECH COMMUNICATION			English	Article						fear-type emotions recognition; fiction corpus; annotation scheme; acoustic features of emotions; machine learning; threatening situations; civil safety	SPEECH; COMMUNICATION; EXPRESSION; ALGORITHM	This paper addresses the issue of automatic emotion recognition in speech. We focus on a type of emotional manifestation which has been rarely studied in speech processing: fear-type emotions occurring during abnormal situations (here, unplanned events where human life is threatened). This study is dedicated to a new application in emotion recognition - public safety. The starting point of this work is the definition and the collection of data illustrating extreme emotional manifestations in threatening situations. For this purpose we develop the SAFE corpus (situation analysis in a fictional and emotional corpus) based on fiction movies. It consists of 7 h of recordings organized into 400 audiovisual sequences. The corpus contains recordings of both normal and abnormal situations and provides a large scope of contexts and therefore a large scope of emotional manifestations. In this way, not only it addresses the issue of the lack of corpora illustrating strong emotions, but also it forms an interesting support to study a high variety of emotional manifestations. We define a task-dependent annotation strategy which has the particularity to describe simultaneously the emotion and the situation evolution in context. The emotion recognition system is based on these data and must handle a large scope of unknown speakers and situations in noisy sound environments. It consists of a fear vs. neutral classification. The novelty of our approach relies on dissociated acoustic models of the voiced and unvoiced contents of speech. The two are then merged at the decision step of the classification system. The results are quite promising given the complexity and the diversity of the data: the error rate is about 30%. (C) 2008 Elsevier B.V. All rights reserved.	[Clavel, C.; Ehrette, T.] Thales Res & Technol France, F-91767 Palaiseau, France; [Vasilescu, I.; Devillers, L.] LIMSI CNRS, F-91403 Orsay, France; [Richard, G.] Telecom ParisTech, F-75014 Paris, France	Clavel, C (reprint author), Thales Res & Technol France, RD 128, F-91767 Palaiseau, France.	chloe.clavel@thalesgroup.com					Allwood J., 2000, P ISCA ITRW SPEECH E, P110; AMIR N, 2007, P AFF COMP INT INT L, P148; Auberge V., 2004, P 4 INT C LANG RES E, P179; Bakeman R, 1997, OBSERVING INTERACTIO; Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614; Banziger T, 2006, P LREC WORKSH CORP R, P15; Batliner A., 2006, P IS LTC 2006 LJUBL, P240; Batliner A., 2004, P 4 INT C LANG RES E, P171; Batliner A, 2003, SPEECH COMMUN, V40, P117, DOI 10.1016/S0167-6393(02)00079-1; Bengio S., 2004, P OD 2004 SPEAK LANG; Boersma Paul, 2005, PRAAT DOING PHONETIC; Breazeal C, 2002, AUTON ROBOT, V12, P83, DOI 10.1023/A:1013215010749; Campbell N., 2003, P 15 INT C PHON SCI, P2417; Carletta J, 1996, COMPUT LINGUIST, V22, P249; CLAVEL C, 2006, P LREC GEN, P1099; Clavel C., 2005, P IEEE INT C MULT EX, P1306; CLAVEL C, 2004, P ICSLP JEJ, P2277; CLAVEL C, 2007, P ICASSP HON, P21; CLAVEL C, 2006, P SPEECH PROS PS6 10; Cowie R, 2003, SPEECH COMMUN, V40, P5, DOI 10.1016/S0167-6393(02)00071-7; CRONBACH LJ, 1951, PSYCHOMETRIKA, V16, P297; Damasio Antonio R., 1994, DESCARTES ERROR EMOT; DARWIN C., 1872, EXPRESSION EMOTIONS; Dellaert F., 1996, Proceedings ICSLP 96. Fourth International Conference on Spoken Language Processing (Cat. No.96TH8206), DOI 10.1109/ICSLP.1996.608022; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Devillers L, 2005, NEURAL NETWORKS, V18, P407, DOI 10.1016/j.neunet.2005.03.007; Devillers L., 2003, P EUR GEN, P189; DEVILLERS L, 2007, SPEAKER CHARACTERIZA; DEVILLERS L, 2005, P 1 INT C AFF COMP I, P519; DEVILLERS L, 2006, THESIS U PARIS 11 OR; Douglas-Cowie E, 2003, SPEECH COMMUN, V40, P33, DOI 10.1016/S0167-6393(02)00070-5; Duda R.O, 1973, PATTERN CLASSIFICATI; Ekman P., 1975, UNMASKING FACE GUIDE; Ekman P., 1999, BASIC EMOTIONS HDB C; Enos F., 2006, P LREC WORKSH CORP R, P6; Fernandez R, 2003, SPEECH COMMUN, V40, P145, DOI 10.1016/S0167-6393(02)00080-8; FRANCE D, 2003, IEEE T BIOMEDICAL EN, V47, P829; Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770; KIENAST M, 2000, P ISCA ITRW SPEECH E, P92; Kipp M., 2001, P 7 EUR C SPEECH COM, P1367; KLEIBER G., 1990, SEMANTIQUE PROTOTYPE; Kwon O.W., 2003, P EUROSPEECH, P125; LANDIS JR, 1977, BIOMETRICS, V33, P174; LEE CM, 1997, INFORM COMM SIGNAL P, V1, P347; LEE CM, 2002, P INT C MULT EXP LAU, P737; MCGILLOWAY S, 1997, THESIS QUEENS U BELF; MOZZICONACCI S, 1998, THESIS TU EIDHOVEN; Nunnaly J., 1978, PSYCHOMETRIC THEORY; ORTHONY A, 1990, PSYCHOL REV, V97, P315; Osgood C. E., 1975, CROSS CULTURAL UNIVE; Oudeyer P., 2003, INT J HUMAN COMPUTER, V59, P157, DOI DOI 10.1016/S1071-581(02)00141-6; Pelachaud C., 2005, P 13 ANN ACM INT C M, P683, DOI 10.1145/1101149.1101301; Picard R. W., 1997, AFFECTIVE COMPUTING; PLUTCHIK R, 1984, GEN PSYCHOEVOLUTIONA; Rosenthal R., 2005, NEW HDB METHODS NONV; RUSSELL JA, 1997, SHALL EMOTION BE CAL; Scherer K. R., 1984, NATURE FUNCTION EMOT; Scherer K. R., 2001, APPRAISAL PROCESSES; Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5; SCHERER U, 1980, INTERNAL PUSH EXTERN; SCHROEDER M, 2007, P ACIL LISB, P440; SCHULLER B, 2004, P ICASSP MONTR, P80; Schuller B, 2003, P ICASSP HONG KONG, P1; SHAFRAN I, 2003, P IEEE AUT SPEECH RE, P31; Vacher M, 2004, Proceedings of the Second IASTED International Conference on Biomedical Engineering, P395; van Bezooijen R., 1984, CHARACTERISTICS RECO; VARADARAJAN V, 2006, P LREC WORKSH CORP R, P72; Vidrascu L., 2005, P INT LISB PORT SEPT, P1841; WAGNER J, 2007, P ACII LISB, P114; WHISSEL C, 1989, DICT AFFECT LANGUAGE; Yacoub S, 2003, P EUROSPEECH, P729; Yegnanarayana B, 1998, IEEE T SPEECH AUDI P, V6, P1, DOI 10.1109/89.650304	72	21	23	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-6393		SPEECH COMMUN	Speech Commun.	JUN	2008	50	6					487	503		10.1016/j.specom.2008.03.012		17	Acoustics; Communication; Computer Science, Interdisciplinary Applications; Language & Linguistics	Acoustics; Communication; Computer Science; Linguistics	321HY	WOS:000257296600004	
J	Gesell, T; Washietl, S				Gesell, Tanja; Washietl, Stefan			Dinucleotide controlled null models for comparative RNA gene prediction	BMC BIOINFORMATICS			English	Article							DNA-SEQUENCE EVOLUTION; NONCODING RNAS; SECONDARY STRUCTURE; MAXIMUM-LIKELIHOOD; COMPARATIVE GENOMICS; SUBSTITUTION RATES; DEPENDENT-RATES; ALIGNMENT; ALGORITHM; IDENTIFICATION	Background: Comparative prediction of RNA structures can be used to identify functional noncoding RNAs in genomic screens. It was shown recently by Babak et al. [BMC Bioinformatics. 8: 33] that RNA gene prediction programs can be biased by the genomic dinucleotide content, in particular those programs using a thermodynamic folding model including stacking energies. As a consequence, there is need for dinucleotide-preserving control strategies to assess the significance of such predictions. While there have been randomization algorithms for single sequences for many years, the problem has remained challenging for multiple alignments and there is currently no algorithm available. Results: We present a program called SISSIz that simulates multiple alignments of a given average dinucleotide content. Meeting additional requirements of an accurate null model, the randomized alignments are on average of the same sequence diversity and preserve local conservation and gap patterns. We make use of a phylogenetic substitution model that includes overlapping dependencies and site-specific rates. Using fast heuristics and a distance based approach, a tree is estimated under this model which is used to guide the simulations. The new algorithm is tested on vertebrate genomic alignments and the effect on RNA structure predictions is studied. In addition, we directly combined the new null model with the RNAalifold consensus folding algorithm giving a new variant of a thermodynamic structure based RNA gene finding program that is not biased by the dinucleotide content. Conclusion: SISSIz implements an efficient algorithm to randomize multiple alignments preserving dinucleotide content. It can be used to get more accurate estimates of false positive rates of existing programs, to produce negative controls for the training of machine learning based programs, or as standalone RNA gene finding program. Other applications in comparative genomics that require randomization of multiple alignments can be considered. Availability: SISSIz is available as open source C code that can be compiled for every major platform and downloaded here: http:// sourceforge. net/ projects/ sissiz.	[Washietl, Stefan] Univ Vienna, Inst Theoret Chem, A-1090 Vienna, Austria; [Gesell, Tanja] Ctr Integrat Bioinformat Vienna, Max F Perutz Labs, Vienna, Austria; [Gesell, Tanja] Med Univ Vienna, Vienna, Austria; [Gesell, Tanja] Vet Univ Vienna, A-1030 Vienna, Austria; [Washietl, Stefan] EMBL European Bioinformat Inst, Cambridge CB10 1SD, England	Washietl, S (reprint author), Univ Vienna, Inst Theoret Chem, Wahringerstr 17, A-1090 Vienna, Austria.	tanja.gesell@univie.ac.at; washietl@ebi.ac.uk					ALTSCHUL SF, 1985, MOL BIOL EVOL, V2, P526; Arndt PF, 2003, J COMPUT BIOL, V10, P313, DOI 10.1089/10665270360688039; ATHANASIUS F, 2007, J EXP ZOOL PART B, V308, P1; AXMANN IM, 2005, GENOME BIOL, V6; Babak T, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-33; Blanchette M, 2004, GENOME RES, V14, P708, DOI 10.1101/gr.1933104; CHRISTENSEN OF, 2006, STAT APPL GENET MOL, V5, P1; Clote P, 2005, RNA, V11, P578, DOI 10.1261/rna.7220505; Coventry A, 2004, P NATL ACAD SCI USA, V101, P12102, DOI 10.1073/pnas.0404193101; del Val C, 2007, MOL MICROBIOL, V66, P1080, DOI 10.1111/j.1365-2958.2007.05978.x; Duret L, 2000, MOL BIOL EVOL, V17, P1620; Felsenstein J., 2004, INFERRING PHYLOGENIE; Fleissner R, 2005, SYST BIOL, V54, P548, DOI 10.1080/10635150590950371; Forsdyke DR, 2007, J THEOR BIOL, V248, P745, DOI 10.1016/j.jtbi.2007.07.008; Gascuel O, 1997, MOL BIOL EVOL, V14, P685; Gesell T, 2006, BIOINFORMATICS, V22, P716, DOI 10.1093/bioinformatics/bti812; Griffiths-Jones S, 2007, ANNU REV GENOM HUM G, V8, P279, DOI 10.1146/annurev.genom.8.080706.092419; Griffiths-Jones S, 2005, NUCLEIC ACIDS RES, V33, pD121, DOI 10.1093/nar/gri081; Guindon S, 2003, SYST BIOL, V52, P696, DOI 10.1080/10635150390235520; HASEGAWA M, 1985, J MOL EVOL, V22, P160, DOI 10.1007/BF02101694; Hofacker IL, 2002, J MOL BIOL, V319, P1059, DOI 10.1016/S0022-2836(02)00308-X; Jensen JL, 2000, ADV APPL PROBAB, V32, P499; KAROLCHIK D, 2007, NUCL ACIDS RES; Levmar, LEVMAR LEVENBERG MAR; Lunter G, 2004, BIOINFORMATICS, V20, P216, DOI 10.1093/bioinformatics/bth901; Metzler D, 2003, BIOINFORMATICS, V19, P490, DOI 10.1093/bioinformatics/btg026; Miklos I, 2004, MOL BIOL EVOL, V21, P529, DOI 10.1093/molbev.msh043; Missal K, 2005, BIOINFORMATICS, V21, P77, DOI 10.1093/bioinformatics/bti1113; Missal K, 2006, J EXP ZOOL PART B, V306B, P379, DOI 10.1002/jez.b.21086; MOURIER T, 2007, GENOME RES; Pedersen AMK, 2001, MOL BIOL EVOL, V18, P763; PEDERSEN JS, 2006, PLOS COMPUT BIOL, V2; PEER Y, 2000, J MOL EVOL, V51, P565; Rambaut A, 1997, COMPUT APPL BIOSCI, V13, P235; Rivas E, 2001, BMC Bioinformatics, V2, P8, DOI 10.1186/1471-2105-2-8; Robinson DM, 2003, MOL BIOL EVOL, V20, P1692, DOI 10.1093/molbev/msg184; Rose D, 2007, BMC GENOMICS, V8, DOI 10.1186/1471-2164-8-406; LANAVE C, 1984, J MOL EVOL, V20, P86, DOI 10.1007/BF02101990; SANDMANN T, 2007, PLOS ONE, V2; SCHONIGER M, 1994, MOL PHYLOGENET EVOL, V3, P240, DOI 10.1006/mpev.1994.1026; SCHONIGER M, 1995, COMPUT APPL BIOSCI, V11, P111; Siepel A, 2004, MOL BIOL EVOL, V21, P468, DOI 10.1093/molbev/msh039; Tavare S., 1986, LECTURES MATH LIFE S, P57; THORNE JL, 1991, J MOL EVOL, V33, P114, DOI 10.1007/BF02193625; THORNE JL, 1992, J MOL EVOL, V34, P3, DOI 10.1007/BF00163848; Torarinsson E, 2006, GENOME RES, V16, P885, DOI 10.1101/gr.5226606; Uzilov AV, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-173; Washietl Stefan, 2007, V395, P503; Washietl S, 2004, J MOL BIOL, V342, P19, DOI 10.1016/j.jmb.2004.07.018; Washietl S, 2005, NAT BIOTECHNOL, V23, P1383, DOI 10.1038/ndt1144; Washietl S, 2007, GENOME RES, V17, P852, DOI 10.1101/gr.5650707; Washietl S, 2005, P NATL ACAD SCI USA, V102, P2454, DOI 10.1073/pnas.0409169102; Weile C, 2007, BMC GENOMICS, V8, DOI 10.1186/1471-2164-8-244; Workman C, 1999, NUCLEIC ACIDS RES, V27, P4816, DOI 10.1093/nar/27.24.4816; Yao ZZ, 2006, BIOINFORMATICS, V22, P445, DOI 10.1093/bioinformatics/btk008; [Anonymous], UCSC GENOME BROWSER; [Anonymous], VIENNA RNA PACKAGE; RNAZ PREDICTING STRU; ALIFOLDZ SHUFFLE ALN; SEA GEN	60	20	22	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	MAY 27	2008	9								248	10.1186/1471-2105-9-248		16	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	326IV	WOS:000257652800001	
J	Varshavsky, R; Horn, D; Linial, M				Varshavsky, Roy; Horn, David; Linial, Michal			Global Considerations in Hierarchical Clustering Reveal Meaningful Patterns in Data	PLOS ONE			English	Article								Background: A hierarchy, characterized by tree-like relationships, is a natural method of organizing data in various domains. When considering an unsupervised machine learning routine, such as clustering, a bottom-up hierarchical (BU, agglomerative) algorithm is used as a default and is often the only method applied. Methodology/Principal Findings: We show that hierarchical clustering that involve global considerations, such as topdown (TD, divisive), or glocal (global-local) algorithms are better suited to reveal meaningful patterns in the data. This is demonstrated, by testing the correspondence between the results of several algorithms (TD, glocal and BU) and the correct annotations provided by experts. The correspondence was tested in multiple domains including gene expression experiments, stock trade records and functional protein families. The performance of each of the algorithms is evaluated by statistical criteria that are assigned to clusters (nodes of the hierarchy tree) based on expert-labeled data. Whereas TD algorithms perform better on global patterns, BU algorithms perform well and are advantageous when finer granularity of the data is sought. In addition, a novel TD algorithm that is based on genuine density of the data points is presented and is shown to outperform other divisive and agglomerative methods. Application of the algorithm to more than 500 protein sequences belonging to ion-channels illustrates the potential of the method for inferring overlooked functional annotations. ClustTree, a graphical Matlab toolbox for applying various hierarchical clustering algorithms and testing their quality is made available. Conclusions: Although currently rarely used, global approaches, in particular, TD or glocal algorithms, should be considered in the exploratory process of clustering. In general, applying unsupervised clustering methods can leverage the quality of manually-created mapping of proteins families. As demonstrated, it can also provide insights in erroneous and missed annotations.	[Varshavsky, Roy] Hebrew Univ Jerusalem, Sch Engn & Comp Sci, Jerusalem, Israel; [Horn, David] Tel Aviv Univ, Sch Phys & Astron, Tel Aviv, Israel; [Linial, Michal] Hebrew Univ Jerusalem, Inst Life Sci, Dept Biol Chem, Jerusalem, Israel	Varshavsky, R (reprint author), Hebrew Univ Jerusalem, Sch Engn & Comp Sci, Jerusalem, Israel.	roy.varshavsky@mail.huji.ac.il			Sudarsky Center for Computational Biology at the Hebrew University of Jerusalem; EU Framework VI consortium	R.V. is supported by SCCB, the Sudarsky Center for Computational Biology at the Hebrew University of Jerusalem. This study was supported by the EU Framework VI consortium.	Alter O, 2000, P NATL ACAD SCI USA, V97, P10101, DOI 10.1073/pnas.97.18.10101; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Apweiler R, 2001, NUCLEIC ACIDS RES, V29, P44, DOI 10.1093/nar/29.1.44; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; BERRIDGE M, 2004, CONFORMATIONAL COUPL, pPE33; BOLEY D, 1998, PRINCIPAL DIRECTION, P325; Cangelosi R, 2007, BIOL DIRECT, V2, DOI 10.1186/1745-6150-2-2; Chipman H, 2006, BIOSTATISTICS, V7, P286, DOI 10.1093/biostatistics/kxj007; CIMIANO P, 2004, COMPARING CONCEPTUAL, P435; D'haeseleer P, 2005, NAT BIOTECHNOL, V23, P1499, DOI 10.1038/nbt1205-1499; Duda R., 2000, PATTERN CLASSIFICATI; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Getz G, 2000, P NATL ACAD SCI USA, V97, P12079, DOI 10.1073/pnas.210134797; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Handl J, 2005, BIOINFORMATICS, V21, P3201, DOI 10.1093/bioinformatics/bti517; HANSEN P, 1978, J AM STAT ASSOC, V73, P397, DOI 10.2307/2286672; HORN D, 2002, PHYS REV LETT, V88; Horn D, 2003, BIOINFORMATICS, V19, P1110, DOI 10.1093/bioinformatics/btg053; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Kaczmarek LK, 2006, NAT REV NEUROSCI, V7, P761, DOI 10.1038/nrn1988; Kaplan N, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-196; Kruskal J. B., 1981, MULTIDIMENSIONAL SCA; Landauer TK, 1998, DISCOURSE PROCESS, V25, P259; ORLOWSKI J, 2004, EUR J PHYSL, V447, P549; Owsianik G, 2006, ANNU REV PHYSIOL, V68, P685, DOI 10.1146/annurev.physiol.68.040204.101406; Planet PJ, 2001, GENOME RES, V11, P1149, DOI 10.1101/gr.187601; Ren QH, 2005, PLOS COMPUT BIOL, V1, P190, DOI 10.1371/journal.pcbi.0010027; RUNE M, 2007, PROTEOMICS, V7, P2815; Sasson O, 2003, NUCLEIC ACIDS RES, V31, P348, DOI 10.1093/nar/gkg096; SAVARESI MS, 2004, INTELL DATA ANAL, V8, P345; SHARAN R, 2000, ISMB 00, P307; Slonim N, 2005, P NATL ACAD SCI USA, V102, P18297, DOI 10.1073/pnas.0507432102; STEINBACH M, 2000, COMPARISON DOCUMENT; Torrente A, 2005, BIOINFORMATICS, V21, P3993, DOI 10.1093/bioinformatics/bti644; Varshavsky R, 2007, LECT N BIOINFORMAT, V4463, P85; Varshavsky R, 2005, LECT NOTES COMPUT SC, V3759, P159; Zhao Y., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; ZORUMSKI CF, 1992, PROG NEUROBIOL, V39, P295, DOI 10.1016/0301-0082(92)90020-F; *MATH WORLD, 2007, MATL STAT TOOLB 6 1	39	5	5	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	185 BERRY ST, STE 1300, SAN FRANCISCO, CA 94107 USA	1932-6203		PLOS ONE	PLoS One	MAY 21	2008	3	5							e2247	10.1371/journal.pone.0002247		10	Multidisciplinary Sciences	Science & Technology - Other Topics	391UK	WOS:000262258700054	
J	Lange, S; Zeugmann, T; Zilles, S				Lange, Steffen; Zeugmann, Thomas; Zilles, Sandra			Learning indexed families of recursive languages from positive data: A survey	THEORETICAL COMPUTER SCIENCE			English	Review						inductive inference; formal languages; recursion theory; query learning	ERASING PATTERN LANGUAGES; INDUCTIVE INFERENCE; GRAMMATICAL INFERENCE; CHARACTERISTIC SETS; GOOD EXAMPLES; SIMPLE GRAMMARS; LEARNABILITY; IDENTIFICATION; COMPLEXITY; LEARNERS	In the past 40 years, research on inductive inference has developed along different lines, e.g., in the formalizations used, and in the classes of target concepts considered. One common root of many of these formalizations is Gold's model of identification in the limit. This model has been studied for learning recursive functions, recursively enumerable languages, and recursive languages, reflecting different aspects of machine learning, artificial intelligence, complexity theory, and recursion theory. One line of research focuses on indexed families of recursive languages - classes of recursive languages described in a representation scheme for which the question of membership for any string in any of the given languages is effectively decidable with a uniform procedure. Such language classes are of interest because of their naturalness. The survey at hand picks out important studies on learning indexed families (including basic as well as recent research), summarizes and illustrates the corresponding results, and points out links to related fields such as grammatical inference, machine learning, and artificial intelligence in general. (C) 2008 Elsevier B.V. All rights reserved.	[Zilles, Sandra] Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada; [Lange, Steffen] Hsch Darmstadt, Fachbereich Informat, D-64295 Darmstadt, Germany; [Zeugmann, Thomas] Hokkaido Univ, Div Comp Sci, Sapporo, Hokkaido 0600814, Japan	Zilles, S (reprint author), Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada.	s.lange@fbi.h-da.de; thomas@ist.hokudai.ac.jp; zilles@cs.ualberta.ca					Adriaans P, 2000, LECT NOTES COMPUT SC, V1963, P173; ANGLUIN D, 1980, J COMPUT SYST SCI, V21, P46, DOI 10.1016/0022-0000(80)90041-0; Angluin D, 2004, THEOR COMPUT SCI, V313, P175, DOI 10.1016/j.tcs.2003.11.004; ANGLUIN D, 1982, J ACM, V29, P741, DOI 10.1145/322326.322334; ANGLUIN D, 1980, INFORM CONTROL, V45, P117, DOI 10.1016/S0019-9958(80)90285-5; Angluin D., 1988, Machine Learning, V2, DOI 10.1007/BF00116828; ANGLUIN D, 1987, INFORM COMPUT, V75, P87, DOI 10.1016/0890-5401(87)90052-6; Baliga GR, 1999, INFORM COMPUT, V152, P16, DOI 10.1006/inco.1998.2782; BARZDIN J, 1974, LECT NOTES COMPUTER, V5, P53; BARZDIN J, 1977, AM MATH SOC TRANSL, P107; BARZDIN JM, 1972, INFORMATION PROCESSI, V71, P81; Barzdins J., 1972, SOV MATH DOKL, V13, P1224; BERWICK R, 1985, ACQUISITION SYNTATIC; Bishop C. M., 2006, PATTERN RECOGNITION; BLUM L, 1975, INFORM CONTROL, V28, P125, DOI 10.1016/S0019-9958(75)90261-2; BLUM M, 1967, J ACM, V14, P322, DOI 10.1145/321386.321395; Case J, 2001, THEOR COMPUT SCI, V261, P31, DOI 10.1016/S0304-3975(00)00132-8; CASE J, 1982, LECT NOTES COMPUT SC, V140, P107; Case J, 1999, INFORM COMPUT, V152, P74, DOI 10.1006/inco.1998.2784; Case J, 2001, J COMPUT SYST SCI, V62, P413, DOI 10.1006/jcss./2000.1736; Cicchello O., 2003, J MACHINE LEARNING R, V4, P603; Clark A, 2005, LECT NOTES ARTIF INT, V3734, P283; DALEY RP, 1986, INFORM COMPUT, V69, P12, DOI 10.1016/S0019-9958(86)80042-0; De Jongh D., 1996, Proceedings of the Ninth Annual Conference on Computational Learning Theory, DOI 10.1145/238061.238095; DelaHiguera C, 1997, MACH LEARN, V27, P125, DOI 10.1023/A:1007353007695; de la Higuera C, 2005, PATTERN RECOGN, V38, P1332, DOI 10.1016/j.patcog.2005.01.003; Erlebach T, 2001, THEOR COMPUT SCI, V261, P119, DOI 10.1016/S0304-3975(00)00136-5; FELDMAN J, 1972, INFORM CONTROL, V20, P244, DOI 10.1016/S0019-9958(72)90424-X; FREIVALDS R, 1993, THEOR COMPUT SCI, V110, P131, DOI 10.1016/0304-3975(93)90353-U; Gold E. M, 1965, J SYMBOLIC LOGIC, V30, P28, DOI 10.2307/2270580; GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5; HAUSSLER D, 1991, INFORM COMPUT, V95, P129, DOI 10.1016/0890-5401(91)90042-Z; Hopcroft JE, 1969, FORMAL LANGUAGES THE; Jain S, 2001, J COMPUT SYST SCI, V63, P305, DOI 10.1006/jcss.2001.1759; Jain S, 1998, ANN MATH ARTIF INTEL, V23, P1, DOI 10.1023/A:1018903922049; Jain S, 2001, THEOR COMPUT SCI, V261, P3, DOI 10.1016/S0304-3975(00)00131-6; Jain S, 2000, THEOR COMPUT SCI, V241, P143, DOI 10.1016/S0304-3975(99)00269-8; Jain S, 2006, LECT NOTES ARTIF INT, V4264, P169; Jain Sanjay, 1999, SYSTEMS LEARN INTRO; Kaufmann S., 1997, Proceedings of the Tenth Annual Conference on Computational Learning Theory, DOI 10.1145/267460.267509; Kearns M., 1989, Proceedings of the Second Annual Workshop on Computational Learning Theory; Kearns MJ, 1994, INTRO COMPUTATIONAL; KINBER E, 1995, INFORM COMPUT, V123, P224, DOI 10.1006/inco.1995.1170; KO KI, 1990, P 7 INT C MACH LEARN, P384; KOBAYASHI S, 1997, LECT NOTES ARTIF INT, V1316, P81; KOBAYASHI S, 1996, 9604 CSIM U EL COMM; Koshiba Takeshi, 1995, LECT NOTES ARTIF INT, V904, P367; Lange S, 2003, THEOR COMPUT SCI, V292, P359, DOI 10.1016/S0304-3975(02)00176-7; Lange S, 1996, MATH SYST THEORY, V29, P599, DOI 10.1007/BF01301967; Lange S, 2004, INFORM PROCESS LETT, V91, P285, DOI 10.1016/j.ipl.2004.05.010; Lange S, 1996, THEOR COMPUT SCI, V155, P365, DOI 10.1016/0304-3975(95)00284-7; Lange S, 1998, ANN MATH ARTIF INTEL, V23, P27, DOI 10.1023/A:1018955906119; Lange S, 2005, INFORM COMPUT, V203, P211, DOI 10.1016/j.ic.2005.08.003; Lange S, 2003, LECT NOTES ARTIF INT, V2842, P129; Lange S, 1996, J COMPUT SYST SCI, V53, P88, DOI 10.1006/jcss.1996.0051; LANGE S, 2000, ALGORITHMIC LEARNING; Lange S., 1993, Proceeding of the Sixth Annual ACM Conference on Computational Learning Theory, DOI 10.1145/168304.168320; Lange S, 2004, LECT NOTES COMPUT SC, V3120, P155, DOI 10.1007/978-3-540-27819-1_11; Lange S., 1991, New Generation Computing, V8; Lange S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130427; Littlestone N., 1988, Machine Learning, V2, DOI 10.1007/BF00116827; Mitchell A. R., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279955; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; Mitchell Tom M., 1997, MACH LEARNING; MORIYAMA T, 1995, IEICE T INF SYST, VE78D, P532; Motoki T., 1991, Proceedings of the Fourth Annual Workshop on Computational Learning Theory; NATARAJAN BK, 1991, MACH LEARNING THEORE; Nessel J, 2005, THEOR COMPUT SCI, V348, P41, DOI 10.1016/j.tcs.2005.09.001; Ng YK, 2006, LECT NOTES ARTIF INT, V4201, P307; Ng YK, 2008, THEOR COMPUT SCI, V397, P150, DOI 10.1016/j.tcs.2008.02.028; Odifreddi P., 1989, CLASSICAL RECURSION; Osherson D., 1986, SYSTEMS LEARN INTRO; PITT L, 1989, LECT NOTES ARTIF INT, V397, P18; Reidenbach D, 2008, THEOR COMPUT SCI, V397, P166, DOI 10.1016/j.tcs.2008.02.029; Reidenbach D, 2004, LECT NOTES COMPUT SC, V3120, P140, DOI 10.1007/978-3-540-27819-1_10; Reidenbach D, 2002, LECT NOTES ARTIF INT, V2533, P308; Reidenbach D, 2006, THEOR COMPUT SCI, V350, P91, DOI 10.1016/j.tcs.2005.10.017; Reischuk R, 2000, J COMPUT SYST SCI, V60, P302, DOI 10.1006/jcss.1999.1669; Rossmanith P, 2001, MACH LEARN, V44, P67, DOI 10.1023/A:1010875913047; Russell S., 2002, ARTIFICIAL INTELLIGE; Sakakibara Y, 1997, THEOR COMPUT SCI, V185, P15, DOI 10.1016/S0304-3975(97)00014-5; Sato M, 1998, LECT NOTES ARTIF INT, V1501, P220; SHINOHARA T, 1994, INFORM COMPUT, V108, P175, DOI 10.1006/inco.1994.1006; Shinohara T., 1982, LECTURE NOTES COMP S, V147, P115; Stephan F, 1997, THEOR COMPUT SCI, V185, P129, DOI 10.1016/S0304-3975(97)00018-2; Trakhtenbrot B.A., 1973, FINITE AUTOMATA BEHA; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; WEXLER K, 1993, KNOWLEDGE LANGUAGE, V1, P217; WEXLER K, 1980, FORMAL PRINCIPLES LA; WIEHAGEN R, 1990, LECT NOTES COMPUTER, V543, P184; WIEHAGEN R, 1994, J EXP THEOR ARTIF IN, V6, P131, DOI 10.1080/09528139408953785; WIEHAGEN R, 1977, LECTURE NOTES COMPUT, V53, P571; WIEHAGEN R, 1978, LECTURE NOTES COMPUT, V62, P494; Wiehagen R., 1976, Elektronische Informationsverarbeitung und Kybernetik (EIK), V12; Wright K., 1989, Proceedings of the Second Annual Workshop on Computational Learning Theory; Yokomori T, 2003, THEOR COMPUT SCI, V298, P179, DOI 10.1016/S0304-3975(02)00423-1; Yoshinaka R, 2007, LECT NOTES ARTIF INT, V4754, P227; Zeugmann T, 1998, ANN MATH ARTIF INTEL, V23, P117, DOI 10.1023/A:1018964207937; Zeugmann T, 2008, THEOR COMPUT SCI, V397, P4, DOI 10.1016/j.tcs.2008.02.021; Zeugmann T., 1995, LECT NOTES ARTIF INT, V961, P190; Zeugmann T, 2006, THEOR COMPUT SCI, V364, P77, DOI 10.1016/j.tcs.2006.07.042; ZILLES S, 2003, DISSERTATIONEN KUNST, V278	102	19	19	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3975		THEOR COMPUT SCI	Theor. Comput. Sci.	MAY 20	2008	397	1-3					194	232		10.1016/j.tcs.2008.02.030		39	Computer Science, Theory & Methods	Computer Science	305SY	WOS:000256199300011	
J	Judson, R; Elloumi, F; Setzer, RW; Li, Z; Shah, I				Judson, Richard; Elloumi, Fathi; Setzer, R. Woodrow; Li, Zhen; Shah, Imran			A comparison of machine learning algorithms for chemical toxicity classification using a simulated multi-scale data model	BMC BIOINFORMATICS			English	Article							PREDICTIVE TOXICOLOGY CHALLENGE; ORPHAN NUCLEAR RECEPTORS; SUPPORT VECTOR MACHINES; MOLECULAR LIBRARIES; FEATURE-SELECTION; CANCER; MICROARRAYS; DISCOVERY; PATTERNS; TARGET	Background: Bioactivity profiling using high-throughput in vitro assays can reduce the cost and time required for toxicological screening of environmental chemicals and can also reduce the need for animal testing. Several public efforts are aimed at discovering patterns or classifiers in high-dimensional bioactivity space that predict tissue, organ or whole animal toxicological endpoints. Supervised machine learning is a powerful approach to discover combinatorial relationships in complex in vitro/in vivo datasets. We present a novel model to simulate complex chemical-toxicology data sets and use this model to evaluate the relative performance of different machine learning (ML) methods. Results: The classification performance of Artificial Neural Networks (ANN), K-Nearest Neighbors (KNN), Linear Discriminant Analysis (LDA), Naive Bayes (NB), Recursive Partitioning and Regression Trees (RPART), and Support Vector Machines (SVM) in the presence and absence of filter-based feature selection was analyzed using K-way cross-validation testing and independent validation on simulated in vitro assay data sets with varying levels of model complexity, number of irrelevant features and measurement noise. While the prediction accuracy of all ML methods decreased as non-causal (irrelevant) features were added, some ML methods performed better than others. In the limit of using a large number of features, ANN and SVM were always in the top performing set of methods while RPART and KNN (k = 5) were always in the poorest performing set. The addition of measurement noise and irrelevant features decreased the classification accuracy of all ML methods, with LDA suffering the greatest performance degradation. LDA performance is especially sensitive to the use of feature selection. Filter-based feature selection generally improved performance, most strikingly for LDA. Conclusion: We have developed a novel simulation model to evaluate machine learning methods for the analysis of data sets in which in vitro bioassay data is being used to predict in vivo chemical toxicology. From our analysis, we can recommend that several ML methods, most notably SVM and ANN, are good candidates for use in real world applications in this area.	[Judson, Richard; Elloumi, Fathi; Setzer, R. Woodrow; Shah, Imran] US EPA, Natl Ctr Computat Toxicol, Off Res & Dev, Res Triangle Pk, NC 27711 USA; [Li, Zhen] Univ N Carolina, Dept Biostat, Chapel Hill, NC 27599 USA	Judson, R (reprint author), US EPA, Natl Ctr Computat Toxicol, Off Res & Dev, Res Triangle Pk, NC 27711 USA.	judson.richard@epa.gov; elloumi.fathi@epa.gov; setzer.woodrow@epa.gov; zli@bios.unc.edu; shah.imran@epa.gov					ALMUALLIM H, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P547; Ancona N, 2006, BMC Bioinformatics, V7, P387, DOI 10.1186/1471-2105-7-387; Austin CP, 2004, SCIENCE, V306, P1138, DOI 10.1126/science.1105511; Baker SG, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-407; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Benigni R, 2003, BIOINFORMATICS, V19, P1194, DOI 10.1093/bioinformatics/btg099; Bhogal N, 2005, TRENDS BIOTECHNOL, V23, P299, DOI 10.1016/j.tibtech.2005.04.006; Bredel M, 2004, NAT REV GENET, V5, P262, DOI 10.1038/nrg1317; Burbidge R, 2001, COMPUT CHEM, V26, P5, DOI 10.1016/S0097-8485(01)00094-8; Dix DJ, 2007, TOXICOL SCI, V95, P5, DOI 10.1093/toxsci/kfl103; Fliri AF, 2005, NAT CHEM BIOL, V1, P389, DOI 10.1038/nchembio747; Fliri AF, 2005, P NATL ACAD SCI USA, V102, P261, DOI 10.1073/pnas.0407790101; Helma C, 2003, BIOINFORMATICS, V19, P1179, DOI 10.1093/bioinformatics/btg084; HEUVEL JPV, 2006, TOXICOL SCI, V92, P476; Inglese J, 2006, P NATL ACAD SCI USA, V103, P11473, DOI 10.1073/pnas.0604348103; Japkowicz N., 2002, Intelligent Data Analysis, V6; Kikkawa Rie, 2006, Journal of Toxicological Sciences, V31, P23, DOI 10.2131/jts.31.23; Klekota J, 2006, J CHEM INF MODEL, V46, P1549, DOI 10.1021/ci050495h; Kohavi R., 1995, INT JOINT C ART INT; KREWSKI D, 2007, TOXICITY TESTING 21; Lamb J, 2006, SCIENCE, V313, P1929, DOI 10.1126/science.1132939; Lepp Z, 2006, J CHEM INF MODEL, V46, P158, DOI 10.1021/ci05030ly; LI LH, 2005, 2005 IEEE INT C NAT, V10, P371; MARTIN MT, 2007, TOXICOLOGIST CD J SO, V96, P219; McMillian M, 2004, BIOCHEM PHARMACOL, V67, P2141, DOI 10.1016/j.bcp.2004.01.029; Melnick JS, 2006, P NATL ACAD SCI USA, V103, P3153, DOI 10.1073/pnas.0511292103; Molinaro AM, 2005, BIOINFORMATICS, V21, P3301, DOI 10.1093/bioinformatics/bti499; Moore LB, 2000, J BIOL CHEM, V275, P15122, DOI 10.1074/jbc.M001215200; Ntzani EE, 2003, LANCET, V362, P1439, DOI 10.1016/S0140-6736(03)14686-7; O'Brien PJ, 2006, ARCH TOXICOL, V80, P580, DOI 10.1007/s00204-006-0091-3; Okey AB, 2007, TOXICOL SCI, V98, P5, DOI 10.1093/toxsci/kfm096; Paolini GV, 2006, NAT BIOTECHNOL, V24, P805, DOI 10.1038/nbt1228; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Scherf U, 2000, NAT GENET, V24, P236, DOI 10.1038/73439; Sima C, 2006, BIOINFORMATICS, V22, P2430, DOI 10.1093/bioinformatics/btl407; Smith SC, 2005, COMB CHEM HIGH T SCR, V8, P577, DOI 10.2174/138620705774575346; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; Strausberg RL, 2003, SCIENCE, V300, P294, DOI 10.1126/science.1083395; Sun YM, 2007, PATTERN RECOGN, V40, P3358, DOI 10.1016/j.patcog.2007.04.009; Tietjen K, 2005, COMB CHEM HIGH T SCR, V8, P589, DOI 10.2174/138620705774575300; Toivonen H, 2003, BIOINFORMATICS, V19, P1183, DOI 10.1093/bioinformatics/btg130; Walum Erik, 2005, Toxicol Appl Pharmacol, V207, P393, DOI 10.1016/j.taap.2005.01.056; Wang HB, 2003, CLIN PHARMACOKINET, V42, P1331, DOI 10.2165/00003088-200342150-00003; Williams GM, 2002, TOXICOL PATHOL, V30, P41, DOI 10.1080/01926230252824699; Zhang J., 2003, ICML; MLINTERFACE UNIFROM; E1071 PACKAGE; PREDICTIVE TOXICOLOG	48	14	14	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	MAY 19	2008	9								241	10.1186/1471-2105-9-241		16	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	308XG	WOS:000256423400001	
J	Moskovitch, R; Elovici, Y; Rokach, L				Moskovitch, Robert; Elovici, Yuval; Rokach, Lior			Detection of unknown computer worms based on behavioral classification of the host	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article								Machine learning techniques are widely used in many fields. One of the applications of machine learning in the field of information security is classification of a computer behavior into malicious and benign. Antiviruses consisting of signature-based methods are helpless against new (unknown) computer worms. This paper focuses on the feasibility of accurately detecting unknown worm activity in individual computers while minimizing the required set of features collected from the monitored computer. A comprehensive experiment for testing the feasibility of detecting unknown computer worms, employing several computer configurations, background applications, and user activity, was performed. During the experiments 323 computer features were monitored by an agent that was developed. Four feature selection methods were used to reduce the number of features and four learning algorithms were applied on the resulting feature subsets. The evaluation results suggest that by using classification algorithms applied on only 20 features the mean detection accuracy exceeded 90%, and for specific unknown worms accuracy reached above 99%, while maintaining a low level of false positive rate. (C) 2008 Elsevier B.V. All rights reserved.	[Moskovitch, Robert; Elovici, Yuval; Rokach, Lior] Ben Gurion Univ Negev, Deutsch Telekom Labs, IL-84105 Beer Sheva, Israel	Rokach, L (reprint author), Ben Gurion Univ Negev, Deutsch Telekom Labs, IL-84105 Beer Sheva, Israel.	robertmo@bgu.ac.il; elovici@bgu.ac.il; liorrk@bgu.ac.il	ELOVICI, YUVAL/F-1468-2012; Rokach, Lior/F-8247-2010				Abou-Assaleh T., 2004, P 28 ANN INT COMP SO; Barbara D, 2001, P 1 SIAM INT C DAT M; Bishop C.M., 1995, NEURAL NETWORKS PATT; Botha M, 2003, COMPUT SECUR, V22, P423, DOI 10.1016/S0167-4048(03)00511-X; Bridges Susan M., 2000, P 23 NAT INF SYST SE; CAIA DM, 2007, COMPUTATIONAL STAT D, V51, P3156; Demuth H., 1998, NEURAL NETWORK TOOLB; Dickerson JE, 2000, PEACHFUZZ 2000 : 19TH INTERNATIONAL CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS, P301, DOI 10.1109/NAFIPS.2000.877441; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; FOSNOCK C, 2005, COMPUTER WORMS PAST; Hu PZ, 2003, P INT JOINT C NEUR N, V3, P1780; PEARL J, 1986, ARTIF INTELL, V29, P241, DOI 10.1016/0004-3702(86)90072-X; Kabiri PEYMAN, 2005, INT J NETWORK SECURI, V1, P84; Kayacik HG, 2003, P INT JOINT C NEUR N, V3, P1808, DOI 10.1109/IJCNN.2003.1223682; Kienzle DM, 2003, P 2003 ACM WORKSH RA, P1, DOI 10.1145/948187.948189; Kolter JZ, 2006, J MACH LEARN RES, V7, P2721; Lee W., 1999, P 1999 IEEE S SEC PR; Lei J. Z., 2004, Proceedings. Second Annual Conference on Communication Networks and Services Research, DOI 10.1109/DNSR.2004.1344728; LIPPMANN RP, 1998, 1 INT WORKSH REC ADV; Lorch Jr, 2000, MSDN MAG, V15, P86; Mitchell T, 1997, MACHINE LEARNING; MOORE D, 2002, P INT MEAS WORKSH 20; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; ROKACH L, 2007, INT J PATTERN RECOGN, V21, P1; ROKACH L, 2007, ENCY CYBER TERRORISM; Schultz M., 2001, P IEEE S SEC PRIV, P178; Weaver N., 2003, P 2003 ACM WORKSH RA, P11, DOI 10.1145/948187.948190; Witten I. H., 2005, DATA MINING PRACTICA; Zanero S., 2004, P 2004 ACM S APPL CO, P412, DOI 10.1145/967900.967988; *CERT, CA200004 CERT	30	27	27	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473		COMPUT STAT DATA AN	Comput. Stat. Data Anal.	MAY 15	2008	52	9					4544	4566		10.1016/j.csda.2008.01.028		23	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	317IS	WOS:000257014000028	
J	Qiu, J; Sheffler, W; Baker, D; Noble, WS				Qiu, Jian; Sheffler, Will; Baker, David; Noble, William Stafford			Ranking predicted protein structures with support vector regression	PROTEINS-STRUCTURE FUNCTION AND BIOINFORMATICS			English	Article						protein structure prediction; scoring function; support vector regression; machine learning; consensus-based feature	TERTIARY STRUCTURES; AUTOMATED-METHOD; ENERGY FUNCTIONS; MODELS; RECOGNITION; SOLVATION; DYNAMICS; CORRECT; QUALITY; TASSER	Protein structure prediction is an important problem of both intellectual and practical interest. Most protein structure prediction approaches generate multiple candidate models first, and then use a scoring function to select the best model among these candidates. In this work, we develop a scoring function using support vector regression (SVR). Both consensus-based features and features from individual structures are extracted from a training data set containing native protein structures and predicted structural models submitted to CASP5 and CASP6. The SVR learns a scoring function that is a linear combination of these features. We test this scoring function on two data sets. First, when used to rank server models submitted to CASP7, the SVR score selects predictions that are comparable to the best performing server in CASP7, Zhang-Server, and significantly better than all the other servers. Even if the SVR score is not allowed to select Zhang-Server models, the SVR score still selects predictions that are significantly better than all the other servers. In addition, the SVR is able to select significantly better models and yield significantly better Pearson correlation coefficients than the two best Quality Assessment groups in CASP7, QA556 (LEE), and QA634 (Pcons). Second, this work aims to improve the ability of the Robetta server to select best models, and hence we evaluate the performance of the SVR score on ranking the Robetta server template-based models for the CASP7 targets. The SVR selects significantly better models than the Robetta K*Sync consensus alignment score.	[Qiu, Jian; Sheffler, Will; Baker, David; Noble, William Stafford] Univ Washington, Dept Genome Sci, Seattle, WA 98195 USA; [Baker, David] Univ Washington, Dept Biochem, Seattle, WA 98195 USA; [Noble, William Stafford] Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA	Noble, WS (reprint author), Foege Bldg S-250,Box 355065, Seattle, WA 98195 USA.	noble@gs.washington.edu	baker, david/K-8941-2012				Andersen E. D., 2000, HIGH PERFORMANCE OPT, P197; Baker D, 2001, SCIENCE, V294, P93, DOI 10.1126/science.1065659; Ben-Hur A, 2005, BIOINFORMATICS, V21, pI38, DOI 10.1093/bioinformatics/bti1016; Bowie F.U., 1991, SCIENCE, V253, P164; BROOKS BR, 1983, J COMPUT CHEM, V4, P187, DOI 10.1002/jcc.540040211; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Cai CZ, 2003, MATH BIOSCI, V185, P111, DOI 10.1016/S0025-5564(03)00096-8; CHIVIAN D, 2006, NUCLEIC ACIDS RES, V34, pC112; Chivian D, 2005, PROTEINS, V61, P157, DOI 10.1002/prot.20733; Cristianini N., 2000, INTRO SUPPORT VECTOR; Eramian D, 2006, PROTEIN SCI, V15, P1653, DOI 10.1110/ps.062095806; Ginalski K, 2005, NUCLEIC ACIDS RES, V33, P1874, DOI 10.1093/nar/gki327; Ginalski K, 2003, BIOINFORMATICS, V19, P1015, DOI 10.1093/bioinformatics/btg124; HUA S, 2001, J MOL BIOL, V208, P397; Jaakkola T, 1999, Proc Int Conf Intell Syst Mol Biol, P149; Jones DT, 1999, J MOL BIOL, V287, P797, DOI 10.1006/jmbi.1999.2583; Lazaridis T, 1999, J MOL BIOL, V288, P477, DOI 10.1006/jmbi.1999.2685; Lee J, 1997, J COMPUT CHEM, V18, P1222, DOI 10.1002/(SICI)1096-987X(19970715)18:9<1222::AID-JCC10>3.0.CO;2-7; Lu H, 2001, PROTEINS, V44, P223, DOI 10.1002/prot.1087; Moult J, 2005, PROTEINS, V61, P3, DOI 10.1002/prot.20716; Noble W. S., 2004, KERNEL METHODS COMPU, P71; Ortiz AR, 2002, PROTEIN SCI, V11, P2606, DOI 10.1110/ps.0215902; Park BH, 1997, J MOL BIOL, V266, P831, DOI 10.1006/jmbi.1996.0809; Qiu J, 2005, PROTEINS, V61, P44, DOI 10.1002/prot.20585; Rohl CA, 2004, METHOD ENZYMOL, V383, P66; Samudrala R, 1998, J MOL BIOL, V275, P895, DOI 10.1006/jmbi.1997.1479; Siew N, 2000, BIOINFORMATICS, V16, P776, DOI 10.1093/bioinformatics/16.9.776; Simons KT, 1999, PROTEINS, V34, P82, DOI 10.1002/(SICI)1097-0134(19990101)34:1<82::AID-PROT7>3.0.CO;2-A; STILL WC, 1990, J AM CHEM SOC, V112, P6127, DOI 10.1021/ja00172a038; Tsai J, 2003, PROTEINS, V53, P76, DOI 10.1002/prot.10454; Vapnik V. N, 1995, NATURE STAT LEARNING; Wallner B, 2005, BIOINFORMATICS, V21, P4248, DOI 10.1093/bioinformatics/bti702; Wallner B, 2003, PROTEIN SCI, V12, P1073, DOI 10.1110/ps.0236803; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Wu ST, 2007, BMC BIOL, V5, DOI 10.1186/1741-7007-5-17; Xia Y, 2000, J MOL BIOL, V300, P171, DOI 10.1006/jmbi.2000.3835; XU J, 2005, P 3 AS PAC BIOINF C, P73, DOI 10.1142/9781860947322_0008; Zemla A, 2003, NUCLEIC ACIDS RES, V31, P3370, DOI 10.1093/nar/gkg571; Zhang Y, 2004, PROTEINS, V57, P702, DOI 10.1002/prot.20264; Zhang Y, 2005, PROTEINS, V61, P91, DOI 10.1002/prot.20724	40	28	29	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0887-3585		PROTEINS	Proteins	MAY 15	2008	71	3					1175	1182		10.1002/prot.21809		8	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	292MC	WOS:000255269200012	
J	Lee, MM; Bundschuh, R; Chan, MK				Lee, Marianne M.; Bundschuh, Ralf; Chan, Michael K.			Distant homology detection using a LEngth and STructure-based sequence alignment tool [LESTAT]	PROTEINS-STRUCTURE FUNCTION AND BIOINFORMATICS			English	Article						remote homolog; distant homologdetection; sequence alignment	NUCLEATION-CONDENSATION MECHANISM; PROTEIN FOLD RECOGNITION; HIDDEN MARKOV-MODELS; ASTRAL COMPENDIUM; GENOME SEQUENCES; TRANSITION-STATE; DATABASE; RESIDUES; CLASSIFICATION; SIMILARITIES	A new machine learning algorithm, LESTAT (LEngth and STructure-based sequence Alignment Tool) has been developed for detecting protein homologs having low-sequence identity. LESTAT is an iterative profile-based method that runs without reliance on a predefined library and incorporates several novel features that enhance its ability to identify remote sequences. To overcome the inherent bias associated with a single starting model, LESTAT utilizes three structural homologs to create a profile consisting of structurally conserved positions and block separation distances. Subsequent profiles are refined iteratively using sequence information obtained from previous cycles. Additionally, the refinement process incorporates a "lock-in" feature to retain the high-scoring sequences involved in previous alignments for subsequent model building and an enhancement factor to complement the weighting scheme used to build the position specific scoring matrix. A comparison of the performance of LESTAT against PSI-BLAST for seven systems reveals that LESTAT exhibits increased sensitivity and specificity over PSI-BLAST in six of these systems, based on the number of true homologs detected and the number of families these homologs covered. Notably, many of the hits identified are unique to each method, presumably resulting from the distinct differences in the two approaches. Taken together, these findings suggest that LESTAT is a useful complementary method to PSI-BLAST in the detection of distant homologs.	[Bundschuh, Ralf] Ohio State Univ, Dept Phys, Columbus, OH 43210 USA; [Lee, Marianne M.; Bundschuh, Ralf; Chan, Michael K.] Ohio State Univ, Ohio State Biophys Program, Columbus, OH 43210 USA; [Chan, Michael K.] Ohio State Univ, Dept Biochem, Columbus, OH 43210 USA; [Chan, Michael K.] Ohio State Univ, Dept Chem, Columbus, OH 43210 USA	Bundschuh, R (reprint author), Ohio State Univ, Dept Phys, 191 W Woodruff Ave, Columbus, OH 43210 USA.	bundschuh@mps.ohio-state.edu; chan@chemistry.ohio-state.edu	Bundschuh, Ralf/B-9623-2008	Bundschuh, Ralf/0000-0002-6699-8614			ABKEVICH VI, 1994, BIOCHEMISTRY-US, V33, P10026, DOI 10.1021/bi00199a029; ALTSCHUL SF, 1997, NUCLEIC ACIDS RES, V25, P3402; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; BOWIE JU, 1991, SCIENCE, V253, P164, DOI 10.1126/science.1853201; Brenner SE, 2000, NUCLEIC ACIDS RES, V28, P254, DOI 10.1093/nar/28.1.254; Brenner SE, 1998, P NATL ACAD SCI USA, V95, P6073, DOI 10.1073/pnas.95.11.6073; CASARI G, 1995, NAT STRUCT BIOL, V2, P171, DOI 10.1038/nsb0295-171; Chandonia JM, 2004, NUCLEIC ACIDS RES, V32, pD189, DOI 10.1093/nar/gkh034; Chandonia JM, 2002, NUCLEIC ACIDS RES, V30, P260, DOI 10.1093/nar/30.1.260; COLLINS JF, 1988, COMPUT APPL BIOSCI, V4, P67; Eddy S R, 1995, Proc Int Conf Intell Syst Mol Biol, V3, P114; Eddy SR, 1996, CURR OPIN STRUC BIOL, V6, P361, DOI 10.1016/S0959-440X(96)80056-X; FERSHT AR, 1995, P NATL ACAD SCI USA, V92, P10869, DOI 10.1073/pnas.92.24.10869; Fischer D, 1996, PROTEIN SCI, V5, P947; Gough J, 2001, J MOL BIOL, V313, P903, DOI 10.1006/jmbi.2001.5080; GRIBSKOV M, 1987, P NATL ACAD SCI USA, V84, P4355, DOI 10.1073/pnas.84.13.4355; Gumbel E. J., 1958, STAT EXTREMES; Hadley C, 1999, STRUCT FOLD DES, V7, P1099, DOI 10.1016/S0969-2126(99)80177-4; Holm L, 1996, SCIENCE, V273, P595, DOI 10.1126/science.273.5275.595; ITZHAKI LS, 1995, J MOL BIOL, V254, P260, DOI 10.1006/jmbi.1995.0616; Kann MG, 2005, BIOINFORMATICS, V21, P1451, DOI 10.1093/bioinformatics/bti233; Kleiger G, 2000, J MOL BIOL, V299, P1019, DOI 10.1006/jmbi.2000.3805; Lo Conte L, 2000, NUCLEIC ACIDS RES, V28, P257, DOI 10.1093/nar/28.1.257; Lu GG, 2000, J APPL CRYSTALLOGR, V33, P176, DOI 10.1107/S0021889899012339; MALLICK P, 2001, DAPS DATABASE DISTAN; Marchler-Bauer A, 2003, NUCLEIC ACIDS RES, V31, P383, DOI 10.1093/nar/gkg087; Marchler-Bauer A, 2005, NUCLEIC ACIDS RES, V33, pD192, DOI 10.1093/nar/gki069; Olsen R, 1999, Proc Int Conf Intell Syst Mol Biol, P211; OSBORNE M, 2004, BMC STRUCT BIOL, V4, P4; Park J, 1998, J MOL BIOL, V284, P1201, DOI 10.1006/jmbi.1998.2221; Pearl FMG, 2002, PROTEIN SCI, V11, P233, DOI 10.1110/ps.16802; PERUTZ MF, 1965, J MOL BIOL, V13, P669; Rice DW, 1997, J MOL BIOL, V267, P1026, DOI 10.1006/jmbi.1997.0924; ROBINSON AB, 1991, P NATL ACAD SCI USA, V88, P8880, DOI 10.1073/pnas.88.20.8880; SALI A, 1994, NATURE, V369, P248; Schaffer AA, 2001, NUCLEIC ACIDS RES, V29, P2994, DOI 10.1093/nar/29.14.2994; SHAKHNOVICH E, 1991, PHYS REV LETT, V67, P1665, DOI 10.1103/PhysRevLett.67.1665; Shakhnovich E, 1996, NATURE, V379, P96, DOI 10.1038/379096a0; SMITH TF, 1985, NUCLEIC ACIDS RES, V13, P645, DOI 10.1093/nar/13.2.645; Tatusova TA, 1999, FEMS MICROBIOL LETT, V174, P247, DOI 10.1111/j.1574-6968.1999.tb13575.x; WOLYNES PG, 1995, SCIENCE, V267, P1619, DOI 10.1126/science.7886447	41	2	3	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0887-3585		PROTEINS	Proteins	MAY 15	2008	71	3					1409	1419		10.1002/prot.21830		11	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	292MC	WOS:000255269200030	
J	Rogan, J; Franklin, J; Stow, D; Miller, J; Woodcock, C; Roberts, D				Rogan, John; Franklin, Janet; Stow, Doug; Miller, Jennifer; Woodcock, Curtis; Roberts, Dar			Mapping land-cover modifications over large areas: A comparison of machine learning algorithms	REMOTE SENSING OF ENVIRONMENT			English	Article						land-cover change; machine learning; large area monitoring	ARTIFICIAL NEURAL-NETWORK; DECISION-TREE; CLASSIFICATION TREES; SATELLITE DATA; UNITED-STATES; FUZZY ARTMAP; DATA SET; GIS DATA; FOREST; VEGETATION	Large area land-cover monitoring scenarios, involving large volumes of data, are becoming more prevalent in remote sensing applications. Thus, there is a pressing need for increased automation in the change mapping process. The objective of this research is to compare the performance of three machine learning algorithms (MLAs); two classification tree software routines (S-plus and C4.5) and an artificial neural network (ARTMAP), in the context of mapping land-cover modifications in northern and southern California study sites between 1990/91 and 1996. Comparisons were based on several criteria: overall accuracy, sensitivity to data set size and variation, and noise. ARTMAP produced the most accurate maps overall (similar to 84%), for two study areas - in southern and northern California, and was most resistant to training data deficiencies. The change map generated using ARTMAP has similar accuracies to a human-interpreted map produced by the U.S. Forest Service in the southern study area. ARTMAP appears to be robust and accurate for automated, large area change monitoring as it performed equally well across the diverse study areas with minimal human intervention in the classification process. (C) 2007 Elsevier Inc. All rights reserved.	[Franklin, Janet] San Diego State Univ, Dept Biol, San Diego, CA 92182 USA; [Rogan, John; Stow, Doug] San Diego State Univ, Dept Geog, San Diego, CA 92182 USA; [Miller, Jennifer] W Virginia Univ, Dept Geol & Geog & Geol, Morgantown, WV 26506 USA; [Woodcock, Curtis] Boston Univ, Dept Geog, Boston, MA 02215 USA; [Roberts, Dar] Univ Calif Santa Barbara, Dept Geog, Santa Barbara, CA 93106 USA	Rogan, J (reprint author), Clark Univ, Dept Geog, 950 Main St, Worcester, MA 01610 USA.	jrogan@clarku.edu	Franklin, Janet/G-6538-2013				Abuelgasim AA, 1999, REMOTE SENS ENVIRON, V70, P208, DOI 10.1016/S0034-4257(99)00039-5; Aspinall R, 2002, PHOTOGRAMM ENG REM S, V68, P1101; Borak JS, 1999, INT J REMOTE SENS, V20, P919, DOI 10.1080/014311699212993; Brodley CE, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P799; Carpenter GA, 1999, REMOTE SENS ENVIRON, V70, P326, DOI 10.1016/S0034-4257(99)00051-6; CARPENTER GA, 1992, IEEE T NEURAL NETWOR, V3, P698, DOI 10.1109/72.159059; Carpenter GA, 1997, IEEE T GEOSCI REMOTE, V35, P308, DOI 10.1109/36.563271; Chan JCW, 2003, INT J REMOTE SENS, V24, P1401, DOI 10.1080/0143116021000050538; CHAN JCW, 2001, P 1 ANN WORSH AN MUL, P440; Chavez PS, 1996, PHOTOGRAMM ENG REM S, V62, P1025; Cihlar J, 2000, INT J REMOTE SENS, V21, P1093, DOI 10.1080/014311600210092; COHEN WB, 2004, BIOSCIENCE, V54, P2004; COHEN WB, 1995, INT J REMOTE SENS, V16, P721; Collins JB, 1996, REMOTE SENS ENVIRON, V56, P66, DOI 10.1016/0034-4257(95)00233-2; CONGALTON R. G., 1999, ASSESSING ACCURACY R; Coppin P, 2001, PHOTOGRAMM ENG REM S, V67, P603; Dai XL, 1999, PHOTOGRAMM ENG REM S, V65, P1187; De'ath G, 2000, ECOLOGY, V81, P3178, DOI 10.1890/0012-9658(2000)081[3178:CARTAP]2.0.CO;2; DeFries RS, 2000, REMOTE SENS ENVIRON, V74, P503, DOI 10.1016/S0034-4257(00)00142-5; DOBSON J, 1994, P PEC 12 SIOUX FALLS, P73; FOODY GM, 1995, INT J GEOGR INF SYST, V9, P527, DOI 10.1080/02693799508902054; Foody GM, 2003, PROG PHYS GEOG, V27, P113, DOI 10.1091/0309133303pp345pr; Foody GM, 1997, INT J REMOTE SENS, V18, P799, DOI 10.1080/014311697218764; Franklin J., 2003, METHODS APPL REMOTE, P279; FRANKLIN J, 2000, T GIS, V5, P285; Franklin J, 1998, J VEG SCI, V9, P733, DOI 10.2307/3237291; Franklin SE, 2002, PROG PHYS GEOG, V26, P173, DOI 10.1191/0309133302pp332ra; Friedl MA, 1997, REMOTE SENS ENVIRON, V61, P399, DOI 10.1016/S0034-4257(97)00049-7; Friedl MA, 1999, IEEE T GEOSCI REMOTE, V37, P969, DOI 10.1109/36.752215; Gahegan M, 2003, INT J GEOGR INF SCI, V17, P69, DOI 10.1080/13658810210157778; GONG P, 2003, METHODS APPL REMOTE, P301; Gopal S, 1999, REMOTE SENS ENVIRON, V67, P230, DOI 10.1016/S0034-4257(98)00088-1; Gopal S, 1996, IEEE T GEOSCI REMOTE, V34, P398, DOI 10.1109/36.485117; Hansen M, 1996, INT J REMOTE SENS, V17, P1075; HANSEN MC, 2002, P 1 ANN WORKSH AN MU; HASTIE T, 2001, ELEMENTS STAT LEARNI, P536; Homer C, 2004, PHOTOGRAMM ENG REM S, V70, P829; Huang XQ, 1997, PHOTOGRAMM ENG REM S, V63, P1185; Jakubauskas ME, 1996, REMOTE SENS ENVIRON, V56, P118, DOI 10.1016/0034-4257(95)00228-6; KASISCHKE ES, 2004, MANUAL REMOTE SENSIN, V4; Kohavi R., 1997, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V6, DOI 10.1142/S021821309700027X; LEES BG, 1991, ENVIRON MANAGE, V15, P823, DOI 10.1007/BF02394820; LEVIEN LM, 1999, P ASPRS ANN C PORTL; Liu X, 2002, INT J REMOTE SENS, V23, P2513, DOI 10.1080/01431160110097240; Loveland TR, 2002, PHOTOGRAMM ENG REM S, V68, P1091; MALERBA D, 2001, GEOGRAPHIC DATA MINI, P291, DOI 10.4324/9780203468029_chapter_12; Mannan B, 1998, INT J REMOTE SENS, V19, P767, DOI 10.1080/014311698215991; Miller J, 2002, ECOL MODEL, V157, P227, DOI 10.1016/S0304-3800(02)00196-5; Muchoney D, 2001, IEEE T GEOSCI REMOTE, V39, P1969, DOI 10.1109/36.951087; Olthof I, 2004, REMOTE SENS ENVIRON, V89, P484, DOI 10.1016/j.rse.2003.11.010; Pal M, 2003, REMOTE SENS ENVIRON, V86, P554, DOI 10.1016/S0034-4257(03)00132-9; PAOLA JD, 1995, INT J REMOTE SENS, V16, P3033; Pontius RG, 2000, PHOTOGRAMM ENG REM S, V66, P1011; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Riou R, 1997, PHOTOGRAMM ENG REM S, V63, P515; Roberts DA, 2002, J GEOPHYS RES-ATMOS, V107, DOI 10.1029/2001JD000374; Rogan J, 2004, PROG PLANN, V61, P301, DOI 10.1016/S0305-9006(03)00066-7; Rogan J, 2003, PHOTOGRAMM ENG REM S, V69, P793; Rogan J., 2006, FOREST DISTURBANCE S; RUBIN MA, 1995, 1995 WORLD C NEUR NE, V1, P197; SCULL P, 2005, ECOL MODEL, V18, P1; Simard M, 2000, IEEE T GEOSCI REMOTE, V38, P2310, DOI 10.1109/36.868888; TURNER BL, 1999, 35 IGBP; Wessels KJ, 2004, REMOTE SENS ENVIRON, V92, P67, DOI 10.1016/j.rse.2004.05.002; Woodcock CE, 2001, REMOTE SENS ENVIRON, V78, P194, DOI 10.1016/S0034-4257(01)00259-0; Lawrence RL, 2001, PHOTOGRAMM ENG REM S, V67, P1137; Wulder MA, 2004, PROG PLANN, V61, P365, DOI 10.1016/S0305-9006(03)00069-2; Zambon M, 2006, PHOTOGRAMM ENG REM S, V72, P25; *INT PAN CLIM CHAN, 2000, LAND US LAND US CHAN, P184	69	40	41	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0034-4257		REMOTE SENS ENVIRON	Remote Sens. Environ.	MAY 15	2008	112	5					2272	2283		10.1016/j.rse.2007.10.004		12	Environmental Sciences; Remote Sensing; Imaging Science & Photographic Technology	Environmental Sciences & Ecology; Remote Sensing; Imaging Science & Photographic Technology	293YG	WOS:000255370700028	
J	Myllykangas, S; Tikka, J; Bohling, T; Knuutila, S; Hollmen, J				Myllykangas, Samuel; Tikka, Jarkko; Boehling, Tom; Knuutila, Sakari; Hollmen, Jaakko			Classification of human cancers based on DNA copy number amplification modeling	BMC MEDICAL GENOMICS			English	Article							GENE AMPLIFICATIONS; SOLID TUMORS; ONCOGENES; ALGORITHM; COMMON	Background: DNA amplifications alter gene dosage in cancer genomes by multiplying the gene copy number. Amplifications are quintessential in a considerable number of advanced cancers of various anatomical locations. The aims of this study were to classify human cancers based on their amplification patterns, explore the biological and clinical fundamentals behind their amplification-pattern based classification, and understand the characteristics in human genomic architecture that associate with amplification mechanisms. Methods: We applied a machine learning approach to model DNA copy number amplifications using a data set of binary amplification records at chromosome sub-band resolution from 4400 cases that represent 82 cancer types. Amplification data was fused with background data: clinical, histological and biological classifications, and cytogenetic annotations. Statistical hypothesis testing was used to mine associations between the data sets. Results: Probabilistic clustering of each chromosome identified 111 amplification models and divided the cancer cases into clusters. The distribution of classification terms in the amplification-model based clustering of cancer cases revealed cancer classes that were associated with specific DNA copy number amplification models. Amplification patterns-finite or bounded descriptions of the ranges of the amplifications in the chromosome-were extracted from the clustered data and expressed according to the original cytogenetic nomenclature. This was achieved by maximal frequent itemset mining using the cluster-specific data sets. The boundaries of amplification patterns were shown to be enriched with fragile sites, telomeres, centromeres, and light chromosome bands. Conclusions: Our results demonstrate that amplifications are non-random chromosomal changes and specifically selected in tumor tissue microenvironment. Furthermore, statistical evidence showed that specific chromosomal features co-localize with amplification breakpoints and link them in the amplification process.	[Myllykangas, Samuel; Boehling, Tom; Knuutila, Sakari] Univ Helsinki, Haartman Inst, Dept Pathol, FI-00014 Helsinki, Finland; [Myllykangas, Samuel; Boehling, Tom; Knuutila, Sakari] Univ Helsinki, HUSLAB, FIN-00014 Helsinki, Finland; [Myllykangas, Samuel; Boehling, Tom; Knuutila, Sakari] Univ Helsinki, Cent Hosp, FIN-00014 Helsinki, Finland; [Tikka, Jarkko; Hollmen, Jaakko] Helsinki Univ Technol, Dept Informat & Comp Sci, FI-02015 Espoo, Finland	Myllykangas, S (reprint author), Univ Helsinki, Haartman Inst, Dept Pathol, POB 21, FI-00014 Helsinki, Finland.	samuel.myllykangas@helsinki.fi; tikka@cis.hut.fi; tom.bohling@helsinki.fi; sakari.knuutila@helsinki.fi; jaakko.hollmen@hut.fi			Academy of Finland; Sigrid Juselius Foundation; Finnish Cancer Organizations	The authors of this article would like to thank Dr. Outi Monni (Institute of Biomedicine/Biochemistry, Genome-Scale Biology Research Program and Biomedicum Biochip Center, University of Helsinki) and Dr. Kai Puolamaki (Department of Information and Computer Science, Helsinki University of Technology) for critical comments on the manuscript. This work was supported by the Academy of Finland in the SYSBIO (Systems Biology and Bioinformatics) Research Program, the State Appropriations of Helsinki University Central Hospital, the Sigrid Juselius Foundation, and the Finnish Cancer Organizations.	Albertson DG, 2003, NAT GENET, V34, P369, DOI 10.1038/ng1215; Baudis M, 2001, BIOINFORMATICS, V17, P1228, DOI 10.1093/bioinformatics/17.12.1228; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; BRODEUR GM, 1998, GENETIC BASIS HUMAN, P161; Burdick D, 2005, IEEE T KNOWL DATA EN, V17, P1490, DOI 10.1109/TKDE.2005.183; Carreira-Perpinan MA, 2000, NEURAL COMPUT, V12, P141, DOI 10.1162/089976600300015925; Dempster A. P., 1977, J ROYAL STAT SOC B, V39, DOI DOI 10.2307/2984875; EFRON B, 1993, MONOGRAPHS STAT APPL; Everitt B.S., 1981, FINITE MIXTURE DISTR; Gilbert N, 2004, CELL, V118, P555, DOI 10.1016/j.cell.2004.08.011; GYLLENBERG M, 1994, J APPL PROBAB, V31, P542, DOI 10.2307/3215044; Hellman A, 2002, CANCER CELL, V1, P89, DOI 10.1016/S1535-6108(02)00017-X; HOLLMEN J, 2007, P 7 INT S INT DAT AN, P1; KALLIONIEMI A, 1992, SCIENCE, V258, P818, DOI 10.1126/science.1359641; Kleihues P, 2000, WHO CLASSIFICATION T; Lengauer C, 1998, NATURE, V396, P643, DOI 10.1038/25292; MacLachlan G., 2000, WILEY SERIES PROBABI; MACLACHLAN GJ, 1996, WILEY SERIES PROBABI; Milton J. S., 1990, INTRO PROBABILITY ST; MITELMAN F, 1994, CATALOG CHROMOSOME A, V2; Murnane JP, 2004, BIOESSAYS, V26, P1164, DOI 10.1002/bies.20125; Myllykangas S, 2006, CANCER LETT, V232, P79, DOI 10.1016/j.canlet.2005.07.045; Myllykangas S, 2007, SEMIN CANCER BIOL, V17, P42, DOI 10.1016/j.semcancer.2006.10.005; Myllykangas S, 2006, ONCOGENE, V25, P7324, DOI 10.1038/sj.onc.1209717; REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034; Schwab M, 1998, BIOESSAYS, V20, P473, DOI 10.1002/(SICI)1521-1878(199806)20:6<473::AID-BIES5>3.0.CO;2-N; Schwab M, 2003, LANCET ONCOL, V4, P472, DOI 10.1016/S1470-2045(03)01166-5; Schwartz M, 2006, CANCER LETT, V232, P13, DOI 10.1016/j.canlet.2005.07.039; Shaffer L, 2005, ISCN 2005 INT SYSTEM; TIKKA J, 2007, P 9 INT WORK C ART N, P972; Vogt N, 2004, P NATL ACAD SCI USA, V101, P11368, DOI 10.1073/pnas.0402979101	31	10	10	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1755-8794		BMC MED GENOMICS	BMC Med. Genomics	MAY 14	2008	1								15	10.1186/1755-8794-1-15		13	Genetics & Heredity	Genetics & Heredity	531QE	WOS:000272682100001	
J	Punia, M; Nautiyal, VP; Kant, Y				Punia, Milap; Nautiyal, Vinod Prasad; Kant, Yogesh			Identifying biomass burned patches of agriculture residue using satellite remote sensing data	CURRENT SCIENCE			English	Article						burned patches; decision-tree classifier; knowledge-based classification; thermal band	MODIS	The combine harvesting technology which has become common in the rice-wheat system in India leaves behind large quantities of straw in the field for open residue burning, and Punjab is one such region where this is regularly happening. This becomes a source for the emission of trace gases, resulting in perturbations to regional atmospheric chemistry. The study attempts to estimate district-wise burned area from agriculture residue burning. The feasibility of using low resolution (MODIS) and moderate resolution (AWiFS) satellite data for estimation of burned areas is shown. It utilizes thermal channels of MODIS and knowledge-based approach for AWiFS data for burned area estimation. A hybrid contextual test-fire detection and tentative-fire detection algorithm for satellite thermal images has been followed to identify the fire pixels over the region. The algorithm essentially treats fire pixels as anomalies in images and can be considered a special case of the more general clutter or background suppression problem. It utilizes the local background around a potential fire pixel, and discriminates fire pixels and avoids the false alarm. It incorporates the statistical properties of individual bands and requires the manual setting of multiple thresholds. Also, a decision-tree classification based on See5 algorithm is applied to AWiFS data. When combined with image classification using a machine learning decision tree (See5) classification, it gives high accuracy. The study compares the estimated burned area over the region using the two algorithms.	[Nautiyal, Vinod Prasad; Kant, Yogesh] Indian Inst Remote Sensing, Dehra Dun 248001, Uttar Pradesh, India; [Punia, Milap] Jawaharlal Nehru Univ, Sch Social Sci, Ctr Study Reg Dev, New Delhi 110067, India	Kant, Y (reprint author), Indian Inst Remote Sensing, 4 Kalidas Rd, Dehra Dun 248001, Uttar Pradesh, India.	yogesh@iirs.gov.in					ANDREAE MO, 1991, GLOBAL BIOMASS BURNI, P1; Badarinath KVS, 2006, CURR SCI INDIA, V91, P1085; CRUTZEN PJ, 1990, SCIENCE, V250, P1669, DOI 10.1126/science.250.4988.1669; Giglio L, 2003, REMOTE SENS ENVIRON, V87, P273, DOI 10.1016/S0034-4257(03)00184-6; Gupta PK, 2004, CURR SCI INDIA, V87, P1713; Gupta R. K., 2003, ASA SPECIAL PUBLICAT, V65; Kaufman YJ, 1998, J GEOPHYS RES-ATMOS, V103, P32215, DOI 10.1029/98JD01644; Kaufman YJ, 1997, SCIENCE, V277, P1636, DOI 10.1126/science.277.5332.1636; Levine J. S., 1991, GLOBAL BIOMASS BURNI; PENNER JE, 1992, SCIENCE, V256, P1432, DOI 10.1126/science.256.5062.1432; QUINHAN JR, 2006, SEE5 MANUAL	11	6	7	INDIAN ACAD SCIENCES	BANGALORE	C V RAMAN AVENUE, SADASHIVANAGAR, P B #8005, BANGALORE 560 080, INDIA	0011-3891		CURR SCI INDIA	Curr. Sci.	MAY 10	2008	94	9					1185	1190				6	Multidisciplinary Sciences	Science & Technology - Other Topics	305BO	WOS:000256153000023	
J	Mandic, DP; Chen, M; Gautama, T; Van Hulle, MM; Constantinides, A				Mandic, D. P.; Chen, M.; Gautama, T.; Van Hulle, M. M.; Constantinides, A.			On the characterization of the deterministic/stochastic and linear/nonlinear nature of time series	PROCEEDINGS OF THE ROYAL SOCIETY A-MATHEMATICAL PHYSICAL AND ENGINEERING SCIENCES			English	Article						signal nonlinearity; embedding dimension; delay vector variance; machine learning; data fusion	CONGESTIVE-HEART-FAILURE; SURROGATE DATA; NONLINEARITY; FMRI; SLEEP	The need for the characterization of real-world signals in terms of their linear, nonlinear, deterministic and stochastic nature is highlighted and a novel framework for signal modality characterization is presented. A comprehensive analysis of signal nonlinearity characterization methods is provided, and based upon local predictability in phase space, a new criterion for qualitative performance assessment in machine learning is introduced. This is achieved based on a simultaneous assessment of nonlinearity and uncertainty within a real-world signal. Next, for a given embedding dimension, based on the target variance of delay vectors, a novel framework for heterogeneous data fusion is introduced. The proposed signal modality characterization framework is verified by comprehensive simulations and comparison against other established methods. Case studies covering a range of machine learning applications support the analysis.	[Mandic, D. P.; Chen, M.; Constantinides, A.] Univ London Imperial Coll Sci Technol & Med, Dept Elect & Elect Engn, London SW7 2BT, England; [Gautama, T.] Philips Leuven, B-3001 Louvain, Belgium; [Van Hulle, M. M.] Katholieke Univ Leuven, Lab Neuroen, B-3000 Louvain, Belgium	Chen, M (reprint author), Univ London Imperial Coll Sci Technol & Med, Dept Elect & Elect Engn, London SW7 2BT, England.	mo.chen@imperial.ac.uk					Anderson C, 2003, SLEEP, V26, P968; Casdagli M J, 1991, J R STAT SOC B, V54, P303; DIKS C, 1995, PHYS LETT A, V201, P221, DOI 10.1016/0375-9601(95)00239-Y; FARMER JD, 1987, PHYS REV LETT, V59, P845, DOI 10.1103/PhysRevLett.59.845; Friston KJ, 2000, NEUROIMAGE, V12, P466, DOI 10.1006/nimg.2000.0630; Gautama T, 2003, IEEE T MED IMAGING, V22, P636, DOI 10.1109/TMI.2003.812248; Gautama T., 2004, International Journal of Knowledge-Based and Intelligent Engineering Systems, V8; Goh SL, 2006, RENEW ENERG, V31, P1733, DOI 10.1016/j.renene.2005.07.006; GOLZ M, 2007, SIGNAL PROCESSING TE, P299; GRASSBERGER P, 1983, PHYSICA D, V9, P189, DOI 10.1016/0167-2789(83)90298-1; Hegger R, 1999, CHAOS, V9, P413, DOI 10.1063/1.166424; Ho KKL, 1997, CIRCULATION, V96, P842; KAPLAN DT, 1994, PHYSICA D, V73, P38, DOI 10.1016/0167-2789(94)90224-0; Kaplan DT, 1997, ST HEAL T, V35, P15; Kugiumtzis D, 1999, PHYS REV E, V60, P2808, DOI 10.1103/PhysRevE.60.2808; MANDIC D, 2005, ICANN 05 WARSAW POLA, V2, P715; Mandic D.P., 2001, RECURRENT NEURAL NET; MANDIC DP, 2005, P IEEE WORKSH MACH L, P147; Morrell MJ, 2007, SLEEP, V30, P648; Narendra K S, 1990, IEEE Trans Neural Netw, V1, P4, DOI 10.1109/72.80202; Poon CS, 1997, NATURE, V389, P492, DOI 10.1038/39043; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Schreiber T., 1999, Physics Reports, V308, DOI 10.1016/S0370-1573(98)00035-0; Schreiber T, 2000, PHYSICA D, V142, P346, DOI 10.1016/S0167-2789(00)00043-9; Schreiber T, 1997, PHYS REV E, V55, P5443, DOI 10.1103/PhysRevE.55.5443; Schreiber T, 1996, PHYS REV LETT, V77, P635, DOI 10.1103/PhysRevLett.77.635; SOMMER D, 2007, INT J VLSI SIGNAL PR, V49, P329, DOI DOI 10.1007/S11265-007-0083-4; Theiler J., 1993, International Journal of Bifurcation and Chaos in Applied Sciences and Engineering, V3, DOI 10.1142/S0218127493000672; THEILER J, 1994, SFI S SCI C, V15, P429; Theiler J, 1996, PHYSICA D, V94, P221, DOI 10.1016/0167-2789(96)00050-4; THEILER J, 1992, PHYSICA D, V58, P77, DOI 10.1016/0167-2789(92)90102-S; Timmer J, 2000, PHYS REV LETT, V85, P2647, DOI 10.1103/PhysRevLett.85.2647; Vanduffel W, 2001, NEURON, V32, P565, DOI 10.1016/S0896-6273(01)00502-5; Wold H., 1938, STUDY ANAL STATIONAR	34	7	7	ROYAL SOC	LONDON	6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND	1364-5021		P ROY SOC A-MATH PHY	Proc. R. Soc. A-Math. Phys. Eng. Sci.	MAY 8	2008	464	2093					1141	1160		10.1098/rspa.2007.0154		20	Multidisciplinary Sciences	Science & Technology - Other Topics	273RJ	WOS:000253949100005	
J	Beg, A; Prasad, PWC; Beg, A				Beg, Azam; Prasad, P. W. Chandana; Beg, Ajmal			Applicability of feed-forward and recurrent neural networks to Boolean function complexity modeling	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						machine learning; feed-forward neural network; recurrent neural network; bias; biological sequence analysis; motif; sub-cellular localization; pattern recognition; classifier design		In this paper, we present the feed-forward neural network (FFNN) and recurrent neural network (RNN) models for predicting Boolean function complexity (BFC). In order to acquire the training data for the neural networks (NNs), we conducted experiments for a large number of randomly generated single output Boolean functions (BFs) and derived the simulated graphs for number of min-terms against the BFC for different number of variables. For NN model (NNM) development, we looked at three data transformation techniques for pre-processing the NN-training and validation data. The trained NNMs are used for complexity estimation for the Boolean logic expressions with a given number of variables and sum of products (SOP) terms. Both FFNNs and RNNs were evaluated against the ISCAS benchmark results. Our FFNNs and RNNs were able to predict the BFC with correlations of 0.811 and 0.629 with the benchmark results, respectively. (c) 2007 Elsevier Ltd. All rights reserved.	[Beg, Azam] United Arab Emirates Univ, Coll Informat Technol, Al Ain, U Arab Emirates; [Prasad, P. W. Chandana] Multimedia Univ, Fac Informat Syst & Technol, Melaka, Malaysia; [Beg, Ajmal] SAP Australia Brisbane, Brisbane, Qld, Australia	Beg, A (reprint author), United Arab Emirates Univ, Coll Informat Technol, Al Ain, U Arab Emirates.	abeg@uaeu.ac.ae ajmal.beg@bigpond.com; m2160062@mmu.edu.my; abeg@uaeu.ac.ae ajmal.beg@bigpond.com					ASSI A, 2005, J COMPUT SCI PUBL, V2, P236; ASSI A, 2006, WSEAS T CIRCUITS SYS, P810; Bhanja S., 2005, Proceedings. 18th International Conference on VLSI Design; BODEN M, 2006, GUIDE RECURRENT NEUR; BREUER MA, 1976, DIAGNOSIS RELIABLE R; BRYANT RE, 1986, IEEE T COMPUT, V35, P677; CAUDILL M, 1990, EXPERT NEURAL NETWOR; CHO K, 1988, THESIS CARNEGIE MELL; COUDERT O, 1989, IMEC IFIP INT WORKSH; DUNNE PE, 2004, P 9 EUR C LOG ART IN, P347; Epitropakis M. G., 2005, ACM SIGSAM B, V39; FRANCO L, 2004, P 2004 IEEE INT JOIN, P973; Franco L, 2005, LECT NOTES COMPUT SC, V3512, P1; GRAVES A, 2006, ICML 06 JUN 2006; Hansen M, 1999, ABA J, V85, P16; JEFF, 2004, WHATS Z SCORE WHY US; MAHK S, 1988, P INT C CAD KCAD 88, P6; Masters T, 1994, SIGNAL IMAGE PROCESS; McGeer P., 1989, P 26 ACM IEEE DES AU, P561, DOI 10.1145/74382.74476; Medsker L, 1999, RECURRENT NEURAL NET; Moore G.E., 1975, IEDM, P11; MUROGA S, 1989, IEEE T COMPUT, V38, P1404, DOI 10.1109/12.35836; NEMANI M, 1996, P IEEE INT S LOW POW, P329, DOI 10.1109/LPE.1996.547534; Nemani M, 1999, IEEE T COMPUT AID D, V18, P697, DOI 10.1109/43.766722; RAMALINGAM N, 2005, P ACM GREAT LAK S VL, P112, DOI 10.1145/1057661.1057689; Sornenzi F., CUDD CU DEC DIAGR PA; TRIOLA M, 1994, ELEMENTARY STAT; Wolfe G, 2003, IEEE T COMPUT AID D, V22, P198, DOI 10.1109/TCAD.2002.806600; Yale K, 1997, IEEE SPECTRUM, V34, P64, DOI 10.1109/6.576011; *BRAINMAKER, 1998, US GUID REF MAN	30	3	3	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	MAY 4	2008	34	4					2436	2443		10.1016/j.eswa.2007.04.010		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	267PO	WOS:000253521900021	
J	Eom, JH; Kim, SC; Zhang, BT				Eom, Jae-Hong; Kim, Sung-Chun; Zhang, Byoung-Tak			AptaCDSS-E: A classifier ensemble-based clinical decision support system for cardiovascular disease level prediction	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						clinical decision support system (CDSS); cardiovascular disease; classifier ensemble; support vector machines; neural networks; decision trees; Bayesian networks; machine learning	ARTIFICIAL NEURAL-NETWORKS; EXPERT-SYSTEM; MASS-SPECTRA; VECTOR MACHINE; DIAGNOSIS; TREE; CANCER; MODEL; COMBINATION; ALGORITHMS	Conventional clinical decision support systems are generally based on a single classifier or a simple combination of these models, showing moderate performance. In this paper, we propose a classifier ensemble-based method for supporting the diagnosis of cardiovascular disease (CVD) based on aptamer chips. This AptaCDSS-E system overcomes conventional performance limitations by utilizing ensembles of different classifiers. Recent surveys show that CVD is one of the leading causes of death and that significant life savings can be achieved if precise diagnosis can be made. For CVD diagnosis, our system combines a set of four different classifiers with ensembles. Support vector machines and neural networks are adopted as base classifiers. Decision trees and Bayesian networks are also adopted to augment the system. Four aptamer-based biochip data sets including CVD data containing 66 samples were used to train and test the system. Three other supplementary data sets are used to alleviate data insufficiency. We investigated the effectiveness of the ensemble-based system with several different aggregation approaches by comparing the results with single classifier-based models. The prediction performance of the AptaCDSS-E system was assessed with a cross-validation test. The experimental results show that our system achieves high diagnosis accuracy (> 94%) and comparably small prediction difference intervals (< 6%), proving its usefulness in the clinical decision process of disease diagnosis. Additionally, 10 possible biomarkers are found for further investigation. (c) 2007 Elsevier Ltd. All rights reserved.	[Eom, Jae-Hong; Zhang, Byoung-Tak] Seoul Natl Univ, Sch Engn & Comp Sci, Biointelligence Lab, Seoul 151744, South Korea; [Kim, Sung-Chun] GenoProt Co Ltd, Seoul 152841, South Korea	Zhang, BT (reprint author), Seoul Natl Univ, Sch Engn & Comp Sci, Biointelligence Lab, Seoul 151744, South Korea.	btzhang@bi.snu.ac.kr					BALLA JI, 1985, LANCET, V325, P326, DOI 10.1016/S0140-6736(85)91092-X; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; BAXT WG, 1995, LANCET, V346, P1135, DOI 10.1016/S0140-6736(95)91804-3; Baxt W.G., 1990, NEURAL COMPUT, V2, P480, DOI 10.1162/neco.1990.2.4.480; Bishop C.M., 1995, NEURAL NETWORKS PATT; Brasil LM, 2001, INT J MED INFORM, V63, P19, DOI 10.1016/S1386-5056(01)00168-X; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Chae YM, 1998, EXPERT SYST APPL, V15, P309; Conforti D., 2005, OPTIMIZATION METHODS, V20, P401, DOI 10.1080/10556780512331318164; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; Cortes C., 1995, SUPPORT VECTOR NETWO, P237; Ellenius J, 2000, INT J MED INFORM, V60, P1, DOI 10.1016/S1386-5056(00)00064-2; DYBOWSKI R, 1995, LANCET, V346, P1203, DOI 10.1016/S0140-6736(95)92904-5; Geurts P, 2005, BIOINFORMATICS, V21, P3138, DOI 10.1093/bioinformatics/bti494; Güler Nihal Fatma, 2005, J Med Syst, V29, P271, DOI 10.1007/s10916-005-5187-4; Guven A, 2006, EXPERT SYST APPL, V31, P199, DOI 10.1016/j.eswa.2005.09.017; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; HARRIS NL, 1990, COMPUT METH PROG BIO, V32, P37, DOI 10.1016/0169-2607(90)90083-L; He JY, 2006, EXPERT SYST APPL, V30, P64, DOI 10.1016/j.eswa.2005.09.045; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; Kaplan B, 2001, INT J MED INFORM, V64, P15, DOI 10.1016/S1386-5056(01)00183-6; Kim HC, 2003, PATTERN RECOGN, V36, P2757, DOI 10.1016/S0031-3203(03)00175-4; Kim MJ, 2006, EXPERT SYST APPL, V31, P241, DOI 10.1016/j.eswa.2005.09.020; Li YC, 2000, INT J MED INFORM, V57, P1, DOI 10.1016/S1386-5056(99)00054-4; Liu TF, 2006, EXPERT SYST APPL, V30, P42, DOI 10.1016/j.eswa.2005.09.044; MacDowell M, 2001, MED DECIS MAKING, V21, P433, DOI 10.1177/02729890122062785; Majumder S, 2005, J BIOMEDICAL OPTICS, V10, P24; Mangalampalli A, 2006, EXPERT SYST APPL, V30, P109, DOI 10.1016/j.eswa.2005.09.046; Mendyk A, 2005, EXPERT SYST APPL, V28, P285, DOI 10.1016/j.eswa.2004.10.007; MERCER T, 1909, T LONDON PHIL SOC A, V209, P415; Murphy CK, 2001, MED DECIS MAKING, V21, P368; NILSON NJ, 1965, LEARNING MACH FDN TR; Ohlsson M, 2004, ARTIF INTELL MED, V30, P49, DOI 10.1016/S0933-3657(03)00050-2; Pearl J., 1988, PROBABILISTIC REASON; Prados J, 2004, PROTEOMICS, V4, P2320, DOI 10.1002/pmic.200400857; Qu YS, 2002, CLIN CHEM, V48, P1835; Quinlan J. R., 1993, C4 5 PROGRAMS MACH L; Ripley B. D, 1996, PATTERN RECOGNITION; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sadeghi S, 2006, INT J MED INFORM, V75, P403, DOI 10.1016/j.ijmedinf.2005.07.028; SCHUBERT F, 2003, P GERM C BIOINF GCB, P123; Sharkey AJC, 1999, COMBINING ARTIFICIAL, P1; Shin HJ, 2006, J BIOMED INFORM, V39, P227, DOI 10.1016/j.jbi.2005.04.002; Simpson PK, 1990, ARTIFICIAL NEURAL SY; STOCKWELL DRB, 1993, EXPERT SYST APPL, V6, P137, DOI 10.1016/0957-4174(93)90004-P; Tung KY, 2005, EXPERT SYST APPL, V29, P783, DOI 10.1016/j.eswa.2005.06.012; Turkoglu I, 2002, EXPERT SYST APPL, V23, P229, DOI 10.1016/S0957-4174(02)00042-8; Vapnik V. N, 1995, NATURE STAT LEARNING; VEROPOULOS K, 1999, P ECCAI ADV COURS AR; West D, 2005, EUR J OPER RES, V162, P532, DOI 10.1016/j.ejor.2003.10.013; West D, 2000, ARTIF INTELL MED, V20, P183, DOI 10.1016/S0933-3657(00)00063-4; Won Y, 2003, PROTEOMICS, V3, P2310, DOI 10.1002/pmic.200300590; Yan HM, 2006, EXPERT SYST APPL, V30, P272, DOI 10.1016/j.eswa.2005.07.022; Yang S, 2004, EXPERT SYST, V21, P279, DOI 10.1111/j.1468-0394.2004.00285.x	54	18	18	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	MAY 4	2008	34	4					2465	2479		10.1016/j.eswa.2007.04.015		15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	267PO	WOS:000253521900024	
J	Tan, SB; Zhang, J				Tan, Songbo; Zhang, Jin			An empirical study of sentiment analysis for chinese documents	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						sentiment analysis; information retrieval; machine learning		Up to now, there are very few researches conducted on sentiment classification for Chinese documents. In order to remedy this deficiency, this paper presents an empirical study of sentiment categorization on Chinese documents. Four feature selection methods (MI, IG, CHI and DF) and five learning methods (centroid classifier, K-nearest neighbor, winnow classifier, Naive Bayes and SVM) are investigated on a Chinese sentiment corpus with a size of 1021 documents. The experimental results indicate that IG performs the best for sentimental terms selection and SVM exhibits the best performance for sentiment classification. Furthermore, we found that sentiment classifiers are severely dependent on domains or topics. (c) 2007 Elsevier Ltd. All rights reserved.	[Tan, Songbo; Zhang, Jin] Chinese Acad Sci, Inst Comp Technol, Intelligent Software Dept, Beijing 100080, Peoples R China	Tan, SB (reprint author), Chinese Acad Sci, Inst Comp Technol, Intelligent Software Dept, POB 2704, Beijing 100080, Peoples R China.	tansongbo@software.ict.ac.cn	Tan, Songbo/A-7450-2012				CHAOVALIT P, 2005, IEEE P 38 HAW INT C, P1; GALAVOTTI L, 2000, P KDD; Gamon M., 2004, P 20 INT C COMP LING; HAN E, 2000, PKDD; Joachims T., 1998, EUR C MACH LEARN ECM, P137; KENNEDY A, 2005, WORKSH AN INF FORM I; McCallum A., 1998, AAAI 98 WORKSH LEARN, P41; Mckeown K. R., 1997, P 35 ANN M ASS COMP, P174, DOI DOI 10.3115/976909.979640; Mullen T., 2004, P C EMP METH NAT LAN, P412; Pang B., 2002, P EMNLP 2002; STONE PJ, 1966, GEN INQUIRER COMPTER; TURNEY DP, 2002, EGB1094 NAT RES COUN; TURNEY PD, 2002, P ASS COMP LING 4 AN; Turney PD, 2003, ACM T INFORM SYST, V21, P315, DOI 10.1145/944012.944013; van Rijsbergen C. J., 1979, INFORM RETRIEVAL; VANMUN PPT, TEXT CLASSIFICATION; Vapnik V. N, 1995, NATURE STAT LEARNING; Whitelaw C., 2005, CIKM, P625, DOI DOI 10.1145/1099554.1099714; Yang YM, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P42; Yang Y., 2001, SIGIR, P137; Yang Y, 1997, ICML 97, P412; YE Q, 2005, 4 INT C MACH LEARN C; YE Q, 2006, P HICSS 39 HAW INT C; Zhang Huaping, 2003, 2 SIGHAN WORKSH AFF, P63; Zhang T, 2001, ADV NEUR IN, V13, P703	25	19	24	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	MAY 4	2008	34	4					2622	2629		10.1016/j.eswa.2007.05.028		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	267PO	WOS:000253521900038	
J	Tsai, CF; Wu, JW				Tsai, Chih-Fong; Wu, Jhen-Wei			Using neural network ensembles for bankruptcy prediction and credit scoring	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						bankruptcy prediction; credit scoring; neural networks; classifier ensembles	SUPPORT VECTOR MACHINES; CLASSIFIERS; MODELS	Bankruptcy prediction and credit scoring have long been regarded as critical topics and have been studied extensively in the accounting and finance literature. Artificial intelligence and machine learning techniques have been used to solve these financial decision-making problems. The multilayer perceptron (MLP) network trained by the back-propagation learning algorithm is the mostly used technique for financial decision-making problems. In addition, it is usually superior to other traditional statistical models. Recent studies suggest combining multiple classifiers (or classifier ensembles) should be better than single classifiers. However, the performance of multiple classifiers in bankruptcy prediction and credit scoring is not fully understood. In this paper, we investigate the performance of a single classifier as the baseline classifier to compare with multiple classifiers and diversified multiple classifiers by using neural networks based on three datasets. By comparing with the single classifier as the benchmark in terms of average prediction accuracy, the multiple classifiers only perform better in one of the three datasets. The diversified multiple classifiers trained by not only different classifier parameters but also different sets of training data perform worse in all datasets. However, for the Type I and Type 11 errors, there is no exact winner. We suggest that it is better to consider these three classifier architectures to make the optimal financial decision. (c) 2007 Elsevier Ltd. All rights reserved.	[Tsai, Chih-Fong; Wu, Jhen-Wei] Natl Chung Cheng Univ, Dept Accounting & Informat Technol, Chiayi, Taiwan	Tsai, CF (reprint author), Natl Chung Cheng Univ, Dept Accounting & Informat Technol, Chiayi, Taiwan.	actcft@ccu.edu.tw					Atiya AF, 2001, IEEE T NEURAL NETWOR, V12, P929, DOI 10.1109/72.935101; Chen MC, 2003, EXPERT SYST APPL, V24, P433, DOI 10.1016/S0957-4174(02)00191-4; FAN A, 2000, P INT JOINT C NEUR N, V6, P354; Frosyniotis D, 2003, PATTERN ANAL APPL, V6, P32, DOI 10.1007/s10044-002-0174-6; GHOSH J, 2002, P 3 INT WORKSH MULT, P1; Haykin S., 1999, NEURAL NETWORKS COMP; Huang Z, 2004, DECIS SUPPORT SYST, V37, P543, DOI 10.1016/S0167-9236(03)00086-1; KANG HJ, 2003, P INT C DOC AN REC E, P789; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Lee TS, 2002, EXPERT SYST APPL, V23, P245, DOI 10.1016/S0957-4174(02)00044-1; Lee TS, 2006, COMPUT STAT DATA AN, V50, P1113, DOI 10.1016/j.csda.2004.11.006; Min JH, 2005, EXPERT SYST APPL, V28, P603, DOI 10.1016/j.eswa.2004.12.008; Ong CS, 2005, EXPERT SYST APPL, V29, P41, DOI 10.1016/j.eswa.2005.01.003; ROLI F, 2004, P 5 INT WORKSH MULT; Shin KS, 2005, EXPERT SYST APPL, V28, P127, DOI 10.1016/j.eswa.2004.08.009; Vellido A, 1999, EXPERT SYST APPL, V17, P51, DOI 10.1016/S0957-4174(99)00016-0; West D, 2005, COMPUT OPER RES, V32, P2543, DOI 10.1016/j.cor.2004.03.017; West D, 2000, COMPUT OPER RES, V27, P1131, DOI 10.1016/S0305-0548(99)00149-5; Witten I. H., 2000, DATA MINING PRACTICA; Wong BK, 1998, INFORM MANAGE, V34, P129, DOI 10.1016/S0378-7206(98)00050-0; Zhang GQ, 1999, EUR J OPER RES, V116, P16, DOI 10.1016/S0377-2217(98)00051-4	21	66	70	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	MAY 4	2008	34	4					2639	2649		10.1016/j.eswa.2007.05.019		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	267PO	WOS:000253521900040	
J	Chang, FMM; Chen, YC				Chang, Fengming M.; Chen, Yeong-Chin			A frequency assessment expert system of piezoelectric transducers in paucity of data	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						FAESPT; expert system; Mega-fuzzification; machine learning	ACCURACY; NETWORK	It is difficult to measure in the laboratory the operating frequency of a piezoelectric transducer that is a kind of electric equipment. Some simulation methods were developed for this frequency calculation, but were still complex to perform. With high learning accuracy, a Frequency Assessment Expert System of Piezoelectric Transducers (FAESPT) is developed in this study to assess the frequency easily. FAESPT is based on mega-fuzzification that is a method to increase the learning accuracy with fuzzy neural network for the small data-set environment. In this article, FAESPT is established and its assessment accuracy is compared with traditional neural network and neuro-fuzzy method. The results indicate that FAESPT can easy to assess the frequency of a transducer and get good learning accuracy in the environment of the paucity of data. (c) 2007 Elsevier Ltd. All rights reserved.	[Chang, Fengming M.] Univ E Asia, Dept Informat Sci & Applicat, Taichung, Taichung County, Taiwan; [Chen, Yeong-Chin] Diwan Coll Management, Dept Comp Sci & Informat Engn, Tainan, Tainan County, Taiwan	Chang, FMM (reprint author), Univ E Asia, Dept Informat Sci & Applicat, Taichung, Taichung County, Taiwan.	fengming.chang@gmail.com; ycehen-ster@gmail.com					Anthony M., 1997, COMPUTATIONAL LEARNI; Chang F. M., 2006, WSEAS Transactions on Computers, V5; CHANG FM, 2005, P 2005 IEEE INT C SY, P566; Chen YC, 2004, SENSOR ACTUAT A-PHYS, V115, P38, DOI 10.1016/j.sna.2004.01.063; Huang CF, 1997, FUZZY SET SYST, V91, P69, DOI 10.1016/S0165-0114(96)00257-6; Huang CF, 2004, INT J APPROX REASON, V35, P137, DOI 10.1016/j.ijar.2003.06.001; Inoue T., 1987, Transactions of the Institute of Electronics, Information and Communication Engineers E, VE70; JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541; KRIMHOLT.R, 1970, ELECTRON LETT, V6, P398, DOI 10.1049/el:19700280; Li DC, 2005, INT J ADV MANUF TECH, V27, P321, DOI 10.1007/s00170-003-2184-y; Li DC, 2006, INT J PROD RES, V44, P4491, DOI 10.1080/00207540600559849; Li DC, 2003, INT J PROD RES, V41, P4011, DOI 10.1080/0020754031000149211; MCCAMMON DF, 1980, J ACOUST SOC AM, V68, P754, DOI 10.1121/1.384813; Niyogi P., 1998, P IEEE, P275; STANSFIELD D, 1990, UNDERWATER ELECTROAC, P26	15	1	1	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	MAY 4	2008	34	4					2747	2753		10.1016/j.eswa.2007.05.027		7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	267PO	WOS:000253521900052	
J	Huang, CJ; Yang, DX; Chuang, YT				Huang, Chenn-Jung; Yang, Dian-Xiu; Chuang, Yi-Ta			Application of wrapper approach and composite classifier to the stock trend prediction	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						stock prediction; wrapper; voting; feature selection; classification	SUPPORT VECTOR MACHINES	The research on the stock market prediction has been more popular in recent years. Numerous researchers tried to predict the immediate future stock prices or indices based on technical indices with various mathematical models and machine learning techniques such as artificial neural networks (ANN), support vector machines (SVM) and ARIMA models. Although some researches in the literature exhibit satisfactory prediction achievement when the average percentage error and root mean square error are used as the performance metrics, the prediction accuracy of whether stock market goes or down is seldom analyzed. This paper employs wrapper approach to select the optimal feature subset from original feature set composed of 23 technical indices and then uses voting scheme that combines different classification algorithms to predict the trend in Korea and Taiwan stock markets. Experimental result shows that wrapper approach can achieve better performance than the commonly used feature filters, such as chi(2)-Statistic, Information gain, ReliefF, Symmetrical uncertainty and CFS. Moreover, the proposed voting scheme outperforms single classifier such as SVM, kth nearest neighbor, back-propagation neural network, decision tree, and logistic regression. (c) 2007 Elsevier Ltd. All rights reserved.	[Huang, Chenn-Jung; Yang, Dian-Xiu; Chuang, Yi-Ta] Natl Hualien Univ Educ, Coll Sci, Dept Comp & Informat Sci, Hualien, Taiwan	Huang, CJ (reprint author), Natl Hualien Univ Educ, Coll Sci, Dept Comp & Informat Sci, Hualien, Taiwan.	cjhuang@mail.nhlue.edu.tw					Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Breiman L, 1984, CLASSIFICATION REGRE; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Cristianini N., 2000, INTRO SUPPORT VECTOR; ENDOU T, 2002, IEEE C EV COMP; Haykin S., 1994, NEURAL NETWORKS COMP; Hosmer DW, 2000, APPL LOGISTIC REGRES; HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102; Kelly J. D. J., 1991, P 4 INT C GEN ALG TH, P377; Kim KJ, 2003, NEUROCOMPUTING, V55, P307, DOI 10.1016/S0925-2312(03)00372-2; Kim KJ, 2000, EXPERT SYST APPL, V19, P125, DOI 10.1016/S0957-4174(00)00027-0; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kokuer M, 2006, IEEE T INF TECHNOL B, V10, P581, DOI 10.1109/TITB.2006.872054; LLORA X, 2001, P C ART INT; Medsker L., 1994, DESIGN DEV EXPERT SY; PAPAGELIS A, 2001, P INT C MACH LEARN; PETERSON MR, 2005, IEEE C EV COMP, V3, P2514; Quinlan R, 1993, C4 5 PROGRAMS MACHIN; Russel S., 1995, ARTIFICIAL INTELLIGE; SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458; Vapnik V. N, 1995, NATURE STAT LEARNING; Vapnik VN, 1998, STAT LEARNING THEORY; Witten I. H., 2005, DATA MINING PRACTICA	24	13	13	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	MAY 4	2008	34	4					2870	2878		10.1016/j.eswa.2007.05.035		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	267PO	WOS:000253521900065	
J	Bedo, J; Wenzl, P; Kowalczyk, A; Kilian, A				Bedo, Justin; Wenzl, Peter; Kowalczyk, Adam; Kilian, Andrzej			Precision-mapping and statistical validation of quantitative trait loci by machine learning	BMC GENETICS			English	Article							EXPERIMENTAL CROSSES; LINKAGE MAPS; BARLEY; QTL; GENOME; SELECTION; CANCER; PLANTS; MODEL; RFLP	Background: We introduce a QTL-mapping algorithm based on Statistical Machine Learning (SML) that is conceptually quite different to existing methods as there is a strong focus on generalisation ability. Our approach combines ridge regression, recursive feature elimination, and estimation of generalisation performance and marker effects using bootstrap resampling. Model performance and marker effects are determined using independent testing samples (individuals), thus providing better estimates. We compare the performance of SML against Composite Interval Mapping (CIM), Bayesian Interval Mapping (BIM) and single Marker Regression (MR) on synthetic datasets and a multi-trait and multi-environment dataset of the progeny for a cross between two barley cultivars. Results: In an analysis of the synthetic datasets, SML accurately predicted the number of QTL underlying a trait while BIM tended to underestimate the number of QTL. The QTL identified by SML for the barley dataset broadly coincided with known QTL locations. SML reported approximately half of the QTL reported by either CIM or MR, not unexpected given that neither CIM nor MR incorporates independent testing. The latter makes these two methods susceptible to producing overly optimistic estimates of QTL effects, as we demonstrate for MR. The QTL resolution (peak definition) afforded by SML was consistently superior to MR, CIM and BIM, with QTL detection power similar to BIM. The precision of SML was underscored by repeatedly identifying, at <= 1-cM precision, three QTL for four partially related traits (heading date, plant height, lodging and yield). The set of QTL obtained using a 'raw' and a 'curated' version of the same genotypic dataset were more similar to each other for SML than for CIM or MR. Conclusion: The SML algorithm produces better estimates of QTL effects because it eliminates the optimistic bias in the predictive performance of other QTL methods. It produces narrower peaks than other methods (except BIM) and hence identifies QTL with greater precision. It is more robust to genotyping and linkage mapping errors, and identifies markers linked to QTL in the absence of a genetic map.	[Wenzl, Peter; Kilian, Andrzej] Divers Arrays P L, Canberra, ACT 2600, Australia; [Bedo, Justin; Kowalczyk, Adam] Univ Melbourne, NICTA, Parkville, Vic 3010, Australia; [Bedo, Justin; Kowalczyk, Adam] Univ Melbourne, Dept Elect & Elect Engn, Parkville, Vic 3010, Australia; [Bedo, Justin] Australian Natl Univ, Res Sch Informat Sci & Engn, Canberra, ACT, Australia	Kilian, A (reprint author), Divers Arrays P L, 1 Wilf Crane Cr Yarralumla, Canberra, ACT 2600, Australia.	bedo@ieee.org; peter@DiversityArrays.com; adam.kowalczyk@nicta.com.au; andrzej@DiversityArrays.com					Asins MJ, 2002, PLANT BREEDING, V121, P281, DOI 10.1046/j.1439-0523.2002.730285.x; Basten C., 1994, P 5 WORLD C GEN APPL, P65; Basten C. J., 2005, QTL CARTOGRAPHER REF; Bost B, 2001, GENETICS, V157, P1773; Broman KW, 2003, BIOINFORMATICS, V19, P889, DOI 10.1093/bioinformatics/btg112; CHURCHILL GA, 1994, GENETICS, V138, P963; Doerge RW, 2002, NAT REV GENET, V3, P43, DOI 10.1038/nrg703; Doerge RW, 1996, GENETICS, V142, P285; Efron B, 1994, INTRO BOOTSTRAP; Ein-Dor L, 2005, BIOINFORMATICS, V21, P171, DOI 10.1093/bioinformatics/bth469; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; GUYON I, 2003, J MACHINE LEARNING R, V3, P1156; Han F, 1997, THEOR APPL GENET, V95, P903, DOI 10.1007/s001220050641; HANLEY JA, 1982, RADIOLOGY, V143, P29; Hastie T., 2003, SPRINGER SERIES STAT; HAYES PM, 1993, THEOR APPL GENET, V87, P392, DOI 10.1007/BF01184929; Hayes PM, 1994, BARLEY GENET NEWSL, V23, P98; Kao CH, 1999, GENETICS, V152, P1203; Kearsey MJ, 1998, HEREDITY, V80, P137, DOI 10.1038/sj.hdy.6885001; KLEINHOFS A, 1993, THEOR APPL GENET, V86, P705; LANDER ES, 1989, GENETICS, V121, P185; LINCOLN SE, 1992, GENOMICS, V14, P604, DOI 10.1016/S0888-7543(05)80158-2; Mauricio R, 2001, NAT REV GENET, V2, P370, DOI 10.1038/35072085; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Romagosa I, 1996, THEOR APPL GENET, V93, P30, DOI 10.1007/BF00225723; Sen S, 2001, GENETICS, V159, P371; STAM P, 1993, PLANT J, V3, P739, DOI 10.1111/j.1365-313X.1993.00739.x; Tikhonov A. N., 1943, DOKL AKAD NAUK SSSR, V39, P195; Utz HF, 2000, GENETICS, V154, P1839; Van Os H, 2005, THEOR APPL GENET, V112, P30, DOI 10.1007/s00122-005-0097-x; Wenzl P, 2004, P NATL ACAD SCI USA, V101, P9915, DOI 10.1073/pnas.0401076101; Wenzl P, 2006, BMC GENOMICS, V7, DOI 10.1186/1471-2164-7-206; Yandell BS, 2007, BIOINFORMATICS, V23, P641, DOI 10.1093/bioinformatics/btm011; Yi NJ, 2005, GENETICS, V170, P1333, DOI 10.1534/genetics.104.040386; ZENG ZB, 1993, P NATL ACAD SCI USA, V90, P10972, DOI 10.1073/pnas.90.23.10972; ZENG ZB, 1994, GENETICS, V136, P1457; STEPTOE MOREX BARLEY	37	3	3	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2156		BMC GENET	BMC Genet.	MAY 2	2008	9								35	10.1186/1471-2156-9-35		18	Genetics & Heredity	Genetics & Heredity	308FH	WOS:000256373200001	
J	Zhu, M				Zhu, M.			Kernels and ensembles: Perspectives on statistical learning	AMERICAN STATISTICIAN			English	Article						AdaBoost; kernel PCA; LAGO; parallel evolution; random forest; SVM		Since their emergence in the 1990s, the support vector machine and the AdaBoost algorithm have spawned a wave of research in statistical machine learning. Much of this new research falls into one of two broad categories: kernel methods and ensemble methods. In this expository article, I discuss the main ideas behind these two types of methods, namely how to transform linear algorithms into nonlinear ones by using kernel functions, and how to make predictions with an ensemble or a collection of models rather than a single model. I also share my personal perspectives on how these ideas have influenced and shaped my own research. In particular, I present two recent algorithms that I have invented with my collaborators: LAGO, a fast kernel algorithm for unbalanced classification and rare target detection; and Darwinian evolution in parallel universes, an ensemble method for variable selection.	Univ Waterloo, Dept Stat & Actuarial Sci, Waterloo, ON N2L 3G1, Canada	Zhu, M (reprint author), Univ Waterloo, Dept Stat & Actuarial Sci, Waterloo, ON N2L 3G1, Canada.	m3zhu@math.uwaterloo.ca					Akaike H., 1973, 2 INT S INF THEOR, P267; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Cristianini N., 2000, INTRO SUPPORT VECTOR; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Goldberg D. E., 1989, GENETIC ALGORITHM SE; GOLUB GH, 1979, TECHNOMETRICS, V21, P215, DOI 10.1080/00401706.1979.10489751; Hastie T, 2001, ELEMENTS STAT LEARNI; Mercer J, 1909, PHILOS T R SOC LOND, V209, P415, DOI 10.1098/rsta.1909.0016; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B, 1997, IEEE T SIGNAL PROCES, V45, P2758, DOI 10.1109/78.650102; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Vapnik V. N, 1995, NATURE STAT LEARNING; Zhu M, 2006, TECHNOMETRICS, V48, P193, DOI 10.1198/004017005000000643; Zhu M, 2006, TECHNOMETRICS, V48, P491, DOI 10.1198/004017006000000093	17	9	9	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	0003-1305		AM STAT	Am. Stat.	MAY	2008	62	2					97	109		10.1198/000313008X306367		13	Statistics & Probability	Mathematics	292IX	WOS:000255260800001	
J	Sarinnapakorn, K; Kubat, M				Sarinnapakorn, Kanoksri; Kubat, Miroslav			Induction from multi-label examples in information retrieval systems: A case study	APPLIED ARTIFICIAL INTELLIGENCE			English	Article							TEXT CATEGORIZATION; CLASSIFIERS; PERFORMANCE	Information retrieval systems Often use machine-learning techniques to induce classifiers capable of categorizing documents. Unfortunately, the circumstance that the same document may simultaneously belong to two or more categories has so far received inadequate attention, and induction techniques currently in use often suffer from, prohibitive computational costs. In the case study reported in this article, we managed to reduce these costs by running a "baseline induction algorithm" on the training examples described by diverse feature subsets, thus obtaining several subclassifiers. When asked about, a document's classes, a "master classifier" combines the outputs of the subclassifiers. This combination can be accomplished in several different ways, but we achieved the best results with our own mechanism inspired by the Dempster-Shafer Theory (DST). We describe the technique, compare its performance (experimentally) with that of more traditional voting approaches, and show that its substantial computational savings were achieved in exchange for acceptable loss in classification performance.	[Sarinnapakorn, Kanoksri; Kubat, Miroslav] Univ Miami, Dept Elect & Comp Engn, Coral Gables, FL 33146 USA	Sarinnapakorn, K (reprint author), Univ Miami, Dept Elect & Comp Engn, Coral Gables, FL 33146 USA.	ksarin@miami.edu					Al-Ani M, 2002, J ARTIF INTELL RES, V17, P333; Apte C, 1997, FUTURE GENER COMP SY, V13, P197, DOI 10.1016/S0167-739X(97)00021-6; BAHLER D, 2000, P NAT C ART INT AAAI; Bennett PN, 2005, INFORM RETRIEVAL, V8, P67, DOI 10.1023/B:INRT.0000048491.59134.94; BI Y, 2005, P IEEE INT C TOOLS A, P340; BI Y, 2004, P 1 INT C MOD DEC AR, P127; Blackman S., 1999, DESIGN ANAL MODERN T; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; CHEN J, 2004, P IEEE INT C COMP IN, P1153; Chen P, 2000, APPL PHYS A-MATER, V71, P191; CLARE A, 2001, P 5 EUR C PRINC PRAC; De Comite F., 2003, P 3 INT C MACH LEARN, P35; DECOMITE F, 2001, P C APPR AUT CAP 01, P195; Diao LL, 2002, PROCEEDINGS OF THE 4TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-4, P321; EYHERAMENDY S, 2003, P INT WORKSH ART INT; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; Freund Y., 1999, P 16 INT C MACH LEAR, P124; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Furnkranz J., 2002, Information Fusion, V3, DOI 10.1016/S1566-2535(02)00090-8; Gao S., 2004, P 21 INT C MACH LEAR, P329; Godbole Shantanu, 2004, P 8 PAC AS C KNOWL D, P22; HOLMES G, 2002, P EUR C MACH LEARN E; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Kubat M., 2001, Intelligent Data Analysis, V5; Kwok J. T.-Y., 1998, P INT C NEUR INF PRO, P347; Langley P., 1992, NAT C ART INT, P223; Lewis D. D., 1996, P 19 ANN INT ACM SIG, P298, DOI 10.1145/243199.243277; Li B.L., 2004, ACM T ASIAN LANGUAGE, V3, P215; MCCALLUM A, 1998, P WORKSH LEARN TEXT; RAHMAN AFR, 2002, LECT NOTES COMPUTER, V2423; ROLI F, 2002, DESIGN MULTIPLE CLAS; Ruiz ME, 2002, INFORM RETRIEVAL, V5, P87, DOI 10.1023/A:1012782908347; RUIZ ME, 1998, ADV CLASSIFICATION R, V8, P59; Salton G., 1983, INTRO MODERN INFORM; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Shafer Glenn, 1976, MATH THEORY EVIDENCE; Uren VS, 2002, COMPUT J, V45, P511, DOI 10.1093/comjnl/45.5.511; van Rijsbergen C. J., 1979, INFORM RETRIEVAL; VILAR D, 2004, P ESP NAT LANG PROC; Weiss SM, 1999, IEEE INTELL SYST APP, V14, P63, DOI 10.1109/5254.784086; Wiener E., 1995, P 4 ANN S DOC AN INF, P317; YANG YM, 1994, ACM T INFORM SYST, V12, P252, DOI 10.1145/183422.183424; Zhang DW, 2005, FOREST POLICY ECON, V7, P721, DOI 10.1016/j.forpol.2005.03.002; ZHANG ML, 2006, IEEE T KNOWL DATA EN, P1338; Zhu S., 2005, P 28 ANN INT ACM SIG, P274, DOI 10.1145/1076034.1076082	48	4	4	TAYLOR & FRANCIS INC	PHILADELPHIA	325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA	0883-9514		APPL ARTIF INTELL	Appl. Artif. Intell.	MAY	2008	22	5					407	432		10.1080/08839510801972827		26	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	305OW	WOS:000256188700002	
J	Kianrnehr, K; Alhajj, R				Kianrnehr, Keivan; Alhajj, Reda			Effectiveness of support vector machine for crime hot-spots prediction	APPLIED ARTIFICIAL INTELLIGENCE			English	Article							SPATIAL DATA-ANALYSIS; GENERATION; MODEL	Crime hot-spot location prediction is important for public safety. The output from the predict tion can provide useful information to improve the activities aimed at detecting and preventing safely and security problems. Location prediction is a special case of spatial data mining classification. Tor instance, in the public safety domain, it may be interesting to predict location(s) of crime hot spots. In, this study, we present a support vector machine (SVM)-based approach to predict the location as an alternative to existing modeling approaches. Support vector machine forms the new generation of machine-learning techniques used to find optimal separability between classes within datasets. We compare the performance of two types of SVMs techniques: two-class SVMs and one-class SVMs. We also compared SVM with a neural network-based approach and spatial auto-regression-based approach. Experiments on two different spatial datasets demonstrate that the former approach performs slightly better and the latter one gives reasonable results. Furthermore, in this study, toe provide a general framework to customize the spatial data classification task for other spatial domains that have datasets similar to the analyzed crime datasets.	[Kianrnehr, Keivan; Alhajj, Reda] Univ Calgary, Dept Comp Sci, Calgary, AB T2N 1N4, Canada; [Alhajj, Reda] Global Univ, Dept Comp Sci, Beirut, Lebanon	Kianrnehr, K (reprint author), Univ Calgary, Dept Comp Sci, 2500 Univ Dr NW, Calgary, AB T2N 1N4, Canada.	alhaj@cpsc.ucalgary.ca					Anselin L., 1988, SPATIAL ECONOMETRICS; ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI 10.2307/1990404; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; BROWN MA, 1982, ECON GEOGR, V58, P247, DOI 10.2307/143513; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; CHAWLA S, 2000, PREDICTING LOCATIONS, P14; Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866; Cristianini N., 2000, INTRO SUPPORT VECTOR; Cristianini N, 2002, AI MAG, V23, P31; Dunham MH, 2002, DATA MINING INTRO AD; EDELSTEIN HA, 1999, INTRO DATA MINING KN; GIROSI F, 1997, EQUIVALENCE SPARSE A; GOU Q, 2005, ECOLOGICAL MODELING, V182, P75; Guo Jessica, 2004, THESIS U TEXAS AUSTI; KAMINSKI RJ, 2000, ATLAS CRIME MAPPING, P212; KOPERSKI K., 1995, P 4 INT S LARG SPAT, P47; KOPERSKI K, 1996, P ACM SIGMOD WORKSH, P55; KOWALCZYK A, 2002, SIGKDD EXPLORATIONS, V4, P99; KRUENGKRAI C, 2003, P INT S COMM INF TEC; Kulldorff M, 1997, COMMUN STAT-THEOR M, V26, P1481, DOI 10.1080/03610929708831995; LeSage J., 1999, THEORY PRACTIC UNPUB; LESAGE J, 1999, MATLAB TOOLBOX SPATI; Lesage James.P, 1997, J REGIONAL ANAL POLI, V27, P83; Levine N.L., 2002, CRIMESTAT SPATIAL ST; Lu W., 1993, P FAR E WORKSH GEOGR, P275; Manevitz L., 2001, J MACHINE LEARNING R, V2, P139; McFadden D., 1973, FRONTIERS ECONOMETRI, P105; Messner SF, 1999, J QUANT CRIMINOL, V15, P423, DOI 10.1023/A:1007544208712; Miller H, 2001, GEOGRAPHIC DATA MINI; Murray AT, 2000, GEOGR ANAL, V32, P1; Murray AT, 1998, INT J GEOGR INF SCI, V12, P431; Ozesmi SL, 1999, ECOL MODEL, V116, P15, DOI 10.1016/S0304-3800(98)00149-5; Ozesmi U, 1997, ECOL MODEL, V101, P139, DOI 10.1016/S0304-3800(97)01983-2; Pellegrini PA, 2002, PROG HUM GEOG, V26, P487, DOI 10.1191/0309132502ph382ra; SCHOLKOPF B, 1999, NEURAL COMPUT, P1443; Shapiro G.P., 1991, KNOWLEDGE DISCOVERY; Shekhar S, 2004, DATA MINING NEXT GEN, P357; Tax D M J, 2001, P ASCI 2001 7 ANN C, P234; Tax DMJ, 2002, J MACH LEARN RES, V2, P155, DOI 10.1162/15324430260185583; Vapnik VN, 1998, STAT LEARNING THEORY; Vapnik V.N., 1999, NATURE STAT LEARNING; Wahba G., 1990, CBMS NFS REGIONAL C; Xue WF, 2003, IEEE T SYST MAN CY C, V33, P78, DOI 10.1109/TSMCC.2003.809867; Zeng D., 2004, P 7 IEEE INT C INT T, P106; *HOM OFF, 2004, CRIM RED TOOLK PUBL	45	2	3	TAYLOR & FRANCIS INC	PHILADELPHIA	325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA	0883-9514		APPL ARTIF INTELL	Appl. Artif. Intell.	MAY	2008	22	5					433	458		10.1080/08839510802028405		26	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	305OW	WOS:000256188700003	
J	Kovaievic, M; Davidson, CH				Kovaievic, Milos; Davidson, Colin H.			Crawling the construction web - A machine-learning approach without negative examples	APPLIED ARTIFICIAL INTELLIGENCE			English	Article							RETRIEVAL	Professionals and craftsmen in the construction sector make an intensive use of information in their decision-making processes but only make limited use of the abundant information, that is potentially available to them, particularly on the web. Consequently, designs are impoverished, construction is defective, and innovation is delayed. To facilitate convivial access to focused information, we have developed a question-and-answer (Q-A) system (reported elsewhere). To support this system, we have developed an automated crawler that permits the establishment of a bank of relevant Pages, adopted to the needs of this particular industry-user community. It is based on the in which all intelligent decision unit is trained to distinguish between nontopic and informative pages. We show that standard approaches which use both positive and negative classes are sensitive to the noise in the negative class. We propose different techniques for learning without negative examples, since initially one only has limited, positive information labeled by human experts; they are evaluated. Our crawler that, uses the positive examples-based learning (PEBL) framework is able to collect construction-oriented pages with high precision and discovery rate. It can also be used to build domain-specific collections of pages in different scientific or professional contexts.	[Davidson, Colin H.] Univ Montreal, Sch Architecture, Montreal, PQ H3C 3J7, Canada; [Kovaievic, Milos] Univ Belgrade, Sch Civil Engn, Belgrade, Serbia	Davidson, CH (reprint author), Univ Montreal, Sch Architecture, POB 6128, Montreal, PQ H3C 3J7, Canada.	colinhdavidson@sympatico.ca					Aggarwal C., 2001, P 10 INT WORLD WID W, P96, DOI DOI 10.1145/371920.371955; Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X; Broder A.Z., 1993, SEQUENCES, P143; Chakrabarti S, 1999, COMPUT NETW, V31, P1623, DOI 10.1016/S1389-1286(99)00052-3; Chakrabarti S., 2002, P 11 INT WORLD WID W, P148; Chen HC, 2002, DECIS SUPPORT SYST, V34, P1, DOI 10.1016/S0167-9236(02)00002-7; DAVIDSON CH, 2004, AGENDA 11 INFORM DOC; Davison B. D., 2000, P 23 ANN INT C RES D, P272, DOI 10.1145/345508.345597; Diligenti M., 2000, P 26 INT C VER LARG, P527; Fletcher R., 1987, PRACTICAL METHODS OP; Herscovici M., 1998, P 7 INT WORLD WID WE, P317; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; JOHNSON J, 2003, P 20 INT C MACH LEAR, P298; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kovacevic M, 2008, J COMPUT CIVIL ENG, V22, P3, DOI 10.1061/(ASCE)0887-3801(2008)22:1(3); Lawrence S, 1998, SCIENCE, V280, P98, DOI 10.1126/science.280.5360.98; McCallum AK, 2000, INFORM RETRIEVAL, V3, P127, DOI 10.1023/A:1009953814988; Menczer F, 2000, MACH LEARN, V39, P203, DOI 10.1023/A:1007653114902; Menczer F, 2004, J AM SOC INF SCI TEC, V55, P1261, DOI 10.1002/asi.20081; Menczer F., 2001, P 24 ANN INT ACM SIG, P241, DOI 10.1145/383952.383995; MILUTINOVIC V, 1996, IEEE TCCA SEPT; Mohsini R., 1991, BUILD RES INF, V19, P106, DOI 10.1080/09613219108727107; PANT G, 2003, P 7 EUR C RES ADV TE, P233; Pant G., 2004, P 4 ACM IEEE CS JOIN, P142, DOI 10.1145/996350.996384; Pant G, 2005, ACM T INFORM SYST, V23, P430, DOI 10.1145/1095872.1095875; DEBRA PME, 1994, COMPUT NETWORKS ISDN, V27, P183, DOI 10.1016/0169-7552(94)90132-5; QIN J, 2004, P 4 ACM IEEE CS JOIN, P135, DOI 10.1145/996350.996383; Salton G., 1989, AUTOMATIC TEXT PROCE; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Srinivasan P, 2005, INFORM RETRIEVAL, V8, P417, DOI 10.1007/s10791-005-6993-5; Surges C.J.C., 1998, TUTORIAL SUPPORT VEC; Vapnik V. N, 1995, NATURE STAT LEARNING; Wu XY, 2004, LECT NOTES COMPUT SC, V3201, P489; Yang Yiming, 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; Yang Yiming, 1997, P 14 INT C MACH LEAR, P412; YU H, 2004, IEEE T KNOWL DATA EN, V16, P1	37	0	0	TAYLOR & FRANCIS INC	PHILADELPHIA	325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA	0883-9514		APPL ARTIF INTELL	Appl. Artif. Intell.	MAY	2008	22	5					459	482		10.1080/08839510802028447		24	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	305OW	WOS:000256188700004	
J	Li, HQ; Dai, XB; Zhao, XC				Li, Haiquan; Dai, Xinbin; Zhao, Xuechun			A nearest neighbor approach for automated transporter prediction and categorization from protein sequences	BIOINFORMATICS			English	Article							TRANSMEMBRANE TOPOLOGY; COMPREHENSIVE DATABASE; MEMBRANE-PROTEINS; CLASSIFICATION; FAMILY; RECOGNITION; RESOURCE; CHANNELS; PROGRAM; BIOLOGY	Motivation: Membrane transport proteins play a crucial role in the import and export of ions, small molecules or macromolecules across biological membranes. Currently, there are a limited number of published computational tools which enable the systematic discovery and categorization of transporters prior to costly experimental validation. To approach this problem, we utilized a nearest neighbor method which seamlessly integrates homologous search and topological analysis into a machine-learning framework. Results: Our approach satisfactorily distinguished 484 transporter families in the Transporter Classification Database, a curated and representative database for transporters. A five-fold cross-validation on the database achieved a positive classification rate of 72.3 on average. Furthermore, this method successfully detected transporters in seven model and four non-model organisms, ranging from archaean to mammalian species. A preliminary literature-based validation has cross-validated 65.8 of our predictions on the 11 organisms, including 55.9 of our predictions overlapping with 83.6 of the predicted transporters in TransportDB. Availability and Supplementary information: http://www.w3.org/1999/xlink">http://bioinfo.noble.org/manuscript-support/transporter/ Contact: pzhao@noble.org.	[Li, Haiquan; Dai, Xinbin; Zhao, Xuechun] Samuel Roberts Noble Fdn Inc, Div Plant Biol, Bioinformat Lab, Ardmore, OK 73401 USA	Zhao, XC (reprint author), Samuel Roberts Noble Fdn Inc, Div Plant Biol, Bioinformat Lab, 2510 Sam Noble Pkwy, Ardmore, OK 73401 USA.						ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Apweiler R, 2001, Brief Bioinform, V2, P9, DOI 10.1093/bib/2.1.9; Bejerano G, 2001, BIOINFORMATICS, V17, P23, DOI 10.1093/bioinformatics/17.1.23; Ashburner M, 2000, NAT GENET, V25, P25; Busch W, 2002, CRIT REV BIOCHEM MOL, V37, P287, DOI 10.1080/10409230290771528; Chang AB, 2004, MOL MEMBR BIOL, V21, P171, DOI 10.1080/09687680410001720830; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dibrov P, 1998, FEBS LETT, V424, P1, DOI 10.1016/S0014-5793(98)00119-7; DOOLITTLE RF, 1981, SCIENCE, V214, P149, DOI 10.1126/science.7280687; Eskin E, 2003, J COMPUT BIOL, V10, P187, DOI 10.1089/106652703321825964; Haft DH, 2001, NUCLEIC ACIDS RES, V29, P41, DOI 10.1093/nar/29.1.41; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; Heil B, 2006, BIOINFORMATICS, V22, P1562, DOI 10.1093/bioinformatics/btl132; HENIKOFF S, 1994, GENOMICS, V19, P97, DOI 10.1006/geno.1994.1018; Hofmann K., 1993, BIOL CHEM HOPPESEYLE, V374, P166; Horton P, 1997, Proc Int Conf Intell Syst Mol Biol, V5, P147; John B, 2004, PROTEIN SCI, V13, P54, DOI 10.1110/ps.03335004; KROGH A, 1994, J MOL BIOL, V235, P1501, DOI 10.1006/jmbi.1994.1104; Leonardi FG, 2006, BIOINFORMATICS, V22, P1302, DOI 10.1093/bioinformatics/bt/088; Lin HH, 2006, PROTEINS, V62, P218, DOI 10.1002/prot.20605; Paulsen IT, 1998, J MOL BIOL, V277, P573, DOI 10.1006/jmbi.1998.1609; Pruitt KD, 2005, NUCLEIC ACIDS RES, V33, pD501, DOI 10.1093/nar/gki025; Ren QH, 2004, NUCLEIC ACIDS RES, V32, pD284, DOI 10.1093/nar/gkh016; Ren QH, 2007, NUCLEIC ACIDS RES, V35, pD274, DOI 10.1093/nar/gkl925; RIGAUD JL, 1995, BBA-BIOENERGETICS, V1231, P223, DOI 10.1016/0005-2728(95)00091-V; Saier MH, 2000, MICROBIOL MOL BIOL R, V64, P354, DOI 10.1128/MMBR.64.2.354-411.2000; Saier MH, 2006, NUCLEIC ACIDS RES, V34, pD181, DOI 10.1093/nar/gkj001; SAKMANN B, 1984, ANNU REV PHYSIOL, V46, P455, DOI 10.1146/annurev.physiol.46.1.455; SCHAFFER C, 1993, MACH LEARN, V13, P135, DOI 10.1023/A:1022639714137; Schwacke R, 2003, PLANT PHYSIOL, V131, P16, DOI 10.1104/pp.011577; Sonnhammer ELL, 1997, PROTEINS, V28, P405, DOI 10.1002/(SICI)1097-0134(199707)28:3<405::AID-PROT10>3.0.CO;2-L; Tusnady GE, 2001, BIOINFORMATICS, V17, P849, DOI 10.1093/bioinformatics/17.9.849; YAN Q, 2003, MEMBRANE TRANSPORTER, V227; Zdobnov EM, 2001, BIOINFORMATICS, V17, P847, DOI 10.1093/bioinformatics/17.9.847; Zhai YF, 2001, J MOL MICROB BIOTECH, V3, P501; Zhou XF, 2003, J MOL MICROB BIOTECH, V5, P7, DOI 10.1159/000068719	36	11	13	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	MAY 1	2008	24	9					1129	1136		10.1093/bioinformatics/btn099		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	293DB	WOS:000255313900002	
J	Chuang, CL; Jen, CH; Chen, CM; Shieh, GS				Chuang, Cheng-Long; Jen, Chih-Hung; Chen, Chung-Ming; Shieh, Grace S.			A pattern recognition approach to infer time-lagged genetic interactions	BIOINFORMATICS			English	Article							YEAST SACCHAROMYCES-CEREVISIAE; INTERACTION NETWORK; TRANSCRIPTION FACTOR; EXPRESSION PROFILES; GRAPHICAL MODELS; RECOMBINATION; MICROARRAY; SGS1; HELICASE; REPAIR	Motivation: For any time-course microarray data in which the gene interactions and the associated paired patterns are dependent, the proposed pattern recognition (PARE) approach can infer time-lagged genetic interactions, a challenging task due to the small number of time points and large number of genes. PARE utilizes a non-linear score to identify subclasses of gene pairs with different time lags. In each subclass, PARE extracts non-linear characteristics of paired gene-expression curves and learns weights of the decision score applying an optimization algorithm to microarray gene-expression data (MGED) of some known interactions, from biological experiments or published literature. Namely, PARE integrates both MGED and existing knowledge via machine learning, and subsequently predicts the other genetic interactions in the subclass. Results: PARE, a time-lagged correlation approach and the latest advance in graphical Gaussian models were applied to predict 112 (132) pairs of TC/TD (transcriptional regulatory) interactions. Checked against qRT-PCR results (published literature), their true positive rates are 73 (77), 46 (51), and 52 (59), respectively. The false positive rates of predicting TC and TD (AT and RT) interactions in the yeast genome are bounded by 13 and 10 (10 and 14), respectively. Several predicted TC/TD interactions are shown to coincide with existing pathways involving Sgs1, Srs2 and Mus81. This reinforces the possibility of applying genetic interactions to predict pathways of protein complexes. Moreover, some experimentally testable gene interactions involving DNA repair are predicted. Availability: Supplementary data and PARE software are available at http://www.stat.sinica.edu.tw/similar to gshieh/pare.htm. Contact: gshieh@stat.sinica.edu.tw.	[Chuang, Cheng-Long; Chen, Chung-Ming; Shieh, Grace S.] Natl Taiwan Univ, Inst Biomed Engn, Taipei 106, Taiwan; [Chuang, Cheng-Long; Shieh, Grace S.] Acad Sinica, Inst Stat Sci, Taipei 115, Taiwan; [Jen, Chih-Hung] Natl Yang Ming Univ, Genome Res Ctr, Taipei 112, Taiwan	Shieh, GS (reprint author), Natl Taiwan Univ, Inst Biomed Engn, Taipei 106, Taiwan.						Bay SD, 2002, J BIOMED INFORM, V35, P289, DOI 10.1016/S1532-0464(03)00031-5; Boiteux S, 2006, METHOD ENZYMOL, V408, P79, DOI 10.1016/S0076-6879(06)08006-2; CHUANG CL, 2005, C200505 AC SIN I STA; Collins SR, 2007, NATURE, V446, P806, DOI 10.1038/nature05649; Dobra A, 2004, J MULTIVARIATE ANAL, V90, P196, DOI 10.1016/j.jmva.2004.02.009; DRAPER MP, 1994, MOL CELL BIOL, V14, P4522; Eberhart RC, 1995, P 6 INT S MICR HUM S, P39, DOI DOI 10.1109/MHS.1995.494215; Fabre F, 2002, P NATL ACAD SCI USA, V99, P16887, DOI 10.1073/pnas.252652399; Fricke WM, 2003, GENE DEV, V17, P1768, DOI 10.1101/gad.1105203; Friedman N, 2004, SCIENCE, V303, P799, DOI 10.1126/science.1094068; Gancedo JM, 1998, MICROBIOL MOL BIOL R, V62, P334; Gonzalez RC, 2002, DIGITAL IMAGE PROCES; Hartman JL, 2001, SCIENCE, V291, P1001, DOI 10.1126/science.291.5506.1001; Hoffmann R, 2004, NAT GENET, V36, P664, DOI 10.1038/ng0704-664; Husmeier D, 2003, BIOINFORMATICS, V19, P2271, DOI 10.1093/bioinformatics/btg313; Kafri R, 2005, NAT GENET, V37, P295, DOI 10.1038/ng1523; Kishino H, 2000, Genome Inform Ser Workshop Genome Inform, V11, P83; Lee KM, 2007, GENETICS, V175, P1585, DOI 10.1534/genetics.106.067801; Lemmens K, 2006, GENOME BIOL, V7, DOI 10.1186/gb-2006-7-5-r37; Lesage G, 2004, GENETICS, V167, P35, DOI 10.1534/genetics.167.1.35; Lo YC, 2006, MOL CELL BIOL, V26, P4086, DOI 10.1128/MCB.00136-06; McVey M, 2001, GENETICS, V157, P1531; Mewes HW, 1999, NUCLEIC ACIDS RES, V27, P44, DOI 10.1093/nar/27.1.44; MONSON HH, 1996, STAT DIGITAL SIGNAL; Onoda F, 2001, MOL GEN GENET, V264, P702; Ooi SL, 2003, NAT GENET, V35, P277, DOI 10.1038/ng1258; Pan XW, 2006, CELL, V124, P1069, DOI 10.1016/j.cell.2005.12.036; Qian J, 2001, J MOL BIOL, V314, P1053, DOI 10.1006/jmbi.2000.5219; REIS BY, 2000, P RECOMB, P5; Schafer J, 2005, BIOINFORMATICS, V21, P754, DOI 10.1093/bioinformatics/bti062; Schmidt KH, 2004, MOL CELL BIOL, V24, P3213, DOI 10.1128/MCB.24.8.3213-3226.2004; Schmitt WA, 2004, GENOME RES, V14, P1654, DOI 10.1101/gr.2439804; SHIEH GS, 2004, P 2004 TAIP S STAT G, P357; SHIEH GS, 2005, C200504 AC SIN I STA; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Toh H, 2002, BIOINFORMATICS, V18, P287, DOI 10.1093/bioinformatics/18.2.287; Toh H, 2002, J BIOL PHYS, V28, P449, DOI 10.1023/A:1020337311471; Tong AHY, 2004, SCIENCE, V303, P808, DOI 10.1126/science.1091317; Tong AHY, 2001, SCIENCE, V294, P2364, DOI 10.1126/science.1065810; Tsai HK, 2006, BIOINFORMATICS, V22, P1675, DOI 10.1093/bioinformatics/btl160; Tsai HK, 2005, P NATL ACAD SCI USA, V102, P13532, DOI 10.1073/pnas.0505874102; Waddell P J, 2000, Genome Inform Ser Workshop Genome Inform, V11, P129; WANG F, 2003, BIOMETRIKA, V90, P809; Whittaker J., 1990, GRAPHICAL MODELS APP; Wong SL, 2005, TRENDS GENET, V21, P424, DOI 10.1016/j.tig.2005.06.006; Wong SL, 2005, GENETICS, V171, P829, DOI 10.1534/genetics.105.046060; WU X, 2003, P ACM SIGKDD WORKSH, V3, P63; Xu H, 2004, MOL CELL BIOL, V24, P7082, DOI 10.1128/MCB.24.16.7082-7090.2004; Zhang B, 2005, STAT APPL GENET MO B, V4, DOI 10.2202/1544-6115.1128	49	15	15	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	MAY 1	2008	24	9					1183	1190		10.1093/bioinformatics/btn098		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	293DB	WOS:000255313900009	
J	George, ED; Farid, SS				George, Edmund D.; Farid, Suzanne S.			Strategic biopharmaceutical portfolio development: An analysis of constraint-induced implications	BIOTECHNOLOGY PROGRESS			English	Article; Proceedings Paper	234th National Meeting of the American-Chemical-Society	AUG 19-23, 2007	Boston, MA	Amer Chem Soc			ASSESSING BIOMANUFACTURING STRATEGIES; SIMULATION-OPTIMIZATION FRAMEWORK; DEVELOPMENT PIPELINE MANAGEMENT; DECISION-SUPPORT TOOL; PHARMACEUTICAL-INDUSTRY; PRODUCT DEVELOPMENT; UNCERTAINTY; CAPACITY; MANUFACTURE; DESIGN	Optimizing the structure and development pathway of biopharmaceutical drug portfolios are core concerns to the developer that come with several attached complexities. These include strategic decisions for the choice of drugs, the scheduling of critical activities, and the possible involvement of third parties for development and manufacturing at various stages for each drug. Additional complexities that must be considered include the impact of making such decisions in an uncertain environment. Presented here is the development of a stochastic multi-objective optimization framework designed to address these issues. The framework harnesses the ability of Bayesian networks to characterize the probabilistic structure of superior decisions via machine learning and evolve them to multi-objective optimality. Case studies that entailed three- and five-drug portfolios alongside a range of cash flow constraints were constructed to derive insight from the framework where results demonstrate that a variety of options exist for formulating nondominated strategies in the objective space considered, giving the manufacturer a range of pursuable options. In all cases limitations on cash flow reduce the potential for generating profits for a given probability of success. For the sizes of portfolio considered, results suggest that naively applying strategies optimal for a particular size of portfolio to a portfolio of another size is inappropriate. For the five-drug portfolio the most preferred means for development across the set of optimized strategies is to fully integrate development and commercial activities in-house. For the three-drug portfolio, the preferred means of development involves a mixture of in-house, outsourced, and partnered activities. Also, the size of the portfolio appears to have a larger impact on strategy and the quality of objectives than the magnitude of cash flow constraint.	[George, Edmund D.; Farid, Suzanne S.] UCL, Dept Biochem Engn, Adv Ctr Biochem Engn, London WC1E 7JE, England	Farid, SS (reprint author), UCL, Dept Biochem Engn, Adv Ctr Biochem Engn, Torrington Pl, London WC1E 7JE, England.	s.farid@ucl.ac.uk	Farid, Suzanne/C-2473-2008				ASHTON G, 2001, NAT BIOTECHNOL, V10, P307; BLAU G, 2000, COMPUT CHEM ENG, V24, P2211; BLAU GE, 2004, J PROD INNOVATION MA, V21, P27; Buntine W., 1991, P 7 C UNC ART INT, P52; Choi J, 2004, COMPUT CHEM ENG, V28, P1039, DOI 10.1016/j.compchemeng.2003.09.024; COLVIN M, 2008, COMPUT CHEM ENG; DiMasi JA, 2003, J HEALTH ECON, V22, P151, DOI 10.1016/S0167-6296(02)00126-1; Farid SS, 2005, BIOTECHNOL PROGR, V21, P486, DOI 10.1021/bp049692b; Farid SS, 2005, BIOTECHNOL PROGR, V21, P1183, DOI 10.1021/bp050070f; Farid SS, 2007, COMPUT CHEM ENG, V31, P1141, DOI 10.1016/j.compchemeng.2006.10.020; FINNEGAN S, 2006, BIOPROCESS INT, V4, pS56; FOO F, 2001, BIOPHARM EUR, V13, P58; Gatica G, 2003, CHEM ENG RES DES, V81, P665, DOI 10.1205/026387603322150516; George E, 2007, COMPUT CHEM ENG, V31, P889, DOI 10.1016/j.compchemeng.2006.12.009; GETZ K, 1997, CLIN RES REGUL AFFAI, V14, P243; Goldberg DE, 1989, GENETIC ALGORITHMS S; Harik GR, 1999, IEEE T EVOLUT COMPUT, V3, P287, DOI 10.1109/4235.797971; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; HOLLAND JH, 1975, ADAPTATION NATURAL A; Jain V, 1999, IND ENG CHEM RES, V38, P3013, DOI 10.1021/ie9807809; Lakhdar K, 2005, BIOTECHNOL PROGR, V21, P1478, DOI 10.1021/bp0501571; Levis AA, 2004, COMPUT CHEM ENG, V28, P707, DOI 10.1016/j.compchemeng.2004.02.012; LIM AC, 2005, BIOTECHNOL BIOENG, V93, P687; Lim AC, 2005, BIOTECHNOL PROGR, V21, P1231, DOI 10.1021/bp049578t; Macqueen J. B., 1967, P 5 BERK S MATH STAT, P281; Maravelias CT, 2001, IND ENG CHEM RES, V40, P6147, DOI 10.1021/ie010301x; Matsumoto M., 1998, ACM Transactions on Modeling and Computer Simulation, V8, DOI 10.1145/272991.272995; Muhlenbein H., 1998, EVOLUTIONARY COMPUTA, V5, P303; Muhlenbein H, 1996, PARALLEL PROBLEM SOL, P178, DOI 10.1007/3-540-61723-X; Neapolitan R. E., 2003, LEARNING BAYESIAN NE; Nicholson S, 2005, J BUS, V78, P1433, DOI 10.1086/430865; Oh HC, 2004, IND ENG CHEM RES, V43, P3364, DOI 10.1021/ie034339g; Papageorgiou LG, 2001, IND ENG CHEM RES, V40, P275, DOI 10.1021/ie990870t; Pelikan M., 2005, P 2005 C GEN EV COMP, P663, DOI 10.1145/1068009.1068122; Pelikan M, 2000, EVOL COMPUT, V8, P311, DOI 10.1162/106365600750078808; PELIKAN M, 2000, COMPUTATIONAL OPTIMI, V21, P5; Piachaud BS, 2002, TECHNOVATION, V22, P81, DOI 10.1016/S0166-4972(01)00081-5; RAKAPAKSE A, 2006, J CHEM TECHNOL BIOCH, V81, P1705; RAKAPAKSE A, 2005, COMPUT CHEM ENG, V29, P1357; Reichert JM, 2003, NAT REV DRUG DISCOV, V2, P695, DOI 10.1038/nrd1178; Rogers MJ, 2002, IND ENG CHEM RES, V41, P6607, DOI 10.1021/ie020385p; Rogers MJ, 2005, AICHE J, V51, P198, DOI 10.1002/aic.10280; Subramanian D, 2003, AICHE J, V49, P96, DOI 10.1002/aic.690490110; Subramanian D, 2001, AICHE J, V47, P2226, DOI 10.1002/aic.690471010; TRIANTAPHYLLOU E, 2000, MULTI CRITERIA DECIS; VARMA VA, 2008, COMPUT CHEM ENG; Werner RG, 2004, J BIOTECHNOL, V113, P171, DOI 10.1016/j.jbiotec.2004.04.036; Yang SL, 2002, IEEE T SYST MAN CY A, V32, P419; *BOST CONS GROUP, 2001, REV R D GEN GEN TRAN	49	3	3	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	8756-7938		BIOTECHNOL PROGR	Biotechnol. Prog.	MAY-JUN	2008	24	3					698	713		10.1021/bp070410s		16	Biotechnology & Applied Microbiology; Food Science & Technology	Biotechnology & Applied Microbiology; Food Science & Technology	311IG	WOS:000256593300029	
J	Liu, YB; Wang, JM; Yang, Y; Sun, JG				Liu, Yingbo; Wang, Jianmin; Yang, Yun; Sun, Jiaguang			A semi-automatic approach for workflow staff assignment	COMPUTERS IN INDUSTRY			English	Article						staff assignment; resource management; workflow; machine learning	PATTERNS	Staff assignment is of great importance for workflow management systems. In many workflow applications, staff assignment is still performed manually. In this paper, we present a semi-automatic approach intended to reduce the number of manual staff assignment. Our approach applies a machine learning algorithm to the workflow event log to learn various kinds of activities that each actor undertakes. When staff assignment is needed, the classifiers generated by the machine learning technique suggest a suitable actor to undertake the specified activities. With experiments on three enterprises, our approach achieved a fairly accurate recommendation. (c) 2008 Elsevier B.V. All rights reserved.	[Liu, Yingbo; Wang, Jianmin; Sun, Jiaguang] Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China; [Liu, Yingbo] Tsinghua Univ, Dept Comp Sci, Beijing 100084, Peoples R China; [Wang, Jianmin; Sun, Jiaguang] Tsinghua Natl Lab Informat Sci & Technol, Beijing, Peoples R China; [Yang, Yun] Swinburne Univ Technol, Swinburne CITR Ctr Informat Technol Res, Fac ICT, Hawthorn, Vic 3122, Australia	Liu, YB (reprint author), Tsinghua Univ, Sch Software, 15 Bldg,1327A Room, Beijing 100084, Peoples R China.	lyb01@mails.tsinghua.edu.cn; jimwang@tsinghua.edu.cn; yyang@it.swin.edu.au; sunjg@tsinghua.edu.c					Ahuja R.K., 1993, NETWORK FLOWS THEORY; Bennour M, 2005, INT J PROD RES, V43, P4559, DOI 10.1080/00207540500124579; CASATI F, 2007, 33 INT C VER LARG DA, P1128; DU WM, 1999, ENTERPRISE WORKFLOW, P108; Ferraiolo D. F., 2001, ACM Transactions on Information and Systems Security, V4, DOI 10.1145/501978.501980; Grigori D, 2004, COMPUT IND, V53, P321, DOI 10.1016/j.compind.2003.10.007; Grigori D., 2001, Proceedings of the 27th International Conference on Very Large Data Bases; Han J., 2001, DATA MINING CONCEPTS; Huang YN, 1999, PROC INT CONF DATA, P103; Kumar A., 2002, J MANAGE INFORM SYST, V18, P157; Leymann F., 1999, PRODUCTION WORKFLOW; LIU Y, 2007, 22 ANN ACM S APPL CO, P340; Ly LT, 2006, LECT NOTES COMPUT SC, V3812, P177; PESIC M, 2005, P 6 WORKSH PRACT US, P157; Platt J., 1998, ADV KERNEL METHODS S; QUINLAN R, 1993, ESTIMATING CONTINUOU; REIS CAL, 2002, P 14 INT C SOFTW ENG, P795; Rinderle S., 2007, LIFE CYCLE SUPPORT S; Russell N., 2004, WORKFLOW DATA PATTER; Russell N., 2005, WORKFLOW RESOURCE PA; Russell N, 2005, LECT NOTES COMPUT SC, V3520, P216; SEGAL R, 2000, 7 INT C MACH LEARN, P863; Van Der Aalst W. M. P., 2005, Computer Supported Cooperative Work: The Journal of Collaborative Computing, V14, DOI 10.1007/s10606-005-9005-9; VANDERAALST W, 2003, SAC, P603; van der Aalst WMP, 2004, LECT NOTES COMPUT SC, V3080, P244; Van der Aalst WMP, 2003, DISTRIB PARALLEL DAT, V14, P5, DOI 10.1023/A:1022883727209; Witten I. H., 2005, DATA MINING PRACTICA; zur Muehlen M., 2004, INFORM TECHNOL MANAG, V5, P271, DOI 10.1023/B:ITEM.0000031582.55219.2b; *CIMDATA, PROD LIF MAN; 1996, WORKFLOW MANAGEMENT; INTRO INFOTECH PRODU	31	8	8	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0166-3615		COMPUT IND	Comput. Ind.	MAY	2008	59	5					463	476		10.1016/j.compind.2007.12.002		14	Computer Science, Interdisciplinary Applications	Computer Science	304WM	WOS:000256139800005	
J	Hong, GH; Ha, SH				Hong, Gye-hang; Ha, Sung Ho			Evaluating supply partner's capability for seasonal products using machine learning techniques	COMPUTERS & INDUSTRIAL ENGINEERING			English	Article						supply chain management; supply capability; seasonal products; data mining; multi-criteria decision making	RELATIONSHIP MANAGEMENT-SYSTEM; VENDOR SELECTION; CHAIN; PERFORMANCE; BUSINESS; DESIGN	We develop a dynamic partner assessment system (DPAS) in order to assess change in a supply partner's capability over a period of time. The system embeds a multi-criteria decision model and machine learning methods, and is designed to evaluate a partner's supply capability that can change over time and to maximize revenue with different procurement conditions across time periods. We apply the system to the procurement and management of the agricultural industry. The results are compared with real-world auction markets. (C) 2007 Elsevier Ltd. All rights reserved.	[Ha, Sung Ho] Kyungpook Natl Univ, Sch Business Adm, Taegu 702701, South Korea; [Hong, Gye-hang] Dongbu Financial Ctr, Dongbu CNI, Seoul 135523, South Korea	Ha, SH (reprint author), Kyungpook Natl Univ, Sch Business Adm, 1370 Sangyeokdong, Taegu 702701, South Korea.	kaistduck@dongbu.com; hsh@mail.knu.ac.kr					Cebi F., 2003, Logistics Information Management, V16, DOI 10.1108/09576050310503376; Chen J, 2001, IEEE T SYST MAN CY A, V31, P524; Choy KL, 2003, EXPERT SYST APPL, V25, P87, DOI 10.1016/S0957-4174(03)00009-5; Choy KL, 2002, EXPERT SYST APPL, V23, P281, DOI 10.1016/S0957-4174(02)00048-9; DAVIS RG, 2001, P INT C INF INF INF, P67; De Boer L., 2003, J PURCH SUPPLY MANAG, V9, P109, DOI 10.1016/S1478-4092(03)00018-9; De Boer L., 2001, EUROPEAN J PURCHASIN, V7, P75, DOI 10.1016/S0969-7012(00)00028-9; Dickson G.W., 1966, J PURCHASING, V2, P5; Ha SH, 1998, EXPERT SYST APPL, V15, P1; Han J., 2001, DATA MINING CONCEPTS; Holt G. D., 1998, International Journal of Project Management, V16, DOI 10.1016/S0263-7863(97)00035-5; Humphreys P, 2003, EXPERT SYST APPL, V25, P141, DOI 10.1016/S0957-4174(03)00042-3; KRALJIC P, 1983, HARVARD BUS REV, V61, P109; Kumar M, 2004, COMPUT IND ENG, V46, P69, DOI 10.1016/j.cie.2003.09.010; Lee EK, 2001, IEEE T ENG MANAGE, V48, P307; Lee JH, 2001, IEEE T ROBOTIC AUTOM, V17, P637; Liu J. F., 2000, SUPPLY CHAIN MANAG, V5, P143, DOI 10.1108/13598540010338893; Liu YZ, 2003, DECIS SUPPORT SYST, V36, P81, DOI [10.1016/S0167-9236(02)00133-1, 10.1016/S0167-9236(02)0013301]; MICHALEWICZ Z, 1999, GENETIC ALGORITHMS; Park JH, 2003, DECIS SUPPORT SYST, V35, P311, DOI 10.1016/S0167-9236(02)00111-2; ROBINSON PJ, 1967, INDUSTRIAL BUYING CR; Shervais S, 2003, IEEE T SYST MAN CY A, V33, P235, DOI 10.1109/TSMCA.2003.809214; Talluri S, 2002, INT J PROD RES, V40, P4257, DOI 10.1080/00207540210152894; Timmerman E., 1986, J PURCH SUPPLY MANAG, P27; Wang F., 2004, NONCRYSTALLINE MAT O, V1, P15; Weber CA, 1998, EUR J OPER RES, V108, P208, DOI 10.1016/S0377-2217(97)00131-8; Weber CA, 1996, EUR J OPER RES, V90, P142, DOI 10.1016/0377-2217(94)00336-X; Weber C.A., 2000, SUPPLY CHAIN MANAG, V5, P90, DOI 10.1108/13598540010320009	28	0	0	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0360-8352		COMPUT IND ENG	Comput. Ind. Eng.	MAY	2008	54	4					721	736		10.1016/j.cie.2007.10.009		16	Computer Science, Interdisciplinary Applications; Engineering, Industrial	Computer Science; Engineering	296IZ	WOS:000255538000002	
J	Yoo, PD; Zhou, BB; Zomaya, AY				Yoo, Paul D.; Zhou, Bing Bing; Zomaya, Albert Y.			Machine learning techniques for protein secondary structure prediction: An overview and evaluation	CURRENT BIOINFORMATICS			English	Review						amino acids encoding; evolutionary information; long-range dependencies; machine learning; protein secondary structure	SUPPORT VECTOR MACHINES; AMINO-ACID-SEQUENCE; NONLINEAR DIMENSIONALITY REDUCTION; PRINCIPAL COMPONENT ANALYSIS; ARTIFICIAL NEURAL-NETWORKS; LONG-RANGE INTERACTIONS; BETA-SHEETS; FOLD RECOGNITION; IDENTIFICATION; ALIGNMENTS	The prediction of protein secondary structures is not only of great importance for many biological applications but also regarded as an important stepping stone for solving the mystery of how amino acid sequences fold into tertiary structures. Recent research on secondary structure prediction is mainly based on widely known machine learning techniques, such as Artificial Neural Networks and Support Vector Machines. The most significant breakthroughs were the incorporation of new biological information into an efficient prediction model and the development of new models which can efficiently exploit suitable information from its primary sequence. Hence this paper reviews the theoretical and experimental literature of these models with a focus on informational issues involving evolutionary and long-range information of protein sequences. Furthermore, we investigate several key issues in protein data processing which involve dimensionality reduction and encoding schemes.	[Yoo, Paul D.; Zhou, Bing Bing] Univ Sydney, Adv Networks Res Grp, Sch Informat Technol J12, Sydney, NSW 2006, Australia; [Zomaya, Albert Y.] Univ Sydney, Sydney Bioinformat Ctr, Sydney, NSW 2006, Australia; [Zomaya, Albert Y.] Univ Sydney, Ctr Math Biol, Sydney, NSW 2006, Australia	Yoo, PD (reprint author), Univ Sydney, Adv Networks Res Grp, Sch Informat Technol J12, Sydney, NSW 2006, Australia.	dyoo4334@it.usyd.edu.au					AKKALADEVI S, 2004, ENG IN MED BIOL SOC, V2, P2987; ANFINSEN CB, 1954, J BIOL CHEM, V207, P201; ANFINSEN CB, 1973, SCIENCE, V181, P223, DOI 10.1126/science.181.4096.223; Baldi P., 1998, BIOINFORMATICS MACHI; Baldi P, 2002, IEEE INTELL SYST, V17, P28, DOI 10.1109/MIS.2002.999217; Baldi P, 2003, J MACHINE LEARNING R, V4, P575; Berry MJA, 2004, DATA MINING TECHNIQU; BIDARGADDI NP, 2005, CIBCB05, P1; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; Bollacker K.D., 1996, P IEEE INT C NEUR NE, P1528, DOI 10.1109/ICNN.1996.549127; Bradley P, 2003, PROTEINS, V53, P457, DOI 10.1002/prot.10552; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; CAREY J, 1998, ONLINE TXB BIOPHYSIC; Ceroni A, 2003, LECT NOTES ARTIF INT, V2829, P142; CERONI A, 2004, IEEE P NEURAL NETW, V3, P1899; Chen J., 2005, SOFT COMP J, V10, P315; CHEN LH, 1995, IEEE T NEURAL NETWOR, V6, P1255; Crooks GE, 2004, BIOINFORMATICS, V20, P1603, DOI 10.1093/bioinformatics/bth132; Cuff JA, 1999, PROTEINS, V34, P508, DOI 10.1002/(SICI)1097-0134(19990301)34:4<508::AID-PROT10>3.0.CO;2-4; DAVID R, 2000, THESIS MIT CAMBRIDGE; DICKERSON RE, 1976, J MOL BIOL, V100, P473, DOI 10.1016/S0022-2836(76)80041-1; Ding CHQ, 2001, BIOINFORMATICS, V17, P349, DOI 10.1093/bioinformatics/17.4.349; Doong S. H., 2004, Fourth International Conference on Hybrid Intelligent Systems, DOI 10.1109/ICHIS.2004.84; Fiser A, 1997, COMPUT APPL BIOSCI, V13, P297; Fodor I. K., 2002, UCRLID148494 LLNL; Frishman D, 1996, PROTEIN ENG, V9, P133, DOI 10.1093/protein/9.2.133; Green JR, 2003, ANN BIOMED ENG, V31, P462, DOI 10.1114/1.1561293; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; HENIKOFF S, 1992, P NATL ACAD SCI USA, V89, P10915, DOI 10.1073/pnas.89.22.10915; HOLLEY LH, 1989, P NATL ACAD SCI USA, V86, P152, DOI 10.1073/pnas.86.1.152; Hu HJ, 2004, IEEE T NANOBIOSCI, V3, P265, DOI 10.1109/TNB.2004.837906; Hua SJ, 2001, J MOL BIOL, V308, P397, DOI 10.1006/jmbi.2001.4580; Ikeda K, 2003, PROTEIN SCI, V12, P2542, DOI 10.1110/ps.03143803; Jacoboni I, 2000, PROTEINS, V41, P535, DOI 10.1002/1097-0134(20001201)41:4<535::AID-PROT100>3.0.CO;2-C; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; Kambhatla N., 1993, P IEEE INT C NEUR NE, V3, P1213; Kanehisa M, 1998, BIOINFORMATICS, V14, P309, DOI 10.1093/bioinformatics/14.4.309; KAWATANI T, 1998, P 14 INT C PATT REC, V2, P1301, DOI 10.1109/ICPR.1998.711940; Kihara D, 2005, PROTEIN SCI, V14, P1955, DOI 10.1110/ps.051479505; Kim H, 2003, PROTEIN ENG, V16, P553, DOI 10.1093/protein/gzg072; King RD, 1996, PROTEIN SCI, V5, P2298; Korenberg M, 2000, BIOL CYBERN, V82, P15, DOI 10.1007/PL00007958; Kortemme T, 1998, SCIENCE, V281, P253, DOI 10.1126/science.281.5374.253; KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209; Kuhlman B, 2003, SCIENCE, V302, P1364, DOI 10.1126/science.1089427; LEVIN JM, 1993, PROTEIN ENG, V6, P849, DOI 10.1093/protein/6.8.849; Lin K, 2002, J THEOR BIOL, V216, P361, DOI 10.1006/jtbi.2001.2512; LIU C, 1998, P 14 INT C PATT REC, V2, P1368; LOHMANN R, 1994, PROTEIN SCI, V3, P1597; LUNDEGAARD C, 2003, ISSU, V2666, P117; Malina W, 2001, IEEE T SYST MAN CY B, V31, P629, DOI 10.1109/3477.938265; McGuffin LJ, 2003, PROTEINS, V52, P166, DOI 10.1002/prot.10408; McGuffin LJ, 2000, BIOINFORMATICS, V16, P404, DOI 10.1093/bioinformatics/16.4.404; MELO JCB, 2003, IEEE P INT J C NEUR; Merkel JS, 2000, J BIOL CHEM, V275, P29200, DOI 10.1074/jbc.M004734200; METFESSEL BA, 1993, P 26 HAW INT C SYST, V1, P679; Minor DL, 1996, NATURE, V380, P730, DOI 10.1038/380730a0; Mitra S, 2005, LECT NOTES COMPUT SC, V3400, P134; Munoz V, 1996, FOLD DES, V1, P167, DOI 10.1016/S1359-0278(96)00029-6; MUSKAL SM, 1992, J MOL BIOL, V225, P713, DOI 10.1016/0022-2836(92)90396-2; Neumaier A, 1997, SIAM REV, V39, P407, DOI 10.1137/S0036144594278060; Pan XM, 1999, J PROTEIN CHEM, V18, P579, DOI 10.1023/A:1020655417839; Pollastri G, 2005, BIOINFORMATICS, V21, P1719, DOI 10.1093/bioinformatics/bti203; Prompramote S, 2005, BIOINFORMATICS TECHNOLOGIES, P117, DOI 10.1007/3-540-26888-X_5; Przybylski D, 2004, J MOL BIOL, V341, P255, DOI 10.1016/j.jmb.2004.05.041; RADZICKA A, 1988, BIOCHEMISTRY-US, V27, P1664, DOI 10.1021/bi00405a042; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; REGELSON ME, 1997, THESIS CALTECH PASAD; ROSE GD, 1985, SCIENCE, V229, P834, DOI 10.1126/science.4023714; ROST B, 1994, COMPUT APPL BIOSCI, V10, P53; Rost B, 1999, PROTEIN ENG, V12, P85, DOI 10.1093/protein/12.2.85; Rost B, 2000, METH MOL B, V143, P71; ROST B, 1993, J MOL BIOL, V232, P584, DOI 10.1006/jmbi.1993.1413; Rost B, 2003, HDB CHEMOINFORMATICS, P1789, DOI 10.1002/9783527618279.ch45b; ROST B, 1994, PROTEIN STRUCTURE BY DISTANCE ANALYSIS, P257; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Ruczinski I, 2002, PROTEINS, V48, P85, DOI 10.1002/prot.10123; RUGGIERO C, 1993, IEEE T BIO-MED ENG, V40, P1114, DOI 10.1109/10.245628; SALAMOV AA, 1995, J MOL BIOL, V247, P11, DOI 10.1006/jmbi.1994.0116; SCHNEIDER G, 1993, ANGEW CHEM INT EDIT, V32, P1141, DOI 10.1002/anie.199311411; Severcan M, 2001, J MOL STRUCT, V565, P383, DOI 10.1016/S0022-2860(01)00505-1; Shao JL, 2005, LECT NOTES ARTIF INT, V3584, P544; Skolnick J, 2004, PROTEINS, V56, P502, DOI 10.1002/prot.20106; Skolnick J, 2001, PROTEINS, V42, P319, DOI 10.1002/1097-0134(20010215)42:3<319::AID-PROT30>3.3.CO;2-1; Smith CK, 1997, ACCOUNTS CHEM RES, V30, P153, DOI 10.1021/ar9601048; SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5; Steward RE, 2002, PROTEINS, V48, P178, DOI 10.1002/prot.10152; TAN AC, 2003, P 1 AS PAC BIOINF C, V33, P219; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tibshirani R., 1992, Statistics and Computing, V2, DOI 10.1007/BF01889678; Vapnik V. N, 1995, NATURE STAT LEARNING; Vapnik VN, 1998, STAT LEARNING THEORY; Wang J. T. L., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347157; WANG L, 2004, P 3 INT C MACH LEARN, V5, P2730; WHITE G, 1998, EJB; Woo SK, 2005, LECT NOTES COMPUT SC, V3645, P1; Xiuju Fu, 2003, IEEE Transactions on Systems, Man and Cybernetics, Part B (Cybernetics), V33, DOI 10.1109/TSMCB.2003.810911; Yang ZR, 2004, BIOINFORMATICS, V20, P735, DOI 10.1093/bioinformatics/btg477; Zaremba SM, 1999, J MOL BIOL, V291, P463, DOI 10.1006/jmbi.1999.2961; Zavaljevski N, 2002, BIOINFORMATICS, V18, P689, DOI 10.1093/bioinformatics/18.5.689; ZHANG B, 2005, P IEEE C NEUR NETW I, V1, P532; Zhang GQ, 1999, EUR J OPER RES, V116, P16, DOI 10.1016/S0377-2217(98)00051-4; ZHANG X, 1994, IEEE EXPERT, V8, P66; ZHONG W, 2004, EMBC, V2, P2968; Zhou XH, 2000, PROTEINS, V41, P248, DOI 10.1002/1097-0134(20001101)41:2<248::AID-PROT90>3.0.CO;2-J; ZHU H, 2002, ARTIFICIAL LIFE ROBO, V8, P168; ZVELEBIL MJ, 1987, J MOL BIOL, V195, P957, DOI 10.1016/0022-2836(87)90501-8	109	1	1	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y26, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	1574-8936		CURR BIOINFORM	Curr. Bioinform.	MAY	2008	3	2					74	86		10.2174/157489308784340676		13	Biochemical Research Methods; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Mathematical & Computational Biology	298IT	WOS:000255682100002	
J	Rogers, WT; Moser, AR; Holyst, HA; Bantly, A; Mohler, ER; Scangas, G; Moore, JS				Rogers, Wade T.; Moser, Allan R.; Holyst, Herbert A.; Bantly, Andrew; Mohler, Emile R., III; Scangas, George; Moore, Jonni S.			Cytometric Fingerprinting: Quantitative characterization of multivariate distributions	CYTOMETRY PART A			English	Article						flow cytometry; cytomics; bioinformatics; computational biology; machine learning; empirical modeling	T-CELL RESPONSES; ENDOTHELIAL PROGENITOR CELLS; DISTRIBUTION DIFFERENCES/; STATISTICAL VARIABLES; PRINCIPAL COMPONENTS; CLUSTER-ANALYSIS; FLOW; IMMUNIZATION; COMPLEX; QUALITY	Recent technological advances in flow cytometry instrumentation provide the basis for high-dimensionality and high-throughput biological experimentation in a heterogeneous cellular context. Concomitant advances in scalable computational algorithms are necessary to better utilize the information that is contained in these high-complexity experiments. The development of such tools has the potential to expand the utility of flow cytometric analysis from a predominantly hypothesis-driven mode to one of discovery, or hypothesis-generating research. A new method of analysis of flow cytometric data called Cytometric Fingerprinting (CF) has been developed. CF captures the set of multivariate probability distribution functions corresponding to list-mode data and then "flattens" them into a computationally efficient fingerprint representation that facilitates quantitative comparisons of samples. An experimental and synthetic data were generated to act as reference sets for evaluating CF. Without the introduction of prior knowledge, CF was able to "discover" the location and concentration of spiked cells in ungated analyses over a concentration range covering four orders of magnitude, to a lower limit on the order of 10 spiked events in a background of 100,000 events. We describe a new method for quantitative analysis of list-mode cytometric data. CF includes a novel algorithm for space subdivision that improves estimation of the probability density function by dividing space into nonrectangular polytopes. Additionally it renders a multidimensional distribution in the form of a one-dimensional multi resolution hierarchical fingerprint that creates a computationally efficient representation of high dimensionality distribution functions. CF supports both the generation and testing of hypotheses, eliminates sources of operator bias, and provides an increased level of automation of data analysis. (C)) 2008 international Society for Advancement of Cytometry.	[Rogers, Wade T.; Moser, Allan R.; Holyst, Herbert A.] Cira Discovery Sci Inc, Philadelphia, PA USA; [Rogers, Wade T.; Moser, Allan R.] Hutzen Womens Hosp, Perinatol Res Branch, Intramural Div, NICHD,NIH,DHHS, Detroit, MI USA; [Rogers, Wade T.; Holyst, Herbert A.; Bantly, Andrew; Scangas, George; Moore, Jonni S.] Univ Penn, Sch Med, Dept Pathol & Lab Med, Philadelphia, PA 19104 USA; [Rogers, Wade T.; Holyst, Herbert A.; Bantly, Andrew; Scangas, George; Moore, Jonni S.] Univ Penn, Sch Med, Flow Cytometry & Cell Sorting Resource Lab, Philadelphia, PA 19104 USA; [Mohler, Emile R., III] Univ Penn, Sch Med, Vasc Med Sect,Dept Med, Div Cardiovasc, Philadelphia, PA 19104 USA	Rogers, WT (reprint author), Cira Discovery Sci Inc, Philadelphia, PA USA.	rogersw@mail.med.upenn.edu					ARNOLD GM, 1993, APPL STAT-J ROY ST C, V42, P381, DOI 10.2307/2986240; De Rosa SC, 2003, NAT MED, V9, P112, DOI 10.1038/nm0103-112; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Hotelling H, 1933, J EDUC PSYCHOL, V24, P498, DOI 10.1037/h0070888; Inokuma M, 2007, J IMMUNOL, V179, P2627; Jackson J. E., 1991, USERS GUIDE PRINCIPA; Jolliffe I.T., 2002, PRINCIPAL COMPONENT; LIU RC, 1993, ANN STAT, V21, P1, DOI 10.1214/aos/1176349012; Lizard G, 2007, CYTOM PART A, V71A, P646, DOI 10.1002/cyto.a.20444; Lugli E, 2007, CYTOM PART A, V71A, P334, DOI 10.1002/cyto.a.20387; MURPHY RF, 1985, CYTOMETRY, V6, P302, DOI 10.1002/cyto.990060405; Neeson P, 2004, CYTOM PART A, V60A, P8, DOI 10.1002/cyto.a.20023; OCONNELL MJ, 1974, COMPUT PHYS COMMUN, V8, P49, DOI 10.1016/0010-4655(74)90084-8; Pearson K, 1901, PHILOS MAG, V2, P559; Precopio ML, 2007, J EXP MED, V204, P1405, DOI 10.1084/jem.20062363; ROBINSON JP, 1991, CYTOMETRY, V12, P82, DOI 10.1002/cyto.990120112; ROBINSON JP, 1992, CYTOMETRY, V13, P75, DOI 10.1002/cyto.990130112; Roederer M, 2001, CYTOMETRY, V45, P37, DOI 10.1002/1097-0320(20010901)45:1<37::AID-CYTO1142>3.0.CO;2-E; Roederer M, 2001, CYTOMETRY, V45, P47, DOI 10.1002/1097-0320(20010901)45:1<47::AID-CYTO1143>3.0.CO;2-A; Roederer M, 2001, CYTOMETRY, V45, P56, DOI 10.1002/1097-0320(20010901)45:1<56::AID-CYTO1144>3.0.CO;2-9; Rogers W, 2007, CYTOM PART B-CLIN CY, V72B, P490; Shaffer RG, 2006, VASC MED, V11, P219, DOI 10.1177/1358863x06072213; Sturges HA, 1926, J AM STAT ASSOC, V21, P65; Wille-Reece U, 2006, J EXP MED, V203, P1249, DOI 10.1084/jem.20052433; Wu KH, 2007, TRANSPL P, V39, P1620, DOI 10.1016/j.transproceed.2006.12.041; Zhao XH, 2007, TRANSPL INT, V20, P712, DOI 10.1111/j.1432-2277.2007.00497.x	26	10	10	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	1552-4922		CYTOM PART A	Cytom. Part A	MAY	2008	73A	5					430	441		10.1002/cyto.a.20545		12	Biochemical Research Methods; Cell Biology	Biochemistry & Molecular Biology; Cell Biology	293TW	WOS:000255359100011	
J	Wong, ML; Guo, YY				Wong, Man Leung; Guo, Yuan Yuan			Learning Bayesian networks from incomplete databases using a novel evolutionary algorithm	DECISION SUPPORT SYSTEMS			English	Article						data mining; machine learning; Bayesian networks; evolutionary algorithms	EM ALGORITHM; GENETIC ALGORITHMS; DECISION-SUPPORT; MICROARRAY DATA; MISSING DATA; INDUCTION	This paper proposes a novel method for learning Bayesian networks from incomplete databases in the presence of missing values, which combines an evolutionary algorithm with the traditional Expectation Maximization (EM) algorithm. A data completing procedure is presented for learning and evaluating the candidate networks. Moreover, a strategy is introduced to obtain better initial networks to facilitate the method. The new method can also overcome the problem of getting stuck in sub-optimal solutions which occurs in most existing learning algorithms. The experimental results on the databases generated from several benchmark networks illustrate that the new method has better performance than some state-of-the-art algorithms. We also apply the method to a data mining problem and compare the performance of the discovered Bayesian networks with the models generated by other learning algorithms. The results demonstrate that our method outperforms other algorithms. (c) 2008 Elsevier B.V All rights reserved.	[Wong, Man Leung; Guo, Yuan Yuan] Lingnan Univ, Dept Computing & Decis Sci, Tuen Mun, Hong Kong, Peoples R China	Wong, ML (reprint author), Lingnan Univ, Dept Computing & Decis Sci, Tuen Mun, Hong Kong, Peoples R China.	mlwong@ln.edu.hk; yy2guo@gmail.com					Ahn JH, 1997, DECIS SUPPORT SYST, V21, P17, DOI 10.1016/S0167-9236(97)00009-2; Andreassen S, 1987, P 10 INT JOINT C ART, P366; Beaumont GP, 1996, STAT TESTS INTRO MIN; Beinlich IA, 1989, P 2 EUR C ART INT ME, P247; Bhattacharyya S., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Blanco R, 2003, INT J INTELL SYST, V18, P205, DOI 10.1002/int.10084; Cai ZP, 2006, SER ADV BIOINFORM, V3, P159, DOI 10.1142/9781860947292_0019; Cheng J, 2002, ARTIF INTELL, V137, P43, DOI 10.1016/S0004-3702(02)00191-1; Chickering DM, 2002, J MACH LEARN RES, V2, P445, DOI 10.1162/153244302760200696; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; Cotta C., 2002, Parallel Problem Solving from Nature - PPSN VII. 7th International Conference. Proceedings (Lecture Notes in Computer Science Vol.2439); COTTA C, 2004, P 2 EUR WORKSH PROB, P65; de Campos LM, 2002, INT J APPROX REASON, V31, P291, DOI 10.1016/S0888-613X(02)00091-9; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DJANSAMPSON PO, 2004, P IEEE INT C SYST MA, P3619; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Friedman N., 1998, P 14 C UNC ART INT, P129; Friedman N., 1997, P 14 INT C MACH LEAR, P125; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; HECKERMAN D, 1995, COMMUN ACM, V38, P27, DOI 10.1145/203330.203336; Heckerman D., 1998, P 14 C UNC ART INT, P230; Heckerman D., 1995, MSRTR9506 MICR RES; Hruschka E. R.  Jr., 2002, Intelligent Data Analysis, V6; Huang C, 1996, INT J APPROX REASON, V15, P225, DOI 10.1016/S0888-613X(96)00069-2; Huang Z, 2007, DECIS SUPPORT SYST, V43, P1207, DOI 10.1016/j.dss.2006.02.002; Jensen F., 1996, INTRO BAYESIAN NETWO; KIM H, 2004, P IEEE COMP SYST BIO, P572; Kim SH, 2005, DECIS SUPPORT SYST, V39, P253, DOI 10.1016/j.dss.2003.10.010; Lakshminarayan K, 1996, P 2 INT C KNOWL DISC, P140; Lam W., 1994, COMPUT INTELL, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x; Larranaga P, 1996, IEEE T SYST MAN CY A, V26, P487, DOI 10.1109/3468.508827; Larranaga P, 1996, IEEE T PATTERN ANAL, V18, P912, DOI 10.1109/34.537345; Lauria EJM, 2006, DECIS SUPPORT SYST, V42, P1573, DOI 10.1016/j.dss.2006.01.003; LAURITZEN SL, 1995, COMPUT STAT DATA AN, V19, P191, DOI 10.1016/0167-9473(93)E0056-A; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; Little R. J. A., 2002, STAT ANAL MISSING DA; Liu L, 2003, P NATL ACAD SCI USA, V100, P13167, DOI 10.1073/pnas.1733249100; MYERS JW, 1999, P GEN EV COMP C JOIN, P458; Neal R. M., 1996, BAYESIAN LEARNING NE; Pearl J., 1988, PROBABILISTIC REASON; Pena JM, 2000, PATTERN RECOGN LETT, V21, P779, DOI 10.1016/S0167-8655(00)00038-6; Pena JM, 2002, MACH LEARN, V47, P63, DOI 10.1023/A:1013683712412; RAMONI M, 1997, KMITR44 OP U KNOWL M; Ramoni M, 2001, MACH LEARN, V45, P147, DOI 10.1023/A:1010968702992; RAMONI M, 1997, KMITR41 OP U KNOWL M; Rubin D. B., 1987, MULTIPLE IMPUTATION; Rud O., 2001, DATA MINING COOKBOOK; Schafer JL, 2002, PSYCHOL METHODS, V7, P147, DOI 10.1037//1082-989X.7.2.147; Spirtes P, 2000, CAUSATION PREDICTION; Wong ML, 1999, IEEE T PATTERN ANAL, V21, P174; Wong ML, 2004, IEEE T EVOLUT COMPUT, V8, P378, DOI 10.1109/TEVC.2004.830334; Wong ML, 2004, DECIS SUPPORT SYST, V38, P451, DOI 10.1016/S0167-9236(03)00115-5; Zahavi J., 1997, J DIRECT MARKETING, V11, P63, DOI 10.1002/(SICI)1522-7138(199723)11:4<63::AID-DIR9>3.0.CO;2-U; Zio M.D., 2004, J ROYAL STAT SOC A, V167, P309	54	9	10	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9236		DECIS SUPPORT SYST	Decis. Support Syst.	MAY	2008	45	2					368	383		10.1016/j.dss.2008.01.002		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science	Computer Science; Operations Research & Management Science	313MV	WOS:000256745600015	
J	Illoldi-Rangel, P; Fuller, T; Linaje, M; Pappas, C; Sanchez-Cordero, V; Sarkar, S				Illoldi-Rangel, Patricia; Fuller, Trevon; Linaje, Miguel; Pappas, Christopher; Sanchez-Cordero, Victor; Sarkar, Sahotra			Solving the maximum representation problem to prioritize areas for the conservation of terrestrial mammals at risk in Oaxaca	DIVERSITY AND DISTRIBUTIONS			English	Review						conservation area network; endemic species; mammal conservation; maximum representation problem; Oaxaca	RESERVE SITE SELECTION; SPECIES DISTRIBUTION MODELS; PROPOSED NATURE-RESERVES; BIODIVERSITY CONSERVATION; BIOLOGICAL DIVERSITY; PARSIMONY ANALYSIS; MEXICAN MAMMALS; DISTRIBUTIONS; INFORMATION; ENDEMICITY	Oaxaca, located in south-west Mexico within the Mesoamerican biodiversity hotspot, holds exceptionally high biodiversity for several taxa, including mammals. It has four decreed natural protected areas (NPAs) covering 5% of its total area, but only three of these, covering only 0.2% of the area, are strictly protected as National Parks. The current study develops ecological niche models for 183 terrestrial mammals for use as biodiversity surrogates in a systematic conservation planning exercise. Forty-five of these species were selected on the basis of their being either endangered or threatened or otherwise listed under the Mexican Red List or because they were endemic to either Oaxaca or to Mexico. The niche models were constructed with a machine-learning algorithm (GARP, Genetic Algorithm for Rule-Set Prediction) and refined by restricting each model to sites with suitable vegetation and habitat patches contiguous with known occurrences of the species. If the entire predicted geographical distribution of each of the 45 species listed above is put under protection, the entire state of Oaxaca gets included. Therefore, we imposed different constraints on the maximum area that can be put under protection (5-30% of the area of Oaxaca) and selected nominal conservation area networks based on different percentage representation targets for the species' modelled distributions based on their conservation status (10-100%). The area selection utilized a rarity- and complementarity-based algorithm (in the ResNet software package). The goal was to have as many as possible of the 45 species at risk meet their specified representation targets in the budgeted area. The methods developed here combine ecological niche modelling and area prioritization algorithms for integrated conservation planning in a protocol that is suitable for other highly biodiverse regions.	[Illoldi-Rangel, Patricia; Linaje, Miguel; Sanchez-Cordero, Victor] Univ Nacl Autonoma Mexico, Inst Biol, Dept Zool, Mexico City 04510, DF, Mexico; [Illoldi-Rangel, Patricia; Fuller, Trevon; Pappas, Christopher; Sarkar, Sahotra] Univ Texas Austin, Sect Integrat Biol, Biodivers & Biocultural Conservat Lab, Austin, TX 78712 USA	Illoldi-Rangel, P (reprint author), Univ Nacl Autonoma Mexico, Inst Biol, Dept Zool, Apartado Postal 70-153, Mexico City 04510, DF, Mexico.	pilloldi@ibiologia.unam.mx					AGUILAR C., 2001, INTRO BIOGEOGRAFIA L, P31; Anderson RP, 2003, ECOL MODEL, V162, P211, DOI 10.1016/S0304-3800(02)00349-6; Arita HT, 1997, CONSERV BIOL, V11, P92, DOI 10.1046/j.1523-1739.1997.95274.x; Arthur JL, 1997, ENVIRON ECOL STAT, V4, P153, DOI 10.1023/A:1018570311399; Arthur JL, 2004, ECOL APPL, V14, P1936, DOI 10.1890/02-5360; ASBJORNSEN H, 2002, J SUSTAINABLE FOREST, V15, P127, DOI 10.1300/J091v15n01_09; Asbjornsen H., 2002, Journal of Sustainable Forestry, V15, P1, DOI 10.1300/J091v15n01_01; BARRANCE A, 2006, LINKING PEOPLE NATUR, P53; BARRANTESMORENO G, 2006, ECOLOGY CONSERVATION, P435; BOJORQUEZTAPIA LA, 1995, ECOL APPL, V5, P215, DOI 10.2307/1942065; Brandon K, 2005, WORLD DEV, V33, P1403, DOI 10.1016/j.worlddev.2004.10.005; Bray DB, 1996, COLUMB U SEM SER, P215; Briones-Salas Miguel, 2004, P423; Burgman MA, 2001, CONSERV BIOL, V15, P603, DOI 10.1046/j.1523-1739.2001.015003603.x; Camm JD, 1996, BIOL CONSERV, V78, P353, DOI 10.1016/0006-3207(95)00132-8; Camm JD, 2002, OPER RES, V50, P946, DOI 10.1287/opre.50.6.946.351; Cantu C, 2003, NAT AREA J, V23, P220; Cantu C, 2004, BIOL CONSERV, V115, P411, DOI 10.1016/S0006-3207(03)00158-7; Cantu S, 2004, NAT AREA J, V24, P150; CASTILLEJA G, 1995, CONSERVATION ATLAS T, P195; Ceballos G, 1998, ECOL APPL, V8, P8, DOI 10.2307/2641307; Ceballos Gerardo, 2002, Occasional Papers Museum of Texas Tech University, V218, P1; Chapela F., 2005, COMMUNITY FORESTS ME, P91; Church R, 2000, FOREST SCI, V46, P157; Csuti B, 1997, BIOL CONSERV, V80, P83, DOI 10.1016/S0006-3207(96)00068-7; Davila P, 2002, BIODIVERS CONSERV, V11, P421, DOI 10.1023/A:1014888822920; Davis S. D., 1997, CTR PLANT DIVERSITY, V3; Dennis RLH, 2000, J INSECT CONSERV, V4, P73, DOI 10.1023/A:1009690919835; Elith J, 2006, ECOGRAPHY, V29, P129, DOI 10.1111/j.2006.0906-7590.04596.x; Escalante T, 2003, SOUTHWEST NAT, V48, P563, DOI 10.1894/0038-4909(2003)048<0563:UPAOET>2.0.CO;2; ESCALANTE T, IN PRESS BIOGEOGRAFI; Escalante T, 2004, BIOL J LINN SOC, V83, P327, DOI 10.1111/j.1095-8312.2004.00386.x; FAITH DP, 2004, STANFORD ENCY PHILOS; Flores-Villela O., 1994, BIODIVERSIDAD CONSER; Fox J., 1996, DECENTRALIZATION RUR; Fuller T, 2007, BIOL CONSERV, V134, P593, DOI 10.1016/j.biocon.2006.08.028; Garcia A, 2006, BIOL CONSERV, V130, P25, DOI 10.1016/j.biocon.2005.11.030; GARCIAMENDOZA A, 2004, DIVERSIDAD BIOL ESTA; Gomez-Mendoza L, 2006, APPL GEOGR, V26, P276, DOI 10.1016/j.apgeog.2006.09.003; Goodwin G. G., 1969, Bulletin of the American Museum of Natural History, V141, P1; Gordon JE, 2006, SYST ASSOC SPEC VOL, P343; Gordon JE, 2006, ENVIRON SCI POLICY, V9, P547, DOI 10.1016/j.envsci.2006.05.001; Gordon JE, 2004, BIOL CONSERV, V117, P429, DOI 10.1016/j.biocon.2003.08.011; Griffiths GH, 1999, GLOBAL ECOL BIOGEOGR, V8, P329, DOI 10.1046/j.1365-2699.1999.00143.x; HALFFTER GONZALO, 1965, REV SOC MEX HIST NATUR, V26, P1; Hall E. R., 1981, MAMMALS N AM, V1; Hall E. R., 1981, MAMMALS N AM, V2; HELMER EH, 2000, QUANTIFYING SUSTAINA, P503, DOI 10.1016/B978-012318860-1/50024-1; Hummel M., 1995, PROTECTING CANADAS E; Illoldi-Rangel P, 2004, J MAMMAL, V85, P658, DOI 10.1644/BER-024; Juutinen A, 2004, FOREST SCI, V50, P527; KAPPELLE M, 2006, ECOLOGY CONSERVATION, P449; KAPPELLE M, 2006, ECOLOGY CONSERVATION, P393; LOPEZARZOLA R, 2005, COMMUNITY FORESTS ME, P111; Margules CR, 2007, ECOL BIODIVERS CONS, P1; MARGULES CR, 1988, BIOL CONSERV, V43, P63, DOI 10.1016/0006-3207(88)90078-X; Margules CR, 2000, NATURE, V405, P243, DOI 10.1038/35012251; Mas J. F., 2004, International Journal of Applied Earth Observation and Geoinformation, V5, P249, DOI 10.1016/j.jag.2004.06.002; Mendez-Larios I, 2005, INTERCIENCIA, V30, P267; Merino-Perez L., 2005, COMMUNITY FORESTS ME, P49; MITCHELL RE, 2005, ENV ISSUES LATIN AM; Mittermeier R., 2002, WILDERNESS EARTHS LA; Moilanen A, 2005, AM NAT, V165, P695, DOI 10.1086/430011; Fa John E., 1993, P319; Myers N, 2000, NATURE, V403, P853, DOI 10.1038/35002501; O'Hanley JR, 2007, BIOL CONSERV, V135, P170, DOI 10.1016/j.biocon.2006.10.004; Olson DM, 2001, BIOSCIENCE, V51, P933, DOI 10.1641/0006-3568(2001)051[0933:TEOTWA]2.0.CO;2; Onal H., 2003, BIOL CONSERV, V115, P55; Ortega J, 1998, J MAMMAL, V79, P772, DOI 10.2307/1383088; Ortega-Huerta MA, 2004, DIVERS DISTRIB, V10, P39, DOI 10.1111/j.1472-4642.2004.00051.x; Perez-Arteaga A, 2005, ANIM CONSERV, V8, P41, DOI 10.1017/S1367943004001817; Peterson A. Townsend, 2003, Huitzil, V4, P3; Peterson A.T., 1993, Biodiversity Letters, V1, P33, DOI 10.2307/2999648; Peterson AT, 2003, Q REV BIOL, V78, P419, DOI 10.1086/378926; Peterson AT, 2003, ECOL LETT, V6, P774, DOI 10.1046/j.1461-0248.2003.00502.x; Peterson AT, 2003, BIRD CONSERV INT, V13, P227, DOI 10.1017/S0959270903003186; Peterson AT, 2006, ECOL MODEL, V195, P229, DOI 10.1016/j.ecolmodel.2005.11.020; Peterson AT, 2000, BIOL CONSERV, V93, P85, DOI 10.1016/S0006-3207(99)00074-9; Peterson AT, 2002, NATURE, V416, P626, DOI 10.1038/416626a; Polasky S, 2001, BIODIVERS CONSERV, V10, P1051, DOI 10.1023/A:1016618206124; Pressey RL, 2003, BIOL CONSERV, V112, P99, DOI 10.1016/S0006-3207(02)00424-X; PRESSEY RL, 1994, CONSERV BIOL, V8, P662, DOI 10.1046/j.1523-1739.1994.08030662.x; ReVelle CS, 2002, ENVIRON MODEL ASSESS, V7, P71, DOI 10.1023/A:1015641514293; Rothley KD, 1999, ECOL APPL, V9, P741, DOI 10.2307/2641326; Rzedowski J, 1986, VEGETACION MEXICO; SANCHEZCORDERO V, 1993, ASS SYSTEMATIC COLLE, V21, P54; Sanchez-Cordero V, 2005, BIOL CONSERV, V126, P465, DOI 10.1016/j.biocon.2005.06.022; Sanchez-Cordero V, 2004, Frontiers of Biogeography: New Directions in the Geography of Nature, P311; Sanchez-Cordero V, 2001, GLOBAL ECOL BIOGEOGR, V10, P63, DOI 10.1046/j.1466-822x.2001.00235.x; Sanchez-Cordero Victor, 2005, Biodiversity Informatics, V2, P11; Sarakinos H, 2001, BIODIVERS CONSERV, V10, P1419, DOI 10.1023/A:1011871723686; Sarkar S, 2005, CONSERV BIOL, V19, P815, DOI 10.1111/j.1523-1739.2005.00236.x; Sarkar S, 2006, ANNU REV ENV RESOUR, V31, P123, DOI 10.1146/annurev.energy.31.042606.085844; Sarkar S., 2004, STANFORD ENCY PHILOS; Sarkar S, 2002, J BIOSCIENCES, V27, P339, DOI 10.1007/BF02704964; Soberon J, 2004, PHILOS T ROY SOC B, V359, P689, DOI 10.1098/rstb.2003.1439; Stockwell D, 1999, INT J GEOGR INF SCI, V13, P143, DOI 10.1080/136588199241391; Stockwell DRB, 2002, ECOL MODEL, V148, P1, DOI 10.1016/S0304-3800(01)00388-X; Szekely Alberto, 2005, P87; Tole L, 2006, ECOL MODEL, V194, P344, DOI 10.1016/j.ecolmodel.2005.10.027; Velazquez A, 2003, GLOBAL ENVIRON CHANG, V13, P175, DOI 10.1016/S0959-3780(03)00035-9; Vergara CH, 2002, J KANSAS ENTOMOL SOC, V75, P16; VILLA B., 2003, MAMIFEROS MEXICO; WEGE DC, 1995, KEA AREAS THREATENED; WESTERN D, 1994, NATURAL CONNECTIONS, P1; WHITE A., 2002, WHO OWNS WORLDS FORE; Whiteford S, 1996, COLUMB U SEM SER, P223; Williams P, 1996, CONSERV BIOL, V10, P155, DOI 10.1046/j.1523-1739.1996.10010155.x; World Commission on Environment and Development (World Council on Environment and Development), 1997, OUR COMM FUT; [Anonymous], 2002, NOM059ECOL2001; *IUCN, 1983, 4 WORLD C NAT PARKS; *UNAM, 1993, LIST FLOR MEX; *US GEOL SURV, 1998, GTOPO30 GLOB 30 ARC	113	8	10	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1366-9516		DIVERS DISTRIB	Divers. Distrib.	MAY	2008	14	3					493	508		10.1111/j.1472-4642.2007.00458.x		16	Biodiversity Conservation; Ecology	Biodiversity & Conservation; Environmental Sciences & Ecology	287WI	WOS:000254946900006	
J	Stjernschantz, E; Vermeulen, NPE; Oostenbrink, C				Stjernschantz, Eva; Vermeulen, Nico P. E.; Oostenbrink, Chris			Computational prediction of drug binding and rationalisation of selectivity towards cytochromes P450	EXPERT OPINION ON DRUG METABOLISM & TOXICOLOGY			English	Review						binding affinity; binding free energy; CYP; docking; in silico; machine learning; metabolite formation; molecular dynamics; pharmacophore; polymorphism; QSAR; scoring; selectivity	IN-SILICO PREDICTION; COMPETITIVE CYP2C9 INHIBITORS; EMPIRICAL SCORING FUNCTIONS; MOLECULAR-DYNAMICS SIMULATIONS; MACHINE-LEARNING TECHNIQUES; SITE-DIRECTED MUTAGENESIS; PROTEIN-LIGAND COMPLEXES; SUBSTRATE-BINDING; 3A4 INHIBITION; FREE-ENERGIES	Background: Early in-vitro consideration of metabolism and inhibition of cytochrome P450 has proven its merits over the last 15 years. Simultaneously, many computational drug-design methods have been developed, and are being applied to study the interactions between drug candidates and cytochrome P450 enzymes (P450s). Objective: This review discusses the recent advances of these methods and the implications that are specific for P450s. Methods: Mainly focusing on the prediction of binding affinity and ligand selectivity, we outline the applicability of the different methods to answer specific questions. Special emphasis is put on the different levels of theory that are being used in recent computational descriptions of ligand-P450 interactions. Conclusion: P450s offer an additional challenge for computational methods, considering the ambiguities of the catalytic cycle and the significant flexibility of the active site. Different computational methods display different limitations, which is crucial to take into account when choosing the method appropriate to each application.	[Stjernschantz, Eva; Vermeulen, Nico P. E.; Oostenbrink, Chris] Vrije Univ Amsterdam, Leiden Amsterdam Ctr Drug Res, Div Mol Toxicol, NL-1081 HV Amsterdam, Netherlands	Oostenbrink, C (reprint author), Vrije Univ Amsterdam, Leiden Amsterdam Ctr Drug Res, Div Mol Toxicol, Boelelaan 1083, NL-1081 HV Amsterdam, Netherlands.	c.oostenbrink@few.vu.nl					Afzelius L, 2001, MOL PHARMACOL, V59, P909; Afzelius L, 2004, J MED CHEM, V47, P907, DOI 10.1021/jm030972s; Afzelius L, 2007, DRUG METAB REV, V39, P61, DOI 10.1080/03602530600969374; Afzelius L, 2002, J COMPUT AID MOL DES, V16, P443, DOI 10.1023/A:1021281008423; Ahlstrom MM, 2007, J MED CHEM, V50, P4444, DOI 10.1021/jm0705096; Almlof M, 2004, J COMPUT CHEM, V25, P1242, DOI 10.1002/jcc.20047; AQVIST J, 1994, PROTEIN ENG, V7, P385, DOI 10.1093/protein/7.3.385; Arimoto R, 2006, CURR TOP MED CHEM, V6, P1609, DOI 10.2174/156802606778108951; Arimoto R, 2005, J BIOMOL SCREEN, V10, P197, DOI 10.1177/1087057104274091; Audergon C, 1999, J AM CHEM SOC, V121, P41, DOI 10.1021/ja983000w; Baranczewski P, 2006, PHARMACOL REP, V58, P453; Bazeley PS, 2006, J CHEM INF MODEL, V46, P2698, DOI 10.1021/ci600267k; Bertz RJ, 1997, CLIN PHARMACOKINET, V32, P210; BEVERIDGE DL, 1989, ANNU REV BIOPHYS BIO, V18, P431, DOI 10.1146/annurev.biophys.18.1.431; Burton J, 2006, J MED CHEM, V49, P6231, DOI 10.1021/jm060267u; Chohan KK, 2005, J MED CHEM, V48, P5154, DOI 10.1021/jm048959a; Chohan KK, 2006, CURR TOP MED CHEM, V6, P1569, DOI 10.2174/156802606778108960; CRAMER RD, 1988, J AM CHEM SOC, V110, P5959, DOI 10.1021/ja00226a005; Crivori P, 2005, BASIC CLIN PHARMACOL, V96, P251, DOI 10.1111/j.1742-7843.2005.pto960320.x; Cruciani G, 2005, J MED CHEM, V48, P6970, DOI 10.1021/jm050529c; de Graaf C, 2005, J MED CHEM, V48, P2725, DOI 10.1021/jm040180d; de Graaf C, 2007, CURR DRUG METAB, V8, P59, DOI 10.2174/138920007779315062; de Graaf C, 2007, EUR BIOPHYS J BIOPHY, V36, P589, DOI 10.1007/s00249-006-0126-y; de Graaf C, 2005, J MED CHEM, V48, P2308, DOI 10.1021/jm.049650u; de Graaf C, 2006, J MED CHEM, V49, P2417, DOI 10.1021/jm0508538; de Groot MJ, 2004, CURR TOP MED CHEM, V4, P1803, DOI 10.2174/1568026043387061; Denisov IG, 2005, CHEM REV, V105, P2253, DOI 10.1021/cr0307143; De Rienzo F, 2000, J COMPUT AID MOL DES, V14, P93, DOI 10.1023/A:1008187802746; Ekins S, 2000, DRUG METAB DISPOS, V28, P994; Ekins S, 1999, J PHARMACOL EXP THER, V290, P429; Ekroos M, 2006, P NATL ACAD SCI USA, V103, P13682, DOI 10.1073/pnas.0603236103; Eldridge MD, 1997, J COMPUT AID MOL DES, V11, P425, DOI 10.1023/A:1007996124545; Feenstra KA, 2007, PROTEIN SCI, V16, P420, DOI 10.1110/ps.062224407; Ferrara P, 2004, J MED CHEM, V47, P3032, DOI 10.1021/jm030489h; FERRARI AM, 2004, J MED CHEM, V47, P507; Flanagan JU, 2004, BIOCHEM J, V380, P353, DOI 10.1042/BJ20040062; Fox T, 2006, CURR TOP MED CHEM, V6, P1579, DOI 10.2174/156802606778108915; Friesner RA, 2006, J MED CHEM, V49, P6177, DOI 10.1021/jm051256o; Friesner RA, 2004, J MED CHEM, V47, P1739, DOI 10.1021/jm0306430; Fukunishi Y, 2006, J CHEM INF MODEL, V46, P2610, DOI 10.1021/ci600334u; Terfloth L, 2007, J CHEM INF MODEL, V47, P1688, DOI 10.1021/ci700010t; Gleeson MP, 2007, J COMPUT AID MOL DES, V21, P559, DOI 10.1007/s10822-007-9139-6; Groenhof AR, 2007, J AM CHEM SOC, V129, P6204, DOI 10.1021/ja0685654; Guengerich FP, 2005, CYTOCHROME P450 STRU, P377, DOI 10.1007/0-387-27447-2_10; Guengerich FP, 2008, CHEM RES TOXICOL, V21, P70, DOI 10.1021/tx700079z; Guengerich FP, 2006, P NATL ACAD SCI USA, V103, P13565, DOI 10.1073/pnas.0606333103; Guengerich FP, 2007, CHEM RES TOXICOL, V20, P344, DOI 10.1021/tx600260a; Guengerich FP, 2007, J BIOCHEM MOL TOXIC, V21, P163, DOI 10.1002/jbt.02174; Guengerich FP, 2001, CHEM RES TOXICOL, V14, P611, DOI 10.1021/tx0002583; Haji-Momenian S, 2003, BIOORGAN MED CHEM, V11, P5545, DOI 10.1016/S0968-0896(03)00525-X; Halgren TA, 2004, J MED CHEM, V47, P1750, DOI 10.1021/jm030644s; Hansch C, 2004, DRUG METAB REV, V36, P105, DOI 10.1081/DMR-120028428; Harris DL, 2004, PROTEINS, V55, P895, DOI 10.1002/prot.20062; Helms V, 1998, J AM CHEM SOC, V120, P2710, DOI 10.1021/ja9738539; Huang SM, 2004, J CLIN PHARMACOL, V44, P559, DOI 10.1177/0091270004265367; HUDELSON MG, 2008, J MED CHEM, V51, P168; Huey R, 2007, J COMPUT CHEM, V28, P1145, DOI 10.1002/jcc.20634; Isin EM, 2006, J BIOL CHEM, V281, P9127, DOI 10.1074/jbc.M511375200; Ito Y, 2008, J MOL GRAPH MODEL, V26, P947, DOI 10.1016/j.jmgm.2007.07.004; Jensen BF, 2007, J MED CHEM, V50, P501, DOI 10.1021/jm060333; Kemp CA, 2004, J MED CHEM, V47, P5340, DOI 10.1021/jm049934e; Keseru GM, 2001, J COMPUT AID MOL DES, V15, P649, DOI 10.1023/A:1011911204383; Kirton SB, 2005, PROTEINS, V58, P836, DOI 10.1002/prot.20389; Kjellander B, 2007, J CHEM INF MODEL, V47, P1234, DOI 10.1021/ci600561v; Kollman PA, 2000, ACCOUNTS CHEM RES, V33, P889, DOI 10.1021/ar000033j; Korhonen LE, 2005, J MED CHEM, V48, P3808, DOI 10.1021/jm0489713; Korolev D, 2003, J MED CHEM, V46, P3631, DOI 10.1021/jm030102a; Kriegl JM, 2005, EUR J PHARM SCI, V24, P451, DOI 10.1016/j.ejps.2004.12.009; Kriegl JM, 2005, J COMPUT AID MOL DES, V19, P189, DOI 10.1007/s10822-005-3785-3; Lamb DC, 2007, CURR OPIN BIOTECH, V18, P504, DOI 10.1016/j.copbio.2007.09.010; Leach AR, 2001, MOL MODELLING PRINCI; Lewis DFV, 2007, J ENZYM INHIB MED CH, V22, P1, DOI 10.1080/14756360600952183; Lewis DFV, 2004, DRUG DISCOV TODAY, V9, P530, DOI 10.1016/S1359-6446(04)03115-0; Lewis DFV, 2003, ARCH BIOCHEM BIOPHYS, V409, P32, DOI 10.1016/S0003-9861(02)00349-1; Lewis DFV, 2000, BIOCHEM PHARMACOL, V60, P293, DOI 10.1016/S0006-2952(00)00335-X; Lill MA, 2006, CHEMMEDCHEM, V1, P73, DOI 10.1002/cmdc.200500024; Locuson CW, 2007, J MED CHEM, V50, P1158, DOI 10.1021/jm060706p; Locuson CW, 2004, BIOCHEMISTRY-US, V43, P6948, DOI 10.1021/bi049651o; Robeits BC, 2008, J CHEM INF MODEL, V48, P397, DOI 10.1021/ci700285e; Mao B, 2006, J CHEM INF MODEL, V46, P2125, DOI 10.1021/ci0600915; Marechal JD, 2006, DRUG METAB DISPOS, V34, P534, DOI 10.1124/dmd.105.007625; McLaughlin LA, 2005, J BIOL CHEM, V280, P38617, DOI 10.1074/jbc.M505974200; Merkwirth C, 2004, J CHEM INF COMP SCI, V44, P1971, DOI 10.1021/ci049850e; Mestres J, 2005, PROTEINS, V58, P596, DOI 10.1002/prot.20354; Moon T, 2000, QUANT STRUCT-ACT REL, V19, P257, DOI 10.1002/1521-3838(200006)19:3<257::AID-QSAR257>3.0.CO;2-2; Murray CW, 1998, J COMPUT AID MOL DES, V12, P503, DOI 10.1023/A:1008040323669; Oostenbrink C, 2004, PROTEINS, V54, P237, DOI 10.1002/prot.10558; Park H, 2005, J AM CHEM SOC, V127, P13634, DOI 10.1021/ja053809q; Park JY, 2003, J MED CHEM, V46, P1645, DOI 10.1021/jm020538a; Paulsen MD, 1996, PROTEIN ENG, V9, P567, DOI 10.1093/protein/9.7.567; Prasad JC, 2007, BIOCHEMISTRY-US, V46, P2640, DOI 10.1021/bi062320m; Rao S, 2000, J MED CHEM, V43, P2789, DOI 10.1021/jm000048n; Ridderstrom M, 2001, J MED CHEM, V44, P4072, DOI 10.1021/jm0109107; Rowland P, 2006, J BIOL CHEM, V281, P7614, DOI 10.1074/jbc.M511232200; Sansen S, 2007, J BIOL CHEM, V282, P14348, DOI 10.1074/jbc.M611692200; Sansen S, 2007, ARCH BIOCHEM BIOPHYS, V464, P197, DOI 10.1016/j.abb.2007.04.028; Schuster D, 2006, CURR TOP MED CHEM, V6, P1627, DOI 10.2174/156802606778108924; Schuster Daniela, 2006, Curr Drug Discov Technol, V3, P1, DOI 10.2174/157016306776637609; Seifert A, 2006, PROTEINS, V64, P147, DOI 10.1002/prot.20951; Shaik S, 2004, EUR J INORG CHEM, P207, DOI 10.1002/ejic.200300448; Sheridan RP, 2007, J MED CHEM, V50, P3173, DOI 10.1021/jm0613471; Snyder R, 2002, QUANT STRUCT-ACT REL, V21, P357, DOI 10.1002/1521-3838(200210)21:4<357::AID-QSAR357>3.0.CO;2-D; Spatzenegger M, 2003, J PHARMACOL EXP THER, V304, P477, DOI 10.1124/jpet.102.043323; Stortelder A, 2006, BIOCHEM J, V393, P635, DOI 10.1042/BJ20051169; Susnow RG, 2003, J CHEM INF COMP SCI, V43, P1308, DOI 10.1021/ci030283p; Szklarz GD, 2002, J BIOMOL STRUCT DYN, V20, P155; Vaz RJ, 2005, BIOORG MED CHEM LETT, V15, P3816, DOI 10.1016/j.bmcl.2005.06.007; Vedani A., 2005, TOXICOL APPL PHARM, V207, pS398; Verdonk ML, 2005, J MED CHEM, V48, P6504, DOI 10.1021/jm050543p; Keizers PHJ, 2005, J MED CHEM, V48, P6117, DOI 10.1021/jm050338+; Wanchana S, 2003, PHARMACEUT RES, V20, P1401, DOI 10.1023/A:1025702009611; Wang RX, 2002, J COMPUT AID MOL DES, V16, P11, DOI 10.1023/A:1016357811882; Warren GL, 2006, J MED CHEM, V49, P5912, DOI 10.1021/jm050362n; Wester MR, 2004, J BIOL CHEM, V279, P35630, DOI 10.1074/jbc.M405427200; Williams JA, 2004, DRUG METAB DISPOS, V32, P1201, DOI 10.1124/dmd.104.000794; Williams PA, 2004, SCIENCE, V305, P683, DOI 10.1126/science.1099736; Williams PA, 2003, NATURE, V424, P464, DOI 10.1038/nature01862; Witten I. H., 2005, DATA MINING PRACTICA; Yano JK, 2004, J BIOL CHEM, V279, P38091, DOI 10.1074/jbc.C400293200; Yap CW, 2006, CURR TOP MED CHEM, V6, P1593, DOI 10.2174/156802606778108942; Yu JL, 2006, DRUG METAB DISPOS, V34, P1386, DOI 10.1124/dmd.106.009852; Zhou DS, 2007, LETT DRUG DES DISCOV, V4, P192, DOI 10.2174/157018007780077462; Zhou DS, 2006, DRUG METAB DISPOS, V34, P976, DOI 10.1124/dmd.105.008631; Zlokarnik G, 2005, DRUG DISCOV TODAY, V10, P1443, DOI 10.1016/S1359-6446(05)03580-4; Zuegge J, 2002, QUANT STRUCT-ACT REL, V21, P249, DOI 10.1002/1521-3838(200208)21:3<249::AID-QSAR249>3.0.CO;2-S	125	31	31	INFORMA HEALTHCARE	LONDON	TELEPHONE HOUSE, 69-77 PAUL STREET, LONDON EC2A 4LQ, ENGLAND	1742-5255		EXPERT OPIN DRUG MET	Expert Opin. Drug Metab. Toxicol.	MAY	2008	4	5					513	527		10.1517/17425250802067085		15	Biochemistry & Molecular Biology; Pharmacology & Pharmacy	Biochemistry & Molecular Biology; Pharmacology & Pharmacy	311BV	WOS:000256576000001	
J	Capobianco, E				Capobianco, Enrico			Model validation for gene selection and regulation maps	FUNCTIONAL & INTEGRATIVE GENOMICS			English	Review						regularization; dimensionality reduction; feature extraction; model validation	INDEPENDENT COMPONENT ANALYSIS; BLIND SOURCE SEPARATION; PROJECTION PURSUIT; MICROARRAY DATA; EXPRESSION DATA; ARRAY DATA; ALGORITHM; NORMALIZATION; CANCER; DECOMPOSITION	Consider the problem of investigating the structure of a set of sample points in a very high dimensional (Euclidean) space. This case is paradigmatic, for instance, in postgenomic applications. The high dimensionality and small sample size make statistical inference and optimization difficult problems, such that selecting a model or choosing a learning algorithm face the evidence that currently no consensus guidelines exist. Usually, the intervention of linear or nonlinear projection method is required to map the observations into a low-dimensional space with the most salient data features preserved. This step usual involves computing statistics from the low-dimension I projected space of features and then inferring on the highly dimensional original structures (the genes). This work deals with model validation for gene selection and regulation dynamics. The analysis is conducted through a mix of quantitative methods and qualitative aspects. A regularized inference approach is employed based on dimensionality reduction, data denoising, and feature extraction tasks. Each task requires the implementation of statistics and machine learning algorithms. We focus on the complex problem of inferring the coregulation from the coexpression gene dynamics in the presence of limited biological information and time course perturbation experiments. In particular, both separation and interference gene dynamics are considered and validated to design the most coherent underlying transcriptional regulatory map.	Technol Pk Sardinia, CRS4 Bioinformat Lab, Cagliari, Sardinia, Italy	Capobianco, E (reprint author), Technol Pk Sardinia, CRS4 Bioinformat Lab, Cagliari, Sardinia, Italy.	ecapob@crs4.it					ALLISON DB, 2005, NAT REV GENET, V7, P55; Alter O, 2000, P NATL ACAD SCI USA, V97, P10101, DOI 10.1073/pnas.97.18.10101; Amari S, 1997, IEEE T SIGNAL PROCES, V45, P2692; Bay SD, 2004, J COMPUT BIOL, V11, P971, DOI 10.1089/1066527042432297; BERGER JA, 2003, P 2003 IEEE INT WORK, P81; Biggar SR, 2001, EMBO J, V20, P3167, DOI 10.1093/emboj/20.12.3167; Bolstad BM, 2003, BIOINFORMATICS, V19, P185, DOI 10.1093/bioinformatics/19.2.185; Bonneau R, 2006, GENOME BIOL, V7, DOI 10.1186/gb-2006-7-5-r36; Capobianco Enrico, 2005, Journal of Bioinformatics and Computational Biology, V3, P1191, DOI 10.1142/S0219720005001454; CARDOSO J, 1993, IEE P F, V140, P771; Cardoso J.F., 2003, J MACHINE LEARNING R, V4, P1177, DOI 10.1162/jmlr.2003.4.7-8.1177; Cardoso J.F., 1989, P IEEE INT C AC SPEE, P2109; Chiappetta P, 2004, J COMPUT BIOL, V11, P1090, DOI 10.1089/cmb.2004.11.1090; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; DIACONIS P, 1984, ANN STAT, V12, P793, DOI 10.1214/aos/1176346703; Donoho DL, 1998, IEEE T INFORM THEORY, V44, P2435, DOI 10.1109/18.720544; Eckart C, 1936, PSYCHOMETRIKA, V1, P211, DOI 10.1007/BF02288367; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; FRIEDMAN JH, 1974, IEEE T COMPUT, VC 23, P881, DOI 10.1109/T-C.1974.224051; FRIEDMAN JH, 1987, J AM STAT ASSOC, V82, P249, DOI 10.2307/2289161; Frigyesi A, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-290; Gentleman R, 2005, BIOINFORMATICS COMPU; Getz G, 2000, P NATL ACAD SCI USA, V97, P12079, DOI 10.1073/pnas.210134797; Golub G. H., 1996, MATRIX COMPUTATIONS; Hod G., 2001, GEN INFORM, V12, P255; Holter NS, 2000, P NATL ACAD SCI USA, V97, P8409, DOI 10.1073/pnas.150242097; Holter NS, 2001, P NATL ACAD SCI USA, V98, P1693, DOI 10.1073/pnas.98.4.1693; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; Huerta AM, 1998, NUCLEIC ACIDS RES, V26, P55, DOI 10.1093/nar/26.1.55; Hyvarinen A, 1999, IEEE T NEURAL NETWOR, V10, P626, DOI 10.1109/72.761722; Hyvarinen A, 1997, NEURAL COMPUT, V9, P1483, DOI 10.1162/neco.1997.9.7.1483; Irizarry RA, 2003, BIOSTATISTICS, V4, P249, DOI 10.1093/biostatistics/4.2.249; Jolliffe I, 1996, PRINCIPAL COMPONENT; JONES MC, 1987, J ROY STAT SOC A STA, V150, P1, DOI 10.2307/2981662; KERR M, 2001, P NATL ACAD SCI USA, V97, P8961; Kluger Y, 2003, GENOME RES, V13, P703, DOI 10.1101/gr.648603; Krupa B, 2002, J THEOR BIOL, V219, P257, DOI 10.1006/jtbi.2002.3119; Lee SI, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-11-r76; Liebermeister W, 2002, BIOINFORMATICS, V18, P51, DOI 10.1093/bioinformatics/18.1.51; Luscombe NM, 2004, NATURE, V431, P308, DOI 10.1038/nature02782; Martoglio AM, 2002, BIOINFORMATICS, V18, P1617, DOI 10.1093/bioinformatics/18.12.1617; Murtagh F, 2004, J CLASSIF, V21, P167, DOI 10.1007/s00357-004-0015-z; Pollard KS, 2002, MATH BIOSCI, V176, P99, DOI 10.1016/S0025-5564(01)00116-X; Quackenbush J, 2002, NAT GENET, V32, P496, DOI 10.1038/ng1032; Saidi SA, 2004, ONCOGENE, V23, P6677, DOI 10.1038/sj.onc.1207562; Schafer J, 2005, STAT APPL GENET MO B, V4, DOI 10.2202/1544-6115.1175; Zhang XW, 2005, EUR J HUM GENET, V13, P1303, DOI 10.1038/sj.ejhg.5201495	48	5	6	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	1438-793X		FUNCT INTEGR GENOMIC	Funct. Integr. Genomics	MAY	2008	8	2					87	99		10.1007/s10142-007-0066-3		13	Genetics & Heredity	Genetics & Heredity	285UC	WOS:000254800700001	
J	Motsinger-Reif, AA; Dudek, SM; Hahn, LW; Ritchie, MD				Motsinger-Reif, Alison A.; Dudek, Scott M.; Hahn, Lance W.; Ritchie, Marylyn D.			Comparison of approaches for machine-learning optimization of neural networks for detecting gene-gene interactions in genetic epidemiology	GENETIC EPIDEMIOLOGY			English	Article						grammatical evolution neural networks; epistasis; genetic programming neural networks	MULTIFACTOR-DIMENSIONALITY REDUCTION; LINKAGE ANALYSIS; MARKER GENOTYPES; HUMAN-DISEASES; SUSCEPTIBILITY; ARCHITECTURE; ASSOCIATION; EPISTASIS; POWER	The detection of genotypes that predict common, complex disease is a challenge for human geneticists. The phenomenon of epistasis, or gene-gene interactions, is particularly problematic for traditional statistical techniques. Additionally, the explosion of genetic information makes exhaustive searches of multilocus combinations computationally infeasible. To address these challenges, neural networks (NN), a pattern recognition method, have been used. One limitation of the NN approach is that its success is dependent on the architecture of the network. To solve this, machine-learning approaches have been suggested to evolve the best NN architecture for a particular data set. In this study we provide a detailed technical description of the use of grammatical evolution to optimize neural networks (GENN) for use in genetic association studies. We compare the performance of GENN to that of a previous machine-learning NN application-genetic programming neural networks in both simulated and real data. We show that GENN greatly outperforms genetic programming neural networks in data sets with a large number of single nucleotide polymorphisms. Additionally, we demonstrate that GENN has high power to detect disease-risk loci in a range of high-order epistatic models. Finally, we demonstrate the scalability of the GENN method with increasing numbers of variables-as many as 500,000 single nucleotide polymorphisms.	[Motsinger-Reif, Alison A.] Vanderbilt Univ, Med Ctr, Ctr Human Genet Res, Dept Mol Physiol, Nashville, TN 37203 USA; [Dudek, Scott M.; Ritchie, Marylyn D.] N Carolina State Univ, Bioinformat Res Ctr, Raleigh, NC 27695 USA; [Hahn, Lance W.] Western Kentucky Univ, Dept Psychol, Bowling Green, KY 42101 USA	Ritchie, MD (reprint author), Vanderbilt Univ, Med Ctr, Ctr Human Genet Res, Dept Mol Physiol, 519 Ligh Hall, Nashville, TN 37203 USA.	ritchie@chgr.mc.vanderbilt.edu	Ritchie, Marylyn/C-1114-2012				Cantu-Paz E., 2000, EFFICIENT ACCURATE P; CANTUPAZ E, 2002, P GEN EV COMP C GECC, P1019; Cho YM, 2004, DIABETOLOGIA, V47, P549, DOI 10.1007/s00125-003-1321-3; Coffey CS, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-49; Curtis D, 2001, ANN HUM GENET, V65, P95, DOI 10.1046/j.1469-1809.2001.6510095.x; GRUAU FC, 1992, CELLULAR ENCODING GE; Haas DW, 2006, J INFECT DIS, V194, P1098, DOI 10.1086/507313; Hahn LW, 2003, BIOINFORMATICS, V19, P376, DOI 10.1093/bioinformatics/btf869; Hastie T, 2001, ELEMENTS STAT LEARNI; Hoh J, 2001, GENOME RES, V11, P2115, DOI 10.1101/gr.204001; KARDIA S, 2000, IDENTIFYING MULTILOC; Koza J. R., 1991, INT JOINT C NEUR NET, VII, P397; Lucek P, 1998, HUM HERED, V48, P275, DOI 10.1159/000022816; Lucek PR, 1997, GENET EPIDEMIOL, V14, P1101, DOI 10.1002/(SICI)1098-2272(1997)14:6<1101::AID-GEPI90>3.0.CO;2-K; Marinov M, 2001, HUM HERED, V51, P169, DOI 10.1159/000053338; Millstein J, 2006, AM J HUM GENET, V78, P15, DOI 10.1086/498850; Mitchell M, 1996, INTRO GENETIC ALGORI; MOODY J, 1994, NEURAL NETWORKS CAPI; MOODY J, 1994, NATO ASI SERIES F; Moore JH, 2002, ANN MED, V34, P88, DOI 10.1080/07853890252953473; Moore JH, 2004, APPL SOFT COMPUT, V4, P79, DOI 10.1016/j.asoc.2003.08.003; Moore JH, 2003, HUM HERED, V56, P73, DOI 10.1159/000073735; MOORE JH, 2001, METHODS MICROARRAY D; Moore JH, 2003, BIOSYSTEMS, V72, P177, DOI 10.1016/S0303-2647(03)00142-4; Motsinger Alison A., 2006, Human Genomics, V2, P318; Motsinger AA, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-39; MOTSINGER AA, 2006, IEEE S COMP INT BIOI, P1; Motsinger AA, 2006, LECT NOTES COMPUT SC, V3907, P103; MOTSINGER AA, 2008, UNPUB BIOINFORMATICS; North BV, 2003, ANN HUM GENET, V67, P348, DOI 10.1046/j.1469-1809.2003.00030.x; NOTSINGER AA, 2006, P GEN EV COMP C NY A, P947; O'Neill M., 2003, GRAMMATICAL EVOLUTIO; O'Neill M, 2001, IEEE T EVOLUT COMPUT, V5, P349, DOI 10.1109/4235.942529; Ott J, 2001, AM J MED GENET B, V105, P61; Ripley B. D, 1996, PATTERN RECOGNITION; Ritchie MD, 2004, LECT NOTES COMPUT SC, V3102, P438; Ritchie MD, 2001, AM J HUM GENET, V69, P138, DOI 10.1086/321276; Ritchie MD, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-28; Ritchie MD, 2003, GENET EPIDEMIOL, V24, P150, DOI 10.1002/gepi.10218; Saccone NL, 1999, GENET EPIDEMIOL, V17, pS703; Sexton RS, 1999, EUR J OPER RES, V114, P589, DOI 10.1016/S0377-2217(98)00114-3; Skapura D. M, 1995, BUILDING NEURAL NETW; Tarassenko L., 1998, GUIDE NEURAL COMPUTI; Templeton A., 2000, EPISTASIS EVOLUTIONA; Yao X, 1999, P IEEE, V87, P1423	45	23	23	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0741-0395		GENET EPIDEMIOL	Genet. Epidemiol.	MAY	2008	32	4					325	340		10.1002/gepi.20307		16	Genetics & Heredity; Public, Environmental & Occupational Health	Genetics & Heredity; Public, Environmental & Occupational Health	295JP	WOS:000255471100004	
J	Sun, YV; Bielak, LE; Peyser, PA; Turner, ST; Sheedy, PE; Boerwinkle, E; Kardia, SLR				Sun, Yan V.; Bielak, Lawrence E.; Peyser, Patricia A.; Turner, Stephen T.; Sheedy, Patrick E., II; Boerwinkle, Eric; Kardia, Sharon L. R.			Application of machine learning algorithms to predict coronary artery calcification with a sibship-based design	GENETIC EPIDEMIOLOGY			English	Article						machine learning; Random Forests; RuleFit; coronary artery calcification; sibship	BEAM COMPUTED-TOMOGRAPHY; NITRIC-OXIDE SYNTHASE; PROTEIN-COUPLED RECEPTOR; C-REACTIVE PROTEIN; HEART-DISEASE; RISK-FACTOR; ASSOCIATION; ADULTS; POLYMORPHISM; QUANTITY	As part of the Genetic Epidemiology Network of Arteriopathy study, hypertensive non-Hispanic White sibships were screened using 471 single nucleotide polymorphisms (SNPs) to identify genes influencing coronary artery calcification (CAC) measured by computed tomography. Individuals with detectable CAC and CAC quantity >= 70th age- and sex-specific percentile were classified as having a high CAC burden and compared to individuals with CAC quantity < 70th percentile. Two sibs from each sibship were randomly chosen and divided into two data sets, each with 360 unrelated individuals. Within each data set, we applied two machine learning algorithms, Random Forests and RuleFit, to identify the best predictors of having high CAC burden among 17 risk factors and 471 SNPs. Using five-fold cross-validation, both methods had similar to 70% sensitivity and similar to 60% specificity. Prediction accuracies were significantly different from random predictions (P-value<0.001) based on 1,000 permutation tests. Predictability of using 287 tagSNPs was as good as using all 471 SNPs. For Random Forests, among the top 50 predictors, the same eight tagSNPs and 15 risk factors were found in both data sets while eight tagSNPs and 12 risk factors were found in both data sets for RuleFit. Replicable effects of two tagSNPs (in genes GPR35 and NOS3) and 12 risk factors (age, body mass index, sex, serum glucose, high-density lipoprotein cholesterol, systolic blood pressure, cholesterol, homocysteine, triglycerides, fibrinogen, Lp(a) and low-density lipoprotein particle size) were identified by both methods. This study illustrates how machine learning methods can be used in sibships to identify important, replicable predictors of subdinical coronary atherosclerosis.	[Sun, Yan V.; Bielak, Lawrence E.; Peyser, Patricia A.; Kardia, Sharon L. R.] Univ Michigan, Sch Publ Hlth, Dept Epidemiol, Observ 109, Ann Arbor, MI 48109 USA; [Turner, Stephen T.] Mayo Clin, Div Nephrol & Hypertens, Rochester, MI USA; [Sheedy, Patrick E., II] Mayo Clin, Div Diagnost Radiol, Rochester, MI USA; [Boerwinkle, Eric] Univ Texas Hlth Sci Ctr, Ctr Human Genet, Houston, TX USA	Sun, YV (reprint author), Univ Michigan, Sch Publ Hlth, Dept Epidemiol, Observ 109, Ann Arbor, MI 48109 USA.	yansun@umich.edu	Sun, Yan/A-7461-2008				AGATSTON AS, 1990, J AM COLL CARDIOL, V15, P827; Arad Y, 2000, J AM COLL CARDIOL, V36, P1253, DOI 10.1016/S0735-1097(00)00872-X; Bielak LF, 2001, RADIOLOGY, V218, P224; Bielak LF, 2000, ARTERIOSCL THROM VAS, V20, P2167; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Budoff MJ, 2007, J AM COLL CARDIOL, V49, P1860, DOI 10.1016/j.jacc.2006.10.079; Carlson CS, 2004, AM J HUM GENET, V74, P106, DOI 10.1086/381000; Cassidy AE, 2004, MED SCI MONITOR, V10, pCR493; Chiano MN, 1998, ANN HUM GENET, V62, P55, DOI 10.1017/S0003480098006678; CLAUSS A., 1957, ACTA HAEMATOL, V17, P237; GRUNDY SM, 1993, JAMA-J AM MED ASSOC, V269, P3015; Fornage M, 2004, CIRCULATION, V109, P335, DOI 10.1161/01.CIR.0000109487.46725.02; Friedman J., 2005, PREDICTIVE LEARNING; Gunderson KL, 2006, METHOD ENZYMOL, V410, P359, DOI 10.1016/S0076-6879(06)10017-8; Hingorani AD, 1999, CIRCULATION, V100, P1515; Hoefner DM, 2001, CLIN CHEM, V47, P266; Kardia SLR, 1999, ARTERIOSCL THROM VAS, V19, P427; Keelan PC, 2001, CIRCULATION, V104, P412, DOI 10.1161/hc2901.093112; Keevil BG, 1998, ANN CLIN BIOCHEM, V35, P671; Kelly RJ, 2007, BIOINFORMATICS, V23, P249, DOI 10.1093/bioinformatics/btl510; Konig IR, 2007, STAT MED, V26, P5499, DOI 10.1002/sim.3069; KOTTKE BA, 1991, MAYO CLIN PROC, V66, P1198; Kuhlencordt PJ, 2001, CIRCULATION, V104, P448, DOI 10.1161/hc2901.091399; Kuller LH, 1999, ARTERIOSCL THROM VAS, V19, P2189; Kullo IJ, 2004, AM J HYPERTENS, V17, P845, DOI 10.1016/j.amjhyper.2004.06.012; Kullo IJ, 2006, MAYO CLIN PROC, V81, P177; Lange LA, 2002, ARTERIOSCL THROM VAS, V22, P418, DOI 10.1161/hq0302.105721; LEVINE DM, 1992, INT J CLIN LAB RES, V22, P173, DOI 10.1007/BF02591419; Magera MJ, 1999, CLIN CHEM, V45, P1517; Matsuzaki H, 2004, NAT METHODS, V1, P109, DOI 10.1038/nmeth718; Naber CK, 2001, AM J PHYSIOL-HEART C, V281, pH1908; Okumura S, 2004, CANCER SCI, V95, P131, DOI 10.1111/j.1349-7006.2004.tb03193.x; O'Meara JG, 2004, ARCH INTERN MED, V164, P1313, DOI 10.1001/archinte.164.12.1313; Peyser PA, 2002, CIRCULATION, V106, P304, DOI 10.1161/01.CIR.0000022664.21832.5D; Rankinen T, 2000, HYPERTENSION, V36, P885; Rosamond W, 2007, CIRCULATION, V115, pE69, DOI 10.1161/CIRCULATIONAHA.106.179918; Savvidou MD, 2001, HYPERTENSION, V38, P1289, DOI 10.1161/hy1201.097305; Strobl C, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-25; SU YV, 2007, BMC P, V1, pS62; SUN YV, 2008, IN PRESS EUR J HUM G; Turner ST, 2006, ATHEROSCLEROSIS, V185, P340, DOI 10.1016/j.atherosclerosis.2005.06.010; Wang JH, 2006, J BIOL CHEM, V281, P22021, DOI 10.1074/jbc.M603503200; Wang TJ, 2002, CIRCULATION, V106, P1189, DOI 10.1161/01.CIR.000032135.98011.C4; Wang XL, 1996, NAT MED, V2, P41, DOI 10.1038/nm0196-41; Wexler L, 1996, CIRCULATION, V94, P1175; Wilson PWF, 1998, CIRCULATION, V97, P1837	46	13	13	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0741-0395		GENET EPIDEMIOL	Genet. Epidemiol.	MAY	2008	32	4					350	360		10.1002/gepi.20309		11	Genetics & Heredity; Public, Environmental & Occupational Health	Genetics & Heredity; Public, Environmental & Occupational Health	295JP	WOS:000255471100006	
J	Su, MF; Taha, MMR; Christodoulou, CG; El-Kady, I				Su, Mehmet F.; Taha, Mahmoud M. Reda; Christodoulou, Christos G.; El-Kady, Ihab			Fuzzy learning of talbot effect guides optimal mask design for proximity field nanopatterning lithography	IEEE PHOTONICS TECHNOLOGY LETTERS			English	Article						finite-difference time-domain (FDTD) methods; nanotechnology; numerical analysis; optimization methods; photolithography	3-DIMENSIONAL NANOSTRUCTURES	Processing methods used in photonics and nanotechnology possess many limitations restricting their application areas such as high cost, inability to produce fine details, problems with scalability, and long processing time. Proximity field nanopatterning is a lithography method which surpasses these limitations. By using interference patterns produced by a two-dimensional phase mask, the technique is able to generate a submicron detailed exposure on a millimeter-size slab of light sensitive photopolymer, which is then developed like a photographic plate to reveal three-dimensional interference patterns from the phase mask. While it is possible to use simulations to obtain the interference patterns produced by a phase mask, realizing the mask dimensions necessary for producing a desired interference pattern is analytically challenging due to the intricacies of light interactions involved in producing the final interference pattern. An alternative method is to iteratively optimize the phase mask until the interference patterns obtained converge to the desired pattern. However, depending on the optimization technique used, one either risks a significant probability of failure or requires a prohibitive number of iterations. We argue that an optimization technique that is to take advantage of the physics of the problem using machine learning methods (here fuzzy learning) can lead to competent mask design. This technique is described in this letter.	[Su, Mehmet F.; Christodoulou, Christos G.; El-Kady, Ihab] Univ New Mexico, Dept Elect & Comp Engn, Albuquerque, NM 87131 USA; [Taha, Mahmoud M. Reda] Univ New Mexico, Dept Civil Engn, Albuquerque, NM 87131 USA; [El-Kady, Ihab] Dept Photon Microsyst Technol, Sandia Natl Labs, Albuquerque, NM 87185 USA	Su, MF (reprint author), Univ New Mexico, Dept Elect & Comp Engn, Albuquerque, NM 87131 USA.	mfatihsu@ece.unm.edu; mrtaha@unm.edu; Christos@ece.unm.edu; ielkady@sandia.gov	El-Kady, Ihab/D-2886-2013	El-Kady, Ihab/0000-0001-7417-9814			Berry MV, 1996, J MOD OPTIC, V43, P2139, DOI 10.1080/095003496154761; Jang J.-S.R., 1997, NEURO FUZZY SOFT COM; Jeon S, 2007, OPT EXPRESS, V15, P6358, DOI 10.1364/OE.15.006358; Jeon S, 2004, P NATL ACAD SCI USA, V101, P12428, DOI 10.1073/pnas.0403048101; Ravindran A., 2006, ENG OPTIMIZATION; Ross Timothy J., 2004, FUZZY LOGIC ENG APPL; SU MF, PHOTON NANOSTRUCTURE; Tolt G, 2006, SOFT COMPUT, V10, P1117, DOI 10.1007/s00500-005-0034-6; YEE KS, 1966, IEEE T ANTENN PROPAG, VAP14, P302	9	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1041-1135		IEEE PHOTONIC TECH L	IEEE Photonics Technol. Lett.	MAY-JUN	2008	20	9-12					761	763		10.1109/LPT.2008.91951		3	Engineering, Electrical & Electronic; Optics; Physics, Applied	Engineering; Optics; Physics	316QZ	WOS:000256966100032	
J	Robnik-Sikonja, M; Kononenko, I				Robnik-Sikonja, Marko; Kononenko, Igor			Explaining classifications for individual instances	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						machine learning; decision support; knowledge modeling; information visualization; model explanation; model comprehensibility; decision visualization; prediction models; classification; nearest neighbor; neural nets; support vector machines	NEURAL-NETWORKS; RULES	We present a method for explaining predictions for individual instances. The presented approach is general and can be used with all classification models that output probabilities. It is based on the decomposition of a model's predictions on individual contributions of each attribute. Our method works for the so-called black box models such as support vector machines, neural networks, and nearest neighbor algorithms, as well as for ensemble methods such as boosting and random forests. We demonstrate that the generated explanations closely follow the learned models and present a visualization technique that shows the utility of our approach and enables the comparison of different prediction methods.	[Robnik-Sikonja, Marko; Kononenko, Igor] Univ Ljubljana, Fac Comp & Informat Sci, Ljubljana 1000, Slovenia	Robnik-Sikonja, M (reprint author), Univ Ljubljana, Fac Comp & Informat Sci, Trzaska 25, Ljubljana 1000, Slovenia.	marko.robnik@fri.uni-lj.si; igor.konnenko@fri.uni-lj.si					Andrews R, 1995, KNOWL-BASED SYST, V8, P373, DOI 10.1016/0950-7051(96)81920-4; Becker B., 1997, P KDD WORKSH ISS INT; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CARAGEA D, 2003, P 3 IEEE INT C DAT M, P497; Craven M. W., 1994, P 11 INT C MACH LEAR, P37; Craven MW, 1996, ADV NEUR IN, V8, P24; FRAMLING K, 1996, P ART INT SIM BEH C; d'Avila Garcez A. S., 2001, Artificial Intelligence, V125, DOI 10.1016/S0004-3702(00)00077-1; GOOD LJ, 1950, PROBABILITY WEIGHING; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; HAMEL L, 2006, P IEEE S COMP INT BI; Hosmer DW, 2000, APPL LOGISTIC REGRES; Jacobsson H, 2005, NEURAL COMPUT, V17, P1223, DOI 10.1162/0899766053630350; Jakulin A., 2005, P 17 INT C KNOWL DIS, P108, DOI 10.1145/1081870.1081886; KONONENKO I, 1993, APPL ARTIF INTELL, V7, P317, DOI 10.1080/08839519308949993; Liao Tim Futing, 1994, INTERPRETING PROBABI; LUBSEN J, 1978, METHOD INFORM MED, V17, P127; Madigan D, 1997, J COMPUT GRAPH STAT, V6, P160, DOI 10.2307/1390929; Mitchell T, 1997, MACHINE LEARNING; Mozina M., 2004, P PRINC PRACT KNOWL, P337; NICULESCUMIZIL A, 2005, P 22 INT C MACH LEAR; PALADE V, 2001, P INT C 7 FUZZ DAYS, P152; Poulet F, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P499, DOI 10.1109/ICDM.2004.10068; POULIN B, 2006, P 21 NAT C ART INT A; Robins JM, 2000, EPIDEMIOLOGY, V11, P550, DOI 10.1097/00001648-200009000-00011; ROBNIKSIKONJA M, 2007, EFFICIENT METHOD EXP; Setiono R, 1995, P 14 INT JOINT C ART, P480; SHANNON CE, 1948, AT&T TECH J, V27, P379; Thrun S., 1995, ADV NEURAL INFORMATI, V7, P505; TOWELL GG, 1993, MACH LEARN, V13, P71, DOI 10.1007/BF00993103; TVERSKY A, 1974, SCIENCE, V185, P1124, DOI 10.1126/science.185.4157.1124	31	14	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAY	2008	20	5					589	600		10.1109/TKDE.2007.190734		12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	287NG	WOS:000254923200002	
J	Chen, XW; Anantha, G; Lin, XT				Chen, Xue-Wen; Anantha, Gopalakrishna; Lin, Xiaotong			Improving Bayesian network structure learning with mutual information-based node ordering in the K2 algorithm	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						classification; data mining; machine-learning	PROBABILISTIC NETWORKS; STRUCTURE DISCOVERY; GENETIC ALGORITHMS; MODELS	Structure learning of Bayesian networks is a well-researched but computationally hard task. We present an algorithm that integrates an information-theory-based approach and a scoring-function-based approach for learning structures of Bayesian networks. Our algorithm also makes use of basic Bayesian network concepts like cl-separation and condition independence. We show that the proposed algorithm is capable of handling networks with a large number of variables. We present the applicability of the proposed algorithm on four standard network data sets and also compare its performance and computational efficiency with other standard structured learning methods. The experimental results show that our method can efficiently and accurately identify complex network structures from data.	[Chen, Xue-Wen; Anantha, Gopalakrishna; Lin, Xiaotong] Univ Kansas, Dept Comp Sci & Elect Engn, Lawrence, KS 66045 USA	Chen, XW (reprint author), Univ Kansas, Dept Comp Sci & Elect Engn, 1520 W 15th St, Lawrence, KS 66045 USA.	xwchen@ku.edu; gopal.anantha@gmail.com; cindylin@ku.edu					Abramson B, 1996, INT J FORECASTING, V12, P57, DOI 10.1016/0169-2070(95)00664-8; Acid S, 2003, J ARTIF INTELL RES, V18, P445; AGOSTA JM, 1990, UNCERTAINTY ARTIFICI, V4, P397; Beinlich I. A., 1989, P 2 EUR C ART INT ME; Bouckaert R. R., 1993, LECT NOTES COMPUTER, V747, P41; Buntine W., 1991, P 7 C UNC ART INT, P52; Buntine W, 1996, IEEE T KNOWL DATA EN, V8, P195, DOI 10.1109/69.494161; CAMPOS L, 1997, INT J INTELL SYST, V12, P495; Castelo R, 2004, J MACH LEARN RES, V4, P527, DOI 10.1162/153244304773936045; CHARTRAND G, 2005, GRAPHS DIGRAPH; Cheng J, 2002, ARTIF INTELL, V137, P43, DOI 10.1016/S0004-3702(02)00191-1; Cheng J., 1997, P 6 INT WORKSH ART I; CHICKERING D, 1995, PRELIMINARY PAPERS 5; CHICKERING D. M., 2002, J MACHINE LEARNING R, V3, P507; Chickering DM, 2002, J MACH LEARN RES, V2, P445, DOI 10.1162/153244302760200696; Chickering D.M., 1996, LEARNING DATA ARTIFI, P121; Chickering DM, 2004, J MACH LEARN RES, V5, P1287; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; De Campos LM, 1998, J EXP THEOR ARTIF IN, V10, P511, DOI 10.1080/095281398146743; de Campos LM, 2000, INT J APPROX REASON, V24, P11, DOI 10.1016/S0888-613X(99)00042-0; Friedman N, 2003, MACH LEARN, V50, P95, DOI 10.1023/A:1020249912095; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Friedman N., 1996, P 12 C UNC ART INT; GEIGER D, 1993, INT J INTELL SYST, V8, P231; GEIGER D, 1990, P 8 NAT C ART INT AA; Heckerman D., 1996, MSRTR9506; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; HECKERMAN D, 1990, NETWORKS, V20, P607, DOI 10.1002/net.3230200508; Jensen F., 1996, INTRO BAYESIAN NETWO; Koivisto M, 2004, J MACH LEARN RES, V5, P549; Lam W., 1994, COMPUT INTELL, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x; Larranaga P, 1996, IEEE T SYST MAN CY A, V26, P487, DOI 10.1109/3468.508827; Larranaga P, 1996, IEEE T PATTERN ANAL, V18, P912, DOI 10.1109/34.537345; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; MADIGAN D, 1995, INT STAT REV, V63, P215, DOI 10.2307/1403615; Meek C., 1995, P 11 C UNC ART INT; MURPHY P, 1995, UCI RESP MACHINE LEA; Nikovski D, 2000, IEEE T KNOWL DATA EN, V12, P509, DOI 10.1109/69.868904; Pearl J., 1988, PROBABILISTIC REASON; Pearl J., 1990, P 6 C UNC ART INT; PIETQUIN O, 2005, IEEE T SPEECH AUDIO, V14, P589; Proakis J. G., 2000, DIGITAL COMMUNICATIO; SPIRTES P, 1993, LECT NOTES STAT 81; Suzuki J.A., 1993, P 9 C UNC ART INT, P266; WERMUTH N, 1983, BIOMETRIKA, V70, P537, DOI 10.2307/2336490; Yu J, 2004, BIOINFORMATICS, V20, P3594, DOI 10.1093/bioinformatics/bth448	47	15	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAY	2008	20	5					628	640		10.1109/TKDE.2007.190732		13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	287NG	WOS:000254923200005	
J	Lin, T; Zha, HB				Lin, Tong; Zha, Hongbin			Riemannian manifold learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						dimensionality reduction; manifold learning; manifold reconstruction; Riemannian manifolds; Riemannian normal coordinates	NONLINEAR DIMENSIONALITY REDUCTION; INTRINSIC DIMENSIONALITY; DIFFUSION MAPS; RECOGNITION; FRAMEWORK; EIGENMAPS; DESIGN	Recently, manifold learning has been widely exploited in pattern recognition, data analysis, and machine learning. This paper presents a novel framework, called Riemannian manifold learning (RML), based on the assumption that the input high-dimensional data lie on an intrinsically low-dimensional Riemannian manifold. The main idea is to formulate the dimensionality reduction problem as a classical problem in Riemannian geometry, that is, how to construct coordinate charts for a given Riemannian manifold? We implement the Riemannian normal coordinate chart, which has been the most widely used in Riemannian geometry, for a set of unorganized data points. First, two input parameters (the neighborhood size k and the intrinsic dimension d) are estimated based on an efficient simplicial reconstruction of the underlying manifold. Then, the normal coordinates are computed to map the input high-dimensional data into a low-dimensional space. Experiments on synthetic data, as well as real-world images, demonstrate that our algorithm can learn intrinsic geometric structures of the data, preserve radial geodesic distances, and yield regular embeddings.	[Lin, Tong; Zha, Hongbin] Peking Univ, Sch EECS, Key Lab Machine Percept, Beijing 100871, Peoples R China	Lin, T (reprint author), Peking Univ, Sch EECS, Key Lab Machine Percept, Sci Bldg, Beijing 100871, Peoples R China.	lintong@cis.pku.edu.cn; zha@cis.pku.edu.cn					Atiyah M, 2002, B LOND MATH SOC, V34, P1, DOI 10.1112/S0024609301008566; Balasubramanian Mukund, 2002, Science, V295, P7; BALDI P, 1989, NEURAL NETWORKS, V2, P53, DOI 10.1016/0893-6080(89)90014-2; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bengio Y., 2003, P ADV NEUR INF PROC, V16, P177; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; Brand M., 2003, ADV NEURAL INFORMATI, V15, P961; BRUN A, 2005, P 14 SCAND C IM AN, P920; Bruske J, 1998, IEEE T PATTERN ANAL, V20, P572, DOI 10.1109/34.682189; Camastra F, 2003, PATTERN RECOGN, V36, P2945, DOI 10.1016/S0031-3203(03)00176-6; Camastra F, 2002, IEEE T PATTERN ANAL, V24, P1404, DOI 10.1109/TPAMI.2002.1039212; Coifman RR, 2006, APPL COMPUT HARMON A, V21, P5, DOI 10.1016/j.acha.2006.04.006; Coifman RR, 2006, APPL COMPUT HARMON A, V21, P31, DOI 10.1016/j.acha.2005.07.005; CORMEN T, 2001, INTRO ALGORTITHMS; Costa JA, 2004, IEEE T SIGNAL PROCES, V52, P2210, DOI 10.1109/TSP.2004.831130; Cox TF, 1994, MULTIDIMENSIONAL SCA; De Silva V., 2003, P ADV NEURAL INFORM, V15, P705; Donoho DL, 2000, P AMS MATH CHALL 21; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100; Donoho D.L., 2002, 200227 STANF U DEP S; Duda R. O., 2001, PATTERN CLASSIFICATI; EBERLY D, 1999, DISTANCE POINT GEN Q; EBERLY D, 2005, COMPUTING GEODESICS; Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185; Freedman D, 2002, IEEE T PATTERN ANAL, V24, P1349, DOI 10.1109/TPAMI.2002.1039206; FUKUNAGA K, 1976, IEEE T COMPUT, V20, P165; GOLUB GH, 2004, CONSTRAINED LEAST SQ; He XF, 2005, IEEE T PATTERN ANAL, V27, P328; Jolliffe I.T., 1989, PRINCIPAL COMPONENT; Jost J., 2002, RIEMANNIAN GEOMETRY; Kegl B, 2000, IEEE T PATTERN ANAL, V22, P281, DOI 10.1109/34.841759; Kohonen T., 2001, SELF ORGANIZING MAPS; Lafon S, 2006, IEEE T PATTERN ANAL, V28, P1393, DOI 10.1109/TPAMI.2006.184; Law MHC, 2006, IEEE T PATTERN ANAL, V28, P377, DOI 10.1109/TPAMI.2006.56; Lee J. M., 1997, RIEMANNIAN MANIFOLDS; LEVINA E, 2005, P ADV NEURAL INFORM, V17, P777; Lin T, 2006, P 9 EUR C COMP VIS, P44; Nadler B, 2006, APPL COMPUT HARMON A, V21, P113, DOI 10.1016/j.acha.2005.07.004; PETTIS KW, 1979, IEEE T PATTERN ANAL, V1, P25; Press WH, 1992, NUMERICAL RECIPES C; RAGINSKY M, 2005, P ADV NEURAL INFORM; Riemann Bernhard, 1873, NATURE, V8, P36; Riemann Bernhard, 1873, NATURE, V8, P14; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Saul LK., 2003, J MACHINE LEARNING R, V4, P119; Seung HS, 2000, SCIENCE, V290, P2268, DOI 10.1126/science.290.5500.2268; SHA F, 2005, P 22 INT C MACH LEAR, P785; Smolinski P, 2001, COMPUT APPL ENG EDUC, V9, P1, DOI 10.1002/cae.1000; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; TRUNK GV, 1976, IEEE T COMPUT, V25, P165; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; VERVEER PJ, 1995, IEEE T PATTERN ANAL, V17, P81, DOI 10.1109/34.368147; Wang A, 2005, IIE TRANS, V37, P17, DOI 10.1080/07408170590516773; Weinberger K.Q., 2004, P IEEE C COMP VIS PA, P988, DOI 10.1109/CVPR.2004.1315272; WITTMAN T, 2005, MANI MATLAB DEMO; Yang J, 2005, IEEE T PATTERN ANAL, V27, P230; Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154	57	69	86	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2008	30	5					796	809		10.1109/TPAMI.2007.70735		14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	272SI	WOS:000253879700004	
J	Landgrebe, TCW; Duin, RPW				Landgrebe, Thomas C. W.; Duin, Robert P. W.			Efficient multiclass ROC approximation by decomposition via confusion matrix perturbation analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern recognition; machine learning; design methodology; classifier design and evaluation; receiver operator characteristic; multiclass analysis; cost sensitive; volume under the ROC	N-CLASS CLASSIFICATION; OBSERVERS; CURVE; AREA	Receiver operator characteristic (ROC) analysis has become a standard tool in the design and evaluation of two-class classification problems. It allows for an analysis that incorporates all possible priors, costs, and operating points, which is important in many real problems, where conditions are often nonideal. Extending this to the multiclass case is attractive, conferring the benefits of ROC analysis to a multitude of new problems. Even though the ROC analysis extends theoretically to the multiclass case, the exponential computational complexity as a function of the number of classes is restrictive. In this paper, we show that the multiclass ROC can often be simplified considerably because some ROC dimensions are independent of each other. We present an algorithm that analyzes interactions between various ROC dimensions, identifying independent classes, and groups of interacting classes, allowing the ROC to be decomposed. The resulting decomposed ROC hypersurface can be interrogated in a similar fashion to the ideal case, allowing for approaches such as cost-sensitive and Neyman-Pearson optimization, as well as the volume under the ROC. An extensive bouquet of examples and experiments demonstrates the potential of this methodology.	[Landgrebe, Thomas C. W.; Duin, Robert P. W.] Delft Univ Technol, Informat & Commun Theory Grp, NL-2628 CD Delft, Netherlands	Landgrebe, TCW (reprint author), Delft Univ Technol, Informat & Commun Theory Grp, Mekelweg 4, NL-2628 CD Delft, Netherlands.	LandgrebeTCW@gmail.com; r.duin@ieee.org					Abe N., 2004, P 10 ACM SIGKDD INT, P3, DOI 10.1145/1014052.1014056; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Dreiseitl S, 2000, MED DECIS MAKING, V20, P323, DOI 10.1177/0272989X0002000309; Duda R. O., 2001, PATTERN CLASSIFICATI; Edwards DC, 2004, IEEE T MED IMAGING, V23, P891, DOI 10.1109/TMI.2004.828358; Edwards DC, 2005, IEEE T MED IMAGING, V24, P293, DOI 10.1109/TMI.2004.841227; EVERSON R, 2005, PATTERN RECOGNITION, V27; Fawcatt T., 2005, PATTERN RECOGN, V27, P861; Ferri C., 2003, P 14 EUR C MACH LEAR, P108; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; Lachiche N., 2003, P 20 INT C MACH LEAR, P416; LANDGREBE T, 2007, PATTERN RECOGNITION; LANDGREBE T, 2005, P 16 ANN S PATT REC; LANDGREBE T, 2006, P IAPR INT WORKSH ST, P512; Landgrebe T. C. W., 2006, P 17 ANN S PATT REC; Li M, 2006, PATTERN RECOGN, V39, P1230, DOI 10.1016/j.patcog.2006.01.010; Loog M, 2001, IEEE T PATTERN ANAL, V23, P762, DOI 10.1109/34.935849; McDonald RA, 2006, PATTERN RECOGN LETT, V27, P1472, DOI 10.1016/j.patrec.2006.02.012; METZ C, 1978, SEMINARS NUCL MED, V3; Mossman D, 1999, MED DECIS MAKING, V19, P78, DOI 10.1177/0272989X9901900110; MURPHY P, 1992, CI REPOSITORY MACHIN; OBRIEN D, 2005, P 22 INT C MACH LEAR; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; PROVOST F, 2001, P 3 INT C KNOWL DISC, P43; PROVOST F, 2001, IS0004 CEDER NEW YOR; Srinivasan A., 1999, PRGTR299 OXF U COMP; WILSON C, 1992, ADV SYSTEMS DIVISION; *ELENA PROJ, 2004, EURO ESPRIT 5516 PRO; *U TOR, 2008, DELV DAT IM SEGM	30	18	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2008	30	5					810	822		10.1109/TPAMI.2007.70740		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	272SI	WOS:000253879700005	
J	Chan, AB; Vasconcelos, N				Chan, Antoni B.; Vasconcelos, Nuno			Modeling, clustering, and segmenting video with mixtures of dynamic textures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						dynamic texture; temporal textures; video modeling; video clustering; motion segmentation; mixture models; linear dynamical systems; time-series clustering; Kalman filter; probabilistic models; expectation-maximization	TIME-SERIES; MOTION SEGMENTATION; MAXIMUM-LIKELIHOOD; IMAGE SEGMENTATION; LINEAR-MODELS; OPTICAL-FLOW; TRACKING; LAYERS	Adynamic texture is a spatio-temporal generative model for video, which represents video sequences as observations from a linear dynamical system. This work studies the mixture of dynamic textures, a statistical model for an ensemble of video sequences that is sampled from a finite collection of visual processes, each of which is a dynamic texture. An expectation-maximization (EM) algorithm is derived for learning the parameters of the model, and the model is related to previous works in linear systems, machine learning, time-series clustering, control theory, and computer vision. Through experimentation, it is shown that the mixture of dynamic textures is a suitable representation for both the appearance and dynamics of a variety of visual processes that have traditionally been challenging for computer vision (for example, fire, steam, water, vehicle and pedestrian traffic, and so forth). When compared with state-of-the-art methods in motion segmentation, including both temporal texture methods and traditional representations (for example, optical flow or other localized motion representations), the mixture of dynamic textures achieves superior performance in the problems of clustering and segmenting video of such processes.	[Chan, Antoni B.; Vasconcelos, Nuno] Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA	Chan, AB (reprint author), Univ Calif San Diego, Dept Elect & Comp Engn, Gilman Dr,Mail Code 0409, La Jolla, CA 92093 USA.	abchan@ucsd.edu; nuno@ece.ucsd.edu	Chan, Antoni/D-7858-2013				ANANDAN P, 1993, MOTION ANAL IMAGE SE, P1; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Bauer D, 2005, J TIME SER ANAL, V26, P631, DOI 10.1111/j.1467-9892.2005.00441.x; BROWN RG, 1983, IEEE T CIRCUITS SYST, V30, P765, DOI 10.1109/TCS.1983.1085288; Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800; Chan A., 2006, ADV NEURAL INFORM PR, V18, P203; Chan A. B., 2005, P IEEE INT C COMP VI, V1, P641; CHAN AB, 2005, P IEEE C COMP VIS PA, V1, P846; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; COOPER L, 2005, P IEEE INT C COMP VI; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Digalakis V, 1993, IEEE T SPEECH AUDI P, V1, P431, DOI 10.1109/89.242489; Doretto G., 2003, P IEEE INT C COMP VI, V2, P1236; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; Duda R. O., 2001, PATTERN CLASSIFICATI; Fitzpatrick JJ, 2001, APPL NURS RES, V14, P1, DOI 10.1053/apnr.2001.22463; Frey B. J., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), DOI 10.1109/CVPR.1999.786972; Ghahramani Z, 2000, NEURAL COMPUT, V12, P831, DOI 10.1162/089976600300015619; Ghahramani Z., 1997, CRGTR961 U TOR DEP C; Ghahramani Z., 1996, CRGTR962 U TOR DEP C; GHOREYSHI A, 2006, P EUR C COMP VIS DYN; HANSEN M, 1994, P ARPA IM UND WORKSH, P457; Horn B. K. P., 1986, ROBOT VISION; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Irani M., 1992, P 2 EUR C COMP VIS S, P282; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Isard M., 1998, P 6 INT C COMP VIS, P107; JENSEN F, 2001, BAYESIAN NETWORKS DE; Jepson A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), DOI 10.1109/CVPR.1993.341161; Kakizawa Y, 1998, J AM STAT ASSOC, V93, P328, DOI 10.2307/2669629; Kay SM, 1993, FUNDAMENTALS STAT SI; KIM CJ, 1994, J ECONOMETRICS, V60, P1, DOI 10.1016/0304-4076(94)90036-1; LAINIOTIS DG, 1976, P IEEE, V64, P1126, DOI 10.1109/PROC.1976.10284; Liao TW, 2005, PATTERN RECOGN, V38, P1857, DOI 10.1016/j.patcog.2005.01.025; Lucas B. D., 1981, P DARPA IM UND WORKS, P121; MAGILL DT, 1965, IEEE T AUTOMAT CONTR, VAC10, P434, DOI 10.1109/TAC.1965.1098191; Narendra KS, 1997, IEEE T AUTOMAT CONTR, V42, P171, DOI 10.1109/9.554398; OH SM, 2005, P 10 IEE INT C COMP, V2, P1161; Overschee P. V., 1994, AUTOMATICA, V30, P75; PAVLOVIC V, 1999, P IEEE C COMP VIS PA; PAVLOVIC V, 2000, ADV NEURAL INFORM PR, V13; Ponce J., 2002, COMPUTER VISION MODE; Roweis S, 1999, NEURAL COMPUT, V11, P305, DOI 10.1162/089976699300016674; Saisan P., 2001, P C COMP VIS PATT RE, V2, P58; Sawhney HS, 1996, IEEE T PATTERN ANAL, V18, P814, DOI 10.1109/34.531801; SHI J, 1999, P INT C COMP VIS, P1154; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; Shumway R. H., 1982, Journal of Time Series Analysis, V3, DOI 10.1111/j.1467-9892.1982.tb00349.x; SHUMWAY RH, 1991, J AM STAT ASSOC, V86, P763, DOI 10.2307/2290410; SINGHAL A, 2002, P AM CONTR C, V5, P3931, DOI 10.1109/ACC.2002.1024543; Soatto S., 2001, Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001, DOI 10.1109/ICCV.2001.937658; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; Vasconcelos N, 2004, IEEE T SIGNAL PROCES, V52, P2322, DOI 10.1109/TSP.2004.831125; Vasconcelos N, 2001, IEEE T PATTERN ANAL, V23, P217, DOI 10.1109/34.908972; VIDAL R, 2005, P IEEE C COMP VIS PA, V2, P516; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; Weiss Y, 1997, PROC CVPR IEEE, P520, DOI 10.1109/CVPR.1997.609375; Wu Y, 2003, PROC CVPR IEEE, P295; Xiong YM, 2004, PATTERN RECOGN, V37, P1675, DOI 10.1016/j.patcog.2003.12.018; Young S., 2006, HTK BOOK; 2008, MIXTURES DYNAMIC TEX	62	48	52	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2008	30	5					909	926		10.1109/TPAMI.2007.70738		18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	272SI	WOS:000253879700012	
J	Voumvoulakis, EM; Hatziargyriou, ND				Voumvoulakis, Emmanouil M.; Hatziargyriou, Nikos D.			Decision trees-aided self-organized maps for corrective dynamic security	IEEE TRANSACTIONS ON POWER SYSTEMS			English	Article						artificial intelligence; corrective control; decision trees; dynamic security; load shedding; machine learning; preventive control; self-organized maps	POWER-SYSTEMS; VOLTAGE STABILITY; NEURAL NETWORKS	Difficulties in expanding the generation and transmission system force modern power systems to operate often close to their stability limits, in order to meet the continuously growing demand. An effective way to face power system contingencies that can lead to instability is load shedding. This paper proposes a machine learning framework for the evaluation of load shedding for corrective dynamic security of the system. The proposed method employs a self-organized map with decision trees nested in some of its nodes in order to classify the load profiles of a power system. The method is applied on a realistic model of the Hellenic Power System and its added value is shown by comparing results with the ones obtained from the application of simple self-organized maps and simple decision trees.	[Voumvoulakis, Emmanouil M.; Hatziargyriou, Nikos D.] Natl Tech Univ Athens, Dept Elect & Comp Engn, GR-15773 Athens, Greece	Voumvoulakis, EM (reprint author), Natl Tech Univ Athens, Dept Elect & Comp Engn, GR-15773 Athens, Greece.						ARESI R, 1999, P POW ENG SOC GEN M; BIJWE P, 1999, P I ELECT ENG GEN TR, V146, P483; Cutsem T.V., 1998, VOLTAGE STABILITY EL; DASILVA APA, 2005, P POW ENG SOC GEN M, V3, P2653; De Tuglie E, 2000, IEEE T POWER SYST, V15, P1345, DOI 10.1109/59.898111; ELSHARKAWI MA, 1996, IEEE PES SPECIAL PUB; Feng ZH, 1998, IEEE T POWER SYST, V13, P1285, DOI 10.1109/59.736266; GAVOYIANNIS AE, 2005, P 15 PSCC LIEG BELG; GAVOYIANNIS AE, 2001, P INT C INT SYST APP; Jensen CA, 2001, IEEE T POWER SYST, V16, P757, DOI 10.1109/59.962423; Karapidakis ES, 2002, IEEE T POWER SYST, V17, P297, DOI 10.1109/TPWRS.2002.1007896; LOPES JP, 2000, P POW ENG SOC WINT M, V2, P1075; MORISON K, 2006, P POW ENG SOC GEN M; Moulin LS, 2001, ENG INTELL SYST ELEC, V9, P205; SOBAJIC DJ, 1989, IEEE T POWER SYST, V4, P220, DOI 10.1109/59.32481; TAO S, 1998, P INT C POW SYST TEC, V2, P1315; TAYLOR CW, 1992, IEEE T POWER DELIVER, V7, P480, DOI 10.1109/61.127040; TUAN T, 1994, IEEE T POWER SYST, V19, P341; Vesanto J, 2000, SOM TOOLBOX MATLAB 5; VOUMVOULAKIS EM, 2006, P POW ENG SOC GEN M; VOURNAS C, 2005, P IEEE SAINT PET POW; Wehenkel L., 1998, AUTOMATIC LEARNING T; *CIGRE, 2007, WG601 CIGRE; *CIGRE, 1997, TF380213 CIGRE	24	7	11	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0885-8950		IEEE T POWER SYST	IEEE Trans. Power Syst.	MAY	2008	23	2					622	630		10.1109/TPWRS.2008.920194		9	Engineering, Electrical & Electronic	Engineering	342DX	WOS:000258765900040	
J	Jin, YC; Sendhoff, B				Jin, Yaochu; Sendhoff, Bernhard			Pareto-based multiobjective machine learning: An overview and case studies	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART C-APPLICATIONS AND REVIEWS			English	Review						ensemble; evolutionary multiobjective optimization; generalization; machine learning; multiobjective learning; multiobjective optimization; neural networks; Pareto optimization	ARTIFICIAL NEURAL-NETWORKS; KNOWLEDGE EXTRACTION; OPTIMIZATION; ENSEMBLE; ALGORITHMS; GENERATION; CURVES; MODEL; CLASSIFIERS; OBJECTIVES	Machine learning is inherently a multiobjective task. Traditionally, however, either only one of the objectives is adopted as the cost function or multiple objectives are aggregated to a scalar cost function. This can be mainly attributed to the fact that most conventional learning algorithms can only deal with a scalar cost function. Over the last decade, efforts on solving machine learning problems using the Pareto-based multiobjective optimization methodology have gained increasing impetus, particularly due to the great success of multiobjective optimization using evolutionary algorithms and other population-based stochastic search methods. It has been shown that Pareto-based multiobjective learning approaches are more powerful compared to learning algorithms with a scalar cost function in addressing various topics of machine learning, such as clustering, feature selection, improvement of generalization ability, knowledge extraction, and ensemble generation. One common benefit of the different multiobjective learning approaches is that a deeper insight into the learning problem can be gained by analyzing the Pareto front composed of multiple Pareto-optimal solutions. This paper provides an overview of the existing research on multiobjective machine learning, focusing on supervised learning. In addition, a number of case studies are provided to illustrate the major benefits of the Pareto-based approach to machine learning, e.g., how to identify interpretable models and models that can generalize on unseen data from the obtained Pareto-optimal solutions. Three approaches to Pareto-based multiobjective ensemble generation are compared and discussed in detail. Finally, potentially interesting topics in multiobjective machine learning are suggested.	[Jin, Yaochu; Sendhoff, Bernhard] Honda Res Inst Europe, D-63073 Offenbach, Germany	Jin, YC (reprint author), Honda Res Inst Europe, D-63073 Offenbach, Germany.	yaochujin@honda-ri.de; bernhard.sendhoff@honda-ri.de	Jin, Yaochu/B-3776-2012				Abbass H. A., 2001, P 14 AUSTR JOINT C A, P1; Abbass HA, 2003, NEURAL COMPUT, V15, P2705, DOI 10.1162/089976603322385126; ABBASS HA, 2003, P IEEE C EV COMP, P2074; ADAMS R, 2006, P BRAIN INSP COGN SY, P153; Alpaydin E, 2004, INTRO MACHINE LEARNI; AMARI SI, 1993, NEURAL NETWORKS, V6, P161, DOI 10.1016/0893-6080(93)90013-M; BANFIELD JD, 1993, BIOMETRICS, V49, P803, DOI 10.2307/2532201; BERNADOMANSSILL.E, LECT NOTES COMPUTER, P696; BI J, 2003, P 20 INT C MACH LEAR, P35; Brown MT, 2005, GEOCHEM GEOPHY GEOSY, V6, DOI 10.1029/2004GC000893; Burnham K. P., 2002, MODEL SELECTION MULT; Chandra A, 2006, NEUROCOMPUTING, V69, P686, DOI 10.1016/j.neucom.2005.12.014; CHANDRA A, 2004, P 5 INT C INT DAT EN, P619; Cordon O., 2001, P JOINT 9 IFSA WORLD, V3, P1253, DOI 10.1109/NAFIPS.2001.943727; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Das I, 1997, STRUCT OPTIMIZATION, V14, P63, DOI 10.1007/BF01197559; DEANGULO VR, 1995, IEEE T NEURAL NETWOR, V6, P657, DOI 10.1109/72.377971; Deb K., 2000, P PAR PROBL SOLV NAT, VVI, P849; Deb K., 2001, MULTIOBJECTIVE OPTIM; EMMANOUILIDIS C, 1999, P ICANN 99 9 INT C A, P749; Everson RM, 2006, PATTERN RECOGN LETT, V27, P918, DOI 10.1016/j.patrec.2005.10.016; FAWCETT T, 2003, HPL20034 HP LABS; FIELDSEND J, 2002, P INT JOINT C NEUR N, V1, P388; Fieldsend JE, 2005, IEEE T NEURAL NETWOR, V16, P338, DOI [10.1109/TNN.2004.841794, 10.1109/TNN.2004.841797]; Fine TL, 1999, NEURAL COMPUT, V11, P747, DOI 10.1162/089976699300016647; Frean M, 1999, NETWORK-COMP NEURAL, V10, P227, DOI 10.1088/0954-898X/10/3/302; Furukawa T, 2001, INT J NUMER METH ENG, V52, P219, DOI 10.1002/nme.215; Garcia-Pedrajas N, 2002, NEURAL NETWORKS, V15, P1255; Garcia-Pedrajas N, 2003, IEEE T NEURAL NETWOR, V14, P575, DOI 10.1109/TNN.2003.810618; GIROSI F, 1995, NEURAL COMPUT, V7, P219, DOI 10.1162/neco.1995.7.2.219; GOMEZSKARLETA A, 1997, P 6 EUR C INT TECH S, P694; GRANING L, 2006, P INT JOINT C NEUR N, P9893; Handl J, 2005, LECT NOTES COMPUT SC, V3410, P547; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Hastie T, 2001, ELEMENTS STAT LEARNI; HATANAKA T, 2003, P 2003 C EV COMP, P1095; HATANAKA T, 2006, MULTI OBJECTIVE MACH, P491; Horn J, 1993, 93005 ILLIGAL U ILL; Igel C, 2003, NEUROCOMPUTING, V50, P105, DOI 10.1016/S0925-2312(01)00700-7; Igel C, 2005, LECT NOTES COMPUT SC, V3410, P534; Ishibuchi H, 2001, INFORM SCIENCES, V136, P109, DOI 10.1016/S0020-0255(01)00144-X; Ishibuchi H, 2003, LECT NOTES COMPUT SC, V2723, P1077; Ishibuchi H, 1997, FUZZY SET SYST, V89, P135, DOI 10.1016/S0165-0114(96)00098-X; JIMENEZ F, 2002, P IEEE INT C SYST MA, V3, P253; Jin Y., 2006, MULTIOBJECTIVE MACHI; JIN Y, 2004, P 2004 IEEE C EV COM, P1; Jin Y., 2001, P GEN EV COMP C GECC, P1042; Jin Y, 2003, ADV FUZZY SYSTEMS DE; JIN Y, 2006, P INT JOINT C NEUR N, P6367; JIN Y, 2004, APPL MULTIOBJECTIVE, P653; Jin YC, 1999, IEEE T SYST MAN CY B, V29, P829, DOI 10.1109/3477.809036; Jin YC, 2005, LECT NOTES COMPUT SC, V3410, P752; Jin YC, 2000, IEEE T FUZZY SYST, V8, P212, DOI 10.1109/91.842154; Jin YC, 2007, LECT NOTES COMPUT SC, V4668, P370; KAMRUZZAMAN S, 2005, T ENG COMPUT TECHNOL, V10, P271; Kim DE, 2004, LECT NOTES COMPUT SC, V3003, P338; Kim Y., 2002, INTELL DATA ANAL, V6, P531; Knowles JD, 2001, LECT NOTES COMPUT SC, V1993, P269; Kottathra K, 1996, J NETW COMPUT APPL, V19, P135, DOI 10.1006/jnca.1996.0011; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; Kupinski MA, 1999, IEEE T MED IMAGING, V18, P675, DOI 10.1109/42.796281; Law M. H. C., 2004, P IEEE COMP SOC C CO, V2, P424, DOI 10.1109/CVPR.2004.1315194; LIU GP, 1995, P 4 INT C ART NEUR N, P53; Liu Y, 1999, NEURAL NETWORKS, V12, P1399, DOI 10.1016/S0893-6080(99)00073-8; LOUIS SJ, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P118; LUQUE M, 2006, MULTIOBJECTIVE MACHI, P585; Maass W., 1999, PULSED NEURAL NETWOR; Markowska-Kaczmar U, 2004, LECT NOTES ARTIF INT, V3070, P450; Matsuyama Y, 1996, IEEE T NEURAL NETWOR, V7, P652, DOI 10.1109/72.501723; Mitchell T, 1997, MACHINE LEARNING; NAKAYAMA H, 2001, P ICOTA2001, V3, P1171; OLIVEIRA LS, 2003, P 7 ICDAR, P676; Olshausen B.A., 1997, VISION RES, V37, P3311; Opitz DW, 1996, ADV NEUR IN, V8, P535; PARK S, 1999, P IEEE INT C FUZZ SE, V1, P533; PRECHELT L, 1994, PROBENI SET NEURAL N; Riedmiller M., 1993, P INT C NEUR NETW, V1, P586; Rosen B. E., 1996, Connection Science, V8, DOI 10.1080/095400996116820; Setiono R, 2000, ARTIF INTELL MED, V18, P205, DOI 10.1016/S0933-3657(99)00041-X; Sporns O., 2001, COMPLEXITY, V7, P28, DOI DOI 10.1016/S0893-6080(00)00053-8; SUZUKI T, 1999, P IEEE INT C SYST MA, V5, P314; TACHIBANA K, 2001, INT J INTELL SYST, V17, P495; Teixeira RD, 2000, NEUROCOMPUTING, V35, P189, DOI 10.1016/S0925-2312(00)00327-1; Teo J, 2004, EVOL COMPUT, V12, P355, DOI 10.1162/1063656041774974; THRUN S, 1994, P ADV NEUR INF PROC, P505; Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293; Wan S, 2006, IEEE T NEURAL NETWOR, V17, P1424, DOI 10.1109/TNN.2006.880581; Wang HL, 2005, FUZZY SET SYST, V149, P149, DOI 10.1016/j.fss.2004.07.013; Wang HL, 2005, IEEE T SYST MAN CY C, V35, P143, DOI 10.1109/TSMCC.2004.841910; Wiegand S., 2004, International Journal of Computational Intelligence and Applications, V4, DOI 10.1142/S1469026804001288; Yao X, 1999, P IEEE, V87, P1423; YEN GG, 2002, P C EV COMP HON HI, V1, P25, DOI 10.1109/CEC.2002.1006204; Zhang Y., 2005, P C GEN EV COMP, P795, DOI 10.1145/1068009.1068143; ZOLTAN Z, 1998, P INT C MACH LEARN, P197	94	54	55	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1094-6977		IEEE T SYST MAN CY C	IEEE Trans. Syst. Man Cybern. Part C-Appl. Rev.	MAY	2008	38	3					397	415		10.1109/TSMCC.2008.919172		19	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications	Computer Science	293SL	WOS:000255354900010	
J	Wang, CZ; Wu, CX; Chen, DG				Wang, Changzhong; Wu, Congxin; Chen, Degang			A systematic study on attribute reduction with rough sets based on general binary relations	INFORMATION SCIENCES			English	Article						attribute reduction; discernibility matrix; rough sets based on general binary relations; relation information systems; relation decision systems	INCOMPLETE INFORMATION-SYSTEMS; KNOWLEDGE REDUCTION; FEATURE-SELECTION; MODEL; RULES	Attribute reduction is considered as an important preprocessing step for pattern recognition, machine learning, and data mining. This paper provides a systematic study on attribute reduction with rough sets based on general binary relations. We define a relation information system, a consistent relation decision system, and a relation decision system and their attribute reductions. Furthermore, we present a judgment theorem and a discernibility matrix associated with attribute reduction in each type of system; based on the discernibility matrix, we can compute all the reducts. Finally, the experimental results with UCI data sets show that the proposed reduction methods are an effective technique to deal with complex data sets. (c) 2008 Elsevier Inc. All rights reserved.	[Wang, Changzhong; Wu, Congxin] Harbin Inst Technol, Dept Math, Harbin 150001, Heilongjiang, Peoples R China; [Chen, Degang] N China Elect Power Univ, Dept Math & Phys, Beijing 102206, Peoples R China	Wang, CZ (reprint author), Harbin Inst Technol, Dept Math, Harbin 150001, Heilongjiang, Peoples R China.	changzhongwang@126.com; chengdedang@263.net					Bazan J, 1998, ROUGH SETS KNOWLEDGE, P321; Beynon M, 2001, EUR J OPER RES, V134, P592, DOI 10.1016/S0377-2217(00)00280-0; Bonikowski Z., 1994, ROUGH SETS FUZZY SET, P243; Bonikowski Z, 1998, INFORM SCIENCES, V107, P149, DOI 10.1016/S0020-0255(97)10046-9; Bryniaski E., 1989, B POL ACAD SCI, V36, P71; Cattaneo G., 1998, ROUGH SETS KNOWLEDGE, P59; Chen D. G., 2006, INFORM SCI, V176, P1829; Chen DG, 2007, INFORM SCIENCES, V177, P3500, DOI 10.1016/j.ins.2007.02.041; Chen DG, 2004, LECT NOTES ARTIF INT, V3066, P477; Dash M, 2003, ARTIF INTELL, V151, P155, DOI 10.1016/S0004-3702(03)00079-1; Greco S, 2002, EUR J OPER RES, V138, P247, DOI 10.1016/S0377-2217(01)00244-2; Greco S, 2001, EUR J OPER RES, V129, P1, DOI 10.1016/S0377-2217(00)00167-3; Hall M., 2000, P 17 INT C MACH LEAR, P359; HU Q, 2006, EXPERT SYSTEMS APPL; Hu QH, 2006, PATTERN RECOGN LETT, V27, P414, DOI 10.1016/patrec.2005.09.004; Hu QH, 2004, INT J UNCERTAIN FUZZ, V12, P575, DOI 10.1142/S0218488504003089; Hu QH, 2006, IEEE T FUZZY SYST, V14, P191, DOI 10.1109/TFUZZ.2005.864086; Kryszkiewicz M, 2001, INT J INTELL SYST, V16, P105, DOI 10.1002/1098-111X(200101)16:1<105::AID-INT8>3.0.CO;2-S; Kryszkiewicz M, 1998, INFORM SCIENCES, V112, P39, DOI 10.1016/S0020-0255(98)10019-1; Kryszkiewicz M, 1999, INFORM SCIENCES, V113, P271, DOI 10.1016/S0020-0255(98)10065-8; Mi JS, 2004, INFORM SCIENCES, V159, P255, DOI 10.1016/j.ins.2003.07.004; Mordeson JN, 2001, FUZZY SET SYST, V121, P315, DOI 10.1016/S0165-0114(00)00023-3; NEWMAN DJ, 1998, UCI REPOSITORY MACH; Nguyen HS, 1999, LECT NOTES ARTIF INT, V1711, P137; NGUYEN HS, 1985, LNCS, V4100, P334; Nguyen SH, 2000, STUD FUZZ SOFT COMP, V56, P289; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; PAWLAK Z, 2006, INFORM SCI, V177, P41; Pawlak Z, 1998, CYBERNET SYST, V29, P661, DOI 10.1080/019697298125470; PAWLAK Z, 2006, INFORM SCI, V177, P28; Pawlak Z., 1991, ROUGH SETS THEORETIC; Pawlak Z., 2006, INFORM SCI, V177, P3; Polkowski L., 1995, SOFT COMPUTING ROUGH, P55; Polkowski L., 1994, P RSSC 94 3 WORKSH R, P142; Pomykala J.A., 1987, B POLISH ACAD SCI MA, V9-10, P653; Quafafou M, 2000, INFORM SCIENCES, V124, P301, DOI 10.1016/S0020-0255(99)00075-4; Shen Q, 2004, PATTERN RECOGN, V37, P1351, DOI 10.1016/j.patcog.2003.10.016; Skowron A., 1996, Fundamenta Informaticae, V27; Skowron A., 1992, INTELLIGENT DECISION, P331; Slezak D., 1998, P IPMU 98 PAR FRANC, V2, P1362; Slezak D., 1996, P IPMU 96 GRAN SPAIN, V3, P1159; Slowinski R, 2000, IEEE T KNOWL DATA EN, V12, P331, DOI 10.1109/69.842271; Stefanowski J., 1998, ROUGH SETS KNOWLEDGE, V1, P500; Wu WZ, 2005, INFORM SCIENCES, V174, P143, DOI 10.1016/j.ins.2004.09.002; Wybraniec-Skardowska U., 1989, B POLISH ACAD SCI MA, V37, P51; Yao YY, 1998, INFORM SCIENCES, V109, P21, DOI 10.1016/S0020-0255(98)00012-7; Yao YY, 1998, INFORM SCIENCES, V111, P239, DOI 10.1016/S0020-0255(98)10006-3; Yeung DS, 2005, IEEE T FUZZY SYST, V13, P343, DOI 10.1109/TFUZZ.2004.841734; Yu Da-ren, 2004, Proceedings of the CSEE, V24; Yu L, 2004, J MACH LEARN RES, V5, P1205; Zakowski W., 1983, DEMONSTRATIO MATH, V16, P761; Zhang W.X., 2001, THEORY METHODS ROUGH; Zhu W., 2007, INFORM SCI, V177, P1892; Zhu W, 2003, INFORM SCIENCES, V152, P217, DOI 10.1016/S0020-0255(03)00056-2; ZIARKO W, 1993, J COMPUT SYST SCI, V46, P39, DOI 10.1016/0022-0000(93)90048-2	55	34	40	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255		INFORM SCIENCES	Inf. Sci.	MAY 1	2008	178	9					2237	2261		10.1016/j.ins.2008.01.007		25	Computer Science, Information Systems	Computer Science	289QJ	WOS:000255068700010	
J	Zhang, Z				Zhang, Zhu			Mining relational data from text: From strictly supervised to weakly supervised learning	INFORMATION SYSTEMS			English	Article						information extraction; relation classification; active learning; bootstrapping; support vector machines; random subspace method	KERNELS	This paper approaches the relation classification problem in information extraction framework with different machine learning strategies, from strictly supervised to weakly supervised. A number of learning algorithms are presented and empirically evaluated on a standard data set. We show that a supervised SVM classifier using various lexical and syntactic features can achieve competitive classification accuracy. Furthermore, a variety of weakly supervised learning algorithms can be applied to take advantage of large amount of unlabeled data when labeling is expensive. Newly introduced random-subspace-based algorithms demonstrate their empirical advantage over competitors in the context of both active learning and bootstrapping. (C) 2007 Elsevier B.V. All rights reserved.	Univ Arizona, Dept Management Informat Syst, Tucson, AZ 85721 USA	Zhang, Z (reprint author), Univ Arizona, Dept Management Informat Syst, Tucson, AZ 85721 USA.	zhuzhang@eller.arizona.edu					ABNEY S, 2002, P ACL 02  40 ANN M A; ABNEY S, 2004, COMPUT LINGUISTICS, V30; AGICHTEIN E, 2000, P 5 ACM INT C DIG LI; Argamon-Engelson S, 1999, J ARTIF INTELL RES, V11, P335; BALCAN MF, 2005, ADV NEURAL INFORM PR, V17, P489; BALDRIDGE J, 2003, P 7 C NAT LANG LEARN; Banko M., 2007, IJCAI, P2670; BANKO M, 2001, M ASS COMP LING, P26; Blum A., 1998, COLT; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; BRIN S, 1998, WEBDB WORKSH 6 INT C; Cancedda N, 2003, J MACH LEARN RES, V3, P1059, DOI 10.1162/153244303322533197; Charniak E., 1999, CS9912 BROWN U COMP; COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211; COLLINS M, 1999, EMNLPVLC 99; Cristianini N., 2000, INTRO SUPPORT VECTOR; Culotta A., 2004, ACL 2004, P423; Cunningham H., 2002, P 40 ANN M ASS COMP; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y, 1997, MACH LEARN, V28, P133, DOI 10.1023/A:1007330508534; Fujii A, 1998, COMPUT LINGUIST, V24, P573; Goldman S., 2000, P 17 INT C MACH LEAR, P327; Grishman R., 2005, P 43 ANN M ASS COMP, P419, DOI 10.3115/1219840.1219892; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Hwa R, 2000, PROCEEDINGS OF THE 2000 JOINT SIGDAT CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND VERY LARGE CORPORA, P45; Joachims T., 1998, P ECML 98 10 EUR C M, V1398, P137; Kudo T., 2001, P 2 M N AM CHAPT ASS, P192; Lewis D. D., 1994, P 17 ANN INT ACM SIG, P3; Lewis D, 1994, P 11 INT C MACH LEAR, P148; Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687; McDonald R., 2005, P 43 ACL ASS COMP LI, P491, DOI 10.3115/1219840.1219901; Muslea I., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); Ng V, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P173; NGAI G, 2000, P 38 ANN M ASS COMP, P117, DOI 10.3115/1075218.1075234; Rosario B, 2004, P 42 ANN M ASS COMP; SASSANO M, 2002, P ACL 02 40 ANN M AS; Sekine S., 2006, P COLING ACL MAIN C, P731, DOI 10.3115/1273073.1273167; Tang M., 2002, P 40 ANN M ASS COMP, P120; Thompson C.A., 1999, P 16 INT C MACH LEAR, P406; Tong S., 2002, J MACHINE LEARNING R, V2, P45, DOI 10.1162/153244302760185243; Vapnik V. N, 1995, NATURE STAT LEARNING; Yarowsky D, 1995, M ASS COMP LING, P189; Zelenko D, 2003, J MACH LEARN RES, V3, P1083, DOI 10.1162/153244303322533205; Zhou G., 2005, P 43 ANN M ASS COMP, P427; ZHU X, 1530 U WISC COMP SCI	46	4	4	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0306-4379		INFORM SYST	Inf. Syst.	MAY	2008	33	3					300	314		10.1016/j.is.2007.10.002		15	Computer Science, Information Systems	Computer Science	269AI	WOS:000253621500003	
J	Ren, XF; Fowlkes, CC; Malik, J				Ren, Xiaofeng; Fowlkes, Charless C.; Malik, Jitendra			Learning probabilistic models for contour completion in natural images	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						grouping; natural images; boundary detection; scale invariance; conditional random fields; machine learning	RANDOM-FIELDS; SCALE; SHAPE; RECOGNITION; PERFORMANCE; BOUNDARIES; ALGORITHM	Using a large set of human segmented natural images, we study the statistics of region boundaries. We observe several power law distributions which likely arise from both multi-scale structure within individual objects and from arbitrary viewing distance. Accordingly, we develop a scale-invariant representation of images from the bottom up, using a piecewise linear approximation of contours and constrained Delaunay triangulation to complete gaps. We model curvilinear grouping on top of this graphical/geometric structure using a conditional random field to capture the statistics of continuity and different junction types. Quantitative evaluations on several large datasets show that our contour grouping algorithm consistently dominates and significantly improves on local edge detection.	[Ren, Xiaofeng] Toyota Technol Inst Chicago, Chicago, IL 60637 USA; [Fowlkes, Charless C.] Univ Calif Irvine, Sch Informat & Comp Sci, Irvine, CA 92697 USA; [Malik, Jitendra] Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA	Ren, XF (reprint author), Toyota Technol Inst Chicago, 1427 E 60th St, Chicago, IL 60637 USA.	xren@tti-c.org; fowlkes@ics.uci.edu; malik@cs.berkeley.edu					ALVAREZ L, 1999, SCALE SPACE THEORIES; ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663; August J, 1999, COMPUT VIS IMAGE UND, V76, P146, DOI 10.1006/cviu.1998.0795; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BORENSTEIN E, 2002, P EUR C COMP VIS ECC, V2, P109; BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679; Donoho D. L., 2002, LECT NOTES COMPUT SC, V20, P149; Elder James H, 2002, J Vis, V2, P324, DOI 10.1167/2.4.5; ELDER JH, 1996, P 4 EUR C COMP VIS, V1, P399; FELZENSZWALB P, 2001, P IEEE C COMP VIS PA; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; Geisler WS, 2001, VISION RES, V41, P711, DOI 10.1016/S0042-6989(00)00277-7; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; He X., 2004, P IEEE C COMP VIS PA, V2, P695; Heitger F, 1993, P 4 INT C COMP VIS, P32; Huang J., 1999, P IEEE C COMP VIS PA, P541; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; HUTTENLOCHER DP, 1992, INT J COMPUT VISION, V8, P7, DOI 10.1007/BF00126398; Jermyn IH, 2001, IEEE T PATTERN ANAL, V23, P1075, DOI 10.1109/34.954599; Kanizsa G., 1979, ORG VISION ESSAYS GE; KELLMAN PJ, 1991, COGNITIVE PSYCHOL, V23, P141, DOI 10.1016/0010-0285(91)90009-D; Konishi S., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), DOI 10.1109/CVPR.1999.786996; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; Kumar S, 2006, INT J COMPUT VISION, V68, P179, DOI 10.1007/s11263-006-7007-9; LAFFERTY J, 2001, P 18 INIT C MACH LEA; Lee AB, 2001, INT J COMPUT VISION, V41, P35, DOI 10.1023/A:1011109015675; LEUTTGEN M, 1993, SPECIAL ISSUE IEEE T, V41, P3377; Li S.Z., 1995, MARKOV RANDOM FIELD; MARTIN D, 2002, BERKELEY SEGMENTATIO; Martin DR, 2003, PERCEPTION, V32, P55; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Mori G, 2004, P IEEE C COMP VIS PA, P326, DOI 10.1109/CVPR.2004.1315182; Mumford D., 1994, ALGEBRAIC GEOMETRY I, P491; Murphy KP, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P467; Palmer S., 1999, VISION SCI PHOTONS P; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; Pearl J., 1988, PROBABILISTIC REASON; Ren X., 2005, P 10 INT C COMP VIS, V1, P824; Ren X., 2007, P IEEE C COMP VIS PA; Ruderman DL, 1997, VISION RES, V37, P3385, DOI 10.1016/S0042-6989(97)00008-4; RUDERMAN DL, 1994, PHYS REV LETT, V73, P814, DOI 10.1103/PhysRevLett.73.814; Sharon E, 2000, IEEE T PATTERN ANAL, V22, P1117, DOI 10.1109/34.879792; Shashua A., 1988, P INT C COMP VIS, P321; Shental N., 2003, Proceedings Ninth IEEE International Conference on Computer Vision; Shewchuk J.R., 1996, 1 WORKSH APPL COMP G, P124; SUN J, 2002, P EUR C COMP VIS, P510; Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x; VONDERHEYDT R, 1984, SCIENCE, V224, P1260, DOI 10.1126/science.6539501; Weiss Y, 1997, ADV NEUR IN, V9, P908; WEISS Y, 2000, NEURAL COMPUT, P1; Wertheimer Max, 1938, SOURCE BOOK GESTALT, P71, DOI 10.1037/11496-005; Williams LR, 2001, NEURAL COMPUT, V13, P1683, DOI 10.1162/08997660152469305; Williams LR, 1997, NEURAL COMPUT, V9, P837, DOI 10.1162/neco.1997.9.4.837; Williams LR, 1999, INT J COMPUT VISION, V34, P81, DOI 10.1023/A:1008187804026; Wu Q., 2003, P DICTA, P957; YU S, 2002, ADV NEURAL INFORM PR, V16; ZHU S. C, 1998, INT J COMPUT VISION, V27, P1; Zhu SC, 1999, IEEE T PATTERN ANAL, V21, P1170	60	22	24	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2008	77	1-3					47	63		10.1007/s11263-007-0092-6		17	Computer Science, Artificial Intelligence	Computer Science	267RE	WOS:000253526100004	
J	Fink, M; Ullman, S				Fink, Michael; Ullman, Shimon			From Aardvark to Zorro: A benchmark for mammal image classification	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						database; dataset; benchmark; mammals; svm; multiclass; annotation; natural images; animals; machine learning; object recognition	VECTOR MACHINES; FEATURES	Current object recognition systems aim at recognizing numerous object classes under limited supervision conditions. This paper provides a benchmark for evaluating progress on this fundamental task. Several methods have recently proposed to utilize the commonalities between object classes in order to improve generalization accuracy. Such methods can be termed interclass transfer techniques. However, it is currently difficult to asses which of the proposed methods maximally utilizes the shared structure of related classes. In order to facilitate the development, as well as the assessment of methods for dealing with multiple related classes, a new dataset including images of several hundred mammal classes, is provided, together with preliminary results of its use. The images in this dataset are organized into five levels of variability, and their labels include information on the objects' identity, location and pose. From this dataset, a classification benchmark has been derived, requiring fine distinctions between 72 mammal classes. It is then demonstrated that a recognition method which is highly successful on the Caltech101, attains limited accuracy on the current benchmark (36.5%). Since this method does not utilize the shared structure between classes, the question remains as to whether interclass transfer methods can increase the accuracy to the level of human performance (90%). We suggest that a labeled benchmark of the type provided, containing a large number of related classes is crucial for the development and evaluation of classification methods which make efficient use of interclass transfer.	[Fink, Michael] Hebrew Univ Jerusalem, Interdisciplinary Ctr Neural Computat, IL-91904 Jerusalem, Israel; [Ullman, Shimon] Weizmann Inst Sci, Fac Math & Comp Sci, IL-76100 Rehovot, Israel	Fink, M (reprint author), Hebrew Univ Jerusalem, Interdisciplinary Ctr Neural Computat, IL-91904 Jerusalem, Israel.	fink@huji.ac.il					BELONGIE S, 2001, ICCV; BENDAVID S, 2003, COLT; Berg T., 2006, CVPR; Changizi MA, 2005, P ROY SOC B-BIOL SCI, V272, P267, DOI 10.1098/rspb.2004.2942; Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628; Fei-Fei L., 2002, P NATL ACAD SCI USA, V99, P9596; FEIFEI L, 2004, CVPR WORKSH GEN BAS; Fink M., 2004, NIPS, P1; FINK M, 2007, COGNITIVE SCI; FINK M, 2006, ICML; Grauman K., 2005, CVPR; Grauman K., 2005, ICCV; KREMPP S, 2002, SEQUENTIAL LEARNING; LAZEBNIK S, 2003, ICCV; LEVI K, 2004, LCVPR04 WORKSH LEARN; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Miller E., 2000, CVPR; Ponce J., 2006, CATEGORY LEVEL OBJEC; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Schiele B, 2000, INT J COMPUT VISION, V36, P31, DOI 10.1023/A:1008120406972; Schneiderman H., 2000, CVPR; Scholkopf B., 2002, LEARNING KERNELS SUP; Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0; Thrun S., 1997, LEARNING LEARN; Torralba A., 2004, CVPR; Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4	28	4	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2008	77	1-3					143	156		10.1007/s11263-007-0066-8		14	Computer Science, Artificial Intelligence	Computer Science	267RE	WOS:000253526100009	
J	Holub, AD; Welling, M; Perona, P				Holub, Alex D.; Welling, Max; Perona, Pietro			Hybrid generative-discriminative visual categorization	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						machine learning; object recognition; discriminative learning; support vector machines	FEATURES; MODELS; SCALE	Learning models for detecting and classifying object categories is a challenging problem in machine vision. While discriminative approaches to learning and classification have, in principle, superior performance, generative approaches provide many useful features, one of which is the ability to naturally establish explicit correspondence between model components and scene features this, in turn, allows for the handling of missing data and unsupervised learning in clutter. We explore a hybrid generative/discriminative approach, using 'Fisher Kernels' (Jaakola, T., et al. in Advances in neural information processing systems, Vol. 11, pp. 487-493, 1999), which retains most of the desirable properties of generative methods, while increasing the classification performance through a discriminative setting. Our experiments, conducted on a number of popular benchmarks, show strong performance improvements over the corresponding generative approach. In addition, we demonstrate how this hybrid learning paradigm can be extended to address several outstanding challenges within computer vision including how to combine multiple object models and learning with unlabeled data.	[Holub, Alex D.; Perona, Pietro] CALTECH, Pasadena, CA 91125 USA; [Welling, Max] Univ Calif Irvine, Dept Comp Sci, Irvine, CA 92697 USA	Holub, AD (reprint author), CALTECH, MC 136-93, Pasadena, CA 91125 USA.	holub@vision.caltech.edu; welling@ics.uci.edu					BURL MC, 1996, CVPR, P223; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; CROWLEY JL, 1984, PATTERN RECOGNITION; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Dorko G., 2005, RR5497 INRIA; Fei-Fei L., 2004, COMPUTER VISION PATT; Fergus R., 2003, CVPR, V2, DOI DOI 10.1109/CVPR.2003.1211479; FERGUS R, 2005, THESIS U OXFORD DEP; GOLD C, 2005, NEURAL NETWORKS; HOLUB A, 2005, COMPUTER VISION PATT; HOLUB A, 2005, INT C COMP VIS ICCV; Jaakkola T, 1999, P 7 INT WORKSH ART I; Jaakkola TS, 1999, ADV NEUR IN, V11, P487; Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855; LEIBE B, 2004, DAGM, P145; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; NG A, 2002, ADV NEURAL INFORM PR, V12; OPELT A, 2004, ECCV, P71; Opper M, 2000, ADV NEUR IN, P311; SCHNEIDERMAN H, 2004, CVPR, P639; Schoelkopf B., 2002, LEARNING KERNELS; Seeger M, 2002, ADV NEUR IN, V14, P905; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Torralba A., 2004, COMPUTER VISION PATT; TSUDA K, 2003, ASYMPTOTIC PROPERTIE; Ullman S, 2002, NAT NEUROSCI, V5, P682, DOI 10.1038/nn870; Vapnik VN, 1998, STAT LEARNING THEORY; VASCONCELOS N, 2004, ECCV, P430; Wallraven C., 2003, ICCV, P257; WEBER M, 2000, CVPR, P2101	30	13	14	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2008	77	1-3					239	258		10.1007/s11263-007-0084-6		20	Computer Science, Artificial Intelligence	Computer Science	267RE	WOS:000253526100014	
J	Bailenson, JN; Pontikakis, ED; Mauss, IB; Gross, JJ; Jabon, ME; Hutcherson, CAC; Nass, C; John, O				Bailenson, Jeremy N.; Pontikakis, Emmanuel D.; Mauss, Iris B.; Gross, James J.; Jabon, Maria E.; Hutcherson, Cendri A. C.; Nass, Clifford; John, Oliver			Real-time classification of evoked emotions using facial feature tracking and physiological responses	INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES			English	Article						affective computing; facial tracking; emotion; computer vision	EXPRESSION RECOGNITION; COHERENCE; DYNAMICS	We present automated, real-time models built with machine learning algorithms which use videotapes of subjects' faces in conjunction with physiological measurements to predict rated emotion (trained coders' second-by-second assessments of sadness or amusement). Input consisted of videotapes of 41 subjects watching emotionally evocative films along with measures of their cardiovascular activity, somatic activity, and electrodermal responding. We built algorithms based on extracted points from the subjects' faces as well as their physiological responses. Strengths of the current approach are (1) we are assessing real behavior of subjects watching emotional videos instead of actors making facial poses, (2) the training data allow us to predict both emotion type (amusement versus sadness) as well as the intensity level of each emotion, (3) we provide a direct comparison between person-specific, gender-specific, and general models. Results demonstrated good fits for the models overall, with better performance for emotion categories than for emotion intensity, for amusement ratings than sadness ratings, for a full model using both physiological measures and facial tracking than for either cue alone, and for person-specific models than for gender-specific or general models. (c) 2007 Elsevier Ltd. All rights reserved.	[Bailenson, Jeremy N.; Nass, Clifford] Stanford Univ, Dept Commun, Stanford, CA 94305 USA; [Pontikakis, Emmanuel D.] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA; [Mauss, Iris B.] Univ Denver, Dept Psychol, Denver, CO 80208 USA; [Gross, James J.; Hutcherson, Cendri A. C.] Stanford Univ, Dept Psychol, Stanford, CA 94305 USA; [Jabon, Maria E.] Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA; [John, Oliver] Univ Calif Berkeley, Dept Psychol, Berkeley, CA 94720 USA	Bailenson, JN (reprint author), Stanford Univ, Dept Commun, Stanford, CA 94305 USA.	bailenson@stanford.edu; manos@cs.stanford.edu; imauss@psy.du.edu; james@psych.stanford.edu; mjabon@stanford.edu; hutcherson@psych.stanford.edu; nass@stanford.edu; oliver.john@berkeley.edu					Bailenson JN, 2006, PRESENCE-TELEOP VIRT, V15, P359, DOI 10.1162/pres.15.4.359; BARTLETT M, 2005, IEEE CVPR 2005; Bonanno G, 2004, COGNITION EMOTION, V18, P431, DOI 10.1080/02699930341000149; Bradley M., 2000, HDB PSYCHOPHYSIOLOGY; Curhan JR, 2007, J APPL PSYCHOL, V92, P802, DOI 10.1037/0021-9010.92.3.802; DENG Z, 2006, P 6 INT C INT VIRT A; Ehrlich S. M., 2000, CHI 2000, P251; EKMAN P, 1990, J PERS SOC PSYCHOL, V58, P342, DOI 10.1037/0022-3514.58.2.342; Ekman P., 1978, FACIAL ACTION CODING; el Kaliouby R, 2005, Real-Time Vision for Human-Computer Interaction, P181; ELKALIOUBY R, 2003, P HCI INT CRET JUN 2, V2, P631; Essa IA, 1997, IEEE T PATTERN ANAL, V19, P757, DOI 10.1109/34.598232; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Gross J. J., 2007, HDB EMOTION REGULATI, P3; GROSS JJ, 1995, COGNITION EMOTION, V9, P87, DOI 10.1080/02699939508408966; Hall J. A., 1984, NONVERBAL SEX DIFFER; Kimura S, 1997, PROC CVPR IEEE, P295, DOI 10.1109/CVPR.1997.609338; Kring A.M., 2000, GENDER EMOTION SOCIA, P211, DOI 10.1017/CBO9780511628191.011; LI SZ, 2005, HDB FACE RECOGNITION, pCH11; Lien JJJ, 1998, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.1998.698704; LYONS MJ, 2006, CHI 06, P1671, DOI 10.1145/1125451.1125759; LYONS MJ, 2004, IEEE INT C SYST MAN, V1, P598; MAUSS IB, 2006, PERSONALITY SOCIAL P, V32, P389; Mauss IB, 2005, EMOTION, V5, P175, DOI 10.1037/1528-3542.5.2.175; Michel P., 2003, P 5 INT C MULT INT, P258; NASS C, 2005, WIRED SPEECH VOICE A; Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075; PHILIPPOT P, 1993, COGNITION EMOTION, V7, P171, DOI 10.1080/02699939308409183; Picard R. W., 1997, AFFECTIVE COMPUTING; PICARD RW, 2005, CHI WORKSH EV AFF IN; ROSENBERG EL, 2000, ENCY PSYCHOL, V3, P171; Sayette MA, 2001, J NONVERBAL BEHAV, V25, P167, DOI 10.1023/A:1010671109788; SCHIANO DJ, 2004, C HUM FACT COMP SYST, P49; SEBE N, 2002, P ICPR, V1, P17; TIAN Y, 2000, P INT C MULT US INT, P143; Timmers M, 1998, PERS SOC PSYCHOL B, V24, P974, DOI 10.1177/0146167298249005; WATSON D, 1985, PSYCHOL BULL, V98, P219, DOI 10.1037/0033-2909.98.2.219; Witten H. I., 2005, DATA MINING PRACTICA; Zhang Z., 1998, 3 IEEE INT C AUT FAC, P454; ZLOCHOWER A, INT C INF STUD	41	27	27	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	1071-5819		INT J HUM-COMPUT ST	Int. J. Hum.-Comput. Stud.	MAY	2008	66	5					303	317		10.1016/j.ijhcs.2007.10.011		15	Computer Science, Cybernetics; Ergonomics; Psychology, Multidisciplinary	Computer Science; Engineering; Psychology	298ON	WOS:000255697100001	
J	Kasabov, N				Kasabov, Nikola			Adaptive modeling and discovery in bioinformatics: The evolving connectionist approach	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS			English	Article							FUZZY INFERENCE SYSTEM; GENE-EXPRESSION DATA; PREDICTION; SIMULATION; PROFILES; SUPPORT; CANCER; TUMOR	Most biological processes that are currently being researched in bioinformatics are complex, dynamic processes that are difficult to model and understand. The paper presents evolving connectionist systems (ECOS) as a general approach to adaptive modeling and knowledge discovery in bioinformatics. This approach extends the traditional machine learning approaches with various adaptive learning and rule extraction procedures. ECOS belong to the class of incremental local learning and knowledge-based neural networks. They are applied here to challenging problems in Bioinformatics, such as: microarray gene expression profiling, gene regulatory network (GRN) modeling, computational neurogenetic modeling. The ECOS models have several advantages when compared to the traditional techniques: fast learning, incremental adaptation to new data, facilitating knowledge discovery through fuzzy rules. (c) 2008 Wiley Periodicals, Inc.	Auckland Univ Technol, Knowledge Engn & Discovery Res Inst, Auckland 1020, New Zealand	Kasabov, N (reprint author), Auckland Univ Technol, Knowledge Engn & Discovery Res Inst, Private Bag 92006, Auckland 1020, New Zealand.	nkasabov@aut.ac.nz					Adorjan P, 2002, NUCLEIC ACIDS RES, V30, DOI 10.1093/nar/30.5.e21; ANDERSON KM, 1991, AM HEART J, V121, P293, DOI 10.1016/0002-8703(91)90861-B; Arbib M, 2003, HDB BRAIN THEORY NEU; Attwood T., 1999, INTRO BIOINFORMATICS; Azuaje F, 2001, IEEE T BIO-MED ENG, V48, P332, DOI 10.1109/10.914796; Bajic VB, 2003, J MOL GRAPH MODEL, V21, P323, DOI 10.1016/S1093-3263(02)00179-1; BALDI P, 2001, BIOINFORMATICS MACHI, P351; BALDI P, 2000, DNA MICROARRAYS GENE, P213; Benuskova L., 2007, COMPUTATIONAL NEUROG; Benuskova L, 2007, NEUROCOMPUTING, V70, P2035, DOI 10.1016/j.neucom.2006.10.133; Bower JM, 2001, COMPUTATIONAL MODELL; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Chan ZSH, 2006, EXPERT SYST APPL, V30, P59, DOI 10.1016/j.eswa.2005.09.048; Clote P., 2000, COMPUTATIONAL MOL BI; De Jong H, 2002, J COMPUT BIOL, V9, P67, DOI 10.1089/10665270252833208; DOW J, 1995, BIOCH MOL CELLS BODY, P592; Gibson Michael Andrew, 2001, P3; Jang R., 1993, IEEE T SYST MAN CYB, V23, P665, DOI DOI 10.1109/21.256541; Kasabov N, 2006, APPL SOFT COMPUT, V6, P307, DOI 10.1016/j.asoc.2005.01.006; KASABOV N, 2003, METHOD MED DECISION; Kasabov N, 2007, PATTERN RECOGN LETT, V28, P673, DOI 10.1016/j.patrec.2006.08.007; Kasabov N., 2007, EVOLVING CONNECTIONI; Kasabov N, 2004, J COMPUT THEOR NANOS, V1, P47, DOI 10.1166/jctn.2004.006; Kasabov N, 2007, CYBERNET SYST, V38, P495, DOI 10.1080/01969720701344277; KASABOV N, 2004, DRUG DISCOV TODAY, V2, P253, DOI 10.1016/S1741-8364(04)02427-8; KASABOV NK, 2002, PERSPECTIVES NEURAL; Kasabov N.K., 1996, FDN NEURAL NETWORKS; Kasabov NK, 2002, IEEE T FUZZY SYST, V10, P144, DOI 10.1109/91.995117; KASAI Y, 2001, ENVIRON MICROBIOL, V3, P1; KASSABOV N, 2002, ICONIP 2002; KOHN KW, 1999, COMPUTER MODELING SI; Lee KE, 2003, BIOINFORMATICS, V19, P90, DOI 10.1093/bioinformatics/19.1.90; Levey AS, 1999, ANN INTERN MED, V130, P461; Lukashin AV, 2001, BIOINFORMATICS, V17, P405, DOI 10.1093/bioinformatics/17.5.405; Mitchell M., 1997, MACHINE LEARNING; OZAWA S, 2005, NEURAL NETWORKS  AUG, P575; Pang S, 2005, IEEE T SYST MAN CY B, V35, P905, DOI 10.1109/TSMCB.2005.847744; Ramsey F. L., 2002, STAT SLEUTH COURSE M; REGGIA JA, 1999, DISORDERS BRAIN BEHA; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; SOBRAL B, 1999, JAY LUSH GENOMICS VI; Song Q, 2006, NEURAL NETWORKS, V19, P1591, DOI 10.1016/j.neunet.2006.05.028; TOWELL GG, 1994, ARTIF INTELL, V70, P119, DOI 10.1016/0004-3702(94)90105-8; Vapnik V., 1998, STAT LEARNING THEORY, P736; Vasselli JR, 2003, P NATL ACAD SCI USA, V100, P6958, DOI 10.1073/pnas.11317454100; Veer LJ, 2002, NATURE, V415, P530, DOI DOI 10.1038/415530A; Venter JC, 2001, SCIENCE, V291, P1304, DOI 10.1126/science.1058040; Vohradsky J, 2001, FASEB J, V15, P846, DOI 10.1096/fj.00-0361com; YAMAKAWA T, 1993, P 5 IFSA WORLD C, P1017	49	1	1	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	0884-8173		INT J INTELL SYST	Int. J. Intell. Syst.	MAY	2008	23	5					545	555		10.1002/int.20282		11	Computer Science, Artificial Intelligence	Computer Science	287SV	WOS:000254937700003	
J	Mohammadi, M; Gharehpetian, GB				Mohammadi, M.; Gharehpetian, G. B.			Application of Multi-Class Support Vector Machines for Power System On-Line Static Security Assessment	INTERNATIONAL REVIEW OF ELECTRICAL ENGINEERING-IREE			English	Article						Machine learning; Multi-Class Support Vector Machines (SVM); Feature Selection; Power System Security	NEURAL-NETWORKS; SELECTION	This paper presents a multi-class Support Vector Machine (SVM) based method for on-line static security assessment of power systems. To classify the system security status, a group of binary SVMs have been trained One of the main points, to apply machine learning method is feature selection. In this paper, a new Decision Tree (DT) based feature selection algorithm has been presented The SVM decision boundary is determined by a small subset of training data, called Support Vectors (SVs). Therefore, it is desirable, to select only SVs, to reduce the problem size and consequently to reduce the training time. Data for SVM training has been selected based on a new modified algorithm. The proposed method has been applied to New England 39-bus power system. The simulation results demonstrate the effectiveness and the stability of the proposed method for on-line static security assessment procedure of large scale power System. Also, the effectiveness of the proposed feature selection and the data selection algorithms have been investigated, too. It has been shown that the proposed algorithms can reduce the SVM training set size and maintain the generalization performance of the resulting multi-class SVM. Copyright (C) 2008 Praise Worthy Prize S.r.l. - All rights reserved.	[Mohammadi, M.; Gharehpetian, G. B.] Amir Kabir Univ Technol, Tehran, Iran	Mohammadi, M (reprint author), Amir Kabir Univ Technol, Tehran, Iran.						ACKER VV, 2000, INT J ENG INTELLIGEN, V8, P161; Breiman L, 1984, CLASSIFICATION REGRE; EJEBE GC, 1979, IEEE T POWER AP SYST, V98, P97, DOI 10.1109/TPAS.1979.319518; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; HATZIARGYRIOU ND, 1994, IEEE T POWER SYST, V9, P1052, DOI 10.1109/59.317626; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Jensen CA, 2001, IEEE T POWER SYST, V16, P757, DOI 10.1109/59.962423; Kim H, 2005, ELECTR POW SYST RES, V74, P157, DOI 10.1016/j.epsr.2004.10.004; KreBel U.H.G., 1999, ADV KERNEL METHODS S, P255; LEI HS, 2005, P MULT CLASS SYST 20, P156; Lucarella D, 2005, ENG INTELL SYST ELEC, V13, P69; MARKS RJ, 2001, INT J ENG INTELLIGEN, V9, P205; Moulin LS, 2004, IEEE T POWER SYST, V19, P818, DOI 10.1109/TPWRS.2004.826018; NEIBUR D, 1992, IEEE T POWER SYSTEMS, V7, P865; Platt JR, 1998, IEEE AERO EL SYS MAG, V13, P26, DOI 10.1109/62.656331; Platt J. C., 1999, P NEURAL INFORM PROC, V12, P547; Scholkopf B, 1998, IEEE INTELL SYST APP, V13, P18; Vapnik V., 1982, ESTIMATION DEPENDENC; Vapnik VN, 1998, STAT LEARNING THEORY; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Wang JG, 2007, STUD COMP INTELL, V35, P61; Yang JH, 1998, IEEE INTELL SYST APP, V13, P44, DOI 10.1109/5254.671091; Zhena S. F., 2003, P IEEE INT C AC SPEE, V2, P821; ZHOU Q, 1994, IEEE T POWER SYST, V9, P525	24	1	1	PRAISE WORTHY PRIZE SRL	NAPOLI	PIAZZA G D ANNUNZIO, NAPOLI, 15-I80125, ITALY	1827-6660		INT REV ELECTR ENG-I	Int. Rev. Electr. Eng.-IREE	MAY-JUN	2008	3	3					532	542				11	Engineering, Electrical & Electronic	Engineering	424ZV	WOS:000264607700013	
J	Du, CJ; Sun, DW				Du, Cheng-Jin; Sun, Da-Wen			Multi-classification of pizza using computer vision and support vector machine	JOURNAL OF FOOD ENGINEERING			English	Article						classification; colour; computer vision; image processing; principal component analysis; pizza base; pizza sauce spread; pizza topping; shape; support vector machine	SAUCE SPREAD; BASE	The classification of pizza base, sauce spread and topping is highly sensitive to human error for its subjective and inconsistent nature. Image processing techniques combined with machine learning provide an objective and consistent way to accomplish this task. By using a combination of several binary classifiers, support vector machine (SVM) is a state-of-the-art learning algorithm for multi-classification of pizza base, sauce spread, and topping. With the selected features as input, the one-versus-one and directed acyclic graph (DAG) methods achieved 89.17% and 88.33% multi-classification accuracy respectively for pizza base, both 87.5% for pizza sauce spread, and 80.83% and 80.00%, respectively for pizza topping. The results showed that the computer vision systems developed had a great potential to assist in the automatic multi-classification of pizza base, sauce spread, and topping. (C) 2007 Elsevier Ltd. All rights reserved.	[Du, Cheng-Jin; Sun, Da-Wen] Natl Univ Ireland Univ Coll Dublin, Biosyst Engn, FRCFT Grp, Dublin 2, Ireland	Sun, DW (reprint author), Natl Univ Ireland Univ Coll Dublin, Biosyst Engn, FRCFT Grp, Eastfort Terrace, Dublin 2, Ireland.	dawen.sun@ucd.ie	Sun, Da-Wen/B-1899-2012				Anon, 2000, SAS INSIGHT USERS GU; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679; Crammer K, 2001, J MACHINE LEARNING R, V2, P265; Du CJ, 2004, J FOOD ENG, V64, P489, DOI 10.1016/j.jfoodeng.2003.11.016; Du CJ, 2005, J FOOD ENG, V66, P137, DOI 10.1016/j.jfoodeng.2004.03.011; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Hsu CW, 2002, MACH LEARN, V46, P291, DOI 10.1023/A:1012427100071; Kressel UHG, 1999, ADVANCES IN KERNEL METHODS, P255; Luo X, 1999, T ASAE, V42, P413; Paliwal J, 2001, J AGR ENG RES, V79, P361, DOI 10.1006/jaer.2001.0724; Platt JC, 2000, ADV NEUR IN, V12, P547; Shahin MA, 1999, T ASAE, V42, P1889; Sun DW, 2003, J FOOD ENG, V57, P81, DOI 10.1016/S0260-8774(02)00275-3; Sun DW, 2000, J FOOD ENG, V44, P245, DOI 10.1016/S0260-8774(00)00024-8; Sun DW, 2003, J FOOD ENG, V57, P91, DOI 10.1016/S0260-8774(02)00276-5; Vapnik VN, 1998, STAT LEARNING THEORY; *MATHWORKS INC, 1998, MATL REF GUID	17	7	9	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0260-8774		J FOOD ENG	J. Food Eng.	MAY	2008	86	2					234	242		10.1016/j.jfoodeng.2007.10.001		9	Engineering, Chemical; Food Science & Technology	Engineering; Food Science & Technology	260MC	WOS:000253013400011	
J	Trott, O; Siggers, K; Rost, B; Palmer, AG				Trott, Oleg; Siggers, Ken; Rost, Burkhard; Palmer, Arthur G., III			Protein conformational flexibility prediction using machine learning	JOURNAL OF MAGNETIC RESONANCE			English	Article						fibronectin; FREAC-11; generalized order parameter; NMR; neural network; relaxation; tenascin	SIDE-CHAIN DYNAMICS; BACKBONE ORDER PARAMETERS; COLI RIBONUCLEASE HI; MOLECULAR-DYNAMICS; NMR RELAXATION; STAPHYLOCOCCAL NUCLEASE; SECONDARY STRUCTURE; GLOBULAR-PROTEINS; N-15; MOTIONS	Using a data set of 16 proteins, a neural network has been trained to predict backbone N-15 generalized order parameters from the three-dimensional structures of proteins. The final network parameterization contains six input features. The average prediction accuracy, as measured by the Pearson's correlation coefficient between experimental and predicted values of the square of the generalized order parameter is > 0.70. Predicted order parameters for non-terminal amino acid residues depends most strongly on the local packing density and the probability that the residue is located in regular secondary structure. (C) 2008 Elsevier Inc. All rights reserved.	[Trott, Oleg; Siggers, Ken; Rost, Burkhard; Palmer, Arthur G., III] Columbia Univ Coll Phys & Surg, Dept Biochem & Mol Biophys, New York, NY 10032 USA	Palmer, AG (reprint author), Columbia Univ Coll Phys & Surg, Dept Biochem & Mol Biophys, Box 36,630 W 168th St, New York, NY 10032 USA.	agp6@columbia.edu					Abergel D, 2005, J CHEM PHYS, V123, DOI 10.1063/1.2110028; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Carlson HA, 2002, CURR OPIN CHEM BIOL, V6, P447, DOI 10.1016/S1367-5931(02)00341-1; Chatfield DC, 1998, J AM CHEM SOC, V120, P5301, DOI 10.1021/ja972215n; Doruker P, 2000, PROTEINS, V40, P512, DOI 10.1002/1097-0134(20000815)40:3<512::AID-PROT180>3.0.CO;2-M; FARROW NA, 1994, BIOCHEMISTRY-US, V33, P5984, DOI 10.1021/bi00185a040; FRAUENFELDER H, 1991, SCIENCE, V254, P1598, DOI 10.1126/science.1749933; Goodman JL, 2000, J MOL BIOL, V295, P963, DOI 10.1006/jmbi.1999.3419; Grey MJ, 2006, J MOL BIOL, V355, P1078, DOI 10.1016/j.jmb.2005.11.001; HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697; Hall JB, 2006, J AM CHEM SOC, V128, P7855, DOI 10.1021/ja060406x; Halle B, 2002, P NATL ACAD SCI USA, V99, P1274, DOI 10.1073/pnas.032522499; Hykin S., 1999, NEURAL NETWORKS COMP; Jacobs DJ, 2001, PROTEINS, V44, P150, DOI 10.1002/prot.1081; KABSCH W, 1983, FEBS LETT, V155, P179, DOI 10.1016/0014-5793(82)80597-8; Karplus M, 2002, ACCOUNTS CHEM RES, V35, P321, DOI 10.1021/ar020082r; KAY LE, 1989, BIOCHEMISTRY-US, V28, P8972, DOI 10.1021/bi00449a003; Kroenke CD, 1999, J AM CHEM SOC, V121, P10119, DOI 10.1021/ja9909273; Levenberg K., 1944, Quarterly of Applied Mathematics, V2; Li Q, 2003, BIOCHEMISTRY-US, V42, P4648, DOI 10.1021/bi0274120; LIPARI G, 1982, J AM CHEM SOC, V104, P4546, DOI 10.1021/ja00381a009; MANDEL AM, 1995, J MOL BIOL, V246, P144, DOI 10.1006/jmbi.1994.0073; Mandel AM, 1996, BIOCHEMISTRY-US, V35, P16009, DOI 10.1021/bi962089k; Millet O, 2002, J AM CHEM SOC, V124, P6439, DOI 10.1021/ja012497y; MING D, 2004, J BIOMOL NMR, V29, DOI UNSP 363368; Ming DM, 2006, BIOPHYS J, V90, P3382, DOI 10.1529/biophysj.105.071902; Mittermaier A, 2003, J AM CHEM SOC, V125, P9004, DOI 10.1021/ja034856q; Moncrieffe MC, 2000, J MOL BIOL, V297, P147, DOI 10.1006/jmbi.2000.3549; MUHANDIRAM DR, 1995, J AM CHEM SOC, V117, P11536, DOI 10.1021/ja00151a018; Nodet G, 2007, EUR BIOPHYS J BIOPHY, V36, P985, DOI 10.1007/s00249-007-0167-x; Palmer AG, 2001, METHOD ENZYMOL, V339, P204; Palmer AG, 2001, ANNU REV BIOPH BIOM, V30, P129, DOI 10.1146/annurev.biophys.30.1.129; PALMER AG, 1993, J AM CHEM SOC, V115, P6333, DOI 10.1021/ja00067a057; Philippopoulos M, 1997, PROTEINS, V28, P481, DOI 10.1002/(SICI)1097-0134(199708)28:4<481::AID-PROT3>3.0.CO;2-D; POWERS R, 1993, J MAGN RESON SER B, V101, P325, DOI 10.1006/jmrb.1993.1051; Anderson CAF, 2002, STRUCTURE, V10, P175, DOI 10.1016/S0969-2126(02)00700-1; Schlessinger A, 2005, PROTEINS, V61, P115, DOI 10.1002/prot.20587; SEAVEY B R, 1991, Journal of Biomolecular NMR, V1, P217, DOI 10.1007/BF01875516; Siggers K, 2007, BIOPHYS J, V93, P2447, DOI 10.1529/biophysj.106.100578; van Dongen MJP, 2000, J MOL BIOL, V296, P351, DOI 10.1006/jmbi.1999.3476; YAMASAKI K, 1995, BIOCHEMISTRY-US, V34, P6587, DOI 10.1021/bi00020a003; Zhang FL, 2002, J AM CHEM SOC, V124, P12654, DOI 10.1021/ja027847a	42	5	5	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1090-7807		J MAGN RESON	J. Magn. Reson.	MAY	2008	192	1					37	47		10.1016/j.jmr.2008.01.011		11	Biochemical Research Methods; Physics, Atomic, Molecular & Chemical; Spectroscopy	Biochemistry & Molecular Biology; Physics; Spectroscopy	299OK	WOS:000255764700005	
J	Sims, JS; George, WL; Griffin, TJ; Hagedorn, JC; Hung, HK; Kelso, JT; Olano, M; Peskin, AP; Satterfield, SG; Terrill, JD; Bryant, GW; Diaz, JG				Sims, James S.; George, William L.; Griffin, Terence J.; Hagedorn, John C.; Hung, Howard K.; Kelso, John T.; Olano, Marc; Peskin, Adele P.; Satterfield, Steven G.; Terrill, Judith Devaney; Bryant, Garnett W.; Diaz, Jose G.			Accelerating scientific discovery through computation and visualization - III. Tight-binding wave functions for quantum dots	JOURNAL OF RESEARCH OF THE NATIONAL INSTITUTE OF STANDARDS AND TECHNOLOGY			English	Article						high-performance; computing; MPI; nanotechnology; parallel computing; quantum dots; RAVE; tight-binding; virtual measurements; visualization		This is the third in a series of articles that describe, through examples, how the Scientific Applications and Visualization Group (SAVG) at NIST has utilized high performance parallel computing, visualization, and machine learning to accelerate scientific discovery. In this article we focus on the use of high performance computing and visualization for simulations of nanotechnology.	[Sims, James S.; George, William L.; Griffin, Terence J.; Hagedorn, John C.; Hung, Howard K.; Kelso, John T.; Olano, Marc; Satterfield, Steven G.; Terrill, Judith Devaney] Natl Inst Stand & Technol, Math & Computat Sci Div ITL, Sci Applicat & Visualizat Grp, Gaithersburg, MD 20899 USA; [Bryant, Garnett W.; Diaz, Jose G.] Natl Inst Stand & Technol, Atom Phys Div PL, Gaithersburg, MD 20899 USA; [Olano, Marc] Univ Maryland Baltimore Cty, Dept Comp Sci & Elect Engn, Baltimore, MD 21228 USA	Sims, JS (reprint author), Natl Inst Stand & Technol, Math & Computat Sci Div ITL, Sci Applicat & Visualizat Grp, Gaithersburg, MD 20899 USA.	james.sims@nist.gov; william.george@nist.gov; terence.griffin@nist.gov; john.hagedorn@nist.gov; hhung@verizon.net; john.kelso@nist.gov; marc.olano@nist.gov; adele.peskin@nist.gov; steven.satterfield@nist.gov; judith.terrill@nist.gov; garnett.bryant@nist.gov; gabriel_fyd@hotmail.com			Linux; SGI	We would like to thank Heidi Thornquist of Rice University for help extracting eigenvectors from PARPACK, Steve Plimpton for the irregular grid code, William Mitchell, for his expertise with ARPACK and Fortran 90, Julien C. Franiatte for writing the first version of the parallel code used in this work, Robert Bohn for help with figures, Denis Lehane, Carl Spangler and Michael Strawbridge for Linux cluster support, Chris Schanzle for Linux support, and Donald Koss for SGI support. One of us (JSS) would like to thank Kraemer Sims Becker for introducing him to quantum dots.	Alivisatos AP, 1996, SCIENCE, V271, P933, DOI 10.1126/science.271.5251.933; Bai Z., 2000, TEMPLATES SOLUTION A; Bryant GW, 2001, PHYSICA E, V11, P72, DOI 10.1016/S1386-9477(01)00179-5; Diaz JG, 2006, PHYS REV B, V73, DOI 10.1103/PhysRevB.73.075329; Dubertret B, 2002, SCIENCE, V298, P1759, DOI 10.1126/science.1077194; GARNETT W, 2003, PHYS REV B, V67; Jaskolski W, 2003, PHYSICA E, V17, P40, DOI 10.1016/S1386-9477(02)00729-4; JASKOLSKI W, 2006, PHYS REV B, V74; MASCHHOFF K, 1996, EFFICIENT PORTABLE L; Ouyang M, 2003, SCIENCE, V301, P1074, DOI 10.1126/science.1086963; Sims JS, 2000, J RES NATL INST STAN, V105, P875; Sims JS, 2002, J RES NATL INST STAN, V107, P223; Sleijpen GLG, 2000, SIAM REV, V42, P267, DOI 10.1137/S0036144599363084; SORENSEN DC, 1992, SIAM J MATRIX ANAL A, V13, P357, DOI 10.1137/0613025; VOGL P, 1983, J PHYS CHEM SOLIDS, V44, P365, DOI 10.1016/0022-3697(83)90064-1; Williamson AJ, 2000, PHYS REV B, V61, P1978, DOI 10.1103/PhysRevB.61.1978; VISUALIZATION NONO S; PARALLEL ALGORITHMS	18	0	0	US GOVERNMENT PRINTING OFFICE	WASHINGTON	SUPERINTENDENT DOCUMENTS,, WASHINGTON, DC 20402-9325 USA	1044-677X		J RES NATL INST STAN	J. Res. Natl. Inst. Stand. Technol.	MAY-JUN	2008	113	3					131	142		10.6028/jres.113.010		12	Instruments & Instrumentation; Physics, Applied	Instruments & Instrumentation; Physics	339JL	WOS:000258573800001	
J	Elish, KO; Elish, MO				Elish, Karim O.; Elish, Mahmoud O.			Predicting defect-prone software modules using support vector machines	JOURNAL OF SYSTEMS AND SOFTWARE			English	Article; Proceedings Paper	Joint Meeting of the International Workshop on Software Measurement (IWSM)/International Conference on Software Process and Product Measurement (MENSURA)	NOV 05-07, 2007	Palma de Majorque, SPAIN			software metrics; defect-prone modules; support vector machines; predictive models	OBJECT-ORIENTED DESIGN; NETWORKS; METRICS; TELECOMMUNICATIONS; CATEGORIZATION; SYSTEM; TREES	Effective prediction of defect-prone software modules can enable software developers to focus quality assurance activities and allocate effort and resources more efficiently. Support vector machines (SVM) have been successfully applied for solving both classification and regression problems in many applications. This paper evaluates the capability of SVM in predicting defect-prone software modules and compares its prediction performance against eight statistical and machine learning models in the context of four NASA datasets. The results indicate that the prediction performance of SVM is generally better than, or at least, is competitive against the compared models. (C) 2007 Elsevier Inc. All rights reserved.	[Elish, Karim O.; Elish, Mahmoud O.] King Fahd Univ Petr & Minerals, Dept Informat & Comp Sci, Dhahran 31261, Saudi Arabia	Elish, MO (reprint author), King Fahd Univ Petr & Minerals, Dept Informat & Comp Sci, POB 1082, Dhahran 31261, Saudi Arabia.	kelish@kfupm.edu.sa; clish@krupm.edu.sa					Abe S., 2005, SUPPORT VECTOR MACHI; Azar D., 2002, Proceedings ASE 2002. 17th IEEE International Conference on Automated Software Engineering, DOI 10.1109/ASE.2002.1115031; Bao L, 2002, FEBS LETT, V521, P109, DOI 10.1016/S0014-5793(02)02835-1; Basili VR, 1996, IEEE T SOFTWARE ENG, V22, P751, DOI 10.1109/32.544352; BASILI VR, 1988, IEEE T SOFTWARE ENG, V14, P758, DOI 10.1109/32.6156; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BRIAND LC, 1993, IEEE T SOFTWARE ENG, V19, P1028, DOI 10.1109/32.256851; Burbidge R, 2001, COMPUT CHEM, V26, P5, DOI 10.1016/S0097-8485(01)00094-8; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Cai YD, 2002, COMPUT CHEM, V26, P293, DOI 10.1016/S0097-8485(01)00113-9; Chen WH, 2005, COMPUT OPER RES, V32, P2617, DOI 10.1016/j.cor.2004.03.019; CHIDAMBER SR, 1994, IEEE T SOFTWARE ENG, V20, P476, DOI 10.1109/32.295895; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cristianini N., 2000, INTRO SUPPORT VECTOR; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; Duda R. O., 2001, PATTERN CLASSIFICATI; Dumais S, 1998, IEEE INTELL SYST APP, V13, P21; Emam K., 2001, J SYST SOFTWARE, V55, P301; Fenton N, 2002, IEEE SOFTWARE, V19, P116, DOI 10.1109/MS.2002.1020298; Fenton NE, 2000, IEEE T SOFTWARE ENG, V26, P797, DOI 10.1109/32.879815; Gun S., 1998, SUPPORT VECTOR MACHI; Guo L., 2003, Proceedings 18th IEEE International Conference on Automated Software Engineering; Guo Lan, 2004, P 15 INT S SOFTW REL, P417, DOI DOI 10.1109/ISSRE.2004.35; Hall M., 2000, P 17 INT C MACH LEAR, P359; Halstead M.H., 1977, ELEMENTS SOFTWARE SC; Han J., 2001, DATA MINING CONCEPTS; Hosmer DW, 2000, APPL LOGISTIC REGRES; Khoshgoftaar TM, 2002, IEEE T RELIAB, V51, P455, DOI 10.1109/TR.2002.804488; Khoshgoftaar TM, 1997, IEEE T NEURAL NETWOR, V8, P902, DOI 10.1109/72.595888; Khoshgoftaar TM, 1996, IEEE SOFTWARE, V13, P65, DOI 10.1109/52.476287; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; KORU A, 2005, IEEE SOFTWARE, P23; Koru AG, 2003, J SYST SOFTWARE, V67, P153, DOI 10.1016/S0164-1212(02)00126-7; LIN S, 2003, P EUR WORKSH DAT MIN, P35; MA Y, 2006, ADV MACHINE LEARNING; Mair C, 2000, J SYST SOFTWARE, V53, P23, DOI 10.1016/S0164-1212(00)00005-4; McCabe T. J., 1976, IEEE Transactions on Software Engineering, VSE-2, DOI 10.1109/TSE.1976.233837; MCCABE TJ, 1989, COMMUN ACM, V32, P1415, DOI 10.1145/76380.76382; Morris CW, 2001, ECOL MODEL, V146, P57; MUNSON JC, 1992, IEEE T SOFTWARE ENG, V18, P423, DOI 10.1109/32.135775; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; SCHMIDT M, 1996, P INT C AC SPEECH SI, P105; SCHNEIDEWIND NF, 1992, IEEE T SOFTWARE ENG, V18, P410, DOI 10.1109/32.135774; SELBY RW, 1988, IEEE T SOFTWARE ENG, V14, P1743, DOI 10.1109/32.9061; Shepperd M, 2001, IEEE T SOFTWARE ENG, V27, P1014, DOI 10.1109/32.965341; Smola A., 1998, THESIS TU BERLIN GER; Tay FEH, 2001, OMEGA-INT J MANAGE S, V29, P309, DOI 10.1016/S0305-0483(01)00026-3; Vapnik V. N, 1995, NATURE STAT LEARNING; Weaver R., 2003, THESIS U YORK; Webb R., 2002, STAT PATTERN RECOGNI; Witten I. H., 2005, DATA MINING PRACTICA	53	33	37	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0164-1212		J SYST SOFTWARE	J. Syst. Softw.	MAY	2008	81	5					649	660		10.1016/j.jss.2007.07.040		12	Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	292WD	WOS:000255295900005	
J	Yu, B; Xu, ZB				Yu, Bo; Xu, Zong-ben			A comparative study for content-based dynamic spam classification using four machine learning algorithms	KNOWLEDGE-BASED SYSTEMS			English	Article						spam classification; Naive Bayesian; neural network; support vector machine; relevance vector machine	SUPPORT VECTOR MACHINES	The growth of email users has resulted in the dramatic increasing of the spam emails during the past few years. In this paper, four machine learning algorithms, which are Naive Bayesian (NB), neural network (NN), support vector machine (SVM) and relevance vector machine (RVM), are proposed for spam classification. An empirical evaluation for them on the benchmark spam filtering corpora is presented. The experiments are performed based on different training set size and extracted feature size. Experimental results show that NN classifier is unsuitable for using alone as a spam rejection tool. Generally, the performances of SVM and RVM classifiers are obviously superior to NB classifier. Compared with SVM, RVM is shown to provide the similar classification result with less relevance vectors and much faster testing time. Despite the slower learning procedure, RVM is more suitable than SVM for spam classification in terms of the applications that require low complexity. (C) 2008 Elsevier B.V. All rights reserved.	[Yu, Bo] Xian Jiaotong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China; [Xu, Zong-ben] Xian Jiaotong Univ, Sch Sci, Inst Informat & Syst Sci, Xian 710049, Peoples R China	Yu, B (reprint author), Xian Jiaotong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.	xjtuyubo@gmail.com; zbxu@mail.xjtu.edu.cn					ANDROUTSOPOULOS J, 2000, P WORKSH MACH LEARN, P9; BOYKIN PO, 2005, IEEE COMPUT, V38, P61; Carpinter J, 2006, COMPUT SECUR, V25, P566, DOI 10.1016/j.cose.2006.06.001; CATARINA S, 2007, INT J COMPUTATIONAL, V3, P31; Demir B, 2007, IEEE GEOSCI REMOTE S, V4, P586, DOI 10.1109/LGRS.2007.903069; Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; HELFMAN J, 1995, ISHMAIL IMMEDIATE ID; KOPRINSKA CI, 2003, P IEEE WIC INT C WEB, P702; Lin CJ, 2001, NEURAL COMPUT, V13, P307, DOI 10.1162/089976601300014547; MACKAY DJC, 1992, NEURAL COMPUT, V4, P720, DOI 10.1162/neco.1992.4.5.720; MCCALLUM K, 1998, P AAAI WORKSH LEARN, P41; Ozgur L, 2004, PATTERN RECOGN LETT, V25, P1819, DOI 10.1016/j.patrec.2004.07.004; Ozgur L, 2004, LECT NOTES COMPUT SC, V3177, P505; Rennie Jason D.M., 2000, P KDD 2000 TEXT MIN; Sahami M., 1998, LEARNING TEXT CATEGO; TIPPING E, 2000, ADV NEURAL INFORM PR, V12; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Vapnik V., 1982, ESTIMATION DEPENDENC; Vapnik V. N, 1995, NATURE STAT LEARNING; Zorkadis V, 2005, NEURAL NETWORKS, V18, P799, DOI 10.1016/j.neunet.2005.06.045; *AL KNOWL SYST, ANT WHIT PAP	21	17	18	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051		KNOWL-BASED SYST	Knowledge-Based Syst.	MAY	2008	21	4					355	362		10.1016/j.knosys.2008.01.001		8	Computer Science, Artificial Intelligence	Computer Science	310ZC	WOS:000256568600007	
J	Ekbal, A; Bandyopadhyay, S				Ekbal, Asif; Bandyopadhyay, Sivaji			A web-based Bengali news corpus for named entity recognition	LANGUAGE RESOURCES AND EVALUATION			English	Article						web as corpus; news corpus; web-based tagged Bengali news corpus; named entity; named entity recognition		The rapid development of language resources and tools using machine learning techniques for less computerized languages requires appropriately tagged corpus. A tagged Bengali news corpus has been developed from the web archive of a widely read Bengali newspaper. A web crawler retrieves the web pages in Hyper Text Markup Language (HTML) format from the news archive. At present, the corpus contains approximately 34 million wordforms. Named Entity Recognition (NER) systems based on pattern based shallow parsing with or without using linguistic knowledge have been developed using a part of this corpus. The NER system that uses linguistic knowledge has performed better yielding highest F-Score values of 75.40%, 72.30%, 71.37%, and 70.13% for person, location, organization, and miscellaneous names, respectively.	[Ekbal, Asif; Bandyopadhyay, Sivaji] Jadavpur Univ, Dept Comp Sci & Engn, Calcutta 700032, India	Ekbal, A (reprint author), Jadavpur Univ, Dept Comp Sci & Engn, Calcutta 700032, India.	asif.ekbal@gmail.com; sivaji_cse_ju@yahoo.com					Baroni M., 2004, P LREC 2004, P1313; BERTAGNA F, 2004, P LREC 2004, P131; BHARATI A, 2001, P 6 NLP PAC RIM S PO; BOLEDA G, 2006, P 2 INT WORKSH WEB C, P19, DOI 10.3115/1628297.1628301; CALZOLARI N, 2003, ISLE DELIVERABLE D 2; Cunningham H, 2002, COMPUT HUMANITIES, V36, P223, DOI 10.1023/A:1014348124664; FLETCHER W, 2001, P 3 N AM S CORP LING; Fletcher WH, 2004, LANG COMPUT, P191; GIGUET E, 2006, P COLING ACL 2006 MA, P271; Kilgarriff A, 2003, COMPUT LINGUIST, V29, P333, DOI 10.1162/089120103322711569; Lenci A., 2000, INT J LEXICOGR, V13, P249, DOI 10.1093/ijl/13.4.249; Okanohara D., 2006, P 21 INT C COMP LING, P465, DOI 10.3115/1220175.1220234; RAYSON P, 2006, P 2 INT WORKSH WEB C, P27, DOI 10.3115/1628297.1628302; ROBB T, 2003, ETJ J            SPR, V4; Rundle J, 2000, COMPUT SCI ENG, V2, P3; TOKUNAGA T, 2006, P COLING ACL 2006 MA, P827; YANGARBER R, 2002, P COLING 2002	17	13	13	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1574-020X		LANG RESOUR EVAL	Lang. Resour. Eval.	MAY	2008	42	2					173	182		10.1007/s10579-008-9064-x		10	Computer Science, Interdisciplinary Applications	Computer Science	332XY	WOS:000258117600006	
J	Hao, L; Lewin, PL; Swingler, SG				Hao, L.; Lewin, P. L.; Swingler, S. G.			Improving detection sensitivity for partial discharge monitoring of high voltage equipment	MEASUREMENT SCIENCE & TECHNOLOGY			English	Article						partial discharge; power transformer; radio frequency current transducer; electro-optic modulation; wavelet analysis; data mining; support vector machine	WAVELET ANALYSIS; CABLES; SIGNALS	Partial discharge (PD) measurements are an important technique for assessing the health of power apparatus. Previous published research by the authors has shown that an electro-optic system can be used for PD measurement of oil-filled power transformers. A PD signal generated within an oil-filled power transformer may reach a winding and then travel along the winding to the bushing core bar. The bushing, acting like a capacitor, can transfer the high frequency components of the partial discharge signal to its earthed tap point. Therefore, an effective PD current measurement can be implemented at the bushing tap by using a radio frequency current transducer around the bushing-tap earth connection. In addition, the use of an optical transmission technique not only improves the electrical noise immunity and provides the possibility of remote measurement but also realizes electrical isolation and enhances safety for operators. However, the bushing core bar can act as an aerial and in addition noise induced by the electro-optic modulation system may influence overall measurement sensitivity. This paper reports on a machine learning technique, namely the use of a support vector machine (SVM), to improve the detection sensitivity of the system. Comparison between the signal extraction performances of a passive hardware filter and the SVM technique has been assessed. The results obtained from the laboratory-based experiment have been analysed and indicate that the SVM approach provides better performance than the passive hardware filter and it can reliably detect discharge signals with apparent charge greater than 30 pC.	[Hao, L.; Lewin, P. L.; Swingler, S. G.] Univ Southampton, Tony Davies High Voltage Lab, Elect Power Engn Grp, Sch Elect & Comp Sci, Southampton SO17 1BJ, Hants, England	Hao, L (reprint author), Univ Southampton, Tony Davies High Voltage Lab, Elect Power Engn Grp, Sch Elect & Comp Sci, Southampton SO17 1BJ, Hants, England.	haoliwei@soton.ac.uk					Bian Zhaoqi, 2000, PATTERN RECOGNITION; Chang CS, 2005, IEE P-SCI MEAS TECH, V152, P129, DOI 10.1049/ip-smt:20041315; Chang CS, 2005, IEEE T POWER DELIVER, V20, P1363, DOI 10.1109/TPWRD.2004.839187; Han B., 2004, THESIS U SOUTHAMPTON; HAO L, 2006, P 2006 IEEE C INT S, P110; HAO L, 2005, P 14 INT S HIGH VOLT; HAO L, 2006, P 2006 IEEE ISEI, P412; Kyprianou A, 2006, MEAS SCI TECHNOL, V17, P2367, DOI 10.1088/0957-0233/17/9/001; Ma X, 2002, IEEE T DIELECT EL IN, V9, P446, DOI 10.1109/TDEI.2002.1007709; Scholkopf B., 2002, LEARNING KERNELS SUP; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Tian Y, 2003, IEEE T DIELECT EL IN, V10, P343, DOI 10.1109/TDEI.2003.1194121; Tian Y, 2005, IEEE T DIELECT EL IN, V12, P1222; Tian Y, 2005, Proceedings of the 2005 International Symposium on Electrical Insulating Materials, Vols, 1-3, P841, DOI 10.1109/ISEIM.2005.193510; Vapnik V. N, 1995, NATURE STAT LEARNING; Wang P, 2004, PROCEEDINGS OF THE 2004 IEEE INTERNATIONAL CONFERENCE ON SOLID DIELECTRICS, VOLS 1 AND 2, P619; Yang L, 2003, IEE P-SCI MEAS TECH, V150, P119, DOI 10.1049/ip-smt:20030201	17	3	3	IOP PUBLISHING LTD	BRISTOL	TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND	0957-0233		MEAS SCI TECHNOL	Meas. Sci. Technol.	MAY	2008	19	5							055707	10.1088/0957-0233/19/5/055707		10	Engineering, Multidisciplinary; Instruments & Instrumentation	Engineering; Instruments & Instrumentation	298BT	WOS:000255662100030	
J	Girish, V; Jayadeva; Nooshabadi, S				Girish, V.; Jayadeva; Nooshabadi, S.			Design methodology for configurable analog to digital conversion using support vector machines	MICROELECTRONICS JOURNAL			English	Article						support vector machine; machine learning; analog to digital conversion; integrated circuits		We apply a support vector machine (SVM) classifier to the design of analog to digital converters. Each output bit of the converter is the output of a binary classifier, which is a nonlinear SVM. The classifier effectively learns a folding characteristic for each bit, which is realized as the weighted sum of a set of kernel functions. In our proposal, the kernel does not need to be symmetric or positive definite, unlike in the case of a conventional SVM. This makes the approach more amenable to VLSI design, where such constraints are hard to satisfy. The SVM uses a set of binary weights, which allows the folding characteristics to be digitally corrected after fabrication. This facility is of considerable value in analog design in a deep sub micron era, where simulation models do not adequately capture the behavior of devices, or their variations. The proposed methodology reduces design time, can be automated and calibrated for process variations and ageing, by changing a set of digital scaling coefficients. (C) 2007 Elsevier Ltd. All rights reserved.	[Girish, V.; Jayadeva] Indian Inst Technol, Dept Elect Engn, Delhi, India	Jayadeva (reprint author), Indian Inst Technol, Dept Elect Engn, Delhi, India.	girish.vgl@gmail.com; jayadeva@ee.iitd.ac.in; saeid@gist.ac.kr					CHANG F, 2003, P 2003 INT C MACH LE, P3022; CHENG J, 2001, P 4 INT C ASIC ASICO, P271; DELBRUCK T, 1991, P INT JOINT C NEUR N; Fung G., 2001, P KDD 2001 KNOWL DIS, P77, DOI 10.1145/502512.502527; JAYADEVA RK, 2006, P INT JOINT C NEUR N, P593; LI K, 2002, P INT C MACH LEARN C, V3, P1635; Lu SX, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P4277; Luenberger D.G., 2005, LINEAR NONLINEAR PRO; Mangasarian OL, 2000, ADV NEUR IN, P135; Sebald DJ, 2000, IEEE T SIGNAL PROCES, V48, P3217, DOI 10.1109/78.875477; Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646; Vapnik V. N, 1995, NATURE STAT LEARNING; ZHANG MG, 2005, P 17 IEEE INT C TOOL, P3	13	0	0	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0026-2692		MICROELECTRON J	Microelectron. J.	MAY	2008	39	5					822	827		10.1016/j.mejo.2007.12.010		6	Engineering, Electrical & Electronic; Nanoscience & Nanotechnology	Engineering; Science & Technology - Other Topics	311PA	WOS:000256610900023	
J	Cai, YD; Qian, ZL; Lu, L; Feng, KY; Meng, X; Niu, B; Zhao, GD; Lu, WC				Cai, Yu-Dong; Qian, Ziliang; Lu, Lin; Feng, Kai-Yan; Meng, Xin; Niu, Bing; Zhao, Guo-Dong; Lu, Wen-Cong			Prediction of compounds' biological function (metabolic pathways) based on functional group composition	MOLECULAR DIVERSITY			English	Article						compound; biological functions; nearest neighbor algorithm; functional group composition; metabolic pathway	AMINO-ACID-COMPOSITION; DOMAIN COMPOSITION; PROTEIN LOCALIZATION; WEB SERVER; METABONOMICS; SYSTEMS; GENE	Efficient in silico screening approaches may provide valuable hints on biological functions of the compound-candidates, which could help to screen functional compounds either in basic researches on metabolic pathways or drug discovery. Here, we introduce a machine learning method (Nearest Neighbor Algorithm) based on functional group composition of compounds to the analysis of metabolic pathways. This method can quickly map small chemical molecules to the metabolic pathway that they likely belong to. A set of 2,764 compounds from 11 major classes of metabolic pathways were selected for study. The overall prediction rate reached 73.3%, indicating that functional group composition of compounds was really related to their biological metabolic functions.	[Cai, Yu-Dong; Meng, Xin; Zhao, Guo-Dong] Chinese Acad Sci, Shanghai Inst Biol Sci, CAS MPG Partner Inst Computat Biol, Shanghai 200072, Peoples R China; [Cai, Yu-Dong; Feng, Kai-Yan] Univ Manchester, Inst Sci & Technol, Dept Math, Manchester M60 1QD, Lancs, England; [Qian, Ziliang] Chinese Acad Sci, Grad Sch, Beijing 100039, Peoples R China; [Qian, Ziliang] Chinese Acad Sci, Bioinformat Ctr, Key Lab Mol Syst Biol, Shanghai Inst Biol Sci, Shanghai 200031, Peoples R China; [Lu, Lin] Shanghai Jiao Tong Univ, Dept Biomed Engn, Shanghai 200240, Peoples R China; [Niu, Bing; Lu, Wen-Cong] Shanghai Univ, Sch Mat Sci & Engn, Shanghai 200072, Peoples R China	Cai, YD (reprint author), Chinese Acad Sci, Shanghai Inst Biol Sci, CAS MPG Partner Inst Computat Biol, Shanghai 200072, Peoples R China.	cyd@picb.ac.cn					Burkart MD, 2003, ORG BIOMOL CHEM, V1, P1, DOI 10.1039/b210173d; Cai YD, 2004, BIOINFORMATICS, V20, P1292, DOI 10.1093/bioinformatics/bth085; Cai YD, 2005, J PROTEOME RES, V4, P967, DOI 10.1021/pr0500399; Chou KC, 2005, BIOINFORMATICS, V21, P944, DOI 10.1093/bioinformatics/bti104; Jia PL, 2007, BIOCHEM BIOPH RES CO, V357, P366, DOI 10.1016/j.bbrc.2007.03.139; Kanehisa M, 2006, NUCLEIC ACIDS RES, V34, pD354, DOI 10.1093/nar/gkj102; Lu LY, 2007, COMPUT BIOL CHEM, V31, P226, DOI 10.1016/j.compbiolchem.2007.03.008; Marchand-Geneste N, 2002, J MED CHEM, V45, P399, DOI 10.1021/jm0155244; MCKEE JR, 1999, BIOCH INTRO; Mondal S, 2006, J THEOR BIOL, V243, P252, DOI 10.1016/j.jtbi.2006.06.014; Nicholson JK, 1999, XENOBIOTICA, V29, P1181; Nicholson JK, 2002, NAT REV DRUG DISCOV, V1, P153, DOI 10.1038/nrd728; Nicholson JK, 2004, NAT BIOTECHNOL, V22, P1268, DOI 10.1038/nbt1015; Nicholson JK, 2003, NAT REV DRUG DISCOV, V2, P668, DOI 10.1038/nrd1157; Qian ZL, 2007, BIOINFORMATICS, V23, P2449, DOI 10.1093/bioinformatics/btm348; SALZBERG S, 1992, J MOL BIOL, V227, P371, DOI 10.1016/0022-2836(92)90892-N; Vastrik I, 2007, GENOME BIOL, V8, DOI 10.1186/gb-2007-8-3-r39; Wong YH, 2007, NUCLEIC ACIDS RES, V35, pW588, DOI 10.1093/nar/gkm322; Xie D, 2005, NUCLEIC ACIDS RES, V33, pW105, DOI 10.1093/nar/gki359	19	14	14	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1381-1991		MOL DIVERS	Mol. Divers.	MAY	2008	12	2					131	137		10.1007/s11030-008-9085-9		7	Biochemistry & Molecular Biology; Chemistry, Applied; Chemistry, Medicinal; Chemistry, Multidisciplinary	Biochemistry & Molecular Biology; Chemistry; Pharmacology & Pharmacy	340WK	WOS:000258675500006	
J	Peters, J; Schaal, S				Peters, Jan; Schaal, Stefan			Reinforcement learning of motor skills with policy gradients	NEURAL NETWORKS			English	Article						reinforcement learning; policy gradient methods; natural gradients; Natural Actor-Critic; motor skills; motor primitives	REACHING MOVEMENTS; INFINITE-HORIZON; BIPED LOCOMOTION; APPROXIMATION; OPTIMIZATION; ESTIMATION/; SIMULATION; ALGORITHM; ARM	Autonomous learning is one of the hallmarks of human and animal behavior, and understanding the principles of learning will be crucial in order to achieve true autonomy in advanced machines like humanoid robots. In this paper, we examine learning of complex motor skills with human-like limbs. While supervised learning can offer useful tools for bootstrapping behavior, e.g., by learning from demonstration, it is only reinforcement learning that offers a general approach to the final trial-and-error improvement that is needed by each individual acquiring a skill. Neither neurobiological nor machine learning studies have, so far, offered compelling results on how reinforcement learning can be scaled to the high-dimensional continuous state and action spaces of humans or humanoids. Here, we combine two recent research developments on learning motor control in order to achieve this scaling. First, we interpret the idea of modular motor control by means of motor primitives as a suitable way to generate parameterized control policies for reinforcement learning. Second, we combine motor primitives with the theory of stochastic policy gradient learning, which currently seems to be the only feasible framework for reinforcement learning for humanoids. We evaluate different policy gradient methods with a focus on their applicability to parameterized motor primitives. We compare these algorithms in the context of motor primitive learning, and show that our most modern algorithm, the Episodic Natural Actor-Critic outperforms previous algorithms by at least an order of magnitude. We demonstrate the efficiency of this reinforcement learning method in the application of learning to hit a baseball with an anthropomorphic robot arm. (C) 2008 Elsevier Ltd. All rights reserved.	[Peters, Jan] Max Planck Inst Biol Cybernet, D-72076 Tubingen, Germany; [Peters, Jan; Schaal, Stefan] Univ So Calif, Los Angeles, CA 90089 USA; [Schaal, Stefan] ATR Computat Neurosci Lab, Kyoto 6190288, Japan	Peters, J (reprint author), Max Planck Inst Biol Cybernet, Spemannstr 38, D-72076 Tubingen, Germany.	jan.peters@tuebingen.mpg.de	Peters, Jan/D-5068-2009				ABERDEEN D, 2006, MACH LEARN SUMM SCH; Aleksandrov V. M., 1968, ENG CYBERN, V5, P11; Amari S, 1998, NEURAL COMPUT, V10, P251, DOI 10.1162/089976698300017746; ATKESON CG, 1994, ADV NEURAL INFORM PR, P503; Bagnell J. A., 2003, P INT JOINT C ART IN, P1019; Baird L. C., 1993, WLTR931146; Balasubramanian V, 1997, NEURAL COMPUT, V9, P349, DOI 10.1162/neco.1997.9.2.349; BARTO AG, 1983, IEEE T SYST MAN CYB, V13, P115; Baxter J, 2001, J ARTIF INTELL RES, V15, P319; Baxter J, 2001, J ARTIF INTELL RES, V15, P351; BENBRAHIM H, 1992, P INT JOINT C NEUR N, P92; Benbrahim H, 1997, ROBOT AUTON SYST, V22, P283, DOI 10.1016/S0921-8890(97)00043-2; Ben-Itzhak S, 2008, NEURAL COMPUT, V20, P779, DOI 10.1162/neco.2007.12-05-077; BERNY A, 2000, LECT NOTES NATURAL C, V33, P287; Endo G., 2005, P 20 NAT C ART INT 9, P1267; Flash T, 2005, CURR OPIN NEUROBIOL, V15, P660, DOI 10.1016/j.conb.2005.10.011; Fletcher R., 2000, PRACTICAL METHODS OP; Fu MC, 2002, INFORMS J COMPUT, V14, P192, DOI 10.1287/ijoc.14.3.192.113; Gibbs AL, 2002, INT STAT REV, V70, P419, DOI 10.2307/1403865; Glynn P., 1987, P 1987 WINT SIM C, P366, DOI 10.1145/318371.318612; GLYNN PW, 1990, COMMUN ACM, V33, P75, DOI 10.1145/84537.84552; Greensmith E, 2004, J MACH LEARN RES, V5, P1471; GREENSMITH E, 2001, ADV NEURAL INFORM PR, V14; Guenter F, 2007, ADV ROBOTICS, V21, P1521; GULLAPALLI V, 1990, NEURAL NETWORKS, V3, P671, DOI 10.1016/0893-6080(90)90056-Q; GULLAPALLI V, 1992, ADV NEURAL INFORM PR, P327; Gullapalli V, 1994, IEEE CONTROL SYSTEMS, V4, P13; HARVILLE D. A, 2000, MATRIX ALGEBRA STAT; Hasdorff L., 1976, GRADIENT OPTIMIZATIO; Ijspeert A., 2003, ADV NEURAL INFORM PR, P1547; Ijspeert J.A., 2002, P IEEE INT C ROB AUT, P1398; Jacobson D. H., 1970, DIFFERENTIAL DYNAMIC; KAKADE S, 2001, P C COMP LEARN THEOR, P605; Kakade S, 2002, ADV NEUR IN, V14, P1531; Kakade S.M., 2003, THESIS U COLL LONDON; KIMURA H, 1998, P INT C INT AUT SYST, V5, P288; KIMURA H, 1997, P 6 EUR WORKSH LEARN, P144; Kleinman NL, 1999, MANAGE SCI, V45, P1570, DOI 10.1287/mnsc.45.11.1570; Kohl N., 2004, P IEEE INT C ROB AUT, P2619; KONDA V, 2000, ADV NEURAL INFORMATI, P12; Lawrence G., 2003, P INT C UNC ART INT, P354; McReynolds S.R., 1970, COMPUTATION THEORY O; MITSUNAGA N, 2005, P 2005 IEEE RSJ INT, P1594; Miyamoto H., 1995, Proceedings 4th IEEE International Workshop on Robot and Human Communication. RO-MAN'95 TOKYO (Cat. No.95TH8115), DOI 10.1109/ROMAN.1995.531981; Miyamoto H., 1996, Progress in Neural Information Processing. Proceedings of the International Conference on Neural Information Processing; Moon T. K., 2000, MATH METHODS ALGORIT; MORI T, 2005, ADV NEURAL INFORM PR; Mori T, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P623; MORIMOTO J, 2003, ADV NEURAL INFORM PR, V15, P1539; Nakamura Y, 2004, LECT NOTES COMPUT SC, V3242, P972; Nakanishi J, 2004, ROBOT AUTON SYST, V47, P79, DOI 10.1016/j.robot.2004.03.003; Ng A., 2000, P 16 C UNC ART INT, P406; Park J, 2005, LECT NOTES ARTIF INT, V3801, P65; Peters J., 2005, P 16 EUR C MACH LEAR, P280; Peters J., 2006, P IEEE RSJ INT C INT, P2219; PETERS J, 2005, CS05867 U SO CALIFOR; PETERS J, 2003, P IEEE RAS INT C HUM, P103; Peters J., 2007, THESIS U SO CALIFORN; Peters J, 2005, LECT NOTES ARTIF INT, V3720, P280; Pongas D., 2005, P IEEE INT C INT ROB, P2911; Richter S., 2007, ADV NEURAL INFORM PR, V19; Sadegh P, 1997, P AMER CONTR CONF, P3582, DOI 10.1109/ACC.1997.609490; Sato M, 2002, LECT NOTES COMPUT SC, V2415, P777; SCHAAL S, 2004, SPRING TRACTS ADV RO, P561; Schaal S, 1997, ADV NEUR IN, V9, P1040; Sciavicco L., 2007, MODELING CONTROL ROB; Spall J., 2003, INTRO STOCHASTIC SEA; Sutton RS, 2000, ADV NEUR IN, V12, P1057; TEDRAKE R, 2005, P YAL WORKSH AD LEAR, P10; UENO T, 2006, P IEEE RSJ INT C INT, P5226; VACHENAUER P, 2000, TASCHENBUCH INGENIEU; Wada Y., 1994, SYST COMPUT JPN, V24, P37; WEAVER L, 2001, P INT C UNC ART INT, V17, P538; WEAVER L, 2001, 30 ANU; WERBOS P, 1979, POLICY ANAL INFORM S, V3; Williams R. J., 1992, MACHINE LEARNING, V8	76	60	60	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080		NEURAL NETWORKS	Neural Netw.	MAY	2008	21	4					682	697		10.1016/j.neunet.2008.02.003		16	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	326EA	WOS:000257639800012	
J	Moseley, LG; Mead, DM				Moseley, Laurence G.; Mead, Donna M.			Predicting who will drop out of nursing courses: A machine learning exercise	NURSE EDUCATION TODAY			English	Article						student drop outs; machine learning; data mining; prediction	DECISION-MAKING; LINEAR-MODELS; ATTRITION; METAANALYSIS; STUDENTS	Introduction: The concepts of causation and prediction are different, and have different implications for practice. This distinction is applied here to studies of the problem of student attrition (although it is more widely applicable). Background: Studies of attrition from nursing courses have tended to concentrate on causation, trying, largely unsuccessfully, to elicit what causes dropout. However, the problem may more fruitfully be cast in terms of predicting who is likely to drop out. Methods: One powerful method for attempting to make predictions is rule induction. This paper reports the use of the Answer Tree package from SPSS for that purpose. Data: The main data set consisted of 3978 records on 528 nursing students, split into a training set and a test set. The source was standard university student records. Results: The method obtained 84% sensitivity, 70% specificity, and 94% accuracy on previously unseen cases. Discussion: The method requires large amounts of high quality data. When such data are available, rule induction offers a way to reduce attrition. It would be desirable to compare its results with those of predictions made by tutors using more informal conventional methods. (C) 2007 Elsevier Ltd. All rights reserved.	[Moseley, Laurence G.; Mead, Donna M.] Univ Glamorgan, HESAS, Pontypridd CF37 1DL, M Glam, Wales	Moseley, LG (reprint author), Univ Glamorgan, HESAS, Glyntaff Campus, Pontypridd CF37 1DL, M Glam, Wales.	LGMoseley@btinternet.com					Alexander JE, 1997, J NURS EDUC, V36, P443; Baron J., 2000, THINKING DECIDING; BOUDREAUX RW, 2004, THESIS U HOUSTON; Christensen-Szalanski Jay J., 1991, Organizational Behav. & Hum. Decision Processes, V48, P147; DAWES RM, 1989, SCIENCE, V243, P1668, DOI 10.1126/science.2648573; DAWES RM, 1974, PSYCHOL BULL, V81, P95, DOI 10.1037/h0037613; DAWES RM, 1979, AM PSYCHOL, V34, P571, DOI 10.1037//0003-066X.34.7.571; Deary IJ, 2003, J ADV NURS, V43, P71, DOI 10.1046/j.1365-2648.2003.02674.x; Gigerenzer G, 2002, RECKONING RISK; Glossop C, 2001, NURS EDUC TODAY, V21, P170, DOI 10.1054/nedt.2000.0525; Glossop C, 2002, NURS EDUC TODAY, V22, P375, DOI 10.1054/nedt.2001.0724; Grove WM, 2000, PSYCHOL ASSESSMENT, V12, P19, DOI 10.1037//1040-3590.12.1.19; Grove WM, 1996, PSYCHOL PUBLIC POL L, V2, P293, DOI 10.1037/1076-8971.2.2.293; Guilbault RL, 2004, BASIC APPL SOC PSYCH, V26, P103, DOI 10.1207/s15324834basp2602&3_1; Haughton D, 2003, AM STAT, V57, P290, DOI 10.1198/0003130032486; HAYES C, 2005, THESIS DELTA STATE U; Johnes G, 2004, OXFORD B ECON STAT, V66, P23, DOI 10.1111/j.1468-0084.2004.00068.x; Jones JK, 2001, CURR THER RES CLIN E, V62, P664, DOI 10.1016/S0011-393X(01)80072-2; Kahneman D, 1982, JUDGEMENT UNCERTAINT; Last L, 2003, NURS EDUC TODAY, V23, P449, DOI 10.1016/S0260-6917(03)00063-7; MARCHESE MC, 1992, PERCEPT MOTOR SKILL, V75, P583; Meehl P.E., 1954, CLIN VERSUS STAT PRE; Meyer GJ, 2001, AM PSYCHOL, V56, P128, DOI 10.1037//0003-066X.56.2.128; MOSELEY LG, 1999, IS THINKING JUST TOO; Myers D, 2004, INTUITION ITS POWERS; SAWYER J, 1966, PSYCHOL BULL, V66, P178, DOI 10.1037/h0023624; Tetlock PE, 2005, EXPERT POLITICAL JUDGMENT: HOW GOOD IS IT, HOW CAN WE KNOW, P1; Wharrad HJ, 2003, NURS EDUC TODAY, V23, P246, DOI 10.1016/S0260-6917(02)00116-8; *AUD GEN WAL, 2001, NAT ASS 1 MARCH 2001; *COMPTR AUD GEN, 2001, 277 HC COMPTR AUD GE; 2006, NURSING STANDAR 0215, P5	31	8	8	CHURCHILL LIVINGSTONE	EDINBURGH	JOURNAL PRODUCTION DEPT, ROBERT STEVENSON HOUSE, 1-3 BAXTERS PLACE, LEITH WALK, EDINBURGH EH1 3AF, MIDLOTHIAN, SCOTLAND	0260-6917		NURS EDUC TODAY	Nurse Educ. Today	MAY	2008	28	4					469	475		10.1016/j.nedt.2007.07.012		7	Nursing	Nursing	304OS	WOS:000256119400010	
J	Xue, H; Chen, SC; Zeng, XQ				Xue, Hui; Chen, Songcan; Zeng, Xiaoqin			Classifier learning with a new locality regularization method	PATTERN RECOGNITION			English	Article						localized generalization error model; stochastic sensitivity measure; locality regularization (LR); classifier learning; pattern classification	SUPPORT VECTOR MACHINES; NETWORKS; APPROXIMATION; SELECTION	It is well known that the generalization capability is one of the most important criterions to develop and evaluate a classifier for a given pattern classification problem. The localized generalization error model (R-SM) recently proposed by Ng et al. [Localized generalization error and its application to RBFNN training, in: Proceedings of the International Conference on Machine Learning and Cybernetics, China, 2005; Image classification with the use of radial basis function neural networks and the minimization of the localized generalization error, Pattern Recognition 40(l) (2007) 4-18] provides a more intuitive look at the generalization error. Although R-SM gives a brand-new method to promote the generalization performance, it is in nature equivalent to another type of regularization. In this paper, we first prove the essential relationship between R-SM and regularization, and demonstrate that the stochastic sensitivity measure in R-SM exactly corresponds to a regularizing term. Then, we develop a new generalization error bound from the regularization viewpoint, which is inspired by the proved relationship between R-SM and regularization. Moreover, we derive a new regularization method, called as locality regularization (LR), from the bound. Different from the existing regularization methods which artificially and externally append the regularizing term in order to smooth the solution, LR is naturally and internally deduced from the defined expected risk functional and calculated by employing locality information. Through combining with spectral graph theory, LR introduces the local structure information of the samples into the regularizing term and further improves the generalization capability. In contrast with R-SM, which is relatively sensitive to the different sampling of the samples, LR uses the discrete k-neighborhood rather than the common continuous Q-neighborhood in R-SM to differentiate the relative position of different training samples automatically and avoid the complex computation of Q for various classifiers. Furthermore, LR uses the regularization parameter to control the trade-off between the training accuracy and the classifier stability. Experimental results on artificial and real world problems show that LR yields better generalization capability than both R-SM and some traditional regularization methods. (c) 2007 Elsevier Ltd. All rights reserved.	[Xue, Hui; Chen, Songcan] Nanjing Univ Aeronaut & Astronaut, Comp Sci & Engn Coll, Nanjing 210016, Peoples R China; [Zeng, Xiaoqin] HoHai Univ, Dept Comp Sci & Engn, Nanjing 210098, Peoples R China	Chen, SC (reprint author), Nanjing Univ Aeronaut & Astronaut, Comp Sci & Engn Coll, Nanjing 210016, Peoples R China.	xuehui@nuaa.edu.cn; s.chen@nuaa.edu.cn; xzeng@hhu.edu.cn					ARGYIOU A, 2005, COMBING GRAPH LAPLAC; BELKIN M, 2001, NIPS, V15; Chen Z, 2002, NEURAL COMPUT, V14, P2791, DOI 10.1162/089976602760805296; Cherkassky V, 1999, IEEE T NEURAL NETWOR, V10, P1075, DOI 10.1109/72.788648; Cherkassky V., 1998, LEARNING DATA CONCEP; CHUNG FRK, 1997, REG C SER MATH, V92; Cristianini N., 2000, INTRO SUPPORT VECTOR; Duda R. O., 2001, PATTERN CLASSIFICATI; Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316; FINNOFF W, 1993, NEURAL NETWORKS, V6, P771, DOI 10.1016/S0893-6080(05)80122-4; Girosi F, 1998, NEURAL COMPUT, V10, P1455, DOI 10.1162/089976698300017269; Gunn S.R., 1998, SUPPORT VECTOR MACHI; Haykin S., 2001, NEURAL NETWORKS COMP; HE X, 2005, TENSOR SUBSPACE ANAL; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; Lu K, 2006, PATTERN RECOGN, V39, P717, DOI 10.1016/j.patcog.2005.11.009; MICCHELLI CA, 2005, MACH LEARN RES, V6, P109; NG WWY, 2005, P INT C MACH LEARN C; Ng WWY, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P4283; NG WWY, 2003, IEE ELECT LETT, V39, P787; Ng WWY, 2004, IEEE SYS MAN CYBERN, P3692, DOI 10.1109/ICSMC.2004.1400917; NG WWY, 2007, PATTER RECOGNITION, V40, P4; Ng WWY, 2005, IEEE SYS MAN CYBERN, P889; Nocedal J., 2000, NUMERICAL OPTIMIZATI; PARTRICK PK, 2005, IEEE P INT C SYST MA, P3604; Pelckmans K, 2006, MACH LEARN, V62, P217, DOI 10.1007/s10994-005-5315-x; PELCKMANS K, 2005, THESIS FACULTY ENG K; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; POGGIO T, 1990, SCIENCE, V247, P978, DOI 10.1126/science.247.4945.978; Prechelt L, 1998, LECT NOTES COMPUT SC, V1524, P55; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; RUDIN W., 1976, PRINCIPLES MATH ANAL; TIKHONOV AN, 1963, DOKL AKAD NAUK SSSR+, V151, P501; TIKHONOV AN, 1977, SOLUTIONS III POSED; Vapnik VN, 1998, STAT LEARNING THEORY; YEUNG DS, 2005, SICE ANN C JAP	36	1	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	MAY	2008	41	5					1479	1490		10.1016/j.patcog.2007.09.016		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	272FQ	WOS:000253845700005	
J	Lopez, FJA; Balboa, JLG				Ariza Lopez, Francisco Javier; Garcia Balboa, Jose Luis			Generalization-oriented road line segmentation by means of an artificial neural network applied over a moving window	PATTERN RECOGNITION			English	Article						artificial neural network; cartographic generalization; knowledge acquisition; line segmentation; machine learning	MAP GENERALIZATION; BOUNDARY SIMPLIFICATION; PLANAR CURVES; ELIMINATION; MULTISCALE; ALGORITHM; FEATURES	In line generalization, results depend very much on the characteristics of the line. For this reason it would be useful to obtain an automatic segmentation and enrichment of lines in order to apply to each section the best algorithm and the appropriate parameter. In this paper we present a methodology for applying a line-classifying backpropagation artificial neural network (BANN) for a line segmentation task. The procedure is based on the use of a moving window along the line to detect changes in the sinuosity and directionality of the line. A summary of the BANN design is presented, and a test is performed over a set of roads from a 1:25k scale map with a recommendation of the value of the parameters of the moving window. Segmentation results were assessed by an independent group of experts; a summary of the evaluation procedure is shown. (c) 2007 Elsevier Ltd. All rights reserved.	[Ariza Lopez, Francisco Javier; Garcia Balboa, Jose Luis] Univ Jaen, Grp Invest Ingn Cartograf, Jaen 23071, Spain	Balboa, JLG (reprint author), Univ Jaen, Grp Invest Ingn Cartograf, Jaen 23071, Spain.	jlbalboa@ujaen.es	Garcia Balboa, Jose Luis/G-4416-2010				Allouche M. K., 2005, INT J GEOGR INF SCI, V19, P957; ALLOUCHE MK, 2002, GEN REPRESENTATION M, P337; Ariza F. J., 2002, CALIDAD PRODUCCION C; ARIZA FJ, 2004, MAPPING, V97, P52; Balboa JLG, 2008, GEOINFORMATICA, V12, P289, DOI 10.1007/s10707-007-0026-z; Balboa JLG, 2000, CARTOGR J, V37, P39; BALBOA JLG, 2006, THESIS U JAEN SPAIN; BARBER C, 1995, CARTOGRAPHY GEOGRAPH, V22, P276, DOI 10.1559/152304095782540230; BARILLOT X, 2002, GENERALISATION REPRE, P203; BERNHARDT MC, 1992, 425 DEP GEOD SCI SUR; BURGHARDT D, 2002, ISPRS ICA WORKSH MUL; Burghardt D, 2005, GEOINFORMATICA, V9, P237, DOI 10.1007/s10707-005-1283-3; Buttenfield B. P., 1991, MAP GENERALIZATION M, P150; Cheung CK, 2006, COMPUT GEOSCI-UK, V32, P462, DOI 10.1016/j.cageo.2005.08.002; Congalton R. G., 1998, ASSESSING ACCURACY R; Dutton GH, 1999, CARTOGRAPHY GEOGRAPH, V26, P33, DOI 10.1559/152304099782424929; GARCIA JA, 1994, COMPUT GEOSCI, V20, P349, DOI 10.1016/0098-3004(94)90046-9; Garrido A, 1998, PATTERN RECOGN, V31, P791, DOI 10.1016/S0031-3203(97)00104-0; GEISSER S, 1975, J AM STAT ASSOC, V70, P320, DOI 10.2307/2285815; Hilera JR, 1995, REDES NEURONALES ART; JASINSKI MJ, 1990, 901 NAT CTR GEOGR IN; Kolesnikov A, 2005, PATTERN RECOGN, V38, P381, DOI 10.1016/j.patcog.2004.07.005; Kulik L, 2005, J VISUAL LANG COMPUT, V16, P245, DOI 10.1016/j.jvlc.2005.02.001; Lecordix F, 1997, GEOINFORMATICA, V1, P161, DOI 10.1023/A:1009736628698; LI Z, 2007, ALGORITHMIC FDN MULT; Li ZL, 2007, CARTOGR J, V44, P80, DOI 10.1179/000870407X173913; Li ZL, 2002, CARTOGR J, V39, P153; Li ZL, 2000, CARTOGR J, V37, P29; Mackaness W, 2006, CARTOGR J, V43, P144, DOI 10.1179/000870406X114630; MCMASTER RB, 1995, GIS GENERALIZATION; MCMASTER RB, 1986, AM CARTOGRAPHER, V13, P103; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34; MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591; MULLER JC, 1986, CARTOGR J, V23, P123; Mustiere S, 2005, INT J GEOGR INF SCI, V19, P937, DOI [10.1080/13658810509161245, 10.1080/136588105099161245]; MUSTIERE S, 1995, MESURES QUALITE GENE; PLAZANET C, 1997, GEOGRAPHIC INFORM RE, P264; Plazanet C., 1998, GeoInformatica, V2, DOI 10.1023/A:1009753320636; Plazanet C, 1995, CARTOGR GEOGR INF SC, V22, P291, DOI 10.1559/152304095782540276; PLAZANET C, 1996, THESIS U MARNE VALLE; PLAZANET C, 1995, P AUTOCARTO 12, V4, P59; RICHARDSON E, 1999, CARTOGRAPHY GEOGRAPH, V26, P3; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Ruas A, 1998, INT J GEOGR INF SCI, V12, P789, DOI 10.1080/136588198241509; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1, P318; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; SARLE WS, 1997, NEURAL NETWOSK FAQ; Saux E, 2003, CARTOGRAPHY GEOGRAPH, V30, P33, DOI 10.1559/152304003100010938; Sester M, 2005, INT J GEOGR INF SCI, V19, P871, DOI 10.1080/13658810500161179; Shi WZ, 2006, CARTOGR J, V43, P27, DOI 10.1179/000870406X93490; Skopeliti A., 1999, CARTOGRAPHICA, V36, P53, DOI 10.3138/J473-P3U0-197J-3602; SPIESS E, 2005, MAP GRAPHICS GENERAL; van der Poorten PM, 2002, INT J GEOGR INF SCI, V16, P773, DOI 10.1080/13658810210149434; Veregin H., 1999, CARTOGRAPHICA, V36, P25, DOI 10.3138/D7R4-M1M7-6632-73X1; Visvalingam M, 1995, CARTOGRAPHY GEOGRAPH, V22, P264, DOI 10.1559/152304095782540249; VISVALINGAM M, 1993, CARTOGR J, V30, P46; Wang Z., 1998, CARTOGRAPHY GEOGRAPH, V25, P3, DOI 10.1559/152304098782441750; Werbos P., 1974, THESIS HARVARD U; Werbos P. J., 1994, ROOTS BACKPROPAGATIO; WERSCHLEIN T, 1994, P EGIS 94 PAR, P76; ZHAN B, 1996, CARTOGRAPHY GEOGR IN, V23, P206, DOI 10.1559/152304096782438800; *AGENT, 1999, C1 D PROJ AGENT; [Anonymous], 2005, 20462 ISO; *EUR GEN PROC, 2005, BENCHM STUD EXP GROU	64	1	1	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	MAY	2008	41	5					1593	1609		10.1016/j.patcog.2007.11.009		17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	272FQ	WOS:000253845700015	
J	Lopez, F; Valiente, JM; Prats, JM; Ferrer, A				Lopez, Fernando; Valiente, Jose Miguel; Prats, Jose Manuel; Ferrer, Alberto			Performance evaluation of soft color texture descriptors for surface grading using experimental design and logistic regression	PATTERN RECOGNITION			English	Article						surface grading; automatic inspection; experimental design; logistic regression; color; texture; feature selection; wrapper techniques	INDUSTRY	This paper presents a novel approach to the question of surface grading, the soft color texture descriptors method. This method is extracted from an extensive evaluation process of several factors based on the use of two well established statistical tools: experimental design and logistic regression. The utility of different combinations of factors is evaluated in regard to the problem of automatic classification of materials such as ceramic tiles that need to be grouped according to homogeneous visual appearance, that is, the surface grading application. The set of factors includes the number of neighbors in the k-NN classifier (several values of k parameter), color space representation schemes (CIE Lab, CIE Luv, RGB, and grayscale), and color texture features (mean, standard deviation, 2nd-5th histogram moments). A factorial experimental design is performed testing all combinations of the above factors on a large image database of ceramic tiles. Accuracy estimates are computed using logistic regression to determine the best combinations of factors. From the point of view of machine learning the overall process conforms a wrapper approach able to select significant design choices (k parameter in k-NN classifier and color space) and carry out a feature selection within the set of color texture features at the same time. Experiments were repeated with alternate color texture schemes from the literature: color histograms and centile-LBP. Comparisons of methods are presented describing both accuracy estimates and runtimes. (c) 2007 Elsevier Ltd. All rights reserved.	[Lopez, Fernando; Valiente, Jose Miguel] Univ Politecn Valencia, DISCA, Dept Comp Engn, Valencia 46022, Spain; [Prats, Jose Manuel; Ferrer, Alberto] Univ Politecn Valencia, DEIOAC, Dept Appl Stat Operat Res & Qual, Valencia 46022, Spain	Lopez, F (reprint author), Univ Politecn Valencia, DISCA, Dept Comp Engn, Camino Vera S-N, Valencia 46022, Spain.	flopez@disca.upv.es	Lopez-Garcia, Fernando/G-9543-2013	Lopez-Garcia, Fernando/0000-0002-2079-1589			BALDRICH R, 1999, EUROPTO SPIE C COL P; Boukouvalas C, 1999, IEEE T IND ELECTRON, V46, P219, DOI 10.1109/41.744415; Box G. E., 2005, STAT EXPT DESIGN INN; Christensen Ronald, 1997, LOG LINEAR MODELS LO; Duda R. O., 2001, PATTERN CLASSIFICATI; Gonzalez R., 1987, DIGITAL IMAGE PROCES; KAUPPINEN H, 1999, THESIS OULU U; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kukkonen S, 2001, OPT ENG, V40, P170, DOI 10.1117/1.1339877; KYLLONEN J, 2000, P IAPR WORKSH MACH V; LEBRUM V, 2001, 5 INT C QUAL CONTR A; LUMBRERAS F, 2001, 5 INT C QUAL CONTR A; Mahy M., 1994, Color Research & Application, V19; Montgomery D. C., 2005, DESIGN ANAL EXPT; Penaranda JA, 1997, P SOC PHOTO-OPT INS, V3101, P182, DOI 10.1117/12.281279; Prats-Montalban JM, 2007, J CHEMOMETR, V21, P10, DOI 10.1002/cem.1026; Tran QL, 2005, IEEE T SYST MAN CY B, V35, P1079, DOI 10.1109/TSMCB.2005.847745; Wyszecki G, 1982, COLOR SCI CONCEPTS M	18	8	8	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	MAY	2008	41	5					1744	1755		10.1016/j.patcog.2007.09.011		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	272FQ	WOS:000253845700025	
J	Tang, YR; Sheng, ZY; Chen, YZ; Zhang, ZD				Tang, Yu-Rong; Sheng, Zhi-Ya; Chen, Yong-Zi; Zhang, Ziding			An improved prediction of catalytic residues in enzyme structures	PROTEIN ENGINEERING DESIGN & SELECTION			English	Article						catalytic residues; closeness centrality; genetic algorithm; neural network; prediction	ACTIVE-SITES; GENETIC ALGORITHM; NEURAL-NETWORK; PROTEIN STRUCTURES; SEQUENCES; FAMILIES; CENTRALITY; EVOLUTION; LOCATION	The protein databases contain a huge number of function unknown proteins, including many proteins with newly determined 3D structures resulted from the Structural Genomics Projects. To accelerate experiment-based assignment of function, de novo prediction of protein functional sites, like active sites in enzymes, becomes increasingly important. Here, we attempted to improve the prediction of catalytic residues in enzyme structures by seeking and refining different encodings (i.e. residue properties) as well as employing new machine learning algorithms. In particular, considering that catalytic residues can often reveal specific network centrality when representing enzyme structure as a residue contact network, the corresponding measurement (i.e. closeness centrality) was used as one of the most important encodings in our new predictor. Meanwhile, a genetic algorithm integrated neural network (GANN) was also employed. Thanks to the above strategies, our GANN predictor demonstrated a high accuracy of 91.2% in the prediction of catalytic residues based on balanced datasets (i.e. the 1: 1 ratio of catalytic to non-catalytic residues). When the GANN method was optimally applied to real enzyme structures, 73.9% of the tested structures had the active site correctly located. Compared with two existing methods, the proposed GANN method also demonstrated a better performance.	[Tang, Yu-Rong; Sheng, Zhi-Ya; Chen, Yong-Zi; Zhang, Ziding] China Agr Univ, Bioinformat Ctr, Coll Biol Sci, Beijing 100094, Peoples R China	Zhang, ZD (reprint author), China Agr Univ, Bioinformat Ctr, Coll Biol Sci, Beijing 100094, Peoples R China.	zidingzhang@cau.edu.cn	Zhang, Ziding/E-9320-2011				ALTSCHUL SF, 1997, NUCLEIC ACIDS RES, V25, P3402; Amitai G, 2004, J MOL BIOL, V344, P1135, DOI 10.1016/j.jmb.2004.10.055; BAGLEY SC, 1995, PROTEIN SCI, V4, P622; Bartlett GJ, 2002, J MOL BIOL, V324, P105, DOI 10.1016/S0022-2836(02)01036-7; Bate P, 2004, J MOL BIOL, V340, P263, DOI 10.1016/j.jmb.2004.04.070; Ben-Shimon A, 2005, J MOL BIOL, V351, P309, DOI 10.1016/j.jmb.2005.06.047; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Brenner SE, 2001, NAT REV GENET, V2, P801, DOI 10.1038/35093574; Carter P, 2003, NUCLEIC ACIDS RES, V31, P3293, DOI 10.1093/nar/gkg626; CHANG CC, 2001, COMPUTER PROGRAM; Chea E, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-153; Cho SB, 1999, FUZZY SET SYST, V103, P339, DOI 10.1016/S0165-0114(98)00232-2; Chou KC, 2004, PROTEINS, V55, P77, DOI 10.1002/prot.10622; del Rio G, 2001, FEBS LETT, V509, P230, DOI 10.1016/S0014-5793(01)03165-9; del Sol A, 2006, PROTEIN SCI, V15, P2120, DOI 10.1110/ps.062249106; Fish KE, 2004, J BUS RES, V57, P79, DOI 10.1016/S0148-2963(02)00287-4; Goyal K, 2007, NUCLEIC ACIDS RES, V35, pW503, DOI 10.1093/nar/gkm252; Greene LH, 2003, J MOL BIOL, V334, P781, DOI 10.1016/j.jmb.2003.08.061; Gutteridge A, 2003, J MOL BIOL, V330, P719, DOI 10.1016/S0022-2836(03)00515-1; Hubbard SJ, 1993, COMPUTER PROGRAM; Ko J, 2005, BIOINFORMATICS S1, V21, pi258; LASKOWSKI RA, 1995, J MOL GRAPHICS, V13, P323, DOI 10.1016/0263-7855(95)00073-9; Li WZ, 2006, BIOINFORMATICS, V22, P1658, DOI 10.1093/bioinformatics/btl158; Liang SD, 2006, NUCLEIC ACIDS RES, V34, P3698, DOI 10.1093/nar/gkl454; MCDONALD IK, 1994, J MOL BIOL, V238, P777, DOI 10.1006/jmbi.1994.1334; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; Nagano N, 2002, J MOL BIOL, V321, P741, DOI 10.1016/S0022-2836(02)00649-6; Ofran Y, 2005, DRUG DISCOV TODAY, V10, P1475, DOI 10.1016/S1359-6446(05)03621-4; Ofran Y, 2007, BIOINFORMATICS, V23, pE13, DOI 10.1093/bioinformatics/btl303; Orengo CA, 1999, CURR OPIN STRUC BIOL, V9, P374, DOI 10.1016/S0959-440X(99)80051-7; Petrova NV, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-312; Porter CT, 2004, NUCLEIC ACIDS RES, V32, pD129, DOI 10.1093/nar/gkh028; Rost B, 2002, J MOL BIOL, V318, P595, DOI 10.1016/S0022-2836(02)00016-5; Shapiro L, 2000, CURR OPIN BIOTECH, V11, P31, DOI 10.1016/S0958-1669(99)00064-6; Tang YR, 2007, PROTEIN ENG DES SEL, V20, P405, DOI 10.1093/protein/gzm035; Tian WD, 2003, J MOL BIOL, V333, P863, DOI 10.1016/j.jmb.2003.08.057; Todd AE, 2001, J MOL BIOL, V307, P1113, DOI 10.1006/jmbi.2001.4513; Torrance JW, 2005, J MOL BIOL, V347, P565, DOI 10.1016/j.jmb.2005.01.044; Tseng YY, 2007, ANN BIOMED ENG, V35, P1037, DOI 10.1007/s10439-006-9241-2; Valdar WSJ, 2002, PROTEINS, V48, P227, DOI 10.1002/prot.10146; Youn E, 2007, PROTEIN SCI, V16, P216, DOI 10.1110/ps.062523907; Yuan Z, 2003, PROTEIN ENG, V16, P109, DOI 10.1093/proeng/gzg014; Zhang ZD, 2007, PROTEIN PEPTIDE LETT, V14, P291, DOI 10.2174/092986607780090775; Zhang ZD, 2006, PROTEINS, V62, P470, DOI 10.1002/prot.20752	44	24	24	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1741-0126		PROTEIN ENG DES SEL	Protein Eng. Des. Sel.	MAY	2008	21	5					295	302		10.1093/protein/gzn003		8	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology	290XH	WOS:000255156400003	
J	Argamon, S; Dodick, J; Chase, P				Argamon, Shlomo; Dodick, Jeff; Chase, Paul			Language use reflects scientific methodology: A corpus-based study of peer-reviewed journal articles	SCIENTOMETRICS			English	Article							TEXT CATEGORIZATION; HISTORICAL SCIENCE; EVOLUTION; GEOLOGY; AUTHOR	Recently, philosophers of science have argued that the epistemological requirements of different scientific fields lead necessarily to differences in scientific method. In this paper, we examine possible variation in how language is used in peer-reviewed journal articles from various fields to see if features of such variation may help to elucidate and support claims of methodological variation among the sciences. We hypothesize that significant methodological differences will be reflected in related differences in scientists' language style. This paper reports a corpus-based study of peer-reviewed articles from twelve separate journals in six fields of experimental and historical sciences. Machine learning methods were applied to compare the discourse styles of articles in different fields, based on easily-extracted linguistic features of the text. Features included function word frequencies, as used often in computational stylistics, as well as lexical features based on systemic functional linguistics, which affords rich resources for comparative textual analysis. We found that indeed the style of writing in the historical sciences is readily distinguishable from that of the experimental sciences. Furthermore, the most significant linguistic features of these distinctive styles are directly related to the methodological differences posited by philosophers of science between historical and experimental sciences, lending empirical weight to their contentions.	[Argamon, Shlomo; Chase, Paul] IIT, Dept Comp Sci, Chicago, IL 60616 USA; [Dodick, Jeff] Hebrew Univ Jerusalem, Dept Sci Teaching, Jerusalem, Israel	Argamon, S (reprint author), IIT, Dept Comp Sci, Chicago, IL 60616 USA.	argamon@iit.edu					ABRAMS E, 1995, J RES SCI TEACH, V32, P643; Argamon S., 2003, TEXT, V23, P321, DOI DOI 10.1515/TEXT.2003.014; ARGAMON S, 1998, P INT WORKSH INN INT; ARGAMON S, 2003, P ACM C KNOWL DISC D; Argamon S, 2007, J AM SOC INF SCI TEC, V58, P802, DOI 10.1002/asi.20553; Argamon-Engelson S., 1998, P AAAI WORKSH LEARN, P1; BAAYEN RH, 1996, LIT LINGUISTIC COMPU, V7, P91; Baker VR, 1996, GEOMORPHOLOGY, V16, P197, DOI 10.1016/S0169-555X(96)80001-8; BAZERMAN C, 2004, J INTERDISCIPLINARY, V1; BAZERMAN C, 2005, MULTIDISCIPLINARY PE; Biber D, 1995, DIMENSIONS REGISTER; BONDROBINSON J, 2005, P 27 ANN COGN SCI SO; BRUNN M, 2001, P 24 ANN INT ACM SIG; CHRISTIANNI N, 2000, INTRO SUPPORT VECTOR; Cleland CE, 2001, GEOLOGY, V29, P987, DOI 10.1130/0091-7613(2001)029<0987:HSESAT>2.0.CO;2; CLELAND CE, 2002, PHILOS SCI; Cooper R. A., 2002, AM BIOL TEACH, P64476; Cooper RA, 2004, AM BIOL TEACH, V66, P101, DOI 10.1662/0002-7685(2004)066[0101:HEBRHP]2.0.CO;2; CRONIN B, 1994, J AM SOC INFORM SCI, V45, P61, DOI 10.1002/(SICI)1097-4571(199403)45:2<61::AID-ASI1>3.0.CO;2-F; Cronin B., 2005, HAND SCI ACAD WRITIN; Dagan I, 1997, P 2 C EMP METH NAT L, P55; Diamond J., 2002, GUNS GERMS STEEL FAT; DIMITROVA M, 2002, P C HUM FACT COMP SY; Dodick J., 2003, SCI ED, V12, P197, DOI DOI 10.1023/A:1023096001250; Dunbar K, 2001, DESIGNING FOR SCIENCE, P115; Dunbar K., 1995, MECH INSIGHT, P365; Dunbar K, 1999, MODEL BASED REASONIN; Dunbar K, 2001, TRENDS COGN SCI, V5, P334, DOI 10.1016/S1364-6613(00)01698-3; FINN A, 2002, P ECIR 02 24 EUR C I; FRODEMAN R, 1995, GEOL SOC AM BULL, V107, P960, DOI 10.1130/0016-7606(1995)107<0960:GRGAAI>2.3.CO;2; FUJIMURA JH, 1987, SOC STUD SCI, V17, P257, DOI 10.1177/030631287017002003; Gilbertson Michael K., 1992, SIGNS GENRES COMMUNI; GOODWIN C, 1994, AM ANTHROPOL, V96, P606, DOI 10.1525/aa.1994.96.3.02a00100; GOODWIN C, 1995, SOC STUD SCI, V25, P237, DOI 10.1177/030631295025002002; GOULD SJ, 1986, AM SCI, V74, P60; GRAHAM N, 2003, WORKSH COMP APPR STY; Grossman D. A., 2004, INFORM RETRIEVAL ALG; Halliday M. A. K., 1976, COHESION ENGLISH; Halliday M. A. K., 1993, WRITING SCI LITERACY; Halliday M.A.K., 1994, INTRO FUNCTIONAL GRA; HARABAGIU S, 1999, J PATTERN RECOGNITIO, V13, P247; HARRIS J, 1989, COLL COMPOS COMMUN, V40, P11, DOI 10.2307/358177; HASAN R, 1988, LANGUAGE SOCIALISATI; HERKECOUCHMAN M, 2004, P AAAI SPRING S EXPL; Holmes D. I., 1998, Literary & Linguistic Computing, V13, DOI 10.1093/llc/13.3.111; HOVY EH, 1993, INTENTIONALITY STRUC, P35; Hull David L., 1973, DARWIN HIS CRITICS R; Hyland K., 2000, DISCIPLINARY DISCOUR; Joachims T., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings; Kelly GJ, 2003, APPL LINGUIST, V24, P28, DOI 10.1093/applin/24.1.28; Kitcher P., 1993, ADV SCI; Koppel M., 2002, Literary & Linguistic Computing, V17, DOI 10.1093/llc/17.4.401; Lang K., 1995, P 12 INT C MACH LEAR, P331; Latour B., 1986, LAB LIFE CONSTRUCTIO; LEWIN BA, 1986, EXPOSITORY DISCOURSE; Lewis D. D., 1998, P 10 EUR C MACH LEAR, P4; MacRoberts MH, 1996, SCIENTOMETRICS, V36, P435, DOI 10.1007/BF02129604; Mann W., 1988, TEXT, V8, P243; Marcu D, 2000, COMPUT LINGUIST, V26, P395, DOI 10.1162/089120100561755; MATTHEWS RAJ, 1997, HDB NEURAL COMPUTATI, pCH8; MATTHIESSEN C, 1992, LEXICOGRAMMATICAL CA; Barzilay R, 1999, ADVANCES IN AUTOMATIC TEXT SUMMARIZATION, P111; Mayr E., 1976, EVOLUTION DIVERSITY; Mayr E., 1985, EVOLUTION CROSSROADS, P43; MOSTELLER F, 1964, INFERENCE DISPUTED A; MULKAY N, 1983, CAN J SOCIOL, V8, P179; Myers G., 1990, WRITING BIOL TEXTS S; National Research Council, 1996, NAT SCI ED STAND; Nersessian NJ, 2005, SCIENTIFIC AND TECHNOLOGICAL THINKING, P17; Ochs E., 1994, CONFIGURATIONS, V2, P151, DOI 10.1353/con.1994.0003; Ochs E, 1997, LANG SOC, V26, P479; Okada T, 1997, COGNITIVE SCI, V21, P109, DOI 10.1016/S0364-0213(99)80020-2; Platt J., 1998, MSRTR9814; PLUM G, 1987, LANGUAGE TOPICS, V2; Rudolph JL, 1998, J RES SCI TEACH, V35, P1069, DOI 10.1002/(SICI)1098-2736(199812)35:10<1069::AID-TEA2>3.3.CO;2-1; RUDWICK MJS, 1998, SPECIAL PUBLICATIONS, V143, P3; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Sober E, 1993, PHILOS BIOL; Stamatatos E, 2000, COMPUT LINGUIST, V26, P471, DOI 10.1162/089120100750105920; STUCKY AP, 2004, P NAT ASS RES SCI TE; Swales J. M., 1990, GENRE ANAL; TEUFEL S, 1998, P AAAI SPRING S INT; Teufel S, 2002, COMPUT LINGUIST, V28, P409, DOI 10.1162/089120102762671936; Whewell William, 1837, HIST INDUCTIVE SCI, V3, P517; WHITE HD, 1989, ANNU REV INFORM SCI, V24, P119; White HD, 1998, J AM SOC INFORM SCI, V49, P327, DOI 10.1002/(SICI)1097-4571(19980401)49:4<327::AID-ASI4>3.0.CO;2-4; WHITELAW C, 2005, P ACM C INF KNOWL MA; Whitelaw C., 2004, P AAAI FALL S STYL M; Wiebe J. M., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); Witten I. H., 2000, DATA MINING PRACTICA; Yule G., 1938, BIOMETRIKA, V30, P363; *AM ASS ADV SCI, 1990, BENCHM SCI LIT; [Anonymous], 2003, P 7 C NAT LANG LEARN	93	5	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0138-9130		SCIENTOMETRICS	Scientometrics	MAY	2008	75	2					203	238		10.1007/s11192-007-1768-y		36	Computer Science, Interdisciplinary Applications; Information Science & Library Science	Computer Science; Information Science & Library Science	290AL	WOS:000255094900002	
J	Massey, L				Massey, Louis			Soft-clustering and improved stability for adaptive resonance theory neural networksication	SOFT COMPUTING			English	Article; Proceedings Paper	4th International Symposium on Neural Networks (ISNN 2007)	JUN 03-07, 2007	Nanjing, PEOPLES R CHINA	Natl Nat Sci Fdn China, KC Wong Educ Fdn, SE Univ China, Chinese Univ Hong Kong, Univ Illinois, Chicago		adaptive resonance theory; stable learning; neural networks; machine learning	TEXT CATEGORIZATION	Stability and plasticity in learning systems are both equally essential, but achieving stability and plasticity simultaneously is difficult. Adaptive resonance theory (ART) neural networks are known for their plastic and stable learning of categories, hence providing an answer to the so called stability-plasticity dilemma. However, it has been demonstrated recently that contrary to general belief, ART stability is not possible with infinite streaming data. In this paper, we present an improved stabilization strategy for ART neural networks that does not suffer from this problem and that produces a soft-clustering solution as a positive side effect. Experimental results in a task of text clustering demonstrate that the new stabilization strategy works well, but with a slight loss in clustering quality compared to the traditional approach. For real-life intelligent applications in which infinite streaming data is generated, the stable and soft-clustering solution obtained with our approach more than outweighs the small loss in quality.	Royal Mil Coll Canada, Dept Math & Comp Sci, Kingston, ON K7K 7B4, Canada	Massey, L (reprint author), Royal Mil Coll Canada, Dept Math & Comp Sci, Kingston, ON K7K 7B4, Canada.	massey@rmc.ca					Carpenter GA, 1995, HDB BRAIN THEORY NEU; CARPENTER GA, 1998, P SPIES 12 ANN S AER; CAUDELL T, 1991, BCSCSACS91001; Cleverdon C., 1984, Information Services & Use, V4; GEORGIOPOULOS M, 1990, NEURAL COMPUT, V2, P502, DOI 10.1162/neco.1990.2.4.502; GROSSBERG S, 1976, BIOL CYBERN, V23, P121, DOI 10.1007/BF00344744; KONDADADI R, 2002, P INT JOINT C NEUR N; Larsen B., 1999, P 5 ACM SIGKDD INT C, P16, DOI 10.1145/312129.312186; APTE C, 1994, ACM T INFORM SYST, V12, P233, DOI 10.1145/183422.183423; MASSEY L, 2002, P REC ADV SOFT COMP; Massey L., 2005, P 2005 IASTED INT C; MASSEY L, 2005, P 2005 INT JOINT C N; Massey L, 2003, NEURAL NETWORKS, V16, P771, DOI 10.1016/S0893-6080(03)00088-1; Moore B., 1988, P 1988 CONN MOD SUMM, P174; SALTON G, 1968, J ACM, V15, P8, DOI 10.1145/321439.321441; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; van Rijsbergen C. J., 1979, INFORM RETRIEVAL; Yang Yiming, 1997, P 14 INT C MACH LEAR, P412	18	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	1432-7643		SOFT COMPUT	Soft Comput.	MAY	2008	12	7					657	665		10.1007/s00500-007-0244-1		9	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	265II	WOS:000253351900007	
J	Nederhof, MJ; Satta, G				Nederhof, Mark-Jan; Satta, Giorgio			Computation of distances for regular and context-free probabilistic languages	THEORETICAL COMPUTER SCIENCE			English	Article						probabilistic context-free languages; probabilistic finite automata; probabilistic language distances; language entropy; Kullback-Leibler divergence	FREE GRAMMARS; RELATIVE ENTROPY; MODELS	Several mathematical distances between probabilistic languages have been investigated in the literature, motivated by applications in language modeling, computational biology, syntactic pattern matching and machine learning. In most cases, only pairs of probabilistic regular languages were considered. In this paper we extend the previous results to pairs of languages generated by a probabilistic context-free grammar and a probabilistic finite automaton. (c) 2008 Elsevier B.V All rights reserved.	[Satta, Giorgio] Univ Padua, Dept Informat Engn, I-35131 Padua, Italy; [Nederhof, Mark-Jan] Univ St Andrews, Sch Comp Sci, St Andrews KY16 9SX, Fife, Scotland	Satta, G (reprint author), Univ Padua, Dept Informat Engn, Via Gradenigo 6-A, I-35131 Padua, Italy.	satta@dei.unipd.it					ABNEY S, 1999, 37 ANN M ASS COMP LI; Aho A., 1974, DESIGN ANAL COMPUTER; BAKER J, 1979, 97 M AC SOC AM; Bar-Hillel Y., 1964, LANGUAGE INFORMATION, P116; BOOTH TL, 1973, IEEE T COMPUT, VC 22, P442, DOI 10.1109/T-C.1973.223746; Calera-Rubio J, 1998, INFORM PROCESS LETT, V68, P283, DOI 10.1016/S0020-0190(98)00172-0; Carrasco RC, 1997, RAIRO-INF THEOR APPL, V31, P437; Charniak E., 1993, STAT LANGUAGE LEARNI; Chi ZY, 1999, COMPUT LINGUIST, V25, P131; CORAZZA A, 1991, IEEE T PATTERN ANAL, V13, P936, DOI 10.1109/34.93811; CORAZZA A, 1994, IEEE T PATTERN ANAL, V16, P1018, DOI 10.1109/34.329008; Cormen Thomas H., 1990, INTRO ALGORITHMS; CORTES C, 2006, LATIN 2006; CORTES C, 2006, LECT NOTES COMPUTER, V4094; Duda R. O., 2001, PATTERN CLASSIFICATI; Durbin R., 1999, BIOL SEQUENCE ANAL P; ETESSAMI K, 2005, LECT NOTES COMPUTER, V3404; Gregory B., 1988, SIGSAM Bulletin, V22; Grenander U., 1976, LECT PATTERN THEORY, V1; Harris T. E., 1963, THEORY BRANCHING PRO; Hopcroft J., 1979, INTRO AUTOMATA THEOR; HUTCHINS SE, 1972, INFORM SCIENCES, V4, P179, DOI 10.1016/S0020-0255(72)80010-0; Jelinek F., 1991, Computational Linguistics, V17; Jelinek F., 1997, STAT METHODS SPEECH; Jurafsky D., 2000, SPEECH LANGUAGE PROC; KELLEY CT, 1995, ITERATIVE METHODS LI; Lewis H., 1981, ELEMENTS THEORY COMP; Lyngso RB, 2002, J COMPUT SYST SCI, V65, P545, DOI 10.1016/S0022-0000(02)00009-0; Manning C. D., 1999, FDN STAT NATURAL LAN; Nederhof MJ, 2003, COMPUT LINGUIST, V29, P135, DOI 10.1162/089120103321337467; Nederhof MJ, 2005, COMPUT LINGUIST, V31, P173, DOI 10.1162/0891201054223986; NEDERHOF MJ, 2003, 8 INT WORKSH PARS TE; NEDERHOF MJ, 2008, COMPUTING PART UNPUB; Paz A., 1971, INTRO PROBABILISTIC; SANTOS ES, 1972, INFORM CONTROL, V21, P27, DOI 10.1016/S0019-9958(72)90026-5; SIPPU S, 1988, EATCS MONOGRAPHS THE, V15; SOULE S, 1974, INFORM CONTROL, V25, P57, DOI 10.1016/S0019-9958(74)90799-2; Starke P, 1972, ABSTRACT AUTOMATA; STOLCKE A, 1995, COMPUTTIONAL LINGUIS, V21, P167; Vidal E, 2005, IEEE T PATTERN ANAL, V27, P1013, DOI 10.1109/TPAMI.2005.147; Wojtczak D, 2007, LECT NOTES COMPUT SC, V4424, P66	41	3	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3975		THEOR COMPUT SCI	Theor. Comput. Sci.	MAY 1	2008	395	2-3					235	254		10.1016/j.tcs.2008.01.010		20	Computer Science, Theory & Methods	Computer Science	323RR	WOS:000257466600008	
J	Mittermayr, S; Olajos, M; Chovan, T; Bonn, GK; Guttman, A				Mittermayr, S.; Olajos, M.; Chovan, T.; Bonn, G. K.; Guttman, A.			Mobility modeling of peptides in capillary electrophoresis	TRAC-TRENDS IN ANALYTICAL CHEMISTRY			English	Article						artificial neural network; capillary electrophoresis; electrophoretic mobility; machine-learning; mobility modeling; multi-variable modeling; peptide; proteomics; semi-empirical modeling	PROPERTY RELATIONSHIP MODEL; ZONE-ELECTROPHORESIS; PHYSICOCHEMICAL PROPERTIES; THEORETICAL SIMULATION; MASS-SPECTROMETRY; PROTEINS; CHARGE; SIZE; SEPARATION; PREDICTION	Recent rapid developments in proteomics require high-resolution separation of a large number of peptides for their downstream identification by mass spectrometry. Capillary electrophoresis (CE) is an electric-field-mediated bioanalytical technique capable of rapid, high-resolution separation of very complex sample mixtures. Development of CE methods for adequate separation of a large number of peptides is usually a time-consuming task. Application of model-based approaches to predict peptide mobilities in CE from known physicochemical properties can shorten tedious experimental optimization of separation. This endeavor requires specification of structural descriptors followed by selection of appropriate modeling methods. To date, numerous theoretical predictive models have been developed, mostly based on Stokes' Law to relate peptide mobilities to structural properties (e.g., charge and size). However, these two-variable models could not successfully predict electrophoretic mobilities for all categories of peptides with a reasonable degree of accuracy. To address the shortcomings of the two-variable models, new strategies were recently introduced, including the usage of additional peptide descriptors or applying non-linear modeling (e.g., artificial neural networks), to attain more accurate, robust prediction. Effective application of machine-learning techniques to the development of predictive models has consolidated conjecture on non-linear relationships between peptide structural descriptors and their electrophoretic mobilities. In this article, we review recent advances in CE mobility modeling of peptides, particularly in respect to predicting optimal separation conditions for the analysis of highly complex peptide mixtures in proteomics applications. (C) 2008 Elsevier Ltd. All rights reserved.	[Mittermayr, S.] Univ Hlth Sci, Hall In Tirol, Austria; [Mittermayr, S.; Olajos, M.; Bonn, G. K.; Guttman, A.] Univ Innsbruck, Inst Analyt Chem & Radiochem, Horvath Lab Bioseparat Sci, A-6020 Innsbruck, Austria; [Olajos, M.] Univ Pannonia, Dept Analyt Chem, Veszprem, Hungary; [Chovan, T.] Univ Pannonia, Dept Proc Engn, Veszprem, Hungary	Mittermayr, S (reprint author), Univ Hlth Sci, Hall In Tirol, Austria.	andras.guttman@uibk.ac.at					ADAMSON NJ, 1995, ELECTROPHORESIS, V16, P525, DOI 10.1002/elps.1150160186; Adamson NJ, 1997, J CHROMATOGR B, V699, P133, DOI 10.1016/S0378-4347(97)00202-8; BASAK SK, 1995, ANAL BIOCHEM, V226, P51, DOI 10.1006/abio.1995.1190; CASTAGNOLA M, 1994, J CHROMATOGR B, V656, P87, DOI 10.1016/0378-4347(94)00082-4; Castagnola M, 1998, ELECTROPHORESIS, V19, P1728, DOI 10.1002/elps.1150191033; CHEN N, 1993, CHROMATOGRAPHIA, V37, P429, DOI 10.1007/BF02272260; Cifuentes A, 1997, ELECTROPHORESIS, V18, P2362, DOI 10.1002/elps.1150181227; CIFUENTES A, 1995, ELECTROPHORESIS, V16, P516, DOI 10.1002/elps.1150160185; CIFUENTES A, 1994, J CHROMATOGR A, V680, P321, DOI 10.1016/0021-9673(94)80083-9; COMPTON BJ, 1991, J CHROMATOGR, V559, P357, DOI 10.1016/0021-9673(91)80085-U; Cross RF, 2001, CHROMATOGRAPHIA, V54, P639, DOI 10.1007/BF02492192; Cross RF, 1997, J CHROMATOGR A, V786, P171, DOI 10.1016/S0021-9673(97)00547-5; De Lorenzi E, 2002, ELECTROPHORESIS, V23, P918; Dolnik V, 2006, ELECTROPHORESIS, V27, P126, DOI 10.1002/elps.200500567; Fausett L., 1994, FUNDAMENTALS NEURAL; GAUS HJ, 1993, ANAL CHEM, V65, P1399, DOI 10.1021/ac00058a016; GROSSMAN PD, 1989, ANAL BIOCHEM, V179, P28, DOI 10.1016/0003-2697(89)90195-4; Hearn MTW, 2000, ANAL CHEM, V72, P1964, DOI 10.1021/ac990369a; HILSER VJ, 1993, J CHROMATOGR, V630, P329, DOI 10.1016/0021-9673(93)80469-O; Hruska V, 2006, ELECTROPHORESIS, V27, P984, DOI 10.1002/elps.200500756; ISSAQ HJ, 1992, J LIQ CHROMATOGR, V15, P1129, DOI 10.1080/10826079208018854; Jalali-Heravi M, 2005, J CHROMATOGR A, V1096, P58, DOI 10.1016/j.chroma.2005.09.043; Jalali-Heravi M, 2005, ELECTROPHORESIS, V26, P1874, DOI 10.1002/elps.200410308; Janini GM, 2001, J CHROMATOGR A, V924, P291, DOI 10.1016/S0021-9673(01)00919-0; Janini GM, 1999, J CHROMATOGR A, V848, P417, DOI 10.1016/S0021-9673(99)00388-X; Jaros M, 2004, ELECTROPHORESIS, V25, P3080, DOI 10.1002/elps.200405982; Kasicka V, 1999, ELECTROPHORESIS, V20, P3084, DOI 10.1002/(SICI)1522-2683(19991001)20:15/16<3084::AID-ELPS3084>3.0.CO;2-4; Kasicka V, 2006, ELECTROPHORESIS, V27, P142, DOI 10.1002/elps.200500527; Katritzky A.R., 1994, CODESSA REFERENCE MA; Kim J, 2003, ELECTROPHORESIS, V24, P782, DOI 10.1002/elps.200390098; Li QF, 2002, COMPUT CHEM, V26, P245, DOI 10.1016/S0097-8485(01)00114-0; Ma WP, 2006, ANALYST, V131, P1254, DOI 10.1039/b605060c; METRAL CJ, 1999, J HIGH RES CHROMATOG, V22, P373, DOI 10.1002/(SICI)1521-4168(19990701)22:7<373::AID-JHRC373>3.0.CO;2-3; Mitchell T, 1997, MACHINE LEARNING; NYBERG F, 1988, P ELECTROPHORESIS, V88, P141; OFFORD RE, 1966, NATURE, V211, P591, DOI 10.1038/211591a0; OLAJOS M, J LIQ CHROM IN PRESS; Piaggio MV, 2006, ELECTROPHORESIS, V27, P4631, DOI 10.1002/elps.200600182; PITTS E, 1953, PROC R SOC LON SER-A, V217, P43, DOI 10.1098/rspa.1953.0045; Plasson R, 2005, ANAL CHEM, V77, P6047, DOI 10.1021/ac050783c; Plasson R, 2007, ELECTROPHORESIS, V28, P3617, DOI 10.1002/elps.200700349; RICKARD EC, 1991, ANAL BIOCHEM, V197, P197, DOI 10.1016/0003-2697(91)90379-8; Sanz-Nebot V, 2002, J CHROMATOGR A, V950, P99, DOI 10.1016/S0021-9673(02)00025-0; SKOOG B, 1986, TRAC-TREND ANAL CHEM, V5, P82, DOI 10.1016/0165-9936(86)80045-0; Solinova V, 2004, ELECTROPHORESIS, V25, P2299, DOI 10.1002/elps.200405924; SURVAY MA, 1993, J CHROMATOGR, V636, P81, DOI 10.1016/0021-9673(93)80059-H; Survay MA, 1996, J CHROMATOGR A, V741, P99, DOI 10.1016/0021-9673(96)00151-3; Tanford C, 1961, PHYS CHEM MACROMOLEC; Tessier B, 2004, J CHROMATOGR A, V1024, P255, DOI 10.1016/j.chroma.2003.10.050; Verzola B, 2003, ELECTROPHORESIS, V24, P794, DOI 10.1002/elps.200390099; Cross RF, 2001, CHROMATOGRAPHIA, V53, P431, DOI 10.1007/BF02491080; Xin Y, 2006, J PHYS CHEM B, V110, P1038, DOI 10.1021/jp0544235; Yu K, 2007, TALANTA, V71, P676, DOI 10.1016/j.talanta.2006.05.013	53	15	15	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0165-9936		TRAC-TREND ANAL CHEM	Trac-Trends Anal. Chem.	MAY	2008	27	5					407	417		10.1016/j.trac.2008.03.010		11	Chemistry, Analytical	Chemistry	321MI	WOS:000257308900011	
J	Schreiner, K				Schreiner, Keri			Machine learning takes on the brain	IEEE INTELLIGENT SYSTEMS			English	News Item																	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1541-1672		IEEE INTELL SYST	IEEE Intell. Syst.	MAY-JUN	2008	23	3					7	8				2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	305CR	WOS:000256155900005	
J	Hoff, KJ; Tech, M; Lingner, T; Daniel, R; Morgenstern, B; Meinicke, P				Hoff, Katharina J.; Tech, Maike; Lingner, Thomas; Daniel, Rolf; Morgenstern, Burkhard; Meinicke, Peter			Gene prediction in metagenomic fragments: A large scale machine learning approach	BMC BIOINFORMATICS			English	Article							MICROBIAL COMMUNITIES; SOIL METAGENOME; GENOMES; MICROORGANISMS; IDENTIFICATION; BIOCATALYSTS; ENVIRONMENT; FINDER	Background: Metagenomics is an approach to the characterization of microbial genomes via the direct isolation of genomic sequences from the environment without prior cultivation. The amount of metagenomic sequence data is growing fast while computational methods for metagenome analysis are still in their infancy. In contrast to genomic sequences of single species, which can usually be assembled and analyzed by many available methods, a large proportion of metagenome data remains as unassembled anonymous sequencing reads. One of the aims of all metagenomic sequencing projects is the identification of novel genes. Short length, for example, Sanger sequencing yields on average 700 bp fragments, and unknown phylogenetic origin of most fragments require approaches to gene prediction that are different from the currently available methods for genomes of single species. In particular, the large size of metagenomic samples requires fast and accurate methods with small numbers of false positive predictions. Results: We introduce a novel gene prediction algorithm for metagenomic fragments based on a two-stage machine learning approach. In the first stage, we use linear discriminants for monocodon usage, dicodon usage and translation initiation sites to extract features from DNA sequences. In the second stage, an artificial neural network combines these features with open reading frame length and fragment GC-content to compute the probability that this open reading frame encodes a protein. This probability is used for the classification and scoring of gene candidates. With large scale training, our method provides fast single fragment predictions with good sensitivity and specificity on artificially fragmented genomic DNA. Additionally, this method is able to predict translation initiation sites accurately and distinguishes complete from incomplete genes with high reliability. Conclusion: Large scale machine learning methods are well-suited for gene prediction in metagenomic DNA fragments. In particular, the combination of linear discriminants and neural networks is promising and should be considered for integration into metagenomic analysis pipelines. The data sets can be downloaded from the URL provided ( see Availability and requirements section).	[Hoff, Katharina J.; Tech, Maike; Lingner, Thomas; Morgenstern, Burkhard; Meinicke, Peter] Univ Gottingen, Abt Bioinformat, D-37077 Gottingen, Germany; [Daniel, Rolf] Univ Gottingen, Abt Genom & Angew Mikrobiol, D-37077 Gottingen, Germany	Hoff, KJ (reprint author), Univ Gottingen, Abt Bioinformat, Goldschmidstr 1, D-37077 Gottingen, Germany.	katharina@gobics.de; maike@gobics.de; thomas@gobics.de; rdaniel@gwdg.de; burkhard@gobics.de; pmeinic@gwdg.de	Lingner, Thomas/A-2345-2008; Morgenstern, Burkhard/A-7486-2008				ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; AMANN RI, 1995, MICROBIOL REV, V59, P143; Bajic VB, 2002, BIOINFORMATICS, V18, P198, DOI 10.1093/bioinformatics/18.1.198; Benson DA, 2007, NUCLEIC ACIDS RES, V35, pD21, DOI 10.1093/nar/gkl986; Besemer J, 1999, NUCLEIC ACIDS RES, V27, P3911, DOI 10.1093/nar/27.19.3911; Bishop C.M., 1995, NEURAL NETWORKS PATT; Chen K, 2005, PLOS COMPUT BIOL, V1, P106, DOI 10.1371/journal.pcbi.0010024; Daniel R, 2004, CURR OPIN BIOTECH, V15, P199, DOI 10.1016/j.copbio.2004.04.005; Daniel R, 2005, NAT REV MICROBIOL, V3, P470, DOI 10.1038/nrmicro1160; Delcher AL, 1999, NUCLEIC ACIDS RES, V27, P4636, DOI 10.1093/nar/27.23.4636; Edwards RA, 2006, BMC GENOMICS, V7, DOI 10.1186/1471-2164-7-57; Frishman D, 1999, GENE, V234, P257, DOI 10.1016/S0378-1119(99)00200-0; Handelsman J, 2004, MICROBIOL MOL BIOL R, V68, P669, DOI 10.1128/MMBR.68.4.669-685.2004; Hastie T, 2001, ELEMENTS STAT LEARNI; Hugenholtz P, 2002, GENOME BIOL, V3; JARVIE T, 2007, BIOCHEMICA, V3, P4; Krause L, 2006, BIOINFORMATICS, V22, pE281, DOI 10.1093/bioinformatics/btl247; Lukashin AV, 1998, NUCLEIC ACIDS RES, V26, P1107, DOI 10.1093/nar/26.4.1107; MACKAY DJC, 1992, NEURAL COMPUT, V4, P448, DOI 10.1162/neco.1992.4.3.448; Nabney Ian T., 2001, NETLAB ALGORITHMS PA; Nielsen P, 2005, BIOINFORMATICS, V21, P4322, DOI 10.1093/bioinformatics/bti701; Noguchi H, 2006, NUCLEIC ACIDS RES, V34, P5623, DOI 10.1093/nar/gkl723; Ou HY, 2004, INT J BIOCHEM CELL B, V36, P535, DOI 10.1016/j.biocel.2003.08.013; R Development Core Team, 2004, R LANG ENV STAT COMP; Rappe MS, 2003, ANNU REV MICROBIOL, V57, P369, DOI 10.1146/annurev.micro.57.030502.090759; Riesenfeld CS, 2004, ANNU REV GENET, V38, P525, DOI 10.1146/annurev.genet.38.072902.091216; Ronaghi M, 1998, SCIENCE, V281, P363, DOI 10.1126/science.281.5375.363; Rudd KE, 2000, NUCLEIC ACIDS RES, V28, P60, DOI 10.1093/nar/28.1.60; SANGER F, 1977, P NATL ACAD SCI USA, V74, P5463, DOI 10.1073/pnas.74.12.5463; Streit WR, 2004, CURR OPIN BIOTECH, V15, P285, DOI 10.1016/j.copbio.2004.05.006; Suzek BE, 2001, BIOINFORMATICS, V17, P1123, DOI 10.1093/bioinformatics/17.12.1123; TECH M, 2005, BIOINFORMATICS, V17, P3568; TECH M, 2006, NUCLEIC ACIDS RES, V34, P588; Tech M, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-121; Torsvik V, 2002, CURR OPIN MICROBIOL, V5, P240, DOI 10.1016/S1369-5274(02)00324-7; Tringe SG, 2005, SCIENCE, V308, P554, DOI 10.1126/science.1107851; Tyson GW, 2004, NATURE, V428, P37, DOI 10.1038/nature02340; van Rijsbergen C. J., 1979, INFORM RETRIEVAL; Venter JC, 2004, SCIENCE, V304, P66, DOI 10.1126/science.1093857; Voget S, 2003, APPL ENVIRON MICROB, V69, P6235, DOI 10.1128/AEM.69.10.6235-6242.2003; WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968; PSEUDOCAP PSEUDOMONA; SETS D	43	29	31	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	APR 28	2008	9								217	10.1186/1471-2105-9-217		14	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	308WS	WOS:000256421900002	
J	Kertesz-Farkas, A; Dhir, S; Sonego, P; Pacurar, M; Netoteia, S; Nijveen, H; Kuzniar, A; Leuissen, JAM; Kocsor, A; Pongor, S				Kertesz-Farkas, Attila; Dhir, Somdutta; Sonego, Paolo; Pacurar, Mircea; Netoteia, Serglu; Nijveen, Harm; Kuzniar, Arnold; Leuissen, Jack A. M.; Kocsor, Andras; Pongor, Sandor			Benchmarking protein classification algorithms via supervised cross-validation	JOURNAL OF BIOCHEMICAL AND BIOPHYSICAL METHODS			English	Article						protein classification; ROC analysis; benchmarking	SEQUENCE CLASSIFICATION; HOMOLOGY DETECTION; DATABASE; FAMILY; INFORMATION; SEARCH	Development and testing of protein classification algorithms are hampered by the fact that the protein universe is characterized by groups vastly different in the number of members, in average protein size, similarity within group, etc. Datasets based on traditional cross-validation (k-fold, leave-one-out, etc.) may not give reliable estimates on how an algorithm will generalize to novel, distantly related subtypes of the known protein classes. Supervised cross-validation, i.e., selection of test and train sets according to the known subtypes within a database has been Successfully used earlier in conjunction with the SCOP database. Our goal was to extend this principle to other databases and to design standardized benchmark datasets for protein classification. Hierarchical classification trees of protein categories provide a simple and general framework for designing supervised cross-validation strategies for protein classification. Benchmark datasets can be designed at various levels of the concept hierarchy using a simple graph-theoretic distance. A combination of supervised and random sampling was selected to construct reduced size model datasets, suitable for algorithm comparison. Over 3000 new classification tasks were added to our recently established protein classification benchmark collection that currently includes protein sequence (including protein domains and entire proteins), protein structure and reading frame DNA sequence data. We carried out an extensive evaluation based on various machine-learning algorithms such as nearest neighbor, Support vector machines, artificial neural networks, random forests and logistic regression, used in conjunction with comparison algorithms, BLAST, Smith-Waterman, Needleman-Wunsch, as well as 3D comparison methods DALI and PRIDE. The resulting datasets provide lower, and in our opinion more realistic estimates of the classifier performance than do random cross-validation schemes. A combination of supervised and random sampling was used to construct model datasets, suitable for algorithm comparison. The datasets are available at http:/hydra.icgeb.trieste.it/benchmark. (c) 2007 Published by Elsevier B.V.	[Dhir, Somdutta; Sonego, Paolo; Pacurar, Mircea; Pongor, Sandor] Int Ctr Genet Engn & Biotechnol, Prot Struct & Bioinformat Grp, I-34012 Trieste, Italy; [Kertesz-Farkas, Attila; Kocsor, Andras] Univ Szeged, H-6720 Szeged, Hungary; [Kertesz-Farkas, Attila; Kocsor, Andras] Hungarian Acad Sci, Res Grp Artificial Intelligence, H-6720 Szeged, Hungary; [Netoteia, Serglu] Biol Res Ctr, H-6701 Szeged, Hungary; [Nijveen, Harm; Kuzniar, Arnold; Leuissen, Jack A. M.] Univ Wageningen & Res Ctr, Lab Bioinformat, NL-6703 HA Wageningen, Netherlands	Pongor, S (reprint author), Int Ctr Genet Engn & Biotechnol, Prot Struct & Bioinformat Grp, Padriciano 99, I-34012 Trieste, Italy.	kfa@inf.u-szeged.hu; sdhir@icgeb.org; sonego@icgeb.org; pacurar@icgeb.org; sergiun@brc.hu; harm.nijveenl@wur.nl; arnold.kuzniar@wur.nl; jack.leunissen@wur.nl; kocsor@infu-szeged.hu; pongor@icgeb.org	Sonego, Paolo/D-4939-2012				ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Andreeva A, 2004, NUCLEIC ACIDS RES, V32, pD226, DOI 10.1093/nar/gkh039; BLOOM C, 1998, SOLVING PROBLEMS CON, P1; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dong QW, 2006, BIOINFORMATICS, V22, P285, DOI 10.1093/bioinformatics/bti801; Duda R., 2000, PATTERN CLASSIFICATI; EGAN JP, 1975, SIGNAL DETECTION THE; Gribskov M, 1996, COMPUT CHEM, V20, P25, DOI 10.1016/S0097-8485(96)80004-0; Henikoff S, 1999, BIOINFORMATICS, V15, P471, DOI 10.1093/bioinformatics/15.6.471; Jaakkola T, 1999, Proc Int Conf Intell Syst Mol Biol, P149; Jaakkola T, 2000, J COMPUT BIOL, V7, P95, DOI 10.1089/10665270050081405; Joachims T., 1998, ADV KERNEL METHODS S; Kajan L, 2006, BIOINFORMATICS, V22, P2865, DOI 10.1093/informatics/btl512; Kocsor A, 2006, BIOINFORMATICS, V22, P407, DOI 10.1093/bioinformatics/bti806; LEMPEL A, 1976, IEEE T INFORM THEORY, V22, P75, DOI 10.1109/TIT.1976.1055501; Liao L, 2003, J COMPUT BIOL, V10, P857, DOI 10.1089/106652703322756113; Lindahl E, 2000, J MOL BIOL, V295, P613, DOI 10.1006/jmbi.1999.3377; Murvai J, 2001, GENOME RES, V11, P1410, DOI 10.1101/gr.168701; Pearl F, 2005, NUCLEIC ACIDS RES, V33, pD247, DOI 10.1093/nar/gki024; Pollack JD, 2005, MOL PHYLOGENET EVOL, V35, P420, DOI 10.1016/j.ympev.2005.02.002; Rice P, 2000, TRENDS GENET, V16, P276, DOI 10.1016/S0168-9525(00)02024-2; Saigo H, 2004, BIOINFORMATICS, V20, P1682, DOI 10.1093/bioinformatics/bth141; SONEGO M, 2007, NUCLEIC ACIDS RES, V35, pD232; Tatusov RL, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-41; Witten I. H., 2005, DATA MINING PRACTICA; Wu CH, 2006, NUCLEIC ACIDS RES, V34, pD187, DOI 10.1093/nar/gkj161; NEEDLEMA.SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4; *MATHWORKS, 2004, MATHWORKS T MATL	28	4	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-022X		J BIOCHEM BIOPH METH	J. Biochem. Biophys. Methods	APR 24	2008	70	6					1215	1223		10.1016/j.jbbm.2007.05.011		9	Biochemical Research Methods; Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	308MB	WOS:000256393200064	
J	Yu, W; Clyne, M; Dolan, SM; Yesupriya, A; Wulf, A; Liu, TB; Khoury, MJ; Gwinn, M				Yu, Wei; Clyne, Melinda; Dolan, Siobhan M.; Yesupriya, Ajay; Wulf, Anja; Liu, Tiebin; Khoury, Muin J.; Gwinn, Marta			GAPscreener: An automatic tool for screening human genetic association literature in PubMed using the support vector machine technique	BMC BIOINFORMATICS			English	Article							HUMAN GENOME EPIDEMIOLOGY; INFORMATION-RETRIEVAL; TEXT; CLASSIFICATION; NETWORKS; HAIRPINS; DATABASE	Background: Synthesis of data from published human genetic association studies is a critical step in the translation of human genome discoveries into health applications. Although genetic association studies account for a substantial proportion of the abstracts in PubMed, identifying them with standard queries is not always accurate or efficient. Further automating the literature-screening process can reduce the burden of a labor-intensive and time-consuming traditional literature search. The Support Vector Machine ( SVM), a well-established machine learning technique, has been successful in classifying text, including biomedical literature. The GAPscreener, a free SVM-based software tool, can be used to assist in screening PubMed abstracts for human genetic association studies. Results: The data source for this research was the HuGE Navigator, formerly known as the HuGE Pub Lit database. Weighted SVM feature selection based on a keyword list obtained by the two-way z score method demonstrated the best screening performance, achieving 97.5% recall, 98.3% specificity and 31.9% precision in performance testing. Compared with the traditional screening process based on a complex PubMed query, the SVM tool reduced by about 90% the number of abstracts requiring individual review by the database curator. The tool also ascertained 47 articles that were missed by the traditional literature screening process during the 4-week test period. We examined the literature on genetic associations with preterm birth as an example. Compared with the traditional, manual process, the GAPscreener both reduced effort and improved accuracy. Conclusion: GAPscreener is the first free SVM-based application available for screening the human genetic association literature in PubMed with high recall and specificity. The user-friendly graphical user interface makes this a practical, stand-alone application. The software can be downloaded at no charge.	[Yu, Wei; Clyne, Melinda; Yesupriya, Ajay; Wulf, Anja; Liu, Tiebin; Khoury, Muin J.; Gwinn, Marta] Ctr Dis Control & Prevent, Natl Off Publ Hlth Genom, Coordinating Ctr Hlth Promot, Atlanta, GA USA; [Dolan, Siobhan M.] Montefiore Med Ctr, Albert Einstein Coll Med, Bronx, NY 10467 USA	Yu, W (reprint author), Ctr Dis Control & Prevent, Natl Off Publ Hlth Genom, Coordinating Ctr Hlth Promot, Atlanta, GA USA.	WYu@cdc.gov; MClyne@cdc.gov; siobhanmdolan@yahoo.com; AYesupriya@cdc.gov; AWulf@cdc.gov; TLiu@cdc.gov; MKhoury@cdc.gov; MGwinn@cdc.gov					Aronson A R, 2001, Proc AMIA Symp, P17; Bertram L, 2007, NAT GENET, V39, P17, DOI 10.1038/ng1934; Chang C.-C., 2001, LIB SUPPORT VECTOR M; Chapelle O, 2007, NEURAL COMPUT, V19, P1155, DOI 10.1162/neco.2007.19.5.1155; Cohen Aaron M, 2006, J Biomed Discov Collab, V1, P4, DOI 10.1186/1747-5333-1-4; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; Donaldson I, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-11; Eckstein R., 1998, JAVA SWING; Guttmacher AE, 2005, JAMA-J AM MED ASSOC, V294, P1399, DOI 10.1001/jama.294.11.1399; Han B, 2006, BIOINFORMATICS, V22, P2136, DOI 10.1093/bioinformatics/btl350; Ioannidis JPA, 2006, NAT GENET, V38, P3, DOI 10.1038/ng0106-3; Ioannidis JPA, 2005, AM J EPIDEMIOL, V162, P302, DOI 10.1093/aje/kwi201; Jensen LJ, 2006, NAT REV GENET, V7, P119, DOI 10.1038/nrg1768; Leong MK, 2007, CHEM RES TOXICOL, V20, P217, DOI 10.1021/tx060230c; Lin BK, 2006, AM J EPIDEMIOL, V164, P1, DOI 10.1093/aje/kwj175; Lin H.-T., 2003, STUDY SIGMOID KERNEL; LINDBERG DAB, 1993, METHOD INFORM MED, V32, P281; Ng KLS, 2007, BIOINFORMATICS, V23, P1321, DOI 10.1093/bioinformatics/btm026; PLAVARAPU N, 2005, P IEEE COMPUT SYST B, P366; Puri ML, 1971, NONPARAMETRIC METHOD; Rice SB, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S1-S22; ROSENER B, 2000, FUNDAMENTALS BIOSTAT, P356; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Shatkay H, 2005, BRIEF BIOINFORM, V6, P222, DOI 10.1093/bib/6.3.222; Yu W, 2008, NAT GENET, V40, P124, DOI 10.1038/ng0208-124; *EMBASE, 2005, EMBASE EXC MED; *HUGENET, 2007, HUGENET HDB SYST REV; *NAT LIB MED, 2006, PUBMED; *NAT LIB MED, 2006, ENTR PROGR UT	30	12	13	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	APR 22	2008	9								205	10.1186/1471-2105-9-205		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	303JQ	WOS:000256037200001	
J	Verma, R; Tiwari, A; Kaur, S; Varshney, GC; Raghava, GPS				Verma, Ruchi; Tiwari, Ajit; Kaur, Sukhwinder; Varshney, Grish C.; Raghava, Gajendra P. S.			Identification of proteins secreted by malaria parasite into erythrocyte using SVM and PSSM profiles	BMC BIOINFORMATICS			English	Article							PREDICTING SUBCELLULAR-LOCALIZATION; FALCIPARUM-INFECTED ERYTHROCYTE; SUPPORT VECTOR MACHINES; AMINO-ACID-COMPOSITION; PLASMODIUM-FALCIPARUM; EVOLUTIONARY INFORMATION; SIGNAL PEPTIDES; WEB SERVER; PSI-BLAST; HOST-CELL	Background: Malaria parasite secretes various proteins in infected RBC for its growth and survival. Thus identification of these secretory proteins is important for developing vaccine/ drug against malaria. The existing motif-based methods have got limited success due to lack of universal motif in all secretory proteins of malaria parasite. Results: In this study a systematic attempt has been made to develop a general method for predicting secretory proteins of malaria parasite. All models were trained and tested on a non-redundant dataset of 252 secretory and 252 non-secretory proteins. We developed SVM models and achieved maximum MCC 0.72 with 85.65% accuracy and MCC 0.74 with 86.45% accuracy using amino acid and dipeptide composition respectively. SVM models were developed using split-amino acid and split-dipeptide composition and achieved maximum MCC 0.74 with 86.40% accuracy and MCC 0.77 with accuracy 88.22% respectively. In this study, for the first time PSSM profiles obtained from PSI-BLAST, have been used for predicting secretory proteins. We achieved maximum MCC 0.86 with 92.66% accuracy using PSSM based SVM model. All models developed in this study were evaluated using 5-fold cross-validation technique. Conclusion: This study demonstrates that secretory proteins have different residue composition than non-secretory proteins. Thus, it is possible to predict secretory proteins from its residue composition-using machine learning technique. The multiple sequence alignment provides more information than sequence itself. Thus performance of method based on PSSM profile is more accurate than method based on sequence composition. A web server PSEApred has been developed for predicting secretory proteins of malaria parasites, the URL can be found in the Availability and requirements section.	[Verma, Ruchi; Raghava, Gajendra P. S.] Inst Microbial Technol, Bioinformat Ctr, Chandigarh, India	Raghava, GPS (reprint author), Inst Microbial Technol, Bioinformat Ctr, Sector 39-A, Chandigarh, India.	ruchi@imtech.res.in; ajit@imtech.res.in; sukhi@imtech.res.in; grish@imtech.res.in; raghava@imtech.res.in	Raghava, Gajendra/B-1717-2009				Bahl A, 2003, NUCLEIC ACIDS RES, V31, P212, DOI 10.1093/nar/gkg081; Bhasin M, 2005, BIOINFORMATICS, V21, P2522, DOI 10.1093/bioinformatics/bti309; Bhasin M, 2004, NUCLEIC ACIDS RES, V32, pW414, DOI 10.1093/nar/gkh350; BRENDEL V, 1992, MATH COMPUT MODEL, V16, P37, DOI 10.1016/0895-7177(92)90150-J; CAI D, 2002, COMPUT CHEM, V26; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2007, BIOCHEM BIOPH RES CO, V357, P633, DOI 10.1016/j.bbrc.2007.03.162; Chou KC, 2007, BIOCHEM BIOPH RES CO, V360, P339, DOI 10.1016/j.bbrc.2007.06.027; Cooke BM, 2004, SEMIN HEMATOL, V41, P173, DOI 10.1053/j.seminhematol.2004.01.004; Sargeant TJ, 2006, GENOME BIOL, V7, DOI 10.1186/gb-2006-7-2-r12; Craig A, 2001, MOL BIOCHEM PARASIT, V115, P129, DOI 10.1016/S0166-6851(01)00275-4; del Portillo HA, 2001, NATURE, V410, P839, DOI 10.1038/35071118; Emanuelsson O, 2000, J MOL BIOL, V300, P1005, DOI 10.1006/jmbi.2000.3903; Florens L, 2004, MOL BIOCHEM PARASIT, V135, P1, DOI 10.1016/j.molbiopara.2003.12.007; Gardner MJ, 2002, NATURE, V419, P498, DOI 10.1038/nature01097; GARG A, 2008, SILICO BIOL, V8, P12; Garg A, 2005, J BIOL CHEM, V280, P14427, DOI 10.1074/jbc.M411789200; Hiller NL, 2004, SCIENCE, V306, P1934, DOI 10.1126/science.1102737; Horton P, 2007, NUCLEIC ACIDS RES, V35, pW585, DOI 10.1093/nar/gkm259; Howard R. J., 1988, The biology of parasitism. A molecular and immunological approach., P111; Kaur H, 2004, PROTEINS, V55, P83, DOI 10.1002/prot.10569; Kaur H, 2003, PROTEIN SCI, V12, P923, DOI 10.1110/ps.0241703; Kaur H, 2004, BIOINFORMATICS, V20, P2751, DOI 10.1093/bioinformatics/bth322; Kumar M, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-463; KUMAR M, 2005, J BIOL CHEM, V281, P5357, DOI 10.1074/jbc.M511061200; Lingelbach K, 2006, MOL BIOCHEM PARASIT, V147, P1, DOI 10.1016/j.molbiopara.2006.01.014; Lu Z, 2004, BIOINFORMATICS, V20, P547, DOI 10.1093/bioinformatics/btg447; Marti M, 2004, SCIENCE, V306, P1930, DOI 10.1126/science.1102452; Park KJ, 2003, BIOINFORMATICS, V19, P1656, DOI 10.1093/bioinformatics/btg222; Rashid M, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-337; Rug M, 2004, INFECT IMMUN, V72, P6095, DOI 10.1128/IAI.72.10.6095-6105.2004; Shen HB, 2007, BIOCHEM BIOPH RES CO, V363, P297, DOI 10.1016/j.bbrc.2007.08.140; Shen HB, 2007, BIOCHEM BIOPH RES CO, V364, P53, DOI 10.1016/j.bbrc.2007.09.098; Shen HB, 2008, ANAL BIOCHEM, V373, P386, DOI 10.1016/j.ab.2007.10.012; Smith JD, 2005, CURR ISSUES MOL BIOL, V7, P81; Snow RW, 2005, NATURE, V434, P214, DOI 10.1038/nature03342; Spielmann T, 2006, MOL BIOL CELL, V17, P3613, DOI 10.1091/mbc.E06-04-0291; Vincensini L, 2005, MOL CELL PROTEOMICS, V4, P582, DOI 10.1074/mcp.M400176-MCP200	38	8	8	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	APR 16	2008	9								201	10.1186/1471-2105-9-201		11	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	303JL	WOS:000256036700001	
J	Kliger, Y; Gofer, E; Wool, A; Toporik, A; Apatoff, A; Olshansky, M				Kliger, Yossef; Gofer, Eyal; Wool, Assaf; Toporik, Amir; Apatoff, Avihay; Olshansky, Moshe			Predicting proteolytic sites in extracellular proteins: only halfway there	BIOINFORMATICS			English	Article							HUMAN-IMMUNODEFICIENCY-VIRUS; DOMINANT HYPOPHOSPHATEMIC RICKETS; ENVELOPE GLYCOPROTEIN; CLEAVAGE SITES; PROPROTEIN CONVERTASES; FURIN; CORONAVIRUS; PEPTIDES; TYPE-1; INHIBITION	Motivation: Many secretory proteins are synthesized as inactive precursors that must undergo post-translational proteolysis in order to mature and become active. In the current study, we address the challenge of sequence-based discovery of proteolytic sites in secreted proteins using machine learning. Results: The results revealed that only half of the extracellular proteolytic sites are currently annotated, leaving over 3600 unannotated ones. Furthermore, we have found that only 6 of the unannotated sites are similar to known proteolytic sites, whereas the remaining 94 do not share significant similarity with any annotated proteolytic site. The computational challenges in these two cases are very different. While the precision in detecting the former group is close to perfect, only a mere 22 of the latter group were detected with a precision of 80. The applicability of the classifier is demonstrated through members of the FGF family, in which we verified the conservation of physiologically-relevant proteolytic sites in homologous proteins.	[Kliger, Yossef; Gofer, Eyal; Wool, Assaf; Toporik, Amir; Apatoff, Avihay; Olshansky, Moshe] Compugen Ltd, IL-69512 Tel Aviv, Israel; [Apatoff, Avihay] Bar Ilan Univ, Mina & Everard Goodman Fac Life Sci, Ramat Gan, Israel	Kliger, Y (reprint author), Compugen Ltd, 72 Pinchas, IL-69512 Tel Aviv, Israel.						Anderson NL, 2004, MOL CELL PROTEOMICS, V3, P311, DOI 10.1074/mcp.M300127-MCP200; Antoine M, 2000, CELL GROWTH DIFFER, V11, P593; Bahbouhi B, 2002, BIOCHEM J, V366, P863, DOI 10.1042/BJ20020052; Basak A, 2005, J MOL MED-JMM, V83, P844, DOI 10.1007/s00109-005-0710-0; Bendtsen JD, 2004, J MOL BIOL, V340, P783, DOI 10.1016/j.jmb.2004.05.028; Bergeron E, 2005, BIOCHEM BIOPH RES CO, V326, P554, DOI 10.1016/j.bbrc.2004.11.063; Blom N, 1996, PROTEIN SCI, V5, P2203; Boeckmann B, 2003, NUCLEIC ACIDS RES, V31, P365, DOI 10.1093/nar/gkg095; Bowe AE, 2001, BIOCHEM BIOPH RES CO, V284, P977, DOI 10.1006/bbrc.2001.5084; BRADBURY AF, 1982, NATURE, V298, P686, DOI 10.1038/298686a0; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cai YD, 1998, J PROTEIN CHEM, V17, P607, DOI 10.1007/BF02780962; Clamp M, 2004, BIOINFORMATICS, V20, P426, DOI 10.1093/bioinformatics/btg430; Day R, 1998, J BIOL CHEM, V273, P829, DOI 10.1074/jbc.273.2.829; de Haan CAM, 2004, J VIROL, V78, P6048, DOI 10.1128/JVI.78.11.6048-6054.2004; Do CB, 2005, GENOME RES, V15, P330, DOI 10.1101/gr.2821705; Duckert P, 2004, PROTEIN ENG DES SEL, V17, P107, DOI 10.1093/protein/gzh013; EARL PL, 1991, J VIROL, V65, P31; Farriol-Mathis N, 2004, PROTEOMICS, V4, P1537, DOI 10.1002/pmic.200300764; Friis-Hansen L, 2001, J ENDOCRINOL, V169, P595, DOI 10.1677/joe.0.1690595; HALLENBERGER S, 1992, NATURE, V360, P358, DOI 10.1038/360358a0; HOBOHM U, 1992, PROTEIN SCI, V1, P409; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; Junker VL, 1999, BIOINFORMATICS, V15, P1066; Kibler KV, 2004, J BIOL CHEM, V279, P49055, DOI 10.1074/jbc.M403394200; KIEFER P, 1993, MOL CELL BIOL, V13, P5781; Kiemer L, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-72; KOWALSKI M, 1987, SCIENCE, V237, P1351, DOI 10.1126/science.3629244; MCCUNE JM, 1988, CELL, V53, P55, DOI 10.1016/0092-8674(88)90487-4; Nakayama K, 1997, BIOCHEM J, V327, P625; Nickel W, 2003, EUR J BIOCHEM, V270, P2109, DOI 10.1046/j.1432-1033.2003.03577.x; Paetzel M, 2002, CHEM REV, V102, P4549, DOI 10.1021/cr010166y; Qian N, 1988, J MOL BIOL, V202, P865, DOI 10.1016/0022-2836(88)90564-5; Seidah NG, 1998, ANN NY ACAD SCI, V839, P9, DOI 10.1111/j.1749-6632.1998.tb10727.x; Shimada T, 2002, ENDOCRINOLOGY, V143, P3179, DOI 10.1210/en.143.8.3179; VAPNIK V, 1995, MACH LEARN, V20, P1; White KE, 2001, KIDNEY INT, V60, P2079, DOI 10.1046/j.1523-1755.2001.00064.x; Yang Zheng Rong, 2004, J Bioinform Comput Biol, V2, P511, DOI 10.1142/S0219720004000715; White KE, 2000, NAT GENET, V26, P345	39	7	7	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	APR 15	2008	24	8					1049	1055		10.1093/bioinformatics/btn084		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	286XE	WOS:000254878500003	
J	Qin, YS; Zhang, SC				Qin, Yongsong; Zhang, Shichao			Empirical likelihood confidence intervals for differences between two datasets with missing data	PATTERN RECOGNITION LETTERS			English	Article						empirical likelihood; confidence interval; missing data; imputation	IMPUTED SURVEY DATA; LINEAR-MODELS; HOT DECK; IMPUTATION; INFERENCE	Detecting differences between populations (or datasets) is an important research topic in machine learning, yet an common application means of evaluating, such as a new medical product by comparing with an old one. Previous researchers focus on change detection. In this paper, we measure the uncertainty of structural differences, such as mean and distribution function differences, between populations, using a confidence interval (CI), via an empirical likelihood approach. We present a statistically sound method for estimating CIs for differences between non-parametric populations with missing values, which are imputed by using simple random hot deck imputation method. We illustrate the power of CI estimation as a new machine learning technique for, such as, distinguishing spam from non-sparn emails in spambase dataset downloaded from UCI. (c) 2008 Elsevier B.V. All rights reserved.	[Qin, Yongsong; Zhang, Shichao] Guangxi Normal Univ Guilin, Sch Comp Sci & Informat Technol, Guilin 541004, Guangxi, Peoples R China	Zhang, SC (reprint author), Guangxi Normal Univ Guilin, Sch Comp Sci & Informat Technol, Guilin 541004, Guangxi, Peoples R China.	ysqin@mailbox.gxnu.edu.cn; zhangsc@mailbox.gxnu.edu.cn					BAY S, 2000, ICML 00, P49; Bay SD, 2001, DATA MIN KNOWL DISC, V5, P213, DOI 10.1023/A:1011429418057; Bay S.D., 1999, KNOWLEDGE DISCOVERY, P302; Chen J, 2000, STAT SINICA, V10, P1153; Chen JH, 2007, STAT SINICA, V17, P1047; Chen YZ, 1999, STAT SINICA, V9, P361; CONG G, 2002, ICDM 02, P107; Einmahl JHJ, 2003, BERNOULLI, V9, P267, DOI 10.3150/bj/1068128978; Hall P., 1988, AUST J STAT A, V30A, P179; Hall P., 1992, BOOTSTRAP EDGEWORTH; HARTLEY HO, 1968, BIOMETRIKA, V55, P547, DOI 10.2307/2334260; JING BY, 1995, STAT PROBABIL LETT, V24, P315, DOI 10.1016/0167-7152(94)00189-F; Kim JK, 2004, BIOMETRIKA, V91, P559, DOI 10.1093/biomet/91.3.559; Kitamura Y, 1997, ANN STAT, V25, P2084, DOI 10.1214/aos/1069362388; Little R. J. A., 2002, STAT ANAL MISSING DA; LIU B, 2002, DAWAK, V2000, P337; MCKEAGUE IW, 2006, INT J BIOSTATIST, V1, P1007; Owen A, 2003, DATA MIN KNOWL DISC, V7, P101, DOI 10.1023/A:1021568920107; OWEN A, 1990, ANN STAT, V18, P90, DOI 10.1214/aos/1176347494; OWEN A, 1991, ANN STAT, V19, P1725, DOI 10.1214/aos/1176348368; OWEN A.B, 2001, EMPIRICAL LIKELIHOOD; OWEN AB, 1988, BIOMETRIKA, V75, P237, DOI 10.1093/biomet/75.2.237; QIN J, 1994, ANN STAT, V22, P300, DOI 10.1214/aos/1176325370; QIN Y, 2000, CHINESE SYSTEMS SCI, V13, P23; Rao JNK, 1996, J AM STAT ASSOC, V91, P499, DOI 10.2307/2291637; Shao J, 1996, J AM STAT ASSOC, V91, P1278, DOI 10.2307/2291746; THOMAS DR, 1975, J AM STAT ASSOC, V70, P865, DOI 10.2307/2285449; WANG K, 2003, SIAMDM 03 SAN FRANCI; Wang QH, 2002, SCAND J STAT, V29, P563, DOI 10.1111/1467-9469.00306; Wang QH, 2002, ANN STAT, V30, P896; Webb G. I., 2003, P 9 ACM SIGKDD INT C, P256	31	6	8	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	APR 15	2008	29	6					803	812		10.1016/j.patrec.2007.12.010		10	Computer Science, Artificial Intelligence	Computer Science	290NN	WOS:000255129600011	
J	Clemencon, S; Lugosi, G; Vayatis, N				Clemencon, Stephan; Lugosi, Gabor; Vayatis, Nicolas			Ranking and empirical minimization of U-statistics	ANNALS OF STATISTICS			English	Article						statistical learning; theory of classification; VC classes; fast rates; convex risk minimization; moment inequalities; U-processes	MOMENT INEQUALITIES; RISK MINIMIZATION; RANDOM-VARIABLES; LIMIT-THEOREMS; CONSISTENCY; BOUNDS; ERROR; CLASSIFICATION; CLASSIFIERS	The problem of ranking/ordering instances, instead of simply classifying them, has recently gained much attention in machine learning. In this paper we formulate the ranking problem in a rigorous statistical framework. The goal is to learn a ranking rule for deciding, among two instances, which one is "better," with minimum ranking risk. Since the natural estimates of the risk are of the form of a U-statistic, results of the theory of U-processes are required for investigating the consistency of empirical risk minimizers. We establish, in particular, a tail inequality for degenerate U-processes, and apply it for showing that fast rates of convergence may be achieved under specific noise assumptions, just like in classification. Convex risk minimization methods are also studied.	[Clemencon, Stephan] Ecole Natl Super Telecommun Bretagne, Dept TSI Signal & Images, F-75014 Paris, France; [Lugosi, Gabor] Univ Pompeu Fabra, Dept Econ & Business, Barcelona 08005, Spain; [Vayatis, Nicolas] Ecole Normale Super, Ctr Math & Leurs Applicat, F-94235 Cachan, France	Clemencon, S (reprint author), Ecole Natl Super Telecommun Bretagne, Dept TSI Signal & Images, 37-39 Rue Dareau, F-75014 Paris, France.	clemenco@enst.fr; lugosi@upf.es; vayatis@cmla.ens-cachan.fr					Adamczak R., 2007, ANN PROBAB, V34, P2288; Agarwal S, 2005, J MACH LEARN RES, V6, P393; ARCONES MA, 1994, STOCH PROC APPL, V52, P17, DOI 10.1016/0304-4149(94)90098-1; ARCONES MA, 1993, ANN PROBAB, V21, P1494, DOI 10.1214/aop/1176989128; Bartlett PL, 2006, PROBAB THEORY REL, V135, P311, DOI 10.1007/s00440-005-0462-3; Bartlett PL, 2006, J AM STAT ASSOC, V101, P138, DOI 10.1198/016214505000000907; BLANCHARD G., 2003, J MACHINE LEARNING R, V4, P861; BOUCHERON S., 2005, ESAIM-PROBAB STAT, V9, P323, DOI 10.1051/ps:2005018; Boucheron S, 2005, ANN PROBAB, V33, P514, DOI 10.1214/009117904000000856; Breiman L, 2004, ANN STAT, V32, P1; Cao Y., 2006, P 29 ANN INT ACM SIG, P186, DOI 10.1145/1148170.1148205; Cortes C, 2004, ADV NEUR IN, V16, P313; Cossock D, 2006, LECT NOTES ARTIF INT, V4005, P605, DOI 10.1007/11776420_44; Cucker F, 2002, B AM MATH SOC, V39, P1; De la Pena V., 1999, DECOUPLING DEPENDENC; Devroye L., 1996, PROBABILISTIC THEORY; Freund Y, 2004, J MACH LEARN RES, V4, P933, DOI 10.1162/1532443041827916; GINE E, 1984, ANN PROBAB, V12, P929, DOI 10.1214/aop/1176993138; Gine E, 2000, PROG PROBAB, V47, P13; Green D. M., 1966, SIGNAL DETECTION THE; HOEFFDING W, 1948, ANN MATH STAT, V19, P293, DOI 10.1214/aoms/1177730196; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; Houdre C, 2003, PROG PROBAB, V56, P55; Jiang WX, 2004, ANN STAT, V32, P13; Koltchinskii V, 2002, ANN STAT, V30, P1; Koltchinskii V, 2006, ANN STAT, V34, P2593, DOI 10.1214/009053606000001019; Ledoux M, 1997, ESAIM-PROBAB STAT, V1, P63, DOI 10.1051/ps:1997103; LUGOSI G, 2002, PRINCIPLES NONPARAME, P5; Lugosi G, 2004, ANN STAT, V32, P30; Major P, 2006, PROBAB THEORY REL, V134, P489, DOI 10.1007/s00440-005-0440-9; Massart P, 2006, ANN STAT, V34, P2326, DOI 10.1214/009053606000000786; Massart P, 2007, LECT NOTES MATH, V1896, P1, DOI 10.1007/978-3-540-48503-2; MCDIARMID C, 1989, LOND MATH S, V141, P148; Rudin C, 2006, LECT NOTES ARTIF INT, V4005, P589, DOI 10.1007/11776420_43; SERFLING R. J., 1980, APPROXIMATION THEORE; Smale S, 2003, ANAL APPL, V1, P17, DOI 10.1142/S0219530503000089; Steinwart I, 2005, LECT NOTES COMPUT SC, V3559, P279, DOI 10.1007/11503415_19; Steinwart I., 2001, J MACHINE LEARNING R, V2, P67, DOI 10.1162/153244302760185252; STUTE W, 1991, ANN PROBAB, V19, P812, DOI 10.1214/aop/1176990452; STUTE W, 1994, ANN STAT, V22, P460, DOI 10.1214/aos/1176325378; Talagrand M, 1996, INVENT MATH, V126, P505, DOI 10.1007/s002220050108; Tsybakov AB, 2004, ANN STAT, V32, P135; USUNIER N, 2005, P NIPS 05 WORKSH LEA; Vapnik V, 1974, THEORY PATTERN RECOG; Vittaut JN, 2006, LECT NOTES COMPUT SC, V3936, P338; VU HT, 2005, P 14 ACM INT C INF K, P309, DOI 10.1145/1099554.1099641; Zhang T, 2004, ANN STAT, V32, P56	47	31	31	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	0090-5364		ANN STAT	Ann. Stat.	APR	2008	36	2					844	874		10.1214/009052607000000910		31	Statistics & Probability	Mathematics	281MW	WOS:000254502700013	
J	Policastro, CA; Carvalho, ACPLF; Delbem, ACB				Policastro, Claudio A.; Carvalho, Andre C. P. L. F.; Delbem, Alexandre C. B.			A hybrid case adaptation approach for case-based reasoning	APPLIED INTELLIGENCE			English	Article						case-based reasoning; case adaptation; knowledge acquisition; hybrid systems	RECOGNITION	Case-Based Reasoning is a methodology for problem solving based on past experiences. This methodology tries to solve a new problem by retrieving and adapting previously known solutions of similar problems. However, retrieved solutions, in general, require adaptations in order to be applied to new contexts. One of the major challenges in Case-Based Reasoning is the development of an efficient methodology for case adaptation. The most widely used form of adaptation employs hand coded adaptation rules, which demands a significant knowledge acquisition and engineering effort. An alternative to overcome the difficulties associated with the acquisition of knowledge for case adaptation has been the use of hybrid approaches and automatic learning algorithms for the acquisition of the knowledge used for the adaptation. We investigate the use of hybrid approaches for case adaptation employing Machine Learning algorithms. The approaches investigated how to automatically learn adaptation knowledge from a case base and apply it to adapt retrieved solutions. In order to verify the potential of the proposed approaches, they are experimentally compared with individual Machine Learning techniques. The results obtained indicate the potential of these approaches as an efficient approach for acquiring case adaptation knowledge. They show that the combination of Instance-Based Learning and Inductive Learning paradigms and the use of a data set of adaptation patterns yield adaptations of the retrieved solutions with high predictive accuracy.	[Policastro, Claudio A.; Carvalho, Andre C. P. L. F.; Delbem, Alexandre C. B.] Univ Sao Paulo, Sao Carlos, SP, Brazil	Policastro, CA (reprint author), Univ Sao Paulo, Sao Carlos, SP, Brazil.	capoli@icmc.usp.br; andre@icmc.usp.br; acbd@icmc.usp.br	de Carvalho, Andre/A-6321-2008; Delbem, Alexandre/A-9287-2008	Delbem, Alexandre/0000-0003-1810-1742			AAMODT A, 1994, AI COMMUN, V7, P39; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; BAILEY T, 1993, 13 INT JOINT C ART I, P895; Bentley JL, 1975, COMMUN ACM, V18; BLAKE C, 1998, UCI REPOSITORY MACH; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CARPENTER GA, 1987, APPL OPTICS, V26, P4919, DOI 10.1364/AO.26.004919; Corchado J., 1998, Computing and Information Systems, V5; Dietterich TG, 1997, AI MAG, V18, P97; Domingos P, 1996, MACH LEARN, V24, P141, DOI 10.1023/A:1018006431188; Duda R. O., 2001, PATTERN CLASSIFICATI; Freund Y., 1996, 13 INT C MACH LEARN, P148; HANNEY K, 1996, THESIS U COLL DUBLIN; HANNEY K, 1995, AAAI 1995 FALL S AD; Haykin S., 1999, NEURAL NETWORKS COMP; HILARIO M, 1997, OVERVIEW STRATEGIES, pCH2; JACKSON WG, 2002, WATER RESOURCES OUTR; KOLODNER J, ADAPTATION METHODS S, pCH11; LAVRAC N, 2003, LECT NOTES COMPUTER, V2837; LEAKE D, 1996, 30 NAT C ART INT 8 I, P684; LEAKE D, 1995, 8 ANN FLOR ART INT R, P1120; Leake D.B., 1996, CASE BASED REASONING, P1; LENZ M, 1996, 4 GERM WORKSH CAS BA, P103; MAIN J, 2001, SOFT COMPUTING CASEB; MALERBA D, 2001, LECT NOTES ARTIFICIA, V2175; MCSHERRY D, 1998, P 4 EUR WORKSH CAS B, P184; Mitchell Tom M., 1997, MACH LEARNING; Moore A. W., INTRO TUTORIAL KD TR; MOSES LE, 1986, COMPARISON AVERAGES, pCH6; Orr M.J.L., 1996, INTRO RADIAL BASIS F; Policastro CA, 2003, LECT NOTES ARTIF INT, V2821, P297; Quinlan R., 1992, 5 AUSTR JOINT C ART, P343; RUSSEL R, 1995, ARTIFICIAL INTELLIGE; SMYTH B, 1998, 12 INT C IND ENG APP, P507; SMYTH B, 1993, 6 IR C ART INT COGN; VALENTINI G, 2002, LECT NOTES COMPUTER; Vapnik VN, 1998, STAT LEARNING THEORY; Wang Y., 1997, 9 EUR C MACH LEARN P, P128; Watson I., 1997, APPLYING CASE BASED; Watson I, 1999, KNOWL-BASED SYST, V12, P303, DOI 10.1016/S0950-7051(99)00020-9; WILKE W, 1996, FRAMEWORK LEARNING A; WIRATUNGA N, 2002, 6 EUR C CAS BAS REAS, P421	43	4	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-669X		APPL INTELL	Appl. Intell.	APR	2008	28	2					101	119		10.1007/s10489-007-0044-4		19	Computer Science, Artificial Intelligence	Computer Science	251PR	WOS:000252386200001	
J	Benito Garzon, M; Sanchez de Dios, R; Sainz Ollero, H				Benito Garzon, Marta; Sanchez de Dios, Rut; Sainz Ollero, Helios			Effects of climate change on the distribution of Iberian tree species	APPLIED VEGETATION SCIENCE			English	Article						forest distributions; iberian peninsula; machine learning; random forest	PINUS-SYLVESTRIS; PLANT DIVERSITY; MODELS; PENINSULA; EUROPE; PHYLOGEOGRAPHY; CONSERVATION; POPULATIONS; PREDICTION; VEGETATION	Question: Will the predicted climate changes affect species distribution in the Iberian Peninsula? Location: Iberian Peninsula (Spain and Portugal). Methods: We modelled current and future tree distributions as a function of climate, using a computational framework that made use of one machine learning technique, the random forest (RF) algorithm. This algorithm provided good predictions of the current distribution of each species, as shown by the area under the corresponding receiver operating characteristics (ROC) curves. Species turnover, richness and the change in distributions over time to 2080 under four Intergovernmental panel on climate change (IPCC) scenarios were calculated using the species map outputs. Results and Conclusions: The results show a notable reduction in the potential distribution of the studied species under all the IPCC scenarios, particularly so for mountain conifer species such as Pinus sylvestris, P. uncinata and Abies alba. Temperate species, especially Fagus sylvatica and Quercus petraea, were also predicted to suffer a reduction in their range; also submediterranean species, especially Q. pyrenaica, were predicted to undergo notable decline. In contrast, typically Mediterranean species appeared to be generally more capable of migration, and are therefore likely to be less affected.	[Benito Garzon, Marta; Sanchez de Dios, Rut; Sainz Ollero, Helios] UAM, Dept Biol, Unidad Bot, Madrid 28049, Spain	Benito Garzon, M (reprint author), UAM, Dept Biol, Unidad Bot, Carretera Colmenar Km 15, Madrid 28049, Spain.	marta.benito@uam.es; rut.sanchez@uam.es; helios.sainz@uam.es	Benito Garzon, Marta/E-3622-2013	Benito Garzon, Marta/0000-0002-3436-123X			Amaral Franco J., 1990, FLORA IBERICA, P15; ANTON MG, 1997, J BIOGEOGR, V26, P929; Bakkenes M, 2002, GLOBAL CHANGE BIOL, V8, P390, DOI 10.1046/j.1354-1013.2001.00467.x; Bolliger J, 2000, REG ENVIRON CHANGE, V1, P99, DOI 10.1007/s101130000018; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cowling RM, 1996, TRENDS ECOL EVOL, V11, P362, DOI 10.1016/0169-5347(96)10044-6; Cubasch U, 1996, CLIMATE RES, V7, P129, DOI 10.3354/cr007129; de Dios RS, 2006, PLANT ECOL, V187, P109, DOI 10.1007/s11258-006-9136-1; Fielding AH, 1997, ENVIRON CONSERV, V24, P38, DOI 10.1017/S0376892997000088; Garzon MB, 2006, ECOL MODEL, V197, P383, DOI 10.1016/j.ecolmodel.2006.03.015; Garzon MB, 2007, ECOGRAPHY, V30, P120, DOI 10.1111/j.2006.0906-7590.04813.x; GITAY M, 2002, CLIMATE CHANGE BIODI; Gomez-Campo C., 1985, IBERIAN PENINSULA PL; Govaerts RHA, 2000, TAXON, V49, P537, DOI 10.2307/1224350; Hansen AJ, 2001, BIOSCIENCE, V51, P765, DOI 10.1641/0006-3568(2001)051[0765:GCIFRO]2.0.CO;2; Hughes L, 2000, TRENDS ECOL EVOL, V15, P56, DOI 10.1016/S0169-5347(99)01764-4; Jalas J, 1972, ATLAS FLORAE EUROPAE; Liaw A., 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; Manel S, 2001, J APPL ECOL, V38, P921, DOI 10.1046/j.1365-2664.2001.00647.x; McCarthy J.J., 2001, CLIMATE CHANGE 2001; Medail F, 1997, ANN MO BOT GARD, V84, P112, DOI 10.2307/2399957; MITASOVA H, 1993, MATH GEOL, V25, P641, DOI 10.1007/BF00893171; MONSERUD RA, 1992, ECOL MODEL, V62, P275, DOI 10.1016/0304-3800(92)90003-W; NAKICENOVIC N, 2000, EMISSION CENARIOS; Neteler M., 2004, OPEN SOURCE GIS GRAS; PALOMARES OS, 1999, MODELOS CARTOGRAFFIA; Pearson RG, 2003, GLOBAL ECOL BIOGEOGR, V12, P361, DOI 10.1046/j.1466-822X.2003.00042.x; Pearson RG, 2004, ECOGRAPHY, V27, P285, DOI 10.1111/j.0906-7590.2004.03740.x; Peterson AT, 2002, NATURE, V416, P626, DOI 10.1038/416626a; Petit RJ, 2005, TAXON, V54, P877; Prasad AM, 2006, ECOSYSTEMS, V9, P181, DOI 10.1007/s10021-005-0054-1; PRUSGLOWACKI W, 1994, SILVAE GENET, V43, P7; Prus-Glowacki W, 2003, PLANT SYST EVOL, V239, P55, DOI 10.1007/s00606-002-0256-3; RODRIGUEZ JMM, 2005, PRINCIPALES CONCLUSI; Sanchez E, 2004, GLOBAL PLANET CHANGE, V44, P163, DOI 10.1016/j.gloplacha.2004.06.010; Schwartz MW, 2001, ECOSYSTEMS, V4, P568, DOI 10.1007/s10021-001-0030-3; Taberlet P, 1998, MOL ECOL, V7, P453, DOI 10.1046/j.1365-294x.1998.00289.x; Theurillat JP, 2001, CLIMATIC CHANGE, V50, P77, DOI 10.1023/A:1010632015572; Thuiller W, 2005, P NATL ACAD SCI USA, V102, P8245, DOI 10.1073/pnas.0409902102; Walther GR, 2002, NATURE, V416, P389, DOI 10.1038/416389a; WATSON RT, 1997, REGIONAL IMPACTS CLI; [Anonymous], 2004, R LANGUAGE ENV STAT; 2006, SRTM SHUTTLE RADAR T	43	38	38	OPULUS PRESS UPPSALA AB	GRANGARDE	GAMLA VAGEN 40, S-770 13 GRANGARDE, SWEDEN	1402-2001		APPL VEG SCI	Appl. Veg. Sci.	APR	2008	11	2					169	178		10.3170/2008-7-18348		10	Plant Sciences; Ecology; Forestry	Plant Sciences; Environmental Sciences & Ecology; Forestry	291XC	WOS:000255229600003	
J	Galway, L; Charles, D; Black, M				Galway, Leo; Charles, Darryl; Black, Michaela			Machine learning in digital games: a survey	ARTIFICIAL INTELLIGENCE REVIEW			English	Review						Machine learning; Computational intelligence; Digital games; Game AI	INJECTED GENETIC ALGORITHMS; COMPUTER GAMES; NETWORKS; TIME	Artificial intelligence for digital games constitutes the implementation of a set of algorithms and techniques from both traditional and modern artificial intelligence in order to provide solutions to a range of game dependent problems. However, the majority of current approaches lead to predefined, static and predictable game agent responses, with no ability to adjust during game-play to the behaviour or playing style of the player. Machine learning techniques provide a way to improve the behavioural dynamics of computer controlled game agents by facilitating the automated generation and selection of behaviours, thus enhancing the capabilities of digital game artificial intelligence and providing the opportunity to create more engaging and entertaining game-play experiences. This paper provides a survey of the current state of academic machine learning research for digital game environments, with respect to the use of techniques from neural networks, evolutionary computation and reinforcement learning for game agent control.	[Galway, Leo; Charles, Darryl; Black, Michaela] Univ Ulster, Fac Engn, Sch Comp & Informat Engn, Coleraine BT52 1SA, Londonderry, North Ireland	Galway, L (reprint author), Univ Ulster, Fac Engn, Sch Comp & Informat Engn, Cromore Rd, Coleraine BT52 1SA, Londonderry, North Ireland.	galway-l1@email.ulster.ac.uk; dk.charles@ulster.ac.uk; mm.black@ulster.ac.uk					Agapitos A., 2007, P 2007 IEEE C EV COM, P1562; Agapitos A., 2007, P C GEN EV COMP ACM, P1543, DOI 10.1145/1276958.1277271; BAEKKELUND C, 2006, AI GAME PROGRAMMING, V3; Baluja S., 1994, CMUCS94163; Bauckhage Christian, 2004, P20; Beyer HG, 2001, THEORY EVOLUTIONARY; Billings D, 2002, ARTIF INTELL, V134, P201, DOI 10.1016/S0004-3702(01)00130-8; BLUMBERG B, 2002, P 29 ANN C COMP GRAP, P417, DOI 10.1145/566570.566597; BRADLEY J, 2005, P 2005 IEEE C EV COM, P1914; BRADLEY J, 2005, P 2005 IEEE S COMP I; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Bryant B., 2007, P 22 NAT C ART INT, P801; BRYANT BD, 2006, P 2006 IEEE S COMP I, P90; BRYANT BD, 2003, P IEEE C EV COMP, V3, P2194; Bryant BD, 2006, P IEEE C EV COMP, P1007; Buckland M., 2005, PROGRAMMING GAME AI; Buro M, 1997, ICCA J, V20, P189; Campbell M, 2002, ARTIF INTELL, V134, P57, DOI 10.1016/S0004-3702(01)00129-1; Chaperot B, 2006, P 2006 IEEE S COMP I, P181; CHARLES D, 2004, P 5 INT C COMP GAM A, P163; Charles D, 2003, P DIG GAM RES C 2003; De Boer P., 2004, ANN OPER RES, V134, P19; Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017; DEJONG KA, 1993, FDN GENETIC ALGORITH, V2, P19; DEMASI P, 2002, INT J INTELLIGENT GA, V2, P80; Dietterich T. G., 2000, LECT NOTES COMPUTER, V1864/2000, P26; DSILVA T, 2005, P 1 ART INT INT DIG, P39; DUAN J, 2002, P 3 INT C INT GAM SI, P104; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1016/0364-0213(90)90002-E; EVANS R, 2001, GAME DEV, V8, P46; Fijrnkranz J., 2001, MACHINES LEARN PLAY, P11; Freund Y., 1996, P 13 INT C MACH LEAR, P148; GALLAGHER M, 2007, P 2007 IEEE S COMP I, P282; Gallagher M., 2003, P IEEE C EV COMP, P2462; GALWAY L, 2007, P 8 INT C INT GAM SI, P42; GEISLER B, 2004, CHALLENGES GAME ARTI, P54; Goldberg DE, 1989, GENETIC ALGORITHMS S; Gomez F, 1997, ADAPT BEHAV, V5, P317, DOI 10.1177/105971239700500305; GORNIAK P, 2007, P ART INT INT DIG EN, P14; Graepel T., 2004, P COMP GAM ART INT D, P193; Grandori A., 1997, J MANAGEMENT GOVERNA, V1, P29, DOI 10.1023/A:1009977627870; HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697; Haykin S., 1994, NEURAL NETWORKS COMP; HOANG H, 2005, P 1 ART INT INT DIG, P63; HOLLAND JH, 1975, ADAPTATION NATURAL A; Hsu Feng-hsiung, 2002, DEEP BLUE BUILDING C; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; KIRBY N, 2004, RABIN SAI GAME PROGR, V2; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Koza J. R., 1992, GENETIC PROGRAMMING; Laird JE, 2001, AI MAG, V22, P15; LAIRD JE, 1999, P GAM DEV C SAN JOS, P577; Louis SJ, 2004, IEEE T EVOLUT COMPUT, V8, P316, DOI 10.1109/TEVC.2004.823466; Louis SJ, 2005, IEEE T EVOLUT COMPUT, V9, P669, DOI 10.1109/TEVC.2005.856209; Lucas S., 2005, P IEEE S COMP INT GA, P203; LUCAS SM, 2007, P 2007 IEEE S COMP I, P260; Lucas S. M., 2004, Proceedings of the 2004 Congress on Evolutionary Computation (IEEE Cat. No.04TH8753), DOI 10.1109/CEC.2004.1330972; Lucas SM, 2006, IEEE COMPUT INTELL M, V1, P10, DOI 10.1109/MCI.2006.1597057; MACNAMEE B, 2001, P 12 IR C ART INT CO, P221; MACNAMEE B, 2003, INT J INTELL GAMES S, V2, P28; MADEIRA C, 2004, CHALL GAM ART INT AI, P72; MADERIA C, 2006, P 2 ART INT INT DIG, P121; MAES P, 1995, COMMUN ACM, V38, P108, DOI 10.1145/219717.219808; MANSLOW J, 2002, RABIN SAI GAME PROGR; MCGLINCHEY S, 2003, P 4 INT C INT GAM SI, P106; MICONI T, 2006, P IEEE C EV COMP, P1639; Miikkulainen R., 2006, COMPUT INTELL, P155; MILES C, 2004, P 2004 GEN EV COMP C, P1365; MILES C, 2007, P 2007 IEEE S COMP I, P88; MILES C, 2006, P 2006 IEEE S COMP I, P75; Miles C., 2004, Proceedings of the 2004 Congress on Evolutionary Computation (IEEE Cat. No.04TH8753), DOI 10.1109/CEC.2004.1331066; Orkin J., 2005, P 1 ART INT INT DIG, P105; PARKER G, 1996, P WORLD AUTOMATION C, P617; PARKER G, 2005, P 2005 IEEE C EV COM, P2416; Parker G. B., 2007, P 2007 IEEE S COMP I, P238; PARKER GB, 2006, P 2006 IEEE C EV COM, P1216; PARKER GB, 2006, P 2006 IEEE C EV COM, P969; PARKER GB, 2005, P 2005 IEEE C EV COM, P2410; PARKER M, 2006, P 2006 IEEE C EV COM, P800; PARKER M, 2007, P 2007 IEEE S COMP I, P232; Parker M., 2006, P 2006 IEEE C EV COM, P1202; PFEIFFER M, 2004, P 5 INT C COMP GAM A, P384; Ponsen M., 2004, P COMP GAM ART INT D, P389; PONSEN M, 2006, P 18 BELG NETH C ART, P251; POTTINGER D, 2000, GAME DEV, V8, P36; Rumelhart D.E., 1989, PARALLEL DISTRIBUTED, V1; Rummery GA, 1994, 166 CUEDFINFENGTR; SAMUEL AL, 1967, IBM J RES DEV, V11, P601; SAMUEL AL, 1959, IBM J RES DEV, V3, P211; SCHAEFFER J, 1997, ONE JUMP AHEAD CHALL; SCHAEFFER J, 2002, ARTIF INTELL, V134, P1, DOI 10.1016/S0004-3702(01)00165-5; Schaeffer J., 2000, ADV COMPUT, V50, P189; Schwab Brian, 2004, AI GAME ENGINE PROGR; SPRONCK P, 2003, P 4 INT C INT GAM SI, P93; Spronck P., 2003, INT J INTELLIGENT GA, V2, P20; Spronck P, 2006, MACH LEARN, V63, P217, DOI 10.1007/s10994-006-6205-6; Stanley KO, 2005, IEEE T EVOLUT COMPUT, V9, P653, DOI 10.1109/TEVC.2005.856210; STANLEY KO, 2005, P 2005 IEEE S COMP I; Stanley KO, 2002, EVOL COMPUT, V10, P99, DOI 10.1162/106365602320169811; Sutton R. S., 1988, Machine Learning, V3, DOI 10.1007/BF00115009; Sutton RS, 1996, ADV NEUR IN, V8, P1038; Sutton R.S., 1998, REINFORCEMENT LEARNI; Szita I, 2006, NEURAL COMPUT, V18, P2936, DOI 10.1162/neco.2006.18.12.2936; Szita I, 2007, J ARTIF INTELL RES, V30, P659; TESAURO G, 1995, COMMUN ACM, V38, P58, DOI 10.1145/203330.203343; THURAU C, 2003, P GAME ON, P119; TOGELIUS J, 2007, P IEEE S COMP INT GA, P252; TOGELIUS J, 2007, P IEEE C EV COMP CEC, P4043; TOGELIUS J, 2005, P IEEE C EV COMP CEC, P1906; Togelius J, 2006, P IEEE C EV COMP VAN, P1187; TOZOUR P, 2002, AI GAME PROGRAMMING; TOZOUR P, 2001, GAME PROGRAMMING GEM, V2, P287; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698; Whiteson S., 2005, P GECCO, P1225, DOI 10.1145/1068009.1068210; WOLPERT DH, 2001, P 17 INT JOINT C ART, P819; WOODCOCK S, 2001, GAME DEV, V8, P36; WOODCOCK S, 1999, GAME DEV, V6, P34; WOODCOCK S, 2002, GAME DEV, V9, P26; WOODCOCK S, 1998, GAME DEV, V5, P28; WOODSTOCK S, 2000, GAME DEV, V7, P24; Yannakakis G., 2004, ANIMALS ANIMATS, V8, P499; Yannakakis G. N., 2003, P 11 MED C CONTR AUT; Yannakakis G. N., 2004, Proceedings of the 2004 Congress on Evolutionary Computation (IEEE Cat. No.04TH8753), DOI 10.1109/CEC.2004.1330969; YONG CH, 2006, P 2 ART INT INT DIG, P98	124	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0269-2821		ARTIF INTELL REV	Artif. Intell. Rev.	APR	2008	29	2					123	161		10.1007/s10462-009-9112-y		39	Computer Science, Artificial Intelligence	Computer Science	483GD	WOS:000268949900002	
J	Stout, M; Bacardit, J; Hirst, JD; Krasnogor, N				Stout, Michael; Bacardit, Jaume; Hirst, Jonathan D.; Krasnogor, Natalio			Prediction of recursive convex hull class assignments for protein residues	BIOINFORMATICS			English	Article							SECONDARY STRUCTURE PREDICTION; MOLECULAR-FIELD ANALYSIS; THERMODYNAMIC DATABASE; SOLVENT ACCESSIBILITY; SEQUENCE ALIGNMENT; LIGAND-BINDING; AMINO-ACID; PROTHERM; SITES; DEPTH	Motivation: We introduce a new method for designating the location of residues in folded protein structures based on the recursive convex hull (RCH) of a point set of atomic coordinates. The RCH can be calculated with an efficient and parameterless algorithm. Results: We show that residue RCH class contains information complementary to widely studied measures such as solvent accessibility (SA), residue depth (RD) and to the distance of residues from the centroid of the chain, the residues exposure (Exp). RCH is more conserved for related structures across folds and correlates better with changes in thermal stability of mutants than the other measures. Further, we assess the predictability of these measures using three types of machine-learning technique: decision trees (C4.5), Naive Bayes and Learning Classifier Systems (LCS) showing that RCH is more easily predicted than the other measures. As an exemplar application of predicted RCH class (in combination with other measures), we show that RCH is potentially helpful in improving prediction of residue contact numbers (CN).	[Stout, Michael; Bacardit, Jaume; Krasnogor, Natalio] Automated Scheduling Optimizat & Planning Res Grp, Sch Comp Sci, Nottingham, England; [Bacardit, Jaume] Univ Nottingham, Sch Biosci, Nottingham NG7 2RD, England; [Hirst, Jonathan D.] Univ Nottingham, Sch Chem, Nottingham NG7 2RD, England	Krasnogor, N (reprint author), Automated Scheduling Optimizat & Planning Res Grp, Sch Comp Sci, Nottingham, England.		Hirst, Jonathan/G-7681-2011				BACARDIT J, 2004, P 8 ANN C GEN EV COM, P247; BACARDIT J, 2004, THESIS RAMON LLULL U; BACARDIT J, 2007, GECCO 07, V1, P346; BADELCHAGNON A, 1994, J MOL GRAPHICS, V12, P162, DOI 10.1016/0263-7855(94)80082-0; Baldi P, 2002, IEEE INTELL SYST, V17, P28, DOI 10.1109/MIS.2002.999217; Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821; Bava KA, 2004, NUCLEIC ACIDS RES, V32, pD120, DOI 10.1093/nar/gkh082; Ben-Shimon A, 2005, J MOL BIOL, V351, P309, DOI 10.1016/j.jmb.2005.06.047; CHAKRAVARTY S, 1999, STRUCTURE, V7, P724; Chen Brian Y, 2007, J Bioinform Comput Biol, V5, P353, DOI 10.1142/S021972000700276X; Coleman RG, 2006, J MOL BIOL, V362, P441, DOI 10.1016/j.jmb.2006.07.022; Cover T., 2006, WILEY SERIES TELECOM; Dor O, 2007, PROTEINS, V66, P838, DOI 10.1002/prot.21298; EIDHAMMER I, 2003, PROTEIN BIOINFORMATI; Gianese G, 2006, J COMPUT CHEM, V27, P621, DOI 10.1002/jcc.20370; Gromiha MM, 1999, NUCLEIC ACIDS RES, V27, P286, DOI 10.1093/nar/27.1.286; Hamelryck T, 2005, PROTEINS, V59, P38, DOI 10.1002/prot.20379; HOLLAND JH, 1975, ADAPTATION NATURAL A, P313; HOLM L, 1993, J MOL BIOL, V233, P123, DOI 10.1006/jmbi.1993.1489; Holmes JB, 2005, J MOL BIOL, V354, P706, DOI 10.1016/j.jmb.2005.09.081; John G. H., 1995, P 11 C UNC ART INT, P338; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; Kawabata T, 2007, PROTEINS, V68, P516, DOI 10.1002/prot.21283; Kinjo AR, 2005, PROTEINS, V58, P158, DOI 10.1002/prot.20300; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Kumar MDS, 2006, NUCLEIC ACIDS RES, V34, pD204, DOI 10.1093/nar/gkj103; LEE B, 1971, J MOL BIOL, V55, P379, DOI 10.1016/0022-2836(71)90324-X; Lee M, 2006, J ORG CHEM, V71, P5082, DOI 10.1021/jo052659z; Liang J, 2001, BIOPHYS J, V81, P751; Lin TH, 1999, BBA-PROTEIN STRUCT M, V1429, P476, DOI 10.1016/S0167-4838(98)00261-1; Lin TH, 2001, COMPUT CHEM, V25, P489, DOI 10.1016/S0097-8485(00)00113-3; Liu S, 2007, PROTEINS, V68, P636, DOI 10.1002/prot.21459; MEIER R, 1995, ICIP 95, V3, P552; MILLER RG, 1981, SIMULTANEOUS STAT IN; Noguchi T, 2001, NUCLEIC ACIDS RES, V29, P219, DOI 10.1093/nar/29.1.219; Pintar A, 2003, BIOINFORMATICS, V19, P313, DOI 10.1093/bioinformatics/19.2.313; PREPARATA FP, 1977, COMMUN ACM, V20, P87, DOI 10.1145/359423.359430; Quinlan J., 1992, C4 5 PROGRAMS MACHIN; ROST B, 1994, PROTEINS, V20, P216, DOI 10.1002/prot.340200303; SANDER C, 1991, PROTEINS, V9, P56, DOI 10.1002/prot.340090107; STOUT M, 2008, IN PRESS SOFT COMPUT; Van Walle I, 2005, BIOINFORMATICS, V21, P1267, DOI 10.1093/bioinformatics/bth493; Vlahovicek K, 2005, NUCLEIC ACIDS RES, V33, pW252, DOI 10.1093/nar/gki362; Wang Y, 2006, LECT NOTES COMPUT SC, V3959, P505; Witten I. H., 2005, DATA MINING PRACTICA; Wood MJ, 2005, PROTEINS, V59, P476, DOI 10.1002/prot.20435	46	12	12	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	APR 1	2008	24	7					916	923		10.1093/bioinformatics/btn050		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	281BJ	WOS:000254470900005	
J	Wu, S; Zhang, Y				Wu, Sitao; Zhang, Yang			A comprehensive assessment of sequence-based and template-based methods for protein contact prediction	BIOINFORMATICS			English	Article							SUPPORT VECTOR MACHINES; CORRELATED MUTATIONS; RESIDUE CONTACTS; FOLD-RECOGNITION; INFORMATION; RESTRAINTS; SCALE; TARGETS; CASP7; MAPS	Motivation: Pair-wise residue-residue contacts in proteins can be predicted from both threading templates and sequence-based machine learning. However, most structure modeling approaches only use the template-based contact predictions in guiding the simulations; this is partly because the sequence-based contact predictions are usually considered to be less accurate than that by threading. With the rapid progress in sequence databases and machine-learning techniques, it is necessary to have a detailed and comprehensive assessment of the contact-prediction methods in different template conditions. Results: We develop two methods for protein-contact predictions: SVM-SEQ is a sequence-based machine learning approach which trains a variety of sequence-derived features on contact maps; SVM-LOMETS collects consensus contact predictions from multiple threading templates. We test both methods on the same set of 554 proteins which are categorized into Easy, Medium, Hard and Very Hard targets based on the evolutionary and structural distance between templates and targets. For the Easy and Medium targets, SVM-LOMETS obviously outperforms SVM-SEQ; but for the Hard and Very Hard targets, the accuracy of the SVM-SEQ predictions is higher than that of SVM-LOMETS by 1225. If we combine the SVM-SEQ and SVM-LOMETS predictions together, the total number of correctly predicted contacts in the Hard proteins will increase by more than 60 (or 70 for the long-range contact with a sequence separation 24), compared with SVM-LOMETS alone. The advantage of SVM-SEQ is also shown in the CASP7 free modeling targets where the SVM-SEQ is around four times more accurate than SVM-LOMETS in the long-range contact prediction. These data demonstrate that the state-of-the-art sequence-based contact prediction has reached a level which may be helpful in assisting tertiary structure modeling for the targets which do not have close structure templates. The maximum yield should be obtained by the combination of both sequence- and template-based predictions.	Univ Kansas, Ctr Bioinformat, Lawrence, KS 66047 USA; Univ Kansas, Dept Mol Biosci, Lawrence, KS 66047 USA	Zhang, Y (reprint author), Univ Kansas, Ctr Bioinformat, Lawrence, KS 66047 USA.		Wu, Sitao/E-8098-2011				ALOY P, 2003, PROTEINS, V6, P436; ALTSCHUL SF, 1997, NUCLEIC ACIDS RES, V25, P3402; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chen HL, 2005, NUCLEIC ACIDS RES, V33, P3193, DOI 10.1093/nar/gki633; Cheng JL, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-113; Chivian D, 2005, PROTEINS, V61, P157, DOI 10.1002/prot.20733; Fariselli P, 2001, PROTEIN ENG, V14, P835, DOI 10.1093/protein/14.11.835; Fariselli P, 1999, PROTEIN ENG, V12, P15, DOI 10.1093/protein/12.1.15; Fischer D, 2003, PROTEINS, V51, P434, DOI 10.1002/prot.10357; Ginalski K, 2003, BIOINFORMATICS, V19, P1015, DOI 10.1093/bioinformatics/btg124; GOBEL U, 1994, PROTEINS, V18, P309, DOI 10.1002/prot.340180402; Grana O, 2005, PROTEINS, V61, P214, DOI 10.1002/prot.20739; Halperin I, 2006, PROTEINS, V63, P832, DOI 10.1002/prot.20933; Hamilton N, 2004, PROTEINS, V56, P679, DOI 10.1002/prot.20160; HOBOHM U, 1994, PROTEIN SCI, V3, P522; Izarzugaza JMG, 2007, PROTEINS, V69, P152, DOI 10.1002/prot.21637; Jauch R, 2007, PROTEINS, V69, P57, DOI 10.1002/prot.21771; JOACHIMS T, 2002, DESSERTATION; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; KARPLUS K, 2003, PROTEINS, V6, P491; Kundrotas PJ, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-503; Li W, 2004, BIOPHYS J, V87, P1241, DOI 10.1529/biophysj.104.044750; Misura KMS, 2006, P NATL ACAD SCI USA, V103, P5361, DOI 10.1073/pnas.0509355103; Olmea O, 1997, FOLD DES, V2, pS25, DOI 10.1016/S1359-0278(97)00060-6; Pollastri G, 2002, Bioinformatics, V18 Suppl 1, pS62; Punta M, 2005, BIOINFORMATICS, V21, P2960, DOI 10.1093/bioinformatics/bti454; SALI A, 1993, J MOL BIOL, V234, P779, DOI 10.1006/jmbi.1993.1626; Shackelford G, 2007, PROTEINS, V69, P159, DOI 10.1002/prot.21791; Shao Y, 2003, PROTEINS, V53, P497, DOI 10.1002/prot.10539; Shi JY, 2001, J MOL BIOL, V310, P243, DOI 10.1006/jmbi.2001.4762; Skolnick J, 2004, PROTEINS, V56, P502, DOI 10.1002/prot.20106; Skolnick J, 1997, J MOL BIOL, V265, P217, DOI 10.1006/jmbi.1996.0720; Soding J, 2005, BIOINFORMATICS, V21, P951, DOI 10.1093/bioinformatics/bti125; Vicatos S, 2005, PROTEINS, V58, P935, DOI 10.1002/prot.20370; Vincent JJ, 2005, PROTEINS, V61, P67, DOI 10.1002/prot.20722; Vullo A, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-180; WU S, 2007, INV TALK GIV MPI C 2; Wu ST, 2007, NUCLEIC ACIDS RES, V35, P3375, DOI 10.1093/nar/gkm251; Xu Y, 2000, PROTEINS, V40, P343, DOI 10.1002/1097-0134(20000815)40:3<343::AID-PROT10>3.0.CO;2-S; Zhang Y, 2004, PROTEINS, V57, P702, DOI 10.1002/prot.20264; Zhang Y, 2004, P NATL ACAD SCI USA, V101, P7594, DOI 10.1073/pnas.0305695101; ZHANG Y, 2008, IN PRESS CURR OPIN S; Zhang Y, 2003, BIOPHYS J, V85, P1145, DOI 10.1016/S0006-3495(03)74551-2; Zhou HY, 2005, PROTEINS, V58, P321, DOI 10.1002/prot.20308; Zhou HY, 2004, PROTEINS, V55, P1005, DOI 10.1002/prot.20007	45	38	38	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	APR 1	2008	24	7					924	931		10.1093/bioinformatics/btn069		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	281BJ	WOS:000254470900006	
J	Poldrack, RA				Poldrack, Russell A.			The role of fMRI in Cognitive Neuroscience: where do we stand?	CURRENT OPINION IN NEUROBIOLOGY			English	Article							HUMAN BRAIN ACTIVITY; DETECTING DECEPTION; NEUROIMAGING DATA; TEMPORAL CORTEX; LIE DETECTION; PATTERNS; ONTOLOGIES; MACHINE; STATES; FACES	Functional magnetic resonance imaging (fMRI) has quickly become the most prominent tool in cognitive neuroscience. In this article, I outline some of the limits on the kinds of inferences that can be supported by fMRI, focusing particularly on reverse inference, in which the engagement of specific mental processes is inferred from patterns of brain activation. Although this form of inference is weak, newly developed methods from the field of machine learning offer the potential to formalize and strengthen reverse inferences. I conclude by discussing the increasing presence of fMRI results in the popular media and the ethical implications of the increasing predictive power of fMRI.	[Poldrack, Russell A.] Univ Calif Los Angeles, Dept Psychol, Los Angeles, CA 90095 USA; [Poldrack, Russell A.] Dept Psychiat & Behav Neurobiol, Los Angeles, CA 90095 USA	Poldrack, RA (reprint author), Univ Calif Los Angeles, Dept Psychol, Franz Hall,Box 951563, Los Angeles, CA 90095 USA.	poldrack@ucla.edu					AGUIRRE GK, 2003, BEHAV NEUROLOGY COGN; ALHO K, 1994, ELECTROEN CLIN NEURO, V91, P353, DOI 10.1016/0013-4694(94)00173-1; Aron A., 2007, NY TIMES; Bard JBL, 2004, NAT REV GENET, V5, P213, DOI 10.1038/nrg1295; Blankertz B, 2007, NEUROIMAGE, V37, P539, DOI 10.1016/j.neuroimage.2007.01.051; BLOOM P, 2006, SEED; Davatzikos C, 2005, NEUROIMAGE, V28, P663, DOI 10.1016/j.neuroimage.2005.08.009; ENGBER D, 2007, SLATE; Farah Martha J., 2007, NEUROETHICS LAW BLOG; Friston Karl J., 1994, Human Brain Mapping, V2, P56, DOI 10.1002/hbm.460020107; GABRIELI JDE, 1995, BEHAV NEUROSCI, V109, P819, DOI 10.1037/0735-7044.109.5.819; Greely HT, 2007, AM J LAW MED, V33, P377; Greene JD, 2001, SCIENCE, V293, P2105, DOI 10.1126/science.1062872; Hanson SJ, 2008, NEURAL COMPUT, V20, P486, DOI 10.1162/neco.2007.09-06-340; Haxby JV, 2001, SCIENCE, V293, P2425, DOI 10.1126/science.1063736; Haynes JD, 2007, CURR BIOL, V17, P323, DOI 10.1016/j.cub.2006.11.072; Haynes JD, 2006, NAT REV NEUROSCI, V7, P523, DOI 10.1038/nrn1931; Henson R, 2005, Q J EXP PSYCHOL-A, V58, P193, DOI 10.1080/02724980443000502; Henson R, 2006, TRENDS COGN SCI, V10, P64, DOI 10.1016/j.tics.2005.12.005; IACOBONI M, 2007, NY TIMES        1111; Kamitani Y, 2005, NAT NEUROSCI, V8, P679, DOI 10.1038/nn1444; Kay KN, 2008, NATURE, V452, P352, DOI 10.1038/nature06713; Knight David C., 2004, Cognitive Affective & Behavioral Neuroscience, V4, P317, DOI 10.3758/CABN.4.3.317; Kozel FA, 2005, BIOL PSYCHIAT, V58, P605, DOI 10.1016/j.biopsych.2005.07.040; Kriegeskorte N, 2007, P NATL ACAD SCI USA, V104, P20600, DOI 10.1073/pnas.0705654104; Kriegeskorte N, 2006, P NATL ACAD SCI USA, V103, P3863, DOI 10.1073/pnas.0600244103; Laird AR, 2005, NEUROINFORMATICS, V3, P65, DOI 10.1385/NI:3:1:065; Lin LN, 2006, TRENDS NEUROSCI, V29, P48, DOI 10.1016/j.tins.2005.11.004; McIntosh AR, 2000, NEURAL NETWORKS, V13, P861, DOI 10.1016/S0893-6080(00)00059-9; Mitchell TM, 2008, SCIENCE, V320, P1191, DOI 10.1126/science.1152876; Mourao-Miranda J, 2005, NEUROIMAGE, V28, P980, DOI 10.1016/j.neuroimage.2005.06.070; Norman KA, 2006, TRENDS COGN SCI, V10, P424, DOI 10.1016/j.tics.2006.07.005; O'Toole AJ, 2007, J COGNITIVE NEUROSCI, V19, P1735, DOI 10.1162/jocn.2007.19.11.1735; Poldrack RA, 2006, TRENDS COGN SCI, V10, P59, DOI 10.1016/j.tics.2005.12.004; Poldrack RA, 2000, NEUROIMAGE, V12, P1, DOI 10.1006/nimg.2000.0596; Price CJ, 1999, HUM BRAIN MAPP, V8, P102, DOI 10.1002/(SICI)1097-0193(1999)8:2/3<102::AID-HBM6>3.0.CO;2-J; Price CJ, 2005, COGN NEUROPSYCHOL, V22, P262, DOI 10.1080/02643290442000095; Racine E, 2005, NAT REV NEUROSCI, V6, P159, DOI 10.1038/nrn1539; Sabb FW, 2008, MOL PSYCHIATR, V13, P350, DOI 10.1038/sj.mp.4002124; Sip KE, 2008, TRENDS COGN SCI, V12, P48, DOI 10.1016/j.tics.2007.11.008; [Anonymous], 2007, NATURE, V450, P457	41	47	48	CURRENT BIOLOGY LTD	LONDON	84 THEOBALDS RD, LONDON WC1X 8RR, ENGLAND	0959-4388		CURR OPIN NEUROBIOL	Curr. Opin. Neurobiol.	APR	2008	18	2					223	226		10.1016/j.conb.2008.07.006		4	Neurosciences	Neurosciences & Neurology	363PO	WOS:000260279400017	
J	Rajwa, B; Venkatapathi, M; Ragheb, K; Banada, PP; Hirleman, ED; Lary, T; Robinson, JP				Rajwa, Bartek; Venkatapathi, Murugesan; Ragheb, Kathy; Banada, Padmapriya P.; Hirleman, E. Daniel; Lary, Todd; Robinson, J. Paul			Automated classification of bacterial particles in flow by multiangle scatter measurement and support vector machine classifier	CYTOMETRY PART A			English	Article; Proceedings Paper	24th International Congress of the International-Society-for-Analytical-Cytology	MAY 17-21, 2008	Budapest, HUNGARY	Int Soc Analyt Cytol		multiangle light-scatter; support vector machines; machine learning; pattern recognition; discrete-dipole approximation	DISCRETE-DIPOLE APPROXIMATION; OUTER-MEMBRANE PROTEIN; DIFFERENTIAL LIGHT-SCATTERING; PATTERN-RECOGNITION; MONOCLONAL-ANTIBODIES; CELL CHARACTERIZATION; BACTEROIDES-FRAGILIS; SINGLE PARTICLES; REFRACTIVE-INDEX; BLOOD-CELLS	Biological microparticles, including bacteria, scatter light in all directions when illuminated. The complex scatter pattern is dependent on particle size, shape, refraction index, density, and morphology. Commercial flow cytometers allow measurement of scattered light intensity at forward and perpendicular (side) angles (2 degrees <= theta(1) <= 20 degrees and 70 degrees <= theta(2) <= 110 degrees, respectively) with a speed varying from 10 to 10,000 particles per second. The choice of angle is dictated by the fact that scattered light in the for-ward region is primarily dependent on cell size and refractive index, whereas side-scatter intensity is dependent on the granularity of cellular structures. However, these two-parameter measurements cannot be used to separate populations of cells of similar shape, size, or structure. Hence, there have been several attempts in flow cytometry to measure the entire scatter patterns. The published concepts require the use of unique custom-built flow cytometers and cannot be applied to existing instruments. It was also not clear how much information about patterns is really necessary to separate various populations of cells present in a given sample. The presented work demonstrates application of pattern-recognition techniques to classify particles on the basis of their discrete scatter patterns collected at just five different angles, and accompanied by the measurement of axial light loss. The proposed approach can be potentially used with existing instruments because it requires only the addition of a compact enhanced scatter detector. An analytical model of scatter of laser beams by individual bacterial cells suspended in a fluid was used to determine the location of scatter sensors. Experimental results were used to train the support vector machine-based pattern recognition system. It has been shown that information provided just by five angles of scatter and axial light loss can be sufficient to recognize various bacteria with 68-99% success rate. (C) 2007 International Society for Analytical Cytology.	Purdue Univ, Purdue Univ Cytometry Lab, Bindley Biosci Ctr, W Lafayette, IN 47907 USA; Purdue Univ, Sch Mech Engn, W Lafayette, IN 47907 USA; Purdue Univ, Dept Food Sci, Mol Food Microbiol Lab, W Lafayette, IN 47907 USA; Becklman Coulter Inc, Cellular Anal Technol Ctr, Miami, FL 33196 USA	Rajwa, B (reprint author), Purdue Univ, Purdue Univ Cytometry Lab, Bindley Biosci Ctr, 1203 W State St, W Lafayette, IN 47907 USA.	brajwa@purdue.edu	Rajwa, Bartek/B-3169-2009; Robinson, Joseph/K-8492-2012	Rajwa, Bartek/0000-0001-7540-8236; 			Adjouadi M, 2005, PART PART SYST CHAR, V22, P107, DOI 10.1002/ppsc.200400888; Alvarez-Barrientos A, 2000, CLIN MICROBIOL REV, V13, P167, DOI 10.1128/CMR.13.2.167-195.2000; Amari S, 1999, NEURAL NETWORKS, V12, P783, DOI 10.1016/S0893-6080(99)00032-5; BARTHOLDI M, 1980, APPL OPTICS, V19, P1573, DOI 10.1364/AO.19.001573; Bhushan R, 1997, INFECT IMMUN, V65, P2668; Boddy L, 2001, CYTOMETRY, V44, P195, DOI 10.1002/1097-0320(20010701)44:3<195::AID-CYTO1112>3.0.CO;2-H; BOWDEN RA, 1995, INFECT IMMUN, V63, P3945; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Cheek RF, 1997, CYTOMETRY, V28, P90, DOI 10.1002/(SICI)1097-0320(19970501)28:1<90::AID-CYTO11>3.0.CO;2-M; Clarke RG, 1998, J APPL MICROBIOL, V84, P577, DOI 10.1046/j.1365-2672.1998.00384.x; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Davey HM, 1996, MICROBIOL REV, V60, P641; Davey HM, 1999, CYTOMETRY, V35, P162, DOI 10.1002/(SICI)1097-0320(19990201)35:2<162::AID-CYTO8>3.0.CO;2-U; DRAINE BT, 1994, J OPT SOC AM A, V11, P1491, DOI 10.1364/JOSAA.11.001491; DRAINE BT, 1988, ASTROPHYS J, V333, P848, DOI 10.1086/166795; DUBELAAR GBJ, 1987, CYTOMETRY, V8, P405, DOI 10.1002/cyto.990080410; Duda R. O., 2001, PATTERN CLASSIFICATI; Fan RE, 2005, J MACH LEARN RES, V6, P1889; Gupta A, 2004, J VAC SCI TECHNOL B, V22, P2785, DOI 10.1116/1.1824047; Hughes EE, 1996, CAN J MICROBIOL, V42, P859; INGRAM M, 1982, CYTOMETRY, V3, P134, DOI 10.1002/cyto.990030212; KAMENTSK.LA, 1965, SCIENCE, V150, P630, DOI 10.1126/science.150.3696.630; Katz A, 2005, OPT LETT, V30, P589, DOI 10.1364/OL.30.6.000589; KERKER M, 1979, J HISTOCHEM CYTOCHEM, V27, P250; LOKEN MR, 1976, J HISTOCHEM CYTOCHEM, V24, P284; LUTTON DA, 1991, J MED MICROBIOL, V35, P229; Maltsev VP, 2000, REV SCI INSTRUM, V71, P243, DOI 10.1063/1.1150190; MCCLELLAND RG, 1994, J APPL BACTERIOL, V77, P440, DOI 10.1111/j.1365-2672.1994.tb03447.x; MEYER RA, 1974, HISTOCHERN CYTOCHEM, V22, P594; Morris CW, 2001, ECOL MODEL, V146, P57; MULLANEY PF, 1969, APPL OPTICS, V8, P2361, DOI 10.1364/AO.8.002361; MULLANEY PF, 1969, REV SCI INSTRUM, V40, P1029, DOI 10.1063/1.1684143; Nebeker BM, 1998, J QUANT SPECTROSC RA, V60, P493, DOI 10.1016/S0022-4073(98)00023-5; Nebeker BM, 2001, J QUANT SPECTROSC RA, V70, P749, DOI 10.1016/S0022-4073(01)00043-7; Ozanne V, 1996, J BACTERIOL, V178, P7254; PATRICK S, 1995, J MED MICROBIOL, V43, P99; PURCELL EM, 1973, ASTROPHYS J, V186, P705, DOI 10.1086/152538; R Development Core Team, 2007, R LANG ENV STAT COMP; SALZMAN GC, 1975, J OPT SOC AM, V65, P1170; SALZMAN GC, 1976, J HISTOCHEM CYTOCHEM, V24, P308; SALZMAN GC, 1975, CLIN CHEM, V21, P1297; SALZMAN GC, 1977, J OPT SOC AM, V67, P1382; SALZMAN GC, 1975, BIOPHYS J, V15, pA240; Schmehl R, 1997, J OPT SOC AM A, V14, P3026, DOI 10.1364/JOSAA.14.003026; SHOLKOPF B, 2002, ADV LECT MATH LEARN, V2600, P41; Shvalov AN, 2000, CYTOMETRY, V41, P41, DOI 10.1002/1097-0320(20000901)41:1<41::AID-CYTO6>3.0.CO;2-N; Shvalov AN, 1999, CYTOMETRY, V37, P215, DOI 10.1002/(SICI)1097-0320(19991101)37:3<215::AID-CYTO8>3.0.CO;2-3; SRIKUMAR R, 1992, MOL MICROBIOL, V6, P665, DOI 10.1111/j.1365-2958.1992.tb01514.x; Steen HB, 2004, CYTOM PART A, V57A, P94, DOI 10.1002/cyto.a.10115; TAUBENBLATT MA, 1993, J OPT SOC AM A, V10, P912, DOI 10.1364/JOSAA.10.000912; Toedling J, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-282; Van De Merwe WP, 2004, APPL OPTICS, V43, P5295, DOI 10.1364/AO.43.005295; Vapnik V. N., 2000, NATURE STAT LEARNING; VISSER JWM, 1980, BLOOD CELLS, V6, P391; Wilkins MF, 1999, APPL ENVIRON MICROB, V65, P4404; Wriedt T, 1998, PART PART SYST CHAR, V15, P67, DOI 10.1002/(SICI)1521-4117(199804)15:2<67::AID-PPSC67>3.0.CO;2-F; WYATT PJ, 1968, APPL OPTICS, V7, P1879, DOI 10.1364/AO.7.001879; Yurkin MA, 2005, APPL OPTICS, V44, P5249, DOI 10.1364/AO.44.005249	59	22	22	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	1552-4922		CYTOM PART A	Cytom. Part A	APR	2008	73A	4					369	379		10.1002/cyto.a.20515		11	Biochemical Research Methods; Cell Biology	Biochemistry & Molecular Biology; Cell Biology	284IB	WOS:000254699000013	
J	Ecker, GF; Stockner, T; Chiba, P				Ecker, Gerhard F.; Stockner, Thomas; Chiba, Peter			Computational models for prediction of interactions with ABC-transporters	DRUG DISCOVERY TODAY			English	Review							ATP-BINDING CASSETTE; MOLECULAR-DYNAMICS SIMULATIONS; PROPAFENONE-TYPE MODULATORS; HUMAN P-GLYCOPROTEIN; DRUG EFFLUX PUMPS; MULTIDRUG-RESISTANCE; NUCLEOTIDE-BINDING; ESCHERICHIA-COLI; LEAD IDENTIFICATION; FIELD ANALYSIS	The polyspecific ligand recognition pattern of ATB-binding cassette (ABC)-transporters, combined with the limited knowledge on the molecular basis of their multispecificity, makes it difficult to apply traditional molecular modelling and quantitative structure-activity relationships (QSAR) methods for identification of new ligands. Recent advances relied mainly on pharmacophore modelling and machine learning methods. Structure-based design studies suffer from the lack of available protein structures at atomic resolution. The recently published protein homology models of P-glycoprotein structure, based on the high-resolution structure of the bacterial ABC-transporter of Sav1866, may open a new chapter for structure-based studies. Last, but not least, molecular dynamics simulations have already proved their high potential for structure-function modelling of ABC-transporter. Because of the recognition of several ABC-transporters as antitargets, algorithms for predicting substrate properties are of increasing interest.	[Ecker, Gerhard F.] Univ Vienna, Dept Med Chem, A-1090 Vienna, Austria; [Stockner, Thomas] Austria Res Ctr Seibersdorf, A-2444 Seibersdorf, Austria; [Chiba, Peter] Med Univ Vienna, Inst Med Chem, Ctr Physiol & Pathophysiol, A-1090 Vienna, Austria	Ecker, GF (reprint author), Univ Vienna, Dept Med Chem, A-1090 Vienna, Austria.	gerhard.f.ecker@univie.ac.at					Boumendjel A, 2005, MED RES REV, V25, P453, DOI 10.1002/med.20032; Cabrera MA, 2006, J PHARM SCI-US, V95, P589, DOI 10.1002/jps.20449; Campbell JD, 2004, BIOPHYS J, V87, P3703, DOI 10.1529/biophysj.104.046870; Campbell JD, 2005, FEBS LETT, V579, P4193, DOI 10.1016/j.febslet.2005.06.027; Campbell JD, 2003, BIOCHEMISTRY-US, V42, P3666, DOI 10.1021/bi027337t; Chang C, 2006, DRUG METAB DISPOS, V34, P1976, DOI 10.1124/dmd.106.012351; Chang G, 2006, SCIENCE, V314, P1875; Chang G, 2001, SCIENCE, V293, P1793, DOI 10.1126/science.293.5536.1793; Chang G, 2003, J MOL BIOL, V330, P419, DOI 10.1016/S0022-2836(03)00587-4; Chiba P, 1997, QUANT STRUCT-ACT REL, V16, P361, DOI 10.1002/qsar.19970160502; Chiba P, 2004, EXPERT OPIN THER PAT, V14, P499, DOI 10.1517/eotp.14.4.499.29818; Cramer J, 2007, CHEMMEDCHEM, V2, P1783, DOI 10.1002/cmdc.200700160; Dawson RJP, 2006, NATURE, V443, P180, DOI 10.1038/nature05155; Dawson RJP, 2007, FEBS LETT, V581, P935, DOI 10.1016/j.febslet.2007.01.073; de Graaf C, 2005, J MED CHEM, V48, P2725, DOI 10.1021/jm040180d; Didziapetris R, 2003, J DRUG TARGET, V11, P391, DOI 10.1080/10611860310001648248; ECKER G, 2001, RRD MED CHE, V1, P121; Ekins S, 2002, MOL PHARMACOL, V61, P964, DOI 10.1124/mol.61.5.964; Garrigues A, 2002, MOL PHARMACOL, V62, P1288, DOI 10.1124/mol.62.6.1288; Gombar VK, 2004, J PHARM SCI-US, V93, P957, DOI 10.1002/jps.20035; Gottesman MM, 2002, NAT REV CANCER, V2, P48, DOI 10.1038/nrc706; Haubertin DY, 2006, BIOPHYS J, V91, P2517, DOI 10.1529/biophysj.106.084020; Hollenstein K, 2007, NATURE, V446, P213, DOI 10.1038/nature05626; Huang JP, 2007, J CHEM INF MODEL, V47, P1638, DOI 10.1021/ci700083n; Ivetac A, 2007, BIOCHEMISTRY-US, V46, P2767, DOI 10.1021/bi0622571; Jones PM, 2002, P NATL ACAD SCI USA, V99, P12639, DOI 10.1073/pnas.152439599; Jones PM, 2007, J BIOL CHEM, V282, P22793, DOI 10.1074/jbc.M700809200; Kaiser D, 2007, J MED CHEM, V50, P1698, DOI 10.1021/jm060604z; Kaiser D, 2005, MED CHEM, V1, P431, DOI 10.2174/1573406054864061; Langer T, 2004, ARCH PHARM, V337, P317, DOI 10.1002/ardp.200300817; Leslie EM, 2005, TOXICOL APPL PHARM, V204, P216, DOI 10.1016/j.taap.2004.10.012; Lima PDC, 2006, J CHEM INF MODEL, V46, P1245, DOI 10.1021/ci0504317; Locher KP, 2002, SCIENCE, V296, P1091, DOI 10.1126/science.1071142; Loo TW, 2002, J BIOL CHEM, V277, P41303, DOI 10.1074/jbc.C200484200; Mao QC, 2005, AAPS J, V7, pE118, DOI 10.1208/aapsj070112; McDevitt CA, 2007, PHARMACOL THERAPEUT, V113, P429, DOI 10.1016/j.pharmthera.2006.10.003; Oldham ML, 2007, NATURE, V450, P515, DOI 10.1038/nature06264; Oloo EO, 2004, J BIOL CHEM, V279, P45013, DOI 10.1074/jbc.M405084200; Oloo EO, 2006, J BIOL CHEM, V281, P28397, DOI 10.1074/jbc.M513614200; O'Mara ML, 2007, FEBS LETT, V581, P4217, DOI 10.1016/j.febslet.2007.07.069; Pajeva I, 1998, J MED CHEM, V41, P1815, DOI 10.1021/jm970786k; Pajeva IK, 2002, J MED CHEM, V45, P5671, DOI 10.1021/jm020941h; Pajeva IK, 1998, QUANT STRUCT-ACT REL, V17, P301, DOI 10.1002/(SICI)1521-3838(199808)17:04<301::AID-QSAR301>3.0.CO;2-J; Pauli-Magnus C, 2006, HEPATOLOGY, V44, P778, DOI 10.1002/hep.21359; Pauwels EKJ, 2007, DRUG NEWS PERSPECT, V20, P371, DOI 10.1358/dnp.2007.20.6.1141496; Pinkett HW, 2007, SCIENCE, V315, P373, DOI 10.1126/science.1133488; Pleban K, 2005, MINI-REV MED CHEM, V5, P153; Pleban K, 2005, MOL PHARMACOL, V67, P365, DOI 10.1124/mol.104.006973; Polli JW, 2001, J PHARMACOL EXP THER, V299, P620; Quintas-Cardama A, 2007, NAT REV DRUG DISCOV, V6, P834, DOI 10.1038/nrd2324; RAUB TJ, 2006, MOL PHARM, V1, P3; RICHTER L, 2007, 5 JOINT M MED CHEM P; Seelig A, 1998, EUR J BIOCHEM, V251, P252, DOI 10.1046/j.1432-1327.1998.2510252.x; Sonne J, 2007, BIOPHYS J, V92, P2727, DOI 10.1529/biophysj.106.097972; Thai KM, 2007, CURR MED CHEM, V14, P3003, DOI 10.2174/092986707782794087; Vandevuer S, 2006, PROTEINS, V63, P466, DOI 10.1002/prot.20892; van Loevezijn A, 2001, BIOORG MED CHEM LETT, V11, P29, DOI 10.1016/S0960-894X(00)00588-6; Wang YH, 2005, J CHEM INF MODEL, V45, P750, DOI 10.1021/ci050041k; Ward A, 2007, P NATL ACAD SCI USA, V104, P19005, DOI 10.1073/pnas.0709388104; Wiese M, 2001, CURR MED CHEM, V8, P685; Xue Y, 2004, J CHEM INF COMP SCI, V44, P1497, DOI 10.1021/ci049971e; Yu EW, 2003, SCIENCE, V300, P976, DOI 10.1126/science.1083137; ZONERCIKS JK, 2007, FASEB J, V21, P3937; *SMI C, 2007, ADMET ROL PROT STRUC	64	28	29	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1359-6446		DRUG DISCOV TODAY	Drug Discov. Today	APR	2008	13	7-8					311	317		10.1016/j.drudis.2007.12.012		7	Pharmacology & Pharmacy	Pharmacology & Pharmacy	295LI	WOS:000255475600006	
J	Wang, Y; de Silva, CW				Wang, Ying; de Silva, Clarence W.			A machine-learning approach to multi-robot coordination	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE			English	Article						multi-robot systems; cooperative control; Q-learning; genetic algorithms; intelligent transportation; multi-agent systems; autonomous robots	MULTIPLE MOBILE ROBOTS; SYSTEMS; TRANSPORTATION; MANIPULATION; ARCHITECTURE; EXPLORATION	This paper presents a machine-learning approach to the multi-robot coordination problem in an unknown dynamic environment. A multi-robot object transportation task is employed as the platform to assess and validate this approach. Specifically, a flexible two-layer multi-agent architecture is developed to implement multi-robot coordination. In this architecture, four software agents form a high-level coordination subsystem while two heterogeneous robots constitute the low-level control subsystem. Two types of machine learning-reinforcement learning (RL) and genetic algorithms (GAs)-are integrated to make decisions when the robots cooperatively transport an object to a goal location while avoiding obstacles. A probabilistic arbitrator is used to determine the winning output between the RL and GA algorithms. In particular, a modified RL algorithm called the sequential Q-learning algorithm is developed to deal with the issues of behavior conflict that arise in multi-robot cooperative transportation tasks. The learning-based high-level coordination subsystem sends commands to the low-level control subsystem, which is implemented with a hybrid force/position control scheme. Simulation and experimental results are presented to demonstrate the effectiveness and adaptivity of the developed approach. (C) 2007 Elsevier Ltd. All rights reserved.	[Wang, Ying; de Silva, Clarence W.] Univ British Columbia, Dept Mech Engn, Ind Automat Lab, Vancouver, BC V6T 1Z4, Canada	Wang, Y (reprint author), Univ British Columbia, Dept Mech Engn, Ind Automat Lab, Vancouver, BC V6T 1Z4, Canada.	yingwang70@hotmail.com					Arai T, 2002, IEEE T ROBOTIC AUTOM, V18, P655, DOI 10.1109/TRA.2002.806024; Astrom K. J., 1994, ADAPTIVE CONTROL; Cao YU, 1997, AUTON ROBOT, V4, P7, DOI 10.1023/A:1008855018923; Craig J., 2005, INTRO ROBOTICS MECH; Ferch M, 2002, ROBOT AUTON SYST, V38, P183, DOI 10.1016/S0921-8890(02)00167-7; Huntsberger T, 2003, IEEE T SYST MAN CY A, V33, P550, DOI 10.1109/TSMCA.2003.817398; Inoue Y., 2004, Proceedings of the 2004 Congress on Evolutionary Computation (IEEE Cat. No.04TH8753), DOI 10.1109/CEC.2004.1330998; Ito K, 2004, ADV ROBOTICS, V18, P83, DOI 10.1163/156855304322753317; Jones C., 2004, P 2004 IEEE RSJ INT, P381; Karray F.O., 2004, SOFT COMPUTING INTEL; Kumar M, 2004, J DYN SYST-T ASME, V126, P276, DOI 10.1115/1.1766029; Littman ML, 2001, J COGNITIVE SYSTEMS, V2, P55; Liu Jiming, 2001, MULTIAGENT ROBOTIC S; MARTINSON E, 2002, P IROS 2002 LAUS CH, P970; MARTISON E, 2003, P 2003 IEEE INT C RO, P2727; Mataric MJ, 1997, AUTON ROBOT, V4, P73, DOI 10.1023/A:1008819414322; Mitchell T, 1997, MACHINE LEARNING; Miyata N, 2002, IEEE T ROBOTIC AUTOM, V18, P769, DOI 10.1109/TRA.2002.803464; Nolfi S, 1999, AUTON ROBOT, V7, P89, DOI 10.1023/A:1008973931182; Parker LE, 2000, AUTON ROBOT, V8, P239, DOI 10.1023/A:1008977508664; Parker LE, 1998, IEEE T ROBOTIC AUTOM, V14, P220, DOI 10.1109/70.681242; Pereira GAS, 2004, INT J ROBOT RES, V23, P783, DOI 10.1177/0278364904045477; Rus D., 1995, Proceedings. 1995 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human Robot Interaction and Cooperative Robots (Cat. No.95CB35836), DOI 10.1109/IROS.1995.525802; Schenker PS, 2003, AUTON ROBOT, V14, P103, DOI 10.1023/A:1022271301244; Stone P, 1998, APPL ARTIF INTELL, V12, P165, DOI 10.1080/088395198117811; Stone P, 2000, AUTON ROBOT, V8, P345, DOI 10.1023/A:1008942012299; Stroupe A, 2005, P 2005 IEEE RSJ INT, P1989; Sugar T., 2001, Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164), DOI 10.1109/ROBOT.2001.933081; Sugar TG, 2002, IEEE T ROBOTIC AUTOM, V18, P94, DOI 10.1109/70.988979; WANG Y, 2005, P 2005 AM CONTR C AC, P1371; Wang YZ, 2006, IN C IND ENG ENG MAN, P98; Wang Y., 2006, P 2006 IEEE RSJ INT, P3694; WANG Z, 2005, P 2005 IEEE RSJ INT, P2664; Wang Z. D., 2004, P 2004 IEEE RSJ INT, P1035; Yamada S, 2001, IEEE T SYST MAN CY C, V31, P398, DOI 10.1109/5326.971668; Yamashita A, 2003, IEEE T ROBOTIC AUTOM, V19, P223, DOI 10.1109/TRA.2003.809592; Yang E, 2004, MULTIAGENT REINFORCE	37	8	10	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0952-1976		ENG APPL ARTIF INTEL	Eng. Appl. Artif. Intell.	APR	2008	21	3					470	484		10.1016/j.engappai.2007.05.006		15	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	312ZF	WOS:000256710200016	
J	Chen, YPP; Chen, F				Chen, Yi-Ping Phoebe; Chen, Feng			Identifying targets for drug discovery using bioinformatics	EXPERT OPINION ON THERAPEUTIC TARGETS			English	Editorial Material						bioinformatics; drug discovery; lead optimization; molecular biology; target identification	STRUCTURAL BIOINFORMATICS; MESSENGER-RNA; BIOLOGY; SOFTWARE; MICRORNA; IDENTIFICATION; PATHWAYS; GENOMICS; CANCER; TOOL	Background: Drug discovery is the process of discovering and designing drugs, which includes target identification, target validation, lead identification, lead optimization and introduction of the new drugs to the public. This process is very important, involving analyzing the causes of the diseases and finding ways to tackle them. Objective: The problems we must face include: i) that this process is so long and expensive that it might cost millions of dollars and take a dozen years; and ii) the accuracy of identification of targets is not good enough, which in turn delays the process. Introducing bioinformatics into the drug discovery process could contribute much to it. Bioinformatics is a booming subject combining biology with computer science. It can explore the causes of diseases at the molecular level, explain the phenomena of the diseases from the angle of the gene and make use of computer techniques, such as data mining, machine learning and so on, to decrease the scope of analysis and enhance the accuracy of the results so as to reduce the cost and time. Methods: Here we describe recent studies about how to apply bioinformatics techniques in the four phases of drug discovery, how these techniques improve the drug discovery process and some possible difficulties that should be dealt with. Results: We conclude that combining bioinformatics with drug discovery is a very promising method although it faces many problems currently.	[Chen, Yi-Ping Phoebe; Chen, Feng] Deakin Univ, Fac Sci & Technol, Geelong, Vic 3217, Australia	Chen, YPP (reprint author), Deakin Univ, Fac Sci & Technol, Geelong, Vic 3217, Australia.	phoebe@deakin.edu.au					Attwood TK, 2000, SCIENCE, V290, P471, DOI 10.1126/science.290.5491.471; AUGEN J, 2002, DRUG DISCOV TODAY, V7, P39; Blundell TL, 2006, PHILOS T R SOC B, V361, P413, DOI 10.1098/rstb.2005.1800; Bo XC, 2005, BIOINFORMATICS, V21, P1401, DOI 10.1093/bioinformatics/bti211; Ashburner M, 2000, NAT GENET, V25, P25; CHEN Q, 2007, BMC BIOINFORMATICS, V7, P394, DOI DOI 10.1186/1471-2105-7-394; Chen Y.P.P., 2005, BIOINFORMATICS TECHN; Dieterich C, 2003, BIOINFORMATICS S2, V19, P1150; Dixit SB, 2006, BIOINFORMATICS, V22, P1007, DOI 10.1093/bioinformatics/btl059; Dobson CM, 2004, NATURE, V432, P824, DOI 10.1038/nature03192; Drews J, 2000, SCIENCE, V287, P1960, DOI 10.1126/science.287.5460.1960; Gibbs JB, 2000, SCIENCE, V287, P1969, DOI 10.1126/science.287.5460.1969; GOND G, 1999, P INT C KNOWL DISC D, P43; Grunberg R, 2007, BIOINFORMATICS, V23, P769, DOI 10.1093/bioinformatics/btl655; Haberman AB, 2005, GENET ENG NEWS, V25, P36; Hede K, 2005, J NATL CANCER I, V97, P1114; Henney AM, 2006, EXPERT OPIN DRUG DIS, V1, P653, DOI 10.1517/17460441.1.7.653; Holford M, 2005, BIOINFORMATICS, V21, P1596, DOI 10.1093/bioinformatics/bti153; Holler TP, 2007, EXPERT OPIN DRUG DIS, V2, P1085, DOI 10.1517/17460441.2.8.1085; HORESH Y, 2003, BIOINFORMATICS, V19, P1173; Jennings A, 2006, EXPERT OPIN DRUG DIS, V1, P709, DOI 10.1517/17460441.1.7.709; Jorgensen WL, 2004, SCIENCE, V303, P1813, DOI 10.1126/science.1096361; Joung JG, 2007, BIOINFORMATICS, V23, P1141, DOI 10.1093/bioinformatics/btm045; Kennedy D, 2004, SCIENCE, V303, P1729, DOI 10.1126/science.303.5665.1729; Kitchen DB, 2004, NAT REV DRUG DISCOV, V3, P935, DOI 10.1038/nrd1549; Knapp K, 2007, NUCLEIC ACIDS RES, V35, P317, DOI 10.1093/nar/gkl1026; Krishnamurthy L, 2003, BIOINFORMATICS, V19, P930, DOI 10.1093/bioinformatics/btg113; KUMBLE K, 2007, EXPERT OPIN DRUG DIS, V2, P1477; Li JY, 2003, BIOINFORMATICS, V19, P71, DOI 10.1093/bioinformatics/19.1.71; Loging W, 2007, NAT REV DRUG DISCOV, V6, P220, DOI 10.1038/nrd2265; Makarenkov V, 2007, BIOINFORMATICS, V23, P1648, DOI 10.1093/bioinformatics/btm145; Makarenkov V, 2006, BIOINFORMATICS, V22, P1408, DOI 10.1093/bioinformatics/bt/126; MANN S, 2007, NUCLEIC ACIDS RES, V35, pE121; NAHAR J, 2007, DNA CELL BIOL, V10, P707; Neumann E., 2006, PAC S BIOC, P176; Novak BA, 2006, BIOINFORMATICS, V22, P233, DOI 10.1093/bioinformatics/bti764; Oyama T, 2002, BIOINFORMATICS, V18, P705, DOI 10.1093/bioinformatics/18.5.705; PFIZER TBS, 2005, CURR OPIN DRUG DISC, V8, P316; Pinter RY, 2005, BIOINFORMATICS, V21, P3401, DOI 10.1093/bioinformatics/bti554; POLLOCK S, 2000, ANNU REP MED CHEM, P1; Ratti E, 2001, PURE APPL CHEM, V73, P67, DOI 10.1351/pac200173010067; Roos DS, 2001, SCIENCE, V291, P1260, DOI 10.1126/science.291.5507.1260; Russ AP, 2007, EXPERT OPIN DRUG DIS, V2, P1379, DOI 10.1517/17460441.2.10.1379; Schreiber SL, 2000, SCIENCE, V287, P1964, DOI 10.1126/science.287.5460.1964; SHELL S, 2007, P NATL ACAD SCI USA, V27, P11400; Stevens RC, 2001, SCIENCE, V294, P89, DOI 10.1126/science.1066011; Szuromi P, 2004, SCIENCE, V303, P1795, DOI 10.1126/science.303.5665.1795; Terstappen GC, 2007, NAT REV DRUG DISCOV, V6, P891, DOI 10.1038/nrd2410; Warmuth MK, 2003, J CHEM INF COMP SCI, V43, P667, DOI 10.1021/ci025620t; Warmuth MK, 2002, ADV NEUR IN, V14, P1449; Yousef M, 2007, BIOINFORMATICS, V23, P2987, DOI 10.1093/bioinformatics/btm484; Zhang M, 2005, BIOINFORMATICS, V21, P624, DOI 10.1093/bioinformatics/bti055; ZHENG Y, 2006, J COMPUTERS, V1, P30	53	28	30	INFORMA HEALTHCARE	LONDON	TELEPHONE HOUSE, 69-77 PAUL STREET, LONDON EC2A 4LQ, ENGLAND	1472-8222		EXPERT OPIN THER TAR	Expert Opin. Ther. Targets	APR	2008	12	4					383	389		10.1517/14728222.12.4.383		7	Pharmacology & Pharmacy	Pharmacology & Pharmacy	285MG	WOS:000254780300001	
J	Hong, TP; Lin, CE; Lin, JH; Wang, SL				Hong, Tzung-Pei; Lin, Chun-E; Lin, Jiann-Horng; Wang, Shyue-Liang			Learning cross-level certain and possible rules by rough sets	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						machine learning; rough set; certain rule; possible rule; hierarchical value		Machine learning can extract desired knowledge and ease the development bottleneck in building expert systems. Among the proposed approaches, deriving rules from training examples is the most common. Given a set of examples, a learning program tries to induce rules that describe each class. Recently, the rough-set theory has been widely used in dealing with data classification problems. Most of the previous studies on rough sets focused on deriving certain rules and possible rules on the single concept level. Data with hierarchical attribute values are, however, commonly seen in real-world applications. This paper thus attempts to propose a new learning algorithm based on rough sets to find cross-level certain and possible rules from training data with hierarchical attribute values. It is more complex than learning rules from training examples with single-level values, but may derive more general knowledge from data. Boundary approximations, instead of upper approximations, are used to find possible rules, thus reducing some subsumption checking. Some pruning heuristics are also adopted in the proposed algorithm to avoid unnecessary search. (C) 2007 Elsevier Ltd. All rights reserved.	[Hong, Tzung-Pei] Natl Univ Kaohsiung, Dept Elect Engn, Kaohsiung 811, Taiwan; [Lin, Chun-E; Lin, Jiann-Horng] I Shou Univ, Inst Informat Management, Kaohsiung 840, Taiwan; [Wang, Shyue-Liang] New York Inst Technol, Dept Comp Sci, New York, NY 10023 USA	Hong, TP (reprint author), Natl Univ Kaohsiung, Dept Elect Engn, Kaohsiung 811, Taiwan.	tphong@nuk.edu.tw; jessic10@ms57.hinet.net; jhlin@isu.edu.tw; slwang@nyit.edu					BUDHANAN BG, 1984, RULE BASED EXPERT SY; Chmielewski M. R., 1993, Foundations of Computing and Decision Sciences, V18; Grzymala-Busse J. W., 1988, Journal of Intelligent and Robotic Systems: Theory and Applications, V1, DOI 10.1007/BF00437317; HIRANO S, 2002, 2002 IEEE INT C FUZZ, V2, P884, DOI 10.1109/FUZZ.2002.1006621; HONG TP, 2001, INT J FUZZY SYSTEMS, V3, P409; HONG TP, 2000, INTELL DATA ANAL, V4, P289; LAMBERTTORRES G, 1996, CAN C EL COMP ENG, P278; LEE CH, 2001, 9 IFSA WORLD C 20 NA, V1, P447; Lingras PJ, 1998, J AM SOC INFORM SCI, V49, P415, DOI 10.1002/(SICI)1097-4571(19980415)49:5<415::AID-ASI4>3.3.CO;2-Q; Michalski R. S., 1983, MACHINE LEARNING ART, V1; MICHALSKI RS, 1984, MACHINE LEARNING ART, V2; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Pawlak Z., 1996, 5 IEEE INT C FUZZ SY, V2, P738; Pawlak Z., 1991, ROUGH SETS THEORETIC; TSUMOTO S, 1998, INTELLIGENT DATA ANA, V2, P215, DOI 10.1016/S1088-467X(98)00025-0; TSUMTO S, 1998, 1998 IEEE INT C FUZZ, V2, P1296, DOI 10.1109/FUZZY.1998.686306; Yao YY, 1999, 18TH INTERNATIONAL CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS, P800, DOI 10.1109/NAFIPS.1999.781804; Zhong N, 1998, IEEE INT C FUZZY SYS, P933	18	9	12	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	APR	2008	34	3					1698	1706		10.1016/j.eswa.2007.01.038		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	262YB	WOS:000253183700012	
J	Kao, YT; Zahara, E; Kao, IW				Kao, Yi-Tung; Zahara, Erwie; Kao, I-Wei			A hybridized approach to data clustering	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						data clustering; K-means clustering; Nelder-Mead simplex search method; Particle swarm optimization	PARTICLE SWARM OPTIMIZATION; FUNCTION MINIMIZATION; GLOBAL OPTIMIZATION; GENETIC ALGORITHMS; SIMPLEX-METHOD; SEARCH	Data clustering helps one discern the structure of and simplify the complexity of massive quantities of data. It is a common technique for statistical data analysis and is used in many fields, including machine learning, data mining, pattern recognition, image analysis, and bioinformatics, in which the distribution of information can be of any size and shape. The well-known K-means algorithm, which has been successfully applied to many practical clustering problems, suffers from several drawbacks due to its choice of initializations. A hybrid technique based on combining the K-means algorithm, Nelder-Mead simplex search, and particle swarm optimization, called K-NM-PSO, is proposed in this research. The K-NM-PSO searches for cluster centers of an arbitrary data set as does the K-means algorithm, but it can effectively and efficiently find the global optima. The new K-NM-PSO algorithm is tested on nine data sets, and its performance is compared with those of PSO, NM-PSO, K-PSO and K-means clustering. Results show that K-NM-PSO is both robust and suitable for handling data clustering. (C) 2007 Elsevier Ltd. All rights reserved.	[Kao, Yi-Tung] Tatung Univ, Dept Comp Sci & Engn, Taipei 104, Taiwan; [Zahara, Erwie; Kao, I-Wei] St Johns Univ, Dept Ind Engn & Management, Tamsui 251, Taiwan	Zahara, E (reprint author), Tatung Univ, Dept Comp Sci & Engn, Taipei 104, Taiwan.	erwi@mail.sju.edu.tw					Bandyopadhyay S, 2002, INFORM SCIENCES, V146, P221, DOI 10.1016/S0020-0255(02)00208-6; Chen C.-Y., 2004, P IEEE INT C NETW SE, P789; Eberhart RC, 2001, IEEE C EVOL COMPUTAT, P94, DOI 10.1109/CEC.2001.934376; Fan SKS, 2004, ENG OPTIMIZ, V36, P401, DOI 10.1080/0305215041000168521; HOOKE R, 1961, J ACM, V8, P212, DOI 10.1145/321062.321069; Hu X, 2001, P WORKSH PART SWARM; KAUFMAN L, 1990, FINGING GROUPS DATA; Kennedy J., 1995, P IEEE INT C NEUR NE, V4, P1942, DOI DOI 10.1109/ICNN.1995.488968; Murthy CA, 1996, PATTERN RECOGN LETT, V17, P825, DOI 10.1016/0167-8655(96)00043-8; NELDER JA, 1965, COMPUT J, V7, P308; OLSSON DM, 1975, TECHNOMETRICS, V17, P45, DOI 10.2307/1267998; Paterlini S, 2006, COMPUT STAT DATA AN, V50, P1220, DOI 10.1016/j.csda.2004.12.004; Renders JM, 1996, IEEE T SYST MAN CY B, V26, P243, DOI 10.1109/3477.485836; SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81; SPENDLEY W, 1962, TECHNOMETRICS, V4, P441, DOI 10.2307/1266283; Yen J, 1998, IEEE T SYST MAN CY B, V28, P173, DOI 10.1109/3477.662758	16	49	53	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	APR	2008	34	3					1754	1762		10.1016/j.eswa.2007.01.028		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	262YB	WOS:000253183700017	
J	Li, DC; Fang, YH				Li, Der-Chiang; Fang, Yao-Hwei			An algorithm to cluster data for efficient classification of support vector machines	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						density-based clustering algorithm; machine learning; support vector machines; computational complexity		Support vector machines (SVM) are widely applied to various classification problems. However, most SVM need lengthy computation time when faced with a large and complicated dataset. This research develops a clustering algorithm for efficient learning. The method mainly categorizes data into clusters, and finds critical data in clusters as a substitute for the original data to reduce the computational complexity. The computational experiments presented in this paper show that the clustering algorithm significantly advances SVM learning efficiency. (c) 2007 Elsevier Ltd. All rights reserved.	[Li, Der-Chiang; Fang, Yao-Hwei] Natl Cheng Kung Univ, Dept Ind & Informat Engn, Tainan 701, Taiwan	Li, DC (reprint author), Natl Cheng Kung Univ, Dept Ind & Informat Engn, 1 Univ Rd, Tainan 701, Taiwan.	lidc@mail.ncku.edu.tw; yaohwei-fang@hotmail.com					Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Corinna C., 1995, MACH LEARN, V20, P273; DON H, 2003, MACH LEARN, V51, P51; EDDA L, 2002, MACH LEARN, V46, P423; Hsu C. W., 2003, PRACTICAL GUIDE SUPP; Jiawei H., 2001, DATA MINING CONCEPTS; Komura D, 2005, BIOINFORMATICS, V21, P439, DOI 10.1093/bioinformatics/bti188; Marcelo B, 2000, P 6 BRAZ S NEUR NETW, P162; MARTIN E, 1996, P 2 INT C KNOWL DISC, P226; Shigeo A, 2005, SUPPORT VECTOR MACHI; Shin KS, 2005, EXPERT SYST APPL, V28, P127, DOI 10.1016/j.eswa.2004.08.009; TRAN QA, 2003, P 2 INT C MACH LEARN, P1245; Yang XW, 2003, PROG NAT SCI, V13, P750, DOI 10.1080/10020070312331344360	13	7	11	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	APR	2008	34	3					2013	2018		10.1016/j.eswa.2007.02.016		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	262YB	WOS:000253183700044	
J	Bibi, S; Tsoumakas, G; Stamelos, I; Vlahavas, I				Bibi, S.; Tsoumakas, G.; Stamelos, I.; Vlahavas, I.			Regression via Classification applied on software defect estimation	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						software quality; software metrics; software fault estimation; Regression via Classification; ISBSG data set; machine learning	MODELS; PREDICTION; FAULTS; NUMBER	In this paper we apply Regression via Classification (RvC) to the problem of estimating the number of software defects. This approach apart from a certain number of faults, it also outputs an associated interval of values, within which this estimate lies with a certain confidence. RvC also allows the production of comprehensible models of software defects exploiting symbolic learning algorithms. To evaluate this approach we perform an extensive comparative experimental study of the effectiveness of several machine learning algorithms in two software data sets. RvC manages to get better regression error than the standard regression approaches on both datasets. (c) 2007 Elsevier Ltd. All rights reserved.	[Bibi, S.; Tsoumakas, G.; Stamelos, I.; Vlahavas, I.] Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece	Bibi, S (reprint author), Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.	sbibi@csd.auth.gr; greg@csd.auth.gr; stamelos@csd.auth.gr; vlahavas@csd.auth.gr					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Bellini P, 2005, IEEE INT C ENG COMP, P205; BIBI S, 2006, P 4 ACS IEEE INT C C, P330; Bishop C.M., 1995, NEURAL NETWORKS PATT; Briand LC, 2002, IEEE T SOFTWARE ENG, V28, P706, DOI 10.1109/TSE.2002.1019484; Cohen W. W., 1995, P 12 INT C MACH LEAR, P115; Cohen WW, 1999, INT J SOFTW ENG KNOW, V9, P519, DOI 10.1142/S0218194099000292; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; Emam MEM, 2001, J THERM ANAL CALORIM, V63, P75, DOI 10.1023/A:1010128201853; Fenton N, 2001, KNOWL-BASED SYST, V14, P307, DOI 10.1016/S0950-7051(00)00071-X; Fenton NE, 1999, IEEE T SOFTWARE ENG, V25, P675, DOI 10.1109/32.815326; GAFFNEY JR, 1984, IEEE T SOFTW ENG, V10; HALSTEAD MH, 1975, ELEMENTS SOFTWARE SC; KAMIYA T, 1999, 2 INT S OBJ OR REAL, P53; KHOSHGOFTAAR TM, 2002, IEEE METRICS, V203; Kohavi R., 1995, THESIS STANFORD U; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Lanubile F, 1997, J SYST SOFTWARE, V38, P225, DOI 10.1016/S0164-1212(96)00153-7; LANUBILE F, 1995, P 7 INT C SOFTW ENG, P312; LIPOW M, 1982, IEEE T SOFTWARE ENG, V8, P437, DOI 10.1109/TSE.1982.235579; Maxwell KD, 2002, APPL STAT SOFTWARE M; McCabe T. J., 1976, IEEE Transactions on Software Engineering, VSE-2, DOI 10.1109/TSE.1976.233837; NEUMANN R, 2004, INT WORKSH SOFTW MEA; Ostrand TJ, 2005, IEEE T SOFTWARE ENG, V31, P340, DOI 10.1109/TSE.2005.49; Platt J., 1998, ADV KERNEL METHODS S; Quah TS, 2004, INFORM SOFTWARE TECH, V46, P519, DOI 10.1016/j.infsof.2003.08.006; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Rousseeuw P, 1987, ROBUST REGRESSION OU; Smola AJ, 1998, NEUROCOLT2 TECHNICAL; STURGE H, 1926, J AM STAT ASSOC, P65; TOMASZEWSKI P, 2003, ECBS, P334; Torgo L., 1997, INTELLIGENT DATA ANA, V4, P275, DOI 10.1016/S1088-467X(97)00013-9; TSOUMAKAS G, 2004, ECML 04, P465; Weiss SM, 1995, J ARTIF INTELL RES, V3, P383; Witten I., 1998, P 15 INT C MACH LEAR, P144; Witten I. H., 1999, DATA MINING PRACTICA; WOLPERT D, 1992, NEURAL NETWORKS, P241; Wooff DA, 2002, IEEE T SOFTWARE ENG, V28, P510, DOI 10.1109/TSE.2002.1000453; Zhong S, 2004, IEEE INTELL SYST, V19, P20, DOI 10.1109/MIS.2004.1274907; Zhong S, 2004, EIGHTH IEEE INTERNATIONAL SYMPOSIUM ON HIGH ASSURANCE SYSTEMS ENGINEERING, PROCEEDINGS, P149	41	7	8	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	APR	2008	34	3					2091	2101		10.1016/j.eswa.2007.02.012		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	262YB	WOS:000253183700052	
J	Levenson, R; Gossage, KW; Hope, T; Hoyt, CC; Gardner, H				Levenson, Richard; Gossage, Kirk W.; Hope, Tyna; Hoyt, Clifford C.; Gardner, Humphrey			Automated machine-learning-based image segmentation plus quantitative, multiplexed imaging for rapid, accurate molecular phenotyping	FASEB JOURNAL			English	Meeting Abstract									[Levenson, Richard; Gossage, Kirk W.; Hope, Tyna; Hoyt, Clifford C.] CRT, Woburn, MA USA; [Gardner, Humphrey] Novartis Inst Biomed Res, Cambridge, MA USA								0	0	0	FEDERATION AMER SOC EXP BIOL	BETHESDA	9650 ROCKVILLE PIKE, BETHESDA, MD 20814-3998 USA	0892-6638		FASEB J	Faseb J.	APR	2008	22											1	Biochemistry & Molecular Biology; Biology; Cell Biology	Biochemistry & Molecular Biology; Life Sciences & Biomedicine - Other Topics; Cell Biology	V25GY	WOS:000208467700597	
J	Morin, RD; Aksay, G; Dolgosheina, E; Ebhardt, HA; Magrini, V; Mardis, ER; Sahinalp, SC; Unrau, PJ				Morin, Ryan D.; Aksay, Gozde; Dolgosheina, Elena; Ebhardt, H. Alexander; Magrini, Vincent; Mardis, Elaine R.; Sahinalp, S. Cenk; Unrau, Peter J.			Comparative analysis of the small RNA transcriptomes of Pinus contorta and Oryza sativa	GENOME RESEARCH			English	Article							ARABIDOPSIS-THALIANA; PLANT MICRORNAS; DATABASE; SEQUENCES; GENES; IDENTIFICATION; ANNOTATION; BIOGENESIS; BROWSER; TARGETS	The diversity of microRNAs and small-interfering RNAs has been extensively explored within angiosperms by focusing on a few key organisms such as Oryza sativa and Arabidopsis thaliana. A deeper division of the plants is defined by the radiation of the angiosperms and gymnosperms, with the latter comprising the commercially important conifers. The conifers are expected to provide important information regarding the evolution of highly conserved small regulatory RNAs. Deep sequencing provides the means to characterize and quantitatively profile small RNAs in understudied organisms such as these. Pyrosequencing of small RNAs from O. sativa revealed, as expected, similar to 21- and similar to 24-nt RNAs. The former contained known microRNAs, and the latter largely comprised intergenic-derived sequences likely representing heterochromatin siRNAs. In contrast, sequences from Pinus contorta were dominated by 21-nt small RNAs. Using a novel sequence-based clustering algorithm, we identified sequences belonging to 18 highly conserved microRNA families in P. contorta as well as numerous clusters of conserved small RNAs of unknown function. Using multiple methods, including expressed sequence folding and machine learning algorithms, we found a further 53 candidate novel microRNA families, 51 appearing specific to the P. contorta library. In addition, alignment of small RNA sequences to the O. sativa genome revealed six perfectly conserved classes of small RNA that included chloroplast transcripts and specific types of genomic repeats. The conservation of microRNAs and other small RNAs between the conifers and the angiosperms indicates that important RNA silencing processes were highly developed in the earliest spermatophytes. Genomic mapping of all sequences to the O. sativa genome can be viewed at http://microrna.bcgsc.ca/cgi-bin/gbrowse/rice_build_3/.	[Dolgosheina, Elena; Unrau, Peter J.] Simon Fraser Univ, Dept Mol Biol & Biochem, Burnaby, BC V5A 1S6, Canada; [Morin, Ryan D.] BC Canc Agcy, Genome Sci Ctr, Vancouver, BC V5Z 1L3, Canada; [Aksay, Gozde] Univ Washington, Dept Genome Sci, Seattle, WA 98195 USA; [Ebhardt, H. Alexander] Univ Alberta, Dept Biochem, Edmonton, AB T6G 2H7, Canada; [Magrini, Vincent; Mardis, Elaine R.] Washington Univ, Sch Med, Genome Sequencing Ctr, St Louis, MO 63108 USA; [Sahinalp, S. Cenk] Simon Fraser Univ, Dept Comp Sci, Burnaby, BC V5A 1S6, Canada	Unrau, PJ (reprint author), Simon Fraser Univ, Dept Mol Biol & Biochem, Burnaby, BC V5A 1S6, Canada.	punrau@sfu.ca					Ambros V, 2003, RNA, V9, P277, DOI 10.1261/rna.2183803; Bartel DP, 2004, CELL, V116, P281, DOI 10.1016/S0092-8674(04)00045-5; Bonnet E, 2004, P NATL ACAD SCI USA, V101, P11511, DOI 10.1073/pnas.0404025101; Borsani O, 2005, CELL, V123, P1279, DOI 10.1016/j.cell.2005.11.035; Chen ZY, 2006, GENETICA, V128, P21, DOI 10.1007/s10709-005-2486-0; Cheng ZK, 2002, PLANT CELL, V14, P1691, DOI 10.1105/tpc.003079; Fahlgren N, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000219; Gower J, 1969, APPL STATIST, V18, P54, DOI 10.2307/2346439; Griffiths-Jones Sam, 2006, V342, P129, DOI 10.1385/1-59745-123-1:129; Griffiths-Jones S, 2003, NUCLEIC ACIDS RES, V31, P439, DOI 10.1093/nar/gkg006; Gustafson AM, 2005, NUCLEIC ACIDS RES, V33, pD637, DOI 10.1093/nar/gki127; Hashimoto M, 2003, PLANT J, V36, P541, DOI 10.1046/j.1365-313X.2003.01900.x; Herr AJ, 2005, FEBS LETT, V579, P5879, DOI 10.1016/j.febslet.2005.08.040; Hofacker IL, 2003, NUCLEIC ACIDS RES, V31, P3429, DOI 10.1093/nar/gkg599; Itoh T, 2007, GENOME RES, V17, P175, DOI 10.1101/gr.5509507; Johnson C, 2007, NUCLEIC ACIDS RES, V35, pD829, DOI 10.1093/nar/gkl991; Jones-Rhoades MW, 2004, MOL CELL, V14, P787, DOI 10.1016/j.molcel.2004.05.027; LAU LC, 2001, SCIENCE, V5543, P858; Bennett MD, 2005, ANN BOT-LONDON, V95, P45, DOI 10.1093/aob/mci003; Lindow M, 2005, BMC GENOMICS, V6, DOI 10.1186/1471-2164-6-119; Lu C, 2005, SCIENCE, V309, P1567, DOI 10.1126/science.1114112; Margulies M, 2005, NATURE, V437, P376, DOI 10.1038/nature03959; McCarthy E.M., 2002, GENOME BIOL, V3, DOI DOI 10.1186/GB-2002-3-10-RESEARCH0053; Nakano M, 2006, NUCLEIC ACIDS RES, V34, pD731, DOI 10.1093/nar/gkj077; Park W, 2002, CURR BIOL, V12, P1484, DOI 10.1016/S0960-9822(02)01017-5; Pavy N, 2005, BMC GENOMICS, V6, DOI 10.1186/1471-2164-6-144; Pontier D, 2005, GENE DEV, V19, P2030, DOI 10.1101/gad.348405; PONTIUS JU, 2002, NCBI HDB; Quackenbush J, 2001, NUCLEIC ACIDS RES, V29, P159, DOI 10.1093/nar/29.1.159; Rajagopalan R, 2006, GENE DEV, V20, P3407, DOI 10.1101/gad.1476406; SCHNEIDER TD, 1990, NUCLEIC ACIDS RES, V18, P6097, DOI 10.1093/nar/18.20.6097; Seliverstov Alexander, 2006, Journal of Bioinformatics and Computational Biology, V4, P783, DOI 10.1142/S0219720006002235; Stein LD, 2002, GENOME RES, V12, P1599, DOI 10.1101/gr.403602; Talmor-Neiman M, 2006, PLANT J, V48, P511, DOI 10.1111/j.1365-313X.2006.02895.x; Vazquez F, 2006, TRENDS PLANT SCI, V11, P460, DOI 10.1016/j.tplants.2006.07.006; Wang MB, 2005, CURR OPIN PLANT BIOL, V8, P216, DOI 10.1016/j.pbi.2005.01.006; Williams L, 2005, P NATL ACAD SCI USA, V102, P9703, DOI 10.1073/pnas.0504029102; Witten I. H., 2005, DATA MINING PRACTICA; NEEDLEMA.SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4; Xie ZX, 2004, PLOS BIOL, V2, P642, DOI 10.1371/journal.pbio.0020104; Yao YY, 2007, GENOME BIOL, V8, DOI 10.1186/gb-2007-8-6-r96; Zhang BH, 2006, CELL MOL LIFE SCI, V63, P246, DOI 10.1007/s00018-005-5467-7; Zhang BH, 2006, PLANT J, V46, P243, DOI 10.1111/j.1365-313X.2006.02697.X; Zhang YJ, 2005, NUCLEIC ACIDS RES, V33, pW701, DOI 10.1093/nar/gki383; Zhang Z, 2000, J COMPUT BIOL, V7, P203, DOI 10.1089/10665270050081478	45	99	101	COLD SPRING HARBOR LAB PRESS, PUBLICATIONS DEPT	WOODBURY	500 SUNNYSIDE BLVD, WOODBURY, NY 11797-2924 USA	1088-9051		GENOME RES	Genome Res.	APR	2008	18	4					571	584		10.1101/gr.6897308		14	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Genetics & Heredity	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Genetics & Heredity	282IZ	WOS:000254562400007	
J	Im, J; Jensen, JR; Hodgson, ME				Im, Jungho; Jensen, John R.; Hodgson, Michael E.			Object-based land cover classification using high-posting-density LiDAR data	GISCIENCE & REMOTE SENSING			English	Article							CORRELATION IMAGE-ANALYSIS; SPECIES COMPOSITION; AERIAL-PHOTOGRAPHY; AIRBORNE LIDAR; LEAF-OFF; ACCURACY; TEXTURE	This study introduces a method for object-based land cover classification based solely on the analysis of LiDAR-derived information-i.e., without the use of conventional optical imagery such as aerial photography or multispectral imagery. The method focuses on the relative information content from height, intensity, and shape of features found in the scene. Eight object-based metrics were used to classify the terrain into land cover information: mean height, standard deviation (STDEV) of height, height homogeneity, height contrast, height entropy, height correlation, mean intensity, and compactness. Using machine-learning decision trees, these metrics yielded land cover classification accuracies > 90%. A sensitivity analysis found that mean intensity was the key metric for differentiating between the grass and road/parking lot classes. Mean height was also a contributing discriminator for distinguishing features with different height information, such as between the building and grass classes. The shape- or texture-based metrics did not significantly improve the land cover classifications. The most important three metrics (i.e., mean height, STDEV height, and mean intensity) were sufficient to achieve classification accuracies > 90%.	[Im, Jungho] SUNY Syracuse, Coll Environm Sci & Forestry, Syracuse, NY 13210 USA; [Jensen, John R.; Hodgson, Michael E.] Univ S Carolina, Dept Geog, Columbia, SC 29208 USA	Im, J (reprint author), SUNY Syracuse, Coll Environm Sci & Forestry, 1 Forestry Dr, Syracuse, NY 13210 USA.	imj@esf.edu					Baatz M., 2004, ECOGNITION USER GUID; Baltsavias EP, 1999, ISPRS J PHOTOGRAMM, V54, P199, DOI 10.1016/S0924-2716(99)00015-5; Benz UC, 2004, ISPRS J PHOTOGRAMM, V58, P239, DOI 10.1016/j.isprsjprs.2003.10.002; BOLAND J, 2004, MANUAL PHOTOGRAMMETR, P629; BORK EW, 2007, IN PRESS REMOTE SENS; Brandtberg T, 2007, ISPRS J PHOTOGRAMM, V61, P325, DOI 10.1016/j.isprsjprs.2006.10.006; Flood M, 1997, PHOTOGRAMM ENG REM S, V63, P327; Franklin SE, 2001, PHOTOGRAMM ENG REM S, V67, P849; GARCIAQUIJANO MJ, 2007, IN PRESS PHOTOGRAMME; Haralick R. M., 1986, HDB PATTERN RECOGNIT; Hill RA, 2005, INT J REMOTE SENS, V26, P3763, DOI 10.1080/01431160500114706; Hodgson ME, 2003, PHOTOGRAMM ENG REM S, V69, P973; Hodgson ME, 2005, PHOTOGRAMM ENG REM S, V71, P817; Huang XQ, 1997, PHOTOGRAMM ENG REM S, V63, P1185; Im J, 2008, INT J REMOTE SENS, V29, P399, DOI 10.1080/01431160601075582; Im J, 2005, REMOTE SENS ENVIRON, V99, P326, DOI 10.1016/j.rse.2005.09.008; IM J, 2006, THESIS U S CARONLINA; Jensen J. R., 2007, GEOSPATIAL TECHNOLOG, P7, DOI 10.1007/978-3-540-69417-5_2; Jensen J.R., 2005, INTRO DIGITAL IMAGE; Jensen J.R., 2007, REMOTE SENSING ENV; Lee JM, 2003, J IMMUNOTHER, V26, P117, DOI 10.1097/00002371-200303000-00004; LEONARD J, 2005, TECHNICAL APPROACH L; MACKEY HE, 1998, ROLES HIST PHOTOGRAP; Maillard P, 2003, PHOTOGRAMM ENG REM S, V69, P357; Mikhail EM, 2001, INTRO MODERN PHOTOGR; Quinlan J., 2003, DATA MINING TOOLS SE; Raber GT, 2007, PHOTOGRAMM ENG REM S, V73, P793; Rottensteiner F., 2005, Information Fusion, V6, DOI 10.1016/j.inffus.2004.06.004; SONG JH, 2002, ISPRS COMM 3 S 9 13; Suarez JC, 2005, COMPUT GEOSCI-UK, V31, P253, DOI 10.1016/j.cageo.2004.09.015; Toyra J, 2005, REMOTE SENS ENVIRON, V97, P174, DOI 10.1016/j.rse.2005.03.012; *RULEQUEST RES, 2005, C5 0 REL 2 01	32	14	15	BELLWETHER PUBL LTD	COLUMBIA	8640 GUILFORD RD, STE 200, COLUMBIA, MD 21046 USA	1548-1603		GISCI REMOTE SENS	GISci. Remote Sens.	APR-JUN	2008	45	2					209	228		10.2747/1548-1603.45.2.209		20	Geography, Physical; Remote Sensing	Physical Geography; Remote Sensing	295KB	WOS:000255472300005	
J	Adamopoulou, E; Demestichas, K; Theologou, M				Adamopoulou, Evgenia; Demestichas, Konstantinos; Theologou, Michael			Enhanced estimation of configuration capabilities in cognitive radio	IEEE COMMUNICATIONS MAGAZINE			English	Article								Cognitive radio is a highly promising answer to the complexity and heterogeneity characterizing the beyond 3G wireless scenario. In this context, this article advances from the field of interference sensing to the fields of (basic) reasoning and robust reasoning. Interference sensing is concerned with the acquisition of interference related measurements for frequency bands of interest. The article describes how a cognitive radio system can reason on these measurements to obtain estimations for the capabilities of alternate configurations, especially in terms of achievable transmission capacity and coverage. Subsequently, it focuses on robust reasoning, namely, on enhancing these estimations by employing machine learning, which constitutes an important aspect of cognitive radio. Several relevant solutions are sketched and explained, with a view to providing a complete picture.	[Adamopoulou, Evgenia; Demestichas, Konstantinos; Theologou, Michael] Natl Tech Univ Athens, Sch Elect & Comp Engn, GR-10682 Athens, Greece	Adamopoulou, E (reprint author), Natl Tech Univ Athens, Sch Elect & Comp Engn, GR-10682 Athens, Greece.	eadam@cn.ntua.gr; cdemest@cn.ntua.gr; theolog@cs.ntua.gr					Del Prado J., 2003, ICC 03, P1108; Haykin S, 2005, IEEE J SEL AREA COMM, V23, P201, DOI 10.1109/JSAC.2004.839380; Kolodzy P. J., 2006, International Journal of Network Management, V16, DOI 10.1002/nem.608; Mitchell T, 1997, MACHINE LEARNING; Mitola III J., 2000, THESIS ROYAL I TECH; Mitola J, 1999, IEEE PERS COMMUN, V6, P13, DOI 10.1109/98.788210; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Williams RJ, 1995, BACK PROPAGATION THE, P433	8	10	13	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0163-6804		IEEE COMMUN MAG	IEEE Commun. Mag.	APR	2008	46	4					56	63		10.1109/MCOM.2008.4481341		8	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	289VY	WOS:000255083200008	
J	Zhong, P; Zhang, P; Wang, RS				Zhong, Ping; Zhang, Peng; Wang, Runsheng			Dynamic learning of SMLR for feature selection and classification of hyperspectral data	IEEE GEOSCIENCE AND REMOTE SENSING LETTERS			English	Article						dynamic learning (DL); feature selection; sparse multinomial logistic regression (SMLR)	MULTINOMIAL LOGISTIC-REGRESSION; ALGORITHMS; IMAGES	Feature selection is an important task in the analysis of hyperspectral data. Recently developed methods for learning sparse classifiers, which combine the automatic feature selection and classifier design, established themselves among the state of the art in the literature of machine learning. In this letter, the sparse multinomial logistic regression (SMLR) is introduced into the community of remote sensing and is utilized for the feature selection in the classification of hyperspectral data. To relieve the heavy degeneration of classification performance caused by the characteristics of the hyperspectral data and the oversparsity when the SMLR selects a small feature subset, we develop a dynamic learning framework to train the SMLR. Experimental results attest to the effectiveness of the proposed method.	[Zhong, Ping; Zhang, Peng; Wang, Runsheng] Natl Univ Def Technol, ATR Natl Lab, Sch Elect Sci & Engn, Changsha 410073, Hunan, Peoples R China	Zhong, P (reprint author), Natl Univ Def Technol, ATR Natl Lab, Sch Elect Sci & Engn, Changsha 410073, Hunan, Peoples R China.	zhongping@nudt.edu.cn; zhangpeng@nudt.edu.cn; rswang@nudt.edu.cn			NDTF Project of the ATR Laboratory [9140C8002010705]	The work of P. Zhang was supported by the NDTF Project of the ATR Laboratory under Grant 9140C8002010705.	BOHNING D, 1992, ANN I STAT MATH, V44, P197, DOI 10.1007/BF00048682; Cheng Q, 2006, IEEE GEOSCI REMOTE S, V3, P491, DOI 10.1109/LGRS.2006.877949; Guo BF, 2006, IEEE GEOSCI REMOTE S, V3, P522, DOI 10.1109/LGRS.2006.878240; HABBEMA JDF, 1977, TECHNOMETRICS, V19, P487, DOI 10.2307/1267890; HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Krishnapuram B, 2005, IEEE T PATTERN ANAL, V27, P957, DOI 10.1109/TPAMI.2005.127; LANDGREBE D, 2002, IEEE SIGNAL PROCESS, V19, P7; Liu H., 1996, P 13 INT C MACH LEAR, P319; Narlikar L, 2006, BIOINFORMATICS, V22, P157, DOI 10.1093/bioinformatics/bti731; Ng A. Y., 2004, P 21 INT C MACH LEAR, P78; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Serpico SB, 2001, IEEE T GEOSCI REMOTE, V39, P1360, DOI 10.1109/36.934069; Serpico SB, 2007, IEEE T GEOSCI REMOTE, V45, P484, DOI 10.1109/TGRS.2006.886177; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8	15	11	11	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1545-598X		IEEE GEOSCI REMOTE S	IEEE Geosci. Remote Sens. Lett.	APR	2008	5	2					280	284		10.1109/LGRS.2008.915930		5	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing	Geochemistry & Geophysics; Engineering; Remote Sensing	342EH	WOS:000258766900034	
J	Zhou, L; Zenebe, A				Zhou, Lina; Zenebe, Azene			Representation and reasoning under uncertainty in deception detection: A neuro-fuzzy approach	IEEE TRANSACTIONS ON FUZZY SYSTEMS			English	Article						deception detection; fuzzy sets; fuzzy systems; uncertainty	COMPUTER-MEDIATED COMMUNICATION; DECISION-MAKING; INTERPERSONAL DECEPTION; CLASSIFICATION; CUES; DOMINANCE; RICHNESS; NETWORKS; SYSTEMS; DESIGN	An analysis of the process and human cognitive model of deception detection (DD) shows that DD is infused with uncertainty, especially in high-stake situations. There is a recent trend toward automating DD in computer-mediated communication. However, extant approaches to automatic DD overlook the importance of representation and reasoning under uncertainty in DD. They represent uncertain cues as crisp values and can only infer whether deception occurs, but not to what extent deception occurs. Based on uncertainty theories and the analyses of uncertainty in DD, we propose a model to represent cues and to reason for DD under uncertainty, and address the uncertainty due to imprecision and vagueness in DD using fuzzy sets and fuzzy logic. Neuro-fuzzy models were developed to discover knowledge for DD. The evaluation results on five data sets showed that the neuro-fuzzy method not only was a good alternative to traditional machine-learning techniques but also offered superior interpretability and reliability. Moreover, the gains of neuro-fuzzy systems over traditional systems became larger as the level of uncertainty associated with DD increased. The findings of this paper have theoretical, methodological, and practical implications to DD and fuzzy systems research.	[Zhou, Lina] Univ Maryland Baltimore Cty, Dept Informat Syst, Baltimore, MD 21250 USA; [Zenebe, Azene] Bowie State Univ, Dept Management Informat Syst, Bowie, MD 20715 USA	Zhou, L (reprint author), Univ Maryland Baltimore Cty, Dept Informat Syst, Baltimore, MD 21250 USA.	zhoul@umbc.edu; azenebe@bowiestate.edu					Abe S., 2001, PATTERN CLASSIFICATI; BAHL HC, 1984, SIGMIS DATABASE, V15, P10; Bilgic T., 1999, HDB FUZZY SETS SYSTE, V1, P195; Boucher TO, 2002, IEEE T SYST MAN CY C, V32, P190, DOI 10.1109/TSMCC.2002.804447; BOUCKAERT R, 2004, PAC AS C KNOWL UNPUB; Buller DB, 1996, COMMUN THEOR, V6, P203, DOI 10.1111/j.1468-2885.1996.tb00127.x; BURGOON JK, 2001, NAT COMM ASS C UNPUB; Burgoon JK, 1993, COMMUN THEORY, V3, P295, DOI 10.1111/j.1468-2885.1993.tb00076.x; BURGOON JK, 2005, 38 HAW INT C S UNPUB; BURGOON JK, 2003, LNCS UNPUB, V2665; Chakraborty D, 2004, IEEE T NEURAL NETWOR, V15, P110, DOI 10.1109/TNN.2003.820557; CHEN Q, 1995, INFORM SYST, P174; CHEN YS, 2001, P IASTED INT C ART I; Chen Z., 2001, DATA MINING UNCERTAI; Cordon O., 2001, ADV FUZZY SYSTEMS AP, V19; Cox E., 1999, FUZZY SYSTEMS HDB; CURRAM SP, 1994, J OPER RES SOC, V45, P440, DOI 10.1057/jors.1994.62; DAFT RL, 1986, MANAGE SCI, V32, P554, DOI 10.1287/mnsc.32.5.554; Dennis AR, 1998, INFORM SYST RES, V9, P256, DOI 10.1287/isre.9.3.256; DePaulo B. M., 1980, REV PERSONALITY SOCI, V1, P125; DePaulo B. M., 1985, SELF SOCIAL LIFE, P323; DePaulo BM, 2003, PSYCHOL BULL, V129, P74, DOI 10.1037//0033-2909.129.1.74; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Dietterich TG, 1995, MACHINE LEARNING BIA; FRIEDMAN J. H., 1996, LOCAL LEARNING BASED; GIORDANO GA, 2005, 38 HAW INT C S UNPUB; Goebel M., 1999, SIGKDD EXPLORATIONS, V1, P20; Iyer NS, 2003, IEEE T SYST MAN CY A, V33, P441, DOI 10.1109/TSMCA.2003.817036; JOHNSON G, 2004, LNCS UNPUB; Joslyn C, 1998, INFORM SCIENCES, V110, P255, DOI 10.1016/S0020-0255(98)00011-5; KLIR GJ, 1988, FUZZY SETS UNC UNPUB; KUNCHEVA LL, 2000, FUZZY CLASSIFIER DES, V49; Mao JY, 2000, J MANAGE INFORM SYST, V17, P153; MCGARTH JE, 1984, GROUPS INTERACTION P; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; NAUCK D, 1997, FDN NEURO FUZZY SYST; Nauck D, 1999, ARTIF INTELL MED, V16, P149, DOI 10.1016/S0933-3657(98)00070-0; Olaru C, 2003, FUZZY SET SYST, V138, P221, DOI 10.1016/S0165-0114(03)00089-7; Pearl J, 1996, ACM COMPUT SURV, V28, P89, DOI 10.1145/234313.234354; QIN T, 2005, 38 HAW INT C S UNPUB; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Roloff M. E., 1987, INTERPERSONAL PROCES, P11; RUMERLHART DE, 1986, PARALLEL DISTRIBUTED; SMETS P, 1999, HDB FUZZY COMP UNPUB; Smithson M, 1989, IGNORANCE UNCERTAINT; Straub DW, 1998, MIS QUART, V22, P441, DOI 10.2307/249551; TWITCHELL DP, 2006, 39 HAW INT C S UNPUB; Vrij A, 2004, GROUP DECIS NEGOT, V13, P61, DOI 10.1023/B:GRUP.0000011946.74290.bc; VYAS A, 2005, IEEE WIC ACM INT JOI; Weber R., 1996, Fuzzy Logic; White CH, 2001, HUM COMMUN RES, V27, P9, DOI 10.1093/hcr/27.1.9; Yager RR, 2000, IEEE T SYST MAN CY B, V30, P60, DOI 10.1109/3477.826947; YU B, 2003, 2 INT JOINT C UNPUB; ZADEH LA, 1994, COMMUN ACM, V37, P77, DOI 10.1145/175247.175255; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; ZHOU L, 2005, 38 HAW INT C S UNPUB; Zhou L, 2004, GROUP DECIS NEGOT, V13, P81, DOI 10.1023/B:GRUP.0000011944.62889.6f; Zhou L, 2004, COMPUT HUM BEHAV, V20, P381, DOI 10.1016/S0747-5632(03)00051-7; Zhou L, 2004, J MANAGE INFORM SYST, V20, P139; Zhou L, 2005, IEEE T PROF COMMUN, V48, P147, DOI 10.1109/TPC.2005.849652	60	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1063-6706		IEEE T FUZZY SYST	IEEE Trans. Fuzzy Syst.	APR	2008	16	2					442	454		10.1109/TFUZZ.2006.889914		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	325IL	WOS:000257582500014	
J	Pedrycz, W; de Oliveira, JV				Pedrycz, Witold; de Oliveira, Jose Valente			A development of fuzzy encoding and decoding through fuzzy clustering	IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT			English	Article						Boolean reconstruction; encoding and decoding; fuzzification coefficient; Fuzzy C-Means (FCM); fuzzy vector quantization; reconstruction error; reconstruction problem	VECTOR QUANTIZATION; IMAGE COMPRESSION; CLASSIFICATION; MODELS; LOGIC	Fuzzy clustering has emerged as a fundamental technique of information granulation. In this study, we introduce and discuss multivariable encoding and decoding mechanisms (referred altogether as a reconstruction problem) expressed in the language of fuzzy sets and fuzzy relations. The underlying performance index associated with the problem helps quantify a reconstruction error that arises when transforming a numeric datum through fuzzy sets (relations) and then reconstructing it into an original numeric format. The clustering platform considered in this study concerns the well-known algorithm of Fuzzy C-Means (FCM). The main design aspects deal with the relationships between the number of clusters versus the reconstruction properties and the resulting reconstruction error. The impact of the fuzzification coefficient on the reconstruction quality is investigated. This finding is of interest, given the fact that predominantly all applications involving FCM use the value of the fuzzification coefficient equal to 2. In light of the completed experiments, we demonstrate that this selection may not be experimentally legitimate. We also carry out a comparative analysis of the reconstruction properties of the Boolean decoding that is induced by the fuzzy partition. Experimental investigations involve selected machine learning data.	[Pedrycz, Witold] Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB TGR 2G7, Canada; [Pedrycz, Witold] Polish Acad Sci, Syst Res Inst, PL-01447 Warsaw, Poland; [de Oliveira, Jose Valente] Univ Algarve, Algarve Informat Lab, P-8000 Faro, Portugal	Pedrycz, W (reprint author), Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB TGR 2G7, Canada.	pedrycz@ee.ualberta.ca; jvo@ualg.pt	de Oliveira, Jose/B-6426-2008				Aiyer A, 2005, SIGNAL PROCESS-IMAGE, V20, P459, DOI 10.1016/j.image.2005.03.003; Andreadis I, 2007, IEEE T INSTRUM MEAS, V56, P1555, DOI 10.1109/TIM.2007.895620; Bezdek J. C., 1981, PATTERN RECOGNITION; Campobello G, 2005, SIGNAL PROCESS-IMAGE, V20, P91, DOI 10.1016/j.image.2004.10.001; Depari A, 2007, IEEE T INSTRUM MEAS, V56, P75, DOI 10.1109/TIM.2006.887321; FERRERO A, 2007, IEEE T INSTRUM MEAS, V56, P706; Ferrero A, 2007, IEEE T INSTRUM MEAS, V56, P1292, DOI 10.1109/TIM.2007.899827; Gersho A., 1992, VECTOR QUANTIZATION; Hoppner F., 1999, FUZZY CLUSTER ANAL; Kampke T, 2003, SIGNAL PROCESS, V83, P1839, DOI 10.1016/S0165-1684(03)00104-X; Laskaris NA, 2004, NEUROCOMPUTING, V61, P421, DOI 10.1016/j.neucom.2004.03.013; Lin TC, 2003, SIGNAL PROCESS, V83, P649, DOI 10.1016/S0165-1684(02)00453-X; Lloyd S.P., 1982, IEEE T INFORMATION T, V28, P129; Pedrycz W, 1996, IEEE T SYST MAN CY B, V26, P627, DOI 10.1109/3477.517038; Pedrycz W, 2005, KNOWLEDGE-BASED CLUSTERING: FROM DATA TO INFORMATION GRANULES, P1, DOI 10.1002/0471708607; PEDRYCZ W, 1994, FUZZY SET SYST, V64, P21, DOI 10.1016/0165-0114(94)90003-5; Stubberud SC, 2006, IEEE T INSTRUM MEAS, V55, P2292, DOI 10.1109/TIM.2006.887037; Tsekouras GE, 2005, APPL MATH COMPUT, V167, P539, DOI 10.1016/j.amc.2004.07.019; Wu KL, 2003, NEUROCOMPUTING, V55, P681, DOI 10.1016/S0925-2312(02)00634-3; Zadeh LA, 1997, FUZZY SET SYST, V90, P111, DOI 10.1016/S0165-0114(97)00077-8; Zadeh LA, 1999, IEEE T CIRCUITS-I, V46, P105, DOI 10.1109/81.739259	21	12	12	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9456		IEEE T INSTRUM MEAS	IEEE Trans. Instrum. Meas.	APR	2008	57	4					829	837		10.1109/TIM.2007.913809		9	Engineering, Electrical & Electronic; Instruments & Instrumentation	Engineering; Instruments & Instrumentation	274VE	WOS:000254029600022	
J	Wang, HX; Chen, SB; Hu, ZL; Zheng, WM				Wang, Haixian; Chen, Sibao; Hu, Zilan; Zheng, Wenming			Locality-preserved maximum information projection	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						dimensionality reduction; image recognition; linear projection; manifold learning; undersampled problem	GENERALIZED DISCRIMINANT-ANALYSIS; NONLINEAR DIMENSIONALITY REDUCTION; FACE-RECOGNITION ALGORITHMS; ROBUST FEATURE-EXTRACTION; UNDERSAMPLED PROBLEMS; MARGIN CRITERION; SAMPLE; LDA; LAPLACIANFACES; CLASSIFICATION	Dimensionality reduction is usually involved in the domains of artificial intelligence and machine learning. Linear projection of features is of particular interest for dimensionality reduction since it is simple to calculate and analytically analyze. In this paper, we propose an essentially linear projection technique, called locality-preserved maximum information projection (LPMIP), to identify the underlying manifold structure of a data set. LPMIP considers both the within-locality and the between-locality in the processing of manifold learning. Equivalently, the goal of LPMIP is to preserve the local structure while maximize the out-of-locality (global) information of the samples simultaneously. Different from principal component analysis (PCA) that aims to preserve the global information and locality-preserving projections (LPPs) that is in favor of preserving the local structure of the data set, LPMIP seeks a tradeoff between the global and local structures, which is adjusted by a parameter alpha, so as to find a sub-space that detects the intrinsic manifold structure for classification tasks. Computationally, by constructing the adjacency matrix, 1,I)LPMIP is formulated as in eigenvalue problem. LPMIP yields orthogonal basis functions, and completely avoids the singularity problem as it exists in LPP. Further, we develop an efficient and stable LPMIP/QR algorithm for implementing LPMIP, especially, on high-dimensional data set. Theoretical analysis shows that conventional linear projection methods such as (weighted) PCA, maximum margin criterion (MMC), linear discriminant analysis (LDA), and LPP could he derived from the LPMIP framework by setting different graph models and constraints. Extensive experiments on face, digit, and facial expression recognition show the effectiveness of the proposed LPMIP method.	[Wang, Haixian; Zheng, Wenming] SE Univ, Key Lab Child Dev & Learning Sci, Minist Educ, RCLS, Jiangsu 210096, Peoples R China; [Chen, Sibao] Univ Sci & Technol China, Dept Elect Engn & Informat Sci, Hefei 230027, Anhui, Peoples R China; [Hu, Zilan] Anhui Univ Technol, Sch Math & Phys, Maanshan 243002, Anhui, Peoples R China	Wang, HX (reprint author), SE Univ, Key Lab Child Dev & Learning Sci, Minist Educ, RCLS, Jiangsu 210096, Peoples R China.	hxwang@seu.edu.cn			FERET; National Natural Science Foundation of China [60503023, 10571001]; Natural Science Foundation of Jiangsu Province [BK2005407]; Program for New Century Excellent Talents in University [NCET-05-0467]; Program of Excellent Young Teachers in Southeast University	This work was supported in part by the National Natural Science Foundation of China under Grants 60503023 and 10571001, the Natural Science Foundation of Jiangsu Province under Grant BK2005407, the Program for New Century Excellent Talents in University under Grant NCET-05-0467, and the Program of Excellent Young Teachers in Southeast University.	Bach F. R., 2002, J MACHINE LEARNING R, V3, P1; Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bengio Y, 2004, ADV NEUR IN, V16, P177; Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945; Cevikalp H, 2006, IEEE T NEURAL NETWOR, V17, P1550, DOI 10.1109/TNN.2006.881485; Chen HT, 2005, PROC CVPR IEEE, P846; Duda R. O., 2001, PATTERN CLASSIFICATI; Fisher RA, 1936, ANN EUGENIC, V7, P179; FOLEY DH, 1972, IEEE T INFORM THEORY, V18, P618, DOI 10.1109/TIT.1972.1054863; Graham D.B., 1998, NATO ASI SERIES F, V163, P446; He XF, 2005, IEEE T PATTERN ANAL, V27, P328; He Xiaofei, 2003, ADV NEURAL INFORM PR; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Jain A. K., 2000, IEEE T PATTERN ANAL, V22, P1; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; KOKIOPOULOU E, 2005, P 4 INT C MACH LEARN, P15; Koren Y, 2004, IEEE T VIS COMPUT GR, V10, P459, DOI 10.1109/TVCG.2004.17; KRZANOWSKI WJ, 1995, APPL STAT-J ROY ST C, V44, P101, DOI 10.2307/2986198; Kyperountas M, 2007, IEEE T NEURAL NETWOR, V18, P506, DOI 10.1109/TNN.2006.885038; Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852; Liu J, 2007, IEEE T NEURAL NETWOR, V18, P1862, DOI 10.1109/TNN.2007.900813; Liu QS, 2006, IEEE T NEURAL NETWOR, V17, P1081, DOI 10.1109/TNN.2006.875970; Liu YH, 2007, IEEE T NEURAL NETWOR, V18, P178, DOI 10.1109/TNN.2006.883013; Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413; Martinez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; RAO CR, 1948, J ROY STAT SOC B, V10, P159; Rosipal R, 2001, NEURAL COMPUT APPL, V10, P231, DOI 10.1007/s521-001-8051-z; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Vlassis N, 2002, NEURAL COMPUT, V14, P191, DOI 10.1162/089976602753284491; Yan J., 2004, P 10 ACM SIGKDD INT, P725, DOI 10.1145/1014052.1014147; Yang J, 2005, IEEE T PATTERN ANAL, V27, P230; Yang J, 2006, NEUROCOMPUTING, V69, P1697, DOI 10.1016/j.neucom.2006.01.009; Yang M.H., 2002, P 5 IEEE INT C AUT F, P215, DOI 10.1109/AFGR.2002.4527207; Ye JP, 2004, IEEE T PATTERN ANAL, V26, P982; Ye JP, 2005, J MACH LEARN RES, V6, P483; Ye JP, 2005, IEEE T PATTERN ANAL, V27, P929; YU W, 2005, P 2 JOINT IEEE INT W, P201; Zhang W, 2006, PATTERN RECOGN, V39, P2240, DOI 10.1016/j.patcog.2006.05.011; Zhang ZF, 2007, J SUPERCRIT FLUID, V40, P1, DOI 10.1016/j.supflu.2006.04.011; Zheng WM, 2006, IEEE T NEURAL NETWOR, V17, P233, DOI 10.1109/TNN.2005.860849; Zheng WM, 2005, NEUROCOMPUTING, V67, P357, DOI 10.1016/j.neucom.2004.12.008	49	22	30	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	APR	2008	19	4					571	585		10.1109/TNN.2007.910733		15	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	342EF	WOS:000258766700003	
J	Toh, KA; Eng, HL				Toh, Kar-Ann; Eng, How-Lung			Between classification-error approximation and weighted least-squares learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern classification; classification error rate; discriminant functions; polynomials and machine learning	RECOGNITION; ALGORITHMS	This paper presents a deterministic solution to an approximated classification-error-based objective function. In the formulation, we propose a quadratic approximation as the function for achieving smooth error counting. The solution is subsequently found to be related to the weighted least-squares, whereby a robust tuning process can be incorporated. The tuning traverses between the least-squares estimate and the approximated total-error-rate estimate to cater to various situations of unbalanced attribute distributions. By adopting a linear parametric classifier model, the proposed classification-error-based learning formulation is empirically shown to be superior to that using the original least-squares-error cost function. Finally, it will be seen that the performance of the proposed formulation is comparable to other classification-error-based and state-of-the-art classifiers without sacrificing the computational simplicity.	[Toh, Kar-Ann] Yonsei Univ, Biometr Engn Res Ctr, Sch Elect & Elect Engn, Seoul 120749, South Korea; [Eng, How-Lung] Inst Infocomm Res, Singapore 119613, Singapore	Toh, KA (reprint author), Yonsei Univ, Biometr Engn Res Ctr, Sch Elect & Elect Engn, 134 Shinchon Dong, Seoul 120749, South Korea.	katoh@yonsei.ac.kr; hleng@i2r.a-star.edu.sg					Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Draper N.R., 1998, APPL REGRESSION ANAL; Duda R. O., 2001, PATTERN CLASSIFICATI; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; GORDON GJ, 2002, P ADV NEUR INF PROC, P577; Hastie T, 2001, ELEMENTS STAT LEARNI; Jones E, 2001, IEEE T PATTERN ANAL, V23, P890, DOI 10.1109/34.946991; Kim NS, 2004, IEEE SIGNAL PROC LET, V11, P40, DOI 10.1109/LSP.2003.819345; Li JY, 2004, MACH LEARN, V54, P99, DOI 10.1023/B:MACH.0000011804.08528.7d; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P117, DOI 10.1109/TNN.2002.806629; Rimer M, 2006, MACH LEARN, V63, P183, DOI 10.1007/s10994-006-6266-6; McCullagh P., 1989, GEN LINEAR MODELS; Newman D.J., UCI REPOSITORY MACHI; OSUNA EE, 1997, 1602 AI CBCL DEP BRA; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Poggio T, 2004, NATURE, V428, P419, DOI 10.1038/nature02341; Scholkopf B., 2002, LEARNING KERNELS SUP; Schurmann J., 1996, PATTERN CLASSIFICATI; Toh KA, 2004, IEEE T PATTERN ANAL, V26, P740, DOI 10.1109/TPAMI.2004.3; Toh KA, 2006, MACH LEARN, V65, P273, DOI 10.1007/s10994-006-9455-4; TOH KA, 2006, P 1 IEEE C IND EL AP, P815; Vapnik VN, 1998, STAT LEARNING THEORY	26	15	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2008	30	4					658	669		10.1109/TPAMI.2007.70730		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	262FY	WOS:000253135600009	
J	Wolf, DF; Sukhatme, GS				Wolf, Denis F.; Sukhatme, Gaurav S.			Semantic mapping using mobile robots	IEEE TRANSACTIONS ON ROBOTICS			English	Article						activity monitoring; robot mapping; semantic mapping; supervised learning; terrain mapping	RECOGNITION; TUTORIAL	Robotic mapping is the process of automatically constructing an environment representation using mobile robots. We address the problem of semantic mapping, which consists of using mobile robots to create maps that represent not only metric occupancy but also other properties of the environment. Specifically, we develop techniques to build maps that represent activity and navigability of the environment. Our approach to semantic mapping is to combine machine learning techniques with standard mapping algorithms. Supervised learning methods are used to automatically associate properties of space to the desired classification patterns. We present two methods, the first based on hidden Markov models and the second on support vector machines. Both approaches have been tested and experimentally validated in two problem domains: terrain mapping and activity-based mapping.	[Wolf, Denis F.] Univ Sao Paulo, Inst Math & Comp Sci, Dept Comp Syst, BR-05508900 Sao Paulo, Brazil; [Sukhatme, Gaurav S.] Univ So Calif, Dept Comp Sci, Robot Embedded Syst Lab, Los Angeles, CA 90089 USA	Wolf, DF (reprint author), Univ Sao Paulo, Inst Math & Comp Sci, Dept Comp Syst, BR-05508900 Sao Paulo, Brazil.	denis@icmc.usp.br; gaurav@use.edu	Wolf, Denis/E-4538-2011				Anguelov D., 2002, P ANN C UNC ART INT, P10; BORENSTEIN J, 1991, IEEE T ROBOTIC AUTOM, V7, P278, DOI 10.1109/70.88137; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; BRAND N, 1997, P IEEE C COMP VIS PA, P994; Buhmann M., 2003, RADIAL BASIS FUNCTIO; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Crammer K, 2001, J MACHINE LEARNING R, V2, P265; DELLAERT F, 2004, AAAI FALL S SER ARL; Duda R. O., 2001, PATTERN CLASSIFICATI; ELFES A, 1986, IEEE T ROBOTIC AUTOM, V3, P249; Forney G.D., 1973, IEEE P, V61, P268; Galindo C., 2005, P IEEE RSJ INT C INT, P3492; Gerkey B. P., 2001, Proceedings 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems. Expanding the Societal Role of Robotics in the the Next Millennium (Cat. No.01CH37180), DOI 10.1109/IROS.2001.977150; Harmandas V, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P296, DOI 10.1145/258525.258594; JOACHIMS T, 2005, SVM LIGHT; KIM D, 2006, P IEEE INT C ROB AUT, P518; KINDERMANN R, 1980, MARKOV RANDOM FIELDS; KLEMEN MD, 2005, P WORKSH ONT BAS TEC, P135; KONOLIGE K, 2006, INT S EXP ROB RIO JA; LIMKETKAI B, 2005, P INT C ART INT IJCA, P1471; LIU Y, 2002, POLYM B, P18; LOOKINGBILL A, 2005, P ICRA2005, P3948, DOI 10.1109/ROBOT.2005.1570724; Modayil J., 2004, P IEEE RSJ INT C INT, P742; Mozos O.M., 2005, P IEEE INT C ROB AUT, P1742; NIELSEN CW, 2004, P IEEE C SYST MAN CY, P10; Niu W., 2004, P IEEE MULT EXP C LO, P719; NUCHTER A, 2005, ROBOCUP INT S OS JAP; Ponce J., 2002, COMPUTER VISION MODE; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RISHE N, 1989, P INT C FOUND DAT OR, P114; Rottmann A., 2005, P NAT C ART INT AAAI, P1306; SCHROTER D, 2005, THESIS TU MUNCHEN MU; STACHNISS C, 2005, P NAT C ART INT PITT, P1324; Thrun S., 2002, EXPLORING ARTIFICIAL; Vapnik V, 1979, ESTIMATION DEPENDENC; Vasudevan Shrihari, 2006, Proceedings of the 2006 IEEE International Conference on Information Acquisition, DOI 10.1109/ICIA.2006.306025; WELLINGTON C, 2005, ROB SCI SYST C CAMBR; WOLF DF, 2005, P IEEE INT C ROB AUT, P2038; WOLF DF, 2005, P IEEE RSJ INT C INT, P1258; Wolf P, 2004, CURR PROB E, V19, P1; YE C, P UGV TECHN C 2003 S, P52; Zhuge H, 2004, J SYST SOFTWARE, V73, P455, DOI 10.1016/j.jss.2003.08.243	42	11	12	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1552-3098		IEEE T ROBOT	IEEE Trans. Robot.	APR	2008	24	2					245	258		10.1109/TRO.2008.917001		14	Robotics	Robotics	284KP	WOS:000254705600001	
J	Huysmans, J; Setiono, R; Baesens, B; Vanthienen, J				Huysmans, Johan; Setiono, Rudy; Baesens, Bart; Vanthienen, Jan			Minerva: Sequential covering for rule extraction	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						classification; rule extraction; support vector machines	ARTIFICIAL NEURAL-NETWORKS; REGRESSION	Various benchmarking studies have shown that artificial neural networks and support vector machines often have superior performance when compared to more traditional machine learning techniques. The main resistance against these newer techniques is based on their lack of interpretability: it is difficult for the human analyst to understand the reasoning behind these models' decisions. Various rule extraction (RE) techniques have been proposed to overcome this opacity restriction. These techniques are able to represent the behavior of the complex model with a set of easily understandable rules. However, most of the existing RE techniques can only be applied under limited circumstances, e.g., they assume that all inputs are categorical or can only be applied if the black-box model is a neural network. In this paper, we present Minerva, which is a new algorithm for RE. The main advantage of Minerva is its ability to extract a set of rules from any type of black-box model. Experiments show that the extracted models perform well in comparison with various other rule and decision tree learners.	[Huysmans, Johan; Baesens, Bart; Vanthienen, Jan] Katholieke Univ Leuven, Dept Decis Sci & Informat Management, B-3000 Louvain, Belgium; [Setiono, Rudy] Natl Univ Singapore, Dept Informat Syst, Singapore 119260, Singapore; [Baesens, Bart] Univ Southampton, Southampton SO17 1BJ, Hants, England; [Baesens, Bart] Vlerick Leuven Ghent Management Sch, B-3000 Louvain, Belgium	Huysmans, J (reprint author), Katholieke Univ Leuven, Dept Decis Sci & Informat Management, B-3000 Louvain, Belgium.						Andrews R, 1995, KNOWL-BASED SYST, V8, P373, DOI 10.1016/0950-7051(96)81920-4; BAESENS B, 2003, THESIS U LEUVEN; Baesens B, 2003, J OPER RES SOC, V54, P627, DOI 10.1057/palgrave.jors.2601545; Barakat N, 2005, INT J COMPUTATIONAL, V2, P59; BARAKAT N, 2004, P 14 ICCTA; Bishop C.M., 1995, NEURAL NETWORKS PATT; Breiman L, 1984, CLASSIFICATION REGRE; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Cohen W. W., 1995, P 12 INT C MACH LEAR, P115; Craven MW, 1996, ADV NEUR IN, V8, P24; Craven M.W., 1996, THESIS U WISCONSIN M; Cristianini N., 2000, INTRO SUPPORT VECTOR; Etchells TA, 2006, IEEE T NEURAL NETWOR, V17, P374, DOI 10.1109/TNN.2005.863472; Fung G., 2005, P 11 ACM SIGKDD INT, P32, DOI 10.1145/1081870.1081878; HUYSMANS J, 2006, P 8 INT C DAWAK, V4081, P270; Michalski R. S., 1969, Proceedings of the 5th Yugoslavian international symposium of information processing; NEUMAN J, 1998, THESIS U EDINBURGH E; Newman D. J., 1998, UCI REPOSITORY MACHI; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Saad EW, 2007, NEURAL NETWORKS, V20, P78, DOI 10.1016/j.neunet.2006.07.005; SAITO K, 1997, P 15 INT JOINT C ART, P1078; Schmitz GPJ, 1999, IEEE T NEURAL NETWOR, V10, P1392, DOI 10.1109/72.809084; Scholkopf B., 1998, ADV KERNEL METHODS S; Setiono R, 2004, EUR J OPER RES, V155, P239, DOI 10.1016/S0377-2217(02)00792-0; Setiono R, 2002, IEEE T NEURAL NETWOR, V13, P564, DOI 10.1109/TNN.2002.1000125; Silverman D, 1986, DENSITY ESTIMATION S; Suykens J. A. K., 1999, P INT JOINT C NEUR N, P900, DOI DOI 10.1109/IJCNN.1999.831072; Suykens J.A.K, 2000, P EUR S ART NEUR NET, P37; Suykens J. A. K., 1999, Proceedings of the European Conference on Circuit Theory and Design. ECCTD'99; Suykens J.A.K., 2002, LEAST SQUARES SUPPOR; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Taha IA, 1999, IEEE T KNOWL DATA EN, V11, P448, DOI 10.1109/69.774103; THRUNIN S, 1993, IAITR935 U BONN I IN; Vapnik V. N, 1995, NATURE STAT LEARNING	34	4	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	APR	2008	38	2					299	309		10.1109/TSMCB.2007.912079		11	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	274VC	WOS:000254029400003	
J	Deng, JD; Simmermacher, C; Cranefield, S				Deng, Jeremiah D.; Simmermacher, Christian; Cranefield, Stephen			A study on feature analysis for musical instrument classification	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						feature extraction; feature selection; music; pattern classification	INFORMATION-RETRIEVAL; SOUND-RECOGNITION; AUDIO; SELECTION; MPEG-7	In tackling data mining and pattern recognition tasks, finding a compact but effective set of features has often been found to be a crucial step in the overall problem-solving process. In this paper, we present an empirical study on feature analysis for recognition of classical instrument, using machine learning techniques to select and evaluate features extracted from a number of different feature schemes. It is revealed that there is significant redundancy between and within feature schemes commonly used in practice. Our results suggest that further feature analysis research is necessary in order to optimize feature selection and achieve better results for the instrument recognition problem.	[Deng, Jeremiah D.; Cranefield, Stephen] Univ Otago, Dept Informat Sci, Dunedin 9054, New Zealand; [Simmermacher, Christian] Materna GmbH, D-44141 Dortmund, Germany	Deng, JD (reprint author), Univ Otago, Dept Informat Sci, Dunedin 9054, New Zealand.	ddeng@infoscience.otago.ac.nz; chris-sim@gmx.de; scranefield@infoscience.otago.ac.nz	Deng, Jeremiah/A-1287-2008; Cranefield, Stephen/A-6605-2008				Agostini G, 2003, EURASIP J APPL SIG P, V2003, P5, DOI 10.1155/S1110865703210118; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; AUCOUTURIER J, 2002, P ICME, V1, P105; Benetos E., 2006, P IEEE INT C AC SPEE, V5, P221; Brown JC, 2001, J ACOUST SOC AM, V109, P1064, DOI 10.1121/1.1342075; Casey M, 2001, IEEE T CIRC SYST VID, V11, P737, DOI 10.1109/76.927433; Divakaran A, 2003, P SOC PHOTO-OPT INS, V5021, P160, DOI 10.1117/12.476294; Eggink J., 2004, P ICASSP, V4, P217; Eronen A, 2001, PROCEEDINGS OF THE 2001 IEEE WORKSHOP ON THE APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS, P19, DOI 10.1109/ASPAA.2001.969532; ESSID S, 2004, AUD ENG SOC 2K INT C; Foote J, 1999, MULTIMEDIA SYST, V7, P2, DOI 10.1007/s005300050106; GRIMALDI M, 2003, TCDCS200321; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Kaminskyj I, 2005, J INTELL INF SYST, V24, P199, DOI 10.1007/s10844-005-0323-7; Kim YK, 2004, EUR RADIOL, V14, P5, DOI 10.1007/s00330-003-2115-1; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kostek B, 2004, P IEEE, V92, P712, DOI 10.1109/JPROC.2004.825903; Lidy T., 2005, P 6 INT C MUS INF RE, P34; Lindsay AT, 2001, J AUDIO ENG SOC, V49, P589; Livshin A, 2004, P 7 INT C DIG AUD EF, P222; Ma L., 2006, ACM T SPEECH LANGUAG, V3, P1, DOI 10.1145/1149290.1149292; MARQUES J, 1999, CRL994 COMP COMP COR; Martin K. D., 1998, J ACOUST SOC AM, V104, P1768; PEETERS G, 2000, P INT COMP MUS C, P166; Press WH, 1988, NUMERICAL RECIPES C; QINLAN JR, 1993, C4 5 PROGRAMS MACHIN; Slaney M, 1998, AUDITORY TOOLBOX; Tenenbaum J. B., 2000, SCIENCE, V290, P5500; TSENG YH, 1999, P 22 INT ACM SIGIR C, P176, DOI 10.1145/312624.312675; Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560; Witten I. H., 2005, DATA MINING PRACTICA; XIONG Z, 2003, P ICME, V3, P397; Yu L, 2004, J MACH LEARN RES, V5, P1205; *IPEM, IPEM TOOLB; *ISO IEC, 2004, MPEG N OV	35	14	14	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	APR	2008	38	2					429	438		10.1109/TSMCB.2007.913394		10	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	274VC	WOS:000254029400013	
J	Chow, TWS; Wang, PY; Ma, EWM				Chow, Tommy W. S.; Wang, Piyang; Ma, Eden W. M.			A new feature selection scheme using a data distribution factor for unsupervised nominal data	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						clustering; feature ranking; unsupervised feature selection	MUTUAL INFORMATION; VARIABLES	A new efficient unsupervised feature selection method is proposed to handle nominal data without data transformation. The proposed feature selection method introduces a new data distribution factor to select appropriate clusters. The proposed method combines the compactness and separation together with a newly introduced concept of singleton item. This new feature selection method considers all features globally. It is computationally inexpensive and able to deliver very promising results. Eight datasets from the University of California Irvine (UCI) machine learning repository and a high-dimensional cDNA dataset are used in this paper. The obtained results show that the proposed method is very efficient and able to deliver very reliable results.	[Chow, Tommy W. S.; Wang, Piyang; Ma, Eden W. M.] City Univ Hong Kong, Dept Elect Engn, Kowloon, Hong Kong, Peoples R China	Chow, TWS (reprint author), City Univ Hong Kong, Dept Elect Engn, Kowloon, Hong Kong, Peoples R China.	eetchow@cityu.edu.hk					Basak J, 1998, PATTERN RECOGN LETT, V19, P997, DOI 10.1016/S0167-8655(98)00083-X; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Bezdek JC, 1998, IEEE T SYST MAN CY B, V28, P301, DOI 10.1109/3477.678624; Chow TWS, 2005, IEEE T NEURAL NETWOR, V16, P213, DOI 10.1109/TNN.2004.841414; Dash M., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183893; Dash M, 1997, PROC INT C TOOLS ART, P532, DOI 10.1109/TAI.1997.632300; Dy JG, 2000, P 17 INT C MACH LEAR, P247; HUANG D, 2004, NEUROCOMPUTING, V63, P325; Huang D, 2005, IEEE T CIRCUITS-I, V52, P785, DOI 10.1109/TCSI.2005.844364; Lashkia GV, 2004, IEEE T SYST MAN CY B, V34, P888, DOI 10.1109/TSMCB.2003.817106; Mao KZ, 2005, IEEE T SYST MAN CY B, V35, P339, DOI 10.1109/TSMCB.2004.843269; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133; Sebban M, 2002, PATTERN RECOGN, V35, P835, DOI 10.1016/S0031-3203(01)00084-X; SHI SYM, 2003, P INT JOINT C NEUR N, V3, P20; THAWONMAS R, 1995, P INT C ART NEUR NET, V4, P2130, DOI 10.1109/ICNN.1995.489007; Wang K, 1999, PROCEEDINGS OF THE EIGHTH INTERNATIONAL CONFERENCE ON INFORMATION KNOWLEDGE MANAGEMENT, CIKM'99, P483, DOI 10.1145/319950.320054; Yang Y., 2002, P 8 ACM SIGKDD INT C, P682; Yu L., 2003, P 9 ACM SIGKDD INT C, P685; Yun CH, 2001, P INT COMP SOFTW APP, P505	19	9	10	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	APR	2008	38	2					499	509		10.1109/TSMCB.2007.914707		11	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	274VC	WOS:000254029400019	
J	Hu, WM; Hu, W; Maybank, S				Hu, Weiming; Hu, Wei; Maybank, Steve			AdaBoost-based algorithm for network intrusion detection	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						AdaBoost; computational complexity; detection rate; false-alarm rate; intrusion detection	ANOMALY DETECTION; NEURAL-NETWORKS; MODEL; ENSEMBLE; BEHAVIOR	Network intrusion detection aims at distinguishing the attacks on the Internet from normal use of the Internet. It is an indispensable part of the information security system. Due to the variety of network behaviors and the rapid development of attack fashions, it is necessary to develop fast machine-learning-based intrusion detection algorithms with high detection rates and low false-alarm rates. In this correspondence, we propose an intrusion detection algorithm based on the AdaBoost algorithm. In the algorithm, decision stumps are used as weak classifiers. The decision rules are provided for both categorical and continuous features. By combining the weak classifiers for continuous features and the weak classifiers for categorical features into a strong classifier, the relations between these two different types of features are handled naturally, without any forced conversions between continuous and categorical features. Adaptable initial weights and a simple strategy for avoiding overfitting are adopted to improve the performance of the algorithm. Experimental results show that our algorithm has low computational complexity and error rates, as compared with algorithms of higher computational complexity, as tested on the benchmark sample data.	[Hu, Weiming; Hu, Wei] Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100080, Peoples R China; [Maybank, Steve] Univ London Birkbeck Coll, Sch Comp Sci & Informat, London WC1E 7HX, England	Hu, WM (reprint author), Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100080, Peoples R China.	winhu@nlpr.ia.ac.cn; whu@nlpr.ia.ac.cn; sjmaybank@dcs.bbk.ac.uk					ABBES T, 2004, P INT C INF TECHN CO, V1, P404; Asaka M., 2002, Proceedings 2002 Symposium on Applications and the Internet (SAINT 2002), DOI 10.1109/SAINT.2002.994451; Bay SD, 2003, P 9 ACM SIGKDD INT C, P29; Bonifacio Jr J.M., 1998, P INT JOINT C NEUR N, V1, P205; CABARERA JBD, 2000, P MOD AN SIM COMP TE, P466; Chebrolu S, 2005, COMPUT SECUR, V24, P295, DOI 10.1016/j.cose.2004.09.008; DENNING DE, 1987, IEEE T SOFTWARE ENG, V13, P222, DOI 10.1109/TSE.1987.232894; Depren MO, 2004, PROCEEDINGS OF THE IEEE 12TH SIGNAL PROCESSING AND COMMUNICATIONS APPLICATIONS CONFERENCE, P76, DOI 10.1109/SIU.2004.1338261; Elkan C., 2000, SIGKDD EXPLORATIONS, V1, P63; Eskin E., 2002, APPL DATA MINING COM; Fern A., 2000, P 17 INT C MACH LEAR, P279; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Guan Y., 2003, P CCECE 2003, V2, P1083; HAN H, 2002, P 2002 INT C NOV, V1, P13; Han SJ, 2006, IEEE T SYST MAN CY B, V36, P559, DOI 10.1109/TSMCB.2005.860136; HOANG XA, 2005, P IEEE INT C NETW, V2, P470; Hoglund A.-J., 2000, P IEEE INNS ENNS INT, V5, P411; HONG P, 2004, P INT C COMM CIRC SY, V2, P1127; HU W, 2006, P IEEE INT C SYST MA, V5, P3895; HU W, 2005, P IEEE WIC ACM INT C, P712; Jiang SY, 2006, PATTERN RECOGN LETT, V27, P802, DOI 10.1016/j.patrec.2005.11.007; Jin H., 2004, P 10 INT WORKSH FUT, P191; Kayacik HG, 2003, P INT JOINT C NEUR N, V3, P1808, DOI 10.1109/IJCNN.2003.1223682; Lee W., 2000, ACM Transactions on Information and Systems Security, V3, DOI 10.1145/382912.382914; LEI JZ, 2004, P 2 ANN C COMM NETW, V4, P190; Li J, 2004, IEE P-COMMUN, V151, P539, DOI 10.1049/ip-com:20040522; Li Zhuowei, 2003, Proceedings. 2003 International Conference on Cyberworlds, DOI 10.1109/CYBER.2003.1253494; Lippmann R, 2000, COMPUT NETW, V34, P579, DOI 10.1016/S1389-1286(00)00139-0; Liu YG, 2004, PATTERN RECOGN, V37, P927, DOI 10.1016/j.patcog.2003.09.011; LIU YH, 2003, P INT C MACH LEARN C, V3, P1337; McHugh J., 2000, ACM Transactions on Information and Systems Security, V3, DOI 10.1145/382912.382923; MILL J, 2004, P INT C FUZZ SYST, V1, P407; MUKKAMALA S, 2002, P INT JOINT C NEUR N, V2, P1702; Mukkamala S, 2005, J NETW COMPUT APPL, V28, P167, DOI 10.1016/j.jnca.2004.01.003; Mukkamala S, 2003, PROC INT C TOOLS ART, P570, DOI 10.1109/TAI.2003.1250243; Otey ME, 2006, DATA MIN KNOWL DISC, V12, P203, DOI 10.1007/s10618-005-0014-6; Oza N. C, 2001, THESIS U CALIFORNIA; Pfahringer B., 2000, SIGKDD EXPLORATIONS, V1, P65; Qin M., 2004, P IEEE INT S NETW CO, P161; QU D, 1998, P 1998 INT C NETW PR, P62; RAPAKA A, 2003, P INT JOINT C NEUR N, V3, P1820, DOI 10.1109/IJCNN.2003.1223684; Rudin C, 2004, J MACH LEARN RES, V5, P1557; Sarasamma ST, 2005, IEEE T SYST MAN CY B, V35, P302, DOI 10.1109/TSMCB.2005.843274; Song D, 2005, IEEE T EVOLUT COMPUT, V9, P225, DOI 10.1109/TEVC.2004.841683; STOLFO S, 2002, 3 INT KNOWL DISC DAT; Lee W, 1999, P IEEE S SECUR PRIV, P120; Sung A. H., 2003, Proceedings 2003 Symposium on Applications and the Internet, DOI 10.1109/SAINT.2003.1183050; Vigna G., 1998, Proceedings 14th Annual Computer Security Applications Conference (Cat. No.98EX217), DOI 10.1109/CSAC.1998.738566; Viola P., 2001, P IEEE C COMP VIS PA, V1, P511; XIAN J, 2005, P INT C MACH LEARN C, V6, P3905; YE N, 2001, P DARPA INF SURV C E, V1, P3; Ye N, 2004, IEEE T RELIAB, V53, P116, DOI 10.1109/TR.2004.823851; Yeung DY, 2003, PATTERN RECOGN, V36, P229, DOI 10.1016/S0031-3203(02)00026-2; Zhang CL, 2005, PATTERN RECOGN LETT, V26, P779, DOI 10.1016/j.aptrec.2004.09.045; ZHANG ZH, 2004, P 18 INT C ADV INF N, V1, P568	57	25	27	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	APR	2008	38	2					577	583		10.1109/TSMCB.2007.914695		7	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	274VC	WOS:000254029400029	
J	Oh, HJ; Yun, BH				Oh, Hyo-Jung; Yun, Bo-Hyun			Sentence topics based knowledge acquisition for question answering	IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS			English	Article						knowledge acquisition; machine learning; question answering	RANDOM-FIELDS	This paper presents a knowledge acquisition method using sentence topics for question answering. We define templates for information extraction by the Korean concept network semi-automatically. Moreover, we propose the two-phase information extraction model by the hybrid machine learning such as maximum entropy and conditional random fields. In our experiments, we examined the role of sentence topics in the template-filling task for information extraction. Our experimental result shows the improvement of 18% in F-score and 434% in training speed over the plain CRF-based method for the extraction task. In addition, our result shows the improvement of 8% in F-score for the subsequent QA task.	[Yun, Bo-Hyun] Mokwon Univ, Taejon 302318, South Korea; [Oh, Hyo-Jung] ETRI, Taejon 350700, South Korea	Yun, BH (reprint author), Mokwon Univ, Mokwon Gil 21, Taejon 302318, South Korea.	ybh@mokwon.ac.kr					Berglund B, 1996, ENVIRON INT, V22, P1, DOI 10.1016/0160-4120(95)00098-4; CHOI MR, 2004, P IECON 2004 30 ANN, P3115; CHRISTENSEN H, 2005, P ICASSP 2005, P1029; DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379; DellaPietra S, 1997, IEEE T PATTERN ANAL, V19, P380, DOI 10.1109/34.588021; Fellbaum C., 1998, WORDNET ELECT LEXICA; Kang BY, 2006, IEICE T INF SYST, VE89D, P377, DOI 10.1093/ietisy/e89-d.1.377; KUPIEC J, 1993, P ACM SIGIR; Lafferty J., 2001, ICML; Lee C, 2006, LECT NOTES COMPUT SC, V4182, P581; LEE CK, 2005, P 28 ANN INT ACM SIG; LI W, 2002, P COL; Malouf R, 2002, P 6 C NAT LANG LEARN, P49; Nigam K., 1999, P IJCAI 99 WORKSH MA, P61; Yang Yiming, 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647	15	0	0	IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG	TOKYO	KIKAI-SHINKO-KAIKAN BLDG MINATO-KU SHIBAKOEN 3 CHOME, TOKYO, 105, JAPAN	0916-8532		IEICE T INF SYST	IEICE Trans. Inf. Syst.	APR	2008	E91D	4					969	975		10.1093/ietisy/e91-4.4.969		7	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	297WS	WOS:000255648700010	
J	Huynh, HT; Won, Y				Huynh, Hieu Trung; Won, Yonggwan			Small number of hidden units for ELM with two-stage liner model	IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS			English	Article						neural networks; single hidden-layer feedforward neural networks; extreme learning machine; least-squares scheme; linear model	SEQUENTIAL LEARNING ALGORITHM; SUPPORT VECTOR MACHINES; FEEDFORWARD NETWORKS; NEURAL-NETWORKS; CLASSIFICATION	The single-hidden-layer feedforward neural networks (SLFNs) are frequently used in machine learning due to their ability which can form boundaries with arbitrary shapes if the activation function of hidden units is chosen properly. Most learning algorithms for the neural networks based on gradient descent are still slow because of the many learning steps. Recently, a learning algorithm called extreme learning machine (ELM) has been proposed for training SLFNs to overcome this problem. It randomly chooses the input weights and hidden-layer biases, and analytically determines the output weights by the matrix inverse operation. This algorithm can achieve good generalization performance with high learning speed in many applications. However, this algorithm often requires a large number of hidden units and takes long time for classification of new observations. In this paper, a new approach for training SLFNs called least-squares extreme learning machine (LS-ELM) is proposed. Unlike the gradient descent-based algorithms and the ELM, our approach analytically determines the input weights, hidden-layer biases and output weights based on linear models. For training with a large number of input patterns, an online training scheme with sub-blocks of the training set is also introduced. Experimental results for real applications show that our proposed algorithm offers high classification accuracy with a smaller number of hidden units and extremely high speed in both learning and testing.	[Huynh, Hieu Trung; Won, Yonggwan] Chonnam Natl Univ, Dept Comp Engn, Kwangju 500757, South Korea	Won, Y (reprint author), Chonnam Natl Univ, Dept Comp Engn, Kwangju 500757, South Korea.	hthieu@hcmut.edu.vn; ykwon@chonnam.ac.kr					ASIRVADAM VS, 2002, P 12 IEEE WORKSH NEU, P129, DOI 10.1109/NNSP.2002.1030024; Bartlett PL, 1998, IEEE T INFORM THEORY, V44, P525, DOI 10.1109/18.661502; Burney S. M. A., 2005, INT J COMPUTATIONAL, V1, P218; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Constantinopoulos C, 2006, IEEE T NEURAL NETWOR, V17, P966, DOI 10.1109/TNN.2006.875982; DeCoste D., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347165; DUMAIS S, 1998, P INT C INF KNOWL MA, V3, P148; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Golub G. H., 1996, MATRIX COMPUTATIONS; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.121.126; Huang GB, 2000, IEEE T NEURAL NETWOR, V11, P799, DOI 10.1109/72.846750; Huang GB, 2004, IEEE T SYST MAN CY B, V34, P2284, DOI 10.1109/TSMCB.2004.834428; Huang Guang-Bin, 2004, P INT JOINT C NEUR N; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Karayiannis N., 1993, ARTIFICIAL NEURAL NE; Keerthi SS, 2002, IEEE T NEURAL NETWOR, V13, P1225, DOI 10.1109/TNN.2002.1031955; LAWRENCE S, 2000, P IEEE INNS ENNS INT, V1, P114; LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9; Liang NY, 2006, IEEE T NEURAL NETWOR, V17, P1411, DOI 10.1109/TNN.2006.880583; LIU ZP, 1999, INT JOINT C NEUR NET, V3, P1788, DOI 10.1109/IJCNN.1999.832649; Lu SX, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P4277; Newman D. J., 1998, UCI REPOSITORY MACHI; NGHIA LS, 1998, P AS C SIGN SYST COM, V1, P697; Nguyen D., 1990, INT JOINT C NEURAL N, P21; RASCH TOG, 1998, P 5 INT C NEUR INF P; Romero E, 2002, IEEE IJCNN, P1968, DOI 10.1109/IJCNN.2002.1007821; Serre D., 2002, MATRICES THEORY APPL; WILSON DR, 1996, P INT C NEUR NETW IC, P1263; Yam JYF, 2001, IEEE T NEURAL NETWOR, V12, P430, DOI 10.1109/72.914538; Yingwei L., 1998, IEEE T NEURAL NETWOR, V9, P308	31	4	4	IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG	TOKYO	KIKAI-SHINKO-KAIKAN BLDG MINATO-KU SHIBAKOEN 3 CHOME, TOKYO, 105, JAPAN	0916-8532		IEICE T INF SYST	IEICE Trans. Inf. Syst.	APR	2008	E91D	4					1042	1049		10.1093/ietisy/e91-1.4.1042		8	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	297WS	WOS:000255648700019	
J	Bracewell, DB; Yan, J; Ren, F				Bracewell, David B.; Yan, Jiajun; Ren, Fuji			Single document keyword extraction for Internet news articles	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL			English	Article						keyword extraction; indexing; news; information retrieval; natural language processing		Keywords are a fundamental part of information retrieval (IR) and as such they have been studied extensively. They are used for everything from, searching to describing a document. A Keyword extraction algorithm can be defined as a combination of a keyword representation and a selection/weighting scheme. The most common selection/weighting schemes are based on collection statistics or using supervised machine learning algorithms. In these cases, keywords can, typically, only be extracted from documents that belong to a collection or using a large amount of annotated training data. The importance of extracting keywords without a document collection has been gradually increasing due to the Internet. In, this paper, a keyword, extraction algorithm designed with news in mind that requires neither a document collection or training data is presented. It, uses noun phrases as its keyword representation and takes in document statistics to derive its weighting scheme. Through experimentation it is shown. that the quality of the keywords extracted from, the proposed algorithm are better than. standard algorithms for both information retrieval and humans.	[Bracewell, David B.; Yan, Jiajun; Ren, Fuji] Univ Tokushima, Dept Informat Sci & Intelligent Syst, Tokushima 7708506, Japan; [Ren, Fuji] Beijing Univ Posts & Telecommun, Sch Informat Engn, Beijing 100876, Peoples R China	Bracewell, DB (reprint author), Univ Tokushima, Dept Informat Sci & Intelligent Syst, Tokushima 7708506, Japan.	david@is.tokushima-u.ac.jp; yanjj@is.tokushima-u.ac.jp; ren@is.tokushima-u.ac.jp					Brants T., 2000, P 6 APPL NLP C; FRY J, 2006, PARALLEL JAPANESE EN; Gale W., 1992, P 4 DARPA SPEECH NAT, P233, DOI 10.3115/1075527.1075579; HULTH A, 2003, P C EMP METH NAT LAN; HULTH A, 2004, P HUM LANG TECHN C N; Lewis DD, 2004, J MACH LEARN RES, V5, P361; Matsuo Y., 2004, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V13, DOI 10.1142/S0218213004001466; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Turney P. D., 2000, Information Retrieval, V2, DOI 10.1023/A:1009976227802; WINOGRAD T, 1983, LANGUAGE COGNITIVE P, V1; Yih W., 2006, P 15 INT C WORLD WID, P213, DOI 10.1145/1135777.1135813; *NFORMATIX, NFORMATIX SOFTW FULL	12	8	8	ICIC INT	KUMAMOTO	KYUSHU TOKAI UNIV, 9-1-1, TOROKU, KUMAMOTO, 862-8652, JAPAN	1349-4198		INT J INNOV COMPUT I	Int. J. Innov. Comp. Inf. Control	APR	2008	4	4					905	913				9	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	288IZ	WOS:000254981200013	
J	Challagulla, VUB; Bastani, FB; Yen, IL; Paul, RA				Challagulla, Venkata Udaya B.; Bastani, Farokh B.; Yen, I-Ling; Paul, Raymond A.			Empirical assessment of machine learning based software defect prediction techniques	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS			English	Article						data analysis; software defect prediction		Automated reliability assessment is essential for systems that entail dynamic adaptation based on runtime mission-specific requirements. One approach along this direction is to monitor and assess the system using machine learning-based software defect prediction techniques. Due to the dynamic nature of software data collected, Instance-based learning algorithms are proposed for the above purposes. To evaluate the accuracy of these methods, the paper presents an empirical analysis of four different real-time software defect data sets using different predictor models. The results show that a combination of 1R and Instance-based learning along with Consistency-based subset evaluation technique provides a relatively better consistency in achieving accurate predictions as compared with other models. No direct relationship is observed between the skewness present in the data sets and the prediction accuracy of these models. Principal Component Analysis (PCA) does not show a consistent advantage in improving the accuracy of the predictions. While random reduction of attributes gave poor accuracy results, simple Feature Subset Selection methods performed better than PCA for most prediction models. Based on these results, the paper presents a high-level design of an Intelligent Software Defect Analysis tool (ISDAT) for dynamic monitoring and defect assessment of software modules.	[Challagulla, Venkata Udaya B.; Bastani, Farokh B.; Yen, I-Ling] Univ Texas Richardson, Dept Comp Sci, Richardson, TX 75083 USA	Challagulla, VUB (reprint author), Univ Texas Richardson, Dept Comp Sci, Richardson, TX 75083 USA.	uday@utdallas.edu; bastani@utdallas.edu; ilyen@utdallas.edu; Raymond.Paul@osd.mil					Aljahdali SH, 2001, ACS/IEEE INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, PROCEEDINGS, P470; Challagulla V. U. B., 2005, 10th IEEE International Workshop on Object-Oriented Real-Time Dependable Systems, DOI 10.1109/WORDS.2005.32; DUMAIS S, 1998, INT C INF KNOWL MAN, P148; EMEN K, 2001, J SYST SOFTWARE, V55, P301; Fenton N, 2002, IEEE SOFTWARE, V19, P116, DOI 10.1109/MS.2002.1020298; Fenton N.E, 1998, SOFTWARE METRICS RIG; Hall M.A., THESIS U WAIKATO NZ; HOLTE RC, 1993, MACH LEARN, V11, P69; Khoshgoftaar T. M., 2001, Proceedings 12th International Symposium on Software Reliability Engineering, DOI 10.1109/ISSRE.2001.989459; Kira K., 1992, 9 INT C MACH LEARN, P249; Liu H., 1996, 13 INT C MACH LEARN, P319; Mair C, 2000, J SYST SOFTWARE, V53, P23, DOI 10.1016/S0164-1212(00)00005-4; MENZIES T, 2003, UNPUB J EMPIRICAL SO; Mitchell T, 1997, MACHINE LEARNING; MORASCA S, 1996, P ANN M ISERN SYDN A; KHOSHGOFTAAR TM, 1990, IEEE J SEL AREA COMM, V8, P253, DOI 10.1109/49.46879; MUNSON JC, 1990, INFORM SOFTWARE TECH, V32, P106, DOI 10.1016/0950-5849(90)90109-5; Neumann DE, 2002, IEEE T SOFTWARE ENG, V28, P904, DOI 10.1109/TSE.2002.1033229; Pickard L., 1999, Proceedings Sixth International Software Metrics Symposium (Cat. No.PR00403), DOI 10.1109/METRIC.1999.809734; REFORMAT M, 2002, P IEEE INT C FUZZ SY, V2, P1156; Schneidewind N., 2001, P 7 INT SOFTW METR S, P328; Shepperd M, 2001, IEEE T SOFTWARE ENG, V27, P1014, DOI 10.1109/32.965341; SUCCI G, ADV STAT MODELS SOFT; WANG Y, 2000, THESIS U WAIKATO NZ	24	3	3	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-2130		INT J ARTIF INTELL T	Int. J. Artif. Intell. Tools	APR	2008	17	2					389	400		10.1142/S0218213008003947		12	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	290YR	WOS:000255160000008	
J	Supek, F; Kralj, M; Marjanovic, M; Suman, L; Smuc, T; Krizmanic, I; Zinic, B				Supek, Fran; Kralj, Marijeta; Marjanovic, Marko; Suman, Lidija; Smuc, Tomislav; Krizmanic, Irena; Zinic, Biserka			Atypical cytostatic mechanism of N-1-sulfonylcytosine derivatives determined by in vitro screening and computational analysis	INVESTIGATIONAL NEW DRUGS			English	Article						nucleobases; antitumor agents; in vitro screening; bioinformatics; random forest	BREAST-CANCER CELLS; 5-FLUOROURACIL DERIVATIVES; BIOLOGICAL-ACTIVITY; GENE-EXPRESSION; AGENTS; SULFONYLUREAS; DRUGS	We have previously shown that N-1-sulfonylpyrimidine derivatives have strong antiproliferative activity on human tumor cell lines, whereby 1-(p-toluenesulfonyl)cytosine showed good selectivity with regard to normal cells and was easily synthesized on a large scale. In the present work we have used an interdisciplinary approach to elucidate the compounds' mechanistic class. An augmented number of cell lines (11) has allowed a computational search for compounds with similar activity profiles and/or mechanistic class by integrating our data with the comprehensive DTP-NCI database. We applied supervised machine learning methodology (Random Forest classifier), which offers information complementary to unsupervised algorithms commonly used for analysis of cytostatic activity profiles, such as self-organizing maps. The computational results taken together with cell cycle perturbation and apoptosis analysis of the cell lines point to an unusual mechanism of cytostatic action, possibly a combination of nucleic acid antimetabolite activity and a novel molecular mechanism.	[Zinic, Biserka] Rudjer Boskovic Inst, Div Organ Chem & Biochem, Lab Supramol & Nucleoside Chem, Zagreb 10002, Croatia; [Supek, Fran; Smuc, Tomislav] Rudjer Boskovic Inst, Div Elect, Informat Syst Lab, Zagreb 10002, Croatia; [Kralj, Marijeta; Marjanovic, Marko; Suman, Lidija] Rudjer Boskovic Inst, Div Mol Med, Lab Funct Genomics, Zagreb 10002, Croatia; [Krizmanic, Irena] HERBOS Chem Ind, Sisak 44000, Croatia; [Krizmanic, Irena] PLIVA Res & Dev Ltd, Zagreb 1000, Croatia	Zinic, B (reprint author), Rudjer Boskovic Inst, Div Organ Chem & Biochem, Lab Supramol & Nucleoside Chem, Bijen Cesta 54, Zagreb 10002, Croatia.	bzinic@irb.hr	Supek, Fran/B-2359-2012				BOYD MR, 1995, DRUG DEVELOP RES, V34, P91, DOI 10.1002/ddr.430340203; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1984, CLASSIFICATION REGRE; Capranico G, 1998, BBA-GENE STRUCT EXPR, V1400, P185, DOI 10.1016/S0167-4781(98)00135-3; Chua MS, 2000, CANCER RES, V60, P5196; Covell DG, 2005, PROTEINS, V59, P403, DOI 10.1002/prot.20392; Erhardt PW, 2002, PURE APPL CHEM, V74, P703, DOI 10.1351/pac200274050703; Furlong ET, 2000, SCI TOTAL ENVIRON, V248, P135, DOI 10.1016/S0048-9697(99)00537-9; Glavas-Obrovac L, 2001, ANTICANCER RES, V21, P1979; Glavas-Obrovac Ljubica, 2005, Farmaco (Lausanne), V60, P479, DOI 10.1016/j.farmac.2005.04.006; Grem JL, 2000, INVEST NEW DRUG, V18, P299, DOI 10.1023/A:1006416410198; HOLM S, 1979, SCAND J STAT, V6, P65; HOUGHTON PJ, 1995, BIOCHEM PHARMACOL, V49, P661, DOI 10.1016/0006-2952(94)00501-C; KALDRIKYAN MA, 1986, KHIM FARM ZH+, V20, P928; Kasnar B, 1997, NUCLEOS NUCLEOT, V16, P1067, DOI 10.1080/07328319708006134; Kasnar-Samprec J, 2005, CROAT CHEM ACTA, V78, P261; Koch-Paiz CA, 2004, MUTAT RES-FUND MOL M, V549, P65, DOI 10.1016/j.mrfmmm.2004.01.010; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; MacCoss M, 1990, CHEM ANTITUMOR AGENT, P261; Marchal JA, 2004, INVEST NEW DRUG, V22, P379, DOI 10.1023/B:DRUG.0000036680.52016.5f; Marjanovic M, 2007, J MED CHEM, V50, P1007, DOI 10.1021/jm061162u; MARTIROSYAN A, 1970, AKAD NAUK SSSR SER K, V8, P1841; Melander A, 1996, DIABETIC MED, V13, pS143; MOHAMADI F, 1992, J MED CHEM, V35, P3012, DOI 10.1021/jm00094a013; Monks A, 2003, MOL PHARMACOL, V63, P766, DOI 10.1124/mol.63.3.766; Morre DJ, 1998, BBA-BIOMEMBRANES, V1369, P185, DOI 10.1016/S0005-2736(97)00202-2; Oprea TI, 2001, J COMB CHEM, V3, P157, DOI 10.1021/cc0000388; PAULL KD, 1989, J NATL CANCER I, V81, P1088, DOI 10.1093/jnci/81.14.1088; Qi YJ, 2006, PROTEINS, V63, P490, DOI 10.1002/prot.20865; Quinlan J.R., 2006, C4 5 PROGRAMS MACHIN; Rabow AA, 2002, J MED CHEM, V45, P818, DOI 10.1021/jm010385b; Robins R.K., 1990, CHEM ANTITUMOR AGENT, P299; Robins RK, 1988, ANTIVIRAL DRUG DEV M, P11; SCHULTZ RM, 1993, ONCOL RES, V5, P223; Sliskovic DR, 1999, ANNU REP MED CHEM, V34, P101; SUPEK F, I2SOM COMPUTER PROGR; TADA M, 1975, CHEM LETT, P129, DOI 10.1246/cl.1975.129; TOPIC G, 2007, PARF PARALLEL RANDOM; Toth JE, 1997, J MED CHEM, V40, P1018, DOI 10.1021/jm960673l; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Witten I. H., 2005, DATA MINING PRACTICA; Zinic B, 1999, CROAT CHEM ACTA, V72, P957	42	12	12	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0167-6997		INVEST NEW DRUG	Invest. New Drugs	APR	2008	26	2					97	110		10.1007/s10637-007-9084-1		14	Oncology; Pharmacology & Pharmacy	Oncology; Pharmacology & Pharmacy	271CB	WOS:000253765400001	
J	Maskery, SM; Hu, H; Hooke, J; Shriver, CD; Liebman, MN				Maskery, Susan M.; Hu, Hai; Hooke, Jeffrey; Shriver, Craig D.; Liebman, Michael N.			A Bayesian derived network of breast pathology co-occurrence	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						Bayesian analysis; histopathology; breast neoplasms; breast diseases	CANCER RISK; DISEASE; LESIONS; CLASSIFICATION; SYSTEM; WOMEN	In this paper, we present the validation and verification of a machine-learning based Bayesian network of breast pathology co-occurrence. The present/not present occurrences of 29 common breast pathologies from 1631 pathology reports were used to build the network. All pathology reports were developed by a single pathologist. The resulting network has 25 diagnosis nodes interconnected by 40 arcs. Each arc represents a predicted co-occurrence or null co-occurrence. Model verification involved assessing the robustness of the original network structure after random exclusion of 25%, 50%, and 75% of the pathology report dataset. The structure of the network appears stable as random removal of 75% of the records in the original dataset leaves 81% of the original network intact. Model validation was primarily assessed by review of the breast pathology literature for each arc in the network. Almost all network identified co-occurrences (95%) have been published in the breast pathology literature or were verified by expert opinion. In conclusion, the Bayesian network of breast pathology co-occurrence presented here is both robust with respect to incomplete data and validated by consistency with the breast pathology literature and by expert opinion. Further, the ability to utilize a specific pathology observation to predict multiple co-current pathologies enables exploration of pathology co-occurrence patterns in an intuitive manner that may have broader application in both the breast pathologist clinical community and the breast cancer research community. (c) 2008 Elsevier Inc. All rights reserved.	[Maskery, Susan M.; Hu, Hai; Liebman, Michael N.] Windber Res Inst, Windber, PA 15963 USA; [Hooke, Jeffrey; Shriver, Craig D.] Walter Reed Army Med Ctr, Clin Breast Care Project, Washington, DC 20307 USA; [Shriver, Craig D.] Walter Reed Army Med Ctr, Gen Surg Serv, Washington, DC 20307 USA	Maskery, SM (reprint author), Windber Res Inst, 620 7th St, Windber, PA 15963 USA.	s.maskery@wriwindber.org					BECKER K, 2003, BMC BIOINFORMATICS, P61; Black P. E., 2006, DICT ALGORITHMS DATA; Burnside ES, 2004, AM J ROENTGENOL, V182, P48; Burnside ES, 2006, RADIOLOGY, V240, P666, DOI 10.1148/radiol.2403051096; COHEN AM, 2005, BMC BIOINFORMATICS, P103; D'Ambrosio B., 1999, AI Magazine, V20; Dumitrescu RG, 2005, J CELL MOL MED, V9, P208, DOI 10.1111/j.1582-4934.2005.tb00350.x; DUPONT WD, 1985, NEW ENGL J MED, V312, P146, DOI 10.1056/NEJM198501173120303; Jelier R, 2005, BIOINFORMATICS, V21, P2049, DOI 10.1093/bioinformatics/bti268; MORALEDA J, 2004, THESIS STANFORD U PA; Morrison ML, 2002, J PATHOL, V197, P403, DOI 10.1002/path.1135; Natkunam Y, 2006, LAB INVEST, V86, P742, DOI 10.1038/labinvest.3700447; Ohno-Machado L, 2001, METHOD INFORM MED, V40, P32; PAGE DL, 1985, CANCER, V55, P2698, DOI 10.1002/1097-0142(19850601)55:11<2698::AID-CNCR2820551127>3.0.CO;2-A; Price GJ, 2003, HUM PATHOL, V34, P1193, DOI 10.1016/S0046-8177(03)00421-0; RAMANI A, 2005, GENOME BIOL, pR40; Reis JS, 2005, PATHOL RES PRACT, V201, P713, DOI 10.1016/j.prp.2005.05.013; Ries LAG, 2004, SEER CANC STAT REV 1; Rosen PP., 2001, ROSENS BREAST PATHOL; Sanders ME, 2006, CANCER, V106, P1453, DOI 10.1002/cncr.21730; Simpson PT, 2005, AM J SURG PATHOL, V29, P734, DOI 10.1097/01.pas.0000157295.93914.3b; Simpson PT, 2005, J PATHOL, V205, P248, DOI 10.1002/path.1691; Sorlie T, 2001, P NATL ACAD SCI USA, V98, P10869, DOI 10.1073/pnas.191367098; Sorlie T, 2004, EUR J CANCER, V40, P2667, DOI 10.1016/j.ejca.2004.08.021; Williams C, 2006, HEALTH TECHNOL ASSES, V10, P1; Wren JD, 2004, BIOINFORMATICS, V20, P191, DOI 10.1093/bioinformatics/btg390	26	9	10	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464		J BIOMED INFORM	J. Biomed. Inform.	APR	2008	41	2					242	250		10.1016/j.jbi.2007.12.005		9	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	293UE	WOS:000255360000004	
J	Wang, XW; Li, SB; Liu, H; Wood, M; Chen, WR; Zheng, B				Wang, Xingwei; Li, Shibo; Liu, Hong; Wood, Marc; Chen, Wei R.; Zheng, Bin			Automated identification of analyzable metaphase chromosomes depicted on microscopic digital images	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						artificial neural network; decision tree; metaphase chromosomes; microscopic digital images	G-BANDED CHROMOSOMES; NEURAL NETWORKS; CLASSIFICATION; ENVIRONMENT; LEUKEMIA; SPREADS; NUCLEI	Visual search and identification of analyzable metaphase chromosomes using optical microscopes is a very tedious and time-consuming task that is routinely performed in genetic laboratories to detect and diagnose cancers and genetic diseases. The purpose of this study is to develop and test a computerized scheme that can automatically identify chromosomes in metaphase stage and classify them into analyzable and un-analyzable groups. Two independent datasets involving 170 images are used to train and test the scheme. The scheme uses image filtering, threshold, and labeling algorithms to detect chromosomes, followed by computing a set of features for each individual chromosome as well as for each identified metaphase cell. Two machine learning classifiers including a decision tree (DT) based on the features of individual chromosomes and an artificial neural network (ANN) using the features of the metaphase cells are optimized and tested to classify between analyzable and un-analyzable cells. Using the DT based classifier the Kappa coefficients for agreement between the cytogeneticist and the scheme are 0.83 and 0.89 for the training and testing datasets, respectively. We apply an independent testing and a 2-fold cross-validation method to assess the performance of the ANN-based classifier. The area under and receiver operating characteristic (ROC) curve is 0.93 for the complete dataset. This preliminary study demonstrates the feasibility of developing a computerized scheme to automatically identify and classify metaphase chromosomes. (c) 2007 Elsevier Inc. All rights reserved.	[Wang, Xingwei; Liu, Hong; Wood, Marc] Univ Oklahoma, Ctr Bioengn, Norman, OK 73019 USA; [Wang, Xingwei; Liu, Hong; Wood, Marc] Univ Oklahoma, Sch Elect & Comp Engn, Norman, OK 73019 USA; [Li, Shibo] Univ Oklahoma, Hlth Sci Ctr, Dept Pediat, Oklahoma City, OK USA; [Chen, Wei R.] Univ Cent Oklahoma, Dept Phys & Engn, Edmond, OK 73034 USA; [Zheng, Bin] Univ Pittsburgh, Dept Radiol, Pittsburgh, PA 15213 USA	Zheng, B (reprint author), Univ Oklahoma, Ctr Bioengn, Norman, OK 73019 USA.	zhengb@upmc.edu					Boehm D, 2004, HUM MUTAT, V23, P368, DOI 10.1002/humu.20011; BOSCHMAN GA, 1992, CYTOMETRY, V13, P469, DOI 10.1002/cyto.990130504; CASTLEMAN KR, 1992, J RADIAT RES, V33, P124, DOI 10.1269/jrr.33.SUPPLEMENT_124; Corkidi G, 1998, MED BIOL ENG COMPUT, V36, P679, DOI 10.1007/BF02518869; Cosio FA, 2001, MED BIOL ENG COMPUT, V39, P391, DOI 10.1007/BF02345296; ERRINGTON PA, 1993, CYTOMETRY, V14, P627, DOI 10.1002/cyto.990140607; Gonzalez R. C., 1992, DIGITAL IMAGE PROCES; GUTHRIE C, 1993, COMPUT BIOL MED, V23, P105, DOI 10.1016/0010-4825(93)90142-N; Harnden DG, 1985, INT SYSTEM HUMAN CYT; Hertz J., 1991, INTRO THEORY NEURAL; HOFFBRAND VA, 2000, COLOR ATLAS CLIN HEM; KYAN MJ, 1999, P INT C IMAGE PROCES, V2, P24; LEBEAU MM, 1984, CANCER SURV, V3, P371; Li Q, 2006, MED PHYS, V33, P868, DOI 10.1118/1.2179750; MALET P, 1992, J RADIAT RES, V33, P171, DOI 10.1269/jrr.33.SUPPLEMENT_171; Metz CE, 1998, STAT MED, V17, P1033, DOI 10.1002/(SICI)1097-0258(19980515)17:9<1033::AID-SIM784>3.3.CO;2-Q; Metz CE, 1998, ROCFIT 0 9B BETA VER; Mitchell T, 1997, MACHINE LEARNING; NOWELL PC, 1960, SCIENCE, V132, P1497; Obuchowski NA, 2005, AM J ROENTGENOL, V184, P364; PIPER J, 1989, CYTOMETRY, V10, P242, DOI 10.1002/cyto.990100303; PIPER J, 1980, SIGNAL PROCESS, V2, P203, DOI 10.1016/0165-1684(80)90019-5; Popescu M, 1999, COMPUT BIOL MED, V29, P61, DOI 10.1016/S0010-4825(98)00040-7; Shih L.M., 2005, CURR OPIN ONCOL, V17, P33; Stanley R, 1995, Biomed Sci Instrum, V31, P183; Stanley RJ, 1998, IEEE T MED IMAGING, V17, P451, DOI 10.1109/42.712134; Tjio JH, 1956, HEREDITAS, V42, P1; Truong K., 2004, MED SCI MONITOR, V10, P426; VLIET LJ, 1990, CYTOMETRY, V11, P51; Wang XW, 2005, J PHYS D APPL PHYS, V38, P2536, DOI 10.1088/0022-3727/38/15/003; Wang XW, 2006, TECHNOL CANCER RES T, V5, P429; Wang YP, 2003, IEEE T MED IMAGING, V22, P685, DOI 10.1109/TMI.2003.812255; Wu Q, 2005, IEEE T IMAGE PROCESS, V14, P1277, DOI 10.1109/TIP.2005.852468; Zheng B, 1997, ACAD RADIOL, V4, P497, DOI 10.1016/S1076-6332(97)80236-X; Zheng B, 2006, MED PHYS, V33, P111, DOI 10.1118/1.2143139; ZIMMERMAN SO, 1986, COMPUT BIOL MED, V16, P223, DOI 10.1016/0010-4825(86)90050-8	36	7	7	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464		J BIOMED INFORM	J. Biomed. Inform.	APR	2008	41	2					264	271		10.1016/j.jbi.2007.06.008		8	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	293UE	WOS:000255360000006	
J	Chi, CL; Street, WN; Ward, MM				Chi, Chih-Lin; Street, W. Nick; Ward, Marcia M.			Building a hospital referral expert system with a Prediction and Optimization-Based Decision Support System algorithm	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						decision support systems; expert systems; data mining; machine learning; support vector machines; optimization; artificial intelligence; hospital referral; hospital quality	QUALITY-OF-CARE; VOLUME-OUTCOME RELATIONSHIP; HEALTH-CARE; KNOWLEDGE MANAGEMENT; TEACHING HOSPITALS; UNITED-STATES; MORTALITY; SURGERY; RISK	This study presents a new method for constructing an expert system using a hospital referral problem as an example. Many factors, such as institutional characteristics, patient risks, traveling distance, and chances of survival and complications should be included in the hospital-selection decision. Ideally, each patient should be treated individually, with the decision process including not only their condition but also their beliefs about trade-offs among the desired hospital features. An expert system can help with this complex decision, especially when numerous factors are to be considered. We propose a new method, called the Prediction and Optimization-Based Decision Support System (PODSS) algorithm, which constructs an expert system without an explicit knowledge base. The algorithm obtains knowledge on its own by building machine learning classifiers from a collection of labeled cases. In response to a query, the algorithm gives a customized recommendation, using an optimization step to help the patient maximize the probability of achieving a desired outcome. In this case, the recommended hospital is the optimal solution that maximizes the probability of the desired outcome. With proper formulation, this expert system can combine multiple factors to give hospital-selection decision support at the individual level. (c) 2007 Elsevier Inc. All rights reserved.	[Chi, Chih-Lin; Street, W. Nick] Univ Iowa, Dept Management Sci, Iowa City, IA 52242 USA; [Chi, Chih-Lin] Univ Iowa, Hlth Informat Program, Iowa City, IA 52242 USA; [Ward, Marcia M.] Univ Iowa, Dept Hlth Policy & Management, Gen Hosp E210, Iowa City, IA 52242 USA	Chi, CL (reprint author), Univ Iowa, Dept Management Sci, S210 Pappajohn Business Bldg, Iowa City, IA 52242 USA.	chih-lin-chi@uiowa.edu					Abidi SSR, 2005, IEEE T INF TECHNOL B, V9, P193, DOI 10.1109/TITB.2005.847188; Allison JJ, 2000, JAMA-J AM MED ASSOC, V284, P1256, DOI 10.1001/jama.284.10.1256; Ayanian JZ, 2002, MILBANK Q, V80, P569, DOI 10.1111/1468-0009.00023; Bali RK, 2005, IEEE T INF TECHNOL B, V9, P157, DOI 10.1109/TITB.2005.849395; Birkmeyer JD, 2003, JAMA-J AM MED ASSOC, V290, P2703, DOI 10.1001/jama.290.20.2703; Birkmeyer JD, 2002, NEW ENGL J MED, V346, P1128, DOI 10.1056/NEJMsa012337; Birkmeyer JD, 2006, ANN SURG, V243, P411, DOI 10.1097/01.sla.0000201800.45264.51; Birkmeyer JD, 2001, SURGERY, V130, P415, DOI 10.1067/msy.2001.117139; BROHMAN MK, 2007, P 39 ANN HAW INT C S; Chen J, 2003, HEALTH AFFAIR, V22, P243, DOI 10.1377/hlthaff.22.2.243; CLANCEY WJ, 1985, ARTIF INTELL, V27, P289, DOI 10.1016/0004-3702(85)90016-5; Coenen F., 1992, ICL TECHNICAL J, P76; DEYO RA, 1992, J CLIN EPIDEMIOL, V45, P613, DOI 10.1016/0895-4356(92)90133-8; Dimick JB, 2002, ARCH SURG-CHICAGO, V137, P828, DOI 10.1001/archsurg.137.7.828; DIMICK JB, 2004, HLTH AFF; Elixhauser A, 2003, HEALTH AFFAIR, V22, P167, DOI 10.1377/hlthaff.22.2.167; Elixhauser A, 1998, MED CARE, V36, P8, DOI 10.1097/00005650-199801000-00004; Feigenbaum E, 1977, ART ARTIFICIAL INTEL; Gandjour A, 2003, MED CARE, V41, P1129, DOI 10.1097/01.MLR.0000088301.06323.CA; Glance LG, 2003, ANN THORAC SURG, V76, P1155, DOI 10.1016/S0003-4975(03)00114-0; Halm EA, 2002, ANN INTERN MED, V137, P511; Hillner BE, 2000, J CLIN ONCOL, V18, P2327; HT Lin, 2003, NOTE PLATTS PROBABIL; Ihse I, 2003, ANN SURG, V238, P777, DOI 10.1097/01.sla.0000098616.19622.af; JAANA M, 2003, COM CPH RES WEEK; JEFFREY LR, 1992, MULTIOBJECTIVE OPTIM; Kohn LT, 2000, ERR IS HUMAN BUILDIN; Kupersmith J, 2005, ACAD MED, V80, P458, DOI 10.1097/00001888-200505000-00012; Ling C. X., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Nallamothu BK, 2005, ARCH INTERN MED, V165, P333, DOI 10.1001/archinte.165.3.333; Nemati HR, 2002, DECIS SUPPORT SYST, V33, P143, DOI 10.1016/S0167-9236(01)00141-5; Niculescu-Mizil A., 2005, P 22 INT C MACH LEAR, P625, DOI 10.1145/1102351.1102430; Platt J., 1999, ADV LARGE MARGIN CLA, P61; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; SHORTLIFFE EH, 1975, COMPUT BIOMED RES, V8, P303, DOI 10.1016/0010-4809(75)90009-9; THOMPSON TG, 2004, DECADE HLTH INFROM T; Vapnik V. N, 1995, NATURE STAT LEARNING; Ward MM, 2004, J RURAL HEALTH, V20, P344, DOI 10.1111/j.1748-0361.2004.tb00048.x; MARIR F, 1994, KNOWL ENG REV, V9, P355; Watson I., 1992, Expert Systems, V9, DOI 10.1111/j.1468-0394.1992.tb00401.x; Zadrozny B., 2001, P 18 INT C MACH LEAR, P609; *AM HOSP ASS, DAT SOURC; *HCUP, PROJ DESCR DAT; *LEAPFR GROUP, 2004, EV BAS HOSP REF	44	6	6	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464		J BIOMED INFORM	J. Biomed. Inform.	APR	2008	41	2					371	386		10.1016/j.jbi.2007.10.002		16	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	293UE	WOS:000255360000014	
J	Zhou, D; He, Y				Zhou, Deyu; He, Yulan			Extracting interactions between proteins from the literature	JOURNAL OF BIOMEDICAL INFORMATICS			English	Review						information extraction; biomedicine; computational linguistics; machine learning; text mining; protein-protein interactions	BIOMEDICAL TEXT; INFORMATION EXTRACTION; DISCOVERING PATTERNS; MOLECULAR-BIOLOGY; DATABASE; SYSTEM; RETRIEVAL; NETWORKS; PARSER	During the last decade, biomedicine has witnessed a tremendous development. Large amounts of experimental and computational biomedical data have been generated along with new discoveries, which are accompanied by an exponential increase in the number of biomedical publications describing these discoveries. In the meantime, there has been a great interest with scientific communities in text mining tools to find knowledge such as protein-protein interactions, which is most relevant and useful for specific analysis tasks. This paper provides a outline of the various information extraction methods in biomedical domain, especially for discovery of protein-protein interactions. It surveys methodologies involved in plain texts analyzing and processing, categorizes current work in biomedical information extraction, and provides examples of these methods. Challenges in the field are also presented and possible solutions are discussed. (c) 2007 Elsevier Inc. All rights reserved.	[Zhou, Deyu; He, Yulan] Univ Reading, Informat Res Ctr, Reading RG6 6BX, Berks, England	Zhou, D (reprint author), Univ Reading, Informat Res Ctr, Reading RG6 6BX, Berks, England.	d.zhou@reading.ac.uk; y.he@reading.ac.uk					Ahmed S, 2005, P ACL ISMB WORKSH LI, P54, DOI 10.3115/1641484.1641492; Andrade MA, 1998, BIOINFORMATICS, V14, P600, DOI 10.1093/bioinformatics/14.7.600; Andrade MA, 2000, FEBS LETT, V476, P12, DOI 10.1016/S0014-5793(00)01661-6; ANDREAS D, 2005, NUCLEIC ACIDS RES, V33, pW783; BARAL C, 2007, COMP SYST BIOINF C; Blaschke C, 2002, IEEE INTELL SYST, V17, P14, DOI 10.1109/MIS.2002.999215; Blaschke C, 2005, BIOINFORMATICS, V21, P4199, DOI 10.1093/bioinformatics/bti695; BUNESCU R, 2005, J ARTIF INTEL MED, P139; Cardie C, 1997, AI MAG, V18, P65; CAROL F, 2001, BIOINFORMATICS, V17, pS74; Chen LF, 2005, BIOINFORMATICS, V21, P248, DOI 10.1093/bioinformatics/bth496; Chiang JH, 2004, BIOINFORMATICS, V20, P120, DOI 10.1093/bioinformatics/btg369; CHRISTIAN B, 2001, COMP FUNCT GENOM, V2, P310; CHRISTIAN B, 1999, P 7 INT C INT SYST M, P60; CHRISTIAN V, 2005, NUCLEIC ACIDS RES, V33, P433; CHUN HW, 2005, LECT NOTES ARTIF INT, P777; Chun Hong-Woo, 2006, Pac Symp Biocomput, P4, DOI 10.1142/9789812701626_0002; Cohen AM, 2005, BRIEF BIOINFORM, V6, P57, DOI 10.1093/bib/6.1.57; COHEN KB, 2004, SERIES COMPUTATIONAL, V5; Craven M, 1999, Proc Int Conf Intell Syst Mol Biol, P77; CRAVEN M, 1999, P AAAI 1999 WORKSH M, P25; Cunningham H, 2005, ENCY LANGUAGE LINGUI; Daraselia N, 2004, BIOINFORMATICS, V20, P604, DOI 10.1093/bioinformatics/btg452; DAVID PAC, 2004, BIOINFORMATICS, V20, P3206; DEBRUIJN B, 2002, P EFMI WORKSH NAT LA, P1; DENYS P, 2000, P 8 INT C INT SYST M, P279; DING J, 2003, 15 IEEE INT C TOOLS; Ding J, 2002, Pac Symp Biocomput, P326; EOM JH, 2004, 11 INT C AIMSA 2004; FABIO R, 2007, ARTIF INTELL MED, V39, P127; GARY D, 2003, NUCLEIC ACIDS RES, V31, P248; GERALD S, 1989, ADDISONWESLEY SERIES; HAGIT S, 2007, BIOMEDICAL TEXT MINI; Hahn Udo, 2002, Pac Symp Biocomput, P338; HAO C, 2004, BMC BIOINFORMATICS, V8, P147; Hao Y, 2005, BIOINFORMATICS, V21, P3294, DOI 10.1093/bioinformatics/bti493; HAROLD JD, 2005, BMC BIOINFORM; Henning H., 2004, NUCLEIC ACIDS RES, V1, P452; Hersh W, 2005, BRIEF BIOINFORM, V6, P344, DOI 10.1093/bib/6.4.344; Hersh W. R., 2003, INFORM RETRIEVAL HLT; Hoffmann R, 2004, NAT GENET, V36, P664, DOI 10.1038/ng0704-664; Huang ML, 2004, BIOINFORMATICS, V20, P3604, DOI 10.1093/bioinformatics/bth451; Hunter L, 2006, MOL CELL, V21, P589, DOI 10.1016/j.molcel.2006.02.012; IAN D, 2003, BMC BIOINFORMATICS, P4; JEFFREY T, 2003, THESIS STANFORD U; Jensen LJ, 2006, NAT REV GENET, V7, P119, DOI 10.1038/nrg1768; Jenssen TK, 2001, NAT GENET, V28, P21, DOI 10.1038/ng0501-21; KATRIN F, 2007, BIOINFORMATICS, V23, P365; Klein D, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P423; Krallinger M, 2005, DRUG DISCOV TODAY, V10, P439, DOI 10.1016/S1359-6446(05)03376-3; Krauthammer M, 2004, J BIOMED INFORM, V37, P512, DOI 10.1016/j.jbi.2004.08.004; Leroy G, 2003, J BIOMED INFORM, V36, P145, DOI 10.1016/S1532-0464(03)00039-X; Leroy G, 2002, Pac Symp Biocomput, P350; LESER U, 2005, BRIEF BIOINFORM, V6, P257; Lomax J, 2005, BRIEF BIOINFORM, V6, P298, DOI 10.1093/bib/6.3.298; LYNETTE H, 2002, BIOINFORMATICS, V18, P1553; LYNETTE H, 2004, BMC BIOINFORMATIC S1, V6; Marcotte EM, 2001, BIOINFORMATICS, V17, P359, DOI 10.1093/bioinformatics/17.4.359; MARQUEZ L, 2000, LSI0045R U POL CAT D; MATHIAK B, 2004, DATA MINING TEXT MIN; McNaught J, 2006, TEXT MINING BIOL BIO; Michael Ashburner, 2000, NAT GENET, V25, P25; MOONEY R, 2005, SIGKDD EXPLORATIONS, V7, P3; NEDELLEC C, 2005, LEARN LANG LOG WORKS, P31; NG SK, 1999, P 12 NAT C ART INT; Novichkova S, 2003, BIOINFORMATICS, V19, P1699, DOI 10.1093/bioinformatics/btg207; Park J C, 2001, Pac Symp Biocomput, P396; Pearson H, 2001, NATURE, V411, P631, DOI 10.1038/35079694; Peri S, 2003, GENOME RES, V13, P2363, DOI 10.1101/gr.1680803; PHUONG TM, 2003, 7 PAC AS C KNOWL DIS; Pustejovsky J, 2002, Pac Symp Biocomput, P362; RAY S, 2001, P 17 INT JOINT C ART, P1273; RINALDI F, 2004, 2 EUR WORKSH DAT MIN; Rindflesch T C, 2000, Pac Symp Biocomput, P517; Rindflesch T C, 1999, Proc AMIA Symp, P127; ROSARIO B, 2005, HLT NAACL 05 VANC; Rzhetsky A, 2004, J BIOMED INFORM, V37, P43, DOI 10.1016/j.jbi.2003.10.001; SEKIMIZU T, 1998, WORKSH GEN INF, V9, P62; Seymore K., 1999, AAAI 99 WORKSH MACH; Shatkay H, 2003, J COMPUT BIOL, V10, P821, DOI 10.1089/106652703322756104; SKOUNAKIS M, 2003, P 18 INT JOINT C ART; Skusa A, 2005, BRIEF BIOINFORM, V6, P263, DOI 10.1093/bib/6.3.263; Spasic I, 2005, BRIEF BIOINFORM, V6, P239, DOI 10.1093/bib/6.3.239; Stapley B J, 2000, Pac Symp Biocomput, P529; Stephens M., 2001, PAC S BIOCOMPUT, V6, P483; TAN SY, 2005, INT JOINT C INCOB AA; Temkin JM, 2003, BIOINFORMATICS, V19, P2046, DOI 10.1093/bioinformatics/btg279; Thomas J, 2000, Pac Symp Biocomput, P541; TOSHIHIDE O, 2001, BIOINFORMATICS, V17, P155; VALENCIA A, 2000, WORKSH GEN INF, V12, P123; VANRIJSBERGEN CJ, 1999, INFORM RETRIEVAL; Wong L, 2001, Pac Symp Biocomput, P520; Xenarios I, 2002, NUCLEIC ACIDS RES, V30, P303, DOI 10.1093/nar/30.1.303; Yakushiji A, 2001, Pac Symp Biocomput, P408; Yandell MD, 2002, NAT REV GENET, V3, P601, DOI 10.1038/nrg861; Zanzoni A, 2002, FEBS LETT, V513, P135, DOI 10.1016/S0014-5793(01)03293-8; ZHOU D, 2006, INT WORKSH BIOINF RE	97	29	30	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464		J BIOMED INFORM	J. Biomed. Inform.	APR	2008	41	2					393	407		10.1016/j.jbi.2007.11.008		15	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	293UE	WOS:000255360000016	
J	Schwaighofer, A; Schroeter, T; Mika, S; Hansen, K; ter Laak, A; Lienau, P; Reichel, A; Heinrich, N; Muller, KR				Schwaighofer, Anton; Schroeter, Timon; Mika, Sebastian; Hansen, Katja; ter Laak, Antonius; Lienau, Philip; Reichel, Andreas; Heinrich, Nikolaus; Mueller, Klaus-Robert			A Probabilistic approach to classifying metabolic stability	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							DRUG DISCOVERY; FEATURE-SELECTION; CLASSIFICATION; MACHINE; MODELS; PREDICTION; SOLUBILITY	Metabolic stability is an important property of drug molecules that should-optimally-be taken into account early on in the drug design process. Along with numerous medium- or high-throughput assays being implemented in early drug discovery, a prediction tool for this property could be of high value. However, metabolic stability is inherently difficult to predict, and no commercial tools are available for this purpose. In this work, we present a machine learning approach to predicting metabolic stability that is tailored to compounds from the drug development process at Bayer Schering Pharma. For four different in vitro assays, we develop Bayesian classification models to predict the probability of a compound being metabolically stable. The chosen approach implicitly takes the "domain of applicability" into account. The developed models were validated on recent project data at Bayer Schering Pharma, showing that the predictions are highly accurate and the domain of applicability is estimated correctly. Furthermore, we evaluate the modeling method on a set of publicly available data.	[Schwaighofer, Anton; Schroeter, Timon; Hansen, Katja; Mueller, Klaus-Robert] Fraunhofer FIRST, D-12489 Berlin, Germany; [Schroeter, Timon; Hansen, Katja; Mueller, Klaus-Robert] Tech Univ Berlin, Dept Comp Sci, D-10587 Berlin, Germany; [Mika, Sebastian] Idalab GmbH, D-10178 Berlin, Germany; [ter Laak, Antonius; Lienau, Philip; Reichel, Andreas; Heinrich, Nikolaus] Res Labs Bayer Schering Pharma, D-13342 Berlin, Germany	Schwaighofer, A (reprint author), Fraunhofer FIRST, Kekulestr 7, D-12489 Berlin, Germany.	anton@first.fraunhofer.de	Muller, Klaus/C-3196-2013				Bishop C.M., 1995, NEURAL NETWORKS PATT; Bursi R, 2001, J MOL GRAPH MODEL, V19, P552, DOI 10.1016/S1093-3263(01)00089-4; Byvatov E, 2003, J CHEM INF COMP SCI, V43, P1882, DOI 10.1021/ci0341161; Cashman JR, 1996, DRUG DISCOV TODAY, V1, P209, DOI 10.1016/1359-6446(96)10017-9; Fox T, 2006, CURR TOP MED CHEM, V6, P1579, DOI 10.2174/156802606778108915; Gasteiger J., 2003, CHEMOINFORMATICS TXB; GOMBAR V, 2006, J COMPUT AIDED DRUG, V2, P177; Hastie T, 2001, ELEMENTS STAT LEARNI; Hou TJ, 2003, J CHEM INF COMP SCI, V43, P2137, DOI 10.1021/ci034134i; Jensen BF, 2003, J COMPUT AID MOL DES, V17, P849, DOI 10.1023/B:JCAM.0000021861.31978.da; Kuss M, 2005, J MACH LEARN RES, V6, P1679; Liu Y, 2004, J CHEM INF COMP SCI, V44, P1823, DOI 10.1021/ci049875d; Masimirembwa CM, 2003, CLIN PHARMACOKINET, V42, P515, DOI 10.2165/00003088-200342060-00002; Merkwirth C, 2004, J CHEM INF COMP SCI, V44, P1971, DOI 10.1021/ci049850e; Muller KR, 2005, J CHEM INF MODEL, V45, P249, DOI 10.1021/ci049737o; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; MURPHY AH, 1992, INT J FORECASTING, V7, P435, DOI 10.1016/0169-2070(92)90028-8; Neal Radford, 1998, BAYESIAN STAT, V6, P475; Netzeva T. I, 2005, ATLA-ALTERN LAB ANIM, V33, P1; ORR G, 1998, SPRINGER LNCS, V1524; Platt J., 1999, ADV LARGE MARGIN CLA, P61; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; SADOWSKI J, CORINA V 3 1; Scholkopf B., 2002, LEARNING KERNELS; SCHROETER T, 2007, CHEMMEDCHEM; Schroeter T, 2007, MOL PHARMACEUT, V4, P524, DOI 10.1021/mp0700413; SCHROETER T, 2007, J COMPUT AIDED MOL D; Schwaighofer A, 2007, J CHEM INF MODEL, V47, P407, DOI 10.1021/ci600205g; Shen M, 2003, J MED CHEM, V46, P3013, DOI 10.1021/jm020491t; Tetko IV, 2006, DRUG DISCOV TODAY, V11, P700, DOI 10.1016/j.drudis.2006.06.013; TODESCHINI R, DRAGON WINDOWS LINUX; Vapnik V. N., 1995, NATURE STATE LEARNIN; Wegner JK, 2004, J CHEM INF COMP SCI, V44, P931, DOI 10.1021/ci034233w; Yan AX, 2004, J COMPUT AID MOL DES, V18, P75, DOI 10.1023/B:jcam.0000030031.81235.05; Zhu CY, 1997, ACM T MATH SOFTWARE, V23, P550, DOI 10.1145/279232.279236	35	23	23	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596		J CHEM INF MODEL	J. Chem Inf. Model.	APR	2008	48	4					785	796		10.1021/ci700142c		12	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	295AW	WOS:000255448400009	
J	Pong, JYH; Kwok, RCW; Lau, RYK; Hao, JX; Wong, PCC				Pong, Joanna Yi-Hang; Kwok, Ron Chi-Wai; Lau, Raymond Yiu-Keung; Hao, Jin-Xing; Wong, Percy Ching-Chi			A comparative study of two automatic document classification methods in a library setting	JOURNAL OF INFORMATION SCIENCE			English	Article						automatic document classification; text categorization; machine learning; k-nearest; neighbours classifier; naive Bayes classifier; library practice	TEXT CATEGORIZATION; CATALOG; SYSTEM	In current library practice, trained human experts usually carry out document cataloguing and indexing based on a manual approach. With the explosive growth in the number of electronic documents available on the Internet and digital libraries, it is increasingly difficult for library practitioners to categorize both electronic documents and traditional library materials using just a manual approach. To improve the effectiveness and efficiency of document categorization at the library setting, more in-depth studies of using automatic document classification methods to categorize library items are required. Machine learning research has advanced rapidly in recent years. However, applying machine learning techniques to improve library practice is still a relatively unexplored area. This paper illustrates the design and development of a machine learning based automatic document classification system to alleviate the manual categorization problem encountered within the library setting. Two supervised machine learning algorithms have been tested. Our empirical tests show that supervised machine learning algorithms in general, and the k-nearest neighbours (KNN) algorithm in particular, can be used to develop an effective document classification system to enhance current library practice. Moreover, some concrete recommendations regarding how to practically apply the KNN algorithm to develop automatic document classification in a library setting are made. To our best knowledge, this is the first in-depth study of applying the KNN algorithm to automatic document classification based on the widely used LCC classification scheme adopted by many large libraries.	[Kwok, Ron Chi-Wai; Lau, Raymond Yiu-Keung; Hao, Jin-Xing; Wong, Percy Ching-Chi] City Univ Hong Kong, Dept Informat Syst, Kowloon, Hong Kong, Peoples R China; [Pong, Joanna Yi-Hang] City Univ Hong Kong, Run Run Shaw Library, Kowloon, Hong Kong, Peoples R China	Kwok, RCW (reprint author), City Univ Hong Kong, Dept Informat Syst, Tat Chee Ave, Kowloon, Hong Kong, Peoples R China.	isron@cityu.edu.hk	Hao, Jin-xing/E-9066-2010; Pong, Joanna/C-7083-2012				AVANCINI H, 2002, 2002TR05 I EL INF; Baker L. D., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.290970; CHAN LM, 2000, EXPLOITING LCSH LCC; Chander PG, 1997, EXPERT SYST APPL, V12, P405, DOI 10.1016/S0957-4174(97)00001-8; Chung YM, 2003, J INFORM SCI, V29, P117, DOI 10.1177/016555150302900204; Coyle K, 2007, J ACAD LIBR, V33, P289, DOI 10.1016/j.acalib.2007.02.003; DUMAIS S., 2000, P 23 ANN INT ACM SIG, P256, DOI 10.1145/345508.345593; DUMAIS ST, 2002, WORKSH OP TEXT CLASS; GODBY J, 2001, SUBJECT RETRIEVAL NE; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Koller D, 1997, P 14 INT C MACH LEAR, P170; Kwon OW, 2003, INFORM PROCESS MANAG, V39, P25, DOI 10.1016/S0306-4573(02)00022-5; LEVY D, 1999, P 5 ACM IEEE CS JOIN, P281; Lewis D. D., 1998, P 10 EUR C MACH LEAR, P4; LEWIS DD, 2001, WORKSH OP TEXT CLASS; LEWIS DD, 1997, REUTERS21578; LUHN HP, 1958, IBM J RES DEV, V2, P159; Mitchell T, 1997, MACHINE LEARNING; MOLLER G, 1999, 23 INT ONL INF M LON, P231; Paiste MS, 2003, LIBR COLLECT ACQUIS, V27, P327, DOI 10.1016/S1464-9055(03)00069-1; Porter GM, 1999, J ACAD LIBR, V25, P390, DOI 10.1016/S0099-1333(99)80058-5; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; Salton G., 1983, INTRO MODERN INFORM; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; VIZINEGOETZ D, 2001, EXPLOITING LCSH LCC; Weigend A. S., 1999, Information Retrieval, V1, DOI 10.1023/A:1009983522080; Yang Yiming, 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647	27	4	4	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	0165-5515		J INF SCI	J. Inf. Sci.	APR	2008	34	2					213	230		10.1177/0165551507082592		18	Computer Science, Information Systems; Information Science & Library Science	Computer Science; Information Science & Library Science	286LY	WOS:000254848600007	
J	Weckman, GR; Ganduri, CV; Koonce, DA				Weckman, Gary R.; Ganduri, Chandrasekhar V.; Koonce, David A.			A neural network job-shop scheduler	JOURNAL OF INTELLIGENT MANUFACTURING			English	Article						artificial neural networks; scheduling; job-shop; machine learning; genetic algorithms		This paper focuses on the development of a neural network (NN) scheduler for scheduling job-shops. In this hybrid intelligent system, genetic algorithms (GA) are used to generate optimal schedules to a known benchmark problem. In each optimal solution, every individually scheduled operation of a job is treated as a decision which contains knowledge. Each decision is modeled as a function of a set of job characteristics (e.g., processing time), which are divided into classes using domain knowledge from common dispatching rules (e.g., shortest processing time). A NN is used to capture the predictive knowledge regarding the assignment of operation's position in a sequence. The trained NN could successfully replicate the performance of the GA on the benchmark problem. The developed NN scheduler was then tested against the GA, Attribute-Oriented Induction data mining methodology and common dispatching rules on a test set of randomly generated problems. The better performance of the NN scheduler on the test problem set compared to other methods proves the feasibility of NN-based scheduling. The scalability of the NN scheduler on larger problem sizes was also found to be satisfactory in replicating the performance of the GA.	[Weckman, Gary R.; Ganduri, Chandrasekhar V.; Koonce, David A.] Ohio Univ, Dept Ind & Syst Engn, Athens, OH 45701 USA	Weckman, GR (reprint author), Ohio Univ, Dept Ind & Syst Engn, 280 Stocker Ctr, Athens, OH 45701 USA.	weckman@bobcat.ent.ohiou.edu; ganduri@bobcat.ent.ohiou.edu; koonce@ohio.edu					ADAMS J, 1988, MANAGE SCI, V34, P391, DOI 10.1287/mnsc.34.3.391; Agarwal A, 2006, EUR J OPER RES, V169, P801, DOI 10.1016/j.ejor.2004.06.039; Baker KR, 1974, INTRO SEQUENCING SCH; BLACKSTONE JH, 1982, INT J PROD RES, V20, P27, DOI 10.1080/00207548208947745; CHEUNG JY, 1994, ARTIFICIAL NEURAL NE, P469; Dagli CH, 1995, INT J PROD ECON, V41, P135, DOI 10.1016/0925-5273(95)00072-0; DIETTERICH T, 1996, ACM COMPUT SURV, V28, pES3; Fisher H., 1963, IND SCHEDULING, P225; Fonseca DJ, 2002, ADV ENG INFORM, V16, P241, DOI 10.1016/S1474-0346(03)00005-3; FOO SY, 1995, NEUROCOMPUTING, V8, P79, DOI 10.1016/0925-2312(94)00011-5; FOO YPS, 1988, IEEE ICNN, V2, P341; French S, 1982, SEQUENCING SCHEDULIN; GIFFLER B, 1960, OPER RES, V8, P487, DOI 10.1287/opre.8.4.487; JAIN AS, 1996, P IMS 96 1 S INT MAN, P462; Jain AS, 1998, INT J PROD RES, V36, P1249, DOI 10.1080/002075498193309; KASCHEL J, 1999, EUR S INT TECHN GREE; Koonce DA, 2000, COMPUT IND ENG, V38, P361, DOI 10.1016/S0360-8352(00)00050-4; Lawrence S, 1984, RESOURCE CONSTRAIN S; Mitchell T, 1997, MACHINE LEARNING; PRINCIPLE JC, 2000, NEURAL ADAPTIVE SYST; RABELO LC, 1989, IJCNN, V2; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; SHAH N, 2004, P IIE 2004 ANN C HOU; SORMAZ DN, 2003, IND ENG RES C MAY 18; Turban E., 2001, DECISION SUPPORT SYS; WIDROW B, 1994, COMMUN ACM, V37, P93, DOI 10.1145/175247.175257; Yamada T, 1992, PARALLEL PROBLEM SOL, V2, P281; Yamada T., 1997, Genetic Algorithms in Engineering Systems, DOI 10.1049/PBCE055E_ch7; Yang SX, 2000, IEEE T NEURAL NETWOR, V11, P474, DOI 10.1109/72.839016; Yu HB, 2001, COMPUT IND ENG, V39, P337, DOI 10.1016/S0360-8352(01)00010-9	30	6	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0956-5515		J INTELL MANUF	J. Intell. Manuf.	APR	2008	19	2					191	201		10.1007/s10845-008-0073-9		11	Computer Science, Artificial Intelligence; Engineering, Manufacturing	Computer Science; Engineering	274AX	WOS:000253975300005	
J	Yoon, S; Fern, A; Givan, R				Yoon, Sungwook; Fern, Alan; Givan, Robert			Learning control knowledge for forward search planning	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						planning; machine learning; knowledge representation; search	HEURISTIC-SEARCH; INFERENCE; SPACE; GRAPH	A number of today's state-of-the-art planners are based on forward state-space search. The impressive performance can be attributed to progress in computing domain independent heuristics that perform well across many domains. However, it is easy to find domains where such heuristics provide poor guidance, leading to planning failure. Motivated by such failures, the focus of this paper is to investigate mechanisms for learning domain-specific knowledge to better control forward search in a given domain. While there has been a large body of work on inductive learning of control knowledge for AI planning, there is a void of work aimed at forward-state-space search. One reason for this may be that it is challenging to specify a knowledge representation for compactly representing important concepts across a wide range of domains. One of the main contributions of this work is to introduce a novel feature space for representing such control knowledge. The key idea is to define features in terms of information computed via relaxed plan extraction, which has been a major source of success for non-learning planners. This gives a new way of leveraging relaxed planning techniques in the context of learning. Using this feature space, we describe three forms of control knowledge-reactive policies (decision list rules and measures of progress) and linear heuristics-and show how to learn them and incorporate them into forward state-space search. Our empirical results show that our approaches are able to surpass state-of-the-art non-learning planners across a wide range of planning competition domains.	[Yoon, Sungwook] Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85281 USA; [Fern, Alan] Oregon State Univ, Sch Elect Engn & Comp Sci, Corvallis, OR 97330 USA; [Givan, Robert] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA	Yoon, S (reprint author), Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85281 USA.	sungwook.yoon@asu.edu; afern@eecs.orst.edu; givan@purdue.edu					Aler R, 2002, ARTIF INTELL, V141, P29, DOI 10.1016/S0004-3702(02)00246-1; Ambite JL, 2001, J ARTIF INTELL RES, V15, P207; Bacchus F, 2000, ARTIF INTELL, V116, P123, DOI 10.1016/S0004-3702(99)00071-5; BARTO AG, 1995, ARTIF INTELL, V72, P81, DOI 10.1016/0004-3702(94)00011-O; BENTON J, 2006, P 15 INT C AUT PLANN; Bertsekas D. P., 1996, NEURODYNAMIC PROGRAM; Blum A, 1995, P 14 INT JOINT C ART, P1636; Bonet B, 2001, ARTIF INTELL, V129, P5, DOI 10.1016/S0004-3702(01)00108-4; Botea A, 2005, J ARTIF INTELL RES, V24, P581; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Bryce D, 2006, J ARTIF INTELL RES, V26, P35; BYLANDER T, 1994, ARTIF INTELL, V69, P165, DOI 10.1016/0004-3702(94)90081-7; Coles A, 2007, J ARTIF INTELL RES, V28, P119; Do MB, 2003, J ARTIF INTELL RES, V20, P155; Dzeroski S, 2001, MACH LEARN, V43, P7, DOI 10.1023/A:1007694015589; ESTLIN TA, 1996, P 13 NAT C ART INT; FERN A, 2006, J ARTIFICIAL INTELLI, V25, P85; FIKES RE, 1972, ARTIF INTELL, V3, P251, DOI 10.1016/0004-3702(72)90051-3; Fox M, 1998, J ARTIF INTELL RES, V9, P367; FURNKRANZ J, 2003, P 20 INT C MACH LEAR; Gerevini A., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); Harvey WD, 1995, P 14 INT JOINT C ART; HELMERT M, 2007, P 17 INT C AUT PLANN, V9; HOFFMANN J, 2001, J ARTIFICIAL INTELLI, V14, P263; HUANG YC, 2000, P 17 INT C MACH LEAR, P415; Khardon R, 1999, ARTIF INTELL, V113, P125, DOI 10.1016/S0004-3702(99)00060-0; MARTIN M, 2000, P 17 INT C PRINC KNO; MCALLESTER D, 1993, J ACM, V40, P246, DOI 10.1145/151261.151264; MINTON S, 1989, ARTIF INTELL, V40, P63, DOI 10.1016/0004-3702(89)90047-7; MINTON S, 1993, MACHINE LEARNING MET; MINTON S, 1988, P NAT C ART INT; Nau D., 1999, P 16 INT JOINT C ART, P968; Nguyen XL, 2002, ARTIF INTELL, V135, P73, DOI 10.1016/S0004-3702(01)00158-8; PARMAR A, 2002, P 18 NAT C ART INT J, P498; Rivest R. L., 1987, Machine Learning, V2, DOI 10.1007/BF00058680; VIDAL V, 2004, INT C AUT PLANN SCH; XU YH, 2007, P 20 INT JOINT C ART; YOON S, 2002, P 18 C UNC ART INT; YOON SW, 2005, P 20 NAT C ART INT; Zimmerman T, 2003, AI MAG, V24, P73	40	11	11	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	APR	2008	9						683	718				36	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	312AS	WOS:000256642100006	
J	Seeger, MW				Seeger, Matthias W.			Bayesian inference and optimal design for the sparse linear model	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						sparse linear model; Laplace prior; expectation propagation; approximate inference; optimal design; Bayesian statistics; gene network recovery; image coding; compressive sensing	APPROXIMATE INFERENCE; VECTOR MACHINE; GENE NETWORKS; CLASSIFICATION; LIKELIHOOD; ALGORITHMS; FRAMEWORK; SELECTION; STRATEGY	The linear model with sparsity-favouring prior on the coefficients has important applications in many different domains. In machine learning, most methods to date search for maximum a posteriori sparse solutions and neglect to represent posterior uncertainties. In this paper, we address problems of Bayesian optimal design (or experiment planning), for which accurate estimates of uncertainty are essential. To this end, we employ expectation propagation approximate inference for the linear model with Laplace prior, giving new insight into numerical stability properties and proposing a robust algorithm. We also show how to estimate model hyperparameters by empirical Bayesian maximisation of the marginal likelihood, and propose ideas in order to scale up the method to very large underdetermined problems. We demonstrate the versatility of our framework on the application of gene regulatory network identification from micro-array expression data, where both the Laplace prior and the active experimental design approach are shown to result in significant improvements. We also address the problem of sparse coding of natural images, and show how our framework can be used for compressive sensing tasks. Part of this work appeared in Seeger et al. (2007b). The gene network identification application appears in Steinke et al. (2007).	Max Planck Inst Biol Cybernet, Tubingen, Germany	Seeger, MW (reprint author), Max Planck Inst Biol Cybernet, Spemannstr 38, Tubingen, Germany.	seeger@tuebingen.mpg.de					Attias H, 2000, ADV NEUR IN, V12, P209; BERKES P, 2008, ADV NEURAL INFORM PR, V20; BISHOP C, 2003, WORKSH ART INT STAT, V9, P244; Bogachev V.I., 1998, MATH SURVEYS MONOGRA; BOTTOU L, 1998, ON LINE LEARNING NEU; Boyd S., 2002, CONVEX OPTIMIZATION; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Chaloner K, 1995, STAT SCI, V10, P273, DOI 10.1214/ss/1177009939; Chen S, 1999, SIAM J SCI COMPUT, V20, P33; Chhikara R.S., 1989, INVERSE GAUSSIAN DIS; Chib S, 1995, J AM STAT ASSOC, V90, P1313, DOI 10.2307/2291521; DERISI J, 1997, SCIENCE, V282, P699; Dongarra J., 1979, LINPACK USERS GUIDE; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100; Faul AC, 2002, ADV NEUR IN, V14, P383; Fedorov V. V., 1972, THEORY OPTIMAL EXPT; Figueiredo M., 2003, IEEE T PATTERN ANAL, V25, P1050; Gardner TS, 2000, NATURE, V403, P339; GERWINN S, 2008, ADV NEURAL INFORM PR, V20; Ghahramani Z, 2001, ADV NEUR IN, V13, P507; GILKS WR, 1992, APPL STAT-J ROY ST C, V41, P337, DOI 10.2307/2347565; Gilks WR, 1996, MARKOV CHAIN MONTE C; Girolami M, 2001, NEURAL COMPUT, V13, P2517, DOI 10.1162/089976601753196003; Gneiting T, 1997, J STAT COMPUT SIM, V59, P375, DOI 10.1080/00949659708811867; Hastie T, 2004, J MACH LEARN RES, V5, P1391; HENDERSON HV, 1981, SIAM REV, V23, P53, DOI 10.1137/1023004; Hojen-Sorensen PADFR, 2002, NEURAL COMPUT, V14, P889, DOI 10.1162/089976602317319009; Horn R. A., 1985, MATRIX ANAL; Ishwaran H, 2005, J AM STAT ASSOC, V100, P764, DOI 10.1198/016214505000000051; JAAKKOLA T, 1997, THESIS MASSACHUSETTS; JI S, 2007, INT C MACH LEARN OMN, V24; Jordan M.I., 1997, LEARNING GRAPHICAL M; Kholodenko BN, 2002, P NATL ACAD SCI USA, V99, P12841, DOI 10.1073/pnas.192442699; Kushner HJ, 2000, IEEE T AUTOMAT CONTR, V45, P580, DOI 10.1109/9.847749; Kuss M, 2005, J MACH LEARN RES, V6, P1679; Lawrence N. D., 2003, ADV NEURAL INFORM PR, V15, P609; LEWI J, 2007, ADV NEURAL INFORM PR, V19; Lewicki MS, 1999, J OPT SOC AM A, V16, P1587, DOI 10.1364/JOSAA.16.001587; Lovasz L., 2003, MSRTR200305; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.415; MACKAY D, 1991, NEURAL COMPUT, V4, P589; MINKA T, 2001, UNCERTAINTY ARTIFICI, V17; MINKA T, 2001, THESIS MASSACHUSETTS; MINKA T, 2004, TECHNICAL REPORT MIC; Neal R. M., 1993, CRGTR931 U TOR; Neal R.M., 1996, LECT NOTES STAT, V118; O'Hagan A., 1994, KENDALLS ADV THEOR B, V2B; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Opper M, 2005, J MACH LEARN RES, V6, P2177; Opper M, 2000, NEURAL COMPUT, V12, P2655, DOI 10.1162/089976600300014881; PALMER A, 2006, ADV NEURAL INFORM PR, V18; Paninski L., 2005, ADV NEURAL INFORM PR, V17; Park T., 2005, BAYESIAN LASSO; PEETERS R, 2004, P 16 INT S MATH THEO; PRATT JW, 1981, J AM STAT ASSOC, V76, P103, DOI 10.2307/2287052; QI Y, 2004, INT C MACH LEARN MOR, V21; Rabiner L., 2003, FUNDAMENTALS SPEECH; Rogers S, 2005, BIOINFORMATICS, V21, P3131, DOI 10.1093/bioinformatics/bti487; SAAD Y., 1996, ITERATIVE METHODS SP; SEEGER M, 2007, EUR C MACH LEARN SPR, V18; SEEGER M, 2008, COMPRESSED IN PRESS; SEEGER M, 2007, WORKSH ART INT STAT, V11; Seeger M., 2003, THESIS U EDINBURGH; SEEGER M, 2004, LOW RANK UPDATES CHO; Seeger Matthias, 2005, EXPECTATION PROPAGAT; SEUNG HS, 1992, C COMP LEARN THEOR M, V5, P287; Spiegelhalter D. J., 1995, BUGS BAYESIAN INFERE; STEINKE F, 2007, BMC SYSTEMS BIOL, V1; Tegner J, 2003, P NATL ACAD SCI USA, V100, P5944, DOI 10.1073/pnas.0933416100; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Wainwright M., 2006, 709 UC BERK DEP STAT; Wainwright M. J., 2003, 649 UC BERK DEP STAT; WIPF D, 2007, P ICASSP 2007; WIPF DP, 2004, ADV NEURAL INFORM PR, V16; ZOETER O, 2005, WORKSH ART INT STAT, V10	77	43	44	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	APR	2008	9						759	813				55	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	312AS	WOS:000256642100008	
J	Allahverdyan, AE; Janzing, D				Allahverdyan, Armen E.; Janzing, Dominik			Relating the thermodynamic arrow of time to the causal arrow	JOURNAL OF STATISTICAL MECHANICS-THEORY AND EXPERIMENT			English	Article						new applications of statistical mechanics	QUANTUM SYSTEMS; 2ND-LAW; ENTROPY; THEOREM; CHAOS; GIBBS; PROOF	Consider a Hamiltonian system that consists of a slow subsystem S and a fast subsystem F. The autonomous dynamics of S is driven by an effective Hamiltonian, but its thermodynamics is unexpected. We show that a well-defined thermodynamic arrow of time (second law) emerges for S whenever there is a well-defined causal arrow from S to F and the back-action is negligible. This is because the back-action of F on S is described by a non-globally Hamiltonian Born Oppenheimer term that violates the Liouville theorem, and makes the second law inapplicable to S. If S and F are mixing, under the causal arrow condition they are described by microcanonical distributions P(S) and P(S|F). Their structure supports a causal inference principle proposed recently in machine learning.	[Allahverdyan, Armen E.] Yerevan Phys Inst, Yerevan 375036, Armenia; [Janzing, Dominik] Univ Cent Florida, Sch Elect Engn & Comp Sci, Orlando, FL 32816 USA	Allahverdyan, AE (reprint author), Yerevan Phys Inst, Alikhanian Bros St 2, Yerevan 375036, Armenia.	aarmen@mail.yerphi.am; janzing@ira.uka.de					Allahverdyan AE, 2007, PHYS REV E, V75, DOI 10.1103/PhysRevE.75.051124; Allahverdyan AE, 2002, PHYS REV B, V66, DOI 10.1103/PhysRevB.66.115309; Allahverdyan AE, 2005, PHYS REV E, V71, DOI 10.1103/PhysRevE.71.046107; Balian R, 1992, MICROPHYSICS MACROPH, VII; Balian R, 1992, MICROPHYSICS MACROPH, VI; BASSETT IM, 1978, PHYS REV A, V18, P2356, DOI 10.1103/PhysRevA.18.2356; Becker R., 1967, THEORY HEAT; BERDICHEVSKY VL, 1997, THERMODYNAMICS CHAOS; BERRY MV, 1993, P ROY SOC LOND A MAT, V442, P659, DOI 10.1098/rspa.1993.0127; Campisi M, 2008, STUD HIST PHILOS M P, V39, P181, DOI 10.1016/j.shpsb.2007.09.002; Campisi M, 2005, STUD HIST PHILOS M P, V36B, P275, DOI 10.1016/j.shpsb.2005.01.001; CARROLL SM, 2004, HEPTH0410270; CARROLL SM, 2005, GRQC0505037; DEROECK W, 2005, CONDMAT0508089; Falcioni M, 2007, PHYSICA A, V385, P170, DOI 10.1016/j.physa.2007.06.036; GEMMER J, 2004, SPRINGER LECT NOTES, V657; Gorban A. N., 2005, INVARIANT MANIFOLDS; Haken H., 1983, SYNERGETICS INTRO NO; Hertz P, 1910, ANN PHYS-BERLIN, V33, P225; Hertz P, 1910, ANN PHYS-BERLIN, V33, P537; Hoffding Harald, 1955, HIST MODERN PHILOS; Janzing D., 2000, INT J THEOR PHYS, V39, P2217; JARZYNSKI C, 1993, PHYS REV LETT, V71, P839, DOI 10.1103/PhysRevLett.71.839; JARZYNSKI C, 1995, PHYS REV LETT, V74, P2937, DOI 10.1103/PhysRevLett.74.2937; JAYNES ET, 1965, AM J PHYS, V33, P391, DOI 10.1119/1.1971557; KANO Y, 2003, ISM REPORT RES ED, P261; KASUGA T, 1961, P JPN ACAD, V37, P366; LENARD A, 1978, J STAT PHYS, V19, P575, DOI 10.1007/BF01011769; Lieberman MA, 1991, REGULAR CHAOTIC DYNA; Lindblad G., 1983, NONEQUILIBRIUM ENTRO; Munster A., 1969, STAT THERMODYNAMICS, V1; OTT E, 1979, PHYS REV LETT, V42, P1628, DOI 10.1103/PhysRevLett.42.1628; Pearl J., 2000, CAUSALITY; PENROSE O, 1962, P PHYS SOC LOND, V79, P605, DOI 10.1088/0370-1328/79/3/318; PENROSE R, 1994, J STAT PHYS, V77, P217, DOI 10.1007/BF02186840; PUSZ W, 1978, COMMUN MATH PHYS, V58, P273, DOI 10.1007/BF01614224; Reichenbach H., 1956, DIRECTION TIME; Risken H., 1984, FOKKERPLANCK EQUATIO; RUGH HH, 2001, PHYS REV E, V65; Sagdeev R. Z., 1988, NONLINEAR PHYS; Scholkopf B., 2002, LEARNING KERNELS; Schulman L.S., 1997, TIMES ARROWS QUANTUM; Spirtes P., 1993, CAUSATION PREDICTION; Sun X., 2006, P 9 INT S ART INT MA, P1; SUN X, 2007, NEUROCOMPUTING, V71, P1248; VANKAMPE.NG, 1971, PHYSICA, V53, P98, DOI 10.1016/0031-8914(71)90105-4; WALD RM, 2005, GRQC0507094; Weiss U., 1993, QUANTUM DISSIPATIVE; Zeh H. D., 2001, PHYS BASIS DIRECTION	49	1	1	IOP PUBLISHING LTD	BRISTOL	TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND	1742-5468		J STAT MECH-THEORY E	J. Stat. Mech.-Theory Exp.	APR	2008									P04001	10.1088/1742-5468/2008/04/P04001		21	Mechanics; Physics, Mathematical	Mechanics; Physics	298BS	WOS:000255662000005	
J	Hu, GS; Zhang, GH				Hu Guosheng; Zhang Guohong			Comparison on neural networks and support vector machines in suppliers' selection	JOURNAL OF SYSTEMS ENGINEERING AND ELECTRONICS			English	Article						supplier selection; supply chain management; logistics; support vector machine; BPNN		Suppliers' selection in supply chain management (SCM) has attracted considerable research interests in recent years. Recent literatures show that neural networks achieve better performance than traditional statistical methods. However, neural networks have inherent drawbacks, such as local optimization solution, lack generalization, and uncontrolled convergence. A relatively new machine learning technique, support vector machine (SVM), which overcomes the drawbacks of neural networks, is introduced to provide a model with better explanatory power to select ideal supplier partners. Meanwhile, in practice, the suppliers' samples are very insufficient. SVMs are adaptive to deal with small samples' training and testing. The prediction accuracies for BPNN and SVM methods are compared to choose the appreciating suppliers. The actual examples illustrate that SVM methods are superior to BPNN.	[Hu Guosheng] Guangdong Vocat Coll Sci & Technol, Sch Management, Guangzhou 510640, Peoples R China; [Hu Guosheng] Anqing Teacher Coll, Sch Comp & Informat, Anqing 246011, Peoples R China; [Zhang Guohong] Guangzhou Univ, Adult Educ Coll, Guangzhou 510405, Peoples R China	Hu, GS (reprint author), Guangdong Vocat Coll Sci & Technol, Sch Management, Guangzhou 510640, Peoples R China.	jamhu8@sohu.com; zhangghong@21cn.com					Cristianini N., 2000, INTRO SUPPORT VECTOR; FISHER L, 1959, J POLIT ECON, V67, P217, DOI 10.1086/258172; Gao Jun, 2003, ARTIFICIAL NEURAL NE; Ge M, 2004, MECH SYST SIGNAL PR, V18, P143, DOI 10.1016/S0888-3270(03)00071-2; Gentry J., 1988, FINANCIAL REV, V23, P269, DOI 10.1111/j.1540-6288.1988.tb01267.x; Hart Peter E., 2001, PATTERN CLASSIFICATI; Hu Guo-sheng, 2006, Systems Engineering and Electronics, V28; JACKSON JD, 1998, J BEHAV EC, V17, P173; Joachims T., 1998, P EUR C MACH LEARN E; Maher J. J., 1997, International Journal of Intelligent Systems in Accounting, Finance and Management, V6, DOI 10.1002/(SICI)1099-1174(199703)6:1<59::AID-ISAF116>3.0.CO;2-H; Moody J., 1995, NEURAL NETWORKS CAPI, P277; Moulin LS, 2004, IEEE T POWER SYST, V19, P818, DOI 10.1109/TPWRS.2004.826018; Platt J. C., 1998, ADV KERNEL METHODS S, P185; Taylor C., 1994, MACHINE LEARNING NEU; Taylor JS, 2004, KERNEL METHODS PATTE; TREVOR H, 2001, ELEMENT STAT LEANING; Van Gestel T, 2001, IEEE T NEURAL NETWOR, V12, P809, DOI 10.1109/72.935093; Vapnik V. N, 1995, NATURE STAT LEARNING; Wu Hong, 2004, Journal of Software, V15; Zhang Hui, 2004, Computer Integrated Manufacturing Systems, V10; Zien A, 2000, BIOINFORMATICS, V16, P799, DOI 10.1093/bioinformatics/16.9.799	21	7	9	SYSTEMS ENGINEERING & ELECTRONICS, EDITORIAL DEPT	BEIJING	PO BOX 142-32, BEIJING, 100854, PEOPLES R CHINA	1004-4132		J SYST ENG ELECTRON	J. Syst. Eng. Electron.	APR	2008	19	2					316	320				5	Automation & Control Systems; Engineering, Electrical & Electronic; Operations Research & Management Science	Automation & Control Systems; Engineering; Operations Research & Management Science	295SO	WOS:000255494400018	
J	Gacitua, R; Sawyer, P; Rayson, P				Gacitua, Ricardo; Sawyer, Pete; Rayson, Paul			A flexible framework to experiment with ontology learning techniques	KNOWLEDGE-BASED SYSTEMS			English	Article; Proceedings Paper	27th SGAI International Conference on Innovative Techniques and Applications of Artificial Intelligence	DEC 10-12, 2007	Cambridge, ENGLAND	British Comp Soc Specialist Grp Artificial Intelligence		Semantic Web; ontologies; ontology learning; NLP methods; machine learning methods	SEMANTIC WEB; MEANINGFUL	Ontology learning refers to extracting conceptual knowledge from several sources and building an ontology from scratch, enriching, or adapting an existing ontology. It uses methods from a diverse spectrum of fields such as natural language processing, artificial intelligence and machine learning. However, a crucial challenging issue is to quantitatively evaluate the usefulness and accuracy of both techniques and combinations of techniques, when applied to ontology learning. It is an interesting problem because there are no published comparative studies. We are developing a flexible framework for ontology learning from text which provides a cyclical process that involves the successive application of various NLP techniques and learning algorithms for concept extraction and ontology modelling. The framework provides support to evaluate the usefulness and accuracy of different techniques and possible combinations of techniques into specific processes, to deal with the above challenge. We show our framework's efficacy as a workbench for testing and evaluating concept identification. Our initial experiment supports our assumption about the usefulness of our approach. Crown copyright (c) 2007 Published by Elsevier B.V. All rights reserved.	[Gacitua, Ricardo; Sawyer, Pete; Rayson, Paul] Univ Lancaster, Dept Comp, Infolab21, Lancaster LA1 4WA, England	Gacitua, R (reprint author), Univ Lancaster, Dept Comp, Infolab21, South Dr, Lancaster LA1 4WA, England.	r.gacitua@lancs.ac.uk; sawyer@lanc-s.ac.uk; p.rayson@lancs.ac.uk	Gacitua, Ricardo/B-6812-2008				Alkula R, 2001, INFORM RETRIEVAL, V4, P195, DOI 10.1023/A:1011942104443; Berners-Lee T, 2001, SCI AM, V284, P34; BLOEHDORN S, 2006, DATA INFORM ANAL KNO, V30; Buitelaar P., 2004, P DEM SESS INT SEM W; BUITELAAR S, 2005, P WORKSH LEARN WEB S; CIMIANO P, 2005, ONTOLOGY LEARNING TE, V123, P59; Cimiano P, 2005, LECT NOTES COMPUT SC, V3513, P227; Craven M, 2000, ARTIF INTELL, V118, P69, DOI 10.1016/S0004-3702(00)00004-7; Cunningham H., 2002, P 40 ANN M ASS COMP; Dean M., 2004, OWL WEB ONTOLOGY LAN; FAURE D, 2000, P OL2000 WORKSH ONT; GARSIDE R, 1987, CLAWS WORD TAGGING S; KIETZ JU, 2000, P WORKSH ONT TEXT CO; MAEDCHE A, 1937, LECT NOTES COMPUTER, P189; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; NOY N, 2000, P EKAW 2000 JUAN LES; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; Rayson P., 2000, P WORKSH COMP CORP 3, P1, DOI 10.3115/1604683.1604686; Rayson P., 2004, P WORKSH NAM ENT REC, P7; Rayson P., 2003, THESIS LANCASTER U; Reinberger M. L., 2004, P ECAI 2004 WORKSH O, P19; Reinberger ML, 2004, LECT NOTES COMPUT SC, V3290, P600; Sabou M, 2005, J WEB SEMANT, V3, P340, DOI 10.1016/j.websem.2005.09.008; VELARDI P, 2005, ONTOLOGY LEARNING TE, V123; YAMAGUCHI Y, 2001, P IJACI 2001 WORKSH, V38	25	14	16	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051		KNOWL-BASED SYST	Knowledge-Based Syst.	APR	2008	21	3					192	199		10.1016/j.knosys.2007.11.009		8	Computer Science, Artificial Intelligence	Computer Science	285XM	WOS:000254809500004	
J	Sugimoto, T; Legaspi, R; Ota, A; Moriyama, K; Kurihara, S; Numao, M				Sugimoto, Toshihito; Legaspi, Roberto; Ota, Akihiro; Moriyama, Koichi; Kurihara, Satoshi; Numao, Masayuki			Modelling affective-based music compositional intelligence with the aid of ANS analyses	KNOWLEDGE-BASED SYSTEMS			English	Article; Proceedings Paper	27th SGAI International Conference on Innovative Techniques and Applications of Artificial Intelligence	DEC 10-12, 2007	Cambridge, ENGLAND	British Comp Soc Specialist Grp Artificial Intelligence		adaptive user interface; EEG-based emotion spectrum analysis; user modelling; automated reasoning; machine learning		This research investigates the use of emotion data derived from analyzing change in activity in the autonomic nervous system (ANS) as revealed by brainwave production to support the creative music compositional intelligence of an adaptive interface. A relational model of the influence of musical events on the listener's affect is first induced using inductive logic programming paradigms with the emotion data and musical score features as inputs of the induction task. The components of composition such as interval and scale, instrumentation, chord progression and melody are automatically combined using genetic algorithm and melodic transformation heuristics that depend on the predictive knowledge and character of the induced model. Out of the four targeted basic emotional states, namely, stress, joy, sadness, and relaxation, the empirical results reported here show that the system is able to successfully compose tunes that convey one of these affective states. (c) 2007 Elsevier B.V. All rights reserved.	[Legaspi, Roberto; Moriyama, Koichi; Kurihara, Satoshi; Numao, Masayuki] Osaka Univ, Inst Sci & Ind Res, Osaka 5670047, Japan; [Ota, Akihiro; Moriyama, Koichi] Osaka Univ, Dept Informat Sci & Tech, Suita, Osaka 5650871, Japan	Legaspi, R (reprint author), Osaka Univ, Inst Sci & Ind Res, 8-1 Mihogaoka, Osaka 5670047, Japan.	roberto@ai.sanken.osaka-u.ac.jp					Bresin R, 2000, COMPUT MUSIC J, V24, P44, DOI 10.1162/014892600559515; de Mantaras RL, 2002, AI MAG, V23, P43; Gabrielsson Alf, 2001, MUSIC EMOTION THEORY, P223; JOHANSON BE, 1998, CSRP9813 U BIRM SCH; Juslin PN, 2001, MUSIC EMOTION THEORY; JUSLIN PN, 2003, P STOCKH MUS AC C, P513; KIM S, 2004, P 17 INT FLAIRS C SP; LEGASPI R, 2006, LECT NOTES ARTIF INT, V4009, P890; LEGASPI R, 2007, P 12 INT C INT US IN, P216, DOI 10.1145/1216295.1216335; LI T., 2003, P INT S MUS INF RETR, P239; Musha T., 1997, Artificial Life and Robotics, V1, DOI 10.1007/BF02471106; NATTEE C, 2004, P 21 INT C MACH LEAR, P77; NUMAO M, 2002, P 18 NAT C AI, P193; Picard R. W., 1997, PERSONAL TECHNOLOGIE, V1, P231, DOI 10.1007/BF01682026; Posner J, 2005, DEV PSYCHOPATHOL, V17, P715, DOI 10.1017/S0954579405050340; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; RIECKEN D, 1998, P IEEE INT C SYST MA, P1119; ROSENBOOM D, 1990, LEONARDO MONOGRAPH S, V1; ROZ C, 2001, LECT GIV C 27 MARCH; Sloboda J. A., 1991, PSYCHOL MUSIC, V19, P110, DOI 10.1177/0305735691192002; TANGKITVANICH S, 1992, MACHINE LEARNING /, P436; UNEHARA M, 2003, P IEEE INT C SYST MA, P980; UNEHARA M, 2004, P IEEE INT C SYST MA, P5736; WIGGINS GA, 1999, INT J COMPUTING ANTI, V1	24	7	7	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051		KNOWL-BASED SYST	Knowledge-Based Syst.	APR	2008	21	3					200	208		10.1016/j.knosys.2007.11.010		9	Computer Science, Artificial Intelligence	Computer Science	285XM	WOS:000254809500005	
J	Haggett, SJ; Chu, DF; Marshall, IW				Haggett, Simon J.; Chu, Dominique F.; Marshall, Ian W.			Evolving a dynamic predictive coding mechanism for novelty detection	KNOWLEDGE-BASED SYSTEMS			English	Article; Proceedings Paper	27th SGAI International Conference on Innovative Techniques and Applications of Artificial Intelligence	DEC 10-12, 2007	Cambridge, ENGLAND	British Comp Soc Specialist Grp Artificial Intelligence		novelty detection; neural networks; neuroevolution; evolutionary algorithms	NETWORK	Novelty detection is a machine learning technique which identifies new or unknown information in data sets. We present our current work on the construction of a new novelty detector based on a dynamical version of predictive coding. We compare three evolutionary algorithms, a simple genetic algorithm, NEAT and FS-NEAT, for the task of optimising the structure of an illustrative dynamic predictive coding neural network to improve its performance over stimuli from a number of artificially generated visual environments. We find that NEAT performs more reliably than the other two algorithms in this task and evolves the network with the highest fitness. However, both NEAT and FS-NEAT fail to evolve a network with a significantly higher fitness than the best network evolved by the simple genetic algorithm. The best network evolved demonstrates a more consistent performance over a broader range of inputs than the original network. We also examine the robustness of this network to noise and find that it handles low levels reasonably well, but is outperformed by the illustrative network when the level of noise is increased. (c) 2007 Elsevier B.V. All rights reserved.	[Haggett, Simon J.; Chu, Dominique F.] Univ Kent, Comp Lab, Canterbury CT2 7NF, Kent, England; [Marshall, Ian W.] Univ Lancaster, Lancaster Environm Ctr, Lancaster LA1 4YQ, England	Haggett, SJ (reprint author), Univ Kent, Comp Lab, Canterbury CT2 7NF, Kent, England.	simon.haggett@acm.org; D.F.Chu@kent.ac.uk; I.W.Marshall@lancaster.ac.uk					Hosoya T, 2005, NATURE, V436, P71, DOI 10.1038/nature03689; Jiang J, 1999, SIGNAL PROCESS-IMAGE, V14, P737, DOI 10.1016/S0923-5965(98)00041-1; Markou M, 2003, SIGNAL PROCESS, V83, P2481, DOI [10.1016/j.sigpro.2003.07.018, 10.1016/j.sigpro.2003.018]; Markou M, 2003, SIGNAL PROCESS, V83, P2499, DOI 10.1016/j.sigpro.2003.07.019; Marsland S, 2005, ROBOT AUTON SYST, V51, P191, DOI 10.1016/j.robot.2004.10.006; Marsland S, 2002, NEURAL NETWORKS, V15, P1041, DOI 10.1016/S0893-6080(02)00078-3; MARSLAND S, 2000, P SIM AD BEH; Mitchell M, 1999, INTRO GENETIC ALGORI; Mitchell T, 1997, MACHINE LEARNING; Stanley K.O., 2004, THESIS U TEXAS AUSTI; STIRLING P, 1990, SYNAPTIC ORG BRAIN, P170; WHITESON S, 2005, P GEN EV COMP	12	2	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051		KNOWL-BASED SYST	Knowledge-Based Syst.	APR	2008	21	3					217	224		10.1016/j.knosys.2007.11.007		8	Computer Science, Artificial Intelligence	Computer Science	285XM	WOS:000254809500007	
J	Bridewell, W; Langley, P; Todorovski, L; Dzeroski, S				Bridewell, Will; Langley, Pat; Todorovski, Ljupco; Dzeroski, Saso			Inductive process modeling	MACHINE LEARNING			English	Article						scientific discovery; process models; compositional modeling; system identification; ecosystem modeling	PHYTOPLANKTON; IRON; SUBROUTINES; DISCOVERY; OCEAN	In this paper, we pose a novel research problem for machine learning that involves constructing a process model from continuous data. We claim that casting learned knowledge in terms of processes with associated equations is desirable for scientific and engineering domains, where such notations are commonly used. We also argue that existing induction methods are not well suited to this task, although some techniques hold partial solutions. In response, we describe an approach to learning process models from time-series data and illustrate its behavior in three domains. In closing, we describe open issues in process model induction and encourage other researchers to tackle this important problem.	[Bridewell, Will; Langley, Pat] Stanford Univ, Ctr Study Language & Informat, Comp Learning Lab, Stanford, CA 94305 USA; [Todorovski, Ljupco; Dzeroski, Saso] Jozef Stefan Inst, Dept Knowledge Technol, Ljubljana 1000, Slovenia	Bridewell, W (reprint author), Stanford Univ, Ctr Study Language & Informat, Comp Learning Lab, Stanford, CA 94305 USA.	willb@csli.stanford.edu	Bridewell, Will/A-2520-2009				Arrigo KR, 2003, J GEOPHYS RES-OCEANS, V108, DOI 10.1029/2001JC000856; Asgharbeygi N, 2006, ECOL MODEL, V194, P70, DOI 10.1016/j.ecolmodel.2005.10.008; ASTROM KJ, 1971, AUTOMATICA, V7, P123; Bay SD, 2002, J BIOMED INFORM, V35, P289, DOI 10.1016/S1532-0464(03)00031-5; Bechtel William, 2005, Stud Hist Philos Biol Biomed Sci, V36, P421, DOI 10.1016/j.shpsc.2005.03.010; BERRYMAN AA, 1992, ECOLOGY, V73, P1530, DOI 10.2307/1940005; Box G.E.P., 1994, TIME SERIES ANAL; Bradley E, 2001, ARTIF INTELL, V133, P139, DOI 10.1016/S0004-3702(01)00143-6; Bridewell W, 2006, INT J HUM-COMPUT ST, V64, P1099, DOI 10.1016/j.ijhcs.2006.06.006; BUNCH DS, 1993, ACM T MATH SOFTWARE, V19, P109, DOI 10.1145/151271.151279; Cohen S. D., 1996, Computers in Physics, V10; DENNIS JE, 1981, ACM T MATH SOFTWARE, V7, P348, DOI 10.1145/355958.355965; DIETTERICH TG, 1990, MACH LEARN, V5, P5, DOI 10.1023/A:1022655507603; Domingos P., 1997, P 14 INT C MACH LEAR, P98; Dzeroski S., 1993, P 10 INT C MACH LEAR, P97; Efron B., 1993, INTRO BOOTSTRAP; FORBUS KD, 1984, ARTIF INTELL, V24, P85, DOI 10.1016/0004-3702(84)90038-9; FORBUS KD, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P380; GARRETT S, 2007, COMPUTATIONAL DISCOV; GAY DM, 1983, ACM T MATH SOFTWARE, V9, P503, DOI 10.1145/356056.356066; Ghahramani Z, 1998, ADAPTIVE PROCESSING; Ghosh R., 2001, P 4 INT WORKSH HYBR, P232; Glennan S, 2002, PHILOS SCI, V69, pS342, DOI 10.1086/341857; Glymour C., 1987, DISCOVERING CAUSAL S; Hardle W, 2003, INT STAT REV, V71, P435; Hempel C., 1948, PHILOS SCI, V15, P135, DOI 10.1086/286983; HOLLING C. S., 1959, CANADIAN ENT, V91, P293; IWASAKI Y, 1994, ARTIF INTELL, V67, P143, DOI 10.1016/0004-3702(94)90014-0; Jost C, 2000, P ROY SOC B-BIOL SCI, V267, P1611; Langley P., 1987, SCI DISCOVERY COMPUT; LANGLEY P, 1981, COGNITIVE SCI, V5, P31, DOI 10.1016/S0364-0213(81)80025-0; Lavrac N., 1994, INDUCTIVE LOGIC PROG; Machamer P, 2000, PHILOS SCI, V67, P1, DOI 10.1086/392759; MARTIN JH, 1991, LIMNOL OCEANOGR, V36, P1793; Murray J. D., 2004, MATH BIOL; Needoba JA, 2004, J PHYCOL, V40, P505, DOI 10.1111/j.1529-8817.2004.03171.x; Olson RJ, 2000, DEEP-SEA RES PT II, V47, P3181, DOI 10.1016/S0967-0645(00)00064-3; OURSTON D, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P815; Pazzani MJ, 2001, METHOD INFORM MED, V40, P380; PORITZ AB, 1988, P IEEE INT C AC SPEE, P7; Schwabacher M., 2001, P 18 INT C MACH LEAR, P489; SIMON HA, 1954, J AM STAT ASSOC, V49, P467, DOI 10.2307/2281124; Todorovski L., 1997, P 14 INT C MACH LEAR, P376; TODOROVSKI L, 2003, THESIS U LJUBLJANA L; VEILLEUX BG, 1979, J ANIM ECOL, V48, P787, DOI 10.2307/4195; Washio T., 2000, P 17 INT C MACH LEAR, P1127; Williams R. J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.270; Woodward J, 2002, PHILOS SCI, V69, pS366, DOI 10.1086/341859; Zheng J, 2001, J GEN PHYSIOL, V118, P547, DOI 10.1085/jgp.118.5.547; ZYTKOW JM, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P889	50	11	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	APR	2008	71	1					1	32		10.1007/s10994-007-5042-6		32	Computer Science, Artificial Intelligence	Computer Science	265QI	WOS:000253375600001	
J	Teh, CS; Lim, CP				Teh, Chee Siong; Lim, Chee Peng			An artificial neural network classifier design based-on variable kernel and non-parametric density estimation	NEURAL PROCESSING LETTERS			English	Article						pattern classification; variable kernel; density estimation; topographic map	MAPS	This paper proposes a probabilistic variant of the SOM-kMER (Self Organising Map-kernel-based Maximum Entropy learning Rule) model for data classification. The classifier, known as pSOM-kMER (probabilistic SOM-kMER), is able to operate in a probabilistic environment and to implement the principles of statistical decision theory in undertaking classification problems. A distinctive feature of pSOM-kMER is its ability in revealing the underlying structure of data. In addition, the Receptive Field (RF) regions generated can be used for variable kernel and non-parametric density estimation. Empirical evaluation using benchmark datasets shows that pSOM-kMER is able to achieve good performance as compared with those from a number of machine learning systems. The applicability of the proposed model as a useful data classifier is also demonstrated with a real-world medical data classification problem.	[Teh, Chee Siong] Univ Malaysia Sarawak, Fac Cognit Sci & Human Dev, Kota Samarahan 94300, Sarawak, Malaysia; [Lim, Chee Peng] Univ Sci Malaysia, Sch Elect & Elect Engn, Nibong Tebal 14300, Penang, Malaysia	Teh, CS (reprint author), Univ Malaysia Sarawak, Fac Cognit Sci & Human Dev, Kota Samarahan 94300, Sarawak, Malaysia.	csteh@fcs.unimas.my	Teh, Chee Siong/F-5212-2010				Bishop C.M., 1995, NEURAL NETWORKS PATT; Breiman L, 1984, CLASSIFICATION REGRE; CARPENTER GA, 1992, IEEE T NEURAL NETWOR, V3, P698, DOI 10.1109/72.159059; Devroye L., 1996, PROBABILISTIC THEORY; Duda R., 2000, PATTERN CLASSIFICATI; DUIN RPW, 1994, PATTERN RECOGN LETT, V15, P215, DOI 10.1016/0167-8655(94)90052-3; FLORES JO, 2004, LIVER FUNCTION T JUN; Girolami M, 2003, IEEE T PATTERN ANAL, V25, P1253, DOI 10.1109/TPAMI.2003.1233899; HOLMSTROM L, 1993, IEEE INT C NEUR NETW, V1, P417; Hoti F, 2004, PATTERN RECOGN, V37, P409, DOI 10.1016/j.patcog.2003.08.004; IZENMAN AJ, 1991, J AM STAT ASSOC, V86, P205, DOI 10.2307/2289732; Jain A.K., 2000, IEEE T PATTERN ANAL, V2, P4; JEON BW, 1994, IEEE T PATTERN ANAL, V16, P950; Kohonen T, 2002, NEURAL NETWORKS, V15, P945, DOI 10.1016/S0893-6080(02)00069-2; KOHONEN T, 1988, NEURAL NETWORKS, V1, P303; Lim CP, 1997, NEURAL NETWORKS, V10, P925, DOI 10.1016/S0893-6080(96)00123-2; MEIER F, 2002, LIVER FUNCTION T JUN; MINNOTTE MC, 1992, THESIS RICE U; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P734, DOI 10.1109/TPAMI.2002.1008381; Murphy P.M., 1995, UCI REPOSITORY MACHI; MUSAVI MT, 1993, NEURAL NETWORKS, V6, P397, DOI 10.1016/0893-6080(93)90007-J; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; SCOTT DW, 1992, PROBABILITY MATH STA; SCOTT DW, 1985, COMMUN STAT-THEOR M, V14, P1353, DOI 10.1080/03610928508828980; Silverman B.W., 1986, DENSITY ESTIMATION S; Specht D. F., 1988, P IEEE INT C NEURAL, V1, P525; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Teh CS, 2006, IEEE T NEURAL NETWOR, V17, P1336, DOI 10.1109/TNN.2006.877536; Van Hulle M., 2000, FAITHFUL REPRESENTAT; WERBOS PJ, 1991, ARTIFICIAL NEURAL NE, P11; WONG OL, 1996, DISTRIBUTION C REACT; YAIR E, 1990, NEURAL NETWORKS, V3, P203, DOI 10.1016/0893-6080(90)90090-8	32	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1370-4621		NEURAL PROCESS LETT	Neural Process. Lett.	APR	2008	27	2					137	151		10.1007/s11063-007-9065-6		15	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	267SI	WOS:000253529100004	
J	Davatzikos, C; Fan, Y; Wu, X; Shen, D; Resnick, SM				Davatzikos, Christos; Fan, Yong; Wu, Xiaoying; Shen, Dinggang; Resnick, Susan M.			Detection of prodromal Alzheimer's disease via pattern classification of magnetic resonance imaging	NEUROBIOLOGY OF AGING			English	Article						prodromal Alzheimer's disease; MCI; pattern recognition; MRI	MILD COGNITIVE IMPAIRMENT; MACHINE LEARNING-METHODS; VOXEL-BASED MORPHOMETRY; GRAY-MATTER LOSS; HIPPOCAMPAL-FORMATION; ENTORHINAL CORTEX; TEMPORAL-LOBE; OLDER-ADULTS; MRI; ATROPHY	We report evidence that computer-based high-dimensional pattern classification of magnetic resonance imaging (MRI) detects patterns of brain structure characterizing mild cognitive impairment (MCI), often a prodromal phase of Alzheimer's disease (AD). Ninety percent diagnostic accuracy was achieved, using cross-validation, for 30 participants in the Baltimore Longitudinal Study of Aging. Retrospective evaluation of serial scans obtained during prior years revealed gradual increases in structural abnormality for the MCI group, often before clinical symptoms, but slower increase for individuals remaining cognitively normal. Detecting complex patterns of brain abnormality in very early stages of cognitive impairment has pivotal importance for the detection and management of AD. (C) 2006 Elsevier Inc. All rights reserved.	[Davatzikos, Christos; Fan, Yong; Wu, Xiaoying; Shen, Dinggang] Univ Penn, Dept Radiol, Sect Biomed Image Anal, Philadelphia, PA 19104 USA; [Resnick, Susan M.] NIA, Lab Personal & Cognit, Bethesda, MD 20892 USA	Davatzikos, C (reprint author), Univ Penn, Dept Radiol, Sect Biomed Image Anal, 3600 Market St,Suite 380, Philadelphia, PA 19104 USA.	christos@rad.upenn.edu					Ashburner J, 2003, LANCET NEUROL, V2, P79, DOI 10.1016/S1474-4422(03)00304-1; Bobinski M, 1999, LANCET, V353, P38, DOI 10.1016/S0140-6736(05)74869-8; Bookstein FL, 2001, NEUROIMAGE, V14, P1454, DOI 10.1006/nimg.2001.0770; Braak H, 1998, J NEURAL TRANSM-SUPP, P97; Chetelat G, 2002, NEUROREPORT, V13, P1939; Chetelat G, 2003, NEUROIMAGE, V18, P525, DOI 10.1016/S1053-8119(02)00026-5; Convit A, 2000, NEUROBIOL AGING, V21, P19, DOI 10.1016/S0197-4580(99)00107-4; Convit A, 1997, NEUROBIOL AGING, V18, P131, DOI 10.1016/S0197-4580(97)00001-8; CUENOD CA, 1993, ARCH NEUROL-CHICAGO, V50, P941; Davatzikos C, 2005, NEUROIMAGE, V28, P663, DOI 10.1016/j.neuroimage.2005.08.009; Davatzikos C, 2005, ARCH GEN PSYCHIAT, V62, P1218, DOI 10.1001/archpsyc.62.11.1218; DELEON MJ, 1991, NEUROBIOL AGING, V18, P1; De Santi S, 2001, NEUROBIOL AGING, V22, P529, DOI 10.1016/S0197-4580(01)00230-5; DetoledoMorrell L, 1997, NEUROBIOL AGING, V18, P463, DOI 10.1016/S0197-4580(97)00114-0; Dickerson BC, 2001, NEUROBIOL AGING, V22, P747, DOI 10.1016/S0197-4580(01)00271-8; Du AT, 2001, J NEUROL NEUROSUR PS, V71, P441, DOI 10.1136/jnnp.71.4.441; Fan Y, 2005, LECT NOTES COMPUTER, P1; Frisoni GB, 2006, NEUROIMAGE, V32, P104, DOI 10.1016/j.neuroimage.2006.03.015; Frisoni GB, 1996, AM J NEURORADIOL, V17, P913; Goldszal AF, 1998, J COMPUT ASSIST TOMO, V22, P827, DOI 10.1097/00004728-199809000-00030; GOLLAND P, 2002, DISCRIMINATIVE ANAL, P508; GOLOMB J, 1993, ARCH NEUROL-CHICAGO, V50, P967; Grundman M, 2004, ARCH NEUROL-CHICAGO, V61, P59, DOI 10.1001/archneur.61.1.59; HYMAN BT, 1984, SCIENCE, V225, P1168, DOI 10.1126/science.6474172; Jack CR, 1999, NEUROLOGY, V52, P1397; Jack CR, 1997, NEUROLOGY, V49, P786; Karas GB, 2004, NEUROIMAGE, V23, P708, DOI 10.1016/j.neuroimage.2004.07.006; Kaye JA, 1997, NEUROLOGY, V48, P1297; Killiany RJ, 2000, ANN NEUROL, V47, P430, DOI 10.1002/1531-8249(200004)47:4<430::AID-ANA5>3.0.CO;2-I; KILLIANY RJ, 1993, ARCH NEUROL-CHICAGO, V50, P949; Krasuski JS, 1998, BIOL PSYCHIAT, V43, P60, DOI 10.1016/S0006-3223(97)00013-9; Laakso MP, 2000, NEUROPSYCHOLOGIA, V38, P579, DOI 10.1016/S0028-3932(99)00111-6; LAAKSO MP, 1995, J NEURAL TRANSM-PARK, V9, P73, DOI 10.1007/BF02252964; Lao ZQ, 2004, NEUROIMAGE, V21, P46, DOI 10.1016/j.neuroimage.2003.09.027; LEHERICY S, 1994, AM J NEURORADIOL, V15, P929; LIU Y, 2004, DISCRIMINATIVE MR IM, P393; Medina D, 2006, NEUROBIOL AGING, V27, P663, DOI 10.1016/j.neurobiolaging.2005.03.026; MIRRA S, 2001, NEUROLOGY, V41, P479; MORRIS JC, 1989, NEUROLOGY, V39, P1159; Nestor PJ, 2004, NAT MED, V10, pS34, DOI 10.1038/nm1433; Petersen RC, 2003, MILD COGNITIVE IMPAI; Resnick SM, 2000, CEREB CORTEX, V10, P464, DOI 10.1093/cercor/10.5.464; Rosen AC, 2003, BEHAV NEUROSCI, V117, P1150, DOI 10.1037/0735-7044.117.6.1150; Shen DG, 2003, NEUROIMAGE, V18, P28, DOI 10.1006/nimg.2002.1301; Stoub TR, 2005, NEUROLOGY, V64, P1520, DOI 10.1212/01.WNL.0000160089.43264.1A; Vapnik VN, 2006, STAT LEARNING THEORY; Wang L, 2006, NEUROIMAGE, V30, P52, DOI 10.1016/j.neuroimage.2005.09.017; West MJ, 2004, NEUROBIOL AGING, V25, P1205, DOI 10.1016/j.neurobiolaging.2003.12.005; Xu Y, 2000, NEUROLOGY, V54, P1760	49	99	101	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0197-4580		NEUROBIOL AGING	Neurobiol. Aging	APR	2008	29	4					514	523		10.1016/j.neurobiolaging.2006.11.010		10	Geriatrics & Gerontology; Neurosciences	Geriatrics & Gerontology; Neurosciences & Neurology	275MV	WOS:000254077200003	
J	Hou, CP; Wu, Y; Yi, DY; Jiao, YY				Hou, Chenping; Wu, Yi; Yi, Dongyun; Jiao, Yuanyuan			Novel semisupervised high-dimensional correspondences learning method	OPTICAL ENGINEERING			English	Article						correspondence; manifold learning; locally linear embedding; maximum variance unfolding	LAPLACIAN EIGENMAPS; REDUCTION; MANIFOLDS; IMAGES	Correspondence is one of the big challenges in machine learning and image processing. To match two high-dimensional data sets with a certain number of aligned training examples, a novel semisupervised method is proposed. It is mainly based on two manifold learning approaches: maximum variance unfolding (MVU) and locally linear embedding (LLE). We have modified MVU to a semi-supervised version to solve the correspondence problem. Additionally, the nonuniform warps and folds caused by employing LLE alone and the computational burden of MVU disappear when they are combined. The proposed algorithm outperforms traditional methods in accuracy and efficiency. Three examples are performed to demonstrate the potential of this method. (C) 2008 Society of Photo-Optical Instrumentation Engineers.	[Hou, Chenping; Wu, Yi; Yi, Dongyun; Jiao, Yuanyuan] Natl Univ Def Technol, Dept Syst Sci & Math, Coll Sci, Changsha 410073, Peoples R China	Hou, CP (reprint author), Natl Univ Def Technol, Dept Syst Sci & Math, Coll Sci, Changsha 410073, Peoples R China.						Belhumeur PN, 1998, INT J COMPUT VISION, V28, P245, DOI 10.1023/A:1008005721484; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Belkin M, 2002, ADV NEUR IN, V14, P585; Borchers B, 1999, OPTIM METHOD SOFTW, V11-2, P613, DOI 10.1080/10556789908805765; HAM JH, 2006, P IEE COMP VIS PATT, V1, P817; HAM JH, 2003, P 20 INT C MACH LEAR, P34; HAM JH, 2005, P ANN C UNC ART INT, V1, P120; Hinton GE, 1997, IEEE T NEURAL NETWOR, V8, P65, DOI 10.1109/72.554192; HOU CP, 2007, P IEEE INT C MECH AU, P635; MEHTA B, 2006, P 21 NAT C ART INT B; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Saul LK., 2003, J MACHINE LEARNING R, V4, P119; Seung HS, 2000, SCIENCE, V290, P2268, DOI 10.1126/science.290.5500.2268; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Weinberger K., 2005, P 10 INT WORKSH ART, P381; Weinberger K.Q., 2004, P 21 INT C MACH LEAR, P839; Weinberger K.Q., 2004, P IEEE C COMP VIS PA, P988, DOI 10.1109/CVPR.2004.1315272; Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154; EARTH DATABASE; TEAPOT DATABASE	20	1	1	SPIE-SOC PHOTOPTICAL INSTRUMENTATION ENGINEERS	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA	0091-3286		OPT ENG	Opt. Eng.	APR	2008	47	4							047201	10.1117/1.2903093		10	Optics	Optics	306IT	WOS:000256242200042	
J	Heumer, G; Ben Amor, H; Jung, B				Heumer, Guido; Ben Amor, Heni; Jung, Bernhard			Grasp recognition for uncalibrated data gloves: A machine learning approach	PRESENCE-TELEOPERATORS AND VIRTUAL ENVIRONMENTS			English	Article; Proceedings Paper	IEEE Virtual Reality 2007 Conference	MAR 10-14, 2007	Charlotte, NC	IEEE VGTC, IEEE Comp Soc				This paper presents a comparison of various machine learning methods applied to the problem of recognizing grasp types involved in object manipulations performed with a data glove. Conventional wisdom holds that data gloves need calibration in order to obtain accurate results. However, calibration is a time-consuming process, inherently user-specific, and its results are often not perfect. In contrast, the present study aims at evaluating recognition methods that do not require prior calibration of the data glove. Instead, raw sensor readings are used as input features that are directly mapped to different categories of hand shapes. An experiment was carried out in which test persons wearing a data glove had to grasp physical objects of different shapes corresponding to the various grasp types of the Schlesinger taxonomy. The collected data was comprehensively analyzed using numerous classification techniques provided in an open-source machine learning toolbox. Evaluated machine learning methods are composed of (a) 38 classifiers including different types of function learners, decision trees, rule-based learners, Bayes nets, and lazy learners; (b) data preprocessing using principal component analysis (PCA) with varying degrees of dimensionality reduction; and (c) five meta-learning algorithms under various configurations where selection of suitable base classifier combinations was informed by the results of the foregoing classifier evaluation. Classification performance was analyzed in six different settings, representing various application scenarios with differing generalization demands. The results of this work are twofold: (1) We show that a reasonably good to highly reliable recognition of grasp types can be achieved-depending on whether or not the glove user is among those training the classifier-even with uncalibrated data gloves. (2) We identify the best performing classification methods for the recognition of various grasp types. To conclude, cumbersome calibration processes before productive usage of data gloves can be spared in many situations.		Heumer, G (reprint author), TU Bergakad Freiberg, VR & Multimedia Grp, Inst Informat, Bernhard Von Cotta Str 2, D-09599 Freiberg, Germany.	guido.heumer@informatik.tu-freiberg.ie					Aleotti J, 2006, IEEE INT CONF ROBOT, P2801; Bishop C. M., 2006, PATTERN RECOGNITION; Bishop C.M., 1995, NEURAL NETWORKS PATT; BONTEMPI G, 2002, NEW LEARNING PARADIG, P97; BORST CW, 2005, VR 05 P 2005 IEEE C, P91; BOWDEN R., 2000, IEEE WORKSH HUM MOD; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Chan P. K., 1997, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V8, DOI 10.1023/A:1008640732416; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; Cristianini N., 2000, INTRO SUPPORT VECTOR; CUTKOSKY MR, 1989, IEEE T ROBOTIC AUTOM, V5, P269, DOI 10.1109/70.34763; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Ekvall S, 2005, IEEE INT CONF ROBOT, P748; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; FRIEDRICH H, 1999, IASTED INT C INT SYS, P121; Haykin S., 1994, NEURAL NETWORKS COMP; HEUMER G, 2007, P IEEE VIRT REAL C, P19; Jung B., 2006, P VRST 2006 13 ACM S, P145, DOI 10.1145/1180495.1180526; Kahlesz F, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P403; KASKI S, 1997, COMPUTING MANAGEMENT, V82; Lima A, 2005, IEICE T INF SYST, VE88D, P401, DOI 10.1093/ietisy/e88-d.3.401; NAPIER JR, 1956, J BONE JOINT SURG BR, V38, P902; POLIKAR I, 2006, 1EEE CIRCUITS SYSTEM, V6, P21; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan JR, 1987, P 2 AUSTR C APPL EXP, P137; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; RICHARDS D, 2002, DECISION MAKING SUPP, P207; Schlesinger G., 1919, ERSATZGLIEDER ARBEIT, P321; TAYLOR C L, 1955, Artif Limbs, V2, P22; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), DOI 10.1109/CVPR.1991.139758; Witten H. I., 2005, DATA MINING PRACTICA; Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585893; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; ZACHMANN G, 2001, 8 ISPE INT C CONC EN, P425	36	4	4	MIT PRESS	CAMBRIDGE	55 HAYWARD STREET, CAMBRIDGE, MA 02142 USA	1054-7460		PRESENCE-TELEOP VIRT	Presence-Teleoper. Virtual Env.	APR	2008	17	2					121	142		10.1162/pres.17.2.121		22	Computer Science, Cybernetics; Computer Science, Software Engineering	Computer Science	284XN	WOS:000254741300003	
J	Jakel, F; Scholkopf, B; Wichmann, FA				Jaekel, Frank; Schoelkopf, Bernhard; Wichmann, Felix A.			Generalization and similarity in exemplar models of categorization: Insights from machine learning	PSYCHONOMIC BULLETIN & REVIEW			English	Article							DECISION BOUND MODELS; OBJECT RECOGNITION; STIMULUS-GENERALIZATION; RESPONSE GENERALIZATION; VISUAL CATEGORIZATION; SELECTIVE ATTENTION; TEMPORAL CORTEX; KERNEL METHODS; UNIVERSAL LAW; CLASSIFICATION	Exemplar theories of categorization depend on similarity for explaining subjects' ability to generalize to new stimuli. A major criticism of exemplar theories concerns their lack of abstraction mechanisms and thus, seemingly, of generalization ability Here, we use insights from machine learning to demonstrate that exemplar models can actually generalize very well. Kernel methods in machine learning are akin to exemplar models and are very successful in real-world applications. Their generalization performance depends crucially on the chosen similarity measure. Although similarity plays an important role in describing generalization behavior, it is not the only factor that controls generalization performance. In machine learning, kernel methods are often combined with regularization techniques in order to ensure good generalization. These same techniques are easily incorporated in exemplar models. We show that the generalized context model (Nosofsky, 1986) and ALCOVE (Kruschke, 1992) are closely related to a statistical model called kernel logistic regression. We argue that generalization is central to the enterprise of understanding categorization behavior, and we suggest some ways in which insights from machine learning can offer guidance.	[Jaekel, Frank; Wichmann, Felix A.] Tech Univ Berlin, Fac 4, D-10587 Berlin, Germany; [Jaekel, Frank; Wichmann, Felix A.] Bernstein Ctr Computat Neurosci, Berlin, Germany; [Schoelkopf, Bernhard] Max Planck Inst Biol Cybernet, Tubingen, Germany	Jakel, F (reprint author), Tech Univ Berlin, Fac 4, Sekr 6-4,Franklinstr 28-29, D-10587 Berlin, Germany.	fjaekel@cs.tu-berlin.de	Scholkopf, Bernhard/A-7570-2013				AIZERMAN MA, 1964, AUTOMAT REM CONTR, V25, P1175; Alfonso-Reese LA, 2002, PERCEPT PSYCHOPHYS, V64, P570, DOI 10.3758/BF03194727; ASHBY FG, 1993, J MATH PSYCHOL, V37, P372, DOI 10.1006/jmps.1993.1023; ASHBY FG, 1988, J EXP PSYCHOL LEARN, V14, P33, DOI 10.1037//0278-7393.14.1.33; ASHBY FG, 1992, J EXP PSYCHOL HUMAN, V18, P50, DOI 10.1037//0096-1523.18.1.50; Ashby FG, 2001, J EXP PSYCHOL GEN, V130, P77, DOI 10.1037//0096-3445.130.1.77; ASHBY FG, 1995, J MATH PSYCHOL, V39, P216, DOI 10.1006/jmps.1995.1021; BEALS R, 1968, PSYCHOL REV, V75, P127, DOI 10.1037/h0025470; Bishop C.M., 1995, NEURAL NETWORKS PATT; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; BRADLEY RA, 1976, BIOMETRICS, V32, P213, DOI 10.2307/2529494; BRISCOE E, 2006, P 28 ANN C COGN SCI, P1038; Brown J. S., 1965, STIMULUS GENERALIZAT, P7; BULTHOFF HH, 1992, P NATL ACAD SCI USA, V89, P60, DOI 10.1073/pnas.89.1.60; BUSH RR, 1951, PSYCHOL REV, V58, P413, DOI 10.1037/h0054576; Chater N, 2003, J MATH PSYCHOL, V47, P346, DOI 10.1016/S0022-2496(03)00013-0; Cristianini N, 2002, AI MAG, V23, P31; David H. A., 1988, METHOD PAIRED COMP; DEBEECK HO, 2004, J VISION, V4, pA518; FASS D, 2003, ADV NEURAL INFORM PR, V15, P35; Feldman J, 2000, NATURE, V407, P630, DOI 10.1038/35036586; FRIED LS, 1984, J EXP PSYCHOL LEARN, V10, P234, DOI 10.1037/0278-7393.10.2.234; Garner W. R, 1974, PROCESSING INFORM ST; Ghirlanda S, 2003, ANIM BEHAV, V66, P15, DOI 10.1006/anbe.2003.2174; Graf ABA, 2004, ADV NEUR IN, V16, P905; Graf ABA, 2006, NEURAL COMPUT, V18, P143, DOI 10.1162/089976606774841611; Hastie T, 2001, ELEMENTS STAT LEARNI; Jakel F, 2007, J MATH PSYCHOL, V51, P343, DOI 10.1016/j.jmp.2007.06.002; JAKEL F, 2008, SIMILARITY KER UNPUB; KRUSCHKE JK, 1992, PSYCHOL REV, V99, P22, DOI 10.1037//0033-295X.99.1.22; LAMBERTS K, 1994, J EXP PSYCHOL LEARN, V20, P1003, DOI 10.1037/0278-7393.20.5.1003; LOGOTHETIS NK, 1995, CURR BIOL, V5, P552, DOI 10.1016/S0960-9822(95)00108-4; LOGOTHETIS NK, 1994, CURR BIOL, V4, P401, DOI 10.1016/S0960-9822(00)00089-0; Love BC, 2004, PSYCHOL REV, V111, P309, DOI 10.1037/0033-295X.111.2.309; Luce R. D., 1959, INDIVIDUAL CHOICE BE; Luce RD, 1963, HDB MATH PSYCHOL, V1, P103; LUCE RD, 1977, J MATH PSYCHOL, V15, P215, DOI 10.1016/0022-2496(77)90032-3; McKinley SC, 1996, J EXP PSYCHOL HUMAN, V22, P294, DOI 10.1037/0096-1523.22.2.294; MCKINLEY SC, 1995, J EXP PSYCHOL HUMAN, V21, P128, DOI 10.1037/0096-1523.21.1.128; MEDIN DL, 1993, PSYCHOL REV, V100, P254, DOI 10.1037/0033-295X.100.2.254; MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037//0033-295X.85.3.207; MOSTOFSKY DJ, 1965, STIMULUS GEN; Navarro DJ, 2007, J MATH PSYCHOL, V51, P85, DOI 10.1016/j.jmp.2006.11.003; NAVARRO DJ, 2002, THESIS U ADELAIDE AD; Nosofsky RA, 2002, J EXP PSYCHOL LEARN, V28, P924, DOI 10.1037//0278-7393.28.5.924; Nosofsky R.M., 1992, MULTIDIMENSIONAL MOD, P363; NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39; NOSOFSKY RM, 1999, HUMAN PERCEPTION PER, V17, P3; NOSOFSKY RM, 1987, J EXP PSYCHOL LEARN, V13, P87, DOI 10.1037//0278-7393.13.1.87; NOSOFSKY RM, 1990, J MATH PSYCHOL, V34, P393, DOI 10.1016/0022-2496(90)90020-A; NOSOFSKY RM, 1991, MEM COGNITION, V19, P131, DOI 10.3758/BF03197110; Ohl FW, 2001, NATURE, V412, P733, DOI 10.1038/35089076; Op de Beeck H, 2001, NAT NEUROSCI, V4, P1244, DOI 10.1038/nn767; Orr G., 1998, NEURAL NETWORKS TRIC; Palmeri TJ, 2004, NAT REV NEUROSCI, V5, P291, DOI 10.1038/nrn1364; Pitt MA, 2002, PSYCHOL REV, V109, P472, DOI 10.1037//0033-295X.109.3.472; POGGIO T, 1989, 1140 AI WHIT COLL CT; Poggio T, 2004, NATURE, V431, P768, DOI 10.1038/nature03014; POGGIO T, 1990, COLD SH Q B, V55, P899; Poggio T., 2003, NOTICES AMS, V50, P537; Poggio T, 2004, NATURE, V428, P419, DOI 10.1038/nature02341; POGGIO T, 1990, NATURE, V343, P263, DOI 10.1038/343263a0; POSNER MI, 1968, J EXP PSYCHOL, V77, P353, DOI 10.1037/h0025953; REED SK, 1972, COGNITIVE PSYCHOL, V3, P382, DOI 10.1016/0010-0285(72)90014-X; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; ROSCH E, 1975, COGNITIVE PSYCHOL, V7, P573, DOI 10.1016/0010-0285(75)90024-9; ROSCH E, 1976, COGNITIVE PSYCHOL, V8, P382, DOI 10.1016/0010-0285(76)90013-X; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Rosseel Y, 2002, J MATH PSYCHOL, V46, P178, DOI 10.1006/jmps.2001.1379; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1, P318; Schoenberg IJ, 1938, T AM MATH SOC, V44, P522, DOI 10.2307/1989894; SCHOLKOPE B, 2002, LEARNING KERNALS SUP; SHEPARD RN, 1957, PSYCHOMETRIKA, V22, P325, DOI 10.1007/BF02288967; SHEPARD RN, 1987, SCIENCE, V237, P1317, DOI 10.1126/science.3629243; SHEPARD RN, 1963, J EXP PSYCHOL, V65, P94, DOI 10.1037/h0043732; SHEPARD RN, 1961, PSYCHOL MONOGR, V75, P1; SHEPARD RN, 1965, STIMULUS GEN, P94; SHEPARD RN, 1962, PSYCHOMETRIKA, V27, P125, DOI 10.1007/BF02289630; SHEPARD RN, 1964, J MATH PSYCHOL, V1, P54, DOI 10.1016/0022-2496(64)90017-3; SHEPARD RN, 1958, PSYCHOL REV, V65, P242, DOI 10.1037/h0043083; Sigala N, 2002, J COGNITIVE NEUROSCI, V14, P187, DOI 10.1162/089892902317236830; Sigala N, 2002, NATURE, V415, P318, DOI 10.1038/415318a; Smith JD, 2000, J EXP PSYCHOL LEARN, V26, P3; Smith JD, 1998, J EXP PSYCHOL LEARN, V24, P1411, DOI 10.1037//0278-7393.24.6.1411; Spence KW, 1937, PSYCHOL REV, V44, P430, DOI 10.1037/h0062885; Tenebaum JB, 2001, BEHAV BRAIN SCI, V24, P629; Train K.E., 2003, DISCRETE CHOICE METH; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037//0033-295X.84.4.327; TVERSKY A, 1982, PSYCHOL REV, V89, P123, DOI 10.1037/0033-295X.89.2.123; Vapnik V. N., 2000, NATURE STAT LEARNING; Verguts T, 2004, MEM COGNITION, V32, P379, DOI 10.3758/BF03195832; Wichmann F. A., 2005, ADV NEURAL INFORM PR, V17, P1489	92	5	6	PSYCHONOMIC SOC INC	AUSTIN	1710 FORTVIEW RD, AUSTIN, TX 78704 USA	1069-9384		PSYCHON B REV	Psychon. Bull. Rev.	APR	2008	15	2					256	271		10.3758/PBR.15.2.256		16	Psychology, Mathematical; Psychology, Experimental	Psychology	320EY	WOS:000257217700002	
J	Qahwaji, R; Colak, T; Al-Omari, M; Ipson, S				Qahwaji, R.; Colak, T.; Al-Omari, M.; Ipson, S.			Automated prediction of CMEs using machine learning of CME - Flare associations	SOLAR PHYSICS			English	Article; Proceedings Paper	3rd Solar Image Processing Workshop	SEP, 2006	Dublin, ISRAEL		Trinity Coll	CMEs prediction; machine learning; solar flares; space weather; CME; neural networks; support vector machines	SUPPORT VECTOR MACHINES; NEURAL-NETWORKS; RECOGNITION	Machine-learning algorithms are applied to explore the relation between significant flares and their associated CMEs. The NGDC flares catalogue and the SOHO/LASCO CME catalogue are processed to associate X and M-class flares with CMEs based on timing information. Automated systems are created to process and associate years of flare and CME data, which are later arranged in numerical-training vectors and fed to machine-learning algorithms to extract the embedded knowledge and provide learning rules that can be used for the automated prediction of CMEs. Properties representing the intensity, flare duration, and duration of decline and duration of growth are extracted from all the associated (A) and not-associated (NA) flares and converted to a numerical format that is suitable for machine-learning use. The machine-learning algorithms Cascade Correlation Neural Networks (CCNN) and Support Vector Machines (SVM) are used and compared in our work. The machine-learning systems predict, from the input of a flare's properties, if the flare is likely to initiate a CME. Intensive experiments using Jack-knife techniques are carried out and the relationships between flare properties and CMEs are investigated using the results. The predictive performance of SVM and CCNN is analysed and recommendations for enhancing the performance are provided.	[Qahwaji, R.; Colak, T.; Al-Omari, M.; Ipson, S.] Univ Bradford, Dept Elect Imaging & Media Commun, Bradford BD7 1DP, W Yorkshire, England	Qahwaji, R (reprint author), Univ Bradford, Dept Elect Imaging & Media Commun, Richmond Rd, Bradford BD7 1DP, W Yorkshire, England.	r.s.r.qahwaji@brad.ac.uk					Acir N, 2004, EXPERT SYST APPL, V27, P451, DOI 10.1016/j.eswa.2004.05.007; Borda RAF, 2002, SOL PHYS, V206, P347; Cliver EW, 2002, J ATMOS SOL-TERR PHY, V64, P231, DOI 10.1016/S1364-6826(01)00086-4; Colak T, 2007, ADV SOFT COMP, V39, P316; Distante C, 2003, SENSOR ACTUAT B-CHEM, V88, P30, DOI 10.1016/S0925-4005(02)00306-4; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Fukunaga K., 1990, INTRO STAT PATTERN R; GOSLING JT, 1995, J GEOPHYS RES, V100, P7921, DOI 10.1029/94JA03032; Huang Z, 2004, DECIS SUPPORT SYST, V37, P543, DOI 10.1016/S0167-9236(03)00086-1; Koskinen H, 2001, SPACE WEATHER EFFECT; KUROKAWA H, 2002, COMMUN RES, V49, P49; LENZ D, 2004, IND PHYS, V9, P18; LIN RP, 1976, SOL PHYS, V50, P153; Pal M, 2004, FUTURE GENER COMP SY, V20, P1215, DOI 10.1016/j.future.2003.11.011; Qahwaji R, 2007, SOL PHYS, V241, P195, DOI 10.1007/s11207-006-0272-5; QAHWAJI R, 2006, COMPUT APPL, V13, P9; Qu M, 2003, SOL PHYS, V217, P157, DOI 10.1023/A:1027388729489; Tousey R., 1973, SPACE RES, P713; Webb DF, 2000, J ATMOS SOL-TERR PHY, V62, P1415, DOI 10.1016/S1364-6826(00)00075-4; WILSON RM, 1984, SOL PHYS, V91, P169; Yashiro S, 2005, J GEOPHYS RES-SPACE, V110, DOI 10.1029/2005JA011151; YASHIRO S, 2006, 36 COSPAR SCI ASS BE, P1778; Yun-Chun Jiang, 2006, Chinese Journal of Astronomy and Astrophysics, V6, DOI 10.1088/1009-9271/6/3/10	23	9	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0038-0938		SOL PHYS	Sol. Phys.	APR	2008	248	2					471	483		10.1007/s11207-007-9108-1		13	Astronomy & Astrophysics	Astronomy & Astrophysics	290IE	WOS:000255115700019	
J	Sun, L; Ji, S; Ye, J				Sun, Liang; Ji, Shuiwang; Ye, Jieping			Adaptive diffusion kernel learning from biological networks for protein function prediction	BMC BIOINFORMATICS			English	Article							MATRIX	Background: Machine-learning tools have gained considerable attention during the last few years for analyzing biological networks for protein function prediction. Kernel methods are suitable for learning from graph-based data such as biological networks, as they only require the abstraction of the similarities between objects into the kernel matrix. One key issue in kernel methods is the selection of a good kernel function. Diffusion kernels, the discretization of the familiar Gaussian kernel of Euclidean space, are commonly used for graph-based data. Results: In this paper, we address the issue of learning an optimal diffusion kernel, in the form of a convex combination of a set of pre-specified kernels constructed from biological networks, for protein function prediction. Most prior work on this kernel learning task focus on variants of the loss function based on Support Vector Machines (SVM). Their extensions to other loss functions such as the one based on Kullback-Leibler (KL) divergence, which is more suitable for mining biological networks, lead to expensive optimization problems. By exploiting the special structure of the diffusion kernel, we show that this KL divergence based kernel learning problem can be formulated as a simple optimization problem, which can then be solved efficiently. It is further extended to the multi-task case where we predict multiple functions of a protein simultaneously. We evaluate the efficiency and effectiveness of the proposed algorithms using two benchmark data sets. Conclusion: Results show that the performance of linearly combined diffusion kernel is better than every single candidate diffusion kernel. When the number of tasks is large, the algorithms based on multiple tasks are favored due to their competitive recognition performance and small computational costs.	[Sun, Liang; Ji, Shuiwang; Ye, Jieping] Arizona State Univ, Biodesign Inst, Ctr Evolutionary Funct Genom, Tempe, AZ 85287 USA; [Sun, Liang; Ji, Shuiwang; Ye, Jieping] Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA	Ye, J (reprint author), Arizona State Univ, Biodesign Inst, Ctr Evolutionary Funct Genom, Tempe, AZ 85287 USA.	sun.liang@asu.edu; shuiwang.ji@asu.edu; jieping.ye@asu.edu					Ben-Hur A., 2005, BIOINFORMATICS S1, V21, P38; Boyd S, 2004, CONVEX OPTIMIZATION; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Chua HN, 2006, BIOINFORMATICS, V22, P1623, DOI 10.1093/bioinformatics/btl145; Chua HN, 2007, BMC BIOINFORMATICS, V8, DOI 10.1183/1471-2105-8-S4-S8; Golub G. H., 1996, MATRIX COMPUTATIONS; Hishigaki H, 2001, YEAST, V18, P523, DOI 10.1002/yea.706.abs; Karaoz U, 2004, P NATL ACAD SCI USA, V101, P2888, DOI 10.1073/pnas.0307326101; Kondor R.I., 2002, ICML, P315; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Lanckriet GRG, 2004, BIOINFORMATICS, V20, P2626, DOI 10.1093/bioinformatics/bth294; Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27; LAWRENCE ND, 2004, CS0412 U SHEFF DEP C; Nabieva E., 2005, BIOINFORMATICS S1, V21, P302; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; Pandey G, 2006, 06028 U MINN DEP COM; Roth V, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-S2-S12; Schokopf B., 2000, INT C MACH LEARN, P911; Scholkopf B., 2002, LEARNING KERNELS SUP; Scholkopf B, 2004, KERNEL METHODS COMPU; Schwikowski B, 2000, NAT BIOTECHNOL, V18, P1257, DOI 10.1038/82360; SMOLA AJ, 2001, NIPS, P619; Tsuda K, 2004, BIOINFORMATICS, V20, P326, DOI 10.1093/bioinformatics/bth906; Tsuda K, 2005, BIOINFORMATICS, V21, P59, DOI 10.1093/bioinformatics/bti1110; Vandenberghe L, 1998, SIAM J MATRIX ANAL A, V19, P499, DOI 10.1137/S0895479896303430; Vazquez A, 2003, NAT BIOTECHNOL, V21, P697, DOI 10.1038/nbt825; VERT JP, 2003, NIPS, P1425; von Mering C, 2002, NATURE, V417, P399; Weston J, 2004, P NATL ACAD SCI USA, V101, P6559, DOI 10.1073/pnas.0308067101; Zhou D., 2004, NIPS, P321; *MIPS, MIPS COMPR YEAST GEN	31	2	2	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	MAR 25	2008	9								162	10.1186/1471-2105-9-162		14	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	292RN	WOS:000255283900002	
J	Pivard, S; Demsar, D; Lecomte, J; Debeljak, M; Dzeroski, S				Pivard, Sandrine; Demsar, Damjan; Lecomte, Jane; Debeljak, Marko; Dzeroski, Saso			Characterizing the presence of oilseed rape feral populations on field margins using machine learning	ECOLOGICAL MODELLING			English	Article; Proceedings Paper	5th European Conference on Ecological Modelling	SEP 19-23, 2005	Pushchino, RUSSIA			oilseed rape; feral population; risk assessment; data mining; attribute ranking; classification tree	BOUNDARY VEGETATION; TRANSGENIC CROPS; NATURAL HABITATS; DYNAMICS; L.	Many cultivated species, such as oilseed rape, sunflower, wheat or sorghum can escape from crops, and colonize field margins as feral populations. The general processes leading to the escape and persistence of cultivated species on field margins are still poorly investigated. An exhaustive 4-year survey was conducted in the centre of France at a landscape level to study the origin of feral oilseed rape populations. We present here results obtained with machine learning methods, which are increasingly popular techniques for analysing large ecological datasets. As expected, the dynamics of feral populations relies on large seed immigration from fields and transport. However, the seed bank was shown to be the keystone of their persistence rather than local recruitment. (c) 2007 Elsevier B.V. All rights reserved.	[Pivard, Sandrine; Lecomte, Jane] Univ Paris 11, CNRS, Ecol Lab Systemat & Evolut, UMR 8079,AgroParisTech, F-91405 Orsay, France; [Demsar, Damjan; Debeljak, Marko; Dzeroski, Saso] Jozef Stefan Inst, SI-1000 Ljubljana, Slovenia	Pivard, S (reprint author), Univ Paris 11, CNRS, Ecol Lab Systemat & Evolut, UMR 8079,AgroParisTech, F-91405 Orsay, France.	sandrine.pivard@polytechnique.org					Breiman L, 1984, CLASSIFICATION REGRE; Burel F, 1998, ACTA OECOL, V19, P47, DOI 10.1016/S1146-609X(98)80007-6; CHARTERS YM, 1999, INVESTIGATION FERAL; Clements DR, 2004, AGR ECOSYST ENVIRON, V104, P379, DOI 10.1016/j.agee.2004.03.003; CRAWLEY MJ, 1995, P ROY SOC B-BIOL SCI, V259, P49, DOI 10.1098/rspb.1995.0008; Crawley MJ, 2001, NATURE, V409, P682, DOI 10.1038/35055621; CRAWLEY MJ, 1993, NATURE, V363, P620, DOI 10.1038/363620a0; Debeljak M, 2001, ECOL MODEL, V138, P321, DOI 10.1016/S0304-3800(00)00411-7; Dzeroski S, 2001, ECOL MODEL, V146, P263, DOI 10.1016/S0304-3800(01)00312-X; Dzeroski S, 2003, ECOL MODEL, V170, P129, DOI 10.1016/S0304-3800(03)00221-7; Freemark KE, 2002, CONSERV BIOL, V16, P399, DOI 10.1046/j.1523-1739.2002.00387.x; Garnier A, 2006, ECOL MODEL, V194, P141, DOI 10.1016/j.ecolmodel.2005.10.009; Hancock JF, 1996, HORTSCIENCE, V31, P1080; Hunt E.B., 1966, EXPT INDUCTION; Kleijn D, 1997, J APPL ECOL, V34, P1413, DOI 10.2307/2405258; Kleijn D, 2000, J APPL ECOL, V37, P256, DOI 10.1046/j.1365-2664.2000.00486.x; Kononenko I., 1994, P EUR C MACH LEARN, P171; LEK S, 1999, ECOL MODEL, V120; LUTMAN P, 2003, P 1 EUR C COEX GM CR, P32; Marshall EJR, 2002, AGR ECOSYST ENVIRON, V89, P5, DOI 10.1016/S0167-8809(01)00315-2; Pessel FD, 2001, THEOR APPL GENET, V102, P841, DOI 10.1007/s001220100583; PIVARD S, IN PRESS J APPL ECOL; Price JS, 1996, J AGR ENG RES, V65, P183, DOI 10.1006/jaer.1996.0091; Quinlan J. R., 1993, PROGRAMS MACHINE LEA; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Recknagel F, 2001, ECOL MODEL, V146, P1, DOI 10.1016/S0304-3800(01)00291-5; Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714; Stewart CN, 2003, NAT REV GENET, V4, P806, DOI 10.1038/nrg1179; STONE M, 1977, BIOMETRIKA, V64, P29, DOI 10.1093/biomet/64.1.29; WILSON SD, 1991, OECOLOGIA, V88, P61, DOI 10.1007/BF00328404; Witten I. H., 1999, DATA MINING PRACTICA	31	8	9	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3800		ECOL MODEL	Ecol. Model.	MAR 24	2008	212	1-2					147	154		10.1016/j.ecolmodel.2007.10.012		8	Ecology	Environmental Sciences & Ecology	277PM	WOS:000254227100019	
J	Aquino, LD; Tullis, JA; Stephen, FM				Aquino, Leah D.; Tullis, Jason A.; Stephen, Fred M.			Modeling red oak borer, Enaphalodes rufulus (Haldeman), damage using in situ and ancillary landscape data	FOREST ECOLOGY AND MANAGEMENT			English	Article						red oak borer; tree damage modeling; native insect pest; cerambycidae; Quercus	COLEOPTERA; CLASSIFICATION; CERAMBYCIDAE; MORTALITY; ECOLOGY	Red oak borer, Enaphalodes rufulus (Haldeman) (Coleoptera: Cerambycidae), has been implicated as a contributing factor to oak decline and mortality in forests of Arkansas, Missouri, and Oklahoma. A non-destructive rapid estimation procedure was used to determine red oak borer infestation histories of northern red oaks, Quercus rubra L., in a series of forest stands. Twenty-three biotic and abiotic variables in 364 vegetation-monitoring plots were analyzed for possible inclusion in a data distribution-independent machine-learning decision tree model to predict red oak borer hazard conditions on the Ozark National Forest. Decision tree models generated in this study of red oak borer damage were relatively successful in explaining patterns in the training data (71-81% overall accuracy), but relatively unsuccessful in predicting red oak borer hazard in unknown cases (42-49% overall accuracy based on cross-validation). Average clay content, distance to roads, and ridge-top topographic position were input variables that yielded the highest information content. Increased predictive accuracy likely depends on technology for optimizing the spatial aggregation scale of each input variable. (C) 2007 Elsevier B.V. All rights reserved.	[Aquino, Leah D.; Stephen, Fred M.] 1 Univ Arkansas, Entomol AGRI 319, Fayetteville, AR 72701 USA; [Tullis, Jason A.] Univ Arkansas, Dept Geosci, Fayetteville, AR 72701 USA; [Tullis, Jason A.] Univ Arkansas, Ctr Adv Spatial Technol, Fayetteville, AR 72701 USA	Stephen, FM (reprint author), 1 Univ Arkansas, Entomol AGRI 319, Fayetteville, AR 72701 USA.	fstephen@uark.edu					ADAMSKI JC, 1995, 944022 USGS WAT RES; Bates CG, 1923, ECOLOGY, V4, P54, DOI 10.2307/1929273; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; CARREIRAS, 2006, PHOTOGRAMM ENG REMOT, V72, P897; CARREIRAS JMB, 2006, ENG REMOTE SENSING, V72, P897; COLLIN H, 2002, ASPRS 2002 ANN CONV, P13; DONLEY DE, 1978, ENTOMOL SOC AM, V71, P496; DONLEY DE, 1974, WOOD BORER LOSSES AP, V8, P115; DONLEY DE, 1980, FOREST INSECT DIS LE, V163, P6; Fierke MK, 2005, ENVIRON ENTOMOL, V34, P184; Fierke MK, 2007, FOREST ECOL MANAG, V247, P227, DOI 10.1016/j.foreco.2007.04.051; Fierke MK, 2005, FOREST ECOL MANAG, V215, P163, DOI 10.1016/j.foreco.2005.05.009; Franklin J, 1995, PROG PHYS GEOG, V19, P474, DOI 10.1177/030913339501900403; Gahegan M, 2003, INT J GEOGR INF SCI, V17, P69, DOI 10.1080/13658810210157778; GRANEY DL, 1977, SO139 USDA FOR SERV; GRANEY DL, 1977, SO139 USDA; Guisan A, 2000, ECOL MODEL, V135, P147, DOI 10.1016/S0304-3800(00)00354-9; Hanks LM, 1999, ANNU REV ENTOMOL, V44, P483, DOI 10.1146/annurev.ento.44.1.483; Hay C. J., 1969, Proc. N. cent. Brch Am. Ass. econ. Ent., V24, P125; HAY CJ, 1974, ANN ENTOMOL SOC AM, V67, P981; HUANG C, 2001, 35 ANN MIDW FOR MENS; Huang XQ, 1997, PHOTOGRAMM ENG REM S, V63, P1185; Husch B., 2003, FOREST MENSURATION, P443; Jensen J. R., 2005, INTRO DIGITAL IMAGE, P526; Jensen J.R., 2005, INTRO DIGITAL IMAGE; LEVIN SA, 1992, ECOLOGY, V73, P1943, DOI 10.2307/1941447; McIver DK, 2002, REMOTE SENS ENVIRON, V81, P253, DOI 10.1016/S0034-4257(02)00003-2; NELSON T, 2004, CHALLENGES SOULTIONS; NELSON T, 2004, MOUNT PIN BEET S CHA; Oak S, 1996, ANN SCI FOREST, V53, P721, DOI 10.1051/forest:19960248; PELL WF, 1999, SRS35 SO RES STAT GE; PELL WF, 1999, SRS35 USDA FOR SERV; Potzger JE, 1939, ECOLOGY, V20, P29, DOI 10.2307/1930801; QUINLAN R, 2006, INFORMAL TUTORIAL; QUINLAN R, 2006, INFORM TUTORIAL; SOLOMON JD, 1995, USDA FOR SERV AGR HD, P422; STARKEY D, 2000, 20000202 USDA FOR HL; Stephen Fred M., 2003, Integrated Pest Management Reviews, V6, P247, DOI 10.1023/A:1025779520102; STOECKELER J. H., 1960, JOUR FOREST, V58, P892; STRINGER J W, 1989, Southern Journal of Applied Forestry, V13, P86; XIAN G, 2002, ISPRS COMM 1 S 2002, P8; *USDA FOR SERV, 2001, FOR INV ANAL; *USDA NRCS, 1995, SOIL SURV GEOGR DAT	43	3	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0378-1127		FOREST ECOL MANAG	For. Ecol. Manage.	MAR 20	2008	255	3-4					931	939		10.1016/j.foreco.2007.10.011		9	Forestry	Forestry	275LJ	WOS:000254072700056	
J	Berman, P; DasGupta, B				Berman, Piotr; DasGupta, Bhaskar			Approximating the online set multicover problems via randomized winnowing	THEORETICAL COMPUTER SCIENCE			English	Article						set multicover; online algorithms; randomized algorithms; reverse engineering of biological networks	GENE NETWORKS; PROTEIN; ALGORITHMS	In this paper, we consider the weighted online set k-multicover problem. In this problem, we have a universe V of elements, a family S of subsets of V with a positive real cost for every S is an element of S, and a "coverage factor" (positive integer) k. A subset {i(0), i(1).... } subset of V of elements are presented online in an arbitrary order. When each element i(P) is presented, we are also told the collection of all (at least k) sets (S)i(p) subset of S and their costs to which i(P) belongs and we need to select additional sets from Si-P if necessary such that our collection of selected sets contains at least k sets that contain the element i(P). The goal is to minimize the total cost of the selected sets.' In this paper, we describe a new randomized algorithm for the online multicover problem based on a randomized version of the winnowing approach of [N. Littlestone, Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm, Machine Learning 2 (1988) 285-318]. This algorithm generalizes and improves some earlier results in [N. Alon, B. Awerbuch, Y Azar, N. Buchbinder, J. Naor, A general approach to online network optimization problems, in: Proceedings of the 15th ACM-SIAM Symposium on Discrete Algorithms, 2004, pp. 570-579; N. Alon, B. Awerbuch, Y Azar, N. Buchbinder, J. Naor, The online set cover problem, in: Proceedings of the 35th Annual ACM Symposium on the Theory of Computing, 2003, pp. 100-105]. We also discuss lower bounds on competitive ratios for deterministic algorithms for general k based on the approaches in [N. Alon, B. Awerbuch, Y. Azar, N. Buchbinder, J. Naor, The online set cover problem, in: Proceedings of the 35th Annual ACM Symposium on the Theory of Computing, 2003, pp. 100-105]. (C) 2007 Elsevier B.V. All rights reserved.	[DasGupta, Bhaskar] Univ Illinois, Dept Comp Sci, Chicago, IL 60607 USA; [Berman, Piotr] Penn State Univ, Dept Comp Sci & Engn, University Pk, PA 16802 USA	DasGupta, B (reprint author), Univ Illinois, Dept Comp Sci, Chicago, IL 60607 USA.	berman@cse.psu.edu; dasgupta@cs.uic.edu					ALON N., 2003, P 35 ANN ACM S THEOR, P100, DOI DOI 10.1145/780542.780558; ALON N, 2005, P 17 ACM S PAR ALG A, P238, DOI 10.1145/1073970.1074010; ALON N., 2004, P 15 ACM SIAM S DISC, P570; Andrec M, 2005, J THEOR BIOL, V232, P427, DOI 10.1016/j.jtbi.2004.08.022; Awerbuch B., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/237814.238000; Berman P, 2005, J COMPUT SYST SCI, V71, P145, DOI 10.1016/j.jcss.2005.02.001; Berman P, 2007, ANN NY ACAD SCI, V1115, P132, DOI 10.1196/annals.1407.001; Berman P, 2007, DISCRETE APPL MATH, V155, P733, DOI 10.1016/j.dam.2004.11.009; CHERNOFF H, 1952, ANN MATH STAT, V23, P493, DOI 10.1214/aoms/1177729330; Crampin EJ, 2004, PROG BIOPHYS MOL BIO, V86, P77, DOI 10.1016/j.pbiomolbio.2004.04.002; Feige U, 1998, J ACM, V45, P634, DOI 10.1145/285055.285059; JOHNSON DS, 1974, J COMPUT SYST SCI, V9, P256; KHOLODENKO BN, 2002, ARXIVPHYSICS0205003; Kholodenko BN, 2002, P NATL ACAD SCI USA, V99, P12841, DOI 10.1073/pnas.192442699; Littlestone N., 1988, Machine Learning, V2, DOI 10.1007/BF00116827; Motwani R., 1995, RANDOMIZED ALGORITHM; Slavik P., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/237814.237991; Sontag E, 2004, BIOINFORMATICS, V20, P1877, DOI 10.1093/bioinformatics/bth173; Srinivasan A., 1995, Proceedings of the Twenty-Seventh Annual ACM Symposium on the Theory of Computing, DOI 10.1145/225058.225138; Stark J, 2003, TRENDS BIOTECHNOL, V21, P290, DOI 10.1016/S0167-7799(03)00140-9; TREVISAN L., 2001, P 33 ANN ACM S THEOR, P453, DOI 10.1145/380752.380839; Vazirani V.V, 2001, APPROXIMATION ALGORI	22	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3975		THEOR COMPUT SCI	Theor. Comput. Sci.	MAR 20	2008	393	1-3					54	71		10.1016/j.tcs.2007.10.047		18	Computer Science, Theory & Methods	Computer Science	282BZ	WOS:000254543900005	
J	Waegeman, W; De Baets, B; Boullart, L				Waegeman, Willem; De Baets, Bemard; Boullart, Luc			On the scalability of ordered multi-class ROC analysis	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article							ORDINAL REGRESSION; CURVE; AREA; CLASSIFICATION	Receiver operating characteristics (ROC) analysis provides a way to select possibly optimal models for discriminating two kinds of objects without the need of specifying the cost or class distribution. It is nowadays established as a standard analysis tool in different domains, including medical decision making, pattern recognition and machine learning. Recently, an extension to the ordered multi-class case has been proposed, in which the concept of a ROC curve is generalized to an r-dimensional surface for r ordered categories, and the volume under this ROC surface (VUS) measures the overall power of a model to classify objects of the various categories. However, the computation of this criterion as well as the U-statistics estimators of its variance and covariance for two models is believed to be complex. New algorithms to compute VUS and its (co)variance estimator are presented. In particular, the volume under the ROC surface can be found very efficiently with a simple dynamic program dominated by a single sorting operation on the data set. For the variance and covariance, the respective estimators are reformulated as a series of recurrent functions over layered data graphs and subsequently these functions are rapidly evaluated with a dynamic program. Simulation experiments confirm that the presented algorithms scale well with respect to the size of the data set and the number of categories. For example, the volume under the ROC surface could be rapidly computed on very large data sets of more than 500 000 instances, while a naive implementation spent much more time on data sets of size less than 1000. (c) 2007 Elsevier B.V. All rights reserved.	[Waegeman, Willem; Boullart, Luc] Univ Ghent, Dept Elect Energy Syst & Automat, B-9052 Ghent, Belgium; [De Baets, Bemard] Univ Ghent, Dept Appl Math Biometr & Proc Control, B-9000 Ghent, Belgium	Waegeman, W (reprint author), Univ Ghent, Dept Elect Energy Syst & Automat, Technol Pk 913, B-9052 Ghent, Belgium.	Willem.Waegeman@UGent.be	De Baets, Bernard/E-8877-2010				Agarwal S, 2005, J MACH LEARN RES, V6, P393; Agresti A, 2002, CATEGORICAL DATA ANA, DOI 10.1002/0471249688; Chu W, 2005, J MACH LEARN RES, V6, P1019; CHU W, 2005, P INT C MACH LEARN B, P321; Cortes C., 2003, ADV NEURAL INFORM PR, V16; Cortes C., 2004, ADV NEURAL INFORM PR, V17, P305; Crammer K., 2001, P C NEUR INF PROC SY, P641; Dreiseitl S, 2000, MED DECIS MAKING, V20, P323, DOI 10.1177/0272989X0002000309; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Ferri C., 2003, P 14 EUR C MACH LEAR, P108; Fieldsend J., 2006, PATTERN RECOGN, V27, P918; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; HANLEY JA, 1982, RADIOLOGY, V143, P29; HANLEY JA, 1983, RADIOLOGY, V148, P839; Hastie T, 2001, ELEMENTS STAT LEARNI; HERSCHTAL A, 2005, P INT C MACH LEARN B, P49; KRAMER S, 2000, FUNDAMENTA INFORM, V24, P1; NAKAS C, 2004, STAT MED, V22, P3437; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; SHASHUA A, 2003, P INT C NEUR INF PRO, P937; Waegeman W, 2008, PATTERN RECOGN LETT, V29, P1, DOI 10.1016/j.patrec.2007.07.019; WAEGEMAN W, 2006, P 3 INT WORKSH ROC A, P63; Yan L., 2003, P 20 INT C MACH LEAR, P848	23	10	10	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473		COMPUT STAT DATA AN	Comput. Stat. Data Anal.	MAR 15	2008	52	7					3371	3388		10.1016/j.csda.2007.12.001		18	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	290TU	WOS:000255145900007	
J	Bonates, TO; Hammer, PL; Kogan, A				Bonates, T. O.; Hammer, Peter L.; Kogan, A.			Maximum patterns in datasets	DISCRETE APPLIED MATHEMATICS			English	Article						logical analysis of data; set covering; heuristic; machine learning; classification	LOGICAL ANALYSIS; ALGORITHM; DNF	Given a binary dataset of positive and negative observations, a positive (negative) pattern is a subcube having a nonempty intersection with the positive (negative) subset of the dataset, and an empty intersection with the negative (positive) subset of the dataset. Patterns are the key building blocks in Logical Analysis of Data (LAD), and are an essential too] in identifying the positive or negative nature of "new" observations covered by them. We develop exact and heuristic algorithms for constructing a pattern of maximum coverage which includes a given point. It is shown that the heuristically constructed patterns can achieve 81-98% of the maximum possible coverage, while requiring only a fraction of the computing time of the exact algorithm. Maximum patterns are shown to be useful for constructing highly accurate LAD classification models. In comparisons with the commonly used machine learning algorithms implemented in the publicly available Weka software package, the implementation of LAD using maximum patterns is shown to be a highly competitive classification method. Published by Elsevier B.V.	[Bonates, T. O.; Hammer, Peter L.; Kogan, A.] Rutgers State Univ, RUTCOR, Rutgers Ctr Operat Res, Piscataway, NJ 08854 USA; [Kogan, A.] Rutgers State Univ, Rutgers Business Sch, Accounting & Informat Syst, Newark, NJ 07102 USA	Bonates, TO (reprint author), Rutgers State Univ, RUTCOR, Rutgers Ctr Operat Res, 640 Bartholomew Rd, Piscataway, NJ 08854 USA.	tbonates@rutcor.rutgers.edu; hammer@rutcor.rutgers.edu; kogan@rutgers.edu					Alexe G, 2006, SOFT COMPUT, V10, P442, DOI 10.1007/s00500-005-0505-9; Alexe G, 2006, DISCRETE APPL MATH, V154, P1039, DOI 10.1016/j.dam.2005.03.031; Alexe S, 2006, DISCRETE APPL MATH, V154, P1050, DOI 10.1016/j.dam.2005.03.032; BAZAN JG, 2002, P 3 INT C ROUGH SETS, P397; Blake C. L., 1998, UCI REPOSITORY MACHI; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; BORDA J.-CH., 1781, MEMOIRES ELECTIONS S; Boros E, 2000, IEEE T KNOWL DATA EN, V12, P292, DOI 10.1109/69.842268; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Bshouty NH, 2003, J MACH LEARN RES, V3, P49, DOI 10.1162/153244303768966094; Chvatal V., 1979, Mathematics of Operations Research, V4, DOI 10.1287/moor.4.3.233; Crama Y., 1988, Annals of Operations Research, V16, DOI 10.1007/BF02283750; Dietterich T, 1995, ACM COMPUT SURV, V27, P326, DOI 10.1145/212094.212114; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Dong G., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; Feige U, 1998, J ACM, V45, P634, DOI 10.1145/285055.285059; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; HAMMER PL, 1986, INT C MULT DEC MAK O; Hammer PL, 2004, DISCRETE APPL MATH, V144, P79, DOI 10.1016/j.dam.2003.08.013; HAMMER PL, 1992, METHODS MODELS OPERA, V39, P3; Klivans AR, 2004, J COMPUT SYST SCI, V68, P303, DOI 10.1016/j.jcss.2003.07.007; Lavrac N, 2005, LECT NOTES ARTIF INT, V3518, P2; Pawlak Z., 1992, ROUGH SETS THEORETIC; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; Schapire RE, 1998, ANN STAT, V26, P1651; WANG L, 2004, P 28 ANN INT COMP SO; Witten I. H., 2005, DATA MINING PRACTICA; *DASH OPT INC, 2003, XPRESS MP REL 2003C	29	6	6	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0166-218X		DISCRETE APPL MATH	Discret Appl. Math.	MAR 15	2008	156	6					846	861		10.1016/j.dam.2007.06.004		16	Mathematics, Applied	Mathematics	281FN	WOS:000254482400004	
J	Anthony, M				Anthony, Martin			Aspects of discrete mathematics and probability in the theory of machine learning	DISCRETE APPLIED MATHEMATICS			English	Article						machine learning; uniform glivenko-cantelli theorems; concentration of measure; covering numbers; vapnik-chervonenkis dimension	VAPNIK-CHERVONENKIS DIMENSION; NEURAL-NETWORKS; LIMIT-THEOREMS	This paper discusses the applications of certain combinatorial and probabilistic techniques to the analysis of machine learning. Probabilistic models of learning initially addressed binary classification (or pattern classification). Subsequently, analysis was extended to regression problems, and to classification problems in which the classification is achieved by using real-valued functions (where the concept of a large margin has proven useful). Another development, important in obtaining more applicable models, has been the derivation of data-dependent bounds. Here, we discuss some of the key probabilistic and combinatorial techniques and results, focusing on those of most relevance to researchers in discrete applied mathematics. (C) 2007 Elsevier B.V. All rights reserved.	[Anthony, Martin] London Sch Econ & Polit Sci, Dept Math, London WC2A 2AE, England	Anthony, M (reprint author), London Sch Econ & Polit Sci, Dept Math, Houghton St, London WC2A 2AE, England.	m.anthony@lse.ac.uk					ALON N, 1997, J ASSOC COMPUT MACH, V44, P616; ANTHONY M, 1992, CAMBRIDGE TRACTS THO, V30; ANTHONY M, 1997, NEURAL COMPUTING SUR, V1; Anthony M., 1999, NEURAL NETWORK LEARN; ANTOS A, 2002, J MACHINE LEARNING R, V3, P73; Bartlett P., 2001, LECT NOTES ARTIF INT, P224; BARTLETT PL, 2002, SPRINGER LECT NOTES, V2375; Bartlett P.L., 1995, P 8 ANN C COMP LEARN, P392, DOI 10.1145/225298.225346; Bartlett PL, 1998, IEEE T INFORM THEORY, V44, P525, DOI 10.1109/18.661502; BLUMER A, 1989, J ACM, V36, P929, DOI 10.1145/76359.76371; Bollobas B., 1986, COMBINATORICS SET SY; BOUCHERON S, 2003, ANN PROBAB, V31; Boucheron S, 2000, RANDOM STRUCT ALGOR, V16, P277, DOI 10.1002/(SICI)1098-2418(200005)16:3<277::AID-RSA4>3.0.CO;2-1; BOUSQUET O, 2002, SPRINGER LECT NOTES, V2375; Cristianini N., 2000, INTRO SUPPORT VECTOR; DEVROYE L, 2001, SPRINGER SERIES STAT; Duda R.O, 1973, PATTERN CLASSIFICATI; DUDLEY RM, 1978, ANN PROBAB, V6, P899, DOI 10.1214/aop/1176995384; Dudley R. M., 1999, CAMBRIDGE STUDIES AD, V63; EHRENFEUCHT A, 1989, INFORM COMPUT, V82, P247, DOI 10.1016/0890-5401(89)90002-3; GINE E, 1984, ANN PROBAB, V12, P929, DOI 10.1214/aop/1176993138; HAUSSLER D, 1995, J COMB THEORY A, V69, P217, DOI 10.1016/0097-3165(95)90052-7; HAUSSLER D, 1992, INFORM COMPUT, V100, P78, DOI 10.1016/0890-5401(92)90010-D; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; Karpinski M, 1997, J COMPUT SYST SCI, V54, P169, DOI 10.1006/jcss.1997.1477; KEARNS MJ, 1994, J COMPUT SYST SCI, V48, P464, DOI 10.1016/S0022-0000(05)80062-5; KEARNS MJ, 1995, INTRO COMPUTATIONAL; KOLTCHINSKI V, 2000, HIGH DIMENSIONAL PRO, V2; Lugosi G, 2002, CISM COURSES LECT, P1; McDiarmid C., 1989, LONDON MATH SOC LECT, V141; Mendelson S., 2003, LECT NOTES COMPUT SC, P1; POLLARD D., 1984, CONVERGENCE STOCHAST; Sauer N., 1972, Journal of Combinatorial Theory, Series A, V13, DOI 10.1016/0097-3165(72)90019-2; Shawe-Taylor J, 1998, IEEE T INFORM THEORY, V44, P1926, DOI 10.1109/18.705570; SHELAH S, 1972, PAC J MATH, V41, P247; STEELE JM, 1978, J COMB THEORY A, V24, P84, DOI 10.1016/0097-3165(78)90046-8; TALAGRAND M, 1987, ANN PROBAB, V15, P837, DOI 10.1214/aop/1176992069; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; van der Vaart A.W., 1996, SPRINGER SERIES STAT; Vapnik V., 1982, ESTIMATION DEPENDENC; Vapnik VN, 1998, STAT LEARNING THEORY; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; VIDYASAGAR M, 1996, THEORY LEARNING GENE; WILLIAMSON R, 1999, P 4 EUR C COMP LEARN, P274	44	1	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0166-218X		DISCRETE APPL MATH	Discret Appl. Math.	MAR 15	2008	156	6					883	902		10.1016/j.dam.2007.05.040		20	Mathematics, Applied	Mathematics	281FN	WOS:000254482400007	
J	Gromiha, MM; Yabuki, Y				Gromiha, M. Michael; Yabuki, Yukimitsu			Functional discrimination of membrane proteins using machine learning techniques	BMC BIOINFORMATICS			English	Article							COBALAMIN TRANSPORTER BTUB; AMINO-ACID-COMPOSITION; BETA-BARREL PROTEINS; ESCHERICHIA-COLI; STRUCTURE PREDICTION; CLASSIFICATION; ACCURACY; DATABASE; SELECTIVITY; MECHANISM	Background: Discriminating membrane proteins based on their functions is an important task in genome annotation. In this work, we have analyzed the characteristic features of amino acid residues in membrane proteins that perform major functions, such as channels/pores, electrochemical potential-driven transporters and primary active transporters. Results: We observed that the residues Asp, Asn and Tyr are dominant in channels/pores whereas the composition of hydrophobic residues, Phe, Gly, Ile, Leu and Val is high in electrochemical potential-driven transporters. The composition of all the amino acids in primary active transporters lies in between other two classes of proteins. We have utilized different machine learning algorithms, such as, Bayes rule, Logistic function, Neural network, Support vector machine, Decision tree etc. for discriminating these classes of proteins. We observed that most of the algorithms have discriminated them with similar accuracy. The neural network method discriminated the channels/pores, electrochemical potential-driven transporters and active transporters with the 5-fold cross validation accuracy of 64% in a data set of 1718 membrane proteins. The application of amino acid occurrence improved the overall accuracy to 68%. In addition, we have discriminated transporters from other alpha-helical and beta-barrel membrane proteins with the accuracy of 85% using k-nearest neighbor method. The classification of transporters and all other proteins (globular and membrane) showed the accuracy of 82%. Conclusion: The performance of discrimination with amino acid occurrence is better than that with amino acid composition. We suggest that this method could be effectively used to discriminate transporters from all other globular and membrane proteins, and classify them into channels/pores, electrochemical and active transporters.	[Gromiha, M. Michael; Yabuki, Yukimitsu] AIST Tokyo, CBRC, Koto Ku, Tokyo 1350064, Japan	Gromiha, MM (reprint author), AIST Tokyo, CBRC, Koto Ku, Waterfront Bio IT Res Bldg,2-42 Aomi, Tokyo 1350064, Japan.	michael-gromiha@aist.go.jp; yukimitsu-yabuki@aist.go.jp					Abramson J, 2003, SCIENCE, V301, P610, DOI 10.1126/science.1088196; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Bagos PG, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-29; Borths EL, 2002, P NATL ACAD SCI USA, V99, P16642, DOI 10.1073/pnas.262659699; Cai YD, 2006, J THEOR BIOL, V238, P395, DOI 10.1016/j.jtbi.2005.05.035; Chimento DP, 2003, NAT STRUCT BIOL, V10, P394, DOI 10.1038/nsb914; Chimento DP, 2003, J MOL BIOL, V332, P999, DOI 10.1016/j.jmb.2003.07.005; Dutzler R, 2003, SCIENCE, V300, P108, DOI 10.1126/science.1082708; Fu DX, 2000, SCIENCE, V290, P481, DOI 10.1126/science.290.5491.481; Garrow AG, 2005, NUCLEIC ACIDS RES, V33, pW188, DOI 10.1093/nat/gki384; Gromiha MM, 2005, BIOINFORMATICS, V21, P961, DOI 10.1093/bioinformatics/bti126; Gromiha MM, 2006, BBA-PROTEINS PROTEOM, V1764, P1493, DOI 10.1016/j.bbapap.2006.07.005; Gromiha MM, 2006, PROTEINS, V63, P1031, DOI 10.1002/prot.20929; Gromiha MM, 2007, CURR PROTEIN PEPT SC, V8, P580, DOI 10.2174/138920307783018712; Hirokawa T, 1998, BIOINFORMATICS, V14, P378, DOI 10.1093/bioinformatics/14.4.378; Huang YF, 2003, SCIENCE, V301, P616, DOI 10.1126/science.1087619; Martelli Pier Luigi, 2002, Bioinformatics, V18 Suppl 1, pS46; Murakami S, 2002, NATURE, V419, P587, DOI 10.1038/nature01050; Natt NK, 2004, PROTEINS, V56, P11, DOI 10.1002/prot.20092; NOGI T, 2000, P NATL ACAD SCI USA, V97, P1356; Ren QH, 2007, NUCLEIC ACIDS RES, V35, pD274, DOI 10.1093/nar/gkl925; ROST B, 1995, PROTEIN SCI, V4, P521; Saier MH, 2000, MICROBIOL MOL BIOL R, V64, P354, DOI 10.1128/MMBR.64.2.354-411.2000; Saier MH, 2006, NUCLEIC ACIDS RES, V34, pD181, DOI 10.1093/nar/gkj001; Taguchi YH, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-404; Tusnady GE, 1998, J MOL BIOL, V283, P489, DOI 10.1006/jmbi.1998.2107; VONHEIJNE G, 1992, J MOL BIOL, V225, P487, DOI 10.1016/0022-2836(92)90934-C; Witten I. H., 2005, DATA MINING PRACTICA	28	23	23	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	MAR 3	2008	9								135	10.1186/1471-2105-9-135		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	275XR	WOS:000254106000001	
J	Lao, ZQ; Shen, DG; Liu, DF; Jawad, AF; Melhern, ER; Launer, LJ; Bryan, RN; Davatzikos, C				Lao, Zhiqiang; Shen, Dinggang; Liu, Dengfeng; Jawad, Abbas F.; Melhern, Elias R.; Launer, Lenore J.; Bryan, R. Nick; Davatzikos, Christos			Computer-assisted segmentation of white matter lesions in 3D MR images using support vector machine	ACADEMIC RADIOLOGY			English	Article						white matter lesion segmentation; support vector machine; machine learning	ATTENUATED INVERSION-RECOVERY; MULTIPLE-SCLEROSIS LESIONS; SPIN-ECHO SEQUENCES; AUTOMATED SEGMENTATION; COGNITIVE FUNCTION; DIABETES-MELLITUS; ALZHEIMER-DISEASE; PROBABILISTIC SEGMENTATION; CARDIOVASCULAR HEALTH; CEREBRAL INFARCTIONS	Rationale and Objectives. Brain lesions, especially white matter lesions (WMLs), are associated with cardiac and vascular disease, but also with normal aging. Quantitative analysis of WML in large clinical trials is becoming more and more important. Materials and Methods. In this article, we present a computer-assisted WML segmentation method, based on local features extracted from multiparametric magnetic resonance imaging (MRI) sequences (ie, T1-weighted, T2-weighted, proton density-weighted, and fluid attenuation inversion recovery MRI scans). A support vector machine classifier is first trained on expert-defined WMLs, and is then used to classify new scans. Results. Postprocessing analysis further reduces false positives by using anatomic knowledge and measures of distance from the training set. Conclusions. Cross-validation on a population of 35 patients from three different imaging sites with WMLs of varying sizes, shapes, and locations tests the robustness and accuracy of the proposed segmentation method, compared with the manual segmentation results from two experienced neuroradiologists.	[Lao, Zhiqiang; Shen, Dinggang; Jawad, Abbas F.; Melhern, Elias R.; Bryan, R. Nick; Davatzikos, Christos] Univ Penn, Dept Radiol, Philadelphia, PA 19104 USA; [Jawad, Abbas F.] Childrens Hosp Philadelphia, Dept Biostat, Philadelphia, PA 19104 USA; [Launer, Lenore J.] NIA, Lab Epidemiol Demog & Biometry, Bethesda, MD 20892 USA; [Liu, Dengfeng] Natl Lib Med, Lister Hill Natl Ctr Biomed Commun, Natl Inst Hlth, Bethesda, MD USA	Lao, ZQ (reprint author), Univ Penn, Dept Radiol, 3600 Market St,Suite 380, Philadelphia, PA 19104 USA.	Zhiqiang.Lao@uphs.upenn.edu	Melhem, Elias/E-5205-2013				Admiraal-Behloul F, 2005, NEUROIMAGE, V28, P607, DOI 10.1016/j.neuroimage.2005.06.061; Alfano B, 2000, J MAGN RESON IMAGING, V12, P799, DOI 10.1002/1522-2586(200012)12:6<799::AID-JMRI2>3.0.CO;2-#; Allen KV, 2004, EUR J PHARMACOL, V490, P169, DOI 10.1016/j.ejphar.2004.02.054; Anbeek P, 2005, NEUROIMAGE, V27, P795, DOI 10.1016/j.neuroimage.2005.05.046; Anbeek P, 2004, NEUROIMAGE, V21, P1037, DOI 10.1016/j.neuroimage.2003.10.012; ARAKI Y, 1994, NEURORADIOLOGY, V36, P101; Arvanitakis Z, 2004, ARCH NEUROL-CHICAGO, V61, P661, DOI 10.1001/archneur.61.5.661; Bakshi R, 2000, AM J NEURORADIOL, V21, P503; Bastianello S, 1997, AM J NEURORADIOL, V18, P699; Benson RR, 2002, NEUROLOGY, V58, P48; Briley DP, 2000, NEUROLOGY, V54, P90; BRYAN RN, 1994, AM J NEURORADIOL, V15, P1625; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; de Groot JC, 2000, ARCH GEN PSYCHIAT, V57, P1071, DOI 10.1001/archpsyc.57.11.1071; de Groot JC, 2000, ANN NEUROL, V47, P145; de Groot JC, 2002, ANN NEUROL, V52, P335, DOI 10.1002/ana.10294; Duda R. O., 2001, PATTERN CLASSIFICATI; Eguchi K, 2003, STROKE, V34, P2471, DOI 10.1161/01.STR.0000089684.41902.CD; Gawne-Cain ML, 1998, J NEUROL NEUROSUR PS, V64, P197, DOI 10.1136/jnnp.64.2.197; GEARING M, 1995, NEUROLOGY, V45, P461; Gerig G, 2000, MED IMAGE ANAL, V4, P31, DOI 10.1016/S1361-8415(00)00005-0; HEIJER T, 2003, DIABETOLOGIA, V46, P1604; Ince P, 2000, BRAIN PATHOL, V10, P592; Inoue T, 1996, DIABETES RES CLIN PR, V31, P81, DOI 10.1016/0168-8227(96)01196-5; Jack CR, 2001, J MAGN RESON IMAGING, V14, P668, DOI 10.1002/jmri.10011; KAMBER M, 1995, IEEE T MED IMAGING, V14, P442, DOI 10.1109/42.414608; Kario K, 2005, HYPERTENSION, V45, P887, DOI 10.1161/01.HYP.0000163460.07639.3f; Lao ZQ, 2004, NEUROIMAGE, V21, P46, DOI 10.1016/j.neuroimage.2003.09.027; Longstreth WT, 1996, STROKE, V27, P1274; Luchsinger JA, 2001, AM J EPIDEMIOL, V154, P635, DOI 10.1093/aje/154.7.635; Mantyla R, 1997, STROKE, V28, P1614; Meier DS, 2006, NEUROIMAGE, V32, P531, DOI 10.1016/j.neuroimage.2006.04.181; Mohamed FB, 2001, MAGN RESON IMAGING, V19, P207, DOI 10.1016/S0730-725X(01)00291-0; Prins ND, 2004, ARCH NEUROL-CHICAGO, V61, P1531, DOI 10.1001/archneur.61.10.1531; Rovaris M, 1999, AM J NEURORADIOL, V20, P813; Schmidt R, 2004, DIABETES, V53, P687, DOI 10.2337/diabetes.53.3.687; Schneider JA, 2004, NEUROLOGY, V62, P1148; Schneider JA, 2003, NEUROLOGY, V60, P1082; Sled JG, 1998, IEEE T MED IMAGING, V17, P87, DOI 10.1109/42.668698; Smith CD, 2000, NEUROLOGY, V54, P838; Smith SM, 2002, HUM BRAIN MAPP, V17, P143, DOI 10.1002/hbm.10062; Snowdon DA, 1997, JAMA-J AM MED ASSOC, V277, P813, DOI 10.1001/jama.277.10.813; Tanaka N, 2000, AM J NEURORADIOL, V21, P1095; Udupa JK, 1997, IEEE T MED IMAGING, V16, P598, DOI 10.1109/42.640750; Udupa JK, 2001, ACAD RADIOL, V8, P1116, DOI 10.1016/S1076-6332(03)80723-7; Van Leemput K, 2001, IEEE T MED IMAGING, V20, P677, DOI 10.1109/42.938237; VANLEEMPUT K, 2000, AUTOMATED SEGMENTATI; Vapnik VN, 1998, STAT LEARNING THEORY; Vapnik V.N., 1999, NATURE STAT LEARNING; Vermeer SE, 2003, NEW ENGL J MED, V348, P1215, DOI 10.1056/NEJMoa022066; VIOLA P, 1995, P INT C COMP VIS LOS; Warfield S, 1995, J Image Guid Surg, V1, P326, DOI 10.1002/(SICI)1522-712X(1995)1:6<326::AID-IGS4>3.0.CO;2-C; Warfield SK, 2000, MED IMAGE ANAL, V4, P43, DOI 10.1016/S1361-8415(00)00003-7; Wei XC, 2002, J MAGN RESON IMAGING, V15, P203, DOI 10.1002/jmri.10053; Welti D, 2001, P INF PROC MED IM IP, P438; Williamson JD, 2007, AM J CARDIOL, V99, p112I, DOI 10.1016/j.amjcard.2007.03.029; Wu Y, 2006, NEUROIMAGE, V32, P1205, DOI 10.1016/j.neuroimage.2006.04.211; YU S, 2001, MACRO NANO, P253; Zekry D, 2002, ACTA NEUROPATHOL, V103, P481, DOI 10.1007/s00401-001-0493-5; ZIJDENBOS AP, 1994, IEEE T MED IMAGING, V13, P716, DOI 10.1109/42.363096; Zijdenbos AP, 2002, IEEE T MED IMAGING, V21, P1280, DOI 10.1109/TMI.2002.806283; ZWEIG MH, 1993, CLIN CHEM, V39, P561	62	37	37	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	1076-6332		ACAD RADIOL	Acad. Radiol.	MAR	2008	15	3					300	313		10.1016/j.acra.2007.10.012		14	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	271LD	WOS:000253789000005	
J	Chun, AHW				Chun, Andy Hon Wai			An AI framework for the automatic assessment of e-government forms	AI MAGAZINE			English	Article; Proceedings Paper	Conference on Innovative Applications Artificial Intelligence	JUN 22-26, 2007	Vancouver, CANADA					This article describes the architecture and AI technology behind an XML-based AI framework designed to streamline e-government form processing. The framework performs several crucial assessment and decision support functions, including workflow case assignment, automatic assessment, follow-up action generation, precedent case retrieval, and learning of current practices. To implement these services, several At techniques were used, including rule-based processing, schema-based reasoning, AI clustering, case-based reasoning, data mining, and machine learning. The primary objective or using AI for e-govemment form processing is of course to provide faster and higher quality service as well as ensure that all forms are processed fairly and accurately. With AI, all relevant laws and regulations as well as current practices are guaranteed to be considered and followed. An AI framework has been used to implement an AI module for one or the busiest immigration agencies in the world.	City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China	Chun, AHW (reprint author), City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.						ALLENDOERFER KR, 2004, P EUR 7 EUR C CAS RE, P476; Buchanan BG, 1984, RULE BASED EXPERT SY; CAMPBELL M, 2006, P NIST TRECVID 2006; CHEN KT, 1992, RM1992081 ER U; DUNLAVY DM, 2006, SYSTEM QUERYING CLUS; ESMAILI M, 1996, P 24 INT C VER LARG; FISHER D, 1993, IEEE EXPERT, V8, P51, DOI 10.1109/64.248353; Forgy C., 1977, P 5 INT JOINT C ART, P933; Gardner A., 1987, ARTIFICIAL INTELLIGE; KOLODNER J, 1993, CASEBASED REASONING; Odubiyi J. B., 1997, Proceedings of the First International Conference on Autonomous Agents, DOI 10.1145/267658.267731; Quinlan J. R., 1987, P 10 INT JOINT C ART, P304; RYU TW, 1998, P C SMART ENG SYST D; TABET S, 2000, LECT NOTES COMPUTER, V2112, P103; TURNER EH, 1991, P IEEE OCEANIC ENG S; Turner R.M., 1994, ADAPTIVE REASONING R; Utgoff P. E., 1989, Machine Learning, V4, DOI 10.1023/A:1022699900025; WINSTON P, 1992, LEARNING BUILDING ID, P423; Xu LD, 1996, INT J BIOMED COMPUT, V40, P197, DOI 10.1016/0020-7101(95)01145-5; *ADM REV COUNC, 2004, 46 ADM REV; *CAPT SOFTW CORP, 2002, SWISS TAX OFF PROC M; *HONG KONG GOV, 2004, SPEC ADM REG PEOPL R; *HONG KONG GOV, 2007, SPEC ADM REG PEOPL R; *QUEST MED, 2006, ENT INN; *US BUR CUST BORD, 2005, TARG CTR BRAINS BEH; *US GEN ACC OFF, 2004, HOM SEC SUMM CHALL F; *US HOUS REPR, 1997, SUBC IMM CLAIMS COMM; *VERTM IT GROUP, 2002, ENT CONT MAN NEWS SO; *VERTM IT GROUP, 2003, AUSTR GOV AG IMPR IM; *XINH NEWS AG, 2007, HONG KONG ISSN E PAS	30	0	0	AMER ASSOC ARTIFICIAL INTELL	MENLO PK	445 BURGESS DRIVE, MENLO PK, CA 94025-3496 USA	0738-4602		AI MAG	AI Mag.	SPR	2008	29	1					52	64				13	Computer Science, Artificial Intelligence	Computer Science	279TX	WOS:000254378700006	
J	Na, S; Paek, E; Lee, C				Na, Seungjin; Paek, Eunok; Lee, Cheolju			CIFTER: Automated charge-state determination for peptide tandem mass spectra	ANALYTICAL CHEMISTRY			English	Article							SPECTROMETRY; PROTEOMICS; IDENTIFICATIONS; DATABASE; MS/MS	Tandem mass spectrometry (MS/MS) has become a common and useful tool for analyzing complex protein mixtures. Database search programs are the most popular means for peptide identification from MS/MS spectra. However, estimations of charge states of peptide MS/MS spectra obtained from low-resolution mass spectrometers have not been reliable. They require repetitive database searches and additional analyses of the search results. We propose here an algorithm designed to reliably differentiate doubly charged spectra from triply charged ones. We conducted a rigorous analysis of various spectral features and their effects. We employed the distinguishing features found in our analysis and developed a classifier for multiply charged spectra using a machine learning approach. The test on various data sets showed that our method could be successfully applied independent of experimental setup and mass instrument. Ibis algorithm can be used to prefilter spectra so that only reasonably good spectra are submitted to database search programs, thereby saving considerable time.	[Na, Seungjin; Paek, Eunok] Univ Seoul, Dept Mech & Informat Engn, Seoul, South Korea; [Lee, Cheolju] Korea Inst Sci & Technol, Div Life Sci, Seoul, South Korea	Paek, E (reprint author), Univ Seoul, Dept Mech & Informat Engn, 90 Jeonnong Dong, Seoul, South Korea.	paek@uos.ac.kr					Aebersold R, 2003, NATURE, V422, P198, DOI 10.1038/nature01511; Bern M, 2004, BIOINFORMATICS, V20, P49, DOI 10.1093/bioinformatics/bth947; Colinge J, 2003, PROTEOMICS, V3, P1434, DOI 10.1002/pmic.200300489; ENG JK, 1994, J AM SOC MASS SPECTR, V5, P976, DOI 10.1016/1044-0305(94)80016-2; Frank A, 2005, ANAL CHEM, V77, P964, DOI 10.1021/ac048788h; Hogan JM, 2005, OMICS, V9, P233, DOI 10.1089/omi.2005.9.233; Horn DM, 2000, J AM SOC MASS SPECTR, V11, P320, DOI 10.1016/S1044-0305(99)00157-9; Huang YY, 2005, ANAL CHEM, V77, P5800, DOI 10.1021/ac0480949; Keller Andrew, 2002, OMICS A Journal of Integrative Biology, V6, P207, DOI 10.1089/153623102760092805; Keller A, 2002, ANAL CHEM, V74, P5383, DOI 10.1021/ac025747h; Klammer Aaron A, 2005, Proc IEEE Comput Syst Bioinform Conf, P175; Ma B, 2003, RAPID COMMUN MASS SP, V17, P2337, DOI 10.1002/rcm.1196; Na SJ, 2006, J PROTEOME RES, V5, P3241, DOI 10.1021/pr0603248; Perkins DN, 1999, ELECTROPHORESIS, V20, P3551, DOI 10.1002/(SICI)1522-2683(19991201)20:18<3551::AID-ELPS3551>3.0.CO;2-2; Sadygov RG, 2002, J PROTEOME RES, V1, P211, DOI 10.1021/pr015514r; Schnapp LM, 2006, AM J PATHOL, V169, P86, DOI 10.2353/ajpath.2006.050612; Steen H, 2004, NAT REV MOL CELL BIO, V5, P699, DOI 10.1038/nrm1468; Tabb DL, 2002, J PROTEOME RES, V1, P21, DOI 10.1021/pr015504q	18	11	11	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0003-2700		ANAL CHEM	Anal. Chem.	MAR 1	2008	80	5					1520	1528		10.1021/ac702038q		9	Chemistry, Analytical	Chemistry	268EG	WOS:000253560900032	
J	Savicky, P; Robnik-Sikonja, M				Savicky, Petr; Robnik-Sikonja, Marko			Learning random numbers: A MATLAB anomaly	APPLIED ARTIFICIAL INTELLIGENCE			English	Article							GENERATORS	We describe how dependencies between random numbers generated with some popular pseudo-random number generators can be detected using general purpose machine-learning techniques. This is a novel approach, since usually pseudo-random number generators are evaluated using tests specifically designed for this purpose. Such specific tests (ire more sensitive. Hence, detecting the dependence using machine-learning methods implies that the dependence is indeed very strong. 7, he most important example of a generator, where dependencies may easily be found using our approach, is MATLAB's function rand if the method state is used. This method was the default in MATLAB versions between 5 (1995) and 7.3 (2006b), i.e., for more than 10 years. In order to evaluate the strength of the dependence in it, we used the same machine-teaming tools to detect dependencies in some other random number generators, which are known to be bad or insufficient for large simulations: the infamous RANDU, ANSIC, the oldest generator in C library, minimal standard generator suggested by Park. and Miller (1988), and the rand function in Microsoft C compiler.	[Robnik-Sikonja, Marko] Univ Ljubljana, Fac Comp & Informat Sci, SI-1000 Ljubljana, Slovenia; [Savicky, Petr] Acad Sci Czech Republic, Inst Comp Sci, Prague, Czech Republic	Savicky, P (reprint author), Univ Ljubljana, Fac Comp & Informat Sci, Trzaska 25, SI-1000 Ljubljana, Slovenia.	Marko.Robnik@fri.uni.lj.si					Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; GOLDREICH O, 2000, LECT NOTES PSEUDORAN; GOLDREICH O, 1998, MODERN CRYPTOGRAPHY, V17; Knuth D. E., 1998, ART COMPUTER PROGRAM, V2; LECUYER P, 2006, HDB OPERATIONS RES M; LECUYER P, 2007, ACM T MATH SOFTWARE, V33, P4; L'Ecuyer P, 1999, OPER RES, V47, P159, DOI 10.1287/opre.47.1.159; L'Ecuyer P, 2002, SIAM J SCI COMPUT, V24, P652, DOI 10.1137/S1064827598349033; Matsumoto M., 1998, ACM Transactions on Modeling and Computer Simulation, V8, DOI 10.1145/272991.272995; Panneton F, 2006, ACM T MATH SOFTWARE, V32, P1, DOI 10.1145/1132973.1132974; PARK SK, 1998, COMMUN ACM, V12, P1192; Press WH, 1988, NUMERICAL RECIPES C; R Development Core Team, 2008, LANG ENV STAT COMP; Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714; SAVICKY P, 2006, STRONG NONRANDOM PAT; Wichmann BA, 2006, COMPUT STAT DATA AN, V51, P1614, DOI 10.1016/j.csda.2006.05.019; Witten I. H., 1999, DATA MINING PRACTICA	17	1	1	TAYLOR & FRANCIS INC	PHILADELPHIA	325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA	0883-9514		APPL ARTIF INTELL	Appl. Artif. Intell.	MAR	2008	22	3					254	265		10.1080/08839510701768382		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	282PO	WOS:000254579900005	
J	Rodriguez, B; Perez, O; Garcia, J; Molina, JM				Rodriguez, Blanca; Perez, Oscar; Garcia, Jesus; Molina, Jose M.			Machine learning techniques for acquiring new knowledge in image tracking	APPLIED ARTIFICIAL INTELLIGENCE			English	Article								The purpose of this research is to apply data mining (DM) to an optimized surveillance video system. with the objective of improving tracking robustness and stability. Specifically, the machine learning has been applied to blob extraction and detection, in order to decide whether a detected blob corresponds to a real target or not. Performance is assessed with an Evaluation function, which has been developed for optimizing the video surveillance system. This Evaluation function measures the quality level reached by the tracking system.	[Rodriguez, Blanca; Perez, Oscar; Garcia, Jesus; Molina, Jose M.] Univ Carlos III Madrid, Dept Informat, Madrid 28270, Spain	Molina, JM (reprint author), Univ Carlos III Madrid, Dept Informat, Avda Univ Carlos III,22 Colmenarejo, Madrid 28270, Spain.	jesus.garcia@uc3m.es					Besada JA, 2005, IEEE T AERO ELEC SYS, V41, P1075; BESADA JA, 2001, FUSION 2001 C MONTR; Besada JA, 2004, MACH VISION APPL, V15, P164, DOI 10.1007/s00138-004-0135-8; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679; COHEN I, 1998, DARPA IM UND WORKSH, P217; Faceli K, 2004, APPL INTELL, V20, P199, DOI 10.1023/B:APIN.0000021413.05467.20; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; PEREZ OJ, 2005, 7 EUR WORKSH EV COMP; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Rosin PL, 2003, PATTERN RECOGN LETT, V24, P2345, DOI 10.1016/S0167-8655(03)00060-6; SANKA M, 1999, IMAGE PROCESSING ANA; Witten I. H., 2000, DATA MINING PRACTICA	13	0	0	TAYLOR & FRANCIS INC	PHILADELPHIA	325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA	0883-9514		APPL ARTIF INTELL	Appl. Artif. Intell.	MAR	2008	22	3					266	282		10.1080/08839510701821652		17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	282PO	WOS:000254579900006	
J	Zhang, NL; Yuan, SH; Chen, T; Wang, Y				Zhang, Nevin L.; Yuan, Shihong; Chen, Tao; Wang, Yi			Latent tree models and diagnosis in traditional Chinese medicine	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						machine learning; latent structure models; multidimensional clustering; traditional Chinese medicine; syndrome differentiation		Objective: TCM (traditional Chinese medicine) is an important avenue for disease prevention and treatment for the Chinese people and is gaining popularity among others. However, many remain skeptical and even critical of TCM because of a number of its shortcomings. One key shortcoming is the tack of objective diagnosis standards. We endeavor to alleviate this shortcoming using machine learning techniques. Method: TCM diagnosis consists of two steps, patient information gathering and syndrome differentiation. We focus on the tatter. When viewed as a black box, syndrome differentiation is simply a classifier that classifies patients into different classes based on their symptoms. A fundamental question is: do those classes exist in reality? To seek an answer to the question from the machine learning perspective, one would naturally use cluster analysis. Previous clustering methods are unable to cope with the complexity of TCM. We have therefore developed a new clustering method in the form of latent tree models. We have conducted a case study where we first collected a data set about a TCM domain called KIDNEY DEFICIENCY and then used latent tree models to analyze the data set. Results: Our analysis has found natural clusters in the data set that correspond well to TCM syndrome types. This is an important discovery because (1) it provides statistical validation to TCM syndrome types and (2) it suggests the possibility of establishing objective and quantitative diagnosis standards for syndrome differentiation. In this paper, we provide a summary of research work on latent tree models and report the aforementioned case study. (c) 2007 Elsevier B.V. All rights reserved.	[Zhang, Nevin L.; Chen, Tao; Wang, Yi] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Kowloon, Hong Kong, Peoples R China; [Yuan, Shihong] Beijing Univ Tradit Chinese Med, Dept Chinese Med Diagnost, Beijing 100029, Peoples R China	Zhang, NL (reprint author), Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Clear Water Bay Rd, Kowloon, Hong Kong, Peoples R China.	lzhang@cse.ust.hk					Bartholomew D. J., 1999, LATENT VARIABLE MODE; Chickering DM, 2002, J MACH LEARN RES, V2, P445, DOI 10.1162/153244302760200696; Dempster A. P., 1997, J ROYAL STAT SOC B, V39, P1; Durbin R., 1998, BIOL SEQUENCE ANAL P; Feng Y, 2006, ARTIF INTELL MED, V38, P219, DOI 10.1016/j.artmed.2006.07.005; Friedman N., 1997, P 14 INT C MACH LEAR, P125; GEIGER D, 1996, P 12 ANN C UNC ART I, P158; GOODMAN LA, 1974, BIOMETRIKA, V61, P215, DOI 10.1093/biomet/61.2.215; Green P.J, 1999, ENCY STAT SCI, V3, P578; HAGENAARS JA, 1988, SOCIOL METHOD RES, V16, P379, DOI 10.1177/0049124188016003002; KOCKA T, 2002, P 18 C UNC ART INT U, P267; LAURITZEN SL, 1995, COMPUT STAT DATA AN, V19, P191, DOI 10.1016/0167-9473(93)E0056-A; Lazarsfeld P, 1968, LATENT STRUCTURE ANA; LIANG MX, 1998, PERPLEXITY TCM SYNDR; Pearl J., 1988, PROBABILISTIC REASON; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Sung JJY, 2004, ALIMENT PHARM THERAP, V20, P1205, DOI 10.1111/j.1365-2036.2004.02242.x; Uebersax J., PRACTICAL GUIDE LOCA; VANDERPUTTEN P, 2002, COIL CHALLENGE 2000; Vermunt J. K., 2002, APPL LATENT CLASS AN, P89, DOI DOI 10.1017/CBO9780511499531.004; WANG HX, 1999, CURRENT STATE FUTURE; YAN SL, 2001, J CHENGDU U CHIN MED, V24, P56; Yang W., 1998, DIAGNOSTICS TRADITIO; Zhang NL, 2004, PROC INT C TOOLS ART, P585; Zhang NL, 2004, J MACH LEARN RES, V5, P697; Zhang NL, 2004, J ARTIF INTELL RES, V21, P1; ZHANG NL, 2002, P AAAI02, P230; ZHUWE D, 1995, DIAGNOSTICS TRADITIO; *CHIN STAT BUR TEC, 1997, GBT1675121997 CHIN S; *WHO, WHO TRAD MED STRAT	30	15	18	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657		ARTIF INTELL MED	Artif. Intell. Med.	MAR	2008	42	3					229	245		10.1016/j.artmed.2007.10.004		17	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	279UD	WOS:000254379400005	
J	Chu, A; Ahn, H; Halwan, B; Kalmin, B; Artifon, ELA; Barkun, A; Lagoudakis, MG; Kumar, A				Chu, Adrienne; Ahn, Hongshik; Halwan, Bhawna; Kalmin, Bruce; Artifon, Everson L. A.; Barkun, Alan; Lagoudakis, Michail G.; Kumar, Atul			A decision support system to facilitate management of patients with acute gastrointestinal bleeding	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						class prediction; cross validation; gastrointestinal bleeding; machine learning	ARTIFICIAL NEURAL-NETWORK; CLINICAL GUIDELINE; HOSPITAL LENGTH; HEMORRHAGE; RISK; PREDICTORS; MORTALITY; DIAGNOSIS; ENDOSCOPY; MODELS	Objective: To develop a model to predict the bleeding source and identify the cohort amongst patients with acute gastrointestinal bleeding (GIB) who require urgent intervention, including endoscopy. Patients with acute GIB, an unpredictable event, are most commonly evaluated and managed by non-gastroenterologists. Rapid and consistently reliable risk stratification of patients with acute GIB for urgent endoscopy may potentially improve outcomes amongst such patients by targeting scarce health-care resources to those who need it the most. Design and methods: Using ICD-9 codes for acute GIB, 189 patients with acute GIB and all. available data variables required to develop and test models were identified from a hospital medical records database. Data on 122 patients was utilized for development of the model and on 67 patients utilized to perform comparative analysis of the models. Clinical data such as presenting signs and symptoms, demographic data, presence of co-morbidities, laboratory data and corresponding endoscopic diagnosis and outcomes were collected. Clinical data and endoscopic diagnosis collected for each patient was utilized to retrospectively ascertain optimal management for each patient. Clinical presentations and corresponding treatment was utilized as training examples. Eight mathematical models including artificial neural network (ANN), support vector machine (SVM), k-nearest neighbor, linear discriminant analysis (LDA), shrunken centroid (SC), random forest (RF), logistic regression, and boosting were trained and tested. The performance of these models was compared using standard statistical analysis and ROC curves. Results: Overall the random forest model best predicted the source, need for resuscitation, and disposition with accuracies of approximately 80% or higher (accuracy for endoscopy was greater than 75%). The area under ROC curve for RF was greater than 0.85, indicating excellent performance by the random forest model Conclusion: While most mathematical models are effective as a decision support system for evaluation and management of patients with acute GIB, in our testing, the RF model consistently demonstrated the best performance. Amongst patients presenting with acute GIB, mathematical models may facilitate the identification of the source of GIB, need for intervention and allow optimization of care and healthcare resource allocation; these however require further validation. (c) 2007 Elsevier B.V. All rights reserved.	[Kumar, Atul] SUNY Stony Brook, US Dept Vet Affairs, Stony Brook, NY 11794 USA; [Chu, Adrienne; Ahn, Hongshik] SUNY Stony Brook, Dept Appl Math & Stat, Stony Brook, NY 11794 USA; [Halwan, Bhawna] Suny Downstate Med Ctr, Brooklyn, NY 11203 USA; [Kalmin, Bruce] Med Univ S Carolina, Div Gastroenterol, Charleston, SC 29425 USA; [Artifon, Everson L. A.] Univ Sao Paulo, Sch Med, Sao Paulo, Brazil; [Barkun, Alan] McGill Univ, Montreal, PQ H3A 2T5, Canada; [Lagoudakis, Michail G.] Tech Univ Crete, Intelligent Syst Lab, Dept Elect & Comp Engn, Kounoupidiana 73100, Chania Hellas, Greece	Kumar, A (reprint author), SUNY Stony Brook, US Dept Vet Affairs, Stony Brook, NY 11794 USA.	atul.kumar2@va.gov	Lagoudakis, Michail/C-5145-2008				Adler DG, 2004, GASTROINTEST ENDOSC, V60, P497; Ahn H, 2007, COMPUT STAT DATA AN, V51, P6166, DOI 10.1016/j.csda.2006.12.043; BAMBER D, 1975, J MATH PSYCHOL, V12, P387, DOI 10.1016/0022-2496(75)90001-2; Baradarian R, 2004, AM J GASTROENTEROL, V99, P619, DOI 10.1111/j.1572-0241.2004.04073.x; Barkun A, 2003, ANN INTERN MED, V139, P843; Blatchford O, 2000, LANCET, V356, P1318, DOI 10.1016/S0140-6736(00)02816-6; BORDLEY DR, 1985, JAMA-J AM MED ASSOC, V253, P3282, DOI 10.1001/jama.253.22.3282; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; CHONG CF, 2003, P AMIA S         NOV, P160; Corley DA, 1998, AM J GASTROENTEROL, V93, P336; Das A, 2003, LANCET, V362, P1261, DOI 10.1016/S0140-6736(03)14568-0; Das A, 2004, GASTROINTEST ENDOSC, V60, P85, DOI 10.1016/S0016-5107(04)01291-X; ETTA GH, 2004, GASTROINTEST ENDOSC, V59, P402; Hay JA, 1997, JAMA-J AM MED ASSOC, V278, P2151, DOI 10.1001/jama.278.24.2151; Hay JA, 1996, AM J MED, V100, P313, DOI 10.1016/S0002-9343(97)89490-9; KATULA SZ, 2003, S AFR MED J, V93, P286; Kennedy RL, 1997, COMPUT METH PROG BIO, V52, P93, DOI 10.1016/S0169-2607(96)01782-8; KLEBT F, 2004, INT J COLORECTAT DIS, P19; Lisboa PJG, 2002, NEURAL NETWORKS, V15, P11, DOI 10.1016/S0893-6080(01)00111-3; Lund LH, 2004, ARCH INTERN MED, V164, P1698, DOI 10.1001/archinte.164.15.1698-a; Molinaro AM, 2005, BIOINFORMATICS, V21, P3301, DOI 10.1093/bioinformatics/bti499; MORTENSEN PB, 1994, DAN MED BULL, V41, P237; Palmer KR, 2002, GUT, V51, P1; Prakash C, 2003, GASTROINTEST ENDOSC, V58, P330, DOI 10.1016/S0016-5107(03)00003-8; PRAKASH C, 2003, GASTROINTEST ENDOSC, V58, P409; Quirk DM, 1997, GASTROENTEROLOGY, V113, P1443, DOI 10.1053/gast.1997.v113.pm9352845; Rockall TA, 1996, LANCET, V347, P1138, DOI 10.1016/S0140-6736(96)90607-8; ROCKALL TA, 1995, BRIT MED J, V311, P222; Rockall TA, 1996, GUT, V38, P316, DOI 10.1136/gut.38.3.316; Rosenblatt KP, 2004, ANNU REV MED, V55, P97, DOI 10.1146/annurev.med.55.091902.105237; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Selaru FM, 2002, GASTROENTEROLOGY, V122, P606, DOI 10.1053/gast.2002.31904; Strate LL, 2003, ARCH INTERN MED, V163, P838, DOI 10.1001/archinte.163.7.838; Terdiman JP, 1997, AM J GASTROENTEROL, V92, P1805; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Timmerman D, 1999, ULTRASOUND OBST GYN, V13, P17, DOI 10.1046/j.1469-0705.1999.13010017.x; VAPNIK V, 1995, NATURE STAT EARNING; VETAYOS FS, 2004, CLIN GASTROENTEROL H, V2, P485; Zaragoza Marcet A, 2002, Rev Esp Enferm Dig, V94, P139; ZIMMERMAN J, 1995, SCAND J GASTROENTERO, V30, P327, DOI 10.3109/00365529509093285	41	15	15	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657		ARTIF INTELL MED	Artif. Intell. Med.	MAR	2008	42	3					247	259		10.1016/j.artmed.2007.10.003		13	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	279UD	WOS:000254379400006	
J	Flener, P; Schmid, U				Flener, Pierre; Schmid, Ute			An introduction to inductive programming	ARTIFICIAL INTELLIGENCE REVIEW			English	Article						Inductive programming; Machine learning	LOGIC PROGRAMS; INFERENCE; ACHIEVEMENTS; PROSPECTS; EXAMPLES; SYSTEMS	The research field of inductive programming is concerned with the design of algorithms for learning computer programs with complex flow of control (typically recursive calls) from incomplete specifications such as examples. We introduce a basic algorithmic approach for inductive programming and illustrate it with three systems: dialogs learns logic programs by combining inductive and abductive reasoning; the classical thesys system and its extension igor1 learn functional programs based on a recurrence detection mechanism in traces; igor2 learns functional programs over algebraic data-types making use of constructor-term rewriting systems. Furthermore, we give a short history of inductive programming, discuss related approaches, and give hints about current applications and possible future directions of research.	[Schmid, Ute] Otto Friedrich Univ Bamberg, Fac Informat Syst & Appl Comp Sci, D-96045 Bamberg, Germany; [Flener, Pierre] Uppsala Univ, Dept Informat Technol, S-75105 Uppsala, Sweden	Schmid, U (reprint author), Otto Friedrich Univ Bamberg, Fac Informat Syst & Appl Comp Sci, Feldkirchenstr 21, D-96045 Bamberg, Germany.	Pierre.Flener@it.uu.se; ute.schmid@uni-bamberg.de					Angluin D., 1988, Machine Learning, V2, DOI 10.1007/BF00116828; BACKUS J, 1981, FORMALIZATION PROGRA, V107, P1; Biermann A., 1984, AUTOMATIC PROGRAM CO; Biermann A. W., 1984, AUTOMATIC PROGRAM CO, P307; BIERMANN AW, 1972, ARTIF INTELL, V3, P181, DOI 10.1016/0004-3702(72)90048-3; BIERMANN AW, 1978, IEEE T SYST MAN CYB, V8, P585, DOI 10.1109/TSMC.1978.4310035; BIERMANN AW, 1992, ENCY ARTIFICIAL INTE, P18; CYPHER A, 1993, WATCH WHAT I DO PROG, P205; FIELD AJ, 1988, FUNCTIONAL PROGAMMIN; Flener P, 2000, J SYMB COMPUT, V30, P93, DOI 10.1006/jsco.1999.0348; Flener P, 1999, J LOGIC PROGRAM, V41, P141, DOI 10.1016/S0743-1066(99)00028-X; Flener P, 2002, LECT NOTES ARTIF INT, V2407, P310; Flener P, 1997, LECT NOTES ARTIF INT, V1314, P175; Flener P., 1995, LOGIC PROGRAM SYNTHE; FLENER P, 2001, AUTOMAT SOFTW ENG, V8, P131, DOI 10.1023/A:1008797606116; GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5; HOFMANN M, 2008, AUTOMATED CONSTRUCTI; Hofmann M, 2008, LECT NOTES ARTIF INT, V5243, P78, DOI 10.1007/978-3-540-85845-4_10; Kitzelmann E, 2006, J MACH LEARN RES, V7, P429; KITZELMANN E, 2007, P WORKSH APPR APPL I; Lieberman H., 2001, YOUR WISH IS MY COMM; LOWRY ML, 1991, AUTOMATIC SOFTWARE D; MANNA Z, 1992, IEEE T SOFTWARE ENG, V18, P674, DOI 10.1109/32.153379; Mitchell T, 1997, MACHINE LEARNING; Muggleton S., 1990, P 1 C ALG LEARN THEO, P368; MUGGLETON S, 2000, P 17 INT C MACH LEAR, P631; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; OLSSON JR, 2003, P INT C COGN SCI U N, P507; OLSSON R, 1995, ARTIF INTELL, V74, P55, DOI 10.1016/0004-3702(94)00042-Y; Quinlan JR, 1996, J ARTIF INTELL RES, V5, P139; QUINLAN JR, 1995, NEW GENERAT COMPUT, V13, P287; Rao MRKK, 2004, LECT NOTES ARTIF INT, V3244, P69; RICH C, 1993, ADV COMPUTERS, V37; Schmid U, 2004, Proceedings of the IASTED International Conference on Artificial Intelligence and Applications, Vols 1and 2, P252; SCHMID U, 1997, LNAI, V2654; SCHMID U, 1998, LECT NOTES ARTIF INT, V1398, P214; Schmid U., 2000, Proceedings of the Fifth International Conference on Artificial Intelligence Planning and Scheduling; SCHRODL S, 1999, P 23 ANN GERM C ART, V1701, P171; Shapiro E.Y., 1983, ALGORITHMIC PROGRAM; SHAVLIK JW, 1990, MACH LEARN, V5, P39, DOI 10.1023/A:1022659708512; SMITH DR, 1985, ARTIF INTELL, V27, P43, DOI 10.1016/0004-3702(85)90083-9; STAHL S, 1995, J GRAPH THEOR, V20, P1, DOI 10.1002/jgt.3190200102; Stoy J. E., 1977, DENOTATIONAL SEMANTI; SUMMERS PD, 1977, J ACM, V24, P161, DOI 10.1145/321992.322002; WYSOTZKI F, 1983, P 8 INT JOINT C ART, P409; Zeugmann T, 2008, THEOR COMPUT SCI, V397, P4, DOI 10.1016/j.tcs.2008.02.021	46	4	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0269-2821		ARTIF INTELL REV	Artif. Intell. Rev.	MAR	2008	29	1					45	62		10.1007/s10462-009-9108-7		18	Computer Science, Artificial Intelligence	Computer Science	476FM	WOS:000268424100002	
J	Blanzieri, E; Bryl, A				Blanzieri, Enrico; Bryl, Anton			A survey of learning-based techniques of email spam filtering	ARTIFICIAL INTELLIGENCE REVIEW			English	Review						Spam filtering; Machine learning		Email spam is one of the major problems of the today's Internet, bringing financial damage to companies and annoying individual users. Among the approaches developed to stop spam, filtering is an important and popular one. In this paper we give an overview of the state of the art of machine learning applications for spam filtering, and of the ways of evaluation and comparison of different filtering methods. We also provide a brief description of other branches of anti-spam protection and discuss the use of various approaches in commercial and non-commercial anti-spam software solutions.	[Bryl, Anton] Univ Trent, ICT Int Doctorate Sch, Trento, Italy; [Blanzieri, Enrico] Univ Trent, Dept Informat & Commun Technol, Trento, Italy	Bryl, A (reprint author), Univ Trent, ICT Int Doctorate Sch, Trento, Italy.	ilnur@tut.by					Agrawal B, 2005, P INT C COMM SEOUL S, V3, P1588; ALBRECHT K, 2005, P 2 C EM ANT CEAS 20; Androutsopoulos I., 2004, 20042 NCSR DEM; Androutsopoulos I., 2000, P WORKSH MACH LEARN, P1; Androutsopoulos I., 2000, P WORKSH MACH LEARN, P9; ANDROUTSOPOULOS I, 2005, P 2 C EM ANT CEAS 20; Androutsopoulos I., 2000, P 23 ANN INT ACM SIG, P160, DOI 10.1145/345508.345569; Aradhye H. B., 2005, P 8 INT C DOC AN REC, V2, P914; Blanzieri E., 2007, P 4 C EM ANT CEAS 20, P5; Boykin PO, 2005, COMPUTER, V38, P61, DOI 10.1109/MC.2005.132; Bratko A, 2006, J MACH LEARN RES, V7, P2673; CAPTCHA, 2005, CAPTCHA PROJ; Carroll S.M., 2001, LIVING REV RELATIV, V4, P1; CHAN J, 2004, P 9 AUSTR DOC COMP S; Chirita P.A., 2005, P 14 ACM INT C INF K, P373, DOI 10.1145/1099554.1099671; CHUAN Z, 2005, ACM SIGOPS OPERATING, V39, P34, DOI DOI 10.1145/1044552.1044555; COHEN W, 1996, P 1996 AAAI SPRING S; Cormack G., 2005, TREC 2005 SPAM TRACK; Cormack G.V., 2005, P 2 C EM ANT CEAS 20; CORMACK GV, 2006, P 3 C EM ANT CEAS 20; Cukier Wendy L., 2006, P 39 ANN HAW INT C S; Damiani E., 2004, Proceedings. Fourth International Conference on Peer-to-Peer Computing, DOI 10.1109/PTP.2004.1334945; de Lange T, 2004, BMC GASTROENTEROL, V4, DOI 10.1186/1471-230X-4-9; Drake C., 2004, P 1 C EM ANT CEAS 20; DREDZE M, 2007, P 4 C EM ANT CEAS 20; Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; Duan Z., 2005, P 11 INT C PAR DISTR, V2, P255; Dwork C., 1992, ADV CRYPTOLOGY CRYPT, P139; Fawcett T., 2003, KDD EXPLORATIONS, V5, P140; FECYK G, 2003, DESIGNATED MAILERS P; Fumera G, 2006, J MACH LEARN RES, V7, P2699; GARG A, 2006, AINA 2006; Golbeck J., 2004, CEAS 2004; GOMES LH, 2004, IMC 04 P 4 ACM SIGCO, P356; GOODMAN J, 2004, P 1 C EM ANT CEAS 20; Goodman J, 2007, COMMUN ACM, V50, P25; GOODMAN J, 2006, P 3 C EM ANT CEAS 20; GOODMAN J, 2004, EC 04; Graham P., 2002, PLAN SPAM; GRAHAM P, 2003, BETTER BAYESIAN FILT; GRIMES GA, 2007, COMMUNICATIONF ACM, V50, P55; Harris E., 2003, NEXT STEP SPAM CONTR; HERSHKOP S, 2006, THESIS; HULTEN G, 2004, P 1 C EM ANT CEAS 20; International Telecommunication Union (ITU), 2005, ITU SURV ANT LEG WOR; Joachims T., 1997, P 14 INT C MACH LEAR, P143; JUNG J, 2004, IMC 04 P 4 ACM SIGCO, P370; KLIMT B, 2004, P 1 C EM ANT CEAS 20; Kuipers B. J., 2005, Proceedings. 25th IEEE International Conference on Distributed Computing Systems Workshops; KUNLUN L, 2002, MACH LEARN CYBERN, V3, P1198; Lai C.C., 2004, HYBRID INTELL SYST, P44; Lazzari L., 2005, Proceedings. Fourteenth IEEE International Workshops on Enabling Technologies Infrastructure for Collaborative Enterprises; LEE H, 2005, P 2 C EM ANT CEAS 20; LEIBA B, 2005, P 2 C EM ANT CEAS 20; LEVINE J, 2004, LIGHTWEIGHT MTA AUTH; LI K, 2006, SIGMETRICS PERFORM E, V34, P347; LI K, 2004, P 1 C EM ANT CEAS 20; LOWD D, 2005, P 2 C EM ANT CEAS 20; LUGARESI N, 2004, P 1 C EM ANT CEAS 20; LUO X, 2005, P IEEE INT JOINT C N, V4, P2571; MEDLOCK B, 2005, ADAPTIVE APPROACH SP; MEDLOCK B, 2006, P 3 C EM ANT CEAS 20; METSIS V, 2006, P 3 C EM ANT CEAS 20; MICHELAKIS E, 2004, P 1 C EM ANT CEAS 20; MO G, 2006, IAT 06, P428; MOUSTAKAS E, 2005, P 2 C EM ANT CEAS 20; Nagamalai D, 2007, MUE: 2007 International Conference on Multimedia and Ubiquitous Engineering, Proceedings, P97; O'Brien C., 2003, P 1 INT S INF COMM T, P291; PANTEL P, 1998, LEARNING TEXT CATEGO; PARK SY, 2006, ICACT 2006, V2; PRINCE M, 2005, P 2 C EM ANT CEAS 20; PU C, 2006, P 3 C EM ANT CEAS 20; Ramachandran A., 2006, SIGCOMM 06; RIGOUTSOS I, 2004, P 1 C EM ANT CEAS 20; Sahami M., 1998, LEARNING TEXT CATEGO; Saito T, 2005, ACTA HORTIC, P57; Sakkis G, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P44; Sakkis G, 2003, INFORM RETRIEVAL, V6, P49, DOI 10.1023/A:1022948414856; SASAKI M, 2005, P 2005 INT C CYB, P316; SCHIAVONE V, 2003, TRUSTED EMAIL OPEN S; Sculley D., 2007, P 30 ANN INT ACM SIG, P415, DOI 10.1145/1277741.1277813; SELTZER L, 2003, EWEEK; SENDER ID, 2004, SENDER ID TECHNOLOGY; SIPONEN M, 2006, P HICSS 06, P6; SOONTHORNPHISAJ N, 2002, SIGNAL PROCESS, V2, P1096; Twining R.D., 2004, HPL20045R1; Wang XL, 2005, Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9, P5716; WANG Z, 2007, P 4 C EM ANT CEAS 20; WITTEL G, 2004, P 1 C EM ANT CEAS 20; Woitaszek M., 2003, Proceedings 2003 Symposium on Applications and the Internet, DOI 10.1109/SAINT.2003.1183045; Wu C., 2005, IEEE INT C IMAGE PRO, V3, P509; Yamai N., 2005, Proceedings. The 2005 Symposium on Applications and the Internet; YEH CY, 2005, P IEEE INT C SYST MA, V4, P3872; YIH WT, 2006, P 3 C EM ANT CEAS 20; Zhang L., 2004, ACM T ASIAN LANGUAGE, V3, P243, DOI 10.1145/1039621.1039625; ZHANG L, 2003, P 20 INT C COMP PROC, P446; Zhao WQ, 2005, Proceedings of the 2005 International Conference on Active Media Technology (AMT 2005), P403; ZHOU F, 2003, P ACM IFIP USENIX IN; Zhou Y., 2005, P 17 IEEE INT C TOOL, P302; ZINMAN A, 2007, P 4 C EM ANT CEAS 20; ZORKADIS V, 2005, POC IEEE INT JOINT C, V1, P179; *FERRISRESEARCH, 2005, 409 FERRISRESEARCH; *HONEYPOT, 2004, PROJ HON POT DISTR S; *MAAWG, 2006, EM METR REP 3 4 QUAR; *SPAMHAUS, 2005, DEF SPAM; *SPAMHAUS, 2003, SPAM DEF LEG GAM; 2001, SPAM DEFINED	107	14	16	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0269-2821		ARTIF INTELL REV	Artif. Intell. Rev.	MAR	2008	29	1					63	92		10.1007/s10462-009-9109-6		30	Computer Science, Artificial Intelligence	Computer Science	476FM	WOS:000268424100003	
J	Borne, KD				Borne, K. D.			A machine learning classification broker for the LSST transient database	ASTRONOMISCHE NACHRICHTEN			English	Article; Proceedings Paper	Workshop on Hot-Wiring the Transient Universe	JUN 04-07, 2007	Tucson, AZ	VOEvent Working Grp, Heterogeneous Telescope Networks		astronomical databases : miscellaneous; methods : data analysis; methods : statistical		We describe the largest data-producing astronomy project in the coming decade - the LSST (Large Synoptic Survey Telescope). The enormous data output, database contents, knowledge, discovery, and community science expected from this project will impose massive data challenges on the astronomical research community. One of these challenge areas is the rapid machine learning, data mining, and classification of all novel astronomical events from each 3-gigapixel (6-GB) image obtained every 20 seconds throughout every night for the project duration of 10 years. We describe these challenges and a particular implementation of a classification broker for this data fire hose. (C) 2008 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim.	George Mason Univ, Dept Computat & Data Sci, Fairfax, VA 22030 USA	Borne, KD (reprint author), George Mason Univ, Dept Computat & Data Sci, MS 6A2, Fairfax, VA 22030 USA.	kborne@gmu.edu					BORNE K, 2006, P IEEE SPAC MISS CHA; BORNE KD, 2007, IN PRESS NEXT GENERA; BORNE KD, 2006, EOS T AGU S, V87; Bose R, 2006, LECT NOTES COMPUT SC, V4145, P193; GRAY J, 2004, MSRTR2004110; MAHOOTIAN F, 2007, IN PRESS WORLD FUTUR; McDowell JC, 2004, IEEE SPECTRUM, V41, P35, DOI 10.1109/MSPEC.2004.1318181; VANAHN L, 2004, HUMAN FACTORS COMPUT, P319	8	5	5	WILEY-V C H VERLAG GMBH	WEINHEIM	PO BOX 10 11 61, D-69451 WEINHEIM, GERMANY	0004-6337		ASTRON NACHR	Astro. Nachr.	MAR	2008	329	3					255	258		10.1002/asna.200710946		4	Astronomy & Astrophysics	Astronomy & Astrophysics	282CW	WOS:000254546200008	
J	Mahabal, A; Djorgovski, SG; Turmon, M; Jewell, J; Williams, RR; Drake, AJ; Graham, MG; Donalek, C; Glikman, E				Mahabal, A.; Djorgovski, S. G.; Turmon, M.; Jewell, J.; Williams, R. R.; Drake, A. J.; Graham, M. G.; Donalek, C.; Glikman, E.		Palomar-Quest Team	Automated probabilistic classification of transients and variables	ASTRONOMISCHE NACHRICHTEN			English	Article; Proceedings Paper	Workshop on Hot-Wiring the Transient Universe	JUN 04-07, 2007	Tucson, AZ	VOEvent Working Grp, Heterogeneous Telescope Networks		astronomical databases : miscellaneous; methods : data analysis; methods : statistical; surveys		There is an increasing number of large, digital, synoptic sky surveys, in which repeated observations are obtained over large areas of the sky in multiple epochs. Likewise, there is a growth in the number of (often automated or robotic) follow-up facilities with varied capabilities in terms of instruments, depth, cadence, wavelengths, etc., most of which are geared toward some specific astrophysical phenomenon. As the number of detected transient events grows, an automated, probabilistic classification of the detected variables and transients becomes increasingly important, so that an optimal use can be made of follow-up facilities, without unnecessary duplication of effort. We describe a methodology now under development for a prototype event classification system; it involves Bayesian and Machine Learning classifiers, automated incorporation of feedback from follow-up observations, and discriminated or directed follow-up requests. This type of methodology may be essential for the massive synoptic sky surveys in the future. (C) 2008 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim.	[Mahabal, A.; Djorgovski, S. G.; Williams, R. R.; Drake, A. J.; Graham, M. G.; Donalek, C.; Glikman, E.] CALTECH, Pasadena, CA 91125 USA; [Turmon, M.; Jewell, J.] Jet Propuls Lab, Pasadena, CA USA	Mahabal, A (reprint author), CALTECH, Pasadena, CA 91125 USA.	aam@astro.caltech.edu					Cover TM, 1991, ELEMENTS INFORM THEO; Cristianini N., 2000, INTRO SUPPORT VECTOR; DJORGOVSKI SG, 2006, PATTERN RECOGN, P856; Djorgovski SG, 2008, ASTRON NACHR, V329, P263, DOI 10.1002/asna.200710948; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Fan RE, 2005, J MACH LEARN RES, V6, P1889; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; John G. H., 1995, Uncertainty in Artificial Intelligence. Proceedings of the Eleventh Conference (1995); Loredo T.L., 2003, STAT CHALLENGES MODE, P57; Ripley B. D, 1996, PATTERN RECOGNITION; SCHOLKOPF B, 2001, LEARNING KERNELS SVM; Silverman B.W., 1986, DENSITY ESTIMATION S; Turmon M, 2002, ASTROPHYS J, V568, P396, DOI 10.1086/338681; Vapnik V. N, 1995, NATURE STAT LEARNING	14	18	18	WILEY-V C H VERLAG GMBH	WEINHEIM	PO BOX 10 11 61, D-69451 WEINHEIM, GERMANY	0004-6337		ASTRON NACHR	Astro. Nachr.	MAR	2008	329	3					288	291		10.1002/asna.200710943		4	Astronomy & Astrophysics	Astronomy & Astrophysics	282CW	WOS:000254546200018	
J	Tetko, IV; Rodchenkov, IV; Walter, MC; Rattei, T; Mewes, HW				Tetko, Igor V.; Rodchenkov, Igor V.; Walter, Mathias C.; Rattei, Thomas; Mewes, Hans-Werner			Beyond the best match: machine learning annotation of protein sequences by integration of different sources of information	BIOINFORMATICS			English	Article							FUNCTION PREDICTION; NEURAL-NETWORK; AUTOMATIC ANNOTATION; VARIABLE SELECTION; SORTING SIGNALS; GENE ONTOLOGY; DATABASE; CLASSIFICATION; GENOMES; ALGORITHM	Motivation: Accurate automatic assignment of protein functions remains a challenge for genome annotation. We have developed and compared the automatic annotation of four bacterial genomes employing a 5-fold cross-validation procedure and several machine learning methods. Results: The analyzed genomes were manually annotated with FunCat categories in MIPS providing a gold standard. Features describing a pair of sequences rather than each sequence alone were used. The descriptors were derived from sequence alignment scores, InterPro domains, synteny information, sequence length and calculated protein properties. Following training we scored all pairs from the validation sets, selected a pair with the highest predicted score and annotated the target protein with functional categories of the prototype protein. The data integration using machine-learning methods provided significantly higher annotation accuracy compared to the use of individual descriptors alone. The neural network approach showed the best performance. The descriptors derived from the InterPro domains and sequence similarity provided the highest contribution to the method performance. The predicted annotation scores allow differentiation of reliable versus non-reliable annotations. The developed approach was applied to annotate the protein sequences from 180 complete bacterial genomes.	[Tetko, Igor V.; Rodchenkov, Igor V.; Walter, Mathias C.; Mewes, Hans-Werner] German Res Ctr Environm Hlth GmbH, Helmholtz Zentrum Munchen, Inst Bioinformat & Syst Biol, D-85764 Neuherberg, Germany; [Rattei, Thomas; Mewes, Hans-Werner] Tech Univ Munich, Wissensch Zentrum Weihenstephan, Dept Genome Oriented Bioinformat, D-85350 Freising Weihenstephan, Germany	Tetko, IV (reprint author), German Res Ctr Environm Hlth GmbH, Helmholtz Zentrum Munchen, Inst Bioinformat & Syst Biol, Ingolstadter Landstr 1, D-85764 Neuherberg, Germany.		Tetko, Igor/B-1540-2010; Rattei, Thomas/F-1366-2011; Walter, Mathias/B-8837-2013	Tetko, Igor/0000-0002-6855-0012; Walter, Mathias/0000-0003-3012-2626			Abascal F, 2003, PROTEINS, V53, P683, DOI 10.1002/prot.10449; ALTSCHUL SF, 1997, NUCLEIC ACIDS RES, V25, P3402; Andrade MA, 1999, BIOINFORMATICS, V15, P391, DOI 10.1093/bioinformatics/15.5.391; Arnold R, 2005, BIOINFORMATICS, V21, P42, DOI 10.1093/bioinformatics/bti1107; AZUAJE F, 2006, P IEEE ICDM 2006 WOR; Bairoch A, 2005, NUCLEIC ACIDS RES, V33, pD154, DOI 10.1093/nar/gki070; Barutcuoglu Z, 2006, BIOINFORMATICS, V22, P830, DOI 10.1093/bioinformatics/btk048; Bendtsen JD, 2004, J MOL BIOL, V340, P783, DOI 10.1016/j.jmb.2004.05.028; Biswas Margaret, 2002, Brief Bioinform, V3, P285, DOI 10.1093/bib/3.3.285; Ashburner M, 2000, NAT GENET, V25, P25; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Cilibrasi R, 2005, IEEE T INFORM THEORY, V51, P1523, DOI 10.1109/TIT.2005.844059; Clare A, 2006, BIOINFORMATICS, V22, P1130, DOI 10.1093/bioinformatics/btl051; Clare A., 2003, BIOINFORMATICS, V19, P42; Enright AJ, 2002, NUCLEIC ACIDS RES, V30, P1575, DOI 10.1093/nar/30.7.1575; Friedberg I, 2006, BRIEF BIOINFORM, V7, P225, DOI 10.1093/bib/bbl004; Frishman D, 1997, PROTEINS, V27, P329, DOI 10.1002/(SICI)1097-0134(199703)27:3<329::AID-PROT1>3.0.CO;2-8; Frishman D, 2007, CHEM REV, V107, P3448, DOI 10.1021/cr068303k; Jensen LJ, 2003, BIOINFORMATICS, V19, P635, DOI 10.1093/bioinformatics/btg036; Jensen LJ, 2002, J MOL BIOL, V319, P1257, DOI 10.1016/S0022-2836(02)00379-0; Kaplan N, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-196; Kocsor A, 2006, BIOINFORMATICS, V22, P407, DOI 10.1093/bioinformatics/bti806; Kolesov G, 2001, J MOL BIOL, V311, P639, DOI 10.1006/jmbi.2001.4701; Krebs WG, 2004, BIOINFORMATICS, V20, P1066, DOI 10.1093/bioinformatics/bth039; Kretschmann E, 2001, BIOINFORMATICS, V17, P920, DOI 10.1093/bioinformatics/17.10.920; Krogh A, 2001, J MOL BIOL, V305, P567, DOI 10.1006/jmbi.2000.4315; Lanckriet GRG, 2004, BIOINFORMATICS, V20, P2626, DOI 10.1093/bioinformatics/bth294; LeCun Y, 1990, ADV NEURAL INFORMATI, V2, P598; Levy ED, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-302; Lin D, 1998, P 15 INT C MACH LEAR, P296; Linding R, 2003, NUCLEIC ACIDS RES, V31, P3701, DOI 10.1093/nar/gkg519; Lupas A, 1996, METHOD ENZYMOL, V266, P513; Marcotte EM, 1999, NATURE, V402, P83; Mateos A, 2002, GENOME RES, V12, P1703, DOI 10.1101/gr.192502; Meinel T, 2005, NUCLEIC ACIDS RES, V33, pD226; Mewes HW, 1997, NATURE, V387, P7; Mewes HW, 1999, NUCLEIC ACIDS RES, V27, P44, DOI 10.1093/nar/27.1.44; Mulder NJ, 2007, NUCLEIC ACIDS RES, V35, pD224, DOI 10.1093/nar/gkl841; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; Nielsen H, 1999, PROTEIN ENG, V12, P3, DOI 10.1093/protein/12.1.3; Paccanaro A, 2006, NUCLEIC ACIDS RES, V34, P1571, DOI 10.1093/nar/gkj515; Pearson WR, 1996, METHOD ENZYMOL, V266, P227; Rattei T, 2008, NUCLEIC ACIDS RES, V36, pD289, DOI 10.1093/nar/gkm963; Remm M, 2001, J MOL BIOL, V314, P1041, DOI 10.1006/jmbi.2001.5197; RESNIK R, 1995, P 14 INT JOINT C ART, P448; Riley ML, 2007, NUCLEIC ACIDS RES, V35, pD354, DOI 10.1093/nar/gkl1005; Ruepp A, 2004, NUCLEIC ACIDS RES, V32, P5539, DOI 10.1093/nar/gkh894; Ruepp A., 2006, DRUG DISCOV TODAY TE, V3, P145, DOI 10.1016/j.ddtec.2006.06.011; SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5; Sonnhammer ELL, 1997, PROTEINS, V28, P405, DOI 10.1002/(SICI)1097-0134(199707)28:3<405::AID-PROT10>3.0.CO;2-L; Tetko IV, 2005, BIOINFORMATICS, V21, P2520, DOI 10.1093/bioinformatics/bti380; Tetko IV, 1996, J CHEM INF COMP SCI, V36, P794, DOI 10.1021/ci950204c; Tetko IV, 2002, NEURAL PROCESS LETT, V16, P187, DOI 10.1023/A:1019903710291; Tetko IV, 2005, J COMPUT AID MOL DES, V19, P453, DOI 10.1007/s10822-005-8694-y; Tetko IV, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-82; Tetko IV, 2006, J CHEM INF MODEL, V46, P808, DOI 10.1021/ci0504216; Tetko IV, 2002, J CHEM INF COMP SCI, V42, P717, DOI 10.1021/ci010379o; Troyanskaya OG, 2003, P NATL ACAD SCI USA, V100, P8348, DOI 10.1073/pnas.0832373100; Valencia A, 2005, CURR OPIN STRUC BIOL, V15, P267, DOI 10.1016/j.sbi.2005.05.010; Vazquez A, 2003, NAT BIOTECHNOL, V21, P697, DOI 10.1038/nbt825; von Mering C, 2007, NUCLEIC ACIDS RES, V35, pD358, DOI 10.1093/nar/gkl825; WIKEL JH, 1993, BIOORG MED CHEM LETT, V3, P645, DOI 10.1016/S0960-894X(01)81246-4; WOOTTON JC, 1993, COMPUT CHEM, V17, P149, DOI 10.1016/0097-8485(93)85006-X; Yona G, 2000, NUCLEIC ACIDS RES, V28, P49, DOI 10.1093/nar/28.1.49; Yu HY, 2007, BIOINFORMATICS, V23, P2163, DOI 10.1093/bioinformatics/btm291	65	4	4	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	MAR 1	2008	24	5					621	628		10.1093/bioinformatics/btm633		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	270UT	WOS:000253746400004	
J	Bernauer, J; Bahadur, RP; Rodier, F; Janin, J; Poupon, A				Bernauer, Julie; Bahadur, Ranjit Prasad; Rodier, Francis; Janin, Joel; Poupon, Anne			DiMoVo: a Voronoi tessellation-based method for discriminating crystallographic and biological proteinprotein interactions	BIOINFORMATICS			English	Article							BINDING-SITES; ARC REPRESSOR; PREDICTION; INTERFACES; CONTACTS; RECOGNITION; INFERENCE; CRYSTALS; STATE	Motivation: Knowledge of the oligomeric state of a protein is often essential for understanding its function and mechanism. Within a protein crystal, each protein monomer is in contact with many others, forming many small interfaces and a few larger ones that are biologically significant if the protein is a homodimer in solution, but not if the protein is monomeric. Telling such crystal dimers from real ones remains a difficult task. Results: It has already been demonstrated that the interfaces of native and non-native proteinprotein complexes can be distinguished using a combination of parameters computed with a method on the Voronoi tessellation. We show in this article that the same parameters highlight significant differences between the interfaces of biological and crystal dimers. Using these parameters as descriptors in machine learning methods leads to accurate classification of specific and non-specific proteinprotein interfaces.	[Bernauer, Julie; Bahadur, Ranjit Prasad; Janin, Joel; Poupon, Anne] Univ Paris 11, Yeast Struct Genom, IBBMC, UMR 8619, F-91405 Orsay, France; [Bernauer, Julie] Stanford Univ, Sch Med, Dept Biol Struct, Stanford, CA 94305 USA; [Rodier, Francis] CNRS, LEBS, UPR 9063, F-91191 Gif Sur Yvette, France	Poupon, A (reprint author), Univ Paris 11, Yeast Struct Genom, IBBMC, UMR 8619, Batiment 430, F-91405 Orsay, France.		Janin, Joel/I-2958-2012				Bahadur RP, 2004, J MOL BIOL, V336, P943, DOI 10.1016/j.jmb.2003.12.073; Bahadur RP, 2003, PROTEINS, V53, P708, DOI 10.1002/prot.10461; Bernauer J, 2007, BIOINFORMATICS, V23, P555, DOI 10.1093/bioinformatics/btl654; Bernauer J, 2005, PHYS BIOL, V2, pS17, DOI 10.1088/1478-3975/2/2/S02; Block P, 2006, PROTEINS, V65, P607, DOI 10.1002/prot.21104; BOISSONNAT JD, 1999, S COMPUT GEOMETRY, V1999, P421; BONVIN AMJJ, 1994, J MOL BIOL, V236, P328, DOI 10.1006/jmbi.1994.1138; Bradford JR, 2005, BIOINFORMATICS, V21, P1487, DOI 10.1093/bioinformatics/bti242; Carugo O, 1997, PROTEIN SCI, V6, P2261; CHANG CC, 2001, MULTIPLE CLASSIFIER; Cristiani N, 2000, INTRO SUPPORT VECTOR; Dasgupta S, 1997, PROTEINS, V28, P494, DOI 10.1002/(SICI)1097-0134(199708)28:4<494::AID-PROT4>3.0.CO;2-A; Hsu C. W., 2003, PRACTICAL GUIDE SUPP; Janin J, 1997, NAT STRUCT BIOL, V4, P973, DOI 10.1038/nsb1297-973; Krissinel E, 2007, J MOL BIOL, V372, P774, DOI 10.1016/j.jmb.2007.05.022; Liu SY, 2006, PROTEINS, V64, P68, DOI 10.1002/prot.20954; MILLA ME, 1995, BIOCHEMISTRY-US, V34, P13914, DOI 10.1021/bi00042a024; Mintseris J, 2003, PROTEINS, V53, P629, DOI 10.1002/prot.10432; Neuvirth H, 2004, J MOL BIOL, V338, P181, DOI 10.1016/j.jmb.2004.02.040; Nooren IMA, 2003, EMBO J, V22, P3486, DOI 10.1093/emboj/cdg359; Ponstingl H, 2003, J APPL CRYSTALLOGR, V36, P1116, DOI 10.1107/S0021889803012421; Poupon A, 2004, CURR OPIN STRUC BIOL, V14, P233, DOI 10.1016/j.sbi.2004.03.010; SCHOLHOPF B, 1997, SUPPORT VECTOR LEARN; SHAW A, 1995, J CELL BIOL, V130, P1117, DOI 10.1083/jcb.130.5.1117; Sing T, 2005, BIOINFORMATICS, V21, P3940, DOI 10.1093/bioinformatics/bti623; Zhu HB, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-27	26	28	28	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	MAR 1	2008	24	5					652	658		10.1093/bioinformatics/btn022		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	270UT	WOS:000253746400008	
J	Khatun, J; Hamlett, E; Giddings, MC				Khatun, Jainab; Hamlett, Eric; Giddings, Morgan C.			Incorporating sequence information into the scoring function: a hidden Markov model for improved peptide identification	BIOINFORMATICS			English	Article							TANDEM MASS-SPECTROMETRY; COLLISION-INDUCED DISSOCIATION; PROTEIN IDENTIFICATION; SPECTRAL DATA; SEARCH; DATABASES; FRAGMENTATION; ALGORITHM	Motivation: The identification of peptides by tandem mass spectrometry (MS/MS) is a central method of proteomics research, but due to the complexity of MS/MS data and the large databases searched, the accuracy of peptide identification algorithms remains limited. To improve the accuracy of identification we applied a machine-learning approach using a hidden Markov model (HMM) to capture the complex and often subtle links between a peptide sequence and its MS/MS spectrum. Model: Our model, HMM_Score, represents ion types as HMM states and calculates the maximum joint probability for a peptide/spectrum pair using emission probabilities from three factors: the amino acids adjacent to each fragmentation site, the mass dependence of ion types and the intensity dependence of ion types. The Viterbi algorithm is used to calculate the most probable assignment between ion types in a spectrum and a peptide sequence, then a correction factor is added to account for the propensity of the model to favor longer peptides. An expectation value is calculated based on the model score to assess the significance of each peptide/spectrum match. Results: We trained and tested HMM_Score on three data sets generated by two different mass spectrometer types. For a reference data set recently reported in the literature and validated using seven identification algorithms, HMM_Score produced 43 more positive identification results at a 1 false positive rate than the best of two other commonly used algorithms, Mascot and XTandem. HMM_Score is a highly accurate platform for peptide identification that works well for a variety of mass spectrometer and biological sample types.	[Khatun, Jainab; Hamlett, Eric; Giddings, Morgan C.] Univ N Carolina, Dept Microbiol & Immunol, Chapel Hill, NC 27599 USA; [Giddings, Morgan C.] Univ N Carolina, Dept Biomed Engn, Chapel Hill, NC 27599 USA; [Giddings, Morgan C.] Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27599 USA	Giddings, MC (reprint author), Univ N Carolina, Dept Microbiol & Immunol, Chapel Hill, NC 27599 USA.						ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Bafna V, 2001, Bioinformatics, V17 Suppl 1, pS13; Bandeira N, 2004, ANAL CHEM, V76, P7221, DOI 10.1021/ac0489162; Blattner FR, 1997, SCIENCE, V277, P1453, DOI 10.1126/science.277.5331.1453; Craig R, 2004, J PROTEOME RES, V3, P1234, DOI 10.1021/pr049882h; Dancik V, 1999, J COMPUT BIOL, V6, P327, DOI 10.1089/106652799318300; Davis J, 2006, P 23 INT C MACH LEAR; DURBIN R, 1998, BIOL SEQ ANAL PROBAB; ENG JK, 1994, J AM SOC MASS SPECTR, V5, P976, DOI 10.1016/1044-0305(94)80016-2; Falkner J, 2005, BIOINFORMATICS, V21, P2177, DOI 10.1093/bioinformatics/bti362; Fenyo D, 2003, ANAL CHEM, V75, P768, DOI 10.1021/ac0258709; Fischer B, 2005, ANAL CHEM, V77, P7265, DOI 10.1021/ac0508853; Frank A, 2005, ANAL CHEM, V77, P964, DOI 10.1021/ac048788h; Geer LY, 2004, J PROTEOME RES, V3, P958, DOI 10.1021/pr0499491; Giddings MC, 2003, P NATL ACAD SCI USA, V100, P20, DOI 10.1073/pnas.0136893100; HANLEY JA, 1982, RADIOLOGY, V143, P29; Horn DM, 2000, P NATL ACAD SCI USA, V97, P10313, DOI 10.1073/pnas.97.19.10313; Kapp EA, 2005, PROTEOMICS, V5, P3475, DOI 10.1002/pmic.200500126; Khatun J, 2007, ANAL CHEM, V79, P3032, DOI 10.1021/ac061455v; Kuster B, 2001, PROTEOMICS, V1, P641; LeDuc RD, 2004, NUCLEIC ACIDS RES, V32, pW340, DOI 10.1093/nar/gkh447; Ma B, 2003, RAPID COMMUN MASS SP, V17, P2337, DOI 10.1002/rcm.1196; MANN M, 1994, ANAL CHEM, V66, P4390, DOI 10.1021/ac00096a002; Narasimhan C, 2005, ANAL CHEM, V77, P7581, DOI 10.1021/ac0501745; Perkins DN, 1999, ELECTROPHORESIS, V20, P3551, DOI 10.1002/(SICI)1522-2683(19991201)20:18<3551::AID-ELPS3551>3.0.CO;2-2; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Sadygov RG, 2003, ANAL CHEM, V75, P3792, DOI 10.1021/ac034157w; Tabb DL, 2004, ANAL CHEM, V76, P1243, DOI 10.1021/ac0351163; Tabb DL, 2003, ANAL CHEM, V75, P1155, DOI 10.1021/ac026122m; Taylor JA, 2001, ANAL CHEM, V73, P2594, DOI 10.1021/ac001196o; Wan YH, 2006, ANAL CHEM, V78, P432, DOI 10.1021/ac051319a; Washburn MP, 2001, NAT BIOTECHNOL, V19, P242, DOI 10.1038/85686; Wysocki VH, 2005, METHODS, V35, P211, DOI 10.1016/j.ymeth.2004.08.013; Yague J, 2003, ANAL CHEM, V75, P1524, DOI 10.1021/ac02628d; Zhang N, 2002, PROTEOMICS, V2, P1406, DOI 10.1002/1615-9861(200210)2:10<1406::AID-PROT1406>3.0.CO;2-9	35	9	10	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	MAR 1	2008	24	5					674	681		10.1093/bioinformatics/btn011		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	270UT	WOS:000253746400011	
J	Choi, JH; Kim, S; Tang, H; Andrews, J; Gilbert, DG; Colbourne, JK				Choi, Jeong-Hyeon; Kim, Sun; Tang, Haixu; Andrews, Justen; Gilbert, Don G.; Colbourne, John K.			A machine-learning approach to combined evidence validation of genome assemblies	BIOINFORMATICS			English	Article							SEQUENCE; QUALITY; SHOTGUN; TOOL; DNA	Motivation: While it is common to refer to 'the genome sequence' as if it were a single, complete and contiguous DNA string, it is in fact an assembly of millions of small, partially overlapping DNA fragments. Sophisticated computer algorithms (assemblers and scaffolders) merge these DNA fragments into contigs, and place these contigs into sequence scaffolds using the paired-end sequences derived from large-insert DNA libraries. Each step in this automated process is susceptible to producing errors; hence, the resulting draft assembly represents (in practice) only a likely assembly that requires further validation. Knowing which parts of the draft assembly are likely free of errors is critical if researchers are to draw reliable conclusions from the assembled sequence data. Results: We develop a machine-learning method to detect assembly errors in sequence assemblies. Several in silico measures for assembly validation have been proposed by various researchers. Using three benchmarking Drosophila draft genomes, we evaluate these techniques along with some new measures that we propose, including the good-minus-bad coverage (GMB), the good-to-bad-ratio (RGB), the average Z-score (AZ) and the average absolute Z-score (ASZ). Our results show that the GMB measure performs better than the others in both its sensitivity and its specificity for assembly error detection. Nevertheless, no single method performs sufficiently well to reliably detect genomic regions requiring attention for further experimental verification. To utilize the advantages of all these measures, we develop a novel machine learning approach that combines these individual measures to achieve a higher prediction accuracy (i.e. greater than 90%). Our combined evidence approach avoids the difficult and often ad hoc selection of many parameters the individual measures require, and significantly improves the overall precisions on the benchmarking data sets.	[Choi, Jeong-Hyeon; Kim, Sun; Tang, Haixu; Andrews, Justen; Gilbert, Don G.; Colbourne, John K.] Indiana Univ, Ctr Genom & Bioinformat, Bloomington, IN 47405 USA; [Kim, Sun; Tang, Haixu] Indiana Univ, Sch Informat, Bloomington, IN 47405 USA; [Andrews, Justen] Indiana Univ, Dept Biol, Bloomington, IN 47405 USA	Choi, JH (reprint author), Indiana Univ, Ctr Genom & Bioinformat, Bloomington, IN 47405 USA.		Choi, Jeong-Hyeon/E-3084-2010				Bartels D, 2005, BIOINFORMATICS, V21, P853, DOI 10.1093/bioinformatics/bti091; Batzoglou S, 2002, GENOME RES, V12, P177, DOI 10.1101/gr.208902; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dew IM, 2005, J COMPUT BIOL, V12, P497, DOI 10.1089/cmb.2005.12.497; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Duda R.O., 1973, PATTERN CLASSIFICATI, P10; Gilbert DG, 2007, NUCLEIC ACIDS RES, V35, pD480, DOI 10.1093/nar/gkl997; Green P, 1997, GENOME RES, V7, P410; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; Hillier LW, 2004, NATURE, V432, P695, DOI 10.1038/nature03154; KECECIOGLU JD, 1995, ALGORITHMICA, V13, P7, DOI 10.1007/BF01188580; Kim S., 2001, Postdeadline Papers. CLEO/Pacific Rim 2001. 4th Pacific Rim Conference on Lasers and Electro-Optics (Cat. No.01TH8557), DOI 10.1109/CLEOPR.2001.968023; Kim S., 2007, GENOME SEQUENCING TE; Lindblad-Toh K, 2005, NATURE, V438, P803, DOI 10.1038/nature04338; 2007, NATURE, V447, P167; Myers E W, 1995, J Comput Biol, V2, P275, DOI 10.1089/cmb.1995.2.275; Nelson WM, 2005, PLANT PHYSIOL, V139, P27, DOI 10.1104/pp.105.061978; POP M, 2002, IEEE COMPUT, V35, P47; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Salzberg SL, 2005, BIOINFORMATICS, V21, P4320, DOI 10.1093/bioinformatics/bti769; Samanta Manoj Pratim, 2007, Methods Mol Biol, V377, P163; SANGER F, 1982, J MOL BIOL, V162, P729, DOI 10.1016/0022-2836(82)90546-0; Schatz MC, 2007, GENOME BIOL, V8, DOI 10.1186/gb-2007-8-3-r34; Schmutz J, 2004, NATURE, V429, P365, DOI 10.1038/nature02390; Schmutz J, 2003, COLD SPRING HARB SYM, V68, P31, DOI 10.1101/sqb.2003.68.31; Tang H, 2007, CHEM REV, V107, P3391, DOI 10.1021/cr0683008; Venter JC, 2001, SCIENCE, V291, P1304, DOI 10.1126/science.1058040; Waterston RH, 2002, NATURE, V420, P520, DOI 10.1038/nature01262; West J, 2006, J COMPUT BIOL, V13, P1, DOI 10.1089/cmb.2006.13.1; WITTEN I, 2001, DATA MINING; ZIMIN AV, 2005, ASSEMBLY RECONCILIAT	31	7	7	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	MAR	2008	24	6					744	750		10.1093/bioinformatics/btm608		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	274OK	WOS:000254010400002	
J	Shah, AR; Oehmen, CS; Webb-Robertson, BJ				Shah, Anuj R.; Oehmen, Christopher S.; Webb-Robertson, Bobbie-Jo			SVM-HUSTLE - an iterative semi-supervised machine learning approach for pairwise protein remote homology detection	BIOINFORMATICS			English	Article							TWILIGHT ZONE; INFORMATION; ALIGNMENT; MODELS; TOOL	Motivation: As the amount of biological sequence data continues to grow exponentially we face the increasing challenge of assigning function to this enormous molecular 'parts list'. The most popular approaches to this challenge make use of the simplifying assumption that similar functional molecules, or proteins, sometimes have similar composition, or sequence. However, these algorithms often fail to identify remote homologs (proteins with similar function but dissimilar sequence) which often are a significant fraction of the total homolog collection for a given sequence. We introduce a Support Vector Machine (SVM)-based tool to detect homology using semi-supervised iterative learning (SVM-HUSTLE) that identifies significantly more remote homologs than current state-of-the-art sequence or cluster-based methods. As opposed to building profiles or position specific scoring matrices, SVM-HUSTLE builds an SVM classifier for a query sequence by training on a collection of representative high-confidence training sets, recruits additional sequences and assigns a statistical measure of homology between a pair of sequences. SVM-HUSTLE combines principles of semi-supervised learning theory with statistical sampling to create many concurrent classifiers to iteratively detect and refine, on-the-fly, patterns indicating homology. Results: When compared against existing methods for identifying protein homologs (BLAST, PSI-BLAST, COMPASS, PROF_SIM, RANKPROP and their variants) on two different benchmark datasets SVM-HUSTLE significantly outperforms each of the above methods using the most stringent ROC1 statistic with P-values less than 1e-20. SVM-HUSTLE also yields results comparable to HHSearch but at a substantially reduced computational cost since we do not require the construction of HMMs.	Pacific NW Natl Lab, Richland, WA 99352 USA	Shah, AR (reprint author), Pacific NW Natl Lab, Richland, WA 99352 USA.						ALTSCHUL SF, 1997, NUCLEIC ACIDS RES, V25, P3402; ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Atalay V, 2005, BIOINFORMATICS, V21, P1429, DOI 10.1093/bioinformatics/bti212; BALDI P, 1994, P NATL ACAD SCI USA, V91, P1059, DOI 10.1073/pnas.91.3.1059; BENHUR A, 2003, BIOINFORMATICS S1, V19, P126; Busuttil Steven, 2004, Genome Inform, V15, P191; Dunker AK, 2002, BIOCHEMISTRY-US, V41, P6573, DOI 10.1021/bi012159+; Gribskov M, 1996, COMPUT CHEM, V20, P25, DOI 10.1016/S0097-8485(96)80004-0; HANLEY JA, 1982, RADIOLOGY, V143, P29; Hou Y, 2003, BIOINFORMATICS, V19, P2294, DOI 10.1093/bioinformatics/btg317; Hou YN, 2004, PROTEINS, V57, P518, DOI 10.1002/prot.20221; Jaakkola T, 2000, J COMPUT BIOL, V7, P95, DOI 10.1089/10665270050081405; Kuang R, 2005, BIOINFORMATICS, V21, P3711, DOI 10.1093/bioinformatics/bti608; Kuang Rui, 2005, Journal of Bioinformatics and Computational Biology, V3, P527, DOI 10.1142/S021972000500120X; Leslie C., 2003, BIOINFORMATICS, V1, P1; Liao L, 2003, J COMPUT BIOL, V10, P857, DOI 10.1089/106652703322756113; Lingner T, 2006, BIOINFORMATICS, V22, P2224, DOI 10.1093/bioinformatics/btl376; OGUL H, 2006, J MOL BIOL, V284, P1202; PARK J, 1998, J MOL BIOL, V284, P1202; PEARSON WR, 1990, METHOD ENZYMOL, V183, P63, DOI 10.1016/0076-6879(90)83007-V; Rangwala H, 2005, BIOINFORMATICS, V21, P4239, DOI 10.1093/bioinformatics/bti687; Rost B, 1999, PROTEIN ENG, V12, P85, DOI 10.1093/protein/12.2.85; Sadreyev RI, 2003, PROTEIN SCI, V12, P2262, DOI 10.1110/ps.03197403; Salzberg SL, 1997, DATA MIN KNOWL DISC, V1, P317, DOI 10.1023/A:1009752403260; Schaffer AA, 2001, NUCLEIC ACIDS RES, V29, P2994, DOI 10.1093/nar/29.14.2994; Shah AR, 2007, COMPUT BIOL CHEM, V31, P138, DOI 10.1016/j.compbiolchem.2007.02.012; SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5; Soeding Johannes, 2005, Bioinformatics (Oxford), V21, P951; Vapnik V. N, 1995, NATURE STAT LEARNING; Vapnik VN, 1998, STAT LEARNING THEORY; Webb-Robertson BJ, 2005, COMPUT BIOL CHEM, V29, P440, DOI 10.1016/j.compbiolchem.2005.09.006; WETSON J, 2004, P NATL ACAD SCI USA, V101, P6559; WETSON J, 2005, BIOINFORMATICS, V21, P3241; WETSON J, 2006, BMC BIOINFORMATIC S1, V7, pS10; Yona G, 2002, J MOL BIOL, V315, P1257, DOI 10.1006/jmbi.2001.5293; ZAKI NM, 2003, J THEOR, V5; Zhu X., 2006, SEMISUPERVISED LEARN	37	12	12	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	MAR	2008	24	6					783	790		10.1093/bioinformatics/btn028		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	274OK	WOS:000254010400007	
J	Kolodziejski, C; Porr, B; Woergoetter, F				Kolodziejski, Christoph; Porr, Bernd; Woergoetter, Florentin			Mathematical properties of neuronal TD-rules and differential Hebbian learning: a comparison	BIOLOGICAL CYBERNETICS			English	Article						differential Hebbian learning; correlation-based learning; temporal difference learning; reinforcement learning	NEURAL-NETWORK MODEL; REINFORCEMENT SIGNAL; DOPAMINE NEURONS; NAVIGATION; PLASTICITY; PREDICTION; REWARD; CONVERGENCE; MODULATION; TD(LAMBDA)	A confusingly wide variety of temporally asymmetric learning rules exists related to reinforcement learning and/or to spike-timing dependent plasticity, many of which look exceedingly similar, while displaying strongly different behavior. These rules often find their use in control tasks, for example in robotics and for this rigorous convergence and numerical stability is required. The goal of this article is to review these rules and compare them to provide a better overview over their different properties. Two main classes will be discussed: temporal difference (TD) rules and correlation based (differential hebbian) rules and some transition cases. In general we will focus on neuronal implementations with changeable synaptic weights and a time-continuous representation of activity. In a machine learning (non-neuronal) context, for TD-learning a solid mathematical theory has existed since several years. This can partly be transfered to a neuronal framework, too. On the other hand, only now a more complete theory has also emerged for differential Hebb rules. In general rules differ by their convergence conditions and their numerical stability, which can lead to very undesirable behavior, when wanting to apply them. For TD, convergence can be enforced with a certain output condition assuring that the delta-error drops on average to zero (output control). Correlation based rules, on the other hand, converge when one input drops to zero (input control). Temporally asymmetric learning rules treat situations where incoming stimuli follow each other in time. Thus, it is necessary to remember the first stimulus to be able to relate it to the later occurring second one. To this end different types of so-called eligibility traces are being used by these two different types of rules. This aspect leads again to different properties of TD and differential Hebbian learning as discussed here. Thus, this paper, while also presenting several novel mathematical results, is mainly meant to provide a road map through the different neuronally emulated temporal asymmetrical learning rules and their behavior to provide some guidance for possible applications.	[Kolodziejski, Christoph; Woergoetter, Florentin] Univ Gottingen, Bernstein Ctr Computat Neurosci, D-37073 Gottingen, Germany; [Porr, Bernd] Univ Glasgow, Dept Elect & Elect Engn, Glasgow GT12 8LT, Lanark, Scotland	Woergoetter, F (reprint author), Univ Gottingen, Bernstein Ctr Computat Neurosci, Bunsenstr 10, D-37073 Gottingen, Germany.	b.porr@elec.gla.ac.uk; worgott@bccn-goettingen.de					Arleo A, 2000, BIOL CYBERN, V83, P287, DOI 10.1007/s004220000171; Barto A, 1995, MODELS INFORM PROCES, P215; Bi GQ, 2001, ANNU REV NEUROSCI, V24, P139, DOI 10.1146/annurev.neuro.24.1.139; Boykin TB, 2003, AM J PHYS, V71, P462, DOI 10.1119/1.1557302; DAYAN P, 1992, MACH LEARN, V8, P341, DOI 10.1007/BF00992701; DAYAN P, 1994, MACH LEARN, V14, P295, DOI 10.1007/BF00993978; DAYAN P, 2003, THEORETICAL NEUROSCI; Florian RV, 2007, NEURAL COMPUT, V19, P1468, DOI 10.1162/neco.2007.19.6.1468; Foster DJ, 2000, HIPPOCAMPUS, V10, P1, DOI 10.1002/(SICI)1098-1063(2000)10:1<1::AID-HIPO1>3.0.CO;2-1; Gerstner W, 1996, NATURE, V383, P76, DOI 10.1038/383076a0; Hull C. L., 1943, PRINCIPLES BEHAV; Hull CL, 1939, PSYCHOL REV, V46, P9, DOI 10.1037/h0054032; Humeau Y, 2003, NATURE, V426, P841, DOI 10.1038/nature02194; IZHIKEVICH E, 2007, CEREBRAL CORTEX; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237; Klopf A, 1982, HEDONISTIC NEURON TH; KLOPF AH, 1988, PSYCHOBIOLOGY, V16, P85; KLOPF AH, 1972, 133 DEF TECHN INF CT; KLOPF AH, 1986, NEURAL NETWORKS COMP, V151; KOLODZIEJSKI C, 2006, P 15 ANN COMP NEUR M; KOLODZIEJSKI C, 2007, P 15 ANN COMP NEUR M; KOSCO B, 1986, NEUR NETW COMP AIP C, V151; Krichmar JL, 2005, NEUROINFORMATICS, V3, P197, DOI 10.1385/NI:3:3:197; KULVICIUS T, 2007, BIOL CYBERN; Magee JC, 1997, SCIENCE, V275, P209, DOI 10.1126/science.275.5297.209; Manoonpong P, 2007, PLOS COMPUT BIOL, V3, P1305, DOI 10.1371/journal.pcbi.0030134; Markram H, 1997, SCIENCE, V275, P213, DOI 10.1126/science.275.5297.213; MILLER JD, 1981, LIFE SCI, V29, P1255, DOI 10.1016/0024-3205(81)90231-9; Montague PR, 1996, J NEUROSCI, V16, P1936; MONTAGUE PR, 1995, NATURE, V377, P725, DOI 10.1038/377725a0; Pfister J.-P., 2006, NEURAL COMPUT, V18, P1309; Saudargiene A, 2004, NEURAL COMPUT, V16, P595, DOI 10.1162/089976604772744929; Porr B, 2003, NEURAL COMPUT, V15, P831, DOI 10.1162/08997660360581921; PORR B, 2007, IN PRESS NEURAL COMP; Porr B, 2003, NEURAL COMPUT, V15, P865, DOI 10.1162/08997660360581930; Porr B, 2006, NEURAL COMPUT, V18, P1380, DOI 10.1162/neco.2006.18.6.1380; Roberts PD, 1999, J COMPUT NEUROSCI, V7, P235, DOI 10.1023/A:1008910918445; SANTIAGO RA, 2007, P 15 ANN COMP NEUR M; Schultz W, 1998, J NEUROPHYSIOL, V80, P1; Schultz W, 1997, SCIENCE, V275, P1593, DOI 10.1126/science.275.5306.1593; Singh SP, 1996, MACH LEARN, V22, P123, DOI 10.1023/A:1018012322525; Strosslin T, 2005, NEURAL NETWORKS, V18, P1125, DOI 10.1016/j.neunet.2005.08.012; Suri RE, 1998, EXP BRAIN RES, V121, P350, DOI 10.1007/s002210050467; Suri RE, 2001, NEUROSCIENCE, V103, P65, DOI 10.1016/S0306-4522(00)00554-6; Suri RE, 2001, NEURAL COMPUT, V13, P841, DOI 10.1162/089976601300014376; Suri RE, 2002, NEURAL NETWORKS, V15, P523, DOI 10.1016/S0893-6080(02)00046-1; Suri RE, 1999, NEUROSCIENCE, V91, P871, DOI 10.1016/S0306-4522(98)00697-6; SUTTOH RS, 1990, LEARNING COMPUTATION; Sutton R. S., 1988, Machine Learning, V3, DOI 10.1007/BF00115009; Sutton R.S., 1998, REINFORCEMENT LEARNI; SUTTON RS, 1981, PSYCHOL REV, V88, P135, DOI 10.1037/0033-295X.88.2.135; Tsukamoto M, 2003, J PHYSIOL-LONDON, V546, P665, DOI 10.1113/jphysiol.2002.033803; Watkins C., 1989, THESIS U CAMBRIDGE C; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698; WITTEN IH, 1977, INFORM CONTR, V34, P86; Worgotter F, 2005, NEURAL COMPUT, V17, P245, DOI 10.1162/0899766053011555	56	3	4	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0340-1200		BIOL CYBERN	Biol. Cybern.	MAR	2008	98	3					259	272		10.1007/s00422-007-0209-6		14	Computer Science, Cybernetics; Neurosciences	Computer Science; Neurosciences & Neurology	269BF	WOS:000253623800006	
J	Barla, A; Jurman, G; Riccadonna, S; Merler, S; Chierici, M; Furlanello, C				Barla, Annalisa; Jurman, Giuseppe; Riccadonna, Samantha; Merler, Stefano; Chierici, Marco; Furlanello, Cesare			Machine learning methods for predictive proteomics	BRIEFINGS IN BIOINFORMATICS			English	Article						proteomics; selection bias; feature selection; functional profiling	MASS-SPECTROMETRY DATA; FEATURE-EXTRACTION; SELECTION BIAS; OVARIAN-CANCER; PEAK DETECTION; SERUM; CLASSIFICATION; MALDI; REPRODUCIBILITY; QUANTIFICATION	The search for predictive biomarkers of disease from high-throughput mass spectrometry (MS) data requires a complex analysis path. Preprocessing and machine-learning modules are pipelined, starting from raw spectra, to set up a predictive classifier based on a shortlist of candidate features. As a machine-learning problem, proteomic profiling on MS data needs caution like the microarray case. The risk of overfitting and of selection bias effects is pervasive: not only potential features easily outnumber samples by 10(3) times, but it is easy to neglect information-leakage effects during preprocessing from spectra to peaks. The aim of this review is to explain how to build a general purpose design analysis protocol (DAP) for predictive proteomic profiling: we show how to limit leakage due to parameter tuning and how to organize classification and ranking on large numbers of replicate versions of the original data to avoid selection bias. The DAP can be used with alternative components, i.e. with different preprocessing methods (peak clustering or wavelet based), classifiers e.g. Support Vector Machine (SVM) or feature ranking methods (recursive feature elimination or I-Relief). A procedure for assessing stability and predictive value of the resulting biomarkers list is also provided. The approach is exemplified with experiments on synthetic datasets (from the Cromwell MS simulator) and with publicly available datasets from cancer studies.	[Furlanello, Cesare] FBK, MPBA Unit, I-38100 Trento, Italy	Furlanello, C (reprint author), FBK, MPBA Unit, Via Sommarive 18, I-38100 Trento, Italy.	furlan@fbk.eu					Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Baggerly Keith A, 2005, Cancer Inform, V1, P9; Baggerly KA, 2004, BIOINFORMATICS, V20, P777, DOI 10.1093/bioinformatics/btg484; Baggerly KA, 2005, J NATL CANCER I, V97, P307, DOI 10.1093/jnci/dji008; BARLA A, 2006, P CBMS 2006, P941; Chambers J, 1983, GRAPHICAL METHODS DA; Codrea MC, 2007, LECT NOTES COMPUT SC, V4447, P35; Coombes K., 2007, FUNDAMENTALS DATA MI, P79, DOI 10.1007/978-0-387-47509-7_4; Coombes KR, 2005, PROTEOMICS, V5, P4107, DOI 10.1002/pmic.200401261; Coombes Kevin R, 2005, Cancer Inform, V1, P41; Coombes KR, 2005, NAT BIOTECHNOL, V23, P291, DOI 10.1038/nbt0305-291; Daubechies I., 1992, 10 LECT WAVELETS; Furlanello C, 2005, IEEE ACM T COMPUT BI, V2, P110, DOI 10.1109/TCBB.2005.28; Furlanello C, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-54; JONG K, 2004, IEEE S COMP INT BIOI, P41, DOI 10.1109/CIBCB.2004.1393930; Jurman G, 2008, BIOINFORMATICS, V24, P258, DOI 10.1093/bioinformatics/btm550; Klann E, 2007, INVERSE PROBL, V23, P2231, DOI 10.1088/0266-5611/23/5/025; LI J, 2006, P 23 INT C MACH LEAR, P913; Marchiori E, 2006, LECT NOTES COMPUT SC, V3907, P79; Merler S, 2006, NEURAL NETWORKS, V19, P1597, DOI 10.1016/j.neunet.2005.11.004; Morris JS, 2005, BIOINFORMATICS, V21, P1764, DOI 10.1093/bioinformatics/bti254; Noy K, 2007, BIOINFORMATICS, V23, P2528, DOI 10.1093/bioinformatics/btm385; Paoli S, 2008, INT J APPROX REASON, V47, P58, DOI 10.1016/j.ijar.2007.03.012; PATRICOIN EF, 2002, LANCET, V359, P572; R Development Core Team, 2004, R LANG ENV STAT COMP; Ressom HW, 2007, BIOINFORMATICS, V23, P619, DOI 10.1093/bioinformatics/btl678; SHI L, 2007, CURR OPIN BIOTE 1221; Sorace JM, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-24; Sun YJ, 2007, BIOINFORMATICS, V23, P30, DOI 10.1093/bioinformatics/btl543; Tibshirani R, 2004, BIOINFORMATICS, V20, P3034, DOI 10.1093/bioinformatics/bth357; Wagner M, 2003, PROTEOMICS, V3, P1692, DOI 10.1002/pmic.200300519; Wu Baolin, 2006, Cancer Inform, V2, P123; Yasui Y, 2003, J BIOMED BIOTECHNOL, P242; Yu Weichuan, 2006, V328, P199; Yu WC, 2006, COMPUT BIOL CHEM, V30, P27, DOI 10.1016/j.compbiolchem.2005.10.006; Yu WC, 2006, IEEE ACM T COMPUT BI, V3, P208; Zhu W, 2003, P NATL ACAD SCI USA, V100, P14666, DOI 10.1073/pnas.2532248100	37	21	23	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1467-5463		BRIEF BIOINFORM	Brief. Bioinform.	MAR	2008	9	2					119	128		10.1093/bib/bbn008		10	Biochemical Research Methods; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Mathematical & Computational Biology	284CI	WOS:000254682400003	
J	Villmann, T; Schleif, FM; Kostrzewa, M; Walch, A; Hammer, B				Villmann, Thomas; Schleif, Frank-Michael; Kostrzewa, Markus; Walch, Axel; Hammer, Barbara			Classification of mass-spectrometric data in clinical proteomics using learning vector quantization methods	BRIEFINGS IN BIOINFORMATICS			English	Article						classification; vector quantization; class visualization; machine learning; fuzzy-labeled self-organizing map; mass spectrometry	ORGANIZING FEATURE MAPS; SUPERVISED NEURAL GAS; FUZZY CLASSIFICATION; RELEVANCE; IDENTIFICATION; PRESERVATION; SPECTRA; TIME	In the present contribution we propose two recently developed classification algorithms for the analysis of mass-spectrometric datathe supervised neural gas and the fuzzy-labeled self-organizing map. The algorithms are inherently regularizing, which is recommended, for these spectral data because of its high dimensionality and the sparseness for specific problems. The algorithms are both prototype-based such that the principle of characteristic representants is realized. This leads to an easy interpretation of the generated classifcation model. Further, the fuzzy-labeled self-organizing map is able to process uncertainty in data, and classification results can be obtained as fuzzy decisions. Moreover, this fuzzy classification together with the property of topographic mapping offers the possibility of class similarity detection, which can be used for class visualization. We demonstrate the power of both methods for two exemplary examples: the classification of bacteria (listeria types) and neoplastic and non-neoplastic cell populations in breast cancer tissue sections.	[Villmann, Thomas] Univ Leipzig, Dept Med, Leipzig, Germany	Villmann, T (reprint author), Univ Leipzig, Dept Med, Leipzig, Germany.	thomas.villmann@medizin.uni-leipzig.de	Hammer, Barbara /E-8624-2010; Schleif, Frank-Michael/G-2186-2011; Walch, Axel/B-4554-2012				Baldi P., 1998, BIOINFORMATICS MACHI; BAUER HU, 1992, IEEE T NEURAL NETWOR, V3, P570, DOI 10.1109/72.143371; Bauer HU, 1997, IEEE T NEURAL NETWOR, V8, P218, DOI 10.1109/72.557659; Bishop C. M., 2006, PATTERN RECOGNITION; Bishop C.M., 1995, NEURAL NETWORKS PATT; CHANG C, 2001, LIBSVM LIBARY SUPPOR; CRAMMER K, 2002, P NIPS 2002; Cristianini N., 2000, INTRO SUPPORT VECTOR; de Noo ME, 2006, ONKOLOGIE, V29, P501, DOI 10.1159/000095933; de Noo ME, 2006, EUR J CANCER, V42, P1068, DOI 10.1016/j.ejca.2005.12.023; Duda R.O, 1973, PATTERN CLASSIFICATI; Fritzke B., 1995, ADV NEURAL INFORMATI, V7, P625; GERHARD M, 2007, P 20 IEEE S COMP BAS, P403; Groseclose MR, 2007, J MASS SPECTROM, V42, P254, DOI 10.1002/jms.1177; Hammer B, 2005, NEURAL PROCESS LETT, V21, P21, DOI 10.1007/s11063-004-3255-2; Hammer B, 2002, NEURAL NETWORKS, V15, P1059, DOI 10.1016/S0893-6080(02)00079-5; HAMMER B, 2005, P EUR S ART NEUR NET, P303; Heskes T, 1999, KOHONEN MAPS, P303, DOI 10.1016/B978-044450270-4/50024-3; JOACHIMS T., 2002, LEARNING CLASSIFY TE; Ketterlinus R, 2005, BIOTECHNIQUES, V38, P37; Kohonen T., 1997, SPRINGER SERIES INFO, V30; KOLMOGOROV A, 1975, REELE FUNKTIONEN FUN; Lee J.A., 2005, P WORKSH SELF ORG MA, P733; Maier T, 2007, CHIM OGGI, V25, P68; MARTINETZ TM, 1993, IEEE T NEURAL NETWOR, V4, P558, DOI 10.1109/72.238311; Sato A, 1996, ADV NEUR IN, V8, P423; Schleif FM, 2006, COMP MED SY, P919, DOI 10.1109/CBMS.2006.44; Schleif FM, 2007, LECT NOTES COMPUT SC, V4507, P1036; Schlelf FM, 2008, INT J APPROX REASON, V47, P4, DOI 10.1016/j.ijar.2007.03.005; Scholkopf B., 2002, LEARNING KERNELS; Schurmann J., 1996, PATTERN CLASSIFICATI; SEIFFERT U, 2006, P EUR S ART NEUR NET, P521; SEIFFERT U, 2004, BIOINFORMATICS USING; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Silverman BW, 1996, ANN STAT, V24, P1; Strickert M, 2006, NEUROCOMPUTING, V69, P651, DOI 10.1016/j.neucom.2005.12.004; Swamidass SJ, 2007, J CHEM INF MODEL, V47, P302, DOI 10.1021/ci600358f; TODAR K, 2003, TODARS ONLINE TXB BA; VERLEYSEN M, COMPUTATIONAL INTELL, P785; Villmann T, 1998, NEUROCOMPUTING, V21, P91, DOI 10.1016/S0925-2312(98)00037-X; Villmann T, 2006, NEUROCOMPUTING, V69, P2425, DOI 10.1016/j.neucom.2006.02.003; VILLMANN T, 2007, IN PRESS P WORKSH SE, P1; Villmann T., 2007, MACHINE LEARNING REP, P1; Villmann T, 1997, IEEE T NEURAL NETWOR, V8, P256, DOI 10.1109/72.557663; VILLMANN T, 2006, P C ART NEUR NETW PA, V4087, P46; Villmann T, 2006, NEURAL COMPUT, V18, P446, DOI 10.1162/089976606775093918; Villmann T, 2006, NEURAL NETWORKS, V19, P610, DOI 10.1016/j.neunet.2005.07.013; VILLMANN T, 2007, P EUR S ART NEUR NET, P103; Villmann T, 2007, LECT NOTES COMPUT SC, V4507, P556; VILLMANN T, 1996, TOPOLOGIEERHALTUNG S	50	19	19	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1467-5463		BRIEF BIOINFORM	Brief. Bioinform.	MAR	2008	9	2					129	143		10.1093/bib/bbn009		15	Biochemical Research Methods; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Mathematical & Computational Biology	284CI	WOS:000254682400004	
J	Cruz-Monteagudo, M; Gonzalez-Diaz, H; Borges, F; Dominguez, ER; Cordeiro, MNDS				Cruz-Monteagudo, Maykel; Gonzalez-Diaz, Humberto; Borges, Fernanda; Dominguez, Elena Rosa; Cordeiro, M. Natalia D. S.			3D-MEDNEs: an alternative "in silico" technique for chemical research in toxicology. 2. Quantitative Proteome-Toxicity Relationships (QPTR) based on mass spectrum spiral entropy	CHEMICAL RESEARCH IN TOXICOLOGY			English	Review							2-D GRAPHICAL REPRESENTATION; AVERAGE ELECTROSTATIC POTENTIALS; STOCHASTIC MOLECULAR DESCRIPTORS; DNA PRIMARY SEQUENCES; DESIGN MARCH-INSIDE; COMPUTATIONAL CHEMISTRY APPROACH; THERMODYNAMIC MARKOV MODEL; A(3) ADENOSINE RECEPTORS; BINARY QSAR CALCULATIONS; CORONARY-ARTERY DISEASE	Low range mass spectra (MS) characterization of serum proteome offers the best chance of discovering proteome-(early drug-induced cardiac toxicity) relationships, called here Pro-EDICToRs. However, due to the thousands of proteins involved, finding the single disease-related protein could be a hard task. The search for a model based on general MS patterns becomes a more realistic choice. In our previous work (Gonzalez-Diaz, H., et al. Chem. Res. Toxicol. 2003, 16, 1318-1327), we introduced the molecular structure information indices called 3D-Markovian electronic delocalization entropies (3D-MEDNEs). In this previous work, quantitative structure-toxicity relationship (QSTR) techniques allowed us to link 3D-MEDNEs with blood toxicological properties of drugs. In this second part, we extend 3D-MEDNEs to numerically encode biologically relevant information present in MS of the serum proteome for the first time. Using the same idea behind QSTR techniques, we can seek now by analogy a quantitative proteome-toxicity relationship (QPTR). The new QPTR models link MS 3D-MEDNEs with drug-induced toxicological properties from blood proteome information. We first generalized Randic's spiral graph and lattice networks of protein sequences to represent the MS of 62 serum proteome samples with more than 370 100 intensity (I(i)) signals with m/z bandwidth above 700-12000 each. Next, we calculated the 3D-MEDNEs for each MS using the software MARCA-INSIDE. After that, we developed several QPTR models using different machine learning and MS representation algorithms to classify samples as control or positive Pro-EDICToRs samples. The best QPTR proposed showed accuracy values ranging from 83.8% to 87.1% and leave-one-out (LOO) predictive ability of 77.4-85.5%. This work demonstrated that the idea behind classic drug QSTR models may be extended to construct QPTRs with proteome MS data.	[Gonzalez-Diaz, Humberto] Univ Santiago, Fac Pharm, Dept Organ Chem, Santiago De Compostela, Spain; [Cruz-Monteagudo, Maykel; Borges, Fernanda] Univ Porto, Fac Pharm, Dept Organ Chem, Phiys Chem Mol Res Unit, P-4150047 Oporto, Portugal; [Cruz-Monteagudo, Maykel; Dominguez, Elena Rosa] UCLV, Fac Chem & Pharm, Appl Chem Res Ctr, Santa Clara 54830, Cuba; [Cordeiro, M. Natalia D. S.] Univ Porto, Fac Sci, Dept Chem, REQUIMTE, P-4169007 Oporto, Portugal	Gonzalez-Diaz, H (reprint author), Univ Santiago, Fac Pharm, Dept Organ Chem, Santiago De Compostela, Spain.	gonzalezdiazh@yahoo.es	Cordeiro, Maria Natalia /A-7413-2012; Gonzalez-Diaz, Humberto/A-6785-2012	Gonzalez-Diaz, Humberto/0000-0002-9392-2797			Agrawal VK, 2003, BIOORG MED CHEM LETT, V13, P447, DOI 10.1016/S0960-894X(02)00954-X; Agrawal V. K., 2003, Acta Microbiologica et Immunologica Hungarica, V50, P385, DOI 10.1556/AMicr.50.2003.4.6; Agrawal VK, 2001, SAR QSAR ENVIRON RES, V12, P529, DOI 10.1080/10629360108039833; Agrawal VK, 2001, BIOORGAN MED CHEM, V9, P2787, DOI 10.1016/S0968-0896(01)00147-X; Aguero-Chapin GA, 2006, FEBS LETT, V580, P723, DOI 10.1016/j.febslet.2005.12.072; Anderson NL, 2002, MOL CELL PROTEOMICS, V1, P845, DOI 10.1074/mcp.R200007-MCP200; BANDEIRA N, 2007, BIOTECHNIQUES, V42, P691; Bandeira N, 2004, ANAL CHEM, V76, P7221, DOI 10.1021/ac0489162; Bandeira N, 2007, P NATL ACAD SCI USA, V104, P6140, DOI 10.1073/pnas.0701130104; BARTELS C, 1990, BIOMED ENVIRON MASS, V19, P363, DOI 10.1002/bms.1200190607; Basak SC, 2001, SAR QSAR ENVIRON RES, V12, P481, DOI 10.1080/10629360108039830; CHOU KC, 1990, BIOPHYS CHEM, V35, P1, DOI 10.1016/0301-4622(90)80056-D; Conrods TP, 2003, EXPERT REV MOL DIAGN, V3, P411, DOI 10.1586/14737159.3.4.411; Cruz-Monteagudo M, 2006, B MATH BIOL, V68, P1527, DOI 10.1007/s11538-005-9013-4; Cruz-Monteagudo M, 2005, EUR J MED CHEM, V40, P1030, DOI 10.1016/j.ejmech.2005.04.012; Cruz-Monteagudo M, 2007, J COMPUT CHEM, V28, P1909, DOI 10.1002/jcc.20730; de Armas RR, 2004, PROTEINS, V56, P715, DOI 10.1002/prot.20159; de Armas RR, 2004, BIOORGAN MED CHEM, V12, P4815, DOI 10.1016/j.bmc.2004.07.017; Devillers J, 2002, SAR QSAR ENVIRON RES, V13, P705, DOI 10.1080/1062936021000043445; Diaz HG, 2002, J MOL MODEL, V8, P237, DOI 10.1007/s00894-002-0088-7; Dima RI, 2004, BIOINFORMATICS, V20, P2345, DOI 10.1093/bioinformatics/bth245; Enslein K, 1997, FOOD CHEM TOXICOL, V35, P1091, DOI 10.1016/S0278-6915(97)87277-8; Estrada E, 2001, CURR MED CHEM, V8, P1573; Fernandez M, 2005, BIOORGAN MED CHEM, V13, P3269, DOI 10.1016/j.bmc.2005.02.038; Frank E, 2004, BIOINFORMATICS, V20, P2479, DOI 10.1093/bioinformatics/bth261; FREUND JA, 2000, LECT NOTES PHYS, V557; Gan HH, 2003, NUCLEIC ACIDS RES, V31, P2926, DOI 10.1093/nar/gkg365; Gia O, 2005, BIOORGAN MED CHEM, V13, P809, DOI 10.1016/j.bmc.2004.10.044; GOMBAR VK, 1995, CHEMOSPHERE, V31, P2499, DOI 10.1016/0045-6535(95)00119-S; Gonzalez MN, 2006, BIOORG MED CHEM LETT, V16, P1291, DOI 10.1016/j.bmcl.2005.11.063; Gonzalez MP, 2006, STEROIDS, V71, P510, DOI 10.1016/j.steroids.2006.02.001; Gonzalez MP, 2004, BIOORG MED CHEM LETT, V14, P3077, DOI 10.1016/j.bmcl.2004.04.040; Gonzalez MP, 2005, BIOORG MED CHEM LETT, V15, P3491, DOI 10.1016/j.bmcl.2005.05.122; Gonzalez MP, 2006, MOL DIVERS, V10, P109, DOI 10.1007/s11030-005-9004-2; Gonzalez MP, 2005, BIOORGAN MED CHEM, V13, P1775, DOI 10.1016/j.bmc.2004.11.059; Gonzalez MP, 2004, POLYMER, V45, P2073, DOI 10.1016/j.polymer.2003.12.014; Gonzalez-Diaz H, 2007, J COMPUT CHEM, V28, P1990, DOI 10.1002/jcc.20700; Gonzalez-Diaz H, 2005, BIOORG MED CHEM LETT, V15, P5088, DOI 10.1016/j.bmcl.2005.07.056; Gonzalez-Diaz H, 2007, J COMPUT CHEM, V28, P1049, DOI 10.1002/jcc.20576; Gonzalez-Diaz H, 2005, BIOORG MED CHEM LETT, V15, P551, DOI 10.1016/j.bmcl.2004.11.059; Gonzalez Diaz Humberto, 2003, Chemical Research in Toxicology, V16, P1318; GONZALEZDIAZ H, 2007, MARCH INSIDE VERSION; Gonzalez-Diaz H, 2007, J PROTEOME RES, V6, P904, DOI 10.1021/pr060493s; Gonzalez Diaz Humberto, 2003, Bioinformatics (Oxford), V19, P2079; Gonzalez-Diaz H, 2004, BIOORG MED CHEM LETT, V14, P4691, DOI 10.1016/j.bmcl.2004.06.100; Gonzalez-Diaz H, 2005, BIOORG MED CHEM LETT, V15, P2932, DOI 10.1016/j.bmcl.2005.03.017; Gonzalez-Diaz H, 2007, BIOORGAN MED CHEM, V15, P962, DOI 10.1016/j.bmc.2006.10.032; Gonzalez-Diaz H, 2005, BIOORGAN MED CHEM, V13, P323, DOI 10.1016/j.bmc.2004.10.024; Gonzalez-Diaz H, 2005, POLYMER, V46, P6461, DOI 10.1016/j.polymer.2005.04.104; Gonzalez-Diaz H, 2007, CHEMOMETR INTELL LAB, V85, P20, DOI 10.1016/j.chemolab.2006.03.005; Gonzalez-Diaz H, 2005, POLYMER, V46, P2791, DOI 10.1016/j.polymer.2005.01.066; Gonzalez Diaz H., 2004, Bulletin of Mathematical Biology, V66, P1285; Gonzalez-Diaz H, 2005, BIOORGAN MED CHEM, V13, P1523, DOI 10.1016/j.bmc.2004.12.028; Gonzalez-Diaz H, 2005, BIOORGAN MED CHEM, V13, P1119, DOI 10.1016/j.bmc.2004.11.030; Gonzalez-Diaz H, 2007, J COMPUT CHEM, V28, P1042, DOI 10.1002/jcc.20649; Gonzalez-Diaz H, 2006, J INORG BIOCHEM, V100, P1290, DOI 10.1016/j.jinorgbio.2006.02.019; Gonzalez-Diaz H, 2005, J MOL MODEL, V11, P116, DOI 10.1007/s00894-004-0228-3; Gonzalez-Diaz H., 2007, CURR TOP MED CHEM, V7, P1025; Gonzalez-Diaz H, 2006, BIOORGAN MED CHEM, V14, P1095, DOI 10.1016/j.bmc.2005.09.039; Gonzalez-Diaz H, 2006, BIOORG MED CHEM LETT, V16, P547, DOI 10.1016/j.bmcl.2005.10.057; Gonzalez-Diaz H, 2005, BIOPOLYMERS, V77, P296, DOI 10.1002/bip.20234; Gonzalez-Diaz H, 2005, BIOORG MED CHEM LETT, V15, P1651, DOI 10.1016/j.bmcl.2005.01.047; Gonzales-Diaz H, 2003, J MOL MODEL, V9, P395, DOI 10.1007/s00894-003-0148-7; Gonzalez-Diaz H, 2005, FEBS LETT, V579, P4297, DOI 10.1016/j..febslet.2005.06.065; Graham DJ, 2004, J CHEM INF COMP SCI, V44, P1612, DOI 10.1021/ci040022v; Graham DJ, 2004, J CHEM INF COMP SCI, V44, P1601, DOI 10.1021/ci0400213; Graham DJ, 2007, J CHEM INF MODEL, V47, P376, DOI 10.1021/ci600488x; Graham DJ, 2000, J CHEM INF COMP SCI, V40, P942, DOI 10.1021/ci990182k; Graham DJ, 2002, J CHEM INF COMP SCI, V42, P215, DOI 10.1021/ci0102923; Graham DJ, 2005, J CHEM INF MODEL, V45, P1223, DOI 10.1021/ci050101m; Gromiha MM, 1999, PROTEIN ENG, V12, P549, DOI 10.1093/protein/12.7.549; HAGE P, 1995, SOC NETWORKS, V17, P57, DOI 10.1016/0378-8733(94)00248-9; Herman EH, 2001, CANCER CHEMOTH PHARM, V48, P297, DOI 10.1007/s002800100348; Hu S, 2006, PROTEOMICS, V6, P6326, DOI 10.1002/pmic.200600284; Jacobs MN, 2004, TOXICOLOGY, V205, P43, DOI 10.1016/j.tox.2004.06.036; Jones RL, 2006, EXPERT REV ANTICANC, V6, P1249, DOI 10.1586/14737140.6.9.1249; Kantor AB, 2002, DIS MARKERS, V18, P91; KATRITZKY AR, 1993, J CHEM INF COMP SCI, V33, P835, DOI 10.1021/ci00016a005; Katritzky AR, 2002, J CHEM INF COMP SCI, V42, P71, DOI 10.1021/ci0100503; Katritzky Alan R., 2002, Current Topics in Medicinal Chemistry, V2, P1333, DOI 10.2174/1568026023392922; Katritzky AR, 2001, J CHEM INF COMP SCI, V41, P569, DOI 10.1021/ci000099t; Katritzky AR, 2001, J CHEM INF COMP SCI, V41, P679, DOI 10.1021/ci000134w; KIER LB, 1980, J PHARM SCI, V69, P807, DOI 10.1002/jps.2600690717; Kowalski RD, 1982, HDB STAT, P673; Kutner M., 2005, APPL LINEAR STAT MOD, P271; KUTNER MH, 2005, APPL LINEAR STAT MOD, P278; LAMBERTENGHIDELILIERS G, 1976, TUMORI, V62, P517; Liao B, 2005, CHEM PHYS LETT, V402, P380, DOI 10.1016/j.cplett.2004.12.062; Liao B, 2004, J COMPUT CHEM, V25, P1364, DOI 10.1002/jcc.20060; Liao B, 2005, CHEM PHYS LETT, V414, P296, DOI 10.1016/j.cplett.2005.08.079; Liao B, 2005, CHEM PHYS LETT, V401, P196, DOI 10.1016/j.cplett.2004.11.059; Liotta LA, 2003, NATURE, V425, P905, DOI 10.1038/425905a; Liu YC, 2002, J CHEM INF COMP SCI, V42, P529, DOI 10.1021/ci010017g; Loewenstern D, 1999, J COMPUT BIOL, V6, P125, DOI 10.1089/cmb.1999.6.125; Manke Thomas, 2005, Genome Inform, V16, P159; Mason O, 2007, IET SYST BIOL, V1, P89, DOI 10.1049/iet-syb:20060038; McDonald WH, 2002, DIS MARKERS, V18, P99; Mehta AI, 2003, DIS MARKERS, V19, P1; Mei H, 2005, BIOPOLYMERS, V80, P775, DOI 10.1002/bip.20296; Morales AH, 2006, TOXICOLOGY, V220, P51, DOI 10.1016/j.tox.2005.11.024; Morales AH, 2006, J MOL MODEL, V12, P769, DOI 10.1007/s00894-005-0088-5; Moridani MY, 2004, CHEM-BIOL INTERACT, V147, P297, DOI 10.1016/j.cbi.2004.02.001; Moudgal CJ, 2003, ENVIRON SCI TECHNOL, V37, P5228, DOI 10.1021/es034201p; Nascimento DG, 2006, TOXICON, V47, P628, DOI 10.1016/j.toxicon.2006.01.015; Petricoin EF, 2002, J NATL CANCER I, V94, P1576; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Petricoin Emanuel F, 2004, Toxicol Pathol, V32 Suppl 1, P122, DOI 10.1080/01926230490426516; Pillai S, 2003, AIDS RES HUM RETROV, V19, P145, DOI 10.1089/088922203762688658; Prusis P, 2002, PROTEIN ENG, V15, P305, DOI 10.1093/protein/15.4.305; Radestock S, 2005, J MED CHEM, V48, P5466, DOI 10.1021/jm050114r; Randic M, 2000, J CHEM INF COMP SCI, V40, P50, DOI 10.1021/ci990084z; Randic M, 2000, J CHEM INF COMP SCI, V40, P1235, DOI 10.1021/ci000034q; Randic M, 2004, SAR QSAR ENVIRON RES, V15, P191, DOI 10.1080/10629360410001697753; Randic M, 2004, CHEM PHYS LETT, V386, P468, DOI 10.1016/j.cplett.2004.01.088; Randic M, 2005, CHEM PHYS LETT, V407, P205, DOI 10.1016/j.cplett.2005.03.086; Randic M, 2003, J CHEM INF COMP SCI, V43, P532, DOI 10.1021/ci020051a; Randic M, 2003, CHEM PHYS LETT, V373, P558, DOI 10.1016/S0009-2614(03)00639-0; Randic M, 2004, SAR QSAR ENVIRON RES, V15, P147, DOI 10.1080/10629360410001697744; RANDIC M, 1991, NEW J CHEM, V15, P517; RANDIC M, 1991, J CHEM INF COMP SCI, V31, P311, DOI 10.1021/ci00002a018; RANDIC M, 1993, J COMPUT CHEM, V14, P363, DOI 10.1002/jcc.540140311; Roy K, 2003, J MOL MODEL, V9, P259, DOI 10.1007/s00894-003-0135-z; Roy K, 2004, J CHEM INF COMP SCI, V44, P559, DOI 10.1021/ci0342066; Saiz-Urra L, 2007, EUR J MED CHEM, V42, P64, DOI 10.1016/j.ejmech.2006.08.005; Saiz-Urra L, 2005, BIOORGAN MED CHEM, V13, P3641, DOI 10.1016/j.bmc.2005.03.041; Saiz-Urra L, 2007, J MOL GRAPH MODEL, V25, P680, DOI 10.1016/j.jmgm.2006.05.006; Saiz-Urraa L, 2006, BIOORGAN MED CHEM, V14, P7347, DOI 10.1016/j.bmc.2006.05.081; Santana L, 2006, J MED CHEM, V49, P1149, DOI 10.1021/jm0509849; Seifert M.H.J., 2003, DRUG DISCOV TODAY, V1, P143; Serra JR, 2001, CHEM RES TOXICOL, V14, P1535, DOI 10.1021/tx010101q; Siraki AG, 2004, CURR OPIN DRUG DISC, V7, P118; Stahura FL, 2000, J CHEM INF COMP SCI, V40, P1245, DOI 10.1021/ci0003303; Stahura FL, 2002, J CHEM INF COMP SCI, V42, P550, DOI 10.1021/ci010243q; Stewart J., 1998, ECONOMETRICS; Strait BJ, 1996, BIOPHYS J, V71, P148; Taraviras SL, 2000, J CHEM INF COMP SCI, V40, P1128, DOI 10.1021/ci990149y; Urbanova D, 2006, NEOPLASMA, V53, P183; van Dalen EC, 2006, EUR J CANCER, V42, P3199, DOI 10.1016/j.ejca.2006.08.002; VANWATERBEEMD H, 1995, CHEMOMETRIC METHODS, V2; VANWATERBEEND H, 1995, CHEMOMETRIC METHODS, P265; Ward JB, 1996, ENVIRON HEALTH PERSP, V104, P895, DOI 10.2307/3433007; Witten I. H., 2005, DATA MINING PRACTICA; Witten IH, 2000, DATA MINING PRACTICA, P265; Zhang J, 2002, TOXICOL PATHOL, V30, P28, DOI 10.1080/01926230252824680; ZHANG J, 1993, AM J PATHOL, V142, P1916; Zupan J, 2005, J CHEM INF MODEL, V45, P309, DOI 10.1021/ci040104j; ZWEIG MH, 1994, ARCH PATHOL LAB MED, V118, P141; ZWEIG MH, 1992, CLIN CHEM, V38, P1425; *STATS INC, 2001, ATISTICA; *WEKA, 2002, WAIK ENV KNOWL AN	150	22	23	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0893-228X		CHEM RES TOXICOL	Chem. Res. Toxicol.	MAR	2008	21	3					619	632		10.1021/tx700296t		14	Chemistry, Medicinal; Chemistry, Multidisciplinary; Toxicology	Pharmacology & Pharmacy; Chemistry; Toxicology	275PY	WOS:000254085300011	
J	Cahill, A; Burke, M; O'Donovan, R; Riezler, S; van Genabith, J; Way, A				Cahill, Aoife; Burke, Michael; O'Donovan, Ruth; Riezler, Stefan; van Genabith, Josef; Way, Andy			Wide-coverage deep statistical parsing using automatic dependency structure annotation	COMPUTATIONAL LINGUISTICS			English	Article								A number of researchers have recently conducted experiments comparing "deep" hand-crafted wide-coverage with "shallow" treebank- and machine-learning-based parsers at the level of dependencies, using simple and automatic methods to convert tree output generated by the shallow parsers into dependencies. In this article, we revisit such experiments, this time using sophisticated automatic LFG f-structure annotation methodologies with surprising results. We compare various PCFG and history-based parsers to find a baseline parsing system that fits best into our automatic dependency structure annotation technique. This combined system of syntactic parser and dependency structure annotation is compared to two hand-crafted, deep constraint-based parsers, RASP and XLE. We evaluate using dependency-based gold standards and use the Approximate Randomization Test to test the statistical significance of the results. Our experiments show that machine-learning-based shallow grammars augmented with sophisticated automatic dependency annotation technology outperform hand-crafted, deep, wide-coverage constraint grammars. Currently our best system achieves an f-score of 82.73% against the PARC 700 Dependency Bank, a statistically significant improvement of 2.18% over the most recent results of 80.55% for the hand-crafted LFG grammar and XLE parsing system and an f-score of 80.23% against the CBS 500 Dependency Bank, a statistically significant 3.66% improvement over the 76.57% achieved by the hand-crafted RASP grammar and parsing system.	[Burke, Michael; van Genabith, Josef; Way, Andy] Dublin City Univ, IBM Ctr Adv Studies, Dublin 9, Ireland; [Riezler, Stefan] Palo Alto Res Ctr, Palo Alto, CA USA	Cahill, A (reprint author), Univ Stuttgart, Inst Maschinelle Sprachverarbeitung, D-7000 Stuttgart, Germany.	cahill@ims.uni-stuttgart.de					Abney SP, 1997, COMPUT LINGUIST, V23, P597; ALSHAWI H, 1992, ELLIPSIS COMP GENERA; Baldwin T., 2004, P 4 INT C LANG RES E, P2047; BIKEL DM, 2002, P HLT 2002 SAN DIEG, P24; Black E., 1991, P DARPA SPEECH NAT L, P306, DOI 10.3115/112405.112467; Bod Rens, 2003, P 10 C EUR CHAPT ASS, P19; BOUMA G, 2000, COMPUTATIONAL LINGUI, P45; Bresnan J., 2001, LEXICAL FUNCTIONAL S; BRISCOE E, 1987, P 10 INT JOINT C ART, P703; Briscoe T., 1993, Computational Linguistics, V19; Briscoe Ted, 2006, P41, DOI 10.3115/1273073.1273079; BURKE M, 2006, AUTOMATIC TREEBANK A; BURKE M, 2004, P 9 INT C LFG CHRIST, P101; Butt Miriam, 2002, P COLING 2002 WORKSH, P1; CAHILL A, 2002, P 7 INT C LFG PAL AL; CAHILL A, 2004, PARSING AUTOMATICALL; CAHILL A, 2002, P LREC WORKSH LING K, P8; CAHILL A, 2004, P 42 ANN M ASS COMP, P320; CARROLL J, 2002, P 19 INT C COMP LING, P134; CARROLL J, 2002, HLT WORKSH PARSEVAL; CARROLL J, 1998, P 1 INT C LANG RES E, P447; Charniak E, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1031; Charniak Eugene, 2000, P 1 C N AM CHAPT ASS, P132; Chinchor Nancy, 1993, COMPUTATIONAL LINGUI, V19, P409; Clark S., 2004, P 42 ANN M ASS COMP, P104; CLARK S, 2002, P LREC WORKSH PARS, P60; Clark Stephen, 2007, P 45 ANN M ASS COMP, P248; Cohen P. R., 1995, EMPIRICAL METHODS AR; Collins M., 1999, THESIS U PENNSYLVANI; Collins M.J., 1997, P 35 ANN M ASS COMP, P16; CROUCH R, 2002, P LREC WORKSH PARSEV; DALRYMPLE M, 2003, LEXICAL FUNCTIONAL G; Dienes P, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P33; EISELE A, 1986, P INT C COMP LING, P551, DOI 10.3115/991365.991525; Flickinger D., 2000, NAT LANG ENG, V6, P15, DOI 10.1017/S1351324900002370; GAIZAUSKA R, 1995, CS9525 U SHEFF DEP C; Gildea D, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P57; Hockenmaier J., 2002, P 40 ANN M ASS COMP, P335; HOCKENMAIER J, 2003, P 41 ANN C ASS COMP; Johnson M, 1998, COMPUT LINGUIST, V24, P613; JONSON M, 2002, P 40 ANN M ASS COMP, P136; KAPLAN R, 1982, MENTAL REPRESENTATIO, P172; Kaplan Ronald M, 2004, P HUM LANG TECHN C N, P97; KAPLAN RM, 1989, ALTERNATIVE CONCEPTIONS OF PHRASE STRUCTURE, P17; KING T, 2003, P EACL03 4 INT WORKS; Kingsbury Paul, 2002, P HUM LANG TECHN C H, DOI 10.3115/1289189.1289207; Klein D., 2003, P 41 M ASS COMP LING, P423; LEECH G, 1991, ENGLISH COMPUTER COR, P15; Levy Roger, 2004, P 41 M ACL BARC SPAI, P328; Lin Dekang, 1995, P IJCAI 95, P1420; Magerman D., 1994, THESIS STANFORD U; MARCUS M, 1994, P 1994 HUM LANG TECH, P110; MCCARTHY M, 2003, DESIGN EVALUATION LI; Miyao Y., 2002, P HUM LANG TECHN C H, P292; MIYAO Y, 2003, P INT C REC ADV NAT, P285; MIYAO Y, 2004, P COLING 2004, P1392, DOI 10.3115/1220355.1220559; NOREEN EW, 1989, COMPUTER INTESIVE ME; ODONOVAN R, 2004, P 42 ANN M ASS COMP, P368; Pereira Fernando, 2006, P 11 C EUR CHAPT ASS, P81; Pollard C., 1994, HEAD DRIVEN PHRASE S; PREISS J, 2003, P EACL 03, P291; Ratnaparkhi A., 1996, P C EMP METH NAT LAN, P133; Riezler S., 2002, P 40 ANN M ASS COMP, P271; Sampson G., 1995, ENGLISH COMPUTER SUS; TSURUOKA Y, 2004, P IJCNLP 04 WORKSH S; VANGENABITH J, 1997, P ACL EACL 97, P402; VANGENABITH J, 1996, 16 INT C COMP LING C, P262; Xia F, 1999, P 5 NAT LANG PROC PA, P398; XUE NW, 2004, NATURAL LANGUAGE ENG, V10, P1; Yeh Alexander, 2000, P 18 INT C COMP LING, P947	70	2	2	M I T PRESS	CAMBRIDGE	238 MAIN STREET, STE 500, CAMBRIDGE, MA 02142-1046 USA	0891-2017		COMPUT LINGUIST	Comput. Linguist.	MAR	2008	34	1					81	124		10.1162/coli.2008.34.1.81		44	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics; Language & Linguistics	Computer Science; Linguistics	281GR	WOS:000254485400003	
J	Sewell, C; Morris, D; Blevins, NH; Dutta, S; Agrawal, S; Barbagli, F; Salisbury, K				Sewell, Christopher; Morris, Dan; Blevins, Nikolas H.; Dutta, Sanjeev; Agrawal, Sumit; Barbagli, Federico; Salisbury, Kenneth			Providing metrics and performance feedback in a surgical simulator	COMPUTER AIDED SURGERY			English	Article						simulation; metrics; feedback; performance evaluation; mastoidectomy; validation	PROBABILISTIC FUNCTIONS; SURGERY; SKILLS	One of the most important advantages of computer simulators for surgical training is the opportunity they afford for independent learning. However, if the simulator does not provide useful instructional feedback to the user, this advantage is significantly blunted by the need for an instructor to supervise and tutor the trainee while using the simulator. Thus, the incorporation of relevant, intuitive metrics is essential to the development of efficient simulators. Equally as important is the presentation of such metrics to the user in such a way so as to provide constructive feedback that facilitates independent learning and improvement. This paper presents a number of novel metrics for the automated evaluation of surgical technique. The general approach was to take criteria that are intuitive to surgeons and develop ways to quantify them in a simulator. Although many of the concepts behind these metrics have wide application throughout surgery, they have been implemented specifically in the context of a simulation of mastoidectomy. First, the visuohaptic simulator itself is described, followed by the details of a wide variety of metrics designed to assess the user's performance. We present mechanisms for presenting visualizations and other feedback based on these metrics during a virtual procedure. We further describe a novel performance evaluation console that displays metric-based information during an automated debriefing session. Finally, the results of several user studies are reported, providing some preliminary validation of the simulator, the metrics, and the feedback mechanisms. Several machine learning algorithms, including Hidden Markov Models and a Naive Bayes Classifier, are applied to our simulator data to automatically differentiate users' expertise levels.	[Sewell, Christopher; Morris, Dan; Barbagli, Federico; Salisbury, Kenneth] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA; [Blevins, Nikolas H.; Agrawal, Sumit] Stanford Univ, Dept Otolaryngol, Stanford, CA 94305 USA; [Dutta, Sanjeev; Salisbury, Kenneth] Stanford Univ, Dept Surg, Stanford, CA 94305 USA	Sewell, C (reprint author), 1325 Mills St,Apt 9, Menlo Pk, CA 94025 USA.	csewell@cs.stanford.edu					Agus M., 2002, Computing and Visualization in Science, V5, DOI 10.1007/s00791-002-0085-5; Agus M., 2004, Proceedings. 12th International Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems; Anastakis DJ, 2003, AM J SURG, V185, P378, DOI 10.1016/S0002-9610(02)01403-4; BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196; BAUM LE, 1967, B AM MATH SOC, V73, P360, DOI 10.1090/S0002-9904-1967-11751-8; Bridges M, 1999, AM J SURG, V177, P28, DOI 10.1016/S0002-9610(98)00289-X; Bryan J., 2001, Proceedings Visualization 2001 (Cat. No.01CH37269), DOI 10.1109/VISUAL.2001.964561; Cotin S, 2002, LECT NOTES COMPUT SC, V2488, P35; Dosis A, 2005, ST HEAL T, V111, P115; FEYGIN D, 2002, P 10 IEEE HAPT S ORL; Gates EA, 1997, AM J OBSTET GYNECOL, V176, P1293, DOI 10.1016/S0002-9378(97)70348-X; GATES EA, 1997, AM J OBSTET GYNECOL, V176, P98; KAHOL K, 2007, IEEE MULTIM IN PRESS; KERNODLE MW, 1992, J MOTOR BEHAV, V24, P187; LUPERFOY S, 2006, PLEN SESS MED M VIRT; MACKEL T, 2006, STUDIES HLTH TECHNOL, V119, P355; MORRIS D, 200606 STANF U DEP C; Morris D, 2006, IEEE COMPUT GRAPH, V26, P48, DOI 10.1109/MCG.2006.140; Morris D., 2007, P 2 JOINT EUROHAPTIC, P21; Murphy TE, 2004, THESIS J HOPKINS U; Paisley AM, 2005, MED TEACH, V27, P634, DOI 10.1080/01421590500251175; PETERSIK A, 2002, P IEEE VIRT REAL VR; Pflesser Bernhard, 2002, Comput Aided Surg, V7, P74, DOI 10.3109/10929080209146018; RENZ M, 2001, P EUR C, P149; Reznick R, 1996, AM J SURG, V172, P226; Rissanen MJ, 2007, ST HEAL T, V125, P388; Ritter E Matt, 2005, Surg Innov, V12, P233, DOI 10.1177/155335060501200308; Rosen J, 2001, IEEE T BIO-MED ENG, V48, P579, DOI 10.1109/10.918597; ROTH AM, 1976, METAB PEDIATR SYST O, V1, P35; Sewell C, 2005, ST HEAL T, V111, P451; Sewell C, 2006, ST HEAL T, V119, P497; Sewell C, 2007, ST HEAL T, V125, P427; Sidhu RS, 2004, SURGERY, V135, P6, DOI 10.1016/S0039-6060(03)00154-5; Silverstein J, 2007, ST HEAL T, V125, P436; STREDNEY D, 2003, OH LEARN NETW WIND F; TUCHSCHMID S, 2007, STUDIES HLTH TECHNOL, V125, P473; WINSTEIN CJ, 1990, J EXP PSYCHOL LEARN, V16, P677, DOI 10.1037//0278-7393.16.4.677; Yang UY, 2002, PRESENCE-TELEOP VIRT, V11, P304, DOI 10.1162/105474602317473240	38	18	18	INFORMA HEALTHCARE	LONDON	TELEPHONE HOUSE, 69-77 PAUL STREET, LONDON EC2A 4LQ, ENGLAND	1092-9088		COMPUT AIDED SURG	Comput. Aided Surg.	MAR	2008	13	2					63	81		10.1080/10929080801957712		19	Surgery	Surgery	308VK	WOS:000256418000001	
J	Craninx, M; Fievez, V; Vlaeminck, B; De Baets, B				Craninx, M.; Fievez, V.; Vlaeminck, B.; De Baets, B.			Artificial neural network models of the rumen fermentation pattern in dairy cattle	COMPUTERS AND ELECTRONICS IN AGRICULTURE			English	Article						artificial neural networks; milk fatty acids; prediction; rumen fermentation; volatile fatty acids	CHAIN FATTY-ACIDS; MILK-FAT; LACTATING COW; BOVINE-MILK; IN-VIVO; ODD; CONCENTRATE; SILAGES; FORAGE; DIET	The objectives of this study were: (1) to predict the rumen fermentation pattern from milk fatty acids using a machine learning technique, i.e. artificial neural networks (ANN) combined with feature selection and (2) to compare the prediction accuracy of the resulting model to that of a statistical multi-linear regression model, based on odd and branched chain milk fatty acids. Data were collected from 10 experiments with rumen fistulated dairy cows, resulting in a dataset of 138 observations. Feature selection was based on correlation and principal component analysis, and background physiological knowledge. Different ANN architectures and training algorithms were assessed. The evaluation of the model performance, based on the test dataset, showed a root mean square prediction error, expressed relative to the observed mean, of 2.65%, 7.67% and 7.61% of the observed mean for acetate, propionate and butyrate, respectively. Compared to a multi-linear regression model, the ANN revealed not to perform significantly better. However, the results confirm that milk fatty acids have great potential to predict molar proportions of individual volatile fatty acids in the rumen. (C) 2007 Elsevier B.V. All rights reserved.	[Craninx, M.; Fievez, V.; Vlaeminck, B.] Univ Ghent, Lab Anim Nutr & Anim Prod Qual, B-9090 Melle, Belgium; [De Baets, B.] Univ Ghent, Dept Appl Math Biometr & Proc Control, B-9000 Ghent, Belgium	Fievez, V (reprint author), Univ Ghent, Lab Anim Nutr & Anim Prod Qual, Proefhoevestr 10, B-9090 Melle, Belgium.	veerle.fievez@UGent.be	De Baets, Bernard/E-8877-2010				BALDWIN RL, 1987, J DAIRY RES, V54, P107; Bannink A, 1997, J THEOR BIOL, V189, P353, DOI 10.1006/jtbi.1997.0510; Basheer IA, 2000, J MICROBIOL METH, V43, P3, DOI 10.1016/S0167-7012(00)00201-3; Bauman DE, 2001, LIVEST PROD SCI, V70, P15, DOI 10.1016/S0301-6226(01)00195-6; Beale M., 2005, NEURAL NETWORK TOOLB; Bibby J., 1977, PREDICTION IMPROVEME; Brown VE, 2002, ANIM FEED SCI TECH, V98, P13, DOI 10.1016/S0377-8401(01)00341-8; Bruinenberg MH, 2004, J AGR SCI, V142, P79, DOI 10.1017/S0021859604004046; Cabrita ARJ, 2003, J DAIRY SCI, V86, P4020; de Brabander D. L., 2004, 55 ANN M EUR ASS AN, P97; de Brabander D. L., 2005, 56 ANN M EUR ASS AN, P134; Dewhurst RJ, 2003, J DAIRY SCI, V86, P2598, DOI 10.3168/jds.S0022-0302(03)73855-7; DIJKSTRA J, 1992, J NUTR, V122, P2239; Fievez V, 2003, J DAIRY SCI, V86, P4047; Friggens NC, 1998, J DAIRY SCI, V81, P1331; Heald CW, 2000, J DAIRY SCI, V83, P711; Hindle VA, 2005, J ANIM PHYSIOL AN N, V89, P158, DOI 10.1111/j.1439-0396.2005.00560.x; Kalscheur KF, 1997, J DAIRY SCI, V80, P2104; Lek S, 1999, ECOL MODEL, V120, P65, DOI 10.1016/S0304-3800(99)00092-7; Loor JJ, 2005, J DAIRY SCI, V88, P726; Maier HR, 2000, ENVIRON MODELL SOFTW, V15, P101, DOI 10.1016/S1364-8152(99)00007-9; McDonald P, 1995, ANIMAL NUTR; MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5; Moorby JM, 2006, J DAIRY SCI, V89, P3552; OLDEN JD, 2004, ECOL MODEL, V178, P289; Olden JD, 2002, ECOL MODEL, V154, P135, DOI 10.1016/S0304-3800(02)00064-9; Ozesmi SL, 2006, ECOL MODEL, V195, P83, DOI 10.1016/j.ecolmodel.2005.11.012; Pietersma D, 2003, COMPUT ELECTRON AGR, V38, P1, DOI 10.1016/S0168-1699(02)00104-7; Piramuthu S, 2004, EUR J OPER RES, V156, P483, DOI [10.1016/S0377-2217(02)00911-6, 10.1016/s0377-2217(02)00911-6]; Plumb AP, 2005, EUR J PHARM SCI, V25, P395, DOI 10.1016/j.ejps.2005.04.010; Rymer C, 2002, ANIM FEED SCI TECH, V101, P31, DOI 10.1016/S0377-8401(02)00215-8; Salehi F, 1998, COMPUT ELECTRON AGR, V20, P199, DOI 10.1016/S0168-1699(98)00018-0; SHINGFIELD KJ, 2005, J DAIRY RES, V72, P1; Shingfield KJ, 2003, ANIM SCI, V77, P165; Skapura D. M., 1996, BUILDING NEURAL NETW; Stefanon B, 2001, J NUTR, V131, P3307; St-Pierre NR, 2003, J DAIRY SCI, V86, P344, DOI 10.3168/jds.S0022-0302(03)73612-1; SUTTON JD, 1985, J DAIRY SCI, V68, P3376; Vlaeminck B, 2005, J DAIRY SCI, V88, P1031; Vlaeminck B, 2006, J DAIRY SCI, V89, P2668; Vlaeminck B, 2006, J DAIRY SCI, V89, P3954; Vlaeminck B, 2004, J ANIM PHYSIOL AN N, V88, P401, DOI 10.1111/j.1439-0396.2004.00497.x; Vlaeminck B, 2006, ANIM FEED SCI TECH, V131, P389, DOI 10.1016/j.anifeedsci.2006.06.017; Walczak S, 1999, INFORM SOFTWARE TECH, V41, P107, DOI 10.1016/S0950-5849(98)00116-5; Weimer PJ, 1999, J DAIRY SCI, V82, P122; *AFRC, 1998, 11 AFRC TECH COMM RE	46	14	17	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0168-1699		COMPUT ELECTRON AGR	Comput. Electron. Agric.	MAR	2008	60	2					226	238		10.1016/j.compag.2007.08.005		13	Agriculture, Multidisciplinary; Computer Science, Interdisciplinary Applications	Agriculture; Computer Science	265BI	WOS:000253333700011	
J	Lambach, D; Gamberger, D				Lambach, Daniel; Gamberger, Dragan			Temporal analysis of political instability through descriptive subgroup discovery	CONFLICT MANAGEMENT AND PEACE SCIENCE			English	Article						dynamic variables; political instability task force; subgroup discovery	CIVIL-WAR; MODELS	This paper analyzes the Political Instability Task Force (PITF) data set using a new methodology based on machine learning tools for subgroup discovery. While the PITF used static data, this study employs both static and dynamic descriptors covering the 5-year period before onset. The methodology provides several descriptive models of countries especially prone to political instability. For the most part, these models corroborate the PITF's findings and support earlier theoretical works. The paper also shows the value of subgroup discovery as a tool for developing a unified concept of political instability as well as for similar research designs.	Univ Duisburg Essen, INEF, Inst Dev & Peace, D-47057 Duisburg, Germany; [Gamberger, Dragan] Rudjer Boskovic Inst, Informat Syst Lab, Zagreb, Croatia	Lambach, D (reprint author), Univ Duisburg Essen, INEF, Inst Dev & Peace, Geibelstr 41, D-47057 Duisburg, Germany.	daniel.lambach@inef.uni-due.de	Gamberger, Dragan/J-3752-2012				Baker JR, 2004, MOLECULES, V9, P989, DOI 10.3390/91200989; Buhaug H, 2005, POLIT GEOGR, V24, P399, DOI 10.1016/j.polgeo.2005.01.006; CLEMENT C, 2004, THESIS U LOUVAIN BEL; Collier Paul, 2001, GREED GRIEVANCE CIVI; DANN A, 2003, THESIS U COLOGNE GER; DEWAAL A, 2000, WHO FIGHTS WHO CARES; ESTY DC, 1998, PREVENTIVE MEASURES, P27; Esty DC, 1998, STATE FAILURE TASK F; ESTY DC, 1995, STATE FAILURE TASK F; Fearon JD, 2003, AM POLIT SCI REV, V97, P75; Fearon JD, 2004, J PEACE RES, V41, P275, DOI 10.1177/0022343304043770; Gamberger D, 2003, ARTIF INTELL MED, V28, P27, DOI 10.1016/S0933-3657(03)00034-4; Gamberger D., 2002, J ARTIF INTELL RES, V17, P501; Gamberger D, 2004, J BIOMED INFORM, V37, P269, DOI 10.1016/j.jbi.2004.07.007; George A. L., 2005, CASE STUDIES THEORY; Goldstone Jack A., 2000, STATE FAILURE TASK F; Hegre H, 2001, AM POLIT SCI REV, V95, P33; Huntington S., 1969, POLITICAL ORDER CHAN; King G, 2001, WORLD POLIT, V53, P623, DOI 10.1353/wp.2001.0018; Lacina B, 2006, J CONFLICT RESOLUT, V50, P276, DOI 10.1177/0022002705284828; Sambanis N, 2004, J CONFLICT RESOLUT, V48, P814, DOI 10.1177/0022002704269355; SARTORI G, 1970, AM POLIT SCI REV, V64, P1033, DOI 10.2307/1958356; SCHRODT PA, 2002, APSA C BOST MA 29 AU; Zartman I. William, 1995, COLLAPSED STATES DIS	24	3	3	TAYLOR & FRANCIS INC	PHILADELPHIA	325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA	0738-8942		CONFLICT MANAG PEACE	Confl. Manage. Peace Sci.	SPR	2008	25	1					19	32		10.1090/07388940701860359		14	International Relations	International Relations	288QM	WOS:000255000900002	
J	Jullian, N; Afshar, M				Jullian, Nathalie; Afshar, Mohammad			Novel rule-based method for multi-parametric multi-objective decision support in lead optimization using KEM	CURRENT COMPUTER-AIDED DRUG DESIGN			English	Article						Galois lattices; drug design; multi-objective optimization; structure-activity relationships (SAR); machine learning	NAIVE BAYES CLASSIFIER; DRUG DISCOVERY; RANDOM FOREST; BINDING AFFINITIES; VECTOR MACHINES; PREDICTION; MODEL; IDENTIFICATION; INHIBITORS; MUTAGENICITY	This paper focuses on the recent development of rule-based methods and their applications to the drug discovery process. For a given target, the path for designing new drugs with a lower attrition rate is based on an effective mining of the huge amount of experimental in vitro and in vivo data which has been collected. These data often come in various formats, from many different areas such as chemistry, biology, pharmacology, toxicity and extraction of the critical information is not an easy task. To guide the multi-objective optimization, we have developed a decision-support system (KEM(R)), based on the Galois lattices theory and constraint satisfaction programming (CSP). After a brief overview of machine learning applications, we will describe the methodology used in KEM for data mining and prediction. Two examples of applications in the drug discovery area will be discussed.	[Jullian, Nathalie; Afshar, Mohammad] Ariana Pharma, Inst Pasteur BioTop, F-75724 Paris 15, France	Afshar, M (reprint author), Ariana Pharma, Inst Pasteur BioTop, 28 Rue Docteur Roux, F-75724 Paris 15, France.	m.afshar@arianapharma.com					AFSHAR M, 2006, J COMPR MED CHEM 2, V4, P767; Andrews CW, 2000, PHARM RES-DORDR, V17, P639, DOI 10.1023/A:1007556711109; BAO L, 2005, NUCL ACAD RES, P33; Bhavani S, 2006, J CHEM INF MODEL, V46, P2478, DOI 10.1021/ci0601281; Blair RM, 2000, TOXICOL SCI, V54, P138, DOI 10.1093/toxsci/54.1.138; Bruce CL, 2007, J CHEM INF MODEL, V47, P219, DOI [10.1021/ci600332j, 10.1021/ci600322j]; Burbidge R, 2001, COMPUT CHEM, V26, P5, DOI 10.1016/S0097-8485(01)00094-8; Burden FR, 1999, J MED CHEM, V42, P3183, DOI 10.1021/jm980697n; Cannon EO, 2007, J COMPUT AID MOL DES, V21, P269, DOI 10.1007/s10822-007-9113-3; Chen B, 2007, J COMPUT AID MOL DES, V21, P53, DOI 10.1007/s10822-006-9096-5; Cottrell SJ, 2006, J COMPUT AID MOL DES, V20, P735, DOI 10.1007/s10822-006-9086-7; CRONIN MTD, 2003, ENV HLTH PERSPECT, V11, P1376; DIAZURIATE R, 2006, BMC BIOINFORMATICS, V6, P3; Ekins S, 2002, J COMPUT AID MOL DES, V16, P381, DOI 10.1023/A:1020816005910; Ekins S, 2006, ADV DRUG DELIVER REV, V58, P1409, DOI 10.1016/j.addr.2006.09.005; Fang H, 2001, CHEM RES TOXICOL, V14, P280, DOI 10.1021/tx000208y; GILLIGAN PJ, 1992, J MED CHEM, V35, P4344, DOI 10.1021/jm00101a012; Helma C, 2004, J CHEM INF COMP SCI, V44, P1402, DOI 10.1021/ci034254q; Hou TJ, 2006, CURR MED CHEM, V13, P2653, DOI 10.2174/092986706778201558; Jacobsson M, 2003, J MED CHEM, V46, P5781, DOI 10.1021/jm030896t; Karwath A, 2006, J CHEM INF MODEL, V46, P2432, DOI 10.1021/ci060159g; King RD, 1997, J COMPUT AID MOL DES, V11, P571, DOI 10.1023/A:1007967728701; King RD, 1996, P NATL ACAD SCI USA, V93, P438, DOI 10.1073/pnas.93.1.438; King RD, 2000, YEAST, V17, P283, DOI 10.1002/1097-0061(200012)17:4<283::AID-YEA52>3.0.CO;2-F; Klon AE, 2004, J MED CHEM, V47, P4356, DOI 10.1021/jm049970d; KRAMER JA, 2007, D L NAT REV DRUG DIS, V6, P636; Kramer S, 2002, SAR QSAR ENVIRON RES, V13, P509, DOI 10.1080/10629360290023340; LEE PH, 2007, IN PRESS J COMP AIDE; Lipinski CA, 1997, ADV DRUG DELIVER REV, V23, P3, DOI 10.1016/S0169-409X(96)00423-1; LIQUIERE M, 1998, INT C MACH LEARN; Liu HX, 2005, J COMPUT AID MOL DES, V19, P33, DOI 10.1007/s10822-005-0095-8; Loging W, 2007, NAT REV DRUG DISCOV, V6, P220, DOI 10.1038/nrd2265; Lombardo F, 2006, J MED CHEM, V49, P2262, DOI 10.1021/jm050200r; LUAN F, 2007, IN PRESS EUR J MED C; Marchand-Geneste N, 2002, J MED CHEM, V45, P399, DOI 10.1021/jm0155244; MARTIN YC, 1981, J MED CHEM, V24, P229, DOI 10.1021/jm00135a001; McDowell RM, 2002, SAR QSAR ENVIRON RES, V13, P111, DOI 10.1080/10629360290002280; Michailidis G, 2003, J COMPUT BIOL, V10, P689, DOI 10.1089/106652703322539033; Murray CW, 1998, J COMPUT AID MOL DES, V12, P503, DOI 10.1023/A:1008040323669; Norinder U, 2006, MOL DIVERS, V10, P207, DOI 10.1007/s11030-006-9019-3; Oloff S, 2007, J COMPUT AID MOL DES, V21, P87, DOI 10.1007/s10822-007-9108-0; Palmer DS, 2007, J CHEM INF MODEL, V47, P150, DOI 10.1021/ci060164k; Polley MJ, 2004, J MED CHEM, V47, P6230, DOI 10.1021/jm049621j; SAKIYAMA Y, 2007, IN PRESS J MOL GRAPH; Sawyer TK, 2006, NAT CHEM BIOL, V2, P646, DOI 10.1038/nchembio1206-646; SCHROETER TS, 2007, IN PRESS J COMP AIDE; Schuffenhauer A, 2007, J CHEM INF MODEL, V47, P325, DOI 10.1021/ci6004004; Searls DB, 2005, NAT REV DRUG DISCOV, V4, P45, DOI 10.1038/nrd1608; Sun HM, 2006, CHEMMEDCHEM, V1, P315, DOI 10.1002/cmdc.200500047; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; TERAMOTO R, 2007, IN PRESS J CHEM INF; TONG W, 2003, DSSTOX NCTRER SDF FI; Turcotte M, 2001, J MOL BIOL, V306, P591, DOI 10.1006/jmbi.2000.4414; VAMEK A, 2005, J COMPUT AID MOL DES, V19, P693; van de Waterbeemd H, 2003, NAT REV DRUG DISCOV, V2, P192, DOI 10.1038/nrd1032; VRACKO M, 2005, J COMPUT AID MOL DES, V1, P73; Wagener M, 2000, J CHEM INF COMP SCI, V40, P280, DOI 10.1021/ci990266t; WRINKLER DA, 2004, MOL BIOTECHNOL, V27, P139; Xia XY, 2004, J MED CHEM, V47, P4463, DOI 10.1021/jm0303195	59	1	1	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y26, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	1573-4099		CURR COMPUT-AID DRUG	Curr. Comput.-Aided Drug Des.	MAR	2008	4	1					35	45				11	Chemistry, Medicinal; Computer Science, Interdisciplinary Applications	Pharmacology & Pharmacy; Computer Science	273MY	WOS:000253936200005	
J	Van Heijst, D; Potharst, R; van Wezel, M				Van Heijst, Dennis; Potharst, Rob; van Wezel, Michiel			A support system for predicting eBay end prices	DECISION SUPPORT SYSTEMS			English	Article						boosting; eBay; electronic auctions; text mining	BUILDING TRUST; E-COMMERCE; ONLINE; AUCTIONS; INTERNET; MARKETS	We create a support system for predicting end prices on eBay. The end price predictions are based on the item descriptions found in the item listings of eBay, and on some numerical item features. The system uses text mining and boosting algorithms from the field of machine learning. Our system substantially outperforms the naive method of predicting the category mean price. Moreover, interpretation of the model enables us to identify influential terms in the item descriptions and shows that the item description is more influential than the seller feedback rating, which was shown to be influential in earlier studies. (c) 2007 Elsevier B.V. All rights reserved.	[Van Heijst, Dennis; Potharst, Rob; van Wezel, Michiel] Erasmus Univ, Inst Econ, Erasmus Sch Econ, NL-3000 DR Rotterdam, Netherlands	van Wezel, M (reprint author), Erasmus Univ, Inst Econ, Erasmus Sch Econ, POB 1738, NL-3000 DR Rotterdam, Netherlands.	mvanwezel@few.eur.nl					Atif Y, 2002, IEEE INTERNET COMPUT, V6, P18, DOI 10.1109/4236.978365; Ba SL, 2003, DECIS SUPPORT SYST, V35, P273, DOI 10.1016/S0167-9236(02)00074-X; Ba SL, 2002, MIS QUART, V26, P243, DOI 10.2307/4132332; Ba SL, 2001, DECIS SUPPORT SYST, V31, P323, DOI 10.1016/S0167-9236(00)00144-5; Bajari P, 2004, J ECON LIT, V42, P457, DOI 10.1257/0022051041409075; BREIMAN L, 1996, CLASSIFICATION REGRE; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; BRYAN D, 1999, 0003 VAND U DEP EC; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FREUND Y, 2006, P 13 INT C MACH LEAN, P148; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Ghani R, 2004, P INT WORKSH DAT MIN; Gregg DG, 2006, DECIS SUPPORT SYST, V41, P449, DOI 10.1016/j.dss.2004.07.007; Jones AJI, 2002, DECIS SUPPORT SYST, V33, P225, DOI 10.1016/S0167-9236(02)00013-1; Krishna V., 2002, AUCTION THEORY; MCCALLUM A, 1998, P AAAI98 WORKSH LEAR; Nasukawa T, 2001, IBM SYST J, V40, P967; Olson JS, 2000, COMMUN ACM, V43, P41, DOI 10.1145/355112.355121; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; R DEVELOPMENT CORE TEAM, 2005, R LANG ENV STAT COMP; Resnick P, 2006, EXP ECON, V9, P79, DOI 10.1007/s10683-006-4309-2; RIPLDY BD, 1996, PATTERN RECOGNITION; Roth AE, 2002, AM ECON REV, V92, P1093, DOI 10.1257/00028280260344632; SALGON G, 1989, AUTOMATIC TEXT PROCE; Slattery S., 1998, LECT NOTES COMPUTER, V1446, P38; THERNEAU TM, 2005, RPART RECURSIVE PART; WANG SS, IN PRESS J BUSINESS; Weiss SM, 1999, IEEE INTELL SYST APP, V14, P63, DOI 10.1109/5254.784086	29	6	6	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9236		DECIS SUPPORT SYST	Decis. Support Syst.	MAR	2008	44	4					970	982		10.1016/j.dss.2007.11.004		13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science	Computer Science; Operations Research & Management Science	270WF	WOS:000253750200015	
J	Teipel, SJ; Meindl, T; Grinberg, L; Heinsen, H; Hampel, H				Teipel, Stefan J.; Meindl, Thomas; Grinberg, Lea; Heinsen, Helmut; Hampel, Harald			Novel MRI techniques in the assessment of dementia	EUROPEAN JOURNAL OF NUCLEAR MEDICINE AND MOLECULAR IMAGING			English	Article						Alzheimer's disease; Dementia; MRI; DTI; Hippocampus; Brain atrophy; Disconnection; Diagnosis		Introduction Positive markers of Alzheimer's disease (AD) have been established in MRI that may allow early detection of AD in at-risk groups. In the near future, these markers will be of high relevance for the selection of at-risk subjects in secondary preventive trials. Methods We describe the methodology and diagnostic value of manual volumetry of the hippocampus and entorhinal cortex, automated voxel-based morphometry, cortical thickness measurement, basal forebrain volumetry and deformation-based morphometry, implementing multivariate statistics and machine learning algorithms to improve group separation and prediction of AD in at-risk groups. We also describe the methodological basis and results obtained in AD using the recently developed technique of diffusion tensor-based morphometry (DTI). This technique gives access to the integrity of subcortical fibre systems in the human brain. Results The best established structural biomarker of AD to date is hippocampus volume that already has been implemented as secondary endpoint in clinical trials on disease modification in AD. Automated approaches will gain an increasing role as endpoints of clinical trials in the near future given the interest in these techniques expressed by the regulatory authorities. DTI is still a developing field where analysis techniques are presently being devised to make optimal use of the multivariate data. Data on changes of fibre tract in preclinical AD are still limited, but the first results are promising in respect to a further enhancement of diagnostic accuracy by combining MRI and DTI. Conclusion Besides their diagnostic use, MRI and DTI will broaden our understanding of the pathophysiology of AD and the structural and functional basis of normal cognition.	[Teipel, Stefan J.; Hampel, Harald] Univ Munich, Dementia & Neuroimaging Sect, Dept Psychiat, Alzheimer Mem Ctr, D-80336 Munich, Germany; [Teipel, Stefan J.] Univ Rostock, Dept Psychiat, D-18147 Rostock, Germany; [Meindl, Thomas] Univ Munich, Univ Hosp Grosshadern, Dept Clin Radiol, D-81377 Munich, Germany; [Grinberg, Lea] Dept Patologia FMUSP, Sao Paulo, Brazil; [Grinberg, Lea] Inst Israelita Ensino & Pesquisa Albert Einstein, Sao Paulo, Brazil; [Heinsen, Helmut] Univ Wurzburg, Morphol Brain Res Unit, D-97070 Wurzburg, Germany; [Hampel, Harald] Incorporating Natl Childrens Hosp & Trinity Coll, Adelaide & Meath Hosp, Trin Coll Dublin, Discipline Psychiat,Sch Med, Dublin, Ireland	Teipel, SJ (reprint author), Univ Munich, Dementia & Neuroimaging Sect, Dept Psychiat, Alzheimer Mem Ctr, Nussbaumstr 7, D-80336 Munich, Germany.	stefan.teipel@med.uni-muenchen.de			Medical Faculty of the Ludwig-Maximilian University (Munich, Germany); Hirnliga e. V. (Nurmbrecht, Germany); Janssen-CILAG (Neuss, Germany); Bundesministerium fur Bildung und Forschung [BMBF 01 GI 0102]	Part of this work was supported by grants of the Medical Faculty of the Ludwig-Maximilian University (Munich, Germany) to S.J.T. and of the Hirnliga e. V. (Nurmbrecht, Germany) to S.J.T., an unrestricted research grant from Janssen-CILAG (Neuss, Germany) to H. H. and S.J.T. and a grant from the Bundesministerium fur Bildung und Forschung (BMBF 01 GI 0102) awarded to the dementia network "Kompetenznetz Demenzen".	Ashburner J, 2000, NEUROIMAGE, V11, P805, DOI 10.1006/nimg.2000.0582; Baron JC, 2001, NEUROIMAGE, V14, P298, DOI 10.1006/nimg.2001.0848; BASSER PJ, 1994, BIOPHYS J, V66, P259; Birks J, 2006, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD006104; Bookstein FL, 2001, NEUROIMAGE, V14, P1454, DOI 10.1006/nimg.2001.0770; Bozzali M, 2002, J NEUROL NEUROSUR PS, V72, P742, DOI 10.1136/jnnp.72.6.742; Broich K, 2007, INT PSYCHOGERIATR, V19, P509, DOI 10.1017/S1041610207005273; Brookmeyer R, 2007, FORECASTING GLOBAL B; BRUN A, 1986, ANN NEUROL, V19, P253, DOI 10.1002/ana.410190306; Busatto GF, 2003, NEUROBIOL AGING, V24, P221, DOI 10.1016/S0197-4580(02)00084-2; Chetelat G, 2002, NEUROREPORT, V13, P1939; Chetelat G, 2005, NEUROIMAGE, V27, P934, DOI 10.1016/j.neuroimage.2005.05.015; Chetelat G, 2003, NEUROIMAGE, V18, P525, DOI 10.1016/S1053-8119(02)00026-5; Csernansky JG, 2005, NEUROIMAGE, V25, P783, DOI 10.1016/j.neuroimage.2004.12.036; Davatzikos C, 2007, NEUROBIOL A IN PRESS; Devanand DP, 2007, NEUROLOGY, V68, P828, DOI 10.1212/01.wnl.0000256697.20968.d7; Du AT, 2001, J NEUROL NEUROSUR PS, V71, P441, DOI 10.1136/jnnp.71.4.441; Ewers M, 2006, NEUROBIOL AGING, V27, P1051, DOI 10.1016/j.neurobiolaging.2005.05.032; Fan Y, 2005, LECT NOTES COMPUT SC, V3749, P1; Fellgiebel A, 2005, NEUROBIOL AGING, V26, P1193, DOI 10.1016/j.neurobiolaging.2004.11.006; Fellgiebel A, 2004, DEMENT GERIATR COGN, V18, P101, DOI 10.1159/000077817; Fellgiebel A, 2006, PSYCHIAT RES-NEUROIM, V146, P283, DOI 10.1016/j.pscychresns.2006.01.006; Fox NC, 2000, ARCH NEUROL-CHICAGO, V57, P339, DOI 10.1001/archneur.57.3.339; Giannakopoulos P, 2003, NEUROLOGY, V60, P1495; Good CD, 2001, NEUROIMAGE, V14, P21, DOI 10.1006/nimg.2001.0786; Head D, 2004, CEREB CORTEX, V14, P410, DOI 10.1093/cercor/bhh003; Heinsen H, 2006, BRAIN, V129, pE43, DOI 10.1093/brain/awl026; Hirata Y, 2005, NEUROSCI LETT, V382, P269, DOI 10.1016/j.neulet.2005.03.038; Hsu YY, 2002, J MAGN RESON IMAGING, V16, P305, DOI 10.1002/jmri.10163; Huang JB, 2007, ANN NY ACAD SCI, V1097, P259, DOI 10.1196/annals.1379.021; Jack CR, 1998, NEUROLOGY, V51, P993; Jack CR, 1999, NEUROLOGY, V52, P1397; Jensen K, 1999, MED KLIN, V94, P522; Karas GB, 2004, NEUROIMAGE, V23, P708, DOI 10.1016/j.neuroimage.2004.07.006; KOWALL NW, 1987, ANN NEUROL, V22, P639, DOI 10.1002/ana.410220514; Krasuski JS, 1998, BIOL PSYCHIAT, V43, P60, DOI 10.1016/S0006-3223(97)00013-9; Laakso MP, 2000, BIOL PSYCHIAT, V47, P557, DOI 10.1016/S0006-3223(99)00167-5; Lerch J, 2002, NEUROIMAGE S1, V1, P7; Lerch JP, 2008, NEUROBIOL AGING, V29, P23, DOI 10.1016/j.neurobiolaging.2006.09.013; LEYS D, 1991, J NEUROL NEUROSUR PS, V54, P46, DOI 10.1136/jnnp.54.1.46; Lobo A, 2000, NEUROLOGY, V54, pS4; Loy C, 2006, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD001747.pub3; Medina D, 2006, NEUROBIOL AGING, V27, P663, DOI 10.1016/j.neurobiolaging.2005.03.026; MESULAM MM, 1988, J COMP NEUROL, V275, P216, DOI 10.1002/cne.902750205; MOSELEY ME, 1990, AM J NEURORADIOL, V11, P423; Mourao-Miranda J, 2005, NEUROIMAGE, V28, P980, DOI 10.1016/j.neuroimage.2005.06.070; Muller MJ, 2007, NEUROBIOL AGING, V28, P398, DOI 10.1016/j.neurobiolaging.2006.01.009; Muller MJ, 2005, NEUROIMAGE, V28, P1033, DOI 10.1016/j.neuroimage.2005.06.029; Naggara O, 2006, PSYCHIAT RES-NEUROIM, V146, P243, DOI 10.1016/j.pscychresns.2006.01.005; Pennanen C, 2004, NEUROBIOL AGING, V25, P303, DOI 10.1016/S0197-4580(03)00084-8; Pennanen C, 2005, J NEUROL NEUROSUR PS, V76, P11, DOI 10.1136/jnnp.2004.035600; Petersen RC, 2001, ARCH NEUROL-CHICAGO, V58, P1985, DOI 10.1001/archneur.58.12.1985; Raz N, 2004, NEUROLOGY, V62, P433; Ringman JM, 2007, BRAIN, V130, P1767, DOI 10.1093/brain/awm102; Rose SE, 2000, J NEUROL NEUROSUR PS, V69, P528, DOI 10.1136/jnnp.69.4.528; Rose SE, 2006, J NEUROL NEUROSUR PS, V77, P1122, DOI 10.1136/jnnp.2005.074336; Smith AD, 2002, P NATL ACAD SCI USA, V99, P4135, DOI 10.1073/pnas.082107399; Stahl R, 2007, RADIOLOGY, V243, P483, DOI 10.1148/radiol.2432051714; SU JH, 1993, BRAIN RES, V625, P228, DOI 10.1016/0006-8993(93)91063-X; Sydykova D, 2007, CEREB CORTEX, V17, P2276, DOI 10.1093/cercor/bhl136; Takahashi S, 2002, NEUROSCI LETT, V332, P45, DOI 10.1016/S0304-3940(02)00914-X; Teipel SJ, 2007, NEUROIMAGE, V34, P985, DOI 10.1016/j.neuroimage.2006.07.047; Teipel SJ, 2004, BRAIN, V127, P811, DOI 10.1093/brain/awh101; Teipel SJ, 2007, NEUROIMAGE, V38, P13, DOI 10.1016/j.neuroimage.2007.07.008; Teipel SJ, 2005, BRAIN, V128, P2626, DOI 10.1093/brain/awh589; Teipel SJ, 2006, J NEUROL, V253, P794, DOI 10.1007/s00415-006-0120-4; Teipel SJ, 2007, BRAIN, V130, P1745, DOI 10.1093/brain/awm117; Teipel SJ, 2006, BEHAV GENET, V36, P405, DOI 10.1007/s10519-006-9047-x; Wang L, 2007, IEEE T MED IMAGING, V26, P462, DOI 10.1109/TMI.2006.887380; Wang PN, 2006, NEUROBIOL AGING, V27, P1797, DOI 10.1016/j.neurobiolaging.2005.10.002; Xu Y, 2000, NEUROLOGY, V54, P1760; Yoshiura T, 2002, NEUROREPORT, V13, P2299, DOI 10.1097/01.wnr.0000044991.13025.e6; Zhang Y, 2007, NEUROLOGY, V68, P13, DOI 10.1212/01.wnl.0000250326.77323.01	73	28	29	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1619-7070		EUR J NUCL MED MOL I	Eur. J. Nucl. Med. Mol. Imaging	MAR	2008	35			1			S58	S69		10.1007/s00259-007-0703-z		12	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	V28OR	WOS:000208690600008	
J	Vadera, S; Rodriguez, A; Succar, E; Wu, J				Vadera, Sunil; Rodriguez, Andres; Succar, Enrique; Wu, Jia			Using Wittgenstein's Family Resemblance Principle to Learn Exemplars	FOUNDATIONS OF SCIENCE			English	Article; Proceedings Paper	International Conference Model-Based Reasoning in Science and Engineering - Abduction, Visualization, Simulation (MBR04)	DEC, 2004	Pavia, ITALY		Univ Pavis	Machine learning; Family resemblance; Bayesian networks		The introduction of the notion of family resemblance represented a major shift in Wittgenstein's thoughts on the meaning of words, moving away from a belief that words were well defined, to a view that words denoted less well defined categories of meaning. This paper presents the use of the notion of family resemblance in the area of machine learning as an example of the benefits that can accrue from adopting the kind of paradigm shift taken by Wittgenstein. The paper presents a model capable of learning exemplars using the principle of family resemblance and adopting Bayesian networks for a representation of exemplars. An empirical evaluation is presented on three data sets and shows promising results that suggest that previous assumptions about the way we categories need reopening.	[Vadera, Sunil; Wu, Jia] Univ Salford, Sch Engn & Comp Sci, Salford M5 4WT, Lancs, England; [Rodriguez, Andres] Inst Invest Elect, Cuernavaca, Morelos, Mexico; [Succar, Enrique] Inst Nacl Astrofis Opt & Electr, Puebla, Mexico	Vadera, S (reprint author), Univ Salford, Sch Engn & Comp Sci, Salford M5 4WT, Lancs, England.	S.Vadera@salford.ac.uk					ADDIS JT, 2008, FDN SCIECNE; ADDIS T, 2004, P GRAND CHALL COMP N, P1; AHN WK, 1992, COGNITIVE SCI, V16, P81, DOI 10.1207/s15516709cog1601_3; Anderson J. R., 1990, ADAPTIVE CHARACTER T; Bareiss R, 1989, EXEMPLAR BASED KNOWL; Blake C. L., 1998, UCI REPOSITORY MACHI; Pearl J., 1991, PROBABILISTIC REASON; RODRIGUEZ A, 1999, P INT JOINT C AI SAN, P242; ROSCH E, 1975, COGNITIVE PSYCHOL, V7, P573, DOI 10.1016/0010-0285(75)90024-9; Wittgenstein L, 1953, PHILOS INVESTIGATION; WITTGENSTEIN L, 1921, TRACTUS LOGICOPHILOS	11	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1233-1821		FOUND SCI	Found. Sci.	MAR	2008	13	1					67	74		10.1007/s10699-007-9119-2		8	History & Philosophy Of Science	History & Philosophy of Science	417QI	WOS:000264090800006	
J	Wu, JX; Brubaker, SC; Mullin, MD; Rehg, JM				Wu, Jianxin; Brubaker, S. Charles; Mullin, Matthew D.; Rehg, James M.			Fast asymmetric learning for cascade face detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						face detection; cascade classifier; asymmetry; feature selection	SUPPORT VECTOR MACHINES; OBJECT DETECTION; FEATURE-SELECTION; CLASSIFIERS; RECOGNITION; HIERARCHY; REJECTION; IMAGES	A cascade face detector uses a sequence of node classifiers to distinguish faces from nonfaces. This paper presents a new approach to design node classifiers in the cascade detector. Previous methods used machine learning algorithms that simultaneously select features and form ensemble classifiers. We argue that if these two parts are decoupled, we have the freedom to design a classifier that explicitly addresses the difficulties caused by the asymmetric learning goal. There are three contributions in this paper: The first is a categorization of asymmetries in the learning goal and why they make face detection hard. The second is the Forward Feature Selection (FFS) algorithm and a fast precomputing strategy for AdaBoost. FFS and the fast AdaBoost can reduce the training time by approximately 100 and 50 times, in comparison to a naive implementation of the AdaBoost feature selection method. The last contribution is a Linear Asymmetric Classifier ( LAC), a classifier that explicitly handles the asymmetric learning goal as a well-defined constrained optimization problem. We demonstrated experimentally that LAC results in an improved ensemble classifier performance.	[Wu, Jianxin; Brubaker, S. Charles; Mullin, Matthew D.; Rehg, James M.] Georgia Inst Technol, Coll Comp, Sch Interact Comp, Atlanta, GA 30332 USA	Wu, JX (reprint author), Georgia Inst Technol, Coll Comp, Sch Interact Comp, 85 5th St NW, Atlanta, GA 30332 USA.	wujx@cc.gatech.edu; brubaker@cc.gatech.edu; mdmullin@cc.gatech.edu; rehg@cc.gatech.edu	Wu, Jianxin/A-3700-2011; Wu, Jianxin/B-8539-2012				Amit Y, 1999, NEURAL COMPUT, V11, P1691, DOI 10.1162/089976699300016197; Anthony M, 2004, J MACH LEARN RES, V5, P189; Avidan S., 2005, ADV NEURAL INFORM PR, V17, P57; Baker S, 1996, PROC CVPR IEEE, P544, DOI 10.1109/CVPR.1996.517125; Blanchard G, 2005, ANN STAT, V33, P1155, DOI 10.1214/009053605000000174; BRUBAKER S, 2005, GITGVU0528 GVC CTR G; Carmichael O, 2003, PROC CVPR IEEE, P401; Chen XR, 2004, PROC CVPR IEEE, P366; Elad M, 2002, PATTERN RECOGN LETT, V23, P1459, DOI 10.1016/S0167-8655(02)00106-X; Fan Wei, 1999, P 16 INT C MACH LEAR, P97; Fleuret F, 2004, J MACH LEARN RES, V5, P1531; Fleuret F, 2001, INT J COMPUT VISION, V41, P85, DOI 10.1023/A:1011113216584; Heisele B, 2001, PROC CVPR IEEE, P18; Huang KZ, 2004, J MACH LEARN RES, V5, P1253; JONES MJ, 2003, TR200396 MITS ELECT; Karakoulas G, 1999, ADV NEUR IN, V11, P253; Keren D, 2001, IEEE T PATTERN ANAL, V23, P747, DOI 10.1109/34.935848; Kim S., 2006, P 23 INT C MACH LEAR, P473, DOI 10.1145/1143844.1143904; Lanckriet G. R. G., 2002, J MACHINE LEARNING R, V3, P555; Levi K, 2004, PROC CVPR IEEE, P53; LI S, 2003, ADV NEURAL INFORM PR, V15, P993; Lienhart R, 2003, LECT NOTES COMPUT SC, V2781, P297; Liu C., 2003, P IEEE C COMP VIS PA, V1, P587; Mason L, 2000, ADV NEUR IN, P221; OSADCHY R, 2005, ADV NEURAL INFORM PR, V17, P1017; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; Papageorgiou C P, 1998, P INT C COMP VIS, P555; Ren L, 2005, ACM T GRAPHIC, V24, P1303, DOI 10.1145/1095878.1095882; Rivest R. L., 1987, Machine Learning, V2, DOI 10.1007/BF00058680; Romdhani S., 2001, Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001, DOI 10.1109/ICCV.2001.937694; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Sahbi H, 2006, J MACH LEARN RES, V7, P2087; Schapire R. E., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.290996; Schapire RE, 1998, ANN STAT, V26, P1651; Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895; Sun J, 2004, PROC CVPR IEEE, P276; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; Ting K. M., 2000, P 17 INT C MACH LEAR, P983; Torralba A, 2004, PROC CVPR IEEE, P762; Viola P., 2003, Proceedings Ninth IEEE International Conference on Computer Vision; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Viola P, 2002, ADV NEUR IN, V14, P1311; Webb A., 1999, STAT PATTERN RECOGNI; Weiss G., 2004, ACM SIGKDD EXPLORATI, V6, P7, DOI 10.1145/1007730.1007734; Wu JX, 2004, ADV NEUR IN, V16, P1523; XIAO R, 2003, P ICCV, V1, P709; Yang MH, 2000, ADV NEUR IN, V12, P862; Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34	48	44	50	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2008	30	3					369	382		10.1109/TPAMI.2007.1181		14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	250FT	WOS:000252286100001	
J	Bloy, GJ				Bloy, Greg J.			Blind camera fingerprinting and image clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						clustering algorithms; forensics; image processing; pattern recognition; machine learning		Previous studies have shown how to "fingerprint" a digital camera given a set of images known to come from the camera. A clustering technique is proposed to construct such fingerprints from a mixed set of images, enabling identification of each image's source camera without any prior knowledge of source.	Aerosp Corp, Chantilly, VA 20151 USA	Bloy, GJ (reprint author), Aerosp Corp, 15049 Conf Ctr Dr,CH3-240, Chantilly, VA 20151 USA.	greg.j.bloy@aero.org					GERADTS ZJ, 2001, P SPIE EN TECHN LAW, V4232; Kundu S, 1999, PATTERN RECOGN, V32, P1149, DOI 10.1016/S0031-3203(98)00143-5; LUKAS J, 2005, P I C IM PROC; Lukas J., 2005, P SPIE ELECT IMAGING, P249; Lukas J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602	5	7	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2008	30	3					532	U1		10.1109/TPAMI.2007.1183		4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	250FT	WOS:000252286100013	
J	Makinen, E; Raisamo, R				Makinen, Erno; Raisamo, Roope			Evaluation of gender classification methods with automatically detected and aligned faces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						classifier design and evaluation; computer vision; face and gesture classification; face detection; interactive systems; machine learning; vision I/O	PERFORMANCE	We present a systematic study on gender classification with automatically detected and aligned faces. We experimented with 120 combinations of automatic face detection, face alignment, and gender classification. One of the findings was that the automatic face alignment methods did not increase the gender classification rates. However, manual alignment increased classification rates a little, which suggests that automatic alignment would be useful when the alignment methods are further improved. We also found that the gender classification methods performed almost equally well with different input image sizes. In any case, the best classification rate was achieved with a support vector machine. A neural network and Adaboost achieved almost as good classification rates as the support vector machine and could be used in applications where classification speed is considered more important than the maximum classification accuracy.	[Makinen, Erno; Raisamo, Roope] Univ Tampere, Dept Comp Sci, FIN-33014 Tampere, Finland	Makinen, E (reprint author), Univ Tampere, Dept Comp Sci, FIN-33014 Tampere, Finland.	etm@cs.uta.fi; rr@cs.uta.fi					Baluja S, 2007, INT J COMPUT VISION, V71, P111, DOI 10.1007/s11263-006-8910-9; Benadelkader C., 2005, P 2005 IEEE CS C COM, P52; CASTRILLONSANTA.M, 2006, P 2 WORKSH MULT AUTH; CASTRILLONSANTA.M, 2003, P C ASS ESP INT ART; CASTRILLONSANTA.MF, 2003, THESIS U PALMAS GRAN; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; COOTES E, 2001, P AS PAC C COMP HUM; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Jesorsky O., 2001, P 3 INT C AUD VID BA, P90; LIAN HC, 2006, P 3 I S NEUR NET, V2, P202; Makinen E., 2002, P AS PAC C COMP HUM, P528; Moghaddam B., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), DOI 10.1109/AFGR.2000.840651; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Rodriguez Y, 2006, IMAGE VISION COMPUT, V24, P882, DOI 10.1016/j.imavis.2006.02.012; Shakhnarovich G., 2002, P IEEE INT C AUT FAC, P14; Stegmann MB, 2003, IEEE T MED IMAGING, V22, P1319, DOI 10.1109/TMI.2003.817780; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Viola P., 2001, P IEEE C COMP VIS PA, V1, P511; Wang T., 2003, P 3 I S MULT IM PROC, P558; Wu B, 2003, P SOC PHOTO-OPT INS, V5286, P498, DOI 10.1117/12.539077; XIAO X, 2002, THESIS TSINGHUA U; YANG Z, 2006, P 18 IEEE I C PATT R, V3, P1099; *OPENCV, OP SOURC COMP VIS LI	26	40	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2008	30	3					541	547		10.1109/TPAMI.2007.70800		7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	250FT	WOS:000252286100015	
J	Kim, S; Whitehead, EJ; Zhang, Y				Kim, Sunghun; Whitehead, E. James, Jr.; Zhang, Yi			Classifying software changes: Clean or buggy?	IEEE TRANSACTIONS ON SOFTWARE ENGINEERING			English	Article						maintenance; software metrics; software fault diagnosis; configuration management; classification; association rules; data mining; machine learning	HISTORY; SYSTEM; FAULTS	This paper introduces a new technique for predicting latent software bugs, called change classification. Change classification uses a machine learning classifier to determine whether a new software change is more similar to prior buggy changes or clean changes. In this manner, change classification predicts the existence of bugs in software changes. The classifier is trained using features ( in the machine learning sense) extracted from the revision history of a software project stored in its software configuration management repository. The trained classifier can classify changes as buggy or clean, with a 78 percent accuracy and a 60 percent buggy change recall on average. Change classification has several desirable qualities: 1) The prediction granularity is small ( a change to a single file), 2) predictions do not require semantic information about the source code, 3) the technique works for a broad array of project types and programming languages, and 4) predictions can be made immediately upon the completion of a change. Contributions of this paper include a description of the change classification approach, techniques for extracting features from the source code and change histories, a characterization of the performance of change classification across 12 open source projects, and an evaluation of the predictive power of different groups of features.	[Kim, Sunghun] MIT, Cambridge, MA 02139 USA; [Whitehead, E. James, Jr.; Zhang, Yi] Univ Calif Santa Cruz, Santa Cruz, CA 95064 USA	Kim, S (reprint author), MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	hunkim@csail.mit.edu; ejw@cs.ucsc.edu; yiz@soe.ucsc.edu					Alpaydin E, 2004, INTRO MACHINE LEARNI; ANTONIOL G, 2000, P 7 WORK C REV ENG, P247; Anvik J., 2006, P 28 INT C SOFTW ENG, P361, DOI DOI 10.1145/1134285.1134336; Brun Y, 2004, PROC INT CONF SOFTW, P480, DOI 10.1109/ICSE.2004.1317470; Cubranic D, 2003, PROC INT CONF SOFTW, P408, DOI 10.1109/ICSE.2003.1201219; Di Lucca GA, 2002, PROC IEEE INT CONF S, P93, DOI 10.1109/ICSM.2002.1167756; EESSAN AE, 2005, P 21 INT C SOFTW MAI, P263; FISCHER M, 2003, P 19 INT C SOFTW MAI, P19; Flanagan C, 2002, P ACM SIGPLAN 2002 C, P234; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; Graves TL, 2000, IEEE T SOFTWARE ENG, V26, P653, DOI 10.1109/32.859533; Gyimothy T, 2005, IEEE T SOFTWARE ENG, V31, P897, DOI 10.1109/TSE.2005.112; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Khoshgoftaar T. M., 1998, Proceedings Ninth International Symposium on Software Reliability Engineering (Cat. No.98TB100257), DOI 10.1109/ISSRE.1998.730899; Khoshgoftaar TM, 2003, SOFTWARE QUAL J, V11, P19, DOI 10.1023/A:1023632027907; Kim MH, 2006, J INTEL MAT SYST STR, V17, P35, DOI 10.1177/1045389X06056064; Kim S, 2007, PROC INT CONF SOFTW, P489; Kim S., 2005, P 2005 EUR SOFTW ENG, P177, DOI DOI 10.1145/1081706.1081736; KROVETZ R, 2003, P 26 ANN INT ACM SIG, P425; KUHN A, 2005, P 12 WORK C REV ENG, P133, DOI DOI 10.1109/WCRE.2005.16; KUMAR R, 1998, P A REL MAI, P155; Landauer TK, 1998, DISCOURSE PROCESS, V25, P259; LEWIS DD, 2004, J MACH LEARN RES, V5, P397; Li Z., 2005, P ESEC FSE, P306, DOI 10.1145/1081706.1081755; Livshits B., 2005, P INT S FDN SOFTW EN, P296, DOI 10.1145/1081706.1081754; Lyle J. R., 1987, P 2 INT C COMP APPL, P877; MADHAVAN J, 2007, P ECL TECHN EXCH WOR; Maletic Jonathan I., 1999, P 14 IEEE INT C AUT, P251; Marchal D, 2003, J STRUCT GEOL, V25, P135, DOI 10.1016/S0191-8141(02)00011-1; Matwin S., 1999, P 16 INT C MACH LEAR, P379; Menzies T, 2007, IEEE T SOFTWARE ENG, V33, P2, DOI 10.1109/TSE.2007.256941; Mizuno O, 2007, P 6 JOINT M EUR SOFT, P405, DOI 10.1145/1287624.1287683; Mockus A, 2000, PROC IEEE INT CONF S, P120, DOI 10.1109/ICSM.2000.883028; Mockus A, 2000, BELL LABS TECH J, V5, P169, DOI 10.1002/bltj.2229; Montgomery D.C., 2001, ENG STAT; MOORE AW, 2005, CROSS VALIDATION; Nagappan N, 2005, PROC INT CONF SOFTW, P284, DOI 10.1145/1062455.1062514; NEWMAN DJ, 1988, UCI REPOSITORY MACHI; Ostrand T. J., 2004, P 2004 ACM SIGSOFT I, P86, DOI 10.1145/1007512.1007524; Ostrand TJ, 2005, IEEE T SOFTWARE ENG, V31, P340, DOI 10.1109/TSE.2005.49; Ostrand T.J., 2002, P ACM INT S SOFTW TE, P55; PAN K, 2006, P 6 IEEE INT WORKSH; PENTA MD, 2002, P 10 IEEE INT WORKSH, P207; RASKUTTI B, 2001, P 12 EUR C MACH LEAR, P419; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Sliwerski J., 2005, P INT WORKSH MIN SOF, P24; SPOHRER JC, 1985, P ACM C HUM FACT COM, P47, DOI 10.1145/317456.317465; Vapnik V. N, 1995, NATURE STAT LEARNING; Williams CC, 2005, IEEE T SOFTWARE ENG, V31, P466, DOI 10.1109/TSE.2005.63; Witten I. H., 2005, DATA MINING PRACTICA; Zhang L., 2004, ACM T ASIAN LANGUAGE, V3, P243, DOI 10.1145/1039621.1039625; Zheng Z., 2004, ACM SIGKDD EXPLORATI, V6, P80, DOI DOI 10.1145/1007730.1007741; Zimmermann T., 2004, P 1 INT WORKSH MIN S, P2; Zimmermann T, 2005, IEEE T SOFTWARE ENG, V31, P429, DOI 10.1109/TSE.2005.72; *SCH TOOLWORKS, 2005, MAIN UND METR DOC TO	55	36	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0098-5589		IEEE T SOFTWARE ENG	IEEE Trans. Softw. Eng.	MAR-APR	2008	34	2					181	196		10.1109/TSE.2007.70773		16	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	276SC	WOS:000254161500002	
J	Qin, T; Zhang, XD; Tsai, MF; Wang, DS; Liu, TY; Li, H				Qin, Tao; Zhang, Xu-Dong; Tsai, Ming-Feng; Wang, De-Sheng; Liu, Tie-Yan; Li, Hang			Query-level loss functions for information retrieval	INFORMATION PROCESSING & MANAGEMENT			English	Article						information retrieval; learning to rank; query-level loss function; RankCosine		Many machine learning technologies such as support vector machines, boosting, and neural networks have been applied to the ranking problem in information retrieval. However, since originally the methods were not developed for this task, their loss functions do not directly link to the criteria used in the evaluation of ranking. Specifically, the loss functions are defined on the level of documents or document pairs, in contrast to the fact that the evaluation criteria are defined on the level of queries. Therefore, minimizing the loss functions does not necessarily imply enhancing ranking performances. To solve this problem.. we propose using query-level loss functions in learning of ranking functions. We discuss the basic properties that a query-level loss function should have and propose a query-level loss function based on the cosine similarity between a ranking list and the corresponding ground truth. We further design a coordinate descent algorithm, referred to as RankCosine, which utilizes the proposed loss function to create a generalized additive ranking model. We also discuss whether the loss functions of existing ranking algorithms can be extended to query-level. Experimental results on the datasets of TREC web track, OHSUMED, and a commercial web search engine show that with the use of the proposed query-level loss function we can significantly improve ranking accuracies. Furthermore, we found that it is difficult to extend the document-level loss functions to query-level loss functions. (c) 2007 Elsevier Ltd. All rights reserved.	[Qin, Tao; Zhang, Xu-Dong; Wang, De-Sheng] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China; [Liu, Tie-Yan; Li, Hang] Microsoft Res Asia, Beijing 100080, Peoples R China; [Tsai, Ming-Feng] Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan	Qin, T (reprint author), Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.	tsintao@gmail.com; zhangxd@tsinghua.edu.cn; mftsai@nlg.csie.ntu.edu.tw; wangdsh_ee@tsinghua.edu.cn; tyliu@microsoft.com; hangli@microsoft.com					BAEZYATES R, 1999, MODERN INFORM RETRIE; Borlund P, 2003, J AM SOC INF SCI TEC, V54, P913, DOI 10.1002/asi.10286; Burges C., 2005, 22 INT C MACH LEARN; CAO Y, 2006, SIGIR 2006 P 29 ANN; CAO Z, 2007, P 1M ANN INT C MACH; CARMMER K, 2002, 14 NIPS; CARSWELL N, 2003, NIST SPECIAL PUBLICA, P78; DEKEL O, 2004, LOGLINEAR MODELS LAB; FREIDMAN J, 1998, ADDITIVE LOGISTIC RE; Freund Y., 2003, J MACHINE LEARNING R; Herbrich R, 2000, ADV NEUR IN, P115; Hersh W.R., 1994, P 17 ANN INT ACM SIG, P192; Jarvelin K., 2002, ACM T INFORM SYSTEMS; JARVELIN K, 2000, P 23 ACM SIGIR; Joachims T., 1999, ADV KERNEL METHODS S; JOACHIMS T, 2002, P ACM C KNOWLEDGE DI; Matveeva I., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/1148170.1148246; Nallapati R., 2004, SIGIR, P64; PAGE L, 1998, PAGERANK CITIATION R; QIN T, 2005, SIGIR 05, P408; QIN T, 2007, P SIGIR 2007 P 30 AN; Robertson S., 2000, P 9 TEXT RETR C, P25; Robertson SE, 1997, J DOC, V53, P3, DOI 10.1108/EUM0000000007186; SONG R, 2004, 13 TREC; SORMUNEN E, 2002, P 25 ANN INT ACM SIG; TSAI MF, 2007, P SIGIR 2007 P 30 AN; Vapnik VN, 1998, STAT LEARNING THEORY; Voorhees E.M., 2005, TREC EXPT EVALUATION; Xue G.-R., 2005, P 28 ANN INT ACM SIG	29	18	19	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0306-4573		INFORM PROCESS MANAG	Inf. Process. Manage.	MAR	2008	44	2					838	855		10.1016/j.ipm.2007.07.016		18	Computer Science, Information Systems; Information Science & Library Science	Computer Science; Information Science & Library Science	285YX	WOS:000254813200024	
J	Boylu, F; Aytug, H; Koehler, GJ				Boylu, Fidan; Aytug, Haldun; Koehler, Gary J.			Systems for strategic learning	INFORMATION SYSTEMS AND E-BUSINESS MANAGEMENT			English	Article						Discriminant analysis; Principal-agent; Strategic gaming; Data mining; Machine learning		An important decision support system component is machine learning/data mining. Classical machine learning methods implicitly assume that attributes of instances under classification do not change to acquire a positive classification. However, in many situations these instances represent people or organizations that can proactively seek to alter their characteristics to gain a positive classification. We argue that the learning mechanism should take this possible strategic learning into consideration during the induction process. We call this strategic learning. In this paper we define this concept, summarize related research, and present a number of future research areas.	[Boylu, Fidan] Univ Connecticut, Sch Business, Storrs, CT 06269 USA; [Aytug, Haldun; Koehler, Gary J.] Univ Florida, Warrington Coll Business Adm, Informat Syst & Operat Management Dept, Gainesville, FL USA	Boylu, F (reprint author), Univ Connecticut, Sch Business, Storrs, CT 06269 USA.	fidan.boylu@business.uconn.edu; aytugh@ufl.edu; gary.koehler@cba.ufl.edu					ABDELKHALIK AR, 1980, J ACCOUNTING RES, V18, P325, DOI 10.2307/2490581; Agrawal R., 1993, SIGMOD, P207; ARNT A, 2005, P 1 INT WORKSH UT BA, P39, DOI 10.1145/1089827.1089832; AYTUG H, 2006, P 39 ANN HAW INT C S, V7, pB158, DOI 10.1109/HICSS.2006.250; BHATTACHARYYA S, 2005, REINFORCEMENT LEARNI; Bishop C.M., 1995, NEURAL NETWORKS PATT; BOYLU F, 2005, DECISION INFORM SCI; BOYLU F, 2006, DECISION INFORM SCI; Ciraco M., 2005, P KDD 05 WORKSH UT B, P46, DOI 10.1145/1089827.1089833; Cristianini N., 2000, INTRO SUPPORT VECTOR; Crone S., 2005, P 1 INT WORKSH UT BA, P59, DOI 10.1145/1089827.1089835; DALVI N, 2004, 10 ACM SIGKDD INT C, P99; EHTAMO H, 2002, OPTIMAL CONTROL DIFF, P121; Elkan C., 2001, IJCAI, P973; Fan M, 2003, INFORM SYST RES, V14, P1, DOI 10.1287/isre.14.1.1.14763; Fisher RA, 1936, ANN EUGENIC, V7, P179; HOLTE RC, 2005, P 1 INT WORKSH UT BA, P3, DOI 10.1145/1089827.1089843; KAELBLING LP, 1996, J ARTIF INTELL RES, V4, P1039; Kapoor A., 2005, P KDD 05 WORKSH UT B, P17, DOI 10.1145/1089827.1089829; Keyhani A, 2003, IEEE T POWER SYST, V18, P837, DOI 10.1109/TPWRS.2003.810985; Laffont J.-J., 2002, THEORY INCENTIVES PR; Littman M. L., 1994, P 11 INT C MACH LEAR, P157; McCarthy K, 2005, P 1 INT WORKSH UT BA, P69, DOI 10.1145/1089827.1089836; MELVILLE P, 2005, P 1 INT WORKSH UT BA, P10, DOI 10.1145/1089827.1089828; MORRISON CT, 2005, P 1 INT WORKSH UT BA, P34, DOI 10.1145/1089827.1089831; PROVOST FJ, 2005, P ACM SIGKDD WORKSH, P1, DOI 10.1145/1089827.1089841; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; Samuel A.L., 1959, IBM Journal of Research and Development, V3; Sutton R.S., 1998, REINFORCEMENT LEARNI; Vapnik VN, 1998, STAT LEARNING THEORY; Weiss GM, 2003, J ARTIF INTELL RES, V19, P315; Zadrozny B., 2005, P 1 INT WORKSH UT BA, P53, DOI 10.1145/1089827.1089834	32	1	1	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	1617-9846		INF SYST E-BUS MANAG	Inf. Syst. E-Bus. Manag.	MAR	2008	6	2			SI		205	220		10.1007/s10257-007-0065-x		16	Business; Management	Business & Economics	V15IG	WOS:000207795100006	
J	Adamopoulou, E; Demestichas, K; Demestichas, P; Theologou, M				Adamopoulou, Evgenia; Demestichas, Konstantinos; Demestichas, Panagiotis; Theologou, Michael			Enhancing cognitive radio systems with robust reasoning	INTERNATIONAL JOURNAL OF COMMUNICATION SYSTEMS			English	Article						Bayesian networks; cognitive radio; interference sensing; machine learning; reasoning	POWER SUMS; MANAGEMENT; INTERFERENCE; NETWORKS	Cognitive radio systems dynamically reconfigure the algorithms and parameters they use, in order to adapt to the changing environment conditions. However, reaching proper reconfiguration decisions presupposes a way of knowing, with high enough assurance, the capabilities of the alternate configurations, especially in terms of achievable transmission capacity and coverage. The present paper addresses this problem, firstly, by specifying a complete process for extracting estimations of the capabilities of candidate configurations, in terms of transmission capacity and coverage, and, secondly, by enhancing these estimations with the employment of a machine learning technique. The technique is based on the use of Bayesian Networks, in conjunction with an effective learning and adaptation strategy, and aims at extracting and exploiting knowledge and experience, in order to reach robust (i.e. stable and reliable) estimations of the configurations' capabilities. Comprehensive results of the proposed method are presented, in order to validate its functionality. Copyright (C) 2007 John Wiley & Sons, Ltd.	[Adamopoulou, Evgenia; Demestichas, Konstantinos; Theologou, Michael] Natl Tech Univ Athens, Sch Elect & Comp Engn, GR-15773 Athens, Greece; [Demestichas, Panagiotis] Univ Piraeus, Dept Technol Educ & Digital Syst, Piraeus, Greece	Demestichas, K (reprint author), Natl Tech Univ Athens, Sch Elect & Comp Engn, 9 Iroon Polytechniou St, GR-15773 Athens, Greece.	cdemest@cn.ntua.gr					ADAMOPOULOU E, 2005, P 15 WIR WORLD RES F; CHENG J, 2001, P 14 BIENN C CAN SOC, P141; Demestichas P, 2006, IEEE COMMUN MAG, V44, P118, DOI 10.1109/MCOM.2006.1668430; Demestichas P, 2004, IEEE COMMUN MAG, V42, P90, DOI 10.1109/MCOM.2004.1299348; Frodigh M, 2001, IEEE PERS COMMUN, V8, P10, DOI 10.1109/98.960335; Graziosi F, 1999, IEEE T VEH TECHNOL, V48, P802, DOI 10.1109/25.764997; Haykin S, 2005, IEEE J SEL AREA COMM, V23, P201, DOI 10.1109/JSAC.2004.839380; Kim Y, 2003, IEEE COMMUN MAG, V41, P120; KOLODZY PJ, 2006, MANAGEMENT INTERFERE, V16, P103; Koutsorodi A., 2007, WIRELESS PERSONAL CO; Leung KK, 2002, IEEE T WIREL COMMUN, V1, P256, DOI 10.1109/7693.994819; MARLOW NA, 1967, AT&T TECH J, V46, P2081; MCHENRY M, 2003, FCC WORKSH COGN RAD; McHenry M. A., 2005, NSF SPECTRUM OCCUPAN; Mitola J., 2000, THESIS ROYAL I TECHN; Mitola J, 1999, IEEE PERS COMMUN, V6, P13, DOI 10.1109/98.788210; NEAPOLITAN RE, 2002, LEARNING BAYESIAN NE; NEEL JO, 2006, THESIS FACULTY VIRGI; PRATESI M, 1997, P IEEE VTC 97 PHOEN, P530; Raman L, 1998, IEEE COMMUN MAG, V36, P46, DOI 10.1109/35.663327; Santucci F, 2000, IEEE T COMMUN, V48, P231, DOI 10.1109/26.823556; SCHWARTZ SC, 1982, AT&T TECH J, V61, P1441; Staple G, 2004, IEEE SPECTRUM, V41, P48, DOI 10.1109/MSPEC.2004.1270548	23	1	1	JOHN WILEY & SONS LTD	CHICHESTER	THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND	1074-5351		INT J COMMUN SYST	Int. J. Commun. Syst.	MAR	2008	21	3					311	330		10.1002/dac.898		20	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	280EW	WOS:000254409100005	
J	Bauer, A; Wollherr, D; Buss, M				Bauer, Andrea; Wollherr, Dirk; Buss, Martin			Human-robot collaboration: A survey	INTERNATIONAL JOURNAL OF HUMANOID ROBOTICS			English	Article						human-robot collaboration; intention estimation; action planning; machine learning	MOBILE ROBOT; SYSTEM	As robots are gradually leaving highly structured factory environments and moving into human populated environments, they need to possess more complex cognitive abilities. They do not only have to operate efficiently and safely in natural, populated environments, but also be able to achieve higher levels of cooperation and communication with humans. Human-robot collaboration (HRC) is a research field with a wide range of applications, future scenarios, and potentially a high economic impact. HRC is an interdisciplinary research area comprising classical robotics, cognitive sciences, and psychology. This paper gives a survey of the state of the art of HRC. Established methods for intention estimation, action planning, joint action, and machine learning are presented together with existing guidelines to hardware design. This paper is meant to provide the reader with a good overview of technologies and methods for HRC.	[Bauer, Andrea; Wollherr, Dirk; Buss, Martin] Tech Univ Munich, Inst Automat Control Engn LSR, D-80290 Munich, Germany	Bauer, A (reprint author), Tech Univ Munich, Inst Automat Control Engn LSR, D-80290 Munich, Germany.	ab@tum.de; dw@tum.de; mb@tum.de					ALAMI R, 2005, JOINT C SMART OB AMB, P81; ASIMOV I, 1968, ROBOT; Baldwin DA, 2001, TRENDS COGN SCI, V5, P171, DOI 10.1016/S1364-6613(00)01615-6; BEETZ M, 2007, COE WORKSH HUM AD ME; Bluethmann W, 2003, AUTON ROBOT, V14, P179, DOI 10.1023/A:1022231703061; BOBICK A, 1997, ROY SOC WORKSH KNOWL, P1257; Breazeal C., 2004, INT J HUM ROBOT, V1, P315, DOI 10.1142/S0219843604000150; Breazeal C., 1999, IROS99, P858; Burgard W, 1999, ARTIF INTELL, V114, P3, DOI 10.1016/S0004-3702(99)00070-3; COHEN PR, 1991, 504 STANF U; DAVIS KH, 1952, J ACOUST SOC AM, V24, P637, DOI 10.1121/1.1906946; DEMIRIS J, 1996, 5 EUR WORKSH LEARN R, P9; DEWEERDT M, 2005, EUR AGENT SUMMER SCH, P1; DISALVO CF, 2002, S DES INT SYST, P321; ESTEVES C, 2005, IEEE INT C MECH AUT, P1766; FELDMAN JA, 1974, ARTIF INTELL, V5, P349, DOI 10.1016/0004-3702(74)90002-2; FOSTER ME, 2006, RSS 2006 WORKSH INT; FRY DB, 1959, J BRIT INSS RADIO EN, V19, P211; GENTRY S, 2003, IEEE INT C SYST MAN, V4, P3432; GROSZ B, 1996, AI MAG, V2, P67; HATTORI Y, 2006, INT WORKSH EP ROB MO, V123, P139; ISHIGURO H, 2005, 12 INT S ROB RES; Ito M, 2004, ADAPT BEHAV, V12, P93, DOI 10.1177/105971230401200202; IWATSUKA K, 2004, CAN C COMP ROB VIS, P401; JIA P, 2005, C CHIN AUT COMP SOC, P85; KADOUS MW, 2005, AUSTR C ROB AUT; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237; Kanade T, 2000, INT C AUT FAC GEST R, P46; Kaplan F., 2004, INT J HUM ROBOT, V1, P465, DOI 10.1142/S0219843604000289; Katzenbach J.R., 1994, WISDOM TEAMS CREATIN; Kiesler S, 2004, HUM-COMPUT INTERACT, V19, P1, DOI 10.1207/s15327051hci1901&2_1; KOBAYASHI K, 2005, IEEE RSJ INT C INT R, P2977; KORTENKAMP D, 1996, NAT C ART INT, V2, P915; KOSUGE K, 2000, ICRA 2000, P583; KOSUGE K, 1997, IEEE INT WORKSH ROB, P142; KOSUGE K, 2003, IEEE RSJ INT C INT R, V4, P3459; KRANZ M, 2006, SYST SUPP UB COMP WO; Kulic D., 2005, Journal of Robotic Systems, V22, DOI 10.1002/rob.20073; KULIC D, 2003, IEEE INT C ADV ROB, P810; Kulyukin V, 2006, AUTON ROBOT, V21, P29, DOI 10.1007/s10514-006-7223-8; Kunii Y., 1995, IEEE IECON 17 INT C, P179; Kuroki Y, 2003, IEEE INT CONF ROBOT, P471; Lawton JH, 2004, PROC INT C TOOLS ART, P408; LI B, 2005, IEEE SSRR, P31; LI Z, 2005, WORKSH MOD PEOPL HUM; Maeda Y, 2001, IEEE INT CONF ROBOT, P3477; MAES P, 1995, COMPUTER ANIMATION 9, P11; MATSUI T, 2001, B ELECTROTECH LAB, V64, P51; MCDERMOTT D, 1992, AI MAG, V13, P55; MINNEN D, 2003, COMPUTER VISION PATT, V2, P626; Minton S., 1994, J ARTIFICIAL INTELLI, V2, P227; Miura J, 2005, IEEE INT CONF ROBOT, P3378; MOLLER B, 2002, DAGM S PATT REC, P361; Montemerlo M., 2002, NAT C ART INT EDM AB, P587; Moore D.J., 1999, IEEE INT C COMP VIS, V1, P80; Mori M., 1970, ENERGY, V7, P33; MULLER A, 2006, WORKSH COGN ROB, P119; MURAKAMI K, 1991, SIGCHI C P, P237; MURPHY RR, 2004, IEEE INT WORKSH ROB, P301; MURPHY RR, 2004, SYST MAN CYBERNET, P138; NGUYEN X, 2001, IJCAI, P459; Nourbakhsh I., 2002, CMURITR0229; NUGUES P, 2006, INTRO LANGUAGE PROCE, P1; PACCHIEROTTI E, 2006, IEEE RSJ INT C INT R; Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226; Pieraccini R, 2005, LECT NOTES ARTIF INT, V3533, P6; Pineau J, 2003, ROBOT AUTON SYST, V42, P271, DOI 10.1016/S0921-8890(02)00381-0; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Rani P, 2004, ROBOTICA, V22, P85, DOI 10.1017/S0263574703005319; Rodriguez-Losada D, 2005, IEEE INT CONF ROBOT, P3390; Sakita K., 2004, IROS, P846; SCHANK RC, 1972, COGNITIVE PSYCHOL, V3, P552, DOI 10.1016/0010-0285(72)90022-9; SCHREMPF OC, 2005, IEEE INT WORKSH ROB, P555; Schroder Marc, 2001, P 7 EUR C SPEECH COM, V1, P561; SOSNOWSKI S, 2006, IEEE INT C ROB INT S, P3113; Sparrow R., 2002, Ethics and Information Technology, V4, DOI 10.1023/A:1021386708994; STARNER T, 1995, IEEE INT S COMP VIS; Thrun S, 1999, LECT NOTES ARTIF INT, V1701, P14; TRAVER V, 2000, INT C INT ROB SYST, V1, P696; Ulrich I, 2001, IEEE T SYST MAN CY A, V31, P131, DOI 10.1109/3468.911370; Wada K, 2006, IEEE INT CONF ROBOT, P3966; WANG Y, 2003, IEEE INT C INT ROB S, V1, P424; WERRY I, 2001, EUR C ADV ASS TECHN; Woods W.A., 1991, PRINCIPLES SEMANTIC, P45; YAMADA S, 2006, IEEE RSJ INT C INT R, P2614; Yanco HA, 2004, IEEE SYS MAN CYBERN, P2841; You BJ, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2630; You M., 2006, IEEE INT S IND EL, V1, P515	88	12	13	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0219-8436		INT J HUM ROBOT	Int. J. Humanoid Robot.	MAR	2008	5	1					47	66		10.1142/S0219843608001303		20	Robotics	Robotics	286RT	WOS:000254864400004	
J	Varshavskaya, P; Kaelbling, LP; Rus, D				Varshavskaya, Paulina; Kaelbling, Leslie Pack; Rus, Daniela			Automated design of adaptive controllers for modular robots using reinforcement learning	INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH			English	Article						learning and adaptive systems; cellular and modular robots; animation and simulation		Designing distributed controllers for self-reconfiguring modular robots has been consistently challenging. We have developed a reinforcement learning approach which can be used both to automate controller design and to adapt robot behavior on-line. In this paper, we report on our study of reinforcement learning in the domain of self-reconfigurable modular robots: the underlying assumptions, the applicable algorithms and the issues of partial observability, large search spaces and local optima. We propose and validate experimentally in simulation a number of techniques designed to address these and other scalability issues that arise in applying machine learning to distributed systems such as modular robots. We discuss ways to make learning faster, more robust and amenable to on-line application by giving scaffolding to the learning agents in the form of policy representation, structured experience and additional information. With enough structure modular robots can run learning algorithms to both automate the generation of distributed controllers, and adapt to the changing environment and deliver on the self-organization promise with less interference from human designers, programmers and operators.	[Varshavskaya, Paulina; Kaelbling, Leslie Pack; Rus, Daniela] MIT, Comp Sci & AI Lab, Cambridge, MA 02139 USA	Varshavskaya, P (reprint author), MIT, Comp Sci & AI Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	paulina@csail.mit.edu; lpk@csail.mit.edu; rus@csail.mit.edu					ANDRE D, 2000, ADV NEURAL INFORM PR; Bagnell J.A., 2004, ADV NEURAL INFORM PR, V16; Baxter J, 2001, J ARTIF INTELL RES, V15, P319; Bertsekas D., 1995, DYNAMIC PROGRAMMING; Butler Z, 2004, INT J ROBOT RES, V23, P919, DOI 10.1177/0278364904044409; BUTLER Z, 2001, P INT C INT ROB SYST; Chang Y. H., 2004, ADV NEURAL INFORM PR, V16; Fernandez F., 2001, International Journal of Robotics & Automation, V16; FITCH R, 2006, DIG P RSS WORKSH SEL; GRUDIC G, 2003, P INT C INT ROB SYST; Guestrin C., 2002, ADV NEURAL INFORM PR, V14; KAMIMURA A, 2004, P INT C INT ROB SYST; Kitano H., 1997, Proceedings of the First International Conference on Autonomous Agents, DOI 10.1145/267658.267738; Kok JR, 2006, J MACH LEARN RES, V7, P1789; KOTAY K, 2005, P INT C ROB AUT BARC; KUBICA J, 2002, GECCO 2002 P GEN EV, P804; Lagoudakis M.G., 2003, J MACHINE LEARNING R, V4, P1107, DOI 10.1162/jmlr.2003.4.6.1107; MARTIN M, 2004, 582 MIT MED LAB; Mataric MJ, 1997, AUTON ROBOT, V4, P73, DOI 10.1023/A:1008819414322; MYTILINAIOS E, 2004, P 9 INT C ART LIF AL; Nagpal R., 2002, P 1 INT JOINT C AUT; NG AY, 2004, P INT S EXP ROB ISER; NG AY, 2000, P INT C UNC AI UAI S; Peshkin L., 2001, THESIS BROWN U; SCHAAL S, 2003, P INT S ROB RES ISRR; SCHNEIDER J, 1999, P INT C MACH LEARN B; Shoham Y., 2003, MULTIAGENT REINFORCE; Stone P, 2000, AUTON ROBOT, V8, P345, DOI 10.1023/A:1008942012299; Sutton R., 2000, ADV NEURAL INFORM PR, V12; Sutton R.S., 1998, REINFORCEMENT LEARNI; SUTTON RS, 1995, ADV NEURAL INFORM PR, P1038; Tedrake R., 2005, P 14 YAL WORKSH AD L; VARSHAVSKAYA P, 2006, DIG P RSS WORKSH SEL; VARSHAVSKAYA P, 2004, P INT C INT ROB SYST; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698; YU W, 2002, P INT WORKSH DISTR A, V5, P455; Zykov V, 2005, NATURE, V435, P163, DOI 10.1038/435163a	37	11	12	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	0278-3649		INT J ROBOT RES	Int. J. Robot. Res.	MAR	2008	27	3-4					505	526		10.1177/0278364907084983		22	Robotics	Robotics	302QU	WOS:000255985200014	
J	Bowd, C; Hao, JC; Tavares, IM; Medeiros, FA; Zangwill, LM; Lee, TW; Sample, PA; Weinreb, RN; Goldbaum, MH				Bowd, Christopher; Hao, Jiucang; Tavares, Ivan M.; Medeiros, Felipe A.; Zangwill, Linda M.; Lee, Te-Won; Sample, Pamela A.; Weinreb, Robert N.; Goldbaum, Michael H.			Bayesian machine learning classifiers for combining structural and functional measurements to classify healthy and glaucomatous eyes	INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE			English	Article							OPTICAL COHERENCE TOMOGRAPHY; HEIDELBERG RETINA TOMOGRAPH; RELEVANCE VECTOR MACHINE; NEURAL-NETWORKS; DIAGNOSIS; ALGORITHMS; PERIMETRY; DISC	PURPOSE. To determine whether combining structural (optical coherence tomography, OCT) and functional (standard automated perimetry, SAP) measurements as input for machine learning classifiers (MLCs; relevance vector machine, RVM; and subspace mixture of Gaussians, SSMoG) improves diagnostic accuracy for detecting glaucomatous eyes compared with using each measurement method alone. METHODS. Sixty-nine eyes of 69 healthy control subjects (average age, 62.0, SD 9.7 years; visual field mean deviation [MD], -0.70, SD 1.41 dB) and 156 eyes of 156 patients with glaucoma (average age, 66.4, SD 10.2 years; visual field MD, -3.12, SD 3.43 dB) were imaged with OCT (Stratus OCT, Carl Zeiss Meditec, Inc., Dublin, CA) and tested with SAP (Humphrey Field Analyzer II with Swedish Interactive Thresholding Algorithm, SITA; Carl Zeiss Meditec, Inc.) within 3 months of each other. RVM and SSMoG MLCs were trained and tested on OCT-determined RNFL thickness measurements from 32 sectors (similar to 11.25 degrees each) obtained in the circumpapillary area under the instrument-defined measurement ellipse and SAP pattern deviation values from 52 points from the 24-2 grid, independently and in combination. Tenfold cross-validation was used to train and test classifiers on unique subsets of the full 225-eye data set, and areas under the receiver operating characteristic curve (AUROC) for the classification of eyes in the test set were generated. AUROC results from classifiers trained on OCT and SAP alone and those trained on OCT and SAP in combination were compared. In addition, these results were compared to currently available OCT measurements (mean retinal nerve fiber layer [RNFL] thickness, inferior RNFL thickness, and superior RNFL thickness) and SAP indices (MD and pattern standard deviation [PSD]). RESULTS. The AUROCs for RVM trained on OCT parameters alone, SAP parameters alone and OCT and SAP parameters combined were 0.809, 0.815, and 0.845, respectively. The AUROCs for SSMoG trained on OCT parameters alone, SAP parameters alone, and OCT and SAP parameters combined were 0.817, 0.841, and 0.869, respectively. Combining techniques using both RVM and SSMoG significantly improved on MLC analysis of OCT, but not SAP, measurements alone. Classification performance using RVM and SSMoG was statistically similar. CONCLUSIONS. RVM and SSMoG Bayesian MLCs trained on OCT and SAP data can successfully discriminate between healthy and early glaucomatous eyes. Combining OCT and SAP measurements using RVM and SSMoG increased diagnostic performance marginally compared with MLC analysis of data obtained using each technology alone.	[Bowd, Christopher; Tavares, Ivan M.; Medeiros, Felipe A.; Zangwill, Linda M.; Sample, Pamela A.; Weinreb, Robert N.; Goldbaum, Michael H.] Univ Calif San Diego, Hamilton Glaucoma Ctr 178, La Jolla, CA 92037 USA; [Hao, Jiucang; Lee, Te-Won] Univ Calif San Diego, Inst Neural Comp, La Jolla, CA 92093 USA; [Lee, Te-Won] Salk Inst Biol Studies, Comp Neurobiol Labs, La Jolla, CA USA; [Goldbaum, Michael H.] VA San Diego Hlth Serv, San Diego, CA USA	Bowd, C (reprint author), Univ Calif San Diego, Hamilton Glaucoma Ctr 178, La Jolla, CA 92037 USA.	cbowd@eyecenter.ucsd.edu	Tavares, Ivan/F-6766-2010; Hao, Jiucang/G-7017-2012	Tavares, Ivan/0000-0003-2220-7603; 			Bengtsson B, 2005, INVEST OPHTH VIS SCI, V46, P3730, DOI 10.1167/iovs.05-0175; Bishop C, 2003, ADV LEARNING THEORY, P267; Bishop CM, 2000, UNCERTAINTY ARTIFICI, P45; Bizios D, 2007, J GLAUCOMA, V16, P20, DOI 10.1097/IJG.0b013e31802b34e4; Bowd C, 2002, INVEST OPHTH VIS SCI, V43, P3444; Bowd C, 2006, ACTA OPHTHALMOL SCAN, V84, P569; Bowd C, 2001, INVEST OPHTH VIS SCI, V42, P1993; Bowd C, 2005, INVEST OPHTH VIS SCI, V46, P1322, DOI 10.1167/iovs.04-1122; Brigatti L, 1996, AM J OPHTHALMOL, V121, P511; Burgansky-Eliash Z, 2005, INVEST OPHTH VIS SCI, V46, P4147, DOI 10.1167/iovs.05-0366; CAPRIOLI J, 1992, INVEST OPHTH VIS SCI, V33, P153; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; Goldbaum MH, 2002, INVEST OPHTH VIS SCI, V43, P162; Huang ML, 2005, INVEST OPHTH VIS SCI, V46, P4121, DOI 10.1167/iovs.050069; Huang ML, 2007, INVEST OPHTH VIS SCI, V48, P244, DOI 10.1167/iovs.06-0320; JAESCHKE R, 1994, JAMA-J AM MED ASSOC, V271, P703, DOI 10.1001/jama.271.9.703; Kass MA, 2002, ARCH OPHTHALMOL-CHIC, V120, P829; Kass MA, 2002, ARCH OPHTHALMOL-CHIC, V120, P701; Lietman T, 1999, J GLAUCOMA, V8, P77; Mardin CY, 2006, J GLAUCOMA, V15, P299, DOI 10.1097/01.ijg.0000212232.03664.ee; Medeiros FA, 2003, INVEST OPHTH VIS SCI, V44, P2606, DOI 10.1167/iovs.02-0814; Centofanti M, 2005, OPHTHALMOLOGY, V112, P366, DOI 10.1016/j.ophtha.2004.11.030; Shah NN, 2006, OPHTHALMOLOGY, V113, P1593, DOI 10.1016/j.ophtha.2006.06.004; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; TRESP V, 2002, HDB NEURAL NETWORK, P1; Vapnik V. N., 2000, NATURE STAT LEARNING; Vapnik VN, 1998, STAT LEARNING THEORY; Zangwill LM, 2004, INVEST OPHTH VIS SCI, V45, P3144, DOI 10.1167/iovs.04-0202; Zangwill LM, 2001, ARCH OPHTHALMOL-CHIC, V119, P985; ZANGWILL LM, 2004, GLAUCOMA, P63	30	10	10	ASSOC RESEARCH VISION OPHTHALMOLOGY INC	ROCKVILLE	12300 TWINBROOK PARKWAY, ROCKVILLE, MD 20852-1606 USA	0146-0404		INVEST OPHTH VIS SCI	Invest. Ophthalmol. Vis. Sci.	MAR	2008	49	3					945	953		10.1167/iovs.07-1083		9	Ophthalmology	Ophthalmology	271TZ	WOS:000253812900019	
J	Fukunishi, H; Teramoto, R; Shimada, J				Fukunishi, Hiroaki; Teramoto, Reiji; Shimada, Jiro			Hidden active. information in a random compound library: Extraction using a pseudo-structure-activity relationship model	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							PROTEIN-LIGAND DOCKING; MOLECULAR DOCKING; GENETIC ALGORITHM; AUTOMATED DOCKING; FLEXIBLE DOCKING; SCORING FUNCTIONS; RANDOM FOREST; TABU SEARCH; CLASSIFICATION; ACCURACY	We propose a hypothesis that "a model of active compound can be provided by integrating information of compounds high-ranked by docking simulation of a random compound library". In our hypothesis, the inclusion of true active compounds in the high-ranked compound is not necessary. We regard the high-ranked compounds as being pseudo-active compounds.-As a method to embody our hypothesis, we introduce a pseudo-structure-activity relationship (PSAR) model. Although the PSAR model is the same as a quantitative structure activity relationship (QSAR) model, in terms of statistical methodology, the implications of the training data are different. Known active compounds (ligands) are used as training data in the QSAR model, whereas the pseudo-active compounds are used in the PSAR model. In this study, Random Forest was used as a machine-learning algorithm. From tests for four functionally different targets, estrogen receptor antagonist (ER), thymidine kinase (TK), thrombin, and acetylcholine esterase (AChE), using five scoring functions, we obtained three conclusions: (1) the PSAR models significantly gave higher percentages of known ligands found than random sampling, and these results are sufficient to support our hypothesis; (2) the PSAR models gave higher percentages of known ligands found than normal scoring by scoring function, and these results demonstrate the practical usefulness of the PSAR model; and (3) the PSAR model can assess compounds failed in the docking simulation. Note that PSAR and QSAR models are used in different situations; the advantage of the PSAR model emerges when no ligand is available as training data or when one wants to find novel types of ligands, whereas the QSAR model is effective for finding compounds similar to known ligands when the ligands are already known.	[Fukunishi, Hiroaki; Shimada, Jiro] NEC Corp Ltd, Cent Res Labs, Nano Elect Res Labs, Tsukuba, Ibaraki 3058501, Japan; [Teramoto, Reiji] NEC Corp Ltd, Cent Res Labs, Bio IT Ctr, Tsukuba, Ibaraki 3058501, Japan	Fukunishi, H (reprint author), NEC Corp Ltd, Cent Res Labs, Nano Elect Res Labs, 34 Miyukigaoka, Tsukuba, Ibaraki 3058501, Japan.	h-fukunishi@bu.jp.nec.com					Baxter CA, 1998, PROTEINS, V33, P367, DOI 10.1002/(SICI)1097-0134(19981115)33:3<367::AID-PROT6>3.0.CO;2-W; Bissantz C, 2000, J MED CHEM, V43, P4759, DOI 10.1021/jm001044l; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bruce CL, 2007, J CHEM INF MODEL, V47, P219, DOI [10.1021/ci600332j, 10.1021/ci600322j]; Charifson PS, 1999, J MED CHEM, V42, P5100, DOI 10.1021/jm990352k; Cherkasov A, 2006, J MED CHEM, V49, P7466, DOI 10.1021/jm060961+; Clark RD, 2002, J MOL GRAPH MODEL, V20, P281, DOI 10.1016/S1093-3263(01)00125-5; Ehrman TM, 2007, J CHEM INF MODEL, V47, P264, DOI 10.1021/ci600289v; Ewing TJA, 2001, J COMPUT AID MOL DES, V15, P411, DOI 10.1023/A:1011115820450; Friesner RA, 2004, J MED CHEM, V47, P1739, DOI 10.1021/jm0306430; Hou TJ, 1999, PROTEIN ENG, V12, P639, DOI 10.1093/protein/12.8.639; Huang N, 2006, J MED CHEM, V49, P6789, DOI 10.1021/jm0608356; Jacobsson M, 2003, J MED CHEM, V46, P5781, DOI 10.1021/jm030896t; Jain AN, 2003, J MED CHEM, V46, P499, DOI 10.1021/jm.020406h; Jones G, 1997, J MOL BIOL, V267, P727, DOI 10.1006/jmbi.1996.0897; Kellenberger E, 2004, PROTEINS, V57, P225, DOI 10.1002/prot.20149; KONTOYIANNI M, 2004, J MED CHEM, V56, P235; Kontoyianni M, 2005, J COMPUT CHEM, V26, P11, DOI 10.1002/jcc.20141; Kroemer RT, 2004, J CHEM INF COMP SCI, V44, P871, DOI 10.1021/ci049970m; KUNTZ ID, 1982, J MOL BIOL, V161, P269, DOI 10.1016/0022-2836(82)90153-X; Liu M, 1999, J COMPUT AID MOL DES, V13, P435, DOI 10.1023/A:1008005918983; McMartin C, 1997, J COMPUT AID MOL DES, V11, P333, DOI 10.1023/A:1007907728892; Morris GM, 1998, J COMPUT CHEM, V19, P1639, DOI 10.1002/(SICI)1096-987X(19981115)19:14<1639::AID-JCC10>3.0.CO;2-B; PALMER DS, 2006, J CHEM INF MODEL, V47, P150; Perola E, 2004, PROTEINS, V56, P235, DOI 10.1002/prot.20088; Perola E, 2000, J MED CHEM, V43, P401, DOI 10.1021/jm990408a; Plewczynski D, 2006, J CHEM INF MODEL, V46, P1098, DOI 10.1021/ci050519k; R DEVELOPMENT CORE TEAM, 2005, R LANG ENV STAT COMP; Rarey M, 1996, J MOL BIOL, V261, P470, DOI 10.1006/jmbi.1996.0477; Sheridan RP, 2004, J CHEM INF COMP SCI, V44, P1912, DOI 10.1021/ci049782w; Stahl M, 2001, J MED CHEM, V44, P1035, DOI 10.1021/jm0003992; Svetnik V, 2005, J CHEM INF MODEL, V45, P786, DOI 10.1021/ci0500379; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Teramoto R, 2007, J CHEM INF MODEL, V47, P526, DOI 10.1021/ci6004993; Verdonk ML, 2004, J CHEM INF COMP SCI, V44, P793, DOI 10.1021/ci034289q; Wang RX, 2003, J MED CHEM, V46, P2287, DOI 10.1021/jm0203783; Warren GL, 2006, J MED CHEM, V49, P5912, DOI 10.1021/jm050362n; Welch W, 1996, CHEM BIOL, V3, P449, DOI 10.1016/S1074-5521(96)90093-9; Yang JM, 2005, J CHEM INF MODEL, V45, P1134, DOI 10.1021/ci050034w; Yoon S, 2005, J COMPUT AID MOL DES, V19, P483, DOI 10.1007/s10822-005-9002-6; Zavodszky MI, 2002, J COMPUT AID MOL DES, V16, P883, DOI 10.1023/A:1023866311551; *BIO SOLV IT GMBH, FLESIS	42	3	3	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596		J CHEM INF MODEL	J. Chem Inf. Model.	MAR	2008	48	3					575	582		10.1021/ci7003384		8	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	279KG	WOS:000254353500011	
J	Melesse, AM; Krishnaswamy, J; Zhang, KQ				Melesse, Assefa M.; Krishnaswamy, Jayachandran; Zhang, Keqi			Modeling coastal eutrophication at Florida bay using neural networks	JOURNAL OF COASTAL RESEARCH			English	Article						chlorophyll a; artificial neural network; Florida Bay; eutrophication; nutrient loading	ALGAL BLOOMS	Nutrient loading and eutrophication in coastal waters are the causes of water quality degradation and loss of marine biota, which has led to ecological imbalance. Understanding and modeling the level of eutrophication as a function of environmental parameters can be beneficial to coastal ecosystem management. The limitation of deterministic and empirical models in accurately predicting the level of algal blooms, and the nonlinear relationship between the water quality and environmental parameters and that of the level of chlorophyll a necessitate a new approach using machine learning and data-driven modeling. A multilayer perceptron-back propagation (MLP-BP) algorithm of artificial neural network (ANN) was used to predict the level of eutrophication (chlorophyll a) from water quality parameters monitored at two Florida Bay water quality monitoring stations (FLAB03 and FLAB14). Based on the correlation of monthly nutrients (total phosphate, nitrite, ammonium) and other water data (temperature, turbidity, and dissolved oxygen) to the level of chlorophyll a, an input-output data structure was selected. Seven input data scenarios were studied, and model performance was compared using four indices. Monthly data from 1992 to 2004 were partitioned into training and testing subsets. Results show that chlorophyll a was predicted well with the selected inputs, with an average R 2 and model efficiency (E) of 0.856 and 0.582, respectively. Prediction with antecedent chlorophyll a alone gave a stable result with smaller error and higher performance attributed to easier and more efficient training. It was also found that ANN performed better at FLA03 than at FLA14. It is shown that the MLP-BP technique is applicable to the monitoring and prediction of algal blooms and will be crucial to coastal watershed management.	[Melesse, Assefa M.; Krishnaswamy, Jayachandran; Zhang, Keqi] Florida Int Univ, Dept Environm Studies, Miami, FL 33199 USA; [Krishnaswamy, Jayachandran] Florida Int Univ, SE Environm Res Ctr, Miami, FL 33199 USA; [Zhang, Keqi] Florida Int Univ, Int Hurricane Res Ctr, Miami, FL 33199 USA	Melesse, AM (reprint author), Florida Int Univ, Dept Environm Studies, 11200 SW 8th St, Miami, FL 33199 USA.	melessea@fiu.edu					ANDERSON JA, 1993, NEURAL NETWORKS KNOW, P311; Barciela RM, 1999, ECOL MODEL, V120, P199, DOI 10.1016/S0304-3800(99)00102-7; Caudill M., 1992, UNDERSTANDING NEURAL; FRENCH M, 1994, COMPUTER TECHNIQUES, V5, P87; HOLGER R, 1998, ECOLOGICAL MODELING, V105, P257; Karul C, 2000, ECOL MODEL, V134, P145, DOI 10.1016/S0304-3800(00)00360-4; KHAN AI, 1993, NEURAL NETWORKS AND COMBINATORIAL OPTIMIZATION IN CIVIL AND STRUCTURAL ENGINEERING, P81; Lee JHW, 2003, ECOL MODEL, V159, P179, DOI 10.1016/S0304-3800(02)00281-8; McIvor C.C., 1997, EVERGLADES ECOSYSTEM, P117; Melesse AM, 2005, ECOL MODEL, V189, P305, DOI 10.1016/j.ecolmodel.2005.03.014; Nash J E, 1970, J HYDROL, V10, P282, DOI DOI 10.1016/0022-1694(70)90255-6; Recknagel F, 1997, ECOL MODEL, V96, P11, DOI 10.1016/S0304-3800(96)00049-X; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1, P318; Smith M., 1993, NEURAL NETWORKS STAT; SNYDER GH, 1997, EVERGLADES ECOSYSTEM, P85; *EV NAT PARK, 2005, FL BAY RES PROGR	16	8	10	COASTAL EDUCATION & RESEARCH FOUNDATION	LAWRENCE	810 EAST 10TH STREET, LAWRENCE, KS 66044 USA	0749-0208		J COASTAL RES	J. Coast. Res.	MAR	2008	24	2B		S			190	196		10.2112/06-0646.1		7	Environmental Sciences; Geography, Physical; Geosciences, Multidisciplinary	Environmental Sciences & Ecology; Physical Geography; Geology	280SC	WOS:000254445500019	
J	Cruz-Monteagudo, M; Cordeiro, MNDS; Borges, F				Cruz-Monteagudo, Maykel; Cordeiro, M. Natalia D. S.; Borges, Fernanda			Computational chemistry approach for the early detection of drug-induced idiosyncratic liver toxicity	JOURNAL OF COMPUTATIONAL CHEMISTRY			English	Article						chemoinformatics; computational prediction; drug development; early detection; idiosyncratic hepatotoxicity; quantitative structure-toxicity relationships	CORONARY-ARTERY DISEASE; DESIGN MARCH-INSIDE; IN-SILICO; FULMINANT-HEPATITIS; BIOLOGICAL-ACTIVITY; PROMISING APPROACH; FAILURE; HEPATOTOXICITY; DESCRIPTORS; QSAR	Idiosyncratic drug toxicity (IDT), considered as a toxic host-dependent event, with an apparent lack of dose response relationship, is usually not predictable from early phases of clinical trials, representing a particularly confounding complication in drug development. Albeit a rare event (usually <1/5000), IDT is often life threatening and is one of the major reasons new drugs never reach the market or are withdrawn post marketing. Computational methodologies, like the computer-based approach proposed in the present study, can play an important role in addressing IDT in early drug discovery. We report for the first time a systematic evaluation of classification models to predict idiosyncratic hepatotoxicity based on linear discriminant analysis (LDA), artificial neural networks (ANN), and machine learning algorithms (OneR) in conjunction with a 3D molecular structure representation and feature selection methods. These modeling techniques (LDA, feature selection to prevent over-fitting and multicollinearity, ANN to capture nonlinear relationships in the data, as well as the simple OneR classifier) were found to produce QSTR models with satisfactory internal cross-validation statistics and predictivity on an external subset of chemicals. More specifically, the models reached values of accuracy/sensitivity/specificity over 84%/78%/90%, respectively in the training series along with predictivity values ranging from ca. 78 to 86% of correctly classified drugs. An LDA-based desirability analysis was carried out in order to select the levels of the predictor variables needed to trigger the more desirable drug, i.e. the drug with lower potential for idiosyncratic hepatotoxicity. Finally, two external test sets were used to evaluate the ability of the models in discriminating toxic from nontoxic structurally and phannacologically related drugs and the ability of the best model (LDA) in detecting potential idiosyncratic hepatotoxic drugs, respectively. The computational approach proposed here can be considered as a useful tool in early IDT prognosis. (c) 2007 Wiley Periodicals, Inc.	[Cruz-Monteagudo, Maykel; Borges, Fernanda] Univ Porto, Fac Pharm, Dept Organ Chem, Phys Chem Mol Res Unit, P-4150047 Oporto, Portugal; [Cruz-Monteagudo, Maykel] Cent Univ Las Villas, CEQA, Santa Clara 54830, Cuba; [Cruz-Monteagudo, Maykel] Cent Univ Las Villas, CBQ, Santa Clara 54830, Cuba; [Cordeiro, M. Natalia D. S.] Univ Porto, Fac Sci, Dept Chem, REQUIMTE, P-4169007 Oporto, Portugal	Borges, F (reprint author), Univ Porto, Fac Pharm, Dept Organ Chem, Phys Chem Mol Res Unit, P-4150047 Oporto, Portugal.	mfemandamborges@gmail.com	Cruz-Monteagudo, Maykel/G-4814-2010; Cordeiro, Maria Natalia /A-7413-2012				Aguero-Chapin GA, 2006, FEBS LETT, V580, P723, DOI 10.1016/j.febslet.2005.12.072; Aranda-Michel J, 1999, ANN INTERN MED, V130, P285; ATKINSON AC, 1985, TRANSFORMATIONS REGR; BATY V, 1994, GASTROEN CLIN BIOL, V18, P1129; BERNUAU J, 1988, J HEPATOL, V6, P109, DOI 10.1016/S0168-8278(88)80469-0; BOELSTERLI UA, 1987, CELL BIOL TOXICOL, V3, P231, DOI 10.1007/BF00117862; Boelsterli UA, 2006, CURR DRUG METAB, V7, P715, DOI 10.2174/138920006778520606; Chase Michael P., 2002, American Journal of Gastroenterology, V97, P502; Cruz-Monteagudo M, 2005, EUR J MED CHEM, V40, P1030, DOI 10.1016/j.ejmech.2005.04.012; Cruz-Monteagudo M, 2006, B MATH BIOL, V68, P1555, DOI 10.1007/s11538-006-9083-y; DERRINGER G, 1980, J QUAL TECHNOL, V12, P214; Eriksson L, 2003, ENVIRON HEALTH PERSP, V111, P1361, DOI 10.1289/ehp.5758; Estrada E, 2003, J CHEM INF COMP SCI, V43, P75, DOI 10.1021/ci025604w; Farley-Hills E, 2004, BRIT MED J, V329, P429, DOI 10.1136/bmj.329.7463.429; Federsel HJ, 2006, DRUG DISCOV TODAY, V11, P966, DOI 10.1016/j.drudis.2006.09.012; Fontana RJ, 1999, LIVER TRANSPLANT SUR, V5, P480, DOI 10.1002/lt.500050607; Frank E, 2004, BIOINFORMATICS, V20, P2479, DOI 10.1093/bioinformatics/bth261; Galati G, 2002, CHEM-BIOL INTERACT, V142, P25, DOI 10.1016/S0009-2797(02)00052-2; Gao J, 2004, TOXICOL IN VITRO, V18, P533, DOI 10.1016/j.tiv.2004.01.012; GARCIA AG, 1994, INDICE ESPECIALIDADE; Gasteiger J, 1996, J CHEM INF COMP SCI, V36, P1030, DOI 10.1021/ci960343+; Gonzalez MP, 2006, STEROIDS, V71, P510, DOI 10.1016/j.steroids.2006.02.001; Gonzalez-Diaz H, 2006, BIOORGAN MED CHEM, V14, P5973, DOI 10.1016/j.bmc.2006.05.018; Gonzalez-Diaz H, 2005, J MOL MODEL, V11, P116, DOI 10.1007/s00894-004-0228-3; Gonzalez-Diaz H, 2005, BIOORG MED CHEM LETT, V15, P1651, DOI 10.1016/j.bmcl.2005.01.047; Gonzales-Diaz H, 2003, J MOL MODEL, V9, P395, DOI 10.1007/s00894-003-0148-7; Gordin A, 2004, J NEURAL TRANSM, V111, P1343, DOI 10.1007/s00702-004-0190-3; HANSCH C, 1963, J AM CHEM SOC, V85, P2817, DOI 10.1021/ja00901a033; HANSCH C, 1964, J AM CHEM SOC, V86, P1616, DOI 10.1021/ja01062a035; Helguera A.M., 2006, J MOL MODEL, V12, P769, DOI 10.1007/s00894-005-0088-5; Hemmer MC, 1999, VIB SPECTROSC, V19, P151, DOI 10.1016/S0924-2031(99)00014-4; Hunter EB, 1999, AM J GASTROENTEROL, V94, P2299; Klein DJ, 1997, INT J QUANTUM CHEM, V63, P215, DOI 10.1002/(SICI)1097-461X(1997)63:1<215::AID-QUA22>3.0.CO;2-9; Kutner M. H., 2005, APPL LINEAR STAT MOD; Lazarou J, 1998, JAMA-J AM MED ASSOC, V279, P1200, DOI 10.1001/jama.279.15.1200; Li AP, 2002, CHEM-BIOL INTERACT, V142, P7, DOI 10.1016/S0009-2797(02)00051-0; Macfarlane B, 1997, GASTROENTEROLOGY, V112, P1707, DOI 10.1016/S0016-5085(97)70054-4; Masubuchi Y, 2006, DRUG METAB PHARMACOK, V21, P347, DOI 10.2133/dmpk.21.347; May LD, 2002, ANN INTERN MED, V136, P449; Menon KVN, 2001, AM J GASTROENTEROL, V96, P1631; MIN DI, 1992, PHARMACOTHERAPY, V12, P68; Nascimento DG, 2006, TOXICON, V47, P628, DOI 10.1016/j.toxicon.2006.01.015; Panagiotis B, 1999, J NEUROPSYCH CLIN N, V11, P117; PEREZ MAC, 2001, EUR B DRUG RES, V9, P1; Rabkin JM, 1999, ANN PHARMACOTHER, V33, P945, DOI 10.1345/aph.18364; RANDIC M, 1991, NEW J CHEM, V15, P517; Richard AM, 2006, CHEM RES TOXICOL, V19, P1257, DOI 10.1021/tx060116u; Rietjens IMCM, 2006, CHEM RES TOXICOL, V19, P977, DOI 10.1021/tx0601051; ROTHFUSS A, 2006, J CHEM RES TOXICOL, V19, P1313; Rothwell Charles, 2002, J Toxicol Sci, V27, P35, DOI 10.2131/jts.27.35; Scheen AJ, 2001, DIABETES METAB, V27, P305; STATISTICA 6.0, 2001, STATISTICA 6 0; Stewart J., 1998, ECONOMETRICS; STEWART JJP, 1989, J COMPUT CHEM, V10, P209, DOI 10.1002/jcc.540100208; Todeschini R., 2002, DRAGON SOFTWARE; Ulrich RG, 2001, CHEM-BIOL INTERACT, V134, P251, DOI 10.1016/S0009-2797(01)00161-2; Ulrich RG, 2007, ANNU REV MED, V58, P17, DOI 10.1146/annurev.med.58.072905.160823; Van Waterbeemd H, 1995, CHEMOMETRIC METHODS; Van Waterbeemd H, 1995, CHEMOMETRIC METHODS, P265; Van de Waterbeemd H, 1989, Prog Clin Biol Res, V291, P123; Wan CH, 1999, J CHEM INF COMP SCI, V39, P1049, DOI 10.1021/ci990306t; Witten I. H., 2000, DATA MINING PRACTICA; Zupan J., 1999, NEURAL NETWORKS CHEM; ZWEIG MH, 1994, ARCH PATHOL LAB MED, V118, P141; ZWEIG MH, 1992, CLIN CHEM, V38, P1425; [Anonymous], 2002, HYPERCHEM 7 5; *CAMBRIDGESOFT, 2004, CHEMDRAW ULTRA 9 0; *FRANK J SEIL RES, 1993, MOPAC 6 0; *U WAIK, 2002, WEKA SOFTW	69	16	16	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	0192-8651		J COMPUT CHEM	J. Comput. Chem.	MAR	2008	29	4					533	549		10.1002/jcc.20812		17	Chemistry, Multidisciplinary	Chemistry	269KS	WOS:000253648500005	
J	Yan, LJ; Fraser, M; Elgamal, A; Fountain, T; Oliver, K				Yan, Linjun; Fraser, Michael; Elgamal, Ahmed; Fountain, Tony; Oliver, Kendra			Neural networks and principal components analysis for strain-based vehicle classification	JOURNAL OF COMPUTING IN CIVIL ENGINEERING			English	Article								A large database has been acquired and compiled of vehicles crossing over a simply supported bridge deck system. Over the course of 1.5 years, deck strains caused by traffic, along with time-synchronized video images have been archived (400,000 records). Herein, this dataset is presented and used to develop a strain-based vehicle classification approach, as a machine learning application. To achieve this goal, the principal components analysis technique is applied to extract essential features from the strain time histories. Using these features as input, a two-layered back-propagation neural network is built and trained to sort vehicles into five classes. In this regard, availability of the video images provides essential information for developing the needed labeled datasets. The trained network is tested, and satisfactory results are achieved, showing viability of the classification approach for this bridge deck system.	[Fraser, Michael; Elgamal, Ahmed] Univ Calif San Diego, Dept Struct Engn, La Jolla, CA 92093 USA; [Yan, Linjun] Saifu Bouquet Consulting Inc, Pasadena, CA 91101 USA; [Fountain, Tony] Univ Calif San Diego, CELOS, San Diego Supercomp Ctr, La Jolla, CA 92093 USA; [Oliver, Kendra] Han Padron Assoc, Oakland, CA 94612 USA	Elgamal, A (reprint author), Univ Calif San Diego, Dept Struct Engn, 6500 Gilman Dr, La Jolla, CA 92093 USA.	james.linjun.yan@gmail.com; mfraser@ucsd.edu; elgamal@ucsd.edu; fountain@sdsc.edu; kolivcr@hpa.com					Achler O., 2004, 7 INT IEEE C INT TRA, P743; Athol P., 1965, HIGHWAY RES REC, V72, P58; Bishop C. M., 2006, PATTERN RECOGNITION; Bishop C.M., 1995, NEURAL NETWORKS PATT; Bridle J. S., 1990, Neurocomputing, Algorithms, Architectures and Applications. Proceedings of the NATO Advanced Research Workshop; CHANG R, 2004, 7 INT IEEE C INT TRA, P971; Dailey MN, 2002, J COGNITIVE NEUROSCI, V14, P1158, DOI 10.1162/089892902760807177; Elgamal A., 2003, P 4 INT WORKSH STRUC; FLOOD I, 1994, J COMPUT CIVIL ENG, V8, P131, DOI 10.1061/(ASCE)0887-3801(1994)8:2(131); FLOOD I, 1994, J COMPUT CIVIL ENG, V8, P149, DOI 10.1061/(ASCE)0887-3801(1994)8:2(149); FRASER M, 2006, THESIS U CALIFORNIA; Graettinger AJ, 2005, J TRANSP ENG-ASCE, V131, P689, DOI 10.1061/(ASCE)0733-947X(2005)131:9(689); HASSELMAN TK, 1998, P 16 INT MOD AN C SP; Hastie T., 2001, SPRINGER SERIES STAT; Jolliffe IT, 1986, PRINCIPAL COMPONENTS; KARTAM N, 1997, ARTIFICIAL NEURAL NE, P19; Kuzniar K, 2006, J COMPUT CIVIL ENG, V20, P431, DOI 10.1061/(ACSE)0887-3801(2006)20:6(431); LECUN Y, 1998, SPRINGER LECT NOTES, V1524, P5; LU Y, 1989, J TRANSP ENG-ASCE, V118, P223; Mussa R, 2006, J TRANSP ENG-ASCE, V132, P293, DOI 10.1061/(ASCE)0733-947X(2006)132:4(293); OH S, 2001, UCIITSWP0115 DEP CIV; Russell S., 1995, ARTIFICIAL INTELLIGE; Scheaffer R. L., 1996, ELEMENTARY SURVEY SA; Sun C, 2003, COMPUT-AIDED CIV INF, V18, P161, DOI 10.1111/1467-8667.00307; SUN C, 2000, TRANSP RES BOARD ANN; WEI C, 1996, 1551 TRANSP RES BOAR, P45; YUAN XD, 1994, J TRANSP ENG-ASCE, V120, P861, DOI 10.1061/(ASCE)0733-947X(1994)120:6(861); Zhao L., 1999, THESIS U CALIFORNIA	28	2	2	ASCE-AMER SOC CIVIL ENGINEERS	RESTON	1801 ALEXANDER BELL DR, RESTON, VA 20191-4400 USA	0887-3801		J COMPUT CIVIL ENG	J. Comput. Civil. Eng.	MAR-APR	2008	22	2					123	132		10.1061/(ASCE)0887-3801(2008)22:2(123)		10	Computer Science, Interdisciplinary Applications; Engineering, Civil	Computer Science; Engineering	265WM	WOS:000253392500007	
J	Mak, MW; Tewfik, A; Chan, LW; Chan, CCK				Mak, Man Wai; Tewfik, Ahmed; Chan, Lai Wan; Chan, Chun Chung Keith			Introduction to the special issue on machine learning for microarray bioinformatics	JOURNAL OF SIGNAL PROCESSING SYSTEMS FOR SIGNAL IMAGE AND VIDEO TECHNOLOGY			English	Editorial Material									[Mak, Man Wai; Chan, Chun Chung Keith] Hong Kong Polytech Univ, Kowloon, Hong Kong, Peoples R China; [Tewfik, Ahmed] Univ Minnesota, Minneapolis, MN USA; [Chan, Lai Wan] Chinese Univ Hong Kong, Sha Tin, Hong Kong, Peoples R China	Mak, MW (reprint author), Hong Kong Polytech Univ, Kowloon, Hong Kong, Peoples R China.							0	0	0	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1939-8018		J SIGNAL PROCESS SYS	J. Signal Process. Syst. Signal Image Video Technol.	MAR	2008	50	3					263	265		10.1007/s11265-007-0125-y		3	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	272SP	WOS:000253880400001	
J	Feinerer, I; Hornik, K; Meyer, D				Feinerer, Ingo; Hornik, Kurt; Meyer, David			Text mining infrastructure in R	JOURNAL OF STATISTICAL SOFTWARE			English	Article						text mining; R; count-based evaluation; text clustering; text classification; string kernels	LATENT SEMANTIC ANALYSIS; STRING KERNELS; CATEGORIZATION	During the last decade text mining has become a widely used discipline utilizing statistical and machine learning methods. We present the tm package which provides a framework for text mining applications within R. We give a survey on text mining facilities in R and explain how typical application tasks can be carried out using our framework. We present techniques for count- based analysis methods, text clustering, text classification and string kernels.	[Feinerer, Ingo; Hornik, Kurt] Vienna Univ Econ & Business Adm, Dept Math & Stat, A-1090 Vienna, Austria; [Meyer, David] Vienna Univ Econ & Business Adm, Inst Management Informat Syst, A-1090 Vienna, Austria	Feinerer, I (reprint author), Vienna Univ Econ & Business Adm, Dept Math & Stat, Augasse 2-6, A-1090 Vienna, Austria.	h0125130@wu-wien.ac.at; Kurt.Hornik@wu-wien.ac.at; David.Meyer@wu-wien.ac.at					Adeva JJG, 2006, IEEE INTERNET COMPUT, V10, P27; Anderberg M. R, 1973, CLUSTER ANAL APPL; Asuncion A., 2007, UCI MACHINE LEARNING; BATES D, 2007, MATRIX MATRIX PACKAG; Berners-Lee T., 2001, SEMANTIC WEB, P34; Berry M. W., 2003, SURVEY TEXT MINING C; BIERNER G, 2007, OPENNLP COLLECTION N; BILL E, 1995, COMPUTATIONAL LINGUI, V21, P543; Boley D, 1999, DECIS SUPPORT SYST, V27, P329, DOI 10.1016/S0167-9236(99)00055-X; BOLEY D, 1998, 98012 U MINN; Cavnar W. B., 1994, P 3 ANN S DOC AN INF, P161; Chambers J. M., 1998, PROGRAMMING DATA; Christianini N., 2000, INTRO SUPPORT VECTOR; Cunningham H., 2002, P 40 ANN M ASS COMP; Davi A, 2005, AM STAT, V59, P89, DOI 10.1198/000313005X22987; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; DHILLON I, 2005, UNIFIED VIEW KERNEL; Dong QW, 2006, BIOINFORMATICS, V22, P285, DOI 10.1093/bioinformatics/bti801; Eliassi-Rad T., 2006, KDD 06, P935, DOI DOI 10.1145/1150402.1150531; FEINERER I, 2007, TM TEXT MINING PACKA; FEINERER I, 2007, DATA ANAL MACHINE LE; FEINERER I, 2007, LECT NOTES INFORM, V107, P66; FEINERER I, 2007, OPENNLP OPENNLP INTE; FEINERER I, 2007, WORDNET WORDNET INTE; Fellbaum C., 1998, WORDNET ELECT LEXICA; Fowler M, 2003, UML DISTILLED BRIEF; Gentleman R, 2005, BIOINFORMATICS COMPU; GENTLEMAN RC, 2004, GENOME BIOL, V5; Giron J, 2005, AM STAT, V59, P19, DOI 10.1198/000313005X21311; Hartigan J. A., 1979, Applied Statistics, V28, DOI 10.2307/2346830; Hartigan J. A., 1975, CLUSTERING ALGORITHM; HARTIGAN JA, 1972, J AM STAT ASSOC, V67, P123, DOI 10.2307/2284710; Hearst M., 1999, P 37 ANN M ASS COMP, P3, DOI DOI 10.3115/1034678.1034679; HERBRICH R, 2002, ADAPTIVE COMPUTATION; HETTICH S, 1999, UCI KDD ARH; Holmes D.I., 2003, CHANCE, V16, P5; HORNIK K, 2007, SNOWBALL SNOWBALL ST; HORNIK K, 2007, CLUE CLUSTER ENSEMBL; Hornik K., 2005, J STAT SOFTWARE, V14; HORNIK K, 2007, RWEKA R INTERFACE WE; INGEBRIGTSEN LM, 1967, GMANE MAILING LIST A; JOACHIMS T., 2002, LEARNING CLASSIFY TE; Johnson S., 1967, PSYCHOMETRIKA, V2, P241; Karatzoglou A., 2004, J STAT SOFTWARE, V11; KARATZOGLOU A, 2006, KERNLAB KERNEL METHO; Karatzoglou A, 2007, ST CLASS DAT ANAL, P91, DOI 10.1007/978-3-540-70981-7_11; Landauer TK, 1998, DISCOURSE PROCESS, V25, P259; LANG DT, 2004, RSTEM INTERFACE SNOW; LANG DT, 2006, XML TOOLS PARSING GE; Lewis D.D., 1997, REUTERS 21578 TEXT C; Lewis DD, 2004, J MACH LEARN RES, V5, P361; LI Y, 2007, J INTELLIGENT INFORM; Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687; MacQueen J. B., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; Manola F., 2004, RDF PRIMER; McCallum A, 1996, BOW TOOLKIT STAT LAN; MEYER D, 2007, PROXY DISTANCE SIMIL; MILLER TW, 2005, DATA TEXT MINING; Mitchell M., 1993, COMPUTATIONAL LINGUI, V19, P313; MUELLER JP, 2006, TTDA TOOLS TEXTUAL D; NASO PO, 2007, GUTENBERG PROJECT; Ng A.Y., 2002, ADV NEURAL INFORM PR, V14; NILO J, 2003, CHANCE, V16, P9; PENG RD, 2006, R NEWS, V6, P19; PIATETSKYSHAPIR.G, 2005, POLL TEXT MINING TOO; Porter M. F., 1997, READINGS INFORM RETR, P313; R Development Core Team, 2007, R LANG ENV STAT COMP; Radlinski F., 2007, P 13 ACM SIGKDD INT, P570, DOI 10.1145/1281192.1281254; Sakurai S, 2005, APPL SOFT COMPUT, V6, P62, DOI 10.1016/j.asoc.2004.10.007; Scholkopf B., 2002, LEARNING KERNELS; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Sibun P., 1996, Proceedings. Fifth Annual Symposium on Document Analysis and Information Retrieval; Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531; Steinbach M, 2000, KDD WORKSH TEXT MIN; Strehl A., 2000, P AAAI WORKSH AI WEB, P58; TEO CH, 2006, P 23 INT C MACH LEAR; Venables W. N., 2002, MODERN APPL STAT S; VISWANATHAN S, 2004, KERNELS BIOINFORMATI; Watkins C, 2000, ADV NEUR IN, P39; Weiss S., 2004, TEXT MINING PREDICTI; WILD F, 2005, ISA LATENT LATENT SE; Witten I. H., 2005, DATA MINING PRACTICA; WITTEN IH, 2005, CASE STUDIES ASIA PA, P129; Wu YFB, 2005, 5th IEEE International Conference on Advanced Learning Technologies, Proceedings, P388; Zhao Y, 2005, SIAM PROC S, P358; Zhao Y, 2004, MACH LEARN, V55, P311, DOI 10.1023/B:MACH.0000027785.44527.d6; Zhao Y, 2005, DATA MIN KNOWL DISC, V10, P141, DOI 10.1007/s10618-005-0361-3	88	25	25	JOURNAL STATISTICAL SOFTWARE	LOS ANGELES	UCLA DEPT STATISTICS, 8130 MATH SCIENCES BLDG, BOX 951554, LOS ANGELES, CA 90095-1554 USA	1548-7660		J STAT SOFTW	J. Stat. Softw.	MAR	2008	25	5					1	54				54	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	283EP	WOS:000254619800001	
J	Pakhomov, SVS; Hanson, PL; Bjornsen, SS; Smith, SA				Pakhomov, Sercuei V. S.; Hanson, Penny L.; Bjornsen, Susan S.; Smith, Steven A.			Automatic classification of foot examination findings using clinical notes and machine learning	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article							ELECTRONIC HEALTH RECORD; QUALITY MEASURES; MEDICAL-RECORD; CARE; MANAGEMENT; ADHERENCE; VALIDITY; OUTCOMES	We examine the feasibility of a machine learning approach to identification of foot examination (FE) findings from the unstructured text of clinical reports. A Support Vector Machine (SVM) based system was constructed to process the text of physical examination sections of in- and out-patient clinical notes to identify if the findings of structural, neurological, and vascular components of a FE revealed normal or abnormal findings or were not assessed. The system was tested on 145 randomly selected patients for each FE component using 10-fold cross validation. The accuracy was 80%, 87% and 88% for structural, neurological, and vascular component classifiers, respectively. Our results indicate that using machine learning to identify FE findings from clinical reports is a viable alternative to manual review and warrants further investigation. This application may improve quality and safety by providing inexpensive and scalable methodology for quality and risk factor assessments at the point of care.	[Pakhomov, Sercuei V. S.] Univ Minnesota, Dept Pharm Care & Hlth Syst, St Paul, MN USA; [Hanson, Penny L.; Bjornsen, Susan S.; Smith, Steven A.] Mayo Clin, Dept Hlth Care Policy & Res, Rochester, MN USA; [Smith, Steven A.] Mayo Clin, Dept Endocrinol, Rochester, MN USA	Pakhomov, SVS (reprint author), Weaver Densford Hall,308 Harvard St SE, Minneapolis, MN 55455 USA.	pakh0002@umn.edu					Aphinyanaphongs Y, 2005, J AM MED INFORM ASSN, V12, P207, DOI 10.1197/jamia.M1641; BIORNSEN S, 1998, DIABETES S1, V47, pA184; Birke James A, 2003, J La State Med Soc, V155, P37; Bruckner M, 1999, AM J MANAG CARE, V5, P609; Burton C, 2006, CLIN REHABIL, V20, P46, DOI 10.1191/0269215506cr903oa; Cassidy LD, 2002, AM J MANAG CARE, V8, P787; Cohen Aaron M, 2006, AMIA Annu Symp Proc, P161; Fiszman M, 2000, J AM MED INFORM ASSN, V7, P593; Fiszman M, 1999, Proc AMIA Symp, P67; Ford EW, 2006, J AM MED INFORM ASSN, V13, P106, DOI 10.1197/jamia.M1913; Friedman C., 2000, AMIA S, P270; Gompertz PH, 2001, J EVAL CLIN PRACT, V7, P1, DOI 10.1046/j.1365-2753.2001.00274.x; Hazlehurst B, 2005, AM J PREV MED, V29, P434, DOI 10.1016/j.amepre.2005.08.007; Hiissa M, 2006, ST HEAL T, V124, P789; Institute of Medicine, 2001, CROSS QUAL CHASM NEW; Joshi Mahesh, 2006, AMIA Annu Symp Proc, P399; Jutley R S, 2001, J Qual Clin Pract, V21, P71, DOI 10.1046/j.1440-1762.2001.00414.x; Kuo S, 2005, AM J PREV MED, V29, P396, DOI 10.1016/j.amepre.2005.08.010; Mangione CM, 2006, ANN INTERN MED, V145, P107; Manning C. D., 1999, FDN STAT NATURAL LAN; Melton Genevieve B, 2005, J Am Med Inform Assoc, V12, P448, DOI 10.1197/jamia.M1794; PAKHOMOV S, 2007, IN PRESS MED DECISIO; Pakhomov S, 2007, AM J MANAG CARE, V13, P281; Pakhomov SSV, 2007, AM HEART J, V153, P666, DOI 10.1016/j.ahj.2006.12; Persell SD, 2006, ARCH INTERN MED, V166, P2272, DOI 10.1001/archinte.166.20.2272; PLATT JC, 1998, ADV KERNAL METHODS S; Saaddine JB, 2006, ANN INTERN MED, V144, P465; SAGER N, 1994, J AM MED INFORM ASSN, V1, P142; Tang PC, 2007, J AM MED INFORM ASSN, V14, P10, DOI 10.1197/jamia.M2198; Witten I. H., 2005, DATA MINING PRACTICA; Xu H, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-334; 2006, DIABETES PHYS RECOGN	32	3	3	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	1067-5027		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	MAR-APR	2008	15	2					198	202		10.1197/jamia.M2585		5	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Information Science & Library Science; Medical Informatics	Computer Science; Information Science & Library Science; Medical Informatics	273UL	WOS:000253957100010	
J	Peterson, GL; McBride, BT				Peterson, Gilbert L.; McBride, Brent T.			The importance of generalizability for anomaly detection	KNOWLEDGE AND INFORMATION SYSTEMS			English	Article						clustering; anomaly detection; convex polytope; ellipsoid	INTRUSIONS; MODEL	In security-related areas there is concern over novel "zero-day" attacks that penetrate system defenses and wreak havoc. The best methods for countering these threats are recognizing "nonself" as in an Artificial Immune System or recognizing "self" through clustering. For either case, the concern remains that something that appears similar to self could be missed. Given this situation, one could incorrectly assume that a preference for a tighter fit to self over generalizability is important for false positive reduction in this type of learning problem. This article confirms that in anomaly detection as in other forms of classification a tight fit, although important, does not supersede model generality. This is shown using three systems each with a different geometric bias in the decision space. The first two use spherical and ellipsoid clusters with a k-means algorithm modified to work on the one-class/blind classification problem. The third is based on wrapping the self points with a multidimensional convex hull (polytope) algorithm capable of learning disjunctive concepts via a thresholding constant. All three of these algorithms are tested using the Voting dataset from the UCI Machine Learning Repository, the MIT Lincoln Labs intrusion detection dataset, and the lossy-compressed steganalysis domain.	[Peterson, Gilbert L.; McBride, Brent T.] USAF, Inst Technol, Dept Elect & Comp Engn, Wright Patterson AFB, OH 45433 USA	Peterson, GL (reprint author), USAF, Inst Technol, Dept Elect & Comp Engn, 2950 Hobson Way, Wright Patterson AFB, OH 45433 USA.	gilbert.peterson@afit.edu					AVCIBAS I, 2002, INT C IM PROC ROCH N; BARBER CB, 2002, QHULL VERSION 2002 1; Barbera J, 1997, LIQ CRYST, V22, P483; BARRON AR, 1991, PROCEEDINGS OF THE FOURTH ANNUAL WORKSHOP ON COMPUTATIONAL LEARNING THEORY, P243; BAUM EB, 1988, P NEUR INF PROC SYST, P81; Blake C. L., 1998, UCI REPOSITORY MACHI; BROTHERTON T, 2001, IEEE AER C BIG SK MT; Chang CI, 2002, IEEE T GEOSCI REMOTE, V40, P1314, DOI 10.1109/TGRS.2002.800280; Cho SB, 2003, COMPUT SECUR, V22, P45, DOI 10.1016/S0167-4048(03)00112-3; COHEN WW, 1988, MACH LEARN, P256; Coxeter H. S. M., 1973, REGULAR POLYTOPES; Dasgupta D, 2002, IEEE T EVOLUT COMPUT, V6, P281, DOI 10.1109/TEVC.2002.1011541; DELANY SJ, 2006, TCDCS200605 ECUE TRI; DENNING DE, 1987, IEEE T SOFTWARE ENG, V13, P222, DOI 10.1109/TSE.1987.232894; DRUMMOND C, 2005, KDD 2005 WORKSH DAT, P21; Duda R. O., 2001, PATTERN CLASSIFICATI; ESKIN E, 2000, P INT C MACH LEARN S; ESKIN E, 2002, APPL DATA MIN COMP S, P82; FAIRD H, 2003, IEEE WORKSH STAT AN; Fan W, 2004, KNOWL INF SYST, V6, P507, DOI 10.1007/s10115-003-0132-7; FRIDRICH J, 2001, IEEE, P22; GUPTA ASR, 2003, RECENT ADV INTRUSION; HAINES J, 1999, DARPA INTRUSION DETE; HAMERLY G, 2003, ADV NEURAL INF PROCE, V15, P289; INOUS H, 2002, NEW SEC PAR WORKSH, P52; JACKSON J, 2003, THESIS AIR FORCE I T; KHARRAZI M, 2005, IEEE SPIE; KUBLER TL, 2006, THESIS AIR FORCE I T; LAMBERT T, 1998, CONVEX HULL ALGORITH; Lane T, 2003, MACH LEARN, V51, P73, DOI 10.1023/A:1021830128811; LYU S, 2002, INFORM HIDING; Lyu S., 2004, SPIE S EL IM SAN JOS; Macqueen J. B., 1967, P 5 BERK S MATH STAT, P281; Mahoney M., 2003, P REC ADV INTR DET R; MCBRIDE B, 2004, P 17 INT FLAIRS C, P520; McBride BT, 2005, DIGIT INVESTIG, V2, P50, DOI 10.1016/j.diin.2005.01.003; MELNIK O, 2002, MACH LEARN, V48; Mitchell T. M., 1986, Machine Learning, V1, DOI 10.1007/BF00116250; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; NGUYEN H, 2003, EXPLAINING HIGH DIME; OROURKE K, 1998, COMPUTATION GEOMET C; Pelleg D., 2000, P 17 INT C MACH LEAR, P727; PETERSON GL, 2005, KDD 2005 WORKSH DAT, P53; Srivastava Jaideep, 2003, P 3 SIAM INT C DAT M; THRUN S, 1995, CMUCS95208 CARN MELL; Wah BW, 1999, IEEE T KNOWL DATA EN, V11, P175, DOI 10.1109/69.755626; WIDMER G, 1996, MACH LEARN, V23, P68; WONG C, 2000, 9 IEEE INT C FUZZ SY, V1, P48	48	3	3	SPRINGER LONDON LTD	ARTINGTON	ASHBOURNE HOUSE, THE GUILDWAY, OLD PORTSMOUTH ROAD, ARTINGTON GU3 1LP, GUILDFORD, ENGLAND	0219-1377		KNOWL INF SYST	Knowl. Inf. Syst.	MAR	2008	14	3					377	392		10.1007/s10115-007-0072-8		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	277HK	WOS:000254203100006	
J	Guyon, I; Saffari, A; Dror, G; Cawley, G				Guyon, Isabelle; Saffari, Amir; Dror, Gideon; Cawley, Gavin			Analysis of the IJCNN 2007 agnostic learning vs. prior knowledge challenge	NEURAL NETWORKS			English	Article; Proceedings Paper	International Joint Conference on Neural Networks	AUG 12-17, 2007	Orlando, FL	IEEE		supervised learning; classification; competition; agnostic learning; prior knowledge; domain knowledge; boosting; ensemble methods; kernel methods; support vector machines; SVM; LSSVM; data grid models		We organized a challenge for IJCNN 2007 to assess the added value of prior domain knowledge in machine learning. Most commercial data mining programs accept data pre-formatted in the form of a table, with each example being encoded as a linear feature vector. Is it worth spending time incorporating domain knowledge in feature construction or algorithm design, or can off-the-shelf programs working directly on simple low-level features do better than skilled data analysts? To answer these questions, we formatted five datasets using two data representations. The participants in the "prior knowledge" track used the raw data, with full knowledge of the meaning of the data representation. Conversely, the participants in the "agnostic learning" track used a pre-formatted data table, with no knowledge of the identity of the features. The results indicate that black-box methods using relatively unsophisticated features work quite well and rapidly approach the best attainable performance. The winners on the prior knowledge track used feature extraction strategies yielding a large number of low-level features. Incorporating prior knowledge in the form of generic coding/smoothing methods to exploit regularities in data is beneficial, but incorporating actual domain knowledge in feature construction is very time consuming and seldom leads to significant improvements. The AL vs. PK challenge web site remains open for post-challenge submissions: http://www.agnostic.inf.ethz.ch/. (C) 2007 Elsevier Ltd. All rights reserved.	[Guyon, Isabelle] ClopiNet, Berkeley, CA 94708 USA; [Saffari, Amir] Graz Univ Technol, A-8010 Graz, Austria; [Dror, Gideon] Acad Coll Tel Aviv Yaffo, Tel Aviv, Israel; [Cawley, Gavin] Univ E Anglia, Norwich NR4 7TJ, Norfolk, England	Guyon, I (reprint author), ClopiNet, Berkeley, CA 94708 USA.	isabelle@clopinet.com; amir@ymer.org; gideon@mta.ac.il; gcc@cmp.uea.ac.uk					AZENCOTT CA, 2007, J CHEM INF; Baldi P., 2001, BIOINFORMATICS MACHI; BEKKERMAN R, 2003, DISTRIBUTIONAL WORD; BLACKARD JA, 1998, FOREST COVER TYPE; BOULLE M, 2007, JMLR, P1659; BOULLE M, 2007, P IJCNN07 INNS IEEE; CAWLEY GC, 2007, P IJCNN07 INNS IEEE; Cawley GC, 2007, J MACH LEARN RES, V8, P841; COLLINS JM, 1999, DTP AIDS ANTIVIRAL S; ESCALANTE HJ, 2007, P IJCNN07 INNS IEEE; ESCALANTE HJ, 2007, UNPUB JMLR; GUYON I, 2005, DATASETS AGNOSTIC LE; GUYON I, 2006, IEEE INNS C IJCNN 20; GUYON I, 2007, P IJCNN07 INNS IEEE; Guyon I, 2004, ADV NEURAL INFORM PR, V17, P545; KOHAVI R, 1994, ADULT DATABASE; LeCun Y., 1998, MNIST DATABASE HANDW; LUTZ RW, 2006, P IJCNN06 VANC CAN I, P2966; MITCHELL T, 1999, 20 NEWSGROUP DATASET; NIKULIN V, 2007, P IJCNN07 INNS IEEE; PRANCKEVICIENE E, 2007, P IJCNN07 INNS IEEE; REUNANEN J, 2007, P IJCNN07 INNS IEEE; REUNANEN J, 2007, UNPUB JMLR; SAFFARI A, 2006, QUICK START GUIDE CL; SIMARD P., 2003, INT C DOC AN REC ICD, P958; Weston J., 2005, SPIDER MACHINE LEARN; WICHARD J, 2007, P IJCNN07 INNS IEEE	27	8	8	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080		NEURAL NETWORKS	Neural Netw.	MAR-APR	2008	21	2-3					544	550		10.1016/j.neunet.2007.12.024		7	Computer Science, Artificial Intelligence	Computer Science	292AM	WOS:000255238800046	
J	Agarwal, S; Saradhi, VV; Karnick, H				Agarwal, Sumeet; Saradhi, V. Vijaya; Karnick, Harish			Kernel-based online machine learning and support vector reduction	NEUROCOMPUTING			English	Article; Proceedings Paper	15th European Symposium on Artificial Neural Networks	APR, 2007	Brugge, BELGIUM			support vector machines; span of support vectors; classifier complexity reduction; budget algorithm; online SVMs		We apply kernel-based machine learning methods to online learning situations, and look at the related requirement of reducing the complexity of the learnt classifier. Online methods are particularly useful in situations which involve streaming data, such as medical or financial applications. We show that the concept of span of support vectors can be used to build a classifier that performs reasonably well while satisfying given space and time constraints, thus making it potentially suitable for such online situations. The span-based heuristic is observed to be effective under stringent memory limits (that is when the number of support vectors a machine can hold is very small). (c) 2008 Elsevier B.V. All rights reserved.	[Saradhi, V. Vijaya; Karnick, Harish] Indian Inst Technol, Dept Comp Sci & Engn, Kanpur 208016, Uttar Pradesh, India; [Agarwal, Sumeet] Univ Oxford, Syst Biol Doctoral Training Ctr, Oxford OX1 2JD, England	Saradhi, VV (reprint author), Indian Inst Technol, Dept Comp Sci & Engn, Kanpur 208016, Uttar Pradesh, India.	sumeet.agarwal@dtc.ox.ac.uk; saradhi@cse.iitk.ac.in; hk@cse.iitk.ac.in					Burges C.J.C., 1996, 13 INT C MACH LEARN, P71; CAUWENBERGHS G, 2001, NEURAL INFORM PROCES; Crammer K, 2003, J MACH LEARN RES, V3, P951, DOI 10.1162/jmlr.2003.3.4-5.951; Crammer K., 2004, ADV NEURAL INFORM PR; DEKEL O, 2007, ADV NEURAL INFORM PR; Fine S., 2001, J MACHINE LEARNING R, V2, P243; Hsu CW, 2002, MACH LEARN, V46, P291, DOI 10.1023/A:1012427100071; Keerthi SS, 2000, IEEE T NEURAL NETWOR, V11, P124, DOI 10.1109/72.822516; Keerthi SS, 2006, J MACH LEARN RES, V7, P1493; Kivinen J, 2004, IEEE T SIGNAL PROCES, V52, P2165, DOI 10.1109/TSP.2004.830991; LEE Y, 2001, CD P 1 SIAM INT C DA; Masters A., 2001, J MACHINE LEARNING R, V2, P293; NGUYEN D, 2005, 22 INT C MACH LEARN, P617; Platt J.C., 1999, ADV KERNEL METHODS S; Scholkopf B., 2002, LEARNING KERNELS; Steinwart I., 2003, J MACHINE LEARNING R, V4, P1071, DOI 10.1162/jmlr.2003.4.6.1071; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Vapnik V, 2000, NEURAL COMPUT, V12, P2013, DOI 10.1162/089976600300015042; Vapnik V. N, 1995, NATURE STAT LEARNING; WU M, 2005, 22 INT C MACH LEARN	20	11	11	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	MAR	2008	71	7-9					1230	1237		10.1016/j.neucom.2007.11.023		8	Computer Science, Artificial Intelligence	Computer Science	292AQ	WOS:000255239200012	
J	Suresh, S; Sundararajan, N; Saratchandran, P				Suresh, S.; Sundararajan, N.; Saratchandran, P.			A sequential multi-category classifier using radial basis function networks	NEUROCOMPUTING			English	Article						RBF network; hinge loss function; sequential learning; multi-category classification; decoupled extended Kalman filter	NEURAL-NETWORKS; LEARNING ALGORITHM; RBF NETWORKS	This paper presents a new sequential multi-category classifier using radial basis function (SMC-RBF) network for real-world classification problems. The classification algorithm processes the training data one by one and builds the RBF network starting with zero hidden neuron. The growth criterion uses the misclassification error, the approximation error to the true decision boundary and a distance measure between the current sample and the nearest neuron belonging to the same class. SMC-RBF uses the hinge loss function (instead of the mean square loss function) for a more accurate estimate of the posterior probability. For network parameter updates, a decoupled extended Kalman filter is used to reduce the computational overhead. Performance of the proposed algorithm is evaluated using three benchmark problems, viz., image segmentation, vehicle and glass from the UCI machine learning repository. In addition, performance comparison has also been done on two real-world problems in the areas of remote sensing and bio-informatics. The performance of the proposed SMC-RBF classifier is also compared with the other RBF sequential learning algorithms like MRAN, GAP-RBFN, OS-ELM and the well-known batch classification algorithm SM The results indicate that SMC-RBF produces a higher classification accuracy with a more compact network. Also, the study indicates that using a function approximation algorithm for classification problems may not work well when the classes are not well separated and the training data is not uniformly distributed among the classes. (c) 2007 Elsevier B.V. All rights reserved.	[Suresh, S.; Sundararajan, N.; Saratchandran, P.] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore, Singapore	Suresh, S (reprint author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore, Singapore.	ssundaram@ntu.edu.sg	Sundaram, Suresh/A-4026-2010				Anders U, 1999, NEURAL NETWORKS, V12, P309, DOI 10.1016/S0893-6080(98)00117-8; Blake C. L., 1998, UCI REPOSITORY MACHI; Chakravarthy SV, 1996, IEEE T NEURAL NETWOR, V7, P1250, DOI 10.1109/72.536318; Chang CC, 2003, LIBSVM LIB SUPPORT V; Cristianini N., 2000, INTRO SUPPORT VECTOR; FUKUSHIMA K, 1991, IEEE T NEURAL NETWOR, V2, P355, DOI 10.1109/72.97912; Huang GB, 2004, IEEE T SYST MAN CY B, V34, P2284, DOI 10.1109/TSMCB.2004.834428; HWANG JN, 1997, IEEE SIGNAL PROCESSI, V14, P28; JOHN JR, 2000, REMOTE SENSING ENV A; KADIRKAMANATHAN V, 1993, NEURAL COMPUT, V5, P954, DOI 10.1162/neco.1993.5.6.954; Kavzoglu T, 2003, INT J REMOTE SENS, V24, P4907, DOI 10.1080/0143116031000114851; Lee C, 1997, IEEE T NEURAL NETWOR, V8, P75; Leonardis A, 1998, NEURAL NETWORKS, V11, P963, DOI 10.1016/S0893-6080(98)00051-3; Liang NY, 2006, IEEE T NEURAL NETWOR, V17, P1411, DOI 10.1109/TNN.2006.880583; Lu YW, 1998, IEEE T NEURAL NETWOR, V9, P308, DOI 10.1109/72.661125; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; MUSAVI MT, 1992, NEURAL NETWORKS, V5, P595, DOI 10.1016/S0893-6080(05)80038-3; Park J., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.246; Platt J., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.213; PUSKORIUS GV, 1994, IEEE T NEURAL NETWOR, V5, P279, DOI 10.1109/72.279191; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Salzberg SL, 1997, DATA MIN KNOWL DISC, V1, P317, DOI 10.1023/A:1009752403260; SURESH S, 2006, J AEROSP SCI TECHNOL, V58; SURESH S, 2007, PATTERN ANAL APPL; Yan L., 2000, IEE P-CONTR THEOR AP, V147, P476; Yingwei L., 1997, NEURAL COMPUT, V9, P461, DOI 10.1162/neco.1997.9.2.461; Zhang T, 2004, ANN STAT, V32, P56	27	33	33	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	MAR	2008	71	7-9					1345	1358		10.1016/j.neucom.2007.06.003		14	Computer Science, Artificial Intelligence	Computer Science	292AQ	WOS:000255239200022	
J	Toh, KA				Toh, Kar-Ann			An error-counting network for pattern classification	NEUROCOMPUTING			English	Article						neural networks; pattern classification; discriminant functions; polynomials and machine learning	DISCRIMINANT-ANALYSIS; FEEDFORWARD NETWORKS; NEURAL-NETWORKS	This paper presents a novel quadratic error-counting network for pattern classification. Two computational issues namely, the network learning issue and the classification error-counting issue have been addressed. Essentially, a linear series functional approximation to network structure and a smooth quadratic error-counting cost function were proposed to resolve these two computational issues within a single framework. Our analysis shows that the quadratic error-counting objective can be related to the least-squares-error objective by adjusting the class-specific normalization factors. The binary classification network is subsequently extended to cater for multicategory problems. An extensive empirical evaluation validates the usefulness of proposed method. (c) 2007 Elsevier B.V. All rights reserved.	Yonsei Univ, Sch Elect & Elect Engn, Biometr Engn Res Ctr, Seoul, South Korea	Toh, KA (reprint author), Yonsei Univ, Sch Elect & Elect Engn, Biometr Engn Res Ctr, Seoul, South Korea.	katoh@yonsei.ac.kr					Bishop C.M., 1995, NEURAL NETWORKS PATT; CHURMANN J, 1996, PATTERN CLASSIFICATI; Duda R. O., 2001, PATTERN CLASSIFICATI; Duda R.O, 1973, PATTERN CLASSIFICATI; Gordon G. J., 2002, ADV NEURAL INFORM PR, P577; Hai D. -T., 1978, IEEE T COMPUT, VC-27, P648, DOI 10.1109/TC.1978.1675165; Hastie T, 2001, ELEMENTS STAT LEARNI; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Huang GB, 1998, IEEE T NEURAL NETWOR, V9, P224, DOI 10.1109/72.655045; HUANG GB, 2006, NEUROCOMPUTING, V69; Huang GB, 2000, IEEE T NEURAL NETWOR, V11, P799, DOI 10.1109/72.846750; Huang GB, 2006, IEEE T CIRCUITS-II, V53, P187, DOI 10.1109/TCSII.2005.857540; JUANG BH, 1992, IEEE T SIGNAL PROCES, V40, P3043, DOI 10.1109/78.175747; Lam W, 2002, IEEE T PATTERN ANAL, V24, P1075; Li JY, 2004, MACH LEARN, V54, P99, DOI 10.1023/B:MACH.0000011804.08528.7d; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; Mao KZ, 2002, IEEE T NEURAL NETWOR, V13, P1211, DOI 10.1109/TNN.2002.1031953; Rimer M, 2006, MACH LEARN, V63, P183, DOI 10.1007/s10994-006-6266-6; McCullagh P., 1989, GEN LINEAR MODELS; Newman D. J., 1998, UCI REPOSITORY MACHI; OSMAN H, 1994, IEEE T PATTERN ANAL, V16, P837, DOI 10.1109/34.308481; Osman H, 1997, IEEE T SYST MAN CY B, V27, P488, DOI 10.1109/3477.584955; Ripley B. D, 1996, PATTERN RECOGNITION; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; TOH KA, 2003, INT C IM AN PROC ICI, P626; Toh KA, 2004, IEEE T PATTERN ANAL, V26, P740, DOI 10.1109/TPAMI.2004.3; Toh KA, 2006, MACH LEARN, V65, P273, DOI 10.1007/s10994-006-9455-4; TOH KA, 2006, P 1 KOR JAP JOINT WO, P25; TOH KA, 2006, P 1 IEEE C IND EL AP, P815; Tsujitani M, 2000, IEEE T NEURAL NETWOR, V11, P1394, DOI 10.1109/72.883460; Yang ZR, 2006, IEEE T NEURAL NETWOR, V17, P604, DOI 10.1109/TNN.2006.873282; Zhang GQP, 2000, IEEE T SYST MAN CY C, V30, P451, DOI 10.1109/5326.897072	32	2	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	MAR	2008	71	7-9					1680	1693		10.1016/j.neucom.2007.04.007		14	Computer Science, Artificial Intelligence	Computer Science	292AQ	WOS:000255239200049	
J	Xiang, T; Gong, S				Xiang, Tao; Gong, Shaogang			Spectral clustering with eigenvector selection	PATTERN RECOGNITION			English	Article						spectral clustering; feature selection; unsupervised learning; image segmentation; video behaviour pattern clustering	HIDDEN MARKOV-MODELS; IMAGE SEGMENTATION; LIKELIHOOD; ALGORITHM; TRACKING	The task of discovering natural groupings of input patterns, or clustering, is an important aspect of machine learning and pattern analysis. In this paper, we study the widely used spectral clustering algorithm which clusters data using eigenvectors of a similarity/affinity matrix derived from a data set. In particular, we aim to solve two critical issues in spectral clustering: (1) how to automatically determine the number of clusters, and (2) how to perform effective clustering given noisy and sparse data. An analysis of the characteristics of eigenspace is carried out which shows that (a) not every eigenvectors of a data affinity matrix is informative and relevant for clustering; (b) eigenvector selection is critical because using uninformative/irrelevant eigenvectors could lead to poor clustering results; and (c) the corresponding eigenvalues cannot be used for relevant eigenvector selection given a realistic data set. Motivated by the analysis, a novel spectral clustering algorithm is proposed which differs from previous approaches in that only informative/relevant eigenvectors are employed for determining the number of clusters and performing clustering. The key element of the proposed algorithm is a simple but effective relevance learning method which measures the relevance of an eigenvector according to how well it can separate the data set into different clusters. Our algorithm was evaluated using synthetic data sets as well as real-world data sets generated from two challenging visual learning problems. The results demonstrated that our algorithm is able to estimate the cluster number correctly and reveal natural grouping of the input data/patterns even given sparse and noisy data. (C) 2007 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Univ London, Dept Comp Sci, London E1 4NS, England	Xiang, T (reprint author), Univ London, Dept Comp Sci, London E1 4NS, England.	txiang@dcs.qmul.ac.uk; sgg@dcs.qmul.ac.uk					Biernacki C, 2000, IEEE T PATTERN ANAL, V22, P719, DOI 10.1109/34.865189; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Chung Fan R. K., 1997, CBMS REGIONAL C SERI; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Dy JG, 2003, IEEE T PATTERN ANAL, V25, P373, DOI 10.1109/TPAMI.2003.1182100; FIEDLER M, 1973, CZECH MATH J, V23, P298; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Ghahramani Z., 1998, LECT NOTES ARTIF INT, P168; Gong S., 2003, IEEE INT C COMP VIS; Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800; Ng AY, 2002, ADV NEUR IN, V14, P849; PANUCCIO A, 2002, P JOINT IAPR INT WOR, P734; PORIKLI F, 2002, 6 IEEE INT WORKSH PE; Porikli F., 2004, IEEE C COMP VIS PATT, P114; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Roberts SJ, 1998, IEEE T PATTERN ANAL, V20, P1133, DOI 10.1109/34.730550; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; Smyth P, 1997, ADV NEUR IN, V9, P648; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; WEISS Y, 1999, SEGMENTATION USING E, P975; XIANG T, 2002, BRIT MACH VIS C, P233; Xiang T, 2006, INT J COMPUT VISION, V67, P21, DOI 10.1007/s11263-006-4329-6; XIANG T, 2004, BRIT MACH VIS C; Yu S. X., 2003, ICCV, P313, DOI 10.1109/ICCV.2003.1238361; ZELNIKMANOR L, 2004, SELF TUNING SPECTRAL; ZHONG H, 2004, IEEE C COMP VIS PATT, V2, P819	27	22	28	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	MAR	2008	41	3					1012	1029		10.1016/j.patcog.2007.07.023		18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	237EQ	WOS:000251357100021	
J	Toh, KA; Kim, J; Lee, S				Toh, Kar-Ann; Kim, Jaihie; Lee, Sangyoun			Biometric scores fusion based on total error rate minimization	PATTERN RECOGNITION			English	Article						multimodal biometrics; decision fusion; equal error rate; pattern classification; machine learning	CLASSIFIER FUSION; AUTHENTICATION; RECOGNITION; EXPERTS	This paper addresses the biometric scores fusion problem from the error rate minimization point of view. Comparing to the conventional approach which treats fusion classifier design and performance evaluation as a two-stage process, this work directly optimizes the target performance with respect to fusion classifier design. Based on a smooth approximation to the total error rate of identity verification, a deterministic solution is proposed to solve the fusion optimization problem. The proposed method is applied to a face and iris verification fusion problem addressing the demand for high security in the modem networked society. Our empirical evaluations show promising potential in terms of decision accuracy and computing efficiency. (C) 2007 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Yonsei Univ, Sch Elect & Elect Engn, Biometr Engn Res Ctr, Seoul 120749, South Korea	Toh, KA (reprint author), Yonsei Univ, Sch Elect & Elect Engn, Biometr Engn Res Ctr, 134 Shinchon dong, Seodaemun gu, Seoul 120749, South Korea.	katoh@yonsei.ac.kr					Bae K., 2003, P 4 INT C AUD VID BA, P838; Bishop C.M., 1995, NEURAL NETWORKS PATT; Boser B., 1992, 5 ANN ACM WORKSH COL, P144; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676; Duda R. O., 2001, PATTERN CLASSIFICATI; Gordon G. J., 2002, ADV NEURAL INFORM PR, P577; Hong L., 1999, P IEEE WORKSH AUT ID, P59; HUANG YS, 1995, IEEE T PATTERN ANAL, V17, P90, DOI 10.1109/34.368145; Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012; KIM SK, 2006, P 1 IEEE C IND EL AP, P804; KITTLER J, 2002, P 12 IEEE WORKSH NEU, P3, DOI 10.1109/NNSP.2002.1030012; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kuncheva LI, 2003, PATTERN ANAL APPL, V6, P22, DOI 10.1007/s10044-002-0173-7; Kuncheva LI, 2001, PATTERN RECOGN, V34, P299, DOI 10.1016/S0031-3203(99)00223-X; Li S.Z., 2004, HDB FACE RECOGNITION; Ma J., 2002, OSU SVM CLASSIFIER M; Maio D, 2002, IEEE T PATTERN ANAL, V24, P402, DOI 10.1109/34.990140; McCullagh P., 1989, GEN LINEAR MODELS; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Poh N, 2006, PATTERN RECOGN, V39, P223, DOI 10.1016/j.patcog.2005.06.011; Poh N., 2006, THESIS SWISS FEDERAL; Poh N, 2005, IEEE T SIGNAL PROCES, V53, P4384, DOI 10.1109/TSP.2005.857006; Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5; Ross A., 2005, P SPIE C BIOM TECHN, P196; ROSS AA, 2006, HDB MULTIBIOMETRICS, V6; Scholkopf B., 2002, LEARNING KERNELS SUP; TOH KA, 2003, INT C IM AN PROC ICI, P626; Toh KA, 2004, IEEE T PATTERN ANAL, V26, P740, DOI 10.1109/TPAMI.2004.3; Toh KA, 2004, IEEE T CIRC SYST VID, V14, P224, DOI 10.1109/TCSVT.2003.821974; TOH KA, 2006, P 1 IEEE C IND EL AP, P815; Vapnik VN, 1998, STAT LEARNING THEORY; WADE W. R., 2000, INTRO ANAL	33	18	20	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	MAR	2008	41	3					1066	1082		10.1016/j.patcog.2007.07.020		17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	237EQ	WOS:000251357100025	
J	Li, MQ; Tian, J; Chen, FZ				Li, Minqiang; Tian, Jin; Chen, Fuzan			Improving multiclass pattern recognition with a co-evolutionary RBFNN	PATTERN RECOGNITION LETTERS			English	Article						RBFNN; co-operative co-evolutionary algorithms; K-means clustering; multiclass classification	NEURAL-NETWORKS; TEXT CATEGORIZATION; GENETIC ALGORITHM; DECISION TREES; CLASSIFICATION; CLASSIFIERS; ENSEMBLES	A new hybrid scheme of the radial basis function neural network (RBFNN) model and the co-operative co-evolutionary algorithm (Co-CEA) is presented for multiclass classification tasks. This combination of the conventional RBFNN training algorithm and the proposed Co-CEA enforces the strength of both methods. First, the decaying radius selection clustering (DRSC) method is used to obtain the initial hidden nodes of the RBFNN model, which are further partitioned into modules of hidden nodes by the K-means method. Then, subpopulations are initialized on modules, and the Co-CEA evolves all subpopulations to find the optimal RBFNN structural parameters. Matrix-form mixed encoding and special crossover and mutation operators are designed. Finally, the proposed algorithm is tested on 14 real-world classification problems from the UCI machine learning repository, and experimental results illustrate that the algorithm is able to produce RBFNN models that have better prediction accuracies and simpler structures than conventional algorithms of classification. (c) 2007 Elsevier B.V. All rights reserved.	[Li, Minqiang; Tian, Jin; Chen, Fuzan] Tianjin Univ, Sch Management, Tianjin 300072, Peoples R China	Li, MQ (reprint author), Tianjin Univ, Sch Management, Tianjin 300072, Peoples R China.	mqli@tju.edu.cn; jtian_tju@yahoo.com.cn; fzchen@tju.edu.cn					ANNALISA A, 2004, P 21 INT C MACH LEAR, V69, P33; ASIM RSG, 1995, NEURAL NETWORK, V8, P179; Barreto AMS, 2006, NEUROCOMPUTING, V69, P2041, DOI 10.1016/j.neucom.2005.10.004; BERTHOLD MR, 1995, ADV NEURAL INFORM PO, V7, P12; Blanco A, 2001, NEURAL NETWORKS, V14, P93, DOI 10.1016/S0893-6080(00)00081-2; Cantu-Paz E, 2003, IEEE T EVOLUT COMPUT, V7, P54, DOI 10.1109/TEVC.2002.806857; Casasent D, 2003, NEURAL NETWORKS, V16, P529, DOI 10.1016/S0893-6080(03)00086-8; Chen S, 1999, IEEE T NEURAL NETWOR, V10, P1239, DOI 10.1109/72.788663; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Draghici S, 2001, NEURAL NETWORKS, V14, P527, DOI 10.1016/S0893-6080(01)00040-5; Eibl G, 2005, J MACH LEARN RES, V6, P189; EKLUND WP, 1999, P SPIE DAT MIN KNOWL, V3695, P39; ELISSEFF A, 2002, ADV NEURAL INFORM PR, V14, P81; ERIKSSON R, 1997, P 3 INT C ART NEUR N, P83; Frank E, 1998, MACH LEARN, V32, P63, DOI 10.1023/A:1007421302149; FRANK E, 1998, P 5 INT C MACH LEARN, P44; Frank E, 2006, LECT NOTES ARTIF INT, V3918, P97; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y., 1999, P 16 INT C MACH LEAR, P124; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Fu XJ, 2003, IEEE T SYST MAN CY B, V33, P399, DOI 10.1109/TSMCB.2003.810911; Furnkranz J, 2002, J MACH LEARN RES, V2, P721, DOI 10.1162/153244302320884605; GAO DQ, 2002, P 2002 INT JOINT C N, V1, P846; Garcia-Pedrajas N, 2006, IEEE T PATTERN ANAL, V28, P1001, DOI 10.1109/TPAMI.2006.123; GARCIAPEDRAJAS N, 2006, EUR S ART NEUR NETW, P437; Garcia-Pedrajas N, 2005, IEEE T EVOLUT COMPUT, V9, P271, DOI 10.1109/TEVC.2005.844158; George HJ, 1995, P 11 C UNC ART INT, P338; IORIO A, 2002, P 7 C PAR PRBL SOLV, V2439, P247, DOI 10.1007/3-540-45712-7_24; JING Y, 2005, P 22 INT C MACH LEAR, V119, P369; Kazawa H., 2005, ADV NEURAL INFORM PR, V17, P649; Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493; Kim HC, 2006, IEEE T PATTERN ANAL, V28, P1948; KOHAVI R, 1997, P EUR C MACH LEARN; Leonardis A, 1998, NEURAL NETWORKS, V11, P963, DOI 10.1016/S0893-6080(98)00051-3; Li Minqiang, 2002, BASIC THEORIES APPL; Liu Y, 2000, IEEE T EVOLUT COMPUT, V4, P380; Mccallum A., 1999, AAAI 99 WORKSH TEXT; Merz CJ, 1999, MACH LEARN, V36, P33, DOI 10.1023/A:1007559205422; METCHELL TM, 2003, MACHINE LEARNING; OYANG YJ, 2002, P 9 INT C NEUR INF P, P1021; PLATT J, 1999, SEQUENTIAL MINIMAL O, P185; POTTER M, 1998, P 5 INT C PAR PROBL, V1498, P530, DOI 10.1007/BFb0056895; Potter MA, 2000, EVOL COMPUT, V8, P1, DOI 10.1162/106365600568086; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; TIAN L, 2006, J SYSTEM ENG, V21, P163; Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849; Xu Y, 2006, PATTERN RECOGN, V39, P1026, DOI 10.1016/j.patcog.2005.10.029; Yang J., 1999, INTELL DATA ANAL, V3, P55, DOI 10.1016/S1088-467X(99)00005-0; Zhang ML, 2006, IEEE T KNOWL DATA EN, V18, P1338; Zhao QF, 1996, IEEE T NEURAL NETWOR, V7, P762; Zhao Wei-xiang, 2002, Journal of Software, V13; Zhu QM, 1999, NEURAL NETWORKS, V12, P527, DOI 10.1016/S0893-6080(98)00146-4; [Anonymous], 1999, P 6 INT C NEUR INF P, P514	55	9	12	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	MAR 1	2008	29	4					392	406		10.1016/j.patrec.2007.10.019		15	Computer Science, Artificial Intelligence	Computer Science	267OQ	WOS:000253518900002	
J	Yovel, Y; Franz, MO; Stilz, P; Schnitzler, HU				Yovel, Yossi; Franz, Matthias Otto; Stilz, Peter; Schnitzler, Hans-Ulrich			Plant classification from bat-like echolocation signals	PLOS COMPUTATIONAL BIOLOGY			English	Article							SONAR; OBJECT; RECOGNITION; OLFACTION; BEHAVIOR; TARGETS; FRUIT	Classification of plants according to their echoes is an elementary component of bat behavior that plays an important role in spatial orientation and food acquisition. Vegetation echoes are, however, highly complex stochastic signals: from an acoustical point of view, a plant can be thought of as a three-dimensional array of leaves reflecting the emitted bat call. The received echo is therefore a superposition of many reflections. In this work we suggest that the classification of these echoes might not be such a troublesome routine for bats as formerly thought. We present a rather simple approach to classifying signals from a large database of plant echoes that were created by ensonifying plants with a frequency-modulated bat-like ultrasonic pulse. Our algorithm uses the spectrogram of a single echo from which it only uses features that are undoubtedly accessible to bats. We used a standard machine learning algorithm ( SVM) to automatically extract suitable linear combinations of time and frequency cues from the spectrograms such that classification with high accuracy is enabled. This demonstrates that ultrasonic echoes are highly informative about the species membership of an ensonified plant, and that this information can be extracted with rather simple, biologically plausible analysis. Thus, our findings provide a new explanatory basis for the poorly understood observed abilities of bats in classifying vegetation and other complex objects.	[Yovel, Yossi; Stilz, Peter; Schnitzler, Hans-Ulrich] Univ Tubingen, Inst Zool, Tubingen, Germany; [Franz, Matthias Otto] Max Planck Inst Biol Cybernet, Tubingen, Germany	Yovel, Y (reprint author), Univ Tubingen, Inst Zool, Tubingen, Germany.	yossiyovel@hotmail.com	Robertson, Linda/D-1157-2010; Raleva, Sofiya/A-3114-2011; Pillay, Sesharam/E-8068-2010				Cristianini N., 2000, INTRO SUPPORT VECTOR, P93; DROR IE, 1995, NEURAL NETWORKS, V8, P149, DOI 10.1016/0893-6080(94)00057-S; Fergus R., 2003, P IEEE C COMP VIS PA; Firzlaff U, 2007, PLOS BIOL, V5, P1174, DOI 10.1371/journal.pbio.0050100; Ghose K, 2003, J ACOUST SOC AM, V114, P1120, DOI 10.1121/1.1589754; Graf ABA, 2006, NEURAL COMPUT, V18, P143, DOI 10.1162/089976606774841611; Griffiths TD, 2004, NAT REV NEUROSCI, V5, P887, DOI 10.1038/nrn1538; Grunwald JE, 2004, P NATL ACAD SCI USA, V101, P5670, DOI 10.1073/pnas.0308029101; Kalko EKV, 1998, FUNCT ECOL, V12, P364, DOI 10.1046/j.1365-2435.1998.00198.x; Kao G, 2000, INT J ROBOT RES, V19, P895, DOI 10.1177/02783640022067850; Kuc R, 1997, J ACOUST SOC AM, V102, P689, DOI 10.1121/1.419658; McKerrow P, 2001, IEEE SENS J, V1, P245, DOI 10.1109/7361.983464; Moss C.F., 1995, HEARING BATS, P87; Muller R, 2000, J ACOUST SOC AM, V108, P836, DOI 10.1121/1.429617; Muller R, 2003, NETWORK-COMP NEURAL, V14, P595, DOI 10.1088/0954-898X/14/3/311; Nabout A., 1994, Proceedings of the IEEE Southwest Symposium on Image Analysis and Interpretation, DOI 10.1109/IAI.1994.336686; OSWAL J, 1988, ANIMAL SONAR SYSTEMS, P413; PRESS WH, 2002, NUMERICAL RECIPES C, P547; Schaub A, 2007, J COMP PHYSIOL A, V193, P1185, DOI 10.1007/s00359-007-0269-z; Schaub A, 2007, BEHAV ECOL SOCIOBIOL, V61, P513, DOI 10.1007/s00265-006-0279-9; SCHMIDT S, 1992, J ACOUST SOC AM, V91, P2203, DOI 10.1121/1.403654; Schnitzler HU, 2003, TRENDS ECOL EVOL, V18, P386, DOI 10.1016/S0169-5347(03)00185-X; SCHOLKOPF B, 2002, LEARNING KERNELS SUP, P189; Simmons JA, 1998, P NATL ACAD SCI USA, V95, P12647, DOI 10.1073/pnas.95.21.12647; SKOLNIK MI, 1970, RADAR HDB, P50; Thies W, 1998, BEHAV ECOL SOCIOBIOL, V42, P397, DOI 10.1007/s002650050454; von Helversen D, 2004, J COMP PHYSIOL A, V190, P515, DOI 10.1007/s00359-004-0492-9; von Helversen D, 1999, NATURE, V398, P759, DOI 10.1038/19648; von Helversen D, 2003, J COMP PHYSIOL A, V189, P327, DOI 10.1007/s00359-003-0405-3; WICHMANN FA, 2005, ADV NEURAL INFORM PR, P1489	30	20	20	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	185 BERRY ST, STE 1300, SAN FRANCISCO, CA 94107 USA	1553-734X		PLOS COMPUT BIOL	PLoS Comput. Biol.	MAR	2008	4	3							e1000032	10.1371/journal.pcbi.1000032		13	Biochemical Research Methods; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Mathematical & Computational Biology	294MM	WOS:000255410100015	
J	Ahmed, WM; Leavesley, SJ; Rajwa, B; Ayyaz, MN; Ghafoor, A; Robinson, JP				Ahmed, Wamiq Manzoor; Leavesley, Silas J.; Rajwa, Bartek; Ayyaz, Muhammad Naeem; Ghafoor, Arif; Robinson, J. Paul			State of the art in information extraction and quantitative analysis for multimodality biomolecular imaging	PROCEEDINGS OF THE IEEE			English	Review						biomolecular imaging; image analysis; information extraction; quantitative imaging	GREEN-FLUORESCENT PROTEIN; IN-VIVO; QUANTUM DOTS; REPORTER GENE; LIVE CELLS; COLOCALIZATION ANALYSIS; AUTOMATIC SEGMENTATION; SUBCELLULAR LOCATION; LIGHT-MICROSCOPY; CONFOCAL IMAGES	Rapid advances in optical instrumentation, highspeed cameras, and fluorescent probes have spurred tremendous growth in the volume of biomolecular imaging data. Various optical imaging modalities are used for probing biological systems in vivo and in vitro. These include traditional two-dimensional imaging, three-dimensional confocal imaging, time-lapse imaging, and multispectral imaging. Many applications require a combination of these imaging modalities, which gives rise to huge data sets. However, lack of powerful information extraction and quantitative analysis tools poses a major hindrance to exploiting the full potential of the information content of these data. In particular, automated extraction Of I semantic information from multimodality imaging data, crucial, for understanding biological processes, poses unique challenges. Information extraction from large sets of biomolecular imaging data requires modeling at multiple levels of detail to allow not only quantitative analysis but also interpretation and extraction of high-level semantic information. in this paper, we survey the state of the art in the area of information extraction and automated analysis tools for in vivo and in vitro biomolecular imaging. The modeling and knowledge extraction for these data require sophisticated image processing and machine learning techniques, as well as formalisms for information extraction and knowledge management. Development of such tools has the potential to significantly improve biological discovery and drug development processes.	[Ahmed, Wamiq Manzoor; Ayyaz, Muhammad Naeem; Ghafoor, Arif] Sch Elect & Comp Engn, W Lafayette, IN 47907 USA; [Ahmed, Wamiq Manzoor; Leavesley, Silas J.; Rajwa, Bartek; Robinson, J. Paul] Purdue Univ, Cytometry Lab, W Lafayette, IN 47907 USA; [Leavesley, Silas J.; Robinson, J. Paul] Weldon Sch Biomed Engn, W Lafayette, IN 47907 USA; [Rajwa, Bartek; Robinson, J. Paul] Bindley Biosci Ctr, W Lafayette, IN 47907 USA; [Robinson, J. Paul] Sch Vet Med, W Lafayette, IN USA	Ahmed, WM (reprint author), Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.		Rajwa, Bartek/B-3169-2009; Robinson, Joseph/K-8492-2012	Rajwa, Bartek/0000-0001-7540-8236; 			Ahmed WM, 2007, PROCEEDINGS OF THE 7TH IEEE INTERNATIONAL SYMPOSIUM ON BIOINFORMATICS AND BIOENGINEERING, VOLS I AND II, P1113; Ahmed WM, 2007, IEEE MULTIMEDIA, V14, P52, DOI 10.1109/MMUL.2007.77; AHMED WM, IN PRESS IEEE T INF; AHMED WM, 2007, INT J SEMANTIC COMPU, V1, P67, DOI 10.1142/S1793351X07000032; Alivisatos AP, 2005, ANNU REV BIOMED ENG, V7, P55, DOI 10.1146/annurev.bioeng.7.060804.100432; Al-Kofahi O, 2006, IEEE T BIO-MED ENG, V53, P1109, DOI 10.1109/TBME.2006.873565; Aubert-Broche B, 2006, IEEE T MED IMAGING, V25, P1410, DOI 10.1109/TMI.2006.883453; BAMFORD P, 2003, P 2003 INT C IM PROC, V2; BANADA PP, 2006, BIOSENS BIOELECTRON; Bayraktar B, 2006, J BIOMED OPT, V11, DOI 10.1117/1.2203987; Benaron DA, 2002, CANCER METAST REV, V21, P45, DOI 10.1023/A:1020131208786; Biehl L, 2002, COMPUT GEOSCI-UK, V28, P1153, DOI 10.1016/S0098-3004(02)00033-X; Bolte S, 2006, J MICROSC-OXFORD, V224, P213, DOI 10.1111/j.1365-2818.2006.01706.x; Bremer C, 2003, EUR RADIOL, V13, P231, DOI 10.1007/s00330-002-1610-0; Brown L. G., 1992, ACM COMPUT SURV, V24, P325, DOI DOI 10.1145/146370.146374; Chan WCW, 2002, CURR OPIN BIOTECH, V13, P40, DOI 10.1016/S0958-1669(02)00282-3; Chan WCW, 1998, SCIENCE, V281, P2016, DOI 10.1126/science.281.5385.2016; Chang C.-I., 2003, HYPERSPECTRAL IMAGIN; Chaudhari AJ, 2005, PHYS MED BIOL, V50, P5421, DOI 10.1088/0031-9155/50/23/001; Cheezum MK, 2001, BIOPHYS J, V81, P2378; Chen X, 2005, J BIOMED BIOTECHNOL, P87, DOI 10.1155/JBB.2005.87; CHEN X, 2006, BIOMED ENG IEEE T, V53, P762; Chudakov DM, 2004, NAT BIOTECHNOL, V22, P1435, DOI 10.1038/nbt1025; Crum WR, 2006, IEEE T MED IMAGING, V25, P1451, DOI 10.1109/TMI.2006.880587; DIKMEN ZG, 2005, TURK J MED SCI, V35, P65; Dima A, 2002, IEEE T IMAGE PROCESS, V11, P790, DOI 10.1109/TIP.2002.800888; Eden E, 2005, IEEE T MED IMAGING, V24, P1011, DOI 10.1109/TMI.2005.851759; Edinger Matthias, 1999, Neoplasia (New York), V1, P303, DOI 10.1038/sj.neo.7900048; FERNANDEZGONZAL.R, 2005, IEEE T IMAGE PROCESS, V14; Gao XH, 2004, NAT BIOTECHNOL, V22, P969, DOI 10.1038/nbt994; Garrido A, 2000, PATTERN RECOGN, V33, P821, DOI 10.1016/S0031-3203(99)00091-6; Gerstner AOH, 2004, CYTOM PART A, V59A, P210, DOI 10.1002/cyto.a.20054; Giepmans BNG, 2006, SCIENCE, V312, P217, DOI 10.1126/science.1124618; Giuliano KA, 1997, J BIOMOL SCREEN, V2, P249, DOI 10.1177/108705719700200410; GOLDBERG IG, 2006, OPEN MICROSCOPY ENV; Griffin BA, 1998, SCIENCE, V281, P269, DOI 10.1126/science.281.5374.269; HARDER N, 2006, P IEEE INT S BIOM IM, P1016; HERSCHMAN HR, 2003, MOL IMAGING LOOKING; Hiruma T, 2005, P IEEE, V93, P829, DOI 10.1109/JPROC.2005.844616; HU M, 2004, P 2004 INT C IM PROC, V4; Huang K, 2004, J BIOMED OPT, V9, P893, DOI 10.1117/1.1779233; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Jones TR, 2005, LECT NOTES COMPUT SC, V3765, P535; JONES TR, 2007, P WORKSH MICR IM AN, P65; KAMENTSKY LA, 1991, CYTOMETRY, V12, P381, DOI 10.1002/cyto.990120502; Keshava N, 2002, IEEE SIGNAL PROC MAG, V19, P44, DOI 10.1109/79.974727; Lachmanovich E, 2003, J MICROSC-OXFORD, V212, P122, DOI 10.1046/j.1365-2818.2003.01239.x; Landgrebe D, 2002, IEEE SIGNAL PROC MAG, V19, P17, DOI 10.1109/79.974718; Li KCP, 2004, IEEE ENG MED BIOL, V23, P26, DOI 10.1109/MEMB.2004.1337946; Lin G, 2003, CYTOM PART A, V56A, P23, DOI 10.1002/cyto.a.10079; Liotta L, 2000, NAT REV GENET, V1, P48, DOI 10.1038/35049567; Adams SR, 2002, J AM CHEM SOC, V124, P6063, DOI 10.1021/ja017687n; Luck BL, 2005, IEEE T IMAGE PROCESS, V14, P1265, DOI 10.1109/TIP.2005.852460; Lukyanov KA, 2005, NAT REV MOL CELL BIO, V6, P885, DOI 10.1038/nrm1741; Mahmood U, 2003, MOL CANCER THER, V2, P489; Malpica N, 1997, CYTOMETRY, V28, P289, DOI 10.1002/(SICI)1097-0320(19970801)28:4<289::AID-CYTO3>3.0.CO;2-7; MANSFIELD JR, 2005, P OPT SOC AM; Mansfield JR, 2005, J BIOMED OPT, V10, DOI 10.1117/1.2032458; Matz MV, 1999, NAT BIOTECHNOL, V17, P969, DOI 10.1038/13657; McNally JG, 1999, METHODS, V19, P373, DOI 10.1006/meth.1999.0873; Medintz IL, 2005, NAT MATER, V4, P435, DOI 10.1038/nmat1390; Meijering E, 2006, IEEE SIGNAL PROC MAG, V23, P46, DOI 10.1109/MSP.2006.1628877; Michalet X, 2005, SCIENCE, V307, P538, DOI 10.1126/science.1104274; Milstein C, 1999, BIOESSAYS, V21, P966, DOI 10.1002/(SICI)1521-1878(199911)21:11<966::AID-BIES9>3.0.CO;2-Z; Murphy RF, 2005, BIOCHEM SOC T, V33, P535; NEUMANN B, 2006, METHODS, V3, P385; Nguyen AW, 2005, NAT BIOTECHNOL, V23, P355, DOI 10.1038/nbt1066; Ntziachristos Vasilis, 2002, Nature Medicine, V8, P757, DOI 10.1038/nm729; Panchuk-Voloshina N, 1999, J HISTOCHEM CYTOCHEM, V47, P1179; PARK B, 2004, P ASAE ANN INT M; Park JM, 2005, P IEEE, V93, P771, DOI 10.1109/JPROC.2005.844263; Patterson GH, 2002, SCIENCE, V297, P1873, DOI 10.1126/science.1074952; Penarrubia PG, 2005, IEEE T IMAGE PROCESS, V14, P1151, DOI 10.1109/TIP.2005.851699; PERLMAN ZE, 2004, MULTIDIMENSIONAL DRU; Pincus Z, 2007, J MICROSC-OXFORD, V227, P140, DOI 10.1111/j.1365-2818.2007.01799.x; Ploem J S, 1967, Z Wiss Mikrosk, V68, P129; Ponomarev V, 2004, EUR J NUCL MED MOL I, V31, P740, DOI 10.1007/s00259-003-1441-5; PRASHER DC, 1992, GENE, V111, P229, DOI 10.1016/0378-1119(92)90691-H; Rausch O, 2006, CURR OPIN CHEM BIOL, V10, P316, DOI 10.1016/j.cbpa.2006.06.004; Ray N, 2002, IEEE T MED IMAGING, V21, P1222, DOI 10.1109/TMI.2002.806291; Ray P, 2003, CANCER RES, V63, P1160; Rizzo MA, 2004, NAT BIOTECHNOL, V22, P445, DOI 10.1038/nbt945; Schwartzkopf WC, 2005, IEEE T MED IMAGING, V24, P1593, DOI 10.1109/TMI.2005.859207; Shaner NC, 2005, NAT METHODS, V2, P905, DOI 10.1038/NMETH819; Shaner NC, 2004, NAT BIOTECHNOL, V22, P1567, DOI 10.1038/nbt1037; Shapiro H.M., 2003, PRACTICAL FLOW CYTOM; Shaw G, 2002, IEEE SIGNAL PROC MAG, V19, P12, DOI 10.1109/79.974715; Shimomura O, 2005, J Microsc, V217, P1; Sonnichsen B, 2005, NATURE, V434, P462, DOI 10.1038/nature03353; Stephens DJ, 2003, SCIENCE, V300, P82, DOI 10.1126/science.1082160; SWEDLOW J, BIOTECHNIQUES, P1076; Swedlow JR, 2003, SCIENCE, V300, P100, DOI 10.1126/science.1082602; TANAKA M, 2005, CIRCULATION, V112, P1105; Tang Michelle L Y, 2004, Anesth Prog, V51, P2; Tarnok A, 2002, CYTOMETRY, V50, P133, DOI 10.1002/cyto.10099; Thorne SH, 2005, P IEEE, V93, P750, DOI 10.1109/JPROC.2005.844261; Tsagkatakis I, 2001, ANAL CHEM, V73, P315, DOI 10.1021/ac000832f; Tsien RY, 1998, ANNU REV BIOCHEM, V67, P509, DOI 10.1146/annurev.biochem.67.1.509; Vila-Frances J, 2006, REV SCI INSTRUM, V77, DOI 10.1063/1.2221542; Waggoner A, 2006, CURR OPIN CHEM BIOL, V10, P62, DOI 10.1016/j.cbpa.2006.01.005; Wahlby C, 2004, J MICROSC-OXFORD, V215, P67, DOI 10.1111/j.0022-2720.2004.01338.x; Wang L, 2004, P NATL ACAD SCI USA, V101, P16745, DOI 10.1073/pnas.0407752101; Wang XL, 2003, BLOOD, V102, P3478, DOI 10.1182/blood-2003-05-1432; Wang Y, 2006, PROC SPIE, V6343, DOI 10.1117/12.707719; WEISSLEDER R, 1999, MOL IMAGING EXPLORIN; Weissleder R, 2006, SCIENCE, V312, P1168, DOI 10.1126/science.1125949; Weissleder R, 2002, NAT REV CANCER, V2, P11, DOI 10.1038/nrc701; Wu JC, 2002, CIRCULATION, V105, P1631, DOI 10.1161/01.CIR.0000014984.95520.AD; Yang M, 2000, P NATL ACAD SCI USA, V97, P1206, DOI 10.1073/pnas.97.3.1206; Zacharias DA, 2002, SCIENCE, V296, P913, DOI 10.1126/science.1068539; Zapata-Hommer O, 2003, BMC BIOTECHNOL, V3, DOI 10.1186/1472-6750-3-5; Zhou XB, 2006, IEEE SIGNAL PROC MAG, V23, P170; Zhou XB, 2006, IEEE SIGNAL PROC MAG, V23, P63; Zimmer C, 2002, IEEE T MED IMAGING, V21, P1212, DOI [10.1109/TMI.2002.806292, 10.1109/TMI.2002.0806292]; Zimmer C, 2006, IEEE SIGNAL PROC MAG, V23, P54, DOI 10.1109/MSP.2006.1628878; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9; *CAMBR RES INSTR I, 2007, MAESTR VIV IM SYST; *CAR HLTH, 2007, KODAK IV IM SYST FX; *GE HEALTHC, 2007, EXPLORE OPT PRECL IM; *INDEC BIOSYSTEMS, 2007, FLUORVIVO VIV FLUOR; *XEN, 2007, IVIS IM SYST 3D SER	122	5	6	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9219		P IEEE	Proc. IEEE	MAR	2008	96	3					512	531		10.1109/JPROC.2007.913556		20	Engineering, Electrical & Electronic	Engineering	264PB	WOS:000253299600011	
J	Gromiha, MM; Suresh, MX				Gromiha, M. Michael; Suresh, M. Xavier			Discrimination of mesophilic and thermophilic proteins using machine learning algorithms	PROTEINS-STRUCTURE FUNCTION AND BIOINFORMATICS			English	Article							OUTER-MEMBRANE PROTEINS; DNA-BINDING PROTEINS; THERMAL-STABILITY; THERMOSTABILITY; SEQUENCE; PREDICTION; ACCURACY	Discriminating thermophilic proteins from their mesophilic counterparts is a challenging task and it would help to design stable proteins. In this work, we have systematically analyzed the amino acid compositions of 3075 mesophilic and 1609 thermophilic proteins belonging to 9 and 15 families, respectively. We found that the charged residues Lys, Arg, and Glu as well as the hydrophobic residues, Val and Ile have higher occurrence in thermophiles than mesophiles. Further, we have analyzed the performance of different methods, based on Bayes rules, logistic functions, neural networks, support vector machines, decision trees and so forth for discriminating mesophilic and thermophilic proteins. We found that most of the machine learning techniques discriminate these classes of proteins with similar accuracy. The neural network-based method could discriminate the thermophiles from mesophiles at the five-fold cross-validation accuracy of 89% in a dataset of 4684 proteins. Moreover, this method is tested with 325 mesophiles in Xylella fastidosa and 382 thermophiles in Aquifex aeolicus and it could successfully discriminate them with the accuracy of 91%. These accuracy levels are better than other methods in the literature and we suggest that this method could be effectively used to discriminate mesophilic and thermophilic proteins.	[Gromiha, M. Michael; Suresh, M. Xavier] Natl Inst Adv Ind Sci & Technol, Computat Biol Res Ctr, Koto Ku, Tokyo 1350064, Japan	Gromiha, MM (reprint author), Natl Inst Adv Ind Sci & Technol, Computat Biol Res Ctr, Koto Ku, AIST Tokyo Waterfront Bio-IT Res Bldg,2-42 Aomi, Tokyo 1350064, Japan.	michael-gromiha@aist.go.jp					Ahmad S, 2004, BIOINFORMATICS, V20, P477, DOI 10.1093/bioinformatics/btg432; Berezovsky IN, 2007, PLOS COMPUT BIOL, V3, P498, DOI 10.1371/journal.pcbi.0030052; Bhardwaj N, 2005, NUCLEIC ACIDS RES, V33, P6486, DOI 10.1093/nar/gki949; Chakravarty S, 2002, BIOCHEMISTRY-US, V41, P8152, DOI 10.1021/bi025523t; Ding YR, 2004, FEBS LETT, V569, P284, DOI 10.1016/j.febslet.2004.06.009; Dominy BN, 2004, PROTEINS, V57, P128, DOI 10.1002/prot.20190; Fukuchi S, 2001, J MOL BIOL, V309, P835, DOI 10.1006/jmbi.2001.4718; Das Rajdeep, 2000, Functional and Integrative Genomics, V1, P76, DOI 10.1007/s101420000003; Gromiha MM, 2002, PREP BIOCHEM BIOTECH, V32, P355, DOI 10.1081/PB-120015459; Gromiha MM, 1999, BIOPHYS CHEM, V82, P51, DOI 10.1016/S0301-4622(99)00103-9; Gromiha MM, 2005, BIOINFORMATICS, V21, P961, DOI 10.1093/bioinformatics/bti126; Gromiha MM, 2004, PROG BIOPHYS MOL BIO, V86, P235, DOI 10.1016/j.pbiomolbio.2003.09.003; Gromiha MM, 2001, BIOPHYS CHEM, V91, P71, DOI 10.1016/S0301-4622(01)00154-5; Gromiha MM, 2006, PROTEINS, V63, P1031, DOI 10.1002/prot.20929; Gromiha MM, 2005, COMPUT BIOL CHEM, V29, P135, DOI 10.1016/j.compbiolchem.2005.02.006; Hasegawa J, 2000, J BIOL CHEM, V275, P37824, DOI 10.1074/jbc.M005861200; Holm L, 1998, BIOINFORMATICS, V14, P423, DOI 10.1093/bioinformatics/14.5.423; Ibrahim BS, 2004, BIOCHEM BIOPH RES CO, V325, P1082, DOI 10.1016/j.bbrc.2004.10.128; Jaenicke R, 1998, CURR OPIN STRUC BIOL, V8, P738, DOI 10.1016/S0959-440X(98)80094-8; Kannan N, 2000, PROTEIN ENG, V13, P753, DOI 10.1093/protein/13.11.753; Kumar S, 2001, BIOCHEMISTRY-US, V40, P14152, DOI 10.1021/bi0106383; Kumar S, 2001, CELL MOL LIFE SCI, V58, P1216, DOI 10.1007/PL00000935; Kumar S, 2000, PROTEIN ENG, V13, P179, DOI 10.1093/protein/13.3.179; Ladenstein R, 1998, Adv Biochem Eng Biotechnol, V61, P37; Li WZ, 2001, BIOINFORMATICS, V17, P282, DOI 10.1093/bioinformatics/17.3.282; Liang HK, 2005, PROTEINS, V59, P58, DOI 10.1002/prot.20386; Razvi A, 2006, PROTEIN SCI, V15, P1569, DOI 10.1110/ps.062130306; ROST B, 1993, J MOL BIOL, V232, P584, DOI 10.1006/jmbi.1993.1413; Sadeghi M, 2006, BIOPHYS CHEM, V119, P256, DOI 10.1016/j.bpc.2005.09.018; Saha S, 2007, SILICO BIOL, V7, P0025; Saraboji K, 2005, INT J BIOL MACROMOL, V35, P211, DOI 10.1016/j.ijbiomac.2005.02.003; Szilagyi A, 2000, STRUCTURE, V8, P493, DOI 10.1016/S0969-2126(00)00133-7; Witten I. H., 2005, DATA MINING PRACTICA; Xiao L, 1999, J MOL BIOL, V289, P1435, DOI 10.1006/jmbi.1999.2810; Yano JK, 2003, CURR OPIN BIOTECH, V14, P360, DOI 10.1016/S0958-1669(03)00075-2; Yu XJ, 2006, J THEOR BIOL, V240, P175, DOI 10.1016/j.jtbi.2005.09.018; Zhang GY, 2006, PROCESS BIOCHEM, V41, P1792, DOI 10.1016/j.procbio.2006.03.026	37	30	33	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0887-3585		PROTEINS	Proteins	MAR	2008	70	4					1274	1279		10.1002/prot.21616		6	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	268GN	WOS:000253567400018	
J	Martin, O; Schomburg, D				Martin, Oliver; Schomburg, Dietmar			Efficient comprehensive scoring of docked protein complexes using probabilistic support vector machines	PROTEINS-STRUCTURE FUNCTION AND BIOINFORMATICS			English	Article						unbound-unbound protein-protein docking; FFT docking; reranking; supervised machine learning; scoring function	FAVORABLE BINDING-SITES; SHAPE COMPLEMENTARITY; DOCKING ALGORITHM; RECOGNITION SITES; HYDROGEN-BONDS; GEOMETRIC FIT; MEAN FORCE; INTERFACES; ELECTROSTATICS; SURFACE	Biological systems and processes rely on a complex network of molecular interactions. While the association of biological macromolecules is a fundamental biochemical phenomenon crucial for the understanding of complex living systems, protein-protein docking methods aim for the computational prediction of protein complexes from individual subunits. Docking algorithms generally produce large numbers of putative protein complexes with only few of these conformations resembling the native complex structure within an acceptable degree of structural similarity. A major challenge in the field of docking is to extract near-native structure(s) out of the large pool of solutions, the so called scoring or ranking problem. A series of structural, chemical, biological and physical properties are used in this work to classify docked protein-protein complexes. These properties include specialized energy functions, evolutionary relationship, class specific residue interface propensities, gap volume, buried surface area, empiric pair potentials on residue and atom level as well as measures for the tightness of fit. Efficient comprehensive scoring functions have been developed using probabilistic Support Vector Machines in combination with this array of properties on the largest currently available protein-protein docking benchmark. The established classifiers are shown to be specific for certain types of protein-protein complexes and are able to detect near-native complex conformations from large sets of decoys with high sensitivity. Using classification probabilities. the ranking of near-native structures was drastically improved, leading to a significant enrichment of near-native complex conformations within the top ranks. It could be shown that the developed schemes outperform five other previously published scoring functions.	[Martin, Oliver; Schomburg, Dietmar] Univ Cologne, CUBIC, D-50674 Cologne, Germany	Schomburg, D (reprint author), Bioinformat & Biochem Tech Univ Braunschweig, Langer Kamp 19B, D-38106 Braunschweig, Germany.	d.schomburg@tu-bs.de					Andreeva A, 2004, NUCLEIC ACIDS RES, V32, P226; Berchanski A, 2004, PROTEINS, V56, P130, DOI 10.1002/prot.20145; BOOBBYER DNA, 1989, J MED CHEM, V32, P1083, DOI 10.1021/jm00125a025; Caffrey P, 2003, CHEMBIOCHEM, V4, P654, DOI 10.1002/cbic.200300581; Camacho CJ, 2001, P NATL ACAD SCI USA, V98, P10636, DOI 10.1073/pnas.181147798; Chakrabarti P, 2002, PROTEINS, V47, P334, DOI 10.1002/prot.10085; CHANG C. C., LIBSVM LIB SUPPORT V; Chen R, 2003, PROTEINS, V52, P88, DOI 10.1002/prot.10390; Chen R, 2002, PROTEINS, V47, P281, DOI 10.1002/prot.10092; Chen R, 2003, PROTEINS, V52, P80, DOI 10.1002/prot.10389; CHEN YW, 2005, FEATURE EXTRACTION F; Decanniere K, 2001, J MOL BIOL, V313, P473, DOI 10.1006/jmbi.2001.5075; Eisenstein M, 2004, CR BIOL, V327, P409, DOI 10.1016/j.cvri.2004.03.006; Fernandez A, 2003, P NATL ACAD SCI USA, V100, P113, DOI 10.1073/pnas.0136888100; Fernandez-Recio J, 2005, PROTEINS, V60, P308, DOI 10.1002/prot.20575; Gabb HA, 1997, J MOL BIOL, V272, P106, DOI 10.1006/jmbi.1997.1203; Gardiner EJ, 2001, PROTEINS, V44, P44, DOI 10.1002/prot.1070; Glaser F, 2001, PROTEINS, V43, P89, DOI 10.1002/1097-0134(20010501)43:2<89::AID-PROT1021>3.3.CO;2-8; Glaser F, 2003, BIOINFORMATICS, V19, P163, DOI 10.1093/bioinformatics/19.1.163; GOODFORD PJ, 1985, J MED CHEM, V28, P849, DOI 10.1021/jm00145a002; Gottschalk KE, 2004, PROTEIN ENG DES SEL, V17, P183, DOI 10.1093/protein/gzh021; Gray JJ, 2003, J MOL BIOL, V331, P281, DOI 10.1016/S0022-2836(03)00670-3; GRIMM V, 2003, UNTERSUCHUNG WISSENB; Halperin I, 2002, PROTEINS, V47, P409, DOI 10.1002/prot.10115; Halperin I, 2004, STRUCTURE, V12, P1027, DOI 10.1016/j.str.2004.04.009; Heifetz A, 2002, PROTEIN SCI, V11, P571, DOI 10.1110/ps.26002; HUANG B, 2005, P GERM C BIOINF GCB2, P159; Hubbard J. J., 1993, NACCESS COMPUTER PRO; Jackson RM, 1999, PROTEIN SCI, V8, P603; Janin J, 2005, PROTEIN SCI, V14, P278, DOI 10.1110/ps.041081905; JANIN J, 1990, J BIOL CHEM, V265, P16027; Jones S, 1996, P NATL ACAD SCI USA, V93, P13, DOI 10.1073/pnas.93.1.13; Jones S, 1997, J MOL BIOL, V272, P121, DOI 10.1006/jmbi.1997.1234; KATCHALSKIKATZIR E, 1992, P NATL ACAD SCI USA, V89, P2195, DOI 10.1073/pnas.89.6.2195; Kozakov D, 2005, BIOPHYS J, V89, P867, DOI 10.1529/biophysj.104.058768; LASKOWSKI RA, 1995, J MOL GRAPHICS, V13, P323, DOI 10.1016/0263-7855(95)00073-9; Laskowski RA, 1995, J MOL GRAPHICS, V13, P307; Lengauer T, 1996, CURR OPIN STRUC BIOL, V6, P402, DOI 10.1016/S0959-440X(96)80061-3; Li CH, 2003, PROTEIN ENG, V16, P265, DOI 10.1093/proeng/gzg035; Lo Conte L, 1999, J MOL BIOL, V285, P2177; Lorber DM, 2002, PROTEIN SCI, V11, P1393, DOI 10.1110/ps.2830102; Mandell JG, 2001, PROTEIN ENG, V14, P105, DOI 10.1093/protein/14.2.105; McCoy AJ, 1997, J MOL BIOL, V268, P570, DOI 10.1006/jmbi.1997.0987; Melo F, 1997, J MOL BIOL, V267, P207, DOI 10.1006/jmbi.1996.0868; Meyer M, 1996, J MOL BIOL, V264, P199, DOI 10.1006/jmbi.1996.0634; Mintseris J, 2005, PROTEINS, V60, P214, DOI 10.1002/prot.20560; Moont G, 1999, PROTEINS, V35, P364, DOI 10.1002/(SICI)1097-0134(19990515)35:3<364::AID-PROT11>3.0.CO;2-4; Murphy J, 2003, PROTEINS, V53, P840, DOI 10.1002/prot.10473; Neuvirth H, 2004, J MOL BIOL, V338, P181, DOI 10.1016/j.jmb.2004.02.040; Neves-Petersen MT, 2003, BIOTECHNOL ANN REV, V9, P315, DOI 10.1016/S1387-2656(03)09010-0; Norel R, 2001, PROTEIN SCI, V10, P2147, DOI 10.1110/ps.12901; Palma PN, 2000, PROTEINS, V39, P372, DOI 10.1002/(SICI)1097-0134(20000601)39:4<372::AID-PROT100>3.0.CO;2-Q; Pearlman DA, 2001, J MED CHEM, V44, P3417, DOI 10.1021/jm0100279; Reddy Boojala V. B., 2005, Journal of Bioinformatics and Computational Biology, V3, P1137, DOI 10.1142/S0219720005001429; Russell RB, 2004, CURR OPIN STRUC BIOL, V14, P313, DOI 10.1016/j.sbi.2004.04.006; Scarsi M, 1999, PROTEINS, V37, P565, DOI 10.1002/(SICI)1097-0134(19991201)37:4<565::AID-PROT7>3.0.CO;2-V; Sheinerman FB, 2002, J MOL BIOL, V318, P161, DOI 10.1016/S0022-2836(02)00030-X; Sheinerman FB, 2000, CURR OPIN STRUC BIOL, V10, P153, DOI 10.1016/S0959-440X(00)00065-8; SHOICHET BK, 1991, J MOL BIOL, V221, P327, DOI 10.1016/0022-2836(91)90822-N; Smith DK, 2003, PROTEIN SCI, V12, P1060, DOI 10.1110/ps.0236203; Smith GR, 2002, CURR OPIN STRUC BIOL, V12, P28, DOI 10.1016/S0959-440X(02)00285-3; Vajda S, 2004, TRENDS BIOTECHNOL, V22, P110, DOI 10.1016/j.tibtech.2004.01.006; Valdar WSJ, 2001, PROTEINS, V42, P108, DOI 10.1002/1097-0134(20010101)42:1<108::AID-PROT110>3.0.CO;2-O; WADE RC, 1993, J MED CHEM, V36, P140, DOI 10.1021/jm00053a018; Yuan Z, 2003, PROTEIN ENG, V16, P109, DOI 10.1093/proeng/gzg014; Zhang C, 1997, J MOL BIOL, V267, P707, DOI 10.1006/jmbi.1996.0859; Zhang C, 2004, PROTEIN SCI, V13, P400, DOI 10.1110/ps.03348304; ZIMMERMANN O, 2002, UNTERSUCHUNGEN VORHE	68	11	11	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0887-3585		PROTEINS	Proteins	MAR	2008	70	4					1367	1378		10.1002/prot.21603		12	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	268GN	WOS:000253567400026	
J	Bouchaffra, D				Bouchaffra, Djamel			Feature generation and machine learning for robust multimodal biometrics	PATTERN RECOGNITION			English	Editorial Material																	0	1	1	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	MAR	2008	41	3					775	777		10.1016/j.patcog.2007.07.014		3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	237EQ	WOS:000251357100001	
J	Linghu, B; Snitkin, ES; Holloway, DT; Gustafson, AM; Xia, Y; DeLisi, C				Linghu, Bolan; Snitkin, Evan S.; Holloway, Dustin T.; Gustafson, Adam M.; Xia, Yu; DeLisi, Charles			High-precision high-coverage functional inference from integrated data sources	BMC BIOINFORMATICS			English	Article							PROTEIN-INTERACTION NETWORKS; COMPARATIVE GENOME ANALYSIS; HETEROGENEOUS DATA SOURCES; GENE-FUNCTION PREDICTION; SACCHAROMYCES-CEREVISIAE; BIOLOGICAL DATA; YEAST; ANNOTATION; EXPRESSION; DISCOVERY	Background: Information obtained from diverse data sources can be combined in a principled manner using various machine learning methods to increase the reliability and range of knowledge about protein function. The result is a weighted functional linkage network (FLN) in which linked neighbors share at least one function with high probability. Precision is, however, low. Aiming to provide precise functional annotation for as many proteins as possible, we explore and propose a two-step framework for functional annotation ( 1) construction of a high-coverage and reliable FLN via machine learning techniques ( 2) development of a decision rule for the constructed FLN to optimize functional annotation. Results: We first apply this framework to Saccharomyces cerevisiae. In the first step, we demonstrate that four commonly used machine learning methods, Linear SVM, Linear Discriminant Analysis, NaIve Bayes, and Neural Network, all combine heterogeneous data to produce reliable and high-coverage FLNs, in which the linkage weight more accurately estimates functional coupling of linked proteins than use individual data sources alone. In the second step, empirical tuning of an adjustable decision rule on the constructed FLN reveals that basing annotation on maximum edge weight results in the most precise annotation at high coverages. In particular at low coverage all rules evaluated perform comparably. At coverage above approximately 50%, however, they diverge rapidly. At full coverage, the maximum weight decision rule still has a precision of approximately 70%, whereas for other methods, precision ranges from a high of slightly more than 30%, down to 3%. In addition, a scoring scheme to estimate the precisions of individual predictions is also provided. Finally, tests of the robustness of the framework indicate that our framework can be successfully applied to less studied organisms. Conclusion: We provide a general two-step function-annotation framework, and show that high coverage, high precision annotations can be achieved by constructing a high-coverage and reliable FLN via data integration followed by applying a maximum weight decision rule.	[Linghu, Bolan; Snitkin, Evan S.; Gustafson, Adam M.; Xia, Yu; DeLisi, Charles] Boston Univ, Bioinformat Grad Program, Boston, MA 02215 USA; [Linghu, Bolan; Snitkin, Evan S.; Holloway, Dustin T.; Gustafson, Adam M.; Xia, Yu; DeLisi, Charles] Boston Univ, Ctr Adv Genom Technol, Boston, MA 02215 USA	DeLisi, C (reprint author), Boston Univ, Bioinformat Grad Program, Boston, MA 02215 USA.	blinghu@bu.edu; esnitkin@bu.edu; dth128@bu.edu; gustafad@bu.edu; yuxia@bu.edu; delisi@bu.edu					Altaf-Ul-Amin M, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-207; Aravind L, 2000, GENOME RES, V10, P1074, DOI 10.1101/gr.10.8.1074; Asthana S, 2004, GENOME RES, V14, P1170, DOI 10.1101/gr.2203804; Balazsi G, 2005, P NATL ACAD SCI USA, V102, P7841, DOI 10.1073/pnas.0500365102; Barutcuoglu Z, 2006, BIOINFORMATICS, V22, P830, DOI 10.1093/bioinformatics/btk048; Ben-Hur A., 2005, BIOINFORMATICS S1, V21, P38; Bork P, 1998, J MOL BIOL, V283, P707, DOI 10.1006/jmbi.1998.2144; Ashburner M, 2000, NAT GENET, V25, P25; Bowers PM, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-5-r35; Collins SR, 2007, MOL CELL PROTEOMICS, V6, P439, DOI 10.1074/mcp.M600381-MCP200; Deng MH, 2004, J COMPUT BIOL, V11, P463, DOI 10.1089/1066527041410346; Deng MH, 2004, BIOINFORMATICS, V20, P895, DOI 10.1093/bioinformatics/btg500; Deng Xutao, 2006, Journal of Bioinformatics and Computational Biology, V4, P217, DOI 10.1142/S0219720006001928; Dunn R, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-39; Enright AJ, 1999, NATURE, V402, P86; Flannick J, 2006, GENOME RES, V16, P1169, DOI 10.1101/gr.5235706; Franke L, 2006, AM J HUM GENET, V78, P1011, DOI 10.1086/504300; Gasch AP, 2000, MOL BIOL CELL, V11, P4241; Hibbs MA, 2007, BIOINFORMATICS, V23, P2692, DOI 10.1093/bioinformatics/btm403; Hughes TR, 2000, CELL, V102, P109, DOI 10.1016/S0092-8674(00)00015-5; Huttenhower C, 2006, BIOINFORMATICS, V22, P2890, DOI 10.1093/informatics/btl492; Ito T, 2000, P NATL ACAD SCI USA, V97, P1143, DOI 10.1073/pnas.97.3.1143; Ito T, 2001, P NATL ACAD SCI USA, V98, P4569, DOI 10.1073/pnas.061034498; Jansen R, 2003, SCIENCE, V302, P449, DOI 10.1126/science.1087361; Jiang TJ, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-136; Kanehisa M, 2002, NOVART FDN SYMP, V247, P101; Kanehisa M, 2002, NOVART FDN SYMP, V247, P91; Kanehisa M., 2002, NOVART FDN SYMP, V247, P244; Kanehisa M, 2002, NOVART FDN SYMP, V247, P119; Karaoz U, 2004, P NATL ACAD SCI USA, V101, P2888, DOI 10.1073/pnas.0307326101; Kiemer L, 2007, PROTEOMICS, V7, P932, DOI 10.1002/pmic.200600448; Lee I, 2004, SCIENCE, V306, P1555, DOI 10.1126/science.1099511; LETOVSKY S, 2003, BIOINFORMATICS S1, V19, P97; Li JX, 2006, BIOINFORMATICS, V22, P2037, DOI 10.1093/bioinformatics/btl345; MASSJOUNI N, 2006, NUCLEIC ACIDS RES, pW340; McDermott J, 2005, BIOINFORMATICS, V21, P3217, DOI 10.1093/bioinformatics.bti514; Miller JP, 2005, P NATL ACAD SCI USA, V102, P12123, DOI 10.1073/pnas.0505482102; Myers CL, 2005, GENOME BIOL, V6, DOI 10.1186/gb-2005-6-13-r114; Nabieva E., 2005, BIOINFORMATICS S1, V21, P302; Kanehisa M, 2004, NUCLEIC ACIDS RES, V32, pD277, DOI 10.1093/nar/gkh063; Oliver S, 2000, NATURE, V403, P601, DOI 10.1038/35001165; Pellegrini M, 1999, P NATL ACAD SCI USA, V96, P4285, DOI 10.1073/pnas.96.8.4285; Pruitt KD, 2005, NUCLEIC ACIDS RES, V33, pD501, DOI 10.1093/nar/gki025; PRUITT KD, 2007, NUCLEIC ACIDS RES, pD61; Qi YJ, 2006, PROTEINS, V63, P490, DOI 10.1002/prot.20865; Reguly Teresa, 2006, J Biol, V5, P11, DOI 10.1186/jbiol36; Samanta MP, 2003, P NATL ACAD SCI USA, V100, P12579, DOI 10.1073/pnas.2132527100; Schwikowski B, 2000, NAT BIOTECHNOL, V18, P1257, DOI 10.1038/82360; Sharan R, 2007, MOL SYST BIOL, V3, DOI 10.1038/msb4100129; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; Troyanskaya OG, 2005, BRIEF BIOINFORM, V6, P34, DOI 10.1093/bib/6.1.34; Troyanskaya OG, 2003, P NATL ACAD SCI USA, V100, P8348, DOI 10.1073/pnas.0832373100; Vazquez A, 2003, NAT BIOTECHNOL, V21, P697, DOI 10.1038/nbt825; von Mering C, 2003, NUCLEIC ACIDS RES, V31, P258, DOI 10.1093/nar/gkg034; Wu HW, 2005, NUCLEIC ACIDS RES, V33, P2822, DOI 10.1093/nar/gki573; Wu J, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-80; Xiong JH, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-268; Yao ZZ, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-S1-S11	59	10	10	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	FEB 25	2008	9								119	10.1186/1471-2105-9-119		15	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	286VQ	WOS:000254874500001	
J	Qin, ZC; Lawry, J				Qin, Zengchang; Lawry, Jonathan			LFOIL: Linguistic rule induction in the label semantics framework	FUZZY SETS AND SYSTEMS			English	Article						LFOIL; label semantics; FOIL; linguistic rule; fuzzy labels		Label semantics is a random set framework for modelling with words. In previous work, several machine learning algorithms based on this framework have been proposed and studied. In this paper, we introduce a new linguistic rule induction algorithm based on Quinlan's FOIL algorithm. According to this algorithm, a set of linguistic rules is generated for classification problems. The new model is empirically tested on an artificial toy problem and several benchmark problems from UCI repository. The results show that the new model can generate very compact linguistic rules while maintaining comparable accuracy to other well-known data mining algorithms. (c) 2007 Elsevier B.V. All rights reserved.	[Qin, Zengchang] Univ Calif Berkeley, Dept EECS, BISC, Berkeley, CA 94720 USA; [Lawry, Jonathan] Univ Bristol, Dept Engn Math, AI Grp, Bristol BS8 1TH, Avon, England	Qin, ZC (reprint author), Univ Calif Berkeley, Dept EECS, BISC, Berkeley, CA 94720 USA.	zqin@cs.berkeley.edu; j.lawry@bris.ac.uk					Baldwin J., 1995, FRIL FUZZY EVIDENTIA; BALDWIN JF, 2004, INTELLIGENT INFORM P; Blake C, UCI MACHINE LEARNING; Drobics M, 2003, INT J APPROX REASON, V32, P131, DOI 10.1016/S0888-613X(02)00080-4; Jeffrey R., 1965, LOGIC DECISION; Lawry J., 2006, MODELLING REASONING; Lawry J, 2004, ARTIF INTELL, V155, P1, DOI 10.1016/j.artint.2003.10.001; Prade H, 2003, LECT NOTES ARTIF INT, V2838, P399; Qin ZC, 2005, INFORM SCIENCES, V172, P91, DOI 10.1016/j.ins.2004.12.005; Quinlan J. R., 1993, C4 5 PROGRAM MACHINE; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; Randon NJ, 2006, INFORM SCIENCES, V176, P438, DOI 10.1016/j.ins.2005.07.019; WITTEN LH, 1999, DATA MINING PRACTICA; XIE DW, 2005, P IEEE C FUZZ SYST, P779	14	12	12	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114		FUZZY SET SYST	Fuzzy Sets Syst.	FEB 16	2008	159	4					435	448		10.1016/j.fss.2007.10.008		14	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	266ZF	WOS:000253476300005	
J	Ratle, F; Gagne, C; Terrettaz-Zufferey, AL; Kanevski, M; Esseiva, P; Ribaux, O				Ratle, Frederic; Gagne, Christian; Terrettaz-Zufferey, Anne-Laure; Kanevski, Mikhail; Esseiva, Pierre; Ribaux, Olivier			Advanced clustering methods for mining chemical databases in forensic science	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS			English	Article						forensic science; machine learning; pattern analysis; spectral clustering; kernel methods; gas chromatography		Heroin and cocaine gas chromatography data are analyzed using several clustering techniques. A database with clusters confirmed by police investigation is used to assess the potential of the analysis of the chemical signature of these drugs in the investigation process. Results are compared to standard methods in the field of chemical drug profiling and show that conventional approaches miss the inherent structure in the data, which is highlighted by methods such as spectral clustering and its variants. Also, an approach based on genetic programming is presented in order to tune the affinity matrix of the spectral clustering algorithm. Results indicate that all algorithms show a quite different behavior on the two datasets, but in both cases, the data exhibits a level of clustering, since there is at least one type of clustering algorithm that performs significantly better than chance. This confirms the relevancy of using chemical drugs databases in the process of understanding the illicit drugs market, as information regarding drug trafficking networks can likely be extracted from the chemical composition of drugs. (C) 2007 Elsevier B.V. All rights reserved.	[Ratle, Frederic; Kanevski, Mikhail] Univ Lausanne, Fac Earth & Environm Sci, Inst Geomat & Risk Anal, CH-1015 Lausanne, Switzerland; [Gagne, Christian] Univ Lausanne, HEC, Inst Informat Syst, CH-1015 Lausanne, Switzerland; [Terrettaz-Zufferey, Anne-Laure; Esseiva, Pierre; Ribaux, Olivier] Univ Lausanne, Fac Law, Sch Criminal Sci, CH-1015 Lausanne, Switzerland	Ratle, F (reprint author), Univ Lausanne, Fac Earth & Environm Sci, Inst Geomat & Risk Anal, CH-1015 Lausanne, Switzerland.	frederie.ratle@unil.ch					Bengio Y, 2004, NEURAL COMPUT, V16, P2197, DOI 10.1162/0899766041732396; Cristianini N., 2006, INNOVATIONS MACHINE; Eiben A. E., 2003, INTRO EVOLUTIONARY C; Esseiva P, 2003, FORENSIC SCI INT, V132, P139, DOI 10.1016/S0379-0738(03)00010-0; ESSEIVA P, 2005, TALANTA, P360; FISCHER I, 2006, IDSIA0305; FISCHER I, 2004, IDSIA1204; GAGNE C, 2006, P 9 INT C PAR PROBL; GAGNE C, 2006, INT J ARTIFICIAL INT, P173; Gueniat O., 2005, PROFILAGE HEROINE CO; HOWLEY T, 2005, ARTIF INTELL, P379; HOWLEY T, 2006, P 16 INT C ART NEUR; KARATZOGLOU A, 2006, KERNLAB S4 PACKAGE K; Koza J. R., 1992, GENETIC PROGRAMMING; LOCICIRO S, 2007, FORENSIC SCI INT, P220; MADDEN MG, 2002, P INT SOC OPT ENG SP, P1130; Ng A.Y., 2002, ADV NEURAL INFORM PR, V14; OCONNELL ML, 2005, P INT SOC OPT ENG SP, P340; RATLE F, 2006, P 16 INT C ART NEUR; RATLE F, 2006, P 14 EUR S ART NEUR; ROWEIS S, 2000, SCIENCE, P2323; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; TENENBAUM J, 2000, SCIENCE, P2319; ZELNIKMANOR L, 2004, ADV NEURAL PROCESSIN, V16	25	4	4	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-7439		CHEMOMETR INTELL LAB	Chemometrics Intell. Lab. Syst.	FEB 15	2008	90	2					123	131		10.1016/j.chemolab.2007.09.001		9	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	264HR	WOS:000253278900004	
J	Fan, Y; Batmanghelich, N; Clark, CM; Davatzikos, C				Fan, Yong; Batmanghelich, Nematollah; Clark, Chris M.; Davatzikos, Christos		Alzheimers Dis Neuroimaging Initia	Spatial patterns of brain atrophy in MCI patients, identified via high-dimensional pattern classification, predict subsequent cognitive decline	NEUROIMAGE			English	Article						Alzheimer's disease; early detection; mild cognitive impairment; MCI; pattern classification; structural MRI	AMYLOID PRECURSOR PROTEIN; VOXEL-BASED MORPHOMETRY; MACHINE LEARNING-METHODS; EARLY ALZHEIMERS-DISEASE; GRAY-MATTER LOSS; WHITE-MATTER; HIPPOCAMPAL VOLUME; OLDER-ADULTS; CEREBRAL INFARCTIONS; ELASTIC REGISTRATION	Spatial patterns of brain atrophy in mild cognitive impairment (MCI) and Alzheimer's disease (AD) were measured via methods of computational neuroanatomy. These patterns were spatially complex and involved many brain regions. In addition to the hippocampus and the medial temporal lobe gray matter, a number of other regions displayed significant atrophy, including orbitofrontal and medial-prefrontal grey matter, cingulate (mainly posterior), insula, uncus, and temporal lobe white matter. Approximately 2/3 of the MCI group presented patterns of atrophy that overlapped with AD, whereas the remaining 1/3 overlapped with cognitively normal individuals, thereby indicating that some, but not all, MCI patients have significant and extensive brain atrophy in this cohort of MCI patients. Importantly, the group with AD-like patterns presented much higher rate of MMSE decline in follow-up visits; conversely, pattern classification provided relatively high classification accuracy (87%) of the individuals that presented relatively higher MMSE decline within a year from baseline. High-dimensional pattern classification, a nonlinear multivariate analysis, provided measures of structural abnormality that can potentially be useful for individual patient classification, as well as for predicting progression and examining multivariate relationships in group analyses. (C) 2007 Elsevier Inc. All rights reserved.	[Fan, Yong; Batmanghelich, Nematollah; Davatzikos, Christos] Univ Penn, Sch Med, Dept Radiol, Sect Biomed Image Anal, Philadelphia, PA 19104 USA; [Clark, Chris M.] Univ Penn, Alzheimers Dis Ctr, Philadelphia, PA 19104 USA	Davatzikos, C (reprint author), Univ Penn, Sch Med, Dept Radiol, Sect Biomed Image Anal, 3600 Market St,Suite 380, Philadelphia, PA 19104 USA.	christos@rad.upenn.edu					Adeli H, 2005, J ALZHEIMERS DIS, V7, P187; Ashburner J, 2003, LANCET NEUROL, V2, P79, DOI 10.1016/S1474-4422(03)00304-1; Bennett SAL, 2000, NEUROBIOL AGING, V21, P207, DOI 10.1016/S0197-4580(00)00131-7; BERESFORD T, 2006, CLIN EXP RES, V30, P1866; Beresford TP, 2006, J STUD ALCOHOL, V67, P861; Bozzali M, 2006, NEUROLOGY, V67, P453, DOI 10.1212/01.wnl.0000228243.56665.c2; Bozzali M, 2002, J NEUROL NEUROSUR PS, V72, P742, DOI 10.1136/jnnp.72.6.742; Braak H, 1998, J NEURAL TRANSM-SUPP, P97; Chetelat G, 2002, NEUROREPORT, V13, P1939; Chetelat G, 2003, NEUROLOGY, V60, P1374; Chetelat G, 2003, NEUROIMAGE, V18, P525, DOI 10.1016/S1053-8119(02)00026-5; Choi SJ, 2005, J GERIATR PSYCH NEUR, V18, P12, DOI 10.1177/0891988704271763; Convit A, 2000, NEUROBIOL AGING, V21, P19, DOI 10.1016/S0197-4580(99)00107-4; Convit A, 1997, NEUROBIOL AGING, V18, P131, DOI 10.1016/S0197-4580(97)00001-8; Csernansky JG, 2005, NEUROIMAGE, V25, P783, DOI 10.1016/j.neuroimage.2004.12.036; DAVATZIKOS C, IN PRESS NEUROBIOLOG; Davatzikos C, 2005, NEUROIMAGE, V28, P663, DOI 10.1016/j.neuroimage.2005.08.009; Davatzikos C, 2001, NEUROIMAGE, V14, P1361, DOI 10.1006/nimg.2001.0937; Davatzikos C, 2005, ARCH GEN PSYCHIAT, V62, P1218, DOI 10.1001/archpsyc.62.11.1218; DAVATZIKOS C, 2006, 10 INT C ALZH DIS RE; de Leon MJ, 2006, NEUROBIOL AGING, V27, P394, DOI 10.1016/j.neurobiolaging.2005.07.003; De Santi S, 2001, NEUROBIOL AGING, V22, P529, DOI 10.1016/S0197-4580(01)00230-5; Dickerson BC, 2001, NEUROBIOL AGING, V22, P747, DOI 10.1016/S0197-4580(01)00271-8; DRISCOLL I, 2007, SOC NEUROSCIENCE; Du AT, 2001, J NEUROL NEUROSUR PS, V71, P441, DOI 10.1136/jnnp.71.4.441; Fan Y, 2005, LECT NOTES COMPUT SC, V3749, P1; FAN Y, IN PRESS BIOL PSYCHI; Fan Y, 2007, IEEE T MED IMAGING, V26, P93, DOI 10.1109/TMI.2006.886812; Fellgiebel A, 2005, NEUROBIOL AGING, V26, P1193, DOI 10.1016/j.neurobiolaging.2004.11.006; Fellgiebel A, 2004, DEMENT GERIATR COGN, V18, P101, DOI 10.1159/000077817; Fellgiebel A, 2006, PSYCHIAT RES-NEUROIM, V146, P283, DOI 10.1016/j.pscychresns.2006.01.006; Goldszal AF, 1998, J COMPUT ASSIST TOMO, V22, P827, DOI 10.1097/00004728-199809000-00030; Good CD, 2002, NEUROIMAGE, V17, P29, DOI 10.1006/nimg.2002.1202; Grundman M, 2002, J MOL NEUROSCI, V19, P23, DOI 10.1007/s12031-002-0006-6; GUR R, 2006, SCHIZOPHRENIA B, V31, P408; Huang JB, 2007, ANN NY ACAD SCI, V1097, P259, DOI 10.1196/annals.1379.021; Jack CR, 2000, NEUROLOGY, V55, P484; Jack CR, 1999, NEUROLOGY, V52, P1397; Kabani N., 1998, NEUROIMAGE, V7, pS717; Karas GB, 2004, NEUROIMAGE, V23, P708, DOI 10.1016/j.neuroimage.2004.07.006; Kaye JA, 1997, NEUROLOGY, V48, P1297; Kemppainen NM, 2007, NEUROLOGY, V68, P1603, DOI 10.1212/01.wnl.0000260969.94695.56; KHURD P, 2006, IEEE COMP SOC WORKSH, P61; Killiany RJ, 2000, ANN NEUROL, V47, P430, DOI 10.1002/1531-8249(200004)47:4<430::AID-ANA5>3.0.CO;2-I; Kim HS, 1998, NEUROREPORT, V9, P533; KIM JS, 2003, ABNORMAL WHITE MATTE, P410; LaConte S, 2005, NEUROIMAGE, V26, P317, DOI 10.1016/j.neuroimage.2005.01.048; LAO Z, 2003, HUM BRAIN MAPP C HBM; Lao ZQ, 2004, NEUROIMAGE, V21, P46, DOI 10.1016/j.neuroimage.2003.09.027; Li S, 2007, AM J NEURORADIOL, V28, P1339, DOI 10.3174/ajnr.AO620; Lin BW, 1999, ACTA NEUROPATHOL, V97, P359; Liu YX, 2004, LECT NOTES COMPUT SC, V3216, P393; Medina D, 2006, NEUROBIOL AGING, V27, P663, DOI 10.1016/j.neurobiolaging.2005.03.026; Moseley M, 2002, NMR BIOMED, V15, P553, DOI 10.1002/nbm.785; Mourao-Miranda J, 2005, NEUROIMAGE, V28, P980, DOI 10.1016/j.neuroimage.2005.06.070; Naggara O, 2006, PSYCHIAT RES-NEUROIM, V146, P243, DOI 10.1016/j.pscychresns.2006.01.005; Nihashi T, 2001, ACTA NEUROCHIR, V143, P287, DOI 10.1007/s007010170109; Pennanen C, 2005, J NEUROL NEUROSUR PS, V76, P11, DOI 10.1136/jnnp.2004.035600; Pham DL, 1999, IEEE T MED IMAGING, V18, P737, DOI 10.1109/42.802752; Prins ND, 2004, ARCH NEUROL-CHICAGO, V61, P1531, DOI 10.1001/archneur.61.10.1531; Ray KM, 2006, RADIOLOGY, V241, P197, DOI 10.1148/radiol.2411051051; RESNICK S, 2001, NEUROBIOL AGING, V22, P5; Resnick SM, 2004, NEUROBIOL AGING, V25, P263; Resnick SM, 2003, J NEUROSCI, V23, P3295; Resnick SM, 2000, CEREB CORTEX, V10, P464, DOI 10.1093/cercor/10.5.464; Saykin AJ, 2006, NEUROLOGY, V67, P834, DOI 10.1212/01.wnl.0000234032.77541.a2; Schneider JA, 2004, NEUROLOGY, V62, P1148; Schneider JA, 2003, NEUROLOGY, V60, P1082; Shen DG, 2002, IEEE T MED IMAGING, V21, P1421, DOI 10.1109/TMI.2002.803111; Shen DG, 2002, NEUROIMAGE, V15, P422, DOI 10.1006/nimg.2001.0987; Shen DG, 2003, NEUROIMAGE, V18, P28, DOI 10.1006/nimg.2002.1301; Shi J, 2000, BRAIN RES, V853, P1, DOI 10.1016/S0006-8993(99)02113-7; Snowdon DA, 1997, JAMA-J AM MED ASSOC, V277, P813, DOI 10.1001/jama.277.10.813; Stewart WF, 2006, NEUROLOGY, V66, P1476, DOI 10.1212/01.wnl.0000216138.69777.15; Stoub TR, 2005, NEUROLOGY, V64, P1520, DOI 10.1212/01.WNL.0000160089.43264.1A; Tandon R, 2006, ARTIF INTELL MED, V36, P245, DOI 10.1016/j.artmed.2005.10.007; Thompson PM, 2001, CEREB CORTEX, V11, P1, DOI 10.1093/cercor/11.1.1; van der Flier WM, 2002, NEUROLOGY, V59, P874; VERMA R, 2006, MANIFOLD BASED ANAL; Visser PJ, 2002, J NEUROL NEUROSUR PS, V72, P491; Whitwell JL, 2007, BRAIN, V130, P1777, DOI 10.1093/brain/awml12; Xie S, 2006, NEUROLOGY, V66, P1845, DOI 10.1212/01.wnl.0000219625.77625.aa; Xu Y, 2000, NEUROLOGY, V54, P1760; Yekutieli D, 1999, J STAT PLAN INFER, V82, P171, DOI 10.1016/S0378-3758(99)00041-5; ZHANG J, 2002, INT C DIAGN IM AN IC	85	137	139	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1053-8119		NEUROIMAGE	Neuroimage	FEB 15	2008	39	4					1731	1743		10.1016/j.neuroimage.2007.10.031		13	Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical Imaging	Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging	263UK	WOS:000253241800022	
J	Tan, CW; Jones, DT				Tan, Ching-Wai; Jones, David T.			Using neural networks and evolutionary information in decoy discrimination for protein tertiary structure prediction	BMC BIOINFORMATICS			English	Article							MODEL QUALITY ASSESSMENT; FOLD RECOGNITION; ENERGY FUNCTIONS; SECONDARY STRUCTURE; CONFORMATIONS; SEQUENCES; DATABASE; SET	Background: We present a novel method of protein fold decoy discrimination using machine learning, more specifically using neural networks. Here, decoy discrimination is represented as a machine learning problem, where neural networks are used to learn the native-like features of protein structures using a set of positive and negative training examples. A set of native protein structures provides the positive training examples, while negative training examples are simulated decoy structures obtained by reversing the sequences of native structures. Various features are extracted from the training dataset of positive and negative examples and used as inputs to the neural networks. Results: Results have shown that the best performing neural network is the one that uses input information comprising of PSI-BLAST [1] profiles of residue pairs, pairwise distance and the relative solvent accessibilities of the residues. This neural network is the best among all methods tested in discriminating the native structure from a set of decoys for all decoy datasets tested. Conclusion: This method is demonstrated to be viable, and furthermore evolutionary information is successfully used in the neural networks to improve decoy discrimination.	[Tan, Ching-Wai; Jones, David T.] UCL, Dept Comp Sci, London, England	Jones, DT (reprint author), UCL, Dept Comp Sci, London, England.	chingwai@ntu.edu.sg; dtj@cs.ucl.ac.uk					ALTSCHUL SF, 1997, NUCLEIC ACIDS RES, V25, P3402; DONG QW, 2006, BMC BIOINFORMATICS, V7; Eramian D, 2006, PROTEIN SCI, V15, P1653, DOI 10.1110/ps.062095806; FASNACHT M, 2007, PROTEIN SCI; Jones D T, 1997, Proteins, VSuppl 1, P185; Jones DT, 2001, PROTEINS, P127; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; Keasar C, 2003, J MOL BIOL, V329, P159, DOI 10.1016/S0022-2836(03)00323-1; McGuffin LJ, 2003, BIOINFORMATICS, V19, P874, DOI 10.1093/bioinformatics/btg097; Moult J, 2005, PROTEINS, V61, P3, DOI 10.1002/prot.20716; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; Park B, 1996, J MOL BIOL, V258, P367, DOI 10.1006/jmbi.1996.0256; Park BH, 1997, J MOL BIOL, V266, P831, DOI 10.1006/jmbi.1996.0809; Pettitt CS, 2005, BIOINFORMATICS, V21, P3509, DOI 10.1093/bioinformatics/bti540; Reva BA, 1999, PROTEINS, V35, P353, DOI 10.1002/(SICI)1097-0134(19990515)35:3<353::AID-PROT9>3.0.CO;2-E; ROST B, 1994, PROTEINS, V20, P216, DOI 10.1002/prot.340200303; Sadowski MI, 2007, PROTEINS, V69, P476, DOI 10.1002/prot.21531; Samudrala R, 2000, PROTEIN SCI, V9, P1399; Samuel G, 2002, BRILLS TIBET STU LIB, V2, P1; Shortle D, 1998, P NATL ACAD SCI USA, V95, P11158, DOI 10.1073/pnas.95.19.11158; Siew N, 2000, BIOINFORMATICS, V16, P776, DOI 10.1093/bioinformatics/16.9.776; Simons KT, 1997, J MOL BIOL, V268, P209, DOI 10.1006/jmbi.1997.0959; SIPPL MJ, 1990, J MOL BIOL, V213, P859, DOI 10.1016/S0022-2836(05)80269-4; Tosatto SCE, 2005, J COMPUT BIOL, V12, P1316, DOI 10.1089/cmb.2005.12.1316; Tsai J, 2003, PROTEINS, V53, P76, DOI 10.1002/prot.10454; Wallner B, 2005, BIOINFORMATICS, V21, P4248, DOI 10.1093/bioinformatics/bti702; Wiederstein M, 2007, NUCLEIC ACIDS RES, V35, pW407, DOI 10.1093/nar/gkm290; Wu CH, 2006, NUCLEIC ACIDS RES, V34, pD187, DOI 10.1093/nar/gkj161; Xia Y, 2000, J MOL BIOL, V300, P171, DOI 10.1006/jmbi.2000.3835; Zemla A, 2003, NUCLEIC ACIDS RES, V31, P3370, DOI 10.1093/nar/gkg571; Zhang Y, 2004, PROTEINS, V57, P702, DOI 10.1002/prot.20264; Zhang Y, 2004, J COMPUT CHEM, V25, P865, DOI 10.1002/jcc.20011	33	4	4	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	FEB 11	2008	9								94	10.1186/1471-2105-9-94		23	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	274OT	WOS:000254011300001	
J	Khan, A; Javed, SG				Khan, Asifullah; Javed, Syed Gibran			Predicting regularities in lattice constants of GdFeO3-type perovskites	ACTA CRYSTALLOGRAPHICA SECTION B-STRUCTURAL SCIENCE			English	Article								A novel idea of employing genetic programming to obtain mathematical expressions representing the dependency of lattice constants (LC) on their atomic parameters is presented in this paper. The results obtained from simulations reveal that only two atomic parameters are sufficient for LC prediction of GdFeO3-type perovskites. In addition, an advantage of this approach is that there is no need to save any trained model as in the case of other existing machine-learning based approaches.	[Khan, Asifullah] Pakistan Inst Engn & Appl Sci, Dept Informat & Comp Sci, Islamabad, Pakistan; [Javed, Syed Gibran] Ghulam Ishaq Khan Inst Engn Sci & Technol, Fac Comp Sci & Engn, Swabi, Pakistan	Khan, A (reprint author), Pakistan Inst Engn & Appl Sci, Dept Informat & Comp Sci, Islamabad, Pakistan.	asif@pieas.edu.pk					Banzhaf W., 1998, GENETIC PROGRAMMING; CHONGHE L, 2003, J PHYS CHEM SOLIDS, V64, P2147, DOI 10.1016/S0022-3697(03)00209-9; Dawber M, 2005, REV MOD PHYS, V77, P1083, DOI 10.1103/RevModPhys.77.1083; Hannerz H, 1999, J SOLID STATE CHEM, V147, P421, DOI 10.1006/jssc.1999.8357; Javed SG, 2007, COMP MATER SCI, V39, P627, DOI 10.1016/j.commatsci.2006.08.015; Kim SJ, 2001, J SOLID STATE CHEM, V161, P197, DOI 10.1006/jssc.2001.9292; Kim SJ, 2001, J MATER CHEM, V11, P487, DOI 10.1039/b007043m; Lide DR, 1999, HDB CHEM PHYS; Liu L, 2002, MAT SCI ENG R, V37, P61, DOI 10.1016/S0927-796X(02)00008-6; Lufaso MW, 2001, ACTA CRYSTALLOGR B, V57, P725, DOI 10.1107/S0108768101015282; OKEEFFE M, 1977, ACTA CRYSTALLOGR B, V33, P3802, DOI 10.1107/S0567740877012114; SILVA S, 2005, GPLAB; Woodward PM, 2000, PHYS REV B, V62, P844, DOI 10.1103/PhysRevB.62.844; *IN CRYST STRUCT D, 2002, FIZ KARLSRUHE; *MATHW INC, 2005, MATLAB7 0	15	6	6	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	0108-7681		ACTA CRYSTALLOGR B	Acta Crystallogr. Sect. B-Struct. Sci.	FEB	2008	64		1				120	122		10.1107/S0108768107057527		3	Crystallography	Crystallography	252OV	WOS:000252456700013	
J	Kim, CO; Kwon, IH; Baek, JG				Kim, Chang Ouk; Kwon, Ick-Hyun; Baek, Jun-Geol			Asynchronous action-reward learning for nonstationary serial supply chain inventory control	APPLIED INTELLIGENCE			English	Article						action reward learning; machine learning; asynchronous performance measure update; situation reactive inventory control; two-stage serial supply chain; nonstationary customer demand	MODELS; SYSTEM; POLICIES; DEMAND; TIME	Action-reward learning is a reinforcement learning method. In this machine learning approach, an agent interacts with non-deterministic control domain. The agent selects actions at decision epochs and the control domain gives rise to rewards with which the performance measures of the actions are updated. The objective of the agent is to select the future best actions based on the updated performance measures. In this paper, we develop an asynchronous action-reward learning model which updates the performance measures of actions faster than conventional action-reward learning. This learning model is suitable to apply to nonstationary control domain where the rewards for actions vary over time. Based on the asynchronous action-reward learning, two situation reactive inventory control models (centralized and decentralized models) are proposed for a two-stage serial supply chain with nonstationary customer demand. A simulation based experiment was performed to evaluate the performance of the proposed two models.	[Kim, Chang Ouk; Kwon, Ick-Hyun; Baek, Jun-Geol] Yonsei Univ, Dept Informat & Ind Engn, Seoul 120749, South Korea; [Kwon, Ick-Hyun] Univ Illinois, Dept Civil & Environm Engn, Urbana, IL 61801 USA; [Baek, Jun-Geol] Kwangwoon Univ, Dept Business Adm, Seoul 139701, South Korea	Kim, CO (reprint author), Yonsei Univ, Dept Informat & Ind Engn, Seoul 120749, South Korea.	kimco@yonsei.ac.kr; ikwon@uiuc.edu; jungeol@hanmail.net					Achabal DD, 2000, J RETAILING, V76, P430, DOI 10.1016/S0022-4359(00)00037-3; Axsater S, 2001, IIE TRANS, V33, P91, DOI 10.1080/07408170108936810; AZRI Y, 1999, IIE T, V31, P217; Brown R.G., 1959, STAT FORECASTING INV; Cachon GP, 1999, MANAGE SCI, V45, P936, DOI 10.1287/mnsc.45.7.936; CHAUDHURY A, 1990, INT J PROD RES, V28, P437, DOI 10.1080/00207549008942729; Sethi SP, 1997, OPER RES, V45, P931, DOI 10.1287/opre.45.6.931; Gavirneni S, 2001, IIE TRANS, V33, P83, DOI 10.1023/A:1007682416719; Graves S. C., 1999, Manufacturing & Service Operations Management, V1, DOI 10.1287/msom.1.1.50; Kaipia R, 2002, PROD PLAN CONTROL, V13, P17, DOI 10.1080/09537280110061539; Kim CO, 1998, INT J PROD RES, V36, P2497, DOI 10.1080/002075498192652; Kim CO, 2005, INT J ADV MANUF TECH, V26, P1184, DOI 10.1007/s00170-004-2069-8; Lee WW, 1997, J NUCL MED, V38, P3; Li DC, 2003, INT J PROD RES, V41, P4011, DOI 10.1080/0020754031000149211; Min HS, 2003, INT J PROD RES, V41, P3921, DOI 10.1080/0020754031000118099; Min HS, 1998, INT J PROD RES, V36, P1749, DOI 10.1080/002075498192940; MOORE AW, 1993, MACH LEARN, V13, P103, DOI 10.1023/A:1022635613229; Narendra K. S., 1989, LEARNING AUTOMATA; Quintana R, 1997, INT J PROD RES, V35, P2689, DOI 10.1080/002075497194381; Simchi-Levi D., 2003, DESIGNING MANAGING S; Sutton R. S., 1988, Machine Learning, V3, DOI 10.1007/BF00115009; SUTTON R, 1991, ACM SIGART B, V2, P160, DOI 10.1145/122344.122377; Sutton R.S., 1998, REINFORCEMENT LEARNI; Takahashi K, 1999, INT J PROD RES, V37, P2293, DOI 10.1080/002075499190770; Takahashi K, 2003, INT J PROD RES, V41, P4317, DOI 10.1080/0020754031000152569; Waller M.A., 1999, J BUSINESS LOGISTICS, V20, P183; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698; Zhao XD, 2001, INT J PROD RES, V39, P3923, DOI 10.1080/00207540110072236; Zipkin P, 2000, FDN INVENTORY MANAGE	29	4	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-669X		APPL INTELL	Appl. Intell.	FEB	2008	28	1					1	16		10.1007/s10489-007-0038-2		16	Computer Science, Artificial Intelligence	Computer Science	246GG	WOS:000251994900001	
J	Murphey, YL; Chen, ZH; Feldkamp, LA				Murphey, Yi L.; Chen, Zhi Hang; Feldkamp, Lee A.			An incremental neural learning framework and its application to vehicle diagnostics	APPLIED INTELLIGENCE			English	Article						incremental learning; neural networks; vehicle diagnostics	NETWORK ARCHITECTURE; FUZZY ARTMAP; CLASSIFIERS; CLASSIFICATION; MACHINES	This paper presents a framework for incremental neural learning (INL) that allows a base neural learning system to incrementally learn new knowledge from only new data without forgetting the existing knowledge. Upon subsequent encounters of new data examples, INL utilizes prior knowledge to direct its incremental learning. A number of critical issues are addressed including when to make the system learn new knowledge, how to learn new knowledge without forgetting existing knowledge, how to perform inference using both the existing and the newly learnt knowledge, and how to detect and deal with aged learnt systems. To validate the proposed INL framework, we use backpropagation (BP) as a base learner and a multi-layer neural network as a base intelligent system. INL has several advantages over existing incremental algorithms: it can be applied to a broad range of neural network systems beyond the BP trained neural networks; it retains the existing neural network structures and weights even during incremental learning; the neural network committees generated by INL do not interact with one another and each sees the same inputs and error signals at the same time; this limited communication makes the INL architecture attractive for parallel implementation. We have applied INL to two vehicle fault diagnostics problems: end-of-line test in auto assembly plants and onboard vehicle misfire detection. These experimental results demonstrate that the INL framework has the capability to successfully perform incremental learning from unbalanced and noisy data. In order to show the general capabilities of INL, we also applied INL to three general machine learning benchmark data sets. The INL systems showed good generalization capabilities in comparison with other well known machine learning algorithms.	[Murphey, Yi L.; Chen, Zhi Hang] Univ Michigan, Dept Elect & Comp Engn, Dearborn, MI 48128 USA; [Feldkamp, Lee A.] Ford Motor Co, Dearborn, MI 48121 USA	Murphey, YL (reprint author), Univ Michigan, Dept Elect & Comp Engn, Dearborn, MI 48128 USA.	yilu@umich.edu					Alippi C, 2006, IEEE T NEURAL NETWOR, V17, P745, DOI 10.1109/TNN.2006.872345; ASH T, 1989, 8901 U CAL I COGN SC; Baffles P.T., 1992, P INT JOINT C NEUR N, V2, P392, DOI 10.1109/IJCNN.1992.226956; BOHN CA, 1997, IEEE IJCNN, P1792; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Carpenter G. A., 1995, Connection Science, V7, DOI 10.1080/09540099508915655; CARPENTER GA, 1992, IEEE T NEURAL NETWOR, V3, P698, DOI 10.1109/72.159059; Chen JH, 2004, IEEE T SYST MAN CY B, V34, P1173, DOI 10.1109/TSMCB.2003.821867; Draghici S, 2001, NEURAL NETWORKS, V14, P527, DOI 10.1016/S0893-6080(01)00040-5; Drucker H., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, DOI 10.1142/S0218001493000352; ELMAN JL, 1993, COGNITION, V48, P71, DOI 10.1016/0010-0277(93)90058-4; ENGELBRECHT AP, 1999, IJCNN 99 INT JOINT C, V2, P1350, DOI 10.1109/IJCNN.1999.831159; ENGELBRECHT AP, 2001, P INT JOINT C NEUR N, V3, P2019; FAHLMAN S. E., 1990, ADV NEURAL INFORMATI, V2, P524; FAHLMAN SE, 1998, P 1998 CONN MOD SUMM; Feldkamp LA, 1998, P IEEE, V86, P2259, DOI 10.1109/5.726790; Frean M., 1990, NEURAL COMPUT, V2, P198, DOI 10.1162/neco.1990.2.2.198; FREUND Y, 1993, THESIS U CALIFORNIA; FREUND Y, 1997, J COMPUTER SYSTEM SC, V55, P199; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Fu LM, 1996, IEEE T NEURAL NETWOR, V7, P757; Guo H, 2000, IEEE T VEH TECHNOL, V49, P1650; GUO H, 2001, 14 INT C IND ENG APP; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; INOUE M, 2003, J PHYS SOC JPN, V72, P2003; Kasabov N., 2003, EVOLVING CONNECTIONI; Kasabov NK, 2002, IEEE T FUZZY SYST, V10, P144, DOI 10.1109/91.995117; Kuncheva LI, 2002, IEEE T SYST MAN CY B, V32, P146, DOI 10.1109/3477.990871; LEE TC, 1991, STRUCTURE LEVEL ADAP; Lim CP, 1997, NEURAL NETWORKS, V10, P925, DOI 10.1016/S0893-6080(96)00123-2; Loo CK, 2005, IEEE T KNOWL DATA EN, V17, P1589, DOI 10.1109/TKDE.2005.173; Mandziuk J, 2002, INFORM SCIENCES, V141, P193, DOI 10.1016/S0020-0255(02)00170-6; MEZARD M, 1989, J PHYS A-MATH GEN, V22, P2191, DOI 10.1088/0305-4470/22/12/019; Mitchell T, 1997, MACHINE LEARNING; MOODY J, 1989, ADV NEURAL INFORM PR; Murphey YL, 2004, APPL INTELL, V21, P117, DOI 10.1023/B:APIN.0000033632.42843.17; MURPHEY YL, 1999, INT JOINT C ART INT; MURPHEY YL, 2000, IEEE T VEH, V49; MURPHEY YL, 2003, IEEE INT JOINT C NEU; SAAD D, 1999, ON LINE LEARNING NEU; SAAD D, 1995, PHYS REV E, V52, P4225, DOI 10.1103/PhysRevE.52.4225; Schaal S, 1998, NEURAL COMPUT, V10, P2047, DOI 10.1162/089976698300016963; SCHAEFER P, 1990, EARTH ISL J, V5, P2; SCHAPIRE RE, 1999, P ALG LEARN THEOR; Schlimmer J. C., 1986, Machine Learning, V1, DOI 10.1007/BF00116895; SCHWENK H, 1997, 1072 U MONTR; SHIOTANI S, 1995, NEUROCOMPUTING, V9, P111, DOI 10.1016/0925-2312(94)00061-V; Utgoff P. E., 1989, Machine Learning, V4, DOI 10.1023/A:1022699900025; UTGOFF PE, 1991, UMCS1991010; Utgoff PE, 1997, MACH LEARN, V29, P5, DOI 10.1023/A:1007413323501; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; YEN O, 1999, IJCNN 99 INT JOINT C, V5, P3230, DOI 10.1109/IJCNN.1999.836173	53	2	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-669X		APPL INTELL	Appl. Intell.	FEB	2008	28	1					29	49		10.1007/s10489-007-0040-8		21	Computer Science, Artificial Intelligence	Computer Science	246GG	WOS:000251994900003	
J	Wang, XW; El Naqa, IM				Wang, Xiaowei; El Naqa, Issam M.			Prediction of both conserved and nonconserved microRNA targets in animals	BIOINFORMATICS			English	Article							EXPRESSION; IDENTIFICATION; DETERMINANTS; EVOLUTION; DATABASE; SIRNAS; MIRNAS; IMPACT; GENES; LET-7	Motivation: MicroRNAs (miRNAs) are involved in many diverse biological processes and they may potentially regulate the functions of thousands of genes. However, one major issue in miRNA studies is the lack of bioinformatics programs to accurately predict miRNA targets. Animal miRNAs have limited sequence complementarity to their gene targets, which makes it challenging to build target prediction models with high specificity. Results: Here we present a new miRNA target prediction program based on support vector machines (SVMs) and a large microarray training dataset. By systematically analyzing public microarray data, we have identified statistically significant features that are important to target downregulation. Heterogeneous prediction features have been non-linearly integrated in an SVM machine learning framework for the training of our target prediction model, MirTarget2. About half of the predicted miRNA target sites in human are not conserved in other organisms. Our prediction algorithm has been validated with independent experimental data for its improved performance on predicting a large number of miRNA down-regulated gene targets.	[Wang, Xiaowei; El Naqa, Issam M.] Washington Univ, Sch Med, Dept Radiat Oncol, St Louis, MO 63110 USA	Wang, XW (reprint author), Washington Univ, Sch Med, Dept Radiat Oncol, St Louis, MO 63110 USA.						Ambros V, 2004, NATURE, V431, P350, DOI 10.1038/nature02871; Bagga S, 2005, CELL, V122, P553, DOI 10.1016/j.cell.2005.07.031; Barrett T, 2007, NUCLEIC ACIDS RES, V35, pD760, DOI 10.1093/nar/gkl887; Benson DA, 2007, NUCLEIC ACIDS RES, V35, pD21, DOI 10.1093/nar/gkl986; Brennecke J, 2005, PLOS BIOL, V3, P404, DOI 10.1371/journal.pbio.0030085; El-Naqa I, 2002, IEEE T MED IMAGING, V21, P1552, DOI 10.1109/TMI.2002.806569; Enright AJ, 2004, GENOME BIOL, V5; Farh KKH, 2005, SCIENCE, V310, P1817, DOI 10.1126/science.1121158; Gaidatzis D, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-69; Griffiths-Jones S, 2006, NUCLEIC ACIDS RES, V34, pD140, DOI 10.1093/nar/gkj112; Grimson A, 2007, MOL CELL, V27, P91, DOI 10.1016/j.molcel.2007.06.017; He L, 2004, NAT REV GENET, V5, P522, DOI 10.1038/nrg1379; Hofacker IL, 2003, NUCLEIC ACIDS RES, V31, P3429, DOI 10.1093/nar/gkg599; Jing Q, 2005, CELL, V120, P623, DOI 10.1016/j.cell.2004.12.038; Kertesz M, 2007, NAT GENET, V39, P1278, DOI 10.1038/ng2135; Kim SK, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-411; Kiriakidou M, 2004, GENE DEV, V18, P1165, DOI 10.1101/gad.1184704; Krek A, 2005, NAT GENET, V37, P495, DOI 10.1038/ng1536; Lai EC, 2002, NAT GENET, V30, P363, DOI 10.1038/ng865; Lai EC, 2005, GENE DEV, V19, P1067, DOI 10.1101/gad.1291905; Lee YS, 2007, GENE DEV, V21, P1025, DOI 10.1101/gad.1540407; Lewis BP, 2005, CELL, V120, P15, DOI 10.1016/j.cell.2004.12.035; Lim LP, 2005, NATURE, V433, P769, DOI 10.1038/nature03315; Linsley PS, 2007, MOL CELL BIOL, V27, P2240, DOI 10.1128/MCB.02005-06; Long D, 2007, NAT STRUCT MOL BIOL, V14, P287, DOI 10.1038/nsmb1226; Miranda KC, 2006, CELL, V126, P1203, DOI 10.1016/j.cell.2006.07.031; Miska EA, 2005, CURR OPIN GENET DEV, V15, P563, DOI 10.1016/j.gde.2005.08.005; Nielsen CB, 2007, RNA, V13, P1894, DOI 10.1261/rna.768207; Rajewsky N, 2006, NAT GENET, V38, pS8, DOI 10.1038/ng1798; Rehmsmeier M, 2004, RNA, V10, P1507, DOI 10.1021/rna.5248604; Robins H, 2005, P NATL ACAD SCI USA, V102, P4006, DOI 10.1073/pnas.0500775102; Sethupathy P, 2006, RNA, V12, P192, DOI 10.1261/rna.2239606; Sontheimer EJ, 2005, CELL, V122, P9, DOI 10.1016/j.cell.2005.06.030; Stark A, 2005, CELL, V123, P1133, DOI 10.1016/j.cell.2005.11.023; Stark A, 2003, PLOS BIOL, V1, P397, DOI 10.1371/journal.pbio.0000060; Wang XW, 2006, NUCLEIC ACIDS RES, V34, P1646, DOI 10.1093/nar/gkl068; Zhao Y, 2005, NATURE, V436, P214, DOI 10.1038/nature03817	37	134	142	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	FEB 1	2008	24	3					325	332		10.1093/bioinformatics/btm595		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	258XM	WOS:000252903700004	
J	Jacob, L; Vert, JP				Jacob, Laurent; Vert, Jean-Philippe			Efficient peptideMHC-I binding prediction for alleles with few known binders	BIOINFORMATICS			English	Article							T-CELL EPITOPES; MHC BINDING; MOLECULES; MODELS; IMMUNOGENICITY; SUPERTYPES; AFFINITY; DATABASE; LIGANDS; VACCINE	Motivation: In silico methods for the prediction of antigenic peptides binding to MHC class I molecules play an increasingly important role in the identification of T-cell epitopes. Statistical and machine learning methods in particular are widely used to score candidate binders based on their similarity with known binders and non-binders. The genes coding for the MHC molecules, however, are highly polymorphic, and statistical methods have difficulties building models for alleles with few known binders. In this context, recent work has demonstrated the utility of leveraging information across alleles to improve the performance of the prediction. Results: We design a support vector machine algorithm that is able to learn peptideMHC-I binding models for many alleles simultaneously, by sharing binding information across alleles. The sharing of information is controlled by a user-defined measure of similarity between alleles. We show that this similarity can be defined in terms of supertypes, or more directly by comparing key residues known to play a role in the peptideMHC binding. We illustrate the potential of this approach on various benchmark experiments where it outperforms other state-of-the-art methods.	[Jacob, Laurent; Vert, Jean-Philippe] Ecole Mines Paris, Ctr Computat Biol, F-77305 Fontainebleau, France	Jacob, L (reprint author), Ecole Mines Paris, Ctr Computat Biol, 35 Rue St Honore, F-77305 Fontainebleau, France.						Antes I, 2006, BIOINFORMATICS, V22, pE16, DOI 10.1093/bioinformatics/btl216; ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI 10.2307/1990404; Bhasin M, 2003, BIOINFORMATICS, V19, P665, DOI 10.1093/bioinformatics/btg055; Bhasin M, 2004, VACCINE, V22, P3195, DOI 10.1016/j.vaccine.2004.02.005; Bottou L., 2007, LARGE SCALE KERNEL M; Bui HH, 2006, PROTEINS, V63, P43, DOI 10.1002/prot.20870; Bui HH, 2005, IMMUNOGENETICS, V57, P304, DOI 10.1007/s00251-005-0798-y; Davies MN, 2007, DRUG DISCOV TODAY, V12, P389, DOI 10.1016/j.drudis.2007.03.010; Donnes P, 2002, BMC BIOINFORMATICS, V3, DOI 10.1186/1471-2105-3-25; Doytchinova IA, 2004, J IMMUNOL, V172, P4314; Doytchinova IA, 2005, J COMPUT AID MOL DES, V19, P203, DOI 10.1007/s10822-005-3993-x; Evgeniou T, 2005, J MACH LEARN RES, V6, P615; HECKERMAN D, 2006, LEVERAGING INFORM HL; Hertz T, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-S1-S3; JACOB L, 2007, 07093931V1 ARXIV; Jojic N, 2006, BIOINFORMATICS, V22, pE227, DOI 10.1093/bioinformatics/btl255; Korber B, 2006, PLOS COMPUT BIOL, V2, P484, DOI 10.1371/journal.pcbi.0020071; Mamitsuka H, 1998, PROTEINS, V33, P460, DOI 10.1002/(SICI)1097-0134(19981201)33:4<460::AID-PROT2>3.0.CO;2-M; McMichael A, 2002, NAT REV IMMUNOL, V2, P283, DOI 10.1038/nri779; Nielsen M, 2003, PROTEIN SCI, V12, P1007, DOI 10.1110/ps.0239403; Peters B, 2006, PLOS COMPUT BIOL, V2, P574, DOI 10.1371/journal.pcbi.0020065; Peters B, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-132; Rammensee HG, 1999, IMMUNOGENETICS, V50, P213, DOI 10.1007/s002510050595; RAMMENSEE HG, 1995, IMMUNOGENETICS, V41, P178, DOI 10.1007/BF00172063; Robinson J, 2000, TISSUE ANTIGENS, V55, P280, DOI 10.1034/j.1399-0039.2000.550314.x; Rosenfeld R, 1995, GENET ANAL-BIOMOL E, V12, P1, DOI 10.1016/1050-3862(95)00107-7; Salomon J, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-501; Scholkopf B., 2002, LEARNING KERNELS SUP; Scholkopf B, 2004, KERNEL METHODS COMPU; SETTE A, 1994, J IMMUNOL, V153, P5586; Sette A, 2001, IMMUNOGENETICS, V53, P255, DOI 10.1007/s002510100334; Sette A, 1998, CURR OPIN IMMUNOL, V10, P478, DOI 10.1016/S0952-7915(98)80124-6; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Tung CW, 2007, BIOINFORMATICS, V23, P942, DOI 10.1093/bioinformatics/btm061; Vapnik VN, 1998, STAT LEARNING THEORY; Wang RF, 1999, J MOL MED-JMM, V77, P640, DOI 10.1007/s001099900042; Yewdell JTW, 1999, ANNU REV IMMUNOL, V17, P51, DOI 10.1146/annurev.immunol.17.1.51; Zhang GL, 2005, NUCLEIC ACIDS RES, V33, pW172, DOI 10.1093/nar/gki452; Zhao YD, 2003, BIOINFORMATICS, V19, P1978, DOI 10.1093/bioinformatics/btg255; Zhu SF, 2006, BIOINFORMATICS, V22, P1648, DOI 10.1093/bioinformatics/btl141	40	34	34	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	FEB 1	2008	24	3					358	366		10.1093/bioinformatics/btm611		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	258XM	WOS:000252903700008	
J	Samui, P				Samui, Pijush			Prediction of friction capacity of driven piles in clay using the support vector machine	CANADIAN GEOTECHNICAL JOURNAL			English	Article						piles; clay; artificial neural network; support vector machine	NETWORKS	The support vector machine (SVM) is an emerging machine learning technique where prediction error and model complexity are simultaneously minimized. This paper examines the potential of SVM to predict the friction capacity of driven piles in clay. This SVM is firmly based on the statistical learning theory and uses the regression technique by introducing accuracy (epsilon) insensitive loss function. The results are compared with those from a widely used artificial neural network (ANN) model. Overall, the SVM showed good performance and is proven to be better than ANN model. A sensitivity analysis has been also performed to investigate the importance of the input parameters. The study shows that SVM has the potential to be a useful and practical tool for prediction of friction capacity of driven piles in clay.	Indian Inst Sci, Dept Civil Engn, Bangalore 560012, Karnataka, India	Samui, P (reprint author), Indian Inst Sci, Dept Civil Engn, Bangalore 560012, Karnataka, India.	pijush@civil.iisc.ernet.in					Bennett K.P, 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; Boser B, 1992, P 5 ANN WORKSH COMP, P144, DOI DOI 10.1145/130385.130401; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cristianni N., 2000, INTRO SUPPORT VECTOR; Goh ATC, 1995, GEOTECHNIQUE, V45, P709; GUALTIERI JA, 1999, P 8 JET PROP LAB AIR; Haykin S., 1999, NEURAL NETWORKS; Kecman V, 2001, LEARNING SOFT COMPUT; KRAFT LM, 1981, J GEOTECH ENG-ASCE, V107, P1521; Liong SY, 2000, J COMPUT CIVIL ENG, V14, P1, DOI 10.1061/(ASCE)0887-3801(2000)14:1(1); Meyerhof G. G., 1976, J GEOTECHNICAL ENG D, V102, P197; MEYERHOF GG, 1983, J GEOTECH ENG-ASCE, V109, P797; Mukherjee S., 1997, P IEEE WORKSH NEUR N, P511; Park D., 1999, Computer-Aided Civil and Infrastructure Engineering, V14, DOI 10.1111/0885-9507.00154; PECK RB, 1958, 36 HIGHW RES BOARD, P72; Ratsch G., 1997, P INT C ART NEUR NET, P999; SCHOLKOPF B, 1997, THESIS TECHNICAL U O; Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88; Vapnik V., 1997, ADV NEURAL INFORM PR; Vapnik V. N, 1995, NATURE STAT LEARNING; Vapnik VN, 1998, STAT LEARNING THEORY; VIJAYVERGIYA VN, 1972, P 4 ANN OFFSH TECHN, V2, P865; Woodward RJ, 1961, P 5 INT C SOILS MECH, V2, P177; ZEEVAERT L, 1959, P 1 PAN AM C SOIL ME; *MATHWORKS INC, 1999, MATLAB US MAN	25	1	1	NATL RESEARCH COUNCIL CANADA-N R C RESEARCH PRESS	OTTAWA	BUILDING M 55, OTTAWA, ON K1A 0R6, CANADA	0008-3674		CAN GEOTECH J	Can. Geotech. J.	FEB	2008	45	2					288	295		10.1139/T07-072		8	Engineering, Geological; Geosciences, Multidisciplinary	Engineering; Geology	284IT	WOS:000254700800011	
J	Kim, H; Zhang, Y; Heo, YS; Oh, HB; Chen, SS				Kim, Hyeoncheol; Zhang, Yiying; Heo, Yong-Seok; Oh, Heung-Bum; Chen, Su-Shing			Specificity rule discovery in HIV-1 protease cleavage site analysis	COMPUTATIONAL BIOLOGY AND CHEMISTRY			English	Article						HIV-1 cleavage site prediction rule discovery	HUMAN-IMMUNODEFICIENCY-VIRUS; SUPPORT VECTOR MACHINES; NEURAL-NETWORKS; SUBSTRATE-SPECIFICITY; TYPE-1 PROTEASE; FEATURE-SELECTION; DRUG-RESISTANCE; PREDICTION; PROTEINASES; SEQUENCES	Several machine learning algorithms have recently been applied to modeling the specificity of HIV-1 protease. The problem is challenging because of the three issues as follows: (1) datasets with high dimensionality and small number of samples could misguide classification modeling and its interpretation; (2) symbolic interpretation is desirable because it provides us insight to the specificity in the form of human-understandable rules, and thus helps us to design effective HIV inhibitors; (3) the interpretation should take into account complexity or dependency between positions in sequences. Therefore, it is neccessary to investigate multivariate and feature-selective methods to model the specificity and to extract rules from the model. We have tested extensively various machine learning methods, and we have found that the combination of neural networks and decompositional approach can generate a set of effective rules. By validation to experimental results for the HIV-1 protease, the specificity rules outperform the ones generated by frequency-based, univariate or black-box methods. (C) 2007 Elsevier Ltd. All rights reserved.	[Kim, Hyeoncheol] Korea Univ, Dept Comp Sci Educ, Seoul 136701, South Korea; [Zhang, Yiying; Chen, Su-Shing] Univ Florida, Gainesville, FL 32611 USA; [Heo, Yong-Seok] Konkuk Univ, Dept Chem, Seoul 143701, South Korea; [Oh, Heung-Bum] Asan Med Ctr, Dept Lab Med, Seoul, South Korea; [Oh, Heung-Bum] Univ Ulsan, Seoul, South Korea	Kim, H (reprint author), Korea Univ, Dept Comp Sci Educ, Seoul 136701, South Korea.	harrykim@korea.ac.kr	Heo, Yong-Seok/D-8244-2011				Andrews R, 1995, KNOWL-BASED SYST, V8, P373, DOI 10.1016/0950-7051(96)81920-4; Beck HP, 2002, ADV HUM PER, V2, P37, DOI 10.1016/S1479-3601(02)02005-2; Beck ZQ, 2000, VIROLOGY, V274, P391, DOI 10.1006/viro.2000.0420; Beck ZQ, 2001, J VIROL, V75, P9458, DOI 10.1128/JVI.75.19.9458-9469.2001; Boden D, 1998, ANTIMICROB AGENTS CH, V42, P2775; Brik A, 2003, ORG BIOMOL CHEM, V1, P5, DOI 10.1039/b208248a; Cai YD, 2002, J COMPUT CHEM, V23, P267, DOI 10.1002/jcc.10017; Cai YD, 1998, ADV ENG SOFTW, V29, P119, DOI 10.1016/S0965-9978(98)00046-5; Chen LM, 2004, J VIROL, V78, P3722, DOI 10.1128/JVI.78.7.3722-3732.2004; Chou KC, 1996, ANAL BIOCHEM, V233, P1, DOI 10.1006/abio.1996.0001; Crooks GE, 2004, GENOME RES, V14, P1188, DOI 10.1101/gr.849004; Dauber DS, 2002, J VIROL, V76, P1359, DOI 10.1128/JVI.76.3.1359-1368.2002; De Clercq E, 2004, J CLIN VIROL, V30, P115, DOI 10.1016/j.jvc.2004.02.009; de Oliveira T, 2003, J VIROL, V77, P9422, DOI 10.1128/JVI.77.17.9422-9430.2003; Dougherty ER, 2005, IEEE INTELL SYST, V20, P64; Feher A, 2002, EUR J BIOCHEM, V269, P4114, DOI 10.1046/j.1432-1033.2002.03105.x; Forman G, 2005, IEEE INTELL SYST, V20, P74; FU LM, 1994, IEEE T SYST MAN CYB, V24, P1114; Han J., 2001, DATA MINING CONCEPTS; Hazebrouck S, 2001, BIOCHEM J, V358, P505, DOI 10.1042/0264-6021:3580505; KIM H, 1967, LECT NOTES ARTIF INT, P170; Kim H, 2003, PROCEEDINGS OF THE 7TH JOINT CONFERENCE ON INFORMATION SCIENCES, P1520; Narayanan A., 2002, BIOINFORMATICS, V18, P5; PETTIT SC, 1991, J BIOL CHEM, V266, P14539; Ridky TW, 1996, J BIOL CHEM, V271, P4709; Rognvaldsson T, 2004, BIOINFORMATICS, V20, P1702, DOI 10.1093/bioinformatics/bth144; SCHNEIDER TD, 1990, NUCLEIC ACIDS RES, V18, P6097, DOI 10.1093/nar/18.20.6097; SETIONO R, 1995, P IJCAI, V1, P480; Setiono R, 1997, NEURAL COMPUT, V9, P185, DOI 10.1162/neco.1997.9.1.185; TAHA IA, 1999, IEEE T KNOWL DATA EN, V11, P443; Thompson TB, 1995, J THEOR BIOL, V177, P369, DOI 10.1006/jtbi.1995.0254; Thomson R, 2003, BIOINFORMATICS, V19, P1741, DOI 10.1093/bioinformatics/btg237; TOZSER J, 1991, FEBS LETT, V281, P77, DOI 10.1016/0014-5793(91)80362-7; Tozser J, 2000, EUR J BIOCHEM, V267, P6287, DOI 10.1046/j.1432-1327.2000.01714.x; Tozser J, 1997, J BIOL CHEM, V272, P16807, DOI 10.1074/jbc.272.27.16807; WLODAWER A, 1989, SCIENCE, V245, P616, DOI 10.1126/science.2548279; Wu CH, 2000, NEURAL NETWORKS GENO, V1; Xing E., 2001, P 18 INT C MACH LEAR, P601; Yang ZR, 2004, BIOINFORMATICS, V20, P3398, DOI 10.1093/bioinformatics/bth414; Yang ZR, 2004, BIOINFORMATICS, V20, P735, DOI 10.1093/bioinformatics/btg477; You LW, 2005, J VIROL, V79, P12477, DOI 10.1128/JVI.79.19.12477-12486.2005	41	5	5	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1476-9271		COMPUT BIOL CHEM	Comput. Biol. Chem.	FEB	2008	32	1					72	79		10.1016/j.compbiolchem.2007.09.006		8	Biology; Computer Science, Interdisciplinary Applications	Life Sciences & Biomedicine - Other Topics; Computer Science	260RS	WOS:000253028600010	
J	Desjardins, M; Rathod, P; Getoor, L				Desjardins, Marie; Rathod, Priyang; Getoor, Lise			Learning structured bayesian networks: Combining abstraction hierarchies and tree-structured conditional probability tables	COMPUTATIONAL INTELLIGENCE			English	Article						machine learning; Bayesian networks; abstraction hierarchies; background knowledge; clustering; MDL		Context-specific independence representations, such as tree-structured conditional probability distributions, capture local independence relationships among the random variables in a Bayesian network (BN). Local independence relationships among the random variables can also be captured by using attribute-value hierarchies to find an appropriate abstraction level for the values used to describe the conditional probability distributions. Capturing this local structure is important because it reduces the number of parameters required to represent the distribution. This can lead to more robust parameter estimation and structure selection, more efficient inference algorithms, and more interpretable models. In this paper, we introduce Tree-Abstraction-Based Search (TABS), an approach for learning a data distribution by inducing the graph structure and parameters of a BN from training data. TABS combines tree structure and attribute-value hierarchies to compactly represent conditional probability tables. To construct the attribute-value hierarchies, we investigate two data-driven techniques: a global clustering method, which uses all of the training data to build the attribute-value hierarchies, and can be performed as a preprocessing step; and a local clustering method, which uses only the local network structure to learn attribute-value hierarchies. We present empirical results for three real-world domains, finding that (1) combining tree structure and attribute-value hierarchies improves the accuracy of generalization, while providing a significant reduction in the number of parameters in the learned networks, and (2) data-derived hierarchies perform as well or better than expert-provided hierarchies.	[Desjardins, Marie; Rathod, Priyang] Univ Maryland Baltimore Cty, Dept Comp Sci & Elect Engn, Baltimore, MD 21228 USA; [Getoor, Lise] Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA	Desjardins, M (reprint author), Univ Maryland Baltimore Cty, Dept Comp Sci & Elect Engn, 1000 Hilltop Circle, Baltimore, MD 21228 USA.	mariedj@cs.umbc.edu					BOUCKAERT RR, 1994, RUUCS9427 UTR U; Boulle M, 2005, J MACH LEARN RES, V6, P1431; Boutilier C, 1996, P 12 C UNC ART INT U, P115; Burge J, 2006, LECT NOTES COMPUT SC, V4212, P66; Chickering D. M., 1997, P 13 C UNC ART INT U, P80; CHICKERING DM, 1994, MSRTR9417 MICR RES; COOPER KH, 1992, MUNIVIRO, V9, P4; DESJARDINS M, 2000, P SARA 02, P260; DESJARDINS M, 2005, P 16 EUR C MACH LEAR; Friedman N., 1996, P 12 C UNC ART INT, P252; FRIEDMAN N, 1997, INT C MACH LEARN, P125; FRIEDMAN N, 1996, SMAPLE COMPLEXITY LE; GYFTODIMOS E, 2002, P 19 INT C MACH LEAR; Heckerman D., 1995, MSRTR9506 MICR RES; HETTICH S, 1998, UCI MACHINE LEARNING; Jain A. K., 1999, ACM COMPUT SURV, V31; KANG DK, 2004, P ICDM 04; Kass G. V., 1980, APPL STATIST, V29, P119, DOI DOI 10.2307/2986296; Lam W., 1994, COMPUT INTELL, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x; Pearl J., 1988, PROBABILISTIC REASON; Poole D, 2003, J ARTIF INTELL RES, V18, P263; SEGAL E, 2005, J MACHINE LEARNING R, V6, P556; SHARMA R, 2003, P UAI, P535; ZHANG J, 2003, P ICML 03; ZHANG J, 2004, P ICDM 04	25	2	2	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	0824-7935		COMPUT INTELL	Comput. Intell.	FEB	2008	24	1					1	22				22	Computer Science, Artificial Intelligence	Computer Science	253ZR	WOS:000252556600001	
J	Serpen, G; Tekkedil, DK; Orra, M				Serpen, G.; Tekkedil, D. K.; Orra, M.			A knowledge-based artificial neural network classifier for pulmonary embolism diagnosis	COMPUTERS IN BIOLOGY AND MEDICINE			English	Article						KBANN; knowledge-based artificial neural network; PIOPED; pulmonary embolism	VENTILATION-PERFUSION; LUNG SCINTIGRAMS; CRITERIA	. This paper aims to demonstrate that knowledge-based hybrid learning algorithms are positioned to offer better performance in comparison with purely empirical machine learning algorithms for the automatic classification task associated with the diagnosis of a medical condition described as pulmonary embolism (PE). The main premise is that there exists substantial and significant specialized knowledge in the domain of PE, which can readily be leveraged for bootstrapping a knowledge-based hybrid classifier that employs both the explanation-based and the empirical learning. The modified prospective investigation of pulmonary embolism diagnosis (PIOPED) criteria, which represent the preeminent collective experiential knowledge base among nuclear radiologists as a diagnosis procedure for PE, are conveniently defined in terms of a set of if-then rules. As such, it lends itself to being captured into a knowledge base through instantiating a knowledge-based hybrid learning algorithm. This study shows the instantiation of a knowledge-based artificial neural network (KBANN) classifier through the modified PIOPED criteria for the diagnosis of PE. The development effort for the KBANN that captures the rule base associated with the PIOPED criteria as well as further refinement of the same rule base through highly specialized domain expertise is presented. Through a testing dataset generated with the help of nuclear radiologists, performance of the instantiated KBANN is profiled. Performances of a set of empirical machine learning algorithms, which are configured as classifiers and include the naive Bayes, the Bayesian Belief network, the multilayer perceptron neural network, the C4.5 decision tree algorithm, and two meta learners with boosting and bagging, are also profiled on the same dataset for the purpose of comparison with that of the KBANN. Simulation results indicate that the KBANN can effectively model and leverage the PIOPED knowledge base and its further refinements through the domain expertise, and exhibited enhanced performance compared to those of purely empirical learning based classifiers. (C) 2007 Elsevier Ltd. All rights reserved.	[Serpen, G.; Tekkedil, D. K.; Orra, M.] Univ Toledo, Dept Elect Engn & Comp Engn, Toledo, OH 43606 USA	Serpen, G (reprint author), Univ Toledo, Dept Elect Engn & Comp Engn, 2801 W Bancroft St, Toledo, OH 43606 USA.	gserpen@eng.utoledo.edu					BANISH M, 1993, J NUCL MED, V34, P176; BIELLO DR, 1979, AM J ROENTGENOL, V133, P1033; BIELLO DR, 1979, RADIOLOGY, V133, P189; BODAS R, 1999, P ART NEUR NETW ENG, P929; Buntine W, 1996, IEEE T KNOWL DATA EN, V8, P195, DOI 10.1109/69.494161; Cloete I., 2000, KNOWLEDGE BASED NEUR; Datz Frederick L., 1994, V1994, P141; Eng J, 2002, AM J ROENTGENOL, V179; Evander E, 2003, EUR J NUCL MED MOL I, V30, P961, DOI 10.1007/s00259-003-1182-5; Fisher RE, 1996, RADIOLOGY, V198, P699; FREITAS JE, 1995, J NUCL MED, V36, P1573; Frigyesi A, 2003, MED IMAGE ANAL, V7, P341, DOI 10.1016/S1361-8415(03)00030-6; Holst H, 2000, Eur J Nucl Med, V27, P400, DOI 10.1007/s002590050522; Holst H, 2001, EUR J NUCL MED, V28, P33, DOI 10.1007/s002590000409; INVESTIGATORS P, 1990, JAMA-J AM MED ASSOC, V263, P2753; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; JAGADEESH RP, 2004, 4 INT C HYBR INT SYS, P198, DOI 10.1109/ICHIS.2004.74; JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541; McLean RG, 2004, BRIT J RADIOL, V77, P372, DOI 10.1259/bjr/83624598; Mitra S, 2000, IEEE T NEURAL NETWOR, V11, P748, DOI 10.1109/72.846746; POGGIO F, 1994, NATO ASI SER, V136, P83; Scott JA, 1996, RADIOLOGY, V198, P707; Scott JA, 2000, AM J ROENTGENOL, V175, P399; SERPEN G, 2000, P ART NEUR NETW ENG, P1125; SERPEN G, 1999, MED PHYS, V26, P1172; TOURASSI GD, 1995, RADIOLOGY, V194, P889; Tourassi GD, 1998, RADIOLOGY, V206, P81; TOWELL GG, 1994, ARTIF INTELL, V70, P119, DOI 10.1016/0004-3702(94)90105-8; Werbos P. J., 1994, ROOTS BACKPROPAGATIO; Witten I. H., 2005, DATA MINING PRACTICA; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; WORSLEY DF, 1995, J NUCL MED, V36, P2380; *MATHW INC, 2005, MATL SCI TECHN COMP; *SOC NUCL MED, PROC GUID LUNG SCINT	34	3	3	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0010-4825		COMPUT BIOL MED	Comput. Biol. Med.	FEB	2008	38	2					204	220		10.1016/j.compbiomed.2007.10.001		17	Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical & Computational Biology	Life Sciences & Biomedicine - Other Topics; Computer Science; Engineering; Mathematical & Computational Biology	266CL	WOS:000253408800006	
J	Zhu, F; Han, LY; Chen, X; Lin, HH; Ong, S; Xie, B; Zhang, HL; Chen, YZ				Zhu, F.; Han, L. Y.; Chen, X.; Lin, H. H.; Ong, S.; Xie, B.; Zhang, H. L.; Chen, Y. Z.			Homology-free prediction of functional class of proteins and peptides by support vector machines	CURRENT PROTEIN & PEPTIDE SCIENCE			English	Review						machine learning method; peptide; peptide function; protein family; protein function; protein function prediction; protein sequence; support vector machine	AMINO-ACID-COMPOSITION; LIPID-BINDING PROTEINS; STATISTICAL LEARNING-METHOD; SVM-BASED METHOD; HIDDEN MARKOV MODEL; SEQUENCE SIMILARITY; COUPLED RECEPTORS; PHYSICOCHEMICAL PROPERTIES; POSTTRANSLATIONAL MODIFICATIONS; DOMAIN COMPOSITION	Protein and peptide sequences contain clues for functional prediction. A challenge is to predict sequences that show low or no homology to proteins or peptides of known function. A machine learning method, support vector machines (SVM), has recently been explored for predicting functional class of proteins and peptides from sequence-derived properties irrespective of sequence similarity, which has shown impressive performance for predicting a wide range of protein and peptide classes including certain low- and non-homologous sequences. This method serves as a new and valuable addition to complement the extensively-used alignment-based, clustering-based, and structure-based functional prediction methods. This article evaluates the strategies, current progresses, reported prediction performances, available software tools, and underlying difficulties in using SVM for predicting the functional class of proteins and peptides.	[Zhu, F.; Han, L. Y.; Lin, H. H.; Ong, S.; Xie, B.; Zhang, H. L.; Chen, Y. Z.] Natl Univ Singapore, Bioinformat & Drug Design Grp, Dept Pharm, Singapore 117543, Singapore; [Zhu, F.; Han, L. Y.; Lin, H. H.; Ong, S.; Xie, B.; Zhang, H. L.; Chen, Y. Z.] Natl Univ Singapore, Ctr Computat Sci & Engn, Singapore 117543, Singapore; [Chen, X.] Zhejiang Univ, Dept Biotechnol, Hangzhou 310029, Peoples R China; [Chen, Y. Z.] Shanghai Ctr Bioinformat Technol, Shanghai 201203, Peoples R China; [Zhu, F.] Natl Univ Singapore, Dept Biol Sci, Singapore 117543, Singapore	Chen, YZ (reprint author), Natl Univ Singapore, Bioinformat & Drug Design Grp, Dept Pharm, Blk S16,Level 8,3 Sci Dr 2, Singapore 117543, Singapore.	phacyz@nus.edu.sg	Han, Lianyi/D-1499-2009; Zhu, Feng/F-1489-2011				Aguilar D, 2002, BIOINFORMATICS, V18, P597, DOI 10.1093/bioinformatics/18.4.597; ALEXANDER S, 1999, TRENDS PHARMACOL SCI, V5, P85; Al-Shahib Ali, 2005, Appl Bioinformatics, V4, P195, DOI 10.2165/00822942-200594030-00004; Al-Shahib A, 2005, INT J NEURAL SYST, V15, P259, DOI 10.1142/S0129065705000281; ANSARI FA, 2007, PROTEINS; Aravind L, 2000, GENOME RES, V10, P1074, DOI 10.1101/gr.10.8.1074; Bairoch A, 2000, NUCLEIC ACIDS RES, V28, P304, DOI 10.1093/nar/28.1.304; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Balla T, 2005, J CELL SCI, V118, P2093, DOI 10.1242/jcs.02387; Barker WC, 1999, NUCLEIC ACIDS RES, V27, P39, DOI 10.1093/nar/27.1.39; Baxevanis AD, 1998, METHOD BIOCHEM ANAL, V39, P172; Ben-Hur A, 2005, BIOINFORMATICS, V21, pI38, DOI 10.1093/bioinformatics/bti1016; Benner SA, 2000, RES MICROBIOL, V151, P97, DOI 10.1016/S0923-2508(00)00123-6; Benson DA, 2004, NUCLEIC ACIDS RES, V32, pD23, DOI 10.1093/nar/gkh045; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Bernlohr DA, 1997, ANNU REV NUTR, V17, P277, DOI 10.1146/annurev.nutr.17.1.277; Bewley CA, 1998, ANNU REV BIOPH BIOM, V27, P105, DOI 10.1146/annurev.biophys.27.1.105; Bhardwaj N, 2007, FEBS LETT, V581, P1058, DOI 10.1016/j.febslet.2007.01.086; Bhardwaj N, 2005, NUCLEIC ACIDS RES, V33, P6486, DOI 10.1093/nar/gki949; Bhasin M, 2004, J BIOL CHEM, V279, P23262, DOI 10.1074/jbc.M401932200; Bhasin M, 2004, BIOINFORMATICS, V20, P421, DOI 10.1093/bioinformatics/btg424; Bhasin M, 2003, BIOINFORMATICS, V19, P665, DOI 10.1093/bioinformatics/btg055; Bhasin M, 2004, VACCINE, V22, P3195, DOI 10.1016/j.vaccine.2004.02.005; Bhasin M, 2004, NUCLEIC ACIDS RES, V32, pW383, DOI 10.1093/nar/gkh416; Bhaskaran R., 1988, INT J PEPT PROT RES, V32, P242; BIGELOW CC, 1967, J THEOR BIOL, V16, P187, DOI 10.1016/0022-5193(67)90004-5; Bingle CD, 2004, TRENDS IMMUNOL, V25, P53, DOI 10.1016/j.it.2003.11.007; Birch PJ, 2004, DRUG DISCOV TODAY, V9, P410, DOI 10.1016/S1359-6446(04)03043-0; Blythe MJ, 2002, BIOINFORMATICS, V18, P434, DOI 10.1093/bioinformatics/18.3.434; Bock JR, 2003, BIOINFORMATICS, V19, P125, DOI 10.1093/bioinformatics/19.1.125; Bock JR, 2001, BIOINFORMATICS, V17, P455, DOI 10.1093/bioinformatics/17.5.455; Bolanos-Garcia VM, 2003, PROG BIOPHYS MOL BIO, V83, P47, DOI 10.1016/S0079-6107(03)00028-2; Bork P, 1998, NAT GENET, V18, P313, DOI 10.1038/ng0498-313; Bork P, 1998, J MOL BIOL, V283, P707, DOI 10.1006/jmbi.1998.2144; Borst P, 2002, ANNU REV BIOCHEM, V71, P537, DOI 10.1146/annurev.biochem.71.102301.093055; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Brusic V, 1996, NUCLEIC ACIDS RES, V24, P242, DOI 10.1093/nar/24.1.242; BULL HB, 1974, ARCH BIOCHEM BIOPHYS, V161, P665, DOI 10.1016/0003-9861(74)90352-X; Bycroft M, 1997, CELL, V88, P235, DOI 10.1016/S0092-8674(00)81844-9; Cai CZ, 2004, PROTEINS, V55, P66, DOI 10.1002/prot.20045; Cai CZ, 2003, NUCLEIC ACIDS RES, V31, P3692, DOI 10.1093/nar/gkg600; Cai YD, 2004, BIOINFORMATICS, V20, P1292, DOI 10.1093/bioinformatics/bth085; Cai YD, 2002, J COMPUT CHEM, V23, P267, DOI 10.1002/jcc.10017; Cai YD, 2005, J PROTEOME RES, V4, P967, DOI 10.1021/pr0500399; Cai YD, 2003, BBA-PROTEINS PROTEOM, V1648, P127, DOI 10.1016/S1570-9639(03)00112-2; Cai YD, 2003, BIOPHYS J, V84, P3257; Cai YD, 2002, COMPUT CHEM, V26, P293, DOI 10.1016/S0097-8485(01)00113-9; Chalmel F, 2005, BIOINFORMATICS, V21, P2095, DOI 10.1093/bioinformatics/bti252; CHARTON M, 1982, J THEOR BIOL, V99, P629, DOI 10.1016/0022-5193(82)90191-6; CHARTON M, 1981, J THEOR BIOL, V91, P115, DOI 10.1016/0022-5193(81)90377-5; Xu H, 2007, METHOD INFORM MED, V46, P360, DOI 10.1160/ME0425; CHENG XD, 1993, CELL, V74, P299, DOI 10.1016/0092-8674(93)90421-L; CHOTHIA C, 1976, J MOL BIOL, V105, P1, DOI 10.1016/0022-2836(76)90191-1; Chou KC, 2000, BIOCHEM BIOPH RES CO, V278, P477, DOI 10.1006/bbrc.2000.3815; Chou KC, 2005, J CHEM INF MODEL, V45, P407, DOI 10.1021/ci049686v; Chou KC, 2004, BIOCHEM BIOPH RES CO, V320, P1236, DOI 10.1016/j.bbrc.2004.06.073; CID H, 1992, PROTEIN ENG, V5, P373, DOI 10.1093/protein/5.5.373; CUI J, 2006, MOL IMMUNOL, V43; Cui J, 2007, MOL IMMUNOL, V44, P514, DOI 10.1016/j.molimm.2006.02.010; Cui J, 2005, J MOL MICROB BIOTECH, V9, P86, DOI 10.1159/000088839; Cui J, 2006, IMMUNOGENETICS, V58, P607, DOI 10.1007/s00251-006-0117-2; Cui J, 2007, MOL IMMUNOL, V44, P866, DOI 10.1016/j.molimm.2006.04.001; DAYHOFF MO, 1978, ATLAS PROTEIN SEQ S3, V5, P363; de Lichtenberg U, 2003, J MOL BIOL, V329, P663, DOI 10.1016/S0022-2836(03)00490-X; Deshmukh S, 2007, PROTEIN PEPTIDE LETT, V14, P647; des Jardins M, 1997, Proc Int Conf Intell Syst Mol Biol, V5, P92; Ding CHQ, 2001, BIOINFORMATICS, V17, P349, DOI 10.1093/bioinformatics/17.4.349; Dobson PD, 2005, J MOL BIOL, V345, P187, DOI 10.1016/j.jmb.2004.10.024; Donnes P, 2002, BMC BIOINFORMATICS, V3, DOI 10.1186/1471-2105-3-25; Dorazilova V, 1992, Cesk Patol, V28, P245; Downes CP, 2005, TRENDS CELL BIOL, V15, P259, DOI 10.1016/j.tcb.2005.03.008; Driessen AJM, 2000, TRENDS BIOCHEM SCI, V25, P397, DOI 10.1016/S0968-0004(00)01634-0; DUBCHAK I, 1995, P NATL ACAD SCI USA, V92, P8700, DOI 10.1073/pnas.92.19.8700; Dubchak I, 1999, PROTEINS, V35, P401, DOI 10.1002/(SICI)1097-0134(19990601)35:4<401::AID-PROT3>3.0.CO;2-K; Dutta AK, 2003, EUR J PHARMACOL, V479, P93, DOI 10.1016/j.ejphar.2003.08.060; Eisen JA, 1998, GENOME RES, V8, P163; Eisenberg D, 2000, NATURE, V405, P823, DOI 10.1038/35015694; Eisenhaber B, 2004, PROTEOMICS, V4, P1614, DOI 10.1002/pmic.200300781; Eisenhaber F, 2003, NUCLEIC ACIDS RES, V31, P3631, DOI 10.1093/nar/gkg537; Enright AJ, 2002, NUCLEIC ACIDS RES, V30, P1575, DOI 10.1093/nar/30.7.1575; Enright AJ, 1999, NATURE, V402, P86; Enright AJ, 2000, BIOINFORMATICS, V16, P451, DOI 10.1093/bioinformatics/16.5.451; FANG Y, 2007, AMINO ACIDS; FENG ZP, 2000, J PROTEIN CHEM, V19, P262; Fujii Y, 2000, NAT STRUCT BIOL, V7, P889; Fujishima Kosuke, 2007, DNA Res, V14, P91, DOI 10.1093/dnares/dsm011; Fujiwara Y, 2002, NEC RES DEV, V43, P238; Furlanello C, 2003, NEURAL NETWORKS, V16, P641, DOI 10.1016/S0893-6080(03)00103-5; Fyfe PK, 2005, TRENDS PLANT SCI, V10, P275, DOI 10.1016/j.tplants.2005.04.007; GAO Q, 2005, FEBS LETT, V20, P16; Garvie CW, 2001, MOL CELL, V8, P937, DOI 10.1016/S1097-2765(01)00392-6; Gasteiger E, 2005, PROTEOMICS PROTOCOLS, P571, DOI DOI 10.1385/1592598900; Glatz JFC, 2002, MOL CELL BIOCHEM, V239, P3, DOI 10.1023/A:1020529918782; Glenn W.G., 1989, TETRAHEDRON COMPUT M, V2, P349, DOI 10.1016/0898-5529(89)90004-3; Godzik A, 2007, CELL MOL LIFE SCI, V64, P2505, DOI 10.1007/s00018-007-7211-y; Gonnet P, 2002, BIOINFORMATICS, V18, P1091, DOI 10.1093/bioinformatics/18.8.1091; Gonnet P, 2004, PROTEOMICS, V4, P1597, DOI 10.1002/pmic.200300749; GRANTHAM R, 1974, SCIENCE, V185, P862, DOI 10.1126/science.185.4154.862; GROMIHA MM, 2007, PROTEINS; Guo YZ, 2006, AMINO ACIDS, V30, P397, DOI 10.1007/s00726-006-0332-z; GUYON I, 2002, V MACHINE LEARNING, V46, P389; HAMILTON SE, 1986, BIOCHEMISTRY-US, V25, P8178, DOI 10.1021/bi00373a009; Han LY, 2004, RNA, V10, P355, DOI 10.1261/rna.5890304; Han LY, 2005, VIROLOGY, V331, P136, DOI 10.1016/j.virol.2004.10.020; Han LY, 2007, DRUG DISCOV TODAY, V12, P304, DOI 10.1016/j.druidis.2007.02.015; Han LY, 2005, NEW PHYTOL, V168, P109, DOI 10.1111/j.1469-8137.2005.01482.x; Han LY, 2006, PROTEOMICS, V6, P4023, DOI 10.1002/pmic.200500938; Han LY, 2004, NUCLEIC ACIDS RES, V32, P6437, DOI 10.1093/nar/gkh984; Hanhoff T, 2002, MOL CELL BIOCHEM, V239, P45, DOI 10.1023/A:1020502624234; Haunerland NH, 2004, PROG LIPID RES, V43, P328, DOI 10.1016/j.plipres.2004.05.001; HEDIGER MA, 1994, J EXP BIOL, V196, P15; Hodges HC, 2002, FASEB J, V16, pA543; Holm L, 1996, SCIENCE, V273, P595, DOI 10.1126/science.273.5275.595; Horn F, 2003, NUCLEIC ACIDS RES, V31, P294, DOI 10.1093/nar/gkg103; HORNE DS, 1988, BIOPOLYMERS, V27, P451, DOI 10.1002/bip.360270308; Hou YN, 2004, PROTEINS, V57, P518, DOI 10.1002/prot.20221; Huang N, 2005, PROTEIN ENG DES SEL, V18, P365, DOI 10.1093/protein/gzi041; Jaakkola T, 1999, Proc Int Conf Intell Syst Mol Biol, P149; Jensen LJ, 2003, BIOINFORMATICS, V19, P635, DOI 10.1093/bioinformatics/btg036; Jensen LJ, 2002, J MOL BIOL, V319, P1257, DOI 10.1016/S0022-2836(02)00379-0; Joet T, 2003, EXPERT OPIN THER TAR, V7, P593, DOI 10.1517/14728222.7.5.593; JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588; Juncker AS, 2003, PROTEIN SCI, V12, P1652, DOI 10.1110/ps.0303703; Karchin R, 2002, BIOINFORMATICS, V18, P147, DOI 10.1093/bioinformatics/18.1.147; Kawashima S, 2000, NUCLEIC ACIDS RES, V28, P374, DOI 10.1093/nar/28.1.374; Kuang Rui, 2005, Journal of Bioinformatics and Computational Biology, V3, P527, DOI 10.1142/S021972000500120X; Kumar M, 2006, J BIOL CHEM, V281, P5357, DOI 10.1074/jbc.M511061200; KUMAR M, 2005, J BIOL CHEM; Kunik Vered, 2005, Proc IEEE Comput Syst Bioinform Conf, P80; Kunta JR, 2004, CURR DRUG METAB, V5, P109, DOI 10.2174/1389200043489144; Lata S, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-263; Lee W, 2004, ANNU REV PHARMACOL, V44, P137, DOI 10.1146/annurev.pharmtox.44.101802.121856; Lei ZD, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-491; LESLIE C, 2003, KERNEL METHODS COMPU, P95; Leslie CS, 2004, BIOINFORMATICS, V20, P467, DOI 10.1093/bioinformatics/btg431; Lewin B, 2000, GENES; Li H, 2005, CHEM RES TOXICOL, V18, P1071, DOI 10.1021/tx049652h; Li QL, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-353; Li ZR, 2006, NUCLEIC ACIDS RES, V34, pW32, DOI 10.1093/nar/gkl305; Liao L, 2003, J COMPUT BIOL, V10, P857, DOI 10.1089/106652703322756113; LICHTMAN AKA, 2005, CELLULAR MOL IMMUNOL, P485; Lin HH, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-S5-S13; Lin HH, 2006, J LIPID RES, V47, P824, DOI 10.1194/jlr.M500530-JLR200; LIN HH, 2006, UNPUB; Lin HH, 2006, PROTEINS, V62, P218, DOI 10.1002/prot.20605; Lin TY, 1996, PROTEIN SCI, V5, P372; Lin Z, 2001, J PROTEIN CHEM, V20, P217, DOI 10.1023/A:1010967008838; Liu H, 2005, PROTEIN J, V24, P385, DOI 10.1007/s10930-005-7592-4; Lo SL, 2005, PROTEOMICS, V5, P876, DOI 10.1002/pmic.200401118; Lugo MR, 2005, BIOCHEMISTRY-US, V44, P643, DOI 10.1021/bi0485326; Luscombe NM, 2002, J MOL BIOL, V320, P991, DOI 10.1016/S0022-2836(02)00571-5; Luscombe NM, 2001, NUCLEIC ACIDS RES, V29, P2860, DOI 10.1093/nar/29.13.2860; Marcotte EM, 1999, SCIENCE, V285, P751, DOI 10.1126/science.285.5428.751; Martin S, 2005, BIOINFORMATICS, V21, P218, DOI 10.1093/bioinformatics/bth483; MATSUMURA M, 1992, SCIENCE, V257, P927, DOI 10.1126/science.1323878; MATTAJ IW, 1993, CELL, V73, P837, DOI 10.1016/0092-8674(93)90265-R; McFarland BJ, 2002, MED RES REV, V22, P168, DOI 10.1002/med.10006; Mishra NK, 2007, PROTEIN PEPTIDE LETT, V14, P575; Mitra J, 2007, J BIOMOL STRUCT DYN, V25, P289; Mondal S, 2006, J THEOR BIOL, V243, P252, DOI 10.1016/j.jtbi.2006.06.014; Nabieva E., 2005, BIOINFORMATICS S1, V21, P302; NC-IUBMB (Nomenclature Committee of the International Union of Biochemistry and Molecular Biology), 1992, ENZ NOM; Niggli V, 2001, TRENDS BIOCHEM SCI, V26, P604, DOI 10.1016/S0968-0004(01)01927-2; Palsdottir H, 2004, BBA-BIOMEMBRANES, V1666, P2, DOI 10.1016/j.bbamem.2004.06.012; Park KJ, 2005, BIOINFORMATICS, V21, P4223, DOI 10.1093/bioinformatics/bti697; Patel A, 2006, J BIOL CHEM, V281, P6030, DOI 10.1074/jbc.M512332200; Pebay-Peyroula E, 2001, CURR OPIN STRUC BIOL, V11, P427, DOI 10.1016/S0959-440X(00)00228-1; Perez-Canadillas JM, 2001, CURR OPIN STRUC BIOL, V11, P53, DOI 10.1016/S0959-440X(00)00164-0; Plewczynski D, 2005, CELL MOL BIOL LETT, V10, P73; Provost F., 1998, P 15 INT C MACH LEAR; Quentin Y, 2000, J MOL MICROB BIOTECH, V2, P501; Rammensee HG, 1999, IMMUNOGENETICS, V50, P213, DOI 10.1007/s002510050595; Ratsch G, 2005, BIOINFORMATICS, V21, pI369, DOI 10.1093/bioinformatics/bti1053; Raussens V, 1996, J BIOL CHEM, V271, P23089; RECZKO M, 1994, NUCLEIC ACIDS RES, V22, P3616; Ren QH, 2004, NUCLEIC ACIDS RES, V32, pD284, DOI 10.1093/nar/gkh016; Rost B, 2002, J MOL BIOL, V318, P595, DOI 10.1016/S0022-2836(02)00016-5; Saha S, 2006, NUCLEIC ACIDS RES, V34, pW202, DOI 10.1093/nar/gkl343; Saha Sudipto, 2006, Genomics Proteomics & Bioinformatics, V4, P253, DOI 10.1016/S1672-0229(07)60006-0; Saier MH, 2000, MICROBIOL MOL BIOL R, V64, P354, DOI 10.1128/MMBR.64.2.354-411.2000; Saier MH, 2006, NUCLEIC ACIDS RES, V34, pD181, DOI 10.1093/nar/gkj001; Sarai A, 2005, ANNU REV BIOPH BIOM, V34, P379, DOI 10.1146/annurev.biophys.34.040202.144537; SCHNEIDER G, 1994, BIOPHYS J, V66, P344; SCHNEIDER G, 1994, BIOPHYS J, V66, P335; Schomburg I, 2002, NUCLEIC ACIDS RES, V30, P47, DOI 10.1093/nar/30.1.47; Schonbach C, 2000, NUCLEIC ACIDS RES, V28, P222, DOI 10.1093/nar/28.1.222; Schuler GD, 1998, METHOD BIOCHEM ANAL, V39, P145; Seal RP, 1999, ANNU REV PHARMACOL, V39, P431, DOI 10.1146/annurev.pharmtox.39.1.431; Shah I, 1997, Proc Int Conf Intell Syst Mol Biol, V5, P276; Shao J., 1995, JACKKNIFE BOOTSTRAP; Sharan R, 2007, MOL SYST BIOL, V3, DOI 10.1038/msb4100129; Shoshan SH, 2004, PHARMACOGENOMICS, V5, P845, DOI 10.1517/14622416.5.7.845; Smialowski P, 2006, PROTEINS, V62, P343, DOI 10.1002/prot.20789; Smith TF, 1997, NAT BIOTECHNOL, V15, P1222, DOI 10.1038/nbt1197-1222; Soeria-Atmadja D, 2006, NUCLEIC ACIDS RES, V34, P3779, DOI 10.1093/nar/gkl467; Soeria-Atmadja D, 2004, INT ARCH ALLERGY IMM, V133, P101, DOI 10.1159/000076382; Sokal RR, 2006, AM J PHYS ANTHROPOL, V129, P121, DOI 10.1002/ajpa.20250; Stawiski EW, 2003, J MOL BIOL, V326, P1065, DOI 10.1016/S0022-2836(03)00031-7; Steffen N R, 2002, Bioinformatics, V18 Suppl 1, pS22; Strope PK, 2007, GENOMICS, V89, P602, DOI 10.1016/j.ygeno.2007.01.008; Suzuki JY, 1997, ANNU REV GENET, V31, P61, DOI 10.1146/annurev.genet.31.1.61; TAN F, 2007, AMINO ACIDS; Teichmann SA, 2001, CURR OPIN STRUC BIOL, V11, P354, DOI 10.1016/S0959-440X(00)00215-3; Todd AE, 2001, J MOL BIOL, V307, P1113, DOI 10.1006/jmbi.2001.4513; Tolstorukov MY, 2004, J MOL BIOL, V337, P65, DOI 10.1016/j.jmb.2004.01.011; Tsuda K, 2002, NEURAL COMPUT, V14, P2397, DOI 10.1162/08997660260293274; Vapnik V. N, 1995, NATURE STAT LEARNING; Veropulos K, 1999, P INT JOINT C ART IN, P55; VERT JP, 2003, KERNEL METHODS COMPU, P131; VISHWANATHAN SVN, 2002, P NEUR INF PROC SYST; Wang M, 2004, PROTEIN ENG DES SEL, V17, P509, DOI 10.1093/protein/gzh061; Wang ML, 2005, COMPUT BIOL CHEM, V29, P95, DOI 10.1016/j.compbiolchem.2005.02.002; Weisiger RA, 2002, MOL CELL BIOCHEM, V239, P35, DOI 10.1023/A:1020550405578; Weiss S. M., 1991, COMPUTER SYSTEMS LEA; Whisstock JC, 2003, Q REV BIOPHYS, V36, P307, DOI 10.1017/S0033583503003901; XU H, 2007, PROTEOMICS; Xu JR, 2007, NUCLEIC ACIDS RES, V35, pW538, DOI 10.1093/nar/gkm254; Xue L, 2000, J CHEM INF COMP SCI, V40, P1227, DOI 10.1021/ci000327j; Xue L, 2000, COMB CHEM HIGH T SCR, V3, P363; XUE L, 1999, J CHEM INF COMP SCI, V39, P669; Xue Y, 2004, J CHEM INF COMP SCI, V44, P1630, DOI 10.1021/ci049869h; Xue Y, 2004, J CHEM INF COMP SCI, V44, P1497, DOI 10.1021/ci049971e; Yabuki Y, 2005, NUCLEIC ACIDS RES, V33, pW148, DOI 10.1093/nar/gki; Yan Q, 2000, AAPS PharmSci, V2, pE20; Yang ZR, 2005, J CHEM INF MODEL, V45, P1424, DOI 10.1021/ci050004t; Yap CW, 2005, J CHEM INF MODEL, V45, P982, DOI 10.1021/ci0500536; YU H, 2003, IEEE COMP SOC BIOINF, P220; Zhang C, 1998, J MOL BIOL, V281, P929, DOI 10.1006/jmbi.1998.1982; Zhang GL, 2005, NUCLEIC ACIDS RES, V33, pW172, DOI 10.1093/nar/gki452; Zhang GL, 2007, J IMMUNOL METHODS, V320, P143, DOI 10.1016/j.jim.2006.12.011; Zhang GY, 2006, PROTEIN PEPTIDE LETT, V13, P965, DOI 10.2174/092986606778777560; Zhang ZD, 2005, PROTEIN SCI, V14, P431, DOI 10.1110/ps.041035505; Zhao YD, 2003, BIOINFORMATICS, V19, P1978, DOI 10.1093/bioinformatics/btg255; Zhou XB, 2007, J THEOR BIOL, V248, P546, DOI 10.1016/j.jtbi.2007.06.001; Zien A, 2000, BIOINFORMATICS, V16, P799, DOI 10.1093/bioinformatics/16.9.799; Zorzet Anna, 2002, In Silico Biology, V2, P525	236	1	2	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y26, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	1389-2037		CURR PROTEIN PEPT SC	Curr. Protein Pept. Sci.	FEB	2008	9	1					70	95				26	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	275IA	WOS:000254063900006	
J	Li, JZ; Ruhe, G				Li, Jingzhou; Ruhe, Guenther			Analysis of attribute weighting heuristics for analogy-based software effort estimation method AQUA(+)	EMPIRICAL SOFTWARE ENGINEERING			English	Article; Proceedings Paper	5th International Symposium on Empirical Software Engineering	2006	Rio de Janeiro, BRAZIL			effort estimation by analogy; attribute weighting; feature selection; rough set analysis; learning; heuristics	COST ESTIMATION MODELS; VALIDATION; SETS	Estimation by analogy (EBA) predicts effort for a new project by aggregating effort information of similar projects from a given historical data set. Existing research results have shown that a careful selection and weighting of attributes may improve the performance of the estimation methods. This paper continues along that research line and considers weighting of attributes in order to improve the estimation accuracy. More specifically, the impact of weighting (and selection) of attributes is studied as extensions to our former EBA method AQUA, which has shown promising results and also allows estimation in the case of data sets that have non-quantitative attributes and missing values. The new resulting method is called AQUA(+). For attribute weighting, a qualitative analysis pre-step using rough set analysis (RSA) is performed. RSA is a proven machine learning technique for classification of objects. We exploit the RSA results in different ways and define four heuristics for attribute weighting. AQUA(+) was evaluated in two ways: (1) comparison between AQUA(+) and AQUA, along with the comparative analysis between the proposed four heuristics for AQUA(+), (2) comparison of AQUA(+) with other EBA methods. The main evaluation results are: (1) better estimation accuracy was obtained by AQUA(+) compared to AQUA over all six data sets; and (2) AQUA(+) obtained better results than, or very close to that of other EBA methods for the three data sets applied to all the EBA methods. In conclusion, the proposed attribute weighing method using RSA can improve the estimation accuracy of EBA method AQUA(+) according to the empirical studies over six data sets. Testing more data sets is necessary to get results that are more statistical significant.	[Li, Jingzhou; Ruhe, Guenther] Univ Calgary, Software Engn Decis Support Lab, Calgary, AB T2N 1N4, Canada	Li, JZ (reprint author), Univ Calgary, Software Engn Decis Support Lab, Calgary, AB T2N 1N4, Canada.	jingli@ucalgary.ca; ruhe@ucalgary.ca					Boehm B.W., 1981, SOFTWARE ENG EC; Briand L., 2001, ENCY SOFTWARE ENG; Cartwright M. H., 2003, Proceedings. Ninth International Software Metrics Symposium, DOI 10.1109/METRIC.2003.1232464; Chen ZH, 2005, IEEE SOFTWARE, V22, P38, DOI 10.1109/MS.2005.151; Chmielewski M.R., 1994, 3 INT WORKSH ROUGH S, P294; Conte S, 1986, SOFTWARE ENG METRICS; Desharnais J, 1989, THESIS U MONTREAL; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; EFRON B, 1983, AM STAT, V37, P36, DOI 10.2307/2685844; Foss T, 2003, IEEE T SOFTWARE ENG, V29, P985, DOI 10.1109/TSE.2003.1245300; Huang SJ, 2006, INFORM SOFTWARE TECH, V48, P1034, DOI 10.1016/j.infsof.2005.12.020; Jorgensen M, 2003, J SYST SOFTWARE, V68, P253, DOI 10.1016/S0164-1212(03)00066-9; Jorgensen M, 2007, IEEE T SOFTWARE ENG, V33, P33, DOI 10.1109/TSE.2007.256943; KADODA G, 2000, P EASE 2000 4 INT C; KEMERER CF, 1987, COMMUN ACM, V30, P416, DOI 10.1145/22899.22906; KIRSOPP C, 2002, P 2I INT C KNOWL BAS; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; LAPLANTE PA, 2005, INNOVATIONS SYSTEMS, V1, P71, DOI 10.1007/s11334-005-0009-x; Leung H. K. N., 2002, Empirical Software Engineering, V7, DOI 10.1023/A:1015202115651; Li J., 2006, P ACM IEEE INT S EMP; LI JZ, 2007, P ICSE 2007 WORKSH P; Li JZ, 2007, EMPIR SOFTW ENG, V12, P65, DOI 10.1007/s10664-006-7552-4; LI JZ, 2005, DATE SET USP05; Mendes E, 2003, EMPIR SOFTW ENG, V8, P163, DOI 10.1023/A:1023062629183; MENZIES T, 2006, IEEE T SOFTWARE ENG, V32, P1; Molokken K., 2003, Proceedings 2003 International Symposium on Empirical Software Engineering. ISESE 2003; MUKHOPADHYAY T, 1992, MIS QUART, V16, P155, DOI 10.2307/249573; Myrtveit I, 2001, IEEE T SOFTWARE ENG, V27, P999, DOI 10.1109/32.965340; Pawlak Z., 1991, ROUGH SETS THEORETIC; PUTNAM LH, 1978, IEEE T SOFTWARE ENG, V4, P345, DOI 10.1109/TSE.1978.231521; Ruhe G, 1996, PROCEEDINGS OF THE 3RD INTERNATIONAL SOFTWARE METRICS SYMPOSIUM, P10, DOI 10.1109/METRIC.1996.492439; SAYYAD SJ, 2005, PROMISE REPOSITORY S; Shepperd M, 1997, IEEE T SOFTWARE ENG, V23, P736, DOI 10.1109/32.637387; SHEPPERD MJ, 1996, P ICSE, V18, P170; SONG Q, 2005, METRICS 05 P 11 IEEE, P35; Strike K, 2001, IEEE T SOFTWARE ENG, V27, P890, DOI 10.1109/32.962560; Witten I. H., 2005, DATA MINING PRACTICA; Zhang M., 2004, P 23 INT C NAFIPS BA, P434; Zhong N, 2001, J INTELL INF SYST, V16, P199, DOI 10.1023/A:1011219601502; *IDSS, 2006, ROSE2; *ISBSG, 2004, DAT R8	41	8	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1382-3256		EMPIR SOFTW ENG	Empir. Softw. Eng.	FEB	2008	13	1					63	96		10.1007/s10664-007-9054-4		34	Computer Science, Software Engineering	Computer Science	245WT	WOS:000251970200004	
J	Carbonneau, R; Laframboise, K; Vahidov, R				Carbonneau, Real; Laframboise, Kevin; Vahidov, Rustam			Application of machine learning techniques for supply chain demand forecasting	EUROPEAN JOURNAL OF OPERATIONAL RESEARCH			English	Article						supply chain management; forecasting; neural networks; support vector machines; bullwhip effect	MANAGEMENT; PERFORMANCE; INFORMATION	Full collaboration in supply chains is an ideal that the participant firms should try to achieve. However, a number of factors hamper real progress in this direction. Therefore, there is a need for forecasting demand by the participants in the absence of full information about other participants' demand. In this paper we investigate the applicability of advanced machine learning techniques, including neural networks, recurrent neural networks, and support vector machines, to forecasting distorted demand at the end of a supply chain (bullwhip effect). We compare these methods with other, more traditional ones, including naive forecasting, trend, moving average, and linear regression. We use two data sets for our experiments: one obtained from the simulated supply chain, and another one from actual Canadian Foundries orders. Our findings suggest that while recurrent neural networks and support vector machines show the best performance, their forecasting accuracy was not statistically significantly better than that of the regression model. (C) 2007 Elsevier B.V. All rights reserved.	Concordia Univ, Dept Decis Sci, Montreal, PQ H3G 1M8, Canada; Concordia Univ, MIS, John Molson Sch Business, Montreal, PQ H3G 1M8, Canada	Vahidov, R (reprint author), Concordia Univ, Dept Decis Sci, 1455 Maisonneuve Blvd, Montreal, PQ H3G 1M8, Canada.	rcarbonneau@jmsb.concordia.ca; Lafrak@jmsb.concordia.ca; rvahi-dov@jmsb.concordia.ca					BOX GEP, 1970, TIME SERIES ANAL; Chandra C, 2005, EUR J OPER RES, V166, P337, DOI 10.1016/j.ejor.2004.02.012; Cox A., 2001, J SUPPLY CHAIN MANAG, V37, P28, DOI 10.1111/j.1745-493X.2001.tb00097.x; Davis E., 2004, EXTENDED ENTERPRISE; Dejonckheere J, 2003, EUR J OPER RES, V147, P567, DOI 10.1016/S0377-2217(02)00369-7; Demuth H., 1998, NEURAL NETWORK TOOLB; Dorffner G., 1996, Neural Network World, V6; Forrester J, 1961, IND DYNAMICS; Frohlich MT, 2002, J OPER MANAG, V20, P729, DOI 10.1016/S0272-6963(02)00037-2; Gunasekaran A, 2004, EUR J OPER RES, V159, P265, DOI 10.1016/j.rjor.2003.08.015; Heikkila J, 2002, J OPER MANAG, V20, P747, DOI 10.1016/S0272-6963(02)00038-4; HERBRICH R, 2000, ADV COMPUTATIONAL EC, V11, P169; KIMBROUGH S, 2001, DECIS SUPPORT SYST, V33, P323; Kullback S., 1968, INFORM THEORY STAT; LANDT FW, 1997, STOCK PRICE PREDICTI; LAWRENCE S, 1996, NOISY TIME SERIES PR; Lee H.L., 1997, BULLWHIP EFFECT SUPP; MUKHERJEE S, 1997, P IEEE NNSP; PELCKMANS K, 2002, LSSVMLAB MATLAB C TO; Premkumar GP, 2000, INFORM SYST MANAGE, V17, P56; RAGHUNATHAN S, 1999, DECISION SCI, V17, P56; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1, P318; RUPING S, 2003, P ICASSP 2003; Suykens J.A.K., 2002, LEAST SQUARES SUPPOR; Tan K. C., 2001, EUROPEAN J PURCHASIN, V7, P39, DOI 10.1016/S0969-7012(00)00020-4; Thonemann UW, 2002, EUR J OPER RES, V142, P81, DOI 10.1016/S0377-2217(01)00281-8; Vakharia AJ, 2002, DECISION SCI, V33, P495, DOI 10.1111/j.1540-5915.2002.tb01653.x; VAPNIK V, 1995, NATURE STAT LEARING; Vapnik V., 1997, ADV NEURAL INFORM PR, V9, P287; Watson G., 2001, J SUPPLY CHAIN MANAG, V37, P36, DOI 10.1111/j.1745-493X.2001.tb00098.x; WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337; Yusuf YY, 2004, EUR J OPER RES, V159, P379, DOI 10.1016/j.ejor.2003.08.022; Zhao XD, 2002, DECISION SCI, V33, P251, DOI 10.1111/j.1540-5915.2002.tb01644.x; *MATHWORKS INC, 2000, US MATLAB VERS 6; *STATSCAN, 2003, STAT CAN TABL 304 00	35	32	33	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0377-2217		EUR J OPER RES	Eur. J. Oper. Res.	FEB 1	2008	184	3					1140	1154		10.1016/j.ejor.2006.12.004		15	Management; Operations Research & Management Science	Business & Economics; Operations Research & Management Science	220XG	WOS:000250190000019	
J	Ben-David, A				Ben-David, Arie			Comparison of classification accuracy using Cohen's Weighted Kappa	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Weighted Cohen's Kappa; sensitivity analysis; cost-sensitive classification; ordinal data sets; expert systems; machine learning	LEARNING ALGORITHMS; HIGH AGREEMENT; COEFFICIENT; PARADOXES	Many expert systems solve classification problems. While comparing the accuracy of such classifiers, the cost of error must frequently be taken into account. In such cost-sensitive applications just using the percentage of misses as the sole meter for accuracy can be misleading. Typical examples of such problems are medical and military applications, as well as data sets with ordinal (i.e., ordered) class. A new methodology is proposed here for assessing classifiers accuracy. The approach taken is based on Cohen's Kappa statistic. It compensates for classifications that may be due to chance. The use of Kappa is proposed as a standard meter for measuring the accuracy of all multi-valued classification problems. The use of Weighted Kappa enables to effectively deal with cost-sensitive classification. When the cost of error is unknown and can only be roughly estimated, the use of sensitivity analysis with Weighted Kappa is highly recommended. (c) 2006 Elsevier Ltd. All rights reserved.	[Ben-David, Arie] Holon Inst Technol, Dept Technol Management, Holon, Israel	Ben-David, A (reprint author), Holon Inst Technol, Dept Technol Management, Holon, Israel.	hol_abendav@bezeqint.net					Alpaydin E, 2004, INTRO MACHINE LEARNI; Alpaydin E, 1999, NEURAL COMPUT, V11, P1885, DOI 10.1162/089976699300016007; BENDAVID A, 1995, MACH LEARN, V19, P29, DOI 10.1023/A:1022655006810; BRADFORD J, 1998, 10 EUR C MACH LEARN, P131; Cao-Van K, 2002, LECT NOTES COMPUT SC, V2561, P291; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; COOK RJ, 1998, ENCY BIOSTATISTICS, P2166; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Domingos P., 1999, P 5 INT C KNOWL DISC; FEINSTEIN AR, 1990, J CLIN EPIDEMIOL, V43, P543, DOI 10.1016/0895-4356(90)90158-L; CICCHETTI DV, 1990, J CLIN EPIDEMIOL, V43, P551, DOI 10.1016/0895-4356(90)90159-M; Fleiss JL, 1981, STAT METHODS RATES P; GANZACH Y, 1993, ORGAN BEHAV HUM DEC, V56, P422, DOI 10.1006/obhd.1993.1062; HACKETT G, 1999, BUSINESS DECISION AN; HOLLMEN J, 2000, DATA MINING, V2, P495; KLEIBER M, 1993, DESIGN SENSITIVITY A; KNOLL U, 1994, COST SENSITIVE PRUNI, P383; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; MACLURE M, 1987, AM J EPIDEMIOL, V126, P161; MARGINEANTU DD, 2000, P INT C MACH LEARN I, P582; Simon H., 1978, HDB LEARNING COGNITI, V5, P271; THOMPSON WD, 1988, J CLIN EPIDEMIOL, V41, P949, DOI 10.1016/0895-4356(88)90031-5; Witten I. H., 2005, DATA MINING	23	18	18	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	FEB	2008	34	2					825	832		10.1016/j.eswa.2006.10.022		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	263TH	WOS:000253238900003	
J	Hu, QH; Yu, DR; Me, Z				Hu, Qinghua; Yu, Daren; Me, Zongxia			Neighborhood classifiers	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						metric space; neighborhood; rough set; reduction; classifier; norm	K-NEAREST NEIGHBOR; FEATURE-SELECTION; CLASSIFICATION; ROUGH; REDUCTION; DISTANCE; SEARCH; SPACES	K nearest neighbor classifier (K-NN) is widely discussed and applied in pattern recognition and machine learning, however, as a similar lazy classifier using local information for recognizing a new test, neighborhood classifier, few literatures are reported on. In this paper, we introduce neighborhood rough set model as a uniform framework to understand and implement neighborhood classifiers. This algorithm integrates attribute reduction technique with classification learning. We study the influence of the three norms on attribute reduction and classification, and compare neighborhood classifier with KNN, CART and SVM. The experimental results show that neighborhood-based feature selection algorithm is able to delete most of the redundant and irrelevant features. The classification accuracies based on neighborhood classifier is superior to K-NN, CART in original feature spaces and reduced feature subspaces, and a little weaker than SVM. (c) 2006 Elsevier Ltd. All rights reserved.	[Hu, Qinghua; Yu, Daren; Me, Zongxia] Harbin Inst Technol, Harbin 150001, Peoples R China	Hu, QH (reprint author), Harbin Inst Technol, Harbin 150001, Peoples R China.	huqinghua@hcms.hit.edu.cn	Hu, Qinghua/B-8857-2008				Anil K.G., 2006, COMPUTATIONAL STAT D, V50, P3113; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O, 1973, PATTERN CLASSIFICATI; Fix Evelyn, 1951, 4 USAF SCH AV MED; Fu AW, 2000, VLDB J, V9, P154, DOI 10.1007/PL00010672; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; Girolami M, 2003, IEEE T PATTERN ANAL, V25, P1253, DOI 10.1109/TPAMI.2003.1233899; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hu QH, 2006, PATTERN RECOGN LETT, V27, P414, DOI 10.1016/patrec.2005.09.004; Hu QH, 2006, IEEE T FUZZY SYST, V14, P191, DOI 10.1109/TFUZZ.2005.864086; Jensen R, 2004, IEEE T KNOWL DATA EN, V16, P1457, DOI 10.1109/TKDE.2004.96; Kuncheva LI, 1999, PATTERN RECOGN LETT, V20, P1149, DOI 10.1016/S0167-8655(99)00082-3; Kushilevitz E, 2000, SIAM J COMPUT, V30, P457, DOI 10.1137/S0097539798347177; Lin T.Y., 1988, P 1988 ACM 16 ANN CO; Lin T.Y., 1997, ADV MACHINE INTELLIG, P132; Lindenbaum M, 2004, MACH LEARN, V54, P125, DOI 10.1023/B:MACH.0000011805.60520.fe; Muni DP, 2006, IEEE T SYST MAN CY B, V36, P106, DOI 10.1109/TSMCB.2005.854499; Neumann J, 2005, MACH LEARN, V61, P129, DOI 10.1007/s10994-005-1505-9; OWEN A, 1984, CANADIAN J STATISTIC, V12, P191, DOI 10.2307/3314747; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Salzberg S., 1991, MACH LEARN, V6, P277; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P1179, DOI 10.1016/S0167-8655(97)00112-8; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; Swiniarski RW, 2003, PATTERN RECOGN LETT, V24, P833, DOI 10.1016/S0167-8655(02)00196-4; Tan SB, 2005, EXPERT SYST APPL, V28, P667, DOI 10.1016/j.eswa.2004.12.023; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, DOI 10.1016/0167-8655(86)90013-9; Wang H, 2006, IEEE T PATTERN ANAL, V28, P942; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wu WZ, 2002, INFORM SCIENCES, V144, P201, DOI 10.1016/S0020-0255(02)00180-9; Yao YY, 1998, INFORM SCIENCES, V111, P239, DOI 10.1016/S0020-0255(98)10006-3; Zhang B, 2004, IEEE T PATTERN ANAL, V26, P525; Zhou CY, 2006, PATTERN RECOGN, V39, P635, DOI 10.1016/j.patocog.2005.09.004	34	67	85	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	FEB	2008	34	2					866	876		10.1016/j.eswa.2006.10.043		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	263TH	WOS:000253238900008	
J	Kim, D; Lee, H; Cho, S				Kim, Dongil; Lee, Hyoung-joo; Cho, Sungzoon			Response modeling with support vector regression	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						response modeling; customer relationship management; direct marketing; support vector machines; regression; pattern selection	PATTERN SELECTION; NEURAL-NETWORKS; MACHINES	Response modeling has become a key factor to direct marketing. In general, there are two stages in response modeling. The first stage is to identify respondents from a customer database while the second stage is to estimate purchase amounts of the respondents. This paper focuses on the second stage where a regression, not a classification, problem is solved. Recently, several non-linear models based on machine learning such as support vector machines (SVM) have been applied to response modeling. However, there is a major difficulty. A typical training dataset for response modeling is so large that modeling takes very long, or, even worse, modeling may be impossible. Therefore, sampling methods have been usually employed in practice. However a sampled dataset usually leads to lower accuracy. In this paper, we employed an epsilon-tube based sampling for support vector regression (SVR) which leads to better accuracy than the random sampling method. (C) 2006 Elsevier Ltd. All rights reserved.	Seoul Natl Univ, Seoul 151744, South Korea	Cho, S (reprint author), Seoul Natl Univ, San 56-1 Shillim Dong, Seoul 151744, South Korea.	dikim01@snu.ac.kr; imhjlee@gmail.com; zoon@snu.ac.kr					Bentz Y, 2000, J FORECASTING, V19, P177, DOI 10.1002/(SICI)1099-131X(200004)19:3<177::AID-FOR738>3.0.CO;2-6; Cheung KW, 2003, DECIS SUPPORT SYST, V35, P231, DOI 10.1016/S0167-9236(02)00108-2; Chiu CC, 2002, EXPERT SYST APPL, V22, P163, DOI 10.1016/S0957-4174(01)00052-5; Drucker H, 1997, ADV NEUR IN, V9, P155; Ha K, 2005, J INTERACT MARK, V19, P17, DOI 10.1002/dir.20028; Haughton D., 1997, J DIRECT MARKETING, V11, P42, DOI 10.1002/(SICI)1522-7138(199723)11:4<42::AID-DIR7>3.0.CO;2-W; Kim D, 2006, LECT NOTES ARTIF INT, V3918, P215; Levin N., 1997, J DIRECT MARKETING, V11, P76, DOI 10.1002/(SICI)1522-7138(199723)11:4<76::AID-DIR10>3.0.CO;2-D; Ling C. X., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Malthouse E. C., 2002, J INTERACTIVE MARKET, V16, P37, DOI 10.1002/dir.10043; Muller K.R, 1997, LECT NOTES COMPUTER, V1327, P999; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; POTHARST R, 2000, ERS200114LIS RSM ER; Shi M., 2000, J INTERACTIVE MARKET, V14, P2; Shin H, 2003, LECT NOTES COMPUT SC, V2690, P1008; Shin HJ, 2006, EXPERT SYST APPL, V30, P746, DOI 10.1016/j.eswa.2005.07.037; Suh EH, 1999, EXPERT SYST APPL, V17, P89, DOI 10.1016/S0957-4174(99)00026-3; Vapnik V. N, 1995, NATURE STAT LEARNING; Viaene S, 2001, INT J INTELL SYST, V16, P1023, DOI 10.1002/int.1047; Wang K, 2005, DATA MIN KNOWL DISC, V11, P57, DOI 10.1007/s10618-005-1355-x; Yu EZ, 2006, EXPERT SYST APPL, V30, P352, DOI 10.1016/j.eswa.2005.07.026; *KDD98, 1998, KDDCUP98 RES	22	13	13	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	FEB	2008	34	2					1102	1108		10.1016/j.eswa.2006.12.019		7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	263TH	WOS:000253238900030	
J	Carbonneau, R; Kersten, GE; Vahidov, R				Carbonneau, Real; Kersten, Gregory E.; Vahidov, Rustarn			Predicting opponent's moves in electronic negotiations using neural networks	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						electronic negotiations; opponent modeling; counter-offer prediction; offer optimization; neural networks	AUTOMATED NEGOTIATION; FEEDFORWARD NETWORKS; SUPPORT; ALGORITHM; AGENTS	Electronic negotiation experiments provide a rich source of information about relationships between the negotiators, their individual actions, and the negotiation dynamics. This information can be effectively utilized by intelligent agents equipped with adaptive capabilities to learn from past negotiations and assist in selecting appropriate negotiation tactics. This paper presents an approach to modeling the negotiation process in a time-series fashion using artificial neural network. In essence, the network uses information about past offers and the current proposed offer to simulate expected counter-offers. On the basis of the model's prediction, "what-if" analysis of counter-offers can be done with the purpose of optimizing the current offer. The neural network has been trained using the Levenberg-Marquardt algorithm with Bayesian Regularization. The simulation of the predictive model on a testing set has very good and highly significant performance. The findings suggest that machine learning techniques may find useful applications in the context of electronic negotiations. These techniques can be effectively incorporated in an intelligent agent that can sense the environment and assist negotiators by providing predictive information, and possibly automating some negotiation steps. (C) 2006 Published by Elsevier Ltd.	[Kersten, Gregory E.; Vahidov, Rustarn] Concordia Univ, John Molson Sch Business, Montreal, PQ H3G 1M8, Canada; [Carbonneau, Real] Dept Management Sci, Montreal, PQ H3T 2A7, Canada	Vahidov, R (reprint author), Concordia Univ, John Molson Sch Business, 1455 Maisonneuve Blvd W, Montreal, PQ H3G 1M8, Canada.	real.carbonneau@hec.ca; gregory@jmsb.concordia.ca; rvahidov@jmsb.concordia.ca					BEAM C, 1996, AUTOMATED NEGOTIATIO; Chavez A., 1997, Software agents and soft computing. Towards enhancing machine intelligence. Concepts and applications; Chavez A., 1996, 1 INT C PRACT APPL I; CHAVEZ A, 1997, APPL INT AG MULT TEC; CHEN E, 2004, 25 MCMAST WORLD C MA; Chen E., 2005, INT J ELECT BUSINESS, V3, P28, DOI 10.1504/IJEB.2005.006387; Dzeng RJ, 2004, EXPERT SYST APPL, V27, P107, DOI 10.1016/j.eswa.2003.12.006; Dzeng RJ, 2005, COMPUT-AIDED CIV INF, V20, P280, DOI 10.1111/j.1467-8667.2005.00393; Faratin P, 2002, ARTIF INTELL, V142, P205, DOI 10.1016/S0004-3702(02)00290-4; Foresee F. D., 1997, INT JOINT C NEUR NET; HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697; Hagan M.T., 1996, NEURAL NETWORK DESIG; HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T; Jennings NR, 2001, GROUP DECIS NEGOT, V10, P199, DOI 10.1023/A:1008746126376; Kersten GE, 1999, DECIS SUPPORT SYST, V25, P135, DOI 10.1016/S0167-9236(99)00012-3; Kersten G. E., 2003, International Journal of Internet and Enterprise Management, V1, DOI 10.1504/IJIEM.2003.003822; Kwon O, 2006, EXPERT SYST APPL, V31, P275, DOI 10.1016/j.eswa.2005.09.033; Lee WP, 2004, EXPERT SYST APPL, V27, P665, DOI 10.1016/j.eswa.2004.07.001; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.415; Maes P, 1999, COMMUN ACM, V42, P81, DOI 10.1145/295685.295716; MATWIN S, 1991, IEEE T SYST MAN CYB, V21, P102, DOI 10.1109/21.101141; Oprea M., 2002, Studies in Informatics and Control, V11; VAHIDOV R, 2005, CD ROM P; Zeng DJ, 1998, INT J HUM-COMPUT ST, V48, P125, DOI 10.1006/ijhc.1997.0164; *MATHW INC, 2005, US MATLAB VERS 7	25	17	18	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	FEB	2008	34	2					1266	1273		10.1016/j.eswa.2006.12.027		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	263TH	WOS:000253238900048	
J	Castillo, L; Armengol, E; Onaindia, E; Sebastia, L; Gonzalez-Boticario, J; Rodriguez, A; Fernandez, S; Arias, JD; Borrajo, D				Castillo, Luis; Armengol, Eva; Onaindia, Eva; Sebastia, Laura; Gonzalez-Boticario, Jesus; Rodriguez, Antonio; Fernandez, Susana; Arias, Juan D.; Borrajo, Daniel			SAMAP: An user-oriented adaptive system for planning tourist visits	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						planning; machine learning; case-based reasoning; user modelling	LISTS; TERMS	In this paper, we present SAMAP, whose goal is to build a software tool to help different people visit different cities. This tool integrates modules that dynamically capture user models, determine lists of activities that can provide more utility to a user given the past experience of the system with similar users, and generates plans that can be executed by the user. This system is intended to work in portable devices (mobile phones, PDAs, etc.,) with internet connection. In this paper, we describe the architecture, the knowledge model that is shared among components using an ontology, and the three components of the tool: user module, case-based module and planning module. (C) 2007 Elsevier Ltd. All rights reserved.	[Castillo, Luis] Univ Granada, ETSI Informat & Telecomunicac, Dept Ciencias Comp, Granada 18071, Spain; [Armengol, Eva] CSIC, Art Intelligence Res Inst, Bellaterra, Spain; [Onaindia, Eva; Sebastia, Laura] Univ Politecn Valencia, Dept Sist Informat & Comp, E-46071 Valencia, Spain; [Gonzalez-Boticario, Jesus; Rodriguez, Antonio] Univ Nacl Educ Distancia, ETSI Informat, Dipartimento Inteligencia Artificial, aDeNu Res Grp, E-28040 Madrid, Spain; [Fernandez, Susana; Arias, Juan D.; Borrajo, Daniel] Univ Carlos III Madrid, Dept Informat, Madrid 28911, Spain	Castillo, L (reprint author), Univ Granada, ETSI Informat & Telecomunicac, Dept Ciencias Comp, Granada 18071, Spain.	L.Castillo@decsai.ugr.es	Boticario, Jesus/H-5874-2011; Prieto, Ignacio/B-5361-2013				Albers M, 2002, TECH COMMUN, V49, P45; Alm I, 2003, INTERACT COMPUT, V15, P109, DOI 10.1016/S0953-5438(02)00027-9; Ambite J.L., 2002, 14 INN APPL ART INT; Armengol E, 2000, MACH LEARN, V41, P259, DOI 10.1023/A:1007677713969; ARMENGOL E, 2005, EXPLANATION AWARE CO; Armengol E, 2003, ARTIF INTELL REV, V20, P121, DOI 10.1023/A:1026076312419; BACCHUS F, 2001, INT JOINT C ART INT, P417; BISSON G, 1995, P 2 INT C BUILD SHAR, P236; Borrajo D., 2007, EXPERT SYSTEMS APPL, V33, P389; Camacho D, 2005, AI COMMUN, V18, P15; Castillo L, 2006, P 16 INT C AUT PLANN; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DOYLE D, 2003, TCDCS200341 TRIN COL; EDELKAMP S, 2002, AIPS 02; EDELKAMP S, 2004, LANGUAGE 2004 INT PL; Emde W., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); FESENMAIER DR, 2003, P ENTER 2003 C, P29; FOX M, 2001, P IJCAI 01; Fox M., 2002, PDDL2 1 EXTENSION PD; HEFLIN J, 2002, ONTOLOGIES SEMANTIC, P63; Hoffmann J, 2003, J ARTIF INTELL RES, V20, P291; Hoffmann J, 2001, J ARTIF INTELL RES, V14, P253; Horvath T, 2001, MACH LEARN, V43, P53, DOI 10.1023/A:1007668716498; KNOBLOCK CA, 1998, IEEE INTELLIGENT SYS, V13; KRAMER LA, 2005, P ICAPS 05, P272; Mcsherry D, 2005, ARTIF INTELL REV, V24, P179, DOI 10.1007/s10462-005-4612-x; Nau D, 2003, J ARTIF INTELL RES, V20, P379; Nielsen J., 1993, USABILITY ENG; PATCH K, 2001, TECHNOLOGY RES NEWS; Plaza E, 1997, LECT NOTES ARTIF INT, V1221, P180; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; SANTOS OC, 2004, IAIC 04 WORKSH ART I; SMITH D, 2004, P ICAPS 04; [Anonymous], 2002, P ENTER 2002 C, P1	35	13	14	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	FEB	2008	34	2					1318	1332		10.1016/j.eswa.2006.12.029		15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	263TH	WOS:000253238900054	
J	Lin, SW; Tseng, TY; Chou, SY; Chen, SC				Lin, Shih-Wei; Tseng, Tsung-Yuan; Chou, Shuo-Yan; Chen, Shih-Chieh			A simulated-annealing-based approach for simultaneous parameter optimization and feature selection of back-propagation networks	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						back-propagation network; simulated-annealing; optimization; feature selection	ARTIFICIAL NEURAL-NETWORKS; FEATURE SUBSET-SELECTION; GLOBAL OPTIMIZATION; MULTILAYER PERCEPTRONS; GENETIC ALGORITHM	The back-propagation network (BPN) can be used in various fields. Nevertheless, different problems may require different parameter settings for network architectures. Rule of thumb or "trial and error" methods are usually used to determine them. However, these methods may lead worse parameter settings for network architectures. On the other hand, although a dataset may contain many features, not all features are beneficial for classification in BPN. Therefore, a simulated-annealing-based approach, denoted as SA + BPN, is proposed to obtain the optimal parameter settings for network architectures of BPN, and to select the beneficial subset of features which result in a better classification. In order to evaluate the proposed SA + BPN approach, datasets in UCI Machine Learning Repository are used to evaluate the performance of the proposed approach. The experimental results show that the parameter settings for network architectures obtained by the proposed approach are better than those of other approaches. When the feature selection is taken into consideration, the classification accuracy rates of most datasets are increased. Therefore, the developed approach can be utilized to find out the optimal parameter settings for network architectures of BPN, and discover the useful features effectively. (C) 2007 Elsevier Ltd. All rights reserved.	[Chou, Shuo-Yan; Chen, Shih-Chieh] Natl Taiwan Univ Sci & Technol, Dept Ind Management, Taipei, Taiwan		swlin@cc.hfu.edu.tw	Lin, Shih-Wei/F-7247-2011				Abe N, 2006, PATTERN RECOGN, V39, P737, DOI 10.1016/j.patcog.2005.11.007; Berry MJA, 2001, DATA MINING TECHNIQU; Castillo PA, 2000, NEUROCOMPUTING, V35, P149, DOI 10.1016/S0925-2312(00)00302-7; Castillo PA, 2000, NEURAL PROCESS LETT, V12, P115, DOI 10.1023/A:1009684907680; Ghosh Ranadhir, 2003, Int J Neural Syst, V13, P13, DOI 10.1142/S0129065703001364; Gupta JND, 1999, OMEGA-INT J MANAGE S, V27, P679, DOI 10.1016/S0305-0483(99)00027-4; Han J., 2003, DATA MINING CONCEPTS; Hettich S., 1998, UCI REPOSITORY MACHI; KHAW JFC, 1995, NEUROCOMPUTING, V7, P225, DOI 10.1016/0925-2312(94)00013-I; Kim KJ, 2000, EXPERT SYST APPL, V19, P125, DOI 10.1016/S0957-4174(00)00027-0; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Lee KD, 2005, EXPERT SYST APPL, V29, P1, DOI 10.1016/j.eswa.2005.01.004; Lezoray O, 2001, Int J Neural Syst, V11, P33, DOI 10.1016/S0129-0657(01)00048-5; Liu H, 1998, FEATURE SELECTION KN; Malhotra R, 2003, OMEGA-INT J MANAGE S, V31, P83, DOI 10.1016/S0305-0483(03)00016-1; MATSUNAGA A, 1999, P IEEE NUCL SCI S SE, V2, P948; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Qiu XP, 2007, EXPERT SYST APPL, V32, P1094, DOI 10.1016/j.eswa.2006.02.020; REED R, 1993, IEEE T NEURAL NETWOR, V4, P740, DOI 10.1109/72.248452; ROMELIN HE, 1994, J GLOBAL OPTIM, V5, P101, DOI 10.1007/BF01100688; Romeijn HE, 1999, J OPTIMIZ THEORY APP, V101, P403, DOI 10.1023/A:1021745728358; Salzberg SL, 1997, DATA MIN KNOWL DISC, V1, P317, DOI 10.1023/A:1009752403260; Sexton RS, 1998, EUR J OPER RES, V106, P570, DOI 10.1016/S0377-2217(97)00292-0; Sexton RS, 1999, EUR J OPER RES, V114, P589, DOI 10.1016/S0377-2217(98)00114-3; Sexton RS, 2006, EUR J OPER RES, V168, P1009, DOI 10.1016/j.ejor.2004.05.018; Sivagaminathan RK, 2007, EXPERT SYST APPL, V33, P49, DOI 10.1016/j.eswa.2006.04.010; Subasi A, 2005, EXPERT SYST APPL, V28, P701, DOI 10.1016/j.eswa.2004.12.027; Verikas A, 2002, PATTERN RECOGN LETT, V23, P1323, DOI 10.1016/S0167-8655(02)00081-8; Wang TY, 2007, EXPERT SYST APPL, V32, P193, DOI 10.1016/j.eswa.2005.11.007; YAMAZAKI A, 2002, P IEEE NEURAL NETWOR, V1, P547; Yan HM, 2006, EXPERT SYST APPL, V30, P272, DOI 10.1016/j.eswa.2005.07.022; YANG J, 1998, IEEE INTELL SYST APP, V34, P44; YEUNG DS, 2002, P IEEE MACHINE LEARN, V4, P1751, DOI 10.1109/ICMLC.2002.1175337; Zhang L, 2005, MECH SYST SIGNAL PR, V19, P271, DOI 10.1016/j.ymssp.2004.03.002	36	22	24	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	FEB	2008	34	2					1491	1499		10.1016/j.eswa.2007.01.014		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	263TH	WOS:000253238900070	
J	Vernikos, GS; Parkhill, J				Vernikos, Georgios S.; Parkhill, Julian			Resolving the structural features of genomic islands: A machine learning approach	GENOME RESEARCH			English	Article							GROUP-A STREPTOCOCCUS; ESCHERICHIA-COLI; PATHOGENICITY ISLANDS; SALMONELLA-ENTERICA; STAPHYLOCOCCUS-AUREUS; VIRULENCE FACTORS; SEQUENCE; EVOLUTION; DNA; AGALACTIAE	Large inserts of horizontally acquired DNA that contain functionally related genes with limited phylogenetic distribution are often referred to as genomic islands (GIs), and structural definitions of these islands, based on common features, have been proposed. Although a large number of mobile elements fall well within the GI definition, there are several concerns about the structural consensus for GIs: The current GI definition was put forward 10 yr ago when only 12 complete bacterial genomes were available, a large number of GIs deviate from that definition, and in silico predictions assuming a full/partial GI structural model bias the sampling of the GI structural space toward "well-structured" GIs. In this study, the structural features of genomic regions are sampled by a hypothesis-free, bottom-up search, and these are exploited in a machine learning approach with the aim of explicitly quantifying and modeling the contribution of each feature to the GI structure. Performing a whole-genome-based comparative analysis between 37 strains of three different genera and 12 outgroup genomes, 668 genomic regions were sampled and used to train structural GI models. The data show that, overall, GIs from the three different genera fall into distinct, genus-specific structural families. However, decreasing the taxa resolution, by studying GI structures across different genus boundaries, provides models that converge on a fairly similar GI structure, further suggesting that GIs can be seen as a superfamily of mobile elements, with core and variable structural features, rather than a well-defined family.	[Vernikos, Georgios S.; Parkhill, Julian] Wellcome Trust Sanger Inst, Cambridge CB10 1SA, England	Parkhill, J (reprint author), Wellcome Trust Sanger Inst, Wellcome Trust Genome Campus, Cambridge CB10 1SA, England.	parkhill@sanger.ac.uk	Parkhill, Julian/G-4703-2011	Parkhill, Julian/0000-0002-7069-5958			ALTSCHUL SF, 1997, NUCLEIC ACIDS RES, V25, P3402; Banks DJ, 2003, INFECT IMMUN, V71, P7079, DOI 10.1128/IAI.71.12.7079-7086.2003; Beres SB, 2006, P NATL ACAD SCI USA, V103, P7059, DOI 10.1073/pnas.0510279103; Blattner FR, 1997, SCIENCE, V277, P1453, DOI 10.1126/science.277.5331.1453; Bolotin A, 2004, NAT BIOTECHNOL, V22, P1554, DOI 10.1038/nbt1034; Bolotin A, 2001, GENOME RES, V11, P731, DOI 10.1101/gr.GR-1697R; Broker G, 2004, INT J MED MICROBIOL, V294, P169, DOI 10.1016/j.ijmm.2004.06.018; Broudy TB, 2001, INFECT IMMUN, V69, P1440, DOI 10.1128/IAI.69.3.1440-1443.2001; CARTER D, 2006, GENOME BIOL S1, V7; Carver TJ, 2005, BIOINFORMATICS, V21, P3422, DOI 10.1093/bioinformatics/bti553; Censini S, 1996, P NATL ACAD SCI USA, V93, P14648, DOI 10.1073/pnas.93.25.14648; Deng W, 2003, J BACTERIOL, V185, P2330, DOI 10.1128/JB.185.7.2330-2337.2003; Diep BA, 2006, LANCET, V367, P731, DOI 10.1016/S0140-6736(06)68231-7; Down T, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-419; Down TA, 2002, GENOME RES, V12, P458, DOI 10.1101/gr.216102; Felsenstein J, 1996, MOL BIOL EVOL, V13, P93; Felsenstein J, 1989, CLADISTICS, V5, P164; Fischetti VA, 2007, TRENDS MICROBIOL, V15, P297, DOI 10.1016/j.tim.2007.05.003; Glaser P, 2002, MOL MICROBIOL, V45, P1499, DOI 10.1046/j.1365-2958.2002.03126.x; Glaser P, 2001, SCIENCE, V294, P849, DOI 10.1126/science.1063447; HACKER J, 2002, PATHOGENICITY ISLAND, V1; Hacker J, 2000, ANNU REV MICROBIOL, V54, P641, DOI 10.1146/annurev.micro.54.1.641; Hacker J, 1997, MOL MICROBIOL, V23, P1089, DOI 10.1046/j.1365-2958.1997.3101672.x; Herron-Olson L, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0001120; Holden MTG, 2004, P NATL ACAD SCI USA, V101, P9786, DOI 10.1073/pnas.0402521101; Hoskins J, 2001, J BACTERIOL, V183, P5709, DOI 10.1128/JB.183.19.5709-5717.2001; Hsiao W, 2003, BIOINFORMATICS, V19, P418, DOI 10.1093/bioinformatics/btg004; Jin Q, 2002, NUCLEIC ACIDS RES, V30, P4432, DOI 10.1093/nar/gkf566; Kaper JB, 1999, PATHOGENICITY ISLAND; Kleerebezem M, 2003, P NATL ACAD SCI USA, V100, P1990, DOI 10.1073/pnas.0337704100; Kunst F, 1997, NATURE, V390, P249, DOI 10.1038/36786; Lawrence JG, 1997, J MOL EVOL, V44, P383, DOI 10.1007/PL00006158; Lawrence JG, 1998, P NATL ACAD SCI USA, V95, P9413, DOI 10.1073/pnas.95.16.9413; Mantri Y, 2004, NUCLEIC ACIDS RES, V32, pD55, DOI 10.1093/nar/gkh059; McClelland M, 2001, NATURE, V413, P852, DOI 10.1038/35101614; McClelland M, 2004, NAT GENET, V36, P1268, DOI 10.1038/ng1470; McGillivary G, 2005, INFECT IMMUN, V73, P1927, DOI 10.1128/IAI.73.4.1927-1938.2005; Novick Richard P, 2007, Chem Immunol Allergy, V93, P42; Page RDM, 1996, COMPUT APPL BIOSCI, V12, P357; Parkhill J, 2001, NATURE, V413, P848, DOI 10.1038/35101607; Paulsen IT, 2003, SCIENCE, V299, P2071, DOI 10.1126/science.1080613; Perna NT, 2001, NATURE, V409, P529, DOI 10.1038/35054089; Pridmore RD, 2004, P NATL ACAD SCI USA, V101, P2512, DOI 10.1073/pnas.0307327101; Ramsden AE, 2007, CELL MICROBIOL, V9, P2517, DOI 10.1111/j.1462-5822.2007.00977.x; Rosini R, 2006, MOL MICROBIOL, V61, P126, DOI 10.1111/j.1365-2958.2006.05225.x; SAITOU N, 1987, MOL BIOL EVOL, V4, P406; Schmidt H, 2004, CLIN MICROBIOL REV, V17, P14, DOI 10.1128/CMR.17.1.14-56.2004; Schmidt HA, 2002, BIOINFORMATICS, V18, P502, DOI 10.1093/bioinformatics/18.3.502; Takeuchi F, 2005, J BACTERIOL, V187, P7292, DOI 10.1128/JB.187.21.7292-7308.2005; Tettelin H, 2005, P NATL ACAD SCI USA, V102, P13950, DOI 10.1073/pnas.0506758102; Tettelin H, 2001, SCIENCE, V293, P498, DOI 10.1126/science.1061217; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Towers RJ, 2004, J CLIN MICROBIOL, V42, P5357, DOI 10.1128/JCM.42.11.5357-5361.2004; Vernikos GS, 2006, BIOINFORMATICS, V22, P2196, DOI 10.1093/bioinformatics/btl369; Vernikos GS, 2007, GENOME BIOL, V8, DOI 10.1186/gb-2007-8-6-r100; Waterhouse JC, 2006, MICROBIOL-SGM, V152, P1777, DOI 10.1099/mic.028647-0; Welch RA, 2002, P NATL ACAD SCI USA, V99, P17020, DOI 10.1073/pnas.252529799; Williams KP, 2002, NUCLEIC ACIDS RES, V30, P866, DOI 10.1093/nar/30.4.866; Zhang LJ, 1997, MOL MICROBIOL, V23, P63, DOI 10.1046/j.1365-2958.1997.1871558.x; Zhang YQ, 2003, MOL MICROBIOL, V49, P1577, DOI 10.1046/j.1365-2958.2003.03671.x	60	18	18	COLD SPRING HARBOR LAB PRESS, PUBLICATIONS DEPT	WOODBURY	500 SUNNYSIDE BLVD, WOODBURY, NY 11797-2924 USA	1088-9051		GENOME RES	Genome Res.	FEB	2008	18	2					331	342		10.1101/gr.7004508		12	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Genetics & Heredity	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Genetics & Heredity	258ID	WOS:000252860700016	
J	Every, MR				Every, Mark R.			Discriminating between pitched sources in music audio	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						audio features; instrument classification; music information retrieval; timbre discrimination	FEATURE-SELECTION; TIMBRES; EXTRACTION; SYSTEM; MELODY	Though humans find it relatively easy to identify and/or isolate different sources within polyphonic music, the emulation of this ability by a computer is a challenging task, and one that has direct relevance to music content description and information retrieval applications. For an automated system without any prior knowledge of a recording, a possible solution is to perform an initial segmentation of the recording into notes or regions with some time-frequency contiguity, and then collect into groups those units that are acoustically similar, and hence have a high likelihood of arising from a common source. This article addresses the second subtask, and provides two main contributions: 1) a derivation of a suboptimal subset out of a wide range of common audio features that maximizes the potential to discriminate between pitched sources in polyphonic music and 2) an estimation of the improvement in accuracy that can be achieved by using features other than pitch in the grouping process. In addition, the hypothesis was tested that more discriminatory features can be obtained through the application of source separation techniques prior to feature computation. Machine learning techniques have been applied to an annotated database of polyphonic recordings (containing 3181 labeled audio segments) spanning a wide range of musical genres. Average source-labeling accuracies of 68% and 76% were obtained with a 10-dimensional feature subset when the number of sources per recording was unknown and known a priori.	Audience Inc, Mountain View, CA 94041 USA	Every, MR (reprint author), Audience Inc, Mountain View, CA 94041 USA.	mark.every@gmail.com					BAKER FB, 1975, J AM STAT ASSOC, V70, P31, DOI 10.2307/2285371; Balasko B., FUZZY CLUSTERING DAT; Bezdek J. C., 1981, PATTERN RECOGNITION; Calinski T, 1974, COMMUN STAT, V3, P1, DOI DOI 10.1080/03610927408827101; CAMBOUROPOULOS E, 2000, P AAAI 2000 WORKSH A, P19; Davy M., 2006, SIGNAL PROCESSING ME; Duda R., 2000, PATTERN CLASSIFICATI; Dunn J. C., 1973, Journal of Cybernetics, V3; Eggink J., 2004, P ICASSP, V4, P217; EGGINK J, 2003, P 4 INT C MUS INF RE; EGGINK J, 2004, P 5 INT C MUS INF RE, P84; Essid S, 2006, IEEE T AUDIO SPEECH, V14, P68, DOI 10.1109/TSA.2005.860351; Every MR, 2006, IEEE T AUDIO SPEECH, V14, P1845, DOI 10.1109/TSA.2005.858528; EVERY MR, 2006, THESIS U YORK YORK; Fraley C, 2002, J AM STAT ASSOC, V97, P611, DOI 10.1198/016214502760047131; Godsmark D, 1999, SPEECH COMMUN, V27, P351, DOI 10.1016/S0167-6393(98)00082-X; Goto M, 2004, SPEECH COMMUN, V43, P311, DOI 10.1016/j.specom.2004.07.001; GREY JM, 1977, J ACOUST SOC AM, V61, P1270, DOI 10.1121/1.381428; Harma A, 2000, J AUDIO ENG SOC, V48, P1011; Herrera-Boyer P, 2003, J NEW MUSIC RES, V32, P3, DOI 10.1076/jnmr.32.1.3.16798; HUBERT LJ, 1976, PSYCHOL BULL, V83, P1072, DOI 10.1037//0033-2909.83.6.1072; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; JENSEN K., 1999, THESIS U COPENHAGEN; Kashino K, 1999, SPEECH COMMUN, V27, P337, DOI 10.1016/S0167-6393(98)00078-8; Kilian J., 2002, P 3 INT C MUS INF RE, P39; KIRLIN PB, 2005, P 6 INT C MUS INF RE, P552; KITAHARA T, 2006, P IEEE INF C AC SPEE, P229; KITAHARA T, 2005, P ISMIR, P558; Gomez E, 2003, J NEW MUSIC RES, V32, P23, DOI 10.1076/jnmr.32.1.23.16799; KLAPURI A, 2003, P STOCKH MUS AC C SM, P587; Lakatos S, 2000, PERCEPT PSYCHOPHYS, V62, P1426, DOI 10.3758/BF03212144; Livshin A, 2006, P 7 INT C MUS INF RE, P95; MADSEN ST, 2006, P 7 INT C MUS INF RE, P57; MAROLT M, 2005, P 2005 EUR C, P1288; MARTINEZ AR, 2004, MODEL BASED CLUSTERI; MCADAMS S, 1995, PSYCHOL RES-PSYCH FO, V58, P177, DOI 10.1007/BF00419633; MILLIGAN GW, 1985, PSYCHOMETRIKA, V50, P159, DOI 10.1007/BF02294245; MISDARIIS N, 1998, 16 INT C AC 135 M AC; PAIVA RP, 2005, P 6 INT S MUS INF RE, P175; Peeters G., 2004, LARGE SET AUDIO FEAT; Pickens J, 2003, J NEW MUSIC RES, V32, P223, DOI 10.1076/jnmr.32.2.223.16742; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Pudil P, 1998, IEEE INTELL SYST APP, V13, P66, DOI 10.1109/5254.671094; RIZO D, 2006, P 7 INT C MUS INF RE, P61; SAKURABA Y, 2004, P IEEE INT C AC SPEE, V4, P273; Smoorenburg G. F., 1970, FREQUENCY ANAL PERIO, P397; Somol P, 2004, IEEE T PATTERN ANAL, V26, P900, DOI 10.1109/TPAMI.2004.28; THIBAULT F, 2004, THESIS MCGILL U MONT; VINCENT E, 2004, P ISMIR, P576; Webb A.R., 2002, STAT PATTERN RECOGNI; *ISO IEC, 2004, N6828 ISOIEC JTC1SC2; *MAGN, MP3 MUS MUS LIC	52	6	6	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1558-7916		IEEE T AUDIO SPEECH	IEEE Trans. Audio Speech Lang. Process.	FEB	2008	16	2					267	277		10.1109/TASL.2007.908128		11	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	254TY	WOS:000252612100003	
J	Lee, K; Slaney, M				Lee, Kyogu; Slaney, Malcolm			Acoustic chord transcription and key extraction from audio using key-dependent HMMs trained on synthesized audio	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						acoustic chord transcription; hidden Markov model (HMM); key-dependent models; key extraction; symbolic music files		We describe an acoustic chord transcription system that uses symbolic data to train hidden Markov models and gives best-of-class frame-level recognition results. We avoid the extremely laborious task of human annotation of chord names and boundaries-which must be done to provide machine learning models with ground truth-by performing automatic harmony analysis on symbolic music files. In parallel, we synthesize audio from the same symbolic files and extract acoustic feature vectors which are in perfect alignment with the labels. We, therefore, generate a large set of labeled training data with a minimal amount of human labor. This allows for richer models. Thus, we build 24 key-dependent HMMs, one for each key, using the key information derived from symbolic data. Each key model defines a unique state-transition characteristic and helps avoid confusions seen in the observation vector. Given acoustic input, we identify a musical key by choosing a key model with the maximum likelihood, and we obtain the chord sequence from the optimal state path of the corresponding key model, both of which are returned by a Viterbi decoder. This not only increases the chord recognition accuracy, but also gives key information. Experimental results show the models trained on synthesized data perform very well on real recordings, even though the labels automatically generated from symbolic data are not 100% accurate. We also demonstrate the robustness of the tonal centroid feature, which outperforms the conventional chroma feature.	[Lee, Kyogu; Slaney, Malcolm] Stanford Univ, Ctr Comp Res Music & Acoust, Stanford, CA 94305 USA; [Lee, Kyogu] Gracenote Inc, Emeryville, CA 94608 USA; [Slaney, Malcolm] Yahoo Res, Santa Clara, CA 94054 USA	Lee, K (reprint author), Stanford Univ, Ctr Comp Res Music & Acoust, Stanford, CA 94305 USA.		Lee, Kyogu/D-3049-2013				BROWN J, 1990, J ACOUST SOC AM, V89, P425; Fujishima T., 1999, P INT COMP MUS C ICM, P464; Harte C., 2006, P 1 ACM WORKSH AUD M, P21, DOI 10.1145/1178723.1178727; Harte C., 2005, P AUD ENG SOC SPAIN; HURRON D, HUMDRUM TOOLKIT SOFT; LEE K, 2008, P INT WORKSH AD MULT; Lee K., 2007, P 8 INT C MUS INF RE, P245; Lee K., 2006, P INT COMP MUS C NEW, P306; LEE K, 2006, UNPUB MUS INF RETR E; LEE K, 2006, P INT C MUS INF RETR, P133; Lee K., 2006, P 1 ACM WORKSH AUD M, P11, DOI 10.1145/1178723.1178726; MORMAN J, 2006, P AUD MUS COMP MULT, P1, DOI 10.1145/1178723.1178725; POLLACK AW, 2000, SOUNDSCAPES INFO; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Sheh A., 2003, P INT C MUS INF RETR, P185; SLEATOR D, 2001, MELISMA MUSIC ANALYZ; Temperley D., 2001, COGNITION BASIC MUSI	17	27	27	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1558-7916		IEEE T AUDIO SPEECH	IEEE Trans. Audio Speech Lang. Process.	FEB	2008	16	2					291	301		10.1109/TASL.2007.914399		11	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	254TY	WOS:000252612100005	
J	Mion, L; De Poli, G				Mion, Luca; De Poli, Giovanni			Score-independent audio features for description of music expression	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						audio classification; expression communication; music understanding	PERFORMANCE; INTENTIONS; NETWORKS; SYSTEMS; MODEL	During a music performance, the musician adds expressiveness to the musical message by changing timing, dynamics, and timbre of the musical events to communicate an expressive intention. Traditionally, the analysis of music expression is based on measurements of the deviations of the acoustic parameters with respect to the written score. In this paper, we employ machine learning techniques to understand the expressive communication and to derive audio features at an intermediate level, between music intended as a structured language and notes intended as sound at a more physical level. We start by extracting audio features from expressive performances that were recorded by asking the musicians to perform in order to convey different expressive intentions. We use a sequential forward selection procedure to rank and select a set of features for a general description of the expressions, and a second one specific for each instrument. We show that higher recognition ratings are achieved by using a set of four features which can be specifically related to qualitative descriptions of the sound by physical metaphors. These audio features can be used to retrieve expressive content on audio data, and to design the next generation of search engines for music information retrieval.	[Mion, Luca; De Poli, Giovanni] Univ Padua, Dept Informat Engn, I-35131 Padua, Italy	Mion, L (reprint author), Univ Padua, Dept Informat Engn, I-35131 Padua, Italy.	luca.mion@dei.unipd.it; depoli@dei.unipd.it					Bigand E, 2005, ANN NY ACAD SCI, V1060, P429, DOI 10.1196/annals.1360.036; BONINI F, 2006, J NEW MUSIC RES, V35, P197; Bresin R, 2000, COMPUT MUSIC J, V24, P44, DOI 10.1162/014892600559515; Bresin R, 1998, J NEW MUSIC RES, V27, P239, DOI 10.1080/09298219808570748; CAMBOUROPOULOS E, 2001, P ICMC2001 HAV, P290; Camurri A, 2005, IEEE MULTIMEDIA, V12, P43, DOI 10.1109/MMUL.2005.2; Canazza S, 2003, J NEW MUSIC RES, V32, P281, DOI 10.1076/jnmr.32.3.281.16862; Canazza S, 2000, IEEE MULTIMEDIA, V7, P79; CANAZZA S, 2004, P IEEE, V92, P286; CLYNES M, 1990, MUSIC PERCEPT, V7, P403; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Dannenberg R.B., 1997, P INT COMP MUS C, P344; De Poli G, 1998, J NEW MUSIC RES, V27, P293, DOI 10.1080/09298219808570750; DESAIN P, 1991, COMPUTERS MUSIC RES, V3, P43; Duda R. O., 2001, PATTERN CLASSIFICATI; Friberg A, 2000, COMPUT MUSIC J, V24, P23, DOI 10.1162/014892600559407; Friberg Anders, 2002, P INT COMP MUS C GOT, P365; HIRAGA R, 2000, P 2000 MUS 35 IPSJ, P67; IMMERSEEL LV, 1992, J ACOUST SOC AM, V91, P3511; Juslin PN, 2001, MUSIC EMOTION THEORY; Juslin PN, 2001, MUSIC EMOTION THEORY, P305; Laurenti N, 2007, IEEE T AUDIO SPEECH, V15, P531, DOI 10.1109/TASL.2006.881685; LEMAN M, 2000, P C DIG AUD EFF DAFX, P125; Lu L, 2006, IEEE T AUDIO SPEECH, V14, P5, DOI 10.1109/TSA.2005.860344; McKay C., 2004, P INT C MUS INF RETR, P525; MION L, 2006, VIRTUAL REALITY, V10, P62, DOI 10.1007/s10055-006-0029-3; MION L, 2003, P STOCKH MUS AC C SM, P557; RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714; Serra X., 1997, MUSICAL SIGNAL PROCE, P91; STONE M, 1974, J R STAT SOC B, V36, P111; TODD NPM, 1992, J ACOUST SOC AM, V91, P3540; WHITNEY AW, 1971, IEEE T COMPUT, VC 20, P1100, DOI 10.1109/T-C.1971.223410; WIDMER G, 2004, J NEW MUSIC RES, V33, P211; Zoelzer U., 2002, DAFX DIGITAL AUDIO E	34	11	11	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1558-7916		IEEE T AUDIO SPEECH	IEEE Trans. Audio Speech Lang. Process.	FEB	2008	16	2					458	466		10.1109/TASL.2007.913743		9	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	254TY	WOS:000252612100019	
J	Fernandez-Escribano, G; Kalva, H; Cuenca, P; Orozco-Barbosa, L; Garrido, A				Fernandez-Escribano, Gerardo; Kalva, Hari; Cuenca, Pedro; Orozco-Barbosa, Luis; Garrido, Antonio			A fast MB mode decision algorithm for MPEG-2 to H.264 P-frame transcoding	IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY			English	Article						H.264; inter-frame; machine learning; MPEG-2; transcoding	MOTION ESTIMATION; VIDEO TRANSCODER; OPTIMIZATION	The H.264 standard achieves much higher coding efficiency than the MPEG-2 standard, due to its improved inter-and intra-prediction modes at the expense of higher computational complexity. Transcoding MPEG-2 video to H.264 is important to enable gradual migration to H.264. However, given the significant differences between the MPEG-2 and the H.264 coiling algorithms, transcoding is a much more complex task and new approaches to transcoding are necessary. The main problems that need to be addressed in the design of an efficient heterogeneous MPEG-2/H.264 transcoder are: the inter-frame prediction, the transform coding and the intra-frame prediction. In this paper, we focus our attention on the inter-frame prediction, the most computationally intensive task involved in the transcoding process. This paper presents a novel macroblock (MB) mode decision algorithm for P-frame prediction based on machine learning techniques to be used as part of a very low complexity MPEG-2 to H.264 video transcoder. Since coding mode decisions take up the most resources in video transcoding, a fast MB mode estimation would lead to reduced complexity. The proposed approach is based on the hypothesis that MB coding mode decisions in H.264 video have a correlation with the distribution of the motion compensated residual in MPEG-2 video. We use machine learning tools to exploit the correlation and construct decision trees to classify the incoming MPEG-2 MBs into one of the several coding modes in H.264. The proposed approach reduces the H.264 MB mode computation process into a decision tree lookup with very low complexity. Experimental results show that the proposed approach reduces the MB mode selection complexity by as much as 95% while maintaining the coding efficiency. Finally, we conduct a comparative study with some of the most prominent fast inter-prediction methods for H.264 presented in the literature. Our results show that the proposed approach achieves the best results for video transcoding applications.	[Fernandez-Escribano, Gerardo; Cuenca, Pedro; Orozco-Barbosa, Luis; Garrido, Antonio] Univ Castilla La Mancha, Inst Invest & Informat Albacete, Albacete 02071, Spain; [Kalva, Hari] Florida Atlantic Univ, Dept Comp Sci & Engn, Boca Raton, FL 33431 USA	Fernandez-Escribano, G (reprint author), Univ Castilla La Mancha, Inst Invest & Informat Albacete, Albacete 02071, Spain.	gerardo@dsi.uclm.es; pcuenca@dsi.uclm.es; lorozco@dsi.uclm.es; antonjo@dsi.uclm.es					Bjontegaard G, 2001, 13 VCEG M33 M AUST T; CHEN G, 2004, P 12 ANN ACM INT C M, P300, DOI 10.1145/1027527.1027596; CHEN Z, 2002, JVT ISO IEC MPEG ITU; Dogan S, 1999, ELECTRON LETT, V35, P863, DOI 10.1049/el:19990594; Jeon B., 2003, JVTJ033; Kalva H., 2004, P IEEE CONS COMM NET, P657; Kalva H, 2003, P SOC PHOTO-OPT INS, V5117, P341, DOI 10.1117/12.498998; Kim D, 2006, LECT NOTES COMPUT SC, V4319, P1067; Kim YH, 2004, ELECTRON LETT, V40, P1172, DOI 10.1049/el:20046155; Lee JY, 2003, LECT NOTES COMPUT SC, V2899, P410; LEE YK, 2006, P IEEE INT C MULT EX, P57; LIM KP, 2003, JVT1020 MPEG VCE; LU X, 2005, P 2005 IEEE INT S CI, P1246; Ostermann J., 2004, IEEE Circuits and Systems Magazine, V4, DOI 10.1109/MCAS.2004.1286980; PETLJANSKI B, 2006, P ICCE 2006 JAN, P419; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Shanableh T, 2000, IEEE T MULTIMEDIA, V2, P101, DOI 10.1109/6046.845014; SU J, 2005, P IEEE S CIRC SYST M, P1234; Sullivan Gary J., 2001, VCEGN81; Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497; Tourapis AM, 2002, IEEE T CIRC SYST VID, V12, P934, DOI 10.1109/TCSVT.2002.804894; Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P18, DOI 10.1109/MSP.2003.1184336; Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P688, DOI 10.1109/TCSVT.2003.815168; Witten I. H., 2005, DATA MINING PRACTICA; Wu D, 2005, IEEE T CIRC SYST VID, V15, P953, DOI 10.1109/TCSVT.2005.848304; Yang M, 2004, IEE P-VIS IMAGE SIGN, V151, P369, DOI 10.1049/ip-vis:20040720; [Anonymous], 2003, EV SHEET MOT EST; *JVT ISO IEC MPEG, 2006, JVTF100JM102 JVT ISO; *MPEG IMPL STUD GR, 2002, N4964 MPEG IMPL STUD	29	6	7	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1051-8215		IEEE T CIRC SYST VID	IEEE Trans. Circuits Syst. Video Technol.	FEB	2008	18	2					172	185		10.1109/TCSVT.2008.918115		14	Engineering, Electrical & Electronic	Engineering	274VG	WOS:000254029900003	
J	Stratigopoulos, HG; Makris, Y				Stratigopoulos, Haralarnpos-G.; Makris, Yiorgos			Error moderation in low-cost machine-learning-based analog/RF testing	IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS			English	Article						alternate testing; analog circuits; circuit testing; machine learning; RF circuits	FAULT-DIAGNOSIS; NEURAL-NETWORK; TEST-GENERATION; CMOS OPAMPS; CIRCUITS; CLASSIFICATION; ALGORITHMS	Machine-learning-based test methods for analog/RF devices have been the subject of intense investigation over the last decade. However, despite the significant cost benefits that these methods promise, they have seen a limited success in replacing the traditional specification testing, mainly due to the incurred test error which, albeit small, cannot meet industrial standards. To address this problem, we introduce a neural system that is trained not only to predict the pass/fail labels of devices based on a set of low-cost measurements, as aimed by the previous machine-learning-based test methods, but also to assess the confidence in this prediction. Devices for which this confidence is insufficient are then retested through the more expensive specification testing in order to reach an accurate test decision. Thus, this two-tier test approach sustains the high accuracy of specification testing while leveraging the low cost of machine-learning-based testing. In addition, by varying the desired level of confidence, it enables the exploration of the tradeoff between test cost and test accuracy and facilitates the development of cost-effective test plans. We discuss the structure and the training. algorithm of an ontogenic neural network which is embodied in the neural system in the first tier, as well as the extraction of appropriate measurements such that only a small fraction of devices are funneled to the second tier. The proposed test-error-moderation method is demonstrated on a switched-capacitor filter and an ultrahigh-frequency receiver front end.	[Stratigopoulos, Haralarnpos-G.] TIME Lab, CNRS, F-38031 Grenoble, France; [Makris, Yiorgos] Yale Univ, Dept Elect Engn, New Haven, CT 06520 USA; [Makris, Yiorgos] Yale Univ, Dept Comp Sci, New Haven, CT 06520 USA	Stratigopoulos, HG (reprint author), TIME Lab, CNRS, F-38031 Grenoble, France.	haralampos.stratigopoulos@dma.fr; yiorgos.makris@yale.edu					AKBAY SS, 2006, P IEEE INT TEST C; Akbay S. S., 2004, Proceedings. 22nd IEEE VLSI Test Symposium; Akbay SS, 2004, IEEE T ADV PACKAGING, V27, P352, DOI 10.1109/TADVP.2004.828819; AKBAY SS, 2005, P VLSI TEST S, P243; Bhattacharya S., 2004, Proceedings. International Test Conference 2004 (IEEE Cat. No.04CH37586); Bishop C.M., 1995, NEURAL NETWORKS PATT; Biswas S., 2005, Proceedings. Design, Automation and Test in Europe; Brown D., 2004, Proceedings. International Test Conference 2004 (IEEE Cat. No.04CH37586); Burgess N, 1994, Int J Neural Syst, V5, P59, DOI 10.1142/S0129065794000074; COLLINS P, 1994, ELECTRON LETT, V30, P1846, DOI 10.1049/el:19941281; Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017; de Gyves J. P., 2003, Proceedings. International Test Conference 2003 (IEEE Cat. No.03CH37494); ELLOUZ S, 2006, P IEEE INT TEST C; FREAN M, 1992, NEURAL COMPUT, V4, P946, DOI 10.1162/neco.1992.4.6.946; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Gallagher L., 1990, Hypermedia, V2; Gizopoulos D, 2006, ADV ELECT TESTING; Goldberg DE, 1989, GENETIC ALGORITHMS S; Gregorian R., 1986, ANALOG MOS INTEGRATE; HONAVAR V, 1993, INFORM SCIENCES, V70, P75, DOI 10.1016/0020-0255(93)90049-R; Horowitz P, 1989, ART ELECT; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Lindermeir WM, 1999, IEEE T COMPUT AID D, V18, P1353, DOI 10.1109/43.784126; Maidon Y, 1997, IEE P-CIRC DEV SYST, V144, P149, DOI 10.1049/ip-cds:19971146; Pan CY, 1999, IEEE T CIRCUITS-II, V46, P554; Pan CY, 1997, IEEE T COMPUT AID D, V16, P1173; Parekh R, 2000, IEEE T NEURAL NETWOR, V11, P436, DOI 10.1109/72.839013; Raghunathan A., 2004, Proceedings. International Test Conference 2004 (IEEE Cat. No.04CH37586); SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; Somayajula SS, 1996, IEEE T CIRCUITS-II, V43, P703, DOI 10.1109/82.539002; Spina R, 1997, IEEE T CIRCUITS-II, V44, P188, DOI 10.1109/82.558453; SRINIVASAN G, 2006, P VLSI TEST S, P222; Srinivasan G, 2005, IEE P-COMPUT DIG T, V152, P632, DOI 10.1049/ip-cdt:20045074; Stopjakova V, 2005, IEEE T RELIAB, V54, P441, DOI [10.1109/TR.2005.853041, 10.1109/TR.2005.0853041]; Stopjakova V, 2004, J ELECTRON TEST, V20, P25, DOI 10.1023/B:JETT.0000009311.63472.d6; Stratigopoulos HGD, 2005, IEEE T COMPUT AID D, V24, P1760, DOI 10.1109/TCAD.2005.855835; Variyam PN, 2002, IEEE T COMPUT AID D, V21, P349, DOI 10.1109/43.986428; Variyam PN, 2000, IEEE T COMPUT AID D, V19, P1189, DOI 10.1109/43.875320; Voorakaranam R., 2002, Proceedings 2002 Design, Automation and Test in Europe Conference and Exhibition, DOI 10.1109/DATE.2002.998268; Voorakaranam R., 2003, Proceedings. International Test Conference 2003 (IEEE Cat. No.03CH37494); Yang ZR, 2000, IEEE T COMPUT AID D, V19, P142; YU S, 1994, ELECTRON LETT, V30, P695, DOI 10.1049/el:19940472	42	25	25	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0278-0070		IEEE T COMPUT AID D	IEEE Trans. Comput-Aided Des. Integr. Circuits Syst.	FEB	2008	27	2					339	351		10.1109/TCAD.2007.907232		13	Computer Science, Hardware & Architecture; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic	Computer Science; Engineering	254TT	WOS:000252611600012	
J	Garcia-Pedrajas, N; Fyfe, C				Garcia-Pedrajas, Nicolas; Fyfe, Colin			Evolving output codes for multiclass problems	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION			English	Article						evolutionary computation; multiclass; output coding; pattern recognition	CLASSIFIER ENSEMBLES; NEURAL-NETWORKS; ALGORITHMS; DIVERSITY; MACHINES; KERNEL; DESIGN; SIZE	In this paper, we propose an evolutionary approach to the design of output codes for multiclass pattern recognition problems. This approach has the advantage of taking into account the different aspects that are relevant for a code matrix to achieve a good performance. We define a fitness function made up of five terms that refer to overall classifier accuracy, binary classifiers' accuracy, classifiers' diversity, minimum Hamming distance among codewords, and margin of classification. These live factors have not been considered together in previous works. We perform a study of these five terms to obtain a fitness function with three of them. We test our approach on 27 datasets from the UCI Machine Learning Repository, using three different base learners: C4.5, neural networks, and support vector machines. We show a better performance than most of the current standard methods, namely, randomly generated codes with approximately equal random split, codes designed using a CHC algorithm, and one-vs-all and one-vs-one methods.	[Garcia-Pedrajas, Nicolas] Univ Cordoba, Dept Comp & Numer Anal, E-14071 Cordoba, Spain; [Fyfe, Colin] Univ Paisley, Sch Comp, Paisley PA1 2BE, Renfrew, Scotland	Garcia-Pedrajas, N (reprint author), Univ Cordoba, Dept Comp & Numer Anal, Campus Rabanales, E-14071 Cordoba, Spain.	npedrajas@uco.es; colin.fyfe@paisley.ac.uk					Afifi A. A., 1979, STAT ANAL COMPUTER O; Aha DW, 1997, AI APPLICATIONS, V11, P13; Allwein EL, 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; ALPAYDIN E, 1999, P INT C NEUR NETW IC; ANAND R, 1995, IEEE T NEURAL NETWOR, V6, P117, DOI 10.1109/72.363444; Anderson TW, 1984, INTRO MULTIVARIATE S; Bartlett PL, 1998, IEEE T INFORM THEORY, V44, P525, DOI 10.1109/18.661502; Bebis G, 1997, NEUROCOMPUTING, V17, P167, DOI 10.1016/S0925-2312(97)00050-7; Bose R.C., 1960, Information and Control, V3, DOI 10.1016/S0019-9958(60)90287-4; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Cano JR, 2003, IEEE T EVOLUT COMPUT, V7, P561, DOI 10.1109/TEVC.2003.819265; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Clark P., 1991, P 5 EUR WORK SESS LE, P151; Crammer K, 2002, MACH LEARN, V47, P201, DOI 10.1023/A:1013637720281; Cristianini N., 2000, INTRO SUPPORT VECTOR; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Eshelman L., 1990, CHC ADAPTIVE SEARCH; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 1996, ANOTHER APPROACH POL; Goldberg DE, 1989, GENETIC ALGORITHMS S; Hastie T, 1998, ANN STAT, V26, P451; HETTICH S, 1998, UCL REPOSITORY MACHN; Ivakhnenko A. G., 1994, Pattern Recognition and Image Analysis, V4; James G, 1998, J COMPUT GRAPH STAT, V7, P377, DOI 10.2307/1390710; Keerthi SS, 2003, NEURAL COMPUT, V15, P1667, DOI 10.1162/089976603321891855; Knerr S., 1990, NEUROCOMPUTING ALGOR; Kong E., 1995, WHY ERROR CORRECTING; Kuncheva LI, 2005, PATTERN RECOGN LETT, V26, P83, DOI 10.1016/j.patrec.2004.08.019; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; Louis S.J., 1997, LECT NOTES COMPUTER, V1213, P431; Mason L, 2000, MACH LEARN, V38, P243, DOI 10.1023/A:1007697429651; MASULLI F, 2000, P MULT CLASS SYST MC, P107; Michalewicz Z, 1994, GENETIC ALGORITHMS P; Miller GF, 1991, NEURAL NETWORKS, V4, P53; Passerini A, 2004, IEEE T NEURAL NETWOR, V15, P45, DOI 10.1109/TNN.2003.820841; Pujol O, 2006, IEEE T PATTERN ANAL, V28, P1007, DOI 10.1109/TPAMI.2006.116; Quinlan J.R., 1993, C 4 5 PROGRAMS MACHI; Rifkin R, 2004, J MACH LEARN RES, V5, P101; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1, P318; Schapire R., 1997, P 14 INT C MACH LEAR, P313; Schapire RE, 1998, ANN STAT, V26, P1651; SHAPIRE RE, 1997, P 14 INT C MACH LEAR, P313; Utschick W, 2001, NEURAL COMPUT, V13, P1065, DOI 10.1162/08997660151134334; Weigend A. S., 1991, P INT JOINT C NEURAL, V1, P837; WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968; Windeatt T., 2001, Information Fusion, V2, DOI 10.1016/S1566-2535(01)00029-X; Windeatt T., 2003, Information Fusion, V4, DOI 10.1016/S1566-2535(02)00101-X; Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585893; YULE G, 1900, PHIL T, V194, P247	51	3	3	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1089-778X		IEEE T EVOLUT COMPUT	IEEE Trans. Evol. Comput.	FEB	2008	12	1					93	106		10.1109/TEVC.2007.894201		14	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	257VO	WOS:000252827000006	
J	Lee, HE; Park, KH; Bien, ZZ				Lee, Hyong-Euk; Park, Kwang-Hyun; Bien, Zeungnam Zenn			Iterative fuzzy clustering algorithm with supervision to construct probabilistic fuzzy rule base from numerical data	IEEE TRANSACTIONS ON FUZZY SYSTEMS			English	Article						classification; clustering with supervision; fuzzy rule base; iterative fuzzy clustering; probabilistic fuzzy logic	CLASSIFICATION; VALIDITY; CLASSIFIERS; MODEL	To deal with data patterns with linguistic ambiguity and with probabilistic uncertainty in a single framework, we construct an interpretable probabilistic fuzzy rule-based system that requires less human intervention and less prior knowledge than other state of the art methods. Specifically, we present a new iterative fuzzy clustering algorithm that incorporates a supervisory scheme into an unsupervised fuzzy clustering process. The learning process starts in a fully unsupervised manner using fuzzy c-means (FCM) clustering algorithm and a cluster validity criterion, and then gradually constructs meaningful fuzzy partitions over the input space. The corresponding fuzzy rules with probabilities are obtained through an iterative learning process of selecting clusters with supervisory guidance based on the notions of cluster-pureness and class-separability. The proposed algorithm is tested first with synthetic data sets and benchmark data sets from the UCI Repository of Machine Learning Database and then, with real facial expression data and TV viewing data.	[Lee, Hyong-Euk; Park, Kwang-Hyun; Bien, Zeungnam Zenn] Korea Adv Inst Sci & Technol, Human Friendly Welfare Robot Syst Engn Res Ctr, Dept Comp Sci & Elect Engn, Taejon 305701, South Korea	Lee, HE (reprint author), Korea Adv Inst Sci & Technol, Human Friendly Welfare Robot Syst Engn Res Ctr, Dept Comp Sci & Elect Engn, Taejon 305701, South Korea.	helee@ctrsys.kaist.ac.kr; akaii@ee.kaist.ac.kr; zbien@ee.kaist.ac.kr					Abonyi J, 2003, PATTERN RECOGN LETT, V24, P2195, DOI 10.1016/S0167-8655(03)00047-3; Abonyi J, 2003, INT J APPROX REASON, V32, P1, DOI 10.1016/S0888-613X(02)00076-2; BEZDEK JC, 1981, PATTERN RECOGNIT FUZ; BIEN ZZ, 2004, 2 INT C ART INT ENG; Bien ZZ, 2006, ASSIST TECHN RES SER, V18, P75; DEVIJVER PA, 1982, PATTERN RECOGNIT STA; DO JH, 2005, P IEEE RSJ INT C INT, P2193; Doctor F, 2005, IEEE T SYST MAN CY A, V35, P55, DOI 10.1109/TSMCA.2004.838488; Eick CF, 2004, PROC INT C TOOLS ART, P774; Gabrys B, 2000, IEEE T NEURAL NETWOR, V11, P769, DOI 10.1109/72.846747; GORNEZ J, 2005, P IEEE C EV COMP SEP, V2, P1637; Guan SU, 2004, IEEE T SYST MAN CY B, V34, P381, DOI 10.1109/TSMCB.2003.817030; Han JS, 2004, PROCEEDINGS OF THE SIXTH IASTED INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND CONTROL, P307; Ishibuchi H, 2004, FUZZY SET SYST, V141, P59, DOI 10.1016/S0165-0114(03)00114-3; Ishibuchi H, 2005, IEEE T SYST MAN CY B, V35, P359, DOI 10.1109/TSMCB.2004.842257; JANG H, 2005, P IEEE INT C SYST MA; KUNCHEVA LI, 2000, FUZZY CLASSIFIER DES; LAM BSY, 2005, P IEEE INT C SYST MA, V1, P798; LEE C, 1997, P IEEE INT C SYST MA, V3, P2147; LEE SW, 2005, P INT FUZZ SYST ASS, P1309; Liu Z, 2005, IEEE T FUZZY SYST, V13, P848, DOI 10.1109/TFUZZ.2005.859326; Mitchell T, 1997, MACHINE LEARNING; Mohanta DK, 2005, IEEE T POWER SYST, V20, P2117, DOI 10.1109/TPWRS.2005.857932; NANDEDKAR AV, 2006, P INT C PATT REC AUG, V2, P650; NEFTI S, 2004, P IEEE INT C SYST MA, V5, P4786; Pal NR, 2005, IEEE T FUZZY SYST, V13, P517, DOI 10.1109/TFUZZ.2004.840099; PAL NR, 1995, IEEE T FUZZY SYST, V3, P370, DOI 10.1109/91.413225; Pedrycz W, 2004, PATTERN RECOGN LETT, V25, P469, DOI 10.1016/j.patrec.2003.12.010; PEDRYCZ W, 1992, IEEE T NEURAL NETWOR, V3, P794; Sheng WG, 2005, IEEE T SYST MAN CY B, V35, P1156, DOI 10.1109/TSMCB.2005.850173; Simpson P. K., 1993, IEEE Transactions on Fuzzy Systems, V1, DOI 10.1109/TFUZZ.1993.390282; SIMPSON PK, 1992, IEEE T NEURAL NETWOR, V3, P776, DOI 10.1109/72.159066; Waltman L., 2005, Proceedings of the IEEE International Conference on Fuzzy Systems (IEEE Cat. No. 05CH37680); WANG LX, 1992, IEEE T SYST MAN CYB, V22, P1414, DOI 10.1109/21.199466; XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677	35	5	8	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1063-6706		IEEE T FUZZY SYST	IEEE Trans. Fuzzy Syst.	FEB	2008	16	1					263	277		10.1109/TFUZZ.2007.903314		15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	262XS	WOS:000253182600022	
J	Abernethy, J; Evgeniou, T; Toubia, O; Vert, JP				Abernethy, Jacob; Evgeniou, Theodoros; Toubia, Olivier; Vert, Jean-Philippe			Eliciting consumer preferences using robust adaptive choice questionnaires	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article; Proceedings Paper	International Workshop on Customer Relationship Management - Data Mining Meets Marketing	NOV 18-19, 2005	New  York, NY			marketing; machine learning; statistical; interactive systems; personalization; knowledge acquisition	CONJOINT-ANALYSIS; EXPERIMENTAL-DESIGN; MARKETING-RESEARCH; COMMERCIAL USE; HETEROGENEITY; MODELS	We propose a framework for designing adaptive choice-based conjoint questionnaires that are robust to response error. It is developed based on a combination of experimental design and statistical learning theory principles. We implement and test a specific case of this framework using Regularization Networks. We also formalize within this framework the polyhedral methods recently proposed in marketing. We use simulations, as well as an online market research experiment with 500 participants, to compare the proposed method to benchmark methods. Both experiments show that the proposed adaptive questionnaires outperform the existing ones in most cases. This work also indicates the potential of using machine-learning methods in marketing.	[Abernethy, Jacob] Univ Calif Berkeley, Dept Comp Sci, Berkeley, CA 94720 USA; [Evgeniou, Theodoros] INSEAD, F-77300 Fontainebleau, France; [Toubia, Olivier] Columbia Business Sch, Marketing Div, New York, NY 10027 USA; [Vert, Jean-Philippe] Ecole Mines, F-77300 Fontainebleau, France	Abernethy, J (reprint author), Univ Calif Berkeley, Dept Comp Sci, 387 Soda Hall, Berkeley, CA 94720 USA.	jake@eecs.berkeley.edu; theodoros.evgeniou@insead.edu; ot2107@columbia.edu; jean-philippe.vert@mines.org					ADDELMAN S, 1962, TECHNOMETRICS, V4, P47, DOI 10.2307/1266171; ALLENBY GM, 1995, J MARKETING RES, V32, P152, DOI 10.2307/3152044; Allenby GM, 1999, J ECONOMETRICS, V89, P57; ARORA N, 2001, J CONSUMER RES, V28; Ben Akiva M., 1985, DISCRETE CHOICE ANAL; BETTMAN JR, 1998, J CONSUMER RES, V25; BUNCH DS, 1994, COMPARISON EXPT DESI; CARROLL JD, 1995, J MARKETING RES, V32, P385, DOI 10.2307/3152174; CATTIN P, 1982, J MARKETING, V46, P44, DOI 10.2307/1251701; Chaloner K, 1995, STAT SCI, V10, P273, DOI 10.1214/ss/1177009939; Cohn DA, 1996, J ARTIF INTELL RES, V4, P129; COOK RD, 1980, TECHNOMETRICS, V22, P315, DOI 10.2307/1268315; Cortes C, 1995, MACH LEARN, V20, P1; Cui DP, 2005, MARKET SCI, V24, P595, DOI 10.1287/mksc.1050.0123; EVGENIOU T, 2005, MARKETING SCI, V24; Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316; FORD I, 1989, TECHNOMETRICS, V31, P49, DOI 10.2307/1270364; Green P.E., 1990, J MARKETING, V4, P3; GREEN PE, 1978, J CONSUM RES, V5, P103, DOI 10.1086/208721; Greene WH, 2003, ECONOMETRIC ANAL; HAUSER JR, 2006, MARKETING SCI; HAUSER JR, 2005, MARKETING SCI, V24; Huber J, 1996, J MARKETING RES, V33, P307, DOI 10.2307/3152127; KANNINEN B, 2002, J MARKETING RES, V36, P214; Kuhfeld W. F., 2005, MARKETING RES METHOD; KUHFELD WF, 1994, J MARKETING RES, V31, P545, DOI 10.2307/3151882; Lenk PJ, 1996, MARKET SCI, V15, P173, DOI 10.1287/mksc.15.2.173; McFadden D., 1974, FRONTIERS ECONOMETRI, P105; MITCHELL TJ, 1974, TECHNOMETRICS, V16, P203, DOI 10.2307/1267940; Newey W.K., 1994, HDB ECONOMETRICS, V4; Pukelsheim F., 1993, OPTIMAL DESIGN EXPT; Rossi PE, 2003, MARKET SCI, V22, P304, DOI 10.1287/mksc.22.3.304.17739; Saar-Tsechansky M, 2004, MACH LEARN, V54, P153, DOI 10.1023/B:MACH.0000011806.12374.c3; Sandor Z, 2001, J MARKETING RES, V38, P430, DOI 10.1509/jmkr.38.4.430.18904; SONNEVEND G, 1985, LECTURE NOTES CONTRO, V84, P866; SRINIVAS.V, 1973, PSYCHOMETRIKA, V38, P337, DOI 10.1007/BF02291658; STEINBERG DM, 1984, TECHNOMETRICS, V26, P71, DOI 10.2307/1268097; Tikhonov A. N., 1977, SOLUTIONS ILLPOSED P; Tong S., 2000, P 17 INT C MACH LEAR; TOUBIA O, 2003, MARKETING SCI, V22; Toubia O, 2004, J MARKETING RES, V41, P116, DOI 10.1509/jmkr.41.1.116.25082; Vapnik VN, 1998, STAT LEARNING THEORY; WARMUTH MK, 2002, ADV NEURAL INFORM PR, V14; WITTINK DR, 1989, J MARKETING, V53, P91, DOI 10.2307/1251345; *ACA MAN SAWT SOFT, 1996, ACA SYST AD CONJ ANA; [Anonymous], 1993, ADAPTIVE DECISION MA; *SAWT SOFTW, 2002, ACA 5 0 TECHN PAP	47	5	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	FEB	2008	20	2					145	155		10.1109/TKDE.2007.1031		11	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	241WH	WOS:000251686000001	
J	Hsieh, JG; Lin, YL; Jeng, JH				Hsieh, Jer-Guang; Lin, Yih-Lon; Jeng, Jyh-Horng			Preliminary studyon Wilcoxon learning machines	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						artificial neural network (ANN); kernel-based Wilcoxon regressor (KWR); support vector machine (SVM); Wilcoxon learning machine	FUZZY NEURAL-NETWORKS; FUNCTION APPROXIMATION; UNIVERSAL APPROXIMATORS; ALGORITHM; OUTLIERS	As is well known in statistics, the resulting linear regressors by using the rank-based Wilcoxon approach to linear regression problems are usually robust against (or insensitive to) outliers. This motivates us to introduce in this paper the Wilcoxon approach to the area, of machine learning. Specifically, we investigate four new learning machines, namely Wilcoxon neural network (WNN), Wilcoxon generalized radial basis function network (WGRBFN), Wilcoxon fuzzy neural network (WFNN), and kernel-based Wilcoxon regressor (KWR). These provide alternative learning machines when faced with general nonlinear learning problems. Simple weights updating rules based on gradient descent will be derived. Some numerical examples will be provided to compare the robustness against outliers for various learning machines. Simulation results show that the Wilcoxon learning machines proposed in this paper have good robustness against outliers. We firmly believe that the Wilcoxon approach will provide a promising methodology for many machine learning problems.	[Hsieh, Jer-Guang] Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung 804, Taiwan; [Hsieh, Jer-Guang] I Shou Univ, Kaohsiung, Kaohsiung Cty, Taiwan; [Jeng, Jyh-Horng] CSIST, Kaohsiung, Taiwan	Hsieh, JG (reprint author), Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung 804, Taiwan.	jghsieh@mail.ee.nsysu.edu.tw; yihlon.lin@msa.hinet.net; jjeng@isu.edu.tw					Blake C.L., 1998, UCI MACHINE LEARNING; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Chuang CC, 2002, IEEE T NEURAL NETWOR, V13, P1322, DOI 10.1109/TNN.2002.804227; Chuang CC, 2004, NEUROCOMPUTING, V56, P123, DOI 10.1016/S0925-2312(03)00436-3; Chuang CC, 2001, IEEE T FUZZY SYST, V9, P810; Chuang CC, 2000, IEEE T NEURAL NETWOR, V11, P1067, DOI 10.1109/72.870040; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cristianini N., 2000, INTRO SUPPORT VECTOR; HARTMAN EJ, 1990, NEURAL COMPUT, V2, P210, DOI 10.1162/neco.1990.2.2.210; Hogg R., 2005, INTRO MATH STAT; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Kecman V, 2001, LEARNING SOFT COMPUT; KOSKO B, 1994, IEEE T COMPUT, V43, P1329, DOI 10.1109/12.324566; Lee CC, 1999, IEEE T SYST MAN CY B, V29, P674, DOI 10.1109/3477.809023; Park J., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.246; Peng JX, 2006, IEEE T NEURAL NETWOR, V17, P1439, DOI 10.1109/TNN.2006.880860; Perfetti R, 2006, IEEE T NEURAL NETWOR, V17, P1085, DOI 10.1109/TNN.2006.875967; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Romero E, 2007, IEEE T NEURAL NETWOR, V18, P959, DOI 10.1109/TNN.2007.891656; RUMELHART GE, 1986, EXPLORATION MICROSTR, V1, P318; Tsai HH, 2000, IEEE T SYST MAN CY B, V30, P217, DOI 10.1109/3477.826964; Wan S, 2006, IEEE T NEURAL NETWOR, V17, P1424, DOI 10.1109/TNN.2006.880581; WANG L, 1992, IEEE T NEURAL NETWOR, V5, P807; Wang L. X., 1997, COURSE FUZZY SYSTEMS; Wang WY, 1997, IEEE T SYST MAN CY B, V27, P740; Xu Y, 2006, IEEE T NEURAL NETWOR, V17, P19, DOI 10.1109/TNN.2005.860857; Zhao WX, 2004, COMPUT CHEM ENG, V28, P1403, DOI 10.1016/j.compchemeng.2003.10.006	28	13	13	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	FEB	2008	19	2					201	211		10.1109/TNN.2007.904035		11	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	264FM	WOS:000253272100001	
J	Huang, KZ; Yang, HQ; King, I; Lyu, MR				Huang, Kaizhu; Yang, Haiqin; King, Irwin; Lyu, Michael R.			Maxi-min margin machine: Learning large margin classifiers locally and globally	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						classification; kernel methods; large margin; learning locally and globally; second-order cone programming	SUPPORT VECTOR MACHINES	In this paper, we propose a novel large margin classifier, called the maxi-min margin machine (M-4). This model learns the decision boundary both locally and globally. In comparison, other large margin classifiers construct separating hyperplanes only either locally or globally. For example, a state-of-the-art large margin classifier, the support vector machine (SVM), considers data only locally, while another significant model, the minimax probability machine (MPM), focuses on building the decision hyperplane exclusively based on the global information. As a major contribution, we show that SVM yields the same solution as M-4 when data satisfy certain conditions, and MPM can be regarded as a relaxation model of M-4. Moreover, based on our proposed local and global view of data, another popular model, the linear discriminant analysis, can easily be interpreted and extended as well. We describe the M-4 model definition, provide a geometrical interpretation, present theoretical justifications, and propose a practical sequential conic programming method to solve the optimization problem. We also show how to exploit Mercer kernels to extend M-4 for nonlinear classifications. Furthermore, we perform a series of evaluations on both synthetic data sets and real-world benchmark data sets. Comparison with SVM and MPM demonstrates the advantages of our new model.	[Huang, Kaizhu] Fujitsu Res & Dev Ctr Co Ltd, Informat Technol Lab, Beijing 100016, Peoples R China; [Yang, Haiqin] Titanium Technol Ltd, Shenzhen 518000, Peoples R China; [King, Irwin] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China	Huang, KZ (reprint author), Fujitsu Res & Dev Ctr Co Ltd, Informat Technol Lab, Beijing 100016, Peoples R China.	kzhuang@cn.fujitsu.com; austin.yang@titanium-tech.com; king@cse.cuhk.edu.hk; lyu@cse.cuhk.edu.hk					Blake C. L., 1998, UCI REPOSITORY MACHI; BREIMAN L, 1997, 460 U CAL STAT DEPT; Fukunaga K., 1990, INTRO STAT PATTERN R; HUANG K., 2004, P 21 INT C MACH LEAR, P401; Huang KZ, 2004, J MACH LEARN RES, V5, P1253; Ivanov V.V., 1962, SOV MATH DOKL, V3, P981; KOHAVI R, 1995, P 14 INT JOINT C ART, P338; Lanckriet G. R. G., 2002, J MACHINE LEARNING R, V3, P555; Lee YJ, 2007, IEEE T NEURAL NETWOR, V18, P1, DOI 10.1109/TNN.2006.883722; Lin CF, 2002, IEEE T NEURAL NETWOR, V13, P464, DOI 10.1109/72.991432; Lobo MS, 1998, LINEAR ALGEBRA APPL, V284, P193, DOI 10.1016/S0024-3795(98)10032-0; Lotlikar R, 2000, IEEE T PATTERN ANAL, V22, P623, DOI 10.1109/34.862200; Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P195, DOI 10.1109/TNN.2002.806647; Nesterov Y., 1994, INTERIOR POINT POLYN; PENG J, 2001, P 2001 IEEE COMP SOC, V1, P58; Platt J., 1998, MSRTR9814; PRUESSNER A, 2003, P OPT SOFTW STAT ART; Scholkopf B., 2002, LEARNING KERNELS; Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766; Sturm JF, 2000, HIGH PERFORMANCE OPT, P157; Suykens JAK, 2003, IEEE T NEURAL NETWOR, V14, P447, DOI 10.1109/TNN.2003.809414; TIKHONOV AN, 1963, DOKL AKAD NAUK SSSR+, V151, P501; Tong S., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); Vapnik VN, 1998, STAT LEARNING THEORY; Vapnik V.N., 1999, NATURE STAT LEARNING; VASIN VV, 1970, MATH NOTES, V7, P161, DOI 10.1007/BF01093105; Zhu J., 2003, ADV NEURAL INFORM PR, V16	27	24	30	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	FEB	2008	19	2					260	272		10.1109/TNN.2007.905855		13	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	264FM	WOS:000253272100005	
J	Amasyali, MF; Ersoy, O				Amasyali, M. Fatih; Ersoy, Okan			Cline: A new decision-tree family	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						classifier combination; decision forests; decision trees; learning (artificial intelligence); machine learning; multivariate decision trees; pattern classification; pattern recognition	SELECTION	A new family of algorithm called Cline that provides a number of methods to construct and use multivariate decision trees is presented. We report experimental results for two types of data: synthetic data to visualize the behavior of the algorithms and publicly available eight data sets. The new methods have been tested against 23 other decision-tree construction algorithms based on benchmark data sets. Empirical results indicate that our approach achieves better classification accuracy compared to other algorithms.	[Amasyali, M. Fatih] Yildiz Tech Univ, Dept Comp Engn, TR-34349 Istanbul, Turkey; [Ersoy, Okan] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA	Amasyali, MF (reprint author), Yildiz Tech Univ, Dept Comp Engn, TR-34349 Istanbul, Turkey.	mfatih@ce.yildiz.edu.tr; ersoy@purdue.edu					ALPAYDIN E, 2004, INTRO MACHINE LEARNI, P135; AMASYALI MF, 2005, P ICSC C COMP INT ME, P1; Blake C. L., 1998, UCI REPOSITORY MACHI; BREIMAN L, 1999, 567 U CAL DEPT STAT; Breiman L, 1984, CLASSIFICATION REGRE; Fisher RA, 1936, ANN EUGENIC, V7, P179; Kohonen T., 2001, SELF ORGANIZING MAPS, P245; Li XB, 2003, IEEE T SYST MAN CY A, V33, P194, DOI 10.1109/TSMCA.2002.806499; Li YH, 2005, IEEE T NEURAL NETWOR, V16, P1547, DOI 10.1109/TNN.2005.852864; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; Loh WY, 1997, STAT SINICA, V7, P815; Yildiz OT, 2005, INT J PATTERN RECOGN, V19, P323, DOI 10.1142/S0218001405004125; Yildiz OT, 2001, IEEE T NEURAL NETWOR, V12, P1539; Yildiz OT, 2005, LECT NOTES ARTIF INT, V3720, P473	14	7	7	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	FEB	2008	19	2					356	363		10.1109/TNN.2007.910729		8	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	264FM	WOS:000253272100014	
J	Wang, JM; Fleet, DJ; Hertzmann, A				Wang, Jack M.; Fleet, David J.; Hertzmann, Aaron			Gaussian process dynamical models for human motion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						machine learning; motion; tracking; animation; stochastic processes; time series analysis	NONLINEAR DIMENSIONALITY REDUCTION; PRINCIPAL COMPONENT ANALYSIS; EM ALGORITHM; INTERPOLATION	We introduce Gaussian process dynamical models (GPDMs) for nonlinear time series analysis, with applications to learning models of human pose and motion from high-dimensional motion capture data. A GPDM is a latent variable model. It comprises a low-dimensional latent space with associated dynamics, as well as a map from the latent space to an observation space. We marginalize out the model parameters in closed form by using Gaussian process priors for both the dynamical and the observation mappings. This results in a nonparametric model for dynamical systems that accounts for uncertainty in the model. We demonstrate the approach and compare four learning algorithms on human motion capture data, in which each pose is 50-dimensional. Despite the use of small data sets, the GPDM learns an effective representation of the nonlinear dynamics in these spaces.	[Wang, Jack M.; Fleet, David J.; Hertzmann, Aaron] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 2E4, Canada	Wang, JM (reprint author), Univ Toronto, Dept Comp Sci, 40 St George St, Toronto, ON M5S 2E4, Canada.	jmwang@dgp.toronto.edu; fleet@cs.toronto.edu; hertzman@dgp.toronto.edu					Arikan O, 2002, ACM T GRAPHIC, V21, P483; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; BISSACCO A, 2005, P IEEE INT C COMP VI, V1, P421; Bowden Richard, 2000, P IEEE WORKSH HUM MO, P10; BRAINARD D, 1997, J OPT SOC AM A, V7, P1393; BRAND M, 2000, P SIGGRAPH 2000, P183, DOI 10.1145/344779.344865; Caffo BS, 2005, J ROY STAT SOC B, V67, P235, DOI 10.1111/j.1467-9868.2005.00499.x; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DESILVA V, 2003, 15 P ANN C NEUR INF, P705; ELGAMMAL A, 2004, P CVPR, V2, P681, DOI 10.1109/CVPR.2004.1315230; ELGAMMAL A, 2004, P CVPR, V1, P478, DOI 10.1109/CVPR.2004.1315070; Ghahramani Z., 1996, CRGTR962 U TOR DEP C; Giese MA, 2000, INT J COMPUT VISION, V38, P59, DOI 10.1023/A:1008118801668; Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755; Howe NR, 2000, ADV NEUR IN, V12, P820; IJSPEERT AJ, 2002, 15 P ANN C NEUR INF, P1523; Ilg W., 2004, INT J HUM ROBOT, V1, P613, DOI 10.1142/S0219843604000320; Jenkins O. C., 2004, P INT C MACH LEARN, P441; Kovar L, 2002, ACM T GRAPHIC, V21, P473; Lawrence N, 2005, J MACH LEARN RES, V6, P1783; Lawrence N. D., 2006, P 23 INT C MACH LEAR, P513, DOI 10.1145/1143844.1143909; LAWRENCE ND, 2006, CD0603 U SHEFF DEP C; LAWRENCE ND, 2007, P 11 INT C ART INT S; Lee JH, 2002, ACM T GRAPHIC, V21, P491; Li Y, 2002, ACM T GRAPHIC, V21, P465; MacKay D., 2003, INFORM THEORY INFERE; MOLINATANCO L, 2000, P IEEE WORKSH HUM MO, P137; Moon Kooksang, 2006, P C COMP VIS PATT RE, V1, P198; Mukai T, 2005, ACM T GRAPHIC, V24, P1062, DOI 10.1145/1073204.1073313; MURASE H, 1995, INT J COMPUT VISION, V1, P5; MURRAYSMITH R, 2005, P 2 INT WORKSH DET S, P110; Neal R, 1999, LEARNING GRAPHICAL M, P355; Neal R. M., 1996, BAYESIAN LEARNING NE; OGAWA A, 1998, P IEEE INT C AC SPEE, V1, P181, DOI 10.1109/ICASSP.1998.674397; OH SM, 2005, P 10 IEE INT C COMP, V2, P1161; ORMONEIT D, 2001, 13 P ANN C NEUR INF, P894; PAVLOVIC V, 2001, 13 P ANN C NEUR INF, P981; PLESS R, 2003, P 10 INT C COMP VIS, V2, P1433; RAHIMI A, 2005, P IEEE C COMP VIS PA, V1, P868; RASMUSSEN CE, 2004, 16 P ANN C NEUR INF, P751; Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559; ROWEIS S, 2001, KALMAN FILTERING NEU, P175, DOI 10.1002/0471221546.ch6; Roweis S, 1998, ADV NEUR IN, V10, P626; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; RUBIO A, 1997, P IEEE INT C AC SPEE, V1, P895; Shi JQ, 2005, STAT COMPUT, V15, P31, DOI 10.1007/s11222-005-4787-7; Shumway R. H., 1982, Journal of Time Series Analysis, V3, DOI 10.1111/j.1467-9892.1982.tb00349.x; SIDENBLADH H, 2002, P 7 EUR C COMP VIS, V1, P784; SIDENBLADH H, 2000, P 6 EUR C COMP VIS D, V2, P702; Sminchisescu C., 2004, P INT C MACH LEARN I, P759; SMITH GA, 2000, CUEDFINFENGTR345 CAM; SNELSON E, 2006, 18 P ANN C NEUR INF, P1257; SOLAK E, 2003, 15 P ANN C NEUR INF, P1033; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tipping ME, 1999, J ROY STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; Urtasun R., 2005, P 10 IEEE INT C COMP, V1, P403; Urtasun R., 2006, THESIS ECOLE POLYTEC; Urtasun R., 2006, P CVPR, V1, P238; Urtasun R, 2006, COMPUT VIS IMAGE UND, V104, P157, DOI 10.1016/j.cviu.2006.08.006; VANOVERSCHEE P, 1994, AUTOMATICA, V30, P75, DOI 10.1016/0005-1098(94)90230-5; WANG JM, 2006, 18 P ANN C NEUR INF, P1441; WEI GCG, 1990, J AM STAT ASSOC, V85, P699, DOI 10.2307/2290005; Yacoob Y, 1999, COMPUT VIS IMAGE UND, V73, P232, DOI 10.1006/cviu.1998.0726	63	79	87	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2008	30	2					283	298		10.1109/TPAMI.2007.1167		16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	240IC	WOS:000251580300007	
J	Liu, WF; Pokharel, PP; Principe, JC				Liu, Weifeng; Pokharel, Puskal P.; Principe, Jose C.			The kernel least-mean-square algorithm	IEEE TRANSACTIONS ON SIGNAL PROCESSING			English	Article						kernel methods; least mean square; Tikhonov regularization	COMPONENT ANALYSIS; REGULARIZATION; STABILITY; NETWORKS	The combination of the famed kernel trick and the least-mean-square (LMS) algorithm provides an interesting sample-by-sample update for an adaptive filter in reproducing kernel Hilbert spaces (RKHS), which is named in this paper the KLMS. Unlike the accepted view in kernel methods, this paper shows that in the finite training data case, the KLMS algorithm is well posed in RKHS without the addition of an extra regularization term to penalize solution norms as was suggested by Kivinen [Kivinen, Smola and Williamson, "Online Learning With Kernels," IEEE Transactions on Signal Processing, vol. 52, no. 8, pp. 2165-2176, Aug. 2004] and Smale [Smale and Yao, "Online Learning Algorithms," Foundations in Computational Mathematics, vol. 6, no. 2, pp. 145-176, 2006]. This result is the main contribution of the paper and enhances the present understanding of the LMS algorithm with a machine learning perspective. The effect of the KLMS step size is also studied from the viewpoint of regularization. Two experiments are presented to support our conclusion that with finite data the KLMS algorithm can be readily used in high dimensional spaces and particularly in RKHS to derive nonlinear, stable algorithms with comparable performance to batch, regularized solutions.	[Liu, Weifeng; Pokharel, Puskal P.; Principe, Jose C.] Univ Florida, Dept Elect & Comp Engn, Computat NeuroEngn Lab, Gainesville, FL 32611 USA	Liu, WF (reprint author), Univ Florida, Dept Elect & Comp Engn, Computat NeuroEngn Lab, Gainesville, FL 32611 USA.	weifeng@cnel.ufl.edu; pokharel@cnel.ufl.edu; principe@cnel.ufl.edu					Argyriou A., 2005, P 18 C LEARN THEOR, P338; ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI 10.2307/1990404; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; Caponnetto A, 2006, J MACH LEARN RES, V7, P2565; Catala A, 2000, NEURAL PROCESS LETT, V11, P185, DOI 10.1023/A:1009607425536; CHAPELLE O, 2002, MACHINE LEARNING; Engel Y., 2004, IEEE T SIGNAL PROCES, V52; Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316; Fierro RD, 1997, SIAM J SCI COMPUT, V18, P1223, DOI 10.1137/S1064827594263837; Frieb T, 1999, P EUR S ART NEUR NET, P245; GIROSI F, 1995, NEURAL COMPUT, V7, P219, DOI 10.1162/neco.1995.7.2.219; Golub G. H., 1989, MATRIX COMPUTATIONS; Hadamard J, 1902, PRINCETON U B, P49; Haykin S., 1998, NEURAL NETWORKS COMP; Haykin S, 2002, ADAPTIVE FILTER THEO; Kim KI, 2005, IEEE T PATTERN ANAL, V27, P1351; Kivinen J, 2004, IEEE T SIGNAL PROCES, V52, P2165, DOI 10.1109/TSP.2004.830991; Micchelli CA, 2005, J MACH LEARN RES, V6, P1099; Neumaier A, 1998, SIAM REV, V40, P636, DOI 10.1137/S0036144597321909; PARZEN E, 2005, 23 STANF U APPL MATH; Platt J., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.213; Poggio T., 2003, NOTICES AMS, V50, P537; POKHAREL P, 2007, P INT C AC SPEECH SI, V3, P1421; Rudin W., 1991, FUNCTIONAL ANAL; Sayed A.H., 2003, FUNDAMENTALS ADAPTIV; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Smale S, 2006, FOUND COMPUT MATH, V6, P145, DOI 10.1007/s10208-004-0160-z; Stewart G.W., 1973, INTRO MATRIX COMPUTA; TIKHONOV AN, 1977, SOLUTION 3 POSED PRO; Vapnik V. N, 1995, NATURE STAT LEARNING; Vogel CR, 1997, SIAM PROC S, P1; Zhang T, 2005, NEURAL COMPUT, V17, P2077, DOI 10.1162/0899766054323008	32	42	45	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1053-587X		IEEE T SIGNAL PROCES	IEEE Trans. Signal Process.	FEB	2008	56	2					543	554		10.1109/TSP.2007.907881		12	Engineering, Electrical & Electronic	Engineering	254GU	WOS:000252575200009	
J	Cortes, C; Mohri, M; Rastogi, A; Riley, M				Cortes, Corinna; Mohri, Mehryar; Rastogi, Ashish; Riley, Michael			On the computation of the relative entropy of probabilistic automata	INTERNATIONAL JOURNAL OF FOUNDATIONS OF COMPUTER SCIENCE			English	Article							HIDDEN MARKOV-MODELS	We present an exhaustive analysis of the problem of computing the relative entropy of two probabilistic automata. We show that the problem of computing the relative entropy of unambiguous probabilistic automata can be formulated as a shortest-distance problem over an appropriate semiring, give efficient exact and approximate algorithms for its computation in that case, and report the results of experiments demonstrating the practicality of our algorithms for very large weighted automata. We also prove that the computation of the relative entropy of arbitrary probabilistic automata is PSPACE-complete. The relative entropy is used in a variety of machine learning algorithms and applications to measure the discrepancy of two distributions. We examine the use of the symmetrized relative entropy in machine learning algorithms and show that, contrarily to what is suggested by a number of publications in that domain, the symmetrized relative entropy is neither positive definite symmetric nor negative definite symmetric, which limits its use and application in kernel methods. In particular, the convergence of training for learning algorithms is not guaranteed when the symmetrized relative entropy is used directly as a kernel, or as the operand of an exponential as in the case of Gaussian Kernels. Finally, we show that our algorithm. for the computation of the entropy of an unambiguous probabilistic automaton can be generalized to the computation of the norm of an unambiguous probabilistic automaton by using a monoid morphism. In particular, this yields efficient algorithms for the computation of the L-p-norm. of a probabilistic automaton.	[Cortes, Corinna; Riley, Michael] Google Res, New York, NY 10011 USA; [Mohri, Mehryar; Rastogi, Ashish] NYU, Courant Inst Math Sci, New York, NY 10012 USA; [Mohri, Mehryar] Google Res, New York, NY 10012 USA	Cortes, C (reprint author), Google Res, 76 9th Ave, New York, NY 10011 USA.	corinna@google.com; mohri@cims.nyu.edu; rastogi@cs.nyu.edu; riley@google.com					BERG C., 1984, HARMONIC ANAL SEMIGR; Berstel J., 1988, RATIONAL SERIES THEI; BLOOM S, 1991, ITERATION THEORIES; Carrasco R. C., 1997, Informatique Theorique et Applications, V31; CORTES C, 2007, IN PRESS INT J FDN C; Cortes C, 2006, LECT NOTES COMPUT SC, V4094, P137; COVER TM, 1989, ELEMENTS INFORM THEO; CSISZAR I, 1997, INFORM THEORY CODINI; Culik K., 1997, HDB FORMAL LANGUAGES, V3, P599; Durbin R., 1998, BIOL SEQUENCE ANAL P; Eilenberg S., 1974, AUTOMATA LANGUAGES M, VA; Eisner J., 2001, P ESSLLI WORKSH FIN; Garey MR, 1979, COMPUTERS INTRACTABI; Golub G. H., 1996, MATRIX COMPUTATIONS; KROGH A, 1994, J MOL BIOL, V235, P1501, DOI 10.1006/jmbi.1994.1104; Kuich W., 1986, SEMIRINGS AUTOMATA L; Lehmann D. J., 1977, Theoretical Computer Science, V4, DOI 10.1016/0304-3975(77)90056-1; Lyngso RB, 2002, J COMPUT SYST SCI, V65, P545, DOI 10.1016/S0022-0000(02)00009-0; Mandel MI, 2006, MULTIMEDIA SYST, V12, P3, DOI 10.1007/s00530-006-0032-2; MOHRI M, 1998, 98121010TM AT T LABS; Mohri M., 2002, Journal of Automata, Languages and Combinatorics, V7; MOHRI M, 1996, P 12 BIENN EUR C ART; Mohri M., 2002, International Journal of Foundations of Computer Science, V13, DOI 10.1142/S0129054102000996; MOHRI M, 1997, COMPUTATIONAL LINGUI, V23, P2; Mohri M, 2002, COMPUT SPEECH LANG, V16, P69, DOI 10.1006/csla.2001.0184; Paz A., 1971, INTRO PROBABILISTIC; RABIN MO, 1963, INFORM CONTROL, V6, P230, DOI 10.1016/S0019-9958(63)90290-0; SALOMAA A, 1978, AUTOMATA THEORETIC A; Schoenberg IJ, 1938, T AM MATH SOC, V44, P522, DOI 10.2307/1989894; Scholkopf B., 2002, LEARNING KERNELS; Singer Y, 1997, ADV NEUR IN, V9, P641; STOCHMEYER LJ, 1973, P 5 ANN ACM S THEOR; THOMAS H, 1992, INTRO ALGORITHMS; Topsoe F, 2000, IEEE T INFORM THEORY, V46, P1602, DOI 10.1109/18.850703	34	3	3	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0129-0541		INT J FOUND COMPUT S	Int. J. Found. Comput. Sci.	FEB	2008	19	1					219	242		10.1142/S0129054108005644		24	Computer Science, Theory & Methods	Computer Science	273RH	WOS:000253948900016	
J	Tadeusiewicz, R; Ogiela, L; Ogiela, MR				Tadeusiewicz, Ryszard; Ogiela, Lidia; Ogiela, Marek R.			The automatic understanding approach to systems analysis and design	INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT			English	Article						systems analysis and design; information systems (IS); automatic understanding; cognitive analysis		An innovative approach is presented here as a possible paradigm shift for the new generation of information systems (IS). This is a first attempt in bringing automatic understanding (AU) to the attention of the IT community as a new possibility for the systems analysis and design. The novelty of this new approach is in the previously used method of AU in the area of medical image interpretation to a more general and needed area of systems analysis. It is our conjecture that the enhancement of traditional systems analysis via AU will not only contribute to the development of a new generation IS, but it may become the only way of attacking the problem considering the ever growing number of more and more complex IS with an expected development time 'for yesterday'. The proposed AU approach is, in essence, different from other approaches such as, for example, those based on neural networks or machine learning. AU enables the determination of the meaning of analysed data, both numeric and descriptive. Cognitive methods, on which the AU concept and construct are based, have roots in the psychological and neurophysiological processes of understanding analysed data-as they take place in the brain of a competent and particularly gifted person. (c) 2007 Elsevier Ltd. All rights reserved.	[Tadeusiewicz, Ryszard; Ogiela, Marek R.] AGH Univ Sci & Technol, Inst Automat, PL-30059 Krakow, Poland; [Ogiela, Lidia] AGH Univ Sci & Technol, Fac Management, PL-30059 Krakow, Poland	Ogiela, MR (reprint author), AGH Univ Sci & Technol, Inst Automat, Al Mickiewicza 30, PL-30059 Krakow, Poland.	rtad@agh.edu.pl; logiela@agh.edu.pl; mogiela@agh.edu.pl	Ogiela, Marek/A-7735-2013; Ogiela, Lidia/C-4069-2013				Albus J.S., 2001, ENG MIND INTRO SCI I; IZWORSKI A, 2002, ADV MED HLTH CARE TE, V3, P532; LAUDON KC, 2002, MANAGENTENT INFORM S; LES Z, 2000, COMPUTER GRAPHICS IM, P139; MEYSTEL AM, 2002, INTELLIGENT SYSTEM A; OGIELA L, 2005, THESIS AGH; Ogiela MR, 2003, PATTERN RECOGN, V36, P2441, DOI 10.1016/S0031-3203(03)00089-X; SKORNOROWSKI M, 2000, SYNTACTIC STAT APPRO; TADEUSIEWICZ R, 2005, COMPUTER AIDED INTEL, P257; Tadeusiewicz R., 2004, MED IMAGE UNDERSTAND	10	11	11	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0268-4012		INT J INFORM MANAGE	Int. J. Inf. Manage.	FEB	2008	28	1					38	48		10.1016/j.ijinfomgt.2007.03.005		11	Information Science & Library Science	Information Science & Library Science	278GV	WOS:000254274000005	
J	Fernandez, F; Borrajo, D				Fernandez, Fernando; Borrajo, Daniel			Two steps reinforcement learning	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS			English	Article							CLASSIFIERS; ALGORITHM	When applying reinforcement learning in domains with very large or continuous state spaces, the experience obtained by the learning agent in the interaction with the environment must be generalized. The generalization methods are usually based on the approximation of the value functions used to compute the action policy and tackled in two different ways. On the one hand by using an approximation of the value functions based on a supervized learning method. On the other hand, by discretizing the environment to use a tabular representation of the value functions. In this work, we propose an algorithm that uses both approaches to use the benefits of both mechanisms, allowing a higher performance. The approach is based on two learning phases. In the first one, a learner is used as a supervized function approximator, but using a machine learning technique which also outputs a state space discretization of the environment, such as nearest prototype classifiers or decision trees do. In the second learning phase, the space discretization computed in the first phase is used to obtain a tabular representation of the value function computed in the previous phase, allowing a tuning of such value function approximation. Experiments in different domains show that executing both learning phases improves the results obtained executing only the first one. The results take into account the resources used and the performance of the learned behavior. (c) 2008 Wiley Periodicals, Inc.	[Fernandez, Fernando; Borrajo, Daniel] Univ Carlos III Madrid, Madrid 28911, Spain	Fernandez, F (reprint author), Univ Carlos III Madrid, Avda Univ 30, Madrid 28911, Spain.	ffernand@inf.uc3m.es; dborrajo@ia.uc3m.es					Aha D.W., 1997, LAZY LEARNING; ANDERSON C, 1994, MULTIGRID Q LEARNING; BAIRD LC, 1998, NEURAL INFOR PROCESS, P11; Bellman R. E., 1957, DYNAMIC PROGRAMMING; Bertsekas D., 1996, NEURO DYNAMIC PROGRA; Boyan J. A., 1995, ADV NEURAL INFORM PR, V7; DZEROSKI S, 2001, MACHINE LEARNING, V43; Ernst D, 2005, J MACH LEARN RES, V6, P503; Fernandez F, 2005, J INTELL ROBOT SYST, V43, P161, DOI 10.1007/s10846-005-5137-x; FERNANDEZ F, 2002, P EUR C ART INT ECAI, P280; Fernandez F, 2004, J HEURISTICS, V10, P431, DOI 10.1023/B:HEUR.0000034715.70386.5b; Fernandez F., 2001, International Journal of Robotics & Automation, V16; Fernandez F, 2000, LECT NOTES ARTIF INT, V1856, P292; Fernandez F, 2002, COMPUT INFORM, V21, P205; FORBES JR, 2002, THESIS U CALIFORNIA; Frank E, 1998, P 15 INT C MACH LEAR; Gersho A., 1992, VECTOR QUANTIZATION; KAELBLING LP, 1996, INT J ARTIF INTELLI, V4, P237; KITANO H, 1997, P 15 INT JOINT C ART, P24; KUSHNER HJ, 1990, SIAM J CONTROL OPTIM, V28; Lloyd S. P., 1982, IEEE T INFORM THEORY, VIT-28, P127; Modha DS, 2003, MACH LEARN, V52, P217, DOI 10.1023/A:1024016609528; MONSON CK, 2004, P INT C MACH LEARN A; Moore AW, 1995, MACH LEARN, V21, P199, DOI 10.1007/BF00993591; MOORE AW, 1991, P 8 INT MACH LEARN W; Munos R, 2000, MACH LEARN, V40, P265, DOI 10.1023/A:1007686309208; Munos R, 2002, MACH LEARN, V49, P291, DOI 10.1023/A:1017992615625; Parker LE, 2002, ROBOT TEAMS: FROM DIVERSITY TO POLYMORPHISM, P191; Parker LE, 2002, AUTON ROBOT, V12, P231, DOI 10.1023/A:1015256330750; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Reynolds S I, 2000, P 17 INT C MACH LEAR, P783; Reynolds Stuart Ian, 2002, THESIS U BIRMINGHAM; Santamaria J., 1998, ADAPT BEHAV, V6, P163; SHIBATA T, 2003, P ICDM2003, P641; Smart W. D., 2002, THESIS BROWN U PROVI; Smart W.D., 2000, P 17 INT C MACH LEAR, P903; Sutton R.S., 1999, REINFORCEMENT LEARNI; TESAURO G, 1992, MACH LEARN, V8, P257, DOI 10.1007/BF00992697; Touzet CF, 1997, ROBOT AUTON SYST, V22, P251, DOI 10.1016/S0921-8890(97)00042-0; Tsitsiklis JN, 1996, MACH LEARN, V22, P59, DOI 10.1007/BF00114724; UTHER WTB, 2002, THESIS CARNEGIE MELL; Watkins C, 1989, THESIS CAMBRIDGE U C; Witten I. H., 2000, DATA MINING PRACTICA	43	10	10	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	0884-8173		INT J INTELL SYST	Int. J. Intell. Syst.	FEB	2008	23	2					213	245		10.1002/int.20255		33	Computer Science, Artificial Intelligence	Computer Science	254WG	WOS:000252618100007	
J	Lebrun, G; Charrier, C; Lezoray, O; Cardot, H				Lebrun, Gilles; Charrier, Christophe; Lezoray, Olivier; Cardot, Hubert			Tabu search model selection for SVM	INTERNATIONAL JOURNAL OF NEURAL SYSTEMS			English	Article; Proceedings Paper	7th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL 2006)	SEP 20-23, 2006	Burgos, SPAIN		Univ Burgos	model selection; metaheuristic; tabu search; machine learning; Support Vector Machines; vector quantisation; pattern recognition; data mining	SUPPORT VECTOR MACHINES; CLASSIFICATION; IMAGE; SEGMENTATION; COMPLEXITY; COLOR	A model selection method based on tabu search is proposed to build support vector machines (binary decision functions) of reduced complexity and efficient generalization. The aim is to build a fast and efficient support vector machines classifier. A criterion is defined to evaluate the decision function quality which blends recognition rate and the complexity of a binary decision functions together. The selection of the simplification level by vector quantization, of a feature subset and of support vector machines hyperparameters are performed by tabu search method to optimize the defined decision function quality criterion in order to find a good sub-optimal model on tractable times.	[Lebrun, Gilles; Charrier, Christophe; Lezoray, Olivier] Univ Caen Basse Normandie, GREYC UMR 6072, CNRS, Image Team, F-14050 Caen, France; [Cardot, Hubert] Univ Tours, Lab Informat, EA 2101, F-37200 Tours, France	Lebrun, G (reprint author), Univ Caen Basse Normandie, GREYC UMR 6072, CNRS, Image Team, 6 Bd Marechal Juin, F-14050 Caen, France.	gilles.lebrun@unicaen.fr; christophe.charrier@unicaen.fr; olivier.lezoray@unicaen.fr; hubert.cardot@univ-tours.fr					Abe S., 2005, SUPPORT VECTOR MACHI; ACHARYA T, 2003, DATA MINING MULTIMED; BI J, 2003, ICML, P35; Bishop C.M., 1995, NEURAL NETWORKS PATT; BLAKE C, 1998, ADV KERNEL METHODS S; Breiman L, 1984, CLASSIFICATION REGRE; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Chapelle O, 2000, ADV NEUR IN, V12, P230; CHRISTIANINI N, 2005, JMLR, V6, P37; Coello C.A.C., 2002, EVOLUTIONARY ALGORIT; Collobert R, 2001, J MACH LEARN RES, V1, P143, DOI 10.1162/15324430152733142; Cristianini N., 2000, INTRO SUPPORT VECTOR; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Dong JX, 2005, PATTERN RECOGN LETT, V26, P1849, DOI 10.1016/j.patrec.2005.03.006; Engelbrecht A., 2006, FUNDAMENTALS COMPUTA; Frohlich H., 2004, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V13, DOI 10.1142/S0218213004001818; GERSHO ALLEN, 1991, VECTOR QUANTIZATION; Glover F., 1997, TABU SEARCH; Han J., 2000; HASTIE T, 1997, NIPS, P507; Haykin S., 1999, NEURAL NETWORKS COMP; Herbrich R., 2002, LEARNING KERNEL CLAS; Katagiri S, 2006, PATTERN RECOGN LETT, V27, P1495, DOI 10.1016/j.patrec.2006.02.016; Kecman V., 2001, LEARNING SOFT COMPUT; Keerthi SS, 2006, J MACH LEARN RES, V7, P1493; Korycinski D, 2004, P SOC PHOTO-OPT INS, V5238, P213, DOI 10.1117/12.517487; KUNCHEVA LI, 2004, COMBINING PATTERN CL; Lebrun G, 2007, CELL MOL BIOL, V53, P51, DOI 10.1170/T787; LEBRUN G, 2005, CAIP, P865; LEBRUN G, 2004, ICPR, V1, P160; LEBRUN G, 2008, EA MULTIMODEL SELECT; Lebrun G, 2006, LECT NOTES COMPUT SC, V4224, P99; LIN KM, 2003, NEURAL NETWORKS IEEE, V14, P1449; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Meurie C., 2003, WSEAS Transactions on Computers, V2; MEURIE C, 2005, IJRA, V20; MEURIE C, 2003, ISSPIT, P664; MOREIRA M, 1998, EUR C MACH LEARN, P160; Nakayama H, 2005, EUR J OPER RES, V166, P756, DOI 10.1016/j.ejor.2004.03.043; Ou YY, 2003, IEEE SYS MAN CYBERN, P786; PAI PF, 2006, ISNN, P1117; Parrado-Hernandez E, 2003, PATTERN RECOGN, V36, P1479, DOI 10.1016/S0031-3203(02)00351-5; Platt J., 1999, ADV LARGE MARGIN CLA, P61; Platt J. C., 1999, FAST TRAINING SUPPOR, P185; PRICE D, 1994, NIPS, P1109; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Rifkin R, 2004, J MACH LEARN RES, V5, P101; STEINWART I, 2004, NIPS, P169; Tan P.N., 2006, INTRO DATA MINING; Thies T, 2004, NEURAL COMPUT, V16, P1769, DOI 10.1162/0899766041336459; TIKHONOV A, 1994, ILL POSED PROBLEMS T; Tikhonov A. N., 1977, SOLUTION ILL POSED P; Tsang IW, 2005, J MACH LEARN RES, V6, P363; Vandenbroucke N, 2003, COMPUT VIS IMAGE UND, V90, P190, DOI 10.1016/S1077-3142(03)00025-0; Vapnik VN, 1998, STAT LEARNING THEORY; VISHWANATHAN SVN, 2003, ICML, P760; Wu TF, 2004, J MACH LEARN RES, V5, P975; YANG J, 2005, MACHINE LEARNING CYB, V7, P4285; Yu H, 2003, SIGKDD, P306	60	7	7	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0129-0657		INT J NEURAL SYST	Int. J. Neural Syst.	FEB	2008	18	1					19	31		10.1142/S0129065708001348		13	Computer Science, Artificial Intelligence	Computer Science	268LT	WOS:000253582000003	
J	Liu, JM; Wang, JH				Liu, Jiao-Min; Wang, Jing-Hong			Parameters optimize method based on genetic and Simulated Annealing Algorithms	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article; Proceedings Paper	5th International Conference on Machine Learning and Cybernetics	AUG 13-16, 2006	Dalian, PEOPLES R CHINA	IEEE Syst, Man & Cybernet Soc, Hebei Univ, Hong Kong Polytech Univ, Harbin Inst Technol		parameter optimize; fuzzy extension matrix; genetic simulated annealing algorithm; fuzzy entropy		This paper gives an initial study on the comparison between Genetic Algorithm (GA) and Simulated Annealing Algorithm (SAA). Firstly, a new algorithm is presented. This method combines Genetic Algorithm and Simulated Annealing Algorithm, and it can be used to optimize the three parameters alpha, beta and gamma. It involes the rules that are extracted from Fuzzy Extension Matrix (FEM). These parameters play an important part in the entire process of rule extraction based on FEM. Secondly, it provides some theoretical support to the direct selection of the parameter values through experiments. Lastly, five data sets from the UCI Machine Learning centers are employed in the study. Experimental results and discussions are given.	[Wang, Jing-Hong] Hebei Normal Univ, Informat Technol Coll, Shijiazhuang 050091, Peoples R China; [Liu, Jiao-Min] Hebei Univ Technol, Tianjin 300130, Peoples R China	Wang, JH (reprint author), Hebei Normal Univ, Informat Technol Coll, Shijiazhuang 050091, Peoples R China.	wangjinghong6301@163.com					BASK T, 1997, IEEE T EVOLUTIONARY, V4, P3; HONG JR, 1985, INT J COMPUT INF SCI, V14, P421, DOI 10.1007/BF00991183; Kohonen T., 1988, SELF ORG ASS MEMORY; LIU JM, 2006, ICMLC, V7, P2474; Michalewicz Z, 2000, GENETIC ALGORITHMS D; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; WANG JH, 2004, INT C MACH LEARN CYB, V7, P1884; WANG JH, 2006, INT C MACH LEARN CYB, V7, P1739; Wang XZ, 2001, FUZZY SET SYST, V123, P291, DOI 10.1016/S0165-0114(01)00002-1; [Anonymous], UCI REP MACH LEARN D	10	1	1	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014		INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	FEB	2008	22	1					169	181		10.1142/S0218001408006119		13	Computer Science, Artificial Intelligence	Computer Science	277EE	WOS:000254194700013	
J	Bagnell, JA; Schaal, S				Bagnell, J. Andrew; Schaal, Stefan			Special issue on machine learning in robotics	INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH			English	Editorial Material									[Bagnell, J. Andrew] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA; [Schaal, Stefan] Univ So Calif, Los Angeles, CA 90089 USA	Bagnell, JA (reprint author), Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.							0	2	2	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	0278-3649		INT J ROBOT RES	Int. J. Robot. Res.	FEB	2008	27	2					155	156		10.1177/0278364907088064		2	Robotics	Robotics	264VI	WOS:000253318100001	
J	Peters, J; Schaal, S				Peters, Jan; Schaal, Steffan			Learning to control in operational space	INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH			English	Article						operational space control; robot learning; reinforcement learning; reward-weighted regression	MITSUBISHI PA-10; MANIPULATORS; ARM	One of the most general frameworks for phrasing control problems for complex, redundant robots is operational-space control. However, while this framework is of essential importance for robotics and well understood from an analytical point of view, it can be prohibitively hard to achieve accurate control in the face of modeling errors, which are inevitable in complex robots (e.g. humanoid robots). In this paper, we suggest a learning approach for operational-space control as a direct inverse model learning problem. A first important insight for this paper is that a physically correct solution to the inverse problem with redundant degrees of freedom doer exist when learning of the inverse map is performed in a suitable piecewise linear way. The second crucial component of our work is based on the insight that many operational-space controllers can be understood in terms of a constrained optimal control problem. The cost,function associated with this optimal control problem allows us to formulate a learning algorithm that automatically synthesizes a globally consistent desired resolution of redundancy while learning the operational-space controller. From the machine learning point of view, this learning problem corresponds to a reinforcement learning problem that maximizes an immediate reward. We employ an expectation-maximization policy search algorithm in order to solve this problem. Evaluations on a three degrees-of-freedom robot arm are used to illustrate the suggested approach. The application to a physically realistic simulator of the anthropomorphic SARCOS Master arm demonstrates feasibility, for complex high degree-of-freedom robots. We also show that the proposed method works in the setting of learning resolved motion rate control on a real, physical Mitsubishi PA-10 medical robotics arm.	[Peters, Jan] Univ Tubingen, Max Planck Inst Biol Cybernet, D-72076 Tubingen, Germany; [Peters, Jan; Schaal, Steffan] Univ So Calif, Los Angeles, CA 90089 USA; [Schaal, Steffan] ATR Computat Neurosci Lab, Kyoto 6190288, Japan	Peters, J (reprint author), Univ Tubingen, Max Planck Inst Biol Cybernet, Spemannstr 38, D-72076 Tubingen, Germany.	mail@jan-peters.net	Peters, Jan/D-5068-2009				Atkeson CG, 1997, ARTIF INTELL REV, V11, P75, DOI 10.1023/A:1006511328852; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Bruyninckx H., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), DOI 10.1109/ROBOT.2000.846414; BULLOCK D, 1993, J COGNITIVE NEUROSCI, V5, P408, DOI 10.1162/jocn.1993.5.4.408; D'Souza A., 2001, P IEEE RSJ INT C INT; Dayan P, 1997, NEURAL COMPUT, V9, P271, DOI 10.1162/neco.1997.9.2.271; DELUCA A, 1991, P IEEE INT C ROB AUT; DOTY KL, 1993, INT J ROBOT RES, V12, P1, DOI 10.1177/027836499301200101; Farrell J, 2006, ADAPTIVE APPROXIMATI; GUEZ A, 1988, P IEEE INT C NEUR NE, P102; HARUNO M, 1999, ADV NEURAL INFORM PR; HSU P, 1989, J ROBOTIC SYST, V6, P133, DOI 10.1002/rob.4620060203; Israel A. B., 2003, GEN INVERSES THEORY; JORDAN MI, 1992, COGNITIVE SCI, V16, P307, DOI 10.1207/s15516709cog1603_1; Kaebling L., 1996, J ARTIFICIAL INTELLI, V4, P237; Kennedy CW, 2005, IEEE-ASME T MECH, V10, P263, DOI 10.1109/TMECH.2005.848290; KHATIB O, 1987, IEEE T ROBOTIC AUTOM, V3, P43; MacKay D., 2003, INFORM THEORY INFERE; Nakamura Y., 1991, ADV ROBOTICS REDUNDA; Nakanishi J, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P2526; NAKANISHI J, 2004, P IEEE INT C ROB AUT, P2647; Nakanishi J, 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, Vols 1-4, P1575; NGUYENTUONG D, 2007, THESIS MAX PLANCK I; Park J., 1999, Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289), DOI 10.1109/IROS.1999.811690; Peters J, 2008, IEEE INT CONF ROBOT, P2872, DOI 10.1109/ROBOT.2008.4543645; PETERS J, 2007, P INT C MACH LEARN I; Peters J, 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, Vols 1-4, P3522, DOI 10.1109/IROS.2005.1545516; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Schaal S, 2002, APPL INTELL, V17, P49, DOI 10.1023/A:1015727715131; Scholkopf B., 2002, LEARNING KERNELS SUP; Sciavicco L., 2007, MODELING CONTROL ROB; SENTIS L, 2005, P IEEE INT C ROB AUT, P1730; SNELSON E, 2007, P ART INT STAT AISTA, V11; Spall J., 2003, INTRO STOCHASTIC SEA; Spong M.W., 2006, ROBOT MODELLING CONT; TEVATIA G, 2000, P INT C ROB AUT ICRA; TING JA, 2006, P ROB SCI SYST C; Udwadia F. E., 1996, ANAL DYNAMICS NEW AP; UDWADIA FE, 2005, COMMUNICATION; VIJAYAKUMAR S, 2002, AUTON ROBOT, V12, P59; Vijayakumar S, 2005, NEURAL COMPUT, V17, P2602, DOI 10.1162/089976605774320557	41	44	44	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	0278-3649		INT J ROBOT RES	Int. J. Robot. Res.	FEB	2008	27	2					197	212		10.1177/0278364907087548		16	Robotics	Robotics	264VI	WOS:000253318100004	
J	Carugo, O				Carugo, Oliviero			Metalloproteins: metal binding predicted on the basis of the amino acid sequence	JOURNAL OF APPLIED CRYSTALLOGRAPHY			English	Article							PROTEIN DATA-BANK; SELECTION; RESIDUES; SETS	A protein sequence is often insufficient for knowledge of the chemical formula and the properties of the mature molecule that perform its function. Posttranslational modifications are very common and most of them cannot be predicted on the basis of the protein sequence alone. A very common chemical modification of proteins that is not directly encoded by a single gene is the complexation with metal cations. Here it is shown that the uptake of metal ions (calcium, cobalt, copper, iron, magnesium, manganese, nickel or zinc) by proteins can be predicted on the basis of the amino acid composition, by using a mixture of several simplified amino acid alphabets and by employing machine learning methods, with 70-90% accuracy, depending on the type of metal. Not only is it possible to predict if a protein requires a certain metal ion but it is also possible to discriminate amongst various metal species. These results are likely to be useful in structural proteomics, by improving the experiment success rate, and in comparative genomics, where it is interesting to compare metal-ion contents in different organisms. It is particularly important that these predictions can be made when homology-based annotations are impossible.	[Carugo, Oliviero] Univ Pavia, Dept Gen Chem, I-27100 Pavia, Italy; [Carugo, Oliviero] Univ Vienna, Programme Computat & Struct Biol, Max F Perutz Lab, A-1030 Vienna, Austria	Carugo, O (reprint author), Univ Pavia, Dept Gen Chem, Viale Taramelli 12, I-27100 Pavia, Italy.	oliviero.carugo@univie.ac.at					BABOR M, 2007, PROTEINS, V70, P208; Bairoch A, 2007, NUCLEIC ACIDS RES, V35, pD193, DOI 10.1093/nar/gkl929; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; BERNSTEIN FC, 1977, J MOL BIOL, V112, P535, DOI 10.1016/S0022-2836(77)80200-3; Chakrabarti P, 2001, PROG BIOPHYS MOL BIO, V76, P1, DOI 10.1016/S0079-6107(01)00005-0; Cianci M., 2005, CRYSTALLOGR REV, V11, P245, DOI 10.1080/08893110500421268; Da Silva J. J. R. F., 2001, BIOL CHEM ELEMENTS I; GOYAL K, 2007, IN PRESS PROTEINS; Gromiha MM, 2006, PROTEINS, V63, P1031, DOI 10.1002/prot.20929; GURUPRASAD K, 1990, PROTEIN ENG, V4, P155, DOI 10.1093/protein/4.2.155; HOBOHM U, 1992, PROTEIN SCI, V1, P409; KYTE J, 1982, J MOL BIOL, V157, P105, DOI 10.1016/0022-2836(82)90515-0; Li WZ, 2006, BIOINFORMATICS, V22, P1658, DOI 10.1093/bioinformatics/btl158; Mueller-Dieckmann C, 2007, ACTA CRYSTALLOGR D, V63, P366, DOI 10.1107/S0907444906055624; Murphy LR, 2000, PROTEIN ENG, V13, P149, DOI 10.1093/protein/13.3.149; Ofran Y, 2005, DRUG DISCOV TODAY, V10, P1475, DOI 10.1016/S1359-6446(05)03621-4; Raftery J, 2002, ACTA CRYSTALLOGR D, V58, P875, DOI 10.1107/S0907444902004031; ROSE GD, 1985, SCIENCE, V229, P834, DOI 10.1126/science.4023714; Sodhi JS, 2004, J MOL BIOL, V342, P307, DOI 10.1016/j.jmb.2004.07.019; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Witten H. I., 2005, DATA MINING PRACTICA	21	1	1	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	0021-8898		J APPL CRYSTALLOGR	J. Appl. Crystallogr.	FEB	2008	41		1				104	109		10.1107/S0021889807065235		6	Crystallography	Crystallography	270KJ	WOS:000253719400013	
J	Coz-Rakovac, R; Smuc, T; Popovic, NT; Strunjak-Perovic, I; Hacmanjek, M; Jadan, M				Coz-Rakovac, R.; Smuc, T.; Popovic, N. Topic; Strunjak-Perovic, I.; Hacmanjek, M.; Jadan, M.			Novel methods for assessing fish blood biochemical data	JOURNAL OF APPLIED ICHTHYOLOGY			English	Article							CHEMISTRY; TROUT; SEA	The purpose of this study was the identification and quantification of biochemical parameters over a 1-year cycle and to provide a detailed picture of seasonal changes in plasma metabolites and enzymes. Using the novel methods of machine learning techniques, the authors created and generated for the first time comprehensible classification models for exploring the importance of blood chemistry parameters, strength, mutual interactions or dependencies, and reliability of particular parameters within the seasonal groups.	[Coz-Rakovac, R.; Popovic, N. Topic; Strunjak-Perovic, I.; Hacmanjek, M.; Jadan, M.] Rudjer Boskovic Inst, Div Mat Chem, Ichthyopathol Grp Biol Mat, Zagreb, Croatia; [Smuc, T.] Rudjer Boskovic Inst, Div Elect, Informat Syst Lab, Zagreb, Croatia	Coz-Rakovac, R (reprint author), Rudjer Boskovic Inst, Div Mat Chem, Ichthyopathol Grp Biol Mat, Zagreb, Croatia.	rrakovac@irb.hr					Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brown Lydia A., 1993, P79; BURTIS CA, 2000, TIETZ FUNDAMENTALS C; Congleton JL, 2006, J FISH BIOL, V69, P473, DOI 10.1111/j.1095-8649.2006.01114.x; Coz-Rakovac R, 2005, VET RES COMMUN, V29, P677, DOI 10.1007/s11259-005-3684-z; de Pedro N, 2005, AQUAC RES, V36, P1185, DOI 10.1111/j.1365-2109.2005.01338.x; DUDA RO, 2000, PARRENT CLASSIFICATI, P738; Dzeroski S, 2003, ECOL MODEL, V170, P219, DOI 10.1016/S0304-3800(03)00229-1; Edsall CC, 1999, J AQUAT ANIM HEALTH, V11, P81, DOI 10.1577/1548-8667(1999)011<0081:ABCPFL>2.0.CO;2; Hrubec TC, 2001, VET CLIN PATH, V30, P8, DOI 10.1111/j.1939-165X.2001.tb00249.x; Mastrorillo S, 1997, FRESHWATER BIOL, V38, P237, DOI 10.1046/j.1365-2427.1997.00209.x; MCQUEEN RJ, 1995, COMPUT ELECTRON AGR, V12, P275, DOI 10.1016/0168-1699(95)98601-9; PICKERING AD, 1982, J FISH BIOL, V20, P229, DOI 10.1111/j.1095-8649.1982.tb03923.x; Popovic NT, 2006, FISH PHYSIOL BIOCHEM, V32, P99, DOI 10.1007/s10695-006-0001-x; Quinlan J. R., 1992, C4 5 PROGRAM MACHINE; TOPIC G, 2005, P PAR NUM THEOR APPL, P119; TSCHUDI PR, 1995, SCHWEIZ ARCH TIERH, V137, P381; Witten I. H., 1999, DATA MINING PRACTICA	18	3	3	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	0175-8659		J APPL ICHTHYOL	J. Appl. Ichthyol.	FEB	2008	24	1					77	80		10.1111/j.1439-0426.2007.01041.x		4	Fisheries; Marine & Freshwater Biology	Fisheries; Marine & Freshwater Biology	249MW	WOS:000252233700013	
J	Lin, JH; Haug, PJ				Lin, Jau-Huei; Haug, Peter J.			Exploiting missing clinical data in Bayesian network modeling for predicting medical problems	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						missing data; problem list; clinical decision support system; Bayesian network	PROBLEM-ORIENTED APPROACH; SYSTEM; VALIDATION; REGRESSION; RECORD; GUIDE	When machine learning algorithms are applied to data collected during the course of clinical care, it is generally accepted that the data has not been consistently collected. The absence of expected data elements is common and the mechanism through which a data element is missing often involves the clinical relevance of that data element in a specific patient. Therefore, the absence of data may have information value of its own. In the process of designing an application intended to support a medical problem list, we have studied whether the "missingness" of clinical data can provide useful information in building prediction models. In this study, we experimented with four methods of treating missing values in a clinical data set-two of them explicitly model the absence or "missingness" of data. Each of these data sets were used to build four different kinds of Bayesian classifiers-a naive Bayes structure, a human-composed network structure, and two networks based on structural learning algorithms. We compared the performance between groups with and without explicit models of missingness using the area under the ROC curve. The results showed that in most cases the classifiers trained using the explicit missing value treatments performed better. The result suggests that information may exist in "missingness" itself. Thus, when designing a decision support system, we suggest one consider explicitly representing the presence/absence of data in the underlying logic. (C) 2007 Elsevier Inc. All rights reserved.	[Lin, Jau-Huei] Univ Utah, Dept Biomed Informat, Salt Lake City, UT 84112 USA; LDS Hosp, Salt Lake City, UT 84143 USA	Lin, JH (reprint author), Univ Utah, Dept Biomed Informat, 26 South,2000 East,Romm 5775 HSEB, Salt Lake City, UT 84112 USA.	jauhuei.lin@utah.edu					BABBOTT D, 1983, ACAD MED, V58, P947, DOI 10.1097/00001888-198312000-00005; BOLENS M, 1992, M D COMPUT, V9, P149; Bui AAT, 2004, ST HEAL T, V107, P587; Bui AAT, 2001, J AM MED INFORM ASSN, V8, P242; Buntine W, 1996, IEEE T KNOWL DATA EN, V8, P195, DOI 10.1109/69.494161; Campbell J R, 1998, Proc AMIA Symp, P285; CHICKERING DM, 2002, MSRTR2002103; Cios KJ, 2002, ARTIF INTELL MED, V26, P1, DOI 10.1016/S0933-3657(02)00049-0; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Edgington ES, 1995, RANDOMIZATION TESTS; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Enders CK, 2006, PSYCHOSOM MED, V68, P427, DOI 10.1097/01.psy.0000221275.75056.d8; FOLLMANN D, 1995, BIOMETRICS, V51, P151, DOI 10.2307/2533322; Friedman N., 1998, P 14 C UNC ART INT, P129; Gardner RM, 1999, INT J MED INFORM, V54, P169, DOI 10.1016/S1386-5056(99)00013-1; Goldman L, 2003, CECIL TXB MED; HANLEY JA, 1982, RADIOLOGY, V143, P29; Heckerman D., 1995, MSRTR9506; HESTERBERG T, 2002, BOOSTRAP METHODS PER, pCH18; HUST JW, 1971, ARCH INTERN MED, V128, P818; JENSEN F, 2001, BAYESIAN NETWORKS DE; Jones MP, 1996, J AM STAT ASSOC, V91, P222, DOI 10.2307/2291399; Kasper DL, 2005, HARRISONS PRINCIPLES; Lavrac N., 1998, PADD98. Proceedings of the Second International Conference on the Practical Application of Knowledge Discovery and Data Mining; Little R. J. A., 2002, STAT ANAL MISSING DA; MARGOLIS CZ, 1984, AM J PUBLIC HEALTH, V74, P1410, DOI 10.2105/AJPH.74.12.1410; MEYSTRE S, 2005, BMC MED INFORM DECIS, V5; Pearl J., 1988, PROBABILISTIC REASON; RUBIN DB, 1976, BIOMETRIKA, V63, P581, DOI 10.1093/biomet/63.3.581; RUSSELL IJ, 1990, ACAD MED, V65, P333, DOI 10.1097/00001888-199005000-00015; STARMER JM, 1998, P AMIA S; Steyerberg EW, 2001, J CLIN EPIDEMIOL, V54, P774, DOI 10.1016/S0895-4356(01)00341-9; TUFO HM, 1977, JAMA-J AM MED ASSOC, V238, P414, DOI 10.1001/jama.238.5.414; TUFO HM, 1977, JAMA-J AM MED ASSOC, V238, P502, DOI 10.1001/jama.238.6.502; WEED LL, 1968, NEW ENGL J MED, V278, P52; WEED LL, 1968, NEW ENGL J MED, V278, P593, DOI 10.1056/NEJM196803142781105; WU MC, 1988, BIOMETRICS, V44, P175, DOI 10.2307/2531905; *NORS SOFTW CORP, NETICA	38	17	17	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464		J BIOMED INFORM	J. Biomed. Inform.	FEB	2008	41	1					1	14		10.1016/j.jbi.2007.06.001		14	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	292IR	WOS:000255260200001	
J	Wong, HS; Wang, HQ				Wong, Hau-San; Wang, Hong-Qiang			Constructing the gene regulation-level representation of microarray data for cancer classification	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						cancer classification; genetic algorithms; gene expression levels; gene regulation levels; histogram; microarray data	DIFFERENTIALLY EXPRESSED GENES; SUPPORT VECTOR MACHINES; PARTIAL LEAST-SQUARES; CLASS DISCOVERY; TUMOR; PREDICTION; SELECTION	In this paper, we propose a regulation-level representation for microarray data and optimize it using genetic algorithms (GAs) for cancer classification. Compared with the traditional expression-level features, this representation can greatly reduce the dimensionality of microarray data and accommodate noise and variability such that many statistical machine-learning methods now become applicable and efficient for cancer classification. Experimental results on real-world microarray datasets show that the regulation-level representation can consistently converge at a solution with three regulation levels. This verifies the existence of the three regulation levels (up-regulation, down-regulation and non-significant regulation) associated with a particular biological phenotype. The ternary regulation-level representation not only improves the cancer classification capability but also facilitates the visualization of microarray data. (C) 2007 Elsevier Inc. All rights reserved.	[Wong, Hau-San; Wang, Hong-Qiang] City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China	Wang, HQ (reprint author), City Univ Hong Kong, Dept Comp Sci, 83 Tat Chee Ave, Kowloon, Hong Kong, Peoples R China.	hqwang@ustc.edu					Alexandridis R, 2004, BIOINFORMATICS, V20, P2545, DOI 10.1093/bioinformatics/bth281; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Bicciato S, 2003, BIOINFORMATICS, V19, P571, DOI 10.1093/bioinformatics/btg051; CRISTIANIN N, 2001, INTRO SUPPORT VECTOR; Culhane AC, 2002, BIOINFORMATICS, V18, P1600, DOI 10.1093/bioinformatics/18.12.1600; Dougherty ER, 2005, IEEE SIGNAL PROC MAG, V22, P46, DOI 10.1109/MSP.2005.1550189; DOUGHERTY ER, 2005, IEEE T SIGNAL PROCES, V22, P1778; Dudoit S, 2002, STAT SINICA, V12, P111; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Fix E, 1951, 4 US AIR FORC SCH AV; Fort G, 2005, BIOINFORMATICS, V21, P1104, DOI 10.1093/bioinformatics/bti114; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Iizuka N, 2003, LANCET, V361, P923, DOI 10.1016/S0140-6736(03)12775-4; JOACHIMS T, 2003, SVM SUPPORT VECTOR M; KHAN J, 2001, NAUTRE MED, V7, P670; LEE Y, 2003, BIOINFORMATICS, V19, P1123; Mao KZ, 2004, IEEE T SYST MAN CY B, V34, P60, DOI 10.1109/TSMCB.2002.805808; MCLAHLAN GJ, 2004, DISCRIMINANT ANAL ST; Newton MA, 2004, BIOSTATISTICS, V5, P155, DOI 10.1093/biostatistics/5.2.155; Nguyen DV, 2002, BIOINFORMATICS, V18, P39, DOI 10.1093/bioinformatics/18.1.39; Nutt CL, 2003, CANCER RES, V63, P1602; Pan Wei, 2003, Functional & Integrative Genomics, V3, P117; Pochet N, 2004, BIOINFORMATICS, V20, P3185, DOI 10.1093/bioinformatics/bth383; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Webb A.R., 2002, STAT PATTERN RECOGNI; Yan XT, 2005, J THEOR BIOL, V234, P395, DOI 10.1016/j.jtbi.2004.11.039; Yang YH, 2005, BIOINFORMATICS, V21, P1084, DOI 10.1093/bioinformatics/bti108; Yeung KY, 2001, BIOINFORMATICS, V17, P763, DOI 10.1093/bioinformatics/17.9.763; Zhang L, 2004, IEEE T NEURAL NETWOR, V15, P1424, DOI 10.1109/TNN.2004.831161	32	5	6	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464		J BIOMED INFORM	J. Biomed. Inform.	FEB	2008	41	1					95	105		10.1016/j.jbi.2007.04.002		11	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	292IR	WOS:000255260200009	
J	Theodosiou, T; Angelis, L; Vakall, A				Theodosiou, Theodosios; Angelis, Lefteris; Vakall, Athena			Non-linear correlation of content and metadata information extracted from biomedical article datasets	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						biomedical literature; non-linear canonical correlation; MeSH; gene ontology; data reduction; visualization; PubMed	GENE ONTOLOGY; TEXT; KNOWLEDGE; SYSTEM	Biomedical literature databases constitute valuable repositories of up to date scientific knowledge. The development of efficient machine learning methods in order to facilitate the organization of these databases and the extraction of novel biomedical knowledge is becoming increasingly important. Several of these methods require the representation of the documents as vectors of variables forming large multivariate datasets. Since the amount of information contained in different datasets is voluminous, an open issue is to combine information gained from various sources to a concise new dataset, which will efficiently represent the corpus of documents. This paper investigates the use of the multivariate statistical approach, called Non-Linear Canonical Correlation Analysis (NLCCA), for exploiting the correlation among the variables of different document representations and describing the documents with only one new dataset. Experiments with document datasets represented by text words, Medical Subject Headings (MeSH) and Gene Ontology (GO) terms showed the effectiveness of NLCCA. (C) 2007 Elsevier Inc. All rights reserved.	[Theodosiou, Theodosios; Angelis, Lefteris; Vakall, Athena] Aristotle Univ Thessaloniki, Sch Nat Sci, Dept Informat, Thessaloniki 54124, Greece	Theodosiou, T (reprint author), Aristotle Univ Thessaloniki, Sch Nat Sci, Dept Informat, Thessaloniki 54124, Greece.	theodos@csd.auth.gr					Bean Carol A., 2001, RELATIONSHIPS ORG KN; Ashburner M, 2000, NAT GENET, V25, P25; Chang AA, 2006, LARYNGOSCOPE, V116, P336, DOI 10.1097/01.mlg.0000195371.72887.a2; CONSORTIUM T. G. O., 2001, GENOME RES, V11, P1425, DOI 10.1101/gr.180801; HAIR J, 1998, MULTIVARIATE DATA AN; Iliopoulos I, 2001, Pac Symp Biocomput, P384; Izumitani T., 2004, Proceedings. 2004 IEEE Computational Systems Bioinformatics Conference; JURAFSKY D, 2000, SPEECH NATURAL LANGU; Lattin J., 2003, ANAL MULTIVARIATE DA; Lee M, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-140; Manning C. D., 1999, FDN STAT NATURAL LAN; Martin-Sanchez F, 2004, J BIOMED INFORM, V37, P30, DOI 10.1016/j.jbi.2003.09.003; MEULMAN JJ, SPSS CATEGORIES USER; Michailidis G, 1998, STAT SCI, V13, P307; Paice C. D., 1990, SIGIR Forum, V24; Pan H, 2004, NUCLEIC ACIDS RES, V32, pW230, DOI 10.1093/nar/gkh484; PARANTU KS, 2003, BMC BIOINFORMATICS, V4, P20; Raychaudhuri S, 2002, GENOME RES, V12, P203, DOI 10.1101/gr.199701; Rubin DL, 2005, J AM MED INFORM ASSN, V12, P121, DOI 10.1197/jamia.M1640; Ruch P, 2006, BIOINFORMATICS, V22, P658, DOI 10.1093/bioinformatics/bti783; SALTON G, 1970, SCIENCE, V168, P335, DOI 10.1126/science.168.3929.335; Shatkay H, 2003, J COMPUT BIOL, V10, P821, DOI 10.1089/106652703322756104; THEODOSIOU T, 2007, INT J MED INFORM, V67, P601; VANDERBURG E, 1984, NONLINEAR CANONICAL; Weiss N, 2002, INTRO STAT; Yamamoto Y, 2007, J BIOMED INFORM, V40, P114, DOI 10.1016/j.jbi.2006.07.004; Zobel J., 1998, SIGIR Forum, V32; *NCBI NLM NIH, PUBMED	28	0	1	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464		J BIOMED INFORM	J. Biomed. Inform.	FEB	2008	41	1					202	216		10.1016/j.jbi.2007.06.004		15	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	292IR	WOS:000255260200016	
J	Bisht, L; Bshouty, NH; Khoury, L				Bisht, Laurence; Bshouty, Nader H.; Khoury, Lawrance			Learning with errors in answers to membership queries	JOURNAL OF COMPUTER AND SYSTEM SCIENCES			English	Article; Proceedings Paper	36th Annual ACM Symposium on Theory of Computing	JUN 13-15, 2004	Chicago, IL	ACM		exact learning; membership query; equivalence query; limited membership query	ORACLE	We study the learning models defined in [D. Angluin, M. Krikis, R.H. Sloan, G. Turin, Malicious omissions and errors in answering to membership queries, Machine Learning 28 (2 - 3) (1997) 211 - 255]: Learning with equivalence and limited membership queries and learning with equivalence and malicious membership queries. We show that if a class of concepts that is closed under projection is learnable in polynomial time using equivalence and (standard) membership queries then it is learnable in polynomial time in the above models. This closes the open problems in [D. Angluin, M. Krikis, R.H. Sloan, G. Turin, Malicious omissions and errors in answering to membership queries, Machine Learning 28 (2 - 3) (1997) 211 - 255]. Our algorithm can also handle errors in the equivalence queries. (c) 2007 Elsevier Inc. All rights reserved.	[Bisht, Laurence; Bshouty, Nader H.; Khoury, Lawrance] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Bshouty, NH (reprint author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	bisht@cs.technion.ac.il; bshouty@cs.technion.ac.il; khoury@cs.technion.ac.il					Angluin D, 1997, MACH LEARN, V28, P211, DOI 10.1023/A:1007311411259; Angluin D., 1988, Machine Learning, V2, DOI 10.1007/BF00116828; ANGLUIN D, 1994, MACH LEARN, V14, P7, DOI 10.1007/BF00993160; Bennet R, 2005, LECT NOTES ARTIF INT, V3734, P183; Bshouty N, 2001, LECT NOTES ARTIF INT, V2111, P574; Bshouty NH, 1997, COMPUT COMPLEX, V6, P174; Bshouty NH, 2002, J MACH LEARN RES, V2, P359, DOI 10.1162/153244302760200669; BSHOUTY NH, 2002, J MACH LEARN RES, V3, P49; Frazier M, 1996, J COMPUT SYST SCI, V52, P471, DOI 10.1006/jcss.1996.0035; Goldman S. A., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130394; GOLDMAN SA, 1993, SIAM J COMPUT, V22, P705, DOI 10.1137/0222047; Jackson J, 1999, DISCRETE APPL MATH, V92, P157, DOI 10.1016/S0166-218X(99)00045-1; RON D, 1995, MACH LEARN, V18, P149, DOI 10.1007/BF00993409; SAVICKY P, 2002, TR02009 ECCC; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972	15	0	0	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0022-0000		J COMPUT SYST SCI	J. Comput. Syst. Sci.	FEB	2008	74	1					2	15		10.1016/j.jcss.2007.04.010		14	Computer Science, Hardware & Architecture; Computer Science, Theory & Methods	Computer Science	243BC	WOS:000251768900002	
J	Chapelle, O; Sindhwani, V; Keerthi, SS				Chapelle, Olivier; Sindhwani, Vikas; Keerthi, Sathiya S.			Optimization techniques for semi-supervised support vector machines	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						semi-supervised learning; support vector machines; non-convex optimization; transductive learning	CLASSIFICATION	Due to its wide applicability, the problem of semi-supervised classification is attracting increasing attention in machine learning. Semi-Supervised Support Vector Machines ((SVMs)-V-3) are based on applying the margin maximization principle to both labeled and unlabeled examples. Unlike SVMs, their formulation leads to a non-convex optimization problem. A suite of algorithms have recently been proposed for solving (SVMs)-V-3. This paper reviews key ideas in this literature. The performance and behavior of various (SVM)-V-3 algorithms is studied together, under a common experimental setting.	[Chapelle, Olivier; Keerthi, Sathiya S.] Yahoo Res, Santa Clara, CA 95054 USA; [Sindhwani, Vikas] Univ Chicago, Dept Comp Sci, Chicago, IL 60637 USA	Chapelle, O (reprint author), Yahoo Res, 2821 Miss Coll Blvd, Santa Clara, CA 95054 USA.	CHAP@YAHOO-INC.COM; VIKASS@CS.UCHICAGO.EDU; SELVARAK@YAHOO-INC.COM					ABDI H, 2006, ENCY MEASUREMENT STA; Astorino A, 2007, IEEE T PATTERN ANAL, V29, P2135, DOI 10.1109/TPAMI.2007.1102.; BENGIO Y, 2004, ADV NEURAL INFORM PR, V17; Bennett K., 1998, ADV NEURAL INFORM PR, V12; Boser B., 1992, 5 ANN ACM WORKSH COL, P144; Chapelle O., 2006, ADV NEURAL INFORM PR; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Chapelle O., 2006, INT C MACH LEARN; Chapelle O., 2006, SEMISUPERVISED LEARN; CHAPELLE O, 2005, 10 INT WORKSH ART IN; Chapelle O, 2007, NEURAL COMPUT, V19, P1155, DOI 10.1162/neco.2007.19.5.1155; Chen YS, 2003, PATTERN RECOGN LETT, V24, P1845, DOI 10.1016/S0167-8655(03)00008-4; COLE R, 1990, CSE90004 OR GRAD I; Collobert R, 2006, J MACH LEARN RES, V7, P1687; De Bie T., 2006, SEMISUPERVISED LEARN; Fletcher R., 1987, PRACTICAL METHODS OP; Fung G, 2001, OPTIM METHOD SOFTW, V15, P29, DOI 10.1080/10556780108805809; Joachims T., 1999, INT C MACH LEARN; LIU H, 2004, INT J UNCERTAIN FUZZ, V12, P21, DOI 10.1142/S021848850400262X; Nene S.A., 1996, CUCS00596 COL U; Scholkopf B., 2002, LEARNING KERNELS; SEEGER M, 2006, SEMISUPERVISED LERNI; SILVA MS, 2005, 5 INT C HYB INT SYST, P329, DOI 10.1109/ICHIS.2005.21; Sindhwani V., 2005, INT C MACH LEARN; Sindhwani V., 2006, SIGIR; SINDHWANI V, 2006, INT C MACH LEARN; Szummer M., 2001, ADV NEURAL INFORM PR, V14; Vapnik V., 1977, AUTOMAT REM CONTR, V10, P1495; Vapnik VN, 1998, STAT LEARNING THEORY; Wang L., 2007, PREDICTION DISCOVERY; WAPNIK W, 1979, THEORIE ZEICHENERKEN; Wu ZJ, 1996, SIAM J OPTIMIZ, V6, P748, DOI 10.1137/S1052623493254698; XU L, 2004, ADV NEURAL INFORM PR; Yuille AL, 2003, NEURAL COMPUT, V15, P915, DOI 10.1162/08997660360581958; ZHU X, 2002, 02107 CMU CALD	35	54	63	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	FEB	2008	9						203	233				31	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	312AP	WOS:000256641800009	
J	Sakiyama, Y; Yuki, H; Moriya, T; Hattori, K; Suzuki, M; Shimada, K; Honma, T				Sakiyama, Yojiro; Yuki, Hitomi; Moriya, Takashi; Hattori, Kazunari; Suzuki, Misaki; Shimada, Kaoru; Honma, Teruki			Predicting human liver microsomal stability with machine learning techniques	JOURNAL OF MOLECULAR GRAPHICS & MODELLING			English	Article						random forest; in silico; ADMET; metabolic stability; machine learning	CYTOCHROME-P450 3A4 INHIBITORS; RANDOM FOREST; CLASSIFICATION; MODELS; METABOLISM; DESCRIPTORS; VALIDATION; SOLUBILITY; ALGORITHMS; BINDING	To ensure a continuing pipeline in pharmaceutical research, lead candidates must possess appropriate metabolic stability in the drug discovery process. In vitro ADMET (absorption, distribution, metabolism, elimination, and toxicity) screening provides us with useful information regarding the metabolic stability of compounds. However, before the synthesis stage, an efficient process is required in order to deal with the vast quantity of data from large compound libraries and high-throughput screening. Here we have derived a relationship between the chemical structure and its metabolic stability for a data set of in-house compounds by means of various in silico machine learning such as random forest, support vector machine (SVM), logistic regression, and recursive partitioning. For model building, 1952 proprietary compounds comprising two classes (stable/unstable) were used with 193 descriptors calculated by Molecular Operating Environment. The results using test compounds have demonstrated that all classifiers yielded satisfactory results (accuracy > 0.8, sensitivity > 0.9, specificity > 0.6, and precision > 0.8). Above all, classification by random forest as well as SVM yielded kappa values of approximately 0.7 in an independent validation set, slightly higher than other classification tools. These results suggest that nonlinear/ensemble-based classification methods might prove useful in the area of in silico ADME modeling. (C) 2007 Elsevier Inc. All rights reserved.	[Sakiyama, Yojiro; Yuki, Hitomi; Moriya, Takashi; Hattori, Kazunari; Suzuki, Misaki; Shimada, Kaoru; Honma, Teruki] Pfizer Inc, Pfizer Global Res & Dev, Nagoya Labs, Aichi 4702393, Japan	Sakiyama, Y (reprint author), Pfizer Inc, Pfizer Global Res & Dev, Nagoya Labs, Aichi 4702393, Japan.	Yojiro.Sakiyama@pfizer.coru	YUKI, Hitomi/C-5044-2012				Arimoto R, 2005, J BIOMOL SCREEN, V10, P197, DOI 10.1177/1087057104274091; Balakin KV, 2004, DRUG METAB DISPOS, V32, P1183, DOI 10.1124/dmd.104.000356; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Breimann L, 1984, CLASSIFICATION REGRE; BURSI R, 2001, J MOL GRAPH MODEL, V19, P558; Calvocoressi L, 2005, AM J EPIDEMIOL, V162, P1215, DOI 10.1093/aje/kwi337; Cannon EO, 2006, J CHEM INF MODEL, V46, P2369, DOI 10.1021/ci0601160; Chen XW, 2005, BIOINFORMATICS, V21, P4394, DOI 10.1093/bioinformatics/bti721; Chohan KK, 2005, J MED CHEM, V48, P5154, DOI 10.1021/jm048959a; CHRISTIANINI N, 2000, SUPPORT VECTOR MECH; Ekins S, 2003, DRUG METAB DISPOS, V31, P1077, DOI 10.1124/dmd.31.9.1077; Evans WE, 1999, SCIENCE, V286, P487, DOI 10.1126/science.286.5439.487; Fox T, 2006, CURR TOP MED CHEM, V6, P1579, DOI 10.2174/156802606778108915; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Hawkins DM, 1997, QUANT STRUCT-ACT REL, V16, P296, DOI 10.1002/qsar.19970160404; Hosmer DW, 1989, APPL LOGISTIC REGRES; Houston JB, 2000, DRUG METAB DISPOS, V28, P246; Kola I, 2004, NAT REV DRUG DISCOV, V3, P711, DOI 10.1038/nrd1470; Kriegl JM, 2005, J COMPUT AID MOL DES, V19, P189, DOI 10.1007/s10822-005-3785-3; Langowski J, 2002, ADV DRUG DELIVER REV, V54, P407, DOI 10.1016/S0169-409X(02)00011-X; Lehmann C, 2007, J NEUROSCI METH, V161, P342, DOI 10.1016/j.jneumeth.2006.10.023; Lipinski CA, 2001, ADV DRUG DELIVER REV, V46, P3, DOI 10.1016/S0169-409X(00)00129-0; Lombardo F, 2006, J MED CHEM, V49, P2262, DOI 10.1021/jm050200r; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; Merkwirth C, 2004, J CHEM INF COMP SCI, V44, P1971, DOI 10.1021/ci049850e; Molnar L, 2002, BIOORG MED CHEM LETT, V12, P419, DOI 10.1016/S0960-894X(01)00771-5; Obach RS, 1997, J PHARMACOL EXP THER, V283, P46; Obach RS, 1999, DRUG METAB DISPOS, V27, P1350; O'Brien SE, 2005, J MED CHEM, V48, P1287, DOI 10.1021/jm049254b; Palmer DS, 2007, J CHEM INF MODEL, V47, P150, DOI 10.1021/ci060164k; R Development Core Team, 2005, LANG ENV STAT COMP F; Schapire R. E., 1999, P 16 INT JOINT C ART; Shen M, 2003, J MED CHEM, V46, P3013, DOI 10.1021/jm020491t; Shi T, 2005, MODERN PATHOL, V18, P547, DOI 10.1038/modpathol.3800322; STOKES ME, 1995, CATEGORICAL DATA ANA, P98; Strobl C, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-25; Susnow RG, 2003, J CHEM INF COMP SCI, V43, P1308, DOI 10.1021/ci030283p; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; van de Waterbeemd H, 2003, NAT REV DRUG DISCOV, V2, P192, DOI 10.1038/nrd1032; Vapnik V., 1995, NATURE STAT LEARNIN; Wrighton SA, 2000, DRUG METAB REV, V32, P339, DOI 10.1081/DMR-100102338; Yap CW, 2006, CURR TOP MED CHEM, V6, P1593, DOI 10.2174/156802606778108942; Zhang QY, 2007, J CHEM INF MODEL, V47, P1, DOI 10.1021/ci050520j	45	17	17	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	1093-3263		J MOL GRAPH MODEL	J. Mol. Graph.	FEB	2008	26	6					907	915		10.1016/j.jmgm.2007.06.005		9	Biochemical Research Methods; Biochemistry & Molecular Biology; Computer Science, Interdisciplinary Applications; Crystallography; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Computer Science; Crystallography; Mathematical & Computational Biology	261HC	WOS:000253068700003	
J	Durbin, B; Dudoit, S; van der Laan, MJ				Durbin, Blythe; Dudoit, Sandrine; van der Laan, Mark J.			A deletion/substitution/addition algorithm for classification neural networks, with applications to biomedical data	JOURNAL OF STATISTICAL PLANNING AND INFERENCE			English	Article						neural networks; classification; data-adaptive model selection		Neural networks are a popular machine learning tool particularly in applications such as protein structure prediction: however. overfitting can pose an obstacle to their effective use. Due to the large number of parameters in a typical neural network. one may obtain a network fit that perfectly predicts the learning data, yet fails to generalize to other data sets. One way of reducing the size of the parmeter space is to alter the network topology so that some edges are removed: however it is often not immediately apparent which edges should be eliminated. We propose a data-adaptive method of selecting an optimal network architecture using a deletion/substitution/addition algorithm. Results of this approach to classification are presented on simulated data and the breast cancer data of Wolberg and Mangasarian [1990. Multisurface method of pattern separation for medical diagnosis applied to breast cytology. Proc. Nat. Acad. Sci. 87. 9193-9196]. (C) 2007 Elsevier B.V. All rights reserved.	[Durbin, Blythe; Dudoit, Sandrine; van der Laan, Mark J.] Univ Calif Berkeley, Dept Stat, Sch Publ Hlth, Div Biostat, Berkeley, CA 94720 USA	Dudoit, S (reprint author), Univ Calif Berkeley, Dept Stat, Sch Publ Hlth, Div Biostat, 140 Earl Warren Hall 7360, Berkeley, CA 94720 USA.	sandrine@sta.berkeley.edu					BARRON AR, 1993, IEEE T INFORM THEORY, V39, P930, DOI 10.1109/18.256500; Chambers J, 1983, GRAPHICAL METHODS DA; Dudoit S., 2005, STAT METHODOLOGY, V2, P131, DOI 10.1016/j.stamet.2005.02.003; DURBIN B, 2004, 170 U CAL DIV BIOST; Haykin S., 1998, NEURAL NETWORKS COMP; JONES D, 1999, J MOL BIOL, V292; LIU Y, 1998, PARALLEL PROBLEM SOL, V1498, P623, DOI 10.1007/BFb0056904; Meyer D, 2003, NEUROCOMPUTING, V55, P169, DOI 10.1016/S0925-2312(03)00431-4; MOLINARO A, 2004, 162 U CAL DIV BIOST; R Development Core Team, 2004, R LANG ENV STAT COMP; Riis SK, 1996, J COMPUT BIOL, V3, P163, DOI 10.1089/cmb.1996.3.163; SINISI SE, 2004, SAGMB, V3; WOLBERG WH, 1990, P NATL ACAD SCI USA, V87, P9193, DOI 10.1073/pnas.87.23.9193; Yao X, 1997, IEEE T NEURAL NETWOR, V8, P694, DOI 10.1109/72.572107; Yao X, 1999, P IEEE, V87, P1423; Yao X, 1998, APPL MATH COMPUT, V91, P83, DOI 10.1016/S0096-3003(97)10005-4	16	5	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0378-3758		J STAT PLAN INFER	J. Stat. Plan. Infer.	FEB 1	2008	138	2					464	488		10.1016/j.jspi.2007.06.002		25	Statistics & Probability	Mathematics	261GN	WOS:000253067200012	
J	Gondra, I				Gondra, Iker			Applying machine learning to software fault-proneness prediction	JOURNAL OF SYSTEMS AND SOFTWARE			English	Article						software testing; software metrics; ault-proneness; machine learning; neural network; sensitivity analysis; support vector machine	PATTERN-RECOGNITION; METRICS; MAINTENANCE; QUALITY; MODELS; ERRORS	The importance of software testing to quality assurance cannot be overemphasized. The estimation of a module's fault-proneness is important for minimizing cost and improving the effectiveness of the software testing process. Unfortunately, no general technique for estimating software fault-proneness is available. The observed correlation between some software metrics and fault-proneness has resulted in a variety of predictive models based on multiple metrics. Much work has concentrated on how to select the software metrics that are most likely to indicate fault-proneness. In this paper, we propose the use of machine learning for this purpose. Specifically, given historical data on software metric values and number of reported errors, an Artificial Neural Network (ANN) is trained. Then, in order to determine the importance of each software metric in predicting fault-proneness, a sensitivity analysis is performed on the trained ANN. The software metrics that are deemed to be the most critical are then used as the basis of an ANN-based predictive model of a continuous measure of fault-proneness. We also view fault-proneness prediction as a binary classification task (i.e., a module can either contain errors or be error-free) and use Support Vector Machines (SVM) as a state-of-the-art classification method. We perform a comparative experimental study of the effectiveness of ANNs and SVMs on a data set obtained from NASA's Metrics Data Program data repository. (c) 2007 Elsevier Inc. All rights reserved.	St Francis Xavier Univ, Dept Math Stat & Comp Sci, Antigonish, NS B2G 2W5, Canada	Gondra, I (reprint author), St Francis Xavier Univ, Dept Math Stat & Comp Sci, POB 5000, Antigonish, NS B2G 2W5, Canada.	iaondra@stfx.ca					Basili V. R., 2002, Proceedings of the 24th International Conference on Software Engineering. ICSE 2002, DOI 10.1109/ICSE.2002.1007957; Bellman R., 1961, ADAPTIVE CONTROL PRO; BOEHM B, 1987, IEEE SOFTWARE, V4, P84; BOEHM BW, 1988, IEEE T SOFTWARE ENG, V14, P1462, DOI 10.1109/32.6191; BRIAND LC, 1993, IEEE T SOFTWARE ENG, V19, P1028, DOI 10.1109/32.256851; Bryson AE, 1969, APPL OPTIMAL CONTROL; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Cristianini N., 2000, INTRO SUPPORT VECTOR; GERSHENFELD NA, 1993, FUTURE TIME SERIES L, P1; GILL GK, 1991, IEEE T SOFTWARE ENG, V17, P1284, DOI 10.1109/32.106988; Goh TH, 1991, P IEEE INT JOINT C N, P18; Halstead M.H., 1977, ELEMENTS SOFTWARE SC; JOLLIFFE IT, 1986, PRINCIPLA COMPONENT; Khoshgoftaar T. M., 1998, Empirical Software Engineering, V3, DOI 10.1023/A:1009736205722; KHOSHGOFTAAR TM, 1994, IEEE J SEL AREA COMM, V12, P279, DOI 10.1109/49.272878; Lehman MM, 1998, PROC IEEE INT CONF S, P208, DOI 10.1109/ICSM.1998.738510; LI HF, 1987, IEEE T SOFTWARE ENG, V13, P697, DOI 10.1109/TSE.1987.233475; McCabe T. J., 1976, IEEE Transactions on Software Engineering, VSE-2, DOI 10.1109/TSE.1976.233837; MCCABE TJ, 1989, COMMUN ACM, V32, P1415, DOI 10.1145/76380.76382; Mercer J, 1909, PHILOS T R SOC LOND, V209, P415, DOI 10.1098/rsta.1909.0016; Mitchell T, 1997, MACHINE LEARNING; KHOSHGOFTAAR TM, 1990, IEEE J SEL AREA COMM, V8, P253, DOI 10.1109/49.46879; MUNSON JC, 1992, IEEE T SOFTWARE ENG, V18, P423, DOI 10.1109/32.135775; MUNSON JC, 1990, INFORM SOFTWARE TECH, V32, P106, DOI 10.1016/0950-5849(90)90109-5; Myrtveit I, 2005, IEEE T SOFTWARE ENG, V31, P380, DOI 10.1109/TSE.2005.58; Neumann DE, 2002, IEEE T SOFTWARE ENG, V28, P904, DOI 10.1109/TSE.2002.1033229; PORTER AA, 1990, IEEE SOFTWARE, V7, P46, DOI 10.1109/52.50773; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Saltelli A., 2000, SENSITIVITY ANAL; SHEN VY, 1985, IEEE T SOFTWARE ENG, V11, P317, DOI 10.1109/TSE.1985.232222; Xing F., 2005, P 16 IEEE INT S SOFT, P213, DOI DOI 10.1109/ISSRE.2005.6	32	19	24	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0164-1212		J SYST SOFTWARE	J. Syst. Softw.	FEB	2008	81	2					186	195		10.1016/j.jss.2007.05.035		10	Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	261SJ	WOS:000253100000003	
J	Li, ZS; Li, JS; Feng, F; Zhao, X				Li Zhisheng; Li Junshan; Feng Fan; Zhao Xin			Self-organizing fuzzy clustering neural network and application to electronic countermeasures effectiveness evaluation	JOURNAL OF SYSTEMS ENGINEERING AND ELECTRONICS			English	Article						fuzzy clusteringself-organizing neural network; effectiveness evaluation		A self-organizing fuzzy clustering neural network by combining the self-organizing Kohonen clustering network with the fuzzy theory is proposed. This network model is designed for the effectiveness evaluation of electronic countermeasures, which not only exerts the advantages of the fuzzy theory, but also has a good ability in machine learning and data analysis. The subjective value of sample versus class is computed by the fuzzy computing theory, and the classified results obtained by self-organizing learning of Kohonen neural network are represented on output layer. Meanwhile, the fuzzy competition learning algorithm keeps the similar information between samples and overcomes the disadvantages of neural network which has fewer samples. The simulation result indicates that the proposed algorithm is feasible and effective.	[Li Zhisheng; Li Junshan; Feng Fan] Second Artillery Engn Coll, Xian 710025, Peoples R China; [Li Zhisheng] PLA 92941, Huludao 125000, Peoples R China; [Zhao Xin] Beijing Inst Technol, Sch Informat Sci & Technol, Beijing 100081, Peoples R China	Li, ZS (reprint author), Second Artillery Engn Coll, Xian 710025, Peoples R China.	zhisheng_li@126.com					CHEN SY, 2005, J HYDRAULIC, V6, P662; CHEN SY, 1998, ENGINEER FUZZY SET T, P105; LU XL, 2005, ACTA ARMAMENTARII, V26, P681; MELODY Y, 1995, DECIS SUPPORT SYST, V15, P351; Milano M, 2004, IEEE T NEURAL NETWOR, V15, P758, DOI 10.1109/TNN.2004.826132; SPEZIO AE, 2002, T MICROWAVE THECH, V50, P793	6	1	1	SYSTEMS ENGINEERING & ELECTRONICS, EDITORIAL DEPT	BEIJING	PO BOX 142-32, BEIJING, 100854, PEOPLES R CHINA	1004-4132		J SYST ENG ELECTRON	J. Syst. Eng. Electron.	FEB	2008	19	1					119	124				6	Automation & Control Systems; Engineering, Electrical & Electronic; Operations Research & Management Science	Automation & Control Systems; Engineering; Operations Research & Management Science	294KH	WOS:000255404400019	
J	Yuan, XF; Wang, YN				Yuan Xiaofang; Wang Yaonan			Parameter selection of support vector machine for function approximation based on chaos optimization	JOURNAL OF SYSTEMS ENGINEERING AND ELECTRONICS			English	Article						learning systems; support vector machines (SVM); approximation theory; parameter selection; optimization	NEURAL NETWORKS; REGRESSION	The support vector machine (SVM) is a novel machine learning method, which has the ability to approximate nonlinear functions with arbitrary accuracy. Setting parameters well is very crucial for SVM learning results and generalization ability, and now there is no systematic, general method for parameter selection. In this article, the SVM parameter selection for function approximation is regarded as a compound optimization problem and a mutative scale chaos optimization algorithm is employed to search for optimal parameter values. The chaos optimization algorithm is an effective way for global optimal and the mutative scale chaos algorithm could improve the search efficiency and accuracy. Several simulation examples show the sensitivity of the SVM parameters and demonstrate the superiority of this proposed method for nonlinear function approximation.	[Yuan Xiaofang; Wang Yaonan] Hunan Univ, Coll Elect & Informat Engn, Changsha 410082, Hunan, Peoples R China	Yuan, XF (reprint author), Hunan Univ, Coll Elect & Informat Engn, Changsha 410082, Hunan, Peoples R China.	yuanxiaof@21cn.com					Byun H, 2003, INT J PATTERN RECOGN, V17, P459, DOI 10.1142/S0218001403002460; Chan WC, 2001, ENG APPL ARTIF INTEL, V14, P105, DOI 10.1016/S0952-1976(00)00069-5; Cherkassky V, 2004, NEURAL NETWORKS, V17, P113, DOI 10.1016/S0893-6080(03)00169-2; Chuang CC, 2002, IEEE T NEURAL NETWOR, V13, P1322, DOI 10.1109/TNN.2002.804227; FUNAHASHI K, 1989, NEURAL NETWORKS, V2, P183, DOI 10.1016/0893-6080(89)90003-8; He D, 2001, IEEE T CIRCUITS-I, V48, P900; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Li Bing, 1997, Control Theory & Applications, V14; Vapnik V. N, 1995, NATURE STAT LEARNING; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Wang WJ, 2003, NEUROCOMPUTING, V55, P643, DOI 10.1016/S0925-2312(02)00632-X	11	11	16	SYSTEMS ENGINEERING & ELECTRONICS, EDITORIAL DEPT	BEIJING	PO BOX 142-32, BEIJING, 100854, PEOPLES R CHINA	1004-4132		J SYST ENG ELECTRON	J. Syst. Eng. Electron.	FEB	2008	19	1					191	197				7	Automation & Control Systems; Engineering, Electrical & Electronic; Operations Research & Management Science	Automation & Control Systems; Engineering; Operations Research & Management Science	294KH	WOS:000255404400030	
J	Vaidya, J; Yu, HJ; Jiang, XQ				Vaidya, Jaideep; Yu, Hwanjo; Jiang, Xiaoqian			Privacy-preserving SVM classification	KNOWLEDGE AND INFORMATION SYSTEMS			English	Article; Proceedings Paper	10th Pacific-Asia Conference on Knowledge Discovery and Data Mining	APR   09, 2005-APR 12, 2006	Singapore, SINGAPORE	USAF Off Sci Res, Asian Off Aerosp Res & Dev, USA ITC, PAC Asian Res Off, Informat Dev Author Singapore, Lee Fdn, SAS, SPSS Inc, Embassy United States Amer, Singapore		support vector machine; classification; privacy; security	PARTITIONED DATA; DATABASES; SECURE	Traditional Data Mining and Knowledge Discovery algorithms assume free access to data, either at a centralized location or in federated form. Increasingly, privacy and security concerns restrict this access, thus derailing data mining projects. What is required is distributed knowledge discovery that is sensitive to this problem. The key is to obtain valid results, while providing guarantees on the nondisclosure of data. Support vector machine classification is one of the most widely used classification methodologies in data mining and machine learning. It is based on solid theoretical foundations and has wide practical application. This paper proposes a privacy-preserving solution for support vector machine (SVM) classification, PP-SVM for short. Our solution constructs the global SVM classification model from data distributed at multiple parties, without disclosing the data of each party to others. Solutions are sketched out for data that is vertically, horizontally, or even arbitrarily partitioned. We quantify the security and efficiency of the proposed method, and highlight future challenges.	[Vaidya, Jaideep] Rutgers State Univ, Management Sci & Informat Syst Dept, Newark, NJ 07102 USA; [Yu, Hwanjo; Jiang, Xiaoqian] Univ Iowa, Dept Comp Sci, Iowa City, IA USA	Vaidya, J (reprint author), Rutgers State Univ, Management Sci & Informat Syst Dept, Newark, NJ 07102 USA.	jsvaidya@rbs.rutgers.edu	Jiang, Xiaoqian/K-6752-2012				Aggarwal CC, 2004, LECT NOTES COMPUT SC, V2992, P183; Agrawal D, 2000, P ACM SIGMOD C MAN D, P439; AGRAWAL D., 2001, P 20 ACM SIGMOD SIGA, P247, DOI DOI 10.1145/375551.375602; Atallah MJ, 2001, P 17 ANN COMP SEC AP; Benaloh J. C., 1987, LNCS, V263, P251; BLUM M, 1984, ADV CRYPTOLOGY CRYPT; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Christianini N., 2000, INTRO SUPPORT VECTOR; DU W, 2002, IEEE INT C DAT MIN W, V14, P1; Evfimievski A., 2002, 8 ACM SIGKDD INT C K, P217; Fung G., 2001, P KDD 2001 KNOWL DIS, P77, DOI 10.1145/502512.502527; Goethals B, 2004, LECT NOTES COMPUT SC, V3506, P104; Goldreich O., 1987, 19 STOC, P218, DOI DOI 10.1145/28395.28420; HUANG Z, 2005, P 2005 ACM SIGMOD IN; IOANNIDIS I, 2002, 2002 INT C PAR PROC; Jagannathan G., 2005, P 11 ACM SIGKDD INT, P593, DOI 10.1145/1081870.1081942; Kantarcioglu M, 2004, IEEE T KNOWL DATA EN, V16, P1026, DOI 10.1109/TKDE.2004.45; Kargupta H, 2003, P 3 IEEE INT C DAT M; Kargupta H, 2005, KNOWL INF SYST, V7, P387, DOI 10.1007/s10115-004-0173-6; Karr AF, 2005, J COMPUT GRAPH STAT, V14, P263, DOI 10.1198/106186005X47714; Lin XD, 2005, KNOWL INF SYST, V8, P68, DOI 10.1007/s10115-004-0148-7; Lindell Y, 2002, J CRYPTOL, V15, P177, DOI 10.1007/s00145-001-0019-2; Mielikainen T, 2004, LECT NOTES COMPUT SC, V3245, P219; Naccache D., 1998, P 5 ACM C COMP COMM, P59, DOI 10.1145/288090.288106; Okamoto T, 1998, LECT NOTES COMPUT SC, V1403, P308; Oliveira S.R.M., 2003, P 18 BRAZ S DAT MAN, P304; Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223; Ravikumar P., 2004, P WORKSH PRIV SEC AS, P40; Rizvi S., 2002, P 28 INT C VER LARG; Sanil AP, 2004, P 10 ACM SIGKDD INT, P677, DOI 10.1145/1014052.1014139; SWEENEY L, 2004, CMUISRI04126; Vaidya J., 2004, P 4 IEEE INT C DAT M, P233; VAIDYA J, 2005, 19 ANN IFIP WG 11 3; VAIDYA J, 2005, PRIVACY PRESERVING D, V19; Vaidya J., 2003, 9 ACM SIGKDD INT C K, P206; Vaidya J., 2002, 8 ACM SIGKDD INT C K, P639, DOI [10.1145/775047.775142, DOI 10.1145/775047.775142]; VAIDYA J, 2004, 2004 SIAM INT C DAT, P522; Vaidya J., 2005, Journal of Computer Security, V13; Vapnik VN, 1998, STAT LEARNING THEORY; Verykios VS, 2004, SIGMOD REC, V33, P50; Wright R., 2004, P 10 ACM SIGKDD INT; Xu ST, 2006, KNOWL INF SYST, V10, P383, DOI 10.1007/s10115-006-0001-2; Yao A.C.-C., 1986, P 27 IEEE S FDN COMP, P162; Yu H., 2006, SAC 06, P603; Yu H., 2004, UIOWACS0404; YU H, IN PRESS DATA KNOWLE; Yu H, 2006, LECT NOTES ARTIF INT, V3918, P647; ZHANG N, 2004, 8 EUR C PRINC PRACT; ZHU Y, 2004, KDD 04 P 10 ACM SIGK, P761; *STAND PRIV IND ID, 2001, FED REG, V66	50	11	12	SPRINGER LONDON LTD	ARTINGTON	ASHBOURNE HOUSE, THE GUILDWAY, OLD PORTSMOUTH ROAD, ARTINGTON GU3 1LP, GUILDFORD, ENGLAND	0219-1377		KNOWL INF SYST	Knowl. Inf. Syst.	FEB	2008	14	2					161	178		10.1007/s10115-007-0073-7		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	255RF	WOS:000252674400003	
J	Chae, JM; Oh, HB; Choi, SE; Cha, CH; Kim, MH; Jung, SY				Chae, Jeong-Min; Oh, Heung-Bum; Choi, Sung-Eun; Cha, Choong-Hwan; Kim, Myung-Hee; Jung, Soon-Young			Development of a system for extracting the information of candidate tumor markers reported in biomedical literatures	KOREAN JOURNAL OF LABORATORY MEDICINE			Korean	Article						tumor; tumor marker; information extraction	AUTOMATED EXTRACTION; PROTEIN NAMES; GENE; TEXT	Background : Since the human genome project was completed in 2003, there have been numerous reports on cancer and related markers. This study was aimed to develop a system to extract automatically information regarding the relationship between cancer and tumor markers from biomedical literatures. Methods : Named entities of tumor markers were recognized by both a dictionary-based method and machine learning technology of the support vector machine. Named entities of cancers were recognized by the MeSH dictionary. Results : Relational and filtering keywords were selected after annotating 160 abstracts from PubMed. Relational information was extracted only when one of the relational keywords was in an appropriate position along the parse tree of a sentence with both tumor marker and disease entities. The performance of the system developed in this study was evaluated with another set of 77 abstracts. With the relational and filtering keyword used in the system, precision was 94.38% and recall was 66.14%, while without the expert knowledge precision was 49.16% and recall was 69.29%. Conclusions: We developed a system that can extract relational information between a tumor and its markers by incorporating expert knowledge into the system. The system exploiting expert knowledge would serve as a reference when developing another information extraction system in various medical fields.	[Chae, Jeong-Min; Jung, Soon-Young] Korea Univ, Dept Comp Sci Educ, Seoul 136701, South Korea; [Oh, Heung-Bum; Choi, Sung-Eun; Cha, Choong-Hwan; Kim, Myung-Hee] Univ Ulsan, Coll Med, Dept Lab Med, Seoul, South Korea; [Oh, Heung-Bum; Choi, Sung-Eun; Cha, Choong-Hwan; Kim, Myung-Hee] Asan Med Ctr, Seoul, South Korea	Chae, JM (reprint author), Korea Univ, Dept Comp Sci Educ, Seoul 136701, South Korea.	hboh@amc.seoul.kr					Ananiadou S., 2006, TEXT MINING BIOL BIO, P1; ANANIADOU S, 2006, TEXT MINING BIOL BIO, P67; Bodenreider O, 2006, TEXT MINING BIOL BIO, P43; CHAE JM, 2006, TUMOR MARKER INFORM; Collins FS, 2003, NATURE, V422, P835, DOI 10.1038/nature01626; COLLINS M, 1995, THESIS PENNSYLVANIA; Cristianini N., 2000, INTRO SUPPORT VECTOR; Friedman C, 2001, Bioinformatics, V17 Suppl 1, pS74; Hatzivassiloglou V, 2001, Bioinformatics, V17 Suppl 1, pS97; Herbst RS, 2006, J CLIN ONCOL, V24, P190, DOI 10.1200/JCO.2005.04.8678; Hernandez J, 2004, CANCER, V101, P894, DOI 10.1002/cncr.20480; Horn F, 2004, BIOINFORMATICS, V20, P557, DOI 10.1093/bioinformatics/btg449; Jensen LJ, 2006, NAT REV GENET, V7, P119, DOI 10.1038/nrg1768; KAZAMA J, 2002, ACL02 WORKSH NLP BIO, P1; Kim J, 2003, BIOINFORMATICS S1, V19, P180, DOI DOI 10.1093/BIOINFORMATICS/BTG1023; Krauthammer M, 2000, GENE, V259, P245, DOI 10.1016/S0378-1119(00)00431-5; Lee KJ, 2004, J BIOMED INFORM, V37, P436, DOI 10.1016/j.jbi.2004.08.012; Marsh SGE, 2005, TISSUE ANTIGENS, V65, P301, DOI 10.1111/j.1399-0039.2005.00379.x; McNaught J, 2006, TEXT MINING BIOL BIO, P143; Novichkova S, 2003, BIOINFORMATICS, V19, P1699, DOI 10.1093/bioinformatics/btg207; Ono T, 2001, BIOINFORMATICS, V17, P155, DOI 10.1093/bioinformatics/17.2.155; Park J. C., 2006, TEXT MINING BIOL BIO, P121; PROUX D, 1998, GENOME INFORM SER WO, V9, P72; SHIN HR, 2004, J KOREAN ASS CANC PR, V9, P49; Tanabe L, 2002, BIOINFORMATICS, V18, P1124, DOI 10.1093/bioinformatics/18.8.1124; Temkin JM, 2003, BIOINFORMATICS, V19, P2046, DOI 10.1093/bioinformatics/btg279; Zhou GD, 2004, BIOINFORMATICS, V20, P1178, DOI 10.1093/bioinformatics/bth060	27	0	0	KOREAN SOC LABORATORY MEDICINE	SEOUL	KOREAN MEDICAL ASSOC BLDG, RM 602,302-75 ICHON 1-DONG, YONGSAN-GU, SEOUL, 140-721, SOUTH KOREA	1598-6535		KOR J LAB MED	Kor. J. Lab. Med.	FEB	2008	28	1					79	87		10.3343/kjlm.2008.28.1.79		9	Medical Laboratory Technology	Medical Laboratory Technology	287KH	WOS:000254915500011	
J	Gins, G; Smets, IY; Van Impe, JF				Gins, Geert; Smets, Ilse Y.; Van Impe, Jan F.			Efficient tracking of the dominant eigenspace of a normalized kernel matrix	NEURAL COMPUTATION			English	Article							NONLINEAR COMPONENT ANALYSIS	Various machine learning problems rely on kernel-based methods. The power of these methods resides in the ability to solve highly nonlinear problems by reformulating them in a linear context. The dominant eigenspace of a (normalized) kernel matrix is often required. Unfortunately, the computational requirements of the existing kernel methods are such that the applicability is restricted to relatively small data sets. This letter therefore focuses on a kernel-based method for large data sets. More specifically, a numerically stable tracking algorithm for the dominant eigenspace of a normalized kernel matrix is proposed, which proceeds by an updating (the addition of a new data point) followed by a downdating (the exclusion of an old data point) of the kernel matrix. Testing the algorithm on some representative case studies reveals that a very good approximation of the dominant eigenspace is obtained, while only a minimal amount of operations and memory space per iteration step is required.	[Gins, Geert; Smets, Ilse Y.; Van Impe, Jan F.] Katholieke Univ Leuven, B-3001 Louvain, Belgium	Gins, G (reprint author), Katholieke Univ Leuven, W Croylaan 46, B-3001 Louvain, Belgium.	geert.gins@cit.kuleuven.be; ilse.smets@cit.kuleuven.be; jan.vanimpe@cit.kuleuven.be					BAGLAMA J, 2004, IRBLEIGS MATLAB PROG; Blake C. L., 1998, UCI REPOSITORY MACHI; Golub G. H., 1996, MATRIX COMPUTATIONS; Hoegaerts L, 2007, NEURAL NETWORKS, V20, P220, DOI 10.1016/j.neunet.2006.09.012; HOEGAERTS L, 2004, P 16 INT S MATH THEO; Kim K., 2003, 109 MAX PLANCK I BIO, V06, P2003; LARSEN RM, 2004, PROPACK SOFTWARE LAR; Ng A, 2002, ADV NEURAL INFORM PR; Rosipal R, 2001, NEURAL COMPUT, V13, P505, DOI 10.1162/089976601300014439; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B., 2002, LEARNING KERNELS; Suykens J.A.K., 2002, LEAST SQUARES SUPPOR; WEISS Y, 1999, P IEEE INT C COMP VI, V9, P975	13	1	1	M I T PRESS	CAMBRIDGE	238 MAIN STREET, STE 500, CAMBRIDGE, MA 02142-1046 USA	0899-7667		NEURAL COMPUT	Neural Comput.	FEB	2008	20	2					523	554		10.1162/neco.2007.05-06-213		32	Computer Science, Artificial Intelligence	Computer Science	249RU	WOS:000252248200010	
J	Wang, Z; Fernandez-Seara, M; Alsop, DC; Liu, WC; Flax, JF; Benasich, AA; Detre, JA				Wang, Ze; Fernandez-Seara, Maria; Alsop, David C.; Liu, Wen-Ching; Flax, Judy F.; Benasich, April A.; Detre, John A.			Assessment of functional development in normal infant brain using arterial spin labeled perfusion MRI	NEUROIMAGE			English	Article						brain development; ASL perfusion MRI; infants; SVM	POSITRON EMISSION TOMOGRAPHY; SUPPORT VECTOR MACHINES; CEREBRAL-BLOOD-FLOW; FMRI DATA SETS; ALZHEIMERS-DISEASE; DEFAULT-MODE; CORTICAL DEVELOPMENT; COGNITIVE FUNCTION; RESTING BRAIN; ACTIVATION	Arterial spin labeled (ASL) perfusion MRI provides a noninvasive approach for longitudinal imaging of regional brain function in infants. In the present study, continuous ASL (CASL) perfusion MRI was carried out in normally developing 7- and 13-month-old infants while asleep without sedation. The 13-month infant group showed an increase (P<0.05) of relative CBF in frontal regions as compared to the 7-month group using a region of interest based analysis. Using a machine-learning algorithm to automatically classify the relative CBF maps of the two infant groups, a significant (P<0.05, permutation testing) regional CBF increase was found in the hippocampi, anterior cingulate, amygdalae, occipital lobes, and auditory cortex in the 13-month-old infants. These results are consistent with current understanding of infant brain development and demonstrate the feasibility of using perfusion MRI to noninvasively monitor developing brain function. (c) 2007 Elsevier Inc. All rights reserved.	[Wang, Ze; Detre, John A.] Hosp Univ Penn, Sch Med, Dept Neurol, Ctr Funct Neuroimaging, Philadelphia, PA 19104 USA; [Wang, Ze; Detre, John A.] Hosp Univ Penn, Sch Med, Dept Radiol, Ctr Funct Neuroimaging, Philadelphia, PA 19104 USA; [Fernandez-Seara, Maria] Univ Navarra, Ctr Appl Med Res, Dept Neurosci, Neuroimaging Lab, Pamplona 31008, Spain; [Alsop, David C.] Beth Israel Deaconess Med Ctr, Dept Radiol, Boston, MA 02215 USA; [Liu, Wen-Ching; Benasich, April A.] Univ Med & Dent New Jersey, Sch Med, Dept Radiol, Newark, NJ 07103 USA; [Flax, Judy F.; Benasich, April A.] Rutgers State Univ, Ctr Mol & Behav Neurosci, Newark, NJ 07102 USA	Wang, Z (reprint author), Hosp Univ Penn, Sch Med, Dept Radiol, Ctr Funct Neuroimaging, 3400 Spruce St, Philadelphia, PA 19104 USA.	zewang@mail.med.upenn.edu	Wang, Ze/A-1043-2007				Alsop DC, 2000, ANN NEUROL, V47, P93, DOI 10.1002/1531-8249(200001)47:1<93::AID-ANA15>3.0.CO;2-8; Alsop DC, 1998, RADIOLOGY, V208, P410; Badridze N., 2004, P J COGNITIVE NEUR S, V15, pF124; BIAGI L, 2000, J MAGN RESON IMAGING, V25, P696; Biswal BB, 1999, J COMPUT ASSIST TOMO, V23, P265, DOI 10.1097/00004728-199903000-00016; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chalela JA, 2000, STROKE, V31, P680; CHUGANI HT, 1986, SCIENCE, V231, P840, DOI 10.1126/science.3945811; CHUGANI HT, 1987, ANN NEUROL, V22, P487, DOI 10.1002/ana.410220408; Dehaene-Lambertz G, 2006, P NATL ACAD SCI USA, V103, P14240, DOI 10.1073/pnas.0606302103; Dehaene-Lambertz G, 2002, SCIENCE, V298, P2013, DOI 10.1126/science.1077066; Fuster JM, 2002, J NEUROCYTOL, V31, P373, DOI 10.1023/A:1024190429920; FUSTER JM, 1984, TRENDS NEUROSCI, V7, P408, DOI 10.1016/S0166-2236(84)80144-7; GARCIA DM, 2005, P P INTL SOC MAG RES, P13; Gogtay N, 2004, P NATL ACAD SCI USA, V101, P8174, DOI 10.1073/pnas.0402680101; GOLDMANRAKIC PS, 1984, TRENDS NEUROSCI, V7, P425, DOI 10.1016/S0166-2236(84)80147-2; Golub G. H., 1996, MATRIX COMPUTATIONS; Greicius MD, 2003, P NATL ACAD SCI USA, V100, P253, DOI 10.1073/pnas.0135058100; Greicius MD, 2004, P NATL ACAD SCI USA, V101, P4637, DOI 10.1073/pnas.0308627101; Grossmann T, 2007, EUR J NEUROSCI, V25, P909, DOI 10.1111/j.1460-9568.2007.05379.x; He X, 2007, MAGN RESON MED, V57, P115, DOI 10.1002/mrm.21108; HOFFMAN JM, 1989, EUR NEUROL, V29, P16, DOI 10.1159/000116476; Huang CR, 2007, NEUROIMAGE, V34, P714, DOI 10.1016/j.neuroimage.2006.09.003; Iannetti GD, 2005, P NATL ACAD SCI USA, V102, P18195, DOI 10.1073/pnas.0506624102; Joachims T, 1999, ADV KERNEL METHODS S, P42; Kadir A, 2006, PSYCHOPHARMACOLOGY, V188, P509, DOI 10.1007/s00213-006-0447-7; KAGAN J, 1972, SCI AM, V226, P74; LaConte S, 2005, NEUROIMAGE, V26, P317, DOI 10.1016/j.neuroimage.2005.01.048; Liao JR, 1997, MAGNET RESON MED, V37, P569, DOI 10.1002/mrm.1910370416; Maldjian JA, 2003, NEUROIMAGE, V19, P1233, DOI 10.1016/S1053-8119(03)00169-1; MEYER CH, 1992, MAGNET RESON MED, V28, P202, DOI 10.1002/mrm.1910280204; Mourao-Miranda J, 2005, NEUROIMAGE, V28, P980, DOI 10.1016/j.neuroimage.2005.06.070; Nichols TE, 2002, HUM BRAIN MAPP, V15, P1, DOI 10.1002/hbm.1058; Paterson SJ, 2006, NEUROSCI BIOBEHAV R, V30, P1087, DOI 10.1016/j.neubiorev.2006.05.001; Raichle ME, 2001, P NATL ACAD SCI USA, V98, P676, DOI 10.1073/pnas.98.2.676; Rao HY, 2007, BIOL PSYCHIAT, V62, P600, DOI 10.1016/j.biopsych.2006.11.028; ROMBOUTS SA, 2007, HUM BRAIN MAPP; Shaw P, 2006, NATURE, V440, P676, DOI 10.1038/nature04513; Small SA, 2000, NEURON, V28, P653, DOI 10.1016/S0896-6273(00)00144-6; Souweidane MM, 1999, PEDIATR NEUROSURG, V30, P86, DOI 10.1159/000028768; SPIELMAN DM, 1995, MAGNET RESON MED, V34, P388, DOI 10.1002/mrm.1910340316; Vetterling W.T., 2002, NUMERICAL RECIPES C; Wang LH, 2005, CELL CYCLE, V4, P242; WANG Z, 2007, MAGN RESON IMAG 0907; WANG Z, 2006, P 28 IEEE EMBS ANN I, P1006; Wang Z, 2005, MAGNET RESON MED, V54, P732, DOI 10.1002/mrm.20574; Wang Z, 2007, NEUROIMAGE, V36, P1139, DOI 10.1016/j.neuroimage.2007.03.072; WILLIAMS DS, 1992, P NATL ACAD SCI USA, V89, P212, DOI 10.1073/pnas.89.1.212; Ye FQ, 2000, MAGNET RESON MED, V44, P92, DOI 10.1002/1522-2594(200007)44:1<92::AID-MRM14>3.0.CO;2-M; Zarahn E, 1997, NEUROIMAGE, V5, P179, DOI 10.1006/nimg.1997.0263	50	20	20	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1053-8119		NEUROIMAGE	Neuroimage	FEB 1	2008	39	3					973	978		10.1016/j.neuroimage.2007.09.045		6	Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical Imaging	Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging	255XN	WOS:000252691800007	
J	Vemuri, P; Gunter, JL; Senjem, ML; Whitwell, JL; Kantarci, K; Knopman, DS; Boeve, BF; Petersen, RC; Jack, CR				Vemuri, Prashanthi; Gunter, Jeffrey L.; Senjem, Matthew L.; Whitwell, Jennifer L.; Kantarci, Kejal; Knopman, David S.; Boeve, Bradley F.; Petersen, Ronald C.; Jack, Clifford R., Jr.			Alzheimer's disease diagnosis in individual subjects using structural MR images: Validation studies	NEUROIMAGE			English	Article						support vector machines; classification; diagnosis; Alzheimer's	MILD COGNITIVE IMPAIRMENT; VOXEL-BASED MORPHOMETRY; APOLIPOPROTEIN-E GENOTYPE; MACHINE LEARNING-METHODS; HIPPOCAMPAL VOLUME; DEMENTIA; SEX; ATROPHY; AGE; AD	Objective: To develop and validate a tool for Alzheimer's disease (AD) diagnosis in individual subjects using support vector machine (SVM)-based classification of structural MR (sMR) images. Background. Libraries of sMR scans of clinically well characterized subjects can be harnessed for the purpose of diagnosing new incoming subjects. Methods: One hundred ninety patients with probable AD were age-and gender-matched with 190 cognitively normal (CN) subjects. Three different classification models were implemented: Model I uses tissue densities obtained from sMR scans to give STructural Abnormality iNDex (STAND)-score; and Models II and III use tissue densities as well as covariates (demographics and Apolipoprotein E genotype) to give adjusted-STAND (aSTAND)-score. Data from 140 AD and 140 CN were used for training. The SVM parameter optimization and training were done by four-fold cross validation (CV). The remaining independent sample of 50 AD and 50 CN was used to obtain a minimally biased estimate of the generalization error of the algorithm. Results: The CV accuracy of Model II and Model III aSTAND-scores was 88.5% and 89.3%, respectively, and the developed models generalized well on the independent test data sets. Anatomic patterns best differentiating the groups were consistent with the known distribution of neurofibrillary AD pathology. Conclusions: This paper presents preliminary evidence that application of SVM-based classification of an individual sMR scan relative to a library of scans can provide useful information in individual subjects for diagnosis of AD. Including demographic and genetic information in the classification algorithm slightly improves diagnostic accuracy. (c) 2007 Elsevier Inc. All rights reserved.	[Vemuri, Prashanthi; Gunter, Jeffrey L.; Senjem, Matthew L.; Whitwell, Jennifer L.; Kantarci, Kejal; Jack, Clifford R., Jr.] Mayo Clin, Dept Radiol, Rochester, MN 55905 USA; [Knopman, David S.; Boeve, Bradley F.; Petersen, Ronald C.] Mayo Clin, Dept Neurol, Rochester, MN USA	Jack, CR (reprint author), Mayo Clin, Dept Radiol, 200 1st St SW, Rochester, MN 55905 USA.	jack.clifford@mayo.edu	Jack, Clifford/F-2508-2010; Vemuri, Prashanthi/K-7030-2012				Alexander Gene E., 1994, Human Brain Mapping, V2, P79, DOI 10.1002/hbm.460020108; American Psychiatric Association, 1987, DIAGN STAT MAN MENT; Ashburner J, 2005, NEUROIMAGE, V26, P839, DOI 10.1016/j.neuroimage.2005.02.018; Ashburner J, 2000, NEUROIMAGE, V11, P805, DOI 10.1006/nimg.2000.0582; Barnes J, 2004, NEUROIMAGE, V23, P574, DOI 10.1016/j.neuroimage.2004.06.028; Bickeboller H, 1997, AM J HUM GENET, V60, P439; Bigler ED, 2000, AM J NEURORADIOL, V21, P1857; Bozzali M, 2006, NEUROLOGY, V67, P453, DOI 10.1212/01.wnl.0000228243.56665.c2; BRAAK H, 1994, NEUROBIOL AGING, V15, P355, DOI 10.1016/0197-4580(94)90032-9; Craft S, 1998, NEUROLOGY, V51, P149; Cristianini N., 2000, INTRO SUPPORT VECTOR; CRYSTAL HA, 1993, ANN NEUROL, V34, P566, DOI 10.1002/ana.410340410; Csernansky JG, 2005, NEUROIMAGE, V25, P783, DOI 10.1016/j.neuroimage.2004.12.036; Davatzikos C, 2005, NEUROIMAGE, V28, P663, DOI 10.1016/j.neuroimage.2005.08.009; Duda R., 2000, PATTERN CLASSIFICATI; EVANS DA, 1989, JAMA-J AM MED ASSOC, V262, P2551, DOI 10.1001/jama.262.18.2551; Fan Yong, 2005, Med Image Comput Comput Assist Interv, V8, P1; Farrer LA, 1997, JAMA-J AM MED ASSOC, V278, P1349, DOI 10.1001/jama.278.16.1349; Fleisher A, 2005, ARCH NEUROL-CHICAGO, V62, P953, DOI 10.1001/archneur.62.6.953; FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6; Freeborough PA, 1998, IEEE T MED IMAGING, V17, P475, DOI 10.1109/42.712137; Freeborough PA, 1998, J COMPUT ASSIST TOMO, V22, P838, DOI 10.1097/00004728-199809000-00031; GomezIsla T, 1996, J NEUROSCI, V16, P4491; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hastie T, 2001, ELEMENTS STAT LEARNI; Hirata Y, 2005, NEUROSCI LETT, V382, P269, DOI 10.1016/j.neulet.2005.03.038; HUGHES CP, 1982, BRIT J PSYCHIAT, V140, P566, DOI 10.1192/bjp.140.6.566; Hulette CM, 1998, J NEUROPATH EXP NEUR, V57, P1168, DOI 10.1097/00005072-199812000-00009; Jack CR, 1999, NEUROLOGY, V52, P1397; Jack CR, 1997, NEUROLOGY, V49, P786; Jicha GA, 2006, ARCH NEUROL-CHICAGO, V63, P674, DOI 10.1001/archneur.63.5.674; KATZMAN R, 1988, ANN NEUROL, V23, P138, DOI 10.1002/ana.410230206; Knopman DS, 2003, J NEUROPATH EXP NEUR, V62, P1087; Lao ZQ, 2004, NEUROIMAGE, V21, P46, DOI 10.1016/j.neuroimage.2003.09.027; Lemaitre H, 2005, NEUROIMAGE, V26, P900, DOI 10.1016/j.neuroimage.2005.02.042; MCKHANN G, 1984, NEUROLOGY, V34, P939; Metz CE, 1999, INT CONGR SER, V1182, P543; MLADENI D, 2004, P 27 ANN INT ACM SIG; Morris JC, 2001, J MOL NEUROSCI, V17, P101, DOI 10.1385/JMN:17:2:101; PALVIDIS P, 2002, J COMPUT BIOL, V9, P401; PETERSEN RC, 1995, JAMA-J AM MED ASSOC, V273, P1274, DOI 10.1001/jama.273.16.1274; Rakotomamonjy A., 2005, SVM KERNEL METHODS M; Riley KP, 2002, ANN NEUROL, V51, P567, DOI 10.1002/ana.10161; Schmitt FA, 2000, NEUROLOGY, V55, P370; Shiino A, 2006, NEUROIMAGE, V33, P17, DOI 10.1016/j.neuroimage.2006.06.010; SMITH CD, 2006, NEUROBIOL AGING; Testa C, 2004, J MAGN RESON IMAGING, V19, P274, DOI 10.1002/jmri.20001; Thompson PM, 2007, ANN NY ACAD SCI, V1097, P183, DOI 10.1196/annals.1379.017; Vapnik VN, 1998, STAT LEARNING THEORY; Varma S, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-91	50	126	126	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1053-8119		NEUROIMAGE	Neuroimage	FEB 1	2008	39	3					1186	1197		10.1016/j.neuroimage.2007.09.073		12	Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical Imaging	Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging	255XN	WOS:000252691800026	
J	da Silva, JPM; Acencio, ML; Mornbach, JCM; Vieira, R; da Silva, JC; Lemke, N; Sinigagliac, M				Muller da Silva, Joao Paulo; Acencio, Marcio Luis; Merino Mornbach, Jose Carlos; Vieira, Renata; da Silva, Jose Camargo; Lemke, Ney; Sinigagliac, Marialva			In silico network topology-based prediction of gene essentiality	PHYSICA A-STATISTICAL MECHANICS AND ITS APPLICATIONS			English	Article						biological networks; complex systems; gene essentiality; machine learning	PROTEIN-INTERACTION NETWORK; ESCHERICHIA-COLI; METABOLIC NETWORKS; GENOME; IDENTIFICATION; YEAST	The identification of genes essential for survival is important for the understanding of the minimal requirements for cellular life and for drug design. As experimental studies with the purpose of building a catalog of essential genes for a given organism are time-consuming and laborious, a computational approach which could predict gene essentiality with high accuracy would be of great value. We present here a novel computational approach, called NTPGE (Network Topology-based Prediction of Gene Essentiality), that relies on the network topology features of a gene to estimate its essentiality. The first step of NTPGE is to construct the integrated molecular network for a given organism comprising protein physical, metabolic and transcriptional regulation interactions. The second step consists in training a decision-tree-based machine-learning algorithm on known essential and non-essential genes of the organism of interest, considering as learning attributes the network topology information for each of these genes. Finally, the decision-tree classifier generated is applied to the set of genes of this organism to estimate essentiality for each gene. We applied the NTPGE approach for discovering the essential genes in Escherichia coli and then assessed its performance. (C) 2007 Elsevier B.V. All rights reserved.	[Muller da Silva, Joao Paulo; Acencio, Marcio Luis; Lemke, Ney] UNESP, Inst Biosci, Dept Phys & Biophys, BR-18618000 Botucatu, SP, Brazil; [Merino Mornbach, Jose Carlos] Univ Fed Santa Maria, Ctr Ciencias Rurais, Unipampa Sao Gabriel Posgrad Fis, BR-97105900 Santa Maria, RS, Brazil; [Vieira, Renata; da Silva, Jose Camargo; Sinigagliac, Marialva] Univ Vale Rio dos Sinos, Programs Interdisciplinar Computacao Aplicada, BR-93022000 Sao Leopoldo, RS, Brazil	Lemke, N (reprint author), UNESP, Inst Biosci, Dept Phys & Biophys, BR-18618000 Botucatu, SP, Brazil.	lemke@ibb.unesp.br	Lemke, Ney/A-8213-2008; Acencio, Marcio/D-9264-2012	Lemke, Ney/0000-0001-7463-4303; 			Butland G, 2005, NATURE, V433, P531, DOI 10.1038/nature03239; Cullen LM, 2005, IMMUNOL CELL BIOL, V83, P217, DOI 10.1111/j.1440-1711.2005.01332.x; DESILVA JPM, 2006, GENET MOL RES, V5, P182; Estrada E, 2006, PROTEOMICS, V6, P35, DOI 10.1002/pmic.200500209; Giaever G, 2002, NATURE, V418, P387, DOI 10.1038/nature00935; Gustafson AM, 2006, BMC GENOMICS, V7, DOI 10.1186/1471-2164-7-265; Imielinski M, 2005, BIOINFORMATICS, V21, P2008, DOI 10.1093/bioinformatics/bti245; ITAYA M, 1995, FEBS LETT, V362, P257, DOI 10.1016/0014-5793(95)00233-Y; Jeong H, 2001, NATURE, V411, P41, DOI 10.1038/35075138; Judson N, 2000, NAT BIOTECHNOL, V18, P740, DOI 10.1038/77305; Kanehisa M, 2006, NUCLEIC ACIDS RES, V34, pD354, DOI 10.1093/nar/gkj102; Kang PS, 2006, LECT NOTES COMPUT SC, V4232, P837; Kobayashi K, 2003, P NATL ACAD SCI USA, V100, P4678, DOI 10.1073/pnas.0730515100; Lemke N, 2004, BIOINFORMATICS, V20, P115, DOI 10.1093/bioinformatics/btg386; Palumbo MC, 2005, FEBS LETT, V579, P4642, DOI 10.1016/j.febslet.2005.07.033; QUINLAN JR, 1993, C45 PROGRAMS MACH LE; Roemer T, 2003, MOL MICROBIOL, V50, P167, DOI 10.1046/j.1365-2958.2003.03697.x; Salgado H, 2006, NUCLEIC ACIDS RES, V34, pD394, DOI 10.1093/nar/gkj156; Seringhaus M, 2006, GENOME RES, V16, P1126, DOI 10.1101/gr.5144106; Witten I. H., 2000, DATA MINING PRACTICA; Wuchty S, 2004, GENOME RES, V14, P1310, DOI 10.1101/gr.2300204	21	4	4	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0378-4371		PHYSICA A	Physica A	FEB 1	2008	387	4					1049	1055		10.1016/j.physa.2007.10.044		7	Physics, Multidisciplinary	Physics	254UK	WOS:000252613300029	
J	Tong, WX; Williams, RJ; Wei, Y; Murga, LF; Ko, JJ; Ondrechen, MJ				Tong, Wenxu; Williams, Ronald J.; Wei, Ying; Murga, Leonel F.; Ko, Jaeju; Ondrechen, Mary Jo			Enhanced performance in prediction of protein active sites with THEMATICS and support vector machines	PROTEIN SCIENCE			English	Article						functional genomics; active sites; THEMATICS; SVM; site prediction	CATALYTIC RESIDUES; BINDING-SITES; CRYSTAL-STRUCTURE; FUNCTIONAL SITES; ENZYME; SEQUENCE; IDENTIFICATION; PEROXIDASE; ANNOTATION; LOCATION	Theoretical microscopic titration curves (THEMATICS) is a computational method for the identification of active sites in proteins through deviations in computed titration behavior of ionizable residues. While the sensitivity to catalytic sites is high, the previously reported sensitivity to catalytic residues was not as high, about 50%. Here THEMATICS is combined with support vector machines (SVM) to improve sensitivity for catalytic residue prediction from protein 3D structure alone. For a test set of 64 proteins taken from the Catalytic Site Atlas (CSA), the average recall rate for annotated catalytic residues is 61%; good precision is maintained selecting only 4% of all residues. The average false positive rate, using the CSA annotations is only 3.2%, far lower than other 3D-structure-based methods. THEMATICS-SVM returns higher precision, lower false positive rate, and better overall performance, compared with other 3D-structure-based methods. Comparison is also made with the latest machine learning methods that are based on both sequence alignments and 3D structures. For annotated sets of well-characterized enzymes, THEMATICS-SVM performance compares very favorably with methods that utilize sequence homology. However, since THEMATICS depends only on the 3D structure of the query protein, no decline in performance is expected when applied to novel folds, proteins with few sequence homologues, or even orphan sequences. An extension of the method to predict non-ionizable catalytic residues is also presented. THEMATICS-SVM predicts a local network of ionizable residues with strong interactions between protonation events; this appears to be a special feature of enzyme active sites.	[Wei, Ying; Murga, Leonel F.; Ondrechen, Mary Jo] Northeastern Univ, Dept Chem & Biol Chem, Boston, MA 02115 USA; [Tong, Wenxu; Williams, Ronald J.] Northeastern Univ, Coll Comp & Informat Sci, Boston, MA 02115 USA; [Tong, Wenxu; Williams, Ronald J.; Wei, Ying; Murga, Leonel F.; Ondrechen, Mary Jo] Northeastern Univ, Inst Complex Sci Software, Boston, MA 02115 USA; [Ko, Jaeju] Indiana Univ Penn, Dept Chem, Indiana, PA 15705 USA	Ondrechen, MJ (reprint author), Northeastern Univ, Dept Chem & Biol Chem, 360 Huntington Ave, Boston, MA 02115 USA.	M.Ondrechen@neu.edu					Aloy P, 2001, J MOL BIOL, V311, P395, DOI 10.1006/jmbi.2001.4870; Amitai G, 2004, J MOL BIOL, V344, P1135, DOI 10.1016/j.jmb.2004.10.055; Bartlett GJ, 2002, J MOL BIOL, V324, P105, DOI 10.1016/S0022-2836(02)01036-7; Bate P, 2004, J MOL BIOL, V340, P263, DOI 10.1016/j.jmb.2004.04.070; Ben-Shimon A, 2005, J MOL BIOL, V351, P309, DOI 10.1016/j.jmb.2005.06.047; Burges C., 1998, DATA MIN KNOWL DISC, P1; Carter CW, 2001, J MOL BIOL, V311, P625, DOI 10.1006/jmbi.2001.4906; CHRISTIANINI N, 1999, INTRO SUPPORT VECTOR; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; de Rinaldis M, 1998, J MOL BIOL, V284, P1211, DOI 10.1006/jmbi.1998.2248; Devos D, 2000, PROTEINS, V41, P98, DOI 10.1002/1097-0134(20001001)41:1<98::AID-PROT120>3.0.CO;2-S; EDWARDS SL, 1987, BIOCHEMISTRY-US, V26, P1503, DOI 10.1021/bi00380a002; Elcock AH, 2001, J MOL BIOL, V312, P885, DOI 10.1006/jmbi.2001.5009; Gutteridge A, 2003, J MOL BIOL, V330, P719, DOI 10.1016/S0022-2836(03)00515-1; Hermann JC, 2007, NATURE, V448, P775, DOI 10.1038/nature05981; Innis CA, 2004, J MOL BIOL, V337, P1053, DOI 10.1016/j.jmb.2004.01.053; Joachims T., 1999, MAKING LARGE SCALE S; JORGENSEN WL, 1988, J AM CHEM SOC, V110, P1657, DOI 10.1021/ja00214a001; JORGENSEN WL, 1983, J CHEM PHYS, V79, P926, DOI 10.1063/1.445869; Karp PD, 1998, BIOINFORMATICS, V14, P753, DOI 10.1093/bioinformatics/14.9.753; Ko JJ, 2005, PROTEINS, V59, P183, DOI 10.1002/prot.20418; LANDGRAF R, 2001, J MOL BIOL, V307, P487; Laurie ATR, 2005, BIOINFORMATICS, V21, P1908, DOI 10.1093/bioinformatics/bti315; Mattos C, 1996, NAT BIOTECHNOL, V14, P595, DOI 10.1038/nbt0596-595; Meng EC, 2004, PROTEINS, V55, P962, DOI 10.1002/prot.20099; Ondrechen MJ, 2001, P NATL ACAD SCI USA, V98, P12473, DOI 10.1073/pnas.211436698; Ota M, 2003, J MOL BIOL, V327, P1053, DOI 10.1016/S0022-2836(03)00207-9; PATTERSON WR, 1995, BIOCHEMISTRY-US, V34, P4331, DOI 10.1021/bi00013a023; Petrova NV, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-312; Porter C.T., 2004, NUCLEIC ACIDS RES, V32, P129; Ren PY, 2003, J PHYS CHEM B, V107, P5933, DOI 10.1021/jp027815+; Shehadi IA, 2002, MOL BIOL REP, V29, P329, DOI 10.1023/A:1021220208562; Silberstein M, 2003, J MOL BIOL, V332, P1095, DOI 10.1016/j.jmb.2003.08.019; Sobolev V, 1999, BIOINFORMATICS, V15, P327, DOI 10.1093/bioinformatics/15.4.327; Vapnik VN, 1998, STAT LEARNING THEORY; Wei Y, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-119; WEI Y, 2007, THESIS NE U BOSTON; Wilson CA, 2000, J MOL BIOL, V297, P233, DOI 10.1006/jmbi.2000.3550; Youn E, 2007, PROTEIN SCI, V16, P216, DOI 10.1110/ps.062523907	39	15	16	COLD SPRING HARBOR LAB PRESS, PUBLICATIONS DEPT	WOODBURY	500 SUNNYSIDE BLVD, WOODBURY, NY 11797-2924 USA	0961-8368		PROTEIN SCI	Protein Sci.	FEB	2008	17	2					333	341		10.1110/ps.073213608		9	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	256IB	WOS:000252720700015	
J	London, N; Schueler-Furman, O				London, Nir; Schueler-Furman, Ora			Funnel hunting in a rough terrain: Learning and discriminating native energy funnels	STRUCTURE			English	Article							PROTEIN-PROTEIN DOCKING; BINDING-SITES; ASSOCIATION RATES; CAPRI EXPERIMENT; INTERFACES; FLEXIBILITY; PREDICTIONS; LANDSCAPE; CONFORMATIONS; OPTIMIZATION	Protein folding and binding is commonly depicted as a search for the minimum energy conformation. Modeling of protein complex structures by RosettaDock often results in a set of low-energy conformations near the native structure. Ensembles of low-energy conformations can appear, however, in other regions, especially when backbone movements occur upon binding. What then characterizes the energy landscape near the correct orientation? We applied a machine learning algorithm to distinguish ensembles of low-energy conformations around the native conformation from other low-energy ensembles. The resulting classifier, FunHunt, identifies the native orientation in 50/52 protein complexes in a test set. The features used by FunHunt teach us about the nature of native interfaces. Remarkably, the energy decrease of trajectories toward near-native orientations is significantly larger than for other orientations. This provides a possible explanation for the stability of association in the native orientation.	[London, Nir; Schueler-Furman, Ora] Hebrew Univ Jerusalem, Hadassah Med Sch, Dept Mol Genet & Biotechnol, IL-91120 Jerusalem, Israel	Schueler-Furman, O (reprint author), Hebrew Univ Jerusalem, Hadassah Med Sch, Dept Mol Genet & Biotechnol, POB 12272, IL-91120 Jerusalem, Israel.	oraf@ekmd.huji.ac.il					Bahadur RP, 2004, J MOL BIOL, V336, P943, DOI 10.1016/j.jmb.2003.12.073; Bastard K, 2006, PROTEINS, V62, P956, DOI 10.1002/prot.20770; Ben-Shimon A, 2005, J MOL BIOL, V351, P309, DOI 10.1016/j.jmb.2005.06.047; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Bernauer J, 2007, BIOINFORMATICS, V23, P555, DOI 10.1093/bioinformatics/btl654; Bonvin AM, 2006, CURR OPIN STRUC BIOL, V16, P194, DOI 10.1016/j.sbi.2006.02.002; Bordner AJ, 2005, PROTEINS, V60, P353, DOI 10.1002/prot.20433; Caffrey DR, 2004, PROTEIN SCI, V13, P190, DOI 10.1110/ps.03323604; Camacho CJ, 1999, BIOPHYS J, V76, P1166; Chelliah V, 2006, J MOL BIOL, V357, P1669, DOI 10.1016/j.jmb.2006.01.001; Chen R, 2003, PROTEINS, V52, P88, DOI 10.1002/prot.10390; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Dill KA, 1997, NAT STRUCT BIOL, V4, P10, DOI 10.1038/nsb0197-10; Dima RI, 2002, PROTEIN SCI, V11, P1036, DOI 10.1110/ps.4220102; Dominguez C, 2003, J AM CHEM SOC, V125, P1731, DOI 10.1021/ja026939x; Fernandez-Recio J, 2003, PROTEINS, V52, P113, DOI 10.1002/prot.10383; Gamble TR, 1996, CELL, V87, P1285, DOI 10.1016/S0092-8674(00)81823-1; Glaser F, 2005, PROTEINS, V58, P610, DOI 10.1002/prot.20305; Gray JJ, 2006, CURR OPIN STRUC BIOL, V16, P183, DOI 10.1016/j.sbi.2006.03.003; Gray JJ, 2003, J MOL BIOL, V331, P281, DOI 10.1016/S0022-2836(03)00670-3; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Halperin I, 2002, PROTEINS, V47, P409, DOI 10.1002/prot.10115; Janin J, 2005, PROTEIN SCI, V14, P278, DOI 10.1110/ps.041081905; Joachims T., 1999, ADV KERNEL METHODS S; Kohavi R., 1995, P 14 INT JOINT C ART; KOSAKOV D, 2007, IN PRESS PROTEINS; Levy Y, 2005, J MOL BIOL, V346, P1121, DOI 10.1016/j.jmb.2004.12.021; LI ZQ, 1987, P NATL ACAD SCI USA, V84, P6611, DOI 10.1073/pnas.84.19.6611; Lo Conte L, 1999, J MOL BIOL, V285, P2177; London N, 2007, PROTEINS, V69, P809, DOI 10.1002/prot.21736; MCDONALD IK, 1994, J MOL BIOL, V238, P777, DOI 10.1006/jmbi.1994.1334; Neuvirth H, 2007, NUCLEIC ACIDS RES, V35, pW543, DOI 10.1093/nar/gkm301; Neuvirth H, 2004, J MOL BIOL, V338, P181, DOI 10.1016/j.jmb.2004.02.040; Nicola G, 2007, BIOINFORMATICS, V23, P789, DOI 10.1093/bioinformatics/btm018; Nooren IMA, 2003, J MOL BIOL, V325, P991, DOI 10.1016/S0022-2836(02)01281-0; Onuchic JN, 1997, ANNU REV PHYS CHEM, V48, P545, DOI 10.1146/annurev.physchem.48.1.545; Pettersen EF, 2004, J COMPUT CHEM, V25, P1605, DOI 10.1002/jcc.20084; Pierce B, 2007, PROTEINS, V67, P1078, DOI 10.1002/prot.21373; Reichmann D, 2007, CURR OPIN STRUC BIOL, V17, P67, DOI 10.1016/j.sbi.2007.01.004; Rodier F, 2005, PROTEINS, V60, P36, DOI 10.1002/prot.20478; Rohl CA, 2004, METHOD ENZYMOL, V383, P66; Schlosshauer M, 2002, J PHYS CHEM B, V106, P12079, DOI 10.1021/jp025894j; Schlosshauer M, 2004, PROTEIN SCI, V13, P1660, DOI 10.1110/ps.03517304; Schueler-Furman O, 2005, SCIENCE, V310, P638, DOI 10.1126/science.1112160; Schueler-Furman O, 2005, PROTEINS, V60, P187, DOI 10.1002/prot.20556; Shortle D, 1998, P NATL ACAD SCI USA, V95, P11158, DOI 10.1073/pnas.95.19.11158; Slutsky M, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.061903; Smith GR, 2005, J MOL BIOL, V347, P1077, DOI 10.1016/j.jmb.2005.01.058; SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615; Tsai CJ, 1999, PROTEIN SCI, V8, P1181; Wang C, 2007, PROTEINS, V69, P758, DOI 10.1002/prot.21684; Wang C, 2007, J MOL BIOL, V373, P503, DOI 10.1016/j.jmb.2007.07.050; Wang C, 2005, PROTEIN SCI, V14, P1328, DOI 10.1110/ps.041222905	53	11	11	CELL PRESS	CAMBRIDGE	600 TECHNOLOGY SQUARE, 5TH FLOOR, CAMBRIDGE, MA 02139 USA	0969-2126		STRUCTURE	Structure	FEB	2008	16	2					269	279		10.1016/j.str.2007.11.013		11	Biochemistry & Molecular Biology; Biophysics; Cell Biology	Biochemistry & Molecular Biology; Biophysics; Cell Biology	263LU	WOS:000253219400012	
J	D'Mello, SK; Craig, SD; Witherspoon, A; McDaniel, B; Graesser, A				D'Mello, Sidney K.; Craig, Scotty D.; Witherspoon, Amy; McDaniel, Bethany; Graesser, Arthur			Automatic detection of learner's affect from conversational cues	USER MODELING AND USER-ADAPTED INTERACTION			English	Article						affect detection; human-computer interaction; human-computer dialogue; dialogue features; discourse markers; conversational cues; intelligent tutoring systems; AutoTutor	COMPUTER; EMOTIONS; DIALOGUE; COMMUNICATION; ATTENTION; AUTONOMY; LANGUAGE; SYSTEM; USER	We explored the reliability of detecting a learner's affect from conversational features extracted from interactions with AutoTutor, an intelligent tutoring system (ITS) that helps students learn by holding a conversation in natural language. Training data were collected in a learning session with AutoTutor, after which the affective states of the learner were rated by the learner, a peer, and two trained judges. Inter-rater reliability scores indicated that the classifications of the trained judges were more reliable than the novice judges. Seven data sets that temporally integrated the affective judgments with the dialogue features of each learner were constructed. The first four datasets corresponded to the judgments of the learner, a peer, and two trained judges, while the remaining three data sets combined judgments of two or more raters. Multiple regression analyses confirmed the hypothesis that dialogue features could significantly predict the affective states of boredom, confusion, flow, and frustration. Machine learning experiments indicated that standard classifiers were moderately successful in discriminating the affective states of boredom, confusion, flow, frustration, and neutral, yielding a peak accuracy of 42% with neutral (chance = 20%) and 54% without neutral (chance = 25%). Individual detections of boredom, confusion, flow, and frustration, when contrasted with neutral affect, had maximum accuracies of 69, 68, 71, and 78%, respectively (chance = 50%). The classifiers that operated on the emotion judgments of the trained judges and combined models outperformed those based on judgments of the novices (i.e., the self and peer). Follow-up classification analyses that assessed the degree to which machine-generated affect labels correlated with affect judgments provided by humans revealed that human-machine agreement was on par with novice judges (self and peer) but quantitatively lower than trained judges. We discuss the prospects of extending AutoTutor into an affect-sensing ITS.	[D'Mello, Sidney K.] Memphis State Univ, Dept Comp Sci, Memphis, TN 38152 USA; [Craig, Scotty D.] Univ Pittsburgh, Ctr Learning Res & Dev, Pittsburgh, PA 15260 USA; [Witherspoon, Amy; McDaniel, Bethany; Graesser, Arthur] Memphis State Univ, Dept Psychol, Memphis, TN 38152 USA	D'Mello, SK (reprint author), Memphis State Univ, Dept Comp Sci, Memphis, TN 38152 USA.	sdmello@memphis.edu; scraig@pitt.edu; awthrpsn@memphis.edu; btmcdanl@memphis.edu; a-graesser@memphis.edu					Aist G, 2002, LECT NOTES COMPUT SC, V2363, P992; Aleven VAWMM, 2002, COGNITIVE SCI, V26, P147, DOI 10.1016/S0364-0213(02)00061-7; ALM CO, 2005, ITNERSPEECH, P533; Anderson JR, 1995, J LEARN SCI, V4, P167, DOI 10.1207/s15327809jls0402_2; Ang J., 2002, P INT C SPOK LANG PR, P2037; Azevedo R, 2004, J EDUC PSYCHOL, V96, P523, DOI 10.1037/0022-0663.96.3.523; BATLINER A, 2008, J PERS RES, V18, DOI DOI 10.1007/S11257-007-9039-4; Batliner A, 2003, SPEECH COMMUN, V40, P117, DOI 10.1016/S0167-6393(02)00079-1; BIANCHIBERTHOUZ.N, 2002, INT J USER MODELING, V12, P49; Boersma P, PRAAT DOING PHONETIC; Bosch L. T., 2003, SPEECH COMMUN, V40, P213; BOWER GH, 1981, AM PSYCHOL, V36, P129, DOI 10.1037//0003-066X.36.2.129; BRUNER JS, 1961, HARVARD EDUC REV, V31, P21; Bull E.P., 1987, POSTURE GESTURE; CAMPBELL DT, 1959, PSYCHOL BULL, V56, P81, DOI 10.1037/h0046016; Carberry S, 2002, APPL ARTIF INTELL, V16, P495, DOI 10.1080/08839510290030372; COHN JF, IN PRESS HDB EMOTION; Conati C, 2002, APPL ARTIF INTELL, V16, P555, DOI 10.1080/08839510290030390; Craig S., 2004, J ED MEDIA, V29, P241, DOI DOI 10.1080/1358165042000283101; CRAIG SD, 2004, P INT C ELEARNING, P284; CSIKSZENTMIHALY.M, 1990, FLOW PSYCHOL OPTIMAL; Dai D. Y., 2004, MOTIVATION EMOTION C, P57; D'Mello S. K., 2005, AFFECTIVE INTERACTIO, P7; De Vicente A, 2002, LECT NOTES COMPUT SC, V2363, P933; DMELLO KS, 2006, INT J ARTIF INTELL E, V16, P3; Ekman P., 1978, FACIAL ACTION CODING; Ericsson K. A., 1993, PROTOCOL ANAL VERBAL; Forbes-Riley K., 2004, P HUM LANG TECHN C N, P201; FORBESRILEY K, 2008, J PERS RES, V18, DOI DOI 10.1007/S11257-007-9038-5; Fredrickson BL, 2005, COGNITION EMOTION, V19, P313, DOI 10.1080/02699930441000238; Gertner AS, 2000, LECT NOTES COMPUT SC, V1839, P133; Goleman D., 1995, EMOTIONAL INTELLIGEN; Gorin AL, 1997, SPEECH COMMUN, V23, P113, DOI 10.1016/S0167-6393(97)00040-X; Graesser A, 2006, P 28 ANN C COGN SCI, P285; Graesser A. C., 2007, HDB LATENT SEMANTIC, P243; Graesser AC, 2005, NEBR SYMP INF TECH E, P143; Graesser A. C., 2001, INT J ARTIFICIAL INT, V12, P257; Graesser A. C., 2000, Interactive Learning Environments, V8, DOI 10.1076/1049-4820(200008)8:2;1-B;FT129; Graesser AC, 2003, J EDUC PSYCHOL, V95, P524, DOI 10.1037/0022-0663.95.3.524; Graesser AC, 2005, IEEE T EDUC, V48, P612, DOI 10.1109/TE.2005.856149; Graesser AC, 2001, AI MAG, V22, P39; Graesser AC, 2004, BEHAV RES METH INS C, V36, P193, DOI 10.3758/BF03195564; Grimm M., 2006, 14 EUR SIGN PROC C E; Hoque ME, 2006, LECT NOTES ARTIF INT, V4133, P42; HUDLICKA E, 2002, INT J USER MODELING, V12, P1; Issroff K., 1996, P EUR C ART INT ED, P284; KIM Y, 2005, WORKSH MOT AFF ED SO; Koedinger K. R., 1997, INT J ARTIFICIAL INT, V8, P30; Kort B., 2001, Proceedings IEEE International Conference on Advanced Learning Technologies, DOI 10.1109/ICALT.2001.943850; Kozma R, 2001, INT J BIFURCAT CHAOS, V11, P1607, DOI 10.1142/S0218127401002870; Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037//0033-295X.104.2.211; Lee CM, 2005, IEEE T SPEECH AUDI P, V13, P293, DOI 10.1109/TSA.2004.838534; Lepper M. R., 2002, IMPROVING ACAD ACHIE, P135, DOI [10.1016/B978-012064455-1/50010-5, DOI 10.1016/B978-012064455-1/50010-5]; Lepper M. R., 1988, LEARNING ISSUES INTE, P242; Lesgold A., 1992, COMPUTER ASSISTED IN, P201; Linnenbrink E. A., 2002, RECONSIDERING CONCEP, P115, DOI 10.1007/0-306-47637-1_6; LISCOMBE J, 2005, EUROSPEECH 05 9 EUR, P1845; LITMAN D, 2004, P INT C INT TUT SYST, P368; Litman D. J., 2004, P 42 ANN M ASS COMP, P352; LITMAN DJ, 2004, P HUM LANG TECHN C 3, P52; Mandler G., 1984, MIND BODY PSYCHOL EM; MATSUBARA Y, 1996, P 3 INT C INT TUT SY, P139; MCQUIGGAN S, 2008, J PERS RES, V18, DOI DOI 10.1007/S11257-007-9040-Y; Miserandino M, 1996, J EDUC PSYCHOL, V88, P203, DOI 10.1037/0022-0663.88.2.203; MORIMTO C, 1998, PUPIL DETECTION TRAC; Mota S., 2003, WORKSH COMP VIS PATT; Oliver N, 1997, PROC CVPR IEEE, P123, DOI 10.1109/CVPR.1997.609309; OLNEY A, 2003, P HLT NAACL 03 WORKS, P1; Ortony A., 1988, COGNITIVE STRUCTURE; Pantic M, 2003, P IEEE, V91, P1370, DOI 10.1109/JPROC.2003.817122; PATRICK BC, 1993, J PERS SOC PSYCHOL, V65, P781, DOI 10.1037/0022-3514.65.4.781; Person N, 2002, LECT NOTES COMPUT SC, V2363, P821; Klein J, 2002, INTERACT COMPUT, V14, P119; Picard R. W., 1997, AFFECTIVE COMPUTING; Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607; PORAYSKAPOMSTA K, 2008, J PERS RES, V18, DOI DOI 10.1007/S11257-007-9041-X; PRENDINGER H, 2005, INT J APPL ARTIFICIA, V19, P267; RANI P, 2003, P 2003 IEEE INT C RO, P2382; Robson C., 1993, REAL WORLD RES RESOU; RUS V, 2006, P AM ASS ART INT, P1495; Russell JA, 2003, PSYCHOL REV, V110, P145, DOI 10.1037/0033-295X.110.1.145; Scheirer J, 2002, INTERACT COMPUT, V14, P93, DOI 10.1016/S0953-5438(01)00059-5; Schutzwohl A, 2005, COGNITION EMOTION, V19, P583, DOI 10.1080/02699930441000337; SELFRIDGE OG, 1959, S MECH THOUGHT PROC, P511; SHAFRAN I, 2005, P INT C AC SPEECH SI, P341; SHAFRAN I, 2003, P IEEE AUT SPEECH RE, P31; Silvia PJ, 2002, COGNITION EMOTION, V16, P845, DOI 10.1080/02699930143000671; SLEEMAN D. H., 1982, INTELLIGENT TUTORING; Stein N. L., 1991, MEMORIES THOUGHTS EM, P295; Tekscan, 1997, TEKSC BOD PRESS MEAS; VANLEHN K, 1990, MIND BUGS ORIGINS PR; VANLEHN K, 2006, COGNITIVE SCI, V30, P1; VanLehn K., 2002, P 6 INT C INT TUT SY, P158; Vavik L., 1993, AUTOMATING INSTRUCTI, P403; Walker MA, 2002, J ARTIF INTELL RES, V16, P293; Whang MC, 2003, HUM FACTORS, V45, P623, DOI 10.1518/hfes.45.4.623.27095; Wiemer-Hastings P, 1999, FRONT ARTIF INTEL AP, V50, P535; Witten I. H., 2005, DATA MINING PRACTICA; YANNAKAKIS G, 2008, J PERS RES, V18, DOI DOI 10.1007/S11257-007-9036-7	99	43	43	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-1868		USER MODEL USER-ADAP	User Model. User-Adapt. Interact.	FEB	2008	18	1-2					45	80		10.1007/s11257-007-9037-6		36	Computer Science, Cybernetics	Computer Science	255SP	WOS:000252678000003	
J	Porayska-Pomsta, K; Mavrikis, M; Pain, H				Porayska-Pomsta, Kaska; Mavrikis, Manolis; Pain, Helen			Diagnosing and acting on student affect: the tutor's perspective	USER MODELING AND USER-ADAPTED INTERACTION			English	Article						situation modelling; affect; machine learning; tutor feedback; empirically based hypotheses generation; computer based tutoring; computer mediated communication	POLITENESS	In this paper we explore human tutors' inferences in relation to learners' affective states and the relationship between those inferences and the actions that tutors take as their consequence. At the core of the investigations presented in this paper lie fundamental questions associated with the role of affective considerations in computer-mediated educational interactions. Theory of linguistic politeness is used as the basis for determining the contextual factors relevant to human tutors's actions, with special attention being dedicated to learner affective states. A study was designed to determine what affective states of the learners are relevant to tutoring mathematics and to identify the mechanisms used by tutors to predict such states. Logs of tutor-student dialogues were recorded along with contextual factors taken into consideration by tutors in relation to their specific tutorial dialogue moves. The logs were annotated in order to determine the types and range of student and tutor actions. Machine learning techniques were then applied to those actions to predict the values of three factors: student confidence, interest and effort. Whilst due to limited size and sparsity of data the results are not conclusive, they are very valuable as the basis for empirically derived hypotheses to be tested in further studies. The potential implications of the hypotheses, if they were confirmed by further studies, are discussed in relation to the impact of tutor's ability to diagnose student affect on the nature of computer-mediated tutorial interactions.	[Porayska-Pomsta, Kaska] Univ London, London Knowledge Lab, London WC1N 3QS, England; [Mavrikis, Manolis; Pain, Helen] Univ Edinburgh, Elect Commun & Collaborat Syst, Edinburgh EH8 9LW, Midlothian, Scotland	Porayska-Pomsta, K (reprint author), Univ London, London Knowledge Lab, 23-29 Emerald St, London WC1N 3QS, England.	K.Porayska-Pomsta@ioe.ac.uk; m.mavrikis@inf.ed.ac.uk; helen@inf.ed.ac.uk					Allanson J, 2004, INTERACT COMPUT, V16, P857, DOI 10.1016/j.intcom.2004.08.001; ARROYO I, 2005, ARTIF INTELL, P88; BAKER R, 1996, P ACM CHI 2004 C HUM, V24, P123; Baker R.S., 2004, P 7 INT C INT TUT SY, P531; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; BURLESON W, 2004, P WORKSH SOC EM INT; Burleson W., 2006, THESIS MIT; CHAE HM, 2005, P 16 MIDW AI COGN SC, P25; Chi MTH, 2001, COGNITIVE SCI, V25, P471, DOI 10.1207/s15516709cog2504_1; Chi MTH, 2004, COGNITION INSTRUCT, V22, P363, DOI 10.1207/s1532690xci2203_4; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Cohen J., 2003, APPL MULTIPLE REGRES; Conati C, 2002, APPL ARTIF INTELL, V16, P555, DOI 10.1080/08839510290030390; CONATI C, 2004, P 7 INT C ITS 2004 M, P55; Conlon T, 1996, INT J ARTIFICIAL INT, V7, P219; Corbett A. T., 2000, P ACM CHI 2000 C HUM, P97, DOI 10.1145/332040.332412; Cromley JG, 2005, DISCOURSE PROCESS, V40, P83, DOI 10.1207/s15326950dp4002_1; CSIKSZENTMIHALY.M, 1990, FLOW PSYCHOL OPTIMAL; D'Mello S. K., 2006, INT J ARTIFICIAL INT, V16, P3; D'Mello S. K., 2005, AFFECTIVE INTERACTIO, P7; Del Soldato T., 1995, Journal of Artificial Intelligence in Education, V6; DEVICENTE A, 1999, P 9 INT C ART INT ED, P651; DEVICENTE A, 2002, LECT NOTES COMPUTER, V2363, P955; Devillers L, 2005, NEURAL NETWORKS, V18, P407, DOI 10.1016/j.neunet.2005.03.007; Di Eugenio B, 2005, FR ART INT, V125, P798; Dillon J. T., 1990, PRACTICE QUESTIONING; Du Boulay B., 2001, INT J ARTIFICIAL INT, V12, P235; Ericsson K.A., 1993, PROTOCAL ANAL VERBAL; FETZER A, 2003, LINGUISTIK, V14, P137; Fleiss JL, 1981, STAT METHODS RATES P; Fox B. A., 1993, HUMAN TUTORIAL DIALO; Glass M., 1999, Proceedings of the Tenth Midwest Artificial Intelligence and Cognitive Science Conference (MAICS-99); Goleman D., 1996, EMOTIONAL INTELLIGEN; Graesser A. C., 1995, APPL COGNITIVE PSYCH, V9, P1; GRAESSER AC, 1993, PROCEEDINGS OF THE FIFTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P126; GRAESSER AC, 1992, QUESTIONS AND INFORMATION SYSTEMS, P167; GRAESSER AC, 1994, AM EDUC RES J, V31, P104, DOI 10.3102/00028312031001104; Haro A, 2000, PROC CVPR IEEE, P163, DOI 10.1109/CVPR.2000.855815; HIGGINS MC, 2001, J APPL BEHAV SCI, V37, P280, DOI 10.1177/0021886301373002; Johnson WL, 2004, LECT NOTES COMPUT SC, V3220, P67; Kapoor A, 2004, INT C PATT RECOG, P969, DOI 10.1109/ICPR.2004.1334690; Kapoor A., 2005, P 13 ANN ACM INT C M, P677, DOI DOI 10.1145/1101149.1101300; Katz S., 2003, INT J ARTIFICIAL INT, V13, P79; Keller J. M., 1983, INSTRUCTIONAL DESIGN, P383; Kort B, 2001, IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P43; LEECH GN, 1980, EXPLORATIONS SEMANTI, P79; Lepper M. R., 1993, COMPUTERS COGNITIVE, P75; Lepper M. R., 1997, SCAFFOLDING STUDENT, P108; Lepper M. R., 1988, LEARNING ISSUES INTE, P242; Levinson S., 1987, STUDIES INTERACTIONA, V4; LU X, 2006, 3 MIDW COMP LING C M; Malone T. W., 1987, APTITUDE LEARNING IN, V3, P223; MAVRIKIS M, 2003, SUPPL P 11 INT C ART, V8, P505; MCARTHUR D, 1990, COGNITION INSTRUCT, V7, P197, DOI 10.1207/s1532690xci0703_2; MESSOM C, 2005, NEURAL NETWORKS APPL; MOTA S, 2003, 2003 C COMP VIS PATT, V5, P49; Murphy PK, 2000, CONTEMP EDUC PSYCHOL, V25, P3, DOI 10.1006/ceps.1999.1019; PERSON NK, 1995, COGNITION INSTRUCT, V13, P161; PICARD R, 2005, C HUM FACT COMP SYST; Picard R. W., 1997, AFFECTIVE COMPUTING; PORAYSKAPOMSTA K, 2004, P NAT LANG GEN 3 INT, P141; PORAYSKAPOMSTA K, 2004, P 7 INT C INT TUT SY, P77; PORAYSKAPOMSTA K, 2003, THESIS U EDINBURGH; Quinlan J. R., 1993, C45 PROGRAMS MACHINE; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; Rebolledo-Mendezl G, 2006, LECT NOTES COMPUT SC, V4053, P545; Sadock Jerrold M., 1971, 7 REG M CHIC LING SO, P223; Schank R, 2001, SMART MACHINES IN EDUCATION, P37; Shah F, 2002, DISCOURSE PROCESS, V33, P23, DOI 10.1207/S15326950DP3301_02; Sinclair John M., 1982, TEACHER TALK; STEVENS R, 2004, P 7 INT C INT TUT SY, P580; STEVENSON JC, 1991, MONOGRAPH SERIES AUS, V2, P144; Stone A. A., 2000, SCI SELF REPORT IMPL; Wagner J., 2005, P IEEE INT C MULT EX, P940; Witten I. H., 2005, DATA MINING PRACTICA; Yates S. J., 2001, DISCOURSE DATA GUIDE; *LEAM, 2003, LEACTIVEMATH CONS LA	77	16	16	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-1868		USER MODEL USER-ADAP	User Model. User-Adapt. Interact.	FEB	2008	18	1-2					125	173		10.1007/s11257-007-9041-x		49	Computer Science, Cybernetics	Computer Science	255SP	WOS:000252678000005	
J	Farkas, R				Farkas, Richard			The strength of co-authorship in gene name disambiguation	BMC BIOINFORMATICS			English	Article								Background: A biomedical entity mention in articles and other free texts is often ambiguous. For example, 13% of the gene names ( aliases) might refer to more than one gene. The task of Gene Symbol Disambiguation (GSD) - a special case of Word Sense Disambiguation (WSD) - is to assign a unique gene identifier for all identified gene name aliases in biology-related articles. Supervised and unsupervised machine learning WSD techniques have been applied in the biomedical field with promising results. We examine here the utilisation potential of the fact - one of the special features of biological articles - that the authors of the documents are known through graph-based semi-supervised methods for the GSD task. Results: Our key hypothesis is that a biologist refers to each particular gene by a fixed gene alias and this holds for the co-authors as well. To make use of the co-authorship information we decided to build the inverse co-author graph on MedLine abstracts. The nodes of the inverse co-author graph are articles and there is an edge between two nodes if and only if the two articles have a mutual author. We introduce here two methods using distances ( based on the graph) of abstracts for the GSD task. We found that a disambiguation decision can be made in 85% of cases with an extremely high (99.5%) precision rate just by using information obtained from the inverse coauthor graph. We incorporated the co-authorship information into two GSD systems in order to attain full coverage and in experiments our procedure achieved precision of 94.3%, 98.85%, 96.05% and 99.63% on the human, mouse, fly and yeast GSD evaluation sets, respectively. Conclusion: Based on the promising results obtained so far we suggest that the co-authorship information and the circumstances of the articles' release ( like the title of the journal, the year of publication) can be a crucial building block of any sophisticated similarity measure among biological articles and hence the methods introduced here should be useful for other biomedical natural language processing tasks ( like organism or target disease detection) as well.	Hungarian Acad Sci, Res Grp Artificial Intelligence, Szeged, Hungary	Farkas, R (reprint author), Hungarian Acad Sci, Res Grp Artificial Intelligence, Szeged, Hungary.	rfarkas@inf.u-szeged.hu					Agirre E, 2006, TEXT SPEECH LANG TEC, V33, P1, DOI 10.1007/978-1-4020-4809-8; Barabasi AL, 2002, PHYSICA A, V311, P590, DOI 10.1016/S0378-4371(02)00736-7; CHEN L, 2005, BIOINFORMATICS, V21; HAKENBERG J, 2007, BIOL TRANSLATIONAL C, P153; HANISCH D, 2005, BMC BIOINFORMATIC S1, V6; Hirschman L, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S1-S11; LIU H, 2001, J BIOMEDICAL INFORM, V34; MAGLOTT DR, 2007, NUCLEIC ACIDS RES, P26; MORGAN A, 2007, PAC S BIOCOMPUT; PODOWSKI RM, 2004, COMPUTATION SYSTEMS, P415; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; SAVOVA G, 2005, 200580 UMSI; Schijvenaars B., 2005, BMC BIOINFORMATICS, V6; Weeber M, 2001, Proc AMIA Symp, P746; Witten I. H., 1999, DATA MINING PRACTICA; Xu H, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-334; XU H, 2007, BIOL TRANSLATIONAL C, P41; Xu H, 2007, BIOINFORMATICS, V23, P1015, DOI 10.1093/bioinformatics/btm056; YEH AS, 2003, CORR	19	4	5	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	JAN 29	2008	9								69	10.1186/1471-2105-9-69		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	269YR	WOS:000253687200001	
J	Yousef, M; Jung, S; Showe, LC; Showe, MK				Yousef, Malik; Jung, Segun; Showe, Louise C.; Showe, Michael K.			Learning from positive examples when the negative class is undetermined-microRNA gene identification	ALGORITHMS FOR MOLECULAR BIOLOGY			English	Article							PREDICTION; PRECURSORS; SEQUENCE; GENOMICS; ELEGANS; SUPPORT	Background: The application of machine learning to classification problems that depend only on positive examples is gaining attention in the computational biology community. We and others have described the use of two- class machine learning to identify novel miRNAs. These methods require the generation of an artificial negative class. However, designation of the negative class can be problematic and if it is not properly done can affect the performance of the classifier dramatically and/ or yield a biased estimate of performance. We present a study using one- class machine learning for microRNA ( miRNA) discovery and compare one- class to two- class approaches using naive Bayes and Support Vector Machines. These results are compared to published two- class miRNA prediction approaches. We also examine the ability of the one- class and two- class techniques to identify miRNAs in newly sequenced species. Results: Of all methods tested, we found that 2- class naive Bayes and Support Vector Machines gave the best accuracy using our selected features and optimally chosen negative examples. One class methods showed average accuracies of 70 - 80% versus 90% for the two 2- class methods on the same feature sets. However, some one- class methods outperform some recently published two- class approaches with different selected features. Using the EBV genome as and external validation of the method we found one- class machine learning to work as well as or better than a two- class approach in identifying true miRNAs as well as predicting new miRNAs. Conclusion: One and two class methods can both give useful classification accuracies when the negative class is well characterized. The advantage of one class methods is that it eliminates guessing at the optimal features for the negative class when they are not well defined. In these cases one-class methods can be superior to two- class methods when the features which are chosen as representative of that positive class are well defined. Availability: The OneClassmiRNA program is available at: [1].	[Yousef, Malik; Jung, Segun; Showe, Louise C.; Showe, Michael K.] Wistar Inst Anat & Biol, Syst Biol Div, Philadelphia, PA 19104 USA; [Jung, Segun] Drexel Univ, Sch Biomed Engn, Sci & Hlth Syst, Philadelphia, PA 19104 USA; [Yousef, Malik] Coll Sakhnin, Sakhnin, Israel; [Jung, Segun] NYU, Sch Med, Sackler Inst Grad Biomed Sci, New York, NY 10016 USA	Showe, MK (reprint author), Wistar Inst Anat & Biol, Syst Biol Div, Philadelphia, PA 19104 USA.	yousef@gal-soc.org; sj801@med.nyu.edu; lshowe@wistar.org; showe@wistar.org	Jung, Segun/C-9857-2009				Bartel DP, 2004, CELL, V116, P281, DOI 10.1016/S0092-8674(04)00045-5; BEREZIKOV E, 2006, NAT GENET; Cai XZ, 2006, PLOS PATHOG, V2, P236, DOI 10.1371/journal.ppat.0020023; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; CRAMMER K, 2004, P 21 INT C MACH LEAR; Grad Y, 2003, MOL CELL, V11, P1253, DOI 10.1016/S1097-2765(03)00153-9; Griffiths-Jones S, 2004, NUCLEIC ACIDS RES, V32, pD109, DOI 10.1093/nar/gkh023; Grundhoff A, 2006, RNA, V12, P733, DOI 10.1261/2326106; Gupta G., 2005, P 22 INT C MACH LEAR, P273, DOI 10.1145/1102351.1102386; Hertel J, 2006, BIOINFORMATICS, V22, pE197, DOI 10.1093/bioinformatics/btl257; Kim SK, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-411; Koppel M., 2004, P 21 INT C MACH LEAR, P62; KOWALCZYK A, 2002, SIGKDD EXPLORATIONS, V4, P99; Lai EC, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-7-r42; Lim LP, 2003, GENE DEV, V17, P991, DOI 10.1101/gad.1074403; Lim LP, 2003, SCIENCE, V299, P1540, DOI 10.1126/science.1080372; Manevitz L., 2001, J MACHINE LEARNING R, V2, P139; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; Nam JW, 2005, NUCLEIC ACIDS RES, V33, P3570, DOI 10.1093/nar/gki668; Pfeffer S, 2005, NAT METHODS, V2, P269, DOI 10.1038/NMETH746; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Scholkopf B., 1999, ADV KERNEL METHODS; Sewer A, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-267; Spinosa Eduardo J, 2005, Genet Mol Res, V4, P608; SUNGKYU K, 2005, IEEE S COMP INT BIOI, P46; TAX DMJ, 2001, ONE CLASS CLASSIFICA; TAX DMJ, 2005, DDTOOLS DAT DESCRIPT; Thirion B, 2004, MED IMAGE ANAL, V8, P403, DOI 10.1016/j.media.2004.09.001; Vapnik V. N, 1995, NATURE STAT LEARNING; WANG C, 2006, BIOINFORMATICS; Weber MJ, 2005, FEBS J, V272, P59, DOI 10.1111/j.1432-1033.2004.04389.x; Xue CH, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-310; Yousef M, 2006, BIOINFORMATICS, V22, P1325, DOI 10.1093/bioinformatics/bt/094; Zuker M, 2003, NUCLEIC ACIDS RES, V31, P3406, DOI 10.1093/nar/gkg595	34	8	9	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1748-7188		ALGORITHM MOL BIOL	Algorithms. Mol. Biol.	JAN 28	2008	3								2	10.1186/1748-7188-3-2		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	263GR	WOS:000253206100001	
J	Zhao, XM; Wang, Y; Chen, LN; Aihara, K				Zhao, Xing-Ming; Wang, Yong; Chen, Luonan; Aihara, Kazuyuki			Gene function prediction using labeled and unlabeled data	BMC BIOINFORMATICS			English	Article							YEAST SACCHAROMYCES-CEREVISIAE; PROTEIN-INTERACTION NETWORKS; EXPRESSION; CLASSIFICATION; ANNOTATION; IDENTIFICATION; COMPLEXES; SEQUENCES; IDENTIFY; GENOMES	Background: In general, gene function prediction can be formalized as a classification problem based on machine learning technique. Usually, both labeled positive and negative samples are needed to train the classifier. For the problem of gene function prediction, however, the available information is only about positive samples. In other words, we know which genes have the function of interested, while it is generally unclear which genes do not have the function, i.e. the negative samples. If all the genes outside of the target functional family are seen as negative samples, the imbalanced problem will arise because there are only a relatively small number of genes annotated in each family. Furthermore, the classifier may be degraded by the false negatives in the heuristically generated negative samples. Results: In this paper, we present a new technique, namely Annotating Genes with Positive Samples ( AGPS), for defining negative samples in gene function prediction. With the defined negative samples, it is straightforward to predict the functions of unknown genes. In addition, the AGPS algorithm is able to integrate various kinds of data sources to predict gene functions in a reliable and accurate manner. With the one-class and two-class Support Vector Machines as the core learning algorithm, the AGPS algorithm shows good performances for function prediction on yeast genes. Conclusion: We proposed a new method for defining negative samples in gene function prediction. Experimental results on yeast genes show that AGPS yields good performances on both training and test sets. In addition, the overlapping between prediction results and GO annotations on unknown genes also demonstrates the effectiveness of the proposed method.	[Zhao, Xing-Ming; Chen, Luonan; Aihara, Kazuyuki] ERATO Aihara Complex Modelling Project, Tokyo, Japan; [Zhao, Xing-Ming] Chinese Acad Sci, Hefei Inst Intelligent Machines, Intelligent Comp Lab, Hefei 230031, Anhui, Peoples R China; [Zhao, Xing-Ming; Chen, Luonan; Aihara, Kazuyuki] Univ Tokyo, Inst Ind Sci, Tokyo, Japan; [Wang, Yong; Chen, Luonan] Osaka Sangyo Univ, Dept Elect Engn & Elect, Osaka, Japan; [Chen, Luonan] Shanghai Univ, Inst Syst Biol, Shanghai, Peoples R China	Chen, LN (reprint author), ERATO Aihara Complex Modelling Project, 4-6-1 Komaba, Tokyo, Japan.	xmzhao@aihara.jst.go.jp; ywang@amss.ac.cn; chen@eic.osaka-sandai.ac.jp; aihara@sat.t.u-tokyo.ac.jp					Barutcuoglu Z, 2006, BIOINFORMATICS, V22, P830, DOI 10.1093/bioinformatics/btk048; Ashburner M, 2000, NAT GENET, V25, P25; Brun Christine, 2003, Genome Biol, V5, pR6, DOI 10.1186/gb-2003-5-1-r6; Carter RJ, 2001, NUCLEIC ACIDS RES, V29, P3928; CHANG C. C., LIBSVM LIB SUPPORT V; Chang K. C., 2002, P ACM SIGKDD INT C K, P239; Chen Y, 2004, NUCLEIC ACIDS RES, V32, P6414, DOI 10.1093/nar/gkh978; CHIEN CT, 1991, P NATL ACAD SCI USA, V88, P9578, DOI 10.1073/pnas.88.21.9578; Chua HN, 2006, BIOINFORMATICS, V22, P1623, DOI 10.1093/bioinformatics/btl145; Deng MH, 2004, BIOINFORMATICS, V20, P895, DOI 10.1093/bioinformatics/btg500; DRINEAS P, 1956, MACH LEARN, V56, P9; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Gasch AP, 2001, MOL BIOL CELL, V12, P2987; Gasch AP, 2000, MOL BIOL CELL, V11, P4241; Gavin AC, 2002, NATURE, V415, P141, DOI 10.1038/415141a; HISHIGAKI H, 2001, YEAST, V18; Ho Y, 2002, NATURE, V415, P180, DOI 10.1038/415180a; LANCKRIET GR, 2004, PAC S BIOC DIV EL EN, P311; Li X, 2003, P 18 INT JOINT C ART, P587; LIU B, 2002, ICML 02, V2, P387; Mewes HW, 2002, NUCLEIC ACIDS RES, V30, P31, DOI 10.1093/nar/30.1.31; Ogawa N, 2000, MOL BIOL CELL, V11, P4309; Ruepp A, 2004, NUCLEIC ACIDS RES, V32, P5539, DOI 10.1093/nar/gkh894; Samanta MP, 2003, P NATL ACAD SCI USA, V100, P12579, DOI 10.1073/pnas.2132527100; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Schwikowski B, 2000, NAT BIOTECHNOL, V18, P1257, DOI 10.1038/82360; Sen TZ, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-355; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Stark C, 2006, NUCLEIC ACIDS RES, V34, pD535, DOI 10.1093/nar/gkj109; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; Vazquez A, 2003, NAT BIOTECHNOL, V21, P697, DOI 10.1038/nbt825; Wang CL, 2006, BIOINFORMATICS, V22, P2590, DOI 10.1093/bioinformatics/btl441; Yoshimoto H, 2002, J BIOL CHEM, V277, P31079, DOI 10.1074/jbc.M202718200; Yu HJ, 2005, MACH LEARN, V61, P49, DOI 10.1007/s10994-005-1122-7; ZHAO X, J BIOINFORMATICS RES; ZHAO X, PROTEINS; Zhao XM, 2008, PROTEINS, V70, P1125, DOI 10.1002/prot.21870; Zhou XH, 2002, P NATL ACAD SCI USA, V99, P12783, DOI 10.1073/pnas.192159399	38	23	23	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	JAN 28	2008	9								57	10.1186/1471-2105-9-57		14	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	280OK	WOS:000254435900002	
J	Yao, XQ; Zhu, HQ; She, ZS				Yao, Xin-Qiu; Zhu, Huaiqiu; She, Zhen-Su			A dynamic Bayesian network approach to protein secondary structure prediction	BMC BIOINFORMATICS			English	Article							SEQUENCE ALIGNMENT PROFILES; SUPPORT VECTOR MACHINES; RECOGNITION; INFORMATION; ACCURACY; DATABASE; MODELS	Background: Protein secondary structure prediction method based on probabilistic models such as hidden Markov model (HMM) appeals to many because it provides meaningful information relevant to sequence-structure relationship. However, at present, the prediction accuracy of pure HMM-type methods is much lower than that of machine learning-based methods such as neural networks (NN) or support vector machines (SVM). Results: In this paper, we report a new method of probabilistic nature for protein secondary structure prediction, based on dynamic Bayesian networks (DBN). The new method models the PSI-BLAST profile of a protein sequence using a multivariate Gaussian distribution, and simultaneously takes into account the dependency between the profile and secondary structure and the dependency between profiles of neighboring residues. In addition, a segment length distribution is introduced for each secondary structure state. Tests show that the DBN method has made a significant improvement in the accuracy compared to other pure HMM-type methods. Further improvement is achieved by combining the DBN with an NN, a method called DBNN, which shows better Q(3) accuracy than many popular methods and is competitive to the current state-of-the-arts. The most interesting feature of DBN/DBNN is that a significant improvement in the prediction accuracy is achieved when combined with other methods by a simple consensus. Conclusion: The DBN method using a Gaussian distribution for the PSI-BLAST profile and a high-ordered dependency between profiles of neighboring residues produces significantly better prediction accuracy than other HMM-type probabilistic methods. Owing to their different nature, the DBN and NN combine to form a more accurate method DBNN. Future improvement may be achieved by combining DBNN with a method of SVM type.	[Yao, Xin-Qiu; Zhu, Huaiqiu; She, Zhen-Su] Peking Univ, State Key Lab Turbulence & Complex Syst, Beijing 100871, Peoples R China; [Yao, Xin-Qiu; Zhu, Huaiqiu; She, Zhen-Su] Peking Univ, Dept Biomed Engn, Beijing 100871, Peoples R China; [Yao, Xin-Qiu; Zhu, Huaiqiu; She, Zhen-Su] Peking Univ, Ctr Theoret Biol, Beijing 100871, Peoples R China; [She, Zhen-Su] Univ Calif Los Angeles, Dept Math, Los Angeles, CA 90095 USA	She, ZS (reprint author), Peking Univ, State Key Lab Turbulence & Complex Syst, Beijing 100871, Peoples R China.	yxq@ctb.pku.edu.cn; hqzhu@pku.edu.cn; she@pku.edu.cn	佘, 振苏/C-1447-2010; Yao, Xin-Qiu/D-3220-2011; Zhu, Huaiqiu/C-3617-2012				Adamczak R, 2005, PROTEINS, V59, P467, DOI 10.1002/prot.20441; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Andreeva A, 2004, NUCLEIC ACIDS RES, V32, pD226, DOI 10.1093/nar/gkh039; Aydin Z, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-178; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Chu W, 2006, IEEE ACM T COMPUT BI, V3, P98; Crooks GE, 2004, BIOINFORMATICS, V20, P1603, DOI 10.1093/bioinformatics/bth132; Cuff JA, 2000, PROTEINS, V40, P502, DOI 10.1002/1097-0134(20000815)40:3<502::AID-PROT170>3.0.CO;2-Q; Cuff JA, 1999, PROTEINS, V34, P508, DOI 10.1002/(SICI)1097-0134(19990301)34:4<508::AID-PROT10>3.0.CO;2-4; Dor O, 2007, PROTEINS, V66, P838, DOI 10.1002/prot.21298; Guo J, 2004, PROTEINS, V54, P738, DOI 10.1002/prot.10634; Hua SJ, 2001, J MOL BIOL, V308, P397, DOI 10.1006/jmbi.2001.4580; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; Karplus K, 1999, PROTEINS, P121; KARPLUS K, 2005, PROTEINS, V7, P135; Karypis G, 2006, PROTEINS, V64, P575, DOI 10.1002/prot.21036; Kim H, 2003, PROTEIN ENG, V16, P553, DOI 10.1093/protein/gzg072; Koh IYY, 2003, NUCLEIC ACIDS RES, V31, P3311, DOI 10.1093/nar/gkg619; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; McGuffin LJ, 2003, PROTEINS, V52, P166, DOI 10.1002/prot.10408; MURPHY KB, 2005, COMPUTER SCI, P225; Ouali M, 2000, PROTEIN SCI, V9, P1162; Pollastri G, 2005, BIOINFORMATICS, V21, P1719, DOI 10.1093/bioinformatics/bti203; Przybylski D, 2002, PROTEINS, V46, P197, DOI 10.1002/prot.10029; Qian N, 1988, J MOL BIOL, V202, P865, DOI 10.1016/0022-2836(88)90564-5; ROST B, 1993, J MOL BIOL, V232, P584, DOI 10.1006/jmbi.1993.1413; Schmidler SC, 2000, J COMPUT BIOL, V7, P233, DOI 10.1089/10665270050081496; STULTZ CM, 1993, PROTEIN SCI, V2, P305; Thompson MJ, 1997, PROTEIN SCI, V6, P1963; Ward JJ, 2003, BIOINFORMATICS, V19, P1650, DOI 10.1093/bioinformatics/btg223; Xu Y, 2000, PROTEINS, V40, P343, DOI 10.1002/1097-0134(20000815)40:3<343::AID-PROT10>3.0.CO;2-S; Zemla A, 1999, PROTEINS, V34, P220, DOI 10.1002/(SICI)1097-0134(19990201)34:2<220::AID-PROT7>3.0.CO;2-K; PREDICTION SCHEME SA	34	13	14	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	JAN 25	2008	9								49	10.1186/1471-2105-9-49		13	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	274OM	WOS:000254010600001	
J	Sadygov, RG; Hao, Z; Huhmer, AFR				Sadygov, Rovshan G.; Hao, Zhiqi; Huhmer, Andreas F. R.			Charger: Combination of signal processing and statistical learning algorithms for precursor charge-state determination from electron-transfer dissociation spectra	ANALYTICAL CHEMISTRY			English	Article							TANDEM MASS-SPECTRA; TRANSFER ION/ION REACTIONS; PROTEIN IDENTIFICATION; SEQUENCE DATABASES; ION-TRAP; SPECTROMETRY; PEPTIDE; EFFICIENCY	Tandem mass spectrometry in combination with liquid chromatography has emerged as a powerful tool for characterization of complex protein mixtures in a high-throughput manner. One of the bioinformatics challenges posed by the mass spectral data analysis is the determination of precursor charge when unit mass resolution is used for detecting fragment ions. The charge-state information is used to filter database sequences before they are correlated to experimental data. In the absence of the accurate charge state, several charge states are assumed. This dramatically increases database search times. To address this problem, we have developed an approach for charge-state determination of peptides from their tandem mass spectra obtained in fragmentations via electron-transfer dissociation (ETD) reactions. Protein analysis by ETD is thought to enhance the range of amino acid sequences that can be analyzed by mass spectrometry-based proteomics. One example is the improved capability to characterize phosphorylated peptides. Our approach to charge-state determination uses a combination of signal processing and statistical machine learning. The signal processing employs correlation and convolution analyses to determine precursor masses and charge states of peptides. We discuss applicability of these methods to spectra of different charge states. We note that in our applications correlation analysis outperforms the convolution in determining peptide charge states. The correlation analysis is best suited for spectra with prevalence of complementary ions. It is highly specific but is dependent on quality of spectra. The linear discriminant analysis (LDA) approach uses a number of other spectral features to predict charge states. We train LDA classifier on a set of manually curated spectral data from a mixture of proteins of known identity. There are over 5000 spectra in the training set. A number of features, pertinent to spectra of peptides obtained via ETD reactions, have been used in the training. The loading coefficients of LDA indicate the relative importance of different features for charge-state determination. We have applied our model to a test data set generated from a mixture of 49 proteins. We search the spectra with and without use of the charge-state determination. The charge-state determination helps to significantly save the database search times. We discuss the cost associated with the possible misclassification of I charge states.	[Sadygov, Rovshan G.; Hao, Zhiqi; Huhmer, Andreas F. R.] ThermoFisher Sci, San Jose, CA 95134 USA	Sadygov, RG (reprint author), ThermoFisher Sci, 355 River Oaks Pkwy, San Jose, CA 95134 USA.	rovshan.sadygov@thermofisher.com					AARON A, 2005, IEEE, V8, P175; Chi A, 2007, P NATL ACAD SCI USA, V104, P2193, DOI 10.1073/pnas.0607084104; Chrisman PA, 2005, J AM SOC MASS SPECTR, V16, P1020, DOI 10.1016/j.jasms.2005.02.010; Colinge J, 2003, PROTEOMICS, V3, P1434, DOI 10.1002/pmic.200300489; Coon JJ, 2005, J AM SOC MASS SPECTR, V16, P880, DOI 10.1016/j.jasms.2005.01.015; Craig R, 2004, J PROTEOME RES, V3, P1234, DOI 10.1021/pr049882h; Dancik V, 1999, J COMPUT BIOL, V6, P327, DOI 10.1089/106652799318300; Domon B, 2006, SCIENCE, V312, P212, DOI 10.1126/science.1124619; Duda R. O., 2001, PATTERN CLASSIFICATI; Elias JE, 2004, NAT BIOTECHNOL, V22, P214, DOI 10.1038/nbt930; ENG JK, 1994, J AM SOC MASS SPECTR, V5, P976, DOI 10.1016/1044-0305(94)80016-2; GEER LY, 2004, EFFICIENT MS MS PEPT; Hogan JM, 2005, OMICS, V9, P233, DOI 10.1089/omi.2005.9.233; HUNT D, 2006, COMMUNICATION; Kelleher N L, 1999, Anal Chem, V71, P4250, DOI 10.1021/ac990684x; Kelleher Neil L, 2004, Anal Chem, V76, p197A; Liang XR, 2007, ANAL CHEM, V79, P3363, DOI 10.1021/ac062295q; Link AJ, 1999, NAT BIOTECHNOL, V17, P676; McDonald WH, 2004, RAPID COMMUN MASS SP, V18, P2162, DOI 10.1002/rcm.1603; OWENS KG, 1992, APPL SPECTROSC REV, V27, P1, DOI 10.1080/05704929208018268; PAPAYANNOPOULOS IA, 1995, MASS SPECTROM REV, V14, P49, DOI 10.1002/mas.1280140104; Perkins DN, 1999, ELECTROPHORESIS, V20, P3551, DOI 10.1002/(SICI)1522-2683(19991201)20:18<3551::AID-ELPS3551>3.0.CO;2-2; Pitteri SJ, 2005, ANAL CHEM, V77, P1831, DOI 10.1021/ac0483872; Press W. H., 2002, NUMERICAL RECIPES C; Sadygov Rovshan, 2006, Anal Chem, V78, P89, DOI 10.1021/ac051206r; Sadygov RG, 2004, NAT METHODS, V1, P195, DOI 10.1038/NMETH725; Sadygov RG, 2003, ANAL CHEM, V75, P3792, DOI 10.1021/ac034157w; Sadygov RG, 2002, J PROTEOME RES, V1, P211, DOI 10.1021/pr015514r; Swaney DL, 2007, ANAL CHEM, V79, P477, DOI 10.1021/ac061457f; Syka JEP, 2004, P NATL ACAD SCI USA, V101, P9528, DOI 10.1073/pnas.0402700101; Taylor GK, 2003, ANAL CHEM, V75, P4081, DOI 10.1021/ac0341721; Venable JD, 2006, ANAL CHEM, V78, P1921, DOI 10.1021/ac051636h; Wysocki VH, 2000, J MASS SPECTROM, V35, P1399, DOI 10.1002/1096-9888(200012)35:12<1399::AID-JMS86>3.0.CO;2-R; Zubarev RA, 2004, CURR OPIN BIOTECH, V15, P12, DOI 10.1016/j.copbio.2003.12.002; [Anonymous], 2006, R LANGUAGE ENV STAT	35	14	15	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0003-2700		ANAL CHEM	Anal. Chem.	JAN 15	2008	80	2					376	386		10.1021/ac071332q		11	Chemistry, Analytical	Chemistry	250RQ	WOS:000252318200005	
J	Hertel, J; Hofacker, IL; Stadler, PF				Hertel, Jana; Hofacker, Ivo L.; Stadler, Peter F.			SnoReport: computational identification of snoRNAs with unknown targets	BIOINFORMATICS			English	Article							SMALL NUCLEOLAR RNAS; NONCODING RNAS; DROSOPHILA-MELANOGASTER; CAENORHABDITIS-ELEGANS; SECONDARY STRUCTURES; GUIDE SNORNAS; HUMAN GENOME; GENES; H/ACA; C/D	Unlike tRNAs and microRNAs, both classes of snoRNAs, which direct two distinct types of chemical modifications of uracil residues, have proved to be surprisingly difficult to find in genomic sequences. Most computational approaches so far have explicitly used the fact that snoRNAs predominantly target ribosomal RNAs and spliceosomal RNAs. The target is specified by a short stretch of sequence complementarity between the snoRNA and its target. This sequence complementarity to known targets crucially contributes to sensitivity and specificity of snoRNA gene finding algorithms. The discovery of orphan snoRNAs, which either have no known target, or which target ordinary protein-coding mRNAs, however, begs the question whether this class of housekeeping non-coding RNAs is much more widespread and might have a diverse set of regulatory functions. In order to approach this question, we present here a combination of RNA secondary structure prediction and machine learning that is designed to recognize the two major classes of snoRNAs, box CD and box HACA snoRNAs, among ncRNA candidate sequences. The snoReport approach deliberately avoids any usage of target information. We find that the combination of the conserved sequence boxes and secondary structure constraints as a pre-filter with SVM classifiers based on a small set of structural descriptors are sufficient for a reliable identification of snoRNAs. Tests of snoReport on data from several recent experimental surveys show that the approach is feasible; the application to a dataset from a large-scale comparative genomics survey for ncRNAs suggests that there are likely hundreds of previously undescribed orphan snoRNAs still hidden in the human genome.	[Hertel, Jana; Hofacker, Ivo L.; Stadler, Peter F.] Univ Vienna, Inst Theoret Chem, A-1090 Vienna, Austria; [Hertel, Jana; Stadler, Peter F.] Univ Leipzig, Bioinformat Grp, Dept Comp Sci, D-04107 Leipzig, Germany; [Hertel, Jana; Stadler, Peter F.] Univ Leipzig, Interdisciplinary Ctr Bioinformat, D-04107 Leipzig, Germany; [Stadler, Peter F.] Fraunhofer Inst Zelltherapie & Immunol Deutsch Pl, D-04103 Leipzig, Germany; [Stadler, Peter F.] Santa Fe Inst, Santa Fe, NM 87501 USA	Hertel, J (reprint author), Univ Vienna, Inst Theoret Chem, Wahringerstr 17, A-1090 Vienna, Austria.	jana@bioinf.uni-leipzig.de	Hofacker, Ivo/A-2378-2013	Hofacker, Ivo/0000-0001-7132-0800			Accardo MC, 2004, BIOINFORMATICS, V20, P3293, DOI 10.1093/bioinformatics/bth394; ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Aravin A, 2006, NATURE, V442, P203, DOI 10.1038/nature04916; ATHANASIUS F, 2007, J EXP ZOOL PART B, V308, P1; Bachellerie JP, 2002, BIOCHIMIE, V84, P775, DOI 10.1016/S0300-9084(02)01402-5; Bailey T L, 1994, Proc Int Conf Intell Syst Mol Biol, V2, P28; Bertone P, 2004, SCIENCE, V306, P2242, DOI 10.1126/science.1103388; Carninci P, 2005, SCIENCE, V309, P1559, DOI 10.1126/science.1112014; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Cheng J, 2005, SCIENCE, V308, P1149, DOI 10.1126/science.1108625; COLLINS LJ, 2004, J INTEGRATED BIOINFO, V6, P15; Deng W, 2006, GENOME RES, V16, P20, DOI 10.1101/gr.4139206; DURBIN R, 1998, THEORY PROFILE HHMS; Edvardsson S, 2003, BIOINFORMATICS, V19, P865, DOI 10.1093/bioinformatics/btg080; Griffiths-Jones S., 2005, NUCLEIC ACIDS RES, V33, P121; Griffiths-Jones S, 2004, NUCLEIC ACIDS RES, V32, pD109, DOI 10.1093/nar/gkh023; Hertel J, 2006, BIOINFORMATICS, V22, pE197, DOI 10.1093/bioinformatics/btl257; Hofacker IL, 2003, NUCLEIC ACIDS RES, V31, P3429, DOI 10.1093/nar/gkg599; HOFACKER IL, 1994, MONATSH CHEM, V125, P167, DOI 10.1007/BF00818163; HOFACKER NL, 2002, J MOL BIOL, V319, P1059; Huang ZP, 2005, RNA, V11, P1303, DOI 10.1261/rna.2380905; Huttenhofer Alexander, 2004, Methods Mol Biol, V265, P409; Huttenhofer A, 2001, EMBO J, V20, P2943, DOI 10.1093/emboj/20.11.2943; Kapranov P, 2007, SCIENCE, V316, P1484, DOI 10.1126/science.1138341; Kel AE, 2003, NUCLEIC ACIDS RES, V31, P3576, DOI 10.1093/nar/gkg585; LAFONTAINE D, 2002, TRENDS BIOCHEM SCI, V23, P383; Lau NC, 2006, SCIENCE, V313, P363, DOI 10.1126/science.1130164; Lestrade L, 2006, NUCLEIC ACIDS RES, V34, pD158, DOI 10.1093/nar/gkj002; Liang XH, 2007, EUKARYOT CELL, V6, P361, DOI 10.1128/EC.00296-06; Lowe TM, 1999, SCIENCE, V283, P1168, DOI 10.1126/science.283.5405.1168; Lowe TM, 1997, NUCLEIC ACIDS RES, V25, P955, DOI 10.1093/nar/25.5.955; Missal K, 2005, BIOINFORMATICS, V21, P77, DOI 10.1093/bioinformatics/bti1113; Missal K, 2006, J EXP ZOOL PART B, V306B, P379, DOI 10.1002/jez.b.21086; Mosig Axel, 2006, Genomics Proteomics & Bioinformatics, V4, P56, DOI 10.1016/S1672-0229(06)60017-X; Nawrocki EP, 2007, PLOS COMPUT BIOL, V3, P540, DOI 10.1371/journal.pcbi.0030056; Pedersen JS, 2006, PLOS COMPUT BIOL, V2, P251, DOI 10.1371/journal.pcbi.0020033; Piccinelli P, 2005, NUCLEIC ACIDS RES, V33, P4485, DOI 10.1093/nar/gki756; Rogelj B, 2006, J MOL NEUROSCI, V28, P103, DOI 10.1385/JMN/28:02:103; Ruby JG, 2006, CELL, V127, P1193, DOI 10.1016/j.cell.2006.10.040; Schattner P, 2006, RNA, V12, P15, DOI 10.1261/rna.2210406; Schattner P, 2004, NUCLEIC ACIDS RES, V32, P4281, DOI 10.1093/nar/gkh768; Vitali P, 2005, J CELL BIOL, V169, P745, DOI 10.1083/jcb.200411129; Washietl S, 2005, NAT BIOTECHNOL, V23, P1383, DOI 10.1038/ndt1144; Washietl S, 2005, P NATL ACAD SCI USA, V102, P2454, DOI 10.1073/pnas.0409169102; Will S, 2007, PLOS COMPUT BIOL, V3, P680, DOI 10.1371/journal.pcbi.0030065; Yang JH, 2006, NUCLEIC ACIDS RES, V34, P5112, DOI 10.1093/nar/gkl672; Yoon Sungroh, 2006, Birth Defects Research, V78, P118, DOI 10.1002/bdrc.20067; Zemann A, 2006, NUCLEIC ACIDS RES, V34, P2676, DOI 10.1093/nar/gkl359	48	44	50	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	JAN 15	2008	24	2					158	164		10.1093/bioinformatics/btm464		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	253DI	WOS:000252498500002	
J	Faulon, JL; Misra, M; Martin, S; Sale, K; Sapra, R				Faulon, Jean-Loup; Misra, Milind; Martin, Shawn; Sale, Ken; Sapra, Rajat			Genome scale enzyme-metabolite and drug-target interaction predictions using the signature molecular descriptor	BIOINFORMATICS			English	Article							PROTEIN-PROTEIN INTERACTIONS; EXTENDED VALENCE SEQUENCES; SUPPORT VECTOR MACHINE	Motivation: Identifying protein enzymatic or pharmacological activities are important areas of research in biology and chemistry. Biological and chemical databases are increasingly being populated with linkages between protein sequences and chemical structures. There is now sufficient information to apply machine-learning techniques to predict interactions between chemicals and proteins at a genome scale. Current machine-learning techniques use as input either protein sequences and structures or chemical information. We propose here a method to infer proteinchemical interactions using heterogeneous input consisting of both protein sequence and chemical information. Results: Our method relies on expressing proteins and chemicals with a common cheminformatics representation. We demonstrate our approach by predicting whether proteins can catalyze reactions not present in training sets. We also predict whether a given drug can bind a target, in the absence of prior binding information for that drug and target. Such predictions cannot be made with current machine-learning techniques requiring binding information for individual reactions or individual targets.	[Faulon, Jean-Loup; Misra, Milind] Sandia Natl Labs, Computat Biosci Dept, Albuquerque, NM 87185 USA; [Martin, Shawn] Sandia Natl Labs, Dept Informat & Comp Sci, Albuquerque, NM 87185 USA; [Sale, Ken; Sapra, Rajat] Sandia Natl Labs, Livermore, CA 94551 USA	Faulon, JL (reprint author), Sandia Natl Labs, Computat Biosci Dept, POB 5800, Albuquerque, NM 87185 USA.	jfaulon@sandia.gov					Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Atchley WR, 2005, P NATL ACAD SCI USA, V102, P6395, DOI 10.1073/pnas.0408677102; Austin CP, 2004, SCIENCE, V306, P1138, DOI 10.1126/science.1105511; Bender A, 2004, J CHEM INF COMP SCI, V44, P1708, DOI 10.1021/ci0498719; Ben-Hur A., 2005, BIOINFORMATICS S1, V21, P38; Bock JR, 2001, BIOINFORMATICS, V17, P455, DOI 10.1093/bioinformatics/17.5.455; Borgwardt K.M., 2005, BIOINFORMATICS, V21, P47; Brooksbank C, 2005, NUCLEIC ACIDS RES, V33, pD46, DOI 10.1093/nar/gki026; Cai CZ, 2003, NUCLEIC ACIDS RES, V31, P3692, DOI 10.1093/nar/gkg600; Churchwell CJ, 2004, J MOL GRAPH MODEL, V22, P263, DOI 10.1016/j.jmgm.2003.10.002; Faulon JL, 2004, J CHEM INF COMP SCI, V44, P427, DOI 10.1021/ci0341823; FAULON JL, 1994, J CHEM INF COMP SCI, V34, P1204, DOI 10.1021/ci00021a031; Faulon JL, 2003, J CHEM INF COMP SCI, V43, P721, DOI 10.1021/ci020346o; Fukuzawa K, 2005, J COMPUT CHEM, V26, P1, DOI 10.1002/jcc.20130; Gartner T., 2003, P 16 ANN C COMP LEAR; Gasteiger J., 2003, CHEMOINFORMATICS; Helma C, 2001, BIOINFORMATICS, V17, P107, DOI 10.1093/bioinformatics/17.1.107; HENIKOFF S, 1992, P NATL ACAD SCI USA, V89, P10915, DOI 10.1073/pnas.89.22.10915; Johnson JM, 2000, P NATL ACAD SCI USA, V97, P3965, DOI 10.1073/pnas.050580897; Kalinina OV, 2004, NUCLEIC ACIDS RES, V32, pW424, DOI 10.1093/nar/gkh391; Kanehisa M, 2006, NUCLEIC ACIDS RES, V34, pD354, DOI 10.1093/nar/gkj102; Kashima H., 2003, P 20 INT C MACH LEAR; Kotera M, 2004, J AM CHEM SOC, V126, P16487, DOI 10.1021/ja0466457; KRAMER S, 2001, 18 INT C MACH LEARN; KUNIK V, 2005, P IEEE COMP SYST BIO, V4, P80; Leslie Christina, 2002, Pac Symp Biocomput, P564; Mahe P, 2006, J CHEM INF MODEL, V46, P2003, DOI 10.1021/ci060138m; Martin S, 2005, BIOINFORMATICS, V21, P218, DOI 10.1093/bioinformatics/bth483; Mulder NJ, 2007, NUCLEIC ACIDS RES, V35, pD224, DOI 10.1093/nar/gkl841; Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565; SWAMIDASS SJ, 2007, BIOINFORMATICS S1, V47, P952; Warren GL, 2006, J MED CHEM, V49, P5912, DOI 10.1021/jm050362n; WEBB EC, 1992, ENZYME NONMENCLATURE; White RH, 2006, J BACTERIOL, V188, P3431, DOI 10.1128/JB.188.10.3431-3432.2006; Wishart DS, 2006, NUCLEIC ACIDS RES, V34, pD668, DOI 10.1093/nar/gkj067	35	38	38	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	JAN 15	2008	24	2					225	233		10.1093/bioinformatics/btm580		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	253DI	WOS:000252498500011	
J	Grinand, C; Arrouays, D; Laroche, B; Martin, MP				Grinand, Clovis; Arrouays, Dominique; Laroche, Bertrand; Martin, Manuel Pascal			Extrapolating regional soil landscapes from an existing soil map: Sampling intensity, validation procedures, and integration of spatial context	GEODERMA			English	Article						digital soil mapping; boosted classification tree; extrapolation; sampling intensity; validation; France	CLASSIFICATION TREE ANALYSIS; REMOTELY-SENSED DATA; KNOWLEDGE DISCOVERY; REFERENCE AREA; LAND-COVER; PREDICTION; TERRAIN	This paper aims to investigate the potential of using soil-landscape pattern extracted from a soil map to predict soil distribution at unvisited location. Recent machine learning advances used in previous studies showed that the knowledge embedded within soil units delineated by experts can be retrieved and explicitly fomulated from environmental data layers However, the extent to which the models can yield valid prediction has been little studied. Our approach is based on a classification tree analysis which has underwent a recent statistics advance, namely, stochastic gradient boosting. We used an existing soil-landscape map to test our methodology. Explanatory variables included classical terrain factors (elevation, slope, curvature plan and profile, wetness index, etc.), various channels and combinations of channels from LANDSAT ETM imagery, land cover and lithology maps. Overall classification accuracy indexes were calculated under two validation schemes, either taken within the training area or from a separated validation area. We focused our study on the accuracy assessment and testing of two modelling parameters: sampling intensity and spatial context integration. First, we observed strong differences in accuracy between the training area and the extrapolated area. Second, sampling intensity, in proportion to the class extent, did not largely influence the classification accuracy. Spatial context integration by the use of a mean filtering algorithm on explanatory variables increased the Kappa index on the extrapolated area by more than ten points. The best accuracy measurements were obtained for a combination of the raw explanatory dataset with the filtered dataset representing regional trend. However, the predictive capacity of models remained quite low when extrapolated to an independent validation area. Nevertheless, this study offers encouragement for the success of extrapolating soil patterns from existing soil maps to fill the gaps in present soil map coverage and to increase efficiency of ongoing soil survey. (C) 2007 Elsevier B.V. All rights reserved.	[Grinand, Clovis; Arrouays, Dominique; Laroche, Bertrand; Martin, Manuel Pascal] INRA, InfoSol, US 1106, F-45166 Olivet, France	Arrouays, D (reprint author), INRA, InfoSol, US 1106, Ave Pomme Pin,BP 20619, F-45166 Olivet, France.	dominique.arrouays@orleans.inra.fr					BONN F, 1992, PRECIS TELEDETECTION, V1; Breiman L, 1984, CLASSIFICATION REGRE; Bui EN, 2006, ECOL MODEL, V191, P431, DOI 10.1016/j.ecolmodel.2005.05.021; Bui EN, 2003, GEODERMA, V111, P21, DOI 10.1016/S0016-7061(02)00238-0; Bui EN, 2004, GEODERMA, V120, P17, DOI 10.1016/j.geoderma.2003.07.006; DOBOS E, 2006, 22123 EN EUR OFF OFF; Dobos E, 2000, GEODERMA, V97, P367, DOI 10.1016/S0016-7061(00)00046-X; Fayyad U.M., 1996, DATA MIN KNOWL DISC, P1; FINKE P, 2001, 18092 FR EUR EUR COM; FOODY GM, 2002, STATUS LAND COVER CL, V80, P185; FREIDMAN JH, 1999, STOCHASTIC GRADIENT; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Friedl MA, 1997, REMOTE SENS ENVIRON, V61, P399, DOI 10.1016/S0034-4257(97)00049-7; Friedl MA, 2000, INT J REMOTE SENS, V21, P1073, DOI 10.1080/014311600210434; Friedman JH, 2003, STAT MED, V22, P1365, DOI 10.1002/sim.1501; GIRARD MC, 1999, TRAITEMENTS DONNEES; Grunwald S, 2006, ENV SOIL LANDSCAPE M; Irvin BJ, 1997, GEODERMA, V77, P137, DOI 10.1016/S0016-7061(97)00019-0; Lagacherie P, 2001, GEODERMA, V101, P105, DOI 10.1016/S0016-7061(00)00101-4; LAGACHERIE P, 2002, CARTOGRAPHIE SOLS LE; Lagacherie P., 1992, THESIS U MONTPELLIER; LAGACHERIE P, 1995, GEODERMA, V65, P283, DOI 10.1016/0016-7061(94)00040-H; Lagacherie P, 1997, INT J GEOGR INF SCI, V11, P183, DOI 10.1080/136588197242455; Lawrence R, 2004, REMOTE SENS ENVIRON, V90, P331, DOI 10.1016/j.rse.2004.01.007; Luoto M, 2005, GEOMORPHOLOGY, V67, P299, DOI 10.1016/j.geomorph.2004.10.006; McBratney AB, 2003, GEODERMA, V117, P3, DOI 10.1016/S0016-7061(03)00223-4; McKenzie NJ, 1999, GEODERMA, V89, P67, DOI 10.1016/S0016-7061(98)00137-2; Moran CJ, 2002, INT J GEOGR INF SCI, V16, P533, DOI 10.1080/13658810210138715; Muchoney DM, 2002, REMOTE SENS ENVIRON, V81, P290, DOI 10.1016/S0034-4257(02)00006-8; Qi F, 2003, INT J GEOGR INF SCI, V17, P771, DOI 10.1080/13658810310001596049; R Development Core Team, 2005, LANG ENV STAT COMP F; Schetselaar EM, 2000, REMOTE SENS ENVIRON, V71, P89, DOI 10.1016/S0034-4257(99)00069-3; Scull P, 2005, ECOL MODEL, V181, P1, DOI 10.1016/j.ecolmodel.2004.06.036; Switzer P, 1980, MATH GEOL, V12, P367; WILSON PJ, 2000, TERRAIN ANAL PRINCIP; *COMM EUR COMM, 1993, COR LAND COV; *IGN, 2006, BDCARTO; *U MAR, 2005, GLOB LAND COV FAC	38	33	37	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0016-7061		GEODERMA	Geoderma	JAN 15	2008	143	1-2					180	190		10.1016/j.geoderma.2007.11.004		11	Soil Science	Agriculture	254KT	WOS:000252586200017	
J	Solomatine, DP; Maskey, M; Shrestha, DL				Solomatine, Dirnitri P.; Maskey, Mahesh; Shrestha, Durga Lal			Instance-based learning compared to other data-driven methods in hydrological forecasting	HYDROLOGICAL PROCESSES			English	Article						hydrological modelling; floods; data-driven models; instance-based learning; artificial neural networks; locally weighted regression; k-nearest neighbour method	ARTIFICIAL NEURAL-NETWORKS; RAINFALL-RUNOFF MODELS; PREDICTION	Data-driven techniques based on machine learning algorithms are becoming popular in hydrological modelling, in particular for forecasting. Artificial neural networks (ANNs) are often the first choice. The so-called instance-based learning (IBL) has received relatively little attention, and the present paper explores the applicability of these methods in the field of hydrological forecasting. Their performance is compared with that of ANNs, M5 model trees and conceptual hydrological models. Four short-term flow forecasting problems were solved for two catchments. Results showed that the IBL methods often produce better results than ANNs and M5 model trees, especially if used with the Gaussian kernel function. The study showed that IBL is an effective data-driven method that can be successfully used in hydrological forecasting. Copyright (c) 2007 John Wiley & Sons, Ltd.	[Solomatine, Dirnitri P.; Shrestha, Durga Lal] UNESCO, IHE, Inst Water Educ, NL-2601 DA Delft, Netherlands; [Maskey, Mahesh] NepalConsult P Ltd, Civil Engn, Kathmandu, Nepal	Solomatine, DP (reprint author), UNESCO, IHE, Inst Water Educ, POB 3015, NL-2601 DA Delft, Netherlands.	d.solomatine@unesco-ihe.org	Shrestha, Durga/B-5610-2013	Shrestha, Durga/0000-0002-5545-1736			Abrahart RJ, 2000, HYDROL PROCESS, V14, P2157, DOI 10.1002/1099-1085(20000815/30)14:11/12<2157::AID-HYP57>3.0.CO;2-S; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Allegra A, 1998, MAGNESIUM RES, V11, P11; BECKER A, 1987, WATER RESOUR RES, V23, P1043, DOI 10.1029/WR023i006p01043; Bray M, 2004, J HYDROINFORM, V6, P265; Cigizoglu HK, 2003, HYDROLOG SCI J, V48, P349, DOI 10.1623/hysj.48.3.349.45288; CLEVELAND WS, 1994, 953 AT T BELL LAB ST; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dawson CW, 2001, PROG PHYS GEOG, V25, P80, DOI 10.1191/030913301674775671; Dibike YB, 2001, PHYS CHEM EARTH PT B, V26, P1, DOI 10.1016/S1464-1909(01)85005-X; DIBIKE Y, 1999, GEOPH RES ABSTR; FEDOROV VV, 1993, NONPARAMETRIC STAT, V2, P355; Franchini M, 1996, HYDROLOG SCI J, V41, P21, DOI 10.1080/02626669609491476; GALEATI G, 1990, HYDROLOG SCI J, V35, P79, DOI 10.1080/02626669009492406; Gasser T., 1979, LECT NOTES MATH, V757, P23; GOVINDARAJU RS, 2000, ARTIFICIAL NEURAL NE, P329; Haykin S., 1999, NEURAL NETWORKS COMP; HSU KL, 1995, WATER RESOUR RES, V31, P2517, DOI 10.1029/95WR01955; KARLSSON M, 1987, WATER RESOUR RES, V23, P1300, DOI 10.1029/WR023i007p01300; KUNCHEVA LI, 2004, COMBINING PATTERN CL; Maier HR, 2000, ENVIRON MODELL SOFTW, V15, P101, DOI 10.1016/S1364-8152(99)00007-9; MARSIGLI M, 2002, MUSIC MULTIPLE SENSO; Minns AW, 1996, HYDROLOG SCI J, V41, P399, DOI 10.1080/02626669609491511; Mitchell T.M., 1997, MACH LEARN, P414; Quinlan J. R, 1992, 5 AUSTR JOINT C ART, P343; QUINLAN JR, 1993, MACH LEARN P 10 INT, P236; REFSGAARD JC, 1996, DISTRIBUTED HYDROLOG, P321; Scott D. W., 1992, MULTIVARIATE DENSITY; Shamseldin AY, 1996, J HYDROL, V179, P353, DOI 10.1016/0022-1694(95)02833-1; Shrestha DL, 2006, NEURAL NETWORKS, V19, P225, DOI 10.1016/j.neunet.2006.01.012; SHRESTHA I, 2003, CONCEPTUAL DATA DRIV; Solomatine D. P., 2004, 6 INT C HYDR; SOLOMATINE DP, 2004, J HYDROLOGIC ENG, V9; Solomatine DP, 2006, NEURAL NETWORKS, V19, P215, DOI 10.1016/j.neunet.2006.01.008; Solomatine DP, 2003, HYDROLOG SCI J, V48, P399, DOI 10.1623/hysj.48.3.399.45291; SOLOMATINE DP, 2005, ENCY HYDROLOGICAL SC; Sugawara M., 1995, COMPUTER MODELS WATE, P165; Todini E, 1996, J HYDROL, V175, P339, DOI 10.1016/S0022-1694(96)80016-3; Toth E, 2000, J HYDROL, V239, P132, DOI 10.1016/S0022-1694(00)00344-9; Weiss SM, 1995, J ARTIF INTELL RES, V3, P383; WITTEN IH, 2000, DATA MINING PRACTICA, P132; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	42	10	10	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0885-6087		HYDROL PROCESS	Hydrol. Process.	JAN 15	2008	22	2					275	287		10.1002/hyp.6592		13	Water Resources	Water Resources	259LE	WOS:000252940000010	
J	Muller, KR; Tangermann, M; Dornhege, G; Krauledat, M; Curio, G; Blankertz, B				Mueller, Klaus-Robert; Tangermann, Michael; Dornhege, Guido; Krauledat, Matthias; Curio, Gabriel; Blankertz, Benjamin			Machine learning for real-time single-trial EEG-analysis: From brain-computer interfacing to mental state monitoring	JOURNAL OF NEUROSCIENCE METHODS			English	Article						EEG; sensorimotor rhythms; alpha-rhythm; single-trial EEG-analysis; real-time; machine learning; mental state monitoring	BOOSTING BIT RATES; INFORMATION-TRANSFER; COMMUNICATION; BCI; CLASSIFICATION; POTENTIALS; FILTERS; CHANNEL	Machine learning methods are an excellent choice for compensating the high variability in EEG when analyzing single-trial data in real-time. This paper briefly reviews preprocessing and classification techniques for efficient EEG-based brain-computer interfacing (BCI) and mental state monitoring applications. More specifically, this paper gives an outline of the Berlin brain-computer interface (BBCI), which can be operated with minimal subject training. Also, spelling with the novel BBCI-based Hex-o-Spell text entry system, which gains communication speeds of 6-8 letters per minute, is discussed. Finally the results of a real-time arousal monitoring experiment are presented. (C) 2007 Elsevier B.V. All rights reserved.	[Mueller, Klaus-Robert; Krauledat, Matthias; Blankertz, Benjamin] Tech Univ Berlin, D-10623 Berlin, Germany; [Mueller, Klaus-Robert; Tangermann, Michael; Dornhege, Guido; Blankertz, Benjamin] Fraunhofer FIRST IDA, D-12489 Berlin, Germany; [Curio, Gabriel] Univ Med Berlin, Charite, Dept Neurol, Berlin, Germany	Muller, KR (reprint author), Tech Univ Berlin, Str 17 Juni 135, D-10623 Berlin, Germany.	klaus@first.fhg.de	Muller, Klaus/C-3196-2013				Bennett K.P, 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; Birbaumer N, 2000, IEEE T REHABIL ENG, V8, P190, DOI 10.1109/86.847812; BLANKERTZ B, 2005, 1 FIRST; Blankertz B, 2007, LECT NOTES COMPUT SC, V4555, P759; Blankertz B., 2006, P 3 INT BRAIN COMP I, P108; Blankertz B, 2002, ADV NEUR IN, V14, P157; Blankertz B, 2006, J UNIVERS COMPUT SCI, V12, P581; Blankertz B, 2007, NEUROIMAGE, V37, P539, DOI 10.1016/j.neuroimage.2007.01.051; Blankertz B, 2003, IEEE T NEUR SYS REH, V11, P127, DOI 10.1109/TNSRE.2003.814456; CARMENA JM, 2003, PLOS BIOL, P42; Curran EA, 2003, BRAIN COGNITION, V51, P326, DOI 10.1016/0278-2626(03)00036-8; Dornhege G, 2006, THESIS U POTSDAM; Dornhege G, 2006, IEEE T BIO-MED ENG, V53, P2274, DOI 10.1109/TBME.2006.883649; Dornhege G, 2007, BRAIN COMPUTER INTER; Dornhege G, 2004, IEEE T BIO-MED ENG, V51, P993, DOI 10.1109/TBME.2004.827088; Dornhege G., 2003, ADV NEURAL INF P SYS, V15, P1115; Blankertz B, 2006, IEEE T NEUR SYS REH, V14, P147, DOI 10.1109/TNSRE.2006.875557; ELBERT T, 1980, ELECTROEN CLIN NEURO, V48, P293, DOI 10.1016/0013-4694(80)90265-5; Fukumizu K, 1996, ADV NEUR IN, V8, P295; Fukunaga K., 1990, INTRO STAT PATTERN R; Haynes JD, 2006, NAT REV NEUROSCI, V7, P523, DOI 10.1038/nrn1931; Kohlmorgen J., 2007, BRAIN COMPUTER INTER, P409; Krauledat M., 2007, BRAIN COMPUTER INTER, P207; Krauledat M, 2007, ADV NEURAL INFORM PR, V19, P753; Krausz G, 2003, APPL PSYCHOPHYS BIOF, V28, P233, DOI 10.1023/A:1024637331493; Krepki R, 2007, INT J HUM-COMPUT ST, V65, P460, DOI 10.1016/j.ijhcs.2006.11.010; Kubler A, 2001, PSYCHOL BULL, V127, P358, DOI 10.1037//0033-2909.127.3.358; Kubler A., 2007, BRAIN COMPUTER INTER, P1; Lal TN, 2004, IEEE T BIO-MED ENG, V51, P1003, DOI 10.1109/TBME.2004.827827; Lemm S, 2005, IEEE T BIO-MED ENG, V52, P1541, DOI 10.1109/TBME.2005.851521; McFarland DJ, 2003, BIOL PSYCHOL, V63, P237, DOI 10.1016/S0301-0511(03)00073-5; MULLER KR, 1995, NOLTA 95 LAS VEG S N, P223; Muller K.-R., 2006, IEEE SIGNAL PROCESSI, V23, P125; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Muller KR, 2003, IEEE T NEUR SYS REH, V11, P165, DOI 10.1109/TNSRE.2003.814484; Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8; Ramoser H, 2000, IEEE T REHABIL ENG, V8, P441, DOI 10.1109/86.895946; ROCKSTROH B, 1984, BIOFEEDBACK SELF-REG, V9, P139, DOI 10.1007/BF00998830; Scholkopf B., 2002, LEARNING KERNELS; SUGIYAMA S, 2005, STAT DEC, V23, P249; TOMIOKA R, ADV NEURAL INF P SYS, V19, P1377; Tomioka R., 2006, P WORKSH INF BAS IND, P65; Vapnik V. N, 1995, NATURE STAT LEARNING; Williamson J, 2005, LECT NOTES COMPUT SC, V3355, P333; Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3	45	76	77	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0270		J NEUROSCI METH	J. Neurosci. Methods	JAN 15	2008	167	1					82	90		10.1016/j.jneumeth.2007.09.022		9	Biochemical Research Methods; Neurosciences	Biochemistry & Molecular Biology; Neurosciences & Neurology	248OU	WOS:000252164300009	
J	Hoffmann, U; Vesin, JM; Ebrahimi, T; Diserens, K				Hoffmann, Ulrich; Vesin, Jean-Marc; Ebrahimi, Touradj; Diserens, Karin			An efficient P300-based brain-computer interface for disabled subjects	JOURNAL OF NEUROSCIENCE METHODS			English	Article						brain-computer interface; P300; disabled subjects; Fisher's linear discriminant analysis; Bayesian linear discriminant analysis	BCI COMPETITION 2003; DATA SET IIB; DISCRIMINANT-ANALYSIS; P300 SPELLER; POTENTIALS; CLASSIFICATION; COMMUNICATION; EEG; ALS	A brain-computer interface (130) is a communication system that translates brain-activity into commands for a computer or other devices. In other words, a BCI allows users to act on their environment by using only brain-activity, without using peripheral nerves and muscles. In this paper, we present a BCI that achieves high classification accuracy and high bitrates for both disabled and able-bodied subjects. The system is based on the P300 evoked potential and is tested with five severely disabled and four able-bodied subjects. For four of the disabled subjects classification accuracies of 100% are obtained. The bitrates obtained for the disabled subjects range between 10 and 25 bits/min. The effect of different electrode configurations and machine learning algorithms on classification accuracy is tested. Further factors that are possibly important for obtaining good classification accuracy in P300-based BCI systems for disabled subjects are discussed. (C) 2007 Elsevier B.V. All rights reserved.	[Hoffmann, Ulrich; Vesin, Jean-Marc; Ebrahimi, Touradj] Ecole Polytech Fed Lausanne, Signal Proc Inst, CH-1015 Lausanne, Switzerland; [Diserens, Karin] CHU Vaudois, CH-1011 Lausanne, Switzerland	Hoffmann, U (reprint author), Ecole Polytech Fed Lausanne, Signal Proc Inst, CH-1015 Lausanne, Switzerland.	ulrich.hoffmann@epfl.ch					Bayliss JD, 2003, IEEE T NEUR SYS REH, V11, P113, DOI 10.1109/TNSRE.2003.814438; Birbaumer N, 1999, NATURE, V398, P297, DOI 10.1038/18581; Bishop C. M., 2006, PATTERN RECOGNITION; Bostanov V, 2004, IEEE T BIO-MED ENG, V51, P1057, DOI 10.1109/TBME.2004.826702; SUTTON S, 1965, SCIENCE, V150, P1187, DOI 10.1126/science.150.3700.1187; Carrillo-de-la-Pena MT, 2000, NEUROPHYSIOL CLIN, V30, P232, DOI 10.1016/S0987-7053(00)00220-3; Centeno TP, 2006, J MACH LEARN RES, V7, P455; DUNCANJOHNSON CC, 1977, PSYCHOPHYSIOLOGY, V14, P456, DOI 10.1111/j.1469-8986.1977.tb01312.x; FARWELL LA, 1988, ELECTROEN CLIN NEURO, V70, P510, DOI 10.1016/0013-4694(88)90149-6; Hill NJ, 2006, IEEE T NEUR SYS REH, V14, P183, DOI 10.1109/TNSRE.2006.875548; HOFFMANN U, 2004, P IEEE ENG MED BIOL; Hoffmann U., 2006, P 14 EUR S ART NEUR; HOFFMANN U, 2005, P IEEE EMBS NEUR ENG; Kaper M, 2004, IEEE T BIO-MED ENG, V51, P1073, DOI 10.1109/TBME.2004.826698; KAPER M, 2006, THESIS U BIELEFELD G; Krusienski DJ, 2006, J NEURAL ENG, V3, P299, DOI 10.1088/1741-2560/3/4/007; Kubler A, 2005, NEUROLOGY, V64, P1775, DOI 10.1212/01.WNL.0000158616.43002.6D; Lebedev MA, 2006, TRENDS NEUROSCI, V29, P536, DOI 10.1016/j.tins.2006.07.004; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.415; Pfurtscheller G, 2001, P IEEE, V89, P1123, DOI 10.1109/5.939829; Piccione F, 2006, CLIN NEUROPHYSIOL, V117, P531, DOI 10.1016/j.clinph.2005.07.024; POLIKOFF J, 1995, P RESNA 95 ANN C; POSNER MI, 1990, ANNU REV NEUROSCI, V13, P25, DOI 10.1146/annurev.neuro.13.1.25; RAKOTOMAMONJY A, 2005, P INT C NEUR NETW IC; Sellers EW, 2006, CLIN NEUROPHYSIOL, V117, P538, DOI 10.1016/j.clinph.2005.06.027; Serby H, 2005, IEEE T NEUR SYS REH, V13, P89, DOI 10.1109/TNSRE.2004.841878; Thulasidas M, 2006, IEEE T NEUR SYS REH, V14, P24, DOI 10.1109/TNSRE.2005.862695; TIAN Q, 1988, J OPT SOC AM A, V5, P1670, DOI 10.1364/JOSAA.5.001670; Van Gestel T, 2002, NEURAL COMPUT, V14, P1115; Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3; Xu N, 2004, IEEE T BIO-MED ENG, V51, P1067, DOI 10.1109/TBME.2004.826699	31	117	128	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0270		J NEUROSCI METH	J. Neurosci. Methods	JAN 15	2008	167	1					115	125		10.1016/j.jneumeth.2007.03.005		11	Biochemical Research Methods; Neurosciences	Biochemistry & Molecular Biology; Neurosciences & Neurology	248OU	WOS:000252164300012	
J	Vincent, M; Passerini, A; Labbe, M; Frasconi, P				Vincent, Marc; Passerini, Andrea; Labbe, Matthieu; Frasconi, Paolo			A simplified approach to disulfide connectivity prediction from protein sequences	BMC BIOINFORMATICS			English	Article							RECURSIVE NEURAL-NETWORKS; BONDING STATE; EVOLUTIONARY INFORMATION; CYSTEINES; CLASSIFICATION; SELECTION; MACHINES; SERVER	Background: Prediction of disulfide bridges from protein sequences is useful for characterizing structural and functional properties of proteins. Several methods based on different machine learning algorithms have been applied to solve this problem and public domain prediction services exist. These methods are however still potentially subject to significant improvements both in terms of prediction accuracy and overall architectural complexity. Results: We introduce new methods for predicting disulfide bridges from protein sequences. The methods take advantage of two new decomposition kernels for measuring the similarity between protein sequences according to the amino acid environments around cysteines. Disulfide connectivity is predicted in two passes. First, a binary classifier is trained to predict whether a given protein chain has at least one intra-chain disulfide bridge. Second, a multiclass classifier (plemented by I-nearest neighbor) is trained to predict connectivity patterns. The two passes can be easily cascaded to obtain connectivity prediction from sequence alone. We report an extensive experimental comparison on several data sets that have been previously employed in the literature to assess the accuracy of cysteine bonding state and disulfide connectivity predictors. Conclusion: We reach state-of-the-art results on bonding state prediction with a simple method that classifies chains rather than individual residues. The prediction accuracy reached by our connectivity prediction method compares favorably with respect to all but the most complex other approaches. On the other hand, our method does not need any model selection or hyperparameter tuning, a property that makes it less prone to overfitting and prediction accuracy overestimation.	[Vincent, Marc; Passerini, Andrea; Labbe, Matthieu; Frasconi, Paolo] Univ Florence, Dipartimento Sistemi & Informat, Machine Learning & Neural Networks Grp, I-50139 Florence, Italy	Frasconi, P (reprint author), Univ Florence, Dipartimento Sistemi & Informat, Machine Learning & Neural Networks Grp, Via Santa Marta 3, I-50139 Florence, Italy.	vincent@dsi.unifi.it; passerini@dsi.unifi.it; labbe@dsi.unifi.it; pf@dsi.unifi.it	Frasconi, Paolo/G-2944-2010				Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Ceroni A, 2006, NUCLEIC ACIDS RES, V34, pW177, DOI 10.1093/nar/gkl266; Ceroni A, 2003, J VLSI SIG PROC SYST, V35, P287, DOI 10.1023/B:VLSI.0000003026.58068.ce; Chen BJ, 2006, PROTEINS, V64, P246, DOI 10.1002/prot.20972; Chen YC, 2004, PROTEINS, V55, P1036, DOI 10.1002/prot.20079; Chen YC, 2005, PROTEINS, V61, P507, DOI 10.1002/prot.20627; CHENG J, 2005, NUCLEIC ACIDS RES, pW72; Cheng JL, 2006, PROTEINS, V62, P617, DOI 10.1002/prot.20787; Fariselli P, 2001, BIOINFORMATICS, V17, P957, DOI 10.1093/bioinformatics/17.10.957; Ferre F, 2005, BIOINFORMATICS, V21, P2336, DOI 10.1093/bioinformatics/bti328; Ferre F, 2006, NUCLEIC ACIDS RES, V34, pW182, DOI 10.1093/nar/gkl189; Fiser A, 2000, BIOINFORMATICS, V16, P251, DOI 10.1093/bioinformatics/16.3.251; FISER A, 1992, FEBS LETT, V302, P117, DOI 10.1016/0014-5793(92)80419-H; Fariselli P, 1999, PROTEINS, V36, P340, DOI 10.1002/(SICI)1097-0134(19990815)36:3<340::AID-PROT8>3.0.CO;2-D; Gold C, 2003, NEUROCOMPUTING, V55, P221, DOI 10.1016/S0925-2312(03)00375-8; Haussler D., 1999, UCSCCRL9910; HOBOHM U, 1992, PROTEIN SCI, V1, P409; HOBOHM U, 1994, PROTEIN SCI, V3, P522; HOBOHM U, 1983, BIOPOLYMERS, V22, P2577; Joachims T., 1999, ADV KERNEL METHODS S; Lu CH, 2007, PROTEINS, V67, P262, DOI 10.1002/prot.21309; Martelli PL, 2004, PROTEOMICS, V4, P1665, DOI 10.1002/pmic.200300745; Mucchielli-Giorgi MHM, 2002, PROTEINS, V46, P243, DOI 10.1002/prot.10047; Platt J., 1999, ADV LARGE MARGIN CLA; Song JN, 2004, BIOCHEM BIOPH RES CO, V318, P142, DOI 10.1016/j.bbrc.2004.03.189; Taskar B., 2005, P 22 INT C MACH LEAR; Tsai CH, 2005, BIOINFORMATICS, V21, P4416, DOI 10.1093/bioinformatics/bti715; Vullo A, 2004, BIOINFORMATICS, V20, P653, DOI 10.1093/bioinformatics/btg463; Zhao E, 2005, BIOINFORMATICS, V21, P1415, DOI 10.1093/bioinformatics/bti179; DLPRO; CYSPRED; PDBSELECT	32	6	6	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	JAN 14	2008	9								20	10.1186/1471-2105-9-20		11	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	280OF	WOS:000254435400001	
J	Sebastiani, P; Zhao, Z; Abad-Grau, MM; Riva, A; Hartley, SW; Sedgewick, AE; Doria, A; Montano, M; Melista, E; Terry, D; Perls, TT; Steinberg, MH; Baldwin, CT				Sebastiani, Paola; Zhao, Zhenming; Abad-Grau, Maria M.; Riva, Alberto; Hartley, Stephen W.; Sedgewick, Amanda E.; Doria, Alessandro; Montano, Monty; Melista, Efthymia; Terry, Dellara; Perls, Thomas T.; Steinberg, Martin H.; Baldwin, Clinton T.			A hierarchical and modular approach to the discovery of robust associations in genome-wide association studies from pooled DNA samples	BMC GENETICS			English	Article							SICKLE-CELL-ANEMIA; G-CSF; MYOCARDIAL-INFARCTION; EXCEPTIONAL LONGEVITY; FETAL-HEMOGLOBIN; KSNP MICROARRAYS; IDENTIFICATION; DISEASE; DETERMINANTS; MOBILIZATION	Background: One of the challenges of the analysis of pooling-based genome wide association studies is to identify authentic associations among potentially thousands of false positive associations. Results: We present a hierarchical and modular approach to the analysis of genome wide genotype data that incorporates quality control, linkage disequilibrium, physical distance and gene ontology to identify authentic associations among those found by statistical association tests. The method is developed for the allelic association analysis of pooled DNA samples, but it can be easily generalized to the analysis of individually genotyped samples. We evaluate the approach using data sets from diverse genome wide association studies including fetal hemoglobin levels in sickle cell anemia and a sample of centenarians and show that the approach is highly reproducible and allows for discovery at different levels of synthesis. Conclusion: Results from the integration of Bayesian tests and other machine learning techniques with linkage disequilibrium data suggest that we do not need to use too stringent thresholds to reduce the number of false positive associations. This method yields increased power even with relatively small samples. In fact, our evaluation shows that the method can reach almost 70% sensitivity with samples of only 100 subjects.	[Sebastiani, Paola; Zhao, Zhenming; Hartley, Stephen W.] Boston Univ, Sch Publ Hlth, Dept Biostat, Boston, MA 02118 USA; [Abad-Grau, Maria M.] Univ Granada, Dept Software Engn, E-18071 Granada, Spain; [Riva, Alberto] Univ Florida, Dept Mol Genet, Gainesville, FL 32611 USA; [Sedgewick, Amanda E.] Boston Univ, Sch Engn, Bioinformat Program, Boston, MA 02116 USA; [Doria, Alessandro] Harvard Univ, Sch Med, Joslin Diabet Ctr, Boston, MA 02215 USA; [Montano, Monty; Melista, Efthymia; Steinberg, Martin H.; Baldwin, Clinton T.] Boston Univ, Sch Med, Dept Med, Boston, MA 02118 USA; [Terry, Dellara; Perls, Thomas T.] Boston Univ, Med Ctr, Geriatr Sect, Boston, MA 02118 USA	Sebastiani, P (reprint author), Boston Univ, Sch Publ Hlth, Dept Biostat, Boston, MA 02118 USA.	sebas@bu.edu; zmzhao@bu.edu; mabad@ugr.es; ariva@ufl.edu; shartley@bu.edu; asedge@bu.edu; Alessandro.Doria@joslin.harvard.edu; mmontano@bu.edu; emelista@bu.edu; laterry@bu.edu; thperls@bu.edu; mhsteinb@bu.edu; cbaldwin@bu.edu	Abad-Grau, Maria Mar/B-2172-2012	Abad-Grau, Maria Mar/0000-0001-8470-9719			Arking R, 2003, J ANTI-AGING MED, V6, P91, DOI 10.1089/109454503769684775; Aulchenko YS, 2007, BIOINFORMATICS, V23, P1294, DOI 10.1093/bioinformatics/btm108; Balding DJ, 2006, NAT REV GENET, V7, P781, DOI 10.1038/nrg1916; Barratt BJ, 2002, ANN HUM GENET, V66, P393, DOI 10.1017/S0003480002001252; Barzilai N, 2003, JAMA-J AM MED ASSOC, V290, P2030, DOI 10.1001/jama.290.15.2030; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Capoccia BJ, 2006, BLOOD, V108, P2438, DOI 10.1182/blood-2006-04-013755; Christensen K, 2007, NEW ENGL J MED, V356, P1094, DOI 10.1056/NEJMp068126; Christensen K, 2006, NAT REV GENET, V7, P436, DOI 10.1038/nrg1871; Clayton D, 2007, HUM HERED, V64, P45, DOI 10.1159/000101422; Craig DW, 2005, BMC GENOMICS, V6, DOI 10.1186/1471-2164-6-138; de Bakker PIW, 2005, NAT GENET, V37, P1217, DOI 10.1038/ng1669; Docherty SJ, 2007, BMC GENOMICS, V8, DOI 10.1186/1471-2164-8-214; ELSTON RC, 2007, ANN REV GENOMICS HUM; Fan JB, 2006, NAT REV GENET, V7, P632, DOI 10.1038/nrg1901; Gao YJ, 2000, NATURE, V404, P897, DOI 10.1038/35009138; Harris MA, 2006, NUCLEIC ACIDS RES, V34, pD322, DOI 10.1093/nar/gkj021; Hanson RL, 2007, DIABETES, V56, P975, DOI 10.2337/db06-1072; Harada M, 2005, NAT MED, V11, P305, DOI 10.1038/nm1199; Hosack DA, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-10-r70; Gibbs RA, 2003, NATURE, V426, P789, DOI 10.1038/nature02168; Altshuler D, 2005, NATURE, V437, P1299, DOI 10.1038/nature04226; Kanehisa M, 2000, NUCLEIC ACIDS RES, V28, P27, DOI 10.1093/nar/28.1.27; Kanehisa M, 2006, NUCLEIC ACIDS RES, V34, pD354, DOI 10.1093/nar/gkj102; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.2307/2291091; Lavebratt C, 2006, NAT PROTOC, V1, P2573, DOI 10.1038/nprot.2006.442; Leone AM, 2006, INT J CARDIOL, V111, P202, DOI 10.1016/j.ijcard.2005.06.043; Levesque JP, 2003, J CLIN INVEST, V111, P187, DOI 10.1172/JCI200315994; Lips EH, 2005, CANCER RES, V65, P10188, DOI 10.1158/0008-5472.CAN-05-2486; Lombard DB, 2000, MOL CELL BIOL, V20, P3286, DOI 10.1128/MCB.20.9.3286-3291.2000; MA Q, 2007, HUM MOL GENET; Meaburn E, 2006, NUCLEIC ACIDS RES, V34, DOI 10.1093/nar/gnj027; MEABURN EL, 2007, MOL PSYCHIAT; Melquist S, 2007, AM J HUM GENET, V80, P769, DOI 10.1086/513320; Niedernhofer LJ, 2006, NATURE, V444, P1038, DOI 10.1038/nature05456; Perls T, 2003, ANN INTERN MED, V139, P445; Petit I, 2002, NAT IMMUNOL, V3, P687, DOI 10.1038/ni813; Purcell S, 2007, AM J HUM GENET, V81, P559, DOI 10.1086/519795; Riva A, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-33; Roeder K, 2006, AM J HUM GENET, V78, P243, DOI 10.1086/500026; Sebastiani P, 2007, BMC GENET, V8, DOI 10.1186/1471-2156-8-36; Sebastiani P, 2005, NAT GENET, V37, P435, DOI 10.1038/ng1533; Sebastiani P, 2007, BLOOD, V110, P2727, DOI 10.1182/blood-2007-04-084921; Sham P, 2002, NAT REV GENET, V3, P862, DOI 10.1038/nrg930; Steer S, 2007, GENES IMMUN, V8, P57, DOI 10.1038/sj.gene.6364359; Steinberg MH, 2003, JAMA-J AM MED ASSOC, V289, P1645, DOI 10.1001/jama.289.13.1645; Steinberg MH, 1997, BLOOD, V89, P1078; Steinberg MH, 2005, BRIT J HAEMATOL, V129, P465, DOI 10.1111/j.1365-2141.2005.05411.x; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Wilkening S, 2007, BMC GENOMICS, V8, DOI 10.1186/1471-2164-8-77; Burton PR, 2007, NATURE, V447, P661, DOI 10.1038/nature05911; Wyszynski DF, 2004, CELL MOL BIOL, V50, P23; Zou GH, 2004, GENET EPIDEMIOL, V26, P1, DOI 10.1002/gepi.10277; [Anonymous], SUPPLEMENTARY MAT; HUMAN AGING GENOMIC	55	13	15	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2156		BMC GENET	BMC Genet.	JAN 14	2008	9								6	10.1186/1471-2156-9-6		14	Genetics & Heredity	Genetics & Heredity	265YI	WOS:000253397400001	
J	Archer, KJ; Kirnes, RV				Archer, Kelfie J.; Kirnes, Ryan V.			Empirical characterization of random forest variable importance measures	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article						random forest; classification tree; variable importance; bootstrap aggregating	CLASSIFICATION TREES; SPLIT SELECTION; LEUKEMIA; MECHANISMS; SUBSETS; MACHINE; BIAS	Microarray studies yield data sets consisting of a large number of candidate predictors (genes) on a small number of observations (samples). When interest lies in predicting phenotypic class using gene expression data, often the goals are both to produce an accurate classifier and to uncover the predictive structure of the problem. Most machine learning methods, such as k-nearest neighbors, support vector machines, and neural networks, are useful for classification. However, these methods provide no insight regarding the covariates that best contribute to the predictive structure. Other methods, such as linear discriminant analysis, require the predictor space be substantially reduced prior to deriving the classifier. A recently developed method, random forests (RF), does not require reduction of the predictor space prior to classification. Additionally, RF yield variable importance measures for each candidate predictor. This study examined the effectiveness of RF variable importance measures in identifying the true predictor among a large number of candidate predictors. An extensive simulation study was conducted using 20 levels of correlation among the predictor variables and 7 levels of association between the true predictor and the dichotomous response. We conclude that the RF methodology is attractive for use in classification problems when the goals of the study are to produce an accurate classifier and to provide insight regarding the discriminative ability of individual predictor variables. Such goals are common among microarray studies, and therefore application of the RF methodology for the purpose of obtaining variable importance measures is demonstrated on a microarray data set.. (c) 2007 Elsevier B.V. All rights reserved.	[Archer, Kelfie J.; Kirnes, Ryan V.] Virginia Commonwealth Univ, Dept Biostat, Richmond, VA 23298 USA	Archer, KJ (reprint author), Virginia Commonwealth Univ, Dept Biostat, 1101 E Marshall St,B1-066, Richmond, VA 23298 USA.	kjarcher@vcu.edu					Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 2003, MANUAL SETTING USING; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, ANN STAT, V24, P2350; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; BRIEM GJ, 2001, P INT WORKSH MULT CL, P279; Bryll R, 2003, PATTERN RECOGN, V36, P1291, DOI 10.1016/S0031-3203(02)00121-8; Bureau A, 2005, GENET EPIDEMIOL, V28, P171, DOI 10.1002/gepi.20041; Bylander T, 2002, MACH LEARN, V48, P287, DOI 10.1023/A:1013964023376; Chiaretti S, 2004, BLOOD, V103, P2771, DOI 10.1182/blood-2003-09-3243; Chiaretti S, 2005, CLIN CANCER RES, V11, P7209, DOI 10.1158/1078-0432.CCR-04-2165; Cummings MP, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-132; Dadi HK, 2003, NEW ENGL J MED, V349, P1821, DOI 10.1056/NEJMoa031178; Diaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3; Dietterich TG, 1997, AI MAG, V18, P97; Gentleman R, 2005, BIOINFORMATICS COMPU; Gentleman RC, 2004, P COMPSTAT, P171; Gentleman RC, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-10-r80; Harrell F. E., 2005, DESIGN DESIGN PACKAG; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Hothorn T, 2006, J COMPUT GRAPH STAT, V15, P651, DOI 10.1198/106186006X133933; Hothorn T, 2003, ARTIF INTELL MED, V27, P65, DOI 10.1016/S0933-3657(02)00085-4; Jiang HY, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-81; Kumar L, 2005, P NATL ACAD SCI USA, V102, P19063, DOI 10.1073/pnas.0509176102; Lausen B, 2004, BIOMETRICAL J, V46, P364, DOI 10.1002/bimj.200310030; Liaw A., 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; Meyer D, 2003, NEUROCOMPUTING, V55, P169, DOI 10.1016/S0925-2312(03)00431-4; Peters J., 2005, Communications in Agricultural and Applied Biological Sciences, V70, P207; Pui C, 2004, NEW ENGL J MED, V350, P1535, DOI 10.1056/NEJMra023001; R DEVELOPMENT CORE TEAM, 2005, R LANG ENV STAT COMP; Shih YS, 2004, COMPUT STAT DATA AN, V45, P457, DOI 10.1016/S0167-9473(03)00064-1; Skurichina M., 2001, Multiple Classifier Systems. Second International Workshop, MCS 2001. Proceedings (Lecture Notes in Computer Science Vol.2096); Strobl C, 2007, COMPUT STAT DATA AN, V52, P483, DOI 10.1016/j.csda.2006.12.030; Strobl C, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-25; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g	36	61	62	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473		COMPUT STAT DATA AN	Comput. Stat. Data Anal.	JAN 10	2008	52	4					2249	2260		10.1016/j.csda.2007.08.015		12	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	264JL	WOS:000253283500033	
J	Lopez, A				Lopez, Adam			Statistical machine translation	ACM COMPUTING SURVEYS			English	Review						algorithms; natural language processing; machine translation	MODELS; ALGORITHM	Statistical machine translation (SMT) treats the translation of natural language as a machine learning problem. By examining many samples of human-produced translation, SMT algorithms automatically learn how to translate. SMT has made tremendous strides in less than two decades, and new ideas are constantly introduced. This survey presents a tutorial overview of the state of the art. We describe the context of the current research and then move to a formal problem description and an overview of the main subproblems: translation modeling, parameter estimation, and decoding. Along the way, we present a taxonomy of some different approaches within these areas. We conclude with an overview of evaluation and a discussion of future directions.	Univ Edinburgh, Dept Informat, Edinburgh EH8 9AB, Midlothian, Scotland	Lopez, A (reprint author), Univ Edinburgh, Dept Informat, 10 Crichton St, Edinburgh EH8 9AB, Midlothian, Scotland.	alopez@inf.ed.ac.uk					Aho A. V., 1969, J COMPUTER SYSTEM SC, V3, P37, DOI 10.1016/S0022-0000(69)80006-1; AHRENBERG L, 2000, P 2 INT C LING RES E, V3, P1255; Albrecht Joshua, 2007, P ASS COMP LING ACL, P296; Al-Onaizan Y., 1999, STAT MACHINE TRANSLA; Al-Onaizan Y., 2006, P 21 INT C COMP LING, P529, DOI 10.3115/1220175.1220242; Alshawi H, 2000, COMPUT LINGUIST, V26, P45, DOI 10.1162/089120100561629; Ayan N.F., 2005, P HLT EMNLP, P65, DOI 10.3115/1220575.1220584; AYAN NF, 2005, P HLT EMNLP, P185, DOI 10.3115/1220575.1220599; AYAN NF, 2006, P ACL COLING, P9, DOI 10.3115/1220175.1220177; AYAN NF, 2005, P HLT NAACL, P96, DOI 10.3115/1220835.1220848; BANCHS RE, 2005, P ACL WORKSH BUILD U, P133, DOI 10.3115/1654449.1654478; Bannard C, 2005, P 43 ANN M ASS COMP, P597, DOI 10.3115/1219840.1219914; Baum L. E., 1972, INEQUALITIES, V3, P1; Berger A., 1996, U.S. patent, Patent No. [5,510,981, 5510981]; Berger AL, 1994, P ARPA WORKSH HUM LA, P157, DOI 10.3115/1075812.1075844; Berglund B, 1996, ENVIRON INT, V22, P1, DOI 10.1016/0160-4120(95)00098-4; BIRCH A, 2006, P HLT NAACL WORKSH S, P154, DOI 10.3115/1654650.1654675; BLUNSOM P, 2006, P COLING ACL, P65, DOI 10.3115/1220175.1220184; Brants T., 2007, P 2007 JOINT C EMP M, P858; Brown P. F., 1993, Computational Linguistics, V19; Brown P. F., 1992, Computational Linguistics, V18; BURBANK A, 2005, 2005 LANG ENG WORKSH; Callison- Burch C., 2005, P ACL, P255, DOI 10.3115/1219840.1219872; Callison-Burch C., 2006, P 11 C EUR CHAPT ASS, P249; Callison-Burch C., 2007, P 2 WORKSH STAT MACH, P136, DOI 10.3115/1626355.1626373; CALLISONBURCH C, 2006, P HLT NAACL; CALLISONBURCH C, 2004, P ASS COMP LING ACL, P176; CARPUAT M, 2005, P 43 ANN M ASS COMP, P387, DOI 10.3115/1219840.1219888; Carpuat M., 2007, P JOINT C EMP METH N, P61; Chan Y., 2007, P 45 ANN M ASS COMP, P33; CHARNIAK E, 2003, P MT SUMM 9; Chelba C., 1998, P 36 ANN M ASS COMP, P225; Chen SF, 1998, TR1098 HARV U COMP S; CHERRY C, 2003, P ASS COMP LING ACL; Chiang D., 2007, P ASS COMP LING ACL, P144; CHIANG D, 2007, COMPUT LINGUIST, V33; CHIANG D, 2006, INTRO SYNCHRONOUS GR; Chiang D., 2005, P HUM LANG TECHN C C, P779, DOI 10.3115/1220575.1220673; Chiang David, 2005, P 43 ANN M ASS COMP, P263, DOI 10.3115/1219840.1219873; Church K, 1982, COMPUTATIONAL LINGUI, V8, P139; Church K. W., 1993, Machine Translation, V8, DOI 10.1007/BF00981759; Collins Michael, 1999, P 37 ANN M ASS COMP, P505, DOI 10.3115/1034678.1034754; DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379; Dejean H, 2003, P HLT NAACL 2003 WOR, P23; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DENEEFE S, 2005, P ASS COMP LING ACL, V97; DENERO J, 2006, P HLT NAACL WORKSH S, P31, DOI 10.3115/1654650.1654656; DENERO J, 2007, P ASS COMP LING ACL, P17; Devonshire A. F., 1951, THESIS U MARYLAND, V42, P1065; DODDINGTON G, 2002, P HUM LANG TECHN C H; Dorr BJ, 1999, ADV COMPUT, V49, P1, DOI 10.1016/S0065-2458(08)60282-X; ECK M, 2004, P INT C LANG RES EV; FEDERICO M, 2006, P NAACL WORKSH STAT, P94, DOI 10.3115/1654650.1654664; FOSTER G, 2006, P EMNLP, P53, DOI 10.3115/1610075.1610084; Fox HJ, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P304; FRASER A, 2006, P COLING ACL, P769, DOI 10.3115/1220175.1220272; FRASER A, 2007, COMPUT LINGUIST, V33; Fraser A, 2007, P JOINT C EMP METH N, P51; Gale WA, 1991, P 4 DARPA SPEECH NAT, P152, DOI 10.3115/112405.112428; GALEF D, 1993, VERBATIM, V19, P1; Galley M., 2004, P HLT NAACL, P273; Galley Michel, 2006, P 21 INT C COMP LING, P961, DOI 10.3115/1220175.1220296; GERMANN U, 2003, P HLT NAACL, P72; Germann U, 2004, ARTIF INTELL, V154, P127, DOI 10.1016/j.artint.2003.06.001; GERMANN U, 2001, P ACL EACL; GILDEA D, 2004, P EMNLP, P214; Goldwater Sharon, 2005, P HUM LANG TECHN C C, P676, DOI 10.3115/1220575.1220660; Graehl J., 2004, P HUM LANG TECHN C N, P105; Hopcroft J., 1979, INTRO AUTOMATA THEOR; Hovy E., 2002, Machine Translation, V17, DOI 10.1023/A:1025510524115; Huang L., 2005, P 9 INT WORKSH PARS, P53, DOI 10.3115/1654494.1654500; Hutchins J., 2007, COMPUTER AIDED TRANS; Hwa R., 2005, Natural Language Engineering, DOI 10.1017/S1351324905003840; ITTYCHERIAH A, 2005, P HLT EMNLP, P89, DOI 10.3115/1220575.1220587; Brown P. F., 1990, Computational Linguistics, V16; Jelinek F., 1998, STAT METHODS SPEECH; JELINEK F, 1969, RC2441 IBM RES CTR; JOHNSON H, 2007, P EMNLP CONLL, P967; Joshi A.K., 1997, HDB FORMAL LANGUAGES, V3, P69; JOSHI AK, 1991, FDN ISSUES NATURAL L, V2, P31; Jurafsky D., 2008, SPEECH LANGUAGE PROC; KIRCHHOFF K, 2005, P ACL WORKSH BUILD U, P125, DOI 10.3115/1654449.1654476; KNIGHT K, 1999, STAT MT TUTORI UNPUB; Knight K, 1999, COMPUT LINGUIST, V25, P607; Knight K, 1997, AI MAG, V18, P81; KNIGHT K, 2005, P ICASSP; Knight K., 1998, P AMTA C LANGH PA US, P421; Knight Kevin, 2005, P CICLING; KOEHN P, 2005, P ACL WORKSH BUILD U, P119, DOI 10.3115/1654449.1654474; Koehn P., 2007, P 2007 JOINT C EMP M, P737; KOEHN P, 2007, STAT MACHIN IN PRESS; Koehn P., 2003, P HLT NAACL, P127; Koehn P., 2007, P JOINT C EMP METH N, P868; KOEHN P, 2004, P C ASS MACH TRANSL; Koehn P, 2006, P WORKSH STAT MACH T, P102, DOI 10.3115/1654650.1654666; Koehn P., 2004, P 2004 C EMP METH NA, P388; Koehn P., 2004, PHARAOH BEAM SEARCH; Koehn P., 2007, P 45 ANN M ASS COMP, P177, DOI 10.3115/1557769.1557821; Koehn P., 2005, P MT SUMM; Kucerova I., 2005, P 43 ANN M ASS COMP, P531, DOI 10.3115/1219840.1219906; KULESZA A, 2004, P INT C THEOR METH I; Kumar S., 2005, NAT LANG ENG, V12, P35; Kumar S., 2004, P HLT NAACL, P169; LARI K, 1990, COMPUT SPEECH LANG, V4; LEWIS PM, 1968, J ACM, V15, P465, DOI 10.1145/321466.321477; Liang P., 2006, P HLT NAACL, P104, DOI 10.3115/1220835.1220849; Liang P., 2006, P ACL COLING, P761, DOI 10.3115/1220175.1220271; Lin C.-Y., 2004, P 42 ANN M ACL, P606; Lita L.V., 2005, P HUM LANG TECHN C C, P740, DOI 10.3115/1220575.1220668; Liu D., 2007, P HLT NAACL, P41; Lopez A., 2007, P EMNLP CONLL, P976; LOPEZ A, 2005, P ACL WORKSH BUILD U, P83, DOI 10.3115/1654449.1654464; LOPEZ A, 2006, P 7 C ASS MACH TRANS, P90; Manning C. D., 1999, FDN STAT NATURAL LAN; Marcu D., 2006, P 2006 C EMP METH NA, P44, DOI 10.3115/1610075.1610083; Marcu D, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P133; MARCUS MP, 1993, COMPUT LINGUIST, V19, P314; Matusov E., 2004, P 20 INT C COMP LING, P219, DOI 10.3115/1220355.1220387; MELAMED I, 1998, 9807 U PENNS I RES C; MELAMED ID, 2004, P THEOR METH ISS MAC; MELAMED ID, 2004, P ASS COMP LING ACL, P662; MELAMED ID, 1996, P C ASS MACH TRANSL; MELAMED ID, 2004, P ASS COMP LING ACL, P654; MELAMED ID, 2003, P HLT NAACL 2003 EDM, P61; Melamed ID, 2000, COMPUT LINGUIST, V26, P221, DOI 10.1162/089120100561683; MELAMED ID, 2003, P NAACL HLT 2003 EDM, P79; Merialdo B., 1994, Computational Linguistics, V20; Mihalcea R., 2003, P HLT NAACL 2003 WOR, P1; MINKOV E, 2007, P 45 ANN M ASS COMP, P128; Mitchell T, 1997, MACHINE LEARNING; MOORE P, 2005, LASER SURG MED, V1, P8; MOORE RC, 2004, P ASS COMP LING ACL, P519; Moore Robert C., 2005, P HUM LANG TECHN C C, P81, DOI 10.3115/1220575.1220586; NIESSEN S, 2004, COMPUT LINGUIST, V30, P182; NIESSEN S, 1998, P 36 ANN M ASS COMP, P960; OARD DW, 2003, P HLT NAACL C LAT BR, P76; OARD DW, 2003, P MT SUMM 9; Och F., 2004, P HUM LANG TECHN C H, P161; Och F. J., 1999, P JOINT SIGDAT C EMP, P20; Och F. J., 2000, P 18 INT C COMP LING, P1086; Och F. J., 2003, Computational Linguistics, V29, DOI 10.1162/089120103321337421; OCH FJ, 2002, P ASS COMP LING ACL, P156; OCH FJ, 2005, P ACL WORKSH BUILD U; Och F.J, 1999, P 9 C EUR CHAPT ASS, P71, DOI 10.3115/977035.977046; Och FJ, 2004, COMPUT LINGUIST, V30, P417, DOI 10.1162/0891201042544884; OCH FJ, 2001, P DAT DRIV MACH TRAN, P55; OCH FJ, 2001, P MT SUMM; OCH FJ, 2003, P ASS COMP LING ACL; OCH FJ, 2004, J HOPK 2003 SUMM WOR; OLTEANU M, 2006, P HLT NAACL WORKSH S, P146, DOI 10.3115/1654650.1654673; Papineni K., 2002, P 40 ANN M ASS COMP, P311; Popovic M., 2006, P WORKSH STAT MACH T, P1, DOI 10.3115/1654650.1654652; Quirk C., 2005, P 43 ANN M ASS COMP, P271, DOI 10.3115/1219840.1219874; Ratnaparkhi A., 1998, THESIS U PENNSYLVANI; Resnik P, 2003, COMPUT LINGUIST, V29, P349, DOI 10.1162/089120103322711578; RESNIK P, 1997, P TEXT ENC IN 10 ANN; Russell S. J., 2003, ARTIFICIAL INTELLIGE; SCHAFER C, 2005, P ACL WORKSH BUILD U, P79, DOI 10.3115/1654449.1654463; Shen L., 2004, P HLT NAACL, P177; SHIEBER SM, 1990, P 13 INT C COMP LING, P253; SIMARD M, 2005, P HUM LANG TECHN C H, P755, DOI 10.3115/1220575.1220670; Sipser M., 2005, INTRO THEORY COMPUTA; SMITH DA, 2004, P C EMP METH NAT LAN, P49; Smith N. A., 2006, THESIS J HOPKINS U; Smith NA, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P95; Snover M., 2006, P ASS MACH TRANSL AM, P223; Talbot D., 2007, P 45 ANN M ASS COMP, P512; Talbot D., 2007, P ASS COMP LING ACL, P468; Taskar B., 2004, THESIS STANFORD U; Taskar Ben, 2005, P HLT EMNLP, P73, DOI 10.3115/1220575.1220585; TILLMAN C, 2003, COMPUT LINGUIST, V29, P98; TILLMAN C, 2006, P ACL COLING, P721, DOI 10.3115/1220175.1220266; TILLMANN C, 1997, P 35 ANN C ASS COMP, P289; Toutanova K, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P87; TURIAN J, 2003, P MT SUMM 9; UEFFING N, 2007, P ACL JUN, P25; UEFFING N, 2005, P HUM LANG TECHN C H, P763, DOI 10.3115/1220575.1220671; Ueffing N, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P156; VENUGOPAL A, 2005, P ACL WORKSH BUILD U, P208, DOI 10.3115/1654449.1654493; VENUGOPAL A, 2007, P HLT NAACL; Vijay-Shanker K., 1987, P 25 ANN M ASS COMP, P104, DOI 10.3115/981175.981190; VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010; Vogel S., 1996, P 16 INT C COMP LING, P836; WANG YY, 1997, P 35 ANN C ASS COMP, P366; Watanabe T., 2007, P EMNLP CONLL, P764; WATANABE T, 2002, P COLING, P1079; Weaver W, 1955, MACHINE TRANSLATION, P15; WELLINGTON B, 2006, P C ASS MACH TRANSL, P251; WELLINGTON B, 2006, P ACL COLING, P977, DOI 10.3115/1220175.1220298; WHITE JS, 1994, P ASS MACH TRANSL AM; Wu D., 1998, P CLOING ACL98, P1408; WU D, 1996, P 34 ANN C ASS COMP, P152, DOI 10.3115/981863.981884; WU D, 1995, P 14 INT JOINT C ART, P1328; WU DK, 1995, P 6 INT C THEOR METH, P354; Xiong D., 2006, P 21 INT C COMP LING, P521, DOI 10.3115/1220175.1220241; YAMADA K, 2001, P ACL EACL; Yamada K., 2002, P 40 ANN M ASS COMP, P303; Yarowsky D., 2001, P HUM LANG TECHN WOR, P109; Yarowsky D., 2001, P 2 M N AM ASS COMP, P200; ZENS R, 2007, P HLT NAACL; ZENS R, 2004, P HUM LANG TECHN C H, P257; Zens R., 2003, P ACL 2003, P144; Zhang H., 2005, P 43 ANN M ASS COMP, P475, DOI 10.3115/1219840.1219899; Zhang H., 2006, P HLT NAACL, P256, DOI 10.3115/1220835.1220868; ZHANG Y, 2005, P EAMT; ZHANG Y, 2006, P 2006 C EMP METH NA, P216, DOI 10.3115/1610075.1610108	206	11	11	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	0360-0300		ACM COMPUT SURV	ACM Comput. Surv.		2008	40	3							8	10.1145/1380584.1380586		49	Computer Science, Theory & Methods	Computer Science	341DS	WOS:000258695000002	
J	Jimenez, DA				Jimenez, Daniel A.			Generalizing Neural Branch Prediction	ACM TRANSACTIONS ON ARCHITECTURE AND CODE OPTIMIZATION			English	Article						Performance; Branch prediction; machine learning		Improved branch prediction accuracy is essential to sustaining instruction throughput with today's deep pipelines. Traditional branch predictors exploit correlations between pattern history and branch outcome to predict branches, but there is a stronger and more natural correlation between path history and branch outcome. We explore the potential for exploiting this correlation. We introduce piecewise linear branch prediction, an idealized branch predictor that develops a set of linear functions, one for each program path to the branch to be predicted, that separate predicted taken from predicted not taken branches. Taken together, all of these linear functions form a piecewise linear decision surface. We present a limit study of this predictor showing its potential to greatly improve predictor accuracy. We then introduce a practical implementable branch predictor based on piecewise linear branch prediction. In making our predictor practical, we show how a parameterized version of it unifies the previously distinct concepts of perceptron prediction and path-based neural prediction. Our new branch predictor has implementation costs comparable to current prominent predictors in the literature while significantly improving accuracy. For a deeply pipelined simulated microarchitecture our predictor with a 256-KB hardware budget improves the harmonic mean normalized instructions-per-cycle rate by 8% over both the original path-based neural predictor and 2Bc-gskew. The average misprediction rate is decreased by 16% over the path-based neural predictor and by 22% over 2Bc-gskew.	[Jimenez, Daniel A.] Rutgers State Univ, New Brunswick, NJ 08901 USA	Jimenez, DA (reprint author), Univ Texas San Antonio, Dept Comp Sci, 1 UTSA Circle, San Antonio, TX 78249 USA.	djimeneth@gmail.com			National Science Foundation [CCF-0311091, CCF-0545898]	This research is supported by National Science Foundation grants CCF-0311091 and CCF-0545898. Author's address: D. Jimenez, Department of Computer Science, The University of Texas at San Antonio, One UTSA Circle, San Antonio, TX 78249-1644; email: djimeneth@gmail.com or djimenez@acm.org	Akkary H, 2004, P 10 INT S HIGH PERF; BLOCK HD, 1962, REV MOD PHYS, V34, P123, DOI 10.1103/RevModPhys.34.123; BREKELBAUM E, 2002, P 35 INT S MICR; Burger D., 1997, 1342 U WISC COMP SCI; CHEN IK, 1996, ASPLOS, V7, P128; ERIKSSON H, 2002, P SWED SYST ON CHIP; Evers M., 1998, Proceedings. 25th Annual International Symposium on Computer Architecture (Cat. No.98CB36235), DOI 10.1109/ISCA.1998.694762; Falcon A., 2004, Proceedings. 31st Annual International Symposium on Computer Architecture, DOI 10.1109/ISCA.2004.1310779; Jimenez D. A., 2001, Proceedings HPCA Seventh International Symposium on High-Performance Computer Architecture, DOI 10.1109/HPCA.2001.903263; JIMENEZ DA, 2005, J INSTRUCT LEVEL PAR, V7; JIMENEZ DA, 2002, P 9 INT S HIGH PERF, P43; Jimenez DA, 2002, ACM T COMPUT SYST, V20, P369, DOI 10.1145/571637.571639; JIMENEZ DA, 2003, P 36 ANN IEEE ACM IN, P243; Jimenez D. A., 2000, Proceedings 33rd Annual IEEE/ACM International Symposium on Microarchitecture. MICRO-33 2000, DOI 10.1109/MICRO.2000.898059; LARSON E, 2001, P INT S PERF AN SYST; Loh G. H., 2002, Proceedings 2002 International Conference on Parallel Architectures and Compilation Techniques. PACT 2002, DOI 10.1109/PACT.2002.1106015; MCFARLING S., 1993, TN36M DIG W RES LAB; SEZNEC A, 2003, P 30 INT S COMP ARCH; SEZNEC A, 2002, P 29 INT S COMP ARCH; SEZNEC A, 2005, J INSTRUCT LEVEL PAR, V7; Sherwood T., 2002, P 10 INT C ARCH SUPP; SHIVAKUMAR P, 2001, 20012 COMP COMP CORP; Sprangle E., 2002, Proceedings 29th Annual International Symposium on Computer Architecture, DOI 10.1109/ISCA.2002.1003559; TARJAN D, 2004, P WORKSH COMPL EFF D; YEH T, 1993, P 20 ANN INT S COMP	25	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1544-3566		ACM T ARCHIT CODE OP	ACM Trans. Archit. Code Optim.		2008	5	4							17	10.1145/1498690.1498692		27	Computer Science, Hardware & Architecture; Computer Science, Theory & Methods	Computer Science	426BQ	WOS:000264682900002	
J	Nguyen, GP; Worring, M				Nguyen, Giang Phuong; Worring, Marcel			Optimization of interactive visual-similarity-based search	ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS			English	Article						experimentation; human factors; algorithms; interactive search; similarity based visualization; active learning	IMAGE RETRIEVAL; RELEVANCE FEEDBACK; TEXTURE	At one end of the spectrum, research in interactive content-based retrieval concentrates on machine learning methods for effective use of relevance feedback. On the other end, the information visualization community focuses on effective methods for conveying information to the user. What is lacking is research considering the information visualization and interactive retrieval as truly integrated parts of one content-based search system. In such an integrated system, there are many degrees of freedom like the similarity function, the number of images to display, the image size, different visualization modes, and possible feedback modes. To base the optimal values for all of those on user studies is unfeasible. We therefore develop search scenarios in which tasks and user actions are simulated. From there, the proposed scheme is optimized based on objective constraints and evaluation criteria. In such a manner, the degrees of freedom are reduced and the remaining degrees can be evaluated in user studies. In this article, we present a system that integrates advanced similarity based visualization with active learning. We have performed extensive experimentation on interactive category search with different image collections. The results using the proposed simulation scheme show that indeed the use of advanced visualization and active learning pays off in all of these datasets.	[Nguyen, Giang Phuong; Worring, Marcel] Univ Amsterdam, Intelligent Syst Lab Amsterdam, NL-1098 SJ Amsterdam, Netherlands	Nguyen, GP (reprint author), Univ Amsterdam, Intelligent Syst Lab Amsterdam, Kruislaan 403, NL-1098 SJ Amsterdam, Netherlands.	giangnp@uva.nl; M.Worring@uva.nl					BASSEVILLE M, 1989, SIGNAL PROCESS, V18, P349, DOI 10.1016/0165-1684(89)90079-0; BEDERSON BB, 2001, P 2001 ACM S US INT, V3, P71; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; CHEN B, 2001, INT ARCH PHOTOGRAMME, V34, P37; CHEN M, 2005, MULTIMEDIA 05, P902; DUBES RC, 1987, PATTERN RECOGN, V20, P645, DOI 10.1016/0031-3203(87)90034-3; Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60; Geusebroek JM, 2005, INT J COMPUT VISION, V62, P7, DOI 10.1007/s11263-005-4632-7; GOSSELIN P, 2004, P INT C IM PROC; GUO G, 2001, P INT C COMP VIS PAT; HEESCH D, 2004, P INT C IM VID RETR, P491; Ivory Y., 2001, ACM COMPUT SURV, V33, P470; KEIM D, 2002, IEEE T VIS COMPUT GR, V7, P10; MANEVITZ L, 2004, J MACH LEARN RES, V2, P139; Moghaddam B, 2004, INT J COMPUT VISION, V56, P109, DOI 10.1023/B:VISI.0000004834.62090.74; Naphade M., 2002, P IEEE INT C IM PROC; NGUYEN G, 2005, P 7 INT WORKSH AUD V; Rodden K, 2001, P SIGCHI C HUM FACT, P190, DOI 10.1145/365024.365097; Rubner Y, 2001, COMPUT VIS IMAGE UND, V84, P25, DOI 10.1006/cviu.2001.0934; Rubner Y, 1999, THESIS STANFORD U ST; Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644; RUMELHART DE, 1985, COGNITIVE SCI, V9, P75, DOI 10.1207/s15516709cog0901_5; Santini S, 2001, IEEE T KNOWL DATA EN, V13, P337, DOI 10.1109/69.929893; Shneiderman B., 1996, Proceedings. IEEE Symposium on Visual Languages (Cat. No.96TB100066), DOI 10.1109/VL.1996.545307; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Snoek C. G. M., 2005, P ACM MULT; SWALN M, 1991, INT J COMPUT VISION, V7, P11; TONG S, 2001, P 9 ACM INT C MULT, V9, P107; VOORHEES E, 2001, TREE 10 P APP COMM E; Zhang L., 2001, P IEEE INT C IM PROC, P721; Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3; ZHU M, 2004, RECALL PRECISION AVE	32	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1551-6857		ACM T MULTIM COMPUT	ACM Trans. Multimed. Comput. Commun. Appl.		2008	4	1							7	10.1145/1324287.1324294		23	Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	264UK	WOS:000253315700007	
S	Wurst, M		Tuyls, K; Nowe, A; Guessoum, Z; Kudenko, D		Wurst, Michael			Multi-agent learning by distributed feature extraction	ADAPTIVE AGENTS AND MULTI-AGENT SYSTEMS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	7th European Symposium on Adaptive Agents and Multi-Agent Systems	2007	Maastricht, NETHERLANDS					Finding the right data representation is essential for virtually every machine learning task. We discuss an extension of this representation problem. In the collaborative representation problem, the aim is to find for each learning agent in a multi-agent system an optimal data representation, such that the overall performance of the system is optimized, while not assuming that all agents learn the same underlying concept. Also, we analyze the problem of keeping the common terminology in which agents express their hypothesis as compact and comprehensible as possible by forcing them to use the same features, where this is possible. We analyze the complexity of this problem and show under which conditions an optimal solution can be found. We then propose a simple heuristic algorithm and show that this algorithm can efficiently be implemented in a multi-agent system. The approach is exemplified on the problem of collaborative media organization and evaluated on a several synthetic and real world datasets.	Univ Dortmund, AI Unit, D-44221 Dortmund, Germany	Wurst, M (reprint author), Univ Dortmund, AI Unit, D-44221 Dortmund, Germany.	michael.wurst@uni-dortmund.de					Argyriou A., 2007, ADV NEURAL INFORM PR; Caruana R, 1993, INT C MACH LEARN, P41; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Evgeniou T, 2005, J MACH LEARN RES, V6, P615; Guyon I, 2006, STUDIES FUZZINESS SO; Hastie T., 2001, SPRINGER SERIES STAT; HOMBURG H, 2005, P INT C MUS INF RETR; JEBARA T, 2004, P INT C MACH LEAR; John G.H., 1994, P 11 INT C MACH LEAR, P121; Kapetanakis S, 2005, LECT NOTES COMPUT SC, V3394, P119; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Mierswa I, 2005, MACH LEARN, V58, P127, DOI 10.1007/s10994-005-5824-7; MIERSWA I, 2006, P INT C GEN EV COMP; NUNES L, 2004, P INT JOINT C AUT AG, P1106; Ontanon S., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems; Schlkopf B., 2001, LEARNING KERNELS SUP; WEIHS C, 2006, DATA SCI CLASSIFICAT; Yu K., 2005, P INT C MACH LEARN; Yu L., 2004, J MACHINE LEARNING R, V5; Yu S., 2007, P INT C MACH LEARN	20	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-77947-6	LECT NOTES ARTIF INT			2008	4865						239	254				16	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	BHK92	WOS:000253938900017	
B	Johnson, S; Valli, S		Thulasiram, R		Johnson, Sandra; Valli, S.			An Approach to Predict Hot Methods using Support Vector Machines	ADCOM: 2008 16TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND COMMUNICATIONS			English	Proceedings Paper	16th International Conference on Advanced Computings and Communicationas	DEC 14-17, 2008	Chennai, INDIA	Adv Comp & Communicat Soc	Anna Univ Chennai, Dept Informat Technol			Most dynamic optimizers use feedback-directed adaptive optimization techniques. These techniques are expensive because of the profiling overhead. Although the recent trend has been toward the application of machine learning heuristics in compiler optimization, its role in identification and prediction of hotspots has been ignored. This approach evaluates a Support Vector Machine (SVM) based machine learning technique in which static program features have been used to develop a model to predict program hot spots. The result has shown that, when trained with just ten features, the model predicts hot methods with an appreciable 70.93% accuracy.	[Johnson, Sandra; Valli, S.] Anna Univ, Dept Comp Sci & Engn, Madras 600025, Tamil Nadu, India	Johnson, S (reprint author), Anna Univ, Dept Comp Sci & Engn, Madras 600025, Tamil Nadu, India.	sandra_johnk@yahoo.com; valli@annauniv.edu					Agakov F., 2006, P INT S COD GEN OPT, P295; Arnold M, 2005, P IEEE, V93, P449, DOI 10.1109/JPROC.2004.840305; CALDER B, 1997, ACM T PROGRAMMING LA, V19; Cavazos . J., 2004, P ACM SIGPLAN C PROG; CAVAZOS J, 2006, 11 INT WORKSH COMP P; CAVAZOS J, 2006, ACM C OBJ OR PROGR S; CAVAZOS J, 2004, THESIS U MASSACHUSET; Cavazos J., 2006, 15 INT C COMP CONSTR; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; CULPEPPER B, 2005, ECS201A U CAL; Dubach C., 2007; FURSIN G, 2007, P 5 GCC DEV SUMM OTT; Jimenez DA, 2002, ACM T COMPUT SYST, V20, P369, DOI 10.1145/571637.571639; Kotsiantis S B, 2007, Informatica, V31; Lattner C, 2004, P 2004 INT S COD GEN; LEE C. G., 1998, UTDSP BENCHMARK SUIT; LONG S, 2004, ACM INT C SUP ICS 04, P237; Monsifrot A, 2002, LECT NOTES ARTIF INT, V2443, P41; SINGER J, 2007, P 1 WORKSH STAT MACH, P96; Stephenson M., 2005, P INT S COD GEN OPT, P123; Stephenson M., 2003, P ACM SIGPLAN C PROG, P77; Stephenson M. W., 2006, THESIS MIT US; VAPNIK VN, 1999, GEN NEURAL NETWORK M, P239	23	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-2962-2				2008							27	31				5	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BMN87	WOS:000272993300005	
S	Anderson, M; Anderson, SL		Sordo, M; Vaidya, S; Jain, LC		Anderson, Michael; Anderson, Susan Leigh			Ethical Healthcare Agents	ADVANCED COMPUTATIONAL INTELLIGENCE PARADIGMS IN HEALTHCARE - 3	Studies in Computational Intelligence		English	Article; Book Chapter							MACHINE; ROBOTS	We have combined a bottom-up casuistry approach with a top-down implementation of an ethical theory to develop a system that uses machine-learning to abstract relationships between prima facie ethical duties from cases of particular types of ethical dilemmas where ethicists are in agreement as to the correct action. This system has discovered a novel ethical principle that governs decisions in a particular type of dilemma that involves three potentially conflicting prima facie duties. We describe two prototype systems in the domain of healthcare that use this principle, one that advises human beings as to the ethically correct action in specific cases of this type of dilemma and the other that uses this principle to guide its own behavior, making it what we believe may be the first explicit ethical agent.	[Anderson, Michael] Univ Hartford, Dept Comp Sci, Hartford, CT 06776 USA; [Anderson, Susan Leigh] Univ Connecticut, Dept Philosophy, Stamford, CT 06901 USA	Anderson, M (reprint author), Univ Hartford, Dept Comp Sci, 200 Bloomfield Ave, Hartford, CT 06776 USA.	anderson@hartford.edu; susan.anderson@uconn.edu					Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428; Anderson LC, 2006, J S AM EARTH SCI, V21, P28, DOI 10.1016/j.jsames.2005.07.008; ANDERSON M, 2005, P AAAI 2005 FALL S M, P1; ANDERSON M, 2006, P 18 C INN APPL ART; ANDERSON S, 1999, QUESTIONING MATTERS, P599; Beauchamp T, 1979, PRINCIPLES BIOMEDICA; BENTHAM J, 1799, INTRO PRINCIPLES MOR; Bringsjord S, 2006, IEEE INTELL SYST, V21, P38, DOI 10.1109/MIS.2006.82; BUCHANAN AE, 1989, DECIDING OTHERS ETHI, P48; GIPS J, 1995, ETHICAL ROBOT, P243; Grau C, 2006, IEEE INTELL SYST, V21, P52, DOI 10.1109/MIS.2006.81; Guarini M, 2006, IEEE INTELL SYST, V21, P22, DOI 10.1109/MIS.2006.76; KHAN AFU, 1995, ETHICS AUTONOMOUS LE, P253; LAVRAC N, 1997, INDUCTIVE LOGIC PROG; MAPPES TA, 2001, BIOMEDICAL ETHICS, P39; McLaren BM, 2003, ARTIF INTELL, V150, P145, DOI 10.1016/S0004-3702(03)00135-8; MILL JS, 1899, UTILITARIANISM; Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80; Powers TM, 2006, IEEE INTELL SYST, V21, P46, DOI 10.1109/MIS.2006.77; RAWLS J, 1951, PHILOS REV, V60; Ross W. D., 1930, RIGHT GOOD; RZEPKA R, 2005, P AAAI FALL S MACH E, P85; WALDROP MM, 1987, MAN MADE MINDS PROMI, pCH11	23	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1860-949X	978-3-540-77661-1	STUD COMPUT INTELL			2008	107						233	257			10.1007/978-3-540-77662-8	25	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology	Computer Science; Mathematical & Computational Biology	BJL79	WOS:000266773000010	
S	Alfred, R		Tang, C; Ling, CX; Zhou, XF; Cercone, NJ; Li, X		Alfred, Rayner			A Genetic-Based Feature Construction Method for Data Summarisation	ADVANCED DATA MINING AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	4th International Conference on Advanced Data Mining and Applications	OCT 08-10, 2008	Chengdu, PEOPLES R CHINA	Natl Sci Fdn China, Sichuan, Univ, WiseSoft Co Ltd		Feature Construction; Data Summarisation; Genetic Algorithm; Clustering	INDUCTION	The importance of input representation has been recognised already in machine learning This paper discusses the application of genetic-based feature construction methods to generate input, data for the data summarisation method called Dynamic Aggregation of Relational Attributes (DARA). Here, feature construction methods are applied ill order to improve the descriptive accuracy of the DARA algorithm. The DARA algorithm is designed to summarise data stored ill the non-target tables by clustering them into groups, where multiple records stored in non-target tables correspond to a single record stored ill a target, table, This paper addresses the question whether or not the descriptive accuracy of the DARA algorithm benefits from the feature construction process. This involves solving the problem of constructing a relevant set of features for the DARA algorithm by using a genetic-based algorithm. This work also evaluates several scoring measures used as fitness functions to find the best set of constructed features.	Univ Malaysia Sabah, Sch Informat Technol & Engn, Kota Kinabalu 88999, Sabah, Malaysia	Alfred, R (reprint author), Univ Malaysia Sabah, Sch Informat Technol & Engn, Locked Bag 2073, Kota Kinabalu 88999, Sabah, Malaysia.						ALFRED R, 2006, 2 ADMA INT C, P889; Amaldi E, 1998, THEOR COMPUT SCI, V209, P237, DOI 10.1016/S0304-3975(97)00115-1; BENSUSAN H, 1996, ICML 1996; BLOCKEEL H, 1999, TILDE WARMR USER MAN; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224; Freitas AA, 2001, ARTIF INTELL REV, V16, P177, DOI 10.1023/A:1011996210207; HOLLAND JH, 1975, ADAPTATION NATURAL A; Hu Y-J, 1998, P 3 ANN GEN PROGR C, P146; HU YJ, 1996, AAAI IAAI, V1, P806; KOZA JR, 1994, STAT COMPUTING, V4; Krawiec K., 2002, Genetic Programming and Evolvable Machines, V3, DOI 10.1023/A:1020984725014; Lavrac N., 2001, ACM T COMPUT LOG, V2, P458, DOI 10.1145/383779.383781; Otero FEB, 2003, LECT NOTES COMPUT SC, V2610, P384; PAGALLO G, 1990, MACH LEARN, V5, P71, DOI 10.1023/A:1022611825350; Quinlan Ross, 1993, M KAUFMANN SERIES MA; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; Shafti LS, 2003, LECT NOTES COMPUT SC, V2810, P599, DOI 10.1007/978-3-540-45231-7_55; Shannon C. E., 1948, BELL SYSTEM TECHNICA, V27; Srinivasan A, 1996, ARTIF INTELL, V85, P277, DOI 10.1016/0004-3702(95)00122-0; Vafaie H, 1998, IEEE INTELL SYST APP, V13, P57, DOI 10.1109/5254.671093; WIENER N, 2000, CYBERNETICS CONTROL; Witten I. H., 1999, DATA MINING PRACTICA; ZHENG Z, 1996, ICTAI, P254; Zheng ZJ, 2000, MACH LEARN, V40, P35, DOI 10.1023/A:1007626017208	24	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-88191-9	LECT NOTES ARTIF INT			2008	5139						39	50				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BIL02	WOS:000260453000005	
S	Hu, B; Liu, HY; He, J; Du, XY		Tang, C; Ling, CX; Zhou, XF; Cercone, NJ; Li, X		Hu, Bo; Liu, Hongyan; He, Jun; Du, Xiaoyong			FARS: A Multi-relational Feature and Relation Selection Approach for Efficient Classification	ADVANCED DATA MINING AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	4th International Conference on Advanced Data Mining and Applications	OCT 08-10, 2008	Chengdu, PEOPLES R CHINA	Natl Sci Fdn China, Sichuan, Univ, WiseSoft Co Ltd				Feature selection is an essential data processing step to remove the irrelevant and redundant attributes for shorter learning time, better accuracy and better comprehensibility. A number of algorithms have been proposed in both data mining, and machine learning area. These algorithms are usually Used ill sin-le table environment. where data are stored in one relational table or one flat file. They are not suitable for multi-relational environment, where data are stored in multiple tables joined each other by semantic relationships. To solve this problem, in this paper we propose a novel approach called FARS to do both feature and relation Selection for efficient multi-relational classification. By this approach, we not only extend traditional feature selection method to selects relevant features from multi-relations, but also develop a new method to reconstruct the multi-relational database schema and get rid of irrelevant tables to further improve classification performance. Results of experiments conducted on several real databases show that FARS can effectively choose a small set of relevant features, enhancing the classification efficiency significantly and improving prediction accuracy.	[Hu, Bo; He, Jun; Du, Xiaoyong] Renmin Univ, China Informat Sch, Key Labs Data Engn & Knowledge Engn, MOE, Beijing 100872, Peoples R China	Hu, B (reprint author), Renmin Univ, China Informat Sch, Key Labs Data Engn & Knowledge Engn, MOE, Beijing 100872, Peoples R China.						Aha D., 1995, P 5 INT WORKSH ART I, P1; Almuallim H., 1991, P 9 NAT C ART INT AA, V2, P547; BLUM A, 1997, ARTIF INTELL, V1, P245; BOZ O, 2002, P INT C MACH LEARN A; Cardie C., 1993, P 10 INT C MACH LEAR, P25; CARUANA R, 1994, P 11 INT C MACH LEAR, P180; Hall M., 2000, P 17 INT C MACH LEAR, P359; Hall M. A., 1999, THESIS U WAIKATO; John G.H., 1994, P 11 INT C MACH LEAR, P121; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Koller D., 1996, P 13 INT C MACH LEAR; Kononenko I., 1994, P EUR C MACH LEARN, P171; Langley P., 1994, P AAAI FALL S REL; Liu H., 2002, P 19 INT C MACH LEAR, P395; LIU H, 2005, P ACM SIGKDD MRDM WO; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Rendell L.A., 1992, P 10 NAT C ART INT, P129; WANG R, 2007, ICITM; YIN X, 2004, P 2004 INT C DAT ENG; YIN X, CROSSMINE SOFTWARE; YU L, 2003, 12 INT C MACH LEARN	21	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-88191-9	LECT NOTES ARTIF INT			2008	5139						73	86				14	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BIL02	WOS:000260453000008	
S	Ha, SH; Jin, JS; Yang, JW		Tang, C; Ling, CX; Zhou, XF; Cercone, NJ; Li, X		Ha, Sung Ho; Jin, Jong Sik; Yang, Jeong Won			Predictive Performance of Clustered Feature-Weighting Case-Based Reasoning	ADVANCED DATA MINING AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	4th International Conference on Advanced Data Mining and Applications	OCT 08-10, 2008	Chengdu, PEOPLES R CHINA	Natl Sci Fdn China, Sichuan, Univ, WiseSoft Co Ltd			SYSTEM; YIELD; PATTERNS	Because many factors are complexly involved in the production of semiconductors, semiconductor manufacturers can hardly manage yield precisely. We present a hybrid machine learning system, i.e., a clustered feature-weighting case-based reasoning, to detect high-yield or low-yield lots in semiconductor manufacturing. The system uses self-organizing map neural networks to identify similar patterns in the process parameters. The trained back-propagation neural networks determine feature weights of case-based reasoning. Based on the clustered feature-weighting case-based reasoning, the hybrid system predicts the yield level of a new manufacturing lot. To validate the effectiveness of our approach, we apply the hybrid system to real data of a semiconductor company.	[Ha, Sung Ho; Jin, Jong Sik; Yang, Jeong Won] Kyungpook Natl Univ, Sch Business Adm, Taegu 702701, South Korea	Ha, SH (reprint author), Kyungpook Natl Univ, Sch Business Adm, 1370 Sangyeok Dong, Taegu 702701, South Korea.						Ahn H, 2006, EXPERT SYST, V23, P290, DOI 10.1111/j.1468-0394.2006.00410.x; Burnham K. P., 2002, MODEL SELECTION MULT; Chien CF, 2007, EXPERT SYST APPL, V33, P192, DOI 10.1016/j.eswa.2006.04.014; Hsu SC, 2007, INT J PROD ECON, V107, P88, DOI 10.1016/j.ijpe.2006.05.015; Kang BS, 1998, EXPERT SYST APPL, V15, P123, DOI 10.1016/S0957-4174(98)00017-7; Last M, 2004, ROBOT AUTON SYST, V49, P137, DOI 10.1016/j.robot.2004.09.002; Lee JH, 2001, EXPERT SYST APPL, V20, P133, DOI 10.1016/S0957-4174(00)00054-3; LI TS, 2007, EXPERT SYSTEMS A OCT; Liu H, 1998, FEATURE SELECTION KN; Shin CK, 1999, EXPERT SYST APPL, V16, P145, DOI 10.1016/S0957-4174(98)00067-0; SOBRINO MDC, 1999, INTELL DATA ANAL, V3, P399; Wang CH, 2008, EXPERT SYST APPL, V34, P1914, DOI 10.1016/j.eswa.2007.02.014; Yang TH, 1999, COMPUT IND ENG, V36, P565, DOI 10.1016/S0360-8352(99)00151-5	13	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-88191-9	LECT NOTES ARTIF INT			2008	5139						469	476				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BIL02	WOS:000260453000044	
J	Hmeidi, I; Hawashin, B; El-Qawasmeh, E				Hmeidi, Ismail; Hawashin, Bilal; El-Qawasmeh, Eyas			Performance of KNN and SVM classifiers on full word Arabic articles	ADVANCED ENGINEERING INFORMATICS			English	Article; Proceedings Paper	13th International Workshop of the European-Group-for-Intelligent-Computing-in-Engineering	JUN 25-30, 2006	Ascona, SWITZERLAND	European Grp Intelligent Comp Engn		Arabic text categorization; full word features; tf.idf weighting; CHI statistics; KNN; SVM		This paper reports a comparative study of two machine learning methods on Arabic text categorization. Based on a collection of news articles as a training set, and another set of news articles as a testing set, we evaluated K nearest neighbor (KNN) algorithm, and support vector machines (SVM) algorithm. We used the full word features and considered the tf.idf as the weighting method for feature selection, and CHI statistics as a ranking metric. Experiments showed that both methods were of superior performance on the test corpus while SVM showed a better micro average F1 and prediction time. (C) 2007 Elsevier Ltd. All rights reserved.	[Hmeidi, Ismail; Hawashin, Bilal; El-Qawasmeh, Eyas] Jordan Univ Sci & Technol, Fac Comp & Informat Technol, Irbid 22110, Jordan	El-Qawasmeh, E (reprint author), Jordan Univ Sci & Technol, Fac Comp & Informat Technol, Irbid 22110, Jordan.	hmeidi@just.edu.jo; hawashin@just.edu.jo; eyas@just.edu.jo					APTE C, 1998, P C AUT LEARN DISC C; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Duwairi R., 2005, P 2005 INT C DAT MIN, P187; El-Halees A., 2007, ISLAMIC U J, V15, P157; Fuhr N., 1991, P RIAO 91, P606; JI H, 2000, P INT WORKSH TEXT WE, P24; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Joachims T., 1997, P 14 INT C MACH LEAR, P143; JOACHIMS T, 1999, SUPPORT VECTOR LEARN; Khreisat L., 2006, P 2006 INT C DAT MIN, P78; Lam W., 1998, P 21 ANN INT ACM SIG, P81, DOI 10.1145/290941.290961; Lewis DD, 1994, P 3 ANN S DOC AN INF, P81; MASAND B, 1992, 15 ANN INT ACM SIGIR, P59; MCCALLUM AK, 1996, TOOLKIT STAT LANGUAG; MOULINIER I, 1997, LAOFORIALIP6 U PAR 6; Vapnik VN, 1998, STAT LEARNING THEORY; YAHYA A, 1989, COMPLEXITY INITIAL S; Yang Y., 1994, 17 ANN INT ACM SIGIR, P13; Yang Y, 1999, J INFORMATION RETRIE, V1, P69; Yang Yiming, 1997, P 14 INT C MACH LEAR, P412; YANG YM, 1994, ACM T INFORM SYST, V12, P252, DOI 10.1145/183422.183424; 1999, GIST SUPPORT VECTOR	22	10	13	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1474-0346		ADV ENG INFORM	Adv. Eng. Inform.	JAN	2008	22	1					106	111		10.1016/j.aei.2007.12.001		6	Computer Science, Artificial Intelligence; Engineering, Multidisciplinary	Computer Science; Engineering	282LP	WOS:000254569600010	
S	Mu, X; Tang, N; Gao, W; Li, L; Zhou, Y		Huang, DS; Wunsch, DC; Levine, DS; Jo, KH		Mu, Xiangyang; Tang, Nan; Gao, Weixin; Li, Lin; Zhou, Yatong			A One-Step Network Traffic Prediction	ADVANCED INTELLIGENT COMPUTING THEORIES AND APPLICATIONS, PROCEEDINGS: WITH ASPECTS OF ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	4th International Conference on Intelligent Computing	SEP 15-18, 2008	Shanghai, PEOPLES R CHINA			Network Traffic; Minimax Probability Machine; Support Vector Machine; Prediction		In the information society today computer networks are an indispensable part of people's life. Network traffic prediction is important to network planning, performance evaluation and network management directly. A variety of machine learning models such as artificial neural networks (ANN) and support vector machine (SVM) have been applied in traffic prediction. In this paper, a novel network traffic one-step-ahead prediction technique is proposed based on a state-of-the-art learning model called minimax probability machine (MPM). The predictive performance is tested on traffic data of Ethernet, experimental results show that the predictions of MPM match the actual traffics accurately and the proposed methods can increases the computational efficiency. Furthermore, we compare the MPM-based prediction technique with the SVM-based techniques. The results show that the predictive performance of MPM is competitive with SVM.	[Mu, Xiangyang; Tang, Nan; Gao, Weixin; Li, Lin] Xian Shiyou Univ, Sch Elect Engn, Xian 710065, Peoples R China	Mu, X (reprint author), Xian Shiyou Univ, Sch Elect Engn, Xian 710065, Peoples R China.						CHAPELLE O, ADV NEURAL INFORM PR, V13, P416; Chen BS, 2000, IEEE T FUZZY SYST, V8, P491; Hall J, 2000, IEE P-COMMUN, V147, P114, DOI 10.1049/ip-com:20000146; HOI CH, 2004, ROBUST FACE RECOGNIT; Khotanzad A., 2003, P INT J C NEUR NETW, V2, P1071, DOI 10.1109/IJCNN.2003.1223839; Lanckriet G. R. G., 2002, J MACHINE LEARNING R, V3, P555; Liu ZX, 2005, LECT NOTES COMPUT SC, V3498, P385; Sang AM, 2002, COMPUT NETW, V39, P329, DOI 10.1016/S1389-1286(01)00304-8; STROHMANN TR, 2002, ADV NEURAL INFORM PR, V14; STROHMANN TR, J MACHINE LEAR UNPUB; TIPPING ME, 2002, ADV NEURAL INFORM PR, V12	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-85983-3	LECT NOTES COMPUT SC			2008	5227						616	621				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	BIK84	WOS:000260436000074	
S	Su, CY; Ding, SF; Jia, WK; Wang, X; Xu, XZ		Huang, DS; Wunsch, DC; Levine, DS; Jo, KH		Su, Chunyang; Ding, Shifei; Jia, Weikuan; Wang, Xin; Xu, Xinzheng			Some Progress of Supervised Learning	ADVANCED INTELLIGENT COMPUTING THEORIES AND APPLICATIONS, PROCEEDINGS: WITH ASPECTS OF ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	4th International Conference on Intelligent Computing	SEP 15-18, 2008	Shanghai, PEOPLES R CHINA				ALGORITHM	Supervised learning is very important in machine learning. In this paper we discuss some progress of supervised learning. At first, we introduce the basic concept and methods of supervised learning; then explain several typical algorithms of supervised learning in details, the algorithms covered are Bayesian networks, decision tree, k-nearest neighbor, supervised manifold learning and support vector machines; at last we point out several developing directions of supervised learning.	[Su, Chunyang; Ding, Shifei; Wang, Xin; Xu, Xinzheng] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221008, Peoples R China	Su, CY (reprint author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221008, Peoples R China.						Baik S, 2004, LECT NOTES COMPUT SC, V3046, P206; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; DICK DR, 2003, LNCS, V2714, P333; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Keerthi SS, 2002, MACH LEARN, V46, P351, DOI 10.1023/A:1012431217818; LESLIE PK, 1996, J ARTIFICIAL INTELLI, V4, P237; Murthy SK, 1998, DATA MIN KNOWL DISC, V2, P345, DOI 10.1023/A:1009744630224; OLCAY TY, 2007, PATTERN RECOGN, V28, P825; OSUNA EE, 1996, 1602 AIM MIT; PAL M, 2001, P 22 AS C REM SENS A, P245; PLATT JC, 1999, ADV NEURAL INFORM PR; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1979, DISCOVERING RULES IN, P168; Ruggieri S, 2002, IEEE T KNOWL DATA EN, V14, P438, DOI 10.1109/69.991727; Sam T.R., 2000, SCIENCE, V290, P2323; Saul LK., 2003, J MACHINE LEARNING R, V4, P119; Vapnik V., 1982, ESTIMATION DEPENDENC; WETTSCHERECK D, 1997, ARTIF INTELL, V10, P1; ZHOU ZH, 2007, MACHINE LEARNING ITS	20	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-85983-3	LECT NOTES COMPUT SC			2008	5227						661	666				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	BIK84	WOS:000260436000079	
S	Ding, SF; Jia, WK; Su, CY; Jin, FX; Shi, ZZ		Huang, DS; Wunsch, DC; Levine, DS; Jo, KH		Ding, Shifei; Jia, Weikuan; Su, Chunyang; Jin, Fengxiang; Shi, Zhongzhi			A Survey on Statistical Pattern Feature Extraction	ADVANCED INTELLIGENT COMPUTING THEORIES AND APPLICATIONS, PROCEEDINGS: WITH ASPECTS OF ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	4th International Conference on Intelligent Computing	SEP 15-18, 2008	Shanghai, PEOPLES R CHINA					The goal of statistical pattern feature extraction (SPFE) is 'low loss dimension reduction'. As the key link of pattern recognition, dimension reduction has become the research hot spot and difficulty in the fields of pattern recognition, machine learning, data mining and so on. Pattern feature extraction is one of the most challenging research fields and has attracted the attention from many scholars. This paper summarily introduces the basic principle of SPFE, and discusses the latest progress of SPFE from the aspects such as classical statistical theories and their modifications, kernel-based methods, wavelet analysis and its modifications, algorithms integration and so on. At last we discuss the development trend of SPFE.	[Ding, Shifei; Su, Chunyang] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221008, Peoples R China	Ding, SF (reprint author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221008, Peoples R China.						Aizerman M.A., 1964, AUTOMAT REM CONTR, P821; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; DING SF, 2005, J COMPUTER AIDED DES, V2, P368; DING SF, 2004, MININTICRO SYSTEMS, V4, P694; Duda R.O, 1973, PATTERN CLASSIFICATI; FAN YP, 2005, ACTA SIMULATA SYSTER, V1, P148; Foman G, 2003, J MACH LEARN RES, V3, P1289; FRIEDMAN JE, 1974, IEEE T COMPUT, V9, P881; Gao MT, 2007, PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3401; HUANG QH, 2007, OPTOELECTRONIC ENG, V1, P121; HUANG R, 2007, CHINESE J COMPUTERS, V7, P1173; JENSN DD, 2000, MACH LEARN, V3, P309; Karhunen J., 1997, P IEEE INT C AC SPEE, P131; Lee DD, 1999, NATURE, V401, P788; LI Q, 2005, ACTA ELECT SINICA, V10, P1886; MAKRAM N, 2008, PATTERN RECOGN, V3, P868; Mika S, 1999, NEURAL NETWORKS SIGN, P41; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Seung HS, 2000, SCIENCE, V290, P2268, DOI 10.1126/science.290.5500.2268; SONG FX, 2005, CHINESE J COMPUTERS, V11, P1915; SUN P, 2004, CHINESE J COMPUTERS, V6, P789; Swiniarski RW, 2003, PATTERN RECOGN LETT, V24, P833, DOI 10.1016/S0167-8655(02)00196-4; TAYLOR JS, 2003, ADV NEURAL INFORM PR, V15, P383; Wiener E., 1995, P 4 ANN S DOC AN INF, P317; YUEN PC, 2001, PATTERN RECOGN, V3, P545; ZUO F, 2005, P IEEE C ADV VID SIG, P348	26	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-85983-3	LECT NOTES COMPUT SC			2008	5227						701	708				8	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	BIK84	WOS:000260436000084	
S	Tavares, LG; Lopes, HS; Lima, CRE		Huang, DS; Wunsch, DC; Levine, DS; Jo, KH		Tavares, Leonardo G.; Lopes, Heitor S.; Lima, Carlos R. Erig			A Comparative Study of Machine Learning Methods for Detecting Promoters in Bacterial DNA Sequences	ADVANCED INTELLIGENT COMPUTING THEORIES AND APPLICATIONS, PROCEEDINGS: WITH ASPECTS OF ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	4th International Conference on Intelligent Computing	SEP 15-18, 2008	Shanghai, PEOPLES R CHINA			Bioinformatics; Data classification; Machine Learning; DNA		Machine Learning methods have been widely used in bioinformatics, mainly for data classification and pattern recognition. The detection of genes in DNA sequences is still an open problem. Identifying the promoter region laying prior the gene itself is an important aid to detect a gene. This paper aims at applying several Machine Learning methods to the construction of classifiers for detection of promoters in the DNA of Escherichia coli. A thorough comparison of methods was done. In general, probabilistic and neural network-based methods were those that performed better regarding accuracy rate.	[Tavares, Leonardo G.; Lopes, Heitor S.; Lima, Carlos R. Erig] Fed Univ Technol Parana UTFPR, Bioinformat Lab, BR-80230901 Curitiba, Parana, Brazil	Tavares, LG (reprint author), Fed Univ Technol Parana UTFPR, Bioinformat Lab, Av 7 Setembro 3165, BR-80230901 Curitiba, Parana, Brazil.						Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Durbin R., 1998, BIOL SEQUENCE ANAL P; Ephraim Y, 2002, IEEE T INFORM THEORY, V48, P1518, DOI 10.1109/TIT.2002.1003838; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; HARLEY C, 1983, NUCLEIC ACIDS RES, V11, P2237; Kohavi R, 1995, 14 INT JOINT C ART I, P1137; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; Mount D.M., 2001, BIOINFORMATICS SEQUE; Nelson D. L., 2006, LEHNINGER PRINCIPLES; Platt J., 1998, ADV KERNEL METHODS S; RENNIE J, 2003, 20 INT C MACH LEARN, P616; Sing T, 2005, BIOINFORMATICS, V21, P3940, DOI 10.1093/bioinformatics/bti623; TOWELL GG, 1990, 8TH P NAT C ART INT, P861; Weinert Wagner Rodrigo, 2004, Appl Bioinformatics, V3, P41; Witten I. H., 2005, DATA MINING PRACTICA; Wolfsberg TG, 2001, NATURE, V409, P824, DOI 10.1038/35057000	16	1	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-85983-3	LECT NOTES COMPUT SC			2008	5227						959	966				8	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	BIK84	WOS:000260436000115	
S	Han, L; Yang, RL; Su, B; Zhao, ZM		Huang, DS; Wunsch, DC; Levine, DS; Jo, KH		Han, Leng; Yang, Ruolin; Su, Bing; Zhao, Zhongming			An SVM-Based Algorithm for Classifying Promoter-Associated CpG Islands in the Human and Mouse Genomes	ADVANCED INTELLIGENT COMPUTING THEORIES AND APPLICATIONS, PROCEEDINGS: WITH ASPECTS OF ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	4th International Conference on Intelligent Computing	SEP 15-18, 2008	Shanghai, PEOPLES R CHINA			CpG islands (CGIs); Support Vector Machine (SVM); promoter; human; mouse	SEQUENCES	CpG islands (CGIs) are clusters of CpG dinucleotides in GC-rich regions and represent an important gene feature of mammalian genomes. Several algorithms have been developed to identify CGIs. Here we applied Support Vector Machine (SVM), a machine learning approach, to classify CGIs that are associated with the promoter regions of genes. We demonstrated that our SVM-based algorithm had much higher sensitivity and specificity in classifying promoter-associated CGIs than other algorithms, and had high reliability. The advantages of SVM in our method and future improvements were discussed.	[Han, Leng; Zhao, Zhongming] Virginia Commonwealth Univ, Dept Psychiat, Richmond, VA 23298 USA	Zhao, ZM (reprint author), Virginia Commonwealth Univ, Dept Psychiat, Med Coll Virginia Campus, Richmond, VA 23298 USA.						Bhasin M, 2005, FEBS LETT, V579, P4302, DOI 10.1016/j.febslet.2005.07.002; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Fang F, 2006, BIOINFORMATICS, V22, P2204, DOI 10.1093/bioinformatics/btl377; GARDINERGARDEN M, 1987, J MOL BIOL, V196, P261, DOI 10.1016/0022-2836(87)90689-9; Ioshikhes IP, 2000, NAT GENET, V26, P61; Jiang CZ, 2006, GENOMICS, V88, P527, DOI 10.1016/j.ygeno.2006.06.003; Jiang CZ, 2007, MOL BIOL EVOL, V24, P1991, DOI 10.1093/molbev/msm128; Lander ES, 2001, NATURE, V409, P860, DOI 10.1038/35057062; Ponger L, 2002, BIOINFORMATICS, V18, P631, DOI 10.1093/bioinformatics/18.4.631; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Takai D, 2002, P NATL ACAD SCI USA, V99, P3740, DOI 10.1073/pnas.052410099; Vapnik VN, 1998, STAT LEARNING THEORY	12	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-85983-3	LECT NOTES COMPUT SC			2008	5227						975	981				7	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	BIK84	WOS:000260436000117	
S	Shrestha, R; Kim, J; Han, K		Huang, DS; Wunsch, DC; Levine, DS; Jo, KH		Shrestha, Rojan; Kim, Jisu; Han, Kyungsook			Prediction of RNA-binding residues in proteins using the interaction propensities of amino acids and nucleotides	ADVANCED INTELLIGENT COMPUTING THEORIES AND APPLICATIONS, PROCEEDINGS: WITH ASPECTS OF THEORETICAL AND METHODOLOGICAL ISSUES	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	4th International Conference on Intelligent Computing	SEP 15-18, 2008	Shanghai, PEOPLES R CHINA				SEQUENCE; RECOGNITION; COMPLEXES; SURFACES; SITES	Recently several machine learning approaches have been attempted to predict RNA-binding residues in amino acid sequences. None of these consider interacting partners (i.e., RNA) for a given protein when predicting RNA-binding amino acids, so they always predict the same RNA-binding residues for a given protein even if the protein may bind to different RNA molecules. In this study, we present a support vector machine (SVM) classifier that takes an RNA sequence as well as a protein sequence as input and predicts potential RNA-binding residues in the protein. The interaction propensity between an amino acid and nucleotide obtained from the extensive analysis of the representative protein-RNA complexes in the Protein Data Bank (PDB) was encoded in the feature vector of the SVM classifier. Four biochemical properties of an amino acid (the side chain pKa value, hydrophobicity index, molecular mass, and accessible surface area) were also encoded in the feature vector. On a dataset of 145 protein sequences and 78 RNA sequences, the SVM classifier achieved a sensitivity of 72.30% and specificity of 78.03%.		Han, K (reprint author), Inha Univ, Sch Engn & Comp Sci, Inchon 402751, South Korea.						Ahmad S, 2004, BIOINFORMATICS, V20, P477, DOI 10.1093/bioinformatics/btg432; Allers J, 2001, J MOL BIOL, V311, P75, DOI 10.1006/jmbi.2001.4857; CHOTHIA C, 1976, J MOL BIOL, V105, P1, DOI 10.1016/0022-2836(76)90191-1; Dupret G, 2001, EUR J OPER RES, V134, P141, DOI 10.1016/S0377-2217(00)00244-7; Han K, 2007, FEBS LETT, V581, P1881, DOI 10.1016/j.febslet.2007.03.085; Hwang S, 2007, BIOINFORMATICS, V23, P634, DOI 10.1093/bioinformatics/btl672; Jones S, 1999, J MOL BIOL, V287, P877, DOI 10.1006/jmbi.1999.2659; Kim H, 2003, FEBS LETT, V552, P231, DOI 10.1016/S0014-5793(03)00930-X; KYTE J, 1982, J MOL BIOL, V157, P105, DOI 10.1016/0022-2836(82)90515-0; MORAS D, 1992, CURR OPIN STRUC BIOL, V2, P138, DOI 10.1016/0959-440X(92)90189-E; Nelson D. L., 2000, LEHNINGER PRINCIPLES; Ofran Y, 2007, BIOINFORMATICS, V23, P347; Pabo CO, 2000, J MOL BIOL, V301, P597, DOI 10.1006/jmbi.2000.3918; TERRIBILINI M, 2007, NUCLEIC ACIDS RES, V294, P1; Terribilini M, 2006, RNA, V12, P1450, DOI 10.1261/rna.2197306; Tjong H, 2007, NUCLEIC ACIDS RES, V35, P1465, DOI 10.1093/nar/gkm008; Varani G, 1998, ANNU REV BIOPH BIOM, V27, P407, DOI 10.1146/annurev.biophys.27.1.407; Wang L., 2006, NUCLEIC ACIDS RES, V34, P243	18	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-87440-9	LECT NOTES COMPUT SC			2008	5226						114	121				8	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Computer Science	BIH57	WOS:000259555200016	
S	Wang, SL; Li, XL; Zhang, SW		Huang, DS; Wunsch, DC; Levine, DS; Jo, KH		Wang, Shulin; Li, Xueling; Zhang, Shanwen			Neighborhood rough set model based gene selection for multi-subtype tumor classification	ADVANCED INTELLIGENT COMPUTING THEORIES AND APPLICATIONS, PROCEEDINGS: WITH ASPECTS OF THEORETICAL AND METHODOLOGICAL ISSUES	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	4th International Conference on Intelligent Computing	SEP 15-18, 2008	Shanghai, PEOPLES R CHINA				EXPRESSION DATA; CANCER; PREDICTION	Multi-subtype tumor diagnosis based on gene expression profiles is promising in clinical medicine application. Therefore, a great deal of research on tumor classification based on gene expression profiles has been developed, where various machine learning approaches were applied to constructing the best tumor classification model to improve the classification performance as much as possible. To achieve this goal, extracting features or finding informative genes that have good classification ability is crucial. We propose a novel gene selection approach, which adopts Kruskal-Wallis rank sum test to rank all genes and then apply an algorithm based on neighborhood rough set model to gene reduction to obtain gene subsets with fewer genes and more classification ability. Experiments on a small round blue cell tumor (SRBCT) dataset show that our approach can achieve very high classification accuracy with only three or four genes as evaluated by three classifiers: support vector machines, K-nearest neighbor and neighborhood classifier, respectively.		Wang, SL (reprint author), Chinese Acad Sci, Hefei Inst Intelligent Machines, Hefei 230031, Anhui, Peoples R China.						Ben-Dor A, 2000, J COMPUT BIOL, V7, P559, DOI 10.1089/106652700750050943; Chen HX, 2005, IEEE T AUTOM SCI ENG, V2, P132, DOI 10.1109/TASE.2005.844537; Dasarathy BV, 1991, NEAREST NEIGHBOR NOR; DENG L, 2004, KDD 2004, P410; Deng L, 2004, CHINESE SCI BULL, V49, P1652, DOI 10.1360/03we0143; Deutsch JM, 2003, BIOINFORMATICS, V19, P45, DOI 10.1093/bioinformatics/19.1.45; Fu LM, 2004, FEBS LETT, V561, P186, DOI 10.1016/S0014-5793(04)00175-9; FUNG BYM, 2004, META CLASSIFICATION, P31; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hu Qing-Hua, 2008, Journal of Software, V19, DOI 10.3724/SP.J.1001.2008.00640; Hu QH, 2008, EXPERT SYST APPL, V34, P866, DOI 10.1016/j.eswa.2006.10.043; Jaeger J, 2003, PAC S BIOC, V8, P53; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583, DOI 10.2307/2280779; Lee Y, 2003, BIOINFORMATICS, V19, P1132, DOI 10.1093/bioinformatics/btg102; Lehmann EL, 1975, NONPARAMETRICS STAT; Vapnik VN, 1998, STAT LEARNING THEORY; Wang LP, 2007, IEEE ACM T COMPUT BI, V4, P40, DOI 10.1109/TCBB.2007.1006; WANG SL, 2006, INT COMP S TAIW, P1368; WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968; Xiong MM, 2001, MOL GENET METAB, V73, P239, DOI 10.1006/mgme.2001.3193; Xiong MM, 2001, GENOME RES, V11, P1878	24	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-87440-9	LECT NOTES COMPUT SC			2008	5226						146	158				13	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Computer Science	BIH57	WOS:000259555200020	
S	Karabulut, M; Ibrikci, T		Huang, DS; Wunsch, DC; Levine, DS; Jo, KH		Karabulut, Mustafa; Ibrikci, Turgay			Fuzzy C-Means based DNA motif discovery	ADVANCED INTELLIGENT COMPUTING THEORIES AND APPLICATIONS, PROCEEDINGS: WITH ASPECTS OF THEORETICAL AND METHODOLOGICAL ISSUES	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	4th International Conference on Intelligent Computing	SEP 15-18, 2008	Shanghai, PEOPLES R CHINA					In this paper, we examined the problem of identifying motifs in DNA sequences. Transcription-binding sites, which are functionally significant sub-sequences, are considered as motifs. In order to reveal such DNA motifs, our method makes use of Fuzzy clustering of Position Weight Matrix. The Fuzzy C-Means (FCM) algorithm clearly predicted known motifs that existed in intergenic regions of GAL4, CBF1 and GCN4 DNA sequences. This paper also provides a comparison of FCM with some clustering methods such as Self-Organizing Map and K-Means. The results of the FCM algorithm is compared to the results of popular motif discovery tool Multiple Expectation Maximization for Motif Elicitation (MEME) as well. We conclude that soft-clustering-based machine learning methods such as FCM are useful to finding patterns in biological sequences.		Karabulut, M (reprint author), Cukurova Univ, Dept Elect & Elect Engn, Adana, Turkey.						DAS MK, 2007, BMC BIOINFORMATIC S7, V8, P21; Derong Liu, 2006, IEEE Transactions on Neural Networks, V17, DOI 10.1109/TNN.2006.875987; FERREIRA PG, 2007, P 2007 IEEE S COMP I; Mahony S, 2005, ARTIF INTELL REV, V24, P397, DOI 10.1007/s10462-005-9011-9; Sandve GK, 2006, BIOL DIRECT, V1, DOI 10.1186/1745-6150-1-11; SHANE T, 2005, BIOINFORMATICS, V21, P3832; TIMOTHY LB, 2006, NUCLEIC ACIDS RES, V34, P369; PROMOTER DATABSE SAC	8	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-87440-9	LECT NOTES COMPUT SC			2008	5226						189	195				7	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Computer Science	BIH57	WOS:000259555200024	
S	Dashevskiy, M; Luo, ZY		Huang, DS; Wunsch, DC; Levine, DS; Jo, KH		Dashevskiy, Mikhail; Luo, Zhiyuan			Reliable probabilistic classification and its application to internet traffic	ADVANCED INTELLIGENT COMPUTING THEORIES AND APPLICATIONS, PROCEEDINGS: WITH ASPECTS OF THEORETICAL AND METHODOLOGICAL ISSUES	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	4th International Conference on Intelligent Computing	SEP 15-18, 2008	Shanghai, PEOPLES R CHINA					Many machine learning algorithms have been used to classify network traffic flows with good performance, but without information about the reliability in classifications. In this paper, we present a recently developed algorithmic framework, namely the Venn Probability Machine, for making reliable decisions under uncertainty. Experiments on publicly available real traffic datasets show the algorithmic framework works well. Comparison is also made to the published results.		Dashevskiy, M (reprint author), Univ London, Comp Learning Res Ctr, Egham TW20 0EX, Surrey, England.						ANDREW M, 2005, RR0513 U LOND DEP CO; ANDREW M, 2005, SIGMETRICS 2005, P50; Auld T, 2007, IEEE T NEURAL NETWOR, V18, P223, DOI 10.1109/TNN.2006.883010; COSMAS JP, 1996, P IFIP WORKSH TC6 4; DENIS Z, 2005, PAM, P321; Vovk V., 2005, ALGORITHMIC LEARNING; Williams N, 2006, COMPUT COMMUN REV, V36, P7; Yu L, 2004, J MACH LEARN RES, V5, P1205; YUNHAO L, 2003, IEEE INT C COMM, V2, P1375, DOI 10.1109/ICC.2003.1204614; Zander S, 2005, IEEE C LOC COMP NETW, P250, DOI 10.1109/LCN.2005.35	10	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-87440-9	LECT NOTES COMPUT SC			2008	5226						380	388				9	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Computer Science	BIH57	WOS:000259555200048	
S	Huang, CJ; Luo, YC; Chen, CH; Chang, TY; Hu, KW; Wu, TH; Huang, KL		Huang, DS; Wunsch, DC; Levine, DS; Jo, KH		Huang, Chenn-Jung; Luo, Yun-Cheng; Chen, Chun-Hua; Chang, Tun-Yu; Hu, Kai-Wen; Wu, Tsung-Hsien; Huang, Kuo-Liang			A learning assistance tool for enhancing ICT application ability of elementary and secondary school students	ADVANCED INTELLIGENT COMPUTING THEORIES AND APPLICATIONS, PROCEEDINGS: WITH ASPECTS OF THEORETICAL AND METHODOLOGICAL ISSUES	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	4th International Conference on Intelligent Computing	SEP 15-18, 2008	Shanghai, PEOPLES R CHINA					In recent years, developing useful learning assistance systems has become a hot research topic in the literature. The learner can be benefited by the useful guidance provided by the learning assistance tool. An effective learning assistance tool can reduce the teaching load of the teacher. However, it is rarely seen that a learning assistance tool employs machine learning techniques to provide appropriate diagnosis or feedback to learners or teachers in the literature. We thus propose a learning assistance tool that employs reinforcement learning technique to continuously interact with the environment in order to offer learners suitable and timely feedback, guide them through the difficulties. Our experimental results reveal that our learning assistance tool can effectively enhance the learners' ICT application ability and assist the learners in overcoming difficulties. The teaching load of the teacher is also significantly reduced.		Huang, CJ (reprint author), Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Hualien, Taiwan.						Barsky DB, 1997, SECOND AIZU INTERNATIONAL SYMPOSIUM ON PARALLEL ALGORITHMS/ARCHITECTURE SYNTHESIS, PROCEEDINGS, P356; BLUMBERG B, 2002, P ACM SIGGRAPH; CHANG GE, 2005, PROMOTING INFORM TAL; EVANS R, 2002, AI GAME PROGRAMMING, P567; HUANG CJ, 2007, P 2007 TAIW AC NETW; ISBELL C, 2001, 5 INT C AUT AG; Kaplan F, 2002, ROBOT AUTON SYST, V38, P197, DOI 10.1016/S0921-8890(02)00168-9; McGough J., 2001, 31 ASEE IEEE FRONT E, V3, P3; MELIS E, 2007, 8 INT C TECHN MATH T; Shafarenko A, 2000, IWALT 2000: INTERNATIONAL WORKSHOP ON ADVANCED LEARNING TECHNOLOGIES, P97	10	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-87440-9	LECT NOTES COMPUT SC			2008	5226						661	668				8	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Computer Science	BIH57	WOS:000259555200082	
S	Fu, JQ; Li, J; Wang, L		Huang, DS; Wunsch, DC; Levine, DS; Jo, KH		Fu, Jingqi; Li, Jing; Wang, Ling			Multi-parameter differential pressure flowmeter nonlinear calibration based on SVM	ADVANCED INTELLIGENT COMPUTING THEORIES AND APPLICATIONS, PROCEEDINGS: WITH ASPECTS OF THEORETICAL AND METHODOLOGICAL ISSUES	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	4th International Conference on Intelligent Computing	SEP 15-18, 2008	Shanghai, PEOPLES R CHINA					In this paper, a novel modeling method of difference pressure mass flow measurement nonlinear correction based on Support Vector Machine is introduced. Support Vector Machine is a novel machine learning method, which identify the correction model definitely just according to the samples. Flow measurement nonlinear correction is a small sample problem. The result of the simulation for orifice flowmeter error correction based on SVM shows that this method can get a better effect.		Fu, JQ (reprint author), Shanghai Univ, Shanghai Key Lab Power Stn Automat Technol, Sch Mechatron & Automat, Shanghai 200072, Peoples R China.						Chang C.-C., 2007, LIBSVM LIB SUPPORT V; CHEN W, 2004, MECH ELECT, P8; Hsu C.W., 2008, PRACTICAL GUIDE SUPP; Nello C., 2006, INTRO SUPPORT VECTOR; RONG H, 2005, APPL SUPPORT VECTOR, P501; WEI YM, 2006, J DATA ACQUISITION S, V21, P218	6	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-87440-9	LECT NOTES COMPUT SC			2008	5226						896	903				8	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Computer Science	BIH57	WOS:000259555200110	
J	Zollo, L; Eskiizmirliler, S; Teti, G; Laschi, C; Burnod, Y; Guglielmelli, E; Maier, MA				Zollo, Loredana; Eskiizmirliler, Selim; Teti, Giancarlo; Laschi, Cecilia; Burnod, Yves; Guglielmelli, Eugenio; Maier, Marc A.			An anthropomorphic robotic platform for progressive and adaptive sensorimotor learning	ADVANCED ROBOTICS			English	Article						sensorimotor control; humanoid and anthropomorphic robots; machine learning; reach-and-grasp	REACHING MOVEMENTS; NEURAL-NETWORK; ARM MOVEMENT; HAND; CEREBELLUM; HUMANS; DESIGN; MONKEY; TASK	In recent years, advances and improvements in engineering and robotics have in part been due to strengthened interactions with the biological sciences. Robots that mimic the complexity and adaptability of biological systems have become a central goal in research and development in robotics. Usually, such a collaboration is addressed to a 2-fold perspective of (i) setting up anthropomorphic platforms as test beds for studies in neuroscience and (ii) promoting new mechatronic and robotic technologies for the development of bio-inspired or humanoid high-performance robotic platforms. This paper provides a brief overview of recent studies on sensorimotor coordination in human motor control and proposes a novel paradigm of adaptive learning for sensorimotor control, based on a multi-network high-level control architecture. The proposed neurobiologically inspired model has been applied to a robotic platform, purposely designed to provide anthropomorphic solutions to neuroscientific requirements. The goal of this work is to use the bio-inspired robotic platform as a test bed for validating the proposed model of high-level sensorimotor control, with the aim of demonstrating adaptive and modular control based on acquired competences, with a higher degree of flexibility and generality than conventional robotic controllers, while preserving their robustness. To this purpose, a set of object-dependent, visually guided reach-and-grasp tasks and the associated training phases were first implemented in a multi-network control architecture in simulation. Subsequently, the offline learning realized in simulation was used to produce the input command of reach-and-grasp to the low-level position control of the robotic platform. Experimental trials demonstrated that the adaptive and modular high-level control allowed reaching and grasping of objects located at different positions and objects of variable size, shape and orientation. A future goal would be to address autonomous and progressive learning based on growing competences. (C) Koninklijke Brill NV, Leiden and The Robotics Society of Japan, 2008.	[Zollo, Loredana; Guglielmelli, Eugenio] Lab Biomed Robot Biomicrosyst, I-00128 Rome, Italy; [Eskiizmirliler, Selim; Burnod, Yves; Maier, Marc A.] Univ Paris 06, INSERM, ANIM, F-75005 Paris, France; [Eskiizmirliler, Selim; Burnod, Yves; Maier, Marc A.] Univ Paris 06, F-75005 Paris, France; [Eskiizmirliler, Selim; Burnod, Yves; Maier, Marc A.] Univ Paris 06, UMR S 742, ANiM, F-75005 Paris, France; [Eskiizmirliler, Selim; Maier, Marc A.] Univ Paris Diderot, UMR S 742, ANiM, F-75013 Paris, France; [Teti, Giancarlo; Laschi, Cecilia] Scuola Super Sant Anna, ARTS Lab, I-56025 Pontedera, PI, Italy	Zollo, L (reprint author), Lab Biomed Robot Biomicrosyst, Univ Campus Bio Med, I-00128 Rome, Italy.	1.zollo@unicampus.it					ABDELMALEK K, UNPUB SAE DIGITAL HU; Beccai L, 2005, SENSOR ACTUAT A-PHYS, V120, P370, DOI 10.1016/j.sna.2005.01.007; Beer RD, 1998, CURR OPIN NEUROBIOL, V8, P777, DOI 10.1016/S0959-4388(98)80121-9; Burnod Y, 1999, EXP BRAIN RES, V129, P325, DOI 10.1007/s002210050902; Carenzi F, 2004, NEUROCOMPUTING, V58, P525, DOI 10.1016/j.neucom.2004.01.090; Carrozza MC, 2004, AUTON ROBOT, V16, P125, DOI 10.1023/B:AURO.0000016863.48502.98; Crawford JD, 2004, J NEUROPHYSIOL, V92, P10, DOI 10.1152/jn.00117.2004; CREUTZFELDT OD, 1977, NATURWISSENSCHAFTEN, V64, P507, DOI 10.1007/BF00483547; DARIO P, 2002, P IARP 2002 3 INT WO, P97; ESKIIZMIRLILER S, 2006, P RAS EMBS INT C BIO; Ferraina S, 1997, J NEUROPHYSIOL, V77, P1034; Flanagan JR, 2003, NATURE, V424, P769, DOI 10.1038/nature01861; FLANDERS M, 1989, J NEUROSCI, V9, P447; Formica D, 2006, J DYN SYST-T ASME, V128, P152, DOI 10.1115/1.2173009; GEORGOPOULOS AP, 1991, ANNU REV NEUROSCI, V14, P361, DOI 10.1146/annurev.neuro.14.1.361; GEORGOPOULOS AP, 1981, J NEUROPHYSIOL, V46, P725; GOODALE MA, 1992, TRENDS NEUROSCI, V15, P20, DOI 10.1016/0166-2236(92)90344-8; Hamill J., 1995, BIOMECHANICAL BASIS; Jordan MI, 1999, COGNITIVE NEUROSCIEN; Kalaska JF, 1997, CURR OPIN NEUROBIOL, V7, P849, DOI 10.1016/S0959-4388(97)80146-8; Kapandji I.A., 1982, PHYSL JOINTS, V1; KATAYAMA M, 1993, BIOL CYBERN, V69, P353, DOI 10.1007/BF00199435; Katayama M, 1998, P ANN INT IEEE EMBS, V20, P2370; Kawato M, 2000, ROBOTICS RESEARCH, P321; Laschi C., 2002, Proceedings IEEE/RSJ International Conference on Intelligent Robots and Systems (Cat. No.02CH37332C), DOI 10.1109/IRDS.2002.1041653; Massa B., 2002, P IEEE INT C ROB AUT, V4, P3374, DOI 10.1109/ROBOT.2002.1014232; MASSONE LLE, 1998, HDB BRAIN THEORY NEU, P860; MIALL RC, 1998, HDB BRAIN THEORY NEU, P597; MIALL RC, 1993, J MOTOR BEHAV, V25, P203; MICHAEL JA, 1966, VISION RES, V6, P707, DOI 10.1016/0042-6989(66)90082-4; Murata A, 2000, J NEUROPHYSIOL, V83, P2580; Rizzolatti G, 2001, NEURON, V31, P889, DOI 10.1016/S0896-6273(01)00423-8; ROBINSON DA, 1986, BIOL CYBERN, V55, P43, DOI 10.1007/BF00363977; SANDINI G, 2003, SENSORS SENSING BIOL, P109; SANGER TD, 1994, IEEE T ROBOTIC AUTOM, V10, P323, DOI 10.1109/70.294207; Schaal S., 1997, TRH209 ATR HUM INF P; Schweighofer N, 1998, EUR J NEUROSCI, V10, P86, DOI 10.1046/j.1460-9568.1998.00006.x; Stein B.E., 1993, MERGING SENSES; THIBODEAU G, 1996, ANATOMY PHYSL; Vijayakumar S., 2000, P 17 INT C MACH LEAR, P1079; Webb B., 2001, BIOROBOTICS METHODS; WESTLING G, 1987, EXP BRAIN RES, V66, P128; Zollo L, 2005, J DYN SYST-T ASME, V127, P321, DOI 10.1115/1.1978911; Zollo L, 2007, IEEE-ASME T MECH, V12, P418, DOI 10.1109/TMECH.2007.901936; Zollo L, 2005, J ROBOTIC SYST, V22, P397, DOI 10.1002/rob.20075; ZOLLO L, 2005, P IEEE C ROB AUT BAR, P12, DOI 10.1109/ROBOT.2005.1570089; Zollo L, 2003, ROBOT AUTON SYST, V44, P101, DOI 10.1016/S0921-8890(03)00042-3	47	2	2	VSP BV	LEIDEN	BRILL ACADEMIC PUBLISHERS, PO BOX 9000, 2300 PA LEIDEN, NETHERLANDS	0169-1864		ADV ROBOTICS	Adv. Robot.		2008	22	1					91	118		10.1163/156855308X291854		28	Robotics	Robotics	283HI	WOS:000254626900005	
J	Mayer, H; Gomez, F; Wierstra, D; Nagy, I; Knoll, A; Schmidhuber, J				Mayer, Hermann; Gomez, Faustino; Wierstra, Daan; Nagy, Istvan; Knoll, Alois; Schmidhuber, Juergen			A System for Robotic Heart Surgery that Learns to Tie Knots Using Recurrent Neural Networks	ADVANCED ROBOTICS			English	Article						Supervised learning; recurrent neural networks; artificial evolution; minimally invasive surgery; automated knot tying	LSTM	Tying suture knots is a time-consuming task performed frequently during minimally invasive Surgery (MIS). Automating this task could greatly reduce total surgery time for patients. Current solutions to this problem replay manually programmed trajectories, but a more general and robust approach is to use Supervised machine learning to smooth surgeon-given training trajectories and generalize from them. Since knot tying generally requires a controller with internal memory to distinguish between identical inputs that require different actions at different points along a trajectory, it would be impossible to teach the system using traditional feedforward neural nets or support vector machines. Instead we exploit more powerful, recurrent neural networks (RNNs) with adaptive internal states. Results obtained using long short-term memory RNNs trained by the recent Evolino algorithm show that this approach can significantly increase the efficiency of suture knot tying in MIS over preprogrammed control. (C) Koninklijke Brill NV, Leiden and The Robotics Society of Japan, 2008	[Gomez, Faustino; Wierstra, Daan; Schmidhuber, Juergen] IDSIA, CH-6928 Manno Lugano, Switzerland; [Mayer, Hermann; Nagy, Istvan; Knoll, Alois; Schmidhuber, Juergen] Tech Univ Munich, Dept Embedded Syst & Robot, D-85748 Garching, Germany	Gomez, F (reprint author), IDSIA, CH-6928 Manno Lugano, Switzerland.	tino@idsia.ch			SNF [200020-107534]; EU MindRaces [FP6 511931]	This research was partially funded by SNF grant 200020-107534 and the EU MindRaces project FP6 511931.	GarciaRuiz A, 1997, J LAPAROENDOSC ADV A, V7, P277, DOI 10.1089/lap.1997.7.277; Garcia-Ruiz A, 1998, ARCH SURG-CHICAGO, V133, P957, DOI 10.1001/archsurg.133.9.957; Gers FA, 2001, IEEE T NEURAL NETWOR, V12, P1333, DOI 10.1109/72.963769; Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015; GOMEZ FJ, 2003, AIRT03303 U TEX AUST; Guthart G. S., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), DOI 10.1109/ROBOT.2000.844121; Hochreiter S., 2001, FIELD GUIDE DYNAMICA, P237, DOI 10.1109/9780470544037.ch14; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735; Kang H., 2002, THESIS RENSSELAER PO; Maillard E. P., 1997, P INT C NEUR NETW, P2187, DOI 10.1109/ICNN.1997.614247; Mayer H, 2007, IEEE INT CONF ROBOT, P1800, DOI 10.1109/ROBOT.2007.363583; Mayer H., 2006, P IEEE RSJ INT C INT, P543; Mayer H., 2004, P IEEE RSJ INT C INT, P3637; Moriarty DE, 1996, MACH LEARN, V22, P11, DOI 10.1007/BF00114722; NAGY I, 2004, P IEEE C MECH ROB ME, P1464; Penrose R, 1955, P CAMBRIDGE PHILOS S, V51, P406; ROBINSON AJ, 1987, CUEDFINFENGTR1 CAMBR; Schmidhuber J., 2005, P 19 INT JOINT C ART, P853; Schmichuber J, 2007, NEURAL COMPUT, V19, P757, DOI 10.1162/neco.2007.19.3.757; SIEGELMANN HT, 1991, APPL MATH LETT, V4, P77, DOI 10.1016/0893-9659(91)90080-F; Vapnik V. N, 1995, NATURE STAT LEARNING; WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337; Wierstra D., 2005, P 2005 C GEN EV COMP, P1795, DOI 10.1145/1068009.1068315; Williams R. J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.270	24	0	0	VSP BV	LEIDEN	BRILL ACADEMIC PUBLISHERS, PO BOX 9000, 2300 PA LEIDEN, NETHERLANDS	0169-1864		ADV ROBOTICS	Adv. Robot.		2008	22	13-14					1521	1537		10.1163/156855308X360604		17	Robotics	Robotics	398DN	WOS:000262712900007	
S	Thongkam, J; Xu, GD; Zhang, YC; Huang, FC		Ishikawa, Y; He, J; Xu, GD; Shi, Y; Huang, GY; Pang, C; Zhang, Q; Wang, G		Thongkam, Jaree; Xu, Guandong; Zhang, Yanchun; Huang, Fuchun			Support Vector Machine for Outlier Detection in Breast Cancer Survivability Prediction	ADVANCED WEB AND NETWORK TECHNOLOGIES, AND APPLICATIONS	Lecture Notes in Computer Science		English	Proceedings Paper	10th Asia-Pacific Web Conference and Workshops	APR 26-28, 2008	Shenyang, PEOPLES R CHINA	APWeb Streering Comm, WISE Soc		Outlier Detection System; C-Support Vector Classification Filter (C-SVCF); Breast Cancer Survivability	CLASSIFICATION PROBLEMS; ELIMINATION	Finding, and removing misclassified instances are important steps ill data mining and machine learning that affect the performance of the data mining algorithm in general. In this paper, we propose a C-Support Vector Classification Filter (C-SVCF) to identify and remove the misclassified instances (outliers) in breast cancer survivability samples collected from Srinagarind hospital in Thailand, to improve the accuracy of the prediction models, Only instances that are correctly classified by the filter are passed to the learning algorithm. Performance of the proposed technique is measured with accuracy and area under the receiver operating characteristic curve (AUC), as well as compared with several popular ensemble filter approaches including AdaBoost, Bagging and ensemble of SVM with AdaBoost and Bagging filters. Our empirical results indicate that C-SVCF is an effective method for identifying misclassified outliers. This approach significantly benefits ongoing research of developing accurate and robust prediction models for breast cancer survivability.	[Thongkam, Jaree; Xu, Guandong; Zhang, Yanchun; Huang, Fuchun] Victoria Univ, Sch Comp Sci & Math, Melbourne, Vic 8001, Australia	Thongkam, J (reprint author), Victoria Univ, Sch Comp Sci & Math, Melbourne, Vic 8001, Australia.	jaree@csm.vu.edu.au; xu@csm.vu.edu.au; yzhang@csm.vu.edu.au; fuchun@csm.vu.edu.au; xu@csm.vu.edu.au					BLANCO A, 2007, P 9 INT WORK C ART N, P903; BRODLEY CE, 1996, J ARTIFICIAL INTELLI, V1; Brodley CE, 1999, J ARTIF INTELL RES, V11, P131; CHANG C. C., LIBSVM LIB SUPPORT V; Gamberger D, 2000, APPL ARTIF INTELL, V14, P205, DOI 10.1080/088395100117124; Han J, 2006, DATA MINING CONCEPTS; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; HE X, 2006, IEEE T MED IMAGING, P979; Hristovski D, 2005, INT J MED INFORM, V74, P289, DOI 10.1016/j.ijmedinf.2004.04.024; Huang J, 2005, IEEE T KNOWL DATA EN, V17, P299; JIANG Y, 2007, INT JOINT C NEUR NET, P2551; John G. H., 1995, P 1 INT C KNOWL DISC, P174; Khoshgoftaar TM, 2004, PROCEEDINGS OF THE 2004 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI-2004), P302, DOI 10.1109/IRI.2004.1431478; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Lallich S., 2002, P 13 INT S FDN INT S, P5; LI J, 2005, P 11 ACM SIGKDD INT, P770, DOI 10.1145/1081870.1081971; Muhlenbach F, 2004, J INTELL INF SYST, V22, P89, DOI 10.1023/A:1025832930864; SUN JW, 2007, FUTURE GENER COMP SY, P244, DOI 10.1109/FGCN.2007.146; TENG CM, 2003, P 3 IEEE INT C DAT M, P743; THONGKAM J, 2007, J KORN KEN U; Tsumoto S, 2000, P INT COMP SOFTW APP, V24, P467; Vapnik VN, 1998, STAT LEARNING THEORY; Verbaeten S, 2003, LECT NOTES COMPUT SC, V2709, P317; Witten I. H., 2005, DATA MINING PRACTICA; Woods K, 1997, IEEE T MED IMAGING, V16, P329, DOI 10.1109/42.585767; Xiao YD, 2005, Proceedings of the 2005 IEEE International Conference on Information Reuse and Integration, P205; YI W, 2006, P 25 CHIN CONTR C, P1853; YIN Z, 2006, MULT COMP ENG SYST A, P581	28	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-89375-2	LECT NOTES COMPUT SC			2008	4977						99	109				11	Computer Science, Information Systems; Computer Science, Theory & Methods; Telecommunications	Computer Science; Telecommunications	BIV33	WOS:000263139900010	
S	Hamdi-Cherif, A; Kara-Mohammed, C; Hamdi-Cherif, A		Harkiolakis, N; Halkia, D; Mastorakis, N; Niola, V; Hebei, X; Catsigeras, E		Hamdi-Cherif, Aboubekeur; Kara-Mohammed, Chafia; Hamdi-Cherif, Alias			Agent-based elearning environment	ADVANCES IN APPLIED MATHEMATICS, SYSTEMS, COMMUNICATIONS AND COMPUTERS	Mathematics and Computers in Science and Engineering		English	Proceedings Paper	Conference on Advances in Applied Mathematics, Systems, Communications and Computers	JUN 01-03, 2008	Marathon Beach, GREECE	Hellen Amer Univ, Hellen Amer Union, N Atlant Univ Union		advanced learning technology (ALT); elearning infostructure; distance education; web-based instruction; multiagents; machine learning; learning from experience		We describe an attempt of bridging the gap between web-based learning and agents capable of learning from experience. The emphasis is made on the interaction between two core fields, namely agents and Unified Modeling Language (UML) as a standard for Object Oriented Design. The tangible results remain the integration of agents for elearning based on machine learning methods such as entropy-based Decision Tree Learning, AdaBoost and First Order Inductive Learning (FOIL). As a special case of soft computing methods, fuzzy agents are used for profile personalization. Prospectively, much effort is still required to meet the actual challenges so as to scale up to real-life problems of any significant complexity.	UFAS, Fac Engn, Dept Comp Sci, Setif 19000, Algeria	Hamdi-Cherif, A (reprint author), UFAS, Fac Engn, Dept Comp Sci, Setif 19000, Algeria.	cherif@ksu.edu.sa; smhmd@qu.edu.sa	Hamdi-Cherif, Aboubekeur/B-5540-2009				CHAN TW, 1996, J ARTIFICIAL INTELLI, V7, P125; Conallen J., 2000, BUILDING WEB APPL UM; CONATI C, 2000, P AAAI FALL S SOC IN; COX E, 1994, HDB FUZZY SYSTEMS; HAMDICHERIF A, 2007, UML BASED ELEARNING; HAMDICHERIF A, 2007, COREFIR VIRTUAL U US; Hamdi-Cherif A, 2008, ELE COM ENG, P61; HAMDICHERIF A, 2004, INT C INF COMP SYST, P115; HAMDICHERIF A, 2007, DTL 1 ORDER INDUCTIV; HARBOUCHE K, 2002, INT E LEARN S DUB UN; HARBOUCHE K, 2004, 1 ELBAHA TECHN M BTM, P34; Johnson W. L., 2000, INT J ARTIFICIAL INT, V11, P47; MANSOURI D, 2004, 1 ELBAHA TECHN M BTM, P66; MANSOURI D, 2002, INT E LEARN S DUB UN; Mitchell T, 1997, MACHINE LEARNING; Nwana HS, 1996, KNOWL ENG REV, V11, P205; Ritter S., 1996, Journal of Artificial Intelligence in Education, V7; VASSILEVA J, 2001, P WORKSH MULT AG ARC, P3; Vassileva J., 1999, P AIED 99 MANS FRANC, P38; WEBBER C, 2002, 2 LEVEL MULTIAGENT A; ZAPATARIVERA JD, 2001, ARTIF INTELL, P446	21	0	0	WORLD SCIENTIFIC AND ENGINEERING ACAD AND SOC	ATHENS	AG LOANNOU THEOLOGOU 17-23, 15773 ZOGRAPHOU, ATHENS, GREECE	1792-4308	978-960-6766-69-5	MATH COMPUT SCI ENG			2008							81	87				7	Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic; Mathematics, Applied; Telecommunications	Computer Science; Engineering; Mathematics; Telecommunications	BIA92	WOS:000257984000013	
S	Annett, M; Kondrak, G		Bergler, S		Annett, Michelle; Kondrak, Grzegorz			A comparison of sentiment analysis techniques: Polarizing movie blogs	ADVANCES IN ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	21st Conference of the Canadian-Society-for-Computational-Studies-of-Intelligence	MAY 28-30, 2008	Windsor, CANADA	Canadian Soc Computat Studies Intelligence				With the ever-growing popularity of online media such as blogs and social networking sites, the Internet is a valuable source of information for product and service reviews. Attempting to classify a subset of these documents using polarity metrics can be a daunting task. After a survey of previous research on sentiment polarity, we propose a novel approach based on Support Vector Machines. We compare our method to previously proposed lexical-based and machine learning (ML) approaches by applying it to a publicly available set of movie reviews. Our algorithm will be integrated within a blog visualization tool.	[Annett, Michelle; Kondrak, Grzegorz] Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2M7, Canada	Annett, M (reprint author), Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2M7, Canada.						AKSHAY J, 2007, P 22 AAAI C ART INT, P1933; ANDREEVSKAIA A, 2007, INT C WEBL SOC MED I; Durant K.T., 2006, P WORKSH WEB MIN WEB; Fellbaum C, 1998, LANGUAGE SPEECH COMM; HATZIVASSILOGLO.V, 2000, P 18 INT C COMP LING; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; Kamps J., 2004, LREC 2004, VIV, P1115; KENNEDY A, 2006, COMPUT INTELL, P110; Ogilvie D. M., 1966, GEN INQUIRER COMPUTE; Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79; Sato N, 2007, LECT NOTES COMPUT SC, V4557, P526; TIRAPAT T, 2006, P 6 INT C WEB ENG PA, P169, DOI 10.1145/1145581.1145619; Toutanova K, 2000, PROCEEDINGS OF THE 2000 JOINT SIGDAT CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND VERY LARGE CORPORA, P63; Turney P., 2002, P 40 ANN M ASS COMP, P417; Turney PD, 2003, ACM T INFORM SYST, V21, P315, DOI 10.1145/944012.944013; Witten H. I., 2005, DATA MINING PRACTICA	16	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-68821-1	LECT NOTES ARTIF INT			2008	5032						25	35				11	Computer Science, Artificial Intelligence	Computer Science	BHT54	WOS:000256248500003	
S	Karimi, K; Hamilton, HJ		Bergler, S		Karimi, Kamran; Hamilton, Howard J.			Using dependence diagrams to summarize decision rule sets	ADVANCES IN ARTIFICIAL INTELLIGENCE	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	21st Conference of the Canadian-Society-for-Computational-Studies-of-Intelligence	MAY 28-30, 2008	Windsor, CANADA	Canadian Soc Computat Studies Intelligence				Generating decision rule sets from observational data is an established branch of machine learning. Although such rules may be well-suited to machine execution, a human being may have problems interpreting them. Making inferences about the dependencies of a number of attributes on each other by looking at the rules is hard, hence the need to summarize and visualize a rule set. In this paper we propose using dependence diagrams as a means of illustrating the amount of influence each attribute has on others. Such information is useful in both causal and non-causal contexts. We provide examples of dependence diagrams using rules extracted from two datasets.	[Karimi, Kamran] Lakehead Univ, Dept Software Engn, Thunder Bay, ON P7B 5E1, Canada	Karimi, K (reprint author), Lakehead Univ, Dept Software Engn, Thunder Bay, ON P7B 5E1, Canada.	kkarimi@lakeheadu.ca; hamilton@cs.uregina.ca					Breiman L, 1984, CLASSIFICATION REGRE; BRUNK C, 1997, 3 C KNOWL DISC DAT M; KARIMI K, 2003, LNCS LNAI, V2903, P175; Karimi K, 2003, LECT NOTES ARTIF INT, V2637, P234; Karimi K, 2002, PROC INT C TOOLS ART, P375, DOI 10.1109/TAI.2002.1180827; Kohavi R, 1995, LECT NOTES ARTIF INT, V912, P174; MICHALSKI RS, 1978, UIUCDCSR78897; Pearl J, 2000, CAUSALITY MODELS REA; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; CONTENTS CHANGE TIME	10	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-68821-1	LECT NOTES ARTIF INT			2008	5032						163	172				10	Computer Science, Artificial Intelligence	Computer Science	BHT54	WOS:000256248500016	
S	Mokhov, SA		Bergler, S		Mokhov, Serguei A.			Choosing best algorithm combinations for speech processing tasks in machine learning using MARF	ADVANCES IN ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	21st Conference of the Canadian-Society-for-Computational-Studies-of-Intelligence	MAY 28-30, 2008	Windsor, CANADA	Canadian Soc Computat Studies Intelligence				This work reports experimental results in various speech processing tasks using an application based on the Modular Audio Recognition Framework (MARF) in terms of the best of the available algorithm configurations for each particular task. This study focuses on the tasks of identification of speakers' as of their gender and accent vs. who they are through machine learning. This work significantly complements a preceding statistical study undertaken only for the text-independent speaker identification.	Concordia Univ, Fac Engn & Comp Sci, Dept Comp Sci & Software Engn, SGW, Montreal, PQ, Canada	Mokhov, SA (reprint author), Concordia Univ, Fac Engn & Comp Sci, Dept Comp Sci & Software Engn, SGW, EV7-139-2, Montreal, PQ, Canada.						Abdi H., 2007, ENCY MEASUREMENT STA; BERNSEE SM, 1999, DFT PIED MASTERING F; Garcia E., 2006, COSINE SIMILARITY TE; HAMMING RW, 1950, AT&T TECH J, V29, P147; KHALIFE M, 2004, THESIS CONCORDIA U M; KISHORE A, 2007, SIMILIARITY MEASURE; Mahalanobis P., 1936, P NAT I SCI INDIA, V2, P49; MOKHOV S, 2002, MODULAR AUDIO RECOGN; MOKHOV SA, 2007, CISSE 2007 UNPUB; MOKHOV SA, 2006, DESIGN IMPLEMENTATIO; MOKHOV SA, 2007, MANAGING DISTRIBUTED; MOKHOV SA, 2008, CCCT 2008; MOKHOV SA, 2008, SEC 2008; *MARF RES DEV GROU, 2002, MOD AUD REC FRAM APP	14	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-68821-1	LECT NOTES ARTIF INT			2008	5032						216	221				6	Computer Science, Artificial Intelligence	Computer Science	BHT54	WOS:000256248500021	
S	Schuman, J; Bergler, S		Bergler, S		Schuman, Jonathan; Bergler, Sabine			The role of nominalizations in prepositional phrase attachment in GENIA	ADVANCES IN ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	21st Conference of the Canadian-Society-for-Computational-Studies-of-Intelligence	MAY 28-30, 2008	Windsor, CANADA	Canadian Soc Computat Studies Intelligence				We demonstrate the importance of nominalizations for prepositional phrase attachment for biomedical journal articles. We outline several significant features of the GENIA corpus data and compare them to Wall Street Journal Data. We evaluate a heuristics-based approach to PP attachment based on shallow chunking and domain dependent resources. We conclude that the heuristics based approach performs well, is appropriate for shallow levels of text analysis, and can easily be adapted to or used with other techniques, such as a filter after a statistical parse, or as features in a more complex machine learning environment.	[Schuman, Jonathan; Bergler, Sabine] Concordia Univ, Dept Comp Sci & Software Engn, Montreal, PQ H3G 1M8, Canada	Schuman, J (reprint author), Concordia Univ, Dept Comp Sci & Software Engn, 1455 Maisoonneuve Blvd W, Montreal, PQ H3G 1M8, Canada.						Baker Collin F., 1998, P COLING ACL MONTR C; Cunningham H, 2002, COMPUT HUMANITIES, V36, P223, DOI 10.1023/A:1014348124664; HAHN U, 2002, P 7 PAC S BIOC HAW U; Kim J, 2003, BIOINFORMATICS S1, V19, P180, DOI DOI 10.1093/BIOINFORMATICS/BTG1023; KIMBALL J, 1973, COGNITION, V2, P15, DOI 10.1016/0010-0277(72)90028-5; Kipper K., 2000, P 7 NAT C ART INT AA; LITKOWSKI K, 2006, P 3 ACL SIGSEM WORKS; LITKOWSKI KC, 2005, P 2 ACL SIGSEM WORKS; MERLO P, 2006, COMPUTATIONAL LINGUI, V32; Palmer M., 2005, COMPUTATIONAL LINGUI, V31; SAINTDIZIER P, 2005, 2 WORKSH SYNT SEM PR, P155; SAURI R, 2005, P HLT EMNLP 2005 VAN; SCHUMAN J, 2006, P BIONLP 2006 WORKSH; Shatkay H, 2003, J COMPUT BIOL, V10, P821, DOI 10.1089/106652703322756104; TATEISI Y, 2004, P IJCNLP 2004 WORKSH	15	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-68821-1	LECT NOTES ARTIF INT			2008	5032						271	282				12	Computer Science, Artificial Intelligence	Computer Science	BHT54	WOS:000256248500026	
S	Smith, R; Japkowicz, N; Dondo, M; Mason, P		Bergler, S		Smith, Reuben; Japkowicz, Nathalie; Dondo, Maxwell; Mason, Peter			Using unsupervised learning for network alert correlation	ADVANCES IN ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	21st Conference of the Canadian-Society-for-Computational-Studies-of-Intelligence	MAY 28-30, 2008	Windsor, CANADA	Canadian Soc Computat Studies Intelligence			INTRUSION DETECTION	Alert correlation systems are post-processing modules that enable intrusion analysts to find important alerts and filter false positives efficiently from the output of Intrusion Detection Systems. Typically, however, these modules require high levels of human involvement in creating the system and/or maintaining it, as patterns of attacks change as often as from month to month. We present an alert correlation system based on unsupervised machine learning algorithms that is accurate and low maintenance. The system is implemented in two stages of correlation. At the first stage, alerts are grouped together such that each group forms one step of an attack. At the second stage, the groups created at the first stage are combined such that each combination of groups contains the alerts of precisely one full attack. We tested various implementations of the system. The most successful one relies in the first stage on a new unsupervised algorithm inspired by an existing novelty detection system, and the EM algorithm in the second stage. Our experimental results show that, with our model, the number of alerts that an analyst has to deal with is significantly reduced.	[Smith, Reuben; Japkowicz, Nathalie] Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON K1N 6N5, Canada	Smith, R (reprint author), Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON K1N 6N5, Canada.						Dain O. M., 2001, P 2001 ACM WORKSH DA, P1; DANYLIW R, ACID ANAL CONSOLE IN; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Haines J., 2003, IEEE Security & Privacy, V1, DOI 10.1109/MSECP.2003.1176995; HATALA A, 2004, P 8 C INF SYST SEC E, P84; JAPKOWICZ N, 2005, 2005155 CRR DRDC OTT; Julisch K., 2002, P 8 ACM SIGKDD INT C, P366; Kohonen T., 1995, SPRINGER SERIES INFO, V30; Laskov P, 2005, LECT NOTES COMPUT SC, V3617, P50; Lippmann R, 2000, COMPUT NETW, V34, P579, DOI 10.1016/S1389-1286(00)00139-0; NORTHCUTT S, 1999, NETWORK INTRUSION DE; NORTHCUTT S, SHADOW 2 HEURISTIC A; Roesch M., 1999, P 13 USENIX C SYST A, P229; Smith BA, 2005, CURR OPIN PEDIATR, V17, P613, DOI 10.1097/01.mop.0000176443.26872.6e; Valdes A., 2001, LNCS, V2212, P54; Zanero S., 2004, P 2004 ACM S APPL CO, P412, DOI 10.1145/967900.967988	16	5	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-68821-1	LECT NOTES ARTIF INT			2008	5032						308	319				12	Computer Science, Artificial Intelligence	Computer Science	BHT54	WOS:000256248500029	
S	Sokolova, M; Lapalme, G		Bergler, S		Sokolova, Marina; Lapalme, Guy			Verbs speak loud: Verb categories in learning polarity and strength of opinions	ADVANCES IN ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	21st Conference of the Canadian-Society-for-Computational-Studies-of-Intelligence	MAY 28-30, 2008	Windsor, CANADA	Canadian Soc Computat Studies Intelligence				We show that verbs reliably represent texts when machine learning algorithms are used to learn opinions. We identify semantic verb categories that capture essential properties of human communication. Lexical patterns are applied to construct verb-based features that represent texts in machine learning experiments. Our empirical results show that expressed actions provide a reliable accuracy in learning opinions.	[Sokolova, Marina; Lapalme, Guy] Univ Montreal, Dept Informat & Rech Operationnelle, Montreal, PQ H3C 3J7, Canada	Sokolova, M (reprint author), Univ Montreal, Dept Informat & Rech Operationnelle, Montreal, PQ H3C 3J7, Canada.						Biber Douglas, 1999, LONGMAN GRAMMAR SPOK; Boulle M, 2005, INTELL DATA ANAL, V9, P175; Etzioni O., 2005, P HUM LANG TECHN C C, P339, DOI 10.3115/1220575.1220618; FEIGUINA O, 2007, LNCS LNAI, V4830, P452; Halliday M. A. K., 2004, INTRO FUNCTIONAL GRA; HU M, 2004, P 19 NAT C ART INT A; KIM SM, 2007, P 2007 JOINT C EMP M, P1056; Leech G, 2002, COMMUNICATIVE GRAMMA; Leech Geoffrey, 2004, MEANING ENGLISH VERB; min Kim S., 2004, P 20 INT C COMP LING, P1367, DOI 10.3115/1220355.1220555; Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79; Perkins M. R., 1983, MODAL EXPRESSIONS EN; SHERBLOM J, 1984, HUM COMMUN RES, V11, P221; SOKOLOVA M, 2007, LNCS LNAI, V4830, P159; SOKOLOVA M, 2006, LNCS LNAI, V4304, P288; THOMAS M., 2006, P 2006 C EMP METH NA, P327, DOI 10.3115/1610075.1610122; Wilson T, 2006, COMPUT INTELL-US, V22, P73, DOI 10.1111/j.1467-8640.2006.00275.x; Witten I. H., 2005, DATA MINING	18	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-68821-1	LECT NOTES ARTIF INT			2008	5032						320	331				12	Computer Science, Artificial Intelligence	Computer Science	BHT54	WOS:000256248500030	
S	Fabris, F; Drago, I; Varejao, FM		Geffner, H; Prada, R; Alexandre, IM; David, N		Fabris, Fabio; Drago, Idilio; Varejao, Flavio M.			A Multi-measure Nearest Neighbor Algorithm for Time Series Classification	ADVANCES IN ARTIFICIAL INTELLIGENCE - IBERAMIA 2008, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	11th Ibero-American Conference on Artificial Intelligence	OCT 14-17, 2008	Lisbon, PORTUGAL	ADETTI, ISCTE, FCT, AEPIA, APPIA		Data Mining; Machine Learning; Time Series Classification; Multi-Measure Classifier	CLASSIFIERS	In this paper, we have evaluated some techniques for the time series classification problem. Many distance measures have been proposed as an alternative to the Euclidean Distance in the Nearest Neighbor Classifier. To verify the assumption that the combination of various similarity measures may produce a more accurate classifier, we have proposed an algorithm to combine several measures based on weights. We have carried out a set of experiments to verify the hypothesis that the new algorithm is better than the classical ones. Our results show an improvement over the well-established Nearest-Neighbor with DTW (Dynamic Time Warping), but in general, they were obtained combining few measures in each problem used in the experimental evaluation.	[Fabris, Fabio; Drago, Idilio; Varejao, Flavio M.] Univ Fed Espirito Santo, Dept Comp Sci, BR-29060900 Vitoria, ES, Brazil	Fabris, F (reprint author), Univ Fed Espirito Santo, Dept Comp Sci, BR-29060900 Vitoria, ES, Brazil.	ffabris@inf.ufes.br; idrago@inf.ufes.br; fvarejao@inf.ufes.br	David, Nuno/B-4662-2012				Agrawal R., 1995, P 21 INT C VER LARG, P490; ANTUNES CM, 2001, P WORKSH TEMP DAT MI; Bozkaya T., 1997, CIKM, P128; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daubechies I., 1992, CBMS NSF REG C SERIE; David BL., 1993, P 4 INT C FDN DAT OR, P69; Demsar J, 2006, J MACH LEARN RES, V7, P1; Devijver P. A., 1982, PATTERN RECOGNITION; Duda R. O., 2001, PATTERN CLASSIFICATI; Gusfield Dan, 1997, ALGORITHMS STRINGS T; HAMMING RW, 1950, AT&T TECH J, V29, P147; Keogh E., 2006, UCR TIME SERIES CLAS; Keogh E, 2003, DATA MIN KNOWL DISC, V7, P349, DOI 10.1023/A:1024988512476; KOHAVI R, 1997, 9 EUR C MACH LEARN P; Levenshtein V., 1966, SOV PHYS DOKL, V10, P707; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; Salzberg SL, 1997, DATA MIN KNOWL DISC, V1, P317, DOI 10.1023/A:1009752403260; SAVARY L, 2002, ECAI 2002 WORKSH KNO, P63; Sheskin D.J., 2000, HDB PARAMETRIC NONPA; Xi X., 2006, ICML 06, P1033	20	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-88308-1	LECT NOTES COMPUT SC			2008	5290						153	162				10	Computer Science, Artificial Intelligence	Computer Science	BIM81	WOS:000260922300016	
S	Reverte, J; Gallego, F; Satorre, R; Llorens, F		Geffner, H; Prada, R; Alexandre, IM; David, N		Reverte, Juan; Gallego, Francisco; Satorre, Rosana; Llorens, Faraon			Mixing Greedy and Evolutive Approaches to Improve Pursuit Strategies	ADVANCES IN ARTIFICIAL INTELLIGENCE - IBERAMIA 2008, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	11th Ibero-American Conference on Artificial Intelligence	OCT 14-17, 2008	Lisbon, PORTUGAL	ADETTI, ISCTE, FCT, AEPIA, APPIA		Multi-agent systems; communication; coordination; neuroevolution		The prey-predator pursuit problem is a generic multi-agent testbed referenced many times in literature. Algorithms and conclusions obtained in this domain can be extended and applied to many particular problems. In first place, greedy algorithms seem to do the job. But when concurrence problems arise, agent communication and coordination is needed to get a reasonable solution. It is quite popular to face these issues directly with non-supervised learning algorithms to train prey and predators. However, results got by most of these approaches still leave a great margin of improvement which should be exploited. In this paper we propose to start from a greedy strategy and extend and improve it by adding communication and machine learning. In this proposal, predator agents get a previous movement decision by using a greedy approach. Then, they focus on learning how to coordinate their own pre-decisions with the ones taken by other surrounding agents. Finally, they get a final decission trying to optimize their chase of the prey without colliding between them. For the learning step, a neuroevolution approach is used. The final results show improvements and leave room for open discussion.	[Reverte, Juan; Gallego, Francisco; Satorre, Rosana; Llorens, Faraon] Univ Alicante, Dept Comp Sci & Artificial Intelligence, Alicante, Spain	Reverte, J (reprint author), Univ Alicante, Dept Comp Sci & Artificial Intelligence, Alicante, Spain.	jreverte@dccia.ua.es; fgallego@dccia.ua.es; rosana@dccia.ua.es; faraon@dccia.ua.es	David, Nuno/B-4662-2012				Benda M., 1986, BCSG201028 BOEING AI; Chainbi W., 1996, P IMACS IEEESMC C CO, P692; Haynes T., 1995, IJCAI 95 WORKSH AD L, P32; Jim KC, 2000, ARTIF LIFE, V6, P237, DOI 10.1162/106454600568861; Katayama K., 2005, SAC 2005, P14; KOK J, 2003, IASUVA0303 U AMST; KORF RE, 1992, P 11 INT WORKSH DIST, P183; Stanley KO, 2002, EVOL COMPUT, V10, P99, DOI 10.1162/106365602320169811; Stone P, 2000, AUTON ROBOT, V8, P345, DOI 10.1023/A:1008942012299; Tan M., 1997, READINGS AGENTS, P487	10	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-88308-1	LECT NOTES COMPUT SC			2008	5290						203	212				10	Computer Science, Artificial Intelligence	Computer Science	BIM81	WOS:000260922300021	
S	Cuevas, RRM; Parabom, I		Geffner, H; Prada, R; Alexandre, IM; David, N		Moya Cuevas, Ramon Re; Parabom, Ivandre			A Machine Learning Approach to Portuguese Pronoun Resolution	ADVANCES IN ARTIFICIAL INTELLIGENCE - IBERAMIA 2008, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	11th Ibero-American Conference on Artificial Intelligence	OCT 14-17, 2008	Lisbon, PORTUGAL	ADETTI, ISCTE, FCT, AEPIA, APPIA				Anaphora resolution is an essential component of most NLP applications, from text understanding to Machine Translation. In this work we discuss a supervised machine learning approach to the problem, focusing on instances of anaphora ubiquitously found in a corpus of Brazilian Portuguese texts, namely, third-person pronominal references. Although still limited to a subset of the more general co-reference resolution problem, our present results are comparable to existing work in the field in both English and Portuguese languages, representing the highest accuracy rates that we are aware of in (Brazilian) Portuguese pronoun resolution.	[Moya Cuevas, Ramon Re; Parabom, Ivandre] Univ Sao Paulo, EACH, BR-03828000 Sao Paulo, Brazil	Cuevas, RRM (reprint author), Univ Sao Paulo, EACH, Av Arlindo Bettio 1000, BR-03828000 Sao Paulo, Brazil.	fusion@usp.br; ivandre@usp.br	David, Nuno/B-4662-2012				BICK E, 2000, THESIS AARHUS U; CHAVES A, 2007, THESIS U SAO CARLOS; COELHO TT, 2005, AN 25 C SOC BRAS COM, P2069; HOBBS JR, 1978, LINGUA, V44, P311, DOI 10.1016/0024-3841(78)90006-2; KENNEDY C, 1996, 16 INT C COMP LING C, P113; Lappin S., 1994, Computational Linguistics, V20; MCCARTHY JF, 1995, 14 INT C ART INT IJC; Mitkov R., 1999, Machine Translation, V14, DOI 10.1023/A:1011184828072; Mitkov R., 2002, ANAPHORA RESOLUTION; MOYA CRR, 2008, LNCS, V4919, P344; Ng V, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P104; PARABONI I, 1998, 17 INT C COMP LING C, P1010; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Santos DND, 2007, LECT NOTES ARTIF INT, V4827, P966; SOON WM, 2001, COMPUTATIONAL LINGUI, V27; SOUZA J, 2008, INT C COMP PROC PORT	16	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-88308-1	LECT NOTES COMPUT SC			2008	5290						262	271				10	Computer Science, Artificial Intelligence	Computer Science	BIM81	WOS:000260922300027	
S	Garcia, B; Aler, R; Ledezma, A; Sanchis, A		Geffner, H; Prada, R; Alexandre, IM; David, N		Garcia, Beatriz; Aler, Ricardo; Ledezma, Agapito; Sanchis, Araceli			Genetic Programming for Predicting Protein Networks	ADVANCES IN ARTIFICIAL INTELLIGENCE - IBERAMIA 2008, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	11th Ibero-American Conference on Artificial Intelligence	OCT 14-17, 2008	Lisbon, PORTUGAL	ADETTI, ISCTE, FCT, AEPIA, APPIA		Protein interaction prediction; genetic programming; data integration; bioinformatics; evolutionary computation; machine learning; classification; control bloat	BLOAT	One of the definitely unsolved main problems in molecular biology is the protein-protein functional association prediction problem. Genetic Programming (GP) is applied to this domain. GP evolves an expression, equivalent to a binary classifier. which predicts if a given pair of proteins interacts. We take advantages of GP flexibility. particularly, the possibility of defining new operations. In this paper, the missing values problem benefits from the definition of if-unknown. a new operation which is more appropriate to the domain data semantics. Besides, in order to improve the solution size and the computational time, we use the Tarpeian method which controls the bloat effect of GP. According to the obtained results, we have verified the feasibility of using GP in this domain, and the enhancement in the search efficiency and interpretability of solutions due to the Tarpeian method.	[Garcia, Beatriz; Aler, Ricardo; Ledezma, Agapito; Sanchis, Araceli] Univ Carlos III Madrid, Dept Comp Sci, Madrid 28911, Spain	Garcia, B (reprint author), Univ Carlos III Madrid, Dept Comp Sci, Avda Univ 30, Madrid 28911, Spain.	beatrizg@inf.uc3m.es; aler@inf.uc3m.es; ledezma@inf.uc3m.es; masm@inf.uc3m.es	David, Nuno/B-4662-2012				Butland G, 2005, NATURE, V433, P531, DOI 10.1038/nature03239; Causler B, 2004, MASS SPECTROM REV, V23, P350, DOI 10.1002/mas.10080; Fawcett T., 2003, ROC GRAPHS NOTES PRA; Fraser HB, 2004, P NATL ACAD SCI USA, V101, P9033, DOI 10.1073/pnas.0402591101; GOMEZ M, 2005, T COMPUTATIONAL SYST, V1, P1; Koza J., 1994, GENETIC PROGRAMMING; Mahler S, 2005, LECT NOTES COMPUT SC, V3447, P203; Mering Cv, 2002, NATURE, V417, P399; Poli R, 2003, LECT NOTES COMPUT SC, V2610, P204; Poli R, 2007, LECT NOTES COMPUT SC, V4445, P193; ROJAS A, 2006, SILICO TECHNOLOGIES, V6, P225; Valencia A, 2002, CURR OPIN STRUC BIOL, V12, P368, DOI 10.1016/S0959-440X(02)00333-0; Witten I. H., 2005, DATA MINING PRACTICA; Yu HY, 2004, GENOME RES, V14, P1107, DOI 10.1101/gr.1774904; ZONGKER D, 1998, LIL GP GENETIC PROGR	15	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-88308-1	LECT NOTES COMPUT SC			2008	5290						432	441				10	Computer Science, Artificial Intelligence	Computer Science	BIM81	WOS:000260922300044	
S	De Raedt, L		Zaverucha, G; LoureiroDaCosta, A		De Raedt, Luc			Logical and Relational Learning	ADVANCES IN ARTIFICIAL INTELLIGENCE - SBIA 2008, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	19th Brazilian Symposium on Artificial Intelligence	OCT 26-30, 2008	Salvador, BRAZIL		Federal Univ Bahia			I use the term logical and relational learning (LRL) to refer to the subfield of machine learning and data mining that is concerned with learning in expressive logical or relational representations. It is the union of inductive logic programming, (statistical) relational learning and multi-relational data mining and constitutes a general class of techniques and methodology for learning from structured data (such as graphs, networks, relational databases) and background knowledge. During the course of its existence, logical and relational learning has changed dramatically. Whereas early work was mainly concerned with logical issues (and even program synthesis from examples), in the 90s its focus was on the discovery, of new and interpretable knowledge from structured data, often in the form of rules or patterns. Since then Hie range of tasks to which logical and relational learning has been applied has significantly broadened and now covers almost all machine learning problems and settings. Today, there exist logical and relational learning methods for reinforcement learning, statistical learning. distance- and kernel-based learning in addition to traditional symbolic machine learning approaches. At the same time, logical and relational learning problems are appearing everywhere. Advances in intelligent systems are enabling the generation of high-level symbolic and structured data in a wide variety of domains, including the semantic web, robotics, vision, social networks, and the life sciences, which ill turn raises new challenges and opportunities for logical and relational learning. These developments have led to a new view on logical and relational learning and its role in machine learning and artificial intelligence. In this talk, I shall reflect oil this view by identifying some of the lessons learned ill logical and relational learning and formulating some challenges, for future developments.	Katholieke Univ Leuven, Dept Comp Sci, B-3001 Heverlee, Belgium	De Raedt, L (reprint author), Katholieke Univ Leuven, Dept Comp Sci, Celestijnenlaan 200 A, B-3001 Heverlee, Belgium.	luc.deraedt@cs.kuleuven.be					DERAEDT L, LOGICAL REL IN PRESS	1	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-88189-6	LECT NOTES ARTIF INT			2008	5249						1	1				1	Computer Science, Artificial Intelligence	Computer Science	BIO71	WOS:000261373200001	
S	Gomes, ER; Kowalczyk, R		Zaverucha, G; LoureiroDaCosta, A		Gomes, Eduardo Rodrigues; Kowalczyk, Ryszard			Individual and Social Behaviour in the IPA Market with RL	ADVANCES IN ARTIFICIAL INTELLIGENCE - SBIA 2008, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	19th Brazilian Symposium on Artificial Intelligence	OCT 26-30, 2008	Salvador, BRAZIL		Federal Univ Bahia	Market-based Resource Allocation; Reinforcement Learning; Multiagent Systems	ALLOCATION	Market-based mechanisms offer a promising approach for distributed resource allocation. Machine Learning been proposed to influence and optimize market-based resource allocation. In particular, Reinforcement Learning (RL) has been used to improve the allocation in terms of utility received by resource requesting agents in the Iterative Price Adjustment (IPA) mechanism. This paper analyses the individual and social behaviour of agents in the IPA market-based resource allocation with RL. In particular: it presents results of experimental investigation on the influences of the amount of learning in the agents behaviour aiming at determining how much learning is sufficient and the theoretical-experimental explanation of the agent's behaviours using game theory. game theory.	[Gomes, Eduardo Rodrigues; Kowalczyk, Ryszard] Swinburne Univ Technol, Fac Informat & Commun Technol, Hawthorn, Vic 3122, Australia	Gomes, ER (reprint author), Swinburne Univ Technol, Fac Informat & Commun Technol, John St, Hawthorn, Vic 3122, Australia.	egomes@ict.swin.edu.au; rkowalczyk@ict.swin.edu.au	Kowalczyk, Ryszard/H-4391-2011				Bowling M, 2002, ARTIF INTELL, V136, P215, DOI 10.1016/S0004-3702(02)00121-2; CHUNLIN L, 2005, P INT C INF TECHN CO, V2, P175; Claus C., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; EVERETT H, 1963, OPER RES, V11, P399, DOI 10.1287/opre.11.3.399; Fink A., 1964, J SCI HIROSHIMA U AI, V28, P89; FULDA N, 2007, IJCAI 2007, P780; GOMES ER, 2007, P 7 INT JOINT C AUT; Gomes ER, 2007, PROCEEDINGS OF THE IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON INTELLIGENT AGENT TECHNOLOGY (IAT 2007), P328; JENNERGR.P, 1973, ECONOMETRICA, V41, P965, DOI 10.2307/1913817; PREIST C, 2001, AGENTS 2001, P545; Sandholm T. W., 1996, Adaption and Learning in Multi-Agent Systems. IJCAI '95 Workshop. Proceedings; SCHNIZLER B, 2005, CATNETS WP 1 THEORET; Sen S, 1998, J EXP THEOR ARTIF IN, V10, P333, DOI 10.1080/095281398146798; Sutton R.S., 1998, REINFORCEMENT LEARNI; Wolski R, 2001, INT J HIGH PERFORM C, V15, P258, DOI 10.1177/109434200101500305; Yeo CS, 2006, SOFTWARE PRACT EXPER, V36, P1381, DOI 10.1002/spe.725	16	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-88189-6	LECT NOTES ARTIF INT			2008	5249						93	102				10	Computer Science, Artificial Intelligence	Computer Science	BIO71	WOS:000261373200015	
S	Silva, LAL; Campbell, JA; Eastaugh, N; Buxton, BF		Zaverucha, G; LoureiroDaCosta, A		Silva, Luis A. L.; Campbell, John A.; Eastaugh, Nicholas; Buxton, Bernard F.			A Case for Numerical Taxonomy in Case-Based Reasoning	ADVANCES IN ARTIFICIAL INTELLIGENCE - SBIA 2008, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	19th Brazilian Symposium on Artificial Intelligence	OCT 26-30, 2008	Salvador, BRAZIL		Federal Univ Bahia			There are applications of case-like knowledge where, on the one hand, no obvious best way to structure the material exists, and on the other, the number of cases is not large enough for machine learning to find regularities that can be used for structuring. Numerical taxonomy is proposed as a technique for determining degrees of similarity between cases under these conditions. Its effect is illustrated in a novel application for case-like knowledge: authentication of paintings.	[Silva, Luis A. L.; Campbell, John A.; Buxton, Bernard F.] UCL, Dept Comp Sci, London WC1E 6BT, England	Silva, LAL (reprint author), UCL, Dept Comp Sci, Malet Pl, London WC1E 6BT, England.	l.silva@cs.ucl.ac.uk; j.campbell@cs.ucl.ac.uk; nicholas.eastaugh@pigmentum.org; b.buxton@cs.ucl.ac.uk					CAMPBELL JA, 2004, REV ROYAL ACAD EXA A, V98, P85; Eastaugh N., 2006, INFOCUS MAGAZINE, P30; Eastaugh N., 2004, PIGMENT COMPENDIUM O; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Kolodner J.L., 1993, CASE BASED REASONING; Mantaras R. L., 2005, KNOWL ENG REV, V20, P215; POPPLE J, 1993, SHYSTER PRAGMATIC LE, P432; Silva LAL, 2007, 20 INT FLOR ART INT, P423; Sneath P. H. A., 1973, NUMERICAL TAXONOMY P	9	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-88189-6	LECT NOTES ARTIF INT			2008	5249						177	186				10	Computer Science, Artificial Intelligence	Computer Science	BIO71	WOS:000261373200023	
S	Matsubara, ET; Prati, RC; Batista, GEAPA; Monard, MC		Zaverucha, G; LoureiroDaCosta, A		Matsubara, Edson T.; Prati, Ronaldo C.; Batista, Gustavo E. A. P. A.; Monard, Maria C.			Missing Value Imputation Using a Semi-supervised Rank Aggregation Approach	ADVANCES IN ARTIFICIAL INTELLIGENCE - SBIA 2008, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	19th Brazilian Symposium on Artificial Intelligence	OCT 26-30, 2008	Salvador, BRAZIL		Federal Univ Bahia		CLASSIFIERS	One relevant problem in data quality is the presence of missing data. In cases where missing data are abundant, effective ways to deal with these absences could improve the performance of machine learning algorithms. Missing data can be treated using imputation. Imputation methods replace the missing data by values estimated from the available data. This paper presents CORAI, an imputation algorithm which is an adaption of Co-TRAINING, a multi-view semi-supervised learning algorithm. The comparison of CORAI with other imputation methods found in the literature in three data sets from UCI with different levels of missingness inserted into up to three attributes, shows that CORAI tends to perform well in data sets at greater percentages of missingness and number of attributes with missing values.	[Matsubara, Edson T.; Prati, Ronaldo C.; Batista, Gustavo E. A. P. A.; Monard, Maria C.] Univ Sao Paulo, Inst Math & Comp Sci, BR-13560970 Sao Carlos, SP, Brazil	Matsubara, ET (reprint author), Univ Sao Paulo, Inst Math & Comp Sci, POB 668, BR-13560970 Sao Carlos, SP, Brazil.	edsontm@icmc.usp.br; prati@icmc.usp.br; gbatista@icmc.usp.br; mcmonard@icmc.usp.br	Batista, Gustavo/E-9847-2011; Prati, Ronaldo/A-1211-2008	Prati, Ronaldo/0000-0001-8597-4987			Asuncion A., 2007, UCI MACHINE LEARNING; Batista GEAPA, 2003, APPL ARTIF INTELL, V17, P519, DOI 10.1080/08839510390219309; Blum A., 1998, COLT, P92; Chapelle O., 2006, SEMISUPERVISED LEARN; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Demsar J, 2006, J MACH LEARN RES, V7, P1; Goldman S. A., 2000, INT C MACH LEARN, P327; LEVY PS, 1998, ENCY BIOSTATISTICS; Little R, 1986, STAT ANAL MISSING DA; Witten I. H., 2005, DATA MINING PRACTICA; Zhou ZH, 2005, IEEE T KNOWL DATA EN, V17, P1529; Zhu Xiaojin, 2007, 1530 U WISC MAD	12	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-88189-6	LECT NOTES ARTIF INT			2008	5249						217	226				10	Computer Science, Artificial Intelligence	Computer Science	BIO71	WOS:000261373200027	
S	Zalewski, W; Lee, BD; Caetano, AMJF; Lorena, AC; Maletzke, AG; Fagundes, JJ; Saddy, C; Coy, R; Wu, FC		Bazzan, ALC; Craven, M; Martins, NF		Zalewski, Willian; Lee, Buei Diana; Caetano, Adewole M. J. F.; Lorena, Ana C.; Maletzke, Andre G.; Fagundes, Joao Jose; Saddy, Claudio; Coy, Rodrigues; Wu, Feng Chung			Evaluation of models for the recognition of hadwritten digits in medical forms	ADVANCES IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY, PROCEEDINGS	LECTURE NOTES IN BIOINFORMATICS		English	Proceedings Paper	3rd Brazilian Symposium on Bioinformatics (BSB 2008)	AUG 28-30, 2008	Santo Andre, BRAZIL	UFABC, CMCC, Brazilian Comp Soc, FAPESP, CNPq, CAPES, CLC bio, SGI		machine learning; digit recognition; medical forms	CHARACTER-RECOGNITION	Medicine has benefited widely from the use of computational techniques, which are often employed in the analysis of data generated in medical clinics. Among the computational techniques used in these analyses are those from Knowledge Discovery in Databases (KDD). In order to apply KDD techniques in the analysis of clinical data, it is often necessary to map them into an adequate structured format. This paper presents an extension in a methodology to map medical forms into structured datasets, in which a sub-system for handwritten digit recognition is added to the overall mapping system.				Lorena, Ana/A-4494-2008				Arica N, 2001, IEEE T SYST MAN CY C, V31, P216, DOI 10.1109/5326.941845; Haykin S., 1999, NEURAL NETWORKS COMP; Heutte L, 1998, PATTERN RECOGN LETT, V19, P629, DOI 10.1016/S0167-8655(98)00039-7; Lee Y., 1991, NEURAL COMPUT, V3, P440, DOI 10.1162/neco.1991.3.3.440; MALETZKE AG, 2007, MAPEAMENTO INFORM ME, P1; Trier OD, 1996, PATTERN RECOGN, V29, P641; Wang Xiaoling, 2004, Proceedings. The Fourth International Conference on Computer and Information Technology	7	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-85556-9	LECT N BIOINFORMAT			2008	5167						178	181				4	Biochemical Research Methods; Computer Science, Information Systems; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Computer Science; Mathematical & Computational Biology	BIF67	WOS:000259140500019	
S	Cheng, WW; Huellermeier, E		Althoff, KD; Bergmann, R; Minor, M; Hanft, A		Cheng, Weiwei; Huellermeier, Eyke			Learning similarity functions from qualitative feedback	ADVANCES IN CASE-BASED REASONING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	9th European Conference on Case-Based Reasoning	SEP 01-04, 2008	Trier, GERMANY	empolis GmbH, DFKI GmbH, Daimler AG			CBR	The performance of a case-based reasoning system often depends on the suitability of an underlying similarity (distance) measure, and specifying such a measure by hand can be very difficult. In this paper, we therefore develop a machine learning approach to similarity assessment. More precisely, we propose a method that learns how to combine given local similarity measures into a global one. As training information, the method merely assumes qualitative feedback in the form of similarity comparisons, revealing which of two candidate cases is more similar to a reference case. Experimental results, focusing on the ranking performance of this approach, are very promising and show that good models can be obtained with a reasonable amount of training information.	[Cheng, Weiwei; Huellermeier, Eyke] Univ Marburg, FB Math Informat, D-35032 Marburg, Germany	Cheng, WW (reprint author), Univ Marburg, FB Math Informat, D-35032 Marburg, Germany.						Asuncion A., 2007, UCI MACHINE LEARNING; Bonzano A, 1997, LECT NOTES ARTIF INT, V1266, P291; Branting LK, 2001, LECT NOTES ARTIF INT, V2080, P59; COHEN WW, 1999, J ARTIFICIAL INTELLI, V10; Cunningham P., 2008, UCDCSI200801; Herbich R, 2001, J MACH LEARN RES, V1, P245, DOI 10.1162/153244301753683717; JOACHIMS T, 2002, KDD 2002; Kendall MG, 1955, RANK CORRELATION MET; Khardon R, 2007, J MACH LEARN RES, V8, P227; Kononenko I., 1994, EUR C MACH LEARN, P171; OLEARY J, 2006, TIMES HIGHER ED SUPP; Pavlidis P, 2002, J COMPUT BIOL, V9, P401, DOI 10.1089/10665270252935539; Ricci F., 1995, LECT NOTES COMPUTER, V1010, P301; RICHTER MM, 2007, 20 INT FLAIRS C KEY; SCHOLKOPF B, 2007, LEARNING KERNELS SUP; Seung H.S., 1992, COMPUTATIONAL LEARNI, P287; Stahl A, 2003, LECT NOTES ARTIF INT, V2689, P537; Stahl A, 2001, LECT NOTES ARTIF INT, V2080, P502; STAHL A, 2002, P INT C ART INT ICAI; Stahl A, 2005, LECT NOTES ARTIF INT, V3620, P507; STAHL A, 2006, P 21 NAT C ART INT A; Torra V., 2007, MODELING DECISIONS I; Toussaint G, 2005, INT J COMPUT GEOM AP, V15, P101, DOI 10.1142/S0218195905001622; WETTSCHERECK D, 1995, LECT NOTES ARTIF INT, V1010, P347; WILKE W, 1996, EUR WORKSH CBR, P460; WU Y, 2001, LNCS, V2013, P222	26	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-85501-9	LECT NOTES ARTIF INT			2008	5239						120	134				15	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Computer Science	BIH20	WOS:000259463400008	
B	Zhdanov, A; Hendler, T; Ungerleider, L; Intrator, N		Wang, R; Gu, F; Shen, E		Zhdanov, Andrey; Hendler, Talma; Ungerleider, Leslie; Intrator, Nathan			Machine Learning Framework for Inferring Cognitive State from Magnetoencephalographic (MEG) Signals	ADVANCES IN COGNITIVE NEURODYNAMICS, PROCEEDINGS			English	Proceedings Paper	1st International Conference on Cognitive Neurodynamics	NOV 17-21, 2007	Shanghai, PEOPLES R CHINA	E China Univ Sci & Technol, Shanghai Soc Biophys, Editorial Board Cognit Neurodynam, Natl Nat Sci Fdn China, Shangai Assoc Sci & Technol, Beijing Univ Technol, Beijing Univ Aeronaut & Astronaut, Brain Sci Res Ctr, KAIST, CAS-MPG Partner Inst Computat Biol, Chinese Soc Neurosci, Chinese Soc Theoret & Appl Mech, IEEE Singapore Computat Intelligence Chapter, Int Neural Network Soc, Japanese Neural Network Soc, Nanjing Univ Aeronaut & Astronaut, Fudan Univ, Res Ctr Brain Sci, RIKEN Brain Sci Nonlinear Sci, Shanghai Univ, Shanghai Soc Nonlinar Sci, Tongji Univ, Xi an Jiaotong Univ, Zhejiang Univ			BRAIN; BCI	We develop a robust linear classification framework for inferring mental states from electrophysiological (MEG and EEG) signals. The framework is centered around the concept of temporal evolution of regularized Fisher Linear Discriminant classifier constructed from the instantaneous signal value. The value of the regularization parameter is selected to minimize the classifier error estimated by cross-validation. In addition, we build upon the proposed framework to develop a feature selection technique. We demonstrate the framework and the feature selection technique on MEG data recorded from 10 subjects in a simple visual classification experiment. We show that using a very simple adaptive feature selection strategy yields considerable improvement of classifier accuracy over the strategy that uses fixed number of features.	[Zhdanov, Andrey] Tel Aviv Univ, Tel Aviv Sourasky Med Ctr, Funct Brain Imaging Unit, IL-69978 Tel Aviv, Israel	Zhdanov, A (reprint author), Tel Aviv Univ, Tel Aviv Sourasky Med Ctr, Funct Brain Imaging Unit, IL-69978 Tel Aviv, Israel.	zhdanova@post.tau.ac.il	hendler, talma/C-7677-2012				Fabiani GE, 2004, IEEE T NEUR SYS REH, V12, P331, DOI 10.1109/TNSRE.2004.834627; Friehs GM, 2004, STROKE, V35, P2702, DOI 10.1161/01.STR.0000143235.93497.03; Haynes JD, 2006, NAT REV NEUROSCI, V7, P523, DOI 10.1038/nrn1931; Kamitani Y, 2005, NAT NEUROSCI, V8, P679, DOI 10.1038/nn1444; Lal TN, 2004, IEEE T BIO-MED ENG, V51, P1003, DOI 10.1109/TBME.2004.827827; Schroder M., 2003, P 1 INT IEEE EMBS C	6	0	0	HUMANA PRESS INC	TOTOWA	999 RIVERVIEW DR, STE 208, TOTOWA, NJ 07512-1165 USA		978-1-4020-8386-0				2008							393	397		10.1007/978-1-4020-8387-7_67		5	Neurosciences	Neurosciences & Neurology	BIR74	WOS:000262360700067	
B	Zhang, J; Zou, JZ; Wang, XY; Chen, LL		Wang, R; Gu, F; Shen, E		Zhang, Jian; Zou, Jun-zhong; Wang, Xing-yu; Chen, Lan-lan			An Improvement of Sequential Minimum Optimization Algorithm	ADVANCES IN COGNITIVE NEURODYNAMICS, PROCEEDINGS			English	Proceedings Paper	1st International Conference on Cognitive Neurodynamics	NOV 17-21, 2007	Shanghai, PEOPLES R CHINA	E China Univ Sci & Technol, Shanghai Soc Biophys, Editorial Board Cognit Neurodynam, Natl Nat Sci Fdn China, Shangai Assoc Sci & Technol, Beijing Univ Technol, Beijing Univ Aeronaut & Astronaut, Brain Sci Res Ctr, KAIST, CAS-MPG Partner Inst Computat Biol, Chinese Soc Neurosci, Chinese Soc Theoret & Appl Mech, IEEE Singapore Computat Intelligence Chapter, Int Neural Network Soc, Japanese Neural Network Soc, Nanjing Univ Aeronaut & Astronaut, Fudan Univ, Res Ctr Brain Sci, RIKEN Brain Sci Nonlinear Sci, Shanghai Univ, Shanghai Soc Nonlinar Sci, Tongji Univ, Xi an Jiaotong Univ, Zhejiang Univ		Machine learning; support vector machine; sequential minimum optimization; kernel caching	SVM CLASSIFIER DESIGN; SMO ALGORITHM	Sequential Minimum Optimization (SMO) algorithm is a good method to solve Support Vector Machine (SVM) problem. One-dimensional cache strategy is proposed to speed up SMO algorithm. Experiments have been conducted to show that the proposed method is effective. Comparing with two-dimensional array, this cache strategy has some advantages: (1) To utilize the memory by the greatest degree; (2) The size of cache is not restrained. The training process will be speed up with the growth of cache; (3) The cost of maintain work is almost zero in contrast.	[Zhang, Jian] E China Univ Sci & Technol, Sch Informat Sci & Engn, Shanghai 200237, Peoples R China	Zhang, J (reprint author), E China Univ Sci & Technol, Sch Informat Sci & Engn, Box 579,130 Meilong Rd, Shanghai 200237, Peoples R China.	zhjmaster@sina.com					Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493; Keerthi SS, 2002, MACH LEARN, V46, P351, DOI 10.1023/A:1012431217818; Platt J. C., 1999, FAST TRAINING SUPPOR, P185; Vapnik V.N., 1995, STAT LEARNING THEORY	5	0	0	HUMANA PRESS INC	TOTOWA	999 RIVERVIEW DR, STE 208, TOTOWA, NJ 07512-1165 USA		978-1-4020-8386-0				2008							1059	1063		10.1007/978-1-4020-8387-7_181		5	Neurosciences	Neurosciences & Neurology	BIR74	WOS:000262360700181	
S	Kuang, ZH; Bi, W; Wang, JH	Yan, XS	Kang, L; Cai, ZH; Liu, Y		Kuang, Zhanghui; Bi, Wei; Wang, Jiahai	Yan, XS		Competitive Hopfield Neural Network with Periodic Stochastic Dynamics for Partitional Clustering	ADVANCES IN COMPUTATION AND INTELLIGENCE, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	3rd International Conference on Intelligence Computation and Applications	DEC 19-21, 2008	Wuhan, PEOPLES R CHINA		China Univ Geosci	Partitional Clustering; Competitive Hopfield Neural Network; Periodic Stochastic Dynamics	PARTICLE SWARM OPTIMIZATION	A novel competitive Hopfield network with periodic stochastic dynamics is proposed for the NP-hard partitional clustering problem in this paper. Clustering technique has been applied to a wide range of problems, such as pattern recognition and machine learning. The aim of partitional clustering is to obtain a specified number of data sets from the original data according to certain criteria. The proposed algorithm introduces periodic stochastic dynamics, which helps the neural network escape from local minima and search a possible better solution based on the Solution which is obtained in the latest period. The performance is evaluated through several benchmark data sets. The Simulation results show that the proposed algorithm outperforms previous approaches, such as k -means, genetic algorithm, particle swarm optimization, differential evolution, combinatorial particle swarm optimization and tabu search.	[Kuang, Zhanghui; Bi, Wei; Wang, Jiahai] Sun Yat Sen Univ, Dept Comp Sci, Guangzhou 510275, Guangdong, Peoples R China	Wang, JH (reprint author), Sun Yat Sen Univ, Dept Comp Sci, 135 Xingang W Rd, Guangzhou 510275, Guangdong, Peoples R China.	kuangzhh@mail2.sysu.edu.cn; wangjiah@mail.sysu.edu.cn					Bhuyan J.N., 1991, P 4 INT C GEN ALG, P408; FORGY EW, 1965, BIOMETRICS, V21, P768; Galan-Marin G, 2003, COMPUT OPER RES, V30, P603, DOI 10.1016/S0305-0548(02)00028-X; HOPFIELD JJ, 1985, BIOL CYBERN, P142; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Jarboui B, 2007, APPL MATH COMPUT, V192, P337, DOI 10.1016/j.amc.2007.03.010; Krishna K, 1999, IEEE T SYST MAN CY B, V29, P433, DOI 10.1109/3477.764879; Liu YG, 2008, INFORM SCIENCES, V178, P2680, DOI 10.1016/j.ins.2008.01.022; Merz C., 1997, UCI REPOSITORY MACHI; Paterlini S, 2006, COMPUT STAT DATA AN, V50, P1220, DOI 10.1016/j.csda.2004.12.004	10	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-92136-3	LECT NOTES COMPUT SC			2008	5370						280	289				10	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Mathematical & Computational Biology	Computer Science; Mathematical & Computational Biology	BJB71	WOS:000264556900031	
S	Khanteymoori, AR; Homayounpour, MM; Menhaj, MB		Sarbazi-Azad, H; Parhami, B; Miremadi, SG; Hessabi, S		Khanteymoori, A. R.; Homayounpour, M. M.; Menhaj, M. B.			A Bayesian Network Based Approach for Data Classification Using Structural Learning	ADVANCES IN COMPUTER SCIENCE AND ENGINEERING	COMMUNICATIONS IN COMPUTER AND INFORMATION SCIENCE		English	Proceedings Paper	13th International-Computer-Society-of-Iran-Computer Conference	MAR 09-11, 2008	Kish Isl, IRAN			Bayesian Networks; Data Classification; Machine learning; Structural learning		This paper describes the theory and implementation of Bayesian networks in the context of data classification. Bayesian networks provide it very general and yet effective gaphical language for factoring joint probability distributions which in turn make them very popular for classification. Finding the optimal structure of Bayesian networks from data has been shown to be NP-hard. In this paper score-based algorithms Such as K2, Hill Climbing, Iterative Hill Climbing and simulated annealing have been developed to provide more efficient structure learning through more investigation on MDL, BIC and AIC scores borrowed from information theory. Our experimental results show that the BIC score is the best one though it is very time consuming. Bayesian naive classifier is the simplest Bayesian network with known structure for data classification. For the purpose of comparison, we considered several cases and applied general Bayesian networks along with this classifier to these cases. The Simulation results approved that using structural learning in order to find Bayesian networks structure improves the classification accuracy. Indeed it was shown that the Iterative Hill Climbing is the most appropriate search algorithm and K2 is the simplest one with the least time complexity.	[Khanteymoori, A. R.; Homayounpour, M. M.] AmirKabir Univ, Dept Comp Engn, Tehran, Iran	Khanteymoori, AR (reprint author), AmirKabir Univ, Dept Comp Engn, Tehran, Iran.	khanteymoori@aut.ac.ir; homayoun@aut.ac.ir; menhaj@aut.ac.ir					Cooper G. F., 1991, P 7 C UNC ART INT LO, P86; COOPER GF, 1990, ARTIF INTELL, V42, P393, DOI 10.1016/0004-3702(90)90060-D; Friedman N., 1996, P 12 C UNC ART INT, P252; Friedman N, 1998, P 14 C UNC ART INT, P139; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GYFTODIMOS E, 2004, 3 HELL C AI SETN 200; Heckerman D, 1999, LEARNING GRAPHICAL M, P301; HECKERMAN D, 1996, 9506 MICR; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; Lam W., 1994, COMPUT INTELL, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x; Murphy K., 2002, THESIS U CALIFORNIA; Pearl J., 1988, PROBABILISTIC REASON; Russell S. J., 2003, ARTIFICIAL INTELLIGE	13	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1865-0929	978-3-540-89984-6	COMM COM INF SC			2008	6						25	32				8	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BJA27	WOS:000264100100004	
S	Sanz, EP; Hidalgo, JMG; Perez, JCC		Zelkowitz, MV		Puertas Sanz, Enrique; Gomez Hidalgo, Jose Maria; Cortizo Perez, Jose Carlos			Email Spam Filtering	ADVANCES IN COMPUTERS, VOL 74: SOFTWARE DEVELOPMENT	Advances In Computers		English	Article; Book Chapter							TEXT CATEGORIZATION; RETRIEVAL	In recent years, email Spam has become an increasingly important problem, with a big economic impact in society. In this work, we present the problem of Spam, how it affects us, and how we can fight against it. We discuss legal, economic, and technical measures used to stop these unsolicited emails. Among all the technical measures, those based on content analysis have been particularly effective in filtering Spam, so we focus on them, explaining how they work in detail. In summary, we explain the structure and the process of different Machine Learning methods used for this task, and how we can make them to be cost sensitive through several methods like threshold optimization, instance weighting, or MetaCost. We also discuss how to evaluate Spam filters using basic metrics, TREC metrics, and the receiver operating characteristic convex bull method, that best suits classification problems in which target conditions are not known, as it is the case. We also describe how actual filters are used in practice. We also present different methods used by spammers to attack Spam filters and what we can expect to find in the coming years in the battle of Spam filters against spammers.	[Puertas Sanz, Enrique] Univ Europea Madrid, Madrid 28670, Spain; [Gomez Hidalgo, Jose Maria] Optenet, Madrid 28230, Spain; [Cortizo Perez, Jose Carlos] AINet Solut, Madrid 28943, Spain	Sanz, EP (reprint author), Univ Europea Madrid, Madrid 28670, Spain.						ABADI M, 2003, P 8 AS COMP SCI C MU; AHN LV, 2004, COMMUNICATION ACM; ANDERSON R, 2004, MAGAZINE ARTICL 0513; Andreas B, 2000, J HIGH ENERGY PHYS; Androutsopoulos I., 2000, P WORKSH MACH LEARN, P9; Androutsopoulos I., 2000, P 23 ANN INT ACM SIG, P160, DOI 10.1145/345508.345569; BELKIN NJ, 1992, COMMUN ACM, V35, P29, DOI 10.1145/138859.138861; BELL S, 2003, FILTERS CAUSING RASH; BICKEL S, 2006, P DISC CHALL WORKSH; Biggio B., 2007, P 4 C EM ANT CEAS 20, P2; Bratko A., 2006, J MACHINE LEARNING R, V7, P2699; BYUN B, 2007, P 4 C EM ANT CEAS 20; Caropreso MF, 2001, TEXT DATABASES AND DOCUMENT MANAGEMENT: THEORY AND PRACTICE, P78; CARRERAS X, 2001, P RANLP 2004 4 INT C; CARUSO J, 2003, NETWORLD WORLD   DEC; CLABURN T, 2005, CONSTANT STRUGGLE SP; Cleary JG, 1997, COMPUT J, V40, P67, DOI 10.1093/comjnl/40.2_and_3.67; Cohen W. W., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; CORMACK G, 2007, ACM 16 C INF KNOWL M; CORMACK GV, 2005, P CEAS 2005 2 C EM A; CORMACK GV, 2005, P TREC 2005 14 TEXT; CORMACK GV, 2006, CEAS 2006; COSOI CA, 2006, VIRUS B; Cranor LF, 1998, COMMUN ACM, V41, P74, DOI 10.1145/280324.280336; Dalvi N., 2004, P 10 ACM SIGKDD INT, P99, DOI 10.1145/1014052.1014066; DANTIN U, 2005, 18 ANN C NAT ADV COM; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288651; DWORK C, 2003, P 23 ANN INT CRYPT C; ECKELBERRY A, 2006, SECURITY PRO PORTAL; Fawcett T, 2003, SIGKDD EXPLORATIONS, V5, P140; Friedl Jeffrey EF, 2006, MASTERING REGULAR EX; Fuhr N., 1991, P RIAO 91, P606; Garcia FD, 2004, INT FED INFO PROC, V147, P395; GEE K, 2003, ACM S APPL COMP DAT; Gomez J.M., 2002, P SAC 02 17 ACM S AP, P615; GOMEZHIDALGO JM, 2000, P 4 COMP NAT LANG LE; GOMEZHIDALGO JM, 2002, P JADT 02 6 INT C ST; GOODMAN J, 2004, P 1 C EM ANT; GRAHAM P, 2003, P 2003 SPAM C; GRAHAM P, 2002, HACKERS PAINTERS BIG; GRAHAMCUMMING J, 2004, MIT SPAM C; GRAHAMCUMMING J, 2003, MIT SPAM C; GRAHAMCUMMING J, 2006, VIRUS B; GRAY A, 2004, P 1 C EM ANT CEAS; HAHN J, 2006, WEB TRENDS; HALL RJ, 1998, COMMUNICATION ACM; HIRD S, 2002, P AUUG2002 MELB; HOVOLD J, 2005, P 2 C EM ANT CEAS ST; Joachims T., 1999, P 16 INT C MACH LEAR, P200; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Keogh E., 2004, P 10 ACM SIGKDD INT, P206, DOI DOI 10.1145/1014052.1014077; KOLCZ A, 2004, P 1 C EM ANT CEAS; Larkey L. S., 1996, P SIGIR 96 19 ACM IN, P289, DOI 10.1145/243199.243276; Lewis D., 1998, LECT NOTES COMPUTER, V1398, P4, DOI DOI 10.1007/BFB0026666; Lewis D. D., 1994, P 17 ANN INT ACM SIG, P3; Li YH, 1998, COMPUT J, V41, P537, DOI 10.1093/comjnl/41.8.537; Lowd D., 2005, P 11 ACM SIGKDD INT; LUCAS MW, 2006, PGP GPG EMAIL PRACTI; McCallum A, 1998, P AAAI 98 WORKSH LEA; MEYER TA, 2004, P 1 C EM ANT CEAS; Mitchell T., 1996, MACHINE LEARNING; OBRIEN C, 2003, P INT S INF COMM TEC; Pampapathi R, 2006, MACH LEARN, V65, P309, DOI 10.1007/s10994-006-9505-y; PANTEL P, 1998, LEARN TEXT CAT PAP 1; Platt J., 1998, ADV KERNEL METHODS S; Provost F., 1997, P 3 INT C KNOWL DISC; Provost J, 1999, NAIVE BAYES VS RULE; Quinlan R, 1992, MACH LEARN, V1, P81; RIGOUTSOS I, 2004, P 1 C EM ANT CEAS; SAARINEN J, 2003, SPAMMER DUCKS COVER; Sahami M, 1998, P AAAI 98 WORKSH LEA; SAKKIS G, 2001, P EMNLP 01 6 C EMP M; Salton G., 1983, INTRO MODERN INFORM; SALTON G, 2001, SIGIR FORUM, V16, P22; SAMOSSEIKO D, 2006, P 16 VIR B INT C; SCULLEY D, 2006, DAT COMPR C DCC 06, P332, DOI 10.1109/DCC.2006.13; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; SEIGNEUR J, 2004, IEEE SECUR PRIV, V1, P35; Sergeant M., 2003, SPAM C; STERN H, 2004, CS200406 DALH U FAC; TAYLOR B, 2006, P 3 C EM ANT SPAM CE; TEAHAN WJ, 2003, LANGUAGE MODELING IN; THEO VD, 2004, NEW UPCOMING FEATURE; THOMAS R, 2006, VIRUS B C; Turing A.M., 1950, MIND, V59, P433, DOI DOI 10.1093/MIND/LIX.236.433; WATSON B, 2004, P 1 C EM ANT CEAS MO; Wiener E., 1995, P 4 ANN S DOC AN INF, P317; WITTEL GL, 2004, P C EM ANT SPAM CEAS; Witten I. H., 2000, DATA MINING PRACTICA; Yang Y., 1997, P ICML 97 14 INT C M; YANG YM, 1994, ACM T INFORM SYST, V12, P252, DOI 10.1145/183422.183424; YERAZUNIS B, 2004, P SPAM C; YERAZUNIS B, 2003, P SPAM C; ZDZIARSKI J, 2004, P SPAM C; Zimmermann P., 1995, OFFICIAL PGP USERS G; *INFOWORLD TEST CT, 2004, STRONG SPAM COMB BRU; *MESSAGELABS, 2006, MESSAGELABS INTELLIG; 2004, CONTENT FILTER NO LO	102	1	1	ELSEVIER ACADEMIC PRESS INC	SAN DIEGO	525 B STREET, SUITE 1900, SAN DIEGO, CA 92101-4495 USA	0065-2458	978-0-12-374426-5	ADV COMPUT	Adv. Comput.		2008	74						45	114		10.1016/S0065-2458(08)00603-7		70	Computer Science, Hardware & Architecture; Computer Science, Software Engineering	Computer Science	BIJ88	WOS:000260166200003	
S	An, LTH; Minh, LH; Phuc, NT; Tao, PD		Perner, P		An, Le Thi Hoai; Minh, Le Hoai; Phuc, Nguyen Trong; Tao, Pham Dinh			Noisy image segmentation by a robust clustering algorithm based on DC programming and DCA	ADVANCES IN DATA MINING, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	8th Industrial Conference on Data Mining	JUL 16-18, 2008	Leipzig, GERMANY			image segmentation; Fuzzy C-Means; DC programming; DCA	FUZZY C-MEANS	We present a fast and robust. algorithm for image segmentation problems via Fuzzy C-Means (FCM) clustering model. Our approach is based oil DC (Difference of Convex functions) programming and DCA (DC Algorithms) that have been successfully applied in a lot of various fields of Applied Sciences, including Machine Learning. In all elegant way, the FCM model is reformulated as a DC program for which a very simple DCA scheme is investigated. For accelerating the DCA, an alternative FCM-DCA procedure is developed. Moreover, ill the case of noisy images, we propose a new model that incorporates spatial information into the membership function for clustering. Experimental results oil noisy images have illustrated the effectiveness of the proposed algorithm and it's superiority with respect, to the standard FCM algorithm in both running-time and quality of solutions.	[An, Le Thi Hoai; Minh, Le Hoai; Phuc, Nguyen Trong] Univ Paul Verlaine Metz, Lab Theoret & Appl Comp Sci LITA, EA 3097, UFR MIM, F-57045 Metz, France	An, LTH (reprint author), Univ Paul Verlaine Metz, Lab Theoret & Appl Comp Sci LITA, EA 3097, UFR MIM, F-57045 Metz, France.						Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338; Bezdek J. C., 1981, PATTERN RECOGNITION; BEZDEK JC, 1993, MED PHYS, V20, P1033, DOI 10.1118/1.597000; Chuang KS, 2006, COMPUT MED IMAG GRAP, V30, P9, DOI 10.1016/j.compmedimag.2005.10.001; Dunn J. C., 1973, Journal of Cybernetics, V3; Hung WL, 2006, PATTERN RECOGN LETT, V27, P424, DOI 10.1016/j.patrec.2005.09.005; KRAUSE N, 2004, INT C MACH LEARN ICM; Le Thi H.A., 1997, CONTRIBUTION OPTIMIS; Le Thi H.A., 2005, ANN OPER RES, V133, P23; Le Thi HA, 2003, SIAM J OPTIMIZ, V14, P77; LETHI HA, 2006, J GLOBAL OPTIMIZ JUL; LETHI HA, 2006, EUROPEAN J IN PRESS; Liu YF, 2005, J COMPUT GRAPH STAT, V14, P219, DOI 10.1198/106186005X37238; Liu YF, 2006, J AM STAT ASSOC, V101, P500, DOI 10.1198/016214505000000781; Neumann J, 2004, LECT NOTES COMPUT SC, V3175, P212; Pham D. L., 2002, P IEEE INT C IM PROC; Pham Dinh T., 1998, SIAM J OPTIMIZ, V8, P476; Pham Dinh T., 1997, ACTA MATH VIETNAMICA, V22, P289; PHAM DL, 2001, IMAGE PROCESSING, V1, P722; Rajapakse JC, 1997, IEEE T MED IMAGING, V16, P176, DOI 10.1109/42.563663; RONAN C, 2006, INT C MACH LEARN ICM; Shen XT, 2003, J AM STAT ASSOC, V98, P724, DOI 10.1198/016214503000000639; Weber S., 2005, ELECT NOTES DISCR MA, V20, P313, DOI 10.1016/j.endm.2005.05.071; YUILLE AL, 2002, ADV NEURAL INFORM PR, V14; Zhang DQ, 2004, ARTIF INTELL MED, V32, P37, DOI 10.1016/j.artmed.2004.01.012	25	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-70717-2	LECT NOTES ARTIF INT			2008	5077						72	86				15	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BID00	WOS:000258494700006	
S	Malazizi, L; Neagu, D; Chaudhry, Q		Perner, P		Malazizi, Ladan; Neagu, Daniel; Chaudhry, Qasim			Improving imbalanced multidimensional dataset learner performance with artificial data generation: Density-based class-boost algorithm	ADVANCES IN DATA MINING, PROCEEDINGS: MEDICAL APPLICATIONS, E-COMMERCE, MARKETING, AND THEORETICAL ASPECTS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	8th Industrial Conference on Data Mining	JUL 16-18, 2008	Leipzig, GERMANY			imbalanced multidimensional dataset; class-boost; density-based clustering		Improving the learner performance over imbalanced and multidimensional datasets raises a challenging task for machine learning community. Although a salient characteristic in data modeling is the amount of data provided for the learner, the proportional distribution of that data in each class has also direct relationship with the classifier performance. In imbalanced datasets when data is distributed into different classes, various in size, understanding of data structure and characteristics plays an important role in improving the learner accuracy. In this paper we introduce a new approach that combines the information gained from traditional classification algorithms, confusion matrix parameters and density-based clustering to generate artificial data in order to increase the learner performance. First a classification algorithm is run on training data. Then the confusion matrix is studied and the True Positive (TP) rate of each class is measured. The class with the lowest TP rate is selected. Using density-based clustering we identify the centroid of the class and measure the samples distribution in multidimensional space in the next step. With the values gained from Probability Density Function estimations for clusters, extra samples are generated and added to the original data-set to rebalance the class proportion and the weight of different classes in the whole training set. Our method has been evaluated in terms of TP, F-Measure and also overall accuracy against a number of Demetra. (toxicology) and UCI datasets. Our method provides an insight view of the data structure and characteristics in order to identify how much and where the data need to be added for increasing the classification accuracy of the learner.								BHATTACHARVYA GK, 1977, STAT CONCEPTS METHOD; Chawla Nitesh V., 2003, 7 EUR C PRINC PRACT, P107; ERTEKIN S, 2007, CIKM 2007; FRANK E, 2003, VISUALIZING CLASS PR; Guo ZH, 2007, J HIGH ENERGY PHYS; HERBIN M, 2005, PATTERN RECOGN, V22, P1557; Japkowicz N, 2000, 2000 INT C ART INT I, P111; JAPKOWICZ N, 2000, AAAI WORKSH; Kubat Miroslav, 1997, 14 INT C MACH LEARN, P179; MALOOF MA, 2003, ICML 2003; MELVILLE P, 2004, CREATING DIVERSITY I; NICKERSON AS, 8 INT WORKSH ART INT; *U WAIK NZ, WEK DAT MIN SYST; UCI DATA REPOSITORY	14	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-70717-2	LECT NOTES ARTIF INT			2008	5077						165	176				12	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BID00	WOS:000258494700013	
S	Alfred, R		Atzeni, P; Caplinskas, A; Jaakkola, H		Alfred, Rayner			Dynamic aggregation of relational attributes based on feature construction	ADVANCES IN DATABASES AND INFORMATION SYSTEMS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	12th East European Conference on Advances in Databases and Information Systems	SEP 05-09, 2008	Pori, FINLAND			feature construction; data summarisation; genetic algorithm; clustering	INDUCTION	The importance of input representation has been recognised already in machine learning. This paper discusses the application of genetic-based feature construction methods to generate input data for the data summarisation method called Dynamic Aggregation of Relational Attributes (DARA). Here, feature construction methods are applied in order to improve the descriptive accuracy of the DARA algorithm. The DARA algorithm is designed to summarise data stored in the non-target tables by clustering them into groups, where multiple records stored in non-target tables correspond to a single record stored in a target table. This paper addresses the question whether or not the descriptive accuracy of the DARA algorithm benefits from the feature construction process. This involves solving the problem of constructing a relevant set of features for the DARA algorithm by using a genetic-based algorithm. This work also evaluates several scoring measures used as fitness functions to find the best set of constructed features.	Univ Malaysia Sabah, Sch Engn & Informat Technol, Kota Kinabalu 88999, Sabah, Malaysia	Alfred, R (reprint author), Univ Malaysia Sabah, Sch Engn & Informat Technol, Locked Bag 2073, Kota Kinabalu 88999, Sabah, Malaysia.						ALFRED R, 2006, 2 ADMA INT C, P889; Amaldi E, 1998, THEOR COMPUT SCI, V209, P237, DOI 10.1016/S0304-3975(97)00115-1; BENSUSAN H, 1996, ICML 1996 EV COMP MA; BLOCKEEL H, 1999, TILDE WARMR USER MAN; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224; Freitas AA, 2001, ARTIF INTELL REV, V16, P177, DOI 10.1023/A:1011996210207; HOLLAND JH, 1975, ADAPTATION NATURAL A; Hu Y-J, 1998, P 3 ANN GEN PROGR C, P146; HU YJ, 1996, AAAI IAAI, V1, P806; KOZA JR, 1994, STAT COMPUTING, V4; Krawiec K., 2002, Genetic Programming and Evolvable Machines, V3, DOI 10.1023/A:1020984725014; Lavrac N., 2001, ACM T COMPUT LOG, V2, P458, DOI 10.1145/383779.383781; Otero FEB, 2003, LECT NOTES COMPUT SC, V2610, P384; PAGALLO G, 1990, MACH LEARN, V5, P71, DOI 10.1023/A:1022611825350; Quinlan Ross, 1993, M KAUFMANN SERIES MA; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; Shafti LS, 2003, LECT NOTES COMPUT SC, V2810, P599, DOI 10.1007/978-3-540-45231-7_55; Shannon C. E., 1948, BELL SYSTEM TECHNICA, V27; Srinivasan A, 1996, ARTIF INTELL, V85, P277, DOI 10.1016/0004-3702(95)00122-0; Vafaie H, 1998, IEEE INTELL SYST APP, V13, P57, DOI 10.1109/5254.671093; WIENER N, 2000, CYBERNETICS CONTROL; Witten I. H., 1999, DATA MINING PRACTICA; ZHENG Z, 1996, ICTAI, P254; Zheng ZJ, 2000, MACH LEARN, V40, P35, DOI 10.1023/A:1007626017208	24	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-85712-9	LECT NOTES COMPUT SC			2008	5207						2	13				12	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BIG79	WOS:000259393600002	
J	Melita, NT; Popescu, I; Holban, S				Melita, Nicolae Teodor; Popescu, Irinel; Holban, Stefan			A Genetic Algorithm Approach to DNA Microarrays Analysis of Pancreatic Cancer	ADVANCES IN ELECTRICAL AND COMPUTER ENGINEERING			English	Article						DNA Microarrays; Feature Selection; Genetic Algorithm; Suppot Vector Machines; Pancreatic Cancer		We address the problem of collecting and analyzing vast amount of information in medicine and biology, in the light of the revolutionary technological evolution during the last decades. Currently, the methods of achieving information challenge our capacity to sort and process that data. However, we use the methods of machine learning to sort and analyze this information. In this comprehensive review we describe an experiment of analyzing DNA microarrays using a Genetic Algorithm for feature selection. We study how we can establish a causal relationship between a pattern of genic expression and the evolution of pancreatic cancer using a Genetic Algorithm.	[Melita, Nicolae Teodor; Holban, Stefan] Politehn Univ Timisoara, Fac Automat & Comp, RO-300223 Timisoara, Romania; [Popescu, Irinel] Fundeni Clin Inst, Ctr Gen Surg & Liver Transplantat, RO-022328 Bucharest, Romania	Melita, NT (reprint author), Politehn Univ Timisoara, Fac Automat & Comp, 2 V Parvan Blvd, RO-300223 Timisoara, Romania.	nt_melita@yahoo.com; irinel.popescu@icfundeni.ro; stefan@cs.utt.ro					Causton HC, 2003, MICROARRAY GENE EXPR; Duda R. O., 2001, PATTERN CLASSIFICATI; Gentleman R, 2005, BIOINFORMATICS COMPU; MORARIU N, 2007, ADV ELECT COMPUTER E, V7; RESSOM H, 2007, LECT NOTES; Roberts S., 2005, USING GENETIC ALGORI; Smyth G., 2004, STAT APPL GENETICS M, V3; Stekel D, 2003, MICROARRAY BIOINFORM; Stork D. G., 2004, COMPUTER MANUAL MATL; Venables W., 2000, S PROGRAMMING; Venables W. N., 2002, MODERN APPL STAT S; VENABLES WN, 2006, INTRO R; Witten I. H., 2005, DATA MINING	13	1	1	UNIV SUCEAVA, FAC ELECTRICAL ENG	SUCEAVA	UNIV SUCEAVA, FAC ELECTRICAL ENG, STEFAN CEL MARE, UNIVERSITATII 13, SUCEAVA, 720229, ROMANIA	1582-7445		ADV ELECTR COMPUT EN	Adv. Electr. Comput. Eng.		2008	8	2					43	48				6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	427YM	WOS:000264815000008	
S	Potthast, M; Stein, B; Gerling, R		Macdonald, C; Ounis, I; Plachouras, V; Ruthven, I; White, RW		Potthast, Martin; Stein, Benno; Gerling, Robert			Automatic vandalism detection in Wikipedia	ADVANCES IN INFORMATION RETRIEVAL	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	30th European Conference on Information Retrieval (ECIR 2008)	MAR 30-APR 03, 2008	Glasgow, SCOTLAND	Univ Glasgow, Dept Comp Sci, Google, Microsoft Res, Matrixware, Yahoo Res, Univ Strathclyde, ACM, BCS				We present results of a new approach to detect destructive article revisions, so-called vandalism, in Wikipedia. Vandalism detection is a one-class classification problem, where vandalism edits are the target to be identified among all revisions. Interestingly, vandalism detection has not been addressed in the Information Retrieval literature by now. In this paper we discuss the characteristics of vandalism as humans recognize it and develop features to render vandalism detection as a machine learning task. We compiled a large number of vandalism edits in a corpus, which allows for the comparison of existing and new detection approaches. Using logistic regression we achieve 83% precision at 77% recall with our model. Compared to the rule-based methods that are currently applied in Wikipedia, our approach increases the F-Measure performance by 49% while being faster at the same time.	[Potthast, Martin; Stein, Benno; Gerling, Robert] Bauhaus Univ Weimar, Fac Med, D-99421 Weimar, Germany	Potthast, M (reprint author), Bauhaus Univ Weimar, Fac Med, D-99421 Weimar, Germany.						BLANZIERI E, 2006, DIT06056 U TRENT; Buriol L, 2006, WI 2006 HONG KONG, P45; Japkowicz N., 2002, Intelligent Data Analysis, V6; Kittur A, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P453; POTTHAST M, 2007, WEBISVC0711 BAUH U W; PRIEDHORSKY R, 2007, GROUP 2007; Vi&eacute;gas F.B., 2007, HICSS 2007, P78; Viegas F. B., 2004, CHI 04, P575; VIEGAS FB, 2007, HICSS 2007, P85	9	10	10	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-78645-0	LECT NOTES COMPUT SC			2008	4956						663	668				6	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BHN96	WOS:000254685500072	
S	Holte, RC; Drummond, C		Washio, T; Suzuki, E; Ting, KM; Inokuchi, A		Holte, Robert C.; Drummond, Chris			Cost-sensitive classifier evaluation using cost curves	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	12th Pacific-Asia Conference on Knowledge Discovery and Data Mining	MAY 20-23, 2008	Osaka, JAPAN	Japanese Soc Artificial Intelligence, Osaka Convent & Tourism Bur, Commemorat Org Japan World Exposit 70, Kayamori Fdn Informat Sci, Air Force Off Sci Res, Asian Off Aerosp Res & Dev, Future Syst Corp, Salford Syst, Math Syst			CLASS IMBALANCE; GRAPHS	The evaluation of classifier performance in a cost-sensitive setting is straightforward if the operating conditions (misclassification costs and class distributions) are fixed and known. When this is not the case, evaluation requires a method of visualizing classifier performance across the full range of possible operating conditions. This talk outlines the most important requirements for cost-sensitive classifier evaluation for machine learning and KDD researchers and practitioners, and introduces a recently developed technique for classifier performance visualization - the cost curve - that meets all these requirements.	[Holte, Robert C.] Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada	Holte, RC (reprint author), Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada.						Adams NM, 1999, PATTERN RECOGN, V32, P1139, DOI 10.1016/S0031-3203(98)00154-X; Antonie M.-L., 2006, P 6 INT C DAT MIN, P33; Bosin A, 2007, LECT NOTES COMPUT SC, V4881, P790; BRIGGS WM, 2007, BIOMETRICS; CHAWLA NV, 2005, WORKSH UT BAS DAT MI, P179; Davis J, 2006, P 23 INT C MACH LEAR, P233, DOI DOI 10.1145/1143844.1143874; DRUMMOND C, 2005, WORKSH DAT MIN METH, P21; Drummond C, 2003, WORKSH LEARN IMB DAT; Drummond C., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347126; Drummond C, 2005, LECT NOTES ARTIF INT, V3720, P539; Drummond C, 2006, MACH LEARN, V65, P95, DOI 10.1007/s10994-006-8199-5; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P882, DOI 10.1016/j.patrec.2005.10.012; Hilden J, 1996, STAT MED, V15, P969, DOI 10.1002/(SICI)1097-0258(19960530)15:10<969::AID-SIM211>3.0.CO;2-9; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; JUMI M, 2003, LNCS LNAI, V3609, P464; Liu FT, 2006, LECT NOTES ARTIF INT, V3918, P81; LIU Y, 2007, P IEEE INT C AC SPEE, V4; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Remaley AT, 1999, CLIN CHEM, V45, P934; TING KM, 2002, P 19 INT C MACH LEAR, P642; Zhou ZH, 2006, IEEE T KNOWL DATA EN, V18, P63	23	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-68124-3	LECT NOTES ARTIF INT			2008	5012						26	29				4	Computer Science, Artificial Intelligence	Computer Science	BHT20	WOS:000256127100003	
S	Han, SG; Ng, WK		Washio, T; Suzuki, E; Ting, KM; Inokuchi, A		Han, Shuguo; Ng, Wee Keong			Privacy-preserving linear fisher discriminant analysis	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	12th Pacific-Asia Conference on Knowledge Discovery and Data Mining	MAY 20-23, 2008	Osaka, JAPAN	Japanese Soc Artificial Intelligence, Osaka Convent & Tourism Bur, Commemorat Org Japan World Exposit 70, Kayamori Fdn Informat Sci Advancement, Air Force Off Sci Res, Asian Off Aerosp Res & Dev, Future Syst Corp, Salford Syst, Math Syst			ALGORITHMS	Privacy-preserving data mining enables two or more parties to collaboratively perform data mining while preserving the data privacy of the participating parties. So far, various data mining and machine learning algorithms have been enhanced to incorporate privacy preservation. In this paper, we propose privacy-preserving solutions for Fisher Discriminant Analysis (FDA) over horizontally and vertically partitioned data. FDA is one of the widely used discriminant algorithms that seeks to separate different classes as much as possible for discriminant analysis or dimension reduction. It has been applied to face recognition, speech recognition, and handwriting recognition. The secure solutions are designed based on two basic secure building blocks that we have proposed-the Secure Matrix Multiplication protocol and the Secure Inverse of Matrix Sum protocol-which are in turn based on cryptographic techniques. We conducted experiments to evaluate the scalability of the proposed secure building blocks and overheads to achieve privacy when performing FDA.	[Han, Shuguo; Ng, Wee Keong] Nanyang Technol Univ, Sch Comp Engn, Singapore, Singapore	Han, SG (reprint author), Nanyang Technol Univ, Sch Comp Engn, Singapore, Singapore.	hans0004@ntu.edu.sg; awkng@ntu.edu.sg					Agrawal R, 2000, P ACM SIGMOD C MAN D, P439, DOI DOI 10.1145/342009.335438; BERKES P, 2005, P INT C ART NEUR NET, P285; Du WL, 2004, SIAM PROC S, P222; Duda R., 2000, PATTERN CLASSIFICATI; Fisher RA, 1936, ANN EUGENIC, V7, P179; GOETHALS B, 2007, P 7 ANN INT C INF SE, P104; Han SG, 2007, LECT NOTES COMPUT SC, V4654, P428; Han SG, 2007, LECT NOTES COMPUT SC, V4654, P407; HONG ZQ, 1991, PATTERN RECOGN, V24, P317, DOI 10.1016/0031-3203(91)90074-F; Jagannathan G., 2005, P 11 ACM SIGKDD INT, P593, DOI 10.1145/1081870.1081942; Katz M., 2002, Proceedings 16th International Conference on Pattern Recognition, DOI 10.1109/ICPR.2002.1047921; Lindell Y, 2000, LECT NOTES COMPUT SC, V1880, P36; Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P117, DOI 10.1109/TNN.2002.806629; Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223; STRANG G, 2006, LINEAR ALGEBRA APPL; Vaidya J., 2002, P 8 ACM SIGKDD INT C, P639; WAN L, 2007, P 13 ACM SIGKDD SAN, P775, DOI 10.1145/1281192.1281275	17	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-68124-3	LECT NOTES ARTIF INT			2008	5012						136	147				12	Computer Science, Artificial Intelligence	Computer Science	BHT20	WOS:000256127100013	
S	Letourneau, S; Matwin, S; Famili, AF		Washio, T; Suzuki, E; Ting, KM; Inokuchi, A		Letourneau, Sylvain; Matwin, Stan; Famili, A. Fazel			Generation of globally relevant continuous features for classification	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	12th Pacific-Asia Conference on Knowledge Discovery and Data Mining	MAY 20-23, 2008	Osaka, JAPAN	Japanese Soc Artificial Intelligence, Osaka Convent & Tourism Bur, Commemorat Org Japan World Exposit 70, Kayamori Fdn Informat Sci, Air Force Off Sci Res, Asian Off Aerosp Res & Dev, Future Syst Corp, Salford Syst, Math Syst		machine learning; attribute interactions; feature extraction		All learning algorithms perform very well when provided with a small number of highly relevant features. This paper proposes a constructive induction method to automatically construct such features. The method, named GLOREF (GLObally RElevant Features), exploits low-level interactions between the attributes in order to generate globally relevant features. The usefulness of the approach is demonstrated empirically through a large scale experiment involving 13 classifiers and 24 datasets. Results demonstrate the ability of the method in generating highly informative features and a strong positive effect on the accuracy of the classifiers.	[Letourneau, Sylvain; Famili, A. Fazel] Natl Res Council Canada, Inst Informat Technol, Ottawa, ON K1A 0R6, Canada	Letourneau, S (reprint author), Natl Res Council Canada, Inst Informat Technol, Ottawa, ON K1A 0R6, Canada.						Bloedorn E, 1998, IEEE INTELL SYST APP, V13, P30, DOI 10.1109/5254.671089; Freitas AA, 2001, ARTIF INTELL REV, V16, P177, DOI 10.1023/A:1011996210207; Fukunaga K., 1990, INTRO STAT PATTERN R; HU YU, 1999, THESIS U CALIFORNIA; Jakulin A, 2003, LECT NOTES ARTIF INT, V2838, P229; Kononenko I, 1997, FUTURE GENER COMP SY, V13, P181, DOI 10.1016/S0167-739X(97)81974-7; LANGLEY P, 1993, LNCS, V667, P152; LETOURNEAU S, 1998, LNCS, V1398, P49; Murthy S.K., 1994, J ARTIFICIAL INTELLI, V2, P1; PAGALLO G, 1990, MACH LEARN, V5, P71, DOI 10.1023/A:1022611825350; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Rendell L., 1990, Computational Intelligence, V6, DOI 10.1111/j.1467-8640.1990.tb00298.x; VILATA R, 1997, GLOBAL DATA ANAL FRA, P312	13	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-68124-3	LECT NOTES ARTIF INT			2008	5012						196	208				13	Computer Science, Artificial Intelligence	Computer Science	BHT20	WOS:000256127100018	
S	Pfahringer, B; Holmes, G; Kirkby, R		Washio, T; Suzuki, E; Ting, KM; Inokuchi, A		Pfahringer, Bernhard; Holmes, Geoffrey; Kirkby, Richard			Handling numeric attributes in Hoeffding trees	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	12th Pacific-Asia Conference on Knowledge Discovery and Data Mining	MAY 20-23, 2008	Osaka, JAPAN	Japanese Soc Artificial Intelligence, Osaka Convent & Tourism Bur, Commemorat Org Japan World Exposit 70, Kayamori Fdn Informat Sci, Air Force Off Sci Res, Asian Off Aerosp Res & Dev, Future Syst Corp, Salford Syst, Math Syst				For conventional machine learning classification algorithms handling numeric attributes is relatively straightforward. Unsupervised and supervised solutions exist that either segment the data into pre-defined bins or sort the data and search for the best split points. Unfortunately, none of these solutions carry over particularly well to a data stream environment. Solutions for data streams have been proposed by several authors but as yet none have been compared empirically. In this paper we investigate a range of methods for multi-class tree-based classification where the handling of numeric attributes takes place as the tree is constructed. To this end, we extend an existing approximation approach, based on simple Gaussian approximation. We then compare this method with four approaches from the literature arriving at eight final algorithm configurations for testing. The solutions cover a range of options from perfectly accurate and memory intensive to highly approximate. All methods are tested using the Hoeffding tree classification algorithm. Surprisingly, the experimental comparison shows that the most approximate methods produce the most accurate trees by allowing for faster tree growth.	[Pfahringer, Bernhard; Holmes, Geoffrey; Kirkby, Richard] Univ Waikato, Hamilton, New Zealand	Pfahringer, B (reprint author), Univ Waikato, Hamilton, New Zealand.						AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; AGRAWAL R, 1995, IN C MAN DAT; ALSABTI K, 1997, INT C VER LARG DAT, P346; CHAN TF, 1979, COMMUN ACM, V22, P526, DOI 10.1145/359146.359152; Domingos P., 2000, INT C KNOWL DISC DAT, P71; GAMA J, 2004, ACM S APPL COMP SAC0, P632; GAMA J, 2003, INT C KNOWL DISC DAT, P523; GREENWALD M, 2001, ACM INT C MAN DAT, P58; HOLMES G, 2005, EUR C PRINC PRACT KN, P495; Hulten G., 2003, VFML TOOLKIT MINING; JAIN R, 1985, COMMUN ACM, V28, P1076, DOI 10.1145/4372.4378; MANKU G, 1998, ACM SIGMOD C MAN DAT, P426; MUNRO JI, 1980, THEOR COMPUT SCI, V12, P315, DOI 10.1016/0304-3975(80)90061-4; Quinlan R., 1996, J ARTIFICIAL INTELLI, V4, P77; VITTER JS, 1985, ACM T MATH SOFTWARE, V11, P37, DOI 10.1145/3147.3165; WELFORD BP, 1962, TECHNOMETRICS, V4, P419, DOI 10.2307/1266577	16	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-68124-3	LECT NOTES ARTIF INT			2008	5012						296	307				12	Computer Science, Artificial Intelligence	Computer Science	BHT20	WOS:000256127100026	
S	Christen, P		Washio, T; Suzuki, E; Ting, KM; Inokuchi, A		Christen, Peter			Automatic training example selection for scalable unsupervised record linkage	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	12th Pacific-Asia Conference on Knowledge Discovery and Data Mining	MAY 20-23, 2008	Osaka, JAPAN	Japanese Soc Artificial Intelligence, Osaka Convent & Tourism Bur, Commemorat Org Japan World Exposit 70, Kayamori Fdn Informat Sci, Air Force Off Sci Res, Asian Off Aerosp Res & Dev, Future Syst Corp, Salford Syst, Math Syst		data linkage; entity resolution; clustering; support vector machines; data mining preprocessing		Linking records from two or more databases is an increasingly important data preparation step in many data mining projects, as linked data can enable studies that are not feasible otherwise, or that would require expensive collection of specific data. The aim of such linkages is to match all records that refer to the same entity. One of the main challenges in record linkage is the accurate classification of record pairs into matches and non-matches. Many modern classification techniques are based on supervised machine learning and thus require training data, which is often not available in real world situations. A novel two-step approach to unsupervised record pair classification is presented in this paper. In the first step, training examples are selected automatically, and they are then used in the second step to train a binary classifier. An experimental evaluation shows that this approach can outperform k-means clustering and also be much faster than other classification techniques.	Australian Natl Univ, Dept Comp Sci, Canberra, ACT 0200, Australia	Christen, P (reprint author), Australian Natl Univ, Dept Comp Sci, GPO Box 4, Canberra, ACT 0200, Australia.						Baxter R., 2003, ACM SIGKDD 03 WORKSH, P25; Bilenko M., 2003, ACM SIGKDD INT C KNO, P39; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; CHRISTEN P, 2008, HDKM 2008 CRPIT WOLL, V80; CHRISTEN P, 2007, AUSDM 2007 CRPIT GOL, V70; Christen P, 2005, LECT NOTES COMPUT SC, V3578, P109; Christen P, 2007, QUALITY MEASURES DAT, V43, P127, DOI 10.1007/978-3-540-44918-8_6; Elfeky M., 2002, IEEE INT C DAT ENG, P17; Liu B, 2002, ICML, P387; Nahm U. Y., 2002, TEXTML 2002 SYDN, P18; Tejada S., 2002, ACM KDD 2002 EDM, P350; Winkler WE, 2004, INFORM SYST, V29, P531, DOI 10.1016/j.is.2003.12.003; YU H, 2002, ACM KDD 2002 EDM	13	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-68124-3	LECT NOTES ARTIF INT			2008	5012						511	518				8	Computer Science, Artificial Intelligence	Computer Science	BHT20	WOS:000256127100044	
S	Cieslak, D; Chawla, N		Washio, T; Suzuki, E; Ting, KM; Inokuchi, A		Cieslak, David; Chawla, Nitesh			Analyzing PETs on imbalanced datasets when training and testing class distributions differ	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	12th Pacific-Asia Conference on Knowledge Discovery and Data Mining	MAY 20-23, 2008	Osaka, JAPAN	Japanese Soc Artificial Intelligence, Osaka Convent & Tourism Bur, Commemorat Org Japan World Exposit 70, Kayamori Fdn Informat Sci, Air Force Off Sci Res, Asian Off Aerosp Res & Dev, Future Syst Corp, Salford Syst, Math Syst				Many machine learning applications like finance, medicine, and risk management suffer from class imbalance: cases of interest occur rarely. Further complicating these applications is that the training and testing samples might differ significantly in their respective class distributions. Sampling has been shown to be a strong solution to imbalance and additionally offers a rich parameter space from which to select classifiers. This paper is concerned with the interaction between Probability Estimation Trees (PETs) [1], sampling, and performance metrics as testing distributions fluctuate substantially. A set of comprehensive analyses is presented, which anticipate classifier performance through a set of widely varying testing distributions.	[Cieslak, David; Chawla, Nitesh] Univ Notre Dame, Notre Dame, IN 46556 USA	Cieslak, D (reprint author), Univ Notre Dame, Notre Dame, IN 46556 USA.						Asuncion A., 2007, UCI MACHINE LEARNING; Batista G. E. A. P. A., 2004, SIGKDD EXPLORATIONS, V6, P20, DOI DOI 10.1145/1007730.1007735; BUJA A, 2006, LOSS FUNCTIONS BINAR; Caruana R., 2006, ICML 06, P161; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; Chawla NV, 2004, SIGKDD EXPLORATIONS, V6, P1; CHAWLA NV, 2008, SPECIAL ISSUE INT J; Estabrooks A, 2004, COMPUT INTELL, V20, P18, DOI 10.1111/j.0824-7935.2004.t01-1-00228.x; Japkowicz N, 2000, IC-AI'2000: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOL 1-III, P111; Kubat M, 1998, MACH LEARN, V30, P195, DOI 10.1023/A:1007452223027; Ling C. X., 1998, KDD, P73; Provost F, 2003, MACH LEARN, V52, P199, DOI 10.1023/A:1024099825458; Quinlan J., 1992, C4 5 PROGRAMS MACHIN; SOLBERG A, 1996, ERS SAR IM IEEE S GE, V3, P1484	14	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-68124-3	LECT NOTES ARTIF INT			2008	5012						519	526				8	Computer Science, Artificial Intelligence	Computer Science	BHT20	WOS:000256127100045	
S	Lee, KC; Chang, J; Chen, MS		Washio, T; Suzuki, E; Ting, KM; Inokuchi, A		Lee, Kuo-Chen; Chang, Jason; Chen, Ming-Syan			PAID: Packet analysis for anomaly intrusion detection	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	12th Pacific-Asia Conference on Knowledge Discovery and Data Mining	MAY 20-23, 2008	Osaka, JAPAN	Japanese Soc Artificial Intelligence, Osaka Convent & Tourism Bur, Commemorat Org Japan World Exposit 70, Kayamori Fdn Informat Sci, Air Force Off Sci Res, Asian Off Aerosp Res & Dev, Future Syst Corp, Salford Syst, Math Syst		data mining; intrusion detection; network security; machine learning		Due to the growing threat of network attacks, detecting and measuring the network abuse are increasingly important. Network intrusion detection is the most frequently deployed approach. Detection frequently relies on only signature matching methods, and therefore suffers from lower accuracy and higher false alarm rates. This investigation presents a data-mining model (PAID) that constructs a packet header anomaly detection system with a Bayesian approach. The model accurately and automatically detects new malicious network attempts. On the DARPA evaluation data set, our method yields an accuracy of over 99.2% and a false positive rate of 0.03% for a DoS attack. Experimental results validate the feasibility of PAID to detect network intrusion.	[Lee, Kuo-Chen; Chang, Jason; Chen, Ming-Syan] Natl Taiwan Univ, Taipei, Taiwan	Lee, KC (reprint author), Natl Taiwan Univ, Taipei, Taiwan.						CARDENAS A, 2006, IEEE S SEC PRIV MAY; GOLDMAN R, 2002, S REC ADV INTR DET R; GU G, 2006, P EUR S RES COMP SEC; Hoagland J., 2000, SPADE SILICAN DEFENS; Javits H. S., 1993, NIDES STAT COMPONENT; JENSEN FV, 1996, INTRO BAYESIEN NETWO; KRUEGEL C, 2002, S APPL COMP SAC SPAN; Lakhina A., 2005, SIGCOMM; Mahoney M., 2003, P ACM SAC; Mahoney M., 2002, P ACM SIGKDD; Mukkamala S, 2002, P IEEE INT JOINT C N; PUTTINI R, 2002, 22 INT WORKSH BAY IN; ROESCH M, 2007, SNORT LIGHTWEIGHT IN; *KDD99, 2006, KDD99 CUP DAT; *MIT LINC LAB, 2005, 1998 DARP INTR DET E	15	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-68124-3	LECT NOTES ARTIF INT			2008	5012						626	633				8	Computer Science, Artificial Intelligence	Computer Science	BHT20	WOS:000256127100057	
B	Liang, SL; Schaepman, M; Jackson, T; Jupp, D; Li, XW; Liu, JY; Liu, RG; Strahler, A; Townshend, JR; Wickland, D		Liang, S		Liang, Shunlin; Schaepman, Michael; Jackson, Thomas; Jupp, David; Li, Xiaowen; Liu, Jiyuan; Liu, Ronggao; Strahler, Alan; Townshend, John R.; Wickland, Diane			Emerging issues in land remote sensing	ADVANCES IN LAND REMOTE SENSING: SYSTEM, MODELING, INVERSION AND APPLICATION			English	Proceedings Paper	9th International Symposium on Physical Measurements and Signatures in Remote Sensing	OCT, 2005	Beijing, PEOPLES R CHINA		Chinese Acad Sci, Inst Geog Sci & Nat Resource Res		ARTIFICIAL NEURAL-NETWORKS; SENSOR NETWORKS; ADVANCED PLATFORM; SCIENCE; MODEL; RULE; TECHNOLOGIES; PREDICTION; EXTRACTION	This chapter summarizes the key questions and issues discussed by three review panels in the 9th International Symposium on Physical Measurements and Signatures in Remote Sensing (ISPMSRS) held in October 2005 in Beijing. The panels focused on remote sensing systems and sensors, modeling and inversion, and remote sensing applications. Some emerging issues in land remote sensing are presented, including sensor networks, modeling complex landscapes, machine learning techniques for inversion, and spatial scaling.	[Liang, Shunlin; Townshend, John R.] Univ Maryland, Dept Geog, College Pk, MD 20742 USA	Liang, SL (reprint author), Univ Maryland, Dept Geog, College Pk, MD 20742 USA.		Schaepman, Michael/B-9213-2009				Akyildiz IF, 2002, IEEE COMMUN MAG, V40, P102, DOI 10.1109/MCOM.2002.1024422; Andrews R, 1995, KNOWL-BASED SYST, V8, P373, DOI 10.1016/0950-7051(96)81920-4; Clark JS, 2006, TRENDS ECOL EVOL, V21, P375, DOI 10.1016/j.tree.2006.03.016; Clark SD, 2006, ACTA ASTRONAUT, V59, P899, DOI 10.1016/j.actaastro.2005.07.022; Ding XQ, 2006, DYNAM CONT DIS SER A, V13, P565; Gotway CA, 2002, J AM STAT ASSOC, V97, P632, DOI 10.1198/016214502760047140; Hart JK, 2006, EARTH-SCI REV, V78, P177, DOI 10.1016/j.earscirev.2006.05.001; Krasnopolsky VM, 2006, ECOL MODEL, V191, P5, DOI 10.1016/j.ecolmodel.2005.08.009; Krasnopolsky VM, 2003, NEURAL NETWORKS, V16, P321, DOI 10.1016/S0893-6080(03)00027-3; Kung HY, 2006, J INF SCI ENG, V22, P751; Kyriakidis PC, 2005, GEOGR ANAL, V37, P124, DOI 10.1111/j.1538-4632.2005.00633.x; Lemmerman L, 2005, ACTA ASTRONAUT, V56, P199, DOI 10.1016/j.actaastro.2004.09.031; Liang SL, 2007, PROG PHYS GEOG, V31, P501, DOI 10.1177/0309133307084626; Lofstrom T, 2004, LECT NOTES COMPUT SC, V3316, P555; Loyola RDG, 2006, NEURAL NETWORKS, V19, P168, DOI 10.1016/j.neunet.2006.01.010; Nunez H, 2006, NEURAL PROCESS LETT, V24, P1, DOI 10.1007/s11063-006-9007-8; Palmer TN, 2005, ANNU REV EARTH PL SC, V33, P163, DOI 10.1146/annurev.earth.33.092203.122552; Pardo-Iguzquiza E, 2006, REMOTE SENS ENVIRON, V102, P86, DOI 10.1016/j.rse.2006.02.014; Paul JL, 2006, IEEE AERO EL SYS MAG, V21, P13, DOI 10.1109/MAES.2006.1581121; Saad EW, 2007, NEURAL NETWORKS, V20, P78, DOI 10.1016/j.neunet.2006.07.005; Wikle CK, 2005, TECHNOMETRICS, V47, P80, DOI 10.1198/004017004000000572	21	0	0	SPRINGER	DORDRECHT	PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS		978-1-4020-6449-4				2008							485	494		10.1007/978-1-4020-6450-0_19		10	Remote Sensing	Remote Sensing	BHR96	WOS:000255865000019	
S	Tahir, MA; Smith, JE		Siarry, P; Michalewicz, Z		Tahir, Muhammad A.; Smith, James E.			Feature Selection for Heterogeneous Ensembles of Nearest-neighbour Classifiers Using Hybrid Tabu Search	ADVANCES IN METAHEURISTICS FOR HARD OPTIMIZATION	Natural Computing Series		English	Article; Book Chapter						Nearest Neighbour; Tabu Search; Ensemble Classifier; Feature Selection		The nearest-neighbour (NN) classifier has long been used in pattern recognition, exploratory data analysis, and data mining problems. A vital consideration in obtaining good results with this technique is the choice of distance function, and correspondingly which features to consider when computing distances between samples. In this chapter, a new ensemble technique is proposed to improve the performance of NN classifiers. The proposed approach combines multiple NN classifiers, where each classifier uses a different distance function and potentially a different set of features (feature vector). These feature vectors are determined for each distance metric using a Simple Voting Scheme incorporated in Tabu Search (TS). The proposed ensemble classifier with different distance metrics and different feature vectors (TS-DF/NN) is evaluated using various benchmark data sets from the UCI Machine Learning Repository. Results have indicated a significant increase in the performance when compared with various well-known classifiers. The proposed ensemble method is also compared with an ensemble classifier using different distance metrics but with the same feature vector (with or without Feature Selection (FS)).	[Tahir, Muhammad A.; Smith, James E.] Univ W England, Sch Comp Sci, Bristol BS16 1QY, Avon, England	Tahir, MA (reprint author), Univ W England, Sch Comp Sci, Bristol BS16 1QY, Avon, England.	Muhammad.Tahir@uwe.ac.uk; James.Smith@uwe.ac.uk					Amaldi E, 1998, THEOR COMPUT SCI, V209, P237, DOI 10.1016/S0304-3975(97)00115-1; BAO Y, 2004, LNCS, V3177; Bay S.D., 1998, P 15 INT C MACH LEAR, P37; Blake CL, UCI REPOSITORY MACHI; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davies S, 1994, P 1994 AAAI FALL S R, P37; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Duda R.O, 1973, PATTERN CLASSIFICATI; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Glover F., 1990, ORSA Journal on Computing, V2; Glover F., 1993, Annals of Operations Research, V41; Glover F., 1989, ORSA Journal on Computing, V1; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; KOHAVI R, 1995, P 8 EUR C MACH LEARN; KORYCINSKI D, 2003, P IEEE INT GEOSC REM; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Okun O., 2005, P ICML WORKSH LEARN, P51; Paredes R, 2006, IEEE T PATTERN ANAL, V28, P1100, DOI 10.1109/TPAMI.2006.145; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; SAIT SM, 1999, GEN ITERATIVE ALGORI; Serpico SB, 2001, IEEE T GEOSCI REMOTE, V39, P1360, DOI 10.1109/36.934069; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; Tahir MA, 2006, IEEE T INF TECHNOL B, V10, P782, DOI 10.1109/TITB.2006.879596; TAHIR MA, 2007, PATTERN RECOGNITION, V28; TAHIR MA, 2006, P IEEE INT C DAT MIN; Taylor C., 1994, MACHINE LEARNING NEU; Wang JG, 2007, PATTERN RECOGN LETT, V28, P207, DOI 10.1016/j.patrec.2006.07.002; WHITNEY AW, 1971, IEEE T COMPUT, VC 20, P1100, DOI 10.1109/T-C.1971.223410; Witten I. H., 2005, DATA MINING PRACTICA; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Yu SX, 2002, PATTERN RECOGN LETT, V23, P183, DOI 10.1016/S0167-8655(01)00118-0; Zhang HB, 2002, PATTERN RECOGN, V35, P701, DOI 10.1016/S0031-3203(01)00046-2	38	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1619-7127	978-3-540-72959-4	NAT COMPUT SER	Nat. Comput. Ser.		2008							69	85		10.1007/978-3-540-72960-0_4	10.1007/978-3-540-72960-0	17	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Computer Science	BKE57	WOS:000267892800004	
S	Tellez, A; Juarez, A; Hernandez, G; Denicia, C; Villatoro, E; Montes, M; Villasenor, L		Peters, C; Jikoun, V; Mandl, T; Muller, H; Oard, DW; Penas, A; Petras, V; Santos, D		Tellez, Alberto; Juarez, Antonio; Hernandez, Gustavo; Denicia, Claudia; Villatoro, Esau; Montes, Manuel; Villasenor, Luis			A Lexical Approach for Spanish Question Answering	ADVANCES IN MULTILINGUAL AND MULTIMODAL INFORMATION RETRIEVAL	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	8th Workshop of the Cross-Language Evaluation Forum	SEP 19-21, 2007	Budapest, HUNGARY					This paper discusses our system's results at the Spanish Question Answering task of CLEF 2007. Our system is centered in a full data-driven approach that combines information retrieval and machine learning techniques. It mainly relies on the use of lexical information and avoids any complex language processing procedure. Evaluation results indicate that this approach is very effective for answering definition questions from Wikipedia. In contrast, they also reveal that it is very difficult to respond factoid questions from this resource solely based on the use of lexical overlaps and redundancy.	[Tellez, Alberto; Juarez, Antonio; Hernandez, Gustavo; Denicia, Claudia; Villatoro, Esau; Montes, Manuel; Villasenor, Luis] Inst Nacl Astrofis Opt & Electr, Lab Tecnol Lenguaje, Santa Maria Tonantzintla, Pue, Mexico	Tellez, A (reprint author), Inst Nacl Astrofis Opt & Electr, Lab Tecnol Lenguaje, Luis Enrrique Erro 1, Santa Maria Tonantzintla, Pue, Mexico.		Villasenor-Pineda, Luis/A-2932-2009				DEPABLOSANCHEZ C, 1961, CLEF 2005, P488; FERRES D, 2005, CLEF 2005, P400; Juarez-Gonzalez A, 2007, LECT NOTES COMPUT SC, V4730, P415; PETERS C, 2006, LNCS, V4022; ROGER S, 2005, CLEF 2005, P457; TELLEZVAKERI A, 2007, 7 WORKSH CROSST QA C	6	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-85759-4	LECT NOTES COMPUT SC			2008	5152						328	331				4	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BIK64	WOS:000260420000040	
S	Garcia-Cumbreras, MA; Perea-Ortega, JM; Martinez-Santiago, F; Urena-Lopez, LA		Peters, C; Jikoun, V; Mandl, T; Muller, H; Oard, DW; Penas, A; Petras, V; Santos, D		Garcia-Cumbreras, M. A.; Perea-Ortega, J. M.; Martinez-Santiago, F.; Alfonso Urena-Lopez, L.			Combining Lexical Information with Machine Learning for Answer Validation at QA@CLEF 2007	ADVANCES IN MULTILINGUAL AND MULTIMODAL INFORMATION RETRIEVAL	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	8th Workshop of the Cross-Language Evaluation Forum	SEP 19-21, 2007	Budapest, HUNGARY					This document contains the description of the experiments carried out by the SINAI group. We have developed an approach based on several lexical measures integrated by means of different machine learning models. Based on lexical features it obtains a 41% of accuracy in answer validation for the Question-Answering task.	[Garcia-Cumbreras, M. A.; Perea-Ortega, J. M.; Martinez-Santiago, F.; Alfonso Urena-Lopez, L.] Univ Jaen, Dept Comp Sci, SINAI Res Grp, Jaen, Spain	Garcia-Cumbreras, MA (reprint author), Univ Jaen, Dept Comp Sci, SINAI Res Grp, Jaen, Spain.						BUDANITSKY A, 2001, SEMANTIC DISTANCE WO; CUMBRERAS MAG, 2006, P MLQA 2006; DAELEMANS W, 1998, TIMBL TILBURG MEMORY; DINUNZIO GM, 2007, LNCS, V5152; FERRANDEZ O, 2007, TECHNOLOGIA IN PRESS; Genkin A., 2005, BBR BAYESIAN LOGISTI; Jiang J.J., 1997, P INT C RES COMP LIN; Lin D, 1998, P 15 INT C MACH LEAR; Resnik P., 1995, P 14 INT JOINT C ART	9	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-85759-4	LECT NOTES COMPUT SC			2008	5152						381	386				6	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BIK64	WOS:000260420000049	
S	Tushabe, F; Wilkinson, MHF		Peters, C; Jikoun, V; Mandl, T; Muller, H; Oard, DW; Penas, A; Petras, V; Santos, D		Tushabe, Florence; Wilkinson, Michael. H. F.			Content-Based Image Retrieval Using Combined 2D Attribute Pattern Spectra	ADVANCES IN MULTILINGUAL AND MULTIMODAL INFORMATION RETRIEVAL	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	8th Workshop of the Cross-Language Evaluation Forum	SEP 19-21, 2007	Budapest, HUNGARY				OPENINGS	This work proposes a region-based shape signature that uses a combination of three different types of pattern spectra. The proposed method is inspired by the connected shape filter proposed by Urbach et al. We extract pattern spectra from the red, green and blue color bands of an image then incorporate machine learning techniques for application in photographic image retrieval. Our experiments show that the combined pattern spectrum gives an improvement of approximately 30% in terms of mean average precision and precision at 20 with respect to Urbach et al's method.	[Tushabe, Florence; Wilkinson, Michael. H. F.] Univ Groningen, Inst Math & Comp Sci, NL-9700 AK Groningen, Netherlands	Tushabe, F (reprint author), Univ Groningen, Inst Math & Comp Sci, POB 407, NL-9700 AK Groningen, Netherlands.		Wilkinson, Michael/C-2386-2009				BAGDANOV A, 2002, P 16 INT C PATT REC, V1, P468; BOBER M, 2001, IEEE T CIRCUITS SYST, V11, P703; Breen EJ, 1996, COMPUT VIS IMAGE UND, V64, P377, DOI 10.1006/cviu.1996.0066; Demsar J, 2004, ORANGE EXPT MACHINE; GARCIA JMF, 2000, 5 IB S PATT REC SIAR, P529; GRUBINGER M, 2006, IAPR NEWSLETTER, V28, P10; Hammer B, 2005, NEURAL PROCESS LETT, V21, P109, DOI 10.1007/s11063-004-1547-1; Hammer B, 2002, NEURAL NETWORKS, V15, P1059, DOI 10.1016/S0893-6080(02)00079-5; HU M, 1962, IRE T INFORM THEOR, V8, P179; Kira K, 1992, P 9 INT C MACH LEARN, P249; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465; MARAGOS P, 2007, P 8 INT S MATH MORPH, P125; Matheron G., 1975, RANDOM SETS INTEGRAL; Meijster A, 2002, IEEE T PATTERN ANAL, V24, P484, DOI 10.1109/34.993556; NARDI A, 2007, 2007 CLEF WORKSH BUD; Salembier P, 1998, IEEE T IMAGE PROCESS, V7, P555, DOI 10.1109/83.663500; Sofou A, 2005, P ICIP, P650; TUSHABE F, 2007, CLEF 2007 WORKSH HUN; Urbach ER, 2007, IEEE T PATTERN ANAL, V29, P272, DOI 10.1109/TPAMI.2007.28; URBACH ER, 2002, INT S MATH MORPH SYD; WILKINSON MHF, 2002, P 16 INT C PATT REC, V1, P701	21	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-85759-4	LECT NOTES COMPUT SC			2008	5152						554	561				8	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BIK64	WOS:000260420000069	
S	Lana-Serrano, S; Villena-Roman, J; Gonzalez-Cristobal, JC; Goni-Menoyo, JM		Peters, C; Jikoun, V; Mandl, T; Muller, H; Oard, DW; Penas, A; Petras, V; Santos, D		Lana-Serrano, Sara; Villena-Roman, Julio; Carlos Gonzalez-Cristobal, Jose; Miguel Goni-Menoyo, Jose			MIRACLE at ImageCLEFanot 2007: Machine Learning Experiments on Medical Image Annotation	ADVANCES IN MULTILINGUAL AND MULTIMODAL INFORMATION RETRIEVAL	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	8th Workshop of the Cross-Language Evaluation Forum	SEP 19-21, 2007	Budapest, HUNGARY			Medical image; image-annotation; classification; IRMA code; axis; learning algorithms; nearest-neighbour; machine learning		This paper describes the participation of MIRACLE research consortium at the ImageCLEF Medical Image Annotation task of ImageCLEF 2007. Our areas of expertise do not include image analysis, thus we approach this task as a machine-learning problem, regardless of the domain. FIRE is used as a black-box algorithm to extract different groups of image features that are later used for training different classifiers based on kNN algorithm in order to predict the IRMA code. The main idea behind the definition of our experiments is to evaluate whether an axis-by-axis prediction is better than a prediction by pairs of axes or the complete code, or vice versa.	[Lana-Serrano, Sara; Carlos Gonzalez-Cristobal, Jose; Miguel Goni-Menoyo, Jose] Univ Politecn Madrid, E-28040 Madrid, Spain	Lana-Serrano, S (reprint author), Univ Politecn Madrid, E-28040 Madrid, Spain.		Goni-Menoyo, Jose Miguel/D-5709-2012; Gonzalez, Jose/A-4005-2009	Goni-Menoyo, Jose Miguel/0000-0001-8922-5529; 			Deselaers T, 2005, LECT NOTES COMPUT SC, V3491, P688; DESELAERS T, 2008, PATTERN REC IN PRESS; DESELAERS T, 2007, MED IMAGE ANNOTATION; Goodrum A. A., 2000, Informing Science, V3; LANASERRANO S, 2007, CLEF 2007 WORKSH BUD; VILLENAROMAN J, 2005, CLEF 2005 WORKSH VIE; FIRE FLEXIBLE IMAGE	7	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-85759-4	LECT NOTES COMPUT SC			2008	5152						597	600				4	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BIK64	WOS:000260420000075	
S	Kalpathy-Cramer, J; Hersh, W		Peters, C; Jikoun, V; Mandl, T; Muller, H; Oard, DW; Penas, A; Petras, V; Santos, D		Kalpathy-Cramer, Jayashree; Hersh, William			Medical Image Retrieval and Automatic Annotation: OHSU at ImageCLEF 2007	ADVANCES IN MULTILINGUAL AND MULTIMODAL INFORMATION RETRIEVAL	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	8th Workshop of the Cross-Language Evaluation Forum	SEP 19-21, 2007	Budapest, HUNGARY				DIAGNOSIS; SYSTEM	Oregon Health & Science University participated in the medical retrieval and medical annotation tasks of ImageCLEF 2007. In the medical retrieval task, we created a web-based retrieval system built on a full-text index of both image and case annotations. The text-based search engine was implemented in Ruby using Ferret, a port of Lucene and a custom query parser. In addition to this textual index of annotations, supervised machine learning techniques using visual features were used to classify the images based on image acquisition modality. All images were annotated with the purported modality. Purely textual runs as well as mixed runs using the purported modality were submitted, with the latter performing among the best of all participating research groups. In the automatic annotation task, we used the 'gist' technique to create the feature vectors. Using statistics derived from a set of multi-scale oriented filters, we created a 5 12-dimensional vector. PCA was then used to create a 100-dimensional vector. This feature vector was fed into a two layer neural network. Our error rate on the 1000 test images was 67.8 using the hierarchical error calculations.	[Kalpathy-Cramer, Jayashree; Hersh, William] Oregon Hlth & Sci Univ, Dept Med Informat & Clin Epidemiol, Portland, OR 97201 USA	Kalpathy-Cramer, J (reprint author), Oregon Hlth & Sci Univ, Dept Med Informat & Clin Epidemiol, Portland, OR 97201 USA.						Aisen AM, 2003, RADIOLOGY, V228, P265, DOI 10.1148/radiol.2281020126; BRASCHLER M, 2004, INFORM RETRIEV, P7; Florea F., 2006, MED INFORM EUROPE; Hersh W, 2007, LECT NOTES COMPUT SC, V4730, P660; Hersh WR, 2006, J AM MED INFORM ASSN, V13, P488, DOI 10.1197/jamia.M2082; Kalpathy-Cramer J, 2007, ST HEAL T, V129, P1334; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Muller H, 2007, LECT NOTES COMPUT SC, V4730, P595; Muller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024; MULLER H, 2005, ACM INT C MULT SING; Nabney I.T., 2004, NETLAB ALGORITHMS PA; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Schmid-Saugeon P, 2003, COMPUT MED IMAG GRAP, V27, P65, DOI 10.1016/S0895-6111(02)00048-4; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; SMITH L, 2004, BIOINFORMATICS, V20; Tagare HD, 1997, J AM MED INFORM ASSN, V4, P184	16	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-85759-4	LECT NOTES COMPUT SC			2008	5152						623	630				8	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BIK64	WOS:000260420000079	
S	Guillen, R		Peters, C; Jikoun, V; Mandl, T; Muller, H; Oard, DW; Penas, A; Petras, V; Santos, D		Guillen, Rocio			GeoParsing Web Queries	ADVANCES IN MULTILINGUAL AND MULTIMODAL INFORMATION RETRIEVAL	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	8th Workshop of the Cross-Language Evaluation Forum	SEP 19-21, 2007	Budapest, HUNGARY					In this paper we present preliminary results for a pattern-based approach to parse web-based queries. The approach is designed to identify and categorize queries that include a geographical reference. Due to the ungrammaticality, multilinguality and ambiguity of the language in the 800,000 web-based queries in the collection, we started by building a list of all the different words in the queries, similar to creating an index. Next, a lookup of the words was done in a list of countries to identify potential locations. Because many locations were missed, we further analyzed the queries looking for spatial prepositions and syntactic cues. Queries were processed by combining search in gazetteers with a set of patterns. Categorization was also based on patterns. Results were low in terms of recall and precision mainly because the set of patterns is incomplete. Further statistical analysis and application of machine learning techniques is likely to improve performance. Error analysis of the results is discussed in detail.	Calif State Univ San Marcos, San Marino, CA 92096 USA	Guillen, R (reprint author), Calif State Univ San Marcos, San Marino, CA 92096 USA.						BANKO M, 2007, P 20 INT JOINT C ART, P2670; Gravano L, 2003, P 12 INT C INF KNOWL, P325; Kohler J, 2004, P WORKSH GEOGR INF R; LARSON RR, 1996, U ILLINOIS, P81; LI Z, 2007, CLEF 2007 WORKSH 200; MANDL T, 2007, CLEF 2007 WORKSH 200; Chen YR, 2006, MATER SCI FORUM, V505-507, P277, DOI 10.1145/1142473.1142505	7	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-85759-4	LECT NOTES COMPUT SC			2008	5152						781	785				5	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BIK64	WOS:000260420000098	
S	Kurimo, M; Creutz, M; Varjokallio, M		Peters, C; Jikoun, V; Mandl, T; Muller, H; Oard, DW; Penas, A; Petras, V; Santos, D		Kurimo, Mikko; Creutz, Mathias; Varjokallio, Matti			Morpho Challenge Evaluation Using a Linguistic Gold Standard	ADVANCES IN MULTILINGUAL AND MULTIMODAL INFORMATION RETRIEVAL	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	8th Workshop of the Cross-Language Evaluation Forum	SEP 19-21, 2007	Budapest, HUNGARY			Morphological analysis; Machine learning		In Morpho Challenge 2007, the objective was to design statistical machine learning algorithms that discover which morphemes (smallest individually meaningful units of language) words consist of. Ideally, these are basic vocabulary units suitable for different tasks, such as text understanding, machine translation, information retrieval, and statistical language modeling. Because in unsupervised morpheme analysis the morphemes can have arbitrary names, the analyses are here evaluated by a comparison to a linguistic gold standard by matching the morphemesharing word pairs. The data sets were provided for four languages: Finnish, German, English, and Turkish and the participants were encouraged to apply their algorithm to all of them. The results show significant variance between the methods and languages, but the best methods seem to be useful in all tested languages and match quite well with the linguistic analysis.	[Kurimo, Mikko; Creutz, Mathias; Varjokallio, Matti] Helsinki Univ Technol, Adapt Informat Res Ctr, FIN-02015 Helsinki, Finland	Kurimo, M (reprint author), Helsinki Univ Technol, Adapt Informat Res Ctr, POB 5400, FIN-02015 Helsinki, Finland.		Kurimo, Mikko/F-6647-2012				Bilmes J. A., 2003, P HLT NACCL, P4; CETINOGLU O, 2000, THESIS BOGAZICI U IS; CREUTZ M, 2006, PASCAL CHALL WORKSH; Creutz Mathias, 2005, P INT INT C AD KNOWL, P106; DUTAGACI H, 2002, THESIS BOGAZICI U IS; KURIMO M, 2008, LNCS, V5152; KURIMO M, 2005, PASCAL CHALL WORKSH; LEE YS, 2004, P HLT NAACL BOST MA; TEPPER M, 2007, THESIS U WASHINGTON; ZIEMAN Y, 1997, P 1997 AM MED INF AS	10	5	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-85759-4	LECT NOTES COMPUT SC			2008	5152						864	872				9	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BIK64	WOS:000260420000111	
S	Li, Q; Ma, HD; Zheng, KY		Huang, YMR; Xu, C; Cheng, KS; Yang, JFK; Swamy, MNS; Li, S; Ding, JW		Li, Qi; Ma, Huadong; Zheng, Kanyan			A Flexible Framework for Audio Semantic Content Detection	Advances in Multimedia Information Processing - PCM 2008, 9th Pacific Rim Conference on Multimedia	Lecture Notes in Computer Science		English	Proceedings Paper	9th Pacific Rim Conference on Multimedia	DEC 09-13, 2008	Tainan, TAIWAN		Natl Cheng Kung Univ	High-level semantic; audio semantic; audio content analysis		Audio semantic analysis is a crucial issue in multimedia applications. In this paper, a hierarchical framework is proposed for high-level semantic content detection for a continuous audio stream. In the proposed framework, basic audio events are modeled with hidden Markov models. Based on the obtained key audio event sequence, a neural network-based approach is proposed to discover the high-level semantic content of the audio context. With the neural network-based approach, human knowledge and machine learning are effectively combined in the semantic inference. We select some audio streams to evaluate the performance of the proposed framework, and the experiment results demonstrate the framework can achieve satisfying results.	[Li, Qi; Ma, Huadong; Zheng, Kanyan] Beijing Univ Posts & Telecommun, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China	Li, Q (reprint author), Beijing Univ Posts & Telecommun, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.	qi.liqi2001@gmail.com; mhd@bupt.edu.cn; zheng_kanyan@yahoo.cn					CHENG Wenhuang, 2003, P 5 ACM SIGMM INT WO, P109, DOI 10.1145/973264.973282; Liu Z, 1998, J VLSI SIG PROCESS S, V20, P61, DOI 10.1023/A:1008066223044; Lu L, 2003, P IEEE INT C MULT EX, V3, P37; LU LC, 2006, P ICASSP, V5; MA YF, 2005, IEEE T CIRCUITS SYST, V15, P296; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; WEI W, 2007, ICMLC 2007, V7, P1620; Xu M, 2003, P IEEE INT C MULT EX, V2, P281	8	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-89795-8	LECT NOTES COMPUT SC			2008	5353						915	918				4	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BIS97	WOS:000262476800113	
S	Yanai, K		Satoh, S; Nack, F; Etoh, M		Yanai, Keiji			Web image gathering with a part-based object recognition method	ADVANCES IN MULTIMEDIA MODELING, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	14th International Multimedia Modeling Conference (MMM 2008)	JAN   09, 2007	Kyoto, JAPAN		Kyoto Univ		FEATURES	We propose a new Web image gathering system which employs a part-based object recognition method. The novelty of our work is introducing the bag-of-keypoints representation into an Web image gathering task instead of color histogram or segmented regions our previous system used. The bag-of-keypoints representation has been proven that it has the excellent ability to represent image concepts in the context of visual object categorization / recognition in spite of its simplicity. Most of object recognition work assumed that complete training data is available. On the other hand, in the Web image gathering task, since images associated with the given keywords are gathered from the Web fully-automatically, complete training images cannot be available. In this paper, we combine the HTML-based automatic positive training image selection and the bag-of-keypoints-based image selection with an SVM which is a supervised machine learning method. This combination enables the system to gather many images related to given concepts with high precision fully automatically needing no human intervention. Our main objective is to examine if the bag-of-keypoints model is also effective for the Web image gathering task where training images always include some noise. By the experiments, we show the new system outperforms our previous systems, other systems and Google Image Search greatly.	Univ Electrocommun, Dept Comp Sci, Chofu, Tokyo 1828585, Japan	Yanai, K (reprint author), Univ Electrocommun, Dept Comp Sci, 1-5-1 Chofugaoka, Chofu, Tokyo 1828585, Japan.						Csurka G., 2004, P ECCV WORKSH STAT L, P1; Feng H.M., 2004, P ACM INT C MULT, P960, DOI 10.1145/1027527.1027748; Fergus R., 2004, P EUR C COMP VIS, P242; Kataymaand N., 1997, P ACM SIGMOD INT C M, P369, DOI 10.1145/253260.253347; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490; SUN Y, 2006, P ACM SIGMM INT WORK, P127, DOI 10.1145/1178677.1178697; YANAI K, 2003, P ACM INT C MULT, P67; YANAI K, 2001, P IEEE INT C MULT EX, P704; Yanai K., 2005, P ACM SIGMM INT WORK, P57, DOI 10.1145/1101826.1101838	10	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-77407-5	LECT NOTES COMPUT SC			2008	4903						297	306				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BHD52	WOS:000252344900028	
S	Agarwal, R; Prabhakar, TV; Chakrabarty, S		Nordstrom, B; Ranta, A		Agarwal, Ritesh; Prabhakar, T. V.; Chakrabarty, Sugato			"I Know What You Feel": Analyzing the role of conjunctions in automatic sentiment analysis	ADVANCES IN NATURAL LANGUAGE PROCESSING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	6th International Conference on Natural Language Processing	AUG 25-27, 2008	Gothenburg, SWEDEN	Ctr Language Technol, City Gothenburg, Lingsoft Ltd	Chalmers Univ Technol	sentiment analysis; linguistic analysis; natural language processing; support vector machines; machine learning		We are interested in finding how people feel about certain topics. This could be considered as a task of classifying the sentiment: sentiment could be positive, negative or neutral. In this paper, we examine the problem of automatic sentiment analysis at sentence level. We observe that sentence structure has a fair contribution towards sentiment determination, and conjunctions play a major role in defining the sentence structure. Our assumption is that in presence of conjunctions, not all phrases have equal contribution towards overall sentiment. We compile a set of conjunction rules to determine relevant phrases for sentiment analysis. Our approach is a representation of the idea to use linguistic resources at phrase level for the analysis at sentence level. We incorporate our approach with support vector machines to conclude that linguistic analysis plays a significant role in sentiment determination. Finally, we verify our results on movie, car and book reviews.	[Agarwal, Ritesh; Prabhakar, T. V.] Indian Inst Technol, Kanpur 208016, Uttar Pradesh, India	Agarwal, R (reprint author), Indian Inst Technol, Kanpur 208016, Uttar Pradesh, India.						Boiy E., 2007, P INT C EL PUBL, P349; DAS SR, 2001, P 8 AS PAC FIN ASS A; Dave K., 2003, WWW, P519; Gamon M., 2005, P ACL WORKSH FEAT EN, P57, DOI 10.3115/1610230.1610241; Hovy E., 2005, P INT JOINT C NAT LA, P61; HU M, 2004, MINING OPINION FEATU; Meena A, 2007, LECT NOTES COMPUT SC, V4425, P573; Mullen T., 2004, P C EMP METH NAT LAN, P412; Ng V., 2006, P COLING ACL MAIN C, P611, DOI 10.3115/1273073.1273152; Pang B., 2002, P 2002 C EMP METH NA; Pang Bo, 2005, P 43 ANN M ASS COMP, P115, DOI DOI 10.3115/1219840.1219855; SINGHAL A, 1996, RES DEV INFORM RETRI, P21; Turney P.D., 2001, ACL 02, P417; WILSON T, 2005, HLT 2005; YI J, 2003, SENTIMENT ANAL EXTRA, P427; Yu H, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P129; ZHANG L, 2006, P ACL WORKSH SENT SU, P47, DOI 10.3115/1654641.1654648	17	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-85286-5	LECT NOTES ARTIF INT			2008	5221						28	39				12	Computer Science, Artificial Intelligence	Computer Science	BIE63	WOS:000258935200004	
S	Ingason, AK; Helgadottir, S; Loftsson, H; Rognvaldsson, E		Nordstrom, B; Ranta, A		Ingason, Anton Karl; Helgadottir, Sigrun; Loftsson, Hrafn; Rognvaldsson, Eirikur			A mixed method lemmatization algorithm using a Hierarchy of Linguistic Identities (HOLI)	ADVANCES IN NATURAL LANGUAGE PROCESSING, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	6th International Conference on Natural Language Processing	AUG 25-27, 2008	Gothenburg, SWEDEN	Ctr Language Technol, City Gothenburg, Lingsoft Ltd	Chalmers Univ Technol	lemma; lemmatization; normalization; machine learning; BLARK; Icelandic; Lemmald; IceTagger	TEXT	We present a new mixed method lemmatizer for Icelandic, Lemmald, which achieves good performance by relying on IceTagger [1] for tagging and The Icelandic Frequency Dictionary [2] corpus for training. We combine the advantages of data-driven machine learning with linguistic insights to maximize performance. To achieve this, we make use of a novel approach: Hierarchy of Linguistic Identities (HOLI), which involves organizing features and feature structures for the machine learning based on linguistic knowledge. Accuracy of the lemmatization is further improved using an add-on which connects to the Database of Modern Icelandic Inflections [3]. Given correct tagging, our system lemmatizes Icelandic text with an accuracy of 99.55%. We believe our method can be fruitfully adapted to other morphologically rich languages.	[Ingason, Anton Karl; Rognvaldsson, Eirikur] Univ Iceland, Dept Iceland, IS-101 Reykjavik, Iceland	Ingason, AK (reprint author), Univ Iceland, Dept Iceland, IS-101 Reykjavik, Iceland.	anton@akademia.is; sigruhel@hi.is; hrafn@ru.is; eirikur@hi.is					Airio E, 2006, INFORM RETRIEVAL, V9, P249, DOI 10.1007/s10791-006-0884-2; BJARNADOTTIR K, 2005, NORDISK SPROGTEKNOLO; Braschler M, 2004, INFORM RETRIEVAL, V7, P291, DOI 10.1023/B:INRT.0000011208.60754.a1; CARLBERGER J, 2001, P NODALIDA 2001 13 N; CASSATA F, 2007, AUTOMATICS THESAURUS; DALIANIS H, 2006, LREC 2006; HELGADOTTIR S, 2005, NORDISK SPROGTEKNOLO; JONGEJAN B, 2005, CST LEMMATISER; Kenstowicz M, 1993, PHONOLOGY GENERATIVE; KORENIUS T, 2004, CIKM 2004, P625; KRAUWER S, 2003, BASIC LANGUAGE RESOU; LEZIUS W, 1998, P COLING ACL 1998, P743; Loftsson H, 2008, NORD J LINGUIST, V31, P47, DOI 10.1017/S0332586508001820; LOFTSSON H, 2007, P INT 2007 SPEC SESS; MANNING C, 2005, NATURAL LANGUAGE SPE; PIND J, 1991, ICELANDIC FREQUENCY; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; PRINCE A, 1993, OPTIMALITY THE UNPUB	18	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-85286-5	LECT NOTES ARTIF INT			2008	5221						205	216				12	Computer Science, Artificial Intelligence	Computer Science	BIE63	WOS:000258935200020	
S	Kobylinski, L; Przepiorkowski, A		Nordstrom, B; Ranta, A		Kobylinski, Lukasz; Przepiorkowski, Adam			Definition extraction with balanced Random Forests	ADVANCES IN NATURAL LANGUAGE PROCESSING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	6th International Conference on Natural Language Processing	AUG 25-27, 2008	Gothenburg, SWEDEN	Ctr Language Technol, City Gothenburg, Lingsoft Ltd	Chalmers Univ Technol			We propose a novel machine learning approach to the task of identifying definitions in Polish documents. Specifics of the problem domain and characteristics of the available dataset have been taken into consideration, by carefully choosing and adapting a classification method to highly imbalanced and noisy data. We evaluate the performance of a Random Forest-based classifier in extracting definitional sentences from natural language text and give a comparison with previous work.	[Kobylinski, Lukasz] Warsaw Univ Technol, Inst Comp Sci, PL-00665 Warsaw, Poland	Kobylinski, L (reprint author), Warsaw Univ Technol, Inst Comp Sci, Ul Nowowiejska 15-19, PL-00665 Warsaw, Poland.						Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chen C, 2004, 666 U CAL; DEGORSKI L, 2008, P 6 INT C LANG RES E; FAHMI I, 2006, P EACL 2006 WORKSH L; Kingsbury P., 2002, P 3 INT C LANG RES E; KLAVANS JL, 2001, P AMIA S; KLAVANS JL, 2000, P ANN FALL S AM MED; LIN D, 2004, P 2004 C EMP METH NA; MALAISE V, 2004, COLING 2004 COMPUTER, P55; MILIARAKI S, 2004, P INT C COMP LING CO, P1360, DOI 10.3115/1220355.1220554; NIELSEN RD, 2004, MIXING WEAK LEARNERS, P80; PEARSON J, 1996, P 7 EUR INT C GOT, P817; PRZEPIORKOWSKI A, 2007, P 3 LANG TECHN C POZ, P473; Przepiorkowski A., 2007, P WORKSH BALT SLAV N, P43, DOI 10.3115/1567545.1567554; PRZEPIORKOWSKI A, 2008, LNCS LNAI; STORRER A, 2006, P 5 INT C LANG RES E; WALTER S, 2006, P COLING 2006 WORKSH, P20, DOI 10.3115/1641408.1641411; Xu P, 2007, COMPUT SPEECH LANG, V21, P105, DOI 10.1016/j.csl.2006.01.003; XU P, 2004, RANDOM FORESTS LANGU, P325	19	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-85286-5	LECT NOTES ARTIF INT			2008	5221						237	247				11	Computer Science, Artificial Intelligence	Computer Science	BIE63	WOS:000258935200023	
S	Pandian, SL; Geetha, TV		Nordstrom, B; Ranta, A		Pandian, S. Lakshmana; Geetha, T. V.			Tamil question classification using morpheme features	ADVANCES IN NATURAL LANGUAGE PROCESSING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	6th International Conference on Natural Language Processing	AUG 25-27, 2008	Gothenburg, SWEDEN	Ctr Language Technol, City Gothenburg, Lingsoft Ltd	Chalmers Univ Technol	classification; machine learning		Question classification plays an important role in question answering systems. This paper presents the Conditional Random field (CRF) model based on Morpheme features for Tamil question classification. It is a process that analyzes a question and labels it based on its question type and expected answer type (EAT). The selected features are the morpheme parts of the question terms and its dependent terms. The main contribution in this work is in the way of selection of features for constructing CRF Model. They discriminates the position of expected answer type information with respect to question term's position. The CRF model to find out the phrase which contains the information about EAT is trained with tagged question corpus. The EAT is semantically derived by analyzing the phrase obtained from CRF engine using WordNet. The performance of this morpheme based CRF model is compared with the generic CRF engine.	[Pandian, S. Lakshmana; Geetha, T. V.] Anna Univ, Dept Comp Sci & Engn, Madras 600025, Tamil Nadu, India	Pandian, SL (reprint author), Anna Univ, Dept Comp Sci & Engn, Madras 600025, Tamil Nadu, India.						ANANDAN P, 2002, INT C NAT LANG PROC; GRAESSER AC, 1994, AM EDUC RES J, V31, P104, DOI 10.3102/00028312031001104; Krishnan V., 2005, P HLT EMNLP VANC BRI, P315, DOI 10.3115/1220575.1220615; Lafferty J., 2001, P INT C MACH LEARN I; LEE C, 2005, ACM SIGIR WORKSH MAT; LI W, QUESTION CLASSIFICAT; PINTO D, 2002, P JCDL 2002 JOINT C; POONGULHALI PD, 2002, TAM WORDNET 1 INT GL; RABINER LR, 1989, P IEEE IEEE LOS AL; ROTH LD, 2002, LEARN QUEST CLASS IN; XIN L, 2006, IJCSNS INT J COMPUTE, V6; ZHANG D, 2003, 26 ANN INT ACM SIGIR	12	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-85286-5	LECT NOTES ARTIF INT			2008	5221						272	283				12	Computer Science, Artificial Intelligence	Computer Science	BIE63	WOS:000258935200026	
S	Piasecki, M; Szpakowicz, S; Marcinczuk, M; Broda, B		Nordstrom, B; Ranta, A		Piasecki, Maciej; Szpakowicz, Stanislaw; Marcinczuk, Michal; Broda, Bartosz			Classification-based filtering of semantic relatedness in hypernymy extraction	ADVANCES IN NATURAL LANGUAGE PROCESSING, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	6th International Conference on Natural Language Processing	AUG 25-27, 2008	Gothenburg, SWEDEN	Ctr Language Technol, City Gothenburg, Lingsoft Ltd	Chalmers Univ Technol	lexical-semantic relations; measures of semantic relatedness; wordnet coustruction; Polish WordNet; nouns; hypernymy extraction; supervised Machine Learning; classifiers; Rank Weight Function; filtering		Manual construction of a wordnet can be facilitated by a system that suggests semantic relations acquired from corpora. Such systems tend to produce many wrong suggestions. We propose a method of filtering a raw list of noun pairs potentially linked by hypernymy, and test it on Polish. The method aims for good recall and sufficient, precision. The classifiers work with complex features that give clues on the relation between the nouns. We apply a corpus-based measure of semantic relatedness enhanced with a Rank Weight Function. The evaluation is based on the data in Polish WordNet. The results compare favourably with similar methods applied to English, despite the small size of Polish WordNet.	[Piasecki, Maciej; Marcinczuk, Michal; Broda, Bartosz] Wroclaw Univ Technol, Inst Appl Informat, PL-50370 Wroclaw, Poland	Piasecki, M (reprint author), Wroclaw Univ Technol, Inst Appl Informat, PL-50370 Wroclaw, Poland.	maciej.piasecki@pwr.wroc.pl; szpak@site.uottawa.ca; maciej.piasecki@pwr.wroc.p1; bartosz.broda@pwr.wroc.pl					Agirre E, 2006, TEXT SPEECH LANG TEC, V33, P1, DOI 10.1007/978-1-4020-4809-8; BRODA B, 2008, P 6 LANG RE IN PRESS; Caraballo S. A., 1999, P JOINT SIGDAT C EMP, P63; DERWOJEDOWA M, 2008, P GLOB WORDNET C SEG, P162; Fellbaum C., 1998, WORDNET ELECT LEXICA; HEARST M., 1998, WORDNET ELECT LEXICA; KENNEDY A, 2006, THESIS U OTTAWA; Piasecki M., 2007, P 3 LANG TECHN C OCT, P104; Przepiorkowski A., 2004, IPI PAN CORPUS PRELI; RYU PM, 2006, P 2 WORKSH ONT LEARN, P41; Snow R., 2005, ADV NEURAL INFORM PR, P1297; SOJKA P, 2006, P TEXT SPEECH DIAL 2; Weeds J, 2005, COMPUT LINGUIST, V31, P439, DOI 10.1162/089120105775299122; Weiss D., 2008, KORPUS RZECZPOSPOLIT; Zhang M., 2006, P NAACL NEW YORK CIT, P288, DOI 10.3115/1220835.1220872; *ACL, 2006, P 21 INT C COMP LING; *WEK, 2008, WEK 3 DAT MIN SOFTW	17	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-85286-5	LECT NOTES ARTIF INT			2008	5221						393	404				12	Computer Science, Artificial Intelligence	Computer Science	BIE63	WOS:000258935200038	
S	Chen, YC; Chen, AP		Sun, F; Zhang, J; Tan, Y; Cao, J		Chen, Yichang; Chen, Anpin			A Dual-Mode Learning Mechanism Combining Knowledge-Education and Machine-Learning	ADVANCES IN NEURAL NETWORKS - ISNN 2008, PT I, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	5th International Symposium on Neural Networks	SEP 24-28, 2008	Beijing, PEOPLES R CHINA			Artificial intelligence; Psychology; Trial and error; Teaching-base education; Intelligence-Learning	STIMULUS-CONTROL	From 1956, the definitions of learning according to Artificial Intelligence and Psychology to human mind/behavior are obviously different. Owing to the rapid development of the computing power, we have potential to enhance the learning mechanism of AI. This work tries to discuss the learning process from the traditional AI learning models which are almost based on trial and error style. Furthermore, some relative literatures have pointed out that teaching-base education would increase the learning efficiency better than trial and error style. That is the reason we enhance the learning process to propose a dual-perspective learning mechanism, E&R-R XCS. As for XCS is a better accuracy model of AI, we have applied it as a basement and proposed to develop an intelligence-learning model. Finally, this work will give the inference discussion about the accuracy and accumulative performance of XCS, R-R XCS, and E&R-R XCS respectively, and the obvious summary would be concluded. That is, the proposed dual-learning mechanism has enhanced successfully.	[Chen, Yichang] NPIC, Dept Informat Management, Pingtung City 900, Pingtung County, Taiwan	Chen, YC (reprint author), NPIC, Dept Informat Management, 51 Minsheng E Rd, Pingtung City 900, Pingtung County, Taiwan.	ycchen.npic@gmail.com; apc@iim.nctu.edu.tw					Atkinson R., 1968, PSYCHOL LEARN MOTIV, V2, P89, DOI DOI 10.1016/S0079-7421(08)60422-3; BUTZ MV, 2004, LNCS, V3103, P144; CHEN YC, 2005, THESIS NATL CHIAO T; CHIEW V, 2002, IEEE INT C COGN INF, P163; Gagne R. M., 1985, CONDITIONS LEARNING; Gagne R. M., 1996, CONDITIONS LEARNING; Ghirlanda S, 1999, ANIM BEHAV, V58, P695, DOI 10.1006/anbe.1999.1187; Ghirlanda S, 1998, ANIM BEHAV, V56, P1383, DOI 10.1006/anbe.1998.0903; MCCARTHY J, 1987, COMMUN ACM, V30, P1030, DOI 10.1145/33447.33448; Piaget J., 1970, STRUCTURALISM; WAUGH NC, 1965, PSYCHOL REV, V72, P89, DOI 10.1037/h0021797; Wilson SW, 1995, EVOL COMPUT, V3, P149, DOI 10.1162/evco.1995.3.2.149	12	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-87731-8	LECT NOTES COMPUT SC			2008	5263		I				87	96				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	BIM03	WOS:000260660500011	
S	Das, A; Bossain, MS; Abdullah, SM; Islam, RU		Sun, F; Zhang, J; Tan, Y; Cao, J		Das, Anupam; Bossain, Md. Shohrab; Abdullah, Saeed Muhammad; Islam, Rashed Ul			Permutation Free Encoding Technique for Evolving Neural Networks	ADVANCES IN NEURAL NETWORKS - ISNN 2008, PT I, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	5th International Symposium on Neural Networks	SEP 24-28, 2008	Beijing, PEOPLES R CHINA			Permutation problem; genetic algorithm (GA); evolutionary programming (EP); artificial neural network(ANN)		This paper presents a new evolutionary system using genetic algorithm for evolving artificial neural networks (ANNs). The proposed algorithm is "Permutation free Encoding Technique for Evolving Neural Networks" (PETENN) that uses a, novel encoding scheme for representing ANNs. Existing genetic algorithms (CAs) for evolving ANNs suffer from the permutation problem, resulting from the recombination operator. Evolutionary Programming (EP) does not use recombination operator entirely. But the proposed encoding scheme avoids permutation problem by applying a sorting technique. PETENN uses two types of recombination operators that ensure automatic addition or deletion of nodes or links during the crossover process. The evolutionary system has been implemented and applied to a number of benchmark problems in machine learning and neural networks. The experimental results show that the system can dynamically evolve ANN architectures, showing competitiveness and, in some cases, superiority in performance.	[Das, Anupam; Bossain, Md. Shohrab; Abdullah, Saeed Muhammad; Islam, Rashed Ul] Bangladesh Univ Engn & Technol, Dept Comp Sci & Engn, Dhaka, Bangladesh	Das, A (reprint author), Bangladesh Univ Engn & Technol, Dept Comp Sci & Engn, Dhaka, Bangladesh.	anupamdas@cse.buet.ac.bd; mshohrabhossain@cse.buet.ac.bd; saeed.siam@gmail.com; rislam101010@yahoo.com					BELEW RK, 1992, WORKSH ART LIF, P511; Bennett K.P, 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; DAS A, 2007, THESIS BANGLADESH U; FUNAHASHI K, 1989, NEURAL NETWORKS, V2, P183, DOI 10.1016/0893-6080(89)90003-8; Hancock P. J. B., 1992, COGANN-92. International Workshop on Combinations of Genetic Algorithms and Neural Networks (Cat. No.92TH0435-8), DOI 10.1109/COGANN.1992.273944; SETIONO R, 1995, IEEE T NEURAL NETWOR, V6, P273, DOI 10.1109/72.363426; PRECHELT L, 1994, 2194 U KARLSR FAK IN; SCHIFFMANN W, 1992, 161992 U KOBL I PHYS; Treadgold NK, 1999, IEEE T NEURAL NETWOR, V10, P1335, DOI 10.1109/72.809079; Yao X, 1997, IEEE T NEURAL NETWOR, V8, P694, DOI 10.1109/72.572107	11	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-87731-8	LECT NOTES COMPUT SC			2008	5263		I				255	265				11	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	BIM03	WOS:000260660500029	
B	Vrabie, D; Lewis, F		Won, CH; Schrader, CB; Michel, AN		Vrabie, Draguna; Lewis, Frank			Direct Adaptive Optimal Control: Biologically Inspired Feedback Control	ADVANCES IN STATISTICAL CONTROL, ALGEBRAIC SYSTEMS THEORY, AND DYNAMIC SYSTEMS CHARACTERISTICS: A TRIBUTE TO MICHAEL K SAIN	SYSTEMS & CONTROL : FOUNDATIONS & APPLICATIONS		English	Proceedings Paper	Workshop on Advances in Statistical Control, System Theory, and Engineering Education	OCT   27, 2007	Notre Dame, IN	Note Dame Elect Engn Dept			ITERATIVE TECHNIQUE; BASAL GANGLIA; COMPUTATIONS; CEREBELLUM; TIME	Control system theory has been based on certain well understood and accepted techniques such as transfer function-based methods, adaptive control, robust control, nonlinear systems theory and state-space methods. Besides these classical techniques, in recent decades, many successful results have been obtained by incorporating artificial neural networks in classical control structures. Due to their universal approximation property, neural network structures are the perfect candidates for designing controllers for complex nonlinear systems. These successful results have caused a number of control engineers to focus their interest on the results and algorithms of the machine learning and computational intelligence community and, at the same time, to find new inspiration in the biological neural structures of living organisms in their most evolved and complex form: the human brain. In this chapter we discuss two algorithms that were developed, based on a biologically inspired structure, with the purpose of learning the optimal state feedback controller for a linear system, while at the same time performing continuous-time online control for the system at hand. Moreover, since the algorithms are related to the reinforcement learning techniques in which an agent tries to maximize the total amount of reward received while interacting with an unknown environment, the optimal controller will be obtained while only making use of the input-to-state system dynamics. Mathematically speaking, the solution of the algebraic Riccati equation underlying the optimal control problem will be obtained without making use of any knowledge of the system internal dynamics. The two algorithms are built on iteration between the policy evaluation and policy update steps until updating the control policy no longer improves the system performance. Both algorithms can be characterized as direct adaptive optimal control types since the optimal control solution is determined without using an explicit, a priori obtained, model of the system internal dynamics. The effectiveness of the algorithms is shown and their performances compared while finding the optimal state feedback dynamics of an F-16 autopilot.	[Vrabie, Draguna; Lewis, Frank] Univ Texas Arlington, Automat & Robot Res Inst, Ft Worth, TX 76118 USA	Vrabie, D (reprint author), Univ Texas Arlington, Automat & Robot Res Inst, 7300 Jack Newell Blvd S, Ft Worth, TX 76118 USA.						ALCHALABI A, 2006, BRAIN BEGINNERS GUID; Al-Tamimi A., 2007, P IEEE S APPR DYN PR, P38; Al-Tamimi A, 2007, AUTOMATICA, V43, P473, DOI 10.1016/j.automatica.2006.09.019; BAIRD L, 1994, P INT C NEUR NETW OR; Bellman R. E., 2003, DYNAMIC PROGRAMMING; Bertsekas D. P., 1996, NEURODYNAMIC PROGRAM; BERTSEKAS DP, 2005, P CDC 05; BRADTKE SJ, 1994, PROCEEDINGS OF THE 1994 AMERICAN CONTROL CONFERENCE, VOLS 1-3, P3475; Brewer J.W., 1978, IEEE T CIRCUITS SYST, V25; Buzsaki G., 2006, RHYTHMS BRAIN; Doya K, 2001, IEEE CONTR SYST MAG, V21, P42, DOI 10.1109/37.939943; Doya K, 1999, NEURAL NETWORKS, V12, P961, DOI 10.1016/S0893-6080(99)00046-5; Doya K, 2000, NEURAL COMPUT, V12, P219, DOI 10.1162/089976600300015961; Doya K, 2000, CURR OPIN NEUROBIOL, V10, P732, DOI 10.1016/S0959-4388(00)00153-7; Ferrari S, 2002, P AMER CONTR CONF, P2665, DOI 10.1109/ACC.2002.1025189; HEWER GA, 1971, IEEE T AUTOMAT CONTR, VAC16, P382, DOI 10.1109/TAC.1971.1099755; Howard R. A., 1960, DYNAMIC PROGRAMMING; KLEINMAN DL, 1968, IEEE T AUTOMAT CONTR, VAC13, P114, DOI 10.1109/TAC.1968.1098829; Landelius T, 1997, THESIS LINKOPING U S; LEVINE DS, 1997, OPTIMALITY BIOL ARTI; LEVINE DS, 2000, OSCILLATIONS NEURAL; Lewis F. L., 1995, OPTIMAL CONTROL; Liu X, 2000, P AMER CONTR CONF, P1929; Murray JJ, 2002, IEEE T SYST MAN CY C, V32, P140, DOI 10.1109/TSMCC.2002.801727; Si J., 2004, HDB LEARNING APPROXI; Stevens B.L., 2003, AIRCRAFT CONTROL SIM; Sutton R. S., 1988, Machine Learning, V3, DOI 10.1007/BF00115009; Sutton R.S., 1998, REINFORCEMENT LEARNI; VRABIE D, 2007, P MED C CONTR AUT ME; Vrabie D., 2007, P IEEE INT S ADPRL, P247; Watkins C. J. C. H., 1989, THESIS U CAMBRIDGE E; Werbos P. J., 1992, HDB INTELLIGENT CONT; WERBOS PJ, 1989, IEEE P CDC89 IEEE; White D. A., 1992, HDB INTELLIGENT CONT; Widrow B., 1995, ADAPTIVE INVERSE CON	35	0	0	BIRKHAUSER BOSTON	CAMBRIDGE	675 MASSACHUSETTS AVE, CAMBRIDGE, MA 02139-2333 USA		978-0-81764-794-0	SYS CON FDN			2008							201	222		10.1007/978-0-8176-4795-7_10		22	Computer Science, Information Systems; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	BIL86	WOS:000260633800010	
S	Hofhauser, A; Steger, C; Navab, N		Bebis, G		Hofhauser, Andreas; Steger, Carsten; Navab, Nassir			Edge-Based Template Matching and Tracking for Perspectively Distorted Planar Objects	ADVANCES IN VISUAL COMPUTING, PT I, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	4th International Symposium on Visual Computing	DEC 01-03, 2008	Las Vegas, NV	UNR Comp Vis Lab, Desert Res Inst, Berkeley Lab, NASA, SIEMENS, Intel, Digital Persona, EQUINOX, Hp Invent, Ford, MITSUBISHI, Utopia Compress, Informat CORE				This paper presents a template snatching approach to high accuracy detection and tracking of perspectively distorted objects. To this end we propose a robust snatch metric that allows significant perspective shape changes. Using a coarse-to-fine representation for the detection of the template further increases efficiency. Once an template is detected at interactive frame-rate, we immediately switch to tracking with the same algorithm, enabling detection times of only Wars. We show in a number of experiments that tire presented approach is not only fast, but also very robust and highly accurate in detecting the 3D pose of planar objects or planar subparts of lion-planar objects. The approach is used in augmented reality applications that could up to now riot be sufficiently solved, because existing approaches either needed extensive training data, like machine learning methods, or relied on interest point; extraction, like descriptors-based methods.	[Hofhauser, Andreas] Tech Univ Munich, D-85748 Garching, Germany	Hofhauser, A (reprint author), Tech Univ Munich, Boltzmannstr 3, D-85748 Garching, Germany.						Benhimane S, 2007, INT J ROBOT RES, V26, P661, DOI 10.1177/0278364907080252; BERG A, 2005, C COMP VIS PATT REC; GAVRILA DM, 1999, 7 INT C COMP VIS, V1, P87; Hartley R., 2000, MULTIPLE VIEW GEOMET; LADIKOS A, 2007, INT C COMP VIS THEOR; Lowe D., 2004, INT J COMPUTER VISIO; Olson CF, 1997, IEEE T IMAGE PROCESS, V6, P103, DOI 10.1109/83.552100; Ozuysal M, 2007, C COMP VIS PATT REC; Steger C., 2002, INT ARCH PHOTOGRAMME, V34, P345; ULRICH M, 2002, INT ARCH PHOTOGRAMME, V34, P99; ZIMMERMANN K, 2008, T PATTERN A IN PRESS	11	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-89638-8	LECT NOTES COMPUT SC			2008	5358						35	44				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BIZ95	WOS:000264057800004	
S	Scalzo, F; Xu, P; Bergsneider, M; Hu, X		Bebis, G		Scalzo, Fabien; Xu, Peng; Bergsneider, Marvin; Hu, Xiao			Random Subwindows for Robust Peak Recognition in Intracranial Pressure Signals	ADVANCES IN VISUAL COMPUTING, PT I, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	4th International Symposium on Visual Computing	DEC 01-03, 2008	Las Vegas, NV	UNR Comp Vis Lab, Desert Res Inst, Berkeley Lab, NASA, SIEMENS, Intel, Digital Persona, EQUINOX, Hp Invent, Ford, MITSUBISHI, Utopia Compress, Informat CORE			FLUID PULSE-WAVE	Following recent studies, the automatic analysis of intracranial pressure pulses (ICP) seems to be a promising tool for forecasting critical intracranial and cerebrovascular pathophysiological variations during the management of many neurological disorders. MOCAIP algorithm has recently been developed to automatically extract ICP morphological features. The algorithm is able to enhance the quality of ICP signals, to segment ICP pulses; and to recognize the three peaks occurring in a ICP Pulse. This paper extends MOCAIP by introducing a generic framework to perform robust peak recognition. The method is local in the sense that, it exploits subwindows that are randomly extracted from ICP pulses. The recognition process combines recently developed machine learning algorithms. The experimental evaluations are performed on a database built from several hundreds of hours of ICP recordings. They indicate that the proposed extension increases the robustness of the peak recognition.	[Scalzo, Fabien; Xu, Peng; Bergsneider, Marvin; Hu, Xiao] Univ Calif Los Angeles, David Geffen Sch Med, Div Neurosurg, Los Angeles, CA 90095 USA	Scalzo, F (reprint author), Univ Calif Los Angeles, David Geffen Sch Med, Div Neurosurg, Los Angeles, CA 90095 USA.	fabien.scalzo@gmail.com					Afonso VX, 1999, IEEE T BIO-MED ENG, V46, P192, DOI 10.1109/10.740882; CARDOSO ER, 1983, J NEUROSURG, V59, P817, DOI 10.3171/jns.1983.59.5.0817; Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1; HU X, 2008, IEEE T BIOMEDI UNPUB; HU X, 2008, PHYSL MEASUREMENT; KNERR S, 1990, STEPWISE PROCEDURE B; Maree R., 2005, IEEE C COMP VIS PATT, P34; Rousseeuw P. J., 2005, WILEY SERIES PROBABI; SCALZO F, 2008, IEEE INT C ENG BIOL; Silverman B.W., 1986, DENSITY ESTIMATION S; TAKIZAWA H, 1987, NEUROSURGERY, V20, P355	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-89638-8	LECT NOTES COMPUT SC			2008	5358						370	380				11	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BIZ95	WOS:000264057800036	
S	Roman, N; Pless, R		Bebis, G; Boyle, R; Parvin, B; Koracin, D; Remagnino, P; Porikli, F; Peters, J; Klosowski, J; Arns, L; Chun, YK; Rhyne, TM; Monroe, L		Roman, Nathaniel; Pless, Robert			A System for Rapid Interactive Training of Object Detectors	ADVANCES IN VISUAL COMPUTING, PT II, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	4th International Symposium on Visual Computing	DEC 01-03, 2008	Las Vegas, NV	UNR Comp Vis Lab, Desert Res Inst, Berkeley Lab, NASA, SIEMENS, Intel, Digital Persona, EQUINOX, Hp Invent, Ford, MITSUBISHI, Utopia Compress, Informat CORE				Machine learning approaches have become the de-facto standard for creating object detectors (such as face and pedestrian detectors) which arc robust to lighting, viewpoint, and pose. Generating sufficiently large labeled data sets to support accurate training is often the most challenging problem. To address this, the active learning paradigm suggests interactive user input, creating an initial classifier based oil a few samples and refining that classifier by identifying errors and re-training. In this paper we seek to maximize the efficiency of the user input; minimizing the number of labels the user must provide and minimizing the accuracy with which the user must: identify the object. We propose, implement, and test a system that allows an untrained user to create high-quality classifiers in minutes for many different types of objects in arbitrary scenes.	[Roman, Nathaniel; Pless, Robert] Washington Univ, Dept Comp Sci & Engn, St Louis, MO 63130 USA	Roman, N (reprint author), Washington Univ, Dept Comp Sci & Engn, St Louis, MO 63130 USA.	ngroman@wustl.edu; pless@wustl.edu					ABRAMSON Y, 2005, P IEEE C COMP VIS PA, V1; Cawley G. C., 2000, MATLAB SUPPORT VECTO; Dalai N., 2005, P IEEE C COMP VIS PA, V1, P886, DOI DOI 10.1109/CVPR.2005.177; Grabner H., 2006, P IEEE C COMP VIS PA, P260; Grabner H., 2006, BRIT MACH VIS C BMVC, P47; Jacobs N, 2007, P IEEE 11 INT C COMP, P1; KLUCKNER S, 2007, P IEEE INT C COMP VI, P1; Mortensen E. N., 1995, P 22 ANN C COMP GRAP, P191, DOI 10.1145/218380.218442; Mortensen E., 1992, Proceedings of Computer in Cardiology 1992 (Cat. No.92CH3259-9), DOI 10.1109/CIC.1992.269378; Oren M, 1997, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.1997.609319; Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689; Viola P, 2001, PROC CVPR IEEE, P511; Wohler C, 2001, IMAGE VISION COMPUT, V19, P593, DOI 10.1016/S0262-8856(01)00040-3; Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3	14	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-89645-6	LECT NOTES COMPUT SC			2008	5359						123	132				10	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BIT91	WOS:000262709700013	
S	Chang, X; Zheng, QH		Leung, H; Li, F; Lau, R; Li, Q		Chang, Xiao; Zheng, Qinghua			Knowledge element extraction for knowledge-based learning resources organization	ADVANCES IN WEB BASED LEARNING - ICWL 2007	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	6th International Conference on Web Based Learning (ICWL 2007)	AUG 15-17, 2007	Edinburgh, SCOTLAND			learning resource organization; knowledge element extraction; machine learning		In this paper, we propose a machine learning method to knowledge element extraction from learning resources. First, we build a knowledge element taxonomy containing 25 semantic types. Second, we formalize the knowledge element extraction of single semantic type as binary classification. Finally, we construct the multi-class classification model which can predict the semantic type of knowledge element by merge the results of binary classifiers. We annotate three semantic types in corpus and use them as training data, train the machine learning models. In experiment, we compared three binary classification models: Decision Tree, SVM and Naive Bayesian. The experimental results show that SVM has better average performance. We employ ECOC method to construct multi-class classification model and use SVM as base binary classifier in the model. Our approach outperforms the baseline in experiment. The experimental results indicate that our approach is effective.	[Chang, Xiao; Zheng, Qinghua] Xian Jiaotong Univ, Dept Comp Sci & Engn, Xian, Peoples R China							Chang JT, 2004, BIOINFORMATICS, V20, P216, DOI 10.1093/bioinformatics/btg393; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Han KS, 2007, INFORM PROCESS MANAG, V43, P353, DOI 10.1016/j.ipm.2006.07.010; HOVY E, 2001, HUM LANG TECHN C HLT, P339; ITTYCHERIAH A, 2000, 9 TEXT RETRIEVAL C; Kressel U.H.-G., 1998, ADV KERNEL METHODS S, P255; LUO S, 2002, LNCS, V2436, P81; MANN GS, 2001, WORKSH ARABIC LANG P, P1; MASULLI F, 2004, J PATTERN ANAL APPL, P285; MOENS MF, 2003, 9 INT C ART INT LAW, P142; NAKAGAWA H, 2002, 2 INT WORKSH COMP TE, P29; NG HT, 2001, 2001 C EMP METH NAT, P67; PASCA M, 2001, ACL 2001 WORKSH OP D, P38; Platt JC, 2000, ADV NEUR IN, V12, P547; Qing Y, 2004, 18TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 2 (REGULAR PAPERS), PROCEEDINGS, P528; RAMAKRISHNAN G, 2004, 13 INT C WORLD WID W, P111; SUZUKI J, 2002, 19 INT C COMP LING, P1; YAMANISHI K, 2001, IEEE INTELLIGENT SYS	18	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-78138-7	LECT NOTES COMPUT SC			2008	4823						102	113				12	Computer Science, Information Systems; Computer Science, Theory & Methods; Education & Educational Research; Information Science & Library Science	Computer Science; Education & Educational Research; Information Science & Library Science	BHQ00	WOS:000255270900010	
S	Stein, B		Liu, Y; Sun, A; Loh, HT; Lu, WF; Lim, EP		Stein, Benno			Model Construction for Knowledge-Intensive Engineering Tasks	ADVANCES OF COMPUTATIONAL INTELLIGENCE IN INDUSTRIAL SYSTEMS	Studies in Computational Intelligence		English	Article; Book Chapter							DESIGN; SIMULATION; SYSTEMS; ORDER	The construction of adequate models to solve engineering tasks is a field of paramount interest. The starting point for an engineering task is a single system, S, or a set of systems, S, along with a shortcoming of information, often formulated as a question: Which component is broken in S? (diagnosis similar to analysis) How does S react on the input u? (simulation similar to analysis) Does a system with the desired functionality exist in S? (design similar to synthesis) If such an analysis or synthesis question shall be answered automatically, both adequate algorithmic models along with the problem solving expertise of a human problem solver must be operationalized on a computer. Often, the construction of an adequate model turns out to be the key challenge when tackling the engineering task. Model construction - also known as model creation, model formation, model finding, or model building - is an artistic discipline that highly depends on the reasoning job in question. Model construction can be supported by means of a computer, and in this chapter we present a comprehensive view on model construction, characterize both existing and new paradigms, and give examples for the state of the art; of the realization technology. Our contributions are as follows: In Sect. 2 we classify existing model construction approaches with respect to their position in the model hierarchy. Nearly all of the existing methods support a top-down procedure of the human modeler; they can be characterized as being either structure-defining (top), structure-filling (middle), or structure propagating (down). Domain experts and knowledge engineers rarely start from scratch when constructing a new model; instead, they develop an appropriate model by modifying an existing one. Following this observation we analyzed various projects and classified the found model construction principles as model simplification, model compilation, and model reformulation. In Sect. 3 we introduce these principles as horizontal modeling construction and provide a generic characterization of each. Section 4 presents real-world case studies to show horizontal model construction principles at work. The underlying technology includes, among others, hybrid knowledge representations, case-based as well as rule-based reasoning, and machine learning.	Bauhaus Univ Weimar, Fac Media, D-99421 Weimar, Germany	Stein, B (reprint author), Bauhaus Univ Weimar, Fac Media, D-99421 Weimar, Germany.	benno.stein@medien.uni-weimar.de					ABDERRAHIM M, 1998, INTERFACING AUTOLEV, P897; ADDANKI S, 1989, P 11 INT JOINT C ART, P1324; ANANTHARAMAN M, 1995, P 3 C MECH ROB PAD G; ANGLUIN D, 1983, COMPUT SURV, V15, P237; Bradley E, 1996, ANN MATH ARTIF INTEL, V17, P1, DOI 10.1007/BF02284622; Brown D. C., 1989, DESIGN PROBLEM SOLVI; CELLIER FE, 1991, CONTINUOUS SYSTEM SI; CLANCY DJ, 1994, P 8 INT WORKSH QUAL, P45; DECHTER R, 1987, P 3 C ART INT APPL O; DEKLEER J, 1986, ARTIF INTELL, V28, P197, DOI 10.1016/0004-3702(86)90082-2; ELMQUIST H, 1993, SIMS 93; FETTWEIS A, 1986, P IEEE, V74, P270, DOI 10.1109/PROC.1986.13458; FISHWICK PA, 1988, IEEE T SYST MAN CYB, V18, P18, DOI 10.1109/21.87052; FORGY CL, 1982, ARTIF INTELL, V19, P17, DOI 10.1016/0004-3702(82)90020-0; FRANTZ F, 1995, P 1995 WINT SIM C SA, P1413, DOI 10.1145/224401.224834; GERO JS, 1990, AI MAG, V11, P26; GOLDSCHMIDT S, 1996, MODELLBILDUNG BEISPI; HIBBELER RC, 1992, ENG MECH STATICS DYN; IWASAKI Y, 1993, QS93 KSL; Klir G.J., 1985, ARCHITECTURE SYSTEMS; KORN GA, 1978, DIGITAL CONTINUOUS S; LEWELING KU, 1999, 5 INT C PRINC PRACT, P45; Mah R. S. H, 1990, CHEM PROCESS STRUCTU; Maher M. L., 1997, ISSUES APPL CASE BAS; MARCUS S, 1988, AUTOMATING KNOWLEDGE, P81; MESSMER BT, 1995, AM95003 U BERN RES G; Minsky M., 1965, P IFIP C, P45; NAYAK PP, 1994, ARTIF INTELL, V70, P277, DOI 10.1016/0004-3702(94)90108-2; NAYAK PP, 1995, AUTOMATED MODELLING; PIELA PC, 1991, COMPUT CHEM ENG, V15, P53, DOI 10.1016/0098-1354(91)87006-U; Puppe F., 1993, SYSTEMATIC INTRO EXP; PURVIS L, 1996, P WORKSH AD CAS BAS; RAIMAN O, 1991, ARTIF INTELL, V51, P11, DOI 10.1016/0004-3702(91)90107-U; Raphael B, 1996, AI EDAM, V10, P47; RICKEL J, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P1191; SACKS EP, 1987, P AAAI 87 SEATTLE, P655; SASAJIMA M, 1994, P 8 INT WORKSH QUAL, P224; SCHAECHTER DB, 1991, AUTOLEV USERS MANUAL; Schmidt LC, 1998, J MECH DESIGN, V120, P2, DOI 10.1115/1.2826672; SELMAN B, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P904; STEIN B, 1998, WORKSH SIM KNOWL BAS; STEIN B, 1997, EUR C 370 SYNTH MECH; STEIN B, 1995, FUNCTIONAL MODELS CO; STEIN B, 2001, MODEL CONSTRUCTION A; STRUSS P, 1991, SPQR WORKSH MULT MOD; SUERMANN M, 1994, THESIS U PADERBORN; WALLASCHECK J, 1995, 1215 VDI, P35; WELD DS, 1986, ARTIF INTELL, V30, P1, DOI 10.1016/0004-3702(86)90066-4; WYMORE AW, 1976, SYSTEMS ENG INTERDIS; Yip KMK, 1996, ARTIF INTELL, V80, P309, DOI 10.1016/0004-3702(94)00068-9; Zeigler BP, 2000, THEORY MODELING SIMU; Zupan B, 1998, IEEE T KNOWL DATA EN, V10, P238, DOI 10.1109/69.683755	52	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1860-949X	978-3-540-78296-4	STUD COMPUT INTELL			2008	116						139	167			10.1007/978-3-540-78297-1	29	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Mathematics, Applied	Computer Science; Mathematics	BJO38	WOS:000266897500007	
B	Verlic, M; Stiglic, G; Kokol, P		Kazovsky, L; Borne, P; Mastorakis, N; KuriMorales, A; Sakellaris, I		Verlic, Mateja; Stiglic, Gregor; Kokol, Peter			Identifying psycho-social fingerprints in medical and engineering documents	ADVANCES ON ARTIFICIAL INTELLIGENCE, KNOWLEDGE ENGINEERING AND DATA BASES, PROCEEDINGS	Artificial Intelligence Series-WSEAS		English	Proceedings Paper	7th WSEAS International Conference on Artificial Intelligence, Knowledge Engineering and Data Bases	FEB 20-22, 2008	Cambridge, ENGLAND	WSEAS	Univ Cambridge	text mining; text analysis; sentiment analysis; sentiment classification; psycho-social categories; machine learning		Sentiment analysis enables new possibilities for classification of text documents by considering different aspects of sentiment, appraisal and other linguistic elements. Our psycho-social fingerprint approach to the text-classification is based on the General Inquirer dictionary of psycho-social categories and provides instant solution for text classification in quickly changing target domains, such as newsgroups.	[Verlic, Mateja; Stiglic, Gregor; Kokol, Peter] Univ Maribor, Fac Elect Engn & Comp Sci, SLO-2000 Maribor, Slovenia	Verlic, M (reprint author), Univ Maribor, Fac Elect Engn & Comp Sci, Smetanova 17, SLO-2000 Maribor, Slovenia.	mateja.verlic@uni-mb.si; gregor.stiglic@uni-mb.si; kokol@uni-mb.si	Stiglic, Gregor/E-5286-2011				Benamara F., 2007, P INT C WEBL SOC MED; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Dietterich Thomas G., 2002, HDB BRAIN THEORY NEU, P405; GOERGE H, 1995, 11 C UNC ART INT SAN, V338; JASON DM, 2001, THESIS MIT; Joachims T., 1997, P 14 INT C MACH LEAR, P143; Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493; MCCALLUM A, 1998, AAAIICML98 WORKSH LE; McCallum A., 1998, P 15 INT C MACH LEAR, P359; Osgood C. E., 1971, MEASUREMENT MEANING; Platt J., 1998, ADV KERNEL METHODS S; Quinlan J. R., 1993, PROGRAMS MACHINE LEA; Turney P., 2002, P 40 ANN M ASS COMP, P417; Vapnik V. N, 1995, NATURE STAT LEARNING; WHITELAW C, 2005, P CIKM 2005 14 ACM S; Witten Ian H., 2005, DATA MINING PRACTICA; ENGLISH 20 NEWSGROUP	19	0	0	WORLD SCIENTIFIC AND ENGINEERING ACAD AND SOC	ATHENS	AG LOANNOU THEOLOGOU 17-23, 15773 ZOGRAPHOU, ATHENS, GREECE		978-960-6766-41-1	ARTIF INT SER WSEAS			2008							62	66				5	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BHY60	WOS:000257462700006	
B	Khayat, O; Shahdoosti, HR; Motlagh, AJ		Kazovsky, L; Borne, P; Mastorakis, N; KuriMorales, A; Sakellaris, I		Khayat, Omid; Shahdoosti, Hamid Reza; Motlagh, Ahmad Jaberi			Huge scale feature selection using GA with special fitness function	ADVANCES ON ARTIFICIAL INTELLIGENCE, KNOWLEDGE ENGINEERING AND DATA BASES, PROCEEDINGS	Artificial Intelligence Series-WSEAS		English	Proceedings Paper	7th WSEAS International Conference on Artificial Intelligence, Knowledge Engineering and Data Bases	FEB 20-22, 2008	Cambridge, ENGLAND	WSEAS	Univ Cambridge	feature selection; genetic algorithm; huge scale; special fitness function; gene information; cancer classification	GENE-EXPRESSION DATA; FEATURE SUBSET-SELECTION; CLASSIFICATION; CANCER; PREDICTION; ALGORITHMS	Feature selection, as a preprocessing step to machine learning, has been effective in reducing dimensionality, removing irrelevant data, increasing learning accuracy, and improving comprehensibility. However, the recent increase of dimensionality of data poses a severe challenge to many existing feature selection methods with respect to efficiency and effectiveness. With increasing interest in bioinformatics, sophisticated tools are required to efficiently analyze gene information. The classification of gene expression profiles is crucial in those fields. Since the features of data obtained by microarray technology come to be over thousands, it is essential to extract useful information by selecting proper features. The information without any feature selection might be redundant so that this can deteriorate the performance of classification. The conventional feature selection method with genetic algorithm has difficulty for huge-scale feature selection. In this paper, we modify the representation of chromosome to be suitable for huge scale feature selection and apply a special fitness function to enhance the performance of feature selection by obtaining diverse solutions. Experimental results with DNA microarray data from cancer show that the selected genes by the proposed method are useful for cancer classification.	[Khayat, Omid; Shahdoosti, Hamid Reza; Motlagh, Ahmad Jaberi] Amirkabir Univ, Dept Biomed Eng, Tehran, Iran	Khayat, O (reprint author), Amirkabir Univ, Dept Biomed Eng, Tehran, Iran.						Ben-Dor A, 2000, J COMPUT BIOL, V7, P559, DOI 10.1089/106652700750050943; Bins J., 2001, P INT C COMP VIS, P159, DOI 10.1109/ICCV.2001.937619; Brazma A, 2000, FEBS LETT, V480, P17, DOI 10.1016/S0014-5793(00)01772-5; CABALLERO RE, 1998, P 8 INT C ART NEUR N, V1, P311; Cho SB, 2002, P IEEE, V90, P1744, DOI 10.1109/JPROC.2002.804682; DEB K, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P42; DEJONG KA, 1988, MACHINE LEARNING, V3; Deutsch JM, 2003, BIOINFORMATICS, V19, P45, DOI 10.1093/bioinformatics/19.1.45; EHSELMAN L, 1989, P FDN GEN ALG WORKSH, P265; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Goldberg DE, 1989, GENETIC ALGORITHMS S; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Haykin S., 1999, NEURAL NETWORKS; HOLLAND JH, 1975, ADAPTATION NATURAL A; HWANG KS, 2002, P 2002 C EV COMP, V1, P437; Inza I, 2001, ARTIF INTELL MED, V23, P187, DOI 10.1016/S0933-3657(01)00085-9; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Li LP, 2001, BIOINFORMATICS, V17, P1131, DOI 10.1093/bioinformatics/17.12.1131; Li W, 2002, METHODS MICROARRAY D, P137; LIN SM, 2001, CAMDA 00; Lossos IS, 2000, P NATL ACAD SCI USA, V97, P10209, DOI 10.1073/pnas.180316097; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; SAMEH MY, 1997, PATTERN RECOGN, V18, P1205; Shixin Yu, 2002, Pattern Recognition Letters, V23, DOI 10.1016/S0167-8655(01)00118-0; VAFAIE H, 1991, P 1 INT WORKSH MULTI; Vafaie H., 1993, MACHINE LEARNING MUL, V4	26	0	0	WORLD SCIENTIFIC AND ENGINEERING ACAD AND SOC	ATHENS	AG LOANNOU THEOLOGOU 17-23, 15773 ZOGRAPHOU, ATHENS, GREECE		978-960-6766-41-1	ARTIF INT SER WSEAS			2008							72	77				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BHY60	WOS:000257462700008	
B	Chang, FMM		Kazovsky, L; Borne, P; Mastorakis, N; KuriMorales, A; Sakellaris, I		Chang, Fengming M.			Characteristics analysis for small data set learning and the comparison of classification methods	ADVANCES ON ARTIFICIAL INTELLIGENCE, KNOWLEDGE ENGINEERING AND DATA BASES, PROCEEDINGS	Artificial Intelligence Series-WSEAS		English	Proceedings Paper	7th WSEAS International Conference on Artificial Intelligence, Knowledge Engineering and Data Bases	FEB 20-22, 2008	Cambridge, ENGLAND	WSEAS	Univ Cambridge	small data set; Mega-fuzzification; machine learning; classification method; paucity of data	INFORMATION; TECHNOLOGY; ACCURACY; NETWORK; SYSTEM	In recent years, there has been a tremendous growth in the studies of the small data set learning methods in the condition of the paucity of data. Without double, information in data of small size is scarced and have some learning limit. As well as each classification method has its property. A method is the best solution for one data but is not the best for another. This article analyzes the characteristics of small data set learning. The Mega-fuzzification method for small data set learning is applied mainly. The comparison of different classification methods for small data set learning is also presented.								Anthony M., 1997, COMPUTATIONAL LEARNI; Chang F. M., 2006, WSEAS Transactions on Computers, V5; CHANG FM, 2008, EXPERT SYSTEMS APPL, V36; CHANG FM, 2005, 2005 P IEEE INT C SY, P566; Chang F. M., 2005, WSEAS Transactions on Information Science and Applications, V2; Huang CF, 1997, FUZZY SET SYST, V91, P69, DOI 10.1016/S0165-0114(96)00257-6; Huang CF, 2004, INT J APPROX REASON, V35, P137, DOI 10.1016/j.ijar.2003.06.001; JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541; Kiang MY, 2003, DECIS SUPPORT SYST, V35, P441, DOI 10.1016/S0167-9236(02)00110-0; Lauria EJM, 2007, EUR J OPER RES, V179, P234, DOI 10.1016/j.ejor.2006.01.016; Li DC, 2005, INT J ADV MANUF TECH, V27, P321, DOI 10.1007/s00170-003-2184-y; Li DC, 2006, INT J PROD RES, V44, P4491, DOI 10.1080/00207540600559849; Li DC, 2003, INT J PROD RES, V41, P4011, DOI 10.1080/0020754031000149211; MACKEY MC, 1977, SCIENCE, V197, P287, DOI 10.1126/science.267326; Niyogi P., 1998, P IEEE, P275; Quinlan JR, 1996, ACM COMPUT SURV, V28, P71, DOI 10.1145/234313.234346; Seo KK, 2007, EXPERT SYST APPL, V33, P491, DOI 10.1016/j.eswa.2006.05.030	17	1	1	WORLD SCIENTIFIC AND ENGINEERING ACAD AND SOC	ATHENS	AG LOANNOU THEOLOGOU 17-23, 15773 ZOGRAPHOU, ATHENS, GREECE		978-960-6766-41-1	ARTIF INT SER WSEAS			2008							122	127				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BHY60	WOS:000257462700015	
B	Burdescu, DD; Mihaescu, MC		Kazovsky, L; Borne, P; Mastorakis, N; KuriMorales, A; Sakellaris, I		Burdescu, Dumitru Dan; Mihaescu, Marian Cristian			Blending e-Learning and knowledge management for optimizing learning paths	ADVANCES ON ARTIFICIAL INTELLIGENCE, KNOWLEDGE ENGINEERING AND DATA BASES, PROCEEDINGS	Artificial Intelligence Series-WSEAS		English	Proceedings Paper	7th WSEAS International Conference on Artificial Intelligence, Knowledge Engineering and Data Bases	FEB 20-22, 2008	Cambridge, ENGLAND	WSEAS	Univ Cambridge	knowledge management; machine learning; e-Learning; learning path		Within any e-Learning environment there are many types of users, with different backgrounds and different goals. This paper addresses the problem of optimizing learner's learning path in order to achieve a certain goal. This goal regards acquisition of a certain level of knowledge regarding a discipline. The paper proposes a methodology for guiding the student such that he finally obtains needed knowledge level in minimum amount of time. Since evaluation is the activity that generates quality in teaching, the method is based on continuous testing and monitoring learners. Within this process, a learner's model is created and maintained. This model is consulted whenever needed for classification purposes of students.	[Burdescu, Dumitru Dan; Mihaescu, Marian Cristian] Univ Craiova, Software Engn Dept, Craiova 200440, Dolj, Romania	Burdescu, DD (reprint author), Univ Craiova, Software Engn Dept, Bvd Decebal,Nr 107, Craiova 200440, Dolj, Romania.						ADELSONVELSKII GM, 1962, DOKL AKAD NAUK SSSR+, V146, P263; Burdescu D.D., 2006, P INT JOINT C E BUS, P315; Han J., 2001, DATA MINING CONCEPTS; KNUTH D, 1997, ART COMPUTER PROGRAM, V3, P458; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1986, MACH LEARN, V1, P106; Rud O., 2001, DATA MINING COOKBOOK; Witten I. H., 2000, DATA MINING PRACTICA	8	0	0	WORLD SCIENTIFIC AND ENGINEERING ACAD AND SOC	ATHENS	AG LOANNOU THEOLOGOU 17-23, 15773 ZOGRAPHOU, ATHENS, GREECE		978-960-6766-41-1	ARTIF INT SER WSEAS			2008							396	402				7	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BHY60	WOS:000257462700058	
S	Lichtenstein, A; Oehme, A; Kupschick, S; Jurgensohn, T		Peter, C; Beale, R		Lichtenstein, Antje; Oehme, Astrid; Kupschick, Stefan; Juergensohn, Thomas			Comparing Two Emotion Models for Deriving Affective States from Physiological Data	AFFECT AND EMOTION IN HUMAN-COMPUTER INTERACTION: FROM THEORY TO APPLICATIONS	Lecture Notes in Computer Science		English	Proceedings Paper	3rd Workshop on Emotion in Human-Computer Interaction held at the Annual Conference of the British-HCI-Group	SEP 04, 2007	Lancaster, ENGLAND	British HCI Grp	Lancaster Univ	Emotion classification; dimensional model of affect; basic emotions; ambient intelligence; psychophysiology	NERVOUS-SYSTEM ACTIVITY	This paper describes an experiment on emotion measurement and classification based on different physiological parameters, which was conducted in the context of a European project on ambient intelligent mobile devices. Emotion induction material consisted of five four-minute video films that induced two positive and three negative emotions. The experimental design gave consideration to both, the basic and the dimensional model of the structure of emotion. Statistical analyses were conducted for films and for self-assessed emotional state and in addition, supervised machine learning technique was utilized. Recognition rates reached up to 72% for a specific emotion (one out of five) and up to 82% for an underlying dimension (one out of two).	[Lichtenstein, Antje] Tech Univ Berlin, Inst Psychol & Arbeitswissensch, Fachgebiet Mensch Maschine Syst, D-10587 Berlin, Germany	Lichtenstein, A (reprint author), Tech Univ Berlin, Inst Psychol & Arbeitswissensch, Fachgebiet Mensch Maschine Syst, Franklinstr 28-29, D-10587 Berlin, Germany.	Antje.Lichtenstein@zmms.tu-berlin.de; astrid.oehme@human-factors-consult.de; stefan.kupschick@human-factors-consult.de; thomas.juergensohn@human-factors-consult.de					Anttonen J., 2005, CHI 05 C P NEW YORK, P491; AX A, 1953, PSYCHOSOM MED, V55, P433; Bradley MM, 1993, STRUCTURE EMOTION, P48; Christie I.C., 2002, THESIS VIRGINIA POLY; COOK EW, 1989, J PSYCHOPHYSIOL, V3, P51; DETENBER BH, 1998, J BROADCAST ELECTRON, V21, P112; Dey AK, 2001, PERS UBIQUIT COMPUT, V5, P4, DOI 10.1007/s007790170019; EKMAN P, 1992, COGNITION EMOTION, V6; EKMAN P, 1983, SCIENCE, V221, P1208, DOI 10.1126/science.6612338; FELDMANBARRETT L, 1998, COGNITION EMOTION, V12, P579; FOREST F, 2006, 15 IST MOBILE WIRELE; Fredrickson BL, 2000, MOTIV EMOTION, V24, P237, DOI 10.1023/A:1010796329158; HERBON A, 2005, P 2005 HCI INT C LAS; Johnstone T., 2000, HDB EMOTIONS, P220; Lang P. J., 1980, TECHNOLOGY MENTAL HL, P119; LEVENSON RW, 1990, PSYCHOPHYSIOLOGY, V27, P363, DOI 10.1111/j.1469-8986.1990.tb02330.x; MAHLKE S, 2008, LNCS, V4868; Malik Marek, 1996, EUROPEAN HEART J, V17, P354; Nasoz F., 2003, INT J COGNITION TECH, V6; Neumann SA, 2001, J PSYCHOSOM RES, V50, P245, DOI 10.1016/S0022-3999(01)00198-2; PALOMBA D, 1993, STRUCTURE EMOTION, P158; Palomba D, 2000, INT J PSYCHOPHYSIOL, V36, P45, DOI 10.1016/S0167-8760(99)00099-9; PERETZ I, 1998, COGNITION, V100, P1; Peter C, 2006, INTERACT COMPUT, V18, P139, DOI 10.1016/j.intcom.2005.10.006; Prkachin KM, 1999, J PSYCHOSOM RES, V47, P255, DOI 10.1016/S0022-3999(99)00036-7; Ritz T, 2005, PSYCHOPHYSIOLOGY, V42, P568, DOI 10.1111/j.1469-8986.2005.00312.x; Roedema TM, 1999, PSYCHOPHYSIOLOGY, V36, P379, DOI 10.1017/S0048577299980290; Russell J. A., 1997, CIRCUMPLEX MODELS PE, P205, DOI 10.1037/10261-009; RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714; Russell JA, 1999, J PERS SOC PSYCHOL, V76, P805, DOI 10.1037//0022-3514.76.5.805; Vapnik V.N., 1999, NATURE STAT LEARNING	31	3	3	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	0302-9743	978-3-540-85098-4	LECT NOTES COMPUT SC			2008	4868						35	50				16	Computer Science, Cybernetics; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BIN45	WOS:000261051300004	
S	Tadeusiewicz, R; Szczepaniak, PS		Nguyen, NT; Jo, GS; Howlett, RJ; Jain, LC		Tadeusiewicz, R.; Szczepaniak, P. S.			Basic concepts of knowledge-based image understanding	AGENT AND MULTI-AGENT SYSTEMS: TECHNOLOGIES AND APPLICATIONS, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	2nd KES International Symposium on Agent and Multi-Agent Systems	MAR 26-28, 2008	Incheon, SOUTH KOREA	Inha Univ, Sch Comp & Informat Engn, KES Int, KES Focus Grp Agent & Multi Agent Syst		image understanding; machine learning; active contours	RECOGNITION SYSTEMS	In the paper, the main paradigm of image understanding as well as possible way for practical machine realization in relatively simple situations is presented. The notion 'simple situations' reflects more our humility with respect to the complication of human perception process than the form of objects to be recognized and interpreted. Crucial for our approach are formalization of human knowledge about class of images to be automatically interpreted and realization of cognitive resonance while the particular method put at work is the active contour approach.	[Tadeusiewicz, R.] AGH Univ Technol, PL-30059 Krakow, Poland	Tadeusiewicz, R (reprint author), AGH Univ Technol, Mickiewicza 30, PL-30059 Krakow, Poland.						Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; Kass M., 1988, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; LIS B, 2004, SOFT COMPUTING TOOLS; Ogiela L, 2006, LECT NOTES COMPUT SC, V4153, P244; Ogiela L, 2006, LECT NOTES CONTR INF, V344, P851; Ogiela MR, 2006, PATTERN RECOGN, V39, P2157, DOI 10.1016/j.patcog.2006.03.014; Ogiela MR, 2006, COMPUT VIS IMAGE UND, V103, P112, DOI 10.1016/j.cviu.2006.04.001; PEDRYCZ W, 2004, FUZZY SETS SYSTEMS, V128, P21; Tadeusiewicz R, 2007, LECT NOTES COMPUT SC, V4432, P477; TADEUSIEWICZ R, 2004, STUDIES FUZZINESS SO, V156; Tomczyk A, 2006, LECT NOTES COMPUT SC, V4029, P692; Tomczyk A., 2005, Proceedings. 5th International Conference on Intelligent Systems Design and Applications; Tomczyk A, 2004, LECT NOTES ARTIF INT, V3070, P760; TOMCZYK A, 2007, P IEEE INT WORKSH IM; Tomczyk A, 2005, ADV SOFT COMP, P303	15	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-78581-1	LECT NOTES ARTIF INT			2008	4953						42	52				11	Computer Science, Artificial Intelligence	Computer Science	BHN59	WOS:000254510100005	
S	Szczepaniak, PS		Nguyen, NT; Jo, GS; Howlett, RJ; Jain, LC		Szczepaniak, P. S.			Contribution of hypercontours to multiagent automatic image analysis	AGENT AND MULTI-AGENT SYSTEMS: TECHNOLOGIES AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	2nd KES International Symposium on Agent and Multi-Agent Systems	MAR 26-28, 2008	Incheon, SOUTH KOREA	Inha Univ, Sch Comp & Informat Engn, KES Int, KES Focus Grp Agent & Multi Agent Syst		image analysis; agents; machine learning; active contours		Hypercountors are methods for automatic image analysis. They can be interpreted as contextual classifiers that use expert knowledge and operate in supervised or unsupervised mode. In the present paper, it is shown that hypercontours may act as agents cooperating in recognition of objects placed on computer images.	Tech Univ Lodz, Inst Comp Sci, PL-90924 Lodz, Poland	Szczepaniak, PS (reprint author), Tech Univ Lodz, Inst Comp Sci, Ul Wolczanska 215, PL-90924 Lodz, Poland.						ALIEV RA, 2001, SOFT COMPUTING ITS A; KUNCHEVA LI, 2004, COMBINING PATTERN CL; LIU J, 2005, PROBLEM SOLVING COMP; PEDRYCZ W, 2004, FUZZY SETS SYSTEMS, V128, P21; TADEUSIEWICZ R, 2008, LNCS LNAI, V4953, P41; TOMCZYK A, 2007, LNCS LNAI, V4755; Tomczyk A, 2006, LECT NOTES COMPUT SC, V4029, P692; TOMCZYK A, 2005, P 4 INT C COMP REC S, P303; TOMECZYK A, 2005, P 5 INT C INT SYST D, P256; WANG Y, 2004, FUZZY LOGIC INTERNET, P309; Weiss G., 1999, MULTIAGENT SYSTEMS	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-78581-1	LECT NOTES ARTIF INT			2008	4953						647	653				7	Computer Science, Artificial Intelligence	Computer Science	BHN59	WOS:000254510100065	
S	Truong, MNQ; Hoang, TN		Nguyen, NT; Jo, GS; Howlett, RJ; Jain, LC		Truong, Minh Nhat Quang; Hoang, Trong Nghia			A multi-agent mechanism in machine learning approach to anti-virus system	AGENT AND MULTI-AGENT SYSTEMS: TECHNOLOGIES AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	2nd KES International Symposium on Agent and Multi-Agent Systems	MAR 26-28, 2008	Incheon, SOUTH KOREA	Inha Univ, Sch Comp & Informat Engn, KES Int, KES Focus Grp Agent & Multi Agent Syst		anti-virus; computer virus; machine learning; multi-agent		In this paper, we would like to introduce a multi-agent mechanism to protect target systems from computer virus infections. Using a machine learning approach, we first define a form of object knowledge to determine computer viruses and diagnosed objects. Second, we set up an association model of knowledge base and database. The database stores information of diagnosed objects. The knowledge base contains certain sets of deduction rules. Finally, we build two active agents to control virus infections. In an event-learning model, the first agent named Virus Auto-protect Agent is used to monitor all suspicious events. The second one, Virus Scanning Agent is used in an explanation-learning model to scan for viruses, to warn users of dangers and to restore the data from the previous state of safety. The experimentation results show that the anti-virus system can quickly recognize known and unknown computer virus infections.								ARNOLD W, 2000, P 2000 INT VIR B C; BONTCHEV V, 1998, THESIS U HAMBURG; BORDERA M, 1997, LEGAL SYSTEM FIGHTIN; KIEM H, 2005, P RIVF 05 INT C COMP, P295; KIEM H, 2006, P IEEE INT C GRAN CO, P600; KIEM H, 2004, P JOINT WORKSH VIETN, P61; QUANG TMN, 2006, P WMSCI 2006 C FLOR, P277; RABAIOTTI J, 2007, THESIS CARDIFF U, P38; SCHULTZ MG, 2001, P IEEE S SEC PRIV OA; SZOR P, 2002, BEHAV BLOCKING, pCH11; THUY NT, 1999, P 1 INT C ADV COMM T, P374; THUY NT, 1998, P LASTED INT C ART I, P371	12	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-78581-1	LECT NOTES ARTIF INT			2008	4953						743	752				10	Computer Science, Artificial Intelligence	Computer Science	BHN59	WOS:000254510100075	
S	Frank, E; Hall, M		Wobcke, W; Zhang, M		Frank, Eibe; Hall, Mark			Additive Regression Applied to a Large-Scale Collaborative Filtering Problem	AI 2008: ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	21st Australian Joint Conference on Artificial Intelligence	DEC 01-05, 2008	Auckland, NEW ZEALAND		Auckland Univ Technol			The much-publicized Netflix competition has put the spotlight on the application domain of collaborative filtering and has sparked interest in machine learning algorithms that can be applied to this sort of problem. The demanding nature of the Netflix data has lead to some interesting and ingenious modifications to standard learning methods in the name of efficiency and speed. There are three basic methods that have been applied in most approaches to the Netflix problem so far: stand-alone neighborhood-based methods, latent factor models based on singular-value decomposition, and ensembles consisting of variations of these techniques. In this paper we investigate the application of forward stage-wise additive modeling to the Netflix problem, using two regression schemes as base learners: ensembles of weighted simple linear regressors and k-means clustering-the latter being interpreted as a tool for multivariate regression in this context. Experimental results show that our methods produce competitive results.	[Frank, Eibe] Univ Waikato, Dept Comp Sci, Hamilton, New Zealand	Frank, E (reprint author), Univ Waikato, Dept Comp Sci, Hamilton, New Zealand.	eibe@cs.waikato.ac.nz; mhall@pentaho.org					BELL R., 2007, ASA STAT COMPUTING G, V18, P4; BELL RM, 2007, KDD CUP WORKSH 13 AC; Dembczynski K., 2008, P 3 INT WORKSH MIN C, P169; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; KURUCZ M, 2007, KDD CUP WORKSH 13 AC; LIM YJ, 2007, KDD CUP WORKSH 13 AC; PATEREK A, 2007, KDD CUP WORKSH 13 AC; TAKACS G, 2007, KDD CUP WORKSH 13 AC; WU M, 2007, KDD CUP WORKSH 13 AC	11	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-89377-6	LECT NOTES ARTIF INT			2008	5360						435	446				12	Computer Science, Artificial Intelligence	Computer Science	BIW26	WOS:000263294500044	
S	Thornton, J; Faichney, J; Blumenstein, M; Hine, T		Wobcke, W; Zhang, M		Thornton, John; Faichney, Jolon; Blumenstein, Michael; Hine, Trevor			Character Recognition Using Hierarchical Vector Quantization and Temporal Pooling	AI 2008: ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	21st Australian Joint Conference on Artificial Intelligence	DEC 01-05, 2008	Auckland, NEW ZEALAND		Auckland Univ Technol		VISUAL-CORTEX	In recent years, there has been a cross-fertilization of ideas between computational neuroscience models of the operation of the neocortex and artificial intelligence models of machine learning. Much of this work has focussed on the mammalian visual cortex, treating it as a hierarchically-structured pattern recognition machine that exploits statistical regularities in retinal input. It has further been proposed that the neocortex represents sensory information probabilistically, using some form of Bayesian inference to disambiguate noisy data. In the current paper, we focus on a particular model of the neocortex developed by Hawkins, known as hierarchical temporal memory (HTM). Our aim is to evaluate all important and recently implemented aspect of this model, namely its ability to represent temporal sequences of input within a hierarchically structured vector quantization algorithm. We test this temporal pooling feature of HTM on a benchmark of cursive handwriting recognition problems and compare it, to a current state-of-the-art support vector machine implementation. We also examine whether two pre-processing techniques can enhance the temporal pooling algorithm's performance. Our results show that a relatively simple temporal pooling approach can produce recognition rates that approach the current state-of-the-art without the need for extensive timing of parameters. We also show that temporal pooling performance is Surprisingly unaffected by the use of preprocessing techniques.	[Thornton, John; Faichney, Jolon; Blumenstein, Michael; Hine, Trevor] Griffith Univ, Inst Integrated & Intelligent Syst, Nathan, Qld 4111, Australia	Thornton, J (reprint author), Griffith Univ, Inst Integrated & Intelligent Syst, Nathan, Qld 4111, Australia.	j.thornton@griffith.edu.au; j.faichney@griffith.edu.au; m.blumenstein@griffith.edu.au; t.hine@griffith.edu.au					Camastra F, 2007, PATTERN RECOGN, V40, P3721, DOI 10.1016/j.patcog.2007.03.014; DEAN T, 2006, P 9 INT S ART INT MA; Dean T., 2005, P 20 NAT C ART INT A, P938; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; GEORGE D, 2006, HTM LEARNING ALGORIT; GEORGE D, 2005, P INT JOINT C NEUR N; Gersho A., 1992, VECTOR QUANTIZATION; Gonzalez R. C., 1992, DIGITAL IMAGE PROCES; Hawkins J., 2006, HIERARCHICAL TEMPORA; Hawkinsi J., 2004, INTELLIGENCE; Hubel DH, 1998, NEURON, V20, P401, DOI 10.1016/S0896-6273(00)80984-8; Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; MIYASHITA Y, 1988, NATURE, V335, P817, DOI 10.1038/335817a0; Mountcastle VB, 2003, CEREB CORTEX, V13, P2, DOI 10.1093/cercor/13.1.2; Nicchiotti G., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), DOI 10.1109/ICDAR.1999.791891; Pratt W. K., 2001, DIGITAL IMAGE PROCES; Serre T, 2007, P NATL ACAD SCI USA, V104, P6424, DOI 10.1073/pnas.0700622104; Thornton J, 2006, LECT NOTES COMPUT SC, V4304, P1259	19	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-89377-6	LECT NOTES ARTIF INT			2008	5360						562	572				11	Computer Science, Artificial Intelligence	Computer Science	BIW26	WOS:000263294500057	
J	Plisson, J; Lavrac, N; Mladenic, D; Erjavec, T				Plisson, Joel; Lavrac, Nada; Mladenic, Dunja; Erjavec, Tomaz			Ripple Down Rule learning for automated word lemmatisation	AI COMMUNICATIONS			English	Article						Ripple Down Rules; lemmatisation; machine learning; Slovene language		Lemmatisation is the process of finding the normalised forms of wordforms as they appear in text. It is a useful preprocessing step for a large number of language engineering tasks, and especially important for languages with rich inflection morphology. This paper presents a machine learning approach to automated word lemmatisation using a Ripple Down Rule learning algorithm, specially adapted to this task. By focusing on word suffixes, the induced Ripple Down Rules determine which wordform suffix should be removed and/or added to generate the lemma. The rules, induced from a lexicon of lemmatised Slovene words, were evaluated by cross-validation in the lexicon and on a hand-validated annotated corpus, and compared to previous work using two other inductive lemmatisers, ATRIS and CLOG. We show that RDR outperforms ATRIS and is more flexible than CLOG, as it can, unlike CLOG, also work without prior part-of-speech tagging. The RDR lemmatiser is easy to train and use for new languages and is, together with CLOG, available via a Web service.	[Plisson, Joel; Lavrac, Nada; Mladenic, Dunja; Erjavec, Tomaz] Jozef Stefan Inst, Ljubljana 1000, Slovenia; [Lavrac, Nada] Univ Nova Gorcia, Nova Gorica 5000, Slovenia	Plisson, J (reprint author), Jozef Stefan Inst, Jamova 39, Ljubljana 1000, Slovenia.	joel.plisson@ijs.si					Brants T., 2000, P 6 C APPL NAT LANG, P224, DOI 10.3115/974147.974178; CHRUPALA G, 2006, P SEPLN 2006 ZAR SPA; CLARK A, 2002, P 40 ANN M ASS COMP, P513; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Compton P., 1990, Knowledge Acquisition, V2, DOI 10.1016/S1042-8143(05)80017-2; DZEROSKI S, 2000, LEARNING LANGUAGE LO, V1925, P69, DOI 10.1007/3-540-40030-3_5; ERJAVEC T, 2006, 5 INT C LANG RES EV, P2138; Erjavec T, 2004, APPL ARTIF INTELL, V18, P17, DOI 10.1080/08839510490250088; ERJAVEC T, 2004, 4 INT C LANG RES EV, P1535; Erjavec T., 2006, Informatica, V30; GAINES B, 1991, 6 AAAI KNOW ACQ KNOW; Kiparsky Paul, 1973, FESTSCHRIFT M HALLE, P93; Ling C. X., 1994, Journal of Artificial Intelligence Research, V1; MANANDHAR S, 1998, LECT NOTES ARTIF INT, V1446, P135; MLADENIC D, 1993, P 10 INT C MACH LEAR, P205; Mladenic D., 2002, P INT C MACH LEARN, P427; MOONEY RJ, 1995, J ARTIF INTELL RES, V3, P1; MOONEY RJ, 1997, P 6 INT WORKSH IND L, P3; NAKOV P, 2003, P WORKSH BALK LANG R; PORTER M, 1980, ACM SIGIR C R D INF, P318; Rivest R. L., 1987, Machine Learning, V2, DOI 10.1007/BF00058680; SRINIVASAN A, 1991, P EUR KNOWL ACQ WORK; Stroppa N., 2005, P 9 C COMP NAT LANG, P120, DOI 10.3115/1706543.1706565; van den Bosch A., 1999, P 37 ANN M ASS COMP, P285, DOI 10.3115/1034678.1034726; Yarowski D., 2001, P 1 INT C HUM LANG T, P1, DOI 10.3115/1072133.1072187	25	3	3	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0921-7126		AI COMMUN	AI Commun.		2008	21	1					15	26				12	Computer Science, Artificial Intelligence	Computer Science	291QJ	WOS:000255211600002	
J	Fierens, D				Fierens, Daan			Learning directed probabilistic logical models from relational data	AI COMMUNICATIONS			English	Article						Probabilistic logic learning; Bayesian networks; decision trees	ORDERING-SEARCH	Data that has a complex relational structure and in which observations are noisy or partially missing poses several challenges to traditional machine learning algorithms. One solution to this problem is the use of so-called probabilistic logical models (models that combine elements of first-order logic with probabilities) and corresponding learning algorithms. In this thesis we focus on directed probabilistic logical models. We show how to represent such models and develop several algorithms to learn such models from data.	Katholieke Univ Leuven, Dept Comp Sci, B-3001 Heverlee, Belgium	Fierens, D (reprint author), Katholieke Univ Leuven, Dept Comp Sci, Celestijnenlaan 200A, B-3001 Heverlee, Belgium.	daan.fierens@cs.kuleuven.be			Institute for the Promotion of Innovation by Science and Technology in Flanders	Daan Fierens is supported by the Institute for the Promotion of Innovation by Science and Technology in Flanders (IWT Vlaanderen).	De Raedt L, 2008, COGN TECHNOL, P1; DE RAEDT L., 2003, SIGKDD EXPLORATIONS, V5, P31; Fierens D, 2005, LECT NOTES ARTIF INT, V3625, P121; Fierens D, 2007, LECT NOTES ARTIF INT, V4701, P567; Fierens D, 2005, LECT NOTES ARTIF INT, V3720, P556; Fierens D., 2008, THESIS KATHOLIEKE U; Friedman N, 1998, NATO ADV SCI I D-BEH, V89, P421; Neapolitan R. E., 2003, LEARNING BAYESIAN NE; Ramon J, 2008, MACH LEARN, V70, P169, DOI 10.1007/s10994-007-5033-7	9	0	0	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0921-7126		AI COMMUN	AI Commun.		2008	21	4					269	270		10.3233/AIC-2008-0428		2	Computer Science, Artificial Intelligence	Computer Science	394MZ	WOS:000262452100006	
S	Agarwal, S		Freund, Y; Gyorfi, L; Turan, G; Zeugmann, T		Agarwal, Shivani			Generalization Bounds for Some Ordinal Regression Algorithms	ALGORITHMIC LEARNING THEORY, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	19th International Conference on Algorithmic Learning Theory	OCT 13-16, 2008	Budapest, HUNGARY	Aegon Hungary, Fraunhofer IAIS, Univ Szeged, Inst Informat, Tohoku Univ, Dept Syst Informat Sci, Kyushu Univ, Dept Informat, Hokkaido Univ, Div Comp			CLASSIFICATION; RANKING	The problem of ordinal regression, in which the goal is to learn a rule to predict labels from a discrete but ordered set, has gained considerable attention in machine learning in recent years. We study generalization properties of algorithms for this problem. We start with the most basic algorithms that work by learning a real-valued function in a regression framework and then rounding off a predicted real value to the closest discrete label; our most basic bounds for such algorithms are derived by relating the ordinal regression error of the resulting prediction rule to the regression error of the learned real-valued function. We end with a margin-based bound for the state-of-the-art ordinal regression algorithm of Chu & Keerthi (2007).	MIT, Cambridge, MA 02139 USA	Agarwal, S (reprint author), MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.						AGARWAL S, 2005, P 18 ANN C LEARN THE; Anthony M., 1999, LEARNING NEURAL NETW; Bartlett PL, 2006, J AM STAT ASSOC, V101, P138, DOI 10.1198/016214505000000907; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; Cardoso JS, 2007, J MACH LEARN RES, V8, P1393; Chu W, 2005, J MACH LEARN RES, V6, P1019; Chu W, 2007, NEURAL COMPUT, V19, P792, DOI 10.1162/neco.2007.19.3.792; Crammer K, 2005, NEURAL COMPUT, V17, P145, DOI 10.1162/0899766052530848; Crammer K, 2002, ADV NEUR IN, V14, P641; Frank E., 2001, P 12 EUR C MACH LEAR, P145; Harrington EF, 2003, P 20 INT C MACH LEAR, P250; Herbrich R, 2000, ADV NEUR IN, P115; Kramer S., 2001, FUNDAMENTA INFORM, V47, P1001; Mathieson M., 1996, Neural Networks in Financial Engineering. Proceedings of the Third International Conference on Neural Networks in the Capital Markets; McCullagh P., 1989, GEN LINEAR MODELS; Rajaram Shyamsundar, 2005, P NIPS 2005 WORKSH L; Rennie J. D. M., 2005, P IJCAI MULT WORKSH; Shashua A., 2003, ADV NEURAL INFORM PR, P937; SHASHUA A, 2002, 200239 HEBR U JER LE; Waegeman W, 2008, PATTERN RECOGN LETT, V29, P1, DOI 10.1016/j.patrec.2007.07.019; Zhang T, 2004, ANN STAT, V32, P56; Zhang T, 2002, J MACH LEARN RES, V2, P527, DOI 10.1162/153244302760200713	22	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-87986-2	LECT NOTES ARTIF INT			2008	5254						7	21				15	Computer Science, Artificial Intelligence; Mathematics, Applied	Computer Science; Mathematics	BIL22	WOS:000260480700002	
S	Cortes, C; Mohri, M; Riley, M; Rostamizadeh, A		Freund, Y; Gyorfi, L; Turan, G; Zeugmann, T		Cortes, Corinna; Mohri, Mehryar; Riley, Michael; Rostamizadeh, Afshin			Sample Selection Bias Correction Theory	ALGORITHMIC LEARNING THEORY, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	19th International Conference on Algorithmic Learning Theory	OCT 13-16, 2008	Budapest, HUNGARY	Aegon Hungary, Fraunhofer IAIS, Univ Szeged, Inst Informat, Tohoku Univ, Dept Syst Informat Sci, Kyushu Univ, Dept Informat, Hokkaido Univ, Div Comp				This paper presents a theoretical analysis of sample selection bias correction. The sample bias correction technique commonly used in machine learning consists of reweighting the cost of an error on each training point of a biased sample to more closely reflect the unbiased distribution. This relies on weights derived by various estimation techniques based on finite samples. We analyze the effect of an error in that estimation on the accuracy of the hypothesis returned by the learning algorithm for two estimation techniques: a cluster-based estimation technique and kernel mean matching. We also report the results of sample bias correction experiments with several data, sets using these techniques. Our analysis is based on the novel concept of distribution stability which generalizes the existing concept of point-based stability. Much of our work and proof techniques can be used to analyze. other importance weighting techniques and their effect on accuracy when using a distributionally stable algorithm.	[Cortes, Corinna; Mohri, Mehryar; Riley, Michael] Google Res, New York, NY 10011 USA	Cortes, C (reprint author), Google Res, 76 9th Ave, New York, NY 10011 USA.						BICKEL S, 2007, ICML 2007, P81; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; Breiman L, 1984, CLASSIFICATION REGRE; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; DEVROYE LP, 1979, IEEE T INFORM THEORY, V25, P601, DOI 10.1109/TIT.1979.1056087; DUDIK M, 2006, NIPS 2005; Elkan C., 2001, IJCAI, P973; FAN W, 2005, ICDM 2005, P605; HECKMAN JJ, 1979, ECONOMETRICA, V47, P151; HUANG J, 2006, CS200644 U WAT; Huang J., 2006, NIPS, P601; Kearns M. J., 1997, COMPUTATIONAL LEARNI, P152; Little R, 1986, STAT ANAL MISSING DA; Saunders C, 1998, ICML 98 P 15 INT C M, P515; Steinwart I, 2002, J MACH LEARN RES, V2, P67; SUGIYAMA M, 2008, NIPS 2008; Vapnik VN, 1998, STAT LEARNING THEORY; ZADROZNY B, 2003, ICDM 2003; ZADROZNY B, 2004, ICML 2004	19	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-87986-2	LECT NOTES ARTIF INT			2008	5254						38	53				16	Computer Science, Artificial Intelligence; Mathematics, Applied	Computer Science; Mathematics	BIL22	WOS:000260480700004	
S	Lingner, T; Meinicke, P		Crandall, KA; Lagergren, J		Lingner, Thomas; Meinicke, Peter			Fast Target Set Reduction for Large-Scale Protein Function Prediction: A Multi-class Multi-label Machine Learning Approach	ALGORITHMS IN BIOINFORMATICS, WABI 2008	LECTURE NOTES IN BIOINFORMATICS		English	Proceedings Paper	8th International Workshop on Algorithms in Bioinformatics (WABI 2008)	SEP 15-19, 2008	Karlsruhe, GERMANY		Univ Karlsruhe	protein classification; large-scale; multi-class; multi-label; Pfam; homology search; metagenomics; target set reduction; protein function prediction; machine learning	REMOTE HOMOLOGY DETECTION; SEQUENCE SIMILARITY; CLASSIFICATION; KERNELS	Large-scale sequencing projects have led to a vast amount of protein sequences, which have to be assigned to functional categories. Currently, profile hidden markov models and kernel-based machine learning methods provide the most accurate results for protein classification. However, the prediction of new sequences with these approaches is computationally expensive. We present an approach for fast scoring of protein sequences by means of feature-based protein sequence representation and multi-class multi-label machine learning techniques. Using the Pfam database, we show that our method provides high computational efficiency and that the approach is well-suitable for pre-filtering of large sequence sets.	[Lingner, Thomas; Meinicke, Peter] Univ Gottingen, Inst Microbiol & Genet, Dept Bioinformat, D-37077 Gottingen, Germany	Lingner, T (reprint author), Univ Gottingen, Inst Microbiol & Genet, Dept Bioinformat, Goldschmidtstr 1, D-37077 Gottingen, Germany.						ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Ben-Hur A., 2003, BIOINFORMATICS, V19, P26; COHEN C, 2006, ARTIF INTELL MED, P7; Diplaris S, 2005, LECT NOTES COMPUT SC, V3746, P448; Eddy SR, 1998, BIOINFORMATICS, V14, P755, DOI 10.1093/bioinformatics/14.9.755; Elisseeff A., 2001, NEURAL INFORM PROCES, P681; Finn RD, 2006, NUCLEIC ACIDS RES, V34, pD247, DOI 10.1093/nar/gkj149; Friedberg I, 2006, BRIEF BIOINFORM, V7, P225, DOI 10.1093/bib/bbl004; Han LY, 2006, PROTEOMICS, V6, P4023, DOI 10.1002/pmic.200500938; Hoff KJ, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-217; Jensen LJ, 2003, BIOINFORMATICS, V19, P635, DOI 10.1093/bioinformatics/btg036; Lee K, 2006, NUCLEIC ACIDS RES, V34, P4655, DOI 10.1093/nar/gkl638; Leslie Christina, 2002, Pac Symp Biocomput, P564; Leslie CS, 2004, BIOINFORMATICS, V20, P467, DOI 10.1093/bioinformatics/btg431; Liao L, 2003, J COMPUT BIOL, V10, P857, DOI 10.1089/106652703322756113; Lingner T, 2006, BIOINFORMATICS, V22, P2224, DOI 10.1093/bioinformatics/btl376; Ong SAK, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-300; PARIDEY G, 2006, 06028 TR U MINN DEP; Rangwala H, 2005, BIOINFORMATICS, V21, P4239, DOI 10.1093/bioinformatics/bti687; Rifkin R., 2003, NATO SCI SERIES, V190, P131; Rifkin R, 2004, J MACH LEARN RES, V5, P101; Saigo H, 2004, BIOINFORMATICS, V20, P1682, DOI 10.1093/bioinformatics/bth141; SCHAPIRE R, 1998, SYSTEM MULTICLASS MU; Strope PK, 2007, GENOMICS, V89, P602, DOI 10.1016/j.ygeno.2007.01.008; Walters JP, 2007, J VLSI SIG PROC SYST, V48, P223, DOI 10.1007/s11265-007-0062-9; Yooseph S., 2007, PLOS BIOL, V5, P16; Zhang M, 2005, IEEE INT C GRAN COMP, V2, P718	27	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-87360-0	LECT N BIOINFORMAT			2008	5251						198	209				12	Biochemical Research Methods; Computer Science, Information Systems; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Computer Science; Mathematical & Computational Biology	BIJ46	WOS:000260069100017	
S	Pfeifer, N; Kohlbacher, O		Crandall, KA; Lagergren, J		Pfeifer, Nico; Kohlbacher, Oliver			Multiple Instance Learning Allows MHC Class II Epitope Predictions Across Alleles	ALGORITHMS IN BIOINFORMATICS, WABI 2008	LECTURE NOTES IN BIOINFORMATICS		English	Proceedings Paper	8th International Workshop on Algorithms in Bioinformatics (WABI 2008)	SEP 15-19, 2008	Karlsruhe, GERMANY		Univ Karlsruhe		MAJOR HISTOCOMPATIBILITY COMPLEX; PEPTIDE BINDING PREDICTION; HLA; MOLECULES; GENERATION; DATABASES; BINDERS; SERVER	Human adaptive immune response relies on the recognition of short peptides through proteins of the major histocompatibility complex (MHC). MHC class II molecules are responsible for the recognition of antigens external to a cell. Understanding their specificity is an important step in the design of peptide-based vaccines. The high degree of polymorphism in MHC class II makes the prediction of peptides that bind (and then usually cause an immune response) a challenging task. Typically, these predictions rely on machine learning methods, thus a sufficient amount of data points is required. Due to the scarcity of data, currently there are reliable prediction models only for about 7% of all known alleles available. We show how to transform the problem of MHC class II binding peptide prediction into a well-studied machine learning problem called multiple instance learning. For alleles with sufficient data, we show how to build a well-performing predictor using standard kernels for multiple instance learning. Furthermore, we introduce a new method for training a classifier of an allele without the necessity for binding allele data of the target allele. Instead, we use binding peptide data from other alleles and similarities between the structures of the MHC class II alleles to guide the learning process. This allows for the first time constructing predictors for about two thirds of all known MHC class II alleles. The average performance of these predictors on 14 test alleles is 0.71, measured as area under the ROC curve.	[Pfeifer, Nico; Kohlbacher, Oliver] Univ Tubingen, Div Simulat Biol Syst, Ctr Bioinformat Tubingen, D-72076 Tubingen, Germany	Pfeifer, N (reprint author), Univ Tubingen, Div Simulat Biol Syst, Ctr Bioinformat Tubingen, D-72076 Tubingen, Germany.		Kohlbacher, Oliver/B-7310-2008	Kohlbacher, Oliver/0000-0003-1739-4598			Brusic V, 1998, BIOINFORMATICS, V14, P121, DOI 10.1093/bioinformatics/14.2.121; Bui HH, 2005, IMMUNOGENETICS, V57, P304, DOI 10.1007/s00251-005-0798-y; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Consogno G, 2003, BLOOD, V101, P1038, DOI 10.1182/blood-2002-03-0933; Crooks GE, 2004, GENOME RES, V14, P1188, DOI 10.1101/gr.849004; DeLuca DS, 2007, IMMUNOGENETICS, V59, P25, DOI 10.1007/s00251-006-0176-4; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; DONNES P, 2006, NUCLEIC ACIDS RES, V34, P194; Dooly D., 2002, J MACHINE LEARNING R, V3, P651; FELDHAHN M, 2008, NUCLEIC ACIDS RES, DOI DOI 10.1093/NAR/GKN229; Gartner T, 2002, ICML, P179; Guan PP, 2003, NUCLEIC ACIDS RES, V31, P3621, DOI 10.1093/nar/gkg510; HAMMER J, 1994, P NATL ACAD SCI USA, V91, P4456, DOI 10.1073/pnas.91.10.4456; Hertz T, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-S1-S3; Jacob L, 2008, BIOINFORMATICS, V24, P358, DOI 10.1093/bioinformatics/btm611; Karpenko O, 2005, ARTIF INTELL MED, V35, P147, DOI 10.1016/j.artmed.2005.02.002; Kawashima S, 1999, NUCLEIC ACIDS RES, V27, P368, DOI 10.1093/nar/27.1.368; Li H, 2004, RECOMB, P262; NIELSEN M, 2007, PLOS ONE, V2, P796; Nielsen M, 2004, BIOINFORMATICS, V20, P1388, DOI 10.1093/bioinformatics/bth100; Nielsen M, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-238; Noguchi H, 2002, J BIOSCI BIOENG, V94, P264, DOI 10.1263/jbb.94.264; PETERS B, 2005, PLOS BIOL, V3, P91; RAMMENSEE HG, 1995, IMMUNOGENETICS, V41, P178, DOI 10.1007/BF00172063; RAYS S, 2001, ICML 2001, P425; Reche PA, 2004, IMMUNOGENETICS, V56, P405, DOI 10.1007/s00251-004-0709-7; Robinson J, 2003, NUCLEIC ACIDS RES, V31, P311, DOI 10.1093/nar/GKG070; Salomon J, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-501; Schoenberg IJ, 1938, T AM MATH SOC, V44, P522, DOI 10.2307/1989894; Scholkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565; Singh H, 2001, BIOINFORMATICS, V17, P1236, DOI 10.1093/bioinformatics/17.12.1236; Sturniolo T, 1999, NAT BIOTECHNOL, V17, P555; TOPALIAN SL, 1994, CURR OPIN IMMUNOL, V6, P741, DOI 10.1016/0952-7915(94)90078-7; Venkatarajan MS, 2001, J MOL MODEL, V7, P445, DOI 10.1007/s00894-001-0058-5; Wan J, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-463; WANG P, 2008, PLOS COMPUT BIOL, V4; Zaitlen N, 2007, LECT NOTES COMPUT SC, V4453, P181	37	5	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-87360-0	LECT N BIOINFORMAT			2008	5251						210	221				12	Biochemical Research Methods; Computer Science, Information Systems; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Computer Science; Mathematical & Computational Biology	BIJ46	WOS:000260069100018	
B	Son, JW; Park, SB; Han, YJ; Park, SY		Sun, M; Ock, CY; Byun, JY; Bi, YD; Lin, HF		Son, Jeong-Woo; Park, Seong-Bae; Han, Young-Jin; Park, Se-Young			A Weighted k-Nearest Neighborhood for BaseNP Detection under Covariate Shift	ALPIT 2008: SEVENTH INTERNATIONAL CONFERENCE ON ADVANCED LANGUAGE PROCESSING AND WEB INFORMATION TECHNOLOGY, PROCEEDINGS			English	Proceedings Paper	7th International Conference on Advanced Language Processing and Web Information Technology	JUL 23-25, 2008	Liaoning, PEOPLES R CHINA		Dalian Univ Technol			In common, machine learning methods, there is a basic assumption that training data and test data are sampled from the same distribution. However, this assumption is commonly violated in practical fields. The situation. where the training and test data are generated from different distributions is so-called covariate shift. In natural language processing, it is highly possible to occur covariate shift due to the size of sample space. Natural language data have theoretically infinite size, which causes that the distribution of training data can not reflect that of entire data. In this paper, we try to verify that the performance of methods on natural language processing can be improved by reducing error from covariate shift. For this purpose, we propose the importance weighted k-NN for base noun detection. In the proposed method, the weights are set as a difference between the training and test distribution. Theoretically, the performance under covariate shift can be improved using importance weight method. In the experiment, the proposed method shows better performance than normal k-NN.	[Son, Jeong-Woo; Park, Seong-Bae; Han, Young-Jin; Park, Se-Young] Kyungpook Natl Univ, Dept Comp Engn, Taegu 702701, South Korea	Son, JW (reprint author), Kyungpook Natl Univ, Dept Comp Engn, Taegu 702701, South Korea.	jwson@sejong.knu.ac.kr; sbpark@sejong.knu.ac.kr; yjhan@sejong.knu.ac.kr; seyoung@knu.ac.kr					ARGAMON S, 1999, J EXPT THEORETICAL A, V11; Baldi P., 1998, BIOINFORMATICS MACHI; BICKEL S, 2007, ADV NEURAL INFORM PR, V19; DAELEMANS W, 1999, J MACHINE LEARNING, V34; Daelemans W, 1999, 9901 ILK; DEJEAN H, 2000, COLING 2000; ERIK F, 2000, COLING 2000, P857; HUANG J, 2007, ADV NEURAL INFORM PR, V19; Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19; Mitchell T, 1997, MACHINE LEARNING; PENG J, 2004, IEEE T PATTERN ANAL, V26; QUINLAN JR, 1993, MORGANKAUFMANN SERIE; RAMSHAW L, 1995, 3 ACL WORKSH VER LAR; SHELTON CR, 2001, THESIS MIT; Shimodaira H, 2000, J STAT PLAN INFER, V90, P227, DOI 10.1016/S0378-3758(00)00115-4; Sugiyama M., 2005, STAT DECISIONS, V23, P249, DOI 10.1524/stnd.2005.23.4.249; Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3	17	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		978-0-7695-3273-8				2008							87	92		10.1109/ALPIT.2008.78		6	Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications	Computer Science; Telecommunications	BIM30	WOS:000260735100016	
B	Nguyen, DK; Bui, TD		Sun, M; Ock, CY; Byun, JY; Bi, YD; Lin, HF		Nguyen, Duy Khuong; Bui, The Duy			Recognizing Vietnamese Online Handwritten Separated Characters	ALPIT 2008: SEVENTH INTERNATIONAL CONFERENCE ON ADVANCED LANGUAGE PROCESSING AND WEB INFORMATION TECHNOLOGY, PROCEEDINGS			English	Proceedings Paper	7th International Conference on Advanced Language Processing and Web Information Technology	JUL 23-25, 2008	Liaoning, PEOPLES R CHINA		Dalian Univ Technol			Vietnamese alphabet is based on the Latin alphabet with the addition of nine accent marks or diacritics four of them to create additional sounds, and the other five to indicate the tone of each word. Because Vietnamese is a tonal language that uses tone to distinguish words, recognizing diacritics is an important part in recognizing Vietnamese word. However, in written form, diacritics are much smaller then the characters, which make very them hard to recognize. Previous works on Vietnamese characters recognition often pre-process input with a graph-based approach by trying to separate the main characters with their diacritics by determining connected regions at pixel level. his approach, however, only works well where the input contains only characters with separable diacritics, for example, scanned image of printed documents. We propose in this paper a robust method to recognize online Vietnamese characters with diacritics. Using cosine transformation with appropriated sampling algorithms, we represent multiple strokes of a character together in a single set of features. This set of features is then used as the input for a well designed machine learning based system. We have tested our system on the combination of Vietnamese characters with diacritics and Section 1c (isolated characters) of the Unipen data set, and have obtained very competitive results.	[Nguyen, Duy Khuong; Bui, The Duy] Vietnam Natl Univ, Coll Technol, Hanoi, Vietnam	Nguyen, DK (reprint author), Vietnam Natl Univ, Coll Technol, Hanoi, Vietnam.	s0420219@coltech.vnu.vn; duybt@coltech.vnu.vn					AHMED N, 1974, IEEE T COMPUTERS, V23; BECKER PW, 1972, IEEE T SYSTEM MAN CY, V2; BELLEGARDA JR, 1996, Patent No. 5491758; BUI TD, 2007, P ALPIT 2007; CONNELL S, 2001, PATTERN RECOGNITION, V34; CONNELL SD, 1998, P ICPR; GAGNE C, 2006, IJDAR, V8; GUYON I, 1994, P 14 ICPR; Hagan M. T, 1995, NEURAL NETWORK DESIG; HEBERT JF, 1998, P 14 ICPR; KIEM H, 1999, P ICIP99, P585; LI X, 1998, PATTERN RECOGNITION, V31; MANDLER E, 1985, P 4 SCAND C IM AN JU; PARIZEAU M, 2001, P 6 ICDAR; POLYAKOV VG, 1995, Patent No. 5473742; QUAN V, 2001, P ICDAR01; QUAN V, 2002, P ICPR02; TAPPEN CC, 1990, IEEE T PATTERN ANAL, V12; TEREDESAI A, 2004, CEC 04; TEREDESAI A, 2002, P IND C COMP VIS GRA	20	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		978-0-7695-3273-8				2008							279	284		10.1109/ALPIT.2008.58		6	Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications	Computer Science; Telecommunications	BIM30	WOS:000260735100049	
S	Zheng, H; Wang, H; Lightbody, G; McCullagh, P; McAllister, G		Jan, J; Kozumplik, J; Provaznik, I		Zheng, H.; Wang, H.; Lightbody, G.; McCullagh, P.; McAllister, G.			Classifier Comparison For Auditory Brainstem Responses	ANALYSIS OF BIOMEDICAL SIGNALS AND IMAGES	Biosignal-Brno		English	Proceedings Paper	19th International EURASIP Conference (BIOSIGNAL)	JUN, 2008	Brno, CZECH REPUBLIC	Brno Univ Technol, Fac Elect Engn & Commun, Dept Biomed Engn, European Assoc Speech, Signal & Image Proc (EURASIP), Inst Elect & Elect Engineers, Engn Med & Biol Soc (IEEE EMB)				Expert classification of hearing levels from the Auditory Brainstem Response can be assisted in an objective manner through the use of machine learning algorithms. In this paper features are ranked and a comparison is made of the number of features used within several topical algorithms, namely, Naive Bayes (NB), KStar and Multi-Layer Perceptron. Receiver Operating Characteristic (ROC) graphs showing the relationship between sensitivity and specificity where used as a comparison mechanism. The outcome showed that reducing the input feature set from 20 to 4 did not have a significant impact on the ROC performance of all three models. Overall, NB provided the best performance, but this tailed off significantly when the input feature set was reduced to less than the top four.	[Zheng, H.; Wang, H.; Lightbody, G.; McCullagh, P.; McAllister, G.] Univ Ulster, Coleraine BT52 1SA, Londonderry, North Ireland	Zheng, H (reprint author), Univ Ulster, Coleraine BT52 1SA, Londonderry, North Ireland.	g.lightbody@ulster.ac.uk					Alpsan D, 1992, AUTOMEDICA, V15, P83; AOYAGI M, 1988, MED INFORM, V13, P211; Batista G. E. A. P. A., 2004, SIGKDD EXPLORATIONS, V6, P20, DOI DOI 10.1145/1007730.1007735; Davey R, 2007, ARTIF INTELL MED, V40, P1, DOI 10.1016/j.artmed.2006.07.001; JEWETT DL, 1970, ELECTROEN CLIN NEURO, V28, P609, DOI 10.1016/0013-4694(70)90203-8; Lightbody G, 2006, IEE IR SIGN SYST C, P321; McCullagh PJ, 2007, MEDINFO C; O'Connell B, 2002, J CLIN NURS, V11, P134, DOI 10.1046/j.1365-2702.2002.00578.x; Pratt T.L., 1995, AM J AUDIOL, V4, P47; Witten I. H., 2005, DATA MINING PRACTICA	10	0	0	BRNO UNIV TECHNOLOGY VUT PRESS	BRNO	PURKYNOVA 118, BRNO 61200, CZECH REPUBLIC	1211-412X	978-80-214-3613-8	BIOSIG BRNO			2008							265	268				4	Engineering, Biomedical	Engineering	BAB75	WOS:000303717200057	
B	Grzegorczyk, M; Husmeier, D; Werhli, AV		EmmertStreib, F; Dehmer, M		Grzegorczyk, Marco; Husmeier, Dirk; Werhli, Adriano V.			Reverse Engineering Gene Regulatory Networks with Various Machine Learning Methods	ANALYSIS OF MICROARRAY DATA: A NETWORK-BASED APPROACH			English	Article; Book Chapter							BAYESIAN NETWORKS; GENOMICS; MODELS; LOGIC		[Grzegorczyk, Marco; Husmeier, Dirk] Univ Edinburgh, Sch Biol Sci & Biomath & Stat Scotland BioSS, Edinburgh EH9 3JZ, Midlothian, Scotland; [Werhli, Adriano V.] Pontificia Univ Catolica Rio Grande do Sul, Dept Comp Sci, Porto Alegre, RS, Brazil	Grzegorczyk, M (reprint author), Univ Edinburgh, Sch Biol Sci & Biomath & Stat Scotland BioSS, Kings Bldg, Edinburgh EH9 3JZ, Midlothian, Scotland.						Atkins PW, 1986, PHYS CHEM; Bing N, 2005, GENETICS, V170, P533, DOI 10.1534/genetics.105.041103; Butte A J, 2000, Pac Symp Biocomput, P418; Butte A. S., 2003, ANAL GENE EXPRESSION, P428, DOI 10.1007/0-387-21679-0_19; Chickering DM, 2002, J MACH LEARN RES, V2, P445, DOI 10.1162/153244302760200696; CHICKERING DM, 1995, INT C UNC ART INT UA, V11, P87; Cooper G., 1999, COMPUTATION CAUSATIO; Cowles MK, 1996, J AM STAT ASSOC, V91, P883, DOI 10.2307/2291683; Dougherty MK, 2005, MOL CELL, V17, P215, DOI 10.1016/j.molcel.2004.11.055; Edwards D, 2000, INTRO GRAPHICAL MODE; Friedman N, 2003, MACH LEARN, V50, P95, DOI 10.1023/A:1020249912095; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Geiger D, 1994, P 10 C UNC ART INT, P235; Gilks WR, 1996, MARKOV CHAIN MONTE C; Giudici P, 2003, MACH LEARN, V50, P127, DOI 10.1023/A:1020202028934; GRZEGORCZYK M, 2006, THESIS U DORTMUND; Hartemink A.J., 2001, THESIS MIT; Heckerman D, 1999, LEARNING GRAPHICAL M, P301; Husmeier D, 2003, BIOINFORMATICS, V19, P2271, DOI 10.1093/bioinformatics/btg313; Imoto Seiya, 2003, J Bioinform Comput Biol, V1, P231, DOI 10.1142/S0219720003000071; Imoto S, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P104; Jensen F., 1996, INTRO BAYESIAN NETWO; Ledoit O, 2004, J MULTIVARIATE ANAL, V88, P365, DOI 10.1016/S0047-259X(03)00096-4; MADIGAN D, 1995, INT STAT REV, V63, P215, DOI 10.2307/1403615; Nariai N, 2005, BIOINFORMATICS, V21, P206, DOI 10.1093/bioinformatics/bti1133; Pearl J, 2000, CAUSALITY MODELS REA; POURNARA IV, 2005, THESIS U LONDON; Sachs K, 2005, SCIENCE, V308, P523, DOI 10.1126/science.1105809; Schafer J, 2005, STAT APPL GENET MO B, V4, DOI 10.2202/1544-6115.1175; Schafer J, 2005, BIOINFORMATICS, V21, P754, DOI 10.1093/bioinformatics/bti062; Smith V.A., 2002, BIOINFORMATICS, V18, pS216; Storey JD, 2003, P NATL ACAD SCI USA, V100, P9440, DOI 10.1073/pnas.1530509100; TIAN J, 2001, ACTIVE LEARNING STRU, V17, P863; VERMA T, 1990, P 6 C UNC ART INT, V6, P220; Werhli AV, 2006, BIOINFORMATICS, V22, P2523, DOI 10.1093/bioinformatics/btl391; WERHLI AV, 2007, THESIS U EDINBURGH; Pournara I, 2004, BIOINFORMATICS, V20, P2934, DOI 10.1093/bioinformatics/bth337; YOO C, 2002, P PAC S BIOC, V7, P498; Yuh CH, 2001, DEVELOPMENT, V128, P617; Yuh CH, 1998, SCIENCE, V279, P1896, DOI 10.1126/science.279.5358.1896; ZAK DE, 2001, P 2 INT C SYST BIOL, P231	41	7	7	BLACKWELL SCIENCE PUBL	OXFORD	OSNEY MEAD, OXFORD OX2 0EL, ENGLAND		978-3-527-31822-3				2008							101	142		10.1002/9783527622818.ch5	10.1002/9783527622818	42	Biochemistry & Molecular Biology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Mathematical & Computational Biology	BUF10	WOS:000289069000006	
B	Jankowski, A; Skowron, A		Ehrenfeucht, A; Marek, VW; Srebrny, M		Jankowski, Andrzej; Skowron, Andrzej			Logic for Artificial Intelligence: A Rasiowa-Pawlak School Perspective	ANDRZEJ MOSTOWSKI AND FOUNDATIONAL STUDIES			English	Article; Book Chapter						Logic; AI; algebraic logic; abstract logic; approximation; wisdom technology; adaptive rough-granular computing; rough sets; machine learning	BEHAVIORAL-PATTERN IDENTIFICATION; HUMAN-LEVEL INTELLIGENCE; APPROXIMATION SPACES; ROUGH SETS; INCOMPLETE INFORMATION; COMPLEX PATTERNS; SYSTEMS; KNOWLEDGE; REPRESENTATION; DATABASES	The Rasiowa-Pawlak school was established during the second half of the twentieth century. The school concentrates on studies in logics, foundations of computer science and artificial intelligence (AI). Its formation has been greatly influenced by the logician Andrzej Mostowski, a professor at Warsaw University [110,111], who, in particular, directed the doctoral dissertation of Helena Rasiowa. Nowadays, the disciples of the Rasiowa-Pawlak school are active in many research-development centres worldwide. The school founded its own journal, Fundamenta Informaticae. In this paper, we present selected trends in the studies of the school concerning applications of logic in AI. At the beginning, we briefly describe the genesis of the Rasiowa-Pawlak school. We then present the understanding, currently dominating within the school, on such basic concepts as AI and logic. Since the beginning of the 1950's, the focus of the research by Helena Rasiowa and her associates has been the application of algebraic and topological methods to the investigation of crucial problems of logic from an AI perspective. Amongst them are the completeness theorem, construction of deduction systems, construction of models, especially models for constructive mathematics [136,241,67] and related logics such as intuitionistic, intermediate, modal, and approximation logics. In the paper, we discuss the fundamental, in our opinion, ideas underlying these roots of the Rasiowa-Pawlak school. A great importance in the studies of the school is assigned to the search for optimal tools for reasoning about complex vague concepts, construction of knowledge representation systems, reasoning about knowledge as well as for the application of logics in learning, communication, perception, planning, action, cooperation, and competition. It should be noted that as is the case with many other research centers, the Rasiowa- school studies pertaining to the application of logics in AI have also undergone an evolution which we present in this paper. We include extensive references to the literature on the approach presented in this paper.	[Jankowski, Andrzej] Inst Decis Proc Support, PL-02796 Warsaw, Poland; [Jankowski, Andrzej] AdgaM Solut Sp Zoo, PL-02796 Warsaw, Poland; [Skowron, Andrzej] Warsaw Univ, Inst Math, PL-02097 Warsaw, Poland	Jankowski, A (reprint author), Inst Decis Proc Support, Wawozowa 9,Lok 64, PL-02796 Warsaw, Poland.	andrzejj@adgam.com.pl; skowron@mimuw.edu.pl					Axelrod R., 1997, COMPLEXITY COOPERATI; BAEZAYATES R, 1999, ACM PRESS SERIES ADD; BANACHOWSKI L, 1977, INTRO ALGORITHMIC LO, P7; Bargiela A, 2003, GRANULAR COMPUTING I; BARWISE J, 1972, ANN MATH LOGIC, V4, P309; BARWISE J, 1974, ANN MATH LOGIC, V7, P221; Barwise J., 1997, INFORM FLOW LOGIC DI; Bazan J, 2006, LECT NOTES COMPUT SC, V4100, P39; BAZAN J, 2002, PATTERN CLASSIFICATI, P191; Bazan JG, 2005, LECT NOTES ARTIF INT, V3642, P688; Bazan JG, 2005, LECT NOTES COMPUT SC, V3776, P720; Bell J., 2005, SET THEORY BOOLEAN V; BENTHEM J, 2006, AGE ALTERNATIVE LOGI; Berry M. W., 2003, SURVEY TEXT MINING C; Beziau J.-Y., 2005, LOGICA UNIVERSALIS G; Birkhoff G., 1967, AMS C PUBLICATIONS, VXXV; Bloom S. L., 1972, NOTRE DAME J FORM L, V13, P289, DOI 10.1305/ndjfl/1093890617; Bolc L., 1992, MANY VALUED LOGICS; Bolc L., 2003, MANY VALUED LOGICS, V2; BORKOWSKI L, 1970, JAN LUKASIEWICZ SELE; Borkowski M., 2002, THESIS U MANITOBA; Borkowski M, 2006, LECT NOTES COMPUT SC, V4100, P63; Brachman R, 2004, KNOWLEDGE REPRESENTA; Bratteli O., 2002, WAVELETS LOOKING GLA; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Brin S., 1998, ANATOMY LARGE SCALE; Brown D. J., 1973, DISSERTATIONES MATH, V102, P9; CALISHAIN T, 2004, GOOGLE HACKS; Carpineto C., 2004, CONCEPT DATA ANAL TH; Cassimatis N, 2006, AI MAG, V27, P12; Cassimatis NL, 2006, AI MAG, V27, P45; CHAKRABARTI S, 2002, M KAUFMANN SERIES DA; CHURCH A., 1956, INTRO MATH LOGIC; Cohen Paul J., 1966, SET THEORY CONTINUUM; Dalla Chiara M. L., 2004, REASONING QUANTUM TH; DAVIS M, 1977, INT J THEOR PHYS, V16, P867, DOI 10.1007/BF01807619; DEMRI S, 2002, MONOGRAPHS THEORETIC; Desai A, 2005, COMMUN ACM, V48, P32, DOI 10.1145/1060710.1060736; Doherty P., 2006, STUDIES FUZZINESS SO, V202; Duda R., 2002, PATTERN CLASSIFICATI; DUNINKEPLICZ B, 2005, SERIES SOFT COMPUTIN; Eiben A.E., 2003, NATURAL COMPUTING SE; Everett CJ, 1944, T AM MATH SOC, V55, P514, DOI 10.2307/1990306; EVERETT CJ, 1946, AM J MATH, V68, P77, DOI 10.2307/2371742; Feigenbaum E. A., 1963, COMPUTERS THOUGHT; FELDMAN S, 2006, TEXT MINING HDB ADV; Fensel D., 2003, ONTOLOGIES SILVER BU; Forbus KD, 2006, AI MAG, V27, P83; FOURMAN MP, 1999, SPRINGER LECT NOTES, V753, P302; Frege G., 1879, BEGRIFFSSCHRIFT ARIT; Friedman J. H., 2001, ELEMENTS STAT LEARNI; Gabbay DM, 2006, HBK HIST LOGIC, V7, pVII; Ganter B., 2005, LNCS, V3626; Gardenfors P., 2000, CONCEPTUAL SPACES GE; GARLING DJH, 1987, COURSE GALOIS THEORY; Gell-Mann Murray, 1994, QUARK JAGUAR ADVENTU; Ghallab M., 2004, AUTOMATED PLANNING T; GHEMAWAT S, 2005, SHUN TAK LEUNG; Ghilardi S., 2002, TRENDS LOGIC, V14; Glivenko V., 1929, ACAD ROY BELG, V5, P183; GODEL K, 1933, ERGEBNISSE MATH K, V4, p[34, 286]; Gottfredson LS, 1997, INTELLIGENCE, V24, P13, DOI 10.1016/S0160-2896(97)90011-8; Grabowski J., 1981, FUNDAMENTA INFORMATI, V4, P427; Granger R, 2006, AI MAG, V27, P15; GRIMES S, 2005, DEV TEXT MINING MARK; GRZEGORCZYK A, 1959, STUDIES LOGIC FDN MA, P43; HAGAN A, 2006, UNCERTAIN JUDGEMENTS; Harmelen F. V, 2004, SEMANTIC WEB PRIMER; Heaton J, 2002, PROGRAMMING SPIDERS; Henkin L., 1971, CYLINDRIC ALGEBRAS 1; HENRY C, 2007, P 2007 JOINT ROUGH S; HENZINGER M, 2004, EXTRACTING KNOWLEDGE; Higgs D., 1973, CATEGORY APPROACH BO; Hintikka J., 1996, PRINCIPLES MATH REVI; Hirvensalo M., 2001, QUANTUM COMPUTING; Ho TB, 2002, INT J INTELL SYST, V17, P199, DOI 10.1002/int.10016; Holland J. H., 1998, EMERGENCE CHAOS ORDE; Holland J., 1975, ADAPTATION NATURAL A; HOLLAND JH, 1995, HIDDEN ORDER ADAPTAT; Huhns M.N., 1998, READINGS AGENTS; IMIELINSKI T, 1984, J ACM, V31, P761, DOI 10.1145/1634.1886; Jackson P., 2002, NATURAL LANGUAGE PRO, V5; JANISZEWSKI Z, 1918, NAUKA POLSKA JEJ POT; JANKOWSKI A, 1988, EVOLUTION PROGRAMMIN; JANKOWSKI A, 1989, P 4 INT S ISMIS 1989; JANKOWSKI A, 1982, B ACAD POL SCI SER M, V30, P9; JANKOWSKI A, 1986, PROPOSAL EVOLUTION P; Jankowski A., 2007, LNCS, V4374, P94; JANKOWSKI A, 2007, HDB GRANULA IN PRESS; JANKOWSKI A, 1985, STUDIA LOGICA, V44, P237, DOI 10.1007/BF00394444; JANKOWSKI A, 1983, THEOR COMPUT SCI, V23, P11; Jankowski A. W., 1985, STUDIA LOGICA, V44, P109, DOI 10.1007/BF00379761; Johnstone P. T., 1986, STONE SPACES; Jones RM, 2006, AI MAG, V27, P57; Jorgensen PET, 2006, GRAD TEXTS MATH, V234, P1; Kahneman D, 1982, JUDGEMENT UNCERTAINT; Kan Daniel M., 1958, T AM MATH SOC, V87, P294, DOI 10.2307/1993102; Keefe R., 2000, CAMBRIDGE STUDIES PH; Kleene S. C., 1952, INTRO METAMATHEMATIC; KLOESGEN W, 2002, HDB KNOWLEDGE DISCOV; Kodratoff Y., 1990, MACHINE LEARNING ART, V3; KONRAD E, 1981, 433 PAS I COMP SCI; KONRAD E, 1981, 8107 TU BERL; Kraus S., 2001, STRATEGIC NEGOTIATIO; Kreczmar A., 1990, LNCS, V414; Kuratowski K., 1968, TOPOLOGY, V2; KURATOWSKI K, 1973, POL WIEKU MATEMATYKI; Kuratowski K., 1966, TOPOLOGY, VI; KURATOWSKI K, 1979, MOSTOWSKI FOUNDATION, V2; KURATOWSKI K, 1979, MOSTOWSKI FOUNDATION, V1; Kuratowski K., 1931, FUND MATH, V17, P240; LAMBEK J., 1986, CAMBRIDGE STUDIES AD, V7; Lane Saunders Mac, 1994, SHEAVES GEOMETRY LOG; Langdon W. B., 2002, FDN GENETIC PROGRAMM; Langley P., 1987, SCI DISCOVERY COMPUT; Leibniz G. W, 1982, NEW ESSAYS HUMAN UND; LEIBNIZ GW, 1666, DISSERTIO ARTE COMBI; LEIBNIZ GW, 1989, PHILOS ESSAYS, P35; Lesniewski S, 1982, TOPOI, V2, P7; Lesniewski S., 1929, FUND MATH, V14, P1; LINDSTROM P, 1969, THEORIA, V35, P1; LIPSKI W, 1981, J ACM, V28, P41, DOI 10.1145/322234.322239; LIPSKI W, 1974, LNCS, V14, P270; Lipski W.  Jr., 1976, Theoretical Computer Science, V3, DOI 10.1016/0304-3975(76)90023-2; Liu J., 2001, AUTONOMOUS AGENTS MU; Liu J., 2005, AUTONOMY ORIENTED CO; LIU J, 2003, SPATIAL REASONING PL; Luck M., 2003, AGENT TECHNOLOGY ENA; LYNDON RC, 1967, NOTES LOGIC D VANNOS; MACLANE S, 1997, GRADUATE TEXTS MATH; MACZYNSKI MJ, 1996, B SECTION LOGIC, V25, P161; MARCZYNSKI RW, 1980, ANN HIST COMPUT, V2, P37; MAREK V, 1988, FUNDAMENTA INFORM, V11, P241; Marek V. W., 1999, Fundamenta Informaticae, V39; MAREK VW, 1986, THEORETICAL COMPUTER, V48, P145; Marek W., 1976, Theoretical Computer Science, V1, DOI 10.1016/0304-3975(76)90077-3; MAZUR S, 1963, ROZPRAWY MATEMATYCZN, V33; Mazurkiewicz A, 1977, PB78 DAIMI AARH U; Michalski R. S., 1994, MACHINE LEARNING MUL, V4; Michalski R. S., 1986, MACHINE LEARNING ART, V2; Michalski R. S., 1983, MACHINE LEARNING ART; MIRKOWSKA G, 1987, ALGORITHMIC LOGIC; Mitchell T, 1997, MACHINE LEARNING; MOORE EH, 1910, AMS C, V2; MOSTOWSKI A, 1947, FUND MATH, V34, P81; Mostowski A., 1957, FUND MATH, V44, P12; Mostowski A.W., 1948, J SYMBOLIC LOGIC, V13, P204, DOI 10.2307/2267135; Ngo C.L., 2005, P 2005 IEEE WIC ACM, P673; NGUYEN HS, 2006, LNCS, V3100, P187; Nguyen TT, 2005, LECT NOTES COMPUT SC, V3776, P762; OCONNOR M, 2007, P LOG FDN C IN PRESS; ORE O, 1944, T AM MATH SOC, V55, P494; ORLOWSKA E, 1984, INT J MAN MACH STUD, V20, P485, DOI 10.1016/S0020-7373(84)80023-1; ORLOWSKA E, 1990, STUDIA LOGICA, V49, P255, DOI 10.1007/BF00935602; Orlowska E, 1980, FUNDAMENTA INFORMATI, VIII, P333; Orlowska E., 1982, 469 POL AC SCI I COM; ORLOWSKA E, 1981, 432 PAS I COMP SCI; ORLOWSKA E, 1997, STUDIES FUZZINESS SO, V13; ORLOWSKA E, 1984, THEOR COMPUT SCI, V29, P27, DOI 10.1016/0304-3975(84)90010-0; Pal S. K., 2004, ROUGH NEURAL COMPUTI; PAL SK, 2005, LNCS, V3776; Parsons S., 2002, GAME THEORY DECISION; Passin Thomas B., 2004, EXPLORERS GUIDE SEMA; PAWLAK Z, 1981, 431 CC PAS I COMP SC; PAWLAK Z, 1985, B POLISH ACAD SCI TE, V33, P551; PAWLAK Z, 1981, 429 CC PAS I COMP SC; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Pawlak Z, 2007, INFORM SCIENCES, V177, P28, DOI 10.1016/j.ins.2006.06.006; Pawlak Z., 1991, KNOWLEDGE ENG PROBLE, V9; PAWLAK Z, 1973, P S MATH FDN COMP SC, P135; Pawlak Z, 2007, INFORM SCIENCES, V177, P41, DOI 10.1016/j.ins.2006.06.007; Pawlak Z, 2007, INFORM SCIENCES, V177, P3, DOI 10.1016/j.ins.2006.06.003; Peters JF, 2006, FUND INFORM, V71, P323; Peters JF, 2007, ENG APPL ARTIF INTEL, V20, P667, DOI 10.1016/j.engappai.2006.11.005; Peters J.F., 2007, P IEEE S SER FDN COM, P1; PETERS JF, 2007, P 2007 JOINT ROUGH S; Peters JF, 2007, FUND INFORM, V75, P407; PETERS JF, 2007, INT J HYBRI IN PRESS; Peters JF, 2006, LECT NOTES ARTIF INT, V4062, P1; Peters JF, 2005, LECT NOTES COMPUT SC, V3400, P153; Plaza J. A., 1989, P 4 INT S METH INT S, P201; Plous S, 1993, PSYCHOL JUDGEMENT DE; Poggio T., 2003, NOTICES AMS, V50, P537; Poli Roberto, 1996, FORMAL ONTOLOGY; Polkowski L., 2000, STUDIES FUZZINESS SO, V56; Polkowski L., 2002, ADV SOFT COMPUTING; Polkowski L, 1996, INT J APPROX REASON, V15, P333, DOI 10.1016/S0888-613X(96)00072-2; PRATT V, 1999, NOTES SCH CATEGORY T; Pratt V. R., 2003, Mathematical Structures in Computer Science, V13, DOI 10.1017/S0960129503004031; Prawitz D., 2006, NATURAL DEDUCTION PR; RASIOWA H, 1989, METHODOLOGIES INTELL, P234; Rasiowa H, 1974, ALGEBRAIC APPROACH N; RASIOWA H, 1963, ONOGRAFIE MATEMATYC, V41; Rasiowa H., 2001, ALGEBRAIC MODELS LOG; Rauszer C., 1977, FUND MATH, V96, P127; RAUSZER C, 1994, PHILOS LOGIC POLAND, P217; RAUSZER C, 1995, KNOWLEDGE BELIEF PHI, P87; Rauszer C., 1975, STUDIA LOGICA, V34, P265, DOI 10.1007/BF02125229; Rauszer C. M., 1991, Fundamenta Informaticae, V15; RAUSZER C, 1982, SERIES BANACH CTR PU, V9, P431; Rauszer C. M., 1993, Fundamenta Informaticae, V19; Read Stephen, 1995, THINKING LOGIC INTRO; Rota G.-C, 1997, INDISCRETE THOUGHTS; Russel S., 2002, ARTIFICIAL INTELLIGE; SCOTT D, 1967, MATH SYST THEORY, V1, P89, DOI 10.1007/BF01705520; SCOTT D, 1967, P UCLA SET THEOR C; SHANKER S, 2006, WITTGENSTEINS REMARK; Sikorski R., 1964, BOOLEAN ALGEBRAS; Skowron A., 1996, Fundamenta Informaticae, V27; SKOWRON A, 1996, B SECTION LOGIC, V25; Skowron A, 2005, LECT NOTES COMPUT SC, V3776, P21; Skowron A, 2005, LECT NOTES COMPUT SC, V3400, P175; Skowron A., 1992, HDB APPL ADV ROUGH S, V11, P331; SKOWRON A, 2004, ROUGH NEURAL COMPUTI, P43; SKOWRON A, 2005, P 8 JOINT C INF SCI, P1; Skowron A, 2004, FUND INFORM, V60, P351; Skowron A, 2001, INT J INTELL SYST, V16, P57, DOI 10.1002/1098-111X(200101)16:1<57::AID-INT6>3.0.CO;2-Y; SLEZAK D, 2005, LNAI, V3642; SMITH JM, 2006, EVOLUTION THEORY GAM; Stepaniuk J, 2005, FUND INFORM, V67, P203; STEPANIUK J, 2006, FUNDAMENTA INFORM, V72, P363; Sun R., 2006, COGNITION MULTIAGENT; SUN R, 2001, DUALITY MIND BOTTOM; SUSZKO R, 1968, NOTRE DAME J FORM L, V9, P7, DOI 10.1305/ndjfl/1093893349; Svozil K., 1998, QUANTUM LOGIC; Swartout W, 2006, AI MAG, V27, P96; Sycara K, 1998, AI MAG, P79; TARSKI A, 1963, INTRO LOGIC METHODOL; TARSKI A, 1986, COLLECTED PAPERS ALF; Tarski Alfred, 1955, INDAGATIONES MATH, V17, P56; Tarski Alfred, 1944, PHILOS PHENOMENOLOGI, V4, P341, DOI 10.2307/2102968; Tarski Alfred, 1954, INDAGATIONES MATH, V16, P572; Troelstra A., 2000, BASIC PROOF THEORY; TROELSTRA A, 1988, STUDIES LOGIC FDN MA, V2; TROELSTRA AS, 1988, STUDIES LOGIC FDN MA, V1; Turing A.M., 1950, MIND, V59, P433, DOI DOI 10.1093/MIND/LIX.236.433; Ulam S. M., 1991, ADVENTURES MATH; Van Wezel W., 2006, PLANNING INTELLIGENT; VANRIJSBERGEN K, 2006, GEOMETRY INFORM RETR; Vapnik VN, 1998, STAT LEARNING THEORY; Vincent TL, 2005, EVOLUTIONARY GAME TH; WANG P, WHAT YOU MEAN AI; WANTZEL L, 1837, J MATH PURE APPL, V1, P366; Weiss S., 2004, TEXT MINING PREDICTI; Widdows D., 2004, GEOMETRY MEANING; Wittgenstein L., 2004, PHILOS INVESTIGATION; Zadeh L.A, 1965, INFORM CONTR, V8, P333; ZADEH LA, 1999, IEEE T CIRCUITS SYST, V45, P105; ZADEH LA, 2005, INFORM SCI, V171, P1; [Anonymous], 1933, OXFORD ENGLISH DICT; *MATH FDN INF RETR, 1973, 101 CC PAS MATH FDN	251	11	11	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS		978-1-58603-782-6				2008							106	143				38	Mathematics	Mathematics	BMB01	WOS:000271714600009	
S	Long, N; Gianola, D; Rosa, GJM; Weigel, KA; Avendano, S		Pinard, MH; Gay, C; Pastoret, PP; Dodet, B		Long, N.; Gianola, D.; Rosa, G. J. M.; Weigel, K. A.; Avendano, S.			Machine Learning Classification Procedure for Selecting SNPs in Genomic Selection: Application to Early Mortality in Broilers	ANIMAL GENOMICS FOR ANIMAL HEALTH	DEVELOPMENTS IN BIOLOGICALS		English	Proceedings Paper	International Symposium on Animal Genomics for Animal Health	OCT 25-27, 2007	Paris, FRANCE	Agr Res Serv, Biotechnol & Biol Sci Res Council, European Anim Dis Genom Network Excellence Anim Hlth & Food Safety, Inst Natl Rech Agron, Int Assoc Biol, World Org Anim Hlth		machine learning; filter-wrapper feature selection; mortality; SNP		In genome-wide association studies using single nucleotide polymorphisms (SNPs), typically thousands of SNPs are genotyped, whereas the number of phenotypes for which there is genomic information may be smaller. A two-step SNP (feature) selection method was developed, which consisted of filtering (using information gain), and wrapping (using naive Bayesian classification). This was based on discretization of the continuous phenotypic values. The method was applied to chick early mortality rates (0-14 days of age) on progeny from 201 sires in a commercial broiler line, with the goal of identifying SNPs (over 5,000) related to progeny mortality. Sires were clustered into two groups, low and high, according to two arbitrarily chosen mortality rate thresholds. By varying these thresholds, 11 different "case-control" samples were formed, and the SNP selection procedure was applied to each sample. To compare the 11 sets of chosen SNPs, predicted residual sum of squares (PRESS) from a linear model was used. Naive Bayesian classification accuracy was improved over the case without feature selection (from 50% to 90%). Seventeen SNPs in the best case-control group (with smallest PRESS) accounted for 31% of the variance among sire family mortality rates.	[Long, N.; Gianola, D.] Univ Wisconsin, Dept Anim Sci, Madison, WI 53706 USA	Long, N (reprint author), Univ Wisconsin, Dept Anim Sci, 454 Anim Sci Bldg,1675 Observ Dr, Madison, WI 53706 USA.	nlong@wisc.edu					Balding DJ, 2006, NAT REV GENET, V7, P781, DOI 10.1038/nrg1916; Elkan C., 1997, CS97557 U CAL; Gianola D, 2006, GENETICS, V173, P1761, DOI 10.1534/genetics.105.049510; Mitchell T, 1997, MACHINE LEARNING; Ruppert D, 2003, SEMIPARAMETRIC REGRE; Witten I. H., 2005, DATA MINING PRACTICA	6	1	1	KARGER	BASEL	POSTFACH, CH-4009 BASEL, SWITZERLAND	1424-6074	978-3-8055-8619-1	DEV BIOLOGICALS	Dev. Biols		2008	132						373	376				4	Agricultural Engineering; Biotechnology & Applied Microbiology	Agriculture; Biotechnology & Applied Microbiology	BJA67	WOS:000264184200049	
S	Coman, D		Katalinc, B		Coman, Danicla			USING PETRI NETS IN THE SOCCER ROBOT CONTROL ARCHITECTURE	ANNALS OF DAAAM FOR 2008 & PROCEEDINGS OF THE 19TH INTERNATIONAL DAAAM SYMPOSIUM	Annals of DAAAM and Proceedings		English	Proceedings Paper	19th International Symposium of the Danube-Adria-Association-for-Automation-and-Manufacturing	OCT 22-25, 2008	Trnava, SLOVAKIA			robot soccer; Petri net; MiroSoT		Robot soccer is a challenging platform for multi-agent research, involving topics such as real-time image processing and control, robot path planning, obstacle avoidance and machine learning. A soccer robot has to take an appropriate decision based on environment situation. With the role of a robot fixed as goalkeeper, the supervisor, according to the game situation, assigns the role of attacking or defending to the other robots and then the respective controllers control the robots. The controller for the attacking robot is designed using Petri nets. The Petri net model are implemented in Petri Net Toolbox under MATLAB environment.								Kim J.-H., 2004, SOCCER ROBOTICS; PASTRAVANU O, 2003, ADV AUTOMATIC CONTRO, P247; PASTRAVANU O, 2002, APPL PETRI NET STUDY; Peterson J, 1981, PETRI NET THEORY MOD; Shim HS, 1997, ROBOT AUTON SYST, V21, P149, DOI 10.1016/S0921-8890(97)00023-7; ZIPARO V, 2006, PETRI NET PLANS	6	1	1	DAAAM INT VIENNA	WIEN	VIENNA UNIV TECHNOLOGY, KARLSPLATZ 13, WIEN, A-1040, AUSTRIA	1726-9679	978-3-901509-68-1	ANN DAAAM			2008							295	296				2	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Manufacturing	Automation & Control Systems; Computer Science; Engineering	BIU04	WOS:000262860100147	
S	Denzinger, J; Laureyns, I; Frietsch, M; Burger, W; Meckl, P		Katalinc, B		Denzinger, Joachim; Laureyns, Isabelle; Frietsch, Markus; Burger, Wolfgang; Meckl, Peter			A STUDY OF REWARD FUNCTIONS IN REINFORCEMENT LEARNING ON A DYNAMIC MODEL OF A TWO-LINK PLANAR ROBOT	ANNALS OF DAAAM FOR 2008 & PROCEEDINGS OF THE 19TH INTERNATIONAL DAAAM SYMPOSIUM	Annals of DAAAM and Proceedings		English	Proceedings Paper	19th International Symposium of the Danube-Adria-Association-for-Automation-and-Manufacturing	OCT 22-25, 2008	Trnava, SLOVAKIA			Machine Learning; Reinforcement Learning; Multi-Link Robot; Reward Function		Reinforcement Learning is one approach for executing a point-to-point movement using complex multi-link robots in an environment. The work presented in this paper, we: (1) use torque commands as input for a two-link manipulator; position commands do not take the dynamics of the system into consideration, (2) identify, the optimal composition of a set of reward functions in fulfilling certain requirements. These requirements include: a smooth velocity profile while reaching the target, no overshooting and a minimum number of steps. We experimentally validate our approach on a two-link planar robot for reaching different target positions.								DENZINGER J, 2008, IMPLEMENTATION DISTI; MARTIN HJA, 2007, ICINCO 2007, P192; Rummery GA, 1994, 166 CUEDFINFENGTR; Sutton R.S., 1998, REINFORCEMENT LEARNI; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698	5	0	0	DAAAM INT VIENNA	WIEN	VIENNA UNIV TECHNOLOGY, KARLSPLATZ 13, WIEN, A-1040, AUSTRIA	1726-9679	978-3-901509-68-1	ANN DAAAM			2008							373	374				2	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Manufacturing	Automation & Control Systems; Computer Science; Engineering	BIU04	WOS:000262860100186	
S	Pozdnoukhov, A; Purves, RS; Kanevski, M		Schneebeli, M		Pozdnoukhov, A.; Purves, R. S.; Kanevski, M.			Applying machine learning methods to avalanche forecasting	ANNALS OF GLACIOLOGY, VOL 49, 2008	ANNALS OF GLACIOLOGY		English	Proceedings Paper	International Symposium on Snow Science	SEP 03-07, 2007	Moscow, RUSSIA				NEAREST-NEIGHBORS; MODEL; CLASSIFICATION; VERIFICATION; MOUNTAIN	Avalanche forecasting is a complex process involving the assimilation of multiple data sources to make predictions over varying spatial and temporal resolutions. Numerically assisted forecasting often uses nearest-neighbour methods (NN), which are known to have limitations when dealing with high-dimensional data. We apply support vector machines (SVMs) to a dataset from Lochaber, Scotland, UK, to assess their applicability in avalanche forecasting. SVMs belong to a family of theoretically based techniques from machine learning and are designed to deal with high-dimensional data. Initial experiments showed that SVMs gave results that were comparable with NN for categorical and probabilistic forecasts. Experiments utilizing the ability of SVMs to deal with high dimensionality in producing a spatial forecast show promise, but require further work.	[Pozdnoukhov, A.; Kanevski, M.] Univ Lausanne, Inst Geomat & Anal Risk, CH-1015 Lausanne, Switzerland	Pozdnoukhov, A (reprint author), Univ Lausanne, Inst Geomat & Anal Risk, CH-1015 Lausanne, Switzerland.	alexei.pozdnoukhov@unil.ch					Bartelt P, 2002, COLD REG SCI TECHNOL, V35, P123, DOI 10.1016/S0165-232X(02)00074-5; Brabec B, 2001, ANN GLACIOL, V32, P130, DOI 10.3189/172756401781819247; BUSER O, 1983, COLD REG SCI TECHNOL, V8, P155, DOI 10.1016/0165-232X(83)90006-X; Davis RE, 1999, COLD REG SCI TECHNOL, V30, P79, DOI 10.1016/S0165-232X(99)00032-4; DOSWELL CA, 1990, WEATHER FORECAST, V5, P576, DOI 10.1175/1520-0434(1990)005<0576:OSMOSI>2.0.CO;2; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Heierli J, 2004, ANN GLACIOL, V38, P84, DOI 10.3189/172756404781815095; LACHAPELLE ER, 1980, J GLACIOL, V26, P75; McClung D., 1993, AVALANCHE HDB; McCollister C, 2003, COLD REG SCI TECHNOL, V37, P299, DOI 10.1016/S0165-232X(03)00072-7; OBLED C, 1980, J GLACIOL, V25, P315; Platt J., 1999, ADV LARGE MARGIN CLA, P61; Purves RS, 2003, COLD REG SCI TECHNOL, V37, P343, DOI 10.1016/S0165-232X(03)00075-2; Scholkopf B., 2001, LEARNING KERNELS SUP; Schweizer J, 1996, J GLACIOL, V42, P318; Vapnik V. N, 1995, NATURE STAT LEARNING; Wilks D. S., 1995, STAT METHODS ATMOSPH	17	7	7	INT GLACIOLOGICAL SOC	CAMBRIDGE	LENSFIELD RD, CAMBRIDGE CB2 1ER, ENGLAND	0260-3055		ANN GLACIOL			2008	49						107	113				7	Geosciences, Multidisciplinary	Geology	BJC94	WOS:000264862900018	
B	Volna, E		Madani, K		Volna, Eva			Learning and evolution in artificial neural networks: A comparison study	ANNIP 2008: PROCEEDINGS OF THE ARTIFICIAL NEURAL NETWORKS AND INTELLIGENT INFORMATION PROCESSING			English	Proceedings Paper	4th International Workshop on Artificial Neural Networks and Intelligent Information Processing	MAY, 2008	Maderia, PORTUGAL				RECOGNITION	This paper aims at learning and evolution in artificial neural networks. Here is presented a system evolving populations of neural nets that are fully connected multilayer feedforward networks with fixed architecture solving given tasks. The system is compared with gradient descent weight training (like backpropagation) and with hybrid neural network adaptation. All neural networks have the same architecture and solve the same problems to be able to be compared mutually. In order to test the efficiency of described algorithms, we applied them to the Fisher's Iris data set [1] that is the bench test database from the area of machine learning.	Univ Ostrava, Ostrava 70103, Czech Republic	Volna, E (reprint author), Univ Ostrava, 30ht Dubna St 22, Ostrava 70103, Czech Republic.	eva.volna@osu.cz					ANGELINE PJ, 1994, IEEE T NEURAL NETWOR, V5, P54, DOI 10.1109/72.265960; Back T., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585888; FELS SS, 1993, IEEE T NEURAL NETWOR, V4, P2, DOI 10.1109/72.182690; Hertz J., 1991, INTRO THEORY NEURAL; Janson D. J., 1992, Journal of Systems Engineering, V2; KNERR S, 1992, IEEE T NEURAL NETWOR, V3, P962, DOI 10.1109/72.165597; LANG KJ, 1990, NEURAL NETWORKS, V3, P33; Lee SW, 1996, IEEE T PATTERN ANAL, V18, P648; Lehotsky M, 1995, NEURAL NETW WORLD, V5, P91; MERELO JJ, 1993, LECT NOTES COMPUTER, V686, P185; Montana D., 1989, P 11 INT JOINT C ART, P762; Pujol JCF, 1998, APPL INTELL, V8, P73, DOI 10.1023/A:1008272615525; WANG DD, P 1996 IEEE INT C SY, V1, P255; Yao X, 1999, P IEEE, V87, P1423	14	0	0	INSTICC-INST SYST TECHNOLOGIES INFORMATION CONTROL & COMMUNICATION	SETUBAL	AVENIDA D MANUEL L, 27A 2 ESQUERDO, SETUBAL, 2910-595, PORTUGAL		978-989-8111-33-3				2008							10	17				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BID09	WOS:000258499000002	
B	Sun, Y; Shafarenko, A; Adams, R; Davey, N; Slater, B; Bhamber, R; Boscolo, S; Turitsyn, SK		Madani, K		Sun, Yi; Shafarenko, Alex; Adams, Rod; Davey, Neil; Slater, Brendan; Bhamber, Ranjeet; Boscolo, Sonia; Turitsyn, Sergei K.			Adaptive electrical signal post-processing in optical communication systems	ANNIP 2008: PROCEEDINGS OF THE ARTIFICIAL NEURAL NETWORKS AND INTELLIGENT INFORMATION PROCESSING			English	Proceedings Paper	4thInternational Workshop on Artificial Neural Networks and Intelligent Information Processing held in Conjunction with the 5th International Conferenece on Informatics in Control, Automation and Robotics	MAY, 2008	Maderia, PORTUGAL					Improving bit error rates in optical communication systems is a difficult and important problem. The error correction must take place at high speed and be extremely accurate. We show the feasibility of using hardware implementable machine learning techniques. This may enable some error correction at the speed required.	[Sun, Yi; Shafarenko, Alex; Adams, Rod; Davey, Neil] Univ Hertfordshire, Dept Comp Sci, Hatfield AL10 9AB, Herts, England	Sun, Y (reprint author), Univ Hertfordshire, Dept Comp Sci, Hatfield AL10 9AB, Herts, England.						Bishop C.M., 1995, NEURAL NETWORKS PATT; BULOW H, 2002, TUE4 OFC; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; HAUNSTEIN HF, 2004, P 30 EUR C OP COMM E; Rosenkranz W, 2007, AEU-INT J ELECTRON C, V61, P153, DOI 10.1016/j.aeue.2006.12.009; Watts PM, 2005, IEEE PHOTONIC TECH L, V17, P2206, DOI 10.1109/LPT.2005.856326	6	0	0	INSTICC-INST SYST TECHNOLOGIES INFORMATION CONTROL & COMMUNICATION	SETUBAL	AVENIDA D MANUEL L, 27A 2 ESQUERDO, SETUBAL, 2910-595, PORTUGAL		978-989-8111-33-3				2008							71	79				9	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BID09	WOS:000258499000008	
S	Greene, CS; White, BC; Moore, JH		Dorigo, M; Birattari, M; Blum, C; Clerc, M; Stutzle, T; Winfield, AFT		Greene, Casey S.; White, Bill C.; Moore, Jason H.			Ant Colony Optimization for Genome-Wide Genetic Analysis	ANT COLONY OPTIMIZATION AND SWARM INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	6th Biannual International Conference on Ant Colony Optimization and Swarm Intelligence	SEP 22-24, 2008	Brussels, BELGIUM	IEEE Computat Intelligence Soc, Co AntOptima, Belgian Fund Sci Res, French Comm Belgium			MULTIFACTOR-DIMENSIONALITY REDUCTION; EXPERT KNOWLEDGE; SUSCEPTIBILITY; EPISTASIS; RELIEFF	In human genetics it is now feasible to measure large numbers of DNA sequence variations across the human genome. Given current knowledge about biological networks and disease processes it seems likely that disease risk can best be modeled by interactions between biological components, which can be examined as interacting DNA sequence variations. The machine learning challenge is to effectively explore interactions in these datasets to identify combinations of variations which are predictive of common human diseases. Ant. colony optimization (AGO) is a promising approach to this problem. The goal of this study is to examine the usefulness of ACO for problems in this domain and to develop a prototype of an expert knowledge guided probabilistic search wrapper. We show that an ACO approach is not successful in the absence of expert knowledge but is successful when expert knowledge is supplied through the pheromone updating rule.	[Greene, Casey S.; White, Bill C.; Moore, Jason H.] Dartmouth Coll, Lebanon, NH 03756 USA	Greene, CS (reprint author), Dartmouth Coll, 1 Med Ctr Dr, Lebanon, NH 03756 USA.						DORIGO M, 1991, 91016 DIP EL INF; Freitas AA, 2001, ARTIF INTELL REV, V16, P177, DOI 10.1023/A:1011996210207; Goldberg D. E., 2002, DESIGN INNOVATION; Gonzalez G, 2007, PAC S BIOC, P28; Greene CS, 2007, LECT NOTES COMPUT SC, V4774, P30; Hoos Stutzle T., 1997, IEEE INT C EV COMP, P309; Altshuler D, 2005, NATURE, V437, P1299, DOI 10.1038/nature04226; KIRA K, 1992, MACHINE LEARNING; KONONENKO I, 1994, MACHINE LEARNING ECM, V94, P171; Merkle D, 2002, IEEE T EVOLUT COMPUT, V6, P333, DOI 10.1109/TEVC.2002.802450; Moore JH, 2006, LECT NOTES COMPUT SC, V4193, P969; MOORE JH, 2007, KNOWLEDGE DISCOVERY; Moore JH, 2004, EXPERT REV MOL DIAGN, V4, P795, DOI 10.1586/14737159.4.6.795; MOORE JH, 2007, GENETIC PROGRAMMING, V4; Moore JH, 2007, LECT NOTES COMPUT SC, V4447, P166; Moore JH, 2003, HUM HERED, V56, P73, DOI 10.1159/000073735; Moore JH, 2006, J THEOR BIOL, V241, P252, DOI 10.1016/j.jtbi.2005.11.036; Parpinelli R.S., 2001, P GEN EV COMP C, P791; Ritchie MD, 2001, AM J HUM GENET, V69, P138, DOI 10.1086/321276; Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714; Sokal R, 1995, BIOMETRY PRINCIPLES; Strauss C., 1999, CENTRAL EUROPEAN J O, V7, P25; Stutzle T, 2000, FUTURE GENER COMP SY, V16, P889, DOI 10.1016/S0167-739X(00)00043-1; White B. C., 2005, P IEEE C EV COMP, P676; Wilke RA, 2005, NAT REV DRUG DISCOV, V4, P911, DOI 10.1038/nrd1874	25	11	11	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-87526-0	LECT NOTES COMPUT SC			2008	5217						37	47				11	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BIK78	WOS:000260431900004	
B	Gyftodimos, E; Moss, L; Sleeman, D; Welch, A		Ellis, R; Allen, T; Petridis, M		Gyftodimos, Elias; Moss, Laura; Sleeman, Derek; Welch, Andrew			Analysing PET scans data for predicting response to chemotherapy in breast cancer patients	APPLICATIONS AND INNOVATIONS IN INTELLIGENT SYSTEMS XV			English	Proceedings Paper	27th SGAI International Conference on Innovative Techniques and Applications of Artificial Intelligence	DEC 10-12, 2007	Cambridge, ENGLAND	British Comp Soc Specialist Grp Artificial Intelligence			POSITRON-EMISSION-TOMOGRAPHY	We discuss the use of machine learning algorithms to predict which breast cancer patients are likely to respond to (neoadjunctive) chemotherapy. A group of 96 patients from the Aberdeen Royal Infirmary had the size of their tumours assessed by Positron Emission Tomography at various stages of their chemotherapy treatment. The aim is to predict at an early stage which patients have low response to the therapy, for which alternative treatment plans should be followed. A variety of machine learning algorithms were used with this data set. Results indicate that machine learning methods outperform previous statistical approaches on the same data set.	[Gyftodimos, Elias; Moss, Laura; Sleeman, Derek] Univ Aberdeen, Dept Comp Sci, Aberdeen AB9 1FX, Scotland	Gyftodimos, E (reprint author), Univ Aberdeen, Dept Comp Sci, Aberdeen AB9 1FX, Scotland.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Avril N, 2005, J CLIN ONCOL, V23, P7445, DOI 10.1200/JCO.2005.06.956; Black QC, 2004, INT J RADIAT ONCOL, V60, P1272, DOI 10.1016/j.ijrobp.2004.06.254; BONADONNA G, 1995, CA-CANCER J CLIN, V45, P227, DOI 10.3322/canjclin.45.4.227; Erdi YE, 1997, CANCER, V80, P2505, DOI 10.1002/(SICI)1097-0142(19971215)80:12+<2505::AID-CNCR24>3.3.CO;2-B; Fisher B, 1997, J CLIN ONCOL, V15, P2483; Freund Y., 1999, P 16 INT C MACH LEAR, P124; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Gennari A, 2000, Clin Breast Cancer, V1, P156, DOI 10.3816/CBC.2000.n.014; George HJ, 1995, P 11 C UNC ART INT, P338; Gregory F.C., 1992, MACH LEARN, V9, P309; Heckerman D, 1997, DATA MIN KNOWL DISC, V1, P79, DOI 10.1023/A:1009730122752; JANSSON T, 1995, J CLIN ONCOL, V13, P1470; Kaushal V, 2004, ENDOTHELIUM-J ENDOTH, V11, P253, DOI 10.1080/10623320490904124; Kohavi R, 1996, P 2 INT C KNOWL DISC; MCDERMOTT GM, 2006, BREAST CANC RES TREA; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Schelling M, 2000, J CLIN ONCOL, V18, P1689; Smith IC, 2000, J CLIN ONCOL, V18, P1676; Spaepen K, 2003, EUR J NUCL MED MOL I, V30, P682, DOI 10.1007/s00259-003-1120-6; Tom M M, 1997, MACHINE LEARNING; Wakabayashi I, 2003, CURR MED CHEM, V10, P427; Wieder HA, 2004, J CLIN ONCOL, V22, P900, DOI 10.1200/JCO.2004.07.122; Witten I. H., 2005, DATA MINING PRACTICA	24	0	0	SPRINGER-VERLAG LONDON LTD	GODALMING	SWEETAPPLE HOUSE CATTESHALL RD FARNCOMBE, GODALMING GU7 1NH, SURREY, ENGLAND		978-1-84800-085-8				2008							59	72		10.1007/978-1-84800-086-5_5		14	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BHB19	WOS:000252038200005	
S	Magness, DR; Huettmann, F; Morton, JM		Smolinski, TG; Milanova, MG; Hassanien, AE		Magness, Dawn R.; Huettmann, Falk; Morton, John M.			Using Random Forests to Provide Predicted Species Distribution Maps as a Metric for Ecological Inventory & Monitoring Programs	APPLICATIONS OF COMPUTATIONAL INTELLIGENCE IN BIOLOGY: CURRENT TRENDS AND OPEN PROBLEMS	Studies in Computational Intelligence		English	Article; Book Chapter							HABITAT MODELS; CONSERVATION	Sustainable management efforts are currently hindered by a lack of basic information about the spatial distribution of species on large landscapes. Based on complex ecological databases, computationally advanced species distribution models can provide great progress for solving this ecological problem. However, current lack of knowledge about the ecological relationships that drive species distributions reduces the capacity for classical statistical approaches to produce accurate predictive maps. Advancements in machine learning, like classification and bagging algorithms, provide a powerful tool for quickly building accurate predictive models of species distributions even when little ecological knowledge is readily available. Such approaches are also well known for their robustness when dealing with large data sets that have low quality. Here, we used Random Forests (Salford System's Ltd. and R language), a highly accurate bagging classification algorithm originally developed by L. Breiman and A. Cutler, to build multi-species avian distribution models using data collected as part of the Kenai National Wildlife Refuge Long-term Ecological Monitoring Program (LTEMP). Distribution maps are a useful monitoring metric because they can be used to document range expansions or contractions and can also be linked to population estimates. We utilized variable radius point count data collected in 2004 and 2006 at 255 points arranged in a 4.8 km resolution, systematic grid spanning the 7722 km 2 spatial extent of Alaska's Kenai National Wildlife Refuge. We built distribution models for 40 bird species that are present within 200m of 2-56% of the sampling points resulting in models that represent species which are both rare and common on the landscape. All models were built using a common set of 157 environmental predictor variables representing topographical features, climatic space, vegetation, anthropogenic variables, spatial structure, and 5 randomly generated neutral landscape variables for quality assessment. Models with that many predictors have not been used before in avian modeling, but are commonly used in similar types of applications in commercial disciplines. Random Forests produced strong models (ROC > 0.8) for 16 bird species, marginal models (0.7 > ROC < 0.8) for 13 species, and weak models (ROC < 0.7) for 11 species. The ability of Random Forests to provide accurate predictive models was independent of how common or rare a bird was on the landscape. Random Forests did not rank any of the 5 neutral landscape variables as important for any of the 41 bird species. We argue that for inventory and monitoring programs the interpretive focus and confidence in reliability should be placed in the predictive ability of the map, and not in the assumed ecological meaning of the predictors or their linear relationships to the response variable. Given this focus, computer learning algorithms would provide a very powerful, cost-saving approach for building reliable predictions of species occurrence on the landscape given the current lack of knowledge on the ecological drivers for many species. Land management agencies need reliable predictions of current species distributions in order to detect and understand how climate change and other landscape drivers will affect future biodiversity.	[Magness, Dawn R.; Huettmann, Falk] Univ Alaska, Dept Biol & Wildlife, EWHALE Lab, Inst Arctic Biol, Fairbanks, AK 99775 USA; [Magness, Dawn R.; Morton, John M.] US Fish & Wildlife Serv, Kenai Natl Wildlife Refuge, Soldotna, AL 99669 USA	Magness, DR (reprint author), Univ Alaska, Dept Biol & Wildlife, EWHALE Lab, Inst Arctic Biol, Fairbanks, AK 99775 USA.	dawn.magness@uaf.edu; fffh@uaf.edu; john_m_morton@fws.gov					ANGERMEIER PL, 1994, BIOSCIENCE, V44, P690, DOI 10.2307/1312512; Boyce MS, 1999, TRENDS ECOL EVOL, V14, P268, DOI 10.1016/S0169-5347(99)01593-1; BOYCE MS, 2002, ECOLOGICAL MODELLING, V157, P218; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Buckland S.T., 2001, INTRO DISTANCE SAMPL; BUSCH DE, 2003 MONITORING ECOS; CROZIER L, 2002, WILDLIFE RESPONSES C; Daly C, 2006, INT J CLIMATOL, V26, P707, DOI 10.1002/joc.1322; DAWSON DW, 1995, MONITORING BIRD POPU; Efron B., 1993, INTRO BOOTSTRAP; Elith J, 2006, ECOGRAPHY, V29, P129, DOI 10.1111/j.2006.0906-7590.04596.x; Fielding AH, 1997, ENVIRON CONSERV, V24, P38, DOI 10.1017/S0376892997000088; Gottschalk TK, 2005, INT J REMOTE SENS, V26, P2631, DOI 10.1080/01431160512331338041; Gu WD, 2004, BIOL CONSERV, V116, P195, DOI 10.1016/S0006-3207(03)00190-3; Guisan A, 2005, ECOL LETT, V8, P993, DOI 10.1111/j.1461-0248.2005.00792.x; Guisan A, 2000, ECOL MODEL, V135, P147, DOI 10.1016/S0304-3800(00)00354-9; Hand DJ, 1998, AM STAT, V52, P112, DOI 10.2307/2685468; HEGLUND PJ, 2002, PREDICTING SPECIES O; Hijmans RJ, 2005, INT J CLIMATOL, V25, P1965, DOI 10.1002/joc.1276; HOLTHAUSEN R, 2005, RMRSGTR161 US DEP AG; Lunetta R. S., 1998, REMOTE SENSING CHANG; MacKenzie DI, 2006, OCCUPANCY ESTIMATION; MCGARIGAL K, 1995, PNW351 US DEP AGR FO; Meretsky VJ, 2006, BIOSCIENCE, V56, P135, DOI 10.1641/0006-3568(2006)056[0135:NDICFT]2.0.CO;2; Parmesan C, 2003, NATURE, V421, P37, DOI 10.1038/nature01286; Pearce J, 2000, ECOL MODEL, V133, P225, DOI 10.1016/S0304-3800(00)00322-7; Yen PPW, 2004, ECOL MODEL, V171, P395, DOI 10.1016/j.ecolmodel.2003.07.006	28	6	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1860-949X	978-3-540-78533-0	STUD COMPUT INTELL			2008	122						209	229			10.1007/978-3-540-78534-7	21	Biology; Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Life Sciences & Biomedicine - Other Topics; Computer Science	BLZ08	WOS:000271477100009	
S	Colton, S		Giacobini, M		Colton, Simon			Automatic invention of fitness functions with application to scene generation	APPLICATIONS OF EVOLUTIONARY COMPUTING, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	Evoworkshops 2008	MAR 26-28, 2008	Naples, ITALY	Res Ctr Pure & Appl Math, Inst High Performance Comp & Networking, Natl Res Council, Univ Naples Federico II, Napier Univ Edinburgh, Ctr Emergent Comp				We investigate the automatic construction of visual scenes via a hybrid evolutionary/hill-climbing approach using a correlation-based fitness function. This forms part of The Painting Fool system, an automated artist which is able to render the scenes using simulated art materials. We further describe a novel method for inventing fitness functions using the HR descriptive machine learning system, and we combine this with The Painting Fool to generate and artistically render novel scenes. We demonstrate the potential of this approach with applications to cityscape and flower arrangement scene generation.	Univ London Imperial Coll Sci Technol & Med, Dept Comp, London SW7 2RH, England	Colton, S (reprint author), Univ London Imperial Coll Sci Technol & Med, Dept Comp, 180 Queens Gate, London SW7 2RH, England.						Boden M. A., 1990, CREATIVE MIND; Buchanan BG, 2001, AI MAG, V22, P13; COLTON S, 1999, J INTEGER SEQUENCES, V2; COLTON S, 2000, P 17 NAT C ART INT; COLTON S, 2002, AUTOMATED THEORY FOR; Colton S, 2006, MACH LEARN, V64, P25, DOI 10.1007/s10994-006-8259-x; MAHER ML, 1995, IEEE INT C EV COMP; McCorduck P, 1991, AARONS CODE METAART; Ritchie G., 2001, P AISB S ART INT CRE, P3; SORGE V, 2007, IN PRESS J AUTOMATED	10	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-78760-0	LECT NOTES COMPUT SC			2008	4974						381	391				11	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BHN58	WOS:000254509400041	
S	Marti, L; Garcia, J; Berlanga, A; Molina, JM		Giacobini, M		Marti, Luis; Garcia, Jesas; Berlanga, Antonio; Molina, Jose M.			Scalable continuous multiobjective optimization with a neural network-based estimation of distribution algorithm	APPLICATIONS OF EVOLUTIONARY COMPUTING, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	Evoworkshops 2008	MAR 26-28, 2008	Naples, ITALY	Res Ctr Pure & Appl Math, Inst High Performance Comp & Networking, Natl Res Council, Univ Naples Federico II, Napier Univ Edinburgh, Ctr Emergent Comp			CLUSTER-ANALYSIS	To achieve a substantial improvement of MOEDAs regarding MOEAs it is necessary to adapt their model building algorithm to suit this particular task. Most current model building schemes used so far off-the-shelf machine learning methods. However, the model building problem has specific requirements that those methods do not meet and even avoid. In this we work propose a novel approach to model building in MOEDAs using an algorithm custom-made for the task. We base our proposal on the growing neural gas (GNG) network. The resulting model-building GNG (MB-GNG) is capable of yielding good results when confronted to high-dimensional problems.	[Marti, Luis; Garcia, Jesas; Berlanga, Antonio; Molina, Jose M.] Univ Carlos III Madrid, Grp Appl Artificial Intelligence, Madrid, Spain	Marti, L (reprint author), Univ Carlos III Madrid, Grp Appl Artificial Intelligence, Av Univ Carlos 3,22-Colmenarejo, Madrid, Spain.						Ahn C. W., 2006, ADV EVOLUTIONARY ALG; Back T., 1996, EVOLUTIONARY ALGORIT; Bellman R., 1961, ADAPTIVE CONTROL PRO; Bleuler S, 2003, LECT NOTES COMPUT SC, V2632, P494; Bosman P.A.N., 2003, THESIS U UTRECHT UTR; Bosman PAN, 2005, LECT NOTES COMPUT SC, V3410, P428; Coello CAC, 2006, IEEE COMPUT INTELL M, V1, P28, DOI 10.1109/MCI.2006.1597059; Corne DW, 2003, LECT NOTES COMPUT SC, V2632, P327; Costa M, 2003, LECT NOTES COMPUT SC, V2859, P61; DEB K, 2004, EVOLUTIONARY MULTIOB, P105; Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017; DEB K, 2005, 2005011 KANGAL; Deb Kalyanmoi, 2001, MULTI OBJECTIVE OPTI; Fritzke B., 1995, ADV NEURAL INFORMATI, V7, P625; KNOWLES J, 2006, 214 COMP ENG NETW; Larranaga P, 2002, ESTIMATION DISTRIBUT; MARTINETZ TM, 1993, IEEE T NEURAL NETWOR, V4, P558, DOI 10.1109/72.238311; Miettinen K., 1999, INT SERIES OPERATION, V12; PARETO V, 1996, COURS EC POLITIQUE; PELIKANN M, 1999, 99018 ILLIGAL ILLIN; Qin AK, 2004, NEURAL NETWORKS, V17, P1135, DOI 10.1016/j.neunet.2004.06.013; Thomas Martinetz T. M., 1993, INT C ART NEUR NETW, P427; Timm H, 2004, FUZZY SET SYST, V147, P3, DOI 10.1016/j.fss.2003.11.009; Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141; ZHANG Q, 2007, IN PRESS IEEE T EVOL; Zitzler E, 2001, EVOLUTIONARY METHODS, P95	26	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-78760-0	LECT NOTES COMPUT SC			2008	4974						535	544				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BHN58	WOS:000254509400059	
J	Ludl, MC; Lewandowski, A; Dorffner, G				Ludl, Marcus-Christopher; Lewandowski, Achim; Dorffner, Georg			Adaptive machine learning in delayed feedback domains by selective relearning	APPLIED ARTIFICIAL INTELLIGENCE			English	Article							CONTEXT	We present a novel hybrid technique for improving the predictive performance of an online machine learning system: Combining advantages from both memory-based and concept-based procedures selective relearning tackles the problem of learning in gradually changing domains with delayed feedback. The idea is based on training and retraining the model only on the subsegment of the historical dataset which has been identified as the one most similar to the current conditions. We exemplify the effectiveness of our approach by evaluation in a well-known artificial dataset and show that selective relearning is rather insensitive to noise. Additionally, we present preliminary experimental results for a complex synthetic dataset resembling an online diagnostic system for the tile manufacturing industry and show that the procedure for selecting the best segment yields favorable training results in terms of the mean-squared error of the predictions.	[Dorffner, Georg] Med Univ Vienna, Ctr Brain Res, Dept Med Cybernet & Artificial Intelligence, A-1010 Vienna, Austria; [Ludl, Marcus-Christopher; Lewandowski, Achim] Austrian Res Inst Artificial Intelligence, Vienna, Austria	Lewandowski, A (reprint author), Med Univ Vienna, Ctr Brain Res, Dept Med Cybernet & Artificial Intelligence, Freyung 6-2, A-1010 Vienna, Austria.	achim.lewandowski@meduniwien.ac.at					Binder J, 1997, MACH LEARN, V29, P213, DOI 10.1023/A:1007421730016; DEVENTER R, 2000, P 14 EUR C ART INT E; Harries MB, 1998, MACH LEARN, V32, P101, DOI 10.1023/A:1007420529897; HELMBOLD DP, 1994, MACH LEARN, V14, P27, DOI 10.1007/BF00993161; Klinkenberg R, 2003, ADV SOFT COMP, P55; KLINKENBERG R, 2005, ANN WORKSH SPEC INT; KLINKENBERG R, 1998, WORKSH NOT ICML AAAI, P33; MAASS W, 1991, PROCEEDINGS OF THE FOURTH ANNUAL WORKSHOP ON COMPUTATIONAL LEARNING THEORY, P167; Maloof MA, 2000, MACH LEARN, V41, P27, DOI 10.1023/A:1007661119649; MALOOF MA, 1999, P 8 WORKSH INT INF S, P70; Poynton C, 1997, FREQUENTLY ASKED QUE; Salganicoff M., 1993, P 10 INT C MACH LEAR, P276; SCHLIMMER JC, P 5 NAT C ART INT LO, P505; Widmer G, 1997, MACH LEARN, V27, P259, DOI 10.1023/A:1007365809034; Widmer G, 1996, MACH LEARN, V23, P69, DOI 10.1023/A:1018046501280	15	1	1	TAYLOR & FRANCIS INC	PHILADELPHIA	325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA	0883-9514		APPL ARTIF INTELL	Appl. Artif. Intell.		2008	22	6					543	557		10.1080/08839510802226793		15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	331ID	WOS:000258005000003	
J	Webb, RY; Smith, PJ				Webb, Russell Y.; Smith, Peter J.			A population monte carlo method for generating random matrices with known characteristics	APPLIED ARTIFICIAL INTELLIGENCE			English	Article; Proceedings Paper	International Conference on Machine Learning - Models, Technologies and Applications	2007	Las Vegas, NV				SYSTEMS	An algorithm which provides approximate solutions to a certain matrix inverse problem is presented. In this inverse problem, we usually assume that the distribution of a functional of a random matrix is known. For example, we may know the distribution of the determinant or trace of the matrix. The algorithm attempts to find the mean and covariance structure of a random Gaussian matrix which yields the correct distribution for the functional. The algorithm is based on population Monte Carlo (PMC). Density estimation and importance sampling are used to converge toward a Gaussian matrix solution space described by the means and covariances. We also apply the algorithm to a machine learning problem without a known distribution and show the algorithm can find solutions maximizing an objective function. Results of the algorithm can give insights into the nature of random matrices with certain properties and allow statistical machine learning to create hypotheses about matrix structures from limited measurements. Furthermore, there are applications in testing and communications theory.	[Webb, Russell Y.; Smith, Peter J.] Univ Canterbury, Christchurch 8001, New Zealand	Webb, RY (reprint author), Univ Canterbury, Private Bag 4800, Christchurch 8001, New Zealand.	r.webb@elec.canterbury.ac.nz					ANDERWON TW, 2003, INTRO MULTIVARIATE S; Cappe O, 2004, J COMPUT GRAPH STAT, V13, P907, DOI 10.1198/106186004X12803; CASELLA G, 2000, RAO BLACKWELLIZATION; Cover TM, 1991, ELEMENTS INFORM THEO; DAVIES PI, 1999, GENERATING TEST MATR; Edelman A., 1989, THESIS MIT; Gupta A. K., 2000, MATRIX VARIATE DISTR; Jaeger H, 2004, SCIENCE, V304, P78, DOI 10.1126/science.1091277; JAMES AT, 1964, ANN MATH STAT, V35, P475, DOI 10.1214/aoms/1177703550; Johnstone IM, 2001, ANN STAT, V29, P295, DOI 10.1214/aos/1009210544; MACKEY MC, 1977, SCIENCE, V197, P287, DOI 10.1126/science.267326; Olkin I, 2002, LINEAR ALGEBRA APPL, V354, P231, DOI 10.1016/S0024-3795(01)00314-7; Press W. H., 1992, NUMERICAL RECIPES FO, P617; Robert C., 2004, MONTE CARLO STAT MET; Silverman B. W., 1986, DENSITY ESTIMATION; Smith PJ, 1997, IEEE J SEL AREA COMM, V15, P597, DOI 10.1109/49.585771; Tulino A. M., 2004, Foundations and Trends in Communications and Information Theory, V1, DOI 10.1561/0100000001	17	0	0	TAYLOR & FRANCIS INC	PHILADELPHIA	325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA	0883-9514		APPL ARTIF INTELL	Appl. Artif. Intell.		2008	22	7-8					730	748		10.1080/08839510802164143		19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	344DC	WOS:000258905000005	
B	Tan, SB; Wang, YF; Cheng, XQ			ACM	Tan, Songbo; Wang, Yuefen; Cheng, Xueqi			An Efficient Feature Ranking Measure for Text Categorization	APPLIED COMPUTING 2008, VOLS 1-3			English	Proceedings Paper	23rd Annual ACM Symposium on Applied Computing	MAR 16-20, 2008	Fortaleza, BRAZIL	ACM SIGAC, Univ Fortaleza, Federal Univ Ceara		Feature Selection; Document Categorization; Information Retrieval; Machine Learning		A major obstacle that decreases the performance of text classifiers is the extremely high dimensionality of text data. To reduce the dimension, a number of approaches based on rough-set theory have been proposed. However, these works often suffer from two problems: the first is that they cannot directly deal with continuous text features; the second is that they often incur considerable running time. To deal with the first issue, we make some extensions to discernibility matrix so that it can work with continuous features. To cut down running time, we employ centroids rather than examples to construct discernibility matrix, which reduce the time complexity from O(T(2)W) to O(K(2)W) where T denotes the size of training examples, K denotes the number of training classes and W denotes the size of vocabulary. The experimental results indicate that proposed method not only yields much higher accuracy than Information Gain when the number of selected features is smaller than 6000, but also incurs much smaller CPU time than Information Gain.	[Tan, Songbo; Cheng, Xueqi] Chinese Acad Sci, Inst Comp Technol, Informat Secur Ctr, Beijing 100864, Peoples R China	Tan, SB (reprint author), Chinese Acad Sci, Inst Comp Technol, Informat Secur Ctr, Beijing 100864, Peoples R China.	tansongbo@software.ict.ac.cn	Cheng, Xueqi/F-1706-2010; Tan, Songbo/A-7450-2012				BAO Y, ROUGH SET BASED HYBR, P254; BAO Y, EFFECTIVE ROUGH SET, P545; CHOUCHOULAS A, 1999, THESIS; CHOUCHOULAS A, ROUGH SET BASED APPR, P118; Dhillon I. S., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753661; GILADBACHRACH R, 2004, MARGIN BASED FEATURE; Han E.-H., 2000, CENTROID BASED DOCUM; HOA N, 1996, SOME EFFICIENT ALGOR; HU K, SAMPLING APPROXIMATE; JOACHIMS T, 1998, TEXT CATEGORIZATION, P137; JOHNSON DS, 1974, J COMPUT SYST SCI, V9, P256; Karypis G, 2000, TR000016 U MINN; LEWIS DD, 1996, TRAINING ALGORITHMS, P298; Liu H., 1998, FEATURE EXTRACTION C; McCallum A., 1998, AAAI 98 WORKSH LEARN, P41; MUN PT, TEXT CLASSIFICATION; Pal S. K., 1999, ROUGH FUZZY HYBRIDIZ; Pawlak Z., 1991, ROUGH SETS THEORETIC; Rijsbergen C.J.V., 1979, INFORM RETRIEVAL; Salton G., 1983, INTRO MODERN RETRIEV; Skowron A., 1992, HDB APPL ADV ROUGH S, P331; YANG Y, 1999, REEXAMINATION TEXT C, P42; YANG Y., 1997, COMP STUDY FEATURE S, P412	23	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA						2008							407	413				7	Computer Science, Interdisciplinary Applications	Computer Science	BKK67	WOS:000268392200076	
B	Su, XY; Khoshgoftaar, TM; Zhu, XQ; Greiner, R			ACM	Su, Xiaoyuan; Khoshgoftaar, Taghi M.; Zhu, Xingquan; Greiner, Russell			Imputation-Boosted Collaborative Filtering Using Machine Learning Classifiers	APPLIED COMPUTING 2008, VOLS 1-3			English	Proceedings Paper	23rd Annual ACM Symposium on Applied Computing	MAR 16-20, 2008	Fortaleza, BRAZIL	ACM SIGAC, Univ Fortaleza, Federal Univ Ceara		Collaborative filtering; recommendation systems; imputation techniques; machine learning classifiers; incomplete data		As data sparsity remains a significant challenge for collaborative filtering (CF), we conjecture that predicted ratings based on imputed data may be more accurate than those based on the originally very sparse rating data. In this paper, we propose a framework of imputation-boosted collaborative filtering (IBCF), which first uses an imputation technique, or perhaps machine learned classifier, to fill-in the sparse user-item rating matrix, then runs a traditional Pearson correlation-based CF algorithm on this matrix to predict a novel rating. Empirical results show that IBCF using machine learning classifiers can improve predictive accuracy of CF tasks. In particular, IBCF using a classifier capable of dealing well with missing data, such as naive Bayes, can outperform the content-boosted CF (a representative hybrid CF algorithm) and IBCF using PMM (predictive mean matching, a state-of-the-art imputation technique), without using external content information.	[Su, Xiaoyuan; Khoshgoftaar, Taghi M.; Zhu, Xingquan] Florida Atlantic Univ, Boca Raton, FL 33431 USA	Su, XY (reprint author), Florida Atlantic Univ, Boca Raton, FL 33431 USA.	xsu@fau.edu; taghi@cse.fau.edu; xqzhu@cse.fau.edu; greiner@cs.ualberta.ca					LITTLE RJA, 1988, J BUS ECON STAT, V6, P287, DOI 10.2307/1391878; Melville P., 2002, CONTENT BOOSTED COLL; Sarwar B, 2001, INT WORLD WID WEB C, P285; Witten I. H., 2005, DATA MINING PRACTICA	4	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA						2008							949	950				2	Computer Science, Interdisciplinary Applications	Computer Science	BKK67	WOS:000268392201018	
B	Barczak, ALC; Johnson, MJ; Messom, CH			ACM	Barczak, A. L. C.; Johnson, M. J.; Messom, C. H.			Empirical Evaluation of a New Structure for AdaBoost	APPLIED COMPUTING 2008, VOLS 1-3			English	Proceedings Paper	23rd Annual ACM Symposium on Applied Computing	MAR 16-20, 2008	Fortaleza, BRAZIL	ACM SIGAC, Univ Fortaleza, Federal Univ Ceara		Machine Learning; AdaBoost; Image Classification		We propose a mixed structure to form cascades for AdaBoost classifiers, where parallel strong classifiers are trained for each layer. The structure allows for rapid training and guarantees high hit rates without changing the original threshold. We implemented and tested the approach for two datasets from UCI [1], and compared results of binary classifiers using three different structures: standard AdaBoost, a cascade classifier with threshold adjustments, and the proposed structure.	[Barczak, A. L. C.; Johnson, M. J.; Messom, C. H.] Massey Univ, Inst Informat & Math Sci, Auckland, New Zealand	Barczak, ALC (reprint author), Massey Univ, Inst Informat & Math Sci, Private Bag 102904,N Shore Mail Ctr, Auckland, New Zealand.	a.l.barczak@massey.ac.nz; m.j.johnson@massey.ac.nz; c.h.messom@massey.ac.nz					Asuncion A., 2007, UCI MACHINE LEARNING; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; Lienhart R., 2003, IEEE ICME2003, P277; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb	4	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA						2008							1764	1765				2	Computer Science, Interdisciplinary Applications	Computer Science	BKK67	WOS:000268392202024	
B	Braga, PL; Oliveira, ALI; Meira, SRL			ACM	Braga, Petronio L.; Oliveira, Adriano L. I.; Meira, Silvio R. L.			A GA-based Feature Selection and Parameters Optimization for Support Vector Regression Applied to Software Effort Estimation	APPLIED COMPUTING 2008, VOLS 1-3			English	Proceedings Paper	23rd Annual ACM Symposium on Applied Computing	MAR 16-20, 2008	Fortaleza, BRAZIL	ACM SIGAC, Univ Fortaleza, Federal Univ Ceara		Support Vector Regression; Feature Selection; Genetic Algorithm; Software effort estimation		The precision of the estimation of the effort of software projects is very important for the competitiveness of software companies. Machine learning methods have recently been applied for this task, included methods based on sup port vector regression (SVR). This paper proposes and investigates the use of a genetic algorithm approach for simultaneously (1) select in optimal feature subset and (2) optimize SVR parameters, aiming to improve the precision of the software effort estimates. We report on experiments carried out using two datasets of software projects. In both datasets, the simulations have shown that the proposed GA-based approach was able to improve substantially the performance of SVR and outperform some recent results reported in the literature.	[Braga, Petronio L.; Oliveira, Adriano L. I.] Pernambuco State Univ, Dept Comp Syst, Recife, PE, Brazil	Braga, PL (reprint author), Pernambuco State Univ, Dept Comp Syst, Recife, PE, Brazil.	plb@dsc.upe.br; adriano@dsc.upe.br; srlm@cin.ufpe.br	Oliveira, Adriano/A-3532-2008				BRAGA PL, 2007, IEEE INT C TOOLS ART; BRAGA PL, 2007, IEEE INT JOINT C NEU; Burgess CJ, 2001, INFORM SOFTWARE TECH, V43, P863; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Engelbrecht A., 2006, FUNDAMENTALS COMPUTA; Huang CL, 2006, EXPERT SYST APPL, V31, P231, DOI 10.1016/j.eswa.2005.09.024; Oliveira ALI, 2006, NEUROCOMPUTING, V69, P1749, DOI 10.1016/j.neucom.2005.12.119; Shin M, 2000, IEEE T SOFTWARE ENG, V26, P567; Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88; *STAND GROUP, PROJ SUCC RAT IMPR 1	10	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA						2008							1788	1792				5	Computer Science, Interdisciplinary Applications	Computer Science	BKK67	WOS:000268392202029	
B	Sung, S; Chung, S; McLeod, D			ACM	Sung, Sangsoo; Chung, Seokkyung; McLeod, Dennis			Efficient Concept Clustering for Ontology Learning using an Event Life Cycle on the Web	APPLIED COMPUTING 2008, VOLS 1-3			English	Proceedings Paper	23rd Annual ACM Symposium on Applied Computing	MAR 16-20, 2008	Fortaleza, BRAZIL	ACM SIGAC, Univ Fortaleza, Federal Univ Ceara		concept clustering; ontology learning; similarity measures		Ontology learning integrates many complementary techniques, including machine learning, natural language processing, and data mining. Specifically, clustering techniques facilitate the building of interrelationships between terms by exploiting similarities of concepts. With the rapid growth of the Web, online information has become one of the major information sources. The ontology learning process where traditional clustering algorithms are involved tends to be slow and computationally expensive when the dataset is as large as the Web. To address this problem, we present an efficient concept clustering technique for ontology learning that reduces the number of required pairwise term similarity computations without a loss of quality. Our approach is to identify relevant terms using a computationally inexpensive similarity metric based on an event life cycle in online news articles. Then, we perform more sophisticated similarity computations. Hence, we can build clusters with high precision/recall and high speed. Without a loss of clustering quality, our framework reduces the number of required computations from O(N(2)) to (N + L(2)) (L << N) where N is the number of candidate concepts. Our experimental results show that clustering based on our similarity framework can construct concept clusters 1541.07% faster than clustering with all term pair similarity computations.	[Sung, Sangsoo] Google Inc, Mountain View, CA 94043 USA	Sung, S (reprint author), Google Inc, 1600 Amphitheater Pkwy, Mountain View, CA 94043 USA.	sangsoos@google.com; schung@yahoo-inc.com; mcleod@usc.edu					CHUNG S, 2006, OTM C 1, P1092; Gallistel CR, 2001, J EXP PSYCHOL ANIM B, V27, P354, DOI 10.1037//0097-7403.27.4.354; KLEINBERG JM, 2003, DATA MIN KNOWL DISCO, V7; McCallum A., 2000, KNOWLEDGE DISCOVERY, P169; MELAMED ID, 1995, CMPLG9505044 CORR; Miller George A., 1994, HLT; O'mahony M., 1986, SENSORY EVALUATION F; Salton G., 1983, INTRO MODERN INFORM; SUNG S, 2006, ICDE WORKSH, P6	9	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA						2008							2310	2314				5	Computer Science, Interdisciplinary Applications	Computer Science	BKK67	WOS:000268392202125	
B	Kuang, LW; Zulkernine, M			ACM	Kuang, Liwei; Zulkernine, Mohammad			An Anomaly Intrusion Detection Method Using the CSI-KNN Algorithm	APPLIED COMPUTING 2008, VOLS 1-3			English	Proceedings Paper	23rd Annual ACM Symposium on Applied Computing	MAR 16-20, 2008	Fortaleza, BRAZIL	ACM SIGAC, Univ Fortaleza, Federal Univ Ceara		Intrusion detection; Machine learning; CSI-KNN algorithm		Machine learning-based anomaly detection approaches have attracted increasing attention in the network intrusion detection community because of their intrinsic capabilities in discovering novel attacks. However, most of today's anomaly-based H)Ss generate high false positive rates and miss many attacks because of a deficiency in their ability to discriminate attacks from legitimate behaviors. In this paper, we propose an anomaly intrusion detection method using the Combined Strangeness and Isolation measure K-Nearest Neighbors (CSI-KNN) algorithm. The intrusion detection algorithm analyzes different characteristics of network data by employing two measures: strangeness and isolation. Based on these measures, a correlation unit raises intrusion alerts with associated confidence estimates. Multiple CSI-KNN classifiers work in parallel to deal with different types of network services so that the CSI-KNN-based NIDS can work more efficiently than processing all network services together.	[Kuang, Liwei; Zulkernine, Mohammad] Queens Univ, Sch Comp, Kingston, ON, Canada	Kuang, LW (reprint author), Queens Univ, Sch Comp, Kingston, ON, Canada.	kuang@cs.queensu.ca; mzulker@cs.queensu.ca					BARBARA D, 2006, P 12 ANN SIGKDD INT, P54; Elkan C., 2000, SIGKDD EXPLORATIONS, V1, P63; Eskin E., 2002, APPL DATA MINING COM; Garcia E., 2006, COSINE SIMILARITY TE; HWANG TS, 2007, MINENET 07; LEE W, 2000, P ACM T INF SYST SEC, V3, P227; LI Y, 2007, ASIACCS 07, P13; Liao YH, 2002, COMPUT SECUR, V21, P439, DOI 10.1016/S0167-4048(02)00514-X; McHugh J., 2000, ACM Transactions on Information and Systems Security, V3, DOI 10.1145/382912.382923; PRAEDROU K, 2002, LECT NOTES COMPUTER, V2430, P381; Prerau M.J., THESIS; SKOUDIS E, 2005, COUNTER HACK RELOADE; *MIT LINC LAB, DARPA INTR DET EV DA; KDD CUP 1999 DATA IN	14	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA						2008							921	926				6	Computer Science, Interdisciplinary Applications	Computer Science	BKK67	WOS:000268392201013	
